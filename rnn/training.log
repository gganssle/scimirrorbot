tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 606, val: 32, test: 0	
vocab size: 169	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 306985	
cloning rnn	
cloning criterion	
1/30300 (epoch 0.002), train_loss = 5.13631993, grad/param norm = 5.7536e-01, time/batch = 0.7339s	
2/30300 (epoch 0.003), train_loss = 4.84621572, grad/param norm = 1.5568e+00, time/batch = 0.6924s	
3/30300 (epoch 0.005), train_loss = 4.01442518, grad/param norm = 1.4764e+00, time/batch = 0.6948s	
4/30300 (epoch 0.007), train_loss = 3.88513857, grad/param norm = 1.0133e+00, time/batch = 0.7054s	
5/30300 (epoch 0.008), train_loss = 3.74222392, grad/param norm = 8.4594e-01, time/batch = 0.6899s	
6/30300 (epoch 0.010), train_loss = 3.49501040, grad/param norm = 6.2738e-01, time/batch = 0.6950s	
7/30300 (epoch 0.012), train_loss = 3.51998183, grad/param norm = 6.4039e-01, time/batch = 0.6924s	
8/30300 (epoch 0.013), train_loss = 3.54089310, grad/param norm = 5.6220e-01, time/batch = 0.6978s	
9/30300 (epoch 0.015), train_loss = 3.55367157, grad/param norm = 5.8775e-01, time/batch = 0.7200s	
10/30300 (epoch 0.017), train_loss = 3.43792190, grad/param norm = 8.0885e-01, time/batch = 0.7024s	
11/30300 (epoch 0.018), train_loss = 3.44542226, grad/param norm = 7.6484e-01, time/batch = 0.6930s	
12/30300 (epoch 0.020), train_loss = 3.56656158, grad/param norm = 7.3837e-01, time/batch = 0.6907s	
13/30300 (epoch 0.021), train_loss = 3.40076297, grad/param norm = 8.4501e-01, time/batch = 0.6906s	
14/30300 (epoch 0.023), train_loss = 3.53374795, grad/param norm = 8.0634e-01, time/batch = 0.6898s	
15/30300 (epoch 0.025), train_loss = 3.52714375, grad/param norm = 7.4821e-01, time/batch = 0.6926s	
16/30300 (epoch 0.026), train_loss = 3.55280429, grad/param norm = 6.8797e-01, time/batch = 0.6877s	
17/30300 (epoch 0.028), train_loss = 3.52166780, grad/param norm = 6.0334e-01, time/batch = 0.6884s	
18/30300 (epoch 0.030), train_loss = 3.54890677, grad/param norm = 6.2562e-01, time/batch = 0.6920s	
19/30300 (epoch 0.031), train_loss = 3.54964691, grad/param norm = 8.1566e-01, time/batch = 0.6905s	
20/30300 (epoch 0.033), train_loss = 3.60946509, grad/param norm = 7.0713e-01, time/batch = 0.6947s	
21/30300 (epoch 0.035), train_loss = 3.48425018, grad/param norm = 6.0668e-01, time/batch = 0.6892s	
22/30300 (epoch 0.036), train_loss = 3.68329353, grad/param norm = 7.4324e-01, time/batch = 0.6890s	
23/30300 (epoch 0.038), train_loss = 3.46122948, grad/param norm = 6.3775e-01, time/batch = 0.7121s	
24/30300 (epoch 0.040), train_loss = 3.43640867, grad/param norm = 5.5798e-01, time/batch = 0.7082s	
25/30300 (epoch 0.041), train_loss = 3.56575688, grad/param norm = 6.4631e-01, time/batch = 0.6914s	
26/30300 (epoch 0.043), train_loss = 3.47737007, grad/param norm = 6.0657e-01, time/batch = 0.6923s	
27/30300 (epoch 0.045), train_loss = 3.56335950, grad/param norm = 6.7250e-01, time/batch = 0.6896s	
28/30300 (epoch 0.046), train_loss = 3.39522477, grad/param norm = 6.4989e-01, time/batch = 0.6883s	
29/30300 (epoch 0.048), train_loss = 3.45410817, grad/param norm = 5.4553e-01, time/batch = 0.6898s	
30/30300 (epoch 0.050), train_loss = 3.86625072, grad/param norm = 8.7660e-01, time/batch = 0.6905s	
31/30300 (epoch 0.051), train_loss = 3.86048260, grad/param norm = 9.1270e-01, time/batch = 0.6889s	
32/30300 (epoch 0.053), train_loss = 3.66069431, grad/param norm = 6.7261e-01, time/batch = 0.6894s	
33/30300 (epoch 0.054), train_loss = 3.49714137, grad/param norm = 7.1951e-01, time/batch = 0.6893s	
34/30300 (epoch 0.056), train_loss = 3.47494699, grad/param norm = 6.1702e-01, time/batch = 0.6898s	
35/30300 (epoch 0.058), train_loss = 3.55586412, grad/param norm = 5.4803e-01, time/batch = 0.6994s	
36/30300 (epoch 0.059), train_loss = 3.61738345, grad/param norm = 7.8526e-01, time/batch = 0.6938s	
37/30300 (epoch 0.061), train_loss = 3.43180688, grad/param norm = 7.1375e-01, time/batch = 0.7018s	
38/30300 (epoch 0.063), train_loss = 3.48235889, grad/param norm = 6.2154e-01, time/batch = 0.7190s	
39/30300 (epoch 0.064), train_loss = 3.56526613, grad/param norm = 5.6734e-01, time/batch = 0.6867s	
40/30300 (epoch 0.066), train_loss = 3.48719317, grad/param norm = 5.9271e-01, time/batch = 0.6896s	
41/30300 (epoch 0.068), train_loss = 3.33412486, grad/param norm = 4.2863e-01, time/batch = 0.6872s	
42/30300 (epoch 0.069), train_loss = 3.58336772, grad/param norm = 6.5384e-01, time/batch = 0.6900s	
43/30300 (epoch 0.071), train_loss = 3.55858334, grad/param norm = 7.5235e-01, time/batch = 0.7007s	
44/30300 (epoch 0.073), train_loss = 3.47130808, grad/param norm = 5.7224e-01, time/batch = 0.6912s	
45/30300 (epoch 0.074), train_loss = 3.48236172, grad/param norm = 5.0732e-01, time/batch = 0.6912s	
46/30300 (epoch 0.076), train_loss = 3.46581851, grad/param norm = 7.0818e-01, time/batch = 0.6864s	
47/30300 (epoch 0.078), train_loss = 3.52225762, grad/param norm = 7.7170e-01, time/batch = 0.6903s	
48/30300 (epoch 0.079), train_loss = 3.42636028, grad/param norm = 7.0247e-01, time/batch = 0.6930s	
49/30300 (epoch 0.081), train_loss = 3.55097970, grad/param norm = 7.3051e-01, time/batch = 0.6924s	
50/30300 (epoch 0.083), train_loss = 3.71919277, grad/param norm = 6.6252e-01, time/batch = 0.6859s	
51/30300 (epoch 0.084), train_loss = 3.41185160, grad/param norm = 6.5802e-01, time/batch = 0.6924s	
52/30300 (epoch 0.086), train_loss = 3.50877092, grad/param norm = 5.7652e-01, time/batch = 0.6896s	
53/30300 (epoch 0.087), train_loss = 3.37587213, grad/param norm = 4.6923e-01, time/batch = 0.6842s	
54/30300 (epoch 0.089), train_loss = 3.59922700, grad/param norm = 5.9468e-01, time/batch = 0.6933s	
55/30300 (epoch 0.091), train_loss = 3.34157190, grad/param norm = 5.9890e-01, time/batch = 0.6891s	
56/30300 (epoch 0.092), train_loss = 3.40530510, grad/param norm = 5.1215e-01, time/batch = 0.6962s	
57/30300 (epoch 0.094), train_loss = 3.56842383, grad/param norm = 6.4107e-01, time/batch = 0.6875s	
58/30300 (epoch 0.096), train_loss = 3.43062740, grad/param norm = 8.5331e-01, time/batch = 0.6933s	
59/30300 (epoch 0.097), train_loss = 3.48852540, grad/param norm = 7.3616e-01, time/batch = 0.6988s	
60/30300 (epoch 0.099), train_loss = 3.65190954, grad/param norm = 9.1680e-01, time/batch = 0.6960s	
61/30300 (epoch 0.101), train_loss = 3.95801232, grad/param norm = 8.2450e-01, time/batch = 0.6959s	
62/30300 (epoch 0.102), train_loss = 4.03596705, grad/param norm = 8.8592e-01, time/batch = 0.6947s	
63/30300 (epoch 0.104), train_loss = 4.02637774, grad/param norm = 9.4513e-01, time/batch = 0.6921s	
64/30300 (epoch 0.106), train_loss = 3.90734710, grad/param norm = 8.1909e-01, time/batch = 0.6891s	
65/30300 (epoch 0.107), train_loss = 3.69830631, grad/param norm = 4.5236e-01, time/batch = 0.6943s	
66/30300 (epoch 0.109), train_loss = 3.56646706, grad/param norm = 5.8150e-01, time/batch = 0.6882s	
67/30300 (epoch 0.111), train_loss = 3.42862411, grad/param norm = 5.7281e-01, time/batch = 0.7026s	
68/30300 (epoch 0.112), train_loss = 3.51948805, grad/param norm = 4.8494e-01, time/batch = 0.6865s	
69/30300 (epoch 0.114), train_loss = 3.41908294, grad/param norm = 5.3986e-01, time/batch = 0.6914s	
70/30300 (epoch 0.116), train_loss = 3.49972585, grad/param norm = 4.2507e-01, time/batch = 0.6891s	
71/30300 (epoch 0.117), train_loss = 3.54194151, grad/param norm = 5.7484e-01, time/batch = 0.6911s	
72/30300 (epoch 0.119), train_loss = 3.38915235, grad/param norm = 5.5716e-01, time/batch = 0.7056s	
73/30300 (epoch 0.120), train_loss = 3.42704709, grad/param norm = 6.2140e-01, time/batch = 0.7028s	
74/30300 (epoch 0.122), train_loss = 3.45279203, grad/param norm = 5.8195e-01, time/batch = 0.7042s	
75/30300 (epoch 0.124), train_loss = 3.50377645, grad/param norm = 6.6664e-01, time/batch = 0.6853s	
76/30300 (epoch 0.125), train_loss = 3.50772348, grad/param norm = 5.1124e-01, time/batch = 0.6877s	
77/30300 (epoch 0.127), train_loss = 3.47479423, grad/param norm = 4.8660e-01, time/batch = 0.6872s	
78/30300 (epoch 0.129), train_loss = 3.41125989, grad/param norm = 6.9872e-01, time/batch = 0.6891s	
79/30300 (epoch 0.130), train_loss = 3.53978852, grad/param norm = 5.8951e-01, time/batch = 0.6847s	
80/30300 (epoch 0.132), train_loss = 3.43904533, grad/param norm = 8.7145e-01, time/batch = 0.7121s	
81/30300 (epoch 0.134), train_loss = 3.41134212, grad/param norm = 6.7109e-01, time/batch = 0.7045s	
82/30300 (epoch 0.135), train_loss = 3.55132301, grad/param norm = 6.4003e-01, time/batch = 0.6914s	
83/30300 (epoch 0.137), train_loss = 3.44906754, grad/param norm = 5.9675e-01, time/batch = 0.6915s	
84/30300 (epoch 0.139), train_loss = 3.62465188, grad/param norm = 6.9126e-01, time/batch = 0.6958s	
85/30300 (epoch 0.140), train_loss = 4.00128817, grad/param norm = 6.3573e-01, time/batch = 0.6941s	
86/30300 (epoch 0.142), train_loss = 3.93685329, grad/param norm = 7.0406e-01, time/batch = 0.6878s	
87/30300 (epoch 0.144), train_loss = 3.82480493, grad/param norm = 6.4085e-01, time/batch = 0.6983s	
88/30300 (epoch 0.145), train_loss = 3.92524328, grad/param norm = 5.9499e-01, time/batch = 0.6998s	
89/30300 (epoch 0.147), train_loss = 3.88151540, grad/param norm = 8.4066e-01, time/batch = 0.6827s	
90/30300 (epoch 0.149), train_loss = 3.83994716, grad/param norm = 5.4527e-01, time/batch = 0.6974s	
91/30300 (epoch 0.150), train_loss = 3.84752494, grad/param norm = 3.4743e-01, time/batch = 0.7208s	
92/30300 (epoch 0.152), train_loss = 3.66245681, grad/param norm = 4.3358e-01, time/batch = 0.6898s	
93/30300 (epoch 0.153), train_loss = 3.76412761, grad/param norm = 9.4981e-01, time/batch = 0.6946s	
94/30300 (epoch 0.155), train_loss = 3.95799714, grad/param norm = 2.4907e+00, time/batch = 0.6836s	
95/30300 (epoch 0.157), train_loss = 3.71040428, grad/param norm = 3.8449e-01, time/batch = 0.6827s	
96/30300 (epoch 0.158), train_loss = 3.77410121, grad/param norm = 5.5380e-01, time/batch = 0.6830s	
97/30300 (epoch 0.160), train_loss = 3.44852095, grad/param norm = 4.7594e-01, time/batch = 0.6849s	
98/30300 (epoch 0.162), train_loss = 3.52046640, grad/param norm = 5.6022e-01, time/batch = 0.6862s	
99/30300 (epoch 0.163), train_loss = 3.46278350, grad/param norm = 4.9169e-01, time/batch = 0.6874s	
100/30300 (epoch 0.165), train_loss = 3.57770138, grad/param norm = 5.1586e-01, time/batch = 0.6875s	
101/30300 (epoch 0.167), train_loss = 3.56319410, grad/param norm = 3.8565e-01, time/batch = 0.6829s	
102/30300 (epoch 0.168), train_loss = 3.41428918, grad/param norm = 4.5157e-01, time/batch = 0.6932s	
103/30300 (epoch 0.170), train_loss = 3.75168279, grad/param norm = 7.2010e-01, time/batch = 0.6899s	
104/30300 (epoch 0.172), train_loss = 3.63238247, grad/param norm = 5.6674e-01, time/batch = 0.6857s	
105/30300 (epoch 0.173), train_loss = 3.56497286, grad/param norm = 4.1801e-01, time/batch = 0.6905s	
106/30300 (epoch 0.175), train_loss = 3.53580012, grad/param norm = 4.2619e-01, time/batch = 0.6874s	
107/30300 (epoch 0.177), train_loss = 3.54990809, grad/param norm = 4.4108e-01, time/batch = 0.6898s	
108/30300 (epoch 0.178), train_loss = 3.46490859, grad/param norm = 3.5661e-01, time/batch = 0.6942s	
109/30300 (epoch 0.180), train_loss = 3.45740166, grad/param norm = 3.9061e-01, time/batch = 0.6902s	
110/30300 (epoch 0.182), train_loss = 3.30243301, grad/param norm = 5.5428e-01, time/batch = 0.7040s	
111/30300 (epoch 0.183), train_loss = 3.41471031, grad/param norm = 4.1746e-01, time/batch = 0.6916s	
112/30300 (epoch 0.185), train_loss = 3.51905170, grad/param norm = 5.6962e-01, time/batch = 0.6968s	
113/30300 (epoch 0.186), train_loss = 3.47781628, grad/param norm = 5.3595e-01, time/batch = 0.7130s	
114/30300 (epoch 0.188), train_loss = 3.32705619, grad/param norm = 4.0481e-01, time/batch = 0.7193s	
115/30300 (epoch 0.190), train_loss = 3.38975853, grad/param norm = 6.4936e-01, time/batch = 0.6920s	
116/30300 (epoch 0.191), train_loss = 3.46335141, grad/param norm = 4.9778e-01, time/batch = 0.6959s	
117/30300 (epoch 0.193), train_loss = 3.41276246, grad/param norm = 4.2748e-01, time/batch = 0.6917s	
118/30300 (epoch 0.195), train_loss = 3.51743114, grad/param norm = 5.2153e-01, time/batch = 0.6885s	
119/30300 (epoch 0.196), train_loss = 3.31704825, grad/param norm = 5.8954e-01, time/batch = 0.6903s	
120/30300 (epoch 0.198), train_loss = 3.34758122, grad/param norm = 9.9903e-01, time/batch = 0.6896s	
121/30300 (epoch 0.200), train_loss = 3.51857488, grad/param norm = 7.1921e-01, time/batch = 0.7001s	
122/30300 (epoch 0.201), train_loss = 3.59906551, grad/param norm = 4.9473e-01, time/batch = 0.6966s	
123/30300 (epoch 0.203), train_loss = 3.46498949, grad/param norm = 5.0510e-01, time/batch = 0.7114s	
124/30300 (epoch 0.205), train_loss = 3.56597466, grad/param norm = 3.9983e-01, time/batch = 0.7208s	
125/30300 (epoch 0.206), train_loss = 3.53548415, grad/param norm = 3.7673e-01, time/batch = 0.6948s	
126/30300 (epoch 0.208), train_loss = 3.44290623, grad/param norm = 3.1542e-01, time/batch = 0.7004s	
127/30300 (epoch 0.210), train_loss = 3.40080787, grad/param norm = 3.9368e-01, time/batch = 0.6936s	
128/30300 (epoch 0.211), train_loss = 3.39346917, grad/param norm = 4.5959e-01, time/batch = 0.6949s	
129/30300 (epoch 0.213), train_loss = 3.36829483, grad/param norm = 4.4734e-01, time/batch = 0.7022s	
130/30300 (epoch 0.215), train_loss = 3.40217121, grad/param norm = 7.5092e-01, time/batch = 0.6962s	
131/30300 (epoch 0.216), train_loss = 3.50891336, grad/param norm = 5.8181e-01, time/batch = 0.6937s	
132/30300 (epoch 0.218), train_loss = 3.42500649, grad/param norm = 5.1704e-01, time/batch = 0.6966s	
133/30300 (epoch 0.219), train_loss = 3.37221771, grad/param norm = 7.1679e-01, time/batch = 0.7072s	
134/30300 (epoch 0.221), train_loss = 3.47880399, grad/param norm = 4.0227e-01, time/batch = 0.6892s	
135/30300 (epoch 0.223), train_loss = 3.61323517, grad/param norm = 6.7173e-01, time/batch = 0.6907s	
136/30300 (epoch 0.224), train_loss = 3.53900214, grad/param norm = 4.6547e-01, time/batch = 0.6878s	
137/30300 (epoch 0.226), train_loss = 3.38078204, grad/param norm = 4.9520e-01, time/batch = 0.6878s	
138/30300 (epoch 0.228), train_loss = 3.32476362, grad/param norm = 4.9353e-01, time/batch = 0.7192s	
139/30300 (epoch 0.229), train_loss = 3.31855875, grad/param norm = 7.9656e-01, time/batch = 0.7180s	
140/30300 (epoch 0.231), train_loss = 3.38135705, grad/param norm = 7.0445e-01, time/batch = 0.7188s	
141/30300 (epoch 0.233), train_loss = 3.31028933, grad/param norm = 4.0079e-01, time/batch = 0.7072s	
142/30300 (epoch 0.234), train_loss = 3.43346131, grad/param norm = 4.9650e-01, time/batch = 0.7060s	
143/30300 (epoch 0.236), train_loss = 3.43821933, grad/param norm = 5.3602e-01, time/batch = 0.7102s	
144/30300 (epoch 0.238), train_loss = 3.37278202, grad/param norm = 5.2892e-01, time/batch = 0.7128s	
145/30300 (epoch 0.239), train_loss = 3.62960833, grad/param norm = 1.1939e+00, time/batch = 0.7180s	
146/30300 (epoch 0.241), train_loss = 3.66224235, grad/param norm = 1.0465e+00, time/batch = 0.7167s	
147/30300 (epoch 0.243), train_loss = 3.53233717, grad/param norm = 4.4749e-01, time/batch = 0.7149s	
148/30300 (epoch 0.244), train_loss = 3.55595325, grad/param norm = 4.3148e-01, time/batch = 0.7166s	
149/30300 (epoch 0.246), train_loss = 3.57115804, grad/param norm = 3.6554e-01, time/batch = 0.7170s	
150/30300 (epoch 0.248), train_loss = 3.36700886, grad/param norm = 3.9051e-01, time/batch = 0.7276s	
151/30300 (epoch 0.249), train_loss = 3.36998674, grad/param norm = 3.2212e-01, time/batch = 0.7284s	
152/30300 (epoch 0.251), train_loss = 3.38919815, grad/param norm = 4.3061e-01, time/batch = 0.7287s	
153/30300 (epoch 0.252), train_loss = 3.46506263, grad/param norm = 5.2113e-01, time/batch = 0.7273s	
154/30300 (epoch 0.254), train_loss = 3.44661575, grad/param norm = 3.6692e-01, time/batch = 0.7268s	
155/30300 (epoch 0.256), train_loss = 3.30510394, grad/param norm = 6.6984e-01, time/batch = 0.7274s	
156/30300 (epoch 0.257), train_loss = 3.52240437, grad/param norm = 1.3629e+00, time/batch = 0.7492s	
157/30300 (epoch 0.259), train_loss = 3.37912863, grad/param norm = 9.3637e-01, time/batch = 0.7508s	
158/30300 (epoch 0.261), train_loss = 3.46047487, grad/param norm = 5.1024e-01, time/batch = 0.7444s	
159/30300 (epoch 0.262), train_loss = 3.38162653, grad/param norm = 3.5893e-01, time/batch = 0.7403s	
160/30300 (epoch 0.264), train_loss = 3.23156300, grad/param norm = 3.7902e-01, time/batch = 0.7501s	
161/30300 (epoch 0.266), train_loss = 3.28198149, grad/param norm = 4.1677e-01, time/batch = 0.7434s	
162/30300 (epoch 0.267), train_loss = 3.31420419, grad/param norm = 3.8733e-01, time/batch = 0.7276s	
163/30300 (epoch 0.269), train_loss = 3.34517853, grad/param norm = 3.0127e-01, time/batch = 0.7484s	
164/30300 (epoch 0.271), train_loss = 3.45505683, grad/param norm = 4.5845e-01, time/batch = 0.7406s	
165/30300 (epoch 0.272), train_loss = 3.35997062, grad/param norm = 5.8305e-01, time/batch = 0.7333s	
166/30300 (epoch 0.274), train_loss = 3.47103991, grad/param norm = 6.7806e-01, time/batch = 0.7140s	
167/30300 (epoch 0.276), train_loss = 3.49584309, grad/param norm = 6.2166e-01, time/batch = 0.6869s	
168/30300 (epoch 0.277), train_loss = 3.41101659, grad/param norm = 1.0193e+00, time/batch = 0.6917s	
169/30300 (epoch 0.279), train_loss = 3.30804526, grad/param norm = 3.8822e-01, time/batch = 0.6884s	
170/30300 (epoch 0.281), train_loss = 3.21758389, grad/param norm = 3.8464e-01, time/batch = 0.6875s	
171/30300 (epoch 0.282), train_loss = 3.36256103, grad/param norm = 5.2370e-01, time/batch = 0.7084s	
172/30300 (epoch 0.284), train_loss = 3.34989655, grad/param norm = 5.9832e-01, time/batch = 0.6891s	
173/30300 (epoch 0.285), train_loss = 3.32375740, grad/param norm = 6.1654e-01, time/batch = 0.6860s	
174/30300 (epoch 0.287), train_loss = 3.35604817, grad/param norm = 7.3713e-01, time/batch = 0.6856s	
175/30300 (epoch 0.289), train_loss = 3.22030058, grad/param norm = 6.8079e-01, time/batch = 0.6861s	
176/30300 (epoch 0.290), train_loss = 3.30743245, grad/param norm = 5.3652e-01, time/batch = 0.6874s	
177/30300 (epoch 0.292), train_loss = 3.30080000, grad/param norm = 5.4634e-01, time/batch = 0.6891s	
178/30300 (epoch 0.294), train_loss = 3.53595961, grad/param norm = 4.5945e-01, time/batch = 0.6932s	
179/30300 (epoch 0.295), train_loss = 3.37665085, grad/param norm = 4.0812e-01, time/batch = 0.6952s	
180/30300 (epoch 0.297), train_loss = 3.30795327, grad/param norm = 5.0307e-01, time/batch = 0.7206s	
181/30300 (epoch 0.299), train_loss = 3.29134188, grad/param norm = 6.3023e-01, time/batch = 0.6925s	
182/30300 (epoch 0.300), train_loss = 3.32812370, grad/param norm = 9.2434e-01, time/batch = 0.6904s	
183/30300 (epoch 0.302), train_loss = 3.27341560, grad/param norm = 1.0346e+00, time/batch = 0.6876s	
184/30300 (epoch 0.304), train_loss = 3.33261313, grad/param norm = 8.5450e-01, time/batch = 0.6880s	
185/30300 (epoch 0.305), train_loss = 3.21645516, grad/param norm = 6.1695e-01, time/batch = 0.6875s	
186/30300 (epoch 0.307), train_loss = 3.21445079, grad/param norm = 4.8993e-01, time/batch = 0.6949s	
187/30300 (epoch 0.309), train_loss = 3.36209906, grad/param norm = 5.0868e-01, time/batch = 0.6976s	
188/30300 (epoch 0.310), train_loss = 3.21322315, grad/param norm = 4.2035e-01, time/batch = 0.6919s	
189/30300 (epoch 0.312), train_loss = 3.12981491, grad/param norm = 5.2878e-01, time/batch = 0.6957s	
190/30300 (epoch 0.314), train_loss = 3.29028668, grad/param norm = 6.7869e-01, time/batch = 0.6906s	
191/30300 (epoch 0.315), train_loss = 3.23171375, grad/param norm = 7.7604e-01, time/batch = 0.6940s	
192/30300 (epoch 0.317), train_loss = 3.33732800, grad/param norm = 1.0163e+00, time/batch = 0.6904s	
193/30300 (epoch 0.318), train_loss = 3.31424428, grad/param norm = 8.4465e-01, time/batch = 0.6970s	
194/30300 (epoch 0.320), train_loss = 3.28006442, grad/param norm = 5.3332e-01, time/batch = 0.7198s	
195/30300 (epoch 0.322), train_loss = 3.27398714, grad/param norm = 5.2265e-01, time/batch = 0.7046s	
196/30300 (epoch 0.323), train_loss = 3.14593430, grad/param norm = 5.4199e-01, time/batch = 0.6896s	
197/30300 (epoch 0.325), train_loss = 3.31257989, grad/param norm = 5.0944e-01, time/batch = 0.6895s	
198/30300 (epoch 0.327), train_loss = 3.23571690, grad/param norm = 4.8152e-01, time/batch = 0.6988s	
199/30300 (epoch 0.328), train_loss = 3.12616882, grad/param norm = 4.5821e-01, time/batch = 0.6868s	
200/30300 (epoch 0.330), train_loss = 3.33154511, grad/param norm = 6.1174e-01, time/batch = 0.6918s	
201/30300 (epoch 0.332), train_loss = 3.22709216, grad/param norm = 6.9651e-01, time/batch = 0.6942s	
202/30300 (epoch 0.333), train_loss = 3.39940077, grad/param norm = 8.0624e-01, time/batch = 0.7041s	
203/30300 (epoch 0.335), train_loss = 3.25585308, grad/param norm = 6.8959e-01, time/batch = 0.6948s	
204/30300 (epoch 0.337), train_loss = 3.19447708, grad/param norm = 3.4831e-01, time/batch = 0.6892s	
205/30300 (epoch 0.338), train_loss = 3.23318820, grad/param norm = 3.6917e-01, time/batch = 0.6908s	
206/30300 (epoch 0.340), train_loss = 3.15417588, grad/param norm = 3.5158e-01, time/batch = 0.6924s	
207/30300 (epoch 0.342), train_loss = 3.18462078, grad/param norm = 3.5992e-01, time/batch = 0.7031s	
208/30300 (epoch 0.343), train_loss = 3.24364933, grad/param norm = 5.0010e-01, time/batch = 0.7254s	
209/30300 (epoch 0.345), train_loss = 3.23408687, grad/param norm = 5.5937e-01, time/batch = 0.7211s	
210/30300 (epoch 0.347), train_loss = 3.07109075, grad/param norm = 4.9936e-01, time/batch = 0.7198s	
211/30300 (epoch 0.348), train_loss = 3.15715904, grad/param norm = 6.3258e-01, time/batch = 0.7276s	
212/30300 (epoch 0.350), train_loss = 3.14731276, grad/param norm = 4.7827e-01, time/batch = 0.7213s	
213/30300 (epoch 0.351), train_loss = 3.21741398, grad/param norm = 3.6149e-01, time/batch = 0.7034s	
214/30300 (epoch 0.353), train_loss = 3.14720384, grad/param norm = 2.9498e-01, time/batch = 0.6948s	
215/30300 (epoch 0.355), train_loss = 3.30099098, grad/param norm = 3.9593e-01, time/batch = 0.6890s	
216/30300 (epoch 0.356), train_loss = 3.30668952, grad/param norm = 5.3555e-01, time/batch = 0.6858s	
217/30300 (epoch 0.358), train_loss = 3.17204038, grad/param norm = 5.6146e-01, time/batch = 0.6865s	
218/30300 (epoch 0.360), train_loss = 3.17122284, grad/param norm = 6.4873e-01, time/batch = 0.6889s	
219/30300 (epoch 0.361), train_loss = 3.11837423, grad/param norm = 1.0366e+00, time/batch = 0.6917s	
220/30300 (epoch 0.363), train_loss = 3.39918754, grad/param norm = 1.0865e+00, time/batch = 0.6866s	
221/30300 (epoch 0.365), train_loss = 3.33726270, grad/param norm = 1.0889e+00, time/batch = 0.6912s	
222/30300 (epoch 0.366), train_loss = 3.26106400, grad/param norm = 1.0902e+00, time/batch = 0.6895s	
223/30300 (epoch 0.368), train_loss = 3.20214359, grad/param norm = 6.8486e-01, time/batch = 0.6889s	
224/30300 (epoch 0.370), train_loss = 3.22899096, grad/param norm = 4.4562e-01, time/batch = 0.6871s	
225/30300 (epoch 0.371), train_loss = 3.16446491, grad/param norm = 3.3026e-01, time/batch = 0.6856s	
226/30300 (epoch 0.373), train_loss = 3.22617106, grad/param norm = 3.6238e-01, time/batch = 0.6890s	
227/30300 (epoch 0.375), train_loss = 3.18324541, grad/param norm = 3.3599e-01, time/batch = 0.7206s	
228/30300 (epoch 0.376), train_loss = 3.13034392, grad/param norm = 3.8127e-01, time/batch = 0.6979s	
229/30300 (epoch 0.378), train_loss = 3.19281617, grad/param norm = 5.5406e-01, time/batch = 0.6884s	
230/30300 (epoch 0.380), train_loss = 3.18044729, grad/param norm = 8.0707e-01, time/batch = 0.6926s	
231/30300 (epoch 0.381), train_loss = 3.27527725, grad/param norm = 9.1224e-01, time/batch = 0.6892s	
232/30300 (epoch 0.383), train_loss = 3.19923228, grad/param norm = 6.1975e-01, time/batch = 0.6908s	
233/30300 (epoch 0.384), train_loss = 3.28513321, grad/param norm = 5.4480e-01, time/batch = 0.6862s	
234/30300 (epoch 0.386), train_loss = 3.13040338, grad/param norm = 5.6913e-01, time/batch = 0.6886s	
235/30300 (epoch 0.388), train_loss = 3.14351172, grad/param norm = 5.4585e-01, time/batch = 0.6851s	
236/30300 (epoch 0.389), train_loss = 3.19399809, grad/param norm = 5.3406e-01, time/batch = 0.6906s	
237/30300 (epoch 0.391), train_loss = 3.14591580, grad/param norm = 2.9527e-01, time/batch = 0.6917s	
238/30300 (epoch 0.393), train_loss = 3.15040691, grad/param norm = 4.4437e-01, time/batch = 0.6893s	
239/30300 (epoch 0.394), train_loss = 3.17228872, grad/param norm = 4.7156e-01, time/batch = 0.6876s	
240/30300 (epoch 0.396), train_loss = 3.12296002, grad/param norm = 3.8354e-01, time/batch = 0.6933s	
241/30300 (epoch 0.398), train_loss = 3.14400397, grad/param norm = 3.4761e-01, time/batch = 0.7114s	
242/30300 (epoch 0.399), train_loss = 3.16883093, grad/param norm = 4.5408e-01, time/batch = 0.7148s	
243/30300 (epoch 0.401), train_loss = 3.12503666, grad/param norm = 5.8803e-01, time/batch = 0.7130s	
244/30300 (epoch 0.403), train_loss = 3.11906127, grad/param norm = 9.0702e-01, time/batch = 0.6968s	
245/30300 (epoch 0.404), train_loss = 3.17645623, grad/param norm = 1.0564e+00, time/batch = 0.6894s	
246/30300 (epoch 0.406), train_loss = 3.07770978, grad/param norm = 9.6619e-01, time/batch = 0.6892s	
247/30300 (epoch 0.408), train_loss = 3.11409635, grad/param norm = 6.4612e-01, time/batch = 0.6909s	
248/30300 (epoch 0.409), train_loss = 2.97292663, grad/param norm = 3.7361e-01, time/batch = 0.6942s	
249/30300 (epoch 0.411), train_loss = 3.04588499, grad/param norm = 5.2590e-01, time/batch = 0.6941s	
250/30300 (epoch 0.413), train_loss = 3.07107148, grad/param norm = 4.6172e-01, time/batch = 0.6910s	
251/30300 (epoch 0.414), train_loss = 3.21249945, grad/param norm = 4.2663e-01, time/batch = 0.6889s	
252/30300 (epoch 0.416), train_loss = 3.17935904, grad/param norm = 5.1565e-01, time/batch = 0.6915s	
253/30300 (epoch 0.417), train_loss = 3.13349406, grad/param norm = 4.8814e-01, time/batch = 0.6931s	
254/30300 (epoch 0.419), train_loss = 3.12135775, grad/param norm = 6.9363e-01, time/batch = 0.6956s	
255/30300 (epoch 0.421), train_loss = 3.04964361, grad/param norm = 6.4219e-01, time/batch = 0.7043s	
256/30300 (epoch 0.422), train_loss = 3.11793090, grad/param norm = 6.9059e-01, time/batch = 0.7206s	
257/30300 (epoch 0.424), train_loss = 3.12726560, grad/param norm = 8.0672e-01, time/batch = 0.6886s	
258/30300 (epoch 0.426), train_loss = 3.07421500, grad/param norm = 9.7161e-01, time/batch = 0.6928s	
259/30300 (epoch 0.427), train_loss = 3.10369729, grad/param norm = 8.9960e-01, time/batch = 0.7034s	
260/30300 (epoch 0.429), train_loss = 3.16386746, grad/param norm = 7.6958e-01, time/batch = 0.6935s	
261/30300 (epoch 0.431), train_loss = 3.05423615, grad/param norm = 7.0188e-01, time/batch = 0.6908s	
262/30300 (epoch 0.432), train_loss = 3.00920799, grad/param norm = 3.9919e-01, time/batch = 0.7003s	
263/30300 (epoch 0.434), train_loss = 3.01571109, grad/param norm = 4.8873e-01, time/batch = 0.6994s	
264/30300 (epoch 0.436), train_loss = 3.04478547, grad/param norm = 6.5136e-01, time/batch = 0.6975s	
265/30300 (epoch 0.437), train_loss = 3.16459320, grad/param norm = 6.5388e-01, time/batch = 0.6912s	
266/30300 (epoch 0.439), train_loss = 3.17397845, grad/param norm = 4.4559e-01, time/batch = 0.6888s	
267/30300 (epoch 0.441), train_loss = 2.99167679, grad/param norm = 2.8531e-01, time/batch = 0.6874s	
268/30300 (epoch 0.442), train_loss = 3.04467517, grad/param norm = 3.8989e-01, time/batch = 0.6903s	
269/30300 (epoch 0.444), train_loss = 3.01369301, grad/param norm = 3.9765e-01, time/batch = 0.6910s	
270/30300 (epoch 0.446), train_loss = 2.95010382, grad/param norm = 3.7022e-01, time/batch = 0.7206s	
271/30300 (epoch 0.447), train_loss = 3.08182162, grad/param norm = 4.6393e-01, time/batch = 0.6966s	
272/30300 (epoch 0.449), train_loss = 3.10834662, grad/param norm = 6.8723e-01, time/batch = 0.6882s	
273/30300 (epoch 0.450), train_loss = 3.04144088, grad/param norm = 4.0482e-01, time/batch = 0.6856s	
274/30300 (epoch 0.452), train_loss = 3.02445331, grad/param norm = 5.9577e-01, time/batch = 0.6853s	
275/30300 (epoch 0.454), train_loss = 2.98465342, grad/param norm = 7.7643e-01, time/batch = 0.6880s	
276/30300 (epoch 0.455), train_loss = 3.19544185, grad/param norm = 1.1085e+00, time/batch = 0.6883s	
277/30300 (epoch 0.457), train_loss = 3.14106784, grad/param norm = 7.7808e-01, time/batch = 0.6859s	
278/30300 (epoch 0.459), train_loss = 3.02330452, grad/param norm = 7.3864e-01, time/batch = 0.6851s	
279/30300 (epoch 0.460), train_loss = 3.05252011, grad/param norm = 7.7344e-01, time/batch = 0.6840s	
280/30300 (epoch 0.462), train_loss = 3.07545068, grad/param norm = 4.5511e-01, time/batch = 0.6845s	
281/30300 (epoch 0.464), train_loss = 3.12088927, grad/param norm = 4.3010e-01, time/batch = 0.6879s	
282/30300 (epoch 0.465), train_loss = 2.97981680, grad/param norm = 3.2850e-01, time/batch = 0.6863s	
283/30300 (epoch 0.467), train_loss = 3.06436863, grad/param norm = 3.4686e-01, time/batch = 0.6869s	
284/30300 (epoch 0.469), train_loss = 2.93149327, grad/param norm = 2.9096e-01, time/batch = 0.6895s	
285/30300 (epoch 0.470), train_loss = 3.11944868, grad/param norm = 4.4131e-01, time/batch = 0.6874s	
286/30300 (epoch 0.472), train_loss = 2.97073801, grad/param norm = 5.6037e-01, time/batch = 0.6923s	
287/30300 (epoch 0.474), train_loss = 3.06186688, grad/param norm = 5.9126e-01, time/batch = 0.6877s	
288/30300 (epoch 0.475), train_loss = 3.05774672, grad/param norm = 6.8092e-01, time/batch = 0.6843s	
289/30300 (epoch 0.477), train_loss = 3.03187623, grad/param norm = 5.6702e-01, time/batch = 0.6835s	
290/30300 (epoch 0.479), train_loss = 3.08876124, grad/param norm = 4.3901e-01, time/batch = 0.6854s	
291/30300 (epoch 0.480), train_loss = 3.00022198, grad/param norm = 5.3130e-01, time/batch = 0.6969s	
292/30300 (epoch 0.482), train_loss = 3.07435620, grad/param norm = 5.0704e-01, time/batch = 0.6934s	
293/30300 (epoch 0.483), train_loss = 2.89747674, grad/param norm = 8.0742e-01, time/batch = 0.6918s	
294/30300 (epoch 0.485), train_loss = 3.11259661, grad/param norm = 9.7276e-01, time/batch = 0.6855s	
295/30300 (epoch 0.487), train_loss = 3.05157293, grad/param norm = 9.4682e-01, time/batch = 0.7013s	
296/30300 (epoch 0.488), train_loss = 2.91477042, grad/param norm = 6.2750e-01, time/batch = 0.6904s	
297/30300 (epoch 0.490), train_loss = 3.09680137, grad/param norm = 4.3722e-01, time/batch = 0.6876s	
298/30300 (epoch 0.492), train_loss = 3.02146083, grad/param norm = 4.1589e-01, time/batch = 0.6886s	
299/30300 (epoch 0.493), train_loss = 2.97256633, grad/param norm = 3.9679e-01, time/batch = 0.6860s	
300/30300 (epoch 0.495), train_loss = 2.90379884, grad/param norm = 4.2702e-01, time/batch = 0.6870s	
301/30300 (epoch 0.497), train_loss = 2.81332481, grad/param norm = 4.5213e-01, time/batch = 0.6894s	
302/30300 (epoch 0.498), train_loss = 3.06652892, grad/param norm = 4.6791e-01, time/batch = 0.6853s	
303/30300 (epoch 0.500), train_loss = 3.21381115, grad/param norm = 7.1751e-01, time/batch = 0.7156s	
304/30300 (epoch 0.502), train_loss = 3.02358454, grad/param norm = 1.1764e+00, time/batch = 0.7062s	
305/30300 (epoch 0.503), train_loss = 3.01040838, grad/param norm = 6.9661e-01, time/batch = 0.6895s	
306/30300 (epoch 0.505), train_loss = 2.99348112, grad/param norm = 4.6146e-01, time/batch = 0.6884s	
307/30300 (epoch 0.507), train_loss = 2.91445406, grad/param norm = 3.8039e-01, time/batch = 0.6846s	
308/30300 (epoch 0.508), train_loss = 3.01076872, grad/param norm = 3.0945e-01, time/batch = 0.6854s	
309/30300 (epoch 0.510), train_loss = 2.96107822, grad/param norm = 4.1154e-01, time/batch = 0.6848s	
310/30300 (epoch 0.512), train_loss = 2.88982672, grad/param norm = 4.4480e-01, time/batch = 0.6883s	
311/30300 (epoch 0.513), train_loss = 3.01791787, grad/param norm = 3.9489e-01, time/batch = 0.6865s	
312/30300 (epoch 0.515), train_loss = 2.92365187, grad/param norm = 4.7992e-01, time/batch = 0.6881s	
313/30300 (epoch 0.517), train_loss = 2.87939142, grad/param norm = 6.7530e-01, time/batch = 0.6915s	
314/30300 (epoch 0.518), train_loss = 3.05830838, grad/param norm = 1.3200e+00, time/batch = 0.6884s	
315/30300 (epoch 0.520), train_loss = 3.07860270, grad/param norm = 9.1669e-01, time/batch = 0.6891s	
316/30300 (epoch 0.521), train_loss = 2.96923805, grad/param norm = 7.3333e-01, time/batch = 0.6891s	
317/30300 (epoch 0.523), train_loss = 3.03669481, grad/param norm = 8.9342e-01, time/batch = 0.7029s	
318/30300 (epoch 0.525), train_loss = 3.05381363, grad/param norm = 6.9967e-01, time/batch = 0.7187s	
319/30300 (epoch 0.526), train_loss = 2.91300992, grad/param norm = 4.7653e-01, time/batch = 0.6824s	
320/30300 (epoch 0.528), train_loss = 2.91594655, grad/param norm = 3.4499e-01, time/batch = 0.6840s	
321/30300 (epoch 0.530), train_loss = 3.07426286, grad/param norm = 3.7032e-01, time/batch = 0.6870s	
322/30300 (epoch 0.531), train_loss = 2.94739936, grad/param norm = 4.4377e-01, time/batch = 0.6853s	
323/30300 (epoch 0.533), train_loss = 2.99841736, grad/param norm = 3.1480e-01, time/batch = 0.6846s	
324/30300 (epoch 0.535), train_loss = 2.85517621, grad/param norm = 3.5722e-01, time/batch = 0.6842s	
325/30300 (epoch 0.536), train_loss = 2.92742124, grad/param norm = 4.1248e-01, time/batch = 0.6833s	
326/30300 (epoch 0.538), train_loss = 2.83931635, grad/param norm = 5.1578e-01, time/batch = 0.6861s	
327/30300 (epoch 0.540), train_loss = 3.00561704, grad/param norm = 6.0022e-01, time/batch = 0.6848s	
328/30300 (epoch 0.541), train_loss = 2.88099231, grad/param norm = 5.7982e-01, time/batch = 0.6851s	
329/30300 (epoch 0.543), train_loss = 2.97648229, grad/param norm = 5.8321e-01, time/batch = 0.7058s	
330/30300 (epoch 0.545), train_loss = 2.95290158, grad/param norm = 6.0794e-01, time/batch = 0.6967s	
331/30300 (epoch 0.546), train_loss = 2.91147718, grad/param norm = 5.6004e-01, time/batch = 0.7023s	
332/30300 (epoch 0.548), train_loss = 2.79749940, grad/param norm = 5.5149e-01, time/batch = 0.7191s	
333/30300 (epoch 0.550), train_loss = 3.16881908, grad/param norm = 7.0016e-01, time/batch = 0.7161s	
334/30300 (epoch 0.551), train_loss = 3.00700098, grad/param norm = 8.0246e-01, time/batch = 0.6954s	
335/30300 (epoch 0.553), train_loss = 2.95438124, grad/param norm = 7.4129e-01, time/batch = 0.6987s	
336/30300 (epoch 0.554), train_loss = 2.96604969, grad/param norm = 4.9768e-01, time/batch = 0.6936s	
337/30300 (epoch 0.556), train_loss = 2.90437139, grad/param norm = 3.8396e-01, time/batch = 0.6922s	
338/30300 (epoch 0.558), train_loss = 2.89670406, grad/param norm = 4.1185e-01, time/batch = 0.6982s	
339/30300 (epoch 0.559), train_loss = 2.90808926, grad/param norm = 4.7293e-01, time/batch = 0.7168s	
340/30300 (epoch 0.561), train_loss = 2.92447779, grad/param norm = 6.5725e-01, time/batch = 0.6966s	
341/30300 (epoch 0.563), train_loss = 2.98261385, grad/param norm = 6.7869e-01, time/batch = 0.6990s	
342/30300 (epoch 0.564), train_loss = 2.89772300, grad/param norm = 3.7393e-01, time/batch = 0.7044s	
343/30300 (epoch 0.566), train_loss = 2.93809124, grad/param norm = 3.3993e-01, time/batch = 0.7024s	
344/30300 (epoch 0.568), train_loss = 2.81610217, grad/param norm = 4.7805e-01, time/batch = 0.7045s	
345/30300 (epoch 0.569), train_loss = 2.87022808, grad/param norm = 6.2870e-01, time/batch = 0.6888s	
346/30300 (epoch 0.571), train_loss = 2.94943866, grad/param norm = 7.8759e-01, time/batch = 0.7163s	
347/30300 (epoch 0.573), train_loss = 2.86220125, grad/param norm = 6.0624e-01, time/batch = 0.7125s	
348/30300 (epoch 0.574), train_loss = 2.94658382, grad/param norm = 4.0863e-01, time/batch = 0.6920s	
349/30300 (epoch 0.576), train_loss = 2.97285467, grad/param norm = 4.1601e-01, time/batch = 0.6880s	
350/30300 (epoch 0.578), train_loss = 2.87317114, grad/param norm = 3.8085e-01, time/batch = 0.6981s	
351/30300 (epoch 0.579), train_loss = 2.79011510, grad/param norm = 4.4463e-01, time/batch = 0.6904s	
352/30300 (epoch 0.581), train_loss = 3.08210276, grad/param norm = 7.3547e-01, time/batch = 0.6884s	
353/30300 (epoch 0.583), train_loss = 2.96309479, grad/param norm = 7.2666e-01, time/batch = 0.6899s	
354/30300 (epoch 0.584), train_loss = 2.85409396, grad/param norm = 3.6987e-01, time/batch = 0.6896s	
355/30300 (epoch 0.586), train_loss = 2.87704847, grad/param norm = 4.6288e-01, time/batch = 0.6910s	
356/30300 (epoch 0.587), train_loss = 2.79077950, grad/param norm = 6.2687e-01, time/batch = 0.6929s	
357/30300 (epoch 0.589), train_loss = 2.74316675, grad/param norm = 5.3253e-01, time/batch = 0.6899s	
358/30300 (epoch 0.591), train_loss = 2.80219747, grad/param norm = 3.3196e-01, time/batch = 0.7005s	
359/30300 (epoch 0.592), train_loss = 2.83409165, grad/param norm = 5.0717e-01, time/batch = 0.7000s	
360/30300 (epoch 0.594), train_loss = 2.81222725, grad/param norm = 6.5364e-01, time/batch = 0.7141s	
361/30300 (epoch 0.596), train_loss = 2.76816219, grad/param norm = 6.8695e-01, time/batch = 0.7223s	
362/30300 (epoch 0.597), train_loss = 2.82287636, grad/param norm = 5.8119e-01, time/batch = 0.7100s	
363/30300 (epoch 0.599), train_loss = 2.81957370, grad/param norm = 7.2813e-01, time/batch = 0.7066s	
364/30300 (epoch 0.601), train_loss = 2.81451038, grad/param norm = 8.1130e-01, time/batch = 0.6979s	
365/30300 (epoch 0.602), train_loss = 2.77020039, grad/param norm = 6.5892e-01, time/batch = 0.6995s	
366/30300 (epoch 0.604), train_loss = 2.91217133, grad/param norm = 6.8082e-01, time/batch = 0.7047s	
367/30300 (epoch 0.606), train_loss = 3.28212252, grad/param norm = 7.3318e-01, time/batch = 0.7007s	
368/30300 (epoch 0.607), train_loss = 2.96824427, grad/param norm = 6.9746e-01, time/batch = 0.6899s	
369/30300 (epoch 0.609), train_loss = 2.90270313, grad/param norm = 3.7265e-01, time/batch = 0.6932s	
370/30300 (epoch 0.611), train_loss = 2.70595889, grad/param norm = 4.2178e-01, time/batch = 0.6927s	
371/30300 (epoch 0.612), train_loss = 2.84167041, grad/param norm = 2.7613e-01, time/batch = 0.6903s	
372/30300 (epoch 0.614), train_loss = 2.71901108, grad/param norm = 3.3591e-01, time/batch = 0.6942s	
373/30300 (epoch 0.616), train_loss = 2.88784538, grad/param norm = 3.2068e-01, time/batch = 0.7007s	
374/30300 (epoch 0.617), train_loss = 2.81603036, grad/param norm = 4.1376e-01, time/batch = 0.7053s	
375/30300 (epoch 0.619), train_loss = 2.66809720, grad/param norm = 5.7423e-01, time/batch = 0.7206s	
376/30300 (epoch 0.620), train_loss = 2.93178016, grad/param norm = 9.7505e-01, time/batch = 0.6905s	
377/30300 (epoch 0.622), train_loss = 2.84449666, grad/param norm = 8.8585e-01, time/batch = 0.6936s	
378/30300 (epoch 0.624), train_loss = 2.82914527, grad/param norm = 4.4894e-01, time/batch = 0.6981s	
379/30300 (epoch 0.625), train_loss = 2.79401065, grad/param norm = 4.0864e-01, time/batch = 0.6924s	
380/30300 (epoch 0.627), train_loss = 2.82909936, grad/param norm = 2.9388e-01, time/batch = 0.6932s	
381/30300 (epoch 0.629), train_loss = 2.84124688, grad/param norm = 3.4059e-01, time/batch = 0.6938s	
382/30300 (epoch 0.630), train_loss = 2.80616866, grad/param norm = 4.8152e-01, time/batch = 0.6876s	
383/30300 (epoch 0.632), train_loss = 2.86704735, grad/param norm = 7.6436e-01, time/batch = 0.6929s	
384/30300 (epoch 0.634), train_loss = 2.72141382, grad/param norm = 6.6701e-01, time/batch = 0.6902s	
385/30300 (epoch 0.635), train_loss = 2.82624494, grad/param norm = 7.5581e-01, time/batch = 0.6925s	
386/30300 (epoch 0.637), train_loss = 2.87690759, grad/param norm = 7.3656e-01, time/batch = 0.6907s	
387/30300 (epoch 0.639), train_loss = 2.68048655, grad/param norm = 6.7179e-01, time/batch = 0.6903s	
388/30300 (epoch 0.640), train_loss = 2.84299429, grad/param norm = 6.4876e-01, time/batch = 0.6882s	
389/30300 (epoch 0.642), train_loss = 2.79720036, grad/param norm = 4.5605e-01, time/batch = 0.7203s	
390/30300 (epoch 0.644), train_loss = 2.78644135, grad/param norm = 3.9141e-01, time/batch = 0.7028s	
391/30300 (epoch 0.645), train_loss = 2.68108225, grad/param norm = 4.3511e-01, time/batch = 0.6907s	
392/30300 (epoch 0.647), train_loss = 2.76904103, grad/param norm = 4.8594e-01, time/batch = 0.6950s	
393/30300 (epoch 0.649), train_loss = 2.80632556, grad/param norm = 5.1373e-01, time/batch = 0.6882s	
394/30300 (epoch 0.650), train_loss = 2.72692239, grad/param norm = 3.9049e-01, time/batch = 0.6902s	
395/30300 (epoch 0.652), train_loss = 2.67285815, grad/param norm = 3.9655e-01, time/batch = 0.6937s	
396/30300 (epoch 0.653), train_loss = 2.87647045, grad/param norm = 5.3404e-01, time/batch = 0.6941s	
397/30300 (epoch 0.655), train_loss = 2.81556309, grad/param norm = 3.8558e-01, time/batch = 0.6876s	
398/30300 (epoch 0.657), train_loss = 2.85489811, grad/param norm = 2.9600e-01, time/batch = 0.6933s	
399/30300 (epoch 0.658), train_loss = 2.74799661, grad/param norm = 2.9103e-01, time/batch = 0.6926s	
400/30300 (epoch 0.660), train_loss = 2.74053329, grad/param norm = 4.1061e-01, time/batch = 0.6878s	
401/30300 (epoch 0.662), train_loss = 2.79395336, grad/param norm = 6.0641e-01, time/batch = 0.6932s	
402/30300 (epoch 0.663), train_loss = 2.79589771, grad/param norm = 6.7708e-01, time/batch = 0.6944s	
403/30300 (epoch 0.665), train_loss = 2.76234046, grad/param norm = 7.8626e-01, time/batch = 0.6959s	
404/30300 (epoch 0.667), train_loss = 2.82914256, grad/param norm = 7.6176e-01, time/batch = 0.6865s	
405/30300 (epoch 0.668), train_loss = 2.83750591, grad/param norm = 5.6454e-01, time/batch = 0.6902s	
406/30300 (epoch 0.670), train_loss = 2.75383263, grad/param norm = 3.4500e-01, time/batch = 0.6923s	
407/30300 (epoch 0.672), train_loss = 2.84650367, grad/param norm = 3.0110e-01, time/batch = 0.6917s	
408/30300 (epoch 0.673), train_loss = 2.74398622, grad/param norm = 3.0673e-01, time/batch = 0.6892s	
409/30300 (epoch 0.675), train_loss = 2.70384597, grad/param norm = 3.4149e-01, time/batch = 0.6947s	
410/30300 (epoch 0.677), train_loss = 2.70851345, grad/param norm = 3.9998e-01, time/batch = 0.6931s	
411/30300 (epoch 0.678), train_loss = 2.73143768, grad/param norm = 3.6427e-01, time/batch = 0.6905s	
412/30300 (epoch 0.680), train_loss = 2.62009672, grad/param norm = 3.9855e-01, time/batch = 0.6908s	
413/30300 (epoch 0.682), train_loss = 2.66135760, grad/param norm = 3.7249e-01, time/batch = 0.6933s	
414/30300 (epoch 0.683), train_loss = 2.74980344, grad/param norm = 4.5960e-01, time/batch = 0.6910s	
415/30300 (epoch 0.685), train_loss = 2.87432319, grad/param norm = 4.9442e-01, time/batch = 0.7110s	
416/30300 (epoch 0.686), train_loss = 2.73356380, grad/param norm = 4.3693e-01, time/batch = 0.7115s	
417/30300 (epoch 0.688), train_loss = 2.77048789, grad/param norm = 4.6582e-01, time/batch = 0.6989s	
418/30300 (epoch 0.690), train_loss = 2.66051256, grad/param norm = 5.3029e-01, time/batch = 0.7049s	
419/30300 (epoch 0.691), train_loss = 2.74405131, grad/param norm = 8.3494e-01, time/batch = 0.7049s	
420/30300 (epoch 0.693), train_loss = 2.81847037, grad/param norm = 7.9449e-01, time/batch = 0.6959s	
421/30300 (epoch 0.695), train_loss = 2.85936609, grad/param norm = 6.3468e-01, time/batch = 0.7082s	
422/30300 (epoch 0.696), train_loss = 2.81582737, grad/param norm = 4.7165e-01, time/batch = 0.7350s	
423/30300 (epoch 0.698), train_loss = 2.76116278, grad/param norm = 3.0747e-01, time/batch = 0.6978s	
424/30300 (epoch 0.700), train_loss = 2.61042637, grad/param norm = 3.8089e-01, time/batch = 0.7037s	
425/30300 (epoch 0.701), train_loss = 2.55879553, grad/param norm = 3.6995e-01, time/batch = 0.6925s	
426/30300 (epoch 0.703), train_loss = 2.58395258, grad/param norm = 2.9923e-01, time/batch = 0.6967s	
427/30300 (epoch 0.705), train_loss = 2.74788333, grad/param norm = 4.0449e-01, time/batch = 0.6978s	
428/30300 (epoch 0.706), train_loss = 2.62979255, grad/param norm = 5.0310e-01, time/batch = 0.7098s	
429/30300 (epoch 0.708), train_loss = 2.67677327, grad/param norm = 5.2562e-01, time/batch = 0.7094s	
430/30300 (epoch 0.710), train_loss = 2.65613517, grad/param norm = 3.7874e-01, time/batch = 0.6938s	
431/30300 (epoch 0.711), train_loss = 2.57609979, grad/param norm = 3.5284e-01, time/batch = 0.6978s	
432/30300 (epoch 0.713), train_loss = 2.61364720, grad/param norm = 3.5302e-01, time/batch = 0.7267s	
433/30300 (epoch 0.715), train_loss = 2.66093284, grad/param norm = 4.1612e-01, time/batch = 0.7103s	
434/30300 (epoch 0.716), train_loss = 2.81195874, grad/param norm = 5.2545e-01, time/batch = 0.6930s	
435/30300 (epoch 0.718), train_loss = 2.75777091, grad/param norm = 5.1527e-01, time/batch = 0.6911s	
436/30300 (epoch 0.719), train_loss = 2.67399877, grad/param norm = 5.5270e-01, time/batch = 0.7035s	
437/30300 (epoch 0.721), train_loss = 2.76896017, grad/param norm = 3.9811e-01, time/batch = 0.6871s	
438/30300 (epoch 0.723), train_loss = 2.60336092, grad/param norm = 3.0089e-01, time/batch = 0.6845s	
439/30300 (epoch 0.724), train_loss = 2.75887620, grad/param norm = 5.3182e-01, time/batch = 0.6885s	
440/30300 (epoch 0.726), train_loss = 3.00731301, grad/param norm = 7.8779e-01, time/batch = 0.6862s	
441/30300 (epoch 0.728), train_loss = 2.57602775, grad/param norm = 4.2070e-01, time/batch = 0.6923s	
442/30300 (epoch 0.729), train_loss = 2.83892731, grad/param norm = 6.2014e-01, time/batch = 0.6953s	
443/30300 (epoch 0.731), train_loss = 2.72116213, grad/param norm = 5.6064e-01, time/batch = 0.6896s	
444/30300 (epoch 0.733), train_loss = 2.63133214, grad/param norm = 3.6860e-01, time/batch = 0.6899s	
445/30300 (epoch 0.734), train_loss = 2.67984944, grad/param norm = 3.5029e-01, time/batch = 0.7104s	
446/30300 (epoch 0.736), train_loss = 2.62590303, grad/param norm = 5.0593e-01, time/batch = 0.7053s	
447/30300 (epoch 0.738), train_loss = 2.49687105, grad/param norm = 4.9395e-01, time/batch = 0.6909s	
448/30300 (epoch 0.739), train_loss = 2.67773080, grad/param norm = 4.4121e-01, time/batch = 0.6922s	
449/30300 (epoch 0.741), train_loss = 2.70493159, grad/param norm = 4.7990e-01, time/batch = 0.6889s	
450/30300 (epoch 0.743), train_loss = 2.55671786, grad/param norm = 4.5892e-01, time/batch = 0.7035s	
451/30300 (epoch 0.744), train_loss = 2.71890572, grad/param norm = 5.1096e-01, time/batch = 0.7168s	
452/30300 (epoch 0.746), train_loss = 2.52790399, grad/param norm = 3.1538e-01, time/batch = 0.6871s	
453/30300 (epoch 0.748), train_loss = 2.65920944, grad/param norm = 3.7196e-01, time/batch = 0.6920s	
454/30300 (epoch 0.749), train_loss = 2.59837957, grad/param norm = 3.6714e-01, time/batch = 0.6876s	
455/30300 (epoch 0.751), train_loss = 2.63684462, grad/param norm = 3.8926e-01, time/batch = 0.6871s	
456/30300 (epoch 0.752), train_loss = 2.60978423, grad/param norm = 3.6399e-01, time/batch = 0.6895s	
457/30300 (epoch 0.754), train_loss = 2.61973071, grad/param norm = 3.5176e-01, time/batch = 0.6879s	
458/30300 (epoch 0.756), train_loss = 2.53820439, grad/param norm = 2.7951e-01, time/batch = 0.6844s	
459/30300 (epoch 0.757), train_loss = 2.76974440, grad/param norm = 4.4642e-01, time/batch = 0.6887s	
460/30300 (epoch 0.759), train_loss = 2.53447920, grad/param norm = 5.8645e-01, time/batch = 0.6972s	
461/30300 (epoch 0.761), train_loss = 2.57145252, grad/param norm = 5.4170e-01, time/batch = 0.6855s	
462/30300 (epoch 0.762), train_loss = 2.57811577, grad/param norm = 5.0072e-01, time/batch = 0.6877s	
463/30300 (epoch 0.764), train_loss = 2.65824714, grad/param norm = 5.0509e-01, time/batch = 0.6987s	
464/30300 (epoch 0.766), train_loss = 2.68938387, grad/param norm = 4.1078e-01, time/batch = 0.6898s	
465/30300 (epoch 0.767), train_loss = 2.74504934, grad/param norm = 3.3311e-01, time/batch = 0.7207s	
466/30300 (epoch 0.769), train_loss = 2.74617267, grad/param norm = 3.6347e-01, time/batch = 0.6957s	
467/30300 (epoch 0.771), train_loss = 2.66241596, grad/param norm = 3.3661e-01, time/batch = 0.6896s	
468/30300 (epoch 0.772), train_loss = 2.59493495, grad/param norm = 3.5985e-01, time/batch = 0.6877s	
469/30300 (epoch 0.774), train_loss = 2.64334303, grad/param norm = 3.2156e-01, time/batch = 0.6941s	
470/30300 (epoch 0.776), train_loss = 2.52226790, grad/param norm = 3.5924e-01, time/batch = 0.6921s	
471/30300 (epoch 0.777), train_loss = 2.62862722, grad/param norm = 4.2010e-01, time/batch = 0.6865s	
472/30300 (epoch 0.779), train_loss = 2.70579482, grad/param norm = 5.4948e-01, time/batch = 0.6922s	
473/30300 (epoch 0.781), train_loss = 2.64512026, grad/param norm = 7.2231e-01, time/batch = 0.6891s	
474/30300 (epoch 0.782), train_loss = 2.64873427, grad/param norm = 8.6756e-01, time/batch = 0.6869s	
475/30300 (epoch 0.784), train_loss = 2.81733379, grad/param norm = 5.7529e-01, time/batch = 0.6902s	
476/30300 (epoch 0.785), train_loss = 2.82146536, grad/param norm = 3.8933e-01, time/batch = 0.6906s	
477/30300 (epoch 0.787), train_loss = 2.65185596, grad/param norm = 3.4628e-01, time/batch = 0.6925s	
478/30300 (epoch 0.789), train_loss = 2.92314448, grad/param norm = 4.9571e-01, time/batch = 0.6928s	
479/30300 (epoch 0.790), train_loss = 2.76463444, grad/param norm = 4.3509e-01, time/batch = 0.7148s	
480/30300 (epoch 0.792), train_loss = 2.63444051, grad/param norm = 3.7148e-01, time/batch = 0.7119s	
481/30300 (epoch 0.794), train_loss = 2.63541202, grad/param norm = 3.7988e-01, time/batch = 0.6908s	
482/30300 (epoch 0.795), train_loss = 2.68346445, grad/param norm = 3.4166e-01, time/batch = 0.6910s	
483/30300 (epoch 0.797), train_loss = 2.64176467, grad/param norm = 2.7638e-01, time/batch = 0.6882s	
484/30300 (epoch 0.799), train_loss = 2.74195903, grad/param norm = 4.0588e-01, time/batch = 0.6920s	
485/30300 (epoch 0.800), train_loss = 2.54998103, grad/param norm = 3.7089e-01, time/batch = 0.6917s	
486/30300 (epoch 0.802), train_loss = 2.64169254, grad/param norm = 4.0282e-01, time/batch = 0.6894s	
487/30300 (epoch 0.804), train_loss = 2.72054625, grad/param norm = 3.9887e-01, time/batch = 0.6883s	
488/30300 (epoch 0.805), train_loss = 2.65219711, grad/param norm = 5.2523e-01, time/batch = 0.6868s	
489/30300 (epoch 0.807), train_loss = 2.68570191, grad/param norm = 5.4781e-01, time/batch = 0.7038s	
490/30300 (epoch 0.809), train_loss = 2.71931882, grad/param norm = 4.4910e-01, time/batch = 0.6963s	
491/30300 (epoch 0.810), train_loss = 2.67481603, grad/param norm = 3.6832e-01, time/batch = 0.6962s	
492/30300 (epoch 0.812), train_loss = 2.66120058, grad/param norm = 3.3002e-01, time/batch = 0.6950s	
493/30300 (epoch 0.814), train_loss = 2.70165571, grad/param norm = 3.4039e-01, time/batch = 0.7043s	
494/30300 (epoch 0.815), train_loss = 2.68010720, grad/param norm = 5.0642e-01, time/batch = 0.7193s	
495/30300 (epoch 0.817), train_loss = 2.64846076, grad/param norm = 5.9853e-01, time/batch = 0.7017s	
496/30300 (epoch 0.818), train_loss = 2.60075867, grad/param norm = 3.9554e-01, time/batch = 0.6962s	
497/30300 (epoch 0.820), train_loss = 2.77073235, grad/param norm = 3.8983e-01, time/batch = 0.6939s	
498/30300 (epoch 0.822), train_loss = 2.76288615, grad/param norm = 3.5322e-01, time/batch = 0.6963s	
499/30300 (epoch 0.823), train_loss = 2.81670276, grad/param norm = 4.7999e-01, time/batch = 0.6938s	
500/30300 (epoch 0.825), train_loss = 2.64843967, grad/param norm = 4.2960e-01, time/batch = 0.6962s	
501/30300 (epoch 0.827), train_loss = 2.61382261, grad/param norm = 3.1358e-01, time/batch = 0.7091s	
502/30300 (epoch 0.828), train_loss = 2.60847418, grad/param norm = 2.3539e-01, time/batch = 0.6980s	
503/30300 (epoch 0.830), train_loss = 2.56652990, grad/param norm = 2.7482e-01, time/batch = 0.6984s	
504/30300 (epoch 0.832), train_loss = 2.45779310, grad/param norm = 3.5339e-01, time/batch = 0.6976s	
505/30300 (epoch 0.833), train_loss = 2.65085911, grad/param norm = 3.4622e-01, time/batch = 0.6934s	
506/30300 (epoch 0.835), train_loss = 2.62229035, grad/param norm = 2.9061e-01, time/batch = 0.6953s	
507/30300 (epoch 0.837), train_loss = 2.45085977, grad/param norm = 3.2394e-01, time/batch = 0.7064s	
508/30300 (epoch 0.838), train_loss = 2.57775722, grad/param norm = 3.3734e-01, time/batch = 0.7217s	
509/30300 (epoch 0.840), train_loss = 2.59663534, grad/param norm = 5.3655e-01, time/batch = 0.6988s	
510/30300 (epoch 0.842), train_loss = 2.54695739, grad/param norm = 5.2756e-01, time/batch = 0.6939s	
511/30300 (epoch 0.843), train_loss = 2.56802930, grad/param norm = 3.8749e-01, time/batch = 0.6902s	
512/30300 (epoch 0.845), train_loss = 2.51574921, grad/param norm = 4.2322e-01, time/batch = 0.6870s	
513/30300 (epoch 0.847), train_loss = 2.58657883, grad/param norm = 4.3409e-01, time/batch = 0.7002s	
514/30300 (epoch 0.848), train_loss = 2.68311863, grad/param norm = 5.9081e-01, time/batch = 0.6951s	
515/30300 (epoch 0.850), train_loss = 2.61258203, grad/param norm = 7.3091e-01, time/batch = 0.7025s	
516/30300 (epoch 0.851), train_loss = 2.74484297, grad/param norm = 5.8729e-01, time/batch = 0.7035s	
517/30300 (epoch 0.853), train_loss = 2.58814476, grad/param norm = 3.8595e-01, time/batch = 0.6933s	
518/30300 (epoch 0.855), train_loss = 2.56740892, grad/param norm = 3.8878e-01, time/batch = 0.6912s	
519/30300 (epoch 0.856), train_loss = 2.54740960, grad/param norm = 3.8380e-01, time/batch = 0.6906s	
520/30300 (epoch 0.858), train_loss = 2.48498171, grad/param norm = 3.1480e-01, time/batch = 0.6901s	
521/30300 (epoch 0.860), train_loss = 2.58263841, grad/param norm = 3.4717e-01, time/batch = 0.6985s	
522/30300 (epoch 0.861), train_loss = 2.60751009, grad/param norm = 5.6659e-01, time/batch = 0.7213s	
523/30300 (epoch 0.863), train_loss = 2.67556939, grad/param norm = 5.2144e-01, time/batch = 0.7040s	
524/30300 (epoch 0.865), train_loss = 2.83182444, grad/param norm = 3.8273e-01, time/batch = 0.6911s	
525/30300 (epoch 0.866), train_loss = 2.54800741, grad/param norm = 3.2690e-01, time/batch = 0.6899s	
526/30300 (epoch 0.868), train_loss = 2.64571574, grad/param norm = 3.8574e-01, time/batch = 0.6902s	
527/30300 (epoch 0.870), train_loss = 2.55369921, grad/param norm = 4.1160e-01, time/batch = 0.6896s	
528/30300 (epoch 0.871), train_loss = 2.47356125, grad/param norm = 2.7186e-01, time/batch = 0.6920s	
529/30300 (epoch 0.873), train_loss = 2.68914198, grad/param norm = 3.4659e-01, time/batch = 0.6901s	
530/30300 (epoch 0.875), train_loss = 2.57361933, grad/param norm = 3.4697e-01, time/batch = 0.6902s	
531/30300 (epoch 0.876), train_loss = 2.47646285, grad/param norm = 3.3454e-01, time/batch = 0.6911s	
532/30300 (epoch 0.878), train_loss = 2.54391526, grad/param norm = 3.3700e-01, time/batch = 0.6893s	
533/30300 (epoch 0.880), train_loss = 2.44991112, grad/param norm = 3.3155e-01, time/batch = 0.6931s	
534/30300 (epoch 0.881), train_loss = 2.62892539, grad/param norm = 3.0918e-01, time/batch = 0.6896s	
535/30300 (epoch 0.883), train_loss = 2.54314509, grad/param norm = 3.6931e-01, time/batch = 0.6898s	
536/30300 (epoch 0.884), train_loss = 2.50738140, grad/param norm = 4.4543e-01, time/batch = 0.7080s	
537/30300 (epoch 0.886), train_loss = 2.53898312, grad/param norm = 4.1038e-01, time/batch = 0.7152s	
538/30300 (epoch 0.888), train_loss = 2.68382396, grad/param norm = 3.7888e-01, time/batch = 0.7112s	
539/30300 (epoch 0.889), train_loss = 2.55859321, grad/param norm = 4.4729e-01, time/batch = 0.7166s	
540/30300 (epoch 0.891), train_loss = 2.57411129, grad/param norm = 4.9996e-01, time/batch = 0.7194s	
541/30300 (epoch 0.893), train_loss = 2.59178023, grad/param norm = 4.9030e-01, time/batch = 0.6972s	
542/30300 (epoch 0.894), train_loss = 2.59663075, grad/param norm = 5.0856e-01, time/batch = 0.7176s	
543/30300 (epoch 0.896), train_loss = 2.50460346, grad/param norm = 4.1271e-01, time/batch = 0.7152s	
544/30300 (epoch 0.898), train_loss = 2.44005313, grad/param norm = 3.1503e-01, time/batch = 0.7137s	
545/30300 (epoch 0.899), train_loss = 2.57190807, grad/param norm = 3.7707e-01, time/batch = 0.6968s	
546/30300 (epoch 0.901), train_loss = 2.67917988, grad/param norm = 4.5165e-01, time/batch = 0.7152s	
547/30300 (epoch 0.903), train_loss = 2.63331093, grad/param norm = 4.4079e-01, time/batch = 0.7073s	
548/30300 (epoch 0.904), train_loss = 2.53138114, grad/param norm = 2.9892e-01, time/batch = 0.6929s	
549/30300 (epoch 0.906), train_loss = 2.66677714, grad/param norm = 3.2942e-01, time/batch = 0.7000s	
550/30300 (epoch 0.908), train_loss = 2.61508448, grad/param norm = 3.3944e-01, time/batch = 0.6925s	
551/30300 (epoch 0.909), train_loss = 2.75758440, grad/param norm = 3.5749e-01, time/batch = 0.6875s	
552/30300 (epoch 0.911), train_loss = 2.50826004, grad/param norm = 3.5481e-01, time/batch = 0.6967s	
553/30300 (epoch 0.913), train_loss = 2.55717725, grad/param norm = 3.7258e-01, time/batch = 0.6928s	
554/30300 (epoch 0.914), train_loss = 2.65315695, grad/param norm = 3.9944e-01, time/batch = 0.6896s	
555/30300 (epoch 0.916), train_loss = 2.53158208, grad/param norm = 4.7004e-01, time/batch = 0.6919s	
556/30300 (epoch 0.917), train_loss = 2.47072235, grad/param norm = 4.8020e-01, time/batch = 0.6932s	
557/30300 (epoch 0.919), train_loss = 2.61089242, grad/param norm = 4.4536e-01, time/batch = 0.6941s	
558/30300 (epoch 0.921), train_loss = 2.64481201, grad/param norm = 3.4974e-01, time/batch = 0.6936s	
559/30300 (epoch 0.922), train_loss = 2.59913089, grad/param norm = 2.7000e-01, time/batch = 0.6925s	
560/30300 (epoch 0.924), train_loss = 2.49397716, grad/param norm = 3.4855e-01, time/batch = 0.6929s	
561/30300 (epoch 0.926), train_loss = 2.51116525, grad/param norm = 4.5777e-01, time/batch = 0.6896s	
562/30300 (epoch 0.927), train_loss = 2.45143821, grad/param norm = 4.5444e-01, time/batch = 0.6979s	
563/30300 (epoch 0.929), train_loss = 2.61206059, grad/param norm = 5.8065e-01, time/batch = 0.6901s	
564/30300 (epoch 0.931), train_loss = 2.66586727, grad/param norm = 5.0312e-01, time/batch = 0.6903s	
565/30300 (epoch 0.932), train_loss = 2.52299452, grad/param norm = 2.8448e-01, time/batch = 0.6910s	
566/30300 (epoch 0.934), train_loss = 2.52804647, grad/param norm = 3.0936e-01, time/batch = 0.6936s	
567/30300 (epoch 0.936), train_loss = 2.50556869, grad/param norm = 3.2301e-01, time/batch = 0.6930s	
568/30300 (epoch 0.937), train_loss = 2.55744949, grad/param norm = 3.9688e-01, time/batch = 0.6893s	
569/30300 (epoch 0.939), train_loss = 2.58096317, grad/param norm = 3.9568e-01, time/batch = 0.6871s	
570/30300 (epoch 0.941), train_loss = 2.57974146, grad/param norm = 4.2084e-01, time/batch = 0.6905s	
571/30300 (epoch 0.942), train_loss = 2.46885870, grad/param norm = 3.6652e-01, time/batch = 0.6887s	
572/30300 (epoch 0.944), train_loss = 2.50339527, grad/param norm = 3.7433e-01, time/batch = 0.6883s	
573/30300 (epoch 0.946), train_loss = 2.72668031, grad/param norm = 3.6133e-01, time/batch = 0.6892s	
574/30300 (epoch 0.947), train_loss = 2.66851802, grad/param norm = 4.6121e-01, time/batch = 0.6921s	
575/30300 (epoch 0.949), train_loss = 2.71481406, grad/param norm = 4.0731e-01, time/batch = 0.6935s	
576/30300 (epoch 0.950), train_loss = 2.66617994, grad/param norm = 3.3776e-01, time/batch = 0.6877s	
577/30300 (epoch 0.952), train_loss = 2.64232859, grad/param norm = 3.1201e-01, time/batch = 0.6880s	
578/30300 (epoch 0.954), train_loss = 2.58131485, grad/param norm = 3.6144e-01, time/batch = 0.6911s	
579/30300 (epoch 0.955), train_loss = 2.54462723, grad/param norm = 2.9066e-01, time/batch = 0.6902s	
580/30300 (epoch 0.957), train_loss = 2.62546319, grad/param norm = 3.6383e-01, time/batch = 0.6864s	
581/30300 (epoch 0.959), train_loss = 2.67547196, grad/param norm = 3.4367e-01, time/batch = 0.6901s	
582/30300 (epoch 0.960), train_loss = 2.52143205, grad/param norm = 2.9009e-01, time/batch = 0.6933s	
583/30300 (epoch 0.962), train_loss = 2.53272194, grad/param norm = 2.8100e-01, time/batch = 0.6908s	
584/30300 (epoch 0.964), train_loss = 2.61623432, grad/param norm = 3.3066e-01, time/batch = 0.6870s	
585/30300 (epoch 0.965), train_loss = 2.52486065, grad/param norm = 3.5612e-01, time/batch = 0.6934s	
586/30300 (epoch 0.967), train_loss = 2.53471954, grad/param norm = 3.4399e-01, time/batch = 0.6937s	
587/30300 (epoch 0.969), train_loss = 2.47398771, grad/param norm = 4.2837e-01, time/batch = 0.7109s	
588/30300 (epoch 0.970), train_loss = 2.51675474, grad/param norm = 4.8354e-01, time/batch = 0.7020s	
589/30300 (epoch 0.972), train_loss = 2.49098766, grad/param norm = 4.3558e-01, time/batch = 0.7111s	
590/30300 (epoch 0.974), train_loss = 2.63594071, grad/param norm = 3.7873e-01, time/batch = 0.7129s	
591/30300 (epoch 0.975), train_loss = 2.53914311, grad/param norm = 2.8916e-01, time/batch = 0.6971s	
592/30300 (epoch 0.977), train_loss = 2.45638911, grad/param norm = 2.8324e-01, time/batch = 0.6938s	
593/30300 (epoch 0.979), train_loss = 2.62692868, grad/param norm = 2.8088e-01, time/batch = 0.7062s	
594/30300 (epoch 0.980), train_loss = 2.60308173, grad/param norm = 3.0853e-01, time/batch = 0.6956s	
595/30300 (epoch 0.982), train_loss = 2.60946509, grad/param norm = 3.2688e-01, time/batch = 0.6973s	
596/30300 (epoch 0.983), train_loss = 2.63484213, grad/param norm = 5.1067e-01, time/batch = 0.6961s	
597/30300 (epoch 0.985), train_loss = 2.66471870, grad/param norm = 5.5819e-01, time/batch = 0.6914s	
598/30300 (epoch 0.987), train_loss = 2.47468012, grad/param norm = 3.9226e-01, time/batch = 0.6942s	
599/30300 (epoch 0.988), train_loss = 2.66744690, grad/param norm = 3.3695e-01, time/batch = 0.7037s	
600/30300 (epoch 0.990), train_loss = 2.35793341, grad/param norm = 2.5290e-01, time/batch = 0.6917s	
601/30300 (epoch 0.992), train_loss = 2.44166913, grad/param norm = 2.6232e-01, time/batch = 0.6886s	
602/30300 (epoch 0.993), train_loss = 2.68523800, grad/param norm = 3.8205e-01, time/batch = 0.6937s	
603/30300 (epoch 0.995), train_loss = 2.64787047, grad/param norm = 3.0610e-01, time/batch = 0.7049s	
604/30300 (epoch 0.997), train_loss = 2.47850012, grad/param norm = 2.4620e-01, time/batch = 0.7197s	
605/30300 (epoch 0.998), train_loss = 2.46485494, grad/param norm = 3.0153e-01, time/batch = 0.6908s	
606/30300 (epoch 1.000), train_loss = 2.40497656, grad/param norm = 3.6170e-01, time/batch = 0.6958s	
607/30300 (epoch 1.002), train_loss = 2.42951990, grad/param norm = 3.5028e-01, time/batch = 0.6944s	
608/30300 (epoch 1.003), train_loss = 2.57160835, grad/param norm = 2.7387e-01, time/batch = 0.6930s	
609/30300 (epoch 1.005), train_loss = 2.59894682, grad/param norm = 3.4173e-01, time/batch = 0.6936s	
610/30300 (epoch 1.007), train_loss = 2.57307908, grad/param norm = 4.3720e-01, time/batch = 0.6943s	
611/30300 (epoch 1.008), train_loss = 2.53210156, grad/param norm = 4.6204e-01, time/batch = 0.6885s	
612/30300 (epoch 1.010), train_loss = 2.51508095, grad/param norm = 3.9547e-01, time/batch = 0.6885s	
613/30300 (epoch 1.012), train_loss = 2.45911701, grad/param norm = 3.0746e-01, time/batch = 0.6926s	
614/30300 (epoch 1.013), train_loss = 2.56034986, grad/param norm = 3.1543e-01, time/batch = 0.6896s	
615/30300 (epoch 1.015), train_loss = 2.60969637, grad/param norm = 3.0520e-01, time/batch = 0.6971s	
616/30300 (epoch 1.017), train_loss = 2.42568329, grad/param norm = 3.3247e-01, time/batch = 0.7013s	
617/30300 (epoch 1.018), train_loss = 2.54493187, grad/param norm = 2.7644e-01, time/batch = 0.7057s	
618/30300 (epoch 1.020), train_loss = 2.61530098, grad/param norm = 3.5663e-01, time/batch = 0.7208s	
619/30300 (epoch 1.021), train_loss = 2.59434272, grad/param norm = 4.3189e-01, time/batch = 0.7049s	
620/30300 (epoch 1.023), train_loss = 2.49820175, grad/param norm = 3.4158e-01, time/batch = 0.6951s	
621/30300 (epoch 1.025), train_loss = 2.48721475, grad/param norm = 2.6380e-01, time/batch = 0.6898s	
622/30300 (epoch 1.026), train_loss = 2.54152448, grad/param norm = 2.8908e-01, time/batch = 0.6878s	
623/30300 (epoch 1.028), train_loss = 2.50179551, grad/param norm = 2.8186e-01, time/batch = 0.6860s	
624/30300 (epoch 1.030), train_loss = 2.40738655, grad/param norm = 2.9049e-01, time/batch = 0.6867s	
625/30300 (epoch 1.031), train_loss = 2.49175805, grad/param norm = 3.5607e-01, time/batch = 0.6888s	
626/30300 (epoch 1.033), train_loss = 2.54754915, grad/param norm = 3.2208e-01, time/batch = 0.6890s	
627/30300 (epoch 1.035), train_loss = 2.55496012, grad/param norm = 3.1048e-01, time/batch = 0.6872s	
628/30300 (epoch 1.036), train_loss = 2.68398221, grad/param norm = 4.1130e-01, time/batch = 0.6886s	
629/30300 (epoch 1.038), train_loss = 2.57361004, grad/param norm = 3.3373e-01, time/batch = 0.6911s	
630/30300 (epoch 1.040), train_loss = 2.27058107, grad/param norm = 2.9466e-01, time/batch = 0.6851s	
631/30300 (epoch 1.041), train_loss = 2.51480645, grad/param norm = 3.9021e-01, time/batch = 0.6996s	
632/30300 (epoch 1.043), train_loss = 2.52630528, grad/param norm = 3.6870e-01, time/batch = 0.7158s	
633/30300 (epoch 1.045), train_loss = 2.42275987, grad/param norm = 3.6819e-01, time/batch = 0.7103s	
634/30300 (epoch 1.046), train_loss = 2.44546571, grad/param norm = 3.7557e-01, time/batch = 0.6889s	
635/30300 (epoch 1.048), train_loss = 2.44534115, grad/param norm = 4.3572e-01, time/batch = 0.6931s	
636/30300 (epoch 1.050), train_loss = 2.63629940, grad/param norm = 3.8011e-01, time/batch = 0.6900s	
637/30300 (epoch 1.051), train_loss = 2.49722116, grad/param norm = 3.6852e-01, time/batch = 0.6923s	
638/30300 (epoch 1.053), train_loss = 2.44039467, grad/param norm = 4.8424e-01, time/batch = 0.7077s	
639/30300 (epoch 1.054), train_loss = 2.42384685, grad/param norm = 4.4445e-01, time/batch = 0.6919s	
640/30300 (epoch 1.056), train_loss = 2.45720867, grad/param norm = 2.8664e-01, time/batch = 0.6877s	
641/30300 (epoch 1.058), train_loss = 2.53182052, grad/param norm = 3.1264e-01, time/batch = 0.6907s	
642/30300 (epoch 1.059), train_loss = 2.61189608, grad/param norm = 3.6416e-01, time/batch = 0.6898s	
643/30300 (epoch 1.061), train_loss = 2.49413055, grad/param norm = 4.1609e-01, time/batch = 0.6936s	
644/30300 (epoch 1.063), train_loss = 2.46921664, grad/param norm = 3.4873e-01, time/batch = 0.6862s	
645/30300 (epoch 1.064), train_loss = 2.53358961, grad/param norm = 3.9484e-01, time/batch = 0.6912s	
646/30300 (epoch 1.066), train_loss = 2.54735775, grad/param norm = 3.3824e-01, time/batch = 0.7034s	
647/30300 (epoch 1.068), train_loss = 2.35005205, grad/param norm = 3.0622e-01, time/batch = 0.6957s	
648/30300 (epoch 1.069), train_loss = 2.53622780, grad/param norm = 3.2278e-01, time/batch = 0.7013s	
649/30300 (epoch 1.071), train_loss = 2.51408114, grad/param norm = 3.5846e-01, time/batch = 0.7083s	
650/30300 (epoch 1.073), train_loss = 2.57594628, grad/param norm = 2.9360e-01, time/batch = 0.7017s	
651/30300 (epoch 1.074), train_loss = 2.56095829, grad/param norm = 3.1878e-01, time/batch = 0.7023s	
652/30300 (epoch 1.076), train_loss = 2.37005073, grad/param norm = 3.6264e-01, time/batch = 0.7008s	
653/30300 (epoch 1.078), train_loss = 2.31795858, grad/param norm = 3.3042e-01, time/batch = 0.6974s	
654/30300 (epoch 1.079), train_loss = 2.26357265, grad/param norm = 2.5146e-01, time/batch = 0.7016s	
655/30300 (epoch 1.081), train_loss = 2.62532461, grad/param norm = 2.9686e-01, time/batch = 0.7011s	
656/30300 (epoch 1.083), train_loss = 2.75371318, grad/param norm = 3.6415e-01, time/batch = 0.6915s	
657/30300 (epoch 1.084), train_loss = 2.42777683, grad/param norm = 4.0517e-01, time/batch = 0.6893s	
658/30300 (epoch 1.086), train_loss = 2.51172319, grad/param norm = 3.4837e-01, time/batch = 0.6902s	
659/30300 (epoch 1.087), train_loss = 2.39449194, grad/param norm = 2.8456e-01, time/batch = 0.6923s	
660/30300 (epoch 1.089), train_loss = 2.51625164, grad/param norm = 3.2473e-01, time/batch = 0.6961s	
661/30300 (epoch 1.091), train_loss = 2.51738765, grad/param norm = 3.2280e-01, time/batch = 0.7222s	
662/30300 (epoch 1.092), train_loss = 2.41574826, grad/param norm = 3.1555e-01, time/batch = 0.7037s	
663/30300 (epoch 1.094), train_loss = 2.68088386, grad/param norm = 3.2378e-01, time/batch = 0.6938s	
664/30300 (epoch 1.096), train_loss = 2.45286816, grad/param norm = 3.7169e-01, time/batch = 0.6935s	
665/30300 (epoch 1.097), train_loss = 2.49447063, grad/param norm = 4.1202e-01, time/batch = 0.6912s	
666/30300 (epoch 1.099), train_loss = 2.67893506, grad/param norm = 3.1293e-01, time/batch = 0.6884s	
667/30300 (epoch 1.101), train_loss = 2.58060671, grad/param norm = 2.5323e-01, time/batch = 0.6892s	
668/30300 (epoch 1.102), train_loss = 2.59328902, grad/param norm = 3.2496e-01, time/batch = 0.6911s	
669/30300 (epoch 1.104), train_loss = 2.32488856, grad/param norm = 3.5794e-01, time/batch = 0.6857s	
670/30300 (epoch 1.106), train_loss = 2.63736401, grad/param norm = 3.2903e-01, time/batch = 0.6871s	
671/30300 (epoch 1.107), train_loss = 2.46813891, grad/param norm = 2.9965e-01, time/batch = 0.6882s	
672/30300 (epoch 1.109), train_loss = 2.57069769, grad/param norm = 3.4591e-01, time/batch = 0.7067s	
673/30300 (epoch 1.111), train_loss = 2.48068848, grad/param norm = 3.4618e-01, time/batch = 0.6960s	
674/30300 (epoch 1.112), train_loss = 2.50376163, grad/param norm = 2.9654e-01, time/batch = 0.6955s	
675/30300 (epoch 1.114), train_loss = 2.41521805, grad/param norm = 2.6560e-01, time/batch = 0.7201s	
676/30300 (epoch 1.116), train_loss = 2.51861716, grad/param norm = 2.5611e-01, time/batch = 0.7077s	
677/30300 (epoch 1.117), train_loss = 2.41079853, grad/param norm = 2.6202e-01, time/batch = 0.6912s	
678/30300 (epoch 1.119), train_loss = 2.28479430, grad/param norm = 2.8275e-01, time/batch = 0.7038s	
679/30300 (epoch 1.120), train_loss = 2.34144411, grad/param norm = 3.6782e-01, time/batch = 0.6981s	
680/30300 (epoch 1.122), train_loss = 2.53887993, grad/param norm = 2.8577e-01, time/batch = 0.6946s	
681/30300 (epoch 1.124), train_loss = 2.48727790, grad/param norm = 2.5638e-01, time/batch = 0.7024s	
682/30300 (epoch 1.125), train_loss = 2.34198348, grad/param norm = 2.8947e-01, time/batch = 0.7058s	
683/30300 (epoch 1.127), train_loss = 2.52964859, grad/param norm = 4.4143e-01, time/batch = 0.6926s	
684/30300 (epoch 1.129), train_loss = 2.50899261, grad/param norm = 3.4775e-01, time/batch = 0.6885s	
685/30300 (epoch 1.130), train_loss = 2.54156810, grad/param norm = 2.9937e-01, time/batch = 0.6903s	
686/30300 (epoch 1.132), train_loss = 2.42749351, grad/param norm = 3.2238e-01, time/batch = 0.7010s	
687/30300 (epoch 1.134), train_loss = 2.33938014, grad/param norm = 3.8402e-01, time/batch = 0.6943s	
688/30300 (epoch 1.135), train_loss = 2.54429365, grad/param norm = 3.5629e-01, time/batch = 0.7017s	
689/30300 (epoch 1.137), train_loss = 2.53989749, grad/param norm = 3.4745e-01, time/batch = 0.7205s	
690/30300 (epoch 1.139), train_loss = 2.40566750, grad/param norm = 4.1276e-01, time/batch = 0.7138s	
691/30300 (epoch 1.140), train_loss = 3.01368402, grad/param norm = 7.7301e-01, time/batch = 0.6897s	
692/30300 (epoch 1.142), train_loss = 2.77093980, grad/param norm = 7.2022e-01, time/batch = 0.6883s	
693/30300 (epoch 1.144), train_loss = 2.56234902, grad/param norm = 3.3548e-01, time/batch = 0.6979s	
694/30300 (epoch 1.145), train_loss = 2.60767142, grad/param norm = 2.8729e-01, time/batch = 0.6958s	
695/30300 (epoch 1.147), train_loss = 2.58041772, grad/param norm = 3.7913e-01, time/batch = 0.6907s	
696/30300 (epoch 1.149), train_loss = 2.63044573, grad/param norm = 3.6646e-01, time/batch = 0.6914s	
697/30300 (epoch 1.150), train_loss = 2.64021479, grad/param norm = 3.3509e-01, time/batch = 0.6884s	
698/30300 (epoch 1.152), train_loss = 2.60848340, grad/param norm = 4.5241e-01, time/batch = 0.6870s	
699/30300 (epoch 1.153), train_loss = 2.58793490, grad/param norm = 3.4531e-01, time/batch = 0.6904s	
700/30300 (epoch 1.155), train_loss = 2.29079793, grad/param norm = 2.6110e-01, time/batch = 0.6922s	
701/30300 (epoch 1.157), train_loss = 2.48564595, grad/param norm = 2.5674e-01, time/batch = 0.6975s	
702/30300 (epoch 1.158), train_loss = 2.56763650, grad/param norm = 2.6781e-01, time/batch = 0.6904s	
703/30300 (epoch 1.160), train_loss = 2.39947412, grad/param norm = 3.5954e-01, time/batch = 0.6972s	
704/30300 (epoch 1.162), train_loss = 2.38416539, grad/param norm = 4.6984e-01, time/batch = 0.7206s	
705/30300 (epoch 1.163), train_loss = 2.41343353, grad/param norm = 4.2788e-01, time/batch = 0.6902s	
706/30300 (epoch 1.165), train_loss = 2.56285664, grad/param norm = 4.5937e-01, time/batch = 0.6897s	
707/30300 (epoch 1.167), train_loss = 2.50538557, grad/param norm = 3.4575e-01, time/batch = 0.6906s	
708/30300 (epoch 1.168), train_loss = 2.36162862, grad/param norm = 3.2182e-01, time/batch = 0.6901s	
709/30300 (epoch 1.170), train_loss = 2.52283676, grad/param norm = 2.8149e-01, time/batch = 0.6921s	
710/30300 (epoch 1.172), train_loss = 2.33467387, grad/param norm = 2.3240e-01, time/batch = 0.6892s	
711/30300 (epoch 1.173), train_loss = 2.55071229, grad/param norm = 2.7130e-01, time/batch = 0.6931s	
712/30300 (epoch 1.175), train_loss = 2.42860900, grad/param norm = 2.8112e-01, time/batch = 0.6916s	
713/30300 (epoch 1.177), train_loss = 2.57276150, grad/param norm = 2.7500e-01, time/batch = 0.6898s	
714/30300 (epoch 1.178), train_loss = 2.30235475, grad/param norm = 2.3668e-01, time/batch = 0.6946s	
715/30300 (epoch 1.180), train_loss = 2.35544549, grad/param norm = 2.3173e-01, time/batch = 0.6922s	
716/30300 (epoch 1.182), train_loss = 2.41088726, grad/param norm = 3.2249e-01, time/batch = 0.6901s	
717/30300 (epoch 1.183), train_loss = 2.39438842, grad/param norm = 3.5411e-01, time/batch = 0.6946s	
718/30300 (epoch 1.185), train_loss = 2.68348446, grad/param norm = 2.8686e-01, time/batch = 0.7183s	
719/30300 (epoch 1.186), train_loss = 2.48386409, grad/param norm = 3.0570e-01, time/batch = 0.7035s	
720/30300 (epoch 1.188), train_loss = 2.42933505, grad/param norm = 4.1504e-01, time/batch = 0.6873s	
721/30300 (epoch 1.190), train_loss = 2.33031896, grad/param norm = 3.7981e-01, time/batch = 0.6943s	
722/30300 (epoch 1.191), train_loss = 2.51663320, grad/param norm = 2.6072e-01, time/batch = 0.6935s	
723/30300 (epoch 1.193), train_loss = 2.34808430, grad/param norm = 2.4358e-01, time/batch = 0.6851s	
724/30300 (epoch 1.195), train_loss = 2.44675920, grad/param norm = 2.9838e-01, time/batch = 0.6879s	
725/30300 (epoch 1.196), train_loss = 2.50554043, grad/param norm = 3.2503e-01, time/batch = 0.6842s	
726/30300 (epoch 1.198), train_loss = 2.19678295, grad/param norm = 2.7946e-01, time/batch = 0.6870s	
727/30300 (epoch 1.200), train_loss = 2.47688499, grad/param norm = 3.5811e-01, time/batch = 0.6875s	
728/30300 (epoch 1.201), train_loss = 2.56232127, grad/param norm = 2.7769e-01, time/batch = 0.6888s	
729/30300 (epoch 1.203), train_loss = 2.44971310, grad/param norm = 3.0547e-01, time/batch = 0.6889s	
730/30300 (epoch 1.205), train_loss = 2.61204426, grad/param norm = 2.9824e-01, time/batch = 0.6928s	
731/30300 (epoch 1.206), train_loss = 2.60578910, grad/param norm = 2.7836e-01, time/batch = 0.6899s	
732/30300 (epoch 1.208), train_loss = 2.59498223, grad/param norm = 2.6744e-01, time/batch = 0.7137s	
733/30300 (epoch 1.210), train_loss = 2.46415465, grad/param norm = 3.3087e-01, time/batch = 0.7137s	
734/30300 (epoch 1.211), train_loss = 2.43406358, grad/param norm = 3.5278e-01, time/batch = 0.6930s	
735/30300 (epoch 1.213), train_loss = 2.46272907, grad/param norm = 3.7815e-01, time/batch = 0.6929s	
736/30300 (epoch 1.215), train_loss = 2.31352130, grad/param norm = 3.3266e-01, time/batch = 0.7062s	
737/30300 (epoch 1.216), train_loss = 2.49011308, grad/param norm = 3.2027e-01, time/batch = 0.7204s	
738/30300 (epoch 1.218), train_loss = 2.39679041, grad/param norm = 2.7872e-01, time/batch = 0.6942s	
739/30300 (epoch 1.219), train_loss = 2.33522560, grad/param norm = 3.2210e-01, time/batch = 0.6897s	
740/30300 (epoch 1.221), train_loss = 2.34522670, grad/param norm = 3.2986e-01, time/batch = 0.6903s	
741/30300 (epoch 1.223), train_loss = 2.33227347, grad/param norm = 2.4582e-01, time/batch = 0.6854s	
742/30300 (epoch 1.224), train_loss = 2.23092500, grad/param norm = 2.6535e-01, time/batch = 0.6968s	
743/30300 (epoch 1.226), train_loss = 2.45483476, grad/param norm = 2.7269e-01, time/batch = 0.6892s	
744/30300 (epoch 1.228), train_loss = 2.37040914, grad/param norm = 2.7160e-01, time/batch = 0.6928s	
745/30300 (epoch 1.229), train_loss = 2.25855360, grad/param norm = 2.7391e-01, time/batch = 0.6885s	
746/30300 (epoch 1.231), train_loss = 2.37545140, grad/param norm = 3.3349e-01, time/batch = 0.6899s	
747/30300 (epoch 1.233), train_loss = 2.29618755, grad/param norm = 2.5452e-01, time/batch = 0.6972s	
748/30300 (epoch 1.234), train_loss = 2.45357017, grad/param norm = 3.0944e-01, time/batch = 0.6877s	
749/30300 (epoch 1.236), train_loss = 2.41982286, grad/param norm = 4.2299e-01, time/batch = 0.6927s	
750/30300 (epoch 1.238), train_loss = 2.51675212, grad/param norm = 4.6353e-01, time/batch = 0.6913s	
751/30300 (epoch 1.239), train_loss = 2.39992869, grad/param norm = 3.7902e-01, time/batch = 0.7214s	
752/30300 (epoch 1.241), train_loss = 2.37544529, grad/param norm = 3.5862e-01, time/batch = 0.7044s	
753/30300 (epoch 1.243), train_loss = 2.40257330, grad/param norm = 3.8731e-01, time/batch = 0.6934s	
754/30300 (epoch 1.244), train_loss = 2.61675575, grad/param norm = 3.9528e-01, time/batch = 0.6955s	
755/30300 (epoch 1.246), train_loss = 2.40659040, grad/param norm = 3.8225e-01, time/batch = 0.6912s	
756/30300 (epoch 1.248), train_loss = 2.52283367, grad/param norm = 3.2426e-01, time/batch = 0.6905s	
757/30300 (epoch 1.249), train_loss = 2.27464708, grad/param norm = 3.5878e-01, time/batch = 0.6919s	
758/30300 (epoch 1.251), train_loss = 2.37757533, grad/param norm = 3.2051e-01, time/batch = 0.7026s	
759/30300 (epoch 1.252), train_loss = 2.53296695, grad/param norm = 3.3131e-01, time/batch = 0.7139s	
760/30300 (epoch 1.254), train_loss = 2.43722633, grad/param norm = 2.6216e-01, time/batch = 0.6884s	
761/30300 (epoch 1.256), train_loss = 2.41562898, grad/param norm = 2.9365e-01, time/batch = 0.6949s	
762/30300 (epoch 1.257), train_loss = 2.56659582, grad/param norm = 2.7588e-01, time/batch = 0.6927s	
763/30300 (epoch 1.259), train_loss = 2.40666932, grad/param norm = 2.6699e-01, time/batch = 0.6905s	
764/30300 (epoch 1.261), train_loss = 2.53409813, grad/param norm = 2.8223e-01, time/batch = 0.7028s	
765/30300 (epoch 1.262), train_loss = 2.34838446, grad/param norm = 2.5566e-01, time/batch = 0.7172s	
766/30300 (epoch 1.264), train_loss = 2.38787134, grad/param norm = 2.9813e-01, time/batch = 0.7064s	
767/30300 (epoch 1.266), train_loss = 2.32883650, grad/param norm = 2.7502e-01, time/batch = 0.6973s	
768/30300 (epoch 1.267), train_loss = 2.44341015, grad/param norm = 2.8143e-01, time/batch = 0.6918s	
769/30300 (epoch 1.269), train_loss = 2.45340182, grad/param norm = 2.6302e-01, time/batch = 0.6938s	
770/30300 (epoch 1.271), train_loss = 2.44329868, grad/param norm = 3.5032e-01, time/batch = 0.6914s	
771/30300 (epoch 1.272), train_loss = 2.46789267, grad/param norm = 3.2099e-01, time/batch = 0.6915s	
772/30300 (epoch 1.274), train_loss = 2.56560447, grad/param norm = 2.8876e-01, time/batch = 0.7021s	
773/30300 (epoch 1.276), train_loss = 2.57297712, grad/param norm = 3.0499e-01, time/batch = 0.7009s	
774/30300 (epoch 1.277), train_loss = 2.35293324, grad/param norm = 3.1438e-01, time/batch = 0.7151s	
775/30300 (epoch 1.279), train_loss = 2.44681633, grad/param norm = 2.7773e-01, time/batch = 0.7093s	
776/30300 (epoch 1.281), train_loss = 2.41411565, grad/param norm = 2.5725e-01, time/batch = 0.7125s	
777/30300 (epoch 1.282), train_loss = 2.37570715, grad/param norm = 2.7824e-01, time/batch = 0.7109s	
778/30300 (epoch 1.284), train_loss = 2.55582286, grad/param norm = 3.0520e-01, time/batch = 0.6954s	
779/30300 (epoch 1.285), train_loss = 2.49044722, grad/param norm = 3.2526e-01, time/batch = 0.7071s	
780/30300 (epoch 1.287), train_loss = 2.48320931, grad/param norm = 3.3349e-01, time/batch = 0.7030s	
781/30300 (epoch 1.289), train_loss = 2.36204747, grad/param norm = 3.6600e-01, time/batch = 0.6908s	
782/30300 (epoch 1.290), train_loss = 2.22950801, grad/param norm = 3.1417e-01, time/batch = 0.6870s	
783/30300 (epoch 1.292), train_loss = 2.31667692, grad/param norm = 2.5746e-01, time/batch = 0.6875s	
784/30300 (epoch 1.294), train_loss = 2.59751032, grad/param norm = 3.0665e-01, time/batch = 0.6865s	
785/30300 (epoch 1.295), train_loss = 2.42235172, grad/param norm = 3.0824e-01, time/batch = 0.6993s	
786/30300 (epoch 1.297), train_loss = 2.37984227, grad/param norm = 3.2058e-01, time/batch = 0.6989s	
787/30300 (epoch 1.299), train_loss = 2.50619922, grad/param norm = 3.1277e-01, time/batch = 0.6927s	
788/30300 (epoch 1.300), train_loss = 2.37898551, grad/param norm = 2.8418e-01, time/batch = 0.6909s	
789/30300 (epoch 1.302), train_loss = 2.30384433, grad/param norm = 2.9084e-01, time/batch = 0.6927s	
790/30300 (epoch 1.304), train_loss = 2.35434514, grad/param norm = 2.6436e-01, time/batch = 0.6928s	
791/30300 (epoch 1.305), train_loss = 2.40997969, grad/param norm = 3.0612e-01, time/batch = 0.6889s	
792/30300 (epoch 1.307), train_loss = 2.31763948, grad/param norm = 3.8993e-01, time/batch = 0.6961s	
793/30300 (epoch 1.309), train_loss = 2.62455820, grad/param norm = 4.2292e-01, time/batch = 0.7013s	
794/30300 (epoch 1.310), train_loss = 2.29431979, grad/param norm = 4.0730e-01, time/batch = 0.7207s	
795/30300 (epoch 1.312), train_loss = 2.39296624, grad/param norm = 3.9648e-01, time/batch = 0.7001s	
796/30300 (epoch 1.314), train_loss = 2.35715035, grad/param norm = 3.0941e-01, time/batch = 0.6947s	
797/30300 (epoch 1.315), train_loss = 2.37882153, grad/param norm = 2.6465e-01, time/batch = 0.6893s	
798/30300 (epoch 1.317), train_loss = 2.39697277, grad/param norm = 2.5189e-01, time/batch = 0.6875s	
799/30300 (epoch 1.318), train_loss = 2.57361365, grad/param norm = 2.5804e-01, time/batch = 0.6921s	
800/30300 (epoch 1.320), train_loss = 2.42014933, grad/param norm = 3.2131e-01, time/batch = 0.7008s	
801/30300 (epoch 1.322), train_loss = 2.29637870, grad/param norm = 3.5228e-01, time/batch = 0.7024s	
802/30300 (epoch 1.323), train_loss = 2.35545313, grad/param norm = 2.5678e-01, time/batch = 0.6969s	
803/30300 (epoch 1.325), train_loss = 2.26713432, grad/param norm = 2.9938e-01, time/batch = 0.6901s	
804/30300 (epoch 1.327), train_loss = 2.31209793, grad/param norm = 2.7221e-01, time/batch = 0.6925s	
805/30300 (epoch 1.328), train_loss = 2.30184285, grad/param norm = 2.5789e-01, time/batch = 0.6887s	
806/30300 (epoch 1.330), train_loss = 2.43276331, grad/param norm = 2.6990e-01, time/batch = 0.6899s	
807/30300 (epoch 1.332), train_loss = 2.53505660, grad/param norm = 2.9188e-01, time/batch = 0.6949s	
808/30300 (epoch 1.333), train_loss = 2.44009167, grad/param norm = 3.5530e-01, time/batch = 0.6893s	
809/30300 (epoch 1.335), train_loss = 2.23702727, grad/param norm = 3.4146e-01, time/batch = 0.6915s	
810/30300 (epoch 1.337), train_loss = 2.54242018, grad/param norm = 3.0904e-01, time/batch = 0.6961s	
811/30300 (epoch 1.338), train_loss = 2.36377139, grad/param norm = 3.2559e-01, time/batch = 0.6911s	
812/30300 (epoch 1.340), train_loss = 2.40141921, grad/param norm = 3.3128e-01, time/batch = 0.6938s	
813/30300 (epoch 1.342), train_loss = 2.32575338, grad/param norm = 2.6226e-01, time/batch = 0.6910s	
814/30300 (epoch 1.343), train_loss = 2.31055304, grad/param norm = 2.8778e-01, time/batch = 0.6919s	
815/30300 (epoch 1.345), train_loss = 2.35682625, grad/param norm = 2.7354e-01, time/batch = 0.6935s	
816/30300 (epoch 1.347), train_loss = 2.21023855, grad/param norm = 2.1297e-01, time/batch = 0.6927s	
817/30300 (epoch 1.348), train_loss = 2.23683842, grad/param norm = 2.4248e-01, time/batch = 0.6932s	
818/30300 (epoch 1.350), train_loss = 2.37044927, grad/param norm = 2.5845e-01, time/batch = 0.6934s	
819/30300 (epoch 1.351), train_loss = 2.32368725, grad/param norm = 3.1750e-01, time/batch = 0.6940s	
820/30300 (epoch 1.353), train_loss = 2.20452731, grad/param norm = 3.6989e-01, time/batch = 0.6893s	
821/30300 (epoch 1.355), train_loss = 2.38095356, grad/param norm = 3.3032e-01, time/batch = 0.6925s	
822/30300 (epoch 1.356), train_loss = 2.44105913, grad/param norm = 2.6212e-01, time/batch = 0.6927s	
823/30300 (epoch 1.358), train_loss = 2.45414513, grad/param norm = 2.9646e-01, time/batch = 0.6904s	
824/30300 (epoch 1.360), train_loss = 2.26558059, grad/param norm = 3.0302e-01, time/batch = 0.6891s	
825/30300 (epoch 1.361), train_loss = 2.37728892, grad/param norm = 2.9924e-01, time/batch = 0.6861s	
826/30300 (epoch 1.363), train_loss = 2.50550367, grad/param norm = 2.5972e-01, time/batch = 0.6901s	
827/30300 (epoch 1.365), train_loss = 2.32380691, grad/param norm = 3.6225e-01, time/batch = 0.7205s	
828/30300 (epoch 1.366), train_loss = 2.34699616, grad/param norm = 3.6126e-01, time/batch = 0.6974s	
829/30300 (epoch 1.368), train_loss = 2.21676949, grad/param norm = 2.9283e-01, time/batch = 0.6885s	
830/30300 (epoch 1.370), train_loss = 2.40256052, grad/param norm = 2.7645e-01, time/batch = 0.6871s	
831/30300 (epoch 1.371), train_loss = 2.38596030, grad/param norm = 3.0459e-01, time/batch = 0.6895s	
832/30300 (epoch 1.373), train_loss = 2.33479380, grad/param norm = 2.8030e-01, time/batch = 0.6923s	
833/30300 (epoch 1.375), train_loss = 2.25449976, grad/param norm = 2.4123e-01, time/batch = 0.6928s	
834/30300 (epoch 1.376), train_loss = 2.32013819, grad/param norm = 2.5082e-01, time/batch = 0.6890s	
835/30300 (epoch 1.378), train_loss = 2.28226066, grad/param norm = 2.5754e-01, time/batch = 0.6886s	
836/30300 (epoch 1.380), train_loss = 2.49399939, grad/param norm = 2.6171e-01, time/batch = 0.6939s	
837/30300 (epoch 1.381), train_loss = 2.35225292, grad/param norm = 2.3818e-01, time/batch = 0.6895s	
838/30300 (epoch 1.383), train_loss = 2.44212742, grad/param norm = 3.0457e-01, time/batch = 0.6958s	
839/30300 (epoch 1.384), train_loss = 2.53515052, grad/param norm = 3.0364e-01, time/batch = 0.6951s	
840/30300 (epoch 1.386), train_loss = 2.29520147, grad/param norm = 3.2132e-01, time/batch = 0.6876s	
841/30300 (epoch 1.388), train_loss = 2.39168266, grad/param norm = 3.8204e-01, time/batch = 0.7142s	
842/30300 (epoch 1.389), train_loss = 2.36368400, grad/param norm = 3.9188e-01, time/batch = 0.7087s	
843/30300 (epoch 1.391), train_loss = 2.41141363, grad/param norm = 2.7398e-01, time/batch = 0.6927s	
844/30300 (epoch 1.393), train_loss = 2.25604044, grad/param norm = 2.4612e-01, time/batch = 0.7097s	
845/30300 (epoch 1.394), train_loss = 2.33646413, grad/param norm = 2.6627e-01, time/batch = 0.7023s	
846/30300 (epoch 1.396), train_loss = 2.34947843, grad/param norm = 2.8736e-01, time/batch = 0.7285s	
847/30300 (epoch 1.398), train_loss = 2.34291667, grad/param norm = 3.1121e-01, time/batch = 0.7005s	
848/30300 (epoch 1.399), train_loss = 2.24901493, grad/param norm = 2.4928e-01, time/batch = 0.6861s	
849/30300 (epoch 1.401), train_loss = 2.40613434, grad/param norm = 3.0840e-01, time/batch = 0.6922s	
850/30300 (epoch 1.403), train_loss = 2.34807304, grad/param norm = 2.9167e-01, time/batch = 0.7140s	
851/30300 (epoch 1.404), train_loss = 2.36706736, grad/param norm = 3.3735e-01, time/batch = 0.7279s	
852/30300 (epoch 1.406), train_loss = 2.33545072, grad/param norm = 3.2954e-01, time/batch = 0.7042s	
853/30300 (epoch 1.408), train_loss = 2.35147059, grad/param norm = 2.9398e-01, time/batch = 0.6962s	
854/30300 (epoch 1.409), train_loss = 2.11115530, grad/param norm = 2.7952e-01, time/batch = 0.6955s	
855/30300 (epoch 1.411), train_loss = 2.24744322, grad/param norm = 3.4193e-01, time/batch = 0.6879s	
856/30300 (epoch 1.413), train_loss = 2.21512768, grad/param norm = 2.9758e-01, time/batch = 0.6881s	
857/30300 (epoch 1.414), train_loss = 2.44830304, grad/param norm = 3.1618e-01, time/batch = 0.6885s	
858/30300 (epoch 1.416), train_loss = 2.38961336, grad/param norm = 3.2413e-01, time/batch = 0.6910s	
859/30300 (epoch 1.417), train_loss = 2.20851798, grad/param norm = 2.3875e-01, time/batch = 0.6945s	
860/30300 (epoch 1.419), train_loss = 2.16216802, grad/param norm = 2.5499e-01, time/batch = 0.6923s	
861/30300 (epoch 1.421), train_loss = 2.18766320, grad/param norm = 2.9365e-01, time/batch = 0.6920s	
862/30300 (epoch 1.422), train_loss = 2.25923396, grad/param norm = 2.6903e-01, time/batch = 0.6932s	
863/30300 (epoch 1.424), train_loss = 2.40807635, grad/param norm = 2.5855e-01, time/batch = 0.6947s	
864/30300 (epoch 1.426), train_loss = 2.11565837, grad/param norm = 3.0842e-01, time/batch = 0.6972s	
865/30300 (epoch 1.427), train_loss = 2.27223762, grad/param norm = 3.6107e-01, time/batch = 0.6895s	
866/30300 (epoch 1.429), train_loss = 2.42288039, grad/param norm = 3.8385e-01, time/batch = 0.6903s	
867/30300 (epoch 1.431), train_loss = 2.39357619, grad/param norm = 4.3032e-01, time/batch = 0.6892s	
868/30300 (epoch 1.432), train_loss = 2.28806609, grad/param norm = 2.9135e-01, time/batch = 0.6937s	
869/30300 (epoch 1.434), train_loss = 2.27702949, grad/param norm = 2.4165e-01, time/batch = 0.6906s	
870/30300 (epoch 1.436), train_loss = 2.32076871, grad/param norm = 3.2073e-01, time/batch = 0.6927s	
871/30300 (epoch 1.437), train_loss = 2.35145365, grad/param norm = 2.6897e-01, time/batch = 0.6918s	
872/30300 (epoch 1.439), train_loss = 2.35850946, grad/param norm = 2.5733e-01, time/batch = 0.6941s	
873/30300 (epoch 1.441), train_loss = 2.20494899, grad/param norm = 2.3558e-01, time/batch = 0.6958s	
874/30300 (epoch 1.442), train_loss = 2.16536141, grad/param norm = 2.6803e-01, time/batch = 0.6912s	
875/30300 (epoch 1.444), train_loss = 2.27818916, grad/param norm = 3.1574e-01, time/batch = 0.6900s	
876/30300 (epoch 1.446), train_loss = 2.22628587, grad/param norm = 3.3095e-01, time/batch = 0.6907s	
877/30300 (epoch 1.447), train_loss = 2.35629216, grad/param norm = 3.2683e-01, time/batch = 0.6882s	
878/30300 (epoch 1.449), train_loss = 2.29468821, grad/param norm = 3.2822e-01, time/batch = 0.6912s	
879/30300 (epoch 1.450), train_loss = 2.44900674, grad/param norm = 3.2909e-01, time/batch = 0.6903s	
880/30300 (epoch 1.452), train_loss = 2.21535746, grad/param norm = 2.3701e-01, time/batch = 0.6892s	
881/30300 (epoch 1.454), train_loss = 2.23384450, grad/param norm = 2.2892e-01, time/batch = 0.6909s	
882/30300 (epoch 1.455), train_loss = 2.50552828, grad/param norm = 2.9609e-01, time/batch = 0.6893s	
883/30300 (epoch 1.457), train_loss = 2.37689986, grad/param norm = 2.5506e-01, time/batch = 0.6915s	
884/30300 (epoch 1.459), train_loss = 2.27049529, grad/param norm = 2.9655e-01, time/batch = 0.7168s	
885/30300 (epoch 1.460), train_loss = 2.33161781, grad/param norm = 3.2126e-01, time/batch = 0.7066s	
886/30300 (epoch 1.462), train_loss = 2.37294909, grad/param norm = 2.9968e-01, time/batch = 0.7077s	
887/30300 (epoch 1.464), train_loss = 2.41048076, grad/param norm = 2.9721e-01, time/batch = 0.7141s	
888/30300 (epoch 1.465), train_loss = 2.18299005, grad/param norm = 2.5443e-01, time/batch = 0.7060s	
889/30300 (epoch 1.467), train_loss = 2.09124375, grad/param norm = 3.0272e-01, time/batch = 0.6943s	
890/30300 (epoch 1.469), train_loss = 2.23392942, grad/param norm = 2.8158e-01, time/batch = 0.6873s	
891/30300 (epoch 1.470), train_loss = 2.29282921, grad/param norm = 2.9962e-01, time/batch = 0.6913s	
892/30300 (epoch 1.472), train_loss = 2.12745271, grad/param norm = 2.6849e-01, time/batch = 0.6908s	
893/30300 (epoch 1.474), train_loss = 2.34590865, grad/param norm = 3.4279e-01, time/batch = 0.6950s	
894/30300 (epoch 1.475), train_loss = 2.27881322, grad/param norm = 2.7936e-01, time/batch = 0.6930s	
895/30300 (epoch 1.477), train_loss = 2.32782833, grad/param norm = 2.9749e-01, time/batch = 0.6907s	
896/30300 (epoch 1.479), train_loss = 2.39126865, grad/param norm = 3.3429e-01, time/batch = 0.6903s	
897/30300 (epoch 1.480), train_loss = 2.20011145, grad/param norm = 3.1439e-01, time/batch = 0.6931s	
898/30300 (epoch 1.482), train_loss = 2.41915390, grad/param norm = 4.4998e-01, time/batch = 0.7103s	
899/30300 (epoch 1.483), train_loss = 2.32218447, grad/param norm = 4.0289e-01, time/batch = 0.7152s	
900/30300 (epoch 1.485), train_loss = 2.30199019, grad/param norm = 3.3469e-01, time/batch = 0.6916s	
901/30300 (epoch 1.487), train_loss = 2.38715309, grad/param norm = 2.4228e-01, time/batch = 0.6933s	
902/30300 (epoch 1.488), train_loss = 2.19409529, grad/param norm = 2.7529e-01, time/batch = 0.6890s	
903/30300 (epoch 1.490), train_loss = 2.14900086, grad/param norm = 3.1620e-01, time/batch = 0.6902s	
904/30300 (epoch 1.492), train_loss = 2.31683775, grad/param norm = 2.7432e-01, time/batch = 0.6912s	
905/30300 (epoch 1.493), train_loss = 2.17853031, grad/param norm = 2.7647e-01, time/batch = 0.6999s	
906/30300 (epoch 1.495), train_loss = 2.28940739, grad/param norm = 2.7583e-01, time/batch = 0.6931s	
907/30300 (epoch 1.497), train_loss = 2.26384856, grad/param norm = 3.2649e-01, time/batch = 0.6966s	
908/30300 (epoch 1.498), train_loss = 2.36430111, grad/param norm = 2.9820e-01, time/batch = 0.7140s	
909/30300 (epoch 1.500), train_loss = 2.48675542, grad/param norm = 2.9341e-01, time/batch = 0.7165s	
910/30300 (epoch 1.502), train_loss = 2.17022272, grad/param norm = 3.0117e-01, time/batch = 0.6883s	
911/30300 (epoch 1.503), train_loss = 2.29050670, grad/param norm = 2.5594e-01, time/batch = 0.6931s	
912/30300 (epoch 1.505), train_loss = 2.36484074, grad/param norm = 2.5964e-01, time/batch = 0.6930s	
913/30300 (epoch 1.507), train_loss = 2.25515363, grad/param norm = 2.7475e-01, time/batch = 0.6904s	
914/30300 (epoch 1.508), train_loss = 2.39177780, grad/param norm = 2.7307e-01, time/batch = 0.6914s	
915/30300 (epoch 1.510), train_loss = 2.32472295, grad/param norm = 2.9260e-01, time/batch = 0.6988s	
916/30300 (epoch 1.512), train_loss = 2.17411004, grad/param norm = 2.4589e-01, time/batch = 0.7008s	
917/30300 (epoch 1.513), train_loss = 2.31542205, grad/param norm = 2.7228e-01, time/batch = 0.6934s	
918/30300 (epoch 1.515), train_loss = 2.25445425, grad/param norm = 3.3715e-01, time/batch = 0.6926s	
919/30300 (epoch 1.517), train_loss = 2.16007802, grad/param norm = 3.3479e-01, time/batch = 0.6916s	
920/30300 (epoch 1.518), train_loss = 2.38276920, grad/param norm = 2.5378e-01, time/batch = 0.6855s	
921/30300 (epoch 1.520), train_loss = 2.48556238, grad/param norm = 2.9117e-01, time/batch = 0.6888s	
922/30300 (epoch 1.521), train_loss = 2.25190498, grad/param norm = 2.8626e-01, time/batch = 0.7039s	
923/30300 (epoch 1.523), train_loss = 2.39128341, grad/param norm = 2.3953e-01, time/batch = 0.7211s	
924/30300 (epoch 1.525), train_loss = 2.33389870, grad/param norm = 2.4084e-01, time/batch = 0.6896s	
925/30300 (epoch 1.526), train_loss = 2.25686434, grad/param norm = 2.5117e-01, time/batch = 0.6867s	
926/30300 (epoch 1.528), train_loss = 2.21523537, grad/param norm = 2.6568e-01, time/batch = 0.6908s	
927/30300 (epoch 1.530), train_loss = 2.27893473, grad/param norm = 2.7381e-01, time/batch = 0.6870s	
928/30300 (epoch 1.531), train_loss = 2.34092163, grad/param norm = 3.1471e-01, time/batch = 0.6900s	
929/30300 (epoch 1.533), train_loss = 2.35023571, grad/param norm = 2.5026e-01, time/batch = 0.6951s	
930/30300 (epoch 1.535), train_loss = 2.18601921, grad/param norm = 2.3105e-01, time/batch = 0.7055s	
931/30300 (epoch 1.536), train_loss = 2.27974420, grad/param norm = 2.4477e-01, time/batch = 0.7027s	
932/30300 (epoch 1.538), train_loss = 2.06486080, grad/param norm = 2.8139e-01, time/batch = 0.7021s	
933/30300 (epoch 1.540), train_loss = 2.32024654, grad/param norm = 2.7611e-01, time/batch = 0.6942s	
934/30300 (epoch 1.541), train_loss = 2.20651268, grad/param norm = 2.5350e-01, time/batch = 0.7056s	
935/30300 (epoch 1.543), train_loss = 2.28534005, grad/param norm = 2.5193e-01, time/batch = 0.6904s	
936/30300 (epoch 1.545), train_loss = 2.40826919, grad/param norm = 3.6803e-01, time/batch = 0.6988s	
937/30300 (epoch 1.546), train_loss = 2.42981136, grad/param norm = 5.2388e-01, time/batch = 0.7207s	
938/30300 (epoch 1.548), train_loss = 2.21182683, grad/param norm = 4.2479e-01, time/batch = 0.7009s	
939/30300 (epoch 1.550), train_loss = 2.46991178, grad/param norm = 2.8989e-01, time/batch = 0.6912s	
940/30300 (epoch 1.551), train_loss = 2.29754811, grad/param norm = 2.5178e-01, time/batch = 0.6960s	
941/30300 (epoch 1.553), train_loss = 2.24544257, grad/param norm = 2.3363e-01, time/batch = 0.6902s	
942/30300 (epoch 1.554), train_loss = 2.40028714, grad/param norm = 2.4848e-01, time/batch = 0.6964s	
943/30300 (epoch 1.556), train_loss = 2.33298949, grad/param norm = 2.4586e-01, time/batch = 0.6886s	
944/30300 (epoch 1.558), train_loss = 2.36494981, grad/param norm = 2.3884e-01, time/batch = 0.6879s	
945/30300 (epoch 1.559), train_loss = 2.24104568, grad/param norm = 2.5912e-01, time/batch = 0.6839s	
946/30300 (epoch 1.561), train_loss = 2.21958022, grad/param norm = 3.0501e-01, time/batch = 0.6873s	
947/30300 (epoch 1.563), train_loss = 2.37978212, grad/param norm = 3.1323e-01, time/batch = 0.6883s	
948/30300 (epoch 1.564), train_loss = 2.29767757, grad/param norm = 2.4045e-01, time/batch = 0.6951s	
949/30300 (epoch 1.566), train_loss = 2.42597745, grad/param norm = 2.9052e-01, time/batch = 0.6882s	
950/30300 (epoch 1.568), train_loss = 2.15354816, grad/param norm = 3.9033e-01, time/batch = 0.6922s	
951/30300 (epoch 1.569), train_loss = 2.24792559, grad/param norm = 3.3500e-01, time/batch = 0.7147s	
952/30300 (epoch 1.571), train_loss = 2.33597765, grad/param norm = 3.0506e-01, time/batch = 0.7113s	
953/30300 (epoch 1.573), train_loss = 2.29662196, grad/param norm = 2.6456e-01, time/batch = 0.6897s	
954/30300 (epoch 1.574), train_loss = 2.34132395, grad/param norm = 2.9675e-01, time/batch = 0.7181s	
955/30300 (epoch 1.576), train_loss = 2.38567900, grad/param norm = 2.8681e-01, time/batch = 0.6919s	
956/30300 (epoch 1.578), train_loss = 2.17471441, grad/param norm = 2.2884e-01, time/batch = 0.6862s	
957/30300 (epoch 1.579), train_loss = 2.17988434, grad/param norm = 2.8181e-01, time/batch = 0.6892s	
958/30300 (epoch 1.581), train_loss = 2.44211901, grad/param norm = 3.5121e-01, time/batch = 0.6913s	
959/30300 (epoch 1.583), train_loss = 2.43462736, grad/param norm = 2.6132e-01, time/batch = 0.6917s	
960/30300 (epoch 1.584), train_loss = 2.37881290, grad/param norm = 2.3871e-01, time/batch = 0.6915s	
961/30300 (epoch 1.586), train_loss = 2.29112700, grad/param norm = 2.7979e-01, time/batch = 0.6908s	
962/30300 (epoch 1.587), train_loss = 2.23572440, grad/param norm = 2.7480e-01, time/batch = 0.6940s	
963/30300 (epoch 1.589), train_loss = 1.98491256, grad/param norm = 2.3780e-01, time/batch = 0.7016s	
964/30300 (epoch 1.591), train_loss = 2.25537527, grad/param norm = 2.8480e-01, time/batch = 0.7017s	
965/30300 (epoch 1.592), train_loss = 2.25001481, grad/param norm = 2.8291e-01, time/batch = 0.7046s	
966/30300 (epoch 1.594), train_loss = 2.30351149, grad/param norm = 2.8518e-01, time/batch = 0.7206s	
967/30300 (epoch 1.596), train_loss = 2.14467585, grad/param norm = 3.8881e-01, time/batch = 0.6912s	
968/30300 (epoch 1.597), train_loss = 2.27065553, grad/param norm = 2.8060e-01, time/batch = 0.6917s	
969/30300 (epoch 1.599), train_loss = 2.08358308, grad/param norm = 2.9136e-01, time/batch = 0.6915s	
970/30300 (epoch 1.601), train_loss = 2.25673884, grad/param norm = 2.7116e-01, time/batch = 0.6944s	
971/30300 (epoch 1.602), train_loss = 2.24280876, grad/param norm = 2.5517e-01, time/batch = 0.6926s	
972/30300 (epoch 1.604), train_loss = 2.24257813, grad/param norm = 3.2960e-01, time/batch = 0.6914s	
973/30300 (epoch 1.606), train_loss = 2.65489540, grad/param norm = 4.6744e-01, time/batch = 0.6911s	
974/30300 (epoch 1.607), train_loss = 2.42603633, grad/param norm = 3.4438e-01, time/batch = 0.6905s	
975/30300 (epoch 1.609), train_loss = 2.49046590, grad/param norm = 3.2400e-01, time/batch = 0.6915s	
976/30300 (epoch 1.611), train_loss = 2.10504778, grad/param norm = 2.6941e-01, time/batch = 0.6863s	
977/30300 (epoch 1.612), train_loss = 2.28802359, grad/param norm = 2.9404e-01, time/batch = 0.6921s	
978/30300 (epoch 1.614), train_loss = 2.15362533, grad/param norm = 3.7619e-01, time/batch = 0.6890s	
979/30300 (epoch 1.616), train_loss = 2.34761862, grad/param norm = 3.5182e-01, time/batch = 0.6994s	
980/30300 (epoch 1.617), train_loss = 2.33534609, grad/param norm = 3.1079e-01, time/batch = 0.7226s	
981/30300 (epoch 1.619), train_loss = 2.09159293, grad/param norm = 2.2017e-01, time/batch = 0.7077s	
982/30300 (epoch 1.620), train_loss = 2.37810174, grad/param norm = 2.6057e-01, time/batch = 0.6937s	
983/30300 (epoch 1.622), train_loss = 2.20286394, grad/param norm = 2.8971e-01, time/batch = 0.6881s	
984/30300 (epoch 1.624), train_loss = 2.19222358, grad/param norm = 2.8690e-01, time/batch = 0.6891s	
985/30300 (epoch 1.625), train_loss = 2.18901658, grad/param norm = 2.9073e-01, time/batch = 0.6916s	
986/30300 (epoch 1.627), train_loss = 2.41036289, grad/param norm = 2.5705e-01, time/batch = 0.6911s	
987/30300 (epoch 1.629), train_loss = 2.32550713, grad/param norm = 2.7549e-01, time/batch = 0.6917s	
988/30300 (epoch 1.630), train_loss = 2.30035560, grad/param norm = 2.6322e-01, time/batch = 0.6886s	
989/30300 (epoch 1.632), train_loss = 2.27147849, grad/param norm = 2.8251e-01, time/batch = 0.6980s	
990/30300 (epoch 1.634), train_loss = 2.02675395, grad/param norm = 2.1250e-01, time/batch = 0.6870s	
991/30300 (epoch 1.635), train_loss = 2.29388676, grad/param norm = 2.8955e-01, time/batch = 0.6896s	
992/30300 (epoch 1.637), train_loss = 2.22412933, grad/param norm = 3.2091e-01, time/batch = 0.6898s	
993/30300 (epoch 1.639), train_loss = 2.09318993, grad/param norm = 2.8098e-01, time/batch = 0.6916s	
994/30300 (epoch 1.640), train_loss = 2.30401378, grad/param norm = 3.1631e-01, time/batch = 0.7118s	
995/30300 (epoch 1.642), train_loss = 2.28710937, grad/param norm = 2.8323e-01, time/batch = 0.7117s	
996/30300 (epoch 1.644), train_loss = 2.28517830, grad/param norm = 2.4112e-01, time/batch = 0.6910s	
997/30300 (epoch 1.645), train_loss = 2.22674228, grad/param norm = 2.5957e-01, time/batch = 0.6877s	
998/30300 (epoch 1.647), train_loss = 2.25649893, grad/param norm = 3.6184e-01, time/batch = 0.6899s	
999/30300 (epoch 1.649), train_loss = 2.28004825, grad/param norm = 2.7810e-01, time/batch = 0.6885s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch1.65_2.2623.t7	
1000/30300 (epoch 1.650), train_loss = 2.23622516, grad/param norm = 2.8175e-01, time/batch = 0.6914s	
1001/30300 (epoch 1.652), train_loss = 2.17488348, grad/param norm = 2.6657e-01, time/batch = 0.6906s	
1002/30300 (epoch 1.653), train_loss = 2.37693830, grad/param norm = 3.1397e-01, time/batch = 0.6950s	
1003/30300 (epoch 1.655), train_loss = 2.25067970, grad/param norm = 2.5697e-01, time/batch = 0.6907s	
1004/30300 (epoch 1.657), train_loss = 2.35558167, grad/param norm = 2.3696e-01, time/batch = 0.6950s	
1005/30300 (epoch 1.658), train_loss = 2.20046745, grad/param norm = 2.6943e-01, time/batch = 0.6933s	
1006/30300 (epoch 1.660), train_loss = 2.26581659, grad/param norm = 2.6362e-01, time/batch = 0.6931s	
1007/30300 (epoch 1.662), train_loss = 2.22603708, grad/param norm = 2.5242e-01, time/batch = 0.7124s	
1008/30300 (epoch 1.663), train_loss = 2.24964640, grad/param norm = 2.7795e-01, time/batch = 0.6894s	
1009/30300 (epoch 1.665), train_loss = 2.10449250, grad/param norm = 2.3260e-01, time/batch = 0.6880s	
1010/30300 (epoch 1.667), train_loss = 2.34355965, grad/param norm = 2.6828e-01, time/batch = 0.6968s	
1011/30300 (epoch 1.668), train_loss = 2.37003870, grad/param norm = 2.7154e-01, time/batch = 0.6887s	
1012/30300 (epoch 1.670), train_loss = 2.25007693, grad/param norm = 2.6726e-01, time/batch = 0.6894s	
1013/30300 (epoch 1.672), train_loss = 2.35517908, grad/param norm = 2.4457e-01, time/batch = 0.7072s	
1014/30300 (epoch 1.673), train_loss = 2.23977000, grad/param norm = 2.4128e-01, time/batch = 0.7218s	
1015/30300 (epoch 1.675), train_loss = 2.16534054, grad/param norm = 3.0147e-01, time/batch = 0.7137s	
1016/30300 (epoch 1.677), train_loss = 2.20811563, grad/param norm = 3.4806e-01, time/batch = 0.6948s	
1017/30300 (epoch 1.678), train_loss = 2.23889665, grad/param norm = 2.8748e-01, time/batch = 0.6905s	
1018/30300 (epoch 1.680), train_loss = 2.00056291, grad/param norm = 2.9820e-01, time/batch = 0.6872s	
1019/30300 (epoch 1.682), train_loss = 2.18975258, grad/param norm = 2.5925e-01, time/batch = 0.6882s	
1020/30300 (epoch 1.683), train_loss = 2.28431125, grad/param norm = 2.3511e-01, time/batch = 0.6865s	
1021/30300 (epoch 1.685), train_loss = 2.37895229, grad/param norm = 3.0269e-01, time/batch = 0.6859s	
1022/30300 (epoch 1.686), train_loss = 2.23191828, grad/param norm = 2.3339e-01, time/batch = 0.6876s	
1023/30300 (epoch 1.688), train_loss = 2.32497406, grad/param norm = 2.7674e-01, time/batch = 0.7098s	
1024/30300 (epoch 1.690), train_loss = 2.23438527, grad/param norm = 3.3117e-01, time/batch = 0.6882s	
1025/30300 (epoch 1.691), train_loss = 2.28709287, grad/param norm = 4.7480e-01, time/batch = 0.6878s	
1026/30300 (epoch 1.693), train_loss = 2.53496570, grad/param norm = 3.6098e-01, time/batch = 0.6897s	
1027/30300 (epoch 1.695), train_loss = 2.35539523, grad/param norm = 2.9739e-01, time/batch = 0.6896s	
1028/30300 (epoch 1.696), train_loss = 2.39455045, grad/param norm = 3.1929e-01, time/batch = 0.6984s	
1029/30300 (epoch 1.698), train_loss = 2.21112586, grad/param norm = 2.4782e-01, time/batch = 0.7207s	
1030/30300 (epoch 1.700), train_loss = 2.17853700, grad/param norm = 2.3066e-01, time/batch = 0.6850s	
1031/30300 (epoch 1.701), train_loss = 2.01074359, grad/param norm = 2.2825e-01, time/batch = 0.6855s	
1032/30300 (epoch 1.703), train_loss = 2.12576509, grad/param norm = 2.2825e-01, time/batch = 0.6862s	
1033/30300 (epoch 1.705), train_loss = 2.28431812, grad/param norm = 3.0763e-01, time/batch = 0.6862s	
1034/30300 (epoch 1.706), train_loss = 2.11762725, grad/param norm = 3.0389e-01, time/batch = 0.6866s	
1035/30300 (epoch 1.708), train_loss = 2.22390001, grad/param norm = 2.7001e-01, time/batch = 0.6879s	
1036/30300 (epoch 1.710), train_loss = 2.12624228, grad/param norm = 2.6781e-01, time/batch = 0.6904s	
1037/30300 (epoch 1.711), train_loss = 2.13903530, grad/param norm = 2.2553e-01, time/batch = 0.6857s	
1038/30300 (epoch 1.713), train_loss = 2.03353620, grad/param norm = 2.6030e-01, time/batch = 0.6895s	
1039/30300 (epoch 1.715), train_loss = 2.23041164, grad/param norm = 2.7789e-01, time/batch = 0.6863s	
1040/30300 (epoch 1.716), train_loss = 2.37517168, grad/param norm = 2.6795e-01, time/batch = 0.6873s	
1041/30300 (epoch 1.718), train_loss = 2.37324472, grad/param norm = 2.8258e-01, time/batch = 0.6924s	
1042/30300 (epoch 1.719), train_loss = 2.17366019, grad/param norm = 2.5365e-01, time/batch = 0.6906s	
1043/30300 (epoch 1.721), train_loss = 2.20408730, grad/param norm = 2.3814e-01, time/batch = 0.7185s	
1044/30300 (epoch 1.723), train_loss = 2.14500789, grad/param norm = 2.3615e-01, time/batch = 0.7027s	
1045/30300 (epoch 1.724), train_loss = 2.23937139, grad/param norm = 2.6362e-01, time/batch = 0.6881s	
1046/30300 (epoch 1.726), train_loss = 2.56754028, grad/param norm = 2.9600e-01, time/batch = 0.6869s	
1047/30300 (epoch 1.728), train_loss = 2.11651654, grad/param norm = 2.9819e-01, time/batch = 0.6880s	
1048/30300 (epoch 1.729), train_loss = 2.26953563, grad/param norm = 3.6105e-01, time/batch = 0.6857s	
1049/30300 (epoch 1.731), train_loss = 2.26207652, grad/param norm = 2.6639e-01, time/batch = 0.6893s	
1050/30300 (epoch 1.733), train_loss = 2.18290214, grad/param norm = 2.2235e-01, time/batch = 0.6898s	
1051/30300 (epoch 1.734), train_loss = 2.20765972, grad/param norm = 2.2632e-01, time/batch = 0.6903s	
1052/30300 (epoch 1.736), train_loss = 2.19776161, grad/param norm = 2.9042e-01, time/batch = 0.7021s	
1053/30300 (epoch 1.738), train_loss = 2.07336240, grad/param norm = 2.3453e-01, time/batch = 0.6922s	
1054/30300 (epoch 1.739), train_loss = 2.32392222, grad/param norm = 2.4577e-01, time/batch = 0.6938s	
1055/30300 (epoch 1.741), train_loss = 2.30413364, grad/param norm = 2.7200e-01, time/batch = 0.6896s	
1056/30300 (epoch 1.743), train_loss = 2.09835196, grad/param norm = 2.5654e-01, time/batch = 0.7094s	
1057/30300 (epoch 1.744), train_loss = 2.32304200, grad/param norm = 2.8971e-01, time/batch = 0.7094s	
1058/30300 (epoch 1.746), train_loss = 2.06537267, grad/param norm = 2.5569e-01, time/batch = 0.7069s	
1059/30300 (epoch 1.748), train_loss = 2.25705460, grad/param norm = 3.3576e-01, time/batch = 0.6967s	
1060/30300 (epoch 1.749), train_loss = 2.24020896, grad/param norm = 3.6472e-01, time/batch = 0.6919s	
1061/30300 (epoch 1.751), train_loss = 2.17587766, grad/param norm = 2.8989e-01, time/batch = 0.6916s	
1062/30300 (epoch 1.752), train_loss = 2.10714958, grad/param norm = 2.8364e-01, time/batch = 0.6879s	
1063/30300 (epoch 1.754), train_loss = 2.04794142, grad/param norm = 2.3010e-01, time/batch = 0.6883s	
1064/30300 (epoch 1.756), train_loss = 2.10845570, grad/param norm = 2.5309e-01, time/batch = 0.6887s	
1065/30300 (epoch 1.757), train_loss = 2.30951823, grad/param norm = 2.6222e-01, time/batch = 0.6910s	
1066/30300 (epoch 1.759), train_loss = 2.09887631, grad/param norm = 3.3963e-01, time/batch = 0.6894s	
1067/30300 (epoch 1.761), train_loss = 2.16710575, grad/param norm = 3.3954e-01, time/batch = 0.6866s	
1068/30300 (epoch 1.762), train_loss = 1.98842399, grad/param norm = 2.6636e-01, time/batch = 0.6902s	
1069/30300 (epoch 1.764), train_loss = 2.12454306, grad/param norm = 2.5365e-01, time/batch = 0.6866s	
1070/30300 (epoch 1.766), train_loss = 2.21941946, grad/param norm = 2.3292e-01, time/batch = 0.6894s	
1071/30300 (epoch 1.767), train_loss = 2.31706193, grad/param norm = 2.6302e-01, time/batch = 0.6907s	
1072/30300 (epoch 1.769), train_loss = 2.32758216, grad/param norm = 2.6362e-01, time/batch = 0.6902s	
1073/30300 (epoch 1.771), train_loss = 2.22433765, grad/param norm = 2.3375e-01, time/batch = 0.6893s	
1074/30300 (epoch 1.772), train_loss = 2.14344085, grad/param norm = 2.3460e-01, time/batch = 0.6884s	
1075/30300 (epoch 1.774), train_loss = 2.26090940, grad/param norm = 2.5200e-01, time/batch = 0.6876s	
1076/30300 (epoch 1.776), train_loss = 2.15425629, grad/param norm = 2.2710e-01, time/batch = 0.7163s	
1077/30300 (epoch 1.777), train_loss = 2.19249699, grad/param norm = 2.5056e-01, time/batch = 0.7072s	
1078/30300 (epoch 1.779), train_loss = 2.26766312, grad/param norm = 2.5953e-01, time/batch = 0.6942s	
1079/30300 (epoch 1.781), train_loss = 2.17665065, grad/param norm = 2.7551e-01, time/batch = 0.6909s	
1080/30300 (epoch 1.782), train_loss = 2.05642816, grad/param norm = 2.7234e-01, time/batch = 0.6894s	
1081/30300 (epoch 1.784), train_loss = 2.34232786, grad/param norm = 2.6966e-01, time/batch = 0.6921s	
1082/30300 (epoch 1.785), train_loss = 2.36209050, grad/param norm = 2.5542e-01, time/batch = 0.6874s	
1083/30300 (epoch 1.787), train_loss = 2.23737905, grad/param norm = 2.3654e-01, time/batch = 0.6924s	
1084/30300 (epoch 1.789), train_loss = 2.56761709, grad/param norm = 2.4616e-01, time/batch = 0.6923s	
1085/30300 (epoch 1.790), train_loss = 2.32263766, grad/param norm = 2.4986e-01, time/batch = 0.6927s	
1086/30300 (epoch 1.792), train_loss = 2.18163897, grad/param norm = 2.8450e-01, time/batch = 0.6944s	
1087/30300 (epoch 1.794), train_loss = 2.13061567, grad/param norm = 2.7630e-01, time/batch = 0.6892s	
1088/30300 (epoch 1.795), train_loss = 2.21767881, grad/param norm = 2.4092e-01, time/batch = 0.6932s	
1089/30300 (epoch 1.797), train_loss = 2.27572634, grad/param norm = 2.9022e-01, time/batch = 0.6885s	
1090/30300 (epoch 1.799), train_loss = 2.37418486, grad/param norm = 4.1892e-01, time/batch = 0.7061s	
1091/30300 (epoch 1.800), train_loss = 2.15797739, grad/param norm = 3.0248e-01, time/batch = 0.7162s	
1092/30300 (epoch 1.802), train_loss = 2.32698288, grad/param norm = 2.7997e-01, time/batch = 0.6913s	
1093/30300 (epoch 1.804), train_loss = 2.29801864, grad/param norm = 2.7827e-01, time/batch = 0.7067s	
1094/30300 (epoch 1.805), train_loss = 2.31553018, grad/param norm = 2.6081e-01, time/batch = 0.7081s	
1095/30300 (epoch 1.807), train_loss = 2.31955620, grad/param norm = 2.8602e-01, time/batch = 0.7148s	
1096/30300 (epoch 1.809), train_loss = 2.38147169, grad/param norm = 2.4665e-01, time/batch = 0.7106s	
1097/30300 (epoch 1.810), train_loss = 2.26552548, grad/param norm = 2.1710e-01, time/batch = 0.7102s	
1098/30300 (epoch 1.812), train_loss = 2.19142567, grad/param norm = 2.4592e-01, time/batch = 0.7055s	
1099/30300 (epoch 1.814), train_loss = 2.31659482, grad/param norm = 2.5962e-01, time/batch = 0.6980s	
1100/30300 (epoch 1.815), train_loss = 2.24629728, grad/param norm = 3.1257e-01, time/batch = 0.6896s	
1101/30300 (epoch 1.817), train_loss = 2.23439900, grad/param norm = 2.5945e-01, time/batch = 0.6896s	
1102/30300 (epoch 1.818), train_loss = 2.19069375, grad/param norm = 2.4291e-01, time/batch = 0.6898s	
1103/30300 (epoch 1.820), train_loss = 2.42478863, grad/param norm = 3.0617e-01, time/batch = 0.6892s	
1104/30300 (epoch 1.822), train_loss = 2.36069910, grad/param norm = 3.0210e-01, time/batch = 0.6986s	
1105/30300 (epoch 1.823), train_loss = 2.45247526, grad/param norm = 3.0524e-01, time/batch = 0.7282s	
1106/30300 (epoch 1.825), train_loss = 2.28344948, grad/param norm = 2.8768e-01, time/batch = 0.6958s	
1107/30300 (epoch 1.827), train_loss = 2.19889675, grad/param norm = 2.4929e-01, time/batch = 0.6979s	
1108/30300 (epoch 1.828), train_loss = 2.23366318, grad/param norm = 2.0928e-01, time/batch = 0.7069s	
1109/30300 (epoch 1.830), train_loss = 2.22143080, grad/param norm = 2.6022e-01, time/batch = 0.6934s	
1110/30300 (epoch 1.832), train_loss = 2.08666672, grad/param norm = 2.5254e-01, time/batch = 0.6940s	
1111/30300 (epoch 1.833), train_loss = 2.26033974, grad/param norm = 2.4384e-01, time/batch = 0.7000s	
1112/30300 (epoch 1.835), train_loss = 2.27080969, grad/param norm = 2.4519e-01, time/batch = 0.6999s	
1113/30300 (epoch 1.837), train_loss = 2.02633931, grad/param norm = 2.3660e-01, time/batch = 0.6973s	
1114/30300 (epoch 1.838), train_loss = 2.13217544, grad/param norm = 2.3101e-01, time/batch = 0.6893s	
1115/30300 (epoch 1.840), train_loss = 2.16724510, grad/param norm = 2.5463e-01, time/batch = 0.6889s	
1116/30300 (epoch 1.842), train_loss = 2.08915513, grad/param norm = 2.8231e-01, time/batch = 0.6875s	
1117/30300 (epoch 1.843), train_loss = 2.20839229, grad/param norm = 2.9216e-01, time/batch = 0.6890s	
1118/30300 (epoch 1.845), train_loss = 2.02611442, grad/param norm = 2.4088e-01, time/batch = 0.6907s	
1119/30300 (epoch 1.847), train_loss = 2.15064887, grad/param norm = 2.6499e-01, time/batch = 0.6880s	
1120/30300 (epoch 1.848), train_loss = 2.32099036, grad/param norm = 3.0382e-01, time/batch = 0.6879s	
1121/30300 (epoch 1.850), train_loss = 2.12514348, grad/param norm = 3.2077e-01, time/batch = 0.6881s	
1122/30300 (epoch 1.851), train_loss = 2.43158275, grad/param norm = 2.6524e-01, time/batch = 0.6898s	
1123/30300 (epoch 1.853), train_loss = 2.21780122, grad/param norm = 2.5844e-01, time/batch = 0.7107s	
1124/30300 (epoch 1.855), train_loss = 2.16438076, grad/param norm = 2.7482e-01, time/batch = 0.7116s	
1125/30300 (epoch 1.856), train_loss = 2.14089278, grad/param norm = 2.7133e-01, time/batch = 0.6878s	
1126/30300 (epoch 1.858), train_loss = 2.03843244, grad/param norm = 2.4161e-01, time/batch = 0.6896s	
1127/30300 (epoch 1.860), train_loss = 2.26245479, grad/param norm = 2.5293e-01, time/batch = 0.6886s	
1128/30300 (epoch 1.861), train_loss = 2.29553576, grad/param norm = 3.4735e-01, time/batch = 0.6893s	
1129/30300 (epoch 1.863), train_loss = 2.29710258, grad/param norm = 3.4836e-01, time/batch = 0.6877s	
1130/30300 (epoch 1.865), train_loss = 2.49446389, grad/param norm = 2.8153e-01, time/batch = 0.6867s	
1131/30300 (epoch 1.866), train_loss = 2.18933801, grad/param norm = 2.6172e-01, time/batch = 0.6894s	
1132/30300 (epoch 1.868), train_loss = 2.26602839, grad/param norm = 2.7162e-01, time/batch = 0.6884s	
1133/30300 (epoch 1.870), train_loss = 2.18351160, grad/param norm = 2.9514e-01, time/batch = 0.6930s	
1134/30300 (epoch 1.871), train_loss = 2.10703059, grad/param norm = 2.1843e-01, time/batch = 0.6882s	
1135/30300 (epoch 1.873), train_loss = 2.28302300, grad/param norm = 2.3297e-01, time/batch = 0.6899s	
1136/30300 (epoch 1.875), train_loss = 2.09537781, grad/param norm = 2.3575e-01, time/batch = 0.6919s	
1137/30300 (epoch 1.876), train_loss = 2.03232174, grad/param norm = 2.1182e-01, time/batch = 0.6976s	
1138/30300 (epoch 1.878), train_loss = 2.05093610, grad/param norm = 2.5895e-01, time/batch = 0.7061s	
1139/30300 (epoch 1.880), train_loss = 2.04010364, grad/param norm = 2.3963e-01, time/batch = 0.6895s	
1140/30300 (epoch 1.881), train_loss = 2.30755663, grad/param norm = 2.4492e-01, time/batch = 0.6917s	
1141/30300 (epoch 1.883), train_loss = 2.15826519, grad/param norm = 2.3933e-01, time/batch = 0.6895s	
1142/30300 (epoch 1.884), train_loss = 2.10367890, grad/param norm = 2.2929e-01, time/batch = 0.7021s	
1143/30300 (epoch 1.886), train_loss = 2.07942569, grad/param norm = 2.1844e-01, time/batch = 0.7108s	
1144/30300 (epoch 1.888), train_loss = 2.30278869, grad/param norm = 2.4385e-01, time/batch = 0.6934s	
1145/30300 (epoch 1.889), train_loss = 2.18359816, grad/param norm = 2.8466e-01, time/batch = 0.6857s	
1146/30300 (epoch 1.891), train_loss = 2.17983129, grad/param norm = 3.2616e-01, time/batch = 0.6852s	
1147/30300 (epoch 1.893), train_loss = 2.27927503, grad/param norm = 2.5415e-01, time/batch = 0.6860s	
1148/30300 (epoch 1.894), train_loss = 2.23453906, grad/param norm = 2.8359e-01, time/batch = 0.6846s	
1149/30300 (epoch 1.896), train_loss = 2.07757031, grad/param norm = 2.7723e-01, time/batch = 0.6963s	
1150/30300 (epoch 1.898), train_loss = 2.01042300, grad/param norm = 2.4383e-01, time/batch = 0.7085s	
1151/30300 (epoch 1.899), train_loss = 2.17074915, grad/param norm = 2.5581e-01, time/batch = 0.7222s	
1152/30300 (epoch 1.901), train_loss = 2.25227491, grad/param norm = 2.4676e-01, time/batch = 0.7242s	
1153/30300 (epoch 1.903), train_loss = 2.26260024, grad/param norm = 2.4344e-01, time/batch = 0.7232s	
1154/30300 (epoch 1.904), train_loss = 2.17868964, grad/param norm = 2.6691e-01, time/batch = 0.7172s	
1155/30300 (epoch 1.906), train_loss = 2.23223444, grad/param norm = 2.4512e-01, time/batch = 0.7044s	
1156/30300 (epoch 1.908), train_loss = 2.20072167, grad/param norm = 2.5910e-01, time/batch = 0.7004s	
1157/30300 (epoch 1.909), train_loss = 2.31267187, grad/param norm = 2.5934e-01, time/batch = 0.6902s	
1158/30300 (epoch 1.911), train_loss = 2.11261546, grad/param norm = 2.5647e-01, time/batch = 0.6864s	
1159/30300 (epoch 1.913), train_loss = 2.17413665, grad/param norm = 2.2928e-01, time/batch = 0.6863s	
1160/30300 (epoch 1.914), train_loss = 2.27327424, grad/param norm = 2.8376e-01, time/batch = 0.6879s	
1161/30300 (epoch 1.916), train_loss = 2.20779584, grad/param norm = 2.9115e-01, time/batch = 0.6889s	
1162/30300 (epoch 1.917), train_loss = 2.14350449, grad/param norm = 2.7687e-01, time/batch = 0.6964s	
1163/30300 (epoch 1.919), train_loss = 2.24204163, grad/param norm = 2.6080e-01, time/batch = 0.6865s	
1164/30300 (epoch 1.921), train_loss = 2.29923339, grad/param norm = 2.4914e-01, time/batch = 0.6882s	
1165/30300 (epoch 1.922), train_loss = 2.28458324, grad/param norm = 2.4457e-01, time/batch = 0.6946s	
1166/30300 (epoch 1.924), train_loss = 2.17776278, grad/param norm = 2.8814e-01, time/batch = 0.7126s	
1167/30300 (epoch 1.926), train_loss = 2.18901862, grad/param norm = 3.4942e-01, time/batch = 0.7098s	
1168/30300 (epoch 1.927), train_loss = 2.11771896, grad/param norm = 3.3739e-01, time/batch = 0.6869s	
1169/30300 (epoch 1.929), train_loss = 2.25863923, grad/param norm = 3.7597e-01, time/batch = 0.6857s	
1170/30300 (epoch 1.931), train_loss = 2.29064396, grad/param norm = 3.2777e-01, time/batch = 0.6849s	
1171/30300 (epoch 1.932), train_loss = 2.12932887, grad/param norm = 2.5401e-01, time/batch = 0.6901s	
1172/30300 (epoch 1.934), train_loss = 2.16087989, grad/param norm = 2.6499e-01, time/batch = 0.6865s	
1173/30300 (epoch 1.936), train_loss = 2.14724996, grad/param norm = 2.2926e-01, time/batch = 0.6852s	
1174/30300 (epoch 1.937), train_loss = 2.21285252, grad/param norm = 2.6120e-01, time/batch = 0.6875s	
1175/30300 (epoch 1.939), train_loss = 2.24521975, grad/param norm = 2.5629e-01, time/batch = 0.6834s	
1176/30300 (epoch 1.941), train_loss = 2.23290030, grad/param norm = 2.4649e-01, time/batch = 0.6922s	
1177/30300 (epoch 1.942), train_loss = 2.09118528, grad/param norm = 2.6476e-01, time/batch = 0.6846s	
1178/30300 (epoch 1.944), train_loss = 2.05191334, grad/param norm = 2.5628e-01, time/batch = 0.6881s	
1179/30300 (epoch 1.946), train_loss = 2.36874401, grad/param norm = 2.4669e-01, time/batch = 0.7098s	
1180/30300 (epoch 1.947), train_loss = 2.32697779, grad/param norm = 2.4826e-01, time/batch = 0.7072s	
1181/30300 (epoch 1.949), train_loss = 2.38358287, grad/param norm = 2.2050e-01, time/batch = 0.7224s	
1182/30300 (epoch 1.950), train_loss = 2.30719172, grad/param norm = 2.3208e-01, time/batch = 0.6917s	
1183/30300 (epoch 1.952), train_loss = 2.31464088, grad/param norm = 2.8402e-01, time/batch = 0.7057s	
1184/30300 (epoch 1.954), train_loss = 2.32124463, grad/param norm = 2.4351e-01, time/batch = 0.6890s	
1185/30300 (epoch 1.955), train_loss = 2.16996441, grad/param norm = 2.6751e-01, time/batch = 0.6910s	
1186/30300 (epoch 1.957), train_loss = 2.28403355, grad/param norm = 2.8665e-01, time/batch = 0.7143s	
1187/30300 (epoch 1.959), train_loss = 2.27087416, grad/param norm = 2.4239e-01, time/batch = 0.6892s	
1188/30300 (epoch 1.960), train_loss = 2.13780989, grad/param norm = 2.1730e-01, time/batch = 0.6935s	
1189/30300 (epoch 1.962), train_loss = 2.14456487, grad/param norm = 2.5782e-01, time/batch = 0.6939s	
1190/30300 (epoch 1.964), train_loss = 2.29272834, grad/param norm = 3.3583e-01, time/batch = 0.6891s	
1191/30300 (epoch 1.965), train_loss = 2.15068767, grad/param norm = 2.7213e-01, time/batch = 0.6901s	
1192/30300 (epoch 1.967), train_loss = 2.23983918, grad/param norm = 2.8692e-01, time/batch = 0.6901s	
1193/30300 (epoch 1.969), train_loss = 2.12795655, grad/param norm = 2.5005e-01, time/batch = 0.6894s	
1194/30300 (epoch 1.970), train_loss = 2.17998854, grad/param norm = 3.1129e-01, time/batch = 0.6905s	
1195/30300 (epoch 1.972), train_loss = 2.08124297, grad/param norm = 2.6212e-01, time/batch = 0.6897s	
1196/30300 (epoch 1.974), train_loss = 2.32644160, grad/param norm = 2.9618e-01, time/batch = 0.6896s	
1197/30300 (epoch 1.975), train_loss = 2.31780594, grad/param norm = 2.5702e-01, time/batch = 0.6909s	
1198/30300 (epoch 1.977), train_loss = 2.15966652, grad/param norm = 2.3810e-01, time/batch = 0.6944s	
1199/30300 (epoch 1.979), train_loss = 2.29288423, grad/param norm = 2.5509e-01, time/batch = 0.7195s	
1200/30300 (epoch 1.980), train_loss = 2.25877253, grad/param norm = 2.4712e-01, time/batch = 0.7133s	
1201/30300 (epoch 1.982), train_loss = 2.24507990, grad/param norm = 2.1675e-01, time/batch = 0.7033s	
1202/30300 (epoch 1.983), train_loss = 2.29055080, grad/param norm = 2.9902e-01, time/batch = 0.6906s	
1203/30300 (epoch 1.985), train_loss = 2.26511307, grad/param norm = 3.7497e-01, time/batch = 0.6890s	
1204/30300 (epoch 1.987), train_loss = 2.09417866, grad/param norm = 2.6666e-01, time/batch = 0.6891s	
1205/30300 (epoch 1.988), train_loss = 2.34484318, grad/param norm = 2.5609e-01, time/batch = 0.6889s	
1206/30300 (epoch 1.990), train_loss = 2.00183026, grad/param norm = 1.9740e-01, time/batch = 0.6877s	
1207/30300 (epoch 1.992), train_loss = 2.17576541, grad/param norm = 2.1843e-01, time/batch = 0.6869s	
1208/30300 (epoch 1.993), train_loss = 2.36470970, grad/param norm = 2.6594e-01, time/batch = 0.6903s	
1209/30300 (epoch 1.995), train_loss = 2.29748357, grad/param norm = 2.5127e-01, time/batch = 0.6897s	
1210/30300 (epoch 1.997), train_loss = 2.20547187, grad/param norm = 2.3073e-01, time/batch = 0.6876s	
1211/30300 (epoch 1.998), train_loss = 2.22770926, grad/param norm = 2.4650e-01, time/batch = 0.7013s	
1212/30300 (epoch 2.000), train_loss = 2.08752385, grad/param norm = 2.5045e-01, time/batch = 0.6898s	
1213/30300 (epoch 2.002), train_loss = 2.10801996, grad/param norm = 2.2376e-01, time/batch = 0.7023s	
1214/30300 (epoch 2.003), train_loss = 2.21861891, grad/param norm = 2.2823e-01, time/batch = 0.7184s	
1215/30300 (epoch 2.005), train_loss = 2.24274430, grad/param norm = 2.7140e-01, time/batch = 0.6887s	
1216/30300 (epoch 2.007), train_loss = 2.26199627, grad/param norm = 2.1921e-01, time/batch = 0.6864s	
1217/30300 (epoch 2.008), train_loss = 2.12056337, grad/param norm = 2.3015e-01, time/batch = 0.6846s	
1218/30300 (epoch 2.010), train_loss = 2.19955105, grad/param norm = 2.5159e-01, time/batch = 0.6868s	
1219/30300 (epoch 2.012), train_loss = 2.10798076, grad/param norm = 2.2676e-01, time/batch = 0.6885s	
1220/30300 (epoch 2.013), train_loss = 2.27071861, grad/param norm = 2.3086e-01, time/batch = 0.7050s	
1221/30300 (epoch 2.015), train_loss = 2.20224321, grad/param norm = 2.8004e-01, time/batch = 0.7046s	
1222/30300 (epoch 2.017), train_loss = 2.04501643, grad/param norm = 3.5359e-01, time/batch = 0.7109s	
1223/30300 (epoch 2.018), train_loss = 2.25754069, grad/param norm = 2.6688e-01, time/batch = 0.7177s	
1224/30300 (epoch 2.020), train_loss = 2.34866946, grad/param norm = 2.9436e-01, time/batch = 0.7068s	
1225/30300 (epoch 2.021), train_loss = 2.26854683, grad/param norm = 3.2208e-01, time/batch = 0.7009s	
1226/30300 (epoch 2.023), train_loss = 2.11208309, grad/param norm = 3.1119e-01, time/batch = 0.7130s	
1227/30300 (epoch 2.025), train_loss = 2.12257333, grad/param norm = 2.5911e-01, time/batch = 0.7087s	
1228/30300 (epoch 2.026), train_loss = 2.16201108, grad/param norm = 2.3270e-01, time/batch = 0.7218s	
1229/30300 (epoch 2.028), train_loss = 2.17432887, grad/param norm = 2.5287e-01, time/batch = 0.7045s	
1230/30300 (epoch 2.030), train_loss = 2.02238467, grad/param norm = 2.4073e-01, time/batch = 0.6933s	
1231/30300 (epoch 2.031), train_loss = 2.13473752, grad/param norm = 2.6837e-01, time/batch = 0.6873s	
1232/30300 (epoch 2.033), train_loss = 2.17568357, grad/param norm = 2.8994e-01, time/batch = 0.6920s	
1233/30300 (epoch 2.035), train_loss = 2.21404532, grad/param norm = 2.5455e-01, time/batch = 0.6905s	
1234/30300 (epoch 2.036), train_loss = 2.37488426, grad/param norm = 2.7173e-01, time/batch = 0.7016s	
1235/30300 (epoch 2.038), train_loss = 2.22166215, grad/param norm = 2.3984e-01, time/batch = 0.6972s	
1236/30300 (epoch 2.040), train_loss = 1.83752677, grad/param norm = 2.0364e-01, time/batch = 0.6897s	
1237/30300 (epoch 2.041), train_loss = 2.03056096, grad/param norm = 2.4152e-01, time/batch = 0.6867s	
1238/30300 (epoch 2.043), train_loss = 2.20217395, grad/param norm = 2.3265e-01, time/batch = 0.6898s	
1239/30300 (epoch 2.045), train_loss = 2.07948925, grad/param norm = 2.4422e-01, time/batch = 0.6905s	
1240/30300 (epoch 2.046), train_loss = 2.12858590, grad/param norm = 2.3367e-01, time/batch = 0.6879s	
1241/30300 (epoch 2.048), train_loss = 2.16414727, grad/param norm = 2.7352e-01, time/batch = 0.6882s	
1242/30300 (epoch 2.050), train_loss = 2.32420125, grad/param norm = 2.5918e-01, time/batch = 0.7189s	
1243/30300 (epoch 2.051), train_loss = 2.16029829, grad/param norm = 2.3466e-01, time/batch = 0.7042s	
1244/30300 (epoch 2.053), train_loss = 2.05664857, grad/param norm = 2.7990e-01, time/batch = 0.6898s	
1245/30300 (epoch 2.054), train_loss = 2.05542350, grad/param norm = 3.0484e-01, time/batch = 0.6874s	
1246/30300 (epoch 2.056), train_loss = 2.07829572, grad/param norm = 2.5034e-01, time/batch = 0.6866s	
1247/30300 (epoch 2.058), train_loss = 2.24511477, grad/param norm = 2.7678e-01, time/batch = 0.6860s	
1248/30300 (epoch 2.059), train_loss = 2.22955725, grad/param norm = 2.6517e-01, time/batch = 0.6881s	
1249/30300 (epoch 2.061), train_loss = 2.25554434, grad/param norm = 3.0968e-01, time/batch = 0.6875s	
1250/30300 (epoch 2.063), train_loss = 2.12444363, grad/param norm = 2.5591e-01, time/batch = 0.6851s	
1251/30300 (epoch 2.064), train_loss = 2.26261657, grad/param norm = 2.6010e-01, time/batch = 0.6864s	
1252/30300 (epoch 2.066), train_loss = 2.17876125, grad/param norm = 2.4890e-01, time/batch = 0.6841s	
1253/30300 (epoch 2.068), train_loss = 2.01507933, grad/param norm = 2.1936e-01, time/batch = 0.6883s	
1254/30300 (epoch 2.069), train_loss = 2.26399549, grad/param norm = 2.4112e-01, time/batch = 0.6871s	
1255/30300 (epoch 2.071), train_loss = 2.21801206, grad/param norm = 2.6021e-01, time/batch = 0.6877s	
1256/30300 (epoch 2.073), train_loss = 2.31814367, grad/param norm = 2.9043e-01, time/batch = 0.7017s	
1257/30300 (epoch 2.074), train_loss = 2.25507601, grad/param norm = 2.5649e-01, time/batch = 0.7169s	
1258/30300 (epoch 2.076), train_loss = 2.09688165, grad/param norm = 2.8356e-01, time/batch = 0.6844s	
1259/30300 (epoch 2.078), train_loss = 1.98763546, grad/param norm = 2.7165e-01, time/batch = 0.6857s	
1260/30300 (epoch 2.079), train_loss = 1.95797637, grad/param norm = 2.1070e-01, time/batch = 0.6854s	
1261/30300 (epoch 2.081), train_loss = 2.33302530, grad/param norm = 2.4119e-01, time/batch = 0.6891s	
1262/30300 (epoch 2.083), train_loss = 2.40701830, grad/param norm = 2.4738e-01, time/batch = 0.6885s	
1263/30300 (epoch 2.084), train_loss = 2.10860894, grad/param norm = 2.6128e-01, time/batch = 0.6897s	
1264/30300 (epoch 2.086), train_loss = 2.17390672, grad/param norm = 2.5071e-01, time/batch = 0.6909s	
1265/30300 (epoch 2.087), train_loss = 2.05244713, grad/param norm = 2.2329e-01, time/batch = 0.7096s	
1266/30300 (epoch 2.089), train_loss = 2.17354585, grad/param norm = 2.6472e-01, time/batch = 0.7179s	
1267/30300 (epoch 2.091), train_loss = 2.24134254, grad/param norm = 2.5970e-01, time/batch = 0.7128s	
1268/30300 (epoch 2.092), train_loss = 2.04965576, grad/param norm = 2.5684e-01, time/batch = 0.6984s	
1269/30300 (epoch 2.094), train_loss = 2.36616510, grad/param norm = 2.4134e-01, time/batch = 0.6862s	
1270/30300 (epoch 2.096), train_loss = 2.14842598, grad/param norm = 3.6224e-01, time/batch = 0.6911s	
1271/30300 (epoch 2.097), train_loss = 2.10794920, grad/param norm = 2.9486e-01, time/batch = 0.7220s	
1272/30300 (epoch 2.099), train_loss = 2.37510159, grad/param norm = 3.5467e-01, time/batch = 0.7210s	
1273/30300 (epoch 2.101), train_loss = 2.33869517, grad/param norm = 2.3945e-01, time/batch = 0.6981s	
1274/30300 (epoch 2.102), train_loss = 2.27226559, grad/param norm = 2.5141e-01, time/batch = 0.6912s	
1275/30300 (epoch 2.104), train_loss = 2.04236218, grad/param norm = 2.2289e-01, time/batch = 0.6908s	
1276/30300 (epoch 2.106), train_loss = 2.30045124, grad/param norm = 3.5958e-01, time/batch = 0.6933s	
1277/30300 (epoch 2.107), train_loss = 2.13638388, grad/param norm = 2.3200e-01, time/batch = 0.6915s	
1278/30300 (epoch 2.109), train_loss = 2.24485914, grad/param norm = 2.7059e-01, time/batch = 0.6878s	
1279/30300 (epoch 2.111), train_loss = 2.18904814, grad/param norm = 2.6737e-01, time/batch = 0.6901s	
1280/30300 (epoch 2.112), train_loss = 2.19047071, grad/param norm = 2.9063e-01, time/batch = 0.6881s	
1281/30300 (epoch 2.114), train_loss = 2.08560318, grad/param norm = 2.4286e-01, time/batch = 0.7021s	
1282/30300 (epoch 2.116), train_loss = 2.17631169, grad/param norm = 2.4788e-01, time/batch = 0.6968s	
1283/30300 (epoch 2.117), train_loss = 2.08696397, grad/param norm = 2.2103e-01, time/batch = 0.6909s	
1284/30300 (epoch 2.119), train_loss = 1.99270848, grad/param norm = 2.6327e-01, time/batch = 0.6941s	
1285/30300 (epoch 2.120), train_loss = 2.05146461, grad/param norm = 2.7532e-01, time/batch = 0.7204s	
1286/30300 (epoch 2.122), train_loss = 2.22790459, grad/param norm = 2.3867e-01, time/batch = 0.7000s	
1287/30300 (epoch 2.124), train_loss = 2.27798031, grad/param norm = 2.4230e-01, time/batch = 0.6886s	
1288/30300 (epoch 2.125), train_loss = 1.99558043, grad/param norm = 2.4851e-01, time/batch = 0.6871s	
1289/30300 (epoch 2.127), train_loss = 2.18236233, grad/param norm = 2.5134e-01, time/batch = 0.6896s	
1290/30300 (epoch 2.129), train_loss = 2.25370701, grad/param norm = 2.2333e-01, time/batch = 0.6905s	
1291/30300 (epoch 2.130), train_loss = 2.25161650, grad/param norm = 2.3805e-01, time/batch = 0.6926s	
1292/30300 (epoch 2.132), train_loss = 2.13094237, grad/param norm = 2.9132e-01, time/batch = 0.6983s	
1293/30300 (epoch 2.134), train_loss = 2.02860034, grad/param norm = 2.9587e-01, time/batch = 0.6904s	
1294/30300 (epoch 2.135), train_loss = 2.17731982, grad/param norm = 2.3661e-01, time/batch = 0.7011s	
1295/30300 (epoch 2.137), train_loss = 2.26677053, grad/param norm = 2.4727e-01, time/batch = 0.6891s	
1296/30300 (epoch 2.139), train_loss = 2.14095583, grad/param norm = 2.8346e-01, time/batch = 0.6922s	
1297/30300 (epoch 2.140), train_loss = 2.61390206, grad/param norm = 5.0728e-01, time/batch = 0.6922s	
1298/30300 (epoch 2.142), train_loss = 2.34394147, grad/param norm = 2.7726e-01, time/batch = 0.6883s	
1299/30300 (epoch 2.144), train_loss = 2.22413510, grad/param norm = 2.6732e-01, time/batch = 0.7046s	
1300/30300 (epoch 2.145), train_loss = 2.30497508, grad/param norm = 2.3743e-01, time/batch = 0.7144s	
1301/30300 (epoch 2.147), train_loss = 2.24766745, grad/param norm = 2.5913e-01, time/batch = 0.7024s	
1302/30300 (epoch 2.149), train_loss = 2.33138345, grad/param norm = 2.6100e-01, time/batch = 0.6899s	
1303/30300 (epoch 2.150), train_loss = 2.33281079, grad/param norm = 2.0745e-01, time/batch = 0.6884s	
1304/30300 (epoch 2.152), train_loss = 2.16895636, grad/param norm = 2.9935e-01, time/batch = 0.6901s	
1305/30300 (epoch 2.153), train_loss = 2.22781037, grad/param norm = 2.5915e-01, time/batch = 0.6908s	
1306/30300 (epoch 2.155), train_loss = 1.98308738, grad/param norm = 2.1824e-01, time/batch = 0.6871s	
1307/30300 (epoch 2.157), train_loss = 2.18097173, grad/param norm = 2.2026e-01, time/batch = 0.6910s	
1308/30300 (epoch 2.158), train_loss = 2.24673753, grad/param norm = 2.2247e-01, time/batch = 0.6879s	
1309/30300 (epoch 2.160), train_loss = 2.07312169, grad/param norm = 2.7734e-01, time/batch = 0.6857s	
1310/30300 (epoch 2.162), train_loss = 2.05873539, grad/param norm = 3.1064e-01, time/batch = 0.6881s	
1311/30300 (epoch 2.163), train_loss = 2.05358236, grad/param norm = 2.7875e-01, time/batch = 0.7004s	
1312/30300 (epoch 2.165), train_loss = 2.19995117, grad/param norm = 2.9143e-01, time/batch = 0.6883s	
1313/30300 (epoch 2.167), train_loss = 2.21757167, grad/param norm = 2.5870e-01, time/batch = 0.6942s	
1314/30300 (epoch 2.168), train_loss = 2.05653867, grad/param norm = 2.7146e-01, time/batch = 0.7205s	
1315/30300 (epoch 2.170), train_loss = 2.21438948, grad/param norm = 2.5779e-01, time/batch = 0.6997s	
1316/30300 (epoch 2.172), train_loss = 2.08417349, grad/param norm = 2.0875e-01, time/batch = 0.6852s	
1317/30300 (epoch 2.173), train_loss = 2.24092221, grad/param norm = 2.6342e-01, time/batch = 0.6863s	
1318/30300 (epoch 2.175), train_loss = 2.15202799, grad/param norm = 2.7417e-01, time/batch = 0.6974s	
1319/30300 (epoch 2.177), train_loss = 2.23190688, grad/param norm = 2.3242e-01, time/batch = 0.7093s	
1320/30300 (epoch 2.178), train_loss = 1.97115813, grad/param norm = 2.2214e-01, time/batch = 0.6964s	
1321/30300 (epoch 2.180), train_loss = 2.09203645, grad/param norm = 2.3059e-01, time/batch = 0.6946s	
1322/30300 (epoch 2.182), train_loss = 2.09123969, grad/param norm = 2.2546e-01, time/batch = 0.6870s	
1323/30300 (epoch 2.183), train_loss = 2.03983539, grad/param norm = 2.3296e-01, time/batch = 0.6884s	
1324/30300 (epoch 2.185), train_loss = 2.47895015, grad/param norm = 2.4897e-01, time/batch = 0.6861s	
1325/30300 (epoch 2.186), train_loss = 2.30044482, grad/param norm = 2.4997e-01, time/batch = 0.6868s	
1326/30300 (epoch 2.188), train_loss = 2.16197864, grad/param norm = 2.4140e-01, time/batch = 0.6850s	
1327/30300 (epoch 2.190), train_loss = 2.03266358, grad/param norm = 2.2381e-01, time/batch = 0.6855s	
1328/30300 (epoch 2.191), train_loss = 2.23585516, grad/param norm = 2.3223e-01, time/batch = 0.7148s	
1329/30300 (epoch 2.193), train_loss = 2.04934942, grad/param norm = 2.4932e-01, time/batch = 0.7042s	
1330/30300 (epoch 2.195), train_loss = 2.19513286, grad/param norm = 2.8696e-01, time/batch = 0.6884s	
1331/30300 (epoch 2.196), train_loss = 2.29088945, grad/param norm = 3.0915e-01, time/batch = 0.6885s	
1332/30300 (epoch 2.198), train_loss = 1.90350859, grad/param norm = 2.4450e-01, time/batch = 0.6887s	
1333/30300 (epoch 2.200), train_loss = 2.13779935, grad/param norm = 3.0043e-01, time/batch = 0.6901s	
1334/30300 (epoch 2.201), train_loss = 2.30654508, grad/param norm = 2.4479e-01, time/batch = 0.6866s	
1335/30300 (epoch 2.203), train_loss = 2.14897041, grad/param norm = 2.2325e-01, time/batch = 0.6902s	
1336/30300 (epoch 2.205), train_loss = 2.33902778, grad/param norm = 2.2174e-01, time/batch = 0.6873s	
1337/30300 (epoch 2.206), train_loss = 2.34409685, grad/param norm = 2.5087e-01, time/batch = 0.6903s	
1338/30300 (epoch 2.208), train_loss = 2.34170951, grad/param norm = 2.6163e-01, time/batch = 0.6946s	
1339/30300 (epoch 2.210), train_loss = 2.17305786, grad/param norm = 2.4084e-01, time/batch = 0.6882s	
1340/30300 (epoch 2.211), train_loss = 2.15963287, grad/param norm = 2.1921e-01, time/batch = 0.6883s	
1341/30300 (epoch 2.213), train_loss = 2.15016496, grad/param norm = 2.5233e-01, time/batch = 0.6863s	
1342/30300 (epoch 2.215), train_loss = 1.94692946, grad/param norm = 2.1530e-01, time/batch = 0.6871s	
1343/30300 (epoch 2.216), train_loss = 2.19075886, grad/param norm = 2.6494e-01, time/batch = 0.6872s	
1344/30300 (epoch 2.218), train_loss = 2.11880620, grad/param norm = 2.6237e-01, time/batch = 0.6849s	
1345/30300 (epoch 2.219), train_loss = 2.01676772, grad/param norm = 2.6151e-01, time/batch = 0.6849s	
1346/30300 (epoch 2.221), train_loss = 1.99511988, grad/param norm = 2.3776e-01, time/batch = 0.6886s	
1347/30300 (epoch 2.223), train_loss = 2.05231287, grad/param norm = 2.1592e-01, time/batch = 0.6859s	
1348/30300 (epoch 2.224), train_loss = 1.88752525, grad/param norm = 2.0685e-01, time/batch = 0.6868s	
1349/30300 (epoch 2.226), train_loss = 2.20342955, grad/param norm = 2.4267e-01, time/batch = 0.6891s	
1350/30300 (epoch 2.228), train_loss = 2.13458691, grad/param norm = 2.6387e-01, time/batch = 0.6849s	
1351/30300 (epoch 2.229), train_loss = 1.99519995, grad/param norm = 2.6505e-01, time/batch = 0.7139s	
1352/30300 (epoch 2.231), train_loss = 2.12754137, grad/param norm = 2.8753e-01, time/batch = 0.7021s	
1353/30300 (epoch 2.233), train_loss = 2.02709969, grad/param norm = 2.0400e-01, time/batch = 0.7012s	
1354/30300 (epoch 2.234), train_loss = 2.19242140, grad/param norm = 2.3464e-01, time/batch = 0.6929s	
1355/30300 (epoch 2.236), train_loss = 2.10305639, grad/param norm = 2.9077e-01, time/batch = 0.6910s	
1356/30300 (epoch 2.238), train_loss = 2.25524007, grad/param norm = 3.3847e-01, time/batch = 0.6961s	
1357/30300 (epoch 2.239), train_loss = 2.09620289, grad/param norm = 2.7684e-01, time/batch = 0.7205s	
1358/30300 (epoch 2.241), train_loss = 2.09508787, grad/param norm = 2.3104e-01, time/batch = 0.6979s	
1359/30300 (epoch 2.243), train_loss = 2.09874479, grad/param norm = 2.5153e-01, time/batch = 0.6914s	
1360/30300 (epoch 2.244), train_loss = 2.40767844, grad/param norm = 2.7310e-01, time/batch = 0.7032s	
1361/30300 (epoch 2.246), train_loss = 2.07796991, grad/param norm = 2.3393e-01, time/batch = 0.6973s	
1362/30300 (epoch 2.248), train_loss = 2.22395930, grad/param norm = 2.0839e-01, time/batch = 0.6923s	
1363/30300 (epoch 2.249), train_loss = 1.95062740, grad/param norm = 2.4573e-01, time/batch = 0.6927s	
1364/30300 (epoch 2.251), train_loss = 2.02922179, grad/param norm = 2.3557e-01, time/batch = 0.6891s	
1365/30300 (epoch 2.252), train_loss = 2.29474391, grad/param norm = 2.5246e-01, time/batch = 0.6901s	
1366/30300 (epoch 2.254), train_loss = 2.15257526, grad/param norm = 2.1007e-01, time/batch = 0.6937s	
1367/30300 (epoch 2.256), train_loss = 2.15660933, grad/param norm = 2.3379e-01, time/batch = 0.6908s	
1368/30300 (epoch 2.257), train_loss = 2.28229360, grad/param norm = 2.1275e-01, time/batch = 0.6884s	
1369/30300 (epoch 2.259), train_loss = 2.18272398, grad/param norm = 2.4817e-01, time/batch = 0.6881s	
1370/30300 (epoch 2.261), train_loss = 2.29825785, grad/param norm = 2.3682e-01, time/batch = 0.6931s	
1371/30300 (epoch 2.262), train_loss = 2.08881969, grad/param norm = 2.1436e-01, time/batch = 0.6945s	
1372/30300 (epoch 2.264), train_loss = 2.14575335, grad/param norm = 2.4975e-01, time/batch = 0.7044s	
1373/30300 (epoch 2.266), train_loss = 2.05295215, grad/param norm = 2.1816e-01, time/batch = 0.6903s	
1374/30300 (epoch 2.267), train_loss = 2.24612169, grad/param norm = 2.5071e-01, time/batch = 0.6946s	
1375/30300 (epoch 2.269), train_loss = 2.18628280, grad/param norm = 2.3402e-01, time/batch = 0.6876s	
1376/30300 (epoch 2.271), train_loss = 2.15006741, grad/param norm = 2.6560e-01, time/batch = 0.6867s	
1377/30300 (epoch 2.272), train_loss = 2.16703830, grad/param norm = 2.2028e-01, time/batch = 0.6910s	
1378/30300 (epoch 2.274), train_loss = 2.26853877, grad/param norm = 2.3361e-01, time/batch = 0.6923s	
1379/30300 (epoch 2.276), train_loss = 2.28754483, grad/param norm = 2.7733e-01, time/batch = 0.6988s	
1380/30300 (epoch 2.277), train_loss = 2.07003636, grad/param norm = 2.6073e-01, time/batch = 0.6911s	
1381/30300 (epoch 2.279), train_loss = 2.15110933, grad/param norm = 2.2055e-01, time/batch = 0.6922s	
1382/30300 (epoch 2.281), train_loss = 2.15342606, grad/param norm = 2.5092e-01, time/batch = 0.6851s	
1383/30300 (epoch 2.282), train_loss = 2.05934410, grad/param norm = 2.8327e-01, time/batch = 0.6905s	
1384/30300 (epoch 2.284), train_loss = 2.33505273, grad/param norm = 2.6203e-01, time/batch = 0.6958s	
1385/30300 (epoch 2.285), train_loss = 2.20517065, grad/param norm = 2.1907e-01, time/batch = 0.7046s	
1386/30300 (epoch 2.287), train_loss = 2.22194616, grad/param norm = 2.4952e-01, time/batch = 0.7204s	
1387/30300 (epoch 2.289), train_loss = 2.11843225, grad/param norm = 2.6495e-01, time/batch = 0.6871s	
1388/30300 (epoch 2.290), train_loss = 1.85641271, grad/param norm = 2.1638e-01, time/batch = 0.6900s	
1389/30300 (epoch 2.292), train_loss = 2.00843876, grad/param norm = 2.3018e-01, time/batch = 0.6874s	
1390/30300 (epoch 2.294), train_loss = 2.29535046, grad/param norm = 2.4451e-01, time/batch = 0.6892s	
1391/30300 (epoch 2.295), train_loss = 2.09033568, grad/param norm = 2.7436e-01, time/batch = 0.6916s	
1392/30300 (epoch 2.297), train_loss = 2.06229483, grad/param norm = 2.4033e-01, time/batch = 0.6894s	
1393/30300 (epoch 2.299), train_loss = 2.20198169, grad/param norm = 2.5987e-01, time/batch = 0.6961s	
1394/30300 (epoch 2.300), train_loss = 2.08723824, grad/param norm = 2.1113e-01, time/batch = 0.6944s	
1395/30300 (epoch 2.302), train_loss = 2.00308316, grad/param norm = 2.3360e-01, time/batch = 0.6922s	
1396/30300 (epoch 2.304), train_loss = 2.02460222, grad/param norm = 2.3535e-01, time/batch = 0.6902s	
1397/30300 (epoch 2.305), train_loss = 2.10431435, grad/param norm = 2.2100e-01, time/batch = 0.6962s	
1398/30300 (epoch 2.307), train_loss = 2.06906300, grad/param norm = 2.5555e-01, time/batch = 0.6928s	
1399/30300 (epoch 2.309), train_loss = 2.26586778, grad/param norm = 2.4445e-01, time/batch = 0.6913s	
1400/30300 (epoch 2.310), train_loss = 2.01613126, grad/param norm = 2.3806e-01, time/batch = 0.6933s	
1401/30300 (epoch 2.312), train_loss = 2.11339515, grad/param norm = 2.9968e-01, time/batch = 0.6875s	
1402/30300 (epoch 2.314), train_loss = 2.13644265, grad/param norm = 2.5632e-01, time/batch = 0.6939s	
1403/30300 (epoch 2.315), train_loss = 2.16140439, grad/param norm = 2.3469e-01, time/batch = 0.6964s	
1404/30300 (epoch 2.317), train_loss = 2.15043008, grad/param norm = 2.1627e-01, time/batch = 0.6939s	
1405/30300 (epoch 2.318), train_loss = 2.35716481, grad/param norm = 2.4577e-01, time/batch = 0.6934s	
1406/30300 (epoch 2.320), train_loss = 2.18085010, grad/param norm = 2.7024e-01, time/batch = 0.6915s	
1407/30300 (epoch 2.322), train_loss = 1.98604120, grad/param norm = 2.4004e-01, time/batch = 0.6916s	
1408/30300 (epoch 2.323), train_loss = 2.16254765, grad/param norm = 2.2717e-01, time/batch = 0.7006s	
1409/30300 (epoch 2.325), train_loss = 2.01768083, grad/param norm = 2.3713e-01, time/batch = 0.6986s	
1410/30300 (epoch 2.327), train_loss = 1.98441047, grad/param norm = 2.4804e-01, time/batch = 0.6917s	
1411/30300 (epoch 2.328), train_loss = 2.00960626, grad/param norm = 2.3445e-01, time/batch = 0.6905s	
1412/30300 (epoch 2.330), train_loss = 2.18135262, grad/param norm = 2.2682e-01, time/batch = 0.6871s	
1413/30300 (epoch 2.332), train_loss = 2.27525218, grad/param norm = 2.6028e-01, time/batch = 0.6901s	
1414/30300 (epoch 2.333), train_loss = 2.15478307, grad/param norm = 2.8914e-01, time/batch = 0.6843s	
1415/30300 (epoch 2.335), train_loss = 1.92466141, grad/param norm = 2.9447e-01, time/batch = 0.6866s	
1416/30300 (epoch 2.337), train_loss = 2.32494165, grad/param norm = 2.4984e-01, time/batch = 0.6862s	
1417/30300 (epoch 2.338), train_loss = 2.05974530, grad/param norm = 2.8928e-01, time/batch = 0.6865s	
1418/30300 (epoch 2.340), train_loss = 2.13763505, grad/param norm = 2.5985e-01, time/batch = 0.6855s	
1419/30300 (epoch 2.342), train_loss = 2.08513248, grad/param norm = 2.4169e-01, time/batch = 0.7040s	
1420/30300 (epoch 2.343), train_loss = 2.10506651, grad/param norm = 2.5499e-01, time/batch = 0.6933s	
1421/30300 (epoch 2.345), train_loss = 2.11502442, grad/param norm = 2.3949e-01, time/batch = 0.6934s	
1422/30300 (epoch 2.347), train_loss = 1.90378321, grad/param norm = 2.0896e-01, time/batch = 0.6942s	
1423/30300 (epoch 2.348), train_loss = 1.98302777, grad/param norm = 2.3677e-01, time/batch = 0.6908s	
1424/30300 (epoch 2.350), train_loss = 2.08999680, grad/param norm = 2.4851e-01, time/batch = 0.6899s	
1425/30300 (epoch 2.351), train_loss = 2.07297249, grad/param norm = 2.4782e-01, time/batch = 0.6869s	
1426/30300 (epoch 2.353), train_loss = 1.87954982, grad/param norm = 2.9364e-01, time/batch = 0.6905s	
1427/30300 (epoch 2.355), train_loss = 2.14802296, grad/param norm = 2.2496e-01, time/batch = 0.6986s	
1428/30300 (epoch 2.356), train_loss = 2.19177366, grad/param norm = 2.0843e-01, time/batch = 0.6913s	
1429/30300 (epoch 2.358), train_loss = 2.25248320, grad/param norm = 2.5105e-01, time/batch = 0.6932s	
1430/30300 (epoch 2.360), train_loss = 2.01743343, grad/param norm = 2.1253e-01, time/batch = 0.6945s	
1431/30300 (epoch 2.361), train_loss = 2.13963784, grad/param norm = 2.1643e-01, time/batch = 0.6936s	
1432/30300 (epoch 2.363), train_loss = 2.20464236, grad/param norm = 2.3588e-01, time/batch = 0.6922s	
1433/30300 (epoch 2.365), train_loss = 2.06388882, grad/param norm = 2.8140e-01, time/batch = 0.7195s	
1434/30300 (epoch 2.366), train_loss = 2.04707317, grad/param norm = 2.4383e-01, time/batch = 0.7078s	
1435/30300 (epoch 2.368), train_loss = 1.90070859, grad/param norm = 2.3775e-01, time/batch = 0.6968s	
1436/30300 (epoch 2.370), train_loss = 2.10267518, grad/param norm = 2.2118e-01, time/batch = 0.6934s	
1437/30300 (epoch 2.371), train_loss = 2.09110603, grad/param norm = 2.1756e-01, time/batch = 0.7084s	
1438/30300 (epoch 2.373), train_loss = 2.08215066, grad/param norm = 2.3635e-01, time/batch = 0.6971s	
1439/30300 (epoch 2.375), train_loss = 1.99496455, grad/param norm = 2.1922e-01, time/batch = 0.7072s	
1440/30300 (epoch 2.376), train_loss = 2.04884347, grad/param norm = 2.2567e-01, time/batch = 0.7167s	
1441/30300 (epoch 2.378), train_loss = 2.02657358, grad/param norm = 2.1716e-01, time/batch = 0.6965s	
1442/30300 (epoch 2.380), train_loss = 2.26510799, grad/param norm = 2.2277e-01, time/batch = 0.7007s	
1443/30300 (epoch 2.381), train_loss = 2.11271698, grad/param norm = 2.0736e-01, time/batch = 0.7116s	
1444/30300 (epoch 2.383), train_loss = 2.21062179, grad/param norm = 2.6645e-01, time/batch = 0.7060s	
1445/30300 (epoch 2.384), train_loss = 2.27171230, grad/param norm = 2.3439e-01, time/batch = 0.6929s	
1446/30300 (epoch 2.386), train_loss = 2.01209660, grad/param norm = 2.4585e-01, time/batch = 0.6921s	
1447/30300 (epoch 2.388), train_loss = 2.11306605, grad/param norm = 2.3384e-01, time/batch = 0.6904s	
1448/30300 (epoch 2.389), train_loss = 2.09245554, grad/param norm = 2.5669e-01, time/batch = 0.6888s	
1449/30300 (epoch 2.391), train_loss = 2.14786192, grad/param norm = 2.1814e-01, time/batch = 0.7115s	
1450/30300 (epoch 2.393), train_loss = 1.97621672, grad/param norm = 2.2156e-01, time/batch = 0.6929s	
1451/30300 (epoch 2.394), train_loss = 2.06294488, grad/param norm = 2.1326e-01, time/batch = 0.6879s	
1452/30300 (epoch 2.396), train_loss = 2.15875589, grad/param norm = 2.2752e-01, time/batch = 0.6921s	
1453/30300 (epoch 2.398), train_loss = 2.04379414, grad/param norm = 2.3089e-01, time/batch = 0.6945s	
1454/30300 (epoch 2.399), train_loss = 1.98276672, grad/param norm = 2.0668e-01, time/batch = 0.7042s	
1455/30300 (epoch 2.401), train_loss = 2.19005795, grad/param norm = 2.6328e-01, time/batch = 0.6937s	
1456/30300 (epoch 2.403), train_loss = 2.12671663, grad/param norm = 3.3697e-01, time/batch = 0.6944s	
1457/30300 (epoch 2.404), train_loss = 2.09413644, grad/param norm = 2.7495e-01, time/batch = 0.6999s	
1458/30300 (epoch 2.406), train_loss = 2.12115378, grad/param norm = 2.9348e-01, time/batch = 0.6862s	
1459/30300 (epoch 2.408), train_loss = 2.02559625, grad/param norm = 2.1955e-01, time/batch = 0.6852s	
1460/30300 (epoch 2.409), train_loss = 1.84885760, grad/param norm = 2.5549e-01, time/batch = 0.6893s	
1461/30300 (epoch 2.411), train_loss = 1.98434908, grad/param norm = 2.6537e-01, time/batch = 0.6991s	
1462/30300 (epoch 2.413), train_loss = 1.91860003, grad/param norm = 2.1430e-01, time/batch = 0.7200s	
1463/30300 (epoch 2.414), train_loss = 2.21263278, grad/param norm = 2.1126e-01, time/batch = 0.6893s	
1464/30300 (epoch 2.416), train_loss = 2.10495276, grad/param norm = 2.4486e-01, time/batch = 0.6839s	
1465/30300 (epoch 2.417), train_loss = 1.95231414, grad/param norm = 1.9172e-01, time/batch = 0.6822s	
1466/30300 (epoch 2.419), train_loss = 1.88495864, grad/param norm = 2.6088e-01, time/batch = 0.6854s	
1467/30300 (epoch 2.421), train_loss = 1.95762962, grad/param norm = 2.4561e-01, time/batch = 0.6845s	
1468/30300 (epoch 2.422), train_loss = 1.99292142, grad/param norm = 2.3618e-01, time/batch = 0.6868s	
1469/30300 (epoch 2.424), train_loss = 2.16871448, grad/param norm = 2.3884e-01, time/batch = 0.6842s	
1470/30300 (epoch 2.426), train_loss = 1.84887171, grad/param norm = 2.4237e-01, time/batch = 0.6882s	
1471/30300 (epoch 2.427), train_loss = 2.00564031, grad/param norm = 2.3445e-01, time/batch = 0.6859s	
1472/30300 (epoch 2.429), train_loss = 2.11189183, grad/param norm = 2.9426e-01, time/batch = 0.6871s	
1473/30300 (epoch 2.431), train_loss = 2.16846539, grad/param norm = 3.1687e-01, time/batch = 0.6850s	
1474/30300 (epoch 2.432), train_loss = 2.07164295, grad/param norm = 2.4337e-01, time/batch = 0.6838s	
1475/30300 (epoch 2.434), train_loss = 1.99419744, grad/param norm = 2.1905e-01, time/batch = 0.6859s	
1476/30300 (epoch 2.436), train_loss = 2.07481553, grad/param norm = 2.3225e-01, time/batch = 0.6875s	
1477/30300 (epoch 2.437), train_loss = 2.09711579, grad/param norm = 2.3587e-01, time/batch = 0.6893s	
1478/30300 (epoch 2.439), train_loss = 2.00231981, grad/param norm = 2.5018e-01, time/batch = 0.6865s	
1479/30300 (epoch 2.441), train_loss = 1.95789239, grad/param norm = 2.4767e-01, time/batch = 0.6853s	
1480/30300 (epoch 2.442), train_loss = 1.90701087, grad/param norm = 2.5297e-01, time/batch = 0.6859s	
1481/30300 (epoch 2.444), train_loss = 1.97450164, grad/param norm = 2.4810e-01, time/batch = 0.6865s	
1482/30300 (epoch 2.446), train_loss = 1.94976250, grad/param norm = 2.3801e-01, time/batch = 0.6961s	
1483/30300 (epoch 2.447), train_loss = 2.08997701, grad/param norm = 2.6536e-01, time/batch = 0.6857s	
1484/30300 (epoch 2.449), train_loss = 2.01102121, grad/param norm = 2.4454e-01, time/batch = 0.6838s	
1485/30300 (epoch 2.450), train_loss = 2.21752408, grad/param norm = 3.2197e-01, time/batch = 0.6844s	
1486/30300 (epoch 2.452), train_loss = 1.98737140, grad/param norm = 1.9395e-01, time/batch = 0.6847s	
1487/30300 (epoch 2.454), train_loss = 1.99670869, grad/param norm = 2.3080e-01, time/batch = 0.6849s	
1488/30300 (epoch 2.455), train_loss = 2.25408835, grad/param norm = 2.5106e-01, time/batch = 0.6877s	
1489/30300 (epoch 2.457), train_loss = 2.12224554, grad/param norm = 2.2554e-01, time/batch = 0.6986s	
1490/30300 (epoch 2.459), train_loss = 2.09065558, grad/param norm = 2.4187e-01, time/batch = 0.6858s	
1491/30300 (epoch 2.460), train_loss = 2.08030198, grad/param norm = 2.3227e-01, time/batch = 0.6894s	
1492/30300 (epoch 2.462), train_loss = 2.13671229, grad/param norm = 2.4758e-01, time/batch = 0.6884s	
1493/30300 (epoch 2.464), train_loss = 2.09880014, grad/param norm = 2.3195e-01, time/batch = 0.6871s	
1494/30300 (epoch 2.465), train_loss = 1.92766066, grad/param norm = 2.3788e-01, time/batch = 0.6868s	
1495/30300 (epoch 2.467), train_loss = 1.79222078, grad/param norm = 2.0799e-01, time/batch = 0.6881s	
1496/30300 (epoch 2.469), train_loss = 1.99059773, grad/param norm = 2.3979e-01, time/batch = 0.6857s	
1497/30300 (epoch 2.470), train_loss = 1.98912569, grad/param norm = 2.2019e-01, time/batch = 0.6885s	
1498/30300 (epoch 2.472), train_loss = 1.91960012, grad/param norm = 2.7035e-01, time/batch = 0.6845s	
1499/30300 (epoch 2.474), train_loss = 2.07665460, grad/param norm = 3.0749e-01, time/batch = 0.6844s	
1500/30300 (epoch 2.475), train_loss = 2.04311083, grad/param norm = 2.2838e-01, time/batch = 0.6843s	
1501/30300 (epoch 2.477), train_loss = 2.06225451, grad/param norm = 2.3406e-01, time/batch = 0.6890s	
1502/30300 (epoch 2.479), train_loss = 2.17673684, grad/param norm = 2.6497e-01, time/batch = 0.6877s	
1503/30300 (epoch 2.480), train_loss = 1.97839503, grad/param norm = 2.1520e-01, time/batch = 0.6876s	
1504/30300 (epoch 2.482), train_loss = 2.13106752, grad/param norm = 2.8993e-01, time/batch = 0.6883s	
1505/30300 (epoch 2.483), train_loss = 2.11862523, grad/param norm = 2.8300e-01, time/batch = 0.7128s	
1506/30300 (epoch 2.485), train_loss = 2.02270670, grad/param norm = 2.5147e-01, time/batch = 0.6902s	
1507/30300 (epoch 2.487), train_loss = 2.16251716, grad/param norm = 2.4126e-01, time/batch = 0.6893s	
1508/30300 (epoch 2.488), train_loss = 1.96705859, grad/param norm = 2.0888e-01, time/batch = 0.6898s	
1509/30300 (epoch 2.490), train_loss = 1.89697725, grad/param norm = 2.5524e-01, time/batch = 0.6871s	
1510/30300 (epoch 2.492), train_loss = 2.08166513, grad/param norm = 2.1438e-01, time/batch = 0.6865s	
1511/30300 (epoch 2.493), train_loss = 1.94518676, grad/param norm = 2.4119e-01, time/batch = 0.6863s	
1512/30300 (epoch 2.495), train_loss = 2.03978745, grad/param norm = 2.1735e-01, time/batch = 0.6890s	
1513/30300 (epoch 2.497), train_loss = 2.03655183, grad/param norm = 2.4008e-01, time/batch = 0.6873s	
1514/30300 (epoch 2.498), train_loss = 2.07696553, grad/param norm = 2.5502e-01, time/batch = 0.6865s	
1515/30300 (epoch 2.500), train_loss = 2.23327267, grad/param norm = 2.4400e-01, time/batch = 0.6870s	
1516/30300 (epoch 2.502), train_loss = 1.94697158, grad/param norm = 2.4629e-01, time/batch = 0.6856s	
1517/30300 (epoch 2.503), train_loss = 2.07534039, grad/param norm = 2.3920e-01, time/batch = 0.6855s	
1518/30300 (epoch 2.505), train_loss = 2.10286801, grad/param norm = 2.5694e-01, time/batch = 0.6866s	
1519/30300 (epoch 2.507), train_loss = 2.05562997, grad/param norm = 2.3428e-01, time/batch = 0.7039s	
1520/30300 (epoch 2.508), train_loss = 2.21257502, grad/param norm = 2.4024e-01, time/batch = 0.7160s	
1521/30300 (epoch 2.510), train_loss = 2.12336283, grad/param norm = 2.4079e-01, time/batch = 0.6875s	
1522/30300 (epoch 2.512), train_loss = 1.93161697, grad/param norm = 2.0629e-01, time/batch = 0.6861s	
1523/30300 (epoch 2.513), train_loss = 2.05976597, grad/param norm = 2.4370e-01, time/batch = 0.6974s	
1524/30300 (epoch 2.515), train_loss = 2.00387183, grad/param norm = 2.5902e-01, time/batch = 0.7107s	
1525/30300 (epoch 2.517), train_loss = 1.89571069, grad/param norm = 2.2899e-01, time/batch = 0.6937s	
1526/30300 (epoch 2.518), train_loss = 2.15783861, grad/param norm = 2.4293e-01, time/batch = 0.6894s	
1527/30300 (epoch 2.520), train_loss = 2.32391346, grad/param norm = 2.5998e-01, time/batch = 0.6904s	
1528/30300 (epoch 2.521), train_loss = 2.02077075, grad/param norm = 2.4879e-01, time/batch = 0.6901s	
1529/30300 (epoch 2.523), train_loss = 2.17522296, grad/param norm = 2.3182e-01, time/batch = 0.6908s	
1530/30300 (epoch 2.525), train_loss = 2.09426726, grad/param norm = 2.2926e-01, time/batch = 0.6856s	
1531/30300 (epoch 2.526), train_loss = 2.01036103, grad/param norm = 2.1644e-01, time/batch = 0.6881s	
1532/30300 (epoch 2.528), train_loss = 1.89306634, grad/param norm = 2.2118e-01, time/batch = 0.6894s	
1533/30300 (epoch 2.530), train_loss = 1.96982646, grad/param norm = 2.4533e-01, time/batch = 0.6957s	
1534/30300 (epoch 2.531), train_loss = 2.10300647, grad/param norm = 2.3904e-01, time/batch = 0.7282s	
1535/30300 (epoch 2.533), train_loss = 2.10263464, grad/param norm = 1.9877e-01, time/batch = 0.7089s	
1536/30300 (epoch 2.535), train_loss = 1.89225733, grad/param norm = 2.1044e-01, time/batch = 0.6889s	
1537/30300 (epoch 2.536), train_loss = 2.06632958, grad/param norm = 2.3132e-01, time/batch = 0.6880s	
1538/30300 (epoch 2.538), train_loss = 1.84211415, grad/param norm = 2.1496e-01, time/batch = 0.6927s	
1539/30300 (epoch 2.540), train_loss = 2.09092706, grad/param norm = 2.2783e-01, time/batch = 0.6878s	
1540/30300 (epoch 2.541), train_loss = 1.98364059, grad/param norm = 2.1492e-01, time/batch = 0.6920s	
1541/30300 (epoch 2.543), train_loss = 2.03613077, grad/param norm = 2.1532e-01, time/batch = 0.6977s	
1542/30300 (epoch 2.545), train_loss = 2.19469487, grad/param norm = 2.9526e-01, time/batch = 0.6922s	
1543/30300 (epoch 2.546), train_loss = 2.24644294, grad/param norm = 3.0964e-01, time/batch = 0.6894s	
1544/30300 (epoch 2.548), train_loss = 1.98458024, grad/param norm = 3.5533e-01, time/batch = 0.6909s	
1545/30300 (epoch 2.550), train_loss = 2.24910310, grad/param norm = 2.2556e-01, time/batch = 0.6869s	
1546/30300 (epoch 2.551), train_loss = 2.02712076, grad/param norm = 2.3081e-01, time/batch = 0.6898s	
1547/30300 (epoch 2.553), train_loss = 1.99156158, grad/param norm = 2.1323e-01, time/batch = 0.6892s	
1548/30300 (epoch 2.554), train_loss = 2.21275357, grad/param norm = 2.2759e-01, time/batch = 0.7166s	
1549/30300 (epoch 2.556), train_loss = 2.07476282, grad/param norm = 2.0970e-01, time/batch = 0.7072s	
1550/30300 (epoch 2.558), train_loss = 2.17134519, grad/param norm = 2.1846e-01, time/batch = 0.6912s	
1551/30300 (epoch 2.559), train_loss = 2.01637595, grad/param norm = 2.2974e-01, time/batch = 0.6896s	
1552/30300 (epoch 2.561), train_loss = 1.95328291, grad/param norm = 2.1712e-01, time/batch = 0.6975s	
1553/30300 (epoch 2.563), train_loss = 2.13372416, grad/param norm = 2.3363e-01, time/batch = 0.7098s	
1554/30300 (epoch 2.564), train_loss = 2.06737008, grad/param norm = 2.2062e-01, time/batch = 0.7186s	
1555/30300 (epoch 2.566), train_loss = 2.16650608, grad/param norm = 3.0901e-01, time/batch = 0.7118s	
1556/30300 (epoch 2.568), train_loss = 1.92355276, grad/param norm = 2.8038e-01, time/batch = 0.7111s	
1557/30300 (epoch 2.569), train_loss = 2.03588616, grad/param norm = 2.7988e-01, time/batch = 0.6935s	
1558/30300 (epoch 2.571), train_loss = 2.13520744, grad/param norm = 2.5506e-01, time/batch = 0.6879s	
1559/30300 (epoch 2.573), train_loss = 2.09174842, grad/param norm = 2.2314e-01, time/batch = 0.6863s	
1560/30300 (epoch 2.574), train_loss = 2.06144409, grad/param norm = 2.2903e-01, time/batch = 0.6905s	
1561/30300 (epoch 2.576), train_loss = 2.09480661, grad/param norm = 2.3515e-01, time/batch = 0.6934s	
1562/30300 (epoch 2.578), train_loss = 1.94284967, grad/param norm = 1.9600e-01, time/batch = 0.7091s	
1563/30300 (epoch 2.579), train_loss = 1.97775629, grad/param norm = 2.4120e-01, time/batch = 0.7135s	
1564/30300 (epoch 2.581), train_loss = 2.14990969, grad/param norm = 2.6805e-01, time/batch = 0.6894s	
1565/30300 (epoch 2.583), train_loss = 2.21863732, grad/param norm = 2.5288e-01, time/batch = 0.6897s	
1566/30300 (epoch 2.584), train_loss = 2.19966451, grad/param norm = 2.1084e-01, time/batch = 0.6895s	
1567/30300 (epoch 2.586), train_loss = 2.08111442, grad/param norm = 2.3378e-01, time/batch = 0.6921s	
1568/30300 (epoch 2.587), train_loss = 2.04355806, grad/param norm = 2.2493e-01, time/batch = 0.6935s	
1569/30300 (epoch 2.589), train_loss = 1.73940003, grad/param norm = 2.0448e-01, time/batch = 0.6922s	
1570/30300 (epoch 2.591), train_loss = 2.06023482, grad/param norm = 2.4358e-01, time/batch = 0.6883s	
1571/30300 (epoch 2.592), train_loss = 2.02055617, grad/param norm = 2.1885e-01, time/batch = 0.6940s	
1572/30300 (epoch 2.594), train_loss = 2.09285706, grad/param norm = 2.5952e-01, time/batch = 0.6901s	
1573/30300 (epoch 2.596), train_loss = 1.93783371, grad/param norm = 2.6416e-01, time/batch = 0.6913s	
1574/30300 (epoch 2.597), train_loss = 2.03052377, grad/param norm = 2.5263e-01, time/batch = 0.6885s	
1575/30300 (epoch 2.599), train_loss = 1.81638420, grad/param norm = 2.3202e-01, time/batch = 0.6927s	
1576/30300 (epoch 2.601), train_loss = 2.04741689, grad/param norm = 2.2563e-01, time/batch = 0.6992s	
1577/30300 (epoch 2.602), train_loss = 1.99672328, grad/param norm = 2.0367e-01, time/batch = 0.7231s	
1578/30300 (epoch 2.604), train_loss = 1.97970545, grad/param norm = 2.5114e-01, time/batch = 0.6947s	
1579/30300 (epoch 2.606), train_loss = 2.33980467, grad/param norm = 3.0812e-01, time/batch = 0.6900s	
1580/30300 (epoch 2.607), train_loss = 2.18476525, grad/param norm = 2.4292e-01, time/batch = 0.6906s	
1581/30300 (epoch 2.609), train_loss = 2.32779320, grad/param norm = 2.5390e-01, time/batch = 0.6866s	
1582/30300 (epoch 2.611), train_loss = 1.85281118, grad/param norm = 2.0688e-01, time/batch = 0.6882s	
1583/30300 (epoch 2.612), train_loss = 2.02132942, grad/param norm = 2.3746e-01, time/batch = 0.6992s	
1584/30300 (epoch 2.614), train_loss = 1.87445743, grad/param norm = 2.2325e-01, time/batch = 0.7013s	
1585/30300 (epoch 2.616), train_loss = 2.09698509, grad/param norm = 2.4374e-01, time/batch = 0.6926s	
1586/30300 (epoch 2.617), train_loss = 2.05387560, grad/param norm = 2.3652e-01, time/batch = 0.6931s	
1587/30300 (epoch 2.619), train_loss = 1.85193601, grad/param norm = 2.1206e-01, time/batch = 0.6916s	
1588/30300 (epoch 2.620), train_loss = 2.12438045, grad/param norm = 2.2849e-01, time/batch = 0.6907s	
1589/30300 (epoch 2.622), train_loss = 1.95846177, grad/param norm = 2.3612e-01, time/batch = 0.6882s	
1590/30300 (epoch 2.624), train_loss = 1.94156993, grad/param norm = 2.3158e-01, time/batch = 0.6883s	
1591/30300 (epoch 2.625), train_loss = 1.96940313, grad/param norm = 2.4559e-01, time/batch = 0.6886s	
1592/30300 (epoch 2.627), train_loss = 2.19706244, grad/param norm = 2.3321e-01, time/batch = 0.6881s	
1593/30300 (epoch 2.629), train_loss = 2.10311431, grad/param norm = 2.3186e-01, time/batch = 0.6892s	
1594/30300 (epoch 2.630), train_loss = 2.07915697, grad/param norm = 2.0850e-01, time/batch = 0.6883s	
1595/30300 (epoch 2.632), train_loss = 2.06770651, grad/param norm = 3.2103e-01, time/batch = 0.6853s	
1596/30300 (epoch 2.634), train_loss = 1.81954945, grad/param norm = 2.6374e-01, time/batch = 0.6855s	
1597/30300 (epoch 2.635), train_loss = 2.09798996, grad/param norm = 2.2249e-01, time/batch = 0.6875s	
1598/30300 (epoch 2.637), train_loss = 2.01525685, grad/param norm = 2.6627e-01, time/batch = 0.6917s	
1599/30300 (epoch 2.639), train_loss = 1.91501804, grad/param norm = 2.6109e-01, time/batch = 0.6879s	
1600/30300 (epoch 2.640), train_loss = 2.09298673, grad/param norm = 2.4753e-01, time/batch = 0.6877s	
1601/30300 (epoch 2.642), train_loss = 2.04263483, grad/param norm = 2.1756e-01, time/batch = 0.6875s	
1602/30300 (epoch 2.644), train_loss = 2.06351432, grad/param norm = 2.2663e-01, time/batch = 0.6874s	
1603/30300 (epoch 2.645), train_loss = 1.99361912, grad/param norm = 2.2920e-01, time/batch = 0.6885s	
1604/30300 (epoch 2.647), train_loss = 2.03468044, grad/param norm = 2.5858e-01, time/batch = 0.6874s	
1605/30300 (epoch 2.649), train_loss = 2.02400436, grad/param norm = 2.0743e-01, time/batch = 0.7038s	
1606/30300 (epoch 2.650), train_loss = 2.03201368, grad/param norm = 2.1739e-01, time/batch = 0.7194s	
1607/30300 (epoch 2.652), train_loss = 1.88790585, grad/param norm = 2.2614e-01, time/batch = 0.6981s	
1608/30300 (epoch 2.653), train_loss = 2.20399487, grad/param norm = 2.5636e-01, time/batch = 0.6985s	
1609/30300 (epoch 2.655), train_loss = 2.02746999, grad/param norm = 2.1958e-01, time/batch = 0.6979s	
1610/30300 (epoch 2.657), train_loss = 2.12990652, grad/param norm = 2.2822e-01, time/batch = 0.7102s	
1611/30300 (epoch 2.658), train_loss = 1.96403664, grad/param norm = 2.3195e-01, time/batch = 0.6934s	
1612/30300 (epoch 2.660), train_loss = 2.06210259, grad/param norm = 2.1354e-01, time/batch = 0.7082s	
1613/30300 (epoch 2.662), train_loss = 2.04867229, grad/param norm = 2.1388e-01, time/batch = 0.7001s	
1614/30300 (epoch 2.663), train_loss = 2.03581575, grad/param norm = 2.2228e-01, time/batch = 0.6905s	
1615/30300 (epoch 2.665), train_loss = 1.83712464, grad/param norm = 1.9480e-01, time/batch = 0.6928s	
1616/30300 (epoch 2.667), train_loss = 2.14816492, grad/param norm = 2.3642e-01, time/batch = 0.6901s	
1617/30300 (epoch 2.668), train_loss = 2.20757318, grad/param norm = 2.4570e-01, time/batch = 0.6903s	
1618/30300 (epoch 2.670), train_loss = 2.05983755, grad/param norm = 2.3848e-01, time/batch = 0.6896s	
1619/30300 (epoch 2.672), train_loss = 2.11338654, grad/param norm = 2.2086e-01, time/batch = 0.6918s	
1620/30300 (epoch 2.673), train_loss = 2.04013318, grad/param norm = 2.2686e-01, time/batch = 0.6870s	
1621/30300 (epoch 2.675), train_loss = 1.93582609, grad/param norm = 2.3100e-01, time/batch = 0.6929s	
1622/30300 (epoch 2.677), train_loss = 1.96916316, grad/param norm = 2.4027e-01, time/batch = 0.6921s	
1623/30300 (epoch 2.678), train_loss = 1.99267735, grad/param norm = 2.2011e-01, time/batch = 0.6874s	
1624/30300 (epoch 2.680), train_loss = 1.75739890, grad/param norm = 2.1889e-01, time/batch = 0.6962s	
1625/30300 (epoch 2.682), train_loss = 1.98885167, grad/param norm = 2.2593e-01, time/batch = 0.7045s	
1626/30300 (epoch 2.683), train_loss = 2.10145085, grad/param norm = 2.2989e-01, time/batch = 0.6974s	
1627/30300 (epoch 2.685), train_loss = 2.16630191, grad/param norm = 2.3689e-01, time/batch = 0.6921s	
1628/30300 (epoch 2.686), train_loss = 2.04382145, grad/param norm = 2.1292e-01, time/batch = 0.6931s	
1629/30300 (epoch 2.688), train_loss = 2.06804283, grad/param norm = 2.3521e-01, time/batch = 0.6900s	
1630/30300 (epoch 2.690), train_loss = 2.00734904, grad/param norm = 2.8617e-01, time/batch = 0.6919s	
1631/30300 (epoch 2.691), train_loss = 2.06672231, grad/param norm = 3.5013e-01, time/batch = 0.6935s	
1632/30300 (epoch 2.693), train_loss = 2.40034897, grad/param norm = 3.0742e-01, time/batch = 0.6980s	
1633/30300 (epoch 2.695), train_loss = 2.18216628, grad/param norm = 2.5018e-01, time/batch = 0.7134s	
1634/30300 (epoch 2.696), train_loss = 2.26523417, grad/param norm = 2.9185e-01, time/batch = 0.7138s	
1635/30300 (epoch 2.698), train_loss = 1.97567135, grad/param norm = 2.3756e-01, time/batch = 0.7145s	
1636/30300 (epoch 2.700), train_loss = 2.00162565, grad/param norm = 2.2772e-01, time/batch = 0.7037s	
1637/30300 (epoch 2.701), train_loss = 1.78901655, grad/param norm = 2.1537e-01, time/batch = 0.7101s	
1638/30300 (epoch 2.703), train_loss = 1.91881251, grad/param norm = 1.9076e-01, time/batch = 0.7003s	
1639/30300 (epoch 2.705), train_loss = 2.06398927, grad/param norm = 2.5011e-01, time/batch = 0.7035s	
1640/30300 (epoch 2.706), train_loss = 1.93022197, grad/param norm = 2.0924e-01, time/batch = 0.7070s	
1641/30300 (epoch 2.708), train_loss = 2.02191407, grad/param norm = 2.3681e-01, time/batch = 0.7064s	
1642/30300 (epoch 2.710), train_loss = 1.94203740, grad/param norm = 2.3609e-01, time/batch = 0.7075s	
1643/30300 (epoch 2.711), train_loss = 1.90150958, grad/param norm = 2.0133e-01, time/batch = 0.7037s	
1644/30300 (epoch 2.713), train_loss = 1.80012974, grad/param norm = 2.0742e-01, time/batch = 0.7204s	
1645/30300 (epoch 2.715), train_loss = 2.01292483, grad/param norm = 2.3092e-01, time/batch = 0.7007s	
1646/30300 (epoch 2.716), train_loss = 2.18243720, grad/param norm = 2.3007e-01, time/batch = 0.6893s	
1647/30300 (epoch 2.718), train_loss = 2.14673393, grad/param norm = 2.2783e-01, time/batch = 0.6954s	
1648/30300 (epoch 2.719), train_loss = 1.97871604, grad/param norm = 2.2233e-01, time/batch = 0.6931s	
1649/30300 (epoch 2.721), train_loss = 2.01392429, grad/param norm = 2.1156e-01, time/batch = 0.6893s	
1650/30300 (epoch 2.723), train_loss = 1.94237247, grad/param norm = 2.2020e-01, time/batch = 0.6928s	
1651/30300 (epoch 2.724), train_loss = 2.04687415, grad/param norm = 2.4635e-01, time/batch = 0.7129s	
1652/30300 (epoch 2.726), train_loss = 2.42453527, grad/param norm = 2.6580e-01, time/batch = 0.7014s	
1653/30300 (epoch 2.728), train_loss = 1.93678588, grad/param norm = 2.3151e-01, time/batch = 0.6956s	
1654/30300 (epoch 2.729), train_loss = 2.05099596, grad/param norm = 2.7853e-01, time/batch = 0.6917s	
1655/30300 (epoch 2.731), train_loss = 2.08786591, grad/param norm = 2.1982e-01, time/batch = 0.6867s	
1656/30300 (epoch 2.733), train_loss = 1.97863968, grad/param norm = 1.9919e-01, time/batch = 0.6888s	
1657/30300 (epoch 2.734), train_loss = 2.01235150, grad/param norm = 1.9522e-01, time/batch = 0.6880s	
1658/30300 (epoch 2.736), train_loss = 2.00700555, grad/param norm = 2.3799e-01, time/batch = 0.7101s	
1659/30300 (epoch 2.738), train_loss = 1.85019584, grad/param norm = 1.8997e-01, time/batch = 0.7090s	
1660/30300 (epoch 2.739), train_loss = 2.13943253, grad/param norm = 2.3751e-01, time/batch = 0.6959s	
1661/30300 (epoch 2.741), train_loss = 2.10373991, grad/param norm = 2.2461e-01, time/batch = 0.7158s	
1662/30300 (epoch 2.743), train_loss = 1.86931532, grad/param norm = 2.1565e-01, time/batch = 0.7147s	
1663/30300 (epoch 2.744), train_loss = 2.14344404, grad/param norm = 2.4172e-01, time/batch = 0.7070s	
1664/30300 (epoch 2.746), train_loss = 1.86180150, grad/param norm = 2.4532e-01, time/batch = 0.7135s	
1665/30300 (epoch 2.748), train_loss = 2.09081361, grad/param norm = 2.9954e-01, time/batch = 0.7119s	
1666/30300 (epoch 2.749), train_loss = 2.02653994, grad/param norm = 2.7365e-01, time/batch = 0.7094s	
1667/30300 (epoch 2.751), train_loss = 1.93872119, grad/param norm = 2.2973e-01, time/batch = 0.6936s	
1668/30300 (epoch 2.752), train_loss = 1.91294011, grad/param norm = 2.2485e-01, time/batch = 0.6909s	
1669/30300 (epoch 2.754), train_loss = 1.79107090, grad/param norm = 1.9839e-01, time/batch = 0.6880s	
1670/30300 (epoch 2.756), train_loss = 1.92745114, grad/param norm = 2.7138e-01, time/batch = 0.6905s	
1671/30300 (epoch 2.757), train_loss = 2.10015471, grad/param norm = 2.3254e-01, time/batch = 0.6880s	
1672/30300 (epoch 2.759), train_loss = 1.87167560, grad/param norm = 2.3525e-01, time/batch = 0.7077s	
1673/30300 (epoch 2.761), train_loss = 1.92534358, grad/param norm = 2.0466e-01, time/batch = 0.7143s	
1674/30300 (epoch 2.762), train_loss = 1.75180828, grad/param norm = 2.0625e-01, time/batch = 0.6862s	
1675/30300 (epoch 2.764), train_loss = 1.91932464, grad/param norm = 2.1758e-01, time/batch = 0.6872s	
1676/30300 (epoch 2.766), train_loss = 2.00951548, grad/param norm = 2.1769e-01, time/batch = 0.6864s	
1677/30300 (epoch 2.767), train_loss = 2.12492576, grad/param norm = 2.4610e-01, time/batch = 0.6847s	
1678/30300 (epoch 2.769), train_loss = 2.19256090, grad/param norm = 2.6023e-01, time/batch = 0.6886s	
1679/30300 (epoch 2.771), train_loss = 2.01198051, grad/param norm = 2.0603e-01, time/batch = 0.6888s	
1680/30300 (epoch 2.772), train_loss = 1.95854845, grad/param norm = 2.2117e-01, time/batch = 0.6894s	
1681/30300 (epoch 2.774), train_loss = 2.06505972, grad/param norm = 2.2254e-01, time/batch = 0.6880s	
1682/30300 (epoch 2.776), train_loss = 1.98047596, grad/param norm = 2.0753e-01, time/batch = 0.6886s	
1683/30300 (epoch 2.777), train_loss = 2.00219478, grad/param norm = 2.2117e-01, time/batch = 0.6895s	
1684/30300 (epoch 2.779), train_loss = 2.07454218, grad/param norm = 2.1280e-01, time/batch = 0.6914s	
1685/30300 (epoch 2.781), train_loss = 1.98085325, grad/param norm = 2.1954e-01, time/batch = 0.6904s	
1686/30300 (epoch 2.782), train_loss = 1.86241338, grad/param norm = 2.0247e-01, time/batch = 0.6945s	
1687/30300 (epoch 2.784), train_loss = 2.08325177, grad/param norm = 2.1231e-01, time/batch = 0.7202s	
1688/30300 (epoch 2.785), train_loss = 2.14742899, grad/param norm = 2.0093e-01, time/batch = 0.6951s	
1689/30300 (epoch 2.787), train_loss = 2.00484733, grad/param norm = 2.1652e-01, time/batch = 0.6860s	
1690/30300 (epoch 2.789), train_loss = 2.36787438, grad/param norm = 2.2670e-01, time/batch = 0.6908s	
1691/30300 (epoch 2.790), train_loss = 2.11795232, grad/param norm = 2.0757e-01, time/batch = 0.6896s	
1692/30300 (epoch 2.792), train_loss = 1.96264267, grad/param norm = 2.3215e-01, time/batch = 0.6917s	
1693/30300 (epoch 2.794), train_loss = 1.89864172, grad/param norm = 2.0993e-01, time/batch = 0.6900s	
1694/30300 (epoch 2.795), train_loss = 1.97217703, grad/param norm = 2.0546e-01, time/batch = 0.6951s	
1695/30300 (epoch 2.797), train_loss = 2.08365083, grad/param norm = 2.3030e-01, time/batch = 0.6982s	
1696/30300 (epoch 2.799), train_loss = 2.15300555, grad/param norm = 3.1236e-01, time/batch = 0.7042s	
1697/30300 (epoch 2.800), train_loss = 2.00360684, grad/param norm = 2.5493e-01, time/batch = 0.7147s	
1698/30300 (epoch 2.802), train_loss = 2.16692768, grad/param norm = 2.5158e-01, time/batch = 0.6979s	
1699/30300 (epoch 2.804), train_loss = 2.07916425, grad/param norm = 2.7316e-01, time/batch = 0.6919s	
1700/30300 (epoch 2.805), train_loss = 2.14838985, grad/param norm = 2.4483e-01, time/batch = 0.6932s	
1701/30300 (epoch 2.807), train_loss = 2.13229943, grad/param norm = 2.6147e-01, time/batch = 0.7168s	
1702/30300 (epoch 2.809), train_loss = 2.19716735, grad/param norm = 2.4385e-01, time/batch = 0.7211s	
1703/30300 (epoch 2.810), train_loss = 2.09005248, grad/param norm = 2.2589e-01, time/batch = 0.7141s	
1704/30300 (epoch 2.812), train_loss = 1.96624626, grad/param norm = 2.2805e-01, time/batch = 0.6962s	
1705/30300 (epoch 2.814), train_loss = 2.09628629, grad/param norm = 2.2265e-01, time/batch = 0.6903s	
1706/30300 (epoch 2.815), train_loss = 2.02777627, grad/param norm = 2.4051e-01, time/batch = 0.6935s	
1707/30300 (epoch 2.817), train_loss = 2.06687159, grad/param norm = 2.4901e-01, time/batch = 0.6964s	
1708/30300 (epoch 2.818), train_loss = 2.00522530, grad/param norm = 2.1999e-01, time/batch = 0.6959s	
1709/30300 (epoch 2.820), train_loss = 2.24579235, grad/param norm = 2.5120e-01, time/batch = 0.6901s	
1710/30300 (epoch 2.822), train_loss = 2.19077462, grad/param norm = 2.4556e-01, time/batch = 0.6900s	
1711/30300 (epoch 2.823), train_loss = 2.27989572, grad/param norm = 2.5360e-01, time/batch = 0.6902s	
1712/30300 (epoch 2.825), train_loss = 2.08464574, grad/param norm = 2.3637e-01, time/batch = 0.6922s	
1713/30300 (epoch 2.827), train_loss = 2.00091607, grad/param norm = 2.1980e-01, time/batch = 0.6925s	
1714/30300 (epoch 2.828), train_loss = 2.03363688, grad/param norm = 1.8890e-01, time/batch = 0.7043s	
1715/30300 (epoch 2.830), train_loss = 2.03245836, grad/param norm = 2.2815e-01, time/batch = 0.7089s	
1716/30300 (epoch 2.832), train_loss = 1.93592433, grad/param norm = 2.1133e-01, time/batch = 0.7044s	
1717/30300 (epoch 2.833), train_loss = 2.09007479, grad/param norm = 2.2034e-01, time/batch = 0.7004s	
1718/30300 (epoch 2.835), train_loss = 2.06468362, grad/param norm = 2.2561e-01, time/batch = 0.6899s	
1719/30300 (epoch 2.837), train_loss = 1.84079307, grad/param norm = 2.0274e-01, time/batch = 0.6921s	
1720/30300 (epoch 2.838), train_loss = 1.91965374, grad/param norm = 1.9406e-01, time/batch = 0.6891s	
1721/30300 (epoch 2.840), train_loss = 1.94774726, grad/param norm = 2.0957e-01, time/batch = 0.6897s	
1722/30300 (epoch 2.842), train_loss = 1.88202126, grad/param norm = 2.4457e-01, time/batch = 0.6912s	
1723/30300 (epoch 2.843), train_loss = 2.02381121, grad/param norm = 2.5767e-01, time/batch = 0.6938s	
1724/30300 (epoch 2.845), train_loss = 1.83834119, grad/param norm = 2.0164e-01, time/batch = 0.6884s	
1725/30300 (epoch 2.847), train_loss = 1.97169159, grad/param norm = 2.3491e-01, time/batch = 0.7078s	
1726/30300 (epoch 2.848), train_loss = 2.15554581, grad/param norm = 2.5588e-01, time/batch = 0.7145s	
1727/30300 (epoch 2.850), train_loss = 1.89450167, grad/param norm = 2.4715e-01, time/batch = 0.6904s	
1728/30300 (epoch 2.851), train_loss = 2.27223936, grad/param norm = 2.4185e-01, time/batch = 0.6902s	
1729/30300 (epoch 2.853), train_loss = 2.01921444, grad/param norm = 2.2645e-01, time/batch = 0.6930s	
1730/30300 (epoch 2.855), train_loss = 1.94365403, grad/param norm = 2.3656e-01, time/batch = 0.6874s	
1731/30300 (epoch 2.856), train_loss = 1.92687118, grad/param norm = 2.2788e-01, time/batch = 0.6889s	
1732/30300 (epoch 2.858), train_loss = 1.86166413, grad/param norm = 2.0464e-01, time/batch = 0.6895s	
1733/30300 (epoch 2.860), train_loss = 2.04344840, grad/param norm = 2.1477e-01, time/batch = 0.6885s	
1734/30300 (epoch 2.861), train_loss = 2.13819963, grad/param norm = 3.0964e-01, time/batch = 0.6912s	
1735/30300 (epoch 2.863), train_loss = 2.07943007, grad/param norm = 2.4720e-01, time/batch = 0.6944s	
1736/30300 (epoch 2.865), train_loss = 2.32393603, grad/param norm = 2.4065e-01, time/batch = 0.6942s	
1737/30300 (epoch 2.866), train_loss = 2.04617933, grad/param norm = 2.4863e-01, time/batch = 0.6929s	
1738/30300 (epoch 2.868), train_loss = 2.07429006, grad/param norm = 2.4923e-01, time/batch = 0.6908s	
1739/30300 (epoch 2.870), train_loss = 1.97546729, grad/param norm = 2.4728e-01, time/batch = 0.6951s	
1740/30300 (epoch 2.871), train_loss = 1.90756598, grad/param norm = 2.0394e-01, time/batch = 0.7206s	
1741/30300 (epoch 2.873), train_loss = 2.09201945, grad/param norm = 2.2834e-01, time/batch = 0.6990s	
1742/30300 (epoch 2.875), train_loss = 1.86928858, grad/param norm = 2.0527e-01, time/batch = 0.6929s	
1743/30300 (epoch 2.876), train_loss = 1.80966831, grad/param norm = 1.9790e-01, time/batch = 0.6930s	
1744/30300 (epoch 2.878), train_loss = 1.80365086, grad/param norm = 2.3181e-01, time/batch = 0.6950s	
1745/30300 (epoch 2.880), train_loss = 1.85234781, grad/param norm = 2.1053e-01, time/batch = 0.6895s	
1746/30300 (epoch 2.881), train_loss = 2.14796798, grad/param norm = 2.2024e-01, time/batch = 0.6920s	
1747/30300 (epoch 2.883), train_loss = 2.02062866, grad/param norm = 2.2167e-01, time/batch = 0.6942s	
1748/30300 (epoch 2.884), train_loss = 1.88767643, grad/param norm = 2.0364e-01, time/batch = 0.6941s	
1749/30300 (epoch 2.886), train_loss = 1.89634068, grad/param norm = 2.3025e-01, time/batch = 0.6898s	
1750/30300 (epoch 2.888), train_loss = 2.07654402, grad/param norm = 2.5250e-01, time/batch = 0.6903s	
1751/30300 (epoch 2.889), train_loss = 2.00706219, grad/param norm = 3.0012e-01, time/batch = 0.6941s	
1752/30300 (epoch 2.891), train_loss = 1.93835814, grad/param norm = 2.5381e-01, time/batch = 0.6919s	
1753/30300 (epoch 2.893), train_loss = 2.13982402, grad/param norm = 2.4977e-01, time/batch = 0.6922s	
1754/30300 (epoch 2.894), train_loss = 2.06158137, grad/param norm = 2.2852e-01, time/batch = 0.6890s	
1755/30300 (epoch 2.896), train_loss = 1.85649747, grad/param norm = 2.5963e-01, time/batch = 0.6897s	
1756/30300 (epoch 2.898), train_loss = 1.81098629, grad/param norm = 2.2333e-01, time/batch = 0.6909s	
1757/30300 (epoch 2.899), train_loss = 1.95324355, grad/param norm = 2.2675e-01, time/batch = 0.6878s	
1758/30300 (epoch 2.901), train_loss = 2.05183112, grad/param norm = 2.2514e-01, time/batch = 0.6905s	
1759/30300 (epoch 2.903), train_loss = 2.07408335, grad/param norm = 2.2733e-01, time/batch = 0.6892s	
1760/30300 (epoch 2.904), train_loss = 1.99378949, grad/param norm = 2.2477e-01, time/batch = 0.6864s	
1761/30300 (epoch 2.906), train_loss = 2.06168742, grad/param norm = 2.2874e-01, time/batch = 0.6903s	
1762/30300 (epoch 2.908), train_loss = 1.95211429, grad/param norm = 2.1049e-01, time/batch = 0.6883s	
1763/30300 (epoch 2.909), train_loss = 2.07181114, grad/param norm = 2.3115e-01, time/batch = 0.6866s	
1764/30300 (epoch 2.911), train_loss = 1.93272264, grad/param norm = 2.6661e-01, time/batch = 0.6873s	
1765/30300 (epoch 2.913), train_loss = 1.99906485, grad/param norm = 1.9783e-01, time/batch = 0.6889s	
1766/30300 (epoch 2.914), train_loss = 2.06021412, grad/param norm = 2.4534e-01, time/batch = 0.6880s	
1767/30300 (epoch 2.916), train_loss = 2.01030431, grad/param norm = 2.2935e-01, time/batch = 0.6879s	
1768/30300 (epoch 2.917), train_loss = 1.93611955, grad/param norm = 2.1749e-01, time/batch = 0.6880s	
1769/30300 (epoch 2.919), train_loss = 2.02623508, grad/param norm = 2.1547e-01, time/batch = 0.6891s	
1770/30300 (epoch 2.921), train_loss = 2.10454129, grad/param norm = 2.3771e-01, time/batch = 0.6872s	
1771/30300 (epoch 2.922), train_loss = 2.10172408, grad/param norm = 2.2195e-01, time/batch = 0.6951s	
1772/30300 (epoch 2.924), train_loss = 1.99346096, grad/param norm = 2.6631e-01, time/batch = 0.6935s	
1773/30300 (epoch 2.926), train_loss = 2.00325598, grad/param norm = 2.8105e-01, time/batch = 0.7208s	
1774/30300 (epoch 2.927), train_loss = 1.94624487, grad/param norm = 2.7976e-01, time/batch = 0.6968s	
1775/30300 (epoch 2.929), train_loss = 2.04598243, grad/param norm = 2.4964e-01, time/batch = 0.6881s	
1776/30300 (epoch 2.931), train_loss = 2.09364316, grad/param norm = 2.4497e-01, time/batch = 0.6923s	
1777/30300 (epoch 2.932), train_loss = 1.92860996, grad/param norm = 2.2898e-01, time/batch = 0.6918s	
1778/30300 (epoch 2.934), train_loss = 1.97010299, grad/param norm = 2.2485e-01, time/batch = 0.6865s	
1779/30300 (epoch 2.936), train_loss = 1.95118524, grad/param norm = 2.1160e-01, time/batch = 0.6881s	
1780/30300 (epoch 2.937), train_loss = 2.01243590, grad/param norm = 2.1142e-01, time/batch = 0.6904s	
1781/30300 (epoch 2.939), train_loss = 2.08333048, grad/param norm = 2.1108e-01, time/batch = 0.7017s	
1782/30300 (epoch 2.941), train_loss = 2.03184758, grad/param norm = 2.1692e-01, time/batch = 0.7025s	
1783/30300 (epoch 2.942), train_loss = 1.91333995, grad/param norm = 2.1352e-01, time/batch = 0.6936s	
1784/30300 (epoch 2.944), train_loss = 1.85022229, grad/param norm = 2.0346e-01, time/batch = 0.6924s	
1785/30300 (epoch 2.946), train_loss = 2.18360590, grad/param norm = 2.2073e-01, time/batch = 0.6896s	
1786/30300 (epoch 2.947), train_loss = 2.16166996, grad/param norm = 2.2732e-01, time/batch = 0.6909s	
1787/30300 (epoch 2.949), train_loss = 2.21348474, grad/param norm = 2.0775e-01, time/batch = 0.7190s	
1788/30300 (epoch 2.950), train_loss = 2.13304794, grad/param norm = 2.2680e-01, time/batch = 0.7087s	
1789/30300 (epoch 2.952), train_loss = 2.13897638, grad/param norm = 2.6179e-01, time/batch = 0.6972s	
1790/30300 (epoch 2.954), train_loss = 2.20347873, grad/param norm = 2.3196e-01, time/batch = 0.7004s	
1791/30300 (epoch 2.955), train_loss = 1.96227413, grad/param norm = 2.3841e-01, time/batch = 0.6896s	
1792/30300 (epoch 2.957), train_loss = 2.05346026, grad/param norm = 2.2900e-01, time/batch = 0.6846s	
1793/30300 (epoch 2.959), train_loss = 2.03269095, grad/param norm = 2.1326e-01, time/batch = 0.6909s	
1794/30300 (epoch 2.960), train_loss = 1.95382936, grad/param norm = 1.9729e-01, time/batch = 0.6928s	
1795/30300 (epoch 2.962), train_loss = 1.93132521, grad/param norm = 2.2038e-01, time/batch = 0.6870s	
1796/30300 (epoch 2.964), train_loss = 2.08236765, grad/param norm = 2.3272e-01, time/batch = 0.6856s	
1797/30300 (epoch 2.965), train_loss = 1.92886007, grad/param norm = 2.0899e-01, time/batch = 0.6859s	
1798/30300 (epoch 2.967), train_loss = 2.05384785, grad/param norm = 2.2649e-01, time/batch = 0.7025s	
1799/30300 (epoch 2.969), train_loss = 1.97346384, grad/param norm = 2.6768e-01, time/batch = 0.6879s	
1800/30300 (epoch 2.970), train_loss = 1.97674303, grad/param norm = 3.1746e-01, time/batch = 0.6931s	
1801/30300 (epoch 2.972), train_loss = 1.87843682, grad/param norm = 1.9922e-01, time/batch = 0.7025s	
1802/30300 (epoch 2.974), train_loss = 2.12465010, grad/param norm = 2.1762e-01, time/batch = 0.7187s	
1803/30300 (epoch 2.975), train_loss = 2.19831413, grad/param norm = 2.3416e-01, time/batch = 0.6958s	
1804/30300 (epoch 2.977), train_loss = 2.02046738, grad/param norm = 2.1725e-01, time/batch = 0.6979s	
1805/30300 (epoch 2.979), train_loss = 2.10374880, grad/param norm = 2.2205e-01, time/batch = 0.6842s	
1806/30300 (epoch 2.980), train_loss = 2.06705422, grad/param norm = 2.2926e-01, time/batch = 0.6830s	
1807/30300 (epoch 2.982), train_loss = 2.06862055, grad/param norm = 2.0599e-01, time/batch = 0.6853s	
1808/30300 (epoch 2.983), train_loss = 2.10579695, grad/param norm = 2.1871e-01, time/batch = 0.6868s	
1809/30300 (epoch 2.985), train_loss = 2.03497939, grad/param norm = 2.5159e-01, time/batch = 0.6893s	
1810/30300 (epoch 2.987), train_loss = 1.90332246, grad/param norm = 1.9788e-01, time/batch = 0.6960s	
1811/30300 (epoch 2.988), train_loss = 2.15767995, grad/param norm = 2.2330e-01, time/batch = 0.6891s	
1812/30300 (epoch 2.990), train_loss = 1.83297376, grad/param norm = 1.8179e-01, time/batch = 0.6902s	
1813/30300 (epoch 2.992), train_loss = 2.01833512, grad/param norm = 2.0638e-01, time/batch = 0.6897s	
1814/30300 (epoch 2.993), train_loss = 2.18563740, grad/param norm = 2.4454e-01, time/batch = 0.6921s	
1815/30300 (epoch 2.995), train_loss = 2.10871800, grad/param norm = 2.2284e-01, time/batch = 0.6920s	
1816/30300 (epoch 2.997), train_loss = 2.04409251, grad/param norm = 2.1446e-01, time/batch = 0.7205s	
1817/30300 (epoch 2.998), train_loss = 2.07542706, grad/param norm = 2.3877e-01, time/batch = 0.7011s	
1818/30300 (epoch 3.000), train_loss = 1.92810820, grad/param norm = 2.2858e-01, time/batch = 0.6969s	
1819/30300 (epoch 3.002), train_loss = 1.93740511, grad/param norm = 1.9908e-01, time/batch = 0.6911s	
1820/30300 (epoch 3.003), train_loss = 2.04498117, grad/param norm = 2.2005e-01, time/batch = 0.6907s	
1821/30300 (epoch 3.005), train_loss = 2.04128937, grad/param norm = 2.3483e-01, time/batch = 0.6906s	
1822/30300 (epoch 3.007), train_loss = 2.10354067, grad/param norm = 2.1178e-01, time/batch = 0.6920s	
1823/30300 (epoch 3.008), train_loss = 1.92366414, grad/param norm = 2.1299e-01, time/batch = 0.6942s	
1824/30300 (epoch 3.010), train_loss = 1.99932888, grad/param norm = 2.3342e-01, time/batch = 0.6885s	
1825/30300 (epoch 3.012), train_loss = 1.92219026, grad/param norm = 1.9906e-01, time/batch = 0.6941s	
1826/30300 (epoch 3.013), train_loss = 2.08659570, grad/param norm = 2.1440e-01, time/batch = 0.6896s	
1827/30300 (epoch 3.015), train_loss = 1.96138266, grad/param norm = 2.2581e-01, time/batch = 0.6888s	
1828/30300 (epoch 3.017), train_loss = 1.83722272, grad/param norm = 2.1448e-01, time/batch = 0.6841s	
1829/30300 (epoch 3.018), train_loss = 2.08783437, grad/param norm = 2.1116e-01, time/batch = 0.7009s	
1830/30300 (epoch 3.020), train_loss = 2.16837131, grad/param norm = 2.2249e-01, time/batch = 0.7161s	
1831/30300 (epoch 3.021), train_loss = 2.10454447, grad/param norm = 2.5551e-01, time/batch = 0.7231s	
1832/30300 (epoch 3.023), train_loss = 1.89847601, grad/param norm = 2.5902e-01, time/batch = 0.7204s	
1833/30300 (epoch 3.025), train_loss = 1.91267965, grad/param norm = 2.2654e-01, time/batch = 0.7202s	
1834/30300 (epoch 3.026), train_loss = 1.96017223, grad/param norm = 2.0226e-01, time/batch = 0.7170s	
1835/30300 (epoch 3.028), train_loss = 1.98595084, grad/param norm = 2.0956e-01, time/batch = 0.7026s	
1836/30300 (epoch 3.030), train_loss = 1.84285222, grad/param norm = 2.2396e-01, time/batch = 0.6944s	
1837/30300 (epoch 3.031), train_loss = 1.97888380, grad/param norm = 2.4005e-01, time/batch = 0.6909s	
1838/30300 (epoch 3.033), train_loss = 1.95568722, grad/param norm = 2.5232e-01, time/batch = 0.6874s	
1839/30300 (epoch 3.035), train_loss = 2.03560890, grad/param norm = 1.9905e-01, time/batch = 0.6888s	
1840/30300 (epoch 3.036), train_loss = 2.16128677, grad/param norm = 2.3754e-01, time/batch = 0.6904s	
1841/30300 (epoch 3.038), train_loss = 2.01761768, grad/param norm = 2.1461e-01, time/batch = 0.6892s	
1842/30300 (epoch 3.040), train_loss = 1.65034329, grad/param norm = 1.9744e-01, time/batch = 0.6876s	
1843/30300 (epoch 3.041), train_loss = 1.77125277, grad/param norm = 2.2060e-01, time/batch = 0.6904s	
1844/30300 (epoch 3.043), train_loss = 2.06339472, grad/param norm = 2.2102e-01, time/batch = 0.6856s	
1845/30300 (epoch 3.045), train_loss = 1.92166456, grad/param norm = 2.4367e-01, time/batch = 0.6899s	
1846/30300 (epoch 3.046), train_loss = 1.99276473, grad/param norm = 2.3575e-01, time/batch = 0.6919s	
1847/30300 (epoch 3.048), train_loss = 2.00169689, grad/param norm = 2.4413e-01, time/batch = 0.6871s	
1848/30300 (epoch 3.050), train_loss = 2.09430786, grad/param norm = 2.1966e-01, time/batch = 0.6890s	
1849/30300 (epoch 3.051), train_loss = 1.98600861, grad/param norm = 2.1663e-01, time/batch = 0.6980s	
1850/30300 (epoch 3.053), train_loss = 1.87360877, grad/param norm = 2.2419e-01, time/batch = 0.7035s	
1851/30300 (epoch 3.054), train_loss = 1.88364668, grad/param norm = 2.5105e-01, time/batch = 0.7002s	
1852/30300 (epoch 3.056), train_loss = 1.87850946, grad/param norm = 2.3189e-01, time/batch = 0.6925s	
1853/30300 (epoch 3.058), train_loss = 2.05315903, grad/param norm = 2.3220e-01, time/batch = 0.6903s	
1854/30300 (epoch 3.059), train_loss = 1.99956921, grad/param norm = 1.9721e-01, time/batch = 0.6891s	
1855/30300 (epoch 3.061), train_loss = 2.13175912, grad/param norm = 2.5544e-01, time/batch = 0.6926s	
1856/30300 (epoch 3.063), train_loss = 1.94012681, grad/param norm = 2.1857e-01, time/batch = 0.6924s	
1857/30300 (epoch 3.064), train_loss = 2.09375180, grad/param norm = 2.0161e-01, time/batch = 0.6907s	
1858/30300 (epoch 3.066), train_loss = 1.96527331, grad/param norm = 1.9863e-01, time/batch = 0.6951s	
1859/30300 (epoch 3.068), train_loss = 1.84269371, grad/param norm = 1.8598e-01, time/batch = 0.7159s	
1860/30300 (epoch 3.069), train_loss = 2.10201134, grad/param norm = 2.0237e-01, time/batch = 0.7218s	
1861/30300 (epoch 3.071), train_loss = 2.05960359, grad/param norm = 2.3118e-01, time/batch = 0.7183s	
1862/30300 (epoch 3.073), train_loss = 2.14892202, grad/param norm = 2.7134e-01, time/batch = 0.7176s	
1863/30300 (epoch 3.074), train_loss = 2.07897041, grad/param norm = 2.2553e-01, time/batch = 0.7159s	
1864/30300 (epoch 3.076), train_loss = 1.91517281, grad/param norm = 2.1752e-01, time/batch = 0.7152s	
1865/30300 (epoch 3.078), train_loss = 1.80848633, grad/param norm = 2.2589e-01, time/batch = 0.7286s	
1866/30300 (epoch 3.079), train_loss = 1.80021757, grad/param norm = 1.8283e-01, time/batch = 0.7282s	
1867/30300 (epoch 3.081), train_loss = 2.13078519, grad/param norm = 2.3516e-01, time/batch = 0.7447s	
1868/30300 (epoch 3.083), train_loss = 2.23010342, grad/param norm = 2.1887e-01, time/batch = 0.7507s	
1869/30300 (epoch 3.084), train_loss = 1.94220267, grad/param norm = 2.2552e-01, time/batch = 0.7402s	
1870/30300 (epoch 3.086), train_loss = 1.99434265, grad/param norm = 2.1197e-01, time/batch = 0.7247s	
1871/30300 (epoch 3.087), train_loss = 1.87707412, grad/param norm = 1.9519e-01, time/batch = 0.7256s	
1872/30300 (epoch 3.089), train_loss = 1.97104794, grad/param norm = 2.1616e-01, time/batch = 0.7242s	
1873/30300 (epoch 3.091), train_loss = 2.06960162, grad/param norm = 2.2307e-01, time/batch = 0.7418s	
1874/30300 (epoch 3.092), train_loss = 1.89566595, grad/param norm = 2.4349e-01, time/batch = 0.7262s	
1875/30300 (epoch 3.094), train_loss = 2.20813789, grad/param norm = 2.1546e-01, time/batch = 0.6867s	
1876/30300 (epoch 3.096), train_loss = 1.96113315, grad/param norm = 2.1622e-01, time/batch = 0.6854s	
1877/30300 (epoch 3.097), train_loss = 1.87615567, grad/param norm = 2.4755e-01, time/batch = 0.6883s	
1878/30300 (epoch 3.099), train_loss = 2.14161228, grad/param norm = 2.1948e-01, time/batch = 0.7035s	
1879/30300 (epoch 3.101), train_loss = 2.16930296, grad/param norm = 1.9642e-01, time/batch = 0.6978s	
1880/30300 (epoch 3.102), train_loss = 2.05516360, grad/param norm = 2.1962e-01, time/batch = 0.6938s	
1881/30300 (epoch 3.104), train_loss = 1.85652351, grad/param norm = 1.8886e-01, time/batch = 0.6885s	
1882/30300 (epoch 3.106), train_loss = 2.07683495, grad/param norm = 2.6054e-01, time/batch = 0.6930s	
1883/30300 (epoch 3.107), train_loss = 1.96984649, grad/param norm = 2.5725e-01, time/batch = 0.6889s	
1884/30300 (epoch 3.109), train_loss = 2.09408376, grad/param norm = 2.3851e-01, time/batch = 0.6885s	
1885/30300 (epoch 3.111), train_loss = 2.05716778, grad/param norm = 2.3541e-01, time/batch = 0.6945s	
1886/30300 (epoch 3.112), train_loss = 2.01061618, grad/param norm = 2.2844e-01, time/batch = 0.6894s	
1887/30300 (epoch 3.114), train_loss = 1.90267511, grad/param norm = 2.0994e-01, time/batch = 0.6923s	
1888/30300 (epoch 3.116), train_loss = 2.02653601, grad/param norm = 2.1507e-01, time/batch = 0.6990s	
1889/30300 (epoch 3.117), train_loss = 1.91599211, grad/param norm = 1.9212e-01, time/batch = 0.7066s	
1890/30300 (epoch 3.119), train_loss = 1.82846576, grad/param norm = 2.2043e-01, time/batch = 0.6943s	
1891/30300 (epoch 3.120), train_loss = 1.91061468, grad/param norm = 2.4801e-01, time/batch = 0.7117s	
1892/30300 (epoch 3.122), train_loss = 2.03359889, grad/param norm = 2.1218e-01, time/batch = 0.6964s	
1893/30300 (epoch 3.124), train_loss = 2.15715063, grad/param norm = 2.6229e-01, time/batch = 0.6942s	
1894/30300 (epoch 3.125), train_loss = 1.81358932, grad/param norm = 2.3913e-01, time/batch = 0.6907s	
1895/30300 (epoch 3.127), train_loss = 1.99183734, grad/param norm = 2.0793e-01, time/batch = 0.6927s	
1896/30300 (epoch 3.129), train_loss = 2.08566968, grad/param norm = 2.0645e-01, time/batch = 0.6931s	
1897/30300 (epoch 3.130), train_loss = 2.11366241, grad/param norm = 2.0910e-01, time/batch = 0.6898s	
1898/30300 (epoch 3.132), train_loss = 1.96784321, grad/param norm = 2.2150e-01, time/batch = 0.6924s	
1899/30300 (epoch 3.134), train_loss = 1.83519872, grad/param norm = 2.3077e-01, time/batch = 0.6937s	
1900/30300 (epoch 3.135), train_loss = 1.97088162, grad/param norm = 2.1196e-01, time/batch = 0.6935s	
1901/30300 (epoch 3.137), train_loss = 2.10647174, grad/param norm = 2.1565e-01, time/batch = 0.7193s	
1902/30300 (epoch 3.139), train_loss = 1.97096163, grad/param norm = 2.2788e-01, time/batch = 0.7055s	
1903/30300 (epoch 3.140), train_loss = 2.27917049, grad/param norm = 5.5694e-01, time/batch = 0.6882s	
1904/30300 (epoch 3.142), train_loss = 2.18229599, grad/param norm = 2.4310e-01, time/batch = 0.6891s	
1905/30300 (epoch 3.144), train_loss = 2.05331878, grad/param norm = 2.2763e-01, time/batch = 0.6945s	
1906/30300 (epoch 3.145), train_loss = 2.12661160, grad/param norm = 1.9828e-01, time/batch = 0.6920s	
1907/30300 (epoch 3.147), train_loss = 2.04675469, grad/param norm = 2.3263e-01, time/batch = 0.6918s	
1908/30300 (epoch 3.149), train_loss = 2.18553347, grad/param norm = 2.2149e-01, time/batch = 0.6941s	
1909/30300 (epoch 3.150), train_loss = 2.16377702, grad/param norm = 1.9127e-01, time/batch = 0.6905s	
1910/30300 (epoch 3.152), train_loss = 1.99002594, grad/param norm = 2.3014e-01, time/batch = 0.6921s	
1911/30300 (epoch 3.153), train_loss = 2.04963421, grad/param norm = 2.3202e-01, time/batch = 0.7056s	
1912/30300 (epoch 3.155), train_loss = 1.78859239, grad/param norm = 2.0190e-01, time/batch = 0.6986s	
1913/30300 (epoch 3.157), train_loss = 1.99300122, grad/param norm = 2.0285e-01, time/batch = 0.6887s	
1914/30300 (epoch 3.158), train_loss = 2.05859649, grad/param norm = 2.1634e-01, time/batch = 0.6911s	
1915/30300 (epoch 3.160), train_loss = 1.88273833, grad/param norm = 2.2560e-01, time/batch = 0.7067s	
1916/30300 (epoch 3.162), train_loss = 1.89278201, grad/param norm = 2.5626e-01, time/batch = 0.7172s	
1917/30300 (epoch 3.163), train_loss = 1.87997797, grad/param norm = 2.4867e-01, time/batch = 0.6939s	
1918/30300 (epoch 3.165), train_loss = 2.01224628, grad/param norm = 2.3715e-01, time/batch = 0.7102s	
1919/30300 (epoch 3.167), train_loss = 2.03266703, grad/param norm = 2.2649e-01, time/batch = 0.6927s	
1920/30300 (epoch 3.168), train_loss = 1.88516288, grad/param norm = 2.3935e-01, time/batch = 0.6920s	
1921/30300 (epoch 3.170), train_loss = 2.01552640, grad/param norm = 2.1831e-01, time/batch = 0.6903s	
1922/30300 (epoch 3.172), train_loss = 1.91562125, grad/param norm = 1.9524e-01, time/batch = 0.6916s	
1923/30300 (epoch 3.173), train_loss = 2.06291108, grad/param norm = 2.0615e-01, time/batch = 0.6929s	
1924/30300 (epoch 3.175), train_loss = 1.95244853, grad/param norm = 2.2765e-01, time/batch = 0.6934s	
1925/30300 (epoch 3.177), train_loss = 2.02998233, grad/param norm = 1.9541e-01, time/batch = 0.6952s	
1926/30300 (epoch 3.178), train_loss = 1.80856921, grad/param norm = 2.5937e-01, time/batch = 0.6894s	
1927/30300 (epoch 3.180), train_loss = 1.92963634, grad/param norm = 2.1015e-01, time/batch = 0.6910s	
1928/30300 (epoch 3.182), train_loss = 1.92121771, grad/param norm = 2.3948e-01, time/batch = 0.6928s	
1929/30300 (epoch 3.183), train_loss = 1.84086038, grad/param norm = 1.8537e-01, time/batch = 0.6955s	
1930/30300 (epoch 3.185), train_loss = 2.32819416, grad/param norm = 2.3110e-01, time/batch = 0.7206s	
1931/30300 (epoch 3.186), train_loss = 2.18072930, grad/param norm = 2.3295e-01, time/batch = 0.6983s	
1932/30300 (epoch 3.188), train_loss = 1.98523536, grad/param norm = 2.1263e-01, time/batch = 0.6903s	
1933/30300 (epoch 3.190), train_loss = 1.87212600, grad/param norm = 2.0173e-01, time/batch = 0.6918s	
1934/30300 (epoch 3.191), train_loss = 2.06481350, grad/param norm = 2.1725e-01, time/batch = 0.6957s	
1935/30300 (epoch 3.193), train_loss = 1.84754116, grad/param norm = 2.1188e-01, time/batch = 0.6894s	
1936/30300 (epoch 3.195), train_loss = 2.03071518, grad/param norm = 2.6503e-01, time/batch = 0.6906s	
1937/30300 (epoch 3.196), train_loss = 2.11498092, grad/param norm = 2.5099e-01, time/batch = 0.6962s	
1938/30300 (epoch 3.198), train_loss = 1.75369070, grad/param norm = 2.0184e-01, time/batch = 0.6985s	
1939/30300 (epoch 3.200), train_loss = 1.91788003, grad/param norm = 2.3419e-01, time/batch = 0.6905s	
1940/30300 (epoch 3.201), train_loss = 2.13701875, grad/param norm = 2.1640e-01, time/batch = 0.6904s	
1941/30300 (epoch 3.203), train_loss = 1.96134101, grad/param norm = 2.0326e-01, time/batch = 0.6909s	
1942/30300 (epoch 3.205), train_loss = 2.20843416, grad/param norm = 2.0890e-01, time/batch = 0.6973s	
1943/30300 (epoch 3.206), train_loss = 2.20822590, grad/param norm = 2.2447e-01, time/batch = 0.7034s	
1944/30300 (epoch 3.208), train_loss = 2.18004214, grad/param norm = 2.3579e-01, time/batch = 0.7193s	
1945/30300 (epoch 3.210), train_loss = 2.01681360, grad/param norm = 2.1212e-01, time/batch = 0.7031s	
1946/30300 (epoch 3.211), train_loss = 1.99188341, grad/param norm = 1.9701e-01, time/batch = 0.6892s	
1947/30300 (epoch 3.213), train_loss = 1.96674902, grad/param norm = 2.3443e-01, time/batch = 0.6877s	
1948/30300 (epoch 3.215), train_loss = 1.76435002, grad/param norm = 1.9587e-01, time/batch = 0.6929s	
1949/30300 (epoch 3.216), train_loss = 1.99373718, grad/param norm = 2.3169e-01, time/batch = 0.6898s	
1950/30300 (epoch 3.218), train_loss = 1.92901808, grad/param norm = 2.2095e-01, time/batch = 0.6915s	
1951/30300 (epoch 3.219), train_loss = 1.82996780, grad/param norm = 2.2432e-01, time/batch = 0.6921s	
1952/30300 (epoch 3.221), train_loss = 1.81526381, grad/param norm = 2.0164e-01, time/batch = 0.7020s	
1953/30300 (epoch 3.223), train_loss = 1.89824172, grad/param norm = 1.9035e-01, time/batch = 0.7055s	
1954/30300 (epoch 3.224), train_loss = 1.72170557, grad/param norm = 1.8564e-01, time/batch = 0.7003s	
1955/30300 (epoch 3.226), train_loss = 2.02880321, grad/param norm = 2.2067e-01, time/batch = 0.6894s	
1956/30300 (epoch 3.228), train_loss = 1.99475432, grad/param norm = 2.1243e-01, time/batch = 0.6903s	
1957/30300 (epoch 3.229), train_loss = 1.86231535, grad/param norm = 2.4937e-01, time/batch = 0.6894s	
1958/30300 (epoch 3.231), train_loss = 1.95617670, grad/param norm = 2.3333e-01, time/batch = 0.7116s	
1959/30300 (epoch 3.233), train_loss = 1.86995531, grad/param norm = 2.1506e-01, time/batch = 0.7213s	
1960/30300 (epoch 3.234), train_loss = 2.03521294, grad/param norm = 2.1109e-01, time/batch = 0.6949s	
1961/30300 (epoch 3.236), train_loss = 1.91142257, grad/param norm = 2.5615e-01, time/batch = 0.6928s	
1962/30300 (epoch 3.238), train_loss = 2.08054379, grad/param norm = 2.8216e-01, time/batch = 0.6895s	
1963/30300 (epoch 3.239), train_loss = 1.94567728, grad/param norm = 2.5652e-01, time/batch = 0.6885s	
1964/30300 (epoch 3.241), train_loss = 1.93569096, grad/param norm = 1.9428e-01, time/batch = 0.6992s	
1965/30300 (epoch 3.243), train_loss = 1.93240923, grad/param norm = 2.1678e-01, time/batch = 0.6929s	
1966/30300 (epoch 3.244), train_loss = 2.29054175, grad/param norm = 2.3459e-01, time/batch = 0.6903s	
1967/30300 (epoch 3.246), train_loss = 1.90534653, grad/param norm = 1.9870e-01, time/batch = 0.6914s	
1968/30300 (epoch 3.248), train_loss = 2.04844217, grad/param norm = 1.8941e-01, time/batch = 0.6921s	
1969/30300 (epoch 3.249), train_loss = 1.77422982, grad/param norm = 2.1619e-01, time/batch = 0.6892s	
1970/30300 (epoch 3.251), train_loss = 1.85342365, grad/param norm = 1.9929e-01, time/batch = 0.6887s	
1971/30300 (epoch 3.252), train_loss = 2.13307784, grad/param norm = 2.1564e-01, time/batch = 0.6976s	
1972/30300 (epoch 3.254), train_loss = 1.99911701, grad/param norm = 1.9809e-01, time/batch = 0.7124s	
1973/30300 (epoch 3.256), train_loss = 1.99811820, grad/param norm = 2.0238e-01, time/batch = 0.7210s	
1974/30300 (epoch 3.257), train_loss = 2.14342466, grad/param norm = 2.2052e-01, time/batch = 0.6894s	
1975/30300 (epoch 3.259), train_loss = 2.02839510, grad/param norm = 2.2352e-01, time/batch = 0.6888s	
1976/30300 (epoch 3.261), train_loss = 2.14877305, grad/param norm = 2.2832e-01, time/batch = 0.6873s	
1977/30300 (epoch 3.262), train_loss = 1.94005837, grad/param norm = 1.9359e-01, time/batch = 0.6860s	
1978/30300 (epoch 3.264), train_loss = 1.97767655, grad/param norm = 2.1705e-01, time/batch = 0.6873s	
1979/30300 (epoch 3.266), train_loss = 1.88904977, grad/param norm = 1.8386e-01, time/batch = 0.6868s	
1980/30300 (epoch 3.267), train_loss = 2.12157226, grad/param norm = 2.2261e-01, time/batch = 0.6873s	
1981/30300 (epoch 3.269), train_loss = 2.02431313, grad/param norm = 2.2182e-01, time/batch = 0.6872s	
1982/30300 (epoch 3.271), train_loss = 1.98292301, grad/param norm = 2.3551e-01, time/batch = 0.6890s	
1983/30300 (epoch 3.272), train_loss = 1.99111817, grad/param norm = 1.9253e-01, time/batch = 0.6932s	
1984/30300 (epoch 3.274), train_loss = 2.09307776, grad/param norm = 2.0991e-01, time/batch = 0.6906s	
1985/30300 (epoch 3.276), train_loss = 2.11562290, grad/param norm = 2.2943e-01, time/batch = 0.6874s	
1986/30300 (epoch 3.277), train_loss = 1.90104713, grad/param norm = 2.2105e-01, time/batch = 0.6862s	
1987/30300 (epoch 3.279), train_loss = 1.98041166, grad/param norm = 2.0019e-01, time/batch = 0.7190s	
1988/30300 (epoch 3.281), train_loss = 1.99929057, grad/param norm = 2.0629e-01, time/batch = 0.7019s	
1989/30300 (epoch 3.282), train_loss = 1.85535705, grad/param norm = 2.0771e-01, time/batch = 0.6835s	
1990/30300 (epoch 3.284), train_loss = 2.18471203, grad/param norm = 2.5576e-01, time/batch = 0.6843s	
1991/30300 (epoch 3.285), train_loss = 2.03853358, grad/param norm = 2.2464e-01, time/batch = 0.6876s	
1992/30300 (epoch 3.287), train_loss = 2.05015952, grad/param norm = 2.3022e-01, time/batch = 0.6824s	
1993/30300 (epoch 3.289), train_loss = 1.98746446, grad/param norm = 2.2887e-01, time/batch = 0.6913s	
1994/30300 (epoch 3.290), train_loss = 1.68066547, grad/param norm = 1.8895e-01, time/batch = 0.6939s	
1995/30300 (epoch 3.292), train_loss = 1.85633602, grad/param norm = 1.9585e-01, time/batch = 0.6904s	
1996/30300 (epoch 3.294), train_loss = 2.11073984, grad/param norm = 1.9385e-01, time/batch = 0.6934s	
1997/30300 (epoch 3.295), train_loss = 1.90056589, grad/param norm = 1.8745e-01, time/batch = 0.6899s	
1998/30300 (epoch 3.297), train_loss = 1.88537985, grad/param norm = 2.1343e-01, time/batch = 0.6871s	
1999/30300 (epoch 3.299), train_loss = 2.01978868, grad/param norm = 2.3152e-01, time/batch = 0.6869s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch3.30_1.9930.t7	
2000/30300 (epoch 3.300), train_loss = 1.94606052, grad/param norm = 1.8887e-01, time/batch = 0.6870s	
2001/30300 (epoch 3.302), train_loss = 1.98194903, grad/param norm = 2.2210e-01, time/batch = 0.7016s	
2002/30300 (epoch 3.304), train_loss = 1.82656962, grad/param norm = 2.1093e-01, time/batch = 0.7001s	
2003/30300 (epoch 3.305), train_loss = 1.93483132, grad/param norm = 2.0313e-01, time/batch = 0.6960s	
2004/30300 (epoch 3.307), train_loss = 1.92821520, grad/param norm = 2.1727e-01, time/batch = 0.6988s	
2005/30300 (epoch 3.309), train_loss = 2.08444349, grad/param norm = 2.1047e-01, time/batch = 0.6996s	
2006/30300 (epoch 3.310), train_loss = 1.86237855, grad/param norm = 2.1105e-01, time/batch = 0.6889s	
2007/30300 (epoch 3.312), train_loss = 1.95616720, grad/param norm = 2.1119e-01, time/batch = 0.6977s	
2008/30300 (epoch 3.314), train_loss = 1.98994307, grad/param norm = 2.0521e-01, time/batch = 0.6893s	
2009/30300 (epoch 3.315), train_loss = 2.02715813, grad/param norm = 2.0512e-01, time/batch = 0.6880s	
2010/30300 (epoch 3.317), train_loss = 2.01862683, grad/param norm = 2.0327e-01, time/batch = 0.6951s	
2011/30300 (epoch 3.318), train_loss = 2.19638816, grad/param norm = 2.2293e-01, time/batch = 0.7100s	
2012/30300 (epoch 3.320), train_loss = 2.05032013, grad/param norm = 2.3757e-01, time/batch = 0.7162s	
2013/30300 (epoch 3.322), train_loss = 1.80927755, grad/param norm = 2.0177e-01, time/batch = 0.6837s	
2014/30300 (epoch 3.323), train_loss = 2.02849917, grad/param norm = 1.9364e-01, time/batch = 0.6947s	
2015/30300 (epoch 3.325), train_loss = 1.87369550, grad/param norm = 2.0096e-01, time/batch = 0.6896s	
2016/30300 (epoch 3.327), train_loss = 1.81667480, grad/param norm = 2.1380e-01, time/batch = 0.6897s	
2017/30300 (epoch 3.328), train_loss = 1.85925814, grad/param norm = 1.9852e-01, time/batch = 0.6931s	
2018/30300 (epoch 3.330), train_loss = 2.02948926, grad/param norm = 2.1632e-01, time/batch = 0.6903s	
2019/30300 (epoch 3.332), train_loss = 2.08183880, grad/param norm = 2.0643e-01, time/batch = 0.6933s	
2020/30300 (epoch 3.333), train_loss = 1.98656263, grad/param norm = 2.1500e-01, time/batch = 0.6898s	
2021/30300 (epoch 3.335), train_loss = 1.73612345, grad/param norm = 2.3350e-01, time/batch = 0.6922s	
2022/30300 (epoch 3.337), train_loss = 2.16872340, grad/param norm = 2.2882e-01, time/batch = 0.6905s	
2023/30300 (epoch 3.338), train_loss = 1.88092820, grad/param norm = 2.3958e-01, time/batch = 0.6906s	
2024/30300 (epoch 3.340), train_loss = 1.93959205, grad/param norm = 2.5568e-01, time/batch = 0.6890s	
2025/30300 (epoch 3.342), train_loss = 1.98846453, grad/param norm = 1.9896e-01, time/batch = 0.6942s	
2026/30300 (epoch 3.343), train_loss = 1.95530476, grad/param norm = 2.2111e-01, time/batch = 0.7208s	
2027/30300 (epoch 3.345), train_loss = 1.96343732, grad/param norm = 2.4163e-01, time/batch = 0.6985s	
2028/30300 (epoch 3.347), train_loss = 1.73656213, grad/param norm = 1.9531e-01, time/batch = 0.6996s	
2029/30300 (epoch 3.348), train_loss = 1.82358608, grad/param norm = 2.0526e-01, time/batch = 0.6955s	
2030/30300 (epoch 3.350), train_loss = 1.93792609, grad/param norm = 2.3070e-01, time/batch = 0.7047s	
2031/30300 (epoch 3.351), train_loss = 1.92396984, grad/param norm = 2.1785e-01, time/batch = 0.7043s	
2032/30300 (epoch 3.353), train_loss = 1.71773013, grad/param norm = 2.3413e-01, time/batch = 0.7133s	
2033/30300 (epoch 3.355), train_loss = 1.97876778, grad/param norm = 1.9316e-01, time/batch = 0.6992s	
2034/30300 (epoch 3.356), train_loss = 2.05819475, grad/param norm = 2.0305e-01, time/batch = 0.6902s	
2035/30300 (epoch 3.358), train_loss = 2.12381242, grad/param norm = 2.3594e-01, time/batch = 0.6908s	
2036/30300 (epoch 3.360), train_loss = 1.87103990, grad/param norm = 1.8430e-01, time/batch = 0.6897s	
2037/30300 (epoch 3.361), train_loss = 2.00118026, grad/param norm = 2.3464e-01, time/batch = 0.6893s	
2038/30300 (epoch 3.363), train_loss = 2.05255573, grad/param norm = 2.4349e-01, time/batch = 0.6895s	
2039/30300 (epoch 3.365), train_loss = 1.89607066, grad/param norm = 2.3510e-01, time/batch = 0.6883s	
2040/30300 (epoch 3.366), train_loss = 1.88955986, grad/param norm = 2.1482e-01, time/batch = 0.6930s	
2041/30300 (epoch 3.368), train_loss = 1.72379153, grad/param norm = 2.0345e-01, time/batch = 0.6902s	
2042/30300 (epoch 3.370), train_loss = 1.94420401, grad/param norm = 2.0835e-01, time/batch = 0.6978s	
2043/30300 (epoch 3.371), train_loss = 1.94350265, grad/param norm = 2.0583e-01, time/batch = 0.6972s	
2044/30300 (epoch 3.373), train_loss = 1.91506190, grad/param norm = 2.0880e-01, time/batch = 0.6931s	
2045/30300 (epoch 3.375), train_loss = 1.83863941, grad/param norm = 2.0257e-01, time/batch = 0.6934s	
2046/30300 (epoch 3.376), train_loss = 1.88029800, grad/param norm = 1.9513e-01, time/batch = 0.6926s	
2047/30300 (epoch 3.378), train_loss = 1.88265477, grad/param norm = 1.9874e-01, time/batch = 0.6917s	
2048/30300 (epoch 3.380), train_loss = 2.14440815, grad/param norm = 2.1352e-01, time/batch = 0.6907s	
2049/30300 (epoch 3.381), train_loss = 1.95319660, grad/param norm = 1.9240e-01, time/batch = 0.6888s	
2050/30300 (epoch 3.383), train_loss = 2.05019200, grad/param norm = 2.1922e-01, time/batch = 0.7173s	
2051/30300 (epoch 3.384), train_loss = 2.07861740, grad/param norm = 2.0002e-01, time/batch = 0.7046s	
2052/30300 (epoch 3.386), train_loss = 1.82844608, grad/param norm = 2.2148e-01, time/batch = 0.6911s	
2053/30300 (epoch 3.388), train_loss = 1.91942640, grad/param norm = 2.0010e-01, time/batch = 0.6890s	
2054/30300 (epoch 3.389), train_loss = 1.94239004, grad/param norm = 2.2138e-01, time/batch = 0.6907s	
2055/30300 (epoch 3.391), train_loss = 2.00731734, grad/param norm = 2.0151e-01, time/batch = 0.6897s	
2056/30300 (epoch 3.393), train_loss = 1.78186434, grad/param norm = 2.0534e-01, time/batch = 0.6957s	
2057/30300 (epoch 3.394), train_loss = 1.91574897, grad/param norm = 1.8529e-01, time/batch = 0.7056s	
2058/30300 (epoch 3.396), train_loss = 2.04007742, grad/param norm = 2.1011e-01, time/batch = 0.7025s	
2059/30300 (epoch 3.398), train_loss = 1.86623329, grad/param norm = 1.9850e-01, time/batch = 0.6947s	
2060/30300 (epoch 3.399), train_loss = 1.82988264, grad/param norm = 1.8734e-01, time/batch = 0.6880s	
2061/30300 (epoch 3.401), train_loss = 2.06069133, grad/param norm = 2.1253e-01, time/batch = 0.6867s	
2062/30300 (epoch 3.403), train_loss = 1.95673822, grad/param norm = 2.1800e-01, time/batch = 0.6897s	
2063/30300 (epoch 3.404), train_loss = 1.92289819, grad/param norm = 2.4561e-01, time/batch = 0.6920s	
2064/30300 (epoch 3.406), train_loss = 1.96640850, grad/param norm = 2.2570e-01, time/batch = 0.7090s	
2065/30300 (epoch 3.408), train_loss = 1.84099307, grad/param norm = 2.0353e-01, time/batch = 0.7126s	
2066/30300 (epoch 3.409), train_loss = 1.70687183, grad/param norm = 2.3505e-01, time/batch = 0.6963s	
2067/30300 (epoch 3.411), train_loss = 1.80009481, grad/param norm = 2.3352e-01, time/batch = 0.6932s	
2068/30300 (epoch 3.413), train_loss = 1.76597750, grad/param norm = 2.0464e-01, time/batch = 0.6904s	
2069/30300 (epoch 3.414), train_loss = 2.06972951, grad/param norm = 1.9826e-01, time/batch = 0.6922s	
2070/30300 (epoch 3.416), train_loss = 1.92721366, grad/param norm = 2.0797e-01, time/batch = 0.6939s	
2071/30300 (epoch 3.417), train_loss = 1.82488387, grad/param norm = 1.7722e-01, time/batch = 0.6906s	
2072/30300 (epoch 3.419), train_loss = 1.72653473, grad/param norm = 2.2733e-01, time/batch = 0.6916s	
2073/30300 (epoch 3.421), train_loss = 1.81255346, grad/param norm = 2.1873e-01, time/batch = 0.7005s	
2074/30300 (epoch 3.422), train_loss = 1.84697223, grad/param norm = 2.0580e-01, time/batch = 0.6954s	
2075/30300 (epoch 3.424), train_loss = 1.96733418, grad/param norm = 2.2131e-01, time/batch = 0.6912s	
2076/30300 (epoch 3.426), train_loss = 1.70668793, grad/param norm = 1.9311e-01, time/batch = 0.6891s	
2077/30300 (epoch 3.427), train_loss = 1.86209809, grad/param norm = 2.0585e-01, time/batch = 0.6940s	
2078/30300 (epoch 3.429), train_loss = 1.94686958, grad/param norm = 2.6348e-01, time/batch = 0.6981s	
2079/30300 (epoch 3.431), train_loss = 1.99257408, grad/param norm = 2.6291e-01, time/batch = 0.7205s	
2080/30300 (epoch 3.432), train_loss = 1.92225854, grad/param norm = 2.2331e-01, time/batch = 0.7074s	
2081/30300 (epoch 3.434), train_loss = 1.82724279, grad/param norm = 1.9685e-01, time/batch = 0.6947s	
2082/30300 (epoch 3.436), train_loss = 1.94712657, grad/param norm = 2.1101e-01, time/batch = 0.6958s	
2083/30300 (epoch 3.437), train_loss = 1.91716251, grad/param norm = 2.1596e-01, time/batch = 0.6914s	
2084/30300 (epoch 3.439), train_loss = 1.82252461, grad/param norm = 2.1499e-01, time/batch = 0.6915s	
2085/30300 (epoch 3.441), train_loss = 1.82493558, grad/param norm = 2.1481e-01, time/batch = 0.6919s	
2086/30300 (epoch 3.442), train_loss = 1.74681578, grad/param norm = 2.2045e-01, time/batch = 0.6920s	
2087/30300 (epoch 3.444), train_loss = 1.79955027, grad/param norm = 2.3339e-01, time/batch = 0.6916s	
2088/30300 (epoch 3.446), train_loss = 1.80703539, grad/param norm = 2.1986e-01, time/batch = 0.6945s	
2089/30300 (epoch 3.447), train_loss = 1.95537835, grad/param norm = 2.8144e-01, time/batch = 0.6911s	
2090/30300 (epoch 3.449), train_loss = 1.84314435, grad/param norm = 2.1785e-01, time/batch = 0.6878s	
2091/30300 (epoch 3.450), train_loss = 2.04659513, grad/param norm = 2.8303e-01, time/batch = 0.6919s	
2092/30300 (epoch 3.452), train_loss = 1.85288534, grad/param norm = 1.7621e-01, time/batch = 0.6885s	
2093/30300 (epoch 3.454), train_loss = 1.86506126, grad/param norm = 2.1955e-01, time/batch = 0.7205s	
2094/30300 (epoch 3.455), train_loss = 2.06933756, grad/param norm = 2.1957e-01, time/batch = 0.7042s	
2095/30300 (epoch 3.457), train_loss = 1.97524908, grad/param norm = 2.1108e-01, time/batch = 0.6919s	
2096/30300 (epoch 3.459), train_loss = 1.95829216, grad/param norm = 2.2630e-01, time/batch = 0.6896s	
2097/30300 (epoch 3.460), train_loss = 1.94272597, grad/param norm = 2.0493e-01, time/batch = 0.6900s	
2098/30300 (epoch 3.462), train_loss = 1.99962611, grad/param norm = 2.1266e-01, time/batch = 0.6907s	
2099/30300 (epoch 3.464), train_loss = 1.91089983, grad/param norm = 2.1882e-01, time/batch = 0.6885s	
2100/30300 (epoch 3.465), train_loss = 1.76680328, grad/param norm = 1.9755e-01, time/batch = 0.6910s	
2101/30300 (epoch 3.467), train_loss = 1.62722094, grad/param norm = 1.9509e-01, time/batch = 0.6927s	
2102/30300 (epoch 3.469), train_loss = 1.85536198, grad/param norm = 2.1560e-01, time/batch = 0.6911s	
2103/30300 (epoch 3.470), train_loss = 1.80916008, grad/param norm = 1.9030e-01, time/batch = 0.6873s	
2104/30300 (epoch 3.472), train_loss = 1.79606567, grad/param norm = 2.2729e-01, time/batch = 0.6922s	
2105/30300 (epoch 3.474), train_loss = 1.91567961, grad/param norm = 2.5075e-01, time/batch = 0.6926s	
2106/30300 (epoch 3.475), train_loss = 1.86268975, grad/param norm = 2.0068e-01, time/batch = 0.6905s	
2107/30300 (epoch 3.477), train_loss = 1.91535172, grad/param norm = 2.1258e-01, time/batch = 0.6885s	
2108/30300 (epoch 3.479), train_loss = 2.00956708, grad/param norm = 2.2039e-01, time/batch = 0.6894s	
2109/30300 (epoch 3.480), train_loss = 1.86288079, grad/param norm = 1.8760e-01, time/batch = 0.6935s	
2110/30300 (epoch 3.482), train_loss = 1.96247207, grad/param norm = 2.5682e-01, time/batch = 0.6938s	
2111/30300 (epoch 3.483), train_loss = 1.96049917, grad/param norm = 2.2755e-01, time/batch = 0.6935s	
2112/30300 (epoch 3.485), train_loss = 1.85946220, grad/param norm = 1.9675e-01, time/batch = 0.6919s	
2113/30300 (epoch 3.487), train_loss = 2.01919426, grad/param norm = 2.3050e-01, time/batch = 0.7000s	
2114/30300 (epoch 3.488), train_loss = 1.83573638, grad/param norm = 1.8837e-01, time/batch = 0.6909s	
2115/30300 (epoch 3.490), train_loss = 1.75861015, grad/param norm = 2.0664e-01, time/batch = 0.7017s	
2116/30300 (epoch 3.492), train_loss = 1.93695497, grad/param norm = 2.2308e-01, time/batch = 0.7088s	
2117/30300 (epoch 3.493), train_loss = 1.83862036, grad/param norm = 2.3841e-01, time/batch = 0.7019s	
2118/30300 (epoch 3.495), train_loss = 1.87832749, grad/param norm = 2.0482e-01, time/batch = 0.7209s	
2119/30300 (epoch 3.497), train_loss = 1.90198002, grad/param norm = 2.2067e-01, time/batch = 0.6992s	
2120/30300 (epoch 3.498), train_loss = 1.92690741, grad/param norm = 2.0414e-01, time/batch = 0.7088s	
2121/30300 (epoch 3.500), train_loss = 2.08132522, grad/param norm = 2.1912e-01, time/batch = 0.7039s	
2122/30300 (epoch 3.502), train_loss = 1.80139638, grad/param norm = 2.4451e-01, time/batch = 0.7221s	
2123/30300 (epoch 3.503), train_loss = 1.94212395, grad/param norm = 2.0121e-01, time/batch = 0.7146s	
2124/30300 (epoch 3.505), train_loss = 1.93830120, grad/param norm = 2.1459e-01, time/batch = 0.6855s	
2125/30300 (epoch 3.507), train_loss = 1.92729692, grad/param norm = 2.0818e-01, time/batch = 0.6838s	
2126/30300 (epoch 3.508), train_loss = 2.07277991, grad/param norm = 2.2462e-01, time/batch = 0.6874s	
2127/30300 (epoch 3.510), train_loss = 1.97691646, grad/param norm = 2.2420e-01, time/batch = 0.6913s	
2128/30300 (epoch 3.512), train_loss = 1.81546569, grad/param norm = 2.0828e-01, time/batch = 0.7019s	
2129/30300 (epoch 3.513), train_loss = 1.93125622, grad/param norm = 2.2650e-01, time/batch = 0.7061s	
2130/30300 (epoch 3.515), train_loss = 1.88690323, grad/param norm = 2.2240e-01, time/batch = 0.6922s	
2131/30300 (epoch 3.517), train_loss = 1.72482643, grad/param norm = 1.9241e-01, time/batch = 0.6980s	
2132/30300 (epoch 3.518), train_loss = 2.00914458, grad/param norm = 2.1575e-01, time/batch = 0.6840s	
2133/30300 (epoch 3.520), train_loss = 2.19997138, grad/param norm = 2.3327e-01, time/batch = 0.6845s	
2134/30300 (epoch 3.521), train_loss = 1.85052813, grad/param norm = 2.2084e-01, time/batch = 0.6869s	
2135/30300 (epoch 3.523), train_loss = 2.03913754, grad/param norm = 2.2225e-01, time/batch = 0.6931s	
2136/30300 (epoch 3.525), train_loss = 1.94765686, grad/param norm = 2.0201e-01, time/batch = 0.6907s	
2137/30300 (epoch 3.526), train_loss = 1.86333983, grad/param norm = 1.9407e-01, time/batch = 0.7096s	
2138/30300 (epoch 3.528), train_loss = 1.73193682, grad/param norm = 2.0243e-01, time/batch = 0.7075s	
2139/30300 (epoch 3.530), train_loss = 1.78557273, grad/param norm = 2.2013e-01, time/batch = 0.6979s	
2140/30300 (epoch 3.531), train_loss = 1.94823833, grad/param norm = 2.0074e-01, time/batch = 0.7068s	
2141/30300 (epoch 3.533), train_loss = 1.96567797, grad/param norm = 1.9120e-01, time/batch = 0.6988s	
2142/30300 (epoch 3.535), train_loss = 1.73222697, grad/param norm = 1.9579e-01, time/batch = 0.7083s	
2143/30300 (epoch 3.536), train_loss = 1.94303250, grad/param norm = 1.9835e-01, time/batch = 0.7126s	
2144/30300 (epoch 3.538), train_loss = 1.72464106, grad/param norm = 2.0030e-01, time/batch = 0.7206s	
2145/30300 (epoch 3.540), train_loss = 1.93540713, grad/param norm = 2.0295e-01, time/batch = 0.7220s	
2146/30300 (epoch 3.541), train_loss = 1.84410604, grad/param norm = 2.0192e-01, time/batch = 0.7180s	
2147/30300 (epoch 3.543), train_loss = 1.89127400, grad/param norm = 2.0193e-01, time/batch = 0.7149s	
2148/30300 (epoch 3.545), train_loss = 2.02344480, grad/param norm = 2.2841e-01, time/batch = 0.7022s	
2149/30300 (epoch 3.546), train_loss = 2.10262650, grad/param norm = 2.2703e-01, time/batch = 0.6911s	
2150/30300 (epoch 3.548), train_loss = 1.82981591, grad/param norm = 2.5065e-01, time/batch = 0.7191s	
2151/30300 (epoch 3.550), train_loss = 2.09740279, grad/param norm = 1.9780e-01, time/batch = 0.7066s	
2152/30300 (epoch 3.551), train_loss = 1.87254310, grad/param norm = 2.0519e-01, time/batch = 0.6930s	
2153/30300 (epoch 3.553), train_loss = 1.82515200, grad/param norm = 1.9156e-01, time/batch = 0.6888s	
2154/30300 (epoch 3.554), train_loss = 2.06802812, grad/param norm = 2.1667e-01, time/batch = 0.6904s	
2155/30300 (epoch 3.556), train_loss = 1.91027578, grad/param norm = 1.8675e-01, time/batch = 0.6884s	
2156/30300 (epoch 3.558), train_loss = 2.04100585, grad/param norm = 1.9756e-01, time/batch = 0.6931s	
2157/30300 (epoch 3.559), train_loss = 1.87594639, grad/param norm = 2.1713e-01, time/batch = 0.6922s	
2158/30300 (epoch 3.561), train_loss = 1.79264196, grad/param norm = 1.9370e-01, time/batch = 0.6947s	
2159/30300 (epoch 3.563), train_loss = 1.94930414, grad/param norm = 2.0389e-01, time/batch = 0.7069s	
2160/30300 (epoch 3.564), train_loss = 1.88490348, grad/param norm = 1.8738e-01, time/batch = 0.6906s	
2161/30300 (epoch 3.566), train_loss = 1.97720818, grad/param norm = 2.4180e-01, time/batch = 0.6917s	
2162/30300 (epoch 3.568), train_loss = 1.76329442, grad/param norm = 2.1595e-01, time/batch = 0.6924s	
2163/30300 (epoch 3.569), train_loss = 1.85775247, grad/param norm = 1.9844e-01, time/batch = 0.6880s	
2164/30300 (epoch 3.571), train_loss = 1.99300262, grad/param norm = 2.3119e-01, time/batch = 0.6868s	
2165/30300 (epoch 3.573), train_loss = 1.95315436, grad/param norm = 2.0513e-01, time/batch = 0.6952s	
2166/30300 (epoch 3.574), train_loss = 1.90364641, grad/param norm = 2.1339e-01, time/batch = 0.6933s	
2167/30300 (epoch 3.576), train_loss = 1.92877295, grad/param norm = 2.0995e-01, time/batch = 0.6920s	
2168/30300 (epoch 3.578), train_loss = 1.78796273, grad/param norm = 1.8160e-01, time/batch = 0.6990s	
2169/30300 (epoch 3.579), train_loss = 1.84517180, grad/param norm = 2.1154e-01, time/batch = 0.7204s	
2170/30300 (epoch 3.581), train_loss = 1.97480096, grad/param norm = 2.3850e-01, time/batch = 0.6954s	
2171/30300 (epoch 3.583), train_loss = 2.06827250, grad/param norm = 2.4068e-01, time/batch = 0.6903s	
2172/30300 (epoch 3.584), train_loss = 2.04463085, grad/param norm = 2.0177e-01, time/batch = 0.6888s	
2173/30300 (epoch 3.586), train_loss = 1.94478515, grad/param norm = 2.0606e-01, time/batch = 0.6894s	
2174/30300 (epoch 3.587), train_loss = 1.92481968, grad/param norm = 2.0401e-01, time/batch = 0.6869s	
2175/30300 (epoch 3.589), train_loss = 1.60626038, grad/param norm = 1.8526e-01, time/batch = 0.6832s	
2176/30300 (epoch 3.591), train_loss = 1.92628286, grad/param norm = 2.1941e-01, time/batch = 0.6856s	
2177/30300 (epoch 3.592), train_loss = 1.88596165, grad/param norm = 1.9595e-01, time/batch = 0.6861s	
2178/30300 (epoch 3.594), train_loss = 1.94702563, grad/param norm = 2.6877e-01, time/batch = 0.6873s	
2179/30300 (epoch 3.596), train_loss = 1.82353542, grad/param norm = 2.5021e-01, time/batch = 0.6905s	
2180/30300 (epoch 3.597), train_loss = 1.88278863, grad/param norm = 2.3802e-01, time/batch = 0.6914s	
2181/30300 (epoch 3.599), train_loss = 1.67439319, grad/param norm = 2.1466e-01, time/batch = 0.6897s	
2182/30300 (epoch 3.601), train_loss = 1.90705693, grad/param norm = 2.1241e-01, time/batch = 0.6893s	
2183/30300 (epoch 3.602), train_loss = 1.86344605, grad/param norm = 1.8573e-01, time/batch = 0.7101s	
2184/30300 (epoch 3.604), train_loss = 1.80851618, grad/param norm = 2.1087e-01, time/batch = 0.6908s	
2185/30300 (epoch 3.606), train_loss = 2.15983104, grad/param norm = 2.5154e-01, time/batch = 0.6863s	
2186/30300 (epoch 3.607), train_loss = 1.99888443, grad/param norm = 2.0849e-01, time/batch = 0.6966s	
2187/30300 (epoch 3.609), train_loss = 2.20199274, grad/param norm = 2.3511e-01, time/batch = 0.6958s	
2188/30300 (epoch 3.611), train_loss = 1.70339851, grad/param norm = 1.8394e-01, time/batch = 0.6934s	
2189/30300 (epoch 3.612), train_loss = 1.85484918, grad/param norm = 2.1056e-01, time/batch = 0.6883s	
2190/30300 (epoch 3.614), train_loss = 1.69701073, grad/param norm = 1.8641e-01, time/batch = 0.6896s	
2191/30300 (epoch 3.616), train_loss = 1.96048501, grad/param norm = 2.0915e-01, time/batch = 0.6894s	
2192/30300 (epoch 3.617), train_loss = 1.88362592, grad/param norm = 2.0333e-01, time/batch = 0.6853s	
2193/30300 (epoch 3.619), train_loss = 1.70252042, grad/param norm = 1.9873e-01, time/batch = 0.6893s	
2194/30300 (epoch 3.620), train_loss = 1.97324424, grad/param norm = 2.0603e-01, time/batch = 0.6885s	
2195/30300 (epoch 3.622), train_loss = 1.82065905, grad/param norm = 2.0614e-01, time/batch = 0.6873s	
2196/30300 (epoch 3.624), train_loss = 1.79234160, grad/param norm = 1.9604e-01, time/batch = 0.6854s	
2197/30300 (epoch 3.625), train_loss = 1.82275210, grad/param norm = 2.1270e-01, time/batch = 0.7055s	
2198/30300 (epoch 3.627), train_loss = 2.05225151, grad/param norm = 2.0553e-01, time/batch = 0.7171s	
2199/30300 (epoch 3.629), train_loss = 1.95239879, grad/param norm = 2.0502e-01, time/batch = 0.6890s	
2200/30300 (epoch 3.630), train_loss = 1.94300462, grad/param norm = 2.0456e-01, time/batch = 0.6883s	
2201/30300 (epoch 3.632), train_loss = 1.97771940, grad/param norm = 2.4700e-01, time/batch = 0.6994s	
2202/30300 (epoch 3.634), train_loss = 1.67931806, grad/param norm = 1.7935e-01, time/batch = 0.7039s	
2203/30300 (epoch 3.635), train_loss = 1.98403456, grad/param norm = 1.9045e-01, time/batch = 0.6950s	
2204/30300 (epoch 3.637), train_loss = 1.89933035, grad/param norm = 2.1762e-01, time/batch = 0.7066s	
2205/30300 (epoch 3.639), train_loss = 1.80246306, grad/param norm = 2.4536e-01, time/batch = 0.7077s	
2206/30300 (epoch 3.640), train_loss = 1.96440716, grad/param norm = 2.2105e-01, time/batch = 0.6938s	
2207/30300 (epoch 3.642), train_loss = 1.89565566, grad/param norm = 2.6517e-01, time/batch = 0.6906s	
2208/30300 (epoch 3.644), train_loss = 1.96185899, grad/param norm = 3.1104e-01, time/batch = 0.6928s	
2209/30300 (epoch 3.645), train_loss = 1.85212724, grad/param norm = 2.1074e-01, time/batch = 0.6906s	
2210/30300 (epoch 3.647), train_loss = 1.88478468, grad/param norm = 2.1200e-01, time/batch = 0.6867s	
2211/30300 (epoch 3.649), train_loss = 1.85512821, grad/param norm = 1.9654e-01, time/batch = 0.7019s	
2212/30300 (epoch 3.650), train_loss = 1.89260273, grad/param norm = 1.9918e-01, time/batch = 0.7225s	
2213/30300 (epoch 3.652), train_loss = 1.74769732, grad/param norm = 2.2201e-01, time/batch = 0.6941s	
2214/30300 (epoch 3.653), train_loss = 2.04961059, grad/param norm = 2.2632e-01, time/batch = 0.6881s	
2215/30300 (epoch 3.655), train_loss = 1.86324749, grad/param norm = 2.0352e-01, time/batch = 0.7044s	
2216/30300 (epoch 3.657), train_loss = 1.98581970, grad/param norm = 2.1882e-01, time/batch = 0.6931s	
2217/30300 (epoch 3.658), train_loss = 1.81516129, grad/param norm = 2.0947e-01, time/batch = 0.6906s	
2218/30300 (epoch 3.660), train_loss = 1.92841021, grad/param norm = 1.9830e-01, time/batch = 0.6899s	
2219/30300 (epoch 3.662), train_loss = 1.93518718, grad/param norm = 2.0909e-01, time/batch = 0.6946s	
2220/30300 (epoch 3.663), train_loss = 1.88709979, grad/param norm = 1.9486e-01, time/batch = 0.6950s	
2221/30300 (epoch 3.665), train_loss = 1.72499062, grad/param norm = 1.8088e-01, time/batch = 0.6882s	
2222/30300 (epoch 3.667), train_loss = 2.03981397, grad/param norm = 2.2851e-01, time/batch = 0.6959s	
2223/30300 (epoch 3.668), train_loss = 2.08766107, grad/param norm = 2.1417e-01, time/batch = 0.6907s	
2224/30300 (epoch 3.670), train_loss = 1.93995971, grad/param norm = 2.1575e-01, time/batch = 0.6874s	
2225/30300 (epoch 3.672), train_loss = 1.96625470, grad/param norm = 2.0675e-01, time/batch = 0.6863s	
2226/30300 (epoch 3.673), train_loss = 1.92955162, grad/param norm = 2.1007e-01, time/batch = 0.7179s	
2227/30300 (epoch 3.675), train_loss = 1.79397893, grad/param norm = 2.0574e-01, time/batch = 0.7086s	
2228/30300 (epoch 3.677), train_loss = 1.81493579, grad/param norm = 2.0794e-01, time/batch = 0.6854s	
2229/30300 (epoch 3.678), train_loss = 1.83421017, grad/param norm = 1.9721e-01, time/batch = 0.6878s	
2230/30300 (epoch 3.680), train_loss = 1.62283675, grad/param norm = 2.0626e-01, time/batch = 0.6867s	
2231/30300 (epoch 3.682), train_loss = 1.87066431, grad/param norm = 2.7930e-01, time/batch = 0.6882s	
2232/30300 (epoch 3.683), train_loss = 1.95271474, grad/param norm = 2.0887e-01, time/batch = 0.6852s	
2233/30300 (epoch 3.685), train_loss = 2.04678638, grad/param norm = 2.2219e-01, time/batch = 0.6842s	
2234/30300 (epoch 3.686), train_loss = 1.90317364, grad/param norm = 2.0780e-01, time/batch = 0.6887s	
2235/30300 (epoch 3.688), train_loss = 1.89817734, grad/param norm = 2.0511e-01, time/batch = 0.6866s	
2236/30300 (epoch 3.690), train_loss = 1.87238636, grad/param norm = 2.3509e-01, time/batch = 0.6876s	
2237/30300 (epoch 3.691), train_loss = 1.92027342, grad/param norm = 2.7751e-01, time/batch = 0.6900s	
2238/30300 (epoch 3.693), train_loss = 2.25605352, grad/param norm = 2.4364e-01, time/batch = 0.6927s	
2239/30300 (epoch 3.695), train_loss = 2.05039867, grad/param norm = 2.0971e-01, time/batch = 0.6854s	
2240/30300 (epoch 3.696), train_loss = 2.14244496, grad/param norm = 2.5576e-01, time/batch = 0.6870s	
2241/30300 (epoch 3.698), train_loss = 1.80364645, grad/param norm = 2.1145e-01, time/batch = 0.6914s	
2242/30300 (epoch 3.700), train_loss = 1.87682635, grad/param norm = 2.0731e-01, time/batch = 0.6919s	
2243/30300 (epoch 3.701), train_loss = 1.63430165, grad/param norm = 1.8366e-01, time/batch = 0.6885s	
2244/30300 (epoch 3.703), train_loss = 1.80591569, grad/param norm = 1.7391e-01, time/batch = 0.6918s	
2245/30300 (epoch 3.705), train_loss = 1.92874558, grad/param norm = 2.2843e-01, time/batch = 0.6904s	
2246/30300 (epoch 3.706), train_loss = 1.83299921, grad/param norm = 1.9728e-01, time/batch = 0.7086s	
2247/30300 (epoch 3.708), train_loss = 1.86373107, grad/param norm = 2.0206e-01, time/batch = 0.7058s	
2248/30300 (epoch 3.710), train_loss = 1.83112219, grad/param norm = 2.1885e-01, time/batch = 0.6916s	
2249/30300 (epoch 3.711), train_loss = 1.75909057, grad/param norm = 1.9624e-01, time/batch = 0.6859s	
2250/30300 (epoch 3.713), train_loss = 1.67720046, grad/param norm = 1.7826e-01, time/batch = 0.6834s	
2251/30300 (epoch 3.715), train_loss = 1.86120016, grad/param norm = 1.9519e-01, time/batch = 0.6894s	
2252/30300 (epoch 3.716), train_loss = 2.04432168, grad/param norm = 2.1224e-01, time/batch = 0.6913s	
2253/30300 (epoch 3.718), train_loss = 1.98592018, grad/param norm = 2.0851e-01, time/batch = 0.6880s	
2254/30300 (epoch 3.719), train_loss = 1.86544814, grad/param norm = 2.1337e-01, time/batch = 0.6907s	
2255/30300 (epoch 3.721), train_loss = 1.87869996, grad/param norm = 1.9063e-01, time/batch = 0.6879s	
2256/30300 (epoch 3.723), train_loss = 1.80980606, grad/param norm = 2.0052e-01, time/batch = 0.6906s	
2257/30300 (epoch 3.724), train_loss = 1.90549938, grad/param norm = 2.0768e-01, time/batch = 0.6878s	
2258/30300 (epoch 3.726), train_loss = 2.30740080, grad/param norm = 2.3387e-01, time/batch = 0.6899s	
2259/30300 (epoch 3.728), train_loss = 1.82704763, grad/param norm = 2.0662e-01, time/batch = 0.7142s	
2260/30300 (epoch 3.729), train_loss = 1.90131682, grad/param norm = 2.1985e-01, time/batch = 0.7082s	
2261/30300 (epoch 3.731), train_loss = 1.96363648, grad/param norm = 1.9262e-01, time/batch = 0.6913s	
2262/30300 (epoch 3.733), train_loss = 1.85421021, grad/param norm = 1.9076e-01, time/batch = 0.6863s	
2263/30300 (epoch 3.734), train_loss = 1.89649971, grad/param norm = 1.8511e-01, time/batch = 0.6885s	
2264/30300 (epoch 3.736), train_loss = 1.85501206, grad/param norm = 1.9695e-01, time/batch = 0.6873s	
2265/30300 (epoch 3.738), train_loss = 1.69588537, grad/param norm = 1.7835e-01, time/batch = 0.6991s	
2266/30300 (epoch 3.739), train_loss = 1.98645338, grad/param norm = 2.0633e-01, time/batch = 0.6929s	
2267/30300 (epoch 3.741), train_loss = 1.94557425, grad/param norm = 1.9679e-01, time/batch = 0.6896s	
2268/30300 (epoch 3.743), train_loss = 1.74230959, grad/param norm = 2.0332e-01, time/batch = 0.6863s	
2269/30300 (epoch 3.744), train_loss = 2.02052969, grad/param norm = 2.2298e-01, time/batch = 0.6920s	
2270/30300 (epoch 3.746), train_loss = 1.71222398, grad/param norm = 2.1551e-01, time/batch = 0.6893s	
2271/30300 (epoch 3.748), train_loss = 1.95159350, grad/param norm = 2.5934e-01, time/batch = 0.6936s	
2272/30300 (epoch 3.749), train_loss = 1.88371963, grad/param norm = 2.3950e-01, time/batch = 0.6959s	
2273/30300 (epoch 3.751), train_loss = 1.79059471, grad/param norm = 2.0040e-01, time/batch = 0.6932s	
2274/30300 (epoch 3.752), train_loss = 1.79797836, grad/param norm = 1.9188e-01, time/batch = 0.6942s	
2275/30300 (epoch 3.754), train_loss = 1.63929256, grad/param norm = 1.8549e-01, time/batch = 0.6875s	
2276/30300 (epoch 3.756), train_loss = 1.79002437, grad/param norm = 2.0638e-01, time/batch = 0.6949s	
2277/30300 (epoch 3.757), train_loss = 1.94328506, grad/param norm = 2.0794e-01, time/batch = 0.6929s	
2278/30300 (epoch 3.759), train_loss = 1.73299519, grad/param norm = 2.0688e-01, time/batch = 0.6864s	
2279/30300 (epoch 3.761), train_loss = 1.77481418, grad/param norm = 1.9699e-01, time/batch = 0.6898s	
2280/30300 (epoch 3.762), train_loss = 1.62285496, grad/param norm = 1.8897e-01, time/batch = 0.6908s	
2281/30300 (epoch 3.764), train_loss = 1.79479341, grad/param norm = 2.1366e-01, time/batch = 0.6908s	
2282/30300 (epoch 3.766), train_loss = 1.87769199, grad/param norm = 2.0655e-01, time/batch = 0.6886s	
2283/30300 (epoch 3.767), train_loss = 1.99371816, grad/param norm = 2.2440e-01, time/batch = 0.6977s	
2284/30300 (epoch 3.769), train_loss = 2.05995392, grad/param norm = 2.4547e-01, time/batch = 0.6953s	
2285/30300 (epoch 3.771), train_loss = 1.89065385, grad/param norm = 2.0481e-01, time/batch = 0.6906s	
2286/30300 (epoch 3.772), train_loss = 1.84961548, grad/param norm = 2.1590e-01, time/batch = 0.6914s	
2287/30300 (epoch 3.774), train_loss = 1.92621459, grad/param norm = 2.0852e-01, time/batch = 0.6945s	
2288/30300 (epoch 3.776), train_loss = 1.85102221, grad/param norm = 2.0192e-01, time/batch = 0.7113s	
2289/30300 (epoch 3.777), train_loss = 1.88034471, grad/param norm = 2.1555e-01, time/batch = 0.6977s	
2290/30300 (epoch 3.779), train_loss = 1.94854209, grad/param norm = 1.9043e-01, time/batch = 0.6916s	
2291/30300 (epoch 3.781), train_loss = 1.83704672, grad/param norm = 2.0628e-01, time/batch = 0.6909s	
2292/30300 (epoch 3.782), train_loss = 1.74798555, grad/param norm = 1.9090e-01, time/batch = 0.6894s	
2293/30300 (epoch 3.784), train_loss = 1.90831184, grad/param norm = 1.9769e-01, time/batch = 0.6939s	
2294/30300 (epoch 3.785), train_loss = 2.02470092, grad/param norm = 1.9365e-01, time/batch = 0.6977s	
2295/30300 (epoch 3.787), train_loss = 1.82208067, grad/param norm = 2.0215e-01, time/batch = 0.7087s	
2296/30300 (epoch 3.789), train_loss = 2.21172379, grad/param norm = 2.0587e-01, time/batch = 0.6921s	
2297/30300 (epoch 3.790), train_loss = 1.98280107, grad/param norm = 1.9124e-01, time/batch = 0.6880s	
2298/30300 (epoch 3.792), train_loss = 1.82625791, grad/param norm = 2.1787e-01, time/batch = 0.6920s	
2299/30300 (epoch 3.794), train_loss = 1.76569057, grad/param norm = 1.9329e-01, time/batch = 0.6868s	
2300/30300 (epoch 3.795), train_loss = 1.84205577, grad/param norm = 1.8989e-01, time/batch = 0.7062s	
2301/30300 (epoch 3.797), train_loss = 1.97162923, grad/param norm = 2.2149e-01, time/batch = 0.6900s	
2302/30300 (epoch 3.799), train_loss = 2.00942521, grad/param norm = 2.5728e-01, time/batch = 0.7099s	
2303/30300 (epoch 3.800), train_loss = 1.89251926, grad/param norm = 2.3881e-01, time/batch = 0.7090s	
2304/30300 (epoch 3.802), train_loss = 2.06339754, grad/param norm = 2.2658e-01, time/batch = 0.6835s	
2305/30300 (epoch 3.804), train_loss = 1.93399707, grad/param norm = 2.3033e-01, time/batch = 0.6831s	
2306/30300 (epoch 3.805), train_loss = 2.01711717, grad/param norm = 2.1223e-01, time/batch = 0.6887s	
2307/30300 (epoch 3.807), train_loss = 1.97117997, grad/param norm = 2.2679e-01, time/batch = 0.6838s	
2308/30300 (epoch 3.809), train_loss = 2.03505352, grad/param norm = 2.1372e-01, time/batch = 0.6988s	
2309/30300 (epoch 3.810), train_loss = 1.96558370, grad/param norm = 2.3424e-01, time/batch = 0.6850s	
2310/30300 (epoch 3.812), train_loss = 1.81299030, grad/param norm = 2.0147e-01, time/batch = 0.6890s	
2311/30300 (epoch 3.814), train_loss = 1.93047628, grad/param norm = 1.9701e-01, time/batch = 0.6827s	
2312/30300 (epoch 3.815), train_loss = 1.89053754, grad/param norm = 2.1543e-01, time/batch = 0.6874s	
2313/30300 (epoch 3.817), train_loss = 1.96151533, grad/param norm = 2.1117e-01, time/batch = 0.6844s	
2314/30300 (epoch 3.818), train_loss = 1.88879613, grad/param norm = 2.0704e-01, time/batch = 0.6851s	
2315/30300 (epoch 3.820), train_loss = 2.13311663, grad/param norm = 2.0996e-01, time/batch = 0.6859s	
2316/30300 (epoch 3.822), train_loss = 2.07949392, grad/param norm = 2.1482e-01, time/batch = 0.6947s	
2317/30300 (epoch 3.823), train_loss = 2.16273413, grad/param norm = 2.3895e-01, time/batch = 0.7209s	
2318/30300 (epoch 3.825), train_loss = 1.96638993, grad/param norm = 2.1063e-01, time/batch = 0.6898s	
2319/30300 (epoch 3.827), train_loss = 1.86027913, grad/param norm = 2.0215e-01, time/batch = 0.6849s	
2320/30300 (epoch 3.828), train_loss = 1.90402457, grad/param norm = 1.7095e-01, time/batch = 0.6836s	
2321/30300 (epoch 3.830), train_loss = 1.90387903, grad/param norm = 2.0455e-01, time/batch = 0.6866s	
2322/30300 (epoch 3.832), train_loss = 1.82842764, grad/param norm = 1.9160e-01, time/batch = 0.6841s	
2323/30300 (epoch 3.833), train_loss = 1.96574990, grad/param norm = 1.9793e-01, time/batch = 0.6849s	
2324/30300 (epoch 3.835), train_loss = 1.89754272, grad/param norm = 2.0288e-01, time/batch = 0.6869s	
2325/30300 (epoch 3.837), train_loss = 1.71249566, grad/param norm = 1.7917e-01, time/batch = 0.6846s	
2326/30300 (epoch 3.838), train_loss = 1.77694399, grad/param norm = 1.8359e-01, time/batch = 0.6877s	
2327/30300 (epoch 3.840), train_loss = 1.82376808, grad/param norm = 1.8477e-01, time/batch = 0.6869s	
2328/30300 (epoch 3.842), train_loss = 1.73058659, grad/param norm = 1.9799e-01, time/batch = 0.6867s	
2329/30300 (epoch 3.843), train_loss = 1.87812218, grad/param norm = 2.3832e-01, time/batch = 0.6863s	
2330/30300 (epoch 3.845), train_loss = 1.71854524, grad/param norm = 1.7616e-01, time/batch = 0.6897s	
2331/30300 (epoch 3.847), train_loss = 1.86603060, grad/param norm = 2.2491e-01, time/batch = 0.6889s	
2332/30300 (epoch 3.848), train_loss = 2.03360075, grad/param norm = 2.1791e-01, time/batch = 0.6914s	
2333/30300 (epoch 3.850), train_loss = 1.76461671, grad/param norm = 1.9990e-01, time/batch = 0.7045s	
2334/30300 (epoch 3.851), train_loss = 2.15110417, grad/param norm = 2.3221e-01, time/batch = 0.6921s	
2335/30300 (epoch 3.853), train_loss = 1.86470648, grad/param norm = 2.1070e-01, time/batch = 0.6898s	
2336/30300 (epoch 3.855), train_loss = 1.79953152, grad/param norm = 2.1693e-01, time/batch = 0.6931s	
2337/30300 (epoch 3.856), train_loss = 1.78863935, grad/param norm = 2.0680e-01, time/batch = 0.6921s	
2338/30300 (epoch 3.858), train_loss = 1.76095501, grad/param norm = 1.8945e-01, time/batch = 0.6971s	
2339/30300 (epoch 3.860), train_loss = 1.90342223, grad/param norm = 2.0534e-01, time/batch = 0.7109s	
2340/30300 (epoch 3.861), train_loss = 2.04075207, grad/param norm = 2.6427e-01, time/batch = 0.6930s	
2341/30300 (epoch 3.863), train_loss = 1.95552663, grad/param norm = 2.2804e-01, time/batch = 0.6878s	
2342/30300 (epoch 3.865), train_loss = 2.19606801, grad/param norm = 2.6209e-01, time/batch = 0.6862s	
2343/30300 (epoch 3.866), train_loss = 1.95449171, grad/param norm = 2.2436e-01, time/batch = 0.6882s	
2344/30300 (epoch 3.868), train_loss = 1.90308264, grad/param norm = 1.8105e-01, time/batch = 0.6977s	
2345/30300 (epoch 3.870), train_loss = 1.82341709, grad/param norm = 1.9624e-01, time/batch = 0.7040s	
2346/30300 (epoch 3.871), train_loss = 1.76459687, grad/param norm = 1.8946e-01, time/batch = 0.6940s	
2347/30300 (epoch 3.873), train_loss = 1.93000917, grad/param norm = 1.9058e-01, time/batch = 0.6853s	
2348/30300 (epoch 3.875), train_loss = 1.71539659, grad/param norm = 1.8258e-01, time/batch = 0.6855s	
2349/30300 (epoch 3.876), train_loss = 1.65990965, grad/param norm = 1.7682e-01, time/batch = 0.6936s	
2350/30300 (epoch 3.878), train_loss = 1.64560958, grad/param norm = 1.9707e-01, time/batch = 0.7221s	
2351/30300 (epoch 3.880), train_loss = 1.73227959, grad/param norm = 1.7653e-01, time/batch = 0.6959s	
2352/30300 (epoch 3.881), train_loss = 2.03134699, grad/param norm = 2.0089e-01, time/batch = 0.6881s	
2353/30300 (epoch 3.883), train_loss = 1.91549305, grad/param norm = 2.0915e-01, time/batch = 0.6903s	
2354/30300 (epoch 3.884), train_loss = 1.74812947, grad/param norm = 1.9968e-01, time/batch = 0.6850s	
2355/30300 (epoch 3.886), train_loss = 1.77432614, grad/param norm = 1.9120e-01, time/batch = 0.6868s	
2356/30300 (epoch 3.888), train_loss = 1.92031470, grad/param norm = 2.2777e-01, time/batch = 0.6866s	
2357/30300 (epoch 3.889), train_loss = 1.84958789, grad/param norm = 2.5533e-01, time/batch = 0.6857s	
2358/30300 (epoch 3.891), train_loss = 1.78574872, grad/param norm = 2.1449e-01, time/batch = 0.6908s	
2359/30300 (epoch 3.893), train_loss = 2.05880481, grad/param norm = 2.2277e-01, time/batch = 0.6875s	
2360/30300 (epoch 3.894), train_loss = 1.92706372, grad/param norm = 2.0224e-01, time/batch = 0.6867s	
2361/30300 (epoch 3.896), train_loss = 1.68633806, grad/param norm = 2.2920e-01, time/batch = 0.6881s	
2362/30300 (epoch 3.898), train_loss = 1.68764201, grad/param norm = 2.0217e-01, time/batch = 0.6883s	
2363/30300 (epoch 3.899), train_loss = 1.80598864, grad/param norm = 2.0017e-01, time/batch = 0.6894s	
2364/30300 (epoch 3.901), train_loss = 1.90274321, grad/param norm = 1.9573e-01, time/batch = 0.7128s	
2365/30300 (epoch 3.903), train_loss = 1.93545538, grad/param norm = 2.1169e-01, time/batch = 0.7085s	
2366/30300 (epoch 3.904), train_loss = 1.83903166, grad/param norm = 1.9730e-01, time/batch = 0.6873s	
2367/30300 (epoch 3.906), train_loss = 1.96773413, grad/param norm = 2.1920e-01, time/batch = 0.6952s	
2368/30300 (epoch 3.908), train_loss = 1.79078493, grad/param norm = 2.0159e-01, time/batch = 0.6935s	
2369/30300 (epoch 3.909), train_loss = 1.90143056, grad/param norm = 1.9883e-01, time/batch = 0.6890s	
2370/30300 (epoch 3.911), train_loss = 1.82399206, grad/param norm = 2.0581e-01, time/batch = 0.6826s	
2371/30300 (epoch 3.913), train_loss = 1.88544137, grad/param norm = 2.0301e-01, time/batch = 0.6897s	
2372/30300 (epoch 3.914), train_loss = 1.91021006, grad/param norm = 2.3766e-01, time/batch = 0.6877s	
2373/30300 (epoch 3.916), train_loss = 1.88573983, grad/param norm = 2.0369e-01, time/batch = 0.6853s	
2374/30300 (epoch 3.917), train_loss = 1.79717330, grad/param norm = 1.9038e-01, time/batch = 0.7142s	
2375/30300 (epoch 3.919), train_loss = 1.89402486, grad/param norm = 1.8657e-01, time/batch = 0.6914s	
2376/30300 (epoch 3.921), train_loss = 1.96191868, grad/param norm = 2.2175e-01, time/batch = 0.6919s	
2377/30300 (epoch 3.922), train_loss = 1.97351217, grad/param norm = 2.1194e-01, time/batch = 0.7037s	
2378/30300 (epoch 3.924), train_loss = 1.86617188, grad/param norm = 2.1760e-01, time/batch = 0.6887s	
2379/30300 (epoch 3.926), train_loss = 1.86007718, grad/param norm = 2.2374e-01, time/batch = 0.6854s	
2380/30300 (epoch 3.927), train_loss = 1.81629091, grad/param norm = 2.2342e-01, time/batch = 0.6849s	
2381/30300 (epoch 3.929), train_loss = 1.89271835, grad/param norm = 2.1032e-01, time/batch = 0.6909s	
2382/30300 (epoch 3.931), train_loss = 1.96362435, grad/param norm = 2.1302e-01, time/batch = 0.6969s	
2383/30300 (epoch 3.932), train_loss = 1.79380590, grad/param norm = 2.0546e-01, time/batch = 0.7011s	
2384/30300 (epoch 3.934), train_loss = 1.84470163, grad/param norm = 1.9746e-01, time/batch = 0.7180s	
2385/30300 (epoch 3.936), train_loss = 1.81739703, grad/param norm = 1.8914e-01, time/batch = 0.7052s	
2386/30300 (epoch 3.937), train_loss = 1.88103247, grad/param norm = 1.9464e-01, time/batch = 0.6957s	
2387/30300 (epoch 3.939), train_loss = 1.98012450, grad/param norm = 1.8743e-01, time/batch = 0.6959s	
2388/30300 (epoch 3.941), train_loss = 1.89196723, grad/param norm = 1.9883e-01, time/batch = 0.6932s	
2389/30300 (epoch 3.942), train_loss = 1.78204283, grad/param norm = 1.8980e-01, time/batch = 0.6902s	
2390/30300 (epoch 3.944), train_loss = 1.71112446, grad/param norm = 1.8336e-01, time/batch = 0.7033s	
2391/30300 (epoch 3.946), train_loss = 2.03600226, grad/param norm = 2.1021e-01, time/batch = 0.6994s	
2392/30300 (epoch 3.947), train_loss = 2.05556270, grad/param norm = 2.0917e-01, time/batch = 0.6990s	
2393/30300 (epoch 3.949), train_loss = 2.11196466, grad/param norm = 2.1136e-01, time/batch = 0.7217s	
2394/30300 (epoch 3.950), train_loss = 2.01395387, grad/param norm = 2.0877e-01, time/batch = 0.6985s	
2395/30300 (epoch 3.952), train_loss = 2.01914097, grad/param norm = 2.2542e-01, time/batch = 0.6942s	
2396/30300 (epoch 3.954), train_loss = 2.09575047, grad/param norm = 1.9418e-01, time/batch = 0.6888s	
2397/30300 (epoch 3.955), train_loss = 1.80915793, grad/param norm = 2.1648e-01, time/batch = 0.6894s	
2398/30300 (epoch 3.957), train_loss = 1.91075359, grad/param norm = 1.9229e-01, time/batch = 0.6889s	
2399/30300 (epoch 3.959), train_loss = 1.89568390, grad/param norm = 2.0165e-01, time/batch = 0.6909s	
2400/30300 (epoch 3.960), train_loss = 1.83552718, grad/param norm = 1.7811e-01, time/batch = 0.6890s	
2401/30300 (epoch 3.962), train_loss = 1.81087010, grad/param norm = 2.1594e-01, time/batch = 0.6909s	
2402/30300 (epoch 3.964), train_loss = 1.92918931, grad/param norm = 2.1164e-01, time/batch = 0.6914s	
2403/30300 (epoch 3.965), train_loss = 1.79754174, grad/param norm = 1.9588e-01, time/batch = 0.6969s	
2404/30300 (epoch 3.967), train_loss = 1.92243991, grad/param norm = 2.1071e-01, time/batch = 0.7008s	
2405/30300 (epoch 3.969), train_loss = 1.86642399, grad/param norm = 2.5556e-01, time/batch = 0.6872s	
2406/30300 (epoch 3.970), train_loss = 1.80697120, grad/param norm = 2.4545e-01, time/batch = 0.6873s	
2407/30300 (epoch 3.972), train_loss = 1.74652000, grad/param norm = 1.8630e-01, time/batch = 0.7143s	
2408/30300 (epoch 3.974), train_loss = 2.03309327, grad/param norm = 1.9972e-01, time/batch = 0.7078s	
2409/30300 (epoch 3.975), train_loss = 2.09072039, grad/param norm = 2.3760e-01, time/batch = 0.6944s	
2410/30300 (epoch 3.977), train_loss = 1.91752945, grad/param norm = 1.9537e-01, time/batch = 0.6909s	
2411/30300 (epoch 3.979), train_loss = 1.95642196, grad/param norm = 2.0459e-01, time/batch = 0.6924s	
2412/30300 (epoch 3.980), train_loss = 1.95068265, grad/param norm = 2.4338e-01, time/batch = 0.6892s	
2413/30300 (epoch 3.982), train_loss = 1.94140676, grad/param norm = 1.9822e-01, time/batch = 0.6884s	
2414/30300 (epoch 3.983), train_loss = 2.00124338, grad/param norm = 1.9969e-01, time/batch = 0.6871s	
2415/30300 (epoch 3.985), train_loss = 1.89380564, grad/param norm = 2.1753e-01, time/batch = 0.6879s	
2416/30300 (epoch 3.987), train_loss = 1.79565900, grad/param norm = 1.7965e-01, time/batch = 0.6888s	
2417/30300 (epoch 3.988), train_loss = 2.02514386, grad/param norm = 2.0746e-01, time/batch = 0.6909s	
2418/30300 (epoch 3.990), train_loss = 1.71320893, grad/param norm = 1.8078e-01, time/batch = 0.6920s	
2419/30300 (epoch 3.992), train_loss = 1.90463654, grad/param norm = 2.0609e-01, time/batch = 0.6903s	
2420/30300 (epoch 3.993), train_loss = 2.05162075, grad/param norm = 2.2802e-01, time/batch = 0.6936s	
2421/30300 (epoch 3.995), train_loss = 1.98160205, grad/param norm = 2.0142e-01, time/batch = 0.6902s	
2422/30300 (epoch 3.997), train_loss = 1.92157448, grad/param norm = 1.9625e-01, time/batch = 0.6894s	
2423/30300 (epoch 3.998), train_loss = 1.95392253, grad/param norm = 2.0666e-01, time/batch = 0.6901s	
2424/30300 (epoch 4.000), train_loss = 1.80623590, grad/param norm = 2.0684e-01, time/batch = 0.6909s	
2425/30300 (epoch 4.002), train_loss = 1.81709227, grad/param norm = 1.8255e-01, time/batch = 0.6896s	
2426/30300 (epoch 4.003), train_loss = 1.91045837, grad/param norm = 2.0724e-01, time/batch = 0.6872s	
2427/30300 (epoch 4.005), train_loss = 1.90779439, grad/param norm = 2.1501e-01, time/batch = 0.6887s	
2428/30300 (epoch 4.007), train_loss = 1.98443922, grad/param norm = 1.9268e-01, time/batch = 0.6910s	
2429/30300 (epoch 4.008), train_loss = 1.80053531, grad/param norm = 1.9572e-01, time/batch = 0.6870s	
2430/30300 (epoch 4.010), train_loss = 1.85478301, grad/param norm = 2.1634e-01, time/batch = 0.6876s	
2431/30300 (epoch 4.012), train_loss = 1.79904734, grad/param norm = 1.9365e-01, time/batch = 0.6864s	
2432/30300 (epoch 4.013), train_loss = 1.94584011, grad/param norm = 1.9936e-01, time/batch = 0.6891s	
2433/30300 (epoch 4.015), train_loss = 1.80985071, grad/param norm = 1.9444e-01, time/batch = 0.6876s	
2434/30300 (epoch 4.017), train_loss = 1.71453721, grad/param norm = 1.9475e-01, time/batch = 0.6877s	
2435/30300 (epoch 4.018), train_loss = 1.95184172, grad/param norm = 1.9185e-01, time/batch = 0.6891s	
2436/30300 (epoch 4.020), train_loss = 2.04965693, grad/param norm = 1.9749e-01, time/batch = 0.6938s	
2437/30300 (epoch 4.021), train_loss = 1.98656733, grad/param norm = 2.1127e-01, time/batch = 0.6920s	
2438/30300 (epoch 4.023), train_loss = 1.75208192, grad/param norm = 1.9916e-01, time/batch = 0.6865s	
2439/30300 (epoch 4.025), train_loss = 1.77060879, grad/param norm = 1.9907e-01, time/batch = 0.6858s	
2440/30300 (epoch 4.026), train_loss = 1.85962125, grad/param norm = 1.9246e-01, time/batch = 0.7070s	
2441/30300 (epoch 4.028), train_loss = 1.85796455, grad/param norm = 1.9466e-01, time/batch = 0.7156s	
2442/30300 (epoch 4.030), train_loss = 1.71966270, grad/param norm = 2.2955e-01, time/batch = 0.6922s	
2443/30300 (epoch 4.031), train_loss = 1.87184778, grad/param norm = 2.2161e-01, time/batch = 0.6945s	
2444/30300 (epoch 4.033), train_loss = 1.83182746, grad/param norm = 2.2330e-01, time/batch = 0.6932s	
2445/30300 (epoch 4.035), train_loss = 1.91062903, grad/param norm = 1.8555e-01, time/batch = 0.7323s	
2446/30300 (epoch 4.036), train_loss = 1.99839222, grad/param norm = 2.0779e-01, time/batch = 0.7249s	
2447/30300 (epoch 4.038), train_loss = 1.87224247, grad/param norm = 2.0113e-01, time/batch = 0.7326s	
2448/30300 (epoch 4.040), train_loss = 1.54121255, grad/param norm = 1.8265e-01, time/batch = 0.7277s	
2449/30300 (epoch 4.041), train_loss = 1.61230306, grad/param norm = 1.8294e-01, time/batch = 0.7249s	
2450/30300 (epoch 4.043), train_loss = 1.94933811, grad/param norm = 2.0102e-01, time/batch = 0.7249s	
2451/30300 (epoch 4.045), train_loss = 1.79954657, grad/param norm = 2.1201e-01, time/batch = 0.7269s	
2452/30300 (epoch 4.046), train_loss = 1.88503283, grad/param norm = 2.2016e-01, time/batch = 0.7300s	
2453/30300 (epoch 4.048), train_loss = 1.88301716, grad/param norm = 2.1575e-01, time/batch = 0.7276s	
2454/30300 (epoch 4.050), train_loss = 1.94276581, grad/param norm = 2.0552e-01, time/batch = 0.7226s	
2455/30300 (epoch 4.051), train_loss = 1.85892299, grad/param norm = 1.9194e-01, time/batch = 0.7191s	
2456/30300 (epoch 4.053), train_loss = 1.76503782, grad/param norm = 2.0515e-01, time/batch = 0.7123s	
2457/30300 (epoch 4.054), train_loss = 1.76060843, grad/param norm = 2.3096e-01, time/batch = 0.7115s	
2458/30300 (epoch 4.056), train_loss = 1.74472846, grad/param norm = 2.0811e-01, time/batch = 0.7152s	
2459/30300 (epoch 4.058), train_loss = 1.91305551, grad/param norm = 2.1645e-01, time/batch = 0.7259s	
2460/30300 (epoch 4.059), train_loss = 1.84018956, grad/param norm = 1.8281e-01, time/batch = 0.7265s	
2461/30300 (epoch 4.061), train_loss = 2.03424121, grad/param norm = 2.2904e-01, time/batch = 0.7288s	
2462/30300 (epoch 4.063), train_loss = 1.82913182, grad/param norm = 2.0639e-01, time/batch = 0.7122s	
2463/30300 (epoch 4.064), train_loss = 1.96564520, grad/param norm = 1.9431e-01, time/batch = 0.7076s	
2464/30300 (epoch 4.066), train_loss = 1.84271585, grad/param norm = 1.7705e-01, time/batch = 0.7036s	
2465/30300 (epoch 4.068), train_loss = 1.72910718, grad/param norm = 1.7089e-01, time/batch = 0.6961s	
2466/30300 (epoch 4.069), train_loss = 1.97559628, grad/param norm = 1.9026e-01, time/batch = 0.6922s	
2467/30300 (epoch 4.071), train_loss = 1.93376824, grad/param norm = 2.3037e-01, time/batch = 0.6867s	
2468/30300 (epoch 4.073), train_loss = 2.00702756, grad/param norm = 2.3129e-01, time/batch = 0.7133s	
2469/30300 (epoch 4.074), train_loss = 1.93858427, grad/param norm = 1.9870e-01, time/batch = 0.7071s	
2470/30300 (epoch 4.076), train_loss = 1.79806314, grad/param norm = 1.8919e-01, time/batch = 0.6890s	
2471/30300 (epoch 4.078), train_loss = 1.70007775, grad/param norm = 2.0829e-01, time/batch = 0.6957s	
2472/30300 (epoch 4.079), train_loss = 1.68999743, grad/param norm = 1.6905e-01, time/batch = 0.7109s	
2473/30300 (epoch 4.081), train_loss = 1.99718964, grad/param norm = 2.1937e-01, time/batch = 0.6941s	
2474/30300 (epoch 4.083), train_loss = 2.09711751, grad/param norm = 2.1696e-01, time/batch = 0.6956s	
2475/30300 (epoch 4.084), train_loss = 1.80971473, grad/param norm = 2.0796e-01, time/batch = 0.6955s	
2476/30300 (epoch 4.086), train_loss = 1.86531493, grad/param norm = 1.9496e-01, time/batch = 0.6911s	
2477/30300 (epoch 4.087), train_loss = 1.74619836, grad/param norm = 1.8067e-01, time/batch = 0.6936s	
2478/30300 (epoch 4.089), train_loss = 1.82862838, grad/param norm = 1.9767e-01, time/batch = 0.6951s	
2479/30300 (epoch 4.091), train_loss = 1.94871418, grad/param norm = 2.0573e-01, time/batch = 0.6879s	
2480/30300 (epoch 4.092), train_loss = 1.77692526, grad/param norm = 2.1860e-01, time/batch = 0.6962s	
2481/30300 (epoch 4.094), train_loss = 2.08308708, grad/param norm = 1.9605e-01, time/batch = 0.6903s	
2482/30300 (epoch 4.096), train_loss = 1.83697044, grad/param norm = 2.0403e-01, time/batch = 0.7061s	
2483/30300 (epoch 4.097), train_loss = 1.71458556, grad/param norm = 2.0346e-01, time/batch = 0.7175s	
2484/30300 (epoch 4.099), train_loss = 2.00610910, grad/param norm = 1.9324e-01, time/batch = 0.6864s	
2485/30300 (epoch 4.101), train_loss = 2.07930234, grad/param norm = 1.9006e-01, time/batch = 0.6875s	
2486/30300 (epoch 4.102), train_loss = 1.91499767, grad/param norm = 1.9760e-01, time/batch = 0.6911s	
2487/30300 (epoch 4.104), train_loss = 1.74519869, grad/param norm = 1.7207e-01, time/batch = 0.6880s	
2488/30300 (epoch 4.106), train_loss = 1.93237084, grad/param norm = 2.1168e-01, time/batch = 0.6906s	
2489/30300 (epoch 4.107), train_loss = 1.83658513, grad/param norm = 2.0769e-01, time/batch = 0.7070s	
2490/30300 (epoch 4.109), train_loss = 1.98382081, grad/param norm = 1.9738e-01, time/batch = 0.7089s	
2491/30300 (epoch 4.111), train_loss = 1.95882440, grad/param norm = 2.1074e-01, time/batch = 0.7103s	
2492/30300 (epoch 4.112), train_loss = 1.89329448, grad/param norm = 1.9803e-01, time/batch = 0.7127s	
2493/30300 (epoch 4.114), train_loss = 1.79658688, grad/param norm = 1.9095e-01, time/batch = 0.7171s	
2494/30300 (epoch 4.116), train_loss = 1.89220618, grad/param norm = 1.8306e-01, time/batch = 0.6952s	
2495/30300 (epoch 4.117), train_loss = 1.80583705, grad/param norm = 1.7460e-01, time/batch = 0.6894s	
2496/30300 (epoch 4.119), train_loss = 1.72702615, grad/param norm = 2.0590e-01, time/batch = 0.6969s	
2497/30300 (epoch 4.120), train_loss = 1.79538951, grad/param norm = 1.8547e-01, time/batch = 0.6991s	
2498/30300 (epoch 4.122), train_loss = 1.90146273, grad/param norm = 1.7343e-01, time/batch = 0.6873s	
2499/30300 (epoch 4.124), train_loss = 2.05370947, grad/param norm = 2.3139e-01, time/batch = 0.6859s	
2500/30300 (epoch 4.125), train_loss = 1.70017460, grad/param norm = 2.0049e-01, time/batch = 0.6881s	
2501/30300 (epoch 4.127), train_loss = 1.85967165, grad/param norm = 1.8825e-01, time/batch = 0.6933s	
2502/30300 (epoch 4.129), train_loss = 1.96736738, grad/param norm = 1.9071e-01, time/batch = 0.6968s	
2503/30300 (epoch 4.130), train_loss = 1.99622633, grad/param norm = 2.0438e-01, time/batch = 0.6928s	
2504/30300 (epoch 4.132), train_loss = 1.85561088, grad/param norm = 2.0525e-01, time/batch = 0.6880s	
2505/30300 (epoch 4.134), train_loss = 1.72100832, grad/param norm = 2.0924e-01, time/batch = 0.6897s	
2506/30300 (epoch 4.135), train_loss = 1.83865636, grad/param norm = 1.9841e-01, time/batch = 0.6886s	
2507/30300 (epoch 4.137), train_loss = 1.99057726, grad/param norm = 2.0899e-01, time/batch = 0.6905s	
2508/30300 (epoch 4.139), train_loss = 1.85710120, grad/param norm = 2.2983e-01, time/batch = 0.6940s	
2509/30300 (epoch 4.140), train_loss = 2.13253170, grad/param norm = 3.0251e-01, time/batch = 0.6905s	
2510/30300 (epoch 4.142), train_loss = 2.09907631, grad/param norm = 2.5215e-01, time/batch = 0.6924s	
2511/30300 (epoch 4.144), train_loss = 1.93290424, grad/param norm = 2.0535e-01, time/batch = 0.6918s	
2512/30300 (epoch 4.145), train_loss = 2.02290674, grad/param norm = 1.8245e-01, time/batch = 0.6889s	
2513/30300 (epoch 4.147), train_loss = 1.89973421, grad/param norm = 1.9282e-01, time/batch = 0.6918s	
2514/30300 (epoch 4.149), train_loss = 2.08509156, grad/param norm = 2.0651e-01, time/batch = 0.7012s	
2515/30300 (epoch 4.150), train_loss = 2.05478150, grad/param norm = 1.9279e-01, time/batch = 0.6984s	
2516/30300 (epoch 4.152), train_loss = 1.86948242, grad/param norm = 2.2826e-01, time/batch = 0.6943s	
2517/30300 (epoch 4.153), train_loss = 1.93533746, grad/param norm = 2.1991e-01, time/batch = 0.6921s	
2518/30300 (epoch 4.155), train_loss = 1.65279085, grad/param norm = 1.8593e-01, time/batch = 0.6913s	
2519/30300 (epoch 4.157), train_loss = 1.86771921, grad/param norm = 1.8098e-01, time/batch = 0.6897s	
2520/30300 (epoch 4.158), train_loss = 1.93358154, grad/param norm = 2.0084e-01, time/batch = 0.6893s	
2521/30300 (epoch 4.160), train_loss = 1.76969622, grad/param norm = 2.0089e-01, time/batch = 0.6890s	
2522/30300 (epoch 4.162), train_loss = 1.76554464, grad/param norm = 2.1207e-01, time/batch = 0.6854s	
2523/30300 (epoch 4.163), train_loss = 1.77049076, grad/param norm = 2.2860e-01, time/batch = 0.6924s	
2524/30300 (epoch 4.165), train_loss = 1.89035066, grad/param norm = 2.0477e-01, time/batch = 0.6886s	
2525/30300 (epoch 4.167), train_loss = 1.90871199, grad/param norm = 2.1134e-01, time/batch = 0.7050s	
2526/30300 (epoch 4.168), train_loss = 1.77967853, grad/param norm = 2.0279e-01, time/batch = 0.7178s	
2527/30300 (epoch 4.170), train_loss = 1.89460744, grad/param norm = 2.1625e-01, time/batch = 0.6889s	
2528/30300 (epoch 4.172), train_loss = 1.80223480, grad/param norm = 1.9089e-01, time/batch = 0.6907s	
2529/30300 (epoch 4.173), train_loss = 1.94547676, grad/param norm = 1.9444e-01, time/batch = 0.6886s	
2530/30300 (epoch 4.175), train_loss = 1.83443615, grad/param norm = 1.8414e-01, time/batch = 0.6887s	
2531/30300 (epoch 4.177), train_loss = 1.90125223, grad/param norm = 1.8783e-01, time/batch = 0.6861s	
2532/30300 (epoch 4.178), train_loss = 1.66234726, grad/param norm = 1.8229e-01, time/batch = 0.6877s	
2533/30300 (epoch 4.180), train_loss = 1.79204752, grad/param norm = 1.8209e-01, time/batch = 0.6867s	
2534/30300 (epoch 4.182), train_loss = 1.78255610, grad/param norm = 1.9743e-01, time/batch = 0.6888s	
2535/30300 (epoch 4.183), train_loss = 1.72563547, grad/param norm = 1.8053e-01, time/batch = 0.6866s	
2536/30300 (epoch 4.185), train_loss = 2.19947337, grad/param norm = 2.3002e-01, time/batch = 0.6873s	
2537/30300 (epoch 4.186), train_loss = 2.08708637, grad/param norm = 2.1619e-01, time/batch = 0.6911s	
2538/30300 (epoch 4.188), train_loss = 1.88052243, grad/param norm = 1.9368e-01, time/batch = 0.6860s	
2539/30300 (epoch 4.190), train_loss = 1.74312218, grad/param norm = 1.8529e-01, time/batch = 0.6923s	
2540/30300 (epoch 4.191), train_loss = 1.96860084, grad/param norm = 2.0696e-01, time/batch = 0.7206s	
2541/30300 (epoch 4.193), train_loss = 1.71721744, grad/param norm = 1.9595e-01, time/batch = 0.6995s	
2542/30300 (epoch 4.195), train_loss = 1.92359144, grad/param norm = 2.2797e-01, time/batch = 0.6929s	
2543/30300 (epoch 4.196), train_loss = 1.97402782, grad/param norm = 2.4563e-01, time/batch = 0.7013s	
2544/30300 (epoch 4.198), train_loss = 1.64282998, grad/param norm = 1.9408e-01, time/batch = 0.6912s	
2545/30300 (epoch 4.200), train_loss = 1.79853452, grad/param norm = 2.1730e-01, time/batch = 0.7076s	
2546/30300 (epoch 4.201), train_loss = 2.00217045, grad/param norm = 2.1089e-01, time/batch = 0.7036s	
2547/30300 (epoch 4.203), train_loss = 1.81470255, grad/param norm = 1.8128e-01, time/batch = 1.5193s	
2548/30300 (epoch 4.205), train_loss = 2.09828545, grad/param norm = 1.9523e-01, time/batch = 0.7139s	
2549/30300 (epoch 4.206), train_loss = 2.11926178, grad/param norm = 2.1079e-01, time/batch = 0.6909s	
2550/30300 (epoch 4.208), train_loss = 2.04999599, grad/param norm = 2.2137e-01, time/batch = 0.7082s	
2551/30300 (epoch 4.210), train_loss = 1.89133936, grad/param norm = 1.9587e-01, time/batch = 0.7309s	
2552/30300 (epoch 4.211), train_loss = 1.88475556, grad/param norm = 2.0250e-01, time/batch = 0.7242s	
2553/30300 (epoch 4.213), train_loss = 1.82704582, grad/param norm = 2.0914e-01, time/batch = 0.7712s	
2554/30300 (epoch 4.215), train_loss = 1.64543237, grad/param norm = 1.8866e-01, time/batch = 0.7011s	
2555/30300 (epoch 4.216), train_loss = 1.84609672, grad/param norm = 2.1160e-01, time/batch = 0.6866s	
2556/30300 (epoch 4.218), train_loss = 1.77238419, grad/param norm = 1.8532e-01, time/batch = 0.6891s	
2557/30300 (epoch 4.219), train_loss = 1.69541745, grad/param norm = 1.9767e-01, time/batch = 0.6880s	
2558/30300 (epoch 4.221), train_loss = 1.68585040, grad/param norm = 1.8978e-01, time/batch = 0.6867s	
