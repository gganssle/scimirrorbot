tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 676, val: 36, test: 0	
vocab size: 145	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 291601	
cloning rnn	
cloning criterion	
1/33800 (epoch 0.001), train_loss = 4.97323802, grad/param norm = 6.2935e-01, time/batch = 0.7394s	
2/33800 (epoch 0.003), train_loss = 4.75755777, grad/param norm = 1.1813e+00, time/batch = 0.6949s	
3/33800 (epoch 0.004), train_loss = 3.92718744, grad/param norm = 1.6134e+00, time/batch = 0.6946s	
4/33800 (epoch 0.006), train_loss = 3.47037525, grad/param norm = 9.7750e-01, time/batch = 0.6947s	
5/33800 (epoch 0.007), train_loss = 3.53671501, grad/param norm = 7.6782e-01, time/batch = 0.6913s	
6/33800 (epoch 0.009), train_loss = 3.44099479, grad/param norm = 6.0837e-01, time/batch = 0.6926s	
7/33800 (epoch 0.010), train_loss = 3.28333563, grad/param norm = 7.2176e-01, time/batch = 0.6920s	
8/33800 (epoch 0.012), train_loss = 3.32103478, grad/param norm = 7.9695e-01, time/batch = 0.7062s	
9/33800 (epoch 0.013), train_loss = 3.40267134, grad/param norm = 7.6607e-01, time/batch = 0.7040s	
10/33800 (epoch 0.015), train_loss = 3.24861832, grad/param norm = 6.0638e-01, time/batch = 0.6899s	
11/33800 (epoch 0.016), train_loss = 3.25787581, grad/param norm = 7.2195e-01, time/batch = 0.6896s	
12/33800 (epoch 0.018), train_loss = 3.14805181, grad/param norm = 5.4422e-01, time/batch = 0.6909s	
13/33800 (epoch 0.019), train_loss = 3.27327917, grad/param norm = 6.0272e-01, time/batch = 0.6949s	
14/33800 (epoch 0.021), train_loss = 3.34350518, grad/param norm = 8.7004e-01, time/batch = 0.6920s	
15/33800 (epoch 0.022), train_loss = 3.34346037, grad/param norm = 7.9575e-01, time/batch = 0.6925s	
16/33800 (epoch 0.024), train_loss = 3.13153598, grad/param norm = 6.1556e-01, time/batch = 0.6900s	
17/33800 (epoch 0.025), train_loss = 3.27568024, grad/param norm = 7.2058e-01, time/batch = 0.6960s	
18/33800 (epoch 0.027), train_loss = 3.33351010, grad/param norm = 8.3734e-01, time/batch = 0.7087s	
19/33800 (epoch 0.028), train_loss = 3.20951851, grad/param norm = 8.4891e-01, time/batch = 0.7336s	
20/33800 (epoch 0.030), train_loss = 3.37270466, grad/param norm = 1.0090e+00, time/batch = 0.7468s	
21/33800 (epoch 0.031), train_loss = 3.19260898, grad/param norm = 7.9168e-01, time/batch = 0.7276s	
22/33800 (epoch 0.033), train_loss = 3.28567153, grad/param norm = 4.8614e-01, time/batch = 0.7214s	
23/33800 (epoch 0.034), train_loss = 3.30265235, grad/param norm = 4.7625e-01, time/batch = 0.7395s	
24/33800 (epoch 0.036), train_loss = 3.35871968, grad/param norm = 9.0361e-01, time/batch = 0.7366s	
25/33800 (epoch 0.037), train_loss = 3.34306237, grad/param norm = 7.5623e-01, time/batch = 0.7154s	
26/33800 (epoch 0.038), train_loss = 3.33186358, grad/param norm = 6.1741e-01, time/batch = 0.7241s	
27/33800 (epoch 0.040), train_loss = 3.23545361, grad/param norm = 7.8618e-01, time/batch = 0.7099s	
28/33800 (epoch 0.041), train_loss = 3.47523878, grad/param norm = 7.8629e-01, time/batch = 0.7102s	
29/33800 (epoch 0.043), train_loss = 3.27886987, grad/param norm = 5.9678e-01, time/batch = 0.7144s	
30/33800 (epoch 0.044), train_loss = 3.22224337, grad/param norm = 6.5319e-01, time/batch = 0.7094s	
31/33800 (epoch 0.046), train_loss = 3.17099375, grad/param norm = 6.0014e-01, time/batch = 0.7120s	
32/33800 (epoch 0.047), train_loss = 3.34035808, grad/param norm = 7.5541e-01, time/batch = 0.7003s	
33/33800 (epoch 0.049), train_loss = 3.29809177, grad/param norm = 6.3075e-01, time/batch = 0.6914s	
34/33800 (epoch 0.050), train_loss = 3.44762369, grad/param norm = 5.7007e-01, time/batch = 0.6878s	
35/33800 (epoch 0.052), train_loss = 3.25114084, grad/param norm = 9.4774e-01, time/batch = 0.6897s	
36/33800 (epoch 0.053), train_loss = 3.30891506, grad/param norm = 9.9728e-01, time/batch = 0.6897s	
37/33800 (epoch 0.055), train_loss = 3.23833648, grad/param norm = 9.1872e-01, time/batch = 0.6905s	
38/33800 (epoch 0.056), train_loss = 3.18264397, grad/param norm = 7.7134e-01, time/batch = 0.6865s	
39/33800 (epoch 0.058), train_loss = 3.32917740, grad/param norm = 6.7119e-01, time/batch = 0.6907s	
40/33800 (epoch 0.059), train_loss = 3.14915716, grad/param norm = 4.9437e-01, time/batch = 0.6929s	
41/33800 (epoch 0.061), train_loss = 3.34172159, grad/param norm = 7.1091e-01, time/batch = 0.6934s	
42/33800 (epoch 0.062), train_loss = 3.18499898, grad/param norm = 5.2297e-01, time/batch = 0.6908s	
43/33800 (epoch 0.064), train_loss = 3.49562120, grad/param norm = 7.5274e-01, time/batch = 0.6903s	
44/33800 (epoch 0.065), train_loss = 3.24322452, grad/param norm = 7.3205e-01, time/batch = 0.6902s	
45/33800 (epoch 0.067), train_loss = 3.27703981, grad/param norm = 5.5395e-01, time/batch = 0.6918s	
46/33800 (epoch 0.068), train_loss = 3.29712440, grad/param norm = 6.6716e-01, time/batch = 0.6846s	
47/33800 (epoch 0.070), train_loss = 3.35021351, grad/param norm = 5.6751e-01, time/batch = 0.6901s	
48/33800 (epoch 0.071), train_loss = 3.31802435, grad/param norm = 6.1281e-01, time/batch = 0.6897s	
49/33800 (epoch 0.072), train_loss = 3.29332829, grad/param norm = 5.4431e-01, time/batch = 0.6868s	
50/33800 (epoch 0.074), train_loss = 3.39394745, grad/param norm = 7.7084e-01, time/batch = 0.6871s	
51/33800 (epoch 0.075), train_loss = 3.29684880, grad/param norm = 8.0203e-01, time/batch = 0.6864s	
52/33800 (epoch 0.077), train_loss = 3.24736114, grad/param norm = 5.9823e-01, time/batch = 0.6852s	
53/33800 (epoch 0.078), train_loss = 3.22873587, grad/param norm = 5.6245e-01, time/batch = 0.6826s	
54/33800 (epoch 0.080), train_loss = 3.23398924, grad/param norm = 5.2318e-01, time/batch = 0.6862s	
55/33800 (epoch 0.081), train_loss = 3.31153712, grad/param norm = 5.7214e-01, time/batch = 0.6876s	
56/33800 (epoch 0.083), train_loss = 3.22833515, grad/param norm = 6.2575e-01, time/batch = 0.6853s	
57/33800 (epoch 0.084), train_loss = 3.24961730, grad/param norm = 6.9445e-01, time/batch = 0.6845s	
58/33800 (epoch 0.086), train_loss = 3.21237754, grad/param norm = 7.2367e-01, time/batch = 0.6850s	
59/33800 (epoch 0.087), train_loss = 3.48218984, grad/param norm = 6.1497e-01, time/batch = 0.6870s	
60/33800 (epoch 0.089), train_loss = 3.35453816, grad/param norm = 8.9001e-01, time/batch = 0.6909s	
61/33800 (epoch 0.090), train_loss = 3.31234641, grad/param norm = 6.4352e-01, time/batch = 0.6862s	
62/33800 (epoch 0.092), train_loss = 3.31190794, grad/param norm = 5.3456e-01, time/batch = 0.6838s	
63/33800 (epoch 0.093), train_loss = 3.31606152, grad/param norm = 4.8926e-01, time/batch = 0.6842s	
64/33800 (epoch 0.095), train_loss = 3.28479353, grad/param norm = 6.5765e-01, time/batch = 0.6922s	
65/33800 (epoch 0.096), train_loss = 3.21911687, grad/param norm = 7.4246e-01, time/batch = 0.6848s	
66/33800 (epoch 0.098), train_loss = 3.18721489, grad/param norm = 5.8006e-01, time/batch = 0.6857s	
67/33800 (epoch 0.099), train_loss = 3.34862350, grad/param norm = 7.2936e-01, time/batch = 0.6848s	
68/33800 (epoch 0.101), train_loss = 3.17758316, grad/param norm = 5.7916e-01, time/batch = 0.6871s	
69/33800 (epoch 0.102), train_loss = 3.36604569, grad/param norm = 6.5637e-01, time/batch = 0.6854s	
70/33800 (epoch 0.104), train_loss = 3.28647634, grad/param norm = 7.5277e-01, time/batch = 0.6893s	
71/33800 (epoch 0.105), train_loss = 3.29153105, grad/param norm = 7.6391e-01, time/batch = 0.6973s	
72/33800 (epoch 0.107), train_loss = 3.23281943, grad/param norm = 4.3264e-01, time/batch = 0.7080s	
73/33800 (epoch 0.108), train_loss = 3.20382054, grad/param norm = 6.3591e-01, time/batch = 0.7214s	
74/33800 (epoch 0.109), train_loss = 3.29138377, grad/param norm = 6.2048e-01, time/batch = 0.7475s	
75/33800 (epoch 0.111), train_loss = 3.22609133, grad/param norm = 5.1992e-01, time/batch = 0.7029s	
76/33800 (epoch 0.112), train_loss = 3.15661401, grad/param norm = 5.0453e-01, time/batch = 0.6951s	
77/33800 (epoch 0.114), train_loss = 3.34693869, grad/param norm = 9.1809e-01, time/batch = 0.6917s	
78/33800 (epoch 0.115), train_loss = 3.24624347, grad/param norm = 8.8771e-01, time/batch = 0.6896s	
79/33800 (epoch 0.117), train_loss = 3.40734056, grad/param norm = 5.1695e-01, time/batch = 0.6906s	
80/33800 (epoch 0.118), train_loss = 3.32163045, grad/param norm = 6.1327e-01, time/batch = 0.6928s	
81/33800 (epoch 0.120), train_loss = 3.35735562, grad/param norm = 5.8779e-01, time/batch = 0.6979s	
82/33800 (epoch 0.121), train_loss = 3.22115467, grad/param norm = 5.3361e-01, time/batch = 0.7145s	
83/33800 (epoch 0.123), train_loss = 3.23498997, grad/param norm = 4.3639e-01, time/batch = 0.7055s	
84/33800 (epoch 0.124), train_loss = 3.11226517, grad/param norm = 5.4256e-01, time/batch = 0.6999s	
85/33800 (epoch 0.126), train_loss = 3.48078480, grad/param norm = 9.9990e-01, time/batch = 0.6893s	
86/33800 (epoch 0.127), train_loss = 3.35023516, grad/param norm = 8.2499e-01, time/batch = 0.6897s	
87/33800 (epoch 0.129), train_loss = 3.38850882, grad/param norm = 6.9989e-01, time/batch = 0.6900s	
88/33800 (epoch 0.130), train_loss = 3.22424343, grad/param norm = 6.0432e-01, time/batch = 0.6997s	
89/33800 (epoch 0.132), train_loss = 3.28077190, grad/param norm = 4.7231e-01, time/batch = 0.6907s	
90/33800 (epoch 0.133), train_loss = 3.24536989, grad/param norm = 5.4328e-01, time/batch = 0.6910s	
91/33800 (epoch 0.135), train_loss = 3.22089123, grad/param norm = 6.9141e-01, time/batch = 0.6925s	
92/33800 (epoch 0.136), train_loss = 3.28929919, grad/param norm = 5.8831e-01, time/batch = 0.6897s	
93/33800 (epoch 0.138), train_loss = 3.28191936, grad/param norm = 4.8104e-01, time/batch = 0.6859s	
94/33800 (epoch 0.139), train_loss = 3.24780899, grad/param norm = 4.8752e-01, time/batch = 0.6866s	
95/33800 (epoch 0.141), train_loss = 3.17459020, grad/param norm = 5.3906e-01, time/batch = 0.6880s	
96/33800 (epoch 0.142), train_loss = 3.23273254, grad/param norm = 5.5010e-01, time/batch = 0.6887s	
97/33800 (epoch 0.143), train_loss = 3.28439411, grad/param norm = 5.2663e-01, time/batch = 0.6914s	
98/33800 (epoch 0.145), train_loss = 3.19744708, grad/param norm = 4.2483e-01, time/batch = 0.6923s	
99/33800 (epoch 0.146), train_loss = 3.21502880, grad/param norm = 6.5859e-01, time/batch = 0.6920s	
100/33800 (epoch 0.148), train_loss = 3.18770111, grad/param norm = 6.6379e-01, time/batch = 0.6938s	
101/33800 (epoch 0.149), train_loss = 3.16615815, grad/param norm = 9.0512e-01, time/batch = 0.6954s	
102/33800 (epoch 0.151), train_loss = 3.11045599, grad/param norm = 1.5475e+00, time/batch = 0.6894s	
103/33800 (epoch 0.152), train_loss = 3.19742920, grad/param norm = 8.8175e-01, time/batch = 0.6896s	
104/33800 (epoch 0.154), train_loss = 3.20030344, grad/param norm = 5.8373e-01, time/batch = 0.6908s	
105/33800 (epoch 0.155), train_loss = 3.10629194, grad/param norm = 5.7093e-01, time/batch = 0.6888s	
106/33800 (epoch 0.157), train_loss = 3.05582926, grad/param norm = 4.8549e-01, time/batch = 0.6904s	
107/33800 (epoch 0.158), train_loss = 3.04506951, grad/param norm = 5.8470e-01, time/batch = 0.6904s	
108/33800 (epoch 0.160), train_loss = 3.10624326, grad/param norm = 5.7399e-01, time/batch = 0.6891s	
109/33800 (epoch 0.161), train_loss = 3.22545946, grad/param norm = 6.8344e-01, time/batch = 0.6887s	
110/33800 (epoch 0.163), train_loss = 3.18891214, grad/param norm = 7.3470e-01, time/batch = 0.6892s	
111/33800 (epoch 0.164), train_loss = 3.09848385, grad/param norm = 8.4590e-01, time/batch = 0.6893s	
112/33800 (epoch 0.166), train_loss = 3.10282490, grad/param norm = 6.3517e-01, time/batch = 0.6894s	
113/33800 (epoch 0.167), train_loss = 3.16715711, grad/param norm = 6.6411e-01, time/batch = 0.6901s	
114/33800 (epoch 0.169), train_loss = 3.07468004, grad/param norm = 6.2078e-01, time/batch = 0.6914s	
115/33800 (epoch 0.170), train_loss = 3.16789695, grad/param norm = 6.7928e-01, time/batch = 0.6914s	
116/33800 (epoch 0.172), train_loss = 3.13367676, grad/param norm = 5.8400e-01, time/batch = 0.6988s	
117/33800 (epoch 0.173), train_loss = 3.05623294, grad/param norm = 6.3562e-01, time/batch = 0.6986s	
118/33800 (epoch 0.175), train_loss = 3.17383645, grad/param norm = 6.8388e-01, time/batch = 0.6950s	
119/33800 (epoch 0.176), train_loss = 3.04665307, grad/param norm = 8.0327e-01, time/batch = 0.7034s	
120/33800 (epoch 0.178), train_loss = 3.20954495, grad/param norm = 1.1672e+00, time/batch = 0.6947s	
121/33800 (epoch 0.179), train_loss = 3.16648410, grad/param norm = 1.0543e+00, time/batch = 0.6917s	
122/33800 (epoch 0.180), train_loss = 3.00934133, grad/param norm = 5.1946e-01, time/batch = 0.6814s	
123/33800 (epoch 0.182), train_loss = 3.13803088, grad/param norm = 4.3927e-01, time/batch = 0.6810s	
124/33800 (epoch 0.183), train_loss = 3.11692453, grad/param norm = 5.1395e-01, time/batch = 0.6749s	
125/33800 (epoch 0.185), train_loss = 3.05455059, grad/param norm = 5.4960e-01, time/batch = 0.6803s	
126/33800 (epoch 0.186), train_loss = 3.11870828, grad/param norm = 5.7322e-01, time/batch = 0.6791s	
127/33800 (epoch 0.188), train_loss = 3.22121805, grad/param norm = 5.5472e-01, time/batch = 0.6760s	
128/33800 (epoch 0.189), train_loss = 2.99453562, grad/param norm = 5.4881e-01, time/batch = 0.6769s	
129/33800 (epoch 0.191), train_loss = 3.00900681, grad/param norm = 4.9112e-01, time/batch = 0.6798s	
130/33800 (epoch 0.192), train_loss = 2.96384123, grad/param norm = 5.3869e-01, time/batch = 0.6773s	
131/33800 (epoch 0.194), train_loss = 3.04141808, grad/param norm = 4.3579e-01, time/batch = 0.6811s	
132/33800 (epoch 0.195), train_loss = 2.93343372, grad/param norm = 3.6444e-01, time/batch = 0.6941s	
133/33800 (epoch 0.197), train_loss = 2.93161131, grad/param norm = 5.3422e-01, time/batch = 0.7009s	
134/33800 (epoch 0.198), train_loss = 2.98663176, grad/param norm = 6.4346e-01, time/batch = 0.6848s	
135/33800 (epoch 0.200), train_loss = 2.95165735, grad/param norm = 9.2361e-01, time/batch = 0.7023s	
136/33800 (epoch 0.201), train_loss = 3.08295461, grad/param norm = 1.1311e+00, time/batch = 0.6930s	
137/33800 (epoch 0.203), train_loss = 3.09489108, grad/param norm = 1.5645e+00, time/batch = 0.6911s	
138/33800 (epoch 0.204), train_loss = 3.04183067, grad/param norm = 1.7766e+00, time/batch = 0.6922s	
139/33800 (epoch 0.206), train_loss = 3.01464931, grad/param norm = 1.5355e+00, time/batch = 0.6915s	
140/33800 (epoch 0.207), train_loss = 3.16442143, grad/param norm = 6.2830e-01, time/batch = 0.6918s	
141/33800 (epoch 0.209), train_loss = 2.86247342, grad/param norm = 4.6914e-01, time/batch = 0.6991s	
142/33800 (epoch 0.210), train_loss = 2.89025913, grad/param norm = 3.1775e-01, time/batch = 0.6939s	
143/33800 (epoch 0.212), train_loss = 3.01215169, grad/param norm = 4.0410e-01, time/batch = 0.6892s	
144/33800 (epoch 0.213), train_loss = 2.94423571, grad/param norm = 5.6857e-01, time/batch = 0.6903s	
145/33800 (epoch 0.214), train_loss = 2.94866252, grad/param norm = 5.9673e-01, time/batch = 0.6915s	
146/33800 (epoch 0.216), train_loss = 2.83785261, grad/param norm = 4.3975e-01, time/batch = 0.6891s	
147/33800 (epoch 0.217), train_loss = 2.86495028, grad/param norm = 4.8467e-01, time/batch = 0.6912s	
148/33800 (epoch 0.219), train_loss = 2.93321998, grad/param norm = 4.9511e-01, time/batch = 0.6893s	
149/33800 (epoch 0.220), train_loss = 2.86160332, grad/param norm = 4.8889e-01, time/batch = 0.6888s	
150/33800 (epoch 0.222), train_loss = 2.95486469, grad/param norm = 4.1939e-01, time/batch = 0.6943s	
151/33800 (epoch 0.223), train_loss = 2.81732329, grad/param norm = 7.2491e-01, time/batch = 0.6965s	
152/33800 (epoch 0.225), train_loss = 2.91232399, grad/param norm = 1.4465e+00, time/batch = 0.6915s	
153/33800 (epoch 0.226), train_loss = 3.06848794, grad/param norm = 1.3882e+00, time/batch = 0.6908s	
154/33800 (epoch 0.228), train_loss = 2.97344969, grad/param norm = 1.2859e+00, time/batch = 0.6924s	
155/33800 (epoch 0.229), train_loss = 2.84426450, grad/param norm = 9.5050e-01, time/batch = 0.7000s	
156/33800 (epoch 0.231), train_loss = 2.87361591, grad/param norm = 8.6059e-01, time/batch = 0.6936s	
157/33800 (epoch 0.232), train_loss = 2.82394560, grad/param norm = 7.4124e-01, time/batch = 0.7019s	
158/33800 (epoch 0.234), train_loss = 2.82212855, grad/param norm = 7.4662e-01, time/batch = 0.7108s	
159/33800 (epoch 0.235), train_loss = 2.75266068, grad/param norm = 7.1326e-01, time/batch = 0.7118s	
160/33800 (epoch 0.237), train_loss = 2.85845764, grad/param norm = 7.6406e-01, time/batch = 0.7095s	
161/33800 (epoch 0.238), train_loss = 2.80761027, grad/param norm = 4.7210e-01, time/batch = 0.7032s	
162/33800 (epoch 0.240), train_loss = 2.73482109, grad/param norm = 4.7189e-01, time/batch = 0.6966s	
163/33800 (epoch 0.241), train_loss = 2.86240260, grad/param norm = 4.4647e-01, time/batch = 0.6964s	
164/33800 (epoch 0.243), train_loss = 2.72887151, grad/param norm = 5.0752e-01, time/batch = 0.7020s	
165/33800 (epoch 0.244), train_loss = 2.82127664, grad/param norm = 4.5337e-01, time/batch = 0.7020s	
166/33800 (epoch 0.246), train_loss = 2.82045242, grad/param norm = 5.2557e-01, time/batch = 0.7040s	
167/33800 (epoch 0.247), train_loss = 2.83047279, grad/param norm = 7.9639e-01, time/batch = 0.6999s	
168/33800 (epoch 0.249), train_loss = 2.97851912, grad/param norm = 1.3275e+00, time/batch = 0.6989s	
169/33800 (epoch 0.250), train_loss = 3.00713316, grad/param norm = 1.5064e+00, time/batch = 0.7367s	
170/33800 (epoch 0.251), train_loss = 3.29083855, grad/param norm = 1.2125e+00, time/batch = 0.7033s	
171/33800 (epoch 0.253), train_loss = 3.02576456, grad/param norm = 1.6166e+00, time/batch = 0.7007s	
172/33800 (epoch 0.254), train_loss = 3.02769232, grad/param norm = 9.8800e-01, time/batch = 0.6992s	
173/33800 (epoch 0.256), train_loss = 2.80522330, grad/param norm = 6.5991e-01, time/batch = 0.6936s	
174/33800 (epoch 0.257), train_loss = 2.88230529, grad/param norm = 3.8434e-01, time/batch = 0.6980s	
175/33800 (epoch 0.259), train_loss = 2.69091942, grad/param norm = 2.8870e-01, time/batch = 0.6918s	
176/33800 (epoch 0.260), train_loss = 2.64053225, grad/param norm = 3.7015e-01, time/batch = 0.6851s	
177/33800 (epoch 0.262), train_loss = 2.84455357, grad/param norm = 4.8319e-01, time/batch = 0.6865s	
178/33800 (epoch 0.263), train_loss = 2.90616376, grad/param norm = 3.4997e-01, time/batch = 0.6902s	
179/33800 (epoch 0.265), train_loss = 2.81574344, grad/param norm = 3.7100e-01, time/batch = 0.6865s	
180/33800 (epoch 0.266), train_loss = 2.83610851, grad/param norm = 4.9276e-01, time/batch = 0.6849s	
181/33800 (epoch 0.268), train_loss = 2.77597403, grad/param norm = 7.2008e-01, time/batch = 0.6886s	
182/33800 (epoch 0.269), train_loss = 2.78323625, grad/param norm = 1.0721e+00, time/batch = 0.6845s	
183/33800 (epoch 0.271), train_loss = 2.79145303, grad/param norm = 1.0484e+00, time/batch = 0.6867s	
184/33800 (epoch 0.272), train_loss = 2.81877406, grad/param norm = 8.2018e-01, time/batch = 0.6881s	
185/33800 (epoch 0.274), train_loss = 2.84687379, grad/param norm = 6.8933e-01, time/batch = 0.6906s	
186/33800 (epoch 0.275), train_loss = 2.77745271, grad/param norm = 4.7752e-01, time/batch = 0.7164s	
187/33800 (epoch 0.277), train_loss = 2.72398663, grad/param norm = 5.2360e-01, time/batch = 0.7216s	
188/33800 (epoch 0.278), train_loss = 2.79951033, grad/param norm = 5.2438e-01, time/batch = 0.7015s	
189/33800 (epoch 0.280), train_loss = 2.65961727, grad/param norm = 7.8419e-01, time/batch = 0.7005s	
190/33800 (epoch 0.281), train_loss = 2.73366466, grad/param norm = 8.1712e-01, time/batch = 0.6954s	
191/33800 (epoch 0.283), train_loss = 2.73106340, grad/param norm = 9.2812e-01, time/batch = 0.6936s	
192/33800 (epoch 0.284), train_loss = 2.78697016, grad/param norm = 8.9862e-01, time/batch = 0.6891s	
193/33800 (epoch 0.286), train_loss = 2.81807172, grad/param norm = 6.4716e-01, time/batch = 0.6874s	
194/33800 (epoch 0.287), train_loss = 2.69327650, grad/param norm = 5.6866e-01, time/batch = 0.6896s	
195/33800 (epoch 0.288), train_loss = 2.68987207, grad/param norm = 6.5731e-01, time/batch = 0.6884s	
196/33800 (epoch 0.290), train_loss = 2.67411322, grad/param norm = 7.8696e-01, time/batch = 0.6872s	
197/33800 (epoch 0.291), train_loss = 2.86900503, grad/param norm = 9.2634e-01, time/batch = 0.6845s	
198/33800 (epoch 0.293), train_loss = 2.77796073, grad/param norm = 1.0676e+00, time/batch = 0.6818s	
199/33800 (epoch 0.294), train_loss = 3.03452354, grad/param norm = 1.0710e+00, time/batch = 0.6844s	
200/33800 (epoch 0.296), train_loss = 2.80979473, grad/param norm = 6.9343e-01, time/batch = 0.6851s	
201/33800 (epoch 0.297), train_loss = 2.78331394, grad/param norm = 3.5801e-01, time/batch = 0.6877s	
202/33800 (epoch 0.299), train_loss = 2.70942494, grad/param norm = 4.0650e-01, time/batch = 0.6914s	
203/33800 (epoch 0.300), train_loss = 2.77915927, grad/param norm = 3.8056e-01, time/batch = 0.6893s	
204/33800 (epoch 0.302), train_loss = 2.74142495, grad/param norm = 4.7894e-01, time/batch = 0.6894s	
205/33800 (epoch 0.303), train_loss = 2.76511320, grad/param norm = 5.6860e-01, time/batch = 0.6883s	
206/33800 (epoch 0.305), train_loss = 2.64178032, grad/param norm = 5.4662e-01, time/batch = 0.6937s	
207/33800 (epoch 0.306), train_loss = 2.63708986, grad/param norm = 5.0215e-01, time/batch = 0.6990s	
208/33800 (epoch 0.308), train_loss = 2.71917647, grad/param norm = 4.6363e-01, time/batch = 0.6989s	
209/33800 (epoch 0.309), train_loss = 2.83875630, grad/param norm = 9.6590e-01, time/batch = 0.7082s	
210/33800 (epoch 0.311), train_loss = 2.80724601, grad/param norm = 1.5300e+00, time/batch = 0.6931s	
211/33800 (epoch 0.312), train_loss = 2.68039956, grad/param norm = 1.1867e+00, time/batch = 0.7009s	
212/33800 (epoch 0.314), train_loss = 2.76129495, grad/param norm = 8.9142e-01, time/batch = 0.7102s	
213/33800 (epoch 0.315), train_loss = 2.86805628, grad/param norm = 1.0148e+00, time/batch = 0.7070s	
214/33800 (epoch 0.317), train_loss = 2.83028565, grad/param norm = 7.9868e-01, time/batch = 0.7020s	
215/33800 (epoch 0.318), train_loss = 2.71417247, grad/param norm = 4.3624e-01, time/batch = 0.6881s	
216/33800 (epoch 0.320), train_loss = 2.86164660, grad/param norm = 5.3139e-01, time/batch = 0.6908s	
217/33800 (epoch 0.321), train_loss = 2.75526236, grad/param norm = 5.1740e-01, time/batch = 0.6919s	
218/33800 (epoch 0.322), train_loss = 2.72465201, grad/param norm = 3.4490e-01, time/batch = 0.6932s	
219/33800 (epoch 0.324), train_loss = 2.59709558, grad/param norm = 4.4223e-01, time/batch = 0.6888s	
220/33800 (epoch 0.325), train_loss = 2.73872983, grad/param norm = 6.6268e-01, time/batch = 0.6890s	
221/33800 (epoch 0.327), train_loss = 2.74322793, grad/param norm = 5.7408e-01, time/batch = 0.6909s	
222/33800 (epoch 0.328), train_loss = 2.62033460, grad/param norm = 3.7592e-01, time/batch = 0.6891s	
223/33800 (epoch 0.330), train_loss = 2.61666982, grad/param norm = 5.7924e-01, time/batch = 0.6867s	
224/33800 (epoch 0.331), train_loss = 2.75545550, grad/param norm = 7.5556e-01, time/batch = 0.6895s	
225/33800 (epoch 0.333), train_loss = 2.73420548, grad/param norm = 7.3804e-01, time/batch = 0.6907s	
226/33800 (epoch 0.334), train_loss = 2.73167053, grad/param norm = 6.2695e-01, time/batch = 0.6909s	
227/33800 (epoch 0.336), train_loss = 2.63101915, grad/param norm = 5.4980e-01, time/batch = 0.6904s	
228/33800 (epoch 0.337), train_loss = 2.53957479, grad/param norm = 6.5628e-01, time/batch = 0.6925s	
229/33800 (epoch 0.339), train_loss = 2.71344334, grad/param norm = 6.1667e-01, time/batch = 0.6930s	
230/33800 (epoch 0.340), train_loss = 2.71585075, grad/param norm = 6.8537e-01, time/batch = 0.6921s	
231/33800 (epoch 0.342), train_loss = 2.84357471, grad/param norm = 1.2184e+00, time/batch = 0.7023s	
232/33800 (epoch 0.343), train_loss = 2.88473140, grad/param norm = 1.2897e+00, time/batch = 0.7123s	
233/33800 (epoch 0.345), train_loss = 2.77377572, grad/param norm = 1.0167e+00, time/batch = 0.7142s	
234/33800 (epoch 0.346), train_loss = 2.96812593, grad/param norm = 5.9898e-01, time/batch = 0.7132s	
235/33800 (epoch 0.348), train_loss = 2.79404294, grad/param norm = 6.0166e-01, time/batch = 0.7104s	
236/33800 (epoch 0.349), train_loss = 2.70709447, grad/param norm = 5.7930e-01, time/batch = 0.7020s	
237/33800 (epoch 0.351), train_loss = 2.57563208, grad/param norm = 5.3406e-01, time/batch = 0.6950s	
238/33800 (epoch 0.352), train_loss = 2.74529487, grad/param norm = 7.0543e-01, time/batch = 0.6924s	
239/33800 (epoch 0.354), train_loss = 2.65426570, grad/param norm = 7.3148e-01, time/batch = 0.6938s	
240/33800 (epoch 0.355), train_loss = 2.65277460, grad/param norm = 6.9131e-01, time/batch = 0.6934s	
241/33800 (epoch 0.357), train_loss = 2.72945836, grad/param norm = 6.3058e-01, time/batch = 0.6941s	
242/33800 (epoch 0.358), train_loss = 2.77844372, grad/param norm = 4.5728e-01, time/batch = 0.6927s	
243/33800 (epoch 0.359), train_loss = 2.62676269, grad/param norm = 4.2951e-01, time/batch = 0.6962s	
244/33800 (epoch 0.361), train_loss = 2.57630879, grad/param norm = 4.0305e-01, time/batch = 0.7071s	
245/33800 (epoch 0.362), train_loss = 2.63915119, grad/param norm = 4.5096e-01, time/batch = 0.7215s	
246/33800 (epoch 0.364), train_loss = 2.83528717, grad/param norm = 4.9469e-01, time/batch = 0.7025s	
247/33800 (epoch 0.365), train_loss = 2.70713122, grad/param norm = 6.8846e-01, time/batch = 0.6992s	
248/33800 (epoch 0.367), train_loss = 2.67311864, grad/param norm = 5.4963e-01, time/batch = 0.6972s	
249/33800 (epoch 0.368), train_loss = 2.74058915, grad/param norm = 4.7660e-01, time/batch = 0.6987s	
250/33800 (epoch 0.370), train_loss = 2.78074030, grad/param norm = 4.6213e-01, time/batch = 0.6999s	
251/33800 (epoch 0.371), train_loss = 2.69877764, grad/param norm = 4.5561e-01, time/batch = 0.7158s	
252/33800 (epoch 0.373), train_loss = 2.74345333, grad/param norm = 4.6035e-01, time/batch = 0.7509s	
253/33800 (epoch 0.374), train_loss = 2.66958785, grad/param norm = 3.5366e-01, time/batch = 0.7373s	
254/33800 (epoch 0.376), train_loss = 2.70282796, grad/param norm = 4.4080e-01, time/batch = 0.7152s	
255/33800 (epoch 0.377), train_loss = 2.65986875, grad/param norm = 7.8199e-01, time/batch = 0.7091s	
256/33800 (epoch 0.379), train_loss = 2.89812473, grad/param norm = 1.3084e+00, time/batch = 0.6990s	
257/33800 (epoch 0.380), train_loss = 2.86075231, grad/param norm = 9.9881e-01, time/batch = 0.7042s	
258/33800 (epoch 0.382), train_loss = 2.62783576, grad/param norm = 4.6605e-01, time/batch = 0.7051s	
259/33800 (epoch 0.383), train_loss = 2.76176703, grad/param norm = 4.1580e-01, time/batch = 0.6849s	
260/33800 (epoch 0.385), train_loss = 2.73126481, grad/param norm = 2.9777e-01, time/batch = 0.6899s	
261/33800 (epoch 0.386), train_loss = 2.60138237, grad/param norm = 4.3083e-01, time/batch = 0.6923s	
262/33800 (epoch 0.388), train_loss = 2.63934498, grad/param norm = 3.5243e-01, time/batch = 0.6856s	
263/33800 (epoch 0.389), train_loss = 2.61458571, grad/param norm = 3.0718e-01, time/batch = 0.6898s	
264/33800 (epoch 0.391), train_loss = 2.75569398, grad/param norm = 3.9470e-01, time/batch = 0.6924s	
265/33800 (epoch 0.392), train_loss = 2.69711968, grad/param norm = 4.0479e-01, time/batch = 0.6913s	
266/33800 (epoch 0.393), train_loss = 2.70139654, grad/param norm = 7.6398e-01, time/batch = 0.6914s	
267/33800 (epoch 0.395), train_loss = 2.68739549, grad/param norm = 1.3944e+00, time/batch = 0.6927s	
268/33800 (epoch 0.396), train_loss = 2.68980397, grad/param norm = 1.3480e+00, time/batch = 0.6919s	
269/33800 (epoch 0.398), train_loss = 2.58225846, grad/param norm = 7.8105e-01, time/batch = 0.6961s	
270/33800 (epoch 0.399), train_loss = 2.69659346, grad/param norm = 6.0614e-01, time/batch = 0.6932s	
271/33800 (epoch 0.401), train_loss = 2.57407024, grad/param norm = 4.5430e-01, time/batch = 0.6911s	
272/33800 (epoch 0.402), train_loss = 2.85679878, grad/param norm = 5.5876e-01, time/batch = 0.6919s	
273/33800 (epoch 0.404), train_loss = 2.66503834, grad/param norm = 4.4074e-01, time/batch = 0.6926s	
274/33800 (epoch 0.405), train_loss = 2.69804857, grad/param norm = 3.0983e-01, time/batch = 0.6892s	
275/33800 (epoch 0.407), train_loss = 2.58328247, grad/param norm = 3.0876e-01, time/batch = 0.7006s	
276/33800 (epoch 0.408), train_loss = 2.68901820, grad/param norm = 4.6375e-01, time/batch = 0.6879s	
277/33800 (epoch 0.410), train_loss = 2.70255684, grad/param norm = 5.4863e-01, time/batch = 0.6862s	
278/33800 (epoch 0.411), train_loss = 2.59342245, grad/param norm = 4.9975e-01, time/batch = 0.6844s	
279/33800 (epoch 0.413), train_loss = 2.73259150, grad/param norm = 4.5903e-01, time/batch = 0.6885s	
280/33800 (epoch 0.414), train_loss = 2.50724413, grad/param norm = 5.5047e-01, time/batch = 0.6880s	
281/33800 (epoch 0.416), train_loss = 2.59843201, grad/param norm = 7.0755e-01, time/batch = 0.6898s	
282/33800 (epoch 0.417), train_loss = 2.62660374, grad/param norm = 8.5603e-01, time/batch = 0.6925s	
283/33800 (epoch 0.419), train_loss = 2.60401978, grad/param norm = 7.1173e-01, time/batch = 0.6899s	
284/33800 (epoch 0.420), train_loss = 2.67741515, grad/param norm = 5.4410e-01, time/batch = 0.6895s	
285/33800 (epoch 0.422), train_loss = 2.63164062, grad/param norm = 5.9775e-01, time/batch = 0.6896s	
286/33800 (epoch 0.423), train_loss = 2.51071332, grad/param norm = 6.3703e-01, time/batch = 0.6902s	
287/33800 (epoch 0.425), train_loss = 2.56611952, grad/param norm = 5.9469e-01, time/batch = 0.7006s	
288/33800 (epoch 0.426), train_loss = 2.68763662, grad/param norm = 6.0436e-01, time/batch = 0.6929s	
289/33800 (epoch 0.428), train_loss = 2.67768564, grad/param norm = 5.3106e-01, time/batch = 0.6983s	
290/33800 (epoch 0.429), train_loss = 2.55995277, grad/param norm = 5.8110e-01, time/batch = 0.6962s	
291/33800 (epoch 0.430), train_loss = 2.60721601, grad/param norm = 4.9611e-01, time/batch = 0.6875s	
292/33800 (epoch 0.432), train_loss = 2.49820931, grad/param norm = 5.9378e-01, time/batch = 0.6874s	
293/33800 (epoch 0.433), train_loss = 2.54814851, grad/param norm = 5.6394e-01, time/batch = 0.6878s	
294/33800 (epoch 0.435), train_loss = 2.61142957, grad/param norm = 4.2580e-01, time/batch = 0.6911s	
295/33800 (epoch 0.436), train_loss = 2.53218266, grad/param norm = 4.7073e-01, time/batch = 0.6856s	
296/33800 (epoch 0.438), train_loss = 2.54831187, grad/param norm = 6.1559e-01, time/batch = 0.6848s	
297/33800 (epoch 0.439), train_loss = 2.60969188, grad/param norm = 7.0186e-01, time/batch = 0.6834s	
298/33800 (epoch 0.441), train_loss = 2.54696683, grad/param norm = 5.8490e-01, time/batch = 0.6910s	
299/33800 (epoch 0.442), train_loss = 2.58419111, grad/param norm = 5.8255e-01, time/batch = 0.6914s	
300/33800 (epoch 0.444), train_loss = 2.52586470, grad/param norm = 7.2912e-01, time/batch = 0.6868s	
301/33800 (epoch 0.445), train_loss = 2.54736290, grad/param norm = 6.8787e-01, time/batch = 0.6914s	
302/33800 (epoch 0.447), train_loss = 2.61327443, grad/param norm = 7.3677e-01, time/batch = 0.6871s	
303/33800 (epoch 0.448), train_loss = 2.58335032, grad/param norm = 7.0052e-01, time/batch = 0.6864s	
304/33800 (epoch 0.450), train_loss = 2.52731579, grad/param norm = 5.9406e-01, time/batch = 0.6869s	
305/33800 (epoch 0.451), train_loss = 2.49475797, grad/param norm = 5.5739e-01, time/batch = 0.6880s	
306/33800 (epoch 0.453), train_loss = 2.59791558, grad/param norm = 4.9492e-01, time/batch = 0.6837s	
307/33800 (epoch 0.454), train_loss = 2.57366342, grad/param norm = 3.9293e-01, time/batch = 0.6850s	
308/33800 (epoch 0.456), train_loss = 2.49572443, grad/param norm = 4.0267e-01, time/batch = 0.6852s	
309/33800 (epoch 0.457), train_loss = 2.38857031, grad/param norm = 3.0368e-01, time/batch = 0.6864s	
310/33800 (epoch 0.459), train_loss = 2.67339922, grad/param norm = 3.6247e-01, time/batch = 0.6877s	
311/33800 (epoch 0.460), train_loss = 2.50591576, grad/param norm = 4.2962e-01, time/batch = 0.6896s	
312/33800 (epoch 0.462), train_loss = 2.59792500, grad/param norm = 3.3976e-01, time/batch = 0.6917s	
313/33800 (epoch 0.463), train_loss = 2.51565292, grad/param norm = 3.3447e-01, time/batch = 0.6878s	
314/33800 (epoch 0.464), train_loss = 2.62489201, grad/param norm = 5.5142e-01, time/batch = 0.6922s	
315/33800 (epoch 0.466), train_loss = 2.50503862, grad/param norm = 4.4688e-01, time/batch = 0.6903s	
316/33800 (epoch 0.467), train_loss = 2.53250257, grad/param norm = 3.8762e-01, time/batch = 0.6897s	
317/33800 (epoch 0.469), train_loss = 2.46643041, grad/param norm = 3.9172e-01, time/batch = 0.6930s	
318/33800 (epoch 0.470), train_loss = 2.48947482, grad/param norm = 4.3058e-01, time/batch = 0.6914s	
319/33800 (epoch 0.472), train_loss = 2.51629259, grad/param norm = 4.5276e-01, time/batch = 0.6894s	
320/33800 (epoch 0.473), train_loss = 2.52193668, grad/param norm = 5.2095e-01, time/batch = 0.6880s	
321/33800 (epoch 0.475), train_loss = 2.54190116, grad/param norm = 9.4723e-01, time/batch = 0.6939s	
322/33800 (epoch 0.476), train_loss = 2.68513916, grad/param norm = 1.4085e+00, time/batch = 0.6935s	
323/33800 (epoch 0.478), train_loss = 2.76580815, grad/param norm = 8.3355e-01, time/batch = 0.6932s	
324/33800 (epoch 0.479), train_loss = 2.63579876, grad/param norm = 5.1130e-01, time/batch = 0.6938s	
325/33800 (epoch 0.481), train_loss = 2.56635029, grad/param norm = 3.6949e-01, time/batch = 0.6947s	
326/33800 (epoch 0.482), train_loss = 2.73982772, grad/param norm = 3.3855e-01, time/batch = 0.6935s	
327/33800 (epoch 0.484), train_loss = 2.57423355, grad/param norm = 3.8947e-01, time/batch = 0.6945s	
328/33800 (epoch 0.485), train_loss = 2.44792389, grad/param norm = 2.6917e-01, time/batch = 0.6929s	
329/33800 (epoch 0.487), train_loss = 2.56282511, grad/param norm = 3.2534e-01, time/batch = 0.6983s	
330/33800 (epoch 0.488), train_loss = 2.57105877, grad/param norm = 3.6693e-01, time/batch = 0.7063s	
331/33800 (epoch 0.490), train_loss = 2.57519050, grad/param norm = 3.7065e-01, time/batch = 0.7147s	
332/33800 (epoch 0.491), train_loss = 2.44249359, grad/param norm = 3.9620e-01, time/batch = 0.7217s	
333/33800 (epoch 0.493), train_loss = 2.48275481, grad/param norm = 5.6537e-01, time/batch = 0.7108s	
334/33800 (epoch 0.494), train_loss = 2.69893310, grad/param norm = 9.1263e-01, time/batch = 0.7375s	
335/33800 (epoch 0.496), train_loss = 2.55267709, grad/param norm = 9.1731e-01, time/batch = 0.7057s	
336/33800 (epoch 0.497), train_loss = 2.59274462, grad/param norm = 6.7019e-01, time/batch = 0.6909s	
337/33800 (epoch 0.499), train_loss = 2.53835448, grad/param norm = 3.3096e-01, time/batch = 0.6925s	
338/33800 (epoch 0.500), train_loss = 2.63875812, grad/param norm = 3.4451e-01, time/batch = 0.6899s	
339/33800 (epoch 0.501), train_loss = 2.59746658, grad/param norm = 3.0352e-01, time/batch = 0.6884s	
340/33800 (epoch 0.503), train_loss = 2.62767688, grad/param norm = 3.6317e-01, time/batch = 0.6953s	
341/33800 (epoch 0.504), train_loss = 2.56513618, grad/param norm = 3.5547e-01, time/batch = 0.6941s	
342/33800 (epoch 0.506), train_loss = 2.57264038, grad/param norm = 5.2679e-01, time/batch = 0.6904s	
343/33800 (epoch 0.507), train_loss = 2.51981932, grad/param norm = 4.7771e-01, time/batch = 0.6942s	
344/33800 (epoch 0.509), train_loss = 2.57954188, grad/param norm = 6.0278e-01, time/batch = 0.6966s	
345/33800 (epoch 0.510), train_loss = 2.52692206, grad/param norm = 6.0022e-01, time/batch = 0.7326s	
346/33800 (epoch 0.512), train_loss = 2.53132266, grad/param norm = 4.0682e-01, time/batch = 0.7137s	
347/33800 (epoch 0.513), train_loss = 2.59653764, grad/param norm = 2.9788e-01, time/batch = 0.7179s	
348/33800 (epoch 0.515), train_loss = 2.64282059, grad/param norm = 4.3949e-01, time/batch = 0.6963s	
349/33800 (epoch 0.516), train_loss = 2.61634896, grad/param norm = 4.9940e-01, time/batch = 0.6954s	
350/33800 (epoch 0.518), train_loss = 2.59678967, grad/param norm = 6.3652e-01, time/batch = 0.7035s	
351/33800 (epoch 0.519), train_loss = 2.55007276, grad/param norm = 7.9400e-01, time/batch = 0.7034s	
352/33800 (epoch 0.521), train_loss = 2.54699209, grad/param norm = 6.9223e-01, time/batch = 0.6932s	
353/33800 (epoch 0.522), train_loss = 2.44619806, grad/param norm = 7.0292e-01, time/batch = 0.6887s	
354/33800 (epoch 0.524), train_loss = 2.50699893, grad/param norm = 5.0320e-01, time/batch = 0.6909s	
355/33800 (epoch 0.525), train_loss = 2.44184417, grad/param norm = 3.5168e-01, time/batch = 0.6922s	
356/33800 (epoch 0.527), train_loss = 2.50489668, grad/param norm = 3.7626e-01, time/batch = 0.6905s	
357/33800 (epoch 0.528), train_loss = 2.51888549, grad/param norm = 3.4059e-01, time/batch = 0.6881s	
358/33800 (epoch 0.530), train_loss = 2.63873837, grad/param norm = 4.0603e-01, time/batch = 0.6908s	
359/33800 (epoch 0.531), train_loss = 2.60397060, grad/param norm = 5.4791e-01, time/batch = 0.6888s	
360/33800 (epoch 0.533), train_loss = 2.44023081, grad/param norm = 5.9980e-01, time/batch = 0.6890s	
361/33800 (epoch 0.534), train_loss = 2.48491686, grad/param norm = 4.5832e-01, time/batch = 0.6968s	
362/33800 (epoch 0.536), train_loss = 2.69670165, grad/param norm = 5.8841e-01, time/batch = 0.6932s	
363/33800 (epoch 0.537), train_loss = 2.64855234, grad/param norm = 7.0289e-01, time/batch = 0.6984s	
364/33800 (epoch 0.538), train_loss = 2.52407823, grad/param norm = 5.2986e-01, time/batch = 0.6961s	
365/33800 (epoch 0.540), train_loss = 2.47735885, grad/param norm = 5.4331e-01, time/batch = 0.6987s	
366/33800 (epoch 0.541), train_loss = 2.44813517, grad/param norm = 4.8339e-01, time/batch = 0.6954s	
367/33800 (epoch 0.543), train_loss = 2.46839035, grad/param norm = 4.3341e-01, time/batch = 0.6912s	
368/33800 (epoch 0.544), train_loss = 2.69422334, grad/param norm = 3.9030e-01, time/batch = 0.6922s	
369/33800 (epoch 0.546), train_loss = 2.72961009, grad/param norm = 4.6736e-01, time/batch = 0.6915s	
370/33800 (epoch 0.547), train_loss = 2.83554398, grad/param norm = 3.7924e-01, time/batch = 0.6926s	
371/33800 (epoch 0.549), train_loss = 2.50938488, grad/param norm = 4.0891e-01, time/batch = 0.7040s	
372/33800 (epoch 0.550), train_loss = 2.51721775, grad/param norm = 4.1649e-01, time/batch = 0.7017s	
373/33800 (epoch 0.552), train_loss = 2.53965448, grad/param norm = 3.2155e-01, time/batch = 0.6899s	
374/33800 (epoch 0.553), train_loss = 2.61699647, grad/param norm = 2.7255e-01, time/batch = 0.6903s	
375/33800 (epoch 0.555), train_loss = 2.49304838, grad/param norm = 4.8823e-01, time/batch = 0.6912s	
376/33800 (epoch 0.556), train_loss = 2.45878947, grad/param norm = 6.0985e-01, time/batch = 0.6903s	
377/33800 (epoch 0.558), train_loss = 2.35789747, grad/param norm = 5.0147e-01, time/batch = 0.6877s	
378/33800 (epoch 0.559), train_loss = 2.57020850, grad/param norm = 4.7754e-01, time/batch = 0.6858s	
379/33800 (epoch 0.561), train_loss = 2.50851721, grad/param norm = 5.3787e-01, time/batch = 0.6912s	
380/33800 (epoch 0.562), train_loss = 2.50505459, grad/param norm = 4.4181e-01, time/batch = 0.6924s	
381/33800 (epoch 0.564), train_loss = 2.47189027, grad/param norm = 3.6060e-01, time/batch = 0.6932s	
382/33800 (epoch 0.565), train_loss = 2.62049537, grad/param norm = 4.7707e-01, time/batch = 0.6965s	
383/33800 (epoch 0.567), train_loss = 2.50386190, grad/param norm = 4.2810e-01, time/batch = 0.7088s	
384/33800 (epoch 0.568), train_loss = 2.54895020, grad/param norm = 2.9994e-01, time/batch = 0.7120s	
385/33800 (epoch 0.570), train_loss = 2.53281848, grad/param norm = 4.6093e-01, time/batch = 0.7030s	
386/33800 (epoch 0.571), train_loss = 2.43874877, grad/param norm = 6.1264e-01, time/batch = 0.6965s	
387/33800 (epoch 0.572), train_loss = 2.61526230, grad/param norm = 5.1112e-01, time/batch = 0.6956s	
388/33800 (epoch 0.574), train_loss = 2.62963266, grad/param norm = 5.7393e-01, time/batch = 0.6917s	
389/33800 (epoch 0.575), train_loss = 2.63521561, grad/param norm = 1.8394e+00, time/batch = 0.6937s	
390/33800 (epoch 0.577), train_loss = 2.50075089, grad/param norm = 6.5124e-01, time/batch = 0.6917s	
391/33800 (epoch 0.578), train_loss = 2.42634690, grad/param norm = 6.6682e-01, time/batch = 0.7123s	
392/33800 (epoch 0.580), train_loss = 2.53373668, grad/param norm = 6.8018e-01, time/batch = 0.7060s	
393/33800 (epoch 0.581), train_loss = 2.50555379, grad/param norm = 4.3622e-01, time/batch = 0.7032s	
394/33800 (epoch 0.583), train_loss = 2.53256924, grad/param norm = 3.9026e-01, time/batch = 0.6861s	
395/33800 (epoch 0.584), train_loss = 2.52197120, grad/param norm = 3.2579e-01, time/batch = 0.6891s	
396/33800 (epoch 0.586), train_loss = 2.44435207, grad/param norm = 3.3691e-01, time/batch = 0.6868s	
397/33800 (epoch 0.587), train_loss = 2.34519776, grad/param norm = 3.1793e-01, time/batch = 0.6931s	
398/33800 (epoch 0.589), train_loss = 2.48910855, grad/param norm = 3.3305e-01, time/batch = 0.6950s	
399/33800 (epoch 0.590), train_loss = 2.48097718, grad/param norm = 3.4237e-01, time/batch = 0.6873s	
400/33800 (epoch 0.592), train_loss = 2.42597581, grad/param norm = 3.2284e-01, time/batch = 0.6860s	
401/33800 (epoch 0.593), train_loss = 2.45915244, grad/param norm = 3.9061e-01, time/batch = 0.6935s	
402/33800 (epoch 0.595), train_loss = 2.47033281, grad/param norm = 4.6255e-01, time/batch = 0.6939s	
403/33800 (epoch 0.596), train_loss = 2.58583280, grad/param norm = 5.5184e-01, time/batch = 0.6970s	
404/33800 (epoch 0.598), train_loss = 2.52958133, grad/param norm = 6.4903e-01, time/batch = 0.6979s	
405/33800 (epoch 0.599), train_loss = 2.48186372, grad/param norm = 5.7983e-01, time/batch = 0.6932s	
406/33800 (epoch 0.601), train_loss = 2.36097685, grad/param norm = 6.6162e-01, time/batch = 0.6925s	
407/33800 (epoch 0.602), train_loss = 2.61878496, grad/param norm = 6.3717e-01, time/batch = 0.6924s	
408/33800 (epoch 0.604), train_loss = 2.59984083, grad/param norm = 3.6327e-01, time/batch = 0.6951s	
409/33800 (epoch 0.605), train_loss = 2.48058656, grad/param norm = 2.6765e-01, time/batch = 0.6918s	
410/33800 (epoch 0.607), train_loss = 2.51360719, grad/param norm = 3.5055e-01, time/batch = 0.6927s	
411/33800 (epoch 0.608), train_loss = 2.53738092, grad/param norm = 3.2034e-01, time/batch = 0.6968s	
412/33800 (epoch 0.609), train_loss = 2.46354789, grad/param norm = 3.6111e-01, time/batch = 0.6933s	
413/33800 (epoch 0.611), train_loss = 2.56859463, grad/param norm = 3.8097e-01, time/batch = 0.6855s	
414/33800 (epoch 0.612), train_loss = 2.44771344, grad/param norm = 4.0569e-01, time/batch = 0.6874s	
415/33800 (epoch 0.614), train_loss = 2.45428905, grad/param norm = 4.0883e-01, time/batch = 0.7001s	
416/33800 (epoch 0.615), train_loss = 2.44428331, grad/param norm = 4.0822e-01, time/batch = 0.7083s	
417/33800 (epoch 0.617), train_loss = 2.52373836, grad/param norm = 4.8805e-01, time/batch = 0.7171s	
418/33800 (epoch 0.618), train_loss = 2.49587601, grad/param norm = 3.9491e-01, time/batch = 0.7243s	
419/33800 (epoch 0.620), train_loss = 2.38910470, grad/param norm = 2.6394e-01, time/batch = 0.7081s	
420/33800 (epoch 0.621), train_loss = 2.49746551, grad/param norm = 2.9124e-01, time/batch = 0.7604s	
421/33800 (epoch 0.623), train_loss = 2.44792038, grad/param norm = 3.1076e-01, time/batch = 0.7100s	
422/33800 (epoch 0.624), train_loss = 2.48082220, grad/param norm = 3.0366e-01, time/batch = 0.7037s	
423/33800 (epoch 0.626), train_loss = 2.50270979, grad/param norm = 3.3700e-01, time/batch = 0.7021s	
424/33800 (epoch 0.627), train_loss = 2.45703927, grad/param norm = 2.6211e-01, time/batch = 0.7002s	
425/33800 (epoch 0.629), train_loss = 2.61364982, grad/param norm = 3.7633e-01, time/batch = 0.6996s	
426/33800 (epoch 0.630), train_loss = 2.50351868, grad/param norm = 3.0093e-01, time/batch = 0.6982s	
427/33800 (epoch 0.632), train_loss = 2.48726078, grad/param norm = 3.3135e-01, time/batch = 0.7005s	
428/33800 (epoch 0.633), train_loss = 2.45730982, grad/param norm = 2.9319e-01, time/batch = 0.7010s	
429/33800 (epoch 0.635), train_loss = 2.37971189, grad/param norm = 3.3761e-01, time/batch = 0.7007s	
430/33800 (epoch 0.636), train_loss = 2.47322540, grad/param norm = 3.3923e-01, time/batch = 0.6998s	
431/33800 (epoch 0.638), train_loss = 2.43726323, grad/param norm = 3.2058e-01, time/batch = 0.7033s	
432/33800 (epoch 0.639), train_loss = 2.58768666, grad/param norm = 3.2396e-01, time/batch = 0.7044s	
433/33800 (epoch 0.641), train_loss = 2.40573240, grad/param norm = 3.4848e-01, time/batch = 0.7089s	
434/33800 (epoch 0.642), train_loss = 2.46536604, grad/param norm = 3.9444e-01, time/batch = 0.7105s	
435/33800 (epoch 0.643), train_loss = 2.41185385, grad/param norm = 5.6913e-01, time/batch = 0.7038s	
436/33800 (epoch 0.645), train_loss = 2.67969219, grad/param norm = 9.5222e-01, time/batch = 0.7012s	
437/33800 (epoch 0.646), train_loss = 2.52620989, grad/param norm = 7.4326e-01, time/batch = 0.6964s	
438/33800 (epoch 0.648), train_loss = 2.50581500, grad/param norm = 3.4116e-01, time/batch = 0.6991s	
439/33800 (epoch 0.649), train_loss = 2.48622668, grad/param norm = 4.3221e-01, time/batch = 0.7031s	
440/33800 (epoch 0.651), train_loss = 2.43186927, grad/param norm = 5.3834e-01, time/batch = 0.7410s	
441/33800 (epoch 0.652), train_loss = 2.44579934, grad/param norm = 5.7440e-01, time/batch = 0.7013s	
442/33800 (epoch 0.654), train_loss = 2.47347437, grad/param norm = 4.5306e-01, time/batch = 0.7066s	
443/33800 (epoch 0.655), train_loss = 2.28885511, grad/param norm = 3.3811e-01, time/batch = 0.7024s	
444/33800 (epoch 0.657), train_loss = 2.43961626, grad/param norm = 4.1673e-01, time/batch = 0.7030s	
445/33800 (epoch 0.658), train_loss = 2.38276040, grad/param norm = 3.3296e-01, time/batch = 0.7034s	
446/33800 (epoch 0.660), train_loss = 2.37326030, grad/param norm = 2.4694e-01, time/batch = 0.7020s	
447/33800 (epoch 0.661), train_loss = 2.39103201, grad/param norm = 2.9055e-01, time/batch = 0.7031s	
448/33800 (epoch 0.663), train_loss = 2.45430145, grad/param norm = 2.6529e-01, time/batch = 0.7012s	
449/33800 (epoch 0.664), train_loss = 2.49791819, grad/param norm = 2.7314e-01, time/batch = 0.7018s	
450/33800 (epoch 0.666), train_loss = 2.50873238, grad/param norm = 2.9234e-01, time/batch = 0.6960s	
451/33800 (epoch 0.667), train_loss = 2.53359070, grad/param norm = 4.0765e-01, time/batch = 0.6989s	
452/33800 (epoch 0.669), train_loss = 2.40785746, grad/param norm = 3.4482e-01, time/batch = 0.6987s	
453/33800 (epoch 0.670), train_loss = 2.49885310, grad/param norm = 4.8676e-01, time/batch = 0.7025s	
454/33800 (epoch 0.672), train_loss = 2.40201205, grad/param norm = 5.7498e-01, time/batch = 0.6999s	
455/33800 (epoch 0.673), train_loss = 2.39193812, grad/param norm = 3.5610e-01, time/batch = 0.6971s	
456/33800 (epoch 0.675), train_loss = 2.34354152, grad/param norm = 3.0636e-01, time/batch = 0.6955s	
457/33800 (epoch 0.676), train_loss = 2.48919303, grad/param norm = 4.1403e-01, time/batch = 0.6913s	
458/33800 (epoch 0.678), train_loss = 2.37912206, grad/param norm = 5.3604e-01, time/batch = 0.6920s	
459/33800 (epoch 0.679), train_loss = 2.52735028, grad/param norm = 5.1846e-01, time/batch = 0.6976s	
460/33800 (epoch 0.680), train_loss = 2.30535703, grad/param norm = 4.8847e-01, time/batch = 0.6955s	
461/33800 (epoch 0.682), train_loss = 2.46963018, grad/param norm = 3.3092e-01, time/batch = 0.6964s	
462/33800 (epoch 0.683), train_loss = 2.54003286, grad/param norm = 3.1462e-01, time/batch = 0.6946s	
463/33800 (epoch 0.685), train_loss = 2.41835949, grad/param norm = 3.5755e-01, time/batch = 0.6988s	
464/33800 (epoch 0.686), train_loss = 2.40428038, grad/param norm = 4.4650e-01, time/batch = 0.6937s	
465/33800 (epoch 0.688), train_loss = 2.52882342, grad/param norm = 4.1087e-01, time/batch = 0.7041s	
466/33800 (epoch 0.689), train_loss = 2.41334171, grad/param norm = 2.7865e-01, time/batch = 0.7051s	
467/33800 (epoch 0.691), train_loss = 2.49846444, grad/param norm = 2.5025e-01, time/batch = 0.6976s	
468/33800 (epoch 0.692), train_loss = 2.54760146, grad/param norm = 2.8363e-01, time/batch = 0.6943s	
469/33800 (epoch 0.694), train_loss = 2.46093571, grad/param norm = 3.1693e-01, time/batch = 0.6949s	
470/33800 (epoch 0.695), train_loss = 2.55151818, grad/param norm = 4.5279e-01, time/batch = 0.6960s	
471/33800 (epoch 0.697), train_loss = 2.53638018, grad/param norm = 4.0025e-01, time/batch = 0.6964s	
472/33800 (epoch 0.698), train_loss = 2.37678468, grad/param norm = 4.0691e-01, time/batch = 0.6966s	
473/33800 (epoch 0.700), train_loss = 2.46266837, grad/param norm = 4.0677e-01, time/batch = 0.6965s	
474/33800 (epoch 0.701), train_loss = 2.47255545, grad/param norm = 4.2979e-01, time/batch = 0.6953s	
475/33800 (epoch 0.703), train_loss = 2.48226659, grad/param norm = 3.2273e-01, time/batch = 0.7106s	
476/33800 (epoch 0.704), train_loss = 2.33225577, grad/param norm = 2.9867e-01, time/batch = 0.7093s	
477/33800 (epoch 0.706), train_loss = 2.36121869, grad/param norm = 4.4055e-01, time/batch = 0.7101s	
478/33800 (epoch 0.707), train_loss = 2.51869654, grad/param norm = 7.1014e-01, time/batch = 0.7069s	
479/33800 (epoch 0.709), train_loss = 2.44755902, grad/param norm = 8.3491e-01, time/batch = 0.6991s	
480/33800 (epoch 0.710), train_loss = 2.55673521, grad/param norm = 7.2300e-01, time/batch = 0.7065s	
481/33800 (epoch 0.712), train_loss = 2.54765102, grad/param norm = 4.4185e-01, time/batch = 0.7093s	
482/33800 (epoch 0.713), train_loss = 2.46669584, grad/param norm = 3.3797e-01, time/batch = 0.7103s	
483/33800 (epoch 0.714), train_loss = 2.34895672, grad/param norm = 2.4933e-01, time/batch = 0.7134s	
484/33800 (epoch 0.716), train_loss = 2.40642963, grad/param norm = 3.3914e-01, time/batch = 0.7068s	
485/33800 (epoch 0.717), train_loss = 2.35499026, grad/param norm = 3.5654e-01, time/batch = 0.6968s	
486/33800 (epoch 0.719), train_loss = 2.47883276, grad/param norm = 3.3999e-01, time/batch = 0.7001s	
487/33800 (epoch 0.720), train_loss = 2.36936783, grad/param norm = 4.4295e-01, time/batch = 0.6994s	
488/33800 (epoch 0.722), train_loss = 2.39213411, grad/param norm = 3.8323e-01, time/batch = 0.7021s	
489/33800 (epoch 0.723), train_loss = 2.39054828, grad/param norm = 3.1404e-01, time/batch = 0.7063s	
490/33800 (epoch 0.725), train_loss = 2.38213524, grad/param norm = 3.6182e-01, time/batch = 0.7051s	
491/33800 (epoch 0.726), train_loss = 2.35342467, grad/param norm = 3.2030e-01, time/batch = 0.7026s	
492/33800 (epoch 0.728), train_loss = 2.47419997, grad/param norm = 2.5575e-01, time/batch = 0.6989s	
493/33800 (epoch 0.729), train_loss = 2.49712605, grad/param norm = 3.6320e-01, time/batch = 0.7005s	
494/33800 (epoch 0.731), train_loss = 2.39586694, grad/param norm = 3.5506e-01, time/batch = 0.6977s	
495/33800 (epoch 0.732), train_loss = 2.48885877, grad/param norm = 2.9589e-01, time/batch = 0.6969s	
496/33800 (epoch 0.734), train_loss = 2.38348714, grad/param norm = 3.5783e-01, time/batch = 0.6974s	
497/33800 (epoch 0.735), train_loss = 2.44416816, grad/param norm = 4.7565e-01, time/batch = 0.6971s	
498/33800 (epoch 0.737), train_loss = 2.39633803, grad/param norm = 4.4151e-01, time/batch = 0.6943s	
499/33800 (epoch 0.738), train_loss = 2.37647381, grad/param norm = 3.5230e-01, time/batch = 0.6973s	
500/33800 (epoch 0.740), train_loss = 2.50796651, grad/param norm = 3.5301e-01, time/batch = 0.7124s	
501/33800 (epoch 0.741), train_loss = 2.40624658, grad/param norm = 3.1038e-01, time/batch = 0.7186s	
502/33800 (epoch 0.743), train_loss = 2.35847957, grad/param norm = 2.3042e-01, time/batch = 0.7221s	
503/33800 (epoch 0.744), train_loss = 2.29687426, grad/param norm = 2.7680e-01, time/batch = 0.7164s	
504/33800 (epoch 0.746), train_loss = 2.28372654, grad/param norm = 3.0578e-01, time/batch = 0.7186s	
505/33800 (epoch 0.747), train_loss = 2.45126221, grad/param norm = 4.1484e-01, time/batch = 0.7143s	
506/33800 (epoch 0.749), train_loss = 2.40679076, grad/param norm = 3.6752e-01, time/batch = 0.7042s	
507/33800 (epoch 0.750), train_loss = 2.25888408, grad/param norm = 3.4497e-01, time/batch = 0.7104s	
508/33800 (epoch 0.751), train_loss = 2.64351917, grad/param norm = 4.8219e-01, time/batch = 0.7115s	
509/33800 (epoch 0.753), train_loss = 2.55739444, grad/param norm = 7.3773e-01, time/batch = 0.7157s	
510/33800 (epoch 0.754), train_loss = 2.49514162, grad/param norm = 7.1017e-01, time/batch = 0.7126s	
511/33800 (epoch 0.756), train_loss = 2.59139429, grad/param norm = 6.4771e-01, time/batch = 0.7217s	
512/33800 (epoch 0.757), train_loss = 2.50604293, grad/param norm = 3.6616e-01, time/batch = 0.7491s	
513/33800 (epoch 0.759), train_loss = 2.36779697, grad/param norm = 3.6929e-01, time/batch = 0.7152s	
514/33800 (epoch 0.760), train_loss = 2.37289594, grad/param norm = 3.6449e-01, time/batch = 0.7183s	
515/33800 (epoch 0.762), train_loss = 2.59400334, grad/param norm = 3.7760e-01, time/batch = 0.7136s	
516/33800 (epoch 0.763), train_loss = 2.24017664, grad/param norm = 3.5264e-01, time/batch = 0.7444s	
517/33800 (epoch 0.765), train_loss = 2.45646269, grad/param norm = 3.1677e-01, time/batch = 0.7249s	
518/33800 (epoch 0.766), train_loss = 2.39972778, grad/param norm = 3.3507e-01, time/batch = 0.7178s	
519/33800 (epoch 0.768), train_loss = 2.23485803, grad/param norm = 3.0395e-01, time/batch = 0.7108s	
520/33800 (epoch 0.769), train_loss = 2.32059429, grad/param norm = 3.4585e-01, time/batch = 0.7114s	
521/33800 (epoch 0.771), train_loss = 2.36122883, grad/param norm = 3.2721e-01, time/batch = 0.7136s	
522/33800 (epoch 0.772), train_loss = 2.32647475, grad/param norm = 3.0980e-01, time/batch = 0.7156s	
523/33800 (epoch 0.774), train_loss = 2.43503063, grad/param norm = 2.6463e-01, time/batch = 0.7002s	
524/33800 (epoch 0.775), train_loss = 2.37236596, grad/param norm = 2.8192e-01, time/batch = 0.6979s	
525/33800 (epoch 0.777), train_loss = 2.35436846, grad/param norm = 3.3760e-01, time/batch = 0.6985s	
526/33800 (epoch 0.778), train_loss = 2.48960292, grad/param norm = 3.8470e-01, time/batch = 0.6940s	
527/33800 (epoch 0.780), train_loss = 2.41954245, grad/param norm = 3.6531e-01, time/batch = 0.6968s	
528/33800 (epoch 0.781), train_loss = 2.47858631, grad/param norm = 3.9024e-01, time/batch = 0.7002s	
529/33800 (epoch 0.783), train_loss = 2.38141256, grad/param norm = 4.1954e-01, time/batch = 0.7005s	
530/33800 (epoch 0.784), train_loss = 2.50454880, grad/param norm = 3.6781e-01, time/batch = 0.6956s	
531/33800 (epoch 0.786), train_loss = 2.43872989, grad/param norm = 4.5603e-01, time/batch = 0.7013s	
532/33800 (epoch 0.787), train_loss = 2.41128267, grad/param norm = 5.4455e-01, time/batch = 0.7022s	
533/33800 (epoch 0.788), train_loss = 2.33955083, grad/param norm = 3.8640e-01, time/batch = 0.6966s	
534/33800 (epoch 0.790), train_loss = 2.24528494, grad/param norm = 2.4867e-01, time/batch = 0.7021s	
535/33800 (epoch 0.791), train_loss = 2.38085369, grad/param norm = 3.2645e-01, time/batch = 0.7169s	
536/33800 (epoch 0.793), train_loss = 2.48658486, grad/param norm = 5.2411e-01, time/batch = 0.6930s	
537/33800 (epoch 0.794), train_loss = 2.47402558, grad/param norm = 4.1748e-01, time/batch = 0.6948s	
538/33800 (epoch 0.796), train_loss = 2.39993430, grad/param norm = 4.5102e-01, time/batch = 0.6958s	
539/33800 (epoch 0.797), train_loss = 2.24184003, grad/param norm = 3.1111e-01, time/batch = 0.6953s	
540/33800 (epoch 0.799), train_loss = 2.34136864, grad/param norm = 3.0117e-01, time/batch = 0.6949s	
541/33800 (epoch 0.800), train_loss = 2.46064286, grad/param norm = 4.1862e-01, time/batch = 0.6959s	
542/33800 (epoch 0.802), train_loss = 2.24565077, grad/param norm = 3.1026e-01, time/batch = 0.6982s	
543/33800 (epoch 0.803), train_loss = 2.45974916, grad/param norm = 2.9514e-01, time/batch = 0.6976s	
544/33800 (epoch 0.805), train_loss = 2.37950195, grad/param norm = 3.0912e-01, time/batch = 0.7015s	
545/33800 (epoch 0.806), train_loss = 2.26896102, grad/param norm = 3.5046e-01, time/batch = 0.6985s	
546/33800 (epoch 0.808), train_loss = 2.39953884, grad/param norm = 5.5395e-01, time/batch = 0.6972s	
547/33800 (epoch 0.809), train_loss = 2.44372234, grad/param norm = 5.0834e-01, time/batch = 0.6942s	
548/33800 (epoch 0.811), train_loss = 2.28881014, grad/param norm = 4.0948e-01, time/batch = 0.7003s	
549/33800 (epoch 0.812), train_loss = 2.35449998, grad/param norm = 3.3878e-01, time/batch = 0.6927s	
550/33800 (epoch 0.814), train_loss = 2.39594761, grad/param norm = 2.6347e-01, time/batch = 0.6992s	
551/33800 (epoch 0.815), train_loss = 2.29243324, grad/param norm = 2.8666e-01, time/batch = 0.6958s	
552/33800 (epoch 0.817), train_loss = 2.36875609, grad/param norm = 3.6787e-01, time/batch = 0.6948s	
553/33800 (epoch 0.818), train_loss = 2.45034159, grad/param norm = 2.9870e-01, time/batch = 0.6932s	
554/33800 (epoch 0.820), train_loss = 2.34325454, grad/param norm = 2.4901e-01, time/batch = 0.6961s	
555/33800 (epoch 0.821), train_loss = 2.32456276, grad/param norm = 3.0644e-01, time/batch = 0.6957s	
556/33800 (epoch 0.822), train_loss = 2.36191708, grad/param norm = 3.7567e-01, time/batch = 0.6943s	
557/33800 (epoch 0.824), train_loss = 2.42365507, grad/param norm = 3.6242e-01, time/batch = 0.6945s	
558/33800 (epoch 0.825), train_loss = 2.42335868, grad/param norm = 3.2693e-01, time/batch = 0.6986s	
559/33800 (epoch 0.827), train_loss = 2.41261374, grad/param norm = 3.3610e-01, time/batch = 0.6998s	
560/33800 (epoch 0.828), train_loss = 2.37742078, grad/param norm = 3.2700e-01, time/batch = 0.6956s	
561/33800 (epoch 0.830), train_loss = 2.31571944, grad/param norm = 3.9337e-01, time/batch = 0.6986s	
562/33800 (epoch 0.831), train_loss = 2.45351500, grad/param norm = 4.0136e-01, time/batch = 0.6972s	
563/33800 (epoch 0.833), train_loss = 2.41008533, grad/param norm = 3.8225e-01, time/batch = 0.6948s	
564/33800 (epoch 0.834), train_loss = 2.38403835, grad/param norm = 3.3241e-01, time/batch = 0.6944s	
565/33800 (epoch 0.836), train_loss = 2.37584222, grad/param norm = 4.1285e-01, time/batch = 0.6929s	
566/33800 (epoch 0.837), train_loss = 2.39964433, grad/param norm = 4.3370e-01, time/batch = 0.6902s	
567/33800 (epoch 0.839), train_loss = 2.29596617, grad/param norm = 3.3066e-01, time/batch = 0.6910s	
568/33800 (epoch 0.840), train_loss = 2.36174603, grad/param norm = 2.3884e-01, time/batch = 0.6969s	
569/33800 (epoch 0.842), train_loss = 2.24034999, grad/param norm = 2.4357e-01, time/batch = 0.6978s	
570/33800 (epoch 0.843), train_loss = 2.29536663, grad/param norm = 3.2487e-01, time/batch = 0.6972s	
571/33800 (epoch 0.845), train_loss = 2.42669764, grad/param norm = 3.9927e-01, time/batch = 0.7051s	
572/33800 (epoch 0.846), train_loss = 2.39320875, grad/param norm = 4.8302e-01, time/batch = 0.6998s	
573/33800 (epoch 0.848), train_loss = 2.43871883, grad/param norm = 4.6176e-01, time/batch = 0.6997s	
574/33800 (epoch 0.849), train_loss = 2.30868958, grad/param norm = 3.9217e-01, time/batch = 0.6999s	
575/33800 (epoch 0.851), train_loss = 2.38995026, grad/param norm = 2.9962e-01, time/batch = 0.6994s	
576/33800 (epoch 0.852), train_loss = 2.33890816, grad/param norm = 3.1240e-01, time/batch = 0.6951s	
577/33800 (epoch 0.854), train_loss = 2.38579143, grad/param norm = 2.8699e-01, time/batch = 0.6977s	
578/33800 (epoch 0.855), train_loss = 2.24001089, grad/param norm = 3.4923e-01, time/batch = 0.7029s	
579/33800 (epoch 0.857), train_loss = 2.65759345, grad/param norm = 4.9339e-01, time/batch = 0.7046s	
580/33800 (epoch 0.858), train_loss = 2.48615188, grad/param norm = 9.5037e-01, time/batch = 0.7021s	
581/33800 (epoch 0.859), train_loss = 2.44261905, grad/param norm = 4.3347e-01, time/batch = 0.7120s	
582/33800 (epoch 0.861), train_loss = 2.40584126, grad/param norm = 2.9816e-01, time/batch = 0.7034s	
583/33800 (epoch 0.862), train_loss = 2.33558046, grad/param norm = 2.7918e-01, time/batch = 0.7064s	
584/33800 (epoch 0.864), train_loss = 2.54865410, grad/param norm = 4.4464e-01, time/batch = 0.7004s	
585/33800 (epoch 0.865), train_loss = 2.47623590, grad/param norm = 4.3023e-01, time/batch = 0.7117s	
586/33800 (epoch 0.867), train_loss = 2.46746379, grad/param norm = 3.3316e-01, time/batch = 0.7225s	
587/33800 (epoch 0.868), train_loss = 2.13648503, grad/param norm = 2.6866e-01, time/batch = 0.7056s	
588/33800 (epoch 0.870), train_loss = 2.25889385, grad/param norm = 2.9748e-01, time/batch = 0.7453s	
589/33800 (epoch 0.871), train_loss = 2.36474126, grad/param norm = 2.9496e-01, time/batch = 0.7164s	
590/33800 (epoch 0.873), train_loss = 2.35772437, grad/param norm = 3.7926e-01, time/batch = 0.7161s	
591/33800 (epoch 0.874), train_loss = 2.43777458, grad/param norm = 4.0784e-01, time/batch = 0.7087s	
592/33800 (epoch 0.876), train_loss = 2.33752233, grad/param norm = 3.6766e-01, time/batch = 0.6973s	
593/33800 (epoch 0.877), train_loss = 2.40232508, grad/param norm = 3.4307e-01, time/batch = 0.7028s	
594/33800 (epoch 0.879), train_loss = 2.38431292, grad/param norm = 3.2976e-01, time/batch = 0.6946s	
595/33800 (epoch 0.880), train_loss = 2.42503712, grad/param norm = 3.0748e-01, time/batch = 0.6922s	
596/33800 (epoch 0.882), train_loss = 2.30202753, grad/param norm = 2.8367e-01, time/batch = 0.6921s	
597/33800 (epoch 0.883), train_loss = 2.31050733, grad/param norm = 3.9487e-01, time/batch = 0.6900s	
598/33800 (epoch 0.885), train_loss = 2.32396861, grad/param norm = 4.4146e-01, time/batch = 0.7019s	
599/33800 (epoch 0.886), train_loss = 2.36878589, grad/param norm = 3.9823e-01, time/batch = 0.6999s	
600/33800 (epoch 0.888), train_loss = 2.31619345, grad/param norm = 3.2402e-01, time/batch = 0.6946s	
601/33800 (epoch 0.889), train_loss = 2.22967873, grad/param norm = 2.9807e-01, time/batch = 0.6988s	
602/33800 (epoch 0.891), train_loss = 2.28554772, grad/param norm = 3.9742e-01, time/batch = 0.7024s	
603/33800 (epoch 0.892), train_loss = 2.38275009, grad/param norm = 6.2477e-01, time/batch = 0.6972s	
604/33800 (epoch 0.893), train_loss = 2.31085553, grad/param norm = 5.1386e-01, time/batch = 0.6949s	
605/33800 (epoch 0.895), train_loss = 2.44410686, grad/param norm = 3.2354e-01, time/batch = 0.6957s	
606/33800 (epoch 0.896), train_loss = 2.32550416, grad/param norm = 2.4276e-01, time/batch = 0.6934s	
607/33800 (epoch 0.898), train_loss = 2.34355681, grad/param norm = 2.8009e-01, time/batch = 0.6908s	
608/33800 (epoch 0.899), train_loss = 2.31083911, grad/param norm = 3.9716e-01, time/batch = 0.6999s	
609/33800 (epoch 0.901), train_loss = 2.45631393, grad/param norm = 3.1659e-01, time/batch = 0.7016s	
610/33800 (epoch 0.902), train_loss = 2.38854700, grad/param norm = 2.6690e-01, time/batch = 0.6935s	
611/33800 (epoch 0.904), train_loss = 2.22616145, grad/param norm = 2.6185e-01, time/batch = 0.6999s	
612/33800 (epoch 0.905), train_loss = 2.29012953, grad/param norm = 3.1984e-01, time/batch = 0.7014s	
613/33800 (epoch 0.907), train_loss = 2.25175151, grad/param norm = 2.7330e-01, time/batch = 0.6959s	
614/33800 (epoch 0.908), train_loss = 2.34835024, grad/param norm = 3.1081e-01, time/batch = 0.6942s	
615/33800 (epoch 0.910), train_loss = 2.45355054, grad/param norm = 2.7744e-01, time/batch = 0.6971s	
616/33800 (epoch 0.911), train_loss = 2.38601493, grad/param norm = 2.7726e-01, time/batch = 0.6964s	
617/33800 (epoch 0.913), train_loss = 2.36945265, grad/param norm = 2.8549e-01, time/batch = 0.6986s	
618/33800 (epoch 0.914), train_loss = 2.33264679, grad/param norm = 2.3144e-01, time/batch = 0.6982s	
619/33800 (epoch 0.916), train_loss = 2.30127884, grad/param norm = 2.5602e-01, time/batch = 0.6989s	
620/33800 (epoch 0.917), train_loss = 2.38292648, grad/param norm = 2.6219e-01, time/batch = 0.6976s	
621/33800 (epoch 0.919), train_loss = 2.31959373, grad/param norm = 2.6733e-01, time/batch = 0.6979s	
622/33800 (epoch 0.920), train_loss = 2.34139759, grad/param norm = 4.3836e-01, time/batch = 0.6955s	
623/33800 (epoch 0.922), train_loss = 2.34477138, grad/param norm = 4.7925e-01, time/batch = 0.6946s	
624/33800 (epoch 0.923), train_loss = 2.28773645, grad/param norm = 3.7670e-01, time/batch = 0.6957s	
625/33800 (epoch 0.925), train_loss = 2.36232683, grad/param norm = 2.8770e-01, time/batch = 0.6972s	
626/33800 (epoch 0.926), train_loss = 2.28942276, grad/param norm = 2.7333e-01, time/batch = 0.6958s	
627/33800 (epoch 0.928), train_loss = 2.39877654, grad/param norm = 3.2113e-01, time/batch = 0.7062s	
628/33800 (epoch 0.929), train_loss = 2.26502023, grad/param norm = 3.8601e-01, time/batch = 0.7024s	
629/33800 (epoch 0.930), train_loss = 2.38430408, grad/param norm = 3.5308e-01, time/batch = 0.6980s	
630/33800 (epoch 0.932), train_loss = 2.36553568, grad/param norm = 3.7359e-01, time/batch = 0.7002s	
631/33800 (epoch 0.933), train_loss = 2.32803447, grad/param norm = 3.2067e-01, time/batch = 0.7029s	
632/33800 (epoch 0.935), train_loss = 2.28673407, grad/param norm = 2.8219e-01, time/batch = 0.7001s	
633/33800 (epoch 0.936), train_loss = 2.37437372, grad/param norm = 2.8862e-01, time/batch = 0.7048s	
634/33800 (epoch 0.938), train_loss = 2.32284877, grad/param norm = 3.5529e-01, time/batch = 0.7143s	
635/33800 (epoch 0.939), train_loss = 2.43187328, grad/param norm = 5.0402e-01, time/batch = 0.7141s	
636/33800 (epoch 0.941), train_loss = 2.36985622, grad/param norm = 4.0676e-01, time/batch = 0.7209s	
637/33800 (epoch 0.942), train_loss = 2.38187292, grad/param norm = 3.7184e-01, time/batch = 0.7181s	
638/33800 (epoch 0.944), train_loss = 2.40719739, grad/param norm = 4.9059e-01, time/batch = 0.7125s	
639/33800 (epoch 0.945), train_loss = 2.25576805, grad/param norm = 3.9195e-01, time/batch = 0.7148s	
640/33800 (epoch 0.947), train_loss = 2.39754927, grad/param norm = 3.2781e-01, time/batch = 0.7094s	
641/33800 (epoch 0.948), train_loss = 2.30639803, grad/param norm = 3.7606e-01, time/batch = 0.7108s	
642/33800 (epoch 0.950), train_loss = 2.12866171, grad/param norm = 3.1614e-01, time/batch = 0.6992s	
643/33800 (epoch 0.951), train_loss = 2.31492940, grad/param norm = 2.6713e-01, time/batch = 0.6913s	
644/33800 (epoch 0.953), train_loss = 2.37291119, grad/param norm = 2.6606e-01, time/batch = 0.6989s	
645/33800 (epoch 0.954), train_loss = 2.34645847, grad/param norm = 2.8087e-01, time/batch = 0.6968s	
646/33800 (epoch 0.956), train_loss = 2.34652577, grad/param norm = 2.6259e-01, time/batch = 0.6969s	
647/33800 (epoch 0.957), train_loss = 2.37574669, grad/param norm = 2.7476e-01, time/batch = 0.6939s	
648/33800 (epoch 0.959), train_loss = 2.27511874, grad/param norm = 3.3706e-01, time/batch = 0.6918s	
649/33800 (epoch 0.960), train_loss = 2.41378136, grad/param norm = 2.5100e-01, time/batch = 0.6923s	
650/33800 (epoch 0.962), train_loss = 2.40340288, grad/param norm = 2.4407e-01, time/batch = 0.6928s	
651/33800 (epoch 0.963), train_loss = 2.48267699, grad/param norm = 3.5669e-01, time/batch = 0.6959s	
652/33800 (epoch 0.964), train_loss = 2.56395114, grad/param norm = 3.7079e-01, time/batch = 0.6930s	
653/33800 (epoch 0.966), train_loss = 2.27640770, grad/param norm = 6.0934e-01, time/batch = 0.6954s	
654/33800 (epoch 0.967), train_loss = 2.34937601, grad/param norm = 3.5743e-01, time/batch = 0.6978s	
655/33800 (epoch 0.969), train_loss = 2.31847417, grad/param norm = 2.8734e-01, time/batch = 0.6963s	
656/33800 (epoch 0.970), train_loss = 2.30980434, grad/param norm = 2.5050e-01, time/batch = 0.6983s	
657/33800 (epoch 0.972), train_loss = 2.24712159, grad/param norm = 2.5156e-01, time/batch = 0.6943s	
658/33800 (epoch 0.973), train_loss = 2.32428780, grad/param norm = 3.4722e-01, time/batch = 0.6939s	
659/33800 (epoch 0.975), train_loss = 2.50473517, grad/param norm = 3.3067e-01, time/batch = 0.6988s	
660/33800 (epoch 0.976), train_loss = 2.37833854, grad/param norm = 3.6990e-01, time/batch = 0.6963s	
661/33800 (epoch 0.978), train_loss = 2.28520016, grad/param norm = 2.8926e-01, time/batch = 0.6967s	
662/33800 (epoch 0.979), train_loss = 2.46557846, grad/param norm = 3.3412e-01, time/batch = 0.7051s	
663/33800 (epoch 0.981), train_loss = 2.18929786, grad/param norm = 2.5215e-01, time/batch = 0.7010s	
664/33800 (epoch 0.982), train_loss = 2.45323751, grad/param norm = 3.7706e-01, time/batch = 0.6966s	
665/33800 (epoch 0.984), train_loss = 2.42596012, grad/param norm = 5.1103e-01, time/batch = 0.6929s	
666/33800 (epoch 0.985), train_loss = 2.49461545, grad/param norm = 3.6799e-01, time/batch = 0.6959s	
667/33800 (epoch 0.987), train_loss = 2.25414298, grad/param norm = 3.2428e-01, time/batch = 0.6959s	
668/33800 (epoch 0.988), train_loss = 2.14267217, grad/param norm = 2.8256e-01, time/batch = 0.6937s	
669/33800 (epoch 0.990), train_loss = 2.21240635, grad/param norm = 2.3075e-01, time/batch = 0.6942s	
670/33800 (epoch 0.991), train_loss = 2.39879921, grad/param norm = 3.0460e-01, time/batch = 0.7025s	
671/33800 (epoch 0.993), train_loss = 2.30582757, grad/param norm = 2.8645e-01, time/batch = 0.7142s	
672/33800 (epoch 0.994), train_loss = 2.24718834, grad/param norm = 2.9722e-01, time/batch = 0.7245s	
673/33800 (epoch 0.996), train_loss = 2.12439675, grad/param norm = 3.6011e-01, time/batch = 0.7081s	
674/33800 (epoch 0.997), train_loss = 2.30011986, grad/param norm = 3.7820e-01, time/batch = 0.7010s	
675/33800 (epoch 0.999), train_loss = 2.35736297, grad/param norm = 3.3511e-01, time/batch = 0.7019s	
676/33800 (epoch 1.000), train_loss = 2.33556568, grad/param norm = 4.6499e-01, time/batch = 0.7037s	
677/33800 (epoch 1.001), train_loss = 2.31146946, grad/param norm = 4.4551e-01, time/batch = 0.7001s	
678/33800 (epoch 1.003), train_loss = 2.36011719, grad/param norm = 3.1078e-01, time/batch = 0.7001s	
679/33800 (epoch 1.004), train_loss = 2.29611799, grad/param norm = 3.4668e-01, time/batch = 0.6986s	
680/33800 (epoch 1.006), train_loss = 2.35391331, grad/param norm = 3.2488e-01, time/batch = 0.7012s	
681/33800 (epoch 1.007), train_loss = 2.34643850, grad/param norm = 3.0213e-01, time/batch = 0.7022s	
682/33800 (epoch 1.009), train_loss = 2.34820948, grad/param norm = 2.5470e-01, time/batch = 0.6867s	
683/33800 (epoch 1.010), train_loss = 2.29728428, grad/param norm = 2.8071e-01, time/batch = 0.6831s	
684/33800 (epoch 1.012), train_loss = 2.34206402, grad/param norm = 2.3200e-01, time/batch = 0.6836s	
685/33800 (epoch 1.013), train_loss = 2.36585305, grad/param norm = 2.4532e-01, time/batch = 0.7197s	
686/33800 (epoch 1.015), train_loss = 2.27219628, grad/param norm = 2.7547e-01, time/batch = 0.7014s	
687/33800 (epoch 1.016), train_loss = 2.27081502, grad/param norm = 3.2719e-01, time/batch = 0.6958s	
688/33800 (epoch 1.018), train_loss = 2.12719486, grad/param norm = 3.2845e-01, time/batch = 0.6855s	
689/33800 (epoch 1.019), train_loss = 2.28062084, grad/param norm = 3.1946e-01, time/batch = 0.6919s	
690/33800 (epoch 1.021), train_loss = 2.44693738, grad/param norm = 3.8189e-01, time/batch = 0.6860s	
691/33800 (epoch 1.022), train_loss = 2.19138075, grad/param norm = 3.4464e-01, time/batch = 0.6833s	
692/33800 (epoch 1.024), train_loss = 2.08896104, grad/param norm = 2.8461e-01, time/batch = 0.7009s	
693/33800 (epoch 1.025), train_loss = 2.30891118, grad/param norm = 2.7693e-01, time/batch = 0.6746s	
694/33800 (epoch 1.027), train_loss = 2.24705969, grad/param norm = 2.4426e-01, time/batch = 0.6733s	
695/33800 (epoch 1.028), train_loss = 2.20539563, grad/param norm = 3.0384e-01, time/batch = 0.6728s	
696/33800 (epoch 1.030), train_loss = 2.29618115, grad/param norm = 3.5621e-01, time/batch = 0.6745s	
697/33800 (epoch 1.031), train_loss = 2.13581612, grad/param norm = 3.2358e-01, time/batch = 0.6759s	
698/33800 (epoch 1.033), train_loss = 2.21219309, grad/param norm = 2.9225e-01, time/batch = 0.6814s	
699/33800 (epoch 1.034), train_loss = 2.31354122, grad/param norm = 2.7128e-01, time/batch = 0.6773s	
700/33800 (epoch 1.036), train_loss = 2.41839949, grad/param norm = 3.3582e-01, time/batch = 0.6769s	
701/33800 (epoch 1.037), train_loss = 2.24369359, grad/param norm = 3.0238e-01, time/batch = 0.6774s	
702/33800 (epoch 1.038), train_loss = 2.36175896, grad/param norm = 2.7979e-01, time/batch = 0.6776s	
703/33800 (epoch 1.040), train_loss = 2.28033455, grad/param norm = 2.7617e-01, time/batch = 0.6743s	
704/33800 (epoch 1.041), train_loss = 2.31836935, grad/param norm = 2.4579e-01, time/batch = 0.6764s	
705/33800 (epoch 1.043), train_loss = 2.29228380, grad/param norm = 2.6486e-01, time/batch = 0.6755s	
706/33800 (epoch 1.044), train_loss = 2.12338647, grad/param norm = 2.7201e-01, time/batch = 0.6750s	
707/33800 (epoch 1.046), train_loss = 2.16249046, grad/param norm = 3.7282e-01, time/batch = 0.6766s	
708/33800 (epoch 1.047), train_loss = 2.29498915, grad/param norm = 3.8437e-01, time/batch = 0.6781s	
709/33800 (epoch 1.049), train_loss = 2.24619506, grad/param norm = 3.5473e-01, time/batch = 0.6787s	
710/33800 (epoch 1.050), train_loss = 2.27918002, grad/param norm = 3.2497e-01, time/batch = 0.6768s	
711/33800 (epoch 1.052), train_loss = 2.30135276, grad/param norm = 4.1608e-01, time/batch = 0.6826s	
712/33800 (epoch 1.053), train_loss = 2.28667317, grad/param norm = 3.5042e-01, time/batch = 0.6762s	
713/33800 (epoch 1.055), train_loss = 2.27973529, grad/param norm = 3.2643e-01, time/batch = 0.6755s	
714/33800 (epoch 1.056), train_loss = 2.29362355, grad/param norm = 3.2099e-01, time/batch = 0.6765s	
715/33800 (epoch 1.058), train_loss = 2.27064921, grad/param norm = 2.2909e-01, time/batch = 0.6797s	
716/33800 (epoch 1.059), train_loss = 2.18498295, grad/param norm = 2.5615e-01, time/batch = 0.6767s	
717/33800 (epoch 1.061), train_loss = 2.26936608, grad/param norm = 2.6198e-01, time/batch = 0.6770s	
718/33800 (epoch 1.062), train_loss = 2.29001407, grad/param norm = 2.4740e-01, time/batch = 0.6790s	
719/33800 (epoch 1.064), train_loss = 2.36899882, grad/param norm = 3.9656e-01, time/batch = 0.6767s	
720/33800 (epoch 1.065), train_loss = 2.32333320, grad/param norm = 4.5638e-01, time/batch = 0.6843s	
721/33800 (epoch 1.067), train_loss = 2.24876918, grad/param norm = 2.8412e-01, time/batch = 0.6853s	
722/33800 (epoch 1.068), train_loss = 2.23998649, grad/param norm = 2.4884e-01, time/batch = 0.6680s	
723/33800 (epoch 1.070), train_loss = 2.27342000, grad/param norm = 2.5377e-01, time/batch = 0.6698s	
724/33800 (epoch 1.071), train_loss = 2.20459763, grad/param norm = 2.7419e-01, time/batch = 0.6706s	
725/33800 (epoch 1.072), train_loss = 2.30055213, grad/param norm = 2.6294e-01, time/batch = 0.6698s	
726/33800 (epoch 1.074), train_loss = 2.44753921, grad/param norm = 3.8042e-01, time/batch = 0.6732s	
727/33800 (epoch 1.075), train_loss = 2.35025094, grad/param norm = 5.0401e-01, time/batch = 0.6778s	
728/33800 (epoch 1.077), train_loss = 2.17998167, grad/param norm = 2.6299e-01, time/batch = 0.6812s	
729/33800 (epoch 1.078), train_loss = 2.25718127, grad/param norm = 2.2733e-01, time/batch = 0.6850s	
730/33800 (epoch 1.080), train_loss = 2.17023280, grad/param norm = 3.1885e-01, time/batch = 0.6821s	
731/33800 (epoch 1.081), train_loss = 2.16638895, grad/param norm = 3.9760e-01, time/batch = 0.6795s	
732/33800 (epoch 1.083), train_loss = 2.14835928, grad/param norm = 3.0233e-01, time/batch = 0.6766s	
733/33800 (epoch 1.084), train_loss = 2.32817397, grad/param norm = 2.3315e-01, time/batch = 0.6759s	
734/33800 (epoch 1.086), train_loss = 2.12886742, grad/param norm = 2.7050e-01, time/batch = 0.6742s	
735/33800 (epoch 1.087), train_loss = 2.47423218, grad/param norm = 3.5301e-01, time/batch = 0.6774s	
736/33800 (epoch 1.089), train_loss = 2.30915217, grad/param norm = 4.7931e-01, time/batch = 0.6741s	
737/33800 (epoch 1.090), train_loss = 2.31937726, grad/param norm = 3.6891e-01, time/batch = 0.6767s	
738/33800 (epoch 1.092), train_loss = 2.36906405, grad/param norm = 2.6938e-01, time/batch = 0.6764s	
739/33800 (epoch 1.093), train_loss = 2.30764703, grad/param norm = 2.5190e-01, time/batch = 0.6774s	
740/33800 (epoch 1.095), train_loss = 2.22511159, grad/param norm = 3.5088e-01, time/batch = 0.6805s	
741/33800 (epoch 1.096), train_loss = 2.26125706, grad/param norm = 3.6726e-01, time/batch = 0.6837s	
742/33800 (epoch 1.098), train_loss = 2.30577223, grad/param norm = 3.2671e-01, time/batch = 0.6791s	
743/33800 (epoch 1.099), train_loss = 2.36618644, grad/param norm = 2.7747e-01, time/batch = 0.6791s	
744/33800 (epoch 1.101), train_loss = 2.14089528, grad/param norm = 2.3336e-01, time/batch = 0.6894s	
745/33800 (epoch 1.102), train_loss = 2.40610266, grad/param norm = 4.0359e-01, time/batch = 0.6795s	
746/33800 (epoch 1.104), train_loss = 2.34010463, grad/param norm = 4.0870e-01, time/batch = 0.6850s	
747/33800 (epoch 1.105), train_loss = 2.21495827, grad/param norm = 3.0068e-01, time/batch = 0.6860s	
748/33800 (epoch 1.107), train_loss = 2.21050575, grad/param norm = 2.2192e-01, time/batch = 0.6962s	
749/33800 (epoch 1.108), train_loss = 2.15522806, grad/param norm = 2.4010e-01, time/batch = 0.6873s	
750/33800 (epoch 1.109), train_loss = 2.25424991, grad/param norm = 2.7853e-01, time/batch = 0.7066s	
751/33800 (epoch 1.111), train_loss = 2.18290609, grad/param norm = 3.3610e-01, time/batch = 0.7220s	
752/33800 (epoch 1.112), train_loss = 2.13634644, grad/param norm = 2.4997e-01, time/batch = 0.6781s	
753/33800 (epoch 1.114), train_loss = 2.38672731, grad/param norm = 3.1089e-01, time/batch = 0.6816s	
754/33800 (epoch 1.115), train_loss = 2.17868084, grad/param norm = 2.4502e-01, time/batch = 0.6884s	
755/33800 (epoch 1.117), train_loss = 2.35181859, grad/param norm = 3.0259e-01, time/batch = 0.6789s	
756/33800 (epoch 1.118), train_loss = 2.32303980, grad/param norm = 2.6906e-01, time/batch = 0.6761s	
757/33800 (epoch 1.120), train_loss = 2.32061482, grad/param norm = 2.6027e-01, time/batch = 0.7033s	
758/33800 (epoch 1.121), train_loss = 2.20124218, grad/param norm = 2.2343e-01, time/batch = 0.7099s	
759/33800 (epoch 1.123), train_loss = 2.21357051, grad/param norm = 2.5372e-01, time/batch = 0.7239s	
760/33800 (epoch 1.124), train_loss = 2.14928109, grad/param norm = 3.0154e-01, time/batch = 0.7106s	
761/33800 (epoch 1.126), train_loss = 2.29146349, grad/param norm = 3.2064e-01, time/batch = 0.7087s	
762/33800 (epoch 1.127), train_loss = 2.31180834, grad/param norm = 2.8615e-01, time/batch = 0.7007s	
763/33800 (epoch 1.129), train_loss = 2.33429128, grad/param norm = 3.0863e-01, time/batch = 0.6950s	
764/33800 (epoch 1.130), train_loss = 2.23562596, grad/param norm = 2.7998e-01, time/batch = 0.7080s	
765/33800 (epoch 1.132), train_loss = 2.41767756, grad/param norm = 2.8534e-01, time/batch = 0.6995s	
766/33800 (epoch 1.133), train_loss = 2.22780367, grad/param norm = 2.4963e-01, time/batch = 0.6962s	
767/33800 (epoch 1.135), train_loss = 2.11983746, grad/param norm = 2.9487e-01, time/batch = 0.7036s	
768/33800 (epoch 1.136), train_loss = 2.20381938, grad/param norm = 2.9456e-01, time/batch = 0.6911s	
769/33800 (epoch 1.138), train_loss = 2.26180477, grad/param norm = 2.4957e-01, time/batch = 0.6920s	
770/33800 (epoch 1.139), train_loss = 2.22880244, grad/param norm = 2.2147e-01, time/batch = 0.6929s	
771/33800 (epoch 1.141), train_loss = 2.19424105, grad/param norm = 2.7069e-01, time/batch = 0.6977s	
772/33800 (epoch 1.142), train_loss = 2.32844519, grad/param norm = 3.1123e-01, time/batch = 0.7076s	
773/33800 (epoch 1.143), train_loss = 2.20578330, grad/param norm = 3.2966e-01, time/batch = 0.7465s	
774/33800 (epoch 1.145), train_loss = 2.24231433, grad/param norm = 3.3702e-01, time/batch = 0.7195s	
775/33800 (epoch 1.146), train_loss = 2.29284105, grad/param norm = 3.7486e-01, time/batch = 0.7015s	
776/33800 (epoch 1.148), train_loss = 2.15360080, grad/param norm = 3.0801e-01, time/batch = 0.6944s	
777/33800 (epoch 1.149), train_loss = 2.20556885, grad/param norm = 2.5117e-01, time/batch = 0.6932s	
778/33800 (epoch 1.151), train_loss = 2.05781009, grad/param norm = 2.9790e-01, time/batch = 0.6978s	
779/33800 (epoch 1.152), train_loss = 2.31135742, grad/param norm = 2.6184e-01, time/batch = 0.6931s	
780/33800 (epoch 1.154), train_loss = 2.26573410, grad/param norm = 2.6461e-01, time/batch = 0.6911s	
781/33800 (epoch 1.155), train_loss = 2.17493058, grad/param norm = 2.5550e-01, time/batch = 0.6958s	
782/33800 (epoch 1.157), train_loss = 2.11587717, grad/param norm = 3.2526e-01, time/batch = 0.6925s	
783/33800 (epoch 1.158), train_loss = 2.18727728, grad/param norm = 3.0996e-01, time/batch = 0.6916s	
784/33800 (epoch 1.160), train_loss = 2.12936560, grad/param norm = 2.6665e-01, time/batch = 0.6954s	
785/33800 (epoch 1.161), train_loss = 2.28537382, grad/param norm = 2.5040e-01, time/batch = 0.6910s	
786/33800 (epoch 1.163), train_loss = 2.21380980, grad/param norm = 2.3959e-01, time/batch = 0.6905s	
787/33800 (epoch 1.164), train_loss = 2.18861106, grad/param norm = 2.5140e-01, time/batch = 0.6938s	
788/33800 (epoch 1.166), train_loss = 2.10904204, grad/param norm = 2.8604e-01, time/batch = 0.6929s	
789/33800 (epoch 1.167), train_loss = 2.27359926, grad/param norm = 3.0380e-01, time/batch = 0.6950s	
790/33800 (epoch 1.169), train_loss = 2.25005477, grad/param norm = 3.4247e-01, time/batch = 0.6955s	
791/33800 (epoch 1.170), train_loss = 2.14039722, grad/param norm = 3.3994e-01, time/batch = 0.6968s	
792/33800 (epoch 1.172), train_loss = 2.28232495, grad/param norm = 2.6469e-01, time/batch = 0.6952s	
793/33800 (epoch 1.173), train_loss = 2.15360380, grad/param norm = 3.0577e-01, time/batch = 0.6912s	
794/33800 (epoch 1.175), train_loss = 2.35025645, grad/param norm = 2.9746e-01, time/batch = 0.6944s	
795/33800 (epoch 1.176), train_loss = 2.17100023, grad/param norm = 2.5723e-01, time/batch = 0.6918s	
796/33800 (epoch 1.178), train_loss = 2.33621330, grad/param norm = 2.3574e-01, time/batch = 0.6862s	
797/33800 (epoch 1.179), train_loss = 2.25963990, grad/param norm = 2.5245e-01, time/batch = 0.6917s	
798/33800 (epoch 1.180), train_loss = 2.16705387, grad/param norm = 3.8682e-01, time/batch = 0.6901s	
799/33800 (epoch 1.182), train_loss = 2.38926651, grad/param norm = 4.3115e-01, time/batch = 0.6884s	
800/33800 (epoch 1.183), train_loss = 2.30972015, grad/param norm = 3.3755e-01, time/batch = 0.6886s	
801/33800 (epoch 1.185), train_loss = 2.28991675, grad/param norm = 3.0850e-01, time/batch = 0.6911s	
802/33800 (epoch 1.186), train_loss = 2.30191945, grad/param norm = 2.5487e-01, time/batch = 0.6973s	
803/33800 (epoch 1.188), train_loss = 2.33265582, grad/param norm = 2.2436e-01, time/batch = 0.6999s	
804/33800 (epoch 1.189), train_loss = 2.23068561, grad/param norm = 3.0524e-01, time/batch = 0.7042s	
805/33800 (epoch 1.191), train_loss = 2.27642778, grad/param norm = 3.9523e-01, time/batch = 0.6959s	
806/33800 (epoch 1.192), train_loss = 2.21862562, grad/param norm = 3.8209e-01, time/batch = 0.7079s	
807/33800 (epoch 1.194), train_loss = 2.27802057, grad/param norm = 2.6063e-01, time/batch = 0.7328s	
808/33800 (epoch 1.195), train_loss = 2.09037677, grad/param norm = 3.2221e-01, time/batch = 0.7381s	
809/33800 (epoch 1.197), train_loss = 2.06036317, grad/param norm = 3.0503e-01, time/batch = 0.7328s	
810/33800 (epoch 1.198), train_loss = 2.23889996, grad/param norm = 2.2600e-01, time/batch = 0.7487s	
811/33800 (epoch 1.200), train_loss = 2.20895583, grad/param norm = 2.8409e-01, time/batch = 0.7500s	
812/33800 (epoch 1.201), train_loss = 2.32834354, grad/param norm = 3.3959e-01, time/batch = 0.7185s	
813/33800 (epoch 1.203), train_loss = 2.20433045, grad/param norm = 2.9226e-01, time/batch = 0.7382s	
814/33800 (epoch 1.204), train_loss = 2.20315527, grad/param norm = 3.0414e-01, time/batch = 0.7245s	
815/33800 (epoch 1.206), train_loss = 2.13218529, grad/param norm = 2.8280e-01, time/batch = 0.7096s	
816/33800 (epoch 1.207), train_loss = 2.36200976, grad/param norm = 3.4059e-01, time/batch = 0.7490s	
817/33800 (epoch 1.209), train_loss = 2.15340148, grad/param norm = 3.7405e-01, time/batch = 0.7487s	
818/33800 (epoch 1.210), train_loss = 2.25109783, grad/param norm = 2.5543e-01, time/batch = 0.7357s	
819/33800 (epoch 1.212), train_loss = 2.28675441, grad/param norm = 2.3473e-01, time/batch = 0.7302s	
820/33800 (epoch 1.213), train_loss = 2.37118885, grad/param norm = 3.5376e-01, time/batch = 0.7322s	
821/33800 (epoch 1.214), train_loss = 2.21477749, grad/param norm = 2.9556e-01, time/batch = 0.7335s	
822/33800 (epoch 1.216), train_loss = 2.09916583, grad/param norm = 2.2998e-01, time/batch = 0.7090s	
823/33800 (epoch 1.217), train_loss = 2.17696456, grad/param norm = 2.7159e-01, time/batch = 0.7407s	
824/33800 (epoch 1.219), train_loss = 2.16746877, grad/param norm = 2.7564e-01, time/batch = 0.7205s	
825/33800 (epoch 1.220), train_loss = 2.30620041, grad/param norm = 3.7339e-01, time/batch = 0.6948s	
826/33800 (epoch 1.222), train_loss = 2.32452123, grad/param norm = 3.5000e-01, time/batch = 0.6998s	
827/33800 (epoch 1.223), train_loss = 2.13973110, grad/param norm = 2.4451e-01, time/batch = 0.6959s	
828/33800 (epoch 1.225), train_loss = 2.21432914, grad/param norm = 2.3290e-01, time/batch = 0.6992s	
829/33800 (epoch 1.226), train_loss = 2.33398937, grad/param norm = 2.9873e-01, time/batch = 0.7001s	
830/33800 (epoch 1.228), train_loss = 2.20825759, grad/param norm = 3.2603e-01, time/batch = 0.7063s	
831/33800 (epoch 1.229), train_loss = 2.17790949, grad/param norm = 2.7448e-01, time/batch = 0.7080s	
832/33800 (epoch 1.231), train_loss = 2.29535428, grad/param norm = 2.8821e-01, time/batch = 0.7085s	
833/33800 (epoch 1.232), train_loss = 2.13331404, grad/param norm = 3.2803e-01, time/batch = 0.7077s	
834/33800 (epoch 1.234), train_loss = 2.27676008, grad/param norm = 2.8923e-01, time/batch = 0.7159s	
835/33800 (epoch 1.235), train_loss = 2.13892875, grad/param norm = 2.4940e-01, time/batch = 0.7023s	
836/33800 (epoch 1.237), train_loss = 2.25101926, grad/param norm = 2.7595e-01, time/batch = 0.6942s	
837/33800 (epoch 1.238), train_loss = 2.25323508, grad/param norm = 2.3647e-01, time/batch = 0.6990s	
838/33800 (epoch 1.240), train_loss = 2.14528938, grad/param norm = 2.4759e-01, time/batch = 0.6995s	
839/33800 (epoch 1.241), train_loss = 2.22774309, grad/param norm = 2.8712e-01, time/batch = 0.6938s	
840/33800 (epoch 1.243), train_loss = 2.11742850, grad/param norm = 2.7691e-01, time/batch = 0.6949s	
841/33800 (epoch 1.244), train_loss = 2.24432832, grad/param norm = 3.2482e-01, time/batch = 0.7026s	
842/33800 (epoch 1.246), train_loss = 2.27179387, grad/param norm = 3.5208e-01, time/batch = 0.7112s	
843/33800 (epoch 1.247), train_loss = 2.21689290, grad/param norm = 3.0799e-01, time/batch = 0.7151s	
844/33800 (epoch 1.249), train_loss = 2.27092018, grad/param norm = 3.0028e-01, time/batch = 0.7245s	
845/33800 (epoch 1.250), train_loss = 2.33633360, grad/param norm = 2.6779e-01, time/batch = 0.7075s	
846/33800 (epoch 1.251), train_loss = 2.59301247, grad/param norm = 3.8860e-01, time/batch = 0.7237s	
847/33800 (epoch 1.253), train_loss = 2.38097248, grad/param norm = 6.9371e-01, time/batch = 0.7044s	
848/33800 (epoch 1.254), train_loss = 2.37035587, grad/param norm = 4.8529e-01, time/batch = 0.7027s	
849/33800 (epoch 1.256), train_loss = 2.18625529, grad/param norm = 3.5154e-01, time/batch = 0.7023s	
850/33800 (epoch 1.257), train_loss = 2.24142000, grad/param norm = 2.1215e-01, time/batch = 0.6956s	
851/33800 (epoch 1.259), train_loss = 2.12085631, grad/param norm = 2.0673e-01, time/batch = 0.7097s	
852/33800 (epoch 1.260), train_loss = 2.09404334, grad/param norm = 2.2265e-01, time/batch = 0.7086s	
853/33800 (epoch 1.262), train_loss = 2.18082976, grad/param norm = 2.4664e-01, time/batch = 0.7070s	
854/33800 (epoch 1.263), train_loss = 2.29467999, grad/param norm = 3.3301e-01, time/batch = 0.6947s	
855/33800 (epoch 1.265), train_loss = 2.28694134, grad/param norm = 2.8983e-01, time/batch = 0.6879s	
856/33800 (epoch 1.266), train_loss = 2.24428315, grad/param norm = 2.6961e-01, time/batch = 0.6930s	
857/33800 (epoch 1.268), train_loss = 2.20568225, grad/param norm = 2.7076e-01, time/batch = 0.7450s	
858/33800 (epoch 1.269), train_loss = 2.19142703, grad/param norm = 2.9282e-01, time/batch = 0.7073s	
859/33800 (epoch 1.271), train_loss = 2.17938898, grad/param norm = 2.9058e-01, time/batch = 0.7023s	
860/33800 (epoch 1.272), train_loss = 2.19218520, grad/param norm = 2.9704e-01, time/batch = 0.7107s	
861/33800 (epoch 1.274), train_loss = 2.30622799, grad/param norm = 2.4129e-01, time/batch = 0.6939s	
862/33800 (epoch 1.275), train_loss = 2.09288222, grad/param norm = 2.6749e-01, time/batch = 0.7064s	
863/33800 (epoch 1.277), train_loss = 2.11092060, grad/param norm = 2.5880e-01, time/batch = 0.7045s	
864/33800 (epoch 1.278), train_loss = 2.17316253, grad/param norm = 2.8053e-01, time/batch = 0.7092s	
865/33800 (epoch 1.280), train_loss = 2.06772418, grad/param norm = 3.2098e-01, time/batch = 0.7023s	
866/33800 (epoch 1.281), train_loss = 2.20090056, grad/param norm = 2.9225e-01, time/batch = 0.6983s	
867/33800 (epoch 1.283), train_loss = 2.15374191, grad/param norm = 2.7623e-01, time/batch = 0.7040s	
868/33800 (epoch 1.284), train_loss = 2.24279068, grad/param norm = 3.4155e-01, time/batch = 0.7087s	
869/33800 (epoch 1.286), train_loss = 2.27763468, grad/param norm = 2.8993e-01, time/batch = 0.7026s	
870/33800 (epoch 1.287), train_loss = 2.12723595, grad/param norm = 2.8661e-01, time/batch = 0.6951s	
871/33800 (epoch 1.288), train_loss = 2.10935332, grad/param norm = 2.3282e-01, time/batch = 0.6969s	
872/33800 (epoch 1.290), train_loss = 2.09964719, grad/param norm = 2.3895e-01, time/batch = 0.6971s	
873/33800 (epoch 1.291), train_loss = 2.27942623, grad/param norm = 3.9204e-01, time/batch = 0.6995s	
874/33800 (epoch 1.293), train_loss = 2.20698119, grad/param norm = 3.8225e-01, time/batch = 0.6940s	
875/33800 (epoch 1.294), train_loss = 2.50444747, grad/param norm = 2.9581e-01, time/batch = 0.6933s	
876/33800 (epoch 1.296), train_loss = 2.27016693, grad/param norm = 3.7445e-01, time/batch = 0.6857s	
877/33800 (epoch 1.297), train_loss = 2.20452412, grad/param norm = 2.4857e-01, time/batch = 0.6876s	
878/33800 (epoch 1.299), train_loss = 2.11712429, grad/param norm = 2.5120e-01, time/batch = 0.6897s	
879/33800 (epoch 1.300), train_loss = 2.16677610, grad/param norm = 2.0904e-01, time/batch = 0.6865s	
880/33800 (epoch 1.302), train_loss = 2.24898561, grad/param norm = 2.3424e-01, time/batch = 0.6902s	
881/33800 (epoch 1.303), train_loss = 2.17520592, grad/param norm = 2.1755e-01, time/batch = 0.6822s	
882/33800 (epoch 1.305), train_loss = 2.14530469, grad/param norm = 2.2560e-01, time/batch = 0.6741s	
883/33800 (epoch 1.306), train_loss = 2.05393775, grad/param norm = 2.0482e-01, time/batch = 0.6737s	
884/33800 (epoch 1.308), train_loss = 2.21084296, grad/param norm = 2.5653e-01, time/batch = 0.6725s	
885/33800 (epoch 1.309), train_loss = 2.20953498, grad/param norm = 2.3479e-01, time/batch = 0.6707s	
886/33800 (epoch 1.311), train_loss = 2.13919857, grad/param norm = 2.2151e-01, time/batch = 0.6750s	
887/33800 (epoch 1.312), train_loss = 2.11288095, grad/param norm = 2.4436e-01, time/batch = 0.6815s	
888/33800 (epoch 1.314), train_loss = 2.20920503, grad/param norm = 2.4841e-01, time/batch = 0.6740s	
889/33800 (epoch 1.315), train_loss = 2.36653241, grad/param norm = 2.6188e-01, time/batch = 0.6768s	
890/33800 (epoch 1.317), train_loss = 2.17154070, grad/param norm = 2.7409e-01, time/batch = 0.6730s	
891/33800 (epoch 1.318), train_loss = 2.23123668, grad/param norm = 2.2879e-01, time/batch = 0.6781s	
892/33800 (epoch 1.320), train_loss = 2.36331628, grad/param norm = 2.8701e-01, time/batch = 0.6803s	
893/33800 (epoch 1.321), train_loss = 2.23936489, grad/param norm = 2.6720e-01, time/batch = 0.6830s	
894/33800 (epoch 1.322), train_loss = 2.13620730, grad/param norm = 2.3342e-01, time/batch = 0.6771s	
895/33800 (epoch 1.324), train_loss = 2.03965483, grad/param norm = 2.5480e-01, time/batch = 0.6746s	
896/33800 (epoch 1.325), train_loss = 2.13506529, grad/param norm = 3.3460e-01, time/batch = 0.6752s	
897/33800 (epoch 1.327), train_loss = 2.21762047, grad/param norm = 2.8047e-01, time/batch = 0.6755s	
898/33800 (epoch 1.328), train_loss = 2.10423572, grad/param norm = 2.1541e-01, time/batch = 0.6978s	
899/33800 (epoch 1.330), train_loss = 2.07195329, grad/param norm = 2.3289e-01, time/batch = 0.7004s	
900/33800 (epoch 1.331), train_loss = 2.18715225, grad/param norm = 2.5682e-01, time/batch = 0.6892s	
901/33800 (epoch 1.333), train_loss = 2.24549720, grad/param norm = 2.8230e-01, time/batch = 0.6931s	
902/33800 (epoch 1.334), train_loss = 2.14104285, grad/param norm = 2.4941e-01, time/batch = 0.6980s	
903/33800 (epoch 1.336), train_loss = 2.08314770, grad/param norm = 2.3210e-01, time/batch = 0.6959s	
904/33800 (epoch 1.337), train_loss = 2.07436040, grad/param norm = 2.1598e-01, time/batch = 0.6919s	
905/33800 (epoch 1.339), train_loss = 2.13967276, grad/param norm = 3.2843e-01, time/batch = 0.6941s	
906/33800 (epoch 1.340), train_loss = 2.29022226, grad/param norm = 3.9616e-01, time/batch = 0.6963s	
907/33800 (epoch 1.342), train_loss = 2.34650635, grad/param norm = 2.9655e-01, time/batch = 0.6872s	
908/33800 (epoch 1.343), train_loss = 2.20107083, grad/param norm = 3.0298e-01, time/batch = 0.6960s	
909/33800 (epoch 1.345), train_loss = 2.23696205, grad/param norm = 2.5228e-01, time/batch = 0.7016s	
910/33800 (epoch 1.346), train_loss = 2.47035422, grad/param norm = 2.5270e-01, time/batch = 0.6891s	
911/33800 (epoch 1.348), train_loss = 2.26160410, grad/param norm = 2.7122e-01, time/batch = 0.6937s	
912/33800 (epoch 1.349), train_loss = 2.25334906, grad/param norm = 3.2403e-01, time/batch = 0.6885s	
913/33800 (epoch 1.351), train_loss = 2.11754585, grad/param norm = 2.3346e-01, time/batch = 0.6852s	
914/33800 (epoch 1.352), train_loss = 2.26795785, grad/param norm = 2.2855e-01, time/batch = 0.6887s	
915/33800 (epoch 1.354), train_loss = 2.16692454, grad/param norm = 3.1701e-01, time/batch = 0.6883s	
916/33800 (epoch 1.355), train_loss = 2.09155681, grad/param norm = 3.6687e-01, time/batch = 0.6909s	
917/33800 (epoch 1.357), train_loss = 2.21566817, grad/param norm = 3.6557e-01, time/batch = 0.6911s	
918/33800 (epoch 1.358), train_loss = 2.28054797, grad/param norm = 3.5675e-01, time/batch = 0.6871s	
919/33800 (epoch 1.359), train_loss = 2.11386406, grad/param norm = 2.7358e-01, time/batch = 0.6849s	
920/33800 (epoch 1.361), train_loss = 2.16060250, grad/param norm = 2.9014e-01, time/batch = 0.6888s	
921/33800 (epoch 1.362), train_loss = 2.22455930, grad/param norm = 2.5232e-01, time/batch = 0.6899s	
922/33800 (epoch 1.364), train_loss = 2.36754763, grad/param norm = 2.4664e-01, time/batch = 0.6993s	
923/33800 (epoch 1.365), train_loss = 2.26015462, grad/param norm = 2.4144e-01, time/batch = 0.6889s	
924/33800 (epoch 1.367), train_loss = 2.15609812, grad/param norm = 2.5471e-01, time/batch = 0.6881s	
925/33800 (epoch 1.368), train_loss = 2.24032501, grad/param norm = 2.4216e-01, time/batch = 0.6891s	
926/33800 (epoch 1.370), train_loss = 2.24600839, grad/param norm = 2.2789e-01, time/batch = 0.6860s	
927/33800 (epoch 1.371), train_loss = 2.21033932, grad/param norm = 2.3052e-01, time/batch = 0.6870s	
928/33800 (epoch 1.373), train_loss = 2.32144555, grad/param norm = 2.6889e-01, time/batch = 0.7045s	
929/33800 (epoch 1.374), train_loss = 2.11499197, grad/param norm = 2.4935e-01, time/batch = 0.7120s	
930/33800 (epoch 1.376), train_loss = 2.19035112, grad/param norm = 2.6890e-01, time/batch = 0.7116s	
931/33800 (epoch 1.377), train_loss = 2.14927769, grad/param norm = 2.8983e-01, time/batch = 0.7027s	
932/33800 (epoch 1.379), train_loss = 2.32196618, grad/param norm = 3.0976e-01, time/batch = 0.6985s	
933/33800 (epoch 1.380), train_loss = 2.26142844, grad/param norm = 2.8088e-01, time/batch = 0.6941s	
934/33800 (epoch 1.382), train_loss = 2.09453551, grad/param norm = 2.5443e-01, time/batch = 0.7023s	
935/33800 (epoch 1.383), train_loss = 2.24999961, grad/param norm = 2.3909e-01, time/batch = 0.6978s	
936/33800 (epoch 1.385), train_loss = 2.23340342, grad/param norm = 2.3338e-01, time/batch = 0.6908s	
937/33800 (epoch 1.386), train_loss = 2.13934144, grad/param norm = 2.4082e-01, time/batch = 0.6907s	
938/33800 (epoch 1.388), train_loss = 2.23959864, grad/param norm = 2.1123e-01, time/batch = 0.6936s	
939/33800 (epoch 1.389), train_loss = 2.16895933, grad/param norm = 2.4075e-01, time/batch = 0.6926s	
940/33800 (epoch 1.391), train_loss = 2.30745177, grad/param norm = 2.7021e-01, time/batch = 0.6898s	
941/33800 (epoch 1.392), train_loss = 2.15853770, grad/param norm = 2.4264e-01, time/batch = 0.6911s	
942/33800 (epoch 1.393), train_loss = 2.20568501, grad/param norm = 2.5310e-01, time/batch = 0.6883s	
943/33800 (epoch 1.395), train_loss = 2.18841698, grad/param norm = 3.4356e-01, time/batch = 0.7082s	
944/33800 (epoch 1.396), train_loss = 2.19683961, grad/param norm = 4.6932e-01, time/batch = 0.7020s	
945/33800 (epoch 1.398), train_loss = 2.07837873, grad/param norm = 3.7007e-01, time/batch = 0.6933s	
946/33800 (epoch 1.399), train_loss = 2.24892444, grad/param norm = 3.0484e-01, time/batch = 0.6907s	
947/33800 (epoch 1.401), train_loss = 2.17179822, grad/param norm = 2.6756e-01, time/batch = 0.6870s	
948/33800 (epoch 1.402), train_loss = 2.26549112, grad/param norm = 2.2509e-01, time/batch = 0.6845s	
949/33800 (epoch 1.404), train_loss = 2.10353796, grad/param norm = 2.2465e-01, time/batch = 0.6896s	
950/33800 (epoch 1.405), train_loss = 2.28629431, grad/param norm = 2.6883e-01, time/batch = 0.6899s	
951/33800 (epoch 1.407), train_loss = 2.14868766, grad/param norm = 2.2584e-01, time/batch = 0.6939s	
952/33800 (epoch 1.408), train_loss = 2.23450364, grad/param norm = 2.5113e-01, time/batch = 0.6992s	
953/33800 (epoch 1.410), train_loss = 2.26781755, grad/param norm = 2.5931e-01, time/batch = 0.7004s	
954/33800 (epoch 1.411), train_loss = 2.13347226, grad/param norm = 2.2846e-01, time/batch = 0.6950s	
955/33800 (epoch 1.413), train_loss = 2.27963566, grad/param norm = 2.3181e-01, time/batch = 0.6905s	
956/33800 (epoch 1.414), train_loss = 2.07300998, grad/param norm = 2.7105e-01, time/batch = 0.6891s	
957/33800 (epoch 1.416), train_loss = 2.12398935, grad/param norm = 2.6242e-01, time/batch = 0.6926s	
958/33800 (epoch 1.417), train_loss = 2.04491706, grad/param norm = 2.5672e-01, time/batch = 0.6917s	
959/33800 (epoch 1.419), train_loss = 2.15431812, grad/param norm = 2.4534e-01, time/batch = 0.6921s	
960/33800 (epoch 1.420), train_loss = 2.21519414, grad/param norm = 2.2791e-01, time/batch = 0.6944s	
961/33800 (epoch 1.422), train_loss = 2.19941908, grad/param norm = 3.1783e-01, time/batch = 0.6939s	
962/33800 (epoch 1.423), train_loss = 2.11537567, grad/param norm = 3.1578e-01, time/batch = 0.6877s	
963/33800 (epoch 1.425), train_loss = 2.17693145, grad/param norm = 2.8206e-01, time/batch = 0.6869s	
964/33800 (epoch 1.426), train_loss = 2.14839249, grad/param norm = 2.4994e-01, time/batch = 0.6864s	
965/33800 (epoch 1.428), train_loss = 2.25480857, grad/param norm = 2.0712e-01, time/batch = 0.6885s	
966/33800 (epoch 1.429), train_loss = 2.09040201, grad/param norm = 2.5982e-01, time/batch = 0.6990s	
967/33800 (epoch 1.430), train_loss = 2.15480838, grad/param norm = 2.7131e-01, time/batch = 0.6826s	
968/33800 (epoch 1.432), train_loss = 2.08721046, grad/param norm = 2.8290e-01, time/batch = 0.6827s	
969/33800 (epoch 1.433), train_loss = 2.16528689, grad/param norm = 2.3405e-01, time/batch = 0.6879s	
970/33800 (epoch 1.435), train_loss = 2.24485057, grad/param norm = 2.4507e-01, time/batch = 0.6967s	
971/33800 (epoch 1.436), train_loss = 2.12551278, grad/param norm = 2.2373e-01, time/batch = 0.7052s	
972/33800 (epoch 1.438), train_loss = 2.07712423, grad/param norm = 2.6012e-01, time/batch = 0.6997s	
973/33800 (epoch 1.439), train_loss = 2.19245246, grad/param norm = 3.4887e-01, time/batch = 0.6977s	
974/33800 (epoch 1.441), train_loss = 2.11216319, grad/param norm = 3.0265e-01, time/batch = 0.6979s	
975/33800 (epoch 1.442), train_loss = 2.16679807, grad/param norm = 2.6848e-01, time/batch = 0.6909s	
976/33800 (epoch 1.444), train_loss = 2.12175662, grad/param norm = 2.4875e-01, time/batch = 0.6912s	
977/33800 (epoch 1.445), train_loss = 2.13000648, grad/param norm = 2.4373e-01, time/batch = 0.6980s	
978/33800 (epoch 1.447), train_loss = 2.06130353, grad/param norm = 2.9547e-01, time/batch = 0.7047s	
979/33800 (epoch 1.448), train_loss = 2.18611651, grad/param norm = 3.3186e-01, time/batch = 0.6961s	
980/33800 (epoch 1.450), train_loss = 2.09444911, grad/param norm = 2.4295e-01, time/batch = 0.6913s	
981/33800 (epoch 1.451), train_loss = 2.09453710, grad/param norm = 2.4201e-01, time/batch = 0.6947s	
982/33800 (epoch 1.453), train_loss = 2.22019723, grad/param norm = 2.1775e-01, time/batch = 0.6916s	
983/33800 (epoch 1.454), train_loss = 2.16956188, grad/param norm = 2.4646e-01, time/batch = 0.6854s	
984/33800 (epoch 1.456), train_loss = 2.08375377, grad/param norm = 2.6540e-01, time/batch = 0.6896s	
985/33800 (epoch 1.457), train_loss = 1.99917172, grad/param norm = 1.9969e-01, time/batch = 0.6868s	
986/33800 (epoch 1.459), train_loss = 2.15333908, grad/param norm = 2.2874e-01, time/batch = 0.6873s	
987/33800 (epoch 1.460), train_loss = 2.09990458, grad/param norm = 2.4363e-01, time/batch = 0.6949s	
988/33800 (epoch 1.462), train_loss = 2.16867316, grad/param norm = 2.0618e-01, time/batch = 0.7029s	
989/33800 (epoch 1.463), train_loss = 2.06969899, grad/param norm = 2.1685e-01, time/batch = 0.6923s	
990/33800 (epoch 1.464), train_loss = 2.20178482, grad/param norm = 2.5642e-01, time/batch = 0.6836s	
991/33800 (epoch 1.466), train_loss = 2.06722729, grad/param norm = 2.2066e-01, time/batch = 0.6883s	
992/33800 (epoch 1.467), train_loss = 2.14018391, grad/param norm = 2.5717e-01, time/batch = 0.6890s	
993/33800 (epoch 1.469), train_loss = 2.04641944, grad/param norm = 2.7580e-01, time/batch = 0.6845s	
994/33800 (epoch 1.470), train_loss = 2.07529783, grad/param norm = 2.2415e-01, time/batch = 0.6864s	
995/33800 (epoch 1.472), train_loss = 2.03048335, grad/param norm = 2.8350e-01, time/batch = 0.6841s	
996/33800 (epoch 1.473), train_loss = 2.15194505, grad/param norm = 2.8352e-01, time/batch = 0.6829s	
997/33800 (epoch 1.475), train_loss = 2.13381816, grad/param norm = 3.1348e-01, time/batch = 0.6813s	
998/33800 (epoch 1.476), train_loss = 2.13514847, grad/param norm = 3.1075e-01, time/batch = 0.6895s	
999/33800 (epoch 1.478), train_loss = 2.16955731, grad/param norm = 2.8553e-01, time/batch = 0.6938s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_npr_epoch1.48_2.1422.t7	
1000/33800 (epoch 1.479), train_loss = 2.22214834, grad/param norm = 2.7223e-01, time/batch = 0.6895s	
1001/33800 (epoch 1.481), train_loss = 2.19627963, grad/param norm = 2.5428e-01, time/batch = 0.7005s	
1002/33800 (epoch 1.482), train_loss = 2.27807207, grad/param norm = 2.9087e-01, time/batch = 0.6919s	
1003/33800 (epoch 1.484), train_loss = 2.10978052, grad/param norm = 2.6919e-01, time/batch = 0.6924s	
1004/33800 (epoch 1.485), train_loss = 2.04772125, grad/param norm = 2.0385e-01, time/batch = 0.6930s	
1005/33800 (epoch 1.487), train_loss = 2.11281226, grad/param norm = 2.4164e-01, time/batch = 0.7086s	
1006/33800 (epoch 1.488), train_loss = 2.12238835, grad/param norm = 2.3754e-01, time/batch = 0.7206s	
1007/33800 (epoch 1.490), train_loss = 2.16921991, grad/param norm = 2.3951e-01, time/batch = 0.7103s	
1008/33800 (epoch 1.491), train_loss = 2.04569106, grad/param norm = 2.0950e-01, time/batch = 0.6998s	
1009/33800 (epoch 1.493), train_loss = 2.09798590, grad/param norm = 3.4444e-01, time/batch = 0.6967s	
1010/33800 (epoch 1.494), train_loss = 2.24774001, grad/param norm = 3.4748e-01, time/batch = 0.7052s	
1011/33800 (epoch 1.496), train_loss = 2.08912053, grad/param norm = 2.4912e-01, time/batch = 0.7026s	
1012/33800 (epoch 1.497), train_loss = 2.16148601, grad/param norm = 2.3839e-01, time/batch = 0.6978s	
1013/33800 (epoch 1.499), train_loss = 2.06586280, grad/param norm = 2.3772e-01, time/batch = 0.7211s	
1014/33800 (epoch 1.500), train_loss = 2.24162334, grad/param norm = 2.7468e-01, time/batch = 0.7056s	
1015/33800 (epoch 1.501), train_loss = 2.13721208, grad/param norm = 2.6850e-01, time/batch = 0.6985s	
1016/33800 (epoch 1.503), train_loss = 2.22849895, grad/param norm = 2.3230e-01, time/batch = 0.6985s	
1017/33800 (epoch 1.504), train_loss = 2.07459847, grad/param norm = 2.2885e-01, time/batch = 0.6983s	
1018/33800 (epoch 1.506), train_loss = 2.18781395, grad/param norm = 2.4571e-01, time/batch = 0.6950s	
1019/33800 (epoch 1.507), train_loss = 2.08019766, grad/param norm = 2.1227e-01, time/batch = 0.6964s	
1020/33800 (epoch 1.509), train_loss = 2.15466388, grad/param norm = 2.7082e-01, time/batch = 0.6976s	
1021/33800 (epoch 1.510), train_loss = 2.03352242, grad/param norm = 2.8364e-01, time/batch = 0.6969s	
1022/33800 (epoch 1.512), train_loss = 2.07027792, grad/param norm = 3.1450e-01, time/batch = 0.7034s	
1023/33800 (epoch 1.513), train_loss = 2.22551487, grad/param norm = 2.5533e-01, time/batch = 0.7166s	
1024/33800 (epoch 1.515), train_loss = 2.18268231, grad/param norm = 2.2846e-01, time/batch = 0.6934s	
1025/33800 (epoch 1.516), train_loss = 2.15837208, grad/param norm = 2.4018e-01, time/batch = 0.6954s	
1026/33800 (epoch 1.518), train_loss = 2.22474032, grad/param norm = 3.7303e-01, time/batch = 0.6920s	
1027/33800 (epoch 1.519), train_loss = 2.03447830, grad/param norm = 2.9767e-01, time/batch = 0.6944s	
1028/33800 (epoch 1.521), train_loss = 2.11279554, grad/param norm = 2.3910e-01, time/batch = 0.6948s	
1029/33800 (epoch 1.522), train_loss = 1.98567997, grad/param norm = 2.3150e-01, time/batch = 0.6938s	
1030/33800 (epoch 1.524), train_loss = 2.10193637, grad/param norm = 2.0106e-01, time/batch = 0.7163s	
1031/33800 (epoch 1.525), train_loss = 2.15104900, grad/param norm = 1.9888e-01, time/batch = 0.7148s	
1032/33800 (epoch 1.527), train_loss = 2.08183868, grad/param norm = 2.2401e-01, time/batch = 0.7040s	
1033/33800 (epoch 1.528), train_loss = 2.13615070, grad/param norm = 2.4223e-01, time/batch = 0.6992s	
1034/33800 (epoch 1.530), train_loss = 2.23903617, grad/param norm = 2.4034e-01, time/batch = 0.6955s	
1035/33800 (epoch 1.531), train_loss = 2.19396334, grad/param norm = 2.4532e-01, time/batch = 0.7019s	
1036/33800 (epoch 1.533), train_loss = 2.04814444, grad/param norm = 2.7574e-01, time/batch = 0.6927s	
1037/33800 (epoch 1.534), train_loss = 2.02341890, grad/param norm = 2.4671e-01, time/batch = 0.6895s	
1038/33800 (epoch 1.536), train_loss = 2.29855444, grad/param norm = 2.5867e-01, time/batch = 0.6882s	
1039/33800 (epoch 1.537), train_loss = 2.17611277, grad/param norm = 2.0489e-01, time/batch = 0.6902s	
1040/33800 (epoch 1.538), train_loss = 2.11460620, grad/param norm = 2.2317e-01, time/batch = 0.6876s	
1041/33800 (epoch 1.540), train_loss = 2.06687418, grad/param norm = 2.3754e-01, time/batch = 0.6903s	
1042/33800 (epoch 1.541), train_loss = 2.04603339, grad/param norm = 2.0381e-01, time/batch = 0.6897s	
1043/33800 (epoch 1.543), train_loss = 2.02093495, grad/param norm = 2.2628e-01, time/batch = 0.6844s	
1044/33800 (epoch 1.544), train_loss = 2.25195914, grad/param norm = 2.9411e-01, time/batch = 0.6860s	
1045/33800 (epoch 1.546), train_loss = 2.38101775, grad/param norm = 2.9405e-01, time/batch = 0.6866s	
1046/33800 (epoch 1.547), train_loss = 2.31568647, grad/param norm = 2.8265e-01, time/batch = 0.6900s	
1047/33800 (epoch 1.549), train_loss = 2.18440657, grad/param norm = 3.0235e-01, time/batch = 0.6909s	
1048/33800 (epoch 1.550), train_loss = 2.11437325, grad/param norm = 2.7091e-01, time/batch = 0.6886s	
1049/33800 (epoch 1.552), train_loss = 2.19696413, grad/param norm = 2.7576e-01, time/batch = 0.7039s	
1050/33800 (epoch 1.553), train_loss = 2.31249192, grad/param norm = 2.5625e-01, time/batch = 0.7162s	
1051/33800 (epoch 1.555), train_loss = 2.08767244, grad/param norm = 2.6636e-01, time/batch = 0.7229s	
1052/33800 (epoch 1.556), train_loss = 2.00262474, grad/param norm = 2.7012e-01, time/batch = 0.7137s	
1053/33800 (epoch 1.558), train_loss = 1.95198043, grad/param norm = 2.6564e-01, time/batch = 0.7126s	
1054/33800 (epoch 1.559), train_loss = 2.23679577, grad/param norm = 2.6021e-01, time/batch = 0.7031s	
1055/33800 (epoch 1.561), train_loss = 2.06443516, grad/param norm = 2.3366e-01, time/batch = 0.7059s	
1056/33800 (epoch 1.562), train_loss = 2.13326947, grad/param norm = 2.1814e-01, time/batch = 0.7005s	
1057/33800 (epoch 1.564), train_loss = 2.10823047, grad/param norm = 2.0485e-01, time/batch = 0.7047s	
1058/33800 (epoch 1.565), train_loss = 2.35449390, grad/param norm = 2.5884e-01, time/batch = 0.7025s	
1059/33800 (epoch 1.567), train_loss = 2.17836519, grad/param norm = 2.8143e-01, time/batch = 0.7024s	
1060/33800 (epoch 1.568), train_loss = 2.14347973, grad/param norm = 3.1802e-01, time/batch = 0.6998s	
1061/33800 (epoch 1.570), train_loss = 2.15473916, grad/param norm = 3.5794e-01, time/batch = 0.7040s	
1062/33800 (epoch 1.571), train_loss = 2.06445344, grad/param norm = 2.9525e-01, time/batch = 0.6945s	
1063/33800 (epoch 1.572), train_loss = 2.21576425, grad/param norm = 2.1479e-01, time/batch = 0.6864s	
1064/33800 (epoch 1.574), train_loss = 2.21514214, grad/param norm = 2.4079e-01, time/batch = 0.6875s	
1065/33800 (epoch 1.575), train_loss = 2.03410919, grad/param norm = 2.0228e-01, time/batch = 0.6883s	
1066/33800 (epoch 1.577), train_loss = 2.11331457, grad/param norm = 2.2365e-01, time/batch = 0.6876s	
1067/33800 (epoch 1.578), train_loss = 2.08804206, grad/param norm = 2.2384e-01, time/batch = 0.6808s	
1068/33800 (epoch 1.580), train_loss = 2.13184821, grad/param norm = 2.4265e-01, time/batch = 0.6814s	
1069/33800 (epoch 1.581), train_loss = 2.13586350, grad/param norm = 2.5720e-01, time/batch = 0.6670s	
1070/33800 (epoch 1.583), train_loss = 2.22566659, grad/param norm = 2.4598e-01, time/batch = 0.6710s	
1071/33800 (epoch 1.584), train_loss = 2.13825462, grad/param norm = 2.0341e-01, time/batch = 0.6732s	
1072/33800 (epoch 1.586), train_loss = 2.02603140, grad/param norm = 2.4138e-01, time/batch = 0.6757s	
1073/33800 (epoch 1.587), train_loss = 1.94689853, grad/param norm = 2.1807e-01, time/batch = 0.6779s	
1074/33800 (epoch 1.589), train_loss = 2.09840705, grad/param norm = 2.0587e-01, time/batch = 0.6813s	
1075/33800 (epoch 1.590), train_loss = 2.13075686, grad/param norm = 2.4701e-01, time/batch = 0.6790s	
1076/33800 (epoch 1.592), train_loss = 2.10088582, grad/param norm = 2.3184e-01, time/batch = 0.6807s	
1077/33800 (epoch 1.593), train_loss = 2.10326446, grad/param norm = 2.9432e-01, time/batch = 0.6786s	
1078/33800 (epoch 1.595), train_loss = 2.16488527, grad/param norm = 2.7395e-01, time/batch = 0.6785s	
1079/33800 (epoch 1.596), train_loss = 2.20504152, grad/param norm = 3.1548e-01, time/batch = 0.6801s	
1080/33800 (epoch 1.598), train_loss = 2.16671823, grad/param norm = 3.0481e-01, time/batch = 0.6801s	
1081/33800 (epoch 1.599), train_loss = 2.11957076, grad/param norm = 2.4567e-01, time/batch = 0.6801s	
1082/33800 (epoch 1.601), train_loss = 1.98168558, grad/param norm = 3.0388e-01, time/batch = 0.6849s	
1083/33800 (epoch 1.602), train_loss = 2.21262158, grad/param norm = 2.9440e-01, time/batch = 0.6833s	
1084/33800 (epoch 1.604), train_loss = 2.21358623, grad/param norm = 2.4042e-01, time/batch = 0.6794s	
1085/33800 (epoch 1.605), train_loss = 2.16490390, grad/param norm = 2.4411e-01, time/batch = 0.6715s	
1086/33800 (epoch 1.607), train_loss = 2.12728414, grad/param norm = 2.6950e-01, time/batch = 0.6780s	
1087/33800 (epoch 1.608), train_loss = 2.17711670, grad/param norm = 2.2495e-01, time/batch = 0.6741s	
1088/33800 (epoch 1.609), train_loss = 2.10713982, grad/param norm = 2.3132e-01, time/batch = 0.6733s	
1089/33800 (epoch 1.611), train_loss = 2.13307206, grad/param norm = 2.6463e-01, time/batch = 0.6748s	
1090/33800 (epoch 1.612), train_loss = 2.03059019, grad/param norm = 2.1446e-01, time/batch = 0.6775s	
1091/33800 (epoch 1.614), train_loss = 2.08514208, grad/param norm = 2.4928e-01, time/batch = 0.6997s	
1092/33800 (epoch 1.615), train_loss = 2.07830977, grad/param norm = 2.7192e-01, time/batch = 0.7064s	
1093/33800 (epoch 1.617), train_loss = 2.17104774, grad/param norm = 2.4732e-01, time/batch = 0.6912s	
1094/33800 (epoch 1.618), train_loss = 2.19244899, grad/param norm = 2.4269e-01, time/batch = 0.6887s	
1095/33800 (epoch 1.620), train_loss = 2.08465893, grad/param norm = 2.3819e-01, time/batch = 0.6874s	
1096/33800 (epoch 1.621), train_loss = 2.07617213, grad/param norm = 2.0559e-01, time/batch = 0.6792s	
1097/33800 (epoch 1.623), train_loss = 2.06403128, grad/param norm = 2.2254e-01, time/batch = 0.6880s	
1098/33800 (epoch 1.624), train_loss = 2.10062792, grad/param norm = 2.2997e-01, time/batch = 0.6917s	
1099/33800 (epoch 1.626), train_loss = 2.15522610, grad/param norm = 2.5001e-01, time/batch = 0.6854s	
1100/33800 (epoch 1.627), train_loss = 2.09043441, grad/param norm = 2.1392e-01, time/batch = 0.6884s	
1101/33800 (epoch 1.629), train_loss = 2.27876741, grad/param norm = 2.5827e-01, time/batch = 0.6949s	
1102/33800 (epoch 1.630), train_loss = 2.16011957, grad/param norm = 2.2144e-01, time/batch = 0.6934s	
1103/33800 (epoch 1.632), train_loss = 2.14564336, grad/param norm = 2.0535e-01, time/batch = 0.6957s	
1104/33800 (epoch 1.633), train_loss = 2.15249933, grad/param norm = 2.4463e-01, time/batch = 0.6903s	
1105/33800 (epoch 1.635), train_loss = 2.09073156, grad/param norm = 2.2404e-01, time/batch = 0.6909s	
1106/33800 (epoch 1.636), train_loss = 2.11756674, grad/param norm = 2.2942e-01, time/batch = 0.6986s	
1107/33800 (epoch 1.638), train_loss = 2.09838725, grad/param norm = 2.3913e-01, time/batch = 0.6963s	
1108/33800 (epoch 1.639), train_loss = 2.19965451, grad/param norm = 2.7292e-01, time/batch = 0.6880s	
1109/33800 (epoch 1.641), train_loss = 2.08905506, grad/param norm = 2.3300e-01, time/batch = 0.6834s	
1110/33800 (epoch 1.642), train_loss = 2.07227736, grad/param norm = 2.6537e-01, time/batch = 0.6854s	
1111/33800 (epoch 1.643), train_loss = 2.06666642, grad/param norm = 2.4051e-01, time/batch = 0.6924s	
1112/33800 (epoch 1.645), train_loss = 2.28183549, grad/param norm = 2.4268e-01, time/batch = 0.6900s	
1113/33800 (epoch 1.646), train_loss = 2.09930238, grad/param norm = 2.4453e-01, time/batch = 0.6832s	
1114/33800 (epoch 1.648), train_loss = 2.14036403, grad/param norm = 2.8259e-01, time/batch = 0.6880s	
1115/33800 (epoch 1.649), train_loss = 2.10307611, grad/param norm = 3.6291e-01, time/batch = 0.6800s	
1116/33800 (epoch 1.651), train_loss = 2.11370386, grad/param norm = 3.8547e-01, time/batch = 0.6900s	
1117/33800 (epoch 1.652), train_loss = 2.13028104, grad/param norm = 3.7461e-01, time/batch = 0.6910s	
1118/33800 (epoch 1.654), train_loss = 2.13478921, grad/param norm = 2.7111e-01, time/batch = 0.6762s	
1119/33800 (epoch 1.655), train_loss = 1.94567555, grad/param norm = 2.5318e-01, time/batch = 0.6727s	
1120/33800 (epoch 1.657), train_loss = 2.02972961, grad/param norm = 2.4081e-01, time/batch = 0.6834s	
1121/33800 (epoch 1.658), train_loss = 1.94501655, grad/param norm = 2.0017e-01, time/batch = 0.6778s	
1122/33800 (epoch 1.660), train_loss = 2.08947928, grad/param norm = 2.2284e-01, time/batch = 0.6754s	
1123/33800 (epoch 1.661), train_loss = 2.05357053, grad/param norm = 2.1733e-01, time/batch = 0.6759s	
1124/33800 (epoch 1.663), train_loss = 2.13303998, grad/param norm = 2.5932e-01, time/batch = 0.6756s	
1125/33800 (epoch 1.664), train_loss = 2.08207856, grad/param norm = 2.4149e-01, time/batch = 0.6728s	
1126/33800 (epoch 1.666), train_loss = 2.02954984, grad/param norm = 2.2485e-01, time/batch = 0.6790s	
1127/33800 (epoch 1.667), train_loss = 2.21884374, grad/param norm = 2.3460e-01, time/batch = 0.6783s	
1128/33800 (epoch 1.669), train_loss = 2.04032186, grad/param norm = 2.0650e-01, time/batch = 0.6882s	
1129/33800 (epoch 1.670), train_loss = 2.15748611, grad/param norm = 2.1912e-01, time/batch = 0.6919s	
1130/33800 (epoch 1.672), train_loss = 2.06288191, grad/param norm = 2.3650e-01, time/batch = 0.6896s	
1131/33800 (epoch 1.673), train_loss = 2.04428695, grad/param norm = 2.3192e-01, time/batch = 0.6895s	
1132/33800 (epoch 1.675), train_loss = 1.94768945, grad/param norm = 2.3626e-01, time/batch = 0.6819s	
1133/33800 (epoch 1.676), train_loss = 2.17894640, grad/param norm = 2.2279e-01, time/batch = 0.6992s	
1134/33800 (epoch 1.678), train_loss = 1.99373860, grad/param norm = 2.2682e-01, time/batch = 0.6949s	
1135/33800 (epoch 1.679), train_loss = 2.13639346, grad/param norm = 2.1309e-01, time/batch = 0.6871s	
1136/33800 (epoch 1.680), train_loss = 1.87271757, grad/param norm = 2.3165e-01, time/batch = 0.6899s	
1137/33800 (epoch 1.682), train_loss = 2.13411657, grad/param norm = 2.1887e-01, time/batch = 0.6905s	
1138/33800 (epoch 1.683), train_loss = 2.23574752, grad/param norm = 2.1916e-01, time/batch = 0.6930s	
1139/33800 (epoch 1.685), train_loss = 2.05275693, grad/param norm = 2.2430e-01, time/batch = 0.7143s	
1140/33800 (epoch 1.686), train_loss = 2.04124327, grad/param norm = 2.6454e-01, time/batch = 0.7075s	
1141/33800 (epoch 1.688), train_loss = 2.17308155, grad/param norm = 2.4485e-01, time/batch = 0.7124s	
1142/33800 (epoch 1.689), train_loss = 2.10632260, grad/param norm = 2.1655e-01, time/batch = 0.6921s	
1143/33800 (epoch 1.691), train_loss = 2.18569787, grad/param norm = 2.1128e-01, time/batch = 0.6963s	
1144/33800 (epoch 1.692), train_loss = 2.19018552, grad/param norm = 2.1051e-01, time/batch = 0.6976s	
1145/33800 (epoch 1.694), train_loss = 2.12246164, grad/param norm = 2.7220e-01, time/batch = 0.6840s	
1146/33800 (epoch 1.695), train_loss = 2.23649049, grad/param norm = 3.1810e-01, time/batch = 0.6872s	
1147/33800 (epoch 1.697), train_loss = 2.09185394, grad/param norm = 2.3320e-01, time/batch = 0.6867s	
1148/33800 (epoch 1.698), train_loss = 2.12020347, grad/param norm = 2.3358e-01, time/batch = 0.6837s	
1149/33800 (epoch 1.700), train_loss = 2.10825176, grad/param norm = 2.8002e-01, time/batch = 0.6819s	
1150/33800 (epoch 1.701), train_loss = 2.10419479, grad/param norm = 3.1464e-01, time/batch = 0.6882s	
1151/33800 (epoch 1.703), train_loss = 2.08868701, grad/param norm = 2.5014e-01, time/batch = 0.6896s	
1152/33800 (epoch 1.704), train_loss = 2.05293985, grad/param norm = 2.3211e-01, time/batch = 0.6930s	
1153/33800 (epoch 1.706), train_loss = 2.05667532, grad/param norm = 2.3646e-01, time/batch = 0.6887s	
1154/33800 (epoch 1.707), train_loss = 2.09521808, grad/param norm = 2.4292e-01, time/batch = 0.6864s	
1155/33800 (epoch 1.709), train_loss = 2.07732967, grad/param norm = 2.8867e-01, time/batch = 0.6902s	
1156/33800 (epoch 1.710), train_loss = 2.11861396, grad/param norm = 3.4635e-01, time/batch = 0.6848s	
1157/33800 (epoch 1.712), train_loss = 2.22868403, grad/param norm = 3.0508e-01, time/batch = 0.6825s	
1158/33800 (epoch 1.713), train_loss = 2.17199667, grad/param norm = 2.8190e-01, time/batch = 0.6855s	
1159/33800 (epoch 1.714), train_loss = 2.01863464, grad/param norm = 2.1446e-01, time/batch = 0.6835s	
1160/33800 (epoch 1.716), train_loss = 2.06135754, grad/param norm = 2.4764e-01, time/batch = 0.6831s	
1161/33800 (epoch 1.717), train_loss = 2.03370427, grad/param norm = 2.2604e-01, time/batch = 0.6887s	
1162/33800 (epoch 1.719), train_loss = 2.15352058, grad/param norm = 2.3680e-01, time/batch = 0.6796s	
1163/33800 (epoch 1.720), train_loss = 2.00758265, grad/param norm = 2.9143e-01, time/batch = 0.6857s	
1164/33800 (epoch 1.722), train_loss = 2.07829081, grad/param norm = 2.6121e-01, time/batch = 0.6851s	
1165/33800 (epoch 1.723), train_loss = 2.08438313, grad/param norm = 2.2405e-01, time/batch = 0.6872s	
1166/33800 (epoch 1.725), train_loss = 2.02017697, grad/param norm = 2.3920e-01, time/batch = 0.6860s	
1167/33800 (epoch 1.726), train_loss = 1.90305929, grad/param norm = 1.9400e-01, time/batch = 0.6908s	
1168/33800 (epoch 1.728), train_loss = 2.13429792, grad/param norm = 2.0200e-01, time/batch = 0.7024s	
1169/33800 (epoch 1.729), train_loss = 2.15322406, grad/param norm = 2.5517e-01, time/batch = 0.6988s	
1170/33800 (epoch 1.731), train_loss = 2.07661900, grad/param norm = 2.0846e-01, time/batch = 0.6889s	
1171/33800 (epoch 1.732), train_loss = 2.16820454, grad/param norm = 1.9597e-01, time/batch = 0.6884s	
1172/33800 (epoch 1.734), train_loss = 2.05234332, grad/param norm = 2.2696e-01, time/batch = 0.6834s	
1173/33800 (epoch 1.735), train_loss = 2.06904747, grad/param norm = 2.4455e-01, time/batch = 0.6826s	
1174/33800 (epoch 1.737), train_loss = 2.07391518, grad/param norm = 2.1410e-01, time/batch = 0.6842s	
1175/33800 (epoch 1.738), train_loss = 2.10474405, grad/param norm = 2.2649e-01, time/batch = 0.6858s	
1176/33800 (epoch 1.740), train_loss = 2.22548169, grad/param norm = 2.6228e-01, time/batch = 0.6966s	
1177/33800 (epoch 1.741), train_loss = 2.10241366, grad/param norm = 2.5622e-01, time/batch = 0.6984s	
1178/33800 (epoch 1.743), train_loss = 2.00808967, grad/param norm = 2.1854e-01, time/batch = 0.7094s	
1179/33800 (epoch 1.744), train_loss = 1.97288117, grad/param norm = 2.0216e-01, time/batch = 0.7162s	
1180/33800 (epoch 1.746), train_loss = 1.95807948, grad/param norm = 2.3742e-01, time/batch = 0.7032s	
1181/33800 (epoch 1.747), train_loss = 2.06768717, grad/param norm = 2.4181e-01, time/batch = 0.7064s	
1182/33800 (epoch 1.749), train_loss = 2.05758148, grad/param norm = 2.4911e-01, time/batch = 0.7030s	
1183/33800 (epoch 1.750), train_loss = 1.92778367, grad/param norm = 2.7544e-01, time/batch = 0.6933s	
1184/33800 (epoch 1.751), train_loss = 2.25800627, grad/param norm = 3.1678e-01, time/batch = 0.6959s	
1185/33800 (epoch 1.753), train_loss = 2.08348083, grad/param norm = 2.3553e-01, time/batch = 0.6916s	
1186/33800 (epoch 1.754), train_loss = 2.09361799, grad/param norm = 2.1011e-01, time/batch = 0.6936s	
1187/33800 (epoch 1.756), train_loss = 2.15971837, grad/param norm = 2.0318e-01, time/batch = 0.6999s	
1188/33800 (epoch 1.757), train_loss = 2.08861121, grad/param norm = 2.0855e-01, time/batch = 0.7023s	
1189/33800 (epoch 1.759), train_loss = 2.07577871, grad/param norm = 2.7437e-01, time/batch = 0.7108s	
1190/33800 (epoch 1.760), train_loss = 2.03092472, grad/param norm = 2.9155e-01, time/batch = 0.7084s	
1191/33800 (epoch 1.762), train_loss = 2.22244136, grad/param norm = 2.7711e-01, time/batch = 0.6998s	
1192/33800 (epoch 1.763), train_loss = 1.92265273, grad/param norm = 2.3110e-01, time/batch = 0.7002s	
1193/33800 (epoch 1.765), train_loss = 2.10960315, grad/param norm = 2.3195e-01, time/batch = 0.6949s	
1194/33800 (epoch 1.766), train_loss = 2.13098446, grad/param norm = 2.3278e-01, time/batch = 0.6946s	
1195/33800 (epoch 1.768), train_loss = 1.89063631, grad/param norm = 2.3189e-01, time/batch = 0.6941s	
1196/33800 (epoch 1.769), train_loss = 1.97837008, grad/param norm = 2.5081e-01, time/batch = 0.6919s	
1197/33800 (epoch 1.771), train_loss = 2.04382366, grad/param norm = 2.0082e-01, time/batch = 0.6893s	
1198/33800 (epoch 1.772), train_loss = 1.94933238, grad/param norm = 2.2341e-01, time/batch = 0.7017s	
1199/33800 (epoch 1.774), train_loss = 2.13414956, grad/param norm = 2.2722e-01, time/batch = 0.6964s	
1200/33800 (epoch 1.775), train_loss = 2.05860799, grad/param norm = 2.0412e-01, time/batch = 0.6966s	
1201/33800 (epoch 1.777), train_loss = 2.06586018, grad/param norm = 2.3766e-01, time/batch = 0.6993s	
1202/33800 (epoch 1.778), train_loss = 2.16751339, grad/param norm = 2.5600e-01, time/batch = 0.6915s	
1203/33800 (epoch 1.780), train_loss = 2.12447563, grad/param norm = 2.1663e-01, time/batch = 0.6851s	
1204/33800 (epoch 1.781), train_loss = 2.09113759, grad/param norm = 2.7009e-01, time/batch = 0.6959s	
1205/33800 (epoch 1.783), train_loss = 2.01120061, grad/param norm = 2.2204e-01, time/batch = 0.6856s	
1206/33800 (epoch 1.784), train_loss = 2.14058886, grad/param norm = 2.2576e-01, time/batch = 0.6910s	
1207/33800 (epoch 1.786), train_loss = 2.10536020, grad/param norm = 2.6163e-01, time/batch = 0.6889s	
1208/33800 (epoch 1.787), train_loss = 2.06256351, grad/param norm = 3.0395e-01, time/batch = 0.7010s	
1209/33800 (epoch 1.788), train_loss = 2.05788264, grad/param norm = 2.5821e-01, time/batch = 0.6921s	
1210/33800 (epoch 1.790), train_loss = 1.91682463, grad/param norm = 1.9256e-01, time/batch = 0.6876s	
1211/33800 (epoch 1.791), train_loss = 1.97973550, grad/param norm = 2.4026e-01, time/batch = 0.6904s	
1212/33800 (epoch 1.793), train_loss = 2.16816479, grad/param norm = 2.8041e-01, time/batch = 0.6971s	
1213/33800 (epoch 1.794), train_loss = 2.14447387, grad/param norm = 2.3004e-01, time/batch = 0.6868s	
1214/33800 (epoch 1.796), train_loss = 2.11936186, grad/param norm = 2.8703e-01, time/batch = 0.6980s	
1215/33800 (epoch 1.797), train_loss = 1.90236561, grad/param norm = 2.3046e-01, time/batch = 0.6930s	
1216/33800 (epoch 1.799), train_loss = 2.00521743, grad/param norm = 2.1892e-01, time/batch = 0.6905s	
1217/33800 (epoch 1.800), train_loss = 2.13795294, grad/param norm = 2.8552e-01, time/batch = 0.6862s	
1218/33800 (epoch 1.802), train_loss = 2.01247695, grad/param norm = 2.4555e-01, time/batch = 0.6846s	
1219/33800 (epoch 1.803), train_loss = 2.14137215, grad/param norm = 2.1238e-01, time/batch = 0.6879s	
1220/33800 (epoch 1.805), train_loss = 2.02234680, grad/param norm = 2.3042e-01, time/batch = 0.6862s	
1221/33800 (epoch 1.806), train_loss = 1.94704734, grad/param norm = 2.0602e-01, time/batch = 0.6900s	
1222/33800 (epoch 1.808), train_loss = 2.09649562, grad/param norm = 2.4991e-01, time/batch = 0.6951s	
1223/33800 (epoch 1.809), train_loss = 2.08195895, grad/param norm = 2.4434e-01, time/batch = 0.6912s	
1224/33800 (epoch 1.811), train_loss = 1.93677768, grad/param norm = 2.2204e-01, time/batch = 0.6837s	
1225/33800 (epoch 1.812), train_loss = 2.06794227, grad/param norm = 2.3536e-01, time/batch = 0.6819s	
1226/33800 (epoch 1.814), train_loss = 2.06368947, grad/param norm = 2.3722e-01, time/batch = 0.6850s	
1227/33800 (epoch 1.815), train_loss = 1.95661922, grad/param norm = 2.4852e-01, time/batch = 0.6905s	
1228/33800 (epoch 1.817), train_loss = 2.04066274, grad/param norm = 2.1163e-01, time/batch = 0.7028s	
1229/33800 (epoch 1.818), train_loss = 2.16478244, grad/param norm = 2.2811e-01, time/batch = 0.6970s	
1230/33800 (epoch 1.820), train_loss = 2.02250278, grad/param norm = 1.9877e-01, time/batch = 0.6993s	
1231/33800 (epoch 1.821), train_loss = 2.07990668, grad/param norm = 2.3292e-01, time/batch = 0.7048s	
1232/33800 (epoch 1.822), train_loss = 2.05581432, grad/param norm = 2.6689e-01, time/batch = 0.6959s	
1233/33800 (epoch 1.824), train_loss = 2.07362265, grad/param norm = 2.6162e-01, time/batch = 0.6938s	
1234/33800 (epoch 1.825), train_loss = 2.08838468, grad/param norm = 2.7793e-01, time/batch = 0.6922s	
1235/33800 (epoch 1.827), train_loss = 2.11198976, grad/param norm = 2.4209e-01, time/batch = 0.6908s	
1236/33800 (epoch 1.828), train_loss = 2.06038971, grad/param norm = 1.9750e-01, time/batch = 0.6904s	
1237/33800 (epoch 1.830), train_loss = 1.97198556, grad/param norm = 2.2428e-01, time/batch = 0.6915s	
1238/33800 (epoch 1.831), train_loss = 2.15032443, grad/param norm = 2.3487e-01, time/batch = 0.6912s	
1239/33800 (epoch 1.833), train_loss = 2.03882123, grad/param norm = 2.1400e-01, time/batch = 0.6923s	
1240/33800 (epoch 1.834), train_loss = 2.05870656, grad/param norm = 2.2961e-01, time/batch = 0.7047s	
1241/33800 (epoch 1.836), train_loss = 2.02876519, grad/param norm = 2.3792e-01, time/batch = 0.7129s	
1242/33800 (epoch 1.837), train_loss = 2.13334123, grad/param norm = 2.2536e-01, time/batch = 0.7091s	
1243/33800 (epoch 1.839), train_loss = 1.93157125, grad/param norm = 1.9916e-01, time/batch = 0.6990s	
1244/33800 (epoch 1.840), train_loss = 2.04544544, grad/param norm = 2.0286e-01, time/batch = 0.6909s	
1245/33800 (epoch 1.842), train_loss = 1.96354803, grad/param norm = 1.9968e-01, time/batch = 0.6918s	
1246/33800 (epoch 1.843), train_loss = 1.97635330, grad/param norm = 2.2157e-01, time/batch = 0.6908s	
1247/33800 (epoch 1.845), train_loss = 2.16365500, grad/param norm = 2.1617e-01, time/batch = 0.6921s	
1248/33800 (epoch 1.846), train_loss = 2.11472070, grad/param norm = 2.1009e-01, time/batch = 0.6921s	
1249/33800 (epoch 1.848), train_loss = 2.17478039, grad/param norm = 2.0754e-01, time/batch = 0.6926s	
1250/33800 (epoch 1.849), train_loss = 1.96196660, grad/param norm = 2.5831e-01, time/batch = 0.6868s	
1251/33800 (epoch 1.851), train_loss = 2.04849051, grad/param norm = 2.5618e-01, time/batch = 0.6886s	
1252/33800 (epoch 1.852), train_loss = 1.99400382, grad/param norm = 2.4216e-01, time/batch = 0.6877s	
1253/33800 (epoch 1.854), train_loss = 2.08254071, grad/param norm = 2.2756e-01, time/batch = 0.6887s	
1254/33800 (epoch 1.855), train_loss = 1.97420662, grad/param norm = 2.3536e-01, time/batch = 0.6896s	
1255/33800 (epoch 1.857), train_loss = 2.14480959, grad/param norm = 2.4862e-01, time/batch = 0.7198s	
1256/33800 (epoch 1.858), train_loss = 1.98723558, grad/param norm = 2.8244e-01, time/batch = 0.7198s	
1257/33800 (epoch 1.859), train_loss = 2.07771262, grad/param norm = 2.5296e-01, time/batch = 0.7021s	
1258/33800 (epoch 1.861), train_loss = 2.16523512, grad/param norm = 2.9545e-01, time/batch = 0.6904s	
1259/33800 (epoch 1.862), train_loss = 2.05072514, grad/param norm = 2.6900e-01, time/batch = 0.6907s	
1260/33800 (epoch 1.864), train_loss = 2.30351607, grad/param norm = 3.0082e-01, time/batch = 0.6887s	
1261/33800 (epoch 1.865), train_loss = 2.12782395, grad/param norm = 2.4440e-01, time/batch = 0.6935s	
1262/33800 (epoch 1.867), train_loss = 2.06924826, grad/param norm = 2.4554e-01, time/batch = 0.6968s	
1263/33800 (epoch 1.868), train_loss = 1.77641846, grad/param norm = 2.2940e-01, time/batch = 0.7084s	
1264/33800 (epoch 1.870), train_loss = 2.00385605, grad/param norm = 2.5508e-01, time/batch = 0.7090s	
1265/33800 (epoch 1.871), train_loss = 2.07818939, grad/param norm = 2.3236e-01, time/batch = 0.7213s	
1266/33800 (epoch 1.873), train_loss = 1.98402290, grad/param norm = 2.3166e-01, time/batch = 0.7456s	
1267/33800 (epoch 1.874), train_loss = 2.13004845, grad/param norm = 2.3509e-01, time/batch = 0.7479s	
1268/33800 (epoch 1.876), train_loss = 2.01194452, grad/param norm = 2.0858e-01, time/batch = 0.7469s	
1269/33800 (epoch 1.877), train_loss = 2.05100568, grad/param norm = 2.1511e-01, time/batch = 0.7103s	
1270/33800 (epoch 1.879), train_loss = 2.08134170, grad/param norm = 2.5040e-01, time/batch = 0.6937s	
1271/33800 (epoch 1.880), train_loss = 2.13752560, grad/param norm = 2.3516e-01, time/batch = 0.6963s	
1272/33800 (epoch 1.882), train_loss = 1.99258811, grad/param norm = 2.1683e-01, time/batch = 0.6881s	
1273/33800 (epoch 1.883), train_loss = 1.98410172, grad/param norm = 2.4322e-01, time/batch = 0.6876s	
1274/33800 (epoch 1.885), train_loss = 2.00662375, grad/param norm = 2.2779e-01, time/batch = 0.6815s	
1275/33800 (epoch 1.886), train_loss = 2.04464787, grad/param norm = 2.4292e-01, time/batch = 0.6784s	
1276/33800 (epoch 1.888), train_loss = 2.00518318, grad/param norm = 2.0146e-01, time/batch = 0.6773s	
1277/33800 (epoch 1.889), train_loss = 1.86494623, grad/param norm = 2.0273e-01, time/batch = 0.6777s	
1278/33800 (epoch 1.891), train_loss = 1.98996230, grad/param norm = 2.0861e-01, time/batch = 0.6740s	
1279/33800 (epoch 1.892), train_loss = 2.03209770, grad/param norm = 3.0106e-01, time/batch = 0.6735s	
1280/33800 (epoch 1.893), train_loss = 1.99095244, grad/param norm = 3.1551e-01, time/batch = 0.6823s	
1281/33800 (epoch 1.895), train_loss = 2.20470614, grad/param norm = 2.6836e-01, time/batch = 0.6756s	
1282/33800 (epoch 1.896), train_loss = 2.02834803, grad/param norm = 2.5438e-01, time/batch = 0.6766s	
1283/33800 (epoch 1.898), train_loss = 2.05395218, grad/param norm = 2.5869e-01, time/batch = 0.6686s	
1284/33800 (epoch 1.899), train_loss = 1.92469948, grad/param norm = 2.6047e-01, time/batch = 0.6737s	
1285/33800 (epoch 1.901), train_loss = 2.16328567, grad/param norm = 2.3951e-01, time/batch = 0.6910s	
1286/33800 (epoch 1.902), train_loss = 2.12832489, grad/param norm = 2.0635e-01, time/batch = 0.6897s	
1287/33800 (epoch 1.904), train_loss = 1.94587511, grad/param norm = 2.1385e-01, time/batch = 0.6882s	
1288/33800 (epoch 1.905), train_loss = 2.03119776, grad/param norm = 2.2070e-01, time/batch = 0.6738s	
1289/33800 (epoch 1.907), train_loss = 1.95798237, grad/param norm = 2.0797e-01, time/batch = 0.6730s	
1290/33800 (epoch 1.908), train_loss = 2.10401347, grad/param norm = 2.4187e-01, time/batch = 0.6789s	
1291/33800 (epoch 1.910), train_loss = 2.16731479, grad/param norm = 2.4363e-01, time/batch = 0.6779s	
1292/33800 (epoch 1.911), train_loss = 2.12885895, grad/param norm = 2.2084e-01, time/batch = 0.6980s	
1293/33800 (epoch 1.913), train_loss = 2.11035413, grad/param norm = 2.1162e-01, time/batch = 0.6880s	
1294/33800 (epoch 1.914), train_loss = 2.12219073, grad/param norm = 2.0201e-01, time/batch = 0.6810s	
1295/33800 (epoch 1.916), train_loss = 2.01261637, grad/param norm = 2.1907e-01, time/batch = 0.6749s	
1296/33800 (epoch 1.917), train_loss = 2.07511256, grad/param norm = 2.0372e-01, time/batch = 0.6722s	
1297/33800 (epoch 1.919), train_loss = 2.03675948, grad/param norm = 2.1657e-01, time/batch = 0.6726s	
1298/33800 (epoch 1.920), train_loss = 2.05371491, grad/param norm = 3.0506e-01, time/batch = 0.6750s	
1299/33800 (epoch 1.922), train_loss = 2.05155521, grad/param norm = 2.5212e-01, time/batch = 0.6880s	
1300/33800 (epoch 1.923), train_loss = 2.02405655, grad/param norm = 2.2025e-01, time/batch = 0.6877s	
1301/33800 (epoch 1.925), train_loss = 2.11256972, grad/param norm = 2.0267e-01, time/batch = 0.6733s	
1302/33800 (epoch 1.926), train_loss = 2.08523515, grad/param norm = 2.3160e-01, time/batch = 0.6700s	
1303/33800 (epoch 1.928), train_loss = 2.10111366, grad/param norm = 2.4161e-01, time/batch = 0.6723s	
1304/33800 (epoch 1.929), train_loss = 1.96580835, grad/param norm = 2.4805e-01, time/batch = 0.6725s	
1305/33800 (epoch 1.930), train_loss = 1.98767153, grad/param norm = 1.9704e-01, time/batch = 0.6786s	
1306/33800 (epoch 1.932), train_loss = 2.10220328, grad/param norm = 1.9877e-01, time/batch = 0.6680s	
1307/33800 (epoch 1.933), train_loss = 2.04566498, grad/param norm = 2.4145e-01, time/batch = 0.6755s	
1308/33800 (epoch 1.935), train_loss = 2.05203860, grad/param norm = 2.6329e-01, time/batch = 0.6884s	
1309/33800 (epoch 1.936), train_loss = 2.10248157, grad/param norm = 2.2447e-01, time/batch = 0.6889s	
1310/33800 (epoch 1.938), train_loss = 2.06929369, grad/param norm = 2.6952e-01, time/batch = 0.6886s	
1311/33800 (epoch 1.939), train_loss = 2.08933428, grad/param norm = 3.0190e-01, time/batch = 0.6916s	
1312/33800 (epoch 1.941), train_loss = 2.05091719, grad/param norm = 2.2710e-01, time/batch = 0.6888s	
1313/33800 (epoch 1.942), train_loss = 2.07235745, grad/param norm = 2.3049e-01, time/batch = 0.6937s	
1314/33800 (epoch 1.944), train_loss = 2.15601447, grad/param norm = 2.7821e-01, time/batch = 0.6882s	
1315/33800 (epoch 1.945), train_loss = 1.96984377, grad/param norm = 2.3627e-01, time/batch = 0.6930s	
1316/33800 (epoch 1.947), train_loss = 2.07684673, grad/param norm = 2.4345e-01, time/batch = 0.6912s	
1317/33800 (epoch 1.948), train_loss = 1.99699425, grad/param norm = 2.4630e-01, time/batch = 0.6843s	
1318/33800 (epoch 1.950), train_loss = 1.81248723, grad/param norm = 2.2591e-01, time/batch = 0.6840s	
1319/33800 (epoch 1.951), train_loss = 2.01717653, grad/param norm = 2.0310e-01, time/batch = 0.6766s	
1320/33800 (epoch 1.953), train_loss = 2.07535198, grad/param norm = 2.2215e-01, time/batch = 0.6932s	
1321/33800 (epoch 1.954), train_loss = 2.09027410, grad/param norm = 2.4234e-01, time/batch = 0.6936s	
1322/33800 (epoch 1.956), train_loss = 2.03212204, grad/param norm = 2.2910e-01, time/batch = 0.6952s	
1323/33800 (epoch 1.957), train_loss = 2.10461207, grad/param norm = 2.3262e-01, time/batch = 0.6907s	
1324/33800 (epoch 1.959), train_loss = 1.95353262, grad/param norm = 2.4278e-01, time/batch = 0.6860s	
1325/33800 (epoch 1.960), train_loss = 2.06867425, grad/param norm = 2.2823e-01, time/batch = 0.6874s	
1326/33800 (epoch 1.962), train_loss = 2.17560496, grad/param norm = 2.2650e-01, time/batch = 0.6864s	
1327/33800 (epoch 1.963), train_loss = 2.09240562, grad/param norm = 2.5178e-01, time/batch = 0.6847s	
1328/33800 (epoch 1.964), train_loss = 2.06743331, grad/param norm = 2.1996e-01, time/batch = 0.6873s	
1329/33800 (epoch 1.966), train_loss = 1.88196848, grad/param norm = 2.1704e-01, time/batch = 0.6872s	
1330/33800 (epoch 1.967), train_loss = 2.00300841, grad/param norm = 2.1536e-01, time/batch = 0.6846s	
1331/33800 (epoch 1.969), train_loss = 2.05135787, grad/param norm = 2.5058e-01, time/batch = 0.6879s	
1332/33800 (epoch 1.970), train_loss = 2.02751620, grad/param norm = 2.2431e-01, time/batch = 0.6877s	
1333/33800 (epoch 1.972), train_loss = 1.94649405, grad/param norm = 1.9527e-01, time/batch = 0.6828s	
1334/33800 (epoch 1.973), train_loss = 2.04023777, grad/param norm = 2.2884e-01, time/batch = 0.6882s	
1335/33800 (epoch 1.975), train_loss = 2.18602615, grad/param norm = 2.3058e-01, time/batch = 0.6851s	
1336/33800 (epoch 1.976), train_loss = 2.12775539, grad/param norm = 2.3866e-01, time/batch = 0.6844s	
1337/33800 (epoch 1.978), train_loss = 1.97854239, grad/param norm = 2.2126e-01, time/batch = 0.6923s	
1338/33800 (epoch 1.979), train_loss = 2.21259381, grad/param norm = 2.3944e-01, time/batch = 0.7007s	
1339/33800 (epoch 1.981), train_loss = 1.92725071, grad/param norm = 2.3418e-01, time/batch = 0.6896s	
1340/33800 (epoch 1.982), train_loss = 2.21735036, grad/param norm = 2.7733e-01, time/batch = 0.6888s	
1341/33800 (epoch 1.984), train_loss = 2.15827722, grad/param norm = 2.6520e-01, time/batch = 0.6921s	
1342/33800 (epoch 1.985), train_loss = 2.22785818, grad/param norm = 2.3358e-01, time/batch = 0.6904s	
1343/33800 (epoch 1.987), train_loss = 1.99594127, grad/param norm = 2.2656e-01, time/batch = 0.6898s	
1344/33800 (epoch 1.988), train_loss = 1.90042308, grad/param norm = 2.1527e-01, time/batch = 0.6886s	
1345/33800 (epoch 1.990), train_loss = 1.92225049, grad/param norm = 1.8849e-01, time/batch = 0.6900s	
1346/33800 (epoch 1.991), train_loss = 2.13219309, grad/param norm = 2.2480e-01, time/batch = 0.6918s	
1347/33800 (epoch 1.993), train_loss = 2.00085759, grad/param norm = 2.2017e-01, time/batch = 0.6903s	
1348/33800 (epoch 1.994), train_loss = 1.94983709, grad/param norm = 2.4065e-01, time/batch = 0.7005s	
1349/33800 (epoch 1.996), train_loss = 1.85451981, grad/param norm = 2.5386e-01, time/batch = 0.6908s	
1350/33800 (epoch 1.997), train_loss = 2.04355397, grad/param norm = 2.2021e-01, time/batch = 0.7017s	
1351/33800 (epoch 1.999), train_loss = 2.05850570, grad/param norm = 2.1346e-01, time/batch = 0.7218s	
1352/33800 (epoch 2.000), train_loss = 2.02681608, grad/param norm = 2.7978e-01, time/batch = 0.7051s	
1353/33800 (epoch 2.001), train_loss = 2.06161518, grad/param norm = 2.4548e-01, time/batch = 0.6984s	
1354/33800 (epoch 2.003), train_loss = 2.08750415, grad/param norm = 2.1569e-01, time/batch = 0.6961s	
1355/33800 (epoch 2.004), train_loss = 2.04220063, grad/param norm = 2.1373e-01, time/batch = 0.6926s	
1356/33800 (epoch 2.006), train_loss = 2.10120121, grad/param norm = 2.1777e-01, time/batch = 0.6936s	
1357/33800 (epoch 2.007), train_loss = 2.06864123, grad/param norm = 2.3138e-01, time/batch = 0.6957s	
1358/33800 (epoch 2.009), train_loss = 2.07401566, grad/param norm = 2.1367e-01, time/batch = 0.7018s	
1359/33800 (epoch 2.010), train_loss = 2.02708030, grad/param norm = 2.2085e-01, time/batch = 0.6975s	
1360/33800 (epoch 2.012), train_loss = 2.05678189, grad/param norm = 1.9679e-01, time/batch = 0.7099s	
1361/33800 (epoch 2.013), train_loss = 2.09879685, grad/param norm = 2.0543e-01, time/batch = 0.7130s	
1362/33800 (epoch 2.015), train_loss = 2.02235375, grad/param norm = 2.1632e-01, time/batch = 0.6965s	
1363/33800 (epoch 2.016), train_loss = 1.99555346, grad/param norm = 2.2738e-01, time/batch = 0.6961s	
1364/33800 (epoch 2.018), train_loss = 1.86974661, grad/param norm = 2.3944e-01, time/batch = 0.6940s	
1365/33800 (epoch 2.019), train_loss = 2.10175521, grad/param norm = 2.2786e-01, time/batch = 0.6920s	
1366/33800 (epoch 2.021), train_loss = 2.19590093, grad/param norm = 2.1675e-01, time/batch = 0.6924s	
1367/33800 (epoch 2.022), train_loss = 1.88974639, grad/param norm = 2.1367e-01, time/batch = 0.6891s	
1368/33800 (epoch 2.024), train_loss = 1.79614859, grad/param norm = 2.0497e-01, time/batch = 0.6862s	
1369/33800 (epoch 2.025), train_loss = 2.09693501, grad/param norm = 2.2947e-01, time/batch = 0.6874s	
1370/33800 (epoch 2.027), train_loss = 1.96508005, grad/param norm = 2.1610e-01, time/batch = 0.6920s	
1371/33800 (epoch 2.028), train_loss = 1.92859281, grad/param norm = 2.1034e-01, time/batch = 0.6938s	
1372/33800 (epoch 2.030), train_loss = 2.04000078, grad/param norm = 2.6202e-01, time/batch = 0.6912s	
1373/33800 (epoch 2.031), train_loss = 1.87531018, grad/param norm = 2.0864e-01, time/batch = 0.6872s	
1374/33800 (epoch 2.033), train_loss = 1.92956305, grad/param norm = 2.0554e-01, time/batch = 0.6876s	
1375/33800 (epoch 2.034), train_loss = 2.01499560, grad/param norm = 1.9723e-01, time/batch = 0.6861s	
1376/33800 (epoch 2.036), train_loss = 2.14108722, grad/param norm = 2.4557e-01, time/batch = 0.6882s	
1377/33800 (epoch 2.037), train_loss = 2.05246704, grad/param norm = 2.3470e-01, time/batch = 0.6921s	
1378/33800 (epoch 2.038), train_loss = 2.14536397, grad/param norm = 2.5860e-01, time/batch = 0.6839s	
1379/33800 (epoch 2.040), train_loss = 1.98836491, grad/param norm = 2.3998e-01, time/batch = 0.6850s	
1380/33800 (epoch 2.041), train_loss = 2.06722095, grad/param norm = 2.1341e-01, time/batch = 0.6878s	
1381/33800 (epoch 2.043), train_loss = 2.07577457, grad/param norm = 1.9224e-01, time/batch = 0.6929s	
1382/33800 (epoch 2.044), train_loss = 1.86259679, grad/param norm = 2.1971e-01, time/batch = 0.6942s	
1383/33800 (epoch 2.046), train_loss = 1.84082950, grad/param norm = 2.5949e-01, time/batch = 0.6859s	
1384/33800 (epoch 2.047), train_loss = 1.98260754, grad/param norm = 2.6800e-01, time/batch = 0.6835s	
1385/33800 (epoch 2.049), train_loss = 1.93587111, grad/param norm = 2.2177e-01, time/batch = 0.6811s	
1386/33800 (epoch 2.050), train_loss = 1.93935782, grad/param norm = 2.0709e-01, time/batch = 0.6829s	
1387/33800 (epoch 2.052), train_loss = 2.04073352, grad/param norm = 2.4266e-01, time/batch = 0.6813s	
1388/33800 (epoch 2.053), train_loss = 1.96515348, grad/param norm = 2.2069e-01, time/batch = 0.6989s	
1389/33800 (epoch 2.055), train_loss = 1.99086440, grad/param norm = 2.4856e-01, time/batch = 0.7070s	
1390/33800 (epoch 2.056), train_loss = 2.06706220, grad/param norm = 2.7380e-01, time/batch = 0.7157s	
1391/33800 (epoch 2.058), train_loss = 2.07043914, grad/param norm = 1.9909e-01, time/batch = 0.7154s	
1392/33800 (epoch 2.059), train_loss = 1.91344137, grad/param norm = 2.1920e-01, time/batch = 0.7065s	
1393/33800 (epoch 2.061), train_loss = 2.06804518, grad/param norm = 2.3831e-01, time/batch = 0.7072s	
1394/33800 (epoch 2.062), train_loss = 2.07599220, grad/param norm = 2.3561e-01, time/batch = 0.6858s	
1395/33800 (epoch 2.064), train_loss = 2.09252341, grad/param norm = 2.8644e-01, time/batch = 0.6862s	
1396/33800 (epoch 2.065), train_loss = 2.07504326, grad/param norm = 2.8384e-01, time/batch = 0.6894s	
1397/33800 (epoch 2.067), train_loss = 2.00795461, grad/param norm = 1.9304e-01, time/batch = 0.6885s	
1398/33800 (epoch 2.068), train_loss = 2.05229969, grad/param norm = 2.2563e-01, time/batch = 0.6910s	
1399/33800 (epoch 2.070), train_loss = 2.08850576, grad/param norm = 2.4067e-01, time/batch = 0.7158s	
1400/33800 (epoch 2.071), train_loss = 1.92920424, grad/param norm = 2.1037e-01, time/batch = 0.7127s	
1401/33800 (epoch 2.072), train_loss = 2.04998124, grad/param norm = 2.1252e-01, time/batch = 0.7037s	
1402/33800 (epoch 2.074), train_loss = 2.23012544, grad/param norm = 2.3102e-01, time/batch = 0.6932s	
1403/33800 (epoch 2.075), train_loss = 2.07113694, grad/param norm = 2.5199e-01, time/batch = 0.6993s	
1404/33800 (epoch 2.077), train_loss = 1.91555488, grad/param norm = 2.3071e-01, time/batch = 0.6884s	
1405/33800 (epoch 2.078), train_loss = 2.05275785, grad/param norm = 2.4134e-01, time/batch = 0.6891s	
1406/33800 (epoch 2.080), train_loss = 1.92937885, grad/param norm = 2.6769e-01, time/batch = 0.6860s	
1407/33800 (epoch 2.081), train_loss = 1.87040857, grad/param norm = 2.3621e-01, time/batch = 0.6872s	
1408/33800 (epoch 2.083), train_loss = 1.92784290, grad/param norm = 2.0129e-01, time/batch = 0.6848s	
1409/33800 (epoch 2.084), train_loss = 2.06286744, grad/param norm = 2.0066e-01, time/batch = 0.6950s	
1410/33800 (epoch 2.086), train_loss = 1.87488334, grad/param norm = 2.1290e-01, time/batch = 0.6902s	
1411/33800 (epoch 2.087), train_loss = 2.14411472, grad/param norm = 2.0869e-01, time/batch = 0.6902s	
1412/33800 (epoch 2.089), train_loss = 2.05641269, grad/param norm = 2.1706e-01, time/batch = 0.6880s	
1413/33800 (epoch 2.090), train_loss = 2.05494867, grad/param norm = 2.1480e-01, time/batch = 0.6854s	
1414/33800 (epoch 2.092), train_loss = 2.12144228, grad/param norm = 2.2615e-01, time/batch = 0.6861s	
1415/33800 (epoch 2.093), train_loss = 2.05747686, grad/param norm = 2.0463e-01, time/batch = 0.6843s	
1416/33800 (epoch 2.095), train_loss = 2.00542598, grad/param norm = 2.4025e-01, time/batch = 0.6877s	
1417/33800 (epoch 2.096), train_loss = 2.00631096, grad/param norm = 2.7574e-01, time/batch = 0.6924s	
1418/33800 (epoch 2.098), train_loss = 2.08825015, grad/param norm = 2.4122e-01, time/batch = 0.7018s	
1419/33800 (epoch 2.099), train_loss = 2.06178451, grad/param norm = 2.0497e-01, time/batch = 0.6958s	
1420/33800 (epoch 2.101), train_loss = 1.85707288, grad/param norm = 2.1290e-01, time/batch = 0.6880s	
1421/33800 (epoch 2.102), train_loss = 2.15370593, grad/param norm = 2.8230e-01, time/batch = 0.6911s	
1422/33800 (epoch 2.104), train_loss = 2.07480750, grad/param norm = 2.8426e-01, time/batch = 0.6893s	
1423/33800 (epoch 2.105), train_loss = 1.98006840, grad/param norm = 2.3565e-01, time/batch = 0.6899s	
1424/33800 (epoch 2.107), train_loss = 1.98802333, grad/param norm = 1.8146e-01, time/batch = 0.6849s	
1425/33800 (epoch 2.108), train_loss = 1.88425655, grad/param norm = 2.0408e-01, time/batch = 0.6880s	
1426/33800 (epoch 2.109), train_loss = 1.95464884, grad/param norm = 2.1145e-01, time/batch = 0.6870s	
1427/33800 (epoch 2.111), train_loss = 1.94018504, grad/param norm = 2.1581e-01, time/batch = 0.6880s	
1428/33800 (epoch 2.112), train_loss = 1.91112853, grad/param norm = 1.9405e-01, time/batch = 0.6995s	
1429/33800 (epoch 2.114), train_loss = 2.11717625, grad/param norm = 2.3739e-01, time/batch = 0.6839s	
1430/33800 (epoch 2.115), train_loss = 1.89735236, grad/param norm = 1.8831e-01, time/batch = 0.6745s	
1431/33800 (epoch 2.117), train_loss = 2.07607576, grad/param norm = 2.3856e-01, time/batch = 0.6786s	
1432/33800 (epoch 2.118), train_loss = 2.01381912, grad/param norm = 2.2506e-01, time/batch = 0.6855s	
1433/33800 (epoch 2.120), train_loss = 2.04063331, grad/param norm = 2.4834e-01, time/batch = 0.6778s	
1434/33800 (epoch 2.121), train_loss = 2.06062081, grad/param norm = 2.2125e-01, time/batch = 0.6768s	
1435/33800 (epoch 2.123), train_loss = 2.01642925, grad/param norm = 2.2829e-01, time/batch = 0.6757s	
1436/33800 (epoch 2.124), train_loss = 1.93265901, grad/param norm = 2.1609e-01, time/batch = 0.6859s	
1437/33800 (epoch 2.126), train_loss = 2.01901140, grad/param norm = 2.1579e-01, time/batch = 0.6969s	
1438/33800 (epoch 2.127), train_loss = 2.03285771, grad/param norm = 2.1339e-01, time/batch = 0.7107s	
1439/33800 (epoch 2.129), train_loss = 2.02376839, grad/param norm = 2.1876e-01, time/batch = 0.6932s	
1440/33800 (epoch 2.130), train_loss = 1.95776252, grad/param norm = 2.0421e-01, time/batch = 0.6892s	
1441/33800 (epoch 2.132), train_loss = 2.19493072, grad/param norm = 2.0485e-01, time/batch = 0.6956s	
1442/33800 (epoch 2.133), train_loss = 1.96108987, grad/param norm = 2.0089e-01, time/batch = 0.6934s	
1443/33800 (epoch 2.135), train_loss = 1.92108590, grad/param norm = 2.5995e-01, time/batch = 0.6882s	
1444/33800 (epoch 2.136), train_loss = 1.92794940, grad/param norm = 2.0418e-01, time/batch = 0.6829s	
1445/33800 (epoch 2.138), train_loss = 2.03855437, grad/param norm = 1.9854e-01, time/batch = 0.6786s	
1446/33800 (epoch 2.139), train_loss = 1.98146672, grad/param norm = 2.0051e-01, time/batch = 0.6816s	
1447/33800 (epoch 2.141), train_loss = 1.96975664, grad/param norm = 2.0795e-01, time/batch = 0.6770s	
1448/33800 (epoch 2.142), train_loss = 2.13098192, grad/param norm = 2.0780e-01, time/batch = 0.6824s	
1449/33800 (epoch 2.143), train_loss = 2.00018674, grad/param norm = 2.0864e-01, time/batch = 0.6871s	
1450/33800 (epoch 2.145), train_loss = 1.98236469, grad/param norm = 2.0250e-01, time/batch = 0.7197s	
1451/33800 (epoch 2.146), train_loss = 2.01208796, grad/param norm = 2.6903e-01, time/batch = 0.6942s	
1452/33800 (epoch 2.148), train_loss = 1.86430091, grad/param norm = 2.4426e-01, time/batch = 0.6829s	
1453/33800 (epoch 2.149), train_loss = 1.97017845, grad/param norm = 2.2107e-01, time/batch = 0.6807s	
1454/33800 (epoch 2.151), train_loss = 1.81116726, grad/param norm = 1.9376e-01, time/batch = 0.6788s	
1455/33800 (epoch 2.152), train_loss = 2.10345187, grad/param norm = 1.9133e-01, time/batch = 0.6774s	
1456/33800 (epoch 2.154), train_loss = 2.03574042, grad/param norm = 2.2700e-01, time/batch = 0.6802s	
1457/33800 (epoch 2.155), train_loss = 1.95282731, grad/param norm = 2.0031e-01, time/batch = 0.6779s	
1458/33800 (epoch 2.157), train_loss = 1.89114135, grad/param norm = 2.1190e-01, time/batch = 0.6804s	
1459/33800 (epoch 2.158), train_loss = 1.98992889, grad/param norm = 2.3052e-01, time/batch = 0.6865s	
1460/33800 (epoch 2.160), train_loss = 1.89503935, grad/param norm = 2.1478e-01, time/batch = 0.6758s	
1461/33800 (epoch 2.161), train_loss = 2.03169534, grad/param norm = 1.9590e-01, time/batch = 0.6888s	
1462/33800 (epoch 2.163), train_loss = 2.00093923, grad/param norm = 2.0849e-01, time/batch = 0.6922s	
1463/33800 (epoch 2.164), train_loss = 2.01031137, grad/param norm = 2.3286e-01, time/batch = 0.6917s	
1464/33800 (epoch 2.166), train_loss = 1.87912460, grad/param norm = 2.1957e-01, time/batch = 0.6928s	
1465/33800 (epoch 2.167), train_loss = 2.08477254, grad/param norm = 1.9613e-01, time/batch = 0.6946s	
1466/33800 (epoch 2.169), train_loss = 2.05300288, grad/param norm = 2.1950e-01, time/batch = 0.6890s	
1467/33800 (epoch 2.170), train_loss = 1.90215006, grad/param norm = 2.1913e-01, time/batch = 0.6916s	
1468/33800 (epoch 2.172), train_loss = 2.07175578, grad/param norm = 2.1336e-01, time/batch = 0.6924s	
1469/33800 (epoch 2.173), train_loss = 1.92077495, grad/param norm = 2.2479e-01, time/batch = 0.6926s	
1470/33800 (epoch 2.175), train_loss = 2.12008688, grad/param norm = 2.1892e-01, time/batch = 0.6935s	
1471/33800 (epoch 2.176), train_loss = 1.88539309, grad/param norm = 2.0385e-01, time/batch = 0.6989s	
1472/33800 (epoch 2.178), train_loss = 2.08376524, grad/param norm = 2.0385e-01, time/batch = 0.6940s	
1473/33800 (epoch 2.179), train_loss = 2.01265684, grad/param norm = 2.0016e-01, time/batch = 0.7018s	
1474/33800 (epoch 2.180), train_loss = 1.94853404, grad/param norm = 2.2372e-01, time/batch = 0.6969s	
1475/33800 (epoch 2.182), train_loss = 2.15866902, grad/param norm = 2.4474e-01, time/batch = 0.6903s	
1476/33800 (epoch 2.183), train_loss = 2.14286958, grad/param norm = 2.1912e-01, time/batch = 0.6870s	
1477/33800 (epoch 2.185), train_loss = 2.11028303, grad/param norm = 2.1577e-01, time/batch = 0.6863s	
1478/33800 (epoch 2.186), train_loss = 2.03184954, grad/param norm = 2.0681e-01, time/batch = 0.6870s	
1479/33800 (epoch 2.188), train_loss = 2.08323125, grad/param norm = 2.1131e-01, time/batch = 0.6816s	
1480/33800 (epoch 2.189), train_loss = 2.04390816, grad/param norm = 2.3101e-01, time/batch = 0.6849s	
1481/33800 (epoch 2.191), train_loss = 2.06539080, grad/param norm = 2.8446e-01, time/batch = 0.6911s	
1482/33800 (epoch 2.192), train_loss = 1.98721209, grad/param norm = 2.6516e-01, time/batch = 0.6957s	
1483/33800 (epoch 2.194), train_loss = 2.04038194, grad/param norm = 1.9982e-01, time/batch = 0.6888s	
1484/33800 (epoch 2.195), train_loss = 1.81366991, grad/param norm = 2.4232e-01, time/batch = 0.6879s	
1485/33800 (epoch 2.197), train_loss = 1.80259308, grad/param norm = 2.0008e-01, time/batch = 0.6873s	
1486/33800 (epoch 2.198), train_loss = 1.98148383, grad/param norm = 1.9695e-01, time/batch = 0.7020s	
1487/33800 (epoch 2.200), train_loss = 2.00763732, grad/param norm = 2.2614e-01, time/batch = 0.7306s	
1488/33800 (epoch 2.201), train_loss = 2.09833701, grad/param norm = 2.5335e-01, time/batch = 0.7138s	
1489/33800 (epoch 2.203), train_loss = 1.96308763, grad/param norm = 2.0998e-01, time/batch = 0.7062s	
1490/33800 (epoch 2.204), train_loss = 1.94896863, grad/param norm = 2.2437e-01, time/batch = 0.7041s	
1491/33800 (epoch 2.206), train_loss = 1.88907692, grad/param norm = 2.0878e-01, time/batch = 0.7018s	
1492/33800 (epoch 2.207), train_loss = 2.10817734, grad/param norm = 2.1557e-01, time/batch = 0.6999s	
1493/33800 (epoch 2.209), train_loss = 1.92158656, grad/param norm = 2.3627e-01, time/batch = 0.7018s	
1494/33800 (epoch 2.210), train_loss = 2.00729011, grad/param norm = 2.0805e-01, time/batch = 0.6985s	
1495/33800 (epoch 2.212), train_loss = 2.10405959, grad/param norm = 2.0567e-01, time/batch = 0.6835s	
1496/33800 (epoch 2.213), train_loss = 2.13546075, grad/param norm = 2.5050e-01, time/batch = 0.6899s	
1497/33800 (epoch 2.214), train_loss = 2.03100733, grad/param norm = 2.5673e-01, time/batch = 0.6905s	
1498/33800 (epoch 2.216), train_loss = 1.87074709, grad/param norm = 2.0928e-01, time/batch = 0.6909s	
1499/33800 (epoch 2.217), train_loss = 1.97398399, grad/param norm = 2.2339e-01, time/batch = 0.7008s	
1500/33800 (epoch 2.219), train_loss = 1.94726071, grad/param norm = 1.9948e-01, time/batch = 0.6990s	
1501/33800 (epoch 2.220), train_loss = 2.10603538, grad/param norm = 2.3973e-01, time/batch = 0.6998s	
1502/33800 (epoch 2.222), train_loss = 2.05249226, grad/param norm = 2.2770e-01, time/batch = 0.6965s	
1503/33800 (epoch 2.223), train_loss = 1.92958091, grad/param norm = 2.0799e-01, time/batch = 0.6920s	
1504/33800 (epoch 2.225), train_loss = 2.01931657, grad/param norm = 2.0633e-01, time/batch = 0.6903s	
1505/33800 (epoch 2.226), train_loss = 2.09357373, grad/param norm = 2.4526e-01, time/batch = 0.6870s	
1506/33800 (epoch 2.228), train_loss = 2.01078136, grad/param norm = 2.7314e-01, time/batch = 0.6906s	
1507/33800 (epoch 2.229), train_loss = 1.97608901, grad/param norm = 2.3821e-01, time/batch = 0.6901s	
1508/33800 (epoch 2.231), train_loss = 2.09886082, grad/param norm = 2.3445e-01, time/batch = 0.6927s	
1509/33800 (epoch 2.232), train_loss = 1.94099164, grad/param norm = 2.3356e-01, time/batch = 0.6883s	
1510/33800 (epoch 2.234), train_loss = 2.06892866, grad/param norm = 2.1253e-01, time/batch = 0.6947s	
1511/33800 (epoch 2.235), train_loss = 1.92500534, grad/param norm = 1.9329e-01, time/batch = 0.7028s	
1512/33800 (epoch 2.237), train_loss = 2.00803783, grad/param norm = 2.4172e-01, time/batch = 0.7001s	
1513/33800 (epoch 2.238), train_loss = 2.08916889, grad/param norm = 1.9781e-01, time/batch = 0.7119s	
1514/33800 (epoch 2.240), train_loss = 1.92516288, grad/param norm = 1.9863e-01, time/batch = 0.7441s	
1515/33800 (epoch 2.241), train_loss = 1.97492861, grad/param norm = 2.3497e-01, time/batch = 0.7416s	
1516/33800 (epoch 2.243), train_loss = 1.92374289, grad/param norm = 2.1753e-01, time/batch = 0.7308s	
1517/33800 (epoch 2.244), train_loss = 2.00803757, grad/param norm = 2.4395e-01, time/batch = 0.7130s	
1518/33800 (epoch 2.246), train_loss = 2.04153153, grad/param norm = 2.4727e-01, time/batch = 0.7150s	
1519/33800 (epoch 2.247), train_loss = 1.95017825, grad/param norm = 2.1869e-01, time/batch = 0.7023s	
1520/33800 (epoch 2.249), train_loss = 2.03951533, grad/param norm = 2.1699e-01, time/batch = 0.7061s	
1521/33800 (epoch 2.250), train_loss = 2.07219062, grad/param norm = 2.2160e-01, time/batch = 0.7026s	
1522/33800 (epoch 2.251), train_loss = 2.35620443, grad/param norm = 2.7976e-01, time/batch = 0.7028s	
1523/33800 (epoch 2.253), train_loss = 2.07094798, grad/param norm = 2.3637e-01, time/batch = 0.7400s	
1524/33800 (epoch 2.254), train_loss = 2.10828988, grad/param norm = 2.5911e-01, time/batch = 0.7507s	
1525/33800 (epoch 2.256), train_loss = 1.95619731, grad/param norm = 2.2592e-01, time/batch = 0.7125s	
1526/33800 (epoch 2.257), train_loss = 2.03909782, grad/param norm = 1.9392e-01, time/batch = 0.7091s	
1527/33800 (epoch 2.259), train_loss = 1.94158131, grad/param norm = 1.8585e-01, time/batch = 0.7035s	
1528/33800 (epoch 2.260), train_loss = 1.93271874, grad/param norm = 2.0277e-01, time/batch = 0.7021s	
1529/33800 (epoch 2.262), train_loss = 1.96036246, grad/param norm = 2.2137e-01, time/batch = 0.7017s	
1530/33800 (epoch 2.263), train_loss = 2.08721768, grad/param norm = 2.4720e-01, time/batch = 0.7007s	
1531/33800 (epoch 2.265), train_loss = 2.10337473, grad/param norm = 2.1817e-01, time/batch = 0.7053s	
1532/33800 (epoch 2.266), train_loss = 1.93009307, grad/param norm = 2.0438e-01, time/batch = 0.6969s	
1533/33800 (epoch 2.268), train_loss = 2.00099254, grad/param norm = 1.9237e-01, time/batch = 0.6841s	
1534/33800 (epoch 2.269), train_loss = 1.96900094, grad/param norm = 2.0441e-01, time/batch = 0.6857s	
1535/33800 (epoch 2.271), train_loss = 1.99633090, grad/param norm = 2.1371e-01, time/batch = 0.6875s	
1536/33800 (epoch 2.272), train_loss = 2.02535492, grad/param norm = 2.3515e-01, time/batch = 0.6862s	
1537/33800 (epoch 2.274), train_loss = 2.13673802, grad/param norm = 2.3183e-01, time/batch = 0.6895s	
1538/33800 (epoch 2.275), train_loss = 1.84912234, grad/param norm = 2.1719e-01, time/batch = 0.6925s	
1539/33800 (epoch 2.277), train_loss = 1.88666999, grad/param norm = 1.9469e-01, time/batch = 0.7366s	
1540/33800 (epoch 2.278), train_loss = 1.92282592, grad/param norm = 2.0666e-01, time/batch = 0.6964s	
1541/33800 (epoch 2.280), train_loss = 1.82702650, grad/param norm = 2.0082e-01, time/batch = 0.6954s	
1542/33800 (epoch 2.281), train_loss = 1.98123549, grad/param norm = 2.0420e-01, time/batch = 0.6852s	
1543/33800 (epoch 2.283), train_loss = 1.94360391, grad/param norm = 1.9114e-01, time/batch = 0.6872s	
1544/33800 (epoch 2.284), train_loss = 2.05523687, grad/param norm = 2.0802e-01, time/batch = 0.6869s	
1545/33800 (epoch 2.286), train_loss = 2.05296931, grad/param norm = 1.9550e-01, time/batch = 0.6852s	
1546/33800 (epoch 2.287), train_loss = 1.88278071, grad/param norm = 2.0976e-01, time/batch = 0.6858s	
1547/33800 (epoch 2.288), train_loss = 1.87020663, grad/param norm = 1.9188e-01, time/batch = 0.6883s	
1548/33800 (epoch 2.290), train_loss = 1.90667991, grad/param norm = 2.5972e-01, time/batch = 0.6900s	
1549/33800 (epoch 2.291), train_loss = 1.97572567, grad/param norm = 3.0945e-01, time/batch = 0.7071s	
1550/33800 (epoch 2.293), train_loss = 1.97992443, grad/param norm = 2.4614e-01, time/batch = 0.7006s	
1551/33800 (epoch 2.294), train_loss = 2.28504190, grad/param norm = 2.2015e-01, time/batch = 0.7085s	
1552/33800 (epoch 2.296), train_loss = 2.02108096, grad/param norm = 2.8780e-01, time/batch = 0.7225s	
1553/33800 (epoch 2.297), train_loss = 1.97617721, grad/param norm = 1.9266e-01, time/batch = 0.7255s	
1554/33800 (epoch 2.299), train_loss = 1.90465687, grad/param norm = 2.1851e-01, time/batch = 0.7153s	
1555/33800 (epoch 2.300), train_loss = 1.92295427, grad/param norm = 1.8730e-01, time/batch = 0.7120s	
1556/33800 (epoch 2.302), train_loss = 2.08088800, grad/param norm = 1.8436e-01, time/batch = 0.7022s	
1557/33800 (epoch 2.303), train_loss = 1.97808902, grad/param norm = 1.8697e-01, time/batch = 0.7040s	
1558/33800 (epoch 2.305), train_loss = 1.97743575, grad/param norm = 1.9985e-01, time/batch = 0.7071s	
1559/33800 (epoch 2.306), train_loss = 1.87817990, grad/param norm = 1.8919e-01, time/batch = 0.7084s	
1560/33800 (epoch 2.308), train_loss = 2.02871967, grad/param norm = 2.1449e-01, time/batch = 0.7142s	
1561/33800 (epoch 2.309), train_loss = 1.97045939, grad/param norm = 2.0065e-01, time/batch = 0.7189s	
1562/33800 (epoch 2.311), train_loss = 1.89364766, grad/param norm = 1.7939e-01, time/batch = 0.7153s	
1563/33800 (epoch 2.312), train_loss = 1.91907463, grad/param norm = 2.0196e-01, time/batch = 0.7204s	
1564/33800 (epoch 2.314), train_loss = 1.98327802, grad/param norm = 1.9632e-01, time/batch = 0.7091s	
1565/33800 (epoch 2.315), train_loss = 2.17653800, grad/param norm = 2.1068e-01, time/batch = 0.7126s	
1566/33800 (epoch 2.317), train_loss = 1.96318906, grad/param norm = 2.1092e-01, time/batch = 0.7015s	
1567/33800 (epoch 2.318), train_loss = 2.02188252, grad/param norm = 1.9925e-01, time/batch = 0.7055s	
1568/33800 (epoch 2.320), train_loss = 2.14875563, grad/param norm = 2.3004e-01, time/batch = 0.6935s	
1569/33800 (epoch 2.321), train_loss = 2.03028524, grad/param norm = 2.1058e-01, time/batch = 0.6800s	
1570/33800 (epoch 2.322), train_loss = 1.86750896, grad/param norm = 1.8747e-01, time/batch = 0.6718s	
1571/33800 (epoch 2.324), train_loss = 1.86570958, grad/param norm = 2.0095e-01, time/batch = 0.6797s	
1572/33800 (epoch 2.325), train_loss = 1.94851027, grad/param norm = 2.6124e-01, time/batch = 0.6795s	
1573/33800 (epoch 2.327), train_loss = 2.00563799, grad/param norm = 2.1966e-01, time/batch = 0.6751s	
1574/33800 (epoch 2.328), train_loss = 1.88048128, grad/param norm = 1.8162e-01, time/batch = 0.6881s	
1575/33800 (epoch 2.330), train_loss = 1.86225770, grad/param norm = 1.9788e-01, time/batch = 0.6896s	
1576/33800 (epoch 2.331), train_loss = 1.98074405, grad/param norm = 2.0343e-01, time/batch = 0.6852s	
1577/33800 (epoch 2.333), train_loss = 2.01400709, grad/param norm = 2.1349e-01, time/batch = 0.6848s	
1578/33800 (epoch 2.334), train_loss = 1.89991992, grad/param norm = 1.8265e-01, time/batch = 0.6804s	
1579/33800 (epoch 2.336), train_loss = 1.85131214, grad/param norm = 2.0830e-01, time/batch = 0.6794s	
1580/33800 (epoch 2.337), train_loss = 1.90690767, grad/param norm = 2.1382e-01, time/batch = 0.6830s	
1581/33800 (epoch 2.339), train_loss = 1.93882330, grad/param norm = 2.3212e-01, time/batch = 0.7112s	
1582/33800 (epoch 2.340), train_loss = 2.08045152, grad/param norm = 2.2484e-01, time/batch = 0.6784s	
1583/33800 (epoch 2.342), train_loss = 2.16173374, grad/param norm = 2.0875e-01, time/batch = 0.6788s	
1584/33800 (epoch 2.343), train_loss = 1.95815394, grad/param norm = 2.1635e-01, time/batch = 0.6773s	
1585/33800 (epoch 2.345), train_loss = 2.06717445, grad/param norm = 2.0511e-01, time/batch = 0.6759s	
1586/33800 (epoch 2.346), train_loss = 2.28359905, grad/param norm = 2.0603e-01, time/batch = 0.6785s	
1587/33800 (epoch 2.348), train_loss = 2.08340659, grad/param norm = 2.1507e-01, time/batch = 0.6774s	
1588/33800 (epoch 2.349), train_loss = 2.03660339, grad/param norm = 2.3050e-01, time/batch = 0.6731s	
1589/33800 (epoch 2.351), train_loss = 1.91777932, grad/param norm = 1.8961e-01, time/batch = 0.6753s	
1590/33800 (epoch 2.352), train_loss = 2.10407883, grad/param norm = 2.3355e-01, time/batch = 0.6855s	
1591/33800 (epoch 2.354), train_loss = 1.95753775, grad/param norm = 2.4090e-01, time/batch = 0.6815s	
1592/33800 (epoch 2.355), train_loss = 1.82671313, grad/param norm = 2.0402e-01, time/batch = 0.6801s	
1593/33800 (epoch 2.357), train_loss = 1.93311711, grad/param norm = 2.2161e-01, time/batch = 0.6767s	
1594/33800 (epoch 2.358), train_loss = 2.02656209, grad/param norm = 2.1758e-01, time/batch = 0.6767s	
1595/33800 (epoch 2.359), train_loss = 1.91508681, grad/param norm = 2.1153e-01, time/batch = 0.6849s	
1596/33800 (epoch 2.361), train_loss = 2.00905187, grad/param norm = 2.1582e-01, time/batch = 0.6759s	
1597/33800 (epoch 2.362), train_loss = 2.06997573, grad/param norm = 1.8640e-01, time/batch = 0.6759s	
1598/33800 (epoch 2.364), train_loss = 2.15987828, grad/param norm = 2.0172e-01, time/batch = 0.6737s	
1599/33800 (epoch 2.365), train_loss = 2.01862854, grad/param norm = 2.0272e-01, time/batch = 0.6753s	
1600/33800 (epoch 2.367), train_loss = 1.93628680, grad/param norm = 2.4697e-01, time/batch = 0.6810s	
1601/33800 (epoch 2.368), train_loss = 1.98756420, grad/param norm = 1.9455e-01, time/batch = 0.6857s	
1602/33800 (epoch 2.370), train_loss = 2.01618969, grad/param norm = 1.9403e-01, time/batch = 0.6792s	
1603/33800 (epoch 2.371), train_loss = 2.00906405, grad/param norm = 2.0899e-01, time/batch = 0.6739s	
1604/33800 (epoch 2.373), train_loss = 2.18749932, grad/param norm = 2.6407e-01, time/batch = 0.6769s	
1605/33800 (epoch 2.374), train_loss = 1.84316327, grad/param norm = 2.0063e-01, time/batch = 0.6765s	
1606/33800 (epoch 2.376), train_loss = 1.92241947, grad/param norm = 2.0692e-01, time/batch = 0.6814s	
1607/33800 (epoch 2.377), train_loss = 1.89109258, grad/param norm = 2.3272e-01, time/batch = 0.6836s	
1608/33800 (epoch 2.379), train_loss = 2.05753251, grad/param norm = 2.1398e-01, time/batch = 0.6898s	
1609/33800 (epoch 2.380), train_loss = 2.01640555, grad/param norm = 1.9504e-01, time/batch = 0.6979s	
1610/33800 (epoch 2.382), train_loss = 1.90172793, grad/param norm = 1.9468e-01, time/batch = 0.6943s	
1611/33800 (epoch 2.383), train_loss = 2.07281177, grad/param norm = 2.0839e-01, time/batch = 0.6998s	
1612/33800 (epoch 2.385), train_loss = 2.00234810, grad/param norm = 2.0779e-01, time/batch = 0.6905s	
1613/33800 (epoch 2.386), train_loss = 1.91538077, grad/param norm = 1.9781e-01, time/batch = 0.6840s	
1614/33800 (epoch 2.388), train_loss = 2.06880669, grad/param norm = 1.9197e-01, time/batch = 0.6825s	
1615/33800 (epoch 2.389), train_loss = 1.99023536, grad/param norm = 1.9891e-01, time/batch = 0.6892s	
1616/33800 (epoch 2.391), train_loss = 2.09142924, grad/param norm = 1.9537e-01, time/batch = 0.7253s	
1617/33800 (epoch 2.392), train_loss = 1.92718849, grad/param norm = 1.9273e-01, time/batch = 0.6923s	
1618/33800 (epoch 2.393), train_loss = 1.99182578, grad/param norm = 2.0532e-01, time/batch = 0.6830s	
1619/33800 (epoch 2.395), train_loss = 2.03086613, grad/param norm = 2.3590e-01, time/batch = 0.6793s	
1620/33800 (epoch 2.396), train_loss = 2.01399080, grad/param norm = 2.9648e-01, time/batch = 0.6806s	
1621/33800 (epoch 2.398), train_loss = 1.87563299, grad/param norm = 2.3318e-01, time/batch = 0.6869s	
1622/33800 (epoch 2.399), train_loss = 2.05873390, grad/param norm = 2.2479e-01, time/batch = 0.6870s	
1623/33800 (epoch 2.401), train_loss = 1.97037710, grad/param norm = 2.0934e-01, time/batch = 0.6847s	
1624/33800 (epoch 2.402), train_loss = 2.02113279, grad/param norm = 1.8572e-01, time/batch = 0.6855s	
1625/33800 (epoch 2.404), train_loss = 1.89566533, grad/param norm = 1.9230e-01, time/batch = 0.6786s	
1626/33800 (epoch 2.405), train_loss = 2.11376623, grad/param norm = 2.0643e-01, time/batch = 0.6782s	
1627/33800 (epoch 2.407), train_loss = 1.97022608, grad/param norm = 1.8665e-01, time/batch = 0.6741s	
1628/33800 (epoch 2.408), train_loss = 2.03610954, grad/param norm = 2.1181e-01, time/batch = 0.6701s	
1629/33800 (epoch 2.410), train_loss = 2.09626630, grad/param norm = 1.9844e-01, time/batch = 0.6865s	
1630/33800 (epoch 2.411), train_loss = 1.94346696, grad/param norm = 2.0192e-01, time/batch = 0.6844s	
1631/33800 (epoch 2.413), train_loss = 2.02189111, grad/param norm = 1.9816e-01, time/batch = 0.6732s	
1632/33800 (epoch 2.414), train_loss = 1.86847988, grad/param norm = 1.9330e-01, time/batch = 0.6760s	
1633/33800 (epoch 2.416), train_loss = 1.92921537, grad/param norm = 2.1586e-01, time/batch = 0.6733s	
1634/33800 (epoch 2.417), train_loss = 1.83434763, grad/param norm = 2.1072e-01, time/batch = 0.6746s	
1635/33800 (epoch 2.419), train_loss = 2.01569761, grad/param norm = 1.8075e-01, time/batch = 0.6806s	
1636/33800 (epoch 2.420), train_loss = 1.97772172, grad/param norm = 2.0022e-01, time/batch = 0.6780s	
1637/33800 (epoch 2.422), train_loss = 1.98695702, grad/param norm = 2.3081e-01, time/batch = 0.6753s	
1638/33800 (epoch 2.423), train_loss = 1.93643546, grad/param norm = 2.4035e-01, time/batch = 0.6732s	
1639/33800 (epoch 2.425), train_loss = 1.99481800, grad/param norm = 2.3736e-01, time/batch = 0.6779s	
1640/33800 (epoch 2.426), train_loss = 1.91029274, grad/param norm = 2.1950e-01, time/batch = 0.6747s	
1641/33800 (epoch 2.428), train_loss = 2.08789217, grad/param norm = 2.0255e-01, time/batch = 0.7321s	
1642/33800 (epoch 2.429), train_loss = 1.84993888, grad/param norm = 2.1693e-01, time/batch = 0.7075s	
1643/33800 (epoch 2.430), train_loss = 1.97612637, grad/param norm = 2.0525e-01, time/batch = 0.6891s	
1644/33800 (epoch 2.432), train_loss = 1.93819376, grad/param norm = 1.9175e-01, time/batch = 0.6898s	
1645/33800 (epoch 2.433), train_loss = 1.98690841, grad/param norm = 1.9226e-01, time/batch = 0.6762s	
1646/33800 (epoch 2.435), train_loss = 2.08214988, grad/param norm = 2.0906e-01, time/batch = 0.6713s	
1647/33800 (epoch 2.436), train_loss = 1.95777010, grad/param norm = 2.0067e-01, time/batch = 0.6734s	
1648/33800 (epoch 2.438), train_loss = 1.85719650, grad/param norm = 1.8734e-01, time/batch = 0.6746s	
1649/33800 (epoch 2.439), train_loss = 1.97913243, grad/param norm = 2.2613e-01, time/batch = 0.6739s	
1650/33800 (epoch 2.441), train_loss = 1.93233940, grad/param norm = 2.0094e-01, time/batch = 0.6736s	
1651/33800 (epoch 2.442), train_loss = 1.99793469, grad/param norm = 2.0217e-01, time/batch = 0.6790s	
1652/33800 (epoch 2.444), train_loss = 1.94101732, grad/param norm = 1.9117e-01, time/batch = 0.6741s	
1653/33800 (epoch 2.445), train_loss = 1.92682856, grad/param norm = 1.8734e-01, time/batch = 0.6750s	
1654/33800 (epoch 2.447), train_loss = 1.83784873, grad/param norm = 2.1218e-01, time/batch = 0.6764s	
1655/33800 (epoch 2.448), train_loss = 2.02351995, grad/param norm = 2.0683e-01, time/batch = 0.6748s	
1656/33800 (epoch 2.450), train_loss = 1.91389920, grad/param norm = 1.8462e-01, time/batch = 0.6786s	
1657/33800 (epoch 2.451), train_loss = 1.90144981, grad/param norm = 2.0664e-01, time/batch = 0.6772s	
1658/33800 (epoch 2.453), train_loss = 2.02088656, grad/param norm = 1.9050e-01, time/batch = 0.6779s	
1659/33800 (epoch 2.454), train_loss = 2.00107936, grad/param norm = 1.9602e-01, time/batch = 0.6829s	
1660/33800 (epoch 2.456), train_loss = 1.93424075, grad/param norm = 1.8533e-01, time/batch = 0.6800s	
1661/33800 (epoch 2.457), train_loss = 1.84081932, grad/param norm = 1.7815e-01, time/batch = 0.6901s	
1662/33800 (epoch 2.459), train_loss = 1.93641136, grad/param norm = 1.8544e-01, time/batch = 0.6980s	
1663/33800 (epoch 2.460), train_loss = 1.91595890, grad/param norm = 2.0627e-01, time/batch = 0.6783s	
1664/33800 (epoch 2.462), train_loss = 1.97771453, grad/param norm = 1.8516e-01, time/batch = 0.6741s	
1665/33800 (epoch 2.463), train_loss = 1.85209474, grad/param norm = 1.7696e-01, time/batch = 0.6808s	
1666/33800 (epoch 2.464), train_loss = 2.02332520, grad/param norm = 2.1461e-01, time/batch = 0.6900s	
1667/33800 (epoch 2.466), train_loss = 1.86245697, grad/param norm = 1.8835e-01, time/batch = 0.6782s	
1668/33800 (epoch 2.467), train_loss = 1.95548089, grad/param norm = 2.0380e-01, time/batch = 0.6788s	
1669/33800 (epoch 2.469), train_loss = 1.84255444, grad/param norm = 1.9716e-01, time/batch = 0.6713s	
1670/33800 (epoch 2.470), train_loss = 1.88229830, grad/param norm = 2.0593e-01, time/batch = 0.6698s	
1671/33800 (epoch 2.472), train_loss = 1.84990354, grad/param norm = 2.4905e-01, time/batch = 0.6708s	
1672/33800 (epoch 2.473), train_loss = 1.96852120, grad/param norm = 2.2839e-01, time/batch = 0.6674s	
1673/33800 (epoch 2.475), train_loss = 1.91260846, grad/param norm = 2.0317e-01, time/batch = 0.6740s	
1674/33800 (epoch 2.476), train_loss = 1.93767781, grad/param norm = 1.8861e-01, time/batch = 0.6654s	
1675/33800 (epoch 2.478), train_loss = 1.93075975, grad/param norm = 2.3150e-01, time/batch = 0.6652s	
1676/33800 (epoch 2.479), train_loss = 1.99785965, grad/param norm = 2.2039e-01, time/batch = 0.6653s	
1677/33800 (epoch 2.481), train_loss = 1.93511323, grad/param norm = 1.9981e-01, time/batch = 0.6652s	
1678/33800 (epoch 2.482), train_loss = 2.10034588, grad/param norm = 2.6916e-01, time/batch = 0.6652s	
1679/33800 (epoch 2.484), train_loss = 1.90321272, grad/param norm = 1.9578e-01, time/batch = 0.6725s	
1680/33800 (epoch 2.485), train_loss = 1.89531935, grad/param norm = 2.5409e-01, time/batch = 0.6757s	
1681/33800 (epoch 2.487), train_loss = 1.90135417, grad/param norm = 2.2541e-01, time/batch = 0.6745s	
1682/33800 (epoch 2.488), train_loss = 1.89474557, grad/param norm = 1.9112e-01, time/batch = 0.6713s	
1683/33800 (epoch 2.490), train_loss = 1.98082159, grad/param norm = 1.9111e-01, time/batch = 0.6791s	
1684/33800 (epoch 2.491), train_loss = 1.84961564, grad/param norm = 2.0261e-01, time/batch = 0.6736s	
1685/33800 (epoch 2.493), train_loss = 1.94619540, grad/param norm = 2.2484e-01, time/batch = 0.6870s	
1686/33800 (epoch 2.494), train_loss = 2.03688539, grad/param norm = 2.3270e-01, time/batch = 0.6806s	
1687/33800 (epoch 2.496), train_loss = 1.93659903, grad/param norm = 1.9918e-01, time/batch = 0.6737s	
1688/33800 (epoch 2.497), train_loss = 1.97232859, grad/param norm = 1.9897e-01, time/batch = 0.6838s	
1689/33800 (epoch 2.499), train_loss = 1.86161655, grad/param norm = 1.9866e-01, time/batch = 0.6771s	
1690/33800 (epoch 2.500), train_loss = 2.06237013, grad/param norm = 2.4163e-01, time/batch = 0.6891s	
1691/33800 (epoch 2.501), train_loss = 1.89915970, grad/param norm = 1.8601e-01, time/batch = 0.6775s	
1692/33800 (epoch 2.503), train_loss = 2.02217931, grad/param norm = 1.9329e-01, time/batch = 0.6766s	
1693/33800 (epoch 2.504), train_loss = 1.85663677, grad/param norm = 1.9909e-01, time/batch = 0.6724s	
1694/33800 (epoch 2.506), train_loss = 2.02442649, grad/param norm = 2.1754e-01, time/batch = 0.6750s	
1695/33800 (epoch 2.507), train_loss = 1.89110774, grad/param norm = 1.8473e-01, time/batch = 0.6815s	
1696/33800 (epoch 2.509), train_loss = 1.97215278, grad/param norm = 1.9446e-01, time/batch = 0.6928s	
1697/33800 (epoch 2.510), train_loss = 1.84122521, grad/param norm = 1.9594e-01, time/batch = 0.6984s	
1698/33800 (epoch 2.512), train_loss = 1.87898483, grad/param norm = 2.2197e-01, time/batch = 0.7189s	
1699/33800 (epoch 2.513), train_loss = 2.04851164, grad/param norm = 2.0272e-01, time/batch = 0.7269s	
1700/33800 (epoch 2.515), train_loss = 1.99082203, grad/param norm = 1.9426e-01, time/batch = 0.7199s	
1701/33800 (epoch 2.516), train_loss = 1.95154431, grad/param norm = 1.8711e-01, time/batch = 0.6999s	
1702/33800 (epoch 2.518), train_loss = 1.97510221, grad/param norm = 2.1559e-01, time/batch = 0.6807s	
1703/33800 (epoch 2.519), train_loss = 1.79955770, grad/param norm = 1.8805e-01, time/batch = 0.6793s	
1704/33800 (epoch 2.521), train_loss = 1.96231789, grad/param norm = 2.0745e-01, time/batch = 0.6994s	
1705/33800 (epoch 2.522), train_loss = 1.78878723, grad/param norm = 1.8305e-01, time/batch = 0.6966s	
1706/33800 (epoch 2.524), train_loss = 1.89811910, grad/param norm = 1.8110e-01, time/batch = 0.6840s	
1707/33800 (epoch 2.525), train_loss = 1.99025399, grad/param norm = 1.9614e-01, time/batch = 0.6770s	
1708/33800 (epoch 2.527), train_loss = 1.85841344, grad/param norm = 1.8813e-01, time/batch = 0.6844s	
1709/33800 (epoch 2.528), train_loss = 1.94860283, grad/param norm = 1.8529e-01, time/batch = 0.6795s	
1710/33800 (epoch 2.530), train_loss = 2.03094855, grad/param norm = 2.1477e-01, time/batch = 0.6816s	
1711/33800 (epoch 2.531), train_loss = 2.01492487, grad/param norm = 2.1830e-01, time/batch = 0.6827s	
1712/33800 (epoch 2.533), train_loss = 1.86460415, grad/param norm = 2.1281e-01, time/batch = 0.6808s	
1713/33800 (epoch 2.534), train_loss = 1.82885091, grad/param norm = 1.7961e-01, time/batch = 0.6774s	
1714/33800 (epoch 2.536), train_loss = 2.09100209, grad/param norm = 2.1731e-01, time/batch = 0.6778s	
1715/33800 (epoch 2.537), train_loss = 1.98896505, grad/param norm = 2.2313e-01, time/batch = 0.6836s	
1716/33800 (epoch 2.538), train_loss = 1.93291901, grad/param norm = 1.9186e-01, time/batch = 0.6850s	
1717/33800 (epoch 2.540), train_loss = 1.82574060, grad/param norm = 1.9520e-01, time/batch = 0.6785s	
1718/33800 (epoch 2.541), train_loss = 1.86229401, grad/param norm = 2.0137e-01, time/batch = 0.6715s	
1719/33800 (epoch 2.543), train_loss = 1.81721188, grad/param norm = 1.9517e-01, time/batch = 0.6756s	
1720/33800 (epoch 2.544), train_loss = 2.01402201, grad/param norm = 1.9660e-01, time/batch = 0.6735s	
1721/33800 (epoch 2.546), train_loss = 2.17660089, grad/param norm = 2.2072e-01, time/batch = 0.6791s	
1722/33800 (epoch 2.547), train_loss = 2.05419004, grad/param norm = 2.1847e-01, time/batch = 0.6787s	
1723/33800 (epoch 2.549), train_loss = 1.98431574, grad/param norm = 2.3625e-01, time/batch = 0.6807s	
1724/33800 (epoch 2.550), train_loss = 1.91342585, grad/param norm = 2.0276e-01, time/batch = 0.6771s	
1725/33800 (epoch 2.552), train_loss = 2.05402416, grad/param norm = 2.1955e-01, time/batch = 0.6812s	
1726/33800 (epoch 2.553), train_loss = 2.13522352, grad/param norm = 1.9652e-01, time/batch = 0.6876s	
1727/33800 (epoch 2.555), train_loss = 1.88042989, grad/param norm = 1.8342e-01, time/batch = 0.6807s	
1728/33800 (epoch 2.556), train_loss = 1.78901671, grad/param norm = 1.9963e-01, time/batch = 0.6772s	
1729/33800 (epoch 2.558), train_loss = 1.76631032, grad/param norm = 2.0637e-01, time/batch = 0.6771s	
1730/33800 (epoch 2.559), train_loss = 2.03260752, grad/param norm = 2.1528e-01, time/batch = 0.6806s	
1731/33800 (epoch 2.561), train_loss = 1.85726577, grad/param norm = 1.8876e-01, time/batch = 0.6888s	
1732/33800 (epoch 2.562), train_loss = 1.94720655, grad/param norm = 1.8333e-01, time/batch = 0.6809s	
1733/33800 (epoch 2.564), train_loss = 1.95436305, grad/param norm = 1.8804e-01, time/batch = 0.6743s	
1734/33800 (epoch 2.565), train_loss = 2.22379525, grad/param norm = 2.1884e-01, time/batch = 0.6727s	
1735/33800 (epoch 2.567), train_loss = 1.99832765, grad/param norm = 2.2075e-01, time/batch = 0.6726s	
1736/33800 (epoch 2.568), train_loss = 1.92861260, grad/param norm = 2.4477e-01, time/batch = 0.6738s	
1737/33800 (epoch 2.570), train_loss = 1.92491092, grad/param norm = 2.5926e-01, time/batch = 0.6873s	
1738/33800 (epoch 2.571), train_loss = 1.89727939, grad/param norm = 2.6778e-01, time/batch = 0.6797s	
1739/33800 (epoch 2.572), train_loss = 2.03345977, grad/param norm = 1.9817e-01, time/batch = 0.6761s	
1740/33800 (epoch 2.574), train_loss = 2.07559805, grad/param norm = 2.0705e-01, time/batch = 0.6794s	
1741/33800 (epoch 2.575), train_loss = 1.80742276, grad/param norm = 1.6510e-01, time/batch = 0.6816s	
1742/33800 (epoch 2.577), train_loss = 1.92442110, grad/param norm = 1.9355e-01, time/batch = 0.6788s	
1743/33800 (epoch 2.578), train_loss = 1.91711641, grad/param norm = 1.9124e-01, time/batch = 0.6800s	
1744/33800 (epoch 2.580), train_loss = 1.95166178, grad/param norm = 2.1398e-01, time/batch = 0.6790s	
1745/33800 (epoch 2.581), train_loss = 1.98276708, grad/param norm = 2.0893e-01, time/batch = 0.6815s	
1746/33800 (epoch 2.583), train_loss = 2.04667256, grad/param norm = 1.9333e-01, time/batch = 0.6910s	
1747/33800 (epoch 2.584), train_loss = 1.92783427, grad/param norm = 1.8611e-01, time/batch = 0.6886s	
1748/33800 (epoch 2.586), train_loss = 1.76421593, grad/param norm = 2.0974e-01, time/batch = 0.6903s	
1749/33800 (epoch 2.587), train_loss = 1.73904295, grad/param norm = 1.8417e-01, time/batch = 0.6715s	
1750/33800 (epoch 2.589), train_loss = 1.87233220, grad/param norm = 1.8122e-01, time/batch = 0.6781s	
1751/33800 (epoch 2.590), train_loss = 1.97222000, grad/param norm = 1.9797e-01, time/batch = 0.6904s	
1752/33800 (epoch 2.592), train_loss = 1.91151195, grad/param norm = 2.1899e-01, time/batch = 0.6752s	
1753/33800 (epoch 2.593), train_loss = 1.91122015, grad/param norm = 2.5690e-01, time/batch = 0.6782s	
1754/33800 (epoch 2.595), train_loss = 2.00645711, grad/param norm = 2.0097e-01, time/batch = 0.6766s	
1755/33800 (epoch 2.596), train_loss = 1.98355102, grad/param norm = 2.2051e-01, time/batch = 0.6755s	
1756/33800 (epoch 2.598), train_loss = 2.01787174, grad/param norm = 2.2875e-01, time/batch = 0.6793s	
1757/33800 (epoch 2.599), train_loss = 1.92560842, grad/param norm = 2.3324e-01, time/batch = 0.6770s	
1758/33800 (epoch 2.601), train_loss = 1.79464748, grad/param norm = 2.2778e-01, time/batch = 0.6793s	
1759/33800 (epoch 2.602), train_loss = 2.03883670, grad/param norm = 2.0079e-01, time/batch = 0.7216s	
1760/33800 (epoch 2.604), train_loss = 1.96055281, grad/param norm = 2.0674e-01, time/batch = 0.6990s	
1761/33800 (epoch 2.605), train_loss = 1.98555797, grad/param norm = 1.7315e-01, time/batch = 0.6922s	
1762/33800 (epoch 2.607), train_loss = 1.91896012, grad/param norm = 2.0175e-01, time/batch = 0.6928s	
1763/33800 (epoch 2.608), train_loss = 1.97696893, grad/param norm = 1.8486e-01, time/batch = 0.6832s	
1764/33800 (epoch 2.609), train_loss = 1.94180729, grad/param norm = 2.0333e-01, time/batch = 0.6803s	
1765/33800 (epoch 2.611), train_loss = 1.93046487, grad/param norm = 1.8880e-01, time/batch = 0.6729s	
1766/33800 (epoch 2.612), train_loss = 1.83870916, grad/param norm = 2.0635e-01, time/batch = 0.6760s	
1767/33800 (epoch 2.614), train_loss = 1.93317432, grad/param norm = 2.1562e-01, time/batch = 0.6766s	
1768/33800 (epoch 2.615), train_loss = 1.88734194, grad/param norm = 2.0223e-01, time/batch = 0.6749s	
1769/33800 (epoch 2.617), train_loss = 1.99044387, grad/param norm = 2.1086e-01, time/batch = 0.6800s	
1770/33800 (epoch 2.618), train_loss = 2.02552383, grad/param norm = 2.3046e-01, time/batch = 0.6766s	
1771/33800 (epoch 2.620), train_loss = 1.90499762, grad/param norm = 1.9725e-01, time/batch = 0.6794s	
1772/33800 (epoch 2.621), train_loss = 1.87545894, grad/param norm = 1.8187e-01, time/batch = 0.6770s	
1773/33800 (epoch 2.623), train_loss = 1.86351992, grad/param norm = 1.7483e-01, time/batch = 0.6728s	
1774/33800 (epoch 2.624), train_loss = 1.91595179, grad/param norm = 1.9689e-01, time/batch = 0.6747s	
1775/33800 (epoch 2.626), train_loss = 1.97651895, grad/param norm = 1.9207e-01, time/batch = 0.6803s	
1776/33800 (epoch 2.627), train_loss = 1.89326686, grad/param norm = 1.8987e-01, time/batch = 0.6792s	
1777/33800 (epoch 2.629), train_loss = 2.08207347, grad/param norm = 2.1549e-01, time/batch = 0.6795s	
1778/33800 (epoch 2.630), train_loss = 1.96835499, grad/param norm = 1.9712e-01, time/batch = 0.6806s	
1779/33800 (epoch 2.632), train_loss = 2.01778542, grad/param norm = 1.8889e-01, time/batch = 0.6818s	
1780/33800 (epoch 2.633), train_loss = 1.98108660, grad/param norm = 2.2721e-01, time/batch = 0.6796s	
1781/33800 (epoch 2.635), train_loss = 1.93624048, grad/param norm = 1.9326e-01, time/batch = 0.6812s	
1782/33800 (epoch 2.636), train_loss = 1.97437260, grad/param norm = 1.8214e-01, time/batch = 0.6805s	
1783/33800 (epoch 2.638), train_loss = 1.94649591, grad/param norm = 2.0685e-01, time/batch = 0.6796s	
1784/33800 (epoch 2.639), train_loss = 2.00530063, grad/param norm = 2.1404e-01, time/batch = 0.6967s	
1785/33800 (epoch 2.641), train_loss = 1.85361886, grad/param norm = 2.1625e-01, time/batch = 0.7002s	
1786/33800 (epoch 2.642), train_loss = 1.87487842, grad/param norm = 1.8854e-01, time/batch = 0.6920s	
1787/33800 (epoch 2.643), train_loss = 1.90182576, grad/param norm = 1.7083e-01, time/batch = 0.6838s	
1788/33800 (epoch 2.645), train_loss = 2.11236770, grad/param norm = 1.9741e-01, time/batch = 0.6933s	
1789/33800 (epoch 2.646), train_loss = 1.93984377, grad/param norm = 2.0129e-01, time/batch = 0.6980s	
1790/33800 (epoch 2.648), train_loss = 1.94999496, grad/param norm = 2.0661e-01, time/batch = 0.6845s	
1791/33800 (epoch 2.649), train_loss = 1.86160316, grad/param norm = 2.7178e-01, time/batch = 0.6879s	
1792/33800 (epoch 2.651), train_loss = 1.89656320, grad/param norm = 2.5467e-01, time/batch = 0.6994s	
1793/33800 (epoch 2.652), train_loss = 1.95067790, grad/param norm = 2.6340e-01, time/batch = 0.6962s	
1794/33800 (epoch 2.654), train_loss = 1.94389438, grad/param norm = 2.2850e-01, time/batch = 0.6902s	
1795/33800 (epoch 2.655), train_loss = 1.77654033, grad/param norm = 2.0561e-01, time/batch = 0.6914s	
1796/33800 (epoch 2.657), train_loss = 1.79786913, grad/param norm = 1.9169e-01, time/batch = 0.6986s	
1797/33800 (epoch 2.658), train_loss = 1.71302663, grad/param norm = 1.7705e-01, time/batch = 0.7025s	
1798/33800 (epoch 2.660), train_loss = 1.92553648, grad/param norm = 1.9184e-01, time/batch = 0.7024s	
1799/33800 (epoch 2.661), train_loss = 1.89693512, grad/param norm = 1.8665e-01, time/batch = 0.6938s	
1800/33800 (epoch 2.663), train_loss = 1.96284063, grad/param norm = 2.3397e-01, time/batch = 0.6968s	
1801/33800 (epoch 2.664), train_loss = 1.84551488, grad/param norm = 1.9952e-01, time/batch = 0.7039s	
1802/33800 (epoch 2.666), train_loss = 1.79249613, grad/param norm = 1.7630e-01, time/batch = 0.7015s	
1803/33800 (epoch 2.667), train_loss = 2.04156191, grad/param norm = 2.0758e-01, time/batch = 0.6885s	
1804/33800 (epoch 2.669), train_loss = 1.88912659, grad/param norm = 1.9633e-01, time/batch = 0.6929s	
1805/33800 (epoch 2.670), train_loss = 1.99277935, grad/param norm = 2.0868e-01, time/batch = 0.6898s	
1806/33800 (epoch 2.672), train_loss = 1.88827456, grad/param norm = 2.0977e-01, time/batch = 0.6938s	
1807/33800 (epoch 2.673), train_loss = 1.85435387, grad/param norm = 2.1007e-01, time/batch = 0.6911s	
1808/33800 (epoch 2.675), train_loss = 1.75721905, grad/param norm = 1.9831e-01, time/batch = 0.6863s	
1809/33800 (epoch 2.676), train_loss = 1.97491873, grad/param norm = 2.0312e-01, time/batch = 0.6862s	
1810/33800 (epoch 2.678), train_loss = 1.80596502, grad/param norm = 2.0327e-01, time/batch = 0.6860s	
1811/33800 (epoch 2.679), train_loss = 1.93976160, grad/param norm = 1.8336e-01, time/batch = 0.6983s	
1812/33800 (epoch 2.680), train_loss = 1.71259142, grad/param norm = 1.9175e-01, time/batch = 0.6999s	
1813/33800 (epoch 2.682), train_loss = 1.96955715, grad/param norm = 1.8491e-01, time/batch = 0.6888s	
1814/33800 (epoch 2.683), train_loss = 2.05176448, grad/param norm = 2.0954e-01, time/batch = 0.6836s	
1815/33800 (epoch 2.685), train_loss = 1.86263097, grad/param norm = 1.9732e-01, time/batch = 0.6934s	
1816/33800 (epoch 2.686), train_loss = 1.83236189, grad/param norm = 1.9347e-01, time/batch = 0.6886s	
1817/33800 (epoch 2.688), train_loss = 1.98427187, grad/param norm = 1.9909e-01, time/batch = 0.6913s	
1818/33800 (epoch 2.689), train_loss = 1.91051163, grad/param norm = 1.9559e-01, time/batch = 0.6914s	
1819/33800 (epoch 2.691), train_loss = 1.98850234, grad/param norm = 1.8590e-01, time/batch = 0.6940s	
1820/33800 (epoch 2.692), train_loss = 2.01924231, grad/param norm = 2.0795e-01, time/batch = 0.6907s	
1821/33800 (epoch 2.694), train_loss = 1.95529746, grad/param norm = 1.9701e-01, time/batch = 0.6976s	
1822/33800 (epoch 2.695), train_loss = 2.00415455, grad/param norm = 2.2197e-01, time/batch = 0.7022s	
1823/33800 (epoch 2.697), train_loss = 1.86960544, grad/param norm = 1.8752e-01, time/batch = 0.6950s	
1824/33800 (epoch 2.698), train_loss = 1.99298271, grad/param norm = 2.0984e-01, time/batch = 0.6897s	
1825/33800 (epoch 2.700), train_loss = 1.93290472, grad/param norm = 2.3210e-01, time/batch = 0.6948s	
1826/33800 (epoch 2.701), train_loss = 1.89290653, grad/param norm = 2.2815e-01, time/batch = 0.6934s	
1827/33800 (epoch 2.703), train_loss = 1.89426798, grad/param norm = 2.4223e-01, time/batch = 0.6974s	
1828/33800 (epoch 2.704), train_loss = 1.88086488, grad/param norm = 1.9612e-01, time/batch = 0.6898s	
1829/33800 (epoch 2.706), train_loss = 1.87870246, grad/param norm = 1.9004e-01, time/batch = 0.7007s	
1830/33800 (epoch 2.707), train_loss = 1.90308690, grad/param norm = 1.9052e-01, time/batch = 0.6985s	
1831/33800 (epoch 2.709), train_loss = 1.91750440, grad/param norm = 2.1107e-01, time/batch = 0.7099s	
1832/33800 (epoch 2.710), train_loss = 1.86736898, grad/param norm = 2.3247e-01, time/batch = 0.7027s	
1833/33800 (epoch 2.712), train_loss = 2.07007706, grad/param norm = 2.4299e-01, time/batch = 0.7013s	
1834/33800 (epoch 2.713), train_loss = 1.97295144, grad/param norm = 2.1391e-01, time/batch = 0.6994s	
1835/33800 (epoch 2.714), train_loss = 1.88548124, grad/param norm = 1.8857e-01, time/batch = 0.6975s	
1836/33800 (epoch 2.716), train_loss = 1.88904706, grad/param norm = 2.4638e-01, time/batch = 0.6928s	
1837/33800 (epoch 2.717), train_loss = 1.90849078, grad/param norm = 2.0024e-01, time/batch = 0.6966s	
1838/33800 (epoch 2.719), train_loss = 1.97625088, grad/param norm = 2.0219e-01, time/batch = 0.6982s	
1839/33800 (epoch 2.720), train_loss = 1.81943087, grad/param norm = 2.2381e-01, time/batch = 0.7024s	
1840/33800 (epoch 2.722), train_loss = 1.90991026, grad/param norm = 2.2738e-01, time/batch = 0.6995s	
1841/33800 (epoch 2.723), train_loss = 1.85119769, grad/param norm = 2.0631e-01, time/batch = 0.7040s	
1842/33800 (epoch 2.725), train_loss = 1.84968913, grad/param norm = 2.0597e-01, time/batch = 0.7018s	
1843/33800 (epoch 2.726), train_loss = 1.72137261, grad/param norm = 1.6450e-01, time/batch = 0.7014s	
1844/33800 (epoch 2.728), train_loss = 1.95999933, grad/param norm = 1.8686e-01, time/batch = 0.7004s	
1845/33800 (epoch 2.729), train_loss = 1.97286377, grad/param norm = 2.0269e-01, time/batch = 0.6999s	
1846/33800 (epoch 2.731), train_loss = 1.92152368, grad/param norm = 1.8388e-01, time/batch = 0.7369s	
1847/33800 (epoch 2.732), train_loss = 1.96576962, grad/param norm = 1.8724e-01, time/batch = 0.7203s	
1848/33800 (epoch 2.734), train_loss = 1.91861808, grad/param norm = 1.9877e-01, time/batch = 0.7112s	
1849/33800 (epoch 2.735), train_loss = 1.91748096, grad/param norm = 2.0493e-01, time/batch = 0.7037s	
1850/33800 (epoch 2.737), train_loss = 1.92073936, grad/param norm = 1.8358e-01, time/batch = 0.6977s	
1851/33800 (epoch 2.738), train_loss = 1.91773180, grad/param norm = 2.1105e-01, time/batch = 0.7003s	
1852/33800 (epoch 2.740), train_loss = 2.08469744, grad/param norm = 2.2257e-01, time/batch = 0.7096s	
1853/33800 (epoch 2.741), train_loss = 1.94248810, grad/param norm = 2.0504e-01, time/batch = 0.7016s	
1854/33800 (epoch 2.743), train_loss = 1.83830894, grad/param norm = 1.8205e-01, time/batch = 0.6892s	
1855/33800 (epoch 2.744), train_loss = 1.79458694, grad/param norm = 1.8131e-01, time/batch = 0.6971s	
1856/33800 (epoch 2.746), train_loss = 1.74677836, grad/param norm = 1.8509e-01, time/batch = 0.7053s	
1857/33800 (epoch 2.747), train_loss = 1.86008420, grad/param norm = 2.0410e-01, time/batch = 0.6941s	
1858/33800 (epoch 2.749), train_loss = 1.82482983, grad/param norm = 1.9341e-01, time/batch = 0.6938s	
1859/33800 (epoch 2.750), train_loss = 1.76712438, grad/param norm = 2.2124e-01, time/batch = 0.6920s	
1860/33800 (epoch 2.751), train_loss = 2.08629492, grad/param norm = 2.4241e-01, time/batch = 0.6899s	
1861/33800 (epoch 2.753), train_loss = 1.83414511, grad/param norm = 2.2196e-01, time/batch = 0.6928s	
1862/33800 (epoch 2.754), train_loss = 1.94003354, grad/param norm = 2.1778e-01, time/batch = 0.6969s	
1863/33800 (epoch 2.756), train_loss = 1.97070180, grad/param norm = 1.9537e-01, time/batch = 0.6903s	
1864/33800 (epoch 2.757), train_loss = 1.89184287, grad/param norm = 1.8893e-01, time/batch = 0.6861s	
1865/33800 (epoch 2.759), train_loss = 1.92552234, grad/param norm = 1.9363e-01, time/batch = 0.6965s	
1866/33800 (epoch 2.760), train_loss = 1.81991528, grad/param norm = 2.0222e-01, time/batch = 0.7050s	
1867/33800 (epoch 2.762), train_loss = 2.02359438, grad/param norm = 2.3801e-01, time/batch = 0.6939s	
1868/33800 (epoch 2.763), train_loss = 1.76515886, grad/param norm = 1.9746e-01, time/batch = 0.6968s	
1869/33800 (epoch 2.765), train_loss = 1.88327972, grad/param norm = 1.8685e-01, time/batch = 0.7063s	
1870/33800 (epoch 2.766), train_loss = 1.97954972, grad/param norm = 1.9545e-01, time/batch = 0.7140s	
1871/33800 (epoch 2.768), train_loss = 1.75527644, grad/param norm = 1.9336e-01, time/batch = 0.7243s	
1872/33800 (epoch 2.769), train_loss = 1.76732721, grad/param norm = 2.1922e-01, time/batch = 0.7075s	
1873/33800 (epoch 2.771), train_loss = 1.90106495, grad/param norm = 1.7727e-01, time/batch = 0.7054s	
1874/33800 (epoch 2.772), train_loss = 1.78058191, grad/param norm = 1.9569e-01, time/batch = 0.7013s	
1875/33800 (epoch 2.774), train_loss = 2.00217983, grad/param norm = 2.0843e-01, time/batch = 0.7078s	
1876/33800 (epoch 2.775), train_loss = 1.88774845, grad/param norm = 1.9017e-01, time/batch = 0.7057s	
1877/33800 (epoch 2.777), train_loss = 1.92184600, grad/param norm = 2.0532e-01, time/batch = 0.7055s	
1878/33800 (epoch 2.778), train_loss = 1.99472768, grad/param norm = 2.0895e-01, time/batch = 0.7032s	
1879/33800 (epoch 2.780), train_loss = 1.96558257, grad/param norm = 2.0493e-01, time/batch = 0.6988s	
1880/33800 (epoch 2.781), train_loss = 1.89821834, grad/param norm = 2.1368e-01, time/batch = 0.6981s	
1881/33800 (epoch 2.783), train_loss = 1.81773206, grad/param norm = 1.7885e-01, time/batch = 0.6942s	
1882/33800 (epoch 2.784), train_loss = 1.93175399, grad/param norm = 1.7782e-01, time/batch = 0.6967s	
1883/33800 (epoch 2.786), train_loss = 1.94217284, grad/param norm = 1.9240e-01, time/batch = 0.6960s	
1884/33800 (epoch 2.787), train_loss = 1.84100584, grad/param norm = 2.0882e-01, time/batch = 0.7004s	
1885/33800 (epoch 2.788), train_loss = 1.86794850, grad/param norm = 2.1338e-01, time/batch = 0.7001s	
1886/33800 (epoch 2.790), train_loss = 1.76461719, grad/param norm = 1.7070e-01, time/batch = 0.7058s	
1887/33800 (epoch 2.791), train_loss = 1.75093286, grad/param norm = 1.8271e-01, time/batch = 0.6988s	
1888/33800 (epoch 2.793), train_loss = 1.96537580, grad/param norm = 2.0327e-01, time/batch = 0.6979s	
1889/33800 (epoch 2.794), train_loss = 2.02245865, grad/param norm = 2.3527e-01, time/batch = 0.6940s	
1890/33800 (epoch 2.796), train_loss = 1.93326027, grad/param norm = 2.4366e-01, time/batch = 0.6990s	
1891/33800 (epoch 2.797), train_loss = 1.71319415, grad/param norm = 1.7877e-01, time/batch = 0.6940s	
1892/33800 (epoch 2.799), train_loss = 1.81731778, grad/param norm = 1.9601e-01, time/batch = 0.6949s	
1893/33800 (epoch 2.800), train_loss = 1.96749697, grad/param norm = 2.0767e-01, time/batch = 0.6989s	
1894/33800 (epoch 2.802), train_loss = 1.87937178, grad/param norm = 1.8834e-01, time/batch = 0.7200s	
1895/33800 (epoch 2.803), train_loss = 1.97395013, grad/param norm = 1.8811e-01, time/batch = 0.6966s	
1896/33800 (epoch 2.805), train_loss = 1.83481848, grad/param norm = 2.0438e-01, time/batch = 0.6924s	
1897/33800 (epoch 2.806), train_loss = 1.80554217, grad/param norm = 1.9164e-01, time/batch = 0.6999s	
1898/33800 (epoch 2.808), train_loss = 1.95298789, grad/param norm = 2.0796e-01, time/batch = 0.6998s	
1899/33800 (epoch 2.809), train_loss = 1.93438286, grad/param norm = 1.9938e-01, time/batch = 0.6999s	
1900/33800 (epoch 2.811), train_loss = 1.75091897, grad/param norm = 1.8055e-01, time/batch = 0.6984s	
1901/33800 (epoch 2.812), train_loss = 1.93503963, grad/param norm = 2.0820e-01, time/batch = 0.7005s	
1902/33800 (epoch 2.814), train_loss = 1.91866350, grad/param norm = 2.0874e-01, time/batch = 0.6993s	
1903/33800 (epoch 2.815), train_loss = 1.77131199, grad/param norm = 2.0989e-01, time/batch = 0.7001s	
1904/33800 (epoch 2.817), train_loss = 1.87696113, grad/param norm = 1.8835e-01, time/batch = 0.7033s	
1905/33800 (epoch 2.818), train_loss = 2.01059818, grad/param norm = 2.0926e-01, time/batch = 0.7007s	
1906/33800 (epoch 2.820), train_loss = 1.83435247, grad/param norm = 1.7886e-01, time/batch = 0.6929s	
1907/33800 (epoch 2.821), train_loss = 1.94266257, grad/param norm = 2.1822e-01, time/batch = 0.6704s	
1908/33800 (epoch 2.822), train_loss = 1.86440624, grad/param norm = 2.2078e-01, time/batch = 0.6715s	
1909/33800 (epoch 2.824), train_loss = 1.88649181, grad/param norm = 2.0562e-01, time/batch = 0.6722s	
1910/33800 (epoch 2.825), train_loss = 1.91337753, grad/param norm = 2.3076e-01, time/batch = 0.6735s	
1911/33800 (epoch 2.827), train_loss = 1.96269157, grad/param norm = 1.9990e-01, time/batch = 0.6784s	
1912/33800 (epoch 2.828), train_loss = 1.93677865, grad/param norm = 1.8262e-01, time/batch = 0.6795s	
1913/33800 (epoch 2.830), train_loss = 1.78667361, grad/param norm = 1.9910e-01, time/batch = 0.6774s	
1914/33800 (epoch 2.831), train_loss = 2.02298889, grad/param norm = 2.1327e-01, time/batch = 0.6856s	
1915/33800 (epoch 2.833), train_loss = 1.89622525, grad/param norm = 1.8637e-01, time/batch = 0.6865s	
1916/33800 (epoch 2.834), train_loss = 1.88528393, grad/param norm = 1.9682e-01, time/batch = 0.6818s	
1917/33800 (epoch 2.836), train_loss = 1.82205727, grad/param norm = 2.0276e-01, time/batch = 0.6785s	
1918/33800 (epoch 2.837), train_loss = 2.00700561, grad/param norm = 1.9369e-01, time/batch = 0.6832s	
1919/33800 (epoch 2.839), train_loss = 1.78935181, grad/param norm = 1.8262e-01, time/batch = 0.7253s	
1920/33800 (epoch 2.840), train_loss = 1.84442991, grad/param norm = 1.7994e-01, time/batch = 0.6925s	
1921/33800 (epoch 2.842), train_loss = 1.77707910, grad/param norm = 1.7869e-01, time/batch = 0.6873s	
1922/33800 (epoch 2.843), train_loss = 1.79002623, grad/param norm = 1.9182e-01, time/batch = 0.6892s	
1923/33800 (epoch 2.845), train_loss = 1.99511377, grad/param norm = 1.8597e-01, time/batch = 0.7012s	
1924/33800 (epoch 2.846), train_loss = 1.95348552, grad/param norm = 1.9258e-01, time/batch = 0.7311s	
1925/33800 (epoch 2.848), train_loss = 2.00617474, grad/param norm = 1.8804e-01, time/batch = 0.7022s	
1926/33800 (epoch 2.849), train_loss = 1.77506110, grad/param norm = 1.8540e-01, time/batch = 0.6989s	
1927/33800 (epoch 2.851), train_loss = 1.88702213, grad/param norm = 1.7761e-01, time/batch = 0.6958s	
1928/33800 (epoch 2.852), train_loss = 1.80105464, grad/param norm = 1.7568e-01, time/batch = 0.6733s	
1929/33800 (epoch 2.854), train_loss = 1.89877540, grad/param norm = 2.0130e-01, time/batch = 0.6724s	
1930/33800 (epoch 2.855), train_loss = 1.82544614, grad/param norm = 2.0983e-01, time/batch = 0.6736s	
1931/33800 (epoch 2.857), train_loss = 1.92260520, grad/param norm = 2.0539e-01, time/batch = 0.6760s	
1932/33800 (epoch 2.858), train_loss = 1.78282831, grad/param norm = 2.0335e-01, time/batch = 0.6749s	
1933/33800 (epoch 2.859), train_loss = 1.91753466, grad/param norm = 1.9150e-01, time/batch = 0.6797s	
1934/33800 (epoch 2.861), train_loss = 2.00143387, grad/param norm = 2.1343e-01, time/batch = 0.6743s	
1935/33800 (epoch 2.862), train_loss = 1.85978905, grad/param norm = 1.9055e-01, time/batch = 0.6719s	
1936/33800 (epoch 2.864), train_loss = 2.14025660, grad/param norm = 2.3316e-01, time/batch = 0.6734s	
1937/33800 (epoch 2.865), train_loss = 1.92603800, grad/param norm = 2.1127e-01, time/batch = 0.6730s	
1938/33800 (epoch 2.867), train_loss = 1.81043873, grad/param norm = 2.0738e-01, time/batch = 0.6752s	
1939/33800 (epoch 2.868), train_loss = 1.57140399, grad/param norm = 1.8396e-01, time/batch = 0.6751s	
1940/33800 (epoch 2.870), train_loss = 1.83179077, grad/param norm = 2.0354e-01, time/batch = 0.6738s	
1941/33800 (epoch 2.871), train_loss = 1.90934263, grad/param norm = 1.9492e-01, time/batch = 0.6783s	
1942/33800 (epoch 2.873), train_loss = 1.77991226, grad/param norm = 1.9608e-01, time/batch = 0.6778s	
1943/33800 (epoch 2.874), train_loss = 1.94137480, grad/param norm = 2.0437e-01, time/batch = 0.6786s	
1944/33800 (epoch 2.876), train_loss = 1.79098269, grad/param norm = 1.6964e-01, time/batch = 0.6819s	
1945/33800 (epoch 2.877), train_loss = 1.83611087, grad/param norm = 1.7747e-01, time/batch = 0.6818s	
1946/33800 (epoch 2.879), train_loss = 1.89942417, grad/param norm = 1.8677e-01, time/batch = 0.6764s	
1947/33800 (epoch 2.880), train_loss = 1.97067987, grad/param norm = 2.0283e-01, time/batch = 0.6735s	
1948/33800 (epoch 2.882), train_loss = 1.81544052, grad/param norm = 1.7865e-01, time/batch = 0.6795s	
1949/33800 (epoch 2.883), train_loss = 1.76080239, grad/param norm = 2.0984e-01, time/batch = 0.6733s	
1950/33800 (epoch 2.885), train_loss = 1.83652482, grad/param norm = 1.8789e-01, time/batch = 0.6791s	
1951/33800 (epoch 2.886), train_loss = 1.87694386, grad/param norm = 2.0778e-01, time/batch = 0.6913s	
1952/33800 (epoch 2.888), train_loss = 1.85944314, grad/param norm = 1.7679e-01, time/batch = 0.6792s	
1953/33800 (epoch 2.889), train_loss = 1.66566445, grad/param norm = 1.6931e-01, time/batch = 0.6815s	
1954/33800 (epoch 2.891), train_loss = 1.80074537, grad/param norm = 1.8476e-01, time/batch = 0.6808s	
1955/33800 (epoch 2.892), train_loss = 1.86346464, grad/param norm = 2.2226e-01, time/batch = 0.6823s	
1956/33800 (epoch 2.893), train_loss = 1.81542494, grad/param norm = 2.1287e-01, time/batch = 0.7001s	
1957/33800 (epoch 2.895), train_loss = 2.06537208, grad/param norm = 2.2628e-01, time/batch = 0.7212s	
1958/33800 (epoch 2.896), train_loss = 1.85809046, grad/param norm = 2.0247e-01, time/batch = 0.7056s	
1959/33800 (epoch 2.898), train_loss = 1.86504391, grad/param norm = 2.0237e-01, time/batch = 0.7066s	
1960/33800 (epoch 2.899), train_loss = 1.76930783, grad/param norm = 2.1553e-01, time/batch = 0.7097s	
1961/33800 (epoch 2.901), train_loss = 2.01256707, grad/param norm = 2.0353e-01, time/batch = 0.7176s	
1962/33800 (epoch 2.902), train_loss = 1.97902293, grad/param norm = 1.8635e-01, time/batch = 0.7160s	
1963/33800 (epoch 2.904), train_loss = 1.77665379, grad/param norm = 1.9258e-01, time/batch = 0.7200s	
1964/33800 (epoch 2.905), train_loss = 1.90468822, grad/param norm = 1.9924e-01, time/batch = 0.6976s	
1965/33800 (epoch 2.907), train_loss = 1.76357403, grad/param norm = 1.8431e-01, time/batch = 0.6910s	
1966/33800 (epoch 2.908), train_loss = 1.94940697, grad/param norm = 2.1079e-01, time/batch = 0.6932s	
1967/33800 (epoch 2.910), train_loss = 2.00056941, grad/param norm = 2.2916e-01, time/batch = 0.6890s	
1968/33800 (epoch 2.911), train_loss = 1.96037356, grad/param norm = 2.0153e-01, time/batch = 0.6884s	
1969/33800 (epoch 2.913), train_loss = 1.94935582, grad/param norm = 1.8219e-01, time/batch = 0.6918s	
1970/33800 (epoch 2.914), train_loss = 2.01378978, grad/param norm = 1.8615e-01, time/batch = 0.6876s	
1971/33800 (epoch 2.916), train_loss = 1.84841936, grad/param norm = 1.8837e-01, time/batch = 0.6885s	
1972/33800 (epoch 2.917), train_loss = 1.90146264, grad/param norm = 1.7767e-01, time/batch = 0.6870s	
1973/33800 (epoch 2.919), train_loss = 1.85721610, grad/param norm = 1.9019e-01, time/batch = 0.6919s	
1974/33800 (epoch 2.920), train_loss = 1.88227248, grad/param norm = 2.4294e-01, time/batch = 0.6852s	
1975/33800 (epoch 2.922), train_loss = 1.88235702, grad/param norm = 1.9337e-01, time/batch = 0.6826s	
1976/33800 (epoch 2.923), train_loss = 1.87602361, grad/param norm = 1.8448e-01, time/batch = 0.6932s	
1977/33800 (epoch 2.925), train_loss = 1.94945473, grad/param norm = 1.8096e-01, time/batch = 0.6945s	
1978/33800 (epoch 2.926), train_loss = 1.93359275, grad/param norm = 1.9718e-01, time/batch = 0.6864s	
1979/33800 (epoch 2.928), train_loss = 1.87931607, grad/param norm = 1.9334e-01, time/batch = 0.6758s	
1980/33800 (epoch 2.929), train_loss = 1.80252531, grad/param norm = 1.9652e-01, time/batch = 0.6798s	
1981/33800 (epoch 2.930), train_loss = 1.78189845, grad/param norm = 1.7216e-01, time/batch = 0.6931s	
1982/33800 (epoch 2.932), train_loss = 1.92992868, grad/param norm = 1.7394e-01, time/batch = 0.6784s	
1983/33800 (epoch 2.933), train_loss = 1.91343110, grad/param norm = 2.1179e-01, time/batch = 0.6808s	
1984/33800 (epoch 2.935), train_loss = 1.85560855, grad/param norm = 2.1504e-01, time/batch = 0.6765s	
1985/33800 (epoch 2.936), train_loss = 1.95002192, grad/param norm = 1.9568e-01, time/batch = 0.6769s	
1986/33800 (epoch 2.938), train_loss = 1.92754479, grad/param norm = 2.0563e-01, time/batch = 0.6797s	
1987/33800 (epoch 2.939), train_loss = 1.89090040, grad/param norm = 2.1609e-01, time/batch = 0.6752s	
1988/33800 (epoch 2.941), train_loss = 1.86785561, grad/param norm = 1.8090e-01, time/batch = 0.6777s	
1989/33800 (epoch 2.942), train_loss = 1.88810140, grad/param norm = 1.9060e-01, time/batch = 0.6741s	
1990/33800 (epoch 2.944), train_loss = 1.97161986, grad/param norm = 2.1841e-01, time/batch = 0.6788s	
1991/33800 (epoch 2.945), train_loss = 1.81093479, grad/param norm = 1.8860e-01, time/batch = 0.6949s	
1992/33800 (epoch 2.947), train_loss = 1.85146679, grad/param norm = 2.0453e-01, time/batch = 0.6817s	
1993/33800 (epoch 2.948), train_loss = 1.81592364, grad/param norm = 1.9371e-01, time/batch = 0.6713s	
1994/33800 (epoch 2.950), train_loss = 1.63379637, grad/param norm = 1.8834e-01, time/batch = 0.6761s	
1995/33800 (epoch 2.951), train_loss = 1.87604955, grad/param norm = 1.8369e-01, time/batch = 0.6735s	
1996/33800 (epoch 2.953), train_loss = 1.90019476, grad/param norm = 1.9986e-01, time/batch = 0.6724s	
1997/33800 (epoch 2.954), train_loss = 1.93107729, grad/param norm = 2.0182e-01, time/batch = 0.6774s	
1998/33800 (epoch 2.956), train_loss = 1.85913175, grad/param norm = 2.0930e-01, time/batch = 0.6772s	
1999/33800 (epoch 2.957), train_loss = 1.91648325, grad/param norm = 1.9952e-01, time/batch = 0.6863s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_npr_epoch2.96_1.8684.t7	
2000/33800 (epoch 2.959), train_loss = 1.72267920, grad/param norm = 1.9516e-01, time/batch = 0.6782s	
2001/33800 (epoch 2.960), train_loss = 1.98358371, grad/param norm = 2.0563e-01, time/batch = 0.6925s	
2002/33800 (epoch 2.962), train_loss = 2.03864904, grad/param norm = 2.0774e-01, time/batch = 0.6945s	
2003/33800 (epoch 2.963), train_loss = 1.86568805, grad/param norm = 1.8855e-01, time/batch = 0.6869s	
2004/33800 (epoch 2.964), train_loss = 1.82477998, grad/param norm = 1.8555e-01, time/batch = 0.6882s	
2005/33800 (epoch 2.966), train_loss = 1.66276206, grad/param norm = 1.8135e-01, time/batch = 0.6861s	
2006/33800 (epoch 2.967), train_loss = 1.82895602, grad/param norm = 1.9606e-01, time/batch = 0.6861s	
2007/33800 (epoch 2.969), train_loss = 1.88535992, grad/param norm = 2.3576e-01, time/batch = 0.6848s	
2008/33800 (epoch 2.970), train_loss = 1.81541093, grad/param norm = 1.8356e-01, time/batch = 0.6905s	
2009/33800 (epoch 2.972), train_loss = 1.78491540, grad/param norm = 1.8488e-01, time/batch = 0.6738s	
2010/33800 (epoch 2.973), train_loss = 1.85485468, grad/param norm = 1.9175e-01, time/batch = 0.6782s	
2011/33800 (epoch 2.975), train_loss = 1.99299418, grad/param norm = 2.0700e-01, time/batch = 0.6799s	
2012/33800 (epoch 2.976), train_loss = 2.01206512, grad/param norm = 2.0533e-01, time/batch = 0.6886s	
2013/33800 (epoch 2.978), train_loss = 1.81145656, grad/param norm = 1.8738e-01, time/batch = 0.6761s	
2014/33800 (epoch 2.979), train_loss = 2.04814095, grad/param norm = 2.1362e-01, time/batch = 0.6756s	
2015/33800 (epoch 2.981), train_loss = 1.77254281, grad/param norm = 1.7880e-01, time/batch = 0.6786s	
2016/33800 (epoch 2.982), train_loss = 2.04987968, grad/param norm = 2.0958e-01, time/batch = 0.6739s	
2017/33800 (epoch 2.984), train_loss = 2.01553870, grad/param norm = 2.1128e-01, time/batch = 0.6849s	
2018/33800 (epoch 2.985), train_loss = 2.04964421, grad/param norm = 1.9986e-01, time/batch = 0.6983s	
2019/33800 (epoch 2.987), train_loss = 1.84962322, grad/param norm = 1.9277e-01, time/batch = 0.6893s	
2020/33800 (epoch 2.988), train_loss = 1.75079343, grad/param norm = 1.8620e-01, time/batch = 0.6930s	
2021/33800 (epoch 2.990), train_loss = 1.73913439, grad/param norm = 1.7437e-01, time/batch = 0.7030s	
2022/33800 (epoch 2.991), train_loss = 1.98176012, grad/param norm = 2.1105e-01, time/batch = 0.7060s	
2023/33800 (epoch 2.993), train_loss = 1.85502121, grad/param norm = 1.8686e-01, time/batch = 0.6987s	
2024/33800 (epoch 2.994), train_loss = 1.80312477, grad/param norm = 2.0078e-01, time/batch = 0.6941s	
2025/33800 (epoch 2.996), train_loss = 1.67825236, grad/param norm = 1.9756e-01, time/batch = 0.7015s	
2026/33800 (epoch 2.997), train_loss = 1.86886929, grad/param norm = 1.8643e-01, time/batch = 0.6966s	
2027/33800 (epoch 2.999), train_loss = 1.85814356, grad/param norm = 1.7336e-01, time/batch = 0.6901s	
2028/33800 (epoch 3.000), train_loss = 1.82263851, grad/param norm = 2.1079e-01, time/batch = 0.6974s	
2029/33800 (epoch 3.001), train_loss = 1.92463424, grad/param norm = 1.9156e-01, time/batch = 0.6962s	
2030/33800 (epoch 3.003), train_loss = 1.91194020, grad/param norm = 1.9822e-01, time/batch = 0.6936s	
2031/33800 (epoch 3.004), train_loss = 1.92273861, grad/param norm = 1.9161e-01, time/batch = 0.6971s	
2032/33800 (epoch 3.006), train_loss = 1.95646046, grad/param norm = 1.9653e-01, time/batch = 0.6968s	
2033/33800 (epoch 3.007), train_loss = 1.89786647, grad/param norm = 2.0481e-01, time/batch = 0.7107s	
2034/33800 (epoch 3.009), train_loss = 1.89748996, grad/param norm = 1.8968e-01, time/batch = 0.7224s	
2035/33800 (epoch 3.010), train_loss = 1.82625705, grad/param norm = 1.7863e-01, time/batch = 0.7562s	
2036/33800 (epoch 3.012), train_loss = 1.89095136, grad/param norm = 1.7965e-01, time/batch = 0.7102s	
2037/33800 (epoch 3.013), train_loss = 1.91040474, grad/param norm = 1.9194e-01, time/batch = 0.7133s	
2038/33800 (epoch 3.015), train_loss = 1.83752825, grad/param norm = 1.7895e-01, time/batch = 0.7151s	
2039/33800 (epoch 3.016), train_loss = 1.81066719, grad/param norm = 1.8731e-01, time/batch = 0.7085s	
2040/33800 (epoch 3.018), train_loss = 1.72133980, grad/param norm = 1.9870e-01, time/batch = 0.6993s	
2041/33800 (epoch 3.019), train_loss = 1.92540522, grad/param norm = 1.9049e-01, time/batch = 0.7080s	
2042/33800 (epoch 3.021), train_loss = 2.05988591, grad/param norm = 1.9430e-01, time/batch = 0.7065s	
2043/33800 (epoch 3.022), train_loss = 1.74124038, grad/param norm = 1.8741e-01, time/batch = 0.6969s	
2044/33800 (epoch 3.024), train_loss = 1.63801513, grad/param norm = 1.7369e-01, time/batch = 0.6946s	
2045/33800 (epoch 3.025), train_loss = 1.94714674, grad/param norm = 1.9853e-01, time/batch = 0.6974s	
2046/33800 (epoch 3.027), train_loss = 1.79497977, grad/param norm = 1.8211e-01, time/batch = 0.6925s	
2047/33800 (epoch 3.028), train_loss = 1.79623380, grad/param norm = 1.8808e-01, time/batch = 0.6941s	
2048/33800 (epoch 3.030), train_loss = 1.86845268, grad/param norm = 2.1838e-01, time/batch = 0.6978s	
2049/33800 (epoch 3.031), train_loss = 1.72710465, grad/param norm = 1.8319e-01, time/batch = 0.6939s	
2050/33800 (epoch 3.033), train_loss = 1.75539175, grad/param norm = 1.7704e-01, time/batch = 0.6924s	
2051/33800 (epoch 3.034), train_loss = 1.84790714, grad/param norm = 1.8524e-01, time/batch = 0.6977s	
2052/33800 (epoch 3.036), train_loss = 1.97591370, grad/param norm = 2.2038e-01, time/batch = 0.6898s	
2053/33800 (epoch 3.037), train_loss = 1.89425698, grad/param norm = 1.9407e-01, time/batch = 0.6988s	
2054/33800 (epoch 3.038), train_loss = 1.95667758, grad/param norm = 2.0147e-01, time/batch = 0.7027s	
2055/33800 (epoch 3.040), train_loss = 1.80031200, grad/param norm = 2.0574e-01, time/batch = 0.6927s	
2056/33800 (epoch 3.041), train_loss = 1.91885676, grad/param norm = 1.8836e-01, time/batch = 0.6923s	
2057/33800 (epoch 3.043), train_loss = 1.93565749, grad/param norm = 1.7622e-01, time/batch = 0.6864s	
2058/33800 (epoch 3.044), train_loss = 1.67747759, grad/param norm = 1.8285e-01, time/batch = 0.6904s	
2059/33800 (epoch 3.046), train_loss = 1.62212838, grad/param norm = 1.9593e-01, time/batch = 0.6906s	
2060/33800 (epoch 3.047), train_loss = 1.79587728, grad/param norm = 1.9212e-01, time/batch = 0.6912s	
2061/33800 (epoch 3.049), train_loss = 1.75948123, grad/param norm = 1.9349e-01, time/batch = 0.6959s	
2062/33800 (epoch 3.050), train_loss = 1.74897630, grad/param norm = 1.8926e-01, time/batch = 0.6929s	
2063/33800 (epoch 3.052), train_loss = 1.89226498, grad/param norm = 2.1240e-01, time/batch = 0.6939s	
2064/33800 (epoch 3.053), train_loss = 1.79104725, grad/param norm = 1.7794e-01, time/batch = 0.6966s	
2065/33800 (epoch 3.055), train_loss = 1.79839770, grad/param norm = 1.8988e-01, time/batch = 0.6975s	
2066/33800 (epoch 3.056), train_loss = 1.90903582, grad/param norm = 2.1578e-01, time/batch = 0.6995s	
2067/33800 (epoch 3.058), train_loss = 1.96540081, grad/param norm = 1.7155e-01, time/batch = 0.6998s	
2068/33800 (epoch 3.059), train_loss = 1.74351480, grad/param norm = 1.8583e-01, time/batch = 0.6970s	
2069/33800 (epoch 3.061), train_loss = 1.93444763, grad/param norm = 1.9635e-01, time/batch = 0.6938s	
2070/33800 (epoch 3.062), train_loss = 1.94748493, grad/param norm = 1.8965e-01, time/batch = 0.6968s	
2071/33800 (epoch 3.064), train_loss = 1.93735771, grad/param norm = 2.1264e-01, time/batch = 0.6992s	
2072/33800 (epoch 3.065), train_loss = 1.91414351, grad/param norm = 2.2029e-01, time/batch = 0.6947s	
2073/33800 (epoch 3.067), train_loss = 1.86992781, grad/param norm = 1.8365e-01, time/batch = 0.6936s	
2074/33800 (epoch 3.068), train_loss = 1.93131272, grad/param norm = 2.1346e-01, time/batch = 0.6911s	
2075/33800 (epoch 3.070), train_loss = 1.96227906, grad/param norm = 2.0211e-01, time/batch = 0.6916s	
2076/33800 (epoch 3.071), train_loss = 1.78471246, grad/param norm = 1.8661e-01, time/batch = 0.6920s	
2077/33800 (epoch 3.072), train_loss = 1.90763809, grad/param norm = 1.9217e-01, time/batch = 0.6945s	
2078/33800 (epoch 3.074), train_loss = 2.14301128, grad/param norm = 2.1430e-01, time/batch = 0.6986s	
2079/33800 (epoch 3.075), train_loss = 1.91388675, grad/param norm = 2.0966e-01, time/batch = 0.6893s	
2080/33800 (epoch 3.077), train_loss = 1.76253771, grad/param norm = 2.0368e-01, time/batch = 0.6902s	
2081/33800 (epoch 3.078), train_loss = 1.91231834, grad/param norm = 2.1481e-01, time/batch = 0.6917s	
2082/33800 (epoch 3.080), train_loss = 1.76232015, grad/param norm = 2.1011e-01, time/batch = 0.6949s	
2083/33800 (epoch 3.081), train_loss = 1.70450856, grad/param norm = 1.8100e-01, time/batch = 0.7007s	
2084/33800 (epoch 3.083), train_loss = 1.80624787, grad/param norm = 1.8793e-01, time/batch = 0.6897s	
2085/33800 (epoch 3.084), train_loss = 1.90226115, grad/param norm = 1.8268e-01, time/batch = 0.6890s	
2086/33800 (epoch 3.086), train_loss = 1.70011198, grad/param norm = 1.9705e-01, time/batch = 0.7043s	
2087/33800 (epoch 3.087), train_loss = 1.97525897, grad/param norm = 1.9622e-01, time/batch = 0.6943s	
2088/33800 (epoch 3.089), train_loss = 1.91565482, grad/param norm = 1.9380e-01, time/batch = 0.6919s	
2089/33800 (epoch 3.090), train_loss = 1.88911342, grad/param norm = 1.8896e-01, time/batch = 0.6894s	
2090/33800 (epoch 3.092), train_loss = 1.93358142, grad/param norm = 1.8961e-01, time/batch = 0.6898s	
2091/33800 (epoch 3.093), train_loss = 1.85766223, grad/param norm = 1.9203e-01, time/batch = 0.6952s	
2092/33800 (epoch 3.095), train_loss = 1.90273723, grad/param norm = 2.0183e-01, time/batch = 0.6974s	
2093/33800 (epoch 3.096), train_loss = 1.84364589, grad/param norm = 2.2464e-01, time/batch = 0.6896s	
2094/33800 (epoch 3.098), train_loss = 1.95270812, grad/param norm = 2.0616e-01, time/batch = 0.6881s	
2095/33800 (epoch 3.099), train_loss = 1.89420834, grad/param norm = 1.8601e-01, time/batch = 0.6988s	
2096/33800 (epoch 3.101), train_loss = 1.67204774, grad/param norm = 1.7705e-01, time/batch = 0.7082s	
2097/33800 (epoch 3.102), train_loss = 2.00200789, grad/param norm = 2.2468e-01, time/batch = 0.6991s	
2098/33800 (epoch 3.104), train_loss = 1.89591100, grad/param norm = 2.1040e-01, time/batch = 0.6977s	
2099/33800 (epoch 3.105), train_loss = 1.82302579, grad/param norm = 1.8380e-01, time/batch = 0.6893s	
2100/33800 (epoch 3.107), train_loss = 1.81744102, grad/param norm = 1.8785e-01, time/batch = 0.6863s	
2101/33800 (epoch 3.108), train_loss = 1.72276716, grad/param norm = 1.8550e-01, time/batch = 0.7016s	
2102/33800 (epoch 3.109), train_loss = 1.78347460, grad/param norm = 1.8738e-01, time/batch = 0.6981s	
2103/33800 (epoch 3.111), train_loss = 1.81444653, grad/param norm = 2.0543e-01, time/batch = 0.6918s	
2104/33800 (epoch 3.112), train_loss = 1.79912519, grad/param norm = 1.7708e-01, time/batch = 0.6947s	
2105/33800 (epoch 3.114), train_loss = 1.93689300, grad/param norm = 2.0184e-01, time/batch = 0.6944s	
2106/33800 (epoch 3.115), train_loss = 1.71635313, grad/param norm = 1.6996e-01, time/batch = 0.6984s	
2107/33800 (epoch 3.117), train_loss = 1.88113997, grad/param norm = 1.9017e-01, time/batch = 0.6938s	
2108/33800 (epoch 3.118), train_loss = 1.81515754, grad/param norm = 1.9639e-01, time/batch = 0.6895s	
2109/33800 (epoch 3.120), train_loss = 1.87273036, grad/param norm = 2.1432e-01, time/batch = 0.6902s	
2110/33800 (epoch 3.121), train_loss = 1.93358166, grad/param norm = 1.9855e-01, time/batch = 0.6917s	
2111/33800 (epoch 3.123), train_loss = 1.88082960, grad/param norm = 2.0824e-01, time/batch = 0.6957s	
2112/33800 (epoch 3.124), train_loss = 1.81463269, grad/param norm = 1.8316e-01, time/batch = 0.6881s	
2113/33800 (epoch 3.126), train_loss = 1.86507028, grad/param norm = 1.9556e-01, time/batch = 0.6898s	
2114/33800 (epoch 3.127), train_loss = 1.85657591, grad/param norm = 1.8718e-01, time/batch = 0.6913s	
2115/33800 (epoch 3.129), train_loss = 1.78986057, grad/param norm = 1.7839e-01, time/batch = 0.6918s	
2116/33800 (epoch 3.130), train_loss = 1.80680752, grad/param norm = 1.9046e-01, time/batch = 0.6868s	
2117/33800 (epoch 3.132), train_loss = 2.04934339, grad/param norm = 2.0037e-01, time/batch = 0.6896s	
2118/33800 (epoch 3.133), train_loss = 1.79987108, grad/param norm = 1.8358e-01, time/batch = 0.7003s	
2119/33800 (epoch 3.135), train_loss = 1.79779556, grad/param norm = 2.0831e-01, time/batch = 0.7102s	
2120/33800 (epoch 3.136), train_loss = 1.76096909, grad/param norm = 1.7738e-01, time/batch = 0.7265s	
2121/33800 (epoch 3.138), train_loss = 1.88901516, grad/param norm = 1.7264e-01, time/batch = 0.7385s	
2122/33800 (epoch 3.139), train_loss = 1.78704969, grad/param norm = 1.7564e-01, time/batch = 0.7134s	
2123/33800 (epoch 3.141), train_loss = 1.78329269, grad/param norm = 1.8072e-01, time/batch = 0.7149s	
2124/33800 (epoch 3.142), train_loss = 1.97149102, grad/param norm = 1.7985e-01, time/batch = 0.7289s	
2125/33800 (epoch 3.143), train_loss = 1.88588520, grad/param norm = 1.8142e-01, time/batch = 0.7103s	
2126/33800 (epoch 3.145), train_loss = 1.78464215, grad/param norm = 1.8099e-01, time/batch = 0.6998s	
2127/33800 (epoch 3.146), train_loss = 1.84694651, grad/param norm = 2.3141e-01, time/batch = 0.6978s	
2128/33800 (epoch 3.148), train_loss = 1.70872780, grad/param norm = 2.0299e-01, time/batch = 0.6994s	
2129/33800 (epoch 3.149), train_loss = 1.81495239, grad/param norm = 1.8526e-01, time/batch = 0.6967s	
2130/33800 (epoch 3.151), train_loss = 1.67353006, grad/param norm = 1.6377e-01, time/batch = 0.6953s	
2131/33800 (epoch 3.152), train_loss = 1.96951420, grad/param norm = 1.8387e-01, time/batch = 0.6945s	
2132/33800 (epoch 3.154), train_loss = 1.87321618, grad/param norm = 2.0683e-01, time/batch = 0.6977s	
2133/33800 (epoch 3.155), train_loss = 1.83473947, grad/param norm = 1.8490e-01, time/batch = 0.6957s	
2134/33800 (epoch 3.157), train_loss = 1.75592130, grad/param norm = 1.9215e-01, time/batch = 0.6942s	
2135/33800 (epoch 3.158), train_loss = 1.84725629, grad/param norm = 1.9855e-01, time/batch = 0.6983s	
2136/33800 (epoch 3.160), train_loss = 1.74404498, grad/param norm = 1.9132e-01, time/batch = 0.6970s	
2137/33800 (epoch 3.161), train_loss = 1.86456013, grad/param norm = 1.8777e-01, time/batch = 0.6954s	
2138/33800 (epoch 3.163), train_loss = 1.85299573, grad/param norm = 1.9156e-01, time/batch = 0.6948s	
2139/33800 (epoch 3.164), train_loss = 1.86472872, grad/param norm = 2.0587e-01, time/batch = 0.6980s	
2140/33800 (epoch 3.166), train_loss = 1.78404040, grad/param norm = 2.1217e-01, time/batch = 0.6893s	
2141/33800 (epoch 3.167), train_loss = 1.97305097, grad/param norm = 1.8022e-01, time/batch = 0.6938s	
2142/33800 (epoch 3.169), train_loss = 1.89560912, grad/param norm = 1.9727e-01, time/batch = 0.6951s	
2143/33800 (epoch 3.170), train_loss = 1.76914901, grad/param norm = 1.8083e-01, time/batch = 0.7451s	
2144/33800 (epoch 3.172), train_loss = 1.92832709, grad/param norm = 1.8733e-01, time/batch = 0.7198s	
2145/33800 (epoch 3.173), train_loss = 1.76251235, grad/param norm = 1.8411e-01, time/batch = 0.7130s	
2146/33800 (epoch 3.175), train_loss = 1.94191773, grad/param norm = 1.9162e-01, time/batch = 0.7137s	
2147/33800 (epoch 3.176), train_loss = 1.71075711, grad/param norm = 1.7829e-01, time/batch = 0.7502s	
2148/33800 (epoch 3.178), train_loss = 1.91517656, grad/param norm = 1.7328e-01, time/batch = 0.7160s	
2149/33800 (epoch 3.179), train_loss = 1.84794943, grad/param norm = 1.7525e-01, time/batch = 0.7123s	
2150/33800 (epoch 3.180), train_loss = 1.85199571, grad/param norm = 1.9122e-01, time/batch = 0.7023s	
2151/33800 (epoch 3.182), train_loss = 2.02783609, grad/param norm = 1.9636e-01, time/batch = 0.7042s	
2152/33800 (epoch 3.183), train_loss = 2.01918996, grad/param norm = 1.9026e-01, time/batch = 0.7001s	
2153/33800 (epoch 3.185), train_loss = 1.98607928, grad/param norm = 1.9359e-01, time/batch = 0.7011s	
2154/33800 (epoch 3.186), train_loss = 1.88266873, grad/param norm = 1.9959e-01, time/batch = 0.6961s	
2155/33800 (epoch 3.188), train_loss = 1.92407709, grad/param norm = 2.0449e-01, time/batch = 0.6919s	
2156/33800 (epoch 3.189), train_loss = 1.93052715, grad/param norm = 2.1017e-01, time/batch = 0.6935s	
2157/33800 (epoch 3.191), train_loss = 1.93282674, grad/param norm = 2.3436e-01, time/batch = 0.6933s	
2158/33800 (epoch 3.192), train_loss = 1.84445332, grad/param norm = 1.9500e-01, time/batch = 0.6941s	
2159/33800 (epoch 3.194), train_loss = 1.86651891, grad/param norm = 1.8243e-01, time/batch = 0.7035s	
2160/33800 (epoch 3.195), train_loss = 1.64566436, grad/param norm = 1.8655e-01, time/batch = 0.6935s	
2161/33800 (epoch 3.197), train_loss = 1.62680602, grad/param norm = 1.6577e-01, time/batch = 0.6996s	
2162/33800 (epoch 3.198), train_loss = 1.81457907, grad/param norm = 1.8368e-01, time/batch = 0.6964s	
2163/33800 (epoch 3.200), train_loss = 1.85508061, grad/param norm = 1.9900e-01, time/batch = 0.7126s	
2164/33800 (epoch 3.201), train_loss = 1.95982258, grad/param norm = 2.2316e-01, time/batch = 0.7066s	
2165/33800 (epoch 3.203), train_loss = 1.83058056, grad/param norm = 1.8090e-01, time/batch = 0.6882s	
2166/33800 (epoch 3.204), train_loss = 1.79653188, grad/param norm = 2.0353e-01, time/batch = 0.6873s	
2167/33800 (epoch 3.206), train_loss = 1.69714621, grad/param norm = 1.8124e-01, time/batch = 0.6980s	
2168/33800 (epoch 3.207), train_loss = 1.94175746, grad/param norm = 1.8747e-01, time/batch = 0.6882s	
2169/33800 (epoch 3.209), train_loss = 1.77229431, grad/param norm = 2.1605e-01, time/batch = 0.6905s	
2170/33800 (epoch 3.210), train_loss = 1.83248663, grad/param norm = 1.9761e-01, time/batch = 0.6907s	
2171/33800 (epoch 3.212), train_loss = 1.95446129, grad/param norm = 1.8204e-01, time/batch = 0.7010s	
2172/33800 (epoch 3.213), train_loss = 2.00349408, grad/param norm = 2.1199e-01, time/batch = 0.7141s	
2173/33800 (epoch 3.214), train_loss = 1.88553849, grad/param norm = 2.1807e-01, time/batch = 0.7078s	
2174/33800 (epoch 3.216), train_loss = 1.70759629, grad/param norm = 1.8765e-01, time/batch = 0.7564s	
2175/33800 (epoch 3.217), train_loss = 1.85125763, grad/param norm = 1.9434e-01, time/batch = 0.7650s	
2176/33800 (epoch 3.219), train_loss = 1.81911086, grad/param norm = 1.8509e-01, time/batch = 0.7385s	
2177/33800 (epoch 3.220), train_loss = 1.95143818, grad/param norm = 2.0968e-01, time/batch = 0.7576s	
2178/33800 (epoch 3.222), train_loss = 1.88005752, grad/param norm = 1.9604e-01, time/batch = 0.7330s	
2179/33800 (epoch 3.223), train_loss = 1.79007853, grad/param norm = 1.9537e-01, time/batch = 0.6980s	
2180/33800 (epoch 3.225), train_loss = 1.90120542, grad/param norm = 2.0267e-01, time/batch = 0.7026s	
2181/33800 (epoch 3.226), train_loss = 1.92840453, grad/param norm = 2.3111e-01, time/batch = 0.7517s	
2182/33800 (epoch 3.228), train_loss = 1.87293734, grad/param norm = 2.2172e-01, time/batch = 0.7290s	
2183/33800 (epoch 3.229), train_loss = 1.83845299, grad/param norm = 2.3885e-01, time/batch = 0.6980s	
2184/33800 (epoch 3.231), train_loss = 1.96337033, grad/param norm = 2.0268e-01, time/batch = 0.6966s	
2185/33800 (epoch 3.232), train_loss = 1.79990852, grad/param norm = 2.0360e-01, time/batch = 0.7114s	
2186/33800 (epoch 3.234), train_loss = 1.93129641, grad/param norm = 1.8499e-01, time/batch = 0.7165s	
2187/33800 (epoch 3.235), train_loss = 1.81603991, grad/param norm = 1.8577e-01, time/batch = 0.7150s	
2188/33800 (epoch 3.237), train_loss = 1.82078616, grad/param norm = 1.9797e-01, time/batch = 0.7110s	
2189/33800 (epoch 3.238), train_loss = 1.96782206, grad/param norm = 1.8515e-01, time/batch = 0.7028s	
2190/33800 (epoch 3.240), train_loss = 1.80035640, grad/param norm = 1.7846e-01, time/batch = 0.6894s	
2191/33800 (epoch 3.241), train_loss = 1.79620860, grad/param norm = 2.0102e-01, time/batch = 0.6962s	
2192/33800 (epoch 3.243), train_loss = 1.78609857, grad/param norm = 2.0203e-01, time/batch = 0.7073s	
2193/33800 (epoch 3.244), train_loss = 1.85358263, grad/param norm = 2.2184e-01, time/batch = 0.6979s	
2194/33800 (epoch 3.246), train_loss = 1.87732326, grad/param norm = 2.0435e-01, time/batch = 0.6950s	
2195/33800 (epoch 3.247), train_loss = 1.75005377, grad/param norm = 2.0000e-01, time/batch = 0.6941s	
2196/33800 (epoch 3.249), train_loss = 1.88212671, grad/param norm = 1.9374e-01, time/batch = 0.6988s	
2197/33800 (epoch 3.250), train_loss = 1.91918356, grad/param norm = 2.0840e-01, time/batch = 0.6886s	
2198/33800 (epoch 3.251), train_loss = 2.21944562, grad/param norm = 2.3234e-01, time/batch = 0.6884s	
2199/33800 (epoch 3.253), train_loss = 1.90780127, grad/param norm = 2.4363e-01, time/batch = 0.6851s	
2200/33800 (epoch 3.254), train_loss = 1.98978926, grad/param norm = 2.3690e-01, time/batch = 0.6814s	
2201/33800 (epoch 3.256), train_loss = 1.79540063, grad/param norm = 1.9170e-01, time/batch = 0.6874s	
2202/33800 (epoch 3.257), train_loss = 1.89413823, grad/param norm = 1.7730e-01, time/batch = 0.6880s	
2203/33800 (epoch 3.259), train_loss = 1.82197524, grad/param norm = 1.7475e-01, time/batch = 0.7098s	
2204/33800 (epoch 3.260), train_loss = 1.81925870, grad/param norm = 1.8407e-01, time/batch = 0.7127s	
2205/33800 (epoch 3.262), train_loss = 1.82465641, grad/param norm = 1.9355e-01, time/batch = 0.7140s	
2206/33800 (epoch 3.263), train_loss = 1.93561681, grad/param norm = 1.9810e-01, time/batch = 0.7043s	
2207/33800 (epoch 3.265), train_loss = 1.97296739, grad/param norm = 1.8665e-01, time/batch = 0.6976s	
2208/33800 (epoch 3.266), train_loss = 1.75827887, grad/param norm = 1.8084e-01, time/batch = 0.6954s	
2209/33800 (epoch 3.268), train_loss = 1.88997047, grad/param norm = 1.7667e-01, time/batch = 0.6960s	
2210/33800 (epoch 3.269), train_loss = 1.83999352, grad/param norm = 1.8723e-01, time/batch = 0.6997s	
2211/33800 (epoch 3.271), train_loss = 1.88462496, grad/param norm = 1.9250e-01, time/batch = 0.7009s	
2212/33800 (epoch 3.272), train_loss = 1.90421969, grad/param norm = 1.9442e-01, time/batch = 0.7305s	
2213/33800 (epoch 3.274), train_loss = 1.98485021, grad/param norm = 2.0309e-01, time/batch = 0.7234s	
2214/33800 (epoch 3.275), train_loss = 1.72933735, grad/param norm = 1.9272e-01, time/batch = 0.7160s	
2215/33800 (epoch 3.277), train_loss = 1.74389204, grad/param norm = 1.7513e-01, time/batch = 0.6913s	
2216/33800 (epoch 3.278), train_loss = 1.78982923, grad/param norm = 1.8193e-01, time/batch = 0.6921s	
2217/33800 (epoch 3.280), train_loss = 1.66263061, grad/param norm = 1.6784e-01, time/batch = 0.6953s	
2218/33800 (epoch 3.281), train_loss = 1.81810551, grad/param norm = 1.8113e-01, time/batch = 0.6956s	
2219/33800 (epoch 3.283), train_loss = 1.81509819, grad/param norm = 1.8382e-01, time/batch = 0.6857s	
2220/33800 (epoch 3.284), train_loss = 1.94313313, grad/param norm = 1.8134e-01, time/batch = 0.6879s	
2221/33800 (epoch 3.286), train_loss = 1.91599249, grad/param norm = 1.8434e-01, time/batch = 0.6885s	
2222/33800 (epoch 3.287), train_loss = 1.75463554, grad/param norm = 1.8514e-01, time/batch = 0.6849s	
2223/33800 (epoch 3.288), train_loss = 1.71604001, grad/param norm = 1.9148e-01, time/batch = 0.6885s	
2224/33800 (epoch 3.290), train_loss = 1.76728142, grad/param norm = 2.2777e-01, time/batch = 0.7008s	
2225/33800 (epoch 3.291), train_loss = 1.80149680, grad/param norm = 2.2800e-01, time/batch = 0.6873s	
2226/33800 (epoch 3.293), train_loss = 1.83827051, grad/param norm = 1.8221e-01, time/batch = 0.6849s	
2227/33800 (epoch 3.294), train_loss = 2.14943929, grad/param norm = 2.0709e-01, time/batch = 0.6939s	
2228/33800 (epoch 3.296), train_loss = 1.86123047, grad/param norm = 2.2343e-01, time/batch = 0.7008s	
2229/33800 (epoch 3.297), train_loss = 1.81830225, grad/param norm = 1.7924e-01, time/batch = 0.6997s	
2230/33800 (epoch 3.299), train_loss = 1.77397821, grad/param norm = 1.9263e-01, time/batch = 0.6890s	
2231/33800 (epoch 3.300), train_loss = 1.78093530, grad/param norm = 1.7253e-01, time/batch = 0.6909s	
2232/33800 (epoch 3.302), train_loss = 1.97100291, grad/param norm = 1.7831e-01, time/batch = 0.6919s	
2233/33800 (epoch 3.303), train_loss = 1.86802771, grad/param norm = 1.7967e-01, time/batch = 0.6935s	
2234/33800 (epoch 3.305), train_loss = 1.86321945, grad/param norm = 1.8452e-01, time/batch = 0.6917s	
2235/33800 (epoch 3.306), train_loss = 1.76995085, grad/param norm = 1.7561e-01, time/batch = 0.6993s	
2236/33800 (epoch 3.308), train_loss = 1.89031094, grad/param norm = 1.9436e-01, time/batch = 0.7014s	
2237/33800 (epoch 3.309), train_loss = 1.83764420, grad/param norm = 1.7627e-01, time/batch = 0.7009s	
2238/33800 (epoch 3.311), train_loss = 1.73120696, grad/param norm = 1.6528e-01, time/batch = 0.6986s	
2239/33800 (epoch 3.312), train_loss = 1.78988963, grad/param norm = 1.8791e-01, time/batch = 0.6930s	
2240/33800 (epoch 3.314), train_loss = 1.82636543, grad/param norm = 1.7598e-01, time/batch = 0.6846s	
2241/33800 (epoch 3.315), train_loss = 2.01074324, grad/param norm = 1.8099e-01, time/batch = 0.6933s	
2242/33800 (epoch 3.317), train_loss = 1.83942442, grad/param norm = 1.9782e-01, time/batch = 0.7015s	
2243/33800 (epoch 3.318), train_loss = 1.86648575, grad/param norm = 1.9122e-01, time/batch = 0.7010s	
2244/33800 (epoch 3.320), train_loss = 2.02447534, grad/param norm = 2.2073e-01, time/batch = 0.7010s	
2245/33800 (epoch 3.321), train_loss = 1.89085529, grad/param norm = 1.8894e-01, time/batch = 0.6862s	
2246/33800 (epoch 3.322), train_loss = 1.69779820, grad/param norm = 1.7887e-01, time/batch = 0.6798s	
2247/33800 (epoch 3.324), train_loss = 1.76107567, grad/param norm = 1.7733e-01, time/batch = 0.6769s	
2248/33800 (epoch 3.325), train_loss = 1.80985806, grad/param norm = 2.0287e-01, time/batch = 0.6751s	
2249/33800 (epoch 3.327), train_loss = 1.83451940, grad/param norm = 1.8268e-01, time/batch = 0.6795s	
2250/33800 (epoch 3.328), train_loss = 1.74075490, grad/param norm = 1.6079e-01, time/batch = 0.6745s	
2251/33800 (epoch 3.330), train_loss = 1.74259580, grad/param norm = 1.8068e-01, time/batch = 0.6724s	
2252/33800 (epoch 3.331), train_loss = 1.83680788, grad/param norm = 1.7685e-01, time/batch = 0.6756s	
2253/33800 (epoch 3.333), train_loss = 1.87238812, grad/param norm = 1.9607e-01, time/batch = 0.6922s	
2254/33800 (epoch 3.334), train_loss = 1.76905522, grad/param norm = 1.6713e-01, time/batch = 0.6977s	
2255/33800 (epoch 3.336), train_loss = 1.69278875, grad/param norm = 1.8283e-01, time/batch = 0.6868s	
2256/33800 (epoch 3.337), train_loss = 1.79699408, grad/param norm = 1.9170e-01, time/batch = 0.6935s	
2257/33800 (epoch 3.339), train_loss = 1.79615364, grad/param norm = 2.0040e-01, time/batch = 0.6905s	
2258/33800 (epoch 3.340), train_loss = 1.92830450, grad/param norm = 1.9286e-01, time/batch = 0.6848s	
2259/33800 (epoch 3.342), train_loss = 2.06222354, grad/param norm = 1.9143e-01, time/batch = 0.6846s	
2260/33800 (epoch 3.343), train_loss = 1.79158394, grad/param norm = 1.7737e-01, time/batch = 0.6929s	
2261/33800 (epoch 3.345), train_loss = 1.92675852, grad/param norm = 1.7532e-01, time/batch = 0.6872s	
2262/33800 (epoch 3.346), train_loss = 2.15786064, grad/param norm = 1.8640e-01, time/batch = 0.6935s	
2263/33800 (epoch 3.348), train_loss = 1.97300943, grad/param norm = 1.9752e-01, time/batch = 0.6869s	
2264/33800 (epoch 3.349), train_loss = 1.85530798, grad/param norm = 2.0147e-01, time/batch = 0.6798s	
2265/33800 (epoch 3.351), train_loss = 1.79136888, grad/param norm = 1.7955e-01, time/batch = 0.6780s	
2266/33800 (epoch 3.352), train_loss = 1.99927801, grad/param norm = 2.0214e-01, time/batch = 0.6740s	
2267/33800 (epoch 3.354), train_loss = 1.80561962, grad/param norm = 1.8735e-01, time/batch = 0.6833s	
2268/33800 (epoch 3.355), train_loss = 1.64012539, grad/param norm = 1.6054e-01, time/batch = 0.6778s	
2269/33800 (epoch 3.357), train_loss = 1.74596038, grad/param norm = 1.9128e-01, time/batch = 0.6728s	
2270/33800 (epoch 3.358), train_loss = 1.88660035, grad/param norm = 1.9179e-01, time/batch = 0.6869s	
2271/33800 (epoch 3.359), train_loss = 1.77069615, grad/param norm = 1.8676e-01, time/batch = 0.6771s	
2272/33800 (epoch 3.361), train_loss = 1.90667664, grad/param norm = 1.8803e-01, time/batch = 0.6746s	
2273/33800 (epoch 3.362), train_loss = 1.93698863, grad/param norm = 1.6682e-01, time/batch = 0.6771s	
2274/33800 (epoch 3.364), train_loss = 1.97680633, grad/param norm = 1.9109e-01, time/batch = 0.6826s	
2275/33800 (epoch 3.365), train_loss = 1.86802267, grad/param norm = 1.9486e-01, time/batch = 0.6805s	
2276/33800 (epoch 3.367), train_loss = 1.78147232, grad/param norm = 2.1374e-01, time/batch = 0.6748s	
2277/33800 (epoch 3.368), train_loss = 1.80760832, grad/param norm = 1.8140e-01, time/batch = 0.6724s	
2278/33800 (epoch 3.370), train_loss = 1.87156869, grad/param norm = 1.7723e-01, time/batch = 0.6758s	
2279/33800 (epoch 3.371), train_loss = 1.85433671, grad/param norm = 1.8752e-01, time/batch = 0.6783s	
2280/33800 (epoch 3.373), train_loss = 2.06794288, grad/param norm = 2.2704e-01, time/batch = 0.6863s	
2281/33800 (epoch 3.374), train_loss = 1.69759540, grad/param norm = 1.6880e-01, time/batch = 0.6808s	
2282/33800 (epoch 3.376), train_loss = 1.73774808, grad/param norm = 1.8463e-01, time/batch = 0.6826s	
2283/33800 (epoch 3.377), train_loss = 1.70985180, grad/param norm = 2.0904e-01, time/batch = 0.6802s	
2284/33800 (epoch 3.379), train_loss = 1.87821831, grad/param norm = 1.7580e-01, time/batch = 0.6751s	
2285/33800 (epoch 3.380), train_loss = 1.83370327, grad/param norm = 1.6513e-01, time/batch = 0.6794s	
2286/33800 (epoch 3.382), train_loss = 1.75927947, grad/param norm = 1.7598e-01, time/batch = 0.6833s	
2287/33800 (epoch 3.383), train_loss = 1.95543148, grad/param norm = 1.9423e-01, time/batch = 0.6791s	
2288/33800 (epoch 3.385), train_loss = 1.84830037, grad/param norm = 1.8015e-01, time/batch = 0.6769s	
2289/33800 (epoch 3.386), train_loss = 1.74837976, grad/param norm = 1.7490e-01, time/batch = 0.6819s	
2290/33800 (epoch 3.388), train_loss = 1.94706295, grad/param norm = 1.8557e-01, time/batch = 0.6918s	
2291/33800 (epoch 3.389), train_loss = 1.86697690, grad/param norm = 1.6924e-01, time/batch = 0.7153s	
2292/33800 (epoch 3.391), train_loss = 1.94795945, grad/param norm = 1.7772e-01, time/batch = 0.6834s	
2293/33800 (epoch 3.392), train_loss = 1.81179357, grad/param norm = 1.7555e-01, time/batch = 0.6816s	
2294/33800 (epoch 3.393), train_loss = 1.83774777, grad/param norm = 1.7582e-01, time/batch = 0.6853s	
2295/33800 (epoch 3.395), train_loss = 1.93374258, grad/param norm = 1.8327e-01, time/batch = 0.6799s	
2296/33800 (epoch 3.396), train_loss = 1.88425959, grad/param norm = 2.2635e-01, time/batch = 0.6886s	
2297/33800 (epoch 3.398), train_loss = 1.77785466, grad/param norm = 2.0189e-01, time/batch = 0.6865s	
2298/33800 (epoch 3.399), train_loss = 1.93692949, grad/param norm = 1.9255e-01, time/batch = 0.6903s	
2299/33800 (epoch 3.401), train_loss = 1.82169519, grad/param norm = 1.7522e-01, time/batch = 0.7155s	
2300/33800 (epoch 3.402), train_loss = 1.85055428, grad/param norm = 1.6357e-01, time/batch = 0.6969s	
2301/33800 (epoch 3.404), train_loss = 1.73608184, grad/param norm = 1.7711e-01, time/batch = 0.6846s	
2302/33800 (epoch 3.405), train_loss = 2.00056756, grad/param norm = 1.8944e-01, time/batch = 0.6788s	
2303/33800 (epoch 3.407), train_loss = 1.83659168, grad/param norm = 1.8092e-01, time/batch = 0.6758s	
2304/33800 (epoch 3.408), train_loss = 1.85940083, grad/param norm = 1.8351e-01, time/batch = 0.6798s	
2305/33800 (epoch 3.410), train_loss = 1.98125285, grad/param norm = 1.8731e-01, time/batch = 0.6788s	
2306/33800 (epoch 3.411), train_loss = 1.80188521, grad/param norm = 1.7771e-01, time/batch = 0.6763s	
2307/33800 (epoch 3.413), train_loss = 1.85731291, grad/param norm = 1.7964e-01, time/batch = 0.6714s	
2308/33800 (epoch 3.414), train_loss = 1.73805101, grad/param norm = 1.7230e-01, time/batch = 0.6745s	
2309/33800 (epoch 3.416), train_loss = 1.80366859, grad/param norm = 1.8427e-01, time/batch = 0.6730s	
2310/33800 (epoch 3.417), train_loss = 1.72446417, grad/param norm = 1.7869e-01, time/batch = 0.6713s	
2311/33800 (epoch 3.419), train_loss = 1.90628616, grad/param norm = 1.6481e-01, time/batch = 0.6900s	
2312/33800 (epoch 3.420), train_loss = 1.82296665, grad/param norm = 1.8193e-01, time/batch = 0.6878s	
2313/33800 (epoch 3.422), train_loss = 1.83470304, grad/param norm = 2.0730e-01, time/batch = 0.6865s	
2314/33800 (epoch 3.423), train_loss = 1.82392730, grad/param norm = 1.9858e-01, time/batch = 0.6852s	
2315/33800 (epoch 3.425), train_loss = 1.84223032, grad/param norm = 2.0105e-01, time/batch = 0.6708s	
2316/33800 (epoch 3.426), train_loss = 1.73684565, grad/param norm = 1.9464e-01, time/batch = 0.6730s	
2317/33800 (epoch 3.428), train_loss = 1.97109971, grad/param norm = 2.1474e-01, time/batch = 0.6794s	
2318/33800 (epoch 3.429), train_loss = 1.68727926, grad/param norm = 2.0552e-01, time/batch = 0.6815s	
2319/33800 (epoch 3.430), train_loss = 1.84713755, grad/param norm = 1.8755e-01, time/batch = 0.6782s	
2320/33800 (epoch 3.432), train_loss = 1.82853173, grad/param norm = 1.7052e-01, time/batch = 0.6767s	
2321/33800 (epoch 3.433), train_loss = 1.86298848, grad/param norm = 1.8006e-01, time/batch = 0.6898s	
2322/33800 (epoch 3.435), train_loss = 1.95203338, grad/param norm = 1.9206e-01, time/batch = 0.6771s	
2323/33800 (epoch 3.436), train_loss = 1.82220057, grad/param norm = 1.8690e-01, time/batch = 0.6804s	
2324/33800 (epoch 3.438), train_loss = 1.71985843, grad/param norm = 1.6829e-01, time/batch = 0.6758s	
2325/33800 (epoch 3.439), train_loss = 1.85534232, grad/param norm = 1.9566e-01, time/batch = 0.6796s	
2326/33800 (epoch 3.441), train_loss = 1.79821366, grad/param norm = 1.8740e-01, time/batch = 0.6747s	
2327/33800 (epoch 3.442), train_loss = 1.87165971, grad/param norm = 1.8424e-01, time/batch = 0.6745s	
2328/33800 (epoch 3.444), train_loss = 1.83673014, grad/param norm = 1.6929e-01, time/batch = 0.6739s	
2329/33800 (epoch 3.445), train_loss = 1.81069229, grad/param norm = 1.6995e-01, time/batch = 0.6830s	
2330/33800 (epoch 3.447), train_loss = 1.68807787, grad/param norm = 1.8579e-01, time/batch = 0.6938s	
2331/33800 (epoch 3.448), train_loss = 1.88789723, grad/param norm = 1.7303e-01, time/batch = 0.6843s	
2332/33800 (epoch 3.450), train_loss = 1.78668894, grad/param norm = 1.7658e-01, time/batch = 0.6746s	
2333/33800 (epoch 3.451), train_loss = 1.76325591, grad/param norm = 1.9134e-01, time/batch = 0.6839s	
2334/33800 (epoch 3.453), train_loss = 1.88009222, grad/param norm = 1.8895e-01, time/batch = 0.6795s	
2335/33800 (epoch 3.454), train_loss = 1.88335261, grad/param norm = 1.8501e-01, time/batch = 0.6866s	
2336/33800 (epoch 3.456), train_loss = 1.82037431, grad/param norm = 1.7850e-01, time/batch = 0.6732s	
2337/33800 (epoch 3.457), train_loss = 1.74003645, grad/param norm = 1.6699e-01, time/batch = 0.6755s	
2338/33800 (epoch 3.459), train_loss = 1.79896395, grad/param norm = 1.6945e-01, time/batch = 0.6711s	
2339/33800 (epoch 3.460), train_loss = 1.77860261, grad/param norm = 1.9041e-01, time/batch = 0.6707s	
2340/33800 (epoch 3.462), train_loss = 1.84511671, grad/param norm = 1.7540e-01, time/batch = 0.7008s	
2341/33800 (epoch 3.463), train_loss = 1.71012766, grad/param norm = 1.5757e-01, time/batch = 0.6864s	
2342/33800 (epoch 3.464), train_loss = 1.89128520, grad/param norm = 1.9358e-01, time/batch = 0.6868s	
2343/33800 (epoch 3.466), train_loss = 1.71225216, grad/param norm = 1.7662e-01, time/batch = 0.6847s	
2344/33800 (epoch 3.467), train_loss = 1.78783938, grad/param norm = 1.8233e-01, time/batch = 0.6882s	
2345/33800 (epoch 3.469), train_loss = 1.70814451, grad/param norm = 1.6595e-01, time/batch = 0.6898s	
2346/33800 (epoch 3.470), train_loss = 1.76116977, grad/param norm = 1.8979e-01, time/batch = 0.6840s	
2347/33800 (epoch 3.472), train_loss = 1.73604118, grad/param norm = 2.1321e-01, time/batch = 0.6865s	
2348/33800 (epoch 3.473), train_loss = 1.80142328, grad/param norm = 2.0526e-01, time/batch = 0.6786s	
2349/33800 (epoch 3.475), train_loss = 1.75676441, grad/param norm = 1.7869e-01, time/batch = 0.6779s	
2350/33800 (epoch 3.476), train_loss = 1.80723149, grad/param norm = 1.6566e-01, time/batch = 0.6723s	
2351/33800 (epoch 3.478), train_loss = 1.73755820, grad/param norm = 1.8053e-01, time/batch = 0.6754s	
2352/33800 (epoch 3.479), train_loss = 1.84491074, grad/param norm = 1.8578e-01, time/batch = 0.6773s	
2353/33800 (epoch 3.481), train_loss = 1.77125771, grad/param norm = 1.7593e-01, time/batch = 0.6758s	
2354/33800 (epoch 3.482), train_loss = 1.94796152, grad/param norm = 2.2361e-01, time/batch = 0.6762s	
2355/33800 (epoch 3.484), train_loss = 1.78592835, grad/param norm = 1.7200e-01, time/batch = 0.6797s	
2356/33800 (epoch 3.485), train_loss = 1.76642321, grad/param norm = 2.0693e-01, time/batch = 0.6739s	
2357/33800 (epoch 3.487), train_loss = 1.74009733, grad/param norm = 1.7979e-01, time/batch = 0.6726s	
2358/33800 (epoch 3.488), train_loss = 1.74380604, grad/param norm = 1.7679e-01, time/batch = 0.6747s	
2359/33800 (epoch 3.490), train_loss = 1.85027871, grad/param norm = 1.8431e-01, time/batch = 0.6731s	
2360/33800 (epoch 3.491), train_loss = 1.70093927, grad/param norm = 1.8320e-01, time/batch = 0.6712s	
2361/33800 (epoch 3.493), train_loss = 1.85203387, grad/param norm = 2.0150e-01, time/batch = 0.6808s	
2362/33800 (epoch 3.494), train_loss = 1.91196402, grad/param norm = 1.9901e-01, time/batch = 0.6756s	
2363/33800 (epoch 3.496), train_loss = 1.81081102, grad/param norm = 1.8062e-01, time/batch = 0.6742s	
2364/33800 (epoch 3.497), train_loss = 1.81882077, grad/param norm = 1.7380e-01, time/batch = 0.6781s	
2365/33800 (epoch 3.499), train_loss = 1.73401846, grad/param norm = 1.9201e-01, time/batch = 0.6748s	
2366/33800 (epoch 3.500), train_loss = 1.93087570, grad/param norm = 2.1212e-01, time/batch = 0.6787s	
2367/33800 (epoch 3.501), train_loss = 1.76237507, grad/param norm = 1.7095e-01, time/batch = 0.6877s	
2368/33800 (epoch 3.503), train_loss = 1.89170179, grad/param norm = 1.8217e-01, time/batch = 0.6938s	
2369/33800 (epoch 3.504), train_loss = 1.70710366, grad/param norm = 1.7249e-01, time/batch = 0.6864s	
2370/33800 (epoch 3.506), train_loss = 1.87931969, grad/param norm = 2.0008e-01, time/batch = 0.6868s	
2371/33800 (epoch 3.507), train_loss = 1.74329445, grad/param norm = 1.6339e-01, time/batch = 0.6907s	
2372/33800 (epoch 3.509), train_loss = 1.83472491, grad/param norm = 1.7553e-01, time/batch = 0.6879s	
2373/33800 (epoch 3.510), train_loss = 1.72051326, grad/param norm = 1.8100e-01, time/batch = 0.6884s	
2374/33800 (epoch 3.512), train_loss = 1.74594473, grad/param norm = 2.0641e-01, time/batch = 0.6898s	
2375/33800 (epoch 3.513), train_loss = 1.90531143, grad/param norm = 1.8811e-01, time/batch = 0.6794s	
2376/33800 (epoch 3.515), train_loss = 1.86772765, grad/param norm = 1.8284e-01, time/batch = 0.6845s	
2377/33800 (epoch 3.516), train_loss = 1.81191520, grad/param norm = 1.7759e-01, time/batch = 0.6958s	
2378/33800 (epoch 3.518), train_loss = 1.83695967, grad/param norm = 1.9521e-01, time/batch = 0.6953s	
2379/33800 (epoch 3.519), train_loss = 1.64673163, grad/param norm = 1.6562e-01, time/batch = 0.6987s	
2380/33800 (epoch 3.521), train_loss = 1.85490679, grad/param norm = 1.8942e-01, time/batch = 0.6913s	
2381/33800 (epoch 3.522), train_loss = 1.63347508, grad/param norm = 1.6447e-01, time/batch = 0.6937s	
2382/33800 (epoch 3.524), train_loss = 1.76166735, grad/param norm = 1.6406e-01, time/batch = 0.6857s	
2383/33800 (epoch 3.525), train_loss = 1.83397437, grad/param norm = 1.7986e-01, time/batch = 0.6894s	
2384/33800 (epoch 3.527), train_loss = 1.71251704, grad/param norm = 1.6780e-01, time/batch = 0.6891s	
2385/33800 (epoch 3.528), train_loss = 1.79930879, grad/param norm = 1.7352e-01, time/batch = 0.6809s	
2386/33800 (epoch 3.530), train_loss = 1.88069952, grad/param norm = 2.1172e-01, time/batch = 0.6831s	
2387/33800 (epoch 3.531), train_loss = 1.86715936, grad/param norm = 1.9950e-01, time/batch = 0.6867s	
2388/33800 (epoch 3.533), train_loss = 1.74004296, grad/param norm = 1.8547e-01, time/batch = 0.6808s	
2389/33800 (epoch 3.534), train_loss = 1.72027438, grad/param norm = 1.6456e-01, time/batch = 0.6770s	
2390/33800 (epoch 3.536), train_loss = 1.96263151, grad/param norm = 1.9003e-01, time/batch = 0.6759s	
2391/33800 (epoch 3.537), train_loss = 1.81861155, grad/param norm = 1.8412e-01, time/batch = 0.6970s	
2392/33800 (epoch 3.538), train_loss = 1.79218773, grad/param norm = 1.7086e-01, time/batch = 0.7142s	
2393/33800 (epoch 3.540), train_loss = 1.64391196, grad/param norm = 1.7254e-01, time/batch = 0.6793s	
2394/33800 (epoch 3.541), train_loss = 1.74922075, grad/param norm = 1.9625e-01, time/batch = 0.6795s	
2395/33800 (epoch 3.543), train_loss = 1.66976940, grad/param norm = 1.6875e-01, time/batch = 0.6811s	
2396/33800 (epoch 3.544), train_loss = 1.87236278, grad/param norm = 1.8869e-01, time/batch = 0.6890s	
2397/33800 (epoch 3.546), train_loss = 2.04591664, grad/param norm = 2.0486e-01, time/batch = 0.6868s	
2398/33800 (epoch 3.547), train_loss = 1.88339068, grad/param norm = 2.0160e-01, time/batch = 0.6804s	
2399/33800 (epoch 3.549), train_loss = 1.82246076, grad/param norm = 2.0936e-01, time/batch = 0.7271s	
2400/33800 (epoch 3.550), train_loss = 1.77850400, grad/param norm = 1.8325e-01, time/batch = 0.7005s	
2401/33800 (epoch 3.552), train_loss = 1.91010504, grad/param norm = 2.1419e-01, time/batch = 0.6948s	
2402/33800 (epoch 3.553), train_loss = 2.01855626, grad/param norm = 1.7933e-01, time/batch = 0.6835s	
2403/33800 (epoch 3.555), train_loss = 1.73515112, grad/param norm = 1.7571e-01, time/batch = 0.6764s	
2404/33800 (epoch 3.556), train_loss = 1.64629738, grad/param norm = 1.7838e-01, time/batch = 0.6809s	
2405/33800 (epoch 3.558), train_loss = 1.64525248, grad/param norm = 1.7965e-01, time/batch = 0.6745s	
2406/33800 (epoch 3.559), train_loss = 1.87327708, grad/param norm = 1.8998e-01, time/batch = 0.6763s	
2407/33800 (epoch 3.561), train_loss = 1.71752715, grad/param norm = 1.7677e-01, time/batch = 0.6766s	
2408/33800 (epoch 3.562), train_loss = 1.81268078, grad/param norm = 1.6939e-01, time/batch = 0.6767s	
2409/33800 (epoch 3.564), train_loss = 1.83549781, grad/param norm = 1.8308e-01, time/batch = 0.6743s	
2410/33800 (epoch 3.565), train_loss = 2.10878147, grad/param norm = 2.2291e-01, time/batch = 0.6720s	
2411/33800 (epoch 3.567), train_loss = 1.90043407, grad/param norm = 1.9285e-01, time/batch = 0.6789s	
2412/33800 (epoch 3.568), train_loss = 1.76471576, grad/param norm = 1.8236e-01, time/batch = 0.6770s	
2413/33800 (epoch 3.570), train_loss = 1.73941315, grad/param norm = 1.9771e-01, time/batch = 0.6722s	
2414/33800 (epoch 3.571), train_loss = 1.74371762, grad/param norm = 2.1243e-01, time/batch = 0.6738s	
2415/33800 (epoch 3.572), train_loss = 1.91122679, grad/param norm = 1.8193e-01, time/batch = 0.6706s	
2416/33800 (epoch 3.574), train_loss = 1.97078184, grad/param norm = 1.8215e-01, time/batch = 0.6696s	
2417/33800 (epoch 3.575), train_loss = 1.66523689, grad/param norm = 1.6003e-01, time/batch = 0.6698s	
2418/33800 (epoch 3.577), train_loss = 1.77777368, grad/param norm = 1.8468e-01, time/batch = 0.6700s	
2419/33800 (epoch 3.578), train_loss = 1.79231310, grad/param norm = 1.8099e-01, time/batch = 0.6695s	
2420/33800 (epoch 3.580), train_loss = 1.80228412, grad/param norm = 1.9341e-01, time/batch = 0.6706s	
2421/33800 (epoch 3.581), train_loss = 1.84562523, grad/param norm = 1.9149e-01, time/batch = 0.6812s	
2422/33800 (epoch 3.583), train_loss = 1.90604871, grad/param norm = 1.7660e-01, time/batch = 0.6705s	
2423/33800 (epoch 3.584), train_loss = 1.76043840, grad/param norm = 1.6720e-01, time/batch = 0.6774s	
2424/33800 (epoch 3.586), train_loss = 1.59887975, grad/param norm = 1.8484e-01, time/batch = 0.6780s	
2425/33800 (epoch 3.587), train_loss = 1.57776060, grad/param norm = 1.6553e-01, time/batch = 0.6710s	
2426/33800 (epoch 3.589), train_loss = 1.72125190, grad/param norm = 1.6429e-01, time/batch = 0.6701s	
2427/33800 (epoch 3.590), train_loss = 1.84883487, grad/param norm = 1.7769e-01, time/batch = 0.6705s	
2428/33800 (epoch 3.592), train_loss = 1.77007535, grad/param norm = 2.0047e-01, time/batch = 0.6818s	
2429/33800 (epoch 3.593), train_loss = 1.76210117, grad/param norm = 1.9340e-01, time/batch = 0.6757s	
2430/33800 (epoch 3.595), train_loss = 1.84751882, grad/param norm = 1.6865e-01, time/batch = 0.6716s	
2431/33800 (epoch 3.596), train_loss = 1.84609998, grad/param norm = 1.8365e-01, time/batch = 0.6793s	
2432/33800 (epoch 3.598), train_loss = 1.91301587, grad/param norm = 1.9582e-01, time/batch = 0.6771s	
2433/33800 (epoch 3.599), train_loss = 1.79282055, grad/param norm = 1.9755e-01, time/batch = 0.6765s	
2434/33800 (epoch 3.601), train_loss = 1.66860937, grad/param norm = 1.9030e-01, time/batch = 0.6782s	
2435/33800 (epoch 3.602), train_loss = 1.91931402, grad/param norm = 1.8461e-01, time/batch = 0.6790s	
2436/33800 (epoch 3.604), train_loss = 1.77484755, grad/param norm = 1.8356e-01, time/batch = 0.6793s	
2437/33800 (epoch 3.605), train_loss = 1.87347841, grad/param norm = 1.6703e-01, time/batch = 0.6805s	
2438/33800 (epoch 3.607), train_loss = 1.78413931, grad/param norm = 1.9023e-01, time/batch = 0.6774s	
2439/33800 (epoch 3.608), train_loss = 1.83816837, grad/param norm = 1.7860e-01, time/batch = 0.6748s	
2440/33800 (epoch 3.609), train_loss = 1.83659281, grad/param norm = 1.8723e-01, time/batch = 0.6747s	
2441/33800 (epoch 3.611), train_loss = 1.78476222, grad/param norm = 1.7525e-01, time/batch = 0.6792s	
2442/33800 (epoch 3.612), train_loss = 1.71210709, grad/param norm = 1.8778e-01, time/batch = 0.6810s	
2443/33800 (epoch 3.614), train_loss = 1.82811065, grad/param norm = 1.9232e-01, time/batch = 0.6858s	
2444/33800 (epoch 3.615), train_loss = 1.75482496, grad/param norm = 1.8738e-01, time/batch = 0.6729s	
2445/33800 (epoch 3.617), train_loss = 1.84015234, grad/param norm = 1.9367e-01, time/batch = 0.6710s	
2446/33800 (epoch 3.618), train_loss = 1.88703385, grad/param norm = 1.9621e-01, time/batch = 0.6742s	
2447/33800 (epoch 3.620), train_loss = 1.78270090, grad/param norm = 1.7332e-01, time/batch = 0.6758s	
2448/33800 (epoch 3.621), train_loss = 1.74383316, grad/param norm = 1.8069e-01, time/batch = 0.6790s	
2449/33800 (epoch 3.623), train_loss = 1.73935711, grad/param norm = 1.6337e-01, time/batch = 0.6878s	
2450/33800 (epoch 3.624), train_loss = 1.80353389, grad/param norm = 1.9245e-01, time/batch = 0.6741s	
2451/33800 (epoch 3.626), train_loss = 1.85851503, grad/param norm = 1.7313e-01, time/batch = 0.6809s	
2452/33800 (epoch 3.627), train_loss = 1.74091330, grad/param norm = 1.7167e-01, time/batch = 0.6833s	
2453/33800 (epoch 3.629), train_loss = 1.93631868, grad/param norm = 1.9132e-01, time/batch = 0.6865s	
2454/33800 (epoch 3.630), train_loss = 1.85772709, grad/param norm = 1.8820e-01, time/batch = 0.6788s	
2455/33800 (epoch 3.632), train_loss = 1.88699719, grad/param norm = 1.8192e-01, time/batch = 0.6768s	
2456/33800 (epoch 3.633), train_loss = 1.85009550, grad/param norm = 1.9243e-01, time/batch = 0.6759s	
2457/33800 (epoch 3.635), train_loss = 1.84186338, grad/param norm = 1.8613e-01, time/batch = 0.6840s	
2458/33800 (epoch 3.636), train_loss = 1.88442352, grad/param norm = 1.6781e-01, time/batch = 0.6876s	
2459/33800 (epoch 3.638), train_loss = 1.79605343, grad/param norm = 1.7508e-01, time/batch = 0.6830s	
2460/33800 (epoch 3.639), train_loss = 1.86758516, grad/param norm = 1.8863e-01, time/batch = 0.6738s	
2461/33800 (epoch 3.641), train_loss = 1.68052022, grad/param norm = 2.0229e-01, time/batch = 0.6769s	
2462/33800 (epoch 3.642), train_loss = 1.74149940, grad/param norm = 1.6734e-01, time/batch = 0.6734s	
2463/33800 (epoch 3.643), train_loss = 1.79224804, grad/param norm = 1.5839e-01, time/batch = 0.6759s	
2464/33800 (epoch 3.645), train_loss = 1.93868312, grad/param norm = 1.8257e-01, time/batch = 0.6784s	
2465/33800 (epoch 3.646), train_loss = 1.80627610, grad/param norm = 1.8075e-01, time/batch = 0.6948s	
2466/33800 (epoch 3.648), train_loss = 1.83107420, grad/param norm = 1.8326e-01, time/batch = 0.7225s	
2467/33800 (epoch 3.649), train_loss = 1.67157965, grad/param norm = 2.0076e-01, time/batch = 0.6927s	
2468/33800 (epoch 3.651), train_loss = 1.74897103, grad/param norm = 1.9397e-01, time/batch = 0.6881s	
2469/33800 (epoch 3.652), train_loss = 1.81284768, grad/param norm = 2.1270e-01, time/batch = 0.6827s	
2470/33800 (epoch 3.654), train_loss = 1.80062576, grad/param norm = 1.9376e-01, time/batch = 0.6848s	
2471/33800 (epoch 3.655), train_loss = 1.66157830, grad/param norm = 1.9261e-01, time/batch = 0.6874s	
2472/33800 (epoch 3.657), train_loss = 1.64785888, grad/param norm = 1.7227e-01, time/batch = 0.6860s	
2473/33800 (epoch 3.658), train_loss = 1.54766087, grad/param norm = 1.5859e-01, time/batch = 0.6853s	
2474/33800 (epoch 3.660), train_loss = 1.81374953, grad/param norm = 1.8181e-01, time/batch = 0.6850s	
2475/33800 (epoch 3.661), train_loss = 1.75663602, grad/param norm = 1.6742e-01, time/batch = 0.6877s	
2476/33800 (epoch 3.663), train_loss = 1.80239362, grad/param norm = 2.0275e-01, time/batch = 0.6780s	
2477/33800 (epoch 3.664), train_loss = 1.69579305, grad/param norm = 1.7982e-01, time/batch = 0.6737s	
2478/33800 (epoch 3.666), train_loss = 1.65768620, grad/param norm = 1.5702e-01, time/batch = 0.7052s	
2479/33800 (epoch 3.667), train_loss = 1.89572940, grad/param norm = 1.8807e-01, time/batch = 0.7008s	
2480/33800 (epoch 3.669), train_loss = 1.77762121, grad/param norm = 1.7631e-01, time/batch = 0.6807s	
2481/33800 (epoch 3.670), train_loss = 1.90065808, grad/param norm = 2.0623e-01, time/batch = 0.6781s	
2482/33800 (epoch 3.672), train_loss = 1.72965177, grad/param norm = 1.8383e-01, time/batch = 0.6817s	
2483/33800 (epoch 3.673), train_loss = 1.71428788, grad/param norm = 1.8077e-01, time/batch = 0.6818s	
2484/33800 (epoch 3.675), train_loss = 1.62417440, grad/param norm = 1.8043e-01, time/batch = 0.6841s	
2485/33800 (epoch 3.676), train_loss = 1.80138615, grad/param norm = 1.8233e-01, time/batch = 0.6820s	
2486/33800 (epoch 3.678), train_loss = 1.67511584, grad/param norm = 1.7871e-01, time/batch = 0.6886s	
2487/33800 (epoch 3.679), train_loss = 1.79356580, grad/param norm = 1.6463e-01, time/batch = 0.6817s	
2488/33800 (epoch 3.680), train_loss = 1.61355488, grad/param norm = 1.7997e-01, time/batch = 0.6781s	
2489/33800 (epoch 3.682), train_loss = 1.84314449, grad/param norm = 1.7948e-01, time/batch = 0.6808s	
2490/33800 (epoch 3.683), train_loss = 1.91426313, grad/param norm = 1.8676e-01, time/batch = 0.6822s	
2491/33800 (epoch 3.685), train_loss = 1.71619101, grad/param norm = 1.8301e-01, time/batch = 0.6827s	
2492/33800 (epoch 3.686), train_loss = 1.70381949, grad/param norm = 1.7479e-01, time/batch = 0.6830s	
2493/33800 (epoch 3.688), train_loss = 1.86396928, grad/param norm = 1.9248e-01, time/batch = 0.6802s	
2494/33800 (epoch 3.689), train_loss = 1.77243100, grad/param norm = 1.8051e-01, time/batch = 0.6774s	
2495/33800 (epoch 3.691), train_loss = 1.83390216, grad/param norm = 1.7227e-01, time/batch = 0.6894s	
2496/33800 (epoch 3.692), train_loss = 1.90196171, grad/param norm = 1.8650e-01, time/batch = 0.7221s	
2497/33800 (epoch 3.694), train_loss = 1.83413061, grad/param norm = 1.7578e-01, time/batch = 0.7037s	
2498/33800 (epoch 3.695), train_loss = 1.84596889, grad/param norm = 1.9261e-01, time/batch = 0.7312s	
2499/33800 (epoch 3.697), train_loss = 1.73081038, grad/param norm = 1.7196e-01, time/batch = 0.7262s	
2500/33800 (epoch 3.698), train_loss = 1.89128822, grad/param norm = 2.1029e-01, time/batch = 0.7474s	
2501/33800 (epoch 3.700), train_loss = 1.80871788, grad/param norm = 2.0099e-01, time/batch = 0.7103s	
2502/33800 (epoch 3.701), train_loss = 1.71899319, grad/param norm = 1.7111e-01, time/batch = 0.7081s	
2503/33800 (epoch 3.703), train_loss = 1.74465081, grad/param norm = 2.0110e-01, time/batch = 0.7368s	
2504/33800 (epoch 3.704), train_loss = 1.74425764, grad/param norm = 1.8014e-01, time/batch = 0.7202s	
2505/33800 (epoch 3.706), train_loss = 1.74672586, grad/param norm = 1.6402e-01, time/batch = 0.6864s	
2506/33800 (epoch 3.707), train_loss = 1.78573669, grad/param norm = 1.8189e-01, time/batch = 0.6791s	
2507/33800 (epoch 3.709), train_loss = 1.79739026, grad/param norm = 1.8721e-01, time/batch = 0.7209s	
2508/33800 (epoch 3.710), train_loss = 1.69571020, grad/param norm = 1.9112e-01, time/batch = 0.7445s	
2509/33800 (epoch 3.712), train_loss = 1.91611047, grad/param norm = 2.0673e-01, time/batch = 0.7289s	
2510/33800 (epoch 3.713), train_loss = 1.83614089, grad/param norm = 1.8494e-01, time/batch = 0.7117s	
2511/33800 (epoch 3.714), train_loss = 1.77978900, grad/param norm = 1.7229e-01, time/batch = 0.7275s	
2512/33800 (epoch 3.716), train_loss = 1.73455292, grad/param norm = 2.1547e-01, time/batch = 0.6952s	
2513/33800 (epoch 3.717), train_loss = 1.82752466, grad/param norm = 1.9712e-01, time/batch = 0.7148s	
2514/33800 (epoch 3.719), train_loss = 1.83590363, grad/param norm = 1.7645e-01, time/batch = 0.7279s	
2515/33800 (epoch 3.720), train_loss = 1.66672249, grad/param norm = 2.0218e-01, time/batch = 0.6952s	
2516/33800 (epoch 3.722), train_loss = 1.78633433, grad/param norm = 2.1595e-01, time/batch = 0.6967s	
2517/33800 (epoch 3.723), train_loss = 1.66610533, grad/param norm = 1.8995e-01, time/batch = 0.6978s	
2518/33800 (epoch 3.725), train_loss = 1.73904054, grad/param norm = 1.7758e-01, time/batch = 0.6896s	
2519/33800 (epoch 3.726), train_loss = 1.60439340, grad/param norm = 1.4700e-01, time/batch = 0.6922s	
2520/33800 (epoch 3.728), train_loss = 1.84232309, grad/param norm = 1.7657e-01, time/batch = 0.6899s	
2521/33800 (epoch 3.729), train_loss = 1.82611966, grad/param norm = 1.8351e-01, time/batch = 0.6988s	
2522/33800 (epoch 3.731), train_loss = 1.79593374, grad/param norm = 1.7252e-01, time/batch = 0.6930s	
2523/33800 (epoch 3.732), train_loss = 1.82632537, grad/param norm = 1.7683e-01, time/batch = 0.7118s	
2524/33800 (epoch 3.734), train_loss = 1.82403001, grad/param norm = 1.8344e-01, time/batch = 0.7081s	
2525/33800 (epoch 3.735), train_loss = 1.78836175, grad/param norm = 1.9005e-01, time/batch = 0.6900s	
2526/33800 (epoch 3.737), train_loss = 1.79244946, grad/param norm = 1.6884e-01, time/batch = 0.6833s	
2527/33800 (epoch 3.738), train_loss = 1.79177062, grad/param norm = 1.9051e-01, time/batch = 0.6824s	
2528/33800 (epoch 3.740), train_loss = 1.97065811, grad/param norm = 2.0585e-01, time/batch = 0.6859s	
2529/33800 (epoch 3.741), train_loss = 1.84066195, grad/param norm = 1.8357e-01, time/batch = 0.6783s	
2530/33800 (epoch 3.743), train_loss = 1.74042004, grad/param norm = 1.7305e-01, time/batch = 0.6784s	
2531/33800 (epoch 3.744), train_loss = 1.65722713, grad/param norm = 1.7304e-01, time/batch = 0.6852s	
2532/33800 (epoch 3.746), train_loss = 1.60570050, grad/param norm = 1.6137e-01, time/batch = 0.6780s	
2533/33800 (epoch 3.747), train_loss = 1.71531439, grad/param norm = 1.8887e-01, time/batch = 0.6760s	
2534/33800 (epoch 3.749), train_loss = 1.69057992, grad/param norm = 1.7353e-01, time/batch = 0.6743s	
2535/33800 (epoch 3.750), train_loss = 1.68637070, grad/param norm = 1.9525e-01, time/batch = 0.6749s	
2536/33800 (epoch 3.751), train_loss = 1.94877480, grad/param norm = 2.1456e-01, time/batch = 0.6723s	
2537/33800 (epoch 3.753), train_loss = 1.67452374, grad/param norm = 2.2514e-01, time/batch = 0.6753s	
2538/33800 (epoch 3.754), train_loss = 1.80226599, grad/param norm = 2.0028e-01, time/batch = 0.6827s	
2539/33800 (epoch 3.756), train_loss = 1.84346690, grad/param norm = 1.8462e-01, time/batch = 0.6803s	
2540/33800 (epoch 3.757), train_loss = 1.75355385, grad/param norm = 1.8990e-01, time/batch = 0.6725s	
2541/33800 (epoch 3.759), train_loss = 1.79796804, grad/param norm = 1.7892e-01, time/batch = 0.6730s	
2542/33800 (epoch 3.760), train_loss = 1.69665554, grad/param norm = 1.7389e-01, time/batch = 0.6740s	
2543/33800 (epoch 3.762), train_loss = 1.87718385, grad/param norm = 2.2908e-01, time/batch = 0.6821s	
2544/33800 (epoch 3.763), train_loss = 1.64220301, grad/param norm = 1.7865e-01, time/batch = 0.6951s	
2545/33800 (epoch 3.765), train_loss = 1.71589039, grad/param norm = 1.7258e-01, time/batch = 0.6877s	
2546/33800 (epoch 3.766), train_loss = 1.87658118, grad/param norm = 1.8440e-01, time/batch = 0.6720s	
2547/33800 (epoch 3.768), train_loss = 1.65977296, grad/param norm = 1.8208e-01, time/batch = 0.6885s	
2548/33800 (epoch 3.769), train_loss = 1.60925998, grad/param norm = 1.9593e-01, time/batch = 0.6931s	
2549/33800 (epoch 3.771), train_loss = 1.79499148, grad/param norm = 1.7443e-01, time/batch = 0.6720s	
2550/33800 (epoch 3.772), train_loss = 1.66167565, grad/param norm = 1.7880e-01, time/batch = 0.6794s	
2551/33800 (epoch 3.774), train_loss = 1.87501886, grad/param norm = 1.8417e-01, time/batch = 0.6839s	
2552/33800 (epoch 3.775), train_loss = 1.75292406, grad/param norm = 1.7678e-01, time/batch = 0.9097s	
2553/33800 (epoch 3.777), train_loss = 1.84266853, grad/param norm = 1.9245e-01, time/batch = 1.3030s	
2554/33800 (epoch 3.778), train_loss = 1.85511368, grad/param norm = 1.8701e-01, time/batch = 0.7005s	
2555/33800 (epoch 3.780), train_loss = 1.83266928, grad/param norm = 1.8803e-01, time/batch = 0.6738s	
2556/33800 (epoch 3.781), train_loss = 1.77433689, grad/param norm = 1.7027e-01, time/batch = 0.6797s	
2557/33800 (epoch 3.783), train_loss = 1.67177545, grad/param norm = 1.6949e-01, time/batch = 0.6896s	
2558/33800 (epoch 3.784), train_loss = 1.80076906, grad/param norm = 1.6522e-01, time/batch = 0.6910s	
