tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 665, val: 36, test: 0	
vocab size: 132	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 283268	
cloning rnn	
cloning criterion	
1/33250 (epoch 0.002), train_loss = 4.89483620, grad/param norm = 5.3641e-01, time/batch = 0.6962s	
2/33250 (epoch 0.003), train_loss = 4.59052017, grad/param norm = 1.5968e+00, time/batch = 0.6719s	
3/33250 (epoch 0.005), train_loss = 3.84499791, grad/param norm = 1.1701e+00, time/batch = 0.6736s	
4/33250 (epoch 0.006), train_loss = 3.51077292, grad/param norm = 1.2496e+00, time/batch = 0.6671s	
5/33250 (epoch 0.008), train_loss = 3.54854064, grad/param norm = 1.0692e+00, time/batch = 0.6493s	
6/33250 (epoch 0.009), train_loss = 3.38876855, grad/param norm = 8.8482e-01, time/batch = 0.6550s	
7/33250 (epoch 0.011), train_loss = 3.65641815, grad/param norm = 9.2266e-01, time/batch = 0.6696s	
8/33250 (epoch 0.012), train_loss = 3.58782502, grad/param norm = 6.7413e-01, time/batch = 0.6652s	
9/33250 (epoch 0.014), train_loss = 3.36745592, grad/param norm = 7.4184e-01, time/batch = 0.6498s	
10/33250 (epoch 0.015), train_loss = 3.66540183, grad/param norm = 1.0810e+00, time/batch = 0.6600s	
11/33250 (epoch 0.017), train_loss = 3.49511685, grad/param norm = 6.5139e-01, time/batch = 0.6903s	
12/33250 (epoch 0.018), train_loss = 3.50909854, grad/param norm = 5.6695e-01, time/batch = 0.6823s	
13/33250 (epoch 0.020), train_loss = 3.51800528, grad/param norm = 6.0117e-01, time/batch = 0.6768s	
14/33250 (epoch 0.021), train_loss = 3.46203333, grad/param norm = 6.3743e-01, time/batch = 0.6719s	
15/33250 (epoch 0.023), train_loss = 3.60807065, grad/param norm = 7.6253e-01, time/batch = 0.6737s	
16/33250 (epoch 0.024), train_loss = 3.52925159, grad/param norm = 8.0601e-01, time/batch = 0.6738s	
17/33250 (epoch 0.026), train_loss = 3.48590202, grad/param norm = 5.8272e-01, time/batch = 0.6725s	
18/33250 (epoch 0.027), train_loss = 3.54098210, grad/param norm = 5.9725e-01, time/batch = 0.6740s	
19/33250 (epoch 0.029), train_loss = 3.63104496, grad/param norm = 7.3299e-01, time/batch = 0.6744s	
20/33250 (epoch 0.030), train_loss = 3.51094195, grad/param norm = 5.9537e-01, time/batch = 0.6584s	
21/33250 (epoch 0.032), train_loss = 3.46335553, grad/param norm = 6.9499e-01, time/batch = 0.6628s	
22/33250 (epoch 0.033), train_loss = 3.49928387, grad/param norm = 6.5306e-01, time/batch = 0.6635s	
23/33250 (epoch 0.035), train_loss = 3.42214606, grad/param norm = 5.7728e-01, time/batch = 0.6555s	
24/33250 (epoch 0.036), train_loss = 3.38331694, grad/param norm = 5.9687e-01, time/batch = 0.6703s	
25/33250 (epoch 0.038), train_loss = 3.69276490, grad/param norm = 8.3199e-01, time/batch = 0.6727s	
26/33250 (epoch 0.039), train_loss = 3.44162855, grad/param norm = 7.1863e-01, time/batch = 0.6717s	
27/33250 (epoch 0.041), train_loss = 3.42561396, grad/param norm = 5.4169e-01, time/batch = 0.6720s	
28/33250 (epoch 0.042), train_loss = 3.43896833, grad/param norm = 7.1366e-01, time/batch = 0.6651s	
29/33250 (epoch 0.044), train_loss = 3.40277511, grad/param norm = 5.6600e-01, time/batch = 0.6585s	
30/33250 (epoch 0.045), train_loss = 3.38081501, grad/param norm = 5.9652e-01, time/batch = 0.6474s	
31/33250 (epoch 0.047), train_loss = 3.51986590, grad/param norm = 6.0388e-01, time/batch = 0.6522s	
32/33250 (epoch 0.048), train_loss = 3.38812310, grad/param norm = 7.9551e-01, time/batch = 0.6489s	
33/33250 (epoch 0.050), train_loss = 3.46625681, grad/param norm = 7.3466e-01, time/batch = 0.6478s	
34/33250 (epoch 0.051), train_loss = 3.44293137, grad/param norm = 4.8771e-01, time/batch = 0.6649s	
35/33250 (epoch 0.053), train_loss = 3.40086120, grad/param norm = 7.0653e-01, time/batch = 0.6717s	
36/33250 (epoch 0.054), train_loss = 3.50390797, grad/param norm = 7.6337e-01, time/batch = 0.6846s	
37/33250 (epoch 0.056), train_loss = 3.42007930, grad/param norm = 5.8398e-01, time/batch = 0.6842s	
38/33250 (epoch 0.057), train_loss = 3.51216716, grad/param norm = 4.9947e-01, time/batch = 0.6722s	
39/33250 (epoch 0.059), train_loss = 3.48861119, grad/param norm = 6.7581e-01, time/batch = 0.6731s	
40/33250 (epoch 0.060), train_loss = 3.51795348, grad/param norm = 5.5499e-01, time/batch = 0.6726s	
41/33250 (epoch 0.062), train_loss = 3.57139494, grad/param norm = 7.8641e-01, time/batch = 0.6746s	
42/33250 (epoch 0.063), train_loss = 3.51980289, grad/param norm = 5.4408e-01, time/batch = 0.6719s	
43/33250 (epoch 0.065), train_loss = 3.53849769, grad/param norm = 5.2409e-01, time/batch = 0.6694s	
44/33250 (epoch 0.066), train_loss = 3.38889170, grad/param norm = 5.2513e-01, time/batch = 0.6624s	
45/33250 (epoch 0.068), train_loss = 3.45014933, grad/param norm = 5.6349e-01, time/batch = 0.6510s	
46/33250 (epoch 0.069), train_loss = 3.49095304, grad/param norm = 5.7622e-01, time/batch = 0.6484s	
47/33250 (epoch 0.071), train_loss = 3.45424149, grad/param norm = 5.3546e-01, time/batch = 0.6435s	
48/33250 (epoch 0.072), train_loss = 3.48853701, grad/param norm = 4.7486e-01, time/batch = 0.6515s	
49/33250 (epoch 0.074), train_loss = 3.36942438, grad/param norm = 5.4374e-01, time/batch = 0.6497s	
50/33250 (epoch 0.075), train_loss = 3.39871560, grad/param norm = 6.0043e-01, time/batch = 0.6499s	
51/33250 (epoch 0.077), train_loss = 3.60697552, grad/param norm = 6.7261e-01, time/batch = 0.6517s	
52/33250 (epoch 0.078), train_loss = 3.41951876, grad/param norm = 4.8508e-01, time/batch = 0.6468s	
53/33250 (epoch 0.080), train_loss = 3.51569824, grad/param norm = 7.1628e-01, time/batch = 0.6452s	
54/33250 (epoch 0.081), train_loss = 3.50717402, grad/param norm = 7.1110e-01, time/batch = 0.6604s	
55/33250 (epoch 0.083), train_loss = 3.58353188, grad/param norm = 6.1291e-01, time/batch = 0.6487s	
56/33250 (epoch 0.084), train_loss = 3.49633839, grad/param norm = 5.2958e-01, time/batch = 0.6493s	
57/33250 (epoch 0.086), train_loss = 3.35640609, grad/param norm = 5.8736e-01, time/batch = 0.6468s	
58/33250 (epoch 0.087), train_loss = 3.53226242, grad/param norm = 6.8852e-01, time/batch = 0.6443s	
59/33250 (epoch 0.089), train_loss = 3.49938062, grad/param norm = 7.4887e-01, time/batch = 0.6614s	
60/33250 (epoch 0.090), train_loss = 3.36384849, grad/param norm = 6.6867e-01, time/batch = 0.6590s	
61/33250 (epoch 0.092), train_loss = 3.53237900, grad/param norm = 6.0554e-01, time/batch = 0.6720s	
62/33250 (epoch 0.093), train_loss = 3.29968674, grad/param norm = 6.9551e-01, time/batch = 0.6750s	
63/33250 (epoch 0.095), train_loss = 3.43421009, grad/param norm = 6.4718e-01, time/batch = 0.6700s	
64/33250 (epoch 0.096), train_loss = 3.44586274, grad/param norm = 4.7835e-01, time/batch = 0.6600s	
65/33250 (epoch 0.098), train_loss = 3.29673836, grad/param norm = 6.4121e-01, time/batch = 0.6696s	
66/33250 (epoch 0.099), train_loss = 3.54057226, grad/param norm = 5.9234e-01, time/batch = 0.6645s	
67/33250 (epoch 0.101), train_loss = 3.39162193, grad/param norm = 7.1230e-01, time/batch = 0.6561s	
68/33250 (epoch 0.102), train_loss = 3.45279974, grad/param norm = 6.1258e-01, time/batch = 0.6627s	
69/33250 (epoch 0.104), train_loss = 3.50884990, grad/param norm = 5.4889e-01, time/batch = 0.6627s	
70/33250 (epoch 0.105), train_loss = 3.44330440, grad/param norm = 7.3902e-01, time/batch = 0.6680s	
71/33250 (epoch 0.107), train_loss = 3.47202357, grad/param norm = 6.8455e-01, time/batch = 0.6668s	
72/33250 (epoch 0.108), train_loss = 3.46362764, grad/param norm = 5.4856e-01, time/batch = 0.6669s	
73/33250 (epoch 0.110), train_loss = 3.49369310, grad/param norm = 4.7196e-01, time/batch = 0.6678s	
74/33250 (epoch 0.111), train_loss = 3.36719508, grad/param norm = 6.8612e-01, time/batch = 0.6819s	
75/33250 (epoch 0.113), train_loss = 3.55633170, grad/param norm = 6.7866e-01, time/batch = 0.6866s	
76/33250 (epoch 0.114), train_loss = 3.49501943, grad/param norm = 4.7837e-01, time/batch = 0.6850s	
77/33250 (epoch 0.116), train_loss = 3.51884124, grad/param norm = 5.1754e-01, time/batch = 0.6743s	
78/33250 (epoch 0.117), train_loss = 3.46888717, grad/param norm = 6.7488e-01, time/batch = 0.6744s	
79/33250 (epoch 0.119), train_loss = 3.56045758, grad/param norm = 5.9006e-01, time/batch = 0.6686s	
80/33250 (epoch 0.120), train_loss = 3.52092883, grad/param norm = 5.6324e-01, time/batch = 0.6716s	
81/33250 (epoch 0.122), train_loss = 3.43612042, grad/param norm = 4.8039e-01, time/batch = 0.6899s	
82/33250 (epoch 0.123), train_loss = 3.41300212, grad/param norm = 4.2295e-01, time/batch = 0.6786s	
83/33250 (epoch 0.125), train_loss = 3.40054905, grad/param norm = 5.0188e-01, time/batch = 0.6654s	
84/33250 (epoch 0.126), train_loss = 3.55505023, grad/param norm = 6.1791e-01, time/batch = 0.6743s	
85/33250 (epoch 0.128), train_loss = 3.44687513, grad/param norm = 5.8790e-01, time/batch = 0.6679s	
86/33250 (epoch 0.129), train_loss = 3.53497531, grad/param norm = 9.2328e-01, time/batch = 0.6705s	
87/33250 (epoch 0.131), train_loss = 3.40798964, grad/param norm = 6.7966e-01, time/batch = 0.6715s	
88/33250 (epoch 0.132), train_loss = 3.44423629, grad/param norm = 6.5872e-01, time/batch = 0.6720s	
89/33250 (epoch 0.134), train_loss = 3.47131464, grad/param norm = 5.7744e-01, time/batch = 0.6665s	
90/33250 (epoch 0.135), train_loss = 3.49250076, grad/param norm = 4.9365e-01, time/batch = 0.6601s	
91/33250 (epoch 0.137), train_loss = 3.55572168, grad/param norm = 5.6893e-01, time/batch = 0.6545s	
92/33250 (epoch 0.138), train_loss = 3.53358680, grad/param norm = 4.6737e-01, time/batch = 0.6548s	
93/33250 (epoch 0.140), train_loss = 3.54180627, grad/param norm = 4.7303e-01, time/batch = 0.6482s	
94/33250 (epoch 0.141), train_loss = 3.58529708, grad/param norm = 5.3839e-01, time/batch = 0.6729s	
95/33250 (epoch 0.143), train_loss = 3.48488434, grad/param norm = 4.8216e-01, time/batch = 0.6638s	
96/33250 (epoch 0.144), train_loss = 3.36281648, grad/param norm = 6.4489e-01, time/batch = 0.6467s	
97/33250 (epoch 0.146), train_loss = 3.24912377, grad/param norm = 6.5810e-01, time/batch = 0.6508s	
98/33250 (epoch 0.147), train_loss = 3.38431532, grad/param norm = 4.1256e-01, time/batch = 0.6527s	
99/33250 (epoch 0.149), train_loss = 3.49429223, grad/param norm = 4.6239e-01, time/batch = 0.6511s	
100/33250 (epoch 0.150), train_loss = 3.37923867, grad/param norm = 4.0912e-01, time/batch = 0.6551s	
101/33250 (epoch 0.152), train_loss = 3.36874451, grad/param norm = 6.2886e-01, time/batch = 0.6588s	
102/33250 (epoch 0.153), train_loss = 3.48534759, grad/param norm = 9.8386e-01, time/batch = 0.6614s	
103/33250 (epoch 0.155), train_loss = 3.41212234, grad/param norm = 8.4755e-01, time/batch = 0.6590s	
104/33250 (epoch 0.156), train_loss = 3.43355296, grad/param norm = 6.5450e-01, time/batch = 0.6585s	
105/33250 (epoch 0.158), train_loss = 3.36917252, grad/param norm = 5.7385e-01, time/batch = 0.6635s	
106/33250 (epoch 0.159), train_loss = 3.51575332, grad/param norm = 6.6609e-01, time/batch = 0.6564s	
107/33250 (epoch 0.161), train_loss = 3.43056564, grad/param norm = 1.0656e+00, time/batch = 0.6547s	
108/33250 (epoch 0.162), train_loss = 3.55486044, grad/param norm = 9.1232e-01, time/batch = 0.6539s	
109/33250 (epoch 0.164), train_loss = 3.40834265, grad/param norm = 4.3719e-01, time/batch = 0.6573s	
110/33250 (epoch 0.165), train_loss = 3.47482671, grad/param norm = 4.5258e-01, time/batch = 0.6539s	
111/33250 (epoch 0.167), train_loss = 3.23877458, grad/param norm = 5.5631e-01, time/batch = 0.6573s	
112/33250 (epoch 0.168), train_loss = 3.33073549, grad/param norm = 4.8237e-01, time/batch = 0.6484s	
113/33250 (epoch 0.170), train_loss = 3.26232487, grad/param norm = 6.9277e-01, time/batch = 0.6529s	
114/33250 (epoch 0.171), train_loss = 3.35498967, grad/param norm = 7.5798e-01, time/batch = 0.6527s	
115/33250 (epoch 0.173), train_loss = 3.28594403, grad/param norm = 6.4191e-01, time/batch = 0.6641s	
116/33250 (epoch 0.174), train_loss = 3.21636107, grad/param norm = 5.1576e-01, time/batch = 0.6668s	
117/33250 (epoch 0.176), train_loss = 3.31705920, grad/param norm = 4.8542e-01, time/batch = 0.6789s	
118/33250 (epoch 0.177), train_loss = 3.28990700, grad/param norm = 4.7884e-01, time/batch = 0.6756s	
119/33250 (epoch 0.179), train_loss = 3.39107271, grad/param norm = 6.7929e-01, time/batch = 0.6680s	
120/33250 (epoch 0.180), train_loss = 3.21514330, grad/param norm = 6.1694e-01, time/batch = 0.6891s	
121/33250 (epoch 0.182), train_loss = 3.27877825, grad/param norm = 7.9015e-01, time/batch = 0.6885s	
122/33250 (epoch 0.183), train_loss = 3.66783484, grad/param norm = 2.9130e+00, time/batch = 0.6826s	
123/33250 (epoch 0.185), train_loss = 3.43585109, grad/param norm = 1.4472e+00, time/batch = 0.6815s	
124/33250 (epoch 0.186), train_loss = 3.34764014, grad/param norm = 4.2719e-01, time/batch = 0.6842s	
125/33250 (epoch 0.188), train_loss = 3.32327640, grad/param norm = 3.2710e-01, time/batch = 0.6774s	
126/33250 (epoch 0.189), train_loss = 3.32286962, grad/param norm = 3.6937e-01, time/batch = 0.6848s	
127/33250 (epoch 0.191), train_loss = 3.15701756, grad/param norm = 4.4558e-01, time/batch = 0.6773s	
128/33250 (epoch 0.192), train_loss = 3.34116200, grad/param norm = 5.4863e-01, time/batch = 0.6655s	
129/33250 (epoch 0.194), train_loss = 3.14652614, grad/param norm = 8.0424e-01, time/batch = 0.6697s	
130/33250 (epoch 0.195), train_loss = 3.26651829, grad/param norm = 6.0774e-01, time/batch = 0.6634s	
131/33250 (epoch 0.197), train_loss = 3.17582547, grad/param norm = 3.8575e-01, time/batch = 0.6671s	
132/33250 (epoch 0.198), train_loss = 3.19947453, grad/param norm = 4.8086e-01, time/batch = 0.6711s	
133/33250 (epoch 0.200), train_loss = 3.15071672, grad/param norm = 5.8825e-01, time/batch = 0.6776s	
134/33250 (epoch 0.202), train_loss = 3.27029503, grad/param norm = 9.2603e-01, time/batch = 0.6691s	
135/33250 (epoch 0.203), train_loss = 3.26009910, grad/param norm = 1.0257e+00, time/batch = 0.6680s	
136/33250 (epoch 0.205), train_loss = 3.31879469, grad/param norm = 9.1005e-01, time/batch = 0.6861s	
137/33250 (epoch 0.206), train_loss = 3.12376640, grad/param norm = 7.9138e-01, time/batch = 0.6795s	
138/33250 (epoch 0.208), train_loss = 3.37828255, grad/param norm = 5.6321e-01, time/batch = 0.6777s	
139/33250 (epoch 0.209), train_loss = 3.09153559, grad/param norm = 5.0626e-01, time/batch = 0.6718s	
140/33250 (epoch 0.211), train_loss = 3.25129247, grad/param norm = 4.5262e-01, time/batch = 0.6705s	
141/33250 (epoch 0.212), train_loss = 3.13923962, grad/param norm = 5.5444e-01, time/batch = 0.6739s	
142/33250 (epoch 0.214), train_loss = 3.13868496, grad/param norm = 6.3789e-01, time/batch = 0.6628s	
143/33250 (epoch 0.215), train_loss = 3.27658725, grad/param norm = 7.0115e-01, time/batch = 0.6645s	
144/33250 (epoch 0.217), train_loss = 3.16363679, grad/param norm = 5.8312e-01, time/batch = 0.6676s	
145/33250 (epoch 0.218), train_loss = 3.10868221, grad/param norm = 4.8333e-01, time/batch = 0.6783s	
146/33250 (epoch 0.220), train_loss = 3.22678427, grad/param norm = 8.7506e-01, time/batch = 0.6851s	
147/33250 (epoch 0.221), train_loss = 3.20854852, grad/param norm = 1.6531e+00, time/batch = 0.6883s	
148/33250 (epoch 0.223), train_loss = 3.27180415, grad/param norm = 1.6248e+00, time/batch = 0.6877s	
149/33250 (epoch 0.224), train_loss = 3.18988836, grad/param norm = 9.9372e-01, time/batch = 0.6764s	
150/33250 (epoch 0.226), train_loss = 3.12181552, grad/param norm = 5.7420e-01, time/batch = 0.6852s	
151/33250 (epoch 0.227), train_loss = 3.10831251, grad/param norm = 5.1370e-01, time/batch = 0.6897s	
152/33250 (epoch 0.229), train_loss = 3.02658263, grad/param norm = 4.1001e-01, time/batch = 0.6952s	
153/33250 (epoch 0.230), train_loss = 3.11596162, grad/param norm = 4.6056e-01, time/batch = 0.7022s	
154/33250 (epoch 0.232), train_loss = 3.08353440, grad/param norm = 3.8041e-01, time/batch = 0.7038s	
155/33250 (epoch 0.233), train_loss = 3.02282199, grad/param norm = 2.9188e-01, time/batch = 0.7057s	
156/33250 (epoch 0.235), train_loss = 3.03050272, grad/param norm = 3.1913e-01, time/batch = 0.6932s	
157/33250 (epoch 0.236), train_loss = 2.96905296, grad/param norm = 4.7729e-01, time/batch = 0.6916s	
158/33250 (epoch 0.238), train_loss = 3.01481938, grad/param norm = 5.8575e-01, time/batch = 0.7028s	
159/33250 (epoch 0.239), train_loss = 3.26746111, grad/param norm = 1.2129e+00, time/batch = 0.7029s	
160/33250 (epoch 0.241), train_loss = 3.08123850, grad/param norm = 1.2536e+00, time/batch = 0.7043s	
161/33250 (epoch 0.242), train_loss = 3.03230670, grad/param norm = 7.6058e-01, time/batch = 0.6854s	
162/33250 (epoch 0.244), train_loss = 3.10828288, grad/param norm = 5.3382e-01, time/batch = 0.6779s	
163/33250 (epoch 0.245), train_loss = 3.02213602, grad/param norm = 4.3480e-01, time/batch = 0.6894s	
164/33250 (epoch 0.247), train_loss = 3.11205435, grad/param norm = 5.7878e-01, time/batch = 0.6901s	
165/33250 (epoch 0.248), train_loss = 3.04694179, grad/param norm = 7.9263e-01, time/batch = 0.6933s	
166/33250 (epoch 0.250), train_loss = 3.04706769, grad/param norm = 1.1358e+00, time/batch = 0.6863s	
167/33250 (epoch 0.251), train_loss = 3.09401675, grad/param norm = 9.7311e-01, time/batch = 0.6889s	
168/33250 (epoch 0.253), train_loss = 3.02932615, grad/param norm = 8.6119e-01, time/batch = 0.6816s	
169/33250 (epoch 0.254), train_loss = 3.03732076, grad/param norm = 9.0191e-01, time/batch = 0.6743s	
170/33250 (epoch 0.256), train_loss = 3.04617958, grad/param norm = 7.9393e-01, time/batch = 0.6736s	
171/33250 (epoch 0.257), train_loss = 3.10111643, grad/param norm = 6.2620e-01, time/batch = 0.6727s	
172/33250 (epoch 0.259), train_loss = 3.16025369, grad/param norm = 7.3087e-01, time/batch = 0.6797s	
173/33250 (epoch 0.260), train_loss = 3.12800371, grad/param norm = 5.5528e-01, time/batch = 0.6961s	
174/33250 (epoch 0.262), train_loss = 2.98719909, grad/param norm = 4.1628e-01, time/batch = 0.6880s	
175/33250 (epoch 0.263), train_loss = 2.92141976, grad/param norm = 4.8086e-01, time/batch = 0.6834s	
176/33250 (epoch 0.265), train_loss = 3.02630437, grad/param norm = 6.4340e-01, time/batch = 0.6827s	
177/33250 (epoch 0.266), train_loss = 2.98367492, grad/param norm = 1.0570e+00, time/batch = 0.6904s	
178/33250 (epoch 0.268), train_loss = 3.31525129, grad/param norm = 1.1855e+00, time/batch = 0.6729s	
179/33250 (epoch 0.269), train_loss = 3.00957860, grad/param norm = 8.5273e-01, time/batch = 0.6685s	
180/33250 (epoch 0.271), train_loss = 2.92710557, grad/param norm = 9.1060e-01, time/batch = 0.6645s	
181/33250 (epoch 0.272), train_loss = 3.02230980, grad/param norm = 1.0174e+00, time/batch = 0.6855s	
182/33250 (epoch 0.274), train_loss = 2.89707589, grad/param norm = 7.5701e-01, time/batch = 0.6663s	
183/33250 (epoch 0.275), train_loss = 3.12225072, grad/param norm = 9.3219e-01, time/batch = 0.6661s	
184/33250 (epoch 0.277), train_loss = 3.03608036, grad/param norm = 1.1214e+00, time/batch = 0.6718s	
185/33250 (epoch 0.278), train_loss = 2.96375074, grad/param norm = 7.4544e-01, time/batch = 0.6632s	
186/33250 (epoch 0.280), train_loss = 2.93426870, grad/param norm = 3.6445e-01, time/batch = 0.6653s	
187/33250 (epoch 0.281), train_loss = 2.98077825, grad/param norm = 4.2948e-01, time/batch = 0.6873s	
188/33250 (epoch 0.283), train_loss = 2.99224283, grad/param norm = 3.5911e-01, time/batch = 0.6818s	
189/33250 (epoch 0.284), train_loss = 3.13044444, grad/param norm = 3.8226e-01, time/batch = 0.6789s	
190/33250 (epoch 0.286), train_loss = 3.00960697, grad/param norm = 5.3318e-01, time/batch = 0.6763s	
191/33250 (epoch 0.287), train_loss = 3.13473548, grad/param norm = 7.8623e-01, time/batch = 0.6699s	
192/33250 (epoch 0.289), train_loss = 3.05114929, grad/param norm = 1.0539e+00, time/batch = 0.6711s	
193/33250 (epoch 0.290), train_loss = 2.94387208, grad/param norm = 7.8000e-01, time/batch = 0.6717s	
194/33250 (epoch 0.292), train_loss = 2.96093691, grad/param norm = 7.4053e-01, time/batch = 0.6717s	
195/33250 (epoch 0.293), train_loss = 3.03217146, grad/param norm = 6.6986e-01, time/batch = 0.6756s	
196/33250 (epoch 0.295), train_loss = 2.90529313, grad/param norm = 4.9427e-01, time/batch = 0.6713s	
197/33250 (epoch 0.296), train_loss = 2.82960519, grad/param norm = 5.3751e-01, time/batch = 0.6807s	
198/33250 (epoch 0.298), train_loss = 2.95908641, grad/param norm = 4.8841e-01, time/batch = 0.6893s	
199/33250 (epoch 0.299), train_loss = 2.79664358, grad/param norm = 5.4451e-01, time/batch = 0.6738s	
200/33250 (epoch 0.301), train_loss = 2.92027798, grad/param norm = 6.7302e-01, time/batch = 0.6732s	
201/33250 (epoch 0.302), train_loss = 2.88550407, grad/param norm = 9.9034e-01, time/batch = 0.6736s	
202/33250 (epoch 0.304), train_loss = 2.95837400, grad/param norm = 1.1711e+00, time/batch = 0.6770s	
203/33250 (epoch 0.305), train_loss = 3.01162487, grad/param norm = 8.1715e-01, time/batch = 0.6748s	
204/33250 (epoch 0.307), train_loss = 2.86027820, grad/param norm = 6.1887e-01, time/batch = 0.6726s	
205/33250 (epoch 0.308), train_loss = 2.94140639, grad/param norm = 5.6947e-01, time/batch = 0.6738s	
206/33250 (epoch 0.310), train_loss = 2.80036419, grad/param norm = 6.5769e-01, time/batch = 0.6649s	
207/33250 (epoch 0.311), train_loss = 2.88517620, grad/param norm = 4.3341e-01, time/batch = 0.6652s	
208/33250 (epoch 0.313), train_loss = 2.96364577, grad/param norm = 4.5898e-01, time/batch = 0.6737s	
209/33250 (epoch 0.314), train_loss = 2.83277373, grad/param norm = 6.7173e-01, time/batch = 0.6662s	
210/33250 (epoch 0.316), train_loss = 2.92983915, grad/param norm = 9.0429e-01, time/batch = 0.6639s	
211/33250 (epoch 0.317), train_loss = 2.88064083, grad/param norm = 8.5675e-01, time/batch = 0.6698s	
212/33250 (epoch 0.319), train_loss = 2.86182645, grad/param norm = 5.2045e-01, time/batch = 0.6708s	
213/33250 (epoch 0.320), train_loss = 2.96226342, grad/param norm = 5.3420e-01, time/batch = 0.6715s	
214/33250 (epoch 0.322), train_loss = 2.83623779, grad/param norm = 6.6658e-01, time/batch = 0.6645s	
215/33250 (epoch 0.323), train_loss = 2.95611678, grad/param norm = 7.7519e-01, time/batch = 0.6680s	
216/33250 (epoch 0.325), train_loss = 2.81293051, grad/param norm = 6.7594e-01, time/batch = 0.6704s	
217/33250 (epoch 0.326), train_loss = 2.78914315, grad/param norm = 4.3685e-01, time/batch = 0.6683s	
218/33250 (epoch 0.328), train_loss = 2.78492411, grad/param norm = 3.6163e-01, time/batch = 0.6715s	
219/33250 (epoch 0.329), train_loss = 2.85200686, grad/param norm = 3.2844e-01, time/batch = 0.6669s	
220/33250 (epoch 0.331), train_loss = 2.70823043, grad/param norm = 4.4267e-01, time/batch = 0.6645s	
221/33250 (epoch 0.332), train_loss = 2.83077093, grad/param norm = 6.6995e-01, time/batch = 0.6632s	
222/33250 (epoch 0.334), train_loss = 2.88519262, grad/param norm = 7.9840e-01, time/batch = 0.6623s	
223/33250 (epoch 0.335), train_loss = 2.82859117, grad/param norm = 7.4207e-01, time/batch = 0.6629s	
224/33250 (epoch 0.337), train_loss = 2.85780230, grad/param norm = 8.3298e-01, time/batch = 0.6867s	
225/33250 (epoch 0.338), train_loss = 2.84054826, grad/param norm = 8.6090e-01, time/batch = 0.6774s	
226/33250 (epoch 0.340), train_loss = 2.93910390, grad/param norm = 8.7201e-01, time/batch = 0.6685s	
227/33250 (epoch 0.341), train_loss = 2.83208824, grad/param norm = 9.2205e-01, time/batch = 0.6690s	
228/33250 (epoch 0.343), train_loss = 2.97042449, grad/param norm = 8.2810e-01, time/batch = 0.6653s	
229/33250 (epoch 0.344), train_loss = 2.71372966, grad/param norm = 5.6474e-01, time/batch = 0.6797s	
230/33250 (epoch 0.346), train_loss = 2.67406658, grad/param norm = 5.3078e-01, time/batch = 0.6821s	
231/33250 (epoch 0.347), train_loss = 2.96911377, grad/param norm = 4.7133e-01, time/batch = 0.6776s	
232/33250 (epoch 0.349), train_loss = 2.94748421, grad/param norm = 8.4068e-01, time/batch = 0.6718s	
233/33250 (epoch 0.350), train_loss = 2.79414689, grad/param norm = 9.3616e-01, time/batch = 0.6657s	
234/33250 (epoch 0.352), train_loss = 2.79395998, grad/param norm = 6.0763e-01, time/batch = 0.6622s	
235/33250 (epoch 0.353), train_loss = 2.78289976, grad/param norm = 5.3345e-01, time/batch = 0.6611s	
236/33250 (epoch 0.355), train_loss = 2.74555083, grad/param norm = 8.3323e-01, time/batch = 0.6623s	
237/33250 (epoch 0.356), train_loss = 2.75183840, grad/param norm = 9.2005e-01, time/batch = 0.6629s	
238/33250 (epoch 0.358), train_loss = 2.70325251, grad/param norm = 8.6001e-01, time/batch = 0.6615s	
239/33250 (epoch 0.359), train_loss = 2.77753104, grad/param norm = 7.4373e-01, time/batch = 0.6643s	
240/33250 (epoch 0.361), train_loss = 2.83027041, grad/param norm = 5.5686e-01, time/batch = 0.6836s	
241/33250 (epoch 0.362), train_loss = 2.74449731, grad/param norm = 5.5756e-01, time/batch = 0.6626s	
242/33250 (epoch 0.364), train_loss = 2.81906834, grad/param norm = 5.8137e-01, time/batch = 0.6635s	
243/33250 (epoch 0.365), train_loss = 2.71622083, grad/param norm = 4.2994e-01, time/batch = 0.6613s	
244/33250 (epoch 0.367), train_loss = 2.73188888, grad/param norm = 3.6312e-01, time/batch = 0.6618s	
245/33250 (epoch 0.368), train_loss = 2.73786655, grad/param norm = 3.7226e-01, time/batch = 0.6653s	
246/33250 (epoch 0.370), train_loss = 2.67027029, grad/param norm = 4.4828e-01, time/batch = 0.6671s	
247/33250 (epoch 0.371), train_loss = 2.74832622, grad/param norm = 4.7378e-01, time/batch = 0.6754s	
248/33250 (epoch 0.373), train_loss = 2.66094096, grad/param norm = 5.7264e-01, time/batch = 0.6777s	
249/33250 (epoch 0.374), train_loss = 2.85388804, grad/param norm = 1.0492e+00, time/batch = 0.6638s	
250/33250 (epoch 0.376), train_loss = 2.70718759, grad/param norm = 9.8660e-01, time/batch = 0.6670s	
251/33250 (epoch 0.377), train_loss = 2.72161172, grad/param norm = 7.6831e-01, time/batch = 0.6895s	
252/33250 (epoch 0.379), train_loss = 2.70366056, grad/param norm = 6.7336e-01, time/batch = 0.6914s	
253/33250 (epoch 0.380), train_loss = 2.63831556, grad/param norm = 5.2098e-01, time/batch = 0.6976s	
254/33250 (epoch 0.382), train_loss = 2.77585067, grad/param norm = 4.6845e-01, time/batch = 0.6922s	
255/33250 (epoch 0.383), train_loss = 2.62012058, grad/param norm = 3.3078e-01, time/batch = 0.6907s	
256/33250 (epoch 0.385), train_loss = 2.76639642, grad/param norm = 4.3718e-01, time/batch = 0.6925s	
257/33250 (epoch 0.386), train_loss = 2.66489922, grad/param norm = 5.1069e-01, time/batch = 0.6803s	
258/33250 (epoch 0.388), train_loss = 2.68855662, grad/param norm = 5.2767e-01, time/batch = 0.6672s	
259/33250 (epoch 0.389), train_loss = 2.71732189, grad/param norm = 8.0684e-01, time/batch = 0.6554s	
260/33250 (epoch 0.391), train_loss = 2.61256784, grad/param norm = 6.7502e-01, time/batch = 0.6554s	
261/33250 (epoch 0.392), train_loss = 2.80547025, grad/param norm = 5.7534e-01, time/batch = 0.6595s	
262/33250 (epoch 0.394), train_loss = 2.78246818, grad/param norm = 6.8564e-01, time/batch = 0.6690s	
263/33250 (epoch 0.395), train_loss = 2.84227445, grad/param norm = 4.8866e-01, time/batch = 0.6542s	
264/33250 (epoch 0.397), train_loss = 2.86920446, grad/param norm = 4.2117e-01, time/batch = 0.6504s	
265/33250 (epoch 0.398), train_loss = 2.66288762, grad/param norm = 4.4561e-01, time/batch = 0.6482s	
266/33250 (epoch 0.400), train_loss = 2.68776091, grad/param norm = 5.0309e-01, time/batch = 0.6480s	
267/33250 (epoch 0.402), train_loss = 2.61879101, grad/param norm = 6.6991e-01, time/batch = 0.6482s	
268/33250 (epoch 0.403), train_loss = 2.68874962, grad/param norm = 6.9270e-01, time/batch = 0.6511s	
269/33250 (epoch 0.405), train_loss = 2.66562927, grad/param norm = 6.1532e-01, time/batch = 0.6713s	
270/33250 (epoch 0.406), train_loss = 2.65941447, grad/param norm = 7.3680e-01, time/batch = 0.6697s	
271/33250 (epoch 0.408), train_loss = 2.73150229, grad/param norm = 6.1155e-01, time/batch = 0.6451s	
272/33250 (epoch 0.409), train_loss = 2.63989507, grad/param norm = 6.0138e-01, time/batch = 0.6427s	
273/33250 (epoch 0.411), train_loss = 2.56507576, grad/param norm = 6.6137e-01, time/batch = 0.6435s	
274/33250 (epoch 0.412), train_loss = 2.50559856, grad/param norm = 7.2175e-01, time/batch = 0.6437s	
275/33250 (epoch 0.414), train_loss = 2.80489532, grad/param norm = 8.3604e-01, time/batch = 0.6424s	
276/33250 (epoch 0.415), train_loss = 2.63589561, grad/param norm = 8.6135e-01, time/batch = 0.6460s	
277/33250 (epoch 0.417), train_loss = 2.68925800, grad/param norm = 9.1770e-01, time/batch = 0.6488s	
278/33250 (epoch 0.418), train_loss = 2.80866981, grad/param norm = 7.7331e-01, time/batch = 0.6448s	
279/33250 (epoch 0.420), train_loss = 2.74876553, grad/param norm = 5.3315e-01, time/batch = 0.6501s	
280/33250 (epoch 0.421), train_loss = 2.50843652, grad/param norm = 3.1567e-01, time/batch = 0.6493s	
281/33250 (epoch 0.423), train_loss = 2.57427068, grad/param norm = 4.0375e-01, time/batch = 0.6575s	
282/33250 (epoch 0.424), train_loss = 2.64357907, grad/param norm = 4.6534e-01, time/batch = 0.6500s	
283/33250 (epoch 0.426), train_loss = 2.64414749, grad/param norm = 4.4646e-01, time/batch = 0.6461s	
284/33250 (epoch 0.427), train_loss = 2.55452145, grad/param norm = 4.7751e-01, time/batch = 0.6559s	
285/33250 (epoch 0.429), train_loss = 2.66940126, grad/param norm = 4.0738e-01, time/batch = 0.6560s	
286/33250 (epoch 0.430), train_loss = 2.57160883, grad/param norm = 5.0696e-01, time/batch = 0.6531s	
287/33250 (epoch 0.432), train_loss = 2.65254903, grad/param norm = 7.8628e-01, time/batch = 0.6665s	
288/33250 (epoch 0.433), train_loss = 2.61869279, grad/param norm = 6.4520e-01, time/batch = 0.6573s	
289/33250 (epoch 0.435), train_loss = 2.70921879, grad/param norm = 5.9293e-01, time/batch = 0.6631s	
290/33250 (epoch 0.436), train_loss = 2.69606538, grad/param norm = 3.9744e-01, time/batch = 0.6680s	
291/33250 (epoch 0.438), train_loss = 2.51050755, grad/param norm = 5.1990e-01, time/batch = 0.6628s	
292/33250 (epoch 0.439), train_loss = 2.55082851, grad/param norm = 4.1891e-01, time/batch = 0.6529s	
293/33250 (epoch 0.441), train_loss = 2.53280872, grad/param norm = 4.6198e-01, time/batch = 0.6529s	
294/33250 (epoch 0.442), train_loss = 2.57610564, grad/param norm = 5.4838e-01, time/batch = 0.6442s	
295/33250 (epoch 0.444), train_loss = 2.56361545, grad/param norm = 7.2800e-01, time/batch = 0.6725s	
296/33250 (epoch 0.445), train_loss = 2.66197456, grad/param norm = 8.9709e-01, time/batch = 0.6682s	
297/33250 (epoch 0.447), train_loss = 2.69063926, grad/param norm = 6.1495e-01, time/batch = 0.6438s	
298/33250 (epoch 0.448), train_loss = 2.58691761, grad/param norm = 5.6209e-01, time/batch = 0.6573s	
299/33250 (epoch 0.450), train_loss = 2.65467578, grad/param norm = 4.8446e-01, time/batch = 0.6639s	
300/33250 (epoch 0.451), train_loss = 2.64985094, grad/param norm = 4.8090e-01, time/batch = 0.6584s	
301/33250 (epoch 0.453), train_loss = 2.48831819, grad/param norm = 5.7577e-01, time/batch = 0.6611s	
302/33250 (epoch 0.454), train_loss = 2.61780800, grad/param norm = 7.8300e-01, time/batch = 0.6627s	
303/33250 (epoch 0.456), train_loss = 2.45837432, grad/param norm = 4.7671e-01, time/batch = 0.6615s	
304/33250 (epoch 0.457), train_loss = 2.53978801, grad/param norm = 5.2912e-01, time/batch = 0.6778s	
305/33250 (epoch 0.459), train_loss = 2.66799333, grad/param norm = 6.2942e-01, time/batch = 0.6650s	
306/33250 (epoch 0.460), train_loss = 2.53308536, grad/param norm = 6.2905e-01, time/batch = 0.6581s	
307/33250 (epoch 0.462), train_loss = 2.57649163, grad/param norm = 6.7684e-01, time/batch = 0.6604s	
308/33250 (epoch 0.463), train_loss = 2.51064493, grad/param norm = 5.0427e-01, time/batch = 0.6668s	
309/33250 (epoch 0.465), train_loss = 2.27044958, grad/param norm = 5.2421e-01, time/batch = 0.6572s	
310/33250 (epoch 0.466), train_loss = 2.44673246, grad/param norm = 6.5715e-01, time/batch = 0.6518s	
311/33250 (epoch 0.468), train_loss = 2.47160492, grad/param norm = 5.4583e-01, time/batch = 0.6749s	
312/33250 (epoch 0.469), train_loss = 2.62655566, grad/param norm = 5.2310e-01, time/batch = 0.6751s	
313/33250 (epoch 0.471), train_loss = 2.70705334, grad/param norm = 5.5811e-01, time/batch = 0.6927s	
314/33250 (epoch 0.472), train_loss = 2.58955487, grad/param norm = 5.0039e-01, time/batch = 0.6616s	
315/33250 (epoch 0.474), train_loss = 2.63325610, grad/param norm = 4.8018e-01, time/batch = 0.6649s	
316/33250 (epoch 0.475), train_loss = 2.51356521, grad/param norm = 3.9004e-01, time/batch = 0.6663s	
317/33250 (epoch 0.477), train_loss = 2.53940223, grad/param norm = 4.0783e-01, time/batch = 0.6602s	
318/33250 (epoch 0.478), train_loss = 2.60027099, grad/param norm = 4.7734e-01, time/batch = 0.6757s	
319/33250 (epoch 0.480), train_loss = 2.71097902, grad/param norm = 6.3519e-01, time/batch = 0.6797s	
320/33250 (epoch 0.481), train_loss = 2.55512577, grad/param norm = 7.1004e-01, time/batch = 0.6731s	
321/33250 (epoch 0.483), train_loss = 2.62367545, grad/param norm = 5.3325e-01, time/batch = 0.6847s	
322/33250 (epoch 0.484), train_loss = 2.56090269, grad/param norm = 4.1022e-01, time/batch = 0.6831s	
323/33250 (epoch 0.486), train_loss = 2.51579103, grad/param norm = 4.8814e-01, time/batch = 0.7070s	
324/33250 (epoch 0.487), train_loss = 2.61164150, grad/param norm = 7.5211e-01, time/batch = 0.7043s	
325/33250 (epoch 0.489), train_loss = 2.59363679, grad/param norm = 5.9360e-01, time/batch = 0.6894s	
326/33250 (epoch 0.490), train_loss = 2.55890763, grad/param norm = 3.0717e-01, time/batch = 0.6791s	
327/33250 (epoch 0.492), train_loss = 2.55385894, grad/param norm = 4.0093e-01, time/batch = 0.6827s	
328/33250 (epoch 0.493), train_loss = 2.56370042, grad/param norm = 3.7346e-01, time/batch = 0.6821s	
329/33250 (epoch 0.495), train_loss = 2.56821668, grad/param norm = 3.7587e-01, time/batch = 0.6856s	
330/33250 (epoch 0.496), train_loss = 2.51657089, grad/param norm = 4.4864e-01, time/batch = 0.6827s	
331/33250 (epoch 0.498), train_loss = 2.54819255, grad/param norm = 6.3977e-01, time/batch = 0.6763s	
332/33250 (epoch 0.499), train_loss = 2.60909221, grad/param norm = 8.0623e-01, time/batch = 0.6725s	
333/33250 (epoch 0.501), train_loss = 2.52981066, grad/param norm = 8.8166e-01, time/batch = 0.6658s	
334/33250 (epoch 0.502), train_loss = 2.54649226, grad/param norm = 1.0864e+00, time/batch = 0.6649s	
335/33250 (epoch 0.504), train_loss = 2.63281763, grad/param norm = 6.8976e-01, time/batch = 0.6755s	
336/33250 (epoch 0.505), train_loss = 2.47896737, grad/param norm = 4.0384e-01, time/batch = 0.6675s	
337/33250 (epoch 0.507), train_loss = 2.58026221, grad/param norm = 5.0228e-01, time/batch = 0.6822s	
338/33250 (epoch 0.508), train_loss = 2.46583433, grad/param norm = 5.0653e-01, time/batch = 0.6824s	
339/33250 (epoch 0.510), train_loss = 2.52363536, grad/param norm = 4.7295e-01, time/batch = 0.6868s	
340/33250 (epoch 0.511), train_loss = 2.57862797, grad/param norm = 5.2549e-01, time/batch = 0.6921s	
341/33250 (epoch 0.513), train_loss = 2.70108543, grad/param norm = 4.5330e-01, time/batch = 0.6932s	
342/33250 (epoch 0.514), train_loss = 2.59091548, grad/param norm = 3.9177e-01, time/batch = 0.6952s	
343/33250 (epoch 0.516), train_loss = 2.54140580, grad/param norm = 4.0272e-01, time/batch = 0.6976s	
344/33250 (epoch 0.517), train_loss = 2.60944927, grad/param norm = 4.3810e-01, time/batch = 0.7013s	
345/33250 (epoch 0.519), train_loss = 2.29892158, grad/param norm = 4.7574e-01, time/batch = 0.6915s	
346/33250 (epoch 0.520), train_loss = 2.65716009, grad/param norm = 5.1564e-01, time/batch = 0.6964s	
347/33250 (epoch 0.522), train_loss = 2.58380874, grad/param norm = 4.3475e-01, time/batch = 0.6934s	
348/33250 (epoch 0.523), train_loss = 2.44386621, grad/param norm = 4.4678e-01, time/batch = 0.6882s	
349/33250 (epoch 0.525), train_loss = 2.54245328, grad/param norm = 5.2735e-01, time/batch = 0.6939s	
350/33250 (epoch 0.526), train_loss = 2.49384700, grad/param norm = 6.2733e-01, time/batch = 0.6925s	
351/33250 (epoch 0.528), train_loss = 2.51185792, grad/param norm = 5.4473e-01, time/batch = 0.6874s	
352/33250 (epoch 0.529), train_loss = 2.50181988, grad/param norm = 5.4261e-01, time/batch = 0.6841s	
353/33250 (epoch 0.531), train_loss = 2.37928485, grad/param norm = 6.0754e-01, time/batch = 0.6848s	
354/33250 (epoch 0.532), train_loss = 2.53826114, grad/param norm = 4.4143e-01, time/batch = 0.6842s	
355/33250 (epoch 0.534), train_loss = 2.43537645, grad/param norm = 4.1386e-01, time/batch = 0.6992s	
356/33250 (epoch 0.535), train_loss = 2.50786816, grad/param norm = 5.1400e-01, time/batch = 0.6960s	
357/33250 (epoch 0.537), train_loss = 2.56921216, grad/param norm = 4.9591e-01, time/batch = 0.6922s	
358/33250 (epoch 0.538), train_loss = 2.42574308, grad/param norm = 5.8466e-01, time/batch = 0.6842s	
359/33250 (epoch 0.540), train_loss = 2.59334665, grad/param norm = 5.2177e-01, time/batch = 0.6851s	
360/33250 (epoch 0.541), train_loss = 2.50633934, grad/param norm = 4.0157e-01, time/batch = 0.6864s	
361/33250 (epoch 0.543), train_loss = 2.63204824, grad/param norm = 3.8911e-01, time/batch = 0.6845s	
362/33250 (epoch 0.544), train_loss = 2.60567113, grad/param norm = 3.6810e-01, time/batch = 0.6858s	
363/33250 (epoch 0.546), train_loss = 2.53459256, grad/param norm = 3.7562e-01, time/batch = 0.6807s	
364/33250 (epoch 0.547), train_loss = 2.34034985, grad/param norm = 4.9696e-01, time/batch = 0.6778s	
365/33250 (epoch 0.549), train_loss = 2.54255784, grad/param norm = 5.5623e-01, time/batch = 0.6856s	
366/33250 (epoch 0.550), train_loss = 2.40604375, grad/param norm = 5.8206e-01, time/batch = 0.6814s	
367/33250 (epoch 0.552), train_loss = 2.44015109, grad/param norm = 6.2244e-01, time/batch = 0.6887s	
368/33250 (epoch 0.553), train_loss = 2.40173139, grad/param norm = 6.1117e-01, time/batch = 0.6913s	
369/33250 (epoch 0.555), train_loss = 2.45122086, grad/param norm = 4.9780e-01, time/batch = 0.6878s	
370/33250 (epoch 0.556), train_loss = 2.60744463, grad/param norm = 4.3281e-01, time/batch = 0.6645s	
371/33250 (epoch 0.558), train_loss = 2.60579367, grad/param norm = 4.4084e-01, time/batch = 0.6770s	
372/33250 (epoch 0.559), train_loss = 2.50781206, grad/param norm = 4.7101e-01, time/batch = 0.6895s	
373/33250 (epoch 0.561), train_loss = 2.58773446, grad/param norm = 5.0094e-01, time/batch = 0.6886s	
374/33250 (epoch 0.562), train_loss = 2.60765742, grad/param norm = 7.1117e-01, time/batch = 0.6881s	
375/33250 (epoch 0.564), train_loss = 2.59403850, grad/param norm = 8.7467e-01, time/batch = 0.6878s	
376/33250 (epoch 0.565), train_loss = 2.42848981, grad/param norm = 5.9333e-01, time/batch = 0.6850s	
377/33250 (epoch 0.567), train_loss = 2.45708430, grad/param norm = 4.5872e-01, time/batch = 0.6891s	
378/33250 (epoch 0.568), train_loss = 2.45717862, grad/param norm = 3.6678e-01, time/batch = 0.6830s	
379/33250 (epoch 0.570), train_loss = 2.56206041, grad/param norm = 4.4542e-01, time/batch = 0.6863s	
380/33250 (epoch 0.571), train_loss = 2.59012951, grad/param norm = 4.3151e-01, time/batch = 0.6903s	
381/33250 (epoch 0.573), train_loss = 2.51560067, grad/param norm = 4.3838e-01, time/batch = 0.6939s	
382/33250 (epoch 0.574), train_loss = 2.44188370, grad/param norm = 4.6068e-01, time/batch = 0.7029s	
383/33250 (epoch 0.576), train_loss = 2.60207969, grad/param norm = 4.7163e-01, time/batch = 0.7063s	
384/33250 (epoch 0.577), train_loss = 2.55720728, grad/param norm = 4.6338e-01, time/batch = 0.6892s	
385/33250 (epoch 0.579), train_loss = 2.34417650, grad/param norm = 3.7232e-01, time/batch = 0.6901s	
386/33250 (epoch 0.580), train_loss = 2.41486474, grad/param norm = 3.8091e-01, time/batch = 0.6948s	
387/33250 (epoch 0.582), train_loss = 2.47275421, grad/param norm = 5.3078e-01, time/batch = 0.6933s	
388/33250 (epoch 0.583), train_loss = 2.47095297, grad/param norm = 8.5716e-01, time/batch = 0.6914s	
389/33250 (epoch 0.585), train_loss = 2.48270533, grad/param norm = 6.6773e-01, time/batch = 0.6908s	
390/33250 (epoch 0.586), train_loss = 2.44244510, grad/param norm = 4.0869e-01, time/batch = 0.6945s	
391/33250 (epoch 0.588), train_loss = 2.46276712, grad/param norm = 4.0761e-01, time/batch = 0.6903s	
392/33250 (epoch 0.589), train_loss = 2.62239560, grad/param norm = 5.9042e-01, time/batch = 0.6925s	
393/33250 (epoch 0.591), train_loss = 2.50422135, grad/param norm = 5.5217e-01, time/batch = 0.6887s	
394/33250 (epoch 0.592), train_loss = 2.46209724, grad/param norm = 3.5382e-01, time/batch = 0.6883s	
395/33250 (epoch 0.594), train_loss = 2.59210043, grad/param norm = 3.3097e-01, time/batch = 0.6867s	
396/33250 (epoch 0.595), train_loss = 2.46359967, grad/param norm = 3.3607e-01, time/batch = 0.6833s	
397/33250 (epoch 0.597), train_loss = 2.46439641, grad/param norm = 4.5120e-01, time/batch = 0.6660s	
398/33250 (epoch 0.598), train_loss = 2.43177083, grad/param norm = 4.1478e-01, time/batch = 0.6663s	
399/33250 (epoch 0.600), train_loss = 2.47572332, grad/param norm = 3.6663e-01, time/batch = 0.6659s	
400/33250 (epoch 0.602), train_loss = 2.58763599, grad/param norm = 4.5809e-01, time/batch = 0.6760s	
401/33250 (epoch 0.603), train_loss = 2.36329002, grad/param norm = 5.0454e-01, time/batch = 0.6819s	
402/33250 (epoch 0.605), train_loss = 2.51233409, grad/param norm = 4.7867e-01, time/batch = 0.6865s	
403/33250 (epoch 0.606), train_loss = 2.47714941, grad/param norm = 5.3431e-01, time/batch = 0.6741s	
404/33250 (epoch 0.608), train_loss = 2.45036277, grad/param norm = 4.5151e-01, time/batch = 0.6594s	
405/33250 (epoch 0.609), train_loss = 2.38412998, grad/param norm = 4.2911e-01, time/batch = 0.6632s	
406/33250 (epoch 0.611), train_loss = 2.55088386, grad/param norm = 6.3708e-01, time/batch = 0.6733s	
407/33250 (epoch 0.612), train_loss = 2.67669418, grad/param norm = 6.0683e-01, time/batch = 0.6686s	
408/33250 (epoch 0.614), train_loss = 2.54266400, grad/param norm = 4.9563e-01, time/batch = 0.6634s	
409/33250 (epoch 0.615), train_loss = 2.58842185, grad/param norm = 3.9391e-01, time/batch = 0.6667s	
410/33250 (epoch 0.617), train_loss = 2.67755894, grad/param norm = 3.8351e-01, time/batch = 0.6685s	
411/33250 (epoch 0.618), train_loss = 2.54093994, grad/param norm = 3.0475e-01, time/batch = 0.6712s	
412/33250 (epoch 0.620), train_loss = 2.53844065, grad/param norm = 3.4929e-01, time/batch = 0.6617s	
413/33250 (epoch 0.621), train_loss = 2.32584329, grad/param norm = 4.1029e-01, time/batch = 0.6631s	
414/33250 (epoch 0.623), train_loss = 2.49705265, grad/param norm = 5.3846e-01, time/batch = 0.6697s	
415/33250 (epoch 0.624), train_loss = 2.53953807, grad/param norm = 6.8901e-01, time/batch = 0.6677s	
416/33250 (epoch 0.626), train_loss = 2.43144353, grad/param norm = 6.8248e-01, time/batch = 0.6598s	
417/33250 (epoch 0.627), train_loss = 2.65266595, grad/param norm = 5.2190e-01, time/batch = 0.6799s	
418/33250 (epoch 0.629), train_loss = 2.53260129, grad/param norm = 6.0658e-01, time/batch = 0.6606s	
419/33250 (epoch 0.630), train_loss = 2.53049816, grad/param norm = 4.9974e-01, time/batch = 0.6687s	
420/33250 (epoch 0.632), train_loss = 2.22918569, grad/param norm = 3.4730e-01, time/batch = 0.6738s	
421/33250 (epoch 0.633), train_loss = 2.56925659, grad/param norm = 4.0411e-01, time/batch = 0.6689s	
422/33250 (epoch 0.635), train_loss = 2.31354645, grad/param norm = 4.0443e-01, time/batch = 0.6685s	
423/33250 (epoch 0.636), train_loss = 2.43891963, grad/param norm = 4.4082e-01, time/batch = 0.6667s	
424/33250 (epoch 0.638), train_loss = 2.38783368, grad/param norm = 4.3515e-01, time/batch = 0.6693s	
425/33250 (epoch 0.639), train_loss = 2.55039908, grad/param norm = 4.4502e-01, time/batch = 0.6696s	
426/33250 (epoch 0.641), train_loss = 2.36791520, grad/param norm = 5.4627e-01, time/batch = 0.6692s	
427/33250 (epoch 0.642), train_loss = 2.39771143, grad/param norm = 5.8946e-01, time/batch = 0.6650s	
428/33250 (epoch 0.644), train_loss = 2.38121946, grad/param norm = 6.5179e-01, time/batch = 0.6732s	
429/33250 (epoch 0.645), train_loss = 2.39262684, grad/param norm = 5.8786e-01, time/batch = 0.6885s	
430/33250 (epoch 0.647), train_loss = 2.43709067, grad/param norm = 4.4535e-01, time/batch = 0.6978s	
431/33250 (epoch 0.648), train_loss = 2.40075912, grad/param norm = 4.2677e-01, time/batch = 0.6900s	
432/33250 (epoch 0.650), train_loss = 2.51965765, grad/param norm = 4.2580e-01, time/batch = 0.6883s	
433/33250 (epoch 0.651), train_loss = 2.46850345, grad/param norm = 4.0823e-01, time/batch = 0.6978s	
434/33250 (epoch 0.653), train_loss = 2.28619687, grad/param norm = 3.9111e-01, time/batch = 0.6885s	
435/33250 (epoch 0.654), train_loss = 2.27529473, grad/param norm = 3.9451e-01, time/batch = 0.6890s	
436/33250 (epoch 0.656), train_loss = 2.42360983, grad/param norm = 4.5767e-01, time/batch = 0.6843s	
437/33250 (epoch 0.657), train_loss = 2.37578111, grad/param norm = 4.9119e-01, time/batch = 0.6701s	
438/33250 (epoch 0.659), train_loss = 2.21816692, grad/param norm = 4.9206e-01, time/batch = 0.6693s	
439/33250 (epoch 0.660), train_loss = 2.37153136, grad/param norm = 4.1228e-01, time/batch = 0.6663s	
440/33250 (epoch 0.662), train_loss = 2.46341446, grad/param norm = 4.2398e-01, time/batch = 0.6751s	
441/33250 (epoch 0.663), train_loss = 2.25570437, grad/param norm = 3.0818e-01, time/batch = 0.6860s	
442/33250 (epoch 0.665), train_loss = 2.49809339, grad/param norm = 4.4962e-01, time/batch = 0.6903s	
443/33250 (epoch 0.666), train_loss = 2.38731514, grad/param norm = 4.9377e-01, time/batch = 0.6901s	
444/33250 (epoch 0.668), train_loss = 2.48302101, grad/param norm = 4.8796e-01, time/batch = 0.6737s	
445/33250 (epoch 0.669), train_loss = 2.56264768, grad/param norm = 4.9155e-01, time/batch = 0.6766s	
446/33250 (epoch 0.671), train_loss = 2.44810039, grad/param norm = 4.8022e-01, time/batch = 0.6693s	
447/33250 (epoch 0.672), train_loss = 2.41892974, grad/param norm = 5.2577e-01, time/batch = 0.6663s	
448/33250 (epoch 0.674), train_loss = 2.36367109, grad/param norm = 4.9199e-01, time/batch = 0.6684s	
449/33250 (epoch 0.675), train_loss = 2.36989205, grad/param norm = 3.6892e-01, time/batch = 0.6658s	
450/33250 (epoch 0.677), train_loss = 2.39809578, grad/param norm = 4.1421e-01, time/batch = 0.6670s	
451/33250 (epoch 0.678), train_loss = 2.55420386, grad/param norm = 4.4461e-01, time/batch = 0.6698s	
452/33250 (epoch 0.680), train_loss = 2.45897374, grad/param norm = 3.7772e-01, time/batch = 0.6671s	
453/33250 (epoch 0.681), train_loss = 2.25676846, grad/param norm = 4.4734e-01, time/batch = 0.6701s	
454/33250 (epoch 0.683), train_loss = 2.40379003, grad/param norm = 3.9241e-01, time/batch = 0.6709s	
455/33250 (epoch 0.684), train_loss = 2.41303213, grad/param norm = 3.6041e-01, time/batch = 0.6664s	
456/33250 (epoch 0.686), train_loss = 2.30750438, grad/param norm = 3.3973e-01, time/batch = 0.6620s	
457/33250 (epoch 0.687), train_loss = 2.24576163, grad/param norm = 3.8818e-01, time/batch = 0.6675s	
458/33250 (epoch 0.689), train_loss = 2.29541988, grad/param norm = 4.7342e-01, time/batch = 0.6735s	
459/33250 (epoch 0.690), train_loss = 2.44423023, grad/param norm = 5.4694e-01, time/batch = 0.6667s	
460/33250 (epoch 0.692), train_loss = 2.49380434, grad/param norm = 6.4598e-01, time/batch = 0.6662s	
461/33250 (epoch 0.693), train_loss = 2.31881498, grad/param norm = 3.7109e-01, time/batch = 0.6689s	
462/33250 (epoch 0.695), train_loss = 2.55941155, grad/param norm = 3.1957e-01, time/batch = 0.6694s	
463/33250 (epoch 0.696), train_loss = 2.37223676, grad/param norm = 3.2296e-01, time/batch = 0.6630s	
464/33250 (epoch 0.698), train_loss = 2.16863809, grad/param norm = 3.3754e-01, time/batch = 0.6660s	
465/33250 (epoch 0.699), train_loss = 2.35447017, grad/param norm = 3.8939e-01, time/batch = 0.6701s	
466/33250 (epoch 0.701), train_loss = 2.36450663, grad/param norm = 4.3420e-01, time/batch = 0.6677s	
467/33250 (epoch 0.702), train_loss = 2.49034051, grad/param norm = 5.6102e-01, time/batch = 0.6731s	
468/33250 (epoch 0.704), train_loss = 2.50413591, grad/param norm = 6.3363e-01, time/batch = 0.6739s	
469/33250 (epoch 0.705), train_loss = 2.45314620, grad/param norm = 6.8111e-01, time/batch = 0.6763s	
470/33250 (epoch 0.707), train_loss = 2.33196534, grad/param norm = 4.4125e-01, time/batch = 0.6761s	
471/33250 (epoch 0.708), train_loss = 2.29197718, grad/param norm = 3.3052e-01, time/batch = 0.6787s	
472/33250 (epoch 0.710), train_loss = 2.44712410, grad/param norm = 4.1374e-01, time/batch = 0.6825s	
473/33250 (epoch 0.711), train_loss = 2.43210830, grad/param norm = 4.0196e-01, time/batch = 0.6798s	
474/33250 (epoch 0.713), train_loss = 2.37742951, grad/param norm = 2.8111e-01, time/batch = 0.6723s	
475/33250 (epoch 0.714), train_loss = 2.41247673, grad/param norm = 2.8777e-01, time/batch = 0.6800s	
476/33250 (epoch 0.716), train_loss = 2.33302637, grad/param norm = 4.0490e-01, time/batch = 0.6908s	
477/33250 (epoch 0.717), train_loss = 2.22146242, grad/param norm = 4.3880e-01, time/batch = 0.6896s	
478/33250 (epoch 0.719), train_loss = 2.49205009, grad/param norm = 3.2598e-01, time/batch = 0.6923s	
479/33250 (epoch 0.720), train_loss = 2.52196432, grad/param norm = 4.1754e-01, time/batch = 0.6907s	
480/33250 (epoch 0.722), train_loss = 2.29978252, grad/param norm = 4.4708e-01, time/batch = 0.6910s	
481/33250 (epoch 0.723), train_loss = 2.32915886, grad/param norm = 4.7790e-01, time/batch = 0.6940s	
482/33250 (epoch 0.725), train_loss = 2.07095442, grad/param norm = 5.6364e-01, time/batch = 0.6888s	
483/33250 (epoch 0.726), train_loss = 2.33533178, grad/param norm = 5.2076e-01, time/batch = 0.6875s	
484/33250 (epoch 0.728), train_loss = 2.43807743, grad/param norm = 5.6179e-01, time/batch = 0.6786s	
485/33250 (epoch 0.729), train_loss = 2.36688049, grad/param norm = 6.0323e-01, time/batch = 0.6987s	
486/33250 (epoch 0.731), train_loss = 2.36022029, grad/param norm = 5.3077e-01, time/batch = 0.6792s	
487/33250 (epoch 0.732), train_loss = 2.27551312, grad/param norm = 3.7958e-01, time/batch = 0.6660s	
488/33250 (epoch 0.734), train_loss = 2.28726081, grad/param norm = 4.7005e-01, time/batch = 0.6814s	
489/33250 (epoch 0.735), train_loss = 2.32296893, grad/param norm = 5.2633e-01, time/batch = 0.6850s	
490/33250 (epoch 0.737), train_loss = 2.43085114, grad/param norm = 3.8608e-01, time/batch = 0.6883s	
491/33250 (epoch 0.738), train_loss = 2.31659006, grad/param norm = 3.8654e-01, time/batch = 0.6931s	
492/33250 (epoch 0.740), train_loss = 2.60257334, grad/param norm = 4.1508e-01, time/batch = 0.6865s	
493/33250 (epoch 0.741), train_loss = 2.25361816, grad/param norm = 4.8880e-01, time/batch = 0.6772s	
494/33250 (epoch 0.743), train_loss = 2.37623398, grad/param norm = 4.3015e-01, time/batch = 0.6671s	
495/33250 (epoch 0.744), train_loss = 2.29248734, grad/param norm = 2.9875e-01, time/batch = 0.6538s	
496/33250 (epoch 0.746), train_loss = 2.40309897, grad/param norm = 3.2239e-01, time/batch = 0.6405s	
497/33250 (epoch 0.747), train_loss = 2.29063287, grad/param norm = 3.6510e-01, time/batch = 0.6518s	
498/33250 (epoch 0.749), train_loss = 2.38002767, grad/param norm = 4.3639e-01, time/batch = 0.6465s	
499/33250 (epoch 0.750), train_loss = 2.28991442, grad/param norm = 5.1972e-01, time/batch = 0.6469s	
500/33250 (epoch 0.752), train_loss = 2.29572021, grad/param norm = 5.6404e-01, time/batch = 0.6459s	
501/33250 (epoch 0.753), train_loss = 2.40220236, grad/param norm = 5.1145e-01, time/batch = 0.6413s	
502/33250 (epoch 0.755), train_loss = 2.23812128, grad/param norm = 4.5515e-01, time/batch = 0.6497s	
503/33250 (epoch 0.756), train_loss = 2.37690374, grad/param norm = 3.8685e-01, time/batch = 0.6439s	
504/33250 (epoch 0.758), train_loss = 2.30243358, grad/param norm = 3.7224e-01, time/batch = 0.6433s	
505/33250 (epoch 0.759), train_loss = 2.19079565, grad/param norm = 3.3810e-01, time/batch = 0.6433s	
506/33250 (epoch 0.761), train_loss = 2.33805619, grad/param norm = 4.3405e-01, time/batch = 0.6516s	
507/33250 (epoch 0.762), train_loss = 2.37419519, grad/param norm = 3.9610e-01, time/batch = 0.6561s	
508/33250 (epoch 0.764), train_loss = 2.24848160, grad/param norm = 3.5744e-01, time/batch = 0.6535s	
509/33250 (epoch 0.765), train_loss = 2.28463688, grad/param norm = 3.8690e-01, time/batch = 0.6519s	
510/33250 (epoch 0.767), train_loss = 2.27064159, grad/param norm = 4.4896e-01, time/batch = 0.6542s	
511/33250 (epoch 0.768), train_loss = 2.40959636, grad/param norm = 5.1613e-01, time/batch = 0.6609s	
512/33250 (epoch 0.770), train_loss = 2.25161363, grad/param norm = 5.1673e-01, time/batch = 0.6576s	
513/33250 (epoch 0.771), train_loss = 2.32473021, grad/param norm = 3.7835e-01, time/batch = 0.6620s	
514/33250 (epoch 0.773), train_loss = 2.25154109, grad/param norm = 4.1469e-01, time/batch = 0.6572s	
515/33250 (epoch 0.774), train_loss = 2.11351664, grad/param norm = 4.5096e-01, time/batch = 0.6566s	
516/33250 (epoch 0.776), train_loss = 2.35406474, grad/param norm = 6.0829e-01, time/batch = 0.6611s	
517/33250 (epoch 0.777), train_loss = 2.47915264, grad/param norm = 4.9742e-01, time/batch = 0.6739s	
518/33250 (epoch 0.779), train_loss = 2.12585652, grad/param norm = 3.3848e-01, time/batch = 0.6860s	
519/33250 (epoch 0.780), train_loss = 2.40413349, grad/param norm = 3.3557e-01, time/batch = 0.6873s	
520/33250 (epoch 0.782), train_loss = 2.46892587, grad/param norm = 3.7345e-01, time/batch = 0.6760s	
521/33250 (epoch 0.783), train_loss = 2.21343495, grad/param norm = 5.2996e-01, time/batch = 0.6668s	
522/33250 (epoch 0.785), train_loss = 2.25227801, grad/param norm = 4.9649e-01, time/batch = 0.6593s	
523/33250 (epoch 0.786), train_loss = 2.40261790, grad/param norm = 4.2788e-01, time/batch = 0.6623s	
524/33250 (epoch 0.788), train_loss = 2.30028755, grad/param norm = 3.8804e-01, time/batch = 0.6707s	
525/33250 (epoch 0.789), train_loss = 2.21504141, grad/param norm = 4.0039e-01, time/batch = 0.6654s	
526/33250 (epoch 0.791), train_loss = 2.45025024, grad/param norm = 4.8328e-01, time/batch = 0.6661s	
527/33250 (epoch 0.792), train_loss = 2.43808907, grad/param norm = 3.9380e-01, time/batch = 0.6707s	
528/33250 (epoch 0.794), train_loss = 2.13750450, grad/param norm = 4.0176e-01, time/batch = 0.6563s	
529/33250 (epoch 0.795), train_loss = 2.40582797, grad/param norm = 4.8405e-01, time/batch = 0.6593s	
530/33250 (epoch 0.797), train_loss = 2.39863716, grad/param norm = 4.6337e-01, time/batch = 0.6696s	
531/33250 (epoch 0.798), train_loss = 2.44534822, grad/param norm = 5.4771e-01, time/batch = 0.6682s	
532/33250 (epoch 0.800), train_loss = 2.38209562, grad/param norm = 4.5694e-01, time/batch = 0.6818s	
533/33250 (epoch 0.802), train_loss = 2.16057736, grad/param norm = 3.5715e-01, time/batch = 0.6692s	
534/33250 (epoch 0.803), train_loss = 2.26620681, grad/param norm = 3.7301e-01, time/batch = 0.6625s	
535/33250 (epoch 0.805), train_loss = 2.22744689, grad/param norm = 3.1127e-01, time/batch = 0.6621s	
536/33250 (epoch 0.806), train_loss = 2.35695621, grad/param norm = 3.2464e-01, time/batch = 0.6715s	
537/33250 (epoch 0.808), train_loss = 2.30474204, grad/param norm = 3.4261e-01, time/batch = 0.6616s	
538/33250 (epoch 0.809), train_loss = 2.07987741, grad/param norm = 3.2764e-01, time/batch = 0.6607s	
539/33250 (epoch 0.811), train_loss = 2.33858510, grad/param norm = 4.4118e-01, time/batch = 0.6605s	
540/33250 (epoch 0.812), train_loss = 2.20594894, grad/param norm = 5.9834e-01, time/batch = 0.6728s	
541/33250 (epoch 0.814), train_loss = 2.24761670, grad/param norm = 3.8450e-01, time/batch = 0.6671s	
542/33250 (epoch 0.815), train_loss = 2.34134012, grad/param norm = 3.9185e-01, time/batch = 0.6735s	
543/33250 (epoch 0.817), train_loss = 2.28619832, grad/param norm = 3.2536e-01, time/batch = 0.6707s	
544/33250 (epoch 0.818), train_loss = 2.16293616, grad/param norm = 2.8885e-01, time/batch = 0.6735s	
545/33250 (epoch 0.820), train_loss = 2.18485001, grad/param norm = 3.9454e-01, time/batch = 0.6770s	
546/33250 (epoch 0.821), train_loss = 2.16314994, grad/param norm = 4.8112e-01, time/batch = 0.6843s	
547/33250 (epoch 0.823), train_loss = 2.40113064, grad/param norm = 4.4935e-01, time/batch = 0.6744s	
548/33250 (epoch 0.824), train_loss = 2.22390086, grad/param norm = 3.1142e-01, time/batch = 0.6733s	
549/33250 (epoch 0.826), train_loss = 2.18734342, grad/param norm = 3.4775e-01, time/batch = 0.6704s	
550/33250 (epoch 0.827), train_loss = 2.12504906, grad/param norm = 3.2979e-01, time/batch = 0.6731s	
551/33250 (epoch 0.829), train_loss = 2.24338096, grad/param norm = 3.1213e-01, time/batch = 0.6782s	
552/33250 (epoch 0.830), train_loss = 2.56227994, grad/param norm = 4.6750e-01, time/batch = 0.6721s	
553/33250 (epoch 0.832), train_loss = 2.23263214, grad/param norm = 4.2400e-01, time/batch = 0.6862s	
554/33250 (epoch 0.833), train_loss = 2.28521892, grad/param norm = 4.8351e-01, time/batch = 0.6808s	
555/33250 (epoch 0.835), train_loss = 2.32532860, grad/param norm = 5.6440e-01, time/batch = 0.6681s	
556/33250 (epoch 0.836), train_loss = 2.23217486, grad/param norm = 5.1905e-01, time/batch = 0.6572s	
557/33250 (epoch 0.838), train_loss = 2.14406767, grad/param norm = 4.4192e-01, time/batch = 0.6674s	
558/33250 (epoch 0.839), train_loss = 2.26738928, grad/param norm = 4.8141e-01, time/batch = 0.6629s	
559/33250 (epoch 0.841), train_loss = 2.17864221, grad/param norm = 4.0680e-01, time/batch = 0.6611s	
560/33250 (epoch 0.842), train_loss = 2.19530994, grad/param norm = 3.1043e-01, time/batch = 0.6554s	
561/33250 (epoch 0.844), train_loss = 2.37718079, grad/param norm = 3.1620e-01, time/batch = 0.6636s	
562/33250 (epoch 0.845), train_loss = 2.40987864, grad/param norm = 4.3524e-01, time/batch = 0.6708s	
563/33250 (epoch 0.847), train_loss = 2.26869551, grad/param norm = 3.9627e-01, time/batch = 0.6659s	
564/33250 (epoch 0.848), train_loss = 2.34039471, grad/param norm = 3.5145e-01, time/batch = 0.6590s	
565/33250 (epoch 0.850), train_loss = 2.29624419, grad/param norm = 3.3408e-01, time/batch = 0.6777s	
566/33250 (epoch 0.851), train_loss = 2.14482573, grad/param norm = 4.1068e-01, time/batch = 0.6780s	
567/33250 (epoch 0.853), train_loss = 2.27173822, grad/param norm = 4.7154e-01, time/batch = 0.6738s	
568/33250 (epoch 0.854), train_loss = 2.12006213, grad/param norm = 4.1493e-01, time/batch = 0.6741s	
569/33250 (epoch 0.856), train_loss = 2.19955111, grad/param norm = 3.5982e-01, time/batch = 0.6808s	
570/33250 (epoch 0.857), train_loss = 1.96384454, grad/param norm = 3.3710e-01, time/batch = 0.6788s	
571/33250 (epoch 0.859), train_loss = 2.08175332, grad/param norm = 4.2270e-01, time/batch = 0.6794s	
572/33250 (epoch 0.860), train_loss = 2.09148738, grad/param norm = 4.1453e-01, time/batch = 0.6991s	
573/33250 (epoch 0.862), train_loss = 2.16931460, grad/param norm = 3.3516e-01, time/batch = 0.6959s	
574/33250 (epoch 0.863), train_loss = 2.10883431, grad/param norm = 2.7185e-01, time/batch = 0.6873s	
575/33250 (epoch 0.865), train_loss = 2.22013674, grad/param norm = 3.6144e-01, time/batch = 0.6842s	
576/33250 (epoch 0.866), train_loss = 2.23995572, grad/param norm = 3.9466e-01, time/batch = 0.6816s	
577/33250 (epoch 0.868), train_loss = 2.57602188, grad/param norm = 4.2528e-01, time/batch = 0.6758s	
578/33250 (epoch 0.869), train_loss = 2.32920340, grad/param norm = 3.7662e-01, time/batch = 0.6631s	
579/33250 (epoch 0.871), train_loss = 1.93547272, grad/param norm = 4.7480e-01, time/batch = 0.6723s	
580/33250 (epoch 0.872), train_loss = 2.32798891, grad/param norm = 4.0751e-01, time/batch = 0.6730s	
581/33250 (epoch 0.874), train_loss = 2.25225004, grad/param norm = 4.0290e-01, time/batch = 0.6771s	
582/33250 (epoch 0.875), train_loss = 2.14160350, grad/param norm = 4.1090e-01, time/batch = 0.6683s	
583/33250 (epoch 0.877), train_loss = 2.19343020, grad/param norm = 3.5309e-01, time/batch = 0.6747s	
584/33250 (epoch 0.878), train_loss = 2.14122235, grad/param norm = 2.7369e-01, time/batch = 0.6734s	
585/33250 (epoch 0.880), train_loss = 2.37633603, grad/param norm = 3.1948e-01, time/batch = 0.6671s	
586/33250 (epoch 0.881), train_loss = 2.28192208, grad/param norm = 4.4211e-01, time/batch = 0.6759s	
587/33250 (epoch 0.883), train_loss = 2.29882788, grad/param norm = 4.9335e-01, time/batch = 0.6636s	
588/33250 (epoch 0.884), train_loss = 2.09939218, grad/param norm = 4.9184e-01, time/batch = 0.6725s	
589/33250 (epoch 0.886), train_loss = 2.13758233, grad/param norm = 3.7503e-01, time/batch = 0.6646s	
590/33250 (epoch 0.887), train_loss = 2.19477941, grad/param norm = 3.7802e-01, time/batch = 0.6553s	
591/33250 (epoch 0.889), train_loss = 2.00777170, grad/param norm = 3.3198e-01, time/batch = 0.6644s	
592/33250 (epoch 0.890), train_loss = 2.10442039, grad/param norm = 3.7334e-01, time/batch = 0.6653s	
593/33250 (epoch 0.892), train_loss = 2.28737138, grad/param norm = 3.7695e-01, time/batch = 0.6638s	
594/33250 (epoch 0.893), train_loss = 2.21049814, grad/param norm = 3.3172e-01, time/batch = 0.6662s	
595/33250 (epoch 0.895), train_loss = 2.26501666, grad/param norm = 3.8996e-01, time/batch = 0.6632s	
596/33250 (epoch 0.896), train_loss = 2.26643156, grad/param norm = 3.4112e-01, time/batch = 0.6609s	
597/33250 (epoch 0.898), train_loss = 2.19269867, grad/param norm = 3.1457e-01, time/batch = 0.6603s	
598/33250 (epoch 0.899), train_loss = 2.25435007, grad/param norm = 3.7057e-01, time/batch = 0.6621s	
599/33250 (epoch 0.901), train_loss = 2.08126481, grad/param norm = 3.2562e-01, time/batch = 0.6633s	
600/33250 (epoch 0.902), train_loss = 2.09881507, grad/param norm = 3.5538e-01, time/batch = 0.6804s	
601/33250 (epoch 0.904), train_loss = 2.21681112, grad/param norm = 4.6968e-01, time/batch = 0.6754s	
602/33250 (epoch 0.905), train_loss = 2.16079737, grad/param norm = 3.8990e-01, time/batch = 0.6695s	
603/33250 (epoch 0.907), train_loss = 2.21632210, grad/param norm = 4.1566e-01, time/batch = 0.6639s	
604/33250 (epoch 0.908), train_loss = 2.21380921, grad/param norm = 4.8939e-01, time/batch = 0.6588s	
605/33250 (epoch 0.910), train_loss = 2.32684699, grad/param norm = 4.8606e-01, time/batch = 0.6609s	
606/33250 (epoch 0.911), train_loss = 2.10206296, grad/param norm = 4.0216e-01, time/batch = 0.6755s	
607/33250 (epoch 0.913), train_loss = 2.10642506, grad/param norm = 3.3915e-01, time/batch = 0.6850s	
608/33250 (epoch 0.914), train_loss = 2.06069916, grad/param norm = 4.0502e-01, time/batch = 0.6944s	
609/33250 (epoch 0.916), train_loss = 2.08596806, grad/param norm = 4.1664e-01, time/batch = 0.6782s	
610/33250 (epoch 0.917), train_loss = 2.19637168, grad/param norm = 3.5770e-01, time/batch = 0.6962s	
611/33250 (epoch 0.919), train_loss = 2.25661412, grad/param norm = 3.6609e-01, time/batch = 0.6808s	
612/33250 (epoch 0.920), train_loss = 2.15581081, grad/param norm = 3.6727e-01, time/batch = 0.6691s	
613/33250 (epoch 0.922), train_loss = 2.18155920, grad/param norm = 3.7409e-01, time/batch = 0.6761s	
614/33250 (epoch 0.923), train_loss = 2.26029447, grad/param norm = 3.9722e-01, time/batch = 0.6770s	
615/33250 (epoch 0.925), train_loss = 2.09272947, grad/param norm = 3.6552e-01, time/batch = 0.6679s	
616/33250 (epoch 0.926), train_loss = 2.20399653, grad/param norm = 5.0566e-01, time/batch = 0.6609s	
617/33250 (epoch 0.928), train_loss = 2.31822618, grad/param norm = 6.1411e-01, time/batch = 0.6694s	
618/33250 (epoch 0.929), train_loss = 1.85883268, grad/param norm = 4.1532e-01, time/batch = 0.6637s	
619/33250 (epoch 0.931), train_loss = 2.12737142, grad/param norm = 3.3725e-01, time/batch = 0.6650s	
620/33250 (epoch 0.932), train_loss = 2.25164303, grad/param norm = 2.9378e-01, time/batch = 0.6661s	
621/33250 (epoch 0.934), train_loss = 2.10353844, grad/param norm = 2.8142e-01, time/batch = 0.6708s	
622/33250 (epoch 0.935), train_loss = 2.13549438, grad/param norm = 3.2093e-01, time/batch = 0.6852s	
623/33250 (epoch 0.937), train_loss = 2.13303972, grad/param norm = 3.1791e-01, time/batch = 0.6814s	
624/33250 (epoch 0.938), train_loss = 2.28563274, grad/param norm = 3.4458e-01, time/batch = 0.6683s	
625/33250 (epoch 0.940), train_loss = 2.19889017, grad/param norm = 3.8133e-01, time/batch = 0.6748s	
626/33250 (epoch 0.941), train_loss = 2.30091988, grad/param norm = 5.7907e-01, time/batch = 0.6663s	
627/33250 (epoch 0.943), train_loss = 2.25343878, grad/param norm = 4.4942e-01, time/batch = 0.6664s	
628/33250 (epoch 0.944), train_loss = 2.08443205, grad/param norm = 4.2161e-01, time/batch = 0.6724s	
629/33250 (epoch 0.946), train_loss = 2.37983278, grad/param norm = 3.6179e-01, time/batch = 0.6696s	
630/33250 (epoch 0.947), train_loss = 2.14634753, grad/param norm = 3.4629e-01, time/batch = 0.6802s	
631/33250 (epoch 0.949), train_loss = 2.40988741, grad/param norm = 3.6587e-01, time/batch = 0.6629s	
632/33250 (epoch 0.950), train_loss = 2.19022750, grad/param norm = 3.9037e-01, time/batch = 0.6650s	
633/33250 (epoch 0.952), train_loss = 2.27086580, grad/param norm = 3.9709e-01, time/batch = 0.6633s	
634/33250 (epoch 0.953), train_loss = 2.16664584, grad/param norm = 4.0674e-01, time/batch = 0.6642s	
635/33250 (epoch 0.955), train_loss = 2.29751513, grad/param norm = 3.9376e-01, time/batch = 0.6660s	
636/33250 (epoch 0.956), train_loss = 2.34375610, grad/param norm = 3.7316e-01, time/batch = 0.6737s	
637/33250 (epoch 0.958), train_loss = 2.16864660, grad/param norm = 3.4767e-01, time/batch = 0.6644s	
638/33250 (epoch 0.959), train_loss = 2.07501810, grad/param norm = 3.7533e-01, time/batch = 0.6874s	
639/33250 (epoch 0.961), train_loss = 2.16792375, grad/param norm = 4.1043e-01, time/batch = 0.6826s	
640/33250 (epoch 0.962), train_loss = 2.30038713, grad/param norm = 4.6304e-01, time/batch = 0.6753s	
641/33250 (epoch 0.964), train_loss = 2.19960334, grad/param norm = 4.0745e-01, time/batch = 0.6712s	
642/33250 (epoch 0.965), train_loss = 2.27499237, grad/param norm = 3.5695e-01, time/batch = 0.6728s	
643/33250 (epoch 0.967), train_loss = 2.24042021, grad/param norm = 3.0357e-01, time/batch = 0.6725s	
644/33250 (epoch 0.968), train_loss = 2.18573109, grad/param norm = 2.9666e-01, time/batch = 0.6643s	
645/33250 (epoch 0.970), train_loss = 2.37051834, grad/param norm = 4.2361e-01, time/batch = 0.6709s	
646/33250 (epoch 0.971), train_loss = 2.32987983, grad/param norm = 3.6346e-01, time/batch = 0.6601s	
647/33250 (epoch 0.973), train_loss = 2.11383965, grad/param norm = 3.0272e-01, time/batch = 0.6644s	
648/33250 (epoch 0.974), train_loss = 2.18786772, grad/param norm = 3.2603e-01, time/batch = 0.6636s	
649/33250 (epoch 0.976), train_loss = 2.05953254, grad/param norm = 3.3184e-01, time/batch = 0.6605s	
650/33250 (epoch 0.977), train_loss = 1.96010944, grad/param norm = 3.7347e-01, time/batch = 0.6613s	
651/33250 (epoch 0.979), train_loss = 2.07915308, grad/param norm = 4.3101e-01, time/batch = 0.6699s	
652/33250 (epoch 0.980), train_loss = 2.10943499, grad/param norm = 5.1837e-01, time/batch = 0.6665s	
653/33250 (epoch 0.982), train_loss = 2.07044183, grad/param norm = 3.8483e-01, time/batch = 0.6659s	
654/33250 (epoch 0.983), train_loss = 2.25602200, grad/param norm = 3.3883e-01, time/batch = 0.6685s	
655/33250 (epoch 0.985), train_loss = 2.06108308, grad/param norm = 3.0536e-01, time/batch = 0.6651s	
656/33250 (epoch 0.986), train_loss = 2.37529220, grad/param norm = 3.1208e-01, time/batch = 0.6615s	
657/33250 (epoch 0.988), train_loss = 2.09095106, grad/param norm = 3.4860e-01, time/batch = 0.6635s	
658/33250 (epoch 0.989), train_loss = 2.14493906, grad/param norm = 3.1509e-01, time/batch = 0.6696s	
659/33250 (epoch 0.991), train_loss = 2.17145343, grad/param norm = 3.4678e-01, time/batch = 0.6629s	
660/33250 (epoch 0.992), train_loss = 2.12465914, grad/param norm = 3.7555e-01, time/batch = 0.6566s	
661/33250 (epoch 0.994), train_loss = 2.02574672, grad/param norm = 4.0253e-01, time/batch = 0.6688s	
662/33250 (epoch 0.995), train_loss = 2.14365378, grad/param norm = 3.4439e-01, time/batch = 0.6657s	
663/33250 (epoch 0.997), train_loss = 1.87612587, grad/param norm = 3.3588e-01, time/batch = 0.6657s	
664/33250 (epoch 0.998), train_loss = 2.12523459, grad/param norm = 3.3487e-01, time/batch = 0.6676s	
665/33250 (epoch 1.000), train_loss = 2.16120003, grad/param norm = 3.1388e-01, time/batch = 0.6665s	
666/33250 (epoch 1.002), train_loss = 2.22318722, grad/param norm = 3.1036e-01, time/batch = 0.6669s	
667/33250 (epoch 1.003), train_loss = 2.15272357, grad/param norm = 3.5778e-01, time/batch = 0.6586s	
668/33250 (epoch 1.005), train_loss = 2.07062183, grad/param norm = 3.5768e-01, time/batch = 0.6639s	
669/33250 (epoch 1.006), train_loss = 1.95773756, grad/param norm = 3.1888e-01, time/batch = 0.6641s	
670/33250 (epoch 1.008), train_loss = 2.20486590, grad/param norm = 3.5040e-01, time/batch = 0.6631s	
671/33250 (epoch 1.009), train_loss = 2.19081535, grad/param norm = 3.1056e-01, time/batch = 0.6679s	
672/33250 (epoch 1.011), train_loss = 2.17628588, grad/param norm = 3.2711e-01, time/batch = 0.6619s	
673/33250 (epoch 1.012), train_loss = 2.30453347, grad/param norm = 3.7405e-01, time/batch = 0.6625s	
674/33250 (epoch 1.014), train_loss = 2.05916533, grad/param norm = 3.0733e-01, time/batch = 0.6654s	
675/33250 (epoch 1.015), train_loss = 2.20434326, grad/param norm = 3.5518e-01, time/batch = 0.6686s	
676/33250 (epoch 1.017), train_loss = 2.16361617, grad/param norm = 3.7943e-01, time/batch = 0.6609s	
677/33250 (epoch 1.018), train_loss = 2.09739464, grad/param norm = 3.8993e-01, time/batch = 0.6581s	
678/33250 (epoch 1.020), train_loss = 1.99949696, grad/param norm = 3.3709e-01, time/batch = 0.6599s	
679/33250 (epoch 1.021), train_loss = 2.15545420, grad/param norm = 3.0483e-01, time/batch = 0.6626s	
680/33250 (epoch 1.023), train_loss = 2.06708450, grad/param norm = 3.8355e-01, time/batch = 0.6628s	
681/33250 (epoch 1.024), train_loss = 2.17095270, grad/param norm = 4.4041e-01, time/batch = 0.6664s	
682/33250 (epoch 1.026), train_loss = 2.05198130, grad/param norm = 4.0912e-01, time/batch = 0.6616s	
683/33250 (epoch 1.027), train_loss = 2.13940756, grad/param norm = 4.6684e-01, time/batch = 0.6641s	
684/33250 (epoch 1.029), train_loss = 2.16354346, grad/param norm = 4.5559e-01, time/batch = 0.6628s	
685/33250 (epoch 1.030), train_loss = 2.23724719, grad/param norm = 3.9010e-01, time/batch = 0.6763s	
686/33250 (epoch 1.032), train_loss = 2.27615828, grad/param norm = 3.7732e-01, time/batch = 0.6624s	
687/33250 (epoch 1.033), train_loss = 2.10227772, grad/param norm = 3.8780e-01, time/batch = 0.6634s	
688/33250 (epoch 1.035), train_loss = 2.01508514, grad/param norm = 3.1510e-01, time/batch = 0.6620s	
689/33250 (epoch 1.036), train_loss = 2.04772040, grad/param norm = 2.9147e-01, time/batch = 0.6575s	
690/33250 (epoch 1.038), train_loss = 1.98975632, grad/param norm = 3.5827e-01, time/batch = 0.6629s	
691/33250 (epoch 1.039), train_loss = 2.03739277, grad/param norm = 4.2688e-01, time/batch = 0.6685s	
692/33250 (epoch 1.041), train_loss = 2.28820962, grad/param norm = 3.3175e-01, time/batch = 0.6658s	
693/33250 (epoch 1.042), train_loss = 1.91869767, grad/param norm = 3.0879e-01, time/batch = 0.6697s	
694/33250 (epoch 1.044), train_loss = 2.28043161, grad/param norm = 3.0055e-01, time/batch = 0.6680s	
695/33250 (epoch 1.045), train_loss = 2.11606465, grad/param norm = 2.9396e-01, time/batch = 0.6630s	
696/33250 (epoch 1.047), train_loss = 2.27491775, grad/param norm = 2.8896e-01, time/batch = 0.6841s	
697/33250 (epoch 1.048), train_loss = 2.24839256, grad/param norm = 3.2324e-01, time/batch = 0.6865s	
698/33250 (epoch 1.050), train_loss = 2.17141910, grad/param norm = 3.6622e-01, time/batch = 0.6843s	
699/33250 (epoch 1.051), train_loss = 2.06272347, grad/param norm = 3.8798e-01, time/batch = 0.6671s	
700/33250 (epoch 1.053), train_loss = 2.24529722, grad/param norm = 3.6376e-01, time/batch = 0.6879s	
701/33250 (epoch 1.054), train_loss = 1.94860363, grad/param norm = 3.7391e-01, time/batch = 0.6710s	
702/33250 (epoch 1.056), train_loss = 2.16269460, grad/param norm = 4.5345e-01, time/batch = 0.6700s	
703/33250 (epoch 1.057), train_loss = 2.11908389, grad/param norm = 4.0069e-01, time/batch = 0.6930s	
704/33250 (epoch 1.059), train_loss = 2.03819685, grad/param norm = 3.6911e-01, time/batch = 0.6949s	
705/33250 (epoch 1.060), train_loss = 2.20806290, grad/param norm = 4.0419e-01, time/batch = 0.6789s	
706/33250 (epoch 1.062), train_loss = 2.20794116, grad/param norm = 3.4740e-01, time/batch = 0.6649s	
707/33250 (epoch 1.063), train_loss = 2.21405839, grad/param norm = 2.9772e-01, time/batch = 0.6623s	
708/33250 (epoch 1.065), train_loss = 2.20226629, grad/param norm = 2.9062e-01, time/batch = 0.6608s	
709/33250 (epoch 1.066), train_loss = 2.22563360, grad/param norm = 2.7638e-01, time/batch = 0.6751s	
710/33250 (epoch 1.068), train_loss = 2.05865675, grad/param norm = 2.7661e-01, time/batch = 0.6759s	
711/33250 (epoch 1.069), train_loss = 2.10111122, grad/param norm = 2.8939e-01, time/batch = 0.6729s	
712/33250 (epoch 1.071), train_loss = 2.04622560, grad/param norm = 3.3810e-01, time/batch = 0.6595s	
713/33250 (epoch 1.072), train_loss = 2.05974511, grad/param norm = 3.1370e-01, time/batch = 0.6602s	
714/33250 (epoch 1.074), train_loss = 2.06062721, grad/param norm = 2.9908e-01, time/batch = 0.6593s	
715/33250 (epoch 1.075), train_loss = 2.09429913, grad/param norm = 3.2628e-01, time/batch = 0.6588s	
716/33250 (epoch 1.077), train_loss = 2.20913142, grad/param norm = 3.4222e-01, time/batch = 0.6670s	
717/33250 (epoch 1.078), train_loss = 2.01997613, grad/param norm = 3.0086e-01, time/batch = 0.6623s	
718/33250 (epoch 1.080), train_loss = 2.13872968, grad/param norm = 3.0364e-01, time/batch = 0.6610s	
719/33250 (epoch 1.081), train_loss = 2.20369739, grad/param norm = 3.5124e-01, time/batch = 0.6603s	
720/33250 (epoch 1.083), train_loss = 2.17539588, grad/param norm = 4.2053e-01, time/batch = 0.6626s	
721/33250 (epoch 1.084), train_loss = 2.11373388, grad/param norm = 4.3065e-01, time/batch = 0.6579s	
722/33250 (epoch 1.086), train_loss = 2.10059914, grad/param norm = 3.3319e-01, time/batch = 0.6636s	
723/33250 (epoch 1.087), train_loss = 1.89837809, grad/param norm = 3.3365e-01, time/batch = 0.6585s	
724/33250 (epoch 1.089), train_loss = 2.13885597, grad/param norm = 3.5610e-01, time/batch = 0.6595s	
725/33250 (epoch 1.090), train_loss = 2.12091392, grad/param norm = 3.8828e-01, time/batch = 0.6605s	
726/33250 (epoch 1.092), train_loss = 2.01247316, grad/param norm = 3.9640e-01, time/batch = 0.6572s	
727/33250 (epoch 1.093), train_loss = 2.00770736, grad/param norm = 4.5534e-01, time/batch = 0.6610s	
728/33250 (epoch 1.095), train_loss = 2.18279543, grad/param norm = 4.1050e-01, time/batch = 0.6593s	
729/33250 (epoch 1.096), train_loss = 2.05795679, grad/param norm = 4.3552e-01, time/batch = 0.6605s	
730/33250 (epoch 1.098), train_loss = 1.96788524, grad/param norm = 3.9220e-01, time/batch = 0.6595s	
731/33250 (epoch 1.099), train_loss = 1.98372564, grad/param norm = 3.7276e-01, time/batch = 0.6611s	
732/33250 (epoch 1.101), train_loss = 2.16355645, grad/param norm = 3.5137e-01, time/batch = 0.6661s	
733/33250 (epoch 1.102), train_loss = 1.93944030, grad/param norm = 2.8683e-01, time/batch = 0.6625s	
734/33250 (epoch 1.104), train_loss = 1.88627248, grad/param norm = 2.6180e-01, time/batch = 0.6656s	
735/33250 (epoch 1.105), train_loss = 2.05185936, grad/param norm = 2.7271e-01, time/batch = 0.6624s	
736/33250 (epoch 1.107), train_loss = 1.82910938, grad/param norm = 2.9510e-01, time/batch = 0.6766s	
737/33250 (epoch 1.108), train_loss = 2.10559287, grad/param norm = 3.5050e-01, time/batch = 0.6683s	
738/33250 (epoch 1.110), train_loss = 2.02375034, grad/param norm = 3.3038e-01, time/batch = 0.6630s	
739/33250 (epoch 1.111), train_loss = 1.93618585, grad/param norm = 3.1386e-01, time/batch = 0.6657s	
740/33250 (epoch 1.113), train_loss = 2.04438729, grad/param norm = 3.6551e-01, time/batch = 0.6600s	
741/33250 (epoch 1.114), train_loss = 2.10563758, grad/param norm = 4.0278e-01, time/batch = 0.6762s	
742/33250 (epoch 1.116), train_loss = 2.15751192, grad/param norm = 4.6349e-01, time/batch = 0.6640s	
743/33250 (epoch 1.117), train_loss = 2.10220371, grad/param norm = 4.4836e-01, time/batch = 0.6573s	
744/33250 (epoch 1.119), train_loss = 2.02022251, grad/param norm = 3.6338e-01, time/batch = 0.6546s	
745/33250 (epoch 1.120), train_loss = 1.86583805, grad/param norm = 3.8110e-01, time/batch = 0.6591s	
746/33250 (epoch 1.122), train_loss = 2.06246141, grad/param norm = 2.6080e-01, time/batch = 0.6583s	
747/33250 (epoch 1.123), train_loss = 2.01383074, grad/param norm = 2.5188e-01, time/batch = 0.6570s	
748/33250 (epoch 1.125), train_loss = 1.94589222, grad/param norm = 3.1723e-01, time/batch = 0.6566s	
749/33250 (epoch 1.126), train_loss = 2.10707036, grad/param norm = 3.7541e-01, time/batch = 0.6637s	
750/33250 (epoch 1.128), train_loss = 1.90550054, grad/param norm = 3.4224e-01, time/batch = 0.6602s	
751/33250 (epoch 1.129), train_loss = 2.04086408, grad/param norm = 3.8557e-01, time/batch = 0.6579s	
752/33250 (epoch 1.131), train_loss = 2.01145951, grad/param norm = 3.3976e-01, time/batch = 0.6574s	
753/33250 (epoch 1.132), train_loss = 1.98102602, grad/param norm = 3.0621e-01, time/batch = 0.6594s	
754/33250 (epoch 1.134), train_loss = 2.17089584, grad/param norm = 2.8477e-01, time/batch = 0.6557s	
755/33250 (epoch 1.135), train_loss = 2.12613071, grad/param norm = 3.2369e-01, time/batch = 0.6566s	
756/33250 (epoch 1.137), train_loss = 1.89003932, grad/param norm = 3.7580e-01, time/batch = 0.6582s	
757/33250 (epoch 1.138), train_loss = 1.96958688, grad/param norm = 3.2787e-01, time/batch = 0.6550s	
758/33250 (epoch 1.140), train_loss = 1.93451384, grad/param norm = 3.1156e-01, time/batch = 0.6562s	
759/33250 (epoch 1.141), train_loss = 2.42382094, grad/param norm = 3.7796e-01, time/batch = 0.6643s	
760/33250 (epoch 1.143), train_loss = 1.90198964, grad/param norm = 3.8291e-01, time/batch = 0.6606s	
761/33250 (epoch 1.144), train_loss = 1.92783548, grad/param norm = 3.4635e-01, time/batch = 0.6566s	
762/33250 (epoch 1.146), train_loss = 1.87675154, grad/param norm = 3.1625e-01, time/batch = 0.6618s	
763/33250 (epoch 1.147), train_loss = 1.98239375, grad/param norm = 3.4456e-01, time/batch = 0.6602s	
764/33250 (epoch 1.149), train_loss = 2.10737475, grad/param norm = 3.3926e-01, time/batch = 0.6654s	
765/33250 (epoch 1.150), train_loss = 1.86401625, grad/param norm = 3.5738e-01, time/batch = 0.6865s	
766/33250 (epoch 1.152), train_loss = 1.86401311, grad/param norm = 2.8179e-01, time/batch = 0.6803s	
767/33250 (epoch 1.153), train_loss = 1.94754270, grad/param norm = 3.1351e-01, time/batch = 0.6717s	
768/33250 (epoch 1.155), train_loss = 1.99782697, grad/param norm = 3.0189e-01, time/batch = 0.6709s	
769/33250 (epoch 1.156), train_loss = 1.97656055, grad/param norm = 3.7035e-01, time/batch = 0.6665s	
770/33250 (epoch 1.158), train_loss = 2.33158198, grad/param norm = 3.6985e-01, time/batch = 0.6605s	
771/33250 (epoch 1.159), train_loss = 2.03343125, grad/param norm = 3.6541e-01, time/batch = 0.6642s	
772/33250 (epoch 1.161), train_loss = 2.05927020, grad/param norm = 3.0913e-01, time/batch = 0.6593s	
773/33250 (epoch 1.162), train_loss = 1.97790926, grad/param norm = 3.6358e-01, time/batch = 0.6579s	
774/33250 (epoch 1.164), train_loss = 2.09192014, grad/param norm = 3.4408e-01, time/batch = 0.6775s	
775/33250 (epoch 1.165), train_loss = 2.07478105, grad/param norm = 3.3873e-01, time/batch = 0.6576s	
776/33250 (epoch 1.167), train_loss = 2.04984032, grad/param norm = 3.4356e-01, time/batch = 0.6565s	
777/33250 (epoch 1.168), train_loss = 1.72375358, grad/param norm = 2.8507e-01, time/batch = 0.6532s	
778/33250 (epoch 1.170), train_loss = 1.99110586, grad/param norm = 2.8743e-01, time/batch = 0.6576s	
779/33250 (epoch 1.171), train_loss = 1.83288061, grad/param norm = 2.6877e-01, time/batch = 0.6571s	
780/33250 (epoch 1.173), train_loss = 1.86326177, grad/param norm = 4.2003e-01, time/batch = 0.6538s	
781/33250 (epoch 1.174), train_loss = 2.01193431, grad/param norm = 5.3259e-01, time/batch = 0.6617s	
782/33250 (epoch 1.176), train_loss = 2.14038862, grad/param norm = 5.0289e-01, time/batch = 0.6713s	
783/33250 (epoch 1.177), train_loss = 1.78618319, grad/param norm = 3.4000e-01, time/batch = 0.6586s	
784/33250 (epoch 1.179), train_loss = 1.97873603, grad/param norm = 3.0905e-01, time/batch = 0.6781s	
785/33250 (epoch 1.180), train_loss = 1.87246052, grad/param norm = 3.1597e-01, time/batch = 0.6829s	
786/33250 (epoch 1.182), train_loss = 1.96889767, grad/param norm = 3.7913e-01, time/batch = 0.6859s	
787/33250 (epoch 1.183), train_loss = 2.17792454, grad/param norm = 3.0733e-01, time/batch = 0.6901s	
788/33250 (epoch 1.185), train_loss = 2.04799138, grad/param norm = 3.7467e-01, time/batch = 0.6870s	
789/33250 (epoch 1.186), train_loss = 1.89424628, grad/param norm = 3.6995e-01, time/batch = 0.6857s	
790/33250 (epoch 1.188), train_loss = 2.16492123, grad/param norm = 3.0614e-01, time/batch = 0.6837s	
791/33250 (epoch 1.189), train_loss = 1.83966623, grad/param norm = 2.9288e-01, time/batch = 0.6887s	
792/33250 (epoch 1.191), train_loss = 1.91037851, grad/param norm = 2.8553e-01, time/batch = 0.6676s	
793/33250 (epoch 1.192), train_loss = 1.89323398, grad/param norm = 4.5191e-01, time/batch = 0.6650s	
794/33250 (epoch 1.194), train_loss = 1.77132665, grad/param norm = 3.6009e-01, time/batch = 0.6604s	
795/33250 (epoch 1.195), train_loss = 2.12491058, grad/param norm = 3.0111e-01, time/batch = 0.6708s	
796/33250 (epoch 1.197), train_loss = 2.01065007, grad/param norm = 3.3520e-01, time/batch = 0.6573s	
797/33250 (epoch 1.198), train_loss = 2.09281491, grad/param norm = 3.2494e-01, time/batch = 0.6603s	
798/33250 (epoch 1.200), train_loss = 1.96759686, grad/param norm = 3.0301e-01, time/batch = 0.6567s	
799/33250 (epoch 1.202), train_loss = 2.01438621, grad/param norm = 3.9231e-01, time/batch = 0.6614s	
800/33250 (epoch 1.203), train_loss = 2.03616449, grad/param norm = 3.0475e-01, time/batch = 0.6575s	
801/33250 (epoch 1.205), train_loss = 2.04290650, grad/param norm = 3.5635e-01, time/batch = 0.6946s	
802/33250 (epoch 1.206), train_loss = 1.96265046, grad/param norm = 3.8340e-01, time/batch = 0.6847s	
803/33250 (epoch 1.208), train_loss = 2.23043669, grad/param norm = 3.1292e-01, time/batch = 0.6822s	
804/33250 (epoch 1.209), train_loss = 1.87192836, grad/param norm = 3.3761e-01, time/batch = 0.6731s	
805/33250 (epoch 1.211), train_loss = 2.14437272, grad/param norm = 2.9357e-01, time/batch = 0.6659s	
806/33250 (epoch 1.212), train_loss = 2.11589556, grad/param norm = 3.5994e-01, time/batch = 0.6621s	
807/33250 (epoch 1.214), train_loss = 1.93536003, grad/param norm = 3.4389e-01, time/batch = 0.6586s	
808/33250 (epoch 1.215), train_loss = 2.37128377, grad/param norm = 3.3611e-01, time/batch = 0.6567s	
809/33250 (epoch 1.217), train_loss = 2.06236178, grad/param norm = 2.9352e-01, time/batch = 0.6661s	
810/33250 (epoch 1.218), train_loss = 2.08593801, grad/param norm = 3.3844e-01, time/batch = 0.6650s	
811/33250 (epoch 1.220), train_loss = 2.12176702, grad/param norm = 3.4966e-01, time/batch = 0.6721s	
812/33250 (epoch 1.221), train_loss = 2.28508293, grad/param norm = 3.1731e-01, time/batch = 0.6704s	
813/33250 (epoch 1.223), train_loss = 2.10674681, grad/param norm = 3.2803e-01, time/batch = 0.6593s	
814/33250 (epoch 1.224), train_loss = 2.12920597, grad/param norm = 3.5964e-01, time/batch = 0.6593s	
815/33250 (epoch 1.226), train_loss = 2.07690915, grad/param norm = 2.9318e-01, time/batch = 0.6588s	
816/33250 (epoch 1.227), train_loss = 2.13670086, grad/param norm = 3.2267e-01, time/batch = 0.6636s	
817/33250 (epoch 1.229), train_loss = 1.95447599, grad/param norm = 3.0012e-01, time/batch = 0.6616s	
818/33250 (epoch 1.230), train_loss = 2.05370507, grad/param norm = 3.1600e-01, time/batch = 0.6627s	
819/33250 (epoch 1.232), train_loss = 1.87221078, grad/param norm = 3.1613e-01, time/batch = 0.6861s	
820/33250 (epoch 1.233), train_loss = 1.95975652, grad/param norm = 2.9330e-01, time/batch = 0.6871s	
821/33250 (epoch 1.235), train_loss = 2.06972037, grad/param norm = 3.3987e-01, time/batch = 0.7018s	
822/33250 (epoch 1.236), train_loss = 1.89679379, grad/param norm = 3.7335e-01, time/batch = 0.6994s	
823/33250 (epoch 1.238), train_loss = 1.90461123, grad/param norm = 3.3166e-01, time/batch = 0.6951s	
824/33250 (epoch 1.239), train_loss = 2.26652860, grad/param norm = 3.5031e-01, time/batch = 0.6851s	
825/33250 (epoch 1.241), train_loss = 2.07305635, grad/param norm = 3.3856e-01, time/batch = 0.6829s	
826/33250 (epoch 1.242), train_loss = 1.92218079, grad/param norm = 3.7380e-01, time/batch = 0.6838s	
827/33250 (epoch 1.244), train_loss = 2.02620797, grad/param norm = 3.2664e-01, time/batch = 0.6836s	
828/33250 (epoch 1.245), train_loss = 1.96044451, grad/param norm = 2.9594e-01, time/batch = 0.6530s	
829/33250 (epoch 1.247), train_loss = 2.17814316, grad/param norm = 2.7436e-01, time/batch = 0.6491s	
830/33250 (epoch 1.248), train_loss = 2.24607966, grad/param norm = 2.4640e-01, time/batch = 0.6539s	
831/33250 (epoch 1.250), train_loss = 1.91975236, grad/param norm = 2.6687e-01, time/batch = 0.6601s	
832/33250 (epoch 1.251), train_loss = 2.09361787, grad/param norm = 4.1184e-01, time/batch = 0.6549s	
833/33250 (epoch 1.253), train_loss = 1.86361074, grad/param norm = 4.0840e-01, time/batch = 0.6532s	
834/33250 (epoch 1.254), train_loss = 1.95759101, grad/param norm = 4.2542e-01, time/batch = 0.6526s	
835/33250 (epoch 1.256), train_loss = 2.19029280, grad/param norm = 3.8510e-01, time/batch = 0.6614s	
836/33250 (epoch 1.257), train_loss = 2.20226167, grad/param norm = 3.1356e-01, time/batch = 0.6516s	
837/33250 (epoch 1.259), train_loss = 2.23314360, grad/param norm = 3.5549e-01, time/batch = 0.6561s	
838/33250 (epoch 1.260), train_loss = 1.95998975, grad/param norm = 3.7529e-01, time/batch = 0.6576s	
839/33250 (epoch 1.262), train_loss = 2.02849978, grad/param norm = 2.4806e-01, time/batch = 0.6492s	
840/33250 (epoch 1.263), train_loss = 1.91744750, grad/param norm = 2.5063e-01, time/batch = 0.6517s	
841/33250 (epoch 1.265), train_loss = 1.99822101, grad/param norm = 3.3518e-01, time/batch = 0.6490s	
842/33250 (epoch 1.266), train_loss = 1.98454483, grad/param norm = 3.1653e-01, time/batch = 0.6522s	
843/33250 (epoch 1.268), train_loss = 1.91361589, grad/param norm = 2.9830e-01, time/batch = 0.6524s	
844/33250 (epoch 1.269), train_loss = 1.70063478, grad/param norm = 2.8428e-01, time/batch = 0.6483s	
845/33250 (epoch 1.271), train_loss = 1.98086066, grad/param norm = 2.4370e-01, time/batch = 0.6574s	
846/33250 (epoch 1.272), train_loss = 1.61129325, grad/param norm = 2.1914e-01, time/batch = 0.6539s	
847/33250 (epoch 1.274), train_loss = 1.70920690, grad/param norm = 2.6539e-01, time/batch = 0.6535s	
848/33250 (epoch 1.275), train_loss = 1.86512722, grad/param norm = 3.0416e-01, time/batch = 0.6502s	
849/33250 (epoch 1.277), train_loss = 1.74476111, grad/param norm = 3.0679e-01, time/batch = 0.6517s	
850/33250 (epoch 1.278), train_loss = 1.73649937, grad/param norm = 2.7462e-01, time/batch = 0.6592s	
851/33250 (epoch 1.280), train_loss = 1.76684455, grad/param norm = 2.9452e-01, time/batch = 0.6578s	
852/33250 (epoch 1.281), train_loss = 1.89127494, grad/param norm = 3.2957e-01, time/batch = 0.6572s	
853/33250 (epoch 1.283), train_loss = 1.91006800, grad/param norm = 3.2466e-01, time/batch = 0.6522s	
854/33250 (epoch 1.284), train_loss = 1.94932960, grad/param norm = 3.0102e-01, time/batch = 0.6525s	
855/33250 (epoch 1.286), train_loss = 2.01079720, grad/param norm = 3.4349e-01, time/batch = 0.6533s	
856/33250 (epoch 1.287), train_loss = 1.85825979, grad/param norm = 3.2107e-01, time/batch = 0.6477s	
857/33250 (epoch 1.289), train_loss = 1.85435202, grad/param norm = 3.4240e-01, time/batch = 0.6537s	
858/33250 (epoch 1.290), train_loss = 1.82699026, grad/param norm = 3.3625e-01, time/batch = 0.6490s	
859/33250 (epoch 1.292), train_loss = 1.95173375, grad/param norm = 3.2875e-01, time/batch = 0.6499s	
860/33250 (epoch 1.293), train_loss = 2.07522413, grad/param norm = 3.7620e-01, time/batch = 0.6545s	
861/33250 (epoch 1.295), train_loss = 1.92326977, grad/param norm = 3.4406e-01, time/batch = 0.6497s	
862/33250 (epoch 1.296), train_loss = 1.87044568, grad/param norm = 2.7992e-01, time/batch = 0.6471s	
863/33250 (epoch 1.298), train_loss = 1.69465121, grad/param norm = 2.7452e-01, time/batch = 0.6506s	
864/33250 (epoch 1.299), train_loss = 1.67373743, grad/param norm = 2.6339e-01, time/batch = 0.6527s	
865/33250 (epoch 1.301), train_loss = 1.96248888, grad/param norm = 2.7014e-01, time/batch = 0.6508s	
866/33250 (epoch 1.302), train_loss = 1.85563293, grad/param norm = 3.0783e-01, time/batch = 0.6503s	
867/33250 (epoch 1.304), train_loss = 1.81261530, grad/param norm = 3.0760e-01, time/batch = 0.6400s	
868/33250 (epoch 1.305), train_loss = 1.79628610, grad/param norm = 2.7840e-01, time/batch = 0.6525s	
869/33250 (epoch 1.307), train_loss = 2.02151081, grad/param norm = 2.8513e-01, time/batch = 0.6478s	
870/33250 (epoch 1.308), train_loss = 2.04532718, grad/param norm = 3.0494e-01, time/batch = 0.6452s	
871/33250 (epoch 1.310), train_loss = 1.92499050, grad/param norm = 3.3118e-01, time/batch = 0.6534s	
872/33250 (epoch 1.311), train_loss = 2.00522197, grad/param norm = 3.3110e-01, time/batch = 0.6509s	
873/33250 (epoch 1.313), train_loss = 1.97850380, grad/param norm = 4.1732e-01, time/batch = 0.6515s	
874/33250 (epoch 1.314), train_loss = 1.91653238, grad/param norm = 3.1862e-01, time/batch = 0.6516s	
875/33250 (epoch 1.316), train_loss = 2.10550673, grad/param norm = 2.7333e-01, time/batch = 0.6553s	
876/33250 (epoch 1.317), train_loss = 1.83324655, grad/param norm = 2.8852e-01, time/batch = 0.6714s	
877/33250 (epoch 1.319), train_loss = 2.01694095, grad/param norm = 3.3187e-01, time/batch = 0.6767s	
878/33250 (epoch 1.320), train_loss = 2.13997785, grad/param norm = 3.4543e-01, time/batch = 0.6740s	
879/33250 (epoch 1.322), train_loss = 2.11121152, grad/param norm = 3.8213e-01, time/batch = 0.6715s	
880/33250 (epoch 1.323), train_loss = 2.16108807, grad/param norm = 3.8999e-01, time/batch = 0.6834s	
881/33250 (epoch 1.325), train_loss = 1.92627595, grad/param norm = 3.2698e-01, time/batch = 0.6721s	
882/33250 (epoch 1.326), train_loss = 2.04391900, grad/param norm = 3.0315e-01, time/batch = 0.6687s	
883/33250 (epoch 1.328), train_loss = 1.91565676, grad/param norm = 2.9126e-01, time/batch = 0.6722s	
884/33250 (epoch 1.329), train_loss = 2.04564844, grad/param norm = 2.8016e-01, time/batch = 0.6617s	
885/33250 (epoch 1.331), train_loss = 1.79153118, grad/param norm = 3.1752e-01, time/batch = 0.6549s	
886/33250 (epoch 1.332), train_loss = 1.86742641, grad/param norm = 3.3016e-01, time/batch = 0.6538s	
887/33250 (epoch 1.334), train_loss = 2.02518217, grad/param norm = 3.0573e-01, time/batch = 0.6750s	
888/33250 (epoch 1.335), train_loss = 1.70358216, grad/param norm = 3.3118e-01, time/batch = 0.6748s	
889/33250 (epoch 1.337), train_loss = 1.95380836, grad/param norm = 3.4496e-01, time/batch = 0.6679s	
890/33250 (epoch 1.338), train_loss = 1.98560324, grad/param norm = 2.7320e-01, time/batch = 0.6520s	
891/33250 (epoch 1.340), train_loss = 1.98118691, grad/param norm = 2.5833e-01, time/batch = 0.6550s	
892/33250 (epoch 1.341), train_loss = 1.97340637, grad/param norm = 3.1952e-01, time/batch = 0.6777s	
893/33250 (epoch 1.343), train_loss = 2.08964247, grad/param norm = 4.2864e-01, time/batch = 0.6740s	
894/33250 (epoch 1.344), train_loss = 1.93092595, grad/param norm = 4.2406e-01, time/batch = 0.6758s	
895/33250 (epoch 1.346), train_loss = 1.66278594, grad/param norm = 2.9410e-01, time/batch = 0.6640s	
896/33250 (epoch 1.347), train_loss = 2.24993020, grad/param norm = 3.0445e-01, time/batch = 0.6659s	
897/33250 (epoch 1.349), train_loss = 2.00569055, grad/param norm = 3.5594e-01, time/batch = 0.6518s	
898/33250 (epoch 1.350), train_loss = 1.93459973, grad/param norm = 3.2941e-01, time/batch = 0.6525s	
899/33250 (epoch 1.352), train_loss = 1.83268867, grad/param norm = 3.1074e-01, time/batch = 0.6529s	
900/33250 (epoch 1.353), train_loss = 1.89551676, grad/param norm = 3.0564e-01, time/batch = 0.6498s	
901/33250 (epoch 1.355), train_loss = 1.80770577, grad/param norm = 3.2808e-01, time/batch = 0.6525s	
902/33250 (epoch 1.356), train_loss = 1.79420553, grad/param norm = 2.8635e-01, time/batch = 0.6645s	
903/33250 (epoch 1.358), train_loss = 1.83295383, grad/param norm = 2.9869e-01, time/batch = 0.6647s	
904/33250 (epoch 1.359), train_loss = 1.73917989, grad/param norm = 2.8950e-01, time/batch = 0.6607s	
905/33250 (epoch 1.361), train_loss = 2.15202372, grad/param norm = 2.8490e-01, time/batch = 0.6650s	
906/33250 (epoch 1.362), train_loss = 1.86749255, grad/param norm = 3.3172e-01, time/batch = 0.6544s	
907/33250 (epoch 1.364), train_loss = 2.08163138, grad/param norm = 2.8845e-01, time/batch = 0.6626s	
908/33250 (epoch 1.365), train_loss = 1.89786508, grad/param norm = 2.6476e-01, time/batch = 0.6617s	
909/33250 (epoch 1.367), train_loss = 1.75561478, grad/param norm = 2.3591e-01, time/batch = 0.6640s	
910/33250 (epoch 1.368), train_loss = 1.87082569, grad/param norm = 2.7210e-01, time/batch = 0.6755s	
911/33250 (epoch 1.370), train_loss = 1.75626961, grad/param norm = 2.6470e-01, time/batch = 0.6870s	
912/33250 (epoch 1.371), train_loss = 2.00946762, grad/param norm = 2.9985e-01, time/batch = 0.6825s	
913/33250 (epoch 1.373), train_loss = 1.80304435, grad/param norm = 2.7022e-01, time/batch = 0.6870s	
914/33250 (epoch 1.374), train_loss = 2.01877576, grad/param norm = 3.0658e-01, time/batch = 0.6913s	
915/33250 (epoch 1.376), train_loss = 1.88541222, grad/param norm = 2.9306e-01, time/batch = 0.6916s	
916/33250 (epoch 1.377), train_loss = 1.79985705, grad/param norm = 3.4548e-01, time/batch = 0.6811s	
917/33250 (epoch 1.379), train_loss = 1.84279727, grad/param norm = 2.7745e-01, time/batch = 0.7007s	
918/33250 (epoch 1.380), train_loss = 1.97516416, grad/param norm = 2.6008e-01, time/batch = 0.6900s	
919/33250 (epoch 1.382), train_loss = 2.04356750, grad/param norm = 3.4003e-01, time/batch = 0.6910s	
920/33250 (epoch 1.383), train_loss = 1.98613095, grad/param norm = 3.1403e-01, time/batch = 0.6765s	
921/33250 (epoch 1.385), train_loss = 1.81471303, grad/param norm = 3.0238e-01, time/batch = 0.6757s	
922/33250 (epoch 1.386), train_loss = 1.84994486, grad/param norm = 2.8194e-01, time/batch = 0.6786s	
923/33250 (epoch 1.388), train_loss = 1.89486704, grad/param norm = 2.5506e-01, time/batch = 0.6798s	
924/33250 (epoch 1.389), train_loss = 1.86813801, grad/param norm = 2.9157e-01, time/batch = 0.6957s	
925/33250 (epoch 1.391), train_loss = 1.78413728, grad/param norm = 2.8020e-01, time/batch = 0.6866s	
926/33250 (epoch 1.392), train_loss = 2.07980324, grad/param norm = 2.8829e-01, time/batch = 0.6791s	
927/33250 (epoch 1.394), train_loss = 2.16739699, grad/param norm = 3.6542e-01, time/batch = 0.6826s	
928/33250 (epoch 1.395), train_loss = 2.22100789, grad/param norm = 3.7183e-01, time/batch = 0.6875s	
929/33250 (epoch 1.397), train_loss = 2.10041601, grad/param norm = 3.8904e-01, time/batch = 0.6847s	
930/33250 (epoch 1.398), train_loss = 1.95602226, grad/param norm = 3.1977e-01, time/batch = 0.6775s	
931/33250 (epoch 1.400), train_loss = 1.95051080, grad/param norm = 2.7331e-01, time/batch = 0.6793s	
932/33250 (epoch 1.402), train_loss = 1.77385648, grad/param norm = 2.8945e-01, time/batch = 0.6879s	
933/33250 (epoch 1.403), train_loss = 1.71445438, grad/param norm = 2.7375e-01, time/batch = 0.6862s	
934/33250 (epoch 1.405), train_loss = 1.74916543, grad/param norm = 2.9468e-01, time/batch = 0.6771s	
935/33250 (epoch 1.406), train_loss = 1.87758623, grad/param norm = 2.5521e-01, time/batch = 0.6755s	
936/33250 (epoch 1.408), train_loss = 2.10530614, grad/param norm = 2.8811e-01, time/batch = 0.6767s	
937/33250 (epoch 1.409), train_loss = 1.96663500, grad/param norm = 2.8305e-01, time/batch = 0.6869s	
938/33250 (epoch 1.411), train_loss = 1.66337830, grad/param norm = 3.5026e-01, time/batch = 0.6819s	
939/33250 (epoch 1.412), train_loss = 1.60734311, grad/param norm = 2.4051e-01, time/batch = 0.6829s	
940/33250 (epoch 1.414), train_loss = 2.02669755, grad/param norm = 2.9739e-01, time/batch = 0.6767s	
941/33250 (epoch 1.415), train_loss = 1.87078252, grad/param norm = 2.8043e-01, time/batch = 0.6884s	
942/33250 (epoch 1.417), train_loss = 2.00891361, grad/param norm = 3.2313e-01, time/batch = 0.6798s	
943/33250 (epoch 1.418), train_loss = 2.09562373, grad/param norm = 3.1978e-01, time/batch = 0.6915s	
944/33250 (epoch 1.420), train_loss = 1.98716979, grad/param norm = 3.1482e-01, time/batch = 0.6945s	
945/33250 (epoch 1.421), train_loss = 1.74673193, grad/param norm = 3.3882e-01, time/batch = 0.6799s	
946/33250 (epoch 1.423), train_loss = 1.96875287, grad/param norm = 2.7142e-01, time/batch = 0.6821s	
947/33250 (epoch 1.424), train_loss = 2.08773301, grad/param norm = 3.0403e-01, time/batch = 0.6814s	
948/33250 (epoch 1.426), train_loss = 1.87223555, grad/param norm = 2.5685e-01, time/batch = 0.6837s	
949/33250 (epoch 1.427), train_loss = 1.74119879, grad/param norm = 2.8315e-01, time/batch = 0.6857s	
950/33250 (epoch 1.429), train_loss = 1.98944902, grad/param norm = 3.0648e-01, time/batch = 0.6832s	
951/33250 (epoch 1.430), train_loss = 1.91783778, grad/param norm = 3.4113e-01, time/batch = 0.6821s	
952/33250 (epoch 1.432), train_loss = 1.92843411, grad/param norm = 2.9742e-01, time/batch = 0.6863s	
953/33250 (epoch 1.433), train_loss = 1.85183275, grad/param norm = 2.7030e-01, time/batch = 0.6883s	
954/33250 (epoch 1.435), train_loss = 1.99640727, grad/param norm = 2.9904e-01, time/batch = 0.6822s	
955/33250 (epoch 1.436), train_loss = 1.93292150, grad/param norm = 2.7977e-01, time/batch = 0.6843s	
956/33250 (epoch 1.438), train_loss = 1.82257668, grad/param norm = 3.3847e-01, time/batch = 0.6857s	
957/33250 (epoch 1.439), train_loss = 1.83073427, grad/param norm = 2.6883e-01, time/batch = 0.6801s	
958/33250 (epoch 1.441), train_loss = 1.92186861, grad/param norm = 2.7456e-01, time/batch = 0.6830s	
959/33250 (epoch 1.442), train_loss = 1.88025487, grad/param norm = 2.7540e-01, time/batch = 0.6818s	
960/33250 (epoch 1.444), train_loss = 1.75108048, grad/param norm = 3.0596e-01, time/batch = 0.6822s	
961/33250 (epoch 1.445), train_loss = 1.88910237, grad/param norm = 2.5530e-01, time/batch = 0.6865s	
962/33250 (epoch 1.447), train_loss = 1.89955616, grad/param norm = 2.7419e-01, time/batch = 0.6878s	
963/33250 (epoch 1.448), train_loss = 1.82290568, grad/param norm = 3.5893e-01, time/batch = 0.6894s	
964/33250 (epoch 1.450), train_loss = 2.10760086, grad/param norm = 2.8564e-01, time/batch = 0.6960s	
965/33250 (epoch 1.451), train_loss = 1.96145181, grad/param norm = 3.1575e-01, time/batch = 0.7043s	
966/33250 (epoch 1.453), train_loss = 1.66471470, grad/param norm = 2.7684e-01, time/batch = 0.7157s	
967/33250 (epoch 1.454), train_loss = 1.99457981, grad/param norm = 2.9029e-01, time/batch = 0.6950s	
968/33250 (epoch 1.456), train_loss = 1.93908672, grad/param norm = 3.4003e-01, time/batch = 0.6951s	
969/33250 (epoch 1.457), train_loss = 1.94919227, grad/param norm = 3.1438e-01, time/batch = 0.6901s	
970/33250 (epoch 1.459), train_loss = 1.93976669, grad/param norm = 2.6723e-01, time/batch = 0.6857s	
971/33250 (epoch 1.460), train_loss = 1.86003694, grad/param norm = 3.0166e-01, time/batch = 0.6881s	
972/33250 (epoch 1.462), train_loss = 1.81815350, grad/param norm = 2.8419e-01, time/batch = 0.6860s	
973/33250 (epoch 1.463), train_loss = 1.74533651, grad/param norm = 2.4363e-01, time/batch = 0.6901s	
974/33250 (epoch 1.465), train_loss = 1.53329301, grad/param norm = 2.5611e-01, time/batch = 0.7271s	
975/33250 (epoch 1.466), train_loss = 1.58825774, grad/param norm = 2.9013e-01, time/batch = 0.6966s	
976/33250 (epoch 1.468), train_loss = 1.71381077, grad/param norm = 2.8473e-01, time/batch = 0.6795s	
977/33250 (epoch 1.469), train_loss = 1.99581413, grad/param norm = 2.9489e-01, time/batch = 0.6796s	
978/33250 (epoch 1.471), train_loss = 1.95418847, grad/param norm = 2.8907e-01, time/batch = 0.6811s	
979/33250 (epoch 1.472), train_loss = 1.94303140, grad/param norm = 3.5973e-01, time/batch = 0.6794s	
980/33250 (epoch 1.474), train_loss = 2.12186507, grad/param norm = 3.9605e-01, time/batch = 0.6771s	
981/33250 (epoch 1.475), train_loss = 1.93816162, grad/param norm = 3.8019e-01, time/batch = 0.6820s	
982/33250 (epoch 1.477), train_loss = 1.85623763, grad/param norm = 2.9953e-01, time/batch = 0.6801s	
983/33250 (epoch 1.478), train_loss = 1.81544224, grad/param norm = 2.4619e-01, time/batch = 0.6762s	
984/33250 (epoch 1.480), train_loss = 2.07128980, grad/param norm = 2.8365e-01, time/batch = 0.6779s	
985/33250 (epoch 1.481), train_loss = 1.80548569, grad/param norm = 3.3142e-01, time/batch = 0.6776s	
986/33250 (epoch 1.483), train_loss = 1.98013385, grad/param norm = 2.8381e-01, time/batch = 0.6813s	
987/33250 (epoch 1.484), train_loss = 1.82285422, grad/param norm = 2.8830e-01, time/batch = 0.6852s	
988/33250 (epoch 1.486), train_loss = 1.67702514, grad/param norm = 2.5220e-01, time/batch = 0.6805s	
989/33250 (epoch 1.487), train_loss = 1.88841768, grad/param norm = 3.3793e-01, time/batch = 0.6750s	
990/33250 (epoch 1.489), train_loss = 2.03352674, grad/param norm = 2.9425e-01, time/batch = 0.6828s	
991/33250 (epoch 1.490), train_loss = 2.00531957, grad/param norm = 3.0841e-01, time/batch = 0.6777s	
992/33250 (epoch 1.492), train_loss = 1.83419492, grad/param norm = 2.6861e-01, time/batch = 0.6761s	
993/33250 (epoch 1.493), train_loss = 1.86456073, grad/param norm = 2.5471e-01, time/batch = 0.6792s	
994/33250 (epoch 1.495), train_loss = 1.89559146, grad/param norm = 2.7677e-01, time/batch = 0.6721s	
995/33250 (epoch 1.496), train_loss = 1.85666173, grad/param norm = 2.8437e-01, time/batch = 0.6722s	
996/33250 (epoch 1.498), train_loss = 1.91835230, grad/param norm = 2.6791e-01, time/batch = 0.6772s	
997/33250 (epoch 1.499), train_loss = 1.93348128, grad/param norm = 2.8132e-01, time/batch = 0.6757s	
998/33250 (epoch 1.501), train_loss = 1.78077683, grad/param norm = 2.6618e-01, time/batch = 0.6784s	
999/33250 (epoch 1.502), train_loss = 1.85838712, grad/param norm = 3.4261e-01, time/batch = 0.6815s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch1.50_1.9623.t7	
1000/33250 (epoch 1.504), train_loss = 2.06009318, grad/param norm = 3.2027e-01, time/batch = 0.6776s	
1001/33250 (epoch 1.505), train_loss = 1.71012037, grad/param norm = 2.5295e-01, time/batch = 0.6845s	
1002/33250 (epoch 1.507), train_loss = 1.99087011, grad/param norm = 2.7372e-01, time/batch = 0.6842s	
1003/33250 (epoch 1.508), train_loss = 1.75768601, grad/param norm = 2.4740e-01, time/batch = 0.6712s	
1004/33250 (epoch 1.510), train_loss = 1.78167723, grad/param norm = 3.1085e-01, time/batch = 0.6726s	
1005/33250 (epoch 1.511), train_loss = 1.93268577, grad/param norm = 3.4455e-01, time/batch = 0.6772s	
1006/33250 (epoch 1.513), train_loss = 2.18646521, grad/param norm = 3.8603e-01, time/batch = 0.6871s	
1007/33250 (epoch 1.514), train_loss = 1.95604410, grad/param norm = 3.6403e-01, time/batch = 0.6724s	
1008/33250 (epoch 1.516), train_loss = 1.85460720, grad/param norm = 2.7878e-01, time/batch = 0.6780s	
1009/33250 (epoch 1.517), train_loss = 1.96019649, grad/param norm = 2.4565e-01, time/batch = 0.6789s	
1010/33250 (epoch 1.519), train_loss = 1.60546663, grad/param norm = 2.5459e-01, time/batch = 0.6781s	
1011/33250 (epoch 1.520), train_loss = 2.10186814, grad/param norm = 2.8349e-01, time/batch = 0.6782s	
1012/33250 (epoch 1.522), train_loss = 1.95346274, grad/param norm = 3.0587e-01, time/batch = 0.6900s	
1013/33250 (epoch 1.523), train_loss = 1.76123898, grad/param norm = 2.7964e-01, time/batch = 0.6757s	
1014/33250 (epoch 1.525), train_loss = 1.74546750, grad/param norm = 3.1392e-01, time/batch = 0.6752s	
1015/33250 (epoch 1.526), train_loss = 1.73979280, grad/param norm = 3.5694e-01, time/batch = 0.6769s	
1016/33250 (epoch 1.528), train_loss = 1.87152505, grad/param norm = 2.9209e-01, time/batch = 0.6769s	
1017/33250 (epoch 1.529), train_loss = 1.76432156, grad/param norm = 3.2092e-01, time/batch = 0.6866s	
1018/33250 (epoch 1.531), train_loss = 1.65049653, grad/param norm = 3.3122e-01, time/batch = 0.6856s	
1019/33250 (epoch 1.532), train_loss = 1.98487543, grad/param norm = 2.8315e-01, time/batch = 0.6874s	
1020/33250 (epoch 1.534), train_loss = 1.88895769, grad/param norm = 2.5465e-01, time/batch = 0.6779s	
1021/33250 (epoch 1.535), train_loss = 1.82348095, grad/param norm = 2.2510e-01, time/batch = 0.7015s	
1022/33250 (epoch 1.537), train_loss = 1.98751949, grad/param norm = 2.8696e-01, time/batch = 0.6973s	
1023/33250 (epoch 1.538), train_loss = 1.80388098, grad/param norm = 2.9341e-01, time/batch = 0.6965s	
1024/33250 (epoch 1.540), train_loss = 2.01811810, grad/param norm = 2.7402e-01, time/batch = 0.6953s	
1025/33250 (epoch 1.541), train_loss = 1.95798802, grad/param norm = 2.5865e-01, time/batch = 0.6879s	
1026/33250 (epoch 1.543), train_loss = 1.99717100, grad/param norm = 2.6638e-01, time/batch = 0.6998s	
1027/33250 (epoch 1.544), train_loss = 1.84481520, grad/param norm = 2.6539e-01, time/batch = 0.7146s	
1028/33250 (epoch 1.546), train_loss = 1.91438678, grad/param norm = 3.3921e-01, time/batch = 0.7201s	
1029/33250 (epoch 1.547), train_loss = 1.72393107, grad/param norm = 3.2887e-01, time/batch = 0.7199s	
1030/33250 (epoch 1.549), train_loss = 1.90571764, grad/param norm = 2.8105e-01, time/batch = 0.7339s	
1031/33250 (epoch 1.550), train_loss = 1.75635064, grad/param norm = 2.7109e-01, time/batch = 0.7328s	
1032/33250 (epoch 1.552), train_loss = 1.91201982, grad/param norm = 2.6470e-01, time/batch = 0.7286s	
1033/33250 (epoch 1.553), train_loss = 1.72502338, grad/param norm = 2.5852e-01, time/batch = 0.7283s	
1034/33250 (epoch 1.555), train_loss = 1.72822309, grad/param norm = 2.6395e-01, time/batch = 0.7185s	
1035/33250 (epoch 1.556), train_loss = 2.00015622, grad/param norm = 3.1605e-01, time/batch = 0.7166s	
1036/33250 (epoch 1.558), train_loss = 1.98826369, grad/param norm = 3.1399e-01, time/batch = 0.7046s	
1037/33250 (epoch 1.559), train_loss = 1.84656969, grad/param norm = 2.7744e-01, time/batch = 0.6977s	
1038/33250 (epoch 1.561), train_loss = 1.88499047, grad/param norm = 2.8384e-01, time/batch = 0.7099s	
1039/33250 (epoch 1.562), train_loss = 1.99527342, grad/param norm = 3.1338e-01, time/batch = 0.6896s	
1040/33250 (epoch 1.564), train_loss = 1.93190901, grad/param norm = 2.9090e-01, time/batch = 0.6908s	
1041/33250 (epoch 1.565), train_loss = 1.93618357, grad/param norm = 2.7756e-01, time/batch = 0.7124s	
1042/33250 (epoch 1.567), train_loss = 1.81631177, grad/param norm = 2.4820e-01, time/batch = 0.7157s	
1043/33250 (epoch 1.568), train_loss = 1.80484238, grad/param norm = 2.5613e-01, time/batch = 0.7162s	
1044/33250 (epoch 1.570), train_loss = 2.00725520, grad/param norm = 3.0998e-01, time/batch = 0.6929s	
1045/33250 (epoch 1.571), train_loss = 2.00869747, grad/param norm = 2.7138e-01, time/batch = 0.6972s	
1046/33250 (epoch 1.573), train_loss = 1.99916339, grad/param norm = 2.4104e-01, time/batch = 0.7110s	
1047/33250 (epoch 1.574), train_loss = 1.70171809, grad/param norm = 2.3004e-01, time/batch = 0.6942s	
1048/33250 (epoch 1.576), train_loss = 1.92779216, grad/param norm = 3.0180e-01, time/batch = 0.6971s	
1049/33250 (epoch 1.577), train_loss = 1.88490190, grad/param norm = 3.0837e-01, time/batch = 0.7002s	
1050/33250 (epoch 1.579), train_loss = 1.68655694, grad/param norm = 2.5632e-01, time/batch = 0.7162s	
1051/33250 (epoch 1.580), train_loss = 1.61636673, grad/param norm = 2.4255e-01, time/batch = 0.7220s	
1052/33250 (epoch 1.582), train_loss = 1.78104514, grad/param norm = 2.5697e-01, time/batch = 0.6975s	
1053/33250 (epoch 1.583), train_loss = 1.88369162, grad/param norm = 2.5562e-01, time/batch = 0.6962s	
1054/33250 (epoch 1.585), train_loss = 1.97843197, grad/param norm = 3.1382e-01, time/batch = 0.6956s	
1055/33250 (epoch 1.586), train_loss = 1.82038973, grad/param norm = 3.4210e-01, time/batch = 0.6988s	
1056/33250 (epoch 1.588), train_loss = 1.89309683, grad/param norm = 2.8845e-01, time/batch = 0.6954s	
1057/33250 (epoch 1.589), train_loss = 2.05549563, grad/param norm = 3.5453e-01, time/batch = 0.6919s	
1058/33250 (epoch 1.591), train_loss = 1.94724943, grad/param norm = 3.1910e-01, time/batch = 0.7020s	
1059/33250 (epoch 1.592), train_loss = 1.82654445, grad/param norm = 2.4886e-01, time/batch = 0.6961s	
1060/33250 (epoch 1.594), train_loss = 2.10138339, grad/param norm = 2.9294e-01, time/batch = 0.6955s	
1061/33250 (epoch 1.595), train_loss = 2.00080393, grad/param norm = 2.9086e-01, time/batch = 0.6982s	
1062/33250 (epoch 1.597), train_loss = 1.84590652, grad/param norm = 3.1927e-01, time/batch = 0.7005s	
1063/33250 (epoch 1.598), train_loss = 1.94216576, grad/param norm = 2.6469e-01, time/batch = 0.6917s	
1064/33250 (epoch 1.600), train_loss = 1.82764855, grad/param norm = 3.0708e-01, time/batch = 0.6936s	
1065/33250 (epoch 1.602), train_loss = 2.05130330, grad/param norm = 3.1311e-01, time/batch = 0.6926s	
1066/33250 (epoch 1.603), train_loss = 1.80730604, grad/param norm = 2.8870e-01, time/batch = 0.6932s	
1067/33250 (epoch 1.605), train_loss = 1.90163783, grad/param norm = 2.9939e-01, time/batch = 0.6904s	
1068/33250 (epoch 1.606), train_loss = 1.92181030, grad/param norm = 2.7972e-01, time/batch = 0.6891s	
1069/33250 (epoch 1.608), train_loss = 1.92645802, grad/param norm = 2.5114e-01, time/batch = 0.6914s	
1070/33250 (epoch 1.609), train_loss = 1.74338139, grad/param norm = 2.7095e-01, time/batch = 0.6890s	
1071/33250 (epoch 1.611), train_loss = 2.04358159, grad/param norm = 2.9755e-01, time/batch = 0.6899s	
1072/33250 (epoch 1.612), train_loss = 2.05174738, grad/param norm = 3.1040e-01, time/batch = 0.6902s	
1073/33250 (epoch 1.614), train_loss = 2.18996517, grad/param norm = 3.2002e-01, time/batch = 0.6919s	
1074/33250 (epoch 1.615), train_loss = 1.96964787, grad/param norm = 3.1934e-01, time/batch = 0.6896s	
1075/33250 (epoch 1.617), train_loss = 2.26279367, grad/param norm = 2.8107e-01, time/batch = 0.6901s	
1076/33250 (epoch 1.618), train_loss = 2.13212130, grad/param norm = 3.1129e-01, time/batch = 0.6931s	
1077/33250 (epoch 1.620), train_loss = 2.02234604, grad/param norm = 3.1496e-01, time/batch = 0.6902s	
1078/33250 (epoch 1.621), train_loss = 1.74529124, grad/param norm = 2.2609e-01, time/batch = 0.6877s	
1079/33250 (epoch 1.623), train_loss = 1.82882045, grad/param norm = 2.8810e-01, time/batch = 0.6964s	
1080/33250 (epoch 1.624), train_loss = 1.90543342, grad/param norm = 3.0702e-01, time/batch = 0.6955s	
1081/33250 (epoch 1.626), train_loss = 1.93290875, grad/param norm = 3.1817e-01, time/batch = 0.6918s	
1082/33250 (epoch 1.627), train_loss = 2.00783291, grad/param norm = 2.8513e-01, time/batch = 0.6905s	
1083/33250 (epoch 1.629), train_loss = 1.86151420, grad/param norm = 3.4333e-01, time/batch = 0.6896s	
1084/33250 (epoch 1.630), train_loss = 1.91880130, grad/param norm = 3.8620e-01, time/batch = 0.6923s	
1085/33250 (epoch 1.632), train_loss = 1.60914888, grad/param norm = 2.5288e-01, time/batch = 0.6942s	
1086/33250 (epoch 1.633), train_loss = 2.01216516, grad/param norm = 3.2652e-01, time/batch = 0.6993s	
1087/33250 (epoch 1.635), train_loss = 1.72564106, grad/param norm = 2.9226e-01, time/batch = 0.6898s	
1088/33250 (epoch 1.636), train_loss = 1.83696273, grad/param norm = 2.7570e-01, time/batch = 0.6927s	
1089/33250 (epoch 1.638), train_loss = 1.81850367, grad/param norm = 2.7369e-01, time/batch = 0.6891s	
1090/33250 (epoch 1.639), train_loss = 1.87574105, grad/param norm = 2.8312e-01, time/batch = 0.6862s	
1091/33250 (epoch 1.641), train_loss = 1.73007480, grad/param norm = 2.7129e-01, time/batch = 0.7061s	
1092/33250 (epoch 1.642), train_loss = 1.76832784, grad/param norm = 2.6144e-01, time/batch = 0.6915s	
1093/33250 (epoch 1.644), train_loss = 1.68361502, grad/param norm = 2.9511e-01, time/batch = 0.6909s	
1094/33250 (epoch 1.645), train_loss = 1.95066235, grad/param norm = 3.2702e-01, time/batch = 0.6906s	
1095/33250 (epoch 1.647), train_loss = 1.80779070, grad/param norm = 3.0936e-01, time/batch = 0.6916s	
1096/33250 (epoch 1.648), train_loss = 1.84935191, grad/param norm = 2.8187e-01, time/batch = 0.6870s	
1097/33250 (epoch 1.650), train_loss = 1.97606296, grad/param norm = 2.9263e-01, time/batch = 0.6904s	
1098/33250 (epoch 1.651), train_loss = 1.89378344, grad/param norm = 3.1780e-01, time/batch = 0.6977s	
1099/33250 (epoch 1.653), train_loss = 1.67720160, grad/param norm = 2.5937e-01, time/batch = 0.7163s	
1100/33250 (epoch 1.654), train_loss = 1.66813032, grad/param norm = 2.5149e-01, time/batch = 0.7146s	
1101/33250 (epoch 1.656), train_loss = 1.88215525, grad/param norm = 2.7634e-01, time/batch = 0.7038s	
1102/33250 (epoch 1.657), train_loss = 1.79840934, grad/param norm = 2.8518e-01, time/batch = 0.6989s	
1103/33250 (epoch 1.659), train_loss = 1.63549057, grad/param norm = 2.7677e-01, time/batch = 0.6820s	
1104/33250 (epoch 1.660), train_loss = 1.80069871, grad/param norm = 2.7156e-01, time/batch = 0.6938s	
1105/33250 (epoch 1.662), train_loss = 1.88102670, grad/param norm = 3.5519e-01, time/batch = 0.6830s	
1106/33250 (epoch 1.663), train_loss = 1.75814737, grad/param norm = 3.3902e-01, time/batch = 0.7095s	
1107/33250 (epoch 1.665), train_loss = 1.97560580, grad/param norm = 3.3773e-01, time/batch = 0.6770s	
1108/33250 (epoch 1.666), train_loss = 1.80482106, grad/param norm = 3.2954e-01, time/batch = 0.6807s	
1109/33250 (epoch 1.668), train_loss = 1.94837409, grad/param norm = 2.7249e-01, time/batch = 0.6744s	
1110/33250 (epoch 1.669), train_loss = 1.98229727, grad/param norm = 2.7720e-01, time/batch = 0.6749s	
1111/33250 (epoch 1.671), train_loss = 1.89642519, grad/param norm = 2.5984e-01, time/batch = 0.6788s	
1112/33250 (epoch 1.672), train_loss = 1.97475849, grad/param norm = 2.7198e-01, time/batch = 0.6795s	
1113/33250 (epoch 1.674), train_loss = 1.74270464, grad/param norm = 2.4593e-01, time/batch = 0.6808s	
1114/33250 (epoch 1.675), train_loss = 1.86949561, grad/param norm = 2.6494e-01, time/batch = 0.6785s	
1115/33250 (epoch 1.677), train_loss = 1.84959816, grad/param norm = 3.0290e-01, time/batch = 0.6786s	
1116/33250 (epoch 1.678), train_loss = 1.95393450, grad/param norm = 3.0461e-01, time/batch = 0.6844s	
1117/33250 (epoch 1.680), train_loss = 1.90644269, grad/param norm = 2.6475e-01, time/batch = 0.6767s	
1118/33250 (epoch 1.681), train_loss = 1.67700136, grad/param norm = 2.7265e-01, time/batch = 0.6772s	
1119/33250 (epoch 1.683), train_loss = 1.76189172, grad/param norm = 2.7440e-01, time/batch = 0.6743s	
1120/33250 (epoch 1.684), train_loss = 1.90610893, grad/param norm = 3.3841e-01, time/batch = 0.6757s	
1121/33250 (epoch 1.686), train_loss = 1.75460500, grad/param norm = 3.0327e-01, time/batch = 0.6777s	
1122/33250 (epoch 1.687), train_loss = 1.76223888, grad/param norm = 2.4796e-01, time/batch = 0.6810s	
1123/33250 (epoch 1.689), train_loss = 1.68827976, grad/param norm = 2.2281e-01, time/batch = 0.6813s	
1124/33250 (epoch 1.690), train_loss = 1.92936945, grad/param norm = 2.9237e-01, time/batch = 0.6856s	
1125/33250 (epoch 1.692), train_loss = 1.94965332, grad/param norm = 3.3040e-01, time/batch = 0.6841s	
1126/33250 (epoch 1.693), train_loss = 1.79517045, grad/param norm = 2.4014e-01, time/batch = 0.6827s	
1127/33250 (epoch 1.695), train_loss = 1.99259706, grad/param norm = 3.1731e-01, time/batch = 0.6936s	
1128/33250 (epoch 1.696), train_loss = 1.91403425, grad/param norm = 2.6945e-01, time/batch = 0.7018s	
1129/33250 (epoch 1.698), train_loss = 1.65918491, grad/param norm = 2.3703e-01, time/batch = 0.7081s	
1130/33250 (epoch 1.699), train_loss = 1.96724303, grad/param norm = 2.3718e-01, time/batch = 0.6910s	
1131/33250 (epoch 1.701), train_loss = 1.73673664, grad/param norm = 2.4289e-01, time/batch = 0.7090s	
1132/33250 (epoch 1.702), train_loss = 1.93346332, grad/param norm = 2.7208e-01, time/batch = 0.7051s	
1133/33250 (epoch 1.704), train_loss = 2.00161647, grad/param norm = 3.1623e-01, time/batch = 0.7030s	
1134/33250 (epoch 1.705), train_loss = 1.82859709, grad/param norm = 3.4602e-01, time/batch = 0.7014s	
1135/33250 (epoch 1.707), train_loss = 1.77209725, grad/param norm = 3.2827e-01, time/batch = 0.7184s	
1136/33250 (epoch 1.708), train_loss = 1.85992971, grad/param norm = 2.7709e-01, time/batch = 0.7042s	
1137/33250 (epoch 1.710), train_loss = 1.98207235, grad/param norm = 2.8467e-01, time/batch = 0.7041s	
1138/33250 (epoch 1.711), train_loss = 1.97652746, grad/param norm = 3.0451e-01, time/batch = 0.7112s	
1139/33250 (epoch 1.713), train_loss = 1.90803446, grad/param norm = 2.8736e-01, time/batch = 0.7149s	
1140/33250 (epoch 1.714), train_loss = 1.97042476, grad/param norm = 2.7814e-01, time/batch = 0.6995s	
1141/33250 (epoch 1.716), train_loss = 1.93452686, grad/param norm = 2.7432e-01, time/batch = 0.7068s	
1142/33250 (epoch 1.717), train_loss = 1.75459573, grad/param norm = 2.6432e-01, time/batch = 0.7019s	
1143/33250 (epoch 1.719), train_loss = 1.93019524, grad/param norm = 2.6969e-01, time/batch = 0.6975s	
1144/33250 (epoch 1.720), train_loss = 2.02546953, grad/param norm = 2.6979e-01, time/batch = 0.7018s	
1145/33250 (epoch 1.722), train_loss = 1.73606648, grad/param norm = 2.4222e-01, time/batch = 0.7046s	
1146/33250 (epoch 1.723), train_loss = 1.70932602, grad/param norm = 2.5896e-01, time/batch = 0.6986s	
1147/33250 (epoch 1.725), train_loss = 1.48814267, grad/param norm = 2.3531e-01, time/batch = 0.7035s	
1148/33250 (epoch 1.726), train_loss = 1.75648708, grad/param norm = 2.5941e-01, time/batch = 0.7242s	
1149/33250 (epoch 1.728), train_loss = 1.88413414, grad/param norm = 2.6441e-01, time/batch = 0.7058s	
1150/33250 (epoch 1.729), train_loss = 1.87832209, grad/param norm = 2.7278e-01, time/batch = 0.7036s	
1151/33250 (epoch 1.731), train_loss = 1.73847025, grad/param norm = 2.6934e-01, time/batch = 0.7144s	
1152/33250 (epoch 1.732), train_loss = 1.74407911, grad/param norm = 2.8863e-01, time/batch = 0.7077s	
1153/33250 (epoch 1.734), train_loss = 1.86520231, grad/param norm = 3.6781e-01, time/batch = 0.7020s	
1154/33250 (epoch 1.735), train_loss = 1.85545696, grad/param norm = 3.5885e-01, time/batch = 0.6995s	
1155/33250 (epoch 1.737), train_loss = 1.96978579, grad/param norm = 2.8531e-01, time/batch = 0.7015s	
1156/33250 (epoch 1.738), train_loss = 1.87524981, grad/param norm = 2.7302e-01, time/batch = 0.7004s	
1157/33250 (epoch 1.740), train_loss = 2.07957094, grad/param norm = 2.7379e-01, time/batch = 0.7003s	
1158/33250 (epoch 1.741), train_loss = 1.79370214, grad/param norm = 2.9468e-01, time/batch = 0.7107s	
1159/33250 (epoch 1.743), train_loss = 1.86468804, grad/param norm = 2.8251e-01, time/batch = 0.7013s	
1160/33250 (epoch 1.744), train_loss = 1.86134746, grad/param norm = 2.6828e-01, time/batch = 0.7010s	
1161/33250 (epoch 1.746), train_loss = 1.89477485, grad/param norm = 2.9562e-01, time/batch = 0.7029s	
1162/33250 (epoch 1.747), train_loss = 1.80946944, grad/param norm = 2.3703e-01, time/batch = 0.6998s	
1163/33250 (epoch 1.749), train_loss = 1.95247955, grad/param norm = 2.5572e-01, time/batch = 0.6932s	
1164/33250 (epoch 1.750), train_loss = 1.81767201, grad/param norm = 2.8850e-01, time/batch = 0.6924s	
1165/33250 (epoch 1.752), train_loss = 1.74525084, grad/param norm = 2.8018e-01, time/batch = 0.6992s	
1166/33250 (epoch 1.753), train_loss = 1.83825003, grad/param norm = 2.9746e-01, time/batch = 0.6970s	
1167/33250 (epoch 1.755), train_loss = 1.68536989, grad/param norm = 2.8312e-01, time/batch = 0.6978s	
1168/33250 (epoch 1.756), train_loss = 1.93526150, grad/param norm = 2.5589e-01, time/batch = 0.6948s	
1169/33250 (epoch 1.758), train_loss = 1.87566214, grad/param norm = 2.9662e-01, time/batch = 0.6982s	
1170/33250 (epoch 1.759), train_loss = 1.63444532, grad/param norm = 2.4742e-01, time/batch = 0.6993s	
1171/33250 (epoch 1.761), train_loss = 1.83263626, grad/param norm = 2.9758e-01, time/batch = 0.7011s	
1172/33250 (epoch 1.762), train_loss = 1.85632675, grad/param norm = 2.6810e-01, time/batch = 0.7052s	
1173/33250 (epoch 1.764), train_loss = 1.73410539, grad/param norm = 2.9435e-01, time/batch = 0.7030s	
1174/33250 (epoch 1.765), train_loss = 1.82279784, grad/param norm = 3.0160e-01, time/batch = 0.6989s	
1175/33250 (epoch 1.767), train_loss = 1.66088825, grad/param norm = 3.2309e-01, time/batch = 0.7042s	
1176/33250 (epoch 1.768), train_loss = 1.76596204, grad/param norm = 2.8627e-01, time/batch = 0.6963s	
1177/33250 (epoch 1.770), train_loss = 1.76302194, grad/param norm = 2.5827e-01, time/batch = 0.7026s	
1178/33250 (epoch 1.771), train_loss = 1.86732682, grad/param norm = 2.4664e-01, time/batch = 0.6990s	
1179/33250 (epoch 1.773), train_loss = 1.82256912, grad/param norm = 2.9852e-01, time/batch = 0.6982s	
1180/33250 (epoch 1.774), train_loss = 1.63428697, grad/param norm = 2.8638e-01, time/batch = 0.7000s	
1181/33250 (epoch 1.776), train_loss = 1.84438359, grad/param norm = 2.9850e-01, time/batch = 0.7048s	
1182/33250 (epoch 1.777), train_loss = 1.98068350, grad/param norm = 2.8593e-01, time/batch = 0.7022s	
1183/33250 (epoch 1.779), train_loss = 1.63297428, grad/param norm = 2.7538e-01, time/batch = 0.7005s	
1184/33250 (epoch 1.780), train_loss = 1.98182240, grad/param norm = 2.7886e-01, time/batch = 0.6948s	
1185/33250 (epoch 1.782), train_loss = 1.94848498, grad/param norm = 3.0281e-01, time/batch = 0.6973s	
1186/33250 (epoch 1.783), train_loss = 1.67813754, grad/param norm = 3.0992e-01, time/batch = 0.6986s	
1187/33250 (epoch 1.785), train_loss = 1.73901924, grad/param norm = 3.4966e-01, time/batch = 0.7069s	
1188/33250 (epoch 1.786), train_loss = 1.96739733, grad/param norm = 2.9057e-01, time/batch = 0.7116s	
1189/33250 (epoch 1.788), train_loss = 1.72200755, grad/param norm = 2.5645e-01, time/batch = 0.6988s	
1190/33250 (epoch 1.789), train_loss = 1.82589456, grad/param norm = 3.0585e-01, time/batch = 0.7053s	
1191/33250 (epoch 1.791), train_loss = 1.94667683, grad/param norm = 3.4691e-01, time/batch = 0.7020s	
1192/33250 (epoch 1.792), train_loss = 1.99685582, grad/param norm = 2.8690e-01, time/batch = 0.7051s	
1193/33250 (epoch 1.794), train_loss = 1.67008465, grad/param norm = 2.8794e-01, time/batch = 0.6985s	
1194/33250 (epoch 1.795), train_loss = 1.87034373, grad/param norm = 2.7064e-01, time/batch = 0.6984s	
1195/33250 (epoch 1.797), train_loss = 1.97395396, grad/param norm = 2.8520e-01, time/batch = 0.7016s	
1196/33250 (epoch 1.798), train_loss = 1.98521527, grad/param norm = 3.5759e-01, time/batch = 0.6955s	
1197/33250 (epoch 1.800), train_loss = 1.94982830, grad/param norm = 3.1979e-01, time/batch = 0.7047s	
1198/33250 (epoch 1.802), train_loss = 1.72714990, grad/param norm = 2.5237e-01, time/batch = 0.6952s	
1199/33250 (epoch 1.803), train_loss = 1.76778245, grad/param norm = 2.4931e-01, time/batch = 0.6974s	
1200/33250 (epoch 1.805), train_loss = 1.78988268, grad/param norm = 2.4338e-01, time/batch = 0.6947s	
1201/33250 (epoch 1.806), train_loss = 1.91537145, grad/param norm = 2.5813e-01, time/batch = 0.7038s	
1202/33250 (epoch 1.808), train_loss = 1.87118926, grad/param norm = 2.4596e-01, time/batch = 0.6968s	
1203/33250 (epoch 1.809), train_loss = 1.61967301, grad/param norm = 2.4992e-01, time/batch = 0.6972s	
1204/33250 (epoch 1.811), train_loss = 1.80133169, grad/param norm = 3.1635e-01, time/batch = 0.6930s	
1205/33250 (epoch 1.812), train_loss = 1.74547048, grad/param norm = 3.1432e-01, time/batch = 0.6986s	
1206/33250 (epoch 1.814), train_loss = 1.78235773, grad/param norm = 2.7957e-01, time/batch = 0.6962s	
1207/33250 (epoch 1.815), train_loss = 1.87569760, grad/param norm = 3.2070e-01, time/batch = 0.6931s	
1208/33250 (epoch 1.817), train_loss = 1.79958447, grad/param norm = 2.4743e-01, time/batch = 0.6972s	
1209/33250 (epoch 1.818), train_loss = 1.66204516, grad/param norm = 2.4518e-01, time/batch = 0.7020s	
1210/33250 (epoch 1.820), train_loss = 1.81144672, grad/param norm = 2.6756e-01, time/batch = 0.6993s	
1211/33250 (epoch 1.821), train_loss = 1.61605342, grad/param norm = 2.6183e-01, time/batch = 0.7014s	
1212/33250 (epoch 1.823), train_loss = 1.97535394, grad/param norm = 2.8108e-01, time/batch = 0.7130s	
1213/33250 (epoch 1.824), train_loss = 1.77360015, grad/param norm = 3.2963e-01, time/batch = 0.7213s	
1214/33250 (epoch 1.826), train_loss = 1.77515269, grad/param norm = 3.0342e-01, time/batch = 0.7228s	
1215/33250 (epoch 1.827), train_loss = 1.60580617, grad/param norm = 2.4407e-01, time/batch = 0.7020s	
1216/33250 (epoch 1.829), train_loss = 1.78329523, grad/param norm = 2.3535e-01, time/batch = 0.6821s	
1217/33250 (epoch 1.830), train_loss = 2.12240642, grad/param norm = 3.1863e-01, time/batch = 0.6824s	
1218/33250 (epoch 1.832), train_loss = 1.70293260, grad/param norm = 2.4994e-01, time/batch = 0.6877s	
1219/33250 (epoch 1.833), train_loss = 1.85547749, grad/param norm = 2.9100e-01, time/batch = 0.6921s	
1220/33250 (epoch 1.835), train_loss = 1.84651437, grad/param norm = 3.0969e-01, time/batch = 0.6971s	
1221/33250 (epoch 1.836), train_loss = 1.84025813, grad/param norm = 2.6791e-01, time/batch = 0.6828s	
1222/33250 (epoch 1.838), train_loss = 1.67586800, grad/param norm = 2.3450e-01, time/batch = 0.6803s	
1223/33250 (epoch 1.839), train_loss = 1.74815378, grad/param norm = 2.7145e-01, time/batch = 0.6823s	
1224/33250 (epoch 1.841), train_loss = 1.57302634, grad/param norm = 2.4568e-01, time/batch = 0.6818s	
1225/33250 (epoch 1.842), train_loss = 1.81570297, grad/param norm = 2.4173e-01, time/batch = 0.6777s	
1226/33250 (epoch 1.844), train_loss = 1.98527072, grad/param norm = 2.8062e-01, time/batch = 0.6747s	
1227/33250 (epoch 1.845), train_loss = 2.03227864, grad/param norm = 3.2592e-01, time/batch = 0.6927s	
1228/33250 (epoch 1.847), train_loss = 1.92170142, grad/param norm = 2.8373e-01, time/batch = 0.6958s	
1229/33250 (epoch 1.848), train_loss = 1.99000459, grad/param norm = 3.0198e-01, time/batch = 0.6947s	
1230/33250 (epoch 1.850), train_loss = 1.82293036, grad/param norm = 2.8282e-01, time/batch = 0.6983s	
1231/33250 (epoch 1.851), train_loss = 1.69663939, grad/param norm = 2.7646e-01, time/batch = 0.6968s	
1232/33250 (epoch 1.853), train_loss = 1.85404239, grad/param norm = 2.5162e-01, time/batch = 0.6941s	
1233/33250 (epoch 1.854), train_loss = 1.62432409, grad/param norm = 2.6509e-01, time/batch = 0.6897s	
1234/33250 (epoch 1.856), train_loss = 1.71585897, grad/param norm = 2.8160e-01, time/batch = 0.6904s	
1235/33250 (epoch 1.857), train_loss = 1.50842373, grad/param norm = 2.3011e-01, time/batch = 0.6910s	
1236/33250 (epoch 1.859), train_loss = 1.57412957, grad/param norm = 2.4705e-01, time/batch = 0.6946s	
1237/33250 (epoch 1.860), train_loss = 1.62936539, grad/param norm = 2.3270e-01, time/batch = 0.6930s	
1238/33250 (epoch 1.862), train_loss = 1.70201026, grad/param norm = 2.4156e-01, time/batch = 0.6969s	
1239/33250 (epoch 1.863), train_loss = 1.66322280, grad/param norm = 2.5075e-01, time/batch = 0.6958s	
1240/33250 (epoch 1.865), train_loss = 1.75238282, grad/param norm = 2.4180e-01, time/batch = 0.7162s	
1241/33250 (epoch 1.866), train_loss = 1.78383880, grad/param norm = 2.5772e-01, time/batch = 0.7182s	
1242/33250 (epoch 1.868), train_loss = 2.14360559, grad/param norm = 3.0170e-01, time/batch = 0.7038s	
1243/33250 (epoch 1.869), train_loss = 1.84974573, grad/param norm = 2.3737e-01, time/batch = 0.7139s	
1244/33250 (epoch 1.871), train_loss = 1.47889252, grad/param norm = 2.2298e-01, time/batch = 0.7014s	
1245/33250 (epoch 1.872), train_loss = 1.91628523, grad/param norm = 2.5179e-01, time/batch = 0.6996s	
1246/33250 (epoch 1.874), train_loss = 1.70009686, grad/param norm = 2.5428e-01, time/batch = 0.6990s	
1247/33250 (epoch 1.875), train_loss = 1.73583762, grad/param norm = 3.1685e-01, time/batch = 0.7008s	
1248/33250 (epoch 1.877), train_loss = 1.82280231, grad/param norm = 2.7555e-01, time/batch = 0.6925s	
1249/33250 (epoch 1.878), train_loss = 1.73356452, grad/param norm = 2.2565e-01, time/batch = 0.6982s	
1250/33250 (epoch 1.880), train_loss = 1.91779597, grad/param norm = 2.8434e-01, time/batch = 0.6905s	
1251/33250 (epoch 1.881), train_loss = 1.92056414, grad/param norm = 2.7298e-01, time/batch = 0.7007s	
1252/33250 (epoch 1.883), train_loss = 1.90256192, grad/param norm = 3.0983e-01, time/batch = 0.6958s	
1253/33250 (epoch 1.884), train_loss = 1.69778825, grad/param norm = 2.9173e-01, time/batch = 0.6929s	
1254/33250 (epoch 1.886), train_loss = 1.62077960, grad/param norm = 2.4116e-01, time/batch = 0.6950s	
1255/33250 (epoch 1.887), train_loss = 1.74564157, grad/param norm = 2.8058e-01, time/batch = 0.6941s	
1256/33250 (epoch 1.889), train_loss = 1.60820792, grad/param norm = 1.9630e-01, time/batch = 0.6977s	
1257/33250 (epoch 1.890), train_loss = 1.58463424, grad/param norm = 2.6332e-01, time/batch = 0.6962s	
1258/33250 (epoch 1.892), train_loss = 1.83344121, grad/param norm = 2.6938e-01, time/batch = 0.7067s	
1259/33250 (epoch 1.893), train_loss = 1.80758830, grad/param norm = 2.5058e-01, time/batch = 0.6802s	
1260/33250 (epoch 1.895), train_loss = 1.73849068, grad/param norm = 2.7862e-01, time/batch = 0.6770s	
1261/33250 (epoch 1.896), train_loss = 1.88655373, grad/param norm = 2.8399e-01, time/batch = 0.6889s	
1262/33250 (epoch 1.898), train_loss = 1.69881162, grad/param norm = 2.4377e-01, time/batch = 0.6981s	
1263/33250 (epoch 1.899), train_loss = 1.79162651, grad/param norm = 2.5103e-01, time/batch = 0.6819s	
1264/33250 (epoch 1.901), train_loss = 1.60849043, grad/param norm = 2.1525e-01, time/batch = 0.6840s	
1265/33250 (epoch 1.902), train_loss = 1.63461437, grad/param norm = 2.5658e-01, time/batch = 0.6822s	
1266/33250 (epoch 1.904), train_loss = 1.66775990, grad/param norm = 2.5204e-01, time/batch = 0.6831s	
1267/33250 (epoch 1.905), train_loss = 1.69667511, grad/param norm = 2.5327e-01, time/batch = 0.6840s	
1268/33250 (epoch 1.907), train_loss = 1.75711086, grad/param norm = 2.7520e-01, time/batch = 0.6814s	
1269/33250 (epoch 1.908), train_loss = 1.76427986, grad/param norm = 2.3714e-01, time/batch = 0.6857s	
1270/33250 (epoch 1.910), train_loss = 1.91803127, grad/param norm = 3.0408e-01, time/batch = 0.6814s	
1271/33250 (epoch 1.911), train_loss = 1.63550387, grad/param norm = 3.0488e-01, time/batch = 0.6819s	
1272/33250 (epoch 1.913), train_loss = 1.65892069, grad/param norm = 2.4557e-01, time/batch = 0.6797s	
1273/33250 (epoch 1.914), train_loss = 1.57703806, grad/param norm = 2.8335e-01, time/batch = 0.6793s	
1274/33250 (epoch 1.916), train_loss = 1.62040101, grad/param norm = 2.4627e-01, time/batch = 0.6917s	
1275/33250 (epoch 1.917), train_loss = 1.74547239, grad/param norm = 2.5248e-01, time/batch = 0.6783s	
1276/33250 (epoch 1.919), train_loss = 1.78874743, grad/param norm = 2.8842e-01, time/batch = 0.6871s	
1277/33250 (epoch 1.920), train_loss = 1.76380920, grad/param norm = 2.8379e-01, time/batch = 0.6775s	
1278/33250 (epoch 1.922), train_loss = 1.78927535, grad/param norm = 2.6951e-01, time/batch = 0.6831s	
1279/33250 (epoch 1.923), train_loss = 1.74391137, grad/param norm = 2.7782e-01, time/batch = 0.6788s	
1280/33250 (epoch 1.925), train_loss = 1.70835848, grad/param norm = 2.6844e-01, time/batch = 0.6785s	
1281/33250 (epoch 1.926), train_loss = 1.77423275, grad/param norm = 3.4476e-01, time/batch = 0.6857s	
1282/33250 (epoch 1.928), train_loss = 1.83617386, grad/param norm = 3.3576e-01, time/batch = 0.6781s	
1283/33250 (epoch 1.929), train_loss = 1.40085766, grad/param norm = 2.2859e-01, time/batch = 0.6789s	
1284/33250 (epoch 1.931), train_loss = 1.75375974, grad/param norm = 2.6913e-01, time/batch = 0.6822s	
1285/33250 (epoch 1.932), train_loss = 1.87610934, grad/param norm = 2.6390e-01, time/batch = 0.6770s	
1286/33250 (epoch 1.934), train_loss = 1.68064635, grad/param norm = 2.5215e-01, time/batch = 0.6756s	
1287/33250 (epoch 1.935), train_loss = 1.75073607, grad/param norm = 2.7119e-01, time/batch = 0.6871s	
1288/33250 (epoch 1.937), train_loss = 1.73400634, grad/param norm = 2.5061e-01, time/batch = 0.6892s	
1289/33250 (epoch 1.938), train_loss = 1.88399112, grad/param norm = 2.5296e-01, time/batch = 0.6806s	
1290/33250 (epoch 1.940), train_loss = 1.76624437, grad/param norm = 2.7784e-01, time/batch = 0.6832s	
1291/33250 (epoch 1.941), train_loss = 1.83260996, grad/param norm = 3.1291e-01, time/batch = 0.6892s	
1292/33250 (epoch 1.943), train_loss = 1.91933604, grad/param norm = 2.5131e-01, time/batch = 0.6799s	
1293/33250 (epoch 1.944), train_loss = 1.60186756, grad/param norm = 2.7468e-01, time/batch = 0.6820s	
1294/33250 (epoch 1.946), train_loss = 2.02314625, grad/param norm = 2.6509e-01, time/batch = 0.6875s	
1295/33250 (epoch 1.947), train_loss = 1.69448153, grad/param norm = 2.3700e-01, time/batch = 0.6866s	
1296/33250 (epoch 1.949), train_loss = 1.92996191, grad/param norm = 2.7140e-01, time/batch = 0.6897s	
1297/33250 (epoch 1.950), train_loss = 1.78143212, grad/param norm = 2.7200e-01, time/batch = 0.6865s	
1298/33250 (epoch 1.952), train_loss = 1.82484794, grad/param norm = 2.4633e-01, time/batch = 0.6865s	
1299/33250 (epoch 1.953), train_loss = 1.82877988, grad/param norm = 2.5333e-01, time/batch = 0.6965s	
1300/33250 (epoch 1.955), train_loss = 1.88564679, grad/param norm = 2.8103e-01, time/batch = 0.7134s	
1301/33250 (epoch 1.956), train_loss = 1.95519645, grad/param norm = 2.7137e-01, time/batch = 0.7379s	
1302/33250 (epoch 1.958), train_loss = 1.69162357, grad/param norm = 2.3408e-01, time/batch = 0.7363s	
1303/33250 (epoch 1.959), train_loss = 1.63806060, grad/param norm = 2.1836e-01, time/batch = 0.7276s	
1304/33250 (epoch 1.961), train_loss = 1.82671882, grad/param norm = 2.6493e-01, time/batch = 0.7113s	
1305/33250 (epoch 1.962), train_loss = 1.85416003, grad/param norm = 2.8902e-01, time/batch = 0.7134s	
1306/33250 (epoch 1.964), train_loss = 1.80471350, grad/param norm = 2.6778e-01, time/batch = 0.7124s	
1307/33250 (epoch 1.965), train_loss = 1.84660433, grad/param norm = 2.6207e-01, time/batch = 0.7050s	
1308/33250 (epoch 1.967), train_loss = 1.88880034, grad/param norm = 2.4845e-01, time/batch = 0.7003s	
1309/33250 (epoch 1.968), train_loss = 1.87041366, grad/param norm = 2.5920e-01, time/batch = 0.6933s	
1310/33250 (epoch 1.970), train_loss = 2.05249082, grad/param norm = 3.1471e-01, time/batch = 0.6960s	
1311/33250 (epoch 1.971), train_loss = 1.97447112, grad/param norm = 2.4428e-01, time/batch = 0.7002s	
1312/33250 (epoch 1.973), train_loss = 1.74823912, grad/param norm = 2.2707e-01, time/batch = 0.6988s	
1313/33250 (epoch 1.974), train_loss = 1.81794024, grad/param norm = 2.6072e-01, time/batch = 0.7085s	
1314/33250 (epoch 1.976), train_loss = 1.66195200, grad/param norm = 2.5356e-01, time/batch = 0.7053s	
1315/33250 (epoch 1.977), train_loss = 1.62491853, grad/param norm = 2.7826e-01, time/batch = 0.7090s	
1316/33250 (epoch 1.979), train_loss = 1.72761052, grad/param norm = 3.1155e-01, time/batch = 0.7129s	
1317/33250 (epoch 1.980), train_loss = 1.69614159, grad/param norm = 2.6026e-01, time/batch = 0.7409s	
1318/33250 (epoch 1.982), train_loss = 1.60805908, grad/param norm = 2.3544e-01, time/batch = 0.7244s	
1319/33250 (epoch 1.983), train_loss = 1.85899398, grad/param norm = 2.4652e-01, time/batch = 0.7175s	
1320/33250 (epoch 1.985), train_loss = 1.62974678, grad/param norm = 2.6058e-01, time/batch = 0.7167s	
1321/33250 (epoch 1.986), train_loss = 1.96308551, grad/param norm = 2.9193e-01, time/batch = 0.7002s	
1322/33250 (epoch 1.988), train_loss = 1.74257407, grad/param norm = 3.6361e-01, time/batch = 0.6909s	
1323/33250 (epoch 1.989), train_loss = 1.85700809, grad/param norm = 2.4825e-01, time/batch = 0.6902s	
1324/33250 (epoch 1.991), train_loss = 1.74852453, grad/param norm = 2.3226e-01, time/batch = 0.6905s	
1325/33250 (epoch 1.992), train_loss = 1.69952428, grad/param norm = 2.4899e-01, time/batch = 0.6882s	
1326/33250 (epoch 1.994), train_loss = 1.60809597, grad/param norm = 2.4472e-01, time/batch = 0.6913s	
1327/33250 (epoch 1.995), train_loss = 1.79769145, grad/param norm = 2.7895e-01, time/batch = 0.6897s	
1328/33250 (epoch 1.997), train_loss = 1.44503144, grad/param norm = 2.4076e-01, time/batch = 0.6897s	
1329/33250 (epoch 1.998), train_loss = 1.77262291, grad/param norm = 2.6543e-01, time/batch = 0.6917s	
1330/33250 (epoch 2.000), train_loss = 1.75952659, grad/param norm = 2.6630e-01, time/batch = 0.6931s	
1331/33250 (epoch 2.002), train_loss = 1.89391080, grad/param norm = 2.5029e-01, time/batch = 0.6892s	
1332/33250 (epoch 2.003), train_loss = 1.79001900, grad/param norm = 2.6403e-01, time/batch = 0.6857s	
1333/33250 (epoch 2.005), train_loss = 1.61356421, grad/param norm = 2.7977e-01, time/batch = 0.6894s	
1334/33250 (epoch 2.006), train_loss = 1.51870088, grad/param norm = 2.4907e-01, time/batch = 0.7159s	
1335/33250 (epoch 2.008), train_loss = 1.79660282, grad/param norm = 2.5562e-01, time/batch = 0.7139s	
1336/33250 (epoch 2.009), train_loss = 1.86446878, grad/param norm = 2.7012e-01, time/batch = 0.6943s	
1337/33250 (epoch 2.011), train_loss = 1.73454211, grad/param norm = 2.4818e-01, time/batch = 0.6892s	
1338/33250 (epoch 2.012), train_loss = 1.87140357, grad/param norm = 2.6733e-01, time/batch = 0.6882s	
1339/33250 (epoch 2.014), train_loss = 1.76823349, grad/param norm = 2.2708e-01, time/batch = 0.6897s	
1340/33250 (epoch 2.015), train_loss = 1.78064731, grad/param norm = 2.8510e-01, time/batch = 0.6881s	
1341/33250 (epoch 2.017), train_loss = 1.80508811, grad/param norm = 2.6442e-01, time/batch = 0.6942s	
1342/33250 (epoch 2.018), train_loss = 1.61542826, grad/param norm = 2.6516e-01, time/batch = 0.6924s	
1343/33250 (epoch 2.020), train_loss = 1.68294859, grad/param norm = 2.3774e-01, time/batch = 0.6871s	
1344/33250 (epoch 2.021), train_loss = 1.74402913, grad/param norm = 2.6039e-01, time/batch = 0.6859s	
1345/33250 (epoch 2.023), train_loss = 1.61124035, grad/param norm = 2.7738e-01, time/batch = 0.6968s	
1346/33250 (epoch 2.024), train_loss = 1.82884233, grad/param norm = 2.9016e-01, time/batch = 0.6813s	
1347/33250 (epoch 2.026), train_loss = 1.66183431, grad/param norm = 2.8967e-01, time/batch = 0.6776s	
1348/33250 (epoch 2.027), train_loss = 1.66802921, grad/param norm = 2.8810e-01, time/batch = 0.6806s	
1349/33250 (epoch 2.029), train_loss = 1.71332110, grad/param norm = 2.6370e-01, time/batch = 0.6901s	
1350/33250 (epoch 2.030), train_loss = 1.77917216, grad/param norm = 2.7785e-01, time/batch = 0.6821s	
1351/33250 (epoch 2.032), train_loss = 1.96758753, grad/param norm = 2.7441e-01, time/batch = 0.6843s	
1352/33250 (epoch 2.033), train_loss = 1.64827272, grad/param norm = 2.6986e-01, time/batch = 0.6824s	
1353/33250 (epoch 2.035), train_loss = 1.63566939, grad/param norm = 2.4656e-01, time/batch = 0.7009s	
1354/33250 (epoch 2.036), train_loss = 1.73035690, grad/param norm = 2.5409e-01, time/batch = 0.7239s	
1355/33250 (epoch 2.038), train_loss = 1.57812378, grad/param norm = 2.7633e-01, time/batch = 0.7253s	
1356/33250 (epoch 2.039), train_loss = 1.60876897, grad/param norm = 2.9085e-01, time/batch = 0.7044s	
1357/33250 (epoch 2.041), train_loss = 1.85242855, grad/param norm = 2.7097e-01, time/batch = 0.6972s	
1358/33250 (epoch 2.042), train_loss = 1.50560800, grad/param norm = 2.1501e-01, time/batch = 0.6916s	
1359/33250 (epoch 2.044), train_loss = 1.92266335, grad/param norm = 2.3486e-01, time/batch = 0.6921s	
1360/33250 (epoch 2.045), train_loss = 1.75242963, grad/param norm = 2.3189e-01, time/batch = 0.7012s	
1361/33250 (epoch 2.047), train_loss = 1.89550961, grad/param norm = 2.7176e-01, time/batch = 0.6880s	
1362/33250 (epoch 2.048), train_loss = 1.93694025, grad/param norm = 2.5917e-01, time/batch = 0.6813s	
1363/33250 (epoch 2.050), train_loss = 1.75232893, grad/param norm = 2.5083e-01, time/batch = 0.6744s	
1364/33250 (epoch 2.051), train_loss = 1.70699711, grad/param norm = 2.2278e-01, time/batch = 0.6818s	
1365/33250 (epoch 2.053), train_loss = 1.81659508, grad/param norm = 2.4244e-01, time/batch = 0.6928s	
1366/33250 (epoch 2.054), train_loss = 1.53688649, grad/param norm = 2.4930e-01, time/batch = 0.6888s	
1367/33250 (epoch 2.056), train_loss = 1.68139591, grad/param norm = 2.9795e-01, time/batch = 0.6822s	
1368/33250 (epoch 2.057), train_loss = 1.66359253, grad/param norm = 2.6968e-01, time/batch = 0.6806s	
1369/33250 (epoch 2.059), train_loss = 1.62337892, grad/param norm = 2.5627e-01, time/batch = 0.6793s	
1370/33250 (epoch 2.060), train_loss = 1.78471722, grad/param norm = 2.7620e-01, time/batch = 0.6830s	
1371/33250 (epoch 2.062), train_loss = 1.85783117, grad/param norm = 2.5470e-01, time/batch = 0.6855s	
1372/33250 (epoch 2.063), train_loss = 1.85214507, grad/param norm = 2.4825e-01, time/batch = 0.6795s	
1373/33250 (epoch 2.065), train_loss = 1.79054818, grad/param norm = 2.5307e-01, time/batch = 0.6808s	
1374/33250 (epoch 2.066), train_loss = 1.83587139, grad/param norm = 2.4200e-01, time/batch = 0.6800s	
1375/33250 (epoch 2.068), train_loss = 1.72781391, grad/param norm = 2.5077e-01, time/batch = 0.6790s	
1376/33250 (epoch 2.069), train_loss = 1.75649234, grad/param norm = 2.3113e-01, time/batch = 0.6770s	
1377/33250 (epoch 2.071), train_loss = 1.57287519, grad/param norm = 2.2184e-01, time/batch = 0.6777s	
1378/33250 (epoch 2.072), train_loss = 1.63593368, grad/param norm = 2.1894e-01, time/batch = 0.6775s	
1379/33250 (epoch 2.074), train_loss = 1.72597125, grad/param norm = 2.4148e-01, time/batch = 0.6797s	
1380/33250 (epoch 2.075), train_loss = 1.62802845, grad/param norm = 2.1872e-01, time/batch = 0.6790s	
1381/33250 (epoch 2.077), train_loss = 1.79652715, grad/param norm = 2.3409e-01, time/batch = 0.6824s	
1382/33250 (epoch 2.078), train_loss = 1.58604460, grad/param norm = 2.2430e-01, time/batch = 0.6813s	
1383/33250 (epoch 2.080), train_loss = 1.77152949, grad/param norm = 2.6686e-01, time/batch = 0.6883s	
1384/33250 (epoch 2.081), train_loss = 1.79783428, grad/param norm = 2.9057e-01, time/batch = 0.6913s	
1385/33250 (epoch 2.083), train_loss = 1.80214018, grad/param norm = 3.0757e-01, time/batch = 0.6983s	
1386/33250 (epoch 2.084), train_loss = 1.69536014, grad/param norm = 2.4115e-01, time/batch = 0.7084s	
1387/33250 (epoch 2.086), train_loss = 1.71491920, grad/param norm = 2.3491e-01, time/batch = 0.6936s	
1388/33250 (epoch 2.087), train_loss = 1.56350066, grad/param norm = 2.5766e-01, time/batch = 0.6820s	
1389/33250 (epoch 2.089), train_loss = 1.77040469, grad/param norm = 2.3820e-01, time/batch = 0.6809s	
1390/33250 (epoch 2.090), train_loss = 1.66955556, grad/param norm = 2.7386e-01, time/batch = 0.6856s	
1391/33250 (epoch 2.092), train_loss = 1.56438437, grad/param norm = 2.5069e-01, time/batch = 0.6905s	
1392/33250 (epoch 2.093), train_loss = 1.64605038, grad/param norm = 2.7376e-01, time/batch = 0.6820s	
1393/33250 (epoch 2.095), train_loss = 1.69232364, grad/param norm = 2.5096e-01, time/batch = 0.6809s	
1394/33250 (epoch 2.096), train_loss = 1.59841370, grad/param norm = 2.2711e-01, time/batch = 0.6836s	
1395/33250 (epoch 2.098), train_loss = 1.55845329, grad/param norm = 2.5447e-01, time/batch = 0.7127s	
1396/33250 (epoch 2.099), train_loss = 1.50774174, grad/param norm = 2.8280e-01, time/batch = 0.7266s	
1397/33250 (epoch 2.101), train_loss = 1.71874667, grad/param norm = 2.8191e-01, time/batch = 0.6929s	
1398/33250 (epoch 2.102), train_loss = 1.53360842, grad/param norm = 2.1615e-01, time/batch = 0.6870s	
1399/33250 (epoch 2.104), train_loss = 1.48553558, grad/param norm = 2.1381e-01, time/batch = 0.6811s	
1400/33250 (epoch 2.105), train_loss = 1.65043701, grad/param norm = 2.2621e-01, time/batch = 0.6792s	
1401/33250 (epoch 2.107), train_loss = 1.38692880, grad/param norm = 2.2113e-01, time/batch = 0.6804s	
1402/33250 (epoch 2.108), train_loss = 1.68598504, grad/param norm = 2.6418e-01, time/batch = 0.6856s	
1403/33250 (epoch 2.110), train_loss = 1.52621621, grad/param norm = 2.3565e-01, time/batch = 0.6954s	
1404/33250 (epoch 2.111), train_loss = 1.61616634, grad/param norm = 2.3379e-01, time/batch = 0.6966s	
1405/33250 (epoch 2.113), train_loss = 1.62057773, grad/param norm = 2.5171e-01, time/batch = 0.6892s	
1406/33250 (epoch 2.114), train_loss = 1.65587181, grad/param norm = 2.6266e-01, time/batch = 0.6856s	
1407/33250 (epoch 2.116), train_loss = 1.72493024, grad/param norm = 2.5788e-01, time/batch = 0.6837s	
1408/33250 (epoch 2.117), train_loss = 1.68336030, grad/param norm = 2.6345e-01, time/batch = 0.6839s	
1409/33250 (epoch 2.119), train_loss = 1.59590163, grad/param norm = 2.1344e-01, time/batch = 0.6823s	
1410/33250 (epoch 2.120), train_loss = 1.37277287, grad/param norm = 2.8294e-01, time/batch = 0.6943s	
1411/33250 (epoch 2.122), train_loss = 1.76160429, grad/param norm = 2.4237e-01, time/batch = 0.6848s	
1412/33250 (epoch 2.123), train_loss = 1.73704161, grad/param norm = 2.4807e-01, time/batch = 0.7035s	
1413/33250 (epoch 2.125), train_loss = 1.52983506, grad/param norm = 2.5370e-01, time/batch = 0.7128s	
1414/33250 (epoch 2.126), train_loss = 1.73243836, grad/param norm = 2.6040e-01, time/batch = 0.7135s	
1415/33250 (epoch 2.128), train_loss = 1.56946730, grad/param norm = 2.4787e-01, time/batch = 0.7284s	
1416/33250 (epoch 2.129), train_loss = 1.60499977, grad/param norm = 2.5855e-01, time/batch = 0.7266s	
1417/33250 (epoch 2.131), train_loss = 1.70701494, grad/param norm = 2.3859e-01, time/batch = 0.7186s	
1418/33250 (epoch 2.132), train_loss = 1.62566673, grad/param norm = 2.1455e-01, time/batch = 0.7102s	
1419/33250 (epoch 2.134), train_loss = 1.75012119, grad/param norm = 2.5147e-01, time/batch = 0.7084s	
1420/33250 (epoch 2.135), train_loss = 1.75207438, grad/param norm = 2.3041e-01, time/batch = 0.7032s	
1421/33250 (epoch 2.137), train_loss = 1.50814216, grad/param norm = 2.3674e-01, time/batch = 0.7092s	
1422/33250 (epoch 2.138), train_loss = 1.57442310, grad/param norm = 2.3651e-01, time/batch = 0.6862s	
1423/33250 (epoch 2.140), train_loss = 1.55828667, grad/param norm = 2.5109e-01, time/batch = 0.6821s	
1424/33250 (epoch 2.141), train_loss = 2.04855586, grad/param norm = 2.7220e-01, time/batch = 0.6920s	
1425/33250 (epoch 2.143), train_loss = 1.42561159, grad/param norm = 2.8502e-01, time/batch = 0.6905s	
1426/33250 (epoch 2.144), train_loss = 1.55797227, grad/param norm = 2.1267e-01, time/batch = 0.6870s	
1427/33250 (epoch 2.146), train_loss = 1.51484879, grad/param norm = 2.3045e-01, time/batch = 0.7049s	
1428/33250 (epoch 2.147), train_loss = 1.57395022, grad/param norm = 2.8040e-01, time/batch = 0.6851s	
1429/33250 (epoch 2.149), train_loss = 1.71080371, grad/param norm = 2.3676e-01, time/batch = 0.6916s	
1430/33250 (epoch 2.150), train_loss = 1.47267709, grad/param norm = 2.5126e-01, time/batch = 0.7045s	
1431/33250 (epoch 2.152), train_loss = 1.50440633, grad/param norm = 2.2571e-01, time/batch = 0.6943s	
1432/33250 (epoch 2.153), train_loss = 1.71320915, grad/param norm = 2.8677e-01, time/batch = 0.6902s	
1433/33250 (epoch 2.155), train_loss = 1.70474401, grad/param norm = 2.4783e-01, time/batch = 0.6928s	
1434/33250 (epoch 2.156), train_loss = 1.65307435, grad/param norm = 2.7022e-01, time/batch = 0.6859s	
1435/33250 (epoch 2.158), train_loss = 2.05474442, grad/param norm = 2.8970e-01, time/batch = 0.6890s	
1436/33250 (epoch 2.159), train_loss = 1.67977570, grad/param norm = 2.4058e-01, time/batch = 0.6847s	
1437/33250 (epoch 2.161), train_loss = 1.75337408, grad/param norm = 2.6597e-01, time/batch = 0.6843s	
1438/33250 (epoch 2.162), train_loss = 1.64037769, grad/param norm = 2.6036e-01, time/batch = 0.6883s	
1439/33250 (epoch 2.164), train_loss = 1.75271418, grad/param norm = 2.4641e-01, time/batch = 0.6881s	
1440/33250 (epoch 2.165), train_loss = 1.70736164, grad/param norm = 2.4256e-01, time/batch = 0.7024s	
1441/33250 (epoch 2.167), train_loss = 1.71787477, grad/param norm = 2.4575e-01, time/batch = 0.7179s	
1442/33250 (epoch 2.168), train_loss = 1.45922660, grad/param norm = 2.0963e-01, time/batch = 0.7168s	
1443/33250 (epoch 2.170), train_loss = 1.62164467, grad/param norm = 2.5808e-01, time/batch = 0.7140s	
1444/33250 (epoch 2.171), train_loss = 1.56336240, grad/param norm = 2.1985e-01, time/batch = 0.7134s	
1445/33250 (epoch 2.173), train_loss = 1.52458776, grad/param norm = 2.7182e-01, time/batch = 0.7109s	
1446/33250 (epoch 2.174), train_loss = 1.64112104, grad/param norm = 3.0623e-01, time/batch = 0.7208s	
1447/33250 (epoch 2.176), train_loss = 1.76405231, grad/param norm = 2.7970e-01, time/batch = 0.7094s	
1448/33250 (epoch 2.177), train_loss = 1.39157018, grad/param norm = 1.9931e-01, time/batch = 0.7123s	
1449/33250 (epoch 2.179), train_loss = 1.63532306, grad/param norm = 2.4129e-01, time/batch = 0.7091s	
1450/33250 (epoch 2.180), train_loss = 1.54897524, grad/param norm = 2.2226e-01, time/batch = 0.7077s	
1451/33250 (epoch 2.182), train_loss = 1.63022925, grad/param norm = 2.6664e-01, time/batch = 0.7095s	
1452/33250 (epoch 2.183), train_loss = 1.88651456, grad/param norm = 2.5410e-01, time/batch = 0.7017s	
1453/33250 (epoch 2.185), train_loss = 1.73306599, grad/param norm = 2.7512e-01, time/batch = 0.7005s	
1454/33250 (epoch 2.186), train_loss = 1.54437123, grad/param norm = 2.3922e-01, time/batch = 0.7003s	
1455/33250 (epoch 2.188), train_loss = 1.76791254, grad/param norm = 2.4072e-01, time/batch = 0.6992s	
1456/33250 (epoch 2.189), train_loss = 1.44223536, grad/param norm = 2.3187e-01, time/batch = 0.7007s	
1457/33250 (epoch 2.191), train_loss = 1.56211830, grad/param norm = 2.2686e-01, time/batch = 0.6998s	
1458/33250 (epoch 2.192), train_loss = 1.54963306, grad/param norm = 2.4642e-01, time/batch = 0.6943s	
1459/33250 (epoch 2.194), train_loss = 1.39735663, grad/param norm = 2.5204e-01, time/batch = 0.7184s	
1460/33250 (epoch 2.195), train_loss = 1.77622506, grad/param norm = 2.5236e-01, time/batch = 0.6919s	
1461/33250 (epoch 2.197), train_loss = 1.66936520, grad/param norm = 2.6224e-01, time/batch = 0.6979s	
1462/33250 (epoch 2.198), train_loss = 1.80962942, grad/param norm = 3.0584e-01, time/batch = 0.6921s	
1463/33250 (epoch 2.200), train_loss = 1.63653926, grad/param norm = 2.5588e-01, time/batch = 0.6940s	
1464/33250 (epoch 2.202), train_loss = 1.61984109, grad/param norm = 2.5451e-01, time/batch = 0.7011s	
1465/33250 (epoch 2.203), train_loss = 1.69416306, grad/param norm = 2.4853e-01, time/batch = 0.6914s	
1466/33250 (epoch 2.205), train_loss = 1.70518097, grad/param norm = 2.5608e-01, time/batch = 0.6902s	
1467/33250 (epoch 2.206), train_loss = 1.67601918, grad/param norm = 2.7615e-01, time/batch = 0.6930s	
1468/33250 (epoch 2.208), train_loss = 1.96422909, grad/param norm = 2.6390e-01, time/batch = 0.6967s	
1469/33250 (epoch 2.209), train_loss = 1.53714641, grad/param norm = 2.6327e-01, time/batch = 0.6966s	
1470/33250 (epoch 2.211), train_loss = 1.81438587, grad/param norm = 2.3999e-01, time/batch = 0.7015s	
1471/33250 (epoch 2.212), train_loss = 1.86311519, grad/param norm = 3.0999e-01, time/batch = 0.7153s	
1472/33250 (epoch 2.214), train_loss = 1.65052901, grad/param norm = 2.7351e-01, time/batch = 0.7226s	
1473/33250 (epoch 2.215), train_loss = 2.07408014, grad/param norm = 2.6885e-01, time/batch = 0.6963s	
1474/33250 (epoch 2.217), train_loss = 1.75749738, grad/param norm = 2.3850e-01, time/batch = 0.6995s	
1475/33250 (epoch 2.218), train_loss = 1.75563035, grad/param norm = 2.5022e-01, time/batch = 0.7027s	
1476/33250 (epoch 2.220), train_loss = 1.85065180, grad/param norm = 2.5721e-01, time/batch = 0.6953s	
1477/33250 (epoch 2.221), train_loss = 1.99659060, grad/param norm = 2.4962e-01, time/batch = 0.6965s	
1478/33250 (epoch 2.223), train_loss = 1.73400883, grad/param norm = 2.7772e-01, time/batch = 0.6950s	
1479/33250 (epoch 2.224), train_loss = 1.78195293, grad/param norm = 2.6095e-01, time/batch = 0.6949s	
1480/33250 (epoch 2.226), train_loss = 1.80593006, grad/param norm = 2.3916e-01, time/batch = 0.7000s	
1481/33250 (epoch 2.227), train_loss = 1.76168332, grad/param norm = 2.4540e-01, time/batch = 0.7019s	
1482/33250 (epoch 2.229), train_loss = 1.65142339, grad/param norm = 2.3145e-01, time/batch = 0.6990s	
1483/33250 (epoch 2.230), train_loss = 1.65997924, grad/param norm = 2.5787e-01, time/batch = 0.7006s	
1484/33250 (epoch 2.232), train_loss = 1.56961502, grad/param norm = 2.3018e-01, time/batch = 0.6972s	
1485/33250 (epoch 2.233), train_loss = 1.63857498, grad/param norm = 2.1614e-01, time/batch = 0.7031s	
1486/33250 (epoch 2.235), train_loss = 1.75240499, grad/param norm = 2.6203e-01, time/batch = 0.7041s	
1487/33250 (epoch 2.236), train_loss = 1.60006619, grad/param norm = 3.0532e-01, time/batch = 0.7045s	
1488/33250 (epoch 2.238), train_loss = 1.68615057, grad/param norm = 2.5386e-01, time/batch = 0.7047s	
1489/33250 (epoch 2.239), train_loss = 1.90897643, grad/param norm = 2.8010e-01, time/batch = 0.7118s	
1490/33250 (epoch 2.241), train_loss = 1.83552828, grad/param norm = 3.1203e-01, time/batch = 0.7032s	
1491/33250 (epoch 2.242), train_loss = 1.65237216, grad/param norm = 2.5447e-01, time/batch = 0.7125s	
1492/33250 (epoch 2.244), train_loss = 1.78181035, grad/param norm = 2.4655e-01, time/batch = 0.7059s	
1493/33250 (epoch 2.245), train_loss = 1.63833507, grad/param norm = 2.4109e-01, time/batch = 0.6911s	
1494/33250 (epoch 2.247), train_loss = 1.80851163, grad/param norm = 2.2350e-01, time/batch = 0.6982s	
1495/33250 (epoch 2.248), train_loss = 1.97135852, grad/param norm = 2.2963e-01, time/batch = 0.6973s	
1496/33250 (epoch 2.250), train_loss = 1.67778484, grad/param norm = 2.2037e-01, time/batch = 0.6991s	
1497/33250 (epoch 2.251), train_loss = 1.72711236, grad/param norm = 2.6118e-01, time/batch = 0.7006s	
1498/33250 (epoch 2.253), train_loss = 1.52367883, grad/param norm = 2.4380e-01, time/batch = 0.7004s	
1499/33250 (epoch 2.254), train_loss = 1.60797958, grad/param norm = 2.6129e-01, time/batch = 0.6983s	
1500/33250 (epoch 2.256), train_loss = 1.84697496, grad/param norm = 2.8781e-01, time/batch = 0.6959s	
1501/33250 (epoch 2.257), train_loss = 1.89118284, grad/param norm = 2.7516e-01, time/batch = 0.7048s	
1502/33250 (epoch 2.259), train_loss = 1.88210159, grad/param norm = 2.3856e-01, time/batch = 0.6966s	
1503/33250 (epoch 2.260), train_loss = 1.53621304, grad/param norm = 2.1853e-01, time/batch = 0.6909s	
1504/33250 (epoch 2.262), train_loss = 1.72833643, grad/param norm = 2.0414e-01, time/batch = 0.6990s	
1505/33250 (epoch 2.263), train_loss = 1.62863508, grad/param norm = 2.1582e-01, time/batch = 0.7028s	
1506/33250 (epoch 2.265), train_loss = 1.71678456, grad/param norm = 2.2973e-01, time/batch = 0.7078s	
1507/33250 (epoch 2.266), train_loss = 1.66361899, grad/param norm = 2.5541e-01, time/batch = 0.7165s	
1508/33250 (epoch 2.268), train_loss = 1.55759717, grad/param norm = 2.2826e-01, time/batch = 0.7085s	
1509/33250 (epoch 2.269), train_loss = 1.39684326, grad/param norm = 2.2205e-01, time/batch = 0.7095s	
1510/33250 (epoch 2.271), train_loss = 1.70563284, grad/param norm = 2.2242e-01, time/batch = 0.7129s	
1511/33250 (epoch 2.272), train_loss = 1.32766642, grad/param norm = 1.8404e-01, time/batch = 0.7007s	
1512/33250 (epoch 2.274), train_loss = 1.35797972, grad/param norm = 2.0640e-01, time/batch = 0.6983s	
1513/33250 (epoch 2.275), train_loss = 1.51608219, grad/param norm = 2.1329e-01, time/batch = 0.6956s	
1514/33250 (epoch 2.277), train_loss = 1.40002336, grad/param norm = 2.2752e-01, time/batch = 0.7221s	
1515/33250 (epoch 2.278), train_loss = 1.43120883, grad/param norm = 2.0542e-01, time/batch = 0.6947s	
1516/33250 (epoch 2.280), train_loss = 1.42417790, grad/param norm = 2.3930e-01, time/batch = 0.7101s	
1517/33250 (epoch 2.281), train_loss = 1.54888851, grad/param norm = 2.4163e-01, time/batch = 0.7109s	
1518/33250 (epoch 2.283), train_loss = 1.64852078, grad/param norm = 2.4120e-01, time/batch = 0.7116s	
1519/33250 (epoch 2.284), train_loss = 1.59197975, grad/param norm = 2.1866e-01, time/batch = 0.7088s	
1520/33250 (epoch 2.286), train_loss = 1.70676436, grad/param norm = 2.4356e-01, time/batch = 0.7138s	
1521/33250 (epoch 2.287), train_loss = 1.50659291, grad/param norm = 2.3300e-01, time/batch = 0.7132s	
1522/33250 (epoch 2.289), train_loss = 1.50471404, grad/param norm = 2.5526e-01, time/batch = 0.7117s	
1523/33250 (epoch 2.290), train_loss = 1.53897900, grad/param norm = 2.0269e-01, time/batch = 0.7152s	
1524/33250 (epoch 2.292), train_loss = 1.61494644, grad/param norm = 2.3729e-01, time/batch = 0.7217s	
1525/33250 (epoch 2.293), train_loss = 1.77724230, grad/param norm = 2.6477e-01, time/batch = 0.7289s	
1526/33250 (epoch 2.295), train_loss = 1.61351284, grad/param norm = 2.2173e-01, time/batch = 0.7133s	
1527/33250 (epoch 2.296), train_loss = 1.58909595, grad/param norm = 2.1509e-01, time/batch = 0.7216s	
1528/33250 (epoch 2.298), train_loss = 1.36734545, grad/param norm = 2.0570e-01, time/batch = 0.7293s	
1529/33250 (epoch 2.299), train_loss = 1.35968709, grad/param norm = 2.2244e-01, time/batch = 0.7218s	
1530/33250 (epoch 2.301), train_loss = 1.68106401, grad/param norm = 2.1533e-01, time/batch = 0.7121s	
1531/33250 (epoch 2.302), train_loss = 1.56594065, grad/param norm = 2.5969e-01, time/batch = 0.7103s	
1532/33250 (epoch 2.304), train_loss = 1.52645552, grad/param norm = 2.2106e-01, time/batch = 0.7040s	
1533/33250 (epoch 2.305), train_loss = 1.51886331, grad/param norm = 1.9574e-01, time/batch = 0.7075s	
1534/33250 (epoch 2.307), train_loss = 1.78394375, grad/param norm = 2.2961e-01, time/batch = 0.6889s	
1535/33250 (epoch 2.308), train_loss = 1.84343330, grad/param norm = 2.5689e-01, time/batch = 0.6811s	
1536/33250 (epoch 2.310), train_loss = 1.64814993, grad/param norm = 2.5516e-01, time/batch = 0.6823s	
1537/33250 (epoch 2.311), train_loss = 1.69914124, grad/param norm = 2.3463e-01, time/batch = 0.6782s	
1538/33250 (epoch 2.313), train_loss = 1.58606255, grad/param norm = 2.7357e-01, time/batch = 0.6807s	
1539/33250 (epoch 2.314), train_loss = 1.61877388, grad/param norm = 2.3706e-01, time/batch = 0.6817s	
1540/33250 (epoch 2.316), train_loss = 1.77948150, grad/param norm = 2.1220e-01, time/batch = 0.6801s	
1541/33250 (epoch 2.317), train_loss = 1.55658017, grad/param norm = 2.4250e-01, time/batch = 0.6825s	
1542/33250 (epoch 2.319), train_loss = 1.81209582, grad/param norm = 2.6529e-01, time/batch = 0.6811s	
1543/33250 (epoch 2.320), train_loss = 1.91183758, grad/param norm = 2.8683e-01, time/batch = 0.6786s	
1544/33250 (epoch 2.322), train_loss = 1.87022781, grad/param norm = 2.7630e-01, time/batch = 0.6796s	
1545/33250 (epoch 2.323), train_loss = 1.91879584, grad/param norm = 2.6942e-01, time/batch = 0.6786s	
1546/33250 (epoch 2.325), train_loss = 1.64095375, grad/param norm = 2.3348e-01, time/batch = 0.6776s	
1547/33250 (epoch 2.326), train_loss = 1.85958850, grad/param norm = 2.6869e-01, time/batch = 0.6763s	
1548/33250 (epoch 2.328), train_loss = 1.62619412, grad/param norm = 2.4064e-01, time/batch = 0.6779s	
1549/33250 (epoch 2.329), train_loss = 1.75867865, grad/param norm = 2.3748e-01, time/batch = 0.6764s	
1550/33250 (epoch 2.331), train_loss = 1.52850776, grad/param norm = 2.1033e-01, time/batch = 0.6753s	
1551/33250 (epoch 2.332), train_loss = 1.55145070, grad/param norm = 2.2699e-01, time/batch = 0.6844s	
1552/33250 (epoch 2.334), train_loss = 1.76741194, grad/param norm = 2.5322e-01, time/batch = 0.6833s	
1553/33250 (epoch 2.335), train_loss = 1.33120002, grad/param norm = 2.1905e-01, time/batch = 0.6784s	
1554/33250 (epoch 2.337), train_loss = 1.65475704, grad/param norm = 2.2055e-01, time/batch = 0.6814s	
1555/33250 (epoch 2.338), train_loss = 1.71853578, grad/param norm = 2.3650e-01, time/batch = 0.6905s	
1556/33250 (epoch 2.340), train_loss = 1.65245069, grad/param norm = 2.5056e-01, time/batch = 0.6934s	
1557/33250 (epoch 2.341), train_loss = 1.64580268, grad/param norm = 2.5975e-01, time/batch = 0.7154s	
1558/33250 (epoch 2.343), train_loss = 1.76478248, grad/param norm = 3.0638e-01, time/batch = 0.6856s	
1559/33250 (epoch 2.344), train_loss = 1.63037258, grad/param norm = 2.4633e-01, time/batch = 0.6819s	
1560/33250 (epoch 2.346), train_loss = 1.41412344, grad/param norm = 2.1940e-01, time/batch = 0.6783s	
1561/33250 (epoch 2.347), train_loss = 1.97607902, grad/param norm = 2.5032e-01, time/batch = 0.6819s	
1562/33250 (epoch 2.349), train_loss = 1.68362061, grad/param norm = 2.7312e-01, time/batch = 0.6864s	
1563/33250 (epoch 2.350), train_loss = 1.66572636, grad/param norm = 2.6036e-01, time/batch = 0.6810s	
1564/33250 (epoch 2.352), train_loss = 1.54603181, grad/param norm = 2.5251e-01, time/batch = 0.7101s	
1565/33250 (epoch 2.353), train_loss = 1.59428635, grad/param norm = 2.1504e-01, time/batch = 0.7015s	
1566/33250 (epoch 2.355), train_loss = 1.54382846, grad/param norm = 2.2774e-01, time/batch = 0.6947s	
1567/33250 (epoch 2.356), train_loss = 1.51842360, grad/param norm = 2.3518e-01, time/batch = 0.7037s	
1568/33250 (epoch 2.358), train_loss = 1.56499701, grad/param norm = 2.4877e-01, time/batch = 0.7374s	
1569/33250 (epoch 2.359), train_loss = 1.48512360, grad/param norm = 2.3875e-01, time/batch = 0.7190s	
1570/33250 (epoch 2.361), train_loss = 1.85819060, grad/param norm = 2.3876e-01, time/batch = 0.6957s	
1571/33250 (epoch 2.362), train_loss = 1.57739734, grad/param norm = 2.1992e-01, time/batch = 0.7024s	
1572/33250 (epoch 2.364), train_loss = 1.79575212, grad/param norm = 2.1679e-01, time/batch = 0.6988s	
1573/33250 (epoch 2.365), train_loss = 1.60413234, grad/param norm = 2.4443e-01, time/batch = 0.6990s	
1574/33250 (epoch 2.367), train_loss = 1.52776958, grad/param norm = 2.1076e-01, time/batch = 0.6976s	
1575/33250 (epoch 2.368), train_loss = 1.61728732, grad/param norm = 2.1597e-01, time/batch = 0.6948s	
1576/33250 (epoch 2.370), train_loss = 1.44466879, grad/param norm = 2.3728e-01, time/batch = 0.6947s	
1577/33250 (epoch 2.371), train_loss = 1.70155220, grad/param norm = 2.3455e-01, time/batch = 0.7001s	
1578/33250 (epoch 2.373), train_loss = 1.55266025, grad/param norm = 2.2983e-01, time/batch = 0.7023s	
1579/33250 (epoch 2.374), train_loss = 1.72964130, grad/param norm = 2.7196e-01, time/batch = 0.7244s	
1580/33250 (epoch 2.376), train_loss = 1.58686872, grad/param norm = 2.4467e-01, time/batch = 0.7342s	
1581/33250 (epoch 2.377), train_loss = 1.52626668, grad/param norm = 2.7151e-01, time/batch = 0.7080s	
1582/33250 (epoch 2.379), train_loss = 1.55627817, grad/param norm = 2.4373e-01, time/batch = 0.7086s	
1583/33250 (epoch 2.380), train_loss = 1.69950394, grad/param norm = 2.4056e-01, time/batch = 0.7076s	
1584/33250 (epoch 2.382), train_loss = 1.75769966, grad/param norm = 2.6218e-01, time/batch = 0.7062s	
1585/33250 (epoch 2.383), train_loss = 1.65814554, grad/param norm = 2.3274e-01, time/batch = 0.6979s	
1586/33250 (epoch 2.385), train_loss = 1.48761998, grad/param norm = 2.4748e-01, time/batch = 0.6961s	
1587/33250 (epoch 2.386), train_loss = 1.55956653, grad/param norm = 2.4180e-01, time/batch = 0.6961s	
1588/33250 (epoch 2.388), train_loss = 1.58943760, grad/param norm = 2.3540e-01, time/batch = 0.7272s	
1589/33250 (epoch 2.389), train_loss = 1.60407453, grad/param norm = 2.5218e-01, time/batch = 0.6952s	
1590/33250 (epoch 2.391), train_loss = 1.59395335, grad/param norm = 2.4545e-01, time/batch = 0.6982s	
1591/33250 (epoch 2.392), train_loss = 1.80977946, grad/param norm = 2.3805e-01, time/batch = 0.6985s	
1592/33250 (epoch 2.394), train_loss = 1.92358862, grad/param norm = 2.8822e-01, time/batch = 0.7007s	
1593/33250 (epoch 2.395), train_loss = 1.88329983, grad/param norm = 2.5597e-01, time/batch = 0.6927s	
1594/33250 (epoch 2.397), train_loss = 1.76359614, grad/param norm = 2.5625e-01, time/batch = 0.6949s	
1595/33250 (epoch 2.398), train_loss = 1.65782936, grad/param norm = 2.5761e-01, time/batch = 0.6960s	
1596/33250 (epoch 2.400), train_loss = 1.60931064, grad/param norm = 2.2490e-01, time/batch = 0.6925s	
1597/33250 (epoch 2.402), train_loss = 1.50638414, grad/param norm = 2.4845e-01, time/batch = 0.6969s	
1598/33250 (epoch 2.403), train_loss = 1.49484616, grad/param norm = 2.3251e-01, time/batch = 0.6958s	
1599/33250 (epoch 2.405), train_loss = 1.49483751, grad/param norm = 2.5148e-01, time/batch = 0.6957s	
1600/33250 (epoch 2.406), train_loss = 1.65199836, grad/param norm = 2.3257e-01, time/batch = 0.6933s	
1601/33250 (epoch 2.408), train_loss = 1.80962731, grad/param norm = 2.4141e-01, time/batch = 0.6980s	
1602/33250 (epoch 2.409), train_loss = 1.74706584, grad/param norm = 2.9735e-01, time/batch = 0.6957s	
1603/33250 (epoch 2.411), train_loss = 1.35561025, grad/param norm = 2.8546e-01, time/batch = 0.7007s	
1604/33250 (epoch 2.412), train_loss = 1.38684790, grad/param norm = 2.0623e-01, time/batch = 0.6956s	
1605/33250 (epoch 2.414), train_loss = 1.71431439, grad/param norm = 2.3171e-01, time/batch = 0.7087s	
1606/33250 (epoch 2.415), train_loss = 1.64298675, grad/param norm = 2.3959e-01, time/batch = 0.7007s	
1607/33250 (epoch 2.417), train_loss = 1.70980334, grad/param norm = 2.4960e-01, time/batch = 0.6963s	
1608/33250 (epoch 2.418), train_loss = 1.86900522, grad/param norm = 2.8335e-01, time/batch = 0.6938s	
1609/33250 (epoch 2.420), train_loss = 1.73082479, grad/param norm = 2.4789e-01, time/batch = 0.6992s	
1610/33250 (epoch 2.421), train_loss = 1.51221806, grad/param norm = 2.9669e-01, time/batch = 0.7004s	
1611/33250 (epoch 2.423), train_loss = 1.73290667, grad/param norm = 2.3574e-01, time/batch = 0.7007s	
1612/33250 (epoch 2.424), train_loss = 1.89411711, grad/param norm = 3.0366e-01, time/batch = 0.7000s	
1613/33250 (epoch 2.426), train_loss = 1.54111934, grad/param norm = 2.0524e-01, time/batch = 0.7087s	
1614/33250 (epoch 2.427), train_loss = 1.48439295, grad/param norm = 2.4889e-01, time/batch = 0.7011s	
1615/33250 (epoch 2.429), train_loss = 1.71519173, grad/param norm = 2.7095e-01, time/batch = 0.7040s	
1616/33250 (epoch 2.430), train_loss = 1.57248503, grad/param norm = 2.5532e-01, time/batch = 0.7078s	
1617/33250 (epoch 2.432), train_loss = 1.61511700, grad/param norm = 2.1711e-01, time/batch = 0.6996s	
1618/33250 (epoch 2.433), train_loss = 1.61146841, grad/param norm = 2.3624e-01, time/batch = 0.7003s	
1619/33250 (epoch 2.435), train_loss = 1.72856425, grad/param norm = 2.7966e-01, time/batch = 0.7018s	
1620/33250 (epoch 2.436), train_loss = 1.65030482, grad/param norm = 2.3785e-01, time/batch = 0.6973s	
1621/33250 (epoch 2.438), train_loss = 1.57414326, grad/param norm = 2.7678e-01, time/batch = 0.7026s	
1622/33250 (epoch 2.439), train_loss = 1.59321370, grad/param norm = 2.2851e-01, time/batch = 0.6978s	
1623/33250 (epoch 2.441), train_loss = 1.64148135, grad/param norm = 2.3187e-01, time/batch = 0.7062s	
1624/33250 (epoch 2.442), train_loss = 1.61100213, grad/param norm = 2.3156e-01, time/batch = 0.7047s	
1625/33250 (epoch 2.444), train_loss = 1.47246233, grad/param norm = 2.6962e-01, time/batch = 0.7040s	
1626/33250 (epoch 2.445), train_loss = 1.61844952, grad/param norm = 2.0798e-01, time/batch = 0.7050s	
1627/33250 (epoch 2.447), train_loss = 1.63797815, grad/param norm = 2.3628e-01, time/batch = 0.7033s	
1628/33250 (epoch 2.448), train_loss = 1.52135468, grad/param norm = 2.3221e-01, time/batch = 0.7020s	
1629/33250 (epoch 2.450), train_loss = 1.87483110, grad/param norm = 2.5153e-01, time/batch = 0.6957s	
1630/33250 (epoch 2.451), train_loss = 1.71251621, grad/param norm = 2.4502e-01, time/batch = 0.6979s	
1631/33250 (epoch 2.453), train_loss = 1.39716362, grad/param norm = 2.1481e-01, time/batch = 0.6977s	
1632/33250 (epoch 2.454), train_loss = 1.74086546, grad/param norm = 2.3982e-01, time/batch = 0.6982s	
1633/33250 (epoch 2.456), train_loss = 1.73055267, grad/param norm = 2.8000e-01, time/batch = 0.6979s	
1634/33250 (epoch 2.457), train_loss = 1.68050041, grad/param norm = 2.4968e-01, time/batch = 0.6981s	
1635/33250 (epoch 2.459), train_loss = 1.64927744, grad/param norm = 2.3833e-01, time/batch = 0.6977s	
1636/33250 (epoch 2.460), train_loss = 1.63071254, grad/param norm = 2.6079e-01, time/batch = 0.7006s	
1637/33250 (epoch 2.462), train_loss = 1.54818811, grad/param norm = 2.3311e-01, time/batch = 0.7038s	
1638/33250 (epoch 2.463), train_loss = 1.46013742, grad/param norm = 2.1450e-01, time/batch = 0.6969s	
1639/33250 (epoch 2.465), train_loss = 1.31759061, grad/param norm = 2.2149e-01, time/batch = 0.7007s	
1640/33250 (epoch 2.466), train_loss = 1.31886214, grad/param norm = 2.0664e-01, time/batch = 0.7054s	
1641/33250 (epoch 2.468), train_loss = 1.40761461, grad/param norm = 2.0958e-01, time/batch = 0.7176s	
1642/33250 (epoch 2.469), train_loss = 1.71676916, grad/param norm = 2.5221e-01, time/batch = 0.7242s	
1643/33250 (epoch 2.471), train_loss = 1.70598750, grad/param norm = 2.4035e-01, time/batch = 0.7303s	
1644/33250 (epoch 2.472), train_loss = 1.66872291, grad/param norm = 3.0086e-01, time/batch = 0.7262s	
1645/33250 (epoch 2.474), train_loss = 1.90666607, grad/param norm = 2.7398e-01, time/batch = 0.7199s	
1646/33250 (epoch 2.475), train_loss = 1.67228900, grad/param norm = 2.6673e-01, time/batch = 0.7112s	
1647/33250 (epoch 2.477), train_loss = 1.62062798, grad/param norm = 2.3366e-01, time/batch = 0.7062s	
1648/33250 (epoch 2.478), train_loss = 1.56454939, grad/param norm = 2.2304e-01, time/batch = 0.7084s	
1649/33250 (epoch 2.480), train_loss = 1.83253447, grad/param norm = 2.4057e-01, time/batch = 0.7078s	
1650/33250 (epoch 2.481), train_loss = 1.55024641, grad/param norm = 2.4656e-01, time/batch = 0.7035s	
1651/33250 (epoch 2.483), train_loss = 1.69123398, grad/param norm = 2.5770e-01, time/batch = 0.7048s	
1652/33250 (epoch 2.484), train_loss = 1.55182792, grad/param norm = 2.3309e-01, time/batch = 0.7061s	
1653/33250 (epoch 2.486), train_loss = 1.42611604, grad/param norm = 2.1806e-01, time/batch = 0.7014s	
1654/33250 (epoch 2.487), train_loss = 1.60007537, grad/param norm = 2.5242e-01, time/batch = 0.7011s	
1655/33250 (epoch 2.489), train_loss = 1.80589165, grad/param norm = 2.6984e-01, time/batch = 0.7036s	
1656/33250 (epoch 2.490), train_loss = 1.73773097, grad/param norm = 2.5891e-01, time/batch = 0.7041s	
1657/33250 (epoch 2.492), train_loss = 1.61087872, grad/param norm = 2.1945e-01, time/batch = 0.7301s	
1658/33250 (epoch 2.493), train_loss = 1.60672307, grad/param norm = 2.2776e-01, time/batch = 0.7272s	
1659/33250 (epoch 2.495), train_loss = 1.63096826, grad/param norm = 2.3340e-01, time/batch = 0.7121s	
1660/33250 (epoch 2.496), train_loss = 1.57941466, grad/param norm = 2.3589e-01, time/batch = 0.6975s	
1661/33250 (epoch 2.498), train_loss = 1.66987859, grad/param norm = 2.4639e-01, time/batch = 0.7109s	
1662/33250 (epoch 2.499), train_loss = 1.63280548, grad/param norm = 2.3015e-01, time/batch = 0.6946s	
1663/33250 (epoch 2.501), train_loss = 1.53371298, grad/param norm = 2.2088e-01, time/batch = 0.6982s	
1664/33250 (epoch 2.502), train_loss = 1.61240668, grad/param norm = 2.4165e-01, time/batch = 0.6980s	
1665/33250 (epoch 2.504), train_loss = 1.84365940, grad/param norm = 2.3803e-01, time/batch = 0.6978s	
1666/33250 (epoch 2.505), train_loss = 1.32701893, grad/param norm = 2.0375e-01, time/batch = 0.7006s	
1667/33250 (epoch 2.507), train_loss = 1.71535523, grad/param norm = 2.2918e-01, time/batch = 0.7014s	
1668/33250 (epoch 2.508), train_loss = 1.52493082, grad/param norm = 2.4655e-01, time/batch = 0.6976s	
1669/33250 (epoch 2.510), train_loss = 1.48196017, grad/param norm = 2.4731e-01, time/batch = 0.6978s	
1670/33250 (epoch 2.511), train_loss = 1.67635584, grad/param norm = 2.2541e-01, time/batch = 0.6938s	
1671/33250 (epoch 2.513), train_loss = 1.92198267, grad/param norm = 2.4942e-01, time/batch = 0.6985s	
1672/33250 (epoch 2.514), train_loss = 1.61256138, grad/param norm = 2.2532e-01, time/batch = 0.6963s	
1673/33250 (epoch 2.516), train_loss = 1.59120663, grad/param norm = 2.2485e-01, time/batch = 0.6925s	
1674/33250 (epoch 2.517), train_loss = 1.66633100, grad/param norm = 2.4569e-01, time/batch = 0.6929s	
1675/33250 (epoch 2.519), train_loss = 1.38342906, grad/param norm = 2.3162e-01, time/batch = 0.6986s	
1676/33250 (epoch 2.520), train_loss = 1.89845960, grad/param norm = 2.3855e-01, time/batch = 0.6903s	
1677/33250 (epoch 2.522), train_loss = 1.71768702, grad/param norm = 2.3433e-01, time/batch = 0.6949s	
1678/33250 (epoch 2.523), train_loss = 1.55873206, grad/param norm = 2.3219e-01, time/batch = 0.6897s	
1679/33250 (epoch 2.525), train_loss = 1.43574617, grad/param norm = 2.2661e-01, time/batch = 0.6909s	
1680/33250 (epoch 2.526), train_loss = 1.44417389, grad/param norm = 2.6512e-01, time/batch = 0.6939s	
1681/33250 (epoch 2.528), train_loss = 1.59908393, grad/param norm = 2.3861e-01, time/batch = 0.6914s	
1682/33250 (epoch 2.529), train_loss = 1.49296242, grad/param norm = 2.2040e-01, time/batch = 0.6914s	
1683/33250 (epoch 2.531), train_loss = 1.37967190, grad/param norm = 2.4066e-01, time/batch = 0.6885s	
1684/33250 (epoch 2.532), train_loss = 1.75003506, grad/param norm = 2.1504e-01, time/batch = 0.6890s	
1685/33250 (epoch 2.534), train_loss = 1.61665881, grad/param norm = 2.2513e-01, time/batch = 0.6879s	
1686/33250 (epoch 2.535), train_loss = 1.57812482, grad/param norm = 1.9976e-01, time/batch = 0.6889s	
1687/33250 (epoch 2.537), train_loss = 1.74525395, grad/param norm = 2.2717e-01, time/batch = 0.7092s	
1688/33250 (epoch 2.538), train_loss = 1.62921939, grad/param norm = 2.4034e-01, time/batch = 0.7093s	
1689/33250 (epoch 2.540), train_loss = 1.75610516, grad/param norm = 2.3455e-01, time/batch = 0.6931s	
1690/33250 (epoch 2.541), train_loss = 1.73119405, grad/param norm = 2.5526e-01, time/batch = 0.6914s	
1691/33250 (epoch 2.543), train_loss = 1.75748201, grad/param norm = 2.4616e-01, time/batch = 0.7012s	
1692/33250 (epoch 2.544), train_loss = 1.61758068, grad/param norm = 2.4502e-01, time/batch = 0.6993s	
1693/33250 (epoch 2.546), train_loss = 1.63426082, grad/param norm = 2.3666e-01, time/batch = 0.7110s	
1694/33250 (epoch 2.547), train_loss = 1.46604051, grad/param norm = 2.2863e-01, time/batch = 0.7087s	
1695/33250 (epoch 2.549), train_loss = 1.62306539, grad/param norm = 2.2678e-01, time/batch = 0.7041s	
1696/33250 (epoch 2.550), train_loss = 1.52219021, grad/param norm = 2.2160e-01, time/batch = 0.7007s	
1697/33250 (epoch 2.552), train_loss = 1.69622700, grad/param norm = 2.4061e-01, time/batch = 0.7078s	
1698/33250 (epoch 2.553), train_loss = 1.47446016, grad/param norm = 2.2637e-01, time/batch = 0.7072s	
1699/33250 (epoch 2.555), train_loss = 1.51147026, grad/param norm = 2.1354e-01, time/batch = 0.7055s	
1700/33250 (epoch 2.556), train_loss = 1.75961204, grad/param norm = 2.4964e-01, time/batch = 0.6968s	
1701/33250 (epoch 2.558), train_loss = 1.71264110, grad/param norm = 2.3904e-01, time/batch = 0.7038s	
1702/33250 (epoch 2.559), train_loss = 1.51081825, grad/param norm = 2.4644e-01, time/batch = 0.6915s	
1703/33250 (epoch 2.561), train_loss = 1.61860417, grad/param norm = 2.4161e-01, time/batch = 0.6937s	
1704/33250 (epoch 2.562), train_loss = 1.78323561, grad/param norm = 2.5291e-01, time/batch = 0.7352s	
1705/33250 (epoch 2.564), train_loss = 1.74105039, grad/param norm = 2.2876e-01, time/batch = 0.7343s	
1706/33250 (epoch 2.565), train_loss = 1.75201193, grad/param norm = 2.4585e-01, time/batch = 0.7112s	
1707/33250 (epoch 2.567), train_loss = 1.61948452, grad/param norm = 2.1115e-01, time/batch = 0.7092s	
1708/33250 (epoch 2.568), train_loss = 1.53394745, grad/param norm = 2.2954e-01, time/batch = 0.7071s	
1709/33250 (epoch 2.570), train_loss = 1.79945469, grad/param norm = 2.6551e-01, time/batch = 0.7020s	
1710/33250 (epoch 2.571), train_loss = 1.79626431, grad/param norm = 2.3018e-01, time/batch = 0.6933s	
1711/33250 (epoch 2.573), train_loss = 1.74234174, grad/param norm = 2.0086e-01, time/batch = 0.7034s	
1712/33250 (epoch 2.574), train_loss = 1.47504123, grad/param norm = 2.0402e-01, time/batch = 0.7021s	
1713/33250 (epoch 2.576), train_loss = 1.66897206, grad/param norm = 2.3427e-01, time/batch = 0.7264s	
1714/33250 (epoch 2.577), train_loss = 1.61014638, grad/param norm = 2.1176e-01, time/batch = 0.6994s	
1715/33250 (epoch 2.579), train_loss = 1.43984699, grad/param norm = 2.1949e-01, time/batch = 0.6973s	
1716/33250 (epoch 2.580), train_loss = 1.38245108, grad/param norm = 2.0090e-01, time/batch = 0.6930s	
1717/33250 (epoch 2.582), train_loss = 1.54043987, grad/param norm = 2.0508e-01, time/batch = 0.6917s	
1718/33250 (epoch 2.583), train_loss = 1.60637574, grad/param norm = 2.0688e-01, time/batch = 0.6916s	
1719/33250 (epoch 2.585), train_loss = 1.74923840, grad/param norm = 2.7827e-01, time/batch = 0.6892s	
1720/33250 (epoch 2.586), train_loss = 1.56396974, grad/param norm = 2.6280e-01, time/batch = 0.6914s	
1721/33250 (epoch 2.588), train_loss = 1.65298049, grad/param norm = 2.4082e-01, time/batch = 0.6972s	
1722/33250 (epoch 2.589), train_loss = 1.77055267, grad/param norm = 2.5030e-01, time/batch = 0.6939s	
1723/33250 (epoch 2.591), train_loss = 1.71431724, grad/param norm = 2.2712e-01, time/batch = 0.6952s	
1724/33250 (epoch 2.592), train_loss = 1.56513705, grad/param norm = 2.0715e-01, time/batch = 0.6888s	
1725/33250 (epoch 2.594), train_loss = 1.85029101, grad/param norm = 2.6157e-01, time/batch = 0.7030s	
1726/33250 (epoch 2.595), train_loss = 1.79379313, grad/param norm = 2.2997e-01, time/batch = 0.7104s	
1727/33250 (epoch 2.597), train_loss = 1.53396568, grad/param norm = 2.2869e-01, time/batch = 0.7414s	
1728/33250 (epoch 2.598), train_loss = 1.71750905, grad/param norm = 2.2057e-01, time/batch = 0.7179s	
1729/33250 (epoch 2.600), train_loss = 1.60389951, grad/param norm = 2.2062e-01, time/batch = 0.7044s	
1730/33250 (epoch 2.602), train_loss = 1.73988292, grad/param norm = 2.8292e-01, time/batch = 0.7255s	
1731/33250 (epoch 2.603), train_loss = 1.56019087, grad/param norm = 2.1244e-01, time/batch = 0.7203s	
1732/33250 (epoch 2.605), train_loss = 1.63977252, grad/param norm = 2.4533e-01, time/batch = 0.7428s	
1733/33250 (epoch 2.606), train_loss = 1.65974323, grad/param norm = 2.3274e-01, time/batch = 0.7107s	
1734/33250 (epoch 2.608), train_loss = 1.65312085, grad/param norm = 2.2966e-01, time/batch = 0.7016s	
1735/33250 (epoch 2.609), train_loss = 1.51573717, grad/param norm = 2.4016e-01, time/batch = 0.7129s	
1736/33250 (epoch 2.611), train_loss = 1.78667177, grad/param norm = 2.3029e-01, time/batch = 0.7182s	
1737/33250 (epoch 2.612), train_loss = 1.70033947, grad/param norm = 2.4598e-01, time/batch = 0.7218s	
1738/33250 (epoch 2.614), train_loss = 1.94426318, grad/param norm = 2.6388e-01, time/batch = 0.7069s	
1739/33250 (epoch 2.615), train_loss = 1.77098550, grad/param norm = 2.5009e-01, time/batch = 0.7017s	
1740/33250 (epoch 2.617), train_loss = 2.05559898, grad/param norm = 2.2759e-01, time/batch = 0.6958s	
1741/33250 (epoch 2.618), train_loss = 1.95083269, grad/param norm = 2.8421e-01, time/batch = 0.7014s	
1742/33250 (epoch 2.620), train_loss = 1.80461946, grad/param norm = 2.4726e-01, time/batch = 0.7025s	
1743/33250 (epoch 2.621), train_loss = 1.55464840, grad/param norm = 2.1247e-01, time/batch = 0.7094s	
1744/33250 (epoch 2.623), train_loss = 1.57195732, grad/param norm = 2.6703e-01, time/batch = 0.7052s	
1745/33250 (epoch 2.624), train_loss = 1.66143320, grad/param norm = 2.7167e-01, time/batch = 0.6999s	
1746/33250 (epoch 2.626), train_loss = 1.68568545, grad/param norm = 2.3988e-01, time/batch = 0.6980s	
1747/33250 (epoch 2.627), train_loss = 1.69659259, grad/param norm = 2.4011e-01, time/batch = 0.6837s	
1748/33250 (epoch 2.629), train_loss = 1.60342832, grad/param norm = 2.6265e-01, time/batch = 0.6873s	
1749/33250 (epoch 2.630), train_loss = 1.65201870, grad/param norm = 2.5923e-01, time/batch = 0.6866s	
1750/33250 (epoch 2.632), train_loss = 1.38301353, grad/param norm = 2.0115e-01, time/batch = 0.6895s	
1751/33250 (epoch 2.633), train_loss = 1.75319920, grad/param norm = 2.7416e-01, time/batch = 0.7066s	
1752/33250 (epoch 2.635), train_loss = 1.46378229, grad/param norm = 2.1351e-01, time/batch = 0.7003s	
1753/33250 (epoch 2.636), train_loss = 1.55572746, grad/param norm = 2.2792e-01, time/batch = 0.6961s	
1754/33250 (epoch 2.638), train_loss = 1.58415016, grad/param norm = 2.2226e-01, time/batch = 0.7233s	
1755/33250 (epoch 2.639), train_loss = 1.62217625, grad/param norm = 2.6161e-01, time/batch = 0.7204s	
1756/33250 (epoch 2.641), train_loss = 1.52020787, grad/param norm = 2.2032e-01, time/batch = 0.7424s	
1757/33250 (epoch 2.642), train_loss = 1.53777934, grad/param norm = 2.4311e-01, time/batch = 0.7385s	
1758/33250 (epoch 2.644), train_loss = 1.41026309, grad/param norm = 2.3117e-01, time/batch = 0.7327s	
1759/33250 (epoch 2.645), train_loss = 1.75373025, grad/param norm = 2.5959e-01, time/batch = 0.7317s	
1760/33250 (epoch 2.647), train_loss = 1.51439493, grad/param norm = 2.2462e-01, time/batch = 0.7407s	
1761/33250 (epoch 2.648), train_loss = 1.58765256, grad/param norm = 2.5519e-01, time/batch = 0.7533s	
1762/33250 (epoch 2.650), train_loss = 1.75377696, grad/param norm = 2.7047e-01, time/batch = 0.7287s	
1763/33250 (epoch 2.651), train_loss = 1.64380524, grad/param norm = 2.6004e-01, time/batch = 0.7211s	
1764/33250 (epoch 2.653), train_loss = 1.42315460, grad/param norm = 2.0062e-01, time/batch = 0.7233s	
1765/33250 (epoch 2.654), train_loss = 1.43585580, grad/param norm = 1.9156e-01, time/batch = 0.7278s	
1766/33250 (epoch 2.656), train_loss = 1.66358835, grad/param norm = 2.3285e-01, time/batch = 0.7142s	
1767/33250 (epoch 2.657), train_loss = 1.47379992, grad/param norm = 2.4029e-01, time/batch = 0.7080s	
1768/33250 (epoch 2.659), train_loss = 1.43862378, grad/param norm = 2.0187e-01, time/batch = 0.7219s	
1769/33250 (epoch 2.660), train_loss = 1.51781982, grad/param norm = 2.4770e-01, time/batch = 0.7193s	
1770/33250 (epoch 2.662), train_loss = 1.63496974, grad/param norm = 2.6099e-01, time/batch = 0.7154s	
1771/33250 (epoch 2.663), train_loss = 1.49843906, grad/param norm = 2.3792e-01, time/batch = 0.7215s	
1772/33250 (epoch 2.665), train_loss = 1.76979797, grad/param norm = 2.6560e-01, time/batch = 0.7209s	
1773/33250 (epoch 2.666), train_loss = 1.57087502, grad/param norm = 2.5125e-01, time/batch = 0.7032s	
1774/33250 (epoch 2.668), train_loss = 1.70684387, grad/param norm = 2.1629e-01, time/batch = 0.7044s	
1775/33250 (epoch 2.669), train_loss = 1.72115040, grad/param norm = 2.2432e-01, time/batch = 0.6976s	
1776/33250 (epoch 2.671), train_loss = 1.62517503, grad/param norm = 2.2700e-01, time/batch = 0.6908s	
1777/33250 (epoch 2.672), train_loss = 1.75728926, grad/param norm = 2.3576e-01, time/batch = 0.6886s	
1778/33250 (epoch 2.674), train_loss = 1.54395183, grad/param norm = 2.0879e-01, time/batch = 0.7016s	
1779/33250 (epoch 2.675), train_loss = 1.69560033, grad/param norm = 2.4434e-01, time/batch = 0.6995s	
1780/33250 (epoch 2.677), train_loss = 1.60978391, grad/param norm = 2.4915e-01, time/batch = 0.7145s	
1781/33250 (epoch 2.678), train_loss = 1.66620666, grad/param norm = 2.3087e-01, time/batch = 0.7092s	
1782/33250 (epoch 2.680), train_loss = 1.67319177, grad/param norm = 2.2183e-01, time/batch = 0.7030s	
1783/33250 (epoch 2.681), train_loss = 1.42128147, grad/param norm = 2.1797e-01, time/batch = 0.7012s	
1784/33250 (epoch 2.683), train_loss = 1.48662900, grad/param norm = 2.2869e-01, time/batch = 0.7015s	
1785/33250 (epoch 2.684), train_loss = 1.60891571, grad/param norm = 2.5495e-01, time/batch = 0.6949s	
1786/33250 (epoch 2.686), train_loss = 1.46393577, grad/param norm = 1.9858e-01, time/batch = 0.7003s	
1787/33250 (epoch 2.687), train_loss = 1.51590806, grad/param norm = 2.3324e-01, time/batch = 0.7030s	
1788/33250 (epoch 2.689), train_loss = 1.47717345, grad/param norm = 2.0627e-01, time/batch = 0.7056s	
1789/33250 (epoch 2.690), train_loss = 1.70927187, grad/param norm = 2.4566e-01, time/batch = 0.7004s	
1790/33250 (epoch 2.692), train_loss = 1.73716835, grad/param norm = 2.5485e-01, time/batch = 0.7042s	
1791/33250 (epoch 2.693), train_loss = 1.55881581, grad/param norm = 1.9790e-01, time/batch = 0.7046s	
1792/33250 (epoch 2.695), train_loss = 1.70278671, grad/param norm = 2.3547e-01, time/batch = 0.7018s	
1793/33250 (epoch 2.696), train_loss = 1.61406583, grad/param norm = 2.0461e-01, time/batch = 0.7025s	
1794/33250 (epoch 2.698), train_loss = 1.46388945, grad/param norm = 2.2698e-01, time/batch = 0.6994s	
1795/33250 (epoch 2.699), train_loss = 1.77521428, grad/param norm = 2.2194e-01, time/batch = 0.6966s	
1796/33250 (epoch 2.701), train_loss = 1.51072638, grad/param norm = 2.0655e-01, time/batch = 0.7038s	
1797/33250 (epoch 2.702), train_loss = 1.71554466, grad/param norm = 2.5170e-01, time/batch = 0.7017s	
1798/33250 (epoch 2.704), train_loss = 1.78211019, grad/param norm = 2.4697e-01, time/batch = 0.6994s	
1799/33250 (epoch 2.705), train_loss = 1.51541877, grad/param norm = 2.1452e-01, time/batch = 0.7145s	
1800/33250 (epoch 2.707), train_loss = 1.49088880, grad/param norm = 2.5330e-01, time/batch = 0.6966s	
1801/33250 (epoch 2.708), train_loss = 1.64099261, grad/param norm = 2.2786e-01, time/batch = 0.7031s	
1802/33250 (epoch 2.710), train_loss = 1.75362027, grad/param norm = 2.3440e-01, time/batch = 0.6961s	
1803/33250 (epoch 2.711), train_loss = 1.73110603, grad/param norm = 2.5093e-01, time/batch = 0.6923s	
1804/33250 (epoch 2.713), train_loss = 1.70357241, grad/param norm = 2.4921e-01, time/batch = 0.6942s	
1805/33250 (epoch 2.714), train_loss = 1.71354574, grad/param norm = 2.2196e-01, time/batch = 0.6981s	
1806/33250 (epoch 2.716), train_loss = 1.75872997, grad/param norm = 2.4868e-01, time/batch = 0.6807s	
1807/33250 (epoch 2.717), train_loss = 1.52594516, grad/param norm = 2.1385e-01, time/batch = 0.6811s	
1808/33250 (epoch 2.719), train_loss = 1.67792620, grad/param norm = 2.3199e-01, time/batch = 0.6800s	
1809/33250 (epoch 2.720), train_loss = 1.80449103, grad/param norm = 2.1607e-01, time/batch = 0.6871s	
1810/33250 (epoch 2.722), train_loss = 1.49532996, grad/param norm = 1.8813e-01, time/batch = 0.7006s	
1811/33250 (epoch 2.723), train_loss = 1.40591991, grad/param norm = 1.9881e-01, time/batch = 0.7122s	
1812/33250 (epoch 2.725), train_loss = 1.29842011, grad/param norm = 1.8701e-01, time/batch = 0.7072s	
1813/33250 (epoch 2.726), train_loss = 1.50745696, grad/param norm = 2.1422e-01, time/batch = 0.6866s	
1814/33250 (epoch 2.728), train_loss = 1.64643314, grad/param norm = 2.3338e-01, time/batch = 0.6879s	
1815/33250 (epoch 2.729), train_loss = 1.70234472, grad/param norm = 2.2656e-01, time/batch = 0.6859s	
1816/33250 (epoch 2.731), train_loss = 1.51819632, grad/param norm = 2.1980e-01, time/batch = 0.6835s	
1817/33250 (epoch 2.732), train_loss = 1.51135275, grad/param norm = 2.2349e-01, time/batch = 0.7071s	
1818/33250 (epoch 2.734), train_loss = 1.63699460, grad/param norm = 2.4185e-01, time/batch = 0.7054s	
1819/33250 (epoch 2.735), train_loss = 1.62459464, grad/param norm = 2.3480e-01, time/batch = 0.6796s	
1820/33250 (epoch 2.737), train_loss = 1.70908423, grad/param norm = 2.0779e-01, time/batch = 0.6766s	
1821/33250 (epoch 2.738), train_loss = 1.64538953, grad/param norm = 2.1165e-01, time/batch = 0.6821s	
1822/33250 (epoch 2.740), train_loss = 1.83791672, grad/param norm = 2.2886e-01, time/batch = 0.6874s	
1823/33250 (epoch 2.741), train_loss = 1.60395235, grad/param norm = 2.4183e-01, time/batch = 0.6881s	
1824/33250 (epoch 2.743), train_loss = 1.60169598, grad/param norm = 2.2660e-01, time/batch = 0.7016s	
1825/33250 (epoch 2.744), train_loss = 1.62400731, grad/param norm = 2.2526e-01, time/batch = 0.7075s	
1826/33250 (epoch 2.746), train_loss = 1.63240241, grad/param norm = 2.2235e-01, time/batch = 0.7121s	
1827/33250 (epoch 2.747), train_loss = 1.56752631, grad/param norm = 2.2494e-01, time/batch = 0.7195s	
1828/33250 (epoch 2.749), train_loss = 1.75863887, grad/param norm = 2.2909e-01, time/batch = 0.7417s	
1829/33250 (epoch 2.750), train_loss = 1.62519575, grad/param norm = 2.4784e-01, time/batch = 0.7090s	
1830/33250 (epoch 2.752), train_loss = 1.48475862, grad/param norm = 2.0748e-01, time/batch = 0.7073s	
1831/33250 (epoch 2.753), train_loss = 1.57311965, grad/param norm = 2.1001e-01, time/batch = 0.7294s	
1832/33250 (epoch 2.755), train_loss = 1.45871383, grad/param norm = 2.2312e-01, time/batch = 0.7291s	
1833/33250 (epoch 2.756), train_loss = 1.70125258, grad/param norm = 2.1776e-01, time/batch = 0.7168s	
1834/33250 (epoch 2.758), train_loss = 1.64853487, grad/param norm = 2.1695e-01, time/batch = 0.6982s	
1835/33250 (epoch 2.759), train_loss = 1.43251770, grad/param norm = 1.9763e-01, time/batch = 0.7240s	
1836/33250 (epoch 2.761), train_loss = 1.58463299, grad/param norm = 2.5335e-01, time/batch = 0.7246s	
1837/33250 (epoch 2.762), train_loss = 1.64060107, grad/param norm = 2.6502e-01, time/batch = 0.7068s	
1838/33250 (epoch 2.764), train_loss = 1.52188050, grad/param norm = 2.7669e-01, time/batch = 0.7033s	
1839/33250 (epoch 2.765), train_loss = 1.60646227, grad/param norm = 2.4659e-01, time/batch = 0.7057s	
1840/33250 (epoch 2.767), train_loss = 1.42824652, grad/param norm = 2.8392e-01, time/batch = 0.7186s	
1841/33250 (epoch 2.768), train_loss = 1.51261937, grad/param norm = 2.3626e-01, time/batch = 0.7257s	
1842/33250 (epoch 2.770), train_loss = 1.56996231, grad/param norm = 2.2951e-01, time/batch = 0.7299s	
1843/33250 (epoch 2.771), train_loss = 1.67857126, grad/param norm = 2.3284e-01, time/batch = 0.7116s	
1844/33250 (epoch 2.773), train_loss = 1.57462502, grad/param norm = 2.2998e-01, time/batch = 0.7420s	
1845/33250 (epoch 2.774), train_loss = 1.41145642, grad/param norm = 2.3394e-01, time/batch = 0.7392s	
1846/33250 (epoch 2.776), train_loss = 1.58158512, grad/param norm = 2.4836e-01, time/batch = 0.7293s	
1847/33250 (epoch 2.777), train_loss = 1.75131324, grad/param norm = 2.6812e-01, time/batch = 0.7122s	
1848/33250 (epoch 2.779), train_loss = 1.44224249, grad/param norm = 2.3509e-01, time/batch = 0.7093s	
1849/33250 (epoch 2.780), train_loss = 1.78678626, grad/param norm = 2.4317e-01, time/batch = 0.7088s	
1850/33250 (epoch 2.782), train_loss = 1.66093537, grad/param norm = 2.4901e-01, time/batch = 0.7067s	
1851/33250 (epoch 2.783), train_loss = 1.42472049, grad/param norm = 2.2138e-01, time/batch = 0.7160s	
1852/33250 (epoch 2.785), train_loss = 1.50113236, grad/param norm = 2.3471e-01, time/batch = 0.7134s	
1853/33250 (epoch 2.786), train_loss = 1.71845977, grad/param norm = 2.4989e-01, time/batch = 0.7209s	
1854/33250 (epoch 2.788), train_loss = 1.51591655, grad/param norm = 2.1285e-01, time/batch = 0.7110s	
1855/33250 (epoch 2.789), train_loss = 1.65327315, grad/param norm = 2.3636e-01, time/batch = 0.7087s	
1856/33250 (epoch 2.791), train_loss = 1.69930171, grad/param norm = 2.3371e-01, time/batch = 0.7119s	
1857/33250 (epoch 2.792), train_loss = 1.78262905, grad/param norm = 2.1496e-01, time/batch = 0.7134s	
1858/33250 (epoch 2.794), train_loss = 1.45726871, grad/param norm = 2.1702e-01, time/batch = 0.7060s	
1859/33250 (epoch 2.795), train_loss = 1.65016909, grad/param norm = 2.3279e-01, time/batch = 0.6975s	
1860/33250 (epoch 2.797), train_loss = 1.74773286, grad/param norm = 2.4238e-01, time/batch = 0.7034s	
1861/33250 (epoch 2.798), train_loss = 1.76370974, grad/param norm = 3.1232e-01, time/batch = 0.7055s	
1862/33250 (epoch 2.800), train_loss = 1.73870007, grad/param norm = 2.5953e-01, time/batch = 0.6980s	
1863/33250 (epoch 2.802), train_loss = 1.53674344, grad/param norm = 2.2744e-01, time/batch = 0.6992s	
1864/33250 (epoch 2.803), train_loss = 1.53447970, grad/param norm = 2.1218e-01, time/batch = 0.6984s	
1865/33250 (epoch 2.805), train_loss = 1.61352299, grad/param norm = 2.3746e-01, time/batch = 0.6973s	
1866/33250 (epoch 2.806), train_loss = 1.69707436, grad/param norm = 2.3034e-01, time/batch = 0.6993s	
1867/33250 (epoch 2.808), train_loss = 1.65368534, grad/param norm = 2.1629e-01, time/batch = 0.7003s	
1868/33250 (epoch 2.809), train_loss = 1.41208258, grad/param norm = 2.0752e-01, time/batch = 0.6984s	
1869/33250 (epoch 2.811), train_loss = 1.55597936, grad/param norm = 2.5455e-01, time/batch = 0.6978s	
1870/33250 (epoch 2.812), train_loss = 1.55664192, grad/param norm = 2.3715e-01, time/batch = 0.7082s	
1871/33250 (epoch 2.814), train_loss = 1.53979588, grad/param norm = 2.2844e-01, time/batch = 0.7007s	
1872/33250 (epoch 2.815), train_loss = 1.64442519, grad/param norm = 2.5690e-01, time/batch = 0.6992s	
1873/33250 (epoch 2.817), train_loss = 1.57235188, grad/param norm = 2.3311e-01, time/batch = 0.7003s	
1874/33250 (epoch 2.818), train_loss = 1.45636913, grad/param norm = 2.0632e-01, time/batch = 0.6946s	
1875/33250 (epoch 2.820), train_loss = 1.63851004, grad/param norm = 2.5430e-01, time/batch = 0.7040s	
1876/33250 (epoch 2.821), train_loss = 1.43272752, grad/param norm = 2.1524e-01, time/batch = 0.7014s	
1877/33250 (epoch 2.823), train_loss = 1.82030396, grad/param norm = 2.3475e-01, time/batch = 0.6980s	
1878/33250 (epoch 2.824), train_loss = 1.60962094, grad/param norm = 2.2818e-01, time/batch = 0.6972s	
1879/33250 (epoch 2.826), train_loss = 1.55704715, grad/param norm = 2.4903e-01, time/batch = 0.6945s	
1880/33250 (epoch 2.827), train_loss = 1.40016738, grad/param norm = 2.2828e-01, time/batch = 0.6991s	
1881/33250 (epoch 2.829), train_loss = 1.58659973, grad/param norm = 2.1465e-01, time/batch = 0.6998s	
1882/33250 (epoch 2.830), train_loss = 1.87755433, grad/param norm = 2.7952e-01, time/batch = 0.6949s	
1883/33250 (epoch 2.832), train_loss = 1.51860700, grad/param norm = 2.2555e-01, time/batch = 0.6973s	
1884/33250 (epoch 2.833), train_loss = 1.64486638, grad/param norm = 2.3587e-01, time/batch = 0.6977s	
1885/33250 (epoch 2.835), train_loss = 1.62578293, grad/param norm = 2.3773e-01, time/batch = 0.6970s	
1886/33250 (epoch 2.836), train_loss = 1.61850743, grad/param norm = 2.2247e-01, time/batch = 0.7029s	
1887/33250 (epoch 2.838), train_loss = 1.48280512, grad/param norm = 1.9772e-01, time/batch = 0.6970s	
1888/33250 (epoch 2.839), train_loss = 1.52929496, grad/param norm = 2.1781e-01, time/batch = 0.6962s	
1889/33250 (epoch 2.841), train_loss = 1.35453408, grad/param norm = 1.9890e-01, time/batch = 0.6940s	
1890/33250 (epoch 2.842), train_loss = 1.66040619, grad/param norm = 2.1586e-01, time/batch = 0.6989s	
1891/33250 (epoch 2.844), train_loss = 1.76926465, grad/param norm = 2.4086e-01, time/batch = 0.7017s	
1892/33250 (epoch 2.845), train_loss = 1.84090412, grad/param norm = 2.6590e-01, time/batch = 0.6994s	
1893/33250 (epoch 2.847), train_loss = 1.74026172, grad/param norm = 2.2208e-01, time/batch = 0.6919s	
1894/33250 (epoch 2.848), train_loss = 1.84381557, grad/param norm = 2.5838e-01, time/batch = 0.7017s	
1895/33250 (epoch 2.850), train_loss = 1.62315685, grad/param norm = 2.2867e-01, time/batch = 0.7157s	
1896/33250 (epoch 2.851), train_loss = 1.49908026, grad/param norm = 2.2701e-01, time/batch = 0.7300s	
1897/33250 (epoch 2.853), train_loss = 1.65238781, grad/param norm = 2.4457e-01, time/batch = 0.7468s	
1898/33250 (epoch 2.854), train_loss = 1.43642596, grad/param norm = 2.0628e-01, time/batch = 0.7258s	
1899/33250 (epoch 2.856), train_loss = 1.47890892, grad/param norm = 2.2835e-01, time/batch = 0.7239s	
1900/33250 (epoch 2.857), train_loss = 1.34637761, grad/param norm = 2.0193e-01, time/batch = 0.7062s	
1901/33250 (epoch 2.859), train_loss = 1.36892540, grad/param norm = 2.2874e-01, time/batch = 0.6961s	
1902/33250 (epoch 2.860), train_loss = 1.47164549, grad/param norm = 1.8494e-01, time/batch = 0.6832s	
1903/33250 (epoch 2.862), train_loss = 1.44760033, grad/param norm = 1.9772e-01, time/batch = 0.6855s	
1904/33250 (epoch 2.863), train_loss = 1.46019464, grad/param norm = 2.1249e-01, time/batch = 0.6865s	
1905/33250 (epoch 2.865), train_loss = 1.57817569, grad/param norm = 2.2381e-01, time/batch = 0.6879s	
1906/33250 (epoch 2.866), train_loss = 1.51286154, grad/param norm = 2.3311e-01, time/batch = 0.6918s	
1907/33250 (epoch 2.868), train_loss = 1.92373407, grad/param norm = 2.8262e-01, time/batch = 0.6897s	
1908/33250 (epoch 2.869), train_loss = 1.61376928, grad/param norm = 2.3080e-01, time/batch = 0.6872s	
1909/33250 (epoch 2.871), train_loss = 1.31481573, grad/param norm = 2.0968e-01, time/batch = 0.6898s	
1910/33250 (epoch 2.872), train_loss = 1.69262906, grad/param norm = 2.3017e-01, time/batch = 0.6917s	
1911/33250 (epoch 2.874), train_loss = 1.48633087, grad/param norm = 2.1136e-01, time/batch = 0.6892s	
1912/33250 (epoch 2.875), train_loss = 1.53327671, grad/param norm = 2.6003e-01, time/batch = 0.7065s	
1913/33250 (epoch 2.877), train_loss = 1.60142752, grad/param norm = 2.5528e-01, time/batch = 0.6955s	
1914/33250 (epoch 2.878), train_loss = 1.53899827, grad/param norm = 2.0603e-01, time/batch = 0.7005s	
1915/33250 (epoch 2.880), train_loss = 1.64454436, grad/param norm = 2.5520e-01, time/batch = 0.6858s	
1916/33250 (epoch 2.881), train_loss = 1.75739009, grad/param norm = 2.2158e-01, time/batch = 0.6815s	
1917/33250 (epoch 2.883), train_loss = 1.67374428, grad/param norm = 2.5843e-01, time/batch = 0.6825s	
1918/33250 (epoch 2.884), train_loss = 1.53515065, grad/param norm = 2.3698e-01, time/batch = 0.6820s	
1919/33250 (epoch 2.886), train_loss = 1.42028635, grad/param norm = 2.1281e-01, time/batch = 0.6857s	
1920/33250 (epoch 2.887), train_loss = 1.50380223, grad/param norm = 2.0582e-01, time/batch = 0.6875s	
1921/33250 (epoch 2.889), train_loss = 1.43196775, grad/param norm = 1.7733e-01, time/batch = 0.6845s	
1922/33250 (epoch 2.890), train_loss = 1.35025878, grad/param norm = 2.2235e-01, time/batch = 0.6856s	
1923/33250 (epoch 2.892), train_loss = 1.62985574, grad/param norm = 2.1904e-01, time/batch = 0.6882s	
1924/33250 (epoch 2.893), train_loss = 1.63819603, grad/param norm = 2.1385e-01, time/batch = 0.6807s	
1925/33250 (epoch 2.895), train_loss = 1.51052800, grad/param norm = 2.1742e-01, time/batch = 0.6818s	
1926/33250 (epoch 2.896), train_loss = 1.66569768, grad/param norm = 2.2408e-01, time/batch = 0.6827s	
1927/33250 (epoch 2.898), train_loss = 1.48155512, grad/param norm = 2.1591e-01, time/batch = 0.6779s	
1928/33250 (epoch 2.899), train_loss = 1.53095150, grad/param norm = 2.3813e-01, time/batch = 0.6813s	
1929/33250 (epoch 2.901), train_loss = 1.39290984, grad/param norm = 2.0395e-01, time/batch = 0.6845s	
1930/33250 (epoch 2.902), train_loss = 1.45656982, grad/param norm = 2.1042e-01, time/batch = 0.6900s	
1931/33250 (epoch 2.904), train_loss = 1.42832149, grad/param norm = 2.1544e-01, time/batch = 0.6908s	
1932/33250 (epoch 2.905), train_loss = 1.49168993, grad/param norm = 2.2504e-01, time/batch = 0.6876s	
1933/33250 (epoch 2.907), train_loss = 1.51855367, grad/param norm = 2.3473e-01, time/batch = 0.6832s	
1934/33250 (epoch 2.908), train_loss = 1.54916262, grad/param norm = 1.9575e-01, time/batch = 0.6876s	
1935/33250 (epoch 2.910), train_loss = 1.68427061, grad/param norm = 2.5199e-01, time/batch = 0.6905s	
1936/33250 (epoch 2.911), train_loss = 1.35274958, grad/param norm = 2.1608e-01, time/batch = 0.6831s	
1937/33250 (epoch 2.913), train_loss = 1.47371198, grad/param norm = 2.1253e-01, time/batch = 0.6866s	
1938/33250 (epoch 2.914), train_loss = 1.35428247, grad/param norm = 2.1590e-01, time/batch = 0.6871s	
1939/33250 (epoch 2.916), train_loss = 1.42058204, grad/param norm = 2.0621e-01, time/batch = 0.6906s	
1940/33250 (epoch 2.917), train_loss = 1.50355480, grad/param norm = 2.2144e-01, time/batch = 0.6939s	
1941/33250 (epoch 2.919), train_loss = 1.56494136, grad/param norm = 2.3302e-01, time/batch = 0.6873s	
1942/33250 (epoch 2.920), train_loss = 1.56847693, grad/param norm = 2.2500e-01, time/batch = 0.6828s	
1943/33250 (epoch 2.922), train_loss = 1.59918136, grad/param norm = 2.2457e-01, time/batch = 0.6822s	
1944/33250 (epoch 2.923), train_loss = 1.53469549, grad/param norm = 2.3688e-01, time/batch = 0.6888s	
1945/33250 (epoch 2.925), train_loss = 1.52269813, grad/param norm = 2.2335e-01, time/batch = 0.6905s	
1946/33250 (epoch 2.926), train_loss = 1.53411107, grad/param norm = 2.5616e-01, time/batch = 0.6802s	
1947/33250 (epoch 2.928), train_loss = 1.57405850, grad/param norm = 2.3068e-01, time/batch = 0.6971s	
1948/33250 (epoch 2.929), train_loss = 1.21933480, grad/param norm = 1.9605e-01, time/batch = 0.6984s	
1949/33250 (epoch 2.931), train_loss = 1.57970753, grad/param norm = 2.2967e-01, time/batch = 0.6943s	
1950/33250 (epoch 2.932), train_loss = 1.67145083, grad/param norm = 2.4177e-01, time/batch = 0.6867s	
1951/33250 (epoch 2.934), train_loss = 1.49595972, grad/param norm = 2.3506e-01, time/batch = 0.6842s	
1952/33250 (epoch 2.935), train_loss = 1.57750508, grad/param norm = 2.4244e-01, time/batch = 0.6867s	
1953/33250 (epoch 2.937), train_loss = 1.55051660, grad/param norm = 2.1734e-01, time/batch = 0.6891s	
1954/33250 (epoch 2.938), train_loss = 1.68818188, grad/param norm = 2.2595e-01, time/batch = 0.6837s	
1955/33250 (epoch 2.940), train_loss = 1.52664585, grad/param norm = 2.3188e-01, time/batch = 0.6833s	
1956/33250 (epoch 2.941), train_loss = 1.59792743, grad/param norm = 2.5348e-01, time/batch = 0.6934s	
1957/33250 (epoch 2.943), train_loss = 1.75373290, grad/param norm = 2.3076e-01, time/batch = 0.6808s	
1958/33250 (epoch 2.944), train_loss = 1.40442658, grad/param norm = 2.1825e-01, time/batch = 0.6800s	
1959/33250 (epoch 2.946), train_loss = 1.81789805, grad/param norm = 2.3547e-01, time/batch = 0.6877s	
1960/33250 (epoch 2.947), train_loss = 1.51361246, grad/param norm = 2.2280e-01, time/batch = 0.6807s	
1961/33250 (epoch 2.949), train_loss = 1.68297325, grad/param norm = 2.4132e-01, time/batch = 0.6890s	
1962/33250 (epoch 2.950), train_loss = 1.55574924, grad/param norm = 2.2405e-01, time/batch = 0.6868s	
1963/33250 (epoch 2.952), train_loss = 1.60534831, grad/param norm = 2.3381e-01, time/batch = 0.6876s	
1964/33250 (epoch 2.953), train_loss = 1.64746791, grad/param norm = 2.2876e-01, time/batch = 0.6851s	
1965/33250 (epoch 2.955), train_loss = 1.64809007, grad/param norm = 2.4964e-01, time/batch = 0.6805s	
1966/33250 (epoch 2.956), train_loss = 1.75265237, grad/param norm = 2.3876e-01, time/batch = 0.6879s	
1967/33250 (epoch 2.958), train_loss = 1.46428929, grad/param norm = 2.0976e-01, time/batch = 0.6952s	
1968/33250 (epoch 2.959), train_loss = 1.41499559, grad/param norm = 2.0745e-01, time/batch = 0.7137s	
1969/33250 (epoch 2.961), train_loss = 1.66520430, grad/param norm = 2.3940e-01, time/batch = 0.7132s	
1970/33250 (epoch 2.962), train_loss = 1.61056790, grad/param norm = 2.4527e-01, time/batch = 0.7244s	
1971/33250 (epoch 2.964), train_loss = 1.65358095, grad/param norm = 2.3013e-01, time/batch = 0.7185s	
1972/33250 (epoch 2.965), train_loss = 1.63161856, grad/param norm = 2.3593e-01, time/batch = 0.7138s	
1973/33250 (epoch 2.967), train_loss = 1.71035476, grad/param norm = 2.1537e-01, time/batch = 0.7033s	
1974/33250 (epoch 2.968), train_loss = 1.72841190, grad/param norm = 2.2449e-01, time/batch = 0.6951s	
1975/33250 (epoch 2.970), train_loss = 1.87676405, grad/param norm = 2.5712e-01, time/batch = 0.6759s	
1976/33250 (epoch 2.971), train_loss = 1.74702280, grad/param norm = 2.3550e-01, time/batch = 0.6782s	
1977/33250 (epoch 2.973), train_loss = 1.53080884, grad/param norm = 2.0451e-01, time/batch = 0.6784s	
1978/33250 (epoch 2.974), train_loss = 1.58919384, grad/param norm = 2.3282e-01, time/batch = 0.6819s	
1979/33250 (epoch 2.976), train_loss = 1.47453156, grad/param norm = 2.2211e-01, time/batch = 0.6864s	
1980/33250 (epoch 2.977), train_loss = 1.44553183, grad/param norm = 2.2105e-01, time/batch = 0.6950s	
1981/33250 (epoch 2.979), train_loss = 1.56853984, grad/param norm = 2.4017e-01, time/batch = 0.7096s	
1982/33250 (epoch 2.980), train_loss = 1.49338768, grad/param norm = 1.9460e-01, time/batch = 0.7173s	
1983/33250 (epoch 2.982), train_loss = 1.37142790, grad/param norm = 1.9848e-01, time/batch = 0.7038s	
1984/33250 (epoch 2.983), train_loss = 1.64737511, grad/param norm = 2.4504e-01, time/batch = 0.6856s	
1985/33250 (epoch 2.985), train_loss = 1.43939187, grad/param norm = 2.3402e-01, time/batch = 0.6855s	
1986/33250 (epoch 2.986), train_loss = 1.72814705, grad/param norm = 2.5686e-01, time/batch = 0.7032s	
1987/33250 (epoch 2.988), train_loss = 1.56284464, grad/param norm = 2.5814e-01, time/batch = 0.7305s	
1988/33250 (epoch 2.989), train_loss = 1.70206862, grad/param norm = 2.3137e-01, time/batch = 0.6908s	
1989/33250 (epoch 2.991), train_loss = 1.56515086, grad/param norm = 2.4170e-01, time/batch = 0.6899s	
1990/33250 (epoch 2.992), train_loss = 1.50071649, grad/param norm = 2.1818e-01, time/batch = 0.6791s	
1991/33250 (epoch 2.994), train_loss = 1.40255435, grad/param norm = 1.9605e-01, time/batch = 0.6819s	
1992/33250 (epoch 2.995), train_loss = 1.62056786, grad/param norm = 2.4991e-01, time/batch = 0.6837s	
1993/33250 (epoch 2.997), train_loss = 1.22839402, grad/param norm = 1.9614e-01, time/batch = 0.6782s	
1994/33250 (epoch 2.998), train_loss = 1.55608176, grad/param norm = 2.1860e-01, time/batch = 0.6813s	
1995/33250 (epoch 3.000), train_loss = 1.54230380, grad/param norm = 2.2259e-01, time/batch = 0.6866s	
1996/33250 (epoch 3.002), train_loss = 1.71432283, grad/param norm = 2.1926e-01, time/batch = 0.6807s	
1997/33250 (epoch 3.003), train_loss = 1.59520863, grad/param norm = 2.3105e-01, time/batch = 0.6826s	
1998/33250 (epoch 3.005), train_loss = 1.38968876, grad/param norm = 2.2029e-01, time/batch = 0.6880s	
1999/33250 (epoch 3.006), train_loss = 1.32134798, grad/param norm = 2.0192e-01, time/batch = 0.6846s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch3.01_1.6259.t7	
2000/33250 (epoch 3.008), train_loss = 1.62077662, grad/param norm = 2.4072e-01, time/batch = 0.6845s	
2001/33250 (epoch 3.009), train_loss = 1.73555300, grad/param norm = 2.4252e-01, time/batch = 0.6881s	
2002/33250 (epoch 3.011), train_loss = 1.50301920, grad/param norm = 2.3440e-01, time/batch = 0.6847s	
2003/33250 (epoch 3.012), train_loss = 1.69983573, grad/param norm = 2.6268e-01, time/batch = 0.6828s	
2004/33250 (epoch 3.014), train_loss = 1.62152411, grad/param norm = 2.0820e-01, time/batch = 0.6794s	
2005/33250 (epoch 3.015), train_loss = 1.54411376, grad/param norm = 2.2570e-01, time/batch = 0.6937s	
2006/33250 (epoch 3.017), train_loss = 1.59999163, grad/param norm = 2.3621e-01, time/batch = 0.6910s	
2007/33250 (epoch 3.018), train_loss = 1.40761493, grad/param norm = 2.2202e-01, time/batch = 0.6992s	
2008/33250 (epoch 3.020), train_loss = 1.48224714, grad/param norm = 2.0088e-01, time/batch = 0.6897s	
2009/33250 (epoch 3.021), train_loss = 1.52126625, grad/param norm = 2.1451e-01, time/batch = 0.6973s	
2010/33250 (epoch 3.023), train_loss = 1.38348786, grad/param norm = 2.2669e-01, time/batch = 0.6901s	
2011/33250 (epoch 3.024), train_loss = 1.66307162, grad/param norm = 2.3308e-01, time/batch = 0.6834s	
2012/33250 (epoch 3.026), train_loss = 1.48445737, grad/param norm = 1.9635e-01, time/batch = 0.6767s	
2013/33250 (epoch 3.027), train_loss = 1.44630899, grad/param norm = 2.2514e-01, time/batch = 0.6783s	
2014/33250 (epoch 3.029), train_loss = 1.51932234, grad/param norm = 2.0744e-01, time/batch = 0.6797s	
2015/33250 (epoch 3.030), train_loss = 1.55646922, grad/param norm = 2.4841e-01, time/batch = 0.6847s	
2016/33250 (epoch 3.032), train_loss = 1.81461412, grad/param norm = 2.6121e-01, time/batch = 0.7242s	
2017/33250 (epoch 3.033), train_loss = 1.44159997, grad/param norm = 2.4935e-01, time/batch = 0.7097s	
2018/33250 (epoch 3.035), train_loss = 1.45864887, grad/param norm = 2.1088e-01, time/batch = 0.6863s	
2019/33250 (epoch 3.036), train_loss = 1.56696595, grad/param norm = 2.4149e-01, time/batch = 0.6972s	
2020/33250 (epoch 3.038), train_loss = 1.39772402, grad/param norm = 2.0711e-01, time/batch = 0.6984s	
2021/33250 (epoch 3.039), train_loss = 1.38657751, grad/param norm = 2.1665e-01, time/batch = 0.7050s	
2022/33250 (epoch 3.041), train_loss = 1.66155890, grad/param norm = 2.2900e-01, time/batch = 0.6884s	
2023/33250 (epoch 3.042), train_loss = 1.32004402, grad/param norm = 1.9723e-01, time/batch = 0.6879s	
2024/33250 (epoch 3.044), train_loss = 1.73724604, grad/param norm = 2.0145e-01, time/batch = 0.6904s	
2025/33250 (epoch 3.045), train_loss = 1.58296478, grad/param norm = 2.0204e-01, time/batch = 0.6886s	
2026/33250 (epoch 3.047), train_loss = 1.67974468, grad/param norm = 2.3051e-01, time/batch = 0.6879s	
2027/33250 (epoch 3.048), train_loss = 1.76670836, grad/param norm = 2.4194e-01, time/batch = 0.6864s	
2028/33250 (epoch 3.050), train_loss = 1.51215294, grad/param norm = 2.1903e-01, time/batch = 0.6843s	
2029/33250 (epoch 3.051), train_loss = 1.53515804, grad/param norm = 2.0716e-01, time/batch = 0.6814s	
2030/33250 (epoch 3.053), train_loss = 1.62818556, grad/param norm = 2.3069e-01, time/batch = 0.6819s	
2031/33250 (epoch 3.054), train_loss = 1.34337865, grad/param norm = 2.0183e-01, time/batch = 0.6889s	
2032/33250 (epoch 3.056), train_loss = 1.41031774, grad/param norm = 2.2379e-01, time/batch = 0.6810s	
2033/33250 (epoch 3.057), train_loss = 1.47514494, grad/param norm = 2.2379e-01, time/batch = 0.6919s	
2034/33250 (epoch 3.059), train_loss = 1.45733591, grad/param norm = 2.1912e-01, time/batch = 0.6893s	
2035/33250 (epoch 3.060), train_loss = 1.62156843, grad/param norm = 2.3535e-01, time/batch = 0.6889s	
2036/33250 (epoch 3.062), train_loss = 1.68630861, grad/param norm = 2.2429e-01, time/batch = 0.6893s	
2037/33250 (epoch 3.063), train_loss = 1.64467922, grad/param norm = 2.0833e-01, time/batch = 0.6894s	
2038/33250 (epoch 3.065), train_loss = 1.58278482, grad/param norm = 2.1332e-01, time/batch = 0.6799s	
2039/33250 (epoch 3.066), train_loss = 1.64928436, grad/param norm = 2.1679e-01, time/batch = 0.6861s	
2040/33250 (epoch 3.068), train_loss = 1.55683114, grad/param norm = 2.5604e-01, time/batch = 0.6850s	
2041/33250 (epoch 3.069), train_loss = 1.57990674, grad/param norm = 1.9941e-01, time/batch = 0.6918s	
2042/33250 (epoch 3.071), train_loss = 1.37631192, grad/param norm = 2.0104e-01, time/batch = 0.6891s	
2043/33250 (epoch 3.072), train_loss = 1.46257217, grad/param norm = 2.1374e-01, time/batch = 0.6862s	
2044/33250 (epoch 3.074), train_loss = 1.56614280, grad/param norm = 2.1211e-01, time/batch = 0.6846s	
2045/33250 (epoch 3.075), train_loss = 1.41695702, grad/param norm = 2.0509e-01, time/batch = 0.6852s	
2046/33250 (epoch 3.077), train_loss = 1.57244236, grad/param norm = 2.0311e-01, time/batch = 0.6855s	
2047/33250 (epoch 3.078), train_loss = 1.40991418, grad/param norm = 2.0108e-01, time/batch = 0.6864s	
2048/33250 (epoch 3.080), train_loss = 1.60357952, grad/param norm = 2.6801e-01, time/batch = 0.6852s	
2049/33250 (epoch 3.081), train_loss = 1.60505769, grad/param norm = 2.4960e-01, time/batch = 0.6850s	
2050/33250 (epoch 3.083), train_loss = 1.62106817, grad/param norm = 2.3612e-01, time/batch = 0.6827s	
2051/33250 (epoch 3.084), train_loss = 1.47969008, grad/param norm = 2.0408e-01, time/batch = 0.6853s	
2052/33250 (epoch 3.086), train_loss = 1.50620890, grad/param norm = 2.0898e-01, time/batch = 0.6865s	
2053/33250 (epoch 3.087), train_loss = 1.36315580, grad/param norm = 1.9801e-01, time/batch = 0.6841s	
2054/33250 (epoch 3.089), train_loss = 1.58916115, grad/param norm = 2.3063e-01, time/batch = 0.6823s	
2055/33250 (epoch 3.090), train_loss = 1.45113913, grad/param norm = 2.3595e-01, time/batch = 0.6850s	
2056/33250 (epoch 3.092), train_loss = 1.37609548, grad/param norm = 2.0601e-01, time/batch = 0.6826s	
2057/33250 (epoch 3.093), train_loss = 1.47268953, grad/param norm = 2.1181e-01, time/batch = 0.6844s	
2058/33250 (epoch 3.095), train_loss = 1.46704966, grad/param norm = 2.2278e-01, time/batch = 0.6986s	
2059/33250 (epoch 3.096), train_loss = 1.35269714, grad/param norm = 2.0117e-01, time/batch = 0.7112s	
2060/33250 (epoch 3.098), train_loss = 1.39809320, grad/param norm = 2.2176e-01, time/batch = 0.7135s	
2061/33250 (epoch 3.099), train_loss = 1.26267760, grad/param norm = 2.1696e-01, time/batch = 0.7138s	
2062/33250 (epoch 3.101), train_loss = 1.48405800, grad/param norm = 2.3196e-01, time/batch = 0.7100s	
2063/33250 (epoch 3.102), train_loss = 1.35288516, grad/param norm = 1.8866e-01, time/batch = 0.7209s	
2064/33250 (epoch 3.104), train_loss = 1.29869350, grad/param norm = 1.9249e-01, time/batch = 0.7046s	
2065/33250 (epoch 3.105), train_loss = 1.44547708, grad/param norm = 2.1147e-01, time/batch = 0.7210s	
2066/33250 (epoch 3.107), train_loss = 1.20531878, grad/param norm = 1.8610e-01, time/batch = 0.7158s	
2067/33250 (epoch 3.108), train_loss = 1.48370703, grad/param norm = 2.0539e-01, time/batch = 0.7148s	
2068/33250 (epoch 3.110), train_loss = 1.30637355, grad/param norm = 1.9923e-01, time/batch = 0.6965s	
2069/33250 (epoch 3.111), train_loss = 1.47078750, grad/param norm = 2.1347e-01, time/batch = 0.6897s	
2070/33250 (epoch 3.113), train_loss = 1.45182330, grad/param norm = 2.1760e-01, time/batch = 0.6924s	
2071/33250 (epoch 3.114), train_loss = 1.43471030, grad/param norm = 2.3563e-01, time/batch = 0.6901s	
2072/33250 (epoch 3.116), train_loss = 1.55296694, grad/param norm = 2.3476e-01, time/batch = 0.6879s	
2073/33250 (epoch 3.117), train_loss = 1.47063868, grad/param norm = 2.0716e-01, time/batch = 0.7001s	
2074/33250 (epoch 3.119), train_loss = 1.42797512, grad/param norm = 1.9833e-01, time/batch = 0.6892s	
2075/33250 (epoch 3.120), train_loss = 1.18817734, grad/param norm = 1.8925e-01, time/batch = 0.6875s	
2076/33250 (epoch 3.122), train_loss = 1.58925955, grad/param norm = 2.0580e-01, time/batch = 0.6852s	
2077/33250 (epoch 3.123), train_loss = 1.58805030, grad/param norm = 2.1593e-01, time/batch = 0.6866s	
2078/33250 (epoch 3.125), train_loss = 1.29933471, grad/param norm = 1.9840e-01, time/batch = 0.6833s	
2079/33250 (epoch 3.126), train_loss = 1.53962641, grad/param norm = 2.4469e-01, time/batch = 0.6820s	
2080/33250 (epoch 3.128), train_loss = 1.38335266, grad/param norm = 2.0454e-01, time/batch = 0.6846s	
2081/33250 (epoch 3.129), train_loss = 1.43377717, grad/param norm = 2.1636e-01, time/batch = 0.6919s	
2082/33250 (epoch 3.131), train_loss = 1.53058080, grad/param norm = 2.2047e-01, time/batch = 0.6860s	
2083/33250 (epoch 3.132), train_loss = 1.47039978, grad/param norm = 2.0249e-01, time/batch = 0.6925s	
2084/33250 (epoch 3.134), train_loss = 1.53477632, grad/param norm = 2.1867e-01, time/batch = 0.6895s	
2085/33250 (epoch 3.135), train_loss = 1.55853497, grad/param norm = 2.0365e-01, time/batch = 0.7047s	
2086/33250 (epoch 3.137), train_loss = 1.33106168, grad/param norm = 1.9588e-01, time/batch = 0.7009s	
2087/33250 (epoch 3.138), train_loss = 1.40887752, grad/param norm = 2.0566e-01, time/batch = 0.7018s	
2088/33250 (epoch 3.140), train_loss = 1.35501085, grad/param norm = 2.1892e-01, time/batch = 0.7027s	
2089/33250 (epoch 3.141), train_loss = 1.86304999, grad/param norm = 2.3088e-01, time/batch = 0.6878s	
2090/33250 (epoch 3.143), train_loss = 1.25194307, grad/param norm = 2.0877e-01, time/batch = 0.6883s	
2091/33250 (epoch 3.144), train_loss = 1.37597967, grad/param norm = 2.0136e-01, time/batch = 0.6906s	
2092/33250 (epoch 3.146), train_loss = 1.34985289, grad/param norm = 1.9291e-01, time/batch = 0.6919s	
2093/33250 (epoch 3.147), train_loss = 1.39325197, grad/param norm = 2.2390e-01, time/batch = 0.6910s	
2094/33250 (epoch 3.149), train_loss = 1.51643613, grad/param norm = 2.1495e-01, time/batch = 0.6843s	
2095/33250 (epoch 3.150), train_loss = 1.31243553, grad/param norm = 2.1625e-01, time/batch = 0.6909s	
2096/33250 (epoch 3.152), train_loss = 1.33244172, grad/param norm = 2.0802e-01, time/batch = 0.6861s	
2097/33250 (epoch 3.153), train_loss = 1.60554525, grad/param norm = 2.4505e-01, time/batch = 0.6838s	
2098/33250 (epoch 3.155), train_loss = 1.55210649, grad/param norm = 2.4116e-01, time/batch = 0.6871s	
2099/33250 (epoch 3.156), train_loss = 1.54915989, grad/param norm = 2.2587e-01, time/batch = 0.6873s	
2100/33250 (epoch 3.158), train_loss = 1.85679874, grad/param norm = 2.4813e-01, time/batch = 0.6850s	
2101/33250 (epoch 3.159), train_loss = 1.52695766, grad/param norm = 2.3036e-01, time/batch = 0.6884s	
2102/33250 (epoch 3.161), train_loss = 1.57556617, grad/param norm = 2.3692e-01, time/batch = 0.6945s	
2103/33250 (epoch 3.162), train_loss = 1.45372147, grad/param norm = 2.2800e-01, time/batch = 0.6859s	
2104/33250 (epoch 3.164), train_loss = 1.59039783, grad/param norm = 2.2096e-01, time/batch = 0.6815s	
2105/33250 (epoch 3.165), train_loss = 1.54348111, grad/param norm = 2.0570e-01, time/batch = 0.6965s	
2106/33250 (epoch 3.167), train_loss = 1.54134140, grad/param norm = 2.0543e-01, time/batch = 0.7015s	
2107/33250 (epoch 3.168), train_loss = 1.31533306, grad/param norm = 1.8862e-01, time/batch = 0.6985s	
2108/33250 (epoch 3.170), train_loss = 1.43124030, grad/param norm = 2.0161e-01, time/batch = 0.7025s	
2109/33250 (epoch 3.171), train_loss = 1.45208486, grad/param norm = 1.9482e-01, time/batch = 0.6973s	
2110/33250 (epoch 3.173), train_loss = 1.37661800, grad/param norm = 2.1076e-01, time/batch = 0.6971s	
2111/33250 (epoch 3.174), train_loss = 1.47539706, grad/param norm = 2.3188e-01, time/batch = 0.7103s	
2112/33250 (epoch 3.176), train_loss = 1.57131623, grad/param norm = 2.2808e-01, time/batch = 0.7017s	
2113/33250 (epoch 3.177), train_loss = 1.24921149, grad/param norm = 1.7467e-01, time/batch = 0.6875s	
2114/33250 (epoch 3.179), train_loss = 1.44944810, grad/param norm = 2.1565e-01, time/batch = 0.6846s	
2115/33250 (epoch 3.180), train_loss = 1.35138684, grad/param norm = 1.9686e-01, time/batch = 0.6829s	
2116/33250 (epoch 3.182), train_loss = 1.45852274, grad/param norm = 2.3649e-01, time/batch = 0.6832s	
2117/33250 (epoch 3.183), train_loss = 1.71904989, grad/param norm = 2.2094e-01, time/batch = 0.6888s	
2118/33250 (epoch 3.185), train_loss = 1.58921258, grad/param norm = 2.3978e-01, time/batch = 0.6857s	
2119/33250 (epoch 3.186), train_loss = 1.40145363, grad/param norm = 1.9103e-01, time/batch = 0.6961s	
2120/33250 (epoch 3.188), train_loss = 1.56650121, grad/param norm = 2.0587e-01, time/batch = 0.6853s	
2121/33250 (epoch 3.189), train_loss = 1.28343158, grad/param norm = 1.9703e-01, time/batch = 0.6927s	
2122/33250 (epoch 3.191), train_loss = 1.38670800, grad/param norm = 1.9800e-01, time/batch = 0.6932s	
2123/33250 (epoch 3.192), train_loss = 1.37321866, grad/param norm = 1.9749e-01, time/batch = 0.6929s	
2124/33250 (epoch 3.194), train_loss = 1.26732690, grad/param norm = 2.1280e-01, time/batch = 0.6921s	
2125/33250 (epoch 3.195), train_loss = 1.60786919, grad/param norm = 2.0316e-01, time/batch = 0.6855s	
2126/33250 (epoch 3.197), train_loss = 1.49411610, grad/param norm = 2.3377e-01, time/batch = 0.6855s	
2127/33250 (epoch 3.198), train_loss = 1.61352297, grad/param norm = 2.5114e-01, time/batch = 0.6837s	
2128/33250 (epoch 3.200), train_loss = 1.47277066, grad/param norm = 2.1775e-01, time/batch = 0.6818s	
2129/33250 (epoch 3.202), train_loss = 1.44096844, grad/param norm = 2.0861e-01, time/batch = 0.6834s	
2130/33250 (epoch 3.203), train_loss = 1.50992947, grad/param norm = 2.1320e-01, time/batch = 0.6803s	
2131/33250 (epoch 3.205), train_loss = 1.54744130, grad/param norm = 2.4049e-01, time/batch = 0.6878s	
2132/33250 (epoch 3.206), train_loss = 1.50367112, grad/param norm = 2.2060e-01, time/batch = 0.6878s	
2133/33250 (epoch 3.208), train_loss = 1.77029752, grad/param norm = 2.5858e-01, time/batch = 0.6858s	
2134/33250 (epoch 3.209), train_loss = 1.37509177, grad/param norm = 2.2701e-01, time/batch = 0.6851s	
2135/33250 (epoch 3.211), train_loss = 1.64485075, grad/param norm = 2.0716e-01, time/batch = 0.6867s	
2136/33250 (epoch 3.212), train_loss = 1.72584865, grad/param norm = 2.6437e-01, time/batch = 0.6812s	
2137/33250 (epoch 3.214), train_loss = 1.49345259, grad/param norm = 2.1616e-01, time/batch = 0.6824s	
2138/33250 (epoch 3.215), train_loss = 1.90754357, grad/param norm = 2.4701e-01, time/batch = 0.6789s	
2139/33250 (epoch 3.217), train_loss = 1.64153859, grad/param norm = 2.1939e-01, time/batch = 0.6771s	
2140/33250 (epoch 3.218), train_loss = 1.57730535, grad/param norm = 2.2762e-01, time/batch = 0.6754s	
2141/33250 (epoch 3.220), train_loss = 1.69827028, grad/param norm = 2.2669e-01, time/batch = 0.6850s	
2142/33250 (epoch 3.221), train_loss = 1.81088566, grad/param norm = 2.3303e-01, time/batch = 0.6842s	
2143/33250 (epoch 3.223), train_loss = 1.50211815, grad/param norm = 2.2943e-01, time/batch = 0.6893s	
2144/33250 (epoch 3.224), train_loss = 1.63699951, grad/param norm = 2.4916e-01, time/batch = 0.6991s	
2145/33250 (epoch 3.226), train_loss = 1.64547666, grad/param norm = 2.1741e-01, time/batch = 0.7153s	
2146/33250 (epoch 3.227), train_loss = 1.55317756, grad/param norm = 2.0033e-01, time/batch = 0.7253s	
2147/33250 (epoch 3.229), train_loss = 1.49715708, grad/param norm = 1.9501e-01, time/batch = 0.7027s	
2148/33250 (epoch 3.230), train_loss = 1.45509999, grad/param norm = 2.2670e-01, time/batch = 0.7032s	
2149/33250 (epoch 3.232), train_loss = 1.40390137, grad/param norm = 1.8702e-01, time/batch = 0.7190s	
2150/33250 (epoch 3.233), train_loss = 1.44699395, grad/param norm = 1.9914e-01, time/batch = 0.7138s	
2151/33250 (epoch 3.235), train_loss = 1.60135144, grad/param norm = 2.1878e-01, time/batch = 0.7057s	
2152/33250 (epoch 3.236), train_loss = 1.41758970, grad/param norm = 2.5630e-01, time/batch = 0.7013s	
2153/33250 (epoch 3.238), train_loss = 1.56200515, grad/param norm = 2.1791e-01, time/batch = 0.7129s	
2154/33250 (epoch 3.239), train_loss = 1.74580272, grad/param norm = 2.4329e-01, time/batch = 0.7177s	
2155/33250 (epoch 3.241), train_loss = 1.65424877, grad/param norm = 2.4484e-01, time/batch = 0.6962s	
2156/33250 (epoch 3.242), train_loss = 1.54537170, grad/param norm = 2.0998e-01, time/batch = 0.6971s	
2157/33250 (epoch 3.244), train_loss = 1.63421117, grad/param norm = 2.3443e-01, time/batch = 0.7045s	
2158/33250 (epoch 3.245), train_loss = 1.47546110, grad/param norm = 2.2049e-01, time/batch = 0.7088s	
2159/33250 (epoch 3.247), train_loss = 1.58465813, grad/param norm = 2.0840e-01, time/batch = 0.7064s	
2160/33250 (epoch 3.248), train_loss = 1.80596500, grad/param norm = 2.3310e-01, time/batch = 0.7029s	
2161/33250 (epoch 3.250), train_loss = 1.52566601, grad/param norm = 1.9654e-01, time/batch = 0.7082s	
2162/33250 (epoch 3.251), train_loss = 1.53858594, grad/param norm = 2.3405e-01, time/batch = 0.7012s	
2163/33250 (epoch 3.253), train_loss = 1.34293807, grad/param norm = 2.0916e-01, time/batch = 0.7104s	
2164/33250 (epoch 3.254), train_loss = 1.45183047, grad/param norm = 2.1564e-01, time/batch = 0.7109s	
2165/33250 (epoch 3.256), train_loss = 1.63772941, grad/param norm = 2.2530e-01, time/batch = 0.7059s	
2166/33250 (epoch 3.257), train_loss = 1.70819373, grad/param norm = 2.2418e-01, time/batch = 0.7027s	
2167/33250 (epoch 3.259), train_loss = 1.70863524, grad/param norm = 2.0765e-01, time/batch = 0.7034s	
2168/33250 (epoch 3.260), train_loss = 1.37503886, grad/param norm = 1.9055e-01, time/batch = 0.6953s	
2169/33250 (epoch 3.262), train_loss = 1.56950991, grad/param norm = 1.9715e-01, time/batch = 0.6946s	
2170/33250 (epoch 3.263), train_loss = 1.47509051, grad/param norm = 2.1835e-01, time/batch = 0.6919s	
2171/33250 (epoch 3.265), train_loss = 1.58728219, grad/param norm = 2.0106e-01, time/batch = 0.6953s	
2172/33250 (epoch 3.266), train_loss = 1.50465083, grad/param norm = 2.2352e-01, time/batch = 0.6939s	
2173/33250 (epoch 3.268), train_loss = 1.39711717, grad/param norm = 1.8950e-01, time/batch = 0.6983s	
2174/33250 (epoch 3.269), train_loss = 1.23740599, grad/param norm = 1.9567e-01, time/batch = 0.6891s	
2175/33250 (epoch 3.271), train_loss = 1.53277848, grad/param norm = 1.9606e-01, time/batch = 0.7200s	
2176/33250 (epoch 3.272), train_loss = 1.19999749, grad/param norm = 1.6752e-01, time/batch = 0.6964s	
2177/33250 (epoch 3.274), train_loss = 1.18815683, grad/param norm = 1.9135e-01, time/batch = 0.6958s	
2178/33250 (epoch 3.275), train_loss = 1.34688220, grad/param norm = 1.8249e-01, time/batch = 0.6931s	
2179/33250 (epoch 3.277), train_loss = 1.21390360, grad/param norm = 1.9148e-01, time/batch = 0.7011s	
2180/33250 (epoch 3.278), train_loss = 1.27908777, grad/param norm = 1.8148e-01, time/batch = 0.7222s	
2181/33250 (epoch 3.280), train_loss = 1.26489853, grad/param norm = 1.9439e-01, time/batch = 0.7300s	
2182/33250 (epoch 3.281), train_loss = 1.42780893, grad/param norm = 2.1839e-01, time/batch = 0.7023s	
2183/33250 (epoch 3.283), train_loss = 1.53109697, grad/param norm = 2.1732e-01, time/batch = 0.7034s	
2184/33250 (epoch 3.284), train_loss = 1.41832562, grad/param norm = 2.0086e-01, time/batch = 0.7014s	
2185/33250 (epoch 3.286), train_loss = 1.55754825, grad/param norm = 2.2086e-01, time/batch = 0.7003s	
2186/33250 (epoch 3.287), train_loss = 1.32376824, grad/param norm = 1.9736e-01, time/batch = 0.7086s	
2187/33250 (epoch 3.289), train_loss = 1.34135421, grad/param norm = 2.1317e-01, time/batch = 0.7092s	
2188/33250 (epoch 3.290), train_loss = 1.41084089, grad/param norm = 1.7012e-01, time/batch = 0.7021s	
2189/33250 (epoch 3.292), train_loss = 1.45929378, grad/param norm = 2.1864e-01, time/batch = 0.6994s	
2190/33250 (epoch 3.293), train_loss = 1.63679646, grad/param norm = 2.5883e-01, time/batch = 0.6986s	
2191/33250 (epoch 3.295), train_loss = 1.48514967, grad/param norm = 1.9714e-01, time/batch = 0.7094s	
2192/33250 (epoch 3.296), train_loss = 1.45648308, grad/param norm = 1.9315e-01, time/batch = 0.6913s	
2193/33250 (epoch 3.298), train_loss = 1.22252689, grad/param norm = 1.7092e-01, time/batch = 0.6926s	
2194/33250 (epoch 3.299), train_loss = 1.19845560, grad/param norm = 1.7830e-01, time/batch = 0.7025s	
2195/33250 (epoch 3.301), train_loss = 1.55320424, grad/param norm = 2.0266e-01, time/batch = 0.6951s	
2196/33250 (epoch 3.302), train_loss = 1.40281353, grad/param norm = 2.0815e-01, time/batch = 0.6941s	
2197/33250 (epoch 3.304), train_loss = 1.38326708, grad/param norm = 1.8520e-01, time/batch = 0.6934s	
2198/33250 (epoch 3.305), train_loss = 1.39305303, grad/param norm = 1.8027e-01, time/batch = 0.6918s	
2199/33250 (epoch 3.307), train_loss = 1.62769116, grad/param norm = 2.0427e-01, time/batch = 0.6873s	
2200/33250 (epoch 3.308), train_loss = 1.73348963, grad/param norm = 2.3156e-01, time/batch = 0.6955s	
2201/33250 (epoch 3.310), train_loss = 1.49974488, grad/param norm = 2.2153e-01, time/batch = 0.7010s	
2202/33250 (epoch 3.311), train_loss = 1.56462996, grad/param norm = 2.0697e-01, time/batch = 0.6912s	
2203/33250 (epoch 3.313), train_loss = 1.37234169, grad/param norm = 2.2216e-01, time/batch = 0.6987s	
2204/33250 (epoch 3.314), train_loss = 1.45074380, grad/param norm = 2.0046e-01, time/batch = 0.6889s	
2205/33250 (epoch 3.316), train_loss = 1.64453848, grad/param norm = 2.1909e-01, time/batch = 0.6944s	
2206/33250 (epoch 3.317), train_loss = 1.41601131, grad/param norm = 2.2685e-01, time/batch = 0.6902s	
2207/33250 (epoch 3.319), train_loss = 1.66118958, grad/param norm = 2.2996e-01, time/batch = 0.6904s	
2208/33250 (epoch 3.320), train_loss = 1.77674077, grad/param norm = 2.6514e-01, time/batch = 0.6886s	
2209/33250 (epoch 3.322), train_loss = 1.72711105, grad/param norm = 2.4309e-01, time/batch = 0.6976s	
2210/33250 (epoch 3.323), train_loss = 1.81701849, grad/param norm = 2.3664e-01, time/batch = 0.6970s	
2211/33250 (epoch 3.325), train_loss = 1.48151420, grad/param norm = 2.0938e-01, time/batch = 0.6956s	
2212/33250 (epoch 3.326), train_loss = 1.75130114, grad/param norm = 2.3695e-01, time/batch = 0.6911s	
2213/33250 (epoch 3.328), train_loss = 1.43617343, grad/param norm = 2.0661e-01, time/batch = 0.6939s	
2214/33250 (epoch 3.329), train_loss = 1.57928582, grad/param norm = 2.1379e-01, time/batch = 0.6933s	
2215/33250 (epoch 3.331), train_loss = 1.40373995, grad/param norm = 1.9730e-01, time/batch = 0.6929s	
2216/33250 (epoch 3.332), train_loss = 1.40638465, grad/param norm = 2.1069e-01, time/batch = 0.6943s	
2217/33250 (epoch 3.334), train_loss = 1.61604362, grad/param norm = 2.1038e-01, time/batch = 0.6925s	
2218/33250 (epoch 3.335), train_loss = 1.16374245, grad/param norm = 1.8777e-01, time/batch = 0.6950s	
2219/33250 (epoch 3.337), train_loss = 1.49654020, grad/param norm = 1.9801e-01, time/batch = 0.6942s	
2220/33250 (epoch 3.338), train_loss = 1.59061742, grad/param norm = 2.0793e-01, time/batch = 0.6947s	
2221/33250 (epoch 3.340), train_loss = 1.46271911, grad/param norm = 2.1462e-01, time/batch = 0.6956s	
2222/33250 (epoch 3.341), train_loss = 1.45972067, grad/param norm = 2.1147e-01, time/batch = 0.6927s	
2223/33250 (epoch 3.343), train_loss = 1.55951396, grad/param norm = 2.2664e-01, time/batch = 0.6962s	
2224/33250 (epoch 3.344), train_loss = 1.46279981, grad/param norm = 2.2029e-01, time/batch = 0.6915s	
2225/33250 (epoch 3.346), train_loss = 1.28448258, grad/param norm = 1.8764e-01, time/batch = 0.6944s	
2226/33250 (epoch 3.347), train_loss = 1.84001469, grad/param norm = 2.2830e-01, time/batch = 0.6938s	
2227/33250 (epoch 3.349), train_loss = 1.50854995, grad/param norm = 2.3617e-01, time/batch = 0.6886s	
2228/33250 (epoch 3.350), train_loss = 1.52980901, grad/param norm = 2.2788e-01, time/batch = 0.6954s	
2229/33250 (epoch 3.352), train_loss = 1.40112146, grad/param norm = 2.1354e-01, time/batch = 0.7084s	
2230/33250 (epoch 3.353), train_loss = 1.44524553, grad/param norm = 1.9402e-01, time/batch = 0.7173s	
2231/33250 (epoch 3.355), train_loss = 1.43677999, grad/param norm = 2.1409e-01, time/batch = 0.7203s	
2232/33250 (epoch 3.356), train_loss = 1.36980373, grad/param norm = 1.9748e-01, time/batch = 0.7012s	
2233/33250 (epoch 3.358), train_loss = 1.41693463, grad/param norm = 1.9939e-01, time/batch = 0.6974s	
2234/33250 (epoch 3.359), train_loss = 1.34420677, grad/param norm = 1.8565e-01, time/batch = 0.6898s	
2235/33250 (epoch 3.361), train_loss = 1.69116857, grad/param norm = 2.1572e-01, time/batch = 0.6945s	
2236/33250 (epoch 3.362), train_loss = 1.44364275, grad/param norm = 2.1667e-01, time/batch = 0.7269s	
2237/33250 (epoch 3.364), train_loss = 1.63896837, grad/param norm = 2.1037e-01, time/batch = 0.7298s	
2238/33250 (epoch 3.365), train_loss = 1.43469685, grad/param norm = 2.0434e-01, time/batch = 0.7123s	
2239/33250 (epoch 3.367), train_loss = 1.41323998, grad/param norm = 1.9048e-01, time/batch = 0.7211s	
2240/33250 (epoch 3.368), train_loss = 1.46030913, grad/param norm = 1.8592e-01, time/batch = 0.7357s	
2241/33250 (epoch 3.370), train_loss = 1.27869919, grad/param norm = 1.9793e-01, time/batch = 0.7430s	
2242/33250 (epoch 3.371), train_loss = 1.56881682, grad/param norm = 2.0592e-01, time/batch = 0.7381s	
2243/33250 (epoch 3.373), train_loss = 1.42682637, grad/param norm = 2.0901e-01, time/batch = 0.7434s	
2244/33250 (epoch 3.374), train_loss = 1.55641683, grad/param norm = 2.3161e-01, time/batch = 0.7434s	
2245/33250 (epoch 3.376), train_loss = 1.43913613, grad/param norm = 2.1584e-01, time/batch = 0.7458s	
2246/33250 (epoch 3.377), train_loss = 1.38800107, grad/param norm = 2.5078e-01, time/batch = 0.7266s	
2247/33250 (epoch 3.379), train_loss = 1.38205452, grad/param norm = 1.9015e-01, time/batch = 0.7092s	
2248/33250 (epoch 3.380), train_loss = 1.55060684, grad/param norm = 2.2447e-01, time/batch = 0.7409s	
2249/33250 (epoch 3.382), train_loss = 1.60598979, grad/param norm = 2.3890e-01, time/batch = 0.7431s	
2250/33250 (epoch 3.383), train_loss = 1.45341858, grad/param norm = 2.0781e-01, time/batch = 0.7308s	
2251/33250 (epoch 3.385), train_loss = 1.34691292, grad/param norm = 2.0751e-01, time/batch = 0.7248s	
2252/33250 (epoch 3.386), train_loss = 1.37738569, grad/param norm = 2.1318e-01, time/batch = 0.7172s	
2253/33250 (epoch 3.388), train_loss = 1.42995791, grad/param norm = 2.2206e-01, time/batch = 0.7199s	
2254/33250 (epoch 3.389), train_loss = 1.47284162, grad/param norm = 2.2131e-01, time/batch = 0.6971s	
2255/33250 (epoch 3.391), train_loss = 1.45843540, grad/param norm = 2.1295e-01, time/batch = 0.6992s	
2256/33250 (epoch 3.392), train_loss = 1.63886987, grad/param norm = 2.2739e-01, time/batch = 0.7045s	
2257/33250 (epoch 3.394), train_loss = 1.76041559, grad/param norm = 2.5103e-01, time/batch = 0.7005s	
2258/33250 (epoch 3.395), train_loss = 1.68573257, grad/param norm = 2.2352e-01, time/batch = 0.7032s	
2259/33250 (epoch 3.397), train_loss = 1.59763935, grad/param norm = 2.3038e-01, time/batch = 0.6989s	
2260/33250 (epoch 3.398), train_loss = 1.48904550, grad/param norm = 2.2085e-01, time/batch = 0.6959s	
2261/33250 (epoch 3.400), train_loss = 1.41153085, grad/param norm = 1.9070e-01, time/batch = 0.7031s	
2262/33250 (epoch 3.402), train_loss = 1.34909630, grad/param norm = 2.1777e-01, time/batch = 0.6984s	
2263/33250 (epoch 3.403), train_loss = 1.37579386, grad/param norm = 2.0176e-01, time/batch = 0.6960s	
2264/33250 (epoch 3.405), train_loss = 1.35463662, grad/param norm = 2.1852e-01, time/batch = 0.7016s	
2265/33250 (epoch 3.406), train_loss = 1.51225679, grad/param norm = 2.2464e-01, time/batch = 0.6998s	
2266/33250 (epoch 3.408), train_loss = 1.62542078, grad/param norm = 2.0640e-01, time/batch = 0.7043s	
2267/33250 (epoch 3.409), train_loss = 1.59953378, grad/param norm = 2.5364e-01, time/batch = 0.7107s	
2268/33250 (epoch 3.411), train_loss = 1.19459313, grad/param norm = 2.4285e-01, time/batch = 0.6995s	
2269/33250 (epoch 3.412), train_loss = 1.27805672, grad/param norm = 1.8974e-01, time/batch = 0.7004s	
2270/33250 (epoch 3.414), train_loss = 1.53810629, grad/param norm = 2.0496e-01, time/batch = 0.6979s	
2271/33250 (epoch 3.415), train_loss = 1.54371852, grad/param norm = 2.2135e-01, time/batch = 0.6988s	
2272/33250 (epoch 3.417), train_loss = 1.55095304, grad/param norm = 2.1640e-01, time/batch = 0.7005s	
2273/33250 (epoch 3.418), train_loss = 1.75916654, grad/param norm = 2.6881e-01, time/batch = 0.6974s	
2274/33250 (epoch 3.420), train_loss = 1.58902831, grad/param norm = 2.2259e-01, time/batch = 0.6990s	
2275/33250 (epoch 3.421), train_loss = 1.33993821, grad/param norm = 2.2007e-01, time/batch = 0.6942s	
2276/33250 (epoch 3.423), train_loss = 1.58516188, grad/param norm = 2.1796e-01, time/batch = 0.6984s	
2277/33250 (epoch 3.424), train_loss = 1.77648728, grad/param norm = 2.7571e-01, time/batch = 0.6943s	
2278/33250 (epoch 3.426), train_loss = 1.36068751, grad/param norm = 1.8689e-01, time/batch = 0.6956s	
2279/33250 (epoch 3.427), train_loss = 1.35037659, grad/param norm = 2.2302e-01, time/batch = 0.7072s	
2280/33250 (epoch 3.429), train_loss = 1.57554357, grad/param norm = 2.3346e-01, time/batch = 0.6972s	
2281/33250 (epoch 3.430), train_loss = 1.39857314, grad/param norm = 2.2582e-01, time/batch = 0.7017s	
2282/33250 (epoch 3.432), train_loss = 1.42893462, grad/param norm = 1.8802e-01, time/batch = 0.7020s	
2283/33250 (epoch 3.433), train_loss = 1.46761272, grad/param norm = 2.0431e-01, time/batch = 0.6985s	
2284/33250 (epoch 3.435), train_loss = 1.54657765, grad/param norm = 2.4498e-01, time/batch = 0.6976s	
2285/33250 (epoch 3.436), train_loss = 1.47841992, grad/param norm = 2.2030e-01, time/batch = 0.6972s	
2286/33250 (epoch 3.438), train_loss = 1.42876468, grad/param norm = 2.2276e-01, time/batch = 0.6963s	
2287/33250 (epoch 3.439), train_loss = 1.46380504, grad/param norm = 2.1114e-01, time/batch = 0.6939s	
2288/33250 (epoch 3.441), train_loss = 1.47042598, grad/param norm = 2.1003e-01, time/batch = 0.6962s	
2289/33250 (epoch 3.442), train_loss = 1.44705305, grad/param norm = 2.0624e-01, time/batch = 0.7036s	
2290/33250 (epoch 3.444), train_loss = 1.31500042, grad/param norm = 2.2739e-01, time/batch = 0.7033s	
2291/33250 (epoch 3.445), train_loss = 1.48640311, grad/param norm = 1.9498e-01, time/batch = 0.7014s	
2292/33250 (epoch 3.447), train_loss = 1.48746332, grad/param norm = 1.9874e-01, time/batch = 0.7237s	
2293/33250 (epoch 3.448), train_loss = 1.36608953, grad/param norm = 1.9506e-01, time/batch = 0.7362s	
2294/33250 (epoch 3.450), train_loss = 1.72448997, grad/param norm = 2.4458e-01, time/batch = 0.7109s	
2295/33250 (epoch 3.451), train_loss = 1.55609925, grad/param norm = 2.2698e-01, time/batch = 0.7020s	
2296/33250 (epoch 3.453), train_loss = 1.26377675, grad/param norm = 1.8771e-01, time/batch = 0.6972s	
2297/33250 (epoch 3.454), train_loss = 1.60220119, grad/param norm = 2.2461e-01, time/batch = 0.6958s	
2298/33250 (epoch 3.456), train_loss = 1.62492146, grad/param norm = 2.3702e-01, time/batch = 0.6941s	
2299/33250 (epoch 3.457), train_loss = 1.48752004, grad/param norm = 2.1109e-01, time/batch = 0.6952s	
2300/33250 (epoch 3.459), train_loss = 1.49393812, grad/param norm = 1.9391e-01, time/batch = 0.6922s	
2301/33250 (epoch 3.460), train_loss = 1.50995219, grad/param norm = 2.2614e-01, time/batch = 0.6979s	
2302/33250 (epoch 3.462), train_loss = 1.41433250, grad/param norm = 1.9862e-01, time/batch = 0.7028s	
2303/33250 (epoch 3.463), train_loss = 1.28914733, grad/param norm = 1.7966e-01, time/batch = 0.7064s	
2304/33250 (epoch 3.465), train_loss = 1.19777206, grad/param norm = 1.8383e-01, time/batch = 0.6996s	
2305/33250 (epoch 3.466), train_loss = 1.17631335, grad/param norm = 1.7429e-01, time/batch = 0.7000s	
2306/33250 (epoch 3.468), train_loss = 1.28365156, grad/param norm = 1.8917e-01, time/batch = 0.6969s	
2307/33250 (epoch 3.469), train_loss = 1.55888486, grad/param norm = 2.1464e-01, time/batch = 0.6950s	
2308/33250 (epoch 3.471), train_loss = 1.58715971, grad/param norm = 2.0677e-01, time/batch = 0.6918s	
2309/33250 (epoch 3.472), train_loss = 1.51515078, grad/param norm = 2.4689e-01, time/batch = 0.6936s	
2310/33250 (epoch 3.474), train_loss = 1.79744139, grad/param norm = 2.6077e-01, time/batch = 0.6916s	
2311/33250 (epoch 3.475), train_loss = 1.50673200, grad/param norm = 2.2432e-01, time/batch = 0.6958s	
2312/33250 (epoch 3.477), train_loss = 1.47279641, grad/param norm = 2.0149e-01, time/batch = 0.6962s	
2313/33250 (epoch 3.478), train_loss = 1.42964412, grad/param norm = 1.9870e-01, time/batch = 0.7056s	
2314/33250 (epoch 3.480), train_loss = 1.68059139, grad/param norm = 2.0156e-01, time/batch = 0.7160s	
2315/33250 (epoch 3.481), train_loss = 1.42432242, grad/param norm = 2.2897e-01, time/batch = 0.7253s	
2316/33250 (epoch 3.483), train_loss = 1.51917204, grad/param norm = 2.1689e-01, time/batch = 0.7075s	
2317/33250 (epoch 3.484), train_loss = 1.39496807, grad/param norm = 2.0652e-01, time/batch = 0.7006s	
2318/33250 (epoch 3.486), train_loss = 1.26133360, grad/param norm = 1.8998e-01, time/batch = 0.7029s	
2319/33250 (epoch 3.487), train_loss = 1.44635299, grad/param norm = 2.2192e-01, time/batch = 0.6933s	
2320/33250 (epoch 3.489), train_loss = 1.64873081, grad/param norm = 2.4985e-01, time/batch = 0.6956s	
2321/33250 (epoch 3.490), train_loss = 1.57673810, grad/param norm = 2.2763e-01, time/batch = 0.7000s	
2322/33250 (epoch 3.492), train_loss = 1.50031677, grad/param norm = 2.2167e-01, time/batch = 0.7020s	
2323/33250 (epoch 3.493), train_loss = 1.47908659, grad/param norm = 2.0998e-01, time/batch = 0.6990s	
2324/33250 (epoch 3.495), train_loss = 1.48086483, grad/param norm = 2.0106e-01, time/batch = 0.6889s	
2325/33250 (epoch 3.496), train_loss = 1.41302090, grad/param norm = 1.9709e-01, time/batch = 0.7029s	
2326/33250 (epoch 3.498), train_loss = 1.54258056, grad/param norm = 2.3305e-01, time/batch = 0.7064s	
2327/33250 (epoch 3.499), train_loss = 1.46717158, grad/param norm = 2.1138e-01, time/batch = 0.7019s	
2328/33250 (epoch 3.501), train_loss = 1.39095819, grad/param norm = 2.3597e-01, time/batch = 0.6974s	
2329/33250 (epoch 3.502), train_loss = 1.47390847, grad/param norm = 2.2641e-01, time/batch = 0.6996s	
2330/33250 (epoch 3.504), train_loss = 1.70031938, grad/param norm = 2.2407e-01, time/batch = 0.6933s	
2331/33250 (epoch 3.505), train_loss = 1.19167510, grad/param norm = 1.9201e-01, time/batch = 0.6923s	
2332/33250 (epoch 3.507), train_loss = 1.54613486, grad/param norm = 2.0557e-01, time/batch = 0.6916s	
2333/33250 (epoch 3.508), train_loss = 1.39719163, grad/param norm = 2.0046e-01, time/batch = 0.6925s	
2334/33250 (epoch 3.510), train_loss = 1.32251041, grad/param norm = 1.9789e-01, time/batch = 0.6902s	
2335/33250 (epoch 3.511), train_loss = 1.52771222, grad/param norm = 2.0149e-01, time/batch = 0.6897s	
2336/33250 (epoch 3.513), train_loss = 1.74148377, grad/param norm = 2.2045e-01, time/batch = 0.6938s	
2337/33250 (epoch 3.514), train_loss = 1.42616588, grad/param norm = 1.8908e-01, time/batch = 0.6941s	
2338/33250 (epoch 3.516), train_loss = 1.43793897, grad/param norm = 2.0016e-01, time/batch = 0.6946s	
2339/33250 (epoch 3.517), train_loss = 1.48698186, grad/param norm = 2.1136e-01, time/batch = 0.6988s	
2340/33250 (epoch 3.519), train_loss = 1.27020598, grad/param norm = 1.8928e-01, time/batch = 0.7055s	
2341/33250 (epoch 3.520), train_loss = 1.77668550, grad/param norm = 2.3083e-01, time/batch = 0.7162s	
2342/33250 (epoch 3.522), train_loss = 1.56527773, grad/param norm = 2.1382e-01, time/batch = 0.7028s	
2343/33250 (epoch 3.523), train_loss = 1.42752216, grad/param norm = 2.1567e-01, time/batch = 0.7100s	
2344/33250 (epoch 3.525), train_loss = 1.28598700, grad/param norm = 2.0212e-01, time/batch = 0.7063s	
2345/33250 (epoch 3.526), train_loss = 1.29990053, grad/param norm = 2.2020e-01, time/batch = 0.7097s	
2346/33250 (epoch 3.528), train_loss = 1.43125682, grad/param norm = 2.0680e-01, time/batch = 0.7089s	
2347/33250 (epoch 3.529), train_loss = 1.36726845, grad/param norm = 1.9383e-01, time/batch = 0.7106s	
2348/33250 (epoch 3.531), train_loss = 1.24972648, grad/param norm = 2.0851e-01, time/batch = 0.7101s	
2349/33250 (epoch 3.532), train_loss = 1.61041158, grad/param norm = 1.9707e-01, time/batch = 0.7113s	
2350/33250 (epoch 3.534), train_loss = 1.44730555, grad/param norm = 1.9532e-01, time/batch = 0.7088s	
2351/33250 (epoch 3.535), train_loss = 1.46264478, grad/param norm = 1.8975e-01, time/batch = 0.7125s	
2352/33250 (epoch 3.537), train_loss = 1.58583172, grad/param norm = 1.9917e-01, time/batch = 0.7013s	
2353/33250 (epoch 3.538), train_loss = 1.53564061, grad/param norm = 2.1889e-01, time/batch = 0.7044s	
2354/33250 (epoch 3.540), train_loss = 1.60947119, grad/param norm = 2.0796e-01, time/batch = 0.7015s	
2355/33250 (epoch 3.541), train_loss = 1.61106957, grad/param norm = 2.3008e-01, time/batch = 0.7131s	
2356/33250 (epoch 3.543), train_loss = 1.63353809, grad/param norm = 2.3107e-01, time/batch = 0.7054s	
2357/33250 (epoch 3.544), train_loss = 1.48777402, grad/param norm = 2.4393e-01, time/batch = 0.6972s	
2358/33250 (epoch 3.546), train_loss = 1.48595046, grad/param norm = 2.0283e-01, time/batch = 0.6996s	
2359/33250 (epoch 3.547), train_loss = 1.34578684, grad/param norm = 2.0073e-01, time/batch = 0.6956s	
2360/33250 (epoch 3.549), train_loss = 1.48138273, grad/param norm = 2.0729e-01, time/batch = 0.6984s	
2361/33250 (epoch 3.550), train_loss = 1.39469776, grad/param norm = 1.9594e-01, time/batch = 0.7019s	
2362/33250 (epoch 3.552), train_loss = 1.55521673, grad/param norm = 2.3339e-01, time/batch = 0.6940s	
2363/33250 (epoch 3.553), train_loss = 1.35207265, grad/param norm = 2.0342e-01, time/batch = 0.6999s	
2364/33250 (epoch 3.555), train_loss = 1.42993100, grad/param norm = 1.9113e-01, time/batch = 0.7001s	
2365/33250 (epoch 3.556), train_loss = 1.63927116, grad/param norm = 2.2430e-01, time/batch = 0.6975s	
2366/33250 (epoch 3.558), train_loss = 1.55890935, grad/param norm = 2.0737e-01, time/batch = 0.6981s	
2367/33250 (epoch 3.559), train_loss = 1.33060539, grad/param norm = 2.0329e-01, time/batch = 0.6964s	
2368/33250 (epoch 3.561), train_loss = 1.46451163, grad/param norm = 2.1107e-01, time/batch = 0.6952s	
2369/33250 (epoch 3.562), train_loss = 1.64104492, grad/param norm = 2.2374e-01, time/batch = 0.6944s	
2370/33250 (epoch 3.564), train_loss = 1.66149232, grad/param norm = 2.2835e-01, time/batch = 0.6979s	
2371/33250 (epoch 3.565), train_loss = 1.64850642, grad/param norm = 2.1902e-01, time/batch = 0.6957s	
2372/33250 (epoch 3.567), train_loss = 1.53602384, grad/param norm = 2.0262e-01, time/batch = 0.6912s	
2373/33250 (epoch 3.568), train_loss = 1.40631688, grad/param norm = 2.0673e-01, time/batch = 0.6925s	
2374/33250 (epoch 3.570), train_loss = 1.65986935, grad/param norm = 2.3622e-01, time/batch = 0.6999s	
2375/33250 (epoch 3.571), train_loss = 1.68173571, grad/param norm = 2.0015e-01, time/batch = 0.6972s	
2376/33250 (epoch 3.573), train_loss = 1.58959343, grad/param norm = 1.9513e-01, time/batch = 0.6945s	
2377/33250 (epoch 3.574), train_loss = 1.34807215, grad/param norm = 1.9409e-01, time/batch = 0.6968s	
2378/33250 (epoch 3.576), train_loss = 1.51768072, grad/param norm = 2.0472e-01, time/batch = 0.6979s	
2379/33250 (epoch 3.577), train_loss = 1.46348815, grad/param norm = 1.8811e-01, time/batch = 0.6993s	
2380/33250 (epoch 3.579), train_loss = 1.31515367, grad/param norm = 1.9470e-01, time/batch = 0.6960s	
2381/33250 (epoch 3.580), train_loss = 1.27267847, grad/param norm = 1.8709e-01, time/batch = 0.6967s	
2382/33250 (epoch 3.582), train_loss = 1.41074462, grad/param norm = 1.8844e-01, time/batch = 0.6943s	
2383/33250 (epoch 3.583), train_loss = 1.45794356, grad/param norm = 1.8623e-01, time/batch = 0.6941s	
2384/33250 (epoch 3.585), train_loss = 1.58549998, grad/param norm = 2.3094e-01, time/batch = 0.6980s	
2385/33250 (epoch 3.586), train_loss = 1.40344906, grad/param norm = 2.2992e-01, time/batch = 0.6929s	
2386/33250 (epoch 3.588), train_loss = 1.50063973, grad/param norm = 2.0984e-01, time/batch = 0.6980s	
2387/33250 (epoch 3.589), train_loss = 1.57325988, grad/param norm = 2.1432e-01, time/batch = 0.7012s	
2388/33250 (epoch 3.591), train_loss = 1.59634831, grad/param norm = 2.2005e-01, time/batch = 0.6916s	
2389/33250 (epoch 3.592), train_loss = 1.44094120, grad/param norm = 1.8831e-01, time/batch = 0.6927s	
2390/33250 (epoch 3.594), train_loss = 1.69544842, grad/param norm = 2.2240e-01, time/batch = 0.6908s	
2391/33250 (epoch 3.595), train_loss = 1.67083308, grad/param norm = 2.0488e-01, time/batch = 0.6918s	
2392/33250 (epoch 3.597), train_loss = 1.38210468, grad/param norm = 1.9655e-01, time/batch = 0.6905s	
2393/33250 (epoch 3.598), train_loss = 1.57586577, grad/param norm = 1.9896e-01, time/batch = 0.6868s	
2394/33250 (epoch 3.600), train_loss = 1.48129375, grad/param norm = 2.0347e-01, time/batch = 0.6867s	
2395/33250 (epoch 3.602), train_loss = 1.58621815, grad/param norm = 2.5045e-01, time/batch = 0.6995s	
2396/33250 (epoch 3.603), train_loss = 1.43296012, grad/param norm = 1.9061e-01, time/batch = 0.7186s	
2397/33250 (epoch 3.605), train_loss = 1.49621653, grad/param norm = 2.1069e-01, time/batch = 0.7043s	
2398/33250 (epoch 3.606), train_loss = 1.53045935, grad/param norm = 2.0427e-01, time/batch = 0.7116s	
2399/33250 (epoch 3.608), train_loss = 1.47593728, grad/param norm = 2.0878e-01, time/batch = 0.7200s	
2400/33250 (epoch 3.609), train_loss = 1.39924069, grad/param norm = 2.1556e-01, time/batch = 0.7318s	
2401/33250 (epoch 3.611), train_loss = 1.61651620, grad/param norm = 2.1632e-01, time/batch = 0.7451s	
2402/33250 (epoch 3.612), train_loss = 1.52643900, grad/param norm = 2.1064e-01, time/batch = 0.7374s	
2403/33250 (epoch 3.614), train_loss = 1.80648784, grad/param norm = 2.4859e-01, time/batch = 0.7244s	
2404/33250 (epoch 3.615), train_loss = 1.62796196, grad/param norm = 2.1886e-01, time/batch = 0.7261s	
2405/33250 (epoch 3.617), train_loss = 1.92729667, grad/param norm = 2.0416e-01, time/batch = 0.7195s	
2406/33250 (epoch 3.618), train_loss = 1.83119025, grad/param norm = 2.7180e-01, time/batch = 0.7352s	
2407/33250 (epoch 3.620), train_loss = 1.67253312, grad/param norm = 2.2811e-01, time/batch = 0.7344s	
2408/33250 (epoch 3.621), train_loss = 1.43470834, grad/param norm = 1.8461e-01, time/batch = 0.7182s	
2409/33250 (epoch 3.623), train_loss = 1.42575466, grad/param norm = 2.2345e-01, time/batch = 0.7258s	
2410/33250 (epoch 3.624), train_loss = 1.50539869, grad/param norm = 2.2557e-01, time/batch = 0.7253s	
2411/33250 (epoch 3.626), train_loss = 1.54335869, grad/param norm = 2.0295e-01, time/batch = 0.7216s	
2412/33250 (epoch 3.627), train_loss = 1.48995416, grad/param norm = 1.9078e-01, time/batch = 0.7218s	
2413/33250 (epoch 3.629), train_loss = 1.46386680, grad/param norm = 2.2865e-01, time/batch = 0.7054s	
2414/33250 (epoch 3.630), train_loss = 1.48229539, grad/param norm = 2.0912e-01, time/batch = 0.7120s	
2415/33250 (epoch 3.632), train_loss = 1.26010084, grad/param norm = 1.8158e-01, time/batch = 0.6968s	
2416/33250 (epoch 3.633), train_loss = 1.59639417, grad/param norm = 2.2638e-01, time/batch = 0.6994s	
2417/33250 (epoch 3.635), train_loss = 1.33611002, grad/param norm = 1.8642e-01, time/batch = 0.7033s	
2418/33250 (epoch 3.636), train_loss = 1.41018625, grad/param norm = 2.0102e-01, time/batch = 0.7086s	
2419/33250 (epoch 3.638), train_loss = 1.43367557, grad/param norm = 2.0355e-01, time/batch = 0.7078s	
2420/33250 (epoch 3.639), train_loss = 1.44675436, grad/param norm = 2.3220e-01, time/batch = 0.6964s	
2421/33250 (epoch 3.641), train_loss = 1.36142053, grad/param norm = 1.8954e-01, time/batch = 0.6966s	
2422/33250 (epoch 3.642), train_loss = 1.37592330, grad/param norm = 1.8672e-01, time/batch = 0.7037s	
2423/33250 (epoch 3.644), train_loss = 1.23771858, grad/param norm = 1.9131e-01, time/batch = 0.6965s	
2424/33250 (epoch 3.645), train_loss = 1.63006831, grad/param norm = 2.3408e-01, time/batch = 0.7009s	
2425/33250 (epoch 3.647), train_loss = 1.35343091, grad/param norm = 1.9077e-01, time/batch = 0.6949s	
2426/33250 (epoch 3.648), train_loss = 1.44183306, grad/param norm = 2.2589e-01, time/batch = 0.6911s	
2427/33250 (epoch 3.650), train_loss = 1.64960119, grad/param norm = 2.4031e-01, time/batch = 0.6943s	
2428/33250 (epoch 3.651), train_loss = 1.50016620, grad/param norm = 2.3469e-01, time/batch = 0.6873s	
2429/33250 (epoch 3.653), train_loss = 1.30161850, grad/param norm = 1.7609e-01, time/batch = 0.6952s	
2430/33250 (epoch 3.654), train_loss = 1.32529827, grad/param norm = 1.7396e-01, time/batch = 0.6944s	
2431/33250 (epoch 3.656), train_loss = 1.51840802, grad/param norm = 2.0100e-01, time/batch = 0.6907s	
2432/33250 (epoch 3.657), train_loss = 1.28759780, grad/param norm = 1.9561e-01, time/batch = 0.6910s	
2433/33250 (epoch 3.659), train_loss = 1.34381134, grad/param norm = 1.8563e-01, time/batch = 0.6989s	
2434/33250 (epoch 3.660), train_loss = 1.37093670, grad/param norm = 2.2598e-01, time/batch = 0.6919s	
2435/33250 (epoch 3.662), train_loss = 1.49387458, grad/param norm = 2.1114e-01, time/batch = 0.6892s	
2436/33250 (epoch 3.663), train_loss = 1.38104293, grad/param norm = 1.9847e-01, time/batch = 0.6925s	
2437/33250 (epoch 3.665), train_loss = 1.60732086, grad/param norm = 2.1833e-01, time/batch = 0.6908s	
2438/33250 (epoch 3.666), train_loss = 1.44208207, grad/param norm = 2.2969e-01, time/batch = 0.7003s	
2439/33250 (epoch 3.668), train_loss = 1.59095955, grad/param norm = 2.0424e-01, time/batch = 0.6905s	
2440/33250 (epoch 3.669), train_loss = 1.56838148, grad/param norm = 2.1072e-01, time/batch = 0.6926s	
2441/33250 (epoch 3.671), train_loss = 1.48815761, grad/param norm = 2.1021e-01, time/batch = 0.6998s	
2442/33250 (epoch 3.672), train_loss = 1.63383199, grad/param norm = 2.2279e-01, time/batch = 0.6961s	
2443/33250 (epoch 3.674), train_loss = 1.42892232, grad/param norm = 1.8344e-01, time/batch = 0.6915s	
2444/33250 (epoch 3.675), train_loss = 1.55436294, grad/param norm = 2.1419e-01, time/batch = 0.6931s	
2445/33250 (epoch 3.677), train_loss = 1.47954895, grad/param norm = 2.0370e-01, time/batch = 0.6942s	
2446/33250 (epoch 3.678), train_loss = 1.52650462, grad/param norm = 2.0625e-01, time/batch = 0.6944s	
2447/33250 (epoch 3.680), train_loss = 1.55535717, grad/param norm = 2.0882e-01, time/batch = 0.6960s	
2448/33250 (epoch 3.681), train_loss = 1.28215053, grad/param norm = 1.9008e-01, time/batch = 0.7083s	
2449/33250 (epoch 3.683), train_loss = 1.37708917, grad/param norm = 2.3721e-01, time/batch = 0.7107s	
2450/33250 (epoch 3.684), train_loss = 1.45394537, grad/param norm = 2.5573e-01, time/batch = 0.7107s	
2451/33250 (epoch 3.686), train_loss = 1.33526747, grad/param norm = 1.8206e-01, time/batch = 0.7063s	
2452/33250 (epoch 3.687), train_loss = 1.36697280, grad/param norm = 1.9757e-01, time/batch = 0.7089s	
2453/33250 (epoch 3.689), train_loss = 1.37476043, grad/param norm = 2.0013e-01, time/batch = 0.7033s	
2454/33250 (epoch 3.690), train_loss = 1.57465796, grad/param norm = 2.2494e-01, time/batch = 0.7087s	
2455/33250 (epoch 3.692), train_loss = 1.59762758, grad/param norm = 2.4042e-01, time/batch = 0.6979s	
2456/33250 (epoch 3.693), train_loss = 1.43877844, grad/param norm = 1.8254e-01, time/batch = 0.6921s	
2457/33250 (epoch 3.695), train_loss = 1.55101263, grad/param norm = 2.1800e-01, time/batch = 0.6921s	
2458/33250 (epoch 3.696), train_loss = 1.44408234, grad/param norm = 1.8425e-01, time/batch = 0.6931s	
2459/33250 (epoch 3.698), train_loss = 1.35381948, grad/param norm = 2.0655e-01, time/batch = 0.6994s	
2460/33250 (epoch 3.699), train_loss = 1.65608912, grad/param norm = 2.0631e-01, time/batch = 0.7124s	
2461/33250 (epoch 3.701), train_loss = 1.38554969, grad/param norm = 1.8595e-01, time/batch = 0.7012s	
2462/33250 (epoch 3.702), train_loss = 1.55885311, grad/param norm = 2.3202e-01, time/batch = 0.6962s	
2463/33250 (epoch 3.704), train_loss = 1.65150312, grad/param norm = 2.3133e-01, time/batch = 0.6961s	
2464/33250 (epoch 3.705), train_loss = 1.34268416, grad/param norm = 1.8813e-01, time/batch = 0.6979s	
2465/33250 (epoch 3.707), train_loss = 1.32501278, grad/param norm = 2.1056e-01, time/batch = 0.6952s	
2466/33250 (epoch 3.708), train_loss = 1.51015201, grad/param norm = 2.0657e-01, time/batch = 0.6962s	
2467/33250 (epoch 3.710), train_loss = 1.60232104, grad/param norm = 2.2795e-01, time/batch = 0.6970s	
2468/33250 (epoch 3.711), train_loss = 1.57681962, grad/param norm = 2.2668e-01, time/batch = 0.6942s	
2469/33250 (epoch 3.713), train_loss = 1.59469805, grad/param norm = 2.5132e-01, time/batch = 0.6997s	
2470/33250 (epoch 3.714), train_loss = 1.55623261, grad/param norm = 1.9822e-01, time/batch = 0.6910s	
2471/33250 (epoch 3.716), train_loss = 1.64484624, grad/param norm = 2.2452e-01, time/batch = 0.6954s	
2472/33250 (epoch 3.717), train_loss = 1.39739768, grad/param norm = 1.9320e-01, time/batch = 0.6955s	
2473/33250 (epoch 3.719), train_loss = 1.52331705, grad/param norm = 2.1775e-01, time/batch = 0.6934s	
2474/33250 (epoch 3.720), train_loss = 1.69938711, grad/param norm = 2.0237e-01, time/batch = 0.6917s	
2475/33250 (epoch 3.722), train_loss = 1.36646811, grad/param norm = 1.7579e-01, time/batch = 0.6893s	
2476/33250 (epoch 3.723), train_loss = 1.24303536, grad/param norm = 1.7895e-01, time/batch = 0.7078s	
2477/33250 (epoch 3.725), train_loss = 1.19342882, grad/param norm = 1.6043e-01, time/batch = 0.7090s	
2478/33250 (epoch 3.726), train_loss = 1.36632460, grad/param norm = 1.8606e-01, time/batch = 0.6971s	
2479/33250 (epoch 3.728), train_loss = 1.52191923, grad/param norm = 2.1098e-01, time/batch = 0.7170s	
2480/33250 (epoch 3.729), train_loss = 1.62014158, grad/param norm = 2.1887e-01, time/batch = 0.7122s	
2481/33250 (epoch 3.731), train_loss = 1.39126557, grad/param norm = 1.9749e-01, time/batch = 0.7025s	
2482/33250 (epoch 3.732), train_loss = 1.36641984, grad/param norm = 1.9273e-01, time/batch = 0.6955s	
2483/33250 (epoch 3.734), train_loss = 1.50835523, grad/param norm = 1.9784e-01, time/batch = 0.7046s	
2484/33250 (epoch 3.735), train_loss = 1.50340502, grad/param norm = 1.9622e-01, time/batch = 0.7096s	
2485/33250 (epoch 3.737), train_loss = 1.54744268, grad/param norm = 1.8482e-01, time/batch = 0.7225s	
2486/33250 (epoch 3.738), train_loss = 1.50202353, grad/param norm = 1.8654e-01, time/batch = 0.7124s	
2487/33250 (epoch 3.740), train_loss = 1.68580229, grad/param norm = 2.0846e-01, time/batch = 0.7032s	
2488/33250 (epoch 3.741), train_loss = 1.50383389, grad/param norm = 2.1052e-01, time/batch = 0.7164s	
2489/33250 (epoch 3.743), train_loss = 1.44361358, grad/param norm = 1.8787e-01, time/batch = 0.7172s	
2490/33250 (epoch 3.744), train_loss = 1.47815582, grad/param norm = 1.9954e-01, time/batch = 0.7070s	
2491/33250 (epoch 3.746), train_loss = 1.49589703, grad/param norm = 1.8199e-01, time/batch = 0.7064s	
2492/33250 (epoch 3.747), train_loss = 1.43886462, grad/param norm = 2.0427e-01, time/batch = 0.7003s	
2493/33250 (epoch 3.749), train_loss = 1.66391933, grad/param norm = 2.3682e-01, time/batch = 0.6990s	
2494/33250 (epoch 3.750), train_loss = 1.49708104, grad/param norm = 2.2176e-01, time/batch = 0.6960s	
2495/33250 (epoch 3.752), train_loss = 1.33911606, grad/param norm = 1.8032e-01, time/batch = 0.6979s	
2496/33250 (epoch 3.753), train_loss = 1.44616934, grad/param norm = 1.9149e-01, time/batch = 0.7130s	
2497/33250 (epoch 3.755), train_loss = 1.35717127, grad/param norm = 2.0101e-01, time/batch = 0.7055s	
2498/33250 (epoch 3.756), train_loss = 1.56861068, grad/param norm = 2.0035e-01, time/batch = 0.7082s	
2499/33250 (epoch 3.758), train_loss = 1.53213771, grad/param norm = 1.9504e-01, time/batch = 0.6959s	
2500/33250 (epoch 3.759), train_loss = 1.31619133, grad/param norm = 1.8289e-01, time/batch = 0.6947s	
2501/33250 (epoch 3.761), train_loss = 1.43311452, grad/param norm = 2.1754e-01, time/batch = 0.7005s	
2502/33250 (epoch 3.762), train_loss = 1.50681869, grad/param norm = 2.2272e-01, time/batch = 0.6991s	
2503/33250 (epoch 3.764), train_loss = 1.39477212, grad/param norm = 2.6588e-01, time/batch = 0.6981s	
2504/33250 (epoch 3.765), train_loss = 1.48960531, grad/param norm = 2.2554e-01, time/batch = 0.6952s	
2505/33250 (epoch 3.767), train_loss = 1.26444754, grad/param norm = 2.3276e-01, time/batch = 0.6933s	
2506/33250 (epoch 3.768), train_loss = 1.36024216, grad/param norm = 2.1022e-01, time/batch = 0.6973s	
2507/33250 (epoch 3.770), train_loss = 1.47670097, grad/param norm = 2.2091e-01, time/batch = 0.6966s	
2508/33250 (epoch 3.771), train_loss = 1.55008619, grad/param norm = 2.1190e-01, time/batch = 0.6966s	
2509/33250 (epoch 3.773), train_loss = 1.43979743, grad/param norm = 2.1684e-01, time/batch = 0.6977s	
2510/33250 (epoch 3.774), train_loss = 1.26928022, grad/param norm = 2.0540e-01, time/batch = 0.6951s	
2511/33250 (epoch 3.776), train_loss = 1.41661054, grad/param norm = 2.0727e-01, time/batch = 0.7032s	
2512/33250 (epoch 3.777), train_loss = 1.60317458, grad/param norm = 2.4555e-01, time/batch = 0.6990s	
2513/33250 (epoch 3.779), train_loss = 1.31830593, grad/param norm = 1.9823e-01, time/batch = 0.6950s	
2514/33250 (epoch 3.780), train_loss = 1.67331117, grad/param norm = 2.3338e-01, time/batch = 0.6952s	
2515/33250 (epoch 3.782), train_loss = 1.49191528, grad/param norm = 2.1374e-01, time/batch = 0.6976s	
2516/33250 (epoch 3.783), train_loss = 1.26911353, grad/param norm = 1.9291e-01, time/batch = 0.6931s	
2517/33250 (epoch 3.785), train_loss = 1.36787475, grad/param norm = 2.0240e-01, time/batch = 0.6982s	
2518/33250 (epoch 3.786), train_loss = 1.57707732, grad/param norm = 2.1785e-01, time/batch = 0.6958s	
2519/33250 (epoch 3.788), train_loss = 1.41439127, grad/param norm = 1.8729e-01, time/batch = 0.6994s	
2520/33250 (epoch 3.789), train_loss = 1.54912988, grad/param norm = 2.0858e-01, time/batch = 0.6900s	
2521/33250 (epoch 3.791), train_loss = 1.58437849, grad/param norm = 2.0128e-01, time/batch = 0.7000s	
2522/33250 (epoch 3.792), train_loss = 1.65578904, grad/param norm = 1.9569e-01, time/batch = 0.6964s	
2523/33250 (epoch 3.794), train_loss = 1.36031962, grad/param norm = 2.0546e-01, time/batch = 0.6979s	
2524/33250 (epoch 3.795), train_loss = 1.52963370, grad/param norm = 1.9677e-01, time/batch = 0.6985s	
2525/33250 (epoch 3.797), train_loss = 1.60897558, grad/param norm = 2.1177e-01, time/batch = 0.7082s	
2526/33250 (epoch 3.798), train_loss = 1.58179683, grad/param norm = 2.7162e-01, time/batch = 0.6921s	
2527/33250 (epoch 3.800), train_loss = 1.60794656, grad/param norm = 2.4123e-01, time/batch = 0.6954s	
2528/33250 (epoch 3.802), train_loss = 1.41726992, grad/param norm = 2.0894e-01, time/batch = 0.6934s	
2529/33250 (epoch 3.803), train_loss = 1.41226598, grad/param norm = 1.8977e-01, time/batch = 0.6952s	
2530/33250 (epoch 3.805), train_loss = 1.49766626, grad/param norm = 2.0926e-01, time/batch = 0.6931s	
2531/33250 (epoch 3.806), train_loss = 1.55536375, grad/param norm = 1.9998e-01, time/batch = 0.6976s	
2532/33250 (epoch 3.808), train_loss = 1.50013970, grad/param norm = 2.0186e-01, time/batch = 0.6969s	
2533/33250 (epoch 3.809), train_loss = 1.30277950, grad/param norm = 1.8874e-01, time/batch = 0.7031s	
2534/33250 (epoch 3.811), train_loss = 1.39043954, grad/param norm = 2.1452e-01, time/batch = 0.7035s	
2535/33250 (epoch 3.812), train_loss = 1.46305258, grad/param norm = 2.0237e-01, time/batch = 0.7042s	
2536/33250 (epoch 3.814), train_loss = 1.41200263, grad/param norm = 2.0415e-01, time/batch = 0.7022s	
2537/33250 (epoch 3.815), train_loss = 1.51575699, grad/param norm = 2.2617e-01, time/batch = 0.7077s	
2538/33250 (epoch 3.817), train_loss = 1.44876563, grad/param norm = 2.1133e-01, time/batch = 0.6942s	
2539/33250 (epoch 3.818), train_loss = 1.33018611, grad/param norm = 1.9736e-01, time/batch = 0.6953s	
2540/33250 (epoch 3.820), train_loss = 1.52911102, grad/param norm = 2.2333e-01, time/batch = 0.6943s	
2541/33250 (epoch 3.821), train_loss = 1.33130409, grad/param norm = 1.8746e-01, time/batch = 0.6999s	
2542/33250 (epoch 3.823), train_loss = 1.72332674, grad/param norm = 2.2464e-01, time/batch = 0.6942s	
2543/33250 (epoch 3.824), train_loss = 1.48883820, grad/param norm = 1.9616e-01, time/batch = 0.7094s	
2544/33250 (epoch 3.826), train_loss = 1.43714719, grad/param norm = 2.2627e-01, time/batch = 0.7016s	
2545/33250 (epoch 3.827), train_loss = 1.26413186, grad/param norm = 2.0403e-01, time/batch = 0.6988s	
2546/33250 (epoch 3.829), train_loss = 1.45847613, grad/param norm = 2.0510e-01, time/batch = 0.6981s	
2547/33250 (epoch 3.830), train_loss = 1.71706156, grad/param norm = 2.5354e-01, time/batch = 0.7138s	
2548/33250 (epoch 3.832), train_loss = 1.39954928, grad/param norm = 2.0110e-01, time/batch = 0.7003s	
2549/33250 (epoch 3.833), train_loss = 1.52194830, grad/param norm = 2.0939e-01, time/batch = 0.7020s	
2550/33250 (epoch 3.835), train_loss = 1.47895464, grad/param norm = 2.3040e-01, time/batch = 0.7079s	
2551/33250 (epoch 3.836), train_loss = 1.48177212, grad/param norm = 2.0138e-01, time/batch = 0.7138s	
2552/33250 (epoch 3.838), train_loss = 1.36543019, grad/param norm = 1.8181e-01, time/batch = 0.7119s	
2553/33250 (epoch 3.839), train_loss = 1.40998034, grad/param norm = 2.0272e-01, time/batch = 0.7125s	
2554/33250 (epoch 3.841), train_loss = 1.23446764, grad/param norm = 1.7931e-01, time/batch = 0.7142s	
2555/33250 (epoch 3.842), train_loss = 1.55190506, grad/param norm = 2.0087e-01, time/batch = 0.7143s	
2556/33250 (epoch 3.844), train_loss = 1.62690673, grad/param norm = 2.2866e-01, time/batch = 0.7194s	
2557/33250 (epoch 3.845), train_loss = 1.72522056, grad/param norm = 2.5170e-01, time/batch = 0.7476s	
2558/33250 (epoch 3.847), train_loss = 1.62864243, grad/param norm = 1.9973e-01, time/batch = 0.7395s	
2559/33250 (epoch 3.848), train_loss = 1.74410208, grad/param norm = 2.3873e-01, time/batch = 0.7241s	
2560/33250 (epoch 3.850), train_loss = 1.53861202, grad/param norm = 2.1632e-01, time/batch = 0.7243s	
2561/33250 (epoch 3.851), train_loss = 1.40740762, grad/param norm = 2.0157e-01, time/batch = 0.7295s	
2562/33250 (epoch 3.853), train_loss = 1.52697484, grad/param norm = 2.1885e-01, time/batch = 0.7070s	
2563/33250 (epoch 3.854), train_loss = 1.32289607, grad/param norm = 1.8820e-01, time/batch = 0.7007s	
2564/33250 (epoch 3.856), train_loss = 1.33678069, grad/param norm = 1.8734e-01, time/batch = 0.6972s	
2565/33250 (epoch 3.857), train_loss = 1.23941958, grad/param norm = 1.7877e-01, time/batch = 0.6959s	
2566/33250 (epoch 3.859), train_loss = 1.24590197, grad/param norm = 1.9873e-01, time/batch = 0.7012s	
2567/33250 (epoch 3.860), train_loss = 1.38722607, grad/param norm = 1.6563e-01, time/batch = 0.6980s	
2568/33250 (epoch 3.862), train_loss = 1.31594199, grad/param norm = 1.8133e-01, time/batch = 0.7150s	
2569/33250 (epoch 3.863), train_loss = 1.32689219, grad/param norm = 1.8413e-01, time/batch = 0.7290s	
