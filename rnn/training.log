tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 237, val: 13, test: 0	
vocab size: 122	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 276858	
cloning rnn	
cloning criterion	
1/11850 (epoch 0.004), train_loss = 4.78540610, grad/param norm = 5.8225e-01, time/batch = 0.6998s	
2/11850 (epoch 0.008), train_loss = 4.22119993, grad/param norm = 1.9760e+00, time/batch = 0.6410s	
3/11850 (epoch 0.013), train_loss = 3.51957529, grad/param norm = 1.3707e+00, time/batch = 0.6405s	
4/11850 (epoch 0.017), train_loss = 3.38701870, grad/param norm = 7.1735e-01, time/batch = 0.6412s	
5/11850 (epoch 0.021), train_loss = 3.28118536, grad/param norm = 8.1102e-01, time/batch = 0.6439s	
6/11850 (epoch 0.025), train_loss = 3.14159806, grad/param norm = 4.3657e-01, time/batch = 0.6403s	
7/11850 (epoch 0.030), train_loss = 3.31187959, grad/param norm = 8.1674e-01, time/batch = 0.6421s	
8/11850 (epoch 0.034), train_loss = 3.25734681, grad/param norm = 8.5870e-01, time/batch = 0.6441s	
9/11850 (epoch 0.038), train_loss = 3.26385809, grad/param norm = 1.1548e+00, time/batch = 0.6437s	
10/11850 (epoch 0.042), train_loss = 3.30760779, grad/param norm = 6.1752e-01, time/batch = 0.6427s	
11/11850 (epoch 0.046), train_loss = 3.36565310, grad/param norm = 9.5769e-01, time/batch = 0.6385s	
12/11850 (epoch 0.051), train_loss = 3.31589921, grad/param norm = 7.6089e-01, time/batch = 0.6390s	
13/11850 (epoch 0.055), train_loss = 3.39160160, grad/param norm = 7.0144e-01, time/batch = 0.6390s	
14/11850 (epoch 0.059), train_loss = 3.41575435, grad/param norm = 7.2892e-01, time/batch = 0.6377s	
15/11850 (epoch 0.063), train_loss = 3.31520810, grad/param norm = 5.6555e-01, time/batch = 0.6368s	
16/11850 (epoch 0.068), train_loss = 3.33269355, grad/param norm = 5.9733e-01, time/batch = 0.6369s	
17/11850 (epoch 0.072), train_loss = 3.32382837, grad/param norm = 7.1522e-01, time/batch = 0.6370s	
18/11850 (epoch 0.076), train_loss = 3.25235319, grad/param norm = 5.9876e-01, time/batch = 0.6425s	
19/11850 (epoch 0.080), train_loss = 3.44982693, grad/param norm = 5.7713e-01, time/batch = 0.6415s	
20/11850 (epoch 0.084), train_loss = 3.35147861, grad/param norm = 7.9701e-01, time/batch = 0.6417s	
21/11850 (epoch 0.089), train_loss = 3.29902048, grad/param norm = 7.1458e-01, time/batch = 0.6431s	
22/11850 (epoch 0.093), train_loss = 3.32192692, grad/param norm = 6.7627e-01, time/batch = 0.6386s	
23/11850 (epoch 0.097), train_loss = 3.37892082, grad/param norm = 5.3869e-01, time/batch = 0.6390s	
24/11850 (epoch 0.101), train_loss = 3.45223185, grad/param norm = 5.6403e-01, time/batch = 0.6426s	
25/11850 (epoch 0.105), train_loss = 3.26551420, grad/param norm = 5.7760e-01, time/batch = 0.6363s	
26/11850 (epoch 0.110), train_loss = 3.22757905, grad/param norm = 6.3145e-01, time/batch = 0.6418s	
27/11850 (epoch 0.114), train_loss = 3.44095323, grad/param norm = 6.9998e-01, time/batch = 0.6391s	
28/11850 (epoch 0.118), train_loss = 3.14766274, grad/param norm = 8.7872e-01, time/batch = 0.6346s	
29/11850 (epoch 0.122), train_loss = 3.23995025, grad/param norm = 1.0022e+00, time/batch = 0.6350s	
30/11850 (epoch 0.127), train_loss = 3.36014147, grad/param norm = 9.2633e-01, time/batch = 0.6377s	
31/11850 (epoch 0.131), train_loss = 3.32233804, grad/param norm = 7.3204e-01, time/batch = 0.6386s	
32/11850 (epoch 0.135), train_loss = 3.27022581, grad/param norm = 5.3876e-01, time/batch = 0.6405s	
33/11850 (epoch 0.139), train_loss = 3.33631498, grad/param norm = 5.9994e-01, time/batch = 0.6368s	
34/11850 (epoch 0.143), train_loss = 3.47292615, grad/param norm = 7.6641e-01, time/batch = 0.6387s	
35/11850 (epoch 0.148), train_loss = 3.33124863, grad/param norm = 8.3199e-01, time/batch = 0.6369s	
36/11850 (epoch 0.152), train_loss = 3.32231568, grad/param norm = 9.2438e-01, time/batch = 0.6333s	
37/11850 (epoch 0.156), train_loss = 3.35443294, grad/param norm = 7.9470e-01, time/batch = 0.6436s	
38/11850 (epoch 0.160), train_loss = 3.46195208, grad/param norm = 7.9513e-01, time/batch = 0.6698s	
39/11850 (epoch 0.165), train_loss = 3.38643513, grad/param norm = 6.8104e-01, time/batch = 0.6635s	
40/11850 (epoch 0.169), train_loss = 3.25248714, grad/param norm = 7.8592e-01, time/batch = 0.6472s	
41/11850 (epoch 0.173), train_loss = 3.27800115, grad/param norm = 5.7625e-01, time/batch = 0.6373s	
42/11850 (epoch 0.177), train_loss = 3.31271232, grad/param norm = 7.6308e-01, time/batch = 0.6405s	
43/11850 (epoch 0.181), train_loss = 3.24947686, grad/param norm = 6.5893e-01, time/batch = 0.6388s	
44/11850 (epoch 0.186), train_loss = 3.36347744, grad/param norm = 4.9940e-01, time/batch = 0.6534s	
45/11850 (epoch 0.190), train_loss = 3.33615389, grad/param norm = 5.1285e-01, time/batch = 0.6661s	
46/11850 (epoch 0.194), train_loss = 3.50378159, grad/param norm = 5.7889e-01, time/batch = 0.6673s	
47/11850 (epoch 0.198), train_loss = 3.24692517, grad/param norm = 6.5188e-01, time/batch = 0.6662s	
48/11850 (epoch 0.203), train_loss = 3.17192869, grad/param norm = 5.5795e-01, time/batch = 0.6697s	
49/11850 (epoch 0.207), train_loss = 3.41091103, grad/param norm = 7.2811e-01, time/batch = 0.6699s	
50/11850 (epoch 0.211), train_loss = 3.42887693, grad/param norm = 5.6043e-01, time/batch = 0.6665s	
51/11850 (epoch 0.215), train_loss = 3.33026044, grad/param norm = 4.5543e-01, time/batch = 0.6607s	
52/11850 (epoch 0.219), train_loss = 3.22562599, grad/param norm = 7.3789e-01, time/batch = 0.6428s	
53/11850 (epoch 0.224), train_loss = 3.33685824, grad/param norm = 6.3532e-01, time/batch = 0.6456s	
54/11850 (epoch 0.228), train_loss = 3.33664480, grad/param norm = 6.7717e-01, time/batch = 0.6395s	
55/11850 (epoch 0.232), train_loss = 3.41880447, grad/param norm = 7.6283e-01, time/batch = 0.6413s	
56/11850 (epoch 0.236), train_loss = 3.35456991, grad/param norm = 8.1865e-01, time/batch = 0.6416s	
57/11850 (epoch 0.241), train_loss = 3.30211536, grad/param norm = 5.7127e-01, time/batch = 0.6389s	
58/11850 (epoch 0.245), train_loss = 3.27881038, grad/param norm = 6.9574e-01, time/batch = 0.6375s	
59/11850 (epoch 0.249), train_loss = 3.21892507, grad/param norm = 7.6856e-01, time/batch = 0.6511s	
60/11850 (epoch 0.253), train_loss = 3.39141740, grad/param norm = 7.2672e-01, time/batch = 0.6687s	
61/11850 (epoch 0.257), train_loss = 3.35077939, grad/param norm = 7.6689e-01, time/batch = 0.6400s	
62/11850 (epoch 0.262), train_loss = 3.50283082, grad/param norm = 5.8768e-01, time/batch = 0.6374s	
63/11850 (epoch 0.266), train_loss = 3.32546866, grad/param norm = 6.2550e-01, time/batch = 0.6355s	
64/11850 (epoch 0.270), train_loss = 3.26756852, grad/param norm = 5.4935e-01, time/batch = 0.6401s	
65/11850 (epoch 0.274), train_loss = 3.42951176, grad/param norm = 6.8657e-01, time/batch = 0.6396s	
66/11850 (epoch 0.278), train_loss = 3.32927906, grad/param norm = 7.7718e-01, time/batch = 0.6361s	
67/11850 (epoch 0.283), train_loss = 3.28591274, grad/param norm = 6.3416e-01, time/batch = 0.6374s	
68/11850 (epoch 0.287), train_loss = 3.28150816, grad/param norm = 6.4478e-01, time/batch = 0.6370s	
69/11850 (epoch 0.291), train_loss = 3.36587876, grad/param norm = 5.3732e-01, time/batch = 0.6421s	
70/11850 (epoch 0.295), train_loss = 3.31311906, grad/param norm = 5.6334e-01, time/batch = 0.6447s	
71/11850 (epoch 0.300), train_loss = 3.19304459, grad/param norm = 9.5875e-01, time/batch = 0.6408s	
72/11850 (epoch 0.304), train_loss = 3.29529522, grad/param norm = 5.7527e-01, time/batch = 0.6356s	
73/11850 (epoch 0.308), train_loss = 3.19561324, grad/param norm = 4.2719e-01, time/batch = 0.6360s	
74/11850 (epoch 0.312), train_loss = 3.25349287, grad/param norm = 3.8266e-01, time/batch = 0.6343s	
75/11850 (epoch 0.316), train_loss = 3.25903277, grad/param norm = 5.9956e-01, time/batch = 0.6356s	
76/11850 (epoch 0.321), train_loss = 3.23303950, grad/param norm = 5.0139e-01, time/batch = 0.6343s	
77/11850 (epoch 0.325), train_loss = 3.28667382, grad/param norm = 5.8558e-01, time/batch = 0.6349s	
78/11850 (epoch 0.329), train_loss = 3.31415769, grad/param norm = 8.1642e-01, time/batch = 0.6348s	
79/11850 (epoch 0.333), train_loss = 3.34281088, grad/param norm = 7.9022e-01, time/batch = 0.6362s	
80/11850 (epoch 0.338), train_loss = 3.22365381, grad/param norm = 6.6773e-01, time/batch = 0.6372s	
81/11850 (epoch 0.342), train_loss = 3.40156083, grad/param norm = 5.9440e-01, time/batch = 0.6394s	
82/11850 (epoch 0.346), train_loss = 3.26821961, grad/param norm = 7.3032e-01, time/batch = 0.6355s	
83/11850 (epoch 0.350), train_loss = 3.15855265, grad/param norm = 7.2542e-01, time/batch = 0.6536s	
84/11850 (epoch 0.354), train_loss = 3.34789833, grad/param norm = 1.0994e+00, time/batch = 0.6655s	
85/11850 (epoch 0.359), train_loss = 3.30234517, grad/param norm = 9.2374e-01, time/batch = 0.6673s	
86/11850 (epoch 0.363), train_loss = 3.23042071, grad/param norm = 7.4341e-01, time/batch = 0.6816s	
87/11850 (epoch 0.367), train_loss = 3.25078200, grad/param norm = 6.0292e-01, time/batch = 0.6676s	
88/11850 (epoch 0.371), train_loss = 3.28088263, grad/param norm = 4.9618e-01, time/batch = 0.6648s	
89/11850 (epoch 0.376), train_loss = 3.31023929, grad/param norm = 4.4861e-01, time/batch = 0.6491s	
90/11850 (epoch 0.380), train_loss = 3.26536849, grad/param norm = 4.6731e-01, time/batch = 0.6587s	
91/11850 (epoch 0.384), train_loss = 3.29255656, grad/param norm = 5.1266e-01, time/batch = 0.6628s	
92/11850 (epoch 0.388), train_loss = 3.33368800, grad/param norm = 5.3885e-01, time/batch = 0.6703s	
93/11850 (epoch 0.392), train_loss = 3.30712712, grad/param norm = 5.4465e-01, time/batch = 0.6446s	
94/11850 (epoch 0.397), train_loss = 3.32701403, grad/param norm = 5.0479e-01, time/batch = 0.6458s	
95/11850 (epoch 0.401), train_loss = 3.22739025, grad/param norm = 4.9507e-01, time/batch = 0.6384s	
96/11850 (epoch 0.405), train_loss = 3.35137358, grad/param norm = 4.9403e-01, time/batch = 0.6381s	
97/11850 (epoch 0.409), train_loss = 3.37681452, grad/param norm = 4.8460e-01, time/batch = 0.6393s	
98/11850 (epoch 0.414), train_loss = 3.25409577, grad/param norm = 7.5636e-01, time/batch = 0.6394s	
99/11850 (epoch 0.418), train_loss = 3.31711456, grad/param norm = 6.9887e-01, time/batch = 0.6402s	
100/11850 (epoch 0.422), train_loss = 3.30443615, grad/param norm = 4.8001e-01, time/batch = 0.6389s	
101/11850 (epoch 0.426), train_loss = 3.36817890, grad/param norm = 8.5259e-01, time/batch = 0.6405s	
102/11850 (epoch 0.430), train_loss = 3.36801555, grad/param norm = 7.0067e-01, time/batch = 0.6454s	
103/11850 (epoch 0.435), train_loss = 3.26524816, grad/param norm = 4.5895e-01, time/batch = 0.6687s	
104/11850 (epoch 0.439), train_loss = 3.28090312, grad/param norm = 5.9689e-01, time/batch = 0.6441s	
105/11850 (epoch 0.443), train_loss = 3.33964685, grad/param norm = 6.1473e-01, time/batch = 0.6363s	
106/11850 (epoch 0.447), train_loss = 3.24565055, grad/param norm = 8.0799e-01, time/batch = 0.6366s	
107/11850 (epoch 0.451), train_loss = 3.19404513, grad/param norm = 6.6800e-01, time/batch = 0.6376s	
108/11850 (epoch 0.456), train_loss = 3.39596745, grad/param norm = 4.9274e-01, time/batch = 0.6362s	
109/11850 (epoch 0.460), train_loss = 3.35084327, grad/param norm = 4.1415e-01, time/batch = 0.6379s	
110/11850 (epoch 0.464), train_loss = 3.26915734, grad/param norm = 7.3220e-01, time/batch = 0.6400s	
111/11850 (epoch 0.468), train_loss = 3.36276119, grad/param norm = 1.0517e+00, time/batch = 0.6387s	
112/11850 (epoch 0.473), train_loss = 3.38882020, grad/param norm = 7.9942e-01, time/batch = 0.6462s	
113/11850 (epoch 0.477), train_loss = 3.22953430, grad/param norm = 4.5360e-01, time/batch = 0.6392s	
114/11850 (epoch 0.481), train_loss = 3.30598099, grad/param norm = 5.2119e-01, time/batch = 0.6368s	
115/11850 (epoch 0.485), train_loss = 3.16087263, grad/param norm = 6.3469e-01, time/batch = 0.6369s	
116/11850 (epoch 0.489), train_loss = 3.15218436, grad/param norm = 6.8603e-01, time/batch = 0.6355s	
117/11850 (epoch 0.494), train_loss = 3.26659471, grad/param norm = 4.4348e-01, time/batch = 0.6378s	
118/11850 (epoch 0.498), train_loss = 3.30789965, grad/param norm = 4.8119e-01, time/batch = 0.6381s	
119/11850 (epoch 0.502), train_loss = 3.28673447, grad/param norm = 6.6961e-01, time/batch = 0.6364s	
120/11850 (epoch 0.506), train_loss = 3.16729103, grad/param norm = 6.9562e-01, time/batch = 0.6352s	
121/11850 (epoch 0.511), train_loss = 3.09667884, grad/param norm = 8.5652e-01, time/batch = 0.6364s	
122/11850 (epoch 0.515), train_loss = 3.28493930, grad/param norm = 5.6757e-01, time/batch = 0.6379s	
123/11850 (epoch 0.519), train_loss = 3.10546189, grad/param norm = 4.3608e-01, time/batch = 0.6388s	
124/11850 (epoch 0.523), train_loss = 3.04130701, grad/param norm = 4.4182e-01, time/batch = 0.6395s	
125/11850 (epoch 0.527), train_loss = 3.23791494, grad/param norm = 5.4185e-01, time/batch = 0.6380s	
126/11850 (epoch 0.532), train_loss = 3.16380180, grad/param norm = 6.1235e-01, time/batch = 0.6381s	
127/11850 (epoch 0.536), train_loss = 3.15685665, grad/param norm = 7.9461e-01, time/batch = 0.6382s	
128/11850 (epoch 0.540), train_loss = 3.09168106, grad/param norm = 8.8495e-01, time/batch = 0.6391s	
129/11850 (epoch 0.544), train_loss = 3.15134514, grad/param norm = 9.4186e-01, time/batch = 0.6427s	
130/11850 (epoch 0.549), train_loss = 3.05871364, grad/param norm = 8.9994e-01, time/batch = 0.6392s	
131/11850 (epoch 0.553), train_loss = 3.10592182, grad/param norm = 6.6592e-01, time/batch = 0.6404s	
132/11850 (epoch 0.557), train_loss = 3.39562377, grad/param norm = 6.4084e-01, time/batch = 0.6380s	
133/11850 (epoch 0.561), train_loss = 3.15140615, grad/param norm = 7.3129e-01, time/batch = 0.6381s	
134/11850 (epoch 0.565), train_loss = 3.01978326, grad/param norm = 5.8511e-01, time/batch = 0.6381s	
135/11850 (epoch 0.570), train_loss = 3.00803172, grad/param norm = 5.7424e-01, time/batch = 0.6390s	
136/11850 (epoch 0.574), train_loss = 3.18970294, grad/param norm = 8.9200e-01, time/batch = 0.6384s	
137/11850 (epoch 0.578), train_loss = 3.14221691, grad/param norm = 8.1627e-01, time/batch = 0.6376s	
138/11850 (epoch 0.582), train_loss = 3.04184651, grad/param norm = 5.9512e-01, time/batch = 0.6447s	
139/11850 (epoch 0.586), train_loss = 3.05530970, grad/param norm = 5.2913e-01, time/batch = 0.6358s	
140/11850 (epoch 0.591), train_loss = 3.05561513, grad/param norm = 3.0692e-01, time/batch = 0.6352s	
141/11850 (epoch 0.595), train_loss = 3.00448604, grad/param norm = 3.5502e-01, time/batch = 0.6457s	
142/11850 (epoch 0.599), train_loss = 2.90949761, grad/param norm = 6.3307e-01, time/batch = 0.6360s	
143/11850 (epoch 0.603), train_loss = 3.12070291, grad/param norm = 1.0407e+00, time/batch = 0.6355s	
144/11850 (epoch 0.608), train_loss = 3.24244529, grad/param norm = 1.4177e+00, time/batch = 0.6359s	
145/11850 (epoch 0.612), train_loss = 3.11422694, grad/param norm = 1.2248e+00, time/batch = 0.6359s	
146/11850 (epoch 0.616), train_loss = 3.02678961, grad/param norm = 7.3381e-01, time/batch = 0.6367s	
147/11850 (epoch 0.620), train_loss = 2.93103957, grad/param norm = 7.6387e-01, time/batch = 0.6365s	
148/11850 (epoch 0.624), train_loss = 2.96846115, grad/param norm = 5.6813e-01, time/batch = 0.6381s	
149/11850 (epoch 0.629), train_loss = 3.12021329, grad/param norm = 6.5872e-01, time/batch = 0.6353s	
150/11850 (epoch 0.633), train_loss = 3.05050029, grad/param norm = 4.6871e-01, time/batch = 0.6386s	
151/11850 (epoch 0.637), train_loss = 3.07892316, grad/param norm = 4.4644e-01, time/batch = 0.6711s	
152/11850 (epoch 0.641), train_loss = 3.08056223, grad/param norm = 5.3245e-01, time/batch = 0.6521s	
153/11850 (epoch 0.646), train_loss = 2.97750780, grad/param norm = 6.3536e-01, time/batch = 0.6417s	
154/11850 (epoch 0.650), train_loss = 3.01067763, grad/param norm = 1.0026e+00, time/batch = 0.6491s	
155/11850 (epoch 0.654), train_loss = 3.06466684, grad/param norm = 1.1007e+00, time/batch = 0.6396s	
156/11850 (epoch 0.658), train_loss = 2.92868280, grad/param norm = 1.1046e+00, time/batch = 0.6383s	
157/11850 (epoch 0.662), train_loss = 2.93585337, grad/param norm = 7.5402e-01, time/batch = 0.6388s	
158/11850 (epoch 0.667), train_loss = 2.79765447, grad/param norm = 5.3052e-01, time/batch = 0.6407s	
159/11850 (epoch 0.671), train_loss = 2.88097750, grad/param norm = 4.7030e-01, time/batch = 0.6386s	
160/11850 (epoch 0.675), train_loss = 2.96367372, grad/param norm = 4.7486e-01, time/batch = 0.6477s	
161/11850 (epoch 0.679), train_loss = 2.94946741, grad/param norm = 5.8409e-01, time/batch = 0.6481s	
162/11850 (epoch 0.684), train_loss = 2.92672969, grad/param norm = 1.0507e+00, time/batch = 0.6701s	
163/11850 (epoch 0.688), train_loss = 2.88451484, grad/param norm = 1.0368e+00, time/batch = 0.6480s	
164/11850 (epoch 0.692), train_loss = 2.87981667, grad/param norm = 8.7349e-01, time/batch = 0.6395s	
165/11850 (epoch 0.696), train_loss = 3.02381097, grad/param norm = 7.6872e-01, time/batch = 0.6404s	
166/11850 (epoch 0.700), train_loss = 2.85747461, grad/param norm = 1.0444e+00, time/batch = 0.6387s	
167/11850 (epoch 0.705), train_loss = 2.93047154, grad/param norm = 1.0945e+00, time/batch = 0.6362s	
168/11850 (epoch 0.709), train_loss = 2.98433530, grad/param norm = 1.0006e+00, time/batch = 0.6351s	
169/11850 (epoch 0.713), train_loss = 2.93302661, grad/param norm = 6.7117e-01, time/batch = 0.6395s	
170/11850 (epoch 0.717), train_loss = 2.78230064, grad/param norm = 4.0299e-01, time/batch = 0.6363s	
171/11850 (epoch 0.722), train_loss = 2.99209231, grad/param norm = 5.6605e-01, time/batch = 0.6394s	
172/11850 (epoch 0.726), train_loss = 2.86299983, grad/param norm = 7.2552e-01, time/batch = 0.6495s	
173/11850 (epoch 0.730), train_loss = 2.83720633, grad/param norm = 8.2531e-01, time/batch = 0.6695s	
174/11850 (epoch 0.734), train_loss = 2.77476358, grad/param norm = 7.0017e-01, time/batch = 0.6429s	
175/11850 (epoch 0.738), train_loss = 2.81998451, grad/param norm = 7.0240e-01, time/batch = 0.6373s	
176/11850 (epoch 0.743), train_loss = 2.82964731, grad/param norm = 7.1797e-01, time/batch = 0.6597s	
177/11850 (epoch 0.747), train_loss = 2.84526150, grad/param norm = 1.1837e+00, time/batch = 0.6688s	
178/11850 (epoch 0.751), train_loss = 2.94779541, grad/param norm = 1.3405e+00, time/batch = 0.6652s	
179/11850 (epoch 0.755), train_loss = 2.88087384, grad/param norm = 9.0550e-01, time/batch = 0.6647s	
180/11850 (epoch 0.759), train_loss = 2.74577295, grad/param norm = 7.4669e-01, time/batch = 0.6604s	
181/11850 (epoch 0.764), train_loss = 2.79374325, grad/param norm = 5.2355e-01, time/batch = 0.6410s	
182/11850 (epoch 0.768), train_loss = 2.60362502, grad/param norm = 4.1551e-01, time/batch = 0.6455s	
183/11850 (epoch 0.772), train_loss = 2.87352940, grad/param norm = 4.8216e-01, time/batch = 0.6408s	
184/11850 (epoch 0.776), train_loss = 2.78816763, grad/param norm = 4.5950e-01, time/batch = 0.6387s	
185/11850 (epoch 0.781), train_loss = 2.71591403, grad/param norm = 3.9623e-01, time/batch = 0.6386s	
186/11850 (epoch 0.785), train_loss = 2.73837069, grad/param norm = 4.0851e-01, time/batch = 0.6359s	
187/11850 (epoch 0.789), train_loss = 3.01433633, grad/param norm = 7.2510e-01, time/batch = 0.6388s	
188/11850 (epoch 0.793), train_loss = 2.95284302, grad/param norm = 1.1805e+00, time/batch = 0.6396s	
189/11850 (epoch 0.797), train_loss = 2.87330845, grad/param norm = 1.4789e+00, time/batch = 0.6409s	
190/11850 (epoch 0.802), train_loss = 2.93962228, grad/param norm = 1.6307e+00, time/batch = 0.6427s	
191/11850 (epoch 0.806), train_loss = 2.89851017, grad/param norm = 1.3458e+00, time/batch = 0.6408s	
192/11850 (epoch 0.810), train_loss = 2.89576250, grad/param norm = 9.1229e-01, time/batch = 0.6396s	
193/11850 (epoch 0.814), train_loss = 2.79316187, grad/param norm = 8.4343e-01, time/batch = 0.6381s	
194/11850 (epoch 0.819), train_loss = 2.74378596, grad/param norm = 5.4121e-01, time/batch = 0.6377s	
195/11850 (epoch 0.823), train_loss = 2.84288405, grad/param norm = 5.4183e-01, time/batch = 0.6345s	
196/11850 (epoch 0.827), train_loss = 2.76310127, grad/param norm = 5.8690e-01, time/batch = 0.6379s	
197/11850 (epoch 0.831), train_loss = 2.72189622, grad/param norm = 6.2606e-01, time/batch = 0.6368s	
198/11850 (epoch 0.835), train_loss = 2.74005560, grad/param norm = 5.5638e-01, time/batch = 0.6384s	
199/11850 (epoch 0.840), train_loss = 2.74338179, grad/param norm = 4.8376e-01, time/batch = 0.6382s	
200/11850 (epoch 0.844), train_loss = 2.77546233, grad/param norm = 5.2896e-01, time/batch = 0.6363s	
201/11850 (epoch 0.848), train_loss = 2.87728813, grad/param norm = 5.5471e-01, time/batch = 0.6383s	
202/11850 (epoch 0.852), train_loss = 2.83814238, grad/param norm = 6.1206e-01, time/batch = 0.6358s	
203/11850 (epoch 0.857), train_loss = 2.80284823, grad/param norm = 5.0034e-01, time/batch = 0.6370s	
204/11850 (epoch 0.861), train_loss = 2.79758964, grad/param norm = 5.3069e-01, time/batch = 0.6369s	
205/11850 (epoch 0.865), train_loss = 2.86981787, grad/param norm = 7.8644e-01, time/batch = 0.6419s	
206/11850 (epoch 0.869), train_loss = 2.93859928, grad/param norm = 1.0879e+00, time/batch = 0.6370s	
207/11850 (epoch 0.873), train_loss = 2.96549363, grad/param norm = 8.8424e-01, time/batch = 0.6384s	
208/11850 (epoch 0.878), train_loss = 2.71223033, grad/param norm = 5.0175e-01, time/batch = 0.6402s	
209/11850 (epoch 0.882), train_loss = 2.70146763, grad/param norm = 5.8167e-01, time/batch = 0.6649s	
210/11850 (epoch 0.886), train_loss = 2.87943420, grad/param norm = 6.0676e-01, time/batch = 0.6579s	
211/11850 (epoch 0.890), train_loss = 2.78354575, grad/param norm = 6.6692e-01, time/batch = 0.6576s	
212/11850 (epoch 0.895), train_loss = 2.84964677, grad/param norm = 6.7295e-01, time/batch = 0.6471s	
213/11850 (epoch 0.899), train_loss = 2.83996487, grad/param norm = 7.3790e-01, time/batch = 0.6382s	
214/11850 (epoch 0.903), train_loss = 2.80495534, grad/param norm = 8.7784e-01, time/batch = 0.6372s	
215/11850 (epoch 0.907), train_loss = 2.66825275, grad/param norm = 8.7603e-01, time/batch = 0.6391s	
216/11850 (epoch 0.911), train_loss = 2.81334073, grad/param norm = 1.0439e+00, time/batch = 0.6363s	
217/11850 (epoch 0.916), train_loss = 2.88025301, grad/param norm = 6.3879e-01, time/batch = 0.6393s	
218/11850 (epoch 0.920), train_loss = 2.57870403, grad/param norm = 4.0495e-01, time/batch = 0.6430s	
219/11850 (epoch 0.924), train_loss = 2.68168026, grad/param norm = 4.6412e-01, time/batch = 0.6394s	
220/11850 (epoch 0.928), train_loss = 2.67791496, grad/param norm = 4.9608e-01, time/batch = 0.6388s	
221/11850 (epoch 0.932), train_loss = 2.78952113, grad/param norm = 8.0842e-01, time/batch = 0.6407s	
222/11850 (epoch 0.937), train_loss = 2.79919397, grad/param norm = 6.9135e-01, time/batch = 0.6387s	
223/11850 (epoch 0.941), train_loss = 2.72082970, grad/param norm = 3.7388e-01, time/batch = 0.6363s	
224/11850 (epoch 0.945), train_loss = 2.84017425, grad/param norm = 1.0536e+00, time/batch = 0.6365s	
225/11850 (epoch 0.949), train_loss = 2.96646524, grad/param norm = 1.6428e+00, time/batch = 0.6373s	
226/11850 (epoch 0.954), train_loss = 2.92010106, grad/param norm = 1.0912e+00, time/batch = 0.6351s	
227/11850 (epoch 0.958), train_loss = 2.81879644, grad/param norm = 4.5189e-01, time/batch = 0.6356s	
228/11850 (epoch 0.962), train_loss = 2.76639239, grad/param norm = 4.6301e-01, time/batch = 0.6367s	
229/11850 (epoch 0.966), train_loss = 2.78501341, grad/param norm = 3.8406e-01, time/batch = 0.6388s	
230/11850 (epoch 0.970), train_loss = 2.64348513, grad/param norm = 5.2254e-01, time/batch = 0.6527s	
231/11850 (epoch 0.975), train_loss = 2.84448109, grad/param norm = 8.3467e-01, time/batch = 0.6436s	
232/11850 (epoch 0.979), train_loss = 2.87759373, grad/param norm = 6.7342e-01, time/batch = 0.6358s	
233/11850 (epoch 0.983), train_loss = 3.30499195, grad/param norm = 1.0493e+00, time/batch = 0.6278s	
234/11850 (epoch 0.987), train_loss = 3.04745090, grad/param norm = 3.2944e+00, time/batch = 0.6315s	
235/11850 (epoch 0.992), train_loss = 2.68051871, grad/param norm = 6.8799e-01, time/batch = 0.6242s	
236/11850 (epoch 0.996), train_loss = 2.94364360, grad/param norm = 4.3116e-01, time/batch = 0.6240s	
237/11850 (epoch 1.000), train_loss = 2.82153976, grad/param norm = 4.7479e-01, time/batch = 0.6238s	
238/11850 (epoch 1.004), train_loss = 2.73787332, grad/param norm = 5.5358e-01, time/batch = 0.6224s	
239/11850 (epoch 1.008), train_loss = 2.61161040, grad/param norm = 2.9354e-01, time/batch = 0.6246s	
240/11850 (epoch 1.013), train_loss = 2.69973125, grad/param norm = 3.4593e-01, time/batch = 0.6269s	
241/11850 (epoch 1.017), train_loss = 2.80676247, grad/param norm = 4.0494e-01, time/batch = 0.6305s	
242/11850 (epoch 1.021), train_loss = 2.63658605, grad/param norm = 4.7855e-01, time/batch = 0.6388s	
243/11850 (epoch 1.025), train_loss = 2.45915866, grad/param norm = 3.4464e-01, time/batch = 0.6568s	
244/11850 (epoch 1.030), train_loss = 2.56721326, grad/param norm = 3.6173e-01, time/batch = 0.6328s	
245/11850 (epoch 1.034), train_loss = 2.58152957, grad/param norm = 4.9469e-01, time/batch = 0.6245s	
246/11850 (epoch 1.038), train_loss = 2.65947044, grad/param norm = 6.6345e-01, time/batch = 0.6232s	
247/11850 (epoch 1.042), train_loss = 2.71074675, grad/param norm = 6.2698e-01, time/batch = 0.6244s	
248/11850 (epoch 1.046), train_loss = 2.78379316, grad/param norm = 5.6444e-01, time/batch = 0.6215s	
249/11850 (epoch 1.051), train_loss = 2.63116848, grad/param norm = 4.4407e-01, time/batch = 0.6224s	
250/11850 (epoch 1.055), train_loss = 2.77078508, grad/param norm = 3.2469e-01, time/batch = 0.6236s	
251/11850 (epoch 1.059), train_loss = 2.76827978, grad/param norm = 4.9963e-01, time/batch = 0.6271s	
252/11850 (epoch 1.063), train_loss = 2.67699155, grad/param norm = 6.8621e-01, time/batch = 0.6272s	
253/11850 (epoch 1.068), train_loss = 2.75354875, grad/param norm = 9.4154e-01, time/batch = 0.6355s	
254/11850 (epoch 1.072), train_loss = 2.68622564, grad/param norm = 1.0946e+00, time/batch = 0.6563s	
255/11850 (epoch 1.076), train_loss = 2.67234380, grad/param norm = 7.8280e-01, time/batch = 0.6319s	
256/11850 (epoch 1.080), train_loss = 2.81922692, grad/param norm = 6.0888e-01, time/batch = 0.6289s	
257/11850 (epoch 1.084), train_loss = 2.68340341, grad/param norm = 5.7819e-01, time/batch = 0.6259s	
258/11850 (epoch 1.089), train_loss = 2.63667258, grad/param norm = 3.7747e-01, time/batch = 0.6237s	
259/11850 (epoch 1.093), train_loss = 2.62736028, grad/param norm = 3.3347e-01, time/batch = 0.6243s	
260/11850 (epoch 1.097), train_loss = 2.81626599, grad/param norm = 4.0056e-01, time/batch = 0.6258s	
261/11850 (epoch 1.101), train_loss = 2.82659735, grad/param norm = 3.5111e-01, time/batch = 0.6286s	
262/11850 (epoch 1.105), train_loss = 2.60824642, grad/param norm = 3.5341e-01, time/batch = 0.6265s	
263/11850 (epoch 1.110), train_loss = 2.56723881, grad/param norm = 4.0461e-01, time/batch = 0.6255s	
264/11850 (epoch 1.114), train_loss = 2.77298028, grad/param norm = 7.5383e-01, time/batch = 0.6216s	
265/11850 (epoch 1.118), train_loss = 2.61951173, grad/param norm = 1.2188e+00, time/batch = 0.6242s	
266/11850 (epoch 1.122), train_loss = 2.69411065, grad/param norm = 1.2763e+00, time/batch = 0.6255s	
267/11850 (epoch 1.127), train_loss = 2.80171568, grad/param norm = 1.0517e+00, time/batch = 0.6251s	
268/11850 (epoch 1.131), train_loss = 2.82591418, grad/param norm = 8.0007e-01, time/batch = 0.6233s	
269/11850 (epoch 1.135), train_loss = 2.71620092, grad/param norm = 4.7956e-01, time/batch = 0.6318s	
270/11850 (epoch 1.139), train_loss = 2.76516948, grad/param norm = 3.1089e-01, time/batch = 0.6557s	
271/11850 (epoch 1.143), train_loss = 2.74175646, grad/param norm = 3.7964e-01, time/batch = 0.6592s	
272/11850 (epoch 1.148), train_loss = 2.70886146, grad/param norm = 5.0329e-01, time/batch = 0.6410s	
273/11850 (epoch 1.152), train_loss = 2.63479955, grad/param norm = 7.4081e-01, time/batch = 0.6314s	
274/11850 (epoch 1.156), train_loss = 2.77988059, grad/param norm = 9.6936e-01, time/batch = 0.6296s	
275/11850 (epoch 1.160), train_loss = 2.92023547, grad/param norm = 4.4556e-01, time/batch = 0.6292s	
276/11850 (epoch 1.165), train_loss = 2.74873854, grad/param norm = 3.5703e-01, time/batch = 0.6269s	
277/11850 (epoch 1.169), train_loss = 2.61106120, grad/param norm = 5.2292e-01, time/batch = 0.6285s	
278/11850 (epoch 1.173), train_loss = 2.64559865, grad/param norm = 5.6568e-01, time/batch = 0.6246s	
279/11850 (epoch 1.177), train_loss = 2.72994818, grad/param norm = 6.4782e-01, time/batch = 0.6234s	
280/11850 (epoch 1.181), train_loss = 2.63277544, grad/param norm = 7.2621e-01, time/batch = 0.6223s	
281/11850 (epoch 1.186), train_loss = 2.74095505, grad/param norm = 5.7805e-01, time/batch = 0.6254s	
282/11850 (epoch 1.190), train_loss = 2.67036067, grad/param norm = 4.7006e-01, time/batch = 0.6263s	
283/11850 (epoch 1.194), train_loss = 2.85230087, grad/param norm = 4.5771e-01, time/batch = 0.6279s	
284/11850 (epoch 1.198), train_loss = 2.61030459, grad/param norm = 5.5532e-01, time/batch = 0.6264s	
285/11850 (epoch 1.203), train_loss = 2.51240935, grad/param norm = 4.1327e-01, time/batch = 0.6283s	
286/11850 (epoch 1.207), train_loss = 2.76290970, grad/param norm = 4.0321e-01, time/batch = 0.6244s	
287/11850 (epoch 1.211), train_loss = 2.74179748, grad/param norm = 4.0751e-01, time/batch = 0.6272s	
288/11850 (epoch 1.215), train_loss = 2.74721431, grad/param norm = 4.1203e-01, time/batch = 0.6301s	
289/11850 (epoch 1.219), train_loss = 2.50680544, grad/param norm = 4.1267e-01, time/batch = 0.6255s	
290/11850 (epoch 1.224), train_loss = 2.71656126, grad/param norm = 5.0516e-01, time/batch = 0.6243s	
291/11850 (epoch 1.228), train_loss = 2.70367770, grad/param norm = 4.7091e-01, time/batch = 0.6224s	
292/11850 (epoch 1.232), train_loss = 2.64383390, grad/param norm = 5.8239e-01, time/batch = 0.6248s	
293/11850 (epoch 1.236), train_loss = 2.66502490, grad/param norm = 6.4157e-01, time/batch = 0.6219s	
294/11850 (epoch 1.241), train_loss = 2.62279594, grad/param norm = 5.6603e-01, time/batch = 0.6260s	
295/11850 (epoch 1.245), train_loss = 2.60196846, grad/param norm = 4.3106e-01, time/batch = 0.6252s	
296/11850 (epoch 1.249), train_loss = 2.54465317, grad/param norm = 5.6582e-01, time/batch = 0.6239s	
297/11850 (epoch 1.253), train_loss = 2.69699801, grad/param norm = 5.5524e-01, time/batch = 0.6244s	
298/11850 (epoch 1.257), train_loss = 2.65544990, grad/param norm = 5.4825e-01, time/batch = 0.6236s	
299/11850 (epoch 1.262), train_loss = 2.81369312, grad/param norm = 7.0035e-01, time/batch = 0.6222s	
300/11850 (epoch 1.266), train_loss = 2.99028590, grad/param norm = 3.2484e+00, time/batch = 0.6237s	
301/11850 (epoch 1.270), train_loss = 2.64723271, grad/param norm = 6.3258e-01, time/batch = 0.6266s	
302/11850 (epoch 1.274), train_loss = 2.69570086, grad/param norm = 4.9620e-01, time/batch = 0.6315s	
303/11850 (epoch 1.278), train_loss = 2.63968453, grad/param norm = 6.4065e-01, time/batch = 0.6576s	
304/11850 (epoch 1.283), train_loss = 2.62021343, grad/param norm = 8.3426e-01, time/batch = 0.6562s	
305/11850 (epoch 1.287), train_loss = 2.65360340, grad/param norm = 1.0478e+00, time/batch = 0.6454s	
306/11850 (epoch 1.291), train_loss = 2.78848475, grad/param norm = 8.9348e-01, time/batch = 0.6365s	
307/11850 (epoch 1.295), train_loss = 2.69427822, grad/param norm = 6.3437e-01, time/batch = 0.6395s	
308/11850 (epoch 1.300), train_loss = 2.53158845, grad/param norm = 5.9447e-01, time/batch = 0.6438s	
309/11850 (epoch 1.304), train_loss = 2.56797734, grad/param norm = 3.1934e-01, time/batch = 0.6331s	
310/11850 (epoch 1.308), train_loss = 2.49174189, grad/param norm = 3.3668e-01, time/batch = 0.6335s	
311/11850 (epoch 1.312), train_loss = 2.54048266, grad/param norm = 2.8018e-01, time/batch = 0.6345s	
312/11850 (epoch 1.316), train_loss = 2.55338008, grad/param norm = 3.7137e-01, time/batch = 0.6354s	
313/11850 (epoch 1.321), train_loss = 2.54764550, grad/param norm = 4.3421e-01, time/batch = 0.6441s	
314/11850 (epoch 1.325), train_loss = 2.70780770, grad/param norm = 4.7587e-01, time/batch = 0.6576s	
315/11850 (epoch 1.329), train_loss = 2.59508271, grad/param norm = 4.7797e-01, time/batch = 0.6416s	
316/11850 (epoch 1.333), train_loss = 2.57030174, grad/param norm = 4.4464e-01, time/batch = 0.6364s	
317/11850 (epoch 1.338), train_loss = 2.48214247, grad/param norm = 3.4274e-01, time/batch = 0.6379s	
318/11850 (epoch 1.342), train_loss = 2.70798261, grad/param norm = 4.3574e-01, time/batch = 0.6422s	
319/11850 (epoch 1.346), train_loss = 2.64083998, grad/param norm = 5.5529e-01, time/batch = 0.6436s	
320/11850 (epoch 1.350), train_loss = 2.47487254, grad/param norm = 6.8535e-01, time/batch = 0.6297s	
321/11850 (epoch 1.354), train_loss = 2.77589609, grad/param norm = 1.1368e+00, time/batch = 0.6268s	
322/11850 (epoch 1.359), train_loss = 2.67205715, grad/param norm = 9.2489e-01, time/batch = 0.6266s	
323/11850 (epoch 1.363), train_loss = 2.55237920, grad/param norm = 7.4933e-01, time/batch = 0.6251s	
324/11850 (epoch 1.367), train_loss = 2.63728692, grad/param norm = 6.4386e-01, time/batch = 0.6422s	
325/11850 (epoch 1.371), train_loss = 2.59941394, grad/param norm = 5.2162e-01, time/batch = 0.6585s	
326/11850 (epoch 1.376), train_loss = 2.59026168, grad/param norm = 4.6168e-01, time/batch = 0.6331s	
327/11850 (epoch 1.380), train_loss = 2.53349447, grad/param norm = 4.2533e-01, time/batch = 0.6330s	
328/11850 (epoch 1.384), train_loss = 2.61856225, grad/param norm = 3.2050e-01, time/batch = 0.6238s	
329/11850 (epoch 1.388), train_loss = 2.50519852, grad/param norm = 3.8204e-01, time/batch = 0.6318s	
330/11850 (epoch 1.392), train_loss = 2.62111930, grad/param norm = 3.8097e-01, time/batch = 0.6271s	
331/11850 (epoch 1.397), train_loss = 2.68057749, grad/param norm = 4.0809e-01, time/batch = 0.6298s	
332/11850 (epoch 1.401), train_loss = 2.44167303, grad/param norm = 3.4067e-01, time/batch = 0.6527s	
333/11850 (epoch 1.405), train_loss = 2.65212158, grad/param norm = 3.7795e-01, time/batch = 0.6355s	
334/11850 (epoch 1.409), train_loss = 2.64808117, grad/param norm = 4.3001e-01, time/batch = 0.6405s	
335/11850 (epoch 1.414), train_loss = 2.47237340, grad/param norm = 5.1368e-01, time/batch = 0.6445s	
336/11850 (epoch 1.418), train_loss = 2.48743010, grad/param norm = 6.7217e-01, time/batch = 0.6293s	
337/11850 (epoch 1.422), train_loss = 2.55262288, grad/param norm = 8.1702e-01, time/batch = 0.6282s	
338/11850 (epoch 1.426), train_loss = 2.71417419, grad/param norm = 9.7607e-01, time/batch = 0.6243s	
339/11850 (epoch 1.430), train_loss = 2.63337020, grad/param norm = 7.6794e-01, time/batch = 0.6214s	
340/11850 (epoch 1.435), train_loss = 2.49871841, grad/param norm = 3.7442e-01, time/batch = 0.6227s	
341/11850 (epoch 1.439), train_loss = 2.63325247, grad/param norm = 3.6818e-01, time/batch = 0.6232s	
342/11850 (epoch 1.443), train_loss = 2.63228387, grad/param norm = 5.4525e-01, time/batch = 0.6223s	
343/11850 (epoch 1.447), train_loss = 2.56541424, grad/param norm = 7.3564e-01, time/batch = 0.6260s	
344/11850 (epoch 1.451), train_loss = 2.51742308, grad/param norm = 6.7340e-01, time/batch = 0.6214s	
345/11850 (epoch 1.456), train_loss = 2.78377154, grad/param norm = 6.0569e-01, time/batch = 0.6280s	
346/11850 (epoch 1.460), train_loss = 2.69963466, grad/param norm = 4.6500e-01, time/batch = 0.6393s	
347/11850 (epoch 1.464), train_loss = 2.55196885, grad/param norm = 4.9030e-01, time/batch = 0.6579s	
348/11850 (epoch 1.468), train_loss = 2.71675244, grad/param norm = 6.8621e-01, time/batch = 0.6307s	
349/11850 (epoch 1.473), train_loss = 2.64232314, grad/param norm = 9.8956e-01, time/batch = 0.6238s	
350/11850 (epoch 1.477), train_loss = 2.52498885, grad/param norm = 5.4619e-01, time/batch = 0.6254s	
351/11850 (epoch 1.481), train_loss = 2.59982433, grad/param norm = 3.8542e-01, time/batch = 0.6325s	
352/11850 (epoch 1.485), train_loss = 2.40500072, grad/param norm = 4.3034e-01, time/batch = 0.6224s	
353/11850 (epoch 1.489), train_loss = 2.54103872, grad/param norm = 5.2341e-01, time/batch = 0.6249s	
354/11850 (epoch 1.494), train_loss = 2.63492568, grad/param norm = 3.7643e-01, time/batch = 0.6235s	
355/11850 (epoch 1.498), train_loss = 2.67671976, grad/param norm = 4.6430e-01, time/batch = 0.6253s	
356/11850 (epoch 1.502), train_loss = 2.60643377, grad/param norm = 6.2472e-01, time/batch = 0.6384s	
357/11850 (epoch 1.506), train_loss = 2.59749861, grad/param norm = 7.5001e-01, time/batch = 0.6364s	
358/11850 (epoch 1.511), train_loss = 2.55884673, grad/param norm = 1.1431e+00, time/batch = 0.6264s	
359/11850 (epoch 1.515), train_loss = 2.72175339, grad/param norm = 8.9236e-01, time/batch = 0.6251s	
360/11850 (epoch 1.519), train_loss = 2.52805242, grad/param norm = 7.5526e-01, time/batch = 0.6268s	
361/11850 (epoch 1.523), train_loss = 2.48348547, grad/param norm = 4.3594e-01, time/batch = 0.6294s	
362/11850 (epoch 1.527), train_loss = 2.51919377, grad/param norm = 3.3599e-01, time/batch = 0.6295s	
363/11850 (epoch 1.532), train_loss = 2.63170419, grad/param norm = 4.8544e-01, time/batch = 0.6311s	
364/11850 (epoch 1.536), train_loss = 2.57719241, grad/param norm = 4.8646e-01, time/batch = 0.6469s	
365/11850 (epoch 1.540), train_loss = 2.46103814, grad/param norm = 3.9778e-01, time/batch = 0.6536s	
366/11850 (epoch 1.544), train_loss = 2.56578912, grad/param norm = 3.4020e-01, time/batch = 0.6554s	
367/11850 (epoch 1.549), train_loss = 2.33211944, grad/param norm = 4.4286e-01, time/batch = 0.6545s	
368/11850 (epoch 1.553), train_loss = 2.49383627, grad/param norm = 4.8071e-01, time/batch = 0.6416s	
369/11850 (epoch 1.557), train_loss = 2.80511834, grad/param norm = 4.7359e-01, time/batch = 0.6346s	
370/11850 (epoch 1.561), train_loss = 2.49075354, grad/param norm = 4.9133e-01, time/batch = 0.6265s	
371/11850 (epoch 1.565), train_loss = 2.50491815, grad/param norm = 5.0467e-01, time/batch = 0.6359s	
372/11850 (epoch 1.570), train_loss = 2.40827909, grad/param norm = 4.7393e-01, time/batch = 0.6476s	
373/11850 (epoch 1.574), train_loss = 2.53583108, grad/param norm = 4.5212e-01, time/batch = 0.6472s	
374/11850 (epoch 1.578), train_loss = 2.60974064, grad/param norm = 6.4647e-01, time/batch = 0.6348s	
375/11850 (epoch 1.582), train_loss = 2.50340655, grad/param norm = 6.3053e-01, time/batch = 0.6236s	
376/11850 (epoch 1.586), train_loss = 2.55898005, grad/param norm = 6.0403e-01, time/batch = 0.6264s	
377/11850 (epoch 1.591), train_loss = 2.58969210, grad/param norm = 4.6125e-01, time/batch = 0.6264s	
378/11850 (epoch 1.595), train_loss = 2.47349995, grad/param norm = 4.1991e-01, time/batch = 0.6272s	
379/11850 (epoch 1.599), train_loss = 2.34564527, grad/param norm = 5.1559e-01, time/batch = 0.6280s	
380/11850 (epoch 1.603), train_loss = 2.52110989, grad/param norm = 4.6147e-01, time/batch = 0.6291s	
381/11850 (epoch 1.608), train_loss = 2.60734354, grad/param norm = 5.6367e-01, time/batch = 0.6354s	
382/11850 (epoch 1.612), train_loss = 2.56120696, grad/param norm = 5.5545e-01, time/batch = 0.6270s	
383/11850 (epoch 1.616), train_loss = 2.51630037, grad/param norm = 7.0050e-01, time/batch = 0.6272s	
384/11850 (epoch 1.620), train_loss = 2.45136966, grad/param norm = 7.2084e-01, time/batch = 0.6257s	
385/11850 (epoch 1.624), train_loss = 2.52995062, grad/param norm = 5.2933e-01, time/batch = 0.6296s	
386/11850 (epoch 1.629), train_loss = 2.63790535, grad/param norm = 4.2909e-01, time/batch = 0.6266s	
387/11850 (epoch 1.633), train_loss = 2.51363325, grad/param norm = 4.5730e-01, time/batch = 0.6278s	
388/11850 (epoch 1.637), train_loss = 2.50312928, grad/param norm = 3.8320e-01, time/batch = 0.6304s	
389/11850 (epoch 1.641), train_loss = 2.54141913, grad/param norm = 4.3223e-01, time/batch = 0.6327s	
390/11850 (epoch 1.646), train_loss = 2.48754500, grad/param norm = 4.3369e-01, time/batch = 0.6436s	
391/11850 (epoch 1.650), train_loss = 2.47595331, grad/param norm = 5.1165e-01, time/batch = 0.6482s	
392/11850 (epoch 1.654), train_loss = 2.61125515, grad/param norm = 7.2179e-01, time/batch = 0.6273s	
393/11850 (epoch 1.658), train_loss = 2.49056004, grad/param norm = 8.2434e-01, time/batch = 0.6295s	
394/11850 (epoch 1.662), train_loss = 2.47686299, grad/param norm = 6.4191e-01, time/batch = 0.6282s	
395/11850 (epoch 1.667), train_loss = 2.34807462, grad/param norm = 4.0787e-01, time/batch = 0.6248s	
396/11850 (epoch 1.671), train_loss = 2.36276648, grad/param norm = 3.2680e-01, time/batch = 0.6239s	
397/11850 (epoch 1.675), train_loss = 2.54617227, grad/param norm = 3.4482e-01, time/batch = 0.6243s	
398/11850 (epoch 1.679), train_loss = 2.54097034, grad/param norm = 3.1024e-01, time/batch = 0.6270s	
399/11850 (epoch 1.684), train_loss = 2.47488843, grad/param norm = 4.3676e-01, time/batch = 0.6261s	
400/11850 (epoch 1.688), train_loss = 2.43073017, grad/param norm = 3.3268e-01, time/batch = 0.6283s	
401/11850 (epoch 1.692), train_loss = 2.46051956, grad/param norm = 4.3348e-01, time/batch = 0.6270s	
402/11850 (epoch 1.696), train_loss = 2.56358496, grad/param norm = 4.6440e-01, time/batch = 0.6225s	
403/11850 (epoch 1.700), train_loss = 2.43774890, grad/param norm = 5.6956e-01, time/batch = 0.6239s	
404/11850 (epoch 1.705), train_loss = 2.50952960, grad/param norm = 5.7786e-01, time/batch = 0.6249s	
405/11850 (epoch 1.709), train_loss = 2.52260132, grad/param norm = 5.9305e-01, time/batch = 0.6247s	
406/11850 (epoch 1.713), train_loss = 2.51290783, grad/param norm = 4.9110e-01, time/batch = 0.6445s	
407/11850 (epoch 1.717), train_loss = 2.35461770, grad/param norm = 4.4264e-01, time/batch = 0.6578s	
408/11850 (epoch 1.722), train_loss = 2.65205758, grad/param norm = 4.6104e-01, time/batch = 0.6259s	
409/11850 (epoch 1.726), train_loss = 2.42870492, grad/param norm = 4.3913e-01, time/batch = 0.6263s	
410/11850 (epoch 1.730), train_loss = 2.39916431, grad/param norm = 5.7638e-01, time/batch = 0.6278s	
411/11850 (epoch 1.734), train_loss = 2.37394576, grad/param norm = 3.8106e-01, time/batch = 0.6261s	
412/11850 (epoch 1.738), train_loss = 2.44284183, grad/param norm = 4.3746e-01, time/batch = 0.6250s	
413/11850 (epoch 1.743), train_loss = 2.48042725, grad/param norm = 4.9114e-01, time/batch = 0.6262s	
414/11850 (epoch 1.747), train_loss = 2.49698002, grad/param norm = 8.5338e-01, time/batch = 0.6272s	
415/11850 (epoch 1.751), train_loss = 2.51439119, grad/param norm = 9.2822e-01, time/batch = 0.6200s	
416/11850 (epoch 1.755), train_loss = 2.51706610, grad/param norm = 5.2805e-01, time/batch = 0.6208s	
417/11850 (epoch 1.759), train_loss = 2.38843560, grad/param norm = 3.9797e-01, time/batch = 0.6402s	
418/11850 (epoch 1.764), train_loss = 2.41707427, grad/param norm = 3.3928e-01, time/batch = 0.6481s	
419/11850 (epoch 1.768), train_loss = 2.21152487, grad/param norm = 2.9523e-01, time/batch = 0.6214s	
420/11850 (epoch 1.772), train_loss = 2.45268462, grad/param norm = 3.9275e-01, time/batch = 0.6276s	
421/11850 (epoch 1.776), train_loss = 2.41947691, grad/param norm = 3.7286e-01, time/batch = 0.6244s	
422/11850 (epoch 1.781), train_loss = 2.33464743, grad/param norm = 3.4565e-01, time/batch = 0.6249s	
423/11850 (epoch 1.785), train_loss = 2.39843901, grad/param norm = 3.7787e-01, time/batch = 0.6241s	
424/11850 (epoch 1.789), train_loss = 2.62306224, grad/param norm = 4.6775e-01, time/batch = 0.6315s	
425/11850 (epoch 1.793), train_loss = 2.57901069, grad/param norm = 3.8566e-01, time/batch = 0.6287s	
426/11850 (epoch 1.797), train_loss = 2.47072740, grad/param norm = 4.3658e-01, time/batch = 0.6277s	
427/11850 (epoch 1.802), train_loss = 2.50967564, grad/param norm = 6.0403e-01, time/batch = 0.6264s	
428/11850 (epoch 1.806), train_loss = 2.46893301, grad/param norm = 6.8078e-01, time/batch = 0.6404s	
429/11850 (epoch 1.810), train_loss = 2.54509073, grad/param norm = 6.8539e-01, time/batch = 0.6579s	
430/11850 (epoch 1.814), train_loss = 2.45108275, grad/param norm = 7.2898e-01, time/batch = 0.6357s	
431/11850 (epoch 1.819), train_loss = 2.45537452, grad/param norm = 5.2171e-01, time/batch = 0.6246s	
432/11850 (epoch 1.823), train_loss = 2.48399514, grad/param norm = 5.5045e-01, time/batch = 0.6295s	
433/11850 (epoch 1.827), train_loss = 2.45521527, grad/param norm = 5.4914e-01, time/batch = 0.6244s	
434/11850 (epoch 1.831), train_loss = 2.39114350, grad/param norm = 5.9203e-01, time/batch = 0.6247s	
435/11850 (epoch 1.835), train_loss = 2.42248223, grad/param norm = 5.9169e-01, time/batch = 0.6220s	
436/11850 (epoch 1.840), train_loss = 2.39910564, grad/param norm = 4.7380e-01, time/batch = 0.6265s	
437/11850 (epoch 1.844), train_loss = 2.45790861, grad/param norm = 3.5718e-01, time/batch = 0.6252s	
438/11850 (epoch 1.848), train_loss = 2.58183849, grad/param norm = 3.8532e-01, time/batch = 0.6216s	
439/11850 (epoch 1.852), train_loss = 2.51743046, grad/param norm = 4.7458e-01, time/batch = 0.6350s	
440/11850 (epoch 1.857), train_loss = 2.45292382, grad/param norm = 4.0043e-01, time/batch = 0.6577s	
441/11850 (epoch 1.861), train_loss = 2.47235866, grad/param norm = 3.1111e-01, time/batch = 0.6345s	
442/11850 (epoch 1.865), train_loss = 2.55131785, grad/param norm = 3.7341e-01, time/batch = 0.6297s	
443/11850 (epoch 1.869), train_loss = 2.62652758, grad/param norm = 3.6769e-01, time/batch = 0.6278s	
444/11850 (epoch 1.873), train_loss = 2.56903743, grad/param norm = 3.8624e-01, time/batch = 0.6380s	
445/11850 (epoch 1.878), train_loss = 2.40885047, grad/param norm = 3.1305e-01, time/batch = 0.6319s	
446/11850 (epoch 1.882), train_loss = 2.38617457, grad/param norm = 3.3065e-01, time/batch = 0.6295s	
447/11850 (epoch 1.886), train_loss = 2.48531668, grad/param norm = 3.9907e-01, time/batch = 0.6265s	
448/11850 (epoch 1.890), train_loss = 2.44267047, grad/param norm = 3.9051e-01, time/batch = 0.6298s	
449/11850 (epoch 1.895), train_loss = 2.48971454, grad/param norm = 4.4753e-01, time/batch = 0.6277s	
450/11850 (epoch 1.899), train_loss = 2.51761068, grad/param norm = 6.1520e-01, time/batch = 0.6379s	
451/11850 (epoch 1.903), train_loss = 2.48877342, grad/param norm = 6.4831e-01, time/batch = 0.6594s	
452/11850 (epoch 1.907), train_loss = 2.35869431, grad/param norm = 6.1642e-01, time/batch = 0.6334s	
453/11850 (epoch 1.911), train_loss = 2.43321677, grad/param norm = 6.2889e-01, time/batch = 0.6279s	
454/11850 (epoch 1.916), train_loss = 2.59266243, grad/param norm = 5.1409e-01, time/batch = 0.6252s	
455/11850 (epoch 1.920), train_loss = 2.27929695, grad/param norm = 4.3291e-01, time/batch = 0.6278s	
456/11850 (epoch 1.924), train_loss = 2.36021323, grad/param norm = 4.2059e-01, time/batch = 0.6303s	
457/11850 (epoch 1.928), train_loss = 2.45167570, grad/param norm = 3.1080e-01, time/batch = 0.6281s	
458/11850 (epoch 1.932), train_loss = 2.51490080, grad/param norm = 5.5425e-01, time/batch = 0.6446s	
459/11850 (epoch 1.937), train_loss = 2.55446143, grad/param norm = 5.8354e-01, time/batch = 0.6542s	
460/11850 (epoch 1.941), train_loss = 2.47368188, grad/param norm = 4.8682e-01, time/batch = 0.6596s	
461/11850 (epoch 1.945), train_loss = 2.51571803, grad/param norm = 3.9024e-01, time/batch = 0.6780s	
462/11850 (epoch 1.949), train_loss = 2.50411464, grad/param norm = 4.7788e-01, time/batch = 0.6692s	
463/11850 (epoch 1.954), train_loss = 2.58651030, grad/param norm = 3.7702e-01, time/batch = 0.6335s	
464/11850 (epoch 1.958), train_loss = 2.43708007, grad/param norm = 3.3304e-01, time/batch = 0.6420s	
465/11850 (epoch 1.962), train_loss = 2.50191426, grad/param norm = 4.6931e-01, time/batch = 0.6347s	
466/11850 (epoch 1.966), train_loss = 2.52186258, grad/param norm = 6.4364e-01, time/batch = 0.6312s	
467/11850 (epoch 1.970), train_loss = 2.44191923, grad/param norm = 6.3200e-01, time/batch = 0.6391s	
468/11850 (epoch 1.975), train_loss = 2.53313696, grad/param norm = 4.2597e-01, time/batch = 0.6399s	
469/11850 (epoch 1.979), train_loss = 2.65978076, grad/param norm = 5.1844e-01, time/batch = 0.6250s	
470/11850 (epoch 1.983), train_loss = 3.00262523, grad/param norm = 7.5857e-01, time/batch = 0.6243s	
471/11850 (epoch 1.987), train_loss = 2.57011408, grad/param norm = 4.8915e-01, time/batch = 0.6272s	
472/11850 (epoch 1.992), train_loss = 2.43591964, grad/param norm = 4.2770e-01, time/batch = 0.6458s	
473/11850 (epoch 1.996), train_loss = 2.66748782, grad/param norm = 3.5369e-01, time/batch = 0.6555s	
474/11850 (epoch 2.000), train_loss = 2.54722807, grad/param norm = 3.2758e-01, time/batch = 0.6348s	
475/11850 (epoch 2.004), train_loss = 2.41624336, grad/param norm = 3.5687e-01, time/batch = 0.6299s	
476/11850 (epoch 2.008), train_loss = 2.36647655, grad/param norm = 2.9042e-01, time/batch = 0.6264s	
477/11850 (epoch 2.013), train_loss = 2.40393102, grad/param norm = 2.9567e-01, time/batch = 0.6302s	
478/11850 (epoch 2.017), train_loss = 2.56344902, grad/param norm = 3.3952e-01, time/batch = 0.6265s	
479/11850 (epoch 2.021), train_loss = 2.35980541, grad/param norm = 3.1796e-01, time/batch = 0.6254s	
480/11850 (epoch 2.025), train_loss = 2.14467834, grad/param norm = 2.7653e-01, time/batch = 0.6263s	
481/11850 (epoch 2.030), train_loss = 2.27928449, grad/param norm = 3.6549e-01, time/batch = 0.6259s	
482/11850 (epoch 2.034), train_loss = 2.30878508, grad/param norm = 3.5755e-01, time/batch = 0.6274s	
483/11850 (epoch 2.038), train_loss = 2.40807905, grad/param norm = 4.3578e-01, time/batch = 0.6459s	
484/11850 (epoch 2.042), train_loss = 2.43875281, grad/param norm = 3.4638e-01, time/batch = 0.6582s	
485/11850 (epoch 2.046), train_loss = 2.55911724, grad/param norm = 3.6852e-01, time/batch = 0.6425s	
486/11850 (epoch 2.051), train_loss = 2.38681117, grad/param norm = 5.5433e-01, time/batch = 0.6423s	
487/11850 (epoch 2.055), train_loss = 2.52801106, grad/param norm = 5.8111e-01, time/batch = 0.6526s	
488/11850 (epoch 2.059), train_loss = 2.50491009, grad/param norm = 5.8858e-01, time/batch = 0.6574s	
489/11850 (epoch 2.063), train_loss = 2.46765450, grad/param norm = 6.3782e-01, time/batch = 0.6565s	
490/11850 (epoch 2.068), train_loss = 2.47616467, grad/param norm = 6.0023e-01, time/batch = 0.6560s	
491/11850 (epoch 2.072), train_loss = 2.38508240, grad/param norm = 3.7037e-01, time/batch = 0.6588s	
492/11850 (epoch 2.076), train_loss = 2.44660587, grad/param norm = 3.3973e-01, time/batch = 0.6567s	
493/11850 (epoch 2.080), train_loss = 2.52968425, grad/param norm = 2.9605e-01, time/batch = 0.6516s	
494/11850 (epoch 2.084), train_loss = 2.35801299, grad/param norm = 3.4062e-01, time/batch = 0.6596s	
495/11850 (epoch 2.089), train_loss = 2.32079347, grad/param norm = 3.2293e-01, time/batch = 0.6536s	
496/11850 (epoch 2.093), train_loss = 2.30219415, grad/param norm = 2.8434e-01, time/batch = 0.6229s	
497/11850 (epoch 2.097), train_loss = 2.61809437, grad/param norm = 3.4928e-01, time/batch = 0.6272s	
498/11850 (epoch 2.101), train_loss = 2.58306183, grad/param norm = 3.9725e-01, time/batch = 0.6256s	
499/11850 (epoch 2.105), train_loss = 2.35322917, grad/param norm = 3.4758e-01, time/batch = 0.6314s	
500/11850 (epoch 2.110), train_loss = 2.30531935, grad/param norm = 3.0158e-01, time/batch = 0.6253s	
501/11850 (epoch 2.114), train_loss = 2.48803840, grad/param norm = 5.1819e-01, time/batch = 0.6282s	
502/11850 (epoch 2.118), train_loss = 2.36803829, grad/param norm = 8.9074e-01, time/batch = 0.6280s	
503/11850 (epoch 2.122), train_loss = 2.43051282, grad/param norm = 7.8077e-01, time/batch = 0.6266s	
504/11850 (epoch 2.127), train_loss = 2.55899560, grad/param norm = 6.0491e-01, time/batch = 0.6255s	
505/11850 (epoch 2.131), train_loss = 2.54266340, grad/param norm = 5.9098e-01, time/batch = 0.6545s	
506/11850 (epoch 2.135), train_loss = 2.45137810, grad/param norm = 4.3490e-01, time/batch = 0.6470s	
507/11850 (epoch 2.139), train_loss = 2.51905169, grad/param norm = 3.0475e-01, time/batch = 0.6303s	
508/11850 (epoch 2.143), train_loss = 2.41724483, grad/param norm = 3.1975e-01, time/batch = 0.6301s	
509/11850 (epoch 2.148), train_loss = 2.43703082, grad/param norm = 3.9036e-01, time/batch = 0.6281s	
510/11850 (epoch 2.152), train_loss = 2.36748838, grad/param norm = 5.7964e-01, time/batch = 0.6270s	
511/11850 (epoch 2.156), train_loss = 2.52414210, grad/param norm = 5.9676e-01, time/batch = 0.6281s	
512/11850 (epoch 2.160), train_loss = 2.70469177, grad/param norm = 4.1858e-01, time/batch = 0.6246s	
513/11850 (epoch 2.165), train_loss = 2.51945938, grad/param norm = 2.8901e-01, time/batch = 0.6263s	
514/11850 (epoch 2.169), train_loss = 2.33594766, grad/param norm = 3.4121e-01, time/batch = 0.6270s	
515/11850 (epoch 2.173), train_loss = 2.42181068, grad/param norm = 3.3670e-01, time/batch = 0.6249s	
516/11850 (epoch 2.177), train_loss = 2.47981207, grad/param norm = 3.7031e-01, time/batch = 0.6342s	
517/11850 (epoch 2.181), train_loss = 2.33458026, grad/param norm = 3.9727e-01, time/batch = 0.6238s	
518/11850 (epoch 2.186), train_loss = 2.52570658, grad/param norm = 3.5319e-01, time/batch = 0.6336s	
519/11850 (epoch 2.190), train_loss = 2.41663345, grad/param norm = 2.8210e-01, time/batch = 0.6466s	
520/11850 (epoch 2.194), train_loss = 2.57815939, grad/param norm = 3.1936e-01, time/batch = 0.6373s	
521/11850 (epoch 2.198), train_loss = 2.34179291, grad/param norm = 3.8772e-01, time/batch = 0.6353s	
522/11850 (epoch 2.203), train_loss = 2.21688370, grad/param norm = 3.3767e-01, time/batch = 0.6214s	
523/11850 (epoch 2.207), train_loss = 2.50603953, grad/param norm = 3.8736e-01, time/batch = 0.6261s	
524/11850 (epoch 2.211), train_loss = 2.42497732, grad/param norm = 3.5616e-01, time/batch = 0.6297s	
525/11850 (epoch 2.215), train_loss = 2.46369842, grad/param norm = 3.4220e-01, time/batch = 0.6222s	
526/11850 (epoch 2.219), train_loss = 2.25114591, grad/param norm = 3.1187e-01, time/batch = 0.6295s	
527/11850 (epoch 2.224), train_loss = 2.54157712, grad/param norm = 3.2725e-01, time/batch = 0.6289s	
528/11850 (epoch 2.228), train_loss = 2.46746794, grad/param norm = 2.7632e-01, time/batch = 0.6369s	
529/11850 (epoch 2.232), train_loss = 2.37728393, grad/param norm = 3.6589e-01, time/batch = 0.6343s	
530/11850 (epoch 2.236), train_loss = 2.38875567, grad/param norm = 3.7882e-01, time/batch = 0.6334s	
531/11850 (epoch 2.241), train_loss = 2.43629775, grad/param norm = 4.4589e-01, time/batch = 0.6307s	
532/11850 (epoch 2.245), train_loss = 2.41322590, grad/param norm = 5.5490e-01, time/batch = 0.6325s	
533/11850 (epoch 2.249), train_loss = 2.31544281, grad/param norm = 4.8030e-01, time/batch = 0.6289s	
534/11850 (epoch 2.253), train_loss = 2.42407631, grad/param norm = 2.9909e-01, time/batch = 0.6261s	
535/11850 (epoch 2.257), train_loss = 2.41492055, grad/param norm = 3.8006e-01, time/batch = 0.6251s	
536/11850 (epoch 2.262), train_loss = 2.49276012, grad/param norm = 4.1455e-01, time/batch = 0.6276s	
537/11850 (epoch 2.266), train_loss = 2.45081867, grad/param norm = 5.7765e-01, time/batch = 0.6268s	
538/11850 (epoch 2.270), train_loss = 2.40580526, grad/param norm = 4.1533e-01, time/batch = 0.6230s	
539/11850 (epoch 2.274), train_loss = 2.37404420, grad/param norm = 3.8783e-01, time/batch = 0.6264s	
540/11850 (epoch 2.278), train_loss = 2.37551039, grad/param norm = 4.8380e-01, time/batch = 0.6234s	
541/11850 (epoch 2.283), train_loss = 2.34818310, grad/param norm = 4.4124e-01, time/batch = 0.6248s	
542/11850 (epoch 2.287), train_loss = 2.37844531, grad/param norm = 4.4252e-01, time/batch = 0.6261s	
543/11850 (epoch 2.291), train_loss = 2.48065670, grad/param norm = 3.9033e-01, time/batch = 0.6221s	
544/11850 (epoch 2.295), train_loss = 2.42380550, grad/param norm = 3.8575e-01, time/batch = 0.6238s	
545/11850 (epoch 2.300), train_loss = 2.27442039, grad/param norm = 4.3715e-01, time/batch = 0.6249s	
546/11850 (epoch 2.304), train_loss = 2.32022130, grad/param norm = 2.8524e-01, time/batch = 0.6256s	
547/11850 (epoch 2.308), train_loss = 2.21687810, grad/param norm = 3.1220e-01, time/batch = 0.6232s	
548/11850 (epoch 2.312), train_loss = 2.26259560, grad/param norm = 3.0460e-01, time/batch = 0.6243s	
549/11850 (epoch 2.316), train_loss = 2.34058903, grad/param norm = 4.1850e-01, time/batch = 0.6372s	
550/11850 (epoch 2.321), train_loss = 2.32963875, grad/param norm = 5.3581e-01, time/batch = 0.6282s	
551/11850 (epoch 2.325), train_loss = 2.49189729, grad/param norm = 4.9601e-01, time/batch = 0.6265s	
552/11850 (epoch 2.329), train_loss = 2.39457547, grad/param norm = 3.7385e-01, time/batch = 0.6322s	
553/11850 (epoch 2.333), train_loss = 2.32963492, grad/param norm = 3.2878e-01, time/batch = 0.6618s	
554/11850 (epoch 2.338), train_loss = 2.25409661, grad/param norm = 3.0378e-01, time/batch = 0.6610s	
555/11850 (epoch 2.342), train_loss = 2.52163782, grad/param norm = 4.4249e-01, time/batch = 0.6552s	
556/11850 (epoch 2.346), train_loss = 2.42243396, grad/param norm = 4.4499e-01, time/batch = 0.6448s	
557/11850 (epoch 2.350), train_loss = 2.21693126, grad/param norm = 4.2783e-01, time/batch = 0.6439s	
558/11850 (epoch 2.354), train_loss = 2.51659028, grad/param norm = 5.5733e-01, time/batch = 0.6448s	
559/11850 (epoch 2.359), train_loss = 2.40883225, grad/param norm = 5.8056e-01, time/batch = 0.6825s	
560/11850 (epoch 2.363), train_loss = 2.28773851, grad/param norm = 4.2544e-01, time/batch = 0.6677s	
561/11850 (epoch 2.367), train_loss = 2.39712576, grad/param norm = 3.5593e-01, time/batch = 0.6682s	
562/11850 (epoch 2.371), train_loss = 2.31523436, grad/param norm = 3.6056e-01, time/batch = 0.6458s	
563/11850 (epoch 2.376), train_loss = 2.34682897, grad/param norm = 3.6413e-01, time/batch = 0.6461s	
564/11850 (epoch 2.380), train_loss = 2.27181151, grad/param norm = 3.9184e-01, time/batch = 0.6468s	
565/11850 (epoch 2.384), train_loss = 2.37282218, grad/param norm = 3.5621e-01, time/batch = 0.6472s	
566/11850 (epoch 2.388), train_loss = 2.31729838, grad/param norm = 3.8189e-01, time/batch = 0.6456s	
567/11850 (epoch 2.392), train_loss = 2.37874087, grad/param norm = 4.2948e-01, time/batch = 0.6526s	
568/11850 (epoch 2.397), train_loss = 2.48988364, grad/param norm = 4.5081e-01, time/batch = 0.6438s	
569/11850 (epoch 2.401), train_loss = 2.19759025, grad/param norm = 5.2303e-01, time/batch = 0.6416s	
570/11850 (epoch 2.405), train_loss = 2.39741964, grad/param norm = 3.9763e-01, time/batch = 0.6500s	
571/11850 (epoch 2.409), train_loss = 2.43705746, grad/param norm = 2.8685e-01, time/batch = 0.6449s	
572/11850 (epoch 2.414), train_loss = 2.22092666, grad/param norm = 4.0194e-01, time/batch = 0.6449s	
573/11850 (epoch 2.418), train_loss = 2.24305149, grad/param norm = 4.3279e-01, time/batch = 0.6449s	
574/11850 (epoch 2.422), train_loss = 2.29612287, grad/param norm = 3.4163e-01, time/batch = 0.6433s	
575/11850 (epoch 2.426), train_loss = 2.41636276, grad/param norm = 3.9610e-01, time/batch = 0.6436s	
576/11850 (epoch 2.430), train_loss = 2.33294095, grad/param norm = 4.3254e-01, time/batch = 0.6399s	
577/11850 (epoch 2.435), train_loss = 2.26368017, grad/param norm = 4.0998e-01, time/batch = 0.6412s	
578/11850 (epoch 2.439), train_loss = 2.43260980, grad/param norm = 4.1633e-01, time/batch = 0.6487s	
579/11850 (epoch 2.443), train_loss = 2.41719234, grad/param norm = 3.2997e-01, time/batch = 0.6490s	
580/11850 (epoch 2.447), train_loss = 2.30603617, grad/param norm = 3.2894e-01, time/batch = 0.6472s	
581/11850 (epoch 2.451), train_loss = 2.25595188, grad/param norm = 3.1427e-01, time/batch = 0.6459s	
582/11850 (epoch 2.456), train_loss = 2.50040106, grad/param norm = 3.4802e-01, time/batch = 0.6439s	
583/11850 (epoch 2.460), train_loss = 2.47101026, grad/param norm = 2.9822e-01, time/batch = 0.6464s	
584/11850 (epoch 2.464), train_loss = 2.34069486, grad/param norm = 3.6603e-01, time/batch = 0.6413s	
585/11850 (epoch 2.468), train_loss = 2.44820162, grad/param norm = 4.8564e-01, time/batch = 0.6440s	
586/11850 (epoch 2.473), train_loss = 2.38746253, grad/param norm = 6.1275e-01, time/batch = 0.6705s	
587/11850 (epoch 2.477), train_loss = 2.23252343, grad/param norm = 4.1362e-01, time/batch = 0.6674s	
588/11850 (epoch 2.481), train_loss = 2.33604815, grad/param norm = 3.2258e-01, time/batch = 0.6526s	
589/11850 (epoch 2.485), train_loss = 2.16002125, grad/param norm = 3.5727e-01, time/batch = 0.6509s	
590/11850 (epoch 2.489), train_loss = 2.32770268, grad/param norm = 3.5601e-01, time/batch = 0.6454s	
591/11850 (epoch 2.494), train_loss = 2.40123457, grad/param norm = 3.0828e-01, time/batch = 0.6455s	
592/11850 (epoch 2.498), train_loss = 2.44465923, grad/param norm = 3.2705e-01, time/batch = 0.6433s	
593/11850 (epoch 2.502), train_loss = 2.32155747, grad/param norm = 3.2683e-01, time/batch = 0.6418s	
594/11850 (epoch 2.506), train_loss = 2.39650074, grad/param norm = 3.2291e-01, time/batch = 0.6418s	
595/11850 (epoch 2.511), train_loss = 2.27205660, grad/param norm = 3.7151e-01, time/batch = 0.6455s	
596/11850 (epoch 2.515), train_loss = 2.47150268, grad/param norm = 4.8301e-01, time/batch = 0.6409s	
597/11850 (epoch 2.519), train_loss = 2.29596897, grad/param norm = 5.1403e-01, time/batch = 0.6420s	
598/11850 (epoch 2.523), train_loss = 2.28909593, grad/param norm = 3.6256e-01, time/batch = 0.6411s	
599/11850 (epoch 2.527), train_loss = 2.29549677, grad/param norm = 2.9131e-01, time/batch = 0.6410s	
600/11850 (epoch 2.532), train_loss = 2.44761424, grad/param norm = 3.7312e-01, time/batch = 0.6412s	
601/11850 (epoch 2.536), train_loss = 2.31670776, grad/param norm = 3.5231e-01, time/batch = 0.6444s	
602/11850 (epoch 2.540), train_loss = 2.22622895, grad/param norm = 3.4921e-01, time/batch = 0.6442s	
603/11850 (epoch 2.544), train_loss = 2.35602979, grad/param norm = 3.4989e-01, time/batch = 0.6418s	
604/11850 (epoch 2.549), train_loss = 2.07875320, grad/param norm = 4.0254e-01, time/batch = 0.6450s	
605/11850 (epoch 2.553), train_loss = 2.30803722, grad/param norm = 4.4321e-01, time/batch = 0.6424s	
606/11850 (epoch 2.557), train_loss = 2.55008209, grad/param norm = 4.2369e-01, time/batch = 0.6571s	
607/11850 (epoch 2.561), train_loss = 2.26907872, grad/param norm = 3.9672e-01, time/batch = 0.6565s	
608/11850 (epoch 2.565), train_loss = 2.31556072, grad/param norm = 3.2610e-01, time/batch = 0.6545s	
609/11850 (epoch 2.570), train_loss = 2.18428430, grad/param norm = 3.0139e-01, time/batch = 0.6464s	
610/11850 (epoch 2.574), train_loss = 2.31331920, grad/param norm = 2.8226e-01, time/batch = 0.6419s	
611/11850 (epoch 2.578), train_loss = 2.37439446, grad/param norm = 2.7724e-01, time/batch = 0.6450s	
612/11850 (epoch 2.582), train_loss = 2.26388143, grad/param norm = 2.8664e-01, time/batch = 0.6498s	
613/11850 (epoch 2.586), train_loss = 2.31070506, grad/param norm = 3.8443e-01, time/batch = 0.6427s	
614/11850 (epoch 2.591), train_loss = 2.36052328, grad/param norm = 3.5329e-01, time/batch = 0.6425s	
615/11850 (epoch 2.595), train_loss = 2.21760020, grad/param norm = 3.1866e-01, time/batch = 0.6421s	
616/11850 (epoch 2.599), train_loss = 2.11819039, grad/param norm = 3.2959e-01, time/batch = 0.6456s	
617/11850 (epoch 2.603), train_loss = 2.22479121, grad/param norm = 2.6269e-01, time/batch = 0.6506s	
618/11850 (epoch 2.608), train_loss = 2.38029826, grad/param norm = 3.2378e-01, time/batch = 0.6411s	
619/11850 (epoch 2.612), train_loss = 2.39926995, grad/param norm = 3.0103e-01, time/batch = 0.6460s	
620/11850 (epoch 2.616), train_loss = 2.32285165, grad/param norm = 3.6540e-01, time/batch = 0.6439s	
621/11850 (epoch 2.620), train_loss = 2.23611968, grad/param norm = 4.8432e-01, time/batch = 0.6422s	
622/11850 (epoch 2.624), train_loss = 2.37735287, grad/param norm = 4.9506e-01, time/batch = 0.6421s	
623/11850 (epoch 2.629), train_loss = 2.41241462, grad/param norm = 4.5906e-01, time/batch = 0.6435s	
624/11850 (epoch 2.633), train_loss = 2.26517395, grad/param norm = 4.7603e-01, time/batch = 0.6435s	
625/11850 (epoch 2.637), train_loss = 2.22714413, grad/param norm = 4.2505e-01, time/batch = 0.6413s	
626/11850 (epoch 2.641), train_loss = 2.27568450, grad/param norm = 4.1212e-01, time/batch = 0.6425s	
627/11850 (epoch 2.646), train_loss = 2.27053378, grad/param norm = 3.2233e-01, time/batch = 0.6442s	
628/11850 (epoch 2.650), train_loss = 2.24352217, grad/param norm = 3.6043e-01, time/batch = 0.6419s	
629/11850 (epoch 2.654), train_loss = 2.40052962, grad/param norm = 4.9144e-01, time/batch = 0.6437s	
630/11850 (epoch 2.658), train_loss = 2.26958034, grad/param norm = 4.5857e-01, time/batch = 0.6422s	
631/11850 (epoch 2.662), train_loss = 2.23712696, grad/param norm = 3.7654e-01, time/batch = 0.6444s	
632/11850 (epoch 2.667), train_loss = 2.16975817, grad/param norm = 2.9420e-01, time/batch = 0.6482s	
633/11850 (epoch 2.671), train_loss = 2.12771511, grad/param norm = 2.8454e-01, time/batch = 0.6441s	
634/11850 (epoch 2.675), train_loss = 2.32490974, grad/param norm = 4.0764e-01, time/batch = 0.6721s	
635/11850 (epoch 2.679), train_loss = 2.37189631, grad/param norm = 3.6192e-01, time/batch = 0.6586s	
636/11850 (epoch 2.684), train_loss = 2.28254478, grad/param norm = 4.0327e-01, time/batch = 0.6413s	
637/11850 (epoch 2.688), train_loss = 2.25073271, grad/param norm = 4.0936e-01, time/batch = 0.6421s	
638/11850 (epoch 2.692), train_loss = 2.31448380, grad/param norm = 4.2326e-01, time/batch = 0.6438s	
639/11850 (epoch 2.696), train_loss = 2.33360796, grad/param norm = 5.2868e-01, time/batch = 0.6418s	
640/11850 (epoch 2.700), train_loss = 2.24705756, grad/param norm = 3.8869e-01, time/batch = 0.6408s	
641/11850 (epoch 2.705), train_loss = 2.30337935, grad/param norm = 3.9194e-01, time/batch = 0.6429s	
642/11850 (epoch 2.709), train_loss = 2.29888950, grad/param norm = 3.2647e-01, time/batch = 0.6486s	
643/11850 (epoch 2.713), train_loss = 2.25690706, grad/param norm = 3.1275e-01, time/batch = 0.6433s	
644/11850 (epoch 2.717), train_loss = 2.10520979, grad/param norm = 3.3341e-01, time/batch = 0.6492s	
645/11850 (epoch 2.722), train_loss = 2.42762437, grad/param norm = 3.6881e-01, time/batch = 0.6745s	
646/11850 (epoch 2.726), train_loss = 2.21496342, grad/param norm = 3.7094e-01, time/batch = 0.6755s	
647/11850 (epoch 2.730), train_loss = 2.18662513, grad/param norm = 3.5748e-01, time/batch = 0.6626s	
648/11850 (epoch 2.734), train_loss = 2.19535382, grad/param norm = 3.5051e-01, time/batch = 0.6526s	
649/11850 (epoch 2.738), train_loss = 2.29396074, grad/param norm = 3.9908e-01, time/batch = 0.6461s	
650/11850 (epoch 2.743), train_loss = 2.29920898, grad/param norm = 4.4372e-01, time/batch = 0.6463s	
651/11850 (epoch 2.747), train_loss = 2.31227886, grad/param norm = 6.1303e-01, time/batch = 0.6463s	
652/11850 (epoch 2.751), train_loss = 2.22281419, grad/param norm = 5.7556e-01, time/batch = 0.6425s	
653/11850 (epoch 2.755), train_loss = 2.30531879, grad/param norm = 4.0696e-01, time/batch = 0.6408s	
654/11850 (epoch 2.759), train_loss = 2.19217388, grad/param norm = 3.1823e-01, time/batch = 0.6599s	
655/11850 (epoch 2.764), train_loss = 2.20636797, grad/param norm = 2.8518e-01, time/batch = 0.6669s	
656/11850 (epoch 2.768), train_loss = 2.00864338, grad/param norm = 2.5417e-01, time/batch = 0.6764s	
657/11850 (epoch 2.772), train_loss = 2.22790669, grad/param norm = 3.3619e-01, time/batch = 0.6419s	
658/11850 (epoch 2.776), train_loss = 2.24120591, grad/param norm = 3.3978e-01, time/batch = 0.6435s	
659/11850 (epoch 2.781), train_loss = 2.12142847, grad/param norm = 2.8917e-01, time/batch = 0.6456s	
660/11850 (epoch 2.785), train_loss = 2.19155799, grad/param norm = 2.8855e-01, time/batch = 0.6492s	
661/11850 (epoch 2.789), train_loss = 2.40272414, grad/param norm = 3.8515e-01, time/batch = 0.6458s	
662/11850 (epoch 2.793), train_loss = 2.39526836, grad/param norm = 2.8754e-01, time/batch = 0.6410s	
663/11850 (epoch 2.797), train_loss = 2.27502290, grad/param norm = 2.5562e-01, time/batch = 0.6494s	
664/11850 (epoch 2.802), train_loss = 2.27249837, grad/param norm = 2.8537e-01, time/batch = 0.6460s	
665/11850 (epoch 2.806), train_loss = 2.23545139, grad/param norm = 3.2108e-01, time/batch = 0.6529s	
666/11850 (epoch 2.810), train_loss = 2.36720926, grad/param norm = 3.8762e-01, time/batch = 0.6606s	
667/11850 (epoch 2.814), train_loss = 2.23513324, grad/param norm = 6.3900e-01, time/batch = 0.6521s	
668/11850 (epoch 2.819), train_loss = 2.31305149, grad/param norm = 5.0278e-01, time/batch = 0.6409s	
669/11850 (epoch 2.823), train_loss = 2.33214461, grad/param norm = 4.9187e-01, time/batch = 0.6433s	
670/11850 (epoch 2.827), train_loss = 2.25287513, grad/param norm = 4.6092e-01, time/batch = 0.6409s	
671/11850 (epoch 2.831), train_loss = 2.22732484, grad/param norm = 4.2007e-01, time/batch = 0.6408s	
672/11850 (epoch 2.835), train_loss = 2.23111280, grad/param norm = 4.1334e-01, time/batch = 0.6431s	
673/11850 (epoch 2.840), train_loss = 2.15673779, grad/param norm = 3.4488e-01, time/batch = 0.6409s	
674/11850 (epoch 2.844), train_loss = 2.24817947, grad/param norm = 2.7976e-01, time/batch = 0.6420s	
675/11850 (epoch 2.848), train_loss = 2.38180925, grad/param norm = 3.4164e-01, time/batch = 0.6423s	
676/11850 (epoch 2.852), train_loss = 2.30194418, grad/param norm = 4.1913e-01, time/batch = 0.6414s	
677/11850 (epoch 2.857), train_loss = 2.27373628, grad/param norm = 3.6951e-01, time/batch = 0.6419s	
678/11850 (epoch 2.861), train_loss = 2.32048263, grad/param norm = 3.0720e-01, time/batch = 0.6437s	
679/11850 (epoch 2.865), train_loss = 2.35817849, grad/param norm = 3.3275e-01, time/batch = 0.6425s	
680/11850 (epoch 2.869), train_loss = 2.47797673, grad/param norm = 3.1996e-01, time/batch = 0.6463s	
681/11850 (epoch 2.873), train_loss = 2.33522259, grad/param norm = 3.2850e-01, time/batch = 0.6472s	
682/11850 (epoch 2.878), train_loss = 2.26313588, grad/param norm = 3.0493e-01, time/batch = 0.6569s	
683/11850 (epoch 2.882), train_loss = 2.21505130, grad/param norm = 2.7049e-01, time/batch = 0.6474s	
684/11850 (epoch 2.886), train_loss = 2.29273646, grad/param norm = 3.3689e-01, time/batch = 0.6404s	
685/11850 (epoch 2.890), train_loss = 2.24085841, grad/param norm = 3.3272e-01, time/batch = 0.6405s	
686/11850 (epoch 2.895), train_loss = 2.26081258, grad/param norm = 2.8159e-01, time/batch = 0.6454s	
687/11850 (epoch 2.899), train_loss = 2.28863712, grad/param norm = 3.3747e-01, time/batch = 0.6438s	
688/11850 (epoch 2.903), train_loss = 2.24117435, grad/param norm = 2.7001e-01, time/batch = 0.6441s	
689/11850 (epoch 2.907), train_loss = 2.16472575, grad/param norm = 2.9800e-01, time/batch = 0.6435s	
690/11850 (epoch 2.911), train_loss = 2.17174248, grad/param norm = 3.3009e-01, time/batch = 0.6409s	
691/11850 (epoch 2.916), train_loss = 2.40585957, grad/param norm = 3.8442e-01, time/batch = 0.6426s	
692/11850 (epoch 2.920), train_loss = 2.08986484, grad/param norm = 4.1381e-01, time/batch = 0.6414s	
693/11850 (epoch 2.924), train_loss = 2.19330086, grad/param norm = 3.9886e-01, time/batch = 0.6403s	
694/11850 (epoch 2.928), train_loss = 2.35434379, grad/param norm = 3.5648e-01, time/batch = 0.6451s	
695/11850 (epoch 2.932), train_loss = 2.35507536, grad/param norm = 4.4107e-01, time/batch = 0.6396s	
696/11850 (epoch 2.937), train_loss = 2.36975752, grad/param norm = 4.0232e-01, time/batch = 0.6410s	
697/11850 (epoch 2.941), train_loss = 2.29778737, grad/param norm = 4.3921e-01, time/batch = 0.6433s	
698/11850 (epoch 2.945), train_loss = 2.34591488, grad/param norm = 3.2353e-01, time/batch = 0.6515s	
699/11850 (epoch 2.949), train_loss = 2.30014429, grad/param norm = 3.6067e-01, time/batch = 0.6734s	
700/11850 (epoch 2.954), train_loss = 2.41846543, grad/param norm = 3.2092e-01, time/batch = 0.6529s	
701/11850 (epoch 2.958), train_loss = 2.24235959, grad/param norm = 3.4390e-01, time/batch = 0.6394s	
702/11850 (epoch 2.962), train_loss = 2.30129893, grad/param norm = 3.9961e-01, time/batch = 0.6420s	
703/11850 (epoch 2.966), train_loss = 2.29140124, grad/param norm = 5.1224e-01, time/batch = 0.6418s	
704/11850 (epoch 2.970), train_loss = 2.26948915, grad/param norm = 4.7378e-01, time/batch = 0.6382s	
705/11850 (epoch 2.975), train_loss = 2.33885810, grad/param norm = 3.1299e-01, time/batch = 0.6509s	
706/11850 (epoch 2.979), train_loss = 2.47942960, grad/param norm = 4.6388e-01, time/batch = 0.6406s	
707/11850 (epoch 2.983), train_loss = 2.77041696, grad/param norm = 7.0187e-01, time/batch = 0.6394s	
708/11850 (epoch 2.987), train_loss = 2.37521480, grad/param norm = 4.1996e-01, time/batch = 0.6415s	
709/11850 (epoch 2.992), train_loss = 2.29207879, grad/param norm = 3.1337e-01, time/batch = 0.6596s	
710/11850 (epoch 2.996), train_loss = 2.51167497, grad/param norm = 2.7737e-01, time/batch = 0.6705s	
711/11850 (epoch 3.000), train_loss = 2.34799803, grad/param norm = 2.7527e-01, time/batch = 0.6477s	
712/11850 (epoch 3.004), train_loss = 2.25576022, grad/param norm = 2.7998e-01, time/batch = 0.6413s	
713/11850 (epoch 3.008), train_loss = 2.22226247, grad/param norm = 2.7377e-01, time/batch = 0.6400s	
714/11850 (epoch 3.013), train_loss = 2.23453546, grad/param norm = 2.4353e-01, time/batch = 0.6756s	
715/11850 (epoch 3.017), train_loss = 2.39872631, grad/param norm = 2.5711e-01, time/batch = 0.6555s	
716/11850 (epoch 3.021), train_loss = 2.16506510, grad/param norm = 2.8220e-01, time/batch = 0.6485s	
717/11850 (epoch 3.025), train_loss = 1.94844829, grad/param norm = 2.2280e-01, time/batch = 0.6405s	
718/11850 (epoch 3.030), train_loss = 2.10474472, grad/param norm = 2.5989e-01, time/batch = 0.6373s	
719/11850 (epoch 3.034), train_loss = 2.15375111, grad/param norm = 2.8912e-01, time/batch = 0.6403s	
720/11850 (epoch 3.038), train_loss = 2.20726452, grad/param norm = 3.6534e-01, time/batch = 0.6419s	
721/11850 (epoch 3.042), train_loss = 2.24380622, grad/param norm = 2.6645e-01, time/batch = 0.6431s	
722/11850 (epoch 3.046), train_loss = 2.39358397, grad/param norm = 2.9371e-01, time/batch = 0.6429s	
723/11850 (epoch 3.051), train_loss = 2.19010800, grad/param norm = 3.7775e-01, time/batch = 0.6394s	
724/11850 (epoch 3.055), train_loss = 2.31505586, grad/param norm = 4.1261e-01, time/batch = 0.6446s	
725/11850 (epoch 3.059), train_loss = 2.31029261, grad/param norm = 3.9275e-01, time/batch = 0.6414s	
726/11850 (epoch 3.063), train_loss = 2.28166750, grad/param norm = 3.7644e-01, time/batch = 0.6413s	
727/11850 (epoch 3.068), train_loss = 2.24152251, grad/param norm = 3.7049e-01, time/batch = 0.6443s	
728/11850 (epoch 3.072), train_loss = 2.21339226, grad/param norm = 2.9235e-01, time/batch = 0.6430s	
729/11850 (epoch 3.076), train_loss = 2.30241494, grad/param norm = 2.9085e-01, time/batch = 0.6412s	
730/11850 (epoch 3.080), train_loss = 2.33302158, grad/param norm = 2.6844e-01, time/batch = 0.6436s	
731/11850 (epoch 3.084), train_loss = 2.14401195, grad/param norm = 2.8795e-01, time/batch = 0.6754s	
732/11850 (epoch 3.089), train_loss = 2.10981876, grad/param norm = 2.6208e-01, time/batch = 0.6559s	
733/11850 (epoch 3.093), train_loss = 2.10351774, grad/param norm = 2.8257e-01, time/batch = 0.6421s	
734/11850 (epoch 3.097), train_loss = 2.46794093, grad/param norm = 3.2364e-01, time/batch = 0.6409s	
735/11850 (epoch 3.101), train_loss = 2.38850065, grad/param norm = 3.7019e-01, time/batch = 0.6428s	
736/11850 (epoch 3.105), train_loss = 2.15276620, grad/param norm = 3.0345e-01, time/batch = 0.6414s	
737/11850 (epoch 3.110), train_loss = 2.12419655, grad/param norm = 2.8364e-01, time/batch = 0.6541s	
738/11850 (epoch 3.114), train_loss = 2.30851644, grad/param norm = 4.1137e-01, time/batch = 0.6683s	
739/11850 (epoch 3.118), train_loss = 2.17295033, grad/param norm = 5.4792e-01, time/batch = 0.6719s	
740/11850 (epoch 3.122), train_loss = 2.24088165, grad/param norm = 4.6943e-01, time/batch = 0.6568s	
741/11850 (epoch 3.127), train_loss = 2.37189270, grad/param norm = 4.1028e-01, time/batch = 0.6446s	
742/11850 (epoch 3.131), train_loss = 2.35674215, grad/param norm = 3.8690e-01, time/batch = 0.6461s	
743/11850 (epoch 3.135), train_loss = 2.24132094, grad/param norm = 3.9620e-01, time/batch = 0.6429s	
744/11850 (epoch 3.139), train_loss = 2.31635469, grad/param norm = 3.1510e-01, time/batch = 0.6752s	
745/11850 (epoch 3.143), train_loss = 2.22390620, grad/param norm = 3.1814e-01, time/batch = 0.6475s	
746/11850 (epoch 3.148), train_loss = 2.24562215, grad/param norm = 3.3711e-01, time/batch = 0.6400s	
747/11850 (epoch 3.152), train_loss = 2.19316532, grad/param norm = 3.8946e-01, time/batch = 0.6365s	
748/11850 (epoch 3.156), train_loss = 2.32938219, grad/param norm = 3.2998e-01, time/batch = 0.6385s	
749/11850 (epoch 3.160), train_loss = 2.55084113, grad/param norm = 3.2444e-01, time/batch = 0.6377s	
750/11850 (epoch 3.165), train_loss = 2.34896529, grad/param norm = 2.8220e-01, time/batch = 0.6458s	
751/11850 (epoch 3.169), train_loss = 2.16326031, grad/param norm = 3.2045e-01, time/batch = 0.6440s	
752/11850 (epoch 3.173), train_loss = 2.27682145, grad/param norm = 3.1044e-01, time/batch = 0.6386s	
753/11850 (epoch 3.177), train_loss = 2.30605376, grad/param norm = 3.2366e-01, time/batch = 0.6372s	
754/11850 (epoch 3.181), train_loss = 2.16641200, grad/param norm = 3.2397e-01, time/batch = 0.6396s	
755/11850 (epoch 3.186), train_loss = 2.37110150, grad/param norm = 3.1405e-01, time/batch = 0.6403s	
756/11850 (epoch 3.190), train_loss = 2.24643284, grad/param norm = 2.8190e-01, time/batch = 0.6363s	
757/11850 (epoch 3.194), train_loss = 2.37469685, grad/param norm = 2.8434e-01, time/batch = 0.6395s	
758/11850 (epoch 3.198), train_loss = 2.17653685, grad/param norm = 3.3166e-01, time/batch = 0.6389s	
759/11850 (epoch 3.203), train_loss = 2.00276902, grad/param norm = 2.5159e-01, time/batch = 0.6388s	
760/11850 (epoch 3.207), train_loss = 2.32556941, grad/param norm = 3.2174e-01, time/batch = 0.6392s	
761/11850 (epoch 3.211), train_loss = 2.21859289, grad/param norm = 2.7652e-01, time/batch = 0.6403s	
762/11850 (epoch 3.215), train_loss = 2.24302631, grad/param norm = 2.6716e-01, time/batch = 0.6443s	
763/11850 (epoch 3.219), train_loss = 2.06201563, grad/param norm = 2.6421e-01, time/batch = 0.6759s	
764/11850 (epoch 3.224), train_loss = 2.42922782, grad/param norm = 2.8203e-01, time/batch = 0.6657s	
765/11850 (epoch 3.228), train_loss = 2.32138262, grad/param norm = 2.9771e-01, time/batch = 0.6538s	
766/11850 (epoch 3.232), train_loss = 2.23959642, grad/param norm = 3.6530e-01, time/batch = 0.6563s	
767/11850 (epoch 3.236), train_loss = 2.19674555, grad/param norm = 3.1438e-01, time/batch = 0.6386s	
768/11850 (epoch 3.241), train_loss = 2.31302267, grad/param norm = 3.5163e-01, time/batch = 0.6370s	
769/11850 (epoch 3.245), train_loss = 2.27191173, grad/param norm = 4.0357e-01, time/batch = 0.6431s	
770/11850 (epoch 3.249), train_loss = 2.15141285, grad/param norm = 3.2843e-01, time/batch = 0.6396s	
771/11850 (epoch 3.253), train_loss = 2.27196501, grad/param norm = 2.7168e-01, time/batch = 0.6471s	
772/11850 (epoch 3.257), train_loss = 2.25137363, grad/param norm = 3.8337e-01, time/batch = 0.6367s	
773/11850 (epoch 3.262), train_loss = 2.33084973, grad/param norm = 4.0520e-01, time/batch = 0.6413s	
774/11850 (epoch 3.266), train_loss = 2.26097650, grad/param norm = 3.2221e-01, time/batch = 0.6371s	
775/11850 (epoch 3.270), train_loss = 2.21080720, grad/param norm = 2.6969e-01, time/batch = 0.6370s	
776/11850 (epoch 3.274), train_loss = 2.17907041, grad/param norm = 3.0209e-01, time/batch = 0.6373s	
777/11850 (epoch 3.278), train_loss = 2.14996403, grad/param norm = 3.5543e-01, time/batch = 0.6380s	
778/11850 (epoch 3.283), train_loss = 2.14294737, grad/param norm = 3.1396e-01, time/batch = 0.6380s	
779/11850 (epoch 3.287), train_loss = 2.19859586, grad/param norm = 2.9907e-01, time/batch = 0.6394s	
780/11850 (epoch 3.291), train_loss = 2.29763748, grad/param norm = 2.8784e-01, time/batch = 0.6451s	
781/11850 (epoch 3.295), train_loss = 2.23532458, grad/param norm = 3.0353e-01, time/batch = 0.6416s	
782/11850 (epoch 3.300), train_loss = 2.09870246, grad/param norm = 3.7617e-01, time/batch = 0.6423s	
783/11850 (epoch 3.304), train_loss = 2.16136323, grad/param norm = 3.0820e-01, time/batch = 0.6544s	
784/11850 (epoch 3.308), train_loss = 2.03190740, grad/param norm = 2.6854e-01, time/batch = 0.6463s	
785/11850 (epoch 3.312), train_loss = 2.06127919, grad/param norm = 2.8467e-01, time/batch = 0.6698s	
786/11850 (epoch 3.316), train_loss = 2.15634480, grad/param norm = 2.9118e-01, time/batch = 0.6520s	
787/11850 (epoch 3.321), train_loss = 2.13846038, grad/param norm = 2.5946e-01, time/batch = 0.6348s	
788/11850 (epoch 3.325), train_loss = 2.26730264, grad/param norm = 3.0594e-01, time/batch = 0.6346s	
789/11850 (epoch 3.329), train_loss = 2.22886356, grad/param norm = 3.8660e-01, time/batch = 0.6358s	
790/11850 (epoch 3.333), train_loss = 2.20097254, grad/param norm = 3.7587e-01, time/batch = 0.6369s	
791/11850 (epoch 3.338), train_loss = 2.10343767, grad/param norm = 3.7839e-01, time/batch = 0.6404s	
792/11850 (epoch 3.342), train_loss = 2.40602772, grad/param norm = 5.1283e-01, time/batch = 0.6376s	
793/11850 (epoch 3.346), train_loss = 2.28243038, grad/param norm = 4.1265e-01, time/batch = 0.6362s	
794/11850 (epoch 3.350), train_loss = 2.04755791, grad/param norm = 3.0903e-01, time/batch = 0.6371s	
795/11850 (epoch 3.354), train_loss = 2.34282524, grad/param norm = 3.8590e-01, time/batch = 0.6365s	
796/11850 (epoch 3.359), train_loss = 2.22426542, grad/param norm = 4.2641e-01, time/batch = 0.6371s	
797/11850 (epoch 3.363), train_loss = 2.12212940, grad/param norm = 3.2469e-01, time/batch = 0.6395s	
798/11850 (epoch 3.367), train_loss = 2.19746461, grad/param norm = 2.6409e-01, time/batch = 0.6463s	
799/11850 (epoch 3.371), train_loss = 2.15740081, grad/param norm = 2.7713e-01, time/batch = 0.6364s	
800/11850 (epoch 3.376), train_loss = 2.16856973, grad/param norm = 2.9737e-01, time/batch = 0.6372s	
801/11850 (epoch 3.380), train_loss = 2.11417331, grad/param norm = 3.5734e-01, time/batch = 0.6450s	
802/11850 (epoch 3.384), train_loss = 2.21354012, grad/param norm = 3.3585e-01, time/batch = 0.6425s	
803/11850 (epoch 3.388), train_loss = 2.18390489, grad/param norm = 3.0338e-01, time/batch = 0.6368s	
804/11850 (epoch 3.392), train_loss = 2.21805888, grad/param norm = 3.2103e-01, time/batch = 0.6410s	
805/11850 (epoch 3.397), train_loss = 2.33896972, grad/param norm = 3.0975e-01, time/batch = 0.6387s	
806/11850 (epoch 3.401), train_loss = 1.97596081, grad/param norm = 2.7579e-01, time/batch = 0.6355s	
807/11850 (epoch 3.405), train_loss = 2.18719348, grad/param norm = 2.9116e-01, time/batch = 0.6359s	
808/11850 (epoch 3.409), train_loss = 2.29758003, grad/param norm = 2.9390e-01, time/batch = 0.6378s	
809/11850 (epoch 3.414), train_loss = 2.05605468, grad/param norm = 3.6507e-01, time/batch = 0.6345s	
810/11850 (epoch 3.418), train_loss = 2.07811209, grad/param norm = 3.7858e-01, time/batch = 0.6341s	
811/11850 (epoch 3.422), train_loss = 2.12323123, grad/param norm = 3.1320e-01, time/batch = 0.6404s	
812/11850 (epoch 3.426), train_loss = 2.22094138, grad/param norm = 3.1309e-01, time/batch = 0.6385s	
813/11850 (epoch 3.430), train_loss = 2.12377896, grad/param norm = 2.8723e-01, time/batch = 0.6362s	
814/11850 (epoch 3.435), train_loss = 2.09829337, grad/param norm = 2.8473e-01, time/batch = 0.6390s	
815/11850 (epoch 3.439), train_loss = 2.27577328, grad/param norm = 3.3312e-01, time/batch = 0.6367s	
816/11850 (epoch 3.443), train_loss = 2.27671097, grad/param norm = 2.6006e-01, time/batch = 0.6422s	
817/11850 (epoch 3.447), train_loss = 2.16037915, grad/param norm = 2.7126e-01, time/batch = 0.6593s	
818/11850 (epoch 3.451), train_loss = 2.09972840, grad/param norm = 3.0052e-01, time/batch = 0.6707s	
819/11850 (epoch 3.456), train_loss = 2.33782030, grad/param norm = 3.6075e-01, time/batch = 0.6431s	
820/11850 (epoch 3.460), train_loss = 2.27713941, grad/param norm = 2.5888e-01, time/batch = 0.6399s	
821/11850 (epoch 3.464), train_loss = 2.20709510, grad/param norm = 2.8383e-01, time/batch = 0.6391s	
822/11850 (epoch 3.468), train_loss = 2.23305188, grad/param norm = 2.6743e-01, time/batch = 0.6398s	
823/11850 (epoch 3.473), train_loss = 2.21043703, grad/param norm = 3.5669e-01, time/batch = 0.6382s	
824/11850 (epoch 3.477), train_loss = 2.02697445, grad/param norm = 3.5370e-01, time/batch = 0.6378s	
825/11850 (epoch 3.481), train_loss = 2.14351824, grad/param norm = 3.3307e-01, time/batch = 0.6373s	
826/11850 (epoch 3.485), train_loss = 1.98279377, grad/param norm = 3.3588e-01, time/batch = 0.6366s	
827/11850 (epoch 3.489), train_loss = 2.18694396, grad/param norm = 2.8631e-01, time/batch = 0.6373s	
828/11850 (epoch 3.494), train_loss = 2.19038374, grad/param norm = 2.6330e-01, time/batch = 0.6370s	
829/11850 (epoch 3.498), train_loss = 2.25223084, grad/param norm = 3.1084e-01, time/batch = 0.6386s	
830/11850 (epoch 3.502), train_loss = 2.12213408, grad/param norm = 3.0061e-01, time/batch = 0.6602s	
831/11850 (epoch 3.506), train_loss = 2.27021109, grad/param norm = 2.7748e-01, time/batch = 0.6659s	
832/11850 (epoch 3.511), train_loss = 2.10772510, grad/param norm = 2.7999e-01, time/batch = 0.6694s	
833/11850 (epoch 3.515), train_loss = 2.31236000, grad/param norm = 3.8068e-01, time/batch = 0.6430s	
834/11850 (epoch 3.519), train_loss = 2.13272737, grad/param norm = 3.6543e-01, time/batch = 0.6436s	
835/11850 (epoch 3.523), train_loss = 2.14721036, grad/param norm = 2.8110e-01, time/batch = 0.6402s	
836/11850 (epoch 3.527), train_loss = 2.12671643, grad/param norm = 3.4372e-01, time/batch = 0.6408s	
837/11850 (epoch 3.532), train_loss = 2.30296082, grad/param norm = 4.3561e-01, time/batch = 0.6388s	
838/11850 (epoch 3.536), train_loss = 2.12491709, grad/param norm = 3.0843e-01, time/batch = 0.6344s	
839/11850 (epoch 3.540), train_loss = 2.04569484, grad/param norm = 2.4152e-01, time/batch = 0.6370s	
840/11850 (epoch 3.544), train_loss = 2.16127746, grad/param norm = 2.9112e-01, time/batch = 0.6361s	
841/11850 (epoch 3.549), train_loss = 1.88879308, grad/param norm = 3.3412e-01, time/batch = 0.6370s	
842/11850 (epoch 3.553), train_loss = 2.16317382, grad/param norm = 3.3792e-01, time/batch = 0.6375s	
843/11850 (epoch 3.557), train_loss = 2.37661521, grad/param norm = 2.8689e-01, time/batch = 0.6360s	
844/11850 (epoch 3.561), train_loss = 2.09797275, grad/param norm = 2.6146e-01, time/batch = 0.6410s	
845/11850 (epoch 3.565), train_loss = 2.20999530, grad/param norm = 3.1932e-01, time/batch = 0.6480s	
846/11850 (epoch 3.570), train_loss = 2.04010471, grad/param norm = 2.9941e-01, time/batch = 0.6501s	
847/11850 (epoch 3.574), train_loss = 2.17884517, grad/param norm = 2.6474e-01, time/batch = 0.6645s	
848/11850 (epoch 3.578), train_loss = 2.22529088, grad/param norm = 2.4787e-01, time/batch = 0.6579s	
849/11850 (epoch 3.582), train_loss = 2.10236764, grad/param norm = 2.4899e-01, time/batch = 0.6461s	
850/11850 (epoch 3.586), train_loss = 2.14787984, grad/param norm = 3.7209e-01, time/batch = 0.6366s	
851/11850 (epoch 3.591), train_loss = 2.21755250, grad/param norm = 3.7086e-01, time/batch = 0.6448s	
852/11850 (epoch 3.595), train_loss = 2.01447511, grad/param norm = 3.2648e-01, time/batch = 0.6478s	
853/11850 (epoch 3.599), train_loss = 1.97246500, grad/param norm = 2.7224e-01, time/batch = 0.6382s	
854/11850 (epoch 3.603), train_loss = 2.03425229, grad/param norm = 2.3407e-01, time/batch = 0.6428s	
855/11850 (epoch 3.608), train_loss = 2.22110636, grad/param norm = 2.9161e-01, time/batch = 0.6374s	
856/11850 (epoch 3.612), train_loss = 2.27112125, grad/param norm = 2.4278e-01, time/batch = 0.6381s	
857/11850 (epoch 3.616), train_loss = 2.20129292, grad/param norm = 2.8176e-01, time/batch = 0.6354s	
858/11850 (epoch 3.620), train_loss = 2.06646986, grad/param norm = 3.1418e-01, time/batch = 0.6384s	
859/11850 (epoch 3.624), train_loss = 2.22478784, grad/param norm = 2.7917e-01, time/batch = 0.6392s	
860/11850 (epoch 3.629), train_loss = 2.20774132, grad/param norm = 2.7538e-01, time/batch = 0.6384s	
861/11850 (epoch 3.633), train_loss = 2.03701198, grad/param norm = 2.8665e-01, time/batch = 0.6396s	
862/11850 (epoch 3.637), train_loss = 2.02639829, grad/param norm = 2.8138e-01, time/batch = 0.6384s	
863/11850 (epoch 3.641), train_loss = 2.08721300, grad/param norm = 2.8716e-01, time/batch = 0.6377s	
864/11850 (epoch 3.646), train_loss = 2.12609780, grad/param norm = 2.4783e-01, time/batch = 0.6445s	
865/11850 (epoch 3.650), train_loss = 2.09781950, grad/param norm = 3.1379e-01, time/batch = 0.6369s	
866/11850 (epoch 3.654), train_loss = 2.24177335, grad/param norm = 4.4141e-01, time/batch = 0.6419s	
867/11850 (epoch 3.658), train_loss = 2.13796336, grad/param norm = 4.5248e-01, time/batch = 0.6481s	
868/11850 (epoch 3.662), train_loss = 2.10262005, grad/param norm = 3.8136e-01, time/batch = 0.6352s	
869/11850 (epoch 3.667), train_loss = 2.05256813, grad/param norm = 2.5700e-01, time/batch = 0.6321s	
870/11850 (epoch 3.671), train_loss = 1.98832657, grad/param norm = 2.8275e-01, time/batch = 0.6378s	
871/11850 (epoch 3.675), train_loss = 2.15721251, grad/param norm = 3.3624e-01, time/batch = 0.6472s	
872/11850 (epoch 3.679), train_loss = 2.21966921, grad/param norm = 3.3150e-01, time/batch = 0.6570s	
873/11850 (epoch 3.684), train_loss = 2.14858513, grad/param norm = 3.4689e-01, time/batch = 0.6375s	
874/11850 (epoch 3.688), train_loss = 2.10239020, grad/param norm = 3.1160e-01, time/batch = 0.6470s	
875/11850 (epoch 3.692), train_loss = 2.17400031, grad/param norm = 3.2138e-01, time/batch = 0.6468s	
876/11850 (epoch 3.696), train_loss = 2.15534653, grad/param norm = 3.1767e-01, time/batch = 0.6392s	
877/11850 (epoch 3.700), train_loss = 2.09607153, grad/param norm = 3.3191e-01, time/batch = 0.6360s	
878/11850 (epoch 3.705), train_loss = 2.13895070, grad/param norm = 3.4464e-01, time/batch = 0.6423s	
879/11850 (epoch 3.709), train_loss = 2.14948847, grad/param norm = 3.1068e-01, time/batch = 0.6411s	
880/11850 (epoch 3.713), train_loss = 2.07821242, grad/param norm = 2.6084e-01, time/batch = 0.6402s	
881/11850 (epoch 3.717), train_loss = 1.92907954, grad/param norm = 2.6014e-01, time/batch = 0.6394s	
882/11850 (epoch 3.722), train_loss = 2.27707783, grad/param norm = 2.9992e-01, time/batch = 0.6359s	
883/11850 (epoch 3.726), train_loss = 2.05003013, grad/param norm = 3.1609e-01, time/batch = 0.6350s	
884/11850 (epoch 3.730), train_loss = 2.01992416, grad/param norm = 3.3933e-01, time/batch = 0.6399s	
885/11850 (epoch 3.734), train_loss = 2.04972491, grad/param norm = 3.1245e-01, time/batch = 0.6391s	
886/11850 (epoch 3.738), train_loss = 2.16413302, grad/param norm = 3.5237e-01, time/batch = 0.6356s	
887/11850 (epoch 3.743), train_loss = 2.14969943, grad/param norm = 3.3226e-01, time/batch = 0.6392s	
888/11850 (epoch 3.747), train_loss = 2.11141574, grad/param norm = 3.9086e-01, time/batch = 0.6375s	
889/11850 (epoch 3.751), train_loss = 2.00573513, grad/param norm = 3.9631e-01, time/batch = 0.6398s	
890/11850 (epoch 3.755), train_loss = 2.10902461, grad/param norm = 3.4739e-01, time/batch = 0.6536s	
891/11850 (epoch 3.759), train_loss = 2.02056324, grad/param norm = 3.0683e-01, time/batch = 0.6550s	
892/11850 (epoch 3.764), train_loss = 2.04670583, grad/param norm = 2.6553e-01, time/batch = 0.6470s	
893/11850 (epoch 3.768), train_loss = 1.87838718, grad/param norm = 2.3943e-01, time/batch = 0.6558s	
894/11850 (epoch 3.772), train_loss = 2.09777827, grad/param norm = 3.0771e-01, time/batch = 0.6690s	
895/11850 (epoch 3.776), train_loss = 2.11994210, grad/param norm = 3.4516e-01, time/batch = 0.6441s	
896/11850 (epoch 3.781), train_loss = 1.97575530, grad/param norm = 2.7856e-01, time/batch = 0.6381s	
897/11850 (epoch 3.785), train_loss = 2.03683347, grad/param norm = 2.4947e-01, time/batch = 0.6423s	
898/11850 (epoch 3.789), train_loss = 2.22705033, grad/param norm = 3.5019e-01, time/batch = 0.6381s	
899/11850 (epoch 3.793), train_loss = 2.27373719, grad/param norm = 2.8718e-01, time/batch = 0.6371s	
900/11850 (epoch 3.797), train_loss = 2.13346148, grad/param norm = 2.4096e-01, time/batch = 0.6376s	
901/11850 (epoch 3.802), train_loss = 2.12510620, grad/param norm = 2.7671e-01, time/batch = 0.6403s	
902/11850 (epoch 3.806), train_loss = 2.09261624, grad/param norm = 2.8367e-01, time/batch = 0.6372s	
903/11850 (epoch 3.810), train_loss = 2.26136287, grad/param norm = 3.4599e-01, time/batch = 0.6401s	
904/11850 (epoch 3.814), train_loss = 2.07658576, grad/param norm = 4.7079e-01, time/batch = 0.6605s	
905/11850 (epoch 3.819), train_loss = 2.17848778, grad/param norm = 3.6415e-01, time/batch = 0.6628s	
906/11850 (epoch 3.823), train_loss = 2.20790172, grad/param norm = 3.6683e-01, time/batch = 0.6408s	
907/11850 (epoch 3.827), train_loss = 2.09484553, grad/param norm = 3.5458e-01, time/batch = 0.6420s	
908/11850 (epoch 3.831), train_loss = 2.11367989, grad/param norm = 3.3504e-01, time/batch = 0.6393s	
909/11850 (epoch 3.835), train_loss = 2.10424974, grad/param norm = 3.5696e-01, time/batch = 0.6400s	
910/11850 (epoch 3.840), train_loss = 1.98138021, grad/param norm = 2.9591e-01, time/batch = 0.6409s	
911/11850 (epoch 3.844), train_loss = 2.07708876, grad/param norm = 2.5251e-01, time/batch = 0.6432s	
912/11850 (epoch 3.848), train_loss = 2.22607241, grad/param norm = 2.9273e-01, time/batch = 0.6405s	
913/11850 (epoch 3.852), train_loss = 2.12708177, grad/param norm = 3.5337e-01, time/batch = 0.6395s	
914/11850 (epoch 3.857), train_loss = 2.14219979, grad/param norm = 3.3935e-01, time/batch = 0.6379s	
915/11850 (epoch 3.861), train_loss = 2.19638448, grad/param norm = 2.6555e-01, time/batch = 0.6360s	
916/11850 (epoch 3.865), train_loss = 2.19458174, grad/param norm = 3.0433e-01, time/batch = 0.6389s	
917/11850 (epoch 3.869), train_loss = 2.33844095, grad/param norm = 3.0289e-01, time/batch = 0.6462s	
918/11850 (epoch 3.873), train_loss = 2.17482949, grad/param norm = 3.0638e-01, time/batch = 0.6355s	
919/11850 (epoch 3.878), train_loss = 2.13366224, grad/param norm = 3.3986e-01, time/batch = 0.6365s	
920/11850 (epoch 3.882), train_loss = 2.09678762, grad/param norm = 2.7196e-01, time/batch = 0.6431s	
921/11850 (epoch 3.886), train_loss = 2.16988843, grad/param norm = 3.1311e-01, time/batch = 0.6512s	
922/11850 (epoch 3.890), train_loss = 2.08906295, grad/param norm = 2.6996e-01, time/batch = 0.6577s	
923/11850 (epoch 3.895), train_loss = 2.12190056, grad/param norm = 2.8043e-01, time/batch = 0.6667s	
924/11850 (epoch 3.899), train_loss = 2.12526436, grad/param norm = 3.2348e-01, time/batch = 0.6693s	
925/11850 (epoch 3.903), train_loss = 2.07816246, grad/param norm = 2.4910e-01, time/batch = 0.6795s	
926/11850 (epoch 3.907), train_loss = 2.03485206, grad/param norm = 2.7705e-01, time/batch = 0.6668s	
927/11850 (epoch 3.911), train_loss = 2.03182631, grad/param norm = 2.8240e-01, time/batch = 0.6674s	
928/11850 (epoch 3.916), train_loss = 2.27917337, grad/param norm = 3.4334e-01, time/batch = 0.6652s	
929/11850 (epoch 3.920), train_loss = 1.95546748, grad/param norm = 3.8957e-01, time/batch = 0.6560s	
930/11850 (epoch 3.924), train_loss = 2.08076639, grad/param norm = 3.2455e-01, time/batch = 0.6529s	
931/11850 (epoch 3.928), train_loss = 2.26497483, grad/param norm = 3.0832e-01, time/batch = 0.6417s	
932/11850 (epoch 3.932), train_loss = 2.23793522, grad/param norm = 3.8331e-01, time/batch = 0.6410s	
933/11850 (epoch 3.937), train_loss = 2.23330312, grad/param norm = 3.2180e-01, time/batch = 0.6453s	
934/11850 (epoch 3.941), train_loss = 2.16160517, grad/param norm = 3.4648e-01, time/batch = 0.6462s	
935/11850 (epoch 3.945), train_loss = 2.19818432, grad/param norm = 2.7712e-01, time/batch = 0.6492s	
936/11850 (epoch 3.949), train_loss = 2.16422554, grad/param norm = 3.2790e-01, time/batch = 0.6466s	
937/11850 (epoch 3.954), train_loss = 2.28895889, grad/param norm = 2.9785e-01, time/batch = 0.6527s	
938/11850 (epoch 3.958), train_loss = 2.10387675, grad/param norm = 3.0247e-01, time/batch = 0.6341s	
939/11850 (epoch 3.962), train_loss = 2.14424620, grad/param norm = 3.6147e-01, time/batch = 0.6276s	
940/11850 (epoch 3.966), train_loss = 2.10596284, grad/param norm = 4.0954e-01, time/batch = 0.6265s	
941/11850 (epoch 3.970), train_loss = 2.12457214, grad/param norm = 3.5378e-01, time/batch = 0.6311s	
942/11850 (epoch 3.975), train_loss = 2.20551347, grad/param norm = 2.9984e-01, time/batch = 0.6302s	
943/11850 (epoch 3.979), train_loss = 2.32720844, grad/param norm = 4.7620e-01, time/batch = 0.6246s	
944/11850 (epoch 3.983), train_loss = 2.56699254, grad/param norm = 5.3065e-01, time/batch = 0.6259s	
945/11850 (epoch 3.987), train_loss = 2.20188826, grad/param norm = 3.0513e-01, time/batch = 0.6247s	
946/11850 (epoch 3.992), train_loss = 2.17055137, grad/param norm = 2.4586e-01, time/batch = 0.6233s	
947/11850 (epoch 3.996), train_loss = 2.39155719, grad/param norm = 2.4297e-01, time/batch = 0.6244s	
948/11850 (epoch 4.000), train_loss = 2.17883764, grad/param norm = 2.6488e-01, time/batch = 0.6223s	
949/11850 (epoch 4.004), train_loss = 2.14527063, grad/param norm = 2.5401e-01, time/batch = 0.6222s	
950/11850 (epoch 4.008), train_loss = 2.10340366, grad/param norm = 2.4299e-01, time/batch = 0.6282s	
951/11850 (epoch 4.013), train_loss = 2.10257126, grad/param norm = 2.2476e-01, time/batch = 0.6277s	
952/11850 (epoch 4.017), train_loss = 2.27851783, grad/param norm = 2.5446e-01, time/batch = 0.6300s	
953/11850 (epoch 4.021), train_loss = 2.00507695, grad/param norm = 2.5857e-01, time/batch = 0.6316s	
954/11850 (epoch 4.025), train_loss = 1.81628823, grad/param norm = 2.1034e-01, time/batch = 0.6273s	
955/11850 (epoch 4.030), train_loss = 1.97136679, grad/param norm = 2.3120e-01, time/batch = 0.6291s	
956/11850 (epoch 4.034), train_loss = 2.02631510, grad/param norm = 2.5956e-01, time/batch = 0.6341s	
957/11850 (epoch 4.038), train_loss = 2.03945125, grad/param norm = 2.9441e-01, time/batch = 0.6318s	
958/11850 (epoch 4.042), train_loss = 2.10657042, grad/param norm = 2.3764e-01, time/batch = 0.6315s	
959/11850 (epoch 4.046), train_loss = 2.25189351, grad/param norm = 2.6462e-01, time/batch = 0.6275s	
960/11850 (epoch 4.051), train_loss = 2.04532914, grad/param norm = 3.0500e-01, time/batch = 0.6263s	
961/11850 (epoch 4.055), train_loss = 2.14287736, grad/param norm = 3.6783e-01, time/batch = 0.6276s	
962/11850 (epoch 4.059), train_loss = 2.17862974, grad/param norm = 3.5247e-01, time/batch = 0.6268s	
963/11850 (epoch 4.063), train_loss = 2.13016757, grad/param norm = 2.8592e-01, time/batch = 0.6387s	
964/11850 (epoch 4.068), train_loss = 2.06264549, grad/param norm = 2.7737e-01, time/batch = 0.6311s	
965/11850 (epoch 4.072), train_loss = 2.05986362, grad/param norm = 2.5240e-01, time/batch = 0.6256s	
966/11850 (epoch 4.076), train_loss = 2.17791862, grad/param norm = 2.4289e-01, time/batch = 0.6251s	
967/11850 (epoch 4.080), train_loss = 2.16427491, grad/param norm = 2.6538e-01, time/batch = 0.6265s	
968/11850 (epoch 4.084), train_loss = 1.96713942, grad/param norm = 2.6609e-01, time/batch = 0.6251s	
969/11850 (epoch 4.089), train_loss = 1.96539034, grad/param norm = 2.1322e-01, time/batch = 0.6217s	
970/11850 (epoch 4.093), train_loss = 1.94070834, grad/param norm = 2.4198e-01, time/batch = 0.6248s	
971/11850 (epoch 4.097), train_loss = 2.32957132, grad/param norm = 3.0497e-01, time/batch = 0.6238s	
972/11850 (epoch 4.101), train_loss = 2.22624659, grad/param norm = 3.5760e-01, time/batch = 0.6263s	
973/11850 (epoch 4.105), train_loss = 2.00443724, grad/param norm = 2.8606e-01, time/batch = 0.6234s	
974/11850 (epoch 4.110), train_loss = 2.00332424, grad/param norm = 2.5363e-01, time/batch = 0.6399s	
975/11850 (epoch 4.114), train_loss = 2.16284356, grad/param norm = 3.1446e-01, time/batch = 0.6568s	
976/11850 (epoch 4.118), train_loss = 2.02366041, grad/param norm = 3.6401e-01, time/batch = 0.6329s	
977/11850 (epoch 4.122), train_loss = 2.12273163, grad/param norm = 3.2213e-01, time/batch = 0.6189s	
978/11850 (epoch 4.127), train_loss = 2.21191787, grad/param norm = 3.1494e-01, time/batch = 0.6229s	
979/11850 (epoch 4.131), train_loss = 2.21336381, grad/param norm = 3.3137e-01, time/batch = 0.6218s	
980/11850 (epoch 4.135), train_loss = 2.06603086, grad/param norm = 3.0135e-01, time/batch = 0.6205s	
981/11850 (epoch 4.139), train_loss = 2.16427184, grad/param norm = 2.6497e-01, time/batch = 0.6207s	
982/11850 (epoch 4.143), train_loss = 2.07120297, grad/param norm = 2.8816e-01, time/batch = 0.6226s	
983/11850 (epoch 4.148), train_loss = 2.11713811, grad/param norm = 3.4009e-01, time/batch = 0.6402s	
984/11850 (epoch 4.152), train_loss = 2.09389969, grad/param norm = 3.7997e-01, time/batch = 0.6386s	
985/11850 (epoch 4.156), train_loss = 2.18250553, grad/param norm = 2.7936e-01, time/batch = 0.6384s	
986/11850 (epoch 4.160), train_loss = 2.43053272, grad/param norm = 2.9418e-01, time/batch = 0.6456s	
987/11850 (epoch 4.165), train_loss = 2.22389548, grad/param norm = 2.7170e-01, time/batch = 0.6268s	
988/11850 (epoch 4.169), train_loss = 2.03788280, grad/param norm = 3.1723e-01, time/batch = 0.6303s	
989/11850 (epoch 4.173), train_loss = 2.15651848, grad/param norm = 2.9553e-01, time/batch = 0.6568s	
990/11850 (epoch 4.177), train_loss = 2.17442366, grad/param norm = 2.8872e-01, time/batch = 0.6393s	
991/11850 (epoch 4.181), train_loss = 2.05270688, grad/param norm = 2.8469e-01, time/batch = 0.6407s	
992/11850 (epoch 4.186), train_loss = 2.25772930, grad/param norm = 3.0593e-01, time/batch = 0.6296s	
993/11850 (epoch 4.190), train_loss = 2.11256056, grad/param norm = 2.5404e-01, time/batch = 0.6279s	
994/11850 (epoch 4.194), train_loss = 2.24018289, grad/param norm = 2.7953e-01, time/batch = 0.6232s	
995/11850 (epoch 4.198), train_loss = 2.03804422, grad/param norm = 3.0092e-01, time/batch = 0.6244s	
996/11850 (epoch 4.203), train_loss = 1.85051466, grad/param norm = 2.2206e-01, time/batch = 0.6284s	
997/11850 (epoch 4.207), train_loss = 2.17511732, grad/param norm = 2.9003e-01, time/batch = 0.6208s	
998/11850 (epoch 4.211), train_loss = 2.06790358, grad/param norm = 2.3930e-01, time/batch = 0.6221s	
999/11850 (epoch 4.215), train_loss = 2.07051731, grad/param norm = 2.5220e-01, time/batch = 0.6234s	
evaluating loss over split index 2	
1/13...	
2/13...	
3/13...	
4/13...	
5/13...	
6/13...	
7/13...	
8/13...	
9/13...	
10/13...	
11/13...	
12/13...	
13/13...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_katelyn_salem_epoch4.22_2.1346.t7	
1000/11850 (epoch 4.219), train_loss = 1.94199566, grad/param norm = 2.4919e-01, time/batch = 0.6246s	
1001/11850 (epoch 4.224), train_loss = 2.35850604, grad/param norm = 2.6281e-01, time/batch = 0.6584s	
1002/11850 (epoch 4.228), train_loss = 2.20849658, grad/param norm = 2.7018e-01, time/batch = 0.6420s	
1003/11850 (epoch 4.232), train_loss = 2.12422715, grad/param norm = 3.0894e-01, time/batch = 0.6255s	
1004/11850 (epoch 4.236), train_loss = 2.05301528, grad/param norm = 2.6283e-01, time/batch = 0.6247s	
1005/11850 (epoch 4.241), train_loss = 2.21099935, grad/param norm = 3.0507e-01, time/batch = 0.6247s	
1006/11850 (epoch 4.245), train_loss = 2.15712779, grad/param norm = 3.3612e-01, time/batch = 0.6212s	
1007/11850 (epoch 4.249), train_loss = 2.02667538, grad/param norm = 2.7770e-01, time/batch = 0.6222s	
1008/11850 (epoch 4.253), train_loss = 2.14243290, grad/param norm = 2.7294e-01, time/batch = 0.6292s	
1009/11850 (epoch 4.257), train_loss = 2.13652652, grad/param norm = 3.5051e-01, time/batch = 0.6281s	
1010/11850 (epoch 4.262), train_loss = 2.19828149, grad/param norm = 3.1692e-01, time/batch = 0.6272s	
1011/11850 (epoch 4.266), train_loss = 2.12853001, grad/param norm = 2.7464e-01, time/batch = 0.6241s	
1012/11850 (epoch 4.270), train_loss = 2.08267510, grad/param norm = 2.4411e-01, time/batch = 0.6246s	
1013/11850 (epoch 4.274), train_loss = 2.04022996, grad/param norm = 2.8015e-01, time/batch = 0.6307s	
1014/11850 (epoch 4.278), train_loss = 1.98076317, grad/param norm = 3.1371e-01, time/batch = 0.6604s	
1015/11850 (epoch 4.283), train_loss = 1.99768896, grad/param norm = 3.0781e-01, time/batch = 0.6578s	
1016/11850 (epoch 4.287), train_loss = 2.07238516, grad/param norm = 2.7477e-01, time/batch = 0.6477s	
1017/11850 (epoch 4.291), train_loss = 2.15979262, grad/param norm = 2.7490e-01, time/batch = 0.6428s	
1018/11850 (epoch 4.295), train_loss = 2.07492261, grad/param norm = 2.8491e-01, time/batch = 0.6425s	
1019/11850 (epoch 4.300), train_loss = 1.95747791, grad/param norm = 3.1502e-01, time/batch = 0.6401s	
1020/11850 (epoch 4.304), train_loss = 2.02685323, grad/param norm = 2.7762e-01, time/batch = 0.6470s	
1021/11850 (epoch 4.308), train_loss = 1.90879452, grad/param norm = 2.4180e-01, time/batch = 0.6450s	
1022/11850 (epoch 4.312), train_loss = 1.89583901, grad/param norm = 2.4527e-01, time/batch = 0.6396s	
1023/11850 (epoch 4.316), train_loss = 2.01723168, grad/param norm = 2.6989e-01, time/batch = 0.6290s	
1024/11850 (epoch 4.321), train_loss = 2.02326868, grad/param norm = 2.8240e-01, time/batch = 0.6401s	
1025/11850 (epoch 4.325), train_loss = 2.11536800, grad/param norm = 2.6813e-01, time/batch = 0.6510s	
1026/11850 (epoch 4.329), train_loss = 2.08864286, grad/param norm = 3.0408e-01, time/batch = 0.6417s	
1027/11850 (epoch 4.333), train_loss = 2.08225878, grad/param norm = 2.8753e-01, time/batch = 0.6573s	
1028/11850 (epoch 4.338), train_loss = 1.96083550, grad/param norm = 2.5529e-01, time/batch = 0.6565s	
1029/11850 (epoch 4.342), train_loss = 2.25513285, grad/param norm = 3.4833e-01, time/batch = 0.6571s	
1030/11850 (epoch 4.346), train_loss = 2.12969156, grad/param norm = 3.2727e-01, time/batch = 0.6584s	
1031/11850 (epoch 4.350), train_loss = 1.92179278, grad/param norm = 2.6176e-01, time/batch = 0.6591s	
1032/11850 (epoch 4.354), train_loss = 2.21166787, grad/param norm = 3.5014e-01, time/batch = 0.6629s	
1033/11850 (epoch 4.359), train_loss = 2.12221808, grad/param norm = 3.9477e-01, time/batch = 0.6637s	
1034/11850 (epoch 4.363), train_loss = 2.00323139, grad/param norm = 2.9814e-01, time/batch = 0.6503s	
1035/11850 (epoch 4.367), train_loss = 2.04475839, grad/param norm = 2.4349e-01, time/batch = 0.6457s	
1036/11850 (epoch 4.371), train_loss = 2.04486945, grad/param norm = 2.5255e-01, time/batch = 0.6281s	
1037/11850 (epoch 4.376), train_loss = 2.02530861, grad/param norm = 2.4800e-01, time/batch = 0.6478s	
1038/11850 (epoch 4.380), train_loss = 1.98272293, grad/param norm = 2.9423e-01, time/batch = 0.6260s	
1039/11850 (epoch 4.384), train_loss = 2.06245667, grad/param norm = 2.8780e-01, time/batch = 0.6240s	
1040/11850 (epoch 4.388), train_loss = 2.08580911, grad/param norm = 2.7718e-01, time/batch = 0.6257s	
1041/11850 (epoch 4.392), train_loss = 2.10084146, grad/param norm = 2.3675e-01, time/batch = 0.6344s	
1042/11850 (epoch 4.397), train_loss = 2.21645590, grad/param norm = 2.9363e-01, time/batch = 0.6288s	
1043/11850 (epoch 4.401), train_loss = 1.83980563, grad/param norm = 2.5273e-01, time/batch = 0.6295s	
1044/11850 (epoch 4.405), train_loss = 2.02161519, grad/param norm = 2.5776e-01, time/batch = 0.6311s	
1045/11850 (epoch 4.409), train_loss = 2.17703744, grad/param norm = 2.8786e-01, time/batch = 0.6386s	
1046/11850 (epoch 4.414), train_loss = 1.93997963, grad/param norm = 3.1420e-01, time/batch = 0.6275s	
1047/11850 (epoch 4.418), train_loss = 1.93789074, grad/param norm = 2.8244e-01, time/batch = 0.6316s	
1048/11850 (epoch 4.422), train_loss = 1.95560275, grad/param norm = 2.7131e-01, time/batch = 0.6290s	
1049/11850 (epoch 4.426), train_loss = 2.05261224, grad/param norm = 2.7774e-01, time/batch = 0.6274s	
1050/11850 (epoch 4.430), train_loss = 1.96708001, grad/param norm = 2.6260e-01, time/batch = 0.6319s	
1051/11850 (epoch 4.435), train_loss = 1.97826061, grad/param norm = 2.8147e-01, time/batch = 0.6307s	
1052/11850 (epoch 4.439), train_loss = 2.14725615, grad/param norm = 2.9775e-01, time/batch = 0.6524s	
1053/11850 (epoch 4.443), train_loss = 2.16490812, grad/param norm = 2.3821e-01, time/batch = 0.6499s	
1054/11850 (epoch 4.447), train_loss = 2.03250876, grad/param norm = 2.4282e-01, time/batch = 0.6250s	
1055/11850 (epoch 4.451), train_loss = 1.96369096, grad/param norm = 2.8145e-01, time/batch = 0.6246s	
1056/11850 (epoch 4.456), train_loss = 2.16994265, grad/param norm = 3.7425e-01, time/batch = 0.6223s	
1057/11850 (epoch 4.460), train_loss = 2.12622041, grad/param norm = 2.7342e-01, time/batch = 0.6268s	
1058/11850 (epoch 4.464), train_loss = 2.09083052, grad/param norm = 3.1480e-01, time/batch = 0.6218s	
1059/11850 (epoch 4.468), train_loss = 2.08162500, grad/param norm = 2.6407e-01, time/batch = 0.6246s	
1060/11850 (epoch 4.473), train_loss = 2.10424882, grad/param norm = 2.9950e-01, time/batch = 0.6226s	
1061/11850 (epoch 4.477), train_loss = 1.88173068, grad/param norm = 2.7445e-01, time/batch = 0.6310s	
1062/11850 (epoch 4.481), train_loss = 1.97937350, grad/param norm = 3.7297e-01, time/batch = 0.6455s	
1063/11850 (epoch 4.485), train_loss = 1.85064531, grad/param norm = 3.6987e-01, time/batch = 0.6459s	
1064/11850 (epoch 4.489), train_loss = 2.07434008, grad/param norm = 2.6432e-01, time/batch = 0.6365s	
1065/11850 (epoch 4.494), train_loss = 2.01995511, grad/param norm = 2.3811e-01, time/batch = 0.6386s	
1066/11850 (epoch 4.498), train_loss = 2.09743996, grad/param norm = 2.8404e-01, time/batch = 0.6344s	
1067/11850 (epoch 4.502), train_loss = 1.94678440, grad/param norm = 2.7136e-01, time/batch = 0.6250s	
1068/11850 (epoch 4.506), train_loss = 2.16431307, grad/param norm = 2.8581e-01, time/batch = 0.6301s	
1069/11850 (epoch 4.511), train_loss = 1.96955479, grad/param norm = 2.4397e-01, time/batch = 0.6234s	
1070/11850 (epoch 4.515), train_loss = 2.17921670, grad/param norm = 3.2073e-01, time/batch = 0.6211s	
1071/11850 (epoch 4.519), train_loss = 1.99222461, grad/param norm = 2.8132e-01, time/batch = 0.6230s	
1072/11850 (epoch 4.523), train_loss = 2.02149471, grad/param norm = 2.3852e-01, time/batch = 0.6223s	
1073/11850 (epoch 4.527), train_loss = 1.98390210, grad/param norm = 3.3424e-01, time/batch = 0.6229s	
1074/11850 (epoch 4.532), train_loss = 2.15221433, grad/param norm = 3.2351e-01, time/batch = 0.6471s	
1075/11850 (epoch 4.536), train_loss = 1.96189792, grad/param norm = 2.6501e-01, time/batch = 0.6539s	
1076/11850 (epoch 4.540), train_loss = 1.90299536, grad/param norm = 2.1809e-01, time/batch = 0.6352s	
1077/11850 (epoch 4.544), train_loss = 2.01472100, grad/param norm = 2.8829e-01, time/batch = 0.6302s	
1078/11850 (epoch 4.549), train_loss = 1.74025627, grad/param norm = 2.9231e-01, time/batch = 0.6269s	
1079/11850 (epoch 4.553), train_loss = 2.05340092, grad/param norm = 2.9214e-01, time/batch = 0.6303s	
1080/11850 (epoch 4.557), train_loss = 2.24648192, grad/param norm = 2.4085e-01, time/batch = 0.6255s	
1081/11850 (epoch 4.561), train_loss = 1.97343307, grad/param norm = 2.4149e-01, time/batch = 0.6332s	
1082/11850 (epoch 4.565), train_loss = 2.12562637, grad/param norm = 2.9139e-01, time/batch = 0.6273s	
1083/11850 (epoch 4.570), train_loss = 1.91551546, grad/param norm = 2.7536e-01, time/batch = 0.6245s	
1084/11850 (epoch 4.574), train_loss = 2.06256575, grad/param norm = 2.6446e-01, time/batch = 0.6257s	
1085/11850 (epoch 4.578), train_loss = 2.12793373, grad/param norm = 2.4350e-01, time/batch = 0.6262s	
1086/11850 (epoch 4.582), train_loss = 1.98186005, grad/param norm = 2.4089e-01, time/batch = 0.6253s	
1087/11850 (epoch 4.586), train_loss = 2.00620034, grad/param norm = 3.0304e-01, time/batch = 0.6268s	
1088/11850 (epoch 4.591), train_loss = 2.09938150, grad/param norm = 3.2907e-01, time/batch = 0.6274s	
1089/11850 (epoch 4.595), train_loss = 1.86054837, grad/param norm = 2.7501e-01, time/batch = 0.6264s	
1090/11850 (epoch 4.599), train_loss = 1.85868330, grad/param norm = 2.5952e-01, time/batch = 0.6283s	
1091/11850 (epoch 4.603), train_loss = 1.90922502, grad/param norm = 2.2331e-01, time/batch = 0.6291s	
1092/11850 (epoch 4.608), train_loss = 2.10527903, grad/param norm = 2.7218e-01, time/batch = 0.6284s	
1093/11850 (epoch 4.612), train_loss = 2.17251077, grad/param norm = 2.3131e-01, time/batch = 0.6327s	
1094/11850 (epoch 4.616), train_loss = 2.10742769, grad/param norm = 2.6209e-01, time/batch = 0.6279s	
1095/11850 (epoch 4.620), train_loss = 1.94058321, grad/param norm = 2.8345e-01, time/batch = 0.6256s	
1096/11850 (epoch 4.624), train_loss = 2.12205932, grad/param norm = 2.5188e-01, time/batch = 0.6282s	
1097/11850 (epoch 4.629), train_loss = 2.05208215, grad/param norm = 2.6008e-01, time/batch = 0.6259s	
1098/11850 (epoch 4.633), train_loss = 1.87090815, grad/param norm = 2.4917e-01, time/batch = 0.6256s	
1099/11850 (epoch 4.637), train_loss = 1.88188273, grad/param norm = 2.4268e-01, time/batch = 0.6236s	
1100/11850 (epoch 4.641), train_loss = 1.95050944, grad/param norm = 2.6041e-01, time/batch = 0.6242s	
1101/11850 (epoch 4.646), train_loss = 2.01584224, grad/param norm = 2.4852e-01, time/batch = 0.6254s	
1102/11850 (epoch 4.650), train_loss = 1.98649977, grad/param norm = 2.8579e-01, time/batch = 0.6218s	
1103/11850 (epoch 4.654), train_loss = 2.07802568, grad/param norm = 3.1010e-01, time/batch = 0.6232s	
1104/11850 (epoch 4.658), train_loss = 2.00322413, grad/param norm = 3.2034e-01, time/batch = 0.6303s	
1105/11850 (epoch 4.662), train_loss = 1.98451893, grad/param norm = 3.0433e-01, time/batch = 0.6267s	
1106/11850 (epoch 4.667), train_loss = 1.96698369, grad/param norm = 2.4770e-01, time/batch = 0.6274s	
1107/11850 (epoch 4.671), train_loss = 1.88296250, grad/param norm = 2.8777e-01, time/batch = 0.6349s	
1108/11850 (epoch 4.675), train_loss = 2.03217578, grad/param norm = 3.0556e-01, time/batch = 0.6541s	
1109/11850 (epoch 4.679), train_loss = 2.08325248, grad/param norm = 2.6117e-01, time/batch = 0.6581s	
1110/11850 (epoch 4.684), train_loss = 2.04365097, grad/param norm = 3.0177e-01, time/batch = 0.6402s	
1111/11850 (epoch 4.688), train_loss = 1.96982890, grad/param norm = 2.7342e-01, time/batch = 0.6339s	
1112/11850 (epoch 4.692), train_loss = 2.06435637, grad/param norm = 3.0382e-01, time/batch = 0.6267s	
1113/11850 (epoch 4.696), train_loss = 2.01131466, grad/param norm = 3.1986e-01, time/batch = 0.6316s	
1114/11850 (epoch 4.700), train_loss = 1.98953360, grad/param norm = 3.1539e-01, time/batch = 0.6288s	
1115/11850 (epoch 4.705), train_loss = 2.01237136, grad/param norm = 2.8955e-01, time/batch = 0.6286s	
1116/11850 (epoch 4.709), train_loss = 2.01935451, grad/param norm = 2.8325e-01, time/batch = 0.6258s	
1117/11850 (epoch 4.713), train_loss = 1.96144505, grad/param norm = 2.4685e-01, time/batch = 0.6347s	
1118/11850 (epoch 4.717), train_loss = 1.80891216, grad/param norm = 2.3885e-01, time/batch = 0.6267s	
1119/11850 (epoch 4.722), train_loss = 2.15106775, grad/param norm = 2.7365e-01, time/batch = 0.6269s	
1120/11850 (epoch 4.726), train_loss = 1.89650818, grad/param norm = 2.7712e-01, time/batch = 0.6371s	
1121/11850 (epoch 4.730), train_loss = 1.87809002, grad/param norm = 2.9126e-01, time/batch = 0.6484s	
1122/11850 (epoch 4.734), train_loss = 1.92709476, grad/param norm = 2.6466e-01, time/batch = 0.6270s	
1123/11850 (epoch 4.738), train_loss = 2.05974751, grad/param norm = 3.3700e-01, time/batch = 0.6302s	
1124/11850 (epoch 4.743), train_loss = 2.03279347, grad/param norm = 3.0783e-01, time/batch = 0.6300s	
1125/11850 (epoch 4.747), train_loss = 1.95261952, grad/param norm = 3.6641e-01, time/batch = 0.6435s	
1126/11850 (epoch 4.751), train_loss = 1.87161922, grad/param norm = 3.5674e-01, time/batch = 0.6391s	
1127/11850 (epoch 4.755), train_loss = 1.96782143, grad/param norm = 2.9353e-01, time/batch = 0.6295s	
1128/11850 (epoch 4.759), train_loss = 1.88624012, grad/param norm = 2.6359e-01, time/batch = 0.6292s	
1129/11850 (epoch 4.764), train_loss = 1.91302637, grad/param norm = 2.5353e-01, time/batch = 0.6249s	
1130/11850 (epoch 4.768), train_loss = 1.78266198, grad/param norm = 2.3789e-01, time/batch = 0.6250s	
1131/11850 (epoch 4.772), train_loss = 1.98716740, grad/param norm = 2.5560e-01, time/batch = 0.6288s	
1132/11850 (epoch 4.776), train_loss = 2.01350042, grad/param norm = 3.3354e-01, time/batch = 0.6245s	
1133/11850 (epoch 4.781), train_loss = 1.86838262, grad/param norm = 2.6728e-01, time/batch = 0.6253s	
1134/11850 (epoch 4.785), train_loss = 1.92120225, grad/param norm = 2.4018e-01, time/batch = 0.6249s	
1135/11850 (epoch 4.789), train_loss = 2.08531271, grad/param norm = 2.9477e-01, time/batch = 0.6248s	
1136/11850 (epoch 4.793), train_loss = 2.15861727, grad/param norm = 2.6974e-01, time/batch = 0.6281s	
1137/11850 (epoch 4.797), train_loss = 2.02631671, grad/param norm = 2.5645e-01, time/batch = 0.6261s	
1138/11850 (epoch 4.802), train_loss = 2.00800910, grad/param norm = 2.6526e-01, time/batch = 0.6310s	
1139/11850 (epoch 4.806), train_loss = 1.97845148, grad/param norm = 2.6420e-01, time/batch = 0.6264s	
1140/11850 (epoch 4.810), train_loss = 2.18003085, grad/param norm = 3.1733e-01, time/batch = 0.6233s	
1141/11850 (epoch 4.814), train_loss = 1.95129080, grad/param norm = 3.5086e-01, time/batch = 0.6280s	
1142/11850 (epoch 4.819), train_loss = 2.06725693, grad/param norm = 2.6565e-01, time/batch = 0.6290s	
1143/11850 (epoch 4.823), train_loss = 2.10123391, grad/param norm = 2.9289e-01, time/batch = 0.6271s	
1144/11850 (epoch 4.827), train_loss = 1.97269644, grad/param norm = 2.9528e-01, time/batch = 0.6283s	
1145/11850 (epoch 4.831), train_loss = 2.00090559, grad/param norm = 2.7165e-01, time/batch = 0.6458s	
1146/11850 (epoch 4.835), train_loss = 1.99750700, grad/param norm = 3.0698e-01, time/batch = 0.6567s	
1147/11850 (epoch 4.840), train_loss = 1.86759767, grad/param norm = 2.7142e-01, time/batch = 0.6242s	
1148/11850 (epoch 4.844), train_loss = 1.93597230, grad/param norm = 2.2886e-01, time/batch = 0.6230s	
1149/11850 (epoch 4.848), train_loss = 2.09499997, grad/param norm = 2.7645e-01, time/batch = 0.6231s	
1150/11850 (epoch 4.852), train_loss = 1.99394674, grad/param norm = 3.4576e-01, time/batch = 0.6243s	
1151/11850 (epoch 4.857), train_loss = 2.01420789, grad/param norm = 3.3039e-01, time/batch = 0.6285s	
1152/11850 (epoch 4.861), train_loss = 2.09512571, grad/param norm = 2.6187e-01, time/batch = 0.6399s	
1153/11850 (epoch 4.865), train_loss = 2.06115886, grad/param norm = 2.9625e-01, time/batch = 0.6481s	
1154/11850 (epoch 4.869), train_loss = 2.20494525, grad/param norm = 2.7312e-01, time/batch = 0.6266s	
1155/11850 (epoch 4.873), train_loss = 2.05451010, grad/param norm = 2.5790e-01, time/batch = 0.6465s	
1156/11850 (epoch 4.878), train_loss = 2.01279698, grad/param norm = 2.9850e-01, time/batch = 0.6409s	
1157/11850 (epoch 4.882), train_loss = 2.00477153, grad/param norm = 2.5165e-01, time/batch = 0.6256s	
1158/11850 (epoch 4.886), train_loss = 2.06010636, grad/param norm = 2.8320e-01, time/batch = 0.6243s	
1159/11850 (epoch 4.890), train_loss = 1.98463549, grad/param norm = 2.4758e-01, time/batch = 0.6224s	
1160/11850 (epoch 4.895), train_loss = 2.01878227, grad/param norm = 2.7847e-01, time/batch = 0.6255s	
1161/11850 (epoch 4.899), train_loss = 1.99887694, grad/param norm = 2.8941e-01, time/batch = 0.6267s	
1162/11850 (epoch 4.903), train_loss = 1.94337709, grad/param norm = 2.2405e-01, time/batch = 0.6235s	
1163/11850 (epoch 4.907), train_loss = 1.92367238, grad/param norm = 2.6285e-01, time/batch = 0.6250s	
1164/11850 (epoch 4.911), train_loss = 1.94604456, grad/param norm = 2.5732e-01, time/batch = 0.6215s	
1165/11850 (epoch 4.916), train_loss = 2.17826803, grad/param norm = 3.2967e-01, time/batch = 0.6201s	
1166/11850 (epoch 4.920), train_loss = 1.86049786, grad/param norm = 3.4443e-01, time/batch = 0.6196s	
1167/11850 (epoch 4.924), train_loss = 1.98441639, grad/param norm = 2.6027e-01, time/batch = 0.6437s	
1168/11850 (epoch 4.928), train_loss = 2.17399065, grad/param norm = 2.8257e-01, time/batch = 0.6566s	
1169/11850 (epoch 4.932), train_loss = 2.14440498, grad/param norm = 3.3914e-01, time/batch = 0.6231s	
1170/11850 (epoch 4.937), train_loss = 2.12597287, grad/param norm = 2.7713e-01, time/batch = 0.6221s	
1171/11850 (epoch 4.941), train_loss = 2.06301499, grad/param norm = 3.3716e-01, time/batch = 0.6279s	
1172/11850 (epoch 4.945), train_loss = 2.08322527, grad/param norm = 2.5896e-01, time/batch = 0.6297s	
1173/11850 (epoch 4.949), train_loss = 2.04861438, grad/param norm = 3.1011e-01, time/batch = 0.6262s	
1174/11850 (epoch 4.954), train_loss = 2.16662241, grad/param norm = 2.7078e-01, time/batch = 0.6253s	
1175/11850 (epoch 4.958), train_loss = 1.98321073, grad/param norm = 2.7847e-01, time/batch = 0.6229s	
1176/11850 (epoch 4.962), train_loss = 2.00607709, grad/param norm = 3.1138e-01, time/batch = 0.6276s	
1177/11850 (epoch 4.966), train_loss = 1.93878853, grad/param norm = 3.3847e-01, time/batch = 0.6233s	
1178/11850 (epoch 4.970), train_loss = 1.99903142, grad/param norm = 2.9494e-01, time/batch = 0.6368s	
1179/11850 (epoch 4.975), train_loss = 2.09663247, grad/param norm = 2.6955e-01, time/batch = 0.6567s	
1180/11850 (epoch 4.979), train_loss = 2.15449329, grad/param norm = 4.1331e-01, time/batch = 0.6275s	
1181/11850 (epoch 4.983), train_loss = 2.39911197, grad/param norm = 6.2413e-01, time/batch = 0.6237s	
1182/11850 (epoch 4.987), train_loss = 2.07940954, grad/param norm = 3.4767e-01, time/batch = 0.6210s	
1183/11850 (epoch 4.992), train_loss = 2.08579695, grad/param norm = 2.2450e-01, time/batch = 0.6251s	
1184/11850 (epoch 4.996), train_loss = 2.30948474, grad/param norm = 2.3911e-01, time/batch = 0.6246s	
1185/11850 (epoch 5.000), train_loss = 2.04889403, grad/param norm = 2.6085e-01, time/batch = 0.6233s	
1186/11850 (epoch 5.004), train_loss = 2.04999677, grad/param norm = 2.3880e-01, time/batch = 0.6255s	
1187/11850 (epoch 5.008), train_loss = 2.01101792, grad/param norm = 2.3590e-01, time/batch = 0.6232s	
1188/11850 (epoch 5.013), train_loss = 2.00013326, grad/param norm = 2.1677e-01, time/batch = 0.6260s	
1189/11850 (epoch 5.017), train_loss = 2.18432589, grad/param norm = 2.3744e-01, time/batch = 0.6363s	
1190/11850 (epoch 5.021), train_loss = 1.87881798, grad/param norm = 2.3320e-01, time/batch = 0.6585s	
1191/11850 (epoch 5.025), train_loss = 1.71363542, grad/param norm = 1.9447e-01, time/batch = 0.6318s	
1192/11850 (epoch 5.030), train_loss = 1.87111812, grad/param norm = 2.2010e-01, time/batch = 0.6252s	
1193/11850 (epoch 5.034), train_loss = 1.90514151, grad/param norm = 2.3893e-01, time/batch = 0.6233s	
1194/11850 (epoch 5.038), train_loss = 1.90987055, grad/param norm = 2.4337e-01, time/batch = 0.6251s	
1195/11850 (epoch 5.042), train_loss = 2.01214294, grad/param norm = 2.2704e-01, time/batch = 0.6242s	
1196/11850 (epoch 5.046), train_loss = 2.13769425, grad/param norm = 2.4483e-01, time/batch = 0.6272s	
1197/11850 (epoch 5.051), train_loss = 1.92993752, grad/param norm = 2.5350e-01, time/batch = 0.6249s	
1198/11850 (epoch 5.055), train_loss = 2.00486336, grad/param norm = 3.2893e-01, time/batch = 0.6245s	
1199/11850 (epoch 5.059), train_loss = 2.05939099, grad/param norm = 2.9565e-01, time/batch = 0.6261s	
1200/11850 (epoch 5.063), train_loss = 2.00321836, grad/param norm = 2.4032e-01, time/batch = 0.6326s	
1201/11850 (epoch 5.068), train_loss = 1.93592211, grad/param norm = 2.2099e-01, time/batch = 0.6607s	
1202/11850 (epoch 5.072), train_loss = 1.93794003, grad/param norm = 2.2386e-01, time/batch = 0.6478s	
1203/11850 (epoch 5.076), train_loss = 2.08620334, grad/param norm = 2.2439e-01, time/batch = 0.6526s	
1204/11850 (epoch 5.080), train_loss = 2.01481835, grad/param norm = 2.4587e-01, time/batch = 0.6582s	
1205/11850 (epoch 5.084), train_loss = 1.82743198, grad/param norm = 2.4436e-01, time/batch = 0.6325s	
1206/11850 (epoch 5.089), train_loss = 1.86040973, grad/param norm = 2.0944e-01, time/batch = 0.6318s	
1207/11850 (epoch 5.093), train_loss = 1.82407546, grad/param norm = 2.3843e-01, time/batch = 0.6262s	
1208/11850 (epoch 5.097), train_loss = 2.21450353, grad/param norm = 2.7436e-01, time/batch = 0.6291s	
1209/11850 (epoch 5.101), train_loss = 2.09812660, grad/param norm = 3.1032e-01, time/batch = 0.6239s	
1210/11850 (epoch 5.105), train_loss = 1.88541569, grad/param norm = 2.4700e-01, time/batch = 0.6264s	
1211/11850 (epoch 5.110), train_loss = 1.90743197, grad/param norm = 2.2881e-01, time/batch = 0.6409s	
1212/11850 (epoch 5.114), train_loss = 2.05123799, grad/param norm = 2.7886e-01, time/batch = 0.6499s	
1213/11850 (epoch 5.118), train_loss = 1.91394429, grad/param norm = 3.0952e-01, time/batch = 0.6485s	
1214/11850 (epoch 5.122), train_loss = 2.03816038, grad/param norm = 2.7728e-01, time/batch = 0.6346s	
1215/11850 (epoch 5.127), train_loss = 2.07927870, grad/param norm = 2.8610e-01, time/batch = 0.6308s	
1216/11850 (epoch 5.131), train_loss = 2.10399319, grad/param norm = 3.2083e-01, time/batch = 0.6257s	
1217/11850 (epoch 5.135), train_loss = 1.95165554, grad/param norm = 2.7003e-01, time/batch = 0.6243s	
1218/11850 (epoch 5.139), train_loss = 2.04226118, grad/param norm = 2.4509e-01, time/batch = 0.6249s	
1219/11850 (epoch 5.143), train_loss = 1.94495482, grad/param norm = 2.5237e-01, time/batch = 0.6308s	
1220/11850 (epoch 5.148), train_loss = 2.01153447, grad/param norm = 3.0200e-01, time/batch = 0.6519s	
1221/11850 (epoch 5.152), train_loss = 2.00077291, grad/param norm = 3.3645e-01, time/batch = 0.6454s	
1222/11850 (epoch 5.156), train_loss = 2.07217956, grad/param norm = 2.5240e-01, time/batch = 0.6349s	
1223/11850 (epoch 5.160), train_loss = 2.33834103, grad/param norm = 2.6797e-01, time/batch = 0.6225s	
1224/11850 (epoch 5.165), train_loss = 2.12966437, grad/param norm = 2.4859e-01, time/batch = 0.6232s	
1225/11850 (epoch 5.169), train_loss = 1.92907569, grad/param norm = 2.7062e-01, time/batch = 0.6219s	
1226/11850 (epoch 5.173), train_loss = 2.04285174, grad/param norm = 2.5300e-01, time/batch = 0.6304s	
1227/11850 (epoch 5.177), train_loss = 2.06566184, grad/param norm = 2.7453e-01, time/batch = 0.6379s	
1228/11850 (epoch 5.181), train_loss = 1.97257755, grad/param norm = 2.5491e-01, time/batch = 0.6289s	
1229/11850 (epoch 5.186), train_loss = 2.14769054, grad/param norm = 2.9357e-01, time/batch = 0.6326s	
1230/11850 (epoch 5.190), train_loss = 2.00013443, grad/param norm = 2.2794e-01, time/batch = 0.6388s	
1231/11850 (epoch 5.194), train_loss = 2.13738744, grad/param norm = 2.7605e-01, time/batch = 0.6484s	
1232/11850 (epoch 5.198), train_loss = 1.92258640, grad/param norm = 2.7608e-01, time/batch = 0.6465s	
1233/11850 (epoch 5.203), train_loss = 1.73745389, grad/param norm = 2.1446e-01, time/batch = 0.6537s	
1234/11850 (epoch 5.207), train_loss = 2.05064317, grad/param norm = 2.7119e-01, time/batch = 0.6708s	
1235/11850 (epoch 5.211), train_loss = 1.95575636, grad/param norm = 2.2685e-01, time/batch = 0.6531s	
1236/11850 (epoch 5.215), train_loss = 1.94690594, grad/param norm = 2.3400e-01, time/batch = 0.6501s	
1237/11850 (epoch 5.219), train_loss = 1.85302649, grad/param norm = 2.2888e-01, time/batch = 0.6544s	
1238/11850 (epoch 5.224), train_loss = 2.22164089, grad/param norm = 2.4043e-01, time/batch = 0.6349s	
1239/11850 (epoch 5.228), train_loss = 2.11321437, grad/param norm = 2.3611e-01, time/batch = 0.6345s	
1240/11850 (epoch 5.232), train_loss = 2.02388677, grad/param norm = 2.7843e-01, time/batch = 0.6359s	
1241/11850 (epoch 5.236), train_loss = 1.94570065, grad/param norm = 2.3775e-01, time/batch = 0.6372s	
1242/11850 (epoch 5.241), train_loss = 2.12208290, grad/param norm = 2.7264e-01, time/batch = 0.6339s	
1243/11850 (epoch 5.245), train_loss = 2.05877501, grad/param norm = 3.0665e-01, time/batch = 0.6274s	
1244/11850 (epoch 5.249), train_loss = 1.91283358, grad/param norm = 2.5377e-01, time/batch = 0.6418s	
1245/11850 (epoch 5.253), train_loss = 2.03698532, grad/param norm = 2.7307e-01, time/batch = 0.6514s	
1246/11850 (epoch 5.257), train_loss = 2.04784065, grad/param norm = 3.1430e-01, time/batch = 0.6233s	
1247/11850 (epoch 5.262), train_loss = 2.10056020, grad/param norm = 2.5848e-01, time/batch = 0.6224s	
1248/11850 (epoch 5.266), train_loss = 2.02948667, grad/param norm = 2.4197e-01, time/batch = 0.6246s	
1249/11850 (epoch 5.270), train_loss = 1.96980690, grad/param norm = 2.3178e-01, time/batch = 0.6218s	
1250/11850 (epoch 5.274), train_loss = 1.93197270, grad/param norm = 2.8874e-01, time/batch = 0.6211s	
1251/11850 (epoch 5.278), train_loss = 1.84866032, grad/param norm = 2.9791e-01, time/batch = 0.6260s	
1252/11850 (epoch 5.283), train_loss = 1.88131768, grad/param norm = 2.8230e-01, time/batch = 0.6259s	
1253/11850 (epoch 5.287), train_loss = 1.97734488, grad/param norm = 2.3753e-01, time/batch = 0.6230s	
1254/11850 (epoch 5.291), train_loss = 2.05392231, grad/param norm = 2.6035e-01, time/batch = 0.6251s	
1255/11850 (epoch 5.295), train_loss = 1.94483212, grad/param norm = 2.6721e-01, time/batch = 0.6275s	
1256/11850 (epoch 5.300), train_loss = 1.85838095, grad/param norm = 2.9000e-01, time/batch = 0.6261s	
1257/11850 (epoch 5.304), train_loss = 1.91820369, grad/param norm = 2.6549e-01, time/batch = 0.6294s	
1258/11850 (epoch 5.308), train_loss = 1.81675868, grad/param norm = 2.2558e-01, time/batch = 0.6524s	
1259/11850 (epoch 5.312), train_loss = 1.76754661, grad/param norm = 2.1580e-01, time/batch = 0.6408s	
1260/11850 (epoch 5.316), train_loss = 1.91249316, grad/param norm = 2.4459e-01, time/batch = 0.6315s	
1261/11850 (epoch 5.321), train_loss = 1.91967219, grad/param norm = 2.5462e-01, time/batch = 0.6293s	
1262/11850 (epoch 5.325), train_loss = 1.99766354, grad/param norm = 2.5841e-01, time/batch = 0.6247s	
1263/11850 (epoch 5.329), train_loss = 1.97899721, grad/param norm = 2.8560e-01, time/batch = 0.6267s	
1264/11850 (epoch 5.333), train_loss = 1.97318649, grad/param norm = 2.6242e-01, time/batch = 0.6250s	
1265/11850 (epoch 5.338), train_loss = 1.85090004, grad/param norm = 2.3160e-01, time/batch = 0.6246s	
1266/11850 (epoch 5.342), train_loss = 2.14435983, grad/param norm = 2.9551e-01, time/batch = 0.6296s	
1267/11850 (epoch 5.346), train_loss = 2.01667948, grad/param norm = 2.8918e-01, time/batch = 0.6357s	
1268/11850 (epoch 5.350), train_loss = 1.81333985, grad/param norm = 2.3345e-01, time/batch = 0.6404s	
1269/11850 (epoch 5.354), train_loss = 2.10592257, grad/param norm = 2.9873e-01, time/batch = 0.6396s	
1270/11850 (epoch 5.359), train_loss = 2.01328373, grad/param norm = 3.2752e-01, time/batch = 0.6391s	
1271/11850 (epoch 5.363), train_loss = 1.90215839, grad/param norm = 2.6493e-01, time/batch = 0.6231s	
1272/11850 (epoch 5.367), train_loss = 1.93623473, grad/param norm = 2.3298e-01, time/batch = 0.6208s	
1273/11850 (epoch 5.371), train_loss = 1.93945028, grad/param norm = 2.3206e-01, time/batch = 0.6218s	
1274/11850 (epoch 5.376), train_loss = 1.91331457, grad/param norm = 2.2969e-01, time/batch = 0.6228s	
1275/11850 (epoch 5.380), train_loss = 1.87840404, grad/param norm = 2.5507e-01, time/batch = 0.6236s	
1276/11850 (epoch 5.384), train_loss = 1.94376915, grad/param norm = 2.6171e-01, time/batch = 0.6262s	
1277/11850 (epoch 5.388), train_loss = 2.00685368, grad/param norm = 2.7244e-01, time/batch = 0.6273s	
1278/11850 (epoch 5.392), train_loss = 2.01420546, grad/param norm = 2.2550e-01, time/batch = 0.6246s	
1279/11850 (epoch 5.397), train_loss = 2.11774993, grad/param norm = 2.9909e-01, time/batch = 0.6220s	
1280/11850 (epoch 5.401), train_loss = 1.74442033, grad/param norm = 2.4477e-01, time/batch = 0.6230s	
1281/11850 (epoch 5.405), train_loss = 1.89599547, grad/param norm = 2.3878e-01, time/batch = 0.6248s	
1282/11850 (epoch 5.409), train_loss = 2.07353414, grad/param norm = 2.6375e-01, time/batch = 0.6258s	
1283/11850 (epoch 5.414), train_loss = 1.83373363, grad/param norm = 2.8044e-01, time/batch = 0.6346s	
1284/11850 (epoch 5.418), train_loss = 1.82325854, grad/param norm = 2.5654e-01, time/batch = 0.6234s	
1285/11850 (epoch 5.422), train_loss = 1.82114566, grad/param norm = 2.5757e-01, time/batch = 0.6249s	
1286/11850 (epoch 5.426), train_loss = 1.92358513, grad/param norm = 2.6039e-01, time/batch = 0.6252s	
1287/11850 (epoch 5.430), train_loss = 1.85855290, grad/param norm = 2.4297e-01, time/batch = 0.6254s	
1288/11850 (epoch 5.435), train_loss = 1.87638717, grad/param norm = 2.5505e-01, time/batch = 0.6228s	
1289/11850 (epoch 5.439), train_loss = 2.03143600, grad/param norm = 2.6064e-01, time/batch = 0.6236s	
1290/11850 (epoch 5.443), train_loss = 2.08370537, grad/param norm = 2.4477e-01, time/batch = 0.6260s	
1291/11850 (epoch 5.447), train_loss = 1.91612401, grad/param norm = 2.4163e-01, time/batch = 0.6271s	
1292/11850 (epoch 5.451), train_loss = 1.84988834, grad/param norm = 2.6945e-01, time/batch = 0.6263s	
1293/11850 (epoch 5.456), train_loss = 2.01291717, grad/param norm = 3.3960e-01, time/batch = 0.6293s	
1294/11850 (epoch 5.460), train_loss = 2.00734848, grad/param norm = 2.6105e-01, time/batch = 0.6237s	
1295/11850 (epoch 5.464), train_loss = 1.97080715, grad/param norm = 2.6823e-01, time/batch = 0.6266s	
1296/11850 (epoch 5.468), train_loss = 1.95591556, grad/param norm = 2.3687e-01, time/batch = 0.6309s	
1297/11850 (epoch 5.473), train_loss = 2.02161463, grad/param norm = 2.9999e-01, time/batch = 0.6491s	
1298/11850 (epoch 5.477), train_loss = 1.76928678, grad/param norm = 2.4497e-01, time/batch = 0.6531s	
1299/11850 (epoch 5.481), train_loss = 1.84515303, grad/param norm = 2.8128e-01, time/batch = 0.6578s	
1300/11850 (epoch 5.485), train_loss = 1.73163248, grad/param norm = 2.4449e-01, time/batch = 0.6309s	
1301/11850 (epoch 5.489), train_loss = 1.97813717, grad/param norm = 2.4356e-01, time/batch = 0.6342s	
1302/11850 (epoch 5.494), train_loss = 1.89712290, grad/param norm = 2.3412e-01, time/batch = 0.6371s	
1303/11850 (epoch 5.498), train_loss = 1.96736842, grad/param norm = 2.9768e-01, time/batch = 0.6309s	
1304/11850 (epoch 5.502), train_loss = 1.82193835, grad/param norm = 3.0445e-01, time/batch = 0.6313s	
1305/11850 (epoch 5.506), train_loss = 2.05915729, grad/param norm = 2.7270e-01, time/batch = 0.6274s	
1306/11850 (epoch 5.511), train_loss = 1.85953943, grad/param norm = 2.1971e-01, time/batch = 0.6262s	
1307/11850 (epoch 5.515), train_loss = 2.07496868, grad/param norm = 3.1508e-01, time/batch = 0.6250s	
1308/11850 (epoch 5.519), train_loss = 1.89015624, grad/param norm = 2.7284e-01, time/batch = 0.6253s	
1309/11850 (epoch 5.523), train_loss = 1.91392039, grad/param norm = 2.2042e-01, time/batch = 0.6282s	
1310/11850 (epoch 5.527), train_loss = 1.87180750, grad/param norm = 3.0560e-01, time/batch = 0.6257s	
1311/11850 (epoch 5.532), train_loss = 2.03838220, grad/param norm = 2.7080e-01, time/batch = 0.6274s	
1312/11850 (epoch 5.536), train_loss = 1.84114147, grad/param norm = 2.4239e-01, time/batch = 0.6265s	
1313/11850 (epoch 5.540), train_loss = 1.79427195, grad/param norm = 2.0878e-01, time/batch = 0.6277s	
1314/11850 (epoch 5.544), train_loss = 1.91553822, grad/param norm = 2.7297e-01, time/batch = 0.6283s	
1315/11850 (epoch 5.549), train_loss = 1.62939523, grad/param norm = 2.6118e-01, time/batch = 0.6285s	
1316/11850 (epoch 5.553), train_loss = 1.95536159, grad/param norm = 2.6533e-01, time/batch = 0.6266s	
1317/11850 (epoch 5.557), train_loss = 2.14022144, grad/param norm = 2.3105e-01, time/batch = 0.6259s	
1318/11850 (epoch 5.561), train_loss = 1.88248981, grad/param norm = 2.4475e-01, time/batch = 0.6279s	
1319/11850 (epoch 5.565), train_loss = 2.04968586, grad/param norm = 2.5977e-01, time/batch = 0.6261s	
1320/11850 (epoch 5.570), train_loss = 1.80855637, grad/param norm = 2.4412e-01, time/batch = 0.6247s	
1321/11850 (epoch 5.574), train_loss = 1.95613440, grad/param norm = 2.4152e-01, time/batch = 0.6286s	
1322/11850 (epoch 5.578), train_loss = 2.05769722, grad/param norm = 2.4302e-01, time/batch = 0.6285s	
1323/11850 (epoch 5.582), train_loss = 1.88504219, grad/param norm = 2.5019e-01, time/batch = 0.6244s	
1324/11850 (epoch 5.586), train_loss = 1.90086642, grad/param norm = 2.7392e-01, time/batch = 0.6207s	
1325/11850 (epoch 5.591), train_loss = 2.01833884, grad/param norm = 3.1506e-01, time/batch = 0.6272s	
1326/11850 (epoch 5.595), train_loss = 1.75700618, grad/param norm = 2.5769e-01, time/batch = 0.6346s	
1327/11850 (epoch 5.599), train_loss = 1.77539502, grad/param norm = 2.5416e-01, time/batch = 0.6591s	
1328/11850 (epoch 5.603), train_loss = 1.81326613, grad/param norm = 2.1306e-01, time/batch = 0.6332s	
1329/11850 (epoch 5.608), train_loss = 2.01753785, grad/param norm = 2.5579e-01, time/batch = 0.6240s	
1330/11850 (epoch 5.612), train_loss = 2.09367907, grad/param norm = 2.2456e-01, time/batch = 0.6480s	
1331/11850 (epoch 5.616), train_loss = 2.03321607, grad/param norm = 2.4911e-01, time/batch = 0.6389s	
1332/11850 (epoch 5.620), train_loss = 1.84884433, grad/param norm = 2.5567e-01, time/batch = 0.6398s	
1333/11850 (epoch 5.624), train_loss = 2.03475947, grad/param norm = 2.4186e-01, time/batch = 0.6375s	
1334/11850 (epoch 5.629), train_loss = 1.93280906, grad/param norm = 2.5295e-01, time/batch = 0.6326s	
1335/11850 (epoch 5.633), train_loss = 1.74695123, grad/param norm = 2.2831e-01, time/batch = 0.6245s	
1336/11850 (epoch 5.637), train_loss = 1.77113309, grad/param norm = 2.4315e-01, time/batch = 0.6291s	
1337/11850 (epoch 5.641), train_loss = 1.84964701, grad/param norm = 2.6211e-01, time/batch = 0.6373s	
1338/11850 (epoch 5.646), train_loss = 1.91376325, grad/param norm = 2.5734e-01, time/batch = 0.6482s	
1339/11850 (epoch 5.650), train_loss = 1.90602385, grad/param norm = 2.6608e-01, time/batch = 0.6273s	
1340/11850 (epoch 5.654), train_loss = 1.95619398, grad/param norm = 2.8459e-01, time/batch = 0.6271s	
1341/11850 (epoch 5.658), train_loss = 1.91199152, grad/param norm = 2.8516e-01, time/batch = 0.6296s	
1342/11850 (epoch 5.662), train_loss = 1.89827744, grad/param norm = 2.6955e-01, time/batch = 0.6291s	
1343/11850 (epoch 5.667), train_loss = 1.89776094, grad/param norm = 2.3590e-01, time/batch = 0.6247s	
1344/11850 (epoch 5.671), train_loss = 1.78960099, grad/param norm = 2.5264e-01, time/batch = 0.6233s	
1345/11850 (epoch 5.675), train_loss = 1.92604727, grad/param norm = 2.7113e-01, time/batch = 0.6250s	
1346/11850 (epoch 5.679), train_loss = 1.96935386, grad/param norm = 2.3041e-01, time/batch = 0.6287s	
1347/11850 (epoch 5.684), train_loss = 1.94504021, grad/param norm = 2.6026e-01, time/batch = 0.6349s	
1348/11850 (epoch 5.688), train_loss = 1.84603695, grad/param norm = 2.3656e-01, time/batch = 0.6370s	
1349/11850 (epoch 5.692), train_loss = 1.96679720, grad/param norm = 3.0233e-01, time/batch = 0.6587s	
1350/11850 (epoch 5.696), train_loss = 1.90352497, grad/param norm = 3.2724e-01, time/batch = 0.6311s	
1351/11850 (epoch 5.700), train_loss = 1.93445251, grad/param norm = 4.2139e-01, time/batch = 0.6249s	
1352/11850 (epoch 5.705), train_loss = 1.92530579, grad/param norm = 2.9305e-01, time/batch = 0.6251s	
1353/11850 (epoch 5.709), train_loss = 1.91130541, grad/param norm = 2.7667e-01, time/batch = 0.6307s	
1354/11850 (epoch 5.713), train_loss = 1.86626838, grad/param norm = 2.4638e-01, time/batch = 0.6240s	
1355/11850 (epoch 5.717), train_loss = 1.72721690, grad/param norm = 2.2355e-01, time/batch = 0.6246s	
1356/11850 (epoch 5.722), train_loss = 2.04294388, grad/param norm = 2.5008e-01, time/batch = 0.6268s	
1357/11850 (epoch 5.726), train_loss = 1.77638973, grad/param norm = 2.4926e-01, time/batch = 0.6269s	
1358/11850 (epoch 5.730), train_loss = 1.76665367, grad/param norm = 2.6608e-01, time/batch = 0.6261s	
1359/11850 (epoch 5.734), train_loss = 1.83628477, grad/param norm = 2.6552e-01, time/batch = 0.6269s	
1360/11850 (epoch 5.738), train_loss = 1.98694418, grad/param norm = 3.0621e-01, time/batch = 0.6260s	
1361/11850 (epoch 5.743), train_loss = 1.93715643, grad/param norm = 2.5712e-01, time/batch = 0.6511s	
1362/11850 (epoch 5.747), train_loss = 1.80049879, grad/param norm = 2.8639e-01, time/batch = 0.6348s	
1363/11850 (epoch 5.751), train_loss = 1.76388353, grad/param norm = 2.7194e-01, time/batch = 0.6238s	
1364/11850 (epoch 5.755), train_loss = 1.86099638, grad/param norm = 2.4809e-01, time/batch = 0.6256s	
1365/11850 (epoch 5.759), train_loss = 1.79099251, grad/param norm = 2.3050e-01, time/batch = 0.6306s	
1366/11850 (epoch 5.764), train_loss = 1.81313449, grad/param norm = 2.4108e-01, time/batch = 0.6274s	
1367/11850 (epoch 5.768), train_loss = 1.69655753, grad/param norm = 2.3448e-01, time/batch = 0.6235s	
1368/11850 (epoch 5.772), train_loss = 1.89192543, grad/param norm = 2.4150e-01, time/batch = 0.6242s	
1369/11850 (epoch 5.776), train_loss = 1.91668828, grad/param norm = 3.2374e-01, time/batch = 0.6232s	
1370/11850 (epoch 5.781), train_loss = 1.79407793, grad/param norm = 2.6154e-01, time/batch = 0.6243s	
1371/11850 (epoch 5.785), train_loss = 1.82579829, grad/param norm = 2.3775e-01, time/batch = 0.6251s	
1372/11850 (epoch 5.789), train_loss = 1.97815087, grad/param norm = 2.6041e-01, time/batch = 0.6288s	
1373/11850 (epoch 5.793), train_loss = 2.05660391, grad/param norm = 2.5621e-01, time/batch = 0.6332s	
1374/11850 (epoch 5.797), train_loss = 1.93030900, grad/param norm = 2.5729e-01, time/batch = 0.6242s	
1375/11850 (epoch 5.802), train_loss = 1.89829279, grad/param norm = 2.5973e-01, time/batch = 0.6251s	
1376/11850 (epoch 5.806), train_loss = 1.89136639, grad/param norm = 2.3635e-01, time/batch = 0.6263s	
1377/11850 (epoch 5.810), train_loss = 2.11802191, grad/param norm = 2.8224e-01, time/batch = 0.6239s	
1378/11850 (epoch 5.814), train_loss = 1.84775675, grad/param norm = 2.7316e-01, time/batch = 0.6286s	
1379/11850 (epoch 5.819), train_loss = 1.98342770, grad/param norm = 2.2508e-01, time/batch = 0.6244s	
1380/11850 (epoch 5.823), train_loss = 2.02055491, grad/param norm = 2.6882e-01, time/batch = 0.6279s	
1381/11850 (epoch 5.827), train_loss = 1.87612286, grad/param norm = 2.6917e-01, time/batch = 0.6302s	
1382/11850 (epoch 5.831), train_loss = 1.91629448, grad/param norm = 2.5013e-01, time/batch = 0.6250s	
1383/11850 (epoch 5.835), train_loss = 1.89648308, grad/param norm = 2.6476e-01, time/batch = 0.6254s	
1384/11850 (epoch 5.840), train_loss = 1.77951168, grad/param norm = 2.3363e-01, time/batch = 0.6255s	
1385/11850 (epoch 5.844), train_loss = 1.83141648, grad/param norm = 2.2047e-01, time/batch = 0.6245s	
1386/11850 (epoch 5.848), train_loss = 1.98828335, grad/param norm = 2.6433e-01, time/batch = 0.6225s	
1387/11850 (epoch 5.852), train_loss = 1.87708781, grad/param norm = 2.9703e-01, time/batch = 0.6217s	
1388/11850 (epoch 5.857), train_loss = 1.89817022, grad/param norm = 2.8346e-01, time/batch = 0.6268s	
1389/11850 (epoch 5.861), train_loss = 1.99812984, grad/param norm = 2.4762e-01, time/batch = 0.6253s	
1390/11850 (epoch 5.865), train_loss = 1.96835762, grad/param norm = 2.9086e-01, time/batch = 0.6257s	
1391/11850 (epoch 5.869), train_loss = 2.09083261, grad/param norm = 2.5121e-01, time/batch = 0.6405s	
1392/11850 (epoch 5.873), train_loss = 1.95782002, grad/param norm = 2.4409e-01, time/batch = 0.6567s	
1393/11850 (epoch 5.878), train_loss = 1.92041742, grad/param norm = 2.8223e-01, time/batch = 0.6665s	
1394/11850 (epoch 5.882), train_loss = 1.93732660, grad/param norm = 2.3713e-01, time/batch = 0.6517s	
1395/11850 (epoch 5.886), train_loss = 1.96798744, grad/param norm = 2.4932e-01, time/batch = 0.6318s	
1396/11850 (epoch 5.890), train_loss = 1.90299311, grad/param norm = 2.2877e-01, time/batch = 0.6396s	
1397/11850 (epoch 5.895), train_loss = 1.93442711, grad/param norm = 2.5944e-01, time/batch = 0.6441s	
1398/11850 (epoch 5.899), train_loss = 1.88784855, grad/param norm = 2.5221e-01, time/batch = 0.6579s	
1399/11850 (epoch 5.903), train_loss = 1.84152511, grad/param norm = 2.1065e-01, time/batch = 0.6327s	
1400/11850 (epoch 5.907), train_loss = 1.82633730, grad/param norm = 2.5493e-01, time/batch = 0.6279s	
1401/11850 (epoch 5.911), train_loss = 1.87882538, grad/param norm = 2.3445e-01, time/batch = 0.6225s	
1402/11850 (epoch 5.916), train_loss = 2.08596693, grad/param norm = 3.0253e-01, time/batch = 0.6232s	
1403/11850 (epoch 5.920), train_loss = 1.78354758, grad/param norm = 3.0205e-01, time/batch = 0.6255s	
1404/11850 (epoch 5.924), train_loss = 1.90606285, grad/param norm = 2.4098e-01, time/batch = 0.6270s	
1405/11850 (epoch 5.928), train_loss = 2.09379774, grad/param norm = 2.7648e-01, time/batch = 0.6312s	
1406/11850 (epoch 5.932), train_loss = 2.06368489, grad/param norm = 2.9512e-01, time/batch = 0.6274s	
1407/11850 (epoch 5.937), train_loss = 2.02518088, grad/param norm = 2.4663e-01, time/batch = 0.6322s	
1408/11850 (epoch 5.941), train_loss = 1.97891043, grad/param norm = 3.1434e-01, time/batch = 0.6312s	
1409/11850 (epoch 5.945), train_loss = 1.98691793, grad/param norm = 2.5110e-01, time/batch = 0.6315s	
1410/11850 (epoch 5.949), train_loss = 1.94438155, grad/param norm = 2.8434e-01, time/batch = 0.6300s	
1411/11850 (epoch 5.954), train_loss = 2.05460985, grad/param norm = 2.4978e-01, time/batch = 0.6291s	
1412/11850 (epoch 5.958), train_loss = 1.88895841, grad/param norm = 2.8488e-01, time/batch = 0.6328s	
1413/11850 (epoch 5.962), train_loss = 1.88797727, grad/param norm = 2.8036e-01, time/batch = 0.6307s	
1414/11850 (epoch 5.966), train_loss = 1.82447054, grad/param norm = 2.9100e-01, time/batch = 0.6289s	
1415/11850 (epoch 5.970), train_loss = 1.89759394, grad/param norm = 2.5186e-01, time/batch = 0.6258s	
1416/11850 (epoch 5.975), train_loss = 1.99539987, grad/param norm = 2.4623e-01, time/batch = 0.6289s	
1417/11850 (epoch 5.979), train_loss = 2.02987878, grad/param norm = 2.8845e-01, time/batch = 0.6505s	
1418/11850 (epoch 5.983), train_loss = 2.25738095, grad/param norm = 3.7197e-01, time/batch = 0.6320s	
1419/11850 (epoch 5.987), train_loss = 1.96860947, grad/param norm = 2.8967e-01, time/batch = 0.6346s	
1420/11850 (epoch 5.992), train_loss = 2.01182443, grad/param norm = 2.2661e-01, time/batch = 0.6324s	
1421/11850 (epoch 5.996), train_loss = 2.21621899, grad/param norm = 2.3049e-01, time/batch = 0.6293s	
1422/11850 (epoch 6.000), train_loss = 1.94049398, grad/param norm = 2.5206e-01, time/batch = 0.6255s	
1423/11850 (epoch 6.004), train_loss = 1.97613957, grad/param norm = 2.5058e-01, time/batch = 0.6279s	
1424/11850 (epoch 6.008), train_loss = 1.92950343, grad/param norm = 2.2619e-01, time/batch = 0.6315s	
1425/11850 (epoch 6.013), train_loss = 1.91758918, grad/param norm = 2.1138e-01, time/batch = 0.6222s	
1426/11850 (epoch 6.017), train_loss = 2.09716539, grad/param norm = 2.3729e-01, time/batch = 0.6253s	
1427/11850 (epoch 6.021), train_loss = 1.78441146, grad/param norm = 2.1243e-01, time/batch = 0.6268s	
1428/11850 (epoch 6.025), train_loss = 1.62863980, grad/param norm = 1.9346e-01, time/batch = 0.6290s	
1429/11850 (epoch 6.030), train_loss = 1.79348984, grad/param norm = 2.1867e-01, time/batch = 0.6336s	
1430/11850 (epoch 6.034), train_loss = 1.79744901, grad/param norm = 2.1822e-01, time/batch = 0.6242s	
1431/11850 (epoch 6.038), train_loss = 1.81365198, grad/param norm = 2.1863e-01, time/batch = 0.6257s	
1432/11850 (epoch 6.042), train_loss = 1.93138227, grad/param norm = 2.2124e-01, time/batch = 0.6249s	
1433/11850 (epoch 6.046), train_loss = 2.04566415, grad/param norm = 2.3691e-01, time/batch = 0.6229s	
1434/11850 (epoch 6.051), train_loss = 1.84268716, grad/param norm = 2.3632e-01, time/batch = 0.6244s	
1435/11850 (epoch 6.055), train_loss = 1.90072726, grad/param norm = 2.9473e-01, time/batch = 0.6260s	
1436/11850 (epoch 6.059), train_loss = 1.96267697, grad/param norm = 2.6270e-01, time/batch = 0.6282s	
1437/11850 (epoch 6.063), train_loss = 1.90751769, grad/param norm = 2.2337e-01, time/batch = 0.6269s	
1438/11850 (epoch 6.068), train_loss = 1.84629741, grad/param norm = 2.1472e-01, time/batch = 0.6263s	
1439/11850 (epoch 6.072), train_loss = 1.84844209, grad/param norm = 2.1552e-01, time/batch = 0.6266s	
1440/11850 (epoch 6.076), train_loss = 2.01860340, grad/param norm = 2.2344e-01, time/batch = 0.6294s	
1441/11850 (epoch 6.080), train_loss = 1.89734217, grad/param norm = 2.3414e-01, time/batch = 0.6279s	
1442/11850 (epoch 6.084), train_loss = 1.72413408, grad/param norm = 2.3499e-01, time/batch = 0.6222s	
1443/11850 (epoch 6.089), train_loss = 1.76336837, grad/param norm = 2.0726e-01, time/batch = 0.6228s	
1444/11850 (epoch 6.093), train_loss = 1.72795927, grad/param norm = 2.2425e-01, time/batch = 0.6244s	
1445/11850 (epoch 6.097), train_loss = 2.10927482, grad/param norm = 2.5261e-01, time/batch = 0.6273s	
1446/11850 (epoch 6.101), train_loss = 2.00429747, grad/param norm = 2.9771e-01, time/batch = 0.6295s	
1447/11850 (epoch 6.105), train_loss = 1.79050999, grad/param norm = 2.2358e-01, time/batch = 0.6243s	
1448/11850 (epoch 6.110), train_loss = 1.82898812, grad/param norm = 2.1975e-01, time/batch = 0.6282s	
1449/11850 (epoch 6.114), train_loss = 1.96427563, grad/param norm = 2.7006e-01, time/batch = 0.6241s	
1450/11850 (epoch 6.118), train_loss = 1.82377365, grad/param norm = 2.6723e-01, time/batch = 0.6243s	
1451/11850 (epoch 6.122), train_loss = 1.96263644, grad/param norm = 2.5190e-01, time/batch = 0.6255s	
1452/11850 (epoch 6.127), train_loss = 1.97052101, grad/param norm = 2.6154e-01, time/batch = 0.6234s	
1453/11850 (epoch 6.131), train_loss = 2.00743244, grad/param norm = 2.8516e-01, time/batch = 0.6245s	
1454/11850 (epoch 6.135), train_loss = 1.86257116, grad/param norm = 2.4916e-01, time/batch = 0.6308s	
1455/11850 (epoch 6.139), train_loss = 1.93751217, grad/param norm = 2.3249e-01, time/batch = 0.6229s	
1456/11850 (epoch 6.143), train_loss = 1.84733925, grad/param norm = 2.2758e-01, time/batch = 0.6264s	
1457/11850 (epoch 6.148), train_loss = 1.91368300, grad/param norm = 2.7192e-01, time/batch = 0.6362s	
1458/11850 (epoch 6.152), train_loss = 1.91907087, grad/param norm = 2.9349e-01, time/batch = 0.6317s	
1459/11850 (epoch 6.156), train_loss = 1.98533812, grad/param norm = 2.2534e-01, time/batch = 0.6289s	
1460/11850 (epoch 6.160), train_loss = 2.25682650, grad/param norm = 2.6207e-01, time/batch = 0.6292s	
1461/11850 (epoch 6.165), train_loss = 2.04643626, grad/param norm = 2.3633e-01, time/batch = 0.6242s	
1462/11850 (epoch 6.169), train_loss = 1.84438029, grad/param norm = 2.5122e-01, time/batch = 0.6217s	
1463/11850 (epoch 6.173), train_loss = 1.95531106, grad/param norm = 2.3893e-01, time/batch = 0.6246s	
1464/11850 (epoch 6.177), train_loss = 1.96893592, grad/param norm = 2.6257e-01, time/batch = 0.6402s	
1465/11850 (epoch 6.181), train_loss = 1.90787180, grad/param norm = 2.3258e-01, time/batch = 0.6347s	
1466/11850 (epoch 6.186), train_loss = 2.04635185, grad/param norm = 2.6632e-01, time/batch = 0.6238s	
1467/11850 (epoch 6.190), train_loss = 1.91604069, grad/param norm = 2.2290e-01, time/batch = 0.6220s	
1468/11850 (epoch 6.194), train_loss = 2.04790237, grad/param norm = 2.6648e-01, time/batch = 0.6240s	
1469/11850 (epoch 6.198), train_loss = 1.84033077, grad/param norm = 2.6735e-01, time/batch = 0.6240s	
1470/11850 (epoch 6.203), train_loss = 1.65372961, grad/param norm = 2.0861e-01, time/batch = 0.6248s	
1471/11850 (epoch 6.207), train_loss = 1.94728642, grad/param norm = 2.6512e-01, time/batch = 0.6237s	
1472/11850 (epoch 6.211), train_loss = 1.87231333, grad/param norm = 2.2648e-01, time/batch = 0.6252s	
1473/11850 (epoch 6.215), train_loss = 1.85433963, grad/param norm = 2.1867e-01, time/batch = 0.6250s	
1474/11850 (epoch 6.219), train_loss = 1.77610104, grad/param norm = 2.1420e-01, time/batch = 0.6234s	
1475/11850 (epoch 6.224), train_loss = 2.13506767, grad/param norm = 2.3622e-01, time/batch = 0.6349s	
1476/11850 (epoch 6.228), train_loss = 2.03306146, grad/param norm = 2.1803e-01, time/batch = 0.6272s	
1477/11850 (epoch 6.232), train_loss = 1.93447428, grad/param norm = 2.5923e-01, time/batch = 0.6242s	
1478/11850 (epoch 6.236), train_loss = 1.86493635, grad/param norm = 2.3115e-01, time/batch = 0.6234s	
1479/11850 (epoch 6.241), train_loss = 2.06148442, grad/param norm = 2.4259e-01, time/batch = 0.6230s	
1480/11850 (epoch 6.245), train_loss = 1.96992030, grad/param norm = 2.7135e-01, time/batch = 0.6259s	
1481/11850 (epoch 6.249), train_loss = 1.82060517, grad/param norm = 2.3436e-01, time/batch = 0.6239s	
1482/11850 (epoch 6.253), train_loss = 1.95806710, grad/param norm = 2.8117e-01, time/batch = 0.6238s	
1483/11850 (epoch 6.257), train_loss = 1.97033523, grad/param norm = 2.7809e-01, time/batch = 0.6241s	
1484/11850 (epoch 6.262), train_loss = 2.03118636, grad/param norm = 2.3251e-01, time/batch = 0.6228s	
1485/11850 (epoch 6.266), train_loss = 1.94905016, grad/param norm = 2.2941e-01, time/batch = 0.6217s	
1486/11850 (epoch 6.270), train_loss = 1.87063782, grad/param norm = 2.2187e-01, time/batch = 0.6349s	
1487/11850 (epoch 6.274), train_loss = 1.84860777, grad/param norm = 2.8862e-01, time/batch = 0.6509s	
1488/11850 (epoch 6.278), train_loss = 1.73726911, grad/param norm = 2.6345e-01, time/batch = 0.6569s	
1489/11850 (epoch 6.283), train_loss = 1.79300603, grad/param norm = 2.5075e-01, time/batch = 0.6483s	
1490/11850 (epoch 6.287), train_loss = 1.91435115, grad/param norm = 2.2592e-01, time/batch = 0.6631s	
1491/11850 (epoch 6.291), train_loss = 1.96969908, grad/param norm = 2.4767e-01, time/batch = 0.6540s	
1492/11850 (epoch 6.295), train_loss = 1.84948311, grad/param norm = 2.4879e-01, time/batch = 0.6520s	
1493/11850 (epoch 6.300), train_loss = 1.77293399, grad/param norm = 2.6532e-01, time/batch = 0.6407s	
1494/11850 (epoch 6.304), train_loss = 1.81919983, grad/param norm = 2.4701e-01, time/batch = 0.6378s	
1495/11850 (epoch 6.308), train_loss = 1.73948273, grad/param norm = 2.1368e-01, time/batch = 0.6389s	
1496/11850 (epoch 6.312), train_loss = 1.67025190, grad/param norm = 2.0448e-01, time/batch = 0.6252s	
1497/11850 (epoch 6.316), train_loss = 1.83854203, grad/param norm = 2.3255e-01, time/batch = 0.6261s	
1498/11850 (epoch 6.321), train_loss = 1.82930089, grad/param norm = 2.3463e-01, time/batch = 0.6240s	
1499/11850 (epoch 6.325), train_loss = 1.90612216, grad/param norm = 2.4768e-01, time/batch = 0.6242s	
1500/11850 (epoch 6.329), train_loss = 1.88322772, grad/param norm = 2.6085e-01, time/batch = 0.6231s	
1501/11850 (epoch 6.333), train_loss = 1.87617513, grad/param norm = 2.5355e-01, time/batch = 0.6270s	
1502/11850 (epoch 6.338), train_loss = 1.76388084, grad/param norm = 2.1688e-01, time/batch = 0.6260s	
1503/11850 (epoch 6.342), train_loss = 2.05129709, grad/param norm = 2.6630e-01, time/batch = 0.6228s	
1504/11850 (epoch 6.346), train_loss = 1.93112542, grad/param norm = 2.8486e-01, time/batch = 0.6252s	
1505/11850 (epoch 6.350), train_loss = 1.72660426, grad/param norm = 2.2073e-01, time/batch = 0.6255s	
1506/11850 (epoch 6.354), train_loss = 2.01305136, grad/param norm = 2.7121e-01, time/batch = 0.6226s	
1507/11850 (epoch 6.359), train_loss = 1.92016768, grad/param norm = 2.9530e-01, time/batch = 0.6216s	
1508/11850 (epoch 6.363), train_loss = 1.81761829, grad/param norm = 2.3812e-01, time/batch = 0.6224s	
1509/11850 (epoch 6.367), train_loss = 1.84917821, grad/param norm = 2.2557e-01, time/batch = 0.6203s	
1510/11850 (epoch 6.371), train_loss = 1.85015551, grad/param norm = 2.2110e-01, time/batch = 0.6201s	
1511/11850 (epoch 6.376), train_loss = 1.81519665, grad/param norm = 2.1677e-01, time/batch = 0.6305s	
1512/11850 (epoch 6.380), train_loss = 1.79963522, grad/param norm = 2.4128e-01, time/batch = 0.6386s	
1513/11850 (epoch 6.384), train_loss = 1.84763554, grad/param norm = 2.5462e-01, time/batch = 0.6561s	
1514/11850 (epoch 6.388), train_loss = 1.94253455, grad/param norm = 2.6851e-01, time/batch = 0.6557s	
1515/11850 (epoch 6.392), train_loss = 1.94897244, grad/param norm = 2.2101e-01, time/batch = 0.6563s	
1516/11850 (epoch 6.397), train_loss = 2.02981691, grad/param norm = 2.9655e-01, time/batch = 0.6561s	
1517/11850 (epoch 6.401), train_loss = 1.66404446, grad/param norm = 2.2429e-01, time/batch = 0.6553s	
1518/11850 (epoch 6.405), train_loss = 1.79174580, grad/param norm = 2.2753e-01, time/batch = 0.6577s	
1519/11850 (epoch 6.409), train_loss = 1.97997892, grad/param norm = 2.5655e-01, time/batch = 0.6557s	
1520/11850 (epoch 6.414), train_loss = 1.73232775, grad/param norm = 2.5275e-01, time/batch = 0.6308s	
1521/11850 (epoch 6.418), train_loss = 1.73006123, grad/param norm = 2.4493e-01, time/batch = 0.6519s	
1522/11850 (epoch 6.422), train_loss = 1.71981556, grad/param norm = 2.4613e-01, time/batch = 0.6511s	
1523/11850 (epoch 6.426), train_loss = 1.81801691, grad/param norm = 2.5026e-01, time/batch = 0.6475s	
1524/11850 (epoch 6.430), train_loss = 1.76966760, grad/param norm = 2.3395e-01, time/batch = 0.6314s	
1525/11850 (epoch 6.435), train_loss = 1.79743431, grad/param norm = 2.4387e-01, time/batch = 0.6254s	
1526/11850 (epoch 6.439), train_loss = 1.93576943, grad/param norm = 2.4580e-01, time/batch = 0.6318s	
1527/11850 (epoch 6.443), train_loss = 2.00441940, grad/param norm = 2.4691e-01, time/batch = 0.6208s	
1528/11850 (epoch 6.447), train_loss = 1.81322939, grad/param norm = 2.2778e-01, time/batch = 0.6222s	
1529/11850 (epoch 6.451), train_loss = 1.74686266, grad/param norm = 2.4364e-01, time/batch = 0.6204s	
1530/11850 (epoch 6.456), train_loss = 1.89255856, grad/param norm = 2.8386e-01, time/batch = 0.6275s	
1531/11850 (epoch 6.460), train_loss = 1.90160288, grad/param norm = 2.2239e-01, time/batch = 0.6239s	
1532/11850 (epoch 6.464), train_loss = 1.86683744, grad/param norm = 2.5631e-01, time/batch = 0.6246s	
1533/11850 (epoch 6.468), train_loss = 1.87517207, grad/param norm = 2.2878e-01, time/batch = 0.6394s	
1534/11850 (epoch 6.473), train_loss = 1.93535289, grad/param norm = 2.7303e-01, time/batch = 0.6558s	
1535/11850 (epoch 6.477), train_loss = 1.67148880, grad/param norm = 2.2615e-01, time/batch = 0.6558s	
1536/11850 (epoch 6.481), train_loss = 1.74587546, grad/param norm = 2.5280e-01, time/batch = 0.6538s	
1537/11850 (epoch 6.485), train_loss = 1.65034947, grad/param norm = 2.1295e-01, time/batch = 0.6525s	
1538/11850 (epoch 6.489), train_loss = 1.89620650, grad/param norm = 2.4039e-01, time/batch = 0.6523s	
1539/11850 (epoch 6.494), train_loss = 1.80998224, grad/param norm = 2.2486e-01, time/batch = 0.6534s	
1540/11850 (epoch 6.498), train_loss = 1.84761722, grad/param norm = 2.6574e-01, time/batch = 0.6550s	
1541/11850 (epoch 6.502), train_loss = 1.70511517, grad/param norm = 3.0081e-01, time/batch = 0.6547s	
1542/11850 (epoch 6.506), train_loss = 1.97616215, grad/param norm = 2.7592e-01, time/batch = 0.6525s	
1543/11850 (epoch 6.511), train_loss = 1.77434170, grad/param norm = 2.1810e-01, time/batch = 0.6506s	
1544/11850 (epoch 6.515), train_loss = 1.98956350, grad/param norm = 2.9985e-01, time/batch = 0.6508s	
1545/11850 (epoch 6.519), train_loss = 1.79229108, grad/param norm = 2.4113e-01, time/batch = 0.6514s	
1546/11850 (epoch 6.523), train_loss = 1.82717381, grad/param norm = 2.2274e-01, time/batch = 0.6329s	
1547/11850 (epoch 6.527), train_loss = 1.77416948, grad/param norm = 2.7000e-01, time/batch = 0.6250s	
1548/11850 (epoch 6.532), train_loss = 1.93295224, grad/param norm = 2.4597e-01, time/batch = 0.6241s	
1549/11850 (epoch 6.536), train_loss = 1.74799028, grad/param norm = 2.2474e-01, time/batch = 0.6262s	
1550/11850 (epoch 6.540), train_loss = 1.71283811, grad/param norm = 2.0351e-01, time/batch = 0.6273s	
1551/11850 (epoch 6.544), train_loss = 1.83543394, grad/param norm = 2.5541e-01, time/batch = 0.6364s	
1552/11850 (epoch 6.549), train_loss = 1.54511497, grad/param norm = 2.4493e-01, time/batch = 0.6265s	
1553/11850 (epoch 6.553), train_loss = 1.86620571, grad/param norm = 2.5558e-01, time/batch = 0.6441s	
1554/11850 (epoch 6.557), train_loss = 2.04561599, grad/param norm = 2.2576e-01, time/batch = 0.6413s	
1555/11850 (epoch 6.561), train_loss = 1.80524461, grad/param norm = 2.4016e-01, time/batch = 0.6259s	
1556/11850 (epoch 6.565), train_loss = 1.98375296, grad/param norm = 2.5699e-01, time/batch = 0.6346s	
1557/11850 (epoch 6.570), train_loss = 1.73759256, grad/param norm = 2.4129e-01, time/batch = 0.6456s	
1558/11850 (epoch 6.574), train_loss = 1.86823301, grad/param norm = 2.2142e-01, time/batch = 0.6243s	
1559/11850 (epoch 6.578), train_loss = 1.99549547, grad/param norm = 2.3893e-01, time/batch = 0.6218s	
1560/11850 (epoch 6.582), train_loss = 1.79713769, grad/param norm = 2.4618e-01, time/batch = 0.6258s	
1561/11850 (epoch 6.586), train_loss = 1.81644856, grad/param norm = 2.6098e-01, time/batch = 0.6258s	
1562/11850 (epoch 6.591), train_loss = 1.94171795, grad/param norm = 2.7680e-01, time/batch = 0.6244s	
1563/11850 (epoch 6.595), train_loss = 1.66938101, grad/param norm = 2.3990e-01, time/batch = 0.6242s	
1564/11850 (epoch 6.599), train_loss = 1.70647768, grad/param norm = 2.4442e-01, time/batch = 0.6250s	
1565/11850 (epoch 6.603), train_loss = 1.73479987, grad/param norm = 2.1001e-01, time/batch = 0.6241s	
1566/11850 (epoch 6.608), train_loss = 1.94223941, grad/param norm = 2.4060e-01, time/batch = 0.6262s	
1567/11850 (epoch 6.612), train_loss = 2.02260640, grad/param norm = 2.1933e-01, time/batch = 0.6340s	
1568/11850 (epoch 6.616), train_loss = 1.97135585, grad/param norm = 2.4515e-01, time/batch = 0.6411s	
1569/11850 (epoch 6.620), train_loss = 1.77596857, grad/param norm = 2.3734e-01, time/batch = 0.6263s	
1570/11850 (epoch 6.624), train_loss = 1.95763823, grad/param norm = 2.4421e-01, time/batch = 0.6235s	
1571/11850 (epoch 6.629), train_loss = 1.83413514, grad/param norm = 2.5168e-01, time/batch = 0.6354s	
1572/11850 (epoch 6.633), train_loss = 1.65606617, grad/param norm = 2.1985e-01, time/batch = 0.6268s	
1573/11850 (epoch 6.637), train_loss = 1.68611065, grad/param norm = 2.3593e-01, time/batch = 0.6231s	
1574/11850 (epoch 6.641), train_loss = 1.75692657, grad/param norm = 2.5513e-01, time/batch = 0.6250s	
1575/11850 (epoch 6.646), train_loss = 1.82677938, grad/param norm = 2.5460e-01, time/batch = 0.6240s	
1576/11850 (epoch 6.650), train_loss = 1.83798502, grad/param norm = 2.6701e-01, time/batch = 0.6255s	
1577/11850 (epoch 6.654), train_loss = 1.86776252, grad/param norm = 2.6914e-01, time/batch = 0.6332s	
1578/11850 (epoch 6.658), train_loss = 1.83611021, grad/param norm = 2.4919e-01, time/batch = 0.6224s	
1579/11850 (epoch 6.662), train_loss = 1.81879784, grad/param norm = 2.4896e-01, time/batch = 0.6216s	
1580/11850 (epoch 6.667), train_loss = 1.84348640, grad/param norm = 2.3100e-01, time/batch = 0.6342s	
1581/11850 (epoch 6.671), train_loss = 1.70937784, grad/param norm = 2.2844e-01, time/batch = 0.6511s	
1582/11850 (epoch 6.675), train_loss = 1.82997482, grad/param norm = 2.3788e-01, time/batch = 0.6536s	
1583/11850 (epoch 6.679), train_loss = 1.87234203, grad/param norm = 2.2311e-01, time/batch = 0.6410s	
1584/11850 (epoch 6.684), train_loss = 1.85820934, grad/param norm = 2.3983e-01, time/batch = 0.6317s	
1585/11850 (epoch 6.688), train_loss = 1.74327198, grad/param norm = 2.2399e-01, time/batch = 0.6323s	
1586/11850 (epoch 6.692), train_loss = 1.87278804, grad/param norm = 2.9260e-01, time/batch = 0.6313s	
1587/11850 (epoch 6.696), train_loss = 1.80552678, grad/param norm = 2.9610e-01, time/batch = 0.6281s	
1588/11850 (epoch 6.700), train_loss = 1.83008884, grad/param norm = 3.0908e-01, time/batch = 0.6317s	
1589/11850 (epoch 6.705), train_loss = 1.83166894, grad/param norm = 2.4912e-01, time/batch = 0.6307s	
1590/11850 (epoch 6.709), train_loss = 1.79943774, grad/param norm = 2.4822e-01, time/batch = 0.6268s	
1591/11850 (epoch 6.713), train_loss = 1.78614097, grad/param norm = 2.5271e-01, time/batch = 0.6261s	
1592/11850 (epoch 6.717), train_loss = 1.65723344, grad/param norm = 2.1644e-01, time/batch = 0.6238s	
1593/11850 (epoch 6.722), train_loss = 1.94260951, grad/param norm = 2.4533e-01, time/batch = 0.6235s	
1594/11850 (epoch 6.726), train_loss = 1.68986735, grad/param norm = 2.3607e-01, time/batch = 0.6271s	
1595/11850 (epoch 6.730), train_loss = 1.67711703, grad/param norm = 2.4196e-01, time/batch = 0.6389s	
1596/11850 (epoch 6.734), train_loss = 1.74973244, grad/param norm = 2.5076e-01, time/batch = 0.6313s	
1597/11850 (epoch 6.738), train_loss = 1.91452613, grad/param norm = 2.8222e-01, time/batch = 0.6271s	
1598/11850 (epoch 6.743), train_loss = 1.86546572, grad/param norm = 2.3855e-01, time/batch = 0.6296s	
1599/11850 (epoch 6.747), train_loss = 1.68359977, grad/param norm = 2.3924e-01, time/batch = 0.6291s	
1600/11850 (epoch 6.751), train_loss = 1.67333031, grad/param norm = 2.2816e-01, time/batch = 0.6282s	
1601/11850 (epoch 6.755), train_loss = 1.78781883, grad/param norm = 2.3802e-01, time/batch = 0.6293s	
1602/11850 (epoch 6.759), train_loss = 1.71319508, grad/param norm = 2.1857e-01, time/batch = 0.6278s	
1603/11850 (epoch 6.764), train_loss = 1.73205912, grad/param norm = 2.3598e-01, time/batch = 0.6255s	
1604/11850 (epoch 6.768), train_loss = 1.62322365, grad/param norm = 2.3099e-01, time/batch = 0.6264s	
1605/11850 (epoch 6.772), train_loss = 1.81078019, grad/param norm = 2.3295e-01, time/batch = 0.6265s	
1606/11850 (epoch 6.776), train_loss = 1.83339929, grad/param norm = 3.0299e-01, time/batch = 0.6260s	
1607/11850 (epoch 6.781), train_loss = 1.73069755, grad/param norm = 2.5077e-01, time/batch = 0.6244s	
1608/11850 (epoch 6.785), train_loss = 1.74348907, grad/param norm = 2.3015e-01, time/batch = 0.6236s	
1609/11850 (epoch 6.789), train_loss = 1.88858321, grad/param norm = 2.5069e-01, time/batch = 0.6263s	
1610/11850 (epoch 6.793), train_loss = 1.96800301, grad/param norm = 2.3932e-01, time/batch = 0.6280s	
1611/11850 (epoch 6.797), train_loss = 1.85415011, grad/param norm = 2.4803e-01, time/batch = 0.6296s	
1612/11850 (epoch 6.802), train_loss = 1.80381679, grad/param norm = 2.4884e-01, time/batch = 0.6282s	
1613/11850 (epoch 6.806), train_loss = 1.81362386, grad/param norm = 2.2947e-01, time/batch = 0.6239s	
1614/11850 (epoch 6.810), train_loss = 2.06501722, grad/param norm = 2.8520e-01, time/batch = 0.6232s	
1615/11850 (epoch 6.814), train_loss = 1.76640940, grad/param norm = 2.2598e-01, time/batch = 0.6258s	
1616/11850 (epoch 6.819), train_loss = 1.91761612, grad/param norm = 2.0777e-01, time/batch = 0.6264s	
1617/11850 (epoch 6.823), train_loss = 1.95055047, grad/param norm = 2.4820e-01, time/batch = 0.6246s	
1618/11850 (epoch 6.827), train_loss = 1.79628306, grad/param norm = 2.5078e-01, time/batch = 0.6268s	
1619/11850 (epoch 6.831), train_loss = 1.84812579, grad/param norm = 2.4815e-01, time/batch = 0.6258s	
1620/11850 (epoch 6.835), train_loss = 1.80955096, grad/param norm = 2.4432e-01, time/batch = 0.6243s	
1621/11850 (epoch 6.840), train_loss = 1.70429030, grad/param norm = 2.2300e-01, time/batch = 0.6251s	
1622/11850 (epoch 6.844), train_loss = 1.74704082, grad/param norm = 2.2025e-01, time/batch = 0.6244s	
1623/11850 (epoch 6.848), train_loss = 1.90020350, grad/param norm = 2.5727e-01, time/batch = 0.6248s	
1624/11850 (epoch 6.852), train_loss = 1.78588024, grad/param norm = 2.6404e-01, time/batch = 0.6261s	
1625/11850 (epoch 6.857), train_loss = 1.79855388, grad/param norm = 2.5083e-01, time/batch = 0.6449s	
1626/11850 (epoch 6.861), train_loss = 1.90702677, grad/param norm = 2.4632e-01, time/batch = 0.6443s	
1627/11850 (epoch 6.865), train_loss = 1.89746357, grad/param norm = 2.8085e-01, time/batch = 0.6397s	
1628/11850 (epoch 6.869), train_loss = 1.99557760, grad/param norm = 2.3697e-01, time/batch = 0.6502s	
1629/11850 (epoch 6.873), train_loss = 1.88364936, grad/param norm = 2.3120e-01, time/batch = 0.6316s	
1630/11850 (epoch 6.878), train_loss = 1.83836269, grad/param norm = 2.7708e-01, time/batch = 0.6274s	
1631/11850 (epoch 6.882), train_loss = 1.87164029, grad/param norm = 2.2524e-01, time/batch = 0.6293s	
1632/11850 (epoch 6.886), train_loss = 1.89664232, grad/param norm = 2.4009e-01, time/batch = 0.6347s	
1633/11850 (epoch 6.890), train_loss = 1.83271621, grad/param norm = 2.1316e-01, time/batch = 0.6280s	
1634/11850 (epoch 6.895), train_loss = 1.86425884, grad/param norm = 2.5325e-01, time/batch = 0.6267s	
1635/11850 (epoch 6.899), train_loss = 1.79446759, grad/param norm = 2.3479e-01, time/batch = 0.6237s	
1636/11850 (epoch 6.903), train_loss = 1.76138418, grad/param norm = 2.0833e-01, time/batch = 0.6277s	
1637/11850 (epoch 6.907), train_loss = 1.74328845, grad/param norm = 2.4424e-01, time/batch = 0.6257s	
1638/11850 (epoch 6.911), train_loss = 1.81914561, grad/param norm = 2.3269e-01, time/batch = 0.6307s	
1639/11850 (epoch 6.916), train_loss = 2.00619200, grad/param norm = 2.8431e-01, time/batch = 0.6482s	
1640/11850 (epoch 6.920), train_loss = 1.71287486, grad/param norm = 2.7138e-01, time/batch = 0.6340s	
1641/11850 (epoch 6.924), train_loss = 1.84006862, grad/param norm = 2.2865e-01, time/batch = 0.6267s	
1642/11850 (epoch 6.928), train_loss = 2.01511675, grad/param norm = 2.7875e-01, time/batch = 0.6282s	
1643/11850 (epoch 6.932), train_loss = 1.98709466, grad/param norm = 2.7249e-01, time/batch = 0.6258s	
1644/11850 (epoch 6.937), train_loss = 1.94216404, grad/param norm = 2.3815e-01, time/batch = 0.6289s	
1645/11850 (epoch 6.941), train_loss = 1.89833719, grad/param norm = 2.8226e-01, time/batch = 0.6284s	
1646/11850 (epoch 6.945), train_loss = 1.90091423, grad/param norm = 2.4678e-01, time/batch = 0.6369s	
1647/11850 (epoch 6.949), train_loss = 1.84645599, grad/param norm = 2.9079e-01, time/batch = 0.6258s	
1648/11850 (epoch 6.954), train_loss = 1.95387125, grad/param norm = 2.3739e-01, time/batch = 0.6276s	
1649/11850 (epoch 6.958), train_loss = 1.80881588, grad/param norm = 2.5683e-01, time/batch = 0.6331s	
1650/11850 (epoch 6.962), train_loss = 1.79393887, grad/param norm = 2.7222e-01, time/batch = 0.6572s	
1651/11850 (epoch 6.966), train_loss = 1.73010116, grad/param norm = 2.6170e-01, time/batch = 0.6350s	
1652/11850 (epoch 6.970), train_loss = 1.81385110, grad/param norm = 2.2972e-01, time/batch = 0.6250s	
1653/11850 (epoch 6.975), train_loss = 1.90665327, grad/param norm = 2.2630e-01, time/batch = 0.6231s	
1654/11850 (epoch 6.979), train_loss = 1.93411204, grad/param norm = 2.6307e-01, time/batch = 0.6282s	
1655/11850 (epoch 6.983), train_loss = 2.13148545, grad/param norm = 4.3473e-01, time/batch = 0.6318s	
1656/11850 (epoch 6.987), train_loss = 1.87816149, grad/param norm = 2.5512e-01, time/batch = 0.6254s	
1657/11850 (epoch 6.992), train_loss = 1.94683856, grad/param norm = 2.1583e-01, time/batch = 0.6240s	
1658/11850 (epoch 6.996), train_loss = 2.13731912, grad/param norm = 2.3503e-01, time/batch = 0.6217s	
1659/11850 (epoch 7.000), train_loss = 1.84453391, grad/param norm = 2.4800e-01, time/batch = 0.6227s	
1660/11850 (epoch 7.004), train_loss = 1.91931441, grad/param norm = 2.5474e-01, time/batch = 0.6239s	
1661/11850 (epoch 7.008), train_loss = 1.86540314, grad/param norm = 2.2066e-01, time/batch = 0.6236s	
1662/11850 (epoch 7.013), train_loss = 1.84765953, grad/param norm = 2.1087e-01, time/batch = 0.6296s	
1663/11850 (epoch 7.017), train_loss = 2.02778074, grad/param norm = 2.3283e-01, time/batch = 0.6216s	
1664/11850 (epoch 7.021), train_loss = 1.71470446, grad/param norm = 2.0838e-01, time/batch = 0.6227s	
1665/11850 (epoch 7.025), train_loss = 1.55695638, grad/param norm = 1.8615e-01, time/batch = 0.6253s	
1666/11850 (epoch 7.030), train_loss = 1.72117784, grad/param norm = 2.1987e-01, time/batch = 0.6293s	
1667/11850 (epoch 7.034), train_loss = 1.70894951, grad/param norm = 2.1468e-01, time/batch = 0.6322s	
1668/11850 (epoch 7.038), train_loss = 1.74621027, grad/param norm = 2.0724e-01, time/batch = 0.6230s	
1669/11850 (epoch 7.042), train_loss = 1.86124932, grad/param norm = 2.2307e-01, time/batch = 0.6217s	
1670/11850 (epoch 7.046), train_loss = 1.96293982, grad/param norm = 2.3871e-01, time/batch = 0.6221s	
1671/11850 (epoch 7.051), train_loss = 1.76746573, grad/param norm = 2.2499e-01, time/batch = 0.6217s	
1672/11850 (epoch 7.055), train_loss = 1.81522952, grad/param norm = 2.6803e-01, time/batch = 0.6238s	
1673/11850 (epoch 7.059), train_loss = 1.88214494, grad/param norm = 2.4481e-01, time/batch = 0.6234s	
1674/11850 (epoch 7.063), train_loss = 1.82796654, grad/param norm = 2.1631e-01, time/batch = 0.6247s	
1675/11850 (epoch 7.068), train_loss = 1.77835385, grad/param norm = 2.1349e-01, time/batch = 0.6484s	
1676/11850 (epoch 7.072), train_loss = 1.77305970, grad/param norm = 2.0851e-01, time/batch = 0.6535s	
1677/11850 (epoch 7.076), train_loss = 1.95779885, grad/param norm = 2.2236e-01, time/batch = 0.6428s	
1678/11850 (epoch 7.080), train_loss = 1.80354777, grad/param norm = 2.2116e-01, time/batch = 0.6411s	
1679/11850 (epoch 7.084), train_loss = 1.64413023, grad/param norm = 2.1980e-01, time/batch = 0.6405s	
1680/11850 (epoch 7.089), train_loss = 1.68346498, grad/param norm = 2.0917e-01, time/batch = 0.6272s	
1681/11850 (epoch 7.093), train_loss = 1.64105957, grad/param norm = 2.0959e-01, time/batch = 0.6531s	
1682/11850 (epoch 7.097), train_loss = 2.01066838, grad/param norm = 2.4912e-01, time/batch = 0.6451s	
1683/11850 (epoch 7.101), train_loss = 1.91487636, grad/param norm = 2.7293e-01, time/batch = 0.6437s	
1684/11850 (epoch 7.105), train_loss = 1.69755503, grad/param norm = 2.0214e-01, time/batch = 0.6278s	
1685/11850 (epoch 7.110), train_loss = 1.76484839, grad/param norm = 2.1370e-01, time/batch = 0.6237s	
1686/11850 (epoch 7.114), train_loss = 1.89061325, grad/param norm = 2.6165e-01, time/batch = 0.6246s	
1687/11850 (epoch 7.118), train_loss = 1.74157044, grad/param norm = 2.3964e-01, time/batch = 0.6222s	
1688/11850 (epoch 7.122), train_loss = 1.89321974, grad/param norm = 2.3931e-01, time/batch = 0.6236s	
1689/11850 (epoch 7.127), train_loss = 1.87522004, grad/param norm = 2.4643e-01, time/batch = 0.6233s	
1690/11850 (epoch 7.131), train_loss = 1.92004255, grad/param norm = 2.6616e-01, time/batch = 0.6253s	
1691/11850 (epoch 7.135), train_loss = 1.78372435, grad/param norm = 2.3520e-01, time/batch = 0.6266s	
1692/11850 (epoch 7.139), train_loss = 1.85627784, grad/param norm = 2.2225e-01, time/batch = 0.6263s	
1693/11850 (epoch 7.143), train_loss = 1.76667197, grad/param norm = 2.2123e-01, time/batch = 0.6230s	
1694/11850 (epoch 7.148), train_loss = 1.82673213, grad/param norm = 2.4891e-01, time/batch = 0.6292s	
1695/11850 (epoch 7.152), train_loss = 1.85047168, grad/param norm = 2.6474e-01, time/batch = 0.6234s	
1696/11850 (epoch 7.156), train_loss = 1.91364197, grad/param norm = 2.2568e-01, time/batch = 0.6254s	
1697/11850 (epoch 7.160), train_loss = 2.19110639, grad/param norm = 2.6745e-01, time/batch = 0.6331s	
1698/11850 (epoch 7.165), train_loss = 1.98148847, grad/param norm = 2.4331e-01, time/batch = 0.6305s	
1699/11850 (epoch 7.169), train_loss = 1.76555077, grad/param norm = 2.2680e-01, time/batch = 0.6268s	
1700/11850 (epoch 7.173), train_loss = 1.87717072, grad/param norm = 2.2341e-01, time/batch = 0.6268s	
1701/11850 (epoch 7.177), train_loss = 1.89338269, grad/param norm = 2.6704e-01, time/batch = 0.6254s	
1702/11850 (epoch 7.181), train_loss = 1.85591791, grad/param norm = 2.2669e-01, time/batch = 0.6259s	
1703/11850 (epoch 7.186), train_loss = 1.96708764, grad/param norm = 2.5715e-01, time/batch = 0.6263s	
1704/11850 (epoch 7.190), train_loss = 1.84166503, grad/param norm = 2.1948e-01, time/batch = 0.6262s	
1705/11850 (epoch 7.194), train_loss = 1.96847946, grad/param norm = 2.5536e-01, time/batch = 0.6324s	
1706/11850 (epoch 7.198), train_loss = 1.77307498, grad/param norm = 2.6720e-01, time/batch = 0.6298s	
1707/11850 (epoch 7.203), train_loss = 1.58299768, grad/param norm = 1.9963e-01, time/batch = 0.6256s	
1708/11850 (epoch 7.207), train_loss = 1.86353570, grad/param norm = 2.5403e-01, time/batch = 0.6261s	
1709/11850 (epoch 7.211), train_loss = 1.79602456, grad/param norm = 2.1233e-01, time/batch = 0.6253s	
1710/11850 (epoch 7.215), train_loss = 1.78371114, grad/param norm = 2.1428e-01, time/batch = 0.6296s	
1711/11850 (epoch 7.219), train_loss = 1.71863927, grad/param norm = 2.1211e-01, time/batch = 0.6386s	
1712/11850 (epoch 7.224), train_loss = 2.05361404, grad/param norm = 2.3395e-01, time/batch = 0.6292s	
1713/11850 (epoch 7.228), train_loss = 1.96244531, grad/param norm = 2.1025e-01, time/batch = 0.6296s	
1714/11850 (epoch 7.232), train_loss = 1.86245333, grad/param norm = 2.5159e-01, time/batch = 0.6269s	
1715/11850 (epoch 7.236), train_loss = 1.79051450, grad/param norm = 2.3815e-01, time/batch = 0.6286s	
1716/11850 (epoch 7.241), train_loss = 2.01336044, grad/param norm = 2.2486e-01, time/batch = 0.6449s	
1717/11850 (epoch 7.245), train_loss = 1.89329882, grad/param norm = 2.3800e-01, time/batch = 0.6508s	
1718/11850 (epoch 7.249), train_loss = 1.74750442, grad/param norm = 2.2513e-01, time/batch = 0.6449s	
1719/11850 (epoch 7.253), train_loss = 1.88264311, grad/param norm = 2.8658e-01, time/batch = 0.6487s	
1720/11850 (epoch 7.257), train_loss = 1.90340337, grad/param norm = 2.4644e-01, time/batch = 0.6462s	
1721/11850 (epoch 7.262), train_loss = 1.97518101, grad/param norm = 2.2755e-01, time/batch = 0.6421s	
1722/11850 (epoch 7.266), train_loss = 1.88257300, grad/param norm = 2.3481e-01, time/batch = 0.6416s	
1723/11850 (epoch 7.270), train_loss = 1.78505387, grad/param norm = 2.0530e-01, time/batch = 0.6406s	
1724/11850 (epoch 7.274), train_loss = 1.76741580, grad/param norm = 2.5398e-01, time/batch = 0.6377s	
1725/11850 (epoch 7.278), train_loss = 1.65035116, grad/param norm = 2.3315e-01, time/batch = 0.6405s	
1726/11850 (epoch 7.283), train_loss = 1.72795415, grad/param norm = 2.3858e-01, time/batch = 0.6365s	
1727/11850 (epoch 7.287), train_loss = 1.85816708, grad/param norm = 2.1829e-01, time/batch = 0.6380s	
1728/11850 (epoch 7.291), train_loss = 1.89331940, grad/param norm = 2.4156e-01, time/batch = 0.6369s	
1729/11850 (epoch 7.295), train_loss = 1.77407700, grad/param norm = 2.2135e-01, time/batch = 0.6392s	
1730/11850 (epoch 7.300), train_loss = 1.70687658, grad/param norm = 2.4461e-01, time/batch = 0.6489s	
1731/11850 (epoch 7.304), train_loss = 1.73615555, grad/param norm = 2.3877e-01, time/batch = 0.6465s	
1732/11850 (epoch 7.308), train_loss = 1.67177090, grad/param norm = 2.1190e-01, time/batch = 0.6401s	
1733/11850 (epoch 7.312), train_loss = 1.59586277, grad/param norm = 2.1048e-01, time/batch = 0.6406s	
1734/11850 (epoch 7.316), train_loss = 1.76842613, grad/param norm = 2.2438e-01, time/batch = 0.6384s	
1735/11850 (epoch 7.321), train_loss = 1.74580015, grad/param norm = 2.1355e-01, time/batch = 0.6402s	
1736/11850 (epoch 7.325), train_loss = 1.82370605, grad/param norm = 2.3497e-01, time/batch = 0.6415s	
1737/11850 (epoch 7.329), train_loss = 1.80093729, grad/param norm = 2.4733e-01, time/batch = 0.6428s	
1738/11850 (epoch 7.333), train_loss = 1.79444628, grad/param norm = 2.4190e-01, time/batch = 0.6389s	
1739/11850 (epoch 7.338), train_loss = 1.68545239, grad/param norm = 2.0398e-01, time/batch = 0.6431s	
1740/11850 (epoch 7.342), train_loss = 1.97890676, grad/param norm = 2.6888e-01, time/batch = 0.6400s	
1741/11850 (epoch 7.346), train_loss = 1.86118119, grad/param norm = 2.8490e-01, time/batch = 0.6527s	
1742/11850 (epoch 7.350), train_loss = 1.64367048, grad/param norm = 2.1276e-01, time/batch = 0.6433s	
1743/11850 (epoch 7.354), train_loss = 1.92763100, grad/param norm = 2.6110e-01, time/batch = 0.6387s	
1744/11850 (epoch 7.359), train_loss = 1.85996844, grad/param norm = 3.1211e-01, time/batch = 0.6460s	
1745/11850 (epoch 7.363), train_loss = 1.75606546, grad/param norm = 2.2585e-01, time/batch = 0.6583s	
1746/11850 (epoch 7.367), train_loss = 1.77969801, grad/param norm = 2.1511e-01, time/batch = 0.6584s	
1747/11850 (epoch 7.371), train_loss = 1.78158095, grad/param norm = 2.1453e-01, time/batch = 0.6405s	
1748/11850 (epoch 7.376), train_loss = 1.73373462, grad/param norm = 2.0370e-01, time/batch = 0.6327s	
1749/11850 (epoch 7.380), train_loss = 1.72202053, grad/param norm = 2.2659e-01, time/batch = 0.6513s	
1750/11850 (epoch 7.384), train_loss = 1.75808339, grad/param norm = 2.3457e-01, time/batch = 0.6367s	
1751/11850 (epoch 7.388), train_loss = 1.88007933, grad/param norm = 2.5868e-01, time/batch = 0.6369s	
1752/11850 (epoch 7.392), train_loss = 1.89939890, grad/param norm = 2.2763e-01, time/batch = 0.6373s	
1753/11850 (epoch 7.397), train_loss = 1.94089041, grad/param norm = 2.7783e-01, time/batch = 0.6368s	
1754/11850 (epoch 7.401), train_loss = 1.59963432, grad/param norm = 2.1600e-01, time/batch = 0.6355s	
1755/11850 (epoch 7.405), train_loss = 1.70717532, grad/param norm = 2.1311e-01, time/batch = 0.6397s	
1756/11850 (epoch 7.409), train_loss = 1.89592748, grad/param norm = 2.3758e-01, time/batch = 0.6376s	
1757/11850 (epoch 7.414), train_loss = 1.64995327, grad/param norm = 2.3061e-01, time/batch = 0.6350s	
1758/11850 (epoch 7.418), train_loss = 1.65724970, grad/param norm = 2.5270e-01, time/batch = 0.6587s	
1759/11850 (epoch 7.422), train_loss = 1.64287506, grad/param norm = 2.3666e-01, time/batch = 0.6590s	
1760/11850 (epoch 7.426), train_loss = 1.72808359, grad/param norm = 2.3066e-01, time/batch = 0.6589s	
1761/11850 (epoch 7.430), train_loss = 1.70171767, grad/param norm = 2.4711e-01, time/batch = 0.6405s	
1762/11850 (epoch 7.435), train_loss = 1.72828609, grad/param norm = 2.3104e-01, time/batch = 0.6290s	
1763/11850 (epoch 7.439), train_loss = 1.85659536, grad/param norm = 2.3296e-01, time/batch = 0.6252s	
1764/11850 (epoch 7.443), train_loss = 1.91727306, grad/param norm = 2.5137e-01, time/batch = 0.6416s	
1765/11850 (epoch 7.447), train_loss = 1.73341981, grad/param norm = 2.2674e-01, time/batch = 0.6414s	
1766/11850 (epoch 7.451), train_loss = 1.65635192, grad/param norm = 2.2766e-01, time/batch = 0.6291s	
1767/11850 (epoch 7.456), train_loss = 1.79194867, grad/param norm = 2.4863e-01, time/batch = 0.6322s	
1768/11850 (epoch 7.460), train_loss = 1.82671885, grad/param norm = 2.3902e-01, time/batch = 0.6251s	
1769/11850 (epoch 7.464), train_loss = 1.78025070, grad/param norm = 2.6364e-01, time/batch = 0.6525s	
1770/11850 (epoch 7.468), train_loss = 1.81071072, grad/param norm = 2.3106e-01, time/batch = 0.6574s	
1771/11850 (epoch 7.473), train_loss = 1.85961906, grad/param norm = 2.5345e-01, time/batch = 0.6523s	
1772/11850 (epoch 7.477), train_loss = 1.59133796, grad/param norm = 2.1560e-01, time/batch = 0.6466s	
1773/11850 (epoch 7.481), train_loss = 1.67280434, grad/param norm = 2.4722e-01, time/batch = 0.6377s	
1774/11850 (epoch 7.485), train_loss = 1.58669433, grad/param norm = 1.9726e-01, time/batch = 0.6290s	
1775/11850 (epoch 7.489), train_loss = 1.82101178, grad/param norm = 2.3169e-01, time/batch = 0.6359s	
1776/11850 (epoch 7.494), train_loss = 1.74032158, grad/param norm = 2.2320e-01, time/batch = 0.6315s	
1777/11850 (epoch 7.498), train_loss = 1.75600818, grad/param norm = 2.5280e-01, time/batch = 0.6268s	
1778/11850 (epoch 7.502), train_loss = 1.60354343, grad/param norm = 2.4658e-01, time/batch = 0.6260s	
1779/11850 (epoch 7.506), train_loss = 1.89385020, grad/param norm = 2.4883e-01, time/batch = 0.6214s	
1780/11850 (epoch 7.511), train_loss = 1.70035051, grad/param norm = 2.1156e-01, time/batch = 0.6228s	
1781/11850 (epoch 7.515), train_loss = 1.91303551, grad/param norm = 2.8885e-01, time/batch = 0.6377s	
1782/11850 (epoch 7.519), train_loss = 1.71677560, grad/param norm = 2.2351e-01, time/batch = 0.6405s	
1783/11850 (epoch 7.523), train_loss = 1.75202683, grad/param norm = 2.2914e-01, time/batch = 0.6240s	
1784/11850 (epoch 7.527), train_loss = 1.68909388, grad/param norm = 2.5147e-01, time/batch = 0.6223s	
1785/11850 (epoch 7.532), train_loss = 1.84919593, grad/param norm = 2.2765e-01, time/batch = 0.6240s	
1786/11850 (epoch 7.536), train_loss = 1.67580163, grad/param norm = 2.1333e-01, time/batch = 0.6276s	
1787/11850 (epoch 7.540), train_loss = 1.64694794, grad/param norm = 1.9906e-01, time/batch = 0.6234s	
1788/11850 (epoch 7.544), train_loss = 1.76937188, grad/param norm = 2.4461e-01, time/batch = 0.6270s	
1789/11850 (epoch 7.549), train_loss = 1.47637494, grad/param norm = 2.2925e-01, time/batch = 0.6236s	
1790/11850 (epoch 7.553), train_loss = 1.79219388, grad/param norm = 2.5092e-01, time/batch = 0.6256s	
1791/11850 (epoch 7.557), train_loss = 1.98188096, grad/param norm = 2.3826e-01, time/batch = 0.6261s	
1792/11850 (epoch 7.561), train_loss = 1.74269149, grad/param norm = 2.3305e-01, time/batch = 0.6221s	
1793/11850 (epoch 7.565), train_loss = 1.91043951, grad/param norm = 2.4386e-01, time/batch = 0.6227s	
1794/11850 (epoch 7.570), train_loss = 1.68613127, grad/param norm = 2.5489e-01, time/batch = 0.6302s	
1795/11850 (epoch 7.574), train_loss = 1.79731155, grad/param norm = 2.1070e-01, time/batch = 0.6532s	
1796/11850 (epoch 7.578), train_loss = 1.94003620, grad/param norm = 2.3929e-01, time/batch = 0.6270s	
1797/11850 (epoch 7.582), train_loss = 1.71482735, grad/param norm = 2.3096e-01, time/batch = 0.6349s	
1798/11850 (epoch 7.586), train_loss = 1.73940669, grad/param norm = 2.4773e-01, time/batch = 0.6400s	
1799/11850 (epoch 7.591), train_loss = 1.87675646, grad/param norm = 2.4224e-01, time/batch = 0.6297s	
1800/11850 (epoch 7.595), train_loss = 1.58905302, grad/param norm = 2.1158e-01, time/batch = 0.6272s	
1801/11850 (epoch 7.599), train_loss = 1.64813993, grad/param norm = 2.3398e-01, time/batch = 0.6273s	
1802/11850 (epoch 7.603), train_loss = 1.66782225, grad/param norm = 2.0538e-01, time/batch = 0.6354s	
1803/11850 (epoch 7.608), train_loss = 1.87703145, grad/param norm = 2.3901e-01, time/batch = 0.6294s	
1804/11850 (epoch 7.612), train_loss = 1.96294144, grad/param norm = 2.1937e-01, time/batch = 0.6252s	
1805/11850 (epoch 7.616), train_loss = 1.90918328, grad/param norm = 2.4600e-01, time/batch = 0.6276s	
1806/11850 (epoch 7.620), train_loss = 1.71678240, grad/param norm = 2.2910e-01, time/batch = 0.6287s	
1807/11850 (epoch 7.624), train_loss = 1.88257872, grad/param norm = 2.3922e-01, time/batch = 0.6271s	
1808/11850 (epoch 7.629), train_loss = 1.74424691, grad/param norm = 2.2613e-01, time/batch = 0.6235s	
1809/11850 (epoch 7.633), train_loss = 1.57820717, grad/param norm = 2.1382e-01, time/batch = 0.6246s	
1810/11850 (epoch 7.637), train_loss = 1.62024837, grad/param norm = 2.3027e-01, time/batch = 0.6246s	
1811/11850 (epoch 7.641), train_loss = 1.67802611, grad/param norm = 2.4298e-01, time/batch = 0.6257s	
1812/11850 (epoch 7.646), train_loss = 1.75106319, grad/param norm = 2.3844e-01, time/batch = 0.6246s	
1813/11850 (epoch 7.650), train_loss = 1.76930939, grad/param norm = 2.5105e-01, time/batch = 0.6256s	
1814/11850 (epoch 7.654), train_loss = 1.79683270, grad/param norm = 2.5370e-01, time/batch = 0.6257s	
1815/11850 (epoch 7.658), train_loss = 1.77183053, grad/param norm = 2.3197e-01, time/batch = 0.6275s	
1816/11850 (epoch 7.662), train_loss = 1.74743590, grad/param norm = 2.4558e-01, time/batch = 0.6290s	
1817/11850 (epoch 7.667), train_loss = 1.79421247, grad/param norm = 2.2591e-01, time/batch = 0.6252s	
1818/11850 (epoch 7.671), train_loss = 1.64729835, grad/param norm = 2.1997e-01, time/batch = 0.6280s	
1819/11850 (epoch 7.675), train_loss = 1.75043503, grad/param norm = 2.2454e-01, time/batch = 0.6279s	
1820/11850 (epoch 7.679), train_loss = 1.78984643, grad/param norm = 2.1967e-01, time/batch = 0.6266s	
1821/11850 (epoch 7.684), train_loss = 1.78356920, grad/param norm = 2.3263e-01, time/batch = 0.6287s	
1822/11850 (epoch 7.688), train_loss = 1.65779360, grad/param norm = 2.1306e-01, time/batch = 0.6260s	
1823/11850 (epoch 7.692), train_loss = 1.78677856, grad/param norm = 2.8078e-01, time/batch = 0.6266s	
1824/11850 (epoch 7.696), train_loss = 1.72030065, grad/param norm = 2.9141e-01, time/batch = 0.6309s	
1825/11850 (epoch 7.700), train_loss = 1.75405881, grad/param norm = 2.6782e-01, time/batch = 0.6268s	
1826/11850 (epoch 7.705), train_loss = 1.75425111, grad/param norm = 2.2855e-01, time/batch = 0.6276s	
1827/11850 (epoch 7.709), train_loss = 1.71116350, grad/param norm = 2.3640e-01, time/batch = 0.6253s	
1828/11850 (epoch 7.713), train_loss = 1.71348950, grad/param norm = 2.3595e-01, time/batch = 0.6266s	
1829/11850 (epoch 7.717), train_loss = 1.59406254, grad/param norm = 2.1114e-01, time/batch = 0.6261s	
1830/11850 (epoch 7.722), train_loss = 1.86259810, grad/param norm = 2.4227e-01, time/batch = 0.6258s	
1831/11850 (epoch 7.726), train_loss = 1.61152038, grad/param norm = 2.2978e-01, time/batch = 0.6326s	
1832/11850 (epoch 7.730), train_loss = 1.60304020, grad/param norm = 2.3375e-01, time/batch = 0.6368s	
1833/11850 (epoch 7.734), train_loss = 1.66965569, grad/param norm = 2.2956e-01, time/batch = 0.6318s	
1834/11850 (epoch 7.738), train_loss = 1.84896710, grad/param norm = 2.5337e-01, time/batch = 0.6276s	
1835/11850 (epoch 7.743), train_loss = 1.80286393, grad/param norm = 2.2803e-01, time/batch = 0.6273s	
1836/11850 (epoch 7.747), train_loss = 1.58563071, grad/param norm = 2.1809e-01, time/batch = 0.6412s	
1837/11850 (epoch 7.751), train_loss = 1.60149756, grad/param norm = 2.1330e-01, time/batch = 0.6268s	
1838/11850 (epoch 7.755), train_loss = 1.72366914, grad/param norm = 2.2625e-01, time/batch = 0.6295s	
1839/11850 (epoch 7.759), train_loss = 1.64520401, grad/param norm = 2.1333e-01, time/batch = 0.6237s	
1840/11850 (epoch 7.764), train_loss = 1.67100121, grad/param norm = 2.4339e-01, time/batch = 0.6238s	
1841/11850 (epoch 7.768), train_loss = 1.56196232, grad/param norm = 2.3817e-01, time/batch = 0.6262s	
1842/11850 (epoch 7.772), train_loss = 1.73235659, grad/param norm = 2.2072e-01, time/batch = 0.6235s	
1843/11850 (epoch 7.776), train_loss = 1.75814707, grad/param norm = 2.7438e-01, time/batch = 0.6219s	
1844/11850 (epoch 7.781), train_loss = 1.66573274, grad/param norm = 2.3656e-01, time/batch = 0.6243s	
1845/11850 (epoch 7.785), train_loss = 1.66646303, grad/param norm = 2.2248e-01, time/batch = 0.6248s	
1846/11850 (epoch 7.789), train_loss = 1.81120592, grad/param norm = 2.5093e-01, time/batch = 0.6257s	
1847/11850 (epoch 7.793), train_loss = 1.89328673, grad/param norm = 2.2495e-01, time/batch = 0.6235s	
1848/11850 (epoch 7.797), train_loss = 1.78611398, grad/param norm = 2.4215e-01, time/batch = 0.6255s	
1849/11850 (epoch 7.802), train_loss = 1.71859085, grad/param norm = 2.5115e-01, time/batch = 0.6256s	
1850/11850 (epoch 7.806), train_loss = 1.74025483, grad/param norm = 2.2579e-01, time/batch = 0.6281s	
1851/11850 (epoch 7.810), train_loss = 2.00878336, grad/param norm = 2.8401e-01, time/batch = 0.6300s	
1852/11850 (epoch 7.814), train_loss = 1.70167018, grad/param norm = 2.1059e-01, time/batch = 0.6266s	
1853/11850 (epoch 7.819), train_loss = 1.85752289, grad/param norm = 2.0452e-01, time/batch = 0.6247s	
1854/11850 (epoch 7.823), train_loss = 1.89042204, grad/param norm = 2.3480e-01, time/batch = 0.6246s	
1855/11850 (epoch 7.827), train_loss = 1.72738552, grad/param norm = 2.2976e-01, time/batch = 0.6218s	
1856/11850 (epoch 7.831), train_loss = 1.78495638, grad/param norm = 2.4295e-01, time/batch = 0.6228s	
1857/11850 (epoch 7.835), train_loss = 1.73615469, grad/param norm = 2.3188e-01, time/batch = 0.6236s	
1858/11850 (epoch 7.840), train_loss = 1.63437451, grad/param norm = 2.1813e-01, time/batch = 0.6261s	
1859/11850 (epoch 7.844), train_loss = 1.67034859, grad/param norm = 2.1222e-01, time/batch = 0.6240s	
1860/11850 (epoch 7.848), train_loss = 1.83099370, grad/param norm = 2.5214e-01, time/batch = 0.6243s	
1861/11850 (epoch 7.852), train_loss = 1.71879488, grad/param norm = 2.6310e-01, time/batch = 0.6281s	
1862/11850 (epoch 7.857), train_loss = 1.72209887, grad/param norm = 2.3872e-01, time/batch = 0.6258s	
1863/11850 (epoch 7.861), train_loss = 1.83357629, grad/param norm = 2.5025e-01, time/batch = 0.6285s	
1864/11850 (epoch 7.865), train_loss = 1.83383948, grad/param norm = 2.6776e-01, time/batch = 0.6576s	
1865/11850 (epoch 7.869), train_loss = 1.91590722, grad/param norm = 2.2454e-01, time/batch = 0.6613s	
1866/11850 (epoch 7.873), train_loss = 1.82795899, grad/param norm = 2.3104e-01, time/batch = 0.6633s	
1867/11850 (epoch 7.878), train_loss = 1.76799188, grad/param norm = 2.6688e-01, time/batch = 0.6562s	
1868/11850 (epoch 7.882), train_loss = 1.81313492, grad/param norm = 2.1851e-01, time/batch = 0.6356s	
1869/11850 (epoch 7.886), train_loss = 1.83725830, grad/param norm = 2.4016e-01, time/batch = 0.6511s	
1870/11850 (epoch 7.890), train_loss = 1.77682115, grad/param norm = 2.0545e-01, time/batch = 0.6487s	
1871/11850 (epoch 7.895), train_loss = 1.80142628, grad/param norm = 2.3918e-01, time/batch = 0.6432s	
1872/11850 (epoch 7.899), train_loss = 1.71471333, grad/param norm = 2.3236e-01, time/batch = 0.6549s	
1873/11850 (epoch 7.903), train_loss = 1.68549891, grad/param norm = 2.0136e-01, time/batch = 0.6517s	
1874/11850 (epoch 7.907), train_loss = 1.66914760, grad/param norm = 2.2571e-01, time/batch = 0.6535s	
1875/11850 (epoch 7.911), train_loss = 1.76879399, grad/param norm = 2.2895e-01, time/batch = 0.6759s	
1876/11850 (epoch 7.916), train_loss = 1.93564509, grad/param norm = 2.6560e-01, time/batch = 0.6469s	
1877/11850 (epoch 7.920), train_loss = 1.64779923, grad/param norm = 2.4697e-01, time/batch = 0.6417s	
1878/11850 (epoch 7.924), train_loss = 1.78402546, grad/param norm = 2.2553e-01, time/batch = 0.6424s	
1879/11850 (epoch 7.928), train_loss = 1.94269922, grad/param norm = 2.8596e-01, time/batch = 0.6412s	
1880/11850 (epoch 7.932), train_loss = 1.92076443, grad/param norm = 2.6074e-01, time/batch = 0.6387s	
1881/11850 (epoch 7.937), train_loss = 1.87180357, grad/param norm = 2.3009e-01, time/batch = 0.6421s	
1882/11850 (epoch 7.941), train_loss = 1.83469288, grad/param norm = 2.6401e-01, time/batch = 0.6428s	
1883/11850 (epoch 7.945), train_loss = 1.82469630, grad/param norm = 2.3096e-01, time/batch = 0.6456s	
1884/11850 (epoch 7.949), train_loss = 1.75426356, grad/param norm = 2.7218e-01, time/batch = 0.6404s	
1885/11850 (epoch 7.954), train_loss = 1.87605554, grad/param norm = 2.3625e-01, time/batch = 0.6430s	
1886/11850 (epoch 7.958), train_loss = 1.75684453, grad/param norm = 2.5374e-01, time/batch = 0.6420s	
1887/11850 (epoch 7.962), train_loss = 1.70137177, grad/param norm = 2.4518e-01, time/batch = 0.6400s	
1888/11850 (epoch 7.966), train_loss = 1.64964391, grad/param norm = 2.3904e-01, time/batch = 0.6371s	
1889/11850 (epoch 7.970), train_loss = 1.74844308, grad/param norm = 2.2677e-01, time/batch = 0.6363s	
1890/11850 (epoch 7.975), train_loss = 1.82816889, grad/param norm = 2.2744e-01, time/batch = 0.6341s	
1891/11850 (epoch 7.979), train_loss = 1.85333846, grad/param norm = 2.4940e-01, time/batch = 0.6367s	
1892/11850 (epoch 7.983), train_loss = 2.06162115, grad/param norm = 3.8071e-01, time/batch = 0.6365s	
1893/11850 (epoch 7.987), train_loss = 1.80676906, grad/param norm = 2.5177e-01, time/batch = 0.6385s	
1894/11850 (epoch 7.992), train_loss = 1.89276507, grad/param norm = 2.0797e-01, time/batch = 0.6382s	
1895/11850 (epoch 7.996), train_loss = 2.06817943, grad/param norm = 2.3091e-01, time/batch = 0.6398s	
1896/11850 (epoch 8.000), train_loss = 1.76623120, grad/param norm = 2.4070e-01, time/batch = 0.6725s	
1897/11850 (epoch 8.004), train_loss = 1.85761813, grad/param norm = 2.5093e-01, time/batch = 0.6423s	
1898/11850 (epoch 8.008), train_loss = 1.80373000, grad/param norm = 2.0941e-01, time/batch = 0.6453s	
1899/11850 (epoch 8.013), train_loss = 1.79319026, grad/param norm = 2.1651e-01, time/batch = 0.6451s	
1900/11850 (epoch 8.017), train_loss = 1.96824178, grad/param norm = 2.1984e-01, time/batch = 0.6400s	
1901/11850 (epoch 8.021), train_loss = 1.65091864, grad/param norm = 2.0239e-01, time/batch = 0.6461s	
1902/11850 (epoch 8.025), train_loss = 1.49799143, grad/param norm = 1.7874e-01, time/batch = 0.6436s	
1903/11850 (epoch 8.030), train_loss = 1.64733929, grad/param norm = 2.1600e-01, time/batch = 0.6380s	
1904/11850 (epoch 8.034), train_loss = 1.63408173, grad/param norm = 2.0909e-01, time/batch = 0.6425s	
1905/11850 (epoch 8.038), train_loss = 1.68974965, grad/param norm = 2.0522e-01, time/batch = 0.6378s	
1906/11850 (epoch 8.042), train_loss = 1.79305825, grad/param norm = 2.1644e-01, time/batch = 0.6391s	
1907/11850 (epoch 8.046), train_loss = 1.88858126, grad/param norm = 2.4018e-01, time/batch = 0.6407s	
1908/11850 (epoch 8.051), train_loss = 1.70704883, grad/param norm = 2.2489e-01, time/batch = 0.6381s	
1909/11850 (epoch 8.055), train_loss = 1.74225390, grad/param norm = 2.5141e-01, time/batch = 0.6384s	
1910/11850 (epoch 8.059), train_loss = 1.80562870, grad/param norm = 2.2869e-01, time/batch = 0.6345s	
1911/11850 (epoch 8.063), train_loss = 1.75868604, grad/param norm = 2.1486e-01, time/batch = 0.6375s	
1912/11850 (epoch 8.068), train_loss = 1.72023293, grad/param norm = 2.0594e-01, time/batch = 0.6382s	
1913/11850 (epoch 8.072), train_loss = 1.70794511, grad/param norm = 1.9902e-01, time/batch = 0.6383s	
1914/11850 (epoch 8.076), train_loss = 1.90201095, grad/param norm = 2.2554e-01, time/batch = 0.6358s	
1915/11850 (epoch 8.080), train_loss = 1.72603950, grad/param norm = 2.1475e-01, time/batch = 0.6385s	
1916/11850 (epoch 8.084), train_loss = 1.57818556, grad/param norm = 2.0936e-01, time/batch = 0.6365s	
1917/11850 (epoch 8.089), train_loss = 1.61273088, grad/param norm = 2.0499e-01, time/batch = 0.6380s	
1918/11850 (epoch 8.093), train_loss = 1.56330798, grad/param norm = 2.0554e-01, time/batch = 0.6374s	
1919/11850 (epoch 8.097), train_loss = 1.91791999, grad/param norm = 2.4200e-01, time/batch = 0.6378s	
1920/11850 (epoch 8.101), train_loss = 1.82558210, grad/param norm = 2.3686e-01, time/batch = 0.6375s	
1921/11850 (epoch 8.105), train_loss = 1.62649453, grad/param norm = 1.9856e-01, time/batch = 0.6346s	
1922/11850 (epoch 8.110), train_loss = 1.71105495, grad/param norm = 2.1164e-01, time/batch = 0.6356s	
1923/11850 (epoch 8.114), train_loss = 1.82632791, grad/param norm = 2.4802e-01, time/batch = 0.6385s	
1924/11850 (epoch 8.118), train_loss = 1.67100380, grad/param norm = 2.1820e-01, time/batch = 0.6351s	
1925/11850 (epoch 8.122), train_loss = 1.82745900, grad/param norm = 2.3234e-01, time/batch = 0.6367s	
1926/11850 (epoch 8.127), train_loss = 1.80042775, grad/param norm = 2.5780e-01, time/batch = 0.6340s	
1927/11850 (epoch 8.131), train_loss = 1.85029378, grad/param norm = 2.6620e-01, time/batch = 0.6362s	
1928/11850 (epoch 8.135), train_loss = 1.71564999, grad/param norm = 2.2933e-01, time/batch = 0.6375s	
1929/11850 (epoch 8.139), train_loss = 1.78282874, grad/param norm = 2.1876e-01, time/batch = 0.6356s	
1930/11850 (epoch 8.143), train_loss = 1.69787724, grad/param norm = 2.2120e-01, time/batch = 0.6442s	
1931/11850 (epoch 8.148), train_loss = 1.75279690, grad/param norm = 2.3569e-01, time/batch = 0.6367s	
1932/11850 (epoch 8.152), train_loss = 1.78957534, grad/param norm = 2.4588e-01, time/batch = 0.6400s	
1933/11850 (epoch 8.156), train_loss = 1.85135332, grad/param norm = 2.3296e-01, time/batch = 0.6392s	
1934/11850 (epoch 8.160), train_loss = 2.12582436, grad/param norm = 2.7475e-01, time/batch = 0.6380s	
1935/11850 (epoch 8.165), train_loss = 1.92076815, grad/param norm = 2.6819e-01, time/batch = 0.6355s	
1936/11850 (epoch 8.169), train_loss = 1.70592212, grad/param norm = 2.3086e-01, time/batch = 0.6358s	
1937/11850 (epoch 8.173), train_loss = 1.82144627, grad/param norm = 2.2681e-01, time/batch = 0.6483s	
1938/11850 (epoch 8.177), train_loss = 1.84008167, grad/param norm = 2.7974e-01, time/batch = 0.6424s	
1939/11850 (epoch 8.181), train_loss = 1.80529839, grad/param norm = 2.1977e-01, time/batch = 0.6373s	
1940/11850 (epoch 8.186), train_loss = 1.89787566, grad/param norm = 2.4657e-01, time/batch = 0.6385s	
1941/11850 (epoch 8.190), train_loss = 1.77253582, grad/param norm = 2.1628e-01, time/batch = 0.6413s	
1942/11850 (epoch 8.194), train_loss = 1.90771203, grad/param norm = 2.5960e-01, time/batch = 0.6420s	
1943/11850 (epoch 8.198), train_loss = 1.70806074, grad/param norm = 2.5961e-01, time/batch = 0.6399s	
1944/11850 (epoch 8.203), train_loss = 1.53171455, grad/param norm = 1.9169e-01, time/batch = 0.6410s	
1945/11850 (epoch 8.207), train_loss = 1.79779237, grad/param norm = 2.4628e-01, time/batch = 0.6513s	
1946/11850 (epoch 8.211), train_loss = 1.72842272, grad/param norm = 2.0040e-01, time/batch = 0.6463s	
1947/11850 (epoch 8.215), train_loss = 1.72761896, grad/param norm = 2.1449e-01, time/batch = 0.6366s	
1948/11850 (epoch 8.219), train_loss = 1.66829284, grad/param norm = 2.1099e-01, time/batch = 0.6372s	
1949/11850 (epoch 8.224), train_loss = 1.98627290, grad/param norm = 2.3106e-01, time/batch = 0.6395s	
1950/11850 (epoch 8.228), train_loss = 1.89856524, grad/param norm = 2.0698e-01, time/batch = 0.6385s	
1951/11850 (epoch 8.232), train_loss = 1.80002907, grad/param norm = 2.5120e-01, time/batch = 0.6386s	
1952/11850 (epoch 8.236), train_loss = 1.72267283, grad/param norm = 2.3892e-01, time/batch = 0.6400s	
1953/11850 (epoch 8.241), train_loss = 1.96844792, grad/param norm = 2.2077e-01, time/batch = 0.6389s	
1954/11850 (epoch 8.245), train_loss = 1.82988022, grad/param norm = 2.2192e-01, time/batch = 0.6371s	
1955/11850 (epoch 8.249), train_loss = 1.68032879, grad/param norm = 2.1562e-01, time/batch = 0.6359s	
1956/11850 (epoch 8.253), train_loss = 1.82225431, grad/param norm = 2.8666e-01, time/batch = 0.6390s	
1957/11850 (epoch 8.257), train_loss = 1.84975331, grad/param norm = 2.2941e-01, time/batch = 0.6591s	
1958/11850 (epoch 8.262), train_loss = 1.93193139, grad/param norm = 2.2359e-01, time/batch = 0.6759s	
1959/11850 (epoch 8.266), train_loss = 1.81801591, grad/param norm = 2.3847e-01, time/batch = 0.6707s	
1960/11850 (epoch 8.270), train_loss = 1.71046760, grad/param norm = 1.9982e-01, time/batch = 0.6588s	
1961/11850 (epoch 8.274), train_loss = 1.69922864, grad/param norm = 2.4120e-01, time/batch = 0.6558s	
1962/11850 (epoch 8.278), train_loss = 1.58593895, grad/param norm = 2.2853e-01, time/batch = 0.6550s	
1963/11850 (epoch 8.283), train_loss = 1.67157972, grad/param norm = 2.3949e-01, time/batch = 0.6561s	
1964/11850 (epoch 8.287), train_loss = 1.80738269, grad/param norm = 2.1561e-01, time/batch = 0.6514s	
1965/11850 (epoch 8.291), train_loss = 1.82717202, grad/param norm = 2.3985e-01, time/batch = 0.6499s	
1966/11850 (epoch 8.295), train_loss = 1.72135837, grad/param norm = 2.1222e-01, time/batch = 0.6435s	
1967/11850 (epoch 8.300), train_loss = 1.65359693, grad/param norm = 2.3998e-01, time/batch = 0.6444s	
1968/11850 (epoch 8.304), train_loss = 1.67030225, grad/param norm = 2.4002e-01, time/batch = 0.6430s	
1969/11850 (epoch 8.308), train_loss = 1.61523083, grad/param norm = 2.1148e-01, time/batch = 0.6441s	
1970/11850 (epoch 8.312), train_loss = 1.53367921, grad/param norm = 2.2270e-01, time/batch = 0.6423s	
1971/11850 (epoch 8.316), train_loss = 1.70608344, grad/param norm = 2.1314e-01, time/batch = 0.6460s	
1972/11850 (epoch 8.321), train_loss = 1.67125755, grad/param norm = 1.9989e-01, time/batch = 0.6450s	
1973/11850 (epoch 8.325), train_loss = 1.74607107, grad/param norm = 2.3129e-01, time/batch = 0.6473s	
1974/11850 (epoch 8.329), train_loss = 1.72711002, grad/param norm = 2.3979e-01, time/batch = 0.6474s	
1975/11850 (epoch 8.333), train_loss = 1.73284189, grad/param norm = 2.3209e-01, time/batch = 0.6487s	
1976/11850 (epoch 8.338), train_loss = 1.61656940, grad/param norm = 1.9762e-01, time/batch = 0.6406s	
1977/11850 (epoch 8.342), train_loss = 1.90769543, grad/param norm = 2.6380e-01, time/batch = 0.6417s	
1978/11850 (epoch 8.346), train_loss = 1.78295596, grad/param norm = 2.4937e-01, time/batch = 0.6417s	
1979/11850 (epoch 8.350), train_loss = 1.57979555, grad/param norm = 2.0580e-01, time/batch = 0.6377s	
1980/11850 (epoch 8.354), train_loss = 1.84679829, grad/param norm = 2.4487e-01, time/batch = 0.6366s	
1981/11850 (epoch 8.359), train_loss = 1.80416806, grad/param norm = 2.9423e-01, time/batch = 0.6471s	
1982/11850 (epoch 8.363), train_loss = 1.69906622, grad/param norm = 2.0552e-01, time/batch = 0.6379s	
1983/11850 (epoch 8.367), train_loss = 1.71863645, grad/param norm = 2.0379e-01, time/batch = 0.6430s	
1984/11850 (epoch 8.371), train_loss = 1.71471742, grad/param norm = 2.0535e-01, time/batch = 0.6373s	
1985/11850 (epoch 8.376), train_loss = 1.66797761, grad/param norm = 2.0086e-01, time/batch = 0.6395s	
1986/11850 (epoch 8.380), train_loss = 1.65399559, grad/param norm = 2.2048e-01, time/batch = 0.6390s	
1987/11850 (epoch 8.384), train_loss = 1.67317960, grad/param norm = 2.3364e-01, time/batch = 0.6414s	
1988/11850 (epoch 8.388), train_loss = 1.82867040, grad/param norm = 2.6572e-01, time/batch = 0.6405s	
1989/11850 (epoch 8.392), train_loss = 1.84497363, grad/param norm = 2.2713e-01, time/batch = 0.6379s	
1990/11850 (epoch 8.397), train_loss = 1.87044121, grad/param norm = 2.6961e-01, time/batch = 0.6381s	
1991/11850 (epoch 8.401), train_loss = 1.53860777, grad/param norm = 2.1735e-01, time/batch = 0.6394s	
1992/11850 (epoch 8.405), train_loss = 1.64167644, grad/param norm = 2.0918e-01, time/batch = 0.6423s	
1993/11850 (epoch 8.409), train_loss = 1.82782470, grad/param norm = 2.2691e-01, time/batch = 0.6384s	
1994/11850 (epoch 8.414), train_loss = 1.58098423, grad/param norm = 2.1128e-01, time/batch = 0.6398s	
1995/11850 (epoch 8.418), train_loss = 1.59375555, grad/param norm = 2.5728e-01, time/batch = 0.6357s	
1996/11850 (epoch 8.422), train_loss = 1.57233636, grad/param norm = 2.2331e-01, time/batch = 0.6370s	
1997/11850 (epoch 8.426), train_loss = 1.65735559, grad/param norm = 2.1714e-01, time/batch = 0.6363s	
1998/11850 (epoch 8.430), train_loss = 1.64125130, grad/param norm = 2.3550e-01, time/batch = 0.6447s	
1999/11850 (epoch 8.435), train_loss = 1.65704743, grad/param norm = 2.0945e-01, time/batch = 0.6603s	
evaluating loss over split index 2	
1/13...	
2/13...	
3/13...	
4/13...	
5/13...	
6/13...	
7/13...	
8/13...	
9/13...	
10/13...	
11/13...	
12/13...	
13/13...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_katelyn_salem_epoch8.44_1.9067.t7	
2000/11850 (epoch 8.439), train_loss = 1.79232350, grad/param norm = 2.2258e-01, time/batch = 0.6441s	
2001/11850 (epoch 8.443), train_loss = 1.91262698, grad/param norm = 2.5247e-01, time/batch = 0.6449s	
2002/11850 (epoch 8.447), train_loss = 1.65320462, grad/param norm = 2.2031e-01, time/batch = 0.6447s	
2003/11850 (epoch 8.451), train_loss = 1.58940703, grad/param norm = 2.2801e-01, time/batch = 0.6420s	
2004/11850 (epoch 8.456), train_loss = 1.70442186, grad/param norm = 2.3309e-01, time/batch = 0.6433s	
2005/11850 (epoch 8.460), train_loss = 1.75471818, grad/param norm = 2.3563e-01, time/batch = 0.6573s	
2006/11850 (epoch 8.464), train_loss = 1.69644401, grad/param norm = 2.5380e-01, time/batch = 0.6731s	
2007/11850 (epoch 8.468), train_loss = 1.74801306, grad/param norm = 2.1472e-01, time/batch = 0.6625s	
2008/11850 (epoch 8.473), train_loss = 1.79370063, grad/param norm = 2.4302e-01, time/batch = 0.6540s	
2009/11850 (epoch 8.477), train_loss = 1.52977867, grad/param norm = 2.1049e-01, time/batch = 0.6464s	
2010/11850 (epoch 8.481), train_loss = 1.61371422, grad/param norm = 2.4327e-01, time/batch = 0.6399s	
2011/11850 (epoch 8.485), train_loss = 1.53367372, grad/param norm = 1.8759e-01, time/batch = 0.6476s	
2012/11850 (epoch 8.489), train_loss = 1.75567138, grad/param norm = 2.2830e-01, time/batch = 0.6383s	
2013/11850 (epoch 8.494), train_loss = 1.67813459, grad/param norm = 2.2245e-01, time/batch = 0.6378s	
2014/11850 (epoch 8.498), train_loss = 1.67614133, grad/param norm = 2.3859e-01, time/batch = 0.6426s	
2015/11850 (epoch 8.502), train_loss = 1.51761546, grad/param norm = 2.3126e-01, time/batch = 0.6380s	
2016/11850 (epoch 8.506), train_loss = 1.83262009, grad/param norm = 2.4699e-01, time/batch = 0.6497s	
2017/11850 (epoch 8.511), train_loss = 1.64116793, grad/param norm = 2.0455e-01, time/batch = 0.6700s	
2018/11850 (epoch 8.515), train_loss = 1.83853158, grad/param norm = 2.5997e-01, time/batch = 0.6459s	
2019/11850 (epoch 8.519), train_loss = 1.64993721, grad/param norm = 2.1474e-01, time/batch = 0.6520s	
2020/11850 (epoch 8.523), train_loss = 1.68245749, grad/param norm = 2.1785e-01, time/batch = 0.6491s	
2021/11850 (epoch 8.527), train_loss = 1.61162700, grad/param norm = 2.3771e-01, time/batch = 0.6443s	
2022/11850 (epoch 8.532), train_loss = 1.78180439, grad/param norm = 2.2309e-01, time/batch = 0.6407s	
2023/11850 (epoch 8.536), train_loss = 1.61783303, grad/param norm = 2.1167e-01, time/batch = 0.6389s	
2024/11850 (epoch 8.540), train_loss = 1.58884267, grad/param norm = 1.9504e-01, time/batch = 0.6388s	
2025/11850 (epoch 8.544), train_loss = 1.71202166, grad/param norm = 2.4137e-01, time/batch = 0.6387s	
2026/11850 (epoch 8.549), train_loss = 1.42865928, grad/param norm = 2.1327e-01, time/batch = 0.6364s	
2027/11850 (epoch 8.553), train_loss = 1.72854009, grad/param norm = 2.3720e-01, time/batch = 0.6494s	
2028/11850 (epoch 8.557), train_loss = 1.91623844, grad/param norm = 2.4284e-01, time/batch = 0.6614s	
2029/11850 (epoch 8.561), train_loss = 1.68868574, grad/param norm = 2.2683e-01, time/batch = 0.6440s	
2030/11850 (epoch 8.565), train_loss = 1.84659338, grad/param norm = 2.3751e-01, time/batch = 0.6472s	
2031/11850 (epoch 8.570), train_loss = 1.63291448, grad/param norm = 2.4386e-01, time/batch = 0.6400s	
2032/11850 (epoch 8.574), train_loss = 1.73371307, grad/param norm = 2.0184e-01, time/batch = 0.6356s	
2033/11850 (epoch 8.578), train_loss = 1.88511978, grad/param norm = 2.3890e-01, time/batch = 0.6409s	
2034/11850 (epoch 8.582), train_loss = 1.64800836, grad/param norm = 2.2119e-01, time/batch = 0.6379s	
2035/11850 (epoch 8.586), train_loss = 1.67643856, grad/param norm = 2.4997e-01, time/batch = 0.6399s	
2036/11850 (epoch 8.591), train_loss = 1.81800777, grad/param norm = 2.2769e-01, time/batch = 0.6391s	
2037/11850 (epoch 8.595), train_loss = 1.52765998, grad/param norm = 2.0372e-01, time/batch = 0.6376s	
2038/11850 (epoch 8.599), train_loss = 1.59534795, grad/param norm = 2.2831e-01, time/batch = 0.6624s	
2039/11850 (epoch 8.603), train_loss = 1.60979613, grad/param norm = 2.0639e-01, time/batch = 0.6630s	
2040/11850 (epoch 8.608), train_loss = 1.81170907, grad/param norm = 2.2496e-01, time/batch = 0.6379s	
2041/11850 (epoch 8.612), train_loss = 1.90595556, grad/param norm = 2.2013e-01, time/batch = 0.6424s	
2042/11850 (epoch 8.616), train_loss = 1.85167045, grad/param norm = 2.4361e-01, time/batch = 0.6456s	
2043/11850 (epoch 8.620), train_loss = 1.66161299, grad/param norm = 2.2046e-01, time/batch = 0.6393s	
2044/11850 (epoch 8.624), train_loss = 1.81021091, grad/param norm = 2.3562e-01, time/batch = 0.6462s	
2045/11850 (epoch 8.629), train_loss = 1.66730897, grad/param norm = 2.2016e-01, time/batch = 0.6681s	
2046/11850 (epoch 8.633), train_loss = 1.51409618, grad/param norm = 2.0815e-01, time/batch = 0.6689s	
2047/11850 (epoch 8.637), train_loss = 1.55663882, grad/param norm = 2.1989e-01, time/batch = 0.6710s	
2048/11850 (epoch 8.641), train_loss = 1.60611459, grad/param norm = 2.2876e-01, time/batch = 0.6762s	
2049/11850 (epoch 8.646), train_loss = 1.69147806, grad/param norm = 2.4248e-01, time/batch = 0.6718s	
2050/11850 (epoch 8.650), train_loss = 1.70944503, grad/param norm = 2.2804e-01, time/batch = 0.6596s	
2051/11850 (epoch 8.654), train_loss = 1.73621536, grad/param norm = 2.4943e-01, time/batch = 0.6672s	
2052/11850 (epoch 8.658), train_loss = 1.71471647, grad/param norm = 2.1964e-01, time/batch = 0.6746s	
2053/11850 (epoch 8.662), train_loss = 1.68257728, grad/param norm = 2.5187e-01, time/batch = 0.6741s	
2054/11850 (epoch 8.667), train_loss = 1.74546417, grad/param norm = 2.3068e-01, time/batch = 0.6679s	
2055/11850 (epoch 8.671), train_loss = 1.58706142, grad/param norm = 2.0980e-01, time/batch = 0.6570s	
2056/11850 (epoch 8.675), train_loss = 1.67973675, grad/param norm = 2.1718e-01, time/batch = 0.6407s	
2057/11850 (epoch 8.679), train_loss = 1.71838369, grad/param norm = 2.2144e-01, time/batch = 0.6421s	
2058/11850 (epoch 8.684), train_loss = 1.71944337, grad/param norm = 2.3183e-01, time/batch = 0.6423s	
2059/11850 (epoch 8.688), train_loss = 1.59578686, grad/param norm = 2.0315e-01, time/batch = 0.6408s	
2060/11850 (epoch 8.692), train_loss = 1.71699871, grad/param norm = 2.7061e-01, time/batch = 0.6589s	
2061/11850 (epoch 8.696), train_loss = 1.64488663, grad/param norm = 2.6688e-01, time/batch = 0.6774s	
2062/11850 (epoch 8.700), train_loss = 1.68901270, grad/param norm = 2.4139e-01, time/batch = 0.6449s	
2063/11850 (epoch 8.705), train_loss = 1.68212765, grad/param norm = 2.2379e-01, time/batch = 0.6366s	
2064/11850 (epoch 8.709), train_loss = 1.63752089, grad/param norm = 2.3050e-01, time/batch = 0.6390s	
2065/11850 (epoch 8.713), train_loss = 1.65165491, grad/param norm = 2.3722e-01, time/batch = 0.6398s	
2066/11850 (epoch 8.717), train_loss = 1.53736438, grad/param norm = 2.0739e-01, time/batch = 0.6386s	
2067/11850 (epoch 8.722), train_loss = 1.79198353, grad/param norm = 2.4507e-01, time/batch = 0.6400s	
2068/11850 (epoch 8.726), train_loss = 1.54195650, grad/param norm = 2.3581e-01, time/batch = 0.6430s	
2069/11850 (epoch 8.730), train_loss = 1.54345150, grad/param norm = 2.3251e-01, time/batch = 0.6377s	
2070/11850 (epoch 8.734), train_loss = 1.60116500, grad/param norm = 2.1638e-01, time/batch = 0.6391s	
2071/11850 (epoch 8.738), train_loss = 1.79225154, grad/param norm = 2.5166e-01, time/batch = 0.6411s	
2072/11850 (epoch 8.743), train_loss = 1.74014337, grad/param norm = 2.2254e-01, time/batch = 0.6382s	
2073/11850 (epoch 8.747), train_loss = 1.51016967, grad/param norm = 2.1744e-01, time/batch = 0.6390s	
2074/11850 (epoch 8.751), train_loss = 1.54244269, grad/param norm = 2.0838e-01, time/batch = 0.6376s	
2075/11850 (epoch 8.755), train_loss = 1.66125917, grad/param norm = 2.3009e-01, time/batch = 0.6369s	
2076/11850 (epoch 8.759), train_loss = 1.58362056, grad/param norm = 2.1381e-01, time/batch = 0.6373s	
2077/11850 (epoch 8.764), train_loss = 1.61351118, grad/param norm = 2.3189e-01, time/batch = 0.6364s	
2078/11850 (epoch 8.768), train_loss = 1.49917218, grad/param norm = 2.3345e-01, time/batch = 0.6357s	
2079/11850 (epoch 8.772), train_loss = 1.67022318, grad/param norm = 2.2079e-01, time/batch = 0.6421s	
2080/11850 (epoch 8.776), train_loss = 1.69525835, grad/param norm = 2.6196e-01, time/batch = 0.6451s	
2081/11850 (epoch 8.781), train_loss = 1.60676585, grad/param norm = 2.2579e-01, time/batch = 0.6395s	
2082/11850 (epoch 8.785), train_loss = 1.59746176, grad/param norm = 2.1759e-01, time/batch = 0.6416s	
2083/11850 (epoch 8.789), train_loss = 1.74119004, grad/param norm = 2.3873e-01, time/batch = 0.6363s	
2084/11850 (epoch 8.793), train_loss = 1.82770465, grad/param norm = 2.2066e-01, time/batch = 0.6375s	
2085/11850 (epoch 8.797), train_loss = 1.71599007, grad/param norm = 2.2578e-01, time/batch = 0.6369s	
2086/11850 (epoch 8.802), train_loss = 1.64010266, grad/param norm = 2.4849e-01, time/batch = 0.6375s	
2087/11850 (epoch 8.806), train_loss = 1.67483743, grad/param norm = 2.2496e-01, time/batch = 0.6396s	
2088/11850 (epoch 8.810), train_loss = 1.95410114, grad/param norm = 2.8625e-01, time/batch = 0.6389s	
2089/11850 (epoch 8.814), train_loss = 1.64222522, grad/param norm = 2.0562e-01, time/batch = 0.6416s	
2090/11850 (epoch 8.819), train_loss = 1.79873325, grad/param norm = 2.0556e-01, time/batch = 0.6407s	
2091/11850 (epoch 8.823), train_loss = 1.83126230, grad/param norm = 2.2928e-01, time/batch = 0.6409s	
2092/11850 (epoch 8.827), train_loss = 1.67204511, grad/param norm = 2.1880e-01, time/batch = 0.6566s	
2093/11850 (epoch 8.831), train_loss = 1.71313284, grad/param norm = 2.3332e-01, time/batch = 0.6525s	
2094/11850 (epoch 8.835), train_loss = 1.67407589, grad/param norm = 2.2517e-01, time/batch = 0.6347s	
2095/11850 (epoch 8.840), train_loss = 1.58152369, grad/param norm = 2.1578e-01, time/batch = 0.6379s	
2096/11850 (epoch 8.844), train_loss = 1.60413806, grad/param norm = 2.0396e-01, time/batch = 0.6371s	
2097/11850 (epoch 8.848), train_loss = 1.75941539, grad/param norm = 2.4220e-01, time/batch = 0.6376s	
2098/11850 (epoch 8.852), train_loss = 1.65412597, grad/param norm = 2.4678e-01, time/batch = 0.6389s	
2099/11850 (epoch 8.857), train_loss = 1.65022693, grad/param norm = 2.2092e-01, time/batch = 0.6428s	
2100/11850 (epoch 8.861), train_loss = 1.76600250, grad/param norm = 2.4039e-01, time/batch = 0.6399s	
2101/11850 (epoch 8.865), train_loss = 1.77088253, grad/param norm = 2.5463e-01, time/batch = 0.6452s	
2102/11850 (epoch 8.869), train_loss = 1.84000219, grad/param norm = 2.2428e-01, time/batch = 0.6426s	
2103/11850 (epoch 8.873), train_loss = 1.77283604, grad/param norm = 2.3430e-01, time/batch = 0.6729s	
2104/11850 (epoch 8.878), train_loss = 1.70962929, grad/param norm = 2.7286e-01, time/batch = 0.6523s	
2105/11850 (epoch 8.882), train_loss = 1.75665835, grad/param norm = 2.1863e-01, time/batch = 0.6362s	
2106/11850 (epoch 8.886), train_loss = 1.78461209, grad/param norm = 2.5050e-01, time/batch = 0.6409s	
2107/11850 (epoch 8.890), train_loss = 1.72962193, grad/param norm = 2.0981e-01, time/batch = 0.6371s	
2108/11850 (epoch 8.895), train_loss = 1.74671490, grad/param norm = 2.3876e-01, time/batch = 0.6351s	
2109/11850 (epoch 8.899), train_loss = 1.63912661, grad/param norm = 2.2689e-01, time/batch = 0.6387s	
2110/11850 (epoch 8.903), train_loss = 1.62418768, grad/param norm = 1.9740e-01, time/batch = 0.6364s	
2111/11850 (epoch 8.907), train_loss = 1.60644863, grad/param norm = 2.1911e-01, time/batch = 0.6361s	
2112/11850 (epoch 8.911), train_loss = 1.72373170, grad/param norm = 2.2786e-01, time/batch = 0.6414s	
2113/11850 (epoch 8.916), train_loss = 1.87130585, grad/param norm = 2.6133e-01, time/batch = 0.6459s	
2114/11850 (epoch 8.920), train_loss = 1.58993841, grad/param norm = 2.2146e-01, time/batch = 0.6558s	
2115/11850 (epoch 8.924), train_loss = 1.72922204, grad/param norm = 2.2567e-01, time/batch = 0.6442s	
2116/11850 (epoch 8.928), train_loss = 1.87069487, grad/param norm = 2.7902e-01, time/batch = 0.6352s	
2117/11850 (epoch 8.932), train_loss = 1.85720397, grad/param norm = 2.5183e-01, time/batch = 0.6394s	
2118/11850 (epoch 8.937), train_loss = 1.81106810, grad/param norm = 2.2544e-01, time/batch = 0.6464s	
2119/11850 (epoch 8.941), train_loss = 1.77421558, grad/param norm = 2.6079e-01, time/batch = 0.6389s	
2120/11850 (epoch 8.945), train_loss = 1.75920444, grad/param norm = 2.1613e-01, time/batch = 0.6372s	
2121/11850 (epoch 8.949), train_loss = 1.67440323, grad/param norm = 2.5053e-01, time/batch = 0.6436s	
2122/11850 (epoch 8.954), train_loss = 1.80501505, grad/param norm = 2.2776e-01, time/batch = 0.6401s	
2123/11850 (epoch 8.958), train_loss = 1.70867321, grad/param norm = 2.3683e-01, time/batch = 0.6383s	
2124/11850 (epoch 8.962), train_loss = 1.61913930, grad/param norm = 2.2998e-01, time/batch = 0.6431s	
2125/11850 (epoch 8.966), train_loss = 1.58301170, grad/param norm = 2.2987e-01, time/batch = 0.6385s	
2126/11850 (epoch 8.970), train_loss = 1.69231534, grad/param norm = 2.2799e-01, time/batch = 0.6407s	
2127/11850 (epoch 8.975), train_loss = 1.75427749, grad/param norm = 2.2813e-01, time/batch = 0.6358s	
2128/11850 (epoch 8.979), train_loss = 1.78441224, grad/param norm = 2.4723e-01, time/batch = 0.6380s	
2129/11850 (epoch 8.983), train_loss = 1.96842300, grad/param norm = 3.0690e-01, time/batch = 0.6329s	
2130/11850 (epoch 8.987), train_loss = 1.73151623, grad/param norm = 2.3736e-01, time/batch = 0.6365s	
2131/11850 (epoch 8.992), train_loss = 1.84308144, grad/param norm = 2.0382e-01, time/batch = 0.6265s	
2132/11850 (epoch 8.996), train_loss = 1.99778874, grad/param norm = 2.2605e-01, time/batch = 0.6254s	
2133/11850 (epoch 9.000), train_loss = 1.68849015, grad/param norm = 2.4378e-01, time/batch = 0.6258s	
2134/11850 (epoch 9.004), train_loss = 1.80570396, grad/param norm = 2.5753e-01, time/batch = 0.6246s	
2135/11850 (epoch 9.008), train_loss = 1.74867492, grad/param norm = 2.0785e-01, time/batch = 0.6240s	
2136/11850 (epoch 9.013), train_loss = 1.74110370, grad/param norm = 2.2585e-01, time/batch = 0.6288s	
2137/11850 (epoch 9.017), train_loss = 1.92201766, grad/param norm = 2.1619e-01, time/batch = 0.6261s	
2138/11850 (epoch 9.021), train_loss = 1.59583269, grad/param norm = 1.9875e-01, time/batch = 0.6312s	
2139/11850 (epoch 9.025), train_loss = 1.44590245, grad/param norm = 1.7497e-01, time/batch = 0.6492s	
2140/11850 (epoch 9.030), train_loss = 1.57696592, grad/param norm = 2.1108e-01, time/batch = 0.6613s	
2141/11850 (epoch 9.034), train_loss = 1.57215060, grad/param norm = 2.1167e-01, time/batch = 0.6509s	
2142/11850 (epoch 9.038), train_loss = 1.63561954, grad/param norm = 2.0810e-01, time/batch = 0.6523s	
2143/11850 (epoch 9.042), train_loss = 1.73386416, grad/param norm = 2.2707e-01, time/batch = 0.6499s	
2144/11850 (epoch 9.046), train_loss = 1.81318502, grad/param norm = 2.3863e-01, time/batch = 0.6465s	
2145/11850 (epoch 9.051), train_loss = 1.65509110, grad/param norm = 2.2614e-01, time/batch = 0.6322s	
2146/11850 (epoch 9.055), train_loss = 1.67681449, grad/param norm = 2.3304e-01, time/batch = 0.6249s	
2147/11850 (epoch 9.059), train_loss = 1.74207814, grad/param norm = 2.3291e-01, time/batch = 0.6250s	
2148/11850 (epoch 9.063), train_loss = 1.69818750, grad/param norm = 2.1620e-01, time/batch = 0.6279s	
2149/11850 (epoch 9.068), train_loss = 1.66948213, grad/param norm = 2.1780e-01, time/batch = 0.6252s	
2150/11850 (epoch 9.072), train_loss = 1.65315241, grad/param norm = 1.9268e-01, time/batch = 0.6254s	
2151/11850 (epoch 9.076), train_loss = 1.84089293, grad/param norm = 2.2131e-01, time/batch = 0.6522s	
2152/11850 (epoch 9.080), train_loss = 1.66257665, grad/param norm = 2.1307e-01, time/batch = 0.6504s	
2153/11850 (epoch 9.084), train_loss = 1.51967663, grad/param norm = 2.0696e-01, time/batch = 0.6263s	
2154/11850 (epoch 9.089), train_loss = 1.55338188, grad/param norm = 2.0153e-01, time/batch = 0.6249s	
2155/11850 (epoch 9.093), train_loss = 1.49769977, grad/param norm = 1.9702e-01, time/batch = 0.6258s	
2156/11850 (epoch 9.097), train_loss = 1.83060814, grad/param norm = 2.2481e-01, time/batch = 0.6261s	
2157/11850 (epoch 9.101), train_loss = 1.74472471, grad/param norm = 2.2334e-01, time/batch = 0.6265s	
2158/11850 (epoch 9.105), train_loss = 1.56570363, grad/param norm = 1.9856e-01, time/batch = 0.6257s	
2159/11850 (epoch 9.110), train_loss = 1.66880126, grad/param norm = 2.1370e-01, time/batch = 0.6242s	
2160/11850 (epoch 9.114), train_loss = 1.76684945, grad/param norm = 2.4812e-01, time/batch = 0.6245s	
2161/11850 (epoch 9.118), train_loss = 1.61073848, grad/param norm = 2.0739e-01, time/batch = 0.6268s	
2162/11850 (epoch 9.122), train_loss = 1.77242473, grad/param norm = 2.2818e-01, time/batch = 0.6242s	
2163/11850 (epoch 9.127), train_loss = 1.73048094, grad/param norm = 2.3449e-01, time/batch = 0.6237s	
2164/11850 (epoch 9.131), train_loss = 1.77727691, grad/param norm = 2.6161e-01, time/batch = 0.6238s	
2165/11850 (epoch 9.135), train_loss = 1.66413916, grad/param norm = 2.3367e-01, time/batch = 0.6239s	
2166/11850 (epoch 9.139), train_loss = 1.71141322, grad/param norm = 2.2164e-01, time/batch = 0.6232s	
2167/11850 (epoch 9.143), train_loss = 1.63203062, grad/param norm = 2.2071e-01, time/batch = 0.6251s	
2168/11850 (epoch 9.148), train_loss = 1.68951774, grad/param norm = 2.2972e-01, time/batch = 0.6264s	
2169/11850 (epoch 9.152), train_loss = 1.73569558, grad/param norm = 2.3441e-01, time/batch = 0.6265s	
2170/11850 (epoch 9.156), train_loss = 1.79017407, grad/param norm = 2.2866e-01, time/batch = 0.6253s	
2171/11850 (epoch 9.160), train_loss = 2.06249539, grad/param norm = 2.7338e-01, time/batch = 0.6302s	
2172/11850 (epoch 9.165), train_loss = 1.84879387, grad/param norm = 2.3946e-01, time/batch = 0.6353s	
2173/11850 (epoch 9.169), train_loss = 1.66473563, grad/param norm = 2.4776e-01, time/batch = 0.6310s	
2174/11850 (epoch 9.173), train_loss = 1.77244285, grad/param norm = 2.2680e-01, time/batch = 0.6239s	
2175/11850 (epoch 9.177), train_loss = 1.78210230, grad/param norm = 2.8225e-01, time/batch = 0.6273s	
2176/11850 (epoch 9.181), train_loss = 1.75190201, grad/param norm = 2.1546e-01, time/batch = 0.6284s	
2177/11850 (epoch 9.186), train_loss = 1.85051370, grad/param norm = 2.5550e-01, time/batch = 0.6281s	
2178/11850 (epoch 9.190), train_loss = 1.72589732, grad/param norm = 2.3515e-01, time/batch = 0.6278s	
2179/11850 (epoch 9.194), train_loss = 1.86138789, grad/param norm = 2.5667e-01, time/batch = 0.6242s	
2180/11850 (epoch 9.198), train_loss = 1.64727916, grad/param norm = 2.4834e-01, time/batch = 0.6212s	
2181/11850 (epoch 9.203), train_loss = 1.49283651, grad/param norm = 1.8993e-01, time/batch = 0.6358s	
2182/11850 (epoch 9.207), train_loss = 1.74386875, grad/param norm = 2.4271e-01, time/batch = 0.6238s	
2183/11850 (epoch 9.211), train_loss = 1.67161396, grad/param norm = 1.9944e-01, time/batch = 0.6229s	
2184/11850 (epoch 9.215), train_loss = 1.67697965, grad/param norm = 2.1915e-01, time/batch = 0.6253s	
2185/11850 (epoch 9.219), train_loss = 1.61940209, grad/param norm = 2.1418e-01, time/batch = 0.6243s	
2186/11850 (epoch 9.224), train_loss = 1.92572590, grad/param norm = 2.2440e-01, time/batch = 0.6223s	
2187/11850 (epoch 9.228), train_loss = 1.83645413, grad/param norm = 2.1000e-01, time/batch = 0.6258s	
2188/11850 (epoch 9.232), train_loss = 1.74753651, grad/param norm = 2.4829e-01, time/batch = 0.6271s	
2189/11850 (epoch 9.236), train_loss = 1.65605511, grad/param norm = 2.3008e-01, time/batch = 0.6271s	
2190/11850 (epoch 9.241), train_loss = 1.92233005, grad/param norm = 2.2259e-01, time/batch = 0.6225s	
2191/11850 (epoch 9.245), train_loss = 1.77722751, grad/param norm = 2.1565e-01, time/batch = 0.6265s	
2192/11850 (epoch 9.249), train_loss = 1.62597891, grad/param norm = 2.0803e-01, time/batch = 0.6263s	
2193/11850 (epoch 9.253), train_loss = 1.76471109, grad/param norm = 2.6102e-01, time/batch = 0.6256s	
2194/11850 (epoch 9.257), train_loss = 1.79894458, grad/param norm = 2.2009e-01, time/batch = 0.6300s	
2195/11850 (epoch 9.262), train_loss = 1.88949092, grad/param norm = 2.2741e-01, time/batch = 0.6422s	
2196/11850 (epoch 9.266), train_loss = 1.75401941, grad/param norm = 2.1279e-01, time/batch = 0.6584s	
2197/11850 (epoch 9.270), train_loss = 1.64987710, grad/param norm = 2.0833e-01, time/batch = 0.6289s	
2198/11850 (epoch 9.274), train_loss = 1.63737731, grad/param norm = 2.2765e-01, time/batch = 0.6235s	
2199/11850 (epoch 9.278), train_loss = 1.53929086, grad/param norm = 2.2949e-01, time/batch = 0.6217s	
2200/11850 (epoch 9.283), train_loss = 1.61424191, grad/param norm = 2.3006e-01, time/batch = 0.6244s	
2201/11850 (epoch 9.287), train_loss = 1.75914859, grad/param norm = 2.2041e-01, time/batch = 0.6280s	
2202/11850 (epoch 9.291), train_loss = 1.76785627, grad/param norm = 2.3310e-01, time/batch = 0.6243s	
2203/11850 (epoch 9.295), train_loss = 1.67636216, grad/param norm = 2.1023e-01, time/batch = 0.6260s	
2204/11850 (epoch 9.300), train_loss = 1.60468799, grad/param norm = 2.4102e-01, time/batch = 0.6245s	
2205/11850 (epoch 9.304), train_loss = 1.60898807, grad/param norm = 2.1803e-01, time/batch = 0.6247s	
2206/11850 (epoch 9.308), train_loss = 1.56680928, grad/param norm = 2.0230e-01, time/batch = 0.6324s	
2207/11850 (epoch 9.312), train_loss = 1.47842090, grad/param norm = 2.2167e-01, time/batch = 0.6589s	
2208/11850 (epoch 9.316), train_loss = 1.65664893, grad/param norm = 2.1096e-01, time/batch = 0.6407s	
2209/11850 (epoch 9.321), train_loss = 1.61197632, grad/param norm = 1.9562e-01, time/batch = 0.6458s	
2210/11850 (epoch 9.325), train_loss = 1.68019919, grad/param norm = 2.3041e-01, time/batch = 0.6201s	
2211/11850 (epoch 9.329), train_loss = 1.66380578, grad/param norm = 2.2776e-01, time/batch = 0.6360s	
2212/11850 (epoch 9.333), train_loss = 1.68071603, grad/param norm = 2.3017e-01, time/batch = 0.6335s	
2213/11850 (epoch 9.338), train_loss = 1.55714615, grad/param norm = 1.9688e-01, time/batch = 0.6259s	
2214/11850 (epoch 9.342), train_loss = 1.84461372, grad/param norm = 2.6411e-01, time/batch = 0.6253s	
2215/11850 (epoch 9.346), train_loss = 1.71840123, grad/param norm = 2.4117e-01, time/batch = 0.6267s	
2216/11850 (epoch 9.350), train_loss = 1.52334452, grad/param norm = 2.0028e-01, time/batch = 0.6247s	
2217/11850 (epoch 9.354), train_loss = 1.78200491, grad/param norm = 2.3821e-01, time/batch = 0.6300s	
2218/11850 (epoch 9.359), train_loss = 1.75421120, grad/param norm = 2.8084e-01, time/batch = 0.6250s	
2219/11850 (epoch 9.363), train_loss = 1.65437696, grad/param norm = 2.0035e-01, time/batch = 0.6279s	
2220/11850 (epoch 9.367), train_loss = 1.67350463, grad/param norm = 2.0437e-01, time/batch = 0.6263s	
2221/11850 (epoch 9.371), train_loss = 1.65866363, grad/param norm = 1.9656e-01, time/batch = 0.6249s	
2222/11850 (epoch 9.376), train_loss = 1.60725184, grad/param norm = 2.0146e-01, time/batch = 0.6235s	
2223/11850 (epoch 9.380), train_loss = 1.58905708, grad/param norm = 2.1339e-01, time/batch = 0.6236s	
2224/11850 (epoch 9.384), train_loss = 1.59665188, grad/param norm = 2.2619e-01, time/batch = 0.6280s	
2225/11850 (epoch 9.388), train_loss = 1.78394164, grad/param norm = 2.5834e-01, time/batch = 0.6207s	
2226/11850 (epoch 9.392), train_loss = 1.79200355, grad/param norm = 2.2434e-01, time/batch = 0.6249s	
2227/11850 (epoch 9.397), train_loss = 1.80008159, grad/param norm = 2.8015e-01, time/batch = 0.6217s	
2228/11850 (epoch 9.401), train_loss = 1.48876062, grad/param norm = 2.1999e-01, time/batch = 0.6194s	
2229/11850 (epoch 9.405), train_loss = 1.58716409, grad/param norm = 2.0983e-01, time/batch = 0.6203s	
2230/11850 (epoch 9.409), train_loss = 1.76782487, grad/param norm = 2.1926e-01, time/batch = 0.6216s	
2231/11850 (epoch 9.414), train_loss = 1.52545287, grad/param norm = 2.1283e-01, time/batch = 0.6207s	
2232/11850 (epoch 9.418), train_loss = 1.53467899, grad/param norm = 2.3998e-01, time/batch = 0.6239s	
2233/11850 (epoch 9.422), train_loss = 1.50501323, grad/param norm = 2.1888e-01, time/batch = 0.6401s	
2234/11850 (epoch 9.426), train_loss = 1.58743622, grad/param norm = 2.1067e-01, time/batch = 0.6523s	
2235/11850 (epoch 9.430), train_loss = 1.58492571, grad/param norm = 2.1865e-01, time/batch = 0.6482s	
2236/11850 (epoch 9.435), train_loss = 1.59777920, grad/param norm = 2.0269e-01, time/batch = 0.6454s	
2237/11850 (epoch 9.439), train_loss = 1.74687970, grad/param norm = 2.1888e-01, time/batch = 0.6296s	
2238/11850 (epoch 9.443), train_loss = 1.77533657, grad/param norm = 2.4418e-01, time/batch = 0.6338s	
2239/11850 (epoch 9.447), train_loss = 1.58300519, grad/param norm = 2.2384e-01, time/batch = 0.6271s	
2240/11850 (epoch 9.451), train_loss = 1.52886916, grad/param norm = 2.2448e-01, time/batch = 0.6297s	
2241/11850 (epoch 9.456), train_loss = 1.64137062, grad/param norm = 2.2479e-01, time/batch = 0.6329s	
2242/11850 (epoch 9.460), train_loss = 1.69111494, grad/param norm = 2.2843e-01, time/batch = 0.6284s	
2243/11850 (epoch 9.464), train_loss = 1.62814495, grad/param norm = 2.3881e-01, time/batch = 0.6260s	
2244/11850 (epoch 9.468), train_loss = 1.68682390, grad/param norm = 2.0802e-01, time/batch = 0.6246s	
2245/11850 (epoch 9.473), train_loss = 1.73600444, grad/param norm = 2.3738e-01, time/batch = 0.6263s	
2246/11850 (epoch 9.477), train_loss = 1.47975989, grad/param norm = 2.1009e-01, time/batch = 0.6259s	
2247/11850 (epoch 9.481), train_loss = 1.56452666, grad/param norm = 2.4745e-01, time/batch = 0.6244s	
2248/11850 (epoch 9.485), train_loss = 1.48756871, grad/param norm = 1.8379e-01, time/batch = 0.6250s	
2249/11850 (epoch 9.489), train_loss = 1.69751957, grad/param norm = 2.2395e-01, time/batch = 0.6274s	
2250/11850 (epoch 9.494), train_loss = 1.62802652, grad/param norm = 2.1912e-01, time/batch = 0.6284s	
2251/11850 (epoch 9.498), train_loss = 1.60376989, grad/param norm = 2.2931e-01, time/batch = 0.6297s	
2252/11850 (epoch 9.502), train_loss = 1.45401337, grad/param norm = 2.2928e-01, time/batch = 0.6393s	
2253/11850 (epoch 9.506), train_loss = 1.78298721, grad/param norm = 2.5388e-01, time/batch = 0.6260s	
2254/11850 (epoch 9.511), train_loss = 1.59276029, grad/param norm = 2.0069e-01, time/batch = 0.6248s	
2255/11850 (epoch 9.515), train_loss = 1.77192027, grad/param norm = 2.4960e-01, time/batch = 0.6265s	
2256/11850 (epoch 9.519), train_loss = 1.59203032, grad/param norm = 2.2058e-01, time/batch = 0.6237s	
2257/11850 (epoch 9.523), train_loss = 1.61940417, grad/param norm = 2.1001e-01, time/batch = 0.6256s	
2258/11850 (epoch 9.527), train_loss = 1.53726167, grad/param norm = 2.2520e-01, time/batch = 0.6248s	
2259/11850 (epoch 9.532), train_loss = 1.72202646, grad/param norm = 2.1800e-01, time/batch = 0.6243s	
2260/11850 (epoch 9.536), train_loss = 1.57520033, grad/param norm = 2.0952e-01, time/batch = 0.6235s	
2261/11850 (epoch 9.540), train_loss = 1.53539162, grad/param norm = 1.9664e-01, time/batch = 0.6254s	
2262/11850 (epoch 9.544), train_loss = 1.65657661, grad/param norm = 2.4333e-01, time/batch = 0.6250s	
2263/11850 (epoch 9.549), train_loss = 1.38736598, grad/param norm = 2.0130e-01, time/batch = 0.6278s	
2264/11850 (epoch 9.553), train_loss = 1.67009945, grad/param norm = 2.3135e-01, time/batch = 0.6268s	
2265/11850 (epoch 9.557), train_loss = 1.84618566, grad/param norm = 2.4263e-01, time/batch = 0.6248s	
2266/11850 (epoch 9.561), train_loss = 1.64545139, grad/param norm = 2.3425e-01, time/batch = 0.6241s	
2267/11850 (epoch 9.565), train_loss = 1.79487343, grad/param norm = 2.3962e-01, time/batch = 0.6243s	
2268/11850 (epoch 9.570), train_loss = 1.58652144, grad/param norm = 2.2514e-01, time/batch = 0.6528s	
2269/11850 (epoch 9.574), train_loss = 1.67940412, grad/param norm = 2.0036e-01, time/batch = 0.6284s	
2270/11850 (epoch 9.578), train_loss = 1.83564731, grad/param norm = 2.4468e-01, time/batch = 0.6300s	
2271/11850 (epoch 9.582), train_loss = 1.59118733, grad/param norm = 2.1558e-01, time/batch = 0.6472s	
2272/11850 (epoch 9.586), train_loss = 1.60996264, grad/param norm = 2.3088e-01, time/batch = 0.6392s	
2273/11850 (epoch 9.591), train_loss = 1.75960235, grad/param norm = 2.2029e-01, time/batch = 0.6224s	
2274/11850 (epoch 9.595), train_loss = 1.47488389, grad/param norm = 2.0874e-01, time/batch = 0.6265s	
2275/11850 (epoch 9.599), train_loss = 1.54380858, grad/param norm = 2.2364e-01, time/batch = 0.6230s	
2276/11850 (epoch 9.603), train_loss = 1.56160840, grad/param norm = 2.0250e-01, time/batch = 0.6215s	
2277/11850 (epoch 9.608), train_loss = 1.75343974, grad/param norm = 2.1287e-01, time/batch = 0.6250s	
2278/11850 (epoch 9.612), train_loss = 1.85567859, grad/param norm = 2.2163e-01, time/batch = 0.6271s	
2279/11850 (epoch 9.616), train_loss = 1.79081134, grad/param norm = 2.3450e-01, time/batch = 0.6242s	
2280/11850 (epoch 9.620), train_loss = 1.61173987, grad/param norm = 2.1681e-01, time/batch = 0.6295s	
2281/11850 (epoch 9.624), train_loss = 1.74521254, grad/param norm = 2.3066e-01, time/batch = 0.6247s	
2282/11850 (epoch 9.629), train_loss = 1.59892060, grad/param norm = 2.1253e-01, time/batch = 0.6238s	
2283/11850 (epoch 9.633), train_loss = 1.45807339, grad/param norm = 2.1087e-01, time/batch = 0.6259s	
2284/11850 (epoch 9.637), train_loss = 1.50296701, grad/param norm = 2.1915e-01, time/batch = 0.6330s	
2285/11850 (epoch 9.641), train_loss = 1.53662200, grad/param norm = 2.2082e-01, time/batch = 0.6209s	
2286/11850 (epoch 9.646), train_loss = 1.63520113, grad/param norm = 2.4841e-01, time/batch = 0.6257s	
2287/11850 (epoch 9.650), train_loss = 1.65571609, grad/param norm = 2.3359e-01, time/batch = 0.6260s	
2288/11850 (epoch 9.654), train_loss = 1.67846017, grad/param norm = 2.5282e-01, time/batch = 0.6229s	
2289/11850 (epoch 9.658), train_loss = 1.66462189, grad/param norm = 2.1711e-01, time/batch = 0.6461s	
2290/11850 (epoch 9.662), train_loss = 1.62021384, grad/param norm = 2.4975e-01, time/batch = 0.6409s	
2291/11850 (epoch 9.667), train_loss = 1.69547815, grad/param norm = 2.3340e-01, time/batch = 0.6242s	
2292/11850 (epoch 9.671), train_loss = 1.53386633, grad/param norm = 2.0619e-01, time/batch = 0.6215s	
2293/11850 (epoch 9.675), train_loss = 1.61686710, grad/param norm = 2.0867e-01, time/batch = 0.6234s	
2294/11850 (epoch 9.679), train_loss = 1.65879048, grad/param norm = 2.2263e-01, time/batch = 0.6251s	
2295/11850 (epoch 9.684), train_loss = 1.66149333, grad/param norm = 2.3914e-01, time/batch = 0.6244s	
2296/11850 (epoch 9.688), train_loss = 1.53764974, grad/param norm = 2.0234e-01, time/batch = 0.6246s	
2297/11850 (epoch 9.692), train_loss = 1.64824349, grad/param norm = 2.3564e-01, time/batch = 0.6233s	
2298/11850 (epoch 9.696), train_loss = 1.57757376, grad/param norm = 2.4866e-01, time/batch = 0.6280s	
2299/11850 (epoch 9.700), train_loss = 1.63678100, grad/param norm = 2.3346e-01, time/batch = 0.6251s	
2300/11850 (epoch 9.705), train_loss = 1.61701256, grad/param norm = 2.2487e-01, time/batch = 0.6371s	
2301/11850 (epoch 9.709), train_loss = 1.56699606, grad/param norm = 2.2682e-01, time/batch = 0.6439s	
2302/11850 (epoch 9.713), train_loss = 1.59732070, grad/param norm = 2.3926e-01, time/batch = 0.6394s	
2303/11850 (epoch 9.717), train_loss = 1.48519535, grad/param norm = 1.9898e-01, time/batch = 0.6507s	
2304/11850 (epoch 9.722), train_loss = 1.73072936, grad/param norm = 2.4222e-01, time/batch = 0.6336s	
2305/11850 (epoch 9.726), train_loss = 1.47921606, grad/param norm = 2.2948e-01, time/batch = 0.6369s	
2306/11850 (epoch 9.730), train_loss = 1.48025281, grad/param norm = 2.2946e-01, time/batch = 0.6372s	
2307/11850 (epoch 9.734), train_loss = 1.54458078, grad/param norm = 2.2464e-01, time/batch = 0.6357s	
2308/11850 (epoch 9.738), train_loss = 1.74228715, grad/param norm = 2.4565e-01, time/batch = 0.6358s	
2309/11850 (epoch 9.743), train_loss = 1.68602994, grad/param norm = 2.1946e-01, time/batch = 0.6405s	
2310/11850 (epoch 9.747), train_loss = 1.44446170, grad/param norm = 2.1614e-01, time/batch = 0.6444s	
2311/11850 (epoch 9.751), train_loss = 1.48778604, grad/param norm = 2.1099e-01, time/batch = 0.6732s	
2312/11850 (epoch 9.755), train_loss = 1.60748522, grad/param norm = 2.2934e-01, time/batch = 0.6630s	
2313/11850 (epoch 9.759), train_loss = 1.53485018, grad/param norm = 2.1350e-01, time/batch = 0.6502s	
2314/11850 (epoch 9.764), train_loss = 1.56896819, grad/param norm = 2.3257e-01, time/batch = 0.6568s	
2315/11850 (epoch 9.768), train_loss = 1.44564216, grad/param norm = 2.2868e-01, time/batch = 0.6610s	
2316/11850 (epoch 9.772), train_loss = 1.61514741, grad/param norm = 2.2378e-01, time/batch = 0.6429s	
2317/11850 (epoch 9.776), train_loss = 1.63653940, grad/param norm = 2.4055e-01, time/batch = 0.6468s	
2318/11850 (epoch 9.781), train_loss = 1.55394410, grad/param norm = 2.2051e-01, time/batch = 0.6561s	
2319/11850 (epoch 9.785), train_loss = 1.54055025, grad/param norm = 2.1908e-01, time/batch = 0.6583s	
2320/11850 (epoch 9.789), train_loss = 1.67758737, grad/param norm = 2.4390e-01, time/batch = 0.6479s	
2321/11850 (epoch 9.793), train_loss = 1.77186223, grad/param norm = 2.3184e-01, time/batch = 0.6509s	
2322/11850 (epoch 9.797), train_loss = 1.66402905, grad/param norm = 2.2302e-01, time/batch = 0.6612s	
2323/11850 (epoch 9.802), train_loss = 1.56926488, grad/param norm = 2.3972e-01, time/batch = 0.6366s	
2324/11850 (epoch 9.806), train_loss = 1.61663891, grad/param norm = 2.2439e-01, time/batch = 0.6347s	
2325/11850 (epoch 9.810), train_loss = 1.91468348, grad/param norm = 2.8987e-01, time/batch = 0.6387s	
2326/11850 (epoch 9.814), train_loss = 1.57979803, grad/param norm = 1.9840e-01, time/batch = 0.6375s	
2327/11850 (epoch 9.819), train_loss = 1.74844327, grad/param norm = 2.0658e-01, time/batch = 0.6333s	
2328/11850 (epoch 9.823), train_loss = 1.78158000, grad/param norm = 2.3683e-01, time/batch = 0.6522s	
2329/11850 (epoch 9.827), train_loss = 1.62877009, grad/param norm = 2.1996e-01, time/batch = 0.6617s	
2330/11850 (epoch 9.831), train_loss = 1.64275187, grad/param norm = 2.2315e-01, time/batch = 0.6599s	
2331/11850 (epoch 9.835), train_loss = 1.62133196, grad/param norm = 2.2409e-01, time/batch = 0.6380s	
2332/11850 (epoch 9.840), train_loss = 1.53517559, grad/param norm = 2.1074e-01, time/batch = 0.6507s	
2333/11850 (epoch 9.844), train_loss = 1.55059712, grad/param norm = 1.9634e-01, time/batch = 0.6611s	
2334/11850 (epoch 9.848), train_loss = 1.69673393, grad/param norm = 2.3873e-01, time/batch = 0.6386s	
2335/11850 (epoch 9.852), train_loss = 1.59445224, grad/param norm = 2.4692e-01, time/batch = 0.6261s	
2336/11850 (epoch 9.857), train_loss = 1.59603498, grad/param norm = 2.2246e-01, time/batch = 0.6252s	
2337/11850 (epoch 9.861), train_loss = 1.70244819, grad/param norm = 2.3216e-01, time/batch = 0.6245s	
2338/11850 (epoch 9.865), train_loss = 1.72271340, grad/param norm = 2.5053e-01, time/batch = 0.6267s	
2339/11850 (epoch 9.869), train_loss = 1.76779157, grad/param norm = 2.1967e-01, time/batch = 0.6270s	
2340/11850 (epoch 9.873), train_loss = 1.71431869, grad/param norm = 2.2591e-01, time/batch = 0.6306s	
2341/11850 (epoch 9.878), train_loss = 1.65766221, grad/param norm = 2.6251e-01, time/batch = 0.6298s	
2342/11850 (epoch 9.882), train_loss = 1.69445167, grad/param norm = 2.1528e-01, time/batch = 0.6306s	
2343/11850 (epoch 9.886), train_loss = 1.73498210, grad/param norm = 2.4966e-01, time/batch = 0.6458s	
2344/11850 (epoch 9.890), train_loss = 1.68100829, grad/param norm = 2.1528e-01, time/batch = 0.6728s	
2345/11850 (epoch 9.895), train_loss = 1.69214265, grad/param norm = 2.3421e-01, time/batch = 0.6445s	
2346/11850 (epoch 9.899), train_loss = 1.57457081, grad/param norm = 2.2477e-01, time/batch = 0.6504s	
2347/11850 (epoch 9.903), train_loss = 1.57528821, grad/param norm = 2.0112e-01, time/batch = 0.6430s	
2348/11850 (epoch 9.907), train_loss = 1.54891928, grad/param norm = 2.1788e-01, time/batch = 0.6356s	
2349/11850 (epoch 9.911), train_loss = 1.67793492, grad/param norm = 2.2546e-01, time/batch = 0.6407s	
2350/11850 (epoch 9.916), train_loss = 1.80901335, grad/param norm = 2.5689e-01, time/batch = 0.6295s	
2351/11850 (epoch 9.920), train_loss = 1.54616715, grad/param norm = 2.1253e-01, time/batch = 0.6344s	
2352/11850 (epoch 9.924), train_loss = 1.67614359, grad/param norm = 2.3364e-01, time/batch = 0.6268s	
2353/11850 (epoch 9.928), train_loss = 1.80277945, grad/param norm = 2.6670e-01, time/batch = 0.6264s	
2354/11850 (epoch 9.932), train_loss = 1.79767596, grad/param norm = 2.5021e-01, time/batch = 0.6485s	
2355/11850 (epoch 9.937), train_loss = 1.74492071, grad/param norm = 2.1763e-01, time/batch = 0.6538s	
2356/11850 (epoch 9.941), train_loss = 1.71965705, grad/param norm = 2.5634e-01, time/batch = 0.6270s	
2357/11850 (epoch 9.945), train_loss = 1.70514048, grad/param norm = 2.2576e-01, time/batch = 0.6286s	
2358/11850 (epoch 9.949), train_loss = 1.60533292, grad/param norm = 2.3380e-01, time/batch = 0.6269s	
2359/11850 (epoch 9.954), train_loss = 1.74405959, grad/param norm = 2.2922e-01, time/batch = 0.6263s	
2360/11850 (epoch 9.958), train_loss = 1.66657641, grad/param norm = 2.3508e-01, time/batch = 0.6245s	
2361/11850 (epoch 9.962), train_loss = 1.54873151, grad/param norm = 2.2970e-01, time/batch = 0.6243s	
2362/11850 (epoch 9.966), train_loss = 1.52878458, grad/param norm = 2.2238e-01, time/batch = 0.6302s	
2363/11850 (epoch 9.970), train_loss = 1.63565961, grad/param norm = 2.2163e-01, time/batch = 0.6231s	
2364/11850 (epoch 9.975), train_loss = 1.69207715, grad/param norm = 2.3018e-01, time/batch = 0.6283s	
2365/11850 (epoch 9.979), train_loss = 1.72440744, grad/param norm = 2.5020e-01, time/batch = 0.6484s	
2366/11850 (epoch 9.983), train_loss = 1.87691388, grad/param norm = 2.5139e-01, time/batch = 0.6544s	
2367/11850 (epoch 9.987), train_loss = 1.66799383, grad/param norm = 2.2423e-01, time/batch = 0.6248s	
2368/11850 (epoch 9.992), train_loss = 1.79548246, grad/param norm = 2.1272e-01, time/batch = 0.6229s	
2369/11850 (epoch 9.996), train_loss = 1.93694726, grad/param norm = 2.3740e-01, time/batch = 0.6204s	
decayed learning rate by a factor 0.97 to 0.00194	
2370/11850 (epoch 10.000), train_loss = 1.62751024, grad/param norm = 2.4470e-01, time/batch = 0.6231s	
2371/11850 (epoch 10.004), train_loss = 1.74818354, grad/param norm = 2.5598e-01, time/batch = 0.6250s	
2372/11850 (epoch 10.008), train_loss = 1.69941110, grad/param norm = 2.1319e-01, time/batch = 0.6267s	
2373/11850 (epoch 10.013), train_loss = 1.68651410, grad/param norm = 2.2020e-01, time/batch = 0.6256s	
2374/11850 (epoch 10.017), train_loss = 1.86955184, grad/param norm = 2.1348e-01, time/batch = 0.6282s	
2375/11850 (epoch 10.021), train_loss = 1.54295066, grad/param norm = 1.9220e-01, time/batch = 0.6229s	
2376/11850 (epoch 10.025), train_loss = 1.40547898, grad/param norm = 1.7201e-01, time/batch = 0.6284s	
2377/11850 (epoch 10.030), train_loss = 1.50840355, grad/param norm = 2.0711e-01, time/batch = 0.6257s	
2378/11850 (epoch 10.034), train_loss = 1.52143033, grad/param norm = 2.0924e-01, time/batch = 0.6284s	
2379/11850 (epoch 10.038), train_loss = 1.58847571, grad/param norm = 2.0810e-01, time/batch = 0.6242s	
2380/11850 (epoch 10.042), train_loss = 1.67576323, grad/param norm = 2.2698e-01, time/batch = 0.6255s	
2381/11850 (epoch 10.046), train_loss = 1.74622987, grad/param norm = 2.3689e-01, time/batch = 0.6336s	
2382/11850 (epoch 10.051), train_loss = 1.60232221, grad/param norm = 2.1751e-01, time/batch = 0.6335s	
2383/11850 (epoch 10.055), train_loss = 1.61040855, grad/param norm = 2.2126e-01, time/batch = 0.6269s	
2384/11850 (epoch 10.059), train_loss = 1.69026098, grad/param norm = 2.2897e-01, time/batch = 0.6371s	
2385/11850 (epoch 10.063), train_loss = 1.64149713, grad/param norm = 2.1954e-01, time/batch = 0.6253s	
2386/11850 (epoch 10.068), train_loss = 1.61141466, grad/param norm = 1.9924e-01, time/batch = 0.6210s	
2387/11850 (epoch 10.072), train_loss = 1.60154072, grad/param norm = 1.8965e-01, time/batch = 0.6243s	
2388/11850 (epoch 10.076), train_loss = 1.78513818, grad/param norm = 2.1647e-01, time/batch = 0.6221s	
2389/11850 (epoch 10.080), train_loss = 1.60071091, grad/param norm = 2.0613e-01, time/batch = 0.6232s	
2390/11850 (epoch 10.084), train_loss = 1.46669336, grad/param norm = 2.0798e-01, time/batch = 0.6268s	
2391/11850 (epoch 10.089), train_loss = 1.49532736, grad/param norm = 1.9274e-01, time/batch = 0.6247s	
2392/11850 (epoch 10.093), train_loss = 1.44516360, grad/param norm = 1.9504e-01, time/batch = 0.6268s	
2393/11850 (epoch 10.097), train_loss = 1.76524756, grad/param norm = 2.2771e-01, time/batch = 0.6236s	
2394/11850 (epoch 10.101), train_loss = 1.67670948, grad/param norm = 2.2694e-01, time/batch = 0.6236s	
2395/11850 (epoch 10.105), train_loss = 1.51410076, grad/param norm = 2.0025e-01, time/batch = 0.6296s	
2396/11850 (epoch 10.110), train_loss = 1.63386969, grad/param norm = 2.2247e-01, time/batch = 0.6277s	
2397/11850 (epoch 10.114), train_loss = 1.70139163, grad/param norm = 2.3717e-01, time/batch = 0.6499s	
2398/11850 (epoch 10.118), train_loss = 1.55697951, grad/param norm = 2.0481e-01, time/batch = 0.6531s	
2399/11850 (epoch 10.122), train_loss = 1.72066164, grad/param norm = 2.2453e-01, time/batch = 0.6721s	
2400/11850 (epoch 10.127), train_loss = 1.66598082, grad/param norm = 2.2666e-01, time/batch = 0.6435s	
2401/11850 (epoch 10.131), train_loss = 1.70841138, grad/param norm = 2.6291e-01, time/batch = 0.6422s	
2402/11850 (epoch 10.135), train_loss = 1.60626151, grad/param norm = 2.3456e-01, time/batch = 0.6456s	
2403/11850 (epoch 10.139), train_loss = 1.64170648, grad/param norm = 2.2611e-01, time/batch = 0.6436s	
2404/11850 (epoch 10.143), train_loss = 1.57628153, grad/param norm = 2.1754e-01, time/batch = 0.6404s	
2405/11850 (epoch 10.148), train_loss = 1.63003575, grad/param norm = 2.2700e-01, time/batch = 0.6397s	
2406/11850 (epoch 10.152), train_loss = 1.69001937, grad/param norm = 2.3759e-01, time/batch = 0.6384s	
2407/11850 (epoch 10.156), train_loss = 1.73122899, grad/param norm = 2.2200e-01, time/batch = 0.6418s	
2408/11850 (epoch 10.160), train_loss = 1.99272441, grad/param norm = 2.6014e-01, time/batch = 0.6376s	
2409/11850 (epoch 10.165), train_loss = 1.77981518, grad/param norm = 2.2649e-01, time/batch = 0.6580s	
2410/11850 (epoch 10.169), train_loss = 1.61895196, grad/param norm = 2.5828e-01, time/batch = 0.6617s	
2411/11850 (epoch 10.173), train_loss = 1.71860512, grad/param norm = 2.1468e-01, time/batch = 0.6391s	
2412/11850 (epoch 10.177), train_loss = 1.72014713, grad/param norm = 2.8150e-01, time/batch = 0.6431s	
2413/11850 (epoch 10.181), train_loss = 1.70293381, grad/param norm = 2.1697e-01, time/batch = 0.6395s	
2414/11850 (epoch 10.186), train_loss = 1.80255632, grad/param norm = 2.4655e-01, time/batch = 0.6599s	
2415/11850 (epoch 10.190), train_loss = 1.67049590, grad/param norm = 2.1995e-01, time/batch = 0.6688s	
2416/11850 (epoch 10.194), train_loss = 1.81445710, grad/param norm = 2.3566e-01, time/batch = 0.6492s	
2417/11850 (epoch 10.198), train_loss = 1.58193173, grad/param norm = 2.2433e-01, time/batch = 0.6454s	
2418/11850 (epoch 10.203), train_loss = 1.45487236, grad/param norm = 1.8945e-01, time/batch = 0.6504s	
2419/11850 (epoch 10.207), train_loss = 1.69308651, grad/param norm = 2.4138e-01, time/batch = 0.6633s	
2420/11850 (epoch 10.211), train_loss = 1.62289100, grad/param norm = 2.0127e-01, time/batch = 0.6724s	
2421/11850 (epoch 10.215), train_loss = 1.62615869, grad/param norm = 2.2078e-01, time/batch = 0.6706s	
2422/11850 (epoch 10.219), train_loss = 1.57142532, grad/param norm = 2.1293e-01, time/batch = 0.6669s	
2423/11850 (epoch 10.224), train_loss = 1.86807367, grad/param norm = 2.2040e-01, time/batch = 0.6766s	
2424/11850 (epoch 10.228), train_loss = 1.77785912, grad/param norm = 2.1700e-01, time/batch = 0.6668s	
2425/11850 (epoch 10.232), train_loss = 1.70027900, grad/param norm = 2.4792e-01, time/batch = 0.6642s	
2426/11850 (epoch 10.236), train_loss = 1.58752509, grad/param norm = 2.2070e-01, time/batch = 0.6621s	
2427/11850 (epoch 10.241), train_loss = 1.87982906, grad/param norm = 2.3058e-01, time/batch = 0.6608s	
2428/11850 (epoch 10.245), train_loss = 1.72884942, grad/param norm = 2.1727e-01, time/batch = 0.6585s	
2429/11850 (epoch 10.249), train_loss = 1.57856057, grad/param norm = 2.0508e-01, time/batch = 0.6648s	
2430/11850 (epoch 10.253), train_loss = 1.70966480, grad/param norm = 2.5738e-01, time/batch = 0.6668s	
2431/11850 (epoch 10.257), train_loss = 1.74999831, grad/param norm = 2.1515e-01, time/batch = 0.6903s	
2432/11850 (epoch 10.262), train_loss = 1.83861683, grad/param norm = 2.3176e-01, time/batch = 0.6488s	
2433/11850 (epoch 10.266), train_loss = 1.70295479, grad/param norm = 2.1378e-01, time/batch = 0.6450s	
2434/11850 (epoch 10.270), train_loss = 1.59444492, grad/param norm = 2.1767e-01, time/batch = 0.6418s	
2435/11850 (epoch 10.274), train_loss = 1.58268776, grad/param norm = 2.2246e-01, time/batch = 0.6436s	
2436/11850 (epoch 10.278), train_loss = 1.48201372, grad/param norm = 2.2677e-01, time/batch = 0.6452s	
2437/11850 (epoch 10.283), train_loss = 1.56810408, grad/param norm = 2.2504e-01, time/batch = 0.6436s	
2438/11850 (epoch 10.287), train_loss = 1.71149433, grad/param norm = 2.2667e-01, time/batch = 0.6514s	
2439/11850 (epoch 10.291), train_loss = 1.71673630, grad/param norm = 2.3000e-01, time/batch = 0.6485s	
2440/11850 (epoch 10.295), train_loss = 1.63298311, grad/param norm = 2.0826e-01, time/batch = 0.6441s	
2441/11850 (epoch 10.300), train_loss = 1.55283974, grad/param norm = 2.2689e-01, time/batch = 0.6701s	
2442/11850 (epoch 10.304), train_loss = 1.55820248, grad/param norm = 2.1182e-01, time/batch = 0.6656s	
2443/11850 (epoch 10.308), train_loss = 1.52912788, grad/param norm = 2.0252e-01, time/batch = 0.6358s	
2444/11850 (epoch 10.312), train_loss = 1.42395774, grad/param norm = 2.2064e-01, time/batch = 0.6289s	
2445/11850 (epoch 10.316), train_loss = 1.61230624, grad/param norm = 2.0853e-01, time/batch = 0.6296s	
2446/11850 (epoch 10.321), train_loss = 1.55916540, grad/param norm = 1.9295e-01, time/batch = 0.6261s	
2447/11850 (epoch 10.325), train_loss = 1.62076000, grad/param norm = 2.3654e-01, time/batch = 0.6264s	
2448/11850 (epoch 10.329), train_loss = 1.60412774, grad/param norm = 2.2784e-01, time/batch = 0.6242s	
2449/11850 (epoch 10.333), train_loss = 1.62642166, grad/param norm = 2.3143e-01, time/batch = 0.6256s	
2450/11850 (epoch 10.338), train_loss = 1.50744495, grad/param norm = 2.0001e-01, time/batch = 0.6255s	
2451/11850 (epoch 10.342), train_loss = 1.78900913, grad/param norm = 2.7655e-01, time/batch = 0.6284s	
2452/11850 (epoch 10.346), train_loss = 1.65458874, grad/param norm = 2.4176e-01, time/batch = 0.6532s	
2453/11850 (epoch 10.350), train_loss = 1.47011227, grad/param norm = 1.9927e-01, time/batch = 0.6499s	
2454/11850 (epoch 10.354), train_loss = 1.72377489, grad/param norm = 2.4111e-01, time/batch = 0.6270s	
2455/11850 (epoch 10.359), train_loss = 1.70623697, grad/param norm = 2.7682e-01, time/batch = 0.6258s	
2456/11850 (epoch 10.363), train_loss = 1.61432168, grad/param norm = 2.0329e-01, time/batch = 0.6238s	
2457/11850 (epoch 10.367), train_loss = 1.62808432, grad/param norm = 2.0307e-01, time/batch = 0.6293s	
2458/11850 (epoch 10.371), train_loss = 1.62189685, grad/param norm = 2.1094e-01, time/batch = 0.6288s	
2459/11850 (epoch 10.376), train_loss = 1.55459169, grad/param norm = 2.0272e-01, time/batch = 0.6258s	
2460/11850 (epoch 10.380), train_loss = 1.53188653, grad/param norm = 2.0971e-01, time/batch = 0.6247s	
2461/11850 (epoch 10.384), train_loss = 1.53247986, grad/param norm = 2.2531e-01, time/batch = 0.6260s	
2462/11850 (epoch 10.388), train_loss = 1.73602999, grad/param norm = 2.4908e-01, time/batch = 0.6258s	
2463/11850 (epoch 10.392), train_loss = 1.73781790, grad/param norm = 2.1960e-01, time/batch = 0.6253s	
2464/11850 (epoch 10.397), train_loss = 1.74749716, grad/param norm = 2.8327e-01, time/batch = 0.6248s	
2465/11850 (epoch 10.401), train_loss = 1.43664051, grad/param norm = 2.0857e-01, time/batch = 0.6410s	
2466/11850 (epoch 10.405), train_loss = 1.53268097, grad/param norm = 2.0280e-01, time/batch = 0.6485s	
2467/11850 (epoch 10.409), train_loss = 1.71419393, grad/param norm = 2.2490e-01, time/batch = 0.6429s	
2468/11850 (epoch 10.414), train_loss = 1.47670636, grad/param norm = 2.2262e-01, time/batch = 0.6406s	
2469/11850 (epoch 10.418), train_loss = 1.47982626, grad/param norm = 2.2963e-01, time/batch = 0.6450s	
2470/11850 (epoch 10.422), train_loss = 1.44691446, grad/param norm = 2.1499e-01, time/batch = 0.6270s	
2471/11850 (epoch 10.426), train_loss = 1.52042077, grad/param norm = 2.0971e-01, time/batch = 0.6350s	
2472/11850 (epoch 10.430), train_loss = 1.53773495, grad/param norm = 2.1414e-01, time/batch = 0.6268s	
2473/11850 (epoch 10.435), train_loss = 1.53855869, grad/param norm = 1.9424e-01, time/batch = 0.6276s	
2474/11850 (epoch 10.439), train_loss = 1.70045808, grad/param norm = 2.1706e-01, time/batch = 0.6296s	
2475/11850 (epoch 10.443), train_loss = 1.70789047, grad/param norm = 2.2712e-01, time/batch = 0.6262s	
2476/11850 (epoch 10.447), train_loss = 1.51941514, grad/param norm = 2.0932e-01, time/batch = 0.6260s	
2477/11850 (epoch 10.451), train_loss = 1.47472382, grad/param norm = 2.1605e-01, time/batch = 0.6289s	
2478/11850 (epoch 10.456), train_loss = 1.57997687, grad/param norm = 2.2302e-01, time/batch = 0.6261s	
2479/11850 (epoch 10.460), train_loss = 1.63532717, grad/param norm = 2.2102e-01, time/batch = 0.6266s	
2480/11850 (epoch 10.464), train_loss = 1.57129439, grad/param norm = 2.3288e-01, time/batch = 0.6232s	
2481/11850 (epoch 10.468), train_loss = 1.62543807, grad/param norm = 2.0474e-01, time/batch = 0.6268s	
2482/11850 (epoch 10.473), train_loss = 1.67927078, grad/param norm = 2.3394e-01, time/batch = 0.6277s	
2483/11850 (epoch 10.477), train_loss = 1.43286824, grad/param norm = 2.0492e-01, time/batch = 0.6284s	
2484/11850 (epoch 10.481), train_loss = 1.51530038, grad/param norm = 2.4215e-01, time/batch = 0.6256s	
2485/11850 (epoch 10.485), train_loss = 1.44372740, grad/param norm = 1.8476e-01, time/batch = 0.6312s	
2486/11850 (epoch 10.489), train_loss = 1.65000608, grad/param norm = 2.3768e-01, time/batch = 0.6291s	
2487/11850 (epoch 10.494), train_loss = 1.57919908, grad/param norm = 2.2308e-01, time/batch = 0.6254s	
2488/11850 (epoch 10.498), train_loss = 1.54955197, grad/param norm = 2.4975e-01, time/batch = 0.6342s	
2489/11850 (epoch 10.502), train_loss = 1.41221071, grad/param norm = 2.4819e-01, time/batch = 0.6301s	
2490/11850 (epoch 10.506), train_loss = 1.72742667, grad/param norm = 2.3744e-01, time/batch = 0.6332s	
2491/11850 (epoch 10.511), train_loss = 1.54167126, grad/param norm = 1.9482e-01, time/batch = 0.6403s	
2492/11850 (epoch 10.515), train_loss = 1.71034081, grad/param norm = 2.4958e-01, time/batch = 0.6268s	
2493/11850 (epoch 10.519), train_loss = 1.53473270, grad/param norm = 2.1042e-01, time/batch = 0.6296s	
2494/11850 (epoch 10.523), train_loss = 1.56216349, grad/param norm = 2.0103e-01, time/batch = 0.6271s	
2495/11850 (epoch 10.527), train_loss = 1.48123628, grad/param norm = 2.2193e-01, time/batch = 0.6257s	
2496/11850 (epoch 10.532), train_loss = 1.66585133, grad/param norm = 2.1337e-01, time/batch = 0.6285s	
2497/11850 (epoch 10.536), train_loss = 1.52869460, grad/param norm = 2.1255e-01, time/batch = 0.6272s	
2498/11850 (epoch 10.540), train_loss = 1.48087227, grad/param norm = 1.9928e-01, time/batch = 0.6269s	
2499/11850 (epoch 10.544), train_loss = 1.60071229, grad/param norm = 2.4096e-01, time/batch = 0.6331s	
2500/11850 (epoch 10.549), train_loss = 1.34695964, grad/param norm = 2.0424e-01, time/batch = 0.6407s	
2501/11850 (epoch 10.553), train_loss = 1.62008132, grad/param norm = 2.3056e-01, time/batch = 0.6589s	
2502/11850 (epoch 10.557), train_loss = 1.78325903, grad/param norm = 2.4356e-01, time/batch = 0.6589s	
2503/11850 (epoch 10.561), train_loss = 1.59910957, grad/param norm = 2.3614e-01, time/batch = 0.6572s	
2504/11850 (epoch 10.565), train_loss = 1.74603629, grad/param norm = 2.3772e-01, time/batch = 0.6569s	
2505/11850 (epoch 10.570), train_loss = 1.54824834, grad/param norm = 2.3337e-01, time/batch = 0.6568s	
2506/11850 (epoch 10.574), train_loss = 1.63050733, grad/param norm = 2.0012e-01, time/batch = 0.6503s	
2507/11850 (epoch 10.578), train_loss = 1.77669401, grad/param norm = 2.4465e-01, time/batch = 0.6500s	
2508/11850 (epoch 10.582), train_loss = 1.54379388, grad/param norm = 2.1823e-01, time/batch = 0.6468s	
2509/11850 (epoch 10.586), train_loss = 1.55462456, grad/param norm = 2.2398e-01, time/batch = 0.6289s	
2510/11850 (epoch 10.591), train_loss = 1.69704543, grad/param norm = 2.1589e-01, time/batch = 0.6322s	
2511/11850 (epoch 10.595), train_loss = 1.42711891, grad/param norm = 2.1555e-01, time/batch = 0.6382s	
2512/11850 (epoch 10.599), train_loss = 1.49128364, grad/param norm = 2.1702e-01, time/batch = 0.6374s	
2513/11850 (epoch 10.603), train_loss = 1.51418740, grad/param norm = 1.9575e-01, time/batch = 0.6301s	
2514/11850 (epoch 10.608), train_loss = 1.70109949, grad/param norm = 2.0882e-01, time/batch = 0.6294s	
2515/11850 (epoch 10.612), train_loss = 1.80865587, grad/param norm = 2.2182e-01, time/batch = 0.6535s	
2516/11850 (epoch 10.616), train_loss = 1.73111515, grad/param norm = 2.2745e-01, time/batch = 0.6621s	
2517/11850 (epoch 10.620), train_loss = 1.56251021, grad/param norm = 2.1409e-01, time/batch = 0.6392s	
2518/11850 (epoch 10.624), train_loss = 1.69116998, grad/param norm = 2.3246e-01, time/batch = 0.6296s	
2519/11850 (epoch 10.629), train_loss = 1.53786502, grad/param norm = 2.0938e-01, time/batch = 0.6272s	
2520/11850 (epoch 10.633), train_loss = 1.41074453, grad/param norm = 2.1544e-01, time/batch = 0.6322s	
2521/11850 (epoch 10.637), train_loss = 1.45366117, grad/param norm = 2.2168e-01, time/batch = 0.6331s	
2522/11850 (epoch 10.641), train_loss = 1.47781349, grad/param norm = 2.1002e-01, time/batch = 0.6282s	
2523/11850 (epoch 10.646), train_loss = 1.57587423, grad/param norm = 2.3875e-01, time/batch = 0.6256s	
2524/11850 (epoch 10.650), train_loss = 1.59563660, grad/param norm = 2.1809e-01, time/batch = 0.6256s	
2525/11850 (epoch 10.654), train_loss = 1.61382223, grad/param norm = 2.5467e-01, time/batch = 0.6239s	
2526/11850 (epoch 10.658), train_loss = 1.61563399, grad/param norm = 2.1734e-01, time/batch = 0.6239s	
2527/11850 (epoch 10.662), train_loss = 1.55832667, grad/param norm = 2.4902e-01, time/batch = 0.6258s	
2528/11850 (epoch 10.667), train_loss = 1.65108632, grad/param norm = 2.4141e-01, time/batch = 0.6250s	
2529/11850 (epoch 10.671), train_loss = 1.48716214, grad/param norm = 2.0361e-01, time/batch = 0.6388s	
2530/11850 (epoch 10.675), train_loss = 1.55679947, grad/param norm = 2.0842e-01, time/batch = 0.6384s	
2531/11850 (epoch 10.679), train_loss = 1.60571484, grad/param norm = 2.2199e-01, time/batch = 0.6282s	
2532/11850 (epoch 10.684), train_loss = 1.60691980, grad/param norm = 2.3291e-01, time/batch = 0.6260s	
2533/11850 (epoch 10.688), train_loss = 1.48151510, grad/param norm = 2.0917e-01, time/batch = 0.6300s	
2534/11850 (epoch 10.692), train_loss = 1.59077040, grad/param norm = 2.3057e-01, time/batch = 0.6256s	
2535/11850 (epoch 10.696), train_loss = 1.51385772, grad/param norm = 2.5136e-01, time/batch = 0.6262s	
2536/11850 (epoch 10.700), train_loss = 1.58357244, grad/param norm = 2.3201e-01, time/batch = 0.6523s	
2537/11850 (epoch 10.705), train_loss = 1.55657450, grad/param norm = 2.2146e-01, time/batch = 0.6262s	
2538/11850 (epoch 10.709), train_loss = 1.49775513, grad/param norm = 2.1748e-01, time/batch = 0.6330s	
2539/11850 (epoch 10.713), train_loss = 1.53238824, grad/param norm = 2.2871e-01, time/batch = 0.6389s	
2540/11850 (epoch 10.717), train_loss = 1.44601941, grad/param norm = 2.1927e-01, time/batch = 0.6287s	
2541/11850 (epoch 10.722), train_loss = 1.67599900, grad/param norm = 2.3569e-01, time/batch = 0.6226s	
2542/11850 (epoch 10.726), train_loss = 1.42960521, grad/param norm = 2.3561e-01, time/batch = 0.6219s	
2543/11850 (epoch 10.730), train_loss = 1.42633836, grad/param norm = 2.2716e-01, time/batch = 0.6260s	
2544/11850 (epoch 10.734), train_loss = 1.49736258, grad/param norm = 2.3797e-01, time/batch = 0.6229s	
2545/11850 (epoch 10.738), train_loss = 1.69973410, grad/param norm = 2.5172e-01, time/batch = 0.6255s	
2546/11850 (epoch 10.743), train_loss = 1.63687764, grad/param norm = 2.1780e-01, time/batch = 0.6255s	
2547/11850 (epoch 10.747), train_loss = 1.38685434, grad/param norm = 1.9989e-01, time/batch = 0.6247s	
2548/11850 (epoch 10.751), train_loss = 1.43704310, grad/param norm = 2.1280e-01, time/batch = 0.6260s	
2549/11850 (epoch 10.755), train_loss = 1.55730756, grad/param norm = 2.2077e-01, time/batch = 0.6282s	
2550/11850 (epoch 10.759), train_loss = 1.49092489, grad/param norm = 2.1217e-01, time/batch = 0.6241s	
2551/11850 (epoch 10.764), train_loss = 1.53522499, grad/param norm = 2.4436e-01, time/batch = 0.6502s	
2552/11850 (epoch 10.768), train_loss = 1.39715470, grad/param norm = 2.2265e-01, time/batch = 0.6503s	
2553/11850 (epoch 10.772), train_loss = 1.56037629, grad/param norm = 2.3009e-01, time/batch = 0.6314s	
2554/11850 (epoch 10.776), train_loss = 1.58662138, grad/param norm = 2.3487e-01, time/batch = 0.6241s	
2555/11850 (epoch 10.781), train_loss = 1.50219961, grad/param norm = 2.1685e-01, time/batch = 0.6204s	
2556/11850 (epoch 10.785), train_loss = 1.48966587, grad/param norm = 2.0572e-01, time/batch = 0.6206s	
2557/11850 (epoch 10.789), train_loss = 1.61601278, grad/param norm = 2.2776e-01, time/batch = 0.6201s	
2558/11850 (epoch 10.793), train_loss = 1.71772162, grad/param norm = 2.3373e-01, time/batch = 0.6207s	
2559/11850 (epoch 10.797), train_loss = 1.61699773, grad/param norm = 2.2261e-01, time/batch = 0.6231s	
2560/11850 (epoch 10.802), train_loss = 1.50601117, grad/param norm = 2.2842e-01, time/batch = 0.6209s	
2561/11850 (epoch 10.806), train_loss = 1.55856780, grad/param norm = 2.1535e-01, time/batch = 0.6254s	
2562/11850 (epoch 10.810), train_loss = 1.85939328, grad/param norm = 2.9046e-01, time/batch = 0.6445s	
2563/11850 (epoch 10.814), train_loss = 1.52744342, grad/param norm = 1.9934e-01, time/batch = 0.6345s	
2564/11850 (epoch 10.819), train_loss = 1.70050513, grad/param norm = 2.1273e-01, time/batch = 0.6268s	
2565/11850 (epoch 10.823), train_loss = 1.72949807, grad/param norm = 2.3578e-01, time/batch = 0.6264s	
2566/11850 (epoch 10.827), train_loss = 1.58544939, grad/param norm = 2.1434e-01, time/batch = 0.6230s	
2567/11850 (epoch 10.831), train_loss = 1.57826122, grad/param norm = 2.2158e-01, time/batch = 0.6349s	
2568/11850 (epoch 10.835), train_loss = 1.57128382, grad/param norm = 2.2379e-01, time/batch = 0.6305s	
2569/11850 (epoch 10.840), train_loss = 1.48391356, grad/param norm = 2.0443e-01, time/batch = 0.6321s	
2570/11850 (epoch 10.844), train_loss = 1.49977777, grad/param norm = 1.9244e-01, time/batch = 0.6314s	
2571/11850 (epoch 10.848), train_loss = 1.64288527, grad/param norm = 2.3517e-01, time/batch = 0.6260s	
2572/11850 (epoch 10.852), train_loss = 1.54045645, grad/param norm = 2.3172e-01, time/batch = 0.6281s	
2573/11850 (epoch 10.857), train_loss = 1.54525264, grad/param norm = 2.0997e-01, time/batch = 0.6427s	
2574/11850 (epoch 10.861), train_loss = 1.64962712, grad/param norm = 2.3221e-01, time/batch = 0.6552s	
2575/11850 (epoch 10.865), train_loss = 1.67363923, grad/param norm = 2.4643e-01, time/batch = 0.6257s	
2576/11850 (epoch 10.869), train_loss = 1.70237690, grad/param norm = 2.1693e-01, time/batch = 0.6249s	
2577/11850 (epoch 10.873), train_loss = 1.65806709, grad/param norm = 2.2834e-01, time/batch = 0.6251s	
2578/11850 (epoch 10.878), train_loss = 1.60867952, grad/param norm = 2.4801e-01, time/batch = 0.6272s	
2579/11850 (epoch 10.882), train_loss = 1.63380064, grad/param norm = 2.1614e-01, time/batch = 0.6244s	
2580/11850 (epoch 10.886), train_loss = 1.68104094, grad/param norm = 2.5065e-01, time/batch = 0.6291s	
2581/11850 (epoch 10.890), train_loss = 1.62976859, grad/param norm = 2.2382e-01, time/batch = 0.6296s	
2582/11850 (epoch 10.895), train_loss = 1.63885332, grad/param norm = 2.3571e-01, time/batch = 0.6274s	
2583/11850 (epoch 10.899), train_loss = 1.51810596, grad/param norm = 2.2990e-01, time/batch = 0.6301s	
2584/11850 (epoch 10.903), train_loss = 1.52617028, grad/param norm = 2.0550e-01, time/batch = 0.6295s	
2585/11850 (epoch 10.907), train_loss = 1.49903697, grad/param norm = 2.2543e-01, time/batch = 0.6298s	
2586/11850 (epoch 10.911), train_loss = 1.63616527, grad/param norm = 2.2518e-01, time/batch = 0.6292s	
2587/11850 (epoch 10.916), train_loss = 1.75571299, grad/param norm = 2.5727e-01, time/batch = 0.6241s	
2588/11850 (epoch 10.920), train_loss = 1.50960054, grad/param norm = 2.0818e-01, time/batch = 0.6291s	
2589/11850 (epoch 10.924), train_loss = 1.62539809, grad/param norm = 2.5145e-01, time/batch = 0.6403s	
2590/11850 (epoch 10.928), train_loss = 1.73703642, grad/param norm = 2.6656e-01, time/batch = 0.6416s	
2591/11850 (epoch 10.932), train_loss = 1.74617360, grad/param norm = 2.4360e-01, time/batch = 0.6292s	
2592/11850 (epoch 10.937), train_loss = 1.67933509, grad/param norm = 2.1703e-01, time/batch = 0.6251s	
2593/11850 (epoch 10.941), train_loss = 1.66144067, grad/param norm = 2.5071e-01, time/batch = 0.6235s	
2594/11850 (epoch 10.945), train_loss = 1.65776734, grad/param norm = 2.1792e-01, time/batch = 0.6215s	
2595/11850 (epoch 10.949), train_loss = 1.54044056, grad/param norm = 2.6385e-01, time/batch = 0.6246s	
2596/11850 (epoch 10.954), train_loss = 1.68156822, grad/param norm = 2.3081e-01, time/batch = 0.6285s	
2597/11850 (epoch 10.958), train_loss = 1.62616772, grad/param norm = 2.3953e-01, time/batch = 0.6261s	
2598/11850 (epoch 10.962), train_loss = 1.48725220, grad/param norm = 2.4266e-01, time/batch = 0.6245s	
2599/11850 (epoch 10.966), train_loss = 1.47778274, grad/param norm = 2.2007e-01, time/batch = 0.6230s	
2600/11850 (epoch 10.970), train_loss = 1.58451988, grad/param norm = 2.1712e-01, time/batch = 0.6453s	
2601/11850 (epoch 10.975), train_loss = 1.62640432, grad/param norm = 2.3238e-01, time/batch = 0.6525s	
2602/11850 (epoch 10.979), train_loss = 1.66046137, grad/param norm = 2.4625e-01, time/batch = 0.6245s	
2603/11850 (epoch 10.983), train_loss = 1.80594574, grad/param norm = 2.5745e-01, time/batch = 0.6289s	
2604/11850 (epoch 10.987), train_loss = 1.61338354, grad/param norm = 2.1783e-01, time/batch = 0.6270s	
2605/11850 (epoch 10.992), train_loss = 1.74276195, grad/param norm = 2.0393e-01, time/batch = 0.6235s	
2606/11850 (epoch 10.996), train_loss = 1.86609931, grad/param norm = 2.4375e-01, time/batch = 0.6248s	
decayed learning rate by a factor 0.97 to 0.0018818	
2607/11850 (epoch 11.000), train_loss = 1.57730473, grad/param norm = 2.6534e-01, time/batch = 0.6272s	
2608/11850 (epoch 11.004), train_loss = 1.69536784, grad/param norm = 2.5396e-01, time/batch = 0.6248s	
2609/11850 (epoch 11.008), train_loss = 1.65408919, grad/param norm = 2.1801e-01, time/batch = 0.6294s	
2610/11850 (epoch 11.013), train_loss = 1.62967262, grad/param norm = 2.1629e-01, time/batch = 0.6497s	
2611/11850 (epoch 11.017), train_loss = 1.81652706, grad/param norm = 2.1855e-01, time/batch = 0.6584s	
2612/11850 (epoch 11.021), train_loss = 1.50197993, grad/param norm = 1.9069e-01, time/batch = 0.6588s	
2613/11850 (epoch 11.025), train_loss = 1.37036014, grad/param norm = 1.7769e-01, time/batch = 0.6308s	
2614/11850 (epoch 11.030), train_loss = 1.45543149, grad/param norm = 2.1369e-01, time/batch = 0.6285s	
2615/11850 (epoch 11.034), train_loss = 1.47689971, grad/param norm = 2.0648e-01, time/batch = 0.6308s	
2616/11850 (epoch 11.038), train_loss = 1.54964078, grad/param norm = 2.0822e-01, time/batch = 0.6290s	
2617/11850 (epoch 11.042), train_loss = 1.61859975, grad/param norm = 2.2519e-01, time/batch = 0.6280s	
2618/11850 (epoch 11.046), train_loss = 1.68682462, grad/param norm = 2.2953e-01, time/batch = 0.6366s	
2619/11850 (epoch 11.051), train_loss = 1.55932907, grad/param norm = 2.1934e-01, time/batch = 0.6399s	
2620/11850 (epoch 11.055), train_loss = 1.55851424, grad/param norm = 2.1687e-01, time/batch = 0.6285s	
2621/11850 (epoch 11.059), train_loss = 1.64287397, grad/param norm = 2.2534e-01, time/batch = 0.6292s	
2622/11850 (epoch 11.063), train_loss = 1.58886437, grad/param norm = 2.1710e-01, time/batch = 0.6487s	
2623/11850 (epoch 11.068), train_loss = 1.56551622, grad/param norm = 1.9456e-01, time/batch = 0.6501s	
2624/11850 (epoch 11.072), train_loss = 1.56073533, grad/param norm = 1.8947e-01, time/batch = 0.6234s	
2625/11850 (epoch 11.076), train_loss = 1.73317390, grad/param norm = 2.1571e-01, time/batch = 0.6240s	
2626/11850 (epoch 11.080), train_loss = 1.53902221, grad/param norm = 2.0156e-01, time/batch = 0.6235s	
2627/11850 (epoch 11.084), train_loss = 1.42086335, grad/param norm = 2.1200e-01, time/batch = 0.6240s	
2628/11850 (epoch 11.089), train_loss = 1.44236629, grad/param norm = 1.8950e-01, time/batch = 0.6321s	
2629/11850 (epoch 11.093), train_loss = 1.39770691, grad/param norm = 2.0558e-01, time/batch = 0.6249s	
2630/11850 (epoch 11.097), train_loss = 1.70154000, grad/param norm = 2.3159e-01, time/batch = 0.6270s	
2631/11850 (epoch 11.101), train_loss = 1.61689565, grad/param norm = 2.3631e-01, time/batch = 0.6273s	
2632/11850 (epoch 11.105), train_loss = 1.46850517, grad/param norm = 2.0753e-01, time/batch = 0.6281s	
2633/11850 (epoch 11.110), train_loss = 1.59335029, grad/param norm = 2.2045e-01, time/batch = 0.6472s	
2634/11850 (epoch 11.114), train_loss = 1.63340909, grad/param norm = 2.2554e-01, time/batch = 0.6515s	
2635/11850 (epoch 11.118), train_loss = 1.51418197, grad/param norm = 2.0566e-01, time/batch = 0.6217s	
2636/11850 (epoch 11.122), train_loss = 1.67489487, grad/param norm = 2.2511e-01, time/batch = 0.6249s	
2637/11850 (epoch 11.127), train_loss = 1.61307217, grad/param norm = 2.2485e-01, time/batch = 0.6252s	
2638/11850 (epoch 11.131), train_loss = 1.64303585, grad/param norm = 2.6108e-01, time/batch = 0.6257s	
2639/11850 (epoch 11.135), train_loss = 1.55248544, grad/param norm = 2.3459e-01, time/batch = 0.6471s	
2640/11850 (epoch 11.139), train_loss = 1.57617579, grad/param norm = 2.2521e-01, time/batch = 0.6265s	
2641/11850 (epoch 11.143), train_loss = 1.52691623, grad/param norm = 2.2055e-01, time/batch = 0.6262s	
2642/11850 (epoch 11.148), train_loss = 1.57688845, grad/param norm = 2.2632e-01, time/batch = 0.6248s	
2643/11850 (epoch 11.152), train_loss = 1.65155598, grad/param norm = 2.3694e-01, time/batch = 0.6265s	
2644/11850 (epoch 11.156), train_loss = 1.67622824, grad/param norm = 2.1425e-01, time/batch = 0.6326s	
2645/11850 (epoch 11.160), train_loss = 1.93706282, grad/param norm = 2.6623e-01, time/batch = 0.6275s	
2646/11850 (epoch 11.165), train_loss = 1.73089416, grad/param norm = 2.4724e-01, time/batch = 0.6269s	
2647/11850 (epoch 11.169), train_loss = 1.57675564, grad/param norm = 2.5783e-01, time/batch = 0.6249s	
2648/11850 (epoch 11.173), train_loss = 1.66150778, grad/param norm = 2.1297e-01, time/batch = 0.6338s	
2649/11850 (epoch 11.177), train_loss = 1.65020075, grad/param norm = 2.5611e-01, time/batch = 0.6499s	
2650/11850 (epoch 11.181), train_loss = 1.65639111, grad/param norm = 2.1708e-01, time/batch = 0.6416s	
2651/11850 (epoch 11.186), train_loss = 1.76481782, grad/param norm = 2.6274e-01, time/batch = 0.6416s	
2652/11850 (epoch 11.190), train_loss = 1.62514582, grad/param norm = 2.2996e-01, time/batch = 0.6425s	
2653/11850 (epoch 11.194), train_loss = 1.76746061, grad/param norm = 2.3300e-01, time/batch = 0.6299s	
2654/11850 (epoch 11.198), train_loss = 1.52529408, grad/param norm = 2.1341e-01, time/batch = 0.6313s	
2655/11850 (epoch 11.203), train_loss = 1.41722747, grad/param norm = 1.8890e-01, time/batch = 0.6266s	
2656/11850 (epoch 11.207), train_loss = 1.65074478, grad/param norm = 2.5017e-01, time/batch = 0.6282s	
2657/11850 (epoch 11.211), train_loss = 1.58191642, grad/param norm = 2.0625e-01, time/batch = 0.6277s	
2658/11850 (epoch 11.215), train_loss = 1.57945209, grad/param norm = 2.1955e-01, time/batch = 0.6294s	
2659/11850 (epoch 11.219), train_loss = 1.52887231, grad/param norm = 2.1266e-01, time/batch = 0.6292s	
2660/11850 (epoch 11.224), train_loss = 1.82263697, grad/param norm = 2.2783e-01, time/batch = 0.6278s	
2661/11850 (epoch 11.228), train_loss = 1.72395503, grad/param norm = 2.2308e-01, time/batch = 0.6233s	
2662/11850 (epoch 11.232), train_loss = 1.65161589, grad/param norm = 2.3514e-01, time/batch = 0.6260s	
2663/11850 (epoch 11.236), train_loss = 1.52110178, grad/param norm = 2.1674e-01, time/batch = 0.6240s	
2664/11850 (epoch 11.241), train_loss = 1.83366293, grad/param norm = 2.3506e-01, time/batch = 0.6256s	
2665/11850 (epoch 11.245), train_loss = 1.68528745, grad/param norm = 2.1936e-01, time/batch = 0.6298s	
2666/11850 (epoch 11.249), train_loss = 1.52984976, grad/param norm = 2.1027e-01, time/batch = 0.6269s	
2667/11850 (epoch 11.253), train_loss = 1.65645068, grad/param norm = 2.5807e-01, time/batch = 0.6243s	
2668/11850 (epoch 11.257), train_loss = 1.70443721, grad/param norm = 2.1397e-01, time/batch = 0.6227s	
2669/11850 (epoch 11.262), train_loss = 1.78937887, grad/param norm = 2.3463e-01, time/batch = 0.6218s	
2670/11850 (epoch 11.266), train_loss = 1.66479480, grad/param norm = 2.6042e-01, time/batch = 0.6255s	
2671/11850 (epoch 11.270), train_loss = 1.53305336, grad/param norm = 2.0672e-01, time/batch = 0.6297s	
2672/11850 (epoch 11.274), train_loss = 1.54260809, grad/param norm = 2.3021e-01, time/batch = 0.6273s	
2673/11850 (epoch 11.278), train_loss = 1.42412442, grad/param norm = 2.1907e-01, time/batch = 0.6259s	
2674/11850 (epoch 11.283), train_loss = 1.52252051, grad/param norm = 2.1320e-01, time/batch = 0.6230s	
2675/11850 (epoch 11.287), train_loss = 1.66603618, grad/param norm = 2.3143e-01, time/batch = 0.6290s	
2676/11850 (epoch 11.291), train_loss = 1.66447715, grad/param norm = 2.2589e-01, time/batch = 0.6246s	
2677/11850 (epoch 11.295), train_loss = 1.59427075, grad/param norm = 2.1192e-01, time/batch = 0.6227s	
2678/11850 (epoch 11.300), train_loss = 1.51517284, grad/param norm = 2.2579e-01, time/batch = 0.6246s	
2679/11850 (epoch 11.304), train_loss = 1.51911484, grad/param norm = 2.1376e-01, time/batch = 0.6252s	
2680/11850 (epoch 11.308), train_loss = 1.49696465, grad/param norm = 1.9715e-01, time/batch = 0.6212s	
2681/11850 (epoch 11.312), train_loss = 1.37618946, grad/param norm = 2.1546e-01, time/batch = 0.6376s	
2682/11850 (epoch 11.316), train_loss = 1.57210225, grad/param norm = 2.0670e-01, time/batch = 0.6494s	
2683/11850 (epoch 11.321), train_loss = 1.50744248, grad/param norm = 1.9376e-01, time/batch = 0.6540s	
2684/11850 (epoch 11.325), train_loss = 1.56775836, grad/param norm = 2.3240e-01, time/batch = 0.6249s	
2685/11850 (epoch 11.329), train_loss = 1.54716700, grad/param norm = 2.2188e-01, time/batch = 0.6272s	
2686/11850 (epoch 11.333), train_loss = 1.56780262, grad/param norm = 2.4177e-01, time/batch = 0.6252s	
2687/11850 (epoch 11.338), train_loss = 1.46246176, grad/param norm = 2.0217e-01, time/batch = 0.6276s	
2688/11850 (epoch 11.342), train_loss = 1.73897170, grad/param norm = 2.7788e-01, time/batch = 0.6237s	
2689/11850 (epoch 11.346), train_loss = 1.58610139, grad/param norm = 2.3035e-01, time/batch = 0.6242s	
2690/11850 (epoch 11.350), train_loss = 1.42585159, grad/param norm = 2.0292e-01, time/batch = 0.6340s	
2691/11850 (epoch 11.354), train_loss = 1.67714878, grad/param norm = 2.5682e-01, time/batch = 0.6294s	
2692/11850 (epoch 11.359), train_loss = 1.66566902, grad/param norm = 2.6950e-01, time/batch = 0.6243s	
2693/11850 (epoch 11.363), train_loss = 1.57660513, grad/param norm = 2.0358e-01, time/batch = 0.6244s	
2694/11850 (epoch 11.367), train_loss = 1.57954054, grad/param norm = 2.0009e-01, time/batch = 0.6238s	
2695/11850 (epoch 11.371), train_loss = 1.59354631, grad/param norm = 2.1509e-01, time/batch = 0.6253s	
2696/11850 (epoch 11.376), train_loss = 1.51535391, grad/param norm = 2.0909e-01, time/batch = 0.6223s	
2697/11850 (epoch 11.380), train_loss = 1.47977039, grad/param norm = 2.1050e-01, time/batch = 0.6220s	
2698/11850 (epoch 11.384), train_loss = 1.47495087, grad/param norm = 2.2975e-01, time/batch = 0.6225s	
2699/11850 (epoch 11.388), train_loss = 1.69002547, grad/param norm = 2.4332e-01, time/batch = 0.6200s	
2700/11850 (epoch 11.392), train_loss = 1.68510641, grad/param norm = 2.1506e-01, time/batch = 0.6211s	
2701/11850 (epoch 11.397), train_loss = 1.68971685, grad/param norm = 2.6020e-01, time/batch = 0.6228s	
2702/11850 (epoch 11.401), train_loss = 1.39292804, grad/param norm = 1.9830e-01, time/batch = 0.6202s	
2703/11850 (epoch 11.405), train_loss = 1.48484241, grad/param norm = 2.0857e-01, time/batch = 0.6213s	
2704/11850 (epoch 11.409), train_loss = 1.67316286, grad/param norm = 2.3221e-01, time/batch = 0.6399s	
2705/11850 (epoch 11.414), train_loss = 1.43131987, grad/param norm = 2.1761e-01, time/batch = 0.6576s	
2706/11850 (epoch 11.418), train_loss = 1.43483729, grad/param norm = 2.3602e-01, time/batch = 0.6578s	
2707/11850 (epoch 11.422), train_loss = 1.39282165, grad/param norm = 2.1341e-01, time/batch = 0.6467s	
2708/11850 (epoch 11.426), train_loss = 1.47412922, grad/param norm = 2.2165e-01, time/batch = 0.6320s	
2709/11850 (epoch 11.430), train_loss = 1.48781559, grad/param norm = 2.1633e-01, time/batch = 0.6516s	
2710/11850 (epoch 11.435), train_loss = 1.48790920, grad/param norm = 1.9147e-01, time/batch = 0.6416s	
2711/11850 (epoch 11.439), train_loss = 1.65794899, grad/param norm = 2.1800e-01, time/batch = 0.6438s	
2712/11850 (epoch 11.443), train_loss = 1.65147138, grad/param norm = 2.2922e-01, time/batch = 0.6237s	
2713/11850 (epoch 11.447), train_loss = 1.46915675, grad/param norm = 2.0622e-01, time/batch = 0.6203s	
2714/11850 (epoch 11.451), train_loss = 1.42222707, grad/param norm = 2.1463e-01, time/batch = 0.6230s	
2715/11850 (epoch 11.456), train_loss = 1.52993001, grad/param norm = 2.2274e-01, time/batch = 0.6408s	
2716/11850 (epoch 11.460), train_loss = 1.58209667, grad/param norm = 2.1552e-01, time/batch = 0.6572s	
2717/11850 (epoch 11.464), train_loss = 1.51763512, grad/param norm = 2.2584e-01, time/batch = 0.6245s	
2718/11850 (epoch 11.468), train_loss = 1.57918112, grad/param norm = 2.0824e-01, time/batch = 0.6228s	
2719/11850 (epoch 11.473), train_loss = 1.63290025, grad/param norm = 2.4071e-01, time/batch = 0.6253s	
2720/11850 (epoch 11.477), train_loss = 1.39371186, grad/param norm = 2.0145e-01, time/batch = 0.6245s	
2721/11850 (epoch 11.481), train_loss = 1.46546173, grad/param norm = 2.3786e-01, time/batch = 0.6314s	
2722/11850 (epoch 11.485), train_loss = 1.40246933, grad/param norm = 1.8582e-01, time/batch = 0.6248s	
2723/11850 (epoch 11.489), train_loss = 1.60624304, grad/param norm = 2.4330e-01, time/batch = 0.6281s	
2724/11850 (epoch 11.494), train_loss = 1.53190439, grad/param norm = 2.2595e-01, time/batch = 0.6274s	
2725/11850 (epoch 11.498), train_loss = 1.48914267, grad/param norm = 2.2480e-01, time/batch = 0.6236s	
2726/11850 (epoch 11.502), train_loss = 1.36423364, grad/param norm = 2.0837e-01, time/batch = 0.6401s	
2727/11850 (epoch 11.506), train_loss = 1.67476038, grad/param norm = 2.2591e-01, time/batch = 0.6747s	
2728/11850 (epoch 11.511), train_loss = 1.50072060, grad/param norm = 2.0151e-01, time/batch = 0.6439s	
2729/11850 (epoch 11.515), train_loss = 1.64784345, grad/param norm = 2.2381e-01, time/batch = 0.6458s	
2730/11850 (epoch 11.519), train_loss = 1.48186055, grad/param norm = 2.0850e-01, time/batch = 0.6463s	
2731/11850 (epoch 11.523), train_loss = 1.51083846, grad/param norm = 1.9802e-01, time/batch = 0.6449s	
2732/11850 (epoch 11.527), train_loss = 1.42400373, grad/param norm = 2.1257e-01, time/batch = 0.6450s	
2733/11850 (epoch 11.532), train_loss = 1.61424171, grad/param norm = 2.1437e-01, time/batch = 0.6444s	
2734/11850 (epoch 11.536), train_loss = 1.47787345, grad/param norm = 2.0567e-01, time/batch = 0.6484s	
2735/11850 (epoch 11.540), train_loss = 1.43509518, grad/param norm = 1.9871e-01, time/batch = 0.6449s	
2736/11850 (epoch 11.544), train_loss = 1.54641549, grad/param norm = 2.3276e-01, time/batch = 0.6457s	
2737/11850 (epoch 11.549), train_loss = 1.30998879, grad/param norm = 2.0436e-01, time/batch = 0.6658s	
2738/11850 (epoch 11.553), train_loss = 1.57360687, grad/param norm = 2.2763e-01, time/batch = 0.6670s	
2739/11850 (epoch 11.557), train_loss = 1.72370349, grad/param norm = 2.3826e-01, time/batch = 0.6429s	
2740/11850 (epoch 11.561), train_loss = 1.55510053, grad/param norm = 2.4921e-01, time/batch = 0.6451s	
2741/11850 (epoch 11.565), train_loss = 1.69837640, grad/param norm = 2.3439e-01, time/batch = 0.6552s	
2742/11850 (epoch 11.570), train_loss = 1.50410939, grad/param norm = 2.2192e-01, time/batch = 0.6493s	
2743/11850 (epoch 11.574), train_loss = 1.58827486, grad/param norm = 2.0520e-01, time/batch = 0.6538s	
2744/11850 (epoch 11.578), train_loss = 1.71827569, grad/param norm = 2.4715e-01, time/batch = 0.6551s	
2745/11850 (epoch 11.582), train_loss = 1.49678122, grad/param norm = 2.2017e-01, time/batch = 0.6818s	
2746/11850 (epoch 11.586), train_loss = 1.50524137, grad/param norm = 2.1551e-01, time/batch = 0.6674s	
2747/11850 (epoch 11.591), train_loss = 1.64721303, grad/param norm = 2.1392e-01, time/batch = 0.6722s	
2748/11850 (epoch 11.595), train_loss = 1.38029992, grad/param norm = 2.0925e-01, time/batch = 0.6644s	
2749/11850 (epoch 11.599), train_loss = 1.44760919, grad/param norm = 2.1621e-01, time/batch = 0.6580s	
2750/11850 (epoch 11.603), train_loss = 1.47112766, grad/param norm = 1.9514e-01, time/batch = 0.6540s	
2751/11850 (epoch 11.608), train_loss = 1.65244963, grad/param norm = 2.1973e-01, time/batch = 0.6529s	
2752/11850 (epoch 11.612), train_loss = 1.76675754, grad/param norm = 2.2686e-01, time/batch = 0.6626s	
2753/11850 (epoch 11.616), train_loss = 1.67517731, grad/param norm = 2.2191e-01, time/batch = 0.6583s	
2754/11850 (epoch 11.620), train_loss = 1.51708798, grad/param norm = 2.1956e-01, time/batch = 0.6562s	
2755/11850 (epoch 11.624), train_loss = 1.64809179, grad/param norm = 2.5018e-01, time/batch = 0.6561s	
2756/11850 (epoch 11.629), train_loss = 1.49708845, grad/param norm = 2.3814e-01, time/batch = 0.6563s	
2757/11850 (epoch 11.633), train_loss = 1.37844772, grad/param norm = 2.2917e-01, time/batch = 0.6525s	
2758/11850 (epoch 11.637), train_loss = 1.40230481, grad/param norm = 2.2092e-01, time/batch = 0.6570s	
2759/11850 (epoch 11.641), train_loss = 1.42578462, grad/param norm = 2.0726e-01, time/batch = 0.6470s	
2760/11850 (epoch 11.646), train_loss = 1.52076077, grad/param norm = 2.3204e-01, time/batch = 0.6431s	
2761/11850 (epoch 11.650), train_loss = 1.54485528, grad/param norm = 2.1957e-01, time/batch = 0.6418s	
2762/11850 (epoch 11.654), train_loss = 1.56431951, grad/param norm = 2.6611e-01, time/batch = 0.6432s	
2763/11850 (epoch 11.658), train_loss = 1.56576289, grad/param norm = 2.1798e-01, time/batch = 0.6432s	
2764/11850 (epoch 11.662), train_loss = 1.50515543, grad/param norm = 2.5236e-01, time/batch = 0.6425s	
2765/11850 (epoch 11.667), train_loss = 1.60872018, grad/param norm = 2.3731e-01, time/batch = 0.6492s	
2766/11850 (epoch 11.671), train_loss = 1.45566326, grad/param norm = 2.1797e-01, time/batch = 0.6575s	
2767/11850 (epoch 11.675), train_loss = 1.50467510, grad/param norm = 2.1482e-01, time/batch = 0.6530s	
2768/11850 (epoch 11.679), train_loss = 1.56277973, grad/param norm = 2.2304e-01, time/batch = 0.6517s	
2769/11850 (epoch 11.684), train_loss = 1.55689010, grad/param norm = 2.3382e-01, time/batch = 0.6425s	
2770/11850 (epoch 11.688), train_loss = 1.43794709, grad/param norm = 2.0483e-01, time/batch = 0.6384s	
2771/11850 (epoch 11.692), train_loss = 1.53853055, grad/param norm = 2.3218e-01, time/batch = 0.6456s	
2772/11850 (epoch 11.696), train_loss = 1.46273823, grad/param norm = 2.6101e-01, time/batch = 0.6432s	
2773/11850 (epoch 11.700), train_loss = 1.52931473, grad/param norm = 2.2582e-01, time/batch = 0.6382s	
2774/11850 (epoch 11.705), train_loss = 1.51107013, grad/param norm = 2.2205e-01, time/batch = 0.6465s	
2775/11850 (epoch 11.709), train_loss = 1.43773998, grad/param norm = 2.1867e-01, time/batch = 0.6387s	
2776/11850 (epoch 11.713), train_loss = 1.48262026, grad/param norm = 2.3238e-01, time/batch = 0.6398s	
2777/11850 (epoch 11.717), train_loss = 1.40317578, grad/param norm = 2.0704e-01, time/batch = 0.6412s	
2778/11850 (epoch 11.722), train_loss = 1.61626321, grad/param norm = 2.3952e-01, time/batch = 0.6393s	
2779/11850 (epoch 11.726), train_loss = 1.38446957, grad/param norm = 2.3114e-01, time/batch = 0.6415s	
2780/11850 (epoch 11.730), train_loss = 1.37368217, grad/param norm = 2.1392e-01, time/batch = 0.6404s	
2781/11850 (epoch 11.734), train_loss = 1.44398680, grad/param norm = 2.2277e-01, time/batch = 0.6464s	
2782/11850 (epoch 11.738), train_loss = 1.65609807, grad/param norm = 2.4903e-01, time/batch = 0.6431s	
2783/11850 (epoch 11.743), train_loss = 1.58773103, grad/param norm = 2.2388e-01, time/batch = 0.6491s	
2784/11850 (epoch 11.747), train_loss = 1.34638981, grad/param norm = 1.9773e-01, time/batch = 0.6505s	
2785/11850 (epoch 11.751), train_loss = 1.39907109, grad/param norm = 2.1893e-01, time/batch = 0.6474s	
2786/11850 (epoch 11.755), train_loss = 1.51258046, grad/param norm = 2.1939e-01, time/batch = 0.6436s	
2787/11850 (epoch 11.759), train_loss = 1.44903821, grad/param norm = 2.1375e-01, time/batch = 0.6437s	
2788/11850 (epoch 11.764), train_loss = 1.49445269, grad/param norm = 2.4445e-01, time/batch = 0.6419s	
2789/11850 (epoch 11.768), train_loss = 1.35650935, grad/param norm = 2.1607e-01, time/batch = 0.6424s	
2790/11850 (epoch 11.772), train_loss = 1.51320889, grad/param norm = 2.2915e-01, time/batch = 0.6445s	
2791/11850 (epoch 11.776), train_loss = 1.53492132, grad/param norm = 2.3137e-01, time/batch = 0.6474s	
2792/11850 (epoch 11.781), train_loss = 1.45922555, grad/param norm = 2.0958e-01, time/batch = 0.6398s	
2793/11850 (epoch 11.785), train_loss = 1.44468255, grad/param norm = 2.0556e-01, time/batch = 0.6397s	
2794/11850 (epoch 11.789), train_loss = 1.56996847, grad/param norm = 2.3331e-01, time/batch = 0.6425s	
2795/11850 (epoch 11.793), train_loss = 1.67103998, grad/param norm = 2.3235e-01, time/batch = 0.6417s	
2796/11850 (epoch 11.797), train_loss = 1.57168616, grad/param norm = 2.3360e-01, time/batch = 0.6411s	
2797/11850 (epoch 11.802), train_loss = 1.44504463, grad/param norm = 2.3170e-01, time/batch = 0.6716s	
2798/11850 (epoch 11.806), train_loss = 1.51073170, grad/param norm = 2.2203e-01, time/batch = 0.6789s	
2799/11850 (epoch 11.810), train_loss = 1.80859965, grad/param norm = 2.9874e-01, time/batch = 1.1498s	
2800/11850 (epoch 11.814), train_loss = 1.48504963, grad/param norm = 2.0377e-01, time/batch = 1.0075s	
2801/11850 (epoch 11.819), train_loss = 1.65531151, grad/param norm = 2.1515e-01, time/batch = 0.6615s	
2802/11850 (epoch 11.823), train_loss = 1.68463471, grad/param norm = 2.3639e-01, time/batch = 0.6649s	
2803/11850 (epoch 11.827), train_loss = 1.54628593, grad/param norm = 2.1700e-01, time/batch = 0.6645s	
2804/11850 (epoch 11.831), train_loss = 1.51916735, grad/param norm = 2.2619e-01, time/batch = 0.6513s	
2805/11850 (epoch 11.835), train_loss = 1.52220937, grad/param norm = 2.2253e-01, time/batch = 0.6478s	
2806/11850 (epoch 11.840), train_loss = 1.44185906, grad/param norm = 2.0352e-01, time/batch = 0.6891s	
2807/11850 (epoch 11.844), train_loss = 1.45931254, grad/param norm = 1.9251e-01, time/batch = 0.6531s	
2808/11850 (epoch 11.848), train_loss = 1.59362961, grad/param norm = 2.3056e-01, time/batch = 0.6633s	
2809/11850 (epoch 11.852), train_loss = 1.49318104, grad/param norm = 2.2988e-01, time/batch = 0.6592s	
2810/11850 (epoch 11.857), train_loss = 1.49821626, grad/param norm = 2.1736e-01, time/batch = 0.6609s	
2811/11850 (epoch 11.861), train_loss = 1.58952226, grad/param norm = 2.2493e-01, time/batch = 0.6476s	
2812/11850 (epoch 11.865), train_loss = 1.62853555, grad/param norm = 2.5434e-01, time/batch = 0.6505s	
2813/11850 (epoch 11.869), train_loss = 1.63636813, grad/param norm = 2.1531e-01, time/batch = 0.6467s	
2814/11850 (epoch 11.873), train_loss = 1.60897038, grad/param norm = 2.2777e-01, time/batch = 0.6471s	
2815/11850 (epoch 11.878), train_loss = 1.55957940, grad/param norm = 2.3178e-01, time/batch = 0.6459s	
2816/11850 (epoch 11.882), train_loss = 1.57430642, grad/param norm = 2.1318e-01, time/batch = 0.6468s	
2817/11850 (epoch 11.886), train_loss = 1.63253090, grad/param norm = 2.4990e-01, time/batch = 0.6619s	
2818/11850 (epoch 11.890), train_loss = 1.58688164, grad/param norm = 2.3049e-01, time/batch = 0.6518s	
2819/11850 (epoch 11.895), train_loss = 1.58965163, grad/param norm = 2.3832e-01, time/batch = 0.6443s	
2820/11850 (epoch 11.899), train_loss = 1.46489799, grad/param norm = 2.5056e-01, time/batch = 0.6420s	
2821/11850 (epoch 11.903), train_loss = 1.48111191, grad/param norm = 2.0328e-01, time/batch = 0.6458s	
2822/11850 (epoch 11.907), train_loss = 1.45938592, grad/param norm = 2.3790e-01, time/batch = 0.6475s	
2823/11850 (epoch 11.911), train_loss = 1.60135803, grad/param norm = 2.2945e-01, time/batch = 0.6450s	
2824/11850 (epoch 11.916), train_loss = 1.70333199, grad/param norm = 2.5494e-01, time/batch = 0.6466s	
2825/11850 (epoch 11.920), train_loss = 1.47828716, grad/param norm = 2.1667e-01, time/batch = 0.6439s	
2826/11850 (epoch 11.924), train_loss = 1.57703737, grad/param norm = 2.4849e-01, time/batch = 0.6440s	
2827/11850 (epoch 11.928), train_loss = 1.67124880, grad/param norm = 2.5872e-01, time/batch = 0.6438s	
2828/11850 (epoch 11.932), train_loss = 1.69398547, grad/param norm = 2.4192e-01, time/batch = 0.6423s	
2829/11850 (epoch 11.937), train_loss = 1.62542439, grad/param norm = 2.1890e-01, time/batch = 0.6422s	
2830/11850 (epoch 11.941), train_loss = 1.60762583, grad/param norm = 2.3887e-01, time/batch = 0.6429s	
2831/11850 (epoch 11.945), train_loss = 1.61729341, grad/param norm = 2.1981e-01, time/batch = 0.6484s	
2832/11850 (epoch 11.949), train_loss = 1.49344127, grad/param norm = 2.5504e-01, time/batch = 0.6485s	
2833/11850 (epoch 11.954), train_loss = 1.62447616, grad/param norm = 2.3097e-01, time/batch = 0.6458s	
2834/11850 (epoch 11.958), train_loss = 1.57661584, grad/param norm = 2.3630e-01, time/batch = 0.6413s	
2835/11850 (epoch 11.962), train_loss = 1.42622966, grad/param norm = 2.2304e-01, time/batch = 0.6459s	
2836/11850 (epoch 11.966), train_loss = 1.43140402, grad/param norm = 2.1840e-01, time/batch = 0.6443s	
2837/11850 (epoch 11.970), train_loss = 1.53741955, grad/param norm = 2.1145e-01, time/batch = 0.6428s	
2838/11850 (epoch 11.975), train_loss = 1.56418789, grad/param norm = 2.2940e-01, time/batch = 0.6463s	
2839/11850 (epoch 11.979), train_loss = 1.59385471, grad/param norm = 2.4831e-01, time/batch = 0.6559s	
2840/11850 (epoch 11.983), train_loss = 1.74420514, grad/param norm = 2.5667e-01, time/batch = 0.6461s	
2841/11850 (epoch 11.987), train_loss = 1.55195421, grad/param norm = 2.1437e-01, time/batch = 0.6459s	
2842/11850 (epoch 11.992), train_loss = 1.69725759, grad/param norm = 2.0427e-01, time/batch = 0.6412s	
2843/11850 (epoch 11.996), train_loss = 1.81049981, grad/param norm = 2.4500e-01, time/batch = 0.6443s	
decayed learning rate by a factor 0.97 to 0.001825346	
2844/11850 (epoch 12.000), train_loss = 1.52729493, grad/param norm = 2.5528e-01, time/batch = 0.6456s	
2845/11850 (epoch 12.004), train_loss = 1.64659214, grad/param norm = 2.5832e-01, time/batch = 0.6411s	
2846/11850 (epoch 12.008), train_loss = 1.61210773, grad/param norm = 2.2093e-01, time/batch = 0.6413s	
2847/11850 (epoch 12.013), train_loss = 1.59489208, grad/param norm = 2.2927e-01, time/batch = 0.6481s	
2848/11850 (epoch 12.017), train_loss = 1.76750000, grad/param norm = 2.2088e-01, time/batch = 0.6446s	
2849/11850 (epoch 12.021), train_loss = 1.46622432, grad/param norm = 1.9159e-01, time/batch = 0.6481s	
2850/11850 (epoch 12.025), train_loss = 1.33799590, grad/param norm = 1.8368e-01, time/batch = 0.6442s	
2851/11850 (epoch 12.030), train_loss = 1.40781969, grad/param norm = 2.1079e-01, time/batch = 0.6469s	
2852/11850 (epoch 12.034), train_loss = 1.43594831, grad/param norm = 2.0564e-01, time/batch = 0.6449s	
2853/11850 (epoch 12.038), train_loss = 1.51417903, grad/param norm = 2.1072e-01, time/batch = 0.6526s	
2854/11850 (epoch 12.042), train_loss = 1.56425377, grad/param norm = 2.0612e-01, time/batch = 0.6665s	
2855/11850 (epoch 12.046), train_loss = 1.64245267, grad/param norm = 2.4422e-01, time/batch = 0.6541s	
2856/11850 (epoch 12.051), train_loss = 1.52459031, grad/param norm = 2.2067e-01, time/batch = 0.6426s	
2857/11850 (epoch 12.055), train_loss = 1.51433151, grad/param norm = 2.1210e-01, time/batch = 0.6482s	
2858/11850 (epoch 12.059), train_loss = 1.60137811, grad/param norm = 2.2557e-01, time/batch = 0.6429s	
2859/11850 (epoch 12.063), train_loss = 1.54733669, grad/param norm = 2.1047e-01, time/batch = 0.6411s	
2860/11850 (epoch 12.068), train_loss = 1.52097573, grad/param norm = 1.8920e-01, time/batch = 0.6475s	
2861/11850 (epoch 12.072), train_loss = 1.51719881, grad/param norm = 1.8785e-01, time/batch = 0.6462s	
2862/11850 (epoch 12.076), train_loss = 1.68170534, grad/param norm = 2.1138e-01, time/batch = 0.6495s	
2863/11850 (epoch 12.080), train_loss = 1.48376409, grad/param norm = 2.0011e-01, time/batch = 0.6464s	
2864/11850 (epoch 12.084), train_loss = 1.37877116, grad/param norm = 2.1736e-01, time/batch = 0.6437s	
2865/11850 (epoch 12.089), train_loss = 1.39502828, grad/param norm = 1.8594e-01, time/batch = 0.6547s	
2866/11850 (epoch 12.093), train_loss = 1.35819674, grad/param norm = 2.0489e-01, time/batch = 0.6461s	
2867/11850 (epoch 12.097), train_loss = 1.62957704, grad/param norm = 2.1417e-01, time/batch = 0.6490s	
2868/11850 (epoch 12.101), train_loss = 1.55813639, grad/param norm = 2.3298e-01, time/batch = 0.6485s	
2869/11850 (epoch 12.105), train_loss = 1.42202924, grad/param norm = 2.0682e-01, time/batch = 0.6464s	
2870/11850 (epoch 12.110), train_loss = 1.55318302, grad/param norm = 2.2143e-01, time/batch = 0.6427s	
2871/11850 (epoch 12.114), train_loss = 1.58432119, grad/param norm = 2.4029e-01, time/batch = 0.6482s	
2872/11850 (epoch 12.118), train_loss = 1.47625071, grad/param norm = 2.0870e-01, time/batch = 0.6559s	
2873/11850 (epoch 12.122), train_loss = 1.63119138, grad/param norm = 2.2721e-01, time/batch = 0.6481s	
2874/11850 (epoch 12.127), train_loss = 1.56778457, grad/param norm = 2.3122e-01, time/batch = 0.6481s	
2875/11850 (epoch 12.131), train_loss = 1.57825211, grad/param norm = 2.4505e-01, time/batch = 0.6482s	
2876/11850 (epoch 12.135), train_loss = 1.50253027, grad/param norm = 2.2802e-01, time/batch = 0.6444s	
2877/11850 (epoch 12.139), train_loss = 1.51847312, grad/param norm = 2.2229e-01, time/batch = 0.6449s	
2878/11850 (epoch 12.143), train_loss = 1.48914947, grad/param norm = 2.2785e-01, time/batch = 0.6439s	
2879/11850 (epoch 12.148), train_loss = 1.52567871, grad/param norm = 2.2718e-01, time/batch = 0.6441s	
2880/11850 (epoch 12.152), train_loss = 1.62155345, grad/param norm = 2.3594e-01, time/batch = 0.6443s	
2881/11850 (epoch 12.156), train_loss = 1.62675368, grad/param norm = 2.1866e-01, time/batch = 0.6460s	
2882/11850 (epoch 12.160), train_loss = 1.88016663, grad/param norm = 2.6491e-01, time/batch = 0.6449s	
2883/11850 (epoch 12.165), train_loss = 1.67859127, grad/param norm = 2.4112e-01, time/batch = 0.6438s	
2884/11850 (epoch 12.169), train_loss = 1.53156076, grad/param norm = 2.4739e-01, time/batch = 0.6396s	
2885/11850 (epoch 12.173), train_loss = 1.61890613, grad/param norm = 2.1860e-01, time/batch = 0.6426s	
2886/11850 (epoch 12.177), train_loss = 1.58069052, grad/param norm = 2.6046e-01, time/batch = 0.6438s	
2887/11850 (epoch 12.181), train_loss = 1.61332374, grad/param norm = 2.2093e-01, time/batch = 0.6529s	
2888/11850 (epoch 12.186), train_loss = 1.72143031, grad/param norm = 2.7788e-01, time/batch = 0.6789s	
2889/11850 (epoch 12.190), train_loss = 1.58900795, grad/param norm = 2.3394e-01, time/batch = 0.6829s	
2890/11850 (epoch 12.194), train_loss = 1.71537085, grad/param norm = 2.2483e-01, time/batch = 0.6692s	
2891/11850 (epoch 12.198), train_loss = 1.46888024, grad/param norm = 2.1076e-01, time/batch = 0.6708s	
2892/11850 (epoch 12.203), train_loss = 1.38689091, grad/param norm = 1.9517e-01, time/batch = 0.6646s	
2893/11850 (epoch 12.207), train_loss = 1.60675039, grad/param norm = 2.4267e-01, time/batch = 0.6680s	
2894/11850 (epoch 12.211), train_loss = 1.53426837, grad/param norm = 2.0506e-01, time/batch = 0.6739s	
2895/11850 (epoch 12.215), train_loss = 1.53372566, grad/param norm = 2.2504e-01, time/batch = 0.6675s	
2896/11850 (epoch 12.219), train_loss = 1.48730153, grad/param norm = 2.1129e-01, time/batch = 0.6651s	
2897/11850 (epoch 12.224), train_loss = 1.77600611, grad/param norm = 2.4136e-01, time/batch = 0.6560s	
2898/11850 (epoch 12.228), train_loss = 1.67394391, grad/param norm = 2.2662e-01, time/batch = 0.6471s	
2899/11850 (epoch 12.232), train_loss = 1.60396568, grad/param norm = 2.2372e-01, time/batch = 0.6469s	
2900/11850 (epoch 12.236), train_loss = 1.47196699, grad/param norm = 2.2170e-01, time/batch = 0.6491s	
2901/11850 (epoch 12.241), train_loss = 1.78067932, grad/param norm = 2.3452e-01, time/batch = 0.6501s	
2902/11850 (epoch 12.245), train_loss = 1.64184874, grad/param norm = 2.1749e-01, time/batch = 0.6473s	
2903/11850 (epoch 12.249), train_loss = 1.48228930, grad/param norm = 2.1636e-01, time/batch = 0.6458s	
2904/11850 (epoch 12.253), train_loss = 1.61042458, grad/param norm = 2.6379e-01, time/batch = 0.6410s	
2905/11850 (epoch 12.257), train_loss = 1.66976534, grad/param norm = 2.1964e-01, time/batch = 0.6453s	
2906/11850 (epoch 12.262), train_loss = 1.75078194, grad/param norm = 2.5031e-01, time/batch = 0.6419s	
2907/11850 (epoch 12.266), train_loss = 1.61067929, grad/param norm = 2.1321e-01, time/batch = 0.6426s	
2908/11850 (epoch 12.270), train_loss = 1.49398610, grad/param norm = 2.1995e-01, time/batch = 0.6463s	
2909/11850 (epoch 12.274), train_loss = 1.50066509, grad/param norm = 2.3097e-01, time/batch = 0.6412s	
2910/11850 (epoch 12.278), train_loss = 1.38830702, grad/param norm = 2.2638e-01, time/batch = 0.6394s	
2911/11850 (epoch 12.283), train_loss = 1.47774098, grad/param norm = 2.0118e-01, time/batch = 0.6412s	
2912/11850 (epoch 12.287), train_loss = 1.62799421, grad/param norm = 2.3503e-01, time/batch = 0.6381s	
2913/11850 (epoch 12.291), train_loss = 1.61496100, grad/param norm = 2.5799e-01, time/batch = 0.6388s	
2914/11850 (epoch 12.295), train_loss = 1.55993204, grad/param norm = 2.1249e-01, time/batch = 0.6398s	
2915/11850 (epoch 12.300), train_loss = 1.48288671, grad/param norm = 2.3020e-01, time/batch = 0.6388s	
2916/11850 (epoch 12.304), train_loss = 1.48581684, grad/param norm = 2.1549e-01, time/batch = 0.6410s	
2917/11850 (epoch 12.308), train_loss = 1.46697179, grad/param norm = 1.9931e-01, time/batch = 0.6409s	
2918/11850 (epoch 12.312), train_loss = 1.34057518, grad/param norm = 2.1920e-01, time/batch = 0.6377s	
2919/11850 (epoch 12.316), train_loss = 1.53468932, grad/param norm = 2.0586e-01, time/batch = 0.6381s	
2920/11850 (epoch 12.321), train_loss = 1.46198890, grad/param norm = 1.9265e-01, time/batch = 0.6384s	
2921/11850 (epoch 12.325), train_loss = 1.52103704, grad/param norm = 2.3265e-01, time/batch = 0.6411s	
2922/11850 (epoch 12.329), train_loss = 1.50106385, grad/param norm = 2.2576e-01, time/batch = 0.6368s	
2923/11850 (epoch 12.333), train_loss = 1.52135042, grad/param norm = 2.4684e-01, time/batch = 0.6507s	
2924/11850 (epoch 12.338), train_loss = 1.42565239, grad/param norm = 2.1212e-01, time/batch = 0.6457s	
2925/11850 (epoch 12.342), train_loss = 1.69737738, grad/param norm = 2.8127e-01, time/batch = 0.6431s	
2926/11850 (epoch 12.346), train_loss = 1.53790027, grad/param norm = 2.3041e-01, time/batch = 0.6412s	
2927/11850 (epoch 12.350), train_loss = 1.38444419, grad/param norm = 2.0835e-01, time/batch = 0.6397s	
2928/11850 (epoch 12.354), train_loss = 1.62612420, grad/param norm = 2.2951e-01, time/batch = 0.6413s	
2929/11850 (epoch 12.359), train_loss = 1.62183139, grad/param norm = 2.8295e-01, time/batch = 0.6459s	
2930/11850 (epoch 12.363), train_loss = 1.54708711, grad/param norm = 2.1549e-01, time/batch = 0.6439s	
2931/11850 (epoch 12.367), train_loss = 1.54369338, grad/param norm = 2.0298e-01, time/batch = 0.6450s	
2932/11850 (epoch 12.371), train_loss = 1.56314743, grad/param norm = 2.2469e-01, time/batch = 0.6448s	
2933/11850 (epoch 12.376), train_loss = 1.48217703, grad/param norm = 2.1536e-01, time/batch = 0.6455s	
2934/11850 (epoch 12.380), train_loss = 1.44001670, grad/param norm = 2.0812e-01, time/batch = 0.6423s	
2935/11850 (epoch 12.384), train_loss = 1.43156292, grad/param norm = 2.3135e-01, time/batch = 0.6457s	
2936/11850 (epoch 12.388), train_loss = 1.64013221, grad/param norm = 2.3488e-01, time/batch = 0.6489s	
2937/11850 (epoch 12.392), train_loss = 1.64057940, grad/param norm = 2.1514e-01, time/batch = 0.6407s	
2938/11850 (epoch 12.397), train_loss = 1.63583289, grad/param norm = 2.5631e-01, time/batch = 0.6419s	
2939/11850 (epoch 12.401), train_loss = 1.34425540, grad/param norm = 1.8369e-01, time/batch = 0.6525s	
2940/11850 (epoch 12.405), train_loss = 1.43723091, grad/param norm = 2.0601e-01, time/batch = 0.6705s	
2941/11850 (epoch 12.409), train_loss = 1.63029805, grad/param norm = 2.2451e-01, time/batch = 0.6725s	
2942/11850 (epoch 12.414), train_loss = 1.38901315, grad/param norm = 2.1403e-01, time/batch = 0.6619s	
2943/11850 (epoch 12.418), train_loss = 1.39105531, grad/param norm = 2.2991e-01, time/batch = 0.6397s	
2944/11850 (epoch 12.422), train_loss = 1.33826201, grad/param norm = 1.9498e-01, time/batch = 0.6396s	
2945/11850 (epoch 12.426), train_loss = 1.42030455, grad/param norm = 2.1889e-01, time/batch = 0.6410s	
2946/11850 (epoch 12.430), train_loss = 1.44195018, grad/param norm = 2.1227e-01, time/batch = 0.6422s	
2947/11850 (epoch 12.435), train_loss = 1.44323946, grad/param norm = 1.8951e-01, time/batch = 0.6426s	
2948/11850 (epoch 12.439), train_loss = 1.61817828, grad/param norm = 2.2136e-01, time/batch = 0.6439s	
2949/11850 (epoch 12.443), train_loss = 1.59797481, grad/param norm = 2.3259e-01, time/batch = 0.6417s	
2950/11850 (epoch 12.447), train_loss = 1.41621405, grad/param norm = 2.0479e-01, time/batch = 0.6521s	
2951/11850 (epoch 12.451), train_loss = 1.37486861, grad/param norm = 2.0617e-01, time/batch = 0.6742s	
2952/11850 (epoch 12.456), train_loss = 1.48104634, grad/param norm = 2.2416e-01, time/batch = 0.6426s	
2953/11850 (epoch 12.460), train_loss = 1.53923858, grad/param norm = 2.1565e-01, time/batch = 0.6388s	
2954/11850 (epoch 12.464), train_loss = 1.47002730, grad/param norm = 2.3043e-01, time/batch = 0.6406s	
2955/11850 (epoch 12.468), train_loss = 1.52758751, grad/param norm = 1.9893e-01, time/batch = 0.6481s	
2956/11850 (epoch 12.473), train_loss = 1.57963982, grad/param norm = 2.4392e-01, time/batch = 0.6442s	
2957/11850 (epoch 12.477), train_loss = 1.36863542, grad/param norm = 2.0973e-01, time/batch = 0.6409s	
2958/11850 (epoch 12.481), train_loss = 1.43235724, grad/param norm = 2.6065e-01, time/batch = 0.6520s	
2959/11850 (epoch 12.485), train_loss = 1.36802303, grad/param norm = 1.8848e-01, time/batch = 0.6396s	
2960/11850 (epoch 12.489), train_loss = 1.56683121, grad/param norm = 2.3905e-01, time/batch = 0.6413s	
2961/11850 (epoch 12.494), train_loss = 1.48777545, grad/param norm = 2.3186e-01, time/batch = 0.6586s	
2962/11850 (epoch 12.498), train_loss = 1.44334942, grad/param norm = 2.2138e-01, time/batch = 0.6688s	
2963/11850 (epoch 12.502), train_loss = 1.32889344, grad/param norm = 2.1271e-01, time/batch = 0.6516s	
2964/11850 (epoch 12.506), train_loss = 1.62934058, grad/param norm = 2.2601e-01, time/batch = 0.6512s	
2965/11850 (epoch 12.511), train_loss = 1.46389772, grad/param norm = 2.0384e-01, time/batch = 0.6416s	
2966/11850 (epoch 12.515), train_loss = 1.59686055, grad/param norm = 2.1355e-01, time/batch = 0.6467s	
2967/11850 (epoch 12.519), train_loss = 1.43998677, grad/param norm = 2.0921e-01, time/batch = 0.6488s	
2968/11850 (epoch 12.523), train_loss = 1.46928120, grad/param norm = 1.9977e-01, time/batch = 0.6393s	
2969/11850 (epoch 12.527), train_loss = 1.37406830, grad/param norm = 2.1226e-01, time/batch = 0.6398s	
2970/11850 (epoch 12.532), train_loss = 1.56842263, grad/param norm = 2.1096e-01, time/batch = 0.6420s	
2971/11850 (epoch 12.536), train_loss = 1.43579113, grad/param norm = 2.0691e-01, time/batch = 0.6387s	
2972/11850 (epoch 12.540), train_loss = 1.38847890, grad/param norm = 2.0084e-01, time/batch = 0.6427s	
2973/11850 (epoch 12.544), train_loss = 1.49658956, grad/param norm = 2.3459e-01, time/batch = 0.6403s	
2974/11850 (epoch 12.549), train_loss = 1.27135920, grad/param norm = 1.9842e-01, time/batch = 0.6411s	
2975/11850 (epoch 12.553), train_loss = 1.52999897, grad/param norm = 2.2053e-01, time/batch = 0.6405s	
2976/11850 (epoch 12.557), train_loss = 1.67124092, grad/param norm = 2.3245e-01, time/batch = 0.6404s	
2977/11850 (epoch 12.561), train_loss = 1.51694124, grad/param norm = 2.3393e-01, time/batch = 0.6378s	
2978/11850 (epoch 12.565), train_loss = 1.66579072, grad/param norm = 2.5441e-01, time/batch = 0.6390s	
2979/11850 (epoch 12.570), train_loss = 1.45967144, grad/param norm = 2.2919e-01, time/batch = 0.6409s	
2980/11850 (epoch 12.574), train_loss = 1.55703300, grad/param norm = 2.1299e-01, time/batch = 0.6695s	
2981/11850 (epoch 12.578), train_loss = 1.66471787, grad/param norm = 2.4999e-01, time/batch = 0.6765s	
2982/11850 (epoch 12.582), train_loss = 1.45121088, grad/param norm = 2.2380e-01, time/batch = 0.6535s	
2983/11850 (epoch 12.586), train_loss = 1.46726674, grad/param norm = 2.2044e-01, time/batch = 0.6481s	
2984/11850 (epoch 12.591), train_loss = 1.59954486, grad/param norm = 2.1615e-01, time/batch = 0.6417s	
2985/11850 (epoch 12.595), train_loss = 1.33859216, grad/param norm = 2.0787e-01, time/batch = 0.6478s	
2986/11850 (epoch 12.599), train_loss = 1.41114952, grad/param norm = 2.1821e-01, time/batch = 0.6619s	
2987/11850 (epoch 12.603), train_loss = 1.42246814, grad/param norm = 1.9197e-01, time/batch = 0.6490s	
2988/11850 (epoch 12.608), train_loss = 1.60555583, grad/param norm = 2.2359e-01, time/batch = 0.6424s	
2989/11850 (epoch 12.612), train_loss = 1.71936756, grad/param norm = 2.2632e-01, time/batch = 0.6612s	
2990/11850 (epoch 12.616), train_loss = 1.62850146, grad/param norm = 2.1794e-01, time/batch = 0.6662s	
2991/11850 (epoch 12.620), train_loss = 1.47165950, grad/param norm = 2.1971e-01, time/batch = 0.6498s	
2992/11850 (epoch 12.624), train_loss = 1.60302412, grad/param norm = 2.5485e-01, time/batch = 0.6643s	
2993/11850 (epoch 12.629), train_loss = 1.44418243, grad/param norm = 2.1780e-01, time/batch = 0.6521s	
2994/11850 (epoch 12.633), train_loss = 1.34292572, grad/param norm = 2.2975e-01, time/batch = 0.6518s	
2995/11850 (epoch 12.637), train_loss = 1.35596032, grad/param norm = 2.1843e-01, time/batch = 0.6595s	
2996/11850 (epoch 12.641), train_loss = 1.37743828, grad/param norm = 2.0824e-01, time/batch = 0.6722s	
2997/11850 (epoch 12.646), train_loss = 1.47849496, grad/param norm = 2.4451e-01, time/batch = 0.6674s	
2998/11850 (epoch 12.650), train_loss = 1.50500034, grad/param norm = 2.2253e-01, time/batch = 0.6642s	
2999/11850 (epoch 12.654), train_loss = 1.50786126, grad/param norm = 2.6368e-01, time/batch = 0.6593s	
evaluating loss over split index 2	
1/13...	
2/13...	
3/13...	
4/13...	
5/13...	
6/13...	
7/13...	
8/13...	
9/13...	
10/13...	
11/13...	
12/13...	
13/13...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_katelyn_salem_epoch12.66_1.8669.t7	
3000/11850 (epoch 12.658), train_loss = 1.52918395, grad/param norm = 2.3874e-01, time/batch = 0.6495s	
3001/11850 (epoch 12.662), train_loss = 1.65131172, grad/param norm = 2.7217e-01, time/batch = 0.6453s	
3002/11850 (epoch 12.667), train_loss = 1.56587698, grad/param norm = 2.1748e-01, time/batch = 0.6422s	
3003/11850 (epoch 12.671), train_loss = 1.41552417, grad/param norm = 2.0633e-01, time/batch = 0.6436s	
3004/11850 (epoch 12.675), train_loss = 1.45876968, grad/param norm = 1.9887e-01, time/batch = 0.6409s	
3005/11850 (epoch 12.679), train_loss = 1.52183005, grad/param norm = 2.2438e-01, time/batch = 0.6433s	
3006/11850 (epoch 12.684), train_loss = 1.51125644, grad/param norm = 2.3190e-01, time/batch = 0.6489s	
3007/11850 (epoch 12.688), train_loss = 1.39680568, grad/param norm = 2.0441e-01, time/batch = 0.6602s	
3008/11850 (epoch 12.692), train_loss = 1.49108687, grad/param norm = 2.2943e-01, time/batch = 0.6584s	
3009/11850 (epoch 12.696), train_loss = 1.41042625, grad/param norm = 2.4878e-01, time/batch = 0.6471s	
3010/11850 (epoch 12.700), train_loss = 1.48590032, grad/param norm = 2.2147e-01, time/batch = 0.6492s	
3011/11850 (epoch 12.705), train_loss = 1.46380260, grad/param norm = 2.3308e-01, time/batch = 0.6410s	
3012/11850 (epoch 12.709), train_loss = 1.38546806, grad/param norm = 2.2269e-01, time/batch = 0.6433s	
3013/11850 (epoch 12.713), train_loss = 1.43956260, grad/param norm = 2.3501e-01, time/batch = 0.6463s	
3014/11850 (epoch 12.717), train_loss = 1.36583731, grad/param norm = 2.1073e-01, time/batch = 0.6411s	
3015/11850 (epoch 12.722), train_loss = 1.56187257, grad/param norm = 2.4406e-01, time/batch = 0.6383s	
3016/11850 (epoch 12.726), train_loss = 1.34974538, grad/param norm = 2.2595e-01, time/batch = 0.6398s	
3017/11850 (epoch 12.730), train_loss = 1.32940834, grad/param norm = 2.1095e-01, time/batch = 0.6376s	
3018/11850 (epoch 12.734), train_loss = 1.40329160, grad/param norm = 2.2593e-01, time/batch = 0.6403s	
3019/11850 (epoch 12.738), train_loss = 1.61244546, grad/param norm = 2.3529e-01, time/batch = 0.6438s	
3020/11850 (epoch 12.743), train_loss = 1.54327396, grad/param norm = 2.2380e-01, time/batch = 0.6463s	
3021/11850 (epoch 12.747), train_loss = 1.30559280, grad/param norm = 1.9096e-01, time/batch = 0.6450s	
3022/11850 (epoch 12.751), train_loss = 1.35811515, grad/param norm = 2.1684e-01, time/batch = 0.6423s	
3023/11850 (epoch 12.755), train_loss = 1.47242454, grad/param norm = 2.1524e-01, time/batch = 0.6400s	
3024/11850 (epoch 12.759), train_loss = 1.40629288, grad/param norm = 2.1398e-01, time/batch = 0.6450s	
3025/11850 (epoch 12.764), train_loss = 1.45024149, grad/param norm = 2.2827e-01, time/batch = 0.6451s	
3026/11850 (epoch 12.768), train_loss = 1.31921012, grad/param norm = 2.1334e-01, time/batch = 0.6403s	
3027/11850 (epoch 12.772), train_loss = 1.46796247, grad/param norm = 2.2656e-01, time/batch = 0.6414s	
3028/11850 (epoch 12.776), train_loss = 1.48803377, grad/param norm = 2.2992e-01, time/batch = 0.6411s	
3029/11850 (epoch 12.781), train_loss = 1.41408260, grad/param norm = 2.0790e-01, time/batch = 0.6407s	
3030/11850 (epoch 12.785), train_loss = 1.40290031, grad/param norm = 2.0446e-01, time/batch = 0.6498s	
3031/11850 (epoch 12.789), train_loss = 1.52551416, grad/param norm = 2.3808e-01, time/batch = 0.6460s	
3032/11850 (epoch 12.793), train_loss = 1.62384968, grad/param norm = 2.3699e-01, time/batch = 0.6420s	
3033/11850 (epoch 12.797), train_loss = 1.52971832, grad/param norm = 2.3091e-01, time/batch = 0.6413s	
3034/11850 (epoch 12.802), train_loss = 1.40311354, grad/param norm = 2.3985e-01, time/batch = 0.6408s	
3035/11850 (epoch 12.806), train_loss = 1.46552800, grad/param norm = 2.0843e-01, time/batch = 0.6521s	
3036/11850 (epoch 12.810), train_loss = 1.74601339, grad/param norm = 2.8993e-01, time/batch = 0.6403s	
3037/11850 (epoch 12.814), train_loss = 1.44447904, grad/param norm = 2.0232e-01, time/batch = 0.6397s	
3038/11850 (epoch 12.819), train_loss = 1.61299490, grad/param norm = 2.1850e-01, time/batch = 0.6410s	
3039/11850 (epoch 12.823), train_loss = 1.63451809, grad/param norm = 2.2866e-01, time/batch = 0.6378s	
3040/11850 (epoch 12.827), train_loss = 1.51123114, grad/param norm = 2.2590e-01, time/batch = 0.6416s	
3041/11850 (epoch 12.831), train_loss = 1.47894138, grad/param norm = 2.3392e-01, time/batch = 0.6421s	
3042/11850 (epoch 12.835), train_loss = 1.47886230, grad/param norm = 2.2304e-01, time/batch = 0.6395s	
3043/11850 (epoch 12.840), train_loss = 1.40393593, grad/param norm = 2.0355e-01, time/batch = 0.6579s	
3044/11850 (epoch 12.844), train_loss = 1.42579413, grad/param norm = 1.9521e-01, time/batch = 0.6445s	
3045/11850 (epoch 12.848), train_loss = 1.54264279, grad/param norm = 2.2671e-01, time/batch = 0.6372s	
3046/11850 (epoch 12.852), train_loss = 1.45339646, grad/param norm = 2.1989e-01, time/batch = 0.6366s	
3047/11850 (epoch 12.857), train_loss = 1.45355283, grad/param norm = 2.0633e-01, time/batch = 0.6467s	
3048/11850 (epoch 12.861), train_loss = 1.54163461, grad/param norm = 2.2917e-01, time/batch = 0.6362s	
3049/11850 (epoch 12.865), train_loss = 1.59415945, grad/param norm = 2.5675e-01, time/batch = 0.6378s	
3050/11850 (epoch 12.869), train_loss = 1.57577808, grad/param norm = 2.0575e-01, time/batch = 0.6385s	
3051/11850 (epoch 12.873), train_loss = 1.56046844, grad/param norm = 2.2740e-01, time/batch = 0.6405s	
3052/11850 (epoch 12.878), train_loss = 1.52157687, grad/param norm = 2.3059e-01, time/batch = 0.6405s	
3053/11850 (epoch 12.882), train_loss = 1.52464420, grad/param norm = 2.3030e-01, time/batch = 0.6403s	
3054/11850 (epoch 12.886), train_loss = 1.59045628, grad/param norm = 2.4823e-01, time/batch = 0.6361s	
3055/11850 (epoch 12.890), train_loss = 1.55117569, grad/param norm = 2.4700e-01, time/batch = 0.6375s	
3056/11850 (epoch 12.895), train_loss = 1.54683059, grad/param norm = 2.5302e-01, time/batch = 0.6447s	
3057/11850 (epoch 12.899), train_loss = 1.41000478, grad/param norm = 2.3059e-01, time/batch = 0.6364s	
3058/11850 (epoch 12.903), train_loss = 1.45007530, grad/param norm = 2.2335e-01, time/batch = 0.6379s	
3059/11850 (epoch 12.907), train_loss = 1.41537283, grad/param norm = 2.3915e-01, time/batch = 0.6391s	
3060/11850 (epoch 12.911), train_loss = 1.56538186, grad/param norm = 2.3817e-01, time/batch = 0.6395s	
3061/11850 (epoch 12.916), train_loss = 1.64520053, grad/param norm = 2.4127e-01, time/batch = 0.6409s	
3062/11850 (epoch 12.920), train_loss = 1.44296576, grad/param norm = 2.2530e-01, time/batch = 0.6395s	
3063/11850 (epoch 12.924), train_loss = 1.52639657, grad/param norm = 2.4870e-01, time/batch = 0.6397s	
3064/11850 (epoch 12.928), train_loss = 1.62062089, grad/param norm = 2.4594e-01, time/batch = 0.6396s	
3065/11850 (epoch 12.932), train_loss = 1.64209385, grad/param norm = 2.3712e-01, time/batch = 0.6382s	
3066/11850 (epoch 12.937), train_loss = 1.57331308, grad/param norm = 2.2888e-01, time/batch = 0.6406s	
3067/11850 (epoch 12.941), train_loss = 1.56533951, grad/param norm = 2.4369e-01, time/batch = 0.6411s	
3068/11850 (epoch 12.945), train_loss = 1.57632241, grad/param norm = 2.2149e-01, time/batch = 0.6411s	
3069/11850 (epoch 12.949), train_loss = 1.45026368, grad/param norm = 2.6740e-01, time/batch = 0.6638s	
3070/11850 (epoch 12.954), train_loss = 1.58358556, grad/param norm = 2.3441e-01, time/batch = 0.6705s	
3071/11850 (epoch 12.958), train_loss = 1.53294958, grad/param norm = 2.2294e-01, time/batch = 0.6573s	
3072/11850 (epoch 12.962), train_loss = 1.39380006, grad/param norm = 2.3702e-01, time/batch = 0.6421s	
3073/11850 (epoch 12.966), train_loss = 1.39151838, grad/param norm = 2.1241e-01, time/batch = 0.6415s	
3074/11850 (epoch 12.970), train_loss = 1.50173919, grad/param norm = 2.1865e-01, time/batch = 0.6434s	
3075/11850 (epoch 12.975), train_loss = 1.51225598, grad/param norm = 2.2610e-01, time/batch = 0.6592s	
3076/11850 (epoch 12.979), train_loss = 1.53236767, grad/param norm = 2.4119e-01, time/batch = 0.6652s	
3077/11850 (epoch 12.983), train_loss = 1.70213267, grad/param norm = 2.7337e-01, time/batch = 0.6583s	
3078/11850 (epoch 12.987), train_loss = 1.50790298, grad/param norm = 2.2201e-01, time/batch = 0.6477s	
3079/11850 (epoch 12.992), train_loss = 1.65355896, grad/param norm = 2.0300e-01, time/batch = 0.6403s	
3080/11850 (epoch 12.996), train_loss = 1.75404224, grad/param norm = 2.4455e-01, time/batch = 0.6384s	
decayed learning rate by a factor 0.97 to 0.00177058562	
3081/11850 (epoch 13.000), train_loss = 1.47856093, grad/param norm = 2.3523e-01, time/batch = 0.6420s	
3082/11850 (epoch 13.004), train_loss = 1.60504294, grad/param norm = 2.7429e-01, time/batch = 0.6416s	
3083/11850 (epoch 13.008), train_loss = 1.57061871, grad/param norm = 2.2458e-01, time/batch = 0.6466s	
3084/11850 (epoch 13.013), train_loss = 1.55653573, grad/param norm = 2.3520e-01, time/batch = 0.6450s	
3085/11850 (epoch 13.017), train_loss = 1.72290472, grad/param norm = 2.2609e-01, time/batch = 0.6518s	
3086/11850 (epoch 13.021), train_loss = 1.43323794, grad/param norm = 1.8798e-01, time/batch = 0.6414s	
3087/11850 (epoch 13.025), train_loss = 1.31359084, grad/param norm = 1.9421e-01, time/batch = 0.6508s	
3088/11850 (epoch 13.030), train_loss = 1.37288685, grad/param norm = 2.1836e-01, time/batch = 0.6478s	
3089/11850 (epoch 13.034), train_loss = 1.40098243, grad/param norm = 2.0919e-01, time/batch = 0.6382s	
3090/11850 (epoch 13.038), train_loss = 1.48065210, grad/param norm = 2.0864e-01, time/batch = 0.6433s	
3091/11850 (epoch 13.042), train_loss = 1.51495750, grad/param norm = 2.1609e-01, time/batch = 0.6432s	
3092/11850 (epoch 13.046), train_loss = 1.58646166, grad/param norm = 2.4196e-01, time/batch = 0.6419s	
3093/11850 (epoch 13.051), train_loss = 1.49313053, grad/param norm = 2.2506e-01, time/batch = 0.6407s	
3094/11850 (epoch 13.055), train_loss = 1.47417748, grad/param norm = 2.1093e-01, time/batch = 0.6420s	
3095/11850 (epoch 13.059), train_loss = 1.56080450, grad/param norm = 2.2945e-01, time/batch = 0.6454s	
3096/11850 (epoch 13.063), train_loss = 1.50602802, grad/param norm = 2.0853e-01, time/batch = 0.6611s	
3097/11850 (epoch 13.068), train_loss = 1.47969685, grad/param norm = 1.9547e-01, time/batch = 0.6460s	
3098/11850 (epoch 13.072), train_loss = 1.48372070, grad/param norm = 1.9400e-01, time/batch = 0.6555s	
3099/11850 (epoch 13.076), train_loss = 1.63499328, grad/param norm = 2.1155e-01, time/batch = 0.6536s	
3100/11850 (epoch 13.080), train_loss = 1.43815457, grad/param norm = 2.0027e-01, time/batch = 0.6474s	
3101/11850 (epoch 13.084), train_loss = 1.34252600, grad/param norm = 2.1609e-01, time/batch = 0.6428s	
3102/11850 (epoch 13.089), train_loss = 1.35307294, grad/param norm = 1.8651e-01, time/batch = 0.6404s	
3103/11850 (epoch 13.093), train_loss = 1.32609251, grad/param norm = 2.3529e-01, time/batch = 0.6411s	
3104/11850 (epoch 13.097), train_loss = 1.58122858, grad/param norm = 2.2930e-01, time/batch = 0.6390s	
3105/11850 (epoch 13.101), train_loss = 1.51086349, grad/param norm = 2.3857e-01, time/batch = 0.6400s	
3106/11850 (epoch 13.105), train_loss = 1.38461977, grad/param norm = 2.0596e-01, time/batch = 0.6405s	
3107/11850 (epoch 13.110), train_loss = 1.51631979, grad/param norm = 2.2441e-01, time/batch = 0.6355s	
3108/11850 (epoch 13.114), train_loss = 1.53955303, grad/param norm = 2.5088e-01, time/batch = 0.6375s	
3109/11850 (epoch 13.118), train_loss = 1.43686610, grad/param norm = 2.0445e-01, time/batch = 0.6379s	
3110/11850 (epoch 13.122), train_loss = 1.59248372, grad/param norm = 2.3029e-01, time/batch = 0.6378s	
3111/11850 (epoch 13.127), train_loss = 1.53306412, grad/param norm = 2.2699e-01, time/batch = 0.6473s	
3112/11850 (epoch 13.131), train_loss = 1.54342784, grad/param norm = 2.6708e-01, time/batch = 0.6493s	
3113/11850 (epoch 13.135), train_loss = 1.46088954, grad/param norm = 2.4109e-01, time/batch = 0.6533s	
3114/11850 (epoch 13.139), train_loss = 1.46237823, grad/param norm = 2.1522e-01, time/batch = 0.6539s	
3115/11850 (epoch 13.143), train_loss = 1.45783426, grad/param norm = 2.4595e-01, time/batch = 0.6518s	
3116/11850 (epoch 13.148), train_loss = 1.48684895, grad/param norm = 2.3273e-01, time/batch = 0.6617s	
3117/11850 (epoch 13.152), train_loss = 1.59478432, grad/param norm = 2.4853e-01, time/batch = 0.6546s	
3118/11850 (epoch 13.156), train_loss = 1.57403287, grad/param norm = 2.2047e-01, time/batch = 0.6488s	
3119/11850 (epoch 13.160), train_loss = 1.82609479, grad/param norm = 3.1191e-01, time/batch = 0.6471s	
3120/11850 (epoch 13.165), train_loss = 1.64787084, grad/param norm = 2.5674e-01, time/batch = 0.6488s	
3121/11850 (epoch 13.169), train_loss = 1.48615466, grad/param norm = 2.3945e-01, time/batch = 0.6506s	
3122/11850 (epoch 13.173), train_loss = 1.57456161, grad/param norm = 2.2609e-01, time/batch = 0.6509s	
3123/11850 (epoch 13.177), train_loss = 1.51705809, grad/param norm = 2.4081e-01, time/batch = 0.6599s	
3124/11850 (epoch 13.181), train_loss = 1.57278661, grad/param norm = 2.2469e-01, time/batch = 0.6485s	
3125/11850 (epoch 13.186), train_loss = 1.66581218, grad/param norm = 2.5418e-01, time/batch = 0.6477s	
3126/11850 (epoch 13.190), train_loss = 1.53668963, grad/param norm = 2.0912e-01, time/batch = 0.6621s	
3127/11850 (epoch 13.194), train_loss = 1.66683463, grad/param norm = 2.2142e-01, time/batch = 0.6673s	
3128/11850 (epoch 13.198), train_loss = 1.41429260, grad/param norm = 2.0645e-01, time/batch = 0.6613s	
3129/11850 (epoch 13.203), train_loss = 1.34987409, grad/param norm = 1.9707e-01, time/batch = 0.6622s	
3130/11850 (epoch 13.207), train_loss = 1.56535685, grad/param norm = 2.4918e-01, time/batch = 0.6478s	
3131/11850 (epoch 13.211), train_loss = 1.49952964, grad/param norm = 2.0962e-01, time/batch = 0.6614s	
3132/11850 (epoch 13.215), train_loss = 1.50310036, grad/param norm = 2.6004e-01, time/batch = 0.6603s	
3133/11850 (epoch 13.219), train_loss = 1.45005834, grad/param norm = 2.1324e-01, time/batch = 0.6586s	
3134/11850 (epoch 13.224), train_loss = 1.72452792, grad/param norm = 2.3830e-01, time/batch = 0.6641s	
3135/11850 (epoch 13.228), train_loss = 1.61824999, grad/param norm = 2.3065e-01, time/batch = 0.6511s	
3136/11850 (epoch 13.232), train_loss = 1.56121150, grad/param norm = 2.1757e-01, time/batch = 0.6421s	
3137/11850 (epoch 13.236), train_loss = 1.42905937, grad/param norm = 2.3330e-01, time/batch = 0.6435s	
3138/11850 (epoch 13.241), train_loss = 1.73575431, grad/param norm = 2.4356e-01, time/batch = 0.6411s	
3139/11850 (epoch 13.245), train_loss = 1.60301689, grad/param norm = 2.1106e-01, time/batch = 0.6416s	
3140/11850 (epoch 13.249), train_loss = 1.43607203, grad/param norm = 2.2014e-01, time/batch = 0.6491s	
3141/11850 (epoch 13.253), train_loss = 1.56157965, grad/param norm = 2.6165e-01, time/batch = 0.6381s	
3142/11850 (epoch 13.257), train_loss = 1.63787988, grad/param norm = 2.2821e-01, time/batch = 0.6398s	
3143/11850 (epoch 13.262), train_loss = 1.71695169, grad/param norm = 2.3554e-01, time/batch = 0.6389s	
3144/11850 (epoch 13.266), train_loss = 1.55981953, grad/param norm = 2.1170e-01, time/batch = 0.6383s	
3145/11850 (epoch 13.270), train_loss = 1.45760436, grad/param norm = 2.1999e-01, time/batch = 0.6390s	
3146/11850 (epoch 13.274), train_loss = 1.46513097, grad/param norm = 2.3806e-01, time/batch = 0.6397s	
3147/11850 (epoch 13.278), train_loss = 1.34967714, grad/param norm = 2.2620e-01, time/batch = 0.6445s	
3148/11850 (epoch 13.283), train_loss = 1.43775288, grad/param norm = 2.0489e-01, time/batch = 0.6396s	
3149/11850 (epoch 13.287), train_loss = 1.59231279, grad/param norm = 2.4282e-01, time/batch = 0.6391s	
3150/11850 (epoch 13.291), train_loss = 1.56290840, grad/param norm = 2.2860e-01, time/batch = 0.6372s	
3151/11850 (epoch 13.295), train_loss = 1.52548868, grad/param norm = 2.1138e-01, time/batch = 0.6399s	
3152/11850 (epoch 13.300), train_loss = 1.45277590, grad/param norm = 2.3398e-01, time/batch = 0.6389s	
3153/11850 (epoch 13.304), train_loss = 1.45163712, grad/param norm = 2.1975e-01, time/batch = 0.6397s	
3154/11850 (epoch 13.308), train_loss = 1.44292076, grad/param norm = 2.0320e-01, time/batch = 0.6417s	
3155/11850 (epoch 13.312), train_loss = 1.29999492, grad/param norm = 2.0985e-01, time/batch = 0.6406s	
3156/11850 (epoch 13.316), train_loss = 1.49958736, grad/param norm = 2.1495e-01, time/batch = 0.6404s	
3157/11850 (epoch 13.321), train_loss = 1.42139977, grad/param norm = 1.9038e-01, time/batch = 0.6389s	
3158/11850 (epoch 13.325), train_loss = 1.47484689, grad/param norm = 2.2613e-01, time/batch = 0.6401s	
3159/11850 (epoch 13.329), train_loss = 1.46464258, grad/param norm = 2.2463e-01, time/batch = 0.6392s	
3160/11850 (epoch 13.333), train_loss = 1.47637308, grad/param norm = 2.2965e-01, time/batch = 0.6386s	
3161/11850 (epoch 13.338), train_loss = 1.38546506, grad/param norm = 2.1370e-01, time/batch = 0.6611s	
3162/11850 (epoch 13.342), train_loss = 1.63577216, grad/param norm = 2.6814e-01, time/batch = 0.6658s	
3163/11850 (epoch 13.346), train_loss = 1.50586454, grad/param norm = 2.3324e-01, time/batch = 0.6684s	
3164/11850 (epoch 13.350), train_loss = 1.34219972, grad/param norm = 2.0228e-01, time/batch = 0.6598s	
3165/11850 (epoch 13.354), train_loss = 1.58752545, grad/param norm = 2.3564e-01, time/batch = 0.6738s	
3166/11850 (epoch 13.359), train_loss = 1.58011370, grad/param norm = 2.5118e-01, time/batch = 0.6632s	
3167/11850 (epoch 13.363), train_loss = 1.50998108, grad/param norm = 2.0783e-01, time/batch = 0.6639s	
3168/11850 (epoch 13.367), train_loss = 1.50474082, grad/param norm = 1.9934e-01, time/batch = 0.6466s	
3169/11850 (epoch 13.371), train_loss = 1.53591007, grad/param norm = 2.2430e-01, time/batch = 0.6374s	
3170/11850 (epoch 13.376), train_loss = 1.44241615, grad/param norm = 2.0458e-01, time/batch = 0.6402s	
3171/11850 (epoch 13.380), train_loss = 1.39256917, grad/param norm = 2.0069e-01, time/batch = 0.6421s	
3172/11850 (epoch 13.384), train_loss = 1.39192367, grad/param norm = 2.4299e-01, time/batch = 0.6406s	
3173/11850 (epoch 13.388), train_loss = 1.59755625, grad/param norm = 2.4230e-01, time/batch = 0.6502s	
3174/11850 (epoch 13.392), train_loss = 1.60086872, grad/param norm = 2.1799e-01, time/batch = 0.6370s	
3175/11850 (epoch 13.397), train_loss = 1.59083163, grad/param norm = 2.5765e-01, time/batch = 0.6380s	
3176/11850 (epoch 13.401), train_loss = 1.31514225, grad/param norm = 1.8957e-01, time/batch = 0.6396s	
3177/11850 (epoch 13.405), train_loss = 1.40608906, grad/param norm = 2.1361e-01, time/batch = 0.6554s	
3178/11850 (epoch 13.409), train_loss = 1.59337489, grad/param norm = 2.3091e-01, time/batch = 0.6431s	
3179/11850 (epoch 13.414), train_loss = 1.35317823, grad/param norm = 2.0999e-01, time/batch = 0.6408s	
3180/11850 (epoch 13.418), train_loss = 1.34706932, grad/param norm = 2.1863e-01, time/batch = 0.6386s	
3181/11850 (epoch 13.422), train_loss = 1.29743463, grad/param norm = 1.9832e-01, time/batch = 0.6413s	
3182/11850 (epoch 13.426), train_loss = 1.37476999, grad/param norm = 2.2533e-01, time/batch = 0.6407s	
3183/11850 (epoch 13.430), train_loss = 1.40053162, grad/param norm = 2.0431e-01, time/batch = 0.6403s	
3184/11850 (epoch 13.435), train_loss = 1.40424041, grad/param norm = 1.9078e-01, time/batch = 0.6528s	
3185/11850 (epoch 13.439), train_loss = 1.57974423, grad/param norm = 2.1925e-01, time/batch = 0.6502s	
3186/11850 (epoch 13.443), train_loss = 1.54761097, grad/param norm = 2.2876e-01, time/batch = 0.6388s	
3187/11850 (epoch 13.447), train_loss = 1.37552266, grad/param norm = 2.1585e-01, time/batch = 0.6383s	
3188/11850 (epoch 13.451), train_loss = 1.34412250, grad/param norm = 2.0870e-01, time/batch = 0.6441s	
3189/11850 (epoch 13.456), train_loss = 1.44186452, grad/param norm = 2.2964e-01, time/batch = 0.6404s	
3190/11850 (epoch 13.460), train_loss = 1.49323393, grad/param norm = 2.1510e-01, time/batch = 0.6409s	
3191/11850 (epoch 13.464), train_loss = 1.40730326, grad/param norm = 2.1289e-01, time/batch = 0.6415s	
3192/11850 (epoch 13.468), train_loss = 1.47890245, grad/param norm = 1.9851e-01, time/batch = 0.6396s	
3193/11850 (epoch 13.473), train_loss = 1.53643690, grad/param norm = 2.4804e-01, time/batch = 0.6420s	
3194/11850 (epoch 13.477), train_loss = 1.34086612, grad/param norm = 2.1164e-01, time/batch = 0.6372s	
3195/11850 (epoch 13.481), train_loss = 1.38924848, grad/param norm = 2.2513e-01, time/batch = 0.6407s	
3196/11850 (epoch 13.485), train_loss = 1.33224308, grad/param norm = 1.9604e-01, time/batch = 0.6385s	
3197/11850 (epoch 13.489), train_loss = 1.52090789, grad/param norm = 2.4259e-01, time/batch = 0.6451s	
3198/11850 (epoch 13.494), train_loss = 1.43541756, grad/param norm = 2.3241e-01, time/batch = 0.6409s	
3199/11850 (epoch 13.498), train_loss = 1.40510727, grad/param norm = 2.3381e-01, time/batch = 0.6422s	
3200/11850 (epoch 13.502), train_loss = 1.29267514, grad/param norm = 2.0814e-01, time/batch = 0.6344s	
3201/11850 (epoch 13.506), train_loss = 1.58801240, grad/param norm = 2.2605e-01, time/batch = 0.6372s	
3202/11850 (epoch 13.511), train_loss = 1.43223726, grad/param norm = 2.0522e-01, time/batch = 0.6268s	
3203/11850 (epoch 13.515), train_loss = 1.55808624, grad/param norm = 2.2078e-01, time/batch = 0.6223s	
3204/11850 (epoch 13.519), train_loss = 1.39985381, grad/param norm = 2.1606e-01, time/batch = 0.6295s	
3205/11850 (epoch 13.523), train_loss = 1.43050717, grad/param norm = 2.1011e-01, time/batch = 0.6275s	
3206/11850 (epoch 13.527), train_loss = 1.33385009, grad/param norm = 2.1931e-01, time/batch = 0.6427s	
3207/11850 (epoch 13.532), train_loss = 1.52672667, grad/param norm = 2.1519e-01, time/batch = 0.6408s	
3208/11850 (epoch 13.536), train_loss = 1.39190034, grad/param norm = 2.0404e-01, time/batch = 0.6263s	
3209/11850 (epoch 13.540), train_loss = 1.35030926, grad/param norm = 2.0295e-01, time/batch = 0.6284s	
3210/11850 (epoch 13.544), train_loss = 1.44180528, grad/param norm = 2.1548e-01, time/batch = 0.6300s	
3211/11850 (epoch 13.549), train_loss = 1.24022921, grad/param norm = 1.9316e-01, time/batch = 0.6332s	
3212/11850 (epoch 13.553), train_loss = 1.49007159, grad/param norm = 2.2056e-01, time/batch = 0.6269s	
3213/11850 (epoch 13.557), train_loss = 1.62756545, grad/param norm = 2.3964e-01, time/batch = 0.6274s	
3214/11850 (epoch 13.561), train_loss = 1.47585672, grad/param norm = 2.3433e-01, time/batch = 0.6234s	
3215/11850 (epoch 13.565), train_loss = 1.62690267, grad/param norm = 2.4659e-01, time/batch = 0.6283s	
3216/11850 (epoch 13.570), train_loss = 1.43187538, grad/param norm = 2.2841e-01, time/batch = 0.6262s	
3217/11850 (epoch 13.574), train_loss = 1.52344160, grad/param norm = 2.2201e-01, time/batch = 0.6239s	
3218/11850 (epoch 13.578), train_loss = 1.61341761, grad/param norm = 2.4112e-01, time/batch = 0.6263s	
3219/11850 (epoch 13.582), train_loss = 1.40391732, grad/param norm = 2.1939e-01, time/batch = 0.6254s	
3220/11850 (epoch 13.586), train_loss = 1.42910692, grad/param norm = 2.2740e-01, time/batch = 0.6275s	
3221/11850 (epoch 13.591), train_loss = 1.56005388, grad/param norm = 2.2338e-01, time/batch = 0.6279s	
3222/11850 (epoch 13.595), train_loss = 1.30345804, grad/param norm = 2.0975e-01, time/batch = 0.6292s	
3223/11850 (epoch 13.599), train_loss = 1.38820175, grad/param norm = 2.2575e-01, time/batch = 0.6264s	
3224/11850 (epoch 13.603), train_loss = 1.38436863, grad/param norm = 1.9472e-01, time/batch = 0.6226s	
3225/11850 (epoch 13.608), train_loss = 1.55709511, grad/param norm = 2.1930e-01, time/batch = 0.6284s	
3226/11850 (epoch 13.612), train_loss = 1.67534448, grad/param norm = 2.3080e-01, time/batch = 0.6291s	
3227/11850 (epoch 13.616), train_loss = 1.58732476, grad/param norm = 2.1989e-01, time/batch = 0.6287s	
3228/11850 (epoch 13.620), train_loss = 1.43383039, grad/param norm = 2.2901e-01, time/batch = 0.6305s	
3229/11850 (epoch 13.624), train_loss = 1.55073913, grad/param norm = 2.5238e-01, time/batch = 0.6266s	
3230/11850 (epoch 13.629), train_loss = 1.39960731, grad/param norm = 2.1689e-01, time/batch = 0.6283s	
3231/11850 (epoch 13.633), train_loss = 1.31981404, grad/param norm = 2.2765e-01, time/batch = 0.6271s	
3232/11850 (epoch 13.637), train_loss = 1.32233437, grad/param norm = 2.2745e-01, time/batch = 0.6246s	
3233/11850 (epoch 13.641), train_loss = 1.33791897, grad/param norm = 2.0648e-01, time/batch = 0.6300s	
3234/11850 (epoch 13.646), train_loss = 1.42938802, grad/param norm = 2.3558e-01, time/batch = 0.6321s	
3235/11850 (epoch 13.650), train_loss = 1.46573033, grad/param norm = 2.3622e-01, time/batch = 0.6242s	
3236/11850 (epoch 13.654), train_loss = 1.45218062, grad/param norm = 2.4894e-01, time/batch = 0.6376s	
3237/11850 (epoch 13.658), train_loss = 1.48810903, grad/param norm = 2.3334e-01, time/batch = 0.6276s	
3238/11850 (epoch 13.662), train_loss = 1.41557096, grad/param norm = 2.6036e-01, time/batch = 0.6243s	
3239/11850 (epoch 13.667), train_loss = 1.53512921, grad/param norm = 2.5130e-01, time/batch = 0.6298s	
3240/11850 (epoch 13.671), train_loss = 1.38604308, grad/param norm = 2.1085e-01, time/batch = 0.6252s	
3241/11850 (epoch 13.675), train_loss = 1.41435807, grad/param norm = 1.9501e-01, time/batch = 0.6301s	
3242/11850 (epoch 13.679), train_loss = 1.48638453, grad/param norm = 2.3218e-01, time/batch = 0.6356s	
3243/11850 (epoch 13.684), train_loss = 1.47436268, grad/param norm = 2.3453e-01, time/batch = 0.6281s	
3244/11850 (epoch 13.688), train_loss = 1.36166745, grad/param norm = 1.9567e-01, time/batch = 0.6262s	
3245/11850 (epoch 13.692), train_loss = 1.45374304, grad/param norm = 2.3539e-01, time/batch = 0.6268s	
3246/11850 (epoch 13.696), train_loss = 1.36538172, grad/param norm = 2.4889e-01, time/batch = 0.6246s	
3247/11850 (epoch 13.700), train_loss = 1.44577885, grad/param norm = 2.1797e-01, time/batch = 0.6264s	
3248/11850 (epoch 13.705), train_loss = 1.41649353, grad/param norm = 2.2064e-01, time/batch = 0.6280s	
3249/11850 (epoch 13.709), train_loss = 1.33250564, grad/param norm = 2.1336e-01, time/batch = 0.6264s	
3250/11850 (epoch 13.713), train_loss = 1.39492651, grad/param norm = 2.2764e-01, time/batch = 0.6320s	
3251/11850 (epoch 13.717), train_loss = 1.34157350, grad/param norm = 2.2639e-01, time/batch = 0.6281s	
3252/11850 (epoch 13.722), train_loss = 1.50403495, grad/param norm = 2.4261e-01, time/batch = 0.6386s	
3253/11850 (epoch 13.726), train_loss = 1.31675478, grad/param norm = 2.3974e-01, time/batch = 0.6331s	
3254/11850 (epoch 13.730), train_loss = 1.29105247, grad/param norm = 2.0883e-01, time/batch = 0.6290s	
3255/11850 (epoch 13.734), train_loss = 1.36219366, grad/param norm = 2.1722e-01, time/batch = 0.6524s	
3256/11850 (epoch 13.738), train_loss = 1.57460723, grad/param norm = 2.3495e-01, time/batch = 0.6557s	
3257/11850 (epoch 13.743), train_loss = 1.50564924, grad/param norm = 2.3363e-01, time/batch = 0.6674s	
3258/11850 (epoch 13.747), train_loss = 1.27550573, grad/param norm = 1.9827e-01, time/batch = 0.6526s	
3259/11850 (epoch 13.751), train_loss = 1.31333669, grad/param norm = 2.1062e-01, time/batch = 0.6489s	
3260/11850 (epoch 13.755), train_loss = 1.44084256, grad/param norm = 2.2620e-01, time/batch = 0.6570s	
3261/11850 (epoch 13.759), train_loss = 1.36615914, grad/param norm = 2.2070e-01, time/batch = 0.6395s	
3262/11850 (epoch 13.764), train_loss = 1.40944620, grad/param norm = 2.2310e-01, time/batch = 0.6313s	
3263/11850 (epoch 13.768), train_loss = 1.28199707, grad/param norm = 2.1433e-01, time/batch = 0.6277s	
3264/11850 (epoch 13.772), train_loss = 1.41873830, grad/param norm = 2.2356e-01, time/batch = 0.6241s	
3265/11850 (epoch 13.776), train_loss = 1.43948091, grad/param norm = 2.1939e-01, time/batch = 0.6279s	
3266/11850 (epoch 13.781), train_loss = 1.37555311, grad/param norm = 2.1629e-01, time/batch = 0.6255s	
3267/11850 (epoch 13.785), train_loss = 1.36353971, grad/param norm = 2.0811e-01, time/batch = 0.6240s	
3268/11850 (epoch 13.789), train_loss = 1.48607631, grad/param norm = 2.4102e-01, time/batch = 0.6244s	
3269/11850 (epoch 13.793), train_loss = 1.58394336, grad/param norm = 2.4368e-01, time/batch = 0.6243s	
3270/11850 (epoch 13.797), train_loss = 1.48314443, grad/param norm = 2.2652e-01, time/batch = 0.6259s	
3271/11850 (epoch 13.802), train_loss = 1.34896043, grad/param norm = 2.1623e-01, time/batch = 0.6276s	
3272/11850 (epoch 13.806), train_loss = 1.42701816, grad/param norm = 2.0597e-01, time/batch = 0.6236s	
3273/11850 (epoch 13.810), train_loss = 1.68290132, grad/param norm = 2.9465e-01, time/batch = 0.6296s	
3274/11850 (epoch 13.814), train_loss = 1.41467602, grad/param norm = 2.1107e-01, time/batch = 0.6255s	
3275/11850 (epoch 13.819), train_loss = 1.57540940, grad/param norm = 2.2187e-01, time/batch = 0.6222s	
3276/11850 (epoch 13.823), train_loss = 1.59443254, grad/param norm = 2.3626e-01, time/batch = 0.6238s	
3277/11850 (epoch 13.827), train_loss = 1.47059008, grad/param norm = 2.2569e-01, time/batch = 0.6342s	
3278/11850 (epoch 13.831), train_loss = 1.43247292, grad/param norm = 2.3914e-01, time/batch = 0.6239s	
3279/11850 (epoch 13.835), train_loss = 1.43576411, grad/param norm = 2.2137e-01, time/batch = 0.6242s	
3280/11850 (epoch 13.840), train_loss = 1.37113227, grad/param norm = 2.0513e-01, time/batch = 0.6252s	
3281/11850 (epoch 13.844), train_loss = 1.39463567, grad/param norm = 2.0218e-01, time/batch = 0.6255s	
3282/11850 (epoch 13.848), train_loss = 1.49645770, grad/param norm = 2.3497e-01, time/batch = 0.6304s	
3283/11850 (epoch 13.852), train_loss = 1.41052937, grad/param norm = 2.2137e-01, time/batch = 0.6236s	
3284/11850 (epoch 13.857), train_loss = 1.41830921, grad/param norm = 2.1194e-01, time/batch = 0.6269s	
3285/11850 (epoch 13.861), train_loss = 1.49017531, grad/param norm = 2.3066e-01, time/batch = 0.6233s	
3286/11850 (epoch 13.865), train_loss = 1.54490118, grad/param norm = 2.5356e-01, time/batch = 0.6266s	
3287/11850 (epoch 13.869), train_loss = 1.52460093, grad/param norm = 2.2285e-01, time/batch = 0.6437s	
3288/11850 (epoch 13.873), train_loss = 1.51641672, grad/param norm = 2.2264e-01, time/batch = 0.6440s	
3289/11850 (epoch 13.878), train_loss = 1.48486771, grad/param norm = 2.2769e-01, time/batch = 0.6376s	
3290/11850 (epoch 13.882), train_loss = 1.47619298, grad/param norm = 2.1962e-01, time/batch = 0.6242s	
3291/11850 (epoch 13.886), train_loss = 1.54377334, grad/param norm = 2.3840e-01, time/batch = 0.6289s	
3292/11850 (epoch 13.890), train_loss = 1.51385369, grad/param norm = 2.3797e-01, time/batch = 0.6349s	
3293/11850 (epoch 13.895), train_loss = 1.50049161, grad/param norm = 2.5500e-01, time/batch = 0.6348s	
3294/11850 (epoch 13.899), train_loss = 1.37007626, grad/param norm = 2.4494e-01, time/batch = 0.6254s	
3295/11850 (epoch 13.903), train_loss = 1.41457408, grad/param norm = 2.1569e-01, time/batch = 0.6276s	
3296/11850 (epoch 13.907), train_loss = 1.38047598, grad/param norm = 2.3407e-01, time/batch = 0.6304s	
3297/11850 (epoch 13.911), train_loss = 1.52184605, grad/param norm = 2.2952e-01, time/batch = 0.6254s	
3298/11850 (epoch 13.916), train_loss = 1.59523758, grad/param norm = 2.4486e-01, time/batch = 0.6255s	
3299/11850 (epoch 13.920), train_loss = 1.40648758, grad/param norm = 2.2802e-01, time/batch = 0.6278s	
3300/11850 (epoch 13.924), train_loss = 1.47873498, grad/param norm = 2.4395e-01, time/batch = 0.6250s	
3301/11850 (epoch 13.928), train_loss = 1.57145714, grad/param norm = 2.3467e-01, time/batch = 0.6279s	
3302/11850 (epoch 13.932), train_loss = 1.59710440, grad/param norm = 2.3269e-01, time/batch = 0.6303s	
3303/11850 (epoch 13.937), train_loss = 1.52671469, grad/param norm = 2.3150e-01, time/batch = 0.6257s	
3304/11850 (epoch 13.941), train_loss = 1.52565125, grad/param norm = 2.4199e-01, time/batch = 0.6230s	
3305/11850 (epoch 13.945), train_loss = 1.53625815, grad/param norm = 2.2055e-01, time/batch = 0.6288s	
3306/11850 (epoch 13.949), train_loss = 1.39860631, grad/param norm = 2.7044e-01, time/batch = 0.6219s	
3307/11850 (epoch 13.954), train_loss = 1.53504486, grad/param norm = 2.3592e-01, time/batch = 0.6496s	
3308/11850 (epoch 13.958), train_loss = 1.49449161, grad/param norm = 2.3529e-01, time/batch = 0.6458s	
3309/11850 (epoch 13.962), train_loss = 1.35667881, grad/param norm = 2.4292e-01, time/batch = 0.6390s	
3310/11850 (epoch 13.966), train_loss = 1.34310589, grad/param norm = 2.1899e-01, time/batch = 0.6423s	
3311/11850 (epoch 13.970), train_loss = 1.45789396, grad/param norm = 2.2314e-01, time/batch = 0.6370s	
3312/11850 (epoch 13.975), train_loss = 1.46585016, grad/param norm = 2.3280e-01, time/batch = 0.6258s	
3313/11850 (epoch 13.979), train_loss = 1.48922182, grad/param norm = 2.5947e-01, time/batch = 0.6249s	
3314/11850 (epoch 13.983), train_loss = 1.65190995, grad/param norm = 2.8460e-01, time/batch = 0.6256s	
3315/11850 (epoch 13.987), train_loss = 1.45817614, grad/param norm = 2.2660e-01, time/batch = 0.6287s	
3316/11850 (epoch 13.992), train_loss = 1.61280981, grad/param norm = 2.0967e-01, time/batch = 0.6251s	
3317/11850 (epoch 13.996), train_loss = 1.70646276, grad/param norm = 2.5292e-01, time/batch = 0.6271s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
3318/11850 (epoch 14.000), train_loss = 1.43632608, grad/param norm = 2.2925e-01, time/batch = 0.6263s	
3319/11850 (epoch 14.004), train_loss = 1.56463893, grad/param norm = 2.7884e-01, time/batch = 0.6220s	
3320/11850 (epoch 14.008), train_loss = 1.53423575, grad/param norm = 2.2052e-01, time/batch = 0.6244s	
3321/11850 (epoch 14.013), train_loss = 1.51628126, grad/param norm = 2.4301e-01, time/batch = 0.6273s	
3322/11850 (epoch 14.017), train_loss = 1.68724485, grad/param norm = 2.3939e-01, time/batch = 0.6222s	
3323/11850 (epoch 14.021), train_loss = 1.40275298, grad/param norm = 1.9179e-01, time/batch = 0.6253s	
3324/11850 (epoch 14.025), train_loss = 1.28718551, grad/param norm = 2.0042e-01, time/batch = 0.6283s	
3325/11850 (epoch 14.030), train_loss = 1.33150544, grad/param norm = 2.1410e-01, time/batch = 0.6297s	
3326/11850 (epoch 14.034), train_loss = 1.36411714, grad/param norm = 2.1237e-01, time/batch = 0.6344s	
3327/11850 (epoch 14.038), train_loss = 1.44785483, grad/param norm = 2.0874e-01, time/batch = 0.6235s	
3328/11850 (epoch 14.042), train_loss = 1.47210171, grad/param norm = 2.1115e-01, time/batch = 0.6290s	
3329/11850 (epoch 14.046), train_loss = 1.54386292, grad/param norm = 2.5482e-01, time/batch = 0.6337s	
3330/11850 (epoch 14.051), train_loss = 1.45350585, grad/param norm = 2.1749e-01, time/batch = 0.6238s	
3331/11850 (epoch 14.055), train_loss = 1.43122493, grad/param norm = 2.1429e-01, time/batch = 0.6264s	
3332/11850 (epoch 14.059), train_loss = 1.52327469, grad/param norm = 2.3222e-01, time/batch = 0.6270s	
3333/11850 (epoch 14.063), train_loss = 1.47004944, grad/param norm = 2.1010e-01, time/batch = 0.6212s	
3334/11850 (epoch 14.068), train_loss = 1.44004625, grad/param norm = 2.0097e-01, time/batch = 0.6235s	
3335/11850 (epoch 14.072), train_loss = 1.44729799, grad/param norm = 1.9686e-01, time/batch = 0.6211s	
3336/11850 (epoch 14.076), train_loss = 1.59407636, grad/param norm = 2.1213e-01, time/batch = 0.6289s	
3337/11850 (epoch 14.080), train_loss = 1.39634349, grad/param norm = 2.0470e-01, time/batch = 0.6444s	
3338/11850 (epoch 14.084), train_loss = 1.30217070, grad/param norm = 2.1519e-01, time/batch = 0.6569s	
3339/11850 (epoch 14.089), train_loss = 1.31954229, grad/param norm = 1.9060e-01, time/batch = 0.6548s	
3340/11850 (epoch 14.093), train_loss = 1.29090632, grad/param norm = 2.1319e-01, time/batch = 0.6539s	
3341/11850 (epoch 14.097), train_loss = 1.52626208, grad/param norm = 2.1809e-01, time/batch = 0.6510s	
3342/11850 (epoch 14.101), train_loss = 1.46423477, grad/param norm = 2.4995e-01, time/batch = 0.6468s	
3343/11850 (epoch 14.105), train_loss = 1.34797161, grad/param norm = 2.1094e-01, time/batch = 0.6271s	
3344/11850 (epoch 14.110), train_loss = 1.48265819, grad/param norm = 2.2210e-01, time/batch = 0.6266s	
3345/11850 (epoch 14.114), train_loss = 1.49357007, grad/param norm = 2.5381e-01, time/batch = 0.6216s	
3346/11850 (epoch 14.118), train_loss = 1.40183462, grad/param norm = 2.0554e-01, time/batch = 0.6245s	
3347/11850 (epoch 14.122), train_loss = 1.55171460, grad/param norm = 2.3147e-01, time/batch = 0.6228s	
3348/11850 (epoch 14.127), train_loss = 1.49842707, grad/param norm = 2.4370e-01, time/batch = 0.6218s	
3349/11850 (epoch 14.131), train_loss = 1.49032267, grad/param norm = 2.3916e-01, time/batch = 0.6327s	
3350/11850 (epoch 14.135), train_loss = 1.41801785, grad/param norm = 2.3601e-01, time/batch = 0.6550s	
3351/11850 (epoch 14.139), train_loss = 1.42543901, grad/param norm = 2.2384e-01, time/batch = 0.6679s	
3352/11850 (epoch 14.143), train_loss = 1.41912584, grad/param norm = 2.2706e-01, time/batch = 0.6494s	
3353/11850 (epoch 14.148), train_loss = 1.44260808, grad/param norm = 2.2502e-01, time/batch = 0.6456s	
3354/11850 (epoch 14.152), train_loss = 1.55036930, grad/param norm = 2.4314e-01, time/batch = 0.6446s	
3355/11850 (epoch 14.156), train_loss = 1.52304910, grad/param norm = 2.1928e-01, time/batch = 0.6480s	
3356/11850 (epoch 14.160), train_loss = 1.77533560, grad/param norm = 2.7228e-01, time/batch = 0.6440s	
3357/11850 (epoch 14.165), train_loss = 1.59300601, grad/param norm = 2.4552e-01, time/batch = 0.6451s	
3358/11850 (epoch 14.169), train_loss = 1.45267727, grad/param norm = 2.3668e-01, time/batch = 0.6464s	
3359/11850 (epoch 14.173), train_loss = 1.53633906, grad/param norm = 2.1561e-01, time/batch = 0.6329s	
3360/11850 (epoch 14.177), train_loss = 1.46073038, grad/param norm = 2.4705e-01, time/batch = 0.6273s	
3361/11850 (epoch 14.181), train_loss = 1.53800612, grad/param norm = 2.3347e-01, time/batch = 0.6294s	
3362/11850 (epoch 14.186), train_loss = 1.62631523, grad/param norm = 2.6186e-01, time/batch = 0.6301s	
3363/11850 (epoch 14.190), train_loss = 1.49894159, grad/param norm = 2.2073e-01, time/batch = 0.6283s	
3364/11850 (epoch 14.194), train_loss = 1.62215553, grad/param norm = 2.4482e-01, time/batch = 0.6595s	
3365/11850 (epoch 14.198), train_loss = 1.37813493, grad/param norm = 2.1820e-01, time/batch = 0.6373s	
3366/11850 (epoch 14.203), train_loss = 1.31610271, grad/param norm = 1.9565e-01, time/batch = 0.6299s	
3367/11850 (epoch 14.207), train_loss = 1.52117494, grad/param norm = 2.2643e-01, time/batch = 0.6254s	
3368/11850 (epoch 14.211), train_loss = 1.45797933, grad/param norm = 2.1162e-01, time/batch = 0.6284s	
3369/11850 (epoch 14.215), train_loss = 1.45752486, grad/param norm = 2.4500e-01, time/batch = 0.6295s	
3370/11850 (epoch 14.219), train_loss = 1.41462170, grad/param norm = 2.1427e-01, time/batch = 0.6313s	
3371/11850 (epoch 14.224), train_loss = 1.67786007, grad/param norm = 2.5698e-01, time/batch = 0.6338s	
3372/11850 (epoch 14.228), train_loss = 1.57202841, grad/param norm = 2.2651e-01, time/batch = 0.6263s	
3373/11850 (epoch 14.232), train_loss = 1.52946446, grad/param norm = 2.2311e-01, time/batch = 0.6389s	
3374/11850 (epoch 14.236), train_loss = 1.38615876, grad/param norm = 2.3893e-01, time/batch = 0.6459s	
3375/11850 (epoch 14.241), train_loss = 1.67782422, grad/param norm = 2.4020e-01, time/batch = 0.6321s	
3376/11850 (epoch 14.245), train_loss = 1.56303173, grad/param norm = 2.1302e-01, time/batch = 0.6246s	
3377/11850 (epoch 14.249), train_loss = 1.39311274, grad/param norm = 2.2135e-01, time/batch = 0.6248s	
3378/11850 (epoch 14.253), train_loss = 1.51406057, grad/param norm = 2.5721e-01, time/batch = 0.6251s	
3379/11850 (epoch 14.257), train_loss = 1.59852025, grad/param norm = 2.2508e-01, time/batch = 0.6240s	
3380/11850 (epoch 14.262), train_loss = 1.67474927, grad/param norm = 2.8220e-01, time/batch = 0.6230s	
3381/11850 (epoch 14.266), train_loss = 1.53932428, grad/param norm = 2.3119e-01, time/batch = 0.6262s	
3382/11850 (epoch 14.270), train_loss = 1.40815016, grad/param norm = 2.1234e-01, time/batch = 0.6226s	
3383/11850 (epoch 14.274), train_loss = 1.43379666, grad/param norm = 2.5782e-01, time/batch = 0.6218s	
3384/11850 (epoch 14.278), train_loss = 1.31118498, grad/param norm = 2.3433e-01, time/batch = 0.6261s	
3385/11850 (epoch 14.283), train_loss = 1.40283151, grad/param norm = 2.0271e-01, time/batch = 0.6253s	
3386/11850 (epoch 14.287), train_loss = 1.55176924, grad/param norm = 2.3092e-01, time/batch = 0.6282s	
3387/11850 (epoch 14.291), train_loss = 1.51252818, grad/param norm = 2.3337e-01, time/batch = 0.6289s	
3388/11850 (epoch 14.295), train_loss = 1.48604642, grad/param norm = 2.1835e-01, time/batch = 0.6295s	
3389/11850 (epoch 14.300), train_loss = 1.41836799, grad/param norm = 2.3754e-01, time/batch = 0.6294s	
3390/11850 (epoch 14.304), train_loss = 1.42117308, grad/param norm = 2.2526e-01, time/batch = 0.6281s	
3391/11850 (epoch 14.308), train_loss = 1.40807216, grad/param norm = 2.0349e-01, time/batch = 0.6350s	
3392/11850 (epoch 14.312), train_loss = 1.26656971, grad/param norm = 2.0879e-01, time/batch = 0.6399s	
3393/11850 (epoch 14.316), train_loss = 1.46868409, grad/param norm = 2.1613e-01, time/batch = 0.6221s	
3394/11850 (epoch 14.321), train_loss = 1.37808756, grad/param norm = 1.9166e-01, time/batch = 0.6258s	
3395/11850 (epoch 14.325), train_loss = 1.43465467, grad/param norm = 2.3324e-01, time/batch = 0.6291s	
3396/11850 (epoch 14.329), train_loss = 1.42386619, grad/param norm = 2.2270e-01, time/batch = 0.6224s	
3397/11850 (epoch 14.333), train_loss = 1.44004737, grad/param norm = 2.4194e-01, time/batch = 0.6255s	
3398/11850 (epoch 14.338), train_loss = 1.35619245, grad/param norm = 2.1600e-01, time/batch = 0.6274s	
3399/11850 (epoch 14.342), train_loss = 1.58888623, grad/param norm = 2.7901e-01, time/batch = 0.6235s	
3400/11850 (epoch 14.346), train_loss = 1.46509283, grad/param norm = 2.2407e-01, time/batch = 0.6232s	
3401/11850 (epoch 14.350), train_loss = 1.30566255, grad/param norm = 2.1067e-01, time/batch = 0.6280s	
3402/11850 (epoch 14.354), train_loss = 1.54502564, grad/param norm = 2.3485e-01, time/batch = 0.6267s	
3403/11850 (epoch 14.359), train_loss = 1.53159913, grad/param norm = 2.5423e-01, time/batch = 0.6253s	
3404/11850 (epoch 14.363), train_loss = 1.48995736, grad/param norm = 2.3249e-01, time/batch = 0.6239s	
3405/11850 (epoch 14.367), train_loss = 1.47556198, grad/param norm = 1.9824e-01, time/batch = 0.6290s	
3406/11850 (epoch 14.371), train_loss = 1.49563028, grad/param norm = 2.2388e-01, time/batch = 0.6237s	
3407/11850 (epoch 14.376), train_loss = 1.41095948, grad/param norm = 2.1161e-01, time/batch = 0.6220s	
3408/11850 (epoch 14.380), train_loss = 1.35835105, grad/param norm = 2.0015e-01, time/batch = 0.6220s	
3409/11850 (epoch 14.384), train_loss = 1.34661087, grad/param norm = 2.2539e-01, time/batch = 0.6248s	
3410/11850 (epoch 14.388), train_loss = 1.56425868, grad/param norm = 2.5367e-01, time/batch = 0.6271s	
3411/11850 (epoch 14.392), train_loss = 1.57756192, grad/param norm = 2.3433e-01, time/batch = 0.6270s	
3412/11850 (epoch 14.397), train_loss = 1.54456896, grad/param norm = 2.6534e-01, time/batch = 0.6243s	
3413/11850 (epoch 14.401), train_loss = 1.28390539, grad/param norm = 1.9027e-01, time/batch = 0.6313s	
3414/11850 (epoch 14.405), train_loss = 1.36657625, grad/param norm = 2.1104e-01, time/batch = 0.6284s	
3415/11850 (epoch 14.409), train_loss = 1.55231348, grad/param norm = 2.3165e-01, time/batch = 0.6262s	
3416/11850 (epoch 14.414), train_loss = 1.31835205, grad/param norm = 2.1490e-01, time/batch = 0.6244s	
3417/11850 (epoch 14.418), train_loss = 1.31263402, grad/param norm = 2.1309e-01, time/batch = 0.6262s	
3418/11850 (epoch 14.422), train_loss = 1.26744904, grad/param norm = 2.0846e-01, time/batch = 0.6285s	
3419/11850 (epoch 14.426), train_loss = 1.33209153, grad/param norm = 2.2112e-01, time/batch = 0.6267s	
3420/11850 (epoch 14.430), train_loss = 1.37016871, grad/param norm = 2.1298e-01, time/batch = 0.6275s	
3421/11850 (epoch 14.435), train_loss = 1.37009905, grad/param norm = 1.9739e-01, time/batch = 0.6260s	
3422/11850 (epoch 14.439), train_loss = 1.54548644, grad/param norm = 2.1976e-01, time/batch = 0.6242s	
3423/11850 (epoch 14.443), train_loss = 1.50418047, grad/param norm = 2.3090e-01, time/batch = 0.6232s	
3424/11850 (epoch 14.447), train_loss = 1.32938690, grad/param norm = 2.0967e-01, time/batch = 0.6341s	
3425/11850 (epoch 14.451), train_loss = 1.30895174, grad/param norm = 2.0793e-01, time/batch = 0.6247s	
3426/11850 (epoch 14.456), train_loss = 1.39435177, grad/param norm = 2.3490e-01, time/batch = 0.6230s	
3427/11850 (epoch 14.460), train_loss = 1.45562902, grad/param norm = 2.1921e-01, time/batch = 0.6249s	
3428/11850 (epoch 14.464), train_loss = 1.36246355, grad/param norm = 2.1766e-01, time/batch = 0.6264s	
3429/11850 (epoch 14.468), train_loss = 1.43803308, grad/param norm = 2.0317e-01, time/batch = 0.6239s	
3430/11850 (epoch 14.473), train_loss = 1.48947513, grad/param norm = 2.4896e-01, time/batch = 0.6271s	
3431/11850 (epoch 14.477), train_loss = 1.31210495, grad/param norm = 2.1734e-01, time/batch = 0.6281s	
3432/11850 (epoch 14.481), train_loss = 1.35556137, grad/param norm = 2.2238e-01, time/batch = 0.6251s	
3433/11850 (epoch 14.485), train_loss = 1.30271573, grad/param norm = 1.9607e-01, time/batch = 0.6239s	
3434/11850 (epoch 14.489), train_loss = 1.48110764, grad/param norm = 2.3699e-01, time/batch = 0.6246s	
3435/11850 (epoch 14.494), train_loss = 1.38543493, grad/param norm = 2.2161e-01, time/batch = 0.6253s	
3436/11850 (epoch 14.498), train_loss = 1.35301549, grad/param norm = 2.3107e-01, time/batch = 0.6237s	
3437/11850 (epoch 14.502), train_loss = 1.26623096, grad/param norm = 2.2603e-01, time/batch = 0.6231s	
3438/11850 (epoch 14.506), train_loss = 1.54779376, grad/param norm = 2.2415e-01, time/batch = 0.6228s	
3439/11850 (epoch 14.511), train_loss = 1.40178053, grad/param norm = 2.0716e-01, time/batch = 0.6219s	
3440/11850 (epoch 14.515), train_loss = 1.51948365, grad/param norm = 2.2071e-01, time/batch = 0.6291s	
3441/11850 (epoch 14.519), train_loss = 1.35775551, grad/param norm = 2.1330e-01, time/batch = 0.6381s	
3442/11850 (epoch 14.523), train_loss = 1.39296626, grad/param norm = 2.1177e-01, time/batch = 0.6270s	
3443/11850 (epoch 14.527), train_loss = 1.29092783, grad/param norm = 2.1117e-01, time/batch = 0.6266s	
3444/11850 (epoch 14.532), train_loss = 1.48225806, grad/param norm = 2.1055e-01, time/batch = 0.6394s	
3445/11850 (epoch 14.536), train_loss = 1.35526046, grad/param norm = 2.1014e-01, time/batch = 0.6444s	
3446/11850 (epoch 14.540), train_loss = 1.30860120, grad/param norm = 2.0365e-01, time/batch = 0.6554s	
3447/11850 (epoch 14.544), train_loss = 1.39895407, grad/param norm = 2.2432e-01, time/batch = 0.6409s	
3448/11850 (epoch 14.549), train_loss = 1.20983604, grad/param norm = 1.9743e-01, time/batch = 0.6306s	
3449/11850 (epoch 14.553), train_loss = 1.45626240, grad/param norm = 2.2180e-01, time/batch = 0.6286s	
3450/11850 (epoch 14.557), train_loss = 1.58404073, grad/param norm = 2.4100e-01, time/batch = 0.6336s	
3451/11850 (epoch 14.561), train_loss = 1.44756180, grad/param norm = 2.4902e-01, time/batch = 0.6352s	
3452/11850 (epoch 14.565), train_loss = 1.58778138, grad/param norm = 2.4853e-01, time/batch = 0.6318s	
3453/11850 (epoch 14.570), train_loss = 1.39662667, grad/param norm = 2.2898e-01, time/batch = 0.6324s	
3454/11850 (epoch 14.574), train_loss = 1.49825164, grad/param norm = 2.2813e-01, time/batch = 0.6275s	
3455/11850 (epoch 14.578), train_loss = 1.56972618, grad/param norm = 2.4070e-01, time/batch = 0.6243s	
3456/11850 (epoch 14.582), train_loss = 1.36340244, grad/param norm = 2.2970e-01, time/batch = 0.6229s	
3457/11850 (epoch 14.586), train_loss = 1.38946401, grad/param norm = 2.2942e-01, time/batch = 0.6248s	
3458/11850 (epoch 14.591), train_loss = 1.52445567, grad/param norm = 2.3183e-01, time/batch = 0.6244s	
3459/11850 (epoch 14.595), train_loss = 1.26822208, grad/param norm = 2.1890e-01, time/batch = 0.6322s	
3460/11850 (epoch 14.599), train_loss = 1.36555785, grad/param norm = 2.2969e-01, time/batch = 0.6476s	
3461/11850 (epoch 14.603), train_loss = 1.34431576, grad/param norm = 1.9804e-01, time/batch = 0.6290s	
3462/11850 (epoch 14.608), train_loss = 1.52126662, grad/param norm = 2.2157e-01, time/batch = 0.6300s	
3463/11850 (epoch 14.612), train_loss = 1.63510055, grad/param norm = 2.4112e-01, time/batch = 0.6273s	
3464/11850 (epoch 14.616), train_loss = 1.54732994, grad/param norm = 2.2053e-01, time/batch = 0.6269s	
3465/11850 (epoch 14.620), train_loss = 1.39962720, grad/param norm = 2.2588e-01, time/batch = 0.6271s	
3466/11850 (epoch 14.624), train_loss = 1.49657691, grad/param norm = 2.5135e-01, time/batch = 0.6265s	
3467/11850 (epoch 14.629), train_loss = 1.35234648, grad/param norm = 2.1653e-01, time/batch = 0.6236s	
3468/11850 (epoch 14.633), train_loss = 1.28145386, grad/param norm = 2.3272e-01, time/batch = 0.6220s	
3469/11850 (epoch 14.637), train_loss = 1.28420745, grad/param norm = 2.3172e-01, time/batch = 0.6217s	
3470/11850 (epoch 14.641), train_loss = 1.29839033, grad/param norm = 2.0802e-01, time/batch = 0.6233s	
3471/11850 (epoch 14.646), train_loss = 1.38653308, grad/param norm = 2.3978e-01, time/batch = 0.6236s	
3472/11850 (epoch 14.650), train_loss = 1.41981543, grad/param norm = 2.2851e-01, time/batch = 0.6233s	
3473/11850 (epoch 14.654), train_loss = 1.40653850, grad/param norm = 2.6110e-01, time/batch = 0.6247s	
3474/11850 (epoch 14.658), train_loss = 1.44323491, grad/param norm = 2.2910e-01, time/batch = 0.6281s	
3475/11850 (epoch 14.662), train_loss = 1.36084995, grad/param norm = 2.5568e-01, time/batch = 0.6300s	
3476/11850 (epoch 14.667), train_loss = 1.50161024, grad/param norm = 2.4996e-01, time/batch = 0.6398s	
3477/11850 (epoch 14.671), train_loss = 1.35644076, grad/param norm = 2.0734e-01, time/batch = 0.6341s	
3478/11850 (epoch 14.675), train_loss = 1.38301951, grad/param norm = 2.0112e-01, time/batch = 0.6320s	
3479/11850 (epoch 14.679), train_loss = 1.44279260, grad/param norm = 2.2800e-01, time/batch = 0.6367s	
3480/11850 (epoch 14.684), train_loss = 1.43384649, grad/param norm = 2.4068e-01, time/batch = 0.6496s	
3481/11850 (epoch 14.688), train_loss = 1.32622150, grad/param norm = 1.9393e-01, time/batch = 0.6380s	
3482/11850 (epoch 14.692), train_loss = 1.41966038, grad/param norm = 2.5074e-01, time/batch = 0.6416s	
3483/11850 (epoch 14.696), train_loss = 1.32809515, grad/param norm = 2.5456e-01, time/batch = 0.6404s	
3484/11850 (epoch 14.700), train_loss = 1.41192296, grad/param norm = 2.2039e-01, time/batch = 0.6389s	
3485/11850 (epoch 14.705), train_loss = 1.38042023, grad/param norm = 2.1535e-01, time/batch = 0.6361s	
3486/11850 (epoch 14.709), train_loss = 1.28775991, grad/param norm = 2.1162e-01, time/batch = 0.6380s	
3487/11850 (epoch 14.713), train_loss = 1.35644961, grad/param norm = 2.3346e-01, time/batch = 0.6363s	
3488/11850 (epoch 14.717), train_loss = 1.30976199, grad/param norm = 2.2852e-01, time/batch = 0.6321s	
3489/11850 (epoch 14.722), train_loss = 1.45049093, grad/param norm = 2.4570e-01, time/batch = 0.6345s	
3490/11850 (epoch 14.726), train_loss = 1.28354250, grad/param norm = 2.4163e-01, time/batch = 0.6381s	
3491/11850 (epoch 14.730), train_loss = 1.24808424, grad/param norm = 2.0538e-01, time/batch = 0.6472s	
3492/11850 (epoch 14.734), train_loss = 1.32256558, grad/param norm = 2.1124e-01, time/batch = 0.6402s	
3493/11850 (epoch 14.738), train_loss = 1.53480512, grad/param norm = 2.3901e-01, time/batch = 0.6370s	
3494/11850 (epoch 14.743), train_loss = 1.46039707, grad/param norm = 2.3355e-01, time/batch = 0.6258s	
3495/11850 (epoch 14.747), train_loss = 1.24400432, grad/param norm = 2.0440e-01, time/batch = 0.6319s	
3496/11850 (epoch 14.751), train_loss = 1.27977790, grad/param norm = 2.0922e-01, time/batch = 0.6246s	
3497/11850 (epoch 14.755), train_loss = 1.40871290, grad/param norm = 2.2428e-01, time/batch = 0.6241s	
3498/11850 (epoch 14.759), train_loss = 1.32423962, grad/param norm = 2.1716e-01, time/batch = 0.6437s	
3499/11850 (epoch 14.764), train_loss = 1.37719260, grad/param norm = 2.2209e-01, time/batch = 0.6651s	
3500/11850 (epoch 14.768), train_loss = 1.24958809, grad/param norm = 2.1479e-01, time/batch = 0.6471s	
3501/11850 (epoch 14.772), train_loss = 1.38047833, grad/param norm = 2.2089e-01, time/batch = 0.6400s	
3502/11850 (epoch 14.776), train_loss = 1.39799028, grad/param norm = 2.1444e-01, time/batch = 0.6295s	
3503/11850 (epoch 14.781), train_loss = 1.34101825, grad/param norm = 2.1720e-01, time/batch = 0.6313s	
3504/11850 (epoch 14.785), train_loss = 1.32918990, grad/param norm = 2.1765e-01, time/batch = 0.6267s	
3505/11850 (epoch 14.789), train_loss = 1.44644657, grad/param norm = 2.2432e-01, time/batch = 0.6276s	
3506/11850 (epoch 14.793), train_loss = 1.53362899, grad/param norm = 2.4605e-01, time/batch = 0.6297s	
3507/11850 (epoch 14.797), train_loss = 1.43844323, grad/param norm = 2.2835e-01, time/batch = 0.6265s	
3508/11850 (epoch 14.802), train_loss = 1.30089667, grad/param norm = 2.0730e-01, time/batch = 0.6242s	
3509/11850 (epoch 14.806), train_loss = 1.38414799, grad/param norm = 1.9978e-01, time/batch = 0.6253s	
3510/11850 (epoch 14.810), train_loss = 1.61756220, grad/param norm = 2.8996e-01, time/batch = 0.6260s	
3511/11850 (epoch 14.814), train_loss = 1.38047306, grad/param norm = 2.0864e-01, time/batch = 0.6268s	
3512/11850 (epoch 14.819), train_loss = 1.53858758, grad/param norm = 2.2398e-01, time/batch = 0.6380s	
3513/11850 (epoch 14.823), train_loss = 1.54858210, grad/param norm = 2.3278e-01, time/batch = 0.6280s	
3514/11850 (epoch 14.827), train_loss = 1.43376736, grad/param norm = 2.3148e-01, time/batch = 0.6277s	
3515/11850 (epoch 14.831), train_loss = 1.40307811, grad/param norm = 2.4107e-01, time/batch = 0.6233s	
3516/11850 (epoch 14.835), train_loss = 1.39696663, grad/param norm = 2.1888e-01, time/batch = 0.6213s	
3517/11850 (epoch 14.840), train_loss = 1.33701968, grad/param norm = 2.1203e-01, time/batch = 0.6248s	
3518/11850 (epoch 14.844), train_loss = 1.36671524, grad/param norm = 2.0394e-01, time/batch = 0.6212s	
3519/11850 (epoch 14.848), train_loss = 1.45983103, grad/param norm = 2.3195e-01, time/batch = 0.6327s	
3520/11850 (epoch 14.852), train_loss = 1.38291144, grad/param norm = 2.4079e-01, time/batch = 0.6434s	
3521/11850 (epoch 14.857), train_loss = 1.38448301, grad/param norm = 2.2561e-01, time/batch = 0.6377s	
3522/11850 (epoch 14.861), train_loss = 1.44696207, grad/param norm = 2.3128e-01, time/batch = 0.6270s	
3523/11850 (epoch 14.865), train_loss = 1.49906847, grad/param norm = 2.6847e-01, time/batch = 0.6295s	
3524/11850 (epoch 14.869), train_loss = 1.47162235, grad/param norm = 2.1843e-01, time/batch = 0.6271s	
3525/11850 (epoch 14.873), train_loss = 1.47137454, grad/param norm = 2.3179e-01, time/batch = 0.6302s	
3526/11850 (epoch 14.878), train_loss = 1.45439792, grad/param norm = 2.3564e-01, time/batch = 0.6264s	
3527/11850 (epoch 14.882), train_loss = 1.43162476, grad/param norm = 2.2365e-01, time/batch = 0.6253s	
3528/11850 (epoch 14.886), train_loss = 1.50645995, grad/param norm = 2.8219e-01, time/batch = 0.6263s	
3529/11850 (epoch 14.890), train_loss = 1.48574830, grad/param norm = 2.6129e-01, time/batch = 0.6240s	
3530/11850 (epoch 14.895), train_loss = 1.46350391, grad/param norm = 2.6004e-01, time/batch = 0.6312s	
3531/11850 (epoch 14.899), train_loss = 1.32625413, grad/param norm = 2.5154e-01, time/batch = 0.6520s	
3532/11850 (epoch 14.903), train_loss = 1.39501287, grad/param norm = 2.3596e-01, time/batch = 0.6397s	
3533/11850 (epoch 14.907), train_loss = 1.33816168, grad/param norm = 2.4028e-01, time/batch = 0.6266s	
3534/11850 (epoch 14.911), train_loss = 1.48151977, grad/param norm = 2.3955e-01, time/batch = 0.6257s	
3535/11850 (epoch 14.916), train_loss = 1.54629941, grad/param norm = 2.4518e-01, time/batch = 0.6254s	
3536/11850 (epoch 14.920), train_loss = 1.37716008, grad/param norm = 2.3539e-01, time/batch = 0.6271s	
3537/11850 (epoch 14.924), train_loss = 1.43012983, grad/param norm = 2.3430e-01, time/batch = 0.6238s	
3538/11850 (epoch 14.928), train_loss = 1.52951501, grad/param norm = 2.5355e-01, time/batch = 0.6320s	
3539/11850 (epoch 14.932), train_loss = 1.55075236, grad/param norm = 2.3752e-01, time/batch = 0.6530s	
3540/11850 (epoch 14.937), train_loss = 1.48677801, grad/param norm = 2.4887e-01, time/batch = 0.6519s	
3541/11850 (epoch 14.941), train_loss = 1.49195211, grad/param norm = 2.4906e-01, time/batch = 0.6537s	
3542/11850 (epoch 14.945), train_loss = 1.49214595, grad/param norm = 2.2395e-01, time/batch = 0.6532s	
3543/11850 (epoch 14.949), train_loss = 1.36087938, grad/param norm = 2.5007e-01, time/batch = 0.6464s	
3544/11850 (epoch 14.954), train_loss = 1.48916510, grad/param norm = 2.5994e-01, time/batch = 0.6356s	
3545/11850 (epoch 14.958), train_loss = 1.45422355, grad/param norm = 2.4120e-01, time/batch = 0.6272s	
3546/11850 (epoch 14.962), train_loss = 1.31318210, grad/param norm = 2.3645e-01, time/batch = 0.6349s	
3547/11850 (epoch 14.966), train_loss = 1.29563710, grad/param norm = 2.1001e-01, time/batch = 0.6248s	
3548/11850 (epoch 14.970), train_loss = 1.41996027, grad/param norm = 2.2760e-01, time/batch = 0.6232s	
3549/11850 (epoch 14.975), train_loss = 1.42431750, grad/param norm = 2.2045e-01, time/batch = 0.6496s	
3550/11850 (epoch 14.979), train_loss = 1.44267434, grad/param norm = 2.7130e-01, time/batch = 0.6396s	
3551/11850 (epoch 14.983), train_loss = 1.62508811, grad/param norm = 3.0839e-01, time/batch = 0.6273s	
3552/11850 (epoch 14.987), train_loss = 1.42816957, grad/param norm = 2.5402e-01, time/batch = 0.6292s	
3553/11850 (epoch 14.992), train_loss = 1.57324167, grad/param norm = 2.1013e-01, time/batch = 0.6245s	
3554/11850 (epoch 14.996), train_loss = 1.67168691, grad/param norm = 2.5424e-01, time/batch = 0.6293s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
3555/11850 (epoch 15.000), train_loss = 1.39672729, grad/param norm = 2.4209e-01, time/batch = 0.6294s	
3556/11850 (epoch 15.004), train_loss = 1.51322717, grad/param norm = 2.5557e-01, time/batch = 0.6292s	
3557/11850 (epoch 15.008), train_loss = 1.49549090, grad/param norm = 2.1864e-01, time/batch = 0.6305s	
3558/11850 (epoch 15.013), train_loss = 1.48950977, grad/param norm = 2.6053e-01, time/batch = 0.6233s	
3559/11850 (epoch 15.017), train_loss = 1.64621119, grad/param norm = 2.2896e-01, time/batch = 0.6247s	
3560/11850 (epoch 15.021), train_loss = 1.38266756, grad/param norm = 1.9492e-01, time/batch = 0.6235s	
3561/11850 (epoch 15.025), train_loss = 1.26425635, grad/param norm = 2.0219e-01, time/batch = 0.6257s	
3562/11850 (epoch 15.030), train_loss = 1.29892713, grad/param norm = 2.0330e-01, time/batch = 0.6262s	
3563/11850 (epoch 15.034), train_loss = 1.34019647, grad/param norm = 2.1599e-01, time/batch = 0.6262s	
3564/11850 (epoch 15.038), train_loss = 1.41690711, grad/param norm = 2.1386e-01, time/batch = 0.6524s	
3565/11850 (epoch 15.042), train_loss = 1.43815850, grad/param norm = 2.2527e-01, time/batch = 0.6392s	
3566/11850 (epoch 15.046), train_loss = 1.49300288, grad/param norm = 2.5322e-01, time/batch = 0.6241s	
3567/11850 (epoch 15.051), train_loss = 1.42505991, grad/param norm = 2.2629e-01, time/batch = 0.6261s	
3568/11850 (epoch 15.055), train_loss = 1.38932481, grad/param norm = 2.0825e-01, time/batch = 0.6264s	
3569/11850 (epoch 15.059), train_loss = 1.48802797, grad/param norm = 2.3010e-01, time/batch = 0.6273s	
3570/11850 (epoch 15.063), train_loss = 1.43476249, grad/param norm = 2.0845e-01, time/batch = 0.6348s	
3571/11850 (epoch 15.068), train_loss = 1.40296724, grad/param norm = 2.0334e-01, time/batch = 0.6435s	
3572/11850 (epoch 15.072), train_loss = 1.41698547, grad/param norm = 2.0029e-01, time/batch = 0.6315s	
3573/11850 (epoch 15.076), train_loss = 1.55567984, grad/param norm = 2.0678e-01, time/batch = 0.6297s	
3574/11850 (epoch 15.080), train_loss = 1.36309314, grad/param norm = 2.1471e-01, time/batch = 0.6266s	
3575/11850 (epoch 15.084), train_loss = 1.27186054, grad/param norm = 2.1933e-01, time/batch = 0.6269s	
3576/11850 (epoch 15.089), train_loss = 1.28546467, grad/param norm = 1.8995e-01, time/batch = 0.6291s	
3577/11850 (epoch 15.093), train_loss = 1.26200527, grad/param norm = 2.3938e-01, time/batch = 0.6277s	
3578/11850 (epoch 15.097), train_loss = 1.48427851, grad/param norm = 2.3214e-01, time/batch = 0.6252s	
3579/11850 (epoch 15.101), train_loss = 1.41832327, grad/param norm = 2.5033e-01, time/batch = 0.6219s	
3580/11850 (epoch 15.105), train_loss = 1.31513336, grad/param norm = 2.2442e-01, time/batch = 0.6196s	
3581/11850 (epoch 15.110), train_loss = 1.45356210, grad/param norm = 2.2673e-01, time/batch = 0.6248s	
3582/11850 (epoch 15.114), train_loss = 1.44809875, grad/param norm = 2.2788e-01, time/batch = 0.6241s	
3583/11850 (epoch 15.118), train_loss = 1.37339361, grad/param norm = 2.0140e-01, time/batch = 0.6263s	
3584/11850 (epoch 15.122), train_loss = 1.51397512, grad/param norm = 2.3019e-01, time/batch = 0.6267s	
3585/11850 (epoch 15.127), train_loss = 1.45913255, grad/param norm = 2.4046e-01, time/batch = 0.6282s	
3586/11850 (epoch 15.131), train_loss = 1.45611105, grad/param norm = 2.6471e-01, time/batch = 0.6259s	
3587/11850 (epoch 15.135), train_loss = 1.37878186, grad/param norm = 2.3489e-01, time/batch = 0.6264s	
3588/11850 (epoch 15.139), train_loss = 1.37816609, grad/param norm = 2.1993e-01, time/batch = 0.6266s	
3589/11850 (epoch 15.143), train_loss = 1.38821954, grad/param norm = 2.3733e-01, time/batch = 0.6292s	
3590/11850 (epoch 15.148), train_loss = 1.40648249, grad/param norm = 2.2706e-01, time/batch = 0.6228s	
3591/11850 (epoch 15.152), train_loss = 1.51929269, grad/param norm = 2.5036e-01, time/batch = 0.6292s	
3592/11850 (epoch 15.156), train_loss = 1.47337696, grad/param norm = 2.2168e-01, time/batch = 0.6248s	
3593/11850 (epoch 15.160), train_loss = 1.71544970, grad/param norm = 2.7052e-01, time/batch = 0.6234s	
3594/11850 (epoch 15.165), train_loss = 1.55181426, grad/param norm = 2.4166e-01, time/batch = 0.6414s	
3595/11850 (epoch 15.169), train_loss = 1.41258131, grad/param norm = 2.3732e-01, time/batch = 0.6255s	
3596/11850 (epoch 15.173), train_loss = 1.49682099, grad/param norm = 2.2619e-01, time/batch = 0.6322s	
3597/11850 (epoch 15.177), train_loss = 1.41805098, grad/param norm = 2.6021e-01, time/batch = 0.6256s	
3598/11850 (epoch 15.181), train_loss = 1.50929334, grad/param norm = 2.3756e-01, time/batch = 0.6222s	
3599/11850 (epoch 15.186), train_loss = 1.58895489, grad/param norm = 2.8637e-01, time/batch = 0.6227s	
3600/11850 (epoch 15.190), train_loss = 1.46032558, grad/param norm = 2.2555e-01, time/batch = 0.6237s	
3601/11850 (epoch 15.194), train_loss = 1.57737638, grad/param norm = 2.4874e-01, time/batch = 0.6276s	
3602/11850 (epoch 15.198), train_loss = 1.33316525, grad/param norm = 2.1368e-01, time/batch = 0.6414s	
3603/11850 (epoch 15.203), train_loss = 1.28819807, grad/param norm = 2.1895e-01, time/batch = 0.6368s	
3604/11850 (epoch 15.207), train_loss = 1.48793569, grad/param norm = 2.4183e-01, time/batch = 0.6222s	
3605/11850 (epoch 15.211), train_loss = 1.41816698, grad/param norm = 2.1171e-01, time/batch = 0.6259s	
3606/11850 (epoch 15.215), train_loss = 1.42821892, grad/param norm = 2.3417e-01, time/batch = 0.6221s	
3607/11850 (epoch 15.219), train_loss = 1.38564978, grad/param norm = 2.1831e-01, time/batch = 0.6246s	
3608/11850 (epoch 15.224), train_loss = 1.63539869, grad/param norm = 2.4664e-01, time/batch = 0.6229s	
3609/11850 (epoch 15.228), train_loss = 1.53091284, grad/param norm = 2.3124e-01, time/batch = 0.6274s	
3610/11850 (epoch 15.232), train_loss = 1.49720641, grad/param norm = 2.2081e-01, time/batch = 0.6208s	
3611/11850 (epoch 15.236), train_loss = 1.34827504, grad/param norm = 2.4380e-01, time/batch = 0.6237s	
3612/11850 (epoch 15.241), train_loss = 1.62751379, grad/param norm = 2.4347e-01, time/batch = 0.6202s	
3613/11850 (epoch 15.245), train_loss = 1.52606374, grad/param norm = 2.2766e-01, time/batch = 0.6351s	
3614/11850 (epoch 15.249), train_loss = 1.34636831, grad/param norm = 2.1662e-01, time/batch = 0.6444s	
3615/11850 (epoch 15.253), train_loss = 1.46635261, grad/param norm = 2.4863e-01, time/batch = 0.6272s	
3616/11850 (epoch 15.257), train_loss = 1.55444629, grad/param norm = 2.2491e-01, time/batch = 0.6242s	
3617/11850 (epoch 15.262), train_loss = 1.63103148, grad/param norm = 2.3842e-01, time/batch = 0.6248s	
3618/11850 (epoch 15.266), train_loss = 1.49806307, grad/param norm = 2.3520e-01, time/batch = 0.6245s	
3619/11850 (epoch 15.270), train_loss = 1.37363151, grad/param norm = 2.1163e-01, time/batch = 0.6232s	
3620/11850 (epoch 15.274), train_loss = 1.38655399, grad/param norm = 2.4515e-01, time/batch = 0.6240s	
3621/11850 (epoch 15.278), train_loss = 1.26634448, grad/param norm = 2.2379e-01, time/batch = 0.6267s	
3622/11850 (epoch 15.283), train_loss = 1.36440294, grad/param norm = 2.1316e-01, time/batch = 0.6234s	
3623/11850 (epoch 15.287), train_loss = 1.51781069, grad/param norm = 2.3506e-01, time/batch = 0.6223s	
3624/11850 (epoch 15.291), train_loss = 1.45862953, grad/param norm = 2.1121e-01, time/batch = 0.6241s	
3625/11850 (epoch 15.295), train_loss = 1.45192322, grad/param norm = 2.1780e-01, time/batch = 0.6231s	
3626/11850 (epoch 15.300), train_loss = 1.39559100, grad/param norm = 2.4473e-01, time/batch = 0.6254s	
3627/11850 (epoch 15.304), train_loss = 1.37918812, grad/param norm = 2.1380e-01, time/batch = 0.6230s	
3628/11850 (epoch 15.308), train_loss = 1.38009630, grad/param norm = 2.0965e-01, time/batch = 0.6237s	
3629/11850 (epoch 15.312), train_loss = 1.23624564, grad/param norm = 2.1534e-01, time/batch = 0.6202s	
3630/11850 (epoch 15.316), train_loss = 1.43627825, grad/param norm = 2.1722e-01, time/batch = 0.6255s	
3631/11850 (epoch 15.321), train_loss = 1.34862194, grad/param norm = 1.9473e-01, time/batch = 0.6253s	
3632/11850 (epoch 15.325), train_loss = 1.40012331, grad/param norm = 2.3077e-01, time/batch = 0.6222s	
3633/11850 (epoch 15.329), train_loss = 1.39481660, grad/param norm = 2.3165e-01, time/batch = 0.6268s	
3634/11850 (epoch 15.333), train_loss = 1.40290142, grad/param norm = 2.3929e-01, time/batch = 0.6582s	
3635/11850 (epoch 15.338), train_loss = 1.32535212, grad/param norm = 2.1432e-01, time/batch = 0.6703s	
3636/11850 (epoch 15.342), train_loss = 1.53635381, grad/param norm = 2.7402e-01, time/batch = 0.6575s	
3637/11850 (epoch 15.346), train_loss = 1.42713950, grad/param norm = 2.2754e-01, time/batch = 0.6396s	
3638/11850 (epoch 15.350), train_loss = 1.27505822, grad/param norm = 2.2305e-01, time/batch = 0.6406s	
3639/11850 (epoch 15.354), train_loss = 1.51068574, grad/param norm = 2.3724e-01, time/batch = 0.6444s	
3640/11850 (epoch 15.359), train_loss = 1.49838607, grad/param norm = 2.5108e-01, time/batch = 0.6370s	
3641/11850 (epoch 15.363), train_loss = 1.45412096, grad/param norm = 2.2296e-01, time/batch = 0.6473s	
3642/11850 (epoch 15.367), train_loss = 1.44572315, grad/param norm = 2.0165e-01, time/batch = 0.6365s	
3643/11850 (epoch 15.371), train_loss = 1.45745324, grad/param norm = 2.2067e-01, time/batch = 0.6609s	
3644/11850 (epoch 15.376), train_loss = 1.38345158, grad/param norm = 2.1341e-01, time/batch = 0.6275s	
3645/11850 (epoch 15.380), train_loss = 1.32853066, grad/param norm = 2.0061e-01, time/batch = 0.6326s	
3646/11850 (epoch 15.384), train_loss = 1.31251642, grad/param norm = 2.2599e-01, time/batch = 0.6221s	
3647/11850 (epoch 15.388), train_loss = 1.51051266, grad/param norm = 2.2600e-01, time/batch = 0.6237s	
3648/11850 (epoch 15.392), train_loss = 1.53480089, grad/param norm = 2.2819e-01, time/batch = 0.6527s	
3649/11850 (epoch 15.397), train_loss = 1.49848098, grad/param norm = 2.6775e-01, time/batch = 0.6257s	
3650/11850 (epoch 15.401), train_loss = 1.25531587, grad/param norm = 1.9578e-01, time/batch = 0.6410s	
3651/11850 (epoch 15.405), train_loss = 1.33911899, grad/param norm = 2.1647e-01, time/batch = 0.6379s	
3652/11850 (epoch 15.409), train_loss = 1.51748144, grad/param norm = 2.2632e-01, time/batch = 0.6295s	
3653/11850 (epoch 15.414), train_loss = 1.27998138, grad/param norm = 2.0974e-01, time/batch = 0.6264s	
3654/11850 (epoch 15.418), train_loss = 1.27507980, grad/param norm = 2.0844e-01, time/batch = 0.6260s	
3655/11850 (epoch 15.422), train_loss = 1.23652183, grad/param norm = 2.0721e-01, time/batch = 0.6265s	
3656/11850 (epoch 15.426), train_loss = 1.28879103, grad/param norm = 2.2274e-01, time/batch = 0.6238s	
3657/11850 (epoch 15.430), train_loss = 1.33843207, grad/param norm = 2.0889e-01, time/batch = 0.6229s	
3658/11850 (epoch 15.435), train_loss = 1.33581634, grad/param norm = 2.0524e-01, time/batch = 0.6244s	
3659/11850 (epoch 15.439), train_loss = 1.50914838, grad/param norm = 2.1796e-01, time/batch = 0.6243s	
3660/11850 (epoch 15.443), train_loss = 1.45675075, grad/param norm = 2.2290e-01, time/batch = 0.6260s	
3661/11850 (epoch 15.447), train_loss = 1.29136342, grad/param norm = 2.0546e-01, time/batch = 0.6275s	
3662/11850 (epoch 15.451), train_loss = 1.28203429, grad/param norm = 2.0985e-01, time/batch = 0.6251s	
3663/11850 (epoch 15.456), train_loss = 1.36084280, grad/param norm = 2.3809e-01, time/batch = 0.6276s	
3664/11850 (epoch 15.460), train_loss = 1.41600716, grad/param norm = 2.2192e-01, time/batch = 0.6277s	
3665/11850 (epoch 15.464), train_loss = 1.32693996, grad/param norm = 2.2117e-01, time/batch = 0.6232s	
3666/11850 (epoch 15.468), train_loss = 1.39743214, grad/param norm = 2.0695e-01, time/batch = 0.6346s	
3667/11850 (epoch 15.473), train_loss = 1.45192464, grad/param norm = 2.5989e-01, time/batch = 0.6250s	
3668/11850 (epoch 15.477), train_loss = 1.28409468, grad/param norm = 2.2312e-01, time/batch = 0.6276s	
3669/11850 (epoch 15.481), train_loss = 1.32155728, grad/param norm = 2.3707e-01, time/batch = 0.6205s	
3670/11850 (epoch 15.485), train_loss = 1.27425365, grad/param norm = 2.0503e-01, time/batch = 0.6220s	
3671/11850 (epoch 15.489), train_loss = 1.43833351, grad/param norm = 2.4077e-01, time/batch = 0.6340s	
3672/11850 (epoch 15.494), train_loss = 1.34905981, grad/param norm = 2.3972e-01, time/batch = 0.6268s	
3673/11850 (epoch 15.498), train_loss = 1.31828469, grad/param norm = 2.3309e-01, time/batch = 0.6248s	
3674/11850 (epoch 15.502), train_loss = 1.24272502, grad/param norm = 2.3157e-01, time/batch = 0.6234s	
3675/11850 (epoch 15.506), train_loss = 1.51524730, grad/param norm = 2.3176e-01, time/batch = 0.6209s	
3676/11850 (epoch 15.511), train_loss = 1.37147716, grad/param norm = 2.0503e-01, time/batch = 0.6213s	
3677/11850 (epoch 15.515), train_loss = 1.48312717, grad/param norm = 2.3183e-01, time/batch = 0.6219s	
3678/11850 (epoch 15.519), train_loss = 1.32579452, grad/param norm = 2.1390e-01, time/batch = 0.6268s	
3679/11850 (epoch 15.523), train_loss = 1.35333058, grad/param norm = 2.1769e-01, time/batch = 0.6255s	
3680/11850 (epoch 15.527), train_loss = 1.25682586, grad/param norm = 2.1525e-01, time/batch = 0.6248s	
3681/11850 (epoch 15.532), train_loss = 1.44392677, grad/param norm = 2.1393e-01, time/batch = 0.6263s	
3682/11850 (epoch 15.536), train_loss = 1.31484953, grad/param norm = 2.0415e-01, time/batch = 0.6316s	
3683/11850 (epoch 15.540), train_loss = 1.27588458, grad/param norm = 2.0299e-01, time/batch = 0.6265s	
3684/11850 (epoch 15.544), train_loss = 1.37016049, grad/param norm = 2.3143e-01, time/batch = 0.6287s	
3685/11850 (epoch 15.549), train_loss = 1.17728437, grad/param norm = 1.9588e-01, time/batch = 0.6260s	
3686/11850 (epoch 15.553), train_loss = 1.41982297, grad/param norm = 2.2144e-01, time/batch = 0.6250s	
3687/11850 (epoch 15.557), train_loss = 1.54248516, grad/param norm = 2.5164e-01, time/batch = 0.6242s	
3688/11850 (epoch 15.561), train_loss = 1.40904815, grad/param norm = 2.4929e-01, time/batch = 0.6287s	
3689/11850 (epoch 15.565), train_loss = 1.55077531, grad/param norm = 2.5612e-01, time/batch = 0.6247s	
3690/11850 (epoch 15.570), train_loss = 1.35612626, grad/param norm = 2.1974e-01, time/batch = 0.6298s	
3691/11850 (epoch 15.574), train_loss = 1.46684242, grad/param norm = 2.3642e-01, time/batch = 0.6267s	
3692/11850 (epoch 15.578), train_loss = 1.53070843, grad/param norm = 2.3685e-01, time/batch = 0.6288s	
3693/11850 (epoch 15.582), train_loss = 1.31939545, grad/param norm = 2.2222e-01, time/batch = 0.6246s	
3694/11850 (epoch 15.586), train_loss = 1.36089665, grad/param norm = 2.3608e-01, time/batch = 0.6281s	
3695/11850 (epoch 15.591), train_loss = 1.48443200, grad/param norm = 2.3452e-01, time/batch = 0.6252s	
3696/11850 (epoch 15.595), train_loss = 1.23241271, grad/param norm = 2.1254e-01, time/batch = 0.6287s	
3697/11850 (epoch 15.599), train_loss = 1.33525049, grad/param norm = 2.3648e-01, time/batch = 0.6409s	
3698/11850 (epoch 15.603), train_loss = 1.31155642, grad/param norm = 2.0701e-01, time/batch = 0.6364s	
3699/11850 (epoch 15.608), train_loss = 1.49408975, grad/param norm = 2.3509e-01, time/batch = 0.6369s	
3700/11850 (epoch 15.612), train_loss = 1.58693507, grad/param norm = 2.4400e-01, time/batch = 0.6305s	
3701/11850 (epoch 15.616), train_loss = 1.50609600, grad/param norm = 2.1898e-01, time/batch = 0.6205s	
3702/11850 (epoch 15.620), train_loss = 1.36249873, grad/param norm = 2.2735e-01, time/batch = 0.6241s	
3703/11850 (epoch 15.624), train_loss = 1.44325558, grad/param norm = 2.6703e-01, time/batch = 0.6211s	
3704/11850 (epoch 15.629), train_loss = 1.32192546, grad/param norm = 2.1703e-01, time/batch = 0.6233s	
3705/11850 (epoch 15.633), train_loss = 1.24618426, grad/param norm = 2.2832e-01, time/batch = 0.6245s	
3706/11850 (epoch 15.637), train_loss = 1.25214553, grad/param norm = 2.3815e-01, time/batch = 0.6213s	
3707/11850 (epoch 15.641), train_loss = 1.26055456, grad/param norm = 2.1264e-01, time/batch = 0.6200s	
3708/11850 (epoch 15.646), train_loss = 1.35462316, grad/param norm = 2.5030e-01, time/batch = 0.6204s	
3709/11850 (epoch 15.650), train_loss = 1.38181721, grad/param norm = 2.3869e-01, time/batch = 0.6292s	
3710/11850 (epoch 15.654), train_loss = 1.36325790, grad/param norm = 2.6807e-01, time/batch = 0.6279s	
3711/11850 (epoch 15.658), train_loss = 1.41673107, grad/param norm = 2.5043e-01, time/batch = 0.6253s	
3712/11850 (epoch 15.662), train_loss = 1.31935943, grad/param norm = 2.9414e-01, time/batch = 0.6213s	
3713/11850 (epoch 15.667), train_loss = 1.46731238, grad/param norm = 2.5722e-01, time/batch = 0.6221s	
3714/11850 (epoch 15.671), train_loss = 1.33055176, grad/param norm = 2.1109e-01, time/batch = 0.6244s	
3715/11850 (epoch 15.675), train_loss = 1.35167949, grad/param norm = 2.0709e-01, time/batch = 0.6199s	
3716/11850 (epoch 15.679), train_loss = 1.41152780, grad/param norm = 2.4434e-01, time/batch = 0.6249s	
3717/11850 (epoch 15.684), train_loss = 1.40695190, grad/param norm = 2.4953e-01, time/batch = 0.6223s	
3718/11850 (epoch 15.688), train_loss = 1.29081139, grad/param norm = 1.9267e-01, time/batch = 0.6230s	
3719/11850 (epoch 15.692), train_loss = 1.38133159, grad/param norm = 2.5408e-01, time/batch = 0.6236s	
3720/11850 (epoch 15.696), train_loss = 1.28778350, grad/param norm = 2.4480e-01, time/batch = 0.6236s	
3721/11850 (epoch 15.700), train_loss = 1.36959649, grad/param norm = 2.1283e-01, time/batch = 0.6245s	
3722/11850 (epoch 15.705), train_loss = 1.34196802, grad/param norm = 2.1920e-01, time/batch = 0.6233s	
3723/11850 (epoch 15.709), train_loss = 1.25325447, grad/param norm = 2.2836e-01, time/batch = 0.6212s	
3724/11850 (epoch 15.713), train_loss = 1.32319020, grad/param norm = 2.4729e-01, time/batch = 0.6210s	
3725/11850 (epoch 15.717), train_loss = 1.27996746, grad/param norm = 2.3000e-01, time/batch = 0.6242s	
3726/11850 (epoch 15.722), train_loss = 1.40845055, grad/param norm = 2.6131e-01, time/batch = 0.6251s	
3727/11850 (epoch 15.726), train_loss = 1.25970254, grad/param norm = 2.4389e-01, time/batch = 0.6257s	
3728/11850 (epoch 15.730), train_loss = 1.21935777, grad/param norm = 2.1143e-01, time/batch = 0.6306s	
3729/11850 (epoch 15.734), train_loss = 1.28933351, grad/param norm = 2.1614e-01, time/batch = 0.6433s	
3730/11850 (epoch 15.738), train_loss = 1.49476668, grad/param norm = 2.4756e-01, time/batch = 0.6623s	
3731/11850 (epoch 15.743), train_loss = 1.41847166, grad/param norm = 2.3682e-01, time/batch = 0.6563s	
3732/11850 (epoch 15.747), train_loss = 1.21502052, grad/param norm = 2.0764e-01, time/batch = 0.6444s	
3733/11850 (epoch 15.751), train_loss = 1.23812663, grad/param norm = 2.0729e-01, time/batch = 0.6430s	
3734/11850 (epoch 15.755), train_loss = 1.37440345, grad/param norm = 2.2839e-01, time/batch = 0.6333s	
3735/11850 (epoch 15.759), train_loss = 1.28487870, grad/param norm = 2.2155e-01, time/batch = 0.6259s	
3736/11850 (epoch 15.764), train_loss = 1.34298317, grad/param norm = 2.2529e-01, time/batch = 0.6327s	
3737/11850 (epoch 15.768), train_loss = 1.21371049, grad/param norm = 2.1548e-01, time/batch = 0.6252s	
3738/11850 (epoch 15.772), train_loss = 1.34864384, grad/param norm = 2.2488e-01, time/batch = 0.6250s	
3739/11850 (epoch 15.776), train_loss = 1.35858320, grad/param norm = 2.1601e-01, time/batch = 0.6255s	
3740/11850 (epoch 15.781), train_loss = 1.30702853, grad/param norm = 2.2295e-01, time/batch = 0.6261s	
3741/11850 (epoch 15.785), train_loss = 1.29665768, grad/param norm = 2.1642e-01, time/batch = 0.6309s	
3742/11850 (epoch 15.789), train_loss = 1.41098460, grad/param norm = 2.4087e-01, time/batch = 0.6267s	
3743/11850 (epoch 15.793), train_loss = 1.48288251, grad/param norm = 2.4069e-01, time/batch = 0.6255s	
3744/11850 (epoch 15.797), train_loss = 1.40154296, grad/param norm = 2.3005e-01, time/batch = 0.6262s	
3745/11850 (epoch 15.802), train_loss = 1.26998428, grad/param norm = 2.1381e-01, time/batch = 0.6257s	
3746/11850 (epoch 15.806), train_loss = 1.35210190, grad/param norm = 2.0370e-01, time/batch = 0.6275s	
3747/11850 (epoch 15.810), train_loss = 1.56305578, grad/param norm = 3.0872e-01, time/batch = 0.6313s	
3748/11850 (epoch 15.814), train_loss = 1.34484937, grad/param norm = 2.1127e-01, time/batch = 0.6404s	
3749/11850 (epoch 15.819), train_loss = 1.50092099, grad/param norm = 2.3073e-01, time/batch = 0.6403s	
3750/11850 (epoch 15.823), train_loss = 1.52664863, grad/param norm = 2.5030e-01, time/batch = 0.6282s	
3751/11850 (epoch 15.827), train_loss = 1.40245558, grad/param norm = 2.4917e-01, time/batch = 0.6204s	
3752/11850 (epoch 15.831), train_loss = 1.36938014, grad/param norm = 2.3679e-01, time/batch = 0.6216s	
3753/11850 (epoch 15.835), train_loss = 1.36065714, grad/param norm = 2.1777e-01, time/batch = 0.6253s	
3754/11850 (epoch 15.840), train_loss = 1.31032176, grad/param norm = 2.1715e-01, time/batch = 0.6228s	
3755/11850 (epoch 15.844), train_loss = 1.33686115, grad/param norm = 2.0473e-01, time/batch = 0.6246s	
3756/11850 (epoch 15.848), train_loss = 1.41972328, grad/param norm = 2.2744e-01, time/batch = 0.6225s	
3757/11850 (epoch 15.852), train_loss = 1.34891384, grad/param norm = 2.2428e-01, time/batch = 0.6242s	
3758/11850 (epoch 15.857), train_loss = 1.35950786, grad/param norm = 2.3241e-01, time/batch = 0.6280s	
3759/11850 (epoch 15.861), train_loss = 1.39810460, grad/param norm = 2.3100e-01, time/batch = 0.6318s	
3760/11850 (epoch 15.865), train_loss = 1.44832843, grad/param norm = 2.5544e-01, time/batch = 0.6228s	
3761/11850 (epoch 15.869), train_loss = 1.43263576, grad/param norm = 2.2137e-01, time/batch = 0.6210s	
3762/11850 (epoch 15.873), train_loss = 1.43767324, grad/param norm = 2.3696e-01, time/batch = 0.6321s	
3763/11850 (epoch 15.878), train_loss = 1.42740962, grad/param norm = 2.4076e-01, time/batch = 0.6282s	
3764/11850 (epoch 15.882), train_loss = 1.40588813, grad/param norm = 2.2716e-01, time/batch = 0.6235s	
3765/11850 (epoch 15.886), train_loss = 1.46370358, grad/param norm = 2.4226e-01, time/batch = 0.6241s	
3766/11850 (epoch 15.890), train_loss = 1.43635366, grad/param norm = 2.5255e-01, time/batch = 0.6433s	
3767/11850 (epoch 15.895), train_loss = 1.42545617, grad/param norm = 2.6253e-01, time/batch = 0.6425s	
3768/11850 (epoch 15.899), train_loss = 1.28937879, grad/param norm = 2.5677e-01, time/batch = 0.6389s	
3769/11850 (epoch 15.903), train_loss = 1.35216218, grad/param norm = 2.2217e-01, time/batch = 0.6378s	
3770/11850 (epoch 15.907), train_loss = 1.31783930, grad/param norm = 2.5290e-01, time/batch = 0.6398s	
3771/11850 (epoch 15.911), train_loss = 1.43684011, grad/param norm = 2.3159e-01, time/batch = 0.6401s	
3772/11850 (epoch 15.916), train_loss = 1.49707062, grad/param norm = 2.5166e-01, time/batch = 0.6397s	
3773/11850 (epoch 15.920), train_loss = 1.35262647, grad/param norm = 2.3680e-01, time/batch = 0.6723s	
3774/11850 (epoch 15.924), train_loss = 1.38548050, grad/param norm = 2.3646e-01, time/batch = 0.6556s	
3775/11850 (epoch 15.928), train_loss = 1.48697120, grad/param norm = 2.3585e-01, time/batch = 0.6489s	
3776/11850 (epoch 15.932), train_loss = 1.50003934, grad/param norm = 2.3179e-01, time/batch = 0.6635s	
3777/11850 (epoch 15.937), train_loss = 1.44480830, grad/param norm = 2.3262e-01, time/batch = 0.6687s	
3778/11850 (epoch 15.941), train_loss = 1.45511320, grad/param norm = 2.4342e-01, time/batch = 0.6624s	
3779/11850 (epoch 15.945), train_loss = 1.45500098, grad/param norm = 2.2590e-01, time/batch = 0.6564s	
3780/11850 (epoch 15.949), train_loss = 1.31991229, grad/param norm = 2.5252e-01, time/batch = 0.6350s	
3781/11850 (epoch 15.954), train_loss = 1.44939195, grad/param norm = 2.3032e-01, time/batch = 0.6422s	
3782/11850 (epoch 15.958), train_loss = 1.42655788, grad/param norm = 2.6857e-01, time/batch = 0.6390s	
3783/11850 (epoch 15.962), train_loss = 1.27858326, grad/param norm = 2.4051e-01, time/batch = 0.6457s	
3784/11850 (epoch 15.966), train_loss = 1.26192489, grad/param norm = 2.2227e-01, time/batch = 0.6419s	
3785/11850 (epoch 15.970), train_loss = 1.37907936, grad/param norm = 2.2294e-01, time/batch = 0.6584s	
3786/11850 (epoch 15.975), train_loss = 1.38318441, grad/param norm = 2.3051e-01, time/batch = 0.6570s	
3787/11850 (epoch 15.979), train_loss = 1.38966002, grad/param norm = 2.2892e-01, time/batch = 0.6667s	
3788/11850 (epoch 15.983), train_loss = 1.58084740, grad/param norm = 3.2537e-01, time/batch = 0.6656s	
3789/11850 (epoch 15.987), train_loss = 1.38630657, grad/param norm = 2.4643e-01, time/batch = 0.6641s	
3790/11850 (epoch 15.992), train_loss = 1.53608954, grad/param norm = 2.1530e-01, time/batch = 0.6500s	
3791/11850 (epoch 15.996), train_loss = 1.62615475, grad/param norm = 2.5854e-01, time/batch = 0.6504s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
3792/11850 (epoch 16.000), train_loss = 1.35699247, grad/param norm = 2.3437e-01, time/batch = 0.6494s	
3793/11850 (epoch 16.004), train_loss = 1.48715974, grad/param norm = 2.7809e-01, time/batch = 0.6536s	
3794/11850 (epoch 16.008), train_loss = 1.46715614, grad/param norm = 2.2501e-01, time/batch = 0.6658s	
3795/11850 (epoch 16.013), train_loss = 1.44828878, grad/param norm = 2.4372e-01, time/batch = 0.6660s	
3796/11850 (epoch 16.017), train_loss = 1.60958614, grad/param norm = 2.3331e-01, time/batch = 0.6684s	
3797/11850 (epoch 16.021), train_loss = 1.35951638, grad/param norm = 2.0165e-01, time/batch = 0.6568s	
3798/11850 (epoch 16.025), train_loss = 1.23781082, grad/param norm = 2.0204e-01, time/batch = 0.6568s	
3799/11850 (epoch 16.030), train_loss = 1.27657436, grad/param norm = 2.1154e-01, time/batch = 0.6559s	
3800/11850 (epoch 16.034), train_loss = 1.31162242, grad/param norm = 2.2296e-01, time/batch = 0.6567s	
3801/11850 (epoch 16.038), train_loss = 1.38857723, grad/param norm = 2.1464e-01, time/batch = 0.6516s	
3802/11850 (epoch 16.042), train_loss = 1.40195104, grad/param norm = 2.4474e-01, time/batch = 0.6455s	
3803/11850 (epoch 16.046), train_loss = 1.44941475, grad/param norm = 2.4984e-01, time/batch = 0.6470s	
3804/11850 (epoch 16.051), train_loss = 1.38867375, grad/param norm = 2.2160e-01, time/batch = 0.6381s	
3805/11850 (epoch 16.055), train_loss = 1.35556087, grad/param norm = 2.1438e-01, time/batch = 0.6383s	
3806/11850 (epoch 16.059), train_loss = 1.45302676, grad/param norm = 2.3629e-01, time/batch = 0.6383s	
3807/11850 (epoch 16.063), train_loss = 1.40517808, grad/param norm = 2.0959e-01, time/batch = 0.6370s	
3808/11850 (epoch 16.068), train_loss = 1.37527869, grad/param norm = 2.1048e-01, time/batch = 0.6392s	
3809/11850 (epoch 16.072), train_loss = 1.38982639, grad/param norm = 2.0461e-01, time/batch = 0.6412s	
3810/11850 (epoch 16.076), train_loss = 1.51752902, grad/param norm = 2.1355e-01, time/batch = 0.6372s	
3811/11850 (epoch 16.080), train_loss = 1.32329774, grad/param norm = 2.1678e-01, time/batch = 0.6396s	
3812/11850 (epoch 16.084), train_loss = 1.22890601, grad/param norm = 2.1719e-01, time/batch = 0.6363s	
3813/11850 (epoch 16.089), train_loss = 1.25478128, grad/param norm = 1.9850e-01, time/batch = 0.6336s	
3814/11850 (epoch 16.093), train_loss = 1.22902744, grad/param norm = 2.2747e-01, time/batch = 0.6353s	
3815/11850 (epoch 16.097), train_loss = 1.43974019, grad/param norm = 2.3296e-01, time/batch = 0.6372s	
3816/11850 (epoch 16.101), train_loss = 1.37642606, grad/param norm = 2.4340e-01, time/batch = 0.6355s	
3817/11850 (epoch 16.105), train_loss = 1.28589745, grad/param norm = 2.2526e-01, time/batch = 0.6364s	
3818/11850 (epoch 16.110), train_loss = 1.42590328, grad/param norm = 2.3124e-01, time/batch = 0.6353s	
3819/11850 (epoch 16.114), train_loss = 1.40814137, grad/param norm = 2.3360e-01, time/batch = 0.6369s	
3820/11850 (epoch 16.118), train_loss = 1.34171311, grad/param norm = 2.0336e-01, time/batch = 0.6374s	
3821/11850 (epoch 16.122), train_loss = 1.47942122, grad/param norm = 2.3445e-01, time/batch = 0.6459s	
3822/11850 (epoch 16.127), train_loss = 1.41992314, grad/param norm = 2.4099e-01, time/batch = 0.6582s	
3823/11850 (epoch 16.131), train_loss = 1.41244623, grad/param norm = 2.6339e-01, time/batch = 0.6885s	
3824/11850 (epoch 16.135), train_loss = 1.35502411, grad/param norm = 2.5040e-01, time/batch = 0.6706s	
3825/11850 (epoch 16.139), train_loss = 1.34772574, grad/param norm = 2.3003e-01, time/batch = 0.6622s	
3826/11850 (epoch 16.143), train_loss = 1.35328841, grad/param norm = 2.2663e-01, time/batch = 0.6572s	
3827/11850 (epoch 16.148), train_loss = 1.38015316, grad/param norm = 2.3471e-01, time/batch = 0.6614s	
3828/11850 (epoch 16.152), train_loss = 1.48357443, grad/param norm = 2.5799e-01, time/batch = 0.6603s	
3829/11850 (epoch 16.156), train_loss = 1.43216370, grad/param norm = 2.3085e-01, time/batch = 0.6616s	
3830/11850 (epoch 16.160), train_loss = 1.67087093, grad/param norm = 2.7399e-01, time/batch = 0.6832s	
3831/11850 (epoch 16.165), train_loss = 1.51994846, grad/param norm = 2.4867e-01, time/batch = 0.6634s	
3832/11850 (epoch 16.169), train_loss = 1.37562971, grad/param norm = 2.4008e-01, time/batch = 0.6388s	
3833/11850 (epoch 16.173), train_loss = 1.45378846, grad/param norm = 2.2149e-01, time/batch = 0.6347s	
3834/11850 (epoch 16.177), train_loss = 1.37102711, grad/param norm = 2.6187e-01, time/batch = 0.6455s	
3835/11850 (epoch 16.181), train_loss = 1.47523597, grad/param norm = 2.3710e-01, time/batch = 0.6381s	
3836/11850 (epoch 16.186), train_loss = 1.54168871, grad/param norm = 2.6710e-01, time/batch = 0.6391s	
3837/11850 (epoch 16.190), train_loss = 1.42699419, grad/param norm = 2.1939e-01, time/batch = 0.6384s	
3838/11850 (epoch 16.194), train_loss = 1.53621833, grad/param norm = 2.4632e-01, time/batch = 0.6389s	
3839/11850 (epoch 16.198), train_loss = 1.30097171, grad/param norm = 2.3859e-01, time/batch = 0.6389s	
3840/11850 (epoch 16.203), train_loss = 1.26027613, grad/param norm = 1.9952e-01, time/batch = 0.6404s	
3841/11850 (epoch 16.207), train_loss = 1.44488326, grad/param norm = 2.2927e-01, time/batch = 0.6383s	
3842/11850 (epoch 16.211), train_loss = 1.38466310, grad/param norm = 2.1482e-01, time/batch = 0.6382s	
3843/11850 (epoch 16.215), train_loss = 1.39474768, grad/param norm = 2.3195e-01, time/batch = 0.6388s	
3844/11850 (epoch 16.219), train_loss = 1.35175253, grad/param norm = 2.1999e-01, time/batch = 0.6392s	
3845/11850 (epoch 16.224), train_loss = 1.58700440, grad/param norm = 2.5159e-01, time/batch = 0.6411s	
3846/11850 (epoch 16.228), train_loss = 1.49828140, grad/param norm = 2.4112e-01, time/batch = 0.6393s	
3847/11850 (epoch 16.232), train_loss = 1.46057307, grad/param norm = 2.2874e-01, time/batch = 0.6410s	
3848/11850 (epoch 16.236), train_loss = 1.32219847, grad/param norm = 2.4213e-01, time/batch = 0.6517s	
3849/11850 (epoch 16.241), train_loss = 1.57992575, grad/param norm = 2.4656e-01, time/batch = 0.6345s	
3850/11850 (epoch 16.245), train_loss = 1.48547171, grad/param norm = 2.3686e-01, time/batch = 0.6394s	
3851/11850 (epoch 16.249), train_loss = 1.31173178, grad/param norm = 2.1154e-01, time/batch = 0.6398s	
3852/11850 (epoch 16.253), train_loss = 1.42276804, grad/param norm = 2.5201e-01, time/batch = 0.6404s	
3853/11850 (epoch 16.257), train_loss = 1.52299726, grad/param norm = 2.3267e-01, time/batch = 0.6398s	
3854/11850 (epoch 16.262), train_loss = 1.58932034, grad/param norm = 2.6262e-01, time/batch = 0.6400s	
3855/11850 (epoch 16.266), train_loss = 1.46877655, grad/param norm = 2.4082e-01, time/batch = 0.6376s	
3856/11850 (epoch 16.270), train_loss = 1.33920037, grad/param norm = 2.1345e-01, time/batch = 0.6369s	
3857/11850 (epoch 16.274), train_loss = 1.34485414, grad/param norm = 2.3091e-01, time/batch = 0.6383s	
3858/11850 (epoch 16.278), train_loss = 1.24157738, grad/param norm = 2.3780e-01, time/batch = 0.6412s	
3859/11850 (epoch 16.283), train_loss = 1.32892172, grad/param norm = 2.1551e-01, time/batch = 0.6471s	
3860/11850 (epoch 16.287), train_loss = 1.48795259, grad/param norm = 2.3260e-01, time/batch = 0.6562s	
3861/11850 (epoch 16.291), train_loss = 1.42324910, grad/param norm = 2.2167e-01, time/batch = 0.6462s	
3862/11850 (epoch 16.295), train_loss = 1.41183929, grad/param norm = 2.2169e-01, time/batch = 0.6539s	
3863/11850 (epoch 16.300), train_loss = 1.36386837, grad/param norm = 2.5008e-01, time/batch = 0.6561s	
3864/11850 (epoch 16.304), train_loss = 1.34808899, grad/param norm = 2.1228e-01, time/batch = 0.6404s	
3865/11850 (epoch 16.308), train_loss = 1.34752054, grad/param norm = 2.1253e-01, time/batch = 0.6429s	
3866/11850 (epoch 16.312), train_loss = 1.19799056, grad/param norm = 1.9757e-01, time/batch = 0.6437s	
3867/11850 (epoch 16.316), train_loss = 1.41289572, grad/param norm = 2.1690e-01, time/batch = 0.6418s	
3868/11850 (epoch 16.321), train_loss = 1.31905580, grad/param norm = 1.9902e-01, time/batch = 0.6382s	
3869/11850 (epoch 16.325), train_loss = 1.36455261, grad/param norm = 2.3187e-01, time/batch = 0.6443s	
3870/11850 (epoch 16.329), train_loss = 1.35539425, grad/param norm = 2.3758e-01, time/batch = 0.6474s	
3871/11850 (epoch 16.333), train_loss = 1.36872798, grad/param norm = 2.4776e-01, time/batch = 0.6433s	
3872/11850 (epoch 16.338), train_loss = 1.28799573, grad/param norm = 2.0901e-01, time/batch = 0.6384s	
3873/11850 (epoch 16.342), train_loss = 1.47667311, grad/param norm = 2.5882e-01, time/batch = 0.6390s	
3874/11850 (epoch 16.346), train_loss = 1.38758987, grad/param norm = 2.2513e-01, time/batch = 0.6379s	
3875/11850 (epoch 16.350), train_loss = 1.24292877, grad/param norm = 2.3072e-01, time/batch = 0.6393s	
3876/11850 (epoch 16.354), train_loss = 1.46263705, grad/param norm = 2.3867e-01, time/batch = 0.6442s	
3877/11850 (epoch 16.359), train_loss = 1.46163576, grad/param norm = 2.3894e-01, time/batch = 0.6413s	
3878/11850 (epoch 16.363), train_loss = 1.42416048, grad/param norm = 2.2199e-01, time/batch = 0.6399s	
3879/11850 (epoch 16.367), train_loss = 1.41571649, grad/param norm = 2.0666e-01, time/batch = 0.6394s	
3880/11850 (epoch 16.371), train_loss = 1.41881399, grad/param norm = 2.1304e-01, time/batch = 0.6459s	
3881/11850 (epoch 16.376), train_loss = 1.35348155, grad/param norm = 2.2211e-01, time/batch = 0.6475s	
3882/11850 (epoch 16.380), train_loss = 1.29682539, grad/param norm = 2.0524e-01, time/batch = 0.6424s	
3883/11850 (epoch 16.384), train_loss = 1.28178562, grad/param norm = 2.4107e-01, time/batch = 0.6408s	
3884/11850 (epoch 16.388), train_loss = 1.47554900, grad/param norm = 2.3638e-01, time/batch = 0.6459s	
3885/11850 (epoch 16.392), train_loss = 1.50173039, grad/param norm = 2.4487e-01, time/batch = 0.6381s	
3886/11850 (epoch 16.397), train_loss = 1.46315335, grad/param norm = 2.6884e-01, time/batch = 0.6388s	
3887/11850 (epoch 16.401), train_loss = 1.22742111, grad/param norm = 1.9540e-01, time/batch = 0.6372s	
3888/11850 (epoch 16.405), train_loss = 1.30390409, grad/param norm = 2.1657e-01, time/batch = 0.6378s	
3889/11850 (epoch 16.409), train_loss = 1.47536888, grad/param norm = 2.1955e-01, time/batch = 0.6431s	
3890/11850 (epoch 16.414), train_loss = 1.25436400, grad/param norm = 2.2000e-01, time/batch = 0.6455s	
3891/11850 (epoch 16.418), train_loss = 1.24527803, grad/param norm = 2.1600e-01, time/batch = 0.6442s	
3892/11850 (epoch 16.422), train_loss = 1.20962957, grad/param norm = 2.0824e-01, time/batch = 0.6392s	
3893/11850 (epoch 16.426), train_loss = 1.25093713, grad/param norm = 2.3160e-01, time/batch = 0.6390s	
3894/11850 (epoch 16.430), train_loss = 1.31398529, grad/param norm = 2.3354e-01, time/batch = 0.6417s	
3895/11850 (epoch 16.435), train_loss = 1.29897110, grad/param norm = 2.1256e-01, time/batch = 0.6374s	
3896/11850 (epoch 16.439), train_loss = 1.48055033, grad/param norm = 2.2598e-01, time/batch = 0.6436s	
3897/11850 (epoch 16.443), train_loss = 1.42081654, grad/param norm = 2.2222e-01, time/batch = 0.6468s	
3898/11850 (epoch 16.447), train_loss = 1.26177690, grad/param norm = 2.2308e-01, time/batch = 0.6485s	
3899/11850 (epoch 16.451), train_loss = 1.25246619, grad/param norm = 2.2962e-01, time/batch = 0.6362s	
3900/11850 (epoch 16.456), train_loss = 1.33356945, grad/param norm = 2.5383e-01, time/batch = 0.6349s	
3901/11850 (epoch 16.460), train_loss = 1.37784767, grad/param norm = 2.2170e-01, time/batch = 0.6374s	
3902/11850 (epoch 16.464), train_loss = 1.29188430, grad/param norm = 2.3228e-01, time/batch = 0.6393s	
3903/11850 (epoch 16.468), train_loss = 1.36798139, grad/param norm = 2.1568e-01, time/batch = 0.6504s	
3904/11850 (epoch 16.473), train_loss = 1.41223148, grad/param norm = 2.5295e-01, time/batch = 0.6449s	
3905/11850 (epoch 16.477), train_loss = 1.25484748, grad/param norm = 2.2668e-01, time/batch = 0.6412s	
3906/11850 (epoch 16.481), train_loss = 1.29238223, grad/param norm = 2.4983e-01, time/batch = 0.6377s	
3907/11850 (epoch 16.485), train_loss = 1.24463201, grad/param norm = 2.1259e-01, time/batch = 0.6369s	
3908/11850 (epoch 16.489), train_loss = 1.40643753, grad/param norm = 2.4166e-01, time/batch = 0.6373s	
3909/11850 (epoch 16.494), train_loss = 1.30828095, grad/param norm = 2.4388e-01, time/batch = 0.6367s	
3910/11850 (epoch 16.498), train_loss = 1.28315282, grad/param norm = 2.2870e-01, time/batch = 0.6364s	
3911/11850 (epoch 16.502), train_loss = 1.21655065, grad/param norm = 2.4437e-01, time/batch = 0.6387s	
3912/11850 (epoch 16.506), train_loss = 1.47510552, grad/param norm = 2.2390e-01, time/batch = 0.6389s	
3913/11850 (epoch 16.511), train_loss = 1.34896621, grad/param norm = 2.1649e-01, time/batch = 0.6495s	
3914/11850 (epoch 16.515), train_loss = 1.45428361, grad/param norm = 2.1883e-01, time/batch = 0.6652s	
3915/11850 (epoch 16.519), train_loss = 1.28964570, grad/param norm = 2.1166e-01, time/batch = 0.6710s	
3916/11850 (epoch 16.523), train_loss = 1.31650046, grad/param norm = 2.1809e-01, time/batch = 0.6771s	
3917/11850 (epoch 16.527), train_loss = 1.22725268, grad/param norm = 2.1764e-01, time/batch = 0.6714s	
3918/11850 (epoch 16.532), train_loss = 1.41041493, grad/param norm = 2.2324e-01, time/batch = 0.6693s	
3919/11850 (epoch 16.536), train_loss = 1.28049224, grad/param norm = 2.1235e-01, time/batch = 0.6687s	
3920/11850 (epoch 16.540), train_loss = 1.24475644, grad/param norm = 2.0676e-01, time/batch = 0.6708s	
3921/11850 (epoch 16.544), train_loss = 1.32518758, grad/param norm = 2.2483e-01, time/batch = 0.6731s	
3922/11850 (epoch 16.549), train_loss = 1.14395478, grad/param norm = 1.9524e-01, time/batch = 0.6734s	
3923/11850 (epoch 16.553), train_loss = 1.38647791, grad/param norm = 2.2836e-01, time/batch = 0.6733s	
3924/11850 (epoch 16.557), train_loss = 1.49494223, grad/param norm = 2.4210e-01, time/batch = 0.6727s	
3925/11850 (epoch 16.561), train_loss = 1.37360961, grad/param norm = 2.3804e-01, time/batch = 0.6601s	
3926/11850 (epoch 16.565), train_loss = 1.51103346, grad/param norm = 2.5084e-01, time/batch = 0.6371s	
3927/11850 (epoch 16.570), train_loss = 1.33078234, grad/param norm = 2.2792e-01, time/batch = 0.6367s	
3928/11850 (epoch 16.574), train_loss = 1.43936957, grad/param norm = 2.3818e-01, time/batch = 0.6378s	
3929/11850 (epoch 16.578), train_loss = 1.49144904, grad/param norm = 2.3859e-01, time/batch = 0.6535s	
3930/11850 (epoch 16.582), train_loss = 1.28548018, grad/param norm = 2.3140e-01, time/batch = 0.6645s	
3931/11850 (epoch 16.586), train_loss = 1.31592072, grad/param norm = 2.1778e-01, time/batch = 0.6679s	
3932/11850 (epoch 16.591), train_loss = 1.45408430, grad/param norm = 2.3875e-01, time/batch = 0.6630s	
3933/11850 (epoch 16.595), train_loss = 1.20405226, grad/param norm = 2.1801e-01, time/batch = 0.6623s	
3934/11850 (epoch 16.599), train_loss = 1.31663372, grad/param norm = 2.4020e-01, time/batch = 0.6625s	
3935/11850 (epoch 16.603), train_loss = 1.27393327, grad/param norm = 2.1016e-01, time/batch = 0.6637s	
3936/11850 (epoch 16.608), train_loss = 1.46617082, grad/param norm = 2.3014e-01, time/batch = 0.6489s	
3937/11850 (epoch 16.612), train_loss = 1.55369731, grad/param norm = 2.5589e-01, time/batch = 0.6368s	
3938/11850 (epoch 16.616), train_loss = 1.47466362, grad/param norm = 2.2611e-01, time/batch = 0.6373s	
3939/11850 (epoch 16.620), train_loss = 1.33150124, grad/param norm = 2.2240e-01, time/batch = 0.6355s	
3940/11850 (epoch 16.624), train_loss = 1.39906161, grad/param norm = 2.4846e-01, time/batch = 0.6357s	
3941/11850 (epoch 16.629), train_loss = 1.28582856, grad/param norm = 2.2561e-01, time/batch = 0.6405s	
3942/11850 (epoch 16.633), train_loss = 1.20765437, grad/param norm = 2.3076e-01, time/batch = 0.6383s	
3943/11850 (epoch 16.637), train_loss = 1.21701366, grad/param norm = 2.2996e-01, time/batch = 0.6464s	
3944/11850 (epoch 16.641), train_loss = 1.23209239, grad/param norm = 2.1471e-01, time/batch = 0.6449s	
3945/11850 (epoch 16.646), train_loss = 1.31218438, grad/param norm = 2.3045e-01, time/batch = 0.6372s	
3946/11850 (epoch 16.650), train_loss = 1.34794955, grad/param norm = 2.4423e-01, time/batch = 0.6391s	
3947/11850 (epoch 16.654), train_loss = 1.32792563, grad/param norm = 3.1146e-01, time/batch = 0.6383s	
3948/11850 (epoch 16.658), train_loss = 1.37526412, grad/param norm = 2.3277e-01, time/batch = 0.6446s	
3949/11850 (epoch 16.662), train_loss = 1.28367316, grad/param norm = 2.7178e-01, time/batch = 0.6377s	
3950/11850 (epoch 16.667), train_loss = 1.43250297, grad/param norm = 2.3659e-01, time/batch = 0.6441s	
3951/11850 (epoch 16.671), train_loss = 1.29488862, grad/param norm = 2.0546e-01, time/batch = 0.6388s	
3952/11850 (epoch 16.675), train_loss = 1.31865837, grad/param norm = 2.0599e-01, time/batch = 0.6422s	
3953/11850 (epoch 16.679), train_loss = 1.37654527, grad/param norm = 2.3371e-01, time/batch = 0.6383s	
3954/11850 (epoch 16.684), train_loss = 1.36955142, grad/param norm = 2.4667e-01, time/batch = 0.6392s	
3955/11850 (epoch 16.688), train_loss = 1.27007311, grad/param norm = 2.0217e-01, time/batch = 0.6384s	
3956/11850 (epoch 16.692), train_loss = 1.34798331, grad/param norm = 2.5662e-01, time/batch = 0.6380s	
3957/11850 (epoch 16.696), train_loss = 1.24965365, grad/param norm = 2.4749e-01, time/batch = 0.6410s	
3958/11850 (epoch 16.700), train_loss = 1.33662788, grad/param norm = 2.1344e-01, time/batch = 0.6397s	
3959/11850 (epoch 16.705), train_loss = 1.31048256, grad/param norm = 2.1490e-01, time/batch = 0.6399s	
3960/11850 (epoch 16.709), train_loss = 1.21952138, grad/param norm = 2.1745e-01, time/batch = 0.6391s	
3961/11850 (epoch 16.713), train_loss = 1.28523140, grad/param norm = 2.5126e-01, time/batch = 0.6378s	
3962/11850 (epoch 16.717), train_loss = 1.25960511, grad/param norm = 2.3730e-01, time/batch = 0.6424s	
3963/11850 (epoch 16.722), train_loss = 1.37013945, grad/param norm = 2.6247e-01, time/batch = 0.6452s	
3964/11850 (epoch 16.726), train_loss = 1.22565186, grad/param norm = 2.4641e-01, time/batch = 0.6349s	
3965/11850 (epoch 16.730), train_loss = 1.19063028, grad/param norm = 2.1190e-01, time/batch = 0.6385s	
3966/11850 (epoch 16.734), train_loss = 1.26000683, grad/param norm = 2.1372e-01, time/batch = 0.6420s	
3967/11850 (epoch 16.738), train_loss = 1.44827607, grad/param norm = 2.5214e-01, time/batch = 0.6406s	
3968/11850 (epoch 16.743), train_loss = 1.37910271, grad/param norm = 2.4239e-01, time/batch = 0.6438s	
3969/11850 (epoch 16.747), train_loss = 1.18848279, grad/param norm = 2.1093e-01, time/batch = 0.6445s	
3970/11850 (epoch 16.751), train_loss = 1.20353691, grad/param norm = 2.0707e-01, time/batch = 0.6414s	
3971/11850 (epoch 16.755), train_loss = 1.34016417, grad/param norm = 2.2612e-01, time/batch = 0.6563s	
3972/11850 (epoch 16.759), train_loss = 1.25155624, grad/param norm = 2.2016e-01, time/batch = 0.6643s	
3973/11850 (epoch 16.764), train_loss = 1.31258010, grad/param norm = 2.2629e-01, time/batch = 0.6406s	
3974/11850 (epoch 16.768), train_loss = 1.18365370, grad/param norm = 2.2045e-01, time/batch = 0.6431s	
3975/11850 (epoch 16.772), train_loss = 1.30732260, grad/param norm = 2.1760e-01, time/batch = 0.6391s	
3976/11850 (epoch 16.776), train_loss = 1.32716210, grad/param norm = 2.1437e-01, time/batch = 0.6403s	
3977/11850 (epoch 16.781), train_loss = 1.28066870, grad/param norm = 2.2158e-01, time/batch = 0.6377s	
3978/11850 (epoch 16.785), train_loss = 1.26121597, grad/param norm = 2.1658e-01, time/batch = 0.6386s	
3979/11850 (epoch 16.789), train_loss = 1.37121222, grad/param norm = 2.2994e-01, time/batch = 0.6428s	
3980/11850 (epoch 16.793), train_loss = 1.45321351, grad/param norm = 2.6072e-01, time/batch = 0.6371s	
3981/11850 (epoch 16.797), train_loss = 1.36411945, grad/param norm = 2.3709e-01, time/batch = 0.6421s	
3982/11850 (epoch 16.802), train_loss = 1.23307177, grad/param norm = 2.1749e-01, time/batch = 0.6409s	
3983/11850 (epoch 16.806), train_loss = 1.31969567, grad/param norm = 2.1548e-01, time/batch = 0.6403s	
3984/11850 (epoch 16.810), train_loss = 1.51090334, grad/param norm = 3.0718e-01, time/batch = 0.6374s	
3985/11850 (epoch 16.814), train_loss = 1.31100961, grad/param norm = 2.3841e-01, time/batch = 0.6399s	
3986/11850 (epoch 16.819), train_loss = 1.47106479, grad/param norm = 2.5053e-01, time/batch = 0.6376s	
3987/11850 (epoch 16.823), train_loss = 1.48436228, grad/param norm = 2.3866e-01, time/batch = 0.6423s	
3988/11850 (epoch 16.827), train_loss = 1.37439985, grad/param norm = 2.3798e-01, time/batch = 0.6420s	
3989/11850 (epoch 16.831), train_loss = 1.35222341, grad/param norm = 2.4044e-01, time/batch = 0.6470s	
3990/11850 (epoch 16.835), train_loss = 1.32442681, grad/param norm = 2.1697e-01, time/batch = 0.6453s	
3991/11850 (epoch 16.840), train_loss = 1.27525765, grad/param norm = 2.1501e-01, time/batch = 0.6432s	
3992/11850 (epoch 16.844), train_loss = 1.30883085, grad/param norm = 2.0839e-01, time/batch = 0.6392s	
3993/11850 (epoch 16.848), train_loss = 1.37908313, grad/param norm = 2.2187e-01, time/batch = 0.6401s	
3994/11850 (epoch 16.852), train_loss = 1.32351875, grad/param norm = 2.3756e-01, time/batch = 0.6448s	
3995/11850 (epoch 16.857), train_loss = 1.33649071, grad/param norm = 2.4706e-01, time/batch = 0.6357s	
3996/11850 (epoch 16.861), train_loss = 1.35708774, grad/param norm = 2.3272e-01, time/batch = 0.6385s	
3997/11850 (epoch 16.865), train_loss = 1.41041709, grad/param norm = 2.6377e-01, time/batch = 0.6428s	
3998/11850 (epoch 16.869), train_loss = 1.39468442, grad/param norm = 2.2185e-01, time/batch = 0.6638s	
3999/11850 (epoch 16.873), train_loss = 1.39973262, grad/param norm = 2.3749e-01, time/batch = 0.6518s	
evaluating loss over split index 2	
1/13...	
2/13...	
3/13...	
4/13...	
5/13...	
6/13...	
7/13...	
8/13...	
9/13...	
10/13...	
11/13...	
12/13...	
13/13...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_katelyn_salem_epoch16.88_1.9079.t7	
4000/11850 (epoch 16.878), train_loss = 1.39743458, grad/param norm = 2.4297e-01, time/batch = 0.6383s	
4001/11850 (epoch 16.882), train_loss = 1.49187592, grad/param norm = 2.4322e-01, time/batch = 0.6553s	
4002/11850 (epoch 16.886), train_loss = 1.42579831, grad/param norm = 2.5534e-01, time/batch = 0.6426s	
4003/11850 (epoch 16.890), train_loss = 1.41227701, grad/param norm = 2.5879e-01, time/batch = 0.6536s	
4004/11850 (epoch 16.895), train_loss = 1.38367773, grad/param norm = 2.6858e-01, time/batch = 0.6686s	
4005/11850 (epoch 16.899), train_loss = 1.24980591, grad/param norm = 2.5936e-01, time/batch = 0.6870s	
4006/11850 (epoch 16.903), train_loss = 1.33062896, grad/param norm = 2.4960e-01, time/batch = 0.6664s	
4007/11850 (epoch 16.907), train_loss = 1.29442460, grad/param norm = 2.6020e-01, time/batch = 0.6432s	
4008/11850 (epoch 16.911), train_loss = 1.40388750, grad/param norm = 2.5940e-01, time/batch = 0.6499s	
4009/11850 (epoch 16.916), train_loss = 1.45947757, grad/param norm = 2.6207e-01, time/batch = 0.6502s	
4010/11850 (epoch 16.920), train_loss = 1.33019451, grad/param norm = 2.4779e-01, time/batch = 0.6477s	
4011/11850 (epoch 16.924), train_loss = 1.34600931, grad/param norm = 2.3443e-01, time/batch = 0.6421s	
4012/11850 (epoch 16.928), train_loss = 1.44786359, grad/param norm = 2.5005e-01, time/batch = 0.6381s	
4013/11850 (epoch 16.932), train_loss = 1.47452296, grad/param norm = 2.3882e-01, time/batch = 0.6375s	
4014/11850 (epoch 16.937), train_loss = 1.42141573, grad/param norm = 2.5696e-01, time/batch = 0.6354s	
4015/11850 (epoch 16.941), train_loss = 1.41517731, grad/param norm = 2.3382e-01, time/batch = 0.6369s	
4016/11850 (epoch 16.945), train_loss = 1.42106588, grad/param norm = 2.6696e-01, time/batch = 0.6383s	
4017/11850 (epoch 16.949), train_loss = 1.29887201, grad/param norm = 2.6818e-01, time/batch = 0.6363s	
4018/11850 (epoch 16.954), train_loss = 1.41606080, grad/param norm = 2.6564e-01, time/batch = 0.6381s	
4019/11850 (epoch 16.958), train_loss = 1.39546833, grad/param norm = 2.4468e-01, time/batch = 0.6378s	
4020/11850 (epoch 16.962), train_loss = 1.25255524, grad/param norm = 2.4746e-01, time/batch = 0.6388s	
4021/11850 (epoch 16.966), train_loss = 1.23599762, grad/param norm = 2.3033e-01, time/batch = 0.6394s	
4022/11850 (epoch 16.970), train_loss = 1.34813415, grad/param norm = 2.1717e-01, time/batch = 0.6403s	
4023/11850 (epoch 16.975), train_loss = 1.34321519, grad/param norm = 2.3700e-01, time/batch = 0.6402s	
4024/11850 (epoch 16.979), train_loss = 1.35968018, grad/param norm = 2.4726e-01, time/batch = 0.6382s	
4025/11850 (epoch 16.983), train_loss = 1.51226914, grad/param norm = 2.7918e-01, time/batch = 0.6417s	
4026/11850 (epoch 16.987), train_loss = 1.34287156, grad/param norm = 2.4519e-01, time/batch = 0.6408s	
4027/11850 (epoch 16.992), train_loss = 1.49657403, grad/param norm = 2.1705e-01, time/batch = 0.6390s	
4028/11850 (epoch 16.996), train_loss = 1.58593140, grad/param norm = 2.5569e-01, time/batch = 0.6381s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
4029/11850 (epoch 17.000), train_loss = 1.32741583, grad/param norm = 2.6259e-01, time/batch = 0.6409s	
4030/11850 (epoch 17.004), train_loss = 1.43622856, grad/param norm = 2.5795e-01, time/batch = 0.6456s	
4031/11850 (epoch 17.008), train_loss = 1.44281014, grad/param norm = 2.3520e-01, time/batch = 0.6413s	
4032/11850 (epoch 17.013), train_loss = 1.42556987, grad/param norm = 2.4653e-01, time/batch = 0.6451s	
4033/11850 (epoch 17.017), train_loss = 1.56569414, grad/param norm = 2.3876e-01, time/batch = 0.6410s	
4034/11850 (epoch 17.021), train_loss = 1.34291018, grad/param norm = 2.0560e-01, time/batch = 0.6399s	
4035/11850 (epoch 17.025), train_loss = 1.21647897, grad/param norm = 2.0975e-01, time/batch = 0.6407s	
4036/11850 (epoch 17.030), train_loss = 1.25174035, grad/param norm = 2.2221e-01, time/batch = 0.6408s	
4037/11850 (epoch 17.034), train_loss = 1.28442885, grad/param norm = 2.2349e-01, time/batch = 0.6421s	
4038/11850 (epoch 17.038), train_loss = 1.35624750, grad/param norm = 2.1884e-01, time/batch = 0.6394s	
4039/11850 (epoch 17.042), train_loss = 1.36415317, grad/param norm = 2.2466e-01, time/batch = 0.6411s	
4040/11850 (epoch 17.046), train_loss = 1.41407172, grad/param norm = 2.5542e-01, time/batch = 0.6584s	
4041/11850 (epoch 17.051), train_loss = 1.35268480, grad/param norm = 2.2473e-01, time/batch = 0.6434s	
4042/11850 (epoch 17.055), train_loss = 1.31993469, grad/param norm = 2.1899e-01, time/batch = 0.6397s	
4043/11850 (epoch 17.059), train_loss = 1.42238678, grad/param norm = 2.3626e-01, time/batch = 0.6399s	
4044/11850 (epoch 17.063), train_loss = 1.37426563, grad/param norm = 2.1778e-01, time/batch = 0.6427s	
4045/11850 (epoch 17.068), train_loss = 1.34330968, grad/param norm = 2.1204e-01, time/batch = 0.6417s	
4046/11850 (epoch 17.072), train_loss = 1.36007242, grad/param norm = 2.0661e-01, time/batch = 0.6409s	
4047/11850 (epoch 17.076), train_loss = 1.48018146, grad/param norm = 2.1427e-01, time/batch = 0.6421s	
4048/11850 (epoch 17.080), train_loss = 1.28793876, grad/param norm = 2.2599e-01, time/batch = 0.6433s	
4049/11850 (epoch 17.084), train_loss = 1.19402972, grad/param norm = 2.1563e-01, time/batch = 0.6423s	
4050/11850 (epoch 17.089), train_loss = 1.22369201, grad/param norm = 1.9704e-01, time/batch = 0.6456s	
4051/11850 (epoch 17.093), train_loss = 1.20209547, grad/param norm = 2.2562e-01, time/batch = 0.6450s	
4052/11850 (epoch 17.097), train_loss = 1.39895157, grad/param norm = 2.2300e-01, time/batch = 0.6401s	
4053/11850 (epoch 17.101), train_loss = 1.33146571, grad/param norm = 2.4591e-01, time/batch = 0.6370s	
4054/11850 (epoch 17.105), train_loss = 1.24767640, grad/param norm = 2.1807e-01, time/batch = 0.6378s	
4055/11850 (epoch 17.110), train_loss = 1.39114299, grad/param norm = 2.2507e-01, time/batch = 0.6397s	
4056/11850 (epoch 17.114), train_loss = 1.37231151, grad/param norm = 2.3329e-01, time/batch = 0.6386s	
4057/11850 (epoch 17.118), train_loss = 1.31572142, grad/param norm = 2.0507e-01, time/batch = 0.6410s	
4058/11850 (epoch 17.122), train_loss = 1.43850270, grad/param norm = 2.3669e-01, time/batch = 0.6369s	
4059/11850 (epoch 17.127), train_loss = 1.37963217, grad/param norm = 2.4096e-01, time/batch = 0.6377s	
4060/11850 (epoch 17.131), train_loss = 1.38791424, grad/param norm = 2.8051e-01, time/batch = 0.6378s	
4061/11850 (epoch 17.135), train_loss = 1.30903718, grad/param norm = 2.3821e-01, time/batch = 0.6388s	
4062/11850 (epoch 17.139), train_loss = 1.30503275, grad/param norm = 2.3256e-01, time/batch = 0.6394s	
4063/11850 (epoch 17.143), train_loss = 1.31837301, grad/param norm = 2.2903e-01, time/batch = 0.6387s	
4064/11850 (epoch 17.148), train_loss = 1.35262119, grad/param norm = 2.4080e-01, time/batch = 0.6398s	
4065/11850 (epoch 17.152), train_loss = 1.44950226, grad/param norm = 2.7373e-01, time/batch = 0.6357s	
4066/11850 (epoch 17.156), train_loss = 1.40412497, grad/param norm = 2.4699e-01, time/batch = 0.6385s	
4067/11850 (epoch 17.160), train_loss = 1.63561435, grad/param norm = 3.0461e-01, time/batch = 0.6339s	
4068/11850 (epoch 17.165), train_loss = 1.48386737, grad/param norm = 2.7956e-01, time/batch = 0.6379s	
4069/11850 (epoch 17.169), train_loss = 1.33829982, grad/param norm = 2.3873e-01, time/batch = 0.6603s	
4070/11850 (epoch 17.173), train_loss = 1.41972043, grad/param norm = 2.2499e-01, time/batch = 0.6542s	
4071/11850 (epoch 17.177), train_loss = 1.32967619, grad/param norm = 2.9291e-01, time/batch = 0.6555s	
4072/11850 (epoch 17.181), train_loss = 1.44858912, grad/param norm = 2.4457e-01, time/batch = 0.6449s	
4073/11850 (epoch 17.186), train_loss = 1.50062323, grad/param norm = 2.7609e-01, time/batch = 0.6385s	
4074/11850 (epoch 17.190), train_loss = 1.39368222, grad/param norm = 2.2736e-01, time/batch = 0.6368s	
4075/11850 (epoch 17.194), train_loss = 1.50403240, grad/param norm = 2.5720e-01, time/batch = 0.6334s	
4076/11850 (epoch 17.198), train_loss = 1.26334317, grad/param norm = 2.4147e-01, time/batch = 0.6345s	
4077/11850 (epoch 17.203), train_loss = 1.24537214, grad/param norm = 2.2626e-01, time/batch = 0.6409s	
4078/11850 (epoch 17.207), train_loss = 1.40892657, grad/param norm = 2.2757e-01, time/batch = 0.6383s	
4079/11850 (epoch 17.211), train_loss = 1.35212839, grad/param norm = 2.2592e-01, time/batch = 0.6459s	
4080/11850 (epoch 17.215), train_loss = 1.36329392, grad/param norm = 2.3556e-01, time/batch = 0.6406s	
4081/11850 (epoch 17.219), train_loss = 1.32475494, grad/param norm = 2.2611e-01, time/batch = 0.6697s	
4082/11850 (epoch 17.224), train_loss = 1.54748456, grad/param norm = 2.4415e-01, time/batch = 0.6575s	
4083/11850 (epoch 17.228), train_loss = 1.46909936, grad/param norm = 2.4545e-01, time/batch = 0.6504s	
4084/11850 (epoch 17.232), train_loss = 1.42866847, grad/param norm = 2.2680e-01, time/batch = 0.6523s	
4085/11850 (epoch 17.236), train_loss = 1.28488099, grad/param norm = 2.4112e-01, time/batch = 0.6657s	
4086/11850 (epoch 17.241), train_loss = 1.54017885, grad/param norm = 2.5173e-01, time/batch = 0.6495s	
4087/11850 (epoch 17.245), train_loss = 1.44961394, grad/param norm = 2.3212e-01, time/batch = 0.6574s	
4088/11850 (epoch 17.249), train_loss = 1.27808351, grad/param norm = 2.1568e-01, time/batch = 0.6493s	
4089/11850 (epoch 17.253), train_loss = 1.38188190, grad/param norm = 2.4726e-01, time/batch = 0.6476s	
4090/11850 (epoch 17.257), train_loss = 1.48286635, grad/param norm = 2.1719e-01, time/batch = 0.6485s	
4091/11850 (epoch 17.262), train_loss = 1.55099405, grad/param norm = 2.4586e-01, time/batch = 0.6514s	
4092/11850 (epoch 17.266), train_loss = 1.43684685, grad/param norm = 2.4739e-01, time/batch = 0.6507s	
4093/11850 (epoch 17.270), train_loss = 1.31233340, grad/param norm = 2.2644e-01, time/batch = 0.6522s	
4094/11850 (epoch 17.274), train_loss = 1.32162543, grad/param norm = 2.4761e-01, time/batch = 0.6460s	
4095/11850 (epoch 17.278), train_loss = 1.21140397, grad/param norm = 2.3719e-01, time/batch = 0.6503s	
4096/11850 (epoch 17.283), train_loss = 1.29113755, grad/param norm = 2.2126e-01, time/batch = 0.6662s	
4097/11850 (epoch 17.287), train_loss = 1.45607307, grad/param norm = 2.2793e-01, time/batch = 0.6694s	
4098/11850 (epoch 17.291), train_loss = 1.38583214, grad/param norm = 2.4003e-01, time/batch = 0.6622s	
4099/11850 (epoch 17.295), train_loss = 1.38392571, grad/param norm = 2.2397e-01, time/batch = 0.6480s	
4100/11850 (epoch 17.300), train_loss = 1.33447189, grad/param norm = 2.4784e-01, time/batch = 0.6396s	
4101/11850 (epoch 17.304), train_loss = 1.32123628, grad/param norm = 2.1249e-01, time/batch = 0.6449s	
4102/11850 (epoch 17.308), train_loss = 1.31937539, grad/param norm = 2.2028e-01, time/batch = 0.6606s	
4103/11850 (epoch 17.312), train_loss = 1.16953095, grad/param norm = 1.9802e-01, time/batch = 0.6570s	
4104/11850 (epoch 17.316), train_loss = 1.38655899, grad/param norm = 2.2018e-01, time/batch = 0.6412s	
4105/11850 (epoch 17.321), train_loss = 1.29176108, grad/param norm = 2.0255e-01, time/batch = 0.6431s	
4106/11850 (epoch 17.325), train_loss = 1.34346823, grad/param norm = 2.4853e-01, time/batch = 0.6408s	
4107/11850 (epoch 17.329), train_loss = 1.31859667, grad/param norm = 2.2426e-01, time/batch = 0.6384s	
4108/11850 (epoch 17.333), train_loss = 1.33476964, grad/param norm = 2.4460e-01, time/batch = 0.6411s	
4109/11850 (epoch 17.338), train_loss = 1.24797441, grad/param norm = 2.0204e-01, time/batch = 0.6379s	
4110/11850 (epoch 17.342), train_loss = 1.44184153, grad/param norm = 2.6440e-01, time/batch = 0.6402s	
4111/11850 (epoch 17.346), train_loss = 1.36239777, grad/param norm = 2.3022e-01, time/batch = 0.6407s	
4112/11850 (epoch 17.350), train_loss = 1.21035643, grad/param norm = 2.3232e-01, time/batch = 0.6418s	
4113/11850 (epoch 17.354), train_loss = 1.43409941, grad/param norm = 2.3664e-01, time/batch = 0.6665s	
4114/11850 (epoch 17.359), train_loss = 1.43466288, grad/param norm = 2.4782e-01, time/batch = 0.6586s	
4115/11850 (epoch 17.363), train_loss = 1.39275856, grad/param norm = 2.2761e-01, time/batch = 0.6371s	
4116/11850 (epoch 17.367), train_loss = 1.38961564, grad/param norm = 2.1005e-01, time/batch = 0.6437s	
4117/11850 (epoch 17.371), train_loss = 1.39265889, grad/param norm = 2.1669e-01, time/batch = 0.6390s	
4118/11850 (epoch 17.376), train_loss = 1.32012372, grad/param norm = 2.1985e-01, time/batch = 0.6369s	
4119/11850 (epoch 17.380), train_loss = 1.26624259, grad/param norm = 2.0786e-01, time/batch = 0.6406s	
4120/11850 (epoch 17.384), train_loss = 1.25707435, grad/param norm = 2.5214e-01, time/batch = 0.6391s	
4121/11850 (epoch 17.388), train_loss = 1.43943653, grad/param norm = 2.4171e-01, time/batch = 0.6385s	
4122/11850 (epoch 17.392), train_loss = 1.46051930, grad/param norm = 2.4865e-01, time/batch = 0.6357s	
4123/11850 (epoch 17.397), train_loss = 1.42304108, grad/param norm = 2.6393e-01, time/batch = 0.6403s	
4124/11850 (epoch 17.401), train_loss = 1.20397370, grad/param norm = 1.9985e-01, time/batch = 0.6593s	
4125/11850 (epoch 17.405), train_loss = 1.27508575, grad/param norm = 2.1529e-01, time/batch = 0.6443s	
4126/11850 (epoch 17.409), train_loss = 1.44159618, grad/param norm = 2.2652e-01, time/batch = 0.6420s	
4127/11850 (epoch 17.414), train_loss = 1.22201506, grad/param norm = 2.1251e-01, time/batch = 0.6420s	
4128/11850 (epoch 17.418), train_loss = 1.22264046, grad/param norm = 2.3881e-01, time/batch = 0.6465s	
4129/11850 (epoch 17.422), train_loss = 1.17884438, grad/param norm = 2.2196e-01, time/batch = 0.6440s	
4130/11850 (epoch 17.426), train_loss = 1.21434041, grad/param norm = 2.2777e-01, time/batch = 0.6481s	
4131/11850 (epoch 17.430), train_loss = 1.27952589, grad/param norm = 2.1845e-01, time/batch = 0.6559s	
4132/11850 (epoch 17.435), train_loss = 1.27248772, grad/param norm = 2.2773e-01, time/batch = 0.6556s	
4133/11850 (epoch 17.439), train_loss = 1.43694493, grad/param norm = 2.2415e-01, time/batch = 0.6452s	
4134/11850 (epoch 17.443), train_loss = 1.37981552, grad/param norm = 2.2023e-01, time/batch = 0.6551s	
4135/11850 (epoch 17.447), train_loss = 1.22664886, grad/param norm = 2.6474e-01, time/batch = 0.6740s	
4136/11850 (epoch 17.451), train_loss = 1.22924276, grad/param norm = 2.3513e-01, time/batch = 0.6509s	
4137/11850 (epoch 17.456), train_loss = 1.31173184, grad/param norm = 2.6612e-01, time/batch = 0.6574s	
4138/11850 (epoch 17.460), train_loss = 1.34221851, grad/param norm = 2.2880e-01, time/batch = 0.6474s	
4139/11850 (epoch 17.464), train_loss = 1.26646690, grad/param norm = 2.2604e-01, time/batch = 0.6427s	
4140/11850 (epoch 17.468), train_loss = 1.32579247, grad/param norm = 2.1306e-01, time/batch = 0.6464s	
4141/11850 (epoch 17.473), train_loss = 1.38248749, grad/param norm = 2.4779e-01, time/batch = 0.6473s	
4142/11850 (epoch 17.477), train_loss = 1.22349846, grad/param norm = 2.2793e-01, time/batch = 0.6421s	
4143/11850 (epoch 17.481), train_loss = 1.26268956, grad/param norm = 2.4952e-01, time/batch = 0.6424s	
4144/11850 (epoch 17.485), train_loss = 1.22054957, grad/param norm = 2.1647e-01, time/batch = 0.6489s	
4145/11850 (epoch 17.489), train_loss = 1.36603761, grad/param norm = 2.3679e-01, time/batch = 0.6621s	
4146/11850 (epoch 17.494), train_loss = 1.27159435, grad/param norm = 2.4143e-01, time/batch = 0.6710s	
4147/11850 (epoch 17.498), train_loss = 1.25149916, grad/param norm = 2.4430e-01, time/batch = 0.6409s	
4148/11850 (epoch 17.502), train_loss = 1.18357877, grad/param norm = 2.3479e-01, time/batch = 0.6417s	
4149/11850 (epoch 17.506), train_loss = 1.44501784, grad/param norm = 2.4229e-01, time/batch = 0.6425s	
4150/11850 (epoch 17.511), train_loss = 1.31949904, grad/param norm = 2.1560e-01, time/batch = 0.6395s	
4151/11850 (epoch 17.515), train_loss = 1.43607930, grad/param norm = 2.5243e-01, time/batch = 0.6431s	
4152/11850 (epoch 17.519), train_loss = 1.25961849, grad/param norm = 2.1731e-01, time/batch = 0.6411s	
4153/11850 (epoch 17.523), train_loss = 1.28914017, grad/param norm = 2.5085e-01, time/batch = 0.6407s	
4154/11850 (epoch 17.527), train_loss = 1.20414989, grad/param norm = 2.3247e-01, time/batch = 0.6436s	
4155/11850 (epoch 17.532), train_loss = 1.37910592, grad/param norm = 2.2965e-01, time/batch = 0.6422s	
4156/11850 (epoch 17.536), train_loss = 1.24765281, grad/param norm = 2.1041e-01, time/batch = 0.6440s	
4157/11850 (epoch 17.540), train_loss = 1.21640743, grad/param norm = 2.0901e-01, time/batch = 0.6430s	
4158/11850 (epoch 17.544), train_loss = 1.29924650, grad/param norm = 2.4277e-01, time/batch = 0.6406s	
4159/11850 (epoch 17.549), train_loss = 1.12823003, grad/param norm = 2.0198e-01, time/batch = 0.6471s	
4160/11850 (epoch 17.553), train_loss = 1.35620534, grad/param norm = 2.3050e-01, time/batch = 0.6432s	
4161/11850 (epoch 17.557), train_loss = 1.45006071, grad/param norm = 2.4067e-01, time/batch = 0.6444s	
4162/11850 (epoch 17.561), train_loss = 1.34028894, grad/param norm = 2.5033e-01, time/batch = 0.6440s	
4163/11850 (epoch 17.565), train_loss = 1.46854588, grad/param norm = 2.4124e-01, time/batch = 0.6495s	
4164/11850 (epoch 17.570), train_loss = 1.29759894, grad/param norm = 2.2504e-01, time/batch = 0.6458s	
4165/11850 (epoch 17.574), train_loss = 1.41118904, grad/param norm = 2.4334e-01, time/batch = 0.6462s	
4166/11850 (epoch 17.578), train_loss = 1.45310209, grad/param norm = 2.3731e-01, time/batch = 0.6409s	
4167/11850 (epoch 17.582), train_loss = 1.26230321, grad/param norm = 2.4195e-01, time/batch = 0.6426s	
4168/11850 (epoch 17.586), train_loss = 1.29108012, grad/param norm = 2.2253e-01, time/batch = 0.6418s	
4169/11850 (epoch 17.591), train_loss = 1.41892438, grad/param norm = 2.3377e-01, time/batch = 0.6421s	
4170/11850 (epoch 17.595), train_loss = 1.17321612, grad/param norm = 2.1864e-01, time/batch = 0.6445s	
4171/11850 (epoch 17.599), train_loss = 1.28518356, grad/param norm = 2.4211e-01, time/batch = 0.6471s	
4172/11850 (epoch 17.603), train_loss = 1.23669998, grad/param norm = 2.1994e-01, time/batch = 0.6531s	
4173/11850 (epoch 17.608), train_loss = 1.44120754, grad/param norm = 2.3369e-01, time/batch = 0.6449s	
4174/11850 (epoch 17.612), train_loss = 1.52728364, grad/param norm = 2.6205e-01, time/batch = 0.6466s	
4175/11850 (epoch 17.616), train_loss = 1.44126664, grad/param norm = 2.2464e-01, time/batch = 0.6435s	
4176/11850 (epoch 17.620), train_loss = 1.30130647, grad/param norm = 2.2732e-01, time/batch = 0.6472s	
4177/11850 (epoch 17.624), train_loss = 1.36172525, grad/param norm = 2.8142e-01, time/batch = 0.6446s	
4178/11850 (epoch 17.629), train_loss = 1.25442018, grad/param norm = 2.2702e-01, time/batch = 0.6435s	
4179/11850 (epoch 17.633), train_loss = 1.18437587, grad/param norm = 2.3899e-01, time/batch = 0.6462s	
4180/11850 (epoch 17.637), train_loss = 1.19547532, grad/param norm = 2.3772e-01, time/batch = 0.6426s	
4181/11850 (epoch 17.641), train_loss = 1.19660090, grad/param norm = 2.1795e-01, time/batch = 0.6468s	
4182/11850 (epoch 17.646), train_loss = 1.28001275, grad/param norm = 2.3404e-01, time/batch = 0.6424s	
4183/11850 (epoch 17.650), train_loss = 1.32166093, grad/param norm = 2.6342e-01, time/batch = 0.6409s	
4184/11850 (epoch 17.654), train_loss = 1.30375837, grad/param norm = 3.0050e-01, time/batch = 0.6442s	
4185/11850 (epoch 17.658), train_loss = 1.35367645, grad/param norm = 2.4985e-01, time/batch = 0.6541s	
4186/11850 (epoch 17.662), train_loss = 1.24188938, grad/param norm = 2.9262e-01, time/batch = 0.6469s	
4187/11850 (epoch 17.667), train_loss = 1.40347529, grad/param norm = 2.3771e-01, time/batch = 0.6472s	
4188/11850 (epoch 17.671), train_loss = 1.28052897, grad/param norm = 2.1578e-01, time/batch = 0.6617s	
4189/11850 (epoch 17.675), train_loss = 1.28527648, grad/param norm = 2.1710e-01, time/batch = 0.6755s	
4190/11850 (epoch 17.679), train_loss = 1.34696405, grad/param norm = 2.4322e-01, time/batch = 0.6886s	
4191/11850 (epoch 17.684), train_loss = 1.33410058, grad/param norm = 2.4586e-01, time/batch = 0.6833s	
4192/11850 (epoch 17.688), train_loss = 1.23592734, grad/param norm = 2.0479e-01, time/batch = 0.6732s	
4193/11850 (epoch 17.692), train_loss = 1.30852534, grad/param norm = 2.6855e-01, time/batch = 0.6791s	
4194/11850 (epoch 17.696), train_loss = 1.22658612, grad/param norm = 2.5531e-01, time/batch = 0.6638s	
4195/11850 (epoch 17.700), train_loss = 1.30381495, grad/param norm = 2.2334e-01, time/batch = 0.6465s	
4196/11850 (epoch 17.705), train_loss = 1.27957938, grad/param norm = 2.2394e-01, time/batch = 0.6498s	
4197/11850 (epoch 17.709), train_loss = 1.18656670, grad/param norm = 2.2173e-01, time/batch = 0.6430s	
4198/11850 (epoch 17.713), train_loss = 1.24244280, grad/param norm = 2.4838e-01, time/batch = 0.6445s	
4199/11850 (epoch 17.717), train_loss = 1.23185970, grad/param norm = 2.4116e-01, time/batch = 0.6412s	
4200/11850 (epoch 17.722), train_loss = 1.33674315, grad/param norm = 2.6419e-01, time/batch = 0.6409s	
4201/11850 (epoch 17.726), train_loss = 1.20168165, grad/param norm = 2.4389e-01, time/batch = 0.6462s	
4202/11850 (epoch 17.730), train_loss = 1.16163600, grad/param norm = 2.2067e-01, time/batch = 0.6424s	
4203/11850 (epoch 17.734), train_loss = 1.23819557, grad/param norm = 2.2428e-01, time/batch = 0.6514s	
4204/11850 (epoch 17.738), train_loss = 1.40772809, grad/param norm = 2.4842e-01, time/batch = 0.6751s	
4205/11850 (epoch 17.743), train_loss = 1.33069042, grad/param norm = 2.2777e-01, time/batch = 0.6483s	
4206/11850 (epoch 17.747), train_loss = 1.15430269, grad/param norm = 2.0775e-01, time/batch = 0.6429s	
4207/11850 (epoch 17.751), train_loss = 1.17004683, grad/param norm = 2.0857e-01, time/batch = 0.6563s	
4208/11850 (epoch 17.755), train_loss = 1.30671885, grad/param norm = 2.3789e-01, time/batch = 0.6616s	
4209/11850 (epoch 17.759), train_loss = 1.21882975, grad/param norm = 2.1740e-01, time/batch = 0.6576s	
4210/11850 (epoch 17.764), train_loss = 1.28585143, grad/param norm = 2.3419e-01, time/batch = 0.6564s	
4211/11850 (epoch 17.768), train_loss = 1.14948836, grad/param norm = 2.2118e-01, time/batch = 0.6547s	
4212/11850 (epoch 17.772), train_loss = 1.27224676, grad/param norm = 2.2367e-01, time/batch = 0.6549s	
4213/11850 (epoch 17.776), train_loss = 1.28974124, grad/param norm = 2.1921e-01, time/batch = 0.6512s	
4214/11850 (epoch 17.781), train_loss = 1.25384275, grad/param norm = 2.3684e-01, time/batch = 0.6629s	
4215/11850 (epoch 17.785), train_loss = 1.23104266, grad/param norm = 2.2292e-01, time/batch = 0.6517s	
4216/11850 (epoch 17.789), train_loss = 1.32877807, grad/param norm = 2.3245e-01, time/batch = 0.6443s	
4217/11850 (epoch 17.793), train_loss = 1.40947353, grad/param norm = 2.4193e-01, time/batch = 0.6415s	
4218/11850 (epoch 17.797), train_loss = 1.33063098, grad/param norm = 2.3964e-01, time/batch = 0.6416s	
4219/11850 (epoch 17.802), train_loss = 1.19302696, grad/param norm = 2.1510e-01, time/batch = 0.6445s	
4220/11850 (epoch 17.806), train_loss = 1.28421926, grad/param norm = 2.1157e-01, time/batch = 0.6429s	
4221/11850 (epoch 17.810), train_loss = 1.45234933, grad/param norm = 2.6628e-01, time/batch = 0.6476s	
4222/11850 (epoch 17.814), train_loss = 1.28395518, grad/param norm = 2.3989e-01, time/batch = 0.6428s	
4223/11850 (epoch 17.819), train_loss = 1.43637528, grad/param norm = 2.5017e-01, time/batch = 0.6491s	
4224/11850 (epoch 17.823), train_loss = 1.46141278, grad/param norm = 2.6884e-01, time/batch = 0.6477s	
4225/11850 (epoch 17.827), train_loss = 1.34052364, grad/param norm = 2.6997e-01, time/batch = 0.6432s	
4226/11850 (epoch 17.831), train_loss = 1.31506504, grad/param norm = 2.5214e-01, time/batch = 0.6473s	
4227/11850 (epoch 17.835), train_loss = 1.29762113, grad/param norm = 2.2567e-01, time/batch = 0.6440s	
4228/11850 (epoch 17.840), train_loss = 1.25308465, grad/param norm = 2.1990e-01, time/batch = 0.6473s	
4229/11850 (epoch 17.844), train_loss = 1.28582970, grad/param norm = 2.1394e-01, time/batch = 0.6439s	
4230/11850 (epoch 17.848), train_loss = 1.34714452, grad/param norm = 2.4063e-01, time/batch = 0.6428s	
4231/11850 (epoch 17.852), train_loss = 1.29511729, grad/param norm = 2.3983e-01, time/batch = 0.6450s	
4232/11850 (epoch 17.857), train_loss = 1.31098841, grad/param norm = 2.4921e-01, time/batch = 0.6439s	
4233/11850 (epoch 17.861), train_loss = 1.31161028, grad/param norm = 2.3334e-01, time/batch = 0.6461s	
4234/11850 (epoch 17.865), train_loss = 1.36879941, grad/param norm = 2.6207e-01, time/batch = 0.6429s	
4235/11850 (epoch 17.869), train_loss = 1.36326486, grad/param norm = 2.2867e-01, time/batch = 0.6462s	
4236/11850 (epoch 17.873), train_loss = 1.36697592, grad/param norm = 2.3939e-01, time/batch = 0.6504s	
4237/11850 (epoch 17.878), train_loss = 1.37219149, grad/param norm = 2.4310e-01, time/batch = 0.6451s	
4238/11850 (epoch 17.882), train_loss = 1.35298392, grad/param norm = 2.5806e-01, time/batch = 0.6424s	
4239/11850 (epoch 17.886), train_loss = 1.38672124, grad/param norm = 2.7399e-01, time/batch = 0.6439s	
4240/11850 (epoch 17.890), train_loss = 1.36876086, grad/param norm = 2.5287e-01, time/batch = 0.6423s	
4241/11850 (epoch 17.895), train_loss = 1.34334762, grad/param norm = 2.6166e-01, time/batch = 0.6440s	
4242/11850 (epoch 17.899), train_loss = 1.22300170, grad/param norm = 2.7471e-01, time/batch = 0.6490s	
4243/11850 (epoch 17.903), train_loss = 1.29473903, grad/param norm = 2.3953e-01, time/batch = 0.6442s	
4244/11850 (epoch 17.907), train_loss = 1.25750429, grad/param norm = 2.5254e-01, time/batch = 0.6484s	
4245/11850 (epoch 17.911), train_loss = 1.37476135, grad/param norm = 2.4055e-01, time/batch = 0.6436s	
4246/11850 (epoch 17.916), train_loss = 1.41628594, grad/param norm = 2.5234e-01, time/batch = 0.6468s	
4247/11850 (epoch 17.920), train_loss = 1.30100095, grad/param norm = 2.4960e-01, time/batch = 0.6433s	
4248/11850 (epoch 17.924), train_loss = 1.31296032, grad/param norm = 2.4026e-01, time/batch = 0.6441s	
4249/11850 (epoch 17.928), train_loss = 1.41122083, grad/param norm = 2.7302e-01, time/batch = 0.6405s	
4250/11850 (epoch 17.932), train_loss = 1.42729189, grad/param norm = 2.2718e-01, time/batch = 0.6408s	
4251/11850 (epoch 17.937), train_loss = 1.37277311, grad/param norm = 2.4437e-01, time/batch = 0.6445s	
4252/11850 (epoch 17.941), train_loss = 1.38189676, grad/param norm = 2.2960e-01, time/batch = 0.6496s	
4253/11850 (epoch 17.945), train_loss = 1.38735088, grad/param norm = 2.2983e-01, time/batch = 0.6436s	
4254/11850 (epoch 17.949), train_loss = 1.26748866, grad/param norm = 3.4642e-01, time/batch = 0.6442s	
4255/11850 (epoch 17.954), train_loss = 1.39597519, grad/param norm = 3.1578e-01, time/batch = 0.6456s	
4256/11850 (epoch 17.958), train_loss = 1.37286389, grad/param norm = 2.8241e-01, time/batch = 0.6439s	
4257/11850 (epoch 17.962), train_loss = 1.22641173, grad/param norm = 2.4010e-01, time/batch = 0.6623s	
4258/11850 (epoch 17.966), train_loss = 1.19831459, grad/param norm = 2.3407e-01, time/batch = 0.6746s	
4259/11850 (epoch 17.970), train_loss = 1.31653000, grad/param norm = 2.2516e-01, time/batch = 0.6421s	
4260/11850 (epoch 17.975), train_loss = 1.30642050, grad/param norm = 2.3030e-01, time/batch = 0.6423s	
4261/11850 (epoch 17.979), train_loss = 1.32172549, grad/param norm = 2.5116e-01, time/batch = 0.6439s	
4262/11850 (epoch 17.983), train_loss = 1.46559809, grad/param norm = 2.9466e-01, time/batch = 0.6517s	
4263/11850 (epoch 17.987), train_loss = 1.30102572, grad/param norm = 2.3229e-01, time/batch = 0.6458s	
4264/11850 (epoch 17.992), train_loss = 1.46812874, grad/param norm = 2.1665e-01, time/batch = 0.6511s	
4265/11850 (epoch 17.996), train_loss = 1.54859374, grad/param norm = 2.6621e-01, time/batch = 0.6416s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
4266/11850 (epoch 18.000), train_loss = 1.29027979, grad/param norm = 2.3358e-01, time/batch = 0.6427s	
4267/11850 (epoch 18.004), train_loss = 1.39662401, grad/param norm = 2.5312e-01, time/batch = 0.6450s	
4268/11850 (epoch 18.008), train_loss = 1.42686172, grad/param norm = 2.4006e-01, time/batch = 0.6686s	
4269/11850 (epoch 18.013), train_loss = 1.38951790, grad/param norm = 2.4212e-01, time/batch = 0.6663s	
4270/11850 (epoch 18.017), train_loss = 1.52981256, grad/param norm = 2.4293e-01, time/batch = 0.6412s	
4271/11850 (epoch 18.021), train_loss = 1.32180928, grad/param norm = 2.1092e-01, time/batch = 0.6441s	
4272/11850 (epoch 18.025), train_loss = 1.19258356, grad/param norm = 2.0906e-01, time/batch = 0.6435s	
4273/11850 (epoch 18.030), train_loss = 1.23277238, grad/param norm = 2.2638e-01, time/batch = 0.6397s	
4274/11850 (epoch 18.034), train_loss = 1.25629872, grad/param norm = 2.2675e-01, time/batch = 0.6418s	
4275/11850 (epoch 18.038), train_loss = 1.32260233, grad/param norm = 2.1311e-01, time/batch = 0.6388s	
4276/11850 (epoch 18.042), train_loss = 1.32995310, grad/param norm = 2.4642e-01, time/batch = 0.6400s	
4277/11850 (epoch 18.046), train_loss = 1.37804943, grad/param norm = 2.5253e-01, time/batch = 0.6421s	
4278/11850 (epoch 18.051), train_loss = 1.31229976, grad/param norm = 2.1843e-01, time/batch = 0.6407s	
4279/11850 (epoch 18.055), train_loss = 1.28654353, grad/param norm = 2.0925e-01, time/batch = 0.6732s	
4280/11850 (epoch 18.059), train_loss = 1.39975629, grad/param norm = 2.5163e-01, time/batch = 0.6848s	
4281/11850 (epoch 18.063), train_loss = 1.34632290, grad/param norm = 2.3293e-01, time/batch = 0.6790s	
4282/11850 (epoch 18.068), train_loss = 1.32096095, grad/param norm = 2.1994e-01, time/batch = 0.6750s	
4283/11850 (epoch 18.072), train_loss = 1.32520944, grad/param norm = 2.1003e-01, time/batch = 0.6594s	
4284/11850 (epoch 18.076), train_loss = 1.45170407, grad/param norm = 2.1682e-01, time/batch = 0.6575s	
4285/11850 (epoch 18.080), train_loss = 1.26146143, grad/param norm = 2.2918e-01, time/batch = 0.6596s	
4286/11850 (epoch 18.084), train_loss = 1.15971224, grad/param norm = 2.0935e-01, time/batch = 0.6579s	
4287/11850 (epoch 18.089), train_loss = 1.19531143, grad/param norm = 2.0299e-01, time/batch = 0.6603s	
4288/11850 (epoch 18.093), train_loss = 1.16985721, grad/param norm = 2.6740e-01, time/batch = 0.6584s	
4289/11850 (epoch 18.097), train_loss = 1.36781510, grad/param norm = 2.5788e-01, time/batch = 0.6577s	
4290/11850 (epoch 18.101), train_loss = 1.30625910, grad/param norm = 2.6061e-01, time/batch = 0.6738s	
4291/11850 (epoch 18.105), train_loss = 1.22049090, grad/param norm = 2.3397e-01, time/batch = 0.6413s	
4292/11850 (epoch 18.110), train_loss = 1.36622166, grad/param norm = 2.2817e-01, time/batch = 0.6437s	
4293/11850 (epoch 18.114), train_loss = 1.33110214, grad/param norm = 2.4635e-01, time/batch = 0.6490s	
4294/11850 (epoch 18.118), train_loss = 1.29072554, grad/param norm = 2.0843e-01, time/batch = 0.6431s	
4295/11850 (epoch 18.122), train_loss = 1.40775356, grad/param norm = 2.4318e-01, time/batch = 0.6424s	
4296/11850 (epoch 18.127), train_loss = 1.35528279, grad/param norm = 2.4559e-01, time/batch = 0.6431s	
4297/11850 (epoch 18.131), train_loss = 1.34914911, grad/param norm = 2.8743e-01, time/batch = 0.6418s	
4298/11850 (epoch 18.135), train_loss = 1.29600644, grad/param norm = 2.4549e-01, time/batch = 0.6441s	
4299/11850 (epoch 18.139), train_loss = 1.26807791, grad/param norm = 2.2534e-01, time/batch = 0.6415s	
4300/11850 (epoch 18.143), train_loss = 1.29987004, grad/param norm = 2.4072e-01, time/batch = 0.6648s	
4301/11850 (epoch 18.148), train_loss = 1.33677536, grad/param norm = 2.5700e-01, time/batch = 0.6679s	
4302/11850 (epoch 18.152), train_loss = 1.42024101, grad/param norm = 2.7987e-01, time/batch = 0.6437s	
4303/11850 (epoch 18.156), train_loss = 1.36529136, grad/param norm = 2.8044e-01, time/batch = 0.6418s	
4304/11850 (epoch 18.160), train_loss = 1.61303907, grad/param norm = 3.1896e-01, time/batch = 0.6513s	
4305/11850 (epoch 18.165), train_loss = 1.45240447, grad/param norm = 2.6093e-01, time/batch = 0.6463s	
4306/11850 (epoch 18.169), train_loss = 1.31636088, grad/param norm = 2.7926e-01, time/batch = 0.6436s	
4307/11850 (epoch 18.173), train_loss = 1.38336977, grad/param norm = 2.3406e-01, time/batch = 0.6444s	
4308/11850 (epoch 18.177), train_loss = 1.29656793, grad/param norm = 2.7375e-01, time/batch = 0.6481s	
4309/11850 (epoch 18.181), train_loss = 1.41433688, grad/param norm = 2.3531e-01, time/batch = 0.6457s	
4310/11850 (epoch 18.186), train_loss = 1.47216017, grad/param norm = 2.7910e-01, time/batch = 0.6478s	
4311/11850 (epoch 18.190), train_loss = 1.35570054, grad/param norm = 2.1721e-01, time/batch = 0.6761s	
4312/11850 (epoch 18.194), train_loss = 1.46883888, grad/param norm = 2.6707e-01, time/batch = 0.6575s	
4313/11850 (epoch 18.198), train_loss = 1.22228731, grad/param norm = 2.2964e-01, time/batch = 0.6587s	
4314/11850 (epoch 18.203), train_loss = 1.20180691, grad/param norm = 2.1872e-01, time/batch = 0.6540s	
4315/11850 (epoch 18.207), train_loss = 1.37253245, grad/param norm = 2.3612e-01, time/batch = 0.6485s	
4316/11850 (epoch 18.211), train_loss = 1.32110078, grad/param norm = 2.1914e-01, time/batch = 0.6561s	
4317/11850 (epoch 18.215), train_loss = 1.33054183, grad/param norm = 2.6056e-01, time/batch = 0.6520s	
4318/11850 (epoch 18.219), train_loss = 1.30434689, grad/param norm = 2.3280e-01, time/batch = 0.6461s	
4319/11850 (epoch 18.224), train_loss = 1.50790646, grad/param norm = 2.4219e-01, time/batch = 0.6411s	
4320/11850 (epoch 18.228), train_loss = 1.44117103, grad/param norm = 2.6354e-01, time/batch = 0.6412s	
4321/11850 (epoch 18.232), train_loss = 1.38997767, grad/param norm = 2.3230e-01, time/batch = 0.6552s	
4322/11850 (epoch 18.236), train_loss = 1.25847936, grad/param norm = 2.4367e-01, time/batch = 0.6754s	
4323/11850 (epoch 18.241), train_loss = 1.49694377, grad/param norm = 2.5272e-01, time/batch = 0.6462s	
4324/11850 (epoch 18.245), train_loss = 1.41917984, grad/param norm = 2.4968e-01, time/batch = 0.6437s	
4325/11850 (epoch 18.249), train_loss = 1.25246635, grad/param norm = 2.2507e-01, time/batch = 0.6461s	
4326/11850 (epoch 18.253), train_loss = 1.34993636, grad/param norm = 2.6526e-01, time/batch = 0.6660s	
4327/11850 (epoch 18.257), train_loss = 1.45949674, grad/param norm = 2.3206e-01, time/batch = 0.6745s	
4328/11850 (epoch 18.262), train_loss = 1.51405292, grad/param norm = 2.7769e-01, time/batch = 0.6766s	
4329/11850 (epoch 18.266), train_loss = 1.42385219, grad/param norm = 2.4769e-01, time/batch = 0.6724s	
4330/11850 (epoch 18.270), train_loss = 1.28111627, grad/param norm = 2.1647e-01, time/batch = 0.6696s	
4331/11850 (epoch 18.274), train_loss = 1.29359109, grad/param norm = 2.4387e-01, time/batch = 0.6695s	
4332/11850 (epoch 18.278), train_loss = 1.17589949, grad/param norm = 2.3281e-01, time/batch = 0.6682s	
4333/11850 (epoch 18.283), train_loss = 1.25560405, grad/param norm = 2.1376e-01, time/batch = 0.6679s	
4334/11850 (epoch 18.287), train_loss = 1.43326491, grad/param norm = 2.3416e-01, time/batch = 0.6774s	
4335/11850 (epoch 18.291), train_loss = 1.35463536, grad/param norm = 2.2702e-01, time/batch = 0.6747s	
4336/11850 (epoch 18.295), train_loss = 1.35730083, grad/param norm = 2.3122e-01, time/batch = 0.6749s	
4337/11850 (epoch 18.300), train_loss = 1.29976836, grad/param norm = 2.5145e-01, time/batch = 0.6747s	
4338/11850 (epoch 18.304), train_loss = 1.28688146, grad/param norm = 2.1092e-01, time/batch = 0.6552s	
4339/11850 (epoch 18.308), train_loss = 1.28932069, grad/param norm = 2.2300e-01, time/batch = 0.6420s	
4340/11850 (epoch 18.312), train_loss = 1.14019776, grad/param norm = 2.0071e-01, time/batch = 0.6443s	
4341/11850 (epoch 18.316), train_loss = 1.36496941, grad/param norm = 2.2363e-01, time/batch = 0.6445s	
4342/11850 (epoch 18.321), train_loss = 1.26198356, grad/param norm = 2.0507e-01, time/batch = 0.6443s	
4343/11850 (epoch 18.325), train_loss = 1.31291158, grad/param norm = 2.4915e-01, time/batch = 0.6482s	
4344/11850 (epoch 18.329), train_loss = 1.29529265, grad/param norm = 2.4173e-01, time/batch = 0.6462s	
4345/11850 (epoch 18.333), train_loss = 1.30627224, grad/param norm = 2.4310e-01, time/batch = 0.6438s	
4346/11850 (epoch 18.338), train_loss = 1.21777021, grad/param norm = 2.0341e-01, time/batch = 0.6434s	
4347/11850 (epoch 18.342), train_loss = 1.39404849, grad/param norm = 2.5511e-01, time/batch = 0.6470s	
4348/11850 (epoch 18.346), train_loss = 1.32579983, grad/param norm = 2.3548e-01, time/batch = 0.6465s	
4349/11850 (epoch 18.350), train_loss = 1.18128919, grad/param norm = 2.3562e-01, time/batch = 0.6406s	
4350/11850 (epoch 18.354), train_loss = 1.39423393, grad/param norm = 2.3611e-01, time/batch = 0.6393s	
4351/11850 (epoch 18.359), train_loss = 1.40525831, grad/param norm = 2.7068e-01, time/batch = 0.6423s	
4352/11850 (epoch 18.363), train_loss = 1.36197349, grad/param norm = 2.3382e-01, time/batch = 0.6397s	
4353/11850 (epoch 18.367), train_loss = 1.35972231, grad/param norm = 2.1298e-01, time/batch = 0.6438s	
4354/11850 (epoch 18.371), train_loss = 1.36139675, grad/param norm = 2.2327e-01, time/batch = 0.6408s	
4355/11850 (epoch 18.376), train_loss = 1.29463831, grad/param norm = 2.3243e-01, time/batch = 0.6387s	
4356/11850 (epoch 18.380), train_loss = 1.23899926, grad/param norm = 2.1825e-01, time/batch = 0.6506s	
4357/11850 (epoch 18.384), train_loss = 1.21978977, grad/param norm = 2.4274e-01, time/batch = 0.6399s	
4358/11850 (epoch 18.388), train_loss = 1.40586899, grad/param norm = 2.2713e-01, time/batch = 0.6409s	
4359/11850 (epoch 18.392), train_loss = 1.42250750, grad/param norm = 2.4037e-01, time/batch = 0.6460s	
4360/11850 (epoch 18.397), train_loss = 1.39435567, grad/param norm = 2.8870e-01, time/batch = 0.6407s	
4361/11850 (epoch 18.401), train_loss = 1.18272608, grad/param norm = 2.0938e-01, time/batch = 0.6436s	
4362/11850 (epoch 18.405), train_loss = 1.24554196, grad/param norm = 2.1767e-01, time/batch = 0.6451s	
4363/11850 (epoch 18.409), train_loss = 1.40965013, grad/param norm = 2.2700e-01, time/batch = 0.6432s	
4364/11850 (epoch 18.414), train_loss = 1.18890536, grad/param norm = 2.2466e-01, time/batch = 0.6436s	
4365/11850 (epoch 18.418), train_loss = 1.19247605, grad/param norm = 2.2334e-01, time/batch = 0.6449s	
4366/11850 (epoch 18.422), train_loss = 1.14289172, grad/param norm = 2.1857e-01, time/batch = 0.6422s	
4367/11850 (epoch 18.426), train_loss = 1.18115079, grad/param norm = 2.5838e-01, time/batch = 0.6458s	
4368/11850 (epoch 18.430), train_loss = 1.23391780, grad/param norm = 2.2626e-01, time/batch = 0.6424s	
4369/11850 (epoch 18.435), train_loss = 1.23573999, grad/param norm = 2.3231e-01, time/batch = 0.6518s	
4370/11850 (epoch 18.439), train_loss = 1.39486941, grad/param norm = 2.2004e-01, time/batch = 0.6487s	
4371/11850 (epoch 18.443), train_loss = 1.34512025, grad/param norm = 2.2404e-01, time/batch = 0.6518s	
4372/11850 (epoch 18.447), train_loss = 1.19313212, grad/param norm = 2.3998e-01, time/batch = 0.6649s	
4373/11850 (epoch 18.451), train_loss = 1.20398186, grad/param norm = 2.2713e-01, time/batch = 0.6777s	
4374/11850 (epoch 18.456), train_loss = 1.27171911, grad/param norm = 2.4615e-01, time/batch = 0.6689s	
4375/11850 (epoch 18.460), train_loss = 1.31088639, grad/param norm = 2.3435e-01, time/batch = 0.6515s	
4376/11850 (epoch 18.464), train_loss = 1.23407923, grad/param norm = 2.4000e-01, time/batch = 0.6458s	
4377/11850 (epoch 18.468), train_loss = 1.30186922, grad/param norm = 2.1510e-01, time/batch = 0.6497s	
4378/11850 (epoch 18.473), train_loss = 1.34588170, grad/param norm = 2.4098e-01, time/batch = 0.6633s	
4379/11850 (epoch 18.477), train_loss = 1.19952395, grad/param norm = 2.4179e-01, time/batch = 0.6723s	
4380/11850 (epoch 18.481), train_loss = 1.23228555, grad/param norm = 2.4942e-01, time/batch = 0.6576s	
4381/11850 (epoch 18.485), train_loss = 1.18067053, grad/param norm = 2.1188e-01, time/batch = 0.6443s	
4382/11850 (epoch 18.489), train_loss = 1.34056618, grad/param norm = 2.4842e-01, time/batch = 0.6434s	
4383/11850 (epoch 18.494), train_loss = 1.23546635, grad/param norm = 2.5013e-01, time/batch = 0.6410s	
4384/11850 (epoch 18.498), train_loss = 1.22190835, grad/param norm = 2.4680e-01, time/batch = 0.6442s	
4385/11850 (epoch 18.502), train_loss = 1.16942482, grad/param norm = 2.6728e-01, time/batch = 0.6459s	
4386/11850 (epoch 18.506), train_loss = 1.42223128, grad/param norm = 2.4310e-01, time/batch = 0.6483s	
4387/11850 (epoch 18.511), train_loss = 1.29590731, grad/param norm = 2.2921e-01, time/batch = 0.6422s	
4388/11850 (epoch 18.515), train_loss = 1.41599637, grad/param norm = 2.5836e-01, time/batch = 0.6482s	
4389/11850 (epoch 18.519), train_loss = 1.23087484, grad/param norm = 2.1948e-01, time/batch = 0.6433s	
4390/11850 (epoch 18.523), train_loss = 1.25600698, grad/param norm = 2.1857e-01, time/batch = 0.6471s	
4391/11850 (epoch 18.527), train_loss = 1.18465738, grad/param norm = 2.3927e-01, time/batch = 0.6451s	
4392/11850 (epoch 18.532), train_loss = 1.35145545, grad/param norm = 2.2643e-01, time/batch = 0.6497s	
4393/11850 (epoch 18.536), train_loss = 1.21733834, grad/param norm = 2.1023e-01, time/batch = 0.6483s	
4394/11850 (epoch 18.540), train_loss = 1.19198412, grad/param norm = 2.1351e-01, time/batch = 0.6429s	
4395/11850 (epoch 18.544), train_loss = 1.25953770, grad/param norm = 2.4331e-01, time/batch = 0.6428s	
4396/11850 (epoch 18.549), train_loss = 1.10435804, grad/param norm = 2.0739e-01, time/batch = 0.6427s	
4397/11850 (epoch 18.553), train_loss = 1.31697384, grad/param norm = 2.3033e-01, time/batch = 0.6404s	
4398/11850 (epoch 18.557), train_loss = 1.41108840, grad/param norm = 2.6652e-01, time/batch = 0.6407s	
4399/11850 (epoch 18.561), train_loss = 1.31314469, grad/param norm = 2.4288e-01, time/batch = 0.6441s	
4400/11850 (epoch 18.565), train_loss = 1.43640734, grad/param norm = 2.5355e-01, time/batch = 0.6450s	
4401/11850 (epoch 18.570), train_loss = 1.27234474, grad/param norm = 2.2328e-01, time/batch = 0.6734s	
4402/11850 (epoch 18.574), train_loss = 1.37842709, grad/param norm = 2.4170e-01, time/batch = 0.6703s	
4403/11850 (epoch 18.578), train_loss = 1.42829359, grad/param norm = 2.8231e-01, time/batch = 0.6488s	
4404/11850 (epoch 18.582), train_loss = 1.24116656, grad/param norm = 2.6985e-01, time/batch = 0.6450s	
4405/11850 (epoch 18.586), train_loss = 1.26562833, grad/param norm = 2.2983e-01, time/batch = 0.6465s	
4406/11850 (epoch 18.591), train_loss = 1.38180346, grad/param norm = 2.3053e-01, time/batch = 0.6400s	
4407/11850 (epoch 18.595), train_loss = 1.14601441, grad/param norm = 2.3659e-01, time/batch = 0.6398s	
4408/11850 (epoch 18.599), train_loss = 1.25982213, grad/param norm = 2.3925e-01, time/batch = 0.6446s	
4409/11850 (epoch 18.603), train_loss = 1.21841984, grad/param norm = 2.2921e-01, time/batch = 0.6404s	
4410/11850 (epoch 18.608), train_loss = 1.41410103, grad/param norm = 2.3092e-01, time/batch = 0.6432s	
4411/11850 (epoch 18.612), train_loss = 1.49521824, grad/param norm = 2.5695e-01, time/batch = 0.6457s	
4412/11850 (epoch 18.616), train_loss = 1.41111082, grad/param norm = 2.1993e-01, time/batch = 0.6751s	
4413/11850 (epoch 18.620), train_loss = 1.26822829, grad/param norm = 2.2523e-01, time/batch = 0.6516s	
4414/11850 (epoch 18.624), train_loss = 1.32029586, grad/param norm = 2.4419e-01, time/batch = 0.6400s	
4415/11850 (epoch 18.629), train_loss = 1.22710446, grad/param norm = 2.3277e-01, time/batch = 0.6411s	
4416/11850 (epoch 18.633), train_loss = 1.15744116, grad/param norm = 2.3706e-01, time/batch = 0.6388s	
4417/11850 (epoch 18.637), train_loss = 1.16101656, grad/param norm = 2.3161e-01, time/batch = 0.6443s	
4418/11850 (epoch 18.641), train_loss = 1.16402553, grad/param norm = 2.1686e-01, time/batch = 0.6372s	
4419/11850 (epoch 18.646), train_loss = 1.24997266, grad/param norm = 2.3254e-01, time/batch = 0.6403s	
4420/11850 (epoch 18.650), train_loss = 1.28246609, grad/param norm = 2.5858e-01, time/batch = 0.6399s	
4421/11850 (epoch 18.654), train_loss = 1.24350933, grad/param norm = 2.6418e-01, time/batch = 0.6450s	
4422/11850 (epoch 18.658), train_loss = 1.31310501, grad/param norm = 2.4740e-01, time/batch = 0.6517s	
4423/11850 (epoch 18.662), train_loss = 1.20067313, grad/param norm = 2.6567e-01, time/batch = 0.6745s	
4424/11850 (epoch 18.667), train_loss = 1.38080338, grad/param norm = 2.5730e-01, time/batch = 0.6451s	
4425/11850 (epoch 18.671), train_loss = 1.24691912, grad/param norm = 2.1678e-01, time/batch = 0.6452s	
4426/11850 (epoch 18.675), train_loss = 1.25902826, grad/param norm = 2.2161e-01, time/batch = 0.6458s	
4427/11850 (epoch 18.679), train_loss = 1.31453158, grad/param norm = 2.3333e-01, time/batch = 0.6386s	
4428/11850 (epoch 18.684), train_loss = 1.30386162, grad/param norm = 2.4958e-01, time/batch = 0.6401s	
4429/11850 (epoch 18.688), train_loss = 1.21250137, grad/param norm = 2.0485e-01, time/batch = 0.6401s	
4430/11850 (epoch 18.692), train_loss = 1.28033757, grad/param norm = 2.6156e-01, time/batch = 0.6427s	
4431/11850 (epoch 18.696), train_loss = 1.18704792, grad/param norm = 2.3555e-01, time/batch = 0.6482s	
4432/11850 (epoch 18.700), train_loss = 1.28914618, grad/param norm = 2.4300e-01, time/batch = 0.6603s	
4433/11850 (epoch 18.705), train_loss = 1.25317329, grad/param norm = 2.4485e-01, time/batch = 0.6711s	
4434/11850 (epoch 18.709), train_loss = 1.15902977, grad/param norm = 2.2174e-01, time/batch = 0.6758s	
4435/11850 (epoch 18.713), train_loss = 1.22201031, grad/param norm = 2.6336e-01, time/batch = 0.6718s	
4436/11850 (epoch 18.717), train_loss = 1.20986986, grad/param norm = 2.4356e-01, time/batch = 0.6718s	
4437/11850 (epoch 18.722), train_loss = 1.31003202, grad/param norm = 2.6219e-01, time/batch = 0.6692s	
4438/11850 (epoch 18.726), train_loss = 1.16710599, grad/param norm = 2.4619e-01, time/batch = 0.6723s	
4439/11850 (epoch 18.730), train_loss = 1.13369938, grad/param norm = 2.1685e-01, time/batch = 0.6722s	
4440/11850 (epoch 18.734), train_loss = 1.21583287, grad/param norm = 2.2831e-01, time/batch = 0.6689s	
4441/11850 (epoch 18.738), train_loss = 1.37498154, grad/param norm = 2.5340e-01, time/batch = 0.6558s	
4442/11850 (epoch 18.743), train_loss = 1.29609770, grad/param norm = 2.3453e-01, time/batch = 0.6552s	
4443/11850 (epoch 18.747), train_loss = 1.12491943, grad/param norm = 2.1251e-01, time/batch = 0.6378s	
4444/11850 (epoch 18.751), train_loss = 1.14966692, grad/param norm = 2.1596e-01, time/batch = 0.6373s	
4445/11850 (epoch 18.755), train_loss = 1.27306792, grad/param norm = 2.2641e-01, time/batch = 0.6416s	
4446/11850 (epoch 18.759), train_loss = 1.18649895, grad/param norm = 2.2650e-01, time/batch = 0.6404s	
4447/11850 (epoch 18.764), train_loss = 1.25161736, grad/param norm = 2.3796e-01, time/batch = 0.6389s	
4448/11850 (epoch 18.768), train_loss = 1.11670808, grad/param norm = 2.1292e-01, time/batch = 0.6508s	
4449/11850 (epoch 18.772), train_loss = 1.23815647, grad/param norm = 2.2130e-01, time/batch = 0.6443s	
4450/11850 (epoch 18.776), train_loss = 1.25765833, grad/param norm = 2.2362e-01, time/batch = 0.6455s	
4451/11850 (epoch 18.781), train_loss = 1.23317925, grad/param norm = 2.3054e-01, time/batch = 0.6442s	
4452/11850 (epoch 18.785), train_loss = 1.19912704, grad/param norm = 2.2051e-01, time/batch = 0.6434s	
4453/11850 (epoch 18.789), train_loss = 1.29840933, grad/param norm = 2.3860e-01, time/batch = 0.6429s	
4454/11850 (epoch 18.793), train_loss = 1.37864836, grad/param norm = 2.5639e-01, time/batch = 0.6539s	
4455/11850 (epoch 18.797), train_loss = 1.30203771, grad/param norm = 2.7014e-01, time/batch = 0.6747s	
4456/11850 (epoch 18.802), train_loss = 1.15908018, grad/param norm = 2.2839e-01, time/batch = 0.6578s	
4457/11850 (epoch 18.806), train_loss = 1.26464340, grad/param norm = 2.2850e-01, time/batch = 0.6553s	
4458/11850 (epoch 18.810), train_loss = 1.40763104, grad/param norm = 2.6032e-01, time/batch = 0.6502s	
4459/11850 (epoch 18.814), train_loss = 1.24814970, grad/param norm = 2.3666e-01, time/batch = 0.6408s	
4460/11850 (epoch 18.819), train_loss = 1.40108953, grad/param norm = 2.3676e-01, time/batch = 0.6395s	
4461/11850 (epoch 18.823), train_loss = 1.41983515, grad/param norm = 2.4912e-01, time/batch = 0.6434s	
4462/11850 (epoch 18.827), train_loss = 1.29654309, grad/param norm = 2.4976e-01, time/batch = 0.6410s	
4463/11850 (epoch 18.831), train_loss = 1.29783690, grad/param norm = 2.5159e-01, time/batch = 0.6536s	
4464/11850 (epoch 18.835), train_loss = 1.26361476, grad/param norm = 2.2270e-01, time/batch = 0.6718s	
4465/11850 (epoch 18.840), train_loss = 1.23527316, grad/param norm = 2.2896e-01, time/batch = 0.6784s	
4466/11850 (epoch 18.844), train_loss = 1.25336364, grad/param norm = 2.1241e-01, time/batch = 0.6520s	
4467/11850 (epoch 18.848), train_loss = 1.31312353, grad/param norm = 2.4635e-01, time/batch = 0.6434s	
4468/11850 (epoch 18.852), train_loss = 1.26816221, grad/param norm = 2.3548e-01, time/batch = 0.6438s	
4469/11850 (epoch 18.857), train_loss = 1.27673022, grad/param norm = 2.5902e-01, time/batch = 0.6487s	
4470/11850 (epoch 18.861), train_loss = 1.28805696, grad/param norm = 2.4301e-01, time/batch = 0.6641s	
4471/11850 (epoch 18.865), train_loss = 1.34351894, grad/param norm = 2.8799e-01, time/batch = 0.6565s	
4472/11850 (epoch 18.869), train_loss = 1.33362659, grad/param norm = 2.6113e-01, time/batch = 0.6467s	
4473/11850 (epoch 18.873), train_loss = 1.33617845, grad/param norm = 2.4222e-01, time/batch = 0.6432s	
4474/11850 (epoch 18.878), train_loss = 1.33898837, grad/param norm = 2.6181e-01, time/batch = 0.6457s	
4475/11850 (epoch 18.882), train_loss = 1.30916871, grad/param norm = 2.3351e-01, time/batch = 0.6427s	
4476/11850 (epoch 18.886), train_loss = 1.35066447, grad/param norm = 2.7785e-01, time/batch = 0.6426s	
4477/11850 (epoch 18.890), train_loss = 1.34053545, grad/param norm = 2.8663e-01, time/batch = 0.6475s	
4478/11850 (epoch 18.895), train_loss = 1.32406529, grad/param norm = 3.4047e-01, time/batch = 0.6471s	
4479/11850 (epoch 18.899), train_loss = 1.18890786, grad/param norm = 2.6381e-01, time/batch = 0.6437s	
4480/11850 (epoch 18.903), train_loss = 1.27044028, grad/param norm = 2.5267e-01, time/batch = 0.6446s	
4481/11850 (epoch 18.907), train_loss = 1.24537051, grad/param norm = 2.6828e-01, time/batch = 0.6456s	
4482/11850 (epoch 18.911), train_loss = 1.34734814, grad/param norm = 2.4042e-01, time/batch = 0.6465s	
4483/11850 (epoch 18.916), train_loss = 1.37922005, grad/param norm = 2.5705e-01, time/batch = 0.6456s	
4484/11850 (epoch 18.920), train_loss = 1.27762145, grad/param norm = 2.5281e-01, time/batch = 0.6440s	
4485/11850 (epoch 18.924), train_loss = 1.28099509, grad/param norm = 2.2880e-01, time/batch = 0.6413s	
4486/11850 (epoch 18.928), train_loss = 1.37196596, grad/param norm = 3.0665e-01, time/batch = 0.6499s	
4487/11850 (epoch 18.932), train_loss = 1.39112897, grad/param norm = 2.5508e-01, time/batch = 0.6738s	
4488/11850 (epoch 18.937), train_loss = 1.34356366, grad/param norm = 2.4830e-01, time/batch = 0.6533s	
4489/11850 (epoch 18.941), train_loss = 1.35472649, grad/param norm = 2.3129e-01, time/batch = 0.6433s	
4490/11850 (epoch 18.945), train_loss = 1.36378032, grad/param norm = 2.3259e-01, time/batch = 0.6411s	
4491/11850 (epoch 18.949), train_loss = 1.24678191, grad/param norm = 2.5805e-01, time/batch = 0.6476s	
4492/11850 (epoch 18.954), train_loss = 1.35680046, grad/param norm = 2.9385e-01, time/batch = 0.6593s	
4493/11850 (epoch 18.958), train_loss = 1.33030727, grad/param norm = 2.4673e-01, time/batch = 0.6446s	
4494/11850 (epoch 18.962), train_loss = 1.20255153, grad/param norm = 2.5874e-01, time/batch = 0.6458s	
4495/11850 (epoch 18.966), train_loss = 1.16228250, grad/param norm = 2.2651e-01, time/batch = 0.6465s	
4496/11850 (epoch 18.970), train_loss = 1.28789562, grad/param norm = 2.2421e-01, time/batch = 0.6423s	
4497/11850 (epoch 18.975), train_loss = 1.28493997, grad/param norm = 2.5973e-01, time/batch = 0.6472s	
4498/11850 (epoch 18.979), train_loss = 1.29878234, grad/param norm = 4.2798e-01, time/batch = 0.6425s	
4499/11850 (epoch 18.983), train_loss = 1.48701308, grad/param norm = 1.1754e+00, time/batch = 0.6451s	
4500/11850 (epoch 18.987), train_loss = 1.27814254, grad/param norm = 2.6509e-01, time/batch = 0.6589s	
4501/11850 (epoch 18.992), train_loss = 1.43985277, grad/param norm = 2.3397e-01, time/batch = 0.6473s	
4502/11850 (epoch 18.996), train_loss = 1.51472488, grad/param norm = 2.7323e-01, time/batch = 0.6463s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
4503/11850 (epoch 19.000), train_loss = 1.28252302, grad/param norm = 2.6766e-01, time/batch = 0.6384s	
4504/11850 (epoch 19.004), train_loss = 1.36955643, grad/param norm = 2.5619e-01, time/batch = 0.6261s	
4505/11850 (epoch 19.008), train_loss = 1.39241333, grad/param norm = 2.3122e-01, time/batch = 0.6261s	
4506/11850 (epoch 19.013), train_loss = 1.37421949, grad/param norm = 2.4632e-01, time/batch = 0.6252s	
4507/11850 (epoch 19.017), train_loss = 1.50241297, grad/param norm = 2.6956e-01, time/batch = 0.6251s	
4508/11850 (epoch 19.021), train_loss = 1.30939076, grad/param norm = 2.1787e-01, time/batch = 0.6423s	
4509/11850 (epoch 19.025), train_loss = 1.17398295, grad/param norm = 2.2102e-01, time/batch = 0.6589s	
4510/11850 (epoch 19.030), train_loss = 1.21233806, grad/param norm = 2.3315e-01, time/batch = 0.6499s	
4511/11850 (epoch 19.034), train_loss = 1.23693580, grad/param norm = 2.3175e-01, time/batch = 0.6605s	
4512/11850 (epoch 19.038), train_loss = 1.30961007, grad/param norm = 2.3043e-01, time/batch = 0.6580s	
4513/11850 (epoch 19.042), train_loss = 1.30183671, grad/param norm = 2.7085e-01, time/batch = 0.6246s	
4514/11850 (epoch 19.046), train_loss = 1.34787067, grad/param norm = 2.7244e-01, time/batch = 0.6243s	
4515/11850 (epoch 19.051), train_loss = 1.29518369, grad/param norm = 2.3320e-01, time/batch = 0.6221s	
4516/11850 (epoch 19.055), train_loss = 1.27150677, grad/param norm = 2.3460e-01, time/batch = 0.6217s	
4517/11850 (epoch 19.059), train_loss = 1.36449582, grad/param norm = 2.4305e-01, time/batch = 0.6379s	
4518/11850 (epoch 19.063), train_loss = 1.32107727, grad/param norm = 2.3421e-01, time/batch = 0.6348s	
4519/11850 (epoch 19.068), train_loss = 1.30299184, grad/param norm = 2.3396e-01, time/batch = 0.6500s	
4520/11850 (epoch 19.072), train_loss = 1.30328536, grad/param norm = 2.2219e-01, time/batch = 0.6532s	
4521/11850 (epoch 19.076), train_loss = 1.42664421, grad/param norm = 2.2016e-01, time/batch = 0.6234s	
4522/11850 (epoch 19.080), train_loss = 1.21451383, grad/param norm = 2.0667e-01, time/batch = 0.6247s	
4523/11850 (epoch 19.084), train_loss = 1.13783939, grad/param norm = 2.1527e-01, time/batch = 0.6223s	
4524/11850 (epoch 19.089), train_loss = 1.16737566, grad/param norm = 2.0328e-01, time/batch = 0.6257s	
4525/11850 (epoch 19.093), train_loss = 1.15759977, grad/param norm = 2.5709e-01, time/batch = 0.6251s	
4526/11850 (epoch 19.097), train_loss = 1.32472920, grad/param norm = 2.5367e-01, time/batch = 0.6245s	
4527/11850 (epoch 19.101), train_loss = 1.25749808, grad/param norm = 2.4406e-01, time/batch = 0.6295s	
4528/11850 (epoch 19.105), train_loss = 1.18270026, grad/param norm = 2.3030e-01, time/batch = 0.6275s	
4529/11850 (epoch 19.110), train_loss = 1.34211377, grad/param norm = 2.3212e-01, time/batch = 0.6240s	
4530/11850 (epoch 19.114), train_loss = 1.29528566, grad/param norm = 2.5356e-01, time/batch = 0.6424s	
4531/11850 (epoch 19.118), train_loss = 1.27821287, grad/param norm = 2.2001e-01, time/batch = 0.6586s	
4532/11850 (epoch 19.122), train_loss = 1.38008594, grad/param norm = 2.4358e-01, time/batch = 0.6292s	
4533/11850 (epoch 19.127), train_loss = 1.33263622, grad/param norm = 2.5244e-01, time/batch = 0.6297s	
4534/11850 (epoch 19.131), train_loss = 1.31593145, grad/param norm = 2.6966e-01, time/batch = 0.6240s	
4535/11850 (epoch 19.135), train_loss = 1.26168553, grad/param norm = 2.5240e-01, time/batch = 0.6296s	
4536/11850 (epoch 19.139), train_loss = 1.23669717, grad/param norm = 2.4010e-01, time/batch = 0.6232s	
4537/11850 (epoch 19.143), train_loss = 1.27395027, grad/param norm = 2.6560e-01, time/batch = 0.6217s	
4538/11850 (epoch 19.148), train_loss = 1.30581207, grad/param norm = 2.6321e-01, time/batch = 0.6239s	
4539/11850 (epoch 19.152), train_loss = 1.38801149, grad/param norm = 2.6743e-01, time/batch = 0.6214s	
4540/11850 (epoch 19.156), train_loss = 1.33490791, grad/param norm = 2.6620e-01, time/batch = 0.6214s	
4541/11850 (epoch 19.160), train_loss = 1.56827661, grad/param norm = 2.9596e-01, time/batch = 0.6422s	
4542/11850 (epoch 19.165), train_loss = 1.44239557, grad/param norm = 2.6690e-01, time/batch = 0.6343s	
4543/11850 (epoch 19.169), train_loss = 1.28159444, grad/param norm = 2.7319e-01, time/batch = 0.6305s	
4544/11850 (epoch 19.173), train_loss = 1.36442628, grad/param norm = 2.9782e-01, time/batch = 0.6282s	
4545/11850 (epoch 19.177), train_loss = 1.25588850, grad/param norm = 2.6310e-01, time/batch = 0.6237s	
4546/11850 (epoch 19.181), train_loss = 1.37499038, grad/param norm = 2.3148e-01, time/batch = 0.6244s	
4547/11850 (epoch 19.186), train_loss = 1.43902281, grad/param norm = 2.7850e-01, time/batch = 0.6276s	
4548/11850 (epoch 19.190), train_loss = 1.32774803, grad/param norm = 2.3380e-01, time/batch = 0.6255s	
4549/11850 (epoch 19.194), train_loss = 1.43315674, grad/param norm = 2.7548e-01, time/batch = 0.6239s	
4550/11850 (epoch 19.198), train_loss = 1.18886788, grad/param norm = 2.6650e-01, time/batch = 0.6256s	
4551/11850 (epoch 19.203), train_loss = 1.17821867, grad/param norm = 2.2150e-01, time/batch = 0.6251s	
4552/11850 (epoch 19.207), train_loss = 1.34411582, grad/param norm = 2.4069e-01, time/batch = 0.6357s	
4553/11850 (epoch 19.211), train_loss = 1.29692027, grad/param norm = 2.3806e-01, time/batch = 0.6435s	
4554/11850 (epoch 19.215), train_loss = 1.30309923, grad/param norm = 2.3787e-01, time/batch = 0.6303s	
4555/11850 (epoch 19.219), train_loss = 1.27021252, grad/param norm = 2.3256e-01, time/batch = 0.6284s	
4556/11850 (epoch 19.224), train_loss = 1.46557401, grad/param norm = 2.4442e-01, time/batch = 0.6282s	
4557/11850 (epoch 19.228), train_loss = 1.40188393, grad/param norm = 2.4787e-01, time/batch = 0.6468s	
4558/11850 (epoch 19.232), train_loss = 1.35974836, grad/param norm = 2.3236e-01, time/batch = 0.6570s	
4559/11850 (epoch 19.236), train_loss = 1.23066231, grad/param norm = 2.7200e-01, time/batch = 0.6540s	
4560/11850 (epoch 19.241), train_loss = 1.46215233, grad/param norm = 2.6736e-01, time/batch = 0.6470s	
4561/11850 (epoch 19.245), train_loss = 1.38550709, grad/param norm = 2.3518e-01, time/batch = 0.6505s	
4562/11850 (epoch 19.249), train_loss = 1.23167565, grad/param norm = 2.3054e-01, time/batch = 0.6385s	
4563/11850 (epoch 19.253), train_loss = 1.31641803, grad/param norm = 2.6371e-01, time/batch = 0.6306s	
4564/11850 (epoch 19.257), train_loss = 1.42296754, grad/param norm = 2.2905e-01, time/batch = 0.6260s	
4565/11850 (epoch 19.262), train_loss = 1.47999879, grad/param norm = 2.4725e-01, time/batch = 0.6270s	
4566/11850 (epoch 19.266), train_loss = 1.37468703, grad/param norm = 2.3827e-01, time/batch = 0.6246s	
4567/11850 (epoch 19.270), train_loss = 1.25265115, grad/param norm = 2.2100e-01, time/batch = 0.6230s	
4568/11850 (epoch 19.274), train_loss = 1.25758935, grad/param norm = 2.3954e-01, time/batch = 0.6322s	
4569/11850 (epoch 19.278), train_loss = 1.14165534, grad/param norm = 2.3869e-01, time/batch = 0.6426s	
4570/11850 (epoch 19.283), train_loss = 1.23155420, grad/param norm = 2.2405e-01, time/batch = 0.6414s	
4571/11850 (epoch 19.287), train_loss = 1.39944556, grad/param norm = 2.3520e-01, time/batch = 0.6310s	
4572/11850 (epoch 19.291), train_loss = 1.31444085, grad/param norm = 2.2360e-01, time/batch = 0.6264s	
4573/11850 (epoch 19.295), train_loss = 1.32685437, grad/param norm = 2.3043e-01, time/batch = 0.6275s	
4574/11850 (epoch 19.300), train_loss = 1.26696278, grad/param norm = 2.5282e-01, time/batch = 0.6276s	
4575/11850 (epoch 19.304), train_loss = 1.26224339, grad/param norm = 2.1642e-01, time/batch = 0.6281s	
4576/11850 (epoch 19.308), train_loss = 1.25339412, grad/param norm = 2.2273e-01, time/batch = 0.6284s	
4577/11850 (epoch 19.312), train_loss = 1.11521277, grad/param norm = 2.0137e-01, time/batch = 0.6240s	
4578/11850 (epoch 19.316), train_loss = 1.34341763, grad/param norm = 2.2860e-01, time/batch = 0.6259s	
4579/11850 (epoch 19.321), train_loss = 1.23781824, grad/param norm = 2.1174e-01, time/batch = 0.6260s	
4580/11850 (epoch 19.325), train_loss = 1.28775557, grad/param norm = 2.5115e-01, time/batch = 0.6251s	
4581/11850 (epoch 19.329), train_loss = 1.27028878, grad/param norm = 2.5162e-01, time/batch = 0.6249s	
4582/11850 (epoch 19.333), train_loss = 1.27675681, grad/param norm = 2.4176e-01, time/batch = 0.6255s	
4583/11850 (epoch 19.338), train_loss = 1.18682877, grad/param norm = 2.0390e-01, time/batch = 0.6236s	
4584/11850 (epoch 19.342), train_loss = 1.35867784, grad/param norm = 2.7029e-01, time/batch = 0.6269s	
4585/11850 (epoch 19.346), train_loss = 1.29421711, grad/param norm = 2.3629e-01, time/batch = 0.6374s	
4586/11850 (epoch 19.350), train_loss = 1.15095454, grad/param norm = 2.3503e-01, time/batch = 0.6563s	
4587/11850 (epoch 19.354), train_loss = 1.37577415, grad/param norm = 2.4201e-01, time/batch = 0.6319s	
4588/11850 (epoch 19.359), train_loss = 1.39116673, grad/param norm = 2.5727e-01, time/batch = 0.6267s	
4589/11850 (epoch 19.363), train_loss = 1.33121723, grad/param norm = 2.2902e-01, time/batch = 0.6267s	
4590/11850 (epoch 19.367), train_loss = 1.33154913, grad/param norm = 2.1530e-01, time/batch = 0.6274s	
4591/11850 (epoch 19.371), train_loss = 1.34304461, grad/param norm = 2.3551e-01, time/batch = 0.6265s	
4592/11850 (epoch 19.376), train_loss = 1.26924547, grad/param norm = 2.3010e-01, time/batch = 0.6240s	
4593/11850 (epoch 19.380), train_loss = 1.20441774, grad/param norm = 2.1262e-01, time/batch = 0.6262s	
4594/11850 (epoch 19.384), train_loss = 1.19995131, grad/param norm = 2.4169e-01, time/batch = 0.6308s	
4595/11850 (epoch 19.388), train_loss = 1.37487928, grad/param norm = 2.3902e-01, time/batch = 0.6273s	
4596/11850 (epoch 19.392), train_loss = 1.38513518, grad/param norm = 2.3801e-01, time/batch = 0.6361s	
4597/11850 (epoch 19.397), train_loss = 1.36789223, grad/param norm = 2.9652e-01, time/batch = 0.6564s	
4598/11850 (epoch 19.401), train_loss = 1.14950246, grad/param norm = 1.9926e-01, time/batch = 0.6294s	
4599/11850 (epoch 19.405), train_loss = 1.21968362, grad/param norm = 2.2624e-01, time/batch = 0.6221s	
4600/11850 (epoch 19.409), train_loss = 1.37206687, grad/param norm = 2.3865e-01, time/batch = 0.6239s	
4601/11850 (epoch 19.414), train_loss = 1.16051696, grad/param norm = 2.1097e-01, time/batch = 0.6252s	
4602/11850 (epoch 19.418), train_loss = 1.17913696, grad/param norm = 2.4243e-01, time/batch = 0.6220s	
4603/11850 (epoch 19.422), train_loss = 1.10678798, grad/param norm = 2.2056e-01, time/batch = 0.6248s	
4604/11850 (epoch 19.426), train_loss = 1.14745898, grad/param norm = 2.3234e-01, time/batch = 0.6372s	
4605/11850 (epoch 19.430), train_loss = 1.20207565, grad/param norm = 2.3173e-01, time/batch = 0.6251s	
4606/11850 (epoch 19.435), train_loss = 1.20831511, grad/param norm = 2.2841e-01, time/batch = 0.6272s	
4607/11850 (epoch 19.439), train_loss = 1.35886227, grad/param norm = 2.3325e-01, time/batch = 0.6361s	
4608/11850 (epoch 19.443), train_loss = 1.31204647, grad/param norm = 2.3381e-01, time/batch = 0.6568s	
4609/11850 (epoch 19.447), train_loss = 1.15094967, grad/param norm = 2.1840e-01, time/batch = 0.6416s	
4610/11850 (epoch 19.451), train_loss = 1.17269123, grad/param norm = 2.2085e-01, time/batch = 0.6486s	
4611/11850 (epoch 19.456), train_loss = 1.24358440, grad/param norm = 2.4469e-01, time/batch = 0.6440s	
4612/11850 (epoch 19.460), train_loss = 1.27863115, grad/param norm = 2.2918e-01, time/batch = 0.6390s	
4613/11850 (epoch 19.464), train_loss = 1.20172617, grad/param norm = 2.3241e-01, time/batch = 0.6366s	
4614/11850 (epoch 19.468), train_loss = 1.28625313, grad/param norm = 2.4270e-01, time/batch = 0.6274s	
4615/11850 (epoch 19.473), train_loss = 1.31750837, grad/param norm = 2.4120e-01, time/batch = 0.6259s	
4616/11850 (epoch 19.477), train_loss = 1.16514374, grad/param norm = 2.4546e-01, time/batch = 0.6269s	
4617/11850 (epoch 19.481), train_loss = 1.19185108, grad/param norm = 2.3237e-01, time/batch = 0.6263s	
4618/11850 (epoch 19.485), train_loss = 1.15151059, grad/param norm = 2.1288e-01, time/batch = 0.6242s	
4619/11850 (epoch 19.489), train_loss = 1.30389732, grad/param norm = 2.3174e-01, time/batch = 0.6234s	
4620/11850 (epoch 19.494), train_loss = 1.19847337, grad/param norm = 2.3362e-01, time/batch = 0.6231s	
4621/11850 (epoch 19.498), train_loss = 1.18510133, grad/param norm = 2.4034e-01, time/batch = 0.6417s	
4622/11850 (epoch 19.502), train_loss = 1.12736367, grad/param norm = 2.4475e-01, time/batch = 0.6324s	
4623/11850 (epoch 19.506), train_loss = 1.39933471, grad/param norm = 2.5323e-01, time/batch = 0.6278s	
4624/11850 (epoch 19.511), train_loss = 1.25956602, grad/param norm = 2.2471e-01, time/batch = 0.6279s	
4625/11850 (epoch 19.515), train_loss = 1.38536684, grad/param norm = 2.4573e-01, time/batch = 0.6267s	
4626/11850 (epoch 19.519), train_loss = 1.20261455, grad/param norm = 2.2139e-01, time/batch = 0.6289s	
4627/11850 (epoch 19.523), train_loss = 1.22817631, grad/param norm = 2.2418e-01, time/batch = 0.6249s	
4628/11850 (epoch 19.527), train_loss = 1.15809774, grad/param norm = 2.3836e-01, time/batch = 0.6269s	
4629/11850 (epoch 19.532), train_loss = 1.31929589, grad/param norm = 2.2745e-01, time/batch = 0.6247s	
4630/11850 (epoch 19.536), train_loss = 1.19499212, grad/param norm = 2.1619e-01, time/batch = 0.6236s	
4631/11850 (epoch 19.540), train_loss = 1.16630266, grad/param norm = 2.1551e-01, time/batch = 0.6244s	
4632/11850 (epoch 19.544), train_loss = 1.21461338, grad/param norm = 2.3747e-01, time/batch = 0.6250s	
4633/11850 (epoch 19.549), train_loss = 1.08315054, grad/param norm = 2.0985e-01, time/batch = 0.6313s	
4634/11850 (epoch 19.553), train_loss = 1.28778817, grad/param norm = 2.4059e-01, time/batch = 0.6281s	
4635/11850 (epoch 19.557), train_loss = 1.36432079, grad/param norm = 2.5476e-01, time/batch = 0.6275s	
4636/11850 (epoch 19.561), train_loss = 1.28911034, grad/param norm = 2.6180e-01, time/batch = 0.6386s	
4637/11850 (epoch 19.565), train_loss = 1.40215373, grad/param norm = 2.4391e-01, time/batch = 0.6437s	
4638/11850 (epoch 19.570), train_loss = 1.24499198, grad/param norm = 2.2059e-01, time/batch = 0.6518s	
4639/11850 (epoch 19.574), train_loss = 1.35307452, grad/param norm = 2.5954e-01, time/batch = 0.6412s	
4640/11850 (epoch 19.578), train_loss = 1.39569212, grad/param norm = 2.4782e-01, time/batch = 0.6475s	
4641/11850 (epoch 19.582), train_loss = 1.20536261, grad/param norm = 2.3708e-01, time/batch = 0.6427s	
4642/11850 (epoch 19.586), train_loss = 1.23229010, grad/param norm = 2.2993e-01, time/batch = 0.6346s	
4643/11850 (epoch 19.591), train_loss = 1.35444070, grad/param norm = 2.4586e-01, time/batch = 0.6371s	
4644/11850 (epoch 19.595), train_loss = 1.11669689, grad/param norm = 2.4897e-01, time/batch = 0.6383s	
4645/11850 (epoch 19.599), train_loss = 1.21836732, grad/param norm = 2.4268e-01, time/batch = 0.6429s	
4646/11850 (epoch 19.603), train_loss = 1.18457106, grad/param norm = 2.2459e-01, time/batch = 0.6392s	
4647/11850 (epoch 19.608), train_loss = 1.39185059, grad/param norm = 2.3960e-01, time/batch = 0.6397s	
4648/11850 (epoch 19.612), train_loss = 1.46513817, grad/param norm = 2.5809e-01, time/batch = 0.6586s	
4649/11850 (epoch 19.616), train_loss = 1.37998288, grad/param norm = 2.1832e-01, time/batch = 0.6585s	
4650/11850 (epoch 19.620), train_loss = 1.24805105, grad/param norm = 2.3055e-01, time/batch = 0.6521s	
4651/11850 (epoch 19.624), train_loss = 1.28567106, grad/param norm = 2.6440e-01, time/batch = 0.6590s	
4652/11850 (epoch 19.629), train_loss = 1.19475270, grad/param norm = 2.4586e-01, time/batch = 0.6616s	
4653/11850 (epoch 19.633), train_loss = 1.12627469, grad/param norm = 2.4113e-01, time/batch = 0.6484s	
4654/11850 (epoch 19.637), train_loss = 1.13592745, grad/param norm = 2.3362e-01, time/batch = 0.6457s	
4655/11850 (epoch 19.641), train_loss = 1.13683418, grad/param norm = 2.1507e-01, time/batch = 0.6282s	
4656/11850 (epoch 19.646), train_loss = 1.21285780, grad/param norm = 2.3804e-01, time/batch = 0.6456s	
4657/11850 (epoch 19.650), train_loss = 1.25127182, grad/param norm = 2.4982e-01, time/batch = 0.6407s	
4658/11850 (epoch 19.654), train_loss = 1.20260873, grad/param norm = 2.4246e-01, time/batch = 0.6236s	
4659/11850 (epoch 19.658), train_loss = 1.29161454, grad/param norm = 2.4052e-01, time/batch = 0.6409s	
4660/11850 (epoch 19.662), train_loss = 1.15640096, grad/param norm = 2.5189e-01, time/batch = 0.6365s	
4661/11850 (epoch 19.667), train_loss = 1.34893842, grad/param norm = 2.4143e-01, time/batch = 0.6353s	
4662/11850 (epoch 19.671), train_loss = 1.22200323, grad/param norm = 2.2342e-01, time/batch = 0.6244s	
4663/11850 (epoch 19.675), train_loss = 1.21722840, grad/param norm = 2.1780e-01, time/batch = 0.6355s	
4664/11850 (epoch 19.679), train_loss = 1.28737952, grad/param norm = 2.4167e-01, time/batch = 0.6441s	
4665/11850 (epoch 19.684), train_loss = 1.27228229, grad/param norm = 2.5717e-01, time/batch = 0.6309s	
4666/11850 (epoch 19.688), train_loss = 1.18781796, grad/param norm = 2.2184e-01, time/batch = 0.6349s	
4667/11850 (epoch 19.692), train_loss = 1.24513601, grad/param norm = 2.7836e-01, time/batch = 0.6289s	
4668/11850 (epoch 19.696), train_loss = 1.17128802, grad/param norm = 2.5124e-01, time/batch = 0.6339s	
4669/11850 (epoch 19.700), train_loss = 1.25335960, grad/param norm = 2.2908e-01, time/batch = 0.6282s	
4670/11850 (epoch 19.705), train_loss = 1.22527322, grad/param norm = 2.3364e-01, time/batch = 0.6300s	
4671/11850 (epoch 19.709), train_loss = 1.11658364, grad/param norm = 2.2490e-01, time/batch = 0.6271s	
4672/11850 (epoch 19.713), train_loss = 1.18197877, grad/param norm = 2.4295e-01, time/batch = 0.6249s	
4673/11850 (epoch 19.717), train_loss = 1.18825130, grad/param norm = 2.4620e-01, time/batch = 0.6250s	
4674/11850 (epoch 19.722), train_loss = 1.27344125, grad/param norm = 2.9318e-01, time/batch = 0.6244s	
4675/11850 (epoch 19.726), train_loss = 1.14176921, grad/param norm = 2.4465e-01, time/batch = 0.6255s	
4676/11850 (epoch 19.730), train_loss = 1.11988336, grad/param norm = 2.8916e-01, time/batch = 0.6245s	
4677/11850 (epoch 19.734), train_loss = 1.19781425, grad/param norm = 2.3630e-01, time/batch = 0.6219s	
4678/11850 (epoch 19.738), train_loss = 1.34856452, grad/param norm = 2.7352e-01, time/batch = 0.6398s	
4679/11850 (epoch 19.743), train_loss = 1.25141298, grad/param norm = 2.3107e-01, time/batch = 0.6409s	
4680/11850 (epoch 19.747), train_loss = 1.09355260, grad/param norm = 2.0491e-01, time/batch = 0.6257s	
4681/11850 (epoch 19.751), train_loss = 1.11827161, grad/param norm = 2.1240e-01, time/batch = 0.6290s	
4682/11850 (epoch 19.755), train_loss = 1.24157745, grad/param norm = 2.4005e-01, time/batch = 0.6284s	
4683/11850 (epoch 19.759), train_loss = 1.16902620, grad/param norm = 2.3168e-01, time/batch = 0.6250s	
4684/11850 (epoch 19.764), train_loss = 1.22348200, grad/param norm = 2.4089e-01, time/batch = 0.6265s	
4685/11850 (epoch 19.768), train_loss = 1.09202288, grad/param norm = 2.1399e-01, time/batch = 0.6330s	
4686/11850 (epoch 19.772), train_loss = 1.20830919, grad/param norm = 2.2175e-01, time/batch = 0.6252s	
4687/11850 (epoch 19.776), train_loss = 1.23055555, grad/param norm = 2.2939e-01, time/batch = 0.6288s	
4688/11850 (epoch 19.781), train_loss = 1.19854416, grad/param norm = 2.2564e-01, time/batch = 0.6526s	
4689/11850 (epoch 19.785), train_loss = 1.16873697, grad/param norm = 2.3518e-01, time/batch = 0.6435s	
4690/11850 (epoch 19.789), train_loss = 1.25903317, grad/param norm = 2.4030e-01, time/batch = 0.6290s	
4691/11850 (epoch 19.793), train_loss = 1.34023902, grad/param norm = 2.5975e-01, time/batch = 0.6376s	
4692/11850 (epoch 19.797), train_loss = 1.27497396, grad/param norm = 2.8383e-01, time/batch = 0.6412s	
4693/11850 (epoch 19.802), train_loss = 1.12920478, grad/param norm = 2.3054e-01, time/batch = 0.6333s	
4694/11850 (epoch 19.806), train_loss = 1.22747016, grad/param norm = 2.2083e-01, time/batch = 0.6361s	
4695/11850 (epoch 19.810), train_loss = 1.38217811, grad/param norm = 2.8545e-01, time/batch = 0.6289s	
4696/11850 (epoch 19.814), train_loss = 1.22412779, grad/param norm = 2.3829e-01, time/batch = 0.6223s	
4697/11850 (epoch 19.819), train_loss = 1.36823689, grad/param norm = 2.5002e-01, time/batch = 0.6244s	
4698/11850 (epoch 19.823), train_loss = 1.39509261, grad/param norm = 2.6745e-01, time/batch = 0.6246s	
4699/11850 (epoch 19.827), train_loss = 1.25352949, grad/param norm = 2.4209e-01, time/batch = 0.6234s	
4700/11850 (epoch 19.831), train_loss = 1.26167308, grad/param norm = 2.5546e-01, time/batch = 0.6523s	
4701/11850 (epoch 19.835), train_loss = 1.23782949, grad/param norm = 2.2726e-01, time/batch = 0.6516s	
4702/11850 (epoch 19.840), train_loss = 1.19919023, grad/param norm = 2.1583e-01, time/batch = 0.6252s	
4703/11850 (epoch 19.844), train_loss = 1.22850781, grad/param norm = 2.1477e-01, time/batch = 0.6219s	
4704/11850 (epoch 19.848), train_loss = 1.27135807, grad/param norm = 2.3641e-01, time/batch = 0.6239s	
4705/11850 (epoch 19.852), train_loss = 1.23546246, grad/param norm = 2.3755e-01, time/batch = 0.6239s	
4706/11850 (epoch 19.857), train_loss = 1.25321267, grad/param norm = 2.6071e-01, time/batch = 0.6266s	
4707/11850 (epoch 19.861), train_loss = 1.25590900, grad/param norm = 2.5298e-01, time/batch = 0.6371s	
4708/11850 (epoch 19.865), train_loss = 1.31138837, grad/param norm = 2.8274e-01, time/batch = 0.6255s	
4709/11850 (epoch 19.869), train_loss = 1.30342014, grad/param norm = 2.4818e-01, time/batch = 0.6233s	
4710/11850 (epoch 19.873), train_loss = 1.30854442, grad/param norm = 2.6722e-01, time/batch = 0.6267s	
4711/11850 (epoch 19.878), train_loss = 1.32046772, grad/param norm = 2.4856e-01, time/batch = 0.6271s	
4712/11850 (epoch 19.882), train_loss = 1.27410617, grad/param norm = 2.4512e-01, time/batch = 0.6376s	
4713/11850 (epoch 19.886), train_loss = 1.30744124, grad/param norm = 2.6160e-01, time/batch = 0.6293s	
4714/11850 (epoch 19.890), train_loss = 1.29998572, grad/param norm = 2.5829e-01, time/batch = 0.6224s	
4715/11850 (epoch 19.895), train_loss = 1.29401803, grad/param norm = 3.2840e-01, time/batch = 0.6258s	
4716/11850 (epoch 19.899), train_loss = 1.17646032, grad/param norm = 2.5921e-01, time/batch = 0.6246s	
4717/11850 (epoch 19.903), train_loss = 1.24127368, grad/param norm = 2.6616e-01, time/batch = 0.6261s	
4718/11850 (epoch 19.907), train_loss = 1.19908188, grad/param norm = 2.4374e-01, time/batch = 0.6230s	
4719/11850 (epoch 19.911), train_loss = 1.33692442, grad/param norm = 2.7007e-01, time/batch = 0.6215s	
4720/11850 (epoch 19.916), train_loss = 1.36006556, grad/param norm = 2.8203e-01, time/batch = 0.6261s	
4721/11850 (epoch 19.920), train_loss = 1.27362324, grad/param norm = 2.8529e-01, time/batch = 0.6224s	
4722/11850 (epoch 19.924), train_loss = 1.24661022, grad/param norm = 2.4934e-01, time/batch = 0.6272s	
4723/11850 (epoch 19.928), train_loss = 1.34249130, grad/param norm = 2.7425e-01, time/batch = 0.6254s	
4724/11850 (epoch 19.932), train_loss = 1.36498562, grad/param norm = 2.3486e-01, time/batch = 0.6242s	
4725/11850 (epoch 19.937), train_loss = 1.32092975, grad/param norm = 2.7136e-01, time/batch = 0.6237s	
4726/11850 (epoch 19.941), train_loss = 1.31989977, grad/param norm = 2.2959e-01, time/batch = 0.6220s	
4727/11850 (epoch 19.945), train_loss = 1.33746266, grad/param norm = 3.1351e-01, time/batch = 0.6247s	
4728/11850 (epoch 19.949), train_loss = 1.20979411, grad/param norm = 2.5421e-01, time/batch = 0.6241s	
4729/11850 (epoch 19.954), train_loss = 1.31234893, grad/param norm = 2.7236e-01, time/batch = 0.6248s	
4730/11850 (epoch 19.958), train_loss = 1.30704710, grad/param norm = 2.8875e-01, time/batch = 0.6257s	
4731/11850 (epoch 19.962), train_loss = 1.17181849, grad/param norm = 2.3594e-01, time/batch = 0.6362s	
4732/11850 (epoch 19.966), train_loss = 1.12831486, grad/param norm = 2.3575e-01, time/batch = 0.6228s	
4733/11850 (epoch 19.970), train_loss = 1.27781758, grad/param norm = 2.5160e-01, time/batch = 0.6229s	
4734/11850 (epoch 19.975), train_loss = 1.24546564, grad/param norm = 2.4190e-01, time/batch = 0.6271s	
4735/11850 (epoch 19.979), train_loss = 1.26419160, grad/param norm = 2.9787e-01, time/batch = 0.6245s	
4736/11850 (epoch 19.983), train_loss = 1.42644334, grad/param norm = 3.4952e-01, time/batch = 0.6242s	
4737/11850 (epoch 19.987), train_loss = 1.27486689, grad/param norm = 2.8363e-01, time/batch = 0.6247s	
4738/11850 (epoch 19.992), train_loss = 1.40864829, grad/param norm = 2.3855e-01, time/batch = 0.6259s	
4739/11850 (epoch 19.996), train_loss = 1.48356754, grad/param norm = 3.0845e-01, time/batch = 0.6267s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
4740/11850 (epoch 20.000), train_loss = 1.25432732, grad/param norm = 2.6425e-01, time/batch = 0.6244s	
4741/11850 (epoch 20.004), train_loss = 1.34303766, grad/param norm = 2.6008e-01, time/batch = 0.6278s	
4742/11850 (epoch 20.008), train_loss = 1.38588105, grad/param norm = 2.6019e-01, time/batch = 0.6280s	
4743/11850 (epoch 20.013), train_loss = 1.34279222, grad/param norm = 2.4237e-01, time/batch = 0.6262s	
4744/11850 (epoch 20.017), train_loss = 1.47069522, grad/param norm = 2.6735e-01, time/batch = 0.6251s	
4745/11850 (epoch 20.021), train_loss = 1.29071535, grad/param norm = 2.1604e-01, time/batch = 0.6344s	
4746/11850 (epoch 20.025), train_loss = 1.16373557, grad/param norm = 2.1992e-01, time/batch = 0.6615s	
4747/11850 (epoch 20.030), train_loss = 1.19355033, grad/param norm = 2.3603e-01, time/batch = 0.6574s	
4748/11850 (epoch 20.034), train_loss = 1.21171739, grad/param norm = 2.3351e-01, time/batch = 0.6559s	
4749/11850 (epoch 20.038), train_loss = 1.27826309, grad/param norm = 2.2059e-01, time/batch = 0.6445s	
4750/11850 (epoch 20.042), train_loss = 1.26705978, grad/param norm = 2.3811e-01, time/batch = 0.6358s	
4751/11850 (epoch 20.046), train_loss = 1.31215773, grad/param norm = 2.5527e-01, time/batch = 0.6351s	
4752/11850 (epoch 20.051), train_loss = 1.26250916, grad/param norm = 2.4068e-01, time/batch = 0.6368s	
4753/11850 (epoch 20.055), train_loss = 1.23273848, grad/param norm = 2.2692e-01, time/batch = 0.6413s	
4754/11850 (epoch 20.059), train_loss = 1.33954945, grad/param norm = 2.5066e-01, time/batch = 0.6678s	
4755/11850 (epoch 20.063), train_loss = 1.30121814, grad/param norm = 2.4459e-01, time/batch = 0.6324s	
4756/11850 (epoch 20.068), train_loss = 1.26660744, grad/param norm = 2.2252e-01, time/batch = 0.6311s	
4757/11850 (epoch 20.072), train_loss = 1.27652719, grad/param norm = 2.1155e-01, time/batch = 0.6268s	
4758/11850 (epoch 20.076), train_loss = 1.40139339, grad/param norm = 2.1974e-01, time/batch = 0.6256s	
4759/11850 (epoch 20.080), train_loss = 1.19554757, grad/param norm = 2.2102e-01, time/batch = 0.6273s	
4760/11850 (epoch 20.084), train_loss = 1.11349174, grad/param norm = 2.0711e-01, time/batch = 0.6275s	
4761/11850 (epoch 20.089), train_loss = 1.15543550, grad/param norm = 2.1927e-01, time/batch = 0.6365s	
4762/11850 (epoch 20.093), train_loss = 1.12970661, grad/param norm = 2.4290e-01, time/batch = 0.6305s	
4763/11850 (epoch 20.097), train_loss = 1.29853377, grad/param norm = 2.4817e-01, time/batch = 0.6315s	
4764/11850 (epoch 20.101), train_loss = 1.24106306, grad/param norm = 2.8121e-01, time/batch = 0.6280s	
4765/11850 (epoch 20.105), train_loss = 1.16003121, grad/param norm = 2.3157e-01, time/batch = 0.6257s	
4766/11850 (epoch 20.110), train_loss = 1.31153182, grad/param norm = 2.3531e-01, time/batch = 0.6277s	
4767/11850 (epoch 20.114), train_loss = 1.27982028, grad/param norm = 2.5698e-01, time/batch = 0.6218s	
4768/11850 (epoch 20.118), train_loss = 1.25506232, grad/param norm = 2.1886e-01, time/batch = 0.6211s	
4769/11850 (epoch 20.122), train_loss = 1.35164231, grad/param norm = 2.5073e-01, time/batch = 0.6249s	
4770/11850 (epoch 20.127), train_loss = 1.29765819, grad/param norm = 2.4140e-01, time/batch = 0.6227s	
4771/11850 (epoch 20.131), train_loss = 1.28517288, grad/param norm = 2.7017e-01, time/batch = 0.6246s	
4772/11850 (epoch 20.135), train_loss = 1.24513614, grad/param norm = 2.7020e-01, time/batch = 0.6312s	
4773/11850 (epoch 20.139), train_loss = 1.21338056, grad/param norm = 2.2504e-01, time/batch = 0.6371s	
4774/11850 (epoch 20.143), train_loss = 1.25161846, grad/param norm = 2.4195e-01, time/batch = 0.6381s	
4775/11850 (epoch 20.148), train_loss = 1.28128964, grad/param norm = 2.6858e-01, time/batch = 0.6433s	
4776/11850 (epoch 20.152), train_loss = 1.36913322, grad/param norm = 3.0823e-01, time/batch = 0.6278s	
4777/11850 (epoch 20.156), train_loss = 1.30923839, grad/param norm = 3.1651e-01, time/batch = 0.6285s	
4778/11850 (epoch 20.160), train_loss = 1.56529251, grad/param norm = 4.0772e-01, time/batch = 0.6246s	
4779/11850 (epoch 20.165), train_loss = 1.44152481, grad/param norm = 4.0591e-01, time/batch = 0.6252s	
4780/11850 (epoch 20.169), train_loss = 1.24493070, grad/param norm = 2.6246e-01, time/batch = 0.6275s	
4781/11850 (epoch 20.173), train_loss = 1.33295448, grad/param norm = 2.6577e-01, time/batch = 0.6269s	
4782/11850 (epoch 20.177), train_loss = 1.24164931, grad/param norm = 3.1987e-01, time/batch = 0.6237s	
4783/11850 (epoch 20.181), train_loss = 1.36036488, grad/param norm = 2.4203e-01, time/batch = 0.6237s	
4784/11850 (epoch 20.186), train_loss = 1.40746822, grad/param norm = 2.8929e-01, time/batch = 0.6284s	
4785/11850 (epoch 20.190), train_loss = 1.29709074, grad/param norm = 2.2615e-01, time/batch = 0.6275s	
4786/11850 (epoch 20.194), train_loss = 1.39230492, grad/param norm = 2.8347e-01, time/batch = 0.6225s	
4787/11850 (epoch 20.198), train_loss = 1.15834051, grad/param norm = 2.4276e-01, time/batch = 0.6221s	
4788/11850 (epoch 20.203), train_loss = 1.16568315, grad/param norm = 2.5280e-01, time/batch = 0.6277s	
4789/11850 (epoch 20.207), train_loss = 1.32234785, grad/param norm = 2.4276e-01, time/batch = 0.6564s	
4790/11850 (epoch 20.211), train_loss = 1.27203903, grad/param norm = 2.3531e-01, time/batch = 0.6359s	
4791/11850 (epoch 20.215), train_loss = 1.28148011, grad/param norm = 2.6191e-01, time/batch = 0.6262s	
4792/11850 (epoch 20.219), train_loss = 1.27137828, grad/param norm = 2.4491e-01, time/batch = 0.6210s	
4793/11850 (epoch 20.224), train_loss = 1.44063356, grad/param norm = 2.5355e-01, time/batch = 0.6259s	
4794/11850 (epoch 20.228), train_loss = 1.37825735, grad/param norm = 2.6655e-01, time/batch = 0.6220s	
4795/11850 (epoch 20.232), train_loss = 1.33065533, grad/param norm = 2.4551e-01, time/batch = 0.6244s	
4796/11850 (epoch 20.236), train_loss = 1.19086757, grad/param norm = 2.4213e-01, time/batch = 0.6275s	
4797/11850 (epoch 20.241), train_loss = 1.42829519, grad/param norm = 3.0317e-01, time/batch = 0.6221s	
4798/11850 (epoch 20.245), train_loss = 1.36563534, grad/param norm = 2.5201e-01, time/batch = 0.6335s	
4799/11850 (epoch 20.249), train_loss = 1.20997911, grad/param norm = 2.4275e-01, time/batch = 0.6251s	
4800/11850 (epoch 20.253), train_loss = 1.28426981, grad/param norm = 2.6255e-01, time/batch = 0.6204s	
4801/11850 (epoch 20.257), train_loss = 1.40113680, grad/param norm = 2.3929e-01, time/batch = 0.6324s	
4802/11850 (epoch 20.262), train_loss = 1.44373181, grad/param norm = 2.6337e-01, time/batch = 0.6236s	
4803/11850 (epoch 20.266), train_loss = 1.36302728, grad/param norm = 2.4845e-01, time/batch = 0.6243s	
4804/11850 (epoch 20.270), train_loss = 1.23807275, grad/param norm = 2.2914e-01, time/batch = 0.6255s	
4805/11850 (epoch 20.274), train_loss = 1.22913225, grad/param norm = 2.4513e-01, time/batch = 0.6245s	
4806/11850 (epoch 20.278), train_loss = 1.11213680, grad/param norm = 2.2208e-01, time/batch = 0.6268s	
4807/11850 (epoch 20.283), train_loss = 1.20199427, grad/param norm = 2.2434e-01, time/batch = 0.6243s	
4808/11850 (epoch 20.287), train_loss = 1.37157135, grad/param norm = 2.3227e-01, time/batch = 0.6265s	
4809/11850 (epoch 20.291), train_loss = 1.28017921, grad/param norm = 2.2984e-01, time/batch = 0.6267s	
4810/11850 (epoch 20.295), train_loss = 1.30640674, grad/param norm = 2.4454e-01, time/batch = 0.6283s	
4811/11850 (epoch 20.300), train_loss = 1.22998617, grad/param norm = 2.4442e-01, time/batch = 0.6301s	
4812/11850 (epoch 20.304), train_loss = 1.23132705, grad/param norm = 2.1222e-01, time/batch = 0.6269s	
4813/11850 (epoch 20.308), train_loss = 1.23144178, grad/param norm = 2.3600e-01, time/batch = 0.6241s	
4814/11850 (epoch 20.312), train_loss = 1.09389651, grad/param norm = 2.0859e-01, time/batch = 0.6266s	
4815/11850 (epoch 20.316), train_loss = 1.30975660, grad/param norm = 2.3249e-01, time/batch = 0.6317s	
4816/11850 (epoch 20.321), train_loss = 1.20672314, grad/param norm = 2.1626e-01, time/batch = 0.6277s	
4817/11850 (epoch 20.325), train_loss = 1.26017951, grad/param norm = 2.5338e-01, time/batch = 0.6305s	
4818/11850 (epoch 20.329), train_loss = 1.24061226, grad/param norm = 2.4411e-01, time/batch = 0.6282s	
4819/11850 (epoch 20.333), train_loss = 1.25060937, grad/param norm = 2.4550e-01, time/batch = 0.6291s	
4820/11850 (epoch 20.338), train_loss = 1.16048578, grad/param norm = 2.0680e-01, time/batch = 0.6284s	
4821/11850 (epoch 20.342), train_loss = 1.31802999, grad/param norm = 2.6962e-01, time/batch = 0.6274s	
4822/11850 (epoch 20.346), train_loss = 1.26522753, grad/param norm = 2.3283e-01, time/batch = 0.6280s	
4823/11850 (epoch 20.350), train_loss = 1.12662069, grad/param norm = 2.3955e-01, time/batch = 0.6261s	
4824/11850 (epoch 20.354), train_loss = 1.33307577, grad/param norm = 2.4325e-01, time/batch = 0.6245s	
4825/11850 (epoch 20.359), train_loss = 1.36818836, grad/param norm = 2.9635e-01, time/batch = 0.6295s	
4826/11850 (epoch 20.363), train_loss = 1.30495975, grad/param norm = 2.3086e-01, time/batch = 0.6274s	
4827/11850 (epoch 20.367), train_loss = 1.30637399, grad/param norm = 2.2147e-01, time/batch = 0.6315s	
4828/11850 (epoch 20.371), train_loss = 1.31425800, grad/param norm = 2.4725e-01, time/batch = 0.6275s	
4829/11850 (epoch 20.376), train_loss = 1.23629545, grad/param norm = 2.2956e-01, time/batch = 0.6286s	
4830/11850 (epoch 20.380), train_loss = 1.17716034, grad/param norm = 2.1649e-01, time/batch = 0.6247s	
4831/11850 (epoch 20.384), train_loss = 1.17988113, grad/param norm = 2.4815e-01, time/batch = 0.6237s	
4832/11850 (epoch 20.388), train_loss = 1.35303849, grad/param norm = 2.6545e-01, time/batch = 0.6219s	
4833/11850 (epoch 20.392), train_loss = 1.34979828, grad/param norm = 2.3885e-01, time/batch = 0.6222s	
4834/11850 (epoch 20.397), train_loss = 1.33266825, grad/param norm = 2.8239e-01, time/batch = 0.6240s	
4835/11850 (epoch 20.401), train_loss = 1.13083406, grad/param norm = 2.1612e-01, time/batch = 0.6210s	
4836/11850 (epoch 20.405), train_loss = 1.20687161, grad/param norm = 2.4611e-01, time/batch = 0.6223s	
4837/11850 (epoch 20.409), train_loss = 1.35137097, grad/param norm = 2.4267e-01, time/batch = 0.6242s	
4838/11850 (epoch 20.414), train_loss = 1.13228697, grad/param norm = 2.3175e-01, time/batch = 0.6232s	
4839/11850 (epoch 20.418), train_loss = 1.16290892, grad/param norm = 2.4289e-01, time/batch = 0.6237s	
4840/11850 (epoch 20.422), train_loss = 1.07605696, grad/param norm = 2.2248e-01, time/batch = 0.6292s	
4841/11850 (epoch 20.426), train_loss = 1.11663878, grad/param norm = 2.4577e-01, time/batch = 0.6483s	
4842/11850 (epoch 20.430), train_loss = 1.17372265, grad/param norm = 2.2948e-01, time/batch = 0.6535s	
4843/11850 (epoch 20.435), train_loss = 1.18146386, grad/param norm = 2.1344e-01, time/batch = 0.6487s	
4844/11850 (epoch 20.439), train_loss = 1.33261041, grad/param norm = 2.4181e-01, time/batch = 0.6357s	
4845/11850 (epoch 20.443), train_loss = 1.27450485, grad/param norm = 2.3539e-01, time/batch = 0.6268s	
4846/11850 (epoch 20.447), train_loss = 1.13061211, grad/param norm = 2.3828e-01, time/batch = 0.6270s	
4847/11850 (epoch 20.451), train_loss = 1.14959455, grad/param norm = 2.1674e-01, time/batch = 0.6287s	
4848/11850 (epoch 20.456), train_loss = 1.22293737, grad/param norm = 2.4918e-01, time/batch = 0.6264s	
4849/11850 (epoch 20.460), train_loss = 1.25562030, grad/param norm = 2.3663e-01, time/batch = 0.6359s	
4850/11850 (epoch 20.464), train_loss = 1.18042678, grad/param norm = 2.5945e-01, time/batch = 0.6379s	
4851/11850 (epoch 20.468), train_loss = 1.25943511, grad/param norm = 2.3542e-01, time/batch = 0.6357s	
4852/11850 (epoch 20.473), train_loss = 1.29339529, grad/param norm = 2.4384e-01, time/batch = 0.6278s	
4853/11850 (epoch 20.477), train_loss = 1.14362696, grad/param norm = 2.5128e-01, time/batch = 0.6241s	
4854/11850 (epoch 20.481), train_loss = 1.15721895, grad/param norm = 2.5451e-01, time/batch = 0.6282s	
4855/11850 (epoch 20.485), train_loss = 1.12430733, grad/param norm = 2.1466e-01, time/batch = 0.6288s	
4856/11850 (epoch 20.489), train_loss = 1.26824177, grad/param norm = 2.2822e-01, time/batch = 0.6263s	
4857/11850 (epoch 20.494), train_loss = 1.16000802, grad/param norm = 2.4636e-01, time/batch = 0.6270s	
4858/11850 (epoch 20.498), train_loss = 1.15192523, grad/param norm = 2.4519e-01, time/batch = 0.6258s	
4859/11850 (epoch 20.502), train_loss = 1.10329273, grad/param norm = 2.6858e-01, time/batch = 0.6244s	
4860/11850 (epoch 20.506), train_loss = 1.36397014, grad/param norm = 2.4489e-01, time/batch = 0.6559s	
4861/11850 (epoch 20.511), train_loss = 1.23591587, grad/param norm = 2.3910e-01, time/batch = 0.6454s	
4862/11850 (epoch 20.515), train_loss = 1.35970017, grad/param norm = 2.5014e-01, time/batch = 0.6295s	
4863/11850 (epoch 20.519), train_loss = 1.17816850, grad/param norm = 2.4359e-01, time/batch = 0.6252s	
4864/11850 (epoch 20.523), train_loss = 1.20648355, grad/param norm = 2.3010e-01, time/batch = 0.6258s	
4865/11850 (epoch 20.527), train_loss = 1.12206959, grad/param norm = 2.2762e-01, time/batch = 0.6237s	
4866/11850 (epoch 20.532), train_loss = 1.28681389, grad/param norm = 2.2303e-01, time/batch = 0.6237s	
4867/11850 (epoch 20.536), train_loss = 1.16443699, grad/param norm = 2.1053e-01, time/batch = 0.6268s	
4868/11850 (epoch 20.540), train_loss = 1.13551663, grad/param norm = 2.0942e-01, time/batch = 0.6223s	
4869/11850 (epoch 20.544), train_loss = 1.18672385, grad/param norm = 2.5227e-01, time/batch = 0.6245s	
4870/11850 (epoch 20.549), train_loss = 1.07237215, grad/param norm = 2.2058e-01, time/batch = 0.6228s	
4871/11850 (epoch 20.553), train_loss = 1.25645933, grad/param norm = 2.3600e-01, time/batch = 0.6280s	
4872/11850 (epoch 20.557), train_loss = 1.33383528, grad/param norm = 2.4650e-01, time/batch = 0.6252s	
4873/11850 (epoch 20.561), train_loss = 1.26088702, grad/param norm = 2.4123e-01, time/batch = 0.6205s	
4874/11850 (epoch 20.565), train_loss = 1.36584504, grad/param norm = 2.5569e-01, time/batch = 0.6255s	
4875/11850 (epoch 20.570), train_loss = 1.21363176, grad/param norm = 2.2971e-01, time/batch = 0.6276s	
4876/11850 (epoch 20.574), train_loss = 1.31830402, grad/param norm = 2.6034e-01, time/batch = 0.6241s	
4877/11850 (epoch 20.578), train_loss = 1.37196173, grad/param norm = 2.5076e-01, time/batch = 0.6239s	
4878/11850 (epoch 20.582), train_loss = 1.18515988, grad/param norm = 2.5762e-01, time/batch = 0.6237s	
4879/11850 (epoch 20.586), train_loss = 1.21160000, grad/param norm = 2.2739e-01, time/batch = 0.6258s	
4880/11850 (epoch 20.591), train_loss = 1.32266839, grad/param norm = 2.7548e-01, time/batch = 0.6239s	
4881/11850 (epoch 20.595), train_loss = 1.09112165, grad/param norm = 2.4205e-01, time/batch = 0.6242s	
4882/11850 (epoch 20.599), train_loss = 1.20166158, grad/param norm = 2.5273e-01, time/batch = 0.6249s	
4883/11850 (epoch 20.603), train_loss = 1.16888920, grad/param norm = 2.3542e-01, time/batch = 0.6231s	
4884/11850 (epoch 20.608), train_loss = 1.35837018, grad/param norm = 2.3541e-01, time/batch = 0.6228s	
4885/11850 (epoch 20.612), train_loss = 1.43557754, grad/param norm = 2.5267e-01, time/batch = 0.6251s	
4886/11850 (epoch 20.616), train_loss = 1.35567813, grad/param norm = 2.3027e-01, time/batch = 0.6243s	
4887/11850 (epoch 20.620), train_loss = 1.21726426, grad/param norm = 2.2733e-01, time/batch = 0.6251s	
4888/11850 (epoch 20.624), train_loss = 1.26776580, grad/param norm = 3.0316e-01, time/batch = 0.6315s	
4889/11850 (epoch 20.629), train_loss = 1.18863574, grad/param norm = 2.7330e-01, time/batch = 0.6295s	
4890/11850 (epoch 20.633), train_loss = 1.09876533, grad/param norm = 2.3987e-01, time/batch = 0.6304s	
4891/11850 (epoch 20.637), train_loss = 1.11328478, grad/param norm = 2.4594e-01, time/batch = 0.6328s	
4892/11850 (epoch 20.641), train_loss = 1.10654468, grad/param norm = 2.1636e-01, time/batch = 0.6250s	
4893/11850 (epoch 20.646), train_loss = 1.18327289, grad/param norm = 2.3811e-01, time/batch = 0.6327s	
4894/11850 (epoch 20.650), train_loss = 1.23285419, grad/param norm = 2.6073e-01, time/batch = 0.6450s	
4895/11850 (epoch 20.654), train_loss = 1.17443947, grad/param norm = 2.4763e-01, time/batch = 0.6420s	
4896/11850 (epoch 20.658), train_loss = 1.26604788, grad/param norm = 2.4446e-01, time/batch = 0.6451s	
4897/11850 (epoch 20.662), train_loss = 1.11792778, grad/param norm = 2.4972e-01, time/batch = 0.6263s	
4898/11850 (epoch 20.667), train_loss = 1.32331275, grad/param norm = 2.4487e-01, time/batch = 0.6561s	
4899/11850 (epoch 20.671), train_loss = 1.20221899, grad/param norm = 2.3795e-01, time/batch = 0.6410s	
4900/11850 (epoch 20.675), train_loss = 1.19851983, grad/param norm = 2.3857e-01, time/batch = 0.6240s	
4901/11850 (epoch 20.679), train_loss = 1.25949019, grad/param norm = 2.4417e-01, time/batch = 0.6392s	
4902/11850 (epoch 20.684), train_loss = 1.24690884, grad/param norm = 2.7084e-01, time/batch = 0.6238s	
4903/11850 (epoch 20.688), train_loss = 1.15992538, grad/param norm = 2.2235e-01, time/batch = 0.6271s	
4904/11850 (epoch 20.692), train_loss = 1.21683277, grad/param norm = 2.7080e-01, time/batch = 0.6232s	
4905/11850 (epoch 20.696), train_loss = 1.13253661, grad/param norm = 2.3848e-01, time/batch = 0.6231s	
4906/11850 (epoch 20.700), train_loss = 1.23164614, grad/param norm = 2.5699e-01, time/batch = 0.6260s	
4907/11850 (epoch 20.705), train_loss = 1.19581700, grad/param norm = 2.4006e-01, time/batch = 0.6243s	
4908/11850 (epoch 20.709), train_loss = 1.08612393, grad/param norm = 2.2018e-01, time/batch = 0.6239s	
4909/11850 (epoch 20.713), train_loss = 1.15094715, grad/param norm = 2.4948e-01, time/batch = 0.6530s	
4910/11850 (epoch 20.717), train_loss = 1.16471437, grad/param norm = 2.4486e-01, time/batch = 0.6487s	
4911/11850 (epoch 20.722), train_loss = 1.24838069, grad/param norm = 2.5899e-01, time/batch = 0.6243s	
4912/11850 (epoch 20.726), train_loss = 1.10593834, grad/param norm = 2.3939e-01, time/batch = 0.6282s	
4913/11850 (epoch 20.730), train_loss = 1.10735306, grad/param norm = 2.5097e-01, time/batch = 0.6269s	
4914/11850 (epoch 20.734), train_loss = 1.16543964, grad/param norm = 2.3030e-01, time/batch = 0.6266s	
4915/11850 (epoch 20.738), train_loss = 1.30561752, grad/param norm = 2.6693e-01, time/batch = 0.6231s	
4916/11850 (epoch 20.743), train_loss = 1.22022822, grad/param norm = 2.3089e-01, time/batch = 0.6249s	
4917/11850 (epoch 20.747), train_loss = 1.07054193, grad/param norm = 2.0799e-01, time/batch = 0.6253s	
4918/11850 (epoch 20.751), train_loss = 1.10845341, grad/param norm = 2.2384e-01, time/batch = 0.6249s	
4919/11850 (epoch 20.755), train_loss = 1.22081898, grad/param norm = 2.4983e-01, time/batch = 0.6315s	
4920/11850 (epoch 20.759), train_loss = 1.14685179, grad/param norm = 2.4329e-01, time/batch = 0.6385s	
4921/11850 (epoch 20.764), train_loss = 1.18869257, grad/param norm = 2.3450e-01, time/batch = 0.6578s	
4922/11850 (epoch 20.768), train_loss = 1.07108238, grad/param norm = 2.2064e-01, time/batch = 0.6591s	
4923/11850 (epoch 20.772), train_loss = 1.17153098, grad/param norm = 2.2053e-01, time/batch = 0.6556s	
4924/11850 (epoch 20.776), train_loss = 1.20164177, grad/param norm = 2.2286e-01, time/batch = 0.6591s	
4925/11850 (epoch 20.781), train_loss = 1.17836484, grad/param norm = 2.2631e-01, time/batch = 0.6581s	
4926/11850 (epoch 20.785), train_loss = 1.14859203, grad/param norm = 2.5681e-01, time/batch = 0.6491s	
4927/11850 (epoch 20.789), train_loss = 1.22087112, grad/param norm = 2.4419e-01, time/batch = 0.6524s	
4928/11850 (epoch 20.793), train_loss = 1.30580540, grad/param norm = 2.5970e-01, time/batch = 0.6307s	
4929/11850 (epoch 20.797), train_loss = 1.24498914, grad/param norm = 2.4872e-01, time/batch = 0.6257s	
4930/11850 (epoch 20.802), train_loss = 1.10462439, grad/param norm = 2.4122e-01, time/batch = 0.6258s	
4931/11850 (epoch 20.806), train_loss = 1.20681279, grad/param norm = 2.2489e-01, time/batch = 0.6595s	
4932/11850 (epoch 20.810), train_loss = 1.34781607, grad/param norm = 3.0497e-01, time/batch = 0.6434s	
4933/11850 (epoch 20.814), train_loss = 1.18607818, grad/param norm = 2.1818e-01, time/batch = 0.6246s	
4934/11850 (epoch 20.819), train_loss = 1.34558392, grad/param norm = 2.5974e-01, time/batch = 0.6223s	
4935/11850 (epoch 20.823), train_loss = 1.36937875, grad/param norm = 2.7446e-01, time/batch = 0.6457s	
4936/11850 (epoch 20.827), train_loss = 1.23023937, grad/param norm = 2.4798e-01, time/batch = 0.6528s	
4937/11850 (epoch 20.831), train_loss = 1.22844150, grad/param norm = 2.5500e-01, time/batch = 0.6497s	
4938/11850 (epoch 20.835), train_loss = 1.20589960, grad/param norm = 2.3641e-01, time/batch = 0.6393s	
4939/11850 (epoch 20.840), train_loss = 1.18662436, grad/param norm = 2.3168e-01, time/batch = 0.6280s	
4940/11850 (epoch 20.844), train_loss = 1.20970247, grad/param norm = 2.2680e-01, time/batch = 0.6228s	
4941/11850 (epoch 20.848), train_loss = 1.23548481, grad/param norm = 2.3159e-01, time/batch = 0.6287s	
4942/11850 (epoch 20.852), train_loss = 1.21864741, grad/param norm = 2.4749e-01, time/batch = 0.6260s	
4943/11850 (epoch 20.857), train_loss = 1.22404559, grad/param norm = 2.5851e-01, time/batch = 0.6325s	
4944/11850 (epoch 20.861), train_loss = 1.22314155, grad/param norm = 2.6860e-01, time/batch = 0.6388s	
4945/11850 (epoch 20.865), train_loss = 1.28587285, grad/param norm = 2.8534e-01, time/batch = 0.6464s	
4946/11850 (epoch 20.869), train_loss = 1.26586674, grad/param norm = 2.5468e-01, time/batch = 0.6488s	
4947/11850 (epoch 20.873), train_loss = 1.27403167, grad/param norm = 2.5067e-01, time/batch = 0.6417s	
4948/11850 (epoch 20.878), train_loss = 1.29596859, grad/param norm = 2.7159e-01, time/batch = 0.6277s	
4949/11850 (epoch 20.882), train_loss = 1.23709343, grad/param norm = 2.3715e-01, time/batch = 0.6262s	
4950/11850 (epoch 20.886), train_loss = 1.26427158, grad/param norm = 2.7380e-01, time/batch = 0.6288s	
4951/11850 (epoch 20.890), train_loss = 1.25843426, grad/param norm = 2.7482e-01, time/batch = 0.6274s	
4952/11850 (epoch 20.895), train_loss = 1.26154385, grad/param norm = 2.8200e-01, time/batch = 0.6440s	
4953/11850 (epoch 20.899), train_loss = 1.13547620, grad/param norm = 2.5774e-01, time/batch = 0.6584s	
4954/11850 (epoch 20.903), train_loss = 1.21709783, grad/param norm = 2.7814e-01, time/batch = 0.6378s	
4955/11850 (epoch 20.907), train_loss = 1.18684814, grad/param norm = 2.5598e-01, time/batch = 0.6266s	
4956/11850 (epoch 20.911), train_loss = 1.30029944, grad/param norm = 2.3469e-01, time/batch = 0.6263s	
4957/11850 (epoch 20.916), train_loss = 1.30647055, grad/param norm = 2.6520e-01, time/batch = 0.6237s	
4958/11850 (epoch 20.920), train_loss = 1.23171793, grad/param norm = 2.5865e-01, time/batch = 0.6243s	
4959/11850 (epoch 20.924), train_loss = 1.21746841, grad/param norm = 2.4189e-01, time/batch = 0.6249s	
4960/11850 (epoch 20.928), train_loss = 1.30791917, grad/param norm = 2.7465e-01, time/batch = 0.6263s	
4961/11850 (epoch 20.932), train_loss = 1.33543739, grad/param norm = 2.3450e-01, time/batch = 0.6254s	
4962/11850 (epoch 20.937), train_loss = 1.28513881, grad/param norm = 2.7681e-01, time/batch = 0.6240s	
4963/11850 (epoch 20.941), train_loss = 1.28619040, grad/param norm = 2.3270e-01, time/batch = 0.6282s	
4964/11850 (epoch 20.945), train_loss = 1.30328717, grad/param norm = 2.3783e-01, time/batch = 0.6581s	
4965/11850 (epoch 20.949), train_loss = 1.18858842, grad/param norm = 2.9188e-01, time/batch = 0.6362s	
4966/11850 (epoch 20.954), train_loss = 1.29294560, grad/param norm = 3.0208e-01, time/batch = 0.6354s	
4967/11850 (epoch 20.958), train_loss = 1.31953298, grad/param norm = 3.5257e-01, time/batch = 0.6263s	
4968/11850 (epoch 20.962), train_loss = 1.16737946, grad/param norm = 2.7040e-01, time/batch = 0.6242s	
4969/11850 (epoch 20.966), train_loss = 1.10583293, grad/param norm = 2.5034e-01, time/batch = 0.6263s	
4970/11850 (epoch 20.970), train_loss = 1.24568274, grad/param norm = 2.3375e-01, time/batch = 0.6287s	
4971/11850 (epoch 20.975), train_loss = 1.22780980, grad/param norm = 2.5386e-01, time/batch = 0.6254s	
4972/11850 (epoch 20.979), train_loss = 1.23512841, grad/param norm = 3.1306e-01, time/batch = 0.6260s	
4973/11850 (epoch 20.983), train_loss = 1.38304126, grad/param norm = 2.9248e-01, time/batch = 0.6265s	
4974/11850 (epoch 20.987), train_loss = 1.22008293, grad/param norm = 2.6366e-01, time/batch = 0.6260s	
4975/11850 (epoch 20.992), train_loss = 1.37167914, grad/param norm = 2.3867e-01, time/batch = 0.6586s	
4976/11850 (epoch 20.996), train_loss = 1.42652051, grad/param norm = 2.6556e-01, time/batch = 0.6391s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
4977/11850 (epoch 21.000), train_loss = 1.23629789, grad/param norm = 2.8432e-01, time/batch = 0.6244s	
4978/11850 (epoch 21.004), train_loss = 1.32627208, grad/param norm = 3.1069e-01, time/batch = 0.6257s	
4979/11850 (epoch 21.008), train_loss = 1.35323541, grad/param norm = 2.4861e-01, time/batch = 0.6270s	
4980/11850 (epoch 21.013), train_loss = 1.32497727, grad/param norm = 2.5373e-01, time/batch = 0.6267s	
4981/11850 (epoch 21.017), train_loss = 1.42718139, grad/param norm = 2.5061e-01, time/batch = 0.6289s	
4982/11850 (epoch 21.021), train_loss = 1.27418667, grad/param norm = 2.2293e-01, time/batch = 0.6285s	
4983/11850 (epoch 21.025), train_loss = 1.14369269, grad/param norm = 2.2476e-01, time/batch = 0.6263s	
4984/11850 (epoch 21.030), train_loss = 1.16829406, grad/param norm = 2.3571e-01, time/batch = 0.6271s	
4985/11850 (epoch 21.034), train_loss = 1.18868554, grad/param norm = 2.4019e-01, time/batch = 0.6310s	
4986/11850 (epoch 21.038), train_loss = 1.25066360, grad/param norm = 2.2460e-01, time/batch = 0.6228s	
4987/11850 (epoch 21.042), train_loss = 1.23834321, grad/param norm = 2.3849e-01, time/batch = 0.6239s	
4988/11850 (epoch 21.046), train_loss = 1.28639950, grad/param norm = 2.6975e-01, time/batch = 0.6283s	
4989/11850 (epoch 21.051), train_loss = 1.23158759, grad/param norm = 2.3711e-01, time/batch = 0.6251s	
4990/11850 (epoch 21.055), train_loss = 1.21107846, grad/param norm = 2.3823e-01, time/batch = 0.6262s	
4991/11850 (epoch 21.059), train_loss = 1.30787059, grad/param norm = 2.4551e-01, time/batch = 0.6301s	
4992/11850 (epoch 21.063), train_loss = 1.26805461, grad/param norm = 2.3541e-01, time/batch = 0.6250s	
4993/11850 (epoch 21.068), train_loss = 1.24812271, grad/param norm = 2.3663e-01, time/batch = 0.6268s	
4994/11850 (epoch 21.072), train_loss = 1.25402026, grad/param norm = 2.2336e-01, time/batch = 0.6244s	
4995/11850 (epoch 21.076), train_loss = 1.38174541, grad/param norm = 2.2728e-01, time/batch = 0.6279s	
4996/11850 (epoch 21.080), train_loss = 1.15848222, grad/param norm = 2.1263e-01, time/batch = 0.6577s	
4997/11850 (epoch 21.084), train_loss = 1.09706693, grad/param norm = 2.2101e-01, time/batch = 0.6581s	
4998/11850 (epoch 21.089), train_loss = 1.12302237, grad/param norm = 2.1160e-01, time/batch = 0.6448s	
4999/11850 (epoch 21.093), train_loss = 1.09826031, grad/param norm = 2.2981e-01, time/batch = 0.6308s	
evaluating loss over split index 2	
1/13...	
2/13...	
3/13...	
4/13...	
5/13...	
6/13...	
7/13...	
8/13...	
9/13...	
10/13...	
11/13...	
12/13...	
13/13...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_katelyn_salem_epoch21.10_1.9529.t7	
5000/11850 (epoch 21.097), train_loss = 1.25810677, grad/param norm = 2.4288e-01, time/batch = 0.6244s	
5001/11850 (epoch 21.101), train_loss = 1.53652285, grad/param norm = 2.9299e-01, time/batch = 0.6345s	
5002/11850 (epoch 21.105), train_loss = 1.12891523, grad/param norm = 2.2623e-01, time/batch = 0.6267s	
5003/11850 (epoch 21.110), train_loss = 1.28538676, grad/param norm = 2.2684e-01, time/batch = 0.6300s	
5004/11850 (epoch 21.114), train_loss = 1.25254880, grad/param norm = 2.5541e-01, time/batch = 0.6274s	
5005/11850 (epoch 21.118), train_loss = 1.23998873, grad/param norm = 2.1523e-01, time/batch = 0.6251s	
5006/11850 (epoch 21.122), train_loss = 1.31926897, grad/param norm = 2.4684e-01, time/batch = 0.6323s	
5007/11850 (epoch 21.127), train_loss = 1.26652497, grad/param norm = 2.6282e-01, time/batch = 0.6412s	
5008/11850 (epoch 21.131), train_loss = 1.25386795, grad/param norm = 2.9152e-01, time/batch = 0.6403s	
5009/11850 (epoch 21.135), train_loss = 1.21685202, grad/param norm = 2.8320e-01, time/batch = 0.6326s	
5010/11850 (epoch 21.139), train_loss = 1.19126013, grad/param norm = 2.3562e-01, time/batch = 0.6353s	
5011/11850 (epoch 21.143), train_loss = 1.21917076, grad/param norm = 2.4648e-01, time/batch = 0.6291s	
5012/11850 (epoch 21.148), train_loss = 1.24654129, grad/param norm = 2.6295e-01, time/batch = 0.6335s	
5013/11850 (epoch 21.152), train_loss = 1.35320223, grad/param norm = 3.7003e-01, time/batch = 0.6353s	
5014/11850 (epoch 21.156), train_loss = 1.28808214, grad/param norm = 3.0702e-01, time/batch = 0.6235s	
5015/11850 (epoch 21.160), train_loss = 1.51039529, grad/param norm = 3.4164e-01, time/batch = 0.6249s	
5016/11850 (epoch 21.165), train_loss = 1.40315764, grad/param norm = 3.0222e-01, time/batch = 0.6251s	
5017/11850 (epoch 21.169), train_loss = 1.23959446, grad/param norm = 3.2307e-01, time/batch = 0.6245s	
5018/11850 (epoch 21.173), train_loss = 1.30723359, grad/param norm = 2.9264e-01, time/batch = 0.6278s	
5019/11850 (epoch 21.177), train_loss = 1.20089691, grad/param norm = 2.9246e-01, time/batch = 0.6235s	
5020/11850 (epoch 21.181), train_loss = 1.31894619, grad/param norm = 2.4625e-01, time/batch = 0.6254s	
5021/11850 (epoch 21.186), train_loss = 1.38274600, grad/param norm = 3.2658e-01, time/batch = 0.6255s	
5022/11850 (epoch 21.190), train_loss = 1.26986540, grad/param norm = 2.3685e-01, time/batch = 0.6243s	
5023/11850 (epoch 21.194), train_loss = 1.37014138, grad/param norm = 2.9315e-01, time/batch = 0.6266s	
5024/11850 (epoch 21.198), train_loss = 1.10848717, grad/param norm = 2.4396e-01, time/batch = 0.6254s	
5025/11850 (epoch 21.203), train_loss = 1.13393798, grad/param norm = 2.3612e-01, time/batch = 0.6261s	
5026/11850 (epoch 21.207), train_loss = 1.30107880, grad/param norm = 2.7765e-01, time/batch = 0.6456s	
5027/11850 (epoch 21.211), train_loss = 1.25052346, grad/param norm = 2.4458e-01, time/batch = 0.6599s	
5028/11850 (epoch 21.215), train_loss = 1.25711917, grad/param norm = 2.6019e-01, time/batch = 0.6524s	
5029/11850 (epoch 21.219), train_loss = 1.24248482, grad/param norm = 2.5177e-01, time/batch = 0.6363s	
5030/11850 (epoch 21.224), train_loss = 1.41316841, grad/param norm = 2.4896e-01, time/batch = 0.6260s	
5031/11850 (epoch 21.228), train_loss = 1.34120949, grad/param norm = 2.5325e-01, time/batch = 0.6293s	
5032/11850 (epoch 21.232), train_loss = 1.31260317, grad/param norm = 2.7673e-01, time/batch = 0.6319s	
5033/11850 (epoch 21.236), train_loss = 1.16989373, grad/param norm = 2.4469e-01, time/batch = 0.6312s	
5034/11850 (epoch 21.241), train_loss = 1.37919312, grad/param norm = 2.6877e-01, time/batch = 0.6317s	
5035/11850 (epoch 21.245), train_loss = 1.32773681, grad/param norm = 2.3305e-01, time/batch = 0.6237s	
5036/11850 (epoch 21.249), train_loss = 1.19427090, grad/param norm = 2.6138e-01, time/batch = 0.6275s	
5037/11850 (epoch 21.253), train_loss = 1.25720579, grad/param norm = 2.7164e-01, time/batch = 0.6530s	
5038/11850 (epoch 21.257), train_loss = 1.37281763, grad/param norm = 2.4863e-01, time/batch = 0.6388s	
5039/11850 (epoch 21.262), train_loss = 1.42101414, grad/param norm = 2.5715e-01, time/batch = 0.6420s	
5040/11850 (epoch 21.266), train_loss = 1.34652098, grad/param norm = 2.5234e-01, time/batch = 0.6249s	
5041/11850 (epoch 21.270), train_loss = 1.20252335, grad/param norm = 2.1418e-01, time/batch = 0.6300s	
5042/11850 (epoch 21.274), train_loss = 1.22095106, grad/param norm = 2.9069e-01, time/batch = 0.6291s	
5043/11850 (epoch 21.278), train_loss = 1.08562015, grad/param norm = 2.4884e-01, time/batch = 0.6313s	
5044/11850 (epoch 21.283), train_loss = 1.17257834, grad/param norm = 2.2013e-01, time/batch = 0.6258s	
5045/11850 (epoch 21.287), train_loss = 1.34866033, grad/param norm = 2.4472e-01, time/batch = 0.6286s	
5046/11850 (epoch 21.291), train_loss = 1.24622620, grad/param norm = 2.2845e-01, time/batch = 0.6251s	
5047/11850 (epoch 21.295), train_loss = 1.27935911, grad/param norm = 2.4772e-01, time/batch = 0.6253s	
5048/11850 (epoch 21.300), train_loss = 1.21058816, grad/param norm = 2.5189e-01, time/batch = 0.6277s	
5049/11850 (epoch 21.304), train_loss = 1.21211742, grad/param norm = 2.2141e-01, time/batch = 0.6264s	
5050/11850 (epoch 21.308), train_loss = 1.19774612, grad/param norm = 2.3304e-01, time/batch = 0.6328s	
5051/11850 (epoch 21.312), train_loss = 1.07222199, grad/param norm = 2.0649e-01, time/batch = 0.6278s	
5052/11850 (epoch 21.316), train_loss = 1.28817978, grad/param norm = 2.3323e-01, time/batch = 0.6263s	
5053/11850 (epoch 21.321), train_loss = 1.18298781, grad/param norm = 2.2253e-01, time/batch = 0.6257s	
5054/11850 (epoch 21.325), train_loss = 1.23255763, grad/param norm = 2.4785e-01, time/batch = 0.6252s	
5055/11850 (epoch 21.329), train_loss = 1.22045743, grad/param norm = 2.3843e-01, time/batch = 0.6362s	
5056/11850 (epoch 21.333), train_loss = 1.21889153, grad/param norm = 2.4085e-01, time/batch = 0.6410s	
5057/11850 (epoch 21.338), train_loss = 1.13750207, grad/param norm = 2.1728e-01, time/batch = 0.6260s	
5058/11850 (epoch 21.342), train_loss = 1.28097045, grad/param norm = 2.8131e-01, time/batch = 0.6287s	
5059/11850 (epoch 21.346), train_loss = 1.23092284, grad/param norm = 2.4044e-01, time/batch = 0.6252s	
5060/11850 (epoch 21.350), train_loss = 1.09777441, grad/param norm = 2.3952e-01, time/batch = 0.6244s	
5061/11850 (epoch 21.354), train_loss = 1.30995676, grad/param norm = 2.5495e-01, time/batch = 0.6269s	
5062/11850 (epoch 21.359), train_loss = 1.34227422, grad/param norm = 2.7362e-01, time/batch = 0.6225s	
5063/11850 (epoch 21.363), train_loss = 1.27496524, grad/param norm = 2.3807e-01, time/batch = 0.6233s	
5064/11850 (epoch 21.367), train_loss = 1.27934984, grad/param norm = 2.2932e-01, time/batch = 0.6242s	
5065/11850 (epoch 21.371), train_loss = 1.28720502, grad/param norm = 2.3727e-01, time/batch = 0.6262s	
5066/11850 (epoch 21.376), train_loss = 1.21033184, grad/param norm = 2.4805e-01, time/batch = 0.6278s	
5067/11850 (epoch 21.380), train_loss = 1.16165447, grad/param norm = 2.3455e-01, time/batch = 0.6237s	
5068/11850 (epoch 21.384), train_loss = 1.14915183, grad/param norm = 2.4211e-01, time/batch = 0.6248s	
5069/11850 (epoch 21.388), train_loss = 1.31418895, grad/param norm = 2.4340e-01, time/batch = 0.6255s	
5070/11850 (epoch 21.392), train_loss = 1.32224439, grad/param norm = 2.4487e-01, time/batch = 0.6243s	
5071/11850 (epoch 21.397), train_loss = 1.32248444, grad/param norm = 3.0509e-01, time/batch = 0.6319s	
5072/11850 (epoch 21.401), train_loss = 1.10162765, grad/param norm = 2.1148e-01, time/batch = 0.6278s	
5073/11850 (epoch 21.405), train_loss = 1.17399560, grad/param norm = 2.2781e-01, time/batch = 0.6286s	
5074/11850 (epoch 21.409), train_loss = 1.32076399, grad/param norm = 2.4696e-01, time/batch = 0.6294s	
5075/11850 (epoch 21.414), train_loss = 1.10312593, grad/param norm = 2.2309e-01, time/batch = 0.6315s	
5076/11850 (epoch 21.418), train_loss = 1.13449546, grad/param norm = 2.2006e-01, time/batch = 0.6318s	
5077/11850 (epoch 21.422), train_loss = 1.05313891, grad/param norm = 2.4562e-01, time/batch = 0.6315s	
5078/11850 (epoch 21.426), train_loss = 1.09048487, grad/param norm = 2.4886e-01, time/batch = 0.6224s	
5079/11850 (epoch 21.430), train_loss = 1.14528674, grad/param norm = 2.4605e-01, time/batch = 0.6304s	
5080/11850 (epoch 21.435), train_loss = 1.15488482, grad/param norm = 2.0663e-01, time/batch = 0.6266s	
5081/11850 (epoch 21.439), train_loss = 1.30291102, grad/param norm = 2.4840e-01, time/batch = 0.6271s	
5082/11850 (epoch 21.443), train_loss = 1.24099181, grad/param norm = 2.3216e-01, time/batch = 0.6291s	
5083/11850 (epoch 21.447), train_loss = 1.10299503, grad/param norm = 2.3155e-01, time/batch = 0.6238s	
5084/11850 (epoch 21.451), train_loss = 1.12599593, grad/param norm = 2.1340e-01, time/batch = 0.6230s	
5085/11850 (epoch 21.456), train_loss = 1.19509076, grad/param norm = 2.4531e-01, time/batch = 0.6233s	
5086/11850 (epoch 21.460), train_loss = 1.23258530, grad/param norm = 2.4136e-01, time/batch = 0.6290s	
5087/11850 (epoch 21.464), train_loss = 1.15054925, grad/param norm = 2.2943e-01, time/batch = 0.6264s	
5088/11850 (epoch 21.468), train_loss = 1.23301272, grad/param norm = 2.4638e-01, time/batch = 0.6563s	
5089/11850 (epoch 21.473), train_loss = 1.27269125, grad/param norm = 2.4440e-01, time/batch = 0.6243s	
5090/11850 (epoch 21.477), train_loss = 1.11916570, grad/param norm = 2.4635e-01, time/batch = 0.6377s	
5091/11850 (epoch 21.481), train_loss = 1.13426285, grad/param norm = 2.6704e-01, time/batch = 0.6435s	
5092/11850 (epoch 21.485), train_loss = 1.10736496, grad/param norm = 2.1877e-01, time/batch = 0.6330s	
5093/11850 (epoch 21.489), train_loss = 1.23853207, grad/param norm = 2.2681e-01, time/batch = 0.6251s	
5094/11850 (epoch 21.494), train_loss = 1.13693826, grad/param norm = 2.6131e-01, time/batch = 0.6279s	
5095/11850 (epoch 21.498), train_loss = 1.12137171, grad/param norm = 2.6584e-01, time/batch = 0.6251s	
5096/11850 (epoch 21.502), train_loss = 1.08939427, grad/param norm = 2.7134e-01, time/batch = 0.6272s	
5097/11850 (epoch 21.506), train_loss = 1.34300866, grad/param norm = 2.5457e-01, time/batch = 0.6250s	
5098/11850 (epoch 21.511), train_loss = 1.20911488, grad/param norm = 2.3537e-01, time/batch = 0.6251s	
5099/11850 (epoch 21.515), train_loss = 1.34563151, grad/param norm = 2.6859e-01, time/batch = 0.6246s	
5100/11850 (epoch 21.519), train_loss = 1.15030184, grad/param norm = 2.2707e-01, time/batch = 0.6250s	
5101/11850 (epoch 21.523), train_loss = 1.18809413, grad/param norm = 2.4028e-01, time/batch = 0.6261s	
5102/11850 (epoch 21.527), train_loss = 1.10200837, grad/param norm = 2.4614e-01, time/batch = 0.6263s	
5103/11850 (epoch 21.532), train_loss = 1.25620100, grad/param norm = 2.2196e-01, time/batch = 0.6251s	
5104/11850 (epoch 21.536), train_loss = 1.14396021, grad/param norm = 2.1917e-01, time/batch = 0.6226s	
5105/11850 (epoch 21.540), train_loss = 1.11564616, grad/param norm = 2.2040e-01, time/batch = 0.6242s	
5106/11850 (epoch 21.544), train_loss = 1.15914343, grad/param norm = 2.7514e-01, time/batch = 0.6219s	
5107/11850 (epoch 21.549), train_loss = 1.03849545, grad/param norm = 2.1781e-01, time/batch = 0.6292s	
5108/11850 (epoch 21.553), train_loss = 1.22855100, grad/param norm = 2.4176e-01, time/batch = 0.6354s	
5109/11850 (epoch 21.557), train_loss = 1.29691191, grad/param norm = 2.6832e-01, time/batch = 0.6230s	
5110/11850 (epoch 21.561), train_loss = 1.23785776, grad/param norm = 2.5466e-01, time/batch = 0.6232s	
5111/11850 (epoch 21.565), train_loss = 1.33601407, grad/param norm = 2.5096e-01, time/batch = 0.6256s	
5112/11850 (epoch 21.570), train_loss = 1.18581428, grad/param norm = 2.2395e-01, time/batch = 0.6233s	
5113/11850 (epoch 21.574), train_loss = 1.29059454, grad/param norm = 2.6648e-01, time/batch = 0.6259s	
5114/11850 (epoch 21.578), train_loss = 1.33816743, grad/param norm = 2.5543e-01, time/batch = 0.6249s	
5115/11850 (epoch 21.582), train_loss = 1.16663108, grad/param norm = 3.3792e-01, time/batch = 0.6267s	
5116/11850 (epoch 21.586), train_loss = 1.19045346, grad/param norm = 2.5657e-01, time/batch = 0.6404s	
5117/11850 (epoch 21.591), train_loss = 1.28843309, grad/param norm = 2.5138e-01, time/batch = 0.6273s	
5118/11850 (epoch 21.595), train_loss = 1.06063888, grad/param norm = 2.2449e-01, time/batch = 0.6257s	
5119/11850 (epoch 21.599), train_loss = 1.19072831, grad/param norm = 2.8425e-01, time/batch = 0.6226s	
5120/11850 (epoch 21.603), train_loss = 1.14148183, grad/param norm = 2.2212e-01, time/batch = 0.6280s	
5121/11850 (epoch 21.608), train_loss = 1.34206803, grad/param norm = 2.3773e-01, time/batch = 0.6434s	
5122/11850 (epoch 21.612), train_loss = 1.40660010, grad/param norm = 2.6539e-01, time/batch = 0.6608s	
5123/11850 (epoch 21.616), train_loss = 1.32440647, grad/param norm = 2.3113e-01, time/batch = 0.6777s	
5124/11850 (epoch 21.620), train_loss = 1.19626795, grad/param norm = 2.3763e-01, time/batch = 0.6520s	
5125/11850 (epoch 21.624), train_loss = 1.23529746, grad/param norm = 2.6292e-01, time/batch = 0.6268s	
5126/11850 (epoch 21.629), train_loss = 1.14626577, grad/param norm = 2.2797e-01, time/batch = 0.6598s	
5127/11850 (epoch 21.633), train_loss = 1.07989237, grad/param norm = 2.4640e-01, time/batch = 0.6424s	
5128/11850 (epoch 21.637), train_loss = 1.09758072, grad/param norm = 2.5098e-01, time/batch = 0.6290s	
5129/11850 (epoch 21.641), train_loss = 1.08009378, grad/param norm = 2.1612e-01, time/batch = 0.6334s	
5130/11850 (epoch 21.646), train_loss = 1.15474483, grad/param norm = 2.3989e-01, time/batch = 0.6276s	
5131/11850 (epoch 21.650), train_loss = 1.20608616, grad/param norm = 2.5673e-01, time/batch = 0.6379s	
5132/11850 (epoch 21.654), train_loss = 1.13513024, grad/param norm = 2.4792e-01, time/batch = 0.6474s	
5133/11850 (epoch 21.658), train_loss = 1.23723248, grad/param norm = 2.4125e-01, time/batch = 0.6404s	
5134/11850 (epoch 21.662), train_loss = 1.07848817, grad/param norm = 2.6693e-01, time/batch = 0.6372s	
5135/11850 (epoch 21.667), train_loss = 1.29232254, grad/param norm = 2.3708e-01, time/batch = 0.6260s	
5136/11850 (epoch 21.671), train_loss = 1.18473868, grad/param norm = 2.4093e-01, time/batch = 0.6257s	
5137/11850 (epoch 21.675), train_loss = 1.16672061, grad/param norm = 2.2745e-01, time/batch = 0.6243s	
5138/11850 (epoch 21.679), train_loss = 1.23853220, grad/param norm = 2.6675e-01, time/batch = 0.6248s	
5139/11850 (epoch 21.684), train_loss = 1.21210552, grad/param norm = 2.4849e-01, time/batch = 0.6250s	
5140/11850 (epoch 21.688), train_loss = 1.13583531, grad/param norm = 2.2109e-01, time/batch = 0.6284s	
5141/11850 (epoch 21.692), train_loss = 1.18538185, grad/param norm = 3.1171e-01, time/batch = 0.6238s	
5142/11850 (epoch 21.696), train_loss = 1.11048538, grad/param norm = 2.4293e-01, time/batch = 0.6246s	
5143/11850 (epoch 21.700), train_loss = 1.21600932, grad/param norm = 2.6031e-01, time/batch = 0.6285s	
5144/11850 (epoch 21.705), train_loss = 1.16690623, grad/param norm = 2.5523e-01, time/batch = 0.6264s	
5145/11850 (epoch 21.709), train_loss = 1.05998842, grad/param norm = 2.3674e-01, time/batch = 0.6253s	
5146/11850 (epoch 21.713), train_loss = 1.11910877, grad/param norm = 2.9288e-01, time/batch = 0.6240s	
5147/11850 (epoch 21.717), train_loss = 1.14008154, grad/param norm = 2.3404e-01, time/batch = 0.6219s	
5148/11850 (epoch 21.722), train_loss = 1.22170007, grad/param norm = 2.7458e-01, time/batch = 0.6250s	
5149/11850 (epoch 21.726), train_loss = 1.08190796, grad/param norm = 2.3671e-01, time/batch = 0.6239s	
5150/11850 (epoch 21.730), train_loss = 1.07812253, grad/param norm = 2.4041e-01, time/batch = 0.6260s	
5151/11850 (epoch 21.734), train_loss = 1.13554739, grad/param norm = 2.1889e-01, time/batch = 0.6272s	
5152/11850 (epoch 21.738), train_loss = 1.28120817, grad/param norm = 2.8019e-01, time/batch = 0.6258s	
5153/11850 (epoch 21.743), train_loss = 1.19076843, grad/param norm = 2.3608e-01, time/batch = 0.6329s	
5154/11850 (epoch 21.747), train_loss = 1.05086582, grad/param norm = 2.0768e-01, time/batch = 0.6234s	
5155/11850 (epoch 21.751), train_loss = 1.08926410, grad/param norm = 2.3381e-01, time/batch = 0.6286s	
5156/11850 (epoch 21.755), train_loss = 1.18710171, grad/param norm = 2.4657e-01, time/batch = 0.6376s	
5157/11850 (epoch 21.759), train_loss = 1.13005837, grad/param norm = 2.4411e-01, time/batch = 0.6306s	
5158/11850 (epoch 21.764), train_loss = 1.14761057, grad/param norm = 2.2594e-01, time/batch = 0.6265s	
5159/11850 (epoch 21.768), train_loss = 1.04945792, grad/param norm = 2.2063e-01, time/batch = 0.6292s	
5160/11850 (epoch 21.772), train_loss = 1.14818927, grad/param norm = 2.4602e-01, time/batch = 0.6286s	
5161/11850 (epoch 21.776), train_loss = 1.18051797, grad/param norm = 2.3268e-01, time/batch = 0.6328s	
5162/11850 (epoch 21.781), train_loss = 1.15561582, grad/param norm = 2.4012e-01, time/batch = 0.6242s	
5163/11850 (epoch 21.785), train_loss = 1.11404591, grad/param norm = 2.3054e-01, time/batch = 0.6253s	
5164/11850 (epoch 21.789), train_loss = 1.19424122, grad/param norm = 2.4504e-01, time/batch = 0.6250s	
5165/11850 (epoch 21.793), train_loss = 1.28509700, grad/param norm = 2.7913e-01, time/batch = 0.6307s	
5166/11850 (epoch 21.797), train_loss = 1.20997025, grad/param norm = 2.5396e-01, time/batch = 0.6282s	
5167/11850 (epoch 21.802), train_loss = 1.07371217, grad/param norm = 2.4516e-01, time/batch = 0.6281s	
5168/11850 (epoch 21.806), train_loss = 1.17572706, grad/param norm = 2.3829e-01, time/batch = 0.6282s	
5169/11850 (epoch 21.810), train_loss = 1.30424000, grad/param norm = 2.6652e-01, time/batch = 0.6277s	
5170/11850 (epoch 21.814), train_loss = 1.16753479, grad/param norm = 2.6204e-01, time/batch = 0.6308s	
5171/11850 (epoch 21.819), train_loss = 1.30603184, grad/param norm = 2.5173e-01, time/batch = 0.6324s	
5172/11850 (epoch 21.823), train_loss = 1.33894893, grad/param norm = 2.8056e-01, time/batch = 0.6269s	
5173/11850 (epoch 21.827), train_loss = 1.18576011, grad/param norm = 2.4901e-01, time/batch = 0.6235s	
5174/11850 (epoch 21.831), train_loss = 1.19265258, grad/param norm = 2.5688e-01, time/batch = 0.6270s	
5175/11850 (epoch 21.835), train_loss = 1.17809133, grad/param norm = 2.2885e-01, time/batch = 0.6236s	
5176/11850 (epoch 21.840), train_loss = 1.14964013, grad/param norm = 2.2955e-01, time/batch = 0.6296s	
5177/11850 (epoch 21.844), train_loss = 1.18289992, grad/param norm = 2.2985e-01, time/batch = 0.6233s	
5178/11850 (epoch 21.848), train_loss = 1.21495384, grad/param norm = 2.6160e-01, time/batch = 0.6250s	
5179/11850 (epoch 21.852), train_loss = 1.18667130, grad/param norm = 2.4603e-01, time/batch = 0.6286s	
5180/11850 (epoch 21.857), train_loss = 1.20386686, grad/param norm = 2.8714e-01, time/batch = 0.6624s	
5181/11850 (epoch 21.861), train_loss = 1.20106937, grad/param norm = 2.7527e-01, time/batch = 0.6476s	
5182/11850 (epoch 21.865), train_loss = 1.28643920, grad/param norm = 3.9410e-01, time/batch = 0.6329s	
5183/11850 (epoch 21.869), train_loss = 1.25745889, grad/param norm = 2.8934e-01, time/batch = 0.6353s	
5184/11850 (epoch 21.873), train_loss = 1.26552727, grad/param norm = 3.0742e-01, time/batch = 0.6327s	
5185/11850 (epoch 21.878), train_loss = 1.28385688, grad/param norm = 2.9807e-01, time/batch = 0.6281s	
5186/11850 (epoch 21.882), train_loss = 1.21614825, grad/param norm = 2.6597e-01, time/batch = 0.6292s	
5187/11850 (epoch 21.886), train_loss = 1.24036491, grad/param norm = 2.8379e-01, time/batch = 0.6307s	
5188/11850 (epoch 21.890), train_loss = 1.23102920, grad/param norm = 2.7496e-01, time/batch = 0.6251s	
5189/11850 (epoch 21.895), train_loss = 1.23320653, grad/param norm = 2.8729e-01, time/batch = 0.6258s	
5190/11850 (epoch 21.899), train_loss = 1.11951851, grad/param norm = 2.8139e-01, time/batch = 0.6281s	
5191/11850 (epoch 21.903), train_loss = 1.18720642, grad/param norm = 2.7580e-01, time/batch = 0.6288s	
5192/11850 (epoch 21.907), train_loss = 1.16204458, grad/param norm = 2.7613e-01, time/batch = 0.6311s	
5193/11850 (epoch 21.911), train_loss = 1.28107221, grad/param norm = 2.3859e-01, time/batch = 0.6263s	
5194/11850 (epoch 21.916), train_loss = 1.28368565, grad/param norm = 2.7054e-01, time/batch = 0.6242s	
5195/11850 (epoch 21.920), train_loss = 1.20628261, grad/param norm = 2.5640e-01, time/batch = 0.6254s	
5196/11850 (epoch 21.924), train_loss = 1.18942795, grad/param norm = 2.8379e-01, time/batch = 0.6255s	
5197/11850 (epoch 21.928), train_loss = 1.27939100, grad/param norm = 3.1272e-01, time/batch = 0.6277s	
5198/11850 (epoch 21.932), train_loss = 1.30867889, grad/param norm = 2.5782e-01, time/batch = 0.6285s	
5199/11850 (epoch 21.937), train_loss = 1.26183673, grad/param norm = 2.6298e-01, time/batch = 0.6268s	
5200/11850 (epoch 21.941), train_loss = 1.27244974, grad/param norm = 2.3664e-01, time/batch = 0.6260s	
5201/11850 (epoch 21.945), train_loss = 1.27483225, grad/param norm = 2.4111e-01, time/batch = 0.6299s	
5202/11850 (epoch 21.949), train_loss = 1.16680084, grad/param norm = 2.8742e-01, time/batch = 0.6323s	
5203/11850 (epoch 21.954), train_loss = 1.25419282, grad/param norm = 2.5851e-01, time/batch = 0.6386s	
5204/11850 (epoch 21.958), train_loss = 1.25662941, grad/param norm = 2.9991e-01, time/batch = 0.6384s	
5205/11850 (epoch 21.962), train_loss = 1.13730171, grad/param norm = 2.5490e-01, time/batch = 0.6265s	
5206/11850 (epoch 21.966), train_loss = 1.07844551, grad/param norm = 2.3032e-01, time/batch = 0.6270s	
5207/11850 (epoch 21.970), train_loss = 1.23629866, grad/param norm = 2.8615e-01, time/batch = 0.6286s	
5208/11850 (epoch 21.975), train_loss = 1.19325789, grad/param norm = 2.6451e-01, time/batch = 0.6287s	
5209/11850 (epoch 21.979), train_loss = 1.19538796, grad/param norm = 2.6505e-01, time/batch = 0.6321s	
5210/11850 (epoch 21.983), train_loss = 1.33686754, grad/param norm = 3.2113e-01, time/batch = 0.6256s	
5211/11850 (epoch 21.987), train_loss = 1.19764503, grad/param norm = 2.6418e-01, time/batch = 0.6276s	
5212/11850 (epoch 21.992), train_loss = 1.34286045, grad/param norm = 2.4657e-01, time/batch = 0.6273s	
5213/11850 (epoch 21.996), train_loss = 1.40358460, grad/param norm = 3.0403e-01, time/batch = 0.6263s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
5214/11850 (epoch 22.000), train_loss = 1.20287503, grad/param norm = 2.6490e-01, time/batch = 0.6286s	
5215/11850 (epoch 22.004), train_loss = 1.28555652, grad/param norm = 2.5515e-01, time/batch = 0.6368s	
5216/11850 (epoch 22.008), train_loss = 1.34117098, grad/param norm = 2.6742e-01, time/batch = 0.6627s	
5217/11850 (epoch 22.013), train_loss = 1.30444233, grad/param norm = 2.6651e-01, time/batch = 0.6589s	
5218/11850 (epoch 22.017), train_loss = 1.39719230, grad/param norm = 2.5140e-01, time/batch = 0.6499s	
5219/11850 (epoch 22.021), train_loss = 1.25363898, grad/param norm = 2.2142e-01, time/batch = 0.6687s	
5220/11850 (epoch 22.025), train_loss = 1.11857983, grad/param norm = 2.3550e-01, time/batch = 0.6548s	
5221/11850 (epoch 22.030), train_loss = 1.14494617, grad/param norm = 2.3374e-01, time/batch = 0.6586s	
5222/11850 (epoch 22.034), train_loss = 1.16913160, grad/param norm = 2.4195e-01, time/batch = 0.6703s	
5223/11850 (epoch 22.038), train_loss = 1.23077331, grad/param norm = 2.3253e-01, time/batch = 0.6824s	
5224/11850 (epoch 22.042), train_loss = 1.21084614, grad/param norm = 2.2750e-01, time/batch = 0.6540s	
5225/11850 (epoch 22.046), train_loss = 1.24894045, grad/param norm = 2.6669e-01, time/batch = 0.6477s	
5226/11850 (epoch 22.051), train_loss = 1.20753456, grad/param norm = 2.3528e-01, time/batch = 0.6510s	
5227/11850 (epoch 22.055), train_loss = 1.18495401, grad/param norm = 2.4267e-01, time/batch = 0.6480s	
5228/11850 (epoch 22.059), train_loss = 1.28598491, grad/param norm = 2.5153e-01, time/batch = 0.6450s	
5229/11850 (epoch 22.063), train_loss = 1.25015419, grad/param norm = 2.4051e-01, time/batch = 0.6467s	
5230/11850 (epoch 22.068), train_loss = 1.21420334, grad/param norm = 2.3311e-01, time/batch = 0.6579s	
5231/11850 (epoch 22.072), train_loss = 1.22949178, grad/param norm = 2.2547e-01, time/batch = 0.6712s	
5232/11850 (epoch 22.076), train_loss = 1.35613761, grad/param norm = 2.3110e-01, time/batch = 0.6600s	
5233/11850 (epoch 22.080), train_loss = 1.13288968, grad/param norm = 2.1869e-01, time/batch = 0.6699s	
5234/11850 (epoch 22.084), train_loss = 1.07263780, grad/param norm = 2.1628e-01, time/batch = 0.6521s	
5235/11850 (epoch 22.089), train_loss = 1.10364694, grad/param norm = 2.2643e-01, time/batch = 0.6408s	
5236/11850 (epoch 22.093), train_loss = 1.08168940, grad/param norm = 2.4634e-01, time/batch = 0.6512s	
5237/11850 (epoch 22.097), train_loss = 1.22851602, grad/param norm = 2.6444e-01, time/batch = 0.6450s	
5238/11850 (epoch 22.101), train_loss = 1.19429917, grad/param norm = 2.7898e-01, time/batch = 0.6439s	
5239/11850 (epoch 22.105), train_loss = 1.10932053, grad/param norm = 2.2756e-01, time/batch = 0.6426s	
5240/11850 (epoch 22.110), train_loss = 1.25457727, grad/param norm = 2.5756e-01, time/batch = 0.6648s	
5241/11850 (epoch 22.114), train_loss = 1.23133406, grad/param norm = 2.7415e-01, time/batch = 0.6754s	
5242/11850 (epoch 22.118), train_loss = 1.22708120, grad/param norm = 2.2806e-01, time/batch = 0.6429s	
5243/11850 (epoch 22.122), train_loss = 1.30189088, grad/param norm = 2.5641e-01, time/batch = 0.6442s	
5244/11850 (epoch 22.127), train_loss = 1.24886326, grad/param norm = 2.6476e-01, time/batch = 0.6460s	
5245/11850 (epoch 22.131), train_loss = 1.22024355, grad/param norm = 2.7855e-01, time/batch = 0.6438s	
5246/11850 (epoch 22.135), train_loss = 1.17221600, grad/param norm = 2.5304e-01, time/batch = 0.6434s	
5247/11850 (epoch 22.139), train_loss = 1.15902616, grad/param norm = 2.4127e-01, time/batch = 0.6435s	
5248/11850 (epoch 22.143), train_loss = 1.19188273, grad/param norm = 2.5243e-01, time/batch = 0.6424s	
5249/11850 (epoch 22.148), train_loss = 1.22528742, grad/param norm = 2.7398e-01, time/batch = 0.6450s	
5250/11850 (epoch 22.152), train_loss = 1.31720714, grad/param norm = 2.9972e-01, time/batch = 0.6425s	
5251/11850 (epoch 22.156), train_loss = 1.23104085, grad/param norm = 2.7990e-01, time/batch = 0.6735s	
5252/11850 (epoch 22.160), train_loss = 1.49131229, grad/param norm = 3.5806e-01, time/batch = 0.6717s	
5253/11850 (epoch 22.165), train_loss = 1.38176178, grad/param norm = 2.9705e-01, time/batch = 0.6486s	
5254/11850 (epoch 22.169), train_loss = 1.18770933, grad/param norm = 2.6268e-01, time/batch = 0.6722s	
5255/11850 (epoch 22.173), train_loss = 1.27602964, grad/param norm = 2.5976e-01, time/batch = 0.6735s	
5256/11850 (epoch 22.177), train_loss = 1.16967415, grad/param norm = 2.8572e-01, time/batch = 0.6733s	
5257/11850 (epoch 22.181), train_loss = 1.28792978, grad/param norm = 2.4112e-01, time/batch = 0.6748s	
5258/11850 (epoch 22.186), train_loss = 1.36069902, grad/param norm = 3.0616e-01, time/batch = 0.6733s	
5259/11850 (epoch 22.190), train_loss = 1.23643131, grad/param norm = 2.2423e-01, time/batch = 0.6710s	
5260/11850 (epoch 22.194), train_loss = 1.33021960, grad/param norm = 2.9348e-01, time/batch = 0.6607s	
5261/11850 (epoch 22.198), train_loss = 1.10142365, grad/param norm = 2.5644e-01, time/batch = 0.6643s	
5262/11850 (epoch 22.203), train_loss = 1.10888769, grad/param norm = 2.4602e-01, time/batch = 0.6463s	
5263/11850 (epoch 22.207), train_loss = 1.27372406, grad/param norm = 2.5153e-01, time/batch = 0.6423s	
5264/11850 (epoch 22.211), train_loss = 1.22992594, grad/param norm = 2.4907e-01, time/batch = 0.6438s	
5265/11850 (epoch 22.215), train_loss = 1.22137253, grad/param norm = 2.5799e-01, time/batch = 0.6432s	
5266/11850 (epoch 22.219), train_loss = 1.22940382, grad/param norm = 2.5193e-01, time/batch = 0.6541s	
5267/11850 (epoch 22.224), train_loss = 1.36645124, grad/param norm = 2.3712e-01, time/batch = 0.6480s	
5268/11850 (epoch 22.228), train_loss = 1.30994308, grad/param norm = 2.7902e-01, time/batch = 0.6430s	
5269/11850 (epoch 22.232), train_loss = 1.27034740, grad/param norm = 2.5561e-01, time/batch = 0.6489s	
5270/11850 (epoch 22.236), train_loss = 1.15236527, grad/param norm = 2.7107e-01, time/batch = 0.6438s	
5271/11850 (epoch 22.241), train_loss = 1.33729498, grad/param norm = 2.7804e-01, time/batch = 0.6434s	
5272/11850 (epoch 22.245), train_loss = 1.29606219, grad/param norm = 2.5016e-01, time/batch = 0.6652s	
5273/11850 (epoch 22.249), train_loss = 1.16678996, grad/param norm = 2.6558e-01, time/batch = 0.6697s	
5274/11850 (epoch 22.253), train_loss = 1.23031446, grad/param norm = 2.7026e-01, time/batch = 0.6444s	
5275/11850 (epoch 22.257), train_loss = 1.35118210, grad/param norm = 2.5242e-01, time/batch = 0.6450s	
5276/11850 (epoch 22.262), train_loss = 1.38433436, grad/param norm = 2.6013e-01, time/batch = 0.6456s	
5277/11850 (epoch 22.266), train_loss = 1.32606703, grad/param norm = 2.6115e-01, time/batch = 0.6439s	
5278/11850 (epoch 22.270), train_loss = 1.17809347, grad/param norm = 2.2305e-01, time/batch = 0.6439s	
5279/11850 (epoch 22.274), train_loss = 1.19832349, grad/param norm = 2.8300e-01, time/batch = 0.6475s	
5280/11850 (epoch 22.278), train_loss = 1.05363300, grad/param norm = 2.3513e-01, time/batch = 0.6409s	
5281/11850 (epoch 22.283), train_loss = 1.16322022, grad/param norm = 2.4394e-01, time/batch = 0.6444s	
5282/11850 (epoch 22.287), train_loss = 1.32814243, grad/param norm = 2.5199e-01, time/batch = 0.6452s	
5283/11850 (epoch 22.291), train_loss = 1.22525090, grad/param norm = 2.4965e-01, time/batch = 0.6764s	
5284/11850 (epoch 22.295), train_loss = 1.25017221, grad/param norm = 2.4487e-01, time/batch = 0.6654s	
5285/11850 (epoch 22.300), train_loss = 1.18164788, grad/param norm = 2.5735e-01, time/batch = 0.6462s	
5286/11850 (epoch 22.304), train_loss = 1.18411090, grad/param norm = 2.1954e-01, time/batch = 0.6425s	
5287/11850 (epoch 22.308), train_loss = 1.16455796, grad/param norm = 2.2713e-01, time/batch = 0.6430s	
5288/11850 (epoch 22.312), train_loss = 1.05447577, grad/param norm = 2.2515e-01, time/batch = 0.6403s	
5289/11850 (epoch 22.316), train_loss = 1.25223377, grad/param norm = 2.3716e-01, time/batch = 0.6427s	
5290/11850 (epoch 22.321), train_loss = 1.15479336, grad/param norm = 2.2660e-01, time/batch = 0.6450s	
5291/11850 (epoch 22.325), train_loss = 1.20530287, grad/param norm = 2.4563e-01, time/batch = 0.6424s	
5292/11850 (epoch 22.329), train_loss = 1.20090683, grad/param norm = 2.5579e-01, time/batch = 0.6461s	
5293/11850 (epoch 22.333), train_loss = 1.19634125, grad/param norm = 2.5007e-01, time/batch = 0.6553s	
5294/11850 (epoch 22.338), train_loss = 1.11524057, grad/param norm = 2.1784e-01, time/batch = 0.6748s	
5295/11850 (epoch 22.342), train_loss = 1.24921887, grad/param norm = 2.7388e-01, time/batch = 0.6566s	
5296/11850 (epoch 22.346), train_loss = 1.20188284, grad/param norm = 2.3210e-01, time/batch = 0.6522s	
5297/11850 (epoch 22.350), train_loss = 1.07449607, grad/param norm = 2.4194e-01, time/batch = 0.6438s	
5298/11850 (epoch 22.354), train_loss = 1.27819645, grad/param norm = 2.5378e-01, time/batch = 0.6435s	
5299/11850 (epoch 22.359), train_loss = 1.32187579, grad/param norm = 2.7511e-01, time/batch = 0.6435s	
5300/11850 (epoch 22.363), train_loss = 1.25214608, grad/param norm = 2.4461e-01, time/batch = 0.6433s	
5301/11850 (epoch 22.367), train_loss = 1.24782001, grad/param norm = 2.3918e-01, time/batch = 0.6462s	
5302/11850 (epoch 22.371), train_loss = 1.24986897, grad/param norm = 2.2919e-01, time/batch = 0.6451s	
5303/11850 (epoch 22.376), train_loss = 1.18481697, grad/param norm = 2.2926e-01, time/batch = 0.6488s	
5304/11850 (epoch 22.380), train_loss = 1.13457534, grad/param norm = 2.1361e-01, time/batch = 0.6468s	
5305/11850 (epoch 22.384), train_loss = 1.12353403, grad/param norm = 2.3203e-01, time/batch = 0.6419s	
5306/11850 (epoch 22.388), train_loss = 1.30222809, grad/param norm = 2.7141e-01, time/batch = 0.6427s	
5307/11850 (epoch 22.392), train_loss = 1.28725052, grad/param norm = 2.5151e-01, time/batch = 0.6612s	
5308/11850 (epoch 22.397), train_loss = 1.28521682, grad/param norm = 2.8145e-01, time/batch = 0.6713s	
5309/11850 (epoch 22.401), train_loss = 1.08590474, grad/param norm = 2.2796e-01, time/batch = 0.6696s	
5310/11850 (epoch 22.405), train_loss = 1.14451551, grad/param norm = 2.3654e-01, time/batch = 0.6519s	
5311/11850 (epoch 22.409), train_loss = 1.29074411, grad/param norm = 2.5273e-01, time/batch = 0.6433s	
5312/11850 (epoch 22.414), train_loss = 1.07144040, grad/param norm = 2.2071e-01, time/batch = 0.6578s	
5313/11850 (epoch 22.418), train_loss = 1.11015950, grad/param norm = 2.4022e-01, time/batch = 0.6514s	
5314/11850 (epoch 22.422), train_loss = 1.02492755, grad/param norm = 2.3863e-01, time/batch = 0.6366s	
5315/11850 (epoch 22.426), train_loss = 1.05454110, grad/param norm = 2.2978e-01, time/batch = 0.6541s	
5316/11850 (epoch 22.430), train_loss = 1.11594408, grad/param norm = 2.4684e-01, time/batch = 0.6482s	
5317/11850 (epoch 22.435), train_loss = 1.13613406, grad/param norm = 2.2619e-01, time/batch = 0.6293s	
5318/11850 (epoch 22.439), train_loss = 1.26944670, grad/param norm = 2.4289e-01, time/batch = 0.6332s	
5319/11850 (epoch 22.443), train_loss = 1.22095179, grad/param norm = 2.5669e-01, time/batch = 0.6410s	
5320/11850 (epoch 22.447), train_loss = 1.09240838, grad/param norm = 2.8433e-01, time/batch = 0.6379s	
5321/11850 (epoch 22.451), train_loss = 1.10562318, grad/param norm = 2.2614e-01, time/batch = 0.6403s	
5322/11850 (epoch 22.456), train_loss = 1.17424735, grad/param norm = 2.4982e-01, time/batch = 0.6285s	
5323/11850 (epoch 22.460), train_loss = 1.21720042, grad/param norm = 2.4657e-01, time/batch = 0.6296s	
5324/11850 (epoch 22.464), train_loss = 1.12057950, grad/param norm = 2.2976e-01, time/batch = 0.6303s	
5325/11850 (epoch 22.468), train_loss = 1.21095878, grad/param norm = 2.4206e-01, time/batch = 0.6284s	
5326/11850 (epoch 22.473), train_loss = 1.24512027, grad/param norm = 2.4176e-01, time/batch = 0.6561s	
5327/11850 (epoch 22.477), train_loss = 1.08924744, grad/param norm = 2.5213e-01, time/batch = 0.6485s	
5328/11850 (epoch 22.481), train_loss = 1.10612153, grad/param norm = 2.6422e-01, time/batch = 0.6308s	
5329/11850 (epoch 22.485), train_loss = 1.07466403, grad/param norm = 2.2079e-01, time/batch = 0.6303s	
5330/11850 (epoch 22.489), train_loss = 1.21502468, grad/param norm = 2.4275e-01, time/batch = 0.6286s	
5331/11850 (epoch 22.494), train_loss = 1.11081970, grad/param norm = 2.6333e-01, time/batch = 0.6305s	
5332/11850 (epoch 22.498), train_loss = 1.09480205, grad/param norm = 2.5842e-01, time/batch = 0.6369s	
5333/11850 (epoch 22.502), train_loss = 1.05377778, grad/param norm = 2.4346e-01, time/batch = 0.6418s	
5334/11850 (epoch 22.506), train_loss = 1.31659965, grad/param norm = 2.4624e-01, time/batch = 0.6345s	
5335/11850 (epoch 22.511), train_loss = 1.19292672, grad/param norm = 2.6278e-01, time/batch = 0.6373s	
5336/11850 (epoch 22.515), train_loss = 1.32422772, grad/param norm = 2.7114e-01, time/batch = 0.6456s	
5337/11850 (epoch 22.519), train_loss = 1.12586653, grad/param norm = 2.3047e-01, time/batch = 0.6592s	
5338/11850 (epoch 22.523), train_loss = 1.16165622, grad/param norm = 2.3062e-01, time/batch = 0.6498s	
5339/11850 (epoch 22.527), train_loss = 1.07366777, grad/param norm = 2.3036e-01, time/batch = 0.6379s	
5340/11850 (epoch 22.532), train_loss = 1.23699934, grad/param norm = 2.2535e-01, time/batch = 0.6350s	
5341/11850 (epoch 22.536), train_loss = 1.12323706, grad/param norm = 2.4233e-01, time/batch = 0.6365s	
5342/11850 (epoch 22.540), train_loss = 1.09610467, grad/param norm = 2.1623e-01, time/batch = 0.6359s	
5343/11850 (epoch 22.544), train_loss = 1.13259453, grad/param norm = 2.7489e-01, time/batch = 0.6346s	
5344/11850 (epoch 22.549), train_loss = 1.02983446, grad/param norm = 2.2683e-01, time/batch = 0.6399s	
5345/11850 (epoch 22.553), train_loss = 1.20788846, grad/param norm = 2.6435e-01, time/batch = 0.6416s	
5346/11850 (epoch 22.557), train_loss = 1.25749297, grad/param norm = 2.6951e-01, time/batch = 0.6465s	
5347/11850 (epoch 22.561), train_loss = 1.21088302, grad/param norm = 2.5003e-01, time/batch = 0.6396s	
5348/11850 (epoch 22.565), train_loss = 1.30766628, grad/param norm = 2.4753e-01, time/batch = 0.6631s	
5349/11850 (epoch 22.570), train_loss = 1.17054048, grad/param norm = 2.2972e-01, time/batch = 0.6432s	
5350/11850 (epoch 22.574), train_loss = 1.26623825, grad/param norm = 2.7438e-01, time/batch = 0.6283s	
5351/11850 (epoch 22.578), train_loss = 1.30570560, grad/param norm = 2.5062e-01, time/batch = 0.6289s	
5352/11850 (epoch 22.582), train_loss = 1.17515241, grad/param norm = 3.6951e-01, time/batch = 0.6260s	
5353/11850 (epoch 22.586), train_loss = 1.16651603, grad/param norm = 2.5644e-01, time/batch = 0.6272s	
5354/11850 (epoch 22.591), train_loss = 1.27050664, grad/param norm = 2.8246e-01, time/batch = 0.6342s	
5355/11850 (epoch 22.595), train_loss = 1.03740873, grad/param norm = 2.3852e-01, time/batch = 0.6293s	
5356/11850 (epoch 22.599), train_loss = 1.16854227, grad/param norm = 2.6387e-01, time/batch = 0.6257s	
5357/11850 (epoch 22.603), train_loss = 1.13224843, grad/param norm = 2.4291e-01, time/batch = 0.6270s	
5358/11850 (epoch 22.608), train_loss = 1.32456358, grad/param norm = 2.4657e-01, time/batch = 0.6235s	
5359/11850 (epoch 22.612), train_loss = 1.37351950, grad/param norm = 2.6041e-01, time/batch = 0.6247s	
5360/11850 (epoch 22.616), train_loss = 1.30058210, grad/param norm = 2.2704e-01, time/batch = 0.6266s	
5361/11850 (epoch 22.620), train_loss = 1.16906275, grad/param norm = 2.3702e-01, time/batch = 0.6261s	
5362/11850 (epoch 22.624), train_loss = 1.19755960, grad/param norm = 2.6176e-01, time/batch = 0.6334s	
5363/11850 (epoch 22.629), train_loss = 1.11661241, grad/param norm = 2.5047e-01, time/batch = 0.6296s	
5364/11850 (epoch 22.633), train_loss = 1.07484618, grad/param norm = 2.7294e-01, time/batch = 0.6243s	
5365/11850 (epoch 22.637), train_loss = 1.06300298, grad/param norm = 2.4896e-01, time/batch = 0.6242s	
5366/11850 (epoch 22.641), train_loss = 1.06003474, grad/param norm = 2.1889e-01, time/batch = 0.6251s	
5367/11850 (epoch 22.646), train_loss = 1.11967221, grad/param norm = 2.3990e-01, time/batch = 0.6238s	
5368/11850 (epoch 22.650), train_loss = 1.18162833, grad/param norm = 2.9788e-01, time/batch = 0.6298s	
5369/11850 (epoch 22.654), train_loss = 1.13997157, grad/param norm = 2.9807e-01, time/batch = 0.6279s	
5370/11850 (epoch 22.658), train_loss = 1.21268843, grad/param norm = 2.4768e-01, time/batch = 0.6272s	
5371/11850 (epoch 22.662), train_loss = 1.06079627, grad/param norm = 2.7044e-01, time/batch = 0.6344s	
5372/11850 (epoch 22.667), train_loss = 1.26144161, grad/param norm = 2.3874e-01, time/batch = 0.6258s	
5373/11850 (epoch 22.671), train_loss = 1.16301877, grad/param norm = 2.5301e-01, time/batch = 0.6270s	
5374/11850 (epoch 22.675), train_loss = 1.14226967, grad/param norm = 2.4745e-01, time/batch = 0.6244s	
5375/11850 (epoch 22.679), train_loss = 1.20291178, grad/param norm = 2.5375e-01, time/batch = 0.6237s	
5376/11850 (epoch 22.684), train_loss = 1.17966346, grad/param norm = 2.6896e-01, time/batch = 0.6298s	
5377/11850 (epoch 22.688), train_loss = 1.10823197, grad/param norm = 2.3038e-01, time/batch = 0.6260s	
5378/11850 (epoch 22.692), train_loss = 1.16086841, grad/param norm = 2.7475e-01, time/batch = 0.6253s	
5379/11850 (epoch 22.696), train_loss = 1.09065476, grad/param norm = 2.5131e-01, time/batch = 0.6242s	
5380/11850 (epoch 22.700), train_loss = 1.18398056, grad/param norm = 2.4806e-01, time/batch = 0.6245s	
5381/11850 (epoch 22.705), train_loss = 1.13690475, grad/param norm = 2.5691e-01, time/batch = 0.6550s	
5382/11850 (epoch 22.709), train_loss = 1.04327641, grad/param norm = 2.5503e-01, time/batch = 0.6489s	
5383/11850 (epoch 22.713), train_loss = 1.08473825, grad/param norm = 2.4412e-01, time/batch = 0.6283s	
5384/11850 (epoch 22.717), train_loss = 1.11721364, grad/param norm = 2.5202e-01, time/batch = 0.6280s	
5385/11850 (epoch 22.722), train_loss = 1.19595283, grad/param norm = 2.9320e-01, time/batch = 0.6286s	
5386/11850 (epoch 22.726), train_loss = 1.05731078, grad/param norm = 2.4031e-01, time/batch = 0.6291s	
5387/11850 (epoch 22.730), train_loss = 1.05549074, grad/param norm = 2.3483e-01, time/batch = 0.6306s	
5388/11850 (epoch 22.734), train_loss = 1.11313098, grad/param norm = 2.5092e-01, time/batch = 0.6319s	
5389/11850 (epoch 22.738), train_loss = 1.24989750, grad/param norm = 3.0348e-01, time/batch = 0.6281s	
5390/11850 (epoch 22.743), train_loss = 1.17023184, grad/param norm = 2.4146e-01, time/batch = 0.6361s	
5391/11850 (epoch 22.747), train_loss = 1.03068241, grad/param norm = 2.1181e-01, time/batch = 0.6288s	
5392/11850 (epoch 22.751), train_loss = 1.07089926, grad/param norm = 2.3179e-01, time/batch = 0.6456s	
5393/11850 (epoch 22.755), train_loss = 1.16093160, grad/param norm = 2.2480e-01, time/batch = 0.6290s	
5394/11850 (epoch 22.759), train_loss = 1.10907156, grad/param norm = 2.4746e-01, time/batch = 0.6280s	
5395/11850 (epoch 22.764), train_loss = 1.12514568, grad/param norm = 2.4804e-01, time/batch = 0.6296s	
5396/11850 (epoch 22.768), train_loss = 1.03704608, grad/param norm = 2.3739e-01, time/batch = 0.6294s	
5397/11850 (epoch 22.772), train_loss = 1.11973149, grad/param norm = 2.5852e-01, time/batch = 0.6257s	
5398/11850 (epoch 22.776), train_loss = 1.16175794, grad/param norm = 2.2867e-01, time/batch = 0.6274s	
5399/11850 (epoch 22.781), train_loss = 1.13895913, grad/param norm = 2.3691e-01, time/batch = 0.6242s	
5400/11850 (epoch 22.785), train_loss = 1.09612980, grad/param norm = 2.5636e-01, time/batch = 0.6273s	
5401/11850 (epoch 22.789), train_loss = 1.17252569, grad/param norm = 2.4983e-01, time/batch = 0.6452s	
5402/11850 (epoch 22.793), train_loss = 1.25357261, grad/param norm = 2.8467e-01, time/batch = 0.6518s	
5403/11850 (epoch 22.797), train_loss = 1.18358408, grad/param norm = 2.6452e-01, time/batch = 0.6595s	
5404/11850 (epoch 22.802), train_loss = 1.04779651, grad/param norm = 2.3724e-01, time/batch = 0.6308s	
5405/11850 (epoch 22.806), train_loss = 1.14454851, grad/param norm = 2.2670e-01, time/batch = 0.6338s	
5406/11850 (epoch 22.810), train_loss = 1.27722666, grad/param norm = 2.7597e-01, time/batch = 0.6277s	
5407/11850 (epoch 22.814), train_loss = 1.12760725, grad/param norm = 2.4237e-01, time/batch = 0.6440s	
5408/11850 (epoch 22.819), train_loss = 1.28444802, grad/param norm = 2.5765e-01, time/batch = 0.6388s	
5409/11850 (epoch 22.823), train_loss = 1.31253515, grad/param norm = 2.6057e-01, time/batch = 0.6323s	
5410/11850 (epoch 22.827), train_loss = 1.16751183, grad/param norm = 2.5034e-01, time/batch = 0.6272s	
5411/11850 (epoch 22.831), train_loss = 1.16715650, grad/param norm = 2.5342e-01, time/batch = 0.6298s	
5412/11850 (epoch 22.835), train_loss = 1.15747700, grad/param norm = 2.2522e-01, time/batch = 0.6279s	
5413/11850 (epoch 22.840), train_loss = 1.12845262, grad/param norm = 2.3839e-01, time/batch = 0.6248s	
5414/11850 (epoch 22.844), train_loss = 1.15238476, grad/param norm = 2.2522e-01, time/batch = 0.6299s	
5415/11850 (epoch 22.848), train_loss = 1.17856024, grad/param norm = 2.3241e-01, time/batch = 0.6296s	
5416/11850 (epoch 22.852), train_loss = 1.16752646, grad/param norm = 2.6859e-01, time/batch = 0.6290s	
5417/11850 (epoch 22.857), train_loss = 1.16515254, grad/param norm = 3.0254e-01, time/batch = 0.6283s	
5418/11850 (epoch 22.861), train_loss = 1.15662329, grad/param norm = 2.5949e-01, time/batch = 0.6280s	
5419/11850 (epoch 22.865), train_loss = 1.23692231, grad/param norm = 3.1343e-01, time/batch = 0.6273s	
5420/11850 (epoch 22.869), train_loss = 1.23140868, grad/param norm = 3.0258e-01, time/batch = 0.6291s	
5421/11850 (epoch 22.873), train_loss = 1.23108766, grad/param norm = 2.6040e-01, time/batch = 0.6284s	
5422/11850 (epoch 22.878), train_loss = 1.24803194, grad/param norm = 2.7772e-01, time/batch = 0.6258s	
5423/11850 (epoch 22.882), train_loss = 1.19005217, grad/param norm = 2.4294e-01, time/batch = 0.6262s	
5424/11850 (epoch 22.886), train_loss = 1.20739358, grad/param norm = 2.9391e-01, time/batch = 0.6265s	
5425/11850 (epoch 22.890), train_loss = 1.19985363, grad/param norm = 2.7448e-01, time/batch = 0.6511s	
5426/11850 (epoch 22.895), train_loss = 1.22122851, grad/param norm = 2.9204e-01, time/batch = 0.6496s	
5427/11850 (epoch 22.899), train_loss = 1.07977615, grad/param norm = 2.5226e-01, time/batch = 0.6250s	
5428/11850 (epoch 22.903), train_loss = 1.16568343, grad/param norm = 2.9172e-01, time/batch = 0.6239s	
5429/11850 (epoch 22.907), train_loss = 1.14262867, grad/param norm = 2.6337e-01, time/batch = 0.6271s	
5430/11850 (epoch 22.911), train_loss = 1.26486686, grad/param norm = 2.6425e-01, time/batch = 0.6282s	
5431/11850 (epoch 22.916), train_loss = 1.25042869, grad/param norm = 2.7118e-01, time/batch = 0.6294s	
5432/11850 (epoch 22.920), train_loss = 1.17958445, grad/param norm = 2.5271e-01, time/batch = 0.6400s	
5433/11850 (epoch 22.924), train_loss = 1.16425755, grad/param norm = 2.7245e-01, time/batch = 0.6427s	
5434/11850 (epoch 22.928), train_loss = 1.25204841, grad/param norm = 2.8532e-01, time/batch = 0.6314s	
5435/11850 (epoch 22.932), train_loss = 1.29905883, grad/param norm = 2.3795e-01, time/batch = 0.6426s	
5436/11850 (epoch 22.937), train_loss = 1.22416124, grad/param norm = 2.4456e-01, time/batch = 0.6570s	
5437/11850 (epoch 22.941), train_loss = 1.23340153, grad/param norm = 2.4511e-01, time/batch = 0.6472s	
5438/11850 (epoch 22.945), train_loss = 1.25590848, grad/param norm = 2.4240e-01, time/batch = 0.6250s	
5439/11850 (epoch 22.949), train_loss = 1.13783456, grad/param norm = 2.6888e-01, time/batch = 0.6248s	
5440/11850 (epoch 22.954), train_loss = 1.23607527, grad/param norm = 2.7170e-01, time/batch = 0.6244s	
5441/11850 (epoch 22.958), train_loss = 1.22623468, grad/param norm = 2.7683e-01, time/batch = 0.6274s	
5442/11850 (epoch 22.962), train_loss = 1.11478184, grad/param norm = 2.7166e-01, time/batch = 0.6268s	
5443/11850 (epoch 22.966), train_loss = 1.05496840, grad/param norm = 2.4481e-01, time/batch = 0.6291s	
5444/11850 (epoch 22.970), train_loss = 1.20351011, grad/param norm = 2.7322e-01, time/batch = 0.6338s	
5445/11850 (epoch 22.975), train_loss = 1.17253476, grad/param norm = 2.5389e-01, time/batch = 0.6321s	
5446/11850 (epoch 22.979), train_loss = 1.17217405, grad/param norm = 2.5402e-01, time/batch = 0.6292s	
5447/11850 (epoch 22.983), train_loss = 1.30241503, grad/param norm = 3.2563e-01, time/batch = 0.6520s	
5448/11850 (epoch 22.987), train_loss = 1.16516142, grad/param norm = 2.6733e-01, time/batch = 0.6505s	
5449/11850 (epoch 22.992), train_loss = 1.32035943, grad/param norm = 2.5649e-01, time/batch = 0.6329s	
5450/11850 (epoch 22.996), train_loss = 1.35430796, grad/param norm = 3.0366e-01, time/batch = 0.6347s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
5451/11850 (epoch 23.000), train_loss = 1.18594953, grad/param norm = 2.8731e-01, time/batch = 0.6323s	
5452/11850 (epoch 23.004), train_loss = 1.24814569, grad/param norm = 2.5982e-01, time/batch = 0.6268s	
5453/11850 (epoch 23.008), train_loss = 1.30719866, grad/param norm = 2.5197e-01, time/batch = 0.6257s	
5454/11850 (epoch 23.013), train_loss = 1.27921950, grad/param norm = 2.5322e-01, time/batch = 0.6263s	
5455/11850 (epoch 23.017), train_loss = 1.36050762, grad/param norm = 2.4559e-01, time/batch = 0.6263s	
5456/11850 (epoch 23.021), train_loss = 1.22851293, grad/param norm = 2.3134e-01, time/batch = 0.6373s	
5457/11850 (epoch 23.025), train_loss = 1.09953017, grad/param norm = 2.3078e-01, time/batch = 0.6331s	
5458/11850 (epoch 23.030), train_loss = 1.13025938, grad/param norm = 2.5474e-01, time/batch = 0.6524s	
5459/11850 (epoch 23.034), train_loss = 1.14480009, grad/param norm = 2.4787e-01, time/batch = 0.6486s	
5460/11850 (epoch 23.038), train_loss = 1.19990026, grad/param norm = 2.3701e-01, time/batch = 0.6241s	
5461/11850 (epoch 23.042), train_loss = 1.19045171, grad/param norm = 2.6788e-01, time/batch = 0.6267s	
5462/11850 (epoch 23.046), train_loss = 1.21847254, grad/param norm = 2.6642e-01, time/batch = 0.6273s	
5463/11850 (epoch 23.051), train_loss = 1.18643050, grad/param norm = 2.3915e-01, time/batch = 0.6289s	
5464/11850 (epoch 23.055), train_loss = 1.15688514, grad/param norm = 2.4252e-01, time/batch = 0.6271s	
5465/11850 (epoch 23.059), train_loss = 1.25694575, grad/param norm = 2.4444e-01, time/batch = 0.6247s	
5466/11850 (epoch 23.063), train_loss = 1.22611840, grad/param norm = 2.4988e-01, time/batch = 0.6290s	
5467/11850 (epoch 23.068), train_loss = 1.19066997, grad/param norm = 2.3422e-01, time/batch = 0.6282s	
5468/11850 (epoch 23.072), train_loss = 1.21195223, grad/param norm = 2.2996e-01, time/batch = 0.6248s	
5469/11850 (epoch 23.076), train_loss = 1.33114338, grad/param norm = 2.3804e-01, time/batch = 0.6258s	
5470/11850 (epoch 23.080), train_loss = 1.11205084, grad/param norm = 2.2511e-01, time/batch = 0.6314s	
5471/11850 (epoch 23.084), train_loss = 1.04056089, grad/param norm = 2.1272e-01, time/batch = 0.6444s	
5472/11850 (epoch 23.089), train_loss = 1.07796756, grad/param norm = 2.3094e-01, time/batch = 0.6290s	
5473/11850 (epoch 23.093), train_loss = 1.07332421, grad/param norm = 3.1419e-01, time/batch = 0.6279s	
5474/11850 (epoch 23.097), train_loss = 1.20105777, grad/param norm = 2.6902e-01, time/batch = 0.6256s	
5475/11850 (epoch 23.101), train_loss = 1.15277362, grad/param norm = 2.7871e-01, time/batch = 0.6257s	
5476/11850 (epoch 23.105), train_loss = 1.07544020, grad/param norm = 2.1550e-01, time/batch = 0.6251s	
5477/11850 (epoch 23.110), train_loss = 1.23643711, grad/param norm = 2.3711e-01, time/batch = 0.6287s	
5478/11850 (epoch 23.114), train_loss = 1.20593837, grad/param norm = 2.7219e-01, time/batch = 0.6276s	
5479/11850 (epoch 23.118), train_loss = 1.21485656, grad/param norm = 2.3202e-01, time/batch = 0.6296s	
5480/11850 (epoch 23.122), train_loss = 1.27304689, grad/param norm = 2.6008e-01, time/batch = 0.6309s	
5481/11850 (epoch 23.127), train_loss = 1.21379292, grad/param norm = 2.6886e-01, time/batch = 0.6276s	
5482/11850 (epoch 23.131), train_loss = 1.19671049, grad/param norm = 2.8614e-01, time/batch = 0.6284s	
5483/11850 (epoch 23.135), train_loss = 1.15022383, grad/param norm = 2.6613e-01, time/batch = 0.6277s	
5484/11850 (epoch 23.139), train_loss = 1.13512317, grad/param norm = 2.4282e-01, time/batch = 0.6256s	
5485/11850 (epoch 23.143), train_loss = 1.16743760, grad/param norm = 2.5763e-01, time/batch = 0.6584s	
5486/11850 (epoch 23.148), train_loss = 1.19739283, grad/param norm = 2.8426e-01, time/batch = 0.6460s	
5487/11850 (epoch 23.152), train_loss = 1.29405257, grad/param norm = 2.9393e-01, time/batch = 0.6265s	
5488/11850 (epoch 23.156), train_loss = 1.20812030, grad/param norm = 2.9490e-01, time/batch = 0.6261s	
5489/11850 (epoch 23.160), train_loss = 1.43772739, grad/param norm = 3.3075e-01, time/batch = 0.6272s	
5490/11850 (epoch 23.165), train_loss = 1.34084051, grad/param norm = 2.9837e-01, time/batch = 0.6259s	
5491/11850 (epoch 23.169), train_loss = 1.17279022, grad/param norm = 2.9220e-01, time/batch = 0.6303s	
5492/11850 (epoch 23.173), train_loss = 1.23982885, grad/param norm = 2.5121e-01, time/batch = 0.6290s	
5493/11850 (epoch 23.177), train_loss = 1.14494073, grad/param norm = 3.1155e-01, time/batch = 0.6268s	
5494/11850 (epoch 23.181), train_loss = 1.26412025, grad/param norm = 2.5619e-01, time/batch = 0.6263s	
5495/11850 (epoch 23.186), train_loss = 1.32737117, grad/param norm = 3.1195e-01, time/batch = 0.6343s	
5496/11850 (epoch 23.190), train_loss = 1.21862440, grad/param norm = 2.3608e-01, time/batch = 0.6589s	
5497/11850 (epoch 23.194), train_loss = 1.29002675, grad/param norm = 3.4660e-01, time/batch = 0.6588s	
5498/11850 (epoch 23.198), train_loss = 1.05680014, grad/param norm = 2.4953e-01, time/batch = 0.6382s	
5499/11850 (epoch 23.203), train_loss = 1.09401201, grad/param norm = 2.7670e-01, time/batch = 0.6327s	
5500/11850 (epoch 23.207), train_loss = 1.26213812, grad/param norm = 3.0104e-01, time/batch = 0.6374s	
5501/11850 (epoch 23.211), train_loss = 1.21404235, grad/param norm = 2.6324e-01, time/batch = 0.6451s	
5502/11850 (epoch 23.215), train_loss = 1.19972241, grad/param norm = 2.7603e-01, time/batch = 0.6262s	
5503/11850 (epoch 23.219), train_loss = 1.19550980, grad/param norm = 2.5571e-01, time/batch = 0.6309s	
5504/11850 (epoch 23.224), train_loss = 1.34915136, grad/param norm = 2.5615e-01, time/batch = 0.6307s	
5505/11850 (epoch 23.228), train_loss = 1.28159849, grad/param norm = 2.7642e-01, time/batch = 0.6357s	
5506/11850 (epoch 23.232), train_loss = 1.23424651, grad/param norm = 2.6823e-01, time/batch = 0.6365s	
5507/11850 (epoch 23.236), train_loss = 1.11905308, grad/param norm = 2.7495e-01, time/batch = 0.6596s	
5508/11850 (epoch 23.241), train_loss = 1.30938292, grad/param norm = 2.8849e-01, time/batch = 0.6457s	
5509/11850 (epoch 23.245), train_loss = 1.26891448, grad/param norm = 2.3947e-01, time/batch = 0.6288s	
5510/11850 (epoch 23.249), train_loss = 1.14526433, grad/param norm = 2.6845e-01, time/batch = 0.6247s	
5511/11850 (epoch 23.253), train_loss = 1.20857552, grad/param norm = 2.6949e-01, time/batch = 0.6290s	
5512/11850 (epoch 23.257), train_loss = 1.31848114, grad/param norm = 2.5036e-01, time/batch = 0.6393s	
5513/11850 (epoch 23.262), train_loss = 1.36461000, grad/param norm = 2.8445e-01, time/batch = 0.6256s	
5514/11850 (epoch 23.266), train_loss = 1.29913008, grad/param norm = 2.7514e-01, time/batch = 0.6303s	
5515/11850 (epoch 23.270), train_loss = 1.16521195, grad/param norm = 2.3492e-01, time/batch = 0.6269s	
5516/11850 (epoch 23.274), train_loss = 1.18429917, grad/param norm = 2.7467e-01, time/batch = 0.6238s	
5517/11850 (epoch 23.278), train_loss = 1.04107812, grad/param norm = 2.6496e-01, time/batch = 0.6274s	
5518/11850 (epoch 23.283), train_loss = 1.14035543, grad/param norm = 2.3328e-01, time/batch = 0.6219s	
5519/11850 (epoch 23.287), train_loss = 1.30541588, grad/param norm = 2.4995e-01, time/batch = 0.6213s	
5520/11850 (epoch 23.291), train_loss = 1.18874651, grad/param norm = 2.4485e-01, time/batch = 0.6213s	
5521/11850 (epoch 23.295), train_loss = 1.24988020, grad/param norm = 2.6492e-01, time/batch = 0.6257s	
5522/11850 (epoch 23.300), train_loss = 1.15348617, grad/param norm = 2.5925e-01, time/batch = 0.6282s	
5523/11850 (epoch 23.304), train_loss = 1.16419605, grad/param norm = 2.2172e-01, time/batch = 0.6282s	
5524/11850 (epoch 23.308), train_loss = 1.13990972, grad/param norm = 2.3433e-01, time/batch = 0.6292s	
5525/11850 (epoch 23.312), train_loss = 1.03699820, grad/param norm = 2.1884e-01, time/batch = 0.6340s	
5526/11850 (epoch 23.316), train_loss = 1.23566158, grad/param norm = 2.4808e-01, time/batch = 0.6344s	
5527/11850 (epoch 23.321), train_loss = 1.13691696, grad/param norm = 2.3241e-01, time/batch = 0.6270s	
5528/11850 (epoch 23.325), train_loss = 1.18608564, grad/param norm = 2.6380e-01, time/batch = 0.6293s	
5529/11850 (epoch 23.329), train_loss = 1.17809081, grad/param norm = 2.4607e-01, time/batch = 0.6562s	
5530/11850 (epoch 23.333), train_loss = 1.17322325, grad/param norm = 2.5971e-01, time/batch = 0.6463s	
5531/11850 (epoch 23.338), train_loss = 1.08787488, grad/param norm = 2.2682e-01, time/batch = 0.6352s	
5532/11850 (epoch 23.342), train_loss = 1.22000387, grad/param norm = 2.5113e-01, time/batch = 0.6277s	
5533/11850 (epoch 23.346), train_loss = 1.17795528, grad/param norm = 2.3917e-01, time/batch = 0.6267s	
5534/11850 (epoch 23.350), train_loss = 1.04064125, grad/param norm = 2.3611e-01, time/batch = 0.6280s	
5535/11850 (epoch 23.354), train_loss = 1.25038645, grad/param norm = 2.3869e-01, time/batch = 0.6296s	
5536/11850 (epoch 23.359), train_loss = 1.29636953, grad/param norm = 2.8988e-01, time/batch = 0.6270s	
5537/11850 (epoch 23.363), train_loss = 1.22775012, grad/param norm = 2.3797e-01, time/batch = 0.6268s	
5538/11850 (epoch 23.367), train_loss = 1.23206843, grad/param norm = 2.5554e-01, time/batch = 0.6250s	
5539/11850 (epoch 23.371), train_loss = 1.23283626, grad/param norm = 2.3884e-01, time/batch = 0.6249s	
5540/11850 (epoch 23.376), train_loss = 1.15946111, grad/param norm = 2.2605e-01, time/batch = 0.6548s	
5541/11850 (epoch 23.380), train_loss = 1.11077151, grad/param norm = 2.1032e-01, time/batch = 0.6482s	
5542/11850 (epoch 23.384), train_loss = 1.09519017, grad/param norm = 2.2934e-01, time/batch = 0.6272s	
5543/11850 (epoch 23.388), train_loss = 1.26557870, grad/param norm = 2.6218e-01, time/batch = 0.6294s	
5544/11850 (epoch 23.392), train_loss = 1.25604581, grad/param norm = 2.4587e-01, time/batch = 0.6306s	
5545/11850 (epoch 23.397), train_loss = 1.26881780, grad/param norm = 3.6378e-01, time/batch = 0.6272s	
5546/11850 (epoch 23.401), train_loss = 1.06019325, grad/param norm = 2.2452e-01, time/batch = 0.6282s	
5547/11850 (epoch 23.405), train_loss = 1.12133258, grad/param norm = 2.5578e-01, time/batch = 0.6263s	
5548/11850 (epoch 23.409), train_loss = 1.27493159, grad/param norm = 2.5618e-01, time/batch = 0.6240s	
5549/11850 (epoch 23.414), train_loss = 1.05325942, grad/param norm = 2.3437e-01, time/batch = 0.6274s	
5550/11850 (epoch 23.418), train_loss = 1.08928659, grad/param norm = 2.3657e-01, time/batch = 0.6296s	
5551/11850 (epoch 23.422), train_loss = 0.99900230, grad/param norm = 2.4662e-01, time/batch = 0.6278s	
5552/11850 (epoch 23.426), train_loss = 1.03137893, grad/param norm = 2.5075e-01, time/batch = 0.6281s	
5553/11850 (epoch 23.430), train_loss = 1.09785560, grad/param norm = 2.8976e-01, time/batch = 0.6268s	
5554/11850 (epoch 23.435), train_loss = 1.11539493, grad/param norm = 2.2919e-01, time/batch = 0.6269s	
5555/11850 (epoch 23.439), train_loss = 1.23935257, grad/param norm = 2.5694e-01, time/batch = 0.6274s	
5556/11850 (epoch 23.443), train_loss = 1.17786997, grad/param norm = 2.3871e-01, time/batch = 0.6289s	
5557/11850 (epoch 23.447), train_loss = 1.06724608, grad/param norm = 2.4728e-01, time/batch = 0.6290s	
5558/11850 (epoch 23.451), train_loss = 1.07629095, grad/param norm = 2.2144e-01, time/batch = 0.6388s	
5559/11850 (epoch 23.456), train_loss = 1.15420567, grad/param norm = 2.4469e-01, time/batch = 0.6231s	
5560/11850 (epoch 23.460), train_loss = 1.20230070, grad/param norm = 2.6614e-01, time/batch = 0.6297s	
5561/11850 (epoch 23.464), train_loss = 1.10851321, grad/param norm = 2.5466e-01, time/batch = 0.6365s	
5562/11850 (epoch 23.468), train_loss = 1.18914658, grad/param norm = 2.4710e-01, time/batch = 0.6601s	
5563/11850 (epoch 23.473), train_loss = 1.23254169, grad/param norm = 2.7185e-01, time/batch = 0.6509s	
5564/11850 (epoch 23.477), train_loss = 1.07154866, grad/param norm = 2.5461e-01, time/batch = 0.6270s	
5565/11850 (epoch 23.481), train_loss = 1.09572319, grad/param norm = 2.6530e-01, time/batch = 0.6275s	
5566/11850 (epoch 23.485), train_loss = 1.05830799, grad/param norm = 2.2845e-01, time/batch = 0.6239s	
5567/11850 (epoch 23.489), train_loss = 1.18988388, grad/param norm = 2.4007e-01, time/batch = 0.6264s	
5568/11850 (epoch 23.494), train_loss = 1.07498065, grad/param norm = 2.7049e-01, time/batch = 0.6239s	
5569/11850 (epoch 23.498), train_loss = 1.06800216, grad/param norm = 2.8066e-01, time/batch = 0.6231s	
5570/11850 (epoch 23.502), train_loss = 1.04300436, grad/param norm = 2.7353e-01, time/batch = 0.6236s	
5571/11850 (epoch 23.506), train_loss = 1.29792443, grad/param norm = 2.5675e-01, time/batch = 0.6285s	
5572/11850 (epoch 23.511), train_loss = 1.16396790, grad/param norm = 2.4600e-01, time/batch = 0.6256s	
5573/11850 (epoch 23.515), train_loss = 1.28677983, grad/param norm = 2.6960e-01, time/batch = 0.6507s	
5574/11850 (epoch 23.519), train_loss = 1.11593343, grad/param norm = 2.4467e-01, time/batch = 0.6496s	
5575/11850 (epoch 23.523), train_loss = 1.14854168, grad/param norm = 2.3287e-01, time/batch = 0.6228s	
5576/11850 (epoch 23.527), train_loss = 1.06343158, grad/param norm = 2.4538e-01, time/batch = 0.6262s	
5577/11850 (epoch 23.532), train_loss = 1.20796493, grad/param norm = 2.3213e-01, time/batch = 0.6277s	
5578/11850 (epoch 23.536), train_loss = 1.09680115, grad/param norm = 2.2541e-01, time/batch = 0.6256s	
5579/11850 (epoch 23.540), train_loss = 1.06952910, grad/param norm = 2.1212e-01, time/batch = 0.6279s	
5580/11850 (epoch 23.544), train_loss = 1.09746784, grad/param norm = 2.3364e-01, time/batch = 0.6297s	
5581/11850 (epoch 23.549), train_loss = 1.00435786, grad/param norm = 2.1839e-01, time/batch = 0.6240s	
5582/11850 (epoch 23.553), train_loss = 1.17048132, grad/param norm = 2.4877e-01, time/batch = 0.6246s	
5583/11850 (epoch 23.557), train_loss = 1.22223177, grad/param norm = 2.5039e-01, time/batch = 0.6220s	
5584/11850 (epoch 23.561), train_loss = 1.19494537, grad/param norm = 2.6489e-01, time/batch = 0.6490s	
5585/11850 (epoch 23.565), train_loss = 1.28314864, grad/param norm = 2.5333e-01, time/batch = 0.6514s	
5586/11850 (epoch 23.570), train_loss = 1.14819627, grad/param norm = 2.3854e-01, time/batch = 0.6340s	
5587/11850 (epoch 23.574), train_loss = 1.23902373, grad/param norm = 2.8933e-01, time/batch = 0.6273s	
5588/11850 (epoch 23.578), train_loss = 1.27689985, grad/param norm = 2.5226e-01, time/batch = 0.6252s	
5589/11850 (epoch 23.582), train_loss = 1.13562774, grad/param norm = 2.9099e-01, time/batch = 0.6262s	
5590/11850 (epoch 23.586), train_loss = 1.13921867, grad/param norm = 2.4233e-01, time/batch = 0.6440s	
5591/11850 (epoch 23.591), train_loss = 1.22953987, grad/param norm = 2.6005e-01, time/batch = 0.6606s	
5592/11850 (epoch 23.595), train_loss = 1.01819101, grad/param norm = 2.3280e-01, time/batch = 0.6711s	
5593/11850 (epoch 23.599), train_loss = 1.15343565, grad/param norm = 2.8436e-01, time/batch = 0.6572s	
5594/11850 (epoch 23.603), train_loss = 1.10271121, grad/param norm = 2.3106e-01, time/batch = 0.6495s	
5595/11850 (epoch 23.608), train_loss = 1.30481341, grad/param norm = 2.6041e-01, time/batch = 0.6598s	
5596/11850 (epoch 23.612), train_loss = 1.35436814, grad/param norm = 2.8187e-01, time/batch = 0.6442s	
5597/11850 (epoch 23.616), train_loss = 1.28055955, grad/param norm = 2.4728e-01, time/batch = 0.6557s	
5598/11850 (epoch 23.620), train_loss = 1.15099920, grad/param norm = 2.5127e-01, time/batch = 0.6411s	
5599/11850 (epoch 23.624), train_loss = 1.18621377, grad/param norm = 3.4404e-01, time/batch = 0.6257s	
5600/11850 (epoch 23.629), train_loss = 1.09416452, grad/param norm = 2.4032e-01, time/batch = 0.6322s	
5601/11850 (epoch 23.633), train_loss = 1.03340393, grad/param norm = 2.4611e-01, time/batch = 0.6326s	
5602/11850 (epoch 23.637), train_loss = 1.03378994, grad/param norm = 2.4167e-01, time/batch = 0.6296s	
5603/11850 (epoch 23.641), train_loss = 1.03490658, grad/param norm = 2.3099e-01, time/batch = 0.6305s	
5604/11850 (epoch 23.646), train_loss = 1.10402400, grad/param norm = 2.4892e-01, time/batch = 0.6289s	
5605/11850 (epoch 23.650), train_loss = 1.15826986, grad/param norm = 2.6974e-01, time/batch = 0.6277s	
5606/11850 (epoch 23.654), train_loss = 1.09321161, grad/param norm = 2.5558e-01, time/batch = 0.6583s	
5607/11850 (epoch 23.658), train_loss = 1.18582910, grad/param norm = 2.3614e-01, time/batch = 0.6408s	
5608/11850 (epoch 23.662), train_loss = 1.03155155, grad/param norm = 2.6972e-01, time/batch = 0.6237s	
5609/11850 (epoch 23.667), train_loss = 1.23713201, grad/param norm = 2.4142e-01, time/batch = 0.6417s	
5610/11850 (epoch 23.671), train_loss = 1.14864139, grad/param norm = 2.6451e-01, time/batch = 0.6222s	
5611/11850 (epoch 23.675), train_loss = 1.11810704, grad/param norm = 2.4310e-01, time/batch = 0.6259s	
5612/11850 (epoch 23.679), train_loss = 1.18449236, grad/param norm = 2.8090e-01, time/batch = 0.6341s	
5613/11850 (epoch 23.684), train_loss = 1.15998834, grad/param norm = 2.8529e-01, time/batch = 0.6454s	
5614/11850 (epoch 23.688), train_loss = 1.09304862, grad/param norm = 2.3003e-01, time/batch = 0.6566s	
5615/11850 (epoch 23.692), train_loss = 1.12896463, grad/param norm = 2.9605e-01, time/batch = 0.6563s	
5616/11850 (epoch 23.696), train_loss = 1.06529617, grad/param norm = 2.4983e-01, time/batch = 0.6569s	
5617/11850 (epoch 23.700), train_loss = 1.16117459, grad/param norm = 2.5005e-01, time/batch = 0.6597s	
5618/11850 (epoch 23.705), train_loss = 1.11693300, grad/param norm = 2.5776e-01, time/batch = 0.6554s	
5619/11850 (epoch 23.709), train_loss = 1.00352074, grad/param norm = 2.2396e-01, time/batch = 0.6512s	
5620/11850 (epoch 23.713), train_loss = 1.05381759, grad/param norm = 2.6296e-01, time/batch = 0.6353s	
5621/11850 (epoch 23.717), train_loss = 1.09776453, grad/param norm = 2.5648e-01, time/batch = 0.6383s	
5622/11850 (epoch 23.722), train_loss = 1.17652311, grad/param norm = 2.9272e-01, time/batch = 0.6254s	
5623/11850 (epoch 23.726), train_loss = 1.04198825, grad/param norm = 2.8787e-01, time/batch = 0.6277s	
5624/11850 (epoch 23.730), train_loss = 1.03394219, grad/param norm = 2.3521e-01, time/batch = 0.6277s	
5625/11850 (epoch 23.734), train_loss = 1.08664582, grad/param norm = 2.2491e-01, time/batch = 0.6262s	
5626/11850 (epoch 23.738), train_loss = 1.22982080, grad/param norm = 2.7178e-01, time/batch = 0.6281s	
5627/11850 (epoch 23.743), train_loss = 1.13988675, grad/param norm = 2.4335e-01, time/batch = 0.6348s	
5628/11850 (epoch 23.747), train_loss = 1.00736863, grad/param norm = 2.2095e-01, time/batch = 0.6587s	
5629/11850 (epoch 23.751), train_loss = 1.05539632, grad/param norm = 2.3509e-01, time/batch = 0.6393s	
5630/11850 (epoch 23.755), train_loss = 1.14732189, grad/param norm = 2.5470e-01, time/batch = 0.6286s	
5631/11850 (epoch 23.759), train_loss = 1.07942959, grad/param norm = 2.2901e-01, time/batch = 0.6289s	
5632/11850 (epoch 23.764), train_loss = 1.09549290, grad/param norm = 2.4107e-01, time/batch = 0.6307s	
5633/11850 (epoch 23.768), train_loss = 1.01321449, grad/param norm = 2.4260e-01, time/batch = 0.6289s	
5634/11850 (epoch 23.772), train_loss = 1.09875619, grad/param norm = 2.6937e-01, time/batch = 0.6282s	
5635/11850 (epoch 23.776), train_loss = 1.14885791, grad/param norm = 2.4253e-01, time/batch = 0.6253s	
5636/11850 (epoch 23.781), train_loss = 1.11987299, grad/param norm = 2.7986e-01, time/batch = 0.6248s	
5637/11850 (epoch 23.785), train_loss = 1.08191573, grad/param norm = 2.6817e-01, time/batch = 0.6435s	
5638/11850 (epoch 23.789), train_loss = 1.13934284, grad/param norm = 2.5617e-01, time/batch = 0.6438s	
5639/11850 (epoch 23.793), train_loss = 1.23340989, grad/param norm = 2.8544e-01, time/batch = 0.6581s	
5640/11850 (epoch 23.797), train_loss = 1.15811009, grad/param norm = 2.5281e-01, time/batch = 0.6369s	
5641/11850 (epoch 23.802), train_loss = 1.04402788, grad/param norm = 2.8119e-01, time/batch = 0.6382s	
5642/11850 (epoch 23.806), train_loss = 1.12254818, grad/param norm = 2.4564e-01, time/batch = 0.6323s	
5643/11850 (epoch 23.810), train_loss = 1.24875564, grad/param norm = 2.7566e-01, time/batch = 0.6278s	
5644/11850 (epoch 23.814), train_loss = 1.11911193, grad/param norm = 2.8760e-01, time/batch = 0.6252s	
5645/11850 (epoch 23.819), train_loss = 1.25427611, grad/param norm = 2.8958e-01, time/batch = 0.6293s	
5646/11850 (epoch 23.823), train_loss = 1.28606256, grad/param norm = 2.7250e-01, time/batch = 0.6257s	
5647/11850 (epoch 23.827), train_loss = 1.14945575, grad/param norm = 2.6275e-01, time/batch = 0.6272s	
5648/11850 (epoch 23.831), train_loss = 1.12795316, grad/param norm = 2.3691e-01, time/batch = 0.6277s	
5649/11850 (epoch 23.835), train_loss = 1.13539865, grad/param norm = 2.2342e-01, time/batch = 0.6337s	
5650/11850 (epoch 23.840), train_loss = 1.10500308, grad/param norm = 2.4220e-01, time/batch = 0.6580s	
5651/11850 (epoch 23.844), train_loss = 1.12792876, grad/param norm = 2.3585e-01, time/batch = 0.6367s	
5652/11850 (epoch 23.848), train_loss = 1.15648961, grad/param norm = 2.4485e-01, time/batch = 0.6293s	
5653/11850 (epoch 23.852), train_loss = 1.13921936, grad/param norm = 2.5080e-01, time/batch = 0.6321s	
5654/11850 (epoch 23.857), train_loss = 1.13652101, grad/param norm = 2.7069e-01, time/batch = 0.6314s	
5655/11850 (epoch 23.861), train_loss = 1.13414562, grad/param norm = 2.6316e-01, time/batch = 0.6316s	
5656/11850 (epoch 23.865), train_loss = 1.21307829, grad/param norm = 2.9768e-01, time/batch = 0.6271s	
5657/11850 (epoch 23.869), train_loss = 1.18376276, grad/param norm = 2.5088e-01, time/batch = 0.6265s	
5658/11850 (epoch 23.873), train_loss = 1.19625836, grad/param norm = 2.5874e-01, time/batch = 0.6274s	
5659/11850 (epoch 23.878), train_loss = 1.22380655, grad/param norm = 3.2113e-01, time/batch = 0.6334s	
5660/11850 (epoch 23.882), train_loss = 1.16222301, grad/param norm = 2.5149e-01, time/batch = 0.6399s	
5661/11850 (epoch 23.886), train_loss = 1.17358333, grad/param norm = 3.0500e-01, time/batch = 0.6601s	
5662/11850 (epoch 23.890), train_loss = 1.19400663, grad/param norm = 2.9893e-01, time/batch = 0.6412s	
5663/11850 (epoch 23.895), train_loss = 1.20028536, grad/param norm = 4.6747e-01, time/batch = 0.6277s	
5664/11850 (epoch 23.899), train_loss = 1.08898301, grad/param norm = 3.0806e-01, time/batch = 0.6266s	
5665/11850 (epoch 23.903), train_loss = 1.14286154, grad/param norm = 2.9104e-01, time/batch = 0.6267s	
5666/11850 (epoch 23.907), train_loss = 1.12690742, grad/param norm = 2.9667e-01, time/batch = 0.6243s	
5667/11850 (epoch 23.911), train_loss = 1.25097176, grad/param norm = 2.8027e-01, time/batch = 0.6237s	
5668/11850 (epoch 23.916), train_loss = 1.22550871, grad/param norm = 2.8087e-01, time/batch = 0.6266s	
5669/11850 (epoch 23.920), train_loss = 1.15943262, grad/param norm = 2.6093e-01, time/batch = 0.6301s	
5670/11850 (epoch 23.924), train_loss = 1.13605225, grad/param norm = 2.7341e-01, time/batch = 0.6278s	
5671/11850 (epoch 23.928), train_loss = 1.22199029, grad/param norm = 3.2943e-01, time/batch = 0.6315s	
5672/11850 (epoch 23.932), train_loss = 1.27123334, grad/param norm = 2.6316e-01, time/batch = 0.6257s	
5673/11850 (epoch 23.937), train_loss = 1.20202938, grad/param norm = 2.4164e-01, time/batch = 0.6252s	
5674/11850 (epoch 23.941), train_loss = 1.21891612, grad/param norm = 2.4785e-01, time/batch = 0.6365s	
5675/11850 (epoch 23.945), train_loss = 1.24425245, grad/param norm = 3.3183e-01, time/batch = 0.6254s	
5676/11850 (epoch 23.949), train_loss = 1.11956975, grad/param norm = 2.7871e-01, time/batch = 0.6270s	
5677/11850 (epoch 23.954), train_loss = 1.20977794, grad/param norm = 2.9467e-01, time/batch = 0.6267s	
5678/11850 (epoch 23.958), train_loss = 1.21284350, grad/param norm = 2.8564e-01, time/batch = 0.6255s	
5679/11850 (epoch 23.962), train_loss = 1.09299657, grad/param norm = 2.8004e-01, time/batch = 0.6250s	
5680/11850 (epoch 23.966), train_loss = 1.04170353, grad/param norm = 2.6691e-01, time/batch = 0.6249s	
5681/11850 (epoch 23.970), train_loss = 1.17839073, grad/param norm = 2.5964e-01, time/batch = 0.6287s	
5682/11850 (epoch 23.975), train_loss = 1.14002251, grad/param norm = 2.5730e-01, time/batch = 0.6290s	
5683/11850 (epoch 23.979), train_loss = 1.14222362, grad/param norm = 2.6837e-01, time/batch = 0.6321s	
5684/11850 (epoch 23.983), train_loss = 1.27162262, grad/param norm = 3.0607e-01, time/batch = 0.6526s	
5685/11850 (epoch 23.987), train_loss = 1.14891245, grad/param norm = 2.8763e-01, time/batch = 0.6589s	
5686/11850 (epoch 23.992), train_loss = 1.29249319, grad/param norm = 2.5112e-01, time/batch = 0.6617s	
5687/11850 (epoch 23.996), train_loss = 1.32695047, grad/param norm = 2.6663e-01, time/batch = 0.6446s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
5688/11850 (epoch 24.000), train_loss = 1.15506711, grad/param norm = 2.9927e-01, time/batch = 0.6386s	
5689/11850 (epoch 24.004), train_loss = 1.22371867, grad/param norm = 2.6987e-01, time/batch = 0.6382s	
5690/11850 (epoch 24.008), train_loss = 1.28981533, grad/param norm = 2.6944e-01, time/batch = 0.6378s	
5691/11850 (epoch 24.013), train_loss = 1.25866467, grad/param norm = 2.6786e-01, time/batch = 0.6401s	
5692/11850 (epoch 24.017), train_loss = 1.34552909, grad/param norm = 2.8402e-01, time/batch = 0.6472s	
5693/11850 (epoch 24.021), train_loss = 1.20992904, grad/param norm = 2.3614e-01, time/batch = 0.6507s	
5694/11850 (epoch 24.025), train_loss = 1.08112244, grad/param norm = 2.3601e-01, time/batch = 0.6308s	
5695/11850 (epoch 24.030), train_loss = 1.11026648, grad/param norm = 2.4662e-01, time/batch = 0.6335s	
5696/11850 (epoch 24.034), train_loss = 1.12269803, grad/param norm = 2.4838e-01, time/batch = 0.6281s	
5697/11850 (epoch 24.038), train_loss = 1.17512458, grad/param norm = 2.3798e-01, time/batch = 0.6300s	
5698/11850 (epoch 24.042), train_loss = 1.17116198, grad/param norm = 2.5475e-01, time/batch = 0.6286s	
5699/11850 (epoch 24.046), train_loss = 1.19209599, grad/param norm = 2.7934e-01, time/batch = 0.6280s	
5700/11850 (epoch 24.051), train_loss = 1.16428222, grad/param norm = 2.5168e-01, time/batch = 0.6223s	
5701/11850 (epoch 24.055), train_loss = 1.13988650, grad/param norm = 2.4891e-01, time/batch = 0.6288s	
5702/11850 (epoch 24.059), train_loss = 1.23534677, grad/param norm = 2.4564e-01, time/batch = 0.6221s	
5703/11850 (epoch 24.063), train_loss = 1.19897156, grad/param norm = 2.4478e-01, time/batch = 0.6257s	
5704/11850 (epoch 24.068), train_loss = 1.16030645, grad/param norm = 2.2919e-01, time/batch = 0.6239s	
5705/11850 (epoch 24.072), train_loss = 1.19300330, grad/param norm = 2.3985e-01, time/batch = 0.6249s	
5706/11850 (epoch 24.076), train_loss = 1.30783265, grad/param norm = 2.4614e-01, time/batch = 0.6278s	
5707/11850 (epoch 24.080), train_loss = 1.08437084, grad/param norm = 2.2781e-01, time/batch = 0.6235s	
5708/11850 (epoch 24.084), train_loss = 1.02872665, grad/param norm = 2.1339e-01, time/batch = 0.6276s	
5709/11850 (epoch 24.089), train_loss = 1.05393215, grad/param norm = 2.2703e-01, time/batch = 0.6423s	
5710/11850 (epoch 24.093), train_loss = 1.05048227, grad/param norm = 3.3958e-01, time/batch = 0.6586s	
5711/11850 (epoch 24.097), train_loss = 1.18842122, grad/param norm = 3.0388e-01, time/batch = 0.6356s	
5712/11850 (epoch 24.101), train_loss = 1.12732720, grad/param norm = 2.7733e-01, time/batch = 0.6257s	
5713/11850 (epoch 24.105), train_loss = 1.06382493, grad/param norm = 2.1978e-01, time/batch = 0.6243s	
5714/11850 (epoch 24.110), train_loss = 1.20855264, grad/param norm = 2.4001e-01, time/batch = 0.6276s	
5715/11850 (epoch 24.114), train_loss = 1.16682766, grad/param norm = 2.6730e-01, time/batch = 0.6262s	
5716/11850 (epoch 24.118), train_loss = 1.19105387, grad/param norm = 2.2706e-01, time/batch = 0.6236s	
5717/11850 (epoch 24.122), train_loss = 1.25040624, grad/param norm = 2.5765e-01, time/batch = 0.6258s	
5718/11850 (epoch 24.127), train_loss = 1.18543971, grad/param norm = 2.5357e-01, time/batch = 0.6278s	
5719/11850 (epoch 24.131), train_loss = 1.17505336, grad/param norm = 3.0608e-01, time/batch = 0.6266s	
5720/11850 (epoch 24.135), train_loss = 1.14143106, grad/param norm = 2.7485e-01, time/batch = 0.6382s	
5721/11850 (epoch 24.139), train_loss = 1.12590788, grad/param norm = 2.5861e-01, time/batch = 0.6600s	
5722/11850 (epoch 24.143), train_loss = 1.14149598, grad/param norm = 2.5862e-01, time/batch = 0.6313s	
5723/11850 (epoch 24.148), train_loss = 1.16476737, grad/param norm = 2.6944e-01, time/batch = 0.6311s	
5724/11850 (epoch 24.152), train_loss = 1.26481654, grad/param norm = 3.0374e-01, time/batch = 0.6490s	
5725/11850 (epoch 24.156), train_loss = 1.18399853, grad/param norm = 2.9384e-01, time/batch = 0.6316s	
5726/11850 (epoch 24.160), train_loss = 1.40086334, grad/param norm = 3.1480e-01, time/batch = 0.6331s	
5727/11850 (epoch 24.165), train_loss = 1.33453862, grad/param norm = 3.1955e-01, time/batch = 0.6281s	
5728/11850 (epoch 24.169), train_loss = 1.15258155, grad/param norm = 3.1222e-01, time/batch = 0.6281s	
5729/11850 (epoch 24.173), train_loss = 1.19963122, grad/param norm = 2.4798e-01, time/batch = 0.6274s	
5730/11850 (epoch 24.177), train_loss = 1.10949410, grad/param norm = 3.1877e-01, time/batch = 0.6316s	
5731/11850 (epoch 24.181), train_loss = 1.23137827, grad/param norm = 2.5272e-01, time/batch = 0.6381s	
5732/11850 (epoch 24.186), train_loss = 1.29020882, grad/param norm = 3.3175e-01, time/batch = 0.6287s	
5733/11850 (epoch 24.190), train_loss = 1.18470657, grad/param norm = 2.3589e-01, time/batch = 0.6324s	
5734/11850 (epoch 24.194), train_loss = 1.27587358, grad/param norm = 3.0323e-01, time/batch = 0.6290s	
5735/11850 (epoch 24.198), train_loss = 1.03775325, grad/param norm = 2.7171e-01, time/batch = 0.6280s	
5736/11850 (epoch 24.203), train_loss = 1.04118749, grad/param norm = 2.3830e-01, time/batch = 0.6273s	
5737/11850 (epoch 24.207), train_loss = 1.24190395, grad/param norm = 2.8117e-01, time/batch = 0.6304s	
5738/11850 (epoch 24.211), train_loss = 1.18757320, grad/param norm = 2.5856e-01, time/batch = 0.6281s	
5739/11850 (epoch 24.215), train_loss = 1.17437151, grad/param norm = 2.8248e-01, time/batch = 0.6305s	
5740/11850 (epoch 24.219), train_loss = 1.19414084, grad/param norm = 2.5667e-01, time/batch = 0.6282s	
5741/11850 (epoch 24.224), train_loss = 1.31958620, grad/param norm = 2.5816e-01, time/batch = 0.6242s	
5742/11850 (epoch 24.228), train_loss = 1.25058529, grad/param norm = 2.5970e-01, time/batch = 0.6257s	
5743/11850 (epoch 24.232), train_loss = 1.21087395, grad/param norm = 2.5380e-01, time/batch = 0.6243s	
5744/11850 (epoch 24.236), train_loss = 1.09896776, grad/param norm = 2.8469e-01, time/batch = 0.6339s	
5745/11850 (epoch 24.241), train_loss = 1.26945339, grad/param norm = 3.0577e-01, time/batch = 0.6252s	
5746/11850 (epoch 24.245), train_loss = 1.24072238, grad/param norm = 2.4346e-01, time/batch = 0.6285s	
5747/11850 (epoch 24.249), train_loss = 1.11337015, grad/param norm = 2.5150e-01, time/batch = 0.6236s	
5748/11850 (epoch 24.253), train_loss = 1.17674827, grad/param norm = 2.8079e-01, time/batch = 0.6281s	
5749/11850 (epoch 24.257), train_loss = 1.30427231, grad/param norm = 2.6967e-01, time/batch = 0.6245s	
5750/11850 (epoch 24.262), train_loss = 1.33884481, grad/param norm = 2.8944e-01, time/batch = 0.6262s	
5751/11850 (epoch 24.266), train_loss = 1.27291212, grad/param norm = 2.6813e-01, time/batch = 0.6262s	
5752/11850 (epoch 24.270), train_loss = 1.14254926, grad/param norm = 2.3440e-01, time/batch = 0.6323s	
5753/11850 (epoch 24.274), train_loss = 1.17072836, grad/param norm = 2.9485e-01, time/batch = 0.6286s	
5754/11850 (epoch 24.278), train_loss = 1.01014557, grad/param norm = 2.4322e-01, time/batch = 0.6283s	
5755/11850 (epoch 24.283), train_loss = 1.12570054, grad/param norm = 2.5693e-01, time/batch = 0.6243s	
5756/11850 (epoch 24.287), train_loss = 1.28016895, grad/param norm = 2.5503e-01, time/batch = 0.6272s	
5757/11850 (epoch 24.291), train_loss = 1.16474251, grad/param norm = 2.4785e-01, time/batch = 0.6237s	
5758/11850 (epoch 24.295), train_loss = 1.21875870, grad/param norm = 2.5776e-01, time/batch = 0.6424s	
5759/11850 (epoch 24.300), train_loss = 1.14621838, grad/param norm = 3.1145e-01, time/batch = 0.6603s	
5760/11850 (epoch 24.304), train_loss = 1.14249819, grad/param norm = 2.3845e-01, time/batch = 0.6252s	
5761/11850 (epoch 24.308), train_loss = 1.12218057, grad/param norm = 2.3276e-01, time/batch = 0.6297s	
5762/11850 (epoch 24.312), train_loss = 1.02174804, grad/param norm = 2.2100e-01, time/batch = 0.6422s	
5763/11850 (epoch 24.316), train_loss = 1.20393105, grad/param norm = 2.4310e-01, time/batch = 0.6325s	
5764/11850 (epoch 24.321), train_loss = 1.11757179, grad/param norm = 2.3710e-01, time/batch = 0.6335s	
5765/11850 (epoch 24.325), train_loss = 1.15013204, grad/param norm = 2.4281e-01, time/batch = 0.6331s	
5766/11850 (epoch 24.329), train_loss = 1.16153962, grad/param norm = 2.5771e-01, time/batch = 0.6261s	
5767/11850 (epoch 24.333), train_loss = 1.15479896, grad/param norm = 2.6256e-01, time/batch = 0.6264s	
5768/11850 (epoch 24.338), train_loss = 1.07245944, grad/param norm = 2.3305e-01, time/batch = 0.6248s	
5769/11850 (epoch 24.342), train_loss = 1.19196668, grad/param norm = 2.8745e-01, time/batch = 0.6340s	
5770/11850 (epoch 24.346), train_loss = 1.14179865, grad/param norm = 2.4004e-01, time/batch = 0.6249s	
5771/11850 (epoch 24.350), train_loss = 1.02935019, grad/param norm = 2.4354e-01, time/batch = 0.6254s	
5772/11850 (epoch 24.354), train_loss = 1.24117923, grad/param norm = 2.9757e-01, time/batch = 0.6287s	
5773/11850 (epoch 24.359), train_loss = 1.27337775, grad/param norm = 2.7908e-01, time/batch = 0.6298s	
5774/11850 (epoch 24.363), train_loss = 1.20608671, grad/param norm = 2.4953e-01, time/batch = 0.6266s	
5775/11850 (epoch 24.367), train_loss = 1.20570839, grad/param norm = 2.5161e-01, time/batch = 0.6270s	
5776/11850 (epoch 24.371), train_loss = 1.20549485, grad/param norm = 2.2961e-01, time/batch = 0.6258s	
5777/11850 (epoch 24.376), train_loss = 1.14298050, grad/param norm = 2.4165e-01, time/batch = 0.6230s	
5778/11850 (epoch 24.380), train_loss = 1.09550898, grad/param norm = 2.2227e-01, time/batch = 0.6376s	
5779/11850 (epoch 24.384), train_loss = 1.08403307, grad/param norm = 2.7702e-01, time/batch = 0.6538s	
5780/11850 (epoch 24.388), train_loss = 1.24502221, grad/param norm = 2.7277e-01, time/batch = 0.6587s	
5781/11850 (epoch 24.392), train_loss = 1.22721987, grad/param norm = 2.5455e-01, time/batch = 0.6392s	
5782/11850 (epoch 24.397), train_loss = 1.24486231, grad/param norm = 3.0599e-01, time/batch = 0.6307s	
5783/11850 (epoch 24.401), train_loss = 1.03917092, grad/param norm = 2.1905e-01, time/batch = 0.6276s	
5784/11850 (epoch 24.405), train_loss = 1.09701730, grad/param norm = 2.6575e-01, time/batch = 0.6277s	
5785/11850 (epoch 24.409), train_loss = 1.24781806, grad/param norm = 2.6340e-01, time/batch = 0.6313s	
5786/11850 (epoch 24.414), train_loss = 1.02242675, grad/param norm = 2.3047e-01, time/batch = 0.6283s	
5787/11850 (epoch 24.418), train_loss = 1.06224678, grad/param norm = 2.8725e-01, time/batch = 0.6295s	
5788/11850 (epoch 24.422), train_loss = 0.97385417, grad/param norm = 2.5044e-01, time/batch = 0.6292s	
5789/11850 (epoch 24.426), train_loss = 1.01527194, grad/param norm = 2.5997e-01, time/batch = 0.6352s	
5790/11850 (epoch 24.430), train_loss = 1.07186469, grad/param norm = 2.7181e-01, time/batch = 0.6459s	
5791/11850 (epoch 24.435), train_loss = 1.08605251, grad/param norm = 2.3045e-01, time/batch = 0.6474s	
5792/11850 (epoch 24.439), train_loss = 1.21484382, grad/param norm = 2.7141e-01, time/batch = 0.6583s	
5793/11850 (epoch 24.443), train_loss = 1.16120490, grad/param norm = 2.4779e-01, time/batch = 0.6242s	
5794/11850 (epoch 24.447), train_loss = 1.02267251, grad/param norm = 2.3631e-01, time/batch = 0.6273s	
5795/11850 (epoch 24.451), train_loss = 1.06568401, grad/param norm = 2.6680e-01, time/batch = 0.6269s	
5796/11850 (epoch 24.456), train_loss = 1.14375812, grad/param norm = 2.9401e-01, time/batch = 0.6276s	
5797/11850 (epoch 24.460), train_loss = 1.18052582, grad/param norm = 2.5849e-01, time/batch = 0.6273s	
5798/11850 (epoch 24.464), train_loss = 1.08805051, grad/param norm = 2.7198e-01, time/batch = 0.6246s	
5799/11850 (epoch 24.468), train_loss = 1.17097917, grad/param norm = 2.4703e-01, time/batch = 0.6260s	
5800/11850 (epoch 24.473), train_loss = 1.19783489, grad/param norm = 2.4618e-01, time/batch = 0.6344s	
5801/11850 (epoch 24.477), train_loss = 1.04492312, grad/param norm = 2.5000e-01, time/batch = 0.6279s	
5802/11850 (epoch 24.481), train_loss = 1.06818020, grad/param norm = 2.7679e-01, time/batch = 0.6442s	
5803/11850 (epoch 24.485), train_loss = 1.03207269, grad/param norm = 2.2104e-01, time/batch = 0.6593s	
5804/11850 (epoch 24.489), train_loss = 1.16877715, grad/param norm = 2.3672e-01, time/batch = 0.6241s	
5805/11850 (epoch 24.494), train_loss = 1.07081159, grad/param norm = 2.8609e-01, time/batch = 0.6254s	
5806/11850 (epoch 24.498), train_loss = 1.04192300, grad/param norm = 3.0734e-01, time/batch = 0.6248s	
5807/11850 (epoch 24.502), train_loss = 1.02595526, grad/param norm = 2.8860e-01, time/batch = 0.6275s	
5808/11850 (epoch 24.506), train_loss = 1.28902318, grad/param norm = 2.6033e-01, time/batch = 0.6285s	
5809/11850 (epoch 24.511), train_loss = 1.14429936, grad/param norm = 2.3981e-01, time/batch = 0.6270s	
5810/11850 (epoch 24.515), train_loss = 1.28452304, grad/param norm = 3.1407e-01, time/batch = 0.6277s	
5811/11850 (epoch 24.519), train_loss = 1.07765297, grad/param norm = 2.3750e-01, time/batch = 0.6299s	
5812/11850 (epoch 24.523), train_loss = 1.12398837, grad/param norm = 2.3663e-01, time/batch = 0.6278s	
5813/11850 (epoch 24.527), train_loss = 1.05953132, grad/param norm = 2.5637e-01, time/batch = 0.6389s	
5814/11850 (epoch 24.532), train_loss = 1.19265812, grad/param norm = 2.4450e-01, time/batch = 0.6280s	
5815/11850 (epoch 24.536), train_loss = 1.08914552, grad/param norm = 2.5030e-01, time/batch = 0.6272s	
5816/11850 (epoch 24.540), train_loss = 1.06330439, grad/param norm = 2.2523e-01, time/batch = 0.6274s	
5817/11850 (epoch 24.544), train_loss = 1.06545211, grad/param norm = 2.4542e-01, time/batch = 0.6321s	
5818/11850 (epoch 24.549), train_loss = 0.98573229, grad/param norm = 2.1882e-01, time/batch = 0.6287s	
5819/11850 (epoch 24.553), train_loss = 1.15282984, grad/param norm = 2.5832e-01, time/batch = 0.6298s	
5820/11850 (epoch 24.557), train_loss = 1.19945611, grad/param norm = 2.8191e-01, time/batch = 0.6253s	
5821/11850 (epoch 24.561), train_loss = 1.16884911, grad/param norm = 2.7595e-01, time/batch = 0.6281s	
5822/11850 (epoch 24.565), train_loss = 1.27338085, grad/param norm = 2.7423e-01, time/batch = 0.6266s	
5823/11850 (epoch 24.570), train_loss = 1.12810714, grad/param norm = 2.3019e-01, time/batch = 0.6303s	
5824/11850 (epoch 24.574), train_loss = 1.21030118, grad/param norm = 2.8359e-01, time/batch = 0.6268s	
5825/11850 (epoch 24.578), train_loss = 1.25581809, grad/param norm = 3.0456e-01, time/batch = 0.6294s	
5826/11850 (epoch 24.582), train_loss = 1.11739393, grad/param norm = 2.9620e-01, time/batch = 0.6311s	
5827/11850 (epoch 24.586), train_loss = 1.11328135, grad/param norm = 2.5187e-01, time/batch = 0.6285s	
5828/11850 (epoch 24.591), train_loss = 1.19204179, grad/param norm = 2.4758e-01, time/batch = 0.6283s	
5829/11850 (epoch 24.595), train_loss = 0.99614200, grad/param norm = 2.4003e-01, time/batch = 0.6438s	
5830/11850 (epoch 24.599), train_loss = 1.13615960, grad/param norm = 2.6584e-01, time/batch = 0.6357s	
5831/11850 (epoch 24.603), train_loss = 1.08625488, grad/param norm = 2.4066e-01, time/batch = 0.6336s	
5832/11850 (epoch 24.608), train_loss = 1.27131369, grad/param norm = 2.5196e-01, time/batch = 0.6397s	
5833/11850 (epoch 24.612), train_loss = 1.32812901, grad/param norm = 2.7670e-01, time/batch = 0.6399s	
5834/11850 (epoch 24.616), train_loss = 1.25586910, grad/param norm = 2.4658e-01, time/batch = 0.6276s	
5835/11850 (epoch 24.620), train_loss = 1.12282519, grad/param norm = 2.2992e-01, time/batch = 0.6262s	
5836/11850 (epoch 24.624), train_loss = 1.16308716, grad/param norm = 2.9429e-01, time/batch = 0.6291s	
5837/11850 (epoch 24.629), train_loss = 1.06646738, grad/param norm = 2.5484e-01, time/batch = 0.6261s	
5838/11850 (epoch 24.633), train_loss = 1.03136209, grad/param norm = 2.6558e-01, time/batch = 0.6261s	
5839/11850 (epoch 24.637), train_loss = 1.00587126, grad/param norm = 2.4675e-01, time/batch = 0.6304s	
5840/11850 (epoch 24.641), train_loss = 1.01530563, grad/param norm = 2.2106e-01, time/batch = 0.6527s	
5841/11850 (epoch 24.646), train_loss = 1.06868558, grad/param norm = 2.3726e-01, time/batch = 0.6596s	
5842/11850 (epoch 24.650), train_loss = 1.13128143, grad/param norm = 2.6789e-01, time/batch = 0.6255s	
5843/11850 (epoch 24.654), train_loss = 1.06735482, grad/param norm = 2.6569e-01, time/batch = 0.6261s	
5844/11850 (epoch 24.658), train_loss = 1.16249994, grad/param norm = 2.3505e-01, time/batch = 0.6295s	
5845/11850 (epoch 24.662), train_loss = 1.00680954, grad/param norm = 2.6763e-01, time/batch = 0.6265s	
5846/11850 (epoch 24.667), train_loss = 1.21592011, grad/param norm = 2.5073e-01, time/batch = 0.6231s	
5847/11850 (epoch 24.671), train_loss = 1.11464219, grad/param norm = 2.4983e-01, time/batch = 0.6257s	
5848/11850 (epoch 24.675), train_loss = 1.09612474, grad/param norm = 2.3936e-01, time/batch = 0.6258s	
5849/11850 (epoch 24.679), train_loss = 1.15164585, grad/param norm = 2.6095e-01, time/batch = 0.6219s	
5850/11850 (epoch 24.684), train_loss = 1.12564875, grad/param norm = 2.5931e-01, time/batch = 0.6399s	
5851/11850 (epoch 24.688), train_loss = 1.06534068, grad/param norm = 2.3689e-01, time/batch = 0.6291s	
5852/11850 (epoch 24.692), train_loss = 1.09548227, grad/param norm = 2.7689e-01, time/batch = 0.6266s	
5853/11850 (epoch 24.696), train_loss = 1.04503779, grad/param norm = 2.7628e-01, time/batch = 0.6262s	
5854/11850 (epoch 24.700), train_loss = 1.13287042, grad/param norm = 2.6150e-01, time/batch = 0.6270s	
5855/11850 (epoch 24.705), train_loss = 1.09703801, grad/param norm = 2.8887e-01, time/batch = 0.6278s	
5856/11850 (epoch 24.709), train_loss = 0.98546117, grad/param norm = 2.3574e-01, time/batch = 0.6265s	
5857/11850 (epoch 24.713), train_loss = 1.04083855, grad/param norm = 2.8376e-01, time/batch = 0.6282s	
5858/11850 (epoch 24.717), train_loss = 1.06571423, grad/param norm = 2.4394e-01, time/batch = 0.6281s	
5859/11850 (epoch 24.722), train_loss = 1.12905734, grad/param norm = 2.6173e-01, time/batch = 0.6307s	
5860/11850 (epoch 24.726), train_loss = 1.02086692, grad/param norm = 2.6636e-01, time/batch = 0.6333s	
5861/11850 (epoch 24.730), train_loss = 1.03111956, grad/param norm = 2.4736e-01, time/batch = 0.6264s	
5862/11850 (epoch 24.734), train_loss = 1.06539961, grad/param norm = 2.3449e-01, time/batch = 0.6465s	
5863/11850 (epoch 24.738), train_loss = 1.19868504, grad/param norm = 2.7179e-01, time/batch = 0.6587s	
5864/11850 (epoch 24.743), train_loss = 1.11062040, grad/param norm = 2.3419e-01, time/batch = 0.6382s	
5865/11850 (epoch 24.747), train_loss = 0.98406414, grad/param norm = 2.1157e-01, time/batch = 0.6235s	
5866/11850 (epoch 24.751), train_loss = 1.03418593, grad/param norm = 2.3329e-01, time/batch = 0.6260s	
5867/11850 (epoch 24.755), train_loss = 1.10760985, grad/param norm = 2.3057e-01, time/batch = 0.6230s	
5868/11850 (epoch 24.759), train_loss = 1.06013249, grad/param norm = 2.6128e-01, time/batch = 0.6250s	
5869/11850 (epoch 24.764), train_loss = 1.06944710, grad/param norm = 2.4051e-01, time/batch = 0.6257s	
5870/11850 (epoch 24.768), train_loss = 0.99479871, grad/param norm = 2.4405e-01, time/batch = 0.6278s	
5871/11850 (epoch 24.772), train_loss = 1.06189574, grad/param norm = 2.5819e-01, time/batch = 0.6325s	
5872/11850 (epoch 24.776), train_loss = 1.12553593, grad/param norm = 2.4914e-01, time/batch = 0.6307s	
5873/11850 (epoch 24.781), train_loss = 1.09095216, grad/param norm = 2.6422e-01, time/batch = 0.6541s	
5874/11850 (epoch 24.785), train_loss = 1.06209516, grad/param norm = 2.7098e-01, time/batch = 0.6605s	
5875/11850 (epoch 24.789), train_loss = 1.11374386, grad/param norm = 2.3867e-01, time/batch = 0.6454s	
5876/11850 (epoch 24.793), train_loss = 1.19884296, grad/param norm = 2.7871e-01, time/batch = 0.6378s	
5877/11850 (epoch 24.797), train_loss = 1.12043208, grad/param norm = 2.2903e-01, time/batch = 0.6296s	
5878/11850 (epoch 24.802), train_loss = 1.01633515, grad/param norm = 2.5904e-01, time/batch = 0.6267s	
5879/11850 (epoch 24.806), train_loss = 1.09572745, grad/param norm = 2.4679e-01, time/batch = 0.6325s	
5880/11850 (epoch 24.810), train_loss = 1.22459605, grad/param norm = 2.8804e-01, time/batch = 0.6331s	
5881/11850 (epoch 24.814), train_loss = 1.09277385, grad/param norm = 2.7155e-01, time/batch = 0.6371s	
5882/11850 (epoch 24.819), train_loss = 1.23818988, grad/param norm = 2.7693e-01, time/batch = 0.6327s	
5883/11850 (epoch 24.823), train_loss = 1.26638956, grad/param norm = 2.7722e-01, time/batch = 0.6300s	
5884/11850 (epoch 24.827), train_loss = 1.11585060, grad/param norm = 2.6575e-01, time/batch = 0.6511s	
5885/11850 (epoch 24.831), train_loss = 1.12185494, grad/param norm = 2.5026e-01, time/batch = 0.6580s	
5886/11850 (epoch 24.835), train_loss = 1.10983362, grad/param norm = 2.3050e-01, time/batch = 0.6616s	
5887/11850 (epoch 24.840), train_loss = 1.08193395, grad/param norm = 2.4077e-01, time/batch = 0.6449s	
5888/11850 (epoch 24.844), train_loss = 1.10103673, grad/param norm = 2.3607e-01, time/batch = 0.6460s	
5889/11850 (epoch 24.848), train_loss = 1.12987481, grad/param norm = 2.9434e-01, time/batch = 0.6291s	
5890/11850 (epoch 24.852), train_loss = 1.11097163, grad/param norm = 2.4682e-01, time/batch = 0.6297s	
5891/11850 (epoch 24.857), train_loss = 1.12730910, grad/param norm = 3.0690e-01, time/batch = 0.6315s	
5892/11850 (epoch 24.861), train_loss = 1.10129524, grad/param norm = 2.6287e-01, time/batch = 0.6310s	
5893/11850 (epoch 24.865), train_loss = 1.19350402, grad/param norm = 3.2571e-01, time/batch = 0.6294s	
5894/11850 (epoch 24.869), train_loss = 1.17472051, grad/param norm = 3.0041e-01, time/batch = 0.6277s	
5895/11850 (epoch 24.873), train_loss = 1.15956226, grad/param norm = 2.5592e-01, time/batch = 0.6429s	
5896/11850 (epoch 24.878), train_loss = 1.18549144, grad/param norm = 2.8196e-01, time/batch = 0.6297s	
5897/11850 (epoch 24.882), train_loss = 1.14079337, grad/param norm = 2.5389e-01, time/batch = 0.6247s	
5898/11850 (epoch 24.886), train_loss = 1.14651996, grad/param norm = 2.9186e-01, time/batch = 0.6260s	
5899/11850 (epoch 24.890), train_loss = 1.16349076, grad/param norm = 3.0295e-01, time/batch = 0.6256s	
5900/11850 (epoch 24.895), train_loss = 1.17427607, grad/param norm = 3.0377e-01, time/batch = 0.6257s	
5901/11850 (epoch 24.899), train_loss = 1.03132179, grad/param norm = 2.6108e-01, time/batch = 0.6298s	
5902/11850 (epoch 24.903), train_loss = 1.10993638, grad/param norm = 2.6775e-01, time/batch = 0.6271s	
5903/11850 (epoch 24.907), train_loss = 1.11152657, grad/param norm = 2.8502e-01, time/batch = 0.6276s	
5904/11850 (epoch 24.911), train_loss = 1.21474884, grad/param norm = 2.7255e-01, time/batch = 0.6268s	
5905/11850 (epoch 24.916), train_loss = 1.20396902, grad/param norm = 2.8448e-01, time/batch = 0.6265s	
5906/11850 (epoch 24.920), train_loss = 1.12581710, grad/param norm = 2.5382e-01, time/batch = 0.6471s	
5907/11850 (epoch 24.924), train_loss = 1.11693704, grad/param norm = 3.0927e-01, time/batch = 0.6554s	
5908/11850 (epoch 24.928), train_loss = 1.19517254, grad/param norm = 2.7770e-01, time/batch = 0.6254s	
5909/11850 (epoch 24.932), train_loss = 1.25339370, grad/param norm = 2.6461e-01, time/batch = 0.6261s	
5910/11850 (epoch 24.937), train_loss = 1.19199431, grad/param norm = 2.5734e-01, time/batch = 0.6248s	
5911/11850 (epoch 24.941), train_loss = 1.18455543, grad/param norm = 2.5687e-01, time/batch = 0.6280s	
5912/11850 (epoch 24.945), train_loss = 1.21495834, grad/param norm = 2.5329e-01, time/batch = 0.6243s	
5913/11850 (epoch 24.949), train_loss = 1.10032456, grad/param norm = 3.0888e-01, time/batch = 0.6264s	
5914/11850 (epoch 24.954), train_loss = 1.18210637, grad/param norm = 3.0050e-01, time/batch = 0.6415s	
5915/11850 (epoch 24.958), train_loss = 1.18556524, grad/param norm = 3.0217e-01, time/batch = 0.6438s	
5916/11850 (epoch 24.962), train_loss = 1.08012048, grad/param norm = 2.6904e-01, time/batch = 0.6244s	
5917/11850 (epoch 24.966), train_loss = 1.03023095, grad/param norm = 2.6556e-01, time/batch = 0.6514s	
5918/11850 (epoch 24.970), train_loss = 1.15900173, grad/param norm = 2.5972e-01, time/batch = 0.6563s	
5919/11850 (epoch 24.975), train_loss = 1.11876721, grad/param norm = 2.6068e-01, time/batch = 0.6290s	
5920/11850 (epoch 24.979), train_loss = 1.13033333, grad/param norm = 2.6650e-01, time/batch = 0.6324s	
5921/11850 (epoch 24.983), train_loss = 1.24161656, grad/param norm = 2.8494e-01, time/batch = 0.6439s	
5922/11850 (epoch 24.987), train_loss = 1.10580974, grad/param norm = 2.6212e-01, time/batch = 0.6313s	
5923/11850 (epoch 24.992), train_loss = 1.25527324, grad/param norm = 2.5684e-01, time/batch = 0.6277s	
5924/11850 (epoch 24.996), train_loss = 1.29341154, grad/param norm = 3.3337e-01, time/batch = 0.6266s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
5925/11850 (epoch 25.000), train_loss = 1.14009003, grad/param norm = 3.1905e-01, time/batch = 0.6280s	
5926/11850 (epoch 25.004), train_loss = 1.18440487, grad/param norm = 2.7008e-01, time/batch = 0.6280s	
5927/11850 (epoch 25.008), train_loss = 1.25686590, grad/param norm = 2.6760e-01, time/batch = 0.6239s	
5928/11850 (epoch 25.013), train_loss = 1.24881682, grad/param norm = 2.8700e-01, time/batch = 0.6543s	
5929/11850 (epoch 25.017), train_loss = 1.30396360, grad/param norm = 2.4871e-01, time/batch = 0.6551s	
5930/11850 (epoch 25.021), train_loss = 1.18864953, grad/param norm = 2.3559e-01, time/batch = 0.6247s	
5931/11850 (epoch 25.025), train_loss = 1.07320204, grad/param norm = 2.4622e-01, time/batch = 0.6280s	
5932/11850 (epoch 25.030), train_loss = 1.09799037, grad/param norm = 2.7275e-01, time/batch = 0.6257s	
5933/11850 (epoch 25.034), train_loss = 1.09933747, grad/param norm = 2.4493e-01, time/batch = 0.6283s	
5934/11850 (epoch 25.038), train_loss = 1.14862174, grad/param norm = 2.4253e-01, time/batch = 0.6241s	
5935/11850 (epoch 25.042), train_loss = 1.15243620, grad/param norm = 2.5646e-01, time/batch = 0.6253s	
5936/11850 (epoch 25.046), train_loss = 1.15703304, grad/param norm = 2.6002e-01, time/batch = 0.6252s	
5937/11850 (epoch 25.051), train_loss = 1.14935930, grad/param norm = 2.5465e-01, time/batch = 0.6268s	
5938/11850 (epoch 25.055), train_loss = 1.11997154, grad/param norm = 2.6183e-01, time/batch = 0.6263s	
5939/11850 (epoch 25.059), train_loss = 1.20783809, grad/param norm = 2.5094e-01, time/batch = 0.6489s	
5940/11850 (epoch 25.063), train_loss = 1.18434655, grad/param norm = 2.7405e-01, time/batch = 0.6569s	
5941/11850 (epoch 25.068), train_loss = 1.14329922, grad/param norm = 2.3717e-01, time/batch = 0.6369s	
5942/11850 (epoch 25.072), train_loss = 1.17239104, grad/param norm = 2.3757e-01, time/batch = 0.6330s	
5943/11850 (epoch 25.076), train_loss = 1.27283937, grad/param norm = 2.4301e-01, time/batch = 0.6452s	
5944/11850 (epoch 25.080), train_loss = 1.07235656, grad/param norm = 2.2634e-01, time/batch = 0.6516s	
5945/11850 (epoch 25.084), train_loss = 1.00147234, grad/param norm = 2.1552e-01, time/batch = 0.6367s	
5946/11850 (epoch 25.089), train_loss = 1.02850468, grad/param norm = 2.2516e-01, time/batch = 0.6297s	
5947/11850 (epoch 25.093), train_loss = 1.03743269, grad/param norm = 2.8301e-01, time/batch = 0.6359s	
5948/11850 (epoch 25.097), train_loss = 1.14595450, grad/param norm = 2.5277e-01, time/batch = 0.6366s	
5949/11850 (epoch 25.101), train_loss = 1.08358612, grad/param norm = 2.6329e-01, time/batch = 0.6386s	
5950/11850 (epoch 25.105), train_loss = 1.03305795, grad/param norm = 2.2308e-01, time/batch = 0.6507s	
5951/11850 (epoch 25.110), train_loss = 1.17567368, grad/param norm = 2.4563e-01, time/batch = 0.6535s	
5952/11850 (epoch 25.114), train_loss = 1.14739458, grad/param norm = 3.0097e-01, time/batch = 0.6361s	
5953/11850 (epoch 25.118), train_loss = 1.17640440, grad/param norm = 2.3597e-01, time/batch = 0.6505s	
5954/11850 (epoch 25.122), train_loss = 1.22703011, grad/param norm = 2.6063e-01, time/batch = 0.6559s	
5955/11850 (epoch 25.127), train_loss = 1.17242584, grad/param norm = 2.6660e-01, time/batch = 0.6593s	
5956/11850 (epoch 25.131), train_loss = 1.13988358, grad/param norm = 2.8495e-01, time/batch = 0.6473s	
5957/11850 (epoch 25.135), train_loss = 1.10686292, grad/param norm = 2.8351e-01, time/batch = 0.6499s	
5958/11850 (epoch 25.139), train_loss = 1.10703727, grad/param norm = 2.7136e-01, time/batch = 0.6544s	
5959/11850 (epoch 25.143), train_loss = 1.13325076, grad/param norm = 2.8016e-01, time/batch = 0.6405s	
5960/11850 (epoch 25.148), train_loss = 1.12954839, grad/param norm = 2.5972e-01, time/batch = 0.6418s	
5961/11850 (epoch 25.152), train_loss = 1.23266674, grad/param norm = 3.0056e-01, time/batch = 0.6753s	
5962/11850 (epoch 25.156), train_loss = 1.14478410, grad/param norm = 3.1691e-01, time/batch = 0.6554s	
5963/11850 (epoch 25.160), train_loss = 1.37090821, grad/param norm = 3.3170e-01, time/batch = 0.6427s	
5964/11850 (epoch 25.165), train_loss = 1.29749354, grad/param norm = 3.1606e-01, time/batch = 0.6437s	
5965/11850 (epoch 25.169), train_loss = 1.12003485, grad/param norm = 2.8095e-01, time/batch = 0.6505s	
5966/11850 (epoch 25.173), train_loss = 1.20099284, grad/param norm = 2.9654e-01, time/batch = 0.6595s	
5967/11850 (epoch 25.177), train_loss = 1.09244470, grad/param norm = 3.2031e-01, time/batch = 0.6728s	
5968/11850 (epoch 25.181), train_loss = 1.21350271, grad/param norm = 2.4605e-01, time/batch = 0.6723s	
5969/11850 (epoch 25.186), train_loss = 1.26584508, grad/param norm = 3.1676e-01, time/batch = 0.6736s	
5970/11850 (epoch 25.190), train_loss = 1.17446556, grad/param norm = 2.4137e-01, time/batch = 0.6571s	
5971/11850 (epoch 25.194), train_loss = 1.23972345, grad/param norm = 2.9895e-01, time/batch = 0.6553s	
5972/11850 (epoch 25.198), train_loss = 0.99915703, grad/param norm = 2.7168e-01, time/batch = 0.6700s	
5973/11850 (epoch 25.203), train_loss = 1.02457925, grad/param norm = 2.6443e-01, time/batch = 0.6448s	
5974/11850 (epoch 25.207), train_loss = 1.21331887, grad/param norm = 2.9567e-01, time/batch = 0.6457s	
5975/11850 (epoch 25.211), train_loss = 1.16372665, grad/param norm = 2.6194e-01, time/batch = 0.6476s	
5976/11850 (epoch 25.215), train_loss = 1.13899643, grad/param norm = 2.8405e-01, time/batch = 0.6420s	
5977/11850 (epoch 25.219), train_loss = 1.16373120, grad/param norm = 2.8408e-01, time/batch = 0.6436s	
5978/11850 (epoch 25.224), train_loss = 1.29112070, grad/param norm = 2.5886e-01, time/batch = 0.6422s	
5979/11850 (epoch 25.228), train_loss = 1.21555216, grad/param norm = 2.7100e-01, time/batch = 0.6480s	
5980/11850 (epoch 25.232), train_loss = 1.18061570, grad/param norm = 2.6692e-01, time/batch = 0.6567s	
5981/11850 (epoch 25.236), train_loss = 1.06278226, grad/param norm = 2.5842e-01, time/batch = 0.6453s	
5982/11850 (epoch 25.241), train_loss = 1.24580108, grad/param norm = 2.8678e-01, time/batch = 0.6715s	
5983/11850 (epoch 25.245), train_loss = 1.22359072, grad/param norm = 2.5024e-01, time/batch = 0.6655s	
5984/11850 (epoch 25.249), train_loss = 1.10340019, grad/param norm = 2.6952e-01, time/batch = 0.6445s	
5985/11850 (epoch 25.253), train_loss = 1.15893291, grad/param norm = 2.7568e-01, time/batch = 0.6483s	
5986/11850 (epoch 25.257), train_loss = 1.27048792, grad/param norm = 2.6535e-01, time/batch = 0.6437s	
5987/11850 (epoch 25.262), train_loss = 1.29997889, grad/param norm = 2.7227e-01, time/batch = 0.6438s	
5988/11850 (epoch 25.266), train_loss = 1.24665720, grad/param norm = 2.8136e-01, time/batch = 0.6475s	
5989/11850 (epoch 25.270), train_loss = 1.12650407, grad/param norm = 2.4592e-01, time/batch = 0.6522s	
5990/11850 (epoch 25.274), train_loss = 1.14638153, grad/param norm = 3.0555e-01, time/batch = 0.6471s	
5991/11850 (epoch 25.278), train_loss = 0.97659433, grad/param norm = 2.4112e-01, time/batch = 0.6442s	
5992/11850 (epoch 25.283), train_loss = 1.09893667, grad/param norm = 2.4064e-01, time/batch = 0.6463s	
5993/11850 (epoch 25.287), train_loss = 1.25571087, grad/param norm = 2.5232e-01, time/batch = 0.6746s	
5994/11850 (epoch 25.291), train_loss = 1.14111545, grad/param norm = 2.5441e-01, time/batch = 0.6593s	
5995/11850 (epoch 25.295), train_loss = 1.21135997, grad/param norm = 2.7016e-01, time/batch = 0.6459s	
5996/11850 (epoch 25.300), train_loss = 1.11600377, grad/param norm = 2.8924e-01, time/batch = 0.6452s	
5997/11850 (epoch 25.304), train_loss = 1.11352552, grad/param norm = 2.1985e-01, time/batch = 0.6431s	
5998/11850 (epoch 25.308), train_loss = 1.10422059, grad/param norm = 2.3541e-01, time/batch = 0.6431s	
5999/11850 (epoch 25.312), train_loss = 1.01072517, grad/param norm = 2.3745e-01, time/batch = 0.6437s	
evaluating loss over split index 2	
1/13...	
2/13...	
3/13...	
4/13...	
5/13...	
6/13...	
7/13...	
8/13...	
9/13...	
10/13...	
11/13...	
12/13...	
13/13...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_katelyn_salem_epoch25.32_2.0511.t7	
6000/11850 (epoch 25.316), train_loss = 1.17376529, grad/param norm = 2.4534e-01, time/batch = 0.6500s	
6001/11850 (epoch 25.321), train_loss = 1.27446675, grad/param norm = 2.7449e-01, time/batch = 0.6484s	
6002/11850 (epoch 25.325), train_loss = 1.13227877, grad/param norm = 2.5113e-01, time/batch = 0.6469s	
6003/11850 (epoch 25.329), train_loss = 1.13633363, grad/param norm = 2.5587e-01, time/batch = 0.6443s	
6004/11850 (epoch 25.333), train_loss = 1.13463627, grad/param norm = 2.7906e-01, time/batch = 0.6423s	
6005/11850 (epoch 25.338), train_loss = 1.05423324, grad/param norm = 2.2598e-01, time/batch = 0.6422s	
6006/11850 (epoch 25.342), train_loss = 1.16720487, grad/param norm = 2.6701e-01, time/batch = 0.6461s	
6007/11850 (epoch 25.346), train_loss = 1.12735122, grad/param norm = 2.4284e-01, time/batch = 0.6460s	
6008/11850 (epoch 25.350), train_loss = 1.00127336, grad/param norm = 2.3819e-01, time/batch = 0.6557s	
6009/11850 (epoch 25.354), train_loss = 1.22124478, grad/param norm = 2.5353e-01, time/batch = 0.6492s	
6010/11850 (epoch 25.359), train_loss = 1.24517481, grad/param norm = 2.7353e-01, time/batch = 0.6575s	
6011/11850 (epoch 25.363), train_loss = 1.18504324, grad/param norm = 2.5892e-01, time/batch = 0.6479s	
6012/11850 (epoch 25.367), train_loss = 1.19213961, grad/param norm = 2.4801e-01, time/batch = 0.6442s	
6013/11850 (epoch 25.371), train_loss = 1.17343073, grad/param norm = 2.2605e-01, time/batch = 0.6423s	
6014/11850 (epoch 25.376), train_loss = 1.12051012, grad/param norm = 2.3622e-01, time/batch = 0.6474s	
6015/11850 (epoch 25.380), train_loss = 1.07490895, grad/param norm = 2.2275e-01, time/batch = 0.6704s	
6016/11850 (epoch 25.384), train_loss = 1.05197658, grad/param norm = 2.4401e-01, time/batch = 0.6591s	
6017/11850 (epoch 25.388), train_loss = 1.22823132, grad/param norm = 3.2360e-01, time/batch = 0.6565s	
6018/11850 (epoch 25.392), train_loss = 1.20516613, grad/param norm = 2.6087e-01, time/batch = 0.6521s	
6019/11850 (epoch 25.397), train_loss = 1.21381215, grad/param norm = 2.8354e-01, time/batch = 0.6432s	
6020/11850 (epoch 25.401), train_loss = 1.02163658, grad/param norm = 2.3216e-01, time/batch = 0.6444s	
6021/11850 (epoch 25.405), train_loss = 1.06942977, grad/param norm = 2.5085e-01, time/batch = 0.6460s	
6022/11850 (epoch 25.409), train_loss = 1.21711748, grad/param norm = 2.4842e-01, time/batch = 0.6429s	
6023/11850 (epoch 25.414), train_loss = 0.99676778, grad/param norm = 2.2294e-01, time/batch = 0.6469s	
6024/11850 (epoch 25.418), train_loss = 1.04613199, grad/param norm = 2.6485e-01, time/batch = 0.6453s	
6025/11850 (epoch 25.422), train_loss = 0.96278234, grad/param norm = 2.9213e-01, time/batch = 0.6460s	
6026/11850 (epoch 25.426), train_loss = 0.98686957, grad/param norm = 2.6820e-01, time/batch = 0.6443s	
6027/11850 (epoch 25.430), train_loss = 1.05484520, grad/param norm = 2.7496e-01, time/batch = 0.6457s	
6028/11850 (epoch 25.435), train_loss = 1.06919360, grad/param norm = 2.6201e-01, time/batch = 0.6433s	
6029/11850 (epoch 25.439), train_loss = 1.18685886, grad/param norm = 2.5224e-01, time/batch = 0.6456s	
6030/11850 (epoch 25.443), train_loss = 1.13008845, grad/param norm = 2.4998e-01, time/batch = 0.6564s	
6031/11850 (epoch 25.447), train_loss = 1.01788095, grad/param norm = 2.9438e-01, time/batch = 0.6580s	
6032/11850 (epoch 25.451), train_loss = 1.04143981, grad/param norm = 2.3707e-01, time/batch = 0.6439s	
6033/11850 (epoch 25.456), train_loss = 1.12016769, grad/param norm = 2.7571e-01, time/batch = 0.6479s	
6034/11850 (epoch 25.460), train_loss = 1.16850896, grad/param norm = 2.6537e-01, time/batch = 0.6453s	
6035/11850 (epoch 25.464), train_loss = 1.05941879, grad/param norm = 2.3627e-01, time/batch = 0.6453s	
6036/11850 (epoch 25.468), train_loss = 1.14076275, grad/param norm = 2.3541e-01, time/batch = 0.6419s	
6037/11850 (epoch 25.473), train_loss = 1.18125834, grad/param norm = 2.6348e-01, time/batch = 0.6517s	
6038/11850 (epoch 25.477), train_loss = 1.02946820, grad/param norm = 2.4493e-01, time/batch = 0.6434s	
6039/11850 (epoch 25.481), train_loss = 1.04687639, grad/param norm = 2.7457e-01, time/batch = 0.6444s	
6040/11850 (epoch 25.485), train_loss = 1.00856402, grad/param norm = 2.2514e-01, time/batch = 0.6435s	
6041/11850 (epoch 25.489), train_loss = 1.15408368, grad/param norm = 2.4536e-01, time/batch = 0.6488s	
6042/11850 (epoch 25.494), train_loss = 1.03605092, grad/param norm = 3.2012e-01, time/batch = 0.6459s	
6043/11850 (epoch 25.498), train_loss = 1.03709997, grad/param norm = 3.5985e-01, time/batch = 0.6454s	
6044/11850 (epoch 25.502), train_loss = 1.02276030, grad/param norm = 2.8380e-01, time/batch = 0.6449s	
6045/11850 (epoch 25.506), train_loss = 1.26239180, grad/param norm = 2.6735e-01, time/batch = 0.6428s	
6046/11850 (epoch 25.511), train_loss = 1.12984506, grad/param norm = 2.5826e-01, time/batch = 0.6414s	
6047/11850 (epoch 25.515), train_loss = 1.24211965, grad/param norm = 3.0426e-01, time/batch = 0.6510s	
6048/11850 (epoch 25.519), train_loss = 1.06543499, grad/param norm = 2.4560e-01, time/batch = 0.6427s	
6049/11850 (epoch 25.523), train_loss = 1.11499060, grad/param norm = 2.4458e-01, time/batch = 0.6395s	
6050/11850 (epoch 25.527), train_loss = 1.03496973, grad/param norm = 2.4341e-01, time/batch = 0.6411s	
6051/11850 (epoch 25.532), train_loss = 1.17088073, grad/param norm = 2.5091e-01, time/batch = 0.6448s	
6052/11850 (epoch 25.536), train_loss = 1.06192825, grad/param norm = 2.4005e-01, time/batch = 0.6458s	
6053/11850 (epoch 25.540), train_loss = 1.03378635, grad/param norm = 2.2095e-01, time/batch = 0.6480s	
6054/11850 (epoch 25.544), train_loss = 1.04067172, grad/param norm = 2.6121e-01, time/batch = 0.6463s	
6055/11850 (epoch 25.549), train_loss = 0.97352260, grad/param norm = 2.2856e-01, time/batch = 0.6709s	
6056/11850 (epoch 25.553), train_loss = 1.12041688, grad/param norm = 2.3954e-01, time/batch = 0.6710s	
6057/11850 (epoch 25.557), train_loss = 1.16874742, grad/param norm = 3.0524e-01, time/batch = 0.6723s	
6058/11850 (epoch 25.561), train_loss = 1.14839849, grad/param norm = 2.7011e-01, time/batch = 0.6707s	
6059/11850 (epoch 25.565), train_loss = 1.24789584, grad/param norm = 2.6628e-01, time/batch = 0.6573s	
6060/11850 (epoch 25.570), train_loss = 1.12330518, grad/param norm = 2.5138e-01, time/batch = 0.6585s	
6061/11850 (epoch 25.574), train_loss = 1.17475413, grad/param norm = 2.8044e-01, time/batch = 0.6583s	
6062/11850 (epoch 25.578), train_loss = 1.21631149, grad/param norm = 2.4476e-01, time/batch = 0.6434s	
6063/11850 (epoch 25.582), train_loss = 1.08637139, grad/param norm = 2.9971e-01, time/batch = 0.6389s	
6064/11850 (epoch 25.586), train_loss = 1.08536211, grad/param norm = 2.5591e-01, time/batch = 0.6407s	
6065/11850 (epoch 25.591), train_loss = 1.16640439, grad/param norm = 2.6373e-01, time/batch = 0.6403s	
6066/11850 (epoch 25.595), train_loss = 0.99045835, grad/param norm = 2.5115e-01, time/batch = 0.6378s	
6067/11850 (epoch 25.599), train_loss = 1.11620764, grad/param norm = 2.7544e-01, time/batch = 0.6385s	
6068/11850 (epoch 25.603), train_loss = 1.06560912, grad/param norm = 2.4443e-01, time/batch = 0.6498s	
6069/11850 (epoch 25.608), train_loss = 1.24298953, grad/param norm = 2.5688e-01, time/batch = 0.6670s	
6070/11850 (epoch 25.612), train_loss = 1.31353126, grad/param norm = 2.8896e-01, time/batch = 0.6544s	
6071/11850 (epoch 25.616), train_loss = 1.23109638, grad/param norm = 2.4934e-01, time/batch = 0.6479s	
6072/11850 (epoch 25.620), train_loss = 1.10628864, grad/param norm = 2.4388e-01, time/batch = 0.6421s	
6073/11850 (epoch 25.624), train_loss = 1.12771862, grad/param norm = 3.1435e-01, time/batch = 0.6419s	
6074/11850 (epoch 25.629), train_loss = 1.05971456, grad/param norm = 2.8352e-01, time/batch = 0.6437s	
6075/11850 (epoch 25.633), train_loss = 0.99408768, grad/param norm = 2.4249e-01, time/batch = 0.6397s	
6076/11850 (epoch 25.637), train_loss = 0.97562165, grad/param norm = 2.4441e-01, time/batch = 0.6404s	
6077/11850 (epoch 25.641), train_loss = 1.00039141, grad/param norm = 2.2963e-01, time/batch = 0.6388s	
6078/11850 (epoch 25.646), train_loss = 1.04036566, grad/param norm = 2.3177e-01, time/batch = 0.6380s	
6079/11850 (epoch 25.650), train_loss = 1.12085119, grad/param norm = 2.8559e-01, time/batch = 0.6370s	
6080/11850 (epoch 25.654), train_loss = 1.04348169, grad/param norm = 2.9053e-01, time/batch = 0.6631s	
6081/11850 (epoch 25.658), train_loss = 1.14529633, grad/param norm = 2.9222e-01, time/batch = 0.6706s	
6082/11850 (epoch 25.662), train_loss = 0.97439532, grad/param norm = 2.6041e-01, time/batch = 0.6495s	
6083/11850 (epoch 25.667), train_loss = 1.19296501, grad/param norm = 2.5759e-01, time/batch = 0.6503s	
6084/11850 (epoch 25.671), train_loss = 1.09451170, grad/param norm = 2.5158e-01, time/batch = 0.6426s	
6085/11850 (epoch 25.675), train_loss = 1.06522415, grad/param norm = 2.3873e-01, time/batch = 0.6399s	
6086/11850 (epoch 25.679), train_loss = 1.12774932, grad/param norm = 2.7760e-01, time/batch = 0.6500s	
6087/11850 (epoch 25.684), train_loss = 1.09558936, grad/param norm = 2.5365e-01, time/batch = 0.6436s	
6088/11850 (epoch 25.688), train_loss = 1.05235712, grad/param norm = 2.3616e-01, time/batch = 0.6396s	
6089/11850 (epoch 25.692), train_loss = 1.06860453, grad/param norm = 2.7540e-01, time/batch = 0.6408s	
6090/11850 (epoch 25.696), train_loss = 1.02436235, grad/param norm = 3.6424e-01, time/batch = 0.6391s	
6091/11850 (epoch 25.700), train_loss = 1.11713305, grad/param norm = 2.6643e-01, time/batch = 0.6422s	
6092/11850 (epoch 25.705), train_loss = 1.07511264, grad/param norm = 2.7175e-01, time/batch = 0.6394s	
6093/11850 (epoch 25.709), train_loss = 0.96410815, grad/param norm = 2.3496e-01, time/batch = 0.6398s	
6094/11850 (epoch 25.713), train_loss = 1.00699601, grad/param norm = 2.6003e-01, time/batch = 0.6405s	
6095/11850 (epoch 25.717), train_loss = 1.05695060, grad/param norm = 2.6635e-01, time/batch = 0.6371s	
6096/11850 (epoch 25.722), train_loss = 1.11823271, grad/param norm = 3.1902e-01, time/batch = 0.6372s	
6097/11850 (epoch 25.726), train_loss = 0.99955504, grad/param norm = 3.0682e-01, time/batch = 0.6387s	
6098/11850 (epoch 25.730), train_loss = 1.00959770, grad/param norm = 2.5145e-01, time/batch = 0.6388s	
6099/11850 (epoch 25.734), train_loss = 1.04121547, grad/param norm = 2.4166e-01, time/batch = 0.6401s	
6100/11850 (epoch 25.738), train_loss = 1.17948698, grad/param norm = 2.8461e-01, time/batch = 0.6372s	
6101/11850 (epoch 25.743), train_loss = 1.09324514, grad/param norm = 2.4464e-01, time/batch = 0.6503s	
6102/11850 (epoch 25.747), train_loss = 0.97010458, grad/param norm = 2.2685e-01, time/batch = 0.6708s	
6103/11850 (epoch 25.751), train_loss = 1.01579918, grad/param norm = 2.3403e-01, time/batch = 0.6434s	
6104/11850 (epoch 25.755), train_loss = 1.10637682, grad/param norm = 2.6319e-01, time/batch = 0.6406s	
6105/11850 (epoch 25.759), train_loss = 1.03686081, grad/param norm = 2.4293e-01, time/batch = 0.6381s	
6106/11850 (epoch 25.764), train_loss = 1.04767968, grad/param norm = 2.4515e-01, time/batch = 0.6392s	
6107/11850 (epoch 25.768), train_loss = 0.97045457, grad/param norm = 2.4228e-01, time/batch = 0.6437s	
6108/11850 (epoch 25.772), train_loss = 1.04550805, grad/param norm = 2.6036e-01, time/batch = 0.6393s	
6109/11850 (epoch 25.776), train_loss = 1.10597551, grad/param norm = 2.3877e-01, time/batch = 0.6400s	
6110/11850 (epoch 25.781), train_loss = 1.08078407, grad/param norm = 2.8872e-01, time/batch = 0.6480s	
6111/11850 (epoch 25.785), train_loss = 1.03203201, grad/param norm = 2.5951e-01, time/batch = 0.6520s	
6112/11850 (epoch 25.789), train_loss = 1.08019444, grad/param norm = 2.5893e-01, time/batch = 0.6558s	
6113/11850 (epoch 25.793), train_loss = 1.17525954, grad/param norm = 2.9919e-01, time/batch = 0.6692s	
6114/11850 (epoch 25.797), train_loss = 1.11530710, grad/param norm = 2.9349e-01, time/batch = 0.6512s	
6115/11850 (epoch 25.802), train_loss = 0.98277255, grad/param norm = 2.5537e-01, time/batch = 0.6486s	
6116/11850 (epoch 25.806), train_loss = 1.07587195, grad/param norm = 2.4536e-01, time/batch = 0.6389s	
6117/11850 (epoch 25.810), train_loss = 1.18448312, grad/param norm = 2.6983e-01, time/batch = 0.6368s	
6118/11850 (epoch 25.814), train_loss = 1.06786609, grad/param norm = 2.6438e-01, time/batch = 0.6379s	
6119/11850 (epoch 25.819), train_loss = 1.21864515, grad/param norm = 3.0103e-01, time/batch = 0.6392s	
6120/11850 (epoch 25.823), train_loss = 1.22647624, grad/param norm = 2.5606e-01, time/batch = 0.6402s	
6121/11850 (epoch 25.827), train_loss = 1.10721875, grad/param norm = 2.6742e-01, time/batch = 0.6373s	
6122/11850 (epoch 25.831), train_loss = 1.09160188, grad/param norm = 2.5281e-01, time/batch = 0.6398s	
6123/11850 (epoch 25.835), train_loss = 1.10310843, grad/param norm = 2.4710e-01, time/batch = 0.6616s	
6124/11850 (epoch 25.840), train_loss = 1.06311028, grad/param norm = 2.5681e-01, time/batch = 0.6646s	
6125/11850 (epoch 25.844), train_loss = 1.07235393, grad/param norm = 2.3103e-01, time/batch = 0.6430s	
6126/11850 (epoch 25.848), train_loss = 1.11346969, grad/param norm = 2.6248e-01, time/batch = 0.6356s	
6127/11850 (epoch 25.852), train_loss = 1.08732316, grad/param norm = 2.5448e-01, time/batch = 0.6346s	
6128/11850 (epoch 25.857), train_loss = 1.09367244, grad/param norm = 3.0253e-01, time/batch = 0.6400s	
6129/11850 (epoch 25.861), train_loss = 1.08394998, grad/param norm = 2.9225e-01, time/batch = 0.6443s	
6130/11850 (epoch 25.865), train_loss = 1.17409317, grad/param norm = 3.4707e-01, time/batch = 0.6415s	
6131/11850 (epoch 25.869), train_loss = 1.14407172, grad/param norm = 2.9802e-01, time/batch = 0.6576s	
6132/11850 (epoch 25.873), train_loss = 1.14924541, grad/param norm = 2.6345e-01, time/batch = 0.6365s	
6133/11850 (epoch 25.878), train_loss = 1.15883184, grad/param norm = 2.6714e-01, time/batch = 0.6522s	
6134/11850 (epoch 25.882), train_loss = 1.12794026, grad/param norm = 2.7803e-01, time/batch = 0.6710s	
6135/11850 (epoch 25.886), train_loss = 1.10859641, grad/param norm = 2.7812e-01, time/batch = 0.6702s	
6136/11850 (epoch 25.890), train_loss = 1.12263157, grad/param norm = 2.8278e-01, time/batch = 0.6694s	
6137/11850 (epoch 25.895), train_loss = 1.15165840, grad/param norm = 2.9067e-01, time/batch = 0.6682s	
6138/11850 (epoch 25.899), train_loss = 1.00487974, grad/param norm = 2.6331e-01, time/batch = 0.6619s	
6139/11850 (epoch 25.903), train_loss = 1.06827996, grad/param norm = 2.4508e-01, time/batch = 0.6599s	
6140/11850 (epoch 25.907), train_loss = 1.06450291, grad/param norm = 2.7635e-01, time/batch = 0.6506s	
6141/11850 (epoch 25.911), train_loss = 1.20755072, grad/param norm = 2.9502e-01, time/batch = 0.6463s	
6142/11850 (epoch 25.916), train_loss = 1.17507566, grad/param norm = 3.0191e-01, time/batch = 0.6352s	
6143/11850 (epoch 25.920), train_loss = 1.11671739, grad/param norm = 2.7707e-01, time/batch = 0.6461s	
6144/11850 (epoch 25.924), train_loss = 1.09321830, grad/param norm = 2.8794e-01, time/batch = 0.6563s	
6145/11850 (epoch 25.928), train_loss = 1.16885505, grad/param norm = 2.9561e-01, time/batch = 0.6365s	
6146/11850 (epoch 25.932), train_loss = 1.22917624, grad/param norm = 2.6042e-01, time/batch = 0.6375s	
6147/11850 (epoch 25.937), train_loss = 1.16202077, grad/param norm = 2.4713e-01, time/batch = 0.6735s	
6148/11850 (epoch 25.941), train_loss = 1.16697352, grad/param norm = 2.5084e-01, time/batch = 0.6711s	
6149/11850 (epoch 25.945), train_loss = 1.18939660, grad/param norm = 2.7609e-01, time/batch = 0.6722s	
6150/11850 (epoch 25.949), train_loss = 1.08158281, grad/param norm = 3.1790e-01, time/batch = 0.6559s	
6151/11850 (epoch 25.954), train_loss = 1.16435142, grad/param norm = 3.2261e-01, time/batch = 0.6573s	
6152/11850 (epoch 25.958), train_loss = 1.16558160, grad/param norm = 2.8122e-01, time/batch = 0.6542s	
6153/11850 (epoch 25.962), train_loss = 1.05196022, grad/param norm = 2.6095e-01, time/batch = 0.6560s	
6154/11850 (epoch 25.966), train_loss = 1.02700617, grad/param norm = 3.3258e-01, time/batch = 0.6558s	
6155/11850 (epoch 25.970), train_loss = 1.16096265, grad/param norm = 3.3315e-01, time/batch = 0.6489s	
6156/11850 (epoch 25.975), train_loss = 1.09959803, grad/param norm = 2.7127e-01, time/batch = 0.6446s	
6157/11850 (epoch 25.979), train_loss = 1.12168467, grad/param norm = 3.1013e-01, time/batch = 0.6440s	
6158/11850 (epoch 25.983), train_loss = 1.23460700, grad/param norm = 3.6842e-01, time/batch = 0.6446s	
6159/11850 (epoch 25.987), train_loss = 1.10248206, grad/param norm = 2.8834e-01, time/batch = 0.6449s	
6160/11850 (epoch 25.992), train_loss = 1.25195626, grad/param norm = 2.7182e-01, time/batch = 0.6641s	
6161/11850 (epoch 25.996), train_loss = 1.27606639, grad/param norm = 2.9593e-01, time/batch = 0.6610s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
6162/11850 (epoch 26.000), train_loss = 1.11209492, grad/param norm = 2.9156e-01, time/batch = 0.6434s	
6163/11850 (epoch 26.004), train_loss = 1.16707310, grad/param norm = 2.9761e-01, time/batch = 0.6468s	
6164/11850 (epoch 26.008), train_loss = 1.23772862, grad/param norm = 2.8223e-01, time/batch = 0.6492s	
6165/11850 (epoch 26.013), train_loss = 1.21507656, grad/param norm = 2.7359e-01, time/batch = 0.6490s	
6166/11850 (epoch 26.017), train_loss = 1.26743499, grad/param norm = 2.4421e-01, time/batch = 0.6446s	
6167/11850 (epoch 26.021), train_loss = 1.17562407, grad/param norm = 2.4619e-01, time/batch = 0.6417s	
6168/11850 (epoch 26.025), train_loss = 1.04218712, grad/param norm = 2.3867e-01, time/batch = 0.6410s	
6169/11850 (epoch 26.030), train_loss = 1.07178339, grad/param norm = 2.7375e-01, time/batch = 0.6257s	
6170/11850 (epoch 26.034), train_loss = 1.08112029, grad/param norm = 2.7402e-01, time/batch = 0.6237s	
6171/11850 (epoch 26.038), train_loss = 1.12815222, grad/param norm = 2.4612e-01, time/batch = 0.6277s	
6172/11850 (epoch 26.042), train_loss = 1.13558210, grad/param norm = 2.5990e-01, time/batch = 0.6242s	
6173/11850 (epoch 26.046), train_loss = 1.12708391, grad/param norm = 2.7689e-01, time/batch = 0.6276s	
6174/11850 (epoch 26.051), train_loss = 1.12951822, grad/param norm = 2.5020e-01, time/batch = 0.6333s	
6175/11850 (epoch 26.055), train_loss = 1.10602259, grad/param norm = 2.7805e-01, time/batch = 0.6302s	
6176/11850 (epoch 26.059), train_loss = 1.20015968, grad/param norm = 2.5782e-01, time/batch = 0.6288s	
6177/11850 (epoch 26.063), train_loss = 1.16999127, grad/param norm = 2.6761e-01, time/batch = 0.6445s	
6178/11850 (epoch 26.068), train_loss = 1.11859040, grad/param norm = 2.4175e-01, time/batch = 0.6461s	
6179/11850 (epoch 26.072), train_loss = 1.15472346, grad/param norm = 2.6222e-01, time/batch = 0.6263s	
6180/11850 (epoch 26.076), train_loss = 1.27151831, grad/param norm = 2.7723e-01, time/batch = 0.6227s	
6181/11850 (epoch 26.080), train_loss = 1.06442122, grad/param norm = 2.5943e-01, time/batch = 0.6271s	
6182/11850 (epoch 26.084), train_loss = 0.98244642, grad/param norm = 2.2094e-01, time/batch = 0.6263s	
6183/11850 (epoch 26.089), train_loss = 1.01049841, grad/param norm = 2.3546e-01, time/batch = 0.6221s	
6184/11850 (epoch 26.093), train_loss = 1.01060661, grad/param norm = 2.5876e-01, time/batch = 0.6237s	
6185/11850 (epoch 26.097), train_loss = 1.13070930, grad/param norm = 2.7226e-01, time/batch = 0.6268s	
6186/11850 (epoch 26.101), train_loss = 1.06021248, grad/param norm = 2.7403e-01, time/batch = 0.6221s	
6187/11850 (epoch 26.105), train_loss = 1.01958352, grad/param norm = 2.3704e-01, time/batch = 0.6264s	
6188/11850 (epoch 26.110), train_loss = 1.15799936, grad/param norm = 2.5960e-01, time/batch = 0.6534s	
6189/11850 (epoch 26.114), train_loss = 1.10703101, grad/param norm = 2.6143e-01, time/batch = 0.6450s	
6190/11850 (epoch 26.118), train_loss = 1.16008028, grad/param norm = 2.4172e-01, time/batch = 0.6232s	
6191/11850 (epoch 26.122), train_loss = 1.21020225, grad/param norm = 2.6275e-01, time/batch = 0.6279s	
6192/11850 (epoch 26.127), train_loss = 1.14314383, grad/param norm = 2.6894e-01, time/batch = 0.6266s	
6193/11850 (epoch 26.131), train_loss = 1.11505281, grad/param norm = 3.0612e-01, time/batch = 0.6231s	
6194/11850 (epoch 26.135), train_loss = 1.07616082, grad/param norm = 2.7479e-01, time/batch = 0.6259s	
6195/11850 (epoch 26.139), train_loss = 1.07640937, grad/param norm = 2.7066e-01, time/batch = 0.6308s	
6196/11850 (epoch 26.143), train_loss = 1.11620131, grad/param norm = 2.8068e-01, time/batch = 0.6252s	
6197/11850 (epoch 26.148), train_loss = 1.09631305, grad/param norm = 2.5969e-01, time/batch = 0.6247s	
6198/11850 (epoch 26.152), train_loss = 1.20864321, grad/param norm = 2.9685e-01, time/batch = 0.6233s	
6199/11850 (epoch 26.156), train_loss = 1.12703753, grad/param norm = 3.1765e-01, time/batch = 0.6526s	
6200/11850 (epoch 26.160), train_loss = 1.33407012, grad/param norm = 3.0183e-01, time/batch = 0.6461s	
6201/11850 (epoch 26.165), train_loss = 1.28369641, grad/param norm = 3.3989e-01, time/batch = 0.6247s	
6202/11850 (epoch 26.169), train_loss = 1.09529017, grad/param norm = 2.8236e-01, time/batch = 0.6257s	
6203/11850 (epoch 26.173), train_loss = 1.16104273, grad/param norm = 2.5780e-01, time/batch = 0.6240s	
6204/11850 (epoch 26.177), train_loss = 1.06642735, grad/param norm = 3.2111e-01, time/batch = 0.6220s	
6205/11850 (epoch 26.181), train_loss = 1.18975922, grad/param norm = 2.4793e-01, time/batch = 0.6245s	
6206/11850 (epoch 26.186), train_loss = 1.25092901, grad/param norm = 3.3678e-01, time/batch = 0.6222s	
6207/11850 (epoch 26.190), train_loss = 1.14470074, grad/param norm = 2.3910e-01, time/batch = 0.6234s	
6208/11850 (epoch 26.194), train_loss = 1.21465799, grad/param norm = 3.1792e-01, time/batch = 0.6254s	
6209/11850 (epoch 26.198), train_loss = 0.97105544, grad/param norm = 2.5328e-01, time/batch = 0.6265s	
6210/11850 (epoch 26.203), train_loss = 0.98709837, grad/param norm = 2.3946e-01, time/batch = 0.6238s	
6211/11850 (epoch 26.207), train_loss = 1.19243117, grad/param norm = 3.2312e-01, time/batch = 0.6318s	
6212/11850 (epoch 26.211), train_loss = 1.13427114, grad/param norm = 2.5504e-01, time/batch = 0.6333s	
6213/11850 (epoch 26.215), train_loss = 1.10904140, grad/param norm = 2.6441e-01, time/batch = 0.6288s	
6214/11850 (epoch 26.219), train_loss = 1.14682612, grad/param norm = 2.6676e-01, time/batch = 0.6265s	
6215/11850 (epoch 26.224), train_loss = 1.27364677, grad/param norm = 2.5448e-01, time/batch = 0.6269s	
6216/11850 (epoch 26.228), train_loss = 1.18612425, grad/param norm = 2.7315e-01, time/batch = 0.6281s	
6217/11850 (epoch 26.232), train_loss = 1.15971432, grad/param norm = 2.5238e-01, time/batch = 0.6276s	
6218/11850 (epoch 26.236), train_loss = 1.03840521, grad/param norm = 2.6445e-01, time/batch = 0.6238s	
6219/11850 (epoch 26.241), train_loss = 1.21488815, grad/param norm = 3.3849e-01, time/batch = 0.6260s	
6220/11850 (epoch 26.245), train_loss = 1.19152395, grad/param norm = 2.4750e-01, time/batch = 0.6222s	
6221/11850 (epoch 26.249), train_loss = 1.07657139, grad/param norm = 2.6553e-01, time/batch = 0.6259s	
6222/11850 (epoch 26.253), train_loss = 1.14011270, grad/param norm = 2.9990e-01, time/batch = 0.6249s	
6223/11850 (epoch 26.257), train_loss = 1.25836586, grad/param norm = 2.8750e-01, time/batch = 0.6258s	
6224/11850 (epoch 26.262), train_loss = 1.27507785, grad/param norm = 3.1836e-01, time/batch = 0.6261s	
6225/11850 (epoch 26.266), train_loss = 1.22523529, grad/param norm = 2.7000e-01, time/batch = 0.6248s	
6226/11850 (epoch 26.270), train_loss = 1.10321563, grad/param norm = 2.2767e-01, time/batch = 0.6257s	
6227/11850 (epoch 26.274), train_loss = 1.12246216, grad/param norm = 2.9265e-01, time/batch = 0.6247s	
6228/11850 (epoch 26.278), train_loss = 0.97053525, grad/param norm = 2.5596e-01, time/batch = 0.6262s	
6229/11850 (epoch 26.283), train_loss = 1.09094167, grad/param norm = 2.6105e-01, time/batch = 0.6272s	
6230/11850 (epoch 26.287), train_loss = 1.23189881, grad/param norm = 2.6641e-01, time/batch = 0.6218s	
6231/11850 (epoch 26.291), train_loss = 1.11139256, grad/param norm = 2.6462e-01, time/batch = 0.6264s	
6232/11850 (epoch 26.295), train_loss = 1.18153496, grad/param norm = 2.6201e-01, time/batch = 0.6274s	
6233/11850 (epoch 26.300), train_loss = 1.07653989, grad/param norm = 2.8557e-01, time/batch = 0.6348s	
6234/11850 (epoch 26.304), train_loss = 1.10050015, grad/param norm = 2.3324e-01, time/batch = 0.6307s	
6235/11850 (epoch 26.308), train_loss = 1.08412578, grad/param norm = 2.3850e-01, time/batch = 0.6216s	
6236/11850 (epoch 26.312), train_loss = 0.99382706, grad/param norm = 2.3404e-01, time/batch = 0.6208s	
6237/11850 (epoch 26.316), train_loss = 1.16140013, grad/param norm = 2.4452e-01, time/batch = 0.6222s	
6238/11850 (epoch 26.321), train_loss = 1.09954175, grad/param norm = 2.5400e-01, time/batch = 0.6216s	
6239/11850 (epoch 26.325), train_loss = 1.11136693, grad/param norm = 2.5401e-01, time/batch = 0.6306s	
6240/11850 (epoch 26.329), train_loss = 1.11571970, grad/param norm = 2.5033e-01, time/batch = 0.6202s	
6241/11850 (epoch 26.333), train_loss = 1.10575483, grad/param norm = 2.6910e-01, time/batch = 0.6385s	
6242/11850 (epoch 26.338), train_loss = 1.04406199, grad/param norm = 2.4672e-01, time/batch = 0.6504s	
6243/11850 (epoch 26.342), train_loss = 1.13635082, grad/param norm = 2.7399e-01, time/batch = 0.6600s	
6244/11850 (epoch 26.346), train_loss = 1.10254253, grad/param norm = 2.5770e-01, time/batch = 0.6487s	
6245/11850 (epoch 26.350), train_loss = 0.98794649, grad/param norm = 2.4595e-01, time/batch = 0.6259s	
6246/11850 (epoch 26.354), train_loss = 1.19243744, grad/param norm = 2.4407e-01, time/batch = 0.6324s	
6247/11850 (epoch 26.359), train_loss = 1.23298809, grad/param norm = 2.9566e-01, time/batch = 0.6273s	
6248/11850 (epoch 26.363), train_loss = 1.15200993, grad/param norm = 2.4382e-01, time/batch = 0.6267s	
6249/11850 (epoch 26.367), train_loss = 1.17325395, grad/param norm = 2.5555e-01, time/batch = 0.6310s	
6250/11850 (epoch 26.371), train_loss = 1.15970757, grad/param norm = 2.3976e-01, time/batch = 0.6312s	
6251/11850 (epoch 26.376), train_loss = 1.10007104, grad/param norm = 2.5048e-01, time/batch = 0.6286s	
6252/11850 (epoch 26.380), train_loss = 1.06958024, grad/param norm = 2.3662e-01, time/batch = 0.6472s	
6253/11850 (epoch 26.384), train_loss = 1.03022276, grad/param norm = 2.4520e-01, time/batch = 0.6679s	
6254/11850 (epoch 26.388), train_loss = 1.20139070, grad/param norm = 2.8181e-01, time/batch = 0.6493s	
6255/11850 (epoch 26.392), train_loss = 1.17944380, grad/param norm = 2.5754e-01, time/batch = 0.6399s	
6256/11850 (epoch 26.397), train_loss = 1.19731830, grad/param norm = 2.7511e-01, time/batch = 0.6249s	
6257/11850 (epoch 26.401), train_loss = 0.99871039, grad/param norm = 2.2905e-01, time/batch = 0.6227s	
6258/11850 (epoch 26.405), train_loss = 1.05332765, grad/param norm = 2.7504e-01, time/batch = 0.6270s	
6259/11850 (epoch 26.409), train_loss = 1.20164710, grad/param norm = 2.6636e-01, time/batch = 0.6252s	
6260/11850 (epoch 26.414), train_loss = 0.97578595, grad/param norm = 2.4618e-01, time/batch = 0.6244s	
6261/11850 (epoch 26.418), train_loss = 1.01966557, grad/param norm = 2.4785e-01, time/batch = 0.6260s	
6262/11850 (epoch 26.422), train_loss = 0.93269830, grad/param norm = 2.5344e-01, time/batch = 0.6224s	
6263/11850 (epoch 26.426), train_loss = 0.96090952, grad/param norm = 2.5279e-01, time/batch = 0.6282s	
6264/11850 (epoch 26.430), train_loss = 1.03343998, grad/param norm = 2.8487e-01, time/batch = 0.6225s	
6265/11850 (epoch 26.435), train_loss = 1.04885602, grad/param norm = 2.5756e-01, time/batch = 0.6220s	
6266/11850 (epoch 26.439), train_loss = 1.16032249, grad/param norm = 2.5890e-01, time/batch = 0.6225s	
6267/11850 (epoch 26.443), train_loss = 1.10122591, grad/param norm = 2.4569e-01, time/batch = 0.6211s	
6268/11850 (epoch 26.447), train_loss = 0.99050990, grad/param norm = 2.4737e-01, time/batch = 0.6215s	
6269/11850 (epoch 26.451), train_loss = 1.01710689, grad/param norm = 2.5992e-01, time/batch = 0.6234s	
6270/11850 (epoch 26.456), train_loss = 1.09853261, grad/param norm = 2.6686e-01, time/batch = 0.6233s	
6271/11850 (epoch 26.460), train_loss = 1.14756282, grad/param norm = 2.4588e-01, time/batch = 0.6265s	
6272/11850 (epoch 26.464), train_loss = 1.04370629, grad/param norm = 2.8607e-01, time/batch = 0.6229s	
6273/11850 (epoch 26.468), train_loss = 1.12963078, grad/param norm = 2.6075e-01, time/batch = 0.6221s	
6274/11850 (epoch 26.473), train_loss = 1.16375869, grad/param norm = 2.7437e-01, time/batch = 0.6267s	
6275/11850 (epoch 26.477), train_loss = 1.02583792, grad/param norm = 2.6316e-01, time/batch = 0.6236s	
6276/11850 (epoch 26.481), train_loss = 1.02819552, grad/param norm = 2.4792e-01, time/batch = 0.6273s	
6277/11850 (epoch 26.485), train_loss = 0.99843321, grad/param norm = 2.3977e-01, time/batch = 0.6257s	
6278/11850 (epoch 26.489), train_loss = 1.12700091, grad/param norm = 2.3930e-01, time/batch = 0.6253s	
6279/11850 (epoch 26.494), train_loss = 1.02163268, grad/param norm = 3.1478e-01, time/batch = 0.6263s	
6280/11850 (epoch 26.498), train_loss = 0.99967797, grad/param norm = 2.7215e-01, time/batch = 0.6260s	
6281/11850 (epoch 26.502), train_loss = 0.98982862, grad/param norm = 2.7606e-01, time/batch = 0.6259s	
6282/11850 (epoch 26.506), train_loss = 1.25974991, grad/param norm = 2.8570e-01, time/batch = 0.6281s	
6283/11850 (epoch 26.511), train_loss = 1.10623262, grad/param norm = 2.6344e-01, time/batch = 0.6226s	
6284/11850 (epoch 26.515), train_loss = 1.22629310, grad/param norm = 2.9517e-01, time/batch = 0.6245s	
6285/11850 (epoch 26.519), train_loss = 1.05999618, grad/param norm = 2.5455e-01, time/batch = 0.6230s	
6286/11850 (epoch 26.523), train_loss = 1.08657386, grad/param norm = 2.4408e-01, time/batch = 0.6260s	
6287/11850 (epoch 26.527), train_loss = 1.01915958, grad/param norm = 2.4765e-01, time/batch = 0.6312s	
6288/11850 (epoch 26.532), train_loss = 1.15324983, grad/param norm = 2.7080e-01, time/batch = 0.6320s	
6289/11850 (epoch 26.536), train_loss = 1.04672927, grad/param norm = 2.5202e-01, time/batch = 0.6236s	
6290/11850 (epoch 26.540), train_loss = 1.02297030, grad/param norm = 2.2712e-01, time/batch = 0.6223s	
6291/11850 (epoch 26.544), train_loss = 1.02033719, grad/param norm = 2.6088e-01, time/batch = 0.6221s	
6292/11850 (epoch 26.549), train_loss = 0.94617886, grad/param norm = 2.1537e-01, time/batch = 0.6253s	
6293/11850 (epoch 26.553), train_loss = 1.10635534, grad/param norm = 2.6880e-01, time/batch = 0.6203s	
6294/11850 (epoch 26.557), train_loss = 1.13928456, grad/param norm = 2.6963e-01, time/batch = 0.6249s	
6295/11850 (epoch 26.561), train_loss = 1.11790728, grad/param norm = 3.0951e-01, time/batch = 0.6266s	
6296/11850 (epoch 26.565), train_loss = 1.22660943, grad/param norm = 2.5708e-01, time/batch = 0.6261s	
6297/11850 (epoch 26.570), train_loss = 1.09605058, grad/param norm = 2.4118e-01, time/batch = 0.6222s	
6298/11850 (epoch 26.574), train_loss = 1.16056217, grad/param norm = 3.1031e-01, time/batch = 0.6222s	
6299/11850 (epoch 26.578), train_loss = 1.19416752, grad/param norm = 2.8103e-01, time/batch = 0.6207s	
6300/11850 (epoch 26.582), train_loss = 1.07083611, grad/param norm = 3.0704e-01, time/batch = 0.6237s	
6301/11850 (epoch 26.586), train_loss = 1.05783357, grad/param norm = 2.4606e-01, time/batch = 0.6229s	
6302/11850 (epoch 26.591), train_loss = 1.14930308, grad/param norm = 3.0487e-01, time/batch = 0.6277s	
6303/11850 (epoch 26.595), train_loss = 0.95613165, grad/param norm = 2.7426e-01, time/batch = 0.6258s	
6304/11850 (epoch 26.599), train_loss = 1.09428527, grad/param norm = 2.5679e-01, time/batch = 0.6264s	
6305/11850 (epoch 26.603), train_loss = 1.04298614, grad/param norm = 2.4055e-01, time/batch = 0.6248s	
6306/11850 (epoch 26.608), train_loss = 1.22049553, grad/param norm = 2.4563e-01, time/batch = 0.6251s	
6307/11850 (epoch 26.612), train_loss = 1.28755638, grad/param norm = 2.9175e-01, time/batch = 0.6270s	
6308/11850 (epoch 26.616), train_loss = 1.20883831, grad/param norm = 2.5590e-01, time/batch = 0.6273s	
6309/11850 (epoch 26.620), train_loss = 1.08834700, grad/param norm = 2.4466e-01, time/batch = 0.6274s	
6310/11850 (epoch 26.624), train_loss = 1.12112135, grad/param norm = 3.5472e-01, time/batch = 0.6282s	
6311/11850 (epoch 26.629), train_loss = 1.02288466, grad/param norm = 2.4761e-01, time/batch = 0.6279s	
6312/11850 (epoch 26.633), train_loss = 0.99023009, grad/param norm = 2.5981e-01, time/batch = 0.6294s	
6313/11850 (epoch 26.637), train_loss = 0.94715673, grad/param norm = 2.5388e-01, time/batch = 0.6270s	
6314/11850 (epoch 26.641), train_loss = 0.97352844, grad/param norm = 2.2253e-01, time/batch = 0.6365s	
6315/11850 (epoch 26.646), train_loss = 1.01894691, grad/param norm = 2.4411e-01, time/batch = 0.6335s	
6316/11850 (epoch 26.650), train_loss = 1.09028502, grad/param norm = 2.8333e-01, time/batch = 0.6240s	
6317/11850 (epoch 26.654), train_loss = 1.03116113, grad/param norm = 2.8406e-01, time/batch = 0.6209s	
6318/11850 (epoch 26.658), train_loss = 1.12887750, grad/param norm = 3.1508e-01, time/batch = 0.6257s	
6319/11850 (epoch 26.662), train_loss = 0.96956090, grad/param norm = 3.2765e-01, time/batch = 0.6248s	
6320/11850 (epoch 26.667), train_loss = 1.16537345, grad/param norm = 2.5653e-01, time/batch = 0.6237s	
6321/11850 (epoch 26.671), train_loss = 1.09436278, grad/param norm = 2.7806e-01, time/batch = 0.6245s	
6322/11850 (epoch 26.675), train_loss = 1.05242419, grad/param norm = 2.5330e-01, time/batch = 0.6251s	
6323/11850 (epoch 26.679), train_loss = 1.10132300, grad/param norm = 2.6622e-01, time/batch = 0.6255s	
6324/11850 (epoch 26.684), train_loss = 1.06129880, grad/param norm = 2.7697e-01, time/batch = 0.6250s	
6325/11850 (epoch 26.688), train_loss = 1.03069732, grad/param norm = 2.5573e-01, time/batch = 0.6203s	
6326/11850 (epoch 26.692), train_loss = 1.03866381, grad/param norm = 2.7917e-01, time/batch = 0.6556s	
6327/11850 (epoch 26.696), train_loss = 1.01244570, grad/param norm = 2.9075e-01, time/batch = 0.6424s	
6328/11850 (epoch 26.700), train_loss = 1.09103785, grad/param norm = 2.5964e-01, time/batch = 0.6235s	
6329/11850 (epoch 26.705), train_loss = 1.05449404, grad/param norm = 2.5276e-01, time/batch = 0.6351s	
6330/11850 (epoch 26.709), train_loss = 0.95107580, grad/param norm = 2.4610e-01, time/batch = 0.6275s	
6331/11850 (epoch 26.713), train_loss = 0.97767685, grad/param norm = 2.6841e-01, time/batch = 0.6256s	
6332/11850 (epoch 26.717), train_loss = 1.03682016, grad/param norm = 2.7046e-01, time/batch = 0.6264s	
6333/11850 (epoch 26.722), train_loss = 1.09465414, grad/param norm = 2.9644e-01, time/batch = 0.6251s	
6334/11850 (epoch 26.726), train_loss = 0.97563960, grad/param norm = 2.5639e-01, time/batch = 0.6295s	
6335/11850 (epoch 26.730), train_loss = 0.99447345, grad/param norm = 2.5082e-01, time/batch = 0.6218s	
6336/11850 (epoch 26.734), train_loss = 1.02426351, grad/param norm = 2.3074e-01, time/batch = 0.6480s	
6337/11850 (epoch 26.738), train_loss = 1.15596159, grad/param norm = 2.6791e-01, time/batch = 0.6536s	
6338/11850 (epoch 26.743), train_loss = 1.08050553, grad/param norm = 2.8021e-01, time/batch = 0.6490s	
6339/11850 (epoch 26.747), train_loss = 0.94794104, grad/param norm = 2.1969e-01, time/batch = 0.6414s	
6340/11850 (epoch 26.751), train_loss = 1.00160170, grad/param norm = 2.3642e-01, time/batch = 0.6372s	
6341/11850 (epoch 26.755), train_loss = 1.06957047, grad/param norm = 2.4973e-01, time/batch = 0.6285s	
6342/11850 (epoch 26.759), train_loss = 1.01728639, grad/param norm = 2.3923e-01, time/batch = 0.6318s	
6343/11850 (epoch 26.764), train_loss = 1.02788189, grad/param norm = 2.4579e-01, time/batch = 0.6283s	
6344/11850 (epoch 26.768), train_loss = 0.95619693, grad/param norm = 2.4099e-01, time/batch = 0.6304s	
6345/11850 (epoch 26.772), train_loss = 1.03344833, grad/param norm = 3.2847e-01, time/batch = 0.6315s	
6346/11850 (epoch 26.776), train_loss = 1.09148240, grad/param norm = 2.6495e-01, time/batch = 0.6263s	
6347/11850 (epoch 26.781), train_loss = 1.05458473, grad/param norm = 2.6590e-01, time/batch = 0.6268s	
6348/11850 (epoch 26.785), train_loss = 1.02909963, grad/param norm = 3.1773e-01, time/batch = 0.6361s	
6349/11850 (epoch 26.789), train_loss = 1.05911238, grad/param norm = 2.5170e-01, time/batch = 0.6318s	
6350/11850 (epoch 26.793), train_loss = 1.14962240, grad/param norm = 2.9245e-01, time/batch = 0.6238s	
6351/11850 (epoch 26.797), train_loss = 1.08696750, grad/param norm = 2.5918e-01, time/batch = 0.6252s	
6352/11850 (epoch 26.802), train_loss = 0.97842635, grad/param norm = 2.6726e-01, time/batch = 0.6269s	
6353/11850 (epoch 26.806), train_loss = 1.05987599, grad/param norm = 2.6513e-01, time/batch = 0.6490s	
6354/11850 (epoch 26.810), train_loss = 1.16211190, grad/param norm = 2.7456e-01, time/batch = 0.6354s	
6355/11850 (epoch 26.814), train_loss = 1.06261621, grad/param norm = 2.7198e-01, time/batch = 0.6306s	
6356/11850 (epoch 26.819), train_loss = 1.19577780, grad/param norm = 2.7222e-01, time/batch = 0.6335s	
6357/11850 (epoch 26.823), train_loss = 1.20976118, grad/param norm = 2.6185e-01, time/batch = 0.6241s	
6358/11850 (epoch 26.827), train_loss = 1.07485436, grad/param norm = 2.6368e-01, time/batch = 0.6254s	
6359/11850 (epoch 26.831), train_loss = 1.06297685, grad/param norm = 2.6032e-01, time/batch = 0.6237s	
6360/11850 (epoch 26.835), train_loss = 1.07719415, grad/param norm = 2.4040e-01, time/batch = 0.6260s	
6361/11850 (epoch 26.840), train_loss = 1.03507677, grad/param norm = 2.6322e-01, time/batch = 0.6234s	
6362/11850 (epoch 26.844), train_loss = 1.05190761, grad/param norm = 2.1052e-01, time/batch = 0.6271s	
6363/11850 (epoch 26.848), train_loss = 1.08636324, grad/param norm = 2.8287e-01, time/batch = 0.6240s	
6364/11850 (epoch 26.852), train_loss = 1.07648237, grad/param norm = 3.0869e-01, time/batch = 0.6226s	
6365/11850 (epoch 26.857), train_loss = 1.06696351, grad/param norm = 2.6311e-01, time/batch = 0.6262s	
6366/11850 (epoch 26.861), train_loss = 1.04730006, grad/param norm = 2.7042e-01, time/batch = 0.6337s	
6367/11850 (epoch 26.865), train_loss = 1.13551548, grad/param norm = 2.7696e-01, time/batch = 0.6232s	
6368/11850 (epoch 26.869), train_loss = 1.11418122, grad/param norm = 2.8454e-01, time/batch = 0.6246s	
6369/11850 (epoch 26.873), train_loss = 1.11995274, grad/param norm = 2.6305e-01, time/batch = 0.6239s	
6370/11850 (epoch 26.878), train_loss = 1.13221951, grad/param norm = 2.9579e-01, time/batch = 0.6231s	
6371/11850 (epoch 26.882), train_loss = 1.08919608, grad/param norm = 2.6394e-01, time/batch = 0.6280s	
6372/11850 (epoch 26.886), train_loss = 1.09541402, grad/param norm = 3.5540e-01, time/batch = 0.6231s	
6373/11850 (epoch 26.890), train_loss = 1.10777667, grad/param norm = 2.9641e-01, time/batch = 0.6225s	
6374/11850 (epoch 26.895), train_loss = 1.14026833, grad/param norm = 3.0364e-01, time/batch = 0.6250s	
6375/11850 (epoch 26.899), train_loss = 0.98841907, grad/param norm = 2.7122e-01, time/batch = 0.6315s	
6376/11850 (epoch 26.903), train_loss = 1.05355428, grad/param norm = 2.9679e-01, time/batch = 0.6261s	
6377/11850 (epoch 26.907), train_loss = 1.03195325, grad/param norm = 2.4254e-01, time/batch = 0.6272s	
6378/11850 (epoch 26.911), train_loss = 1.17710774, grad/param norm = 2.9458e-01, time/batch = 0.6223s	
6379/11850 (epoch 26.916), train_loss = 1.15194484, grad/param norm = 2.7676e-01, time/batch = 0.6254s	
6380/11850 (epoch 26.920), train_loss = 1.09597072, grad/param norm = 2.6613e-01, time/batch = 0.6228s	
6381/11850 (epoch 26.924), train_loss = 1.06820098, grad/param norm = 3.2376e-01, time/batch = 0.6257s	
6382/11850 (epoch 26.928), train_loss = 1.14684404, grad/param norm = 2.8418e-01, time/batch = 0.6235s	
6383/11850 (epoch 26.932), train_loss = 1.19111024, grad/param norm = 3.2390e-01, time/batch = 0.6189s	
6384/11850 (epoch 26.937), train_loss = 1.14165871, grad/param norm = 2.4120e-01, time/batch = 0.6218s	
6385/11850 (epoch 26.941), train_loss = 1.15052967, grad/param norm = 2.7563e-01, time/batch = 0.6268s	
6386/11850 (epoch 26.945), train_loss = 1.16060632, grad/param norm = 2.5483e-01, time/batch = 0.6347s	
6387/11850 (epoch 26.949), train_loss = 1.06188678, grad/param norm = 3.5720e-01, time/batch = 0.6371s	
6388/11850 (epoch 26.954), train_loss = 1.14748171, grad/param norm = 3.3520e-01, time/batch = 0.6213s	
6389/11850 (epoch 26.958), train_loss = 1.13171676, grad/param norm = 2.6641e-01, time/batch = 0.6232s	
6390/11850 (epoch 26.962), train_loss = 1.04573929, grad/param norm = 2.8973e-01, time/batch = 0.6254s	
6391/11850 (epoch 26.966), train_loss = 0.99687989, grad/param norm = 2.7401e-01, time/batch = 0.6222s	
6392/11850 (epoch 26.970), train_loss = 1.12130332, grad/param norm = 2.8239e-01, time/batch = 0.6286s	
6393/11850 (epoch 26.975), train_loss = 1.07085382, grad/param norm = 2.5995e-01, time/batch = 0.6246s	
6394/11850 (epoch 26.979), train_loss = 1.09215614, grad/param norm = 3.0864e-01, time/batch = 0.6231s	
6395/11850 (epoch 26.983), train_loss = 1.19851973, grad/param norm = 3.3766e-01, time/batch = 0.6246s	
6396/11850 (epoch 26.987), train_loss = 1.06292374, grad/param norm = 2.7720e-01, time/batch = 0.6244s	
6397/11850 (epoch 26.992), train_loss = 1.22370418, grad/param norm = 2.7137e-01, time/batch = 0.6434s	
6398/11850 (epoch 26.996), train_loss = 1.25651102, grad/param norm = 2.9414e-01, time/batch = 0.6378s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
6399/11850 (epoch 27.000), train_loss = 1.10869907, grad/param norm = 3.7214e-01, time/batch = 0.6237s	
6400/11850 (epoch 27.004), train_loss = 1.15838550, grad/param norm = 3.1683e-01, time/batch = 0.6269s	
6401/11850 (epoch 27.008), train_loss = 1.21560669, grad/param norm = 2.7785e-01, time/batch = 0.6295s	
6402/11850 (epoch 27.013), train_loss = 1.20046384, grad/param norm = 2.9323e-01, time/batch = 0.6254s	
6403/11850 (epoch 27.017), train_loss = 1.24998200, grad/param norm = 2.8163e-01, time/batch = 0.6297s	
6404/11850 (epoch 27.021), train_loss = 1.14590100, grad/param norm = 2.4149e-01, time/batch = 0.6215s	
6405/11850 (epoch 27.025), train_loss = 1.03637024, grad/param norm = 2.4421e-01, time/batch = 0.6242s	
6406/11850 (epoch 27.030), train_loss = 1.06648753, grad/param norm = 2.9941e-01, time/batch = 0.6216s	
6407/11850 (epoch 27.034), train_loss = 1.06161106, grad/param norm = 2.5857e-01, time/batch = 0.6231s	
6408/11850 (epoch 27.038), train_loss = 1.10347649, grad/param norm = 2.5264e-01, time/batch = 0.6214s	
6409/11850 (epoch 27.042), train_loss = 1.11839122, grad/param norm = 2.6953e-01, time/batch = 0.6238s	
6410/11850 (epoch 27.046), train_loss = 1.10091581, grad/param norm = 2.7534e-01, time/batch = 0.6197s	
6411/11850 (epoch 27.051), train_loss = 1.10147957, grad/param norm = 2.4452e-01, time/batch = 0.6225s	
6412/11850 (epoch 27.055), train_loss = 1.06662820, grad/param norm = 2.4306e-01, time/batch = 0.6219s	
6413/11850 (epoch 27.059), train_loss = 1.17047828, grad/param norm = 2.5768e-01, time/batch = 0.6247s	
6414/11850 (epoch 27.063), train_loss = 1.14476323, grad/param norm = 2.5891e-01, time/batch = 0.6206s	
6415/11850 (epoch 27.068), train_loss = 1.09950151, grad/param norm = 2.5181e-01, time/batch = 0.6238s	
6416/11850 (epoch 27.072), train_loss = 1.13132020, grad/param norm = 2.3978e-01, time/batch = 0.6227s	
6417/11850 (epoch 27.076), train_loss = 1.23447261, grad/param norm = 2.6011e-01, time/batch = 0.6337s	
6418/11850 (epoch 27.080), train_loss = 1.04030526, grad/param norm = 2.3638e-01, time/batch = 0.6205s	
6419/11850 (epoch 27.084), train_loss = 0.97164157, grad/param norm = 2.4493e-01, time/batch = 0.6247s	
6420/11850 (epoch 27.089), train_loss = 0.99219864, grad/param norm = 2.3777e-01, time/batch = 0.6214s	
6421/11850 (epoch 27.093), train_loss = 0.99985308, grad/param norm = 3.0378e-01, time/batch = 0.6232s	
6422/11850 (epoch 27.097), train_loss = 1.09926279, grad/param norm = 2.6279e-01, time/batch = 0.6243s	
6423/11850 (epoch 27.101), train_loss = 1.05288972, grad/param norm = 3.0915e-01, time/batch = 0.6220s	
6424/11850 (epoch 27.105), train_loss = 0.99899108, grad/param norm = 2.4657e-01, time/batch = 0.6230s	
6425/11850 (epoch 27.110), train_loss = 1.13873302, grad/param norm = 2.4977e-01, time/batch = 0.6340s	
6426/11850 (epoch 27.114), train_loss = 1.08676194, grad/param norm = 2.6920e-01, time/batch = 0.6240s	
6427/11850 (epoch 27.118), train_loss = 1.14094452, grad/param norm = 2.3927e-01, time/batch = 0.6244s	
6428/11850 (epoch 27.122), train_loss = 1.18617140, grad/param norm = 2.7381e-01, time/batch = 0.6232s	
6429/11850 (epoch 27.127), train_loss = 1.13267692, grad/param norm = 2.6968e-01, time/batch = 0.6351s	
6430/11850 (epoch 27.131), train_loss = 1.09943058, grad/param norm = 3.3869e-01, time/batch = 0.6361s	
6431/11850 (epoch 27.135), train_loss = 1.06004402, grad/param norm = 2.6447e-01, time/batch = 0.6329s	
6432/11850 (epoch 27.139), train_loss = 1.07576345, grad/param norm = 2.8068e-01, time/batch = 0.6541s	
6433/11850 (epoch 27.143), train_loss = 1.07941534, grad/param norm = 2.6281e-01, time/batch = 0.6604s	
6434/11850 (epoch 27.148), train_loss = 1.08103762, grad/param norm = 2.7329e-01, time/batch = 0.6542s	
6435/11850 (epoch 27.152), train_loss = 1.17994127, grad/param norm = 2.9663e-01, time/batch = 0.6437s	
6436/11850 (epoch 27.156), train_loss = 1.09951187, grad/param norm = 3.6655e-01, time/batch = 0.6278s	
6437/11850 (epoch 27.160), train_loss = 1.32188624, grad/param norm = 3.8612e-01, time/batch = 0.6280s	
6438/11850 (epoch 27.165), train_loss = 1.23110926, grad/param norm = 2.9191e-01, time/batch = 0.6275s	
6439/11850 (epoch 27.169), train_loss = 1.07825582, grad/param norm = 2.9169e-01, time/batch = 0.6355s	
6440/11850 (epoch 27.173), train_loss = 1.15713501, grad/param norm = 3.1787e-01, time/batch = 0.6244s	
6441/11850 (epoch 27.177), train_loss = 1.04025164, grad/param norm = 3.2389e-01, time/batch = 0.6403s	
6442/11850 (epoch 27.181), train_loss = 1.16839900, grad/param norm = 2.6951e-01, time/batch = 0.6353s	
6443/11850 (epoch 27.186), train_loss = 1.22202995, grad/param norm = 3.0491e-01, time/batch = 0.6273s	
6444/11850 (epoch 27.190), train_loss = 1.11969624, grad/param norm = 2.3633e-01, time/batch = 0.6304s	
6445/11850 (epoch 27.194), train_loss = 1.17918011, grad/param norm = 2.7327e-01, time/batch = 0.6545s	
6446/11850 (epoch 27.198), train_loss = 0.95058698, grad/param norm = 2.7478e-01, time/batch = 0.6546s	
6447/11850 (epoch 27.203), train_loss = 0.97457723, grad/param norm = 2.6343e-01, time/batch = 0.6481s	
6448/11850 (epoch 27.207), train_loss = 1.16568426, grad/param norm = 2.8757e-01, time/batch = 0.6244s	
6449/11850 (epoch 27.211), train_loss = 1.11552264, grad/param norm = 2.7781e-01, time/batch = 0.6260s	
6450/11850 (epoch 27.215), train_loss = 1.10773646, grad/param norm = 3.0046e-01, time/batch = 0.6400s	
6451/11850 (epoch 27.219), train_loss = 1.14045116, grad/param norm = 3.0990e-01, time/batch = 0.6255s	
6452/11850 (epoch 27.224), train_loss = 1.25552436, grad/param norm = 2.8871e-01, time/batch = 0.6230s	
6453/11850 (epoch 27.228), train_loss = 1.16515104, grad/param norm = 2.7917e-01, time/batch = 0.6290s	
6454/11850 (epoch 27.232), train_loss = 1.13029692, grad/param norm = 2.9236e-01, time/batch = 0.6215s	
6455/11850 (epoch 27.236), train_loss = 1.01346406, grad/param norm = 2.7220e-01, time/batch = 0.6235s	
6456/11850 (epoch 27.241), train_loss = 1.19257958, grad/param norm = 3.1551e-01, time/batch = 0.6230s	
6457/11850 (epoch 27.245), train_loss = 1.18348430, grad/param norm = 2.9519e-01, time/batch = 0.6485s	
6458/11850 (epoch 27.249), train_loss = 1.05875504, grad/param norm = 2.5295e-01, time/batch = 0.6503s	
6459/11850 (epoch 27.253), train_loss = 1.12587273, grad/param norm = 3.0043e-01, time/batch = 0.6228s	
6460/11850 (epoch 27.257), train_loss = 1.22626147, grad/param norm = 2.6127e-01, time/batch = 0.6245s	
6461/11850 (epoch 27.262), train_loss = 1.26650298, grad/param norm = 3.1505e-01, time/batch = 0.6278s	
6462/11850 (epoch 27.266), train_loss = 1.21829486, grad/param norm = 3.0404e-01, time/batch = 0.6228s	
6463/11850 (epoch 27.270), train_loss = 1.08584621, grad/param norm = 2.4107e-01, time/batch = 0.6240s	
6464/11850 (epoch 27.274), train_loss = 1.10099034, grad/param norm = 2.7609e-01, time/batch = 0.6192s	
6465/11850 (epoch 27.278), train_loss = 0.94724323, grad/param norm = 2.4258e-01, time/batch = 0.6206s	
6466/11850 (epoch 27.283), train_loss = 1.07168617, grad/param norm = 2.4907e-01, time/batch = 0.6233s	
6467/11850 (epoch 27.287), train_loss = 1.21389996, grad/param norm = 2.6024e-01, time/batch = 0.6192s	
6468/11850 (epoch 27.291), train_loss = 1.08773552, grad/param norm = 2.6165e-01, time/batch = 0.6470s	
6469/11850 (epoch 27.295), train_loss = 1.15909891, grad/param norm = 2.6905e-01, time/batch = 0.6460s	
6470/11850 (epoch 27.300), train_loss = 1.05630575, grad/param norm = 2.7980e-01, time/batch = 0.6369s	
6471/11850 (epoch 27.304), train_loss = 1.07965260, grad/param norm = 2.3200e-01, time/batch = 0.6250s	
6472/11850 (epoch 27.308), train_loss = 1.06084516, grad/param norm = 2.3033e-01, time/batch = 0.6264s	
6473/11850 (epoch 27.312), train_loss = 0.98428945, grad/param norm = 2.4346e-01, time/batch = 0.6253s	
6474/11850 (epoch 27.316), train_loss = 1.13877739, grad/param norm = 2.5084e-01, time/batch = 0.6214s	
6475/11850 (epoch 27.321), train_loss = 1.07247530, grad/param norm = 2.6726e-01, time/batch = 0.6196s	
6476/11850 (epoch 27.325), train_loss = 1.09591526, grad/param norm = 2.6416e-01, time/batch = 0.6245s	
6477/11850 (epoch 27.329), train_loss = 1.09488515, grad/param norm = 2.6113e-01, time/batch = 0.6221s	
6478/11850 (epoch 27.333), train_loss = 1.07459040, grad/param norm = 2.5823e-01, time/batch = 0.6237s	
6479/11850 (epoch 27.338), train_loss = 1.01326139, grad/param norm = 2.3010e-01, time/batch = 0.6237s	
6480/11850 (epoch 27.342), train_loss = 1.11584011, grad/param norm = 2.7119e-01, time/batch = 0.6196s	
6481/11850 (epoch 27.346), train_loss = 1.07370980, grad/param norm = 2.5674e-01, time/batch = 0.6262s	
6482/11850 (epoch 27.350), train_loss = 0.97358051, grad/param norm = 2.5689e-01, time/batch = 0.6235s	
6483/11850 (epoch 27.354), train_loss = 1.17945560, grad/param norm = 2.7632e-01, time/batch = 0.6190s	
6484/11850 (epoch 27.359), train_loss = 1.20582798, grad/param norm = 2.9428e-01, time/batch = 0.6214s	
6485/11850 (epoch 27.363), train_loss = 1.14086554, grad/param norm = 2.5174e-01, time/batch = 0.6307s	
6486/11850 (epoch 27.367), train_loss = 1.15272193, grad/param norm = 2.6053e-01, time/batch = 0.6220s	
6487/11850 (epoch 27.371), train_loss = 1.13436056, grad/param norm = 2.2454e-01, time/batch = 0.6295s	
6488/11850 (epoch 27.376), train_loss = 1.08050166, grad/param norm = 2.5681e-01, time/batch = 0.6202s	
6489/11850 (epoch 27.380), train_loss = 1.04396760, grad/param norm = 2.2701e-01, time/batch = 0.6210s	
6490/11850 (epoch 27.384), train_loss = 1.00806009, grad/param norm = 2.2683e-01, time/batch = 0.6225s	
6491/11850 (epoch 27.388), train_loss = 1.19093747, grad/param norm = 2.9885e-01, time/batch = 0.6242s	
6492/11850 (epoch 27.392), train_loss = 1.15982500, grad/param norm = 2.7419e-01, time/batch = 0.6364s	
6493/11850 (epoch 27.397), train_loss = 1.17172535, grad/param norm = 2.7561e-01, time/batch = 0.6507s	
6494/11850 (epoch 27.401), train_loss = 0.98143255, grad/param norm = 2.4143e-01, time/batch = 0.6275s	
6495/11850 (epoch 27.405), train_loss = 1.02877731, grad/param norm = 2.6080e-01, time/batch = 0.6264s	
6496/11850 (epoch 27.409), train_loss = 1.17230360, grad/param norm = 2.6187e-01, time/batch = 0.6276s	
6497/11850 (epoch 27.414), train_loss = 0.95625963, grad/param norm = 2.7082e-01, time/batch = 0.6300s	
6498/11850 (epoch 27.418), train_loss = 0.99891251, grad/param norm = 2.5422e-01, time/batch = 0.6345s	
6499/11850 (epoch 27.422), train_loss = 0.91604541, grad/param norm = 2.4115e-01, time/batch = 0.6513s	
6500/11850 (epoch 27.426), train_loss = 0.93731498, grad/param norm = 2.4149e-01, time/batch = 0.6385s	
6501/11850 (epoch 27.430), train_loss = 1.00825243, grad/param norm = 3.1693e-01, time/batch = 0.6332s	
6502/11850 (epoch 27.435), train_loss = 1.02477889, grad/param norm = 2.6889e-01, time/batch = 0.6357s	
6503/11850 (epoch 27.439), train_loss = 1.13335453, grad/param norm = 2.5464e-01, time/batch = 0.6488s	
6504/11850 (epoch 27.443), train_loss = 1.07003772, grad/param norm = 2.3315e-01, time/batch = 0.6392s	
6505/11850 (epoch 27.447), train_loss = 0.97157018, grad/param norm = 2.4951e-01, time/batch = 0.6382s	
6506/11850 (epoch 27.451), train_loss = 0.99282716, grad/param norm = 2.3550e-01, time/batch = 0.6333s	
6507/11850 (epoch 27.456), train_loss = 1.07114180, grad/param norm = 2.8815e-01, time/batch = 0.6388s	
6508/11850 (epoch 27.460), train_loss = 1.13250886, grad/param norm = 2.5341e-01, time/batch = 0.6346s	
6509/11850 (epoch 27.464), train_loss = 1.02684645, grad/param norm = 2.6650e-01, time/batch = 0.6415s	
6510/11850 (epoch 27.468), train_loss = 1.11687236, grad/param norm = 2.5446e-01, time/batch = 0.6429s	
6511/11850 (epoch 27.473), train_loss = 1.13700765, grad/param norm = 2.6606e-01, time/batch = 0.6365s	
6512/11850 (epoch 27.477), train_loss = 0.99029898, grad/param norm = 2.4857e-01, time/batch = 0.6466s	
6513/11850 (epoch 27.481), train_loss = 1.01042205, grad/param norm = 2.9049e-01, time/batch = 0.6582s	
6514/11850 (epoch 27.485), train_loss = 0.96830587, grad/param norm = 2.2891e-01, time/batch = 0.6378s	
6515/11850 (epoch 27.489), train_loss = 1.12088744, grad/param norm = 2.6598e-01, time/batch = 0.6309s	
6516/11850 (epoch 27.494), train_loss = 0.99249655, grad/param norm = 2.6313e-01, time/batch = 0.6232s	
6517/11850 (epoch 27.498), train_loss = 0.97864289, grad/param norm = 2.7509e-01, time/batch = 0.6230s	
6518/11850 (epoch 27.502), train_loss = 0.96375655, grad/param norm = 2.6844e-01, time/batch = 0.6257s	
6519/11850 (epoch 27.506), train_loss = 1.23602682, grad/param norm = 3.0543e-01, time/batch = 0.6280s	
6520/11850 (epoch 27.511), train_loss = 1.09061093, grad/param norm = 2.8178e-01, time/batch = 0.6309s	
6521/11850 (epoch 27.515), train_loss = 1.18846897, grad/param norm = 2.8570e-01, time/batch = 0.6226s	
6522/11850 (epoch 27.519), train_loss = 1.02553615, grad/param norm = 2.5871e-01, time/batch = 0.6209s	
6523/11850 (epoch 27.523), train_loss = 1.07474843, grad/param norm = 2.4247e-01, time/batch = 0.6235s	
6524/11850 (epoch 27.527), train_loss = 1.00214669, grad/param norm = 2.4771e-01, time/batch = 0.6225s	
6525/11850 (epoch 27.532), train_loss = 1.11368076, grad/param norm = 2.4479e-01, time/batch = 0.6258s	
6526/11850 (epoch 27.536), train_loss = 1.03640492, grad/param norm = 2.4663e-01, time/batch = 0.6405s	
6527/11850 (epoch 27.540), train_loss = 1.00294163, grad/param norm = 2.3207e-01, time/batch = 0.6530s	
6528/11850 (epoch 27.544), train_loss = 0.99465507, grad/param norm = 2.6230e-01, time/batch = 0.6601s	
6529/11850 (epoch 27.549), train_loss = 0.92881871, grad/param norm = 2.2190e-01, time/batch = 0.6638s	
6530/11850 (epoch 27.553), train_loss = 1.08426469, grad/param norm = 2.5498e-01, time/batch = 0.6546s	
6531/11850 (epoch 27.557), train_loss = 1.10359151, grad/param norm = 2.7874e-01, time/batch = 0.6530s	
6532/11850 (epoch 27.561), train_loss = 1.11158635, grad/param norm = 2.9296e-01, time/batch = 0.6461s	
6533/11850 (epoch 27.565), train_loss = 1.20474303, grad/param norm = 2.5204e-01, time/batch = 0.6386s	
6534/11850 (epoch 27.570), train_loss = 1.07277859, grad/param norm = 2.4730e-01, time/batch = 0.6251s	
6535/11850 (epoch 27.574), train_loss = 1.11221847, grad/param norm = 2.5802e-01, time/batch = 0.6349s	
6536/11850 (epoch 27.578), train_loss = 1.16647749, grad/param norm = 2.9167e-01, time/batch = 0.6311s	
6537/11850 (epoch 27.582), train_loss = 1.04013716, grad/param norm = 2.9565e-01, time/batch = 0.6394s	
6538/11850 (epoch 27.586), train_loss = 1.03823489, grad/param norm = 2.4825e-01, time/batch = 0.6233s	
6539/11850 (epoch 27.591), train_loss = 1.10495245, grad/param norm = 2.5064e-01, time/batch = 0.6286s	
6540/11850 (epoch 27.595), train_loss = 0.95252223, grad/param norm = 2.6398e-01, time/batch = 0.6417s	
6541/11850 (epoch 27.599), train_loss = 1.08110590, grad/param norm = 2.8556e-01, time/batch = 0.6242s	
6542/11850 (epoch 27.603), train_loss = 1.01157323, grad/param norm = 2.3630e-01, time/batch = 0.6274s	
6543/11850 (epoch 27.608), train_loss = 1.19937582, grad/param norm = 2.5833e-01, time/batch = 0.6356s	
6544/11850 (epoch 27.612), train_loss = 1.26957035, grad/param norm = 2.9584e-01, time/batch = 0.6214s	
6545/11850 (epoch 27.616), train_loss = 1.19042621, grad/param norm = 2.6542e-01, time/batch = 0.6454s	
6546/11850 (epoch 27.620), train_loss = 1.06587336, grad/param norm = 2.3685e-01, time/batch = 0.6549s	
6547/11850 (epoch 27.624), train_loss = 1.09327593, grad/param norm = 3.6324e-01, time/batch = 0.6195s	
6548/11850 (epoch 27.629), train_loss = 1.01482070, grad/param norm = 2.6672e-01, time/batch = 0.6230s	
6549/11850 (epoch 27.633), train_loss = 0.97751797, grad/param norm = 2.5454e-01, time/batch = 0.6300s	
6550/11850 (epoch 27.637), train_loss = 0.92162906, grad/param norm = 2.4520e-01, time/batch = 0.6395s	
6551/11850 (epoch 27.641), train_loss = 0.96158014, grad/param norm = 2.3192e-01, time/batch = 0.6452s	
6552/11850 (epoch 27.646), train_loss = 0.99228424, grad/param norm = 2.4604e-01, time/batch = 0.6309s	
6553/11850 (epoch 27.650), train_loss = 1.06417688, grad/param norm = 2.6174e-01, time/batch = 0.6344s	
6554/11850 (epoch 27.654), train_loss = 1.00815401, grad/param norm = 2.9747e-01, time/batch = 0.6209s	
6555/11850 (epoch 27.658), train_loss = 1.09616214, grad/param norm = 2.4278e-01, time/batch = 0.6231s	
6556/11850 (epoch 27.662), train_loss = 0.94757930, grad/param norm = 2.9859e-01, time/batch = 0.6260s	
6557/11850 (epoch 27.667), train_loss = 1.15428381, grad/param norm = 2.5358e-01, time/batch = 0.6236s	
6558/11850 (epoch 27.671), train_loss = 1.04863830, grad/param norm = 2.6034e-01, time/batch = 0.6239s	
6559/11850 (epoch 27.675), train_loss = 1.02038168, grad/param norm = 2.4075e-01, time/batch = 0.6205s	
6560/11850 (epoch 27.679), train_loss = 1.07483385, grad/param norm = 2.8029e-01, time/batch = 0.6206s	
6561/11850 (epoch 27.684), train_loss = 1.05725409, grad/param norm = 2.6936e-01, time/batch = 0.6338s	
6562/11850 (epoch 27.688), train_loss = 1.00881859, grad/param norm = 2.5023e-01, time/batch = 0.6272s	
6563/11850 (epoch 27.692), train_loss = 1.02444637, grad/param norm = 2.9284e-01, time/batch = 0.6251s	
6564/11850 (epoch 27.696), train_loss = 0.98003631, grad/param norm = 2.8275e-01, time/batch = 0.6231s	
6565/11850 (epoch 27.700), train_loss = 1.07423025, grad/param norm = 2.5593e-01, time/batch = 0.6277s	
6566/11850 (epoch 27.705), train_loss = 1.02125100, grad/param norm = 2.4950e-01, time/batch = 0.6345s	
6567/11850 (epoch 27.709), train_loss = 0.91742488, grad/param norm = 2.3887e-01, time/batch = 0.6371s	
6568/11850 (epoch 27.713), train_loss = 0.95559437, grad/param norm = 2.7575e-01, time/batch = 0.6228s	
6569/11850 (epoch 27.717), train_loss = 1.00371985, grad/param norm = 2.6230e-01, time/batch = 0.6227s	
6570/11850 (epoch 27.722), train_loss = 1.06753585, grad/param norm = 2.8743e-01, time/batch = 0.6266s	
6571/11850 (epoch 27.726), train_loss = 0.95864288, grad/param norm = 2.8041e-01, time/batch = 0.6276s	
6572/11850 (epoch 27.730), train_loss = 0.96232699, grad/param norm = 2.3293e-01, time/batch = 0.6252s	
6573/11850 (epoch 27.734), train_loss = 1.00629963, grad/param norm = 2.4553e-01, time/batch = 0.6251s	
6574/11850 (epoch 27.738), train_loss = 1.13997630, grad/param norm = 2.9107e-01, time/batch = 0.6275s	
6575/11850 (epoch 27.743), train_loss = 1.05107640, grad/param norm = 2.5642e-01, time/batch = 0.6310s	
6576/11850 (epoch 27.747), train_loss = 0.93599447, grad/param norm = 2.3371e-01, time/batch = 0.6249s	
6577/11850 (epoch 27.751), train_loss = 0.97940022, grad/param norm = 2.3675e-01, time/batch = 0.6240s	
6578/11850 (epoch 27.755), train_loss = 1.05088810, grad/param norm = 2.3484e-01, time/batch = 0.6249s	
6579/11850 (epoch 27.759), train_loss = 0.99921808, grad/param norm = 2.5652e-01, time/batch = 0.6444s	
6580/11850 (epoch 27.764), train_loss = 1.00419774, grad/param norm = 2.5150e-01, time/batch = 0.6289s	
6581/11850 (epoch 27.768), train_loss = 0.93575770, grad/param norm = 2.5148e-01, time/batch = 0.6230s	
6582/11850 (epoch 27.772), train_loss = 1.03833618, grad/param norm = 3.4426e-01, time/batch = 0.6293s	
6583/11850 (epoch 27.776), train_loss = 1.06581949, grad/param norm = 2.5925e-01, time/batch = 0.6449s	
6584/11850 (epoch 27.781), train_loss = 1.03107193, grad/param norm = 2.6225e-01, time/batch = 0.6551s	
6585/11850 (epoch 27.785), train_loss = 1.01407247, grad/param norm = 2.7529e-01, time/batch = 0.6264s	
6586/11850 (epoch 27.789), train_loss = 1.03349243, grad/param norm = 2.4628e-01, time/batch = 0.6266s	
6587/11850 (epoch 27.793), train_loss = 1.12638342, grad/param norm = 3.0367e-01, time/batch = 0.6225s	
6588/11850 (epoch 27.797), train_loss = 1.05960864, grad/param norm = 2.5950e-01, time/batch = 0.6221s	
6589/11850 (epoch 27.802), train_loss = 0.94985167, grad/param norm = 2.5464e-01, time/batch = 0.6246s	
6590/11850 (epoch 27.806), train_loss = 1.03719995, grad/param norm = 2.5923e-01, time/batch = 0.6259s	
6591/11850 (epoch 27.810), train_loss = 1.13219766, grad/param norm = 2.7982e-01, time/batch = 0.6288s	
6592/11850 (epoch 27.814), train_loss = 1.02604640, grad/param norm = 2.4940e-01, time/batch = 0.6256s	
6593/11850 (epoch 27.819), train_loss = 1.17145937, grad/param norm = 2.9880e-01, time/batch = 0.6353s	
6594/11850 (epoch 27.823), train_loss = 1.19395942, grad/param norm = 2.8058e-01, time/batch = 0.6479s	
6595/11850 (epoch 27.827), train_loss = 1.05656094, grad/param norm = 2.9027e-01, time/batch = 0.6584s	
6596/11850 (epoch 27.831), train_loss = 1.04943678, grad/param norm = 2.5437e-01, time/batch = 0.6555s	
6597/11850 (epoch 27.835), train_loss = 1.06197445, grad/param norm = 3.0586e-01, time/batch = 0.6605s	
6598/11850 (epoch 27.840), train_loss = 1.03246181, grad/param norm = 2.6365e-01, time/batch = 0.6598s	
6599/11850 (epoch 27.844), train_loss = 1.04304259, grad/param norm = 2.2877e-01, time/batch = 0.6532s	
6600/11850 (epoch 27.848), train_loss = 1.06535319, grad/param norm = 2.8463e-01, time/batch = 0.6481s	
6601/11850 (epoch 27.852), train_loss = 1.04976563, grad/param norm = 2.5125e-01, time/batch = 0.6349s	
6602/11850 (epoch 27.857), train_loss = 1.06104422, grad/param norm = 3.2022e-01, time/batch = 0.6260s	
6603/11850 (epoch 27.861), train_loss = 1.02807446, grad/param norm = 2.8817e-01, time/batch = 0.6228s	
6604/11850 (epoch 27.865), train_loss = 1.12181598, grad/param norm = 3.0018e-01, time/batch = 0.6242s	
6605/11850 (epoch 27.869), train_loss = 1.09272916, grad/param norm = 2.7095e-01, time/batch = 0.6494s	
6606/11850 (epoch 27.873), train_loss = 1.11386229, grad/param norm = 2.6879e-01, time/batch = 0.6496s	
6607/11850 (epoch 27.878), train_loss = 1.10743123, grad/param norm = 2.6269e-01, time/batch = 0.6240s	
6608/11850 (epoch 27.882), train_loss = 1.06580173, grad/param norm = 3.0359e-01, time/batch = 0.6292s	
6609/11850 (epoch 27.886), train_loss = 1.07079161, grad/param norm = 3.1395e-01, time/batch = 0.6246s	
6610/11850 (epoch 27.890), train_loss = 1.08445378, grad/param norm = 3.2188e-01, time/batch = 0.6235s	
6611/11850 (epoch 27.895), train_loss = 1.11195995, grad/param norm = 3.1391e-01, time/batch = 0.6277s	
6612/11850 (epoch 27.899), train_loss = 0.96785766, grad/param norm = 2.7116e-01, time/batch = 0.6236s	
6613/11850 (epoch 27.903), train_loss = 1.01941598, grad/param norm = 2.4069e-01, time/batch = 0.6266s	
6614/11850 (epoch 27.907), train_loss = 1.03476015, grad/param norm = 3.0907e-01, time/batch = 0.6321s	
6615/11850 (epoch 27.911), train_loss = 1.15669719, grad/param norm = 2.6909e-01, time/batch = 0.6265s	
6616/11850 (epoch 27.916), train_loss = 1.11311857, grad/param norm = 2.9551e-01, time/batch = 0.6480s	
6617/11850 (epoch 27.920), train_loss = 1.07467219, grad/param norm = 2.7339e-01, time/batch = 0.6516s	
6618/11850 (epoch 27.924), train_loss = 1.05514406, grad/param norm = 3.0277e-01, time/batch = 0.6253s	
6619/11850 (epoch 27.928), train_loss = 1.12539187, grad/param norm = 2.9984e-01, time/batch = 0.6243s	
6620/11850 (epoch 27.932), train_loss = 1.16651148, grad/param norm = 2.6254e-01, time/batch = 0.6580s	
6621/11850 (epoch 27.937), train_loss = 1.11545424, grad/param norm = 2.4168e-01, time/batch = 0.6656s	
6622/11850 (epoch 27.941), train_loss = 1.11754518, grad/param norm = 2.6255e-01, time/batch = 0.6596s	
6623/11850 (epoch 27.945), train_loss = 1.13488003, grad/param norm = 2.7230e-01, time/batch = 0.6523s	
6624/11850 (epoch 27.949), train_loss = 1.03548418, grad/param norm = 3.1094e-01, time/batch = 0.6431s	
6625/11850 (epoch 27.954), train_loss = 1.13384871, grad/param norm = 3.0573e-01, time/batch = 0.6444s	
6626/11850 (epoch 27.958), train_loss = 1.11706797, grad/param norm = 2.7835e-01, time/batch = 0.6452s	
6627/11850 (epoch 27.962), train_loss = 1.00903727, grad/param norm = 2.6277e-01, time/batch = 0.6587s	
6628/11850 (epoch 27.966), train_loss = 0.97837927, grad/param norm = 2.7863e-01, time/batch = 0.6545s	
6629/11850 (epoch 27.970), train_loss = 1.10787807, grad/param norm = 2.8760e-01, time/batch = 0.6319s	
6630/11850 (epoch 27.975), train_loss = 1.05059301, grad/param norm = 2.7431e-01, time/batch = 0.6265s	
6631/11850 (epoch 27.979), train_loss = 1.06790782, grad/param norm = 2.8350e-01, time/batch = 0.6284s	
6632/11850 (epoch 27.983), train_loss = 1.17291461, grad/param norm = 3.2342e-01, time/batch = 0.6286s	
6633/11850 (epoch 27.987), train_loss = 1.03561585, grad/param norm = 3.0312e-01, time/batch = 0.6271s	
6634/11850 (epoch 27.992), train_loss = 1.20491312, grad/param norm = 2.8728e-01, time/batch = 0.6262s	
6635/11850 (epoch 27.996), train_loss = 1.21300120, grad/param norm = 2.7261e-01, time/batch = 0.6284s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
6636/11850 (epoch 28.000), train_loss = 1.10213856, grad/param norm = 3.8354e-01, time/batch = 0.6279s	
6637/11850 (epoch 28.004), train_loss = 1.12496286, grad/param norm = 3.0440e-01, time/batch = 0.6460s	
6638/11850 (epoch 28.008), train_loss = 1.18737659, grad/param norm = 2.9134e-01, time/batch = 0.6597s	
6639/11850 (epoch 28.013), train_loss = 1.17405188, grad/param norm = 2.6421e-01, time/batch = 0.6763s	
6640/11850 (epoch 28.017), train_loss = 1.22611313, grad/param norm = 2.7416e-01, time/batch = 0.6706s	
6641/11850 (epoch 28.021), train_loss = 1.13711583, grad/param norm = 2.5435e-01, time/batch = 0.6623s	
6642/11850 (epoch 28.025), train_loss = 1.02719149, grad/param norm = 2.5630e-01, time/batch = 0.6626s	
6643/11850 (epoch 28.030), train_loss = 1.05158303, grad/param norm = 3.0239e-01, time/batch = 0.6781s	
6644/11850 (epoch 28.034), train_loss = 1.04688825, grad/param norm = 2.6249e-01, time/batch = 0.6651s	
6645/11850 (epoch 28.038), train_loss = 1.07429621, grad/param norm = 2.5072e-01, time/batch = 0.6711s	
6646/11850 (epoch 28.042), train_loss = 1.10297681, grad/param norm = 2.6532e-01, time/batch = 0.6470s	
6647/11850 (epoch 28.046), train_loss = 1.07911978, grad/param norm = 2.8891e-01, time/batch = 0.6459s	
6648/11850 (epoch 28.051), train_loss = 1.08902635, grad/param norm = 2.6991e-01, time/batch = 0.6446s	
6649/11850 (epoch 28.055), train_loss = 1.05536903, grad/param norm = 2.6719e-01, time/batch = 0.6451s	
6650/11850 (epoch 28.059), train_loss = 1.15862277, grad/param norm = 2.6784e-01, time/batch = 0.6430s	
6651/11850 (epoch 28.063), train_loss = 1.12440310, grad/param norm = 2.6642e-01, time/batch = 0.6464s	
6652/11850 (epoch 28.068), train_loss = 1.06670818, grad/param norm = 2.3143e-01, time/batch = 0.6446s	
6653/11850 (epoch 28.072), train_loss = 1.11716826, grad/param norm = 2.5698e-01, time/batch = 0.6451s	
6654/11850 (epoch 28.076), train_loss = 1.20657904, grad/param norm = 2.8758e-01, time/batch = 0.6451s	
6655/11850 (epoch 28.080), train_loss = 1.03463633, grad/param norm = 2.7182e-01, time/batch = 0.6427s	
6656/11850 (epoch 28.084), train_loss = 0.95485955, grad/param norm = 2.3345e-01, time/batch = 0.6433s	
6657/11850 (epoch 28.089), train_loss = 0.96350437, grad/param norm = 2.5713e-01, time/batch = 0.6458s	
6658/11850 (epoch 28.093), train_loss = 0.97424438, grad/param norm = 3.0441e-01, time/batch = 0.6469s	
6659/11850 (epoch 28.097), train_loss = 1.09417582, grad/param norm = 2.8740e-01, time/batch = 0.6630s	
6660/11850 (epoch 28.101), train_loss = 1.02252851, grad/param norm = 3.0265e-01, time/batch = 0.6703s	
6661/11850 (epoch 28.105), train_loss = 0.97716617, grad/param norm = 2.3787e-01, time/batch = 0.6414s	
6662/11850 (epoch 28.110), train_loss = 1.12387705, grad/param norm = 2.5706e-01, time/batch = 0.6392s	
6663/11850 (epoch 28.114), train_loss = 1.05485443, grad/param norm = 2.9733e-01, time/batch = 0.6392s	
6664/11850 (epoch 28.118), train_loss = 1.12001776, grad/param norm = 2.3752e-01, time/batch = 0.6409s	
6665/11850 (epoch 28.122), train_loss = 1.16489538, grad/param norm = 2.5405e-01, time/batch = 0.6394s	
6666/11850 (epoch 28.127), train_loss = 1.09943690, grad/param norm = 2.6030e-01, time/batch = 0.6433s	
6667/11850 (epoch 28.131), train_loss = 1.07976299, grad/param norm = 3.1019e-01, time/batch = 0.6425s	
6668/11850 (epoch 28.135), train_loss = 1.05828596, grad/param norm = 3.0386e-01, time/batch = 0.6463s	
6669/11850 (epoch 28.139), train_loss = 1.06050043, grad/param norm = 2.9420e-01, time/batch = 0.6407s	
6670/11850 (epoch 28.143), train_loss = 1.06332962, grad/param norm = 2.7154e-01, time/batch = 0.6728s	
6671/11850 (epoch 28.148), train_loss = 1.05121024, grad/param norm = 2.7060e-01, time/batch = 0.6659s	
6672/11850 (epoch 28.152), train_loss = 1.16229072, grad/param norm = 3.1925e-01, time/batch = 0.6428s	
6673/11850 (epoch 28.156), train_loss = 1.08097133, grad/param norm = 3.7903e-01, time/batch = 0.6387s	
6674/11850 (epoch 28.160), train_loss = 1.28612923, grad/param norm = 3.8963e-01, time/batch = 0.6432s	
6675/11850 (epoch 28.165), train_loss = 1.21535859, grad/param norm = 3.5263e-01, time/batch = 0.6487s	
6676/11850 (epoch 28.169), train_loss = 1.05759222, grad/param norm = 3.2563e-01, time/batch = 0.6411s	
6677/11850 (epoch 28.173), train_loss = 1.12552222, grad/param norm = 3.1087e-01, time/batch = 0.6415s	
6678/11850 (epoch 28.177), train_loss = 1.00462714, grad/param norm = 3.3418e-01, time/batch = 0.6456s	
6679/11850 (epoch 28.181), train_loss = 1.14066275, grad/param norm = 2.6434e-01, time/batch = 0.6437s	
6680/11850 (epoch 28.186), train_loss = 1.21708658, grad/param norm = 4.0364e-01, time/batch = 0.6415s	
6681/11850 (epoch 28.190), train_loss = 1.10385324, grad/param norm = 2.5953e-01, time/batch = 0.6458s	
6682/11850 (epoch 28.194), train_loss = 1.16049569, grad/param norm = 3.4147e-01, time/batch = 0.6426s	
6683/11850 (epoch 28.198), train_loss = 0.92604531, grad/param norm = 2.7782e-01, time/batch = 0.6448s	
6684/11850 (epoch 28.203), train_loss = 0.95034452, grad/param norm = 2.5115e-01, time/batch = 0.6422s	
6685/11850 (epoch 28.207), train_loss = 1.13426616, grad/param norm = 2.9188e-01, time/batch = 0.6454s	
6686/11850 (epoch 28.211), train_loss = 1.08078303, grad/param norm = 2.6359e-01, time/batch = 0.6441s	
6687/11850 (epoch 28.215), train_loss = 1.07019306, grad/param norm = 2.7879e-01, time/batch = 0.6423s	
6688/11850 (epoch 28.219), train_loss = 1.11667168, grad/param norm = 2.7821e-01, time/batch = 0.6438s	
6689/11850 (epoch 28.224), train_loss = 1.23869232, grad/param norm = 2.9557e-01, time/batch = 0.6490s	
6690/11850 (epoch 28.228), train_loss = 1.13637172, grad/param norm = 2.8111e-01, time/batch = 0.6397s	
6691/11850 (epoch 28.232), train_loss = 1.11144347, grad/param norm = 2.6332e-01, time/batch = 0.6464s	
6692/11850 (epoch 28.236), train_loss = 0.99736053, grad/param norm = 2.7837e-01, time/batch = 0.6407s	
6693/11850 (epoch 28.241), train_loss = 1.16058544, grad/param norm = 3.3072e-01, time/batch = 0.6407s	
6694/11850 (epoch 28.245), train_loss = 1.15118849, grad/param norm = 2.4762e-01, time/batch = 0.6398s	
6695/11850 (epoch 28.249), train_loss = 1.03597110, grad/param norm = 2.4699e-01, time/batch = 0.6432s	
6696/11850 (epoch 28.253), train_loss = 1.08145795, grad/param norm = 2.8784e-01, time/batch = 0.6435s	
6697/11850 (epoch 28.257), train_loss = 1.21519917, grad/param norm = 3.0143e-01, time/batch = 0.6558s	
6698/11850 (epoch 28.262), train_loss = 1.23032879, grad/param norm = 3.0854e-01, time/batch = 0.6434s	
6699/11850 (epoch 28.266), train_loss = 1.18725030, grad/param norm = 3.0939e-01, time/batch = 0.6425s	
6700/11850 (epoch 28.270), train_loss = 1.07616656, grad/param norm = 2.4451e-01, time/batch = 0.6459s	
6701/11850 (epoch 28.274), train_loss = 1.07621341, grad/param norm = 2.8230e-01, time/batch = 0.6454s	
6702/11850 (epoch 28.278), train_loss = 0.93256092, grad/param norm = 2.5161e-01, time/batch = 0.6446s	
6703/11850 (epoch 28.283), train_loss = 1.05487380, grad/param norm = 2.5149e-01, time/batch = 0.6464s	
6704/11850 (epoch 28.287), train_loss = 1.18998112, grad/param norm = 2.5712e-01, time/batch = 0.6448s	
6705/11850 (epoch 28.291), train_loss = 1.05703040, grad/param norm = 2.5774e-01, time/batch = 0.6451s	
6706/11850 (epoch 28.295), train_loss = 1.13874125, grad/param norm = 2.6943e-01, time/batch = 0.6448s	
6707/11850 (epoch 28.300), train_loss = 1.04679828, grad/param norm = 3.0208e-01, time/batch = 0.6525s	
6708/11850 (epoch 28.304), train_loss = 1.07064375, grad/param norm = 2.3823e-01, time/batch = 0.6418s	
6709/11850 (epoch 28.308), train_loss = 1.04189983, grad/param norm = 2.3370e-01, time/batch = 0.6404s	
6710/11850 (epoch 28.312), train_loss = 0.96774328, grad/param norm = 2.3474e-01, time/batch = 0.6438s	
6711/11850 (epoch 28.316), train_loss = 1.12029156, grad/param norm = 2.6224e-01, time/batch = 0.6432s	
6712/11850 (epoch 28.321), train_loss = 1.05717323, grad/param norm = 2.5765e-01, time/batch = 0.6492s	
6713/11850 (epoch 28.325), train_loss = 1.06624458, grad/param norm = 2.3955e-01, time/batch = 0.6707s	
6714/11850 (epoch 28.329), train_loss = 1.07864043, grad/param norm = 2.7713e-01, time/batch = 0.6749s	
6715/11850 (epoch 28.333), train_loss = 1.05532893, grad/param norm = 2.7007e-01, time/batch = 0.6574s	
6716/11850 (epoch 28.338), train_loss = 1.00952423, grad/param norm = 2.3947e-01, time/batch = 0.6563s	
6717/11850 (epoch 28.342), train_loss = 1.08985179, grad/param norm = 2.9109e-01, time/batch = 0.6489s	
6718/11850 (epoch 28.346), train_loss = 1.06053218, grad/param norm = 2.5616e-01, time/batch = 0.6639s	
6719/11850 (epoch 28.350), train_loss = 0.95118240, grad/param norm = 2.4526e-01, time/batch = 0.6620s	
6720/11850 (epoch 28.354), train_loss = 1.16547647, grad/param norm = 2.8112e-01, time/batch = 0.6482s	
6721/11850 (epoch 28.359), train_loss = 1.18491001, grad/param norm = 2.5807e-01, time/batch = 0.6541s	
6722/11850 (epoch 28.363), train_loss = 1.11634162, grad/param norm = 2.5716e-01, time/batch = 0.6460s	
6723/11850 (epoch 28.367), train_loss = 1.13748604, grad/param norm = 2.5498e-01, time/batch = 0.6417s	
6724/11850 (epoch 28.371), train_loss = 1.12255523, grad/param norm = 2.4140e-01, time/batch = 0.6399s	
6725/11850 (epoch 28.376), train_loss = 1.05692190, grad/param norm = 2.4689e-01, time/batch = 0.6415s	
6726/11850 (epoch 28.380), train_loss = 1.04043059, grad/param norm = 2.4020e-01, time/batch = 0.6451s	
6727/11850 (epoch 28.384), train_loss = 0.98819930, grad/param norm = 2.6133e-01, time/batch = 0.6456s	
6728/11850 (epoch 28.388), train_loss = 1.15291142, grad/param norm = 2.5750e-01, time/batch = 0.6463s	
6729/11850 (epoch 28.392), train_loss = 1.13058913, grad/param norm = 2.6137e-01, time/batch = 0.6500s	
6730/11850 (epoch 28.397), train_loss = 1.15513760, grad/param norm = 2.8928e-01, time/batch = 0.6452s	
6731/11850 (epoch 28.401), train_loss = 0.96501282, grad/param norm = 2.4240e-01, time/batch = 0.6490s	
6732/11850 (epoch 28.405), train_loss = 1.01121583, grad/param norm = 2.8047e-01, time/batch = 0.6444s	
6733/11850 (epoch 28.409), train_loss = 1.15547229, grad/param norm = 2.8100e-01, time/batch = 0.6528s	
6734/11850 (epoch 28.414), train_loss = 0.93030910, grad/param norm = 2.3324e-01, time/batch = 0.6573s	
6735/11850 (epoch 28.418), train_loss = 0.97595692, grad/param norm = 2.5473e-01, time/batch = 0.6599s	
6736/11850 (epoch 28.422), train_loss = 0.90042314, grad/param norm = 2.4839e-01, time/batch = 0.6533s	
6737/11850 (epoch 28.426), train_loss = 0.91011206, grad/param norm = 2.5468e-01, time/batch = 0.6616s	
6738/11850 (epoch 28.430), train_loss = 0.99002628, grad/param norm = 3.1033e-01, time/batch = 0.6673s	
6739/11850 (epoch 28.435), train_loss = 1.00896039, grad/param norm = 2.7806e-01, time/batch = 0.6715s	
6740/11850 (epoch 28.439), train_loss = 1.11165249, grad/param norm = 2.3918e-01, time/batch = 0.6680s	
6741/11850 (epoch 28.443), train_loss = 1.05635588, grad/param norm = 2.5220e-01, time/batch = 0.6590s	
6742/11850 (epoch 28.447), train_loss = 0.95186067, grad/param norm = 2.4099e-01, time/batch = 0.6621s	
6743/11850 (epoch 28.451), train_loss = 0.98189757, grad/param norm = 2.9923e-01, time/batch = 0.6565s	
6744/11850 (epoch 28.456), train_loss = 1.05499420, grad/param norm = 2.7340e-01, time/batch = 0.6651s	
6745/11850 (epoch 28.460), train_loss = 1.12253253, grad/param norm = 2.6864e-01, time/batch = 0.6552s	
6746/11850 (epoch 28.464), train_loss = 1.00342344, grad/param norm = 2.8221e-01, time/batch = 0.6563s	
6747/11850 (epoch 28.468), train_loss = 1.08494726, grad/param norm = 2.5882e-01, time/batch = 0.6538s	
6748/11850 (epoch 28.473), train_loss = 1.11627588, grad/param norm = 2.5292e-01, time/batch = 0.6562s	
6749/11850 (epoch 28.477), train_loss = 0.98951264, grad/param norm = 2.8272e-01, time/batch = 0.6565s	
6750/11850 (epoch 28.481), train_loss = 0.99972068, grad/param norm = 2.7666e-01, time/batch = 0.6481s	
6751/11850 (epoch 28.485), train_loss = 0.95719377, grad/param norm = 2.3326e-01, time/batch = 0.6443s	
6752/11850 (epoch 28.489), train_loss = 1.09240117, grad/param norm = 2.5063e-01, time/batch = 0.6505s	
6753/11850 (epoch 28.494), train_loss = 0.97265185, grad/param norm = 2.9369e-01, time/batch = 0.6449s	
6754/11850 (epoch 28.498), train_loss = 0.95640053, grad/param norm = 2.8760e-01, time/batch = 0.6427s	
6755/11850 (epoch 28.502), train_loss = 0.94562422, grad/param norm = 2.7088e-01, time/batch = 0.6411s	
6756/11850 (epoch 28.506), train_loss = 1.21121474, grad/param norm = 2.7600e-01, time/batch = 0.6413s	
6757/11850 (epoch 28.511), train_loss = 1.05706875, grad/param norm = 2.4218e-01, time/batch = 0.6394s	
6758/11850 (epoch 28.515), train_loss = 1.17455015, grad/param norm = 2.8487e-01, time/batch = 0.6424s	
6759/11850 (epoch 28.519), train_loss = 1.01065205, grad/param norm = 2.4917e-01, time/batch = 0.6449s	
6760/11850 (epoch 28.523), train_loss = 1.04686036, grad/param norm = 2.4981e-01, time/batch = 0.6459s	
6761/11850 (epoch 28.527), train_loss = 0.98773620, grad/param norm = 2.6688e-01, time/batch = 0.6449s	
6762/11850 (epoch 28.532), train_loss = 1.10228896, grad/param norm = 2.6009e-01, time/batch = 0.6438s	
6763/11850 (epoch 28.536), train_loss = 1.01861114, grad/param norm = 2.5896e-01, time/batch = 0.6382s	
6764/11850 (epoch 28.540), train_loss = 0.98350190, grad/param norm = 2.3602e-01, time/batch = 0.6434s	
6765/11850 (epoch 28.544), train_loss = 0.96879897, grad/param norm = 2.6488e-01, time/batch = 0.6544s	
6766/11850 (epoch 28.549), train_loss = 0.91520250, grad/param norm = 2.3195e-01, time/batch = 0.6556s	
6767/11850 (epoch 28.553), train_loss = 1.07622415, grad/param norm = 2.8793e-01, time/batch = 0.6546s	
6768/11850 (epoch 28.557), train_loss = 1.08724054, grad/param norm = 2.9434e-01, time/batch = 0.6516s	
6769/11850 (epoch 28.561), train_loss = 1.08670709, grad/param norm = 2.9957e-01, time/batch = 0.6428s	
6770/11850 (epoch 28.565), train_loss = 1.19237571, grad/param norm = 2.7566e-01, time/batch = 0.6479s	
6771/11850 (epoch 28.570), train_loss = 1.05742321, grad/param norm = 2.4065e-01, time/batch = 0.6711s	
6772/11850 (epoch 28.574), train_loss = 1.10286938, grad/param norm = 2.7978e-01, time/batch = 0.6673s	
6773/11850 (epoch 28.578), train_loss = 1.14154211, grad/param norm = 2.8371e-01, time/batch = 0.6431s	
6774/11850 (epoch 28.582), train_loss = 1.02219842, grad/param norm = 3.2269e-01, time/batch = 0.6439s	
6775/11850 (epoch 28.586), train_loss = 1.02912981, grad/param norm = 2.8733e-01, time/batch = 0.6456s	
6776/11850 (epoch 28.591), train_loss = 1.09162734, grad/param norm = 2.8403e-01, time/batch = 0.6408s	
6777/11850 (epoch 28.595), train_loss = 0.92862862, grad/param norm = 2.5582e-01, time/batch = 0.6455s	
6778/11850 (epoch 28.599), train_loss = 1.06063591, grad/param norm = 2.7317e-01, time/batch = 0.6424s	
6779/11850 (epoch 28.603), train_loss = 1.00203077, grad/param norm = 2.4961e-01, time/batch = 0.6422s	
6780/11850 (epoch 28.608), train_loss = 1.18983609, grad/param norm = 2.8336e-01, time/batch = 0.6420s	
6781/11850 (epoch 28.612), train_loss = 1.24199853, grad/param norm = 2.9590e-01, time/batch = 0.6467s	
6782/11850 (epoch 28.616), train_loss = 1.17797118, grad/param norm = 2.7119e-01, time/batch = 0.6726s	
6783/11850 (epoch 28.620), train_loss = 1.04958865, grad/param norm = 2.4244e-01, time/batch = 0.6595s	
6784/11850 (epoch 28.624), train_loss = 1.06949668, grad/param norm = 2.9353e-01, time/batch = 0.6427s	
6785/11850 (epoch 28.629), train_loss = 0.99720649, grad/param norm = 2.6142e-01, time/batch = 0.6413s	
6786/11850 (epoch 28.633), train_loss = 0.93312773, grad/param norm = 2.5681e-01, time/batch = 0.6408s	
6787/11850 (epoch 28.637), train_loss = 0.90816870, grad/param norm = 2.9238e-01, time/batch = 0.6435s	
6788/11850 (epoch 28.641), train_loss = 0.94381037, grad/param norm = 2.3292e-01, time/batch = 0.6398s	
6789/11850 (epoch 28.646), train_loss = 0.97588759, grad/param norm = 2.5620e-01, time/batch = 0.6429s	
6790/11850 (epoch 28.650), train_loss = 1.05318885, grad/param norm = 2.9904e-01, time/batch = 0.6693s	
6791/11850 (epoch 28.654), train_loss = 0.98599238, grad/param norm = 2.8950e-01, time/batch = 0.6428s	
6792/11850 (epoch 28.658), train_loss = 1.07376591, grad/param norm = 2.4104e-01, time/batch = 0.6318s	
6793/11850 (epoch 28.662), train_loss = 0.92552387, grad/param norm = 2.7629e-01, time/batch = 0.6270s	
6794/11850 (epoch 28.667), train_loss = 1.14835977, grad/param norm = 2.7022e-01, time/batch = 0.6259s	
6795/11850 (epoch 28.671), train_loss = 1.03684610, grad/param norm = 2.7541e-01, time/batch = 0.6281s	
6796/11850 (epoch 28.675), train_loss = 1.00317341, grad/param norm = 2.3695e-01, time/batch = 0.6232s	
6797/11850 (epoch 28.679), train_loss = 1.04827841, grad/param norm = 2.6284e-01, time/batch = 0.6268s	
6798/11850 (epoch 28.684), train_loss = 1.01891711, grad/param norm = 2.6884e-01, time/batch = 0.6273s	
6799/11850 (epoch 28.688), train_loss = 0.99249806, grad/param norm = 2.6124e-01, time/batch = 0.6249s	
6800/11850 (epoch 28.692), train_loss = 0.99396545, grad/param norm = 2.7338e-01, time/batch = 0.6344s	
6801/11850 (epoch 28.696), train_loss = 0.95314147, grad/param norm = 2.7725e-01, time/batch = 0.6269s	
6802/11850 (epoch 28.700), train_loss = 1.05659037, grad/param norm = 2.7452e-01, time/batch = 0.6295s	
6803/11850 (epoch 28.705), train_loss = 1.00192223, grad/param norm = 2.9036e-01, time/batch = 0.6285s	
6804/11850 (epoch 28.709), train_loss = 0.89786289, grad/param norm = 2.3472e-01, time/batch = 0.6585s	
6805/11850 (epoch 28.713), train_loss = 0.93569074, grad/param norm = 2.8166e-01, time/batch = 0.6561s	
6806/11850 (epoch 28.717), train_loss = 0.99844746, grad/param norm = 2.8201e-01, time/batch = 0.6606s	
6807/11850 (epoch 28.722), train_loss = 1.04962890, grad/param norm = 2.7969e-01, time/batch = 0.6571s	
6808/11850 (epoch 28.726), train_loss = 0.93431179, grad/param norm = 2.7803e-01, time/batch = 0.6490s	
6809/11850 (epoch 28.730), train_loss = 0.95640221, grad/param norm = 3.0382e-01, time/batch = 0.6462s	
6810/11850 (epoch 28.734), train_loss = 0.98712564, grad/param norm = 2.6149e-01, time/batch = 0.6423s	
6811/11850 (epoch 28.738), train_loss = 1.10768126, grad/param norm = 2.9391e-01, time/batch = 0.6525s	
6812/11850 (epoch 28.743), train_loss = 1.03889936, grad/param norm = 2.7067e-01, time/batch = 0.6436s	
6813/11850 (epoch 28.747), train_loss = 0.91562319, grad/param norm = 2.1854e-01, time/batch = 0.6384s	
6814/11850 (epoch 28.751), train_loss = 0.96706710, grad/param norm = 2.3804e-01, time/batch = 0.6521s	
6815/11850 (epoch 28.755), train_loss = 1.03766576, grad/param norm = 2.5443e-01, time/batch = 0.6475s	
6816/11850 (epoch 28.759), train_loss = 0.97622708, grad/param norm = 2.5290e-01, time/batch = 0.6475s	
6817/11850 (epoch 28.764), train_loss = 0.98616878, grad/param norm = 2.4376e-01, time/batch = 0.6466s	
6818/11850 (epoch 28.768), train_loss = 0.91725034, grad/param norm = 2.4397e-01, time/batch = 0.6453s	
6819/11850 (epoch 28.772), train_loss = 0.99435004, grad/param norm = 2.8803e-01, time/batch = 0.6463s	
6820/11850 (epoch 28.776), train_loss = 1.05540418, grad/param norm = 2.5925e-01, time/batch = 0.6499s	
6821/11850 (epoch 28.781), train_loss = 1.00663408, grad/param norm = 2.6627e-01, time/batch = 0.6503s	
6822/11850 (epoch 28.785), train_loss = 0.98701594, grad/param norm = 2.7414e-01, time/batch = 0.6460s	
6823/11850 (epoch 28.789), train_loss = 1.00858385, grad/param norm = 2.5636e-01, time/batch = 0.6465s	
6824/11850 (epoch 28.793), train_loss = 1.09898449, grad/param norm = 3.0642e-01, time/batch = 0.6480s	
6825/11850 (epoch 28.797), train_loss = 1.03509552, grad/param norm = 2.6582e-01, time/batch = 0.6435s	
6826/11850 (epoch 28.802), train_loss = 0.94198467, grad/param norm = 2.7134e-01, time/batch = 0.6443s	
6827/11850 (epoch 28.806), train_loss = 1.01969550, grad/param norm = 2.6368e-01, time/batch = 0.6422s	
6828/11850 (epoch 28.810), train_loss = 1.09268365, grad/param norm = 2.5588e-01, time/batch = 0.6457s	
6829/11850 (epoch 28.814), train_loss = 1.02302997, grad/param norm = 2.6973e-01, time/batch = 0.6442s	
6830/11850 (epoch 28.819), train_loss = 1.14836965, grad/param norm = 2.7058e-01, time/batch = 0.6443s	
6831/11850 (epoch 28.823), train_loss = 1.15700170, grad/param norm = 2.7675e-01, time/batch = 0.6460s	
6832/11850 (epoch 28.827), train_loss = 1.04287431, grad/param norm = 2.7949e-01, time/batch = 0.6422s	
6833/11850 (epoch 28.831), train_loss = 1.02635733, grad/param norm = 2.8469e-01, time/batch = 0.6451s	
6834/11850 (epoch 28.835), train_loss = 1.05679802, grad/param norm = 2.6406e-01, time/batch = 0.6463s	
6835/11850 (epoch 28.840), train_loss = 0.99807467, grad/param norm = 2.7532e-01, time/batch = 0.6403s	
6836/11850 (epoch 28.844), train_loss = 1.01588839, grad/param norm = 2.2171e-01, time/batch = 0.6405s	
6837/11850 (epoch 28.848), train_loss = 1.04066820, grad/param norm = 2.6797e-01, time/batch = 0.6427s	
6838/11850 (epoch 28.852), train_loss = 1.03287786, grad/param norm = 3.1347e-01, time/batch = 0.6381s	
6839/11850 (epoch 28.857), train_loss = 1.02831327, grad/param norm = 3.1920e-01, time/batch = 0.6435s	
6840/11850 (epoch 28.861), train_loss = 1.00331120, grad/param norm = 2.9214e-01, time/batch = 0.6386s	
6841/11850 (epoch 28.865), train_loss = 1.08728303, grad/param norm = 2.9432e-01, time/batch = 0.6432s	
6842/11850 (epoch 28.869), train_loss = 1.07511304, grad/param norm = 2.9873e-01, time/batch = 0.6426s	
6843/11850 (epoch 28.873), train_loss = 1.08166077, grad/param norm = 2.5658e-01, time/batch = 0.6376s	
6844/11850 (epoch 28.878), train_loss = 1.08863798, grad/param norm = 2.7585e-01, time/batch = 0.6362s	
6845/11850 (epoch 28.882), train_loss = 1.04210082, grad/param norm = 2.7617e-01, time/batch = 0.6400s	
6846/11850 (epoch 28.886), train_loss = 1.04150633, grad/param norm = 2.9139e-01, time/batch = 0.6421s	
6847/11850 (epoch 28.890), train_loss = 1.06813257, grad/param norm = 3.3988e-01, time/batch = 0.6446s	
6848/11850 (epoch 28.895), train_loss = 1.11358904, grad/param norm = 3.4076e-01, time/batch = 0.6349s	
6849/11850 (epoch 28.899), train_loss = 0.94633257, grad/param norm = 2.5815e-01, time/batch = 0.6380s	
6850/11850 (epoch 28.903), train_loss = 1.00773314, grad/param norm = 2.8578e-01, time/batch = 0.6398s	
6851/11850 (epoch 28.907), train_loss = 0.99795693, grad/param norm = 2.8452e-01, time/batch = 0.6649s	
6852/11850 (epoch 28.911), train_loss = 1.13095898, grad/param norm = 2.9062e-01, time/batch = 0.6729s	
6853/11850 (epoch 28.916), train_loss = 1.09557438, grad/param norm = 3.0415e-01, time/batch = 0.6487s	
6854/11850 (epoch 28.920), train_loss = 1.07707379, grad/param norm = 2.9792e-01, time/batch = 0.6422s	
6855/11850 (epoch 28.924), train_loss = 1.01474874, grad/param norm = 2.8681e-01, time/batch = 0.6428s	
6856/11850 (epoch 28.928), train_loss = 1.11667455, grad/param norm = 3.3739e-01, time/batch = 0.6385s	
6857/11850 (epoch 28.932), train_loss = 1.14754029, grad/param norm = 2.6858e-01, time/batch = 0.6397s	
6858/11850 (epoch 28.937), train_loss = 1.10146654, grad/param norm = 2.4216e-01, time/batch = 0.6435s	
6859/11850 (epoch 28.941), train_loss = 1.09420635, grad/param norm = 2.6628e-01, time/batch = 0.6394s	
6860/11850 (epoch 28.945), train_loss = 1.11260690, grad/param norm = 2.4972e-01, time/batch = 0.6384s	
6861/11850 (epoch 28.949), train_loss = 1.02356415, grad/param norm = 3.5069e-01, time/batch = 0.6397s	
6862/11850 (epoch 28.954), train_loss = 1.10167835, grad/param norm = 2.9886e-01, time/batch = 0.6408s	
6863/11850 (epoch 28.958), train_loss = 1.09664271, grad/param norm = 2.6349e-01, time/batch = 0.6381s	
6864/11850 (epoch 28.962), train_loss = 0.99364089, grad/param norm = 2.7215e-01, time/batch = 0.6375s	
6865/11850 (epoch 28.966), train_loss = 0.94839543, grad/param norm = 2.5701e-01, time/batch = 0.6368s	
6866/11850 (epoch 28.970), train_loss = 1.07876988, grad/param norm = 2.8618e-01, time/batch = 0.6391s	
6867/11850 (epoch 28.975), train_loss = 1.02691050, grad/param norm = 2.9161e-01, time/batch = 0.6362s	
6868/11850 (epoch 28.979), train_loss = 1.06650800, grad/param norm = 3.5187e-01, time/batch = 0.6409s	
6869/11850 (epoch 28.983), train_loss = 1.16969774, grad/param norm = 3.4140e-01, time/batch = 0.6376s	
6870/11850 (epoch 28.987), train_loss = 1.00921816, grad/param norm = 2.8977e-01, time/batch = 0.6401s	
6871/11850 (epoch 28.992), train_loss = 1.18802748, grad/param norm = 2.9813e-01, time/batch = 0.6520s	
6872/11850 (epoch 28.996), train_loss = 1.18947159, grad/param norm = 2.7874e-01, time/batch = 0.6388s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
6873/11850 (epoch 29.000), train_loss = 1.06420831, grad/param norm = 3.1439e-01, time/batch = 0.6390s	
6874/11850 (epoch 29.004), train_loss = 1.09563386, grad/param norm = 2.9259e-01, time/batch = 0.6420s	
6875/11850 (epoch 29.008), train_loss = 1.15079952, grad/param norm = 2.9707e-01, time/batch = 0.6386s	
6876/11850 (epoch 29.013), train_loss = 1.15820650, grad/param norm = 2.9067e-01, time/batch = 0.6430s	
6877/11850 (epoch 29.017), train_loss = 1.20288719, grad/param norm = 2.8750e-01, time/batch = 0.6386s	
6878/11850 (epoch 29.021), train_loss = 1.11524657, grad/param norm = 2.4825e-01, time/batch = 0.6380s	
6879/11850 (epoch 29.025), train_loss = 1.00076677, grad/param norm = 2.4715e-01, time/batch = 0.6419s	
6880/11850 (epoch 29.030), train_loss = 1.01822216, grad/param norm = 2.7353e-01, time/batch = 0.6402s	
6881/11850 (epoch 29.034), train_loss = 1.02395583, grad/param norm = 2.6866e-01, time/batch = 0.6432s	
6882/11850 (epoch 29.038), train_loss = 1.05120998, grad/param norm = 2.5791e-01, time/batch = 0.6408s	
6883/11850 (epoch 29.042), train_loss = 1.08206255, grad/param norm = 2.9273e-01, time/batch = 0.6386s	
6884/11850 (epoch 29.046), train_loss = 1.04774800, grad/param norm = 2.8706e-01, time/batch = 0.6421s	
6885/11850 (epoch 29.051), train_loss = 1.06524833, grad/param norm = 2.5742e-01, time/batch = 0.6432s	
6886/11850 (epoch 29.055), train_loss = 1.02754467, grad/param norm = 2.5905e-01, time/batch = 0.6395s	
6887/11850 (epoch 29.059), train_loss = 1.13653055, grad/param norm = 2.7989e-01, time/batch = 0.6375s	
6888/11850 (epoch 29.063), train_loss = 1.11153202, grad/param norm = 2.6560e-01, time/batch = 0.6406s	
6889/11850 (epoch 29.068), train_loss = 1.05289897, grad/param norm = 2.4763e-01, time/batch = 0.6484s	
6890/11850 (epoch 29.072), train_loss = 1.09946973, grad/param norm = 2.5346e-01, time/batch = 0.6391s	
6891/11850 (epoch 29.076), train_loss = 1.18390597, grad/param norm = 2.5564e-01, time/batch = 0.6420s	
6892/11850 (epoch 29.080), train_loss = 1.00683462, grad/param norm = 2.5683e-01, time/batch = 0.6396s	
6893/11850 (epoch 29.084), train_loss = 0.94497098, grad/param norm = 2.6034e-01, time/batch = 0.6504s	
6894/11850 (epoch 29.089), train_loss = 0.96051822, grad/param norm = 2.5976e-01, time/batch = 0.6418s	
6895/11850 (epoch 29.093), train_loss = 0.96714048, grad/param norm = 3.2024e-01, time/batch = 0.6409s	
6896/11850 (epoch 29.097), train_loss = 1.06400851, grad/param norm = 2.5975e-01, time/batch = 0.6389s	
6897/11850 (epoch 29.101), train_loss = 1.00966117, grad/param norm = 3.7428e-01, time/batch = 0.6527s	
6898/11850 (epoch 29.105), train_loss = 0.96565353, grad/param norm = 2.5554e-01, time/batch = 0.6663s	
6899/11850 (epoch 29.110), train_loss = 1.10048421, grad/param norm = 2.5464e-01, time/batch = 0.6706s	
6900/11850 (epoch 29.114), train_loss = 1.02911126, grad/param norm = 2.7246e-01, time/batch = 0.6698s	
6901/11850 (epoch 29.118), train_loss = 1.10649133, grad/param norm = 2.6894e-01, time/batch = 0.6513s	
6902/11850 (epoch 29.122), train_loss = 1.14799745, grad/param norm = 2.6867e-01, time/batch = 0.6406s	
6903/11850 (epoch 29.127), train_loss = 1.09369690, grad/param norm = 2.7749e-01, time/batch = 0.6374s	
6904/11850 (epoch 29.131), train_loss = 1.05301096, grad/param norm = 3.3296e-01, time/batch = 0.6428s	
6905/11850 (epoch 29.135), train_loss = 1.02495736, grad/param norm = 2.7397e-01, time/batch = 0.6476s	
6906/11850 (epoch 29.139), train_loss = 1.06306518, grad/param norm = 2.9612e-01, time/batch = 0.6386s	
6907/11850 (epoch 29.143), train_loss = 1.04527219, grad/param norm = 2.7761e-01, time/batch = 0.6430s	
6908/11850 (epoch 29.148), train_loss = 1.02401890, grad/param norm = 2.7675e-01, time/batch = 0.6411s	
6909/11850 (epoch 29.152), train_loss = 1.14461624, grad/param norm = 3.2022e-01, time/batch = 0.6414s	
6910/11850 (epoch 29.156), train_loss = 1.04061977, grad/param norm = 3.5232e-01, time/batch = 0.6620s	
6911/11850 (epoch 29.160), train_loss = 1.24632872, grad/param norm = 3.2183e-01, time/batch = 0.6794s	
6912/11850 (epoch 29.165), train_loss = 1.20312620, grad/param norm = 3.5219e-01, time/batch = 0.6402s	
6913/11850 (epoch 29.169), train_loss = 1.03623391, grad/param norm = 2.9103e-01, time/batch = 0.6444s	
6914/11850 (epoch 29.173), train_loss = 1.12103188, grad/param norm = 3.1545e-01, time/batch = 0.6408s	
6915/11850 (epoch 29.177), train_loss = 0.98552264, grad/param norm = 2.9490e-01, time/batch = 0.6429s	
6916/11850 (epoch 29.181), train_loss = 1.13509295, grad/param norm = 3.0171e-01, time/batch = 0.6479s	
6917/11850 (epoch 29.186), train_loss = 1.18967059, grad/param norm = 3.3724e-01, time/batch = 0.6418s	
6918/11850 (epoch 29.190), train_loss = 1.09431749, grad/param norm = 2.6642e-01, time/batch = 0.6397s	
6919/11850 (epoch 29.194), train_loss = 1.13080529, grad/param norm = 3.0048e-01, time/batch = 0.6397s	
6920/11850 (epoch 29.198), train_loss = 0.90588901, grad/param norm = 3.0820e-01, time/batch = 0.6380s	
6921/11850 (epoch 29.203), train_loss = 0.93772663, grad/param norm = 2.7188e-01, time/batch = 0.6759s	
6922/11850 (epoch 29.207), train_loss = 1.10817509, grad/param norm = 2.8955e-01, time/batch = 0.6707s	
6923/11850 (epoch 29.211), train_loss = 1.06361002, grad/param norm = 2.6553e-01, time/batch = 0.6472s	
6924/11850 (epoch 29.215), train_loss = 1.05863770, grad/param norm = 2.7670e-01, time/batch = 0.6491s	
6925/11850 (epoch 29.219), train_loss = 1.08533220, grad/param norm = 2.5458e-01, time/batch = 0.6442s	
6926/11850 (epoch 29.224), train_loss = 1.21091629, grad/param norm = 2.9030e-01, time/batch = 0.6385s	
6927/11850 (epoch 29.228), train_loss = 1.11109945, grad/param norm = 2.8734e-01, time/batch = 0.6383s	
6928/11850 (epoch 29.232), train_loss = 1.08796086, grad/param norm = 2.6299e-01, time/batch = 0.6393s	
6929/11850 (epoch 29.236), train_loss = 0.97405852, grad/param norm = 2.8404e-01, time/batch = 0.6352s	
6930/11850 (epoch 29.241), train_loss = 1.12773882, grad/param norm = 2.7956e-01, time/batch = 0.6390s	
6931/11850 (epoch 29.245), train_loss = 1.14151690, grad/param norm = 2.7298e-01, time/batch = 0.6412s	
6932/11850 (epoch 29.249), train_loss = 1.02878975, grad/param norm = 2.4811e-01, time/batch = 0.6409s	
6933/11850 (epoch 29.253), train_loss = 1.07530537, grad/param norm = 3.0978e-01, time/batch = 0.6391s	
6934/11850 (epoch 29.257), train_loss = 1.19379263, grad/param norm = 2.9158e-01, time/batch = 0.6374s	
6935/11850 (epoch 29.262), train_loss = 1.20739825, grad/param norm = 3.1348e-01, time/batch = 0.6392s	
6936/11850 (epoch 29.266), train_loss = 1.16788449, grad/param norm = 3.1796e-01, time/batch = 0.6403s	
6937/11850 (epoch 29.270), train_loss = 1.04819352, grad/param norm = 2.4646e-01, time/batch = 0.6384s	
6938/11850 (epoch 29.274), train_loss = 1.09330180, grad/param norm = 4.3883e-01, time/batch = 0.6442s	
6939/11850 (epoch 29.278), train_loss = 0.91696765, grad/param norm = 2.4664e-01, time/batch = 0.6367s	
6940/11850 (epoch 29.283), train_loss = 1.03806206, grad/param norm = 2.4890e-01, time/batch = 0.6395s	
6941/11850 (epoch 29.287), train_loss = 1.17428417, grad/param norm = 2.7008e-01, time/batch = 0.6402s	
6942/11850 (epoch 29.291), train_loss = 1.05040510, grad/param norm = 2.6541e-01, time/batch = 0.6385s	
6943/11850 (epoch 29.295), train_loss = 1.12638554, grad/param norm = 2.8478e-01, time/batch = 0.6376s	
6944/11850 (epoch 29.300), train_loss = 1.02463296, grad/param norm = 2.9769e-01, time/batch = 0.6362s	
6945/11850 (epoch 29.304), train_loss = 1.05094941, grad/param norm = 2.4464e-01, time/batch = 0.6381s	
6946/11850 (epoch 29.308), train_loss = 1.03121899, grad/param norm = 2.2837e-01, time/batch = 0.6434s	
6947/11850 (epoch 29.312), train_loss = 0.95133832, grad/param norm = 2.5050e-01, time/batch = 0.6380s	
6948/11850 (epoch 29.316), train_loss = 1.10991904, grad/param norm = 2.7824e-01, time/batch = 0.6337s	
6949/11850 (epoch 29.321), train_loss = 1.04194277, grad/param norm = 2.8275e-01, time/batch = 0.6396s	
6950/11850 (epoch 29.325), train_loss = 1.05409306, grad/param norm = 2.5756e-01, time/batch = 0.6410s	
6951/11850 (epoch 29.329), train_loss = 1.06144640, grad/param norm = 2.7078e-01, time/batch = 0.6384s	
6952/11850 (epoch 29.333), train_loss = 1.04165030, grad/param norm = 2.6560e-01, time/batch = 0.6392s	
6953/11850 (epoch 29.338), train_loss = 0.99131192, grad/param norm = 2.4539e-01, time/batch = 0.6350s	
6954/11850 (epoch 29.342), train_loss = 1.05795053, grad/param norm = 2.7189e-01, time/batch = 0.6369s	
6955/11850 (epoch 29.346), train_loss = 1.03512493, grad/param norm = 2.5995e-01, time/batch = 0.6393s	
6956/11850 (epoch 29.350), train_loss = 0.93822487, grad/param norm = 2.4734e-01, time/batch = 0.6377s	
6957/11850 (epoch 29.354), train_loss = 1.12529886, grad/param norm = 2.5475e-01, time/batch = 0.6383s	
6958/11850 (epoch 29.359), train_loss = 1.17556304, grad/param norm = 2.8985e-01, time/batch = 0.6372s	
6959/11850 (epoch 29.363), train_loss = 1.09686110, grad/param norm = 2.5854e-01, time/batch = 0.6413s	
6960/11850 (epoch 29.367), train_loss = 1.12008841, grad/param norm = 2.6406e-01, time/batch = 0.6380s	
6961/11850 (epoch 29.371), train_loss = 1.10205591, grad/param norm = 2.3860e-01, time/batch = 0.6402s	
6962/11850 (epoch 29.376), train_loss = 1.03764741, grad/param norm = 2.5627e-01, time/batch = 0.6412s	
6963/11850 (epoch 29.380), train_loss = 1.02361169, grad/param norm = 2.5330e-01, time/batch = 0.6407s	
6964/11850 (epoch 29.384), train_loss = 0.97390843, grad/param norm = 2.3625e-01, time/batch = 0.6362s	
6965/11850 (epoch 29.388), train_loss = 1.13478113, grad/param norm = 2.7549e-01, time/batch = 0.6378s	
6966/11850 (epoch 29.392), train_loss = 1.10131510, grad/param norm = 2.5504e-01, time/batch = 0.6378s	
6967/11850 (epoch 29.397), train_loss = 1.11630348, grad/param norm = 2.7445e-01, time/batch = 0.6432s	
6968/11850 (epoch 29.401), train_loss = 0.94391650, grad/param norm = 2.5381e-01, time/batch = 0.6371s	
6969/11850 (epoch 29.405), train_loss = 0.99151597, grad/param norm = 2.6714e-01, time/batch = 0.6611s	
6970/11850 (epoch 29.409), train_loss = 1.13569230, grad/param norm = 2.9246e-01, time/batch = 0.6670s	
6971/11850 (epoch 29.414), train_loss = 0.91578224, grad/param norm = 2.4297e-01, time/batch = 0.6481s	
6972/11850 (epoch 29.418), train_loss = 0.95592967, grad/param norm = 2.7194e-01, time/batch = 0.6413s	
6973/11850 (epoch 29.422), train_loss = 0.89114649, grad/param norm = 2.5204e-01, time/batch = 0.6381s	
6974/11850 (epoch 29.426), train_loss = 0.90106422, grad/param norm = 2.5025e-01, time/batch = 0.6394s	
6975/11850 (epoch 29.430), train_loss = 0.97032774, grad/param norm = 2.9112e-01, time/batch = 0.6376s	
6976/11850 (epoch 29.435), train_loss = 0.98333204, grad/param norm = 2.5611e-01, time/batch = 0.6369s	
6977/11850 (epoch 29.439), train_loss = 1.09286218, grad/param norm = 2.5850e-01, time/batch = 0.6376s	
6978/11850 (epoch 29.443), train_loss = 1.02476198, grad/param norm = 2.6104e-01, time/batch = 0.6389s	
6979/11850 (epoch 29.447), train_loss = 0.94225143, grad/param norm = 2.5492e-01, time/batch = 0.6388s	
6980/11850 (epoch 29.451), train_loss = 0.94936501, grad/param norm = 2.3498e-01, time/batch = 0.6629s	
6981/11850 (epoch 29.456), train_loss = 1.03991604, grad/param norm = 2.9275e-01, time/batch = 0.6613s	
6982/11850 (epoch 29.460), train_loss = 1.10847874, grad/param norm = 2.6759e-01, time/batch = 0.6340s	
6983/11850 (epoch 29.464), train_loss = 0.98859825, grad/param norm = 2.7209e-01, time/batch = 0.6364s	
6984/11850 (epoch 29.468), train_loss = 1.06322173, grad/param norm = 2.5664e-01, time/batch = 0.6340s	
6985/11850 (epoch 29.473), train_loss = 1.10740550, grad/param norm = 2.9303e-01, time/batch = 0.6325s	
6986/11850 (epoch 29.477), train_loss = 0.95599361, grad/param norm = 2.5085e-01, time/batch = 0.6428s	
6987/11850 (epoch 29.481), train_loss = 0.98241981, grad/param norm = 2.8173e-01, time/batch = 0.6344s	
6988/11850 (epoch 29.485), train_loss = 0.93016513, grad/param norm = 2.3772e-01, time/batch = 0.6352s	
6989/11850 (epoch 29.489), train_loss = 1.06483858, grad/param norm = 2.5089e-01, time/batch = 0.6351s	
6990/11850 (epoch 29.494), train_loss = 0.95121919, grad/param norm = 2.7405e-01, time/batch = 0.6499s	
6991/11850 (epoch 29.498), train_loss = 0.94056049, grad/param norm = 2.6039e-01, time/batch = 0.6723s	
6992/11850 (epoch 29.502), train_loss = 0.91908584, grad/param norm = 2.5647e-01, time/batch = 0.6842s	
6993/11850 (epoch 29.506), train_loss = 1.18804044, grad/param norm = 2.9426e-01, time/batch = 0.6723s	
6994/11850 (epoch 29.511), train_loss = 1.03811717, grad/param norm = 2.6010e-01, time/batch = 0.6602s	
6995/11850 (epoch 29.515), train_loss = 1.13348280, grad/param norm = 2.9230e-01, time/batch = 0.6574s	
6996/11850 (epoch 29.519), train_loss = 0.99931980, grad/param norm = 2.6300e-01, time/batch = 0.6617s	
6997/11850 (epoch 29.523), train_loss = 1.04313387, grad/param norm = 2.5430e-01, time/batch = 0.6416s	
6998/11850 (epoch 29.527), train_loss = 0.96502697, grad/param norm = 2.3040e-01, time/batch = 0.6461s	
6999/11850 (epoch 29.532), train_loss = 1.07143414, grad/param norm = 2.6938e-01, time/batch = 0.6376s	
evaluating loss over split index 2	
1/13...	
2/13...	
3/13...	
4/13...	
5/13...	
6/13...	
7/13...	
8/13...	
9/13...	
10/13...	
11/13...	
12/13...	
13/13...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_katelyn_salem_epoch29.54_2.1617.t7	
7000/11850 (epoch 29.536), train_loss = 1.00948098, grad/param norm = 2.7001e-01, time/batch = 0.6419s	
7001/11850 (epoch 29.540), train_loss = 1.38705105, grad/param norm = 3.5030e-01, time/batch = 0.6542s	
7002/11850 (epoch 29.544), train_loss = 0.95258433, grad/param norm = 2.8955e-01, time/batch = 0.6767s	
7003/11850 (epoch 29.549), train_loss = 0.89219925, grad/param norm = 2.3373e-01, time/batch = 0.6584s	
7004/11850 (epoch 29.553), train_loss = 1.04939033, grad/param norm = 2.7374e-01, time/batch = 0.6527s	
7005/11850 (epoch 29.557), train_loss = 1.06901069, grad/param norm = 3.9358e-01, time/batch = 0.6424s	
7006/11850 (epoch 29.561), train_loss = 1.08549654, grad/param norm = 2.9651e-01, time/batch = 0.6408s	
7007/11850 (epoch 29.565), train_loss = 1.18042793, grad/param norm = 2.8061e-01, time/batch = 0.6407s	
7008/11850 (epoch 29.570), train_loss = 1.04840724, grad/param norm = 2.5888e-01, time/batch = 0.6468s	
7009/11850 (epoch 29.574), train_loss = 1.08131226, grad/param norm = 3.1128e-01, time/batch = 0.6534s	
7010/11850 (epoch 29.578), train_loss = 1.11432383, grad/param norm = 2.7932e-01, time/batch = 0.6663s	
7011/11850 (epoch 29.582), train_loss = 1.00819534, grad/param norm = 3.7530e-01, time/batch = 0.6578s	
7012/11850 (epoch 29.586), train_loss = 1.01501151, grad/param norm = 2.9153e-01, time/batch = 0.6444s	
7013/11850 (epoch 29.591), train_loss = 1.06812278, grad/param norm = 2.7533e-01, time/batch = 0.6488s	
7014/11850 (epoch 29.595), train_loss = 0.92168841, grad/param norm = 2.5828e-01, time/batch = 0.6364s	
7015/11850 (epoch 29.599), train_loss = 1.05481353, grad/param norm = 2.9106e-01, time/batch = 0.6383s	
7016/11850 (epoch 29.603), train_loss = 0.97950962, grad/param norm = 2.4376e-01, time/batch = 0.6403s	
7017/11850 (epoch 29.608), train_loss = 1.17791916, grad/param norm = 2.8164e-01, time/batch = 0.6394s	
7018/11850 (epoch 29.612), train_loss = 1.22720870, grad/param norm = 3.0435e-01, time/batch = 0.6355s	
7019/11850 (epoch 29.616), train_loss = 1.15072879, grad/param norm = 2.6492e-01, time/batch = 0.6474s	
7020/11850 (epoch 29.620), train_loss = 1.04004338, grad/param norm = 3.2563e-01, time/batch = 0.6691s	
7021/11850 (epoch 29.624), train_loss = 1.05152229, grad/param norm = 3.2018e-01, time/batch = 0.6431s	
7022/11850 (epoch 29.629), train_loss = 0.98907496, grad/param norm = 2.6281e-01, time/batch = 0.6366s	
7023/11850 (epoch 29.633), train_loss = 0.93346496, grad/param norm = 2.8179e-01, time/batch = 0.6503s	
7024/11850 (epoch 29.637), train_loss = 0.88005546, grad/param norm = 2.6499e-01, time/batch = 0.6427s	
7025/11850 (epoch 29.641), train_loss = 0.91625638, grad/param norm = 2.3615e-01, time/batch = 0.6492s	
7026/11850 (epoch 29.646), train_loss = 0.95668088, grad/param norm = 2.7985e-01, time/batch = 0.6503s	
7027/11850 (epoch 29.650), train_loss = 1.02948611, grad/param norm = 2.7617e-01, time/batch = 0.6645s	
7028/11850 (epoch 29.654), train_loss = 0.96691898, grad/param norm = 2.7136e-01, time/batch = 0.6496s	
7029/11850 (epoch 29.658), train_loss = 1.06147259, grad/param norm = 2.5987e-01, time/batch = 0.6466s	
7030/11850 (epoch 29.662), train_loss = 0.91097698, grad/param norm = 3.1864e-01, time/batch = 0.6641s	
7031/11850 (epoch 29.667), train_loss = 1.12524327, grad/param norm = 2.9034e-01, time/batch = 0.6679s	
7032/11850 (epoch 29.671), train_loss = 1.02686850, grad/param norm = 2.8792e-01, time/batch = 0.6470s	
7033/11850 (epoch 29.675), train_loss = 0.99296138, grad/param norm = 2.7163e-01, time/batch = 0.6510s	
7034/11850 (epoch 29.679), train_loss = 1.04234049, grad/param norm = 2.8012e-01, time/batch = 0.6553s	
7035/11850 (epoch 29.684), train_loss = 1.00748883, grad/param norm = 2.6593e-01, time/batch = 0.6465s	
7036/11850 (epoch 29.688), train_loss = 0.96816610, grad/param norm = 2.5205e-01, time/batch = 0.6480s	
7037/11850 (epoch 29.692), train_loss = 0.98008387, grad/param norm = 3.2984e-01, time/batch = 0.6509s	
7038/11850 (epoch 29.696), train_loss = 0.95943982, grad/param norm = 3.3383e-01, time/batch = 0.6537s	
7039/11850 (epoch 29.700), train_loss = 1.02646094, grad/param norm = 2.5722e-01, time/batch = 0.6500s	
7040/11850 (epoch 29.705), train_loss = 0.98002995, grad/param norm = 2.6498e-01, time/batch = 0.6375s	
7041/11850 (epoch 29.709), train_loss = 0.89590993, grad/param norm = 2.5713e-01, time/batch = 0.6728s	
7042/11850 (epoch 29.713), train_loss = 0.92348344, grad/param norm = 2.6333e-01, time/batch = 0.6524s	
7043/11850 (epoch 29.717), train_loss = 0.98270594, grad/param norm = 2.7341e-01, time/batch = 0.6373s	
7044/11850 (epoch 29.722), train_loss = 1.03749776, grad/param norm = 3.0273e-01, time/batch = 0.6415s	
7045/11850 (epoch 29.726), train_loss = 0.91901146, grad/param norm = 2.7485e-01, time/batch = 0.6464s	
7046/11850 (epoch 29.730), train_loss = 0.93345639, grad/param norm = 2.4486e-01, time/batch = 0.7728s	
7047/11850 (epoch 29.734), train_loss = 0.96806189, grad/param norm = 2.5153e-01, time/batch = 0.9386s	
7048/11850 (epoch 29.738), train_loss = 1.08862874, grad/param norm = 3.0181e-01, time/batch = 0.9419s	
7049/11850 (epoch 29.743), train_loss = 1.02580668, grad/param norm = 2.8202e-01, time/batch = 0.9293s	
7050/11850 (epoch 29.747), train_loss = 0.89541703, grad/param norm = 2.1965e-01, time/batch = 0.9812s	
7051/11850 (epoch 29.751), train_loss = 0.95639656, grad/param norm = 2.4386e-01, time/batch = 1.1129s	
7052/11850 (epoch 29.755), train_loss = 1.01846279, grad/param norm = 2.6204e-01, time/batch = 1.7465s	
7053/11850 (epoch 29.759), train_loss = 0.95418799, grad/param norm = 2.5298e-01, time/batch = 1.7489s	
7054/11850 (epoch 29.764), train_loss = 0.97504498, grad/param norm = 2.5266e-01, time/batch = 7.7047s	
7055/11850 (epoch 29.768), train_loss = 0.90336201, grad/param norm = 2.5521e-01, time/batch = 16.7863s	
7056/11850 (epoch 29.772), train_loss = 0.96825701, grad/param norm = 3.2413e-01, time/batch = 18.7150s	
7057/11850 (epoch 29.776), train_loss = 1.03844524, grad/param norm = 2.5196e-01, time/batch = 16.6359s	
7058/11850 (epoch 29.781), train_loss = 0.99038319, grad/param norm = 2.7219e-01, time/batch = 17.7936s	
7059/11850 (epoch 29.785), train_loss = 0.97565399, grad/param norm = 3.2081e-01, time/batch = 18.9613s	
7060/11850 (epoch 29.789), train_loss = 0.99403289, grad/param norm = 2.6554e-01, time/batch = 18.2139s	
7061/11850 (epoch 29.793), train_loss = 1.07429275, grad/param norm = 2.8329e-01, time/batch = 18.2086s	
7062/11850 (epoch 29.797), train_loss = 1.01162283, grad/param norm = 2.6071e-01, time/batch = 18.2839s	
7063/11850 (epoch 29.802), train_loss = 0.92848798, grad/param norm = 2.6856e-01, time/batch = 17.7604s	
7064/11850 (epoch 29.806), train_loss = 0.99495216, grad/param norm = 2.5379e-01, time/batch = 18.1452s	
7065/11850 (epoch 29.810), train_loss = 1.08405061, grad/param norm = 3.1821e-01, time/batch = 17.0278s	
7066/11850 (epoch 29.814), train_loss = 1.00807432, grad/param norm = 2.6200e-01, time/batch = 18.1252s	
7067/11850 (epoch 29.819), train_loss = 1.12863468, grad/param norm = 2.9317e-01, time/batch = 17.8150s	
7068/11850 (epoch 29.823), train_loss = 1.13440801, grad/param norm = 2.7648e-01, time/batch = 16.6251s	
7069/11850 (epoch 29.827), train_loss = 1.01319415, grad/param norm = 2.7305e-01, time/batch = 17.3012s	
7070/11850 (epoch 29.831), train_loss = 1.00843602, grad/param norm = 2.6060e-01, time/batch = 18.3000s	
7071/11850 (epoch 29.835), train_loss = 1.03396043, grad/param norm = 2.3721e-01, time/batch = 17.9718s	
7072/11850 (epoch 29.840), train_loss = 0.97876847, grad/param norm = 2.5191e-01, time/batch = 16.4502s	
7073/11850 (epoch 29.844), train_loss = 0.99837840, grad/param norm = 2.2476e-01, time/batch = 16.4637s	
7074/11850 (epoch 29.848), train_loss = 1.05065206, grad/param norm = 3.6189e-01, time/batch = 17.5455s	
7075/11850 (epoch 29.852), train_loss = 1.02541565, grad/param norm = 2.5978e-01, time/batch = 17.1362s	
7076/11850 (epoch 29.857), train_loss = 1.00612050, grad/param norm = 3.0158e-01, time/batch = 17.8677s	
7077/11850 (epoch 29.861), train_loss = 0.98934343, grad/param norm = 2.9743e-01, time/batch = 14.8883s	
7078/11850 (epoch 29.865), train_loss = 1.07714126, grad/param norm = 3.1532e-01, time/batch = 18.8913s	
7079/11850 (epoch 29.869), train_loss = 1.06282771, grad/param norm = 3.1812e-01, time/batch = 17.6017s	
7080/11850 (epoch 29.873), train_loss = 1.06450109, grad/param norm = 2.9890e-01, time/batch = 18.3824s	
7081/11850 (epoch 29.878), train_loss = 1.06319744, grad/param norm = 2.7911e-01, time/batch = 19.1227s	
7082/11850 (epoch 29.882), train_loss = 1.02512402, grad/param norm = 3.1006e-01, time/batch = 16.8784s	
7083/11850 (epoch 29.886), train_loss = 1.02144372, grad/param norm = 3.0713e-01, time/batch = 17.7317s	
7084/11850 (epoch 29.890), train_loss = 1.04920275, grad/param norm = 3.3291e-01, time/batch = 17.7173s	
7085/11850 (epoch 29.895), train_loss = 1.07395358, grad/param norm = 3.0977e-01, time/batch = 17.1390s	
7086/11850 (epoch 29.899), train_loss = 0.93389337, grad/param norm = 2.6818e-01, time/batch = 17.4483s	
7087/11850 (epoch 29.903), train_loss = 0.99197941, grad/param norm = 2.7531e-01, time/batch = 17.8764s	
7088/11850 (epoch 29.907), train_loss = 0.97010170, grad/param norm = 2.5179e-01, time/batch = 17.3044s	
7089/11850 (epoch 29.911), train_loss = 1.11435246, grad/param norm = 3.3986e-01, time/batch = 17.1213s	
7090/11850 (epoch 29.916), train_loss = 1.07166001, grad/param norm = 2.8085e-01, time/batch = 16.0531s	
7091/11850 (epoch 29.920), train_loss = 1.04815914, grad/param norm = 2.8324e-01, time/batch = 19.1332s	
7092/11850 (epoch 29.924), train_loss = 1.00555924, grad/param norm = 3.2304e-01, time/batch = 17.2184s	
7093/11850 (epoch 29.928), train_loss = 1.08819146, grad/param norm = 3.2564e-01, time/batch = 18.2973s	
7094/11850 (epoch 29.932), train_loss = 1.13118354, grad/param norm = 3.0772e-01, time/batch = 18.0540s	
7095/11850 (epoch 29.937), train_loss = 1.08046074, grad/param norm = 2.4950e-01, time/batch = 17.2984s	
7096/11850 (epoch 29.941), train_loss = 1.07264492, grad/param norm = 2.7250e-01, time/batch = 17.7945s	
7097/11850 (epoch 29.945), train_loss = 1.10423764, grad/param norm = 2.9237e-01, time/batch = 17.9537s	
7098/11850 (epoch 29.949), train_loss = 1.00349605, grad/param norm = 2.9117e-01, time/batch = 18.9542s	
7099/11850 (epoch 29.954), train_loss = 1.09077003, grad/param norm = 2.7630e-01, time/batch = 17.9556s	
7100/11850 (epoch 29.958), train_loss = 1.07881638, grad/param norm = 2.7909e-01, time/batch = 16.7041s	
7101/11850 (epoch 29.962), train_loss = 0.97244426, grad/param norm = 2.6647e-01, time/batch = 16.2841s	
7102/11850 (epoch 29.966), train_loss = 0.93741752, grad/param norm = 3.0539e-01, time/batch = 20.8335s	
7103/11850 (epoch 29.970), train_loss = 1.05101948, grad/param norm = 2.6214e-01, time/batch = 27.3595s	
7104/11850 (epoch 29.975), train_loss = 1.00287960, grad/param norm = 2.6882e-01, time/batch = 17.0561s	
7105/11850 (epoch 29.979), train_loss = 1.04369231, grad/param norm = 3.5488e-01, time/batch = 16.2049s	
7106/11850 (epoch 29.983), train_loss = 1.13011540, grad/param norm = 3.3726e-01, time/batch = 18.2244s	
7107/11850 (epoch 29.987), train_loss = 1.01329591, grad/param norm = 3.2407e-01, time/batch = 18.6328s	
7108/11850 (epoch 29.992), train_loss = 1.15582355, grad/param norm = 2.7995e-01, time/batch = 15.4451s	
7109/11850 (epoch 29.996), train_loss = 1.17388798, grad/param norm = 2.7567e-01, time/batch = 17.0345s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
7110/11850 (epoch 30.000), train_loss = 1.05878857, grad/param norm = 4.1177e-01, time/batch = 18.4700s	
7111/11850 (epoch 30.004), train_loss = 1.10252442, grad/param norm = 3.6255e-01, time/batch = 18.5537s	
7112/11850 (epoch 30.008), train_loss = 1.13703175, grad/param norm = 2.8965e-01, time/batch = 16.8021s	
7113/11850 (epoch 30.013), train_loss = 1.14102593, grad/param norm = 2.8346e-01, time/batch = 19.6278s	
7114/11850 (epoch 30.017), train_loss = 1.18577524, grad/param norm = 2.8614e-01, time/batch = 17.2256s	
7115/11850 (epoch 30.021), train_loss = 1.10269991, grad/param norm = 2.6180e-01, time/batch = 16.9393s	
7116/11850 (epoch 30.025), train_loss = 0.99124952, grad/param norm = 2.5199e-01, time/batch = 16.3580s	
7117/11850 (epoch 30.030), train_loss = 1.01149852, grad/param norm = 2.9527e-01, time/batch = 18.5524s	
7118/11850 (epoch 30.034), train_loss = 1.01113576, grad/param norm = 2.8750e-01, time/batch = 18.5449s	
7119/11850 (epoch 30.038), train_loss = 1.03280304, grad/param norm = 2.5459e-01, time/batch = 16.8829s	
7120/11850 (epoch 30.042), train_loss = 1.07420058, grad/param norm = 2.8126e-01, time/batch = 19.0405s	
7121/11850 (epoch 30.046), train_loss = 1.03073441, grad/param norm = 2.9329e-01, time/batch = 18.6980s	
7122/11850 (epoch 30.051), train_loss = 1.05411682, grad/param norm = 2.6721e-01, time/batch = 15.1313s	
7123/11850 (epoch 30.055), train_loss = 1.00286115, grad/param norm = 2.5240e-01, time/batch = 15.9645s	
7124/11850 (epoch 30.059), train_loss = 1.10946387, grad/param norm = 2.6904e-01, time/batch = 18.4601s	
7125/11850 (epoch 30.063), train_loss = 1.09800978, grad/param norm = 3.1252e-01, time/batch = 15.0990s	
7126/11850 (epoch 30.068), train_loss = 1.03024957, grad/param norm = 2.5232e-01, time/batch = 17.7239s	
7127/11850 (epoch 30.072), train_loss = 1.10785914, grad/param norm = 3.1538e-01, time/batch = 16.8052s	
7128/11850 (epoch 30.076), train_loss = 1.15955323, grad/param norm = 2.9355e-01, time/batch = 19.1340s	
7129/11850 (epoch 30.080), train_loss = 0.99167005, grad/param norm = 2.6393e-01, time/batch = 16.1270s	
7130/11850 (epoch 30.084), train_loss = 0.92552691, grad/param norm = 2.4279e-01, time/batch = 18.5299s	
7131/11850 (epoch 30.089), train_loss = 0.93683905, grad/param norm = 2.4726e-01, time/batch = 18.3744s	
7132/11850 (epoch 30.093), train_loss = 0.93436311, grad/param norm = 2.5865e-01, time/batch = 17.6276s	
7133/11850 (epoch 30.097), train_loss = 1.04544668, grad/param norm = 2.5709e-01, time/batch = 17.6264s	
7134/11850 (epoch 30.101), train_loss = 0.98095086, grad/param norm = 2.9411e-01, time/batch = 16.0366s	
7135/11850 (epoch 30.105), train_loss = 0.93071557, grad/param norm = 2.3944e-01, time/batch = 17.5430s	
7136/11850 (epoch 30.110), train_loss = 1.08641928, grad/param norm = 2.5523e-01, time/batch = 15.5396s	
7137/11850 (epoch 30.114), train_loss = 1.01070519, grad/param norm = 2.7777e-01, time/batch = 18.2113s	
7138/11850 (epoch 30.118), train_loss = 1.09422490, grad/param norm = 2.5445e-01, time/batch = 17.2847s	
7139/11850 (epoch 30.122), train_loss = 1.13439530, grad/param norm = 2.7219e-01, time/batch = 16.9465s	
7140/11850 (epoch 30.127), train_loss = 1.06554568, grad/param norm = 2.7665e-01, time/batch = 18.2913s	
7141/11850 (epoch 30.131), train_loss = 1.03590964, grad/param norm = 2.8406e-01, time/batch = 18.0999s	
7142/11850 (epoch 30.135), train_loss = 1.01661350, grad/param norm = 2.9226e-01, time/batch = 18.2222s	
7143/11850 (epoch 30.139), train_loss = 1.03422147, grad/param norm = 2.8607e-01, time/batch = 18.3749s	
7144/11850 (epoch 30.143), train_loss = 1.02108784, grad/param norm = 2.7500e-01, time/batch = 14.3319s	
7145/11850 (epoch 30.148), train_loss = 1.00707721, grad/param norm = 2.8293e-01, time/batch = 18.5577s	
7146/11850 (epoch 30.152), train_loss = 1.11580685, grad/param norm = 3.2966e-01, time/batch = 17.5326s	
7147/11850 (epoch 30.156), train_loss = 1.02622608, grad/param norm = 3.0880e-01, time/batch = 17.7858s	
7148/11850 (epoch 30.160), train_loss = 1.23125725, grad/param norm = 3.4888e-01, time/batch = 19.1271s	
7149/11850 (epoch 30.165), train_loss = 1.16407615, grad/param norm = 3.4451e-01, time/batch = 16.9647s	
7150/11850 (epoch 30.169), train_loss = 1.02249328, grad/param norm = 2.9011e-01, time/batch = 16.4433s	
7151/11850 (epoch 30.173), train_loss = 1.08890418, grad/param norm = 2.6811e-01, time/batch = 17.0527s	
7152/11850 (epoch 30.177), train_loss = 0.94825008, grad/param norm = 3.0851e-01, time/batch = 18.9633s	
7153/11850 (epoch 30.181), train_loss = 1.09707480, grad/param norm = 2.7430e-01, time/batch = 16.0520s	
7154/11850 (epoch 30.186), train_loss = 1.17852680, grad/param norm = 3.7866e-01, time/batch = 16.8064s	
7155/11850 (epoch 30.190), train_loss = 1.06701288, grad/param norm = 2.5384e-01, time/batch = 17.3074s	
7156/11850 (epoch 30.194), train_loss = 1.10840982, grad/param norm = 2.9355e-01, time/batch = 17.2866s	
7157/11850 (epoch 30.198), train_loss = 0.87921987, grad/param norm = 2.5245e-01, time/batch = 16.6386s	
7158/11850 (epoch 30.203), train_loss = 0.92400141, grad/param norm = 2.7356e-01, time/batch = 17.2228s	
7159/11850 (epoch 30.207), train_loss = 1.10441538, grad/param norm = 3.3726e-01, time/batch = 16.1247s	
7160/11850 (epoch 30.211), train_loss = 1.05426648, grad/param norm = 3.0112e-01, time/batch = 17.0448s	
7161/11850 (epoch 30.215), train_loss = 1.04155237, grad/param norm = 2.8454e-01, time/batch = 18.2180s	
7162/11850 (epoch 30.219), train_loss = 1.07174101, grad/param norm = 3.2135e-01, time/batch = 19.0524s	
7163/11850 (epoch 30.224), train_loss = 1.19306223, grad/param norm = 2.7710e-01, time/batch = 17.8054s	
7164/11850 (epoch 30.228), train_loss = 1.08575767, grad/param norm = 2.9204e-01, time/batch = 18.3684s	
7165/11850 (epoch 30.232), train_loss = 1.07366635, grad/param norm = 2.8652e-01, time/batch = 16.3985s	
7166/11850 (epoch 30.236), train_loss = 0.96545085, grad/param norm = 3.3930e-01, time/batch = 16.5406s	
7167/11850 (epoch 30.241), train_loss = 1.11696431, grad/param norm = 3.1724e-01, time/batch = 15.0657s	
7168/11850 (epoch 30.245), train_loss = 1.11214804, grad/param norm = 2.5213e-01, time/batch = 17.8096s	
7169/11850 (epoch 30.249), train_loss = 1.01959126, grad/param norm = 2.6683e-01, time/batch = 17.9620s	
7170/11850 (epoch 30.253), train_loss = 1.04547244, grad/param norm = 2.9341e-01, time/batch = 16.5512s	
7171/11850 (epoch 30.257), train_loss = 1.17992997, grad/param norm = 2.9973e-01, time/batch = 18.0351s	
7172/11850 (epoch 30.262), train_loss = 1.18871731, grad/param norm = 4.1354e-01, time/batch = 16.3025s	
7173/11850 (epoch 30.266), train_loss = 1.18418357, grad/param norm = 3.9484e-01, time/batch = 18.1461s	
7174/11850 (epoch 30.270), train_loss = 1.03968438, grad/param norm = 2.4918e-01, time/batch = 17.0179s	
7175/11850 (epoch 30.274), train_loss = 1.05101133, grad/param norm = 3.0086e-01, time/batch = 16.2236s	
7176/11850 (epoch 30.278), train_loss = 0.91218354, grad/param norm = 2.6604e-01, time/batch = 18.1493s	
7177/11850 (epoch 30.283), train_loss = 1.03009705, grad/param norm = 2.6558e-01, time/batch = 16.4505s	
7178/11850 (epoch 30.287), train_loss = 1.15958153, grad/param norm = 2.8317e-01, time/batch = 18.2034s	
7179/11850 (epoch 30.291), train_loss = 1.03009288, grad/param norm = 2.6667e-01, time/batch = 17.2280s	
7180/11850 (epoch 30.295), train_loss = 1.10757644, grad/param norm = 2.7846e-01, time/batch = 18.7153s	
7181/11850 (epoch 30.300), train_loss = 1.01809244, grad/param norm = 3.3818e-01, time/batch = 17.9617s	
7182/11850 (epoch 30.304), train_loss = 1.03295473, grad/param norm = 2.4744e-01, time/batch = 18.6355s	
7183/11850 (epoch 30.308), train_loss = 1.00380856, grad/param norm = 2.3316e-01, time/batch = 18.2156s	
7184/11850 (epoch 30.312), train_loss = 0.94219628, grad/param norm = 2.7678e-01, time/batch = 16.0481s	
7185/11850 (epoch 30.316), train_loss = 1.09019877, grad/param norm = 2.7558e-01, time/batch = 18.4672s	
7186/11850 (epoch 30.321), train_loss = 1.02408021, grad/param norm = 2.7547e-01, time/batch = 18.1446s	
7187/11850 (epoch 30.325), train_loss = 1.04649993, grad/param norm = 2.5269e-01, time/batch = 17.0384s	
7188/11850 (epoch 30.329), train_loss = 1.04111337, grad/param norm = 2.7554e-01, time/batch = 17.8924s	
7189/11850 (epoch 30.333), train_loss = 1.00993369, grad/param norm = 2.6630e-01, time/batch = 17.3047s	
7190/11850 (epoch 30.338), train_loss = 0.97943331, grad/param norm = 2.4503e-01, time/batch = 17.7357s	
7191/11850 (epoch 30.342), train_loss = 1.04187375, grad/param norm = 2.8677e-01, time/batch = 15.5421s	
7192/11850 (epoch 30.346), train_loss = 1.02060581, grad/param norm = 2.7026e-01, time/batch = 15.0379s	
7193/11850 (epoch 30.350), train_loss = 0.92611747, grad/param norm = 2.5161e-01, time/batch = 18.5429s	
7194/11850 (epoch 30.354), train_loss = 1.11008224, grad/param norm = 2.8260e-01, time/batch = 16.5491s	
7195/11850 (epoch 30.359), train_loss = 1.14707653, grad/param norm = 2.7824e-01, time/batch = 17.8088s	
7196/11850 (epoch 30.363), train_loss = 1.08405492, grad/param norm = 2.8144e-01, time/batch = 18.3933s	
7197/11850 (epoch 30.367), train_loss = 1.10532246, grad/param norm = 2.6730e-01, time/batch = 17.8881s	
7198/11850 (epoch 30.371), train_loss = 1.08575055, grad/param norm = 3.0985e-01, time/batch = 15.9711s	
7199/11850 (epoch 30.376), train_loss = 1.02166392, grad/param norm = 2.5343e-01, time/batch = 18.4018s	
7200/11850 (epoch 30.380), train_loss = 1.00318245, grad/param norm = 2.4169e-01, time/batch = 15.7032s	
7201/11850 (epoch 30.384), train_loss = 0.94616255, grad/param norm = 2.4617e-01, time/batch = 17.2120s	
7202/11850 (epoch 30.388), train_loss = 1.11948890, grad/param norm = 2.7583e-01, time/batch = 17.3790s	
7203/11850 (epoch 30.392), train_loss = 1.08505664, grad/param norm = 2.8135e-01, time/batch = 18.5495s	
7204/11850 (epoch 30.397), train_loss = 1.09954943, grad/param norm = 2.6238e-01, time/batch = 17.8802s	
7205/11850 (epoch 30.401), train_loss = 0.92787094, grad/param norm = 2.3898e-01, time/batch = 16.2049s	
7206/11850 (epoch 30.405), train_loss = 0.98607133, grad/param norm = 3.1531e-01, time/batch = 18.9711s	
7207/11850 (epoch 30.409), train_loss = 1.11171844, grad/param norm = 2.7652e-01, time/batch = 16.7923s	
7208/11850 (epoch 30.414), train_loss = 0.89965690, grad/param norm = 2.4711e-01, time/batch = 15.2002s	
7209/11850 (epoch 30.418), train_loss = 0.93965013, grad/param norm = 2.4985e-01, time/batch = 18.1350s	
7210/11850 (epoch 30.422), train_loss = 0.86197790, grad/param norm = 2.4233e-01, time/batch = 18.2904s	
7211/11850 (epoch 30.426), train_loss = 0.88054126, grad/param norm = 2.6569e-01, time/batch = 17.1454s	
7212/11850 (epoch 30.430), train_loss = 0.94118219, grad/param norm = 2.5834e-01, time/batch = 17.9705s	
7213/11850 (epoch 30.435), train_loss = 0.95672224, grad/param norm = 2.3293e-01, time/batch = 16.1352s	
7214/11850 (epoch 30.439), train_loss = 1.05783050, grad/param norm = 2.3497e-01, time/batch = 17.7959s	
7215/11850 (epoch 30.443), train_loss = 1.00840609, grad/param norm = 2.5778e-01, time/batch = 17.0420s	
7216/11850 (epoch 30.447), train_loss = 0.93350637, grad/param norm = 2.9030e-01, time/batch = 18.1410s	
7217/11850 (epoch 30.451), train_loss = 0.93552958, grad/param norm = 2.8724e-01, time/batch = 18.2163s	
7218/11850 (epoch 30.456), train_loss = 1.02010450, grad/param norm = 3.1278e-01, time/batch = 16.8730s	
7219/11850 (epoch 30.460), train_loss = 1.08612392, grad/param norm = 2.4854e-01, time/batch = 18.7990s	
7220/11850 (epoch 30.464), train_loss = 0.97336587, grad/param norm = 2.7777e-01, time/batch = 17.3723s	
7221/11850 (epoch 30.468), train_loss = 1.04275504, grad/param norm = 2.5229e-01, time/batch = 18.3712s	
7222/11850 (epoch 30.473), train_loss = 1.08854485, grad/param norm = 2.8846e-01, time/batch = 18.3652s	
7223/11850 (epoch 30.477), train_loss = 0.93550711, grad/param norm = 2.5357e-01, time/batch = 16.9634s	
7224/11850 (epoch 30.481), train_loss = 0.96303717, grad/param norm = 2.8843e-01, time/batch = 18.2970s	
7225/11850 (epoch 30.485), train_loss = 0.91401379, grad/param norm = 2.4882e-01, time/batch = 15.9442s	
7226/11850 (epoch 30.489), train_loss = 1.05390367, grad/param norm = 2.6646e-01, time/batch = 17.9469s	
7227/11850 (epoch 30.494), train_loss = 0.92936716, grad/param norm = 2.9387e-01, time/batch = 18.1945s	
7228/11850 (epoch 30.498), train_loss = 0.92921618, grad/param norm = 2.9071e-01, time/batch = 17.2143s	
7229/11850 (epoch 30.502), train_loss = 0.90384021, grad/param norm = 2.8126e-01, time/batch = 15.8126s	
7230/11850 (epoch 30.506), train_loss = 1.17555205, grad/param norm = 2.9482e-01, time/batch = 17.5452s	
7231/11850 (epoch 30.511), train_loss = 1.01599616, grad/param norm = 2.6632e-01, time/batch = 17.5330s	
7232/11850 (epoch 30.515), train_loss = 1.10892368, grad/param norm = 2.8123e-01, time/batch = 15.0614s	
7233/11850 (epoch 30.519), train_loss = 0.97551864, grad/param norm = 2.5898e-01, time/batch = 17.4055s	
7234/11850 (epoch 30.523), train_loss = 1.01408323, grad/param norm = 2.4600e-01, time/batch = 17.7137s	
7235/11850 (epoch 30.527), train_loss = 0.96116697, grad/param norm = 2.9442e-01, time/batch = 17.1326s	
7236/11850 (epoch 30.532), train_loss = 1.05542653, grad/param norm = 2.5785e-01, time/batch = 16.9769s	
7237/11850 (epoch 30.536), train_loss = 0.99160269, grad/param norm = 2.5657e-01, time/batch = 18.4719s	
7238/11850 (epoch 30.540), train_loss = 0.94761462, grad/param norm = 2.6131e-01, time/batch = 18.0541s	
7239/11850 (epoch 30.544), train_loss = 0.94166716, grad/param norm = 2.8159e-01, time/batch = 16.2894s	
7240/11850 (epoch 30.549), train_loss = 0.88749472, grad/param norm = 2.4940e-01, time/batch = 17.5637s	
7241/11850 (epoch 30.553), train_loss = 1.02769254, grad/param norm = 2.8025e-01, time/batch = 17.9738s	
7242/11850 (epoch 30.557), train_loss = 1.05880714, grad/param norm = 3.2316e-01, time/batch = 16.3839s	
7243/11850 (epoch 30.561), train_loss = 1.04736528, grad/param norm = 2.6681e-01, time/batch = 18.8673s	
7244/11850 (epoch 30.565), train_loss = 1.16979393, grad/param norm = 3.0998e-01, time/batch = 15.8991s	
7245/11850 (epoch 30.570), train_loss = 1.02428341, grad/param norm = 2.5052e-01, time/batch = 19.3076s	
7246/11850 (epoch 30.574), train_loss = 1.05855904, grad/param norm = 2.7170e-01, time/batch = 16.7139s	
7247/11850 (epoch 30.578), train_loss = 1.10373910, grad/param norm = 2.9708e-01, time/batch = 17.6210s	
7248/11850 (epoch 30.582), train_loss = 0.99614514, grad/param norm = 3.2165e-01, time/batch = 19.1251s	
7249/11850 (epoch 30.586), train_loss = 0.98824822, grad/param norm = 2.6861e-01, time/batch = 15.5932s	
7250/11850 (epoch 30.591), train_loss = 1.05087712, grad/param norm = 3.0312e-01, time/batch = 17.7942s	
7251/11850 (epoch 30.595), train_loss = 0.90119387, grad/param norm = 2.7166e-01, time/batch = 18.3004s	
7252/11850 (epoch 30.599), train_loss = 1.03279660, grad/param norm = 3.0931e-01, time/batch = 17.5348s	
7253/11850 (epoch 30.603), train_loss = 0.96521199, grad/param norm = 2.2906e-01, time/batch = 17.4759s	
7254/11850 (epoch 30.608), train_loss = 1.15466450, grad/param norm = 2.7830e-01, time/batch = 18.2237s	
7255/11850 (epoch 30.612), train_loss = 1.19849466, grad/param norm = 2.9787e-01, time/batch = 17.0626s	
7256/11850 (epoch 30.616), train_loss = 1.12800979, grad/param norm = 2.8064e-01, time/batch = 16.2860s	
7257/11850 (epoch 30.620), train_loss = 1.01986154, grad/param norm = 2.4509e-01, time/batch = 16.3609s	
7258/11850 (epoch 30.624), train_loss = 1.02586950, grad/param norm = 3.0475e-01, time/batch = 15.9034s	
7259/11850 (epoch 30.629), train_loss = 0.96961380, grad/param norm = 2.6508e-01, time/batch = 17.6854s	
7260/11850 (epoch 30.633), train_loss = 0.91097721, grad/param norm = 2.9209e-01, time/batch = 17.7860s	
7261/11850 (epoch 30.637), train_loss = 0.86582553, grad/param norm = 2.7593e-01, time/batch = 16.8078s	
7262/11850 (epoch 30.641), train_loss = 0.90701768, grad/param norm = 2.3145e-01, time/batch = 18.3083s	
7263/11850 (epoch 30.646), train_loss = 0.93875624, grad/param norm = 2.8496e-01, time/batch = 16.2955s	
7264/11850 (epoch 30.650), train_loss = 1.02265455, grad/param norm = 3.4988e-01, time/batch = 18.7969s	
7265/11850 (epoch 30.654), train_loss = 0.97852097, grad/param norm = 3.4631e-01, time/batch = 18.2298s	
7266/11850 (epoch 30.658), train_loss = 1.04669678, grad/param norm = 2.8108e-01, time/batch = 18.5445s	
7267/11850 (epoch 30.662), train_loss = 0.89812478, grad/param norm = 2.9969e-01, time/batch = 17.2899s	
7268/11850 (epoch 30.667), train_loss = 1.09640865, grad/param norm = 2.7836e-01, time/batch = 15.2906s	
7269/11850 (epoch 30.671), train_loss = 0.99564474, grad/param norm = 2.8436e-01, time/batch = 18.3960s	
7270/11850 (epoch 30.675), train_loss = 0.97692040, grad/param norm = 2.7335e-01, time/batch = 18.1907s	
7271/11850 (epoch 30.679), train_loss = 1.01491324, grad/param norm = 2.7674e-01, time/batch = 18.6286s	
7272/11850 (epoch 30.684), train_loss = 0.98653337, grad/param norm = 2.7943e-01, time/batch = 16.8848s	
7273/11850 (epoch 30.688), train_loss = 0.94506852, grad/param norm = 2.5374e-01, time/batch = 15.7892s	
7274/11850 (epoch 30.692), train_loss = 0.95744236, grad/param norm = 2.9946e-01, time/batch = 16.1956s	
7275/11850 (epoch 30.696), train_loss = 0.92069589, grad/param norm = 2.9443e-01, time/batch = 17.3982s	
7276/11850 (epoch 30.700), train_loss = 1.02074660, grad/param norm = 2.8283e-01, time/batch = 16.7270s	
7277/11850 (epoch 30.705), train_loss = 0.95137879, grad/param norm = 2.7638e-01, time/batch = 15.9466s	
7278/11850 (epoch 30.709), train_loss = 0.86423742, grad/param norm = 2.4323e-01, time/batch = 18.5532s	
7279/11850 (epoch 30.713), train_loss = 0.88895524, grad/param norm = 2.9828e-01, time/batch = 18.0485s	
7280/11850 (epoch 30.717), train_loss = 0.96249632, grad/param norm = 2.8595e-01, time/batch = 17.3821s	
7281/11850 (epoch 30.722), train_loss = 1.02019441, grad/param norm = 3.7021e-01, time/batch = 17.3779s	
7282/11850 (epoch 30.726), train_loss = 0.92325266, grad/param norm = 3.2257e-01, time/batch = 19.3730s	
7283/11850 (epoch 30.730), train_loss = 0.92074572, grad/param norm = 2.5802e-01, time/batch = 17.7960s	
7284/11850 (epoch 30.734), train_loss = 0.95317529, grad/param norm = 2.9710e-01, time/batch = 17.7843s	
7285/11850 (epoch 30.738), train_loss = 1.06763561, grad/param norm = 2.9714e-01, time/batch = 18.3061s	
7286/11850 (epoch 30.743), train_loss = 1.00216976, grad/param norm = 2.6046e-01, time/batch = 18.3132s	
7287/11850 (epoch 30.747), train_loss = 0.88168831, grad/param norm = 2.2466e-01, time/batch = 15.8910s	
7288/11850 (epoch 30.751), train_loss = 0.95051491, grad/param norm = 2.5472e-01, time/batch = 18.3115s	
7289/11850 (epoch 30.755), train_loss = 1.00423137, grad/param norm = 2.4124e-01, time/batch = 19.4547s	
7290/11850 (epoch 30.759), train_loss = 0.94030642, grad/param norm = 2.5666e-01, time/batch = 15.0151s	
7291/11850 (epoch 30.764), train_loss = 0.95585915, grad/param norm = 2.5130e-01, time/batch = 17.9630s	
7292/11850 (epoch 30.768), train_loss = 0.88374705, grad/param norm = 2.5245e-01, time/batch = 17.1340s	
7293/11850 (epoch 30.772), train_loss = 0.95650038, grad/param norm = 2.8310e-01, time/batch = 18.6290s	
7294/11850 (epoch 30.776), train_loss = 1.03078323, grad/param norm = 2.8434e-01, time/batch = 17.3728s	
7295/11850 (epoch 30.781), train_loss = 0.97694537, grad/param norm = 2.6881e-01, time/batch = 17.3795s	
7296/11850 (epoch 30.785), train_loss = 0.96085394, grad/param norm = 2.9713e-01, time/batch = 15.7747s	
7297/11850 (epoch 30.789), train_loss = 0.98111044, grad/param norm = 2.8186e-01, time/batch = 16.6247s	
7298/11850 (epoch 30.793), train_loss = 1.05979272, grad/param norm = 3.2045e-01, time/batch = 18.5556s	
7299/11850 (epoch 30.797), train_loss = 0.99486777, grad/param norm = 2.7221e-01, time/batch = 18.7247s	
7300/11850 (epoch 30.802), train_loss = 0.90950990, grad/param norm = 2.5600e-01, time/batch = 17.6232s	
7301/11850 (epoch 30.806), train_loss = 0.98730545, grad/param norm = 3.0034e-01, time/batch = 18.7915s	
7302/11850 (epoch 30.810), train_loss = 1.06470834, grad/param norm = 3.0632e-01, time/batch = 17.8108s	
7303/11850 (epoch 30.814), train_loss = 0.99299412, grad/param norm = 2.8390e-01, time/batch = 18.1318s	
7304/11850 (epoch 30.819), train_loss = 1.10258155, grad/param norm = 2.9333e-01, time/batch = 17.0441s	
7305/11850 (epoch 30.823), train_loss = 1.11295587, grad/param norm = 2.8237e-01, time/batch = 18.5532s	
7306/11850 (epoch 30.827), train_loss = 1.01512021, grad/param norm = 2.9546e-01, time/batch = 17.7931s	
7307/11850 (epoch 30.831), train_loss = 0.98488650, grad/param norm = 2.5405e-01, time/batch = 26.9018s	
7308/11850 (epoch 30.835), train_loss = 1.01169094, grad/param norm = 2.5851e-01, time/batch = 20.4142s	
7309/11850 (epoch 30.840), train_loss = 0.95834321, grad/param norm = 2.6345e-01, time/batch = 17.9641s	
7310/11850 (epoch 30.844), train_loss = 0.98083655, grad/param norm = 2.1357e-01, time/batch = 15.1036s	
7311/11850 (epoch 30.848), train_loss = 1.01155924, grad/param norm = 2.7696e-01, time/batch = 16.6223s	
7312/11850 (epoch 30.852), train_loss = 1.01060297, grad/param norm = 2.9524e-01, time/batch = 16.7917s	
7313/11850 (epoch 30.857), train_loss = 0.98570575, grad/param norm = 3.3616e-01, time/batch = 14.3370s	
7314/11850 (epoch 30.861), train_loss = 0.97119981, grad/param norm = 3.0554e-01, time/batch = 14.1030s	
7315/11850 (epoch 30.865), train_loss = 1.05692107, grad/param norm = 3.6402e-01, time/batch = 14.6953s	
7316/11850 (epoch 30.869), train_loss = 1.02365541, grad/param norm = 2.9008e-01, time/batch = 18.7123s	
7317/11850 (epoch 30.873), train_loss = 1.05206473, grad/param norm = 3.1577e-01, time/batch = 17.4727s	
7318/11850 (epoch 30.878), train_loss = 1.04563917, grad/param norm = 2.6266e-01, time/batch = 18.6225s	
7319/11850 (epoch 30.882), train_loss = 0.99343220, grad/param norm = 2.7157e-01, time/batch = 16.3241s	
7320/11850 (epoch 30.886), train_loss = 0.99628067, grad/param norm = 2.9828e-01, time/batch = 17.9602s	
7321/11850 (epoch 30.890), train_loss = 1.02239020, grad/param norm = 2.9183e-01, time/batch = 16.9033s	
7322/11850 (epoch 30.895), train_loss = 1.05864612, grad/param norm = 3.3072e-01, time/batch = 17.3813s	
7323/11850 (epoch 30.899), train_loss = 0.91555688, grad/param norm = 2.7543e-01, time/batch = 17.9043s	
7324/11850 (epoch 30.903), train_loss = 0.97170033, grad/param norm = 2.8276e-01, time/batch = 16.2944s	
7325/11850 (epoch 30.907), train_loss = 0.95476437, grad/param norm = 2.8919e-01, time/batch = 17.5455s	
7326/11850 (epoch 30.911), train_loss = 1.09450570, grad/param norm = 2.9976e-01, time/batch = 16.4797s	
7327/11850 (epoch 30.916), train_loss = 1.06312074, grad/param norm = 3.2042e-01, time/batch = 17.0556s	
7328/11850 (epoch 30.920), train_loss = 1.02545019, grad/param norm = 2.7264e-01, time/batch = 15.2114s	
7329/11850 (epoch 30.924), train_loss = 0.98099222, grad/param norm = 3.4686e-01, time/batch = 18.4592s	
7330/11850 (epoch 30.928), train_loss = 1.07116232, grad/param norm = 4.3612e-01, time/batch = 18.2149s	
7331/11850 (epoch 30.932), train_loss = 1.13236705, grad/param norm = 3.4836e-01, time/batch = 15.5365s	
7332/11850 (epoch 30.937), train_loss = 1.07890182, grad/param norm = 2.6602e-01, time/batch = 16.1718s	
7333/11850 (epoch 30.941), train_loss = 1.05652661, grad/param norm = 2.7240e-01, time/batch = 15.5521s	
7334/11850 (epoch 30.945), train_loss = 1.09204446, grad/param norm = 2.7418e-01, time/batch = 18.2081s	
7335/11850 (epoch 30.949), train_loss = 0.96215287, grad/param norm = 2.6811e-01, time/batch = 18.7898s	
7336/11850 (epoch 30.954), train_loss = 1.07318034, grad/param norm = 3.0870e-01, time/batch = 17.6479s	
7337/11850 (epoch 30.958), train_loss = 1.05003992, grad/param norm = 2.6626e-01, time/batch = 17.2219s	
7338/11850 (epoch 30.962), train_loss = 0.96448873, grad/param norm = 3.0485e-01, time/batch = 17.4642s	
7339/11850 (epoch 30.966), train_loss = 0.91407433, grad/param norm = 2.7690e-01, time/batch = 18.2995s	
7340/11850 (epoch 30.970), train_loss = 1.04124447, grad/param norm = 2.8941e-01, time/batch = 17.8855s	
7341/11850 (epoch 30.975), train_loss = 0.98722579, grad/param norm = 3.0129e-01, time/batch = 17.2834s	
7342/11850 (epoch 30.979), train_loss = 1.01376219, grad/param norm = 2.8063e-01, time/batch = 17.9778s	
7343/11850 (epoch 30.983), train_loss = 1.11640579, grad/param norm = 3.3997e-01, time/batch = 16.2178s	
7344/11850 (epoch 30.987), train_loss = 0.95540875, grad/param norm = 3.0367e-01, time/batch = 18.5540s	
7345/11850 (epoch 30.992), train_loss = 1.13347313, grad/param norm = 3.1930e-01, time/batch = 16.8664s	
7346/11850 (epoch 30.996), train_loss = 1.13671690, grad/param norm = 3.0035e-01, time/batch = 17.3864s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
7347/11850 (epoch 31.000), train_loss = 1.03375253, grad/param norm = 4.2889e-01, time/batch = 16.6243s	
7348/11850 (epoch 31.004), train_loss = 1.05882080, grad/param norm = 2.9263e-01, time/batch = 17.0441s	
7349/11850 (epoch 31.008), train_loss = 1.12802505, grad/param norm = 3.1230e-01, time/batch = 18.7149s	
7350/11850 (epoch 31.013), train_loss = 1.12388163, grad/param norm = 2.9771e-01, time/batch = 17.5519s	
7351/11850 (epoch 31.017), train_loss = 1.16635826, grad/param norm = 3.2177e-01, time/batch = 16.1315s	
7352/11850 (epoch 31.021), train_loss = 1.08462741, grad/param norm = 2.5393e-01, time/batch = 18.6932s	
7353/11850 (epoch 31.025), train_loss = 0.97395106, grad/param norm = 2.5695e-01, time/batch = 17.7300s	
7354/11850 (epoch 31.030), train_loss = 1.00455746, grad/param norm = 3.1202e-01, time/batch = 17.1462s	
7355/11850 (epoch 31.034), train_loss = 0.98854641, grad/param norm = 2.5793e-01, time/batch = 16.2165s	
7356/11850 (epoch 31.038), train_loss = 1.02230559, grad/param norm = 2.5796e-01, time/batch = 18.2924s	
7357/11850 (epoch 31.042), train_loss = 1.05427779, grad/param norm = 2.7914e-01, time/batch = 18.8025s	
7358/11850 (epoch 31.046), train_loss = 1.00275376, grad/param norm = 3.3338e-01, time/batch = 17.1291s	
7359/11850 (epoch 31.051), train_loss = 1.03300137, grad/param norm = 2.8175e-01, time/batch = 18.3805s	
7360/11850 (epoch 31.055), train_loss = 0.98265681, grad/param norm = 2.7016e-01, time/batch = 16.3857s	
7361/11850 (epoch 31.059), train_loss = 1.08495957, grad/param norm = 2.6588e-01, time/batch = 19.1321s	
7362/11850 (epoch 31.063), train_loss = 1.09031801, grad/param norm = 2.9017e-01, time/batch = 16.0237s	
7363/11850 (epoch 31.068), train_loss = 1.02298360, grad/param norm = 2.5513e-01, time/batch = 18.3006s	
7364/11850 (epoch 31.072), train_loss = 1.07829564, grad/param norm = 2.7421e-01, time/batch = 17.2314s	
7365/11850 (epoch 31.076), train_loss = 1.15203570, grad/param norm = 2.8253e-01, time/batch = 17.1300s	
7366/11850 (epoch 31.080), train_loss = 0.96636582, grad/param norm = 2.5617e-01, time/batch = 15.8594s	
7367/11850 (epoch 31.084), train_loss = 0.91910689, grad/param norm = 2.5109e-01, time/batch = 18.8753s	
7368/11850 (epoch 31.089), train_loss = 0.93284219, grad/param norm = 3.0379e-01, time/batch = 19.2075s	
7369/11850 (epoch 31.093), train_loss = 0.92949867, grad/param norm = 2.6605e-01, time/batch = 16.7818s	
7370/11850 (epoch 31.097), train_loss = 1.04470084, grad/param norm = 2.9153e-01, time/batch = 18.5479s	
7371/11850 (epoch 31.101), train_loss = 0.95428455, grad/param norm = 3.0433e-01, time/batch = 18.3599s	
7372/11850 (epoch 31.105), train_loss = 0.92523198, grad/param norm = 2.5972e-01, time/batch = 16.2794s	
7373/11850 (epoch 31.110), train_loss = 1.07144066, grad/param norm = 2.6390e-01, time/batch = 18.8553s	
7374/11850 (epoch 31.114), train_loss = 0.98191765, grad/param norm = 2.9197e-01, time/batch = 17.7212s	
7375/11850 (epoch 31.118), train_loss = 1.07706535, grad/param norm = 2.6261e-01, time/batch = 16.0461s	
7376/11850 (epoch 31.122), train_loss = 1.12329693, grad/param norm = 2.9997e-01, time/batch = 16.3060s	
7377/11850 (epoch 31.127), train_loss = 1.05096391, grad/param norm = 2.7660e-01, time/batch = 17.9707s	
7378/11850 (epoch 31.131), train_loss = 1.01910443, grad/param norm = 3.2640e-01, time/batch = 18.7039s	
7379/11850 (epoch 31.135), train_loss = 0.99724325, grad/param norm = 2.7475e-01, time/batch = 15.1268s	
7380/11850 (epoch 31.139), train_loss = 1.00970478, grad/param norm = 2.7498e-01, time/batch = 16.9421s	
7381/11850 (epoch 31.143), train_loss = 0.99702119, grad/param norm = 2.8923e-01, time/batch = 18.9710s	
7382/11850 (epoch 31.148), train_loss = 0.98843503, grad/param norm = 2.8600e-01, time/batch = 16.9593s	
7383/11850 (epoch 31.152), train_loss = 1.09814272, grad/param norm = 2.9624e-01, time/batch = 18.5394s	
7384/11850 (epoch 31.156), train_loss = 0.99846939, grad/param norm = 3.6363e-01, time/batch = 18.1435s	
7385/11850 (epoch 31.160), train_loss = 1.20928346, grad/param norm = 4.4810e-01, time/batch = 18.5421s	
7386/11850 (epoch 31.165), train_loss = 1.14017596, grad/param norm = 3.4424e-01, time/batch = 18.6328s	
7387/11850 (epoch 31.169), train_loss = 1.00067231, grad/param norm = 3.0456e-01, time/batch = 17.1436s	
7388/11850 (epoch 31.173), train_loss = 1.06930624, grad/param norm = 2.6557e-01, time/batch = 19.2150s	
7389/11850 (epoch 31.177), train_loss = 0.93369171, grad/param norm = 3.1776e-01, time/batch = 16.6273s	
7390/11850 (epoch 31.181), train_loss = 1.06866637, grad/param norm = 2.5607e-01, time/batch = 19.1388s	
7391/11850 (epoch 31.186), train_loss = 1.15737205, grad/param norm = 3.6926e-01, time/batch = 15.4439s	
7392/11850 (epoch 31.190), train_loss = 1.05214574, grad/param norm = 2.6586e-01, time/batch = 16.9447s	
7393/11850 (epoch 31.194), train_loss = 1.10226347, grad/param norm = 3.5043e-01, time/batch = 18.4713s	
7394/11850 (epoch 31.198), train_loss = 0.85943497, grad/param norm = 2.6039e-01, time/batch = 17.7982s	
7395/11850 (epoch 31.203), train_loss = 0.89613600, grad/param norm = 2.5743e-01, time/batch = 17.6345s	
7396/11850 (epoch 31.207), train_loss = 1.06935817, grad/param norm = 2.8832e-01, time/batch = 15.9406s	
7397/11850 (epoch 31.211), train_loss = 1.02879236, grad/param norm = 2.7744e-01, time/batch = 18.8009s	
7398/11850 (epoch 31.215), train_loss = 1.03561622, grad/param norm = 3.1487e-01, time/batch = 18.1159s	
7399/11850 (epoch 31.219), train_loss = 1.05023798, grad/param norm = 2.7510e-01, time/batch = 15.8752s	
7400/11850 (epoch 31.224), train_loss = 1.18082914, grad/param norm = 2.9175e-01, time/batch = 16.9601s	
7401/11850 (epoch 31.228), train_loss = 1.06673150, grad/param norm = 2.7938e-01, time/batch = 19.2118s	
7402/11850 (epoch 31.232), train_loss = 1.04545495, grad/param norm = 2.9525e-01, time/batch = 17.5364s	
7403/11850 (epoch 31.236), train_loss = 0.95336864, grad/param norm = 3.0963e-01, time/batch = 18.9628s	
7404/11850 (epoch 31.241), train_loss = 1.07133628, grad/param norm = 3.0636e-01, time/batch = 18.4717s	
7405/11850 (epoch 31.245), train_loss = 1.10088322, grad/param norm = 2.7117e-01, time/batch = 18.6415s	
7406/11850 (epoch 31.249), train_loss = 1.00699453, grad/param norm = 2.5776e-01, time/batch = 17.3889s	
7407/11850 (epoch 31.253), train_loss = 1.02576813, grad/param norm = 2.9115e-01, time/batch = 16.0594s	
7408/11850 (epoch 31.257), train_loss = 1.14440564, grad/param norm = 2.9674e-01, time/batch = 17.8075s	
7409/11850 (epoch 31.262), train_loss = 1.17429059, grad/param norm = 3.6706e-01, time/batch = 14.9355s	
7410/11850 (epoch 31.266), train_loss = 1.13257254, grad/param norm = 3.3331e-01, time/batch = 18.2893s	
7411/11850 (epoch 31.270), train_loss = 1.02328320, grad/param norm = 2.5900e-01, time/batch = 17.1373s	
7412/11850 (epoch 31.274), train_loss = 1.02464495, grad/param norm = 2.8442e-01, time/batch = 18.5502s	
7413/11850 (epoch 31.278), train_loss = 0.88629363, grad/param norm = 2.6154e-01, time/batch = 15.0325s	
7414/11850 (epoch 31.283), train_loss = 1.01498905, grad/param norm = 2.6854e-01, time/batch = 17.1513s	
7415/11850 (epoch 31.287), train_loss = 1.12914545, grad/param norm = 2.6233e-01, time/batch = 18.0445s	
7416/11850 (epoch 31.291), train_loss = 1.00674873, grad/param norm = 2.6305e-01, time/batch = 17.3693s	
7417/11850 (epoch 31.295), train_loss = 1.08590757, grad/param norm = 2.7522e-01, time/batch = 18.0539s	
7418/11850 (epoch 31.300), train_loss = 0.99244162, grad/param norm = 2.8587e-01, time/batch = 17.6128s	
7419/11850 (epoch 31.304), train_loss = 1.02318272, grad/param norm = 2.8005e-01, time/batch = 17.6382s	
7420/11850 (epoch 31.308), train_loss = 1.00050759, grad/param norm = 2.4945e-01, time/batch = 18.2955s	
7421/11850 (epoch 31.312), train_loss = 0.91788566, grad/param norm = 2.5624e-01, time/batch = 18.1351s	
7422/11850 (epoch 31.316), train_loss = 1.05991751, grad/param norm = 2.8626e-01, time/batch = 17.7275s	
7423/11850 (epoch 31.321), train_loss = 1.00782307, grad/param norm = 2.6700e-01, time/batch = 16.6281s	
7424/11850 (epoch 31.325), train_loss = 1.02560135, grad/param norm = 2.5681e-01, time/batch = 17.2331s	
7425/11850 (epoch 31.329), train_loss = 1.03307358, grad/param norm = 3.0334e-01, time/batch = 18.1433s	
7426/11850 (epoch 31.333), train_loss = 0.99597193, grad/param norm = 2.7993e-01, time/batch = 16.9678s	
7427/11850 (epoch 31.338), train_loss = 0.96767846, grad/param norm = 2.4421e-01, time/batch = 17.2876s	
7428/11850 (epoch 31.342), train_loss = 1.02219460, grad/param norm = 2.7470e-01, time/batch = 16.2179s	
7429/11850 (epoch 31.346), train_loss = 1.00450692, grad/param norm = 2.9156e-01, time/batch = 15.8883s	
7430/11850 (epoch 31.350), train_loss = 0.90968515, grad/param norm = 2.5744e-01, time/batch = 14.8124s	
7431/11850 (epoch 31.354), train_loss = 1.08440716, grad/param norm = 2.5995e-01, time/batch = 17.2348s	
7432/11850 (epoch 31.359), train_loss = 1.13906606, grad/param norm = 2.8623e-01, time/batch = 16.4759s	
7433/11850 (epoch 31.363), train_loss = 1.06678607, grad/param norm = 2.7450e-01, time/batch = 16.9800s	
7434/11850 (epoch 31.367), train_loss = 1.08684541, grad/param norm = 2.5498e-01, time/batch = 18.4719s	
7435/11850 (epoch 31.371), train_loss = 1.06986796, grad/param norm = 2.6005e-01, time/batch = 17.4623s	
7436/11850 (epoch 31.376), train_loss = 1.00767653, grad/param norm = 3.0162e-01, time/batch = 18.1234s	
7437/11850 (epoch 31.380), train_loss = 0.99094057, grad/param norm = 2.4947e-01, time/batch = 16.5280s	
7438/11850 (epoch 31.384), train_loss = 0.94266763, grad/param norm = 2.7043e-01, time/batch = 17.7805s	
7439/11850 (epoch 31.388), train_loss = 1.09946611, grad/param norm = 2.9311e-01, time/batch = 15.5552s	
7440/11850 (epoch 31.392), train_loss = 1.07049217, grad/param norm = 2.7225e-01, time/batch = 16.2228s	
7441/11850 (epoch 31.397), train_loss = 1.08550120, grad/param norm = 2.8407e-01, time/batch = 17.6306s	
7442/11850 (epoch 31.401), train_loss = 0.90661108, grad/param norm = 2.2926e-01, time/batch = 18.6298s	
7443/11850 (epoch 31.405), train_loss = 0.95900033, grad/param norm = 2.6119e-01, time/batch = 17.7227s	
7444/11850 (epoch 31.409), train_loss = 1.09251345, grad/param norm = 2.7895e-01, time/batch = 16.4662s	
7445/11850 (epoch 31.414), train_loss = 0.86639042, grad/param norm = 2.2312e-01, time/batch = 17.6414s	
7446/11850 (epoch 31.418), train_loss = 0.91857245, grad/param norm = 2.6044e-01, time/batch = 17.9659s	
7447/11850 (epoch 31.422), train_loss = 0.85859557, grad/param norm = 2.7132e-01, time/batch = 16.8626s	
7448/11850 (epoch 31.426), train_loss = 0.84943534, grad/param norm = 2.5284e-01, time/batch = 18.4634s	
7449/11850 (epoch 31.430), train_loss = 0.92034174, grad/param norm = 2.6191e-01, time/batch = 14.2558s	
7450/11850 (epoch 31.435), train_loss = 0.95122207, grad/param norm = 2.7771e-01, time/batch = 18.6278s	
7451/11850 (epoch 31.439), train_loss = 1.04355203, grad/param norm = 2.5012e-01, time/batch = 16.1036s	
7452/11850 (epoch 31.443), train_loss = 0.98213526, grad/param norm = 2.5165e-01, time/batch = 18.9776s	
7453/11850 (epoch 31.447), train_loss = 0.90865156, grad/param norm = 2.6088e-01, time/batch = 19.4523s	
7454/11850 (epoch 31.451), train_loss = 0.90868209, grad/param norm = 2.7187e-01, time/batch = 14.7038s	
7455/11850 (epoch 31.456), train_loss = 1.00136315, grad/param norm = 2.9119e-01, time/batch = 18.1283s	
7456/11850 (epoch 31.460), train_loss = 1.07224075, grad/param norm = 2.6925e-01, time/batch = 17.5554s	
7457/11850 (epoch 31.464), train_loss = 0.94841505, grad/param norm = 2.9753e-01, time/batch = 18.3022s	
7458/11850 (epoch 31.468), train_loss = 1.03104151, grad/param norm = 2.5816e-01, time/batch = 16.4690s	
7459/11850 (epoch 31.473), train_loss = 1.07894486, grad/param norm = 3.0321e-01, time/batch = 18.1355s	
7460/11850 (epoch 31.477), train_loss = 0.91555589, grad/param norm = 2.7416e-01, time/batch = 17.9810s	
7461/11850 (epoch 31.481), train_loss = 0.95807821, grad/param norm = 2.9100e-01, time/batch = 16.0503s	
7462/11850 (epoch 31.485), train_loss = 0.89456120, grad/param norm = 2.3648e-01, time/batch = 18.4634s	
7463/11850 (epoch 31.489), train_loss = 1.02541303, grad/param norm = 2.5839e-01, time/batch = 17.1461s	
7464/11850 (epoch 31.494), train_loss = 0.90501747, grad/param norm = 2.6769e-01, time/batch = 17.7932s	
7465/11850 (epoch 31.498), train_loss = 0.91058668, grad/param norm = 2.5973e-01, time/batch = 15.9493s	
7466/11850 (epoch 31.502), train_loss = 0.88667872, grad/param norm = 2.8812e-01, time/batch = 15.3745s	
7467/11850 (epoch 31.506), train_loss = 1.15825594, grad/param norm = 2.8886e-01, time/batch = 17.5718s	
7468/11850 (epoch 31.511), train_loss = 0.99693485, grad/param norm = 2.6389e-01, time/batch = 17.8791s	
7469/11850 (epoch 31.515), train_loss = 1.10156804, grad/param norm = 3.2908e-01, time/batch = 18.6382s	
7470/11850 (epoch 31.519), train_loss = 0.95756880, grad/param norm = 2.5749e-01, time/batch = 17.7285s	
7471/11850 (epoch 31.523), train_loss = 0.99811655, grad/param norm = 2.5544e-01, time/batch = 17.0511s	
7472/11850 (epoch 31.527), train_loss = 0.93736084, grad/param norm = 2.6043e-01, time/batch = 16.2775s	
7473/11850 (epoch 31.532), train_loss = 1.03271686, grad/param norm = 2.6491e-01, time/batch = 16.9850s	
7474/11850 (epoch 31.536), train_loss = 0.97083791, grad/param norm = 2.6099e-01, time/batch = 17.1482s	
7475/11850 (epoch 31.540), train_loss = 0.92564881, grad/param norm = 2.6046e-01, time/batch = 16.4751s	
7476/11850 (epoch 31.544), train_loss = 0.92280123, grad/param norm = 3.1842e-01, time/batch = 17.0572s	
7477/11850 (epoch 31.549), train_loss = 0.86554158, grad/param norm = 2.8096e-01, time/batch = 17.2224s	
7478/11850 (epoch 31.553), train_loss = 1.01385835, grad/param norm = 2.7678e-01, time/batch = 16.8716s	
7479/11850 (epoch 31.557), train_loss = 1.04284725, grad/param norm = 3.6673e-01, time/batch = 17.2840s	
7480/11850 (epoch 31.561), train_loss = 1.05240459, grad/param norm = 3.4769e-01, time/batch = 14.0169s	
7481/11850 (epoch 31.565), train_loss = 1.14582964, grad/param norm = 2.9504e-01, time/batch = 15.9718s	
7482/11850 (epoch 31.570), train_loss = 1.02254164, grad/param norm = 2.7999e-01, time/batch = 16.3799s	
7483/11850 (epoch 31.574), train_loss = 1.05207878, grad/param norm = 2.9803e-01, time/batch = 17.3673s	
7484/11850 (epoch 31.578), train_loss = 1.07973071, grad/param norm = 3.1477e-01, time/batch = 18.4745s	
7485/11850 (epoch 31.582), train_loss = 0.95776727, grad/param norm = 2.7980e-01, time/batch = 17.8727s	
7486/11850 (epoch 31.586), train_loss = 0.97612930, grad/param norm = 2.6957e-01, time/batch = 16.9628s	
7487/11850 (epoch 31.591), train_loss = 1.03160899, grad/param norm = 2.8333e-01, time/batch = 17.1335s	
7488/11850 (epoch 31.595), train_loss = 0.88410296, grad/param norm = 2.5238e-01, time/batch = 16.9633s	
7489/11850 (epoch 31.599), train_loss = 0.99969221, grad/param norm = 2.7719e-01, time/batch = 15.6059s	
7490/11850 (epoch 31.603), train_loss = 0.94511845, grad/param norm = 2.3176e-01, time/batch = 16.3049s	
7491/11850 (epoch 31.608), train_loss = 1.13136172, grad/param norm = 2.7389e-01, time/batch = 18.6289s	
7492/11850 (epoch 31.612), train_loss = 1.19589453, grad/param norm = 2.9977e-01, time/batch = 17.8770s	
7493/11850 (epoch 31.616), train_loss = 1.11312396, grad/param norm = 2.7294e-01, time/batch = 18.4644s	
7494/11850 (epoch 31.620), train_loss = 1.01828058, grad/param norm = 2.9624e-01, time/batch = 16.9652s	
7495/11850 (epoch 31.624), train_loss = 1.01387054, grad/param norm = 2.9823e-01, time/batch = 19.2097s	
7496/11850 (epoch 31.629), train_loss = 0.96349657, grad/param norm = 2.7670e-01, time/batch = 16.4541s	
7497/11850 (epoch 31.633), train_loss = 0.88265215, grad/param norm = 2.4497e-01, time/batch = 18.2209s	
7498/11850 (epoch 31.637), train_loss = 0.83678103, grad/param norm = 2.5743e-01, time/batch = 17.0456s	
7499/11850 (epoch 31.641), train_loss = 0.89156342, grad/param norm = 2.4360e-01, time/batch = 16.7984s	
7500/11850 (epoch 31.646), train_loss = 0.90369086, grad/param norm = 2.7371e-01, time/batch = 18.3680s	
7501/11850 (epoch 31.650), train_loss = 0.99455561, grad/param norm = 2.8431e-01, time/batch = 19.0390s	
7502/11850 (epoch 31.654), train_loss = 0.93022667, grad/param norm = 2.9862e-01, time/batch = 18.3668s	
7503/11850 (epoch 31.658), train_loss = 1.01510538, grad/param norm = 2.7450e-01, time/batch = 18.4532s	
7504/11850 (epoch 31.662), train_loss = 0.87241009, grad/param norm = 2.8894e-01, time/batch = 18.3903s	
7505/11850 (epoch 31.667), train_loss = 1.08452596, grad/param norm = 2.9594e-01, time/batch = 15.2142s	
7506/11850 (epoch 31.671), train_loss = 0.96757285, grad/param norm = 2.7559e-01, time/batch = 16.6822s	
7507/11850 (epoch 31.675), train_loss = 0.95879025, grad/param norm = 2.6818e-01, time/batch = 18.4439s	
7508/11850 (epoch 31.679), train_loss = 1.00264911, grad/param norm = 2.8374e-01, time/batch = 17.7184s	
7509/11850 (epoch 31.684), train_loss = 0.96480077, grad/param norm = 2.7857e-01, time/batch = 17.1303s	
7510/11850 (epoch 31.688), train_loss = 0.92756854, grad/param norm = 2.6505e-01, time/batch = 16.2429s	
7511/11850 (epoch 31.692), train_loss = 0.93590171, grad/param norm = 3.1248e-01, time/batch = 17.2354s	
7512/11850 (epoch 31.696), train_loss = 0.90075862, grad/param norm = 2.8201e-01, time/batch = 18.1271s	
7513/11850 (epoch 31.700), train_loss = 0.99179864, grad/param norm = 2.6276e-01, time/batch = 13.7570s	
7514/11850 (epoch 31.705), train_loss = 0.93687917, grad/param norm = 2.8440e-01, time/batch = 0.6855s	
7515/11850 (epoch 31.709), train_loss = 0.85012805, grad/param norm = 2.6047e-01, time/batch = 0.6401s	
7516/11850 (epoch 31.713), train_loss = 0.87663325, grad/param norm = 3.0619e-01, time/batch = 0.6422s	
7517/11850 (epoch 31.717), train_loss = 0.93933394, grad/param norm = 2.5924e-01, time/batch = 0.6358s	
7518/11850 (epoch 31.722), train_loss = 1.00884358, grad/param norm = 3.3272e-01, time/batch = 0.6388s	
7519/11850 (epoch 31.726), train_loss = 0.90090601, grad/param norm = 3.1310e-01, time/batch = 0.6388s	
7520/11850 (epoch 31.730), train_loss = 0.90731260, grad/param norm = 3.2897e-01, time/batch = 0.6907s	
7521/11850 (epoch 31.734), train_loss = 0.93388481, grad/param norm = 2.6754e-01, time/batch = 0.9305s	
7522/11850 (epoch 31.738), train_loss = 1.04408453, grad/param norm = 3.1602e-01, time/batch = 0.9357s	
7523/11850 (epoch 31.743), train_loss = 0.98765583, grad/param norm = 2.7018e-01, time/batch = 0.9723s	
7524/11850 (epoch 31.747), train_loss = 0.87017411, grad/param norm = 2.2376e-01, time/batch = 0.9617s	
7525/11850 (epoch 31.751), train_loss = 0.93013801, grad/param norm = 2.4036e-01, time/batch = 0.9508s	
7526/11850 (epoch 31.755), train_loss = 0.99543835, grad/param norm = 2.7120e-01, time/batch = 1.7398s	
7527/11850 (epoch 31.759), train_loss = 0.92410731, grad/param norm = 2.6988e-01, time/batch = 1.7549s	
7528/11850 (epoch 31.764), train_loss = 0.95201144, grad/param norm = 2.7944e-01, time/batch = 3.7155s	
7529/11850 (epoch 31.768), train_loss = 0.87295116, grad/param norm = 2.5413e-01, time/batch = 16.8772s	
7530/11850 (epoch 31.772), train_loss = 0.94810791, grad/param norm = 4.8989e-01, time/batch = 18.2182s	
7531/11850 (epoch 31.776), train_loss = 1.02837581, grad/param norm = 2.9228e-01, time/batch = 17.6891s	
7532/11850 (epoch 31.781), train_loss = 0.97405976, grad/param norm = 3.1186e-01, time/batch = 17.2939s	
7533/11850 (epoch 31.785), train_loss = 0.93479229, grad/param norm = 2.7716e-01, time/batch = 19.2092s	
7534/11850 (epoch 31.789), train_loss = 0.95673079, grad/param norm = 2.5785e-01, time/batch = 17.6196s	
7535/11850 (epoch 31.793), train_loss = 1.03227092, grad/param norm = 3.0497e-01, time/batch = 17.9629s	
7536/11850 (epoch 31.797), train_loss = 0.97046643, grad/param norm = 2.6917e-01, time/batch = 19.0432s	
7537/11850 (epoch 31.802), train_loss = 0.89931110, grad/param norm = 2.7680e-01, time/batch = 17.7180s	
7538/11850 (epoch 31.806), train_loss = 0.96964301, grad/param norm = 2.7538e-01, time/batch = 18.5256s	
7539/11850 (epoch 31.810), train_loss = 1.03797850, grad/param norm = 2.8794e-01, time/batch = 18.5518s	
7540/11850 (epoch 31.814), train_loss = 0.97968193, grad/param norm = 2.5999e-01, time/batch = 17.5402s	
7541/11850 (epoch 31.819), train_loss = 1.08509942, grad/param norm = 2.9774e-01, time/batch = 18.4702s	
7542/11850 (epoch 31.823), train_loss = 1.09698531, grad/param norm = 2.8647e-01, time/batch = 18.7144s	
7543/11850 (epoch 31.827), train_loss = 0.98733582, grad/param norm = 3.0351e-01, time/batch = 17.2269s	
7544/11850 (epoch 31.831), train_loss = 0.96727416, grad/param norm = 2.4872e-01, time/batch = 16.8521s	
7545/11850 (epoch 31.835), train_loss = 0.99867729, grad/param norm = 2.5177e-01, time/batch = 18.7965s	
7546/11850 (epoch 31.840), train_loss = 0.95029636, grad/param norm = 2.6227e-01, time/batch = 17.2162s	
7547/11850 (epoch 31.844), train_loss = 0.96999034, grad/param norm = 2.2754e-01, time/batch = 15.5243s	
7548/11850 (epoch 31.848), train_loss = 0.99399654, grad/param norm = 2.9687e-01, time/batch = 18.0288s	
7549/11850 (epoch 31.852), train_loss = 0.99887415, grad/param norm = 3.2056e-01, time/batch = 18.5608s	
7550/11850 (epoch 31.857), train_loss = 0.95440215, grad/param norm = 3.0970e-01, time/batch = 17.8808s	
7551/11850 (epoch 31.861), train_loss = 0.94406704, grad/param norm = 2.7186e-01, time/batch = 18.1416s	
7552/11850 (epoch 31.865), train_loss = 1.03513675, grad/param norm = 4.4080e-01, time/batch = 18.2271s	
7553/11850 (epoch 31.869), train_loss = 1.02822769, grad/param norm = 3.5744e-01, time/batch = 18.4713s	
7554/11850 (epoch 31.873), train_loss = 1.04106351, grad/param norm = 2.9168e-01, time/batch = 15.6367s	
7555/11850 (epoch 31.878), train_loss = 1.03723808, grad/param norm = 2.9971e-01, time/batch = 15.6379s	
7556/11850 (epoch 31.882), train_loss = 0.99435761, grad/param norm = 2.8811e-01, time/batch = 18.4688s	
7557/11850 (epoch 31.886), train_loss = 0.97125865, grad/param norm = 2.9989e-01, time/batch = 17.7977s	
7558/11850 (epoch 31.890), train_loss = 1.01230491, grad/param norm = 2.9277e-01, time/batch = 18.3012s	
7559/11850 (epoch 31.895), train_loss = 1.02627609, grad/param norm = 3.2381e-01, time/batch = 17.3001s	
7560/11850 (epoch 31.899), train_loss = 0.89366245, grad/param norm = 2.7757e-01, time/batch = 16.7205s	
7561/11850 (epoch 31.903), train_loss = 0.94741861, grad/param norm = 2.6340e-01, time/batch = 15.9385s	
7562/11850 (epoch 31.907), train_loss = 0.94090545, grad/param norm = 2.6660e-01, time/batch = 17.4764s	
7563/11850 (epoch 31.911), train_loss = 1.07462037, grad/param norm = 2.8823e-01, time/batch = 16.4466s	
7564/11850 (epoch 31.916), train_loss = 1.03315225, grad/param norm = 3.1243e-01, time/batch = 17.1368s	
7565/11850 (epoch 31.920), train_loss = 1.01541765, grad/param norm = 2.7761e-01, time/batch = 18.7820s	
7566/11850 (epoch 31.924), train_loss = 0.96388126, grad/param norm = 3.1474e-01, time/batch = 17.7298s	
7567/11850 (epoch 31.928), train_loss = 1.09225724, grad/param norm = 4.3883e-01, time/batch = 15.2807s	
7568/11850 (epoch 31.932), train_loss = 1.11234047, grad/param norm = 3.2982e-01, time/batch = 16.3001s	
7569/11850 (epoch 31.937), train_loss = 1.06660564, grad/param norm = 2.7585e-01, time/batch = 18.4615s	
7570/11850 (epoch 31.941), train_loss = 1.04375642, grad/param norm = 2.9265e-01, time/batch = 18.9568s	
7571/11850 (epoch 31.945), train_loss = 1.06048286, grad/param norm = 2.7410e-01, time/batch = 17.0334s	
7572/11850 (epoch 31.949), train_loss = 0.96171520, grad/param norm = 3.8190e-01, time/batch = 19.0566s	
7573/11850 (epoch 31.954), train_loss = 1.06744532, grad/param norm = 3.7906e-01, time/batch = 18.3947s	
7574/11850 (epoch 31.958), train_loss = 1.03932500, grad/param norm = 2.8046e-01, time/batch = 17.7131s	
7575/11850 (epoch 31.962), train_loss = 0.92980882, grad/param norm = 2.6545e-01, time/batch = 17.2846s	
7576/11850 (epoch 31.966), train_loss = 0.91252982, grad/param norm = 3.0451e-01, time/batch = 17.6485s	
7577/11850 (epoch 31.970), train_loss = 1.02849952, grad/param norm = 2.7674e-01, time/batch = 17.5642s	
7578/11850 (epoch 31.975), train_loss = 0.97060235, grad/param norm = 2.7100e-01, time/batch = 16.2245s	
7579/11850 (epoch 31.979), train_loss = 1.00257817, grad/param norm = 3.0053e-01, time/batch = 17.0599s	
7580/11850 (epoch 31.983), train_loss = 1.09646714, grad/param norm = 4.1686e-01, time/batch = 17.3643s	
7581/11850 (epoch 31.987), train_loss = 0.97520350, grad/param norm = 4.2337e-01, time/batch = 17.0984s	
7582/11850 (epoch 31.992), train_loss = 1.12659635, grad/param norm = 3.1365e-01, time/batch = 17.7015s	
7583/11850 (epoch 31.996), train_loss = 1.14348210, grad/param norm = 3.2381e-01, time/batch = 15.7929s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
7584/11850 (epoch 32.000), train_loss = 0.99863175, grad/param norm = 3.2773e-01, time/batch = 14.4980s	
7585/11850 (epoch 32.004), train_loss = 1.06939844, grad/param norm = 3.7418e-01, time/batch = 17.2139s	
7586/11850 (epoch 32.008), train_loss = 1.10140917, grad/param norm = 3.0407e-01, time/batch = 19.2119s	
7587/11850 (epoch 32.013), train_loss = 1.10324482, grad/param norm = 2.6636e-01, time/batch = 17.4749s	
7588/11850 (epoch 32.017), train_loss = 1.15391677, grad/param norm = 2.9557e-01, time/batch = 16.9786s	
7589/11850 (epoch 32.021), train_loss = 1.07737827, grad/param norm = 2.7543e-01, time/batch = 19.2087s	
7590/11850 (epoch 32.025), train_loss = 0.96098796, grad/param norm = 2.4801e-01, time/batch = 17.8753s	
7591/11850 (epoch 32.030), train_loss = 0.99634064, grad/param norm = 3.4808e-01, time/batch = 18.8790s	
7592/11850 (epoch 32.034), train_loss = 0.97246537, grad/param norm = 2.7369e-01, time/batch = 17.8721s	
7593/11850 (epoch 32.038), train_loss = 0.99888377, grad/param norm = 2.6281e-01, time/batch = 18.9797s	
7594/11850 (epoch 32.042), train_loss = 1.04423397, grad/param norm = 3.0264e-01, time/batch = 17.8668s	
7595/11850 (epoch 32.046), train_loss = 0.99575745, grad/param norm = 3.1813e-01, time/batch = 15.2933s	
7596/11850 (epoch 32.051), train_loss = 1.02295146, grad/param norm = 2.7370e-01, time/batch = 19.2109s	
7597/11850 (epoch 32.055), train_loss = 0.98468171, grad/param norm = 2.7223e-01, time/batch = 16.9775s	
7598/11850 (epoch 32.059), train_loss = 1.07513181, grad/param norm = 2.6511e-01, time/batch = 17.5424s	
7599/11850 (epoch 32.063), train_loss = 1.07717312, grad/param norm = 3.0085e-01, time/batch = 18.4469s	
7600/11850 (epoch 32.068), train_loss = 1.00910850, grad/param norm = 2.6525e-01, time/batch = 16.6492s	
7601/11850 (epoch 32.072), train_loss = 1.06955294, grad/param norm = 2.7435e-01, time/batch = 19.6325s	
7602/11850 (epoch 32.076), train_loss = 1.12812410, grad/param norm = 2.7346e-01, time/batch = 18.8497s	
7603/11850 (epoch 32.080), train_loss = 0.94797988, grad/param norm = 2.5789e-01, time/batch = 17.7208s	
7604/11850 (epoch 32.084), train_loss = 0.89355667, grad/param norm = 2.5256e-01, time/batch = 19.6287s	
7605/11850 (epoch 32.089), train_loss = 0.90725346, grad/param norm = 2.5250e-01, time/batch = 17.5408s	
7606/11850 (epoch 32.093), train_loss = 0.91078741, grad/param norm = 3.3843e-01, time/batch = 16.8552s	
7607/11850 (epoch 32.097), train_loss = 1.02203318, grad/param norm = 2.9222e-01, time/batch = 15.3963s	
7608/11850 (epoch 32.101), train_loss = 0.95995368, grad/param norm = 3.1965e-01, time/batch = 16.1441s	
7609/11850 (epoch 32.105), train_loss = 0.89636311, grad/param norm = 2.3725e-01, time/batch = 18.7982s	
7610/11850 (epoch 32.110), train_loss = 1.05334805, grad/param norm = 2.6961e-01, time/batch = 17.3019s	
7611/11850 (epoch 32.114), train_loss = 0.96010356, grad/param norm = 2.6206e-01, time/batch = 19.0430s	
7612/11850 (epoch 32.118), train_loss = 1.06719295, grad/param norm = 3.0421e-01, time/batch = 16.5328s	
7613/11850 (epoch 32.122), train_loss = 1.10267836, grad/param norm = 2.7644e-01, time/batch = 18.1517s	
7614/11850 (epoch 32.127), train_loss = 1.04092473, grad/param norm = 2.9115e-01, time/batch = 17.5647s	
7615/11850 (epoch 32.131), train_loss = 0.99425726, grad/param norm = 2.9830e-01, time/batch = 16.5366s	
7616/11850 (epoch 32.135), train_loss = 1.01258454, grad/param norm = 3.6090e-01, time/batch = 16.7795s	
7617/11850 (epoch 32.139), train_loss = 0.98356783, grad/param norm = 2.6707e-01, time/batch = 16.7334s	
7618/11850 (epoch 32.143), train_loss = 0.98527287, grad/param norm = 3.0541e-01, time/batch = 18.6362s	
7619/11850 (epoch 32.148), train_loss = 0.98038137, grad/param norm = 3.0951e-01, time/batch = 16.5487s	
7620/11850 (epoch 32.152), train_loss = 1.08441590, grad/param norm = 3.0822e-01, time/batch = 17.4737s	
7621/11850 (epoch 32.156), train_loss = 0.97662284, grad/param norm = 3.2059e-01, time/batch = 18.8718s	
7622/11850 (epoch 32.160), train_loss = 1.18998343, grad/param norm = 3.5573e-01, time/batch = 16.6371s	
7623/11850 (epoch 32.165), train_loss = 1.13569829, grad/param norm = 3.8947e-01, time/batch = 19.1300s	
7624/11850 (epoch 32.169), train_loss = 1.00507471, grad/param norm = 3.8802e-01, time/batch = 18.9624s	
7625/11850 (epoch 32.173), train_loss = 1.07952459, grad/param norm = 3.6507e-01, time/batch = 17.5507s	
7626/11850 (epoch 32.177), train_loss = 0.94263062, grad/param norm = 3.2923e-01, time/batch = 17.6141s	
7627/11850 (epoch 32.181), train_loss = 1.05942713, grad/param norm = 2.9275e-01, time/batch = 18.3886s	
7628/11850 (epoch 32.186), train_loss = 1.13165297, grad/param norm = 3.3989e-01, time/batch = 17.5640s	
7629/11850 (epoch 32.190), train_loss = 1.03718995, grad/param norm = 2.7017e-01, time/batch = 16.2789s	
7630/11850 (epoch 32.194), train_loss = 1.07513432, grad/param norm = 3.8145e-01, time/batch = 16.3215s	
7631/11850 (epoch 32.198), train_loss = 0.84713584, grad/param norm = 2.9326e-01, time/batch = 14.9660s	
7632/11850 (epoch 32.203), train_loss = 0.88679384, grad/param norm = 2.7284e-01, time/batch = 16.7851s	
7633/11850 (epoch 32.207), train_loss = 1.05280131, grad/param norm = 3.3139e-01, time/batch = 15.7084s	
7634/11850 (epoch 32.211), train_loss = 1.01460203, grad/param norm = 3.0277e-01, time/batch = 18.6279s	
7635/11850 (epoch 32.215), train_loss = 1.01825920, grad/param norm = 3.4656e-01, time/batch = 18.3013s	
7636/11850 (epoch 32.219), train_loss = 1.04604332, grad/param norm = 2.9281e-01, time/batch = 18.2808s	
7637/11850 (epoch 32.224), train_loss = 1.17507189, grad/param norm = 3.2971e-01, time/batch = 19.2926s	
7638/11850 (epoch 32.228), train_loss = 1.04724761, grad/param norm = 2.8967e-01, time/batch = 16.7280s	
7639/11850 (epoch 32.232), train_loss = 1.03986879, grad/param norm = 3.0368e-01, time/batch = 17.5520s	
7640/11850 (epoch 32.236), train_loss = 0.94167183, grad/param norm = 3.1066e-01, time/batch = 16.3999s	
7641/11850 (epoch 32.241), train_loss = 1.06631539, grad/param norm = 3.2823e-01, time/batch = 18.7982s	
7642/11850 (epoch 32.245), train_loss = 1.07643685, grad/param norm = 2.6779e-01, time/batch = 17.9554s	
7643/11850 (epoch 32.249), train_loss = 0.99509672, grad/param norm = 2.7634e-01, time/batch = 17.4839s	
7644/11850 (epoch 32.253), train_loss = 1.00920506, grad/param norm = 3.2866e-01, time/batch = 17.3062s	
7645/11850 (epoch 32.257), train_loss = 1.13676753, grad/param norm = 2.9004e-01, time/batch = 18.7956s	
7646/11850 (epoch 32.262), train_loss = 1.14482384, grad/param norm = 3.0362e-01, time/batch = 16.9339s	
7647/11850 (epoch 32.266), train_loss = 1.11877545, grad/param norm = 3.0479e-01, time/batch = 15.4427s	
7648/11850 (epoch 32.270), train_loss = 1.00175304, grad/param norm = 2.6206e-01, time/batch = 16.8049s	
7649/11850 (epoch 32.274), train_loss = 1.01915479, grad/param norm = 3.4093e-01, time/batch = 17.6263s	
7650/11850 (epoch 32.278), train_loss = 0.89387395, grad/param norm = 3.1845e-01, time/batch = 17.3638s	
7651/11850 (epoch 32.283), train_loss = 1.00980624, grad/param norm = 2.7570e-01, time/batch = 18.4586s	
7652/11850 (epoch 32.287), train_loss = 1.12972754, grad/param norm = 2.8678e-01, time/batch = 19.1372s	
7653/11850 (epoch 32.291), train_loss = 0.99034480, grad/param norm = 2.8734e-01, time/batch = 18.7006s	
7654/11850 (epoch 32.295), train_loss = 1.06551628, grad/param norm = 2.9001e-01, time/batch = 17.8899s	
7655/11850 (epoch 32.300), train_loss = 0.97365109, grad/param norm = 3.1545e-01, time/batch = 19.1307s	
7656/11850 (epoch 32.304), train_loss = 0.99965099, grad/param norm = 2.4484e-01, time/batch = 15.1983s	
7657/11850 (epoch 32.308), train_loss = 0.97416966, grad/param norm = 2.3329e-01, time/batch = 17.8071s	
7658/11850 (epoch 32.312), train_loss = 0.89991006, grad/param norm = 2.4345e-01, time/batch = 18.2957s	
7659/11850 (epoch 32.316), train_loss = 1.03348094, grad/param norm = 2.6374e-01, time/batch = 17.6382s	
7660/11850 (epoch 32.321), train_loss = 0.98956250, grad/param norm = 2.7626e-01, time/batch = 18.9696s	
7661/11850 (epoch 32.325), train_loss = 1.00815674, grad/param norm = 2.6550e-01, time/batch = 16.8742s	
7662/11850 (epoch 32.329), train_loss = 1.01090197, grad/param norm = 3.4555e-01, time/batch = 17.2183s	
7663/11850 (epoch 32.333), train_loss = 0.98025654, grad/param norm = 2.6932e-01, time/batch = 15.8433s	
7664/11850 (epoch 32.338), train_loss = 0.95517373, grad/param norm = 2.5483e-01, time/batch = 18.4569s	
7665/11850 (epoch 32.342), train_loss = 0.99205701, grad/param norm = 2.8196e-01, time/batch = 17.3858s	
7666/11850 (epoch 32.346), train_loss = 0.98467134, grad/param norm = 3.0233e-01, time/batch = 16.1396s	
7667/11850 (epoch 32.350), train_loss = 0.88886462, grad/param norm = 2.5885e-01, time/batch = 18.8719s	
7668/11850 (epoch 32.354), train_loss = 1.06512561, grad/param norm = 2.6219e-01, time/batch = 15.4625s	
7669/11850 (epoch 32.359), train_loss = 1.11504360, grad/param norm = 2.8136e-01, time/batch = 17.7250s	
7670/11850 (epoch 32.363), train_loss = 1.03622688, grad/param norm = 2.6363e-01, time/batch = 18.6949s	
7671/11850 (epoch 32.367), train_loss = 1.06303449, grad/param norm = 2.6765e-01, time/batch = 15.9654s	
7672/11850 (epoch 32.371), train_loss = 1.05244211, grad/param norm = 2.5393e-01, time/batch = 18.5433s	
7673/11850 (epoch 32.376), train_loss = 0.99984286, grad/param norm = 2.7778e-01, time/batch = 16.3704s	
7674/11850 (epoch 32.380), train_loss = 0.98161883, grad/param norm = 2.8064e-01, time/batch = 19.6271s	
7675/11850 (epoch 32.384), train_loss = 0.92334920, grad/param norm = 2.6262e-01, time/batch = 18.4739s	
7676/11850 (epoch 32.388), train_loss = 1.08000179, grad/param norm = 3.0562e-01, time/batch = 18.2005s	
7677/11850 (epoch 32.392), train_loss = 1.03116459, grad/param norm = 2.5332e-01, time/batch = 18.3007s	
7678/11850 (epoch 32.397), train_loss = 1.05966531, grad/param norm = 2.8903e-01, time/batch = 18.0629s	
7679/11850 (epoch 32.401), train_loss = 0.89150077, grad/param norm = 2.4352e-01, time/batch = 18.1333s	
7680/11850 (epoch 32.405), train_loss = 0.93254685, grad/param norm = 2.6098e-01, time/batch = 17.1058s	
7681/11850 (epoch 32.409), train_loss = 1.07421191, grad/param norm = 2.8847e-01, time/batch = 18.4683s	
7682/11850 (epoch 32.414), train_loss = 0.85012211, grad/param norm = 2.4161e-01, time/batch = 17.7241s	
7683/11850 (epoch 32.418), train_loss = 0.90214335, grad/param norm = 4.0819e-01, time/batch = 16.2094s	
7684/11850 (epoch 32.422), train_loss = 0.83497803, grad/param norm = 2.5974e-01, time/batch = 18.0490s	
7685/11850 (epoch 32.426), train_loss = 0.85907855, grad/param norm = 3.9902e-01, time/batch = 15.0725s	
7686/11850 (epoch 32.430), train_loss = 0.93425130, grad/param norm = 2.9766e-01, time/batch = 16.1820s	
7687/11850 (epoch 32.435), train_loss = 0.92588117, grad/param norm = 2.6096e-01, time/batch = 17.1106s	
7688/11850 (epoch 32.439), train_loss = 1.03285543, grad/param norm = 2.5853e-01, time/batch = 16.9701s	
7689/11850 (epoch 32.443), train_loss = 0.97538762, grad/param norm = 2.6315e-01, time/batch = 18.0604s	
7690/11850 (epoch 32.447), train_loss = 0.90645641, grad/param norm = 2.8254e-01, time/batch = 16.1390s	
7691/11850 (epoch 32.451), train_loss = 0.90212259, grad/param norm = 2.9593e-01, time/batch = 18.5540s	
7692/11850 (epoch 32.456), train_loss = 0.99162364, grad/param norm = 3.0951e-01, time/batch = 17.6449s	
7693/11850 (epoch 32.460), train_loss = 1.05466913, grad/param norm = 2.9101e-01, time/batch = 17.8804s	
7694/11850 (epoch 32.464), train_loss = 0.93770009, grad/param norm = 3.0208e-01, time/batch = 18.1212s	
7695/11850 (epoch 32.468), train_loss = 1.01158232, grad/param norm = 2.7182e-01, time/batch = 17.9029s	
7696/11850 (epoch 32.473), train_loss = 1.06301356, grad/param norm = 3.0807e-01, time/batch = 18.3044s	
7697/11850 (epoch 32.477), train_loss = 0.91044156, grad/param norm = 2.8676e-01, time/batch = 15.7866s	
7698/11850 (epoch 32.481), train_loss = 0.93940326, grad/param norm = 3.6243e-01, time/batch = 19.5359s	
7699/11850 (epoch 32.485), train_loss = 0.88933980, grad/param norm = 2.5130e-01, time/batch = 16.4006s	
7700/11850 (epoch 32.489), train_loss = 1.01931645, grad/param norm = 2.7000e-01, time/batch = 17.1981s	
7701/11850 (epoch 32.494), train_loss = 0.90502439, grad/param norm = 3.0711e-01, time/batch = 18.6123s	
7702/11850 (epoch 32.498), train_loss = 0.89623991, grad/param norm = 3.1161e-01, time/batch = 16.6187s	
7703/11850 (epoch 32.502), train_loss = 0.87478861, grad/param norm = 2.7277e-01, time/batch = 15.6513s	
7704/11850 (epoch 32.506), train_loss = 1.14747583, grad/param norm = 2.9219e-01, time/batch = 16.5439s	
7705/11850 (epoch 32.511), train_loss = 0.97973661, grad/param norm = 2.6441e-01, time/batch = 14.8862s	
7706/11850 (epoch 32.515), train_loss = 1.07506801, grad/param norm = 3.0236e-01, time/batch = 18.2304s	
7707/11850 (epoch 32.519), train_loss = 0.94538701, grad/param norm = 2.9615e-01, time/batch = 16.7953s	
7708/11850 (epoch 32.523), train_loss = 0.99999906, grad/param norm = 2.7292e-01, time/batch = 16.6431s	
7709/11850 (epoch 32.527), train_loss = 0.92617934, grad/param norm = 2.4501e-01, time/batch = 18.2348s	
7710/11850 (epoch 32.532), train_loss = 1.02823996, grad/param norm = 3.1199e-01, time/batch = 17.4715s	
7711/11850 (epoch 32.536), train_loss = 0.95550359, grad/param norm = 2.6575e-01, time/batch = 17.5500s	
7712/11850 (epoch 32.540), train_loss = 0.90578915, grad/param norm = 2.4368e-01, time/batch = 17.5493s	
7713/11850 (epoch 32.544), train_loss = 0.90408322, grad/param norm = 2.9791e-01, time/batch = 18.8695s	
7714/11850 (epoch 32.549), train_loss = 0.85486075, grad/param norm = 2.4629e-01, time/batch = 16.3780s	
7715/11850 (epoch 32.553), train_loss = 1.00596430, grad/param norm = 3.1701e-01, time/batch = 16.6094s	
7716/11850 (epoch 32.557), train_loss = 1.01288819, grad/param norm = 3.2288e-01, time/batch = 17.2925s	
7717/11850 (epoch 32.561), train_loss = 1.02281332, grad/param norm = 2.9623e-01, time/batch = 17.3143s	
7718/11850 (epoch 32.565), train_loss = 1.13542513, grad/param norm = 3.4495e-01, time/batch = 15.7701s	
7719/11850 (epoch 32.570), train_loss = 1.01363833, grad/param norm = 2.9804e-01, time/batch = 18.4858s	
7720/11850 (epoch 32.574), train_loss = 1.02310457, grad/param norm = 2.5452e-01, time/batch = 19.0345s	
7721/11850 (epoch 32.578), train_loss = 1.07300027, grad/param norm = 3.0451e-01, time/batch = 15.3980s	
7722/11850 (epoch 32.582), train_loss = 0.95261636, grad/param norm = 3.1955e-01, time/batch = 17.6399s	
7723/11850 (epoch 32.586), train_loss = 0.96130743, grad/param norm = 2.9195e-01, time/batch = 17.7157s	
7724/11850 (epoch 32.591), train_loss = 1.01142610, grad/param norm = 2.9659e-01, time/batch = 17.9697s	
7725/11850 (epoch 32.595), train_loss = 0.86305572, grad/param norm = 2.6963e-01, time/batch = 16.8847s	
7726/11850 (epoch 32.599), train_loss = 0.98520582, grad/param norm = 3.0704e-01, time/batch = 18.3940s	
7727/11850 (epoch 32.603), train_loss = 0.93611303, grad/param norm = 2.3418e-01, time/batch = 18.4686s	
7728/11850 (epoch 32.608), train_loss = 1.11616396, grad/param norm = 2.7602e-01, time/batch = 17.6327s	
7729/11850 (epoch 32.612), train_loss = 1.17059969, grad/param norm = 2.9822e-01, time/batch = 16.5591s	
7730/11850 (epoch 32.616), train_loss = 1.10024572, grad/param norm = 3.0199e-01, time/batch = 16.8662s	
7731/11850 (epoch 32.620), train_loss = 0.98304062, grad/param norm = 2.8095e-01, time/batch = 19.1827s	
7732/11850 (epoch 32.624), train_loss = 0.99424039, grad/param norm = 3.1566e-01, time/batch = 27.3431s	
7733/11850 (epoch 32.629), train_loss = 0.95044202, grad/param norm = 3.1002e-01, time/batch = 17.8849s	
7734/11850 (epoch 32.633), train_loss = 0.87641985, grad/param norm = 2.8314e-01, time/batch = 15.0128s	
7735/11850 (epoch 32.637), train_loss = 0.81142198, grad/param norm = 2.4166e-01, time/batch = 14.7025s	
7736/11850 (epoch 32.641), train_loss = 0.88202978, grad/param norm = 2.5913e-01, time/batch = 15.3063s	
7737/11850 (epoch 32.646), train_loss = 0.88661942, grad/param norm = 2.5399e-01, time/batch = 14.4558s	
7738/11850 (epoch 32.650), train_loss = 0.97746127, grad/param norm = 2.9213e-01, time/batch = 14.5316s	
7739/11850 (epoch 32.654), train_loss = 0.91873869, grad/param norm = 2.8664e-01, time/batch = 14.8057s	
7740/11850 (epoch 32.658), train_loss = 1.00723978, grad/param norm = 2.7413e-01, time/batch = 15.5434s	
7741/11850 (epoch 32.662), train_loss = 0.85809475, grad/param norm = 3.0074e-01, time/batch = 18.7187s	
7742/11850 (epoch 32.667), train_loss = 1.06800709, grad/param norm = 2.9425e-01, time/batch = 16.0717s	
7743/11850 (epoch 32.671), train_loss = 0.96084318, grad/param norm = 2.9241e-01, time/batch = 19.0618s	
7744/11850 (epoch 32.675), train_loss = 0.94726372, grad/param norm = 2.7304e-01, time/batch = 17.7228s	
7745/11850 (epoch 32.679), train_loss = 0.98669244, grad/param norm = 2.7562e-01, time/batch = 17.0089s	
7746/11850 (epoch 32.684), train_loss = 0.96220385, grad/param norm = 3.1487e-01, time/batch = 18.4515s	
7747/11850 (epoch 32.688), train_loss = 0.91437482, grad/param norm = 2.7695e-01, time/batch = 17.1519s	
7748/11850 (epoch 32.692), train_loss = 0.92049288, grad/param norm = 3.1091e-01, time/batch = 17.8026s	
7749/11850 (epoch 32.696), train_loss = 0.90288732, grad/param norm = 3.1228e-01, time/batch = 16.2931s	
7750/11850 (epoch 32.700), train_loss = 0.97910845, grad/param norm = 2.7107e-01, time/batch = 17.9683s	
7751/11850 (epoch 32.705), train_loss = 0.91233240, grad/param norm = 2.8481e-01, time/batch = 15.9814s	
7752/11850 (epoch 32.709), train_loss = 0.83623711, grad/param norm = 2.5440e-01, time/batch = 16.3061s	
7753/11850 (epoch 32.713), train_loss = 0.85485183, grad/param norm = 2.7720e-01, time/batch = 18.1034s	
7754/11850 (epoch 32.717), train_loss = 0.92039190, grad/param norm = 2.6464e-01, time/batch = 16.9678s	
7755/11850 (epoch 32.722), train_loss = 0.99153099, grad/param norm = 2.9825e-01, time/batch = 17.9782s	
7756/11850 (epoch 32.726), train_loss = 0.88620044, grad/param norm = 2.8517e-01, time/batch = 18.3745s	
7757/11850 (epoch 32.730), train_loss = 0.89459827, grad/param norm = 2.7125e-01, time/batch = 17.0525s	
7758/11850 (epoch 32.734), train_loss = 0.90360860, grad/param norm = 2.6142e-01, time/batch = 18.2856s	
7759/11850 (epoch 32.738), train_loss = 1.02823608, grad/param norm = 2.9420e-01, time/batch = 16.4731s	
7760/11850 (epoch 32.743), train_loss = 0.96095961, grad/param norm = 2.8040e-01, time/batch = 18.8773s	
7761/11850 (epoch 32.747), train_loss = 0.85500020, grad/param norm = 2.3079e-01, time/batch = 18.6362s	
7762/11850 (epoch 32.751), train_loss = 0.92584008, grad/param norm = 2.7027e-01, time/batch = 17.3681s	
7763/11850 (epoch 32.755), train_loss = 0.96732211, grad/param norm = 2.6167e-01, time/batch = 17.6093s	
7764/11850 (epoch 32.759), train_loss = 0.89405537, grad/param norm = 2.6627e-01, time/batch = 18.3018s	
7765/11850 (epoch 32.764), train_loss = 0.93577087, grad/param norm = 2.6236e-01, time/batch = 18.0558s	
7766/11850 (epoch 32.768), train_loss = 0.85642594, grad/param norm = 2.5122e-01, time/batch = 15.0092s	
7767/11850 (epoch 32.772), train_loss = 0.91635062, grad/param norm = 3.0100e-01, time/batch = 17.7915s	
7768/11850 (epoch 32.776), train_loss = 0.99419673, grad/param norm = 2.7048e-01, time/batch = 17.2285s	
7769/11850 (epoch 32.781), train_loss = 0.94083982, grad/param norm = 2.7697e-01, time/batch = 16.6306s	
7770/11850 (epoch 32.785), train_loss = 0.92533032, grad/param norm = 2.9243e-01, time/batch = 16.3846s	
7771/11850 (epoch 32.789), train_loss = 0.94667989, grad/param norm = 2.7887e-01, time/batch = 18.2150s	
7772/11850 (epoch 32.793), train_loss = 1.01594778, grad/param norm = 3.0667e-01, time/batch = 18.1345s	
7773/11850 (epoch 32.797), train_loss = 0.95662018, grad/param norm = 2.7722e-01, time/batch = 16.5592s	
7774/11850 (epoch 32.802), train_loss = 0.87920075, grad/param norm = 2.6094e-01, time/batch = 17.2375s	
7775/11850 (epoch 32.806), train_loss = 0.95899868, grad/param norm = 3.0190e-01, time/batch = 18.1223s	
7776/11850 (epoch 32.810), train_loss = 1.02027018, grad/param norm = 2.9154e-01, time/batch = 15.5360s	
7777/11850 (epoch 32.814), train_loss = 0.96528680, grad/param norm = 2.6054e-01, time/batch = 18.4753s	
7778/11850 (epoch 32.819), train_loss = 1.05503233, grad/param norm = 2.7840e-01, time/batch = 15.6062s	
7779/11850 (epoch 32.823), train_loss = 1.08515283, grad/param norm = 2.9277e-01, time/batch = 18.6180s	
7780/11850 (epoch 32.827), train_loss = 0.96362868, grad/param norm = 2.8146e-01, time/batch = 17.4706s	
7781/11850 (epoch 32.831), train_loss = 0.94294154, grad/param norm = 2.5560e-01, time/batch = 17.8023s	
7782/11850 (epoch 32.835), train_loss = 0.98669028, grad/param norm = 2.4676e-01, time/batch = 18.5612s	
7783/11850 (epoch 32.840), train_loss = 0.92951764, grad/param norm = 2.7060e-01, time/batch = 16.9543s	
7784/11850 (epoch 32.844), train_loss = 0.95177610, grad/param norm = 2.2130e-01, time/batch = 18.5517s	
7785/11850 (epoch 32.848), train_loss = 0.98649864, grad/param norm = 2.6397e-01, time/batch = 16.2305s	
7786/11850 (epoch 32.852), train_loss = 0.96990034, grad/param norm = 2.6911e-01, time/batch = 17.3691s	
7787/11850 (epoch 32.857), train_loss = 0.93855042, grad/param norm = 3.0739e-01, time/batch = 17.8787s	
7788/11850 (epoch 32.861), train_loss = 0.92820395, grad/param norm = 2.9373e-01, time/batch = 15.9563s	
7789/11850 (epoch 32.865), train_loss = 1.02818140, grad/param norm = 3.9318e-01, time/batch = 17.6377s	
7790/11850 (epoch 32.869), train_loss = 0.99853041, grad/param norm = 3.1580e-01, time/batch = 18.0351s	
7791/11850 (epoch 32.873), train_loss = 1.01205770, grad/param norm = 3.0455e-01, time/batch = 19.2143s	
7792/11850 (epoch 32.878), train_loss = 1.01290300, grad/param norm = 2.6980e-01, time/batch = 15.2126s	
7793/11850 (epoch 32.882), train_loss = 0.96927807, grad/param norm = 2.9205e-01, time/batch = 17.7753s	
7794/11850 (epoch 32.886), train_loss = 0.94537381, grad/param norm = 3.0993e-01, time/batch = 18.4760s	
7795/11850 (epoch 32.890), train_loss = 0.98380496, grad/param norm = 3.1989e-01, time/batch = 17.8841s	
7796/11850 (epoch 32.895), train_loss = 1.01255663, grad/param norm = 3.4694e-01, time/batch = 17.1255s	
7797/11850 (epoch 32.899), train_loss = 0.87832499, grad/param norm = 2.8632e-01, time/batch = 18.1227s	
7798/11850 (epoch 32.903), train_loss = 0.92718898, grad/param norm = 2.9033e-01, time/batch = 18.2108s	
7799/11850 (epoch 32.907), train_loss = 0.91714556, grad/param norm = 2.6712e-01, time/batch = 16.9803s	
7800/11850 (epoch 32.911), train_loss = 1.04957295, grad/param norm = 3.1508e-01, time/batch = 16.2068s	
7801/11850 (epoch 32.916), train_loss = 1.02870779, grad/param norm = 3.6311e-01, time/batch = 18.4697s	
7802/11850 (epoch 32.920), train_loss = 1.00456151, grad/param norm = 2.9520e-01, time/batch = 17.2956s	
7803/11850 (epoch 32.924), train_loss = 0.95067548, grad/param norm = 3.1033e-01, time/batch = 17.6323s	
7804/11850 (epoch 32.928), train_loss = 1.02247103, grad/param norm = 3.1601e-01, time/batch = 18.0136s	
7805/11850 (epoch 32.932), train_loss = 1.08874701, grad/param norm = 3.0534e-01, time/batch = 18.6347s	
7806/11850 (epoch 32.937), train_loss = 1.04230779, grad/param norm = 2.6157e-01, time/batch = 17.5646s	
7807/11850 (epoch 32.941), train_loss = 1.01629969, grad/param norm = 2.7693e-01, time/batch = 14.9405s	
7808/11850 (epoch 32.945), train_loss = 1.03737288, grad/param norm = 2.7907e-01, time/batch = 17.4731s	
7809/11850 (epoch 32.949), train_loss = 0.94871404, grad/param norm = 4.1202e-01, time/batch = 18.8111s	
7810/11850 (epoch 32.954), train_loss = 1.03980383, grad/param norm = 2.9968e-01, time/batch = 15.8869s	
7811/11850 (epoch 32.958), train_loss = 1.02766320, grad/param norm = 2.7737e-01, time/batch = 14.2579s	
7812/11850 (epoch 32.962), train_loss = 0.94121934, grad/param norm = 3.7313e-01, time/batch = 17.7215s	
7813/11850 (epoch 32.966), train_loss = 0.88699628, grad/param norm = 2.9202e-01, time/batch = 18.1349s	
7814/11850 (epoch 32.970), train_loss = 1.00412851, grad/param norm = 2.8890e-01, time/batch = 16.6287s	
7815/11850 (epoch 32.975), train_loss = 0.95980882, grad/param norm = 2.9888e-01, time/batch = 16.9137s	
7816/11850 (epoch 32.979), train_loss = 0.98696533, grad/param norm = 3.3713e-01, time/batch = 18.2272s	
7817/11850 (epoch 32.983), train_loss = 1.07160061, grad/param norm = 3.3073e-01, time/batch = 16.3759s	
7818/11850 (epoch 32.987), train_loss = 0.93132348, grad/param norm = 2.9057e-01, time/batch = 16.8768s	
7819/11850 (epoch 32.992), train_loss = 1.09772762, grad/param norm = 2.9645e-01, time/batch = 16.7816s	
7820/11850 (epoch 32.996), train_loss = 1.11571723, grad/param norm = 3.1295e-01, time/batch = 17.7223s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
7821/11850 (epoch 33.000), train_loss = 0.99701090, grad/param norm = 3.6980e-01, time/batch = 15.0508s	
7822/11850 (epoch 33.004), train_loss = 1.05228037, grad/param norm = 3.7113e-01, time/batch = 16.5591s	
7823/11850 (epoch 33.008), train_loss = 1.08906331, grad/param norm = 3.3584e-01, time/batch = 16.5529s	
7824/11850 (epoch 33.013), train_loss = 1.08647556, grad/param norm = 2.7729e-01, time/batch = 16.2079s	
7825/11850 (epoch 33.017), train_loss = 1.12645297, grad/param norm = 3.1306e-01, time/batch = 17.4793s	
7826/11850 (epoch 33.021), train_loss = 1.05269467, grad/param norm = 2.5632e-01, time/batch = 16.6446s	
7827/11850 (epoch 33.025), train_loss = 0.94627562, grad/param norm = 2.5746e-01, time/batch = 17.8730s	
7828/11850 (epoch 33.030), train_loss = 0.98213290, grad/param norm = 2.9223e-01, time/batch = 16.2351s	
7829/11850 (epoch 33.034), train_loss = 0.96409909, grad/param norm = 2.7519e-01, time/batch = 17.0635s	
7830/11850 (epoch 33.038), train_loss = 0.98889696, grad/param norm = 2.7465e-01, time/batch = 19.2054s	
7831/11850 (epoch 33.042), train_loss = 1.02568563, grad/param norm = 2.8827e-01, time/batch = 17.6293s	
7832/11850 (epoch 33.046), train_loss = 0.96379560, grad/param norm = 3.1657e-01, time/batch = 18.2067s	
7833/11850 (epoch 33.051), train_loss = 0.99563684, grad/param norm = 2.6333e-01, time/batch = 18.3889s	
7834/11850 (epoch 33.055), train_loss = 0.94782161, grad/param norm = 2.5540e-01, time/batch = 16.6265s	
7835/11850 (epoch 33.059), train_loss = 1.06159483, grad/param norm = 2.8060e-01, time/batch = 17.1119s	
7836/11850 (epoch 33.063), train_loss = 1.06638211, grad/param norm = 3.2055e-01, time/batch = 17.9607s	
7837/11850 (epoch 33.068), train_loss = 0.99120722, grad/param norm = 2.5117e-01, time/batch = 18.6256s	
7838/11850 (epoch 33.072), train_loss = 1.04789198, grad/param norm = 2.7356e-01, time/batch = 14.4006s	
7839/11850 (epoch 33.076), train_loss = 1.11075784, grad/param norm = 2.9857e-01, time/batch = 19.1307s	
7840/11850 (epoch 33.080), train_loss = 0.93651367, grad/param norm = 2.5629e-01, time/batch = 16.6991s	
7841/11850 (epoch 33.084), train_loss = 0.88178425, grad/param norm = 2.5605e-01, time/batch = 18.8824s	
7842/11850 (epoch 33.089), train_loss = 0.89921837, grad/param norm = 2.7001e-01, time/batch = 18.7868s	
7843/11850 (epoch 33.093), train_loss = 0.88810523, grad/param norm = 2.6499e-01, time/batch = 18.6444s	
7844/11850 (epoch 33.097), train_loss = 0.99638138, grad/param norm = 2.8114e-01, time/batch = 17.1898s	
7845/11850 (epoch 33.101), train_loss = 0.92015504, grad/param norm = 3.1880e-01, time/batch = 16.3657s	
7846/11850 (epoch 33.105), train_loss = 0.88856781, grad/param norm = 2.5178e-01, time/batch = 17.3938s	
7847/11850 (epoch 33.110), train_loss = 1.04031628, grad/param norm = 2.6639e-01, time/batch = 19.1298s	
7848/11850 (epoch 33.114), train_loss = 0.95436256, grad/param norm = 3.0595e-01, time/batch = 17.3808s	
7849/11850 (epoch 33.118), train_loss = 1.05284430, grad/param norm = 2.7708e-01, time/batch = 15.2106s	
7850/11850 (epoch 33.122), train_loss = 1.09060881, grad/param norm = 2.9265e-01, time/batch = 17.7993s	
7851/11850 (epoch 33.127), train_loss = 1.02851281, grad/param norm = 2.9982e-01, time/batch = 18.3980s	
7852/11850 (epoch 33.131), train_loss = 0.98586845, grad/param norm = 2.9757e-01, time/batch = 17.2717s	
7853/11850 (epoch 33.135), train_loss = 0.99352734, grad/param norm = 3.1934e-01, time/batch = 17.7972s	
7854/11850 (epoch 33.139), train_loss = 0.98764467, grad/param norm = 2.8597e-01, time/batch = 17.4657s	
7855/11850 (epoch 33.143), train_loss = 0.96700406, grad/param norm = 2.8325e-01, time/batch = 16.4535s	
7856/11850 (epoch 33.148), train_loss = 0.95899205, grad/param norm = 3.2127e-01, time/batch = 17.9563s	
7857/11850 (epoch 33.152), train_loss = 1.06651415, grad/param norm = 3.6269e-01, time/batch = 17.0460s	
7858/11850 (epoch 33.156), train_loss = 0.95951334, grad/param norm = 3.7497e-01, time/batch = 16.7276s	
7859/11850 (epoch 33.160), train_loss = 1.16631949, grad/param norm = 3.3789e-01, time/batch = 16.9616s	
7860/11850 (epoch 33.165), train_loss = 1.08542070, grad/param norm = 3.1936e-01, time/batch = 18.0628s	
7861/11850 (epoch 33.169), train_loss = 0.98061205, grad/param norm = 3.2690e-01, time/batch = 17.8159s	
7862/11850 (epoch 33.173), train_loss = 1.04930532, grad/param norm = 2.8102e-01, time/batch = 17.3016s	
7863/11850 (epoch 33.177), train_loss = 0.89973102, grad/param norm = 2.9504e-01, time/batch = 18.3725s	
7864/11850 (epoch 33.181), train_loss = 1.02318606, grad/param norm = 3.0238e-01, time/batch = 17.9776s	
7865/11850 (epoch 33.186), train_loss = 1.11810976, grad/param norm = 3.6608e-01, time/batch = 15.1113s	
7866/11850 (epoch 33.190), train_loss = 1.02062171, grad/param norm = 2.8655e-01, time/batch = 18.8778s	
7867/11850 (epoch 33.194), train_loss = 1.05919607, grad/param norm = 3.6705e-01, time/batch = 17.6360s	
7868/11850 (epoch 33.198), train_loss = 0.83418752, grad/param norm = 3.2676e-01, time/batch = 17.6326s	
7869/11850 (epoch 33.203), train_loss = 0.86928107, grad/param norm = 2.6253e-01, time/batch = 16.2055s	
7870/11850 (epoch 33.207), train_loss = 1.03703544, grad/param norm = 3.0819e-01, time/batch = 15.7934s	
7871/11850 (epoch 33.211), train_loss = 1.00035194, grad/param norm = 2.9995e-01, time/batch = 16.6180s	
7872/11850 (epoch 33.215), train_loss = 1.01729310, grad/param norm = 3.5278e-01, time/batch = 18.2100s	
7873/11850 (epoch 33.219), train_loss = 1.01745208, grad/param norm = 2.8290e-01, time/batch = 15.3089s	
7874/11850 (epoch 33.224), train_loss = 1.14917237, grad/param norm = 2.8358e-01, time/batch = 17.8995s	
7875/11850 (epoch 33.228), train_loss = 1.04218399, grad/param norm = 3.1373e-01, time/batch = 18.1331s	
7876/11850 (epoch 33.232), train_loss = 1.02273191, grad/param norm = 3.1505e-01, time/batch = 17.6151s	
7877/11850 (epoch 33.236), train_loss = 0.91759776, grad/param norm = 2.9588e-01, time/batch = 16.8022s	
7878/11850 (epoch 33.241), train_loss = 1.04685550, grad/param norm = 3.3832e-01, time/batch = 17.2298s	
7879/11850 (epoch 33.245), train_loss = 1.06900370, grad/param norm = 2.8110e-01, time/batch = 17.8670s	
7880/11850 (epoch 33.249), train_loss = 0.98540338, grad/param norm = 2.8354e-01, time/batch = 17.0485s	
7881/11850 (epoch 33.253), train_loss = 0.99592295, grad/param norm = 3.3201e-01, time/batch = 16.6377s	
7882/11850 (epoch 33.257), train_loss = 1.12174286, grad/param norm = 2.9473e-01, time/batch = 18.8015s	
7883/11850 (epoch 33.262), train_loss = 1.12083200, grad/param norm = 3.1262e-01, time/batch = 16.9314s	
7884/11850 (epoch 33.266), train_loss = 1.09445357, grad/param norm = 3.5354e-01, time/batch = 18.7218s	
7885/11850 (epoch 33.270), train_loss = 0.97689048, grad/param norm = 2.5360e-01, time/batch = 18.7150s	
7886/11850 (epoch 33.274), train_loss = 0.99546328, grad/param norm = 3.6762e-01, time/batch = 16.8628s	
7887/11850 (epoch 33.278), train_loss = 0.86873571, grad/param norm = 2.5246e-01, time/batch = 19.2115s	
7888/11850 (epoch 33.283), train_loss = 0.97827348, grad/param norm = 2.5603e-01, time/batch = 17.6459s	
7889/11850 (epoch 33.287), train_loss = 1.11961060, grad/param norm = 3.0972e-01, time/batch = 16.8732s	
7890/11850 (epoch 33.291), train_loss = 0.97717588, grad/param norm = 2.7912e-01, time/batch = 15.6902s	
7891/11850 (epoch 33.295), train_loss = 1.04721378, grad/param norm = 2.7365e-01, time/batch = 16.6407s	
7892/11850 (epoch 33.300), train_loss = 0.96175502, grad/param norm = 2.9598e-01, time/batch = 18.9558s	
7893/11850 (epoch 33.304), train_loss = 0.98606350, grad/param norm = 2.6251e-01, time/batch = 17.4520s	
7894/11850 (epoch 33.308), train_loss = 0.96608117, grad/param norm = 2.3715e-01, time/batch = 15.5447s	
7895/11850 (epoch 33.312), train_loss = 0.88279951, grad/param norm = 2.9008e-01, time/batch = 18.4699s	
7896/11850 (epoch 33.316), train_loss = 1.01291078, grad/param norm = 2.7141e-01, time/batch = 16.8881s	
7897/11850 (epoch 33.321), train_loss = 0.97474087, grad/param norm = 2.8596e-01, time/batch = 19.0403s	
7898/11850 (epoch 33.325), train_loss = 1.00385991, grad/param norm = 2.7445e-01, time/batch = 18.7169s	
7899/11850 (epoch 33.329), train_loss = 0.99481131, grad/param norm = 2.7015e-01, time/batch = 18.6288s	
7900/11850 (epoch 33.333), train_loss = 0.97892932, grad/param norm = 2.9541e-01, time/batch = 17.2039s	
7901/11850 (epoch 33.338), train_loss = 0.94186824, grad/param norm = 2.7265e-01, time/batch = 17.8008s	
7902/11850 (epoch 33.342), train_loss = 0.97530144, grad/param norm = 2.9064e-01, time/batch = 19.0349s	
7903/11850 (epoch 33.346), train_loss = 0.97330549, grad/param norm = 2.7775e-01, time/batch = 15.2786s	
7904/11850 (epoch 33.350), train_loss = 0.87620907, grad/param norm = 2.7217e-01, time/batch = 18.4718s	
7905/11850 (epoch 33.354), train_loss = 1.04193047, grad/param norm = 2.8495e-01, time/batch = 16.9846s	
7906/11850 (epoch 33.359), train_loss = 1.10910287, grad/param norm = 4.9227e-01, time/batch = 17.4541s	
7907/11850 (epoch 33.363), train_loss = 1.04005441, grad/param norm = 2.9745e-01, time/batch = 17.3432s	
7908/11850 (epoch 33.367), train_loss = 1.05861809, grad/param norm = 2.9020e-01, time/batch = 17.2192s	
7909/11850 (epoch 33.371), train_loss = 1.03524255, grad/param norm = 2.5676e-01, time/batch = 17.3808s	
7910/11850 (epoch 33.376), train_loss = 0.99308688, grad/param norm = 2.9329e-01, time/batch = 17.2213s	
7911/11850 (epoch 33.380), train_loss = 0.96203804, grad/param norm = 2.5737e-01, time/batch = 18.6319s	
7912/11850 (epoch 33.384), train_loss = 0.91855711, grad/param norm = 2.6385e-01, time/batch = 17.7087s	
7913/11850 (epoch 33.388), train_loss = 1.05153161, grad/param norm = 2.5852e-01, time/batch = 16.8002s	
7914/11850 (epoch 33.392), train_loss = 1.02806781, grad/param norm = 2.9384e-01, time/batch = 15.4618s	
7915/11850 (epoch 33.397), train_loss = 1.04593369, grad/param norm = 2.8523e-01, time/batch = 18.5636s	
7916/11850 (epoch 33.401), train_loss = 0.87744790, grad/param norm = 2.7162e-01, time/batch = 18.2956s	
7917/11850 (epoch 33.405), train_loss = 0.93121850, grad/param norm = 2.9060e-01, time/batch = 16.4626s	
7918/11850 (epoch 33.409), train_loss = 1.04781227, grad/param norm = 2.7434e-01, time/batch = 17.7152s	
7919/11850 (epoch 33.414), train_loss = 0.84667906, grad/param norm = 2.6220e-01, time/batch = 18.9636s	
7920/11850 (epoch 33.418), train_loss = 0.89291515, grad/param norm = 2.7624e-01, time/batch = 15.9759s	
7921/11850 (epoch 33.422), train_loss = 0.82229907, grad/param norm = 2.5561e-01, time/batch = 15.0607s	
7922/11850 (epoch 33.426), train_loss = 0.83967985, grad/param norm = 2.6531e-01, time/batch = 16.9005s	
7923/11850 (epoch 33.430), train_loss = 0.89633163, grad/param norm = 3.1991e-01, time/batch = 18.4028s	
7924/11850 (epoch 33.435), train_loss = 0.91429787, grad/param norm = 2.9708e-01, time/batch = 14.4577s	
7925/11850 (epoch 33.439), train_loss = 1.01279541, grad/param norm = 2.5203e-01, time/batch = 18.1336s	
7926/11850 (epoch 33.443), train_loss = 0.96487529, grad/param norm = 2.5723e-01, time/batch = 17.8128s	
7927/11850 (epoch 33.447), train_loss = 0.88026028, grad/param norm = 2.6139e-01, time/batch = 17.1421s	
7928/11850 (epoch 33.451), train_loss = 0.87767316, grad/param norm = 2.5972e-01, time/batch = 17.0465s	
7929/11850 (epoch 33.456), train_loss = 0.97361093, grad/param norm = 3.3374e-01, time/batch = 17.2104s	
7930/11850 (epoch 33.460), train_loss = 1.03573127, grad/param norm = 3.0750e-01, time/batch = 15.1985s	
7931/11850 (epoch 33.464), train_loss = 0.93904233, grad/param norm = 2.8452e-01, time/batch = 17.9479s	
7932/11850 (epoch 33.468), train_loss = 1.00349833, grad/param norm = 2.9467e-01, time/batch = 17.4811s	
7933/11850 (epoch 33.473), train_loss = 1.06406301, grad/param norm = 3.1197e-01, time/batch = 16.9413s	
7934/11850 (epoch 33.477), train_loss = 0.88337602, grad/param norm = 2.5360e-01, time/batch = 17.4529s	
7935/11850 (epoch 33.481), train_loss = 0.93003122, grad/param norm = 3.0960e-01, time/batch = 18.3664s	
7936/11850 (epoch 33.485), train_loss = 0.87196014, grad/param norm = 2.5157e-01, time/batch = 17.4795s	
7937/11850 (epoch 33.489), train_loss = 0.99623834, grad/param norm = 2.7102e-01, time/batch = 17.3128s	
7938/11850 (epoch 33.494), train_loss = 0.88816899, grad/param norm = 3.3325e-01, time/batch = 30.7134s	
7939/11850 (epoch 33.498), train_loss = 0.88200727, grad/param norm = 2.6244e-01, time/batch = 17.5398s	
7940/11850 (epoch 33.502), train_loss = 0.86480115, grad/param norm = 3.0993e-01, time/batch = 16.8800s	
7941/11850 (epoch 33.506), train_loss = 1.12540432, grad/param norm = 2.9170e-01, time/batch = 18.2016s	
7942/11850 (epoch 33.511), train_loss = 0.96567810, grad/param norm = 2.7521e-01, time/batch = 17.8144s	
7943/11850 (epoch 33.515), train_loss = 1.05850455, grad/param norm = 3.4236e-01, time/batch = 18.2945s	
7944/11850 (epoch 33.519), train_loss = 0.94045317, grad/param norm = 2.9976e-01, time/batch = 17.6826s	
7945/11850 (epoch 33.523), train_loss = 0.98032183, grad/param norm = 2.7760e-01, time/batch = 18.3878s	
7946/11850 (epoch 33.527), train_loss = 0.91183481, grad/param norm = 3.1846e-01, time/batch = 18.7142s	
7947/11850 (epoch 33.532), train_loss = 0.99543382, grad/param norm = 2.6438e-01, time/batch = 18.0376s	
7948/11850 (epoch 33.536), train_loss = 0.93782866, grad/param norm = 2.6672e-01, time/batch = 17.3820s	
7949/11850 (epoch 33.540), train_loss = 0.89464824, grad/param norm = 2.8591e-01, time/batch = 18.3829s	
7950/11850 (epoch 33.544), train_loss = 0.88436204, grad/param norm = 2.8571e-01, time/batch = 17.4612s	
7951/11850 (epoch 33.549), train_loss = 0.83353871, grad/param norm = 2.5130e-01, time/batch = 18.7199s	
7952/11850 (epoch 33.553), train_loss = 0.98106194, grad/param norm = 2.6309e-01, time/batch = 18.0494s	
7953/11850 (epoch 33.557), train_loss = 0.99981109, grad/param norm = 3.6007e-01, time/batch = 17.2907s	
7954/11850 (epoch 33.561), train_loss = 1.01302991, grad/param norm = 3.0874e-01, time/batch = 14.6241s	
7955/11850 (epoch 33.565), train_loss = 1.10844316, grad/param norm = 2.8974e-01, time/batch = 16.5717s	
7956/11850 (epoch 33.570), train_loss = 0.98522440, grad/param norm = 2.5609e-01, time/batch = 16.2351s	
7957/11850 (epoch 33.574), train_loss = 1.01592432, grad/param norm = 3.0099e-01, time/batch = 17.1316s	
7958/11850 (epoch 33.578), train_loss = 1.04722432, grad/param norm = 3.0310e-01, time/batch = 17.1752s	
7959/11850 (epoch 33.582), train_loss = 0.92534126, grad/param norm = 2.7223e-01, time/batch = 18.8807s	
7960/11850 (epoch 33.586), train_loss = 0.93298310, grad/param norm = 2.5690e-01, time/batch = 17.3085s	
7961/11850 (epoch 33.591), train_loss = 0.98624917, grad/param norm = 2.9486e-01, time/batch = 18.7930s	
7962/11850 (epoch 33.595), train_loss = 0.84765897, grad/param norm = 2.5712e-01, time/batch = 17.2117s	
7963/11850 (epoch 33.599), train_loss = 0.98532430, grad/param norm = 2.9559e-01, time/batch = 18.5554s	
7964/11850 (epoch 33.603), train_loss = 0.91205817, grad/param norm = 2.3214e-01, time/batch = 17.1143s	
7965/11850 (epoch 33.608), train_loss = 1.09170335, grad/param norm = 2.6323e-01, time/batch = 16.9779s	
7966/11850 (epoch 33.612), train_loss = 1.16218701, grad/param norm = 3.3075e-01, time/batch = 18.4766s	
7967/11850 (epoch 33.616), train_loss = 1.08275617, grad/param norm = 2.6987e-01, time/batch = 16.7213s	
7968/11850 (epoch 33.620), train_loss = 0.96647843, grad/param norm = 2.6122e-01, time/batch = 19.6120s	
7969/11850 (epoch 33.624), train_loss = 0.97326167, grad/param norm = 3.3223e-01, time/batch = 17.2916s	
7970/11850 (epoch 33.629), train_loss = 0.93170530, grad/param norm = 2.6184e-01, time/batch = 17.9619s	
7971/11850 (epoch 33.633), train_loss = 0.87333901, grad/param norm = 2.8460e-01, time/batch = 15.7591s	
7972/11850 (epoch 33.637), train_loss = 0.80289324, grad/param norm = 2.7015e-01, time/batch = 17.3892s	
7973/11850 (epoch 33.641), train_loss = 0.86311500, grad/param norm = 2.5417e-01, time/batch = 16.8941s	
7974/11850 (epoch 33.646), train_loss = 0.87853996, grad/param norm = 2.8625e-01, time/batch = 16.6452s	
7975/11850 (epoch 33.650), train_loss = 0.97675697, grad/param norm = 4.0197e-01, time/batch = 17.1078s	
7976/11850 (epoch 33.654), train_loss = 0.91790504, grad/param norm = 3.3829e-01, time/batch = 18.6265s	
7977/11850 (epoch 33.658), train_loss = 0.98655851, grad/param norm = 2.7148e-01, time/batch = 18.1337s	
7978/11850 (epoch 33.662), train_loss = 0.85515163, grad/param norm = 3.1457e-01, time/batch = 18.2734s	
7979/11850 (epoch 33.667), train_loss = 1.04187223, grad/param norm = 2.8133e-01, time/batch = 17.3073s	
7980/11850 (epoch 33.671), train_loss = 0.93769492, grad/param norm = 2.8574e-01, time/batch = 16.8666s	
7981/11850 (epoch 33.675), train_loss = 0.92872831, grad/param norm = 2.6161e-01, time/batch = 16.1121s	
7982/11850 (epoch 33.679), train_loss = 0.97352607, grad/param norm = 3.3046e-01, time/batch = 18.4612s	
7983/11850 (epoch 33.684), train_loss = 0.93129572, grad/param norm = 2.8877e-01, time/batch = 18.8777s	
7984/11850 (epoch 33.688), train_loss = 0.88849071, grad/param norm = 2.6160e-01, time/batch = 18.2954s	
7985/11850 (epoch 33.692), train_loss = 0.91823863, grad/param norm = 3.1341e-01, time/batch = 18.4579s	
7986/11850 (epoch 33.696), train_loss = 0.88571343, grad/param norm = 3.6107e-01, time/batch = 16.3280s	
7987/11850 (epoch 33.700), train_loss = 0.96163887, grad/param norm = 2.8409e-01, time/batch = 19.1201s	
7988/11850 (epoch 33.705), train_loss = 0.89969007, grad/param norm = 3.0638e-01, time/batch = 16.9515s	
7989/11850 (epoch 33.709), train_loss = 0.83679621, grad/param norm = 2.8341e-01, time/batch = 18.2183s	
7990/11850 (epoch 33.713), train_loss = 0.83603032, grad/param norm = 2.7688e-01, time/batch = 16.0553s	
7991/11850 (epoch 33.717), train_loss = 0.90968703, grad/param norm = 2.7039e-01, time/batch = 16.3077s	
7992/11850 (epoch 33.722), train_loss = 0.96360785, grad/param norm = 3.0976e-01, time/batch = 17.1249s	
7993/11850 (epoch 33.726), train_loss = 0.86371376, grad/param norm = 2.9049e-01, time/batch = 15.1413s	
7994/11850 (epoch 33.730), train_loss = 0.87268742, grad/param norm = 3.0951e-01, time/batch = 17.4516s	
7995/11850 (epoch 33.734), train_loss = 0.90096922, grad/param norm = 2.6243e-01, time/batch = 17.0495s	
7996/11850 (epoch 33.738), train_loss = 1.01031321, grad/param norm = 3.3891e-01, time/batch = 18.2261s	
7997/11850 (epoch 33.743), train_loss = 0.95253243, grad/param norm = 2.8528e-01, time/batch = 16.4808s	
7998/11850 (epoch 33.747), train_loss = 0.83799087, grad/param norm = 2.2861e-01, time/batch = 17.1175s	
7999/11850 (epoch 33.751), train_loss = 0.90736894, grad/param norm = 2.5404e-01, time/batch = 16.1138s	
evaluating loss over split index 2	
1/13...	
2/13...	
3/13...	
4/13...	
5/13...	
6/13...	
7/13...	
8/13...	
9/13...	
10/13...	
11/13...	
12/13...	
13/13...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_katelyn_salem_epoch33.76_2.2606.t7	
8000/11850 (epoch 33.755), train_loss = 0.95951641, grad/param norm = 2.6225e-01, time/batch = 18.5569s	
8001/11850 (epoch 33.759), train_loss = 1.38997881, grad/param norm = 4.1844e-01, time/batch = 18.2873s	
8002/11850 (epoch 33.764), train_loss = 0.92345180, grad/param norm = 2.6826e-01, time/batch = 16.2929s	
8003/11850 (epoch 33.768), train_loss = 0.84773054, grad/param norm = 2.6081e-01, time/batch = 18.2844s	
8004/11850 (epoch 33.772), train_loss = 0.91078742, grad/param norm = 2.8003e-01, time/batch = 17.2305s	
8005/11850 (epoch 33.776), train_loss = 0.97601381, grad/param norm = 2.6485e-01, time/batch = 18.5328s	
8006/11850 (epoch 33.781), train_loss = 0.93018379, grad/param norm = 3.0964e-01, time/batch = 16.0418s	
8007/11850 (epoch 33.785), train_loss = 0.92836641, grad/param norm = 3.0843e-01, time/batch = 18.2166s	
8008/11850 (epoch 33.789), train_loss = 0.92709059, grad/param norm = 2.6531e-01, time/batch = 16.1230s	
8009/11850 (epoch 33.793), train_loss = 0.99030616, grad/param norm = 2.9740e-01, time/batch = 17.2706s	
8010/11850 (epoch 33.797), train_loss = 0.94422509, grad/param norm = 2.8428e-01, time/batch = 19.0590s	
8011/11850 (epoch 33.802), train_loss = 0.86754919, grad/param norm = 2.9316e-01, time/batch = 18.2065s	
8012/11850 (epoch 33.806), train_loss = 0.93167100, grad/param norm = 2.9168e-01, time/batch = 18.1213s	
8013/11850 (epoch 33.810), train_loss = 1.00309972, grad/param norm = 3.1615e-01, time/batch = 18.0512s	
8014/11850 (epoch 33.814), train_loss = 0.94792081, grad/param norm = 2.7923e-01, time/batch = 18.5537s	
8015/11850 (epoch 33.819), train_loss = 1.05542566, grad/param norm = 3.0645e-01, time/batch = 18.7216s	
8016/11850 (epoch 33.823), train_loss = 1.07253090, grad/param norm = 3.3306e-01, time/batch = 16.6418s	
8017/11850 (epoch 33.827), train_loss = 0.95728228, grad/param norm = 3.2370e-01, time/batch = 18.3872s	
8018/11850 (epoch 33.831), train_loss = 0.94104080, grad/param norm = 3.2122e-01, time/batch = 18.6281s	
8019/11850 (epoch 33.835), train_loss = 0.97228872, grad/param norm = 2.5787e-01, time/batch = 16.6014s	
8020/11850 (epoch 33.840), train_loss = 0.90294647, grad/param norm = 2.6404e-01, time/batch = 18.7886s	
8021/11850 (epoch 33.844), train_loss = 0.94073590, grad/param norm = 2.3101e-01, time/batch = 18.1339s	
8022/11850 (epoch 33.848), train_loss = 0.96226137, grad/param norm = 2.6555e-01, time/batch = 17.1189s	
8023/11850 (epoch 33.852), train_loss = 0.95506936, grad/param norm = 2.8572e-01, time/batch = 17.8586s	
8024/11850 (epoch 33.857), train_loss = 0.92129139, grad/param norm = 2.9100e-01, time/batch = 18.2954s	
8025/11850 (epoch 33.861), train_loss = 0.89962642, grad/param norm = 2.7797e-01, time/batch = 18.2234s	
8026/11850 (epoch 33.865), train_loss = 0.98429294, grad/param norm = 3.5231e-01, time/batch = 17.6474s	
8027/11850 (epoch 33.869), train_loss = 0.97052323, grad/param norm = 2.7601e-01, time/batch = 14.7192s	
8028/11850 (epoch 33.873), train_loss = 0.97725324, grad/param norm = 2.6019e-01, time/batch = 17.1500s	
8029/11850 (epoch 33.878), train_loss = 0.99343183, grad/param norm = 3.3105e-01, time/batch = 16.1287s	
8030/11850 (epoch 33.882), train_loss = 0.96071892, grad/param norm = 2.8371e-01, time/batch = 17.4476s	
8031/11850 (epoch 33.886), train_loss = 0.92575273, grad/param norm = 3.1518e-01, time/batch = 17.6352s	
8032/11850 (epoch 33.890), train_loss = 0.96929959, grad/param norm = 3.1538e-01, time/batch = 17.8841s	
8033/11850 (epoch 33.895), train_loss = 0.99572889, grad/param norm = 3.5115e-01, time/batch = 14.0005s	
8034/11850 (epoch 33.899), train_loss = 0.86585226, grad/param norm = 2.8976e-01, time/batch = 16.6319s	
8035/11850 (epoch 33.903), train_loss = 0.89093824, grad/param norm = 2.6324e-01, time/batch = 18.6326s	
8036/11850 (epoch 33.907), train_loss = 0.90291014, grad/param norm = 2.5704e-01, time/batch = 16.6311s	
8037/11850 (epoch 33.911), train_loss = 1.04310619, grad/param norm = 2.8176e-01, time/batch = 18.4604s	
8038/11850 (epoch 33.916), train_loss = 1.00856398, grad/param norm = 3.4240e-01, time/batch = 16.6425s	
8039/11850 (epoch 33.920), train_loss = 0.98065593, grad/param norm = 2.8287e-01, time/batch = 17.0639s	
8040/11850 (epoch 33.924), train_loss = 0.94884407, grad/param norm = 3.3388e-01, time/batch = 15.0889s	
8041/11850 (epoch 33.928), train_loss = 1.00431608, grad/param norm = 3.1496e-01, time/batch = 16.9760s	
8042/11850 (epoch 33.932), train_loss = 1.05144549, grad/param norm = 3.0102e-01, time/batch = 16.6271s	
8043/11850 (epoch 33.937), train_loss = 1.02440976, grad/param norm = 2.7599e-01, time/batch = 16.7882s	
8044/11850 (epoch 33.941), train_loss = 0.99885641, grad/param norm = 2.7535e-01, time/batch = 18.6976s	
8045/11850 (epoch 33.945), train_loss = 1.02858615, grad/param norm = 3.1992e-01, time/batch = 18.3046s	
8046/11850 (epoch 33.949), train_loss = 0.92282191, grad/param norm = 3.0253e-01, time/batch = 19.1358s	
8047/11850 (epoch 33.954), train_loss = 1.03120538, grad/param norm = 3.4785e-01, time/batch = 16.3786s	
8048/11850 (epoch 33.958), train_loss = 1.02146845, grad/param norm = 3.4146e-01, time/batch = 18.6256s	
8049/11850 (epoch 33.962), train_loss = 0.93267022, grad/param norm = 3.4741e-01, time/batch = 18.6307s	
8050/11850 (epoch 33.966), train_loss = 0.86428320, grad/param norm = 2.8413e-01, time/batch = 15.9633s	
8051/11850 (epoch 33.970), train_loss = 0.99340853, grad/param norm = 2.8893e-01, time/batch = 18.8819s	
8052/11850 (epoch 33.975), train_loss = 0.94036422, grad/param norm = 2.6496e-01, time/batch = 17.4656s	
8053/11850 (epoch 33.979), train_loss = 0.97277050, grad/param norm = 3.1469e-01, time/batch = 17.2831s	
8054/11850 (epoch 33.983), train_loss = 1.05037967, grad/param norm = 3.2960e-01, time/batch = 18.3734s	
8055/11850 (epoch 33.987), train_loss = 0.92393253, grad/param norm = 3.2722e-01, time/batch = 14.1617s	
8056/11850 (epoch 33.992), train_loss = 1.08707734, grad/param norm = 3.0055e-01, time/batch = 15.5322s	
8057/11850 (epoch 33.996), train_loss = 1.08494261, grad/param norm = 3.1139e-01, time/batch = 15.6978s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
8058/11850 (epoch 34.000), train_loss = 0.96738911, grad/param norm = 3.3707e-01, time/batch = 18.7789s	
8059/11850 (epoch 34.004), train_loss = 1.03734268, grad/param norm = 3.7425e-01, time/batch = 16.4526s	
8060/11850 (epoch 34.008), train_loss = 1.07537143, grad/param norm = 3.2028e-01, time/batch = 18.0360s	
8061/11850 (epoch 34.013), train_loss = 1.06669796, grad/param norm = 2.9596e-01, time/batch = 18.1275s	
8062/11850 (epoch 34.017), train_loss = 1.09928111, grad/param norm = 2.8629e-01, time/batch = 16.8955s	
8063/11850 (epoch 34.021), train_loss = 1.03532269, grad/param norm = 2.7042e-01, time/batch = 19.1200s	
8064/11850 (epoch 34.025), train_loss = 0.93148166, grad/param norm = 2.5718e-01, time/batch = 17.5368s	
8065/11850 (epoch 34.030), train_loss = 0.96488989, grad/param norm = 2.8612e-01, time/batch = 17.3760s	
8066/11850 (epoch 34.034), train_loss = 0.93093893, grad/param norm = 2.6641e-01, time/batch = 18.6369s	
8067/11850 (epoch 34.038), train_loss = 0.95821459, grad/param norm = 2.6470e-01, time/batch = 17.2945s	
8068/11850 (epoch 34.042), train_loss = 1.00560367, grad/param norm = 2.9237e-01, time/batch = 16.1510s	
8069/11850 (epoch 34.046), train_loss = 0.94826142, grad/param norm = 2.9963e-01, time/batch = 17.4769s	
8070/11850 (epoch 34.051), train_loss = 0.97794507, grad/param norm = 2.7881e-01, time/batch = 17.3109s	
8071/11850 (epoch 34.055), train_loss = 0.92982703, grad/param norm = 2.4894e-01, time/batch = 15.3344s	
8072/11850 (epoch 34.059), train_loss = 1.02824494, grad/param norm = 2.6091e-01, time/batch = 15.7016s	
8073/11850 (epoch 34.063), train_loss = 1.04558947, grad/param norm = 2.7954e-01, time/batch = 15.8004s	
8074/11850 (epoch 34.068), train_loss = 0.97199334, grad/param norm = 2.5917e-01, time/batch = 17.2995s	
8075/11850 (epoch 34.072), train_loss = 1.04117477, grad/param norm = 2.8190e-01, time/batch = 16.3892s	
8076/11850 (epoch 34.076), train_loss = 1.09926642, grad/param norm = 2.8246e-01, time/batch = 16.6529s	
8077/11850 (epoch 34.080), train_loss = 0.91303552, grad/param norm = 2.7033e-01, time/batch = 17.4850s	
8078/11850 (epoch 34.084), train_loss = 0.85941631, grad/param norm = 2.5004e-01, time/batch = 17.8640s	
8079/11850 (epoch 34.089), train_loss = 0.87037832, grad/param norm = 2.5488e-01, time/batch = 16.5664s	
8080/11850 (epoch 34.093), train_loss = 0.87623474, grad/param norm = 2.7804e-01, time/batch = 18.8030s	
8081/11850 (epoch 34.097), train_loss = 0.99883053, grad/param norm = 2.8663e-01, time/batch = 18.2938s	
8082/11850 (epoch 34.101), train_loss = 0.90225793, grad/param norm = 2.8270e-01, time/batch = 15.6156s	
8083/11850 (epoch 34.105), train_loss = 0.87200181, grad/param norm = 2.4399e-01, time/batch = 18.1403s	
8084/11850 (epoch 34.110), train_loss = 1.00914592, grad/param norm = 2.4508e-01, time/batch = 16.6571s	
8085/11850 (epoch 34.114), train_loss = 0.92720033, grad/param norm = 2.7936e-01, time/batch = 17.8820s	
8086/11850 (epoch 34.118), train_loss = 1.02579437, grad/param norm = 2.5471e-01, time/batch = 18.3888s	
8087/11850 (epoch 34.122), train_loss = 1.06764190, grad/param norm = 2.7386e-01, time/batch = 17.8820s	
8088/11850 (epoch 34.127), train_loss = 1.00148078, grad/param norm = 2.6570e-01, time/batch = 16.4713s	
8089/11850 (epoch 34.131), train_loss = 0.96405289, grad/param norm = 2.9407e-01, time/batch = 18.2961s	
8090/11850 (epoch 34.135), train_loss = 0.97114409, grad/param norm = 3.2520e-01, time/batch = 16.8077s	
8091/11850 (epoch 34.139), train_loss = 0.96007751, grad/param norm = 2.7287e-01, time/batch = 18.0423s	
8092/11850 (epoch 34.143), train_loss = 0.94442872, grad/param norm = 2.7085e-01, time/batch = 16.2782s	
8093/11850 (epoch 34.148), train_loss = 0.94283123, grad/param norm = 3.0591e-01, time/batch = 17.6439s	
8094/11850 (epoch 34.152), train_loss = 1.05317072, grad/param norm = 3.6239e-01, time/batch = 18.6312s	
8095/11850 (epoch 34.156), train_loss = 0.92359101, grad/param norm = 3.1922e-01, time/batch = 17.1256s	
8096/11850 (epoch 34.160), train_loss = 1.14614556, grad/param norm = 3.9957e-01, time/batch = 17.8810s	
8097/11850 (epoch 34.165), train_loss = 1.07165814, grad/param norm = 3.9670e-01, time/batch = 16.4475s	
8098/11850 (epoch 34.169), train_loss = 0.95999901, grad/param norm = 3.1645e-01, time/batch = 17.3102s	
8099/11850 (epoch 34.173), train_loss = 1.04201614, grad/param norm = 2.8487e-01, time/batch = 18.2100s	
8100/11850 (epoch 34.177), train_loss = 0.90538414, grad/param norm = 3.4828e-01, time/batch = 16.3940s	
8101/11850 (epoch 34.181), train_loss = 1.00794424, grad/param norm = 2.7027e-01, time/batch = 19.3659s	
8102/11850 (epoch 34.186), train_loss = 1.08617302, grad/param norm = 3.6222e-01, time/batch = 15.6946s	
8103/11850 (epoch 34.190), train_loss = 1.00668856, grad/param norm = 2.9837e-01, time/batch = 17.7288s	
8104/11850 (epoch 34.194), train_loss = 1.03847974, grad/param norm = 3.1436e-01, time/batch = 18.7880s	
8105/11850 (epoch 34.198), train_loss = 0.81916436, grad/param norm = 3.0032e-01, time/batch = 16.8688s	
8106/11850 (epoch 34.203), train_loss = 0.84461537, grad/param norm = 2.6231e-01, time/batch = 16.1272s	
8107/11850 (epoch 34.207), train_loss = 1.01960311, grad/param norm = 3.1638e-01, time/batch = 16.6382s	
8108/11850 (epoch 34.211), train_loss = 0.96904424, grad/param norm = 3.0151e-01, time/batch = 18.5469s	
8109/11850 (epoch 34.215), train_loss = 0.99229773, grad/param norm = 3.2817e-01, time/batch = 17.1945s	
8110/11850 (epoch 34.219), train_loss = 1.00769074, grad/param norm = 2.8933e-01, time/batch = 17.9696s	
8111/11850 (epoch 34.224), train_loss = 1.12653170, grad/param norm = 3.0200e-01, time/batch = 17.3855s	
8112/11850 (epoch 34.228), train_loss = 1.01516947, grad/param norm = 3.0884e-01, time/batch = 17.4640s	
8113/11850 (epoch 34.232), train_loss = 0.98664453, grad/param norm = 2.7155e-01, time/batch = 18.9702s	
8114/11850 (epoch 34.236), train_loss = 0.91151540, grad/param norm = 2.9476e-01, time/batch = 17.6389s	
8115/11850 (epoch 34.241), train_loss = 1.03603835, grad/param norm = 4.2416e-01, time/batch = 17.9662s	
8116/11850 (epoch 34.245), train_loss = 1.04224970, grad/param norm = 2.6561e-01, time/batch = 16.8897s	
8117/11850 (epoch 34.249), train_loss = 0.96229661, grad/param norm = 2.6607e-01, time/batch = 18.1334s	
8118/11850 (epoch 34.253), train_loss = 0.97832095, grad/param norm = 3.2825e-01, time/batch = 18.6311s	
8119/11850 (epoch 34.257), train_loss = 1.09952437, grad/param norm = 3.0718e-01, time/batch = 16.6740s	
8120/11850 (epoch 34.262), train_loss = 1.10247563, grad/param norm = 3.3398e-01, time/batch = 18.8853s	
8121/11850 (epoch 34.266), train_loss = 1.08545007, grad/param norm = 3.4909e-01, time/batch = 18.7919s	
8122/11850 (epoch 34.270), train_loss = 0.97853062, grad/param norm = 2.9236e-01, time/batch = 16.4498s	
8123/11850 (epoch 34.274), train_loss = 0.96701945, grad/param norm = 2.9830e-01, time/batch = 18.3952s	
8124/11850 (epoch 34.278), train_loss = 0.87779333, grad/param norm = 3.1261e-01, time/batch = 17.7174s	
8125/11850 (epoch 34.283), train_loss = 0.96453290, grad/param norm = 2.7040e-01, time/batch = 16.2535s	
8126/11850 (epoch 34.287), train_loss = 1.09043745, grad/param norm = 2.8834e-01, time/batch = 16.8730s	
8127/11850 (epoch 34.291), train_loss = 0.96206806, grad/param norm = 3.2754e-01, time/batch = 17.2095s	
8128/11850 (epoch 34.295), train_loss = 1.03554871, grad/param norm = 2.8238e-01, time/batch = 18.2136s	
8129/11850 (epoch 34.300), train_loss = 0.95715854, grad/param norm = 3.3440e-01, time/batch = 15.2732s	
8130/11850 (epoch 34.304), train_loss = 0.96910624, grad/param norm = 2.5662e-01, time/batch = 19.9485s	
8131/11850 (epoch 34.308), train_loss = 0.94989945, grad/param norm = 2.4960e-01, time/batch = 19.2150s	
8132/11850 (epoch 34.312), train_loss = 0.87361448, grad/param norm = 2.8041e-01, time/batch = 17.2157s	
8133/11850 (epoch 34.316), train_loss = 0.99706520, grad/param norm = 2.5792e-01, time/batch = 16.5644s	
8134/11850 (epoch 34.321), train_loss = 0.95522950, grad/param norm = 2.6676e-01, time/batch = 18.4707s	
8135/11850 (epoch 34.325), train_loss = 0.98020452, grad/param norm = 2.6684e-01, time/batch = 18.8664s	
8136/11850 (epoch 34.329), train_loss = 0.98699122, grad/param norm = 3.0716e-01, time/batch = 17.3690s	
8137/11850 (epoch 34.333), train_loss = 0.95309353, grad/param norm = 2.9485e-01, time/batch = 13.7613s	
8138/11850 (epoch 34.338), train_loss = 0.93061198, grad/param norm = 2.5302e-01, time/batch = 18.0450s	
8139/11850 (epoch 34.342), train_loss = 0.95749037, grad/param norm = 2.7425e-01, time/batch = 22.0504s	
8140/11850 (epoch 34.346), train_loss = 0.94502201, grad/param norm = 2.7600e-01, time/batch = 26.2110s	
8141/11850 (epoch 34.350), train_loss = 0.86288221, grad/param norm = 2.6014e-01, time/batch = 17.3857s	
8142/11850 (epoch 34.354), train_loss = 1.02421436, grad/param norm = 2.4325e-01, time/batch = 15.3005s	
8143/11850 (epoch 34.359), train_loss = 1.10813009, grad/param norm = 4.5835e-01, time/batch = 18.4733s	
8144/11850 (epoch 34.363), train_loss = 1.02258118, grad/param norm = 3.0462e-01, time/batch = 18.5487s	
8145/11850 (epoch 34.367), train_loss = 1.04259927, grad/param norm = 2.7250e-01, time/batch = 15.0339s	
8146/11850 (epoch 34.371), train_loss = 1.02209275, grad/param norm = 2.8222e-01, time/batch = 18.2960s	
8147/11850 (epoch 34.376), train_loss = 0.97682422, grad/param norm = 2.7490e-01, time/batch = 17.4445s	
8148/11850 (epoch 34.380), train_loss = 0.95512324, grad/param norm = 2.7080e-01, time/batch = 19.2909s	
8149/11850 (epoch 34.384), train_loss = 0.89633969, grad/param norm = 2.7727e-01, time/batch = 18.6153s	
8150/11850 (epoch 34.388), train_loss = 1.04999213, grad/param norm = 3.1459e-01, time/batch = 17.4726s	
8151/11850 (epoch 34.392), train_loss = 1.00459820, grad/param norm = 2.7327e-01, time/batch = 18.3877s	
8152/11850 (epoch 34.397), train_loss = 1.02803266, grad/param norm = 2.9286e-01, time/batch = 16.2994s	
8153/11850 (epoch 34.401), train_loss = 0.85929066, grad/param norm = 2.3731e-01, time/batch = 17.7306s	
8154/11850 (epoch 34.405), train_loss = 0.90718332, grad/param norm = 2.8202e-01, time/batch = 18.0552s	
8155/11850 (epoch 34.409), train_loss = 1.03162645, grad/param norm = 2.9959e-01, time/batch = 17.7080s	
8156/11850 (epoch 34.414), train_loss = 0.82529302, grad/param norm = 2.5040e-01, time/batch = 1.5054s	
8157/11850 (epoch 34.418), train_loss = 0.87732897, grad/param norm = 2.8815e-01, time/batch = 0.6680s	
8158/11850 (epoch 34.422), train_loss = 0.80172272, grad/param norm = 2.6070e-01, time/batch = 0.6600s	
8159/11850 (epoch 34.426), train_loss = 0.81915532, grad/param norm = 2.8082e-01, time/batch = 0.6663s	
8160/11850 (epoch 34.430), train_loss = 0.88567221, grad/param norm = 3.3237e-01, time/batch = 0.6429s	
8161/11850 (epoch 34.435), train_loss = 0.90617364, grad/param norm = 2.8252e-01, time/batch = 0.6534s	
8162/11850 (epoch 34.439), train_loss = 1.00409931, grad/param norm = 2.7834e-01, time/batch = 0.6501s	
8163/11850 (epoch 34.443), train_loss = 0.94289805, grad/param norm = 2.7409e-01, time/batch = 0.7547s	
8164/11850 (epoch 34.447), train_loss = 0.87772978, grad/param norm = 2.6908e-01, time/batch = 0.9460s	
8165/11850 (epoch 34.451), train_loss = 0.86707047, grad/param norm = 2.6632e-01, time/batch = 0.9460s	
8166/11850 (epoch 34.456), train_loss = 0.96686751, grad/param norm = 3.5168e-01, time/batch = 0.9464s	
8167/11850 (epoch 34.460), train_loss = 0.99686309, grad/param norm = 2.5656e-01, time/batch = 0.9348s	
8168/11850 (epoch 34.464), train_loss = 0.91096128, grad/param norm = 3.1796e-01, time/batch = 1.0074s	
8169/11850 (epoch 34.468), train_loss = 0.99383584, grad/param norm = 2.7523e-01, time/batch = 1.7648s	
8170/11850 (epoch 34.473), train_loss = 1.04198924, grad/param norm = 3.1710e-01, time/batch = 1.7960s	
8171/11850 (epoch 34.477), train_loss = 0.86265556, grad/param norm = 2.5978e-01, time/batch = 7.1607s	
8172/11850 (epoch 34.481), train_loss = 0.89875261, grad/param norm = 2.6516e-01, time/batch = 16.6439s	
8173/11850 (epoch 34.485), train_loss = 0.84924760, grad/param norm = 2.3911e-01, time/batch = 18.0526s	
8174/11850 (epoch 34.489), train_loss = 0.97382133, grad/param norm = 2.6709e-01, time/batch = 16.1937s	
8175/11850 (epoch 34.494), train_loss = 0.86096152, grad/param norm = 2.8162e-01, time/batch = 17.1444s	
8176/11850 (epoch 34.498), train_loss = 0.86734139, grad/param norm = 2.7486e-01, time/batch = 17.7323s	
8177/11850 (epoch 34.502), train_loss = 0.85195442, grad/param norm = 3.0348e-01, time/batch = 16.0289s	
8178/11850 (epoch 34.506), train_loss = 1.10985480, grad/param norm = 2.8744e-01, time/batch = 18.3818s	
8179/11850 (epoch 34.511), train_loss = 0.94510882, grad/param norm = 2.6127e-01, time/batch = 18.6343s	
8180/11850 (epoch 34.515), train_loss = 1.04446017, grad/param norm = 3.2649e-01, time/batch = 17.4569s	
8181/11850 (epoch 34.519), train_loss = 0.91039139, grad/param norm = 2.6691e-01, time/batch = 17.5318s	
8182/11850 (epoch 34.523), train_loss = 0.95940156, grad/param norm = 2.6252e-01, time/batch = 17.8661s	
8183/11850 (epoch 34.527), train_loss = 0.88430903, grad/param norm = 2.5115e-01, time/batch = 17.9685s	
8184/11850 (epoch 34.532), train_loss = 0.97260571, grad/param norm = 2.7566e-01, time/batch = 16.2176s	
8185/11850 (epoch 34.536), train_loss = 0.93412134, grad/param norm = 2.9205e-01, time/batch = 17.8984s	
8186/11850 (epoch 34.540), train_loss = 0.87707575, grad/param norm = 2.7764e-01, time/batch = 18.7125s	
8187/11850 (epoch 34.544), train_loss = 0.86561506, grad/param norm = 3.1469e-01, time/batch = 16.0465s	
8188/11850 (epoch 34.549), train_loss = 0.81488862, grad/param norm = 2.4167e-01, time/batch = 16.3880s	
8189/11850 (epoch 34.553), train_loss = 0.95806711, grad/param norm = 2.7934e-01, time/batch = 13.6683s	
8190/11850 (epoch 34.557), train_loss = 0.97996236, grad/param norm = 3.2162e-01, time/batch = 18.2104s	
8191/11850 (epoch 34.561), train_loss = 0.98435408, grad/param norm = 2.8544e-01, time/batch = 15.8716s	
8192/11850 (epoch 34.565), train_loss = 1.08854626, grad/param norm = 3.1803e-01, time/batch = 18.8710s	
8193/11850 (epoch 34.570), train_loss = 0.98317378, grad/param norm = 2.8073e-01, time/batch = 18.8787s	
8194/11850 (epoch 34.574), train_loss = 0.99902849, grad/param norm = 2.7701e-01, time/batch = 17.5490s	
8195/11850 (epoch 34.578), train_loss = 1.03667925, grad/param norm = 3.1863e-01, time/batch = 18.2247s	
8196/11850 (epoch 34.582), train_loss = 0.91360779, grad/param norm = 2.8322e-01, time/batch = 16.4707s	
8197/11850 (epoch 34.586), train_loss = 0.92777619, grad/param norm = 2.7262e-01, time/batch = 18.8550s	
8198/11850 (epoch 34.591), train_loss = 0.97699864, grad/param norm = 3.0543e-01, time/batch = 15.0847s	
8199/11850 (epoch 34.595), train_loss = 0.82472465, grad/param norm = 2.4832e-01, time/batch = 14.6837s	
8200/11850 (epoch 34.599), train_loss = 0.95430788, grad/param norm = 3.1004e-01, time/batch = 15.8681s	
8201/11850 (epoch 34.603), train_loss = 0.89575311, grad/param norm = 2.3605e-01, time/batch = 18.3752s	
8202/11850 (epoch 34.608), train_loss = 1.07018973, grad/param norm = 2.7100e-01, time/batch = 17.0538s	
8203/11850 (epoch 34.612), train_loss = 1.13632319, grad/param norm = 3.0371e-01, time/batch = 18.1275s	
8204/11850 (epoch 34.616), train_loss = 1.06553564, grad/param norm = 2.8346e-01, time/batch = 19.3799s	
8205/11850 (epoch 34.620), train_loss = 0.94597734, grad/param norm = 2.5825e-01, time/batch = 15.1114s	
8206/11850 (epoch 34.624), train_loss = 0.94347166, grad/param norm = 2.9837e-01, time/batch = 17.8827s	
8207/11850 (epoch 34.629), train_loss = 0.92056601, grad/param norm = 2.9815e-01, time/batch = 16.8194s	
8208/11850 (epoch 34.633), train_loss = 0.84620369, grad/param norm = 2.8627e-01, time/batch = 17.8678s	
8209/11850 (epoch 34.637), train_loss = 0.79208353, grad/param norm = 2.7530e-01, time/batch = 18.2787s	
8210/11850 (epoch 34.641), train_loss = 0.85285212, grad/param norm = 2.4928e-01, time/batch = 15.0700s	
8211/11850 (epoch 34.646), train_loss = 0.85391055, grad/param norm = 2.5855e-01, time/batch = 19.5476s	
8212/11850 (epoch 34.650), train_loss = 0.95598597, grad/param norm = 3.6165e-01, time/batch = 18.6994s	
8213/11850 (epoch 34.654), train_loss = 0.89297065, grad/param norm = 3.0736e-01, time/batch = 17.4620s	
8214/11850 (epoch 34.658), train_loss = 0.98440296, grad/param norm = 2.9602e-01, time/batch = 18.6299s	
8215/11850 (epoch 34.662), train_loss = 0.84292479, grad/param norm = 3.7636e-01, time/batch = 15.2840s	
8216/11850 (epoch 34.667), train_loss = 1.01588885, grad/param norm = 2.6920e-01, time/batch = 18.1392s	
8217/11850 (epoch 34.671), train_loss = 0.92886524, grad/param norm = 3.0069e-01, time/batch = 17.2198s	
8218/11850 (epoch 34.675), train_loss = 0.92241873, grad/param norm = 2.9174e-01, time/batch = 16.0608s	
8219/11850 (epoch 34.679), train_loss = 0.95184653, grad/param norm = 2.8405e-01, time/batch = 16.6156s	
8220/11850 (epoch 34.684), train_loss = 0.92270019, grad/param norm = 3.4215e-01, time/batch = 16.9772s	
8221/11850 (epoch 34.688), train_loss = 0.87905109, grad/param norm = 2.8396e-01, time/batch = 17.2067s	
8222/11850 (epoch 34.692), train_loss = 0.89847068, grad/param norm = 3.1806e-01, time/batch = 14.9793s	
8223/11850 (epoch 34.696), train_loss = 0.87795340, grad/param norm = 3.5491e-01, time/batch = 18.7147s	
8224/11850 (epoch 34.700), train_loss = 0.94905340, grad/param norm = 2.8207e-01, time/batch = 17.9774s	
8225/11850 (epoch 34.705), train_loss = 0.87615579, grad/param norm = 2.8545e-01, time/batch = 17.1259s	
8226/11850 (epoch 34.709), train_loss = 0.81555585, grad/param norm = 2.7303e-01, time/batch = 15.8843s	
8227/11850 (epoch 34.713), train_loss = 0.83516600, grad/param norm = 2.8556e-01, time/batch = 16.9840s	
8228/11850 (epoch 34.717), train_loss = 0.89036027, grad/param norm = 2.8924e-01, time/batch = 17.7960s	
8229/11850 (epoch 34.722), train_loss = 0.94094765, grad/param norm = 3.0198e-01, time/batch = 15.5279s	
8230/11850 (epoch 34.726), train_loss = 0.85294164, grad/param norm = 2.7252e-01, time/batch = 15.7844s	
8231/11850 (epoch 34.730), train_loss = 0.86188887, grad/param norm = 2.7690e-01, time/batch = 18.5484s	
8232/11850 (epoch 34.734), train_loss = 0.86461609, grad/param norm = 2.5935e-01, time/batch = 17.8023s	
8233/11850 (epoch 34.738), train_loss = 0.97959179, grad/param norm = 2.9547e-01, time/batch = 18.4552s	
8234/11850 (epoch 34.743), train_loss = 0.94231408, grad/param norm = 3.0234e-01, time/batch = 18.4577s	
8235/11850 (epoch 34.747), train_loss = 0.82450376, grad/param norm = 2.4841e-01, time/batch = 17.5392s	
8236/11850 (epoch 34.751), train_loss = 0.90180572, grad/param norm = 2.7210e-01, time/batch = 16.3829s	
8237/11850 (epoch 34.755), train_loss = 0.95361548, grad/param norm = 2.7844e-01, time/batch = 17.7944s	
8238/11850 (epoch 34.759), train_loss = 0.87865554, grad/param norm = 2.7526e-01, time/batch = 18.9746s	
8239/11850 (epoch 34.764), train_loss = 0.90791597, grad/param norm = 2.5983e-01, time/batch = 17.2841s	
8240/11850 (epoch 34.768), train_loss = 0.83184509, grad/param norm = 2.7793e-01, time/batch = 17.6329s	
8241/11850 (epoch 34.772), train_loss = 0.88353092, grad/param norm = 2.7529e-01, time/batch = 17.5604s	
8242/11850 (epoch 34.776), train_loss = 0.95819571, grad/param norm = 2.8155e-01, time/batch = 17.8076s	
8243/11850 (epoch 34.781), train_loss = 0.90181244, grad/param norm = 2.7484e-01, time/batch = 16.6143s	
8244/11850 (epoch 34.785), train_loss = 0.90164640, grad/param norm = 3.5113e-01, time/batch = 17.9727s	
8245/11850 (epoch 34.789), train_loss = 0.91682823, grad/param norm = 2.8784e-01, time/batch = 17.2022s	
8246/11850 (epoch 34.793), train_loss = 0.98378387, grad/param norm = 3.2686e-01, time/batch = 17.1378s	
8247/11850 (epoch 34.797), train_loss = 0.92521637, grad/param norm = 2.9801e-01, time/batch = 16.7957s	
8248/11850 (epoch 34.802), train_loss = 0.85727498, grad/param norm = 2.7224e-01, time/batch = 19.2842s	
8249/11850 (epoch 34.806), train_loss = 0.92510287, grad/param norm = 3.0433e-01, time/batch = 17.4724s	
8250/11850 (epoch 34.810), train_loss = 0.98426548, grad/param norm = 3.1608e-01, time/batch = 18.9515s	
8251/11850 (epoch 34.814), train_loss = 0.93711991, grad/param norm = 2.7940e-01, time/batch = 16.9810s	
8252/11850 (epoch 34.819), train_loss = 1.02352635, grad/param norm = 2.8366e-01, time/batch = 18.6299s	
8253/11850 (epoch 34.823), train_loss = 1.06311899, grad/param norm = 3.3778e-01, time/batch = 17.6226s	
8254/11850 (epoch 34.827), train_loss = 0.93311452, grad/param norm = 3.2268e-01, time/batch = 15.8829s	
8255/11850 (epoch 34.831), train_loss = 0.91146376, grad/param norm = 2.9167e-01, time/batch = 17.6249s	
8256/11850 (epoch 34.835), train_loss = 0.96777858, grad/param norm = 2.7646e-01, time/batch = 17.1152s	
8257/11850 (epoch 34.840), train_loss = 0.89795931, grad/param norm = 3.0654e-01, time/batch = 17.8766s	
8258/11850 (epoch 34.844), train_loss = 0.92621455, grad/param norm = 2.3472e-01, time/batch = 16.4966s	
8259/11850 (epoch 34.848), train_loss = 0.95820818, grad/param norm = 2.7806e-01, time/batch = 18.2195s	
8260/11850 (epoch 34.852), train_loss = 0.94894069, grad/param norm = 3.4759e-01, time/batch = 15.1959s	
8261/11850 (epoch 34.857), train_loss = 0.90360116, grad/param norm = 2.7864e-01, time/batch = 18.1299s	
8262/11850 (epoch 34.861), train_loss = 0.87120502, grad/param norm = 3.0377e-01, time/batch = 15.6850s	
8263/11850 (epoch 34.865), train_loss = 0.97254071, grad/param norm = 4.3997e-01, time/batch = 17.0625s	
8264/11850 (epoch 34.869), train_loss = 0.95997930, grad/param norm = 3.0823e-01, time/batch = 18.7991s	
8265/11850 (epoch 34.873), train_loss = 0.96573903, grad/param norm = 2.9290e-01, time/batch = 13.9341s	
8266/11850 (epoch 34.878), train_loss = 0.98966359, grad/param norm = 4.1763e-01, time/batch = 14.9638s	
8267/11850 (epoch 34.882), train_loss = 0.96514236, grad/param norm = 3.5437e-01, time/batch = 15.4610s	
8268/11850 (epoch 34.886), train_loss = 0.95585618, grad/param norm = 4.6195e-01, time/batch = 17.8827s	
8269/11850 (epoch 34.890), train_loss = 0.95647302, grad/param norm = 3.1157e-01, time/batch = 17.8893s	
8270/11850 (epoch 34.895), train_loss = 0.98873262, grad/param norm = 4.1669e-01, time/batch = 17.7863s	
8271/11850 (epoch 34.899), train_loss = 0.85676444, grad/param norm = 3.2101e-01, time/batch = 18.7791s	
8272/11850 (epoch 34.903), train_loss = 0.90093753, grad/param norm = 3.0576e-01, time/batch = 18.0657s	
8273/11850 (epoch 34.907), train_loss = 0.90535866, grad/param norm = 2.9098e-01, time/batch = 19.0505s	
8274/11850 (epoch 34.911), train_loss = 1.03742844, grad/param norm = 2.8752e-01, time/batch = 17.5368s	
8275/11850 (epoch 34.916), train_loss = 0.99867388, grad/param norm = 3.4649e-01, time/batch = 17.6257s	
8276/11850 (epoch 34.920), train_loss = 0.96537215, grad/param norm = 2.8675e-01, time/batch = 18.1338s	
8277/11850 (epoch 34.924), train_loss = 0.92239065, grad/param norm = 3.3790e-01, time/batch = 16.0477s	
8278/11850 (epoch 34.928), train_loss = 0.98099675, grad/param norm = 3.0755e-01, time/batch = 17.3630s	
8279/11850 (epoch 34.932), train_loss = 1.03419341, grad/param norm = 2.8062e-01, time/batch = 17.9550s	
8280/11850 (epoch 34.937), train_loss = 1.02701817, grad/param norm = 3.0718e-01, time/batch = 17.3583s	
8281/11850 (epoch 34.941), train_loss = 0.98444581, grad/param norm = 2.9210e-01, time/batch = 17.0370s	
8282/11850 (epoch 34.945), train_loss = 1.01562243, grad/param norm = 3.4326e-01, time/batch = 18.7907s	
8283/11850 (epoch 34.949), train_loss = 0.90693209, grad/param norm = 3.2934e-01, time/batch = 19.5381s	
8284/11850 (epoch 34.954), train_loss = 1.02090163, grad/param norm = 4.5588e-01, time/batch = 17.2978s	
8285/11850 (epoch 34.958), train_loss = 0.99161973, grad/param norm = 2.9439e-01, time/batch = 16.9872s	
8286/11850 (epoch 34.962), train_loss = 0.89598574, grad/param norm = 3.0477e-01, time/batch = 18.6262s	
8287/11850 (epoch 34.966), train_loss = 0.86537883, grad/param norm = 3.1338e-01, time/batch = 17.3751s	
8288/11850 (epoch 34.970), train_loss = 0.96982070, grad/param norm = 2.7871e-01, time/batch = 17.8036s	
8289/11850 (epoch 34.975), train_loss = 0.93082406, grad/param norm = 2.8222e-01, time/batch = 16.9588s	
8290/11850 (epoch 34.979), train_loss = 0.96477271, grad/param norm = 3.3074e-01, time/batch = 17.8893s	
8291/11850 (epoch 34.983), train_loss = 1.03301545, grad/param norm = 4.3208e-01, time/batch = 15.7960s	
8292/11850 (epoch 34.987), train_loss = 0.89138689, grad/param norm = 2.7859e-01, time/batch = 17.1511s	
8293/11850 (epoch 34.992), train_loss = 1.07552757, grad/param norm = 3.0235e-01, time/batch = 17.4753s	
8294/11850 (epoch 34.996), train_loss = 1.06399516, grad/param norm = 3.0507e-01, time/batch = 17.2177s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
8295/11850 (epoch 35.000), train_loss = 0.94964832, grad/param norm = 3.9939e-01, time/batch = 17.1997s	
8296/11850 (epoch 35.004), train_loss = 1.02211246, grad/param norm = 3.6816e-01, time/batch = 17.8881s	
8297/11850 (epoch 35.008), train_loss = 1.05831633, grad/param norm = 3.1944e-01, time/batch = 16.9432s	
8298/11850 (epoch 35.013), train_loss = 1.06441718, grad/param norm = 3.0685e-01, time/batch = 17.8803s	
8299/11850 (epoch 35.017), train_loss = 1.09699534, grad/param norm = 3.3880e-01, time/batch = 17.0490s	
8300/11850 (epoch 35.021), train_loss = 1.04306215, grad/param norm = 2.6695e-01, time/batch = 14.5609s	
8301/11850 (epoch 35.025), train_loss = 0.91101335, grad/param norm = 2.5516e-01, time/batch = 16.6376s	
8302/11850 (epoch 35.030), train_loss = 0.94466166, grad/param norm = 3.1103e-01, time/batch = 18.3901s	
8303/11850 (epoch 35.034), train_loss = 0.93617179, grad/param norm = 2.9517e-01, time/batch = 16.8974s	
8304/11850 (epoch 35.038), train_loss = 0.96217584, grad/param norm = 3.2479e-01, time/batch = 18.0385s	
8305/11850 (epoch 35.042), train_loss = 0.98071547, grad/param norm = 2.9370e-01, time/batch = 18.4735s	
8306/11850 (epoch 35.046), train_loss = 0.95247617, grad/param norm = 3.6138e-01, time/batch = 17.8793s	
8307/11850 (epoch 35.051), train_loss = 0.96359528, grad/param norm = 2.7805e-01, time/batch = 18.2201s	
8308/11850 (epoch 35.055), train_loss = 0.92347995, grad/param norm = 2.6252e-01, time/batch = 16.0467s	
8309/11850 (epoch 35.059), train_loss = 1.01713624, grad/param norm = 2.8000e-01, time/batch = 17.3210s	
8310/11850 (epoch 35.063), train_loss = 1.03581279, grad/param norm = 3.1685e-01, time/batch = 16.3111s	
8311/11850 (epoch 35.068), train_loss = 0.95438114, grad/param norm = 2.6214e-01, time/batch = 16.4856s	
8312/11850 (epoch 35.072), train_loss = 1.01472879, grad/param norm = 3.0417e-01, time/batch = 16.4693s	
8313/11850 (epoch 35.076), train_loss = 1.08169840, grad/param norm = 3.0963e-01, time/batch = 15.7376s	
8314/11850 (epoch 35.080), train_loss = 0.90262632, grad/param norm = 2.6798e-01, time/batch = 17.8008s	
8315/11850 (epoch 35.084), train_loss = 0.85830423, grad/param norm = 2.5431e-01, time/batch = 15.5344s	
8316/11850 (epoch 35.089), train_loss = 0.86199414, grad/param norm = 2.8305e-01, time/batch = 16.8840s	
8317/11850 (epoch 35.093), train_loss = 0.86885819, grad/param norm = 2.9208e-01, time/batch = 17.6301s	
8318/11850 (epoch 35.097), train_loss = 0.97396334, grad/param norm = 2.8666e-01, time/batch = 16.2019s	
8319/11850 (epoch 35.101), train_loss = 0.89228858, grad/param norm = 3.2031e-01, time/batch = 17.6354s	
8320/11850 (epoch 35.105), train_loss = 0.85680416, grad/param norm = 2.5584e-01, time/batch = 17.5531s	
8321/11850 (epoch 35.110), train_loss = 1.00995083, grad/param norm = 2.8551e-01, time/batch = 19.3695s	
8322/11850 (epoch 35.114), train_loss = 0.90500541, grad/param norm = 2.7807e-01, time/batch = 16.6213s	
8323/11850 (epoch 35.118), train_loss = 1.01654464, grad/param norm = 2.6562e-01, time/batch = 18.2961s	
8324/11850 (epoch 35.122), train_loss = 1.06146352, grad/param norm = 2.8680e-01, time/batch = 19.3002s	
8325/11850 (epoch 35.127), train_loss = 1.00413138, grad/param norm = 3.0929e-01, time/batch = 16.5475s	
8326/11850 (epoch 35.131), train_loss = 0.95673300, grad/param norm = 3.2257e-01, time/batch = 17.8932s	
8327/11850 (epoch 35.135), train_loss = 0.96331466, grad/param norm = 3.0642e-01, time/batch = 16.0611s	
8328/11850 (epoch 35.139), train_loss = 0.94856641, grad/param norm = 2.7420e-01, time/batch = 16.7052s	
8329/11850 (epoch 35.143), train_loss = 0.92594826, grad/param norm = 3.0395e-01, time/batch = 15.6987s	
8330/11850 (epoch 35.148), train_loss = 0.91903375, grad/param norm = 2.9399e-01, time/batch = 16.7412s	
8331/11850 (epoch 35.152), train_loss = 1.03280062, grad/param norm = 3.2331e-01, time/batch = 18.6377s	
8332/11850 (epoch 35.156), train_loss = 0.92205531, grad/param norm = 3.8223e-01, time/batch = 18.2068s	
8333/11850 (epoch 35.160), train_loss = 1.12031616, grad/param norm = 3.7741e-01, time/batch = 19.0420s	
8334/11850 (epoch 35.165), train_loss = 1.05714541, grad/param norm = 3.7531e-01, time/batch = 16.9625s	
8335/11850 (epoch 35.169), train_loss = 0.94677228, grad/param norm = 3.7419e-01, time/batch = 18.4631s	
8336/11850 (epoch 35.173), train_loss = 1.01311698, grad/param norm = 3.3311e-01, time/batch = 17.0532s	
8337/11850 (epoch 35.177), train_loss = 0.88621365, grad/param norm = 3.4914e-01, time/batch = 17.6349s	
8338/11850 (epoch 35.181), train_loss = 0.98647981, grad/param norm = 3.1441e-01, time/batch = 14.8760s	
8339/11850 (epoch 35.186), train_loss = 1.08823032, grad/param norm = 4.2317e-01, time/batch = 17.6343s	
8340/11850 (epoch 35.190), train_loss = 0.99997629, grad/param norm = 3.6743e-01, time/batch = 19.2129s	
8341/11850 (epoch 35.194), train_loss = 1.01711725, grad/param norm = 3.9606e-01, time/batch = 17.2131s	
8342/11850 (epoch 35.198), train_loss = 0.80211660, grad/param norm = 2.8970e-01, time/batch = 17.9563s	
8343/11850 (epoch 35.203), train_loss = 0.84428782, grad/param norm = 2.8807e-01, time/batch = 16.3003s	
8344/11850 (epoch 35.207), train_loss = 1.00400090, grad/param norm = 3.0468e-01, time/batch = 17.0315s	
8345/11850 (epoch 35.211), train_loss = 0.95965753, grad/param norm = 3.1708e-01, time/batch = 18.0457s	
8346/11850 (epoch 35.215), train_loss = 0.98505565, grad/param norm = 3.3330e-01, time/batch = 15.6367s	
8347/11850 (epoch 35.219), train_loss = 1.00247752, grad/param norm = 3.4458e-01, time/batch = 19.0386s	
8348/11850 (epoch 35.224), train_loss = 1.11484888, grad/param norm = 3.3660e-01, time/batch = 17.4824s	
8349/11850 (epoch 35.228), train_loss = 1.01048351, grad/param norm = 3.3528e-01, time/batch = 17.2952s	
8350/11850 (epoch 35.232), train_loss = 0.98543166, grad/param norm = 3.4204e-01, time/batch = 18.8701s	
8351/11850 (epoch 35.236), train_loss = 0.89370330, grad/param norm = 2.8747e-01, time/batch = 17.1291s	
8352/11850 (epoch 35.241), train_loss = 1.02082678, grad/param norm = 3.2820e-01, time/batch = 18.7910s	
8353/11850 (epoch 35.245), train_loss = 1.04127903, grad/param norm = 3.2953e-01, time/batch = 18.2138s	
8354/11850 (epoch 35.249), train_loss = 0.95582684, grad/param norm = 2.6299e-01, time/batch = 17.3799s	
8355/11850 (epoch 35.253), train_loss = 0.95801708, grad/param norm = 3.3450e-01, time/batch = 17.7734s	
8356/11850 (epoch 35.257), train_loss = 1.08948944, grad/param norm = 3.1019e-01, time/batch = 17.2185s	
8357/11850 (epoch 35.262), train_loss = 1.09758680, grad/param norm = 3.8185e-01, time/batch = 19.1280s	
8358/11850 (epoch 35.266), train_loss = 1.05407178, grad/param norm = 3.2544e-01, time/batch = 16.7199s	
8359/11850 (epoch 35.270), train_loss = 0.95521765, grad/param norm = 2.6789e-01, time/batch = 20.5091s	
8360/11850 (epoch 35.274), train_loss = 0.95921639, grad/param norm = 2.9936e-01, time/batch = 28.3459s	
8361/11850 (epoch 35.278), train_loss = 0.84374590, grad/param norm = 2.5837e-01, time/batch = 17.6376s	
8362/11850 (epoch 35.283), train_loss = 0.94813635, grad/param norm = 2.5204e-01, time/batch = 15.9523s	
8363/11850 (epoch 35.287), train_loss = 1.08270752, grad/param norm = 3.0724e-01, time/batch = 18.7045s	
8364/11850 (epoch 35.291), train_loss = 0.94801630, grad/param norm = 2.8748e-01, time/batch = 17.1419s	
8365/11850 (epoch 35.295), train_loss = 1.03874778, grad/param norm = 3.1453e-01, time/batch = 15.9492s	
8366/11850 (epoch 35.300), train_loss = 0.94202145, grad/param norm = 3.2011e-01, time/batch = 15.3679s	
8367/11850 (epoch 35.304), train_loss = 0.95079134, grad/param norm = 2.4664e-01, time/batch = 17.8915s	
8368/11850 (epoch 35.308), train_loss = 0.95080992, grad/param norm = 2.7023e-01, time/batch = 16.2284s	
8369/11850 (epoch 35.312), train_loss = 0.85584573, grad/param norm = 2.5890e-01, time/batch = 16.2983s	
8370/11850 (epoch 35.316), train_loss = 0.98269391, grad/param norm = 2.8899e-01, time/batch = 17.7981s	
8371/11850 (epoch 35.321), train_loss = 0.93723092, grad/param norm = 2.7409e-01, time/batch = 18.6299s	
8372/11850 (epoch 35.325), train_loss = 0.95767241, grad/param norm = 2.6681e-01, time/batch = 17.2951s	
8373/11850 (epoch 35.329), train_loss = 0.96578461, grad/param norm = 3.1602e-01, time/batch = 17.0483s	
8374/11850 (epoch 35.333), train_loss = 0.94158750, grad/param norm = 2.9210e-01, time/batch = 16.5718s	
8375/11850 (epoch 35.338), train_loss = 0.91600180, grad/param norm = 2.6250e-01, time/batch = 18.0605s	
8376/11850 (epoch 35.342), train_loss = 0.95758694, grad/param norm = 3.2130e-01, time/batch = 16.3722s	
8377/11850 (epoch 35.346), train_loss = 0.93355585, grad/param norm = 2.9373e-01, time/batch = 18.1512s	
8378/11850 (epoch 35.350), train_loss = 0.84303288, grad/param norm = 2.6483e-01, time/batch = 15.2847s	
8379/11850 (epoch 35.354), train_loss = 1.00072079, grad/param norm = 2.5858e-01, time/batch = 17.6236s	
8380/11850 (epoch 35.359), train_loss = 1.09648292, grad/param norm = 5.1095e-01, time/batch = 16.6075s	
8381/11850 (epoch 35.363), train_loss = 1.00015691, grad/param norm = 2.7683e-01, time/batch = 17.7142s	
8382/11850 (epoch 35.367), train_loss = 1.02648357, grad/param norm = 2.7528e-01, time/batch = 18.8856s	
8383/11850 (epoch 35.371), train_loss = 1.01278636, grad/param norm = 2.8672e-01, time/batch = 17.8704s	
8384/11850 (epoch 35.376), train_loss = 0.96409166, grad/param norm = 2.6688e-01, time/batch = 17.3974s	
8385/11850 (epoch 35.380), train_loss = 0.93051670, grad/param norm = 2.7016e-01, time/batch = 18.5450s	
8386/11850 (epoch 35.384), train_loss = 0.88791088, grad/param norm = 2.8290e-01, time/batch = 17.5328s	
8387/11850 (epoch 35.388), train_loss = 1.03574060, grad/param norm = 3.9871e-01, time/batch = 17.9579s	
8388/11850 (epoch 35.392), train_loss = 0.98719453, grad/param norm = 2.6420e-01, time/batch = 15.5348s	
8389/11850 (epoch 35.397), train_loss = 1.00528498, grad/param norm = 2.8858e-01, time/batch = 18.2074s	
8390/11850 (epoch 35.401), train_loss = 0.85121216, grad/param norm = 2.7386e-01, time/batch = 16.3816s	
8391/11850 (epoch 35.405), train_loss = 0.90255139, grad/param norm = 3.2190e-01, time/batch = 17.8199s	
8392/11850 (epoch 35.409), train_loss = 1.01774752, grad/param norm = 2.6538e-01, time/batch = 17.6425s	
8393/11850 (epoch 35.414), train_loss = 0.82034260, grad/param norm = 2.6442e-01, time/batch = 15.7878s	
8394/11850 (epoch 35.418), train_loss = 0.86090546, grad/param norm = 2.7383e-01, time/batch = 15.9441s	
8395/11850 (epoch 35.422), train_loss = 0.78872284, grad/param norm = 2.5126e-01, time/batch = 16.2173s	
8396/11850 (epoch 35.426), train_loss = 0.80839024, grad/param norm = 2.6342e-01, time/batch = 18.2285s	
8397/11850 (epoch 35.430), train_loss = 0.87857129, grad/param norm = 3.5823e-01, time/batch = 16.0344s	
8398/11850 (epoch 35.435), train_loss = 0.89322500, grad/param norm = 3.4136e-01, time/batch = 18.7193s	
8399/11850 (epoch 35.439), train_loss = 0.98822926, grad/param norm = 2.6159e-01, time/batch = 17.3861s	
8400/11850 (epoch 35.443), train_loss = 0.93141843, grad/param norm = 2.7621e-01, time/batch = 17.3754s	
8401/11850 (epoch 35.447), train_loss = 0.86068957, grad/param norm = 2.6265e-01, time/batch = 19.0469s	
8402/11850 (epoch 35.451), train_loss = 0.84520906, grad/param norm = 2.6438e-01, time/batch = 17.9636s	
8403/11850 (epoch 35.456), train_loss = 0.94033835, grad/param norm = 2.9719e-01, time/batch = 18.1248s	
8404/11850 (epoch 35.460), train_loss = 1.00149237, grad/param norm = 2.8236e-01, time/batch = 17.2994s	
8405/11850 (epoch 35.464), train_loss = 0.89995162, grad/param norm = 2.9957e-01, time/batch = 18.8130s	
8406/11850 (epoch 35.468), train_loss = 0.97716460, grad/param norm = 2.7477e-01, time/batch = 18.0440s	
8407/11850 (epoch 35.473), train_loss = 1.02488606, grad/param norm = 2.9724e-01, time/batch = 16.5317s	
8408/11850 (epoch 35.477), train_loss = 0.84633679, grad/param norm = 2.5316e-01, time/batch = 19.1383s	
8409/11850 (epoch 35.481), train_loss = 0.88281036, grad/param norm = 2.7196e-01, time/batch = 18.8890s	
8410/11850 (epoch 35.485), train_loss = 0.84362556, grad/param norm = 2.4051e-01, time/batch = 16.9607s	
8411/11850 (epoch 35.489), train_loss = 0.95963820, grad/param norm = 2.7247e-01, time/batch = 17.5654s	
8412/11850 (epoch 35.494), train_loss = 0.85203080, grad/param norm = 3.6010e-01, time/batch = 15.8665s	
8413/11850 (epoch 35.498), train_loss = 0.87467947, grad/param norm = 5.8172e-01, time/batch = 17.9666s	
8414/11850 (epoch 35.502), train_loss = 0.83956285, grad/param norm = 3.0457e-01, time/batch = 16.6292s	
8415/11850 (epoch 35.506), train_loss = 1.09028548, grad/param norm = 2.9471e-01, time/batch = 18.0524s	
8416/11850 (epoch 35.511), train_loss = 0.93363371, grad/param norm = 2.9733e-01, time/batch = 18.6277s	
8417/11850 (epoch 35.515), train_loss = 1.03571344, grad/param norm = 3.3826e-01, time/batch = 15.8412s	
8418/11850 (epoch 35.519), train_loss = 0.90668715, grad/param norm = 3.0984e-01, time/batch = 15.0048s	
8419/11850 (epoch 35.523), train_loss = 0.95267089, grad/param norm = 3.1966e-01, time/batch = 17.6422s	
8420/11850 (epoch 35.527), train_loss = 0.89219874, grad/param norm = 3.3607e-01, time/batch = 16.4516s	
8421/11850 (epoch 35.532), train_loss = 0.96531924, grad/param norm = 2.8335e-01, time/batch = 15.9359s	
8422/11850 (epoch 35.536), train_loss = 0.91051852, grad/param norm = 2.7639e-01, time/batch = 19.1330s	
8423/11850 (epoch 35.540), train_loss = 0.85167351, grad/param norm = 2.4866e-01, time/batch = 17.8125s	
8424/11850 (epoch 35.544), train_loss = 0.85805018, grad/param norm = 3.1752e-01, time/batch = 15.4560s	
8425/11850 (epoch 35.549), train_loss = 0.81004505, grad/param norm = 2.6587e-01, time/batch = 18.3035s	
8426/11850 (epoch 35.553), train_loss = 0.95328323, grad/param norm = 3.1157e-01, time/batch = 16.8125s	
8427/11850 (epoch 35.557), train_loss = 0.96761648, grad/param norm = 3.2400e-01, time/batch = 18.2133s	
8428/11850 (epoch 35.561), train_loss = 0.98469322, grad/param norm = 3.2364e-01, time/batch = 16.1403s	
8429/11850 (epoch 35.565), train_loss = 1.07661345, grad/param norm = 3.2195e-01, time/batch = 17.6321s	
8430/11850 (epoch 35.570), train_loss = 0.97382119, grad/param norm = 2.7215e-01, time/batch = 16.8224s	
8431/11850 (epoch 35.574), train_loss = 0.98534061, grad/param norm = 2.9676e-01, time/batch = 16.3040s	
8432/11850 (epoch 35.578), train_loss = 1.02133234, grad/param norm = 3.1070e-01, time/batch = 16.6274s	
8433/11850 (epoch 35.582), train_loss = 0.89495665, grad/param norm = 2.9157e-01, time/batch = 18.3084s	
8434/11850 (epoch 35.586), train_loss = 0.90700654, grad/param norm = 2.8752e-01, time/batch = 16.5961s	
8435/11850 (epoch 35.591), train_loss = 0.96416663, grad/param norm = 3.2985e-01, time/batch = 17.2991s	
8436/11850 (epoch 35.595), train_loss = 0.81062932, grad/param norm = 2.5574e-01, time/batch = 18.6353s	
8437/11850 (epoch 35.599), train_loss = 0.94182245, grad/param norm = 2.9625e-01, time/batch = 15.2880s	
8438/11850 (epoch 35.603), train_loss = 0.89519725, grad/param norm = 2.4113e-01, time/batch = 17.5448s	
8439/11850 (epoch 35.608), train_loss = 1.06499538, grad/param norm = 2.9916e-01, time/batch = 18.5504s	
8440/11850 (epoch 35.612), train_loss = 1.14166652, grad/param norm = 3.3801e-01, time/batch = 17.3105s	
8441/11850 (epoch 35.616), train_loss = 1.05187145, grad/param norm = 2.9492e-01, time/batch = 18.1327s	
8442/11850 (epoch 35.620), train_loss = 0.93614291, grad/param norm = 2.5766e-01, time/batch = 18.5327s	
8443/11850 (epoch 35.624), train_loss = 0.93629098, grad/param norm = 3.4138e-01, time/batch = 17.4653s	
8444/11850 (epoch 35.629), train_loss = 0.90285951, grad/param norm = 2.5318e-01, time/batch = 19.1197s	
8445/11850 (epoch 35.633), train_loss = 0.83319010, grad/param norm = 2.7787e-01, time/batch = 17.6065s	
8446/11850 (epoch 35.637), train_loss = 0.77536187, grad/param norm = 2.6208e-01, time/batch = 16.7246s	
8447/11850 (epoch 35.641), train_loss = 0.82850295, grad/param norm = 2.5288e-01, time/batch = 16.3991s	
8448/11850 (epoch 35.646), train_loss = 0.83149765, grad/param norm = 2.7265e-01, time/batch = 16.8758s	
8449/11850 (epoch 35.650), train_loss = 0.93660102, grad/param norm = 2.9565e-01, time/batch = 18.7810s	
8450/11850 (epoch 35.654), train_loss = 0.87802307, grad/param norm = 3.1408e-01, time/batch = 18.1084s	
8451/11850 (epoch 35.658), train_loss = 0.96327879, grad/param norm = 2.7946e-01, time/batch = 18.1367s	
8452/11850 (epoch 35.662), train_loss = 0.82064998, grad/param norm = 3.1954e-01, time/batch = 15.2815s	
8453/11850 (epoch 35.667), train_loss = 1.00922730, grad/param norm = 2.8421e-01, time/batch = 18.8769s	
8454/11850 (epoch 35.671), train_loss = 0.89623899, grad/param norm = 2.8438e-01, time/batch = 18.3088s	
8455/11850 (epoch 35.675), train_loss = 0.90629321, grad/param norm = 2.8979e-01, time/batch = 17.9673s	
8456/11850 (epoch 35.679), train_loss = 0.93660843, grad/param norm = 2.7519e-01, time/batch = 16.7332s	
8457/11850 (epoch 35.684), train_loss = 0.91185638, grad/param norm = 3.4381e-01, time/batch = 17.7116s	
8458/11850 (epoch 35.688), train_loss = 0.84870010, grad/param norm = 2.6229e-01, time/batch = 17.1192s	
8459/11850 (epoch 35.692), train_loss = 0.87856991, grad/param norm = 2.9294e-01, time/batch = 17.7251s	
8460/11850 (epoch 35.696), train_loss = 0.86470214, grad/param norm = 3.5747e-01, time/batch = 17.4720s	
8461/11850 (epoch 35.700), train_loss = 0.92592481, grad/param norm = 2.7488e-01, time/batch = 18.3784s	
8462/11850 (epoch 35.705), train_loss = 0.86094593, grad/param norm = 2.9270e-01, time/batch = 17.9130s	
8463/11850 (epoch 35.709), train_loss = 0.80493469, grad/param norm = 2.6784e-01, time/batch = 17.9816s	
8464/11850 (epoch 35.713), train_loss = 0.81017531, grad/param norm = 3.0248e-01, time/batch = 17.5602s	
8465/11850 (epoch 35.717), train_loss = 0.86863473, grad/param norm = 2.5140e-01, time/batch = 16.7082s	
8466/11850 (epoch 35.722), train_loss = 0.91566659, grad/param norm = 2.8795e-01, time/batch = 19.2995s	
8467/11850 (epoch 35.726), train_loss = 0.82228103, grad/param norm = 2.6852e-01, time/batch = 17.3788s	
8468/11850 (epoch 35.730), train_loss = 0.84283110, grad/param norm = 2.7911e-01, time/batch = 17.2958s	
8469/11850 (epoch 35.734), train_loss = 0.84645183, grad/param norm = 2.7769e-01, time/batch = 18.5340s	
8470/11850 (epoch 35.738), train_loss = 0.97208028, grad/param norm = 3.2498e-01, time/batch = 17.8973s	
8471/11850 (epoch 35.743), train_loss = 0.91464476, grad/param norm = 2.6909e-01, time/batch = 18.1307s	
8472/11850 (epoch 35.747), train_loss = 0.81144734, grad/param norm = 2.5961e-01, time/batch = 17.2950s	
8473/11850 (epoch 35.751), train_loss = 0.88143733, grad/param norm = 2.6876e-01, time/batch = 18.5640s	
8474/11850 (epoch 35.755), train_loss = 0.93473651, grad/param norm = 2.7072e-01, time/batch = 15.8795s	
8475/11850 (epoch 35.759), train_loss = 0.86705540, grad/param norm = 2.8151e-01, time/batch = 14.5406s	
8476/11850 (epoch 35.764), train_loss = 0.89022009, grad/param norm = 2.6463e-01, time/batch = 17.7110s	
8477/11850 (epoch 35.768), train_loss = 0.82017040, grad/param norm = 2.7340e-01, time/batch = 18.2169s	
8478/11850 (epoch 35.772), train_loss = 0.87778547, grad/param norm = 2.9339e-01, time/batch = 17.7988s	
8479/11850 (epoch 35.776), train_loss = 0.94065084, grad/param norm = 2.6878e-01, time/batch = 16.4556s	
8480/11850 (epoch 35.781), train_loss = 0.88561099, grad/param norm = 2.5829e-01, time/batch = 17.9603s	
8481/11850 (epoch 35.785), train_loss = 0.88833383, grad/param norm = 3.1176e-01, time/batch = 17.9793s	
8482/11850 (epoch 35.789), train_loss = 0.89773339, grad/param norm = 2.6652e-01, time/batch = 15.8100s	
8483/11850 (epoch 35.793), train_loss = 0.96541232, grad/param norm = 3.1549e-01, time/batch = 18.4483s	
8484/11850 (epoch 35.797), train_loss = 0.90720864, grad/param norm = 3.1682e-01, time/batch = 17.6341s	
8485/11850 (epoch 35.802), train_loss = 0.83751889, grad/param norm = 2.6806e-01, time/batch = 17.3863s	
8486/11850 (epoch 35.806), train_loss = 0.89572876, grad/param norm = 2.7782e-01, time/batch = 17.8858s	
8487/11850 (epoch 35.810), train_loss = 0.96575834, grad/param norm = 2.8774e-01, time/batch = 15.7287s	
8488/11850 (epoch 35.814), train_loss = 0.92576333, grad/param norm = 2.7252e-01, time/batch = 14.7105s	
8489/11850 (epoch 35.819), train_loss = 1.01419496, grad/param norm = 2.8959e-01, time/batch = 18.0222s	
8490/11850 (epoch 35.823), train_loss = 1.04080334, grad/param norm = 2.9836e-01, time/batch = 19.2009s	
8491/11850 (epoch 35.827), train_loss = 0.93327844, grad/param norm = 3.8666e-01, time/batch = 16.8184s	
8492/11850 (epoch 35.831), train_loss = 0.90428341, grad/param norm = 3.3176e-01, time/batch = 16.3460s	
8493/11850 (epoch 35.835), train_loss = 0.93856633, grad/param norm = 2.5511e-01, time/batch = 17.8096s	
8494/11850 (epoch 35.840), train_loss = 0.88340570, grad/param norm = 2.8200e-01, time/batch = 16.7347s	
8495/11850 (epoch 35.844), train_loss = 0.91532270, grad/param norm = 2.4017e-01, time/batch = 17.8926s	
8496/11850 (epoch 35.848), train_loss = 0.93729839, grad/param norm = 2.7636e-01, time/batch = 15.7927s	
8497/11850 (epoch 35.852), train_loss = 0.93215433, grad/param norm = 3.2869e-01, time/batch = 16.7308s	
8498/11850 (epoch 35.857), train_loss = 0.89983417, grad/param norm = 3.7895e-01, time/batch = 17.6488s	
8499/11850 (epoch 35.861), train_loss = 0.86323624, grad/param norm = 2.7193e-01, time/batch = 17.8740s	
8500/11850 (epoch 35.865), train_loss = 0.95683549, grad/param norm = 3.5840e-01, time/batch = 16.2140s	
8501/11850 (epoch 35.869), train_loss = 0.93789282, grad/param norm = 2.8037e-01, time/batch = 18.3042s	
8502/11850 (epoch 35.873), train_loss = 0.94699119, grad/param norm = 2.8683e-01, time/batch = 18.4706s	
8503/11850 (epoch 35.878), train_loss = 0.96124002, grad/param norm = 2.8667e-01, time/batch = 15.7949s	
8504/11850 (epoch 35.882), train_loss = 0.94159862, grad/param norm = 3.4511e-01, time/batch = 15.1152s	
8505/11850 (epoch 35.886), train_loss = 0.91405764, grad/param norm = 3.3364e-01, time/batch = 17.9691s	
8506/11850 (epoch 35.890), train_loss = 0.94187577, grad/param norm = 3.3158e-01, time/batch = 17.1352s	
8507/11850 (epoch 35.895), train_loss = 0.94975411, grad/param norm = 3.3996e-01, time/batch = 18.7098s	
8508/11850 (epoch 35.899), train_loss = 0.84749120, grad/param norm = 3.2415e-01, time/batch = 16.8168s	
8509/11850 (epoch 35.903), train_loss = 0.86837460, grad/param norm = 2.7031e-01, time/batch = 17.3872s	
8510/11850 (epoch 35.907), train_loss = 0.87759806, grad/param norm = 3.1447e-01, time/batch = 16.8719s	
8511/11850 (epoch 35.911), train_loss = 1.01068103, grad/param norm = 3.0379e-01, time/batch = 18.1306s	
8512/11850 (epoch 35.916), train_loss = 0.97613537, grad/param norm = 3.3612e-01, time/batch = 18.8889s	
8513/11850 (epoch 35.920), train_loss = 0.96035332, grad/param norm = 3.0113e-01, time/batch = 17.1216s	
8514/11850 (epoch 35.924), train_loss = 0.90067500, grad/param norm = 3.2398e-01, time/batch = 17.1446s	
8515/11850 (epoch 35.928), train_loss = 0.96939534, grad/param norm = 3.3671e-01, time/batch = 17.3968s	
8516/11850 (epoch 35.932), train_loss = 1.02788555, grad/param norm = 3.0624e-01, time/batch = 17.6406s	
8517/11850 (epoch 35.937), train_loss = 1.00488187, grad/param norm = 2.8949e-01, time/batch = 16.2136s	
8518/11850 (epoch 35.941), train_loss = 0.97129380, grad/param norm = 2.8694e-01, time/batch = 17.5516s	
8519/11850 (epoch 35.945), train_loss = 0.98161784, grad/param norm = 2.8456e-01, time/batch = 17.1385s	
8520/11850 (epoch 35.949), train_loss = 0.88588265, grad/param norm = 3.1435e-01, time/batch = 18.1331s	
8521/11850 (epoch 35.954), train_loss = 1.00403343, grad/param norm = 3.6041e-01, time/batch = 19.1335s	
8522/11850 (epoch 35.958), train_loss = 0.98435686, grad/param norm = 3.0922e-01, time/batch = 17.1449s	
8523/11850 (epoch 35.962), train_loss = 0.88367130, grad/param norm = 2.8940e-01, time/batch = 15.5559s	
8524/11850 (epoch 35.966), train_loss = 0.82801046, grad/param norm = 2.6177e-01, time/batch = 16.1266s	
8525/11850 (epoch 35.970), train_loss = 0.97358055, grad/param norm = 3.0892e-01, time/batch = 17.9633s	
8526/11850 (epoch 35.975), train_loss = 0.90932387, grad/param norm = 2.7127e-01, time/batch = 15.5452s	
8527/11850 (epoch 35.979), train_loss = 0.93782772, grad/param norm = 2.9908e-01, time/batch = 15.9641s	
8528/11850 (epoch 35.983), train_loss = 1.03119651, grad/param norm = 4.5032e-01, time/batch = 16.7154s	
8529/11850 (epoch 35.987), train_loss = 0.89958344, grad/param norm = 3.3093e-01, time/batch = 17.3072s	
8530/11850 (epoch 35.992), train_loss = 1.05165710, grad/param norm = 3.1140e-01, time/batch = 18.3023s	
8531/11850 (epoch 35.996), train_loss = 1.05016606, grad/param norm = 3.2243e-01, time/batch = 17.0281s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
8532/11850 (epoch 36.000), train_loss = 0.92747311, grad/param norm = 3.4962e-01, time/batch = 17.7158s	
8533/11850 (epoch 36.004), train_loss = 0.98051278, grad/param norm = 3.3257e-01, time/batch = 17.9555s	
8534/11850 (epoch 36.008), train_loss = 1.03659214, grad/param norm = 3.2742e-01, time/batch = 17.1200s	
8535/11850 (epoch 36.013), train_loss = 1.03643656, grad/param norm = 2.8747e-01, time/batch = 17.4461s	
8536/11850 (epoch 36.017), train_loss = 1.07136497, grad/param norm = 3.1166e-01, time/batch = 14.8588s	
8537/11850 (epoch 36.021), train_loss = 1.00651353, grad/param norm = 2.7645e-01, time/batch = 18.3577s	
8538/11850 (epoch 36.025), train_loss = 0.89968613, grad/param norm = 2.5948e-01, time/batch = 19.1108s	
8539/11850 (epoch 36.030), train_loss = 0.92617266, grad/param norm = 2.9961e-01, time/batch = 18.7200s	
8540/11850 (epoch 36.034), train_loss = 0.91080780, grad/param norm = 2.7626e-01, time/batch = 17.5234s	
8541/11850 (epoch 36.038), train_loss = 0.91616779, grad/param norm = 2.5421e-01, time/batch = 16.4647s	
8542/11850 (epoch 36.042), train_loss = 0.97031543, grad/param norm = 3.1200e-01, time/batch = 18.2208s	
8543/11850 (epoch 36.046), train_loss = 0.92774344, grad/param norm = 3.3930e-01, time/batch = 18.7143s	
8544/11850 (epoch 36.051), train_loss = 0.93917248, grad/param norm = 2.9525e-01, time/batch = 17.3812s	
8545/11850 (epoch 36.055), train_loss = 0.90004327, grad/param norm = 2.6957e-01, time/batch = 19.3078s	
8546/11850 (epoch 36.059), train_loss = 0.99743261, grad/param norm = 2.9423e-01, time/batch = 16.6385s	
8547/11850 (epoch 36.063), train_loss = 1.02550706, grad/param norm = 3.3353e-01, time/batch = 17.8004s	
8548/11850 (epoch 36.068), train_loss = 0.94087274, grad/param norm = 2.6602e-01, time/batch = 17.4640s	
8549/11850 (epoch 36.072), train_loss = 1.01054722, grad/param norm = 2.8802e-01, time/batch = 16.9667s	
8550/11850 (epoch 36.076), train_loss = 1.07118652, grad/param norm = 2.9804e-01, time/batch = 18.0528s	
8551/11850 (epoch 36.080), train_loss = 0.88231311, grad/param norm = 2.7015e-01, time/batch = 15.8743s	
8552/11850 (epoch 36.084), train_loss = 0.83439294, grad/param norm = 2.5499e-01, time/batch = 18.5300s	
8553/11850 (epoch 36.089), train_loss = 0.84586101, grad/param norm = 2.7598e-01, time/batch = 18.2205s	
8554/11850 (epoch 36.093), train_loss = 0.86541185, grad/param norm = 3.7565e-01, time/batch = 16.9629s	
8555/11850 (epoch 36.097), train_loss = 0.95580121, grad/param norm = 3.0918e-01, time/batch = 16.6555s	
8556/11850 (epoch 36.101), train_loss = 0.86915812, grad/param norm = 3.2794e-01, time/batch = 18.5532s	
8557/11850 (epoch 36.105), train_loss = 0.84386806, grad/param norm = 2.5020e-01, time/batch = 18.5577s	
8558/11850 (epoch 36.110), train_loss = 0.99296039, grad/param norm = 2.6291e-01, time/batch = 17.1988s	
8559/11850 (epoch 36.114), train_loss = 0.88784740, grad/param norm = 2.7927e-01, time/batch = 15.2633s	
8560/11850 (epoch 36.118), train_loss = 1.00632661, grad/param norm = 2.7932e-01, time/batch = 18.6987s	
8561/11850 (epoch 36.122), train_loss = 1.04303764, grad/param norm = 3.0114e-01, time/batch = 17.4488s	
8562/11850 (epoch 36.127), train_loss = 0.98105425, grad/param norm = 3.0426e-01, time/batch = 17.7974s	
8563/11850 (epoch 36.131), train_loss = 0.96140586, grad/param norm = 3.8683e-01, time/batch = 18.5460s	
8564/11850 (epoch 36.135), train_loss = 0.96738114, grad/param norm = 3.5831e-01, time/batch = 18.8611s	
8565/11850 (epoch 36.139), train_loss = 0.93077396, grad/param norm = 2.7825e-01, time/batch = 31.3838s	
8566/11850 (epoch 36.143), train_loss = 0.91216425, grad/param norm = 2.9198e-01, time/batch = 16.8928s	
8567/11850 (epoch 36.148), train_loss = 0.91627477, grad/param norm = 3.0031e-01, time/batch = 15.4470s	
8568/11850 (epoch 36.152), train_loss = 1.01221711, grad/param norm = 3.0847e-01, time/batch = 17.0418s	
8569/11850 (epoch 36.156), train_loss = 0.90677404, grad/param norm = 3.6476e-01, time/batch = 18.8783s	
8570/11850 (epoch 36.160), train_loss = 1.11407559, grad/param norm = 3.8796e-01, time/batch = 17.8675s	
8571/11850 (epoch 36.165), train_loss = 1.04443018, grad/param norm = 3.6195e-01, time/batch = 16.9505s	
8572/11850 (epoch 36.169), train_loss = 0.94074633, grad/param norm = 3.4009e-01, time/batch = 18.9655s	
8573/11850 (epoch 36.173), train_loss = 1.02260361, grad/param norm = 3.5996e-01, time/batch = 18.3075s	
8574/11850 (epoch 36.177), train_loss = 0.87436906, grad/param norm = 3.6284e-01, time/batch = 17.7049s	
8575/11850 (epoch 36.181), train_loss = 0.98743660, grad/param norm = 3.3564e-01, time/batch = 15.7941s	
8576/11850 (epoch 36.186), train_loss = 1.08370707, grad/param norm = 5.4518e-01, time/batch = 15.2169s	
8577/11850 (epoch 36.190), train_loss = 0.99865403, grad/param norm = 3.0769e-01, time/batch = 16.9574s	
8578/11850 (epoch 36.194), train_loss = 1.04894117, grad/param norm = 4.5311e-01, time/batch = 18.5513s	
8579/11850 (epoch 36.198), train_loss = 0.80239763, grad/param norm = 3.0482e-01, time/batch = 17.9025s	
8580/11850 (epoch 36.203), train_loss = 0.82341591, grad/param norm = 2.7732e-01, time/batch = 18.3827s	
8581/11850 (epoch 36.207), train_loss = 0.99796919, grad/param norm = 3.2925e-01, time/batch = 16.7011s	
8582/11850 (epoch 36.211), train_loss = 0.94424911, grad/param norm = 3.0399e-01, time/batch = 16.9665s	
8583/11850 (epoch 36.215), train_loss = 0.96538377, grad/param norm = 3.3537e-01, time/batch = 17.4099s	
8584/11850 (epoch 36.219), train_loss = 0.97196219, grad/param norm = 2.9619e-01, time/batch = 17.7825s	
8585/11850 (epoch 36.224), train_loss = 1.09555569, grad/param norm = 3.0256e-01, time/batch = 16.7919s	
8586/11850 (epoch 36.228), train_loss = 0.99582627, grad/param norm = 3.2976e-01, time/batch = 17.7260s	
8587/11850 (epoch 36.232), train_loss = 0.96650715, grad/param norm = 3.2495e-01, time/batch = 18.5574s	
8588/11850 (epoch 36.236), train_loss = 0.89287732, grad/param norm = 3.1922e-01, time/batch = 17.6313s	
8589/11850 (epoch 36.241), train_loss = 0.99598418, grad/param norm = 3.2917e-01, time/batch = 16.6433s	
8590/11850 (epoch 36.245), train_loss = 1.00769033, grad/param norm = 2.8341e-01, time/batch = 18.3043s	
8591/11850 (epoch 36.249), train_loss = 0.93642270, grad/param norm = 2.8255e-01, time/batch = 14.6892s	
8592/11850 (epoch 36.253), train_loss = 0.94745805, grad/param norm = 3.1959e-01, time/batch = 14.9182s	
8593/11850 (epoch 36.257), train_loss = 1.06496706, grad/param norm = 3.3254e-01, time/batch = 16.4031s	
8594/11850 (epoch 36.262), train_loss = 1.08087770, grad/param norm = 3.8236e-01, time/batch = 18.0639s	
8595/11850 (epoch 36.266), train_loss = 1.06519957, grad/param norm = 3.5724e-01, time/batch = 16.6280s	
8596/11850 (epoch 36.270), train_loss = 0.95148299, grad/param norm = 2.7431e-01, time/batch = 17.3866s	
8597/11850 (epoch 36.274), train_loss = 0.94126087, grad/param norm = 3.2878e-01, time/batch = 17.3126s	
8598/11850 (epoch 36.278), train_loss = 0.83214707, grad/param norm = 2.6817e-01, time/batch = 15.2778s	
8599/11850 (epoch 36.283), train_loss = 0.92865617, grad/param norm = 2.5608e-01, time/batch = 16.2793s	
8600/11850 (epoch 36.287), train_loss = 1.05520534, grad/param norm = 2.9068e-01, time/batch = 15.8809s	
8601/11850 (epoch 36.291), train_loss = 0.92768208, grad/param norm = 2.8519e-01, time/batch = 17.6342s	
8602/11850 (epoch 36.295), train_loss = 1.00687120, grad/param norm = 2.9667e-01, time/batch = 16.1123s	
8603/11850 (epoch 36.300), train_loss = 0.91443464, grad/param norm = 2.8571e-01, time/batch = 18.8651s	
8604/11850 (epoch 36.304), train_loss = 0.94705016, grad/param norm = 2.7109e-01, time/batch = 17.3134s	
8605/11850 (epoch 36.308), train_loss = 0.94037228, grad/param norm = 2.5896e-01, time/batch = 17.5597s	
8606/11850 (epoch 36.312), train_loss = 0.83129493, grad/param norm = 2.6269e-01, time/batch = 19.4545s	
8607/11850 (epoch 36.316), train_loss = 0.96393613, grad/param norm = 2.6198e-01, time/batch = 18.2207s	
8608/11850 (epoch 36.321), train_loss = 0.93534812, grad/param norm = 3.0447e-01, time/batch = 17.0143s	
8609/11850 (epoch 36.325), train_loss = 0.95114111, grad/param norm = 2.6620e-01, time/batch = 17.4521s	
8610/11850 (epoch 36.329), train_loss = 0.96590942, grad/param norm = 3.5804e-01, time/batch = 19.2219s	
8611/11850 (epoch 36.333), train_loss = 0.94151834, grad/param norm = 3.2981e-01, time/batch = 17.9602s	
8612/11850 (epoch 36.338), train_loss = 0.90122303, grad/param norm = 2.5497e-01, time/batch = 15.2010s	
8613/11850 (epoch 36.342), train_loss = 0.95480589, grad/param norm = 3.1755e-01, time/batch = 17.3838s	
8614/11850 (epoch 36.346), train_loss = 0.92158583, grad/param norm = 2.8130e-01, time/batch = 18.0568s	
8615/11850 (epoch 36.350), train_loss = 0.83296838, grad/param norm = 2.5488e-01, time/batch = 17.2200s	
8616/11850 (epoch 36.354), train_loss = 0.99795848, grad/param norm = 2.9178e-01, time/batch = 16.2385s	
8617/11850 (epoch 36.359), train_loss = 1.07359152, grad/param norm = 3.1918e-01, time/batch = 17.9720s	
8618/11850 (epoch 36.363), train_loss = 0.97881165, grad/param norm = 2.7117e-01, time/batch = 16.4669s	
8619/11850 (epoch 36.367), train_loss = 1.02032109, grad/param norm = 2.9561e-01, time/batch = 16.9686s	
8620/11850 (epoch 36.371), train_loss = 0.99412449, grad/param norm = 2.8910e-01, time/batch = 17.3614s	
8621/11850 (epoch 36.376), train_loss = 0.94330141, grad/param norm = 2.5415e-01, time/batch = 15.8204s	
8622/11850 (epoch 36.380), train_loss = 0.91695344, grad/param norm = 2.5753e-01, time/batch = 17.6336s	
8623/11850 (epoch 36.384), train_loss = 0.86715822, grad/param norm = 2.7420e-01, time/batch = 16.1903s	
8624/11850 (epoch 36.388), train_loss = 1.01785903, grad/param norm = 3.2220e-01, time/batch = 18.6206s	
8625/11850 (epoch 36.392), train_loss = 0.97932290, grad/param norm = 2.8076e-01, time/batch = 18.0614s	
8626/11850 (epoch 36.397), train_loss = 1.00559048, grad/param norm = 3.1727e-01, time/batch = 15.2853s	
8627/11850 (epoch 36.401), train_loss = 0.84180385, grad/param norm = 2.9800e-01, time/batch = 17.3025s	
8628/11850 (epoch 36.405), train_loss = 0.88188410, grad/param norm = 2.8712e-01, time/batch = 17.3840s	
8629/11850 (epoch 36.409), train_loss = 0.99433946, grad/param norm = 2.8370e-01, time/batch = 17.0499s	
8630/11850 (epoch 36.414), train_loss = 0.79571258, grad/param norm = 2.5023e-01, time/batch = 17.8057s	
8631/11850 (epoch 36.418), train_loss = 0.84282188, grad/param norm = 2.7948e-01, time/batch = 17.5493s	
8632/11850 (epoch 36.422), train_loss = 0.78003858, grad/param norm = 3.0158e-01, time/batch = 16.8117s	
8633/11850 (epoch 36.426), train_loss = 0.78771371, grad/param norm = 2.6189e-01, time/batch = 15.5469s	
8634/11850 (epoch 36.430), train_loss = 0.85462699, grad/param norm = 3.0908e-01, time/batch = 14.9952s	
8635/11850 (epoch 36.435), train_loss = 0.87141659, grad/param norm = 2.6537e-01, time/batch = 15.9897s	
8636/11850 (epoch 36.439), train_loss = 0.97433522, grad/param norm = 2.7670e-01, time/batch = 17.3988s	
8637/11850 (epoch 36.443), train_loss = 0.91182032, grad/param norm = 2.6324e-01, time/batch = 14.7919s	
8638/11850 (epoch 36.447), train_loss = 0.84774056, grad/param norm = 2.7576e-01, time/batch = 17.9016s	
8639/11850 (epoch 36.451), train_loss = 0.82488119, grad/param norm = 2.6339e-01, time/batch = 18.2145s	
8640/11850 (epoch 36.456), train_loss = 0.92126038, grad/param norm = 2.8709e-01, time/batch = 17.7210s	
8641/11850 (epoch 36.460), train_loss = 0.96413915, grad/param norm = 2.7022e-01, time/batch = 17.5990s	
8642/11850 (epoch 36.464), train_loss = 0.88654878, grad/param norm = 2.9264e-01, time/batch = 16.3210s	
8643/11850 (epoch 36.468), train_loss = 0.95814354, grad/param norm = 2.7170e-01, time/batch = 14.9652s	
8644/11850 (epoch 36.473), train_loss = 1.00030807, grad/param norm = 2.9091e-01, time/batch = 17.6912s	
8645/11850 (epoch 36.477), train_loss = 0.83522641, grad/param norm = 2.5774e-01, time/batch = 17.3809s	
8646/11850 (epoch 36.481), train_loss = 0.86381457, grad/param norm = 2.7598e-01, time/batch = 19.2977s	
8647/11850 (epoch 36.485), train_loss = 0.83067074, grad/param norm = 2.5183e-01, time/batch = 16.6163s	
8648/11850 (epoch 36.489), train_loss = 0.94694818, grad/param norm = 2.7872e-01, time/batch = 18.8877s	
8649/11850 (epoch 36.494), train_loss = 0.85747255, grad/param norm = 3.8700e-01, time/batch = 19.1239s	
8650/11850 (epoch 36.498), train_loss = 0.85148770, grad/param norm = 2.9460e-01, time/batch = 17.2083s	
8651/11850 (epoch 36.502), train_loss = 0.83953492, grad/param norm = 3.4164e-01, time/batch = 18.2147s	
8652/11850 (epoch 36.506), train_loss = 1.07093042, grad/param norm = 3.1219e-01, time/batch = 16.1397s	
8653/11850 (epoch 36.511), train_loss = 0.91963100, grad/param norm = 2.6709e-01, time/batch = 18.9703s	
8654/11850 (epoch 36.515), train_loss = 1.01536327, grad/param norm = 3.5365e-01, time/batch = 16.5092s	
8655/11850 (epoch 36.519), train_loss = 0.89772244, grad/param norm = 3.1943e-01, time/batch = 18.0330s	
8656/11850 (epoch 36.523), train_loss = 0.93217724, grad/param norm = 2.9583e-01, time/batch = 19.3744s	
8657/11850 (epoch 36.527), train_loss = 0.86376137, grad/param norm = 2.6546e-01, time/batch = 16.7111s	
8658/11850 (epoch 36.532), train_loss = 0.94082808, grad/param norm = 2.8223e-01, time/batch = 19.0449s	
8659/11850 (epoch 36.536), train_loss = 0.89405499, grad/param norm = 2.8348e-01, time/batch = 18.4672s	
8660/11850 (epoch 36.540), train_loss = 0.84582634, grad/param norm = 2.7419e-01, time/batch = 17.4632s	
8661/11850 (epoch 36.544), train_loss = 0.84664826, grad/param norm = 3.1638e-01, time/batch = 17.8848s	
8662/11850 (epoch 36.549), train_loss = 0.79587997, grad/param norm = 2.5842e-01, time/batch = 17.1249s	
8663/11850 (epoch 36.553), train_loss = 0.93316884, grad/param norm = 2.9960e-01, time/batch = 18.2793s	
8664/11850 (epoch 36.557), train_loss = 0.96691248, grad/param norm = 5.3829e-01, time/batch = 15.7916s	
8665/11850 (epoch 36.561), train_loss = 0.97479931, grad/param norm = 3.2019e-01, time/batch = 17.2309s	
8666/11850 (epoch 36.565), train_loss = 1.05815267, grad/param norm = 3.5192e-01, time/batch = 16.7139s	
8667/11850 (epoch 36.570), train_loss = 0.95808013, grad/param norm = 2.7630e-01, time/batch = 14.9472s	
8668/11850 (epoch 36.574), train_loss = 0.96705056, grad/param norm = 2.8355e-01, time/batch = 18.6869s	
8669/11850 (epoch 36.578), train_loss = 1.01245368, grad/param norm = 3.3165e-01, time/batch = 16.2269s	
8670/11850 (epoch 36.582), train_loss = 0.89773363, grad/param norm = 2.9424e-01, time/batch = 18.8079s	
8671/11850 (epoch 36.586), train_loss = 0.89424631, grad/param norm = 2.7251e-01, time/batch = 16.2898s	
8672/11850 (epoch 36.591), train_loss = 0.94158940, grad/param norm = 3.1401e-01, time/batch = 17.5661s	
8673/11850 (epoch 36.595), train_loss = 0.81313060, grad/param norm = 2.7196e-01, time/batch = 18.4722s	
8674/11850 (epoch 36.599), train_loss = 0.93216623, grad/param norm = 3.2620e-01, time/batch = 16.9720s	
8675/11850 (epoch 36.603), train_loss = 0.86730029, grad/param norm = 2.4690e-01, time/batch = 18.8859s	
8676/11850 (epoch 36.608), train_loss = 1.05116519, grad/param norm = 2.8906e-01, time/batch = 17.4716s	
8677/11850 (epoch 36.612), train_loss = 1.11399557, grad/param norm = 3.3336e-01, time/batch = 16.4646s	
8678/11850 (epoch 36.616), train_loss = 1.03023248, grad/param norm = 2.9387e-01, time/batch = 17.4694s	
8679/11850 (epoch 36.620), train_loss = 0.91408268, grad/param norm = 2.8700e-01, time/batch = 17.4772s	
8680/11850 (epoch 36.624), train_loss = 0.92359596, grad/param norm = 3.4636e-01, time/batch = 18.7151s	
8681/11850 (epoch 36.629), train_loss = 0.90377361, grad/param norm = 3.1185e-01, time/batch = 16.8657s	
8682/11850 (epoch 36.633), train_loss = 0.81883931, grad/param norm = 2.7321e-01, time/batch = 19.1382s	
8683/11850 (epoch 36.637), train_loss = 0.76151461, grad/param norm = 2.7441e-01, time/batch = 16.4874s	
8684/11850 (epoch 36.641), train_loss = 0.81717878, grad/param norm = 2.5720e-01, time/batch = 17.3747s	
8685/11850 (epoch 36.646), train_loss = 0.82912100, grad/param norm = 2.7916e-01, time/batch = 18.6402s	
8686/11850 (epoch 36.650), train_loss = 0.92567604, grad/param norm = 3.3565e-01, time/batch = 16.8140s	
8687/11850 (epoch 36.654), train_loss = 0.85866975, grad/param norm = 2.9710e-01, time/batch = 16.4682s	
8688/11850 (epoch 36.658), train_loss = 0.94662621, grad/param norm = 2.7432e-01, time/batch = 16.5202s	
8689/11850 (epoch 36.662), train_loss = 0.79853795, grad/param norm = 3.4387e-01, time/batch = 18.0378s	
8690/11850 (epoch 36.667), train_loss = 1.00052577, grad/param norm = 2.9025e-01, time/batch = 18.3821s	
8691/11850 (epoch 36.671), train_loss = 0.89050208, grad/param norm = 2.9430e-01, time/batch = 17.6257s	
8692/11850 (epoch 36.675), train_loss = 0.88996721, grad/param norm = 2.7915e-01, time/batch = 17.1076s	
8693/11850 (epoch 36.679), train_loss = 0.91348306, grad/param norm = 2.7333e-01, time/batch = 17.9689s	
8694/11850 (epoch 36.684), train_loss = 0.89059941, grad/param norm = 3.1716e-01, time/batch = 18.5402s	
8695/11850 (epoch 36.688), train_loss = 0.84237233, grad/param norm = 2.8633e-01, time/batch = 17.9457s	
8696/11850 (epoch 36.692), train_loss = 0.87033311, grad/param norm = 3.2960e-01, time/batch = 17.4559s	
8697/11850 (epoch 36.696), train_loss = 0.84745200, grad/param norm = 3.5707e-01, time/batch = 18.9603s	
8698/11850 (epoch 36.700), train_loss = 0.93798183, grad/param norm = 3.2475e-01, time/batch = 16.9516s	
8699/11850 (epoch 36.705), train_loss = 0.84481010, grad/param norm = 2.9214e-01, time/batch = 18.4696s	
8700/11850 (epoch 36.709), train_loss = 0.78269826, grad/param norm = 2.5886e-01, time/batch = 18.9554s	
8701/11850 (epoch 36.713), train_loss = 0.77803818, grad/param norm = 2.8134e-01, time/batch = 16.3567s	
8702/11850 (epoch 36.717), train_loss = 0.85524172, grad/param norm = 2.9994e-01, time/batch = 17.7018s	
8703/11850 (epoch 36.722), train_loss = 0.90274005, grad/param norm = 2.7877e-01, time/batch = 14.5028s	
8704/11850 (epoch 36.726), train_loss = 0.81877085, grad/param norm = 3.0093e-01, time/batch = 18.3825s	
8705/11850 (epoch 36.730), train_loss = 0.82941869, grad/param norm = 2.9925e-01, time/batch = 16.3490s	
8706/11850 (epoch 36.734), train_loss = 0.83613028, grad/param norm = 2.8218e-01, time/batch = 18.3969s	
8707/11850 (epoch 36.738), train_loss = 0.95701805, grad/param norm = 3.4320e-01, time/batch = 17.9547s	
8708/11850 (epoch 36.743), train_loss = 0.90383032, grad/param norm = 2.7538e-01, time/batch = 17.9485s	
8709/11850 (epoch 36.747), train_loss = 0.79678971, grad/param norm = 2.3608e-01, time/batch = 17.7132s	
8710/11850 (epoch 36.751), train_loss = 0.86414577, grad/param norm = 2.7040e-01, time/batch = 19.2812s	
8711/11850 (epoch 36.755), train_loss = 0.92654353, grad/param norm = 3.0229e-01, time/batch = 16.1983s	
8712/11850 (epoch 36.759), train_loss = 0.86068468, grad/param norm = 2.9769e-01, time/batch = 17.7888s	
8713/11850 (epoch 36.764), train_loss = 0.89147690, grad/param norm = 2.8421e-01, time/batch = 17.8367s	
8714/11850 (epoch 36.768), train_loss = 0.81767988, grad/param norm = 2.7505e-01, time/batch = 18.8832s	
8715/11850 (epoch 36.772), train_loss = 0.86787547, grad/param norm = 3.1582e-01, time/batch = 18.4514s	
8716/11850 (epoch 36.776), train_loss = 0.92395682, grad/param norm = 2.8695e-01, time/batch = 16.6424s	
8717/11850 (epoch 36.781), train_loss = 0.86745691, grad/param norm = 2.7436e-01, time/batch = 18.7943s	
8718/11850 (epoch 36.785), train_loss = 0.87249417, grad/param norm = 2.7445e-01, time/batch = 16.8818s	
8719/11850 (epoch 36.789), train_loss = 0.87671102, grad/param norm = 2.7527e-01, time/batch = 19.0313s	
8720/11850 (epoch 36.793), train_loss = 0.93859251, grad/param norm = 2.9446e-01, time/batch = 16.7287s	
8721/11850 (epoch 36.797), train_loss = 0.89088776, grad/param norm = 3.2332e-01, time/batch = 16.9634s	
8722/11850 (epoch 36.802), train_loss = 0.82285133, grad/param norm = 3.1488e-01, time/batch = 16.3915s	
8723/11850 (epoch 36.806), train_loss = 0.87502054, grad/param norm = 2.5940e-01, time/batch = 17.6368s	
8724/11850 (epoch 36.810), train_loss = 0.95249368, grad/param norm = 3.2026e-01, time/batch = 18.2796s	
8725/11850 (epoch 36.814), train_loss = 0.90888912, grad/param norm = 2.7880e-01, time/batch = 17.4566s	
8726/11850 (epoch 36.819), train_loss = 0.99564713, grad/param norm = 2.7726e-01, time/batch = 17.9665s	
8727/11850 (epoch 36.823), train_loss = 1.01003837, grad/param norm = 2.9282e-01, time/batch = 16.3683s	
8728/11850 (epoch 36.827), train_loss = 0.89792318, grad/param norm = 2.7671e-01, time/batch = 16.7884s	
8729/11850 (epoch 36.831), train_loss = 0.88364923, grad/param norm = 3.1852e-01, time/batch = 17.4754s	
8730/11850 (epoch 36.835), train_loss = 0.93313182, grad/param norm = 2.6985e-01, time/batch = 17.7765s	
8731/11850 (epoch 36.840), train_loss = 0.85378202, grad/param norm = 2.6262e-01, time/batch = 16.7019s	
8732/11850 (epoch 36.844), train_loss = 0.90114052, grad/param norm = 2.3439e-01, time/batch = 16.2879s	
8733/11850 (epoch 36.848), train_loss = 0.92488585, grad/param norm = 3.1735e-01, time/batch = 18.4737s	
8734/11850 (epoch 36.852), train_loss = 0.91357333, grad/param norm = 2.7048e-01, time/batch = 16.8073s	
8735/11850 (epoch 36.857), train_loss = 0.89153294, grad/param norm = 3.0926e-01, time/batch = 16.6936s	
8736/11850 (epoch 36.861), train_loss = 0.84722709, grad/param norm = 3.1229e-01, time/batch = 17.7132s	
8737/11850 (epoch 36.865), train_loss = 0.95256599, grad/param norm = 3.1175e-01, time/batch = 16.4849s	
8738/11850 (epoch 36.869), train_loss = 0.91783143, grad/param norm = 2.7375e-01, time/batch = 16.4798s	
8739/11850 (epoch 36.873), train_loss = 0.92545094, grad/param norm = 2.8373e-01, time/batch = 14.3889s	
8740/11850 (epoch 36.878), train_loss = 0.93800003, grad/param norm = 2.6599e-01, time/batch = 16.7704s	
8741/11850 (epoch 36.882), train_loss = 0.92528736, grad/param norm = 3.2306e-01, time/batch = 17.9713s	
8742/11850 (epoch 36.886), train_loss = 0.89549350, grad/param norm = 3.7219e-01, time/batch = 18.0447s	
8743/11850 (epoch 36.890), train_loss = 0.91354736, grad/param norm = 3.2046e-01, time/batch = 18.2953s	
8744/11850 (epoch 36.895), train_loss = 0.93695826, grad/param norm = 4.0982e-01, time/batch = 17.4833s	
8745/11850 (epoch 36.899), train_loss = 0.83569164, grad/param norm = 3.2146e-01, time/batch = 17.8029s	
8746/11850 (epoch 36.903), train_loss = 0.88089667, grad/param norm = 3.6019e-01, time/batch = 17.6039s	
8747/11850 (epoch 36.907), train_loss = 0.87532897, grad/param norm = 2.9307e-01, time/batch = 19.2148s	
8748/11850 (epoch 36.911), train_loss = 1.00398889, grad/param norm = 2.8636e-01, time/batch = 17.4693s	
8749/11850 (epoch 36.916), train_loss = 0.96175973, grad/param norm = 3.6468e-01, time/batch = 17.2106s	
8750/11850 (epoch 36.920), train_loss = 0.93776509, grad/param norm = 3.0741e-01, time/batch = 18.2130s	
8751/11850 (epoch 36.924), train_loss = 0.89157787, grad/param norm = 3.2827e-01, time/batch = 18.7959s	
8752/11850 (epoch 36.928), train_loss = 0.94445277, grad/param norm = 3.1956e-01, time/batch = 17.9668s	
8753/11850 (epoch 36.932), train_loss = 1.03424197, grad/param norm = 3.9730e-01, time/batch = 16.4789s	
8754/11850 (epoch 36.937), train_loss = 0.99677464, grad/param norm = 2.8034e-01, time/batch = 17.7305s	
8755/11850 (epoch 36.941), train_loss = 0.93247466, grad/param norm = 2.8923e-01, time/batch = 16.9004s	
8756/11850 (epoch 36.945), train_loss = 0.97380804, grad/param norm = 3.1059e-01, time/batch = 15.6855s	
8757/11850 (epoch 36.949), train_loss = 0.87662799, grad/param norm = 3.4709e-01, time/batch = 17.4605s	
8758/11850 (epoch 36.954), train_loss = 0.98056982, grad/param norm = 3.7020e-01, time/batch = 17.6488s	
8759/11850 (epoch 36.958), train_loss = 0.96831004, grad/param norm = 3.2972e-01, time/batch = 17.2218s	
8760/11850 (epoch 36.962), train_loss = 0.86415402, grad/param norm = 3.0150e-01, time/batch = 15.2794s	
8761/11850 (epoch 36.966), train_loss = 0.83193963, grad/param norm = 3.1981e-01, time/batch = 18.0453s	
8762/11850 (epoch 36.970), train_loss = 0.94902768, grad/param norm = 2.7746e-01, time/batch = 18.3816s	
8763/11850 (epoch 36.975), train_loss = 0.89824384, grad/param norm = 3.0013e-01, time/batch = 16.3082s	
8764/11850 (epoch 36.979), train_loss = 0.91824565, grad/param norm = 2.8397e-01, time/batch = 17.6471s	
8765/11850 (epoch 36.983), train_loss = 1.01037883, grad/param norm = 3.3794e-01, time/batch = 18.2185s	
8766/11850 (epoch 36.987), train_loss = 0.87612888, grad/param norm = 3.5692e-01, time/batch = 17.8655s	
8767/11850 (epoch 36.992), train_loss = 1.04731670, grad/param norm = 3.0671e-01, time/batch = 17.7167s	
8768/11850 (epoch 36.996), train_loss = 1.03684611, grad/param norm = 3.2708e-01, time/batch = 15.9839s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
8769/11850 (epoch 37.000), train_loss = 0.90397835, grad/param norm = 3.0874e-01, time/batch = 18.4798s	
8770/11850 (epoch 37.004), train_loss = 0.98381377, grad/param norm = 3.5665e-01, time/batch = 30.0371s	
8771/11850 (epoch 37.008), train_loss = 1.02985746, grad/param norm = 3.2133e-01, time/batch = 16.8934s	
8772/11850 (epoch 37.013), train_loss = 1.01485259, grad/param norm = 2.7441e-01, time/batch = 16.7640s	
8773/11850 (epoch 37.017), train_loss = 1.06112483, grad/param norm = 3.1928e-01, time/batch = 16.2251s	
8774/11850 (epoch 37.021), train_loss = 1.02378272, grad/param norm = 2.7982e-01, time/batch = 17.9694s	
8775/11850 (epoch 37.025), train_loss = 0.88239069, grad/param norm = 2.6302e-01, time/batch = 18.6336s	
8776/11850 (epoch 37.030), train_loss = 0.91345778, grad/param norm = 2.9921e-01, time/batch = 17.5227s	
8777/11850 (epoch 37.034), train_loss = 0.91203859, grad/param norm = 3.7442e-01, time/batch = 16.3958s	
8778/11850 (epoch 37.038), train_loss = 0.91462379, grad/param norm = 2.7915e-01, time/batch = 16.5488s	
8779/11850 (epoch 37.042), train_loss = 0.95245364, grad/param norm = 3.0426e-01, time/batch = 17.4563s	
8780/11850 (epoch 37.046), train_loss = 0.92203987, grad/param norm = 3.8656e-01, time/batch = 18.0494s	
8781/11850 (epoch 37.051), train_loss = 0.94045669, grad/param norm = 3.0179e-01, time/batch = 17.8048s	
8782/11850 (epoch 37.055), train_loss = 0.88762591, grad/param norm = 2.7027e-01, time/batch = 18.1293s	
8783/11850 (epoch 37.059), train_loss = 0.97743476, grad/param norm = 2.7568e-01, time/batch = 16.0428s	
8784/11850 (epoch 37.063), train_loss = 1.01070696, grad/param norm = 3.0263e-01, time/batch = 18.1374s	
8785/11850 (epoch 37.068), train_loss = 0.93327618, grad/param norm = 2.7695e-01, time/batch = 19.2862s	
8786/11850 (epoch 37.072), train_loss = 0.98825274, grad/param norm = 3.0484e-01, time/batch = 16.2923s	
8787/11850 (epoch 37.076), train_loss = 1.06466744, grad/param norm = 3.1792e-01, time/batch = 18.3021s	
8788/11850 (epoch 37.080), train_loss = 0.85917682, grad/param norm = 2.5479e-01, time/batch = 17.4852s	
8789/11850 (epoch 37.084), train_loss = 0.82507328, grad/param norm = 2.5906e-01, time/batch = 17.7893s	
8790/11850 (epoch 37.089), train_loss = 0.83198333, grad/param norm = 2.6928e-01, time/batch = 15.5483s	
8791/11850 (epoch 37.093), train_loss = 0.85133865, grad/param norm = 4.0471e-01, time/batch = 16.5592s	
8792/11850 (epoch 37.097), train_loss = 0.93786668, grad/param norm = 2.9596e-01, time/batch = 16.7704s	
8793/11850 (epoch 37.101), train_loss = 0.86541622, grad/param norm = 3.4360e-01, time/batch = 16.3982s	
8794/11850 (epoch 37.105), train_loss = 0.83789038, grad/param norm = 2.6483e-01, time/batch = 18.7933s	
8795/11850 (epoch 37.110), train_loss = 0.98161244, grad/param norm = 2.8389e-01, time/batch = 17.7190s	
8796/11850 (epoch 37.114), train_loss = 0.88347547, grad/param norm = 2.8071e-01, time/batch = 17.7183s	
8797/11850 (epoch 37.118), train_loss = 0.99364989, grad/param norm = 2.7654e-01, time/batch = 17.5347s	
8798/11850 (epoch 37.122), train_loss = 1.02039809, grad/param norm = 2.8582e-01, time/batch = 15.4680s	
8799/11850 (epoch 37.127), train_loss = 0.96690656, grad/param norm = 3.0990e-01, time/batch = 17.1367s	
8800/11850 (epoch 37.131), train_loss = 0.93425987, grad/param norm = 3.1486e-01, time/batch = 15.8775s	
8801/11850 (epoch 37.135), train_loss = 0.93911160, grad/param norm = 3.3724e-01, time/batch = 19.3883s	
8802/11850 (epoch 37.139), train_loss = 0.91645216, grad/param norm = 2.7919e-01, time/batch = 18.4612s	
8803/11850 (epoch 37.143), train_loss = 0.89657058, grad/param norm = 3.1653e-01, time/batch = 17.3762s	
8804/11850 (epoch 37.148), train_loss = 0.90012917, grad/param norm = 3.1438e-01, time/batch = 16.8027s	
8805/11850 (epoch 37.152), train_loss = 1.00083224, grad/param norm = 3.5119e-01, time/batch = 16.9707s	
8806/11850 (epoch 37.156), train_loss = 0.88345737, grad/param norm = 3.3310e-01, time/batch = 16.8979s	
8807/11850 (epoch 37.160), train_loss = 1.08555506, grad/param norm = 3.5477e-01, time/batch = 15.9657s	
8808/11850 (epoch 37.165), train_loss = 1.02620490, grad/param norm = 3.7296e-01, time/batch = 17.3820s	
8809/11850 (epoch 37.169), train_loss = 0.91535107, grad/param norm = 3.2127e-01, time/batch = 17.1444s	
8810/11850 (epoch 37.173), train_loss = 0.99803594, grad/param norm = 3.2501e-01, time/batch = 17.3797s	
8811/11850 (epoch 37.177), train_loss = 0.84719106, grad/param norm = 3.3096e-01, time/batch = 17.8018s	
8812/11850 (epoch 37.181), train_loss = 0.95557896, grad/param norm = 2.8334e-01, time/batch = 18.2913s	
8813/11850 (epoch 37.186), train_loss = 1.03471656, grad/param norm = 3.6015e-01, time/batch = 17.3630s	
8814/11850 (epoch 37.190), train_loss = 0.97547809, grad/param norm = 3.2829e-01, time/batch = 16.5321s	
8815/11850 (epoch 37.194), train_loss = 0.98854849, grad/param norm = 3.3105e-01, time/batch = 18.5606s	
8816/11850 (epoch 37.198), train_loss = 0.77989370, grad/param norm = 3.0958e-01, time/batch = 17.0608s	
8817/11850 (epoch 37.203), train_loss = 0.80471589, grad/param norm = 2.6898e-01, time/batch = 16.3065s	
8818/11850 (epoch 37.207), train_loss = 0.97046703, grad/param norm = 2.9763e-01, time/batch = 17.8913s	
8819/11850 (epoch 37.211), train_loss = 0.90060980, grad/param norm = 3.0678e-01, time/batch = 16.0347s	
8820/11850 (epoch 37.215), train_loss = 0.96716178, grad/param norm = 4.0317e-01, time/batch = 19.3859s	
8821/11850 (epoch 37.219), train_loss = 0.99191958, grad/param norm = 3.1719e-01, time/batch = 5.8438s	
8822/11850 (epoch 37.224), train_loss = 1.08405168, grad/param norm = 2.8734e-01, time/batch = 0.6417s	
8823/11850 (epoch 37.228), train_loss = 0.98250646, grad/param norm = 3.1542e-01, time/batch = 0.6384s	
8824/11850 (epoch 37.232), train_loss = 0.95467659, grad/param norm = 3.0723e-01, time/batch = 0.6413s	
8825/11850 (epoch 37.236), train_loss = 0.87600457, grad/param norm = 3.0124e-01, time/batch = 0.6359s	
8826/11850 (epoch 37.241), train_loss = 0.97845986, grad/param norm = 2.9681e-01, time/batch = 0.6632s	
8827/11850 (epoch 37.245), train_loss = 1.00240610, grad/param norm = 2.7558e-01, time/batch = 0.6650s	
8828/11850 (epoch 37.249), train_loss = 0.93840701, grad/param norm = 2.7761e-01, time/batch = 0.6507s	
8829/11850 (epoch 37.253), train_loss = 0.93101933, grad/param norm = 3.2389e-01, time/batch = 0.9394s	
8830/11850 (epoch 37.257), train_loss = 1.04626381, grad/param norm = 2.9921e-01, time/batch = 0.9309s	
8831/11850 (epoch 37.262), train_loss = 1.07599981, grad/param norm = 4.1265e-01, time/batch = 0.9288s	
8832/11850 (epoch 37.266), train_loss = 1.04737329, grad/param norm = 3.5373e-01, time/batch = 0.9389s	
8833/11850 (epoch 37.270), train_loss = 0.92662914, grad/param norm = 2.6545e-01, time/batch = 0.9361s	
8834/11850 (epoch 37.274), train_loss = 0.93799542, grad/param norm = 3.2537e-01, time/batch = 1.4909s	
8835/11850 (epoch 37.278), train_loss = 0.83022913, grad/param norm = 2.9969e-01, time/batch = 1.7373s	
8836/11850 (epoch 37.283), train_loss = 0.93209434, grad/param norm = 2.8648e-01, time/batch = 1.7563s	
8837/11850 (epoch 37.287), train_loss = 1.04344064, grad/param norm = 3.0078e-01, time/batch = 14.6974s	
8838/11850 (epoch 37.291), train_loss = 0.91353384, grad/param norm = 3.0110e-01, time/batch = 17.9766s	
8839/11850 (epoch 37.295), train_loss = 0.99342255, grad/param norm = 3.0191e-01, time/batch = 14.9446s	
8840/11850 (epoch 37.300), train_loss = 0.90164971, grad/param norm = 2.9731e-01, time/batch = 15.4727s	
8841/11850 (epoch 37.304), train_loss = 0.93150197, grad/param norm = 2.5864e-01, time/batch = 17.0643s	
8842/11850 (epoch 37.308), train_loss = 0.93253257, grad/param norm = 2.8195e-01, time/batch = 18.2302s	
8843/11850 (epoch 37.312), train_loss = 0.81850943, grad/param norm = 2.7243e-01, time/batch = 15.7132s	
8844/11850 (epoch 37.316), train_loss = 0.95041846, grad/param norm = 2.6893e-01, time/batch = 18.8064s	
8845/11850 (epoch 37.321), train_loss = 0.89755305, grad/param norm = 2.7124e-01, time/batch = 19.0413s	
8846/11850 (epoch 37.325), train_loss = 0.94351066, grad/param norm = 2.9652e-01, time/batch = 17.6232s	
8847/11850 (epoch 37.329), train_loss = 0.93074179, grad/param norm = 2.8042e-01, time/batch = 17.9761s	
8848/11850 (epoch 37.333), train_loss = 0.91044767, grad/param norm = 3.1446e-01, time/batch = 17.8769s	
8849/11850 (epoch 37.338), train_loss = 0.88715494, grad/param norm = 2.6832e-01, time/batch = 17.8469s	
8850/11850 (epoch 37.342), train_loss = 0.92416744, grad/param norm = 2.8216e-01, time/batch = 18.8671s	
8851/11850 (epoch 37.346), train_loss = 0.90181748, grad/param norm = 2.7211e-01, time/batch = 15.8723s	
8852/11850 (epoch 37.350), train_loss = 0.82513731, grad/param norm = 2.6327e-01, time/batch = 18.7171s	
8853/11850 (epoch 37.354), train_loss = 0.97760694, grad/param norm = 2.9168e-01, time/batch = 16.4434s	
8854/11850 (epoch 37.359), train_loss = 1.05466357, grad/param norm = 2.8283e-01, time/batch = 17.3034s	
8855/11850 (epoch 37.363), train_loss = 0.95930940, grad/param norm = 2.6869e-01, time/batch = 17.5552s	
8856/11850 (epoch 37.367), train_loss = 0.99573685, grad/param norm = 2.7493e-01, time/batch = 16.7950s	
8857/11850 (epoch 37.371), train_loss = 0.97790942, grad/param norm = 2.5168e-01, time/batch = 16.2926s	
8858/11850 (epoch 37.376), train_loss = 0.94022749, grad/param norm = 2.7429e-01, time/batch = 17.5492s	
8859/11850 (epoch 37.380), train_loss = 0.90982826, grad/param norm = 2.7394e-01, time/batch = 17.7180s	
8860/11850 (epoch 37.384), train_loss = 0.85606186, grad/param norm = 3.1793e-01, time/batch = 15.8690s	
8861/11850 (epoch 37.388), train_loss = 0.99159112, grad/param norm = 2.7915e-01, time/batch = 15.1923s	
8862/11850 (epoch 37.392), train_loss = 0.95598733, grad/param norm = 2.8691e-01, time/batch = 19.0412s	
8863/11850 (epoch 37.397), train_loss = 0.97770857, grad/param norm = 2.7425e-01, time/batch = 18.2842s	
8864/11850 (epoch 37.401), train_loss = 0.81290087, grad/param norm = 2.3655e-01, time/batch = 17.0592s	
8865/11850 (epoch 37.405), train_loss = 0.86209444, grad/param norm = 2.9105e-01, time/batch = 17.2227s	
8866/11850 (epoch 37.409), train_loss = 0.97704008, grad/param norm = 2.9845e-01, time/batch = 17.5617s	
8867/11850 (epoch 37.414), train_loss = 0.79472477, grad/param norm = 2.8578e-01, time/batch = 17.2948s	
8868/11850 (epoch 37.418), train_loss = 0.84313672, grad/param norm = 3.6674e-01, time/batch = 15.8989s	
8869/11850 (epoch 37.422), train_loss = 0.76118820, grad/param norm = 2.6515e-01, time/batch = 18.4673s	
8870/11850 (epoch 37.426), train_loss = 0.76761970, grad/param norm = 2.8964e-01, time/batch = 16.2075s	
8871/11850 (epoch 37.430), train_loss = 0.85343019, grad/param norm = 3.1551e-01, time/batch = 18.2198s	
8872/11850 (epoch 37.435), train_loss = 0.85762384, grad/param norm = 2.8070e-01, time/batch = 17.1366s	
8873/11850 (epoch 37.439), train_loss = 0.95926368, grad/param norm = 2.6183e-01, time/batch = 15.3183s	
8874/11850 (epoch 37.443), train_loss = 0.90782518, grad/param norm = 2.8679e-01, time/batch = 15.5439s	
8875/11850 (epoch 37.447), train_loss = 0.83648767, grad/param norm = 2.8373e-01, time/batch = 17.8828s	
8876/11850 (epoch 37.451), train_loss = 0.80880018, grad/param norm = 2.4639e-01, time/batch = 16.6499s	
8877/11850 (epoch 37.456), train_loss = 0.91775421, grad/param norm = 3.2407e-01, time/batch = 17.0582s	
8878/11850 (epoch 37.460), train_loss = 0.95834933, grad/param norm = 3.0505e-01, time/batch = 17.1044s	
8879/11850 (epoch 37.464), train_loss = 0.87415796, grad/param norm = 3.9853e-01, time/batch = 17.9675s	
8880/11850 (epoch 37.468), train_loss = 0.95079122, grad/param norm = 3.0102e-01, time/batch = 18.1209s	
8881/11850 (epoch 37.473), train_loss = 0.99807512, grad/param norm = 3.5204e-01, time/batch = 17.1094s	
8882/11850 (epoch 37.477), train_loss = 0.83171326, grad/param norm = 2.7624e-01, time/batch = 18.1322s	
8883/11850 (epoch 37.481), train_loss = 0.86561452, grad/param norm = 3.2015e-01, time/batch = 18.0544s	
8884/11850 (epoch 37.485), train_loss = 0.81787922, grad/param norm = 2.5758e-01, time/batch = 17.0510s	
8885/11850 (epoch 37.489), train_loss = 0.93716140, grad/param norm = 2.9798e-01, time/batch = 18.3012s	
8886/11850 (epoch 37.494), train_loss = 0.81820419, grad/param norm = 2.6366e-01, time/batch = 15.2420s	
8887/11850 (epoch 37.498), train_loss = 0.82815539, grad/param norm = 2.9218e-01, time/batch = 17.7169s	
8888/11850 (epoch 37.502), train_loss = 0.81574441, grad/param norm = 3.0277e-01, time/batch = 15.7122s	
8889/11850 (epoch 37.506), train_loss = 1.06695616, grad/param norm = 2.9676e-01, time/batch = 18.3927s	
8890/11850 (epoch 37.511), train_loss = 0.91331250, grad/param norm = 2.7427e-01, time/batch = 18.8870s	
8891/11850 (epoch 37.515), train_loss = 0.99665890, grad/param norm = 3.5796e-01, time/batch = 17.1347s	
8892/11850 (epoch 37.519), train_loss = 0.87975731, grad/param norm = 3.0593e-01, time/batch = 16.6209s	
8893/11850 (epoch 37.523), train_loss = 0.92037712, grad/param norm = 2.8872e-01, time/batch = 18.8747s	
8894/11850 (epoch 37.527), train_loss = 0.85778340, grad/param norm = 2.8786e-01, time/batch = 15.0359s	
8895/11850 (epoch 37.532), train_loss = 0.92543628, grad/param norm = 2.8696e-01, time/batch = 17.1449s	
8896/11850 (epoch 37.536), train_loss = 0.89316643, grad/param norm = 2.8421e-01, time/batch = 17.8057s	
8897/11850 (epoch 37.540), train_loss = 0.83390438, grad/param norm = 2.9177e-01, time/batch = 16.7777s	
8898/11850 (epoch 37.544), train_loss = 0.83566563, grad/param norm = 3.6191e-01, time/batch = 15.4700s	
8899/11850 (epoch 37.549), train_loss = 0.77800941, grad/param norm = 2.5556e-01, time/batch = 19.2980s	
8900/11850 (epoch 37.553), train_loss = 0.91575200, grad/param norm = 3.2023e-01, time/batch = 18.2120s	
8901/11850 (epoch 37.557), train_loss = 0.96809339, grad/param norm = 4.6428e-01, time/batch = 17.6318s	
8902/11850 (epoch 37.561), train_loss = 0.97111377, grad/param norm = 3.6628e-01, time/batch = 18.0445s	
8903/11850 (epoch 37.565), train_loss = 1.04563221, grad/param norm = 3.4580e-01, time/batch = 17.7175s	
8904/11850 (epoch 37.570), train_loss = 0.94870544, grad/param norm = 2.8175e-01, time/batch = 18.7079s	
8905/11850 (epoch 37.574), train_loss = 0.95752462, grad/param norm = 2.9399e-01, time/batch = 16.3403s	
8906/11850 (epoch 37.578), train_loss = 1.00176122, grad/param norm = 3.1431e-01, time/batch = 19.2013s	
8907/11850 (epoch 37.582), train_loss = 0.88515316, grad/param norm = 3.1538e-01, time/batch = 17.4661s	
8908/11850 (epoch 37.586), train_loss = 0.88618707, grad/param norm = 2.8816e-01, time/batch = 15.2925s	
8909/11850 (epoch 37.591), train_loss = 0.93079537, grad/param norm = 3.1426e-01, time/batch = 16.1969s	
8910/11850 (epoch 37.595), train_loss = 0.79972747, grad/param norm = 2.8513e-01, time/batch = 18.1365s	
8911/11850 (epoch 37.599), train_loss = 0.91819647, grad/param norm = 2.9813e-01, time/batch = 17.2227s	
8912/11850 (epoch 37.603), train_loss = 0.85722791, grad/param norm = 2.5355e-01, time/batch = 17.3870s	
8913/11850 (epoch 37.608), train_loss = 1.03183919, grad/param norm = 3.1878e-01, time/batch = 18.8864s	
8914/11850 (epoch 37.612), train_loss = 1.10487384, grad/param norm = 3.3249e-01, time/batch = 18.3879s	
8915/11850 (epoch 37.616), train_loss = 1.02632888, grad/param norm = 3.0054e-01, time/batch = 17.7870s	
8916/11850 (epoch 37.620), train_loss = 0.90250420, grad/param norm = 2.6388e-01, time/batch = 17.7271s	
8917/11850 (epoch 37.624), train_loss = 0.89508140, grad/param norm = 3.7740e-01, time/batch = 19.2051s	
8918/11850 (epoch 37.629), train_loss = 0.90372574, grad/param norm = 3.1732e-01, time/batch = 16.1336s	
8919/11850 (epoch 37.633), train_loss = 0.81311031, grad/param norm = 2.6919e-01, time/batch = 17.8911s	
8920/11850 (epoch 37.637), train_loss = 0.74587437, grad/param norm = 2.6581e-01, time/batch = 17.8807s	
8921/11850 (epoch 37.641), train_loss = 0.80253888, grad/param norm = 2.6572e-01, time/batch = 17.8690s	
8922/11850 (epoch 37.646), train_loss = 0.81912167, grad/param norm = 2.7592e-01, time/batch = 15.0432s	
8923/11850 (epoch 37.650), train_loss = 0.89999264, grad/param norm = 3.1174e-01, time/batch = 18.0239s	
8924/11850 (epoch 37.654), train_loss = 0.84123401, grad/param norm = 2.9228e-01, time/batch = 18.3732s	
8925/11850 (epoch 37.658), train_loss = 0.92825825, grad/param norm = 2.6935e-01, time/batch = 17.7957s	
8926/11850 (epoch 37.662), train_loss = 0.81219119, grad/param norm = 4.5397e-01, time/batch = 17.7951s	
8927/11850 (epoch 37.667), train_loss = 0.99671043, grad/param norm = 3.0357e-01, time/batch = 17.0409s	
8928/11850 (epoch 37.671), train_loss = 0.87116707, grad/param norm = 3.1683e-01, time/batch = 17.8796s	
8929/11850 (epoch 37.675), train_loss = 0.88588240, grad/param norm = 3.0751e-01, time/batch = 17.9712s	
8930/11850 (epoch 37.679), train_loss = 0.90808992, grad/param norm = 2.6825e-01, time/batch = 17.5580s	
8931/11850 (epoch 37.684), train_loss = 0.87382743, grad/param norm = 3.3082e-01, time/batch = 18.8023s	
8932/11850 (epoch 37.688), train_loss = 0.83055876, grad/param norm = 3.0231e-01, time/batch = 18.2067s	
8933/11850 (epoch 37.692), train_loss = 0.86184178, grad/param norm = 3.2984e-01, time/batch = 17.5588s	
8934/11850 (epoch 37.696), train_loss = 0.83122549, grad/param norm = 3.3906e-01, time/batch = 15.5290s	
8935/11850 (epoch 37.700), train_loss = 0.89923248, grad/param norm = 2.6425e-01, time/batch = 16.2208s	
8936/11850 (epoch 37.705), train_loss = 0.82226137, grad/param norm = 2.9586e-01, time/batch = 17.4705s	
8937/11850 (epoch 37.709), train_loss = 0.77913609, grad/param norm = 2.9029e-01, time/batch = 17.4792s	
8938/11850 (epoch 37.713), train_loss = 0.77920724, grad/param norm = 2.9842e-01, time/batch = 17.0696s	
8939/11850 (epoch 37.717), train_loss = 0.84497491, grad/param norm = 2.5518e-01, time/batch = 17.1794s	
8940/11850 (epoch 37.722), train_loss = 0.88927128, grad/param norm = 3.2455e-01, time/batch = 17.4762s	
8941/11850 (epoch 37.726), train_loss = 0.81566845, grad/param norm = 2.9521e-01, time/batch = 17.2295s	
8942/11850 (epoch 37.730), train_loss = 0.81973394, grad/param norm = 2.9494e-01, time/batch = 14.8981s	
8943/11850 (epoch 37.734), train_loss = 0.81883031, grad/param norm = 2.8305e-01, time/batch = 15.7181s	
8944/11850 (epoch 37.738), train_loss = 0.92597750, grad/param norm = 3.0677e-01, time/batch = 15.7901s	
8945/11850 (epoch 37.743), train_loss = 0.88900224, grad/param norm = 2.9532e-01, time/batch = 19.4599s	
8946/11850 (epoch 37.747), train_loss = 0.78489417, grad/param norm = 2.3973e-01, time/batch = 19.1158s	
8947/11850 (epoch 37.751), train_loss = 0.85496106, grad/param norm = 2.5751e-01, time/batch = 18.2072s	
8948/11850 (epoch 37.755), train_loss = 0.90745246, grad/param norm = 2.8407e-01, time/batch = 18.3880s	
8949/11850 (epoch 37.759), train_loss = 0.83115982, grad/param norm = 2.6850e-01, time/batch = 17.6315s	
8950/11850 (epoch 37.764), train_loss = 0.87000711, grad/param norm = 2.9468e-01, time/batch = 19.0382s	
8951/11850 (epoch 37.768), train_loss = 0.79671071, grad/param norm = 3.0741e-01, time/batch = 16.5289s	
8952/11850 (epoch 37.772), train_loss = 0.86447134, grad/param norm = 3.3525e-01, time/batch = 17.0601s	
8953/11850 (epoch 37.776), train_loss = 0.91064330, grad/param norm = 2.7490e-01, time/batch = 18.7092s	
8954/11850 (epoch 37.781), train_loss = 0.85772686, grad/param norm = 2.8918e-01, time/batch = 17.9621s	
8955/11850 (epoch 37.785), train_loss = 0.86867493, grad/param norm = 2.9194e-01, time/batch = 18.4571s	
8956/11850 (epoch 37.789), train_loss = 0.85301063, grad/param norm = 2.5645e-01, time/batch = 16.6145s	
8957/11850 (epoch 37.793), train_loss = 0.92753431, grad/param norm = 3.1290e-01, time/batch = 16.8917s	
8958/11850 (epoch 37.797), train_loss = 0.88094977, grad/param norm = 2.9085e-01, time/batch = 17.8072s	
8959/11850 (epoch 37.802), train_loss = 0.82264391, grad/param norm = 2.9616e-01, time/batch = 15.4513s	
8960/11850 (epoch 37.806), train_loss = 0.89626679, grad/param norm = 3.1282e-01, time/batch = 16.3749s	
8961/11850 (epoch 37.810), train_loss = 0.92842542, grad/param norm = 3.0576e-01, time/batch = 17.4694s	
8962/11850 (epoch 37.814), train_loss = 0.90621017, grad/param norm = 2.9681e-01, time/batch = 18.3492s	
8963/11850 (epoch 37.819), train_loss = 0.98902502, grad/param norm = 3.0687e-01, time/batch = 17.7104s	
8964/11850 (epoch 37.823), train_loss = 0.99938992, grad/param norm = 3.0319e-01, time/batch = 18.8796s	
8965/11850 (epoch 37.827), train_loss = 0.88531817, grad/param norm = 3.4031e-01, time/batch = 18.6159s	
8966/11850 (epoch 37.831), train_loss = 0.86497672, grad/param norm = 3.0436e-01, time/batch = 16.3805s	
8967/11850 (epoch 37.835), train_loss = 0.91995591, grad/param norm = 2.5468e-01, time/batch = 18.8897s	
8968/11850 (epoch 37.840), train_loss = 0.84901649, grad/param norm = 2.7417e-01, time/batch = 17.6310s	
8969/11850 (epoch 37.844), train_loss = 0.88608380, grad/param norm = 2.3890e-01, time/batch = 18.2992s	
8970/11850 (epoch 37.848), train_loss = 0.91763256, grad/param norm = 2.8651e-01, time/batch = 16.2248s	
8971/11850 (epoch 37.852), train_loss = 0.90908020, grad/param norm = 3.0381e-01, time/batch = 18.7155s	
8972/11850 (epoch 37.857), train_loss = 0.86408544, grad/param norm = 3.0296e-01, time/batch = 18.7028s	
8973/11850 (epoch 37.861), train_loss = 0.82386728, grad/param norm = 3.4314e-01, time/batch = 18.1978s	
8974/11850 (epoch 37.865), train_loss = 0.92506174, grad/param norm = 3.3019e-01, time/batch = 17.5539s	
8975/11850 (epoch 37.869), train_loss = 0.90176261, grad/param norm = 3.1071e-01, time/batch = 18.3014s	
8976/11850 (epoch 37.873), train_loss = 0.91296656, grad/param norm = 2.9198e-01, time/batch = 17.5455s	
8977/11850 (epoch 37.878), train_loss = 0.92673294, grad/param norm = 2.9542e-01, time/batch = 17.2018s	
8978/11850 (epoch 37.882), train_loss = 0.91230167, grad/param norm = 3.4787e-01, time/batch = 17.1392s	
8979/11850 (epoch 37.886), train_loss = 0.87255479, grad/param norm = 3.0647e-01, time/batch = 15.6296s	
8980/11850 (epoch 37.890), train_loss = 0.91077242, grad/param norm = 4.8722e-01, time/batch = 15.1922s	
8981/11850 (epoch 37.895), train_loss = 0.92789162, grad/param norm = 3.6558e-01, time/batch = 18.1282s	
8982/11850 (epoch 37.899), train_loss = 0.84407329, grad/param norm = 3.3923e-01, time/batch = 17.6221s	
8983/11850 (epoch 37.903), train_loss = 0.86267504, grad/param norm = 3.1979e-01, time/batch = 16.6098s	
8984/11850 (epoch 37.907), train_loss = 0.86526701, grad/param norm = 2.7964e-01, time/batch = 17.3801s	
8985/11850 (epoch 37.911), train_loss = 0.98936941, grad/param norm = 2.8593e-01, time/batch = 18.7920s	
8986/11850 (epoch 37.916), train_loss = 0.96064943, grad/param norm = 3.4629e-01, time/batch = 18.0454s	
8987/11850 (epoch 37.920), train_loss = 0.92287096, grad/param norm = 3.0868e-01, time/batch = 18.6251s	
8988/11850 (epoch 37.924), train_loss = 0.87126664, grad/param norm = 3.1002e-01, time/batch = 17.2905s	
8989/11850 (epoch 37.928), train_loss = 0.93890649, grad/param norm = 3.3189e-01, time/batch = 16.4801s	
8990/11850 (epoch 37.932), train_loss = 1.00673244, grad/param norm = 3.5487e-01, time/batch = 28.8979s	
8991/11850 (epoch 37.937), train_loss = 0.97570962, grad/param norm = 2.8328e-01, time/batch = 16.7260s	
8992/11850 (epoch 37.941), train_loss = 0.93548780, grad/param norm = 2.9576e-01, time/batch = 17.8817s	
8993/11850 (epoch 37.945), train_loss = 0.95758342, grad/param norm = 3.7542e-01, time/batch = 15.7054s	
8994/11850 (epoch 37.949), train_loss = 0.86202498, grad/param norm = 3.8724e-01, time/batch = 18.1429s	
8995/11850 (epoch 37.954), train_loss = 0.98295596, grad/param norm = 5.1225e-01, time/batch = 18.1382s	
8996/11850 (epoch 37.958), train_loss = 0.96323421, grad/param norm = 3.4053e-01, time/batch = 15.5431s	
8997/11850 (epoch 37.962), train_loss = 0.86544441, grad/param norm = 3.4493e-01, time/batch = 15.0125s	
8998/11850 (epoch 37.966), train_loss = 0.82957126, grad/param norm = 3.6616e-01, time/batch = 19.0527s	
8999/11850 (epoch 37.970), train_loss = 0.93982715, grad/param norm = 2.9246e-01, time/batch = 17.1302s	
evaluating loss over split index 2	
1/13...	
2/13...	
3/13...	
4/13...	
5/13...	
6/13...	
7/13...	
8/13...	
9/13...	
10/13...	
11/13...	
12/13...	
13/13...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_katelyn_salem_epoch37.97_2.3361.t7	
9000/11850 (epoch 37.975), train_loss = 0.89331723, grad/param norm = 2.8907e-01, time/batch = 18.0341s	
9001/11850 (epoch 37.979), train_loss = 1.41768039, grad/param norm = 5.3721e-01, time/batch = 18.8831s	
9002/11850 (epoch 37.983), train_loss = 1.02303961, grad/param norm = 4.8791e-01, time/batch = 19.0414s	
9003/11850 (epoch 37.987), train_loss = 0.87960503, grad/param norm = 3.2816e-01, time/batch = 16.5285s	
9004/11850 (epoch 37.992), train_loss = 1.03247598, grad/param norm = 3.5109e-01, time/batch = 17.9607s	
9005/11850 (epoch 37.996), train_loss = 1.01259352, grad/param norm = 2.9834e-01, time/batch = 16.3106s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
9006/11850 (epoch 38.000), train_loss = 0.89269411, grad/param norm = 3.7834e-01, time/batch = 18.6323s	
9007/11850 (epoch 38.004), train_loss = 0.96396468, grad/param norm = 3.5427e-01, time/batch = 16.9413s	
9008/11850 (epoch 38.008), train_loss = 0.99907649, grad/param norm = 3.5272e-01, time/batch = 18.7005s	
9009/11850 (epoch 38.013), train_loss = 1.01327745, grad/param norm = 2.9575e-01, time/batch = 16.9238s	
9010/11850 (epoch 38.017), train_loss = 1.04379753, grad/param norm = 3.2748e-01, time/batch = 18.4581s	
9011/11850 (epoch 38.021), train_loss = 0.98846866, grad/param norm = 2.7291e-01, time/batch = 16.6871s	
9012/11850 (epoch 38.025), train_loss = 0.86483386, grad/param norm = 2.4722e-01, time/batch = 18.8713s	
9013/11850 (epoch 38.030), train_loss = 0.90346013, grad/param norm = 3.0238e-01, time/batch = 17.6192s	
9014/11850 (epoch 38.034), train_loss = 0.89387733, grad/param norm = 3.0580e-01, time/batch = 19.0545s	
9015/11850 (epoch 38.038), train_loss = 0.91042111, grad/param norm = 2.8126e-01, time/batch = 18.2960s	
9016/11850 (epoch 38.042), train_loss = 0.94119312, grad/param norm = 3.0448e-01, time/batch = 18.3031s	
9017/11850 (epoch 38.046), train_loss = 0.91073112, grad/param norm = 3.7024e-01, time/batch = 18.3653s	
9018/11850 (epoch 38.051), train_loss = 0.92680810, grad/param norm = 3.1377e-01, time/batch = 16.3765s	
9019/11850 (epoch 38.055), train_loss = 0.86743681, grad/param norm = 2.6912e-01, time/batch = 18.8777s	
9020/11850 (epoch 38.059), train_loss = 0.96719015, grad/param norm = 2.8693e-01, time/batch = 16.1355s	
9021/11850 (epoch 38.063), train_loss = 1.00040910, grad/param norm = 3.1750e-01, time/batch = 16.8742s	
9022/11850 (epoch 38.068), train_loss = 0.91148777, grad/param norm = 2.8559e-01, time/batch = 16.4098s	
9023/11850 (epoch 38.072), train_loss = 0.96614454, grad/param norm = 2.9487e-01, time/batch = 17.6473s	
9024/11850 (epoch 38.076), train_loss = 1.04739865, grad/param norm = 3.2508e-01, time/batch = 15.3903s	
9025/11850 (epoch 38.080), train_loss = 0.84221445, grad/param norm = 2.7529e-01, time/batch = 18.1041s	
9026/11850 (epoch 38.084), train_loss = 0.81916735, grad/param norm = 2.8013e-01, time/batch = 17.7287s	
9027/11850 (epoch 38.089), train_loss = 0.82284093, grad/param norm = 2.6641e-01, time/batch = 16.7089s	
9028/11850 (epoch 38.093), train_loss = 0.84180262, grad/param norm = 3.5182e-01, time/batch = 19.3804s	
9029/11850 (epoch 38.097), train_loss = 0.92771296, grad/param norm = 3.0086e-01, time/batch = 16.9749s	
9030/11850 (epoch 38.101), train_loss = 0.84502244, grad/param norm = 3.5235e-01, time/batch = 16.3742s	
9031/11850 (epoch 38.105), train_loss = 0.82484639, grad/param norm = 2.5469e-01, time/batch = 18.4535s	
9032/11850 (epoch 38.110), train_loss = 0.96440291, grad/param norm = 2.9537e-01, time/batch = 16.7354s	
9033/11850 (epoch 38.114), train_loss = 0.86159165, grad/param norm = 2.7459e-01, time/batch = 18.2282s	
9034/11850 (epoch 38.118), train_loss = 0.97241928, grad/param norm = 2.7222e-01, time/batch = 16.0457s	
9035/11850 (epoch 38.122), train_loss = 1.01786040, grad/param norm = 2.7771e-01, time/batch = 17.4702s	
9036/11850 (epoch 38.127), train_loss = 0.95499360, grad/param norm = 3.1689e-01, time/batch = 17.9724s	
9037/11850 (epoch 38.131), train_loss = 0.90652909, grad/param norm = 3.1060e-01, time/batch = 15.5557s	
9038/11850 (epoch 38.135), train_loss = 0.91232267, grad/param norm = 3.1010e-01, time/batch = 16.0480s	
9039/11850 (epoch 38.139), train_loss = 0.89421688, grad/param norm = 2.6808e-01, time/batch = 17.3652s	
9040/11850 (epoch 38.143), train_loss = 0.88406569, grad/param norm = 2.9513e-01, time/batch = 17.9740s	
9041/11850 (epoch 38.148), train_loss = 0.89063306, grad/param norm = 3.2096e-01, time/batch = 17.2971s	
9042/11850 (epoch 38.152), train_loss = 0.98571894, grad/param norm = 3.2363e-01, time/batch = 16.7897s	
9043/11850 (epoch 38.156), train_loss = 0.88143949, grad/param norm = 3.4101e-01, time/batch = 15.3962s	
9044/11850 (epoch 38.160), train_loss = 1.06124477, grad/param norm = 3.5357e-01, time/batch = 18.3658s	
9045/11850 (epoch 38.165), train_loss = 0.99812815, grad/param norm = 3.6629e-01, time/batch = 15.4730s	
9046/11850 (epoch 38.169), train_loss = 0.91913893, grad/param norm = 3.7254e-01, time/batch = 18.2120s	
9047/11850 (epoch 38.173), train_loss = 0.97281211, grad/param norm = 2.7473e-01, time/batch = 18.9785s	
9048/11850 (epoch 38.177), train_loss = 0.81797143, grad/param norm = 2.8825e-01, time/batch = 15.2078s	
9049/11850 (epoch 38.181), train_loss = 0.93372142, grad/param norm = 3.2767e-01, time/batch = 18.9667s	
9050/11850 (epoch 38.186), train_loss = 1.02385891, grad/param norm = 3.4393e-01, time/batch = 18.8818s	
9051/11850 (epoch 38.190), train_loss = 0.95408696, grad/param norm = 3.0423e-01, time/batch = 17.0292s	
9052/11850 (epoch 38.194), train_loss = 0.96188425, grad/param norm = 3.5891e-01, time/batch = 18.6359s	
9053/11850 (epoch 38.198), train_loss = 0.76737588, grad/param norm = 2.7935e-01, time/batch = 18.1403s	
9054/11850 (epoch 38.203), train_loss = 0.78779754, grad/param norm = 2.6279e-01, time/batch = 17.8896s	
9055/11850 (epoch 38.207), train_loss = 0.94241883, grad/param norm = 3.1317e-01, time/batch = 16.4997s	
9056/11850 (epoch 38.211), train_loss = 0.90741973, grad/param norm = 3.1190e-01, time/batch = 14.3368s	
9057/11850 (epoch 38.215), train_loss = 0.94182190, grad/param norm = 3.2691e-01, time/batch = 17.1315s	
9058/11850 (epoch 38.219), train_loss = 0.93146518, grad/param norm = 2.7034e-01, time/batch = 17.3902s	
9059/11850 (epoch 38.224), train_loss = 1.06146687, grad/param norm = 3.1408e-01, time/batch = 15.7947s	
9060/11850 (epoch 38.228), train_loss = 0.96119253, grad/param norm = 2.9846e-01, time/batch = 17.9745s	
9061/11850 (epoch 38.232), train_loss = 0.93484400, grad/param norm = 3.2508e-01, time/batch = 18.8002s	
9062/11850 (epoch 38.236), train_loss = 0.85783114, grad/param norm = 2.8382e-01, time/batch = 18.0419s	
9063/11850 (epoch 38.241), train_loss = 0.97469158, grad/param norm = 3.0604e-01, time/batch = 18.3898s	
9064/11850 (epoch 38.245), train_loss = 0.97369167, grad/param norm = 2.7366e-01, time/batch = 17.8886s	
9065/11850 (epoch 38.249), train_loss = 0.90918648, grad/param norm = 2.6138e-01, time/batch = 17.3050s	
9066/11850 (epoch 38.253), train_loss = 0.91164233, grad/param norm = 3.0607e-01, time/batch = 17.9713s	
9067/11850 (epoch 38.257), train_loss = 1.02768831, grad/param norm = 2.7805e-01, time/batch = 17.0044s	
9068/11850 (epoch 38.262), train_loss = 1.05284836, grad/param norm = 3.4179e-01, time/batch = 17.7157s	
9069/11850 (epoch 38.266), train_loss = 1.03741466, grad/param norm = 4.1740e-01, time/batch = 17.7124s	
9070/11850 (epoch 38.270), train_loss = 0.92648234, grad/param norm = 2.7125e-01, time/batch = 17.5380s	
9071/11850 (epoch 38.274), train_loss = 0.91484820, grad/param norm = 3.2177e-01, time/batch = 18.7995s	
9072/11850 (epoch 38.278), train_loss = 0.81029184, grad/param norm = 2.7295e-01, time/batch = 17.1883s	
9073/11850 (epoch 38.283), train_loss = 0.91468476, grad/param norm = 2.7320e-01, time/batch = 17.9741s	
9074/11850 (epoch 38.287), train_loss = 1.04070520, grad/param norm = 3.0656e-01, time/batch = 18.1404s	
9075/11850 (epoch 38.291), train_loss = 0.90134965, grad/param norm = 2.8862e-01, time/batch = 15.8731s	
9076/11850 (epoch 38.295), train_loss = 0.96752343, grad/param norm = 2.8688e-01, time/batch = 16.8065s	
9077/11850 (epoch 38.300), train_loss = 0.88232525, grad/param norm = 3.0396e-01, time/batch = 16.8818s	
9078/11850 (epoch 38.304), train_loss = 0.91600467, grad/param norm = 2.4834e-01, time/batch = 16.3874s	
9079/11850 (epoch 38.308), train_loss = 0.92071550, grad/param norm = 2.8433e-01, time/batch = 17.3647s	
9080/11850 (epoch 38.312), train_loss = 0.80791790, grad/param norm = 2.7532e-01, time/batch = 17.3770s	
9081/11850 (epoch 38.316), train_loss = 0.92657454, grad/param norm = 2.6848e-01, time/batch = 18.7883s	
9082/11850 (epoch 38.321), train_loss = 0.88459873, grad/param norm = 2.4374e-01, time/batch = 17.4559s	
9083/11850 (epoch 38.325), train_loss = 0.92438809, grad/param norm = 2.9402e-01, time/batch = 18.4636s	
9084/11850 (epoch 38.329), train_loss = 0.92106193, grad/param norm = 2.9879e-01, time/batch = 18.5545s	
9085/11850 (epoch 38.333), train_loss = 0.89282377, grad/param norm = 2.7735e-01, time/batch = 17.7246s	
9086/11850 (epoch 38.338), train_loss = 0.88482660, grad/param norm = 2.6025e-01, time/batch = 17.7213s	
9087/11850 (epoch 38.342), train_loss = 0.90692838, grad/param norm = 2.7956e-01, time/batch = 17.7153s	
9088/11850 (epoch 38.346), train_loss = 0.89037902, grad/param norm = 2.9740e-01, time/batch = 18.6391s	
9089/11850 (epoch 38.350), train_loss = 0.81337736, grad/param norm = 2.7087e-01, time/batch = 17.0109s	
9090/11850 (epoch 38.354), train_loss = 0.96980177, grad/param norm = 2.7246e-01, time/batch = 16.9676s	
9091/11850 (epoch 38.359), train_loss = 1.04429221, grad/param norm = 3.2317e-01, time/batch = 17.3915s	
9092/11850 (epoch 38.363), train_loss = 0.94735929, grad/param norm = 2.7375e-01, time/batch = 16.9751s	
9093/11850 (epoch 38.367), train_loss = 0.98499470, grad/param norm = 2.8173e-01, time/batch = 15.1172s	
9094/11850 (epoch 38.371), train_loss = 0.96542996, grad/param norm = 2.6708e-01, time/batch = 17.0552s	
9095/11850 (epoch 38.376), train_loss = 0.91117042, grad/param norm = 2.6813e-01, time/batch = 17.6479s	
9096/11850 (epoch 38.380), train_loss = 0.89196737, grad/param norm = 2.6972e-01, time/batch = 17.4648s	
9097/11850 (epoch 38.384), train_loss = 0.83893727, grad/param norm = 2.8428e-01, time/batch = 16.4925s	
9098/11850 (epoch 38.388), train_loss = 0.98289768, grad/param norm = 3.1427e-01, time/batch = 18.7211s	
9099/11850 (epoch 38.392), train_loss = 0.94792028, grad/param norm = 2.8987e-01, time/batch = 14.4050s	
9100/11850 (epoch 38.397), train_loss = 0.96814261, grad/param norm = 3.2265e-01, time/batch = 19.2087s	
9101/11850 (epoch 38.401), train_loss = 0.81444913, grad/param norm = 2.6230e-01, time/batch = 16.2775s	
9102/11850 (epoch 38.405), train_loss = 0.84825178, grad/param norm = 3.0907e-01, time/batch = 19.0444s	
9103/11850 (epoch 38.409), train_loss = 0.96790578, grad/param norm = 2.9500e-01, time/batch = 17.6357s	
9104/11850 (epoch 38.414), train_loss = 0.77421034, grad/param norm = 2.5020e-01, time/batch = 18.5429s	
9105/11850 (epoch 38.418), train_loss = 0.80778572, grad/param norm = 2.6581e-01, time/batch = 18.2270s	
9106/11850 (epoch 38.422), train_loss = 0.74820130, grad/param norm = 2.5416e-01, time/batch = 16.2996s	
9107/11850 (epoch 38.426), train_loss = 0.76166253, grad/param norm = 2.6313e-01, time/batch = 16.2109s	
9108/11850 (epoch 38.430), train_loss = 0.83083628, grad/param norm = 2.8650e-01, time/batch = 17.4732s	
9109/11850 (epoch 38.435), train_loss = 0.85765322, grad/param norm = 3.0426e-01, time/batch = 18.1278s	
9110/11850 (epoch 38.439), train_loss = 0.94088431, grad/param norm = 2.5886e-01, time/batch = 15.8012s	
9111/11850 (epoch 38.443), train_loss = 0.89454168, grad/param norm = 2.9813e-01, time/batch = 17.2278s	
9112/11850 (epoch 38.447), train_loss = 0.83066840, grad/param norm = 3.2203e-01, time/batch = 18.3919s	
9113/11850 (epoch 38.451), train_loss = 0.79765472, grad/param norm = 2.7204e-01, time/batch = 17.5261s	
9114/11850 (epoch 38.456), train_loss = 0.90952039, grad/param norm = 3.4221e-01, time/batch = 15.1947s	
9115/11850 (epoch 38.460), train_loss = 0.94353934, grad/param norm = 2.8917e-01, time/batch = 18.5482s	
9116/11850 (epoch 38.464), train_loss = 0.86396179, grad/param norm = 2.9773e-01, time/batch = 17.7816s	
9117/11850 (epoch 38.468), train_loss = 0.95003688, grad/param norm = 3.9672e-01, time/batch = 18.5575s	
9118/11850 (epoch 38.473), train_loss = 0.98628627, grad/param norm = 3.1650e-01, time/batch = 18.3854s	
9119/11850 (epoch 38.477), train_loss = 0.80702427, grad/param norm = 2.6238e-01, time/batch = 17.0525s	
9120/11850 (epoch 38.481), train_loss = 0.85425050, grad/param norm = 2.9504e-01, time/batch = 18.7803s	
9121/11850 (epoch 38.485), train_loss = 0.80094808, grad/param norm = 2.5475e-01, time/batch = 18.3031s	
9122/11850 (epoch 38.489), train_loss = 0.90955046, grad/param norm = 2.9179e-01, time/batch = 18.2970s	
9123/11850 (epoch 38.494), train_loss = 0.81167201, grad/param norm = 3.1893e-01, time/batch = 16.0317s	
9124/11850 (epoch 38.498), train_loss = 0.82070775, grad/param norm = 3.0848e-01, time/batch = 16.0384s	
9125/11850 (epoch 38.502), train_loss = 0.80964780, grad/param norm = 3.3150e-01, time/batch = 17.6156s	
9126/11850 (epoch 38.506), train_loss = 1.03286336, grad/param norm = 2.9808e-01, time/batch = 17.4614s	
9127/11850 (epoch 38.511), train_loss = 0.88712030, grad/param norm = 2.6666e-01, time/batch = 16.2114s	
9128/11850 (epoch 38.515), train_loss = 0.97505679, grad/param norm = 3.0751e-01, time/batch = 17.3930s	
9129/11850 (epoch 38.519), train_loss = 0.86650550, grad/param norm = 3.0311e-01, time/batch = 16.5663s	
9130/11850 (epoch 38.523), train_loss = 0.91396359, grad/param norm = 2.9762e-01, time/batch = 17.1280s	
9131/11850 (epoch 38.527), train_loss = 0.83774356, grad/param norm = 2.6527e-01, time/batch = 18.3938s	
9132/11850 (epoch 38.532), train_loss = 0.91051345, grad/param norm = 2.8335e-01, time/batch = 17.7212s	
9133/11850 (epoch 38.536), train_loss = 0.87065013, grad/param norm = 2.8692e-01, time/batch = 17.0681s	
9134/11850 (epoch 38.540), train_loss = 0.81096243, grad/param norm = 2.6656e-01, time/batch = 16.1981s	
9135/11850 (epoch 38.544), train_loss = 0.81500006, grad/param norm = 3.0142e-01, time/batch = 17.8899s	
9136/11850 (epoch 38.549), train_loss = 0.77208929, grad/param norm = 2.4537e-01, time/batch = 17.8913s	
9137/11850 (epoch 38.553), train_loss = 0.90810901, grad/param norm = 2.9084e-01, time/batch = 16.5508s	
9138/11850 (epoch 38.557), train_loss = 0.93885808, grad/param norm = 3.8438e-01, time/batch = 17.2311s	
9139/11850 (epoch 38.561), train_loss = 0.95603809, grad/param norm = 3.7346e-01, time/batch = 17.1381s	
9140/11850 (epoch 38.565), train_loss = 1.03437474, grad/param norm = 3.4238e-01, time/batch = 15.4554s	
9141/11850 (epoch 38.570), train_loss = 0.94361850, grad/param norm = 2.7850e-01, time/batch = 15.9714s	
9142/11850 (epoch 38.574), train_loss = 0.95799654, grad/param norm = 3.1708e-01, time/batch = 16.7247s	
9143/11850 (epoch 38.578), train_loss = 0.98500548, grad/param norm = 3.1902e-01, time/batch = 18.3843s	
9144/11850 (epoch 38.582), train_loss = 0.87851671, grad/param norm = 3.5380e-01, time/batch = 17.2136s	
9145/11850 (epoch 38.586), train_loss = 0.87424667, grad/param norm = 2.9395e-01, time/batch = 17.4600s	
9146/11850 (epoch 38.591), train_loss = 0.91708505, grad/param norm = 3.2599e-01, time/batch = 15.9612s	
9147/11850 (epoch 38.595), train_loss = 0.76514694, grad/param norm = 2.7709e-01, time/batch = 18.1299s	
9148/11850 (epoch 38.599), train_loss = 0.89261628, grad/param norm = 2.9208e-01, time/batch = 17.5589s	
9149/11850 (epoch 38.603), train_loss = 0.84569147, grad/param norm = 2.5229e-01, time/batch = 17.2204s	
9150/11850 (epoch 38.608), train_loss = 1.02835379, grad/param norm = 3.1211e-01, time/batch = 15.5571s	
9151/11850 (epoch 38.612), train_loss = 1.10119887, grad/param norm = 3.8922e-01, time/batch = 15.4761s	
9152/11850 (epoch 38.616), train_loss = 1.01910997, grad/param norm = 2.9645e-01, time/batch = 17.6053s	
9153/11850 (epoch 38.620), train_loss = 0.87874522, grad/param norm = 2.6132e-01, time/batch = 18.0561s	
9154/11850 (epoch 38.624), train_loss = 0.89372763, grad/param norm = 3.6982e-01, time/batch = 18.2832s	
9155/11850 (epoch 38.629), train_loss = 0.87246386, grad/param norm = 2.6978e-01, time/batch = 17.9562s	
9156/11850 (epoch 38.633), train_loss = 0.81018402, grad/param norm = 2.7895e-01, time/batch = 16.9016s	
9157/11850 (epoch 38.637), train_loss = 0.73490588, grad/param norm = 2.6589e-01, time/batch = 18.7078s	
9158/11850 (epoch 38.641), train_loss = 0.78593371, grad/param norm = 2.5136e-01, time/batch = 15.6113s	
9159/11850 (epoch 38.646), train_loss = 0.81267564, grad/param norm = 3.4853e-01, time/batch = 14.7135s	
9160/11850 (epoch 38.650), train_loss = 0.90351783, grad/param norm = 3.6818e-01, time/batch = 17.9669s	
9161/11850 (epoch 38.654), train_loss = 0.84639453, grad/param norm = 3.1929e-01, time/batch = 17.2915s	
9162/11850 (epoch 38.658), train_loss = 0.92287368, grad/param norm = 2.9160e-01, time/batch = 16.3856s	
9163/11850 (epoch 38.662), train_loss = 0.79562413, grad/param norm = 3.5226e-01, time/batch = 17.0163s	
9164/11850 (epoch 38.667), train_loss = 0.98680278, grad/param norm = 2.9805e-01, time/batch = 17.8706s	
9165/11850 (epoch 38.671), train_loss = 0.85097109, grad/param norm = 2.8537e-01, time/batch = 16.2154s	
9166/11850 (epoch 38.675), train_loss = 0.86329823, grad/param norm = 2.9236e-01, time/batch = 13.9264s	
9167/11850 (epoch 38.679), train_loss = 0.89274044, grad/param norm = 2.8832e-01, time/batch = 17.8198s	
9168/11850 (epoch 38.684), train_loss = 0.86454037, grad/param norm = 3.4648e-01, time/batch = 18.6406s	
9169/11850 (epoch 38.688), train_loss = 0.82533426, grad/param norm = 3.1012e-01, time/batch = 17.0414s	
9170/11850 (epoch 38.692), train_loss = 0.85408974, grad/param norm = 4.7120e-01, time/batch = 18.1211s	
9171/11850 (epoch 38.696), train_loss = 0.81998428, grad/param norm = 3.9112e-01, time/batch = 18.5480s	
9172/11850 (epoch 38.700), train_loss = 0.89593618, grad/param norm = 2.9822e-01, time/batch = 15.9729s	
9173/11850 (epoch 38.705), train_loss = 0.81602533, grad/param norm = 3.2561e-01, time/batch = 18.8796s	
9174/11850 (epoch 38.709), train_loss = 0.75979168, grad/param norm = 2.7171e-01, time/batch = 16.2836s	
9175/11850 (epoch 38.713), train_loss = 0.76848892, grad/param norm = 2.8653e-01, time/batch = 18.0156s	
9176/11850 (epoch 38.717), train_loss = 0.82795703, grad/param norm = 2.5909e-01, time/batch = 16.6321s	
9177/11850 (epoch 38.722), train_loss = 0.88738132, grad/param norm = 3.2777e-01, time/batch = 17.7269s	
9178/11850 (epoch 38.726), train_loss = 0.79062009, grad/param norm = 2.7077e-01, time/batch = 17.7257s	
9179/11850 (epoch 38.730), train_loss = 0.81603059, grad/param norm = 3.5170e-01, time/batch = 17.3788s	
9180/11850 (epoch 38.734), train_loss = 0.80449614, grad/param norm = 2.9411e-01, time/batch = 16.7009s	
9181/11850 (epoch 38.738), train_loss = 0.92525393, grad/param norm = 3.7131e-01, time/batch = 17.8882s	
9182/11850 (epoch 38.743), train_loss = 0.88010539, grad/param norm = 3.1385e-01, time/batch = 17.5432s	
9183/11850 (epoch 38.747), train_loss = 0.78054477, grad/param norm = 2.4945e-01, time/batch = 17.3842s	
9184/11850 (epoch 38.751), train_loss = 0.83750207, grad/param norm = 2.7074e-01, time/batch = 17.3789s	
9185/11850 (epoch 38.755), train_loss = 0.90087747, grad/param norm = 2.8592e-01, time/batch = 16.6029s	
9186/11850 (epoch 38.759), train_loss = 0.81832538, grad/param norm = 2.6610e-01, time/batch = 16.6266s	
9187/11850 (epoch 38.764), train_loss = 0.87078235, grad/param norm = 2.6147e-01, time/batch = 18.6269s	
9188/11850 (epoch 38.768), train_loss = 0.78770930, grad/param norm = 2.8350e-01, time/batch = 18.6387s	
9189/11850 (epoch 38.772), train_loss = 0.84197181, grad/param norm = 3.5758e-01, time/batch = 18.1239s	
9190/11850 (epoch 38.776), train_loss = 0.90641862, grad/param norm = 3.1253e-01, time/batch = 17.3851s	
9191/11850 (epoch 38.781), train_loss = 0.84401438, grad/param norm = 2.5963e-01, time/batch = 18.3778s	
9192/11850 (epoch 38.785), train_loss = 0.86546654, grad/param norm = 2.9873e-01, time/batch = 21.2887s	
9193/11850 (epoch 38.789), train_loss = 0.84364207, grad/param norm = 2.7508e-01, time/batch = 26.5259s	
9194/11850 (epoch 38.793), train_loss = 0.92237613, grad/param norm = 4.4235e-01, time/batch = 16.5568s	
9195/11850 (epoch 38.797), train_loss = 0.90155052, grad/param norm = 4.0385e-01, time/batch = 17.7205s	
9196/11850 (epoch 38.802), train_loss = 0.81935101, grad/param norm = 3.2189e-01, time/batch = 15.0302s	
9197/11850 (epoch 38.806), train_loss = 0.87160906, grad/param norm = 3.0882e-01, time/batch = 16.8048s	
9198/11850 (epoch 38.810), train_loss = 0.92812847, grad/param norm = 3.2996e-01, time/batch = 18.8838s	
9199/11850 (epoch 38.814), train_loss = 0.88515387, grad/param norm = 3.2151e-01, time/batch = 15.5285s	
9200/11850 (epoch 38.819), train_loss = 0.97785397, grad/param norm = 3.2419e-01, time/batch = 18.3068s	
9201/11850 (epoch 38.823), train_loss = 0.99050048, grad/param norm = 3.1180e-01, time/batch = 17.4721s	
9202/11850 (epoch 38.827), train_loss = 0.88898307, grad/param norm = 3.5233e-01, time/batch = 16.8881s	
9203/11850 (epoch 38.831), train_loss = 0.85441250, grad/param norm = 3.2127e-01, time/batch = 18.1380s	
9204/11850 (epoch 38.835), train_loss = 0.90065603, grad/param norm = 2.4921e-01, time/batch = 18.2227s	
9205/11850 (epoch 38.840), train_loss = 0.83780642, grad/param norm = 2.8315e-01, time/batch = 17.0595s	
9206/11850 (epoch 38.844), train_loss = 0.88456643, grad/param norm = 2.3916e-01, time/batch = 18.4458s	
9207/11850 (epoch 38.848), train_loss = 0.91328766, grad/param norm = 3.2187e-01, time/batch = 18.2952s	
9208/11850 (epoch 38.852), train_loss = 0.89074004, grad/param norm = 3.4986e-01, time/batch = 18.8860s	
9209/11850 (epoch 38.857), train_loss = 0.86473164, grad/param norm = 4.1353e-01, time/batch = 17.6810s	
9210/11850 (epoch 38.861), train_loss = 0.82374229, grad/param norm = 3.0848e-01, time/batch = 16.3335s	
9211/11850 (epoch 38.865), train_loss = 0.93402827, grad/param norm = 3.5274e-01, time/batch = 15.4677s	
9212/11850 (epoch 38.869), train_loss = 0.89329071, grad/param norm = 3.0120e-01, time/batch = 16.2154s	
9213/11850 (epoch 38.873), train_loss = 0.89532628, grad/param norm = 3.1865e-01, time/batch = 16.4590s	
9214/11850 (epoch 38.878), train_loss = 0.91179534, grad/param norm = 2.9383e-01, time/batch = 17.8046s	
9215/11850 (epoch 38.882), train_loss = 0.90719027, grad/param norm = 3.6999e-01, time/batch = 15.6582s	
9216/11850 (epoch 38.886), train_loss = 0.86665342, grad/param norm = 3.8971e-01, time/batch = 14.8971s	
9217/11850 (epoch 38.890), train_loss = 0.91158860, grad/param norm = 3.5507e-01, time/batch = 16.6961s	
9218/11850 (epoch 38.895), train_loss = 0.89764118, grad/param norm = 3.8263e-01, time/batch = 18.3020s	
9219/11850 (epoch 38.899), train_loss = 0.79364937, grad/param norm = 2.9736e-01, time/batch = 18.0500s	
9220/11850 (epoch 38.903), train_loss = 0.83151824, grad/param norm = 2.9105e-01, time/batch = 18.1354s	
9221/11850 (epoch 38.907), train_loss = 0.84849275, grad/param norm = 3.5852e-01, time/batch = 17.1460s	
9222/11850 (epoch 38.911), train_loss = 0.97448995, grad/param norm = 2.8162e-01, time/batch = 19.2981s	
9223/11850 (epoch 38.916), train_loss = 0.93190318, grad/param norm = 3.5085e-01, time/batch = 18.3714s	
9224/11850 (epoch 38.920), train_loss = 0.91028064, grad/param norm = 2.9682e-01, time/batch = 18.4636s	
9225/11850 (epoch 38.924), train_loss = 0.85302757, grad/param norm = 3.8048e-01, time/batch = 15.6364s	
9226/11850 (epoch 38.928), train_loss = 0.92453878, grad/param norm = 3.1972e-01, time/batch = 16.9495s	
9227/11850 (epoch 38.932), train_loss = 1.02480499, grad/param norm = 6.4967e-01, time/batch = 17.6332s	
9228/11850 (epoch 38.937), train_loss = 0.98270334, grad/param norm = 2.9792e-01, time/batch = 16.6304s	
9229/11850 (epoch 38.941), train_loss = 0.91763752, grad/param norm = 3.0638e-01, time/batch = 18.2256s	
9230/11850 (epoch 38.945), train_loss = 0.93967424, grad/param norm = 3.1363e-01, time/batch = 16.6311s	
9231/11850 (epoch 38.949), train_loss = 0.85338169, grad/param norm = 3.3268e-01, time/batch = 17.8776s	
9232/11850 (epoch 38.954), train_loss = 0.96338820, grad/param norm = 3.7475e-01, time/batch = 17.5593s	
9233/11850 (epoch 38.958), train_loss = 0.94582604, grad/param norm = 3.0367e-01, time/batch = 16.8846s	
9234/11850 (epoch 38.962), train_loss = 0.85394468, grad/param norm = 3.3358e-01, time/batch = 19.3064s	
9235/11850 (epoch 38.966), train_loss = 0.80533050, grad/param norm = 3.1521e-01, time/batch = 16.3122s	
9236/11850 (epoch 38.970), train_loss = 0.94247384, grad/param norm = 2.9354e-01, time/batch = 17.8680s	
9237/11850 (epoch 38.975), train_loss = 0.88184930, grad/param norm = 2.9008e-01, time/batch = 15.6208s	
9238/11850 (epoch 38.979), train_loss = 0.92638849, grad/param norm = 3.5999e-01, time/batch = 18.9784s	
9239/11850 (epoch 38.983), train_loss = 0.99253531, grad/param norm = 5.1743e-01, time/batch = 15.5149s	
9240/11850 (epoch 38.987), train_loss = 0.85985457, grad/param norm = 3.9210e-01, time/batch = 17.2185s	
9241/11850 (epoch 38.992), train_loss = 1.01549550, grad/param norm = 3.0343e-01, time/batch = 17.3128s	
9242/11850 (epoch 38.996), train_loss = 1.01118825, grad/param norm = 3.6109e-01, time/batch = 17.4664s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
9243/11850 (epoch 39.000), train_loss = 0.87478436, grad/param norm = 3.0648e-01, time/batch = 17.3923s	
9244/11850 (epoch 39.004), train_loss = 0.94849429, grad/param norm = 3.1150e-01, time/batch = 16.2096s	
9245/11850 (epoch 39.008), train_loss = 0.99434229, grad/param norm = 3.2136e-01, time/batch = 18.5615s	
9246/11850 (epoch 39.013), train_loss = 1.00054392, grad/param norm = 3.0496e-01, time/batch = 17.5694s	
9247/11850 (epoch 39.017), train_loss = 1.02842165, grad/param norm = 3.2413e-01, time/batch = 18.1225s	
9248/11850 (epoch 39.021), train_loss = 0.99702771, grad/param norm = 2.9315e-01, time/batch = 16.7006s	
9249/11850 (epoch 39.025), train_loss = 0.85807649, grad/param norm = 2.6226e-01, time/batch = 16.7930s	
9250/11850 (epoch 39.030), train_loss = 0.88873707, grad/param norm = 2.9570e-01, time/batch = 16.7872s	
9251/11850 (epoch 39.034), train_loss = 0.87736719, grad/param norm = 2.8640e-01, time/batch = 18.8622s	
9252/11850 (epoch 39.038), train_loss = 0.88822674, grad/param norm = 2.8293e-01, time/batch = 19.4415s	
9253/11850 (epoch 39.042), train_loss = 0.92892537, grad/param norm = 3.4711e-01, time/batch = 17.8809s	
9254/11850 (epoch 39.046), train_loss = 0.88988563, grad/param norm = 3.8074e-01, time/batch = 19.6297s	
9255/11850 (epoch 39.051), train_loss = 0.90282265, grad/param norm = 2.8303e-01, time/batch = 15.9461s	
9256/11850 (epoch 39.055), train_loss = 0.85264210, grad/param norm = 2.5568e-01, time/batch = 17.9786s	
9257/11850 (epoch 39.059), train_loss = 0.95008748, grad/param norm = 2.9691e-01, time/batch = 15.4566s	
9258/11850 (epoch 39.063), train_loss = 0.98773557, grad/param norm = 3.2666e-01, time/batch = 18.1408s	
9259/11850 (epoch 39.068), train_loss = 0.90680765, grad/param norm = 3.0674e-01, time/batch = 17.2191s	
9260/11850 (epoch 39.072), train_loss = 0.95678774, grad/param norm = 2.9481e-01, time/batch = 17.4518s	
9261/11850 (epoch 39.076), train_loss = 1.03412672, grad/param norm = 3.0359e-01, time/batch = 16.8935s	
9262/11850 (epoch 39.080), train_loss = 0.83270296, grad/param norm = 2.5611e-01, time/batch = 17.8120s	
9263/11850 (epoch 39.084), train_loss = 0.81450566, grad/param norm = 2.9144e-01, time/batch = 18.2161s	
9264/11850 (epoch 39.089), train_loss = 0.79978913, grad/param norm = 2.4141e-01, time/batch = 15.4633s	
9265/11850 (epoch 39.093), train_loss = 0.82412057, grad/param norm = 3.0641e-01, time/batch = 16.7809s	
9266/11850 (epoch 39.097), train_loss = 0.90568980, grad/param norm = 2.9375e-01, time/batch = 18.2240s	
9267/11850 (epoch 39.101), train_loss = 0.82559534, grad/param norm = 3.1091e-01, time/batch = 17.6335s	
9268/11850 (epoch 39.105), train_loss = 0.80601085, grad/param norm = 2.6025e-01, time/batch = 17.4003s	
9269/11850 (epoch 39.110), train_loss = 0.96238309, grad/param norm = 2.9400e-01, time/batch = 17.9740s	
9270/11850 (epoch 39.114), train_loss = 0.83743261, grad/param norm = 2.6598e-01, time/batch = 17.8814s	
9271/11850 (epoch 39.118), train_loss = 0.96569399, grad/param norm = 2.7899e-01, time/batch = 18.0387s	
9272/11850 (epoch 39.122), train_loss = 1.00405699, grad/param norm = 2.9323e-01, time/batch = 17.6312s	
9273/11850 (epoch 39.127), train_loss = 0.95914549, grad/param norm = 3.3149e-01, time/batch = 15.9442s	
9274/11850 (epoch 39.131), train_loss = 0.90561850, grad/param norm = 3.4525e-01, time/batch = 14.8224s	
9275/11850 (epoch 39.135), train_loss = 0.91445762, grad/param norm = 3.4197e-01, time/batch = 18.3862s	
9276/11850 (epoch 39.139), train_loss = 0.90389868, grad/param norm = 2.8074e-01, time/batch = 16.5675s	
9277/11850 (epoch 39.143), train_loss = 0.87511625, grad/param norm = 2.9470e-01, time/batch = 16.1244s	
9278/11850 (epoch 39.148), train_loss = 0.87753249, grad/param norm = 3.0357e-01, time/batch = 16.7086s	
9279/11850 (epoch 39.152), train_loss = 0.96655519, grad/param norm = 3.1367e-01, time/batch = 18.4726s	
9280/11850 (epoch 39.156), train_loss = 0.85887882, grad/param norm = 3.1515e-01, time/batch = 17.3810s	
9281/11850 (epoch 39.160), train_loss = 1.05057069, grad/param norm = 3.5003e-01, time/batch = 18.0328s	
9282/11850 (epoch 39.165), train_loss = 0.99444218, grad/param norm = 3.6084e-01, time/batch = 16.6953s	
9283/11850 (epoch 39.169), train_loss = 0.88072464, grad/param norm = 3.2385e-01, time/batch = 18.2212s	
9284/11850 (epoch 39.173), train_loss = 0.97127420, grad/param norm = 3.4928e-01, time/batch = 18.1175s	
9285/11850 (epoch 39.177), train_loss = 0.82242472, grad/param norm = 3.2830e-01, time/batch = 15.2597s	
9286/11850 (epoch 39.181), train_loss = 0.91725937, grad/param norm = 3.4757e-01, time/batch = 14.8645s	
9287/11850 (epoch 39.186), train_loss = 1.01005326, grad/param norm = 3.7743e-01, time/batch = 15.2831s	
9288/11850 (epoch 39.190), train_loss = 0.95377857, grad/param norm = 3.3749e-01, time/batch = 14.8712s	
9289/11850 (epoch 39.194), train_loss = 0.96384794, grad/param norm = 4.3426e-01, time/batch = 14.6306s	
9290/11850 (epoch 39.198), train_loss = 0.77513647, grad/param norm = 4.2511e-01, time/batch = 14.1302s	
9291/11850 (epoch 39.203), train_loss = 0.78129953, grad/param norm = 2.8406e-01, time/batch = 15.3772s	
9292/11850 (epoch 39.207), train_loss = 0.94171952, grad/param norm = 3.6665e-01, time/batch = 16.2941s	
9293/11850 (epoch 39.211), train_loss = 0.87496036, grad/param norm = 3.0923e-01, time/batch = 18.1509s	
9294/11850 (epoch 39.215), train_loss = 0.93374654, grad/param norm = 3.5172e-01, time/batch = 18.4719s	
9295/11850 (epoch 39.219), train_loss = 0.93442585, grad/param norm = 2.9777e-01, time/batch = 17.7305s	
9296/11850 (epoch 39.224), train_loss = 1.04706131, grad/param norm = 3.1849e-01, time/batch = 15.0442s	
9297/11850 (epoch 39.228), train_loss = 0.94038548, grad/param norm = 3.0491e-01, time/batch = 16.0675s	
9298/11850 (epoch 39.232), train_loss = 0.92665649, grad/param norm = 3.1420e-01, time/batch = 16.0619s	
9299/11850 (epoch 39.236), train_loss = 0.85005014, grad/param norm = 3.4995e-01, time/batch = 14.7147s	
9300/11850 (epoch 39.241), train_loss = 0.96041161, grad/param norm = 3.3496e-01, time/batch = 15.9432s	
9301/11850 (epoch 39.245), train_loss = 0.96878566, grad/param norm = 2.8210e-01, time/batch = 17.8709s	
9302/11850 (epoch 39.249), train_loss = 0.90504458, grad/param norm = 2.8434e-01, time/batch = 17.8051s	
9303/11850 (epoch 39.253), train_loss = 0.90075499, grad/param norm = 3.2204e-01, time/batch = 16.7901s	
9304/11850 (epoch 39.257), train_loss = 1.03477337, grad/param norm = 3.3278e-01, time/batch = 17.7757s	
9305/11850 (epoch 39.262), train_loss = 1.04287528, grad/param norm = 3.8049e-01, time/batch = 18.8046s	
9306/11850 (epoch 39.266), train_loss = 1.00397700, grad/param norm = 3.1941e-01, time/batch = 17.8745s	
9307/11850 (epoch 39.270), train_loss = 0.89361358, grad/param norm = 2.5290e-01, time/batch = 18.1305s	
9308/11850 (epoch 39.274), train_loss = 0.90498163, grad/param norm = 3.7306e-01, time/batch = 17.2070s	
9309/11850 (epoch 39.278), train_loss = 0.80989513, grad/param norm = 3.1342e-01, time/batch = 19.0532s	
9310/11850 (epoch 39.283), train_loss = 0.89277010, grad/param norm = 2.5852e-01, time/batch = 17.5447s	
9311/11850 (epoch 39.287), train_loss = 1.01597990, grad/param norm = 3.0289e-01, time/batch = 17.5552s	
9312/11850 (epoch 39.291), train_loss = 0.89853632, grad/param norm = 2.9347e-01, time/batch = 18.7202s	
9313/11850 (epoch 39.295), train_loss = 0.94334504, grad/param norm = 2.9612e-01, time/batch = 17.0361s	
9314/11850 (epoch 39.300), train_loss = 0.87267493, grad/param norm = 3.1079e-01, time/batch = 18.6419s	
9315/11850 (epoch 39.304), train_loss = 0.91607022, grad/param norm = 2.7235e-01, time/batch = 18.1334s	
9316/11850 (epoch 39.308), train_loss = 0.91655815, grad/param norm = 2.9741e-01, time/batch = 17.8743s	
9317/11850 (epoch 39.312), train_loss = 0.80693949, grad/param norm = 2.7886e-01, time/batch = 16.8667s	
9318/11850 (epoch 39.316), train_loss = 0.92275062, grad/param norm = 2.6628e-01, time/batch = 14.7214s	
9319/11850 (epoch 39.321), train_loss = 0.87457149, grad/param norm = 2.8721e-01, time/batch = 17.3808s	
9320/11850 (epoch 39.325), train_loss = 0.91056648, grad/param norm = 2.6223e-01, time/batch = 17.3050s	
9321/11850 (epoch 39.329), train_loss = 0.90830208, grad/param norm = 3.3423e-01, time/batch = 16.8687s	
9322/11850 (epoch 39.333), train_loss = 0.88907685, grad/param norm = 2.8487e-01, time/batch = 16.8907s	
9323/11850 (epoch 39.338), train_loss = 0.86930861, grad/param norm = 2.5809e-01, time/batch = 17.7192s	
9324/11850 (epoch 39.342), train_loss = 0.89491118, grad/param norm = 2.8107e-01, time/batch = 14.2407s	
9325/11850 (epoch 39.346), train_loss = 0.88673868, grad/param norm = 3.3393e-01, time/batch = 18.2133s	
9326/11850 (epoch 39.350), train_loss = 0.79861435, grad/param norm = 2.8147e-01, time/batch = 17.8096s	
9327/11850 (epoch 39.354), train_loss = 0.94082447, grad/param norm = 2.5184e-01, time/batch = 17.2106s	
9328/11850 (epoch 39.359), train_loss = 1.02850544, grad/param norm = 2.8941e-01, time/batch = 18.3926s	
9329/11850 (epoch 39.363), train_loss = 0.92766196, grad/param norm = 2.7942e-01, time/batch = 17.2127s	
9330/11850 (epoch 39.367), train_loss = 0.97182075, grad/param norm = 2.7750e-01, time/batch = 17.2105s	
9331/11850 (epoch 39.371), train_loss = 0.95663288, grad/param norm = 2.8577e-01, time/batch = 17.8681s	
9332/11850 (epoch 39.376), train_loss = 0.90512106, grad/param norm = 2.6856e-01, time/batch = 17.0645s	
9333/11850 (epoch 39.380), train_loss = 0.87936587, grad/param norm = 2.7183e-01, time/batch = 15.3678s	
9334/11850 (epoch 39.384), train_loss = 0.82194735, grad/param norm = 2.9881e-01, time/batch = 17.2796s	
9335/11850 (epoch 39.388), train_loss = 0.96827359, grad/param norm = 3.0384e-01, time/batch = 16.5513s	
9336/11850 (epoch 39.392), train_loss = 0.93551987, grad/param norm = 2.9968e-01, time/batch = 18.3019s	
9337/11850 (epoch 39.397), train_loss = 0.94712422, grad/param norm = 2.8750e-01, time/batch = 16.3930s	
9338/11850 (epoch 39.401), train_loss = 0.79185966, grad/param norm = 2.6983e-01, time/batch = 18.2963s	
9339/11850 (epoch 39.405), train_loss = 0.82760381, grad/param norm = 2.9580e-01, time/batch = 17.8906s	
9340/11850 (epoch 39.409), train_loss = 0.94899392, grad/param norm = 2.9188e-01, time/batch = 15.3696s	
9341/11850 (epoch 39.414), train_loss = 0.75982672, grad/param norm = 2.6541e-01, time/batch = 16.5524s	
9342/11850 (epoch 39.418), train_loss = 0.79781690, grad/param norm = 2.9322e-01, time/batch = 18.3889s	
9343/11850 (epoch 39.422), train_loss = 0.74675800, grad/param norm = 2.7199e-01, time/batch = 17.7113s	
9344/11850 (epoch 39.426), train_loss = 0.75936568, grad/param norm = 3.0365e-01, time/batch = 16.8792s	
9345/11850 (epoch 39.430), train_loss = 0.81658208, grad/param norm = 3.1225e-01, time/batch = 18.1362s	
9346/11850 (epoch 39.435), train_loss = 0.82990292, grad/param norm = 3.0371e-01, time/batch = 15.9526s	
9347/11850 (epoch 39.439), train_loss = 0.93712523, grad/param norm = 2.9564e-01, time/batch = 18.2090s	
9348/11850 (epoch 39.443), train_loss = 0.87733109, grad/param norm = 2.8230e-01, time/batch = 16.2884s	
9349/11850 (epoch 39.447), train_loss = 0.79866562, grad/param norm = 2.7131e-01, time/batch = 17.4712s	
9350/11850 (epoch 39.451), train_loss = 0.78025110, grad/param norm = 2.5936e-01, time/batch = 17.7289s	
9351/11850 (epoch 39.456), train_loss = 0.87738827, grad/param norm = 2.8481e-01, time/batch = 17.0487s	
9352/11850 (epoch 39.460), train_loss = 0.92845666, grad/param norm = 2.8887e-01, time/batch = 15.7931s	
9353/11850 (epoch 39.464), train_loss = 0.84966765, grad/param norm = 3.3287e-01, time/batch = 16.4951s	
9354/11850 (epoch 39.468), train_loss = 0.92050863, grad/param norm = 2.8479e-01, time/batch = 19.2189s	
9355/11850 (epoch 39.473), train_loss = 0.96332168, grad/param norm = 3.0097e-01, time/batch = 17.8707s	
9356/11850 (epoch 39.477), train_loss = 0.79649493, grad/param norm = 2.5778e-01, time/batch = 17.1461s	
9357/11850 (epoch 39.481), train_loss = 0.82965528, grad/param norm = 2.6763e-01, time/batch = 17.8887s	
9358/11850 (epoch 39.485), train_loss = 0.79691372, grad/param norm = 2.5931e-01, time/batch = 16.5479s	
9359/11850 (epoch 39.489), train_loss = 0.90474892, grad/param norm = 2.7506e-01, time/batch = 19.2904s	
9360/11850 (epoch 39.494), train_loss = 0.80383387, grad/param norm = 3.0662e-01, time/batch = 17.2290s	
9361/11850 (epoch 39.498), train_loss = 0.79487785, grad/param norm = 2.5019e-01, time/batch = 16.8269s	
9362/11850 (epoch 39.502), train_loss = 0.79485870, grad/param norm = 3.3547e-01, time/batch = 14.9583s	
9363/11850 (epoch 39.506), train_loss = 1.03064468, grad/param norm = 3.0241e-01, time/batch = 18.8076s	
9364/11850 (epoch 39.511), train_loss = 0.87787255, grad/param norm = 2.5360e-01, time/batch = 17.6405s	
9365/11850 (epoch 39.515), train_loss = 0.96735543, grad/param norm = 3.4262e-01, time/batch = 16.1448s	
9366/11850 (epoch 39.519), train_loss = 0.84217625, grad/param norm = 2.9220e-01, time/batch = 15.6905s	
9367/11850 (epoch 39.523), train_loss = 0.89390032, grad/param norm = 2.9163e-01, time/batch = 17.1331s	
9368/11850 (epoch 39.527), train_loss = 0.82371881, grad/param norm = 2.6147e-01, time/batch = 17.9672s	
9369/11850 (epoch 39.532), train_loss = 0.90210451, grad/param norm = 2.9773e-01, time/batch = 16.7169s	
9370/11850 (epoch 39.536), train_loss = 0.85570288, grad/param norm = 2.8384e-01, time/batch = 18.6302s	
9371/11850 (epoch 39.540), train_loss = 0.81200649, grad/param norm = 3.8470e-01, time/batch = 18.7040s	
9372/11850 (epoch 39.544), train_loss = 0.80573388, grad/param norm = 3.4352e-01, time/batch = 17.0519s	
9373/11850 (epoch 39.549), train_loss = 0.74972091, grad/param norm = 2.4681e-01, time/batch = 18.3868s	
9374/11850 (epoch 39.553), train_loss = 0.88062466, grad/param norm = 2.8025e-01, time/batch = 16.9853s	
9375/11850 (epoch 39.557), train_loss = 0.93226770, grad/param norm = 3.8925e-01, time/batch = 17.4004s	
9376/11850 (epoch 39.561), train_loss = 0.94040054, grad/param norm = 3.5786e-01, time/batch = 17.9637s	
9377/11850 (epoch 39.565), train_loss = 0.99831404, grad/param norm = 3.1339e-01, time/batch = 19.0612s	
9378/11850 (epoch 39.570), train_loss = 0.91531103, grad/param norm = 2.8392e-01, time/batch = 18.2216s	
9379/11850 (epoch 39.574), train_loss = 0.92207899, grad/param norm = 2.9014e-01, time/batch = 18.6313s	
9380/11850 (epoch 39.578), train_loss = 0.96010606, grad/param norm = 3.3940e-01, time/batch = 17.7217s	
9381/11850 (epoch 39.582), train_loss = 0.86484259, grad/param norm = 3.2975e-01, time/batch = 18.8790s	
9382/11850 (epoch 39.586), train_loss = 0.87396630, grad/param norm = 3.0428e-01, time/batch = 16.1317s	
9383/11850 (epoch 39.591), train_loss = 0.92090250, grad/param norm = 3.7156e-01, time/batch = 18.2986s	
9384/11850 (epoch 39.595), train_loss = 0.76819677, grad/param norm = 2.6850e-01, time/batch = 16.8867s	
9385/11850 (epoch 39.599), train_loss = 0.87736807, grad/param norm = 2.9522e-01, time/batch = 16.7222s	
9386/11850 (epoch 39.603), train_loss = 0.83214408, grad/param norm = 2.6655e-01, time/batch = 16.2936s	
9387/11850 (epoch 39.608), train_loss = 1.01859632, grad/param norm = 3.3120e-01, time/batch = 15.7044s	
9388/11850 (epoch 39.612), train_loss = 1.06605513, grad/param norm = 3.3832e-01, time/batch = 18.8766s	
9389/11850 (epoch 39.616), train_loss = 0.99971647, grad/param norm = 3.2551e-01, time/batch = 16.9704s	
9390/11850 (epoch 39.620), train_loss = 0.87569690, grad/param norm = 2.7994e-01, time/batch = 18.5595s	
9391/11850 (epoch 39.624), train_loss = 0.88047448, grad/param norm = 3.5064e-01, time/batch = 16.7028s	
9392/11850 (epoch 39.629), train_loss = 0.87259106, grad/param norm = 2.8397e-01, time/batch = 16.6902s	
9393/11850 (epoch 39.633), train_loss = 0.79075171, grad/param norm = 2.7861e-01, time/batch = 19.1208s	
9394/11850 (epoch 39.637), train_loss = 0.72591108, grad/param norm = 2.7521e-01, time/batch = 17.8909s	
9395/11850 (epoch 39.641), train_loss = 0.77378245, grad/param norm = 2.5399e-01, time/batch = 17.6421s	
9396/11850 (epoch 39.646), train_loss = 0.80108224, grad/param norm = 2.6575e-01, time/batch = 15.3796s	
9397/11850 (epoch 39.650), train_loss = 0.87970769, grad/param norm = 3.1404e-01, time/batch = 17.2317s	
9398/11850 (epoch 39.654), train_loss = 0.81055141, grad/param norm = 2.9893e-01, time/batch = 19.4734s	
9399/11850 (epoch 39.658), train_loss = 0.91148928, grad/param norm = 2.7471e-01, time/batch = 24.5756s	
9400/11850 (epoch 39.662), train_loss = 0.76736002, grad/param norm = 3.1048e-01, time/batch = 21.3418s	
9401/11850 (epoch 39.667), train_loss = 0.96127480, grad/param norm = 2.8820e-01, time/batch = 19.6357s	
9402/11850 (epoch 39.671), train_loss = 0.85517482, grad/param norm = 3.0702e-01, time/batch = 17.6837s	
9403/11850 (epoch 39.675), train_loss = 0.86578243, grad/param norm = 3.4053e-01, time/batch = 17.5208s	
9404/11850 (epoch 39.679), train_loss = 0.87908512, grad/param norm = 2.7554e-01, time/batch = 17.7093s	
9405/11850 (epoch 39.684), train_loss = 0.85386431, grad/param norm = 3.1794e-01, time/batch = 16.6226s	
9406/11850 (epoch 39.688), train_loss = 0.80999456, grad/param norm = 2.9577e-01, time/batch = 18.3878s	
9407/11850 (epoch 39.692), train_loss = 0.83597580, grad/param norm = 3.5955e-01, time/batch = 17.8996s	
9408/11850 (epoch 39.696), train_loss = 0.81668930, grad/param norm = 4.0794e-01, time/batch = 18.2950s	
9409/11850 (epoch 39.700), train_loss = 0.87821079, grad/param norm = 2.9409e-01, time/batch = 18.4467s	
9410/11850 (epoch 39.705), train_loss = 0.79521984, grad/param norm = 2.7576e-01, time/batch = 15.1443s	
9411/11850 (epoch 39.709), train_loss = 0.74760660, grad/param norm = 2.8022e-01, time/batch = 18.1369s	
9412/11850 (epoch 39.713), train_loss = 0.75700729, grad/param norm = 2.9511e-01, time/batch = 15.5541s	
9413/11850 (epoch 39.717), train_loss = 0.81827485, grad/param norm = 2.6731e-01, time/batch = 18.6370s	
9414/11850 (epoch 39.722), train_loss = 0.85510666, grad/param norm = 3.1526e-01, time/batch = 18.1588s	
9415/11850 (epoch 39.726), train_loss = 0.79653396, grad/param norm = 3.0736e-01, time/batch = 16.7164s	
9416/11850 (epoch 39.730), train_loss = 0.78890375, grad/param norm = 2.9314e-01, time/batch = 17.2154s	
9417/11850 (epoch 39.734), train_loss = 0.77956261, grad/param norm = 2.8951e-01, time/batch = 17.4773s	
9418/11850 (epoch 39.738), train_loss = 0.91792446, grad/param norm = 3.8428e-01, time/batch = 18.4701s	
9419/11850 (epoch 39.743), train_loss = 0.87951117, grad/param norm = 3.1586e-01, time/batch = 16.7033s	
9420/11850 (epoch 39.747), train_loss = 0.77266879, grad/param norm = 2.8616e-01, time/batch = 17.7119s	
9421/11850 (epoch 39.751), train_loss = 0.83628158, grad/param norm = 2.9167e-01, time/batch = 18.7207s	
9422/11850 (epoch 39.755), train_loss = 0.87929264, grad/param norm = 2.5918e-01, time/batch = 16.4610s	
9423/11850 (epoch 39.759), train_loss = 0.80010251, grad/param norm = 2.6653e-01, time/batch = 17.7958s	
9424/11850 (epoch 39.764), train_loss = 0.84922308, grad/param norm = 2.7052e-01, time/batch = 18.4722s	
9425/11850 (epoch 39.768), train_loss = 0.78020130, grad/param norm = 2.6656e-01, time/batch = 17.9528s	
9426/11850 (epoch 39.772), train_loss = 0.82466219, grad/param norm = 2.8991e-01, time/batch = 16.8808s	
9427/11850 (epoch 39.776), train_loss = 0.87898082, grad/param norm = 2.6752e-01, time/batch = 19.5406s	
9428/11850 (epoch 39.781), train_loss = 0.82947013, grad/param norm = 2.7752e-01, time/batch = 17.3739s	
9429/11850 (epoch 39.785), train_loss = 0.85452392, grad/param norm = 3.1358e-01, time/batch = 16.0238s	
9430/11850 (epoch 39.789), train_loss = 0.83005639, grad/param norm = 2.6861e-01, time/batch = 19.2284s	
9431/11850 (epoch 39.793), train_loss = 0.89910664, grad/param norm = 2.9827e-01, time/batch = 19.0655s	
9432/11850 (epoch 39.797), train_loss = 0.84256252, grad/param norm = 3.1198e-01, time/batch = 16.1960s	
9433/11850 (epoch 39.802), train_loss = 0.78388710, grad/param norm = 2.8858e-01, time/batch = 15.9786s	
9434/11850 (epoch 39.806), train_loss = 0.84940456, grad/param norm = 2.7183e-01, time/batch = 17.3983s	
9435/11850 (epoch 39.810), train_loss = 0.92070723, grad/param norm = 3.9807e-01, time/batch = 18.6418s	
9436/11850 (epoch 39.814), train_loss = 0.86980312, grad/param norm = 2.7559e-01, time/batch = 17.7768s	
9437/11850 (epoch 39.819), train_loss = 0.97005612, grad/param norm = 3.1895e-01, time/batch = 15.4060s	
9438/11850 (epoch 39.823), train_loss = 0.97006863, grad/param norm = 3.2244e-01, time/batch = 16.3241s	
9439/11850 (epoch 39.827), train_loss = 0.86337576, grad/param norm = 3.2274e-01, time/batch = 17.1310s	
9440/11850 (epoch 39.831), train_loss = 0.82824772, grad/param norm = 3.1930e-01, time/batch = 15.3605s	
9441/11850 (epoch 39.835), train_loss = 0.90710021, grad/param norm = 3.4524e-01, time/batch = 18.5520s	
9442/11850 (epoch 39.840), train_loss = 0.83803693, grad/param norm = 3.1210e-01, time/batch = 18.8793s	
9443/11850 (epoch 39.844), train_loss = 0.87733671, grad/param norm = 2.6021e-01, time/batch = 19.1028s	
9444/11850 (epoch 39.848), train_loss = 0.89472479, grad/param norm = 3.0454e-01, time/batch = 16.8107s	
9445/11850 (epoch 39.852), train_loss = 0.87936604, grad/param norm = 2.9530e-01, time/batch = 19.6263s	
9446/11850 (epoch 39.857), train_loss = 0.85058873, grad/param norm = 3.3056e-01, time/batch = 17.2854s	
9447/11850 (epoch 39.861), train_loss = 0.80765426, grad/param norm = 3.3858e-01, time/batch = 18.6956s	
9448/11850 (epoch 39.865), train_loss = 0.89615681, grad/param norm = 3.2101e-01, time/batch = 18.1362s	
9449/11850 (epoch 39.869), train_loss = 0.87885158, grad/param norm = 2.9203e-01, time/batch = 17.3773s	
9450/11850 (epoch 39.873), train_loss = 0.89067047, grad/param norm = 3.1257e-01, time/batch = 18.1016s	
9451/11850 (epoch 39.878), train_loss = 0.89969560, grad/param norm = 3.0650e-01, time/batch = 14.9715s	
9452/11850 (epoch 39.882), train_loss = 0.89772951, grad/param norm = 3.3609e-01, time/batch = 17.7162s	
9453/11850 (epoch 39.886), train_loss = 0.85804930, grad/param norm = 3.7151e-01, time/batch = 17.6149s	
9454/11850 (epoch 39.890), train_loss = 0.88967924, grad/param norm = 3.4260e-01, time/batch = 16.9558s	
9455/11850 (epoch 39.895), train_loss = 0.89286847, grad/param norm = 4.3239e-01, time/batch = 16.8900s	
9456/11850 (epoch 39.899), train_loss = 0.79901113, grad/param norm = 2.8325e-01, time/batch = 17.1299s	
9457/11850 (epoch 39.903), train_loss = 0.81354929, grad/param norm = 2.9615e-01, time/batch = 18.6237s	
9458/11850 (epoch 39.907), train_loss = 0.83319699, grad/param norm = 2.9492e-01, time/batch = 19.3807s	
9459/11850 (epoch 39.911), train_loss = 0.96100869, grad/param norm = 3.0440e-01, time/batch = 16.8201s	
9460/11850 (epoch 39.916), train_loss = 0.92317200, grad/param norm = 3.4452e-01, time/batch = 19.5485s	
9461/11850 (epoch 39.920), train_loss = 0.90416805, grad/param norm = 3.1488e-01, time/batch = 17.2220s	
9462/11850 (epoch 39.924), train_loss = 0.84588310, grad/param norm = 3.4825e-01, time/batch = 18.3842s	
9463/11850 (epoch 39.928), train_loss = 0.92274442, grad/param norm = 4.6214e-01, time/batch = 17.2954s	
9464/11850 (epoch 39.932), train_loss = 0.98598377, grad/param norm = 3.4574e-01, time/batch = 16.6474s	
9465/11850 (epoch 39.937), train_loss = 0.95560478, grad/param norm = 2.7826e-01, time/batch = 19.7953s	
9466/11850 (epoch 39.941), train_loss = 0.91031883, grad/param norm = 3.2300e-01, time/batch = 13.7276s	
9467/11850 (epoch 39.945), train_loss = 0.91642903, grad/param norm = 3.5079e-01, time/batch = 0.6413s	
9468/11850 (epoch 39.949), train_loss = 0.83709307, grad/param norm = 4.3533e-01, time/batch = 0.6792s	
9469/11850 (epoch 39.954), train_loss = 0.91564201, grad/param norm = 3.3919e-01, time/batch = 0.6755s	
9470/11850 (epoch 39.958), train_loss = 0.92826687, grad/param norm = 3.1308e-01, time/batch = 0.6636s	
9471/11850 (epoch 39.962), train_loss = 0.83780771, grad/param norm = 3.4535e-01, time/batch = 0.6455s	
9472/11850 (epoch 39.966), train_loss = 0.80013554, grad/param norm = 3.2436e-01, time/batch = 0.6485s	
9473/11850 (epoch 39.970), train_loss = 0.92723289, grad/param norm = 2.9020e-01, time/batch = 0.6505s	
9474/11850 (epoch 39.975), train_loss = 0.86933220, grad/param norm = 3.5865e-01, time/batch = 0.8441s	
9475/11850 (epoch 39.979), train_loss = 0.91265754, grad/param norm = 4.1486e-01, time/batch = 0.9447s	
9476/11850 (epoch 39.983), train_loss = 0.99534494, grad/param norm = 5.3461e-01, time/batch = 0.9428s	
9477/11850 (epoch 39.987), train_loss = 0.84075317, grad/param norm = 3.5388e-01, time/batch = 0.9631s	
9478/11850 (epoch 39.992), train_loss = 0.99281327, grad/param norm = 3.2036e-01, time/batch = 0.9717s	
9479/11850 (epoch 39.996), train_loss = 0.99083974, grad/param norm = 3.1977e-01, time/batch = 1.2819s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
9480/11850 (epoch 40.000), train_loss = 0.87119142, grad/param norm = 3.8392e-01, time/batch = 1.7711s	
9481/11850 (epoch 40.004), train_loss = 0.94449420, grad/param norm = 3.6946e-01, time/batch = 1.7590s	
9482/11850 (epoch 40.008), train_loss = 0.99390618, grad/param norm = 3.5378e-01, time/batch = 12.4418s	
9483/11850 (epoch 40.013), train_loss = 0.99897087, grad/param norm = 3.2313e-01, time/batch = 17.4496s	
9484/11850 (epoch 40.017), train_loss = 1.01524064, grad/param norm = 3.6446e-01, time/batch = 15.6780s	
9485/11850 (epoch 40.021), train_loss = 0.99140865, grad/param norm = 3.1139e-01, time/batch = 16.2014s	
9486/11850 (epoch 40.025), train_loss = 0.85206616, grad/param norm = 2.5951e-01, time/batch = 16.9772s	
9487/11850 (epoch 40.030), train_loss = 0.88816476, grad/param norm = 3.4989e-01, time/batch = 18.7198s	
9488/11850 (epoch 40.034), train_loss = 0.86264085, grad/param norm = 2.9338e-01, time/batch = 16.9497s	
9489/11850 (epoch 40.038), train_loss = 0.88163457, grad/param norm = 2.9592e-01, time/batch = 17.0717s	
9490/11850 (epoch 40.042), train_loss = 0.91033853, grad/param norm = 3.2597e-01, time/batch = 18.8868s	
9491/11850 (epoch 40.046), train_loss = 0.89091222, grad/param norm = 3.6831e-01, time/batch = 16.6063s	
9492/11850 (epoch 40.051), train_loss = 0.88932064, grad/param norm = 2.7670e-01, time/batch = 18.2115s	
9493/11850 (epoch 40.055), train_loss = 0.85023298, grad/param norm = 2.6989e-01, time/batch = 15.4627s	
9494/11850 (epoch 40.059), train_loss = 0.93425159, grad/param norm = 2.8239e-01, time/batch = 18.7909s	
9495/11850 (epoch 40.063), train_loss = 0.99128661, grad/param norm = 3.3484e-01, time/batch = 17.5577s	
9496/11850 (epoch 40.068), train_loss = 0.89037702, grad/param norm = 2.9355e-01, time/batch = 18.0607s	
9497/11850 (epoch 40.072), train_loss = 0.95540000, grad/param norm = 2.9873e-01, time/batch = 19.1210s	
9498/11850 (epoch 40.076), train_loss = 1.01450283, grad/param norm = 3.2862e-01, time/batch = 16.2186s	
9499/11850 (epoch 40.080), train_loss = 0.82444747, grad/param norm = 2.7578e-01, time/batch = 17.2207s	
9500/11850 (epoch 40.084), train_loss = 0.79775936, grad/param norm = 2.9628e-01, time/batch = 16.0379s	
9501/11850 (epoch 40.089), train_loss = 0.80202507, grad/param norm = 2.6252e-01, time/batch = 17.8856s	
9502/11850 (epoch 40.093), train_loss = 0.81745606, grad/param norm = 3.2185e-01, time/batch = 15.2005s	
9503/11850 (epoch 40.097), train_loss = 0.90187831, grad/param norm = 3.0839e-01, time/batch = 17.8948s	
9504/11850 (epoch 40.101), train_loss = 0.82554160, grad/param norm = 3.2970e-01, time/batch = 17.8962s	
9505/11850 (epoch 40.105), train_loss = 0.80117123, grad/param norm = 2.7536e-01, time/batch = 15.1131s	
9506/11850 (epoch 40.110), train_loss = 0.94595939, grad/param norm = 3.0863e-01, time/batch = 19.4647s	
9507/11850 (epoch 40.114), train_loss = 0.82877106, grad/param norm = 2.8790e-01, time/batch = 17.2275s	
9508/11850 (epoch 40.118), train_loss = 0.94756171, grad/param norm = 2.8612e-01, time/batch = 17.9385s	
9509/11850 (epoch 40.122), train_loss = 0.98839968, grad/param norm = 2.8738e-01, time/batch = 17.7255s	
9510/11850 (epoch 40.127), train_loss = 0.92615151, grad/param norm = 3.0021e-01, time/batch = 18.3974s	
9511/11850 (epoch 40.131), train_loss = 0.90305786, grad/param norm = 3.3635e-01, time/batch = 18.2423s	
9512/11850 (epoch 40.135), train_loss = 0.89452453, grad/param norm = 3.0881e-01, time/batch = 16.4586s	
9513/11850 (epoch 40.139), train_loss = 0.87573178, grad/param norm = 2.9059e-01, time/batch = 18.3087s	
9514/11850 (epoch 40.143), train_loss = 0.85177634, grad/param norm = 2.7318e-01, time/batch = 18.1433s	
9515/11850 (epoch 40.148), train_loss = 0.86048488, grad/param norm = 2.9589e-01, time/batch = 16.2980s	
9516/11850 (epoch 40.152), train_loss = 0.95921696, grad/param norm = 3.0605e-01, time/batch = 17.4029s	
9517/11850 (epoch 40.156), train_loss = 0.84316171, grad/param norm = 3.5088e-01, time/batch = 16.9778s	
9518/11850 (epoch 40.160), train_loss = 1.04609499, grad/param norm = 4.0234e-01, time/batch = 16.2201s	
9519/11850 (epoch 40.165), train_loss = 0.97485244, grad/param norm = 3.9333e-01, time/batch = 17.7944s	
9520/11850 (epoch 40.169), train_loss = 0.88677951, grad/param norm = 3.6928e-01, time/batch = 16.9588s	
9521/11850 (epoch 40.173), train_loss = 0.96751585, grad/param norm = 4.2116e-01, time/batch = 18.2984s	
9522/11850 (epoch 40.177), train_loss = 0.79233802, grad/param norm = 3.2250e-01, time/batch = 14.9890s	
9523/11850 (epoch 40.181), train_loss = 0.89687607, grad/param norm = 3.1823e-01, time/batch = 16.5153s	
9524/11850 (epoch 40.186), train_loss = 0.98558892, grad/param norm = 3.5850e-01, time/batch = 17.3200s	
9525/11850 (epoch 40.190), train_loss = 0.92578989, grad/param norm = 2.9107e-01, time/batch = 18.4722s	
9526/11850 (epoch 40.194), train_loss = 0.94441899, grad/param norm = 4.3649e-01, time/batch = 17.2175s	
9527/11850 (epoch 40.198), train_loss = 0.75012411, grad/param norm = 3.6236e-01, time/batch = 16.4741s	
9528/11850 (epoch 40.203), train_loss = 0.77107333, grad/param norm = 3.6518e-01, time/batch = 18.6134s	
9529/11850 (epoch 40.207), train_loss = 0.93924966, grad/param norm = 3.7244e-01, time/batch = 16.0531s	
9530/11850 (epoch 40.211), train_loss = 0.87026591, grad/param norm = 3.2823e-01, time/batch = 18.3154s	
9531/11850 (epoch 40.215), train_loss = 0.93264102, grad/param norm = 3.7735e-01, time/batch = 18.1342s	
9532/11850 (epoch 40.219), train_loss = 0.92184554, grad/param norm = 3.0581e-01, time/batch = 17.6178s	
9533/11850 (epoch 40.224), train_loss = 1.04606628, grad/param norm = 3.4093e-01, time/batch = 16.9555s	
9534/11850 (epoch 40.228), train_loss = 0.93719451, grad/param norm = 3.1463e-01, time/batch = 17.5683s	
9535/11850 (epoch 40.232), train_loss = 0.91336645, grad/param norm = 3.4143e-01, time/batch = 17.8131s	
9536/11850 (epoch 40.236), train_loss = 0.85274375, grad/param norm = 3.2217e-01, time/batch = 16.7155s	
9537/11850 (epoch 40.241), train_loss = 0.95461736, grad/param norm = 3.9819e-01, time/batch = 16.0522s	
9538/11850 (epoch 40.245), train_loss = 0.96197690, grad/param norm = 2.8144e-01, time/batch = 18.8017s	
9539/11850 (epoch 40.249), train_loss = 0.89427502, grad/param norm = 2.8466e-01, time/batch = 17.0470s	
9540/11850 (epoch 40.253), train_loss = 0.88252500, grad/param norm = 3.1615e-01, time/batch = 16.3976s	
9541/11850 (epoch 40.257), train_loss = 1.00172728, grad/param norm = 3.2186e-01, time/batch = 14.8100s	
9542/11850 (epoch 40.262), train_loss = 1.02422221, grad/param norm = 3.2990e-01, time/batch = 19.3048s	
9543/11850 (epoch 40.266), train_loss = 1.01045819, grad/param norm = 3.9887e-01, time/batch = 17.3657s	
9544/11850 (epoch 40.270), train_loss = 0.90065099, grad/param norm = 3.1802e-01, time/batch = 17.7219s	
9545/11850 (epoch 40.274), train_loss = 0.90220085, grad/param norm = 3.5423e-01, time/batch = 15.3700s	
9546/11850 (epoch 40.278), train_loss = 0.78743434, grad/param norm = 3.0747e-01, time/batch = 16.8062s	
9547/11850 (epoch 40.283), train_loss = 0.89892354, grad/param norm = 3.2374e-01, time/batch = 15.6551s	
9548/11850 (epoch 40.287), train_loss = 1.01885629, grad/param norm = 3.1273e-01, time/batch = 17.3235s	
9549/11850 (epoch 40.291), train_loss = 0.88661306, grad/param norm = 3.1699e-01, time/batch = 18.2313s	
9550/11850 (epoch 40.295), train_loss = 0.94102067, grad/param norm = 2.9413e-01, time/batch = 16.2186s	
9551/11850 (epoch 40.300), train_loss = 0.86844714, grad/param norm = 3.4835e-01, time/batch = 17.5546s	
9552/11850 (epoch 40.304), train_loss = 0.90283302, grad/param norm = 2.6755e-01, time/batch = 17.1308s	
9553/11850 (epoch 40.308), train_loss = 0.89768897, grad/param norm = 2.7505e-01, time/batch = 14.8473s	
9554/11850 (epoch 40.312), train_loss = 0.78550209, grad/param norm = 2.7515e-01, time/batch = 16.7202s	
9555/11850 (epoch 40.316), train_loss = 0.90054408, grad/param norm = 2.8900e-01, time/batch = 17.2153s	
9556/11850 (epoch 40.321), train_loss = 0.85656174, grad/param norm = 2.7067e-01, time/batch = 17.1029s	
9557/11850 (epoch 40.325), train_loss = 0.90281156, grad/param norm = 3.0436e-01, time/batch = 17.1420s	
9558/11850 (epoch 40.329), train_loss = 0.89170678, grad/param norm = 2.9612e-01, time/batch = 18.2109s	
9559/11850 (epoch 40.333), train_loss = 0.87003234, grad/param norm = 3.0136e-01, time/batch = 18.0583s	
9560/11850 (epoch 40.338), train_loss = 0.87019492, grad/param norm = 2.8618e-01, time/batch = 17.1346s	
9561/11850 (epoch 40.342), train_loss = 0.88745175, grad/param norm = 2.8765e-01, time/batch = 18.3933s	
9562/11850 (epoch 40.346), train_loss = 0.86473925, grad/param norm = 2.9922e-01, time/batch = 18.2193s	
9563/11850 (epoch 40.350), train_loss = 0.78361723, grad/param norm = 2.6393e-01, time/batch = 19.2934s	
9564/11850 (epoch 40.354), train_loss = 0.93182102, grad/param norm = 2.7151e-01, time/batch = 17.4523s	
9565/11850 (epoch 40.359), train_loss = 1.01338638, grad/param norm = 3.0347e-01, time/batch = 18.8854s	
9566/11850 (epoch 40.363), train_loss = 0.91422738, grad/param norm = 2.6524e-01, time/batch = 17.2380s	
9567/11850 (epoch 40.367), train_loss = 0.95758333, grad/param norm = 2.8729e-01, time/batch = 15.3845s	
9568/11850 (epoch 40.371), train_loss = 0.94485614, grad/param norm = 2.7488e-01, time/batch = 17.5482s	
9569/11850 (epoch 40.376), train_loss = 0.89119077, grad/param norm = 2.6352e-01, time/batch = 17.6404s	
9570/11850 (epoch 40.380), train_loss = 0.85778378, grad/param norm = 2.5465e-01, time/batch = 15.9841s	
9571/11850 (epoch 40.384), train_loss = 0.80831977, grad/param norm = 2.7141e-01, time/batch = 17.0496s	
9572/11850 (epoch 40.388), train_loss = 0.95559869, grad/param norm = 2.9720e-01, time/batch = 18.2146s	
9573/11850 (epoch 40.392), train_loss = 0.91488384, grad/param norm = 2.9403e-01, time/batch = 16.8810s	
9574/11850 (epoch 40.397), train_loss = 0.93257338, grad/param norm = 2.6777e-01, time/batch = 17.0496s	
9575/11850 (epoch 40.401), train_loss = 0.77419136, grad/param norm = 2.3400e-01, time/batch = 17.6601s	
9576/11850 (epoch 40.405), train_loss = 0.81815171, grad/param norm = 3.1109e-01, time/batch = 17.2955s	
9577/11850 (epoch 40.409), train_loss = 0.92708507, grad/param norm = 2.9551e-01, time/batch = 15.1252s	
9578/11850 (epoch 40.414), train_loss = 0.74714361, grad/param norm = 2.5027e-01, time/batch = 17.4812s	
9579/11850 (epoch 40.418), train_loss = 0.78396128, grad/param norm = 2.6431e-01, time/batch = 18.7181s	
9580/11850 (epoch 40.422), train_loss = 0.72817753, grad/param norm = 2.5853e-01, time/batch = 16.3533s	
9581/11850 (epoch 40.426), train_loss = 0.74144572, grad/param norm = 2.6624e-01, time/batch = 16.2287s	
9582/11850 (epoch 40.430), train_loss = 0.80869858, grad/param norm = 2.9428e-01, time/batch = 17.8741s	
9583/11850 (epoch 40.435), train_loss = 0.83442852, grad/param norm = 2.7103e-01, time/batch = 18.4532s	
9584/11850 (epoch 40.439), train_loss = 0.92358302, grad/param norm = 2.7818e-01, time/batch = 17.6310s	
9585/11850 (epoch 40.443), train_loss = 0.87123282, grad/param norm = 3.1568e-01, time/batch = 17.5273s	
9586/11850 (epoch 40.447), train_loss = 0.80058520, grad/param norm = 2.7589e-01, time/batch = 14.7287s	
9587/11850 (epoch 40.451), train_loss = 0.77693158, grad/param norm = 3.1016e-01, time/batch = 16.3012s	
9588/11850 (epoch 40.456), train_loss = 0.88029281, grad/param norm = 3.6271e-01, time/batch = 16.5449s	
9589/11850 (epoch 40.460), train_loss = 0.91973536, grad/param norm = 2.7649e-01, time/batch = 15.8992s	
9590/11850 (epoch 40.464), train_loss = 0.84239325, grad/param norm = 3.0503e-01, time/batch = 16.5601s	
9591/11850 (epoch 40.468), train_loss = 0.91052322, grad/param norm = 2.9233e-01, time/batch = 17.9668s	
9592/11850 (epoch 40.473), train_loss = 0.94410605, grad/param norm = 2.9443e-01, time/batch = 16.2337s	
9593/11850 (epoch 40.477), train_loss = 0.79063446, grad/param norm = 2.8409e-01, time/batch = 18.4780s	
9594/11850 (epoch 40.481), train_loss = 0.82162278, grad/param norm = 2.8332e-01, time/batch = 18.5543s	
9595/11850 (epoch 40.485), train_loss = 0.78328214, grad/param norm = 2.5953e-01, time/batch = 17.7945s	
9596/11850 (epoch 40.489), train_loss = 0.89201904, grad/param norm = 2.9116e-01, time/batch = 18.8949s	
9597/11850 (epoch 40.494), train_loss = 0.77980335, grad/param norm = 2.5675e-01, time/batch = 16.1909s	
9598/11850 (epoch 40.498), train_loss = 0.79541185, grad/param norm = 2.9333e-01, time/batch = 17.4571s	
9599/11850 (epoch 40.502), train_loss = 0.76594732, grad/param norm = 3.0754e-01, time/batch = 19.3718s	
9600/11850 (epoch 40.506), train_loss = 0.99878923, grad/param norm = 2.7837e-01, time/batch = 18.0584s	
9601/11850 (epoch 40.511), train_loss = 0.86576369, grad/param norm = 2.7721e-01, time/batch = 17.5595s	
9602/11850 (epoch 40.515), train_loss = 0.96735698, grad/param norm = 3.3148e-01, time/batch = 16.7880s	
9603/11850 (epoch 40.519), train_loss = 0.82170879, grad/param norm = 3.1079e-01, time/batch = 16.5571s	
9604/11850 (epoch 40.523), train_loss = 0.87194569, grad/param norm = 2.9050e-01, time/batch = 17.1439s	
9605/11850 (epoch 40.527), train_loss = 0.80496624, grad/param norm = 2.6195e-01, time/batch = 15.6030s	
9606/11850 (epoch 40.532), train_loss = 0.88212529, grad/param norm = 2.9346e-01, time/batch = 16.1402s	
9607/11850 (epoch 40.536), train_loss = 0.82845292, grad/param norm = 2.7457e-01, time/batch = 18.3023s	
9608/11850 (epoch 40.540), train_loss = 0.77502891, grad/param norm = 2.5614e-01, time/batch = 17.0271s	
9609/11850 (epoch 40.544), train_loss = 0.80214728, grad/param norm = 3.0637e-01, time/batch = 17.0911s	
9610/11850 (epoch 40.549), train_loss = 0.74573396, grad/param norm = 2.5090e-01, time/batch = 16.7329s	
9611/11850 (epoch 40.553), train_loss = 0.87762620, grad/param norm = 3.3580e-01, time/batch = 19.3698s	
9612/11850 (epoch 40.557), train_loss = 0.92905989, grad/param norm = 4.2267e-01, time/batch = 17.4672s	
9613/11850 (epoch 40.561), train_loss = 0.94103875, grad/param norm = 3.7384e-01, time/batch = 17.6356s	
9614/11850 (epoch 40.565), train_loss = 1.01262660, grad/param norm = 3.6687e-01, time/batch = 19.0454s	
9615/11850 (epoch 40.570), train_loss = 0.91662499, grad/param norm = 2.8940e-01, time/batch = 17.4540s	
9616/11850 (epoch 40.574), train_loss = 0.91734390, grad/param norm = 2.9622e-01, time/batch = 16.9724s	
9617/11850 (epoch 40.578), train_loss = 0.94966836, grad/param norm = 3.3499e-01, time/batch = 17.2345s	
9618/11850 (epoch 40.582), train_loss = 0.85154544, grad/param norm = 3.1091e-01, time/batch = 18.8947s	
9619/11850 (epoch 40.586), train_loss = 0.85622550, grad/param norm = 2.8552e-01, time/batch = 29.9746s	
9620/11850 (epoch 40.591), train_loss = 0.89356069, grad/param norm = 3.4284e-01, time/batch = 17.5499s	
9621/11850 (epoch 40.595), train_loss = 0.74809999, grad/param norm = 2.6164e-01, time/batch = 17.2879s	
9622/11850 (epoch 40.599), train_loss = 0.86232238, grad/param norm = 2.8961e-01, time/batch = 15.8575s	
9623/11850 (epoch 40.603), train_loss = 0.81651238, grad/param norm = 2.5684e-01, time/batch = 16.9772s	
9624/11850 (epoch 40.608), train_loss = 0.99185822, grad/param norm = 2.9561e-01, time/batch = 17.7048s	
9625/11850 (epoch 40.612), train_loss = 1.05570280, grad/param norm = 3.3483e-01, time/batch = 17.1312s	
9626/11850 (epoch 40.616), train_loss = 0.98709810, grad/param norm = 3.3577e-01, time/batch = 17.9652s	
9627/11850 (epoch 40.620), train_loss = 0.85836592, grad/param norm = 2.8212e-01, time/batch = 18.3064s	
9628/11850 (epoch 40.624), train_loss = 0.86456437, grad/param norm = 3.4634e-01, time/batch = 18.5474s	
9629/11850 (epoch 40.629), train_loss = 0.85287441, grad/param norm = 2.7597e-01, time/batch = 19.3627s	
9630/11850 (epoch 40.633), train_loss = 0.77864830, grad/param norm = 2.6081e-01, time/batch = 17.9636s	
9631/11850 (epoch 40.637), train_loss = 0.71583154, grad/param norm = 2.6815e-01, time/batch = 17.9659s	
9632/11850 (epoch 40.641), train_loss = 0.75731415, grad/param norm = 2.5854e-01, time/batch = 17.8033s	
9633/11850 (epoch 40.646), train_loss = 0.78058953, grad/param norm = 3.0689e-01, time/batch = 16.0829s	
9634/11850 (epoch 40.650), train_loss = 0.87808781, grad/param norm = 3.3813e-01, time/batch = 17.6361s	
9635/11850 (epoch 40.654), train_loss = 0.79954959, grad/param norm = 2.8866e-01, time/batch = 17.7077s	
9636/11850 (epoch 40.658), train_loss = 0.90140769, grad/param norm = 2.9636e-01, time/batch = 17.3064s	
9637/11850 (epoch 40.662), train_loss = 0.76660656, grad/param norm = 3.4516e-01, time/batch = 17.5634s	
9638/11850 (epoch 40.667), train_loss = 0.94638313, grad/param norm = 3.0505e-01, time/batch = 16.5572s	
9639/11850 (epoch 40.671), train_loss = 0.82625880, grad/param norm = 2.8436e-01, time/batch = 16.7938s	
9640/11850 (epoch 40.675), train_loss = 0.84242472, grad/param norm = 2.9135e-01, time/batch = 15.5181s	
9641/11850 (epoch 40.679), train_loss = 0.86032555, grad/param norm = 2.7096e-01, time/batch = 18.5515s	
9642/11850 (epoch 40.684), train_loss = 0.83273063, grad/param norm = 3.2786e-01, time/batch = 17.7112s	
9643/11850 (epoch 40.688), train_loss = 0.80961571, grad/param norm = 3.1418e-01, time/batch = 18.3001s	
9644/11850 (epoch 40.692), train_loss = 0.82252845, grad/param norm = 3.5212e-01, time/batch = 18.2294s	
9645/11850 (epoch 40.696), train_loss = 0.78407239, grad/param norm = 3.4245e-01, time/batch = 17.0394s	
9646/11850 (epoch 40.700), train_loss = 0.86770716, grad/param norm = 3.0519e-01, time/batch = 17.5438s	
9647/11850 (epoch 40.705), train_loss = 0.77442913, grad/param norm = 2.6237e-01, time/batch = 17.9463s	
9648/11850 (epoch 40.709), train_loss = 0.74553925, grad/param norm = 2.7835e-01, time/batch = 19.3808s	
9649/11850 (epoch 40.713), train_loss = 0.74896628, grad/param norm = 3.2795e-01, time/batch = 17.3703s	
9650/11850 (epoch 40.717), train_loss = 0.80675202, grad/param norm = 2.5526e-01, time/batch = 17.8793s	
9651/11850 (epoch 40.722), train_loss = 0.85147629, grad/param norm = 3.3189e-01, time/batch = 19.4531s	
9652/11850 (epoch 40.726), train_loss = 0.78499732, grad/param norm = 3.1373e-01, time/batch = 16.1158s	
9653/11850 (epoch 40.730), train_loss = 0.78698566, grad/param norm = 2.8901e-01, time/batch = 17.8081s	
9654/11850 (epoch 40.734), train_loss = 0.76910481, grad/param norm = 2.8130e-01, time/batch = 17.8761s	
9655/11850 (epoch 40.738), train_loss = 0.90617820, grad/param norm = 3.6756e-01, time/batch = 17.9567s	
9656/11850 (epoch 40.743), train_loss = 0.85055587, grad/param norm = 3.1146e-01, time/batch = 16.4681s	
9657/11850 (epoch 40.747), train_loss = 0.76055703, grad/param norm = 2.8240e-01, time/batch = 18.4645s	
9658/11850 (epoch 40.751), train_loss = 0.82153465, grad/param norm = 2.7144e-01, time/batch = 18.7160s	
9659/11850 (epoch 40.755), train_loss = 0.86891377, grad/param norm = 2.7416e-01, time/batch = 18.4587s	
9660/11850 (epoch 40.759), train_loss = 0.77808359, grad/param norm = 2.4086e-01, time/batch = 17.5454s	
9661/11850 (epoch 40.764), train_loss = 0.83251608, grad/param norm = 2.5888e-01, time/batch = 19.0445s	
9662/11850 (epoch 40.768), train_loss = 0.75976532, grad/param norm = 2.6711e-01, time/batch = 15.6416s	
9663/11850 (epoch 40.772), train_loss = 0.82666080, grad/param norm = 4.0279e-01, time/batch = 17.7891s	
9664/11850 (epoch 40.776), train_loss = 0.86941609, grad/param norm = 3.2299e-01, time/batch = 16.5155s	
9665/11850 (epoch 40.781), train_loss = 0.81706949, grad/param norm = 2.4702e-01, time/batch = 17.2272s	
9666/11850 (epoch 40.785), train_loss = 0.85086113, grad/param norm = 3.0611e-01, time/batch = 17.3815s	
9667/11850 (epoch 40.789), train_loss = 0.81026369, grad/param norm = 2.7223e-01, time/batch = 17.2268s	
9668/11850 (epoch 40.793), train_loss = 0.87541780, grad/param norm = 3.1752e-01, time/batch = 18.8841s	
9669/11850 (epoch 40.797), train_loss = 0.84569781, grad/param norm = 3.1630e-01, time/batch = 15.8654s	
9670/11850 (epoch 40.802), train_loss = 0.77371823, grad/param norm = 2.8294e-01, time/batch = 17.8104s	
9671/11850 (epoch 40.806), train_loss = 0.84301150, grad/param norm = 3.0275e-01, time/batch = 17.3005s	
9672/11850 (epoch 40.810), train_loss = 0.88417575, grad/param norm = 3.1466e-01, time/batch = 15.8035s	
9673/11850 (epoch 40.814), train_loss = 0.87152384, grad/param norm = 3.3133e-01, time/batch = 16.7696s	
9674/11850 (epoch 40.819), train_loss = 0.95173042, grad/param norm = 3.4038e-01, time/batch = 17.1241s	
9675/11850 (epoch 40.823), train_loss = 0.95159798, grad/param norm = 3.0804e-01, time/batch = 16.6515s	
9676/11850 (epoch 40.827), train_loss = 0.84415059, grad/param norm = 3.5791e-01, time/batch = 16.1246s	
9677/11850 (epoch 40.831), train_loss = 0.80604250, grad/param norm = 3.0460e-01, time/batch = 18.8051s	
9678/11850 (epoch 40.835), train_loss = 0.89354814, grad/param norm = 2.9831e-01, time/batch = 18.6494s	
9679/11850 (epoch 40.840), train_loss = 0.81076261, grad/param norm = 3.0060e-01, time/batch = 17.2243s	
9680/11850 (epoch 40.844), train_loss = 0.85663040, grad/param norm = 2.5649e-01, time/batch = 19.0377s	
9681/11850 (epoch 40.848), train_loss = 0.88643380, grad/param norm = 2.7628e-01, time/batch = 15.9912s	
9682/11850 (epoch 40.852), train_loss = 0.87357087, grad/param norm = 3.1538e-01, time/batch = 14.3138s	
9683/11850 (epoch 40.857), train_loss = 0.84016180, grad/param norm = 3.2271e-01, time/batch = 14.4699s	
9684/11850 (epoch 40.861), train_loss = 0.78919976, grad/param norm = 3.4498e-01, time/batch = 14.2258s	
9685/11850 (epoch 40.865), train_loss = 0.89564415, grad/param norm = 3.3826e-01, time/batch = 16.5623s	
9686/11850 (epoch 40.869), train_loss = 0.86928381, grad/param norm = 2.8383e-01, time/batch = 18.2968s	
9687/11850 (epoch 40.873), train_loss = 0.87237700, grad/param norm = 3.0226e-01, time/batch = 16.4459s	
9688/11850 (epoch 40.878), train_loss = 0.88777386, grad/param norm = 3.0391e-01, time/batch = 17.3045s	
9689/11850 (epoch 40.882), train_loss = 0.87897643, grad/param norm = 3.0855e-01, time/batch = 17.9633s	
9690/11850 (epoch 40.886), train_loss = 0.82556755, grad/param norm = 2.9791e-01, time/batch = 16.3882s	
9691/11850 (epoch 40.890), train_loss = 0.86575979, grad/param norm = 3.1550e-01, time/batch = 17.0371s	
9692/11850 (epoch 40.895), train_loss = 0.86598798, grad/param norm = 3.3829e-01, time/batch = 18.6317s	
9693/11850 (epoch 40.899), train_loss = 0.76602153, grad/param norm = 2.6833e-01, time/batch = 15.1053s	
9694/11850 (epoch 40.903), train_loss = 0.79313624, grad/param norm = 2.7972e-01, time/batch = 16.6178s	
9695/11850 (epoch 40.907), train_loss = 0.81961707, grad/param norm = 3.2047e-01, time/batch = 17.2302s	
9696/11850 (epoch 40.911), train_loss = 0.93864724, grad/param norm = 3.0206e-01, time/batch = 18.7931s	
9697/11850 (epoch 40.916), train_loss = 0.90336915, grad/param norm = 3.5408e-01, time/batch = 17.6310s	
9698/11850 (epoch 40.920), train_loss = 0.87028935, grad/param norm = 2.8347e-01, time/batch = 18.2158s	
9699/11850 (epoch 40.924), train_loss = 0.82497538, grad/param norm = 2.9252e-01, time/batch = 17.5566s	
9700/11850 (epoch 40.928), train_loss = 0.88538163, grad/param norm = 2.7687e-01, time/batch = 18.1232s	
9701/11850 (epoch 40.932), train_loss = 0.98800004, grad/param norm = 4.4431e-01, time/batch = 18.2726s	
9702/11850 (epoch 40.937), train_loss = 0.93963291, grad/param norm = 2.7067e-01, time/batch = 15.8046s	
9703/11850 (epoch 40.941), train_loss = 0.88480069, grad/param norm = 2.8915e-01, time/batch = 18.9685s	
9704/11850 (epoch 40.945), train_loss = 0.90804554, grad/param norm = 2.9149e-01, time/batch = 17.3801s	
9705/11850 (epoch 40.949), train_loss = 0.83430715, grad/param norm = 4.2575e-01, time/batch = 17.6354s	
9706/11850 (epoch 40.954), train_loss = 0.91723790, grad/param norm = 3.1844e-01, time/batch = 16.9681s	
9707/11850 (epoch 40.958), train_loss = 0.92206245, grad/param norm = 3.4941e-01, time/batch = 18.0518s	
9708/11850 (epoch 40.962), train_loss = 0.81477297, grad/param norm = 3.2529e-01, time/batch = 16.3059s	
9709/11850 (epoch 40.966), train_loss = 0.77369481, grad/param norm = 2.8288e-01, time/batch = 17.8059s	
9710/11850 (epoch 40.970), train_loss = 0.91082733, grad/param norm = 3.1823e-01, time/batch = 16.0168s	
9711/11850 (epoch 40.975), train_loss = 0.84476732, grad/param norm = 2.9941e-01, time/batch = 16.6185s	
9712/11850 (epoch 40.979), train_loss = 0.90176807, grad/param norm = 3.6232e-01, time/batch = 18.1443s	
9713/11850 (epoch 40.983), train_loss = 0.96365850, grad/param norm = 1.7233e+00, time/batch = 17.5604s	
9714/11850 (epoch 40.987), train_loss = 0.85423667, grad/param norm = 4.2330e-01, time/batch = 17.6472s	
9715/11850 (epoch 40.992), train_loss = 1.00911839, grad/param norm = 3.4938e-01, time/batch = 18.1388s	
9716/11850 (epoch 40.996), train_loss = 0.99203094, grad/param norm = 3.4151e-01, time/batch = 18.2182s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
9717/11850 (epoch 41.000), train_loss = 0.86866726, grad/param norm = 3.3385e-01, time/batch = 18.2801s	
9718/11850 (epoch 41.004), train_loss = 0.92579289, grad/param norm = 3.3695e-01, time/batch = 17.6391s	
9719/11850 (epoch 41.008), train_loss = 0.96606409, grad/param norm = 3.0818e-01, time/batch = 19.0497s	
9720/11850 (epoch 41.013), train_loss = 0.98423790, grad/param norm = 3.0617e-01, time/batch = 15.3793s	
9721/11850 (epoch 41.017), train_loss = 1.02153929, grad/param norm = 3.5566e-01, time/batch = 16.6086s	
9722/11850 (epoch 41.021), train_loss = 0.96762328, grad/param norm = 2.9281e-01, time/batch = 16.7278s	
9723/11850 (epoch 41.025), train_loss = 0.83105035, grad/param norm = 2.6779e-01, time/batch = 18.2162s	
9724/11850 (epoch 41.030), train_loss = 0.87110518, grad/param norm = 3.1009e-01, time/batch = 18.3618s	
9725/11850 (epoch 41.034), train_loss = 0.85617568, grad/param norm = 2.9438e-01, time/batch = 15.4622s	
9726/11850 (epoch 41.038), train_loss = 0.86551391, grad/param norm = 2.9344e-01, time/batch = 18.0276s	
9727/11850 (epoch 41.042), train_loss = 0.90677115, grad/param norm = 3.0669e-01, time/batch = 18.3867s	
9728/11850 (epoch 41.046), train_loss = 0.87300335, grad/param norm = 3.9827e-01, time/batch = 17.1883s	
9729/11850 (epoch 41.051), train_loss = 0.89081071, grad/param norm = 3.1325e-01, time/batch = 18.0299s	
9730/11850 (epoch 41.055), train_loss = 0.83581351, grad/param norm = 2.8270e-01, time/batch = 19.3051s	
9731/11850 (epoch 41.059), train_loss = 0.93877837, grad/param norm = 3.3216e-01, time/batch = 15.8170s	
9732/11850 (epoch 41.063), train_loss = 0.98885773, grad/param norm = 3.4676e-01, time/batch = 17.8076s	
9733/11850 (epoch 41.068), train_loss = 0.87979247, grad/param norm = 2.8834e-01, time/batch = 18.1351s	
9734/11850 (epoch 41.072), train_loss = 0.93836881, grad/param norm = 3.4347e-01, time/batch = 17.7984s	
9735/11850 (epoch 41.076), train_loss = 1.00465542, grad/param norm = 3.2006e-01, time/batch = 17.4571s	
9736/11850 (epoch 41.080), train_loss = 0.81611998, grad/param norm = 2.8603e-01, time/batch = 17.7382s	
9737/11850 (epoch 41.084), train_loss = 0.79440951, grad/param norm = 2.8698e-01, time/batch = 17.9670s	
9738/11850 (epoch 41.089), train_loss = 0.78884953, grad/param norm = 2.8658e-01, time/batch = 16.2809s	
9739/11850 (epoch 41.093), train_loss = 0.81161613, grad/param norm = 3.6416e-01, time/batch = 18.4738s	
9740/11850 (epoch 41.097), train_loss = 0.88147322, grad/param norm = 3.0506e-01, time/batch = 16.4890s	
9741/11850 (epoch 41.101), train_loss = 0.80096257, grad/param norm = 3.1600e-01, time/batch = 15.1214s	
9742/11850 (epoch 41.105), train_loss = 0.80269000, grad/param norm = 2.7348e-01, time/batch = 16.7969s	
9743/11850 (epoch 41.110), train_loss = 0.94826933, grad/param norm = 2.8830e-01, time/batch = 14.4518s	
9744/11850 (epoch 41.114), train_loss = 0.82930668, grad/param norm = 2.9877e-01, time/batch = 17.5453s	
9745/11850 (epoch 41.118), train_loss = 0.92703440, grad/param norm = 2.7516e-01, time/batch = 17.5442s	
9746/11850 (epoch 41.122), train_loss = 0.98257231, grad/param norm = 2.9211e-01, time/batch = 18.5540s	
9747/11850 (epoch 41.127), train_loss = 0.93751681, grad/param norm = 3.4852e-01, time/batch = 18.5486s	
9748/11850 (epoch 41.131), train_loss = 0.87948375, grad/param norm = 3.2713e-01, time/batch = 17.2141s	
9749/11850 (epoch 41.135), train_loss = 0.88371300, grad/param norm = 3.0686e-01, time/batch = 18.2280s	
9750/11850 (epoch 41.139), train_loss = 0.86077330, grad/param norm = 2.8468e-01, time/batch = 16.0664s	
9751/11850 (epoch 41.143), train_loss = 0.86041936, grad/param norm = 3.4528e-01, time/batch = 18.3906s	
9752/11850 (epoch 41.148), train_loss = 0.86017592, grad/param norm = 3.4135e-01, time/batch = 17.6282s	
9753/11850 (epoch 41.152), train_loss = 0.95623690, grad/param norm = 3.3980e-01, time/batch = 16.7976s	
9754/11850 (epoch 41.156), train_loss = 0.83632571, grad/param norm = 3.4166e-01, time/batch = 18.2299s	
9755/11850 (epoch 41.160), train_loss = 1.03267736, grad/param norm = 3.5624e-01, time/batch = 17.4360s	
9756/11850 (epoch 41.165), train_loss = 0.96560944, grad/param norm = 4.3157e-01, time/batch = 17.3064s	
9757/11850 (epoch 41.169), train_loss = 0.87084533, grad/param norm = 3.7545e-01, time/batch = 16.6328s	
9758/11850 (epoch 41.173), train_loss = 0.94671967, grad/param norm = 3.2465e-01, time/batch = 19.3027s	
9759/11850 (epoch 41.177), train_loss = 0.80746830, grad/param norm = 3.8893e-01, time/batch = 17.7999s	
9760/11850 (epoch 41.181), train_loss = 0.88946721, grad/param norm = 2.9231e-01, time/batch = 17.0638s	
9761/11850 (epoch 41.186), train_loss = 0.97047314, grad/param norm = 3.4071e-01, time/batch = 17.6265s	
9762/11850 (epoch 41.190), train_loss = 0.91636325, grad/param norm = 3.1501e-01, time/batch = 16.8928s	
9763/11850 (epoch 41.194), train_loss = 0.91585175, grad/param norm = 3.8885e-01, time/batch = 18.7871s	
9764/11850 (epoch 41.198), train_loss = 0.73712935, grad/param norm = 2.8789e-01, time/batch = 16.9476s	
9765/11850 (epoch 41.203), train_loss = 0.76510595, grad/param norm = 3.0808e-01, time/batch = 17.7939s	
9766/11850 (epoch 41.207), train_loss = 0.91766082, grad/param norm = 3.7111e-01, time/batch = 17.2874s	
9767/11850 (epoch 41.211), train_loss = 0.85402423, grad/param norm = 2.9587e-01, time/batch = 16.1200s	
9768/11850 (epoch 41.215), train_loss = 0.90649964, grad/param norm = 3.1094e-01, time/batch = 17.8729s	
9769/11850 (epoch 41.219), train_loss = 0.91539414, grad/param norm = 3.0275e-01, time/batch = 16.2950s	
9770/11850 (epoch 41.224), train_loss = 1.01855417, grad/param norm = 3.3019e-01, time/batch = 19.1374s	
9771/11850 (epoch 41.228), train_loss = 0.91873244, grad/param norm = 2.9846e-01, time/batch = 18.7131s	
9772/11850 (epoch 41.232), train_loss = 0.90565080, grad/param norm = 3.2243e-01, time/batch = 17.8644s	
9773/11850 (epoch 41.236), train_loss = 0.83908812, grad/param norm = 3.6800e-01, time/batch = 16.5610s	
9774/11850 (epoch 41.241), train_loss = 0.93777537, grad/param norm = 3.3516e-01, time/batch = 16.7362s	
9775/11850 (epoch 41.245), train_loss = 0.93661795, grad/param norm = 3.0920e-01, time/batch = 18.8833s	
9776/11850 (epoch 41.249), train_loss = 0.88654513, grad/param norm = 2.7884e-01, time/batch = 15.1785s	
9777/11850 (epoch 41.253), train_loss = 0.87986755, grad/param norm = 3.3950e-01, time/batch = 16.3743s	
9778/11850 (epoch 41.257), train_loss = 1.00522273, grad/param norm = 3.3842e-01, time/batch = 16.3809s	
9779/11850 (epoch 41.262), train_loss = 0.99645320, grad/param norm = 3.3253e-01, time/batch = 15.6393s	
9780/11850 (epoch 41.266), train_loss = 0.99461126, grad/param norm = 3.6895e-01, time/batch = 16.8219s	
9781/11850 (epoch 41.270), train_loss = 0.87570287, grad/param norm = 2.6873e-01, time/batch = 17.4009s	
9782/11850 (epoch 41.274), train_loss = 0.86989966, grad/param norm = 3.0945e-01, time/batch = 18.3867s	
9783/11850 (epoch 41.278), train_loss = 0.77481279, grad/param norm = 3.0854e-01, time/batch = 16.2915s	
9784/11850 (epoch 41.283), train_loss = 0.87096692, grad/param norm = 2.4801e-01, time/batch = 17.0353s	
9785/11850 (epoch 41.287), train_loss = 1.00552675, grad/param norm = 3.3797e-01, time/batch = 18.2110s	
9786/11850 (epoch 41.291), train_loss = 0.86759302, grad/param norm = 2.9782e-01, time/batch = 17.1306s	
9787/11850 (epoch 41.295), train_loss = 0.92959235, grad/param norm = 2.8843e-01, time/batch = 17.1330s	
9788/11850 (epoch 41.300), train_loss = 0.85222697, grad/param norm = 3.9261e-01, time/batch = 17.6531s	
9789/11850 (epoch 41.304), train_loss = 0.88193521, grad/param norm = 2.6065e-01, time/batch = 17.3070s	
9790/11850 (epoch 41.308), train_loss = 0.88175916, grad/param norm = 2.8645e-01, time/batch = 16.7725s	
9791/11850 (epoch 41.312), train_loss = 0.79218870, grad/param norm = 2.9344e-01, time/batch = 17.1204s	
9792/11850 (epoch 41.316), train_loss = 0.89011478, grad/param norm = 2.6183e-01, time/batch = 16.1365s	
9793/11850 (epoch 41.321), train_loss = 0.84748946, grad/param norm = 2.6645e-01, time/batch = 17.0376s	
9794/11850 (epoch 41.325), train_loss = 0.89791246, grad/param norm = 3.3652e-01, time/batch = 17.2925s	
9795/11850 (epoch 41.329), train_loss = 0.88773925, grad/param norm = 3.2226e-01, time/batch = 16.6988s	
9796/11850 (epoch 41.333), train_loss = 0.86477463, grad/param norm = 2.9114e-01, time/batch = 17.7088s	
9797/11850 (epoch 41.338), train_loss = 0.86068060, grad/param norm = 2.9143e-01, time/batch = 18.3703s	
9798/11850 (epoch 41.342), train_loss = 0.88039368, grad/param norm = 3.0661e-01, time/batch = 18.7161s	
9799/11850 (epoch 41.346), train_loss = 0.86245697, grad/param norm = 2.8733e-01, time/batch = 17.8748s	
9800/11850 (epoch 41.350), train_loss = 0.78323913, grad/param norm = 2.6685e-01, time/batch = 15.9443s	
9801/11850 (epoch 41.354), train_loss = 0.92260301, grad/param norm = 3.3026e-01, time/batch = 19.2112s	
9802/11850 (epoch 41.359), train_loss = 1.00465575, grad/param norm = 3.5396e-01, time/batch = 18.7123s	
9803/11850 (epoch 41.363), train_loss = 0.91121563, grad/param norm = 2.9355e-01, time/batch = 17.3724s	
9804/11850 (epoch 41.367), train_loss = 0.94440141, grad/param norm = 2.7772e-01, time/batch = 19.3751s	
9805/11850 (epoch 41.371), train_loss = 0.94568392, grad/param norm = 3.1039e-01, time/batch = 17.0540s	
9806/11850 (epoch 41.376), train_loss = 0.88633976, grad/param norm = 2.6894e-01, time/batch = 18.6271s	
9807/11850 (epoch 41.380), train_loss = 0.86410030, grad/param norm = 2.8461e-01, time/batch = 17.6877s	
9808/11850 (epoch 41.384), train_loss = 0.79856759, grad/param norm = 2.7798e-01, time/batch = 17.9669s	
9809/11850 (epoch 41.388), train_loss = 0.94114823, grad/param norm = 2.9690e-01, time/batch = 17.0120s	
9810/11850 (epoch 41.392), train_loss = 0.91204873, grad/param norm = 3.2075e-01, time/batch = 17.7697s	
9811/11850 (epoch 41.397), train_loss = 0.92391917, grad/param norm = 3.0099e-01, time/batch = 16.3781s	
9812/11850 (epoch 41.401), train_loss = 0.76766414, grad/param norm = 2.3517e-01, time/batch = 19.4586s	
9813/11850 (epoch 41.405), train_loss = 0.81812658, grad/param norm = 3.3194e-01, time/batch = 17.3788s	
9814/11850 (epoch 41.409), train_loss = 0.91000283, grad/param norm = 2.9587e-01, time/batch = 17.0267s	
9815/11850 (epoch 41.414), train_loss = 0.73635469, grad/param norm = 2.5617e-01, time/batch = 17.1536s	
9816/11850 (epoch 41.418), train_loss = 0.79380127, grad/param norm = 3.2542e-01, time/batch = 19.2944s	
9817/11850 (epoch 41.422), train_loss = 0.71351237, grad/param norm = 2.6049e-01, time/batch = 17.7818s	
9818/11850 (epoch 41.426), train_loss = 0.72784677, grad/param norm = 2.8551e-01, time/batch = 17.8653s	
9819/11850 (epoch 41.430), train_loss = 0.78502813, grad/param norm = 3.6433e-01, time/batch = 19.0455s	
9820/11850 (epoch 41.435), train_loss = 0.81192037, grad/param norm = 2.8187e-01, time/batch = 16.3014s	
9821/11850 (epoch 41.439), train_loss = 0.89735722, grad/param norm = 2.7355e-01, time/batch = 19.2074s	
9822/11850 (epoch 41.443), train_loss = 0.87303900, grad/param norm = 3.1317e-01, time/batch = 19.5398s	
9823/11850 (epoch 41.447), train_loss = 0.78352944, grad/param norm = 2.8773e-01, time/batch = 24.7982s	
9824/11850 (epoch 41.451), train_loss = 0.75454680, grad/param norm = 2.4816e-01, time/batch = 24.3694s	
9825/11850 (epoch 41.456), train_loss = 0.86007396, grad/param norm = 2.9290e-01, time/batch = 18.6167s	
9826/11850 (epoch 41.460), train_loss = 0.90149076, grad/param norm = 2.7495e-01, time/batch = 16.8718s	
9827/11850 (epoch 41.464), train_loss = 0.82173152, grad/param norm = 3.4024e-01, time/batch = 15.5975s	
9828/11850 (epoch 41.468), train_loss = 0.90221190, grad/param norm = 3.3917e-01, time/batch = 14.8580s	
9829/11850 (epoch 41.473), train_loss = 0.93645361, grad/param norm = 3.1905e-01, time/batch = 18.5451s	
9830/11850 (epoch 41.477), train_loss = 0.78124764, grad/param norm = 2.9874e-01, time/batch = 18.4645s	
9831/11850 (epoch 41.481), train_loss = 0.79781917, grad/param norm = 2.8364e-01, time/batch = 16.8869s	
9832/11850 (epoch 41.485), train_loss = 0.77003098, grad/param norm = 2.5335e-01, time/batch = 19.4606s	
9833/11850 (epoch 41.489), train_loss = 0.86722633, grad/param norm = 2.6886e-01, time/batch = 17.8769s	
9834/11850 (epoch 41.494), train_loss = 0.78015701, grad/param norm = 3.5547e-01, time/batch = 18.5514s	
9835/11850 (epoch 41.498), train_loss = 0.77484610, grad/param norm = 2.7219e-01, time/batch = 17.9583s	
9836/11850 (epoch 41.502), train_loss = 0.75226038, grad/param norm = 3.1810e-01, time/batch = 16.9699s	
9837/11850 (epoch 41.506), train_loss = 0.98997192, grad/param norm = 2.7781e-01, time/batch = 19.2994s	
9838/11850 (epoch 41.511), train_loss = 0.84323659, grad/param norm = 2.7444e-01, time/batch = 17.3917s	
9839/11850 (epoch 41.515), train_loss = 0.93864971, grad/param norm = 3.5528e-01, time/batch = 17.6095s	
9840/11850 (epoch 41.519), train_loss = 0.81467503, grad/param norm = 3.0567e-01, time/batch = 18.9625s	
9841/11850 (epoch 41.523), train_loss = 0.86337546, grad/param norm = 3.0149e-01, time/batch = 16.7156s	
9842/11850 (epoch 41.527), train_loss = 0.79986094, grad/param norm = 2.9334e-01, time/batch = 18.5361s	
9843/11850 (epoch 41.532), train_loss = 0.86727375, grad/param norm = 3.0788e-01, time/batch = 15.3690s	
9844/11850 (epoch 41.536), train_loss = 0.81963408, grad/param norm = 2.7023e-01, time/batch = 15.1966s	
9845/11850 (epoch 41.540), train_loss = 0.76965761, grad/param norm = 3.1100e-01, time/batch = 18.2124s	
9846/11850 (epoch 41.544), train_loss = 0.78374333, grad/param norm = 3.2224e-01, time/batch = 17.8737s	
9847/11850 (epoch 41.549), train_loss = 0.72838152, grad/param norm = 2.3728e-01, time/batch = 19.1235s	
9848/11850 (epoch 41.553), train_loss = 0.85135132, grad/param norm = 2.7386e-01, time/batch = 14.7460s	
9849/11850 (epoch 41.557), train_loss = 0.91272563, grad/param norm = 4.5743e-01, time/batch = 16.8098s	
9850/11850 (epoch 41.561), train_loss = 0.94152601, grad/param norm = 3.9123e-01, time/batch = 17.0127s	
9851/11850 (epoch 41.565), train_loss = 1.00280040, grad/param norm = 4.1046e-01, time/batch = 17.3136s	
9852/11850 (epoch 41.570), train_loss = 0.89717677, grad/param norm = 2.7273e-01, time/batch = 17.8082s	
9853/11850 (epoch 41.574), train_loss = 0.90059309, grad/param norm = 3.2237e-01, time/batch = 16.2139s	
9854/11850 (epoch 41.578), train_loss = 0.93453569, grad/param norm = 3.2694e-01, time/batch = 18.4526s	
9855/11850 (epoch 41.582), train_loss = 0.83537438, grad/param norm = 2.9469e-01, time/batch = 18.5533s	
9856/11850 (epoch 41.586), train_loss = 0.84057641, grad/param norm = 2.9665e-01, time/batch = 18.0519s	
9857/11850 (epoch 41.591), train_loss = 0.86911988, grad/param norm = 3.1699e-01, time/batch = 15.9360s	
9858/11850 (epoch 41.595), train_loss = 0.73568855, grad/param norm = 2.9438e-01, time/batch = 14.7961s	
9859/11850 (epoch 41.599), train_loss = 0.84406382, grad/param norm = 2.9048e-01, time/batch = 18.0537s	
9860/11850 (epoch 41.603), train_loss = 0.81401555, grad/param norm = 2.6570e-01, time/batch = 17.1284s	
9861/11850 (epoch 41.608), train_loss = 0.98347811, grad/param norm = 3.0697e-01, time/batch = 17.1359s	
9862/11850 (epoch 41.612), train_loss = 1.04497136, grad/param norm = 3.8290e-01, time/batch = 18.4606s	
9863/11850 (epoch 41.616), train_loss = 0.97961119, grad/param norm = 3.1442e-01, time/batch = 17.8750s	
9864/11850 (epoch 41.620), train_loss = 0.85447710, grad/param norm = 3.5255e-01, time/batch = 16.3179s	
9865/11850 (epoch 41.624), train_loss = 0.85022414, grad/param norm = 3.3662e-01, time/batch = 17.9792s	
9866/11850 (epoch 41.629), train_loss = 0.84375916, grad/param norm = 3.1178e-01, time/batch = 16.4507s	
9867/11850 (epoch 41.633), train_loss = 0.77280842, grad/param norm = 2.8342e-01, time/batch = 16.9652s	
9868/11850 (epoch 41.637), train_loss = 0.69762800, grad/param norm = 2.5452e-01, time/batch = 18.6415s	
9869/11850 (epoch 41.641), train_loss = 0.76215406, grad/param norm = 2.8825e-01, time/batch = 17.6349s	
9870/11850 (epoch 41.646), train_loss = 0.77724503, grad/param norm = 3.2472e-01, time/batch = 17.7124s	
9871/11850 (epoch 41.650), train_loss = 0.86962922, grad/param norm = 4.3556e-01, time/batch = 19.0363s	
9872/11850 (epoch 41.654), train_loss = 0.83566175, grad/param norm = 3.9800e-01, time/batch = 17.4655s	
9873/11850 (epoch 41.658), train_loss = 0.88552421, grad/param norm = 2.6563e-01, time/batch = 19.1200s	
9874/11850 (epoch 41.662), train_loss = 0.74501305, grad/param norm = 3.2788e-01, time/batch = 15.5889s	
9875/11850 (epoch 41.667), train_loss = 0.94687414, grad/param norm = 3.3130e-01, time/batch = 17.1475s	
9876/11850 (epoch 41.671), train_loss = 0.81106363, grad/param norm = 2.7340e-01, time/batch = 17.1454s	
9877/11850 (epoch 41.675), train_loss = 0.84232848, grad/param norm = 3.3592e-01, time/batch = 17.7897s	
9878/11850 (epoch 41.679), train_loss = 0.85139599, grad/param norm = 2.7883e-01, time/batch = 17.1265s	
9879/11850 (epoch 41.684), train_loss = 0.83263178, grad/param norm = 3.5145e-01, time/batch = 15.0461s	
9880/11850 (epoch 41.688), train_loss = 0.78628800, grad/param norm = 2.9605e-01, time/batch = 18.4479s	
9881/11850 (epoch 41.692), train_loss = 0.80571187, grad/param norm = 4.4364e-01, time/batch = 17.9518s	
9882/11850 (epoch 41.696), train_loss = 0.78230416, grad/param norm = 3.7426e-01, time/batch = 18.3873s	
9883/11850 (epoch 41.700), train_loss = 0.85381594, grad/param norm = 2.9540e-01, time/batch = 18.2079s	
9884/11850 (epoch 41.705), train_loss = 0.76844659, grad/param norm = 3.1791e-01, time/batch = 16.8823s	
9885/11850 (epoch 41.709), train_loss = 0.72794410, grad/param norm = 2.9336e-01, time/batch = 17.3906s	
9886/11850 (epoch 41.713), train_loss = 0.73901891, grad/param norm = 3.0281e-01, time/batch = 17.3106s	
9887/11850 (epoch 41.717), train_loss = 0.79574736, grad/param norm = 2.6621e-01, time/batch = 17.6280s	
9888/11850 (epoch 41.722), train_loss = 0.83613367, grad/param norm = 2.9859e-01, time/batch = 15.5343s	
9889/11850 (epoch 41.726), train_loss = 0.76598226, grad/param norm = 2.9607e-01, time/batch = 18.2980s	
9890/11850 (epoch 41.730), train_loss = 0.77316414, grad/param norm = 3.1836e-01, time/batch = 18.7184s	
9891/11850 (epoch 41.734), train_loss = 0.76113634, grad/param norm = 2.9597e-01, time/batch = 15.7081s	
9892/11850 (epoch 41.738), train_loss = 0.87457771, grad/param norm = 3.4705e-01, time/batch = 17.8843s	
9893/11850 (epoch 41.743), train_loss = 0.84515729, grad/param norm = 3.3185e-01, time/batch = 17.3975s	
9894/11850 (epoch 41.747), train_loss = 0.74910507, grad/param norm = 2.5608e-01, time/batch = 15.7007s	
9895/11850 (epoch 41.751), train_loss = 0.80177800, grad/param norm = 2.5371e-01, time/batch = 16.9523s	
9896/11850 (epoch 41.755), train_loss = 0.86067750, grad/param norm = 2.9240e-01, time/batch = 16.9718s	
9897/11850 (epoch 41.759), train_loss = 0.77324566, grad/param norm = 2.8323e-01, time/batch = 18.6461s	
9898/11850 (epoch 41.764), train_loss = 0.82181464, grad/param norm = 2.7375e-01, time/batch = 14.3227s	
9899/11850 (epoch 41.768), train_loss = 0.75348497, grad/param norm = 2.6719e-01, time/batch = 17.8945s	
9900/11850 (epoch 41.772), train_loss = 0.79333016, grad/param norm = 2.9500e-01, time/batch = 14.5406s	
9901/11850 (epoch 41.776), train_loss = 0.85665028, grad/param norm = 2.9779e-01, time/batch = 18.0417s	
9902/11850 (epoch 41.781), train_loss = 0.80194633, grad/param norm = 2.7902e-01, time/batch = 16.7321s	
9903/11850 (epoch 41.785), train_loss = 0.82214596, grad/param norm = 2.8497e-01, time/batch = 17.1402s	
9904/11850 (epoch 41.789), train_loss = 0.80116452, grad/param norm = 2.8454e-01, time/batch = 17.3117s	
9905/11850 (epoch 41.793), train_loss = 0.86726021, grad/param norm = 2.9021e-01, time/batch = 16.5534s	
9906/11850 (epoch 41.797), train_loss = 0.82913437, grad/param norm = 3.5049e-01, time/batch = 17.4055s	
9907/11850 (epoch 41.802), train_loss = 0.76237546, grad/param norm = 3.0366e-01, time/batch = 16.9598s	
9908/11850 (epoch 41.806), train_loss = 0.82659513, grad/param norm = 2.9637e-01, time/batch = 18.6092s	
9909/11850 (epoch 41.810), train_loss = 0.87412875, grad/param norm = 3.2450e-01, time/batch = 16.2996s	
9910/11850 (epoch 41.814), train_loss = 0.85703277, grad/param norm = 3.0411e-01, time/batch = 15.8910s	
9911/11850 (epoch 41.819), train_loss = 0.93649671, grad/param norm = 3.1665e-01, time/batch = 17.6366s	
9912/11850 (epoch 41.823), train_loss = 0.92869348, grad/param norm = 3.0811e-01, time/batch = 17.8617s	
9913/11850 (epoch 41.827), train_loss = 0.84463217, grad/param norm = 3.5907e-01, time/batch = 15.5147s	
9914/11850 (epoch 41.831), train_loss = 0.79680186, grad/param norm = 3.1013e-01, time/batch = 18.2156s	
9915/11850 (epoch 41.835), train_loss = 0.88322092, grad/param norm = 3.4597e-01, time/batch = 17.6967s	
9916/11850 (epoch 41.840), train_loss = 0.80319671, grad/param norm = 2.8453e-01, time/batch = 17.7276s	
9917/11850 (epoch 41.844), train_loss = 0.85550206, grad/param norm = 2.5466e-01, time/batch = 17.7231s	
9918/11850 (epoch 41.848), train_loss = 0.86307861, grad/param norm = 2.8659e-01, time/batch = 17.3041s	
9919/11850 (epoch 41.852), train_loss = 0.85796302, grad/param norm = 2.7969e-01, time/batch = 17.1222s	
9920/11850 (epoch 41.857), train_loss = 0.82656405, grad/param norm = 3.2202e-01, time/batch = 19.1398s	
9921/11850 (epoch 41.861), train_loss = 0.78736866, grad/param norm = 3.6885e-01, time/batch = 17.3914s	
9922/11850 (epoch 41.865), train_loss = 0.88625029, grad/param norm = 3.8321e-01, time/batch = 17.2160s	
9923/11850 (epoch 41.869), train_loss = 0.85421015, grad/param norm = 3.0680e-01, time/batch = 18.8903s	
9924/11850 (epoch 41.873), train_loss = 0.86155866, grad/param norm = 3.3514e-01, time/batch = 17.1378s	
9925/11850 (epoch 41.878), train_loss = 0.87843613, grad/param norm = 3.0829e-01, time/batch = 18.3036s	
9926/11850 (epoch 41.882), train_loss = 0.86486225, grad/param norm = 2.9869e-01, time/batch = 14.6780s	
9927/11850 (epoch 41.886), train_loss = 0.82934452, grad/param norm = 3.6400e-01, time/batch = 16.2361s	
9928/11850 (epoch 41.890), train_loss = 0.85619053, grad/param norm = 2.8255e-01, time/batch = 15.9034s	
9929/11850 (epoch 41.895), train_loss = 0.84862700, grad/param norm = 3.4699e-01, time/batch = 17.0599s	
9930/11850 (epoch 41.899), train_loss = 0.77201382, grad/param norm = 2.9607e-01, time/batch = 17.4776s	
9931/11850 (epoch 41.903), train_loss = 0.77607451, grad/param norm = 2.6712e-01, time/batch = 16.8773s	
9932/11850 (epoch 41.907), train_loss = 0.79818326, grad/param norm = 2.6652e-01, time/batch = 18.3018s	
9933/11850 (epoch 41.911), train_loss = 0.92492016, grad/param norm = 2.6984e-01, time/batch = 18.3774s	
9934/11850 (epoch 41.916), train_loss = 0.88721196, grad/param norm = 3.2124e-01, time/batch = 17.8056s	
9935/11850 (epoch 41.920), train_loss = 0.86214799, grad/param norm = 3.0347e-01, time/batch = 17.0351s	
9936/11850 (epoch 41.924), train_loss = 0.80488426, grad/param norm = 3.0437e-01, time/batch = 16.9405s	
9937/11850 (epoch 41.928), train_loss = 0.87162898, grad/param norm = 3.2714e-01, time/batch = 18.6446s	
9938/11850 (epoch 41.932), train_loss = 0.94535094, grad/param norm = 3.1755e-01, time/batch = 18.4561s	
9939/11850 (epoch 41.937), train_loss = 0.93386902, grad/param norm = 3.4662e-01, time/batch = 17.0474s	
9940/11850 (epoch 41.941), train_loss = 0.87169046, grad/param norm = 2.9273e-01, time/batch = 18.7023s	
9941/11850 (epoch 41.945), train_loss = 0.87925603, grad/param norm = 3.0372e-01, time/batch = 18.0505s	
9942/11850 (epoch 41.949), train_loss = 0.82425415, grad/param norm = 3.6183e-01, time/batch = 18.9546s	
9943/11850 (epoch 41.954), train_loss = 0.90660850, grad/param norm = 3.7868e-01, time/batch = 16.9330s	
9944/11850 (epoch 41.958), train_loss = 0.90619882, grad/param norm = 3.1815e-01, time/batch = 15.2067s	
9945/11850 (epoch 41.962), train_loss = 0.80961588, grad/param norm = 3.2091e-01, time/batch = 17.4631s	
9946/11850 (epoch 41.966), train_loss = 0.75725637, grad/param norm = 3.1978e-01, time/batch = 17.2170s	
9947/11850 (epoch 41.970), train_loss = 0.88981219, grad/param norm = 2.8093e-01, time/batch = 17.1146s	
9948/11850 (epoch 41.975), train_loss = 0.84070832, grad/param norm = 3.0360e-01, time/batch = 17.5502s	
9949/11850 (epoch 41.979), train_loss = 0.89220778, grad/param norm = 5.1658e-01, time/batch = 19.5407s	
9950/11850 (epoch 41.983), train_loss = 0.96403016, grad/param norm = 3.3317e-01, time/batch = 17.6255s	
9951/11850 (epoch 41.987), train_loss = 0.82926706, grad/param norm = 3.3934e-01, time/batch = 17.9613s	
9952/11850 (epoch 41.992), train_loss = 0.97775463, grad/param norm = 3.1116e-01, time/batch = 19.0392s	
9953/11850 (epoch 41.996), train_loss = 0.98122659, grad/param norm = 3.8283e-01, time/batch = 17.5350s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
9954/11850 (epoch 42.000), train_loss = 0.84222179, grad/param norm = 3.3805e-01, time/batch = 15.3856s	
9955/11850 (epoch 42.004), train_loss = 0.92005525, grad/param norm = 3.3237e-01, time/batch = 18.4571s	
9956/11850 (epoch 42.008), train_loss = 0.96019298, grad/param norm = 3.6761e-01, time/batch = 17.7142s	
9957/11850 (epoch 42.013), train_loss = 0.97361558, grad/param norm = 3.2206e-01, time/batch = 18.3706s	
9958/11850 (epoch 42.017), train_loss = 0.99348140, grad/param norm = 3.7567e-01, time/batch = 18.3744s	
9959/11850 (epoch 42.021), train_loss = 0.96027826, grad/param norm = 3.2073e-01, time/batch = 18.3732s	
9960/11850 (epoch 42.025), train_loss = 0.82222300, grad/param norm = 2.7108e-01, time/batch = 17.0404s	
9961/11850 (epoch 42.030), train_loss = 0.86024379, grad/param norm = 3.1175e-01, time/batch = 16.8046s	
9962/11850 (epoch 42.034), train_loss = 0.84439111, grad/param norm = 3.1842e-01, time/batch = 16.8624s	
9963/11850 (epoch 42.038), train_loss = 0.83915214, grad/param norm = 2.8035e-01, time/batch = 16.6413s	
9964/11850 (epoch 42.042), train_loss = 0.88308509, grad/param norm = 2.8575e-01, time/batch = 17.2051s	
9965/11850 (epoch 42.046), train_loss = 0.85317385, grad/param norm = 3.9039e-01, time/batch = 16.8834s	
9966/11850 (epoch 42.051), train_loss = 0.86772805, grad/param norm = 2.9373e-01, time/batch = 18.7041s	
9967/11850 (epoch 42.055), train_loss = 0.83204098, grad/param norm = 2.9007e-01, time/batch = 17.5417s	
9968/11850 (epoch 42.059), train_loss = 0.90532929, grad/param norm = 2.9823e-01, time/batch = 19.1386s	
9969/11850 (epoch 42.063), train_loss = 0.96483925, grad/param norm = 2.9924e-01, time/batch = 18.7875s	
9970/11850 (epoch 42.068), train_loss = 0.87165041, grad/param norm = 2.9703e-01, time/batch = 15.9649s	
9971/11850 (epoch 42.072), train_loss = 0.94143679, grad/param norm = 3.3322e-01, time/batch = 19.7173s	
9972/11850 (epoch 42.076), train_loss = 0.99818577, grad/param norm = 3.3271e-01, time/batch = 15.7076s	
9973/11850 (epoch 42.080), train_loss = 0.80117794, grad/param norm = 2.6677e-01, time/batch = 18.1137s	
9974/11850 (epoch 42.084), train_loss = 0.77710702, grad/param norm = 2.9541e-01, time/batch = 18.7192s	
9975/11850 (epoch 42.089), train_loss = 0.77803783, grad/param norm = 2.8363e-01, time/batch = 16.8083s	
9976/11850 (epoch 42.093), train_loss = 0.79616965, grad/param norm = 3.2288e-01, time/batch = 17.3842s	
9977/11850 (epoch 42.097), train_loss = 0.87577063, grad/param norm = 2.9450e-01, time/batch = 17.2014s	
9978/11850 (epoch 42.101), train_loss = 0.77858465, grad/param norm = 2.8264e-01, time/batch = 16.9719s	
9979/11850 (epoch 42.105), train_loss = 0.78918969, grad/param norm = 2.7340e-01, time/batch = 16.5546s	
9980/11850 (epoch 42.110), train_loss = 0.93133032, grad/param norm = 2.7174e-01, time/batch = 16.0451s	
9981/11850 (epoch 42.114), train_loss = 0.79530105, grad/param norm = 2.7540e-01, time/batch = 13.9146s	
9982/11850 (epoch 42.118), train_loss = 0.92056309, grad/param norm = 2.9084e-01, time/batch = 14.6054s	
9983/11850 (epoch 42.122), train_loss = 0.96978447, grad/param norm = 3.3375e-01, time/batch = 16.7267s	
9984/11850 (epoch 42.127), train_loss = 0.91834214, grad/param norm = 3.3670e-01, time/batch = 17.3812s	
9985/11850 (epoch 42.131), train_loss = 0.87619808, grad/param norm = 3.1381e-01, time/batch = 18.2994s	
9986/11850 (epoch 42.135), train_loss = 0.87881583, grad/param norm = 3.3150e-01, time/batch = 17.8051s	
9987/11850 (epoch 42.139), train_loss = 0.86164050, grad/param norm = 3.1029e-01, time/batch = 17.9636s	
9988/11850 (epoch 42.143), train_loss = 0.83303999, grad/param norm = 5.7385e-01, time/batch = 17.3899s	
9989/11850 (epoch 42.148), train_loss = 0.85933982, grad/param norm = 3.2975e-01, time/batch = 18.0316s	
9990/11850 (epoch 42.152), train_loss = 0.94491360, grad/param norm = 3.3657e-01, time/batch = 18.1078s	
9991/11850 (epoch 42.156), train_loss = 0.82708398, grad/param norm = 3.4353e-01, time/batch = 17.9362s	
9992/11850 (epoch 42.160), train_loss = 1.02745884, grad/param norm = 3.8381e-01, time/batch = 18.3844s	
9993/11850 (epoch 42.165), train_loss = 0.95588601, grad/param norm = 4.1960e-01, time/batch = 15.1160s	
9994/11850 (epoch 42.169), train_loss = 0.87053085, grad/param norm = 3.6776e-01, time/batch = 16.6210s	
9995/11850 (epoch 42.173), train_loss = 0.93490828, grad/param norm = 3.3180e-01, time/batch = 16.4688s	
9996/11850 (epoch 42.177), train_loss = 0.78297776, grad/param norm = 3.2272e-01, time/batch = 18.1283s	
9997/11850 (epoch 42.181), train_loss = 0.88112014, grad/param norm = 3.0922e-01, time/batch = 18.0516s	
9998/11850 (epoch 42.186), train_loss = 0.96339098, grad/param norm = 5.8139e-01, time/batch = 19.0366s	
9999/11850 (epoch 42.190), train_loss = 0.92779551, grad/param norm = 3.9727e-01, time/batch = 15.9668s	
evaluating loss over split index 2	
1/13...	
2/13...	
3/13...	
4/13...	
5/13...	
6/13...	
7/13...	
8/13...	
9/13...	
10/13...	
11/13...	
12/13...	
13/13...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_katelyn_salem_epoch42.19_2.4559.t7	
10000/11850 (epoch 42.194), train_loss = 0.91354679, grad/param norm = 4.3975e-01, time/batch = 18.0548s	
10001/11850 (epoch 42.198), train_loss = 1.32703567, grad/param norm = 4.9727e-01, time/batch = 14.6678s	
10002/11850 (epoch 42.203), train_loss = 0.76993548, grad/param norm = 3.7279e-01, time/batch = 16.8710s	
10003/11850 (epoch 42.207), train_loss = 0.91463249, grad/param norm = 3.7195e-01, time/batch = 17.8010s	
10004/11850 (epoch 42.211), train_loss = 0.85497405, grad/param norm = 3.3493e-01, time/batch = 18.3015s	
10005/11850 (epoch 42.215), train_loss = 0.90298507, grad/param norm = 3.4547e-01, time/batch = 16.2982s	
10006/11850 (epoch 42.219), train_loss = 0.88868150, grad/param norm = 3.0301e-01, time/batch = 18.9670s	
10007/11850 (epoch 42.224), train_loss = 1.01764224, grad/param norm = 3.3977e-01, time/batch = 17.5577s	
10008/11850 (epoch 42.228), train_loss = 0.89387627, grad/param norm = 2.8547e-01, time/batch = 17.8734s	
10009/11850 (epoch 42.232), train_loss = 0.89171754, grad/param norm = 3.1525e-01, time/batch = 16.9640s	
10010/11850 (epoch 42.236), train_loss = 0.83504314, grad/param norm = 3.2927e-01, time/batch = 15.8756s	
10011/11850 (epoch 42.241), train_loss = 0.94134107, grad/param norm = 4.6835e-01, time/batch = 17.8829s	
10012/11850 (epoch 42.245), train_loss = 0.93268349, grad/param norm = 2.9984e-01, time/batch = 16.3767s	
10013/11850 (epoch 42.249), train_loss = 0.88447796, grad/param norm = 3.3733e-01, time/batch = 16.1159s	
10014/11850 (epoch 42.253), train_loss = 0.85949030, grad/param norm = 2.8809e-01, time/batch = 17.3958s	
10015/11850 (epoch 42.257), train_loss = 0.97911992, grad/param norm = 3.1739e-01, time/batch = 17.6379s	
10016/11850 (epoch 42.262), train_loss = 1.00901119, grad/param norm = 3.9949e-01, time/batch = 17.6335s	
10017/11850 (epoch 42.266), train_loss = 0.97683945, grad/param norm = 3.4819e-01, time/batch = 17.8945s	
10018/11850 (epoch 42.270), train_loss = 0.87425689, grad/param norm = 2.8125e-01, time/batch = 18.8033s	
10019/11850 (epoch 42.274), train_loss = 0.86617244, grad/param norm = 3.4926e-01, time/batch = 17.1353s	
10020/11850 (epoch 42.278), train_loss = 0.76108734, grad/param norm = 3.0893e-01, time/batch = 19.2177s	
10021/11850 (epoch 42.283), train_loss = 0.87047963, grad/param norm = 2.7454e-01, time/batch = 17.5460s	
10022/11850 (epoch 42.287), train_loss = 0.98746536, grad/param norm = 3.1797e-01, time/batch = 15.7214s	
10023/11850 (epoch 42.291), train_loss = 0.86008263, grad/param norm = 2.9384e-01, time/batch = 18.2280s	
10024/11850 (epoch 42.295), train_loss = 0.91278344, grad/param norm = 3.2350e-01, time/batch = 16.8915s	
10025/11850 (epoch 42.300), train_loss = 0.84278830, grad/param norm = 3.5333e-01, time/batch = 18.3803s	
10026/11850 (epoch 42.304), train_loss = 0.87218115, grad/param norm = 2.6764e-01, time/batch = 30.0170s	
10027/11850 (epoch 42.308), train_loss = 0.88057037, grad/param norm = 3.1378e-01, time/batch = 17.0619s	
10028/11850 (epoch 42.312), train_loss = 0.78180119, grad/param norm = 2.8457e-01, time/batch = 16.9564s	
10029/11850 (epoch 42.316), train_loss = 0.87092274, grad/param norm = 2.4905e-01, time/batch = 17.8754s	
10030/11850 (epoch 42.321), train_loss = 0.83225929, grad/param norm = 2.6513e-01, time/batch = 16.6167s	
10031/11850 (epoch 42.325), train_loss = 0.88539612, grad/param norm = 3.0104e-01, time/batch = 17.0661s	
10032/11850 (epoch 42.329), train_loss = 0.87038362, grad/param norm = 3.2000e-01, time/batch = 16.7848s	
10033/11850 (epoch 42.333), train_loss = 0.85761391, grad/param norm = 3.0092e-01, time/batch = 18.7108s	
10034/11850 (epoch 42.338), train_loss = 0.84719561, grad/param norm = 2.9167e-01, time/batch = 15.2942s	
10035/11850 (epoch 42.342), train_loss = 0.87245967, grad/param norm = 3.3002e-01, time/batch = 18.6227s	
10036/11850 (epoch 42.346), train_loss = 0.84674934, grad/param norm = 3.1822e-01, time/batch = 18.8770s	
10037/11850 (epoch 42.350), train_loss = 0.76820786, grad/param norm = 2.6490e-01, time/batch = 17.2168s	
10038/11850 (epoch 42.354), train_loss = 0.90915315, grad/param norm = 2.6968e-01, time/batch = 18.6209s	
10039/11850 (epoch 42.359), train_loss = 1.01479306, grad/param norm = 3.7648e-01, time/batch = 15.9604s	
10040/11850 (epoch 42.363), train_loss = 0.88794159, grad/param norm = 2.8745e-01, time/batch = 18.1427s	
10041/11850 (epoch 42.367), train_loss = 0.92057932, grad/param norm = 2.6473e-01, time/batch = 18.7147s	
10042/11850 (epoch 42.371), train_loss = 0.92427140, grad/param norm = 2.7181e-01, time/batch = 15.5422s	
10043/11850 (epoch 42.376), train_loss = 0.87775772, grad/param norm = 2.7521e-01, time/batch = 18.2212s	
10044/11850 (epoch 42.380), train_loss = 0.84295386, grad/param norm = 2.7888e-01, time/batch = 16.4765s	
10045/11850 (epoch 42.384), train_loss = 0.78308172, grad/param norm = 3.3059e-01, time/batch = 17.3851s	
10046/11850 (epoch 42.388), train_loss = 0.92829595, grad/param norm = 3.1112e-01, time/batch = 15.2173s	
10047/11850 (epoch 42.392), train_loss = 0.89867149, grad/param norm = 3.0816e-01, time/batch = 16.7748s	
10048/11850 (epoch 42.397), train_loss = 0.91467198, grad/param norm = 3.0914e-01, time/batch = 17.5591s	
10049/11850 (epoch 42.401), train_loss = 0.75092190, grad/param norm = 2.3699e-01, time/batch = 15.9762s	
10050/11850 (epoch 42.405), train_loss = 0.79418863, grad/param norm = 3.0160e-01, time/batch = 17.6539s	
10051/11850 (epoch 42.409), train_loss = 0.89685650, grad/param norm = 2.8973e-01, time/batch = 17.7216s	
10052/11850 (epoch 42.414), train_loss = 0.73202900, grad/param norm = 2.7323e-01, time/batch = 17.7837s	
10053/11850 (epoch 42.418), train_loss = 0.76791452, grad/param norm = 2.8288e-01, time/batch = 16.7216s	
10054/11850 (epoch 42.422), train_loss = 0.71165904, grad/param norm = 2.7307e-01, time/batch = 17.8144s	
10055/11850 (epoch 42.426), train_loss = 0.72490048, grad/param norm = 2.8833e-01, time/batch = 15.1325s	
10056/11850 (epoch 42.430), train_loss = 0.80182732, grad/param norm = 4.6084e-01, time/batch = 16.9658s	
10057/11850 (epoch 42.435), train_loss = 0.81148493, grad/param norm = 3.2281e-01, time/batch = 17.5666s	
10058/11850 (epoch 42.439), train_loss = 0.90192761, grad/param norm = 3.1172e-01, time/batch = 18.3133s	
10059/11850 (epoch 42.443), train_loss = 0.84527892, grad/param norm = 2.9839e-01, time/batch = 17.7191s	
10060/11850 (epoch 42.447), train_loss = 0.77208838, grad/param norm = 2.9629e-01, time/batch = 16.5588s	
10061/11850 (epoch 42.451), train_loss = 0.76417631, grad/param norm = 3.0803e-01, time/batch = 16.6607s	
10062/11850 (epoch 42.456), train_loss = 0.85152127, grad/param norm = 3.1249e-01, time/batch = 16.6499s	
10063/11850 (epoch 42.460), train_loss = 0.88808160, grad/param norm = 2.6524e-01, time/batch = 17.3097s	
10064/11850 (epoch 42.464), train_loss = 0.81305803, grad/param norm = 2.9367e-01, time/batch = 16.4731s	
10065/11850 (epoch 42.468), train_loss = 0.88419935, grad/param norm = 2.9779e-01, time/batch = 16.4887s	
10066/11850 (epoch 42.473), train_loss = 0.93628233, grad/param norm = 3.5603e-01, time/batch = 17.9556s	
10067/11850 (epoch 42.477), train_loss = 0.76284695, grad/param norm = 2.6253e-01, time/batch = 15.4029s	
10068/11850 (epoch 42.481), train_loss = 0.80234451, grad/param norm = 3.1784e-01, time/batch = 18.0523s	
10069/11850 (epoch 42.485), train_loss = 0.76118525, grad/param norm = 2.6507e-01, time/batch = 15.6663s	
10070/11850 (epoch 42.489), train_loss = 0.84931947, grad/param norm = 2.8241e-01, time/batch = 17.3875s	
10071/11850 (epoch 42.494), train_loss = 0.75987492, grad/param norm = 2.5510e-01, time/batch = 18.1346s	
10072/11850 (epoch 42.498), train_loss = 0.77167056, grad/param norm = 3.1412e-01, time/batch = 17.0546s	
10073/11850 (epoch 42.502), train_loss = 0.74505083, grad/param norm = 3.1629e-01, time/batch = 17.7996s	
10074/11850 (epoch 42.506), train_loss = 0.98123756, grad/param norm = 2.9721e-01, time/batch = 18.2201s	
10075/11850 (epoch 42.511), train_loss = 0.83438589, grad/param norm = 2.6907e-01, time/batch = 17.9723s	
10076/11850 (epoch 42.515), train_loss = 0.92004134, grad/param norm = 3.2717e-01, time/batch = 18.3804s	
10077/11850 (epoch 42.519), train_loss = 0.79908818, grad/param norm = 2.9371e-01, time/batch = 15.2156s	
10078/11850 (epoch 42.523), train_loss = 0.84418501, grad/param norm = 2.8684e-01, time/batch = 18.9717s	
10079/11850 (epoch 42.527), train_loss = 0.77408324, grad/param norm = 2.4913e-01, time/batch = 17.9644s	
10080/11850 (epoch 42.532), train_loss = 0.84543170, grad/param norm = 2.6950e-01, time/batch = 16.7184s	
10081/11850 (epoch 42.536), train_loss = 0.80679009, grad/param norm = 2.7367e-01, time/batch = 15.0847s	
10082/11850 (epoch 42.540), train_loss = 0.74708910, grad/param norm = 2.5594e-01, time/batch = 16.5495s	
10083/11850 (epoch 42.544), train_loss = 0.76885155, grad/param norm = 3.1461e-01, time/batch = 17.0394s	
10084/11850 (epoch 42.549), train_loss = 0.72238844, grad/param norm = 2.5039e-01, time/batch = 16.8814s	
10085/11850 (epoch 42.553), train_loss = 0.83493122, grad/param norm = 2.6902e-01, time/batch = 18.7971s	
10086/11850 (epoch 42.557), train_loss = 0.89683147, grad/param norm = 3.9750e-01, time/batch = 18.7148s	
10087/11850 (epoch 42.561), train_loss = 0.90604917, grad/param norm = 3.4422e-01, time/batch = 17.3747s	
10088/11850 (epoch 42.565), train_loss = 0.97271938, grad/param norm = 3.7574e-01, time/batch = 18.2805s	
10089/11850 (epoch 42.570), train_loss = 0.88335826, grad/param norm = 3.0222e-01, time/batch = 18.3853s	
10090/11850 (epoch 42.574), train_loss = 0.89992915, grad/param norm = 3.1226e-01, time/batch = 18.6290s	
10091/11850 (epoch 42.578), train_loss = 0.91520227, grad/param norm = 3.1926e-01, time/batch = 15.2132s	
10092/11850 (epoch 42.582), train_loss = 0.83094179, grad/param norm = 3.4248e-01, time/batch = 17.3959s	
10093/11850 (epoch 42.586), train_loss = 0.84486631, grad/param norm = 2.8096e-01, time/batch = 16.3804s	
10094/11850 (epoch 42.591), train_loss = 0.86189272, grad/param norm = 3.3244e-01, time/batch = 15.7119s	
10095/11850 (epoch 42.595), train_loss = 0.72441189, grad/param norm = 2.7700e-01, time/batch = 17.5578s	
10096/11850 (epoch 42.599), train_loss = 0.82626855, grad/param norm = 3.1413e-01, time/batch = 16.8214s	
10097/11850 (epoch 42.603), train_loss = 0.79194679, grad/param norm = 2.7469e-01, time/batch = 17.9699s	
10098/11850 (epoch 42.608), train_loss = 0.97958643, grad/param norm = 3.2494e-01, time/batch = 16.2064s	
10099/11850 (epoch 42.612), train_loss = 1.01560082, grad/param norm = 3.1879e-01, time/batch = 16.7864s	
10100/11850 (epoch 42.616), train_loss = 0.95609017, grad/param norm = 3.1368e-01, time/batch = 18.8810s	
10101/11850 (epoch 42.620), train_loss = 0.83372665, grad/param norm = 2.9192e-01, time/batch = 16.1191s	
10102/11850 (epoch 42.624), train_loss = 0.82862398, grad/param norm = 3.5117e-01, time/batch = 18.2936s	
10103/11850 (epoch 42.629), train_loss = 0.83011107, grad/param norm = 2.8791e-01, time/batch = 15.4591s	
10104/11850 (epoch 42.633), train_loss = 0.77685001, grad/param norm = 3.0244e-01, time/batch = 18.3903s	
10105/11850 (epoch 42.637), train_loss = 0.69737988, grad/param norm = 2.6636e-01, time/batch = 16.8041s	
10106/11850 (epoch 42.641), train_loss = 0.73266717, grad/param norm = 2.5418e-01, time/batch = 19.1422s	
10107/11850 (epoch 42.646), train_loss = 0.76949206, grad/param norm = 3.0146e-01, time/batch = 18.1416s	
10108/11850 (epoch 42.650), train_loss = 0.83733450, grad/param norm = 2.7203e-01, time/batch = 15.7465s	
10109/11850 (epoch 42.654), train_loss = 0.80281734, grad/param norm = 3.6521e-01, time/batch = 17.3966s	
10110/11850 (epoch 42.658), train_loss = 0.87828500, grad/param norm = 3.0359e-01, time/batch = 17.7223s	
10111/11850 (epoch 42.662), train_loss = 0.74569159, grad/param norm = 3.6778e-01, time/batch = 17.7784s	
10112/11850 (epoch 42.667), train_loss = 0.93236018, grad/param norm = 3.1346e-01, time/batch = 17.9633s	
10113/11850 (epoch 42.671), train_loss = 0.79937459, grad/param norm = 2.7224e-01, time/batch = 17.3144s	
10114/11850 (epoch 42.675), train_loss = 0.82152248, grad/param norm = 3.0004e-01, time/batch = 17.2901s	
10115/11850 (epoch 42.679), train_loss = 0.83941188, grad/param norm = 2.7506e-01, time/batch = 16.8906s	
10116/11850 (epoch 42.684), train_loss = 0.82287192, grad/param norm = 3.4352e-01, time/batch = 15.8024s	
10117/11850 (epoch 42.688), train_loss = 0.77928606, grad/param norm = 2.9901e-01, time/batch = 15.1858s	
10118/11850 (epoch 42.692), train_loss = 0.79802204, grad/param norm = 3.2087e-01, time/batch = 17.2147s	
10119/11850 (epoch 42.696), train_loss = 0.76650723, grad/param norm = 3.5680e-01, time/batch = 16.5988s	
10120/11850 (epoch 42.700), train_loss = 0.82903595, grad/param norm = 2.7867e-01, time/batch = 17.5448s	
10121/11850 (epoch 42.705), train_loss = 0.74969901, grad/param norm = 2.9204e-01, time/batch = 19.0592s	
10122/11850 (epoch 42.709), train_loss = 0.73215329, grad/param norm = 2.9677e-01, time/batch = 14.7624s	
10123/11850 (epoch 42.713), train_loss = 0.72907621, grad/param norm = 2.9667e-01, time/batch = 14.6704s	
10124/11850 (epoch 42.717), train_loss = 0.77415184, grad/param norm = 2.4263e-01, time/batch = 15.0815s	
10125/11850 (epoch 42.722), train_loss = 0.83139074, grad/param norm = 3.9308e-01, time/batch = 17.2108s	
10126/11850 (epoch 42.726), train_loss = 0.75491224, grad/param norm = 3.0197e-01, time/batch = 17.8661s	
10127/11850 (epoch 42.730), train_loss = 0.76000684, grad/param norm = 3.1533e-01, time/batch = 17.3939s	
10128/11850 (epoch 42.734), train_loss = 0.75169119, grad/param norm = 2.9892e-01, time/batch = 18.5567s	
10129/11850 (epoch 42.738), train_loss = 0.87456975, grad/param norm = 3.3975e-01, time/batch = 15.0082s	
10130/11850 (epoch 42.743), train_loss = 0.82521196, grad/param norm = 3.0879e-01, time/batch = 0.6417s	
10131/11850 (epoch 42.747), train_loss = 0.73789921, grad/param norm = 2.6522e-01, time/batch = 0.6462s	
10132/11850 (epoch 42.751), train_loss = 0.79726451, grad/param norm = 2.6552e-01, time/batch = 0.6412s	
10133/11850 (epoch 42.755), train_loss = 0.85822055, grad/param norm = 2.9756e-01, time/batch = 0.6405s	
10134/11850 (epoch 42.759), train_loss = 0.76116139, grad/param norm = 2.5949e-01, time/batch = 0.6388s	
10135/11850 (epoch 42.764), train_loss = 0.81436730, grad/param norm = 2.7342e-01, time/batch = 0.6433s	
10136/11850 (epoch 42.768), train_loss = 0.74834007, grad/param norm = 2.6966e-01, time/batch = 0.6485s	
10137/11850 (epoch 42.772), train_loss = 0.78959693, grad/param norm = 2.8799e-01, time/batch = 0.8365s	
10138/11850 (epoch 42.776), train_loss = 0.83546360, grad/param norm = 2.8856e-01, time/batch = 0.9644s	
10139/11850 (epoch 42.781), train_loss = 0.79039506, grad/param norm = 2.8436e-01, time/batch = 0.9557s	
10140/11850 (epoch 42.785), train_loss = 0.81543011, grad/param norm = 3.0338e-01, time/batch = 0.9402s	
10141/11850 (epoch 42.789), train_loss = 0.78625703, grad/param norm = 2.8919e-01, time/batch = 0.9308s	
10142/11850 (epoch 42.793), train_loss = 0.84144548, grad/param norm = 2.8358e-01, time/batch = 1.1720s	
10143/11850 (epoch 42.797), train_loss = 0.80503980, grad/param norm = 3.0502e-01, time/batch = 1.7895s	
10144/11850 (epoch 42.802), train_loss = 0.74497114, grad/param norm = 2.8466e-01, time/batch = 1.7585s	
10145/11850 (epoch 42.806), train_loss = 0.82207857, grad/param norm = 3.2320e-01, time/batch = 10.0406s	
10146/11850 (epoch 42.810), train_loss = 0.87314587, grad/param norm = 4.0709e-01, time/batch = 17.4767s	
10147/11850 (epoch 42.814), train_loss = 0.83317978, grad/param norm = 3.4780e-01, time/batch = 17.6228s	
10148/11850 (epoch 42.819), train_loss = 0.92408433, grad/param norm = 3.0424e-01, time/batch = 16.1391s	
10149/11850 (epoch 42.823), train_loss = 0.91730668, grad/param norm = 3.2611e-01, time/batch = 18.0508s	
10150/11850 (epoch 42.827), train_loss = 0.83177545, grad/param norm = 3.5712e-01, time/batch = 17.0663s	
10151/11850 (epoch 42.831), train_loss = 0.77899126, grad/param norm = 3.2286e-01, time/batch = 15.2438s	
10152/11850 (epoch 42.835), train_loss = 0.87499513, grad/param norm = 2.9903e-01, time/batch = 16.9669s	
10153/11850 (epoch 42.840), train_loss = 0.79772433, grad/param norm = 3.3864e-01, time/batch = 18.2144s	
10154/11850 (epoch 42.844), train_loss = 0.83247962, grad/param norm = 2.6430e-01, time/batch = 17.0454s	
10155/11850 (epoch 42.848), train_loss = 0.84878486, grad/param norm = 2.9486e-01, time/batch = 18.2189s	
10156/11850 (epoch 42.852), train_loss = 0.83796782, grad/param norm = 3.3657e-01, time/batch = 16.8863s	
10157/11850 (epoch 42.857), train_loss = 0.84807157, grad/param norm = 4.1911e-01, time/batch = 17.6470s	
10158/11850 (epoch 42.861), train_loss = 0.77851299, grad/param norm = 4.0892e-01, time/batch = 18.2743s	
10159/11850 (epoch 42.865), train_loss = 0.89117149, grad/param norm = 4.5939e-01, time/batch = 17.4887s	
10160/11850 (epoch 42.869), train_loss = 0.86100081, grad/param norm = 3.4804e-01, time/batch = 17.7850s	
10161/11850 (epoch 42.873), train_loss = 0.85311042, grad/param norm = 3.2961e-01, time/batch = 16.0081s	
10162/11850 (epoch 42.878), train_loss = 0.86700285, grad/param norm = 3.3610e-01, time/batch = 15.3726s	
10163/11850 (epoch 42.882), train_loss = 0.87146426, grad/param norm = 3.3500e-01, time/batch = 16.7255s	
10164/11850 (epoch 42.886), train_loss = 0.80474862, grad/param norm = 4.0981e-01, time/batch = 17.9867s	
10165/11850 (epoch 42.890), train_loss = 0.85459609, grad/param norm = 3.8474e-01, time/batch = 16.0374s	
10166/11850 (epoch 42.895), train_loss = 0.85021133, grad/param norm = 3.7989e-01, time/batch = 15.8891s	
10167/11850 (epoch 42.899), train_loss = 0.75702792, grad/param norm = 3.0122e-01, time/batch = 18.1460s	
10168/11850 (epoch 42.903), train_loss = 0.78173495, grad/param norm = 3.0485e-01, time/batch = 16.8111s	
10169/11850 (epoch 42.907), train_loss = 0.80852654, grad/param norm = 2.9553e-01, time/batch = 17.3043s	
10170/11850 (epoch 42.911), train_loss = 0.92005688, grad/param norm = 3.3636e-01, time/batch = 17.2395s	
10171/11850 (epoch 42.916), train_loss = 0.86811256, grad/param norm = 3.0934e-01, time/batch = 18.7181s	
10172/11850 (epoch 42.920), train_loss = 0.85592213, grad/param norm = 2.9297e-01, time/batch = 18.3653s	
10173/11850 (epoch 42.924), train_loss = 0.82183403, grad/param norm = 3.6525e-01, time/batch = 17.5529s	
10174/11850 (epoch 42.928), train_loss = 0.88258942, grad/param norm = 3.9898e-01, time/batch = 19.1166s	
10175/11850 (epoch 42.932), train_loss = 0.94741097, grad/param norm = 4.1149e-01, time/batch = 16.5494s	
10176/11850 (epoch 42.937), train_loss = 0.92218692, grad/param norm = 2.9132e-01, time/batch = 17.2070s	
10177/11850 (epoch 42.941), train_loss = 0.85554872, grad/param norm = 3.3196e-01, time/batch = 17.7987s	
10178/11850 (epoch 42.945), train_loss = 0.88056511, grad/param norm = 3.3335e-01, time/batch = 17.1793s	
10179/11850 (epoch 42.949), train_loss = 0.81263113, grad/param norm = 3.6515e-01, time/batch = 18.5358s	
10180/11850 (epoch 42.954), train_loss = 0.89132044, grad/param norm = 3.7415e-01, time/batch = 15.2681s	
10181/11850 (epoch 42.958), train_loss = 0.89285799, grad/param norm = 3.2073e-01, time/batch = 18.8822s	
10182/11850 (epoch 42.962), train_loss = 0.79048675, grad/param norm = 2.9167e-01, time/batch = 17.3793s	
10183/11850 (epoch 42.966), train_loss = 0.75701777, grad/param norm = 3.2712e-01, time/batch = 16.1361s	
10184/11850 (epoch 42.970), train_loss = 0.90514080, grad/param norm = 3.7008e-01, time/batch = 15.1501s	
10185/11850 (epoch 42.975), train_loss = 0.82296817, grad/param norm = 2.8909e-01, time/batch = 18.0346s	
10186/11850 (epoch 42.979), train_loss = 0.87745666, grad/param norm = 4.4860e-01, time/batch = 18.7975s	
10187/11850 (epoch 42.983), train_loss = 0.95317790, grad/param norm = 4.0467e-01, time/batch = 16.4937s	
10188/11850 (epoch 42.987), train_loss = 0.79516734, grad/param norm = 2.9769e-01, time/batch = 16.3205s	
10189/11850 (epoch 42.992), train_loss = 0.94748934, grad/param norm = 3.0372e-01, time/batch = 15.9779s	
10190/11850 (epoch 42.996), train_loss = 0.95157882, grad/param norm = 3.4176e-01, time/batch = 19.1307s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
10191/11850 (epoch 43.000), train_loss = 0.82604622, grad/param norm = 3.4999e-01, time/batch = 17.5510s	
10192/11850 (epoch 43.004), train_loss = 0.90916441, grad/param norm = 3.3396e-01, time/batch = 16.8885s	
10193/11850 (epoch 43.008), train_loss = 0.93691908, grad/param norm = 3.1185e-01, time/batch = 18.2953s	
10194/11850 (epoch 43.013), train_loss = 0.95155207, grad/param norm = 2.9621e-01, time/batch = 17.8040s	
10195/11850 (epoch 43.017), train_loss = 0.98903683, grad/param norm = 3.7467e-01, time/batch = 18.8736s	
10196/11850 (epoch 43.021), train_loss = 0.94317215, grad/param norm = 3.0146e-01, time/batch = 18.2054s	
10197/11850 (epoch 43.025), train_loss = 0.81167907, grad/param norm = 2.6804e-01, time/batch = 18.1305s	
10198/11850 (epoch 43.030), train_loss = 0.85964413, grad/param norm = 3.5940e-01, time/batch = 17.9852s	
10199/11850 (epoch 43.034), train_loss = 0.82515165, grad/param norm = 3.5244e-01, time/batch = 16.7163s	
10200/11850 (epoch 43.038), train_loss = 0.84204444, grad/param norm = 3.2344e-01, time/batch = 17.2096s	
10201/11850 (epoch 43.042), train_loss = 0.87990752, grad/param norm = 3.3413e-01, time/batch = 15.8227s	
10202/11850 (epoch 43.046), train_loss = 0.83422435, grad/param norm = 3.5702e-01, time/batch = 16.8879s	
10203/11850 (epoch 43.051), train_loss = 0.85396710, grad/param norm = 3.0683e-01, time/batch = 17.0562s	
10204/11850 (epoch 43.055), train_loss = 0.82353997, grad/param norm = 2.8893e-01, time/batch = 16.9775s	
10205/11850 (epoch 43.059), train_loss = 0.88389251, grad/param norm = 2.8720e-01, time/batch = 18.2927s	
10206/11850 (epoch 43.063), train_loss = 0.97157747, grad/param norm = 3.5519e-01, time/batch = 17.3848s	
10207/11850 (epoch 43.068), train_loss = 0.85873612, grad/param norm = 3.0075e-01, time/batch = 17.2738s	
10208/11850 (epoch 43.072), train_loss = 0.90954247, grad/param norm = 3.0279e-01, time/batch = 14.8540s	
10209/11850 (epoch 43.076), train_loss = 0.97429557, grad/param norm = 3.2973e-01, time/batch = 17.9713s	
10210/11850 (epoch 43.080), train_loss = 0.78980250, grad/param norm = 2.8809e-01, time/batch = 19.1112s	
10211/11850 (epoch 43.084), train_loss = 0.76769454, grad/param norm = 2.8844e-01, time/batch = 18.2065s	
10212/11850 (epoch 43.089), train_loss = 0.77059813, grad/param norm = 3.0214e-01, time/batch = 19.0535s	
10213/11850 (epoch 43.093), train_loss = 0.79272045, grad/param norm = 3.6077e-01, time/batch = 15.0522s	
10214/11850 (epoch 43.097), train_loss = 0.85636654, grad/param norm = 3.0333e-01, time/batch = 17.5661s	
10215/11850 (epoch 43.101), train_loss = 0.77072319, grad/param norm = 4.0029e-01, time/batch = 16.6538s	
10216/11850 (epoch 43.105), train_loss = 0.78274975, grad/param norm = 2.7525e-01, time/batch = 17.1459s	
10217/11850 (epoch 43.110), train_loss = 0.91842741, grad/param norm = 2.9773e-01, time/batch = 17.0445s	
10218/11850 (epoch 43.114), train_loss = 0.79533433, grad/param norm = 3.0250e-01, time/batch = 16.8026s	
10219/11850 (epoch 43.118), train_loss = 0.90470959, grad/param norm = 2.7638e-01, time/batch = 16.3640s	
10220/11850 (epoch 43.122), train_loss = 0.96041810, grad/param norm = 2.8252e-01, time/batch = 17.2944s	
10221/11850 (epoch 43.127), train_loss = 0.91514370, grad/param norm = 3.2604e-01, time/batch = 16.3080s	
10222/11850 (epoch 43.131), train_loss = 0.86150890, grad/param norm = 3.1813e-01, time/batch = 18.3925s	
10223/11850 (epoch 43.135), train_loss = 0.86222855, grad/param norm = 3.1762e-01, time/batch = 17.0507s	
10224/11850 (epoch 43.139), train_loss = 0.83928824, grad/param norm = 2.9563e-01, time/batch = 16.7226s	
10225/11850 (epoch 43.143), train_loss = 0.85356782, grad/param norm = 3.7725e-01, time/batch = 17.8935s	
10226/11850 (epoch 43.148), train_loss = 0.86277478, grad/param norm = 4.0339e-01, time/batch = 18.0644s	
10227/11850 (epoch 43.152), train_loss = 0.94226248, grad/param norm = 3.5035e-01, time/batch = 17.7961s	
10228/11850 (epoch 43.156), train_loss = 0.81415396, grad/param norm = 3.1184e-01, time/batch = 16.6488s	
10229/11850 (epoch 43.160), train_loss = 1.02615818, grad/param norm = 4.2233e-01, time/batch = 18.1355s	
10230/11850 (epoch 43.165), train_loss = 0.93675289, grad/param norm = 4.2761e-01, time/batch = 16.4736s	
10231/11850 (epoch 43.169), train_loss = 0.85841140, grad/param norm = 3.9541e-01, time/batch = 17.5463s	
10232/11850 (epoch 43.173), train_loss = 0.91265928, grad/param norm = 3.3384e-01, time/batch = 16.0604s	
10233/11850 (epoch 43.177), train_loss = 0.77082015, grad/param norm = 3.7314e-01, time/batch = 16.4039s	
10234/11850 (epoch 43.181), train_loss = 0.86014944, grad/param norm = 2.9138e-01, time/batch = 17.6926s	
10235/11850 (epoch 43.186), train_loss = 0.95365360, grad/param norm = 3.6363e-01, time/batch = 15.5283s	
10236/11850 (epoch 43.190), train_loss = 0.89518816, grad/param norm = 2.9877e-01, time/batch = 16.0634s	
10237/11850 (epoch 43.194), train_loss = 0.88626190, grad/param norm = 4.1793e-01, time/batch = 17.2943s	
10238/11850 (epoch 43.198), train_loss = 0.74230927, grad/param norm = 3.7378e-01, time/batch = 17.3977s	
10239/11850 (epoch 43.203), train_loss = 0.74967927, grad/param norm = 3.7091e-01, time/batch = 16.6505s	
10240/11850 (epoch 43.207), train_loss = 0.90654626, grad/param norm = 3.4692e-01, time/batch = 14.5913s	
10241/11850 (epoch 43.211), train_loss = 0.83556093, grad/param norm = 3.2642e-01, time/batch = 16.6336s	
10242/11850 (epoch 43.215), train_loss = 0.88516873, grad/param norm = 3.5372e-01, time/batch = 19.2217s	
10243/11850 (epoch 43.219), train_loss = 0.88203891, grad/param norm = 3.2265e-01, time/batch = 15.1385s	
10244/11850 (epoch 43.224), train_loss = 0.98660840, grad/param norm = 3.5184e-01, time/batch = 17.2129s	
10245/11850 (epoch 43.228), train_loss = 0.89687166, grad/param norm = 3.2192e-01, time/batch = 17.0414s	
10246/11850 (epoch 43.232), train_loss = 0.87998816, grad/param norm = 3.1341e-01, time/batch = 18.1308s	
10247/11850 (epoch 43.236), train_loss = 0.82048328, grad/param norm = 3.2707e-01, time/batch = 19.0370s	
10248/11850 (epoch 43.241), train_loss = 0.92140317, grad/param norm = 4.6260e-01, time/batch = 31.7041s	
10249/11850 (epoch 43.245), train_loss = 0.93092333, grad/param norm = 3.1237e-01, time/batch = 16.9615s	
10250/11850 (epoch 43.249), train_loss = 0.86533652, grad/param norm = 2.6711e-01, time/batch = 16.1117s	
10251/11850 (epoch 43.253), train_loss = 0.85891293, grad/param norm = 3.3933e-01, time/batch = 18.8787s	
10252/11850 (epoch 43.257), train_loss = 0.97381426, grad/param norm = 3.4811e-01, time/batch = 18.1231s	
10253/11850 (epoch 43.262), train_loss = 0.98909527, grad/param norm = 4.6652e-01, time/batch = 19.8075s	
10254/11850 (epoch 43.266), train_loss = 0.98324932, grad/param norm = 3.8055e-01, time/batch = 15.8576s	
10255/11850 (epoch 43.270), train_loss = 0.85348035, grad/param norm = 2.7505e-01, time/batch = 19.3881s	
10256/11850 (epoch 43.274), train_loss = 0.85061895, grad/param norm = 3.1023e-01, time/batch = 19.4662s	
10257/11850 (epoch 43.278), train_loss = 0.76411567, grad/param norm = 3.4797e-01, time/batch = 15.6753s	
10258/11850 (epoch 43.283), train_loss = 0.86201537, grad/param norm = 2.9392e-01, time/batch = 19.2954s	
10259/11850 (epoch 43.287), train_loss = 0.98332797, grad/param norm = 2.9955e-01, time/batch = 16.9770s	
10260/11850 (epoch 43.291), train_loss = 0.86139438, grad/param norm = 3.7945e-01, time/batch = 17.5426s	
10261/11850 (epoch 43.295), train_loss = 0.89510264, grad/param norm = 2.7748e-01, time/batch = 18.3084s	
10262/11850 (epoch 43.300), train_loss = 0.83949722, grad/param norm = 3.6305e-01, time/batch = 17.9057s	
10263/11850 (epoch 43.304), train_loss = 0.86330528, grad/param norm = 2.6349e-01, time/batch = 17.3900s	
10264/11850 (epoch 43.308), train_loss = 0.87223844, grad/param norm = 3.1718e-01, time/batch = 16.8658s	
10265/11850 (epoch 43.312), train_loss = 0.76854285, grad/param norm = 2.9413e-01, time/batch = 15.7930s	
10266/11850 (epoch 43.316), train_loss = 0.85473832, grad/param norm = 2.5460e-01, time/batch = 16.4168s	
10267/11850 (epoch 43.321), train_loss = 0.83031096, grad/param norm = 2.9583e-01, time/batch = 17.1381s	
10268/11850 (epoch 43.325), train_loss = 0.87746623, grad/param norm = 2.9997e-01, time/batch = 17.6394s	
10269/11850 (epoch 43.329), train_loss = 0.85436186, grad/param norm = 3.2932e-01, time/batch = 17.2103s	
10270/11850 (epoch 43.333), train_loss = 0.84783920, grad/param norm = 3.2025e-01, time/batch = 17.8090s	
10271/11850 (epoch 43.338), train_loss = 0.82914391, grad/param norm = 2.7461e-01, time/batch = 18.0362s	
10272/11850 (epoch 43.342), train_loss = 0.85564439, grad/param norm = 3.1227e-01, time/batch = 17.9813s	
10273/11850 (epoch 43.346), train_loss = 0.83421482, grad/param norm = 3.1454e-01, time/batch = 18.6472s	
10274/11850 (epoch 43.350), train_loss = 0.76185677, grad/param norm = 2.7028e-01, time/batch = 16.0260s	
10275/11850 (epoch 43.354), train_loss = 0.90543555, grad/param norm = 2.9056e-01, time/batch = 18.8697s	
10276/11850 (epoch 43.359), train_loss = 0.99330189, grad/param norm = 4.3614e-01, time/batch = 17.3955s	
10277/11850 (epoch 43.363), train_loss = 0.88693732, grad/param norm = 3.0148e-01, time/batch = 17.7212s	
10278/11850 (epoch 43.367), train_loss = 0.92725788, grad/param norm = 2.9477e-01, time/batch = 18.1207s	
10279/11850 (epoch 43.371), train_loss = 0.92217806, grad/param norm = 2.9241e-01, time/batch = 18.5561s	
10280/11850 (epoch 43.376), train_loss = 0.87005862, grad/param norm = 2.7568e-01, time/batch = 17.8176s	
10281/11850 (epoch 43.380), train_loss = 0.83529686, grad/param norm = 2.8251e-01, time/batch = 17.6179s	
10282/11850 (epoch 43.384), train_loss = 0.78000077, grad/param norm = 2.9291e-01, time/batch = 17.1300s	
10283/11850 (epoch 43.388), train_loss = 0.91654323, grad/param norm = 3.1273e-01, time/batch = 17.1393s	
10284/11850 (epoch 43.392), train_loss = 0.88119452, grad/param norm = 3.1604e-01, time/batch = 17.7907s	
10285/11850 (epoch 43.397), train_loss = 0.89966400, grad/param norm = 2.9026e-01, time/batch = 15.8918s	
10286/11850 (epoch 43.401), train_loss = 0.74376875, grad/param norm = 2.6761e-01, time/batch = 16.9201s	
10287/11850 (epoch 43.405), train_loss = 0.78380587, grad/param norm = 3.3135e-01, time/batch = 17.6348s	
10288/11850 (epoch 43.409), train_loss = 0.88326931, grad/param norm = 3.0306e-01, time/batch = 15.8564s	
10289/11850 (epoch 43.414), train_loss = 0.70288093, grad/param norm = 2.4340e-01, time/batch = 17.7256s	
10290/11850 (epoch 43.418), train_loss = 0.76779130, grad/param norm = 3.8045e-01, time/batch = 17.1471s	
10291/11850 (epoch 43.422), train_loss = 0.70628023, grad/param norm = 2.6072e-01, time/batch = 17.2097s	
10292/11850 (epoch 43.426), train_loss = 0.70814827, grad/param norm = 2.8404e-01, time/batch = 19.1348s	
10293/11850 (epoch 43.430), train_loss = 0.75807093, grad/param norm = 2.8694e-01, time/batch = 18.4710s	
10294/11850 (epoch 43.435), train_loss = 0.79510996, grad/param norm = 2.7530e-01, time/batch = 17.3861s	
10295/11850 (epoch 43.439), train_loss = 0.87568222, grad/param norm = 2.7643e-01, time/batch = 17.9592s	
10296/11850 (epoch 43.443), train_loss = 0.85228290, grad/param norm = 3.4262e-01, time/batch = 17.5647s	
10297/11850 (epoch 43.447), train_loss = 0.77752888, grad/param norm = 3.0900e-01, time/batch = 15.4180s	
10298/11850 (epoch 43.451), train_loss = 0.73882941, grad/param norm = 2.5818e-01, time/batch = 16.9521s	
10299/11850 (epoch 43.456), train_loss = 0.85324693, grad/param norm = 3.5588e-01, time/batch = 19.3009s	
10300/11850 (epoch 43.460), train_loss = 0.88499246, grad/param norm = 3.1702e-01, time/batch = 16.6462s	
10301/11850 (epoch 43.464), train_loss = 0.80919924, grad/param norm = 3.9220e-01, time/batch = 16.9845s	
10302/11850 (epoch 43.468), train_loss = 0.87079173, grad/param norm = 3.2189e-01, time/batch = 17.3710s	
10303/11850 (epoch 43.473), train_loss = 0.91304636, grad/param norm = 3.4398e-01, time/batch = 16.8813s	
10304/11850 (epoch 43.477), train_loss = 0.77151602, grad/param norm = 3.1117e-01, time/batch = 18.8967s	
10305/11850 (epoch 43.481), train_loss = 0.79440444, grad/param norm = 3.8635e-01, time/batch = 16.7087s	
10306/11850 (epoch 43.485), train_loss = 0.74604253, grad/param norm = 2.7650e-01, time/batch = 17.1417s	
10307/11850 (epoch 43.489), train_loss = 0.85670786, grad/param norm = 4.0019e-01, time/batch = 18.9844s	
10308/11850 (epoch 43.494), train_loss = 0.75380265, grad/param norm = 2.8978e-01, time/batch = 17.2222s	
10309/11850 (epoch 43.498), train_loss = 0.76659998, grad/param norm = 3.7803e-01, time/batch = 16.9606s	
10310/11850 (epoch 43.502), train_loss = 0.74397681, grad/param norm = 3.3328e-01, time/batch = 15.9996s	
10311/11850 (epoch 43.506), train_loss = 0.97111047, grad/param norm = 2.9597e-01, time/batch = 18.6425s	
10312/11850 (epoch 43.511), train_loss = 0.82652215, grad/param norm = 3.3300e-01, time/batch = 17.3727s	
10313/11850 (epoch 43.515), train_loss = 0.93565695, grad/param norm = 3.6087e-01, time/batch = 17.4805s	
10314/11850 (epoch 43.519), train_loss = 0.79142115, grad/param norm = 3.0131e-01, time/batch = 18.8851s	
10315/11850 (epoch 43.523), train_loss = 0.84121397, grad/param norm = 3.2588e-01, time/batch = 15.8934s	
10316/11850 (epoch 43.527), train_loss = 0.79109818, grad/param norm = 2.9964e-01, time/batch = 17.9758s	
10317/11850 (epoch 43.532), train_loss = 0.83068259, grad/param norm = 2.6157e-01, time/batch = 16.6351s	
10318/11850 (epoch 43.536), train_loss = 0.80007219, grad/param norm = 2.8650e-01, time/batch = 17.8732s	
10319/11850 (epoch 43.540), train_loss = 0.73725407, grad/param norm = 3.0352e-01, time/batch = 17.0062s	
10320/11850 (epoch 43.544), train_loss = 0.76785517, grad/param norm = 3.4114e-01, time/batch = 16.5622s	
10321/11850 (epoch 43.549), train_loss = 0.71425911, grad/param norm = 2.5492e-01, time/batch = 18.6427s	
10322/11850 (epoch 43.553), train_loss = 0.82514040, grad/param norm = 2.9541e-01, time/batch = 16.3882s	
10323/11850 (epoch 43.557), train_loss = 0.87545120, grad/param norm = 3.4488e-01, time/batch = 17.4004s	
10324/11850 (epoch 43.561), train_loss = 0.89405467, grad/param norm = 3.5969e-01, time/batch = 15.2725s	
10325/11850 (epoch 43.565), train_loss = 0.97496361, grad/param norm = 3.7488e-01, time/batch = 17.5086s	
10326/11850 (epoch 43.570), train_loss = 0.87317871, grad/param norm = 2.8271e-01, time/batch = 18.1385s	
10327/11850 (epoch 43.574), train_loss = 0.88282321, grad/param norm = 2.9738e-01, time/batch = 17.3796s	
10328/11850 (epoch 43.578), train_loss = 0.90237975, grad/param norm = 3.1192e-01, time/batch = 18.4675s	
10329/11850 (epoch 43.582), train_loss = 0.82057164, grad/param norm = 3.4412e-01, time/batch = 16.7123s	
10330/11850 (epoch 43.586), train_loss = 0.83059757, grad/param norm = 3.0457e-01, time/batch = 18.5503s	
10331/11850 (epoch 43.591), train_loss = 0.85597001, grad/param norm = 3.6436e-01, time/batch = 17.3074s	
10332/11850 (epoch 43.595), train_loss = 0.72544230, grad/param norm = 3.2659e-01, time/batch = 17.0444s	
10333/11850 (epoch 43.599), train_loss = 0.82369941, grad/param norm = 3.1409e-01, time/batch = 16.4740s	
10334/11850 (epoch 43.603), train_loss = 0.78538038, grad/param norm = 2.4620e-01, time/batch = 18.3890s	
10335/11850 (epoch 43.608), train_loss = 0.94920251, grad/param norm = 2.9522e-01, time/batch = 18.8736s	
10336/11850 (epoch 43.612), train_loss = 1.01519612, grad/param norm = 3.8083e-01, time/batch = 17.6943s	
10337/11850 (epoch 43.616), train_loss = 0.95416202, grad/param norm = 2.9352e-01, time/batch = 15.3702s	
10338/11850 (epoch 43.620), train_loss = 0.83065486, grad/param norm = 3.0221e-01, time/batch = 19.1358s	
10339/11850 (epoch 43.624), train_loss = 0.83359573, grad/param norm = 3.9609e-01, time/batch = 16.1444s	
10340/11850 (epoch 43.629), train_loss = 0.83408097, grad/param norm = 3.3901e-01, time/batch = 18.9617s	
10341/11850 (epoch 43.633), train_loss = 0.75793756, grad/param norm = 2.8097e-01, time/batch = 17.3827s	
10342/11850 (epoch 43.637), train_loss = 0.67407182, grad/param norm = 2.5283e-01, time/batch = 14.9456s	
10343/11850 (epoch 43.641), train_loss = 0.73032003, grad/param norm = 2.7479e-01, time/batch = 14.6070s	
10344/11850 (epoch 43.646), train_loss = 0.74962599, grad/param norm = 3.0477e-01, time/batch = 18.0481s	
10345/11850 (epoch 43.650), train_loss = 0.83711157, grad/param norm = 3.4496e-01, time/batch = 18.0588s	
10346/11850 (epoch 43.654), train_loss = 0.78358846, grad/param norm = 3.0935e-01, time/batch = 17.4746s	
10347/11850 (epoch 43.658), train_loss = 0.86821677, grad/param norm = 2.8779e-01, time/batch = 18.7947s	
10348/11850 (epoch 43.662), train_loss = 0.72214168, grad/param norm = 3.3910e-01, time/batch = 16.8772s	
10349/11850 (epoch 43.667), train_loss = 0.91858295, grad/param norm = 2.8235e-01, time/batch = 17.4630s	
10350/11850 (epoch 43.671), train_loss = 0.79362760, grad/param norm = 3.1190e-01, time/batch = 15.8022s	
10351/11850 (epoch 43.675), train_loss = 0.80843872, grad/param norm = 2.8605e-01, time/batch = 14.4777s	
10352/11850 (epoch 43.679), train_loss = 0.81965723, grad/param norm = 2.7474e-01, time/batch = 14.1722s	
10353/11850 (epoch 43.684), train_loss = 0.79187109, grad/param norm = 3.1176e-01, time/batch = 17.8046s	
10354/11850 (epoch 43.688), train_loss = 0.76635196, grad/param norm = 2.9238e-01, time/batch = 18.5402s	
10355/11850 (epoch 43.692), train_loss = 0.78478295, grad/param norm = 3.3019e-01, time/batch = 16.9308s	
10356/11850 (epoch 43.696), train_loss = 0.75732331, grad/param norm = 3.9451e-01, time/batch = 16.2044s	
10357/11850 (epoch 43.700), train_loss = 0.82816734, grad/param norm = 2.8918e-01, time/batch = 16.8784s	
10358/11850 (epoch 43.705), train_loss = 0.73135197, grad/param norm = 3.0161e-01, time/batch = 14.2558s	
10359/11850 (epoch 43.709), train_loss = 0.71111818, grad/param norm = 2.9958e-01, time/batch = 16.5646s	
10360/11850 (epoch 43.713), train_loss = 0.72573282, grad/param norm = 3.2879e-01, time/batch = 16.9640s	
10361/11850 (epoch 43.717), train_loss = 0.78851792, grad/param norm = 2.8549e-01, time/batch = 18.0602s	
10362/11850 (epoch 43.722), train_loss = 0.82002991, grad/param norm = 3.8889e-01, time/batch = 18.3824s	
10363/11850 (epoch 43.726), train_loss = 0.77868366, grad/param norm = 5.2390e-01, time/batch = 18.2091s	
10364/11850 (epoch 43.730), train_loss = 0.75631187, grad/param norm = 3.2819e-01, time/batch = 16.3828s	
10365/11850 (epoch 43.734), train_loss = 0.73892340, grad/param norm = 2.9150e-01, time/batch = 17.4683s	
10366/11850 (epoch 43.738), train_loss = 0.85939300, grad/param norm = 3.4163e-01, time/batch = 17.7152s	
10367/11850 (epoch 43.743), train_loss = 0.81817494, grad/param norm = 3.0681e-01, time/batch = 16.9377s	
10368/11850 (epoch 43.747), train_loss = 0.75614008, grad/param norm = 3.1137e-01, time/batch = 16.0040s	
10369/11850 (epoch 43.751), train_loss = 0.78511448, grad/param norm = 2.7485e-01, time/batch = 17.5557s	
10370/11850 (epoch 43.755), train_loss = 0.83481117, grad/param norm = 3.0057e-01, time/batch = 18.4556s	
10371/11850 (epoch 43.759), train_loss = 0.74639878, grad/param norm = 2.5860e-01, time/batch = 16.7039s	
10372/11850 (epoch 43.764), train_loss = 0.80537203, grad/param norm = 2.7453e-01, time/batch = 16.5470s	
10373/11850 (epoch 43.768), train_loss = 0.73659000, grad/param norm = 2.7739e-01, time/batch = 19.0508s	
10374/11850 (epoch 43.772), train_loss = 0.80358123, grad/param norm = 4.1360e-01, time/batch = 16.9692s	
10375/11850 (epoch 43.776), train_loss = 0.83272071, grad/param norm = 3.3798e-01, time/batch = 16.9714s	
10376/11850 (epoch 43.781), train_loss = 0.77857754, grad/param norm = 2.8737e-01, time/batch = 18.0482s	
10377/11850 (epoch 43.785), train_loss = 0.80809304, grad/param norm = 3.1594e-01, time/batch = 18.7777s	
10378/11850 (epoch 43.789), train_loss = 0.77430959, grad/param norm = 2.8304e-01, time/batch = 18.7828s	
10379/11850 (epoch 43.793), train_loss = 0.84464993, grad/param norm = 3.0686e-01, time/batch = 18.3938s	
10380/11850 (epoch 43.797), train_loss = 0.79953159, grad/param norm = 3.4620e-01, time/batch = 15.3736s	
10381/11850 (epoch 43.802), train_loss = 0.75591356, grad/param norm = 3.5583e-01, time/batch = 16.9701s	
10382/11850 (epoch 43.806), train_loss = 0.82021381, grad/param norm = 3.3637e-01, time/batch = 18.2178s	
10383/11850 (epoch 43.810), train_loss = 0.86278621, grad/param norm = 3.4039e-01, time/batch = 18.6369s	
10384/11850 (epoch 43.814), train_loss = 0.83903111, grad/param norm = 3.2958e-01, time/batch = 17.0471s	
10385/11850 (epoch 43.819), train_loss = 0.92369855, grad/param norm = 3.3136e-01, time/batch = 17.2166s	
10386/11850 (epoch 43.823), train_loss = 0.89662080, grad/param norm = 2.9408e-01, time/batch = 16.5556s	
10387/11850 (epoch 43.827), train_loss = 0.80307725, grad/param norm = 3.0588e-01, time/batch = 17.8022s	
10388/11850 (epoch 43.831), train_loss = 0.76967549, grad/param norm = 3.1146e-01, time/batch = 17.3738s	
10389/11850 (epoch 43.835), train_loss = 0.85732127, grad/param norm = 2.6538e-01, time/batch = 15.4732s	
10390/11850 (epoch 43.840), train_loss = 0.78281510, grad/param norm = 2.9426e-01, time/batch = 17.0411s	
10391/11850 (epoch 43.844), train_loss = 0.82610775, grad/param norm = 2.5167e-01, time/batch = 17.4670s	
10392/11850 (epoch 43.848), train_loss = 0.84359757, grad/param norm = 2.9481e-01, time/batch = 17.7163s	
10393/11850 (epoch 43.852), train_loss = 0.83045674, grad/param norm = 2.9529e-01, time/batch = 17.2977s	
10394/11850 (epoch 43.857), train_loss = 0.80396889, grad/param norm = 3.2178e-01, time/batch = 19.1182s	
10395/11850 (epoch 43.861), train_loss = 0.75131121, grad/param norm = 3.0747e-01, time/batch = 18.2962s	
10396/11850 (epoch 43.865), train_loss = 0.86129837, grad/param norm = 3.7256e-01, time/batch = 17.4626s	
10397/11850 (epoch 43.869), train_loss = 0.83831712, grad/param norm = 3.1398e-01, time/batch = 18.6344s	
10398/11850 (epoch 43.873), train_loss = 0.83339585, grad/param norm = 3.3717e-01, time/batch = 17.4508s	
10399/11850 (epoch 43.878), train_loss = 0.85107798, grad/param norm = 3.3121e-01, time/batch = 18.7234s	
10400/11850 (epoch 43.882), train_loss = 0.85272005, grad/param norm = 3.5065e-01, time/batch = 17.5560s	
10401/11850 (epoch 43.886), train_loss = 0.80632950, grad/param norm = 3.8535e-01, time/batch = 17.3574s	
10402/11850 (epoch 43.890), train_loss = 0.82527958, grad/param norm = 3.1703e-01, time/batch = 16.1848s	
10403/11850 (epoch 43.895), train_loss = 0.83036428, grad/param norm = 3.6473e-01, time/batch = 16.8959s	
10404/11850 (epoch 43.899), train_loss = 0.74380046, grad/param norm = 3.1251e-01, time/batch = 16.2164s	
10405/11850 (epoch 43.903), train_loss = 0.76767184, grad/param norm = 3.0161e-01, time/batch = 16.8718s	
10406/11850 (epoch 43.907), train_loss = 0.78733289, grad/param norm = 2.5519e-01, time/batch = 14.9889s	
10407/11850 (epoch 43.911), train_loss = 0.90623887, grad/param norm = 3.2290e-01, time/batch = 16.9709s	
10408/11850 (epoch 43.916), train_loss = 0.86292801, grad/param norm = 3.7489e-01, time/batch = 16.9835s	
10409/11850 (epoch 43.920), train_loss = 0.83659001, grad/param norm = 3.0749e-01, time/batch = 17.9634s	
10410/11850 (epoch 43.924), train_loss = 0.80435090, grad/param norm = 3.3472e-01, time/batch = 15.9703s	
10411/11850 (epoch 43.928), train_loss = 0.87024231, grad/param norm = 5.6847e-01, time/batch = 18.4796s	
10412/11850 (epoch 43.932), train_loss = 0.95548353, grad/param norm = 4.1166e-01, time/batch = 17.5487s	
10413/11850 (epoch 43.937), train_loss = 0.92343130, grad/param norm = 3.2508e-01, time/batch = 18.8797s	
10414/11850 (epoch 43.941), train_loss = 0.84812361, grad/param norm = 3.2023e-01, time/batch = 15.0775s	
10415/11850 (epoch 43.945), train_loss = 0.85586362, grad/param norm = 3.1038e-01, time/batch = 16.3883s	
10416/11850 (epoch 43.949), train_loss = 0.80186786, grad/param norm = 3.5209e-01, time/batch = 18.4702s	
10417/11850 (epoch 43.954), train_loss = 0.89887149, grad/param norm = 4.7185e-01, time/batch = 18.4592s	
10418/11850 (epoch 43.958), train_loss = 0.87756022, grad/param norm = 3.4565e-01, time/batch = 17.3160s	
10419/11850 (epoch 43.962), train_loss = 0.79180379, grad/param norm = 3.4349e-01, time/batch = 16.0289s	
10420/11850 (epoch 43.966), train_loss = 0.74280759, grad/param norm = 3.3751e-01, time/batch = 16.8878s	
10421/11850 (epoch 43.970), train_loss = 0.88217917, grad/param norm = 3.1371e-01, time/batch = 17.3070s	
10422/11850 (epoch 43.975), train_loss = 0.83017227, grad/param norm = 3.5649e-01, time/batch = 17.4697s	
10423/11850 (epoch 43.979), train_loss = 0.86980333, grad/param norm = 3.6851e-01, time/batch = 17.5204s	
10424/11850 (epoch 43.983), train_loss = 0.92614605, grad/param norm = 3.5098e-01, time/batch = 16.0417s	
10425/11850 (epoch 43.987), train_loss = 0.80891479, grad/param norm = 3.7900e-01, time/batch = 17.7942s	
10426/11850 (epoch 43.992), train_loss = 0.94286317, grad/param norm = 3.2371e-01, time/batch = 15.4452s	
10427/11850 (epoch 43.996), train_loss = 0.95253363, grad/param norm = 3.7304e-01, time/batch = 17.2363s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
10428/11850 (epoch 44.000), train_loss = 0.83348352, grad/param norm = 3.7337e-01, time/batch = 18.8091s	
10429/11850 (epoch 44.004), train_loss = 0.90102841, grad/param norm = 3.2277e-01, time/batch = 17.7174s	
10430/11850 (epoch 44.008), train_loss = 0.91971608, grad/param norm = 3.0660e-01, time/batch = 15.7297s	
10431/11850 (epoch 44.013), train_loss = 0.93486715, grad/param norm = 2.9896e-01, time/batch = 18.8005s	
10432/11850 (epoch 44.017), train_loss = 0.97573661, grad/param norm = 3.5667e-01, time/batch = 18.8759s	
10433/11850 (epoch 44.021), train_loss = 0.92494930, grad/param norm = 3.3197e-01, time/batch = 18.4445s	
10434/11850 (epoch 44.025), train_loss = 0.79573373, grad/param norm = 2.6255e-01, time/batch = 15.3903s	
10435/11850 (epoch 44.030), train_loss = 0.84961438, grad/param norm = 3.3999e-01, time/batch = 18.8700s	
10436/11850 (epoch 44.034), train_loss = 0.81506437, grad/param norm = 3.0597e-01, time/batch = 16.8847s	
10437/11850 (epoch 44.038), train_loss = 0.82099346, grad/param norm = 2.9647e-01, time/batch = 17.6298s	
10438/11850 (epoch 44.042), train_loss = 0.86277299, grad/param norm = 3.1390e-01, time/batch = 17.3886s	
10439/11850 (epoch 44.046), train_loss = 0.83293965, grad/param norm = 3.9591e-01, time/batch = 18.1328s	
10440/11850 (epoch 44.051), train_loss = 0.84509006, grad/param norm = 3.1380e-01, time/batch = 18.1832s	
10441/11850 (epoch 44.055), train_loss = 0.80370152, grad/param norm = 2.9500e-01, time/batch = 16.9355s	
10442/11850 (epoch 44.059), train_loss = 0.88812671, grad/param norm = 3.1545e-01, time/batch = 19.8002s	
10443/11850 (epoch 44.063), train_loss = 0.95005400, grad/param norm = 3.4623e-01, time/batch = 18.3648s	
10444/11850 (epoch 44.068), train_loss = 0.84138372, grad/param norm = 2.8385e-01, time/batch = 17.6397s	
10445/11850 (epoch 44.072), train_loss = 0.90399124, grad/param norm = 3.2916e-01, time/batch = 18.3012s	
10446/11850 (epoch 44.076), train_loss = 0.96655097, grad/param norm = 3.2903e-01, time/batch = 15.7294s	
10447/11850 (epoch 44.080), train_loss = 0.78201280, grad/param norm = 2.9760e-01, time/batch = 18.3138s	
10448/11850 (epoch 44.084), train_loss = 0.76288380, grad/param norm = 2.9001e-01, time/batch = 17.3914s	
10449/11850 (epoch 44.089), train_loss = 0.75742022, grad/param norm = 2.9391e-01, time/batch = 17.6977s	
10450/11850 (epoch 44.093), train_loss = 0.77564553, grad/param norm = 3.5812e-01, time/batch = 18.5449s	
10451/11850 (epoch 44.097), train_loss = 0.83555036, grad/param norm = 2.8126e-01, time/batch = 17.7235s	
10452/11850 (epoch 44.101), train_loss = 0.75539033, grad/param norm = 3.5732e-01, time/batch = 16.5493s	
10453/11850 (epoch 44.105), train_loss = 0.76198237, grad/param norm = 2.6940e-01, time/batch = 29.7865s	
10454/11850 (epoch 44.110), train_loss = 0.91269367, grad/param norm = 3.0268e-01, time/batch = 17.1399s	
10455/11850 (epoch 44.114), train_loss = 0.77933539, grad/param norm = 2.9609e-01, time/batch = 17.3988s	
10456/11850 (epoch 44.118), train_loss = 0.89714080, grad/param norm = 2.8886e-01, time/batch = 16.4226s	
10457/11850 (epoch 44.122), train_loss = 0.94057649, grad/param norm = 3.2259e-01, time/batch = 15.0432s	
10458/11850 (epoch 44.127), train_loss = 0.89893903, grad/param norm = 3.1978e-01, time/batch = 18.1418s	
10459/11850 (epoch 44.131), train_loss = 0.83925834, grad/param norm = 3.4606e-01, time/batch = 16.3978s	
10460/11850 (epoch 44.135), train_loss = 0.85787538, grad/param norm = 3.2289e-01, time/batch = 17.9837s	
10461/11850 (epoch 44.139), train_loss = 0.82306607, grad/param norm = 3.0318e-01, time/batch = 16.0626s	
10462/11850 (epoch 44.143), train_loss = 0.81534601, grad/param norm = 3.3545e-01, time/batch = 14.5618s	
10463/11850 (epoch 44.148), train_loss = 0.83008858, grad/param norm = 2.8583e-01, time/batch = 15.3045s	
10464/11850 (epoch 44.152), train_loss = 0.91401501, grad/param norm = 3.3620e-01, time/batch = 18.4676s	
10465/11850 (epoch 44.156), train_loss = 0.79870073, grad/param norm = 3.3270e-01, time/batch = 17.5603s	
10466/11850 (epoch 44.160), train_loss = 0.99037926, grad/param norm = 3.8216e-01, time/batch = 15.0585s	
10467/11850 (epoch 44.165), train_loss = 0.91714516, grad/param norm = 3.4832e-01, time/batch = 17.3097s	
10468/11850 (epoch 44.169), train_loss = 0.82731859, grad/param norm = 3.4264e-01, time/batch = 18.6241s	
10469/11850 (epoch 44.173), train_loss = 0.90519648, grad/param norm = 3.4303e-01, time/batch = 18.3799s	
10470/11850 (epoch 44.177), train_loss = 0.73909798, grad/param norm = 2.9365e-01, time/batch = 16.2106s	
10471/11850 (epoch 44.181), train_loss = 0.85721008, grad/param norm = 3.2059e-01, time/batch = 15.0399s	
10472/11850 (epoch 44.186), train_loss = 0.94141528, grad/param norm = 3.6723e-01, time/batch = 17.4753s	
10473/11850 (epoch 44.190), train_loss = 0.88132239, grad/param norm = 3.1030e-01, time/batch = 17.2873s	
10474/11850 (epoch 44.194), train_loss = 0.85858530, grad/param norm = 3.4658e-01, time/batch = 18.1003s	
10475/11850 (epoch 44.198), train_loss = 0.73186618, grad/param norm = 3.9985e-01, time/batch = 15.7669s	
10476/11850 (epoch 44.203), train_loss = 0.73260143, grad/param norm = 3.1737e-01, time/batch = 19.0635s	
10477/11850 (epoch 44.207), train_loss = 0.89478419, grad/param norm = 4.2523e-01, time/batch = 17.8721s	
10478/11850 (epoch 44.211), train_loss = 0.81814806, grad/param norm = 2.9979e-01, time/batch = 17.6403s	
10479/11850 (epoch 44.215), train_loss = 0.86665746, grad/param norm = 3.2759e-01, time/batch = 19.9500s	
10480/11850 (epoch 44.219), train_loss = 0.87887480, grad/param norm = 3.2482e-01, time/batch = 16.2217s	
10481/11850 (epoch 44.224), train_loss = 0.98367649, grad/param norm = 3.3430e-01, time/batch = 19.0488s	
10482/11850 (epoch 44.228), train_loss = 0.90128855, grad/param norm = 3.5378e-01, time/batch = 19.1186s	
10483/11850 (epoch 44.232), train_loss = 0.87002957, grad/param norm = 3.6378e-01, time/batch = 17.5304s	
10484/11850 (epoch 44.236), train_loss = 0.80989319, grad/param norm = 3.0878e-01, time/batch = 15.2240s	
10485/11850 (epoch 44.241), train_loss = 0.91059624, grad/param norm = 3.3987e-01, time/batch = 16.8708s	
10486/11850 (epoch 44.245), train_loss = 0.91524695, grad/param norm = 3.4882e-01, time/batch = 18.9566s	
10487/11850 (epoch 44.249), train_loss = 0.84985690, grad/param norm = 3.1951e-01, time/batch = 15.2269s	
10488/11850 (epoch 44.253), train_loss = 0.84733656, grad/param norm = 3.4018e-01, time/batch = 17.5617s	
10489/11850 (epoch 44.257), train_loss = 0.97526066, grad/param norm = 3.6638e-01, time/batch = 15.6242s	
10490/11850 (epoch 44.262), train_loss = 0.98981408, grad/param norm = 4.5521e-01, time/batch = 17.0552s	
10491/11850 (epoch 44.266), train_loss = 0.97070223, grad/param norm = 4.1128e-01, time/batch = 17.4775s	
10492/11850 (epoch 44.270), train_loss = 0.85232383, grad/param norm = 2.9534e-01, time/batch = 15.6471s	
10493/11850 (epoch 44.274), train_loss = 0.84393660, grad/param norm = 3.5555e-01, time/batch = 16.1459s	
10494/11850 (epoch 44.278), train_loss = 0.75155444, grad/param norm = 2.9867e-01, time/batch = 15.5462s	
10495/11850 (epoch 44.283), train_loss = 0.85899354, grad/param norm = 3.0939e-01, time/batch = 17.9773s	
10496/11850 (epoch 44.287), train_loss = 0.96606609, grad/param norm = 3.0661e-01, time/batch = 17.7202s	
10497/11850 (epoch 44.291), train_loss = 0.84002628, grad/param norm = 3.0910e-01, time/batch = 17.4027s	
10498/11850 (epoch 44.295), train_loss = 0.89764050, grad/param norm = 2.9629e-01, time/batch = 18.2001s	
10499/11850 (epoch 44.300), train_loss = 0.81672190, grad/param norm = 3.4645e-01, time/batch = 17.9009s	
10500/11850 (epoch 44.304), train_loss = 0.85679183, grad/param norm = 3.2019e-01, time/batch = 18.2922s	
10501/11850 (epoch 44.308), train_loss = 0.85637204, grad/param norm = 3.0859e-01, time/batch = 16.2975s	
10502/11850 (epoch 44.312), train_loss = 0.75966810, grad/param norm = 2.7470e-01, time/batch = 19.1403s	
10503/11850 (epoch 44.316), train_loss = 0.84196689, grad/param norm = 2.5154e-01, time/batch = 18.2264s	
10504/11850 (epoch 44.321), train_loss = 0.80700668, grad/param norm = 2.6121e-01, time/batch = 17.2900s	
10505/11850 (epoch 44.325), train_loss = 0.86709454, grad/param norm = 3.3751e-01, time/batch = 17.7743s	
10506/11850 (epoch 44.329), train_loss = 0.85390061, grad/param norm = 3.2967e-01, time/batch = 15.6326s	
10507/11850 (epoch 44.333), train_loss = 0.83605776, grad/param norm = 3.2363e-01, time/batch = 18.8750s	
10508/11850 (epoch 44.338), train_loss = 0.82381740, grad/param norm = 2.8681e-01, time/batch = 16.7142s	
10509/11850 (epoch 44.342), train_loss = 0.84977623, grad/param norm = 3.2953e-01, time/batch = 17.0326s	
10510/11850 (epoch 44.346), train_loss = 0.82108285, grad/param norm = 2.8522e-01, time/batch = 16.1582s	
10511/11850 (epoch 44.350), train_loss = 0.75062500, grad/param norm = 2.6594e-01, time/batch = 17.7965s	
10512/11850 (epoch 44.354), train_loss = 0.88424365, grad/param norm = 2.8428e-01, time/batch = 18.3770s	
10513/11850 (epoch 44.359), train_loss = 0.96911776, grad/param norm = 3.1090e-01, time/batch = 17.1959s	
10514/11850 (epoch 44.363), train_loss = 0.87460836, grad/param norm = 2.8596e-01, time/batch = 17.7539s	
10515/11850 (epoch 44.367), train_loss = 0.89356102, grad/param norm = 2.7680e-01, time/batch = 16.7018s	
10516/11850 (epoch 44.371), train_loss = 0.90605127, grad/param norm = 2.9680e-01, time/batch = 18.2007s	
10517/11850 (epoch 44.376), train_loss = 0.86980655, grad/param norm = 3.4455e-01, time/batch = 16.7116s	
10518/11850 (epoch 44.380), train_loss = 0.81648818, grad/param norm = 2.7258e-01, time/batch = 17.4676s	
10519/11850 (epoch 44.384), train_loss = 0.75411543, grad/param norm = 2.7612e-01, time/batch = 16.6603s	
10520/11850 (epoch 44.388), train_loss = 0.90106432, grad/param norm = 3.0388e-01, time/batch = 18.5476s	
10521/11850 (epoch 44.392), train_loss = 0.87286377, grad/param norm = 3.2571e-01, time/batch = 17.8740s	
10522/11850 (epoch 44.397), train_loss = 0.88537355, grad/param norm = 2.9964e-01, time/batch = 18.3002s	
10523/11850 (epoch 44.401), train_loss = 0.73064952, grad/param norm = 2.5090e-01, time/batch = 17.1548s	
10524/11850 (epoch 44.405), train_loss = 0.77445518, grad/param norm = 2.9350e-01, time/batch = 17.4716s	
10525/11850 (epoch 44.409), train_loss = 0.87002421, grad/param norm = 2.9740e-01, time/batch = 17.7039s	
10526/11850 (epoch 44.414), train_loss = 0.71942645, grad/param norm = 3.1699e-01, time/batch = 16.3038s	
10527/11850 (epoch 44.418), train_loss = 0.74463052, grad/param norm = 2.7216e-01, time/batch = 18.0451s	
10528/11850 (epoch 44.422), train_loss = 0.68775175, grad/param norm = 3.0782e-01, time/batch = 18.3800s	
10529/11850 (epoch 44.426), train_loss = 0.69880350, grad/param norm = 3.1245e-01, time/batch = 16.3079s	
10530/11850 (epoch 44.430), train_loss = 0.75483971, grad/param norm = 3.0432e-01, time/batch = 17.2209s	
10531/11850 (epoch 44.435), train_loss = 0.78530220, grad/param norm = 2.5928e-01, time/batch = 17.2831s	
10532/11850 (epoch 44.439), train_loss = 0.86862261, grad/param norm = 2.8375e-01, time/batch = 18.7799s	
10533/11850 (epoch 44.443), train_loss = 0.82835983, grad/param norm = 3.0999e-01, time/batch = 18.2190s	
10534/11850 (epoch 44.447), train_loss = 0.74239722, grad/param norm = 2.7977e-01, time/batch = 18.0664s	
10535/11850 (epoch 44.451), train_loss = 0.73042361, grad/param norm = 2.6711e-01, time/batch = 17.2978s	
10536/11850 (epoch 44.456), train_loss = 0.82243013, grad/param norm = 3.4361e-01, time/batch = 18.8049s	
10537/11850 (epoch 44.460), train_loss = 0.86597333, grad/param norm = 2.6863e-01, time/batch = 17.1433s	
10538/11850 (epoch 44.464), train_loss = 0.78631816, grad/param norm = 3.0915e-01, time/batch = 16.6368s	
10539/11850 (epoch 44.468), train_loss = 0.86804041, grad/param norm = 3.1640e-01, time/batch = 15.4469s	
10540/11850 (epoch 44.473), train_loss = 0.90978306, grad/param norm = 3.8797e-01, time/batch = 16.4865s	
10541/11850 (epoch 44.477), train_loss = 0.75536096, grad/param norm = 3.1986e-01, time/batch = 18.5566s	
10542/11850 (epoch 44.481), train_loss = 0.78531273, grad/param norm = 3.2292e-01, time/batch = 16.3642s	
10543/11850 (epoch 44.485), train_loss = 0.74112321, grad/param norm = 2.5751e-01, time/batch = 16.7274s	
10544/11850 (epoch 44.489), train_loss = 0.84148269, grad/param norm = 3.0325e-01, time/batch = 19.2190s	
10545/11850 (epoch 44.494), train_loss = 0.74872012, grad/param norm = 2.8950e-01, time/batch = 16.4696s	
10546/11850 (epoch 44.498), train_loss = 0.75701142, grad/param norm = 2.9874e-01, time/batch = 19.5427s	
10547/11850 (epoch 44.502), train_loss = 0.71377428, grad/param norm = 3.0859e-01, time/batch = 18.3074s	
10548/11850 (epoch 44.506), train_loss = 0.95620060, grad/param norm = 2.9091e-01, time/batch = 15.1810s	
10549/11850 (epoch 44.511), train_loss = 0.80298944, grad/param norm = 2.7094e-01, time/batch = 17.2166s	
10550/11850 (epoch 44.515), train_loss = 0.90260646, grad/param norm = 3.4246e-01, time/batch = 18.4672s	
10551/11850 (epoch 44.519), train_loss = 0.78600372, grad/param norm = 3.0552e-01, time/batch = 17.8893s	
10552/11850 (epoch 44.523), train_loss = 0.81567587, grad/param norm = 2.9842e-01, time/batch = 17.1309s	
10553/11850 (epoch 44.527), train_loss = 0.76339532, grad/param norm = 2.8016e-01, time/batch = 18.2115s	
10554/11850 (epoch 44.532), train_loss = 0.82500551, grad/param norm = 2.9629e-01, time/batch = 18.7239s	
10555/11850 (epoch 44.536), train_loss = 0.78131618, grad/param norm = 2.9984e-01, time/batch = 17.7864s	
10556/11850 (epoch 44.540), train_loss = 0.73144784, grad/param norm = 2.8967e-01, time/batch = 15.9713s	
10557/11850 (epoch 44.544), train_loss = 0.75084585, grad/param norm = 3.5077e-01, time/batch = 17.4680s	
10558/11850 (epoch 44.549), train_loss = 0.70323021, grad/param norm = 2.8024e-01, time/batch = 18.7155s	
10559/11850 (epoch 44.553), train_loss = 0.81955113, grad/param norm = 2.8691e-01, time/batch = 16.7975s	
10560/11850 (epoch 44.557), train_loss = 0.87261704, grad/param norm = 5.0740e-01, time/batch = 16.8060s	
10561/11850 (epoch 44.561), train_loss = 0.87763461, grad/param norm = 3.0257e-01, time/batch = 18.7048s	
10562/11850 (epoch 44.565), train_loss = 0.96112735, grad/param norm = 3.9036e-01, time/batch = 17.3713s	
10563/11850 (epoch 44.570), train_loss = 0.84376782, grad/param norm = 2.7417e-01, time/batch = 19.3846s	
10564/11850 (epoch 44.574), train_loss = 0.87260972, grad/param norm = 3.2120e-01, time/batch = 17.0156s	
10565/11850 (epoch 44.578), train_loss = 0.88128321, grad/param norm = 3.0652e-01, time/batch = 18.4645s	
10566/11850 (epoch 44.582), train_loss = 0.79675164, grad/param norm = 3.0490e-01, time/batch = 18.3013s	
10567/11850 (epoch 44.586), train_loss = 0.82037757, grad/param norm = 3.1561e-01, time/batch = 17.9765s	
10568/11850 (epoch 44.591), train_loss = 0.83917675, grad/param norm = 3.8212e-01, time/batch = 18.4686s	
10569/11850 (epoch 44.595), train_loss = 0.69913266, grad/param norm = 2.7724e-01, time/batch = 17.2809s	
10570/11850 (epoch 44.599), train_loss = 0.81503043, grad/param norm = 3.0867e-01, time/batch = 14.3403s	
10571/11850 (epoch 44.603), train_loss = 0.77785854, grad/param norm = 2.6500e-01, time/batch = 18.3009s	
10572/11850 (epoch 44.608), train_loss = 0.95903397, grad/param norm = 3.6670e-01, time/batch = 16.9244s	
10573/11850 (epoch 44.612), train_loss = 1.00050589, grad/param norm = 3.7393e-01, time/batch = 19.5289s	
10574/11850 (epoch 44.616), train_loss = 0.95467380, grad/param norm = 3.8704e-01, time/batch = 17.4711s	
10575/11850 (epoch 44.620), train_loss = 0.81180825, grad/param norm = 3.5370e-01, time/batch = 17.3569s	
10576/11850 (epoch 44.624), train_loss = 0.82625884, grad/param norm = 4.0216e-01, time/batch = 17.8697s	
10577/11850 (epoch 44.629), train_loss = 0.81074564, grad/param norm = 2.8327e-01, time/batch = 17.0411s	
10578/11850 (epoch 44.633), train_loss = 0.75382392, grad/param norm = 2.8385e-01, time/batch = 16.5602s	
10579/11850 (epoch 44.637), train_loss = 0.67258696, grad/param norm = 2.6750e-01, time/batch = 16.6459s	
10580/11850 (epoch 44.641), train_loss = 0.70650810, grad/param norm = 2.6270e-01, time/batch = 17.2244s	
10581/11850 (epoch 44.646), train_loss = 0.75800438, grad/param norm = 3.2628e-01, time/batch = 18.6284s	
10582/11850 (epoch 44.650), train_loss = 0.84654496, grad/param norm = 3.5270e-01, time/batch = 18.4559s	
10583/11850 (epoch 44.654), train_loss = 0.77669429, grad/param norm = 2.7913e-01, time/batch = 17.9559s	
10584/11850 (epoch 44.658), train_loss = 0.85492297, grad/param norm = 2.8293e-01, time/batch = 18.1297s	
10585/11850 (epoch 44.662), train_loss = 0.73957058, grad/param norm = 4.3746e-01, time/batch = 18.6233s	
10586/11850 (epoch 44.667), train_loss = 0.89443255, grad/param norm = 2.8705e-01, time/batch = 15.4729s	
10587/11850 (epoch 44.671), train_loss = 0.78696649, grad/param norm = 2.8909e-01, time/batch = 18.1401s	
10588/11850 (epoch 44.675), train_loss = 0.79623245, grad/param norm = 2.9495e-01, time/batch = 18.0646s	
10589/11850 (epoch 44.679), train_loss = 0.81294342, grad/param norm = 2.8134e-01, time/batch = 16.7142s	
10590/11850 (epoch 44.684), train_loss = 0.78594484, grad/param norm = 3.7078e-01, time/batch = 17.7207s	
10591/11850 (epoch 44.688), train_loss = 0.75155806, grad/param norm = 2.7455e-01, time/batch = 17.5683s	
10592/11850 (epoch 44.692), train_loss = 0.77477079, grad/param norm = 3.5145e-01, time/batch = 18.3767s	
10593/11850 (epoch 44.696), train_loss = 0.75040520, grad/param norm = 4.0013e-01, time/batch = 18.1256s	
10594/11850 (epoch 44.700), train_loss = 0.80184185, grad/param norm = 2.9435e-01, time/batch = 15.4198s	
10595/11850 (epoch 44.705), train_loss = 0.73063185, grad/param norm = 2.7818e-01, time/batch = 17.4505s	
10596/11850 (epoch 44.709), train_loss = 0.70303680, grad/param norm = 2.8384e-01, time/batch = 17.5667s	
10597/11850 (epoch 44.713), train_loss = 0.70617503, grad/param norm = 2.9348e-01, time/batch = 18.5605s	
10598/11850 (epoch 44.717), train_loss = 0.76949737, grad/param norm = 2.6038e-01, time/batch = 18.1338s	
10599/11850 (epoch 44.722), train_loss = 0.79157297, grad/param norm = 3.2491e-01, time/batch = 18.3029s	
10600/11850 (epoch 44.726), train_loss = 0.74256971, grad/param norm = 2.9168e-01, time/batch = 17.4014s	
10601/11850 (epoch 44.730), train_loss = 0.74051803, grad/param norm = 3.8081e-01, time/batch = 17.1378s	
10602/11850 (epoch 44.734), train_loss = 0.73269348, grad/param norm = 3.0864e-01, time/batch = 18.2335s	
10603/11850 (epoch 44.738), train_loss = 0.83748577, grad/param norm = 4.2709e-01, time/batch = 17.0523s	
10604/11850 (epoch 44.743), train_loss = 0.81940778, grad/param norm = 3.7919e-01, time/batch = 15.9892s	
10605/11850 (epoch 44.747), train_loss = 0.72999073, grad/param norm = 2.5710e-01, time/batch = 18.2118s	
10606/11850 (epoch 44.751), train_loss = 0.79359771, grad/param norm = 2.8496e-01, time/batch = 17.0395s	
10607/11850 (epoch 44.755), train_loss = 0.83398381, grad/param norm = 2.8808e-01, time/batch = 17.5661s	
10608/11850 (epoch 44.759), train_loss = 0.75449169, grad/param norm = 3.0541e-01, time/batch = 16.8188s	
10609/11850 (epoch 44.764), train_loss = 0.79082929, grad/param norm = 2.7886e-01, time/batch = 16.6487s	
10610/11850 (epoch 44.768), train_loss = 0.72407721, grad/param norm = 2.8107e-01, time/batch = 17.8572s	
10611/11850 (epoch 44.772), train_loss = 0.77810471, grad/param norm = 3.4730e-01, time/batch = 15.3887s	
10612/11850 (epoch 44.776), train_loss = 0.81211268, grad/param norm = 3.0048e-01, time/batch = 14.9022s	
10613/11850 (epoch 44.781), train_loss = 0.78473602, grad/param norm = 3.6389e-01, time/batch = 17.7138s	
10614/11850 (epoch 44.785), train_loss = 0.80939180, grad/param norm = 3.3588e-01, time/batch = 16.3657s	
10615/11850 (epoch 44.789), train_loss = 0.76893607, grad/param norm = 2.8189e-01, time/batch = 18.1363s	
10616/11850 (epoch 44.793), train_loss = 0.82340032, grad/param norm = 3.0126e-01, time/batch = 16.3715s	
10617/11850 (epoch 44.797), train_loss = 0.77497001, grad/param norm = 3.0149e-01, time/batch = 17.4593s	
10618/11850 (epoch 44.802), train_loss = 0.74104154, grad/param norm = 3.3318e-01, time/batch = 18.7284s	
10619/11850 (epoch 44.806), train_loss = 0.79429487, grad/param norm = 2.9728e-01, time/batch = 15.9378s	
10620/11850 (epoch 44.810), train_loss = 0.84903499, grad/param norm = 3.6499e-01, time/batch = 17.0364s	
10621/11850 (epoch 44.814), train_loss = 0.81398041, grad/param norm = 3.0055e-01, time/batch = 19.7149s	
10622/11850 (epoch 44.819), train_loss = 0.90250615, grad/param norm = 3.1599e-01, time/batch = 18.7131s	
10623/11850 (epoch 44.823), train_loss = 0.88911356, grad/param norm = 3.3522e-01, time/batch = 17.5424s	
10624/11850 (epoch 44.827), train_loss = 0.80018296, grad/param norm = 3.3144e-01, time/batch = 18.9328s	
10625/11850 (epoch 44.831), train_loss = 0.75764802, grad/param norm = 2.8826e-01, time/batch = 17.0525s	
10626/11850 (epoch 44.835), train_loss = 0.84170936, grad/param norm = 2.7724e-01, time/batch = 18.2977s	
10627/11850 (epoch 44.840), train_loss = 0.78643858, grad/param norm = 3.0000e-01, time/batch = 16.8866s	
10628/11850 (epoch 44.844), train_loss = 0.82099914, grad/param norm = 2.7673e-01, time/batch = 17.0453s	
10629/11850 (epoch 44.848), train_loss = 0.82826563, grad/param norm = 3.1038e-01, time/batch = 17.3090s	
10630/11850 (epoch 44.852), train_loss = 0.81682317, grad/param norm = 2.7608e-01, time/batch = 17.7199s	
10631/11850 (epoch 44.857), train_loss = 0.81126158, grad/param norm = 3.5322e-01, time/batch = 19.3607s	
10632/11850 (epoch 44.861), train_loss = 0.74513971, grad/param norm = 3.5319e-01, time/batch = 18.3121s	
10633/11850 (epoch 44.865), train_loss = 0.86681913, grad/param norm = 3.8149e-01, time/batch = 18.7816s	
10634/11850 (epoch 44.869), train_loss = 0.82261736, grad/param norm = 3.0774e-01, time/batch = 15.8451s	
10635/11850 (epoch 44.873), train_loss = 0.81439681, grad/param norm = 3.1632e-01, time/batch = 17.7857s	
10636/11850 (epoch 44.878), train_loss = 0.84098405, grad/param norm = 2.9640e-01, time/batch = 17.7154s	
10637/11850 (epoch 44.882), train_loss = 0.83312855, grad/param norm = 2.9115e-01, time/batch = 16.0528s	
10638/11850 (epoch 44.886), train_loss = 0.79155849, grad/param norm = 3.8669e-01, time/batch = 18.3103s	
10639/11850 (epoch 44.890), train_loss = 0.81350404, grad/param norm = 3.2984e-01, time/batch = 15.4906s	
10640/11850 (epoch 44.895), train_loss = 0.81976673, grad/param norm = 3.6483e-01, time/batch = 17.5602s	
10641/11850 (epoch 44.899), train_loss = 0.74172162, grad/param norm = 3.3129e-01, time/batch = 18.0357s	
10642/11850 (epoch 44.903), train_loss = 0.75569880, grad/param norm = 2.9469e-01, time/batch = 18.0544s	
10643/11850 (epoch 44.907), train_loss = 0.78264048, grad/param norm = 3.1413e-01, time/batch = 18.7748s	
10644/11850 (epoch 44.911), train_loss = 0.89805215, grad/param norm = 2.9280e-01, time/batch = 16.5407s	
10645/11850 (epoch 44.916), train_loss = 0.84907945, grad/param norm = 3.3666e-01, time/batch = 16.8830s	
10646/11850 (epoch 44.920), train_loss = 0.81960688, grad/param norm = 3.0993e-01, time/batch = 15.9672s	
10647/11850 (epoch 44.924), train_loss = 0.79014815, grad/param norm = 3.5200e-01, time/batch = 17.0127s	
10648/11850 (epoch 44.928), train_loss = 0.86272486, grad/param norm = 3.8039e-01, time/batch = 16.8000s	
10649/11850 (epoch 44.932), train_loss = 0.92980549, grad/param norm = 3.8383e-01, time/batch = 18.0529s	
10650/11850 (epoch 44.937), train_loss = 0.90059684, grad/param norm = 3.1440e-01, time/batch = 19.2205s	
10651/11850 (epoch 44.941), train_loss = 0.83368984, grad/param norm = 3.0548e-01, time/batch = 16.6356s	
10652/11850 (epoch 44.945), train_loss = 0.83977985, grad/param norm = 2.8222e-01, time/batch = 19.5443s	
10653/11850 (epoch 44.949), train_loss = 0.78424354, grad/param norm = 3.5133e-01, time/batch = 18.2167s	
10654/11850 (epoch 44.954), train_loss = 0.87963812, grad/param norm = 3.8262e-01, time/batch = 17.5415s	
10655/11850 (epoch 44.958), train_loss = 0.87210703, grad/param norm = 3.5686e-01, time/batch = 19.1312s	
10656/11850 (epoch 44.962), train_loss = 0.79732620, grad/param norm = 3.7072e-01, time/batch = 16.0619s	
10657/11850 (epoch 44.966), train_loss = 0.74187364, grad/param norm = 4.7407e-01, time/batch = 18.9394s	
10658/11850 (epoch 44.970), train_loss = 0.86642888, grad/param norm = 3.0463e-01, time/batch = 30.2526s	
10659/11850 (epoch 44.975), train_loss = 0.81558453, grad/param norm = 3.3236e-01, time/batch = 15.4133s	
10660/11850 (epoch 44.979), train_loss = 0.83833102, grad/param norm = 3.1609e-01, time/batch = 16.6920s	
10661/11850 (epoch 44.983), train_loss = 0.91372998, grad/param norm = 3.6964e-01, time/batch = 17.6489s	
10662/11850 (epoch 44.987), train_loss = 0.77800463, grad/param norm = 3.2817e-01, time/batch = 17.4674s	
10663/11850 (epoch 44.992), train_loss = 0.91703106, grad/param norm = 2.8913e-01, time/batch = 17.8100s	
10664/11850 (epoch 44.996), train_loss = 0.91217408, grad/param norm = 2.9112e-01, time/batch = 17.1299s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
10665/11850 (epoch 45.000), train_loss = 0.80681345, grad/param norm = 3.2997e-01, time/batch = 17.4853s	
10666/11850 (epoch 45.004), train_loss = 0.88901352, grad/param norm = 3.5150e-01, time/batch = 17.3933s	
10667/11850 (epoch 45.008), train_loss = 0.90512011, grad/param norm = 3.0043e-01, time/batch = 14.9229s	
10668/11850 (epoch 45.013), train_loss = 0.93445448, grad/param norm = 4.3134e-01, time/batch = 16.6400s	
10669/11850 (epoch 45.017), train_loss = 0.96787795, grad/param norm = 3.9344e-01, time/batch = 18.2255s	
10670/11850 (epoch 45.021), train_loss = 0.91993292, grad/param norm = 3.3672e-01, time/batch = 18.1493s	
10671/11850 (epoch 45.025), train_loss = 0.80020996, grad/param norm = 3.1094e-01, time/batch = 18.2123s	
10672/11850 (epoch 45.030), train_loss = 0.84226249, grad/param norm = 3.4711e-01, time/batch = 17.3095s	
10673/11850 (epoch 45.034), train_loss = 0.81319761, grad/param norm = 3.2810e-01, time/batch = 18.3101s	
10674/11850 (epoch 45.038), train_loss = 0.81902717, grad/param norm = 2.8992e-01, time/batch = 15.6231s	
10675/11850 (epoch 45.042), train_loss = 0.85577837, grad/param norm = 3.1915e-01, time/batch = 16.1252s	
10676/11850 (epoch 45.046), train_loss = 0.81589199, grad/param norm = 3.3286e-01, time/batch = 17.7090s	
10677/11850 (epoch 45.051), train_loss = 0.83527599, grad/param norm = 2.9582e-01, time/batch = 18.0471s	
10678/11850 (epoch 45.055), train_loss = 0.79388620, grad/param norm = 2.7762e-01, time/batch = 17.9697s	
10679/11850 (epoch 45.059), train_loss = 0.87752595, grad/param norm = 3.2930e-01, time/batch = 16.4603s	
10680/11850 (epoch 45.063), train_loss = 0.94648578, grad/param norm = 3.3202e-01, time/batch = 17.1468s	
10681/11850 (epoch 45.068), train_loss = 0.83105902, grad/param norm = 2.9537e-01, time/batch = 16.8055s	
10682/11850 (epoch 45.072), train_loss = 0.89953270, grad/param norm = 3.2030e-01, time/batch = 17.6381s	
10683/11850 (epoch 45.076), train_loss = 0.95764897, grad/param norm = 3.5010e-01, time/batch = 15.6960s	
10684/11850 (epoch 45.080), train_loss = 0.77173123, grad/param norm = 2.8364e-01, time/batch = 17.0697s	
10685/11850 (epoch 45.084), train_loss = 0.74859724, grad/param norm = 2.7723e-01, time/batch = 15.0778s	
10686/11850 (epoch 45.089), train_loss = 0.74245716, grad/param norm = 3.2811e-01, time/batch = 17.0618s	
10687/11850 (epoch 45.093), train_loss = 0.77035730, grad/param norm = 3.4961e-01, time/batch = 18.2337s	
10688/11850 (epoch 45.097), train_loss = 0.82930394, grad/param norm = 3.2254e-01, time/batch = 16.3042s	
10689/11850 (epoch 45.101), train_loss = 0.74342178, grad/param norm = 3.3382e-01, time/batch = 17.3960s	
10690/11850 (epoch 45.105), train_loss = 0.76255603, grad/param norm = 2.6728e-01, time/batch = 17.9608s	
10691/11850 (epoch 45.110), train_loss = 0.89610997, grad/param norm = 2.9912e-01, time/batch = 18.3659s	
10692/11850 (epoch 45.114), train_loss = 0.76622266, grad/param norm = 3.1822e-01, time/batch = 16.7090s	
10693/11850 (epoch 45.118), train_loss = 0.88624226, grad/param norm = 2.8686e-01, time/batch = 16.9019s	
10694/11850 (epoch 45.122), train_loss = 0.94516674, grad/param norm = 3.5637e-01, time/batch = 18.6239s	
10695/11850 (epoch 45.127), train_loss = 0.88644842, grad/param norm = 3.2874e-01, time/batch = 15.9580s	
10696/11850 (epoch 45.131), train_loss = 0.83641023, grad/param norm = 3.4600e-01, time/batch = 17.4562s	
10697/11850 (epoch 45.135), train_loss = 0.84704806, grad/param norm = 3.3336e-01, time/batch = 16.7738s	
10698/11850 (epoch 45.139), train_loss = 0.81798308, grad/param norm = 2.9788e-01, time/batch = 18.2102s	
10699/11850 (epoch 45.143), train_loss = 0.80339509, grad/param norm = 2.8254e-01, time/batch = 17.3665s	
10700/11850 (epoch 45.148), train_loss = 0.80573658, grad/param norm = 3.0390e-01, time/batch = 17.7336s	
10701/11850 (epoch 45.152), train_loss = 0.91069866, grad/param norm = 3.3604e-01, time/batch = 17.4667s	
10702/11850 (epoch 45.156), train_loss = 0.79112762, grad/param norm = 3.5702e-01, time/batch = 16.3606s	
10703/11850 (epoch 45.160), train_loss = 0.97524578, grad/param norm = 3.7508e-01, time/batch = 18.2279s	
10704/11850 (epoch 45.165), train_loss = 0.89046104, grad/param norm = 3.4184e-01, time/batch = 18.0460s	
10705/11850 (epoch 45.169), train_loss = 0.81993940, grad/param norm = 3.3545e-01, time/batch = 17.2055s	
10706/11850 (epoch 45.173), train_loss = 0.90396288, grad/param norm = 3.8306e-01, time/batch = 18.4622s	
10707/11850 (epoch 45.177), train_loss = 0.74969236, grad/param norm = 3.6420e-01, time/batch = 17.4791s	
10708/11850 (epoch 45.181), train_loss = 0.84533482, grad/param norm = 4.2439e-01, time/batch = 17.9583s	
10709/11850 (epoch 45.186), train_loss = 0.92437914, grad/param norm = 3.7966e-01, time/batch = 17.9431s	
10710/11850 (epoch 45.190), train_loss = 0.87210043, grad/param norm = 3.3099e-01, time/batch = 16.7287s	
10711/11850 (epoch 45.194), train_loss = 0.86133785, grad/param norm = 4.5470e-01, time/batch = 16.6056s	
10712/11850 (epoch 45.198), train_loss = 0.70556462, grad/param norm = 3.1130e-01, time/batch = 16.5420s	
10713/11850 (epoch 45.203), train_loss = 0.72683549, grad/param norm = 3.3628e-01, time/batch = 17.8848s	
10714/11850 (epoch 45.207), train_loss = 0.88179488, grad/param norm = 3.6203e-01, time/batch = 15.8089s	
10715/11850 (epoch 45.211), train_loss = 0.80893106, grad/param norm = 3.6247e-01, time/batch = 18.2114s	
10716/11850 (epoch 45.215), train_loss = 0.86264063, grad/param norm = 3.5330e-01, time/batch = 18.4541s	
10717/11850 (epoch 45.219), train_loss = 0.86029047, grad/param norm = 3.1186e-01, time/batch = 15.4664s	
10718/11850 (epoch 45.224), train_loss = 0.95623777, grad/param norm = 2.9661e-01, time/batch = 17.3871s	
10719/11850 (epoch 45.228), train_loss = 0.87558984, grad/param norm = 3.4881e-01, time/batch = 16.7001s	
10720/11850 (epoch 45.232), train_loss = 0.86727077, grad/param norm = 3.3345e-01, time/batch = 19.4611s	
10721/11850 (epoch 45.236), train_loss = 0.79508444, grad/param norm = 3.3018e-01, time/batch = 18.0492s	
10722/11850 (epoch 45.241), train_loss = 0.88815938, grad/param norm = 3.0411e-01, time/batch = 18.1098s	
10723/11850 (epoch 45.245), train_loss = 0.90687626, grad/param norm = 3.1761e-01, time/batch = 17.6248s	
10724/11850 (epoch 45.249), train_loss = 0.84556768, grad/param norm = 3.0696e-01, time/batch = 18.3912s	
10725/11850 (epoch 45.253), train_loss = 0.82729682, grad/param norm = 2.9950e-01, time/batch = 18.3052s	
10726/11850 (epoch 45.257), train_loss = 0.94921836, grad/param norm = 3.5271e-01, time/batch = 15.8066s	
10727/11850 (epoch 45.262), train_loss = 1.00517530, grad/param norm = 8.7564e-01, time/batch = 17.8839s	
10728/11850 (epoch 45.266), train_loss = 0.96987010, grad/param norm = 4.1068e-01, time/batch = 17.3097s	
10729/11850 (epoch 45.270), train_loss = 0.83705468, grad/param norm = 2.7395e-01, time/batch = 17.4577s	
10730/11850 (epoch 45.274), train_loss = 0.83350815, grad/param norm = 3.2912e-01, time/batch = 16.8079s	
10731/11850 (epoch 45.278), train_loss = 0.74087195, grad/param norm = 3.0576e-01, time/batch = 17.5380s	
10732/11850 (epoch 45.283), train_loss = 0.85177881, grad/param norm = 2.7081e-01, time/batch = 18.1388s	
10733/11850 (epoch 45.287), train_loss = 0.95318407, grad/param norm = 3.2068e-01, time/batch = 16.7239s	
10734/11850 (epoch 45.291), train_loss = 0.82823918, grad/param norm = 3.0534e-01, time/batch = 17.9730s	
10735/11850 (epoch 45.295), train_loss = 0.87388284, grad/param norm = 3.0958e-01, time/batch = 18.8748s	
10736/11850 (epoch 45.300), train_loss = 0.81667491, grad/param norm = 3.6150e-01, time/batch = 18.0484s	
10737/11850 (epoch 45.304), train_loss = 0.85611959, grad/param norm = 2.9821e-01, time/batch = 18.7934s	
10738/11850 (epoch 45.308), train_loss = 0.85931099, grad/param norm = 3.2679e-01, time/batch = 18.0386s	
10739/11850 (epoch 45.312), train_loss = 0.74964041, grad/param norm = 2.7813e-01, time/batch = 15.0989s	
10740/11850 (epoch 45.316), train_loss = 0.83760304, grad/param norm = 2.6587e-01, time/batch = 17.9618s	
10741/11850 (epoch 45.321), train_loss = 0.80586011, grad/param norm = 2.8562e-01, time/batch = 18.6314s	
10742/11850 (epoch 45.325), train_loss = 0.84912147, grad/param norm = 3.0399e-01, time/batch = 18.7786s	
10743/11850 (epoch 45.329), train_loss = 0.84407252, grad/param norm = 3.2408e-01, time/batch = 20.5613s	
10744/11850 (epoch 45.333), train_loss = 0.82163926, grad/param norm = 3.1583e-01, time/batch = 22.8088s	
10745/11850 (epoch 45.338), train_loss = 0.81931131, grad/param norm = 2.9657e-01, time/batch = 27.5211s	
10746/11850 (epoch 45.342), train_loss = 0.83825093, grad/param norm = 3.1799e-01, time/batch = 25.7885s	
10747/11850 (epoch 45.346), train_loss = 0.82290665, grad/param norm = 3.9965e-01, time/batch = 26.6938s	
10748/11850 (epoch 45.350), train_loss = 0.74206252, grad/param norm = 2.6417e-01, time/batch = 26.6424s	
10749/11850 (epoch 45.354), train_loss = 0.88156403, grad/param norm = 3.2998e-01, time/batch = 27.6106s	
10750/11850 (epoch 45.359), train_loss = 0.95769251, grad/param norm = 3.2574e-01, time/batch = 21.1466s	
10751/11850 (epoch 45.363), train_loss = 0.87752046, grad/param norm = 3.1769e-01, time/batch = 28.2848s	
10752/11850 (epoch 45.367), train_loss = 0.89846103, grad/param norm = 3.0973e-01, time/batch = 23.7845s	
10753/11850 (epoch 45.371), train_loss = 0.89893371, grad/param norm = 2.8237e-01, time/batch = 25.5327s	
10754/11850 (epoch 45.376), train_loss = 0.86208887, grad/param norm = 2.7909e-01, time/batch = 22.3087s	
10755/11850 (epoch 45.380), train_loss = 0.82772662, grad/param norm = 3.0848e-01, time/batch = 23.4713s	
10756/11850 (epoch 45.384), train_loss = 0.74315928, grad/param norm = 2.6169e-01, time/batch = 23.5626s	
10757/11850 (epoch 45.388), train_loss = 0.88984420, grad/param norm = 3.2196e-01, time/batch = 24.2930s	
10758/11850 (epoch 45.392), train_loss = 0.86185819, grad/param norm = 3.1791e-01, time/batch = 24.2103s	
10759/11850 (epoch 45.397), train_loss = 0.87653640, grad/param norm = 3.0724e-01, time/batch = 25.9298s	
10760/11850 (epoch 45.401), train_loss = 0.72697467, grad/param norm = 2.9353e-01, time/batch = 26.1692s	
10761/11850 (epoch 45.405), train_loss = 0.76791973, grad/param norm = 3.6946e-01, time/batch = 32.5452s	
10762/11850 (epoch 45.409), train_loss = 0.86655896, grad/param norm = 3.1603e-01, time/batch = 17.0108s	
10763/11850 (epoch 45.414), train_loss = 0.70388930, grad/param norm = 2.6978e-01, time/batch = 14.9099s	
10764/11850 (epoch 45.418), train_loss = 0.73036822, grad/param norm = 2.5785e-01, time/batch = 18.3758s	
10765/11850 (epoch 45.422), train_loss = 0.68411528, grad/param norm = 2.7222e-01, time/batch = 17.3767s	
10766/11850 (epoch 45.426), train_loss = 0.68913870, grad/param norm = 2.9884e-01, time/batch = 18.3798s	
10767/11850 (epoch 45.430), train_loss = 0.73505420, grad/param norm = 2.9844e-01, time/batch = 16.1821s	
10768/11850 (epoch 45.435), train_loss = 0.77412447, grad/param norm = 2.7509e-01, time/batch = 17.6251s	
10769/11850 (epoch 45.439), train_loss = 0.85579405, grad/param norm = 2.8163e-01, time/batch = 17.2840s	
10770/11850 (epoch 45.443), train_loss = 0.81673179, grad/param norm = 3.0371e-01, time/batch = 17.6350s	
10771/11850 (epoch 45.447), train_loss = 0.73623846, grad/param norm = 2.7778e-01, time/batch = 16.4804s	
10772/11850 (epoch 45.451), train_loss = 0.72558770, grad/param norm = 2.9329e-01, time/batch = 15.1046s	
10773/11850 (epoch 45.456), train_loss = 0.82678711, grad/param norm = 3.6502e-01, time/batch = 16.9536s	
10774/11850 (epoch 45.460), train_loss = 0.87493513, grad/param norm = 3.3310e-01, time/batch = 14.4576s	
10775/11850 (epoch 45.464), train_loss = 0.78522249, grad/param norm = 3.5497e-01, time/batch = 14.1259s	
10776/11850 (epoch 45.468), train_loss = 0.86234179, grad/param norm = 3.3948e-01, time/batch = 15.0301s	
10777/11850 (epoch 45.473), train_loss = 0.89430126, grad/param norm = 3.9049e-01, time/batch = 14.1352s	
10778/11850 (epoch 45.477), train_loss = 0.75242048, grad/param norm = 3.0637e-01, time/batch = 13.6868s	
10779/11850 (epoch 45.481), train_loss = 0.77837508, grad/param norm = 2.8062e-01, time/batch = 14.3166s	
10780/11850 (epoch 45.485), train_loss = 0.72448474, grad/param norm = 2.6116e-01, time/batch = 15.7966s	
10781/11850 (epoch 45.489), train_loss = 0.83074789, grad/param norm = 3.2662e-01, time/batch = 18.4574s	
10782/11850 (epoch 45.494), train_loss = 0.74736969, grad/param norm = 4.8750e-01, time/batch = 18.1400s	
10783/11850 (epoch 45.498), train_loss = 0.76796363, grad/param norm = 5.0990e-01, time/batch = 17.8756s	
10784/11850 (epoch 45.502), train_loss = 0.72108266, grad/param norm = 3.3897e-01, time/batch = 17.4675s	
10785/11850 (epoch 45.506), train_loss = 0.95128778, grad/param norm = 3.8177e-01, time/batch = 18.7188s	
10786/11850 (epoch 45.511), train_loss = 0.81044173, grad/param norm = 3.7073e-01, time/batch = 18.2164s	
10787/11850 (epoch 45.515), train_loss = 0.88999459, grad/param norm = 3.5807e-01, time/batch = 7.6154s	
10788/11850 (epoch 45.519), train_loss = 0.77239172, grad/param norm = 3.1956e-01, time/batch = 0.6381s	
10789/11850 (epoch 45.523), train_loss = 0.80742114, grad/param norm = 2.7913e-01, time/batch = 0.6368s	
10790/11850 (epoch 45.527), train_loss = 0.76607212, grad/param norm = 3.6024e-01, time/batch = 0.6392s	
10791/11850 (epoch 45.532), train_loss = 0.82397114, grad/param norm = 2.9456e-01, time/batch = 0.6554s	
10792/11850 (epoch 45.536), train_loss = 0.76937811, grad/param norm = 2.8914e-01, time/batch = 0.6509s	
10793/11850 (epoch 45.540), train_loss = 0.70827249, grad/param norm = 3.1935e-01, time/batch = 0.6431s	
10794/11850 (epoch 45.544), train_loss = 0.74553752, grad/param norm = 3.5076e-01, time/batch = 0.6423s	
10795/11850 (epoch 45.549), train_loss = 0.70032940, grad/param norm = 2.9035e-01, time/batch = 0.8858s	
10796/11850 (epoch 45.553), train_loss = 0.80741021, grad/param norm = 2.7425e-01, time/batch = 0.9420s	
10797/11850 (epoch 45.557), train_loss = 0.86984184, grad/param norm = 3.4792e-01, time/batch = 0.9316s	
10798/11850 (epoch 45.561), train_loss = 0.87221361, grad/param norm = 3.3269e-01, time/batch = 0.9308s	
10799/11850 (epoch 45.565), train_loss = 0.93977883, grad/param norm = 3.3428e-01, time/batch = 0.9406s	
10800/11850 (epoch 45.570), train_loss = 0.83908624, grad/param norm = 2.8238e-01, time/batch = 1.3227s	
10801/11850 (epoch 45.574), train_loss = 0.85979652, grad/param norm = 3.5545e-01, time/batch = 1.7408s	
10802/11850 (epoch 45.578), train_loss = 0.87371091, grad/param norm = 3.2566e-01, time/batch = 1.7459s	
10803/11850 (epoch 45.582), train_loss = 0.79936222, grad/param norm = 3.1458e-01, time/batch = 13.4715s	
10804/11850 (epoch 45.586), train_loss = 0.82171743, grad/param norm = 2.7709e-01, time/batch = 16.5558s	
10805/11850 (epoch 45.591), train_loss = 0.83710432, grad/param norm = 3.6371e-01, time/batch = 14.5669s	
10806/11850 (epoch 45.595), train_loss = 0.70182087, grad/param norm = 3.2254e-01, time/batch = 16.0661s	
10807/11850 (epoch 45.599), train_loss = 0.79200553, grad/param norm = 3.0441e-01, time/batch = 14.7059s	
10808/11850 (epoch 45.603), train_loss = 0.76629528, grad/param norm = 2.6634e-01, time/batch = 16.5925s	
10809/11850 (epoch 45.608), train_loss = 0.95099803, grad/param norm = 3.2243e-01, time/batch = 17.2872s	
10810/11850 (epoch 45.612), train_loss = 0.98122708, grad/param norm = 3.4525e-01, time/batch = 17.3036s	
10811/11850 (epoch 45.616), train_loss = 0.92328705, grad/param norm = 3.0577e-01, time/batch = 19.5501s	
10812/11850 (epoch 45.620), train_loss = 0.79887940, grad/param norm = 3.0066e-01, time/batch = 17.7813s	
10813/11850 (epoch 45.624), train_loss = 0.78716930, grad/param norm = 3.6469e-01, time/batch = 16.8776s	
10814/11850 (epoch 45.629), train_loss = 0.80120603, grad/param norm = 2.8530e-01, time/batch = 19.0445s	
10815/11850 (epoch 45.633), train_loss = 0.73919683, grad/param norm = 2.6868e-01, time/batch = 18.3804s	
10816/11850 (epoch 45.637), train_loss = 0.66111195, grad/param norm = 2.5302e-01, time/batch = 17.7111s	
10817/11850 (epoch 45.641), train_loss = 0.69852497, grad/param norm = 2.6265e-01, time/batch = 17.9520s	
10818/11850 (epoch 45.646), train_loss = 0.72534723, grad/param norm = 2.9236e-01, time/batch = 18.5553s	
10819/11850 (epoch 45.650), train_loss = 0.80786995, grad/param norm = 3.3536e-01, time/batch = 16.0559s	
10820/11850 (epoch 45.654), train_loss = 0.77275877, grad/param norm = 3.7238e-01, time/batch = 17.8025s	
10821/11850 (epoch 45.658), train_loss = 0.85181230, grad/param norm = 2.9554e-01, time/batch = 16.9688s	
10822/11850 (epoch 45.662), train_loss = 0.72706391, grad/param norm = 4.1390e-01, time/batch = 17.2245s	
10823/11850 (epoch 45.667), train_loss = 0.88936867, grad/param norm = 2.9137e-01, time/batch = 17.4503s	
10824/11850 (epoch 45.671), train_loss = 0.77745004, grad/param norm = 3.0575e-01, time/batch = 16.0189s	
10825/11850 (epoch 45.675), train_loss = 0.79348304, grad/param norm = 3.3723e-01, time/batch = 17.0563s	
10826/11850 (epoch 45.679), train_loss = 0.79577172, grad/param norm = 2.5775e-01, time/batch = 16.4695s	
10827/11850 (epoch 45.684), train_loss = 0.78417480, grad/param norm = 3.2646e-01, time/batch = 17.8082s	
10828/11850 (epoch 45.688), train_loss = 0.74364714, grad/param norm = 3.0669e-01, time/batch = 17.9677s	
10829/11850 (epoch 45.692), train_loss = 0.77244295, grad/param norm = 5.0604e-01, time/batch = 14.4603s	
10830/11850 (epoch 45.696), train_loss = 0.73693583, grad/param norm = 3.4726e-01, time/batch = 16.6296s	
10831/11850 (epoch 45.700), train_loss = 0.80883680, grad/param norm = 2.8299e-01, time/batch = 17.1284s	
10832/11850 (epoch 45.705), train_loss = 0.70677646, grad/param norm = 3.0709e-01, time/batch = 18.1365s	
10833/11850 (epoch 45.709), train_loss = 0.70663423, grad/param norm = 3.3290e-01, time/batch = 15.8112s	
10834/11850 (epoch 45.713), train_loss = 0.70907834, grad/param norm = 3.2446e-01, time/batch = 18.8834s	
10835/11850 (epoch 45.717), train_loss = 0.75942392, grad/param norm = 2.7879e-01, time/batch = 16.5499s	
10836/11850 (epoch 45.722), train_loss = 0.79462120, grad/param norm = 3.1645e-01, time/batch = 17.4458s	
10837/11850 (epoch 45.726), train_loss = 0.72764217, grad/param norm = 3.0936e-01, time/batch = 16.6205s	
10838/11850 (epoch 45.730), train_loss = 0.72810298, grad/param norm = 3.2970e-01, time/batch = 15.3110s	
10839/11850 (epoch 45.734), train_loss = 0.72547162, grad/param norm = 3.2468e-01, time/batch = 16.8854s	
10840/11850 (epoch 45.738), train_loss = 0.84190613, grad/param norm = 4.3260e-01, time/batch = 18.0340s	
10841/11850 (epoch 45.743), train_loss = 0.80388456, grad/param norm = 3.3188e-01, time/batch = 17.2910s	
10842/11850 (epoch 45.747), train_loss = 0.73155018, grad/param norm = 2.9063e-01, time/batch = 16.6325s	
10843/11850 (epoch 45.751), train_loss = 0.78266349, grad/param norm = 2.8168e-01, time/batch = 17.7900s	
10844/11850 (epoch 45.755), train_loss = 0.81228068, grad/param norm = 2.9643e-01, time/batch = 18.1235s	
10845/11850 (epoch 45.759), train_loss = 0.72074124, grad/param norm = 2.5024e-01, time/batch = 15.8872s	
10846/11850 (epoch 45.764), train_loss = 0.78030719, grad/param norm = 3.0142e-01, time/batch = 16.9581s	
10847/11850 (epoch 45.768), train_loss = 0.71619496, grad/param norm = 2.7172e-01, time/batch = 15.7682s	
10848/11850 (epoch 45.772), train_loss = 0.77815261, grad/param norm = 3.4680e-01, time/batch = 17.9650s	
10849/11850 (epoch 45.776), train_loss = 0.80359072, grad/param norm = 3.1250e-01, time/batch = 18.2245s	
10850/11850 (epoch 45.781), train_loss = 0.75909767, grad/param norm = 2.8083e-01, time/batch = 17.6241s	
10851/11850 (epoch 45.785), train_loss = 0.79149219, grad/param norm = 3.7231e-01, time/batch = 18.7932s	
10852/11850 (epoch 45.789), train_loss = 0.75527190, grad/param norm = 2.9743e-01, time/batch = 18.1337s	
10853/11850 (epoch 45.793), train_loss = 0.82653903, grad/param norm = 3.1303e-01, time/batch = 19.1325s	
10854/11850 (epoch 45.797), train_loss = 0.78307308, grad/param norm = 3.5800e-01, time/batch = 16.1716s	
10855/11850 (epoch 45.802), train_loss = 0.72962481, grad/param norm = 3.2439e-01, time/batch = 18.0560s	
10856/11850 (epoch 45.806), train_loss = 0.78982912, grad/param norm = 3.1700e-01, time/batch = 16.7417s	
10857/11850 (epoch 45.810), train_loss = 0.83941786, grad/param norm = 3.1378e-01, time/batch = 16.8874s	
10858/11850 (epoch 45.814), train_loss = 0.80645627, grad/param norm = 3.0919e-01, time/batch = 17.3884s	
10859/11850 (epoch 45.819), train_loss = 0.89030295, grad/param norm = 3.4188e-01, time/batch = 17.4587s	
10860/11850 (epoch 45.823), train_loss = 0.88523253, grad/param norm = 3.7198e-01, time/batch = 17.9779s	
10861/11850 (epoch 45.827), train_loss = 0.79794504, grad/param norm = 3.5831e-01, time/batch = 17.4776s	
10862/11850 (epoch 45.831), train_loss = 0.75785227, grad/param norm = 3.4530e-01, time/batch = 18.4569s	
10863/11850 (epoch 45.835), train_loss = 0.83674516, grad/param norm = 3.0411e-01, time/batch = 16.8278s	
10864/11850 (epoch 45.840), train_loss = 0.76451639, grad/param norm = 2.9408e-01, time/batch = 16.1547s	
10865/11850 (epoch 45.844), train_loss = 0.81360842, grad/param norm = 3.1174e-01, time/batch = 16.8883s	
10866/11850 (epoch 45.848), train_loss = 0.83568853, grad/param norm = 3.5809e-01, time/batch = 17.7332s	
10867/11850 (epoch 45.852), train_loss = 0.81534314, grad/param norm = 3.2035e-01, time/batch = 17.6527s	
10868/11850 (epoch 45.857), train_loss = 0.79634460, grad/param norm = 3.4273e-01, time/batch = 18.5430s	
10869/11850 (epoch 45.861), train_loss = 0.74153217, grad/param norm = 3.2149e-01, time/batch = 17.1363s	
10870/11850 (epoch 45.865), train_loss = 0.83777504, grad/param norm = 4.0598e-01, time/batch = 16.4593s	
10871/11850 (epoch 45.869), train_loss = 0.81903879, grad/param norm = 3.4934e-01, time/batch = 24.3779s	
10872/11850 (epoch 45.873), train_loss = 0.80252815, grad/param norm = 3.1439e-01, time/batch = 26.3543s	
10873/11850 (epoch 45.878), train_loss = 0.83745818, grad/param norm = 3.3469e-01, time/batch = 17.4616s	
10874/11850 (epoch 45.882), train_loss = 0.82383968, grad/param norm = 3.0723e-01, time/batch = 17.6320s	
10875/11850 (epoch 45.886), train_loss = 0.78795437, grad/param norm = 3.7473e-01, time/batch = 14.1583s	
10876/11850 (epoch 45.890), train_loss = 0.81876626, grad/param norm = 5.6105e-01, time/batch = 16.4430s	
10877/11850 (epoch 45.895), train_loss = 0.80924016, grad/param norm = 4.0406e-01, time/batch = 16.9637s	
10878/11850 (epoch 45.899), train_loss = 0.72898263, grad/param norm = 2.9956e-01, time/batch = 18.4535s	
10879/11850 (epoch 45.903), train_loss = 0.75880511, grad/param norm = 3.2205e-01, time/batch = 18.9631s	
10880/11850 (epoch 45.907), train_loss = 0.77611777, grad/param norm = 3.1418e-01, time/batch = 16.9676s	
10881/11850 (epoch 45.911), train_loss = 0.88809911, grad/param norm = 3.0246e-01, time/batch = 16.4730s	
10882/11850 (epoch 45.916), train_loss = 0.84045647, grad/param norm = 3.5971e-01, time/batch = 16.6518s	
10883/11850 (epoch 45.920), train_loss = 0.80968813, grad/param norm = 3.0287e-01, time/batch = 14.8258s	
10884/11850 (epoch 45.924), train_loss = 0.78778810, grad/param norm = 3.7486e-01, time/batch = 14.4851s	
10885/11850 (epoch 45.928), train_loss = 0.82596882, grad/param norm = 3.2128e-01, time/batch = 17.5610s	
10886/11850 (epoch 45.932), train_loss = 0.91684598, grad/param norm = 3.3770e-01, time/batch = 16.4763s	
10887/11850 (epoch 45.937), train_loss = 0.88844166, grad/param norm = 3.3067e-01, time/batch = 18.7191s	
10888/11850 (epoch 45.941), train_loss = 0.81675283, grad/param norm = 2.9367e-01, time/batch = 17.7672s	
10889/11850 (epoch 45.945), train_loss = 0.83011108, grad/param norm = 3.2545e-01, time/batch = 16.6151s	
10890/11850 (epoch 45.949), train_loss = 0.78891347, grad/param norm = 4.3421e-01, time/batch = 16.8838s	
10891/11850 (epoch 45.954), train_loss = 0.85771950, grad/param norm = 3.9915e-01, time/batch = 17.8877s	
10892/11850 (epoch 45.958), train_loss = 0.86104531, grad/param norm = 3.6718e-01, time/batch = 17.9390s	
10893/11850 (epoch 45.962), train_loss = 0.76494150, grad/param norm = 3.6312e-01, time/batch = 18.0404s	
10894/11850 (epoch 45.966), train_loss = 0.71460927, grad/param norm = 3.3016e-01, time/batch = 17.2257s	
10895/11850 (epoch 45.970), train_loss = 0.84944942, grad/param norm = 3.2593e-01, time/batch = 17.5327s	
10896/11850 (epoch 45.975), train_loss = 0.79768007, grad/param norm = 2.9743e-01, time/batch = 18.3968s	
10897/11850 (epoch 45.979), train_loss = 0.84176318, grad/param norm = 3.7259e-01, time/batch = 18.7200s	
10898/11850 (epoch 45.983), train_loss = 0.89145973, grad/param norm = 3.5254e-01, time/batch = 18.1149s	
10899/11850 (epoch 45.987), train_loss = 0.77056289, grad/param norm = 3.3252e-01, time/batch = 19.4687s	
10900/11850 (epoch 45.992), train_loss = 0.92064005, grad/param norm = 3.4223e-01, time/batch = 18.1332s	
10901/11850 (epoch 45.996), train_loss = 0.91381913, grad/param norm = 3.3457e-01, time/batch = 17.1631s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
10902/11850 (epoch 46.000), train_loss = 0.80424156, grad/param norm = 3.3123e-01, time/batch = 17.3002s	
10903/11850 (epoch 46.004), train_loss = 0.87368177, grad/param norm = 3.9233e-01, time/batch = 18.8913s	
10904/11850 (epoch 46.008), train_loss = 0.90047707, grad/param norm = 3.2537e-01, time/batch = 17.2210s	
10905/11850 (epoch 46.013), train_loss = 0.91984268, grad/param norm = 3.3505e-01, time/batch = 15.5685s	
10906/11850 (epoch 46.017), train_loss = 0.96318275, grad/param norm = 4.8157e-01, time/batch = 16.8932s	
10907/11850 (epoch 46.021), train_loss = 0.92049907, grad/param norm = 3.4979e-01, time/batch = 18.9521s	
10908/11850 (epoch 46.025), train_loss = 0.79003897, grad/param norm = 2.7183e-01, time/batch = 16.7076s	
10909/11850 (epoch 46.030), train_loss = 0.82123420, grad/param norm = 3.1867e-01, time/batch = 16.7973s	
10910/11850 (epoch 46.034), train_loss = 0.80160188, grad/param norm = 3.5836e-01, time/batch = 17.0233s	
10911/11850 (epoch 46.038), train_loss = 0.80338580, grad/param norm = 3.0654e-01, time/batch = 16.6365s	
10912/11850 (epoch 46.042), train_loss = 0.83264338, grad/param norm = 3.3191e-01, time/batch = 19.4686s	
10913/11850 (epoch 46.046), train_loss = 0.80819274, grad/param norm = 4.4741e-01, time/batch = 17.8986s	
10914/11850 (epoch 46.051), train_loss = 0.82593828, grad/param norm = 3.5553e-01, time/batch = 18.9507s	
10915/11850 (epoch 46.055), train_loss = 0.78772701, grad/param norm = 3.2711e-01, time/batch = 17.7176s	
10916/11850 (epoch 46.059), train_loss = 0.86031882, grad/param norm = 2.9802e-01, time/batch = 17.0682s	
10917/11850 (epoch 46.063), train_loss = 0.93045811, grad/param norm = 3.4783e-01, time/batch = 16.1925s	
10918/11850 (epoch 46.068), train_loss = 0.81986921, grad/param norm = 2.9617e-01, time/batch = 16.2206s	
10919/11850 (epoch 46.072), train_loss = 0.88141434, grad/param norm = 3.1725e-01, time/batch = 18.4621s	
10920/11850 (epoch 46.076), train_loss = 0.93422521, grad/param norm = 3.2736e-01, time/batch = 18.1380s	
10921/11850 (epoch 46.080), train_loss = 0.76375335, grad/param norm = 3.2363e-01, time/batch = 17.3676s	
10922/11850 (epoch 46.084), train_loss = 0.74953915, grad/param norm = 2.9346e-01, time/batch = 15.0435s	
10923/11850 (epoch 46.089), train_loss = 0.73718865, grad/param norm = 3.1346e-01, time/batch = 15.4886s	
10924/11850 (epoch 46.093), train_loss = 0.75257073, grad/param norm = 3.3319e-01, time/batch = 17.5584s	
10925/11850 (epoch 46.097), train_loss = 0.82131249, grad/param norm = 3.0639e-01, time/batch = 17.4605s	
10926/11850 (epoch 46.101), train_loss = 0.73415352, grad/param norm = 3.2179e-01, time/batch = 18.8604s	
10927/11850 (epoch 46.105), train_loss = 0.74512048, grad/param norm = 2.7287e-01, time/batch = 15.9630s	
10928/11850 (epoch 46.110), train_loss = 0.88996600, grad/param norm = 2.7554e-01, time/batch = 18.3687s	
10929/11850 (epoch 46.114), train_loss = 0.76491981, grad/param norm = 2.8953e-01, time/batch = 17.4687s	
10930/11850 (epoch 46.118), train_loss = 0.86663881, grad/param norm = 2.7245e-01, time/batch = 19.2072s	
10931/11850 (epoch 46.122), train_loss = 0.93507774, grad/param norm = 3.3030e-01, time/batch = 19.4683s	
10932/11850 (epoch 46.127), train_loss = 0.87374609, grad/param norm = 3.6460e-01, time/batch = 17.1335s	
10933/11850 (epoch 46.131), train_loss = 0.82765159, grad/param norm = 3.7487e-01, time/batch = 16.9697s	
10934/11850 (epoch 46.135), train_loss = 0.84754985, grad/param norm = 3.2252e-01, time/batch = 16.2152s	
10935/11850 (epoch 46.139), train_loss = 0.80626584, grad/param norm = 3.2282e-01, time/batch = 17.1907s	
10936/11850 (epoch 46.143), train_loss = 0.79003351, grad/param norm = 3.1407e-01, time/batch = 17.4775s	
10937/11850 (epoch 46.148), train_loss = 0.81109871, grad/param norm = 3.3068e-01, time/batch = 15.7105s	
10938/11850 (epoch 46.152), train_loss = 0.90438276, grad/param norm = 3.5445e-01, time/batch = 18.4606s	
10939/11850 (epoch 46.156), train_loss = 0.78643154, grad/param norm = 4.1801e-01, time/batch = 16.3786s	
10940/11850 (epoch 46.160), train_loss = 0.99503702, grad/param norm = 4.7132e-01, time/batch = 16.5556s	
10941/11850 (epoch 46.165), train_loss = 0.90632154, grad/param norm = 4.4572e-01, time/batch = 16.3856s	
10942/11850 (epoch 46.169), train_loss = 0.80591324, grad/param norm = 3.3483e-01, time/batch = 16.7989s	
10943/11850 (epoch 46.173), train_loss = 0.87337974, grad/param norm = 3.2528e-01, time/batch = 16.5582s	
10944/11850 (epoch 46.177), train_loss = 0.73509222, grad/param norm = 3.5164e-01, time/batch = 16.1273s	
10945/11850 (epoch 46.181), train_loss = 0.85762355, grad/param norm = 3.5931e-01, time/batch = 18.6500s	
10946/11850 (epoch 46.186), train_loss = 0.90266645, grad/param norm = 3.5390e-01, time/batch = 16.5487s	
10947/11850 (epoch 46.190), train_loss = 0.86342129, grad/param norm = 3.2852e-01, time/batch = 18.3936s	
10948/11850 (epoch 46.194), train_loss = 0.84221502, grad/param norm = 3.9544e-01, time/batch = 17.3971s	
10949/11850 (epoch 46.198), train_loss = 0.71946630, grad/param norm = 3.9490e-01, time/batch = 16.8155s	
10950/11850 (epoch 46.203), train_loss = 0.70364037, grad/param norm = 3.0641e-01, time/batch = 17.3084s	
10951/11850 (epoch 46.207), train_loss = 0.87635146, grad/param norm = 3.4514e-01, time/batch = 15.6512s	
10952/11850 (epoch 46.211), train_loss = 0.78768667, grad/param norm = 3.0181e-01, time/batch = 17.6390s	
10953/11850 (epoch 46.215), train_loss = 0.85540792, grad/param norm = 3.9931e-01, time/batch = 17.4534s	
10954/11850 (epoch 46.219), train_loss = 0.84171743, grad/param norm = 2.9292e-01, time/batch = 16.5554s	
10955/11850 (epoch 46.224), train_loss = 0.95075699, grad/param norm = 3.3499e-01, time/batch = 17.4055s	
10956/11850 (epoch 46.228), train_loss = 0.87904359, grad/param norm = 3.6888e-01, time/batch = 16.6371s	
10957/11850 (epoch 46.232), train_loss = 0.83420449, grad/param norm = 2.7690e-01, time/batch = 16.5641s	
10958/11850 (epoch 46.236), train_loss = 0.78537903, grad/param norm = 3.4343e-01, time/batch = 17.5691s	
10959/11850 (epoch 46.241), train_loss = 0.88218401, grad/param norm = 3.6167e-01, time/batch = 17.2314s	
10960/11850 (epoch 46.245), train_loss = 0.88523291, grad/param norm = 2.9687e-01, time/batch = 17.2851s	
10961/11850 (epoch 46.249), train_loss = 0.82681136, grad/param norm = 2.6627e-01, time/batch = 16.0537s	
10962/11850 (epoch 46.253), train_loss = 0.82584982, grad/param norm = 3.3117e-01, time/batch = 17.8960s	
10963/11850 (epoch 46.257), train_loss = 0.94782534, grad/param norm = 4.1439e-01, time/batch = 16.9681s	
10964/11850 (epoch 46.262), train_loss = 0.97793090, grad/param norm = 4.0981e-01, time/batch = 17.7279s	
10965/11850 (epoch 46.266), train_loss = 0.94477464, grad/param norm = 3.6488e-01, time/batch = 17.7222s	
10966/11850 (epoch 46.270), train_loss = 0.83580697, grad/param norm = 3.0039e-01, time/batch = 18.0452s	
10967/11850 (epoch 46.274), train_loss = 0.82153427, grad/param norm = 3.6796e-01, time/batch = 15.0271s	
10968/11850 (epoch 46.278), train_loss = 0.73127716, grad/param norm = 3.3798e-01, time/batch = 18.0489s	
10969/11850 (epoch 46.283), train_loss = 0.83069239, grad/param norm = 2.7604e-01, time/batch = 19.4589s	
10970/11850 (epoch 46.287), train_loss = 0.93960733, grad/param norm = 3.1346e-01, time/batch = 15.5893s	
10971/11850 (epoch 46.291), train_loss = 0.82762581, grad/param norm = 3.4451e-01, time/batch = 19.1450s	
10972/11850 (epoch 46.295), train_loss = 0.85854263, grad/param norm = 2.9501e-01, time/batch = 18.6291s	
10973/11850 (epoch 46.300), train_loss = 0.80506241, grad/param norm = 3.9096e-01, time/batch = 17.3715s	
10974/11850 (epoch 46.304), train_loss = 0.83081556, grad/param norm = 2.6641e-01, time/batch = 18.7887s	
10975/11850 (epoch 46.308), train_loss = 0.84038942, grad/param norm = 3.2002e-01, time/batch = 17.3864s	
10976/11850 (epoch 46.312), train_loss = 0.74464350, grad/param norm = 3.0017e-01, time/batch = 16.6450s	
10977/11850 (epoch 46.316), train_loss = 0.81841263, grad/param norm = 2.4649e-01, time/batch = 17.1250s	
10978/11850 (epoch 46.321), train_loss = 0.79968066, grad/param norm = 2.8145e-01, time/batch = 16.9750s	
10979/11850 (epoch 46.325), train_loss = 0.83826503, grad/param norm = 2.9416e-01, time/batch = 16.8875s	
10980/11850 (epoch 46.329), train_loss = 0.81838422, grad/param norm = 2.8244e-01, time/batch = 16.3103s	
10981/11850 (epoch 46.333), train_loss = 0.79767686, grad/param norm = 2.8477e-01, time/batch = 18.5427s	
10982/11850 (epoch 46.338), train_loss = 0.80282945, grad/param norm = 2.9139e-01, time/batch = 17.2919s	
10983/11850 (epoch 46.342), train_loss = 0.82721769, grad/param norm = 2.9455e-01, time/batch = 18.0672s	
10984/11850 (epoch 46.346), train_loss = 0.80327638, grad/param norm = 3.2963e-01, time/batch = 17.1289s	
10985/11850 (epoch 46.350), train_loss = 0.73394876, grad/param norm = 2.7577e-01, time/batch = 16.3917s	
10986/11850 (epoch 46.354), train_loss = 0.87803365, grad/param norm = 3.0704e-01, time/batch = 17.0377s	
10987/11850 (epoch 46.359), train_loss = 0.94909901, grad/param norm = 3.2324e-01, time/batch = 14.3154s	
10988/11850 (epoch 46.363), train_loss = 0.84565581, grad/param norm = 2.9764e-01, time/batch = 19.4568s	
10989/11850 (epoch 46.367), train_loss = 0.87622290, grad/param norm = 2.9274e-01, time/batch = 18.0487s	
10990/11850 (epoch 46.371), train_loss = 0.88414547, grad/param norm = 2.8769e-01, time/batch = 18.9503s	
10991/11850 (epoch 46.376), train_loss = 0.84911809, grad/param norm = 2.5784e-01, time/batch = 15.3633s	
10992/11850 (epoch 46.380), train_loss = 0.80976741, grad/param norm = 2.7117e-01, time/batch = 15.7192s	
10993/11850 (epoch 46.384), train_loss = 0.72846777, grad/param norm = 2.4744e-01, time/batch = 16.8889s	
10994/11850 (epoch 46.388), train_loss = 0.87977318, grad/param norm = 3.3417e-01, time/batch = 17.6342s	
10995/11850 (epoch 46.392), train_loss = 0.84303336, grad/param norm = 3.0392e-01, time/batch = 17.7196s	
10996/11850 (epoch 46.397), train_loss = 0.86112954, grad/param norm = 3.0770e-01, time/batch = 16.3828s	
10997/11850 (epoch 46.401), train_loss = 0.71047381, grad/param norm = 2.5271e-01, time/batch = 19.2064s	
10998/11850 (epoch 46.405), train_loss = 0.75372143, grad/param norm = 3.2410e-01, time/batch = 18.6216s	
10999/11850 (epoch 46.409), train_loss = 0.85063983, grad/param norm = 3.1958e-01, time/batch = 16.9697s	
evaluating loss over split index 2	
1/13...	
2/13...	
3/13...	
4/13...	
5/13...	
6/13...	
7/13...	
8/13...	
9/13...	
10/13...	
11/13...	
12/13...	
13/13...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_katelyn_salem_epoch46.41_2.5016.t7	
11000/11850 (epoch 46.414), train_loss = 0.68619209, grad/param norm = 2.7614e-01, time/batch = 19.1340s	
11001/11850 (epoch 46.418), train_loss = 1.31356567, grad/param norm = 4.5745e-01, time/batch = 17.9618s	
11002/11850 (epoch 46.422), train_loss = 0.68650505, grad/param norm = 2.9978e-01, time/batch = 15.7726s	
11003/11850 (epoch 46.426), train_loss = 0.69125400, grad/param norm = 3.3654e-01, time/batch = 18.6452s	
11004/11850 (epoch 46.430), train_loss = 0.73312622, grad/param norm = 2.9185e-01, time/batch = 18.6330s	
11005/11850 (epoch 46.435), train_loss = 0.77408364, grad/param norm = 3.1369e-01, time/batch = 16.4585s	
11006/11850 (epoch 46.439), train_loss = 0.83336495, grad/param norm = 2.6064e-01, time/batch = 18.5598s	
11007/11850 (epoch 46.443), train_loss = 0.81187624, grad/param norm = 3.0842e-01, time/batch = 17.2206s	
11008/11850 (epoch 46.447), train_loss = 0.72854960, grad/param norm = 2.9555e-01, time/batch = 17.6272s	
11009/11850 (epoch 46.451), train_loss = 0.72058192, grad/param norm = 3.0140e-01, time/batch = 16.5040s	
11010/11850 (epoch 46.456), train_loss = 0.81073704, grad/param norm = 3.3637e-01, time/batch = 17.2054s	
11011/11850 (epoch 46.460), train_loss = 0.84112871, grad/param norm = 2.6415e-01, time/batch = 18.6314s	
11012/11850 (epoch 46.464), train_loss = 0.77441991, grad/param norm = 3.1963e-01, time/batch = 16.8851s	
11013/11850 (epoch 46.468), train_loss = 0.86015201, grad/param norm = 3.9608e-01, time/batch = 19.1319s	
11014/11850 (epoch 46.473), train_loss = 0.87800498, grad/param norm = 3.2676e-01, time/batch = 18.9670s	
11015/11850 (epoch 46.477), train_loss = 0.73593592, grad/param norm = 3.0389e-01, time/batch = 16.3083s	
11016/11850 (epoch 46.481), train_loss = 0.75998994, grad/param norm = 2.9283e-01, time/batch = 18.0495s	
11017/11850 (epoch 46.485), train_loss = 0.71534143, grad/param norm = 2.6151e-01, time/batch = 18.9668s	
11018/11850 (epoch 46.489), train_loss = 0.81751548, grad/param norm = 3.1317e-01, time/batch = 17.9533s	
11019/11850 (epoch 46.494), train_loss = 0.73739086, grad/param norm = 3.4291e-01, time/batch = 16.9800s	
11020/11850 (epoch 46.498), train_loss = 0.73971033, grad/param norm = 3.2398e-01, time/batch = 17.5532s	
11021/11850 (epoch 46.502), train_loss = 0.70317134, grad/param norm = 3.0601e-01, time/batch = 18.4623s	
11022/11850 (epoch 46.506), train_loss = 0.93701435, grad/param norm = 3.0180e-01, time/batch = 15.9468s	
11023/11850 (epoch 46.511), train_loss = 0.79331475, grad/param norm = 3.2445e-01, time/batch = 16.6072s	
11024/11850 (epoch 46.515), train_loss = 0.88555457, grad/param norm = 3.2446e-01, time/batch = 16.1507s	
11025/11850 (epoch 46.519), train_loss = 0.74905012, grad/param norm = 2.8461e-01, time/batch = 18.2959s	
11026/11850 (epoch 46.523), train_loss = 0.80726019, grad/param norm = 3.0629e-01, time/batch = 17.7917s	
11027/11850 (epoch 46.527), train_loss = 0.74451877, grad/param norm = 2.8439e-01, time/batch = 15.8847s	
11028/11850 (epoch 46.532), train_loss = 0.81043053, grad/param norm = 3.1352e-01, time/batch = 17.7267s	
11029/11850 (epoch 46.536), train_loss = 0.76953099, grad/param norm = 3.0760e-01, time/batch = 16.3605s	
11030/11850 (epoch 46.540), train_loss = 0.71211487, grad/param norm = 2.7453e-01, time/batch = 18.1512s	
11031/11850 (epoch 46.544), train_loss = 0.73183417, grad/param norm = 3.5182e-01, time/batch = 17.2097s	
11032/11850 (epoch 46.549), train_loss = 0.68459969, grad/param norm = 2.5276e-01, time/batch = 16.0424s	
11033/11850 (epoch 46.553), train_loss = 0.80379138, grad/param norm = 3.0943e-01, time/batch = 18.6380s	
11034/11850 (epoch 46.557), train_loss = 0.84698870, grad/param norm = 3.3385e-01, time/batch = 17.3031s	
11035/11850 (epoch 46.561), train_loss = 0.87271420, grad/param norm = 3.3704e-01, time/batch = 16.7875s	
11036/11850 (epoch 46.565), train_loss = 0.92933427, grad/param norm = 3.6420e-01, time/batch = 18.5400s	
11037/11850 (epoch 46.570), train_loss = 0.83356246, grad/param norm = 2.7782e-01, time/batch = 17.6360s	
11038/11850 (epoch 46.574), train_loss = 0.85010628, grad/param norm = 3.0562e-01, time/batch = 18.7973s	
11039/11850 (epoch 46.578), train_loss = 0.86378201, grad/param norm = 3.2641e-01, time/batch = 15.2623s	
11040/11850 (epoch 46.582), train_loss = 0.81857172, grad/param norm = 4.2328e-01, time/batch = 14.0049s	
11041/11850 (epoch 46.586), train_loss = 0.80967979, grad/param norm = 2.9023e-01, time/batch = 17.2287s	
11042/11850 (epoch 46.591), train_loss = 0.81598587, grad/param norm = 3.5586e-01, time/batch = 17.7167s	
11043/11850 (epoch 46.595), train_loss = 0.67971805, grad/param norm = 3.3642e-01, time/batch = 16.8043s	
11044/11850 (epoch 46.599), train_loss = 0.79225536, grad/param norm = 2.9781e-01, time/batch = 15.3911s	
11045/11850 (epoch 46.603), train_loss = 0.74894271, grad/param norm = 2.6671e-01, time/batch = 17.0432s	
11046/11850 (epoch 46.608), train_loss = 0.94479180, grad/param norm = 3.7901e-01, time/batch = 16.5581s	
11047/11850 (epoch 46.612), train_loss = 0.97250526, grad/param norm = 3.2891e-01, time/batch = 19.0506s	
11048/11850 (epoch 46.616), train_loss = 0.91246518, grad/param norm = 3.3181e-01, time/batch = 19.0482s	
11049/11850 (epoch 46.620), train_loss = 0.78827549, grad/param norm = 2.9771e-01, time/batch = 17.5517s	
11050/11850 (epoch 46.624), train_loss = 0.79498175, grad/param norm = 3.9942e-01, time/batch = 18.3000s	
11051/11850 (epoch 46.629), train_loss = 0.79505332, grad/param norm = 2.9862e-01, time/batch = 17.3167s	
11052/11850 (epoch 46.633), train_loss = 0.73374814, grad/param norm = 2.8143e-01, time/batch = 19.0522s	
11053/11850 (epoch 46.637), train_loss = 0.65468450, grad/param norm = 2.7274e-01, time/batch = 17.9620s	
11054/11850 (epoch 46.641), train_loss = 0.70181329, grad/param norm = 2.7283e-01, time/batch = 17.9104s	
11055/11850 (epoch 46.646), train_loss = 0.73507535, grad/param norm = 3.1801e-01, time/batch = 17.1533s	
11056/11850 (epoch 46.650), train_loss = 0.82219005, grad/param norm = 3.7334e-01, time/batch = 16.3766s	
11057/11850 (epoch 46.654), train_loss = 0.74762862, grad/param norm = 3.0728e-01, time/batch = 18.3769s	
11058/11850 (epoch 46.658), train_loss = 0.84262686, grad/param norm = 3.0052e-01, time/batch = 17.7181s	
11059/11850 (epoch 46.662), train_loss = 0.72389423, grad/param norm = 4.6527e-01, time/batch = 17.9563s	
11060/11850 (epoch 46.667), train_loss = 0.88514680, grad/param norm = 3.0879e-01, time/batch = 18.7946s	
11061/11850 (epoch 46.671), train_loss = 0.75468956, grad/param norm = 2.7559e-01, time/batch = 16.4644s	
11062/11850 (epoch 46.675), train_loss = 0.78664961, grad/param norm = 3.1339e-01, time/batch = 18.9529s	
11063/11850 (epoch 46.679), train_loss = 0.78692631, grad/param norm = 2.9011e-01, time/batch = 17.2197s	
11064/11850 (epoch 46.684), train_loss = 0.76687210, grad/param norm = 3.2644e-01, time/batch = 17.8762s	
11065/11850 (epoch 46.688), train_loss = 0.73417094, grad/param norm = 2.8501e-01, time/batch = 18.9642s	
11066/11850 (epoch 46.692), train_loss = 0.75151670, grad/param norm = 3.4293e-01, time/batch = 16.7722s	
11067/11850 (epoch 46.696), train_loss = 0.73619352, grad/param norm = 4.0450e-01, time/batch = 16.2652s	
11068/11850 (epoch 46.700), train_loss = 0.78980987, grad/param norm = 3.6168e-01, time/batch = 18.5581s	
11069/11850 (epoch 46.705), train_loss = 0.70982459, grad/param norm = 2.6833e-01, time/batch = 18.6996s	
11070/11850 (epoch 46.709), train_loss = 0.67966680, grad/param norm = 2.7755e-01, time/batch = 18.3113s	
11071/11850 (epoch 46.713), train_loss = 0.68030171, grad/param norm = 2.8474e-01, time/batch = 17.6534s	
11072/11850 (epoch 46.717), train_loss = 0.75857150, grad/param norm = 2.8193e-01, time/batch = 17.3032s	
11073/11850 (epoch 46.722), train_loss = 0.78532218, grad/param norm = 3.3117e-01, time/batch = 25.6044s	
11074/11850 (epoch 46.726), train_loss = 0.73137454, grad/param norm = 3.7747e-01, time/batch = 23.1694s	
11075/11850 (epoch 46.730), train_loss = 0.72054520, grad/param norm = 3.0297e-01, time/batch = 17.6857s	
11076/11850 (epoch 46.734), train_loss = 0.71084762, grad/param norm = 2.8874e-01, time/batch = 17.2186s	
11077/11850 (epoch 46.738), train_loss = 0.81828554, grad/param norm = 3.6198e-01, time/batch = 16.7848s	
11078/11850 (epoch 46.743), train_loss = 0.79183898, grad/param norm = 3.2569e-01, time/batch = 18.9623s	
11079/11850 (epoch 46.747), train_loss = 0.72064654, grad/param norm = 2.8354e-01, time/batch = 16.4724s	
11080/11850 (epoch 46.751), train_loss = 0.78445594, grad/param norm = 3.2908e-01, time/batch = 19.0554s	
11081/11850 (epoch 46.755), train_loss = 0.80843570, grad/param norm = 2.8653e-01, time/batch = 17.4739s	
11082/11850 (epoch 46.759), train_loss = 0.71608160, grad/param norm = 2.5337e-01, time/batch = 17.5439s	
11083/11850 (epoch 46.764), train_loss = 0.77324971, grad/param norm = 2.6884e-01, time/batch = 18.8859s	
11084/11850 (epoch 46.768), train_loss = 0.71365671, grad/param norm = 3.2197e-01, time/batch = 16.2133s	
11085/11850 (epoch 46.772), train_loss = 0.75513716, grad/param norm = 3.4799e-01, time/batch = 17.2131s	
11086/11850 (epoch 46.776), train_loss = 0.78564547, grad/param norm = 3.2798e-01, time/batch = 15.9754s	
11087/11850 (epoch 46.781), train_loss = 0.75688751, grad/param norm = 3.3206e-01, time/batch = 18.7940s	
11088/11850 (epoch 46.785), train_loss = 0.79221943, grad/param norm = 3.6265e-01, time/batch = 17.7283s	
11089/11850 (epoch 46.789), train_loss = 0.74918617, grad/param norm = 2.9536e-01, time/batch = 14.8608s	
11090/11850 (epoch 46.793), train_loss = 0.83650071, grad/param norm = 4.2954e-01, time/batch = 17.4752s	
11091/11850 (epoch 46.797), train_loss = 0.76466860, grad/param norm = 3.7168e-01, time/batch = 17.2241s	
11092/11850 (epoch 46.802), train_loss = 0.71365127, grad/param norm = 3.4415e-01, time/batch = 16.8903s	
11093/11850 (epoch 46.806), train_loss = 0.78923610, grad/param norm = 3.5348e-01, time/batch = 16.2898s	
11094/11850 (epoch 46.810), train_loss = 0.82955299, grad/param norm = 3.5240e-01, time/batch = 16.3106s	
11095/11850 (epoch 46.814), train_loss = 0.78395214, grad/param norm = 2.7999e-01, time/batch = 17.8915s	
11096/11850 (epoch 46.819), train_loss = 0.89198410, grad/param norm = 3.3883e-01, time/batch = 16.4761s	
11097/11850 (epoch 46.823), train_loss = 0.87076571, grad/param norm = 3.4954e-01, time/batch = 16.9949s	
11098/11850 (epoch 46.827), train_loss = 0.78329049, grad/param norm = 4.2063e-01, time/batch = 18.8109s	
11099/11850 (epoch 46.831), train_loss = 0.74485361, grad/param norm = 2.9743e-01, time/batch = 16.7489s	
11100/11850 (epoch 46.835), train_loss = 0.81713702, grad/param norm = 2.6702e-01, time/batch = 15.9455s	
11101/11850 (epoch 46.840), train_loss = 0.76672079, grad/param norm = 3.1157e-01, time/batch = 16.9830s	
11102/11850 (epoch 46.844), train_loss = 0.80947898, grad/param norm = 2.8342e-01, time/batch = 18.3013s	
11103/11850 (epoch 46.848), train_loss = 0.83894176, grad/param norm = 6.8332e-01, time/batch = 16.2757s	
11104/11850 (epoch 46.852), train_loss = 0.81729659, grad/param norm = 3.8413e-01, time/batch = 17.7089s	
11105/11850 (epoch 46.857), train_loss = 0.80533090, grad/param norm = 3.9245e-01, time/batch = 17.2366s	
11106/11850 (epoch 46.861), train_loss = 0.75713309, grad/param norm = 4.4379e-01, time/batch = 18.3877s	
11107/11850 (epoch 46.865), train_loss = 0.85828571, grad/param norm = 4.7503e-01, time/batch = 17.1262s	
11108/11850 (epoch 46.869), train_loss = 0.79784282, grad/param norm = 2.8804e-01, time/batch = 16.5425s	
11109/11850 (epoch 46.873), train_loss = 0.81000965, grad/param norm = 3.4725e-01, time/batch = 17.9793s	
11110/11850 (epoch 46.878), train_loss = 0.82735358, grad/param norm = 3.6490e-01, time/batch = 16.8017s	
11111/11850 (epoch 46.882), train_loss = 0.81376109, grad/param norm = 3.5584e-01, time/batch = 17.2165s	
11112/11850 (epoch 46.886), train_loss = 0.77912239, grad/param norm = 4.3566e-01, time/batch = 18.8632s	
11113/11850 (epoch 46.890), train_loss = 0.83660875, grad/param norm = 3.8202e-01, time/batch = 17.8821s	
11114/11850 (epoch 46.895), train_loss = 0.80211526, grad/param norm = 4.0558e-01, time/batch = 18.7227s	
11115/11850 (epoch 46.899), train_loss = 0.71737951, grad/param norm = 3.2804e-01, time/batch = 17.7966s	
11116/11850 (epoch 46.903), train_loss = 0.74039153, grad/param norm = 3.0145e-01, time/batch = 18.2221s	
11117/11850 (epoch 46.907), train_loss = 0.78183016, grad/param norm = 3.4256e-01, time/batch = 18.3653s	
11118/11850 (epoch 46.911), train_loss = 0.87923767, grad/param norm = 2.9260e-01, time/batch = 18.7162s	
11119/11850 (epoch 46.916), train_loss = 0.83602916, grad/param norm = 3.4169e-01, time/batch = 17.7278s	
11120/11850 (epoch 46.920), train_loss = 0.81989295, grad/param norm = 3.2349e-01, time/batch = 16.9539s	
11121/11850 (epoch 46.924), train_loss = 0.75915452, grad/param norm = 3.0297e-01, time/batch = 15.8044s	
11122/11850 (epoch 46.928), train_loss = 0.83158873, grad/param norm = 3.7503e-01, time/batch = 16.8053s	
11123/11850 (epoch 46.932), train_loss = 0.90484948, grad/param norm = 3.6283e-01, time/batch = 18.1252s	
11124/11850 (epoch 46.937), train_loss = 0.88062863, grad/param norm = 3.3118e-01, time/batch = 16.4573s	
11125/11850 (epoch 46.941), train_loss = 0.81121631, grad/param norm = 3.2385e-01, time/batch = 17.0575s	
11126/11850 (epoch 46.945), train_loss = 0.81874448, grad/param norm = 3.3648e-01, time/batch = 17.2261s	
11127/11850 (epoch 46.949), train_loss = 0.78643064, grad/param norm = 4.2544e-01, time/batch = 16.6304s	
11128/11850 (epoch 46.954), train_loss = 0.85985560, grad/param norm = 3.5106e-01, time/batch = 18.2122s	
11129/11850 (epoch 46.958), train_loss = 0.84491495, grad/param norm = 3.8631e-01, time/batch = 16.9535s	
11130/11850 (epoch 46.962), train_loss = 0.76316100, grad/param norm = 3.1466e-01, time/batch = 17.2105s	
11131/11850 (epoch 46.966), train_loss = 0.71065446, grad/param norm = 3.3857e-01, time/batch = 18.4307s	
11132/11850 (epoch 46.970), train_loss = 0.84091961, grad/param norm = 3.5077e-01, time/batch = 17.2358s	
11133/11850 (epoch 46.975), train_loss = 0.78483124, grad/param norm = 3.0519e-01, time/batch = 17.2295s	
11134/11850 (epoch 46.979), train_loss = 0.83316801, grad/param norm = 3.6537e-01, time/batch = 16.7876s	
11135/11850 (epoch 46.983), train_loss = 0.87981802, grad/param norm = 3.4200e-01, time/batch = 17.7217s	
11136/11850 (epoch 46.987), train_loss = 0.77060650, grad/param norm = 3.4626e-01, time/batch = 16.6334s	
11137/11850 (epoch 46.992), train_loss = 0.90533610, grad/param norm = 3.6944e-01, time/batch = 17.7995s	
11138/11850 (epoch 46.996), train_loss = 0.89914120, grad/param norm = 3.6308e-01, time/batch = 16.6970s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
11139/11850 (epoch 47.000), train_loss = 0.77776380, grad/param norm = 3.5454e-01, time/batch = 18.3064s	
11140/11850 (epoch 47.004), train_loss = 0.86979478, grad/param norm = 3.3711e-01, time/batch = 18.7074s	
11141/11850 (epoch 47.008), train_loss = 0.88132509, grad/param norm = 3.0957e-01, time/batch = 16.5339s	
11142/11850 (epoch 47.013), train_loss = 0.89421785, grad/param norm = 2.9265e-01, time/batch = 17.3954s	
11143/11850 (epoch 47.017), train_loss = 0.93720802, grad/param norm = 3.9145e-01, time/batch = 17.1227s	
11144/11850 (epoch 47.021), train_loss = 0.89896188, grad/param norm = 3.0547e-01, time/batch = 17.3843s	
11145/11850 (epoch 47.025), train_loss = 0.78069284, grad/param norm = 2.8170e-01, time/batch = 16.9376s	
11146/11850 (epoch 47.030), train_loss = 0.81143865, grad/param norm = 3.1877e-01, time/batch = 16.8791s	
11147/11850 (epoch 47.034), train_loss = 0.78458582, grad/param norm = 3.2480e-01, time/batch = 18.6290s	
11148/11850 (epoch 47.038), train_loss = 0.79245227, grad/param norm = 3.0526e-01, time/batch = 16.7185s	
11149/11850 (epoch 47.042), train_loss = 0.83598328, grad/param norm = 3.3907e-01, time/batch = 18.3716s	
11150/11850 (epoch 47.046), train_loss = 0.80606417, grad/param norm = 4.2246e-01, time/batch = 18.3162s	
11151/11850 (epoch 47.051), train_loss = 0.81794949, grad/param norm = 3.3253e-01, time/batch = 17.7930s	
11152/11850 (epoch 47.055), train_loss = 0.78359882, grad/param norm = 3.2106e-01, time/batch = 17.1416s	
11153/11850 (epoch 47.059), train_loss = 0.85516394, grad/param norm = 3.1627e-01, time/batch = 17.3945s	
11154/11850 (epoch 47.063), train_loss = 0.93334869, grad/param norm = 3.6407e-01, time/batch = 17.8743s	
11155/11850 (epoch 47.068), train_loss = 0.79889325, grad/param norm = 2.7526e-01, time/batch = 18.6231s	
11156/11850 (epoch 47.072), train_loss = 0.87113776, grad/param norm = 3.1906e-01, time/batch = 16.3227s	
11157/11850 (epoch 47.076), train_loss = 0.93058481, grad/param norm = 3.8979e-01, time/batch = 18.8849s	
11158/11850 (epoch 47.080), train_loss = 0.75507298, grad/param norm = 2.7460e-01, time/batch = 17.8446s	
11159/11850 (epoch 47.084), train_loss = 0.73544832, grad/param norm = 2.7054e-01, time/batch = 17.6471s	
11160/11850 (epoch 47.089), train_loss = 0.72867726, grad/param norm = 2.9855e-01, time/batch = 16.3079s	
11161/11850 (epoch 47.093), train_loss = 0.74225637, grad/param norm = 3.1816e-01, time/batch = 16.2033s	
11162/11850 (epoch 47.097), train_loss = 0.81292383, grad/param norm = 3.0269e-01, time/batch = 17.5447s	
11163/11850 (epoch 47.101), train_loss = 0.72979602, grad/param norm = 3.5844e-01, time/batch = 17.6296s	
11164/11850 (epoch 47.105), train_loss = 0.74018188, grad/param norm = 2.7339e-01, time/batch = 17.7087s	
11165/11850 (epoch 47.110), train_loss = 0.87693433, grad/param norm = 2.9945e-01, time/batch = 17.6966s	
11166/11850 (epoch 47.114), train_loss = 0.74145627, grad/param norm = 3.1488e-01, time/batch = 18.8771s	
11167/11850 (epoch 47.118), train_loss = 0.86291810, grad/param norm = 2.8817e-01, time/batch = 18.3097s	
11168/11850 (epoch 47.122), train_loss = 0.91581940, grad/param norm = 3.0774e-01, time/batch = 17.5410s	
11169/11850 (epoch 47.127), train_loss = 0.88036428, grad/param norm = 3.5842e-01, time/batch = 16.8295s	
11170/11850 (epoch 47.131), train_loss = 0.81421135, grad/param norm = 3.3943e-01, time/batch = 19.4565s	
11171/11850 (epoch 47.135), train_loss = 0.81834726, grad/param norm = 3.1951e-01, time/batch = 16.8790s	
11172/11850 (epoch 47.139), train_loss = 0.80011195, grad/param norm = 2.8364e-01, time/batch = 18.2145s	
11173/11850 (epoch 47.143), train_loss = 0.78539399, grad/param norm = 3.4365e-01, time/batch = 17.5636s	
11174/11850 (epoch 47.148), train_loss = 0.80125817, grad/param norm = 3.4509e-01, time/batch = 18.1254s	
11175/11850 (epoch 47.152), train_loss = 0.89415718, grad/param norm = 3.2352e-01, time/batch = 17.5251s	
11176/11850 (epoch 47.156), train_loss = 0.76750812, grad/param norm = 3.7248e-01, time/batch = 17.4883s	
11177/11850 (epoch 47.160), train_loss = 0.96328825, grad/param norm = 3.5614e-01, time/batch = 18.4567s	
11178/11850 (epoch 47.165), train_loss = 0.89903546, grad/param norm = 4.1357e-01, time/batch = 16.7148s	
11179/11850 (epoch 47.169), train_loss = 0.81381664, grad/param norm = 4.3720e-01, time/batch = 17.4538s	
11180/11850 (epoch 47.173), train_loss = 0.87703798, grad/param norm = 3.8746e-01, time/batch = 17.5320s	
11181/11850 (epoch 47.177), train_loss = 0.73531420, grad/param norm = 3.7239e-01, time/batch = 17.9602s	
11182/11850 (epoch 47.181), train_loss = 0.80644109, grad/param norm = 2.8321e-01, time/batch = 16.8794s	
11183/11850 (epoch 47.186), train_loss = 0.89267455, grad/param norm = 3.3077e-01, time/batch = 17.5575s	
11184/11850 (epoch 47.190), train_loss = 0.84547765, grad/param norm = 3.7115e-01, time/batch = 19.0388s	
11185/11850 (epoch 47.194), train_loss = 0.83281186, grad/param norm = 4.0780e-01, time/batch = 17.7847s	
11186/11850 (epoch 47.198), train_loss = 0.70476399, grad/param norm = 3.3087e-01, time/batch = 17.8828s	
11187/11850 (epoch 47.203), train_loss = 0.71427011, grad/param norm = 3.5055e-01, time/batch = 17.5392s	
11188/11850 (epoch 47.207), train_loss = 0.85200266, grad/param norm = 3.4939e-01, time/batch = 17.7879s	
11189/11850 (epoch 47.211), train_loss = 0.79195782, grad/param norm = 3.1684e-01, time/batch = 18.5585s	
11190/11850 (epoch 47.215), train_loss = 0.84317012, grad/param norm = 3.7896e-01, time/batch = 17.2979s	
11191/11850 (epoch 47.219), train_loss = 0.84707449, grad/param norm = 3.2319e-01, time/batch = 17.7108s	
11192/11850 (epoch 47.224), train_loss = 0.93652528, grad/param norm = 3.4399e-01, time/batch = 18.1187s	
11193/11850 (epoch 47.228), train_loss = 0.86135617, grad/param norm = 3.5056e-01, time/batch = 17.0514s	
11194/11850 (epoch 47.232), train_loss = 0.82845195, grad/param norm = 3.0866e-01, time/batch = 18.9699s	
11195/11850 (epoch 47.236), train_loss = 0.77816588, grad/param norm = 3.6922e-01, time/batch = 18.6933s	
11196/11850 (epoch 47.241), train_loss = 0.86477628, grad/param norm = 3.1093e-01, time/batch = 15.8786s	
11197/11850 (epoch 47.245), train_loss = 0.87321873, grad/param norm = 3.1377e-01, time/batch = 19.2937s	
11198/11850 (epoch 47.249), train_loss = 0.82204559, grad/param norm = 2.8253e-01, time/batch = 16.2280s	
11199/11850 (epoch 47.253), train_loss = 0.81025237, grad/param norm = 3.3186e-01, time/batch = 16.3897s	
11200/11850 (epoch 47.257), train_loss = 0.93357780, grad/param norm = 3.8090e-01, time/batch = 17.0315s	
11201/11850 (epoch 47.262), train_loss = 0.94638210, grad/param norm = 3.4532e-01, time/batch = 18.4565s	
11202/11850 (epoch 47.266), train_loss = 0.92997135, grad/param norm = 4.0200e-01, time/batch = 16.9684s	
11203/11850 (epoch 47.270), train_loss = 0.81744901, grad/param norm = 2.8621e-01, time/batch = 17.5712s	
11204/11850 (epoch 47.274), train_loss = 0.83598610, grad/param norm = 6.1236e-01, time/batch = 17.7805s	
11205/11850 (epoch 47.278), train_loss = 0.72568472, grad/param norm = 3.4831e-01, time/batch = 16.3654s	
11206/11850 (epoch 47.283), train_loss = 0.82413350, grad/param norm = 2.9563e-01, time/batch = 18.8732s	
11207/11850 (epoch 47.287), train_loss = 0.92958341, grad/param norm = 3.1893e-01, time/batch = 17.8904s	
11208/11850 (epoch 47.291), train_loss = 0.81688689, grad/param norm = 3.5093e-01, time/batch = 17.6102s	
11209/11850 (epoch 47.295), train_loss = 0.83620112, grad/param norm = 3.0132e-01, time/batch = 18.0283s	
11210/11850 (epoch 47.300), train_loss = 0.78911110, grad/param norm = 3.9511e-01, time/batch = 17.6444s	
11211/11850 (epoch 47.304), train_loss = 0.83353163, grad/param norm = 2.6801e-01, time/batch = 17.5630s	
11212/11850 (epoch 47.308), train_loss = 0.83433067, grad/param norm = 3.2926e-01, time/batch = 16.3045s	
11213/11850 (epoch 47.312), train_loss = 0.74127559, grad/param norm = 3.2465e-01, time/batch = 13.9968s	
11214/11850 (epoch 47.316), train_loss = 0.81181753, grad/param norm = 2.5517e-01, time/batch = 18.8709s	
11215/11850 (epoch 47.321), train_loss = 0.78985457, grad/param norm = 2.9589e-01, time/batch = 17.6207s	
11216/11850 (epoch 47.325), train_loss = 0.83099090, grad/param norm = 3.0535e-01, time/batch = 17.8833s	
11217/11850 (epoch 47.329), train_loss = 0.81819039, grad/param norm = 3.2422e-01, time/batch = 19.0459s	
11218/11850 (epoch 47.333), train_loss = 0.80573399, grad/param norm = 3.1700e-01, time/batch = 17.4397s	
11219/11850 (epoch 47.338), train_loss = 0.79750130, grad/param norm = 2.8542e-01, time/batch = 17.7859s	
11220/11850 (epoch 47.342), train_loss = 0.82127235, grad/param norm = 3.0811e-01, time/batch = 18.3839s	
11221/11850 (epoch 47.346), train_loss = 0.80446007, grad/param norm = 3.1904e-01, time/batch = 17.2341s	
11222/11850 (epoch 47.350), train_loss = 0.72997873, grad/param norm = 3.0543e-01, time/batch = 16.7240s	
11223/11850 (epoch 47.354), train_loss = 0.85945753, grad/param norm = 2.8557e-01, time/batch = 14.6316s	
11224/11850 (epoch 47.359), train_loss = 0.93697994, grad/param norm = 3.3173e-01, time/batch = 17.8004s	
11225/11850 (epoch 47.363), train_loss = 0.83269087, grad/param norm = 2.9820e-01, time/batch = 18.5428s	
11226/11850 (epoch 47.367), train_loss = 0.85733078, grad/param norm = 2.7785e-01, time/batch = 16.1472s	
11227/11850 (epoch 47.371), train_loss = 0.87452261, grad/param norm = 2.8005e-01, time/batch = 17.8805s	
11228/11850 (epoch 47.376), train_loss = 0.84287717, grad/param norm = 2.7386e-01, time/batch = 18.1355s	
11229/11850 (epoch 47.380), train_loss = 0.79985873, grad/param norm = 2.8552e-01, time/batch = 17.6317s	
11230/11850 (epoch 47.384), train_loss = 0.72512430, grad/param norm = 2.7065e-01, time/batch = 15.5657s	
11231/11850 (epoch 47.388), train_loss = 0.86877311, grad/param norm = 3.0642e-01, time/batch = 15.9497s	
11232/11850 (epoch 47.392), train_loss = 0.84096565, grad/param norm = 3.3542e-01, time/batch = 17.6345s	
11233/11850 (epoch 47.397), train_loss = 0.86034386, grad/param norm = 3.4973e-01, time/batch = 16.1425s	
11234/11850 (epoch 47.401), train_loss = 0.71285464, grad/param norm = 2.9067e-01, time/batch = 18.3932s	
11235/11850 (epoch 47.405), train_loss = 0.75070897, grad/param norm = 3.2820e-01, time/batch = 19.2155s	
11236/11850 (epoch 47.409), train_loss = 0.84265660, grad/param norm = 3.2455e-01, time/batch = 17.3115s	
11237/11850 (epoch 47.414), train_loss = 0.68612165, grad/param norm = 3.0657e-01, time/batch = 17.8918s	
11238/11850 (epoch 47.418), train_loss = 0.73073956, grad/param norm = 3.5220e-01, time/batch = 18.4610s	
11239/11850 (epoch 47.422), train_loss = 0.66614788, grad/param norm = 2.7007e-01, time/batch = 15.2800s	
11240/11850 (epoch 47.426), train_loss = 0.66098746, grad/param norm = 3.0865e-01, time/batch = 18.9511s	
11241/11850 (epoch 47.430), train_loss = 0.72084626, grad/param norm = 3.3646e-01, time/batch = 18.0550s	
11242/11850 (epoch 47.435), train_loss = 0.76375230, grad/param norm = 3.1155e-01, time/batch = 18.5206s	
11243/11850 (epoch 47.439), train_loss = 0.82989842, grad/param norm = 2.9560e-01, time/batch = 18.2870s	
11244/11850 (epoch 47.443), train_loss = 0.80018749, grad/param norm = 3.1912e-01, time/batch = 16.0330s	
11245/11850 (epoch 47.447), train_loss = 0.71847903, grad/param norm = 2.9214e-01, time/batch = 16.0755s	
11246/11850 (epoch 47.451), train_loss = 0.69925358, grad/param norm = 2.9944e-01, time/batch = 17.1429s	
11247/11850 (epoch 47.456), train_loss = 0.80339318, grad/param norm = 3.4051e-01, time/batch = 18.3827s	
11248/11850 (epoch 47.460), train_loss = 0.82477182, grad/param norm = 2.6285e-01, time/batch = 16.7975s	
11249/11850 (epoch 47.464), train_loss = 0.76412657, grad/param norm = 3.6021e-01, time/batch = 15.8708s	
11250/11850 (epoch 47.468), train_loss = 0.84210402, grad/param norm = 3.1023e-01, time/batch = 18.2805s	
11251/11850 (epoch 47.473), train_loss = 0.85863632, grad/param norm = 3.2459e-01, time/batch = 18.8732s	
11252/11850 (epoch 47.477), train_loss = 0.73493866, grad/param norm = 3.4432e-01, time/batch = 17.3062s	
11253/11850 (epoch 47.481), train_loss = 0.75382262, grad/param norm = 3.0700e-01, time/batch = 17.6183s	
11254/11850 (epoch 47.485), train_loss = 0.70753369, grad/param norm = 2.7593e-01, time/batch = 18.2162s	
11255/11850 (epoch 47.489), train_loss = 0.80566446, grad/param norm = 3.1991e-01, time/batch = 19.0409s	
11256/11850 (epoch 47.494), train_loss = 0.72009563, grad/param norm = 3.2264e-01, time/batch = 16.5562s	
11257/11850 (epoch 47.498), train_loss = 0.72561398, grad/param norm = 3.1253e-01, time/batch = 19.1294s	
11258/11850 (epoch 47.502), train_loss = 0.69139358, grad/param norm = 3.2123e-01, time/batch = 17.5398s	
11259/11850 (epoch 47.506), train_loss = 0.93818845, grad/param norm = 3.3981e-01, time/batch = 16.9759s	
11260/11850 (epoch 47.511), train_loss = 0.77549699, grad/param norm = 2.8261e-01, time/batch = 16.7003s	
11261/11850 (epoch 47.515), train_loss = 0.86503582, grad/param norm = 3.2046e-01, time/batch = 17.7132s	
11262/11850 (epoch 47.519), train_loss = 0.74365490, grad/param norm = 3.0325e-01, time/batch = 18.6301s	
11263/11850 (epoch 47.523), train_loss = 0.78732010, grad/param norm = 2.8368e-01, time/batch = 16.7200s	
11264/11850 (epoch 47.527), train_loss = 0.72845324, grad/param norm = 2.8480e-01, time/batch = 17.3599s	
11265/11850 (epoch 47.532), train_loss = 0.79262397, grad/param norm = 2.7456e-01, time/batch = 18.7135s	
11266/11850 (epoch 47.536), train_loss = 0.75513661, grad/param norm = 2.7752e-01, time/batch = 17.5473s	
11267/11850 (epoch 47.540), train_loss = 0.69121507, grad/param norm = 2.5718e-01, time/batch = 18.5485s	
11268/11850 (epoch 47.544), train_loss = 0.72577051, grad/param norm = 3.4264e-01, time/batch = 16.5416s	
11269/11850 (epoch 47.549), train_loss = 0.67619258, grad/param norm = 2.5218e-01, time/batch = 19.2103s	
11270/11850 (epoch 47.553), train_loss = 0.78303259, grad/param norm = 2.7241e-01, time/batch = 16.0398s	
11271/11850 (epoch 47.557), train_loss = 0.84349309, grad/param norm = 3.6520e-01, time/batch = 17.5182s	
11272/11850 (epoch 47.561), train_loss = 0.85914627, grad/param norm = 3.7974e-01, time/batch = 18.7144s	
11273/11850 (epoch 47.565), train_loss = 0.92665473, grad/param norm = 3.4572e-01, time/batch = 16.7194s	
11274/11850 (epoch 47.570), train_loss = 0.82151443, grad/param norm = 2.9820e-01, time/batch = 17.3015s	
11275/11850 (epoch 47.574), train_loss = 0.83377807, grad/param norm = 2.7146e-01, time/batch = 18.0655s	
11276/11850 (epoch 47.578), train_loss = 0.84716956, grad/param norm = 3.1602e-01, time/batch = 17.7171s	
11277/11850 (epoch 47.582), train_loss = 0.78274765, grad/param norm = 3.2524e-01, time/batch = 31.0621s	
11278/11850 (epoch 47.586), train_loss = 0.81605683, grad/param norm = 3.4438e-01, time/batch = 16.1936s	
11279/11850 (epoch 47.591), train_loss = 0.81222856, grad/param norm = 3.6804e-01, time/batch = 15.0254s	
11280/11850 (epoch 47.595), train_loss = 0.68325783, grad/param norm = 2.9724e-01, time/batch = 17.7054s	
11281/11850 (epoch 47.599), train_loss = 0.77787097, grad/param norm = 3.2748e-01, time/batch = 16.8850s	
11282/11850 (epoch 47.603), train_loss = 0.75139361, grad/param norm = 2.8382e-01, time/batch = 17.8997s	
11283/11850 (epoch 47.608), train_loss = 0.92417109, grad/param norm = 3.1989e-01, time/batch = 17.5519s	
11284/11850 (epoch 47.612), train_loss = 0.96526495, grad/param norm = 3.5992e-01, time/batch = 16.6576s	
11285/11850 (epoch 47.616), train_loss = 0.91362671, grad/param norm = 3.5912e-01, time/batch = 17.5677s	
11286/11850 (epoch 47.620), train_loss = 0.77916981, grad/param norm = 3.0651e-01, time/batch = 16.6444s	
11287/11850 (epoch 47.624), train_loss = 0.78462542, grad/param norm = 3.5320e-01, time/batch = 17.3911s	
11288/11850 (epoch 47.629), train_loss = 0.77928903, grad/param norm = 3.2877e-01, time/batch = 18.7243s	
11289/11850 (epoch 47.633), train_loss = 0.72368424, grad/param norm = 2.9578e-01, time/batch = 17.4045s	
11290/11850 (epoch 47.637), train_loss = 0.65097197, grad/param norm = 2.6891e-01, time/batch = 15.2457s	
11291/11850 (epoch 47.641), train_loss = 0.68622547, grad/param norm = 2.5276e-01, time/batch = 18.4537s	
11292/11850 (epoch 47.646), train_loss = 0.71428422, grad/param norm = 3.2699e-01, time/batch = 18.8078s	
11293/11850 (epoch 47.650), train_loss = 0.78761794, grad/param norm = 2.9123e-01, time/batch = 16.3012s	
11294/11850 (epoch 47.654), train_loss = 0.76556366, grad/param norm = 3.2650e-01, time/batch = 18.3025s	
11295/11850 (epoch 47.658), train_loss = 0.83933260, grad/param norm = 3.0824e-01, time/batch = 18.0443s	
11296/11850 (epoch 47.662), train_loss = 0.69753883, grad/param norm = 3.2139e-01, time/batch = 17.4694s	
11297/11850 (epoch 47.667), train_loss = 0.86808889, grad/param norm = 2.9110e-01, time/batch = 17.4734s	
11298/11850 (epoch 47.671), train_loss = 0.74533135, grad/param norm = 2.8722e-01, time/batch = 16.1305s	
11299/11850 (epoch 47.675), train_loss = 0.76997205, grad/param norm = 3.0012e-01, time/batch = 16.8069s	
11300/11850 (epoch 47.679), train_loss = 0.78116274, grad/param norm = 2.8833e-01, time/batch = 16.2309s	
11301/11850 (epoch 47.684), train_loss = 0.74209325, grad/param norm = 2.9638e-01, time/batch = 18.8064s	
11302/11850 (epoch 47.688), train_loss = 0.72301087, grad/param norm = 2.8875e-01, time/batch = 19.4631s	
11303/11850 (epoch 47.692), train_loss = 0.75498167, grad/param norm = 4.0718e-01, time/batch = 16.3976s	
11304/11850 (epoch 47.696), train_loss = 0.71824991, grad/param norm = 3.8460e-01, time/batch = 17.1875s	
11305/11850 (epoch 47.700), train_loss = 0.77498326, grad/param norm = 2.9782e-01, time/batch = 17.7240s	
11306/11850 (epoch 47.705), train_loss = 0.68922548, grad/param norm = 2.9746e-01, time/batch = 18.7164s	
11307/11850 (epoch 47.709), train_loss = 0.67514814, grad/param norm = 2.7191e-01, time/batch = 18.2862s	
11308/11850 (epoch 47.713), train_loss = 0.68865682, grad/param norm = 3.9053e-01, time/batch = 17.2264s	
11309/11850 (epoch 47.717), train_loss = 0.74680010, grad/param norm = 2.7731e-01, time/batch = 19.6167s	
11310/11850 (epoch 47.722), train_loss = 0.75912645, grad/param norm = 2.9715e-01, time/batch = 16.4563s	
11311/11850 (epoch 47.726), train_loss = 0.70952805, grad/param norm = 3.1791e-01, time/batch = 17.0170s	
11312/11850 (epoch 47.730), train_loss = 0.72905805, grad/param norm = 3.6246e-01, time/batch = 16.5607s	
11313/11850 (epoch 47.734), train_loss = 0.70234762, grad/param norm = 3.1119e-01, time/batch = 17.5517s	
11314/11850 (epoch 47.738), train_loss = 0.79994682, grad/param norm = 3.6077e-01, time/batch = 17.6222s	
11315/11850 (epoch 47.743), train_loss = 0.78475147, grad/param norm = 3.5217e-01, time/batch = 17.0500s	
11316/11850 (epoch 47.747), train_loss = 0.70182107, grad/param norm = 2.6716e-01, time/batch = 17.4467s	
11317/11850 (epoch 47.751), train_loss = 0.76851487, grad/param norm = 2.6600e-01, time/batch = 16.8003s	
11318/11850 (epoch 47.755), train_loss = 0.78906811, grad/param norm = 3.1408e-01, time/batch = 18.8021s	
11319/11850 (epoch 47.759), train_loss = 0.71492851, grad/param norm = 2.6312e-01, time/batch = 17.4618s	
11320/11850 (epoch 47.764), train_loss = 0.76157266, grad/param norm = 2.9509e-01, time/batch = 18.1315s	
11321/11850 (epoch 47.768), train_loss = 0.69898817, grad/param norm = 2.7226e-01, time/batch = 18.9637s	
11322/11850 (epoch 47.772), train_loss = 0.74723299, grad/param norm = 3.3047e-01, time/batch = 17.8015s	
11323/11850 (epoch 47.776), train_loss = 0.77796097, grad/param norm = 2.9750e-01, time/batch = 18.2795s	
11324/11850 (epoch 47.781), train_loss = 0.74598381, grad/param norm = 2.6899e-01, time/batch = 17.8027s	
11325/11850 (epoch 47.785), train_loss = 0.77749258, grad/param norm = 3.1904e-01, time/batch = 17.3846s	
11326/11850 (epoch 47.789), train_loss = 0.74630829, grad/param norm = 3.2139e-01, time/batch = 19.2122s	
11327/11850 (epoch 47.793), train_loss = 0.80035228, grad/param norm = 2.9829e-01, time/batch = 15.5496s	
11328/11850 (epoch 47.797), train_loss = 0.74617946, grad/param norm = 3.1548e-01, time/batch = 15.3127s	
11329/11850 (epoch 47.802), train_loss = 0.69832407, grad/param norm = 3.0135e-01, time/batch = 15.9140s	
11330/11850 (epoch 47.806), train_loss = 0.78414104, grad/param norm = 3.6447e-01, time/batch = 18.1958s	
11331/11850 (epoch 47.810), train_loss = 0.83124567, grad/param norm = 4.4252e-01, time/batch = 18.7940s	
11332/11850 (epoch 47.814), train_loss = 0.78193203, grad/param norm = 3.2033e-01, time/batch = 15.7283s	
11333/11850 (epoch 47.819), train_loss = 0.87547295, grad/param norm = 3.1186e-01, time/batch = 16.9575s	
11334/11850 (epoch 47.823), train_loss = 0.86169263, grad/param norm = 3.2997e-01, time/batch = 16.3931s	
11335/11850 (epoch 47.827), train_loss = 0.75950500, grad/param norm = 3.5943e-01, time/batch = 19.5555s	
11336/11850 (epoch 47.831), train_loss = 0.73124902, grad/param norm = 3.0800e-01, time/batch = 16.1378s	
11337/11850 (epoch 47.835), train_loss = 0.82239837, grad/param norm = 2.7634e-01, time/batch = 17.1297s	
11338/11850 (epoch 47.840), train_loss = 0.74172393, grad/param norm = 2.7760e-01, time/batch = 19.2988s	
11339/11850 (epoch 47.844), train_loss = 0.78404264, grad/param norm = 2.7243e-01, time/batch = 18.4703s	
11340/11850 (epoch 47.848), train_loss = 0.82024026, grad/param norm = 3.0811e-01, time/batch = 18.3841s	
11341/11850 (epoch 47.852), train_loss = 0.80516864, grad/param norm = 3.6229e-01, time/batch = 17.1717s	
11342/11850 (epoch 47.857), train_loss = 0.77538507, grad/param norm = 3.0841e-01, time/batch = 17.3723s	
11343/11850 (epoch 47.861), train_loss = 0.72465214, grad/param norm = 4.0856e-01, time/batch = 18.2763s	
11344/11850 (epoch 47.865), train_loss = 0.82504632, grad/param norm = 3.3716e-01, time/batch = 17.7757s	
11345/11850 (epoch 47.869), train_loss = 0.80524038, grad/param norm = 3.0986e-01, time/batch = 18.7974s	
11346/11850 (epoch 47.873), train_loss = 0.79645768, grad/param norm = 3.3775e-01, time/batch = 16.7139s	
11347/11850 (epoch 47.878), train_loss = 0.82562624, grad/param norm = 3.5900e-01, time/batch = 18.0523s	
11348/11850 (epoch 47.882), train_loss = 0.80856262, grad/param norm = 3.1428e-01, time/batch = 16.9763s	
11349/11850 (epoch 47.886), train_loss = 0.76894974, grad/param norm = 3.8855e-01, time/batch = 15.6333s	
11350/11850 (epoch 47.890), train_loss = 0.79831030, grad/param norm = 3.1473e-01, time/batch = 19.2125s	
11351/11850 (epoch 47.895), train_loss = 0.79020526, grad/param norm = 3.5936e-01, time/batch = 17.1982s	
11352/11850 (epoch 47.899), train_loss = 0.71115982, grad/param norm = 3.4798e-01, time/batch = 18.3025s	
11353/11850 (epoch 47.903), train_loss = 0.73315400, grad/param norm = 3.0730e-01, time/batch = 16.8934s	
11354/11850 (epoch 47.907), train_loss = 0.76216274, grad/param norm = 3.0009e-01, time/batch = 16.9581s	
11355/11850 (epoch 47.911), train_loss = 0.86504239, grad/param norm = 3.4663e-01, time/batch = 17.0429s	
11356/11850 (epoch 47.916), train_loss = 0.81494288, grad/param norm = 3.4758e-01, time/batch = 15.2132s	
11357/11850 (epoch 47.920), train_loss = 0.79719846, grad/param norm = 3.1354e-01, time/batch = 15.6907s	
11358/11850 (epoch 47.924), train_loss = 0.75356549, grad/param norm = 3.4849e-01, time/batch = 17.2176s	
11359/11850 (epoch 47.928), train_loss = 0.80703574, grad/param norm = 3.0743e-01, time/batch = 17.3699s	
11360/11850 (epoch 47.932), train_loss = 0.88079008, grad/param norm = 3.6808e-01, time/batch = 19.2996s	
11361/11850 (epoch 47.937), train_loss = 0.86488494, grad/param norm = 3.1811e-01, time/batch = 18.2072s	
11362/11850 (epoch 47.941), train_loss = 0.78632221, grad/param norm = 3.1280e-01, time/batch = 17.7702s	
11363/11850 (epoch 47.945), train_loss = 0.79770221, grad/param norm = 2.6924e-01, time/batch = 18.2934s	
11364/11850 (epoch 47.949), train_loss = 0.76340159, grad/param norm = 3.3094e-01, time/batch = 17.0638s	
11365/11850 (epoch 47.954), train_loss = 0.84128932, grad/param norm = 3.5346e-01, time/batch = 17.7728s	
11366/11850 (epoch 47.958), train_loss = 0.84687560, grad/param norm = 3.3242e-01, time/batch = 16.9341s	
11367/11850 (epoch 47.962), train_loss = 0.75751595, grad/param norm = 3.6067e-01, time/batch = 18.3135s	
11368/11850 (epoch 47.966), train_loss = 0.70079897, grad/param norm = 3.1980e-01, time/batch = 15.8472s	
11369/11850 (epoch 47.970), train_loss = 0.82120100, grad/param norm = 4.0554e-01, time/batch = 15.5534s	
11370/11850 (epoch 47.975), train_loss = 0.78646904, grad/param norm = 3.6691e-01, time/batch = 18.5495s	
11371/11850 (epoch 47.979), train_loss = 0.83548729, grad/param norm = 5.4685e-01, time/batch = 17.8707s	
11372/11850 (epoch 47.983), train_loss = 0.88279482, grad/param norm = 3.9874e-01, time/batch = 18.9673s	
11373/11850 (epoch 47.987), train_loss = 0.75555426, grad/param norm = 3.3324e-01, time/batch = 15.0737s	
11374/11850 (epoch 47.992), train_loss = 0.89957638, grad/param norm = 3.1443e-01, time/batch = 18.3098s	
11375/11850 (epoch 47.996), train_loss = 0.88977096, grad/param norm = 3.2344e-01, time/batch = 17.5449s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
11376/11850 (epoch 48.000), train_loss = 0.78311322, grad/param norm = 3.1658e-01, time/batch = 18.6429s	
11377/11850 (epoch 48.004), train_loss = 0.86911388, grad/param norm = 3.8451e-01, time/batch = 18.2885s	
11378/11850 (epoch 48.008), train_loss = 0.87141210, grad/param norm = 3.0864e-01, time/batch = 16.3732s	
11379/11850 (epoch 48.013), train_loss = 0.88590931, grad/param norm = 2.9919e-01, time/batch = 17.7938s	
11380/11850 (epoch 48.017), train_loss = 0.91606594, grad/param norm = 3.3003e-01, time/batch = 16.9797s	
11381/11850 (epoch 48.021), train_loss = 0.87264792, grad/param norm = 2.9279e-01, time/batch = 16.2019s	
11382/11850 (epoch 48.025), train_loss = 0.76025788, grad/param norm = 2.5467e-01, time/batch = 15.2296s	
11383/11850 (epoch 48.030), train_loss = 0.79674056, grad/param norm = 3.0087e-01, time/batch = 16.8808s	
11384/11850 (epoch 48.034), train_loss = 0.77325502, grad/param norm = 3.2433e-01, time/batch = 17.8801s	
11385/11850 (epoch 48.038), train_loss = 0.77295823, grad/param norm = 2.7757e-01, time/batch = 16.8170s	
11386/11850 (epoch 48.042), train_loss = 0.81451206, grad/param norm = 3.3823e-01, time/batch = 19.2841s	
11387/11850 (epoch 48.046), train_loss = 0.77831782, grad/param norm = 3.7848e-01, time/batch = 18.3854s	
11388/11850 (epoch 48.051), train_loss = 0.80264366, grad/param norm = 3.4145e-01, time/batch = 18.2835s	
11389/11850 (epoch 48.055), train_loss = 0.76004754, grad/param norm = 2.8376e-01, time/batch = 16.0945s	
11390/11850 (epoch 48.059), train_loss = 0.83790093, grad/param norm = 3.1468e-01, time/batch = 18.0411s	
11391/11850 (epoch 48.063), train_loss = 0.91310198, grad/param norm = 3.1925e-01, time/batch = 19.0435s	
11392/11850 (epoch 48.068), train_loss = 0.79615986, grad/param norm = 3.5157e-01, time/batch = 16.0525s	
11393/11850 (epoch 48.072), train_loss = 0.84871900, grad/param norm = 3.1573e-01, time/batch = 18.3055s	
11394/11850 (epoch 48.076), train_loss = 0.91844091, grad/param norm = 3.2788e-01, time/batch = 17.7187s	
11395/11850 (epoch 48.080), train_loss = 0.74634543, grad/param norm = 3.0027e-01, time/batch = 17.3867s	
11396/11850 (epoch 48.084), train_loss = 0.73381162, grad/param norm = 3.2282e-01, time/batch = 16.9499s	
11397/11850 (epoch 48.089), train_loss = 0.71172208, grad/param norm = 2.7991e-01, time/batch = 17.4548s	
11398/11850 (epoch 48.093), train_loss = 0.75131805, grad/param norm = 3.5412e-01, time/batch = 16.9354s	
11399/11850 (epoch 48.097), train_loss = 0.79830126, grad/param norm = 3.0431e-01, time/batch = 16.1434s	
11400/11850 (epoch 48.101), train_loss = 0.71019671, grad/param norm = 2.9370e-01, time/batch = 16.2236s	
11401/11850 (epoch 48.105), train_loss = 0.73317211, grad/param norm = 2.6695e-01, time/batch = 18.2101s	
11402/11850 (epoch 48.110), train_loss = 0.87082073, grad/param norm = 2.9621e-01, time/batch = 17.9426s	
11403/11850 (epoch 48.114), train_loss = 0.73308161, grad/param norm = 2.8087e-01, time/batch = 18.8752s	
11404/11850 (epoch 48.118), train_loss = 0.84993408, grad/param norm = 2.9835e-01, time/batch = 18.3063s	
11405/11850 (epoch 48.122), train_loss = 0.91062816, grad/param norm = 3.2944e-01, time/batch = 18.9535s	
11406/11850 (epoch 48.127), train_loss = 0.85505927, grad/param norm = 3.3298e-01, time/batch = 17.8026s	
11407/11850 (epoch 48.131), train_loss = 0.80807846, grad/param norm = 3.3590e-01, time/batch = 17.1330s	
11408/11850 (epoch 48.135), train_loss = 0.81627515, grad/param norm = 3.1279e-01, time/batch = 18.7931s	
11409/11850 (epoch 48.139), train_loss = 0.80309420, grad/param norm = 3.2446e-01, time/batch = 17.2880s	
11410/11850 (epoch 48.143), train_loss = 0.77387041, grad/param norm = 2.8762e-01, time/batch = 18.2328s	
11411/11850 (epoch 48.148), train_loss = 0.78923009, grad/param norm = 3.2886e-01, time/batch = 17.8823s	
11412/11850 (epoch 48.152), train_loss = 0.88063476, grad/param norm = 3.4952e-01, time/batch = 17.2813s	
11413/11850 (epoch 48.156), train_loss = 0.75780017, grad/param norm = 3.2921e-01, time/batch = 17.5586s	
11414/11850 (epoch 48.160), train_loss = 0.94778386, grad/param norm = 4.3709e-01, time/batch = 16.2038s	
11415/11850 (epoch 48.165), train_loss = 0.86073810, grad/param norm = 3.7680e-01, time/batch = 17.9473s	
11416/11850 (epoch 48.169), train_loss = 0.78762261, grad/param norm = 4.6580e-01, time/batch = 17.8583s	
11417/11850 (epoch 48.173), train_loss = 0.86262799, grad/param norm = 3.5671e-01, time/batch = 16.6237s	
11418/11850 (epoch 48.177), train_loss = 0.72000698, grad/param norm = 4.0247e-01, time/batch = 18.3062s	
11419/11850 (epoch 48.181), train_loss = 0.81892565, grad/param norm = 3.1087e-01, time/batch = 17.8787s	
11420/11850 (epoch 48.186), train_loss = 0.88193206, grad/param norm = 3.5586e-01, time/batch = 16.9772s	
11421/11850 (epoch 48.190), train_loss = 0.85033033, grad/param norm = 3.5231e-01, time/batch = 17.4593s	
11422/11850 (epoch 48.194), train_loss = 0.82325061, grad/param norm = 5.1035e-01, time/batch = 16.9595s	
11423/11850 (epoch 48.198), train_loss = 0.69118023, grad/param norm = 3.3581e-01, time/batch = 18.2870s	
11424/11850 (epoch 48.203), train_loss = 0.68782529, grad/param norm = 2.6038e-01, time/batch = 16.9734s	
11425/11850 (epoch 48.207), train_loss = 0.84241413, grad/param norm = 3.5467e-01, time/batch = 18.7229s	
11426/11850 (epoch 48.211), train_loss = 0.78212609, grad/param norm = 3.4458e-01, time/batch = 17.4569s	
11427/11850 (epoch 48.215), train_loss = 0.82960298, grad/param norm = 3.3340e-01, time/batch = 17.1444s	
11428/11850 (epoch 48.219), train_loss = 0.82848789, grad/param norm = 3.0501e-01, time/batch = 18.7998s	
11429/11850 (epoch 48.224), train_loss = 0.91989171, grad/param norm = 3.2295e-01, time/batch = 17.1070s	
11430/11850 (epoch 48.228), train_loss = 0.84669660, grad/param norm = 3.3557e-01, time/batch = 17.7995s	
11431/11850 (epoch 48.232), train_loss = 0.82299981, grad/param norm = 3.6678e-01, time/batch = 18.0535s	
11432/11850 (epoch 48.236), train_loss = 0.75925600, grad/param norm = 2.9550e-01, time/batch = 18.3983s	
11433/11850 (epoch 48.241), train_loss = 0.86929560, grad/param norm = 3.5875e-01, time/batch = 16.1386s	
11434/11850 (epoch 48.245), train_loss = 0.86388654, grad/param norm = 3.4988e-01, time/batch = 15.2311s	
11435/11850 (epoch 48.249), train_loss = 0.80839105, grad/param norm = 2.6219e-01, time/batch = 16.4025s	
11436/11850 (epoch 48.253), train_loss = 0.80562431, grad/param norm = 3.5764e-01, time/batch = 17.3061s	
11437/11850 (epoch 48.257), train_loss = 0.92400690, grad/param norm = 3.4079e-01, time/batch = 16.9709s	
11438/11850 (epoch 48.262), train_loss = 0.93018648, grad/param norm = 3.4426e-01, time/batch = 19.0556s	
11439/11850 (epoch 48.266), train_loss = 0.91289883, grad/param norm = 3.7779e-01, time/batch = 18.6453s	
11440/11850 (epoch 48.270), train_loss = 0.81436169, grad/param norm = 2.7437e-01, time/batch = 18.1195s	
11441/11850 (epoch 48.274), train_loss = 0.79944340, grad/param norm = 3.1787e-01, time/batch = 17.0567s	
11442/11850 (epoch 48.278), train_loss = 0.70272812, grad/param norm = 2.9625e-01, time/batch = 17.4539s	
11443/11850 (epoch 48.283), train_loss = 0.81640364, grad/param norm = 2.7478e-01, time/batch = 14.7150s	
11444/11850 (epoch 48.287), train_loss = 0.91522261, grad/param norm = 3.4804e-01, time/batch = 15.6361s	
11445/11850 (epoch 48.291), train_loss = 0.80660502, grad/param norm = 3.4129e-01, time/batch = 17.3829s	
11446/11850 (epoch 48.295), train_loss = 0.82883396, grad/param norm = 3.0514e-01, time/batch = 17.2187s	
11447/11850 (epoch 48.300), train_loss = 0.76962774, grad/param norm = 3.3380e-01, time/batch = 9.6591s	
11448/11850 (epoch 48.304), train_loss = 0.81834335, grad/param norm = 2.8961e-01, time/batch = 0.6383s	
11449/11850 (epoch 48.308), train_loss = 0.81622802, grad/param norm = 3.8645e-01, time/batch = 0.6407s	
11450/11850 (epoch 48.312), train_loss = 0.73084457, grad/param norm = 3.0872e-01, time/batch = 0.6392s	
11451/11850 (epoch 48.316), train_loss = 0.81114881, grad/param norm = 2.8632e-01, time/batch = 0.6393s	
11452/11850 (epoch 48.321), train_loss = 0.76996583, grad/param norm = 2.8826e-01, time/batch = 0.6430s	
11453/11850 (epoch 48.325), train_loss = 0.82320822, grad/param norm = 3.0878e-01, time/batch = 0.6389s	
11454/11850 (epoch 48.329), train_loss = 0.81091096, grad/param norm = 3.3302e-01, time/batch = 0.6495s	
11455/11850 (epoch 48.333), train_loss = 0.77673562, grad/param norm = 2.8627e-01, time/batch = 0.8394s	
11456/11850 (epoch 48.338), train_loss = 0.78546678, grad/param norm = 2.9281e-01, time/batch = 0.9380s	
11457/11850 (epoch 48.342), train_loss = 0.80990027, grad/param norm = 3.1360e-01, time/batch = 0.9359s	
11458/11850 (epoch 48.346), train_loss = 0.79484650, grad/param norm = 3.3570e-01, time/batch = 0.9273s	
11459/11850 (epoch 48.350), train_loss = 0.72322628, grad/param norm = 2.7404e-01, time/batch = 0.9365s	
11460/11850 (epoch 48.354), train_loss = 0.85073903, grad/param norm = 3.1671e-01, time/batch = 1.1663s	
11461/11850 (epoch 48.359), train_loss = 0.92038354, grad/param norm = 3.1308e-01, time/batch = 1.7503s	
11462/11850 (epoch 48.363), train_loss = 0.82662998, grad/param norm = 2.9512e-01, time/batch = 1.7729s	
11463/11850 (epoch 48.367), train_loss = 0.86509781, grad/param norm = 3.2217e-01, time/batch = 10.1019s	
11464/11850 (epoch 48.371), train_loss = 0.86017746, grad/param norm = 2.8525e-01, time/batch = 15.9849s	
11465/11850 (epoch 48.376), train_loss = 0.82799225, grad/param norm = 2.7461e-01, time/batch = 16.0291s	
11466/11850 (epoch 48.380), train_loss = 0.77424714, grad/param norm = 2.5965e-01, time/batch = 17.5453s	
11467/11850 (epoch 48.384), train_loss = 0.70799721, grad/param norm = 2.7188e-01, time/batch = 15.6283s	
11468/11850 (epoch 48.388), train_loss = 0.86386283, grad/param norm = 3.3276e-01, time/batch = 19.4640s	
11469/11850 (epoch 48.392), train_loss = 0.82359416, grad/param norm = 3.1177e-01, time/batch = 17.1214s	
11470/11850 (epoch 48.397), train_loss = 0.84525833, grad/param norm = 3.3569e-01, time/batch = 17.8128s	
11471/11850 (epoch 48.401), train_loss = 0.69256107, grad/param norm = 2.5395e-01, time/batch = 17.9745s	
11472/11850 (epoch 48.405), train_loss = 0.73245185, grad/param norm = 3.2171e-01, time/batch = 17.4587s	
11473/11850 (epoch 48.409), train_loss = 0.83084308, grad/param norm = 2.8288e-01, time/batch = 18.5455s	
11474/11850 (epoch 48.414), train_loss = 0.67783631, grad/param norm = 2.7851e-01, time/batch = 16.9744s	
11475/11850 (epoch 48.418), train_loss = 0.72394890, grad/param norm = 3.2080e-01, time/batch = 18.5435s	
11476/11850 (epoch 48.422), train_loss = 0.65271441, grad/param norm = 2.7262e-01, time/batch = 17.0342s	
11477/11850 (epoch 48.426), train_loss = 0.64998976, grad/param norm = 3.0974e-01, time/batch = 18.6383s	
11478/11850 (epoch 48.430), train_loss = 0.71136956, grad/param norm = 3.0436e-01, time/batch = 15.4562s	
11479/11850 (epoch 48.435), train_loss = 0.75182243, grad/param norm = 2.8919e-01, time/batch = 16.2869s	
11480/11850 (epoch 48.439), train_loss = 0.81995310, grad/param norm = 2.9071e-01, time/batch = 16.8768s	
11481/11850 (epoch 48.443), train_loss = 0.79396126, grad/param norm = 3.2702e-01, time/batch = 18.0469s	
11482/11850 (epoch 48.447), train_loss = 0.69317562, grad/param norm = 2.8273e-01, time/batch = 16.8909s	
11483/11850 (epoch 48.451), train_loss = 0.69788453, grad/param norm = 2.9154e-01, time/batch = 18.2228s	
11484/11850 (epoch 48.456), train_loss = 0.79099458, grad/param norm = 3.2456e-01, time/batch = 16.3891s	
11485/11850 (epoch 48.460), train_loss = 0.82031257, grad/param norm = 2.8478e-01, time/batch = 16.0478s	
11486/11850 (epoch 48.464), train_loss = 0.75324122, grad/param norm = 3.5922e-01, time/batch = 17.4783s	
11487/11850 (epoch 48.468), train_loss = 0.82806676, grad/param norm = 3.1152e-01, time/batch = 18.1308s	
11488/11850 (epoch 48.473), train_loss = 0.84833023, grad/param norm = 3.0956e-01, time/batch = 18.3027s	
11489/11850 (epoch 48.477), train_loss = 0.71725630, grad/param norm = 3.0541e-01, time/batch = 17.6271s	
11490/11850 (epoch 48.481), train_loss = 0.74291582, grad/param norm = 3.0251e-01, time/batch = 18.2955s	
11491/11850 (epoch 48.485), train_loss = 0.69807746, grad/param norm = 2.6178e-01, time/batch = 16.2106s	
11492/11850 (epoch 48.489), train_loss = 0.79633655, grad/param norm = 2.8375e-01, time/batch = 19.4451s	
11493/11850 (epoch 48.494), train_loss = 0.71440448, grad/param norm = 4.3165e-01, time/batch = 15.9519s	
11494/11850 (epoch 48.498), train_loss = 0.73308715, grad/param norm = 3.8723e-01, time/batch = 19.4700s	
11495/11850 (epoch 48.502), train_loss = 0.67427672, grad/param norm = 2.7511e-01, time/batch = 18.5570s	
11496/11850 (epoch 48.506), train_loss = 0.91605408, grad/param norm = 3.2367e-01, time/batch = 26.3288s	
11497/11850 (epoch 48.511), train_loss = 0.76733000, grad/param norm = 2.8931e-01, time/batch = 21.5065s	
11498/11850 (epoch 48.515), train_loss = 0.86761821, grad/param norm = 3.6611e-01, time/batch = 18.2158s	
11499/11850 (epoch 48.519), train_loss = 0.73050505, grad/param norm = 3.3222e-01, time/batch = 18.4482s	
11500/11850 (epoch 48.523), train_loss = 0.77539562, grad/param norm = 2.9381e-01, time/batch = 15.3560s	
11501/11850 (epoch 48.527), train_loss = 0.74377391, grad/param norm = 3.1107e-01, time/batch = 18.3010s	
11502/11850 (epoch 48.532), train_loss = 0.79472430, grad/param norm = 2.9423e-01, time/batch = 15.8113s	
11503/11850 (epoch 48.536), train_loss = 0.74067903, grad/param norm = 2.9535e-01, time/batch = 15.4881s	
11504/11850 (epoch 48.540), train_loss = 0.67694605, grad/param norm = 3.0646e-01, time/batch = 18.3005s	
11505/11850 (epoch 48.544), train_loss = 0.72798692, grad/param norm = 3.6728e-01, time/batch = 17.2049s	
11506/11850 (epoch 48.549), train_loss = 0.67429707, grad/param norm = 2.8665e-01, time/batch = 19.0309s	
11507/11850 (epoch 48.553), train_loss = 0.78065241, grad/param norm = 3.0714e-01, time/batch = 18.1349s	
11508/11850 (epoch 48.557), train_loss = 0.82694099, grad/param norm = 2.8752e-01, time/batch = 18.4787s	
11509/11850 (epoch 48.561), train_loss = 0.85168148, grad/param norm = 3.3555e-01, time/batch = 16.7122s	
11510/11850 (epoch 48.565), train_loss = 0.91099072, grad/param norm = 3.7996e-01, time/batch = 16.7411s	
11511/11850 (epoch 48.570), train_loss = 0.80578940, grad/param norm = 2.8213e-01, time/batch = 17.5609s	
11512/11850 (epoch 48.574), train_loss = 0.82603301, grad/param norm = 2.8380e-01, time/batch = 17.8662s	
11513/11850 (epoch 48.578), train_loss = 0.82923708, grad/param norm = 2.8766e-01, time/batch = 17.2229s	
11514/11850 (epoch 48.582), train_loss = 0.77230802, grad/param norm = 3.4325e-01, time/batch = 17.8866s	
11515/11850 (epoch 48.586), train_loss = 0.79431288, grad/param norm = 3.4453e-01, time/batch = 17.2915s	
11516/11850 (epoch 48.591), train_loss = 0.79799970, grad/param norm = 4.0259e-01, time/batch = 15.9565s	
11517/11850 (epoch 48.595), train_loss = 0.65816150, grad/param norm = 3.1779e-01, time/batch = 15.8899s	
11518/11850 (epoch 48.599), train_loss = 0.76809299, grad/param norm = 3.0217e-01, time/batch = 18.6313s	
11519/11850 (epoch 48.603), train_loss = 0.73039595, grad/param norm = 2.7722e-01, time/batch = 16.1953s	
11520/11850 (epoch 48.608), train_loss = 0.90336655, grad/param norm = 3.1146e-01, time/batch = 19.1975s	
11521/11850 (epoch 48.612), train_loss = 0.94249494, grad/param norm = 3.7161e-01, time/batch = 18.0455s	
11522/11850 (epoch 48.616), train_loss = 0.89021135, grad/param norm = 2.9861e-01, time/batch = 15.4676s	
11523/11850 (epoch 48.620), train_loss = 0.76866666, grad/param norm = 3.2808e-01, time/batch = 17.4692s	
11524/11850 (epoch 48.624), train_loss = 0.77107473, grad/param norm = 3.3695e-01, time/batch = 18.6399s	
11525/11850 (epoch 48.629), train_loss = 0.76735407, grad/param norm = 2.8448e-01, time/batch = 17.8859s	
11526/11850 (epoch 48.633), train_loss = 0.71437491, grad/param norm = 2.7192e-01, time/batch = 16.7955s	
11527/11850 (epoch 48.637), train_loss = 0.63237700, grad/param norm = 2.6220e-01, time/batch = 18.9709s	
11528/11850 (epoch 48.641), train_loss = 0.67943750, grad/param norm = 2.6099e-01, time/batch = 18.1357s	
11529/11850 (epoch 48.646), train_loss = 0.71225484, grad/param norm = 3.5339e-01, time/batch = 17.7067s	
11530/11850 (epoch 48.650), train_loss = 0.80043756, grad/param norm = 3.9234e-01, time/batch = 18.1287s	
11531/11850 (epoch 48.654), train_loss = 0.73211824, grad/param norm = 3.0627e-01, time/batch = 16.0647s	
11532/11850 (epoch 48.658), train_loss = 0.82436519, grad/param norm = 3.2131e-01, time/batch = 18.4469s	
11533/11850 (epoch 48.662), train_loss = 0.69556594, grad/param norm = 3.7979e-01, time/batch = 17.2931s	
11534/11850 (epoch 48.667), train_loss = 0.86261200, grad/param norm = 2.9606e-01, time/batch = 17.1972s	
11535/11850 (epoch 48.671), train_loss = 0.74249788, grad/param norm = 2.8820e-01, time/batch = 18.7891s	
11536/11850 (epoch 48.675), train_loss = 0.77131760, grad/param norm = 3.3948e-01, time/batch = 16.8829s	
11537/11850 (epoch 48.679), train_loss = 0.76466321, grad/param norm = 2.6186e-01, time/batch = 16.1379s	
11538/11850 (epoch 48.684), train_loss = 0.74722870, grad/param norm = 3.0620e-01, time/batch = 16.6316s	
11539/11850 (epoch 48.688), train_loss = 0.72468694, grad/param norm = 3.0808e-01, time/batch = 18.8880s	
11540/11850 (epoch 48.692), train_loss = 0.73544544, grad/param norm = 3.3020e-01, time/batch = 16.2201s	
11541/11850 (epoch 48.696), train_loss = 0.71566640, grad/param norm = 4.2594e-01, time/batch = 18.5494s	
11542/11850 (epoch 48.700), train_loss = 0.78064599, grad/param norm = 3.4899e-01, time/batch = 19.1329s	
11543/11850 (epoch 48.705), train_loss = 0.67694361, grad/param norm = 2.9601e-01, time/batch = 17.4658s	
11544/11850 (epoch 48.709), train_loss = 0.67042853, grad/param norm = 3.0575e-01, time/batch = 17.4700s	
11545/11850 (epoch 48.713), train_loss = 0.67062525, grad/param norm = 3.3988e-01, time/batch = 18.2261s	
11546/11850 (epoch 48.717), train_loss = 0.74096367, grad/param norm = 2.8079e-01, time/batch = 17.9461s	
11547/11850 (epoch 48.722), train_loss = 0.75544876, grad/param norm = 3.1057e-01, time/batch = 16.2844s	
11548/11850 (epoch 48.726), train_loss = 0.69658419, grad/param norm = 3.2457e-01, time/batch = 17.3604s	
11549/11850 (epoch 48.730), train_loss = 0.69813725, grad/param norm = 2.9978e-01, time/batch = 17.8027s	
11550/11850 (epoch 48.734), train_loss = 0.69209883, grad/param norm = 3.0377e-01, time/batch = 16.0444s	
11551/11850 (epoch 48.738), train_loss = 0.79338347, grad/param norm = 3.6122e-01, time/batch = 17.4656s	
11552/11850 (epoch 48.743), train_loss = 0.76712157, grad/param norm = 3.2870e-01, time/batch = 15.2222s	
11553/11850 (epoch 48.747), train_loss = 0.69097295, grad/param norm = 2.5950e-01, time/batch = 18.3823s	
11554/11850 (epoch 48.751), train_loss = 0.76181858, grad/param norm = 2.8339e-01, time/batch = 16.2234s	
11555/11850 (epoch 48.755), train_loss = 0.77747985, grad/param norm = 2.7741e-01, time/batch = 16.7029s	
11556/11850 (epoch 48.759), train_loss = 0.70301387, grad/param norm = 2.8579e-01, time/batch = 16.7330s	
11557/11850 (epoch 48.764), train_loss = 0.74930283, grad/param norm = 2.8707e-01, time/batch = 17.2180s	
11558/11850 (epoch 48.768), train_loss = 0.69543529, grad/param norm = 3.2511e-01, time/batch = 19.1330s	
11559/11850 (epoch 48.772), train_loss = 0.73273449, grad/param norm = 3.0633e-01, time/batch = 16.8115s	
11560/11850 (epoch 48.776), train_loss = 0.77423442, grad/param norm = 3.0412e-01, time/batch = 17.8626s	
11561/11850 (epoch 48.781), train_loss = 0.73465056, grad/param norm = 2.9482e-01, time/batch = 19.3747s	
11562/11850 (epoch 48.785), train_loss = 0.75484010, grad/param norm = 3.0613e-01, time/batch = 15.1038s	
11563/11850 (epoch 48.789), train_loss = 0.72539742, grad/param norm = 2.8409e-01, time/batch = 18.9587s	
11564/11850 (epoch 48.793), train_loss = 0.78434548, grad/param norm = 2.7294e-01, time/batch = 15.6958s	
11565/11850 (epoch 48.797), train_loss = 0.74028317, grad/param norm = 3.3755e-01, time/batch = 19.2174s	
11566/11850 (epoch 48.802), train_loss = 0.68816317, grad/param norm = 2.9479e-01, time/batch = 15.6233s	
11567/11850 (epoch 48.806), train_loss = 0.75995354, grad/param norm = 3.1841e-01, time/batch = 17.5342s	
11568/11850 (epoch 48.810), train_loss = 0.80382132, grad/param norm = 3.5226e-01, time/batch = 18.8538s	
11569/11850 (epoch 48.814), train_loss = 0.77106783, grad/param norm = 3.2108e-01, time/batch = 18.0399s	
11570/11850 (epoch 48.819), train_loss = 0.86895326, grad/param norm = 2.9698e-01, time/batch = 17.6290s	
11571/11850 (epoch 48.823), train_loss = 0.83711882, grad/param norm = 3.0046e-01, time/batch = 17.0493s	
11572/11850 (epoch 48.827), train_loss = 0.74987182, grad/param norm = 3.3377e-01, time/batch = 19.5268s	
11573/11850 (epoch 48.831), train_loss = 0.72212032, grad/param norm = 3.2016e-01, time/batch = 16.3789s	
11574/11850 (epoch 48.835), train_loss = 0.81257651, grad/param norm = 3.9869e-01, time/batch = 14.4080s	
11575/11850 (epoch 48.840), train_loss = 0.74184705, grad/param norm = 2.8006e-01, time/batch = 17.4782s	
11576/11850 (epoch 48.844), train_loss = 0.77825102, grad/param norm = 2.7708e-01, time/batch = 16.9667s	
11577/11850 (epoch 48.848), train_loss = 0.79994826, grad/param norm = 3.0987e-01, time/batch = 18.4612s	
11578/11850 (epoch 48.852), train_loss = 0.79312956, grad/param norm = 2.7390e-01, time/batch = 17.7952s	
11579/11850 (epoch 48.857), train_loss = 0.75768624, grad/param norm = 3.1123e-01, time/batch = 18.3089s	
11580/11850 (epoch 48.861), train_loss = 0.71821275, grad/param norm = 3.6244e-01, time/batch = 18.9689s	
11581/11850 (epoch 48.865), train_loss = 0.81763889, grad/param norm = 3.5187e-01, time/batch = 15.7707s	
11582/11850 (epoch 48.869), train_loss = 0.79232301, grad/param norm = 3.2641e-01, time/batch = 18.4667s	
11583/11850 (epoch 48.873), train_loss = 0.76541987, grad/param norm = 3.2564e-01, time/batch = 17.0463s	
11584/11850 (epoch 48.878), train_loss = 0.80213207, grad/param norm = 3.2384e-01, time/batch = 17.2963s	
11585/11850 (epoch 48.882), train_loss = 0.79775034, grad/param norm = 3.3952e-01, time/batch = 18.2111s	
11586/11850 (epoch 48.886), train_loss = 0.75364262, grad/param norm = 3.9097e-01, time/batch = 17.2013s	
11587/11850 (epoch 48.890), train_loss = 0.78466711, grad/param norm = 3.8542e-01, time/batch = 17.7145s	
11588/11850 (epoch 48.895), train_loss = 0.76807478, grad/param norm = 3.2314e-01, time/batch = 19.2786s	
11589/11850 (epoch 48.899), train_loss = 0.68950895, grad/param norm = 3.2889e-01, time/batch = 17.7935s	
11590/11850 (epoch 48.903), train_loss = 0.72459114, grad/param norm = 3.2550e-01, time/batch = 18.7168s	
11591/11850 (epoch 48.907), train_loss = 0.74602828, grad/param norm = 3.0537e-01, time/batch = 17.4535s	
11592/11850 (epoch 48.911), train_loss = 0.85256142, grad/param norm = 3.0815e-01, time/batch = 18.3094s	
11593/11850 (epoch 48.916), train_loss = 0.81629914, grad/param norm = 3.4416e-01, time/batch = 19.2159s	
11594/11850 (epoch 48.920), train_loss = 0.80357318, grad/param norm = 3.4636e-01, time/batch = 16.3565s	
11595/11850 (epoch 48.924), train_loss = 0.74596832, grad/param norm = 3.4399e-01, time/batch = 16.9574s	
11596/11850 (epoch 48.928), train_loss = 0.81922316, grad/param norm = 4.8639e-01, time/batch = 18.5509s	
11597/11850 (epoch 48.932), train_loss = 0.87053935, grad/param norm = 3.0048e-01, time/batch = 17.5443s	
11598/11850 (epoch 48.937), train_loss = 0.85665009, grad/param norm = 2.9228e-01, time/batch = 17.1222s	
11599/11850 (epoch 48.941), train_loss = 0.78408623, grad/param norm = 3.2091e-01, time/batch = 16.9653s	
11600/11850 (epoch 48.945), train_loss = 0.78854058, grad/param norm = 2.8116e-01, time/batch = 17.6412s	
11601/11850 (epoch 48.949), train_loss = 0.76250373, grad/param norm = 3.7956e-01, time/batch = 16.7047s	
11602/11850 (epoch 48.954), train_loss = 0.81831360, grad/param norm = 3.4570e-01, time/batch = 15.4486s	
11603/11850 (epoch 48.958), train_loss = 0.82158506, grad/param norm = 3.4591e-01, time/batch = 16.6170s	
11604/11850 (epoch 48.962), train_loss = 0.72788088, grad/param norm = 3.0369e-01, time/batch = 17.6396s	
11605/11850 (epoch 48.966), train_loss = 0.67622356, grad/param norm = 3.1334e-01, time/batch = 18.3683s	
11606/11850 (epoch 48.970), train_loss = 0.82585970, grad/param norm = 3.5404e-01, time/batch = 17.7251s	
11607/11850 (epoch 48.975), train_loss = 0.76392368, grad/param norm = 3.1255e-01, time/batch = 19.0469s	
11608/11850 (epoch 48.979), train_loss = 0.80838112, grad/param norm = 3.3210e-01, time/batch = 18.1252s	
11609/11850 (epoch 48.983), train_loss = 0.87472966, grad/param norm = 4.1244e-01, time/batch = 19.0622s	
11610/11850 (epoch 48.987), train_loss = 0.76494553, grad/param norm = 3.8537e-01, time/batch = 17.5534s	
11611/11850 (epoch 48.992), train_loss = 0.87667648, grad/param norm = 3.2634e-01, time/batch = 16.3836s	
11612/11850 (epoch 48.996), train_loss = 0.86603129, grad/param norm = 3.2619e-01, time/batch = 15.4658s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
11613/11850 (epoch 49.000), train_loss = 0.78634985, grad/param norm = 3.6974e-01, time/batch = 15.8195s	
11614/11850 (epoch 49.004), train_loss = 0.85619700, grad/param norm = 4.3122e-01, time/batch = 18.3791s	
11615/11850 (epoch 49.008), train_loss = 0.86303729, grad/param norm = 3.3858e-01, time/batch = 15.9606s	
11616/11850 (epoch 49.013), train_loss = 0.88221171, grad/param norm = 3.4373e-01, time/batch = 17.2339s	
11617/11850 (epoch 49.017), train_loss = 0.92252894, grad/param norm = 3.7396e-01, time/batch = 17.3916s	
11618/11850 (epoch 49.021), train_loss = 0.87849858, grad/param norm = 3.0762e-01, time/batch = 13.7574s	
11619/11850 (epoch 49.025), train_loss = 0.76192259, grad/param norm = 2.8341e-01, time/batch = 16.8009s	
11620/11850 (epoch 49.030), train_loss = 0.79490797, grad/param norm = 3.2593e-01, time/batch = 15.8995s	
11621/11850 (epoch 49.034), train_loss = 0.76120090, grad/param norm = 3.0566e-01, time/batch = 17.2130s	
11622/11850 (epoch 49.038), train_loss = 0.77153778, grad/param norm = 3.2370e-01, time/batch = 15.6879s	
11623/11850 (epoch 49.042), train_loss = 0.80696699, grad/param norm = 3.2985e-01, time/batch = 18.6366s	
11624/11850 (epoch 49.046), train_loss = 0.77408879, grad/param norm = 3.9213e-01, time/batch = 18.1192s	
11625/11850 (epoch 49.051), train_loss = 0.79137405, grad/param norm = 3.0829e-01, time/batch = 18.0462s	
11626/11850 (epoch 49.055), train_loss = 0.75876440, grad/param norm = 2.8231e-01, time/batch = 17.0613s	
11627/11850 (epoch 49.059), train_loss = 0.83057261, grad/param norm = 3.0837e-01, time/batch = 18.6293s	
11628/11850 (epoch 49.063), train_loss = 0.89955567, grad/param norm = 3.3049e-01, time/batch = 19.5433s	
11629/11850 (epoch 49.068), train_loss = 0.77974904, grad/param norm = 3.0015e-01, time/batch = 17.3738s	
11630/11850 (epoch 49.072), train_loss = 0.84619406, grad/param norm = 3.3213e-01, time/batch = 16.7297s	
11631/11850 (epoch 49.076), train_loss = 0.89575123, grad/param norm = 3.2393e-01, time/batch = 17.4834s	
11632/11850 (epoch 49.080), train_loss = 0.74128062, grad/param norm = 3.1260e-01, time/batch = 17.1217s	
11633/11850 (epoch 49.084), train_loss = 0.71181716, grad/param norm = 2.7911e-01, time/batch = 17.4621s	
11634/11850 (epoch 49.089), train_loss = 0.70924050, grad/param norm = 3.0836e-01, time/batch = 17.0574s	
11635/11850 (epoch 49.093), train_loss = 0.72936767, grad/param norm = 3.2248e-01, time/batch = 14.9571s	
11636/11850 (epoch 49.097), train_loss = 0.78676894, grad/param norm = 2.8568e-01, time/batch = 14.7055s	
11637/11850 (epoch 49.101), train_loss = 0.70212676, grad/param norm = 3.3770e-01, time/batch = 15.5199s	
11638/11850 (epoch 49.105), train_loss = 0.72061833, grad/param norm = 3.3405e-01, time/batch = 14.7707s	
11639/11850 (epoch 49.110), train_loss = 0.87330065, grad/param norm = 2.9506e-01, time/batch = 14.3657s	
11640/11850 (epoch 49.114), train_loss = 0.73012984, grad/param norm = 3.2111e-01, time/batch = 14.3348s	
11641/11850 (epoch 49.118), train_loss = 0.84093039, grad/param norm = 2.9145e-01, time/batch = 15.1238s	
11642/11850 (epoch 49.122), train_loss = 0.90111003, grad/param norm = 3.5012e-01, time/batch = 17.5420s	
11643/11850 (epoch 49.127), train_loss = 0.83628513, grad/param norm = 3.3152e-01, time/batch = 17.6261s	
11644/11850 (epoch 49.131), train_loss = 0.79071097, grad/param norm = 3.7091e-01, time/batch = 19.0373s	
11645/11850 (epoch 49.135), train_loss = 0.80770207, grad/param norm = 3.4303e-01, time/batch = 16.9812s	
11646/11850 (epoch 49.139), train_loss = 0.78163578, grad/param norm = 3.0766e-01, time/batch = 18.1528s	
11647/11850 (epoch 49.143), train_loss = 0.75931247, grad/param norm = 3.0387e-01, time/batch = 17.6245s	
11648/11850 (epoch 49.148), train_loss = 0.78141252, grad/param norm = 3.7130e-01, time/batch = 18.6346s	
11649/11850 (epoch 49.152), train_loss = 0.87296643, grad/param norm = 3.6358e-01, time/batch = 18.4645s	
11650/11850 (epoch 49.156), train_loss = 0.75039018, grad/param norm = 3.5335e-01, time/batch = 16.4367s	
11651/11850 (epoch 49.160), train_loss = 0.94243261, grad/param norm = 3.5605e-01, time/batch = 17.8591s	
11652/11850 (epoch 49.165), train_loss = 0.86179257, grad/param norm = 3.5418e-01, time/batch = 16.9003s	
11653/11850 (epoch 49.169), train_loss = 0.78228209, grad/param norm = 3.9400e-01, time/batch = 18.0456s	
11654/11850 (epoch 49.173), train_loss = 0.84512634, grad/param norm = 4.4618e-01, time/batch = 17.8812s	
11655/11850 (epoch 49.177), train_loss = 0.70557925, grad/param norm = 5.2392e-01, time/batch = 16.1347s	
11656/11850 (epoch 49.181), train_loss = 0.80388889, grad/param norm = 3.2388e-01, time/batch = 16.0580s	
11657/11850 (epoch 49.186), train_loss = 0.87815824, grad/param norm = 3.8155e-01, time/batch = 15.6990s	
11658/11850 (epoch 49.190), train_loss = 0.83198907, grad/param norm = 3.1066e-01, time/batch = 16.1406s	
11659/11850 (epoch 49.194), train_loss = 0.81314831, grad/param norm = 4.2779e-01, time/batch = 18.3078s	
11660/11850 (epoch 49.198), train_loss = 0.68854159, grad/param norm = 3.1938e-01, time/batch = 17.9676s	
11661/11850 (epoch 49.203), train_loss = 0.68263558, grad/param norm = 3.0827e-01, time/batch = 16.8005s	
11662/11850 (epoch 49.207), train_loss = 0.84050119, grad/param norm = 3.6821e-01, time/batch = 16.6511s	
11663/11850 (epoch 49.211), train_loss = 0.75703390, grad/param norm = 3.0454e-01, time/batch = 18.0532s	
11664/11850 (epoch 49.215), train_loss = 0.82355287, grad/param norm = 3.5159e-01, time/batch = 16.3870s	
11665/11850 (epoch 49.219), train_loss = 0.83202553, grad/param norm = 3.0552e-01, time/batch = 18.5479s	
11666/11850 (epoch 49.224), train_loss = 0.90963851, grad/param norm = 3.2573e-01, time/batch = 17.2292s	
11667/11850 (epoch 49.228), train_loss = 0.84710793, grad/param norm = 2.9465e-01, time/batch = 17.2205s	
11668/11850 (epoch 49.232), train_loss = 0.81503757, grad/param norm = 3.0975e-01, time/batch = 17.1347s	
11669/11850 (epoch 49.236), train_loss = 0.75999501, grad/param norm = 3.2581e-01, time/batch = 18.2915s	
11670/11850 (epoch 49.241), train_loss = 0.86294653, grad/param norm = 4.0102e-01, time/batch = 16.7121s	
11671/11850 (epoch 49.245), train_loss = 0.85213585, grad/param norm = 3.3275e-01, time/batch = 17.0420s	
11672/11850 (epoch 49.249), train_loss = 0.79540900, grad/param norm = 2.9099e-01, time/batch = 16.4725s	
11673/11850 (epoch 49.253), train_loss = 0.79335730, grad/param norm = 3.8373e-01, time/batch = 18.4997s	
11674/11850 (epoch 49.257), train_loss = 0.90555729, grad/param norm = 3.2143e-01, time/batch = 17.5488s	
11675/11850 (epoch 49.262), train_loss = 0.91712220, grad/param norm = 3.9103e-01, time/batch = 17.8726s	
11676/11850 (epoch 49.266), train_loss = 0.90784671, grad/param norm = 3.9245e-01, time/batch = 18.7106s	
11677/11850 (epoch 49.270), train_loss = 0.80949467, grad/param norm = 2.8858e-01, time/batch = 19.1336s	
11678/11850 (epoch 49.274), train_loss = 0.80761454, grad/param norm = 3.7002e-01, time/batch = 17.8587s	
11679/11850 (epoch 49.278), train_loss = 0.70787268, grad/param norm = 3.8540e-01, time/batch = 15.8773s	
11680/11850 (epoch 49.283), train_loss = 0.81022455, grad/param norm = 2.9388e-01, time/batch = 19.1101s	
11681/11850 (epoch 49.287), train_loss = 0.90668705, grad/param norm = 3.4440e-01, time/batch = 17.5449s	
11682/11850 (epoch 49.291), train_loss = 0.79849017, grad/param norm = 3.2435e-01, time/batch = 17.3944s	
11683/11850 (epoch 49.295), train_loss = 0.80403429, grad/param norm = 2.8029e-01, time/batch = 18.7198s	
11684/11850 (epoch 49.300), train_loss = 0.77346876, grad/param norm = 3.9854e-01, time/batch = 16.8610s	
11685/11850 (epoch 49.304), train_loss = 0.80002621, grad/param norm = 2.6907e-01, time/batch = 18.7225s	
11686/11850 (epoch 49.308), train_loss = 0.80621762, grad/param norm = 3.4481e-01, time/batch = 18.3007s	
11687/11850 (epoch 49.312), train_loss = 0.73386716, grad/param norm = 3.4131e-01, time/batch = 16.4678s	
11688/11850 (epoch 49.316), train_loss = 0.79543420, grad/param norm = 2.5931e-01, time/batch = 15.1495s	
11689/11850 (epoch 49.321), train_loss = 0.76928845, grad/param norm = 3.0225e-01, time/batch = 17.2992s	
11690/11850 (epoch 49.325), train_loss = 0.80952375, grad/param norm = 3.0948e-01, time/batch = 17.6365s	
11691/11850 (epoch 49.329), train_loss = 0.79580992, grad/param norm = 3.1347e-01, time/batch = 16.5518s	
11692/11850 (epoch 49.333), train_loss = 0.78358017, grad/param norm = 3.2006e-01, time/batch = 17.8877s	
11693/11850 (epoch 49.338), train_loss = 0.77587785, grad/param norm = 2.8610e-01, time/batch = 17.2214s	
11694/11850 (epoch 49.342), train_loss = 0.80224709, grad/param norm = 3.1101e-01, time/batch = 17.4531s	
11695/11850 (epoch 49.346), train_loss = 0.77150701, grad/param norm = 2.9878e-01, time/batch = 16.7060s	
11696/11850 (epoch 49.350), train_loss = 0.71402612, grad/param norm = 2.7921e-01, time/batch = 16.8515s	
11697/11850 (epoch 49.354), train_loss = 0.85578395, grad/param norm = 3.1857e-01, time/batch = 18.5503s	
11698/11850 (epoch 49.359), train_loss = 0.90087067, grad/param norm = 3.7210e-01, time/batch = 17.4638s	
11699/11850 (epoch 49.363), train_loss = 0.82273838, grad/param norm = 2.9758e-01, time/batch = 19.6216s	
11700/11850 (epoch 49.367), train_loss = 0.85041091, grad/param norm = 2.8362e-01, time/batch = 17.0663s	
11701/11850 (epoch 49.371), train_loss = 0.85691994, grad/param norm = 2.7175e-01, time/batch = 19.9937s	
11702/11850 (epoch 49.376), train_loss = 0.82958061, grad/param norm = 2.7982e-01, time/batch = 30.3458s	
11703/11850 (epoch 49.380), train_loss = 0.78294616, grad/param norm = 2.8794e-01, time/batch = 17.7193s	
11704/11850 (epoch 49.384), train_loss = 0.70720353, grad/param norm = 2.9202e-01, time/batch = 15.4653s	
11705/11850 (epoch 49.388), train_loss = 0.84506001, grad/param norm = 3.0956e-01, time/batch = 17.4753s	
11706/11850 (epoch 49.392), train_loss = 0.81774366, grad/param norm = 3.3934e-01, time/batch = 16.9583s	
11707/11850 (epoch 49.397), train_loss = 0.83160529, grad/param norm = 3.0870e-01, time/batch = 17.3858s	
11708/11850 (epoch 49.401), train_loss = 0.68612960, grad/param norm = 2.6051e-01, time/batch = 17.8788s	
11709/11850 (epoch 49.405), train_loss = 0.71007321, grad/param norm = 2.7333e-01, time/batch = 15.6261s	
11710/11850 (epoch 49.409), train_loss = 0.82258675, grad/param norm = 2.9825e-01, time/batch = 16.9533s	
11711/11850 (epoch 49.414), train_loss = 0.66904468, grad/param norm = 2.9367e-01, time/batch = 16.7959s	
11712/11850 (epoch 49.418), train_loss = 0.71129826, grad/param norm = 3.4573e-01, time/batch = 18.5568s	
11713/11850 (epoch 49.422), train_loss = 0.65555102, grad/param norm = 2.9199e-01, time/batch = 17.3825s	
11714/11850 (epoch 49.426), train_loss = 0.64096043, grad/param norm = 2.9025e-01, time/batch = 17.7046s	
11715/11850 (epoch 49.430), train_loss = 0.69540309, grad/param norm = 3.3266e-01, time/batch = 18.3676s	
11716/11850 (epoch 49.435), train_loss = 0.73975100, grad/param norm = 2.8761e-01, time/batch = 16.7318s	
11717/11850 (epoch 49.439), train_loss = 0.79812430, grad/param norm = 2.7666e-01, time/batch = 16.8844s	
11718/11850 (epoch 49.443), train_loss = 0.78197797, grad/param norm = 3.3299e-01, time/batch = 16.3549s	
11719/11850 (epoch 49.447), train_loss = 0.70173750, grad/param norm = 3.0755e-01, time/batch = 19.3013s	
11720/11850 (epoch 49.451), train_loss = 0.67820434, grad/param norm = 2.8052e-01, time/batch = 15.9955s	
11721/11850 (epoch 49.456), train_loss = 0.79165347, grad/param norm = 3.5107e-01, time/batch = 18.2889s	
11722/11850 (epoch 49.460), train_loss = 0.80483332, grad/param norm = 2.8509e-01, time/batch = 17.8858s	
11723/11850 (epoch 49.464), train_loss = 0.73857104, grad/param norm = 2.9340e-01, time/batch = 15.6390s	
11724/11850 (epoch 49.468), train_loss = 0.82515765, grad/param norm = 3.0023e-01, time/batch = 15.1188s	
11725/11850 (epoch 49.473), train_loss = 0.83090847, grad/param norm = 3.4312e-01, time/batch = 18.0398s	
11726/11850 (epoch 49.477), train_loss = 0.70737430, grad/param norm = 3.0481e-01, time/batch = 18.9735s	
11727/11850 (epoch 49.481), train_loss = 0.74211590, grad/param norm = 3.1923e-01, time/batch = 18.2239s	
11728/11850 (epoch 49.485), train_loss = 0.69067197, grad/param norm = 2.5987e-01, time/batch = 17.3804s	
11729/11850 (epoch 49.489), train_loss = 0.77183592, grad/param norm = 2.9046e-01, time/batch = 14.0582s	
11730/11850 (epoch 49.494), train_loss = 0.72101905, grad/param norm = 3.5533e-01, time/batch = 15.4555s	
11731/11850 (epoch 49.498), train_loss = 0.71820926, grad/param norm = 3.8821e-01, time/batch = 17.8921s	
11732/11850 (epoch 49.502), train_loss = 0.66773755, grad/param norm = 3.0808e-01, time/batch = 16.5475s	
11733/11850 (epoch 49.506), train_loss = 0.91006468, grad/param norm = 3.2681e-01, time/batch = 18.0621s	
11734/11850 (epoch 49.511), train_loss = 0.75687903, grad/param norm = 2.8280e-01, time/batch = 18.7971s	
11735/11850 (epoch 49.515), train_loss = 0.85073809, grad/param norm = 3.9412e-01, time/batch = 16.7964s	
11736/11850 (epoch 49.519), train_loss = 0.72848999, grad/param norm = 3.2942e-01, time/batch = 18.3893s	
11737/11850 (epoch 49.523), train_loss = 0.77382153, grad/param norm = 2.8007e-01, time/batch = 15.8874s	
11738/11850 (epoch 49.527), train_loss = 0.72705932, grad/param norm = 3.4907e-01, time/batch = 15.7834s	
11739/11850 (epoch 49.532), train_loss = 0.78366638, grad/param norm = 3.0799e-01, time/batch = 17.2798s	
11740/11850 (epoch 49.536), train_loss = 0.72919295, grad/param norm = 2.8949e-01, time/batch = 16.8130s	
11741/11850 (epoch 49.540), train_loss = 0.66944077, grad/param norm = 2.9557e-01, time/batch = 17.2265s	
11742/11850 (epoch 49.544), train_loss = 0.70610361, grad/param norm = 3.6732e-01, time/batch = 17.0504s	
11743/11850 (epoch 49.549), train_loss = 0.65531237, grad/param norm = 2.6639e-01, time/batch = 18.8751s	
11744/11850 (epoch 49.553), train_loss = 0.76958670, grad/param norm = 2.9900e-01, time/batch = 17.2962s	
11745/11850 (epoch 49.557), train_loss = 0.81783497, grad/param norm = 3.5027e-01, time/batch = 17.2905s	
11746/11850 (epoch 49.561), train_loss = 0.83212522, grad/param norm = 3.0659e-01, time/batch = 17.0345s	
11747/11850 (epoch 49.565), train_loss = 0.90301239, grad/param norm = 4.0551e-01, time/batch = 18.3959s	
11748/11850 (epoch 49.570), train_loss = 0.80037023, grad/param norm = 2.9144e-01, time/batch = 19.2959s	
11749/11850 (epoch 49.574), train_loss = 0.82409709, grad/param norm = 3.0050e-01, time/batch = 16.9620s	
11750/11850 (epoch 49.578), train_loss = 0.81613583, grad/param norm = 2.9598e-01, time/batch = 18.2994s	
11751/11850 (epoch 49.582), train_loss = 0.77732546, grad/param norm = 3.0600e-01, time/batch = 19.4611s	
11752/11850 (epoch 49.586), train_loss = 0.78032234, grad/param norm = 3.5698e-01, time/batch = 16.9711s	
11753/11850 (epoch 49.591), train_loss = 0.78653764, grad/param norm = 3.7895e-01, time/batch = 17.1973s	
11754/11850 (epoch 49.595), train_loss = 0.66021917, grad/param norm = 3.3009e-01, time/batch = 14.7161s	
11755/11850 (epoch 49.599), train_loss = 0.75543979, grad/param norm = 2.8988e-01, time/batch = 17.3186s	
11756/11850 (epoch 49.603), train_loss = 0.72324937, grad/param norm = 2.7244e-01, time/batch = 16.7874s	
11757/11850 (epoch 49.608), train_loss = 0.90989069, grad/param norm = 3.4198e-01, time/batch = 17.7979s	
11758/11850 (epoch 49.612), train_loss = 0.95334672, grad/param norm = 3.9150e-01, time/batch = 15.1423s	
11759/11850 (epoch 49.616), train_loss = 0.88873279, grad/param norm = 3.0253e-01, time/batch = 17.9586s	
11760/11850 (epoch 49.620), train_loss = 0.76400714, grad/param norm = 3.4253e-01, time/batch = 17.1253s	
11761/11850 (epoch 49.624), train_loss = 0.76410415, grad/param norm = 3.8136e-01, time/batch = 18.2021s	
11762/11850 (epoch 49.629), train_loss = 0.76929676, grad/param norm = 3.1310e-01, time/batch = 19.3754s	
11763/11850 (epoch 49.633), train_loss = 0.70186075, grad/param norm = 2.7088e-01, time/batch = 16.1753s	
11764/11850 (epoch 49.637), train_loss = 0.62838191, grad/param norm = 2.6384e-01, time/batch = 18.9727s	
11765/11850 (epoch 49.641), train_loss = 0.66313163, grad/param norm = 2.6475e-01, time/batch = 18.8863s	
11766/11850 (epoch 49.646), train_loss = 0.70087910, grad/param norm = 3.1421e-01, time/batch = 16.8775s	
11767/11850 (epoch 49.650), train_loss = 0.77447913, grad/param norm = 3.0234e-01, time/batch = 19.4754s	
11768/11850 (epoch 49.654), train_loss = 0.72757519, grad/param norm = 3.3973e-01, time/batch = 16.6454s	
11769/11850 (epoch 49.658), train_loss = 0.81416116, grad/param norm = 2.9564e-01, time/batch = 16.2199s	
11770/11850 (epoch 49.662), train_loss = 0.69270394, grad/param norm = 3.4592e-01, time/batch = 17.4543s	
11771/11850 (epoch 49.667), train_loss = 0.85696177, grad/param norm = 3.0038e-01, time/batch = 18.2917s	
11772/11850 (epoch 49.671), train_loss = 0.72714161, grad/param norm = 2.8983e-01, time/batch = 16.8599s	
11773/11850 (epoch 49.675), train_loss = 0.75531720, grad/param norm = 2.9113e-01, time/batch = 16.7108s	
11774/11850 (epoch 49.679), train_loss = 0.76811763, grad/param norm = 2.7406e-01, time/batch = 14.9585s	
11775/11850 (epoch 49.684), train_loss = 0.73408419, grad/param norm = 3.1001e-01, time/batch = 17.8636s	
11776/11850 (epoch 49.688), train_loss = 0.70922430, grad/param norm = 2.7936e-01, time/batch = 17.5524s	
11777/11850 (epoch 49.692), train_loss = 0.72537897, grad/param norm = 3.5145e-01, time/batch = 18.9727s	
11778/11850 (epoch 49.696), train_loss = 0.68307543, grad/param norm = 3.2369e-01, time/batch = 17.9668s	
11779/11850 (epoch 49.700), train_loss = 0.74979793, grad/param norm = 2.9298e-01, time/batch = 19.1214s	
11780/11850 (epoch 49.705), train_loss = 0.66720313, grad/param norm = 2.9013e-01, time/batch = 17.9477s	
11781/11850 (epoch 49.709), train_loss = 0.67573775, grad/param norm = 3.1475e-01, time/batch = 18.0550s	
11782/11850 (epoch 49.713), train_loss = 0.67191648, grad/param norm = 4.2086e-01, time/batch = 18.3022s	
11783/11850 (epoch 49.717), train_loss = 0.73819770, grad/param norm = 2.9420e-01, time/batch = 15.3530s	
11784/11850 (epoch 49.722), train_loss = 0.74731488, grad/param norm = 3.2007e-01, time/batch = 16.1480s	
11785/11850 (epoch 49.726), train_loss = 0.69042198, grad/param norm = 3.0330e-01, time/batch = 17.6276s	
11786/11850 (epoch 49.730), train_loss = 0.69262514, grad/param norm = 2.7514e-01, time/batch = 18.7058s	
11787/11850 (epoch 49.734), train_loss = 0.67627893, grad/param norm = 2.8962e-01, time/batch = 17.6841s	
11788/11850 (epoch 49.738), train_loss = 0.78410179, grad/param norm = 4.4325e-01, time/batch = 17.7080s	
11789/11850 (epoch 49.743), train_loss = 0.77539449, grad/param norm = 4.2617e-01, time/batch = 18.0550s	
11790/11850 (epoch 49.747), train_loss = 0.70367309, grad/param norm = 2.5843e-01, time/batch = 15.8545s	
11791/11850 (epoch 49.751), train_loss = 0.75638546, grad/param norm = 2.8764e-01, time/batch = 17.1180s	
11792/11850 (epoch 49.755), train_loss = 0.76990687, grad/param norm = 2.9398e-01, time/batch = 17.9522s	
11793/11850 (epoch 49.759), train_loss = 0.70183459, grad/param norm = 2.9793e-01, time/batch = 17.6223s	
11794/11850 (epoch 49.764), train_loss = 0.73148258, grad/param norm = 2.6791e-01, time/batch = 18.3697s	
11795/11850 (epoch 49.768), train_loss = 0.68192626, grad/param norm = 2.6172e-01, time/batch = 14.1037s	
11796/11850 (epoch 49.772), train_loss = 0.72129697, grad/param norm = 2.9638e-01, time/batch = 18.4729s	
11797/11850 (epoch 49.776), train_loss = 0.75895402, grad/param norm = 2.8927e-01, time/batch = 17.3806s	
11798/11850 (epoch 49.781), train_loss = 0.72428226, grad/param norm = 3.5387e-01, time/batch = 17.2936s	
11799/11850 (epoch 49.785), train_loss = 0.75384912, grad/param norm = 3.4579e-01, time/batch = 16.2058s	
11800/11850 (epoch 49.789), train_loss = 0.72293673, grad/param norm = 3.0584e-01, time/batch = 17.2038s	
11801/11850 (epoch 49.793), train_loss = 0.78481375, grad/param norm = 2.9808e-01, time/batch = 18.3032s	
11802/11850 (epoch 49.797), train_loss = 0.72674459, grad/param norm = 3.3396e-01, time/batch = 16.9632s	
11803/11850 (epoch 49.802), train_loss = 0.67632671, grad/param norm = 2.9060e-01, time/batch = 18.9672s	
11804/11850 (epoch 49.806), train_loss = 0.76351597, grad/param norm = 3.6874e-01, time/batch = 17.0229s	
11805/11850 (epoch 49.810), train_loss = 0.79405303, grad/param norm = 3.8006e-01, time/batch = 16.8827s	
11806/11850 (epoch 49.814), train_loss = 0.76634787, grad/param norm = 3.3966e-01, time/batch = 17.3003s	
11807/11850 (epoch 49.819), train_loss = 0.85963533, grad/param norm = 3.2384e-01, time/batch = 17.3782s	
11808/11850 (epoch 49.823), train_loss = 0.83574506, grad/param norm = 3.5326e-01, time/batch = 19.1077s	
11809/11850 (epoch 49.827), train_loss = 0.74117616, grad/param norm = 3.3566e-01, time/batch = 17.9450s	
11810/11850 (epoch 49.831), train_loss = 0.71559500, grad/param norm = 3.0852e-01, time/batch = 17.3921s	
11811/11850 (epoch 49.835), train_loss = 0.78643775, grad/param norm = 2.5813e-01, time/batch = 18.2940s	
11812/11850 (epoch 49.840), train_loss = 0.73334136, grad/param norm = 3.2362e-01, time/batch = 18.6435s	
11813/11850 (epoch 49.844), train_loss = 0.76497082, grad/param norm = 2.8751e-01, time/batch = 16.8088s	
11814/11850 (epoch 49.848), train_loss = 0.77756972, grad/param norm = 3.0237e-01, time/batch = 17.1016s	
11815/11850 (epoch 49.852), train_loss = 0.77996306, grad/param norm = 2.9673e-01, time/batch = 16.6949s	
11816/11850 (epoch 49.857), train_loss = 0.75598408, grad/param norm = 3.4731e-01, time/batch = 19.3853s	
11817/11850 (epoch 49.861), train_loss = 0.70468917, grad/param norm = 4.9013e-01, time/batch = 16.8762s	
11818/11850 (epoch 49.865), train_loss = 0.82429243, grad/param norm = 4.2372e-01, time/batch = 18.1427s	
11819/11850 (epoch 49.869), train_loss = 0.78171273, grad/param norm = 3.3956e-01, time/batch = 16.6510s	
11820/11850 (epoch 49.873), train_loss = 0.76566615, grad/param norm = 3.4787e-01, time/batch = 14.6415s	
11821/11850 (epoch 49.878), train_loss = 0.79481381, grad/param norm = 3.2036e-01, time/batch = 16.2016s	
11822/11850 (epoch 49.882), train_loss = 0.78194873, grad/param norm = 3.3401e-01, time/batch = 18.9684s	
11823/11850 (epoch 49.886), train_loss = 0.73127332, grad/param norm = 4.2203e-01, time/batch = 18.0650s	
11824/11850 (epoch 49.890), train_loss = 0.76909140, grad/param norm = 3.3077e-01, time/batch = 17.7036s	
11825/11850 (epoch 49.895), train_loss = 0.77341704, grad/param norm = 4.0614e-01, time/batch = 18.5270s	
11826/11850 (epoch 49.899), train_loss = 0.69725877, grad/param norm = 3.6638e-01, time/batch = 17.7811s	
11827/11850 (epoch 49.903), train_loss = 0.72867746, grad/param norm = 3.5947e-01, time/batch = 18.3705s	
11828/11850 (epoch 49.907), train_loss = 0.74432627, grad/param norm = 2.9911e-01, time/batch = 18.2098s	
11829/11850 (epoch 49.911), train_loss = 0.84332628, grad/param norm = 3.1819e-01, time/batch = 16.7148s	
11830/11850 (epoch 49.916), train_loss = 0.79393404, grad/param norm = 3.6120e-01, time/batch = 19.0459s	
11831/11850 (epoch 49.920), train_loss = 0.77506058, grad/param norm = 2.9012e-01, time/batch = 17.2913s	
11832/11850 (epoch 49.924), train_loss = 0.73729241, grad/param norm = 3.0721e-01, time/batch = 18.5457s	
11833/11850 (epoch 49.928), train_loss = 0.80103254, grad/param norm = 4.1815e-01, time/batch = 16.7379s	
11834/11850 (epoch 49.932), train_loss = 0.87741620, grad/param norm = 4.1444e-01, time/batch = 16.6289s	
11835/11850 (epoch 49.937), train_loss = 0.86463682, grad/param norm = 3.1583e-01, time/batch = 17.3831s	
11836/11850 (epoch 49.941), train_loss = 0.77071377, grad/param norm = 3.3832e-01, time/batch = 18.1486s	
11837/11850 (epoch 49.945), train_loss = 0.78461697, grad/param norm = 2.8640e-01, time/batch = 18.7990s	
11838/11850 (epoch 49.949), train_loss = 0.75598486, grad/param norm = 4.0110e-01, time/batch = 18.3658s	
11839/11850 (epoch 49.954), train_loss = 0.83544366, grad/param norm = 4.0486e-01, time/batch = 16.6409s	
11840/11850 (epoch 49.958), train_loss = 0.82715408, grad/param norm = 3.8916e-01, time/batch = 16.8107s	
11841/11850 (epoch 49.962), train_loss = 0.73327152, grad/param norm = 3.8076e-01, time/batch = 15.7170s	
11842/11850 (epoch 49.966), train_loss = 0.68258708, grad/param norm = 3.4126e-01, time/batch = 14.4821s	
11843/11850 (epoch 49.970), train_loss = 0.80844582, grad/param norm = 3.0615e-01, time/batch = 16.1238s	
11844/11850 (epoch 49.975), train_loss = 0.77203844, grad/param norm = 3.4023e-01, time/batch = 18.7919s	
11845/11850 (epoch 49.979), train_loss = 0.79845492, grad/param norm = 3.3398e-01, time/batch = 17.2977s	
11846/11850 (epoch 49.983), train_loss = 0.83972704, grad/param norm = 3.3024e-01, time/batch = 18.3007s	
11847/11850 (epoch 49.987), train_loss = 0.73773342, grad/param norm = 3.2536e-01, time/batch = 17.1331s	
11848/11850 (epoch 49.992), train_loss = 0.89366324, grad/param norm = 3.4869e-01, time/batch = 16.4753s	
11849/11850 (epoch 49.996), train_loss = 0.87214391, grad/param norm = 3.5068e-01, time/batch = 15.7943s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/13...	
2/13...	
3/13...	
4/13...	
5/13...	
6/13...	
7/13...	
8/13...	
9/13...	
10/13...	
11/13...	
12/13...	
13/13...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_katelyn_salem_epoch50.00_2.5414.t7	
11850/11850 (epoch 50.000), train_loss = 0.77248609, grad/param norm = 4.7470e-01, time/batch = 18.1396s	

real	1454m30.072s
user	1445m3.252s
sys	1m16.936s
