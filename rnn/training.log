tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 663, val: 35, test: 0	
vocab size: 135	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 285191	
cloning rnn	
cloning criterion	
1/33150 (epoch 0.002), train_loss = 4.91886719, grad/param norm = 5.3752e-01, time/batch = 0.7054s	
2/33150 (epoch 0.003), train_loss = 4.68527503, grad/param norm = 1.4804e+00, time/batch = 0.6720s	
3/33150 (epoch 0.005), train_loss = 3.87196514, grad/param norm = 1.2911e+00, time/batch = 0.6750s	
4/33150 (epoch 0.006), train_loss = 3.56078468, grad/param norm = 1.0351e+00, time/batch = 0.6778s	
5/33150 (epoch 0.008), train_loss = 3.51846954, grad/param norm = 1.1221e+00, time/batch = 0.6664s	
6/33150 (epoch 0.009), train_loss = 3.60587410, grad/param norm = 8.3091e-01, time/batch = 0.6666s	
7/33150 (epoch 0.011), train_loss = 3.49732915, grad/param norm = 6.8487e-01, time/batch = 0.6792s	
8/33150 (epoch 0.012), train_loss = 3.53548922, grad/param norm = 7.0418e-01, time/batch = 0.6748s	
9/33150 (epoch 0.014), train_loss = 3.46353583, grad/param norm = 6.7355e-01, time/batch = 0.6775s	
10/33150 (epoch 0.015), train_loss = 3.36797139, grad/param norm = 7.4083e-01, time/batch = 0.6715s	
11/33150 (epoch 0.017), train_loss = 3.49859015, grad/param norm = 6.0619e-01, time/batch = 0.6738s	
12/33150 (epoch 0.018), train_loss = 3.41285380, grad/param norm = 6.0569e-01, time/batch = 0.6659s	
13/33150 (epoch 0.020), train_loss = 3.58764424, grad/param norm = 5.6414e-01, time/batch = 0.6703s	
14/33150 (epoch 0.021), train_loss = 3.39951627, grad/param norm = 5.8960e-01, time/batch = 0.6686s	
15/33150 (epoch 0.023), train_loss = 3.55442505, grad/param norm = 7.4735e-01, time/batch = 0.6674s	
16/33150 (epoch 0.024), train_loss = 3.48252792, grad/param norm = 6.7913e-01, time/batch = 0.6674s	
17/33150 (epoch 0.026), train_loss = 3.49457329, grad/param norm = 8.5233e-01, time/batch = 0.6698s	
18/33150 (epoch 0.027), train_loss = 3.43492518, grad/param norm = 7.2538e-01, time/batch = 0.6750s	
19/33150 (epoch 0.029), train_loss = 3.63173968, grad/param norm = 6.5632e-01, time/batch = 0.6772s	
20/33150 (epoch 0.030), train_loss = 3.46401794, grad/param norm = 7.5266e-01, time/batch = 0.6695s	
21/33150 (epoch 0.032), train_loss = 3.48856019, grad/param norm = 9.9050e-01, time/batch = 0.6706s	
22/33150 (epoch 0.033), train_loss = 3.45574175, grad/param norm = 9.3546e-01, time/batch = 0.6682s	
23/33150 (epoch 0.035), train_loss = 3.42241751, grad/param norm = 5.4766e-01, time/batch = 0.6699s	
24/33150 (epoch 0.036), train_loss = 3.41482271, grad/param norm = 7.4675e-01, time/batch = 0.6685s	
25/33150 (epoch 0.038), train_loss = 3.44340049, grad/param norm = 7.1978e-01, time/batch = 0.6710s	
26/33150 (epoch 0.039), train_loss = 3.51567629, grad/param norm = 5.8907e-01, time/batch = 0.6679s	
27/33150 (epoch 0.041), train_loss = 3.37377798, grad/param norm = 4.9065e-01, time/batch = 0.6678s	
28/33150 (epoch 0.042), train_loss = 3.48400930, grad/param norm = 6.7241e-01, time/batch = 0.6707s	
29/33150 (epoch 0.044), train_loss = 3.50483119, grad/param norm = 5.2115e-01, time/batch = 0.6683s	
30/33150 (epoch 0.045), train_loss = 3.47881253, grad/param norm = 6.0974e-01, time/batch = 0.6719s	
31/33150 (epoch 0.047), train_loss = 3.51210706, grad/param norm = 5.8279e-01, time/batch = 0.6892s	
32/33150 (epoch 0.048), train_loss = 3.59422957, grad/param norm = 4.9540e-01, time/batch = 0.6896s	
33/33150 (epoch 0.050), train_loss = 3.44181909, grad/param norm = 7.1349e-01, time/batch = 0.6811s	
34/33150 (epoch 0.051), train_loss = 3.43396772, grad/param norm = 4.8311e-01, time/batch = 0.6760s	
35/33150 (epoch 0.053), train_loss = 3.33799888, grad/param norm = 5.4133e-01, time/batch = 0.6843s	
36/33150 (epoch 0.054), train_loss = 3.50831860, grad/param norm = 5.4942e-01, time/batch = 0.6953s	
37/33150 (epoch 0.056), train_loss = 3.50520706, grad/param norm = 5.8715e-01, time/batch = 0.6865s	
38/33150 (epoch 0.057), train_loss = 3.38275905, grad/param norm = 6.0543e-01, time/batch = 0.6874s	
39/33150 (epoch 0.059), train_loss = 3.47184345, grad/param norm = 6.3256e-01, time/batch = 0.6861s	
40/33150 (epoch 0.060), train_loss = 3.50303177, grad/param norm = 6.5137e-01, time/batch = 0.6886s	
41/33150 (epoch 0.062), train_loss = 3.45800315, grad/param norm = 3.9540e-01, time/batch = 0.6990s	
42/33150 (epoch 0.063), train_loss = 3.57182818, grad/param norm = 5.7439e-01, time/batch = 0.6984s	
43/33150 (epoch 0.065), train_loss = 3.55056679, grad/param norm = 6.7749e-01, time/batch = 0.7016s	
44/33150 (epoch 0.066), train_loss = 3.46957805, grad/param norm = 6.0031e-01, time/batch = 0.6976s	
45/33150 (epoch 0.068), train_loss = 3.45022428, grad/param norm = 4.6665e-01, time/batch = 0.6998s	
46/33150 (epoch 0.069), train_loss = 3.35383856, grad/param norm = 8.0797e-01, time/batch = 0.6650s	
47/33150 (epoch 0.071), train_loss = 3.46016588, grad/param norm = 5.8775e-01, time/batch = 0.6647s	
48/33150 (epoch 0.072), train_loss = 3.53902833, grad/param norm = 6.9645e-01, time/batch = 0.6685s	
49/33150 (epoch 0.074), train_loss = 3.46060732, grad/param norm = 6.1855e-01, time/batch = 0.6654s	
50/33150 (epoch 0.075), train_loss = 3.49898423, grad/param norm = 4.9749e-01, time/batch = 0.6681s	
51/33150 (epoch 0.077), train_loss = 3.61312789, grad/param norm = 5.0380e-01, time/batch = 0.6672s	
52/33150 (epoch 0.078), train_loss = 3.40209045, grad/param norm = 5.6117e-01, time/batch = 0.6791s	
53/33150 (epoch 0.080), train_loss = 3.51642189, grad/param norm = 5.3210e-01, time/batch = 0.6736s	
54/33150 (epoch 0.081), train_loss = 3.45208187, grad/param norm = 5.5418e-01, time/batch = 0.6696s	
55/33150 (epoch 0.083), train_loss = 3.52732374, grad/param norm = 7.4124e-01, time/batch = 0.6707s	
56/33150 (epoch 0.084), train_loss = 3.60837020, grad/param norm = 7.7805e-01, time/batch = 0.6723s	
57/33150 (epoch 0.086), train_loss = 3.48579279, grad/param norm = 5.5553e-01, time/batch = 0.6765s	
58/33150 (epoch 0.087), train_loss = 3.43362091, grad/param norm = 7.2782e-01, time/batch = 0.6699s	
59/33150 (epoch 0.089), train_loss = 3.47751388, grad/param norm = 5.6171e-01, time/batch = 0.6696s	
60/33150 (epoch 0.090), train_loss = 3.44478640, grad/param norm = 7.8230e-01, time/batch = 0.6701s	
61/33150 (epoch 0.092), train_loss = 3.62712372, grad/param norm = 6.8414e-01, time/batch = 0.6730s	
62/33150 (epoch 0.094), train_loss = 3.44825387, grad/param norm = 6.7106e-01, time/batch = 0.6741s	
63/33150 (epoch 0.095), train_loss = 3.63942000, grad/param norm = 4.7034e-01, time/batch = 0.6703s	
64/33150 (epoch 0.097), train_loss = 3.49118965, grad/param norm = 5.6305e-01, time/batch = 0.6684s	
65/33150 (epoch 0.098), train_loss = 3.61163542, grad/param norm = 6.3195e-01, time/batch = 0.6696s	
66/33150 (epoch 0.100), train_loss = 3.52776361, grad/param norm = 5.5461e-01, time/batch = 0.6676s	
67/33150 (epoch 0.101), train_loss = 3.55374501, grad/param norm = 5.9059e-01, time/batch = 0.6788s	
68/33150 (epoch 0.103), train_loss = 3.47793027, grad/param norm = 7.2258e-01, time/batch = 0.6748s	
69/33150 (epoch 0.104), train_loss = 3.57277889, grad/param norm = 7.0400e-01, time/batch = 0.6796s	
70/33150 (epoch 0.106), train_loss = 3.58999741, grad/param norm = 5.1158e-01, time/batch = 0.6860s	
71/33150 (epoch 0.107), train_loss = 3.47866913, grad/param norm = 6.7851e-01, time/batch = 0.6876s	
72/33150 (epoch 0.109), train_loss = 3.55102535, grad/param norm = 5.6718e-01, time/batch = 0.6726s	
73/33150 (epoch 0.110), train_loss = 3.51123582, grad/param norm = 6.0768e-01, time/batch = 0.6689s	
74/33150 (epoch 0.112), train_loss = 3.40029665, grad/param norm = 6.0376e-01, time/batch = 0.6671s	
75/33150 (epoch 0.113), train_loss = 3.43551554, grad/param norm = 7.0343e-01, time/batch = 0.6668s	
76/33150 (epoch 0.115), train_loss = 3.46790247, grad/param norm = 4.5022e-01, time/batch = 0.6656s	
77/33150 (epoch 0.116), train_loss = 3.51144749, grad/param norm = 5.7788e-01, time/batch = 0.6705s	
78/33150 (epoch 0.118), train_loss = 3.50440540, grad/param norm = 4.3438e-01, time/batch = 0.6689s	
79/33150 (epoch 0.119), train_loss = 3.47488398, grad/param norm = 5.3389e-01, time/batch = 0.6673s	
80/33150 (epoch 0.121), train_loss = 3.50983629, grad/param norm = 5.8404e-01, time/batch = 0.6854s	
81/33150 (epoch 0.122), train_loss = 3.43676022, grad/param norm = 5.6010e-01, time/batch = 0.6839s	
82/33150 (epoch 0.124), train_loss = 3.51767907, grad/param norm = 8.0461e-01, time/batch = 0.6799s	
83/33150 (epoch 0.125), train_loss = 3.50331410, grad/param norm = 5.6303e-01, time/batch = 0.6701s	
84/33150 (epoch 0.127), train_loss = 3.52761832, grad/param norm = 5.1082e-01, time/batch = 0.6708s	
85/33150 (epoch 0.128), train_loss = 3.48199473, grad/param norm = 6.5307e-01, time/batch = 0.6697s	
86/33150 (epoch 0.130), train_loss = 3.49277816, grad/param norm = 3.4677e-01, time/batch = 0.6690s	
87/33150 (epoch 0.131), train_loss = 3.44758844, grad/param norm = 6.0148e-01, time/batch = 0.6658s	
88/33150 (epoch 0.133), train_loss = 3.45543601, grad/param norm = 5.8245e-01, time/batch = 0.6677s	
89/33150 (epoch 0.134), train_loss = 3.46684363, grad/param norm = 4.3734e-01, time/batch = 0.6708s	
90/33150 (epoch 0.136), train_loss = 3.47970378, grad/param norm = 4.4359e-01, time/batch = 0.6694s	
91/33150 (epoch 0.137), train_loss = 3.40923089, grad/param norm = 7.1992e-01, time/batch = 0.6676s	
92/33150 (epoch 0.139), train_loss = 3.47262516, grad/param norm = 8.2187e-01, time/batch = 0.6688s	
93/33150 (epoch 0.140), train_loss = 3.38019005, grad/param norm = 5.1322e-01, time/batch = 0.6724s	
94/33150 (epoch 0.142), train_loss = 3.43076721, grad/param norm = 4.5743e-01, time/batch = 0.6664s	
95/33150 (epoch 0.143), train_loss = 3.34910018, grad/param norm = 4.1591e-01, time/batch = 0.6704s	
96/33150 (epoch 0.145), train_loss = 3.50279007, grad/param norm = 4.6240e-01, time/batch = 0.6745s	
97/33150 (epoch 0.146), train_loss = 3.51734444, grad/param norm = 4.5730e-01, time/batch = 0.6783s	
98/33150 (epoch 0.148), train_loss = 3.48196957, grad/param norm = 4.9955e-01, time/batch = 0.6705s	
99/33150 (epoch 0.149), train_loss = 3.52792565, grad/param norm = 3.6054e-01, time/batch = 0.6716s	
100/33150 (epoch 0.151), train_loss = 3.42619991, grad/param norm = 9.9538e-01, time/batch = 0.6829s	
101/33150 (epoch 0.152), train_loss = 3.45722035, grad/param norm = 1.1081e+00, time/batch = 0.6771s	
102/33150 (epoch 0.154), train_loss = 3.41000898, grad/param norm = 4.2502e-01, time/batch = 0.6691s	
103/33150 (epoch 0.155), train_loss = 3.35358645, grad/param norm = 4.2103e-01, time/batch = 0.6698s	
104/33150 (epoch 0.157), train_loss = 3.50463278, grad/param norm = 4.3424e-01, time/batch = 0.6787s	
105/33150 (epoch 0.158), train_loss = 3.39626614, grad/param norm = 5.9406e-01, time/batch = 0.6723s	
106/33150 (epoch 0.160), train_loss = 3.42944580, grad/param norm = 4.8851e-01, time/batch = 0.6682s	
107/33150 (epoch 0.161), train_loss = 3.42175804, grad/param norm = 3.3236e-01, time/batch = 0.6685s	
108/33150 (epoch 0.163), train_loss = 3.43435497, grad/param norm = 5.7855e-01, time/batch = 0.6696s	
109/33150 (epoch 0.164), train_loss = 3.39016104, grad/param norm = 5.7930e-01, time/batch = 0.6721s	
110/33150 (epoch 0.166), train_loss = 3.42094788, grad/param norm = 6.0647e-01, time/batch = 0.6708s	
111/33150 (epoch 0.167), train_loss = 3.29518197, grad/param norm = 4.2264e-01, time/batch = 0.6779s	
112/33150 (epoch 0.169), train_loss = 3.48006387, grad/param norm = 3.9339e-01, time/batch = 0.6771s	
113/33150 (epoch 0.170), train_loss = 3.46463924, grad/param norm = 3.2955e-01, time/batch = 0.6669s	
114/33150 (epoch 0.172), train_loss = 3.34669461, grad/param norm = 5.1385e-01, time/batch = 0.6856s	
115/33150 (epoch 0.173), train_loss = 3.47364585, grad/param norm = 1.3069e+00, time/batch = 0.6769s	
116/33150 (epoch 0.175), train_loss = 3.42812380, grad/param norm = 9.5102e-01, time/batch = 0.6852s	
117/33150 (epoch 0.176), train_loss = 3.30279323, grad/param norm = 5.8690e-01, time/batch = 0.6770s	
118/33150 (epoch 0.178), train_loss = 3.36464140, grad/param norm = 4.9809e-01, time/batch = 0.6714s	
119/33150 (epoch 0.179), train_loss = 3.40301772, grad/param norm = 5.3178e-01, time/batch = 0.6771s	
120/33150 (epoch 0.181), train_loss = 3.38182540, grad/param norm = 5.1938e-01, time/batch = 0.6661s	
121/33150 (epoch 0.183), train_loss = 3.22380026, grad/param norm = 5.6381e-01, time/batch = 0.6678s	
122/33150 (epoch 0.184), train_loss = 3.29023026, grad/param norm = 6.8116e-01, time/batch = 0.6698s	
123/33150 (epoch 0.186), train_loss = 3.45097818, grad/param norm = 6.5830e-01, time/batch = 0.6689s	
124/33150 (epoch 0.187), train_loss = 3.72441835, grad/param norm = 3.2511e+00, time/batch = 0.6672s	
125/33150 (epoch 0.189), train_loss = 3.60978242, grad/param norm = 1.2397e+00, time/batch = 0.6686s	
126/33150 (epoch 0.190), train_loss = 3.37931566, grad/param norm = 5.8355e-01, time/batch = 0.6795s	
127/33150 (epoch 0.192), train_loss = 3.27130499, grad/param norm = 3.7595e-01, time/batch = 0.6734s	
128/33150 (epoch 0.193), train_loss = 3.33011447, grad/param norm = 5.1771e-01, time/batch = 0.6664s	
129/33150 (epoch 0.195), train_loss = 3.35679390, grad/param norm = 5.1695e-01, time/batch = 0.6782s	
130/33150 (epoch 0.196), train_loss = 3.28780338, grad/param norm = 3.0582e-01, time/batch = 0.6750s	
131/33150 (epoch 0.198), train_loss = 3.29723827, grad/param norm = 3.5726e-01, time/batch = 0.6736s	
132/33150 (epoch 0.199), train_loss = 3.22553815, grad/param norm = 4.3662e-01, time/batch = 0.6698s	
133/33150 (epoch 0.201), train_loss = 3.22860221, grad/param norm = 4.2613e-01, time/batch = 0.6672s	
134/33150 (epoch 0.202), train_loss = 3.21647638, grad/param norm = 3.9094e-01, time/batch = 0.6683s	
135/33150 (epoch 0.204), train_loss = 3.15772642, grad/param norm = 3.5353e-01, time/batch = 0.6683s	
136/33150 (epoch 0.205), train_loss = 3.37694518, grad/param norm = 6.5108e-01, time/batch = 0.6669s	
137/33150 (epoch 0.207), train_loss = 3.20402992, grad/param norm = 1.5042e+00, time/batch = 0.6679s	
138/33150 (epoch 0.208), train_loss = 3.35055306, grad/param norm = 1.4984e+00, time/batch = 0.6672s	
139/33150 (epoch 0.210), train_loss = 3.18076436, grad/param norm = 6.7248e-01, time/batch = 0.6676s	
140/33150 (epoch 0.211), train_loss = 3.17370178, grad/param norm = 3.5503e-01, time/batch = 0.6673s	
141/33150 (epoch 0.213), train_loss = 3.29411672, grad/param norm = 4.9475e-01, time/batch = 0.6841s	
142/33150 (epoch 0.214), train_loss = 3.16516249, grad/param norm = 3.7392e-01, time/batch = 0.6873s	
143/33150 (epoch 0.216), train_loss = 3.20966141, grad/param norm = 3.4660e-01, time/batch = 0.6895s	
144/33150 (epoch 0.217), train_loss = 3.18652558, grad/param norm = 3.6369e-01, time/batch = 0.6865s	
145/33150 (epoch 0.219), train_loss = 3.20051115, grad/param norm = 4.3447e-01, time/batch = 0.6848s	
146/33150 (epoch 0.220), train_loss = 3.17634511, grad/param norm = 4.3942e-01, time/batch = 0.6847s	
147/33150 (epoch 0.222), train_loss = 3.11858995, grad/param norm = 6.0916e-01, time/batch = 0.6845s	
148/33150 (epoch 0.223), train_loss = 3.13245625, grad/param norm = 8.7549e-01, time/batch = 0.6804s	
149/33150 (epoch 0.225), train_loss = 3.33485168, grad/param norm = 7.8792e-01, time/batch = 0.6878s	
150/33150 (epoch 0.226), train_loss = 3.14536900, grad/param norm = 6.4620e-01, time/batch = 0.6876s	
151/33150 (epoch 0.228), train_loss = 3.25823180, grad/param norm = 6.4102e-01, time/batch = 0.6853s	
152/33150 (epoch 0.229), train_loss = 3.36100472, grad/param norm = 6.1447e-01, time/batch = 0.6879s	
153/33150 (epoch 0.231), train_loss = 3.20813664, grad/param norm = 5.0121e-01, time/batch = 0.6713s	
154/33150 (epoch 0.232), train_loss = 3.13212633, grad/param norm = 5.4188e-01, time/batch = 0.6686s	
155/33150 (epoch 0.234), train_loss = 3.08295071, grad/param norm = 8.2367e-01, time/batch = 0.6727s	
156/33150 (epoch 0.235), train_loss = 3.16551792, grad/param norm = 1.1063e+00, time/batch = 0.6786s	
157/33150 (epoch 0.237), train_loss = 3.29133357, grad/param norm = 9.5829e-01, time/batch = 0.6700s	
158/33150 (epoch 0.238), train_loss = 3.17507216, grad/param norm = 6.3994e-01, time/batch = 0.6845s	
159/33150 (epoch 0.240), train_loss = 3.08787326, grad/param norm = 4.0915e-01, time/batch = 0.6895s	
160/33150 (epoch 0.241), train_loss = 3.04541056, grad/param norm = 3.6158e-01, time/batch = 0.6946s	
161/33150 (epoch 0.243), train_loss = 3.16251272, grad/param norm = 4.2835e-01, time/batch = 0.6940s	
162/33150 (epoch 0.244), train_loss = 3.15482919, grad/param norm = 6.3575e-01, time/batch = 0.6759s	
163/33150 (epoch 0.246), train_loss = 3.15277380, grad/param norm = 9.2609e-01, time/batch = 0.6714s	
164/33150 (epoch 0.247), train_loss = 3.19297472, grad/param norm = 1.4039e+00, time/batch = 0.6848s	
165/33150 (epoch 0.249), train_loss = 3.27258224, grad/param norm = 1.0269e+00, time/batch = 0.6926s	
166/33150 (epoch 0.250), train_loss = 3.18801420, grad/param norm = 4.7343e-01, time/batch = 0.6913s	
167/33150 (epoch 0.252), train_loss = 3.09425175, grad/param norm = 3.0813e-01, time/batch = 0.6858s	
168/33150 (epoch 0.253), train_loss = 3.11709473, grad/param norm = 4.3781e-01, time/batch = 0.6746s	
169/33150 (epoch 0.255), train_loss = 3.21688014, grad/param norm = 4.7405e-01, time/batch = 0.6814s	
170/33150 (epoch 0.256), train_loss = 3.12633865, grad/param norm = 4.8338e-01, time/batch = 0.6834s	
171/33150 (epoch 0.258), train_loss = 3.07996888, grad/param norm = 5.3050e-01, time/batch = 0.6657s	
172/33150 (epoch 0.259), train_loss = 2.99036396, grad/param norm = 4.4840e-01, time/batch = 0.6665s	
173/33150 (epoch 0.261), train_loss = 2.96728580, grad/param norm = 5.6398e-01, time/batch = 0.6688s	
174/33150 (epoch 0.262), train_loss = 3.00624874, grad/param norm = 8.7841e-01, time/batch = 0.6654s	
175/33150 (epoch 0.264), train_loss = 3.05150693, grad/param norm = 1.4157e+00, time/batch = 0.6646s	
176/33150 (epoch 0.265), train_loss = 3.23863501, grad/param norm = 8.5884e-01, time/batch = 0.6674s	
177/33150 (epoch 0.267), train_loss = 3.14827111, grad/param norm = 5.1277e-01, time/batch = 0.6658s	
178/33150 (epoch 0.268), train_loss = 3.08916255, grad/param norm = 6.0557e-01, time/batch = 0.6663s	
179/33150 (epoch 0.270), train_loss = 3.12236017, grad/param norm = 5.3306e-01, time/batch = 0.6747s	
180/33150 (epoch 0.271), train_loss = 3.12580922, grad/param norm = 4.4080e-01, time/batch = 0.6765s	
181/33150 (epoch 0.273), train_loss = 3.01462353, grad/param norm = 4.8103e-01, time/batch = 0.6717s	
182/33150 (epoch 0.275), train_loss = 2.95377233, grad/param norm = 5.7855e-01, time/batch = 0.6717s	
183/33150 (epoch 0.276), train_loss = 3.13238477, grad/param norm = 5.9877e-01, time/batch = 0.6715s	
184/33150 (epoch 0.278), train_loss = 3.03702498, grad/param norm = 6.3365e-01, time/batch = 0.6711s	
185/33150 (epoch 0.279), train_loss = 2.98862571, grad/param norm = 7.3005e-01, time/batch = 0.6730s	
186/33150 (epoch 0.281), train_loss = 2.97644205, grad/param norm = 6.6770e-01, time/batch = 0.6730s	
187/33150 (epoch 0.282), train_loss = 3.05399438, grad/param norm = 6.4397e-01, time/batch = 0.6701s	
188/33150 (epoch 0.284), train_loss = 3.02462411, grad/param norm = 6.4288e-01, time/batch = 0.6736s	
189/33150 (epoch 0.285), train_loss = 3.08029640, grad/param norm = 7.9590e-01, time/batch = 0.6755s	
190/33150 (epoch 0.287), train_loss = 3.03560974, grad/param norm = 7.4486e-01, time/batch = 0.6786s	
191/33150 (epoch 0.288), train_loss = 3.13828704, grad/param norm = 6.5187e-01, time/batch = 0.6828s	
192/33150 (epoch 0.290), train_loss = 2.99132379, grad/param norm = 5.3287e-01, time/batch = 0.6851s	
193/33150 (epoch 0.291), train_loss = 3.20233741, grad/param norm = 4.7146e-01, time/batch = 0.6795s	
194/33150 (epoch 0.293), train_loss = 3.01011174, grad/param norm = 4.3454e-01, time/batch = 0.6832s	
195/33150 (epoch 0.294), train_loss = 3.05051964, grad/param norm = 7.0151e-01, time/batch = 0.6829s	
196/33150 (epoch 0.296), train_loss = 3.03162670, grad/param norm = 9.8281e-01, time/batch = 0.6885s	
197/33150 (epoch 0.297), train_loss = 3.07767503, grad/param norm = 8.4930e-01, time/batch = 0.6850s	
198/33150 (epoch 0.299), train_loss = 2.98422173, grad/param norm = 6.0932e-01, time/batch = 0.6842s	
199/33150 (epoch 0.300), train_loss = 3.04317739, grad/param norm = 5.7643e-01, time/batch = 0.6863s	
200/33150 (epoch 0.302), train_loss = 2.99000540, grad/param norm = 4.9389e-01, time/batch = 0.6860s	
201/33150 (epoch 0.303), train_loss = 3.20302924, grad/param norm = 5.3436e-01, time/batch = 0.6801s	
202/33150 (epoch 0.305), train_loss = 3.01958554, grad/param norm = 5.9423e-01, time/batch = 0.6787s	
203/33150 (epoch 0.306), train_loss = 3.00246214, grad/param norm = 5.2996e-01, time/batch = 0.6726s	
204/33150 (epoch 0.308), train_loss = 3.08361028, grad/param norm = 5.7072e-01, time/batch = 0.6800s	
205/33150 (epoch 0.309), train_loss = 3.07098250, grad/param norm = 6.9106e-01, time/batch = 0.6759s	
206/33150 (epoch 0.311), train_loss = 3.07995462, grad/param norm = 5.3066e-01, time/batch = 0.6715s	
207/33150 (epoch 0.312), train_loss = 3.03889806, grad/param norm = 5.5797e-01, time/batch = 0.6698s	
208/33150 (epoch 0.314), train_loss = 3.06743565, grad/param norm = 6.8794e-01, time/batch = 0.6671s	
209/33150 (epoch 0.315), train_loss = 2.99061059, grad/param norm = 1.1085e+00, time/batch = 0.6685s	
210/33150 (epoch 0.317), train_loss = 2.93134273, grad/param norm = 8.6988e-01, time/batch = 0.6687s	
211/33150 (epoch 0.318), train_loss = 2.98959944, grad/param norm = 5.2074e-01, time/batch = 0.6751s	
212/33150 (epoch 0.320), train_loss = 3.12036213, grad/param norm = 4.0492e-01, time/batch = 0.6731s	
213/33150 (epoch 0.321), train_loss = 2.93063974, grad/param norm = 4.6448e-01, time/batch = 0.6687s	
214/33150 (epoch 0.323), train_loss = 2.99057283, grad/param norm = 4.9335e-01, time/batch = 0.6670s	
215/33150 (epoch 0.324), train_loss = 3.06493348, grad/param norm = 7.2480e-01, time/batch = 0.6665s	
216/33150 (epoch 0.326), train_loss = 2.88617911, grad/param norm = 5.2917e-01, time/batch = 0.6666s	
217/33150 (epoch 0.327), train_loss = 2.98074675, grad/param norm = 3.3000e-01, time/batch = 0.6709s	
218/33150 (epoch 0.329), train_loss = 2.82536017, grad/param norm = 4.0016e-01, time/batch = 0.6694s	
219/33150 (epoch 0.330), train_loss = 3.01465838, grad/param norm = 7.0137e-01, time/batch = 0.6796s	
220/33150 (epoch 0.332), train_loss = 3.02165940, grad/param norm = 6.1520e-01, time/batch = 0.6702s	
221/33150 (epoch 0.333), train_loss = 2.96123753, grad/param norm = 4.0433e-01, time/batch = 0.6676s	
222/33150 (epoch 0.335), train_loss = 2.98087117, grad/param norm = 5.0714e-01, time/batch = 0.6657s	
223/33150 (epoch 0.336), train_loss = 3.00215892, grad/param norm = 6.0754e-01, time/batch = 0.6657s	
224/33150 (epoch 0.338), train_loss = 2.86518244, grad/param norm = 7.3796e-01, time/batch = 0.6653s	
225/33150 (epoch 0.339), train_loss = 3.00036112, grad/param norm = 7.7207e-01, time/batch = 0.6663s	
226/33150 (epoch 0.341), train_loss = 3.05465665, grad/param norm = 7.4515e-01, time/batch = 0.6782s	
227/33150 (epoch 0.342), train_loss = 2.95628282, grad/param norm = 8.0180e-01, time/batch = 0.6751s	
228/33150 (epoch 0.344), train_loss = 2.98323170, grad/param norm = 6.9897e-01, time/batch = 0.6712s	
229/33150 (epoch 0.345), train_loss = 2.80555092, grad/param norm = 4.9016e-01, time/batch = 0.6762s	
230/33150 (epoch 0.347), train_loss = 2.84676557, grad/param norm = 3.4085e-01, time/batch = 0.6735s	
231/33150 (epoch 0.348), train_loss = 3.01046935, grad/param norm = 5.4162e-01, time/batch = 0.6686s	
232/33150 (epoch 0.350), train_loss = 3.02043585, grad/param norm = 8.2203e-01, time/batch = 0.6695s	
233/33150 (epoch 0.351), train_loss = 2.94190659, grad/param norm = 8.4927e-01, time/batch = 0.6748s	
234/33150 (epoch 0.353), train_loss = 2.98221232, grad/param norm = 6.2892e-01, time/batch = 0.6802s	
235/33150 (epoch 0.354), train_loss = 2.94083522, grad/param norm = 5.0434e-01, time/batch = 0.6682s	
236/33150 (epoch 0.356), train_loss = 2.68262855, grad/param norm = 3.2858e-01, time/batch = 0.6707s	
237/33150 (epoch 0.357), train_loss = 2.84387717, grad/param norm = 3.7420e-01, time/batch = 0.6707s	
238/33150 (epoch 0.359), train_loss = 2.76624074, grad/param norm = 4.4522e-01, time/batch = 0.6717s	
239/33150 (epoch 0.360), train_loss = 2.86646184, grad/param norm = 5.2202e-01, time/batch = 0.6805s	
240/33150 (epoch 0.362), train_loss = 2.84709653, grad/param norm = 5.5409e-01, time/batch = 0.6682s	
241/33150 (epoch 0.363), train_loss = 2.85505958, grad/param norm = 4.7758e-01, time/batch = 0.6667s	
242/33150 (epoch 0.365), train_loss = 2.89943688, grad/param norm = 4.7824e-01, time/batch = 0.6678s	
243/33150 (epoch 0.367), train_loss = 2.84301684, grad/param norm = 6.3739e-01, time/batch = 0.6697s	
244/33150 (epoch 0.368), train_loss = 3.03359844, grad/param norm = 6.0457e-01, time/batch = 0.6698s	
245/33150 (epoch 0.370), train_loss = 3.04105311, grad/param norm = 6.2094e-01, time/batch = 0.6692s	
246/33150 (epoch 0.371), train_loss = 2.92106276, grad/param norm = 7.3067e-01, time/batch = 0.6771s	
247/33150 (epoch 0.373), train_loss = 2.90738815, grad/param norm = 4.8181e-01, time/batch = 0.6870s	
248/33150 (epoch 0.374), train_loss = 2.81028655, grad/param norm = 4.3231e-01, time/batch = 0.6808s	
249/33150 (epoch 0.376), train_loss = 2.91232333, grad/param norm = 4.1566e-01, time/batch = 0.6917s	
250/33150 (epoch 0.377), train_loss = 2.81381652, grad/param norm = 4.9738e-01, time/batch = 0.6774s	
251/33150 (epoch 0.379), train_loss = 2.91299151, grad/param norm = 7.1112e-01, time/batch = 0.6709s	
252/33150 (epoch 0.380), train_loss = 2.97503641, grad/param norm = 9.7370e-01, time/batch = 0.6685s	
253/33150 (epoch 0.382), train_loss = 2.91569136, grad/param norm = 8.2573e-01, time/batch = 0.6631s	
254/33150 (epoch 0.383), train_loss = 2.80460710, grad/param norm = 7.7502e-01, time/batch = 0.6672s	
255/33150 (epoch 0.385), train_loss = 2.80687316, grad/param norm = 5.9643e-01, time/batch = 0.6692s	
256/33150 (epoch 0.386), train_loss = 2.82318603, grad/param norm = 5.6135e-01, time/batch = 0.6657s	
257/33150 (epoch 0.388), train_loss = 2.78710958, grad/param norm = 5.9409e-01, time/batch = 0.6689s	
258/33150 (epoch 0.389), train_loss = 2.91355128, grad/param norm = 5.1057e-01, time/batch = 0.6719s	
259/33150 (epoch 0.391), train_loss = 2.92513763, grad/param norm = 5.8456e-01, time/batch = 0.6726s	
260/33150 (epoch 0.392), train_loss = 2.87835176, grad/param norm = 6.4220e-01, time/batch = 0.6729s	
261/33150 (epoch 0.394), train_loss = 2.90407725, grad/param norm = 5.1561e-01, time/batch = 0.6744s	
262/33150 (epoch 0.395), train_loss = 2.84014853, grad/param norm = 4.4418e-01, time/batch = 0.6699s	
263/33150 (epoch 0.397), train_loss = 2.53163597, grad/param norm = 4.7792e-01, time/batch = 0.6744s	
264/33150 (epoch 0.398), train_loss = 2.80045116, grad/param norm = 4.1354e-01, time/batch = 0.6678s	
265/33150 (epoch 0.400), train_loss = 2.66925509, grad/param norm = 5.2372e-01, time/batch = 0.6674s	
266/33150 (epoch 0.401), train_loss = 2.65747677, grad/param norm = 6.8579e-01, time/batch = 0.6713s	
267/33150 (epoch 0.403), train_loss = 2.85569480, grad/param norm = 1.0078e+00, time/batch = 0.6671s	
268/33150 (epoch 0.404), train_loss = 2.74105689, grad/param norm = 8.9589e-01, time/batch = 0.6691s	
269/33150 (epoch 0.406), train_loss = 2.90797359, grad/param norm = 9.3191e-01, time/batch = 0.6740s	
270/33150 (epoch 0.407), train_loss = 2.79232290, grad/param norm = 8.7710e-01, time/batch = 0.6703s	
271/33150 (epoch 0.409), train_loss = 2.60737059, grad/param norm = 5.7582e-01, time/batch = 0.6680s	
272/33150 (epoch 0.410), train_loss = 2.71735356, grad/param norm = 3.9434e-01, time/batch = 0.6748s	
273/33150 (epoch 0.412), train_loss = 2.67562376, grad/param norm = 3.3886e-01, time/batch = 0.6707s	
274/33150 (epoch 0.413), train_loss = 2.80822327, grad/param norm = 4.3251e-01, time/batch = 0.6686s	
275/33150 (epoch 0.415), train_loss = 2.81472932, grad/param norm = 4.8245e-01, time/batch = 0.6711s	
276/33150 (epoch 0.416), train_loss = 2.78377227, grad/param norm = 5.9951e-01, time/batch = 0.6706s	
277/33150 (epoch 0.418), train_loss = 2.95832789, grad/param norm = 3.5490e-01, time/batch = 0.6706s	
278/33150 (epoch 0.419), train_loss = 2.80463046, grad/param norm = 3.5811e-01, time/batch = 0.6711s	
279/33150 (epoch 0.421), train_loss = 2.85925147, grad/param norm = 4.6873e-01, time/batch = 0.6696s	
280/33150 (epoch 0.422), train_loss = 2.73885985, grad/param norm = 8.1958e-01, time/batch = 0.6654s	
281/33150 (epoch 0.424), train_loss = 2.84497780, grad/param norm = 6.8759e-01, time/batch = 0.6959s	
282/33150 (epoch 0.425), train_loss = 2.82228898, grad/param norm = 4.6640e-01, time/batch = 0.6730s	
283/33150 (epoch 0.427), train_loss = 2.84482478, grad/param norm = 3.9031e-01, time/batch = 0.6822s	
284/33150 (epoch 0.428), train_loss = 2.75998966, grad/param norm = 2.8982e-01, time/batch = 0.6688s	
285/33150 (epoch 0.430), train_loss = 2.71834333, grad/param norm = 3.4263e-01, time/batch = 0.6670s	
286/33150 (epoch 0.431), train_loss = 2.73315307, grad/param norm = 4.0554e-01, time/batch = 0.6698s	
287/33150 (epoch 0.433), train_loss = 2.83092792, grad/param norm = 7.8259e-01, time/batch = 0.6660s	
288/33150 (epoch 0.434), train_loss = 2.75874455, grad/param norm = 1.0992e+00, time/batch = 0.6639s	
289/33150 (epoch 0.436), train_loss = 2.60698047, grad/param norm = 7.6669e-01, time/batch = 0.6644s	
290/33150 (epoch 0.437), train_loss = 2.84743573, grad/param norm = 4.6342e-01, time/batch = 0.6643s	
291/33150 (epoch 0.439), train_loss = 2.66131563, grad/param norm = 4.7140e-01, time/batch = 0.6722s	
292/33150 (epoch 0.440), train_loss = 2.70838290, grad/param norm = 7.0052e-01, time/batch = 0.6697s	
293/33150 (epoch 0.442), train_loss = 2.68718450, grad/param norm = 5.6456e-01, time/batch = 0.6698s	
294/33150 (epoch 0.443), train_loss = 2.72512994, grad/param norm = 3.9588e-01, time/batch = 0.6694s	
295/33150 (epoch 0.445), train_loss = 2.75281980, grad/param norm = 3.5538e-01, time/batch = 0.6727s	
296/33150 (epoch 0.446), train_loss = 2.90553009, grad/param norm = 4.2402e-01, time/batch = 0.6758s	
297/33150 (epoch 0.448), train_loss = 2.69202043, grad/param norm = 5.3814e-01, time/batch = 0.6749s	
298/33150 (epoch 0.449), train_loss = 2.59012929, grad/param norm = 4.0002e-01, time/batch = 0.6774s	
299/33150 (epoch 0.451), train_loss = 2.73806878, grad/param norm = 3.3129e-01, time/batch = 0.6681s	
300/33150 (epoch 0.452), train_loss = 2.77056290, grad/param norm = 3.7963e-01, time/batch = 0.6679s	
301/33150 (epoch 0.454), train_loss = 2.92082153, grad/param norm = 6.1476e-01, time/batch = 0.6682s	
302/33150 (epoch 0.456), train_loss = 2.63763765, grad/param norm = 6.3909e-01, time/batch = 0.6691s	
303/33150 (epoch 0.457), train_loss = 2.76690567, grad/param norm = 4.7355e-01, time/batch = 0.6686s	
304/33150 (epoch 0.459), train_loss = 2.84245519, grad/param norm = 4.0383e-01, time/batch = 0.6647s	
305/33150 (epoch 0.460), train_loss = 2.65038065, grad/param norm = 3.7859e-01, time/batch = 0.6652s	
306/33150 (epoch 0.462), train_loss = 2.74798948, grad/param norm = 5.7389e-01, time/batch = 0.6669s	
307/33150 (epoch 0.463), train_loss = 2.94689216, grad/param norm = 9.2822e-01, time/batch = 0.6658s	
308/33150 (epoch 0.465), train_loss = 2.77591170, grad/param norm = 6.4574e-01, time/batch = 0.6698s	
309/33150 (epoch 0.466), train_loss = 2.62064177, grad/param norm = 4.1922e-01, time/batch = 0.6695s	
310/33150 (epoch 0.468), train_loss = 2.80002146, grad/param norm = 5.3007e-01, time/batch = 0.6690s	
311/33150 (epoch 0.469), train_loss = 2.82883326, grad/param norm = 5.7107e-01, time/batch = 0.6698s	
312/33150 (epoch 0.471), train_loss = 2.68448743, grad/param norm = 7.9311e-01, time/batch = 0.6809s	
313/33150 (epoch 0.472), train_loss = 2.65008518, grad/param norm = 9.1408e-01, time/batch = 0.6836s	
314/33150 (epoch 0.474), train_loss = 2.57057350, grad/param norm = 7.0285e-01, time/batch = 0.6783s	
315/33150 (epoch 0.475), train_loss = 2.78705477, grad/param norm = 6.6423e-01, time/batch = 0.6655s	
316/33150 (epoch 0.477), train_loss = 2.74154414, grad/param norm = 6.5474e-01, time/batch = 0.6632s	
317/33150 (epoch 0.478), train_loss = 2.69846526, grad/param norm = 5.8410e-01, time/batch = 0.6651s	
318/33150 (epoch 0.480), train_loss = 2.67680052, grad/param norm = 4.2555e-01, time/batch = 0.6648s	
319/33150 (epoch 0.481), train_loss = 2.52163691, grad/param norm = 4.5108e-01, time/batch = 0.6695s	
320/33150 (epoch 0.483), train_loss = 2.64677290, grad/param norm = 5.0196e-01, time/batch = 0.6648s	
321/33150 (epoch 0.484), train_loss = 2.64006450, grad/param norm = 4.0755e-01, time/batch = 0.6681s	
322/33150 (epoch 0.486), train_loss = 2.70694776, grad/param norm = 3.6628e-01, time/batch = 0.6682s	
323/33150 (epoch 0.487), train_loss = 2.69547698, grad/param norm = 2.9355e-01, time/batch = 0.6680s	
324/33150 (epoch 0.489), train_loss = 2.68343924, grad/param norm = 4.1860e-01, time/batch = 0.6665s	
325/33150 (epoch 0.490), train_loss = 2.66715909, grad/param norm = 6.4103e-01, time/batch = 0.6682s	
326/33150 (epoch 0.492), train_loss = 2.70920138, grad/param norm = 7.0453e-01, time/batch = 0.6667s	
327/33150 (epoch 0.493), train_loss = 2.71148277, grad/param norm = 3.7305e-01, time/batch = 0.6660s	
328/33150 (epoch 0.495), train_loss = 2.79483753, grad/param norm = 3.3339e-01, time/batch = 0.6701s	
329/33150 (epoch 0.496), train_loss = 2.69180409, grad/param norm = 3.3898e-01, time/batch = 0.6710s	
330/33150 (epoch 0.498), train_loss = 2.51034615, grad/param norm = 3.8005e-01, time/batch = 0.6690s	
331/33150 (epoch 0.499), train_loss = 2.82621681, grad/param norm = 4.8084e-01, time/batch = 0.6764s	
332/33150 (epoch 0.501), train_loss = 2.76627376, grad/param norm = 1.0384e+00, time/batch = 0.6806s	
333/33150 (epoch 0.502), train_loss = 2.80809562, grad/param norm = 6.5184e-01, time/batch = 0.6688s	
334/33150 (epoch 0.504), train_loss = 2.61600588, grad/param norm = 4.2200e-01, time/batch = 0.6709s	
335/33150 (epoch 0.505), train_loss = 2.75629577, grad/param norm = 3.8250e-01, time/batch = 0.6753s	
336/33150 (epoch 0.507), train_loss = 2.58548238, grad/param norm = 4.3577e-01, time/batch = 0.6869s	
337/33150 (epoch 0.508), train_loss = 2.60992896, grad/param norm = 5.2863e-01, time/batch = 0.6808s	
338/33150 (epoch 0.510), train_loss = 2.69271313, grad/param norm = 7.3328e-01, time/batch = 0.6965s	
339/33150 (epoch 0.511), train_loss = 2.86992462, grad/param norm = 6.1441e-01, time/batch = 0.6822s	
340/33150 (epoch 0.513), train_loss = 2.66378224, grad/param norm = 4.2195e-01, time/batch = 0.6743s	
341/33150 (epoch 0.514), train_loss = 2.51506495, grad/param norm = 3.7640e-01, time/batch = 0.6718s	
342/33150 (epoch 0.516), train_loss = 2.68280891, grad/param norm = 4.1625e-01, time/batch = 0.6835s	
343/33150 (epoch 0.517), train_loss = 2.77959878, grad/param norm = 4.1494e-01, time/batch = 0.6775s	
344/33150 (epoch 0.519), train_loss = 2.60763883, grad/param norm = 3.6372e-01, time/batch = 0.6723s	
345/33150 (epoch 0.520), train_loss = 2.69827465, grad/param norm = 4.2890e-01, time/batch = 0.6697s	
346/33150 (epoch 0.522), train_loss = 2.71067124, grad/param norm = 5.1107e-01, time/batch = 0.6709s	
347/33150 (epoch 0.523), train_loss = 2.70563599, grad/param norm = 5.4292e-01, time/batch = 0.6743s	
348/33150 (epoch 0.525), train_loss = 2.69775687, grad/param norm = 6.1977e-01, time/batch = 0.6676s	
349/33150 (epoch 0.526), train_loss = 2.56327455, grad/param norm = 5.7430e-01, time/batch = 0.6979s	
350/33150 (epoch 0.528), train_loss = 2.64895543, grad/param norm = 4.1728e-01, time/batch = 0.6865s	
351/33150 (epoch 0.529), train_loss = 2.75277636, grad/param norm = 5.3629e-01, time/batch = 0.6762s	
352/33150 (epoch 0.531), train_loss = 2.60976017, grad/param norm = 4.8729e-01, time/batch = 0.6744s	
353/33150 (epoch 0.532), train_loss = 2.69958443, grad/param norm = 4.9695e-01, time/batch = 0.6691s	
354/33150 (epoch 0.534), train_loss = 2.47319863, grad/param norm = 4.4418e-01, time/batch = 0.6703s	
355/33150 (epoch 0.535), train_loss = 2.63379963, grad/param norm = 3.9064e-01, time/batch = 0.6670s	
356/33150 (epoch 0.537), train_loss = 2.76639329, grad/param norm = 5.4108e-01, time/batch = 0.6679s	
357/33150 (epoch 0.538), train_loss = 2.63208429, grad/param norm = 7.4894e-01, time/batch = 0.6697s	
358/33150 (epoch 0.540), train_loss = 2.59054817, grad/param norm = 6.7873e-01, time/batch = 0.6668s	
359/33150 (epoch 0.541), train_loss = 2.59237916, grad/param norm = 4.6670e-01, time/batch = 0.6667s	
360/33150 (epoch 0.543), train_loss = 2.71007303, grad/param norm = 4.3296e-01, time/batch = 0.6645s	
361/33150 (epoch 0.544), train_loss = 2.76538458, grad/param norm = 3.6499e-01, time/batch = 0.6676s	
362/33150 (epoch 0.546), train_loss = 2.72754184, grad/param norm = 3.6461e-01, time/batch = 0.6665s	
363/33150 (epoch 0.548), train_loss = 2.62222776, grad/param norm = 5.0034e-01, time/batch = 0.6653s	
364/33150 (epoch 0.549), train_loss = 2.78570086, grad/param norm = 6.5013e-01, time/batch = 0.6688s	
365/33150 (epoch 0.551), train_loss = 2.56956722, grad/param norm = 3.4829e-01, time/batch = 0.6678s	
366/33150 (epoch 0.552), train_loss = 2.49998131, grad/param norm = 4.2734e-01, time/batch = 0.6655s	
367/33150 (epoch 0.554), train_loss = 2.52743781, grad/param norm = 4.5364e-01, time/batch = 0.6683s	
368/33150 (epoch 0.555), train_loss = 2.69007116, grad/param norm = 3.6584e-01, time/batch = 0.6662s	
369/33150 (epoch 0.557), train_loss = 2.52856128, grad/param norm = 5.6437e-01, time/batch = 0.6672s	
370/33150 (epoch 0.558), train_loss = 2.68795683, grad/param norm = 5.8893e-01, time/batch = 0.6652s	
371/33150 (epoch 0.560), train_loss = 2.77901484, grad/param norm = 6.3841e-01, time/batch = 0.6671s	
372/33150 (epoch 0.561), train_loss = 2.53488246, grad/param norm = 7.9380e-01, time/batch = 0.6668s	
373/33150 (epoch 0.563), train_loss = 2.69967713, grad/param norm = 5.0713e-01, time/batch = 0.6678s	
374/33150 (epoch 0.564), train_loss = 2.70081987, grad/param norm = 5.1324e-01, time/batch = 0.6668s	
375/33150 (epoch 0.566), train_loss = 2.63859106, grad/param norm = 4.5534e-01, time/batch = 0.6657s	
376/33150 (epoch 0.567), train_loss = 2.44407477, grad/param norm = 4.6387e-01, time/batch = 0.6672s	
377/33150 (epoch 0.569), train_loss = 2.52879629, grad/param norm = 4.1469e-01, time/batch = 0.6851s	
378/33150 (epoch 0.570), train_loss = 2.56125084, grad/param norm = 4.0597e-01, time/batch = 0.6881s	
379/33150 (epoch 0.572), train_loss = 2.62114139, grad/param norm = 4.7074e-01, time/batch = 0.6796s	
380/33150 (epoch 0.573), train_loss = 2.35206630, grad/param norm = 5.1086e-01, time/batch = 0.6786s	
381/33150 (epoch 0.575), train_loss = 2.62171048, grad/param norm = 4.7354e-01, time/batch = 0.6751s	
382/33150 (epoch 0.576), train_loss = 2.38389006, grad/param norm = 5.1311e-01, time/batch = 0.6781s	
383/33150 (epoch 0.578), train_loss = 2.67125870, grad/param norm = 6.2303e-01, time/batch = 0.6712s	
384/33150 (epoch 0.579), train_loss = 2.61049067, grad/param norm = 6.3933e-01, time/batch = 0.6686s	
385/33150 (epoch 0.581), train_loss = 2.44343899, grad/param norm = 3.5711e-01, time/batch = 0.6672s	
386/33150 (epoch 0.582), train_loss = 2.44332659, grad/param norm = 3.6824e-01, time/batch = 0.6675s	
387/33150 (epoch 0.584), train_loss = 2.65710603, grad/param norm = 4.8856e-01, time/batch = 0.6714s	
388/33150 (epoch 0.585), train_loss = 2.57778881, grad/param norm = 5.0050e-01, time/batch = 0.6699s	
389/33150 (epoch 0.587), train_loss = 2.53494952, grad/param norm = 5.4316e-01, time/batch = 0.6690s	
390/33150 (epoch 0.588), train_loss = 2.61924639, grad/param norm = 6.9166e-01, time/batch = 0.6699s	
391/33150 (epoch 0.590), train_loss = 2.61169345, grad/param norm = 7.3163e-01, time/batch = 0.6794s	
392/33150 (epoch 0.591), train_loss = 2.63823274, grad/param norm = 5.1719e-01, time/batch = 0.6714s	
393/33150 (epoch 0.593), train_loss = 2.49085799, grad/param norm = 3.6518e-01, time/batch = 0.6684s	
394/33150 (epoch 0.594), train_loss = 2.58876929, grad/param norm = 3.1893e-01, time/batch = 0.6688s	
395/33150 (epoch 0.596), train_loss = 2.28400605, grad/param norm = 4.6063e-01, time/batch = 0.6712s	
396/33150 (epoch 0.597), train_loss = 2.39983459, grad/param norm = 4.5219e-01, time/batch = 0.6670s	
397/33150 (epoch 0.599), train_loss = 2.57789201, grad/param norm = 4.2019e-01, time/batch = 0.6694s	
398/33150 (epoch 0.600), train_loss = 2.53451929, grad/param norm = 4.6671e-01, time/batch = 0.6701s	
399/33150 (epoch 0.602), train_loss = 2.49609915, grad/param norm = 5.0874e-01, time/batch = 0.6679s	
400/33150 (epoch 0.603), train_loss = 2.39720675, grad/param norm = 3.9542e-01, time/batch = 0.6671s	
401/33150 (epoch 0.605), train_loss = 2.52901795, grad/param norm = 4.5796e-01, time/batch = 0.6685s	
402/33150 (epoch 0.606), train_loss = 2.52727396, grad/param norm = 7.4148e-01, time/batch = 0.6678s	
403/33150 (epoch 0.608), train_loss = 2.59532857, grad/param norm = 8.0511e-01, time/batch = 0.6673s	
404/33150 (epoch 0.609), train_loss = 2.52704060, grad/param norm = 6.5731e-01, time/batch = 0.6664s	
405/33150 (epoch 0.611), train_loss = 2.45944259, grad/param norm = 4.5421e-01, time/batch = 0.6727s	
406/33150 (epoch 0.612), train_loss = 2.56192345, grad/param norm = 4.2346e-01, time/batch = 0.6814s	
407/33150 (epoch 0.614), train_loss = 2.45513519, grad/param norm = 4.4624e-01, time/batch = 0.6703s	
408/33150 (epoch 0.615), train_loss = 2.63415636, grad/param norm = 3.6303e-01, time/batch = 0.6688s	
409/33150 (epoch 0.617), train_loss = 2.49548350, grad/param norm = 3.7896e-01, time/batch = 0.6701s	
410/33150 (epoch 0.618), train_loss = 2.37320452, grad/param norm = 4.6870e-01, time/batch = 0.6871s	
411/33150 (epoch 0.620), train_loss = 2.38765887, grad/param norm = 4.6971e-01, time/batch = 0.6713s	
412/33150 (epoch 0.621), train_loss = 2.44516196, grad/param norm = 3.9736e-01, time/batch = 0.6717s	
413/33150 (epoch 0.623), train_loss = 2.49017583, grad/param norm = 4.8822e-01, time/batch = 0.6731s	
414/33150 (epoch 0.624), train_loss = 2.55686245, grad/param norm = 4.5109e-01, time/batch = 0.6722s	
415/33150 (epoch 0.626), train_loss = 2.24826926, grad/param norm = 3.9599e-01, time/batch = 0.6731s	
416/33150 (epoch 0.627), train_loss = 2.34341120, grad/param norm = 4.0133e-01, time/batch = 0.6710s	
417/33150 (epoch 0.629), train_loss = 2.41098525, grad/param norm = 4.8489e-01, time/batch = 0.6702s	
418/33150 (epoch 0.630), train_loss = 2.44244917, grad/param norm = 4.3510e-01, time/batch = 0.6683s	
419/33150 (epoch 0.632), train_loss = 2.39360386, grad/param norm = 6.4137e-01, time/batch = 0.6703s	
420/33150 (epoch 0.633), train_loss = 2.29243027, grad/param norm = 6.9687e-01, time/batch = 0.6743s	
421/33150 (epoch 0.635), train_loss = 2.48471226, grad/param norm = 4.3645e-01, time/batch = 0.6797s	
422/33150 (epoch 0.637), train_loss = 2.33830720, grad/param norm = 4.4813e-01, time/batch = 0.6703s	
423/33150 (epoch 0.638), train_loss = 2.41728215, grad/param norm = 4.0954e-01, time/batch = 0.6671s	
424/33150 (epoch 0.640), train_loss = 2.65362112, grad/param norm = 5.2138e-01, time/batch = 0.6803s	
425/33150 (epoch 0.641), train_loss = 2.41256415, grad/param norm = 4.3727e-01, time/batch = 0.6867s	
426/33150 (epoch 0.643), train_loss = 2.31661310, grad/param norm = 3.8568e-01, time/batch = 0.7029s	
427/33150 (epoch 0.644), train_loss = 2.49435731, grad/param norm = 5.2219e-01, time/batch = 0.6937s	
428/33150 (epoch 0.646), train_loss = 2.56746856, grad/param norm = 6.1680e-01, time/batch = 0.6860s	
429/33150 (epoch 0.647), train_loss = 2.80117954, grad/param norm = 6.0638e-01, time/batch = 0.6803s	
430/33150 (epoch 0.649), train_loss = 2.63114873, grad/param norm = 5.4311e-01, time/batch = 0.6627s	
431/33150 (epoch 0.650), train_loss = 2.37197604, grad/param norm = 5.5057e-01, time/batch = 0.6829s	
432/33150 (epoch 0.652), train_loss = 2.41550583, grad/param norm = 5.3940e-01, time/batch = 0.6897s	
433/33150 (epoch 0.653), train_loss = 2.38811463, grad/param norm = 3.9214e-01, time/batch = 0.6727s	
434/33150 (epoch 0.655), train_loss = 2.29911245, grad/param norm = 3.3741e-01, time/batch = 0.6648s	
435/33150 (epoch 0.656), train_loss = 2.29037336, grad/param norm = 3.6648e-01, time/batch = 0.6798s	
436/33150 (epoch 0.658), train_loss = 2.46668571, grad/param norm = 3.8132e-01, time/batch = 0.6759s	
437/33150 (epoch 0.659), train_loss = 3.01966753, grad/param norm = 6.7938e-01, time/batch = 0.6763s	
438/33150 (epoch 0.661), train_loss = 2.47907494, grad/param norm = 6.0279e-01, time/batch = 0.6773s	
439/33150 (epoch 0.662), train_loss = 2.51002266, grad/param norm = 5.6739e-01, time/batch = 0.6702s	
440/33150 (epoch 0.664), train_loss = 2.45335974, grad/param norm = 5.0712e-01, time/batch = 0.6668s	
441/33150 (epoch 0.665), train_loss = 2.34010553, grad/param norm = 4.9688e-01, time/batch = 0.6676s	
442/33150 (epoch 0.667), train_loss = 2.58615201, grad/param norm = 4.6827e-01, time/batch = 0.6668s	
443/33150 (epoch 0.668), train_loss = 2.45630099, grad/param norm = 3.2056e-01, time/batch = 0.6673s	
444/33150 (epoch 0.670), train_loss = 2.39003493, grad/param norm = 3.3439e-01, time/batch = 0.6646s	
445/33150 (epoch 0.671), train_loss = 2.32897203, grad/param norm = 3.7744e-01, time/batch = 0.6742s	
446/33150 (epoch 0.673), train_loss = 2.61380418, grad/param norm = 4.3416e-01, time/batch = 0.6675s	
447/33150 (epoch 0.674), train_loss = 2.46021707, grad/param norm = 5.0787e-01, time/batch = 0.6696s	
448/33150 (epoch 0.676), train_loss = 2.31856718, grad/param norm = 4.2396e-01, time/batch = 0.6663s	
449/33150 (epoch 0.677), train_loss = 2.61904597, grad/param norm = 4.4281e-01, time/batch = 0.6674s	
450/33150 (epoch 0.679), train_loss = 2.17123372, grad/param norm = 3.9684e-01, time/batch = 0.6795s	
451/33150 (epoch 0.680), train_loss = 2.51250016, grad/param norm = 3.7194e-01, time/batch = 0.6718s	
452/33150 (epoch 0.682), train_loss = 2.29570345, grad/param norm = 3.1550e-01, time/batch = 0.6678s	
453/33150 (epoch 0.683), train_loss = 2.31010267, grad/param norm = 3.2943e-01, time/batch = 0.6651s	
454/33150 (epoch 0.685), train_loss = 2.52386414, grad/param norm = 4.5171e-01, time/batch = 0.6677s	
455/33150 (epoch 0.686), train_loss = 2.39018361, grad/param norm = 4.8222e-01, time/batch = 0.6651s	
456/33150 (epoch 0.688), train_loss = 2.43336198, grad/param norm = 6.1740e-01, time/batch = 0.6644s	
457/33150 (epoch 0.689), train_loss = 2.38857392, grad/param norm = 5.5085e-01, time/batch = 0.6663s	
458/33150 (epoch 0.691), train_loss = 2.22992706, grad/param norm = 4.1675e-01, time/batch = 0.6672s	
459/33150 (epoch 0.692), train_loss = 2.48845779, grad/param norm = 6.5830e-01, time/batch = 0.6821s	
460/33150 (epoch 0.694), train_loss = 2.34411864, grad/param norm = 7.2896e-01, time/batch = 0.6652s	
461/33150 (epoch 0.695), train_loss = 2.30559640, grad/param norm = 5.6326e-01, time/batch = 0.6655s	
462/33150 (epoch 0.697), train_loss = 2.30695698, grad/param norm = 5.1278e-01, time/batch = 0.6640s	
463/33150 (epoch 0.698), train_loss = 2.52183911, grad/param norm = 3.6793e-01, time/batch = 0.6624s	
464/33150 (epoch 0.700), train_loss = 2.12326475, grad/param norm = 3.9577e-01, time/batch = 0.6676s	
465/33150 (epoch 0.701), train_loss = 2.35691512, grad/param norm = 4.5456e-01, time/batch = 0.6795s	
466/33150 (epoch 0.703), train_loss = 2.49736564, grad/param norm = 4.3772e-01, time/batch = 0.6685s	
467/33150 (epoch 0.704), train_loss = 2.33064230, grad/param norm = 4.1469e-01, time/batch = 0.6707s	
468/33150 (epoch 0.706), train_loss = 2.38902416, grad/param norm = 3.3112e-01, time/batch = 0.6669s	
469/33150 (epoch 0.707), train_loss = 2.38141837, grad/param norm = 3.7576e-01, time/batch = 0.6708s	
470/33150 (epoch 0.709), train_loss = 2.26762676, grad/param norm = 3.5732e-01, time/batch = 0.6679s	
471/33150 (epoch 0.710), train_loss = 2.48915360, grad/param norm = 4.2778e-01, time/batch = 0.6700s	
472/33150 (epoch 0.712), train_loss = 2.54654144, grad/param norm = 5.3612e-01, time/batch = 0.6703s	
473/33150 (epoch 0.713), train_loss = 2.26612045, grad/param norm = 4.6158e-01, time/batch = 0.6783s	
474/33150 (epoch 0.715), train_loss = 2.33492892, grad/param norm = 3.5837e-01, time/batch = 0.6837s	
475/33150 (epoch 0.716), train_loss = 2.35846994, grad/param norm = 3.7012e-01, time/batch = 0.6857s	
476/33150 (epoch 0.718), train_loss = 2.48785941, grad/param norm = 3.8368e-01, time/batch = 0.6753s	
477/33150 (epoch 0.719), train_loss = 2.47666529, grad/param norm = 3.8350e-01, time/batch = 0.6816s	
478/33150 (epoch 0.721), train_loss = 2.46137689, grad/param norm = 4.0999e-01, time/batch = 0.6769s	
479/33150 (epoch 0.722), train_loss = 2.33392065, grad/param norm = 3.9337e-01, time/batch = 0.6737s	
480/33150 (epoch 0.724), train_loss = 2.41665585, grad/param norm = 3.2671e-01, time/batch = 0.6844s	
481/33150 (epoch 0.725), train_loss = 2.44497818, grad/param norm = 3.8765e-01, time/batch = 0.6702s	
482/33150 (epoch 0.727), train_loss = 2.46321925, grad/param norm = 4.3517e-01, time/batch = 0.6674s	
483/33150 (epoch 0.729), train_loss = 2.41269415, grad/param norm = 3.7556e-01, time/batch = 0.6663s	
484/33150 (epoch 0.730), train_loss = 2.38642673, grad/param norm = 4.4764e-01, time/batch = 0.6689s	
485/33150 (epoch 0.732), train_loss = 2.40485232, grad/param norm = 5.2248e-01, time/batch = 0.6647s	
486/33150 (epoch 0.733), train_loss = 2.35793787, grad/param norm = 5.3494e-01, time/batch = 0.6653s	
487/33150 (epoch 0.735), train_loss = 2.44413852, grad/param norm = 4.0730e-01, time/batch = 0.6733s	
488/33150 (epoch 0.736), train_loss = 2.28198906, grad/param norm = 3.3002e-01, time/batch = 0.6678s	
489/33150 (epoch 0.738), train_loss = 2.41583264, grad/param norm = 3.9387e-01, time/batch = 0.6669s	
490/33150 (epoch 0.739), train_loss = 2.58430433, grad/param norm = 4.6128e-01, time/batch = 0.6678s	
491/33150 (epoch 0.741), train_loss = 2.39949249, grad/param norm = 4.3717e-01, time/batch = 0.6698s	
492/33150 (epoch 0.742), train_loss = 2.40248753, grad/param norm = 4.4983e-01, time/batch = 0.6677s	
493/33150 (epoch 0.744), train_loss = 2.45626547, grad/param norm = 3.5851e-01, time/batch = 0.6700s	
494/33150 (epoch 0.745), train_loss = 2.42731576, grad/param norm = 4.1568e-01, time/batch = 0.6671s	
495/33150 (epoch 0.747), train_loss = 2.26702085, grad/param norm = 4.5690e-01, time/batch = 0.6729s	
496/33150 (epoch 0.748), train_loss = 2.29117873, grad/param norm = 4.8802e-01, time/batch = 0.6670s	
497/33150 (epoch 0.750), train_loss = 2.33094183, grad/param norm = 4.1619e-01, time/batch = 0.6639s	
498/33150 (epoch 0.751), train_loss = 2.30269512, grad/param norm = 5.0801e-01, time/batch = 0.6631s	
499/33150 (epoch 0.753), train_loss = 2.18624593, grad/param norm = 4.7552e-01, time/batch = 0.6686s	
500/33150 (epoch 0.754), train_loss = 2.50630608, grad/param norm = 4.0928e-01, time/batch = 0.6659s	
501/33150 (epoch 0.756), train_loss = 2.34007014, grad/param norm = 4.3860e-01, time/batch = 0.6688s	
502/33150 (epoch 0.757), train_loss = 2.50891048, grad/param norm = 6.0466e-01, time/batch = 0.6689s	
503/33150 (epoch 0.759), train_loss = 2.51813023, grad/param norm = 4.7392e-01, time/batch = 0.6695s	
504/33150 (epoch 0.760), train_loss = 2.43782313, grad/param norm = 4.4728e-01, time/batch = 0.6673s	
505/33150 (epoch 0.762), train_loss = 2.51554853, grad/param norm = 3.8947e-01, time/batch = 0.6672s	
506/33150 (epoch 0.763), train_loss = 2.30410654, grad/param norm = 3.4150e-01, time/batch = 0.6672s	
507/33150 (epoch 0.765), train_loss = 2.28530901, grad/param norm = 3.0863e-01, time/batch = 0.6689s	
508/33150 (epoch 0.766), train_loss = 2.40332734, grad/param norm = 4.2539e-01, time/batch = 0.6670s	
509/33150 (epoch 0.768), train_loss = 2.30575578, grad/param norm = 5.0753e-01, time/batch = 0.6717s	
510/33150 (epoch 0.769), train_loss = 2.31332979, grad/param norm = 4.9973e-01, time/batch = 0.6665s	
511/33150 (epoch 0.771), train_loss = 2.44554816, grad/param norm = 3.7692e-01, time/batch = 0.6705s	
512/33150 (epoch 0.772), train_loss = 2.45809202, grad/param norm = 3.7945e-01, time/batch = 0.6691s	
513/33150 (epoch 0.774), train_loss = 2.45680974, grad/param norm = 4.0020e-01, time/batch = 0.6794s	
514/33150 (epoch 0.775), train_loss = 2.35073706, grad/param norm = 3.6159e-01, time/batch = 0.6869s	
515/33150 (epoch 0.777), train_loss = 2.38293554, grad/param norm = 3.2383e-01, time/batch = 0.6859s	
516/33150 (epoch 0.778), train_loss = 2.39608396, grad/param norm = 3.8730e-01, time/batch = 0.6686s	
517/33150 (epoch 0.780), train_loss = 2.24787487, grad/param norm = 3.4163e-01, time/batch = 0.6713s	
518/33150 (epoch 0.781), train_loss = 2.38605789, grad/param norm = 3.7884e-01, time/batch = 0.6736s	
519/33150 (epoch 0.783), train_loss = 2.38370392, grad/param norm = 4.1795e-01, time/batch = 0.6682s	
520/33150 (epoch 0.784), train_loss = 2.23956542, grad/param norm = 3.7398e-01, time/batch = 0.6703s	
521/33150 (epoch 0.786), train_loss = 2.53556244, grad/param norm = 4.5719e-01, time/batch = 0.6741s	
522/33150 (epoch 0.787), train_loss = 2.35179893, grad/param norm = 5.1121e-01, time/batch = 0.6756s	
523/33150 (epoch 0.789), train_loss = 2.29237916, grad/param norm = 3.7006e-01, time/batch = 0.6978s	
524/33150 (epoch 0.790), train_loss = 2.16893290, grad/param norm = 3.4072e-01, time/batch = 0.6833s	
525/33150 (epoch 0.792), train_loss = 2.41726975, grad/param norm = 4.2995e-01, time/batch = 0.6771s	
526/33150 (epoch 0.793), train_loss = 2.37190936, grad/param norm = 4.7463e-01, time/batch = 0.6695s	
527/33150 (epoch 0.795), train_loss = 2.28862818, grad/param norm = 5.2445e-01, time/batch = 0.6738s	
528/33150 (epoch 0.796), train_loss = 2.17703463, grad/param norm = 5.2638e-01, time/batch = 0.6711s	
529/33150 (epoch 0.798), train_loss = 2.37608481, grad/param norm = 3.1723e-01, time/batch = 0.6701s	
530/33150 (epoch 0.799), train_loss = 2.24544237, grad/param norm = 3.4128e-01, time/batch = 0.6701s	
531/33150 (epoch 0.801), train_loss = 2.26129841, grad/param norm = 3.8159e-01, time/batch = 0.6679s	
532/33150 (epoch 0.802), train_loss = 2.43552443, grad/param norm = 3.9806e-01, time/batch = 0.6699s	
533/33150 (epoch 0.804), train_loss = 2.35050972, grad/param norm = 3.2778e-01, time/batch = 0.6673s	
534/33150 (epoch 0.805), train_loss = 2.38722647, grad/param norm = 4.3013e-01, time/batch = 0.6680s	
535/33150 (epoch 0.807), train_loss = 2.27593511, grad/param norm = 4.6129e-01, time/batch = 0.6651s	
536/33150 (epoch 0.808), train_loss = 2.38172208, grad/param norm = 4.6235e-01, time/batch = 0.6666s	
537/33150 (epoch 0.810), train_loss = 2.27519793, grad/param norm = 5.4777e-01, time/batch = 0.6668s	
538/33150 (epoch 0.811), train_loss = 2.32120237, grad/param norm = 4.5025e-01, time/batch = 0.6919s	
539/33150 (epoch 0.813), train_loss = 2.34245577, grad/param norm = 4.4562e-01, time/batch = 0.6795s	
540/33150 (epoch 0.814), train_loss = 2.37877118, grad/param norm = 3.8035e-01, time/batch = 0.6797s	
541/33150 (epoch 0.816), train_loss = 2.45393717, grad/param norm = 3.0081e-01, time/batch = 0.6700s	
542/33150 (epoch 0.817), train_loss = 2.34358686, grad/param norm = 3.4192e-01, time/batch = 0.6814s	
543/33150 (epoch 0.819), train_loss = 2.25904253, grad/param norm = 4.4927e-01, time/batch = 0.6646s	
544/33150 (epoch 0.821), train_loss = 2.09901770, grad/param norm = 4.7175e-01, time/batch = 0.6591s	
545/33150 (epoch 0.822), train_loss = 2.31103470, grad/param norm = 4.4423e-01, time/batch = 0.6639s	
546/33150 (epoch 0.824), train_loss = 2.34231743, grad/param norm = 4.0996e-01, time/batch = 0.6717s	
547/33150 (epoch 0.825), train_loss = 2.29928659, grad/param norm = 2.8756e-01, time/batch = 0.6745s	
548/33150 (epoch 0.827), train_loss = 2.37464242, grad/param norm = 3.3679e-01, time/batch = 0.6897s	
549/33150 (epoch 0.828), train_loss = 2.31272772, grad/param norm = 3.1353e-01, time/batch = 0.6681s	
550/33150 (epoch 0.830), train_loss = 2.45960772, grad/param norm = 3.1361e-01, time/batch = 0.6642s	
551/33150 (epoch 0.831), train_loss = 2.22195772, grad/param norm = 3.2082e-01, time/batch = 0.6659s	
552/33150 (epoch 0.833), train_loss = 2.22892362, grad/param norm = 3.6277e-01, time/batch = 0.6615s	
553/33150 (epoch 0.834), train_loss = 2.38179153, grad/param norm = 4.0838e-01, time/batch = 0.6701s	
554/33150 (epoch 0.836), train_loss = 2.37539015, grad/param norm = 3.7954e-01, time/batch = 0.6685s	
555/33150 (epoch 0.837), train_loss = 2.28699174, grad/param norm = 3.5444e-01, time/batch = 0.6694s	
556/33150 (epoch 0.839), train_loss = 2.40013863, grad/param norm = 4.6167e-01, time/batch = 0.6714s	
557/33150 (epoch 0.840), train_loss = 2.30292402, grad/param norm = 7.2213e-01, time/batch = 0.6690s	
558/33150 (epoch 0.842), train_loss = 2.45462740, grad/param norm = 9.4387e-01, time/batch = 0.6706s	
559/33150 (epoch 0.843), train_loss = 2.31848332, grad/param norm = 6.7892e-01, time/batch = 0.6680s	
560/33150 (epoch 0.845), train_loss = 2.27850141, grad/param norm = 4.3221e-01, time/batch = 0.6685s	
561/33150 (epoch 0.846), train_loss = 2.60435279, grad/param norm = 3.6458e-01, time/batch = 0.6673s	
562/33150 (epoch 0.848), train_loss = 2.41057788, grad/param norm = 3.8483e-01, time/batch = 0.6686s	
563/33150 (epoch 0.849), train_loss = 2.29843162, grad/param norm = 3.1397e-01, time/batch = 0.6651s	
564/33150 (epoch 0.851), train_loss = 2.38311243, grad/param norm = 4.0799e-01, time/batch = 0.6661s	
565/33150 (epoch 0.852), train_loss = 2.38565133, grad/param norm = 4.4639e-01, time/batch = 0.6661s	
566/33150 (epoch 0.854), train_loss = 2.40119938, grad/param norm = 3.2527e-01, time/batch = 0.6672s	
567/33150 (epoch 0.855), train_loss = 2.07902161, grad/param norm = 2.8858e-01, time/batch = 0.6653s	
568/33150 (epoch 0.857), train_loss = 2.28396300, grad/param norm = 2.7054e-01, time/batch = 0.6646s	
569/33150 (epoch 0.858), train_loss = 2.21787543, grad/param norm = 3.1404e-01, time/batch = 0.6656s	
570/33150 (epoch 0.860), train_loss = 2.34743924, grad/param norm = 3.1982e-01, time/batch = 0.6650s	
571/33150 (epoch 0.861), train_loss = 2.29515006, grad/param norm = 3.3634e-01, time/batch = 0.6681s	
572/33150 (epoch 0.863), train_loss = 2.36314488, grad/param norm = 3.6046e-01, time/batch = 0.6678s	
573/33150 (epoch 0.864), train_loss = 2.40494163, grad/param norm = 3.7006e-01, time/batch = 0.6676s	
574/33150 (epoch 0.866), train_loss = 2.17384011, grad/param norm = 3.8060e-01, time/batch = 0.6648s	
575/33150 (epoch 0.867), train_loss = 2.47032961, grad/param norm = 3.6783e-01, time/batch = 0.6651s	
576/33150 (epoch 0.869), train_loss = 2.43001593, grad/param norm = 3.0503e-01, time/batch = 0.6689s	
577/33150 (epoch 0.870), train_loss = 2.35279174, grad/param norm = 3.7569e-01, time/batch = 0.6682s	
578/33150 (epoch 0.872), train_loss = 2.43988040, grad/param norm = 4.8520e-01, time/batch = 0.6662s	
579/33150 (epoch 0.873), train_loss = 2.08214121, grad/param norm = 4.6721e-01, time/batch = 0.6654s	
580/33150 (epoch 0.875), train_loss = 2.49886200, grad/param norm = 4.0078e-01, time/batch = 0.6661s	
581/33150 (epoch 0.876), train_loss = 2.37329587, grad/param norm = 4.3468e-01, time/batch = 0.6669s	
582/33150 (epoch 0.878), train_loss = 2.16837428, grad/param norm = 3.8667e-01, time/batch = 0.6659s	
583/33150 (epoch 0.879), train_loss = 2.26050407, grad/param norm = 3.3367e-01, time/batch = 0.6702s	
584/33150 (epoch 0.881), train_loss = 2.38747174, grad/param norm = 3.5510e-01, time/batch = 0.6681s	
585/33150 (epoch 0.882), train_loss = 2.35737809, grad/param norm = 3.3720e-01, time/batch = 0.6715s	
586/33150 (epoch 0.884), train_loss = 2.37393405, grad/param norm = 3.7252e-01, time/batch = 0.6689s	
587/33150 (epoch 0.885), train_loss = 2.09752477, grad/param norm = 3.5559e-01, time/batch = 0.6688s	
588/33150 (epoch 0.887), train_loss = 2.38794206, grad/param norm = 3.9610e-01, time/batch = 0.6796s	
589/33150 (epoch 0.888), train_loss = 2.41385204, grad/param norm = 3.9508e-01, time/batch = 0.6759s	
590/33150 (epoch 0.890), train_loss = 2.25694363, grad/param norm = 3.4316e-01, time/batch = 0.6694s	
591/33150 (epoch 0.891), train_loss = 2.29137665, grad/param norm = 2.8749e-01, time/batch = 0.6662s	
592/33150 (epoch 0.893), train_loss = 2.38929074, grad/param norm = 2.7731e-01, time/batch = 0.6695s	
593/33150 (epoch 0.894), train_loss = 2.37245142, grad/param norm = 3.4095e-01, time/batch = 0.6795s	
594/33150 (epoch 0.896), train_loss = 2.33131228, grad/param norm = 4.9179e-01, time/batch = 0.6812s	
595/33150 (epoch 0.897), train_loss = 2.37147777, grad/param norm = 5.3027e-01, time/batch = 0.6878s	
596/33150 (epoch 0.899), train_loss = 2.30413286, grad/param norm = 5.2129e-01, time/batch = 0.6847s	
597/33150 (epoch 0.900), train_loss = 2.42246209, grad/param norm = 3.8488e-01, time/batch = 0.6866s	
598/33150 (epoch 0.902), train_loss = 2.50169614, grad/param norm = 4.3223e-01, time/batch = 0.6818s	
599/33150 (epoch 0.903), train_loss = 2.18444333, grad/param norm = 4.7005e-01, time/batch = 0.6698s	
600/33150 (epoch 0.905), train_loss = 2.32971458, grad/param norm = 4.8005e-01, time/batch = 0.6686s	
601/33150 (epoch 0.906), train_loss = 2.14715758, grad/param norm = 4.6120e-01, time/batch = 0.6719s	
602/33150 (epoch 0.908), train_loss = 2.37932343, grad/param norm = 3.0547e-01, time/batch = 0.6829s	
603/33150 (epoch 0.910), train_loss = 2.29083715, grad/param norm = 3.2167e-01, time/batch = 0.6810s	
604/33150 (epoch 0.911), train_loss = 2.21343197, grad/param norm = 3.5861e-01, time/batch = 0.6905s	
605/33150 (epoch 0.913), train_loss = 2.21287216, grad/param norm = 4.4947e-01, time/batch = 0.6743s	
606/33150 (epoch 0.914), train_loss = 2.40485281, grad/param norm = 3.5506e-01, time/batch = 0.6826s	
607/33150 (epoch 0.916), train_loss = 2.23341758, grad/param norm = 4.0367e-01, time/batch = 0.6781s	
608/33150 (epoch 0.917), train_loss = 2.44679561, grad/param norm = 5.3167e-01, time/batch = 0.6782s	
609/33150 (epoch 0.919), train_loss = 2.34798738, grad/param norm = 4.9253e-01, time/batch = 0.6846s	
610/33150 (epoch 0.920), train_loss = 2.36292649, grad/param norm = 3.6417e-01, time/batch = 0.6651s	
611/33150 (epoch 0.922), train_loss = 2.47843328, grad/param norm = 3.0281e-01, time/batch = 0.6638s	
612/33150 (epoch 0.923), train_loss = 2.20860485, grad/param norm = 3.5127e-01, time/batch = 0.6663s	
613/33150 (epoch 0.925), train_loss = 2.30153936, grad/param norm = 4.0609e-01, time/batch = 0.6653s	
614/33150 (epoch 0.926), train_loss = 2.19641438, grad/param norm = 3.5481e-01, time/batch = 0.6646s	
615/33150 (epoch 0.928), train_loss = 2.28823061, grad/param norm = 3.6352e-01, time/batch = 0.6623s	
616/33150 (epoch 0.929), train_loss = 2.36269604, grad/param norm = 3.8068e-01, time/batch = 0.6615s	
617/33150 (epoch 0.931), train_loss = 2.39170809, grad/param norm = 3.4476e-01, time/batch = 0.6664s	
618/33150 (epoch 0.932), train_loss = 2.23493789, grad/param norm = 3.3237e-01, time/batch = 0.6665s	
619/33150 (epoch 0.934), train_loss = 2.26670098, grad/param norm = 3.1388e-01, time/batch = 0.6681s	
620/33150 (epoch 0.935), train_loss = 2.32485195, grad/param norm = 3.0865e-01, time/batch = 0.6665s	
621/33150 (epoch 0.937), train_loss = 2.41822204, grad/param norm = 2.8486e-01, time/batch = 0.6698s	
622/33150 (epoch 0.938), train_loss = 2.24870805, grad/param norm = 3.2156e-01, time/batch = 0.6700s	
623/33150 (epoch 0.940), train_loss = 2.48112534, grad/param norm = 3.0829e-01, time/batch = 0.6699s	
624/33150 (epoch 0.941), train_loss = 2.16058403, grad/param norm = 2.7471e-01, time/batch = 0.6763s	
625/33150 (epoch 0.943), train_loss = 2.31352820, grad/param norm = 2.8497e-01, time/batch = 0.6737s	
626/33150 (epoch 0.944), train_loss = 2.26234420, grad/param norm = 2.4643e-01, time/batch = 0.6711s	
627/33150 (epoch 0.946), train_loss = 2.22338679, grad/param norm = 3.7079e-01, time/batch = 0.6717s	
628/33150 (epoch 0.947), train_loss = 2.31970983, grad/param norm = 4.0228e-01, time/batch = 0.6726s	
629/33150 (epoch 0.949), train_loss = 2.52142933, grad/param norm = 5.0269e-01, time/batch = 0.6672s	
630/33150 (epoch 0.950), train_loss = 2.36424669, grad/param norm = 4.6593e-01, time/batch = 0.6950s	
631/33150 (epoch 0.952), train_loss = 2.32279961, grad/param norm = 4.5558e-01, time/batch = 0.6809s	
632/33150 (epoch 0.953), train_loss = 2.11608851, grad/param norm = 5.1646e-01, time/batch = 0.6872s	
633/33150 (epoch 0.955), train_loss = 2.24166828, grad/param norm = 4.1469e-01, time/batch = 0.6677s	
634/33150 (epoch 0.956), train_loss = 2.33645588, grad/param norm = 3.8083e-01, time/batch = 0.6676s	
635/33150 (epoch 0.958), train_loss = 2.11640364, grad/param norm = 3.1259e-01, time/batch = 0.6702s	
636/33150 (epoch 0.959), train_loss = 2.13238916, grad/param norm = 3.1653e-01, time/batch = 0.6646s	
637/33150 (epoch 0.961), train_loss = 2.27818312, grad/param norm = 3.7101e-01, time/batch = 0.6661s	
638/33150 (epoch 0.962), train_loss = 2.11758835, grad/param norm = 3.8827e-01, time/batch = 0.6633s	
639/33150 (epoch 0.964), train_loss = 2.29933873, grad/param norm = 3.3206e-01, time/batch = 0.6636s	
640/33150 (epoch 0.965), train_loss = 2.31650027, grad/param norm = 3.6946e-01, time/batch = 0.6642s	
641/33150 (epoch 0.967), train_loss = 2.36889326, grad/param norm = 4.1595e-01, time/batch = 0.6686s	
642/33150 (epoch 0.968), train_loss = 2.17536807, grad/param norm = 3.8114e-01, time/batch = 0.6715s	
643/33150 (epoch 0.970), train_loss = 2.20639106, grad/param norm = 3.6901e-01, time/batch = 0.6728s	
644/33150 (epoch 0.971), train_loss = 2.31764367, grad/param norm = 4.3613e-01, time/batch = 0.6719s	
645/33150 (epoch 0.973), train_loss = 2.22271399, grad/param norm = 3.6976e-01, time/batch = 0.6784s	
646/33150 (epoch 0.974), train_loss = 2.33903830, grad/param norm = 3.3192e-01, time/batch = 0.6845s	
647/33150 (epoch 0.976), train_loss = 2.25125534, grad/param norm = 2.9855e-01, time/batch = 0.6886s	
648/33150 (epoch 0.977), train_loss = 2.24568278, grad/param norm = 3.0472e-01, time/batch = 0.6879s	
649/33150 (epoch 0.979), train_loss = 2.32723412, grad/param norm = 3.4893e-01, time/batch = 0.6864s	
650/33150 (epoch 0.980), train_loss = 2.31808153, grad/param norm = 3.2231e-01, time/batch = 0.6853s	
651/33150 (epoch 0.982), train_loss = 2.24842333, grad/param norm = 3.8088e-01, time/batch = 0.6810s	
652/33150 (epoch 0.983), train_loss = 2.29139503, grad/param norm = 4.2838e-01, time/batch = 0.6680s	
653/33150 (epoch 0.985), train_loss = 2.28213984, grad/param norm = 3.9332e-01, time/batch = 0.6651s	
654/33150 (epoch 0.986), train_loss = 2.22231238, grad/param norm = 3.1565e-01, time/batch = 0.6660s	
655/33150 (epoch 0.988), train_loss = 2.35423381, grad/param norm = 3.7043e-01, time/batch = 0.6649s	
656/33150 (epoch 0.989), train_loss = 2.26890826, grad/param norm = 3.7281e-01, time/batch = 0.6739s	
657/33150 (epoch 0.991), train_loss = 2.23624229, grad/param norm = 4.6868e-01, time/batch = 0.6768s	
658/33150 (epoch 0.992), train_loss = 2.13047392, grad/param norm = 6.0796e-01, time/batch = 0.6788s	
659/33150 (epoch 0.994), train_loss = 2.16078039, grad/param norm = 4.9452e-01, time/batch = 0.6657s	
660/33150 (epoch 0.995), train_loss = 2.20211177, grad/param norm = 3.2622e-01, time/batch = 0.6653s	
661/33150 (epoch 0.997), train_loss = 2.30905065, grad/param norm = 3.2216e-01, time/batch = 0.6673s	
662/33150 (epoch 0.998), train_loss = 2.04479601, grad/param norm = 3.7765e-01, time/batch = 0.6660s	
663/33150 (epoch 1.000), train_loss = 2.30156135, grad/param norm = 3.9542e-01, time/batch = 0.6620s	
664/33150 (epoch 1.002), train_loss = 2.32515074, grad/param norm = 3.7987e-01, time/batch = 0.6647s	
665/33150 (epoch 1.003), train_loss = 2.18273811, grad/param norm = 3.0961e-01, time/batch = 0.6663s	
666/33150 (epoch 1.005), train_loss = 2.11946352, grad/param norm = 3.2365e-01, time/batch = 0.6658s	
667/33150 (epoch 1.006), train_loss = 1.94108202, grad/param norm = 3.0087e-01, time/batch = 0.6643s	
668/33150 (epoch 1.008), train_loss = 2.20192108, grad/param norm = 2.6945e-01, time/batch = 0.6645s	
669/33150 (epoch 1.009), train_loss = 2.24804121, grad/param norm = 2.9422e-01, time/batch = 0.6641s	
670/33150 (epoch 1.011), train_loss = 2.40235891, grad/param norm = 2.8271e-01, time/batch = 0.6658s	
671/33150 (epoch 1.012), train_loss = 2.13501933, grad/param norm = 3.1011e-01, time/batch = 0.6650s	
672/33150 (epoch 1.014), train_loss = 2.25301624, grad/param norm = 3.7651e-01, time/batch = 0.6730s	
673/33150 (epoch 1.015), train_loss = 2.19300443, grad/param norm = 3.5132e-01, time/batch = 0.6793s	
674/33150 (epoch 1.017), train_loss = 2.13211293, grad/param norm = 2.8745e-01, time/batch = 0.6686s	
675/33150 (epoch 1.018), train_loss = 2.39837318, grad/param norm = 4.2152e-01, time/batch = 0.6689s	
676/33150 (epoch 1.020), train_loss = 2.35289781, grad/param norm = 4.0980e-01, time/batch = 0.6689s	
677/33150 (epoch 1.021), train_loss = 2.05807953, grad/param norm = 3.4818e-01, time/batch = 0.6695s	
678/33150 (epoch 1.023), train_loss = 2.35017363, grad/param norm = 3.6255e-01, time/batch = 0.6719s	
679/33150 (epoch 1.024), train_loss = 2.24796027, grad/param norm = 3.9908e-01, time/batch = 0.6724s	
680/33150 (epoch 1.026), train_loss = 2.02827101, grad/param norm = 4.1624e-01, time/batch = 0.6721s	
681/33150 (epoch 1.027), train_loss = 2.16063679, grad/param norm = 4.8216e-01, time/batch = 0.6702s	
682/33150 (epoch 1.029), train_loss = 2.21472136, grad/param norm = 4.1128e-01, time/batch = 0.6702s	
683/33150 (epoch 1.030), train_loss = 2.29360421, grad/param norm = 2.2695e-01, time/batch = 0.6772s	
684/33150 (epoch 1.032), train_loss = 2.25102542, grad/param norm = 2.7881e-01, time/batch = 0.6818s	
685/33150 (epoch 1.033), train_loss = 2.10933310, grad/param norm = 3.5376e-01, time/batch = 0.6691s	
686/33150 (epoch 1.035), train_loss = 2.35145934, grad/param norm = 3.9882e-01, time/batch = 0.6679s	
687/33150 (epoch 1.036), train_loss = 2.28270954, grad/param norm = 3.9236e-01, time/batch = 0.6696s	
688/33150 (epoch 1.038), train_loss = 2.41584441, grad/param norm = 3.6276e-01, time/batch = 0.6694s	
689/33150 (epoch 1.039), train_loss = 2.30683367, grad/param norm = 2.8903e-01, time/batch = 0.6706s	
690/33150 (epoch 1.041), train_loss = 2.17126289, grad/param norm = 2.2961e-01, time/batch = 0.6711s	
691/33150 (epoch 1.042), train_loss = 1.97989794, grad/param norm = 3.0430e-01, time/batch = 0.6863s	
692/33150 (epoch 1.044), train_loss = 2.14040666, grad/param norm = 3.2815e-01, time/batch = 0.6873s	
693/33150 (epoch 1.045), train_loss = 2.21602606, grad/param norm = 2.8448e-01, time/batch = 0.6846s	
694/33150 (epoch 1.047), train_loss = 2.13396706, grad/param norm = 3.1036e-01, time/batch = 0.6717s	
695/33150 (epoch 1.048), train_loss = 2.45143182, grad/param norm = 4.0912e-01, time/batch = 0.6659s	
696/33150 (epoch 1.050), train_loss = 2.28194021, grad/param norm = 3.9119e-01, time/batch = 0.6753s	
697/33150 (epoch 1.051), train_loss = 2.19877707, grad/param norm = 2.6966e-01, time/batch = 0.6619s	
698/33150 (epoch 1.053), train_loss = 2.12338488, grad/param norm = 2.6775e-01, time/batch = 0.6611s	
699/33150 (epoch 1.054), train_loss = 2.15167920, grad/param norm = 2.7008e-01, time/batch = 0.6631s	
700/33150 (epoch 1.056), train_loss = 2.02317033, grad/param norm = 3.3174e-01, time/batch = 0.6633s	
701/33150 (epoch 1.057), train_loss = 2.16062624, grad/param norm = 3.5070e-01, time/batch = 0.6656s	
702/33150 (epoch 1.059), train_loss = 2.30244248, grad/param norm = 4.3187e-01, time/batch = 0.6860s	
703/33150 (epoch 1.060), train_loss = 2.07270123, grad/param norm = 3.9636e-01, time/batch = 0.6767s	
704/33150 (epoch 1.062), train_loss = 2.26358622, grad/param norm = 3.0796e-01, time/batch = 0.6939s	
705/33150 (epoch 1.063), train_loss = 2.20706428, grad/param norm = 3.0870e-01, time/batch = 0.6705s	
706/33150 (epoch 1.065), train_loss = 2.30315887, grad/param norm = 3.4600e-01, time/batch = 0.6668s	
707/33150 (epoch 1.066), train_loss = 2.15366989, grad/param norm = 4.0297e-01, time/batch = 0.6630s	
708/33150 (epoch 1.068), train_loss = 2.18684185, grad/param norm = 4.0421e-01, time/batch = 0.6663s	
709/33150 (epoch 1.069), train_loss = 2.23921659, grad/param norm = 3.3082e-01, time/batch = 0.6616s	
710/33150 (epoch 1.071), train_loss = 2.27167144, grad/param norm = 3.5165e-01, time/batch = 0.6694s	
711/33150 (epoch 1.072), train_loss = 1.96841482, grad/param norm = 3.3773e-01, time/batch = 0.6708s	
712/33150 (epoch 1.074), train_loss = 2.06966860, grad/param norm = 3.6034e-01, time/batch = 0.6717s	
713/33150 (epoch 1.075), train_loss = 2.26392670, grad/param norm = 2.9270e-01, time/batch = 0.6752s	
714/33150 (epoch 1.077), train_loss = 2.16023017, grad/param norm = 2.6670e-01, time/batch = 0.6724s	
715/33150 (epoch 1.078), train_loss = 2.37633614, grad/param norm = 3.0662e-01, time/batch = 0.6701s	
716/33150 (epoch 1.080), train_loss = 2.18475848, grad/param norm = 3.0647e-01, time/batch = 0.6716s	
717/33150 (epoch 1.081), train_loss = 2.16675435, grad/param norm = 3.0760e-01, time/batch = 0.6688s	
718/33150 (epoch 1.083), train_loss = 1.94971994, grad/param norm = 3.4495e-01, time/batch = 0.6688s	
719/33150 (epoch 1.084), train_loss = 2.17135116, grad/param norm = 3.8636e-01, time/batch = 0.6688s	
720/33150 (epoch 1.086), train_loss = 2.14120349, grad/param norm = 3.7914e-01, time/batch = 0.6739s	
721/33150 (epoch 1.087), train_loss = 2.15226959, grad/param norm = 3.7194e-01, time/batch = 0.6742s	
722/33150 (epoch 1.089), train_loss = 2.00488782, grad/param norm = 3.3284e-01, time/batch = 0.6727s	
723/33150 (epoch 1.090), train_loss = 2.07920363, grad/param norm = 3.2122e-01, time/batch = 0.6716s	
724/33150 (epoch 1.092), train_loss = 2.24930053, grad/param norm = 3.2647e-01, time/batch = 0.6683s	
725/33150 (epoch 1.094), train_loss = 2.18724868, grad/param norm = 3.3009e-01, time/batch = 0.6701s	
726/33150 (epoch 1.095), train_loss = 2.04214727, grad/param norm = 2.9184e-01, time/batch = 0.6752s	
727/33150 (epoch 1.097), train_loss = 2.39227283, grad/param norm = 4.1512e-01, time/batch = 0.6692s	
728/33150 (epoch 1.098), train_loss = 2.47500438, grad/param norm = 4.7782e-01, time/batch = 0.6688s	
729/33150 (epoch 1.100), train_loss = 2.24753061, grad/param norm = 3.7690e-01, time/batch = 0.6683s	
730/33150 (epoch 1.101), train_loss = 2.06564192, grad/param norm = 3.3017e-01, time/batch = 0.6674s	
731/33150 (epoch 1.103), train_loss = 2.17147428, grad/param norm = 2.8666e-01, time/batch = 0.6729s	
732/33150 (epoch 1.104), train_loss = 2.17675127, grad/param norm = 3.4578e-01, time/batch = 0.6802s	
733/33150 (epoch 1.106), train_loss = 2.25299186, grad/param norm = 2.8111e-01, time/batch = 0.6723s	
734/33150 (epoch 1.107), train_loss = 2.17341795, grad/param norm = 3.0151e-01, time/batch = 0.6685s	
735/33150 (epoch 1.109), train_loss = 2.22100598, grad/param norm = 3.5543e-01, time/batch = 0.6728s	
736/33150 (epoch 1.110), train_loss = 2.30398371, grad/param norm = 2.9344e-01, time/batch = 0.6744s	
737/33150 (epoch 1.112), train_loss = 2.08188306, grad/param norm = 2.6813e-01, time/batch = 0.6670s	
738/33150 (epoch 1.113), train_loss = 2.01835187, grad/param norm = 2.9783e-01, time/batch = 0.6673s	
739/33150 (epoch 1.115), train_loss = 2.25611097, grad/param norm = 3.6946e-01, time/batch = 0.6639s	
740/33150 (epoch 1.116), train_loss = 1.98429670, grad/param norm = 2.7710e-01, time/batch = 0.6683s	
741/33150 (epoch 1.118), train_loss = 2.13285988, grad/param norm = 2.6090e-01, time/batch = 0.6698s	
742/33150 (epoch 1.119), train_loss = 2.23966155, grad/param norm = 3.5422e-01, time/batch = 0.6890s	
743/33150 (epoch 1.121), train_loss = 2.25929955, grad/param norm = 4.4049e-01, time/batch = 0.6790s	
744/33150 (epoch 1.122), train_loss = 2.31744980, grad/param norm = 4.8116e-01, time/batch = 0.6704s	
745/33150 (epoch 1.124), train_loss = 2.11520652, grad/param norm = 4.0249e-01, time/batch = 0.6723s	
746/33150 (epoch 1.125), train_loss = 2.11515821, grad/param norm = 4.4328e-01, time/batch = 0.6707s	
747/33150 (epoch 1.127), train_loss = 2.08288941, grad/param norm = 3.1201e-01, time/batch = 0.6699s	
748/33150 (epoch 1.128), train_loss = 2.20113372, grad/param norm = 3.5612e-01, time/batch = 0.6688s	
749/33150 (epoch 1.130), train_loss = 2.23065553, grad/param norm = 2.6414e-01, time/batch = 0.6647s	
750/33150 (epoch 1.131), train_loss = 2.24350029, grad/param norm = 2.8884e-01, time/batch = 0.6664s	
751/33150 (epoch 1.133), train_loss = 2.06979833, grad/param norm = 3.0765e-01, time/batch = 0.6729s	
752/33150 (epoch 1.134), train_loss = 2.22362690, grad/param norm = 3.1664e-01, time/batch = 0.6663s	
753/33150 (epoch 1.136), train_loss = 2.12115160, grad/param norm = 3.3017e-01, time/batch = 0.6658s	
754/33150 (epoch 1.137), train_loss = 2.20204190, grad/param norm = 3.0108e-01, time/batch = 0.6679s	
755/33150 (epoch 1.139), train_loss = 2.19136207, grad/param norm = 2.9642e-01, time/batch = 0.6698s	
756/33150 (epoch 1.140), train_loss = 2.27490443, grad/param norm = 3.3556e-01, time/batch = 0.6634s	
757/33150 (epoch 1.142), train_loss = 2.09611013, grad/param norm = 3.5199e-01, time/batch = 0.6631s	
758/33150 (epoch 1.143), train_loss = 2.20322135, grad/param norm = 3.7694e-01, time/batch = 0.6635s	
759/33150 (epoch 1.145), train_loss = 2.18052918, grad/param norm = 3.7089e-01, time/batch = 0.6638s	
760/33150 (epoch 1.146), train_loss = 2.34722164, grad/param norm = 3.1916e-01, time/batch = 0.6637s	
761/33150 (epoch 1.148), train_loss = 2.21387027, grad/param norm = 3.1025e-01, time/batch = 0.6735s	
762/33150 (epoch 1.149), train_loss = 2.21726464, grad/param norm = 3.3833e-01, time/batch = 0.6863s	
763/33150 (epoch 1.151), train_loss = 2.33124251, grad/param norm = 2.7305e-01, time/batch = 0.6834s	
764/33150 (epoch 1.152), train_loss = 1.96319305, grad/param norm = 2.9296e-01, time/batch = 0.6697s	
765/33150 (epoch 1.154), train_loss = 2.06064051, grad/param norm = 3.1725e-01, time/batch = 0.6841s	
766/33150 (epoch 1.155), train_loss = 2.09814818, grad/param norm = 3.8160e-01, time/batch = 0.6969s	
767/33150 (epoch 1.157), train_loss = 2.15298369, grad/param norm = 3.5643e-01, time/batch = 0.6867s	
768/33150 (epoch 1.158), train_loss = 2.05190446, grad/param norm = 3.1059e-01, time/batch = 0.6762s	
769/33150 (epoch 1.160), train_loss = 2.26783013, grad/param norm = 3.2537e-01, time/batch = 0.6609s	
770/33150 (epoch 1.161), train_loss = 2.08561921, grad/param norm = 3.3290e-01, time/batch = 0.6638s	
771/33150 (epoch 1.163), train_loss = 2.08702130, grad/param norm = 3.4848e-01, time/batch = 0.6684s	
772/33150 (epoch 1.164), train_loss = 2.17867595, grad/param norm = 3.6003e-01, time/batch = 0.6655s	
773/33150 (epoch 1.166), train_loss = 2.29026661, grad/param norm = 4.1451e-01, time/batch = 0.6790s	
774/33150 (epoch 1.167), train_loss = 2.11005498, grad/param norm = 3.1390e-01, time/batch = 0.6847s	
775/33150 (epoch 1.169), train_loss = 2.34938101, grad/param norm = 3.0315e-01, time/batch = 0.6808s	
776/33150 (epoch 1.170), train_loss = 2.27161325, grad/param norm = 2.9077e-01, time/batch = 0.6855s	
777/33150 (epoch 1.172), train_loss = 2.24265350, grad/param norm = 3.2957e-01, time/batch = 0.6771s	
778/33150 (epoch 1.173), train_loss = 2.26641375, grad/param norm = 3.2870e-01, time/batch = 0.6683s	
779/33150 (epoch 1.175), train_loss = 2.01753771, grad/param norm = 3.3030e-01, time/batch = 0.6814s	
780/33150 (epoch 1.176), train_loss = 1.96858860, grad/param norm = 3.7258e-01, time/batch = 0.6921s	
781/33150 (epoch 1.178), train_loss = 2.19712023, grad/param norm = 3.9978e-01, time/batch = 0.6901s	
782/33150 (epoch 1.179), train_loss = 2.21781252, grad/param norm = 3.0414e-01, time/batch = 0.6896s	
783/33150 (epoch 1.181), train_loss = 2.17978081, grad/param norm = 2.8885e-01, time/batch = 0.6712s	
784/33150 (epoch 1.183), train_loss = 2.17628818, grad/param norm = 3.6717e-01, time/batch = 0.6705s	
785/33150 (epoch 1.184), train_loss = 2.18399605, grad/param norm = 3.5510e-01, time/batch = 0.6752s	
786/33150 (epoch 1.186), train_loss = 2.26649395, grad/param norm = 3.3843e-01, time/batch = 0.6774s	
787/33150 (epoch 1.187), train_loss = 2.12597654, grad/param norm = 3.3564e-01, time/batch = 0.6669s	
788/33150 (epoch 1.189), train_loss = 2.17754208, grad/param norm = 3.3942e-01, time/batch = 0.6782s	
789/33150 (epoch 1.190), train_loss = 2.09249641, grad/param norm = 3.0673e-01, time/batch = 0.6712s	
790/33150 (epoch 1.192), train_loss = 2.10829468, grad/param norm = 2.9487e-01, time/batch = 0.6752s	
791/33150 (epoch 1.193), train_loss = 2.00264218, grad/param norm = 3.2057e-01, time/batch = 0.6812s	
792/33150 (epoch 1.195), train_loss = 2.43338809, grad/param norm = 4.1705e-01, time/batch = 0.6763s	
793/33150 (epoch 1.196), train_loss = 2.19698192, grad/param norm = 3.1138e-01, time/batch = 0.6744s	
794/33150 (epoch 1.198), train_loss = 2.10171571, grad/param norm = 2.7171e-01, time/batch = 0.6807s	
795/33150 (epoch 1.199), train_loss = 2.23199058, grad/param norm = 2.6383e-01, time/batch = 0.6685s	
796/33150 (epoch 1.201), train_loss = 2.00393762, grad/param norm = 2.4175e-01, time/batch = 0.6679s	
797/33150 (epoch 1.202), train_loss = 1.88706102, grad/param norm = 2.6076e-01, time/batch = 0.6662s	
798/33150 (epoch 1.204), train_loss = 2.10266330, grad/param norm = 3.3729e-01, time/batch = 0.6644s	
799/33150 (epoch 1.205), train_loss = 2.27093879, grad/param norm = 3.3060e-01, time/batch = 0.6654s	
800/33150 (epoch 1.207), train_loss = 2.16241915, grad/param norm = 4.0370e-01, time/batch = 0.6632s	
801/33150 (epoch 1.208), train_loss = 2.17703887, grad/param norm = 3.4889e-01, time/batch = 0.6754s	
802/33150 (epoch 1.210), train_loss = 2.00750815, grad/param norm = 3.0707e-01, time/batch = 0.6728s	
803/33150 (epoch 1.211), train_loss = 2.22360973, grad/param norm = 3.2826e-01, time/batch = 0.6645s	
804/33150 (epoch 1.213), train_loss = 2.40328926, grad/param norm = 2.8830e-01, time/batch = 0.6659s	
805/33150 (epoch 1.214), train_loss = 2.02971015, grad/param norm = 2.8641e-01, time/batch = 0.6687s	
806/33150 (epoch 1.216), train_loss = 2.16689837, grad/param norm = 3.1181e-01, time/batch = 0.6797s	
807/33150 (epoch 1.217), train_loss = 2.16059879, grad/param norm = 2.5477e-01, time/batch = 0.6706s	
808/33150 (epoch 1.219), train_loss = 2.12572796, grad/param norm = 2.9666e-01, time/batch = 0.6796s	
809/33150 (epoch 1.220), train_loss = 1.92743862, grad/param norm = 2.8117e-01, time/batch = 0.6754s	
810/33150 (epoch 1.222), train_loss = 2.18253448, grad/param norm = 2.9692e-01, time/batch = 0.6775s	
811/33150 (epoch 1.223), train_loss = 2.10781180, grad/param norm = 3.6025e-01, time/batch = 0.6874s	
812/33150 (epoch 1.225), train_loss = 2.33728890, grad/param norm = 3.1657e-01, time/batch = 0.6810s	
813/33150 (epoch 1.226), train_loss = 2.08275138, grad/param norm = 3.5812e-01, time/batch = 0.6772s	
814/33150 (epoch 1.228), train_loss = 2.11688790, grad/param norm = 4.3745e-01, time/batch = 0.6749s	
815/33150 (epoch 1.229), train_loss = 2.24864488, grad/param norm = 3.5040e-01, time/batch = 0.6824s	
816/33150 (epoch 1.231), train_loss = 2.19841770, grad/param norm = 3.1406e-01, time/batch = 0.6725s	
817/33150 (epoch 1.232), train_loss = 2.15554170, grad/param norm = 2.8327e-01, time/batch = 0.6775s	
818/33150 (epoch 1.234), train_loss = 2.09727364, grad/param norm = 3.2729e-01, time/batch = 0.6650s	
819/33150 (epoch 1.235), train_loss = 2.24532455, grad/param norm = 3.5106e-01, time/batch = 0.6689s	
820/33150 (epoch 1.237), train_loss = 2.15501052, grad/param norm = 3.0958e-01, time/batch = 0.6725s	
821/33150 (epoch 1.238), train_loss = 2.31828427, grad/param norm = 2.9482e-01, time/batch = 0.6804s	
822/33150 (epoch 1.240), train_loss = 2.07060479, grad/param norm = 2.8078e-01, time/batch = 0.6727s	
823/33150 (epoch 1.241), train_loss = 2.13060356, grad/param norm = 3.2828e-01, time/batch = 0.6689s	
824/33150 (epoch 1.243), train_loss = 2.26743211, grad/param norm = 2.7934e-01, time/batch = 0.6678s	
825/33150 (epoch 1.244), train_loss = 2.11562804, grad/param norm = 3.0174e-01, time/batch = 0.6681s	
826/33150 (epoch 1.246), train_loss = 2.10686667, grad/param norm = 3.1786e-01, time/batch = 0.6675s	
827/33150 (epoch 1.247), train_loss = 2.07342771, grad/param norm = 2.9824e-01, time/batch = 0.6678s	
828/33150 (epoch 1.249), train_loss = 2.36565325, grad/param norm = 3.2548e-01, time/batch = 0.6680s	
829/33150 (epoch 1.250), train_loss = 2.09402015, grad/param norm = 2.9580e-01, time/batch = 0.6713s	
830/33150 (epoch 1.252), train_loss = 2.05359384, grad/param norm = 2.3966e-01, time/batch = 0.6673s	
831/33150 (epoch 1.253), train_loss = 2.25802080, grad/param norm = 3.4706e-01, time/batch = 0.6687s	
832/33150 (epoch 1.255), train_loss = 2.16825367, grad/param norm = 3.0606e-01, time/batch = 0.6671s	
833/33150 (epoch 1.256), train_loss = 2.21619013, grad/param norm = 2.6805e-01, time/batch = 0.6665s	
834/33150 (epoch 1.258), train_loss = 2.12374448, grad/param norm = 4.1632e-01, time/batch = 0.6683s	
835/33150 (epoch 1.259), train_loss = 1.98941215, grad/param norm = 4.6350e-01, time/batch = 0.6758s	
836/33150 (epoch 1.261), train_loss = 1.98596084, grad/param norm = 4.0786e-01, time/batch = 0.6795s	
837/33150 (epoch 1.262), train_loss = 2.10466639, grad/param norm = 3.9309e-01, time/batch = 0.6814s	
838/33150 (epoch 1.264), train_loss = 1.95393951, grad/param norm = 3.7744e-01, time/batch = 0.6735s	
839/33150 (epoch 1.265), train_loss = 2.20701531, grad/param norm = 4.1794e-01, time/batch = 0.6663s	
840/33150 (epoch 1.267), train_loss = 2.19375477, grad/param norm = 3.1117e-01, time/batch = 0.6703s	
841/33150 (epoch 1.268), train_loss = 1.93825991, grad/param norm = 3.1825e-01, time/batch = 0.6742s	
842/33150 (epoch 1.270), train_loss = 2.22966837, grad/param norm = 2.9245e-01, time/batch = 0.6720s	
843/33150 (epoch 1.271), train_loss = 2.23177051, grad/param norm = 2.8081e-01, time/batch = 0.6698s	
844/33150 (epoch 1.273), train_loss = 2.18267368, grad/param norm = 3.5233e-01, time/batch = 0.6726s	
845/33150 (epoch 1.275), train_loss = 2.15466049, grad/param norm = 2.9012e-01, time/batch = 0.6670s	
846/33150 (epoch 1.276), train_loss = 2.13379199, grad/param norm = 2.9355e-01, time/batch = 0.6676s	
847/33150 (epoch 1.278), train_loss = 2.21300538, grad/param norm = 3.5014e-01, time/batch = 0.6673s	
848/33150 (epoch 1.279), train_loss = 2.16036123, grad/param norm = 3.7742e-01, time/batch = 0.6659s	
849/33150 (epoch 1.281), train_loss = 2.22145767, grad/param norm = 3.1549e-01, time/batch = 0.6652s	
850/33150 (epoch 1.282), train_loss = 2.08402398, grad/param norm = 2.8706e-01, time/batch = 0.6784s	
851/33150 (epoch 1.284), train_loss = 2.09213123, grad/param norm = 2.2974e-01, time/batch = 0.6745s	
852/33150 (epoch 1.285), train_loss = 2.16854640, grad/param norm = 3.1312e-01, time/batch = 0.6648s	
853/33150 (epoch 1.287), train_loss = 2.08057141, grad/param norm = 2.9078e-01, time/batch = 0.6651s	
854/33150 (epoch 1.288), train_loss = 2.35057680, grad/param norm = 2.9725e-01, time/batch = 0.6662s	
855/33150 (epoch 1.290), train_loss = 2.04842098, grad/param norm = 2.9578e-01, time/batch = 0.6674s	
856/33150 (epoch 1.291), train_loss = 2.19552406, grad/param norm = 3.7530e-01, time/batch = 0.6664s	
857/33150 (epoch 1.293), train_loss = 2.19090266, grad/param norm = 3.1571e-01, time/batch = 0.6645s	
858/33150 (epoch 1.294), train_loss = 1.88246852, grad/param norm = 3.3235e-01, time/batch = 0.6675s	
859/33150 (epoch 1.296), train_loss = 2.11613033, grad/param norm = 3.0942e-01, time/batch = 0.6645s	
860/33150 (epoch 1.297), train_loss = 2.11156055, grad/param norm = 2.5771e-01, time/batch = 0.6630s	
861/33150 (epoch 1.299), train_loss = 2.05891908, grad/param norm = 2.7703e-01, time/batch = 0.6659s	
862/33150 (epoch 1.300), train_loss = 1.99375027, grad/param norm = 2.6836e-01, time/batch = 0.6642s	
863/33150 (epoch 1.302), train_loss = 2.09094497, grad/param norm = 3.9412e-01, time/batch = 0.6664s	
864/33150 (epoch 1.303), train_loss = 2.37563960, grad/param norm = 3.8138e-01, time/batch = 0.6657s	
865/33150 (epoch 1.305), train_loss = 2.10436880, grad/param norm = 2.9281e-01, time/batch = 0.6716s	
866/33150 (epoch 1.306), train_loss = 2.13146579, grad/param norm = 2.9915e-01, time/batch = 0.6648s	
867/33150 (epoch 1.308), train_loss = 2.27014114, grad/param norm = 2.8809e-01, time/batch = 0.6667s	
868/33150 (epoch 1.309), train_loss = 2.13866015, grad/param norm = 2.7744e-01, time/batch = 0.6710s	
869/33150 (epoch 1.311), train_loss = 2.27428064, grad/param norm = 3.3691e-01, time/batch = 0.6872s	
870/33150 (epoch 1.312), train_loss = 2.01092240, grad/param norm = 3.9784e-01, time/batch = 0.6913s	
871/33150 (epoch 1.314), train_loss = 2.25792407, grad/param norm = 3.8885e-01, time/batch = 0.6882s	
872/33150 (epoch 1.315), train_loss = 2.19888586, grad/param norm = 4.0758e-01, time/batch = 0.6848s	
873/33150 (epoch 1.317), train_loss = 1.90811492, grad/param norm = 2.8215e-01, time/batch = 0.6787s	
874/33150 (epoch 1.318), train_loss = 2.01981308, grad/param norm = 2.7511e-01, time/batch = 0.6745s	
875/33150 (epoch 1.320), train_loss = 2.08831183, grad/param norm = 2.8586e-01, time/batch = 0.6683s	
876/33150 (epoch 1.321), train_loss = 2.06349464, grad/param norm = 3.7495e-01, time/batch = 0.6935s	
877/33150 (epoch 1.323), train_loss = 2.17589332, grad/param norm = 3.2372e-01, time/batch = 0.6867s	
878/33150 (epoch 1.324), train_loss = 2.25805810, grad/param norm = 2.9965e-01, time/batch = 0.6727s	
879/33150 (epoch 1.326), train_loss = 2.00641339, grad/param norm = 2.9122e-01, time/batch = 0.6646s	
880/33150 (epoch 1.327), train_loss = 2.21677663, grad/param norm = 2.8987e-01, time/batch = 0.6626s	
881/33150 (epoch 1.329), train_loss = 2.05688677, grad/param norm = 2.5626e-01, time/batch = 0.6693s	
882/33150 (epoch 1.330), train_loss = 2.22788148, grad/param norm = 2.9767e-01, time/batch = 0.6772s	
883/33150 (epoch 1.332), train_loss = 2.10102909, grad/param norm = 3.5172e-01, time/batch = 0.6669s	
884/33150 (epoch 1.333), train_loss = 2.05675503, grad/param norm = 2.3734e-01, time/batch = 0.6926s	
885/33150 (epoch 1.335), train_loss = 2.15540485, grad/param norm = 2.7209e-01, time/batch = 0.6807s	
886/33150 (epoch 1.336), train_loss = 2.07887599, grad/param norm = 3.3811e-01, time/batch = 0.6679s	
887/33150 (epoch 1.338), train_loss = 1.91681289, grad/param norm = 4.7570e-01, time/batch = 0.6623s	
888/33150 (epoch 1.339), train_loss = 2.24473933, grad/param norm = 4.4715e-01, time/batch = 0.6697s	
889/33150 (epoch 1.341), train_loss = 2.34246281, grad/param norm = 3.2479e-01, time/batch = 0.6682s	
890/33150 (epoch 1.342), train_loss = 2.08579690, grad/param norm = 2.6599e-01, time/batch = 0.6742s	
891/33150 (epoch 1.344), train_loss = 2.14098773, grad/param norm = 2.7300e-01, time/batch = 0.6746s	
892/33150 (epoch 1.345), train_loss = 1.85172214, grad/param norm = 2.7940e-01, time/batch = 0.6915s	
893/33150 (epoch 1.347), train_loss = 1.85537500, grad/param norm = 2.9663e-01, time/batch = 0.6711s	
894/33150 (epoch 1.348), train_loss = 2.03074191, grad/param norm = 3.4866e-01, time/batch = 0.6753s	
895/33150 (epoch 1.350), train_loss = 2.24543079, grad/param norm = 2.8719e-01, time/batch = 0.6794s	
896/33150 (epoch 1.351), train_loss = 2.15381304, grad/param norm = 3.1855e-01, time/batch = 0.6761s	
897/33150 (epoch 1.353), train_loss = 2.18440559, grad/param norm = 2.8908e-01, time/batch = 0.6750s	
898/33150 (epoch 1.354), train_loss = 2.34308836, grad/param norm = 2.4926e-01, time/batch = 0.6748s	
899/33150 (epoch 1.356), train_loss = 2.02536704, grad/param norm = 3.2599e-01, time/batch = 0.6752s	
900/33150 (epoch 1.357), train_loss = 2.13537571, grad/param norm = 3.7933e-01, time/batch = 0.6718s	
901/33150 (epoch 1.359), train_loss = 2.02230518, grad/param norm = 3.6211e-01, time/batch = 0.6718s	
902/33150 (epoch 1.360), train_loss = 2.21656178, grad/param norm = 3.2222e-01, time/batch = 0.6677s	
903/33150 (epoch 1.362), train_loss = 2.08426935, grad/param norm = 2.6861e-01, time/batch = 0.6755s	
904/33150 (epoch 1.363), train_loss = 2.00318607, grad/param norm = 3.1109e-01, time/batch = 0.6716s	
905/33150 (epoch 1.365), train_loss = 2.14145322, grad/param norm = 3.3983e-01, time/batch = 0.6669s	
906/33150 (epoch 1.367), train_loss = 1.89226147, grad/param norm = 2.9921e-01, time/batch = 0.6660s	
907/33150 (epoch 1.368), train_loss = 2.22038052, grad/param norm = 2.8351e-01, time/batch = 0.6673s	
908/33150 (epoch 1.370), train_loss = 2.30809433, grad/param norm = 2.9485e-01, time/batch = 0.6665s	
909/33150 (epoch 1.371), train_loss = 2.09971291, grad/param norm = 2.8515e-01, time/batch = 0.6753s	
910/33150 (epoch 1.373), train_loss = 2.12823000, grad/param norm = 2.6852e-01, time/batch = 0.6776s	
911/33150 (epoch 1.374), train_loss = 1.96165110, grad/param norm = 3.1752e-01, time/batch = 0.6693s	
912/33150 (epoch 1.376), train_loss = 2.21523775, grad/param norm = 3.1840e-01, time/batch = 0.6714s	
913/33150 (epoch 1.377), train_loss = 2.15065057, grad/param norm = 3.0752e-01, time/batch = 0.6707s	
914/33150 (epoch 1.379), train_loss = 2.13682128, grad/param norm = 2.8520e-01, time/batch = 0.6784s	
915/33150 (epoch 1.380), train_loss = 2.23312338, grad/param norm = 3.1105e-01, time/batch = 0.6730s	
916/33150 (epoch 1.382), train_loss = 1.99674351, grad/param norm = 2.9665e-01, time/batch = 0.6704s	
917/33150 (epoch 1.383), train_loss = 1.94599029, grad/param norm = 2.3959e-01, time/batch = 0.6721s	
918/33150 (epoch 1.385), train_loss = 2.13464246, grad/param norm = 2.6239e-01, time/batch = 0.6701s	
919/33150 (epoch 1.386), train_loss = 1.91599915, grad/param norm = 2.7005e-01, time/batch = 0.6682s	
920/33150 (epoch 1.388), train_loss = 2.08925326, grad/param norm = 3.3887e-01, time/batch = 0.6690s	
921/33150 (epoch 1.389), train_loss = 2.09858007, grad/param norm = 2.8871e-01, time/batch = 0.6691s	
922/33150 (epoch 1.391), train_loss = 2.30750052, grad/param norm = 3.2195e-01, time/batch = 0.6688s	
923/33150 (epoch 1.392), train_loss = 2.08811792, grad/param norm = 3.4604e-01, time/batch = 0.6655s	
924/33150 (epoch 1.394), train_loss = 1.99313046, grad/param norm = 2.7114e-01, time/batch = 0.6781s	
925/33150 (epoch 1.395), train_loss = 2.10639123, grad/param norm = 2.9948e-01, time/batch = 0.6741s	
926/33150 (epoch 1.397), train_loss = 1.61672913, grad/param norm = 3.4077e-01, time/batch = 0.6664s	
927/33150 (epoch 1.398), train_loss = 2.11072642, grad/param norm = 3.0896e-01, time/batch = 0.6786s	
928/33150 (epoch 1.400), train_loss = 1.96666331, grad/param norm = 2.7244e-01, time/batch = 0.6822s	
929/33150 (epoch 1.401), train_loss = 1.84501007, grad/param norm = 2.4898e-01, time/batch = 0.6689s	
930/33150 (epoch 1.403), train_loss = 2.02250081, grad/param norm = 2.9495e-01, time/batch = 0.6794s	
931/33150 (epoch 1.404), train_loss = 2.00331480, grad/param norm = 2.8149e-01, time/batch = 0.6684s	
932/33150 (epoch 1.406), train_loss = 1.97730471, grad/param norm = 3.5874e-01, time/batch = 0.6680s	
933/33150 (epoch 1.407), train_loss = 1.91392688, grad/param norm = 2.7438e-01, time/batch = 0.6713s	
934/33150 (epoch 1.409), train_loss = 1.78463475, grad/param norm = 2.9590e-01, time/batch = 0.6672s	
935/33150 (epoch 1.410), train_loss = 2.11309453, grad/param norm = 2.8166e-01, time/batch = 0.6672s	
936/33150 (epoch 1.412), train_loss = 2.14400085, grad/param norm = 2.6730e-01, time/batch = 0.6686s	
937/33150 (epoch 1.413), train_loss = 2.04323991, grad/param norm = 3.2858e-01, time/batch = 0.6688s	
938/33150 (epoch 1.415), train_loss = 2.20004427, grad/param norm = 2.8416e-01, time/batch = 0.6688s	
939/33150 (epoch 1.416), train_loss = 2.12196404, grad/param norm = 2.5547e-01, time/batch = 0.6801s	
940/33150 (epoch 1.418), train_loss = 2.38829089, grad/param norm = 3.3521e-01, time/batch = 0.6738s	
941/33150 (epoch 1.419), train_loss = 2.09258795, grad/param norm = 2.7175e-01, time/batch = 0.6714s	
942/33150 (epoch 1.421), train_loss = 2.15988133, grad/param norm = 2.6793e-01, time/batch = 0.6678s	
943/33150 (epoch 1.422), train_loss = 1.90047223, grad/param norm = 3.0158e-01, time/batch = 0.6683s	
944/33150 (epoch 1.424), train_loss = 2.04790963, grad/param norm = 2.8985e-01, time/batch = 0.6713s	
945/33150 (epoch 1.425), train_loss = 1.97321285, grad/param norm = 2.6957e-01, time/batch = 0.6708s	
946/33150 (epoch 1.427), train_loss = 2.00046377, grad/param norm = 2.8501e-01, time/batch = 0.6695s	
947/33150 (epoch 1.428), train_loss = 2.16556262, grad/param norm = 2.8227e-01, time/batch = 0.6689s	
948/33150 (epoch 1.430), train_loss = 2.05422661, grad/param norm = 3.0025e-01, time/batch = 0.6707s	
949/33150 (epoch 1.431), train_loss = 2.10772373, grad/param norm = 3.1648e-01, time/batch = 0.6678s	
950/33150 (epoch 1.433), train_loss = 2.11305071, grad/param norm = 2.8162e-01, time/batch = 0.6680s	
951/33150 (epoch 1.434), train_loss = 1.84545224, grad/param norm = 3.3778e-01, time/batch = 0.6702s	
952/33150 (epoch 1.436), train_loss = 1.90332063, grad/param norm = 3.5144e-01, time/batch = 0.6663s	
953/33150 (epoch 1.437), train_loss = 2.03236835, grad/param norm = 3.2361e-01, time/batch = 0.6652s	
954/33150 (epoch 1.439), train_loss = 2.05414864, grad/param norm = 2.6471e-01, time/batch = 0.6800s	
955/33150 (epoch 1.440), train_loss = 2.07695404, grad/param norm = 3.3158e-01, time/batch = 0.6753s	
956/33150 (epoch 1.442), train_loss = 1.84195166, grad/param norm = 2.8052e-01, time/batch = 0.6672s	
957/33150 (epoch 1.443), train_loss = 2.08713836, grad/param norm = 2.9595e-01, time/batch = 0.6749s	
958/33150 (epoch 1.445), train_loss = 2.03854609, grad/param norm = 2.6446e-01, time/batch = 0.6866s	
959/33150 (epoch 1.446), train_loss = 2.16112584, grad/param norm = 3.2241e-01, time/batch = 0.6872s	
960/33150 (epoch 1.448), train_loss = 1.96192597, grad/param norm = 2.6680e-01, time/batch = 0.6810s	
961/33150 (epoch 1.449), train_loss = 1.90499166, grad/param norm = 2.4847e-01, time/batch = 0.6656s	
962/33150 (epoch 1.451), train_loss = 2.08356155, grad/param norm = 2.8225e-01, time/batch = 0.6720s	
963/33150 (epoch 1.452), train_loss = 2.18346596, grad/param norm = 2.3440e-01, time/batch = 0.6898s	
964/33150 (epoch 1.454), train_loss = 2.20544012, grad/param norm = 2.6077e-01, time/batch = 0.6807s	
965/33150 (epoch 1.456), train_loss = 1.77456892, grad/param norm = 2.9381e-01, time/batch = 0.6652s	
966/33150 (epoch 1.457), train_loss = 2.09623592, grad/param norm = 3.6189e-01, time/batch = 0.6657s	
967/33150 (epoch 1.459), train_loss = 2.11614538, grad/param norm = 3.1619e-01, time/batch = 0.6737s	
968/33150 (epoch 1.460), train_loss = 1.97605189, grad/param norm = 2.3578e-01, time/batch = 0.6712s	
969/33150 (epoch 1.462), train_loss = 2.06659714, grad/param norm = 2.9114e-01, time/batch = 0.6801s	
970/33150 (epoch 1.463), train_loss = 2.26100705, grad/param norm = 3.5032e-01, time/batch = 0.6637s	
971/33150 (epoch 1.465), train_loss = 2.02226677, grad/param norm = 2.6920e-01, time/batch = 0.6713s	
972/33150 (epoch 1.466), train_loss = 1.96093058, grad/param norm = 2.6910e-01, time/batch = 0.6692s	
973/33150 (epoch 1.468), train_loss = 2.27516464, grad/param norm = 3.1929e-01, time/batch = 0.6700s	
974/33150 (epoch 1.469), train_loss = 2.20323469, grad/param norm = 2.9063e-01, time/batch = 0.6720s	
975/33150 (epoch 1.471), train_loss = 1.93725712, grad/param norm = 2.9225e-01, time/batch = 0.6719s	
976/33150 (epoch 1.472), train_loss = 1.92296166, grad/param norm = 2.6798e-01, time/batch = 0.6722s	
977/33150 (epoch 1.474), train_loss = 1.96671934, grad/param norm = 3.1728e-01, time/batch = 0.6709s	
978/33150 (epoch 1.475), train_loss = 2.21990163, grad/param norm = 3.0254e-01, time/batch = 0.6698s	
979/33150 (epoch 1.477), train_loss = 2.12138756, grad/param norm = 3.5410e-01, time/batch = 0.6728s	
980/33150 (epoch 1.478), train_loss = 2.04275474, grad/param norm = 2.9166e-01, time/batch = 0.6795s	
981/33150 (epoch 1.480), train_loss = 1.87090528, grad/param norm = 2.7630e-01, time/batch = 0.6684s	
982/33150 (epoch 1.481), train_loss = 1.72485800, grad/param norm = 2.8938e-01, time/batch = 0.6652s	
983/33150 (epoch 1.483), train_loss = 1.91039690, grad/param norm = 3.1195e-01, time/batch = 0.6725s	
984/33150 (epoch 1.484), train_loss = 1.92790606, grad/param norm = 2.8141e-01, time/batch = 0.6641s	
985/33150 (epoch 1.486), train_loss = 2.05930270, grad/param norm = 2.5509e-01, time/batch = 0.6640s	
986/33150 (epoch 1.487), train_loss = 2.03301037, grad/param norm = 2.4196e-01, time/batch = 0.6630s	
987/33150 (epoch 1.489), train_loss = 2.01675889, grad/param norm = 2.4874e-01, time/batch = 0.6688s	
988/33150 (epoch 1.490), train_loss = 1.90728636, grad/param norm = 3.1437e-01, time/batch = 0.6690s	
989/33150 (epoch 1.492), train_loss = 1.95430892, grad/param norm = 3.3833e-01, time/batch = 0.6653s	
990/33150 (epoch 1.493), train_loss = 2.09347693, grad/param norm = 2.4596e-01, time/batch = 0.6655s	
991/33150 (epoch 1.495), train_loss = 2.15476667, grad/param norm = 3.0875e-01, time/batch = 0.6663s	
992/33150 (epoch 1.496), train_loss = 2.03811863, grad/param norm = 3.4756e-01, time/batch = 0.6695s	
993/33150 (epoch 1.498), train_loss = 1.99980590, grad/param norm = 2.6377e-01, time/batch = 0.6720s	
994/33150 (epoch 1.499), train_loss = 2.32050979, grad/param norm = 3.8191e-01, time/batch = 0.6680s	
995/33150 (epoch 1.501), train_loss = 2.05990715, grad/param norm = 4.2161e-01, time/batch = 0.6697s	
996/33150 (epoch 1.502), train_loss = 2.14931770, grad/param norm = 2.8824e-01, time/batch = 0.6695s	
997/33150 (epoch 1.504), train_loss = 2.04424846, grad/param norm = 2.6040e-01, time/batch = 0.6687s	
998/33150 (epoch 1.505), train_loss = 2.23225456, grad/param norm = 3.1461e-01, time/batch = 0.6695s	
999/33150 (epoch 1.507), train_loss = 1.97241455, grad/param norm = 2.9538e-01, time/batch = 0.6655s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch1.51_2.0581.t7	
1000/33150 (epoch 1.508), train_loss = 1.95585475, grad/param norm = 2.6171e-01, time/batch = 0.6657s	
1001/33150 (epoch 1.510), train_loss = 2.15809707, grad/param norm = 3.4060e-01, time/batch = 0.6713s	
1002/33150 (epoch 1.511), train_loss = 2.31165461, grad/param norm = 3.1367e-01, time/batch = 0.6677s	
1003/33150 (epoch 1.513), train_loss = 2.07578042, grad/param norm = 2.7762e-01, time/batch = 0.6698s	
1004/33150 (epoch 1.514), train_loss = 1.72669194, grad/param norm = 2.6207e-01, time/batch = 0.6765s	
1005/33150 (epoch 1.516), train_loss = 2.04853778, grad/param norm = 2.5294e-01, time/batch = 0.6656s	
1006/33150 (epoch 1.517), train_loss = 2.20119190, grad/param norm = 3.0022e-01, time/batch = 0.6659s	
1007/33150 (epoch 1.519), train_loss = 1.95813948, grad/param norm = 2.5528e-01, time/batch = 0.6649s	
1008/33150 (epoch 1.520), train_loss = 2.07653032, grad/param norm = 2.2782e-01, time/batch = 0.6755s	
1009/33150 (epoch 1.522), train_loss = 2.14583253, grad/param norm = 2.8999e-01, time/batch = 0.6755s	
1010/33150 (epoch 1.523), train_loss = 1.96716664, grad/param norm = 2.6848e-01, time/batch = 0.6653s	
1011/33150 (epoch 1.525), train_loss = 1.99877527, grad/param norm = 2.6193e-01, time/batch = 0.6667s	
1012/33150 (epoch 1.526), train_loss = 1.87113600, grad/param norm = 2.5999e-01, time/batch = 0.6705s	
1013/33150 (epoch 1.528), train_loss = 1.97286433, grad/param norm = 2.4162e-01, time/batch = 0.6687s	
1014/33150 (epoch 1.529), train_loss = 2.07203647, grad/param norm = 2.9490e-01, time/batch = 0.6647s	
1015/33150 (epoch 1.531), train_loss = 1.89371300, grad/param norm = 2.6038e-01, time/batch = 0.6648s	
1016/33150 (epoch 1.532), train_loss = 2.06862574, grad/param norm = 3.1212e-01, time/batch = 0.6662s	
1017/33150 (epoch 1.534), train_loss = 1.85656951, grad/param norm = 2.8687e-01, time/batch = 0.6654s	
1018/33150 (epoch 1.535), train_loss = 1.98600901, grad/param norm = 2.7698e-01, time/batch = 0.6676s	
1019/33150 (epoch 1.537), train_loss = 2.18376450, grad/param norm = 3.0591e-01, time/batch = 0.6701s	
1020/33150 (epoch 1.538), train_loss = 2.04742168, grad/param norm = 3.8247e-01, time/batch = 0.6726s	
1021/33150 (epoch 1.540), train_loss = 1.83952423, grad/param norm = 3.2595e-01, time/batch = 0.6667s	
1022/33150 (epoch 1.541), train_loss = 1.99403280, grad/param norm = 2.5644e-01, time/batch = 0.6655s	
1023/33150 (epoch 1.543), train_loss = 2.07890285, grad/param norm = 2.8333e-01, time/batch = 0.6789s	
1024/33150 (epoch 1.544), train_loss = 2.11641100, grad/param norm = 2.5108e-01, time/batch = 0.6777s	
1025/33150 (epoch 1.546), train_loss = 2.29040047, grad/param norm = 3.0851e-01, time/batch = 0.6698s	
1026/33150 (epoch 1.548), train_loss = 2.03801777, grad/param norm = 2.6597e-01, time/batch = 0.6671s	
1027/33150 (epoch 1.549), train_loss = 2.20111695, grad/param norm = 3.0567e-01, time/batch = 0.6650s	
1028/33150 (epoch 1.551), train_loss = 1.92406684, grad/param norm = 2.7707e-01, time/batch = 0.6642s	
1029/33150 (epoch 1.552), train_loss = 1.85075993, grad/param norm = 2.5366e-01, time/batch = 0.6658s	
1030/33150 (epoch 1.554), train_loss = 1.92499194, grad/param norm = 2.5397e-01, time/batch = 0.6666s	
1031/33150 (epoch 1.555), train_loss = 2.12942276, grad/param norm = 2.5401e-01, time/batch = 0.6712s	
1032/33150 (epoch 1.557), train_loss = 1.88754890, grad/param norm = 3.2284e-01, time/batch = 0.6678s	
1033/33150 (epoch 1.558), train_loss = 2.14276010, grad/param norm = 2.9043e-01, time/batch = 0.6708s	
1034/33150 (epoch 1.560), train_loss = 2.13513365, grad/param norm = 2.5545e-01, time/batch = 0.6750s	
1035/33150 (epoch 1.561), train_loss = 1.83866325, grad/param norm = 2.8416e-01, time/batch = 0.6874s	
1036/33150 (epoch 1.563), train_loss = 2.14956352, grad/param norm = 3.0424e-01, time/batch = 0.6863s	
1037/33150 (epoch 1.564), train_loss = 2.16970976, grad/param norm = 3.2123e-01, time/batch = 0.6842s	
1038/33150 (epoch 1.566), train_loss = 2.00699735, grad/param norm = 2.5507e-01, time/batch = 0.6818s	
1039/33150 (epoch 1.567), train_loss = 1.76256230, grad/param norm = 2.6501e-01, time/batch = 0.6864s	
1040/33150 (epoch 1.569), train_loss = 1.93597067, grad/param norm = 2.3197e-01, time/batch = 0.6784s	
1041/33150 (epoch 1.570), train_loss = 1.86844015, grad/param norm = 2.6085e-01, time/batch = 0.6677s	
1042/33150 (epoch 1.572), train_loss = 2.00852639, grad/param norm = 2.8607e-01, time/batch = 0.6712s	
1043/33150 (epoch 1.573), train_loss = 1.64254142, grad/param norm = 2.4056e-01, time/batch = 0.6718s	
1044/33150 (epoch 1.575), train_loss = 2.06470538, grad/param norm = 3.0229e-01, time/batch = 0.6869s	
1045/33150 (epoch 1.576), train_loss = 1.74573703, grad/param norm = 2.4429e-01, time/batch = 0.6735s	
1046/33150 (epoch 1.578), train_loss = 1.99665234, grad/param norm = 2.2410e-01, time/batch = 0.6667s	
1047/33150 (epoch 1.579), train_loss = 1.95473206, grad/param norm = 3.0115e-01, time/batch = 0.6686s	
1048/33150 (epoch 1.581), train_loss = 1.83069626, grad/param norm = 2.8953e-01, time/batch = 0.6705s	
1049/33150 (epoch 1.582), train_loss = 1.87673879, grad/param norm = 2.6548e-01, time/batch = 0.6816s	
1050/33150 (epoch 1.584), train_loss = 2.10225326, grad/param norm = 2.8193e-01, time/batch = 0.6664s	
1051/33150 (epoch 1.585), train_loss = 1.98641478, grad/param norm = 2.4288e-01, time/batch = 0.6712s	
1052/33150 (epoch 1.587), train_loss = 1.97760525, grad/param norm = 2.5139e-01, time/batch = 0.6766s	
1053/33150 (epoch 1.588), train_loss = 1.90130865, grad/param norm = 3.0696e-01, time/batch = 0.6715s	
1054/33150 (epoch 1.590), train_loss = 2.02286316, grad/param norm = 3.2499e-01, time/batch = 0.6684s	
1055/33150 (epoch 1.591), train_loss = 2.06114852, grad/param norm = 2.9217e-01, time/batch = 0.6680s	
1056/33150 (epoch 1.593), train_loss = 1.99871778, grad/param norm = 2.7730e-01, time/batch = 0.6706s	
1057/33150 (epoch 1.594), train_loss = 2.09558639, grad/param norm = 3.5198e-01, time/batch = 0.6689s	
1058/33150 (epoch 1.596), train_loss = 1.75353621, grad/param norm = 2.9799e-01, time/batch = 0.6687s	
1059/33150 (epoch 1.597), train_loss = 1.95372036, grad/param norm = 3.0943e-01, time/batch = 0.6815s	
1060/33150 (epoch 1.599), train_loss = 2.07594595, grad/param norm = 3.1526e-01, time/batch = 0.6852s	
1061/33150 (epoch 1.600), train_loss = 2.03018724, grad/param norm = 3.0219e-01, time/batch = 0.6898s	
1062/33150 (epoch 1.602), train_loss = 1.94378245, grad/param norm = 2.9351e-01, time/batch = 0.6877s	
1063/33150 (epoch 1.603), train_loss = 1.82438460, grad/param norm = 2.5339e-01, time/batch = 0.6815s	
1064/33150 (epoch 1.605), train_loss = 1.92912605, grad/param norm = 2.5832e-01, time/batch = 0.6750s	
1065/33150 (epoch 1.606), train_loss = 1.99011471, grad/param norm = 2.7013e-01, time/batch = 0.6676s	
1066/33150 (epoch 1.608), train_loss = 2.04839448, grad/param norm = 2.9002e-01, time/batch = 0.6626s	
1067/33150 (epoch 1.609), train_loss = 1.97793330, grad/param norm = 3.0348e-01, time/batch = 0.6931s	
1068/33150 (epoch 1.611), train_loss = 1.83897890, grad/param norm = 3.1310e-01, time/batch = 0.6686s	
1069/33150 (epoch 1.612), train_loss = 2.01197029, grad/param norm = 2.9859e-01, time/batch = 0.6865s	
1070/33150 (epoch 1.614), train_loss = 1.73889148, grad/param norm = 2.6248e-01, time/batch = 0.6696s	
1071/33150 (epoch 1.615), train_loss = 1.86163454, grad/param norm = 2.7687e-01, time/batch = 0.6712s	
1072/33150 (epoch 1.617), train_loss = 1.92697650, grad/param norm = 3.0645e-01, time/batch = 0.6758s	
1073/33150 (epoch 1.618), train_loss = 1.82080347, grad/param norm = 2.6548e-01, time/batch = 0.6710s	
1074/33150 (epoch 1.620), train_loss = 1.83407651, grad/param norm = 3.0008e-01, time/batch = 0.6692s	
1075/33150 (epoch 1.621), train_loss = 1.86320582, grad/param norm = 2.8032e-01, time/batch = 0.6707s	
1076/33150 (epoch 1.623), train_loss = 1.96075056, grad/param norm = 3.0838e-01, time/batch = 0.6712s	
1077/33150 (epoch 1.624), train_loss = 2.00874381, grad/param norm = 3.3343e-01, time/batch = 0.6698s	
1078/33150 (epoch 1.626), train_loss = 1.69444615, grad/param norm = 3.2049e-01, time/batch = 0.6798s	
1079/33150 (epoch 1.627), train_loss = 1.79977636, grad/param norm = 3.2111e-01, time/batch = 0.6748s	
1080/33150 (epoch 1.629), train_loss = 1.81205608, grad/param norm = 3.1432e-01, time/batch = 0.6718s	
1081/33150 (epoch 1.630), train_loss = 1.82516517, grad/param norm = 2.6968e-01, time/batch = 0.6728s	
1082/33150 (epoch 1.632), train_loss = 1.72602347, grad/param norm = 2.7760e-01, time/batch = 0.6757s	
1083/33150 (epoch 1.633), train_loss = 1.72308793, grad/param norm = 2.7740e-01, time/batch = 0.6734s	
1084/33150 (epoch 1.635), train_loss = 2.04969661, grad/param norm = 2.4416e-01, time/batch = 0.6686s	
1085/33150 (epoch 1.637), train_loss = 1.77830293, grad/param norm = 2.9719e-01, time/batch = 0.6658s	
1086/33150 (epoch 1.638), train_loss = 1.85483345, grad/param norm = 2.8143e-01, time/batch = 0.6691s	
1087/33150 (epoch 1.640), train_loss = 2.07666362, grad/param norm = 3.6273e-01, time/batch = 0.6670s	
1088/33150 (epoch 1.641), train_loss = 1.84538926, grad/param norm = 2.9683e-01, time/batch = 0.6674s	
1089/33150 (epoch 1.643), train_loss = 1.77798354, grad/param norm = 2.5726e-01, time/batch = 0.6675s	
1090/33150 (epoch 1.644), train_loss = 2.04728875, grad/param norm = 2.5729e-01, time/batch = 0.6654s	
1091/33150 (epoch 1.646), train_loss = 1.88695246, grad/param norm = 2.6015e-01, time/batch = 0.6669s	
1092/33150 (epoch 1.647), train_loss = 2.32904646, grad/param norm = 3.0026e-01, time/batch = 0.6631s	
1093/33150 (epoch 1.649), train_loss = 2.01750235, grad/param norm = 2.8218e-01, time/batch = 0.6643s	
1094/33150 (epoch 1.650), train_loss = 1.83707353, grad/param norm = 3.0507e-01, time/batch = 0.6671s	
1095/33150 (epoch 1.652), train_loss = 1.95492485, grad/param norm = 2.7300e-01, time/batch = 0.6681s	
1096/33150 (epoch 1.653), train_loss = 1.92473587, grad/param norm = 2.5334e-01, time/batch = 0.6637s	
1097/33150 (epoch 1.655), train_loss = 1.90435073, grad/param norm = 2.5516e-01, time/batch = 0.6786s	
1098/33150 (epoch 1.656), train_loss = 1.81766599, grad/param norm = 2.4194e-01, time/batch = 0.6756s	
1099/33150 (epoch 1.658), train_loss = 1.93714492, grad/param norm = 2.8700e-01, time/batch = 0.6771s	
1100/33150 (epoch 1.659), train_loss = 2.64503707, grad/param norm = 5.4648e-01, time/batch = 0.6741s	
1101/33150 (epoch 1.661), train_loss = 1.98325534, grad/param norm = 4.2156e-01, time/batch = 0.6704s	
1102/33150 (epoch 1.662), train_loss = 1.96122894, grad/param norm = 2.9976e-01, time/batch = 0.6702s	
1103/33150 (epoch 1.664), train_loss = 1.95753868, grad/param norm = 2.7167e-01, time/batch = 0.6688s	
1104/33150 (epoch 1.665), train_loss = 1.94024419, grad/param norm = 2.8451e-01, time/batch = 0.6655s	
1105/33150 (epoch 1.667), train_loss = 2.19462479, grad/param norm = 2.4526e-01, time/batch = 0.6632s	
1106/33150 (epoch 1.668), train_loss = 1.98052854, grad/param norm = 2.6204e-01, time/batch = 0.6670s	
1107/33150 (epoch 1.670), train_loss = 1.83826217, grad/param norm = 2.2197e-01, time/batch = 0.6673s	
1108/33150 (epoch 1.671), train_loss = 1.91674803, grad/param norm = 2.7736e-01, time/batch = 0.6648s	
1109/33150 (epoch 1.673), train_loss = 2.05369861, grad/param norm = 2.4117e-01, time/batch = 0.6645s	
1110/33150 (epoch 1.674), train_loss = 1.91223462, grad/param norm = 2.3261e-01, time/batch = 0.6649s	
1111/33150 (epoch 1.676), train_loss = 1.83812507, grad/param norm = 2.4471e-01, time/batch = 0.6680s	
1112/33150 (epoch 1.677), train_loss = 2.19395333, grad/param norm = 3.0169e-01, time/batch = 0.6805s	
1113/33150 (epoch 1.679), train_loss = 1.69633999, grad/param norm = 2.2469e-01, time/batch = 0.6716s	
1114/33150 (epoch 1.680), train_loss = 1.99567194, grad/param norm = 2.4267e-01, time/batch = 0.6683s	
1115/33150 (epoch 1.682), train_loss = 1.80997497, grad/param norm = 2.7028e-01, time/batch = 0.6660s	
1116/33150 (epoch 1.683), train_loss = 1.81960216, grad/param norm = 2.6446e-01, time/batch = 0.6683s	
1117/33150 (epoch 1.685), train_loss = 1.99739976, grad/param norm = 2.6447e-01, time/batch = 0.6669s	
1118/33150 (epoch 1.686), train_loss = 1.86280857, grad/param norm = 2.8732e-01, time/batch = 0.6758s	
1119/33150 (epoch 1.688), train_loss = 1.95783307, grad/param norm = 3.4368e-01, time/batch = 0.6746s	
1120/33150 (epoch 1.689), train_loss = 1.90049331, grad/param norm = 3.5016e-01, time/batch = 0.6688s	
1121/33150 (epoch 1.691), train_loss = 1.64391478, grad/param norm = 2.8050e-01, time/batch = 0.6700s	
1122/33150 (epoch 1.692), train_loss = 1.89882512, grad/param norm = 3.2266e-01, time/batch = 0.6671s	
1123/33150 (epoch 1.694), train_loss = 1.73641615, grad/param norm = 2.4975e-01, time/batch = 0.6672s	
1124/33150 (epoch 1.695), train_loss = 1.86835005, grad/param norm = 2.4968e-01, time/batch = 0.6674s	
1125/33150 (epoch 1.697), train_loss = 1.72083563, grad/param norm = 2.3896e-01, time/batch = 0.6683s	
1126/33150 (epoch 1.698), train_loss = 2.07491644, grad/param norm = 2.4504e-01, time/batch = 0.6818s	
1127/33150 (epoch 1.700), train_loss = 1.60059854, grad/param norm = 2.7687e-01, time/batch = 0.6865s	
1128/33150 (epoch 1.701), train_loss = 1.85397577, grad/param norm = 3.4070e-01, time/batch = 0.6888s	
1129/33150 (epoch 1.703), train_loss = 2.01577718, grad/param norm = 3.4360e-01, time/batch = 0.6739s	
1130/33150 (epoch 1.704), train_loss = 1.78895372, grad/param norm = 3.0161e-01, time/batch = 0.6700s	
1131/33150 (epoch 1.706), train_loss = 1.88993978, grad/param norm = 2.5743e-01, time/batch = 0.6773s	
1132/33150 (epoch 1.707), train_loss = 1.88891689, grad/param norm = 2.6755e-01, time/batch = 0.6764s	
1133/33150 (epoch 1.709), train_loss = 1.81422456, grad/param norm = 2.4002e-01, time/batch = 0.6714s	
1134/33150 (epoch 1.710), train_loss = 2.09106671, grad/param norm = 2.9668e-01, time/batch = 0.6712s	
1135/33150 (epoch 1.712), train_loss = 2.07974604, grad/param norm = 3.0346e-01, time/batch = 0.6696s	
1136/33150 (epoch 1.713), train_loss = 1.85191766, grad/param norm = 2.6666e-01, time/batch = 0.6710s	
1137/33150 (epoch 1.715), train_loss = 1.83841897, grad/param norm = 2.6442e-01, time/batch = 0.6706s	
1138/33150 (epoch 1.716), train_loss = 1.91779945, grad/param norm = 2.5445e-01, time/batch = 0.6665s	
1139/33150 (epoch 1.718), train_loss = 1.96377916, grad/param norm = 2.2489e-01, time/batch = 0.6666s	
1140/33150 (epoch 1.719), train_loss = 2.03456904, grad/param norm = 2.7134e-01, time/batch = 0.6692s	
1141/33150 (epoch 1.721), train_loss = 2.01916993, grad/param norm = 3.2581e-01, time/batch = 0.6882s	
1142/33150 (epoch 1.722), train_loss = 1.82375386, grad/param norm = 2.4829e-01, time/batch = 0.6766s	
1143/33150 (epoch 1.724), train_loss = 1.95827995, grad/param norm = 2.7101e-01, time/batch = 0.6666s	
1144/33150 (epoch 1.725), train_loss = 2.08855957, grad/param norm = 2.6737e-01, time/batch = 0.6760s	
1145/33150 (epoch 1.727), train_loss = 2.00400006, grad/param norm = 2.3493e-01, time/batch = 0.6656s	
1146/33150 (epoch 1.729), train_loss = 1.94568465, grad/param norm = 2.3422e-01, time/batch = 0.6723s	
1147/33150 (epoch 1.730), train_loss = 1.84077925, grad/param norm = 2.4842e-01, time/batch = 0.6765s	
1148/33150 (epoch 1.732), train_loss = 1.96754981, grad/param norm = 2.2699e-01, time/batch = 0.6710s	
1149/33150 (epoch 1.733), train_loss = 1.73405410, grad/param norm = 2.5420e-01, time/batch = 0.6686s	
1150/33150 (epoch 1.735), train_loss = 1.88922413, grad/param norm = 2.5757e-01, time/batch = 0.6751s	
1151/33150 (epoch 1.736), train_loss = 1.66176102, grad/param norm = 2.4573e-01, time/batch = 0.6670s	
1152/33150 (epoch 1.738), train_loss = 2.00773300, grad/param norm = 3.0565e-01, time/batch = 0.6620s	
1153/33150 (epoch 1.739), train_loss = 2.22374886, grad/param norm = 3.0149e-01, time/batch = 0.6653s	
1154/33150 (epoch 1.741), train_loss = 1.96477376, grad/param norm = 2.6957e-01, time/batch = 0.6668s	
1155/33150 (epoch 1.742), train_loss = 1.93616402, grad/param norm = 2.9805e-01, time/batch = 0.6645s	
1156/33150 (epoch 1.744), train_loss = 2.03118875, grad/param norm = 2.6802e-01, time/batch = 0.6708s	
1157/33150 (epoch 1.745), train_loss = 1.97322608, grad/param norm = 2.6467e-01, time/batch = 0.6682s	
1158/33150 (epoch 1.747), train_loss = 1.74076002, grad/param norm = 2.2579e-01, time/batch = 0.6695s	
1159/33150 (epoch 1.748), train_loss = 1.86110719, grad/param norm = 2.7458e-01, time/batch = 0.6671s	
1160/33150 (epoch 1.750), train_loss = 1.90698865, grad/param norm = 2.5429e-01, time/batch = 0.6682s	
1161/33150 (epoch 1.751), train_loss = 1.86391601, grad/param norm = 2.5190e-01, time/batch = 0.6808s	
1162/33150 (epoch 1.753), train_loss = 1.67736319, grad/param norm = 2.8166e-01, time/batch = 0.6730s	
1163/33150 (epoch 1.754), train_loss = 2.09214732, grad/param norm = 2.8697e-01, time/batch = 0.6689s	
1164/33150 (epoch 1.756), train_loss = 1.90888146, grad/param norm = 2.5218e-01, time/batch = 0.6657s	
1165/33150 (epoch 1.757), train_loss = 2.00655376, grad/param norm = 2.6222e-01, time/batch = 0.6692s	
1166/33150 (epoch 1.759), train_loss = 2.08139266, grad/param norm = 2.8008e-01, time/batch = 0.6698s	
1167/33150 (epoch 1.760), train_loss = 1.95165748, grad/param norm = 2.9951e-01, time/batch = 0.6656s	
1168/33150 (epoch 1.762), train_loss = 2.06197660, grad/param norm = 2.6541e-01, time/batch = 0.6688s	
1169/33150 (epoch 1.763), train_loss = 1.76897211, grad/param norm = 2.4170e-01, time/batch = 0.6690s	
1170/33150 (epoch 1.765), train_loss = 1.84917901, grad/param norm = 2.2312e-01, time/batch = 0.6665s	
1171/33150 (epoch 1.766), train_loss = 1.87937364, grad/param norm = 2.4994e-01, time/batch = 0.6696s	
1172/33150 (epoch 1.768), train_loss = 1.79546932, grad/param norm = 2.4927e-01, time/batch = 0.6675s	
1173/33150 (epoch 1.769), train_loss = 1.89632319, grad/param norm = 2.8103e-01, time/batch = 0.6625s	
1174/33150 (epoch 1.771), train_loss = 1.93067862, grad/param norm = 2.7990e-01, time/batch = 0.6618s	
1175/33150 (epoch 1.772), train_loss = 1.95330511, grad/param norm = 2.9061e-01, time/batch = 0.6679s	
1176/33150 (epoch 1.774), train_loss = 2.02761533, grad/param norm = 2.6127e-01, time/batch = 0.6801s	
1177/33150 (epoch 1.775), train_loss = 1.91931527, grad/param norm = 2.6212e-01, time/batch = 0.6737s	
1178/33150 (epoch 1.777), train_loss = 2.00579145, grad/param norm = 2.7562e-01, time/batch = 0.6632s	
1179/33150 (epoch 1.778), train_loss = 1.94139912, grad/param norm = 2.5706e-01, time/batch = 0.6624s	
1180/33150 (epoch 1.780), train_loss = 1.75910036, grad/param norm = 2.6036e-01, time/batch = 0.6654s	
1181/33150 (epoch 1.781), train_loss = 1.89688820, grad/param norm = 2.4693e-01, time/batch = 0.6672s	
1182/33150 (epoch 1.783), train_loss = 1.83538627, grad/param norm = 2.2719e-01, time/batch = 0.6644s	
1183/33150 (epoch 1.784), train_loss = 1.80781968, grad/param norm = 2.3784e-01, time/batch = 0.6627s	
1184/33150 (epoch 1.786), train_loss = 1.96431160, grad/param norm = 2.6938e-01, time/batch = 0.6621s	
1185/33150 (epoch 1.787), train_loss = 1.90095434, grad/param norm = 2.5144e-01, time/batch = 0.6639s	
1186/33150 (epoch 1.789), train_loss = 1.79512073, grad/param norm = 2.3663e-01, time/batch = 0.6666s	
1187/33150 (epoch 1.790), train_loss = 1.63522326, grad/param norm = 2.5387e-01, time/batch = 0.6653s	
1188/33150 (epoch 1.792), train_loss = 1.98571771, grad/param norm = 2.7526e-01, time/batch = 0.6623s	
1189/33150 (epoch 1.793), train_loss = 1.88498555, grad/param norm = 2.4923e-01, time/batch = 0.6622s	
1190/33150 (epoch 1.795), train_loss = 1.87658821, grad/param norm = 2.8722e-01, time/batch = 0.6662s	
1191/33150 (epoch 1.796), train_loss = 1.76424335, grad/param norm = 2.3077e-01, time/batch = 0.6808s	
1192/33150 (epoch 1.798), train_loss = 1.87083433, grad/param norm = 2.3448e-01, time/batch = 0.6703s	
1193/33150 (epoch 1.799), train_loss = 1.81881786, grad/param norm = 2.8758e-01, time/batch = 0.6674s	
1194/33150 (epoch 1.801), train_loss = 1.78487401, grad/param norm = 2.4994e-01, time/batch = 0.6656s	
1195/33150 (epoch 1.802), train_loss = 1.88269676, grad/param norm = 2.7494e-01, time/batch = 0.6692s	
1196/33150 (epoch 1.804), train_loss = 1.90339543, grad/param norm = 2.4901e-01, time/batch = 0.6704s	
1197/33150 (epoch 1.805), train_loss = 1.94212399, grad/param norm = 3.4352e-01, time/batch = 0.6669s	
1198/33150 (epoch 1.807), train_loss = 1.80349015, grad/param norm = 3.6592e-01, time/batch = 0.6681s	
1199/33150 (epoch 1.808), train_loss = 1.91577354, grad/param norm = 2.5790e-01, time/batch = 0.6718s	
1200/33150 (epoch 1.810), train_loss = 1.83704301, grad/param norm = 2.5968e-01, time/batch = 0.6704s	
1201/33150 (epoch 1.811), train_loss = 1.89529064, grad/param norm = 2.4311e-01, time/batch = 0.6731s	
1202/33150 (epoch 1.813), train_loss = 1.94294973, grad/param norm = 2.3882e-01, time/batch = 0.6703s	
1203/33150 (epoch 1.814), train_loss = 1.94809311, grad/param norm = 2.7312e-01, time/batch = 0.6691s	
1204/33150 (epoch 1.816), train_loss = 1.99750641, grad/param norm = 2.6750e-01, time/batch = 0.6692s	
1205/33150 (epoch 1.817), train_loss = 1.97455673, grad/param norm = 2.8123e-01, time/batch = 0.6668s	
1206/33150 (epoch 1.819), train_loss = 1.80610857, grad/param norm = 2.7077e-01, time/batch = 0.6651s	
1207/33150 (epoch 1.821), train_loss = 1.62419067, grad/param norm = 2.3138e-01, time/batch = 0.6663s	
1208/33150 (epoch 1.822), train_loss = 1.84952867, grad/param norm = 2.6954e-01, time/batch = 0.6671s	
1209/33150 (epoch 1.824), train_loss = 1.86795488, grad/param norm = 2.6483e-01, time/batch = 0.6678s	
1210/33150 (epoch 1.825), train_loss = 1.90026934, grad/param norm = 2.4480e-01, time/batch = 0.6782s	
1211/33150 (epoch 1.827), train_loss = 1.96056960, grad/param norm = 2.7135e-01, time/batch = 0.6758s	
1212/33150 (epoch 1.828), train_loss = 1.79282013, grad/param norm = 2.5971e-01, time/batch = 0.6668s	
1213/33150 (epoch 1.830), train_loss = 1.91033931, grad/param norm = 2.6010e-01, time/batch = 0.6647s	
1214/33150 (epoch 1.831), train_loss = 1.74887940, grad/param norm = 2.4465e-01, time/batch = 0.6635s	
1215/33150 (epoch 1.833), train_loss = 1.79146224, grad/param norm = 2.6298e-01, time/batch = 0.6762s	
1216/33150 (epoch 1.834), train_loss = 1.98349078, grad/param norm = 2.5936e-01, time/batch = 0.6852s	
1217/33150 (epoch 1.836), train_loss = 1.99941409, grad/param norm = 3.0654e-01, time/batch = 0.6802s	
1218/33150 (epoch 1.837), train_loss = 1.84874199, grad/param norm = 3.1026e-01, time/batch = 0.6803s	
1219/33150 (epoch 1.839), train_loss = 2.06019650, grad/param norm = 2.8096e-01, time/batch = 0.6625s	
1220/33150 (epoch 1.840), train_loss = 1.88838849, grad/param norm = 3.1220e-01, time/batch = 0.6654s	
1221/33150 (epoch 1.842), train_loss = 1.96737274, grad/param norm = 3.4866e-01, time/batch = 0.6698s	
1222/33150 (epoch 1.843), train_loss = 1.94174386, grad/param norm = 3.6647e-01, time/batch = 0.6660s	
1223/33150 (epoch 1.845), train_loss = 1.82384636, grad/param norm = 2.5426e-01, time/batch = 0.6632s	
1224/33150 (epoch 1.846), train_loss = 2.23299267, grad/param norm = 3.1639e-01, time/batch = 0.6649s	
1225/33150 (epoch 1.848), train_loss = 2.00682895, grad/param norm = 2.6941e-01, time/batch = 0.6814s	
1226/33150 (epoch 1.849), train_loss = 1.88327076, grad/param norm = 2.4204e-01, time/batch = 0.6722s	
1227/33150 (epoch 1.851), train_loss = 2.01895045, grad/param norm = 3.2568e-01, time/batch = 0.6747s	
1228/33150 (epoch 1.852), train_loss = 2.00342968, grad/param norm = 3.2838e-01, time/batch = 0.6681s	
1229/33150 (epoch 1.854), train_loss = 1.96767531, grad/param norm = 2.5962e-01, time/batch = 0.6636s	
1230/33150 (epoch 1.855), train_loss = 1.61879787, grad/param norm = 2.4508e-01, time/batch = 0.6671s	
1231/33150 (epoch 1.857), train_loss = 1.83450305, grad/param norm = 2.2993e-01, time/batch = 0.6782s	
1232/33150 (epoch 1.858), train_loss = 1.77831459, grad/param norm = 2.6741e-01, time/batch = 0.6899s	
1233/33150 (epoch 1.860), train_loss = 1.91886486, grad/param norm = 2.6739e-01, time/batch = 0.6868s	
1234/33150 (epoch 1.861), train_loss = 1.84625144, grad/param norm = 2.6546e-01, time/batch = 0.6674s	
1235/33150 (epoch 1.863), train_loss = 1.93651442, grad/param norm = 2.4407e-01, time/batch = 0.6662s	
1236/33150 (epoch 1.864), train_loss = 2.07339117, grad/param norm = 2.5666e-01, time/batch = 0.6653s	
1237/33150 (epoch 1.866), train_loss = 1.80451739, grad/param norm = 2.4492e-01, time/batch = 0.6693s	
1238/33150 (epoch 1.867), train_loss = 2.01661424, grad/param norm = 2.4613e-01, time/batch = 0.6663s	
1239/33150 (epoch 1.869), train_loss = 2.01063112, grad/param norm = 2.4129e-01, time/batch = 0.6680s	
1240/33150 (epoch 1.870), train_loss = 1.96413082, grad/param norm = 2.7697e-01, time/batch = 0.6668s	
1241/33150 (epoch 1.872), train_loss = 2.02754638, grad/param norm = 3.6413e-01, time/batch = 0.6700s	
1242/33150 (epoch 1.873), train_loss = 1.66396696, grad/param norm = 2.4862e-01, time/batch = 0.6689s	
1243/33150 (epoch 1.875), train_loss = 2.11490296, grad/param norm = 3.3384e-01, time/batch = 0.6794s	
1244/33150 (epoch 1.876), train_loss = 1.94460025, grad/param norm = 3.5360e-01, time/batch = 0.6859s	
1245/33150 (epoch 1.878), train_loss = 1.77978587, grad/param norm = 2.6978e-01, time/batch = 0.7003s	
1246/33150 (epoch 1.879), train_loss = 1.86804080, grad/param norm = 2.4680e-01, time/batch = 0.6848s	
1247/33150 (epoch 1.881), train_loss = 1.93132108, grad/param norm = 2.5662e-01, time/batch = 0.6733s	
1248/33150 (epoch 1.882), train_loss = 1.87315296, grad/param norm = 2.2655e-01, time/batch = 0.6630s	
1249/33150 (epoch 1.884), train_loss = 1.97930078, grad/param norm = 2.6737e-01, time/batch = 0.6601s	
1250/33150 (epoch 1.885), train_loss = 1.68751217, grad/param norm = 2.7524e-01, time/batch = 0.6662s	
1251/33150 (epoch 1.887), train_loss = 2.06094959, grad/param norm = 3.4577e-01, time/batch = 0.6631s	
1252/33150 (epoch 1.888), train_loss = 1.94935277, grad/param norm = 2.8206e-01, time/batch = 0.6638s	
1253/33150 (epoch 1.890), train_loss = 1.79060319, grad/param norm = 2.3606e-01, time/batch = 0.6652s	
1254/33150 (epoch 1.891), train_loss = 1.89375844, grad/param norm = 2.4020e-01, time/batch = 0.6743s	
1255/33150 (epoch 1.893), train_loss = 2.01655509, grad/param norm = 2.5592e-01, time/batch = 0.6845s	
1256/33150 (epoch 1.894), train_loss = 2.00849980, grad/param norm = 2.9676e-01, time/batch = 0.6610s	
1257/33150 (epoch 1.896), train_loss = 1.92221094, grad/param norm = 3.3782e-01, time/batch = 0.6627s	
1258/33150 (epoch 1.897), train_loss = 1.90645895, grad/param norm = 2.7262e-01, time/batch = 0.6637s	
1259/33150 (epoch 1.899), train_loss = 1.80456668, grad/param norm = 2.6390e-01, time/batch = 0.6639s	
1260/33150 (epoch 1.900), train_loss = 2.05545448, grad/param norm = 2.6741e-01, time/batch = 0.6672s	
1261/33150 (epoch 1.902), train_loss = 2.12827841, grad/param norm = 3.1780e-01, time/batch = 0.6667s	
1262/33150 (epoch 1.903), train_loss = 1.83848449, grad/param norm = 2.9920e-01, time/batch = 0.6659s	
1263/33150 (epoch 1.905), train_loss = 1.85730228, grad/param norm = 2.6499e-01, time/batch = 0.6613s	
1264/33150 (epoch 1.906), train_loss = 1.77268831, grad/param norm = 2.4147e-01, time/batch = 0.6631s	
1265/33150 (epoch 1.908), train_loss = 2.03476092, grad/param norm = 2.4371e-01, time/batch = 0.6663s	
1266/33150 (epoch 1.910), train_loss = 1.93492617, grad/param norm = 2.6681e-01, time/batch = 0.6614s	
1267/33150 (epoch 1.911), train_loss = 1.84666666, grad/param norm = 2.5504e-01, time/batch = 0.6616s	
1268/33150 (epoch 1.913), train_loss = 1.76062744, grad/param norm = 2.5086e-01, time/batch = 0.6643s	
1269/33150 (epoch 1.914), train_loss = 2.06205507, grad/param norm = 2.4068e-01, time/batch = 0.6634s	
1270/33150 (epoch 1.916), train_loss = 1.75869334, grad/param norm = 2.5440e-01, time/batch = 0.6648s	
1271/33150 (epoch 1.917), train_loss = 2.06072609, grad/param norm = 2.9732e-01, time/batch = 0.6655s	
1272/33150 (epoch 1.919), train_loss = 2.02906052, grad/param norm = 2.8510e-01, time/batch = 0.6658s	
1273/33150 (epoch 1.920), train_loss = 1.90296807, grad/param norm = 2.3124e-01, time/batch = 0.6676s	
1274/33150 (epoch 1.922), train_loss = 2.13388957, grad/param norm = 2.3698e-01, time/batch = 0.6800s	
1275/33150 (epoch 1.923), train_loss = 1.82169614, grad/param norm = 2.7283e-01, time/batch = 0.6840s	
1276/33150 (epoch 1.925), train_loss = 1.90171621, grad/param norm = 2.9210e-01, time/batch = 0.6730s	
1277/33150 (epoch 1.926), train_loss = 1.87544427, grad/param norm = 2.6414e-01, time/batch = 0.6652s	
1278/33150 (epoch 1.928), train_loss = 1.83755723, grad/param norm = 2.4677e-01, time/batch = 0.6646s	
1279/33150 (epoch 1.929), train_loss = 1.99866089, grad/param norm = 2.5286e-01, time/batch = 0.6654s	
1280/33150 (epoch 1.931), train_loss = 2.02274119, grad/param norm = 2.6486e-01, time/batch = 0.6617s	
1281/33150 (epoch 1.932), train_loss = 1.92114481, grad/param norm = 2.7350e-01, time/batch = 0.6643s	
1282/33150 (epoch 1.934), train_loss = 1.86373129, grad/param norm = 2.9471e-01, time/batch = 0.6653s	
1283/33150 (epoch 1.935), train_loss = 1.93806723, grad/param norm = 2.5441e-01, time/batch = 0.6654s	
1284/33150 (epoch 1.937), train_loss = 2.02118859, grad/param norm = 2.5024e-01, time/batch = 0.6654s	
1285/33150 (epoch 1.938), train_loss = 1.91767331, grad/param norm = 2.3341e-01, time/batch = 0.6648s	
1286/33150 (epoch 1.940), train_loss = 2.16893837, grad/param norm = 2.4300e-01, time/batch = 0.6644s	
1287/33150 (epoch 1.941), train_loss = 1.80581096, grad/param norm = 2.2088e-01, time/batch = 0.6658s	
1288/33150 (epoch 1.943), train_loss = 1.91463498, grad/param norm = 2.7212e-01, time/batch = 0.6661s	
1289/33150 (epoch 1.944), train_loss = 1.98087012, grad/param norm = 2.3989e-01, time/batch = 0.6796s	
1290/33150 (epoch 1.946), train_loss = 1.75995154, grad/param norm = 2.6551e-01, time/batch = 0.6768s	
1291/33150 (epoch 1.947), train_loss = 1.91208516, grad/param norm = 2.3797e-01, time/batch = 0.6722s	
1292/33150 (epoch 1.949), train_loss = 2.10359937, grad/param norm = 3.9177e-01, time/batch = 0.6752s	
1293/33150 (epoch 1.950), train_loss = 2.00767310, grad/param norm = 3.3368e-01, time/batch = 0.6817s	
1294/33150 (epoch 1.952), train_loss = 1.86933276, grad/param norm = 2.9857e-01, time/batch = 0.6764s	
1295/33150 (epoch 1.953), train_loss = 1.74946337, grad/param norm = 2.6802e-01, time/batch = 0.6758s	
1296/33150 (epoch 1.955), train_loss = 1.81775488, grad/param norm = 2.8185e-01, time/batch = 0.6797s	
1297/33150 (epoch 1.956), train_loss = 1.97944235, grad/param norm = 2.6991e-01, time/batch = 0.6788s	
1298/33150 (epoch 1.958), train_loss = 1.73074380, grad/param norm = 2.5222e-01, time/batch = 0.6748s	
1299/33150 (epoch 1.959), train_loss = 1.71302963, grad/param norm = 2.4920e-01, time/batch = 0.6742s	
1300/33150 (epoch 1.961), train_loss = 1.86325164, grad/param norm = 2.4919e-01, time/batch = 0.6765s	
1301/33150 (epoch 1.962), train_loss = 1.66954698, grad/param norm = 2.4164e-01, time/batch = 0.6757s	
1302/33150 (epoch 1.964), train_loss = 1.85262838, grad/param norm = 2.3839e-01, time/batch = 0.6706s	
1303/33150 (epoch 1.965), train_loss = 1.91074939, grad/param norm = 2.4405e-01, time/batch = 0.6730s	
1304/33150 (epoch 1.967), train_loss = 1.98887688, grad/param norm = 2.9044e-01, time/batch = 0.6831s	
1305/33150 (epoch 1.968), train_loss = 1.75104788, grad/param norm = 3.0301e-01, time/batch = 0.6887s	
1306/33150 (epoch 1.970), train_loss = 1.79042122, grad/param norm = 2.4749e-01, time/batch = 0.7023s	
1307/33150 (epoch 1.971), train_loss = 1.97436001, grad/param norm = 3.0120e-01, time/batch = 0.6655s	
1308/33150 (epoch 1.973), train_loss = 1.87869993, grad/param norm = 2.4763e-01, time/batch = 0.6736s	
1309/33150 (epoch 1.974), train_loss = 2.03393372, grad/param norm = 2.6171e-01, time/batch = 0.6694s	
1310/33150 (epoch 1.976), train_loss = 1.91333249, grad/param norm = 2.4883e-01, time/batch = 0.6825s	
1311/33150 (epoch 1.977), train_loss = 1.96770644, grad/param norm = 2.5165e-01, time/batch = 0.6887s	
1312/33150 (epoch 1.979), train_loss = 1.99730956, grad/param norm = 2.8904e-01, time/batch = 0.6663s	
1313/33150 (epoch 1.980), train_loss = 1.98858292, grad/param norm = 2.7861e-01, time/batch = 0.6720s	
1314/33150 (epoch 1.982), train_loss = 1.84606391, grad/param norm = 2.5767e-01, time/batch = 0.6666s	
1315/33150 (epoch 1.983), train_loss = 1.89364475, grad/param norm = 3.0026e-01, time/batch = 0.6796s	
1316/33150 (epoch 1.985), train_loss = 1.94434414, grad/param norm = 3.3473e-01, time/batch = 0.6826s	
1317/33150 (epoch 1.986), train_loss = 1.80843954, grad/param norm = 2.3884e-01, time/batch = 0.6724s	
1318/33150 (epoch 1.988), train_loss = 1.90482319, grad/param norm = 2.3688e-01, time/batch = 0.6719s	
1319/33150 (epoch 1.989), train_loss = 1.78876250, grad/param norm = 2.2150e-01, time/batch = 0.6690s	
1320/33150 (epoch 1.991), train_loss = 1.95169777, grad/param norm = 2.8169e-01, time/batch = 0.6701s	
1321/33150 (epoch 1.992), train_loss = 1.69597041, grad/param norm = 3.0819e-01, time/batch = 0.6695s	
1322/33150 (epoch 1.994), train_loss = 1.76851453, grad/param norm = 2.3821e-01, time/batch = 0.6661s	
1323/33150 (epoch 1.995), train_loss = 1.77083176, grad/param norm = 2.4861e-01, time/batch = 0.6704s	
1324/33150 (epoch 1.997), train_loss = 1.95773204, grad/param norm = 2.2970e-01, time/batch = 0.6676s	
1325/33150 (epoch 1.998), train_loss = 1.59582358, grad/param norm = 2.3740e-01, time/batch = 0.6848s	
1326/33150 (epoch 2.000), train_loss = 1.90022089, grad/param norm = 3.1133e-01, time/batch = 0.6740s	
1327/33150 (epoch 2.002), train_loss = 1.96265720, grad/param norm = 2.8678e-01, time/batch = 0.6692s	
1328/33150 (epoch 2.003), train_loss = 1.81336971, grad/param norm = 2.4943e-01, time/batch = 0.6686s	
1329/33150 (epoch 2.005), train_loss = 1.68882752, grad/param norm = 2.3330e-01, time/batch = 0.6684s	
1330/33150 (epoch 2.006), train_loss = 1.57856471, grad/param norm = 2.3235e-01, time/batch = 0.6916s	
1331/33150 (epoch 2.008), train_loss = 1.85856056, grad/param norm = 2.4970e-01, time/batch = 0.6926s	
1332/33150 (epoch 2.009), train_loss = 1.87276918, grad/param norm = 2.6166e-01, time/batch = 0.6790s	
1333/33150 (epoch 2.011), train_loss = 2.12330139, grad/param norm = 2.6395e-01, time/batch = 0.6807s	
1334/33150 (epoch 2.012), train_loss = 1.81123299, grad/param norm = 2.5553e-01, time/batch = 0.6782s	
1335/33150 (epoch 2.014), train_loss = 1.89227035, grad/param norm = 2.4159e-01, time/batch = 0.6754s	
1336/33150 (epoch 2.015), train_loss = 1.80660810, grad/param norm = 2.4134e-01, time/batch = 0.6646s	
1337/33150 (epoch 2.017), train_loss = 1.76872499, grad/param norm = 2.4202e-01, time/batch = 0.6629s	
1338/33150 (epoch 2.018), train_loss = 1.99091748, grad/param norm = 3.1926e-01, time/batch = 0.6639s	
1339/33150 (epoch 2.020), train_loss = 1.97099304, grad/param norm = 3.0036e-01, time/batch = 0.6681s	
1340/33150 (epoch 2.021), train_loss = 1.69438409, grad/param norm = 2.5324e-01, time/batch = 0.6630s	
1341/33150 (epoch 2.023), train_loss = 1.99767596, grad/param norm = 2.4780e-01, time/batch = 0.6690s	
1342/33150 (epoch 2.024), train_loss = 1.87518087, grad/param norm = 2.5998e-01, time/batch = 0.6724s	
1343/33150 (epoch 2.026), train_loss = 1.60643907, grad/param norm = 2.2967e-01, time/batch = 0.6636s	
1344/33150 (epoch 2.027), train_loss = 1.76134543, grad/param norm = 2.5543e-01, time/batch = 0.6676s	
1345/33150 (epoch 2.029), train_loss = 1.77868871, grad/param norm = 2.9843e-01, time/batch = 0.6676s	
1346/33150 (epoch 2.030), train_loss = 1.95529240, grad/param norm = 2.2685e-01, time/batch = 0.6624s	
1347/33150 (epoch 2.032), train_loss = 1.86580592, grad/param norm = 2.5927e-01, time/batch = 0.6673s	
1348/33150 (epoch 2.033), train_loss = 1.79972244, grad/param norm = 2.8910e-01, time/batch = 0.6653s	
1349/33150 (epoch 2.035), train_loss = 2.02498087, grad/param norm = 2.8499e-01, time/batch = 0.6670s	
1350/33150 (epoch 2.036), train_loss = 1.98146776, grad/param norm = 2.8831e-01, time/batch = 0.6666s	
1351/33150 (epoch 2.038), train_loss = 2.09896006, grad/param norm = 2.7307e-01, time/batch = 0.6705s	
1352/33150 (epoch 2.039), train_loss = 1.92895271, grad/param norm = 2.4824e-01, time/batch = 0.6668s	
1353/33150 (epoch 2.041), train_loss = 1.85208024, grad/param norm = 2.1384e-01, time/batch = 0.6671s	
1354/33150 (epoch 2.042), train_loss = 1.65300727, grad/param norm = 2.2134e-01, time/batch = 0.6705s	
1355/33150 (epoch 2.044), train_loss = 1.78717531, grad/param norm = 2.2345e-01, time/batch = 0.6673s	
1356/33150 (epoch 2.045), train_loss = 1.91005159, grad/param norm = 2.8662e-01, time/batch = 0.6672s	
1357/33150 (epoch 2.047), train_loss = 1.76761586, grad/param norm = 2.6647e-01, time/batch = 0.6730s	
1358/33150 (epoch 2.048), train_loss = 2.05843986, grad/param norm = 3.0888e-01, time/batch = 0.6690s	
1359/33150 (epoch 2.050), train_loss = 1.87332277, grad/param norm = 2.5180e-01, time/batch = 0.6672s	
1360/33150 (epoch 2.051), train_loss = 1.88461470, grad/param norm = 2.5489e-01, time/batch = 0.6683s	
1361/33150 (epoch 2.053), train_loss = 1.81598617, grad/param norm = 2.3795e-01, time/batch = 0.6697s	
1362/33150 (epoch 2.054), train_loss = 1.85728324, grad/param norm = 2.2169e-01, time/batch = 0.6684s	
1363/33150 (epoch 2.056), train_loss = 1.62554671, grad/param norm = 2.2022e-01, time/batch = 0.6695s	
1364/33150 (epoch 2.057), train_loss = 1.85753403, grad/param norm = 2.5866e-01, time/batch = 0.6692s	
1365/33150 (epoch 2.059), train_loss = 1.89805224, grad/param norm = 3.3661e-01, time/batch = 0.6697s	
1366/33150 (epoch 2.060), train_loss = 1.70297661, grad/param norm = 2.5263e-01, time/batch = 0.6657s	
1367/33150 (epoch 2.062), train_loss = 1.92231656, grad/param norm = 2.3694e-01, time/batch = 0.6735s	
1368/33150 (epoch 2.063), train_loss = 1.82941619, grad/param norm = 2.1841e-01, time/batch = 0.6785s	
1369/33150 (epoch 2.065), train_loss = 1.87781525, grad/param norm = 2.6359e-01, time/batch = 0.6657s	
1370/33150 (epoch 2.066), train_loss = 1.75857382, grad/param norm = 2.3625e-01, time/batch = 0.6627s	
1371/33150 (epoch 2.068), train_loss = 1.84689934, grad/param norm = 2.4080e-01, time/batch = 0.6691s	
1372/33150 (epoch 2.069), train_loss = 1.93645585, grad/param norm = 2.3999e-01, time/batch = 0.6867s	
1373/33150 (epoch 2.071), train_loss = 1.92108873, grad/param norm = 2.3948e-01, time/batch = 0.6699s	
1374/33150 (epoch 2.072), train_loss = 1.62666964, grad/param norm = 2.5647e-01, time/batch = 0.6761s	
1375/33150 (epoch 2.074), train_loss = 1.68621292, grad/param norm = 2.3740e-01, time/batch = 0.6713s	
1376/33150 (epoch 2.075), train_loss = 1.89108998, grad/param norm = 2.5166e-01, time/batch = 0.6654s	
1377/33150 (epoch 2.077), train_loss = 1.91719910, grad/param norm = 2.7827e-01, time/batch = 0.6674s	
1378/33150 (epoch 2.078), train_loss = 2.01966099, grad/param norm = 2.7975e-01, time/batch = 0.6667s	
1379/33150 (epoch 2.080), train_loss = 1.91635472, grad/param norm = 2.6771e-01, time/batch = 0.6687s	
1380/33150 (epoch 2.081), train_loss = 1.82501855, grad/param norm = 2.6472e-01, time/batch = 0.6641s	
1381/33150 (epoch 2.083), train_loss = 1.55800022, grad/param norm = 2.6958e-01, time/batch = 0.6666s	
1382/33150 (epoch 2.084), train_loss = 1.79746177, grad/param norm = 2.7224e-01, time/batch = 0.6775s	
1383/33150 (epoch 2.086), train_loss = 1.75727592, grad/param norm = 2.5896e-01, time/batch = 0.6744s	
1384/33150 (epoch 2.087), train_loss = 1.70993035, grad/param norm = 2.5990e-01, time/batch = 0.6675s	
1385/33150 (epoch 2.089), train_loss = 1.67914750, grad/param norm = 2.7593e-01, time/batch = 0.6812s	
1386/33150 (epoch 2.090), train_loss = 1.77492757, grad/param norm = 2.7458e-01, time/batch = 0.6882s	
1387/33150 (epoch 2.092), train_loss = 1.88300220, grad/param norm = 2.3537e-01, time/batch = 0.6864s	
1388/33150 (epoch 2.094), train_loss = 1.87626669, grad/param norm = 2.4495e-01, time/batch = 0.6813s	
1389/33150 (epoch 2.095), train_loss = 1.63137646, grad/param norm = 2.1124e-01, time/batch = 0.6853s	
1390/33150 (epoch 2.097), train_loss = 2.00116873, grad/param norm = 2.9129e-01, time/batch = 0.6610s	
1391/33150 (epoch 2.098), train_loss = 2.14176835, grad/param norm = 2.5992e-01, time/batch = 0.6654s	
1392/33150 (epoch 2.100), train_loss = 1.92881475, grad/param norm = 2.6220e-01, time/batch = 0.6622s	
1393/33150 (epoch 2.101), train_loss = 1.73386589, grad/param norm = 2.8983e-01, time/batch = 0.6776s	
1394/33150 (epoch 2.103), train_loss = 1.88778541, grad/param norm = 2.6522e-01, time/batch = 0.6854s	
1395/33150 (epoch 2.104), train_loss = 1.79084611, grad/param norm = 2.4642e-01, time/batch = 0.6862s	
1396/33150 (epoch 2.106), train_loss = 1.95210991, grad/param norm = 2.5332e-01, time/batch = 0.6691s	
1397/33150 (epoch 2.107), train_loss = 1.92370598, grad/param norm = 2.4381e-01, time/batch = 0.6645s	
1398/33150 (epoch 2.109), train_loss = 1.79916127, grad/param norm = 2.3333e-01, time/batch = 0.6667s	
1399/33150 (epoch 2.110), train_loss = 1.95293359, grad/param norm = 2.2640e-01, time/batch = 0.6664s	
1400/33150 (epoch 2.112), train_loss = 1.71168342, grad/param norm = 2.4291e-01, time/batch = 0.6670s	
1401/33150 (epoch 2.113), train_loss = 1.73447975, grad/param norm = 2.4739e-01, time/batch = 0.6706s	
1402/33150 (epoch 2.115), train_loss = 1.94287250, grad/param norm = 2.5991e-01, time/batch = 0.6639s	
1403/33150 (epoch 2.116), train_loss = 1.66226857, grad/param norm = 2.3251e-01, time/batch = 0.6677s	
1404/33150 (epoch 2.118), train_loss = 1.88652125, grad/param norm = 2.7272e-01, time/batch = 0.6687s	
1405/33150 (epoch 2.119), train_loss = 1.91369646, grad/param norm = 3.0344e-01, time/batch = 0.6662s	
1406/33150 (epoch 2.121), train_loss = 1.86795060, grad/param norm = 2.8860e-01, time/batch = 0.6676s	
1407/33150 (epoch 2.122), train_loss = 2.00312231, grad/param norm = 2.9104e-01, time/batch = 0.6654s	
1408/33150 (epoch 2.124), train_loss = 1.68201797, grad/param norm = 2.5410e-01, time/batch = 0.6643s	
1409/33150 (epoch 2.125), train_loss = 1.74953883, grad/param norm = 2.2529e-01, time/batch = 0.6737s	
1410/33150 (epoch 2.127), train_loss = 1.71263140, grad/param norm = 2.2107e-01, time/batch = 0.6659s	
1411/33150 (epoch 2.128), train_loss = 1.86063326, grad/param norm = 2.6380e-01, time/batch = 0.6676s	
1412/33150 (epoch 2.130), train_loss = 1.90968398, grad/param norm = 2.2921e-01, time/batch = 0.6812s	
1413/33150 (epoch 2.131), train_loss = 1.97187770, grad/param norm = 2.4798e-01, time/batch = 0.6692s	
1414/33150 (epoch 2.133), train_loss = 1.68923683, grad/param norm = 2.5868e-01, time/batch = 0.6722s	
1415/33150 (epoch 2.134), train_loss = 1.88724128, grad/param norm = 2.5066e-01, time/batch = 0.6652s	
1416/33150 (epoch 2.136), train_loss = 1.76954101, grad/param norm = 2.5055e-01, time/batch = 0.6626s	
1417/33150 (epoch 2.137), train_loss = 1.88557057, grad/param norm = 2.4934e-01, time/batch = 0.6674s	
1418/33150 (epoch 2.139), train_loss = 1.85257626, grad/param norm = 2.5045e-01, time/batch = 0.6687s	
1419/33150 (epoch 2.140), train_loss = 1.97059215, grad/param norm = 2.7745e-01, time/batch = 0.6653s	
1420/33150 (epoch 2.142), train_loss = 1.84923894, grad/param norm = 2.5336e-01, time/batch = 0.6653s	
1421/33150 (epoch 2.143), train_loss = 1.90516647, grad/param norm = 2.6361e-01, time/batch = 0.6687s	
1422/33150 (epoch 2.145), train_loss = 1.86747894, grad/param norm = 3.0852e-01, time/batch = 0.6773s	
1423/33150 (epoch 2.146), train_loss = 2.05088357, grad/param norm = 2.7748e-01, time/batch = 0.6770s	
1424/33150 (epoch 2.148), train_loss = 1.91057140, grad/param norm = 2.1304e-01, time/batch = 0.6745s	
1425/33150 (epoch 2.149), train_loss = 1.91078556, grad/param norm = 2.8909e-01, time/batch = 0.6691s	
1426/33150 (epoch 2.151), train_loss = 2.02993096, grad/param norm = 2.4979e-01, time/batch = 0.6680s	
1427/33150 (epoch 2.152), train_loss = 1.67833789, grad/param norm = 2.2426e-01, time/batch = 0.6686s	
1428/33150 (epoch 2.154), train_loss = 1.75070912, grad/param norm = 2.2217e-01, time/batch = 0.6686s	
1429/33150 (epoch 2.155), train_loss = 1.74261671, grad/param norm = 2.5666e-01, time/batch = 0.6678s	
1430/33150 (epoch 2.157), train_loss = 1.80872533, grad/param norm = 3.1880e-01, time/batch = 0.6700s	
1431/33150 (epoch 2.158), train_loss = 1.72396081, grad/param norm = 2.3926e-01, time/batch = 0.6715s	
1432/33150 (epoch 2.160), train_loss = 1.92793532, grad/param norm = 2.7034e-01, time/batch = 0.6697s	
1433/33150 (epoch 2.161), train_loss = 1.77189386, grad/param norm = 2.5697e-01, time/batch = 0.6693s	
1434/33150 (epoch 2.163), train_loss = 1.77443586, grad/param norm = 2.4069e-01, time/batch = 0.6698s	
1435/33150 (epoch 2.164), train_loss = 1.89194030, grad/param norm = 2.4274e-01, time/batch = 0.6706s	
1436/33150 (epoch 2.166), train_loss = 1.93787754, grad/param norm = 2.4828e-01, time/batch = 0.6652s	
1437/33150 (epoch 2.167), train_loss = 1.83919647, grad/param norm = 2.3530e-01, time/batch = 0.6657s	
1438/33150 (epoch 2.169), train_loss = 2.05431746, grad/param norm = 2.7802e-01, time/batch = 0.6635s	
1439/33150 (epoch 2.170), train_loss = 1.88301709, grad/param norm = 2.5504e-01, time/batch = 0.6708s	
1440/33150 (epoch 2.172), train_loss = 1.94017492, grad/param norm = 2.7039e-01, time/batch = 0.6663s	
1441/33150 (epoch 2.173), train_loss = 1.94320736, grad/param norm = 2.8586e-01, time/batch = 0.6737s	
1442/33150 (epoch 2.175), train_loss = 1.70029535, grad/param norm = 2.6381e-01, time/batch = 0.6924s	
1443/33150 (epoch 2.176), train_loss = 1.72448844, grad/param norm = 2.6897e-01, time/batch = 0.6850s	
1444/33150 (epoch 2.178), train_loss = 1.88273743, grad/param norm = 2.5007e-01, time/batch = 0.6775s	
1445/33150 (epoch 2.179), train_loss = 1.89388806, grad/param norm = 2.1654e-01, time/batch = 0.6645s	
1446/33150 (epoch 2.181), train_loss = 1.84964586, grad/param norm = 2.7711e-01, time/batch = 0.6761s	
1447/33150 (epoch 2.183), train_loss = 1.89539753, grad/param norm = 2.7803e-01, time/batch = 0.6695s	
1448/33150 (epoch 2.184), train_loss = 1.91248835, grad/param norm = 2.8931e-01, time/batch = 0.6683s	
1449/33150 (epoch 2.186), train_loss = 1.94507049, grad/param norm = 2.3619e-01, time/batch = 0.6684s	
1450/33150 (epoch 2.187), train_loss = 1.78933586, grad/param norm = 2.3565e-01, time/batch = 0.6691s	
1451/33150 (epoch 2.189), train_loss = 1.78686752, grad/param norm = 2.5720e-01, time/batch = 0.6687s	
1452/33150 (epoch 2.190), train_loss = 1.77454719, grad/param norm = 2.7992e-01, time/batch = 0.6649s	
1453/33150 (epoch 2.192), train_loss = 1.83669732, grad/param norm = 2.4211e-01, time/batch = 0.6671s	
1454/33150 (epoch 2.193), train_loss = 1.74656642, grad/param norm = 2.4129e-01, time/batch = 0.6690s	
1455/33150 (epoch 2.195), train_loss = 2.11767371, grad/param norm = 2.7475e-01, time/batch = 0.6674s	
1456/33150 (epoch 2.196), train_loss = 1.89836422, grad/param norm = 2.1933e-01, time/batch = 0.6763s	
1457/33150 (epoch 2.198), train_loss = 1.74137576, grad/param norm = 2.3888e-01, time/batch = 0.6790s	
1458/33150 (epoch 2.199), train_loss = 1.91689633, grad/param norm = 2.4770e-01, time/batch = 0.6706s	
1459/33150 (epoch 2.201), train_loss = 1.67371285, grad/param norm = 2.0420e-01, time/batch = 0.6681s	
1460/33150 (epoch 2.202), train_loss = 1.56780522, grad/param norm = 2.0351e-01, time/batch = 0.6749s	
1461/33150 (epoch 2.204), train_loss = 1.77577594, grad/param norm = 2.4097e-01, time/batch = 0.6706s	
1462/33150 (epoch 2.205), train_loss = 1.95214978, grad/param norm = 2.4707e-01, time/batch = 0.6692s	
1463/33150 (epoch 2.207), train_loss = 1.80618878, grad/param norm = 3.0637e-01, time/batch = 0.6675s	
1464/33150 (epoch 2.208), train_loss = 1.85030675, grad/param norm = 2.9728e-01, time/batch = 0.6660s	
1465/33150 (epoch 2.210), train_loss = 1.65384393, grad/param norm = 2.2829e-01, time/batch = 0.6650s	
1466/33150 (epoch 2.211), train_loss = 1.93002287, grad/param norm = 2.4720e-01, time/batch = 0.6675s	
1467/33150 (epoch 2.213), train_loss = 2.06893340, grad/param norm = 2.5068e-01, time/batch = 0.6659s	
1468/33150 (epoch 2.214), train_loss = 1.74124905, grad/param norm = 2.4453e-01, time/batch = 0.6690s	
1469/33150 (epoch 2.216), train_loss = 1.81636297, grad/param norm = 2.4678e-01, time/batch = 0.6804s	
1470/33150 (epoch 2.217), train_loss = 1.83417176, grad/param norm = 2.2664e-01, time/batch = 0.6667s	
1471/33150 (epoch 2.219), train_loss = 1.74509342, grad/param norm = 2.7030e-01, time/batch = 0.6771s	
1472/33150 (epoch 2.220), train_loss = 1.61834115, grad/param norm = 2.4021e-01, time/batch = 0.6753s	
1473/33150 (epoch 2.222), train_loss = 1.87862048, grad/param norm = 2.5562e-01, time/batch = 0.6613s	
1474/33150 (epoch 2.223), train_loss = 1.79009917, grad/param norm = 2.3673e-01, time/batch = 0.6638s	
1475/33150 (epoch 2.225), train_loss = 2.02610329, grad/param norm = 2.4590e-01, time/batch = 0.6658s	
1476/33150 (epoch 2.226), train_loss = 1.76354242, grad/param norm = 2.3900e-01, time/batch = 0.6636s	
1477/33150 (epoch 2.228), train_loss = 1.81488355, grad/param norm = 2.6645e-01, time/batch = 0.6636s	
1478/33150 (epoch 2.229), train_loss = 1.84559782, grad/param norm = 2.5067e-01, time/batch = 0.6647s	
1479/33150 (epoch 2.231), train_loss = 1.89835710, grad/param norm = 2.7260e-01, time/batch = 0.6663s	
1480/33150 (epoch 2.232), train_loss = 1.88363707, grad/param norm = 2.3967e-01, time/batch = 0.6650s	
1481/33150 (epoch 2.234), train_loss = 1.74663411, grad/param norm = 2.5376e-01, time/batch = 0.6659s	
1482/33150 (epoch 2.235), train_loss = 1.89015294, grad/param norm = 2.8507e-01, time/batch = 0.6760s	
1483/33150 (epoch 2.237), train_loss = 1.81806523, grad/param norm = 2.5997e-01, time/batch = 0.6879s	
1484/33150 (epoch 2.238), train_loss = 2.04726814, grad/param norm = 2.5726e-01, time/batch = 0.6958s	
1485/33150 (epoch 2.240), train_loss = 1.82562553, grad/param norm = 2.3756e-01, time/batch = 0.6969s	
1486/33150 (epoch 2.241), train_loss = 1.87444771, grad/param norm = 2.5459e-01, time/batch = 0.6905s	
1487/33150 (epoch 2.243), train_loss = 2.00833277, grad/param norm = 2.4527e-01, time/batch = 0.6854s	
1488/33150 (epoch 2.244), train_loss = 1.80541108, grad/param norm = 2.5108e-01, time/batch = 0.6870s	
1489/33150 (epoch 2.246), train_loss = 1.84727481, grad/param norm = 2.6878e-01, time/batch = 0.6906s	
1490/33150 (epoch 2.247), train_loss = 1.75847465, grad/param norm = 2.7886e-01, time/batch = 0.6825s	
1491/33150 (epoch 2.249), train_loss = 2.06672984, grad/param norm = 2.6297e-01, time/batch = 0.6813s	
1492/33150 (epoch 2.250), train_loss = 1.78953773, grad/param norm = 2.2846e-01, time/batch = 0.6769s	
1493/33150 (epoch 2.252), train_loss = 1.76929761, grad/param norm = 2.2740e-01, time/batch = 0.6663s	
1494/33150 (epoch 2.253), train_loss = 1.94378869, grad/param norm = 2.9425e-01, time/batch = 0.6628s	
1495/33150 (epoch 2.255), train_loss = 1.85480104, grad/param norm = 2.3684e-01, time/batch = 0.6625s	
1496/33150 (epoch 2.256), train_loss = 1.92282921, grad/param norm = 2.5387e-01, time/batch = 0.6624s	
1497/33150 (epoch 2.258), train_loss = 1.79415697, grad/param norm = 3.1489e-01, time/batch = 0.6620s	
1498/33150 (epoch 2.259), train_loss = 1.61220312, grad/param norm = 2.8528e-01, time/batch = 0.6661s	
1499/33150 (epoch 2.261), train_loss = 1.66389411, grad/param norm = 2.4228e-01, time/batch = 0.6638s	
1500/33150 (epoch 2.262), train_loss = 1.83377357, grad/param norm = 2.2736e-01, time/batch = 0.6665s	
1501/33150 (epoch 2.264), train_loss = 1.57325897, grad/param norm = 2.4432e-01, time/batch = 0.6811s	
1502/33150 (epoch 2.265), train_loss = 1.85213327, grad/param norm = 2.5334e-01, time/batch = 0.6722s	
1503/33150 (epoch 2.267), train_loss = 1.92553913, grad/param norm = 2.5296e-01, time/batch = 0.6704s	
1504/33150 (epoch 2.268), train_loss = 1.61423168, grad/param norm = 2.3821e-01, time/batch = 0.6741s	
1505/33150 (epoch 2.270), train_loss = 1.98129788, grad/param norm = 2.2985e-01, time/batch = 0.6721s	
1506/33150 (epoch 2.271), train_loss = 1.96995765, grad/param norm = 2.5128e-01, time/batch = 0.6705s	
1507/33150 (epoch 2.273), train_loss = 1.88532351, grad/param norm = 2.9037e-01, time/batch = 0.6696s	
1508/33150 (epoch 2.275), train_loss = 1.88863679, grad/param norm = 2.4315e-01, time/batch = 0.6691s	
1509/33150 (epoch 2.276), train_loss = 1.82171325, grad/param norm = 2.4061e-01, time/batch = 0.6696s	
1510/33150 (epoch 2.278), train_loss = 1.95127442, grad/param norm = 2.8027e-01, time/batch = 0.6706s	
1511/33150 (epoch 2.279), train_loss = 1.83119631, grad/param norm = 2.7562e-01, time/batch = 0.6749s	
1512/33150 (epoch 2.281), train_loss = 1.96639417, grad/param norm = 2.4969e-01, time/batch = 0.6741s	
1513/33150 (epoch 2.282), train_loss = 1.80587999, grad/param norm = 2.3809e-01, time/batch = 0.6759s	
1514/33150 (epoch 2.284), train_loss = 1.77345709, grad/param norm = 2.0373e-01, time/batch = 0.6690s	
1515/33150 (epoch 2.285), train_loss = 1.88263108, grad/param norm = 2.6439e-01, time/batch = 0.6720s	
1516/33150 (epoch 2.287), train_loss = 1.77180164, grad/param norm = 2.2895e-01, time/batch = 0.6799s	
1517/33150 (epoch 2.288), train_loss = 2.00372729, grad/param norm = 2.5012e-01, time/batch = 0.6689s	
1518/33150 (epoch 2.290), train_loss = 1.68166210, grad/param norm = 2.4649e-01, time/batch = 0.6660s	
1519/33150 (epoch 2.291), train_loss = 1.81215236, grad/param norm = 2.8519e-01, time/batch = 0.6681s	
1520/33150 (epoch 2.293), train_loss = 1.90510614, grad/param norm = 2.8071e-01, time/batch = 0.6698s	
1521/33150 (epoch 2.294), train_loss = 1.53673544, grad/param norm = 2.4510e-01, time/batch = 0.6666s	
1522/33150 (epoch 2.296), train_loss = 1.79655654, grad/param norm = 2.3443e-01, time/batch = 0.6650s	
1523/33150 (epoch 2.297), train_loss = 1.82964882, grad/param norm = 2.4499e-01, time/batch = 0.6745s	
1524/33150 (epoch 2.299), train_loss = 1.72735731, grad/param norm = 2.2902e-01, time/batch = 0.6658s	
1525/33150 (epoch 2.300), train_loss = 1.74137312, grad/param norm = 2.2810e-01, time/batch = 0.6631s	
1526/33150 (epoch 2.302), train_loss = 1.81051213, grad/param norm = 2.8539e-01, time/batch = 0.6639s	
1527/33150 (epoch 2.303), train_loss = 1.96135335, grad/param norm = 2.7514e-01, time/batch = 0.6644s	
1528/33150 (epoch 2.305), train_loss = 1.81801605, grad/param norm = 2.3015e-01, time/batch = 0.6689s	
1529/33150 (epoch 2.306), train_loss = 1.88612826, grad/param norm = 2.2384e-01, time/batch = 0.6665s	
1530/33150 (epoch 2.308), train_loss = 2.00064031, grad/param norm = 2.2423e-01, time/batch = 0.6621s	
1531/33150 (epoch 2.309), train_loss = 1.74805492, grad/param norm = 2.1998e-01, time/batch = 0.6715s	
1532/33150 (epoch 2.311), train_loss = 1.94569044, grad/param norm = 2.8840e-01, time/batch = 0.6647s	
1533/33150 (epoch 2.312), train_loss = 1.68148044, grad/param norm = 3.2001e-01, time/batch = 0.6593s	
1534/33150 (epoch 2.314), train_loss = 1.92499223, grad/param norm = 2.8542e-01, time/batch = 0.6596s	
1535/33150 (epoch 2.315), train_loss = 1.89204180, grad/param norm = 2.6669e-01, time/batch = 0.6799s	
1536/33150 (epoch 2.317), train_loss = 1.55349310, grad/param norm = 2.2529e-01, time/batch = 0.6712s	
1537/33150 (epoch 2.318), train_loss = 1.66438072, grad/param norm = 2.2637e-01, time/batch = 0.6654s	
1538/33150 (epoch 2.320), train_loss = 1.70186996, grad/param norm = 2.3834e-01, time/batch = 0.6636s	
1539/33150 (epoch 2.321), train_loss = 1.76330212, grad/param norm = 2.5153e-01, time/batch = 0.6631s	
1540/33150 (epoch 2.323), train_loss = 1.84769063, grad/param norm = 2.3641e-01, time/batch = 0.6773s	
1541/33150 (epoch 2.324), train_loss = 1.95859234, grad/param norm = 2.4532e-01, time/batch = 0.6793s	
1542/33150 (epoch 2.326), train_loss = 1.73160551, grad/param norm = 2.1909e-01, time/batch = 0.6698s	
1543/33150 (epoch 2.327), train_loss = 1.93787426, grad/param norm = 2.4494e-01, time/batch = 0.6666s	
1544/33150 (epoch 2.329), train_loss = 1.79660309, grad/param norm = 2.2317e-01, time/batch = 0.6675s	
1545/33150 (epoch 2.330), train_loss = 1.94036355, grad/param norm = 2.8548e-01, time/batch = 0.6655s	
1546/33150 (epoch 2.332), train_loss = 1.78040013, grad/param norm = 2.5951e-01, time/batch = 0.6686s	
1547/33150 (epoch 2.333), train_loss = 1.76920805, grad/param norm = 2.1375e-01, time/batch = 0.6658s	
1548/33150 (epoch 2.335), train_loss = 1.86213013, grad/param norm = 2.2506e-01, time/batch = 0.6660s	
1549/33150 (epoch 2.336), train_loss = 1.74372649, grad/param norm = 2.5006e-01, time/batch = 0.6650s	
1550/33150 (epoch 2.338), train_loss = 1.56726861, grad/param norm = 2.7848e-01, time/batch = 0.6682s	
1551/33150 (epoch 2.339), train_loss = 1.90602217, grad/param norm = 2.6496e-01, time/batch = 0.6663s	
1552/33150 (epoch 2.341), train_loss = 2.06591405, grad/param norm = 2.5580e-01, time/batch = 0.6662s	
1553/33150 (epoch 2.342), train_loss = 1.74217398, grad/param norm = 2.3681e-01, time/batch = 0.6673s	
1554/33150 (epoch 2.344), train_loss = 1.85358960, grad/param norm = 2.4378e-01, time/batch = 0.6656s	
1555/33150 (epoch 2.345), train_loss = 1.56583227, grad/param norm = 2.1574e-01, time/batch = 0.6670s	
1556/33150 (epoch 2.347), train_loss = 1.50667742, grad/param norm = 2.0371e-01, time/batch = 0.6672s	
1557/33150 (epoch 2.348), train_loss = 1.72151265, grad/param norm = 2.2603e-01, time/batch = 0.6704s	
1558/33150 (epoch 2.350), train_loss = 1.94885257, grad/param norm = 2.6684e-01, time/batch = 0.6745s	
1559/33150 (epoch 2.351), train_loss = 1.86651028, grad/param norm = 2.4942e-01, time/batch = 0.6713s	
1560/33150 (epoch 2.353), train_loss = 1.98122987, grad/param norm = 2.5627e-01, time/batch = 0.6719s	
1561/33150 (epoch 2.354), train_loss = 2.05778376, grad/param norm = 2.4385e-01, time/batch = 0.6718s	
1562/33150 (epoch 2.356), train_loss = 1.85592861, grad/param norm = 2.6618e-01, time/batch = 0.6714s	
1563/33150 (epoch 2.357), train_loss = 1.89146111, grad/param norm = 2.7590e-01, time/batch = 0.6724s	
1564/33150 (epoch 2.359), train_loss = 1.78913401, grad/param norm = 2.5807e-01, time/batch = 0.6865s	
1565/33150 (epoch 2.360), train_loss = 1.97384364, grad/param norm = 2.6097e-01, time/batch = 0.6799s	
1566/33150 (epoch 2.362), train_loss = 1.81701630, grad/param norm = 2.2937e-01, time/batch = 0.6725s	
1567/33150 (epoch 2.363), train_loss = 1.74747027, grad/param norm = 2.2496e-01, time/batch = 0.6676s	
1568/33150 (epoch 2.365), train_loss = 1.80715713, grad/param norm = 2.2225e-01, time/batch = 0.6888s	
1569/33150 (epoch 2.367), train_loss = 1.60960983, grad/param norm = 2.2495e-01, time/batch = 0.6679s	
1570/33150 (epoch 2.368), train_loss = 1.90769984, grad/param norm = 2.3707e-01, time/batch = 0.6642s	
1571/33150 (epoch 2.370), train_loss = 2.01877894, grad/param norm = 2.6276e-01, time/batch = 0.6797s	
1572/33150 (epoch 2.371), train_loss = 1.77109536, grad/param norm = 2.5184e-01, time/batch = 0.6858s	
1573/33150 (epoch 2.373), train_loss = 1.90204289, grad/param norm = 2.5559e-01, time/batch = 0.6917s	
1574/33150 (epoch 2.374), train_loss = 1.63286909, grad/param norm = 2.3176e-01, time/batch = 0.6697s	
1575/33150 (epoch 2.376), train_loss = 1.94427806, grad/param norm = 2.2913e-01, time/batch = 0.6695s	
1576/33150 (epoch 2.377), train_loss = 1.88353910, grad/param norm = 2.7388e-01, time/batch = 0.6730s	
1577/33150 (epoch 2.379), train_loss = 1.87025675, grad/param norm = 2.4002e-01, time/batch = 0.6844s	
1578/33150 (epoch 2.380), train_loss = 1.96567594, grad/param norm = 2.4464e-01, time/batch = 0.6736s	
1579/33150 (epoch 2.382), train_loss = 1.70868295, grad/param norm = 2.3154e-01, time/batch = 0.6753s	
1580/33150 (epoch 2.383), train_loss = 1.64092321, grad/param norm = 2.1592e-01, time/batch = 0.6806s	
1581/33150 (epoch 2.385), train_loss = 1.84023523, grad/param norm = 2.1293e-01, time/batch = 0.6705s	
1582/33150 (epoch 2.386), train_loss = 1.65521259, grad/param norm = 2.3198e-01, time/batch = 0.6713s	
1583/33150 (epoch 2.388), train_loss = 1.79035868, grad/param norm = 2.6617e-01, time/batch = 0.6722s	
1584/33150 (epoch 2.389), train_loss = 1.79372262, grad/param norm = 2.4865e-01, time/batch = 0.6681s	
1585/33150 (epoch 2.391), train_loss = 2.05581440, grad/param norm = 2.8089e-01, time/batch = 0.6677s	
1586/33150 (epoch 2.392), train_loss = 1.76473428, grad/param norm = 2.6704e-01, time/batch = 0.6677s	
1587/33150 (epoch 2.394), train_loss = 1.63973012, grad/param norm = 2.4448e-01, time/batch = 0.6661s	
1588/33150 (epoch 2.395), train_loss = 1.80552243, grad/param norm = 2.5749e-01, time/batch = 0.6629s	
1589/33150 (epoch 2.397), train_loss = 1.36837221, grad/param norm = 2.3925e-01, time/batch = 0.6624s	
1590/33150 (epoch 2.398), train_loss = 1.84730627, grad/param norm = 2.4996e-01, time/batch = 0.6619s	
1591/33150 (epoch 2.400), train_loss = 1.69986293, grad/param norm = 2.1264e-01, time/batch = 0.6644s	
1592/33150 (epoch 2.401), train_loss = 1.57168795, grad/param norm = 2.1365e-01, time/batch = 0.6722s	
1593/33150 (epoch 2.403), train_loss = 1.70079659, grad/param norm = 2.4639e-01, time/batch = 0.6652s	
1594/33150 (epoch 2.404), train_loss = 1.69120953, grad/param norm = 2.3978e-01, time/batch = 0.6741s	
1595/33150 (epoch 2.406), train_loss = 1.64598364, grad/param norm = 2.5233e-01, time/batch = 0.6797s	
1596/33150 (epoch 2.407), train_loss = 1.63652841, grad/param norm = 2.0648e-01, time/batch = 0.6800s	
1597/33150 (epoch 2.409), train_loss = 1.50810470, grad/param norm = 2.3239e-01, time/batch = 0.6802s	
1598/33150 (epoch 2.410), train_loss = 1.87745519, grad/param norm = 2.5692e-01, time/batch = 0.6832s	
1599/33150 (epoch 2.412), train_loss = 1.89790318, grad/param norm = 2.2515e-01, time/batch = 0.6790s	
1600/33150 (epoch 2.413), train_loss = 1.77246067, grad/param norm = 2.5421e-01, time/batch = 0.6815s	
1601/33150 (epoch 2.415), train_loss = 1.94779191, grad/param norm = 2.4400e-01, time/batch = 0.6836s	
1602/33150 (epoch 2.416), train_loss = 1.84066798, grad/param norm = 2.2083e-01, time/batch = 0.6824s	
1603/33150 (epoch 2.418), train_loss = 2.12695109, grad/param norm = 2.8462e-01, time/batch = 0.6796s	
1604/33150 (epoch 2.419), train_loss = 1.74430772, grad/param norm = 2.3544e-01, time/batch = 0.6793s	
1605/33150 (epoch 2.421), train_loss = 1.86383559, grad/param norm = 2.5151e-01, time/batch = 0.6657s	
1606/33150 (epoch 2.422), train_loss = 1.65505325, grad/param norm = 2.4055e-01, time/batch = 0.6686s	
1607/33150 (epoch 2.424), train_loss = 1.77180703, grad/param norm = 2.3736e-01, time/batch = 0.6680s	
1608/33150 (epoch 2.425), train_loss = 1.69022113, grad/param norm = 2.4134e-01, time/batch = 0.6673s	
1609/33150 (epoch 2.427), train_loss = 1.70730052, grad/param norm = 2.5202e-01, time/batch = 0.6677s	
1610/33150 (epoch 2.428), train_loss = 1.87887041, grad/param norm = 2.4184e-01, time/batch = 0.6640s	
1611/33150 (epoch 2.430), train_loss = 1.81537503, grad/param norm = 2.3997e-01, time/batch = 0.6642s	
1612/33150 (epoch 2.431), train_loss = 1.84838533, grad/param norm = 2.5143e-01, time/batch = 0.6674s	
1613/33150 (epoch 2.433), train_loss = 1.85191129, grad/param norm = 2.2033e-01, time/batch = 0.6660s	
1614/33150 (epoch 2.434), train_loss = 1.55762584, grad/param norm = 2.1950e-01, time/batch = 0.6676s	
1615/33150 (epoch 2.436), train_loss = 1.60811075, grad/param norm = 2.6235e-01, time/batch = 0.6818s	
1616/33150 (epoch 2.437), train_loss = 1.76923236, grad/param norm = 2.7929e-01, time/batch = 0.6811s	
1617/33150 (epoch 2.439), train_loss = 1.80142223, grad/param norm = 2.1927e-01, time/batch = 0.6838s	
1618/33150 (epoch 2.440), train_loss = 1.85726296, grad/param norm = 2.6907e-01, time/batch = 0.6809s	
1619/33150 (epoch 2.442), train_loss = 1.57231716, grad/param norm = 2.3198e-01, time/batch = 0.6735s	
1620/33150 (epoch 2.443), train_loss = 1.82561117, grad/param norm = 2.4802e-01, time/batch = 0.6725s	
1621/33150 (epoch 2.445), train_loss = 1.77761378, grad/param norm = 2.4113e-01, time/batch = 0.6824s	
1622/33150 (epoch 2.446), train_loss = 1.86040954, grad/param norm = 2.9413e-01, time/batch = 0.6826s	
1623/33150 (epoch 2.448), train_loss = 1.71481025, grad/param norm = 2.4746e-01, time/batch = 0.6718s	
1624/33150 (epoch 2.449), train_loss = 1.70873003, grad/param norm = 2.1012e-01, time/batch = 0.6755s	
1625/33150 (epoch 2.451), train_loss = 1.87086659, grad/param norm = 2.4556e-01, time/batch = 0.6849s	
1626/33150 (epoch 2.452), train_loss = 1.96466297, grad/param norm = 2.2313e-01, time/batch = 0.6827s	
1627/33150 (epoch 2.454), train_loss = 1.88349306, grad/param norm = 2.2757e-01, time/batch = 0.6828s	
1628/33150 (epoch 2.456), train_loss = 1.47753638, grad/param norm = 2.3021e-01, time/batch = 0.6795s	
1629/33150 (epoch 2.457), train_loss = 1.78614626, grad/param norm = 2.5114e-01, time/batch = 0.6710s	
1630/33150 (epoch 2.459), train_loss = 1.91269125, grad/param norm = 2.5968e-01, time/batch = 0.6739s	
1631/33150 (epoch 2.460), train_loss = 1.73843150, grad/param norm = 2.0304e-01, time/batch = 0.6845s	
1632/33150 (epoch 2.462), train_loss = 1.83655495, grad/param norm = 2.5058e-01, time/batch = 0.6695s	
1633/33150 (epoch 2.463), train_loss = 2.04754026, grad/param norm = 2.8082e-01, time/batch = 0.6688s	
1634/33150 (epoch 2.465), train_loss = 1.70307094, grad/param norm = 2.2801e-01, time/batch = 0.6782s	
1635/33150 (epoch 2.466), train_loss = 1.75827763, grad/param norm = 2.4598e-01, time/batch = 0.6643s	
1636/33150 (epoch 2.468), train_loss = 2.09134878, grad/param norm = 2.7354e-01, time/batch = 0.6662s	
1637/33150 (epoch 2.469), train_loss = 1.96116093, grad/param norm = 2.4191e-01, time/batch = 0.6669s	
1638/33150 (epoch 2.471), train_loss = 1.68026012, grad/param norm = 2.2431e-01, time/batch = 0.6673s	
1639/33150 (epoch 2.472), train_loss = 1.64039983, grad/param norm = 2.2705e-01, time/batch = 0.6675s	
1640/33150 (epoch 2.474), train_loss = 1.78130833, grad/param norm = 2.6383e-01, time/batch = 0.6682s	
1641/33150 (epoch 2.475), train_loss = 1.99526738, grad/param norm = 2.5644e-01, time/batch = 0.6666s	
1642/33150 (epoch 2.477), train_loss = 1.85763041, grad/param norm = 3.0707e-01, time/batch = 0.6656s	
1643/33150 (epoch 2.478), train_loss = 1.80086233, grad/param norm = 2.4526e-01, time/batch = 0.6701s	
1644/33150 (epoch 2.480), train_loss = 1.59226258, grad/param norm = 2.1537e-01, time/batch = 0.6673s	
1645/33150 (epoch 2.481), train_loss = 1.47794052, grad/param norm = 2.0164e-01, time/batch = 0.6663s	
1646/33150 (epoch 2.483), train_loss = 1.60089238, grad/param norm = 2.3876e-01, time/batch = 0.6692s	
1647/33150 (epoch 2.484), train_loss = 1.66935802, grad/param norm = 2.3526e-01, time/batch = 0.6688s	
1648/33150 (epoch 2.486), train_loss = 1.80858347, grad/param norm = 2.2833e-01, time/batch = 0.6656s	
1649/33150 (epoch 2.487), train_loss = 1.82579105, grad/param norm = 2.3063e-01, time/batch = 0.6628s	
1650/33150 (epoch 2.489), train_loss = 1.75589103, grad/param norm = 2.3391e-01, time/batch = 0.6648s	
1651/33150 (epoch 2.490), train_loss = 1.61299587, grad/param norm = 2.5065e-01, time/batch = 0.6668s	
1652/33150 (epoch 2.492), train_loss = 1.71031749, grad/param norm = 2.5418e-01, time/batch = 0.6633s	
1653/33150 (epoch 2.493), train_loss = 1.86738417, grad/param norm = 2.2978e-01, time/batch = 0.6660s	
1654/33150 (epoch 2.495), train_loss = 1.87690366, grad/param norm = 2.7556e-01, time/batch = 0.6802s	
1655/33150 (epoch 2.496), train_loss = 1.74861820, grad/param norm = 2.7860e-01, time/batch = 0.6642s	
1656/33150 (epoch 2.498), train_loss = 1.82439762, grad/param norm = 2.4610e-01, time/batch = 0.6647s	
1657/33150 (epoch 2.499), train_loss = 2.02975436, grad/param norm = 2.7787e-01, time/batch = 0.6666s	
1658/33150 (epoch 2.501), train_loss = 1.78402975, grad/param norm = 2.3381e-01, time/batch = 0.6796s	
1659/33150 (epoch 2.502), train_loss = 1.89122776, grad/param norm = 2.4606e-01, time/batch = 0.6696s	
1660/33150 (epoch 2.504), train_loss = 1.86558821, grad/param norm = 2.4671e-01, time/batch = 0.6786s	
1661/33150 (epoch 2.505), train_loss = 1.98676980, grad/param norm = 2.5593e-01, time/batch = 0.6870s	
1662/33150 (epoch 2.507), train_loss = 1.71268965, grad/param norm = 2.3327e-01, time/batch = 0.6814s	
1663/33150 (epoch 2.508), train_loss = 1.69218850, grad/param norm = 2.2049e-01, time/batch = 0.6878s	
1664/33150 (epoch 2.510), train_loss = 1.77317047, grad/param norm = 2.5750e-01, time/batch = 0.6853s	
1665/33150 (epoch 2.511), train_loss = 2.03270455, grad/param norm = 2.5215e-01, time/batch = 0.6880s	
1666/33150 (epoch 2.513), train_loss = 1.84310671, grad/param norm = 2.3963e-01, time/batch = 0.6656s	
1667/33150 (epoch 2.514), train_loss = 1.46056474, grad/param norm = 2.2237e-01, time/batch = 0.6681s	
1668/33150 (epoch 2.516), train_loss = 1.86050766, grad/param norm = 2.2570e-01, time/batch = 0.6657s	
1669/33150 (epoch 2.517), train_loss = 1.94037085, grad/param norm = 2.4043e-01, time/batch = 0.6654s	
1670/33150 (epoch 2.519), train_loss = 1.72076688, grad/param norm = 2.2407e-01, time/batch = 0.6650s	
1671/33150 (epoch 2.520), train_loss = 1.82371696, grad/param norm = 2.1950e-01, time/batch = 0.6674s	
1672/33150 (epoch 2.522), train_loss = 1.94865041, grad/param norm = 2.4690e-01, time/batch = 0.6979s	
1673/33150 (epoch 2.523), train_loss = 1.67988955, grad/param norm = 2.1844e-01, time/batch = 0.6805s	
1674/33150 (epoch 2.525), train_loss = 1.77771225, grad/param norm = 2.1709e-01, time/batch = 0.6722s	
1675/33150 (epoch 2.526), train_loss = 1.60268272, grad/param norm = 2.3086e-01, time/batch = 0.6694s	
1676/33150 (epoch 2.528), train_loss = 1.78185192, grad/param norm = 2.3131e-01, time/batch = 0.6689s	
1677/33150 (epoch 2.529), train_loss = 1.80594151, grad/param norm = 2.2926e-01, time/batch = 0.6684s	
1678/33150 (epoch 2.531), train_loss = 1.66130875, grad/param norm = 2.2116e-01, time/batch = 0.6642s	
1679/33150 (epoch 2.532), train_loss = 1.81283151, grad/param norm = 2.2640e-01, time/batch = 0.6695s	
1680/33150 (epoch 2.534), train_loss = 1.64321848, grad/param norm = 2.2279e-01, time/batch = 0.6667s	
1681/33150 (epoch 2.535), train_loss = 1.73184637, grad/param norm = 2.6329e-01, time/batch = 0.6694s	
1682/33150 (epoch 2.537), train_loss = 1.92677566, grad/param norm = 2.4403e-01, time/batch = 0.6723s	
1683/33150 (epoch 2.538), train_loss = 1.76565618, grad/param norm = 2.5838e-01, time/batch = 0.6680s	
1684/33150 (epoch 2.540), train_loss = 1.57076209, grad/param norm = 2.1537e-01, time/batch = 0.6685s	
1685/33150 (epoch 2.541), train_loss = 1.77208921, grad/param norm = 2.2619e-01, time/batch = 0.6707s	
1686/33150 (epoch 2.543), train_loss = 1.82848046, grad/param norm = 2.6227e-01, time/batch = 0.6698s	
1687/33150 (epoch 2.544), train_loss = 1.78846282, grad/param norm = 2.2146e-01, time/batch = 0.6679s	
1688/33150 (epoch 2.546), train_loss = 2.03034403, grad/param norm = 2.5181e-01, time/batch = 0.6687s	
1689/33150 (epoch 2.548), train_loss = 1.83381990, grad/param norm = 2.3312e-01, time/batch = 0.6698s	
1690/33150 (epoch 2.549), train_loss = 1.88811639, grad/param norm = 2.6650e-01, time/batch = 0.6699s	
1691/33150 (epoch 2.551), train_loss = 1.64615500, grad/param norm = 2.3717e-01, time/batch = 0.6723s	
1692/33150 (epoch 2.552), train_loss = 1.60939711, grad/param norm = 2.1375e-01, time/batch = 0.6807s	
1693/33150 (epoch 2.554), train_loss = 1.72284521, grad/param norm = 2.2812e-01, time/batch = 0.6755s	
1694/33150 (epoch 2.555), train_loss = 1.96543069, grad/param norm = 2.3578e-01, time/batch = 0.6709s	
1695/33150 (epoch 2.557), train_loss = 1.61759378, grad/param norm = 2.6491e-01, time/batch = 0.6702s	
1696/33150 (epoch 2.558), train_loss = 1.89945525, grad/param norm = 2.3289e-01, time/batch = 0.6718s	
1697/33150 (epoch 2.560), train_loss = 1.84391777, grad/param norm = 2.4895e-01, time/batch = 0.6693s	
1698/33150 (epoch 2.561), train_loss = 1.58470111, grad/param norm = 2.4489e-01, time/batch = 0.6715s	
1699/33150 (epoch 2.563), train_loss = 1.89571075, grad/param norm = 2.6491e-01, time/batch = 0.6669s	
1700/33150 (epoch 2.564), train_loss = 1.97563963, grad/param norm = 2.7646e-01, time/batch = 0.6669s	
1701/33150 (epoch 2.566), train_loss = 1.75079012, grad/param norm = 2.2283e-01, time/batch = 0.6675s	
1702/33150 (epoch 2.567), train_loss = 1.56370291, grad/param norm = 2.3294e-01, time/batch = 0.6682s	
1703/33150 (epoch 2.569), train_loss = 1.71954851, grad/param norm = 2.2157e-01, time/batch = 0.6680s	
1704/33150 (epoch 2.570), train_loss = 1.67102522, grad/param norm = 2.1506e-01, time/batch = 0.6649s	
1705/33150 (epoch 2.572), train_loss = 1.73429330, grad/param norm = 2.4279e-01, time/batch = 0.6672s	
1706/33150 (epoch 2.573), train_loss = 1.41668281, grad/param norm = 1.9373e-01, time/batch = 0.6872s	
1707/33150 (epoch 2.575), train_loss = 1.80971867, grad/param norm = 2.2015e-01, time/batch = 0.6805s	
1708/33150 (epoch 2.576), train_loss = 1.50217684, grad/param norm = 2.0456e-01, time/batch = 0.6796s	
1709/33150 (epoch 2.578), train_loss = 1.74361135, grad/param norm = 2.3344e-01, time/batch = 0.6724s	
1710/33150 (epoch 2.579), train_loss = 1.66483451, grad/param norm = 2.6984e-01, time/batch = 0.6656s	
1711/33150 (epoch 2.581), train_loss = 1.57176137, grad/param norm = 2.2887e-01, time/batch = 0.6761s	
1712/33150 (epoch 2.582), train_loss = 1.67145217, grad/param norm = 2.3677e-01, time/batch = 0.6686s	
1713/33150 (epoch 2.584), train_loss = 1.82519176, grad/param norm = 2.2130e-01, time/batch = 0.6688s	
1714/33150 (epoch 2.585), train_loss = 1.74188925, grad/param norm = 2.1050e-01, time/batch = 0.6705s	
1715/33150 (epoch 2.587), train_loss = 1.76670489, grad/param norm = 2.2358e-01, time/batch = 0.6698s	
1716/33150 (epoch 2.588), train_loss = 1.60702532, grad/param norm = 2.4586e-01, time/batch = 0.6697s	
1717/33150 (epoch 2.590), train_loss = 1.79718159, grad/param norm = 2.3988e-01, time/batch = 0.6714s	
1718/33150 (epoch 2.591), train_loss = 1.80742415, grad/param norm = 2.4229e-01, time/batch = 0.6683s	
1719/33150 (epoch 2.593), train_loss = 1.80586730, grad/param norm = 2.2811e-01, time/batch = 0.6685s	
1720/33150 (epoch 2.594), train_loss = 1.80746942, grad/param norm = 2.5436e-01, time/batch = 0.6715s	
1721/33150 (epoch 2.596), train_loss = 1.52926701, grad/param norm = 2.1807e-01, time/batch = 0.6693s	
1722/33150 (epoch 2.597), train_loss = 1.74042156, grad/param norm = 2.6928e-01, time/batch = 0.6706s	
1723/33150 (epoch 2.599), train_loss = 1.91448378, grad/param norm = 2.5106e-01, time/batch = 0.6684s	
1724/33150 (epoch 2.600), train_loss = 1.81181422, grad/param norm = 2.7929e-01, time/batch = 0.6670s	
1725/33150 (epoch 2.602), train_loss = 1.65835379, grad/param norm = 2.5534e-01, time/batch = 0.6655s	
1726/33150 (epoch 2.603), train_loss = 1.62303635, grad/param norm = 2.1699e-01, time/batch = 0.6668s	
1727/33150 (epoch 2.605), train_loss = 1.65173638, grad/param norm = 2.1537e-01, time/batch = 0.6675s	
1728/33150 (epoch 2.606), train_loss = 1.76612145, grad/param norm = 2.3209e-01, time/batch = 0.6672s	
1729/33150 (epoch 2.608), train_loss = 1.79134708, grad/param norm = 2.6390e-01, time/batch = 0.6662s	
1730/33150 (epoch 2.609), train_loss = 1.74980516, grad/param norm = 2.6623e-01, time/batch = 0.6727s	
1731/33150 (epoch 2.611), train_loss = 1.56095172, grad/param norm = 2.4050e-01, time/batch = 0.6675s	
1732/33150 (epoch 2.612), train_loss = 1.75371572, grad/param norm = 2.3684e-01, time/batch = 0.6644s	
1733/33150 (epoch 2.614), train_loss = 1.47694425, grad/param norm = 2.0774e-01, time/batch = 0.6645s	
1734/33150 (epoch 2.615), train_loss = 1.54794539, grad/param norm = 2.2861e-01, time/batch = 0.6623s	
1735/33150 (epoch 2.617), train_loss = 1.64667447, grad/param norm = 2.4646e-01, time/batch = 0.6639s	
1736/33150 (epoch 2.618), train_loss = 1.59548221, grad/param norm = 2.3575e-01, time/batch = 0.6621s	
1737/33150 (epoch 2.620), train_loss = 1.62333882, grad/param norm = 2.6191e-01, time/batch = 0.6617s	
1738/33150 (epoch 2.621), train_loss = 1.63407358, grad/param norm = 2.3600e-01, time/batch = 0.6626s	
1739/33150 (epoch 2.623), train_loss = 1.75866842, grad/param norm = 2.5088e-01, time/batch = 0.6625s	
1740/33150 (epoch 2.624), train_loss = 1.73607966, grad/param norm = 2.5424e-01, time/batch = 0.6644s	
1741/33150 (epoch 2.626), train_loss = 1.50884642, grad/param norm = 2.4131e-01, time/batch = 0.6669s	
1742/33150 (epoch 2.627), train_loss = 1.57716026, grad/param norm = 2.6838e-01, time/batch = 0.6659s	
1743/33150 (epoch 2.629), train_loss = 1.55318064, grad/param norm = 2.2207e-01, time/batch = 0.6652s	
1744/33150 (epoch 2.630), train_loss = 1.57100251, grad/param norm = 2.2723e-01, time/batch = 0.6663s	
1745/33150 (epoch 2.632), train_loss = 1.48056297, grad/param norm = 2.1756e-01, time/batch = 0.6660s	
1746/33150 (epoch 2.633), train_loss = 1.50300804, grad/param norm = 2.1223e-01, time/batch = 0.6686s	
1747/33150 (epoch 2.635), train_loss = 1.85406242, grad/param norm = 2.2745e-01, time/batch = 0.6681s	
1748/33150 (epoch 2.637), train_loss = 1.54887870, grad/param norm = 2.4133e-01, time/batch = 0.6673s	
1749/33150 (epoch 2.638), train_loss = 1.61894232, grad/param norm = 2.4913e-01, time/batch = 0.6801s	
1750/33150 (epoch 2.640), train_loss = 1.83134077, grad/param norm = 2.9980e-01, time/batch = 0.6856s	
1751/33150 (epoch 2.641), train_loss = 1.60411747, grad/param norm = 2.2003e-01, time/batch = 0.6926s	
1752/33150 (epoch 2.643), train_loss = 1.55420444, grad/param norm = 2.1477e-01, time/batch = 0.6982s	
1753/33150 (epoch 2.644), train_loss = 1.81333453, grad/param norm = 2.2113e-01, time/batch = 0.6928s	
1754/33150 (epoch 2.646), train_loss = 1.60581957, grad/param norm = 2.1106e-01, time/batch = 0.6902s	
1755/33150 (epoch 2.647), train_loss = 2.07894359, grad/param norm = 2.6251e-01, time/batch = 0.6876s	
1756/33150 (epoch 2.649), train_loss = 1.80770296, grad/param norm = 2.4860e-01, time/batch = 0.6937s	
1757/33150 (epoch 2.650), train_loss = 1.61581660, grad/param norm = 2.4609e-01, time/batch = 0.6914s	
1758/33150 (epoch 2.652), train_loss = 1.73806979, grad/param norm = 2.1994e-01, time/batch = 0.6762s	
1759/33150 (epoch 2.653), train_loss = 1.68781090, grad/param norm = 2.2125e-01, time/batch = 0.6687s	
1760/33150 (epoch 2.655), train_loss = 1.67281657, grad/param norm = 2.2048e-01, time/batch = 0.6697s	
1761/33150 (epoch 2.656), train_loss = 1.62939508, grad/param norm = 2.1341e-01, time/batch = 0.6677s	
1762/33150 (epoch 2.658), train_loss = 1.75635446, grad/param norm = 2.6197e-01, time/batch = 0.6678s	
1763/33150 (epoch 2.659), train_loss = 2.27322658, grad/param norm = 5.2148e-01, time/batch = 0.6663s	
1764/33150 (epoch 2.661), train_loss = 1.74619775, grad/param norm = 3.7401e-01, time/batch = 0.6705s	
1765/33150 (epoch 2.662), train_loss = 1.62668058, grad/param norm = 2.2855e-01, time/batch = 0.6645s	
1766/33150 (epoch 2.664), train_loss = 1.77568951, grad/param norm = 2.6260e-01, time/batch = 0.6791s	
1767/33150 (epoch 2.665), train_loss = 1.74201043, grad/param norm = 2.2838e-01, time/batch = 0.6763s	
1768/33150 (epoch 2.667), train_loss = 1.97249599, grad/param norm = 2.1298e-01, time/batch = 0.6679s	
1769/33150 (epoch 2.668), train_loss = 1.75686497, grad/param norm = 2.3653e-01, time/batch = 0.6704s	
1770/33150 (epoch 2.670), train_loss = 1.61020037, grad/param norm = 2.1093e-01, time/batch = 0.6716s	
1771/33150 (epoch 2.671), train_loss = 1.69152468, grad/param norm = 2.4748e-01, time/batch = 0.6713s	
1772/33150 (epoch 2.673), train_loss = 1.79622873, grad/param norm = 2.1081e-01, time/batch = 0.6690s	
1773/33150 (epoch 2.674), train_loss = 1.68642692, grad/param norm = 2.0433e-01, time/batch = 0.6683s	
1774/33150 (epoch 2.676), train_loss = 1.63863928, grad/param norm = 2.1695e-01, time/batch = 0.6844s	
1775/33150 (epoch 2.677), train_loss = 2.01157754, grad/param norm = 2.5768e-01, time/batch = 0.6823s	
1776/33150 (epoch 2.679), train_loss = 1.49923414, grad/param norm = 1.9402e-01, time/batch = 0.6806s	
1777/33150 (epoch 2.680), train_loss = 1.78334584, grad/param norm = 2.2089e-01, time/batch = 0.6868s	
1778/33150 (epoch 2.682), train_loss = 1.55531657, grad/param norm = 2.4205e-01, time/batch = 0.6653s	
1779/33150 (epoch 2.683), train_loss = 1.56145040, grad/param norm = 2.2085e-01, time/batch = 0.6658s	
1780/33150 (epoch 2.685), train_loss = 1.78235039, grad/param norm = 2.1743e-01, time/batch = 0.6651s	
1781/33150 (epoch 2.686), train_loss = 1.55199397, grad/param norm = 2.3546e-01, time/batch = 0.6677s	
1782/33150 (epoch 2.688), train_loss = 1.68629295, grad/param norm = 2.5303e-01, time/batch = 0.6704s	
1783/33150 (epoch 2.689), train_loss = 1.63780947, grad/param norm = 2.5500e-01, time/batch = 0.6662s	
1784/33150 (epoch 2.691), train_loss = 1.41198393, grad/param norm = 2.0138e-01, time/batch = 0.6686s	
1785/33150 (epoch 2.692), train_loss = 1.62170563, grad/param norm = 2.2999e-01, time/batch = 0.6835s	
1786/33150 (epoch 2.694), train_loss = 1.47403308, grad/param norm = 1.9400e-01, time/batch = 0.6866s	
1787/33150 (epoch 2.695), train_loss = 1.64504916, grad/param norm = 2.1251e-01, time/batch = 0.6670s	
1788/33150 (epoch 2.697), train_loss = 1.51169570, grad/param norm = 2.1227e-01, time/batch = 0.6640s	
1789/33150 (epoch 2.698), train_loss = 1.86661625, grad/param norm = 2.2290e-01, time/batch = 0.6633s	
1790/33150 (epoch 2.700), train_loss = 1.38996195, grad/param norm = 2.3011e-01, time/batch = 0.6635s	
1791/33150 (epoch 2.701), train_loss = 1.62103299, grad/param norm = 2.4158e-01, time/batch = 0.6667s	
1792/33150 (epoch 2.703), train_loss = 1.77865856, grad/param norm = 2.4166e-01, time/batch = 0.6635s	
1793/33150 (epoch 2.704), train_loss = 1.51112355, grad/param norm = 2.3164e-01, time/batch = 0.6654s	
1794/33150 (epoch 2.706), train_loss = 1.67253618, grad/param norm = 2.1370e-01, time/batch = 0.6665s	
1795/33150 (epoch 2.707), train_loss = 1.66006905, grad/param norm = 2.4229e-01, time/batch = 0.6640s	
1796/33150 (epoch 2.709), train_loss = 1.64283451, grad/param norm = 2.1312e-01, time/batch = 0.6678s	
1797/33150 (epoch 2.710), train_loss = 1.87145461, grad/param norm = 2.6266e-01, time/batch = 0.6682s	
1798/33150 (epoch 2.712), train_loss = 1.83042733, grad/param norm = 2.4621e-01, time/batch = 0.6664s	
1799/33150 (epoch 2.713), train_loss = 1.68127169, grad/param norm = 2.3106e-01, time/batch = 0.6681s	
1800/33150 (epoch 2.715), train_loss = 1.59592907, grad/param norm = 2.1773e-01, time/batch = 0.6739s	
1801/33150 (epoch 2.716), train_loss = 1.69412848, grad/param norm = 2.2194e-01, time/batch = 0.6784s	
1802/33150 (epoch 2.718), train_loss = 1.69530180, grad/param norm = 2.0338e-01, time/batch = 0.6706s	
1803/33150 (epoch 2.719), train_loss = 1.80549643, grad/param norm = 2.5367e-01, time/batch = 0.6720s	
1804/33150 (epoch 2.721), train_loss = 1.77747309, grad/param norm = 2.7980e-01, time/batch = 0.6944s	
1805/33150 (epoch 2.722), train_loss = 1.64414659, grad/param norm = 2.0956e-01, time/batch = 0.6898s	
1806/33150 (epoch 2.724), train_loss = 1.70114458, grad/param norm = 2.1952e-01, time/batch = 0.6887s	
1807/33150 (epoch 2.725), train_loss = 1.92081504, grad/param norm = 2.5120e-01, time/batch = 0.7071s	
1808/33150 (epoch 2.727), train_loss = 1.83600362, grad/param norm = 2.2843e-01, time/batch = 0.6923s	
1809/33150 (epoch 2.729), train_loss = 1.71777046, grad/param norm = 2.1419e-01, time/batch = 0.7026s	
1810/33150 (epoch 2.730), train_loss = 1.63301755, grad/param norm = 2.1956e-01, time/batch = 0.7035s	
1811/33150 (epoch 2.732), train_loss = 1.75926404, grad/param norm = 2.0755e-01, time/batch = 0.7082s	
1812/33150 (epoch 2.733), train_loss = 1.45354331, grad/param norm = 2.1474e-01, time/batch = 0.7020s	
1813/33150 (epoch 2.735), train_loss = 1.66387429, grad/param norm = 2.2016e-01, time/batch = 0.6999s	
1814/33150 (epoch 2.736), train_loss = 1.46799512, grad/param norm = 2.0202e-01, time/batch = 0.6760s	
1815/33150 (epoch 2.738), train_loss = 1.76333231, grad/param norm = 2.2283e-01, time/batch = 0.6797s	
1816/33150 (epoch 2.739), train_loss = 1.95915362, grad/param norm = 2.5928e-01, time/batch = 0.6712s	
1817/33150 (epoch 2.741), train_loss = 1.77076054, grad/param norm = 2.5858e-01, time/batch = 0.6692s	
1818/33150 (epoch 2.742), train_loss = 1.70225102, grad/param norm = 2.6146e-01, time/batch = 0.6667s	
1819/33150 (epoch 2.744), train_loss = 1.82676611, grad/param norm = 2.3746e-01, time/batch = 0.6676s	
1820/33150 (epoch 2.745), train_loss = 1.72295854, grad/param norm = 2.1951e-01, time/batch = 0.6678s	
1821/33150 (epoch 2.747), train_loss = 1.51139678, grad/param norm = 2.0761e-01, time/batch = 0.6684s	
1822/33150 (epoch 2.748), train_loss = 1.64121584, grad/param norm = 2.1547e-01, time/batch = 0.6666s	
1823/33150 (epoch 2.750), train_loss = 1.72666904, grad/param norm = 2.4048e-01, time/batch = 0.6669s	
1824/33150 (epoch 2.751), train_loss = 1.68053197, grad/param norm = 2.3986e-01, time/batch = 0.6667s	
1825/33150 (epoch 2.753), train_loss = 1.48667496, grad/param norm = 2.4808e-01, time/batch = 0.6693s	
1826/33150 (epoch 2.754), train_loss = 1.91705734, grad/param norm = 2.4680e-01, time/batch = 0.6651s	
1827/33150 (epoch 2.756), train_loss = 1.70598298, grad/param norm = 2.2640e-01, time/batch = 0.6640s	
1828/33150 (epoch 2.757), train_loss = 1.78343277, grad/param norm = 2.3045e-01, time/batch = 0.6640s	
1829/33150 (epoch 2.759), train_loss = 1.87010194, grad/param norm = 2.4580e-01, time/batch = 0.6693s	
1830/33150 (epoch 2.760), train_loss = 1.69686261, grad/param norm = 2.2526e-01, time/batch = 0.6796s	
1831/33150 (epoch 2.762), train_loss = 1.77739384, grad/param norm = 2.2373e-01, time/batch = 0.6707s	
1832/33150 (epoch 2.763), train_loss = 1.55796476, grad/param norm = 2.1718e-01, time/batch = 0.6657s	
1833/33150 (epoch 2.765), train_loss = 1.64192085, grad/param norm = 2.0019e-01, time/batch = 0.6666s	
1834/33150 (epoch 2.766), train_loss = 1.60441041, grad/param norm = 2.0530e-01, time/batch = 0.6650s	
1835/33150 (epoch 2.768), train_loss = 1.56621176, grad/param norm = 2.1387e-01, time/batch = 0.6618s	
1836/33150 (epoch 2.769), train_loss = 1.67165866, grad/param norm = 2.3282e-01, time/batch = 0.6643s	
1837/33150 (epoch 2.771), train_loss = 1.69552345, grad/param norm = 2.3944e-01, time/batch = 0.6671s	
1838/33150 (epoch 2.772), train_loss = 1.72330587, grad/param norm = 2.4257e-01, time/batch = 0.6825s	
1839/33150 (epoch 2.774), train_loss = 1.83558950, grad/param norm = 2.2674e-01, time/batch = 0.6856s	
1840/33150 (epoch 2.775), train_loss = 1.73136332, grad/param norm = 2.5226e-01, time/batch = 0.6870s	
1841/33150 (epoch 2.777), train_loss = 1.80927162, grad/param norm = 2.0880e-01, time/batch = 0.6622s	
1842/33150 (epoch 2.778), train_loss = 1.74459637, grad/param norm = 2.0844e-01, time/batch = 0.6653s	
1843/33150 (epoch 2.780), train_loss = 1.54105529, grad/param norm = 2.2210e-01, time/batch = 0.6671s	
1844/33150 (epoch 2.781), train_loss = 1.66881763, grad/param norm = 2.1966e-01, time/batch = 0.6623s	
1845/33150 (epoch 2.783), train_loss = 1.64142713, grad/param norm = 2.0280e-01, time/batch = 0.6672s	
1846/33150 (epoch 2.784), train_loss = 1.60666820, grad/param norm = 2.1459e-01, time/batch = 0.6647s	
1847/33150 (epoch 2.786), train_loss = 1.67277737, grad/param norm = 2.1518e-01, time/batch = 0.6622s	
1848/33150 (epoch 2.787), train_loss = 1.68427430, grad/param norm = 2.0497e-01, time/batch = 0.6705s	
1849/33150 (epoch 2.789), train_loss = 1.53831032, grad/param norm = 2.0985e-01, time/batch = 0.6801s	
1850/33150 (epoch 2.790), train_loss = 1.43246575, grad/param norm = 2.0857e-01, time/batch = 0.6751s	
1851/33150 (epoch 2.792), train_loss = 1.80520602, grad/param norm = 2.5916e-01, time/batch = 0.6704s	
1852/33150 (epoch 2.793), train_loss = 1.63211014, grad/param norm = 2.1661e-01, time/batch = 0.6735s	
1853/33150 (epoch 2.795), train_loss = 1.67076733, grad/param norm = 2.5318e-01, time/batch = 0.6711s	
1854/33150 (epoch 2.796), train_loss = 1.57339065, grad/param norm = 1.9611e-01, time/batch = 0.6775s	
1855/33150 (epoch 2.798), train_loss = 1.62941113, grad/param norm = 2.0481e-01, time/batch = 0.6880s	
1856/33150 (epoch 2.799), train_loss = 1.58298784, grad/param norm = 2.4695e-01, time/batch = 0.6651s	
1857/33150 (epoch 2.801), train_loss = 1.56985519, grad/param norm = 1.9525e-01, time/batch = 0.6686s	
1858/33150 (epoch 2.802), train_loss = 1.60496623, grad/param norm = 2.3056e-01, time/batch = 0.6686s	
1859/33150 (epoch 2.804), train_loss = 1.69181049, grad/param norm = 2.1853e-01, time/batch = 0.6690s	
1860/33150 (epoch 2.805), train_loss = 1.67858188, grad/param norm = 2.8210e-01, time/batch = 0.6694s	
1861/33150 (epoch 2.807), train_loss = 1.58807053, grad/param norm = 2.7032e-01, time/batch = 0.6657s	
1862/33150 (epoch 2.808), train_loss = 1.71394640, grad/param norm = 2.2193e-01, time/batch = 0.6668s	
1863/33150 (epoch 2.810), train_loss = 1.63456680, grad/param norm = 2.4323e-01, time/batch = 0.6676s	
1864/33150 (epoch 2.811), train_loss = 1.67210683, grad/param norm = 2.2971e-01, time/batch = 0.6708s	
1865/33150 (epoch 2.813), train_loss = 1.70001350, grad/param norm = 2.1653e-01, time/batch = 0.6668s	
1866/33150 (epoch 2.814), train_loss = 1.73965237, grad/param norm = 2.5399e-01, time/batch = 0.6670s	
1867/33150 (epoch 2.816), train_loss = 1.74942136, grad/param norm = 2.4248e-01, time/batch = 0.6683s	
1868/33150 (epoch 2.817), train_loss = 1.75720678, grad/param norm = 2.3341e-01, time/batch = 0.6676s	
1869/33150 (epoch 2.819), train_loss = 1.57736673, grad/param norm = 2.2593e-01, time/batch = 0.6682s	
1870/33150 (epoch 2.821), train_loss = 1.40247951, grad/param norm = 1.9849e-01, time/batch = 0.6685s	
1871/33150 (epoch 2.822), train_loss = 1.60113565, grad/param norm = 2.3516e-01, time/batch = 0.6653s	
1872/33150 (epoch 2.824), train_loss = 1.62541995, grad/param norm = 2.3425e-01, time/batch = 0.6668s	
1873/33150 (epoch 2.825), train_loss = 1.67281377, grad/param norm = 2.3931e-01, time/batch = 0.6667s	
1874/33150 (epoch 2.827), train_loss = 1.76393879, grad/param norm = 2.6021e-01, time/batch = 0.6685s	
1875/33150 (epoch 2.828), train_loss = 1.54254482, grad/param norm = 2.3497e-01, time/batch = 0.6922s	
1876/33150 (epoch 2.830), train_loss = 1.63324668, grad/param norm = 2.3677e-01, time/batch = 0.6834s	
1877/33150 (epoch 2.831), train_loss = 1.55570994, grad/param norm = 2.1427e-01, time/batch = 0.6683s	
1878/33150 (epoch 2.833), train_loss = 1.57023789, grad/param norm = 2.3053e-01, time/batch = 0.6930s	
1879/33150 (epoch 2.834), train_loss = 1.80663695, grad/param norm = 2.2086e-01, time/batch = 0.6850s	
1880/33150 (epoch 2.836), train_loss = 1.80745074, grad/param norm = 2.4068e-01, time/batch = 0.6846s	
1881/33150 (epoch 2.837), train_loss = 1.62446830, grad/param norm = 2.4459e-01, time/batch = 0.6685s	
1882/33150 (epoch 2.839), train_loss = 1.88536074, grad/param norm = 2.5287e-01, time/batch = 0.6758s	
1883/33150 (epoch 2.840), train_loss = 1.74390195, grad/param norm = 2.4721e-01, time/batch = 0.6677s	
1884/33150 (epoch 2.842), train_loss = 1.77662019, grad/param norm = 2.5124e-01, time/batch = 0.6686s	
1885/33150 (epoch 2.843), train_loss = 1.71590051, grad/param norm = 2.7220e-01, time/batch = 0.6653s	
1886/33150 (epoch 2.845), train_loss = 1.60354250, grad/param norm = 2.0453e-01, time/batch = 0.6619s	
1887/33150 (epoch 2.846), train_loss = 1.99862996, grad/param norm = 2.5131e-01, time/batch = 0.6659s	
1888/33150 (epoch 2.848), train_loss = 1.78047217, grad/param norm = 2.0869e-01, time/batch = 0.6651s	
1889/33150 (epoch 2.849), train_loss = 1.67937693, grad/param norm = 2.2498e-01, time/batch = 0.6620s	
1890/33150 (epoch 2.851), train_loss = 1.81442978, grad/param norm = 2.7310e-01, time/batch = 0.6686s	
1891/33150 (epoch 2.852), train_loss = 1.81161390, grad/param norm = 2.5357e-01, time/batch = 0.6680s	
1892/33150 (epoch 2.854), train_loss = 1.72722747, grad/param norm = 2.3211e-01, time/batch = 0.6674s	
1893/33150 (epoch 2.855), train_loss = 1.40621874, grad/param norm = 1.9565e-01, time/batch = 0.6742s	
1894/33150 (epoch 2.857), train_loss = 1.58428912, grad/param norm = 1.9987e-01, time/batch = 0.6785s	
1895/33150 (epoch 2.858), train_loss = 1.55966290, grad/param norm = 2.1583e-01, time/batch = 0.6681s	
1896/33150 (epoch 2.860), train_loss = 1.64489495, grad/param norm = 2.2110e-01, time/batch = 0.6681s	
1897/33150 (epoch 2.861), train_loss = 1.60866837, grad/param norm = 2.1705e-01, time/batch = 0.6683s	
1898/33150 (epoch 2.863), train_loss = 1.70125683, grad/param norm = 2.0580e-01, time/batch = 0.6687s	
1899/33150 (epoch 2.864), train_loss = 1.89149855, grad/param norm = 2.4458e-01, time/batch = 0.6676s	
1900/33150 (epoch 2.866), train_loss = 1.66156596, grad/param norm = 2.2621e-01, time/batch = 0.6650s	
1901/33150 (epoch 2.867), train_loss = 1.77428966, grad/param norm = 2.4474e-01, time/batch = 0.6647s	
1902/33150 (epoch 2.869), train_loss = 1.78057712, grad/param norm = 2.3178e-01, time/batch = 0.6666s	
1903/33150 (epoch 2.870), train_loss = 1.78507314, grad/param norm = 2.1426e-01, time/batch = 0.6676s	
1904/33150 (epoch 2.872), train_loss = 1.77408050, grad/param norm = 2.9294e-01, time/batch = 0.6678s	
1905/33150 (epoch 2.873), train_loss = 1.45402342, grad/param norm = 2.1991e-01, time/batch = 0.6642s	
1906/33150 (epoch 2.875), train_loss = 1.88507742, grad/param norm = 2.5053e-01, time/batch = 0.6640s	
1907/33150 (epoch 2.876), train_loss = 1.68272642, grad/param norm = 2.3947e-01, time/batch = 0.6646s	
1908/33150 (epoch 2.878), train_loss = 1.55905453, grad/param norm = 2.0972e-01, time/batch = 0.6668s	
1909/33150 (epoch 2.879), train_loss = 1.65123991, grad/param norm = 2.2356e-01, time/batch = 0.6698s	
1910/33150 (epoch 2.881), train_loss = 1.67862237, grad/param norm = 2.2848e-01, time/batch = 0.6702s	
1911/33150 (epoch 2.882), train_loss = 1.64277416, grad/param norm = 2.0527e-01, time/batch = 0.6664s	
1912/33150 (epoch 2.884), train_loss = 1.75542341, grad/param norm = 2.3144e-01, time/batch = 0.6694s	
1913/33150 (epoch 2.885), train_loss = 1.43366565, grad/param norm = 2.1651e-01, time/batch = 0.6806s	
1914/33150 (epoch 2.887), train_loss = 1.86548401, grad/param norm = 2.6132e-01, time/batch = 0.6697s	
1915/33150 (epoch 2.888), train_loss = 1.74617687, grad/param norm = 2.3249e-01, time/batch = 0.6631s	
1916/33150 (epoch 2.890), train_loss = 1.59281131, grad/param norm = 2.0880e-01, time/batch = 0.6673s	
1917/33150 (epoch 2.891), train_loss = 1.65392854, grad/param norm = 2.1602e-01, time/batch = 0.6667s	
1918/33150 (epoch 2.893), train_loss = 1.79642127, grad/param norm = 2.3939e-01, time/batch = 0.6663s	
1919/33150 (epoch 2.894), train_loss = 1.82219081, grad/param norm = 2.9605e-01, time/batch = 0.6646s	
1920/33150 (epoch 2.896), train_loss = 1.70680156, grad/param norm = 2.8546e-01, time/batch = 0.6664s	
1921/33150 (epoch 2.897), train_loss = 1.69610017, grad/param norm = 2.0717e-01, time/batch = 0.6643s	
1922/33150 (epoch 2.899), train_loss = 1.54567822, grad/param norm = 2.0380e-01, time/batch = 0.6648s	
1923/33150 (epoch 2.900), train_loss = 1.91794837, grad/param norm = 2.5713e-01, time/batch = 0.6734s	
1924/33150 (epoch 2.902), train_loss = 1.90399927, grad/param norm = 2.6474e-01, time/batch = 0.6707s	
1925/33150 (epoch 2.903), train_loss = 1.64659708, grad/param norm = 2.2386e-01, time/batch = 0.6704s	
1926/33150 (epoch 2.905), train_loss = 1.66181064, grad/param norm = 2.2831e-01, time/batch = 0.6692s	
1927/33150 (epoch 2.906), train_loss = 1.61731894, grad/param norm = 2.0357e-01, time/batch = 0.6833s	
1928/33150 (epoch 2.908), train_loss = 1.84902804, grad/param norm = 2.1612e-01, time/batch = 0.6822s	
1929/33150 (epoch 2.910), train_loss = 1.77708155, grad/param norm = 2.4804e-01, time/batch = 0.6782s	
1930/33150 (epoch 2.911), train_loss = 1.61450654, grad/param norm = 2.4513e-01, time/batch = 0.6716s	
1931/33150 (epoch 2.913), train_loss = 1.56993332, grad/param norm = 2.2687e-01, time/batch = 0.6659s	
1932/33150 (epoch 2.914), train_loss = 1.85086685, grad/param norm = 2.3421e-01, time/batch = 0.6700s	
1933/33150 (epoch 2.916), train_loss = 1.51048452, grad/param norm = 2.0960e-01, time/batch = 0.6705s	
1934/33150 (epoch 2.917), train_loss = 1.84482574, grad/param norm = 2.4311e-01, time/batch = 0.6813s	
1935/33150 (epoch 2.919), train_loss = 1.85122802, grad/param norm = 2.4900e-01, time/batch = 0.6735s	
1936/33150 (epoch 2.920), train_loss = 1.68614076, grad/param norm = 1.9778e-01, time/batch = 0.6633s	
1937/33150 (epoch 2.922), train_loss = 1.92876072, grad/param norm = 2.3108e-01, time/batch = 0.6842s	
1938/33150 (epoch 2.923), train_loss = 1.63539775, grad/param norm = 2.3535e-01, time/batch = 0.6794s	
1939/33150 (epoch 2.925), train_loss = 1.69837244, grad/param norm = 2.4397e-01, time/batch = 0.6806s	
1940/33150 (epoch 2.926), train_loss = 1.66472862, grad/param norm = 2.3638e-01, time/batch = 0.6802s	
1941/33150 (epoch 2.928), train_loss = 1.63133810, grad/param norm = 2.2500e-01, time/batch = 0.6821s	
1942/33150 (epoch 2.929), train_loss = 1.78441400, grad/param norm = 2.3100e-01, time/batch = 0.6828s	
1943/33150 (epoch 2.931), train_loss = 1.83125363, grad/param norm = 2.7427e-01, time/batch = 0.6781s	
1944/33150 (epoch 2.932), train_loss = 1.73509606, grad/param norm = 2.6751e-01, time/batch = 0.6698s	
1945/33150 (epoch 2.934), train_loss = 1.65184048, grad/param norm = 2.2244e-01, time/batch = 0.6661s	
1946/33150 (epoch 2.935), train_loss = 1.73450178, grad/param norm = 2.0798e-01, time/batch = 0.6677s	
1947/33150 (epoch 2.937), train_loss = 1.80197155, grad/param norm = 2.1999e-01, time/batch = 0.6685s	
1948/33150 (epoch 2.938), train_loss = 1.73220217, grad/param norm = 2.1974e-01, time/batch = 0.6708s	
1949/33150 (epoch 2.940), train_loss = 1.98901167, grad/param norm = 2.2535e-01, time/batch = 0.6697s	
1950/33150 (epoch 2.941), train_loss = 1.63910728, grad/param norm = 1.9852e-01, time/batch = 0.6681s	
1951/33150 (epoch 2.943), train_loss = 1.67481790, grad/param norm = 2.3317e-01, time/batch = 0.6937s	
1952/33150 (epoch 2.944), train_loss = 1.82635469, grad/param norm = 2.2462e-01, time/batch = 0.6893s	
1953/33150 (epoch 2.946), train_loss = 1.50186207, grad/param norm = 2.2225e-01, time/batch = 0.6822s	
1954/33150 (epoch 2.947), train_loss = 1.71738766, grad/param norm = 2.1960e-01, time/batch = 0.6853s	
1955/33150 (epoch 2.949), train_loss = 1.88423844, grad/param norm = 3.3015e-01, time/batch = 0.6870s	
1956/33150 (epoch 2.950), train_loss = 1.80348544, grad/param norm = 2.5966e-01, time/batch = 0.6888s	
1957/33150 (epoch 2.952), train_loss = 1.63461430, grad/param norm = 2.6942e-01, time/batch = 0.6814s	
1958/33150 (epoch 2.953), train_loss = 1.55447924, grad/param norm = 2.1242e-01, time/batch = 0.6867s	
1959/33150 (epoch 2.955), train_loss = 1.58477065, grad/param norm = 2.0175e-01, time/batch = 0.6816s	
1960/33150 (epoch 2.956), train_loss = 1.81318513, grad/param norm = 2.3652e-01, time/batch = 0.6863s	
1961/33150 (epoch 2.958), train_loss = 1.54666939, grad/param norm = 2.1617e-01, time/batch = 0.6827s	
1962/33150 (epoch 2.959), train_loss = 1.50953383, grad/param norm = 2.2576e-01, time/batch = 0.6794s	
1963/33150 (epoch 2.961), train_loss = 1.61704280, grad/param norm = 2.1487e-01, time/batch = 0.6672s	
1964/33150 (epoch 2.962), train_loss = 1.46529423, grad/param norm = 2.0340e-01, time/batch = 0.6658s	
1965/33150 (epoch 2.964), train_loss = 1.65665344, grad/param norm = 1.9483e-01, time/batch = 0.6688s	
1966/33150 (epoch 2.965), train_loss = 1.70252730, grad/param norm = 2.0848e-01, time/batch = 0.6693s	
1967/33150 (epoch 2.967), train_loss = 1.76396096, grad/param norm = 2.5503e-01, time/batch = 0.6665s	
1968/33150 (epoch 2.968), train_loss = 1.51529994, grad/param norm = 2.4608e-01, time/batch = 0.6684s	
1969/33150 (epoch 2.970), train_loss = 1.57201958, grad/param norm = 2.1029e-01, time/batch = 0.6685s	
1970/33150 (epoch 2.971), train_loss = 1.76177700, grad/param norm = 2.4940e-01, time/batch = 0.6679s	
1971/33150 (epoch 2.973), train_loss = 1.75736538, grad/param norm = 2.2056e-01, time/batch = 0.6714s	
1972/33150 (epoch 2.974), train_loss = 1.86856957, grad/param norm = 2.3798e-01, time/batch = 0.6714s	
1973/33150 (epoch 2.976), train_loss = 1.70657718, grad/param norm = 2.1227e-01, time/batch = 0.6678s	
1974/33150 (epoch 2.977), train_loss = 1.82038302, grad/param norm = 2.2500e-01, time/batch = 0.6898s	
1975/33150 (epoch 2.979), train_loss = 1.79689321, grad/param norm = 2.5581e-01, time/batch = 0.6899s	
1976/33150 (epoch 2.980), train_loss = 1.79549590, grad/param norm = 2.4466e-01, time/batch = 0.6800s	
1977/33150 (epoch 2.982), train_loss = 1.63624089, grad/param norm = 2.3251e-01, time/batch = 0.6673s	
1978/33150 (epoch 2.983), train_loss = 1.64629646, grad/param norm = 2.5688e-01, time/batch = 0.6650s	
1979/33150 (epoch 2.985), train_loss = 1.73497367, grad/param norm = 2.3783e-01, time/batch = 0.6641s	
1980/33150 (epoch 2.986), train_loss = 1.58559944, grad/param norm = 2.1065e-01, time/batch = 0.6639s	
1981/33150 (epoch 2.988), train_loss = 1.67926551, grad/param norm = 2.2322e-01, time/batch = 0.6652s	
1982/33150 (epoch 2.989), train_loss = 1.55737949, grad/param norm = 2.1705e-01, time/batch = 0.6636s	
1983/33150 (epoch 2.991), train_loss = 1.78915009, grad/param norm = 2.5404e-01, time/batch = 0.6648s	
1984/33150 (epoch 2.992), train_loss = 1.47197414, grad/param norm = 2.3039e-01, time/batch = 0.6647s	
1985/33150 (epoch 2.994), train_loss = 1.60374091, grad/param norm = 2.0114e-01, time/batch = 0.6641s	
1986/33150 (epoch 2.995), train_loss = 1.55378226, grad/param norm = 2.2299e-01, time/batch = 0.6656s	
1987/33150 (epoch 2.997), train_loss = 1.74021498, grad/param norm = 2.1744e-01, time/batch = 0.6655s	
1988/33150 (epoch 2.998), train_loss = 1.37729288, grad/param norm = 1.9449e-01, time/batch = 0.6642s	
1989/33150 (epoch 3.000), train_loss = 1.65486639, grad/param norm = 2.6971e-01, time/batch = 0.6695s	
1990/33150 (epoch 3.002), train_loss = 1.78947235, grad/param norm = 2.2511e-01, time/batch = 0.6668s	
1991/33150 (epoch 3.003), train_loss = 1.63041725, grad/param norm = 2.2417e-01, time/batch = 0.6685s	
1992/33150 (epoch 3.005), train_loss = 1.46690661, grad/param norm = 2.1257e-01, time/batch = 0.6657s	
1993/33150 (epoch 3.006), train_loss = 1.39983189, grad/param norm = 2.0783e-01, time/batch = 0.6661s	
1994/33150 (epoch 3.008), train_loss = 1.67335657, grad/param norm = 2.1162e-01, time/batch = 0.6659s	
1995/33150 (epoch 3.009), train_loss = 1.64811193, grad/param norm = 1.9782e-01, time/batch = 0.6643s	
1996/33150 (epoch 3.011), train_loss = 1.95356713, grad/param norm = 2.2543e-01, time/batch = 0.6654s	
1997/33150 (epoch 3.012), train_loss = 1.62381857, grad/param norm = 2.1248e-01, time/batch = 0.6665s	
1998/33150 (epoch 3.014), train_loss = 1.69637943, grad/param norm = 2.2240e-01, time/batch = 0.6673s	
1999/33150 (epoch 3.015), train_loss = 1.64766063, grad/param norm = 2.2274e-01, time/batch = 0.6682s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch3.02_1.7219.t7	
2000/33150 (epoch 3.017), train_loss = 1.58587092, grad/param norm = 2.2151e-01, time/batch = 0.6699s	
2001/33150 (epoch 3.018), train_loss = 1.97384113, grad/param norm = 2.8140e-01, time/batch = 0.6768s	
2002/33150 (epoch 3.020), train_loss = 1.75128348, grad/param norm = 2.3842e-01, time/batch = 0.6742s	
2003/33150 (epoch 3.021), train_loss = 1.49708442, grad/param norm = 2.1463e-01, time/batch = 0.6871s	
2004/33150 (epoch 3.023), train_loss = 1.80646520, grad/param norm = 2.2120e-01, time/batch = 0.6727s	
2005/33150 (epoch 3.024), train_loss = 1.66877917, grad/param norm = 2.1837e-01, time/batch = 0.6738s	
2006/33150 (epoch 3.026), train_loss = 1.39318130, grad/param norm = 1.9538e-01, time/batch = 0.6882s	
2007/33150 (epoch 3.027), train_loss = 1.53784557, grad/param norm = 2.1101e-01, time/batch = 0.6907s	
2008/33150 (epoch 3.029), train_loss = 1.56897271, grad/param norm = 2.3325e-01, time/batch = 0.6886s	
2009/33150 (epoch 3.030), train_loss = 1.71235539, grad/param norm = 2.0318e-01, time/batch = 0.6719s	
2010/33150 (epoch 3.032), train_loss = 1.65306811, grad/param norm = 2.3319e-01, time/batch = 0.6649s	
2011/33150 (epoch 3.033), train_loss = 1.60224088, grad/param norm = 2.2960e-01, time/batch = 0.6752s	
2012/33150 (epoch 3.035), train_loss = 1.86106703, grad/param norm = 2.5439e-01, time/batch = 0.6719s	
2013/33150 (epoch 3.036), train_loss = 1.78611474, grad/param norm = 2.4638e-01, time/batch = 0.6682s	
2014/33150 (epoch 3.038), train_loss = 1.97967238, grad/param norm = 2.6800e-01, time/batch = 0.6707s	
2015/33150 (epoch 3.039), train_loss = 1.70252518, grad/param norm = 2.1526e-01, time/batch = 0.6655s	
2016/33150 (epoch 3.041), train_loss = 1.66162638, grad/param norm = 1.9096e-01, time/batch = 0.6673s	
2017/33150 (epoch 3.042), train_loss = 1.48235032, grad/param norm = 2.0173e-01, time/batch = 0.6689s	
2018/33150 (epoch 3.044), train_loss = 1.60988166, grad/param norm = 1.9409e-01, time/batch = 0.6704s	
2019/33150 (epoch 3.045), train_loss = 1.70291739, grad/param norm = 2.4291e-01, time/batch = 0.6907s	
2020/33150 (epoch 3.047), train_loss = 1.59779572, grad/param norm = 2.3075e-01, time/batch = 0.6658s	
2021/33150 (epoch 3.048), train_loss = 1.83888562, grad/param norm = 2.3662e-01, time/batch = 0.6720s	
2022/33150 (epoch 3.050), train_loss = 1.67964124, grad/param norm = 2.2564e-01, time/batch = 0.6649s	
2023/33150 (epoch 3.051), train_loss = 1.69000027, grad/param norm = 2.2888e-01, time/batch = 0.6678s	
2024/33150 (epoch 3.053), train_loss = 1.62819563, grad/param norm = 2.0868e-01, time/batch = 0.6624s	
2025/33150 (epoch 3.054), train_loss = 1.66520692, grad/param norm = 1.9534e-01, time/batch = 0.6642s	
2026/33150 (epoch 3.056), train_loss = 1.45632732, grad/param norm = 1.7613e-01, time/batch = 0.6642s	
2027/33150 (epoch 3.057), train_loss = 1.68469809, grad/param norm = 2.0258e-01, time/batch = 0.6695s	
2028/33150 (epoch 3.059), train_loss = 1.65467253, grad/param norm = 2.7415e-01, time/batch = 0.6642s	
2029/33150 (epoch 3.060), train_loss = 1.52935129, grad/param norm = 2.1436e-01, time/batch = 0.6771s	
2030/33150 (epoch 3.062), train_loss = 1.71438578, grad/param norm = 2.0702e-01, time/batch = 0.6613s	
2031/33150 (epoch 3.063), train_loss = 1.62853220, grad/param norm = 1.9265e-01, time/batch = 0.6647s	
2032/33150 (epoch 3.065), train_loss = 1.66437672, grad/param norm = 2.3072e-01, time/batch = 0.6627s	
2033/33150 (epoch 3.066), train_loss = 1.57247628, grad/param norm = 2.2488e-01, time/batch = 0.6612s	
2034/33150 (epoch 3.068), train_loss = 1.65044336, grad/param norm = 2.0816e-01, time/batch = 0.6625s	
2035/33150 (epoch 3.069), train_loss = 1.76103659, grad/param norm = 2.2449e-01, time/batch = 0.6619s	
2036/33150 (epoch 3.071), train_loss = 1.72552385, grad/param norm = 2.2566e-01, time/batch = 0.6643s	
2037/33150 (epoch 3.072), train_loss = 1.46382501, grad/param norm = 2.1326e-01, time/batch = 0.6622s	
2038/33150 (epoch 3.074), train_loss = 1.47908389, grad/param norm = 2.1046e-01, time/batch = 0.6663s	
2039/33150 (epoch 3.075), train_loss = 1.65303264, grad/param norm = 2.3616e-01, time/batch = 0.6632s	
2040/33150 (epoch 3.077), train_loss = 1.77713132, grad/param norm = 2.5462e-01, time/batch = 0.6640s	
2041/33150 (epoch 3.078), train_loss = 1.81510845, grad/param norm = 2.4476e-01, time/batch = 0.6647s	
2042/33150 (epoch 3.080), train_loss = 1.74290629, grad/param norm = 2.0491e-01, time/batch = 0.6650s	
2043/33150 (epoch 3.081), train_loss = 1.62707281, grad/param norm = 2.4366e-01, time/batch = 0.6652s	
2044/33150 (epoch 3.083), train_loss = 1.35737534, grad/param norm = 2.1260e-01, time/batch = 0.6663s	
2045/33150 (epoch 3.084), train_loss = 1.55935602, grad/param norm = 2.2690e-01, time/batch = 0.6630s	
2046/33150 (epoch 3.086), train_loss = 1.56848582, grad/param norm = 2.1697e-01, time/batch = 0.6660s	
2047/33150 (epoch 3.087), train_loss = 1.49609371, grad/param norm = 2.1853e-01, time/batch = 0.6830s	
2048/33150 (epoch 3.089), train_loss = 1.50211034, grad/param norm = 2.2924e-01, time/batch = 0.6796s	
2049/33150 (epoch 3.090), train_loss = 1.57792633, grad/param norm = 2.3399e-01, time/batch = 0.6681s	
2050/33150 (epoch 3.092), train_loss = 1.70975141, grad/param norm = 2.1663e-01, time/batch = 0.6692s	
2051/33150 (epoch 3.094), train_loss = 1.71411775, grad/param norm = 2.2940e-01, time/batch = 0.6700s	
2052/33150 (epoch 3.095), train_loss = 1.45687802, grad/param norm = 2.0517e-01, time/batch = 0.6675s	
2053/33150 (epoch 3.097), train_loss = 1.78916372, grad/param norm = 2.3684e-01, time/batch = 0.6675s	
2054/33150 (epoch 3.098), train_loss = 1.90740642, grad/param norm = 2.2299e-01, time/batch = 0.6701s	
2055/33150 (epoch 3.100), train_loss = 1.77144208, grad/param norm = 2.3117e-01, time/batch = 0.6687s	
2056/33150 (epoch 3.101), train_loss = 1.56028054, grad/param norm = 2.3469e-01, time/batch = 0.6667s	
2057/33150 (epoch 3.103), train_loss = 1.70640784, grad/param norm = 2.2326e-01, time/batch = 0.6667s	
2058/33150 (epoch 3.104), train_loss = 1.61104532, grad/param norm = 2.2218e-01, time/batch = 0.6663s	
2059/33150 (epoch 3.106), train_loss = 1.81664854, grad/param norm = 2.3393e-01, time/batch = 0.6645s	
2060/33150 (epoch 3.107), train_loss = 1.79844543, grad/param norm = 2.1422e-01, time/batch = 0.6609s	
2061/33150 (epoch 3.109), train_loss = 1.56745369, grad/param norm = 2.0712e-01, time/batch = 0.6639s	
2062/33150 (epoch 3.110), train_loss = 1.74640228, grad/param norm = 2.1057e-01, time/batch = 0.6797s	
2063/33150 (epoch 3.112), train_loss = 1.53509405, grad/param norm = 2.0115e-01, time/batch = 0.6787s	
2064/33150 (epoch 3.113), train_loss = 1.58009955, grad/param norm = 2.3533e-01, time/batch = 0.6872s	
2065/33150 (epoch 3.115), train_loss = 1.77729295, grad/param norm = 2.5117e-01, time/batch = 0.6803s	
2066/33150 (epoch 3.116), train_loss = 1.49274291, grad/param norm = 2.2529e-01, time/batch = 0.6794s	
2067/33150 (epoch 3.118), train_loss = 1.73123851, grad/param norm = 2.7147e-01, time/batch = 0.6658s	
2068/33150 (epoch 3.119), train_loss = 1.72602879, grad/param norm = 2.5549e-01, time/batch = 0.6780s	
2069/33150 (epoch 3.121), train_loss = 1.62121171, grad/param norm = 2.3590e-01, time/batch = 0.6625s	
2070/33150 (epoch 3.122), train_loss = 1.79673771, grad/param norm = 2.4176e-01, time/batch = 0.6650s	
2071/33150 (epoch 3.124), train_loss = 1.42023426, grad/param norm = 2.0994e-01, time/batch = 0.6676s	
2072/33150 (epoch 3.125), train_loss = 1.60113137, grad/param norm = 2.0186e-01, time/batch = 0.6666s	
2073/33150 (epoch 3.127), train_loss = 1.52079936, grad/param norm = 1.9953e-01, time/batch = 0.6676s	
2074/33150 (epoch 3.128), train_loss = 1.67245978, grad/param norm = 2.1587e-01, time/batch = 0.6663s	
2075/33150 (epoch 3.130), train_loss = 1.72111641, grad/param norm = 2.1903e-01, time/batch = 0.6633s	
2076/33150 (epoch 3.131), train_loss = 1.81154509, grad/param norm = 2.3188e-01, time/batch = 0.6669s	
2077/33150 (epoch 3.133), train_loss = 1.50245318, grad/param norm = 2.3164e-01, time/batch = 0.6855s	
2078/33150 (epoch 3.134), train_loss = 1.71953684, grad/param norm = 2.2452e-01, time/batch = 0.6866s	
2079/33150 (epoch 3.136), train_loss = 1.57681143, grad/param norm = 2.0060e-01, time/batch = 0.6850s	
2080/33150 (epoch 3.137), train_loss = 1.71179168, grad/param norm = 2.2445e-01, time/batch = 0.6785s	
2081/33150 (epoch 3.139), train_loss = 1.67976263, grad/param norm = 2.2473e-01, time/batch = 0.6707s	
2082/33150 (epoch 3.140), train_loss = 1.76398379, grad/param norm = 2.4913e-01, time/batch = 0.6672s	
2083/33150 (epoch 3.142), train_loss = 1.69690316, grad/param norm = 2.3711e-01, time/batch = 0.6640s	
2084/33150 (epoch 3.143), train_loss = 1.71661249, grad/param norm = 2.3005e-01, time/batch = 0.6639s	
2085/33150 (epoch 3.145), train_loss = 1.66564194, grad/param norm = 2.4610e-01, time/batch = 0.6646s	
2086/33150 (epoch 3.146), train_loss = 1.85004186, grad/param norm = 2.7282e-01, time/batch = 0.6654s	
2087/33150 (epoch 3.148), train_loss = 1.73325712, grad/param norm = 2.0423e-01, time/batch = 0.6676s	
2088/33150 (epoch 3.149), train_loss = 1.72293808, grad/param norm = 2.6206e-01, time/batch = 0.6649s	
2089/33150 (epoch 3.151), train_loss = 1.89632629, grad/param norm = 2.3325e-01, time/batch = 0.6647s	
2090/33150 (epoch 3.152), train_loss = 1.53183769, grad/param norm = 1.9487e-01, time/batch = 0.6686s	
2091/33150 (epoch 3.154), train_loss = 1.58384669, grad/param norm = 1.9760e-01, time/batch = 0.6658s	
2092/33150 (epoch 3.155), train_loss = 1.54098845, grad/param norm = 2.1751e-01, time/batch = 0.6638s	
2093/33150 (epoch 3.157), train_loss = 1.59478137, grad/param norm = 2.5086e-01, time/batch = 0.6625s	
2094/33150 (epoch 3.158), train_loss = 1.52074820, grad/param norm = 2.2472e-01, time/batch = 0.6635s	
2095/33150 (epoch 3.160), train_loss = 1.73969505, grad/param norm = 2.2791e-01, time/batch = 0.6751s	
2096/33150 (epoch 3.161), train_loss = 1.61125248, grad/param norm = 2.3850e-01, time/batch = 0.6860s	
2097/33150 (epoch 3.163), train_loss = 1.59464641, grad/param norm = 2.0231e-01, time/batch = 0.6866s	
2098/33150 (epoch 3.164), train_loss = 1.71027261, grad/param norm = 2.1561e-01, time/batch = 0.6853s	
2099/33150 (epoch 3.166), train_loss = 1.72737924, grad/param norm = 2.1653e-01, time/batch = 0.6613s	
2100/33150 (epoch 3.167), train_loss = 1.67697190, grad/param norm = 2.1172e-01, time/batch = 0.6835s	
2101/33150 (epoch 3.169), train_loss = 1.87099286, grad/param norm = 2.5481e-01, time/batch = 0.6667s	
2102/33150 (epoch 3.170), train_loss = 1.68230154, grad/param norm = 2.2405e-01, time/batch = 0.6629s	
2103/33150 (epoch 3.172), train_loss = 1.76607473, grad/param norm = 2.2213e-01, time/batch = 0.6649s	
2104/33150 (epoch 3.173), train_loss = 1.77135054, grad/param norm = 2.5385e-01, time/batch = 0.6656s	
2105/33150 (epoch 3.175), train_loss = 1.51693463, grad/param norm = 2.1917e-01, time/batch = 0.6657s	
2106/33150 (epoch 3.176), train_loss = 1.61412004, grad/param norm = 2.3087e-01, time/batch = 0.6650s	
2107/33150 (epoch 3.178), train_loss = 1.74479986, grad/param norm = 2.0886e-01, time/batch = 0.6618s	
2108/33150 (epoch 3.179), train_loss = 1.70344505, grad/param norm = 2.0090e-01, time/batch = 0.6619s	
2109/33150 (epoch 3.181), train_loss = 1.65061633, grad/param norm = 2.4622e-01, time/batch = 0.6601s	
2110/33150 (epoch 3.183), train_loss = 1.71157292, grad/param norm = 2.5608e-01, time/batch = 0.6707s	
2111/33150 (epoch 3.184), train_loss = 1.76798006, grad/param norm = 2.3678e-01, time/batch = 0.6935s	
2112/33150 (epoch 3.186), train_loss = 1.79413308, grad/param norm = 2.1244e-01, time/batch = 0.6778s	
2113/33150 (epoch 3.187), train_loss = 1.61872736, grad/param norm = 2.1490e-01, time/batch = 0.6633s	
2114/33150 (epoch 3.189), train_loss = 1.53638380, grad/param norm = 2.2778e-01, time/batch = 0.6623s	
2115/33150 (epoch 3.190), train_loss = 1.58692271, grad/param norm = 2.2324e-01, time/batch = 0.6616s	
2116/33150 (epoch 3.192), train_loss = 1.67950821, grad/param norm = 2.2048e-01, time/batch = 0.6671s	
2117/33150 (epoch 3.193), train_loss = 1.59526784, grad/param norm = 2.0466e-01, time/batch = 0.6582s	
2118/33150 (epoch 3.195), train_loss = 1.94445476, grad/param norm = 2.3602e-01, time/batch = 0.6586s	
2119/33150 (epoch 3.196), train_loss = 1.72922017, grad/param norm = 2.0692e-01, time/batch = 0.6572s	
2120/33150 (epoch 3.198), train_loss = 1.54462375, grad/param norm = 2.0950e-01, time/batch = 0.6629s	
2121/33150 (epoch 3.199), train_loss = 1.73123604, grad/param norm = 2.2315e-01, time/batch = 0.6608s	
2122/33150 (epoch 3.201), train_loss = 1.47724106, grad/param norm = 1.8466e-01, time/batch = 0.6592s	
2123/33150 (epoch 3.202), train_loss = 1.39684630, grad/param norm = 1.7579e-01, time/batch = 0.6621s	
2124/33150 (epoch 3.204), train_loss = 1.59020501, grad/param norm = 2.0195e-01, time/batch = 0.6642s	
2125/33150 (epoch 3.205), train_loss = 1.77117751, grad/param norm = 2.2494e-01, time/batch = 0.6629s	
2126/33150 (epoch 3.207), train_loss = 1.64514760, grad/param norm = 2.7409e-01, time/batch = 0.6674s	
2127/33150 (epoch 3.208), train_loss = 1.67934223, grad/param norm = 2.3028e-01, time/batch = 0.6665s	
2128/33150 (epoch 3.210), train_loss = 1.47667890, grad/param norm = 2.0021e-01, time/batch = 0.6694s	
2129/33150 (epoch 3.211), train_loss = 1.72361341, grad/param norm = 2.1306e-01, time/batch = 0.6659s	
2130/33150 (epoch 3.213), train_loss = 1.84835033, grad/param norm = 2.1295e-01, time/batch = 0.6861s	
2131/33150 (epoch 3.214), train_loss = 1.59023429, grad/param norm = 2.3140e-01, time/batch = 0.6753s	
2132/33150 (epoch 3.216), train_loss = 1.62353446, grad/param norm = 2.0614e-01, time/batch = 0.6798s	
2133/33150 (epoch 3.217), train_loss = 1.61545150, grad/param norm = 2.0066e-01, time/batch = 0.6690s	
2134/33150 (epoch 3.219), train_loss = 1.55055688, grad/param norm = 2.0613e-01, time/batch = 0.6678s	
2135/33150 (epoch 3.220), train_loss = 1.45525012, grad/param norm = 2.1031e-01, time/batch = 0.6750s	
2136/33150 (epoch 3.222), train_loss = 1.71564172, grad/param norm = 2.2675e-01, time/batch = 0.6727s	
2137/33150 (epoch 3.223), train_loss = 1.61262637, grad/param norm = 1.9332e-01, time/batch = 0.6778s	
2138/33150 (epoch 3.225), train_loss = 1.84530050, grad/param norm = 2.2097e-01, time/batch = 0.6691s	
2139/33150 (epoch 3.226), train_loss = 1.57358605, grad/param norm = 2.0803e-01, time/batch = 0.6671s	
2140/33150 (epoch 3.228), train_loss = 1.64285376, grad/param norm = 2.3722e-01, time/batch = 0.6677s	
2141/33150 (epoch 3.229), train_loss = 1.64266450, grad/param norm = 2.3419e-01, time/batch = 0.6696s	
2142/33150 (epoch 3.231), train_loss = 1.73068590, grad/param norm = 2.4028e-01, time/batch = 0.6677s	
2143/33150 (epoch 3.232), train_loss = 1.69493065, grad/param norm = 2.2940e-01, time/batch = 0.6736s	
2144/33150 (epoch 3.234), train_loss = 1.57512573, grad/param norm = 2.3135e-01, time/batch = 0.6694s	
2145/33150 (epoch 3.235), train_loss = 1.68346198, grad/param norm = 2.2952e-01, time/batch = 0.6697s	
2146/33150 (epoch 3.237), train_loss = 1.61416768, grad/param norm = 2.2536e-01, time/batch = 0.6712s	
2147/33150 (epoch 3.238), train_loss = 1.85531722, grad/param norm = 2.4059e-01, time/batch = 0.6713s	
2148/33150 (epoch 3.240), train_loss = 1.63820889, grad/param norm = 2.0730e-01, time/batch = 0.6716s	
2149/33150 (epoch 3.241), train_loss = 1.73855252, grad/param norm = 2.4282e-01, time/batch = 0.6714s	
2150/33150 (epoch 3.243), train_loss = 1.83084291, grad/param norm = 2.2657e-01, time/batch = 0.6723s	
2151/33150 (epoch 3.244), train_loss = 1.59583917, grad/param norm = 2.0033e-01, time/batch = 0.6752s	
2152/33150 (epoch 3.246), train_loss = 1.66822833, grad/param norm = 2.2200e-01, time/batch = 0.6729s	
2153/33150 (epoch 3.247), train_loss = 1.54543296, grad/param norm = 2.2958e-01, time/batch = 0.6723s	
2154/33150 (epoch 3.249), train_loss = 1.86588135, grad/param norm = 2.2765e-01, time/batch = 0.6710s	
2155/33150 (epoch 3.250), train_loss = 1.63565124, grad/param norm = 2.0521e-01, time/batch = 0.6710s	
2156/33150 (epoch 3.252), train_loss = 1.61468380, grad/param norm = 1.9155e-01, time/batch = 0.6680s	
2157/33150 (epoch 3.253), train_loss = 1.74386929, grad/param norm = 2.4948e-01, time/batch = 0.6716s	
2158/33150 (epoch 3.255), train_loss = 1.63772969, grad/param norm = 2.0926e-01, time/batch = 0.6704s	
2159/33150 (epoch 3.256), train_loss = 1.75399468, grad/param norm = 2.2851e-01, time/batch = 0.6716s	
2160/33150 (epoch 3.258), train_loss = 1.63915865, grad/param norm = 2.7518e-01, time/batch = 0.6743s	
2161/33150 (epoch 3.259), train_loss = 1.41199906, grad/param norm = 2.2899e-01, time/batch = 0.6726s	
2162/33150 (epoch 3.261), train_loss = 1.48133885, grad/param norm = 2.0787e-01, time/batch = 0.6711s	
2163/33150 (epoch 3.262), train_loss = 1.67771631, grad/param norm = 2.2031e-01, time/batch = 0.6723s	
2164/33150 (epoch 3.264), train_loss = 1.34889912, grad/param norm = 2.4404e-01, time/batch = 0.6702s	
2165/33150 (epoch 3.265), train_loss = 1.64728527, grad/param norm = 2.1933e-01, time/batch = 0.6739s	
2166/33150 (epoch 3.267), train_loss = 1.76218407, grad/param norm = 2.2181e-01, time/batch = 0.6713s	
2167/33150 (epoch 3.268), train_loss = 1.47740022, grad/param norm = 2.1342e-01, time/batch = 0.6693s	
2168/33150 (epoch 3.270), train_loss = 1.82266730, grad/param norm = 2.1481e-01, time/batch = 0.6730s	
2169/33150 (epoch 3.271), train_loss = 1.80959236, grad/param norm = 2.3528e-01, time/batch = 0.6720s	
2170/33150 (epoch 3.273), train_loss = 1.71222977, grad/param norm = 2.5583e-01, time/batch = 0.6723s	
2171/33150 (epoch 3.275), train_loss = 1.74931040, grad/param norm = 2.1738e-01, time/batch = 0.6737s	
2172/33150 (epoch 3.276), train_loss = 1.63224964, grad/param norm = 2.1107e-01, time/batch = 0.6705s	
2173/33150 (epoch 3.278), train_loss = 1.79138225, grad/param norm = 2.3256e-01, time/batch = 0.6735s	
2174/33150 (epoch 3.279), train_loss = 1.62741823, grad/param norm = 2.1357e-01, time/batch = 0.6677s	
2175/33150 (epoch 3.281), train_loss = 1.79768569, grad/param norm = 2.2121e-01, time/batch = 0.6676s	
2176/33150 (epoch 3.282), train_loss = 1.65245219, grad/param norm = 2.1721e-01, time/batch = 0.6652s	
2177/33150 (epoch 3.284), train_loss = 1.61187326, grad/param norm = 1.9603e-01, time/batch = 0.6678s	
2178/33150 (epoch 3.285), train_loss = 1.70812646, grad/param norm = 2.4966e-01, time/batch = 0.6688s	
2179/33150 (epoch 3.287), train_loss = 1.59690222, grad/param norm = 1.9884e-01, time/batch = 0.6682s	
2180/33150 (epoch 3.288), train_loss = 1.83783131, grad/param norm = 2.2124e-01, time/batch = 0.6681s	
2181/33150 (epoch 3.290), train_loss = 1.48316846, grad/param norm = 2.3205e-01, time/batch = 0.6693s	
2182/33150 (epoch 3.291), train_loss = 1.61011591, grad/param norm = 3.0736e-01, time/batch = 0.6701s	
2183/33150 (epoch 3.293), train_loss = 1.71453974, grad/param norm = 2.3440e-01, time/batch = 0.6688s	
2184/33150 (epoch 3.294), train_loss = 1.37561199, grad/param norm = 2.1443e-01, time/batch = 0.6774s	
2185/33150 (epoch 3.296), train_loss = 1.59240037, grad/param norm = 2.1827e-01, time/batch = 0.6863s	
2186/33150 (epoch 3.297), train_loss = 1.64330874, grad/param norm = 2.1645e-01, time/batch = 0.6972s	
2187/33150 (epoch 3.299), train_loss = 1.54165163, grad/param norm = 2.1240e-01, time/batch = 0.7027s	
2188/33150 (epoch 3.300), train_loss = 1.57795643, grad/param norm = 2.0310e-01, time/batch = 0.6703s	
2189/33150 (epoch 3.302), train_loss = 1.62379786, grad/param norm = 2.3524e-01, time/batch = 0.6704s	
2190/33150 (epoch 3.303), train_loss = 1.74439495, grad/param norm = 2.1928e-01, time/batch = 0.6780s	
2191/33150 (epoch 3.305), train_loss = 1.64646315, grad/param norm = 2.0742e-01, time/batch = 0.7122s	
2192/33150 (epoch 3.306), train_loss = 1.74727537, grad/param norm = 2.0167e-01, time/batch = 0.6912s	
2193/33150 (epoch 3.308), train_loss = 1.86577177, grad/param norm = 2.1232e-01, time/batch = 0.6895s	
2194/33150 (epoch 3.309), train_loss = 1.52650994, grad/param norm = 1.9411e-01, time/batch = 0.6880s	
2195/33150 (epoch 3.311), train_loss = 1.74274038, grad/param norm = 2.4490e-01, time/batch = 0.6868s	
2196/33150 (epoch 3.312), train_loss = 1.48540568, grad/param norm = 2.4023e-01, time/batch = 0.6858s	
2197/33150 (epoch 3.314), train_loss = 1.69994628, grad/param norm = 2.2908e-01, time/batch = 0.6711s	
2198/33150 (epoch 3.315), train_loss = 1.72655356, grad/param norm = 2.2289e-01, time/batch = 0.6681s	
2199/33150 (epoch 3.317), train_loss = 1.36053042, grad/param norm = 1.9619e-01, time/batch = 0.6665s	
2200/33150 (epoch 3.318), train_loss = 1.47938024, grad/param norm = 1.9445e-01, time/batch = 0.6676s	
2201/33150 (epoch 3.320), train_loss = 1.48437026, grad/param norm = 2.0437e-01, time/batch = 0.6665s	
2202/33150 (epoch 3.321), train_loss = 1.58135826, grad/param norm = 2.0349e-01, time/batch = 0.6634s	
2203/33150 (epoch 3.323), train_loss = 1.67506302, grad/param norm = 2.1956e-01, time/batch = 0.6640s	
2204/33150 (epoch 3.324), train_loss = 1.77865499, grad/param norm = 2.2134e-01, time/batch = 0.6645s	
2205/33150 (epoch 3.326), train_loss = 1.59402672, grad/param norm = 1.9256e-01, time/batch = 0.6667s	
2206/33150 (epoch 3.327), train_loss = 1.76572321, grad/param norm = 2.2370e-01, time/batch = 0.6666s	
2207/33150 (epoch 3.329), train_loss = 1.63088423, grad/param norm = 1.9826e-01, time/batch = 0.6651s	
2208/33150 (epoch 3.330), train_loss = 1.76778994, grad/param norm = 2.5613e-01, time/batch = 0.6633s	
2209/33150 (epoch 3.332), train_loss = 1.60540336, grad/param norm = 2.2243e-01, time/batch = 0.6678s	
2210/33150 (epoch 3.333), train_loss = 1.61954266, grad/param norm = 1.9115e-01, time/batch = 0.6646s	
2211/33150 (epoch 3.335), train_loss = 1.68781371, grad/param norm = 2.1037e-01, time/batch = 0.6648s	
2212/33150 (epoch 3.336), train_loss = 1.53973047, grad/param norm = 2.1587e-01, time/batch = 0.6673s	
2213/33150 (epoch 3.338), train_loss = 1.37344107, grad/param norm = 2.0401e-01, time/batch = 0.6673s	
2214/33150 (epoch 3.339), train_loss = 1.75718302, grad/param norm = 2.2216e-01, time/batch = 0.6655s	
2215/33150 (epoch 3.341), train_loss = 1.89989702, grad/param norm = 2.4699e-01, time/batch = 0.6651s	
2216/33150 (epoch 3.342), train_loss = 1.54551863, grad/param norm = 2.2205e-01, time/batch = 0.6664s	
2217/33150 (epoch 3.344), train_loss = 1.68358007, grad/param norm = 2.0566e-01, time/batch = 0.6658s	
2218/33150 (epoch 3.345), train_loss = 1.40134729, grad/param norm = 1.9594e-01, time/batch = 0.6658s	
2219/33150 (epoch 3.347), train_loss = 1.33906282, grad/param norm = 1.7585e-01, time/batch = 0.6663s	
2220/33150 (epoch 3.348), train_loss = 1.56285506, grad/param norm = 1.9528e-01, time/batch = 0.6676s	
2221/33150 (epoch 3.350), train_loss = 1.74037570, grad/param norm = 2.5884e-01, time/batch = 0.6695s	
2222/33150 (epoch 3.351), train_loss = 1.72291369, grad/param norm = 2.2502e-01, time/batch = 0.6671s	
2223/33150 (epoch 3.353), train_loss = 1.81085648, grad/param norm = 2.2740e-01, time/batch = 0.6721s	
2224/33150 (epoch 3.354), train_loss = 1.86924555, grad/param norm = 2.1740e-01, time/batch = 0.6707s	
2225/33150 (epoch 3.356), train_loss = 1.75482585, grad/param norm = 2.5371e-01, time/batch = 0.6689s	
2226/33150 (epoch 3.357), train_loss = 1.73026887, grad/param norm = 2.2638e-01, time/batch = 0.6693s	
2227/33150 (epoch 3.359), train_loss = 1.65119691, grad/param norm = 2.1221e-01, time/batch = 0.6708s	
2228/33150 (epoch 3.360), train_loss = 1.79626385, grad/param norm = 2.2916e-01, time/batch = 0.6682s	
2229/33150 (epoch 3.362), train_loss = 1.65618647, grad/param norm = 2.0563e-01, time/batch = 0.6711s	
2230/33150 (epoch 3.363), train_loss = 1.57792218, grad/param norm = 1.9075e-01, time/batch = 0.6832s	
2231/33150 (epoch 3.365), train_loss = 1.60936883, grad/param norm = 1.9900e-01, time/batch = 0.6782s	
2232/33150 (epoch 3.367), train_loss = 1.46408533, grad/param norm = 2.0345e-01, time/batch = 0.6744s	
2233/33150 (epoch 3.368), train_loss = 1.73475654, grad/param norm = 2.1557e-01, time/batch = 0.6910s	
2234/33150 (epoch 3.370), train_loss = 1.82069078, grad/param norm = 2.3289e-01, time/batch = 0.6767s	
2235/33150 (epoch 3.371), train_loss = 1.56406955, grad/param norm = 1.9958e-01, time/batch = 0.6739s	
2236/33150 (epoch 3.373), train_loss = 1.75927318, grad/param norm = 2.1413e-01, time/batch = 0.6656s	
2237/33150 (epoch 3.374), train_loss = 1.48718999, grad/param norm = 2.0348e-01, time/batch = 0.6762s	
2238/33150 (epoch 3.376), train_loss = 1.78569964, grad/param norm = 2.0981e-01, time/batch = 0.6679s	
2239/33150 (epoch 3.377), train_loss = 1.71960038, grad/param norm = 2.4219e-01, time/batch = 0.6698s	
2240/33150 (epoch 3.379), train_loss = 1.70641294, grad/param norm = 2.2428e-01, time/batch = 0.6626s	
2241/33150 (epoch 3.380), train_loss = 1.77147462, grad/param norm = 2.2520e-01, time/batch = 0.6675s	
2242/33150 (epoch 3.382), train_loss = 1.52403329, grad/param norm = 2.0594e-01, time/batch = 0.6634s	
2243/33150 (epoch 3.383), train_loss = 1.49793162, grad/param norm = 2.0778e-01, time/batch = 0.6620s	
2244/33150 (epoch 3.385), train_loss = 1.64625437, grad/param norm = 1.9213e-01, time/batch = 0.6654s	
2245/33150 (epoch 3.386), train_loss = 1.50478688, grad/param norm = 1.9764e-01, time/batch = 0.6649s	
2246/33150 (epoch 3.388), train_loss = 1.59894813, grad/param norm = 2.1067e-01, time/batch = 0.6644s	
2247/33150 (epoch 3.389), train_loss = 1.59888622, grad/param norm = 2.1854e-01, time/batch = 0.6631s	
2248/33150 (epoch 3.391), train_loss = 1.85969408, grad/param norm = 2.4305e-01, time/batch = 0.6650s	
2249/33150 (epoch 3.392), train_loss = 1.57486260, grad/param norm = 2.2404e-01, time/batch = 0.6611s	
2250/33150 (epoch 3.394), train_loss = 1.46113199, grad/param norm = 1.9635e-01, time/batch = 0.6633s	
2251/33150 (epoch 3.395), train_loss = 1.60932861, grad/param norm = 2.3369e-01, time/batch = 0.6651s	
2252/33150 (epoch 3.397), train_loss = 1.25538432, grad/param norm = 2.0272e-01, time/batch = 0.6642s	
2253/33150 (epoch 3.398), train_loss = 1.68329521, grad/param norm = 2.2139e-01, time/batch = 0.6722s	
2254/33150 (epoch 3.400), train_loss = 1.56777178, grad/param norm = 1.8747e-01, time/batch = 0.6696s	
2255/33150 (epoch 3.401), train_loss = 1.41610574, grad/param norm = 1.8642e-01, time/batch = 0.6648s	
2256/33150 (epoch 3.403), train_loss = 1.50543541, grad/param norm = 2.0326e-01, time/batch = 0.6638s	
2257/33150 (epoch 3.404), train_loss = 1.54333180, grad/param norm = 2.1074e-01, time/batch = 0.6672s	
2258/33150 (epoch 3.406), train_loss = 1.46362291, grad/param norm = 1.9636e-01, time/batch = 0.6797s	
2259/33150 (epoch 3.407), train_loss = 1.47296680, grad/param norm = 1.8989e-01, time/batch = 0.6670s	
2260/33150 (epoch 3.409), train_loss = 1.34901085, grad/param norm = 2.0415e-01, time/batch = 0.6703s	
2261/33150 (epoch 3.410), train_loss = 1.71067025, grad/param norm = 2.3823e-01, time/batch = 0.6940s	
2262/33150 (epoch 3.412), train_loss = 1.73962994, grad/param norm = 2.0747e-01, time/batch = 0.6781s	
2263/33150 (epoch 3.413), train_loss = 1.60182573, grad/param norm = 2.1971e-01, time/batch = 0.6679s	
2264/33150 (epoch 3.415), train_loss = 1.78979617, grad/param norm = 2.1475e-01, time/batch = 0.6662s	
2265/33150 (epoch 3.416), train_loss = 1.65704527, grad/param norm = 1.9911e-01, time/batch = 0.6669s	
2266/33150 (epoch 3.418), train_loss = 1.94778116, grad/param norm = 2.5841e-01, time/batch = 0.6729s	
2267/33150 (epoch 3.419), train_loss = 1.55375793, grad/param norm = 2.2392e-01, time/batch = 0.6693s	
2268/33150 (epoch 3.421), train_loss = 1.69229094, grad/param norm = 2.2777e-01, time/batch = 0.6705s	
2269/33150 (epoch 3.422), train_loss = 1.49336670, grad/param norm = 1.9597e-01, time/batch = 0.6713s	
2270/33150 (epoch 3.424), train_loss = 1.60848790, grad/param norm = 2.1724e-01, time/batch = 0.6639s	
2271/33150 (epoch 3.425), train_loss = 1.52538388, grad/param norm = 2.1836e-01, time/batch = 0.6683s	
2272/33150 (epoch 3.427), train_loss = 1.52666721, grad/param norm = 2.0919e-01, time/batch = 0.6664s	
2273/33150 (epoch 3.428), train_loss = 1.67214073, grad/param norm = 2.1092e-01, time/batch = 0.6752s	
2274/33150 (epoch 3.430), train_loss = 1.67040103, grad/param norm = 2.1536e-01, time/batch = 0.6863s	
2275/33150 (epoch 3.431), train_loss = 1.66947576, grad/param norm = 2.1363e-01, time/batch = 0.6912s	
2276/33150 (epoch 3.433), train_loss = 1.65655907, grad/param norm = 1.9128e-01, time/batch = 0.6698s	
2277/33150 (epoch 3.434), train_loss = 1.41867695, grad/param norm = 2.0681e-01, time/batch = 0.6669s	
2278/33150 (epoch 3.436), train_loss = 1.43153171, grad/param norm = 2.2978e-01, time/batch = 0.6664s	
2279/33150 (epoch 3.437), train_loss = 1.64065682, grad/param norm = 2.4365e-01, time/batch = 0.6730s	
2280/33150 (epoch 3.439), train_loss = 1.66540403, grad/param norm = 2.0827e-01, time/batch = 0.6669s	
2281/33150 (epoch 3.440), train_loss = 1.71623147, grad/param norm = 2.4028e-01, time/batch = 0.6691s	
2282/33150 (epoch 3.442), train_loss = 1.40796968, grad/param norm = 2.0507e-01, time/batch = 0.6956s	
2283/33150 (epoch 3.443), train_loss = 1.67872507, grad/param norm = 2.1698e-01, time/batch = 0.6820s	
2284/33150 (epoch 3.445), train_loss = 1.64222440, grad/param norm = 2.1105e-01, time/batch = 0.6765s	
2285/33150 (epoch 3.446), train_loss = 1.68518435, grad/param norm = 2.5179e-01, time/batch = 0.6699s	
2286/33150 (epoch 3.448), train_loss = 1.57735625, grad/param norm = 2.1645e-01, time/batch = 0.6688s	
2287/33150 (epoch 3.449), train_loss = 1.56309639, grad/param norm = 1.9439e-01, time/batch = 0.6853s	
2288/33150 (epoch 3.451), train_loss = 1.71135848, grad/param norm = 2.2374e-01, time/batch = 0.6917s	
2289/33150 (epoch 3.452), train_loss = 1.81982453, grad/param norm = 2.0838e-01, time/batch = 0.6828s	
2290/33150 (epoch 3.454), train_loss = 1.66746592, grad/param norm = 2.1739e-01, time/batch = 0.6744s	
2291/33150 (epoch 3.456), train_loss = 1.33815191, grad/param norm = 2.0660e-01, time/batch = 0.6682s	
2292/33150 (epoch 3.457), train_loss = 1.61545332, grad/param norm = 2.0291e-01, time/batch = 0.6696s	
2293/33150 (epoch 3.459), train_loss = 1.79204376, grad/param norm = 2.3182e-01, time/batch = 0.6652s	
2294/33150 (epoch 3.460), train_loss = 1.61043664, grad/param norm = 1.8802e-01, time/batch = 0.6651s	
2295/33150 (epoch 3.462), train_loss = 1.69826253, grad/param norm = 2.3317e-01, time/batch = 0.6737s	
2296/33150 (epoch 3.463), train_loss = 1.90340903, grad/param norm = 2.5496e-01, time/batch = 0.6676s	
2297/33150 (epoch 3.465), train_loss = 1.51177160, grad/param norm = 1.9978e-01, time/batch = 0.6674s	
2298/33150 (epoch 3.466), train_loss = 1.58007469, grad/param norm = 2.2360e-01, time/batch = 0.6707s	
2299/33150 (epoch 3.468), train_loss = 1.95137576, grad/param norm = 2.3002e-01, time/batch = 0.6718s	
2300/33150 (epoch 3.469), train_loss = 1.78436868, grad/param norm = 2.1999e-01, time/batch = 0.6707s	
2301/33150 (epoch 3.471), train_loss = 1.54597429, grad/param norm = 1.9313e-01, time/batch = 0.6716s	
2302/33150 (epoch 3.472), train_loss = 1.49746000, grad/param norm = 2.0395e-01, time/batch = 0.6721s	
2303/33150 (epoch 3.474), train_loss = 1.66178359, grad/param norm = 2.2793e-01, time/batch = 0.6720s	
2304/33150 (epoch 3.475), train_loss = 1.87448622, grad/param norm = 2.2557e-01, time/batch = 0.6800s	
2305/33150 (epoch 3.477), train_loss = 1.69176165, grad/param norm = 2.4790e-01, time/batch = 0.6756s	
2306/33150 (epoch 3.478), train_loss = 1.67045929, grad/param norm = 2.1023e-01, time/batch = 0.6715s	
2307/33150 (epoch 3.480), train_loss = 1.45506404, grad/param norm = 1.9282e-01, time/batch = 0.6686s	
2308/33150 (epoch 3.481), train_loss = 1.35013252, grad/param norm = 1.7962e-01, time/batch = 0.6683s	
2309/33150 (epoch 3.483), train_loss = 1.46312768, grad/param norm = 2.2263e-01, time/batch = 0.6694s	
2310/33150 (epoch 3.484), train_loss = 1.50962185, grad/param norm = 2.1188e-01, time/batch = 0.6685s	
2311/33150 (epoch 3.486), train_loss = 1.64925517, grad/param norm = 2.0161e-01, time/batch = 0.6704s	
2312/33150 (epoch 3.487), train_loss = 1.68398849, grad/param norm = 2.1832e-01, time/batch = 0.6706s	
2313/33150 (epoch 3.489), train_loss = 1.60709267, grad/param norm = 2.1858e-01, time/batch = 0.6721s	
2314/33150 (epoch 3.490), train_loss = 1.43772896, grad/param norm = 2.1454e-01, time/batch = 0.6717s	
2315/33150 (epoch 3.492), train_loss = 1.55545613, grad/param norm = 2.3367e-01, time/batch = 0.6710s	
2316/33150 (epoch 3.493), train_loss = 1.73433117, grad/param norm = 2.4188e-01, time/batch = 0.6706s	
2317/33150 (epoch 3.495), train_loss = 1.71085601, grad/param norm = 2.3208e-01, time/batch = 0.6705s	
2318/33150 (epoch 3.496), train_loss = 1.55751327, grad/param norm = 2.4143e-01, time/batch = 0.6687s	
2319/33150 (epoch 3.498), train_loss = 1.71204793, grad/param norm = 2.2445e-01, time/batch = 0.6659s	
2320/33150 (epoch 3.499), train_loss = 1.86475842, grad/param norm = 2.4093e-01, time/batch = 0.6632s	
2321/33150 (epoch 3.501), train_loss = 1.63083984, grad/param norm = 1.9717e-01, time/batch = 0.6684s	
2322/33150 (epoch 3.502), train_loss = 1.76189454, grad/param norm = 2.1885e-01, time/batch = 0.6687s	
2323/33150 (epoch 3.504), train_loss = 1.71877043, grad/param norm = 2.1882e-01, time/batch = 0.6771s	
2324/33150 (epoch 3.505), train_loss = 1.84074722, grad/param norm = 2.3039e-01, time/batch = 0.6755s	
2325/33150 (epoch 3.507), train_loss = 1.55236410, grad/param norm = 2.1497e-01, time/batch = 0.6674s	
2326/33150 (epoch 3.508), train_loss = 1.51575319, grad/param norm = 1.8908e-01, time/batch = 0.6717s	
2327/33150 (epoch 3.510), train_loss = 1.60168127, grad/param norm = 2.1576e-01, time/batch = 0.6634s	
2328/33150 (epoch 3.511), train_loss = 1.86048731, grad/param norm = 2.2273e-01, time/batch = 0.6708s	
2329/33150 (epoch 3.513), train_loss = 1.69288065, grad/param norm = 2.2107e-01, time/batch = 0.6653s	
2330/33150 (epoch 3.514), train_loss = 1.33464139, grad/param norm = 1.9723e-01, time/batch = 0.6650s	
2331/33150 (epoch 3.516), train_loss = 1.73761678, grad/param norm = 2.2765e-01, time/batch = 0.6702s	
2332/33150 (epoch 3.517), train_loss = 1.78597778, grad/param norm = 2.0066e-01, time/batch = 0.6694s	
2333/33150 (epoch 3.519), train_loss = 1.57305281, grad/param norm = 2.0893e-01, time/batch = 0.6732s	
2334/33150 (epoch 3.520), train_loss = 1.66578595, grad/param norm = 2.0100e-01, time/batch = 0.6723s	
2335/33150 (epoch 3.522), train_loss = 1.81038733, grad/param norm = 2.2706e-01, time/batch = 0.6753s	
2336/33150 (epoch 3.523), train_loss = 1.51302405, grad/param norm = 1.9988e-01, time/batch = 0.6706s	
2337/33150 (epoch 3.525), train_loss = 1.61604890, grad/param norm = 1.8279e-01, time/batch = 0.6718s	
2338/33150 (epoch 3.526), train_loss = 1.45968398, grad/param norm = 2.0670e-01, time/batch = 0.6798s	
2339/33150 (epoch 3.528), train_loss = 1.65044943, grad/param norm = 2.0596e-01, time/batch = 0.6814s	
2340/33150 (epoch 3.529), train_loss = 1.67179240, grad/param norm = 1.7968e-01, time/batch = 0.6752s	
2341/33150 (epoch 3.531), train_loss = 1.50376651, grad/param norm = 2.0919e-01, time/batch = 0.6738s	
2342/33150 (epoch 3.532), train_loss = 1.67028497, grad/param norm = 2.0531e-01, time/batch = 0.6695s	
2343/33150 (epoch 3.534), train_loss = 1.50128628, grad/param norm = 2.0594e-01, time/batch = 0.6709s	
2344/33150 (epoch 3.535), train_loss = 1.55775110, grad/param norm = 2.3442e-01, time/batch = 0.6738s	
2345/33150 (epoch 3.537), train_loss = 1.79047810, grad/param norm = 2.2937e-01, time/batch = 0.6694s	
2346/33150 (epoch 3.538), train_loss = 1.60184331, grad/param norm = 2.2688e-01, time/batch = 0.6705s	
2347/33150 (epoch 3.540), train_loss = 1.42832947, grad/param norm = 2.0055e-01, time/batch = 0.6726s	
2348/33150 (epoch 3.541), train_loss = 1.64755373, grad/param norm = 2.2357e-01, time/batch = 0.6735s	
2349/33150 (epoch 3.543), train_loss = 1.65957519, grad/param norm = 2.3375e-01, time/batch = 0.6695s	
2350/33150 (epoch 3.544), train_loss = 1.63238700, grad/param norm = 2.0746e-01, time/batch = 0.6711s	
2351/33150 (epoch 3.546), train_loss = 1.86895704, grad/param norm = 2.2482e-01, time/batch = 0.6710s	
2352/33150 (epoch 3.548), train_loss = 1.70648886, grad/param norm = 2.2168e-01, time/batch = 0.6726s	
2353/33150 (epoch 3.549), train_loss = 1.70587515, grad/param norm = 2.3931e-01, time/batch = 0.6715s	
2354/33150 (epoch 3.551), train_loss = 1.48264548, grad/param norm = 2.0489e-01, time/batch = 0.6754s	
2355/33150 (epoch 3.552), train_loss = 1.44719228, grad/param norm = 2.0192e-01, time/batch = 0.6855s	
2356/33150 (epoch 3.554), train_loss = 1.57768059, grad/param norm = 2.0505e-01, time/batch = 0.6698s	
2357/33150 (epoch 3.555), train_loss = 1.84603267, grad/param norm = 2.2870e-01, time/batch = 0.6691s	
2358/33150 (epoch 3.557), train_loss = 1.44954409, grad/param norm = 2.3633e-01, time/batch = 0.6693s	
2359/33150 (epoch 3.558), train_loss = 1.75203238, grad/param norm = 2.1231e-01, time/batch = 0.6686s	
2360/33150 (epoch 3.560), train_loss = 1.65190059, grad/param norm = 2.2232e-01, time/batch = 0.6697s	
2361/33150 (epoch 3.561), train_loss = 1.42115716, grad/param norm = 2.2551e-01, time/batch = 0.6712s	
2362/33150 (epoch 3.563), train_loss = 1.75104916, grad/param norm = 2.4726e-01, time/batch = 0.6805s	
2363/33150 (epoch 3.564), train_loss = 1.85119623, grad/param norm = 2.3719e-01, time/batch = 0.6849s	
2364/33150 (epoch 3.566), train_loss = 1.58716298, grad/param norm = 2.0130e-01, time/batch = 0.6880s	
2365/33150 (epoch 3.567), train_loss = 1.45581466, grad/param norm = 2.0405e-01, time/batch = 0.6751s	
2366/33150 (epoch 3.569), train_loss = 1.57858105, grad/param norm = 2.0681e-01, time/batch = 0.6954s	
2367/33150 (epoch 3.570), train_loss = 1.54605152, grad/param norm = 1.9775e-01, time/batch = 0.6853s	
2368/33150 (epoch 3.572), train_loss = 1.58253693, grad/param norm = 2.0365e-01, time/batch = 0.6770s	
2369/33150 (epoch 3.573), train_loss = 1.29754980, grad/param norm = 1.7057e-01, time/batch = 0.6892s	
2370/33150 (epoch 3.575), train_loss = 1.66979603, grad/param norm = 2.0293e-01, time/batch = 0.6717s	
2371/33150 (epoch 3.576), train_loss = 1.36253941, grad/param norm = 1.8124e-01, time/batch = 0.6753s	
2372/33150 (epoch 3.578), train_loss = 1.59199352, grad/param norm = 1.9102e-01, time/batch = 0.6768s	
2373/33150 (epoch 3.579), train_loss = 1.47561472, grad/param norm = 2.1212e-01, time/batch = 0.6655s	
2374/33150 (epoch 3.581), train_loss = 1.42237253, grad/param norm = 1.9877e-01, time/batch = 0.6654s	
2375/33150 (epoch 3.582), train_loss = 1.56295479, grad/param norm = 2.0078e-01, time/batch = 0.6658s	
2376/33150 (epoch 3.584), train_loss = 1.65783299, grad/param norm = 2.0111e-01, time/batch = 0.6649s	
2377/33150 (epoch 3.585), train_loss = 1.60466471, grad/param norm = 1.9382e-01, time/batch = 0.6691s	
2378/33150 (epoch 3.587), train_loss = 1.64179015, grad/param norm = 2.0292e-01, time/batch = 0.6676s	
2379/33150 (epoch 3.588), train_loss = 1.44336240, grad/param norm = 2.0627e-01, time/batch = 0.6837s	
2380/33150 (epoch 3.590), train_loss = 1.64968252, grad/param norm = 2.1960e-01, time/batch = 0.6864s	
2381/33150 (epoch 3.591), train_loss = 1.64658241, grad/param norm = 2.1193e-01, time/batch = 0.6901s	
2382/33150 (epoch 3.593), train_loss = 1.67711873, grad/param norm = 2.2529e-01, time/batch = 0.6800s	
2383/33150 (epoch 3.594), train_loss = 1.64419577, grad/param norm = 2.2215e-01, time/batch = 0.6843s	
2384/33150 (epoch 3.596), train_loss = 1.41014220, grad/param norm = 1.9146e-01, time/batch = 0.6852s	
2385/33150 (epoch 3.597), train_loss = 1.57272340, grad/param norm = 2.4027e-01, time/batch = 0.6808s	
2386/33150 (epoch 3.599), train_loss = 1.79959715, grad/param norm = 2.2313e-01, time/batch = 0.6650s	
2387/33150 (epoch 3.600), train_loss = 1.67933271, grad/param norm = 2.4359e-01, time/batch = 0.6666s	
2388/33150 (epoch 3.602), train_loss = 1.48325860, grad/param norm = 2.1970e-01, time/batch = 0.6816s	
2389/33150 (epoch 3.603), train_loss = 1.53583089, grad/param norm = 2.1085e-01, time/batch = 0.6774s	
2390/33150 (epoch 3.605), train_loss = 1.49049544, grad/param norm = 2.0334e-01, time/batch = 0.6660s	
2391/33150 (epoch 3.606), train_loss = 1.61787767, grad/param norm = 2.0532e-01, time/batch = 0.6747s	
2392/33150 (epoch 3.608), train_loss = 1.64442886, grad/param norm = 2.4104e-01, time/batch = 0.6816s	
2393/33150 (epoch 3.609), train_loss = 1.60631577, grad/param norm = 2.2506e-01, time/batch = 0.6794s	
2394/33150 (epoch 3.611), train_loss = 1.37113043, grad/param norm = 2.0124e-01, time/batch = 0.6821s	
2395/33150 (epoch 3.612), train_loss = 1.61691807, grad/param norm = 2.3233e-01, time/batch = 0.6834s	
2396/33150 (epoch 3.614), train_loss = 1.34674868, grad/param norm = 1.8178e-01, time/batch = 0.6794s	
2397/33150 (epoch 3.615), train_loss = 1.39469910, grad/param norm = 1.9096e-01, time/batch = 0.6817s	
2398/33150 (epoch 3.617), train_loss = 1.49539196, grad/param norm = 2.1208e-01, time/batch = 0.6750s	
2399/33150 (epoch 3.618), train_loss = 1.47847863, grad/param norm = 2.1537e-01, time/batch = 0.6745s	
2400/33150 (epoch 3.620), train_loss = 1.48239409, grad/param norm = 2.3003e-01, time/batch = 0.6744s	
2401/33150 (epoch 3.621), train_loss = 1.49134191, grad/param norm = 2.1355e-01, time/batch = 0.6794s	
2402/33150 (epoch 3.623), train_loss = 1.62702196, grad/param norm = 2.1612e-01, time/batch = 0.6618s	
2403/33150 (epoch 3.624), train_loss = 1.55582801, grad/param norm = 2.1052e-01, time/batch = 0.6624s	
2404/33150 (epoch 3.626), train_loss = 1.40588961, grad/param norm = 2.0441e-01, time/batch = 0.6643s	
2405/33150 (epoch 3.627), train_loss = 1.42997840, grad/param norm = 2.1896e-01, time/batch = 0.6643s	
2406/33150 (epoch 3.629), train_loss = 1.40934223, grad/param norm = 1.9534e-01, time/batch = 0.6635s	
2407/33150 (epoch 3.630), train_loss = 1.43750832, grad/param norm = 1.9937e-01, time/batch = 0.6808s	
2408/33150 (epoch 3.632), train_loss = 1.35337058, grad/param norm = 1.8348e-01, time/batch = 0.6770s	
2409/33150 (epoch 3.633), train_loss = 1.39418011, grad/param norm = 1.9637e-01, time/batch = 0.6840s	
2410/33150 (epoch 3.635), train_loss = 1.74908768, grad/param norm = 2.1176e-01, time/batch = 0.6756s	
2411/33150 (epoch 3.637), train_loss = 1.37755458, grad/param norm = 1.9889e-01, time/batch = 0.6703s	
2412/33150 (epoch 3.638), train_loss = 1.48017550, grad/param norm = 2.3327e-01, time/batch = 0.6750s	
2413/33150 (epoch 3.640), train_loss = 1.68880485, grad/param norm = 2.4536e-01, time/batch = 0.6646s	
2414/33150 (epoch 3.641), train_loss = 1.45988350, grad/param norm = 1.9682e-01, time/batch = 0.6645s	
2415/33150 (epoch 3.643), train_loss = 1.43552872, grad/param norm = 2.0487e-01, time/batch = 0.6612s	
2416/33150 (epoch 3.644), train_loss = 1.66157926, grad/param norm = 2.0099e-01, time/batch = 0.6786s	
2417/33150 (epoch 3.646), train_loss = 1.46452404, grad/param norm = 1.9082e-01, time/batch = 0.6785s	
2418/33150 (epoch 3.647), train_loss = 1.91042568, grad/param norm = 2.3395e-01, time/batch = 0.6614s	
2419/33150 (epoch 3.649), train_loss = 1.69028036, grad/param norm = 2.2890e-01, time/batch = 0.6637s	
2420/33150 (epoch 3.650), train_loss = 1.44666030, grad/param norm = 2.0680e-01, time/batch = 0.6678s	
2421/33150 (epoch 3.652), train_loss = 1.62408247, grad/param norm = 2.1010e-01, time/batch = 0.6714s	
2422/33150 (epoch 3.653), train_loss = 1.52801805, grad/param norm = 1.9376e-01, time/batch = 0.6720s	
2423/33150 (epoch 3.655), train_loss = 1.57914557, grad/param norm = 2.1825e-01, time/batch = 0.6723s	
2424/33150 (epoch 3.656), train_loss = 1.49973757, grad/param norm = 2.0318e-01, time/batch = 0.6691s	
2425/33150 (epoch 3.658), train_loss = 1.63909728, grad/param norm = 2.4131e-01, time/batch = 0.6662s	
2426/33150 (epoch 3.659), train_loss = 2.04961285, grad/param norm = 4.3737e-01, time/batch = 0.6681s	
2427/33150 (epoch 3.661), train_loss = 1.59028410, grad/param norm = 2.3488e-01, time/batch = 0.6687s	
2428/33150 (epoch 3.662), train_loss = 1.45506745, grad/param norm = 2.2287e-01, time/batch = 0.6686s	
2429/33150 (epoch 3.664), train_loss = 1.66515363, grad/param norm = 2.3270e-01, time/batch = 0.6681s	
2430/33150 (epoch 3.665), train_loss = 1.61828394, grad/param norm = 2.0084e-01, time/batch = 0.6720s	
2431/33150 (epoch 3.667), train_loss = 1.80305307, grad/param norm = 1.9743e-01, time/batch = 0.6814s	
2432/33150 (epoch 3.668), train_loss = 1.62347629, grad/param norm = 2.1405e-01, time/batch = 0.6765s	
2433/33150 (epoch 3.670), train_loss = 1.46716092, grad/param norm = 1.8238e-01, time/batch = 0.6700s	
2434/33150 (epoch 3.671), train_loss = 1.54702791, grad/param norm = 2.2321e-01, time/batch = 0.6689s	
2435/33150 (epoch 3.673), train_loss = 1.62641433, grad/param norm = 1.8872e-01, time/batch = 0.6657s	
2436/33150 (epoch 3.674), train_loss = 1.57496406, grad/param norm = 1.9925e-01, time/batch = 0.6673s	
2437/33150 (epoch 3.676), train_loss = 1.51989476, grad/param norm = 2.0151e-01, time/batch = 0.6721s	
2438/33150 (epoch 3.677), train_loss = 1.86322435, grad/param norm = 2.3119e-01, time/batch = 0.6736s	
2439/33150 (epoch 3.679), train_loss = 1.37556571, grad/param norm = 1.8470e-01, time/batch = 0.6734s	
2440/33150 (epoch 3.680), train_loss = 1.65713838, grad/param norm = 2.1270e-01, time/batch = 0.6811s	
2441/33150 (epoch 3.682), train_loss = 1.41811240, grad/param norm = 1.8935e-01, time/batch = 0.6669s	
2442/33150 (epoch 3.683), train_loss = 1.39862757, grad/param norm = 1.8421e-01, time/batch = 0.6680s	
2443/33150 (epoch 3.685), train_loss = 1.63819051, grad/param norm = 1.8922e-01, time/batch = 0.6778s	
2444/33150 (epoch 3.686), train_loss = 1.39157089, grad/param norm = 2.0993e-01, time/batch = 0.6878s	
2445/33150 (epoch 3.688), train_loss = 1.52688199, grad/param norm = 2.2764e-01, time/batch = 0.6778s	
2446/33150 (epoch 3.689), train_loss = 1.48109453, grad/param norm = 2.1943e-01, time/batch = 0.6801s	
2447/33150 (epoch 3.691), train_loss = 1.30795608, grad/param norm = 1.8419e-01, time/batch = 0.6741s	
2448/33150 (epoch 3.692), train_loss = 1.48195539, grad/param norm = 2.0595e-01, time/batch = 0.6691s	
2449/33150 (epoch 3.694), train_loss = 1.30676988, grad/param norm = 1.7167e-01, time/batch = 0.6710s	
2450/33150 (epoch 3.695), train_loss = 1.50265560, grad/param norm = 1.9429e-01, time/batch = 0.6670s	
2451/33150 (epoch 3.697), train_loss = 1.36537008, grad/param norm = 1.8511e-01, time/batch = 0.6845s	
2452/33150 (epoch 3.698), train_loss = 1.73870737, grad/param norm = 1.9985e-01, time/batch = 0.6899s	
2453/33150 (epoch 3.700), train_loss = 1.25630210, grad/param norm = 1.9542e-01, time/batch = 0.6827s	
2454/33150 (epoch 3.701), train_loss = 1.47086586, grad/param norm = 1.9962e-01, time/batch = 0.6733s	
2455/33150 (epoch 3.703), train_loss = 1.63578124, grad/param norm = 2.1252e-01, time/batch = 0.6720s	
2456/33150 (epoch 3.704), train_loss = 1.35391071, grad/param norm = 1.8428e-01, time/batch = 0.6725s	
2457/33150 (epoch 3.706), train_loss = 1.52511241, grad/param norm = 1.8599e-01, time/batch = 0.6895s	
2458/33150 (epoch 3.707), train_loss = 1.52450312, grad/param norm = 2.0355e-01, time/batch = 0.6914s	
2459/33150 (epoch 3.709), train_loss = 1.52345737, grad/param norm = 1.8247e-01, time/batch = 0.6779s	
2460/33150 (epoch 3.710), train_loss = 1.71613615, grad/param norm = 2.2880e-01, time/batch = 0.6754s	
2461/33150 (epoch 3.712), train_loss = 1.66532091, grad/param norm = 2.1551e-01, time/batch = 0.6817s	
2462/33150 (epoch 3.713), train_loss = 1.57031158, grad/param norm = 2.0233e-01, time/batch = 0.6768s	
2463/33150 (epoch 3.715), train_loss = 1.45273361, grad/param norm = 1.8615e-01, time/batch = 0.6707s	
2464/33150 (epoch 3.716), train_loss = 1.56645869, grad/param norm = 2.1577e-01, time/batch = 0.6672s	
2465/33150 (epoch 3.718), train_loss = 1.55377291, grad/param norm = 1.9042e-01, time/batch = 0.6687s	
2466/33150 (epoch 3.719), train_loss = 1.67943466, grad/param norm = 2.3414e-01, time/batch = 0.6687s	
2467/33150 (epoch 3.721), train_loss = 1.63243783, grad/param norm = 2.3365e-01, time/batch = 0.6673s	
2468/33150 (epoch 3.722), train_loss = 1.53498976, grad/param norm = 1.9836e-01, time/batch = 0.6668s	
2469/33150 (epoch 3.724), train_loss = 1.53828279, grad/param norm = 2.0787e-01, time/batch = 0.6713s	
2470/33150 (epoch 3.725), train_loss = 1.81055960, grad/param norm = 2.3557e-01, time/batch = 0.6673s	
2471/33150 (epoch 3.727), train_loss = 1.68943097, grad/param norm = 2.1224e-01, time/batch = 0.6717s	
2472/33150 (epoch 3.729), train_loss = 1.58535623, grad/param norm = 1.9902e-01, time/batch = 0.6698s	
2473/33150 (epoch 3.730), train_loss = 1.50548861, grad/param norm = 1.8306e-01, time/batch = 0.6681s	
2474/33150 (epoch 3.732), train_loss = 1.61451208, grad/param norm = 1.8795e-01, time/batch = 0.6676s	
2475/33150 (epoch 3.733), train_loss = 1.30679866, grad/param norm = 1.7927e-01, time/batch = 0.6648s	
2476/33150 (epoch 3.735), train_loss = 1.53170596, grad/param norm = 1.9323e-01, time/batch = 0.6692s	
2477/33150 (epoch 3.736), train_loss = 1.37539851, grad/param norm = 1.8904e-01, time/batch = 0.6698s	
2478/33150 (epoch 3.738), train_loss = 1.63208195, grad/param norm = 2.0518e-01, time/batch = 0.6721s	
2479/33150 (epoch 3.739), train_loss = 1.77582248, grad/param norm = 2.2728e-01, time/batch = 0.6653s	
2480/33150 (epoch 3.741), train_loss = 1.67648412, grad/param norm = 2.3821e-01, time/batch = 0.6654s	
2481/33150 (epoch 3.742), train_loss = 1.55555272, grad/param norm = 2.3177e-01, time/batch = 0.6660s	
2482/33150 (epoch 3.744), train_loss = 1.68854198, grad/param norm = 2.1807e-01, time/batch = 0.6655s	
2483/33150 (epoch 3.745), train_loss = 1.54480846, grad/param norm = 1.9572e-01, time/batch = 0.6689s	
2484/33150 (epoch 3.747), train_loss = 1.38411179, grad/param norm = 1.9315e-01, time/batch = 0.6652s	
2485/33150 (epoch 3.748), train_loss = 1.48755706, grad/param norm = 1.8276e-01, time/batch = 0.6643s	
2486/33150 (epoch 3.750), train_loss = 1.60989267, grad/param norm = 2.1190e-01, time/batch = 0.6656s	
2487/33150 (epoch 3.751), train_loss = 1.55059112, grad/param norm = 2.1249e-01, time/batch = 0.6649s	
2488/33150 (epoch 3.753), train_loss = 1.36601921, grad/param norm = 2.0161e-01, time/batch = 0.6636s	
2489/33150 (epoch 3.754), train_loss = 1.81494281, grad/param norm = 2.3861e-01, time/batch = 0.6671s	
2490/33150 (epoch 3.756), train_loss = 1.57337843, grad/param norm = 2.2169e-01, time/batch = 0.6765s	
2491/33150 (epoch 3.757), train_loss = 1.63651989, grad/param norm = 2.1962e-01, time/batch = 0.6782s	
2492/33150 (epoch 3.759), train_loss = 1.75177154, grad/param norm = 2.2227e-01, time/batch = 0.6699s	
2493/33150 (epoch 3.760), train_loss = 1.57382310, grad/param norm = 1.9734e-01, time/batch = 0.6695s	
2494/33150 (epoch 3.762), train_loss = 1.61110896, grad/param norm = 2.0256e-01, time/batch = 0.6693s	
2495/33150 (epoch 3.763), train_loss = 1.41753648, grad/param norm = 1.8934e-01, time/batch = 0.6667s	
2496/33150 (epoch 3.765), train_loss = 1.50843447, grad/param norm = 1.9303e-01, time/batch = 0.6679s	
2497/33150 (epoch 3.766), train_loss = 1.44163942, grad/param norm = 1.8638e-01, time/batch = 0.6688s	
2498/33150 (epoch 3.768), train_loss = 1.43674848, grad/param norm = 2.0235e-01, time/batch = 0.6653s	
2499/33150 (epoch 3.769), train_loss = 1.52788805, grad/param norm = 2.1011e-01, time/batch = 0.6682s	
2500/33150 (epoch 3.771), train_loss = 1.55250966, grad/param norm = 2.2052e-01, time/batch = 0.6730s	
2501/33150 (epoch 3.772), train_loss = 1.60945220, grad/param norm = 2.2694e-01, time/batch = 0.6706s	
2502/33150 (epoch 3.774), train_loss = 1.71557658, grad/param norm = 2.1495e-01, time/batch = 0.6680s	
2503/33150 (epoch 3.775), train_loss = 1.60853873, grad/param norm = 2.4061e-01, time/batch = 0.6685s	
2504/33150 (epoch 3.777), train_loss = 1.69389081, grad/param norm = 1.9575e-01, time/batch = 0.6668s	
2505/33150 (epoch 3.778), train_loss = 1.60746060, grad/param norm = 1.9123e-01, time/batch = 0.6686s	
2506/33150 (epoch 3.780), train_loss = 1.40914375, grad/param norm = 1.9178e-01, time/batch = 0.6675s	
2507/33150 (epoch 3.781), train_loss = 1.54253222, grad/param norm = 1.9442e-01, time/batch = 0.6698s	
2508/33150 (epoch 3.783), train_loss = 1.52622627, grad/param norm = 1.8392e-01, time/batch = 0.6663s	
2509/33150 (epoch 3.784), train_loss = 1.47829075, grad/param norm = 1.9739e-01, time/batch = 0.6659s	
2510/33150 (epoch 3.786), train_loss = 1.51116640, grad/param norm = 1.8593e-01, time/batch = 0.6656s	
2511/33150 (epoch 3.787), train_loss = 1.54076845, grad/param norm = 1.8696e-01, time/batch = 0.6683s	
2512/33150 (epoch 3.789), train_loss = 1.38454396, grad/param norm = 1.8615e-01, time/batch = 0.6662s	
2513/33150 (epoch 3.790), train_loss = 1.30564565, grad/param norm = 1.7652e-01, time/batch = 0.6675s	
2514/33150 (epoch 3.792), train_loss = 1.67219145, grad/param norm = 2.3512e-01, time/batch = 0.6674s	
2515/33150 (epoch 3.793), train_loss = 1.49808325, grad/param norm = 2.1206e-01, time/batch = 0.6703s	
2516/33150 (epoch 3.795), train_loss = 1.54356882, grad/param norm = 2.3540e-01, time/batch = 0.6683s	
2517/33150 (epoch 3.796), train_loss = 1.44199763, grad/param norm = 1.7977e-01, time/batch = 0.6687s	
2518/33150 (epoch 3.798), train_loss = 1.49743460, grad/param norm = 1.7665e-01, time/batch = 0.6709s	
2519/33150 (epoch 3.799), train_loss = 1.42897472, grad/param norm = 2.2860e-01, time/batch = 0.6863s	
2520/33150 (epoch 3.801), train_loss = 1.46434860, grad/param norm = 1.7588e-01, time/batch = 0.6804s	
2521/33150 (epoch 3.802), train_loss = 1.46340493, grad/param norm = 2.1039e-01, time/batch = 0.6800s	
2522/33150 (epoch 3.804), train_loss = 1.56779052, grad/param norm = 1.9908e-01, time/batch = 0.6669s	
2523/33150 (epoch 3.805), train_loss = 1.51167026, grad/param norm = 2.3157e-01, time/batch = 0.6785s	
2524/33150 (epoch 3.807), train_loss = 1.43874374, grad/param norm = 2.1558e-01, time/batch = 0.6652s	
2525/33150 (epoch 3.808), train_loss = 1.58957038, grad/param norm = 2.1833e-01, time/batch = 0.6661s	
2526/33150 (epoch 3.810), train_loss = 1.49665739, grad/param norm = 2.5818e-01, time/batch = 0.6756s	
2527/33150 (epoch 3.811), train_loss = 1.56260763, grad/param norm = 2.1897e-01, time/batch = 0.6662s	
2528/33150 (epoch 3.813), train_loss = 1.55457325, grad/param norm = 1.9820e-01, time/batch = 0.6665s	
2529/33150 (epoch 3.814), train_loss = 1.58969461, grad/param norm = 2.1129e-01, time/batch = 0.6680s	
2530/33150 (epoch 3.816), train_loss = 1.58024820, grad/param norm = 2.1243e-01, time/batch = 0.6693s	
2531/33150 (epoch 3.817), train_loss = 1.63466804, grad/param norm = 2.0908e-01, time/batch = 0.6710s	
2532/33150 (epoch 3.819), train_loss = 1.45943961, grad/param norm = 2.0422e-01, time/batch = 0.6674s	
2533/33150 (epoch 3.821), train_loss = 1.27363319, grad/param norm = 1.7244e-01, time/batch = 0.6688s	
2534/33150 (epoch 3.822), train_loss = 1.45255630, grad/param norm = 2.0304e-01, time/batch = 0.6830s	
2535/33150 (epoch 3.824), train_loss = 1.46534324, grad/param norm = 2.0585e-01, time/batch = 0.6812s	
2536/33150 (epoch 3.825), train_loss = 1.53350519, grad/param norm = 2.1393e-01, time/batch = 0.6838s	
2537/33150 (epoch 3.827), train_loss = 1.61371515, grad/param norm = 2.2786e-01, time/batch = 0.6736s	
2538/33150 (epoch 3.828), train_loss = 1.39192759, grad/param norm = 2.0393e-01, time/batch = 0.6684s	
2539/33150 (epoch 3.830), train_loss = 1.50973803, grad/param norm = 2.1640e-01, time/batch = 0.6663s	
2540/33150 (epoch 3.831), train_loss = 1.44572113, grad/param norm = 1.9740e-01, time/batch = 0.6863s	
2541/33150 (epoch 3.833), train_loss = 1.42399191, grad/param norm = 2.0673e-01, time/batch = 0.6893s	
2542/33150 (epoch 3.834), train_loss = 1.70339896, grad/param norm = 2.0488e-01, time/batch = 0.6882s	
2543/33150 (epoch 3.836), train_loss = 1.67073557, grad/param norm = 2.2060e-01, time/batch = 0.6738s	
2544/33150 (epoch 3.837), train_loss = 1.50046146, grad/param norm = 2.1587e-01, time/batch = 0.6683s	
2545/33150 (epoch 3.839), train_loss = 1.75903807, grad/param norm = 2.3098e-01, time/batch = 0.6963s	
2546/33150 (epoch 3.840), train_loss = 1.63336689, grad/param norm = 2.3422e-01, time/batch = 0.6884s	
2547/33150 (epoch 3.842), train_loss = 1.67268296, grad/param norm = 2.2878e-01, time/batch = 0.6683s	
2548/33150 (epoch 3.843), train_loss = 1.61717623, grad/param norm = 2.4755e-01, time/batch = 0.6694s	
2549/33150 (epoch 3.845), train_loss = 1.45582468, grad/param norm = 1.9062e-01, time/batch = 0.6747s	
2550/33150 (epoch 3.846), train_loss = 1.85203148, grad/param norm = 2.4039e-01, time/batch = 0.6802s	
2551/33150 (epoch 3.848), train_loss = 1.63159694, grad/param norm = 1.8892e-01, time/batch = 0.6694s	
2552/33150 (epoch 3.849), train_loss = 1.57099196, grad/param norm = 2.0925e-01, time/batch = 0.6833s	
2553/33150 (epoch 3.851), train_loss = 1.69086187, grad/param norm = 2.5046e-01, time/batch = 0.6643s	
2554/33150 (epoch 3.852), train_loss = 1.70505637, grad/param norm = 2.2964e-01, time/batch = 0.6639s	
2555/33150 (epoch 3.854), train_loss = 1.57781885, grad/param norm = 2.0667e-01, time/batch = 0.6650s	
2556/33150 (epoch 3.855), train_loss = 1.28169567, grad/param norm = 1.7589e-01, time/batch = 0.6643s	
2557/33150 (epoch 3.857), train_loss = 1.43433623, grad/param norm = 1.8367e-01, time/batch = 0.6620s	
2558/33150 (epoch 3.858), train_loss = 1.45365496, grad/param norm = 2.0295e-01, time/batch = 0.6611s	
2559/33150 (epoch 3.860), train_loss = 1.46210904, grad/param norm = 1.9321e-01, time/batch = 0.6663s	
2560/33150 (epoch 3.861), train_loss = 1.46725467, grad/param norm = 1.9194e-01, time/batch = 0.6652s	
2561/33150 (epoch 3.863), train_loss = 1.57816428, grad/param norm = 1.8640e-01, time/batch = 0.6724s	
2562/33150 (epoch 3.864), train_loss = 1.73897147, grad/param norm = 2.1296e-01, time/batch = 0.6683s	
2563/33150 (epoch 3.866), train_loss = 1.55553396, grad/param norm = 2.2566e-01, time/batch = 0.6677s	
2564/33150 (epoch 3.867), train_loss = 1.62086325, grad/param norm = 2.0519e-01, time/batch = 0.6723s	
2565/33150 (epoch 3.869), train_loss = 1.65225415, grad/param norm = 2.1916e-01, time/batch = 0.6788s	
2566/33150 (epoch 3.870), train_loss = 1.66675888, grad/param norm = 1.9971e-01, time/batch = 0.6667s	
2567/33150 (epoch 3.872), train_loss = 1.62209729, grad/param norm = 2.4275e-01, time/batch = 0.6658s	
2568/33150 (epoch 3.873), train_loss = 1.31521848, grad/param norm = 1.8857e-01, time/batch = 0.6657s	
2569/33150 (epoch 3.875), train_loss = 1.72925372, grad/param norm = 2.0468e-01, time/batch = 0.6674s	
2570/33150 (epoch 3.876), train_loss = 1.53877478, grad/param norm = 2.1629e-01, time/batch = 0.6685s	
2571/33150 (epoch 3.878), train_loss = 1.42518636, grad/param norm = 1.8326e-01, time/batch = 0.6708s	
2572/33150 (epoch 3.879), train_loss = 1.53219748, grad/param norm = 2.0303e-01, time/batch = 0.6687s	
2573/33150 (epoch 3.881), train_loss = 1.52737823, grad/param norm = 1.9429e-01, time/batch = 0.6646s	
2574/33150 (epoch 3.882), train_loss = 1.48242656, grad/param norm = 1.9445e-01, time/batch = 0.6722s	
2575/33150 (epoch 3.884), train_loss = 1.60756021, grad/param norm = 2.0381e-01, time/batch = 0.6618s	
2576/33150 (epoch 3.885), train_loss = 1.27321581, grad/param norm = 1.8112e-01, time/batch = 0.6621s	
2577/33150 (epoch 3.887), train_loss = 1.74364637, grad/param norm = 2.3581e-01, time/batch = 0.6677s	
2578/33150 (epoch 3.888), train_loss = 1.62414724, grad/param norm = 2.1660e-01, time/batch = 0.6710s	
2579/33150 (epoch 3.890), train_loss = 1.48562361, grad/param norm = 1.8357e-01, time/batch = 0.6639s	
2580/33150 (epoch 3.891), train_loss = 1.50906331, grad/param norm = 2.1391e-01, time/batch = 0.6651s	
2581/33150 (epoch 3.893), train_loss = 1.64845912, grad/param norm = 2.2377e-01, time/batch = 0.6644s	
2582/33150 (epoch 3.894), train_loss = 1.66190661, grad/param norm = 2.2750e-01, time/batch = 0.6661s	
2583/33150 (epoch 3.896), train_loss = 1.54772290, grad/param norm = 2.2452e-01, time/batch = 0.6638s	
2584/33150 (epoch 3.897), train_loss = 1.56780968, grad/param norm = 1.8448e-01, time/batch = 0.6652s	
2585/33150 (epoch 3.899), train_loss = 1.40745983, grad/param norm = 1.8259e-01, time/batch = 0.6731s	
2586/33150 (epoch 3.900), train_loss = 1.82972284, grad/param norm = 2.3646e-01, time/batch = 0.6885s	
2587/33150 (epoch 3.902), train_loss = 1.75770603, grad/param norm = 2.2939e-01, time/batch = 0.6872s	
2588/33150 (epoch 3.903), train_loss = 1.52845173, grad/param norm = 1.9438e-01, time/batch = 0.6785s	
2589/33150 (epoch 3.905), train_loss = 1.55931889, grad/param norm = 2.1937e-01, time/batch = 0.6766s	
2590/33150 (epoch 3.906), train_loss = 1.54023307, grad/param norm = 1.9219e-01, time/batch = 0.6708s	
2591/33150 (epoch 3.908), train_loss = 1.71134470, grad/param norm = 2.0714e-01, time/batch = 0.6815s	
2592/33150 (epoch 3.910), train_loss = 1.65790835, grad/param norm = 2.1934e-01, time/batch = 0.6703s	
2593/33150 (epoch 3.911), train_loss = 1.44994328, grad/param norm = 2.0576e-01, time/batch = 0.6696s	
2594/33150 (epoch 3.913), train_loss = 1.44492160, grad/param norm = 1.9673e-01, time/batch = 0.6666s	
2595/33150 (epoch 3.914), train_loss = 1.69349464, grad/param norm = 2.1327e-01, time/batch = 0.6690s	
2596/33150 (epoch 3.916), train_loss = 1.38830038, grad/param norm = 1.9470e-01, time/batch = 0.6665s	
2597/33150 (epoch 3.917), train_loss = 1.70748972, grad/param norm = 2.0633e-01, time/batch = 0.6650s	
2598/33150 (epoch 3.919), train_loss = 1.75208903, grad/param norm = 2.3898e-01, time/batch = 0.6672s	
2599/33150 (epoch 3.920), train_loss = 1.57033481, grad/param norm = 1.7914e-01, time/batch = 0.6693s	
2600/33150 (epoch 3.922), train_loss = 1.78850556, grad/param norm = 2.1541e-01, time/batch = 0.6690s	
2601/33150 (epoch 3.923), train_loss = 1.52856200, grad/param norm = 2.0823e-01, time/batch = 0.6651s	
2602/33150 (epoch 3.925), train_loss = 1.57275364, grad/param norm = 2.2182e-01, time/batch = 0.6663s	
2603/33150 (epoch 3.926), train_loss = 1.54277106, grad/param norm = 2.2386e-01, time/batch = 0.6861s	
2604/33150 (epoch 3.928), train_loss = 1.52041680, grad/param norm = 2.0766e-01, time/batch = 0.6760s	
2605/33150 (epoch 3.929), train_loss = 1.62749453, grad/param norm = 2.1002e-01, time/batch = 0.6650s	
2606/33150 (epoch 3.931), train_loss = 1.70668739, grad/param norm = 2.3913e-01, time/batch = 0.6660s	
2607/33150 (epoch 3.932), train_loss = 1.60619405, grad/param norm = 2.3102e-01, time/batch = 0.6686s	
2608/33150 (epoch 3.934), train_loss = 1.51981066, grad/param norm = 1.8587e-01, time/batch = 0.6675s	
2609/33150 (epoch 3.935), train_loss = 1.61635567, grad/param norm = 1.8285e-01, time/batch = 0.6636s	
2610/33150 (epoch 3.937), train_loss = 1.67049361, grad/param norm = 2.0055e-01, time/batch = 0.6640s	
2611/33150 (epoch 3.938), train_loss = 1.60945102, grad/param norm = 2.0057e-01, time/batch = 0.6680s	
2612/33150 (epoch 3.940), train_loss = 1.87905376, grad/param norm = 2.1354e-01, time/batch = 0.6630s	
2613/33150 (epoch 3.941), train_loss = 1.50889729, grad/param norm = 1.7592e-01, time/batch = 0.6707s	
2614/33150 (epoch 3.943), train_loss = 1.49783425, grad/param norm = 2.1179e-01, time/batch = 0.6690s	
2615/33150 (epoch 3.944), train_loss = 1.72391645, grad/param norm = 2.1526e-01, time/batch = 0.6674s	
2616/33150 (epoch 3.946), train_loss = 1.33456523, grad/param norm = 1.9727e-01, time/batch = 0.6656s	
2617/33150 (epoch 3.947), train_loss = 1.58791495, grad/param norm = 2.0160e-01, time/batch = 0.6675s	
2618/33150 (epoch 3.949), train_loss = 1.73071351, grad/param norm = 2.6869e-01, time/batch = 0.6803s	
2619/33150 (epoch 3.950), train_loss = 1.68270367, grad/param norm = 2.3147e-01, time/batch = 0.6748s	
2620/33150 (epoch 3.952), train_loss = 1.47280421, grad/param norm = 2.2389e-01, time/batch = 0.6677s	
2621/33150 (epoch 3.953), train_loss = 1.43742592, grad/param norm = 1.9244e-01, time/batch = 0.6693s	
2622/33150 (epoch 3.955), train_loss = 1.44580010, grad/param norm = 1.7825e-01, time/batch = 0.6761s	
2623/33150 (epoch 3.956), train_loss = 1.69719106, grad/param norm = 2.1839e-01, time/batch = 0.6695s	
2624/33150 (epoch 3.958), train_loss = 1.42213774, grad/param norm = 1.9029e-01, time/batch = 0.6655s	
2625/33150 (epoch 3.959), train_loss = 1.38031263, grad/param norm = 2.0632e-01, time/batch = 0.6644s	
2626/33150 (epoch 3.961), train_loss = 1.45662300, grad/param norm = 1.9102e-01, time/batch = 0.6661s	
2627/33150 (epoch 3.962), train_loss = 1.34723749, grad/param norm = 1.9591e-01, time/batch = 0.6644s	
2628/33150 (epoch 3.964), train_loss = 1.54449962, grad/param norm = 1.8535e-01, time/batch = 0.6670s	
2629/33150 (epoch 3.965), train_loss = 1.57343320, grad/param norm = 1.9579e-01, time/batch = 0.6851s	
2630/33150 (epoch 3.967), train_loss = 1.62241551, grad/param norm = 2.3369e-01, time/batch = 0.6871s	
2631/33150 (epoch 3.968), train_loss = 1.38351044, grad/param norm = 2.1837e-01, time/batch = 1.3075s	
2632/33150 (epoch 3.970), train_loss = 1.44440849, grad/param norm = 1.9413e-01, time/batch = 0.6977s	
2633/33150 (epoch 3.971), train_loss = 1.63392835, grad/param norm = 2.2332e-01, time/batch = 0.6809s	
2634/33150 (epoch 3.973), train_loss = 1.68490272, grad/param norm = 2.1094e-01, time/batch = 0.6915s	
2635/33150 (epoch 3.974), train_loss = 1.75248846, grad/param norm = 2.1699e-01, time/batch = 0.6919s	
2636/33150 (epoch 3.976), train_loss = 1.59236109, grad/param norm = 1.9219e-01, time/batch = 0.6822s	
2637/33150 (epoch 3.977), train_loss = 1.70846403, grad/param norm = 2.0741e-01, time/batch = 0.6744s	
2638/33150 (epoch 3.979), train_loss = 1.68117781, grad/param norm = 2.2746e-01, time/batch = 0.6879s	
2639/33150 (epoch 3.980), train_loss = 1.66210220, grad/param norm = 2.0701e-01, time/batch = 0.6746s	
2640/33150 (epoch 3.982), train_loss = 1.51131981, grad/param norm = 2.0923e-01, time/batch = 0.6722s	
2641/33150 (epoch 3.983), train_loss = 1.47791664, grad/param norm = 2.1878e-01, time/batch = 0.6733s	
2642/33150 (epoch 3.985), train_loss = 1.59725734, grad/param norm = 2.0716e-01, time/batch = 0.6731s	
2643/33150 (epoch 3.986), train_loss = 1.44252457, grad/param norm = 1.8525e-01, time/batch = 0.6712s	
2644/33150 (epoch 3.988), train_loss = 1.53550533, grad/param norm = 2.0877e-01, time/batch = 0.6680s	
2645/33150 (epoch 3.989), train_loss = 1.42778389, grad/param norm = 2.0376e-01, time/batch = 0.6746s	
2646/33150 (epoch 3.991), train_loss = 1.67590222, grad/param norm = 2.3760e-01, time/batch = 0.6969s	
2647/33150 (epoch 3.992), train_loss = 1.34088947, grad/param norm = 1.9078e-01, time/batch = 0.6766s	
2648/33150 (epoch 3.994), train_loss = 1.49632298, grad/param norm = 1.8703e-01, time/batch = 0.6803s	
2649/33150 (epoch 3.995), train_loss = 1.42121462, grad/param norm = 1.9130e-01, time/batch = 0.6701s	
2650/33150 (epoch 3.997), train_loss = 1.60973256, grad/param norm = 2.0744e-01, time/batch = 0.6720s	
2651/33150 (epoch 3.998), train_loss = 1.25509361, grad/param norm = 1.9131e-01, time/batch = 0.6834s	
2652/33150 (epoch 4.000), train_loss = 1.49266710, grad/param norm = 2.1780e-01, time/batch = 0.6719s	
2653/33150 (epoch 4.002), train_loss = 1.70510410, grad/param norm = 2.1946e-01, time/batch = 0.6648s	
2654/33150 (epoch 4.003), train_loss = 1.50779700, grad/param norm = 2.0182e-01, time/batch = 0.6757s	
2655/33150 (epoch 4.005), train_loss = 1.35077985, grad/param norm = 1.9497e-01, time/batch = 0.6931s	
2656/33150 (epoch 4.006), train_loss = 1.28556752, grad/param norm = 1.8122e-01, time/batch = 0.6787s	
2657/33150 (epoch 4.008), train_loss = 1.57864467, grad/param norm = 1.9437e-01, time/batch = 0.6805s	
2658/33150 (epoch 4.009), train_loss = 1.52058171, grad/param norm = 1.7715e-01, time/batch = 0.6919s	
2659/33150 (epoch 4.011), train_loss = 1.82821239, grad/param norm = 2.0409e-01, time/batch = 0.6781s	
2660/33150 (epoch 4.012), train_loss = 1.49802473, grad/param norm = 1.9278e-01, time/batch = 0.6777s	
2661/33150 (epoch 4.014), train_loss = 1.55694432, grad/param norm = 2.0727e-01, time/batch = 0.6880s	
2662/33150 (epoch 4.015), train_loss = 1.54134183, grad/param norm = 2.0760e-01, time/batch = 0.6895s	
2663/33150 (epoch 4.017), train_loss = 1.47141274, grad/param norm = 2.0828e-01, time/batch = 0.6778s	
2664/33150 (epoch 4.018), train_loss = 1.65348788, grad/param norm = 2.2472e-01, time/batch = 0.6900s	
2665/33150 (epoch 4.020), train_loss = 1.60620867, grad/param norm = 2.0342e-01, time/batch = 0.6953s	
2666/33150 (epoch 4.021), train_loss = 1.37740785, grad/param norm = 1.8896e-01, time/batch = 0.6887s	
2667/33150 (epoch 4.023), train_loss = 1.68992307, grad/param norm = 1.8988e-01, time/batch = 0.6917s	
2668/33150 (epoch 4.024), train_loss = 1.54027501, grad/param norm = 1.9442e-01, time/batch = 0.6896s	
2669/33150 (epoch 4.026), train_loss = 1.26906281, grad/param norm = 1.7256e-01, time/batch = 0.6872s	
2670/33150 (epoch 4.027), train_loss = 1.41162967, grad/param norm = 1.9979e-01, time/batch = 0.6942s	
2671/33150 (epoch 4.029), train_loss = 1.45893304, grad/param norm = 2.0683e-01, time/batch = 0.6788s	
2672/33150 (epoch 4.030), train_loss = 1.56169245, grad/param norm = 1.8964e-01, time/batch = 0.6811s	
2673/33150 (epoch 4.032), train_loss = 1.52259232, grad/param norm = 2.1589e-01, time/batch = 0.6890s	
2674/33150 (epoch 4.033), train_loss = 1.48592339, grad/param norm = 2.0825e-01, time/batch = 0.6737s	
2675/33150 (epoch 4.035), train_loss = 1.74861911, grad/param norm = 2.3352e-01, time/batch = 0.6816s	
2676/33150 (epoch 4.036), train_loss = 1.64601814, grad/param norm = 2.2675e-01, time/batch = 0.6837s	
2677/33150 (epoch 4.038), train_loss = 1.87831402, grad/param norm = 2.5616e-01, time/batch = 0.6799s	
2678/33150 (epoch 4.039), train_loss = 1.54969148, grad/param norm = 1.8559e-01, time/batch = 0.6890s	
2679/33150 (epoch 4.041), train_loss = 1.56259984, grad/param norm = 1.9075e-01, time/batch = 0.6813s	
2680/33150 (epoch 4.042), train_loss = 1.37244332, grad/param norm = 1.7273e-01, time/batch = 0.6873s	
2681/33150 (epoch 4.044), train_loss = 1.47921810, grad/param norm = 1.7946e-01, time/batch = 0.6822s	
2682/33150 (epoch 4.045), train_loss = 1.55931265, grad/param norm = 2.1325e-01, time/batch = 0.6826s	
2683/33150 (epoch 4.047), train_loss = 1.46973562, grad/param norm = 2.0433e-01, time/batch = 0.6898s	
2684/33150 (epoch 4.048), train_loss = 1.73236176, grad/param norm = 2.3434e-01, time/batch = 0.6903s	
2685/33150 (epoch 4.050), train_loss = 1.55401683, grad/param norm = 2.1036e-01, time/batch = 0.6922s	
2686/33150 (epoch 4.051), train_loss = 1.57855365, grad/param norm = 2.1087e-01, time/batch = 0.6764s	
2687/33150 (epoch 4.053), train_loss = 1.50273870, grad/param norm = 1.9453e-01, time/batch = 0.6705s	
2688/33150 (epoch 4.054), train_loss = 1.53853948, grad/param norm = 1.7664e-01, time/batch = 0.6644s	
2689/33150 (epoch 4.056), train_loss = 1.36621741, grad/param norm = 1.6769e-01, time/batch = 0.6647s	
2690/33150 (epoch 4.057), train_loss = 1.55943699, grad/param norm = 1.9456e-01, time/batch = 0.6628s	
2691/33150 (epoch 4.059), train_loss = 1.49301492, grad/param norm = 2.3578e-01, time/batch = 0.6752s	
2692/33150 (epoch 4.060), train_loss = 1.42351594, grad/param norm = 1.8278e-01, time/batch = 0.6753s	
2693/33150 (epoch 4.062), train_loss = 1.57255494, grad/param norm = 1.9198e-01, time/batch = 0.6713s	
2694/33150 (epoch 4.063), train_loss = 1.49651112, grad/param norm = 1.8580e-01, time/batch = 0.6683s	
2695/33150 (epoch 4.065), train_loss = 1.52883007, grad/param norm = 2.0019e-01, time/batch = 0.6807s	
2696/33150 (epoch 4.066), train_loss = 1.45212371, grad/param norm = 2.2067e-01, time/batch = 0.6802s	
2697/33150 (epoch 4.068), train_loss = 1.51461083, grad/param norm = 1.8684e-01, time/batch = 0.6841s	
2698/33150 (epoch 4.069), train_loss = 1.63885269, grad/param norm = 2.2398e-01, time/batch = 0.6812s	
2699/33150 (epoch 4.071), train_loss = 1.61174899, grad/param norm = 2.1093e-01, time/batch = 0.6671s	
2700/33150 (epoch 4.072), train_loss = 1.37606429, grad/param norm = 1.8907e-01, time/batch = 0.6696s	
2701/33150 (epoch 4.074), train_loss = 1.35659588, grad/param norm = 1.9487e-01, time/batch = 0.6762s	
2702/33150 (epoch 4.075), train_loss = 1.51492259, grad/param norm = 2.0282e-01, time/batch = 0.6762s	
2703/33150 (epoch 4.077), train_loss = 1.67013654, grad/param norm = 2.3999e-01, time/batch = 0.6736s	
2704/33150 (epoch 4.078), train_loss = 1.69963483, grad/param norm = 2.2720e-01, time/batch = 0.6749s	
2705/33150 (epoch 4.080), train_loss = 1.64627728, grad/param norm = 1.7931e-01, time/batch = 0.6729s	
2706/33150 (epoch 4.081), train_loss = 1.48162053, grad/param norm = 2.1588e-01, time/batch = 0.6745s	
2707/33150 (epoch 4.083), train_loss = 1.21417304, grad/param norm = 1.8755e-01, time/batch = 0.6755s	
2708/33150 (epoch 4.084), train_loss = 1.41092480, grad/param norm = 2.0052e-01, time/batch = 0.6700s	
2709/33150 (epoch 4.086), train_loss = 1.46211077, grad/param norm = 2.0067e-01, time/batch = 0.6752s	
2710/33150 (epoch 4.087), train_loss = 1.37869453, grad/param norm = 1.9030e-01, time/batch = 0.6882s	
2711/33150 (epoch 4.089), train_loss = 1.39435434, grad/param norm = 2.1418e-01, time/batch = 0.6824s	
2712/33150 (epoch 4.090), train_loss = 1.46884695, grad/param norm = 2.2068e-01, time/batch = 0.6717s	
2713/33150 (epoch 4.092), train_loss = 1.59425482, grad/param norm = 2.0121e-01, time/batch = 0.6761s	
2714/33150 (epoch 4.094), train_loss = 1.61651539, grad/param norm = 2.1629e-01, time/batch = 0.6703s	
2715/33150 (epoch 4.095), train_loss = 1.35123034, grad/param norm = 1.8628e-01, time/batch = 0.6688s	
2716/33150 (epoch 4.097), train_loss = 1.64089735, grad/param norm = 2.1135e-01, time/batch = 0.6875s	
2717/33150 (epoch 4.098), train_loss = 1.77858141, grad/param norm = 2.1389e-01, time/batch = 0.6860s	
2718/33150 (epoch 4.100), train_loss = 1.67471491, grad/param norm = 2.1232e-01, time/batch = 0.6843s	
2719/33150 (epoch 4.101), train_loss = 1.43789790, grad/param norm = 2.1040e-01, time/batch = 0.6944s	
2720/33150 (epoch 4.103), train_loss = 1.57526569, grad/param norm = 1.9571e-01, time/batch = 0.6956s	
2721/33150 (epoch 4.104), train_loss = 1.49127616, grad/param norm = 1.9821e-01, time/batch = 0.6925s	
2722/33150 (epoch 4.106), train_loss = 1.71903719, grad/param norm = 2.0442e-01, time/batch = 0.7025s	
2723/33150 (epoch 4.107), train_loss = 1.72275206, grad/param norm = 2.0588e-01, time/batch = 0.6916s	
2724/33150 (epoch 4.109), train_loss = 1.44638603, grad/param norm = 1.9381e-01, time/batch = 0.6891s	
2725/33150 (epoch 4.110), train_loss = 1.61248803, grad/param norm = 1.9059e-01, time/batch = 0.6923s	
2726/33150 (epoch 4.112), train_loss = 1.41939953, grad/param norm = 1.8823e-01, time/batch = 0.6900s	
2727/33150 (epoch 4.113), train_loss = 1.45661734, grad/param norm = 2.1595e-01, time/batch = 0.6878s	
2728/33150 (epoch 4.115), train_loss = 1.66002954, grad/param norm = 2.2714e-01, time/batch = 0.6894s	
2729/33150 (epoch 4.116), train_loss = 1.38542905, grad/param norm = 2.0452e-01, time/batch = 0.6998s	
2730/33150 (epoch 4.118), train_loss = 1.61240201, grad/param norm = 2.3334e-01, time/batch = 0.6950s	
2731/33150 (epoch 4.119), train_loss = 1.60607994, grad/param norm = 2.0779e-01, time/batch = 0.6884s	
2732/33150 (epoch 4.121), train_loss = 1.47743087, grad/param norm = 1.9600e-01, time/batch = 0.6895s	
2733/33150 (epoch 4.122), train_loss = 1.67478702, grad/param norm = 2.2124e-01, time/batch = 0.6875s	
2734/33150 (epoch 4.124), train_loss = 1.26508311, grad/param norm = 1.9039e-01, time/batch = 0.6913s	
2735/33150 (epoch 4.125), train_loss = 1.52873125, grad/param norm = 1.8615e-01, time/batch = 0.6851s	
2736/33150 (epoch 4.127), train_loss = 1.40543311, grad/param norm = 1.8714e-01, time/batch = 0.6807s	
2737/33150 (epoch 4.128), train_loss = 1.56380671, grad/param norm = 2.0016e-01, time/batch = 0.6923s	
2738/33150 (epoch 4.130), train_loss = 1.60142278, grad/param norm = 2.0298e-01, time/batch = 0.6911s	
2739/33150 (epoch 4.131), train_loss = 1.71872574, grad/param norm = 2.0862e-01, time/batch = 0.6945s	
2740/33150 (epoch 4.133), train_loss = 1.39522158, grad/param norm = 1.9089e-01, time/batch = 0.6896s	
2741/33150 (epoch 4.134), train_loss = 1.61286099, grad/param norm = 2.0777e-01, time/batch = 0.6919s	
2742/33150 (epoch 4.136), train_loss = 1.47232910, grad/param norm = 1.8173e-01, time/batch = 0.6921s	
2743/33150 (epoch 4.137), train_loss = 1.59284880, grad/param norm = 2.1075e-01, time/batch = 0.6915s	
2744/33150 (epoch 4.139), train_loss = 1.55720779, grad/param norm = 2.1009e-01, time/batch = 0.6883s	
2745/33150 (epoch 4.140), train_loss = 1.64266553, grad/param norm = 2.2911e-01, time/batch = 0.6851s	
2746/33150 (epoch 4.142), train_loss = 1.59415708, grad/param norm = 2.2326e-01, time/batch = 0.6811s	
2747/33150 (epoch 4.143), train_loss = 1.59284720, grad/param norm = 2.0929e-01, time/batch = 0.6941s	
2748/33150 (epoch 4.145), train_loss = 1.53270054, grad/param norm = 2.1340e-01, time/batch = 0.6968s	
2749/33150 (epoch 4.146), train_loss = 1.70526710, grad/param norm = 2.3841e-01, time/batch = 0.6955s	
2750/33150 (epoch 4.148), train_loss = 1.60961594, grad/param norm = 1.9906e-01, time/batch = 0.6812s	
2751/33150 (epoch 4.149), train_loss = 1.58732112, grad/param norm = 2.3112e-01, time/batch = 0.6797s	
2752/33150 (epoch 4.151), train_loss = 1.78721470, grad/param norm = 2.1804e-01, time/batch = 0.6776s	
2753/33150 (epoch 4.152), train_loss = 1.43152058, grad/param norm = 1.8141e-01, time/batch = 0.6793s	
2754/33150 (epoch 4.154), train_loss = 1.48240110, grad/param norm = 1.9246e-01, time/batch = 0.6747s	
2755/33150 (epoch 4.155), train_loss = 1.39544449, grad/param norm = 2.0099e-01, time/batch = 0.6875s	
2756/33150 (epoch 4.157), train_loss = 1.46993273, grad/param norm = 2.1647e-01, time/batch = 0.6848s	
2757/33150 (epoch 4.158), train_loss = 1.39024993, grad/param norm = 2.0523e-01, time/batch = 0.6754s	
2758/33150 (epoch 4.160), train_loss = 1.63978623, grad/param norm = 2.0908e-01, time/batch = 0.6774s	
2759/33150 (epoch 4.161), train_loss = 1.50218882, grad/param norm = 2.1471e-01, time/batch = 0.6798s	
2760/33150 (epoch 4.163), train_loss = 1.47817102, grad/param norm = 1.8542e-01, time/batch = 0.6895s	
2761/33150 (epoch 4.164), train_loss = 1.61029634, grad/param norm = 1.9549e-01, time/batch = 0.6931s	
2762/33150 (epoch 4.166), train_loss = 1.58461727, grad/param norm = 2.1094e-01, time/batch = 0.6818s	
2763/33150 (epoch 4.167), train_loss = 1.56300524, grad/param norm = 1.8715e-01, time/batch = 0.6777s	
2764/33150 (epoch 4.169), train_loss = 1.74512514, grad/param norm = 2.3718e-01, time/batch = 0.6760s	
2765/33150 (epoch 4.170), train_loss = 1.55087121, grad/param norm = 2.0466e-01, time/batch = 0.6814s	
2766/33150 (epoch 4.172), train_loss = 1.65656300, grad/param norm = 2.0095e-01, time/batch = 0.6814s	
2767/33150 (epoch 4.173), train_loss = 1.66278488, grad/param norm = 2.3490e-01, time/batch = 0.6822s	
2768/33150 (epoch 4.175), train_loss = 1.41955826, grad/param norm = 1.9459e-01, time/batch = 0.6795s	
2769/33150 (epoch 4.176), train_loss = 1.52775571, grad/param norm = 2.1447e-01, time/batch = 0.6756s	
2770/33150 (epoch 4.178), train_loss = 1.66315408, grad/param norm = 2.0713e-01, time/batch = 0.6789s	
2771/33150 (epoch 4.179), train_loss = 1.55984748, grad/param norm = 1.7548e-01, time/batch = 0.6807s	
2772/33150 (epoch 4.181), train_loss = 1.54014255, grad/param norm = 2.1908e-01, time/batch = 0.6844s	
2773/33150 (epoch 4.183), train_loss = 1.58369185, grad/param norm = 2.4747e-01, time/batch = 0.6838s	
2774/33150 (epoch 4.184), train_loss = 1.68471104, grad/param norm = 2.2238e-01, time/batch = 0.6788s	
2775/33150 (epoch 4.186), train_loss = 1.68130399, grad/param norm = 2.0506e-01, time/batch = 0.6859s	
2776/33150 (epoch 4.187), train_loss = 1.51028760, grad/param norm = 1.9962e-01, time/batch = 0.6773s	
2777/33150 (epoch 4.189), train_loss = 1.38567235, grad/param norm = 2.1071e-01, time/batch = 0.6758s	
2778/33150 (epoch 4.190), train_loss = 1.47301748, grad/param norm = 2.0002e-01, time/batch = 0.6856s	
2779/33150 (epoch 4.192), train_loss = 1.56093940, grad/param norm = 2.0445e-01, time/batch = 0.6865s	
2780/33150 (epoch 4.193), train_loss = 1.49952927, grad/param norm = 1.8413e-01, time/batch = 0.6860s	
2781/33150 (epoch 4.195), train_loss = 1.84364433, grad/param norm = 2.2124e-01, time/batch = 0.6860s	
2782/33150 (epoch 4.196), train_loss = 1.62428469, grad/param norm = 1.9376e-01, time/batch = 0.6914s	
2783/33150 (epoch 4.198), train_loss = 1.42004917, grad/param norm = 1.9146e-01, time/batch = 0.6851s	
2784/33150 (epoch 4.199), train_loss = 1.61370369, grad/param norm = 2.1132e-01, time/batch = 0.6898s	
2785/33150 (epoch 4.201), train_loss = 1.36060076, grad/param norm = 1.7485e-01, time/batch = 0.6808s	
2786/33150 (epoch 4.202), train_loss = 1.28924842, grad/param norm = 1.6661e-01, time/batch = 0.6820s	
2787/33150 (epoch 4.204), train_loss = 1.48555031, grad/param norm = 1.7979e-01, time/batch = 0.6890s	
2788/33150 (epoch 4.205), train_loss = 1.66394367, grad/param norm = 2.1995e-01, time/batch = 0.6869s	
2789/33150 (epoch 4.207), train_loss = 1.53650246, grad/param norm = 2.2867e-01, time/batch = 0.6924s	
2790/33150 (epoch 4.208), train_loss = 1.57576612, grad/param norm = 1.9082e-01, time/batch = 0.6867s	
2791/33150 (epoch 4.210), train_loss = 1.37249234, grad/param norm = 1.8084e-01, time/batch = 0.6902s	
2792/33150 (epoch 4.211), train_loss = 1.58584397, grad/param norm = 2.0029e-01, time/batch = 0.6812s	
2793/33150 (epoch 4.213), train_loss = 1.69144248, grad/param norm = 1.9283e-01, time/batch = 0.6854s	
2794/33150 (epoch 4.214), train_loss = 1.47847345, grad/param norm = 1.9710e-01, time/batch = 0.6900s	
2795/33150 (epoch 4.216), train_loss = 1.51193650, grad/param norm = 2.0629e-01, time/batch = 0.6840s	
2796/33150 (epoch 4.217), train_loss = 1.47250047, grad/param norm = 1.7981e-01, time/batch = 0.6893s	
2797/33150 (epoch 4.219), train_loss = 1.43058792, grad/param norm = 1.8152e-01, time/batch = 0.6859s	
2798/33150 (epoch 4.220), train_loss = 1.35590634, grad/param norm = 1.7668e-01, time/batch = 0.6889s	
2799/33150 (epoch 4.222), train_loss = 1.59463641, grad/param norm = 2.0219e-01, time/batch = 0.6822s	
2800/33150 (epoch 4.223), train_loss = 1.49127312, grad/param norm = 1.8035e-01, time/batch = 0.6901s	
2801/33150 (epoch 4.225), train_loss = 1.73020349, grad/param norm = 2.1363e-01, time/batch = 0.6967s	
2802/33150 (epoch 4.226), train_loss = 1.46443730, grad/param norm = 1.8861e-01, time/batch = 0.6893s	
2803/33150 (epoch 4.228), train_loss = 1.52631429, grad/param norm = 2.1199e-01, time/batch = 0.6878s	
2804/33150 (epoch 4.229), train_loss = 1.52055061, grad/param norm = 2.0220e-01, time/batch = 0.6857s	
2805/33150 (epoch 4.231), train_loss = 1.62881847, grad/param norm = 2.1516e-01, time/batch = 0.6907s	
2806/33150 (epoch 4.232), train_loss = 1.55911343, grad/param norm = 2.2460e-01, time/batch = 0.6880s	
2807/33150 (epoch 4.234), train_loss = 1.46097012, grad/param norm = 2.1169e-01, time/batch = 0.6899s	
2808/33150 (epoch 4.235), train_loss = 1.55829355, grad/param norm = 2.0227e-01, time/batch = 0.6828s	
2809/33150 (epoch 4.237), train_loss = 1.49070989, grad/param norm = 2.1733e-01, time/batch = 0.6854s	
2810/33150 (epoch 4.238), train_loss = 1.71943804, grad/param norm = 2.1206e-01, time/batch = 0.6866s	
2811/33150 (epoch 4.240), train_loss = 1.51410654, grad/param norm = 1.8410e-01, time/batch = 0.6903s	
2812/33150 (epoch 4.241), train_loss = 1.63341841, grad/param norm = 2.1492e-01, time/batch = 0.6859s	
2813/33150 (epoch 4.243), train_loss = 1.68651987, grad/param norm = 2.0169e-01, time/batch = 0.6860s	
2814/33150 (epoch 4.244), train_loss = 1.46807883, grad/param norm = 1.7361e-01, time/batch = 0.6854s	
2815/33150 (epoch 4.246), train_loss = 1.55683517, grad/param norm = 2.0458e-01, time/batch = 0.6884s	
2816/33150 (epoch 4.247), train_loss = 1.39401982, grad/param norm = 1.8922e-01, time/batch = 0.6832s	
2817/33150 (epoch 4.249), train_loss = 1.74001157, grad/param norm = 2.1970e-01, time/batch = 0.6880s	
2818/33150 (epoch 4.250), train_loss = 1.53950053, grad/param norm = 1.8397e-01, time/batch = 0.6947s	
2819/33150 (epoch 4.252), train_loss = 1.51656923, grad/param norm = 1.6965e-01, time/batch = 0.6835s	
2820/33150 (epoch 4.253), train_loss = 1.61506729, grad/param norm = 2.0876e-01, time/batch = 0.6805s	
2821/33150 (epoch 4.255), train_loss = 1.51619533, grad/param norm = 1.8615e-01, time/batch = 0.6861s	
2822/33150 (epoch 4.256), train_loss = 1.62241596, grad/param norm = 2.0375e-01, time/batch = 0.6800s	
2823/33150 (epoch 4.258), train_loss = 1.52512531, grad/param norm = 2.2399e-01, time/batch = 0.6788s	
2824/33150 (epoch 4.259), train_loss = 1.28834163, grad/param norm = 1.9360e-01, time/batch = 0.6779s	
2825/33150 (epoch 4.261), train_loss = 1.36291532, grad/param norm = 1.8641e-01, time/batch = 0.6915s	
2826/33150 (epoch 4.262), train_loss = 1.57423105, grad/param norm = 2.2901e-01, time/batch = 0.6797s	
2827/33150 (epoch 4.264), train_loss = 1.21254510, grad/param norm = 2.0185e-01, time/batch = 0.6862s	
2828/33150 (epoch 4.265), train_loss = 1.51732440, grad/param norm = 1.9594e-01, time/batch = 0.6849s	
2829/33150 (epoch 4.267), train_loss = 1.64731448, grad/param norm = 2.1170e-01, time/batch = 0.6962s	
2830/33150 (epoch 4.268), train_loss = 1.40499118, grad/param norm = 2.0195e-01, time/batch = 0.6866s	
2831/33150 (epoch 4.270), train_loss = 1.72632452, grad/param norm = 1.9565e-01, time/batch = 0.6902s	
2832/33150 (epoch 4.271), train_loss = 1.68643201, grad/param norm = 2.2037e-01, time/batch = 0.6875s	
2833/33150 (epoch 4.273), train_loss = 1.59900453, grad/param norm = 2.1436e-01, time/batch = 0.6802s	
2834/33150 (epoch 4.275), train_loss = 1.63969680, grad/param norm = 2.0369e-01, time/batch = 0.6826s	
2835/33150 (epoch 4.276), train_loss = 1.51395094, grad/param norm = 1.8623e-01, time/batch = 0.6827s	
2836/33150 (epoch 4.278), train_loss = 1.68390820, grad/param norm = 2.0725e-01, time/batch = 0.6708s	
2837/33150 (epoch 4.279), train_loss = 1.51009144, grad/param norm = 1.9393e-01, time/batch = 0.6828s	
2838/33150 (epoch 4.281), train_loss = 1.67087782, grad/param norm = 2.0397e-01, time/batch = 0.6884s	
2839/33150 (epoch 4.282), train_loss = 1.55381788, grad/param norm = 1.9565e-01, time/batch = 0.6835s	
2840/33150 (epoch 4.284), train_loss = 1.51174640, grad/param norm = 1.8311e-01, time/batch = 0.6831s	
2841/33150 (epoch 4.285), train_loss = 1.58591859, grad/param norm = 2.2239e-01, time/batch = 0.6876s	
2842/33150 (epoch 4.287), train_loss = 1.47355835, grad/param norm = 1.8491e-01, time/batch = 0.6844s	
2843/33150 (epoch 4.288), train_loss = 1.73623323, grad/param norm = 2.0725e-01, time/batch = 0.6723s	
2844/33150 (epoch 4.290), train_loss = 1.37804094, grad/param norm = 2.0521e-01, time/batch = 0.6658s	
2845/33150 (epoch 4.291), train_loss = 1.45196456, grad/param norm = 2.1831e-01, time/batch = 0.6780s	
2846/33150 (epoch 4.293), train_loss = 1.58177416, grad/param norm = 2.0547e-01, time/batch = 0.6682s	
2847/33150 (epoch 4.294), train_loss = 1.25720874, grad/param norm = 1.8154e-01, time/batch = 0.6738s	
2848/33150 (epoch 4.296), train_loss = 1.46410723, grad/param norm = 1.9718e-01, time/batch = 0.6711s	
2849/33150 (epoch 4.297), train_loss = 1.51719573, grad/param norm = 2.0115e-01, time/batch = 0.6687s	
2850/33150 (epoch 4.299), train_loss = 1.43556769, grad/param norm = 2.1075e-01, time/batch = 0.6748s	
2851/33150 (epoch 4.300), train_loss = 1.46947418, grad/param norm = 1.8335e-01, time/batch = 0.6821s	
2852/33150 (epoch 4.302), train_loss = 1.49526516, grad/param norm = 2.1071e-01, time/batch = 0.6669s	
2853/33150 (epoch 4.303), train_loss = 1.60600423, grad/param norm = 2.0858e-01, time/batch = 0.6665s	
2854/33150 (epoch 4.305), train_loss = 1.52964290, grad/param norm = 1.9157e-01, time/batch = 0.6667s	
2855/33150 (epoch 4.306), train_loss = 1.64047172, grad/param norm = 2.0916e-01, time/batch = 0.6669s	
2856/33150 (epoch 4.308), train_loss = 1.76916345, grad/param norm = 1.9851e-01, time/batch = 0.6742s	
2857/33150 (epoch 4.309), train_loss = 1.38819123, grad/param norm = 1.8371e-01, time/batch = 0.6743s	
2858/33150 (epoch 4.311), train_loss = 1.60456666, grad/param norm = 2.1453e-01, time/batch = 0.6683s	
2859/33150 (epoch 4.312), train_loss = 1.36003683, grad/param norm = 2.0191e-01, time/batch = 0.6702s	
2860/33150 (epoch 4.314), train_loss = 1.54960548, grad/param norm = 2.0715e-01, time/batch = 0.6698s	
2861/33150 (epoch 4.315), train_loss = 1.61831881, grad/param norm = 1.9637e-01, time/batch = 0.6745s	
2862/33150 (epoch 4.317), train_loss = 1.25455753, grad/param norm = 1.6750e-01, time/batch = 0.6701s	
2863/33150 (epoch 4.318), train_loss = 1.36829903, grad/param norm = 1.6525e-01, time/batch = 0.6913s	
2864/33150 (epoch 4.320), train_loss = 1.35290465, grad/param norm = 1.8415e-01, time/batch = 0.6731s	
2865/33150 (epoch 4.321), train_loss = 1.44510251, grad/param norm = 1.8654e-01, time/batch = 0.6706s	
2866/33150 (epoch 4.323), train_loss = 1.55311904, grad/param norm = 1.9339e-01, time/batch = 0.6683s	
2867/33150 (epoch 4.324), train_loss = 1.66162694, grad/param norm = 2.1144e-01, time/batch = 0.6709s	
2868/33150 (epoch 4.326), train_loss = 1.50771908, grad/param norm = 1.8165e-01, time/batch = 0.6705s	
2869/33150 (epoch 4.327), train_loss = 1.63579822, grad/param norm = 2.0087e-01, time/batch = 0.6757s	
2870/33150 (epoch 4.329), train_loss = 1.52899949, grad/param norm = 1.7971e-01, time/batch = 0.6662s	
2871/33150 (epoch 4.330), train_loss = 1.64027214, grad/param norm = 2.3032e-01, time/batch = 0.6640s	
2872/33150 (epoch 4.332), train_loss = 1.48051696, grad/param norm = 1.9082e-01, time/batch = 0.6723s	
2873/33150 (epoch 4.333), train_loss = 1.53365166, grad/param norm = 1.7964e-01, time/batch = 0.6796s	
2874/33150 (epoch 4.335), train_loss = 1.55653337, grad/param norm = 1.9225e-01, time/batch = 0.6706s	
2875/33150 (epoch 4.336), train_loss = 1.40146047, grad/param norm = 1.8604e-01, time/batch = 0.6655s	
2876/33150 (epoch 4.338), train_loss = 1.24913357, grad/param norm = 1.7435e-01, time/batch = 0.6755s	
2877/33150 (epoch 4.339), train_loss = 1.62916507, grad/param norm = 1.9512e-01, time/batch = 0.6664s	
2878/33150 (epoch 4.341), train_loss = 1.76330973, grad/param norm = 2.2858e-01, time/batch = 0.6609s	
2879/33150 (epoch 4.342), train_loss = 1.40774535, grad/param norm = 2.0526e-01, time/batch = 0.6628s	
2880/33150 (epoch 4.344), train_loss = 1.57053163, grad/param norm = 1.9584e-01, time/batch = 0.6657s	
2881/33150 (epoch 4.345), train_loss = 1.31902395, grad/param norm = 1.8709e-01, time/batch = 0.6675s	
2882/33150 (epoch 4.347), train_loss = 1.23744936, grad/param norm = 1.6776e-01, time/batch = 0.6701s	
2883/33150 (epoch 4.348), train_loss = 1.46785732, grad/param norm = 1.9544e-01, time/batch = 0.6815s	
2884/33150 (epoch 4.350), train_loss = 1.59601229, grad/param norm = 2.4136e-01, time/batch = 0.6720s	
2885/33150 (epoch 4.351), train_loss = 1.61841257, grad/param norm = 2.0114e-01, time/batch = 0.6708s	
2886/33150 (epoch 4.353), train_loss = 1.68639720, grad/param norm = 2.0845e-01, time/batch = 0.6836s	
2887/33150 (epoch 4.354), train_loss = 1.77209383, grad/param norm = 2.1595e-01, time/batch = 0.6720s	
2888/33150 (epoch 4.356), train_loss = 1.65464719, grad/param norm = 2.3201e-01, time/batch = 0.6908s	
2889/33150 (epoch 4.357), train_loss = 1.62922510, grad/param norm = 2.0396e-01, time/batch = 0.6678s	
2890/33150 (epoch 4.359), train_loss = 1.55639535, grad/param norm = 1.9757e-01, time/batch = 0.6676s	
2891/33150 (epoch 4.360), train_loss = 1.66543300, grad/param norm = 2.1289e-01, time/batch = 0.6865s	
2892/33150 (epoch 4.362), train_loss = 1.54515964, grad/param norm = 1.9499e-01, time/batch = 0.6880s	
2893/33150 (epoch 4.363), train_loss = 1.46811882, grad/param norm = 1.7457e-01, time/batch = 0.6800s	
2894/33150 (epoch 4.365), train_loss = 1.48390116, grad/param norm = 1.7265e-01, time/batch = 0.6711s	
2895/33150 (epoch 4.367), train_loss = 1.36488080, grad/param norm = 1.8604e-01, time/batch = 0.6670s	
2896/33150 (epoch 4.368), train_loss = 1.59029794, grad/param norm = 1.9720e-01, time/batch = 0.6673s	
2897/33150 (epoch 4.370), train_loss = 1.68009737, grad/param norm = 2.1637e-01, time/batch = 0.6698s	
2898/33150 (epoch 4.371), train_loss = 1.43811838, grad/param norm = 1.9325e-01, time/batch = 0.6685s	
2899/33150 (epoch 4.373), train_loss = 1.66187449, grad/param norm = 2.0346e-01, time/batch = 0.6708s	
2900/33150 (epoch 4.374), train_loss = 1.39798739, grad/param norm = 1.8322e-01, time/batch = 0.6841s	
2901/33150 (epoch 4.376), train_loss = 1.66685877, grad/param norm = 1.8783e-01, time/batch = 0.6705s	
2902/33150 (epoch 4.377), train_loss = 1.58019812, grad/param norm = 2.1737e-01, time/batch = 0.7002s	
2903/33150 (epoch 4.379), train_loss = 1.59783269, grad/param norm = 2.1165e-01, time/batch = 0.6868s	
2904/33150 (epoch 4.380), train_loss = 1.64348368, grad/param norm = 1.9981e-01, time/batch = 0.6795s	
2905/33150 (epoch 4.382), train_loss = 1.39990409, grad/param norm = 1.8833e-01, time/batch = 0.6681s	
2906/33150 (epoch 4.383), train_loss = 1.39470109, grad/param norm = 1.9182e-01, time/batch = 0.6709s	
2907/33150 (epoch 4.385), train_loss = 1.53837772, grad/param norm = 1.8534e-01, time/batch = 0.6662s	
2908/33150 (epoch 4.386), train_loss = 1.38533911, grad/param norm = 1.7696e-01, time/batch = 0.6637s	
2909/33150 (epoch 4.388), train_loss = 1.48723924, grad/param norm = 1.9217e-01, time/batch = 0.6877s	
2910/33150 (epoch 4.389), train_loss = 1.46363462, grad/param norm = 1.9375e-01, time/batch = 0.6746s	
2911/33150 (epoch 4.391), train_loss = 1.72873045, grad/param norm = 2.1508e-01, time/batch = 0.6798s	
2912/33150 (epoch 4.392), train_loss = 1.45699879, grad/param norm = 1.9508e-01, time/batch = 0.6863s	
2913/33150 (epoch 4.394), train_loss = 1.35712968, grad/param norm = 1.7279e-01, time/batch = 0.6884s	
2914/33150 (epoch 4.395), train_loss = 1.49338877, grad/param norm = 2.1462e-01, time/batch = 0.6858s	
2915/33150 (epoch 4.397), train_loss = 1.17647846, grad/param norm = 1.7509e-01, time/batch = 0.6770s	
2916/33150 (epoch 4.398), train_loss = 1.57268871, grad/param norm = 2.0576e-01, time/batch = 0.6718s	
2917/33150 (epoch 4.400), train_loss = 1.46741542, grad/param norm = 1.7147e-01, time/batch = 0.6723s	
2918/33150 (epoch 4.401), train_loss = 1.31124805, grad/param norm = 1.7544e-01, time/batch = 0.6665s	
2919/33150 (epoch 4.403), train_loss = 1.38404310, grad/param norm = 1.8546e-01, time/batch = 0.6680s	
2920/33150 (epoch 4.404), train_loss = 1.43384183, grad/param norm = 1.8650e-01, time/batch = 0.6685s	
2921/33150 (epoch 4.406), train_loss = 1.35486376, grad/param norm = 1.6553e-01, time/batch = 0.6759s	
2922/33150 (epoch 4.407), train_loss = 1.36791415, grad/param norm = 1.7152e-01, time/batch = 0.6677s	
2923/33150 (epoch 4.409), train_loss = 1.25902486, grad/param norm = 1.9153e-01, time/batch = 0.6923s	
2924/33150 (epoch 4.410), train_loss = 1.59649550, grad/param norm = 2.3102e-01, time/batch = 0.6777s	
2925/33150 (epoch 4.412), train_loss = 1.63403577, grad/param norm = 2.0783e-01, time/batch = 0.6755s	
2926/33150 (epoch 4.413), train_loss = 1.48346179, grad/param norm = 1.9770e-01, time/batch = 0.6659s	
2927/33150 (epoch 4.415), train_loss = 1.68012053, grad/param norm = 2.0077e-01, time/batch = 0.6690s	
2928/33150 (epoch 4.416), train_loss = 1.51600682, grad/param norm = 1.8538e-01, time/batch = 0.6725s	
2929/33150 (epoch 4.418), train_loss = 1.80716716, grad/param norm = 2.3886e-01, time/batch = 0.6680s	
2930/33150 (epoch 4.419), train_loss = 1.42978668, grad/param norm = 2.1712e-01, time/batch = 0.6685s	
2931/33150 (epoch 4.421), train_loss = 1.58063623, grad/param norm = 2.0650e-01, time/batch = 0.6712s	
2932/33150 (epoch 4.422), train_loss = 1.40086679, grad/param norm = 1.8760e-01, time/batch = 0.6699s	
2933/33150 (epoch 4.424), train_loss = 1.49863948, grad/param norm = 2.2154e-01, time/batch = 0.6643s	
2934/33150 (epoch 4.425), train_loss = 1.42384672, grad/param norm = 2.1038e-01, time/batch = 0.6795s	
2935/33150 (epoch 4.427), train_loss = 1.42221233, grad/param norm = 1.8753e-01, time/batch = 0.6856s	
2936/33150 (epoch 4.428), train_loss = 1.54379553, grad/param norm = 1.9722e-01, time/batch = 0.6655s	
2937/33150 (epoch 4.430), train_loss = 1.55480485, grad/param norm = 1.8952e-01, time/batch = 0.6610s	
2938/33150 (epoch 4.431), train_loss = 1.56923244, grad/param norm = 1.9017e-01, time/batch = 0.6648s	
2939/33150 (epoch 4.433), train_loss = 1.53378052, grad/param norm = 1.6899e-01, time/batch = 0.6779s	
2940/33150 (epoch 4.434), train_loss = 1.32298297, grad/param norm = 1.9182e-01, time/batch = 0.6679s	
2941/33150 (epoch 4.436), train_loss = 1.31032675, grad/param norm = 1.8961e-01, time/batch = 0.6724s	
2942/33150 (epoch 4.437), train_loss = 1.53955821, grad/param norm = 2.1743e-01, time/batch = 0.6816s	
2943/33150 (epoch 4.439), train_loss = 1.58499117, grad/param norm = 1.9968e-01, time/batch = 0.6646s	
2944/33150 (epoch 4.440), train_loss = 1.61090724, grad/param norm = 2.2705e-01, time/batch = 0.6641s	
2945/33150 (epoch 4.442), train_loss = 1.31202709, grad/param norm = 1.9575e-01, time/batch = 0.6618s	
2946/33150 (epoch 4.443), train_loss = 1.57504142, grad/param norm = 1.9575e-01, time/batch = 0.6620s	
2947/33150 (epoch 4.445), train_loss = 1.54002335, grad/param norm = 1.9628e-01, time/batch = 0.6810s	
2948/33150 (epoch 4.446), train_loss = 1.58006996, grad/param norm = 2.3583e-01, time/batch = 0.6679s	
2949/33150 (epoch 4.448), train_loss = 1.49579518, grad/param norm = 1.9913e-01, time/batch = 0.6675s	
2950/33150 (epoch 4.449), train_loss = 1.44489726, grad/param norm = 1.7303e-01, time/batch = 0.6671s	
2951/33150 (epoch 4.451), train_loss = 1.60055767, grad/param norm = 2.1067e-01, time/batch = 0.6722s	
2952/33150 (epoch 4.452), train_loss = 1.73243734, grad/param norm = 2.0057e-01, time/batch = 0.6712s	
2953/33150 (epoch 4.454), train_loss = 1.51561330, grad/param norm = 2.0561e-01, time/batch = 0.6780s	
2954/33150 (epoch 4.456), train_loss = 1.23178820, grad/param norm = 1.8467e-01, time/batch = 0.6742s	
2955/33150 (epoch 4.457), train_loss = 1.52189586, grad/param norm = 1.8512e-01, time/batch = 0.6669s	
2956/33150 (epoch 4.459), train_loss = 1.71462027, grad/param norm = 2.1736e-01, time/batch = 0.6691s	
2957/33150 (epoch 4.460), train_loss = 1.52786708, grad/param norm = 1.7168e-01, time/batch = 0.6685s	
2958/33150 (epoch 4.462), train_loss = 1.59473204, grad/param norm = 2.2162e-01, time/batch = 0.6743s	
2959/33150 (epoch 4.463), train_loss = 1.81489003, grad/param norm = 2.3822e-01, time/batch = 0.6793s	
2960/33150 (epoch 4.465), train_loss = 1.37960140, grad/param norm = 1.8481e-01, time/batch = 0.6672s	
2961/33150 (epoch 4.466), train_loss = 1.46496053, grad/param norm = 1.9885e-01, time/batch = 0.6672s	
2962/33150 (epoch 4.468), train_loss = 1.85023917, grad/param norm = 2.1213e-01, time/batch = 0.6690s	
2963/33150 (epoch 4.469), train_loss = 1.64894501, grad/param norm = 2.1081e-01, time/batch = 0.6722s	
2964/33150 (epoch 4.471), train_loss = 1.45175975, grad/param norm = 1.7804e-01, time/batch = 0.6696s	
2965/33150 (epoch 4.472), train_loss = 1.41354200, grad/param norm = 1.9376e-01, time/batch = 0.6681s	
2966/33150 (epoch 4.474), train_loss = 1.56690122, grad/param norm = 2.1767e-01, time/batch = 0.6816s	
2967/33150 (epoch 4.475), train_loss = 1.79106438, grad/param norm = 2.2913e-01, time/batch = 0.6697s	
2968/33150 (epoch 4.477), train_loss = 1.57706992, grad/param norm = 2.1556e-01, time/batch = 0.6689s	
2969/33150 (epoch 4.478), train_loss = 1.58061721, grad/param norm = 1.8858e-01, time/batch = 0.6763s	
2970/33150 (epoch 4.480), train_loss = 1.36820127, grad/param norm = 1.7450e-01, time/batch = 0.6804s	
2971/33150 (epoch 4.481), train_loss = 1.27261815, grad/param norm = 1.6623e-01, time/batch = 0.6962s	
2972/33150 (epoch 4.483), train_loss = 1.38352416, grad/param norm = 2.1095e-01, time/batch = 0.6861s	
2973/33150 (epoch 4.484), train_loss = 1.40710067, grad/param norm = 1.9465e-01, time/batch = 0.6709s	
2974/33150 (epoch 4.486), train_loss = 1.53853810, grad/param norm = 1.8915e-01, time/batch = 0.6677s	
2975/33150 (epoch 4.487), train_loss = 1.58588885, grad/param norm = 2.0631e-01, time/batch = 0.6756s	
2976/33150 (epoch 4.489), train_loss = 1.49257584, grad/param norm = 2.0269e-01, time/batch = 0.6897s	
2977/33150 (epoch 4.490), train_loss = 1.32961764, grad/param norm = 1.8363e-01, time/batch = 0.6854s	
2978/33150 (epoch 4.492), train_loss = 1.45983955, grad/param norm = 2.1950e-01, time/batch = 0.6874s	
2979/33150 (epoch 4.493), train_loss = 1.62762692, grad/param norm = 2.0721e-01, time/batch = 0.6861s	
2980/33150 (epoch 4.495), train_loss = 1.58596374, grad/param norm = 1.8710e-01, time/batch = 0.6851s	
2981/33150 (epoch 4.496), train_loss = 1.41318352, grad/param norm = 2.1961e-01, time/batch = 0.6903s	
2982/33150 (epoch 4.498), train_loss = 1.62652998, grad/param norm = 2.0339e-01, time/batch = 0.6960s	
2983/33150 (epoch 4.499), train_loss = 1.74526919, grad/param norm = 2.1378e-01, time/batch = 0.6831s	
2984/33150 (epoch 4.501), train_loss = 1.53737603, grad/param norm = 1.8779e-01, time/batch = 0.6856s	
2985/33150 (epoch 4.502), train_loss = 1.66808913, grad/param norm = 2.0508e-01, time/batch = 0.6872s	
2986/33150 (epoch 4.504), train_loss = 1.62492898, grad/param norm = 2.0515e-01, time/batch = 0.6868s	
2987/33150 (epoch 4.505), train_loss = 1.76494295, grad/param norm = 2.1667e-01, time/batch = 0.6741s	
2988/33150 (epoch 4.507), train_loss = 1.45340447, grad/param norm = 2.1718e-01, time/batch = 0.6868s	
2989/33150 (epoch 4.508), train_loss = 1.40941909, grad/param norm = 1.8030e-01, time/batch = 0.6816s	
2990/33150 (epoch 4.510), train_loss = 1.49265169, grad/param norm = 1.8645e-01, time/batch = 0.6630s	
2991/33150 (epoch 4.511), train_loss = 1.75506818, grad/param norm = 2.0830e-01, time/batch = 0.6678s	
2992/33150 (epoch 4.513), train_loss = 1.59109379, grad/param norm = 2.0809e-01, time/batch = 0.6700s	
2993/33150 (epoch 4.514), train_loss = 1.25417106, grad/param norm = 1.8533e-01, time/batch = 0.6701s	
2994/33150 (epoch 4.516), train_loss = 1.65253144, grad/param norm = 2.1950e-01, time/batch = 0.6684s	
2995/33150 (epoch 4.517), train_loss = 1.67448129, grad/param norm = 1.8171e-01, time/batch = 0.6703s	
2996/33150 (epoch 4.519), train_loss = 1.46978564, grad/param norm = 1.8910e-01, time/batch = 0.6666s	
2997/33150 (epoch 4.520), train_loss = 1.54851312, grad/param norm = 1.7931e-01, time/batch = 0.6816s	
2998/33150 (epoch 4.522), train_loss = 1.71752287, grad/param norm = 2.2987e-01, time/batch = 0.6768s	
2999/33150 (epoch 4.523), train_loss = 1.40792575, grad/param norm = 1.9434e-01, time/batch = 0.6875s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch4.52_1.6339.t7	
3000/33150 (epoch 4.525), train_loss = 1.51963893, grad/param norm = 1.7459e-01, time/batch = 0.6883s	
3001/33150 (epoch 4.526), train_loss = 1.51407354, grad/param norm = 1.8830e-01, time/batch = 0.6861s	
3002/33150 (epoch 4.528), train_loss = 1.55281976, grad/param norm = 1.9393e-01, time/batch = 0.6686s	
3003/33150 (epoch 4.529), train_loss = 1.58332509, grad/param norm = 1.7439e-01, time/batch = 0.6775s	
3004/33150 (epoch 4.531), train_loss = 1.38473993, grad/param norm = 1.9279e-01, time/batch = 0.6750s	
3005/33150 (epoch 4.532), train_loss = 1.57581404, grad/param norm = 2.0432e-01, time/batch = 0.6669s	
3006/33150 (epoch 4.534), train_loss = 1.41056559, grad/param norm = 1.8330e-01, time/batch = 0.6835s	
3007/33150 (epoch 4.535), train_loss = 1.43209595, grad/param norm = 2.0354e-01, time/batch = 0.6900s	
3008/33150 (epoch 4.537), train_loss = 1.68946291, grad/param norm = 2.0563e-01, time/batch = 0.6867s	
3009/33150 (epoch 4.538), train_loss = 1.48492737, grad/param norm = 1.9837e-01, time/batch = 0.6858s	
3010/33150 (epoch 4.540), train_loss = 1.30568949, grad/param norm = 1.7974e-01, time/batch = 0.6892s	
3011/33150 (epoch 4.541), train_loss = 1.56363060, grad/param norm = 2.0772e-01, time/batch = 0.6880s	
3012/33150 (epoch 4.543), train_loss = 1.55185603, grad/param norm = 2.0092e-01, time/batch = 0.6782s	
3013/33150 (epoch 4.544), train_loss = 1.51939951, grad/param norm = 1.8353e-01, time/batch = 0.6735s	
3014/33150 (epoch 4.546), train_loss = 1.75750257, grad/param norm = 2.1278e-01, time/batch = 0.6779s	
3015/33150 (epoch 4.548), train_loss = 1.60674537, grad/param norm = 2.1759e-01, time/batch = 0.6877s	
3016/33150 (epoch 4.549), train_loss = 1.58206392, grad/param norm = 2.2898e-01, time/batch = 0.6830s	
3017/33150 (epoch 4.551), train_loss = 1.37615555, grad/param norm = 1.8558e-01, time/batch = 0.6872s	
3018/33150 (epoch 4.552), train_loss = 1.32362962, grad/param norm = 1.8292e-01, time/batch = 0.6787s	
3019/33150 (epoch 4.554), train_loss = 1.48620476, grad/param norm = 1.8462e-01, time/batch = 0.6871s	
3020/33150 (epoch 4.555), train_loss = 1.75612552, grad/param norm = 2.1696e-01, time/batch = 0.6800s	
3021/33150 (epoch 4.557), train_loss = 1.33373094, grad/param norm = 2.0939e-01, time/batch = 0.6871s	
3022/33150 (epoch 4.558), train_loss = 1.63957432, grad/param norm = 2.0731e-01, time/batch = 0.6846s	
3023/33150 (epoch 4.560), train_loss = 1.51617336, grad/param norm = 2.1507e-01, time/batch = 0.6827s	
3024/33150 (epoch 4.561), train_loss = 1.30531741, grad/param norm = 1.9291e-01, time/batch = 0.6802s	
3025/33150 (epoch 4.563), train_loss = 1.65110514, grad/param norm = 2.2963e-01, time/batch = 0.6735s	
3026/33150 (epoch 4.564), train_loss = 1.75126385, grad/param norm = 2.0313e-01, time/batch = 0.6752s	
3027/33150 (epoch 4.566), train_loss = 1.46313688, grad/param norm = 1.8811e-01, time/batch = 0.6755s	
3028/33150 (epoch 4.567), train_loss = 1.37803814, grad/param norm = 1.9168e-01, time/batch = 0.6773s	
3029/33150 (epoch 4.569), train_loss = 1.49479822, grad/param norm = 1.9207e-01, time/batch = 0.6719s	
3030/33150 (epoch 4.570), train_loss = 1.45276350, grad/param norm = 1.8003e-01, time/batch = 0.6752s	
3031/33150 (epoch 4.572), train_loss = 1.45862479, grad/param norm = 1.8666e-01, time/batch = 0.6810s	
3032/33150 (epoch 4.573), train_loss = 1.21428776, grad/param norm = 1.6021e-01, time/batch = 0.6875s	
3033/33150 (epoch 4.575), train_loss = 1.57518682, grad/param norm = 1.9013e-01, time/batch = 0.6872s	
3034/33150 (epoch 4.576), train_loss = 1.26775619, grad/param norm = 1.6397e-01, time/batch = 0.6740s	
3035/33150 (epoch 4.578), train_loss = 1.48132916, grad/param norm = 1.7058e-01, time/batch = 0.6684s	
3036/33150 (epoch 4.579), train_loss = 1.36008661, grad/param norm = 1.7789e-01, time/batch = 0.6705s	
3037/33150 (epoch 4.581), train_loss = 1.32807768, grad/param norm = 1.8360e-01, time/batch = 0.6736s	
3038/33150 (epoch 4.582), train_loss = 1.49121797, grad/param norm = 1.8079e-01, time/batch = 0.6693s	
3039/33150 (epoch 4.584), train_loss = 1.56416323, grad/param norm = 1.9679e-01, time/batch = 0.6709s	
3040/33150 (epoch 4.585), train_loss = 1.51241193, grad/param norm = 1.8211e-01, time/batch = 0.6689s	
3041/33150 (epoch 4.587), train_loss = 1.56278880, grad/param norm = 1.9216e-01, time/batch = 0.6697s	
3042/33150 (epoch 4.588), train_loss = 1.34339934, grad/param norm = 1.8779e-01, time/batch = 0.6694s	
3043/33150 (epoch 4.590), train_loss = 1.54568353, grad/param norm = 2.0967e-01, time/batch = 0.6702s	
3044/33150 (epoch 4.591), train_loss = 1.53507241, grad/param norm = 1.9517e-01, time/batch = 0.6749s	
3045/33150 (epoch 4.593), train_loss = 1.58399246, grad/param norm = 2.0422e-01, time/batch = 0.6700s	
3046/33150 (epoch 4.594), train_loss = 1.54770752, grad/param norm = 2.0873e-01, time/batch = 0.6851s	
3047/33150 (epoch 4.596), train_loss = 1.32744461, grad/param norm = 1.8214e-01, time/batch = 0.6802s	
3048/33150 (epoch 4.597), train_loss = 1.45596967, grad/param norm = 2.2203e-01, time/batch = 0.6689s	
3049/33150 (epoch 4.599), train_loss = 1.71820134, grad/param norm = 2.0845e-01, time/batch = 0.6702s	
3050/33150 (epoch 4.600), train_loss = 1.56585434, grad/param norm = 2.1534e-01, time/batch = 0.6702s	
3051/33150 (epoch 4.602), train_loss = 1.38382126, grad/param norm = 1.9975e-01, time/batch = 0.6688s	
3052/33150 (epoch 4.603), train_loss = 1.47042818, grad/param norm = 1.9709e-01, time/batch = 0.6739s	
3053/33150 (epoch 4.605), train_loss = 1.37814694, grad/param norm = 1.8285e-01, time/batch = 0.6728s	
3054/33150 (epoch 4.606), train_loss = 1.53395465, grad/param norm = 2.0158e-01, time/batch = 0.6735s	
3055/33150 (epoch 4.608), train_loss = 1.54034851, grad/param norm = 2.0572e-01, time/batch = 0.6710s	
3056/33150 (epoch 4.609), train_loss = 1.51903794, grad/param norm = 2.2487e-01, time/batch = 0.6729s	
3057/33150 (epoch 4.611), train_loss = 1.26472551, grad/param norm = 1.8558e-01, time/batch = 0.6862s	
3058/33150 (epoch 4.612), train_loss = 1.49460182, grad/param norm = 2.1834e-01, time/batch = 0.6826s	
3059/33150 (epoch 4.614), train_loss = 1.26366247, grad/param norm = 1.7183e-01, time/batch = 0.6911s	
3060/33150 (epoch 4.615), train_loss = 1.31370916, grad/param norm = 1.7662e-01, time/batch = 0.6884s	
3061/33150 (epoch 4.617), train_loss = 1.41352537, grad/param norm = 2.0148e-01, time/batch = 0.6994s	
3062/33150 (epoch 4.618), train_loss = 1.40358255, grad/param norm = 1.9915e-01, time/batch = 0.6854s	
3063/33150 (epoch 4.620), train_loss = 1.39463221, grad/param norm = 2.0966e-01, time/batch = 0.6702s	
3064/33150 (epoch 4.621), train_loss = 1.40435647, grad/param norm = 2.0233e-01, time/batch = 0.6924s	
3065/33150 (epoch 4.623), train_loss = 1.53030484, grad/param norm = 2.0108e-01, time/batch = 0.6925s	
3066/33150 (epoch 4.624), train_loss = 1.44818694, grad/param norm = 1.9951e-01, time/batch = 0.6729s	
3067/33150 (epoch 4.626), train_loss = 1.33527301, grad/param norm = 1.9767e-01, time/batch = 0.6649s	
3068/33150 (epoch 4.627), train_loss = 1.34121702, grad/param norm = 2.0949e-01, time/batch = 0.6673s	
3069/33150 (epoch 4.629), train_loss = 1.30752944, grad/param norm = 1.8031e-01, time/batch = 0.6645s	
3070/33150 (epoch 4.630), train_loss = 1.34297368, grad/param norm = 1.8383e-01, time/batch = 0.6727s	
3071/33150 (epoch 4.632), train_loss = 1.27011353, grad/param norm = 1.6232e-01, time/batch = 0.6699s	
3072/33150 (epoch 4.633), train_loss = 1.30879494, grad/param norm = 1.9410e-01, time/batch = 0.6661s	
3073/33150 (epoch 4.635), train_loss = 1.67508537, grad/param norm = 1.9502e-01, time/batch = 0.6666s	
3074/33150 (epoch 4.637), train_loss = 1.27343259, grad/param norm = 1.8930e-01, time/batch = 0.6776s	
3075/33150 (epoch 4.638), train_loss = 1.39359594, grad/param norm = 2.0317e-01, time/batch = 0.6884s	
3076/33150 (epoch 4.640), train_loss = 1.60098747, grad/param norm = 2.2325e-01, time/batch = 0.6727s	
3077/33150 (epoch 4.641), train_loss = 1.37696243, grad/param norm = 1.8742e-01, time/batch = 0.6707s	
3078/33150 (epoch 4.643), train_loss = 1.34866804, grad/param norm = 1.8700e-01, time/batch = 0.6708s	
3079/33150 (epoch 4.644), train_loss = 1.56670495, grad/param norm = 1.8108e-01, time/batch = 0.6661s	
3080/33150 (epoch 4.646), train_loss = 1.36688699, grad/param norm = 1.7904e-01, time/batch = 0.6721s	
3081/33150 (epoch 4.647), train_loss = 1.79885488, grad/param norm = 2.0527e-01, time/batch = 0.6660s	
3082/33150 (epoch 4.649), train_loss = 1.59293674, grad/param norm = 2.1645e-01, time/batch = 0.6653s	
3083/33150 (epoch 4.650), train_loss = 1.34092794, grad/param norm = 1.9441e-01, time/batch = 0.6681s	
3084/33150 (epoch 4.652), train_loss = 1.54031161, grad/param norm = 1.9898e-01, time/batch = 0.6616s	
3085/33150 (epoch 4.653), train_loss = 1.42537930, grad/param norm = 1.8096e-01, time/batch = 0.6667s	
3086/33150 (epoch 4.655), train_loss = 1.50951874, grad/param norm = 2.1711e-01, time/batch = 0.6636s	
3087/33150 (epoch 4.656), train_loss = 1.40315962, grad/param norm = 1.8412e-01, time/batch = 0.6616s	
3088/33150 (epoch 4.658), train_loss = 1.54389135, grad/param norm = 2.3752e-01, time/batch = 0.6842s	
3089/33150 (epoch 4.659), train_loss = 1.90989019, grad/param norm = 2.6687e-01, time/batch = 0.6845s	
3090/33150 (epoch 4.661), train_loss = 1.45903806, grad/param norm = 1.8941e-01, time/batch = 0.6772s	
3091/33150 (epoch 4.662), train_loss = 1.32990557, grad/param norm = 1.9622e-01, time/batch = 0.6732s	
3092/33150 (epoch 4.664), train_loss = 1.58533852, grad/param norm = 2.0838e-01, time/batch = 0.6749s	
3093/33150 (epoch 4.665), train_loss = 1.52665163, grad/param norm = 1.8719e-01, time/batch = 0.6712s	
3094/33150 (epoch 4.667), train_loss = 1.68425532, grad/param norm = 2.0049e-01, time/batch = 0.6704s	
3095/33150 (epoch 4.668), train_loss = 1.53056241, grad/param norm = 1.9871e-01, time/batch = 0.6681s	
3096/33150 (epoch 4.670), train_loss = 1.38601775, grad/param norm = 1.6660e-01, time/batch = 0.6733s	
3097/33150 (epoch 4.671), train_loss = 1.43904020, grad/param norm = 2.0068e-01, time/batch = 0.6697s	
3098/33150 (epoch 4.673), train_loss = 1.51706200, grad/param norm = 1.8027e-01, time/batch = 0.6707s	
3099/33150 (epoch 4.674), train_loss = 1.49074261, grad/param norm = 1.9261e-01, time/batch = 0.6742s	
3100/33150 (epoch 4.676), train_loss = 1.42572478, grad/param norm = 1.8404e-01, time/batch = 0.6723s	
3101/33150 (epoch 4.677), train_loss = 1.76554193, grad/param norm = 2.1274e-01, time/batch = 0.6758s	
3102/33150 (epoch 4.679), train_loss = 1.29621975, grad/param norm = 1.6970e-01, time/batch = 0.6878s	
3103/33150 (epoch 4.680), train_loss = 1.57955578, grad/param norm = 2.0302e-01, time/batch = 0.6851s	
3104/33150 (epoch 4.682), train_loss = 1.33420825, grad/param norm = 1.7118e-01, time/batch = 0.6755s	
3105/33150 (epoch 4.683), train_loss = 1.30413965, grad/param norm = 1.9571e-01, time/batch = 0.6764s	
3106/33150 (epoch 4.685), train_loss = 1.53430570, grad/param norm = 1.8438e-01, time/batch = 0.6828s	
3107/33150 (epoch 4.686), train_loss = 1.28600932, grad/param norm = 1.8635e-01, time/batch = 0.6846s	
3108/33150 (epoch 4.688), train_loss = 1.43599093, grad/param norm = 2.1020e-01, time/batch = 0.6840s	
3109/33150 (epoch 4.689), train_loss = 1.36740931, grad/param norm = 2.0531e-01, time/batch = 0.6882s	
3110/33150 (epoch 4.691), train_loss = 1.23655204, grad/param norm = 1.8089e-01, time/batch = 0.6842s	
3111/33150 (epoch 4.692), train_loss = 1.39396542, grad/param norm = 1.9727e-01, time/batch = 0.6812s	
3112/33150 (epoch 4.694), train_loss = 1.18761146, grad/param norm = 1.5357e-01, time/batch = 0.6694s	
3113/33150 (epoch 4.695), train_loss = 1.40715785, grad/param norm = 1.8036e-01, time/batch = 0.6703s	
3114/33150 (epoch 4.697), train_loss = 1.26812478, grad/param norm = 1.6562e-01, time/batch = 0.6702s	
3115/33150 (epoch 4.698), train_loss = 1.61981710, grad/param norm = 1.8986e-01, time/batch = 0.6694s	
3116/33150 (epoch 4.700), train_loss = 1.15941716, grad/param norm = 1.7258e-01, time/batch = 0.6949s	
3117/33150 (epoch 4.701), train_loss = 1.36355860, grad/param norm = 1.8086e-01, time/batch = 0.6892s	
3118/33150 (epoch 4.703), train_loss = 1.52547561, grad/param norm = 2.0120e-01, time/batch = 0.6854s	
3119/33150 (epoch 4.704), train_loss = 1.24666237, grad/param norm = 1.6680e-01, time/batch = 0.6739s	
3120/33150 (epoch 4.706), train_loss = 1.41390032, grad/param norm = 1.7341e-01, time/batch = 0.6743s	
3121/33150 (epoch 4.707), train_loss = 1.42958226, grad/param norm = 1.9012e-01, time/batch = 0.6784s	
3122/33150 (epoch 4.709), train_loss = 1.44520617, grad/param norm = 1.6803e-01, time/batch = 0.6701s	
3123/33150 (epoch 4.710), train_loss = 1.59866966, grad/param norm = 2.1194e-01, time/batch = 0.6676s	
3124/33150 (epoch 4.712), train_loss = 1.57018199, grad/param norm = 2.0692e-01, time/batch = 0.6711s	
3125/33150 (epoch 4.713), train_loss = 1.48962273, grad/param norm = 1.9041e-01, time/batch = 0.6804s	
3126/33150 (epoch 4.715), train_loss = 1.36794655, grad/param norm = 1.7134e-01, time/batch = 0.6659s	
3127/33150 (epoch 4.716), train_loss = 1.48518564, grad/param norm = 2.0119e-01, time/batch = 0.6667s	
3128/33150 (epoch 4.718), train_loss = 1.46355854, grad/param norm = 1.7542e-01, time/batch = 0.6651s	
3129/33150 (epoch 4.719), train_loss = 1.59454352, grad/param norm = 2.1926e-01, time/batch = 0.6737s	
3130/33150 (epoch 4.721), train_loss = 1.50273712, grad/param norm = 2.0870e-01, time/batch = 0.6743s	
3131/33150 (epoch 4.722), train_loss = 1.45400084, grad/param norm = 1.9249e-01, time/batch = 0.6668s	
3132/33150 (epoch 4.724), train_loss = 1.43115421, grad/param norm = 1.9602e-01, time/batch = 0.6686s	
3133/33150 (epoch 4.725), train_loss = 1.71268254, grad/param norm = 2.1442e-01, time/batch = 0.6697s	
3134/33150 (epoch 4.727), train_loss = 1.56577275, grad/param norm = 2.1146e-01, time/batch = 0.6629s	
3135/33150 (epoch 4.729), train_loss = 1.50265227, grad/param norm = 1.9070e-01, time/batch = 0.6661s	
3136/33150 (epoch 4.730), train_loss = 1.43364191, grad/param norm = 1.7070e-01, time/batch = 0.6683s	
3137/33150 (epoch 4.732), train_loss = 1.52441811, grad/param norm = 1.7337e-01, time/batch = 0.6657s	
3138/33150 (epoch 4.733), train_loss = 1.21665993, grad/param norm = 1.6334e-01, time/batch = 0.6630s	
3139/33150 (epoch 4.735), train_loss = 1.43245036, grad/param norm = 1.7829e-01, time/batch = 0.6650s	
3140/33150 (epoch 4.736), train_loss = 1.30538135, grad/param norm = 1.7679e-01, time/batch = 0.6681s	
3141/33150 (epoch 4.738), train_loss = 1.54649933, grad/param norm = 1.9175e-01, time/batch = 0.6826s	
3142/33150 (epoch 4.739), train_loss = 1.66760162, grad/param norm = 2.0990e-01, time/batch = 0.6747s	
3143/33150 (epoch 4.741), train_loss = 1.60814015, grad/param norm = 2.1664e-01, time/batch = 0.6697s	
3144/33150 (epoch 4.742), train_loss = 1.44860965, grad/param norm = 1.9896e-01, time/batch = 0.6683s	
3145/33150 (epoch 4.744), train_loss = 1.58726887, grad/param norm = 2.0055e-01, time/batch = 0.6729s	
3146/33150 (epoch 4.745), train_loss = 1.42738436, grad/param norm = 1.7766e-01, time/batch = 0.6800s	
3147/33150 (epoch 4.747), train_loss = 1.29742277, grad/param norm = 1.7731e-01, time/batch = 0.6865s	
3148/33150 (epoch 4.748), train_loss = 1.38058828, grad/param norm = 1.6791e-01, time/batch = 0.6884s	
3149/33150 (epoch 4.750), train_loss = 1.52392057, grad/param norm = 2.0026e-01, time/batch = 0.6818s	
3150/33150 (epoch 4.751), train_loss = 1.46885593, grad/param norm = 1.9245e-01, time/batch = 0.6870s	
3151/33150 (epoch 4.753), train_loss = 1.28507067, grad/param norm = 1.9002e-01, time/batch = 0.6833s	
3152/33150 (epoch 4.754), train_loss = 1.73014113, grad/param norm = 2.2620e-01, time/batch = 0.6665s	
3153/33150 (epoch 4.756), train_loss = 1.48920854, grad/param norm = 2.0432e-01, time/batch = 0.6852s	
3154/33150 (epoch 4.757), train_loss = 1.52268900, grad/param norm = 1.9721e-01, time/batch = 0.6722s	
3155/33150 (epoch 4.759), train_loss = 1.67313810, grad/param norm = 1.9453e-01, time/batch = 0.6720s	
3156/33150 (epoch 4.760), train_loss = 1.49127131, grad/param norm = 1.8161e-01, time/batch = 0.6661s	
3157/33150 (epoch 4.762), train_loss = 1.51083647, grad/param norm = 1.9359e-01, time/batch = 0.6747s	
3158/33150 (epoch 4.763), train_loss = 1.34999985, grad/param norm = 1.8164e-01, time/batch = 0.6949s	
3159/33150 (epoch 4.765), train_loss = 1.40347345, grad/param norm = 1.7872e-01, time/batch = 0.6774s	
3160/33150 (epoch 4.766), train_loss = 1.34712141, grad/param norm = 1.7150e-01, time/batch = 0.6716s	
3161/33150 (epoch 4.768), train_loss = 1.35210435, grad/param norm = 1.8497e-01, time/batch = 0.6692s	
3162/33150 (epoch 4.769), train_loss = 1.44115140, grad/param norm = 1.8901e-01, time/batch = 0.6745s	
3163/33150 (epoch 4.771), train_loss = 1.46300357, grad/param norm = 1.9698e-01, time/batch = 0.6911s	
3164/33150 (epoch 4.772), train_loss = 1.53655359, grad/param norm = 2.1661e-01, time/batch = 0.6733s	
3165/33150 (epoch 4.774), train_loss = 1.63452598, grad/param norm = 1.9667e-01, time/batch = 0.6890s	
3166/33150 (epoch 4.775), train_loss = 1.52003209, grad/param norm = 2.2170e-01, time/batch = 0.6654s	
3167/33150 (epoch 4.777), train_loss = 1.60684317, grad/param norm = 1.9527e-01, time/batch = 0.6684s	
3168/33150 (epoch 4.778), train_loss = 1.50519378, grad/param norm = 1.8451e-01, time/batch = 0.6678s	
3169/33150 (epoch 4.780), train_loss = 1.32951774, grad/param norm = 1.7555e-01, time/batch = 0.6647s	
3170/33150 (epoch 4.781), train_loss = 1.44217479, grad/param norm = 1.7485e-01, time/batch = 0.6653s	
3171/33150 (epoch 4.783), train_loss = 1.43642995, grad/param norm = 1.6791e-01, time/batch = 0.6660s	
3172/33150 (epoch 4.784), train_loss = 1.40225649, grad/param norm = 1.9412e-01, time/batch = 0.6627s	
3173/33150 (epoch 4.786), train_loss = 1.41560869, grad/param norm = 1.7063e-01, time/batch = 0.6813s	
3174/33150 (epoch 4.787), train_loss = 1.42871212, grad/param norm = 1.7973e-01, time/batch = 0.6761s	
3175/33150 (epoch 4.789), train_loss = 1.28677148, grad/param norm = 1.6837e-01, time/batch = 0.6731s	
3176/33150 (epoch 4.790), train_loss = 1.21735065, grad/param norm = 1.5715e-01, time/batch = 0.6639s	
3177/33150 (epoch 4.792), train_loss = 1.58313278, grad/param norm = 2.2669e-01, time/batch = 0.6822s	
3178/33150 (epoch 4.793), train_loss = 1.42591688, grad/param norm = 1.9943e-01, time/batch = 0.6833s	
3179/33150 (epoch 4.795), train_loss = 1.42835295, grad/param norm = 1.9829e-01, time/batch = 0.6729s	
3180/33150 (epoch 4.796), train_loss = 1.33405615, grad/param norm = 1.6100e-01, time/batch = 0.6746s	
3181/33150 (epoch 4.798), train_loss = 1.40516049, grad/param norm = 1.6188e-01, time/batch = 0.6666s	
3182/33150 (epoch 4.799), train_loss = 1.31597497, grad/param norm = 2.1123e-01, time/batch = 0.6644s	
3183/33150 (epoch 4.801), train_loss = 1.40573599, grad/param norm = 1.6822e-01, time/batch = 0.6653s	
3184/33150 (epoch 4.802), train_loss = 1.37283266, grad/param norm = 1.8436e-01, time/batch = 0.6655s	
3185/33150 (epoch 4.804), train_loss = 1.45880347, grad/param norm = 1.7905e-01, time/batch = 0.6697s	
3186/33150 (epoch 4.805), train_loss = 1.39996261, grad/param norm = 2.0191e-01, time/batch = 0.6732s	
3187/33150 (epoch 4.807), train_loss = 1.33951168, grad/param norm = 1.8697e-01, time/batch = 0.6842s	
3188/33150 (epoch 4.808), train_loss = 1.50504592, grad/param norm = 2.0199e-01, time/batch = 0.6694s	
3189/33150 (epoch 4.810), train_loss = 1.39377356, grad/param norm = 1.8927e-01, time/batch = 0.6640s	
3190/33150 (epoch 4.811), train_loss = 1.49603440, grad/param norm = 2.0184e-01, time/batch = 0.6857s	
3191/33150 (epoch 4.813), train_loss = 1.44534461, grad/param norm = 1.7276e-01, time/batch = 0.6750s	
3192/33150 (epoch 4.814), train_loss = 1.48864329, grad/param norm = 1.8872e-01, time/batch = 0.6655s	
3193/33150 (epoch 4.816), train_loss = 1.47503102, grad/param norm = 2.0601e-01, time/batch = 0.6637s	
3194/33150 (epoch 4.817), train_loss = 1.55770276, grad/param norm = 1.9991e-01, time/batch = 0.6622s	
3195/33150 (epoch 4.819), train_loss = 1.39658485, grad/param norm = 1.8727e-01, time/batch = 0.6610s	
3196/33150 (epoch 4.821), train_loss = 1.20255639, grad/param norm = 1.5582e-01, time/batch = 0.6661s	
3197/33150 (epoch 4.822), train_loss = 1.34802369, grad/param norm = 1.7365e-01, time/batch = 0.6624s	
3198/33150 (epoch 4.824), train_loss = 1.38075942, grad/param norm = 1.9345e-01, time/batch = 0.6677s	
3199/33150 (epoch 4.825), train_loss = 1.43949526, grad/param norm = 1.9260e-01, time/batch = 0.6707s	
3200/33150 (epoch 4.827), train_loss = 1.53077361, grad/param norm = 2.1601e-01, time/batch = 0.6834s	
3201/33150 (epoch 4.828), train_loss = 1.29478721, grad/param norm = 1.7939e-01, time/batch = 0.6710s	
3202/33150 (epoch 4.830), train_loss = 1.42448143, grad/param norm = 1.9732e-01, time/batch = 0.6709s	
3203/33150 (epoch 4.831), train_loss = 1.37606031, grad/param norm = 1.8681e-01, time/batch = 0.6833s	
3204/33150 (epoch 4.833), train_loss = 1.33541088, grad/param norm = 1.9349e-01, time/batch = 0.6874s	
3205/33150 (epoch 4.834), train_loss = 1.62465577, grad/param norm = 1.9990e-01, time/batch = 0.6732s	
3206/33150 (epoch 4.836), train_loss = 1.57221086, grad/param norm = 2.0759e-01, time/batch = 0.6706s	
3207/33150 (epoch 4.837), train_loss = 1.41895587, grad/param norm = 1.9327e-01, time/batch = 0.6832s	
3208/33150 (epoch 4.839), train_loss = 1.66527995, grad/param norm = 2.3799e-01, time/batch = 0.6861s	
3209/33150 (epoch 4.840), train_loss = 1.54364327, grad/param norm = 1.9492e-01, time/batch = 0.6716s	
3210/33150 (epoch 4.842), train_loss = 1.59955822, grad/param norm = 2.2143e-01, time/batch = 0.6716s	
3211/33150 (epoch 4.843), train_loss = 1.54268038, grad/param norm = 2.1934e-01, time/batch = 0.6809s	
3212/33150 (epoch 4.845), train_loss = 1.36433085, grad/param norm = 1.7348e-01, time/batch = 0.6701s	
3213/33150 (epoch 4.846), train_loss = 1.73298356, grad/param norm = 2.1452e-01, time/batch = 0.6767s	
3214/33150 (epoch 4.848), train_loss = 1.53055344, grad/param norm = 1.7602e-01, time/batch = 0.6871s	
3215/33150 (epoch 4.849), train_loss = 1.48976279, grad/param norm = 1.9419e-01, time/batch = 0.6843s	
3216/33150 (epoch 4.851), train_loss = 1.60275677, grad/param norm = 2.3617e-01, time/batch = 0.6869s	
3217/33150 (epoch 4.852), train_loss = 1.63102361, grad/param norm = 2.1352e-01, time/batch = 0.6729s	
3218/33150 (epoch 4.854), train_loss = 1.48095748, grad/param norm = 1.8584e-01, time/batch = 0.6895s	
3219/33150 (epoch 4.855), train_loss = 1.20356917, grad/param norm = 1.6435e-01, time/batch = 0.6884s	
3220/33150 (epoch 4.857), train_loss = 1.32508842, grad/param norm = 1.7814e-01, time/batch = 0.6834s	
3221/33150 (epoch 4.858), train_loss = 1.38059198, grad/param norm = 1.8979e-01, time/batch = 0.6660s	
3222/33150 (epoch 4.860), train_loss = 1.34871022, grad/param norm = 1.7340e-01, time/batch = 0.6655s	
3223/33150 (epoch 4.861), train_loss = 1.37570374, grad/param norm = 1.7198e-01, time/batch = 0.6651s	
3224/33150 (epoch 4.863), train_loss = 1.49436609, grad/param norm = 1.7287e-01, time/batch = 0.6656s	
3225/33150 (epoch 4.864), train_loss = 1.63871767, grad/param norm = 1.9567e-01, time/batch = 0.6681s	
3226/33150 (epoch 4.866), train_loss = 1.46338831, grad/param norm = 2.0306e-01, time/batch = 0.6672s	
3227/33150 (epoch 4.867), train_loss = 1.50539251, grad/param norm = 1.7561e-01, time/batch = 0.6663s	
3228/33150 (epoch 4.869), train_loss = 1.56552845, grad/param norm = 2.1030e-01, time/batch = 0.6874s	
3229/33150 (epoch 4.870), train_loss = 1.58594364, grad/param norm = 1.8902e-01, time/batch = 0.6691s	
3230/33150 (epoch 4.872), train_loss = 1.49943766, grad/param norm = 2.0337e-01, time/batch = 0.6819s	
3231/33150 (epoch 4.873), train_loss = 1.22589113, grad/param norm = 1.6604e-01, time/batch = 0.6843s	
3232/33150 (epoch 4.875), train_loss = 1.64471596, grad/param norm = 1.9772e-01, time/batch = 0.6830s	
3233/33150 (epoch 4.876), train_loss = 1.43326223, grad/param norm = 2.0067e-01, time/batch = 0.6794s	
3234/33150 (epoch 4.878), train_loss = 1.32888924, grad/param norm = 1.6993e-01, time/batch = 0.6758s	
3235/33150 (epoch 4.879), train_loss = 1.43775962, grad/param norm = 1.9504e-01, time/batch = 0.6859s	
3236/33150 (epoch 4.881), train_loss = 1.42106139, grad/param norm = 1.7926e-01, time/batch = 0.6875s	
3237/33150 (epoch 4.882), train_loss = 1.36356353, grad/param norm = 1.9613e-01, time/batch = 0.6890s	
3238/33150 (epoch 4.884), train_loss = 1.49876732, grad/param norm = 1.8491e-01, time/batch = 0.6787s	
3239/33150 (epoch 4.885), train_loss = 1.17759172, grad/param norm = 1.6767e-01, time/batch = 0.6639s	
3240/33150 (epoch 4.887), train_loss = 1.66433520, grad/param norm = 2.0780e-01, time/batch = 0.6880s	
3241/33150 (epoch 4.888), train_loss = 1.52414012, grad/param norm = 1.9425e-01, time/batch = 0.7051s	
3242/33150 (epoch 4.890), train_loss = 1.40247144, grad/param norm = 1.6841e-01, time/batch = 0.6911s	
3243/33150 (epoch 4.891), train_loss = 1.39142105, grad/param norm = 2.0243e-01, time/batch = 0.6786s	
3244/33150 (epoch 4.893), train_loss = 1.53992831, grad/param norm = 2.0316e-01, time/batch = 0.6824s	
3245/33150 (epoch 4.894), train_loss = 1.55544257, grad/param norm = 1.9779e-01, time/batch = 0.6650s	
3246/33150 (epoch 4.896), train_loss = 1.43661665, grad/param norm = 1.8611e-01, time/batch = 0.6667s	
3247/33150 (epoch 4.897), train_loss = 1.48128695, grad/param norm = 1.6896e-01, time/batch = 0.6698s	
3248/33150 (epoch 4.899), train_loss = 1.32095200, grad/param norm = 1.7881e-01, time/batch = 0.6655s	
3249/33150 (epoch 4.900), train_loss = 1.74529137, grad/param norm = 2.0894e-01, time/batch = 0.6869s	
3250/33150 (epoch 4.902), train_loss = 1.66156392, grad/param norm = 2.0249e-01, time/batch = 0.6701s	
3251/33150 (epoch 4.903), train_loss = 1.44654443, grad/param norm = 1.8142e-01, time/batch = 0.6724s	
3252/33150 (epoch 4.905), train_loss = 1.49269224, grad/param norm = 2.0761e-01, time/batch = 0.6773s	
3253/33150 (epoch 4.906), train_loss = 1.49919284, grad/param norm = 1.8601e-01, time/batch = 0.6784s	
3254/33150 (epoch 4.908), train_loss = 1.61579906, grad/param norm = 2.0450e-01, time/batch = 0.6696s	
3255/33150 (epoch 4.910), train_loss = 1.56512289, grad/param norm = 2.0102e-01, time/batch = 0.6690s	
3256/33150 (epoch 4.911), train_loss = 1.34201615, grad/param norm = 1.8838e-01, time/batch = 0.6716s	
3257/33150 (epoch 4.913), train_loss = 1.35527806, grad/param norm = 1.8835e-01, time/batch = 0.6839s	
3258/33150 (epoch 4.914), train_loss = 1.59514475, grad/param norm = 2.0312e-01, time/batch = 0.6647s	
3259/33150 (epoch 4.916), train_loss = 1.31375337, grad/param norm = 1.8472e-01, time/batch = 0.6713s	
3260/33150 (epoch 4.917), train_loss = 1.60961778, grad/param norm = 1.9380e-01, time/batch = 0.6668s	
3261/33150 (epoch 4.919), train_loss = 1.67930020, grad/param norm = 2.2829e-01, time/batch = 0.6695s	
3262/33150 (epoch 4.920), train_loss = 1.49650536, grad/param norm = 1.6908e-01, time/batch = 0.6932s	
3263/33150 (epoch 4.922), train_loss = 1.68641505, grad/param norm = 2.1041e-01, time/batch = 0.6691s	
3264/33150 (epoch 4.923), train_loss = 1.45721435, grad/param norm = 1.9609e-01, time/batch = 0.6660s	
3265/33150 (epoch 4.925), train_loss = 1.48008951, grad/param norm = 1.9959e-01, time/batch = 0.6753s	
3266/33150 (epoch 4.926), train_loss = 1.45571580, grad/param norm = 2.0141e-01, time/batch = 0.6830s	
3267/33150 (epoch 4.928), train_loss = 1.43911403, grad/param norm = 1.8939e-01, time/batch = 0.6841s	
3268/33150 (epoch 4.929), train_loss = 1.52431523, grad/param norm = 1.8556e-01, time/batch = 0.6795s	
3269/33150 (epoch 4.931), train_loss = 1.62593960, grad/param norm = 2.1364e-01, time/batch = 0.6825s	
3270/33150 (epoch 4.932), train_loss = 1.51462239, grad/param norm = 2.1657e-01, time/batch = 0.6823s	
3271/33150 (epoch 4.934), train_loss = 1.43286585, grad/param norm = 1.7325e-01, time/batch = 0.6847s	
3272/33150 (epoch 4.935), train_loss = 1.54403515, grad/param norm = 1.7443e-01, time/batch = 0.6704s	
3273/33150 (epoch 4.937), train_loss = 1.57960511, grad/param norm = 1.8280e-01, time/batch = 0.6682s	
3274/33150 (epoch 4.938), train_loss = 1.53332259, grad/param norm = 1.8133e-01, time/batch = 0.6826s	
3275/33150 (epoch 4.940), train_loss = 1.80102556, grad/param norm = 2.1367e-01, time/batch = 0.6725s	
3276/33150 (epoch 4.941), train_loss = 1.41936318, grad/param norm = 1.6275e-01, time/batch = 0.6695s	
3277/33150 (epoch 4.943), train_loss = 1.38164227, grad/param norm = 2.0915e-01, time/batch = 0.6701s	
3278/33150 (epoch 4.944), train_loss = 1.62521077, grad/param norm = 1.9494e-01, time/batch = 0.6864s	
3279/33150 (epoch 4.946), train_loss = 1.23182245, grad/param norm = 1.7531e-01, time/batch = 0.6731s	
3280/33150 (epoch 4.947), train_loss = 1.49710284, grad/param norm = 1.7829e-01, time/batch = 0.6684s	
3281/33150 (epoch 4.949), train_loss = 1.62630311, grad/param norm = 2.0922e-01, time/batch = 0.6700s	
3282/33150 (epoch 4.950), train_loss = 1.59670383, grad/param norm = 2.1099e-01, time/batch = 0.6679s	
3283/33150 (epoch 4.952), train_loss = 1.36908680, grad/param norm = 1.9183e-01, time/batch = 0.6714s	
3284/33150 (epoch 4.953), train_loss = 1.34880045, grad/param norm = 1.7482e-01, time/batch = 0.6681s	
3285/33150 (epoch 4.955), train_loss = 1.34469202, grad/param norm = 1.6284e-01, time/batch = 0.6670s	
3286/33150 (epoch 4.956), train_loss = 1.60451213, grad/param norm = 1.9985e-01, time/batch = 0.6763s	
3287/33150 (epoch 4.958), train_loss = 1.32973880, grad/param norm = 1.7790e-01, time/batch = 0.6820s	
3288/33150 (epoch 4.959), train_loss = 1.29753718, grad/param norm = 1.9514e-01, time/batch = 0.6790s	
3289/33150 (epoch 4.961), train_loss = 1.34865050, grad/param norm = 1.7334e-01, time/batch = 0.6731s	
3290/33150 (epoch 4.962), train_loss = 1.25425150, grad/param norm = 1.7372e-01, time/batch = 0.6701s	
3291/33150 (epoch 4.964), train_loss = 1.45616202, grad/param norm = 1.8070e-01, time/batch = 0.6796s	
3292/33150 (epoch 4.965), train_loss = 1.48082022, grad/param norm = 1.9112e-01, time/batch = 0.6752s	
3293/33150 (epoch 4.967), train_loss = 1.52386502, grad/param norm = 2.0881e-01, time/batch = 0.6663s	
3294/33150 (epoch 4.968), train_loss = 1.29653543, grad/param norm = 1.9265e-01, time/batch = 0.6662s	
3295/33150 (epoch 4.970), train_loss = 1.36355174, grad/param norm = 1.8391e-01, time/batch = 0.6689s	
3296/33150 (epoch 4.971), train_loss = 1.54168229, grad/param norm = 2.1718e-01, time/batch = 0.6677s	
3297/33150 (epoch 4.973), train_loss = 1.61701940, grad/param norm = 1.9358e-01, time/batch = 0.6677s	
3298/33150 (epoch 4.974), train_loss = 1.67430746, grad/param norm = 2.0726e-01, time/batch = 0.6829s	
3299/33150 (epoch 4.976), train_loss = 1.51782279, grad/param norm = 1.8270e-01, time/batch = 0.6809s	
3300/33150 (epoch 4.977), train_loss = 1.61169809, grad/param norm = 1.9333e-01, time/batch = 0.6665s	
3301/33150 (epoch 4.979), train_loss = 1.59920979, grad/param norm = 2.0811e-01, time/batch = 0.6857s	
3302/33150 (epoch 4.980), train_loss = 1.57863432, grad/param norm = 1.9258e-01, time/batch = 0.6824s	
3303/33150 (epoch 4.982), train_loss = 1.42748114, grad/param norm = 2.0532e-01, time/batch = 0.6805s	
3304/33150 (epoch 4.983), train_loss = 1.35958639, grad/param norm = 1.8831e-01, time/batch = 0.6793s	
3305/33150 (epoch 4.985), train_loss = 1.50523479, grad/param norm = 1.8730e-01, time/batch = 0.6703s	
3306/33150 (epoch 4.986), train_loss = 1.34148828, grad/param norm = 1.6855e-01, time/batch = 0.6693s	
3307/33150 (epoch 4.988), train_loss = 1.42981453, grad/param norm = 1.8440e-01, time/batch = 0.6814s	
3308/33150 (epoch 4.989), train_loss = 1.33428706, grad/param norm = 1.7372e-01, time/batch = 0.6848s	
3309/33150 (epoch 4.991), train_loss = 1.60793916, grad/param norm = 2.3273e-01, time/batch = 0.6787s	
3310/33150 (epoch 4.992), train_loss = 1.25939982, grad/param norm = 1.7245e-01, time/batch = 0.6754s	
3311/33150 (epoch 4.994), train_loss = 1.42215780, grad/param norm = 1.8457e-01, time/batch = 0.6928s	
3312/33150 (epoch 4.995), train_loss = 1.34238311, grad/param norm = 1.7452e-01, time/batch = 0.6694s	
3313/33150 (epoch 4.997), train_loss = 1.53163138, grad/param norm = 1.9174e-01, time/batch = 0.6716s	
3314/33150 (epoch 4.998), train_loss = 1.17914180, grad/param norm = 1.6713e-01, time/batch = 0.6685s	
3315/33150 (epoch 5.000), train_loss = 1.38039298, grad/param norm = 1.9443e-01, time/batch = 0.6701s	
3316/33150 (epoch 5.002), train_loss = 1.65485437, grad/param norm = 2.1118e-01, time/batch = 0.6869s	
3317/33150 (epoch 5.003), train_loss = 1.41931455, grad/param norm = 1.8883e-01, time/batch = 0.6796s	
3318/33150 (epoch 5.005), train_loss = 1.27646501, grad/param norm = 1.7774e-01, time/batch = 0.6723s	
3319/33150 (epoch 5.006), train_loss = 1.21616985, grad/param norm = 1.6906e-01, time/batch = 0.6718s	
3320/33150 (epoch 5.008), train_loss = 1.53017831, grad/param norm = 1.8694e-01, time/batch = 0.6840s	
3321/33150 (epoch 5.009), train_loss = 1.43024285, grad/param norm = 1.6679e-01, time/batch = 0.6710s	
3322/33150 (epoch 5.011), train_loss = 1.72038285, grad/param norm = 1.8959e-01, time/batch = 0.6710s	
3323/33150 (epoch 5.012), train_loss = 1.42425445, grad/param norm = 1.8046e-01, time/batch = 0.6895s	
3324/33150 (epoch 5.014), train_loss = 1.46554996, grad/param norm = 2.0430e-01, time/batch = 0.6838s	
3325/33150 (epoch 5.015), train_loss = 1.44630021, grad/param norm = 1.8257e-01, time/batch = 0.6875s	
3326/33150 (epoch 5.017), train_loss = 1.38008426, grad/param norm = 1.9303e-01, time/batch = 0.7023s	
3327/33150 (epoch 5.018), train_loss = 1.54870210, grad/param norm = 2.0314e-01, time/batch = 0.6914s	
3328/33150 (epoch 5.020), train_loss = 1.50897458, grad/param norm = 1.8826e-01, time/batch = 0.6876s	
3329/33150 (epoch 5.021), train_loss = 1.27647258, grad/param norm = 1.7542e-01, time/batch = 0.6777s	
3330/33150 (epoch 5.023), train_loss = 1.61518477, grad/param norm = 1.7251e-01, time/batch = 0.6828s	
3331/33150 (epoch 5.024), train_loss = 1.45273253, grad/param norm = 1.7835e-01, time/batch = 0.6942s	
3332/33150 (epoch 5.026), train_loss = 1.19110794, grad/param norm = 1.5953e-01, time/batch = 0.6818s	
3333/33150 (epoch 5.027), train_loss = 1.30638141, grad/param norm = 1.8135e-01, time/batch = 0.6853s	
3334/33150 (epoch 5.029), train_loss = 1.37404992, grad/param norm = 1.9366e-01, time/batch = 0.6697s	
3335/33150 (epoch 5.030), train_loss = 1.45584749, grad/param norm = 1.7189e-01, time/batch = 0.6765s	
3336/33150 (epoch 5.032), train_loss = 1.41296754, grad/param norm = 2.0115e-01, time/batch = 0.6962s	
3337/33150 (epoch 5.033), train_loss = 1.41295083, grad/param norm = 1.9613e-01, time/batch = 0.6691s	
3338/33150 (epoch 5.035), train_loss = 1.67064279, grad/param norm = 2.1295e-01, time/batch = 0.6696s	
3339/33150 (epoch 5.036), train_loss = 1.54858820, grad/param norm = 2.0675e-01, time/batch = 0.6717s	
3340/33150 (epoch 5.038), train_loss = 1.79579811, grad/param norm = 2.3126e-01, time/batch = 0.6706s	
3341/33150 (epoch 5.039), train_loss = 1.44854094, grad/param norm = 1.6876e-01, time/batch = 0.6711s	
3342/33150 (epoch 5.041), train_loss = 1.48399457, grad/param norm = 1.8418e-01, time/batch = 0.6705s	
3343/33150 (epoch 5.042), train_loss = 1.30482366, grad/param norm = 1.6428e-01, time/batch = 0.6706s	
3344/33150 (epoch 5.044), train_loss = 1.38264994, grad/param norm = 1.6517e-01, time/batch = 0.6680s	
3345/33150 (epoch 5.045), train_loss = 1.44996453, grad/param norm = 1.8373e-01, time/batch = 0.6773s	
3346/33150 (epoch 5.047), train_loss = 1.38586673, grad/param norm = 1.8962e-01, time/batch = 0.6749s	
3347/33150 (epoch 5.048), train_loss = 1.63399740, grad/param norm = 2.1202e-01, time/batch = 0.6711s	
3348/33150 (epoch 5.050), train_loss = 1.46286241, grad/param norm = 1.8965e-01, time/batch = 0.6663s	
3349/33150 (epoch 5.051), train_loss = 1.49891083, grad/param norm = 2.0054e-01, time/batch = 0.6685s	
3350/33150 (epoch 5.053), train_loss = 1.41101615, grad/param norm = 1.8945e-01, time/batch = 0.6688s	
3351/33150 (epoch 5.054), train_loss = 1.45197714, grad/param norm = 1.7216e-01, time/batch = 0.6669s	
3352/33150 (epoch 5.056), train_loss = 1.30626654, grad/param norm = 1.5867e-01, time/batch = 0.6677s	
3353/33150 (epoch 5.057), train_loss = 1.47182040, grad/param norm = 1.8783e-01, time/batch = 0.6697s	
3354/33150 (epoch 5.059), train_loss = 1.38441881, grad/param norm = 2.0463e-01, time/batch = 0.6681s	
3355/33150 (epoch 5.060), train_loss = 1.34845579, grad/param norm = 1.6640e-01, time/batch = 0.6652s	
3356/33150 (epoch 5.062), train_loss = 1.46459151, grad/param norm = 1.7742e-01, time/batch = 0.6654s	
3357/33150 (epoch 5.063), train_loss = 1.38926090, grad/param norm = 1.7205e-01, time/batch = 0.6707s	
3358/33150 (epoch 5.065), train_loss = 1.44029696, grad/param norm = 1.8628e-01, time/batch = 0.6680s	
3359/33150 (epoch 5.066), train_loss = 1.37281473, grad/param norm = 1.9682e-01, time/batch = 0.6720s	
3360/33150 (epoch 5.068), train_loss = 1.42155365, grad/param norm = 1.7299e-01, time/batch = 0.6853s	
3361/33150 (epoch 5.069), train_loss = 1.53285475, grad/param norm = 2.0624e-01, time/batch = 0.6774s	
3362/33150 (epoch 5.071), train_loss = 1.51372128, grad/param norm = 1.9074e-01, time/batch = 0.6769s	
3363/33150 (epoch 5.072), train_loss = 1.31131693, grad/param norm = 1.7979e-01, time/batch = 0.6765s	
3364/33150 (epoch 5.074), train_loss = 1.26653629, grad/param norm = 1.8745e-01, time/batch = 0.6700s	
3365/33150 (epoch 5.075), train_loss = 1.42609886, grad/param norm = 1.8525e-01, time/batch = 0.6740s	
3366/33150 (epoch 5.077), train_loss = 1.57693583, grad/param norm = 2.2243e-01, time/batch = 0.6679s	
3367/33150 (epoch 5.078), train_loss = 1.61579152, grad/param norm = 2.0702e-01, time/batch = 0.6686s	
3368/33150 (epoch 5.080), train_loss = 1.56576196, grad/param norm = 1.7513e-01, time/batch = 0.6728s	
3369/33150 (epoch 5.081), train_loss = 1.39255423, grad/param norm = 2.0479e-01, time/batch = 0.6732s	
3370/33150 (epoch 5.083), train_loss = 1.11166307, grad/param norm = 1.7902e-01, time/batch = 0.6726s	
3371/33150 (epoch 5.084), train_loss = 1.30552189, grad/param norm = 1.8117e-01, time/batch = 0.6757s	
3372/33150 (epoch 5.086), train_loss = 1.38712344, grad/param norm = 1.9166e-01, time/batch = 0.6974s	
3373/33150 (epoch 5.087), train_loss = 1.30783452, grad/param norm = 1.7544e-01, time/batch = 0.6833s	
3374/33150 (epoch 5.089), train_loss = 1.32055288, grad/param norm = 1.9339e-01, time/batch = 0.6756s	
3375/33150 (epoch 5.090), train_loss = 1.38232859, grad/param norm = 2.1089e-01, time/batch = 0.6789s	
3376/33150 (epoch 5.092), train_loss = 1.50114605, grad/param norm = 1.9716e-01, time/batch = 0.6732s	
3377/33150 (epoch 5.094), train_loss = 1.53631525, grad/param norm = 1.9860e-01, time/batch = 0.6649s	
3378/33150 (epoch 5.095), train_loss = 1.26717299, grad/param norm = 1.6505e-01, time/batch = 0.6642s	
3379/33150 (epoch 5.097), train_loss = 1.52560940, grad/param norm = 1.9388e-01, time/batch = 0.6690s	
3380/33150 (epoch 5.098), train_loss = 1.68276017, grad/param norm = 2.0705e-01, time/batch = 0.6800s	
3381/33150 (epoch 5.100), train_loss = 1.60846744, grad/param norm = 1.9639e-01, time/batch = 0.6672s	
3382/33150 (epoch 5.101), train_loss = 1.34431533, grad/param norm = 1.9422e-01, time/batch = 0.6758s	
3383/33150 (epoch 5.103), train_loss = 1.47625783, grad/param norm = 1.8236e-01, time/batch = 0.6792s	
3384/33150 (epoch 5.104), train_loss = 1.41345019, grad/param norm = 1.9639e-01, time/batch = 0.6660s	
3385/33150 (epoch 5.106), train_loss = 1.64301098, grad/param norm = 2.0040e-01, time/batch = 0.6749s	
3386/33150 (epoch 5.107), train_loss = 1.67911073, grad/param norm = 2.1242e-01, time/batch = 0.6739s	
3387/33150 (epoch 5.109), train_loss = 1.36638214, grad/param norm = 1.9165e-01, time/batch = 0.6695s	
3388/33150 (epoch 5.110), train_loss = 1.51752322, grad/param norm = 1.8253e-01, time/batch = 0.6794s	
3389/33150 (epoch 5.112), train_loss = 1.33069271, grad/param norm = 1.7375e-01, time/batch = 0.6811s	
3390/33150 (epoch 5.113), train_loss = 1.36196268, grad/param norm = 1.9279e-01, time/batch = 0.6654s	
3391/33150 (epoch 5.115), train_loss = 1.58108313, grad/param norm = 2.0572e-01, time/batch = 0.6669s	
3392/33150 (epoch 5.116), train_loss = 1.31165360, grad/param norm = 1.8442e-01, time/batch = 0.6656s	
3393/33150 (epoch 5.118), train_loss = 1.52421480, grad/param norm = 2.1092e-01, time/batch = 0.6656s	
3394/33150 (epoch 5.119), train_loss = 1.52156548, grad/param norm = 2.0002e-01, time/batch = 0.6765s	
3395/33150 (epoch 5.121), train_loss = 1.37735512, grad/param norm = 1.7456e-01, time/batch = 0.6880s	
3396/33150 (epoch 5.122), train_loss = 1.60069717, grad/param norm = 2.0584e-01, time/batch = 0.6793s	
3397/33150 (epoch 5.124), train_loss = 1.16614408, grad/param norm = 1.7276e-01, time/batch = 0.6713s	
3398/33150 (epoch 5.125), train_loss = 1.46616597, grad/param norm = 1.7110e-01, time/batch = 0.6813s	
3399/33150 (epoch 5.127), train_loss = 1.32533876, grad/param norm = 1.7100e-01, time/batch = 0.6909s	
3400/33150 (epoch 5.128), train_loss = 1.48128616, grad/param norm = 1.9207e-01, time/batch = 0.6739s	
3401/33150 (epoch 5.130), train_loss = 1.50819179, grad/param norm = 1.8387e-01, time/batch = 0.6723s	
3402/33150 (epoch 5.131), train_loss = 1.65466002, grad/param norm = 1.9742e-01, time/batch = 0.6837s	
3403/33150 (epoch 5.133), train_loss = 1.31806924, grad/param norm = 1.7153e-01, time/batch = 0.6648s	
3404/33150 (epoch 5.134), train_loss = 1.54415710, grad/param norm = 2.0155e-01, time/batch = 0.6646s	
3405/33150 (epoch 5.136), train_loss = 1.40470478, grad/param norm = 1.6998e-01, time/batch = 0.6652s	
3406/33150 (epoch 5.137), train_loss = 1.51939249, grad/param norm = 1.9889e-01, time/batch = 0.6677s	
3407/33150 (epoch 5.139), train_loss = 1.46699917, grad/param norm = 1.9055e-01, time/batch = 0.6684s	
3408/33150 (epoch 5.140), train_loss = 1.56876524, grad/param norm = 2.0584e-01, time/batch = 0.6689s	
3409/33150 (epoch 5.142), train_loss = 1.51707319, grad/param norm = 2.1356e-01, time/batch = 0.6682s	
3410/33150 (epoch 5.143), train_loss = 1.49820697, grad/param norm = 1.9743e-01, time/batch = 0.6741s	
3411/33150 (epoch 5.145), train_loss = 1.46379785, grad/param norm = 2.0490e-01, time/batch = 0.6750s	
3412/33150 (epoch 5.146), train_loss = 1.61670826, grad/param norm = 2.4381e-01, time/batch = 0.6864s	
3413/33150 (epoch 5.148), train_loss = 1.51908373, grad/param norm = 1.8359e-01, time/batch = 0.6895s	
3414/33150 (epoch 5.149), train_loss = 1.49340855, grad/param norm = 2.1022e-01, time/batch = 0.6832s	
3415/33150 (epoch 5.151), train_loss = 1.70519366, grad/param norm = 2.0550e-01, time/batch = 0.6837s	
3416/33150 (epoch 5.152), train_loss = 1.35182291, grad/param norm = 1.6622e-01, time/batch = 0.6873s	
3417/33150 (epoch 5.154), train_loss = 1.41717665, grad/param norm = 1.7824e-01, time/batch = 0.6793s	
3418/33150 (epoch 5.155), train_loss = 1.30474930, grad/param norm = 1.8247e-01, time/batch = 0.6791s	
3419/33150 (epoch 5.157), train_loss = 1.38750175, grad/param norm = 1.9740e-01, time/batch = 0.6694s	
3420/33150 (epoch 5.158), train_loss = 1.31021919, grad/param norm = 1.8831e-01, time/batch = 0.6663s	
3421/33150 (epoch 5.160), train_loss = 1.55962654, grad/param norm = 1.8878e-01, time/batch = 0.6656s	
3422/33150 (epoch 5.161), train_loss = 1.42809587, grad/param norm = 2.0708e-01, time/batch = 0.6658s	
3423/33150 (epoch 5.163), train_loss = 1.38887031, grad/param norm = 1.7173e-01, time/batch = 0.6675s	
3424/33150 (epoch 5.164), train_loss = 1.54263237, grad/param norm = 1.7816e-01, time/batch = 0.6918s	
3425/33150 (epoch 5.166), train_loss = 1.47844632, grad/param norm = 1.9364e-01, time/batch = 0.6670s	
3426/33150 (epoch 5.167), train_loss = 1.46156569, grad/param norm = 1.7523e-01, time/batch = 0.6692s	
3427/33150 (epoch 5.169), train_loss = 1.62942407, grad/param norm = 2.1976e-01, time/batch = 0.6858s	
3428/33150 (epoch 5.170), train_loss = 1.44084968, grad/param norm = 1.9441e-01, time/batch = 0.6777s	
3429/33150 (epoch 5.172), train_loss = 1.57026123, grad/param norm = 1.9333e-01, time/batch = 0.6641s	
3430/33150 (epoch 5.173), train_loss = 1.57019176, grad/param norm = 2.1993e-01, time/batch = 0.6619s	
3431/33150 (epoch 5.175), train_loss = 1.35222227, grad/param norm = 1.8957e-01, time/batch = 0.6664s	
3432/33150 (epoch 5.176), train_loss = 1.45655562, grad/param norm = 1.9982e-01, time/batch = 0.6720s	
3433/33150 (epoch 5.178), train_loss = 1.60691643, grad/param norm = 1.9606e-01, time/batch = 0.6670s	
3434/33150 (epoch 5.179), train_loss = 1.47340276, grad/param norm = 1.6658e-01, time/batch = 0.6716s	
3435/33150 (epoch 5.181), train_loss = 1.46404249, grad/param norm = 2.1425e-01, time/batch = 0.6666s	
3436/33150 (epoch 5.183), train_loss = 1.49373079, grad/param norm = 2.3734e-01, time/batch = 0.6905s	
3437/33150 (epoch 5.184), train_loss = 1.62568985, grad/param norm = 2.1288e-01, time/batch = 0.6646s	
3438/33150 (epoch 5.186), train_loss = 1.60673122, grad/param norm = 1.9868e-01, time/batch = 0.6758s	
3439/33150 (epoch 5.187), train_loss = 1.43521488, grad/param norm = 1.8448e-01, time/batch = 0.6677s	
3440/33150 (epoch 5.189), train_loss = 1.29290152, grad/param norm = 1.8979e-01, time/batch = 0.6638s	
3441/33150 (epoch 5.190), train_loss = 1.37986861, grad/param norm = 1.8818e-01, time/batch = 0.6658s	
3442/33150 (epoch 5.192), train_loss = 1.47092921, grad/param norm = 1.9589e-01, time/batch = 0.6687s	
3443/33150 (epoch 5.193), train_loss = 1.43569759, grad/param norm = 1.7302e-01, time/batch = 0.6670s	
3444/33150 (epoch 5.195), train_loss = 1.77003858, grad/param norm = 2.0059e-01, time/batch = 0.6668s	
3445/33150 (epoch 5.196), train_loss = 1.55418119, grad/param norm = 1.7930e-01, time/batch = 0.6679s	
3446/33150 (epoch 5.198), train_loss = 1.33358968, grad/param norm = 1.8462e-01, time/batch = 0.6694s	
3447/33150 (epoch 5.199), train_loss = 1.53563572, grad/param norm = 1.9145e-01, time/batch = 0.6683s	
3448/33150 (epoch 5.201), train_loss = 1.27942907, grad/param norm = 1.5743e-01, time/batch = 0.6913s	
3449/33150 (epoch 5.202), train_loss = 1.22620489, grad/param norm = 1.5948e-01, time/batch = 0.6664s	
3450/33150 (epoch 5.204), train_loss = 1.41394389, grad/param norm = 1.7137e-01, time/batch = 0.6668s	
3451/33150 (epoch 5.205), train_loss = 1.58033132, grad/param norm = 2.0892e-01, time/batch = 0.6796s	
3452/33150 (epoch 5.207), train_loss = 1.45317122, grad/param norm = 1.9222e-01, time/batch = 0.6742s	
3453/33150 (epoch 5.208), train_loss = 1.50682300, grad/param norm = 1.7449e-01, time/batch = 0.6723s	
3454/33150 (epoch 5.210), train_loss = 1.29266795, grad/param norm = 1.6471e-01, time/batch = 0.6750s	
3455/33150 (epoch 5.211), train_loss = 1.49059288, grad/param norm = 1.9110e-01, time/batch = 0.6696s	
3456/33150 (epoch 5.213), train_loss = 1.60177742, grad/param norm = 1.8681e-01, time/batch = 0.6657s	
3457/33150 (epoch 5.214), train_loss = 1.39929919, grad/param norm = 1.8026e-01, time/batch = 0.6685s	
3458/33150 (epoch 5.216), train_loss = 1.41075778, grad/param norm = 1.8691e-01, time/batch = 0.6661s	
3459/33150 (epoch 5.217), train_loss = 1.37263622, grad/param norm = 1.6651e-01, time/batch = 0.6647s	
3460/33150 (epoch 5.219), train_loss = 1.33892406, grad/param norm = 1.6464e-01, time/batch = 0.6898s	
3461/33150 (epoch 5.220), train_loss = 1.28875968, grad/param norm = 1.6079e-01, time/batch = 0.6723s	
3462/33150 (epoch 5.222), train_loss = 1.50867055, grad/param norm = 1.8696e-01, time/batch = 0.6649s	
3463/33150 (epoch 5.223), train_loss = 1.39450176, grad/param norm = 1.6916e-01, time/batch = 0.6668s	
3464/33150 (epoch 5.225), train_loss = 1.65022605, grad/param norm = 1.9946e-01, time/batch = 0.6665s	
3465/33150 (epoch 5.226), train_loss = 1.38348612, grad/param norm = 1.7176e-01, time/batch = 0.6697s	
3466/33150 (epoch 5.228), train_loss = 1.43447385, grad/param norm = 1.9933e-01, time/batch = 0.6773s	
3467/33150 (epoch 5.229), train_loss = 1.43873538, grad/param norm = 1.8093e-01, time/batch = 0.6624s	
3468/33150 (epoch 5.231), train_loss = 1.54974166, grad/param norm = 1.8979e-01, time/batch = 0.6631s	
3469/33150 (epoch 5.232), train_loss = 1.47117154, grad/param norm = 2.1441e-01, time/batch = 0.6652s	
3470/33150 (epoch 5.234), train_loss = 1.39136256, grad/param norm = 1.9127e-01, time/batch = 0.6738s	
3471/33150 (epoch 5.235), train_loss = 1.47307036, grad/param norm = 1.9490e-01, time/batch = 0.6879s	
3472/33150 (epoch 5.237), train_loss = 1.40996657, grad/param norm = 1.9158e-01, time/batch = 0.6867s	
3473/33150 (epoch 5.238), train_loss = 1.61913021, grad/param norm = 2.0365e-01, time/batch = 0.6699s	
3474/33150 (epoch 5.240), train_loss = 1.44127314, grad/param norm = 1.7409e-01, time/batch = 0.6746s	
3475/33150 (epoch 5.241), train_loss = 1.56044768, grad/param norm = 2.0379e-01, time/batch = 0.6820s	
3476/33150 (epoch 5.243), train_loss = 1.59324580, grad/param norm = 1.9020e-01, time/batch = 0.6755s	
3477/33150 (epoch 5.244), train_loss = 1.38955882, grad/param norm = 1.6774e-01, time/batch = 0.6854s	
3478/33150 (epoch 5.246), train_loss = 1.47402264, grad/param norm = 1.9673e-01, time/batch = 0.6697s	
3479/33150 (epoch 5.247), train_loss = 1.30353468, grad/param norm = 1.7139e-01, time/batch = 0.6701s	
3480/33150 (epoch 5.249), train_loss = 1.62311705, grad/param norm = 1.9924e-01, time/batch = 0.6827s	
3481/33150 (epoch 5.250), train_loss = 1.46508835, grad/param norm = 1.6603e-01, time/batch = 0.6736s	
3482/33150 (epoch 5.252), train_loss = 1.44408002, grad/param norm = 1.5811e-01, time/batch = 0.6746s	
3483/33150 (epoch 5.253), train_loss = 1.52959661, grad/param norm = 1.9415e-01, time/batch = 0.6768s	
3484/33150 (epoch 5.255), train_loss = 1.43160506, grad/param norm = 1.7460e-01, time/batch = 0.6895s	
3485/33150 (epoch 5.256), train_loss = 1.52396755, grad/param norm = 1.8396e-01, time/batch = 0.6688s	
3486/33150 (epoch 5.258), train_loss = 1.42626196, grad/param norm = 1.9812e-01, time/batch = 0.6676s	
3487/33150 (epoch 5.259), train_loss = 1.21309593, grad/param norm = 1.8674e-01, time/batch = 0.6730s	
3488/33150 (epoch 5.261), train_loss = 1.27129704, grad/param norm = 1.7529e-01, time/batch = 0.6786s	
3489/33150 (epoch 5.262), train_loss = 1.48856813, grad/param norm = 2.0165e-01, time/batch = 0.6905s	
3490/33150 (epoch 5.264), train_loss = 1.12852540, grad/param norm = 1.6984e-01, time/batch = 0.6692s	
3491/33150 (epoch 5.265), train_loss = 1.44526355, grad/param norm = 1.8209e-01, time/batch = 0.6718s	
3492/33150 (epoch 5.267), train_loss = 1.57744740, grad/param norm = 1.8724e-01, time/batch = 0.6698s	
3493/33150 (epoch 5.268), train_loss = 1.34388687, grad/param norm = 1.7845e-01, time/batch = 0.6665s	
3494/33150 (epoch 5.270), train_loss = 1.65551768, grad/param norm = 1.7735e-01, time/batch = 0.6681s	
3495/33150 (epoch 5.271), train_loss = 1.58751003, grad/param norm = 1.9882e-01, time/batch = 0.6903s	
3496/33150 (epoch 5.273), train_loss = 1.51801882, grad/param norm = 1.8743e-01, time/batch = 0.6902s	
3497/33150 (epoch 5.275), train_loss = 1.55194657, grad/param norm = 1.8683e-01, time/batch = 0.6701s	
3498/33150 (epoch 5.276), train_loss = 1.43060440, grad/param norm = 1.7202e-01, time/batch = 0.6637s	
3499/33150 (epoch 5.278), train_loss = 1.59012427, grad/param norm = 1.9513e-01, time/batch = 0.6643s	
3500/33150 (epoch 5.279), train_loss = 1.42807540, grad/param norm = 1.8223e-01, time/batch = 0.6717s	
3501/33150 (epoch 5.281), train_loss = 1.55893306, grad/param norm = 1.9055e-01, time/batch = 0.6874s	
3502/33150 (epoch 5.282), train_loss = 1.46452572, grad/param norm = 1.8048e-01, time/batch = 0.6915s	
3503/33150 (epoch 5.284), train_loss = 1.42791849, grad/param norm = 1.7316e-01, time/batch = 0.6931s	
3504/33150 (epoch 5.285), train_loss = 1.50147875, grad/param norm = 1.9664e-01, time/batch = 0.6715s	
3505/33150 (epoch 5.287), train_loss = 1.38997313, grad/param norm = 1.7172e-01, time/batch = 0.6828s	
3506/33150 (epoch 5.288), train_loss = 1.66125157, grad/param norm = 2.0102e-01, time/batch = 0.6772s	
3507/33150 (epoch 5.290), train_loss = 1.29536747, grad/param norm = 1.8230e-01, time/batch = 0.6902s	
3508/33150 (epoch 5.291), train_loss = 1.34409917, grad/param norm = 1.8558e-01, time/batch = 0.6889s	
3509/33150 (epoch 5.293), train_loss = 1.49715440, grad/param norm = 1.8229e-01, time/batch = 0.6894s	
3510/33150 (epoch 5.294), train_loss = 1.17201145, grad/param norm = 1.7067e-01, time/batch = 0.6850s	
3511/33150 (epoch 5.296), train_loss = 1.37843135, grad/param norm = 1.9522e-01, time/batch = 0.6841s	
3512/33150 (epoch 5.297), train_loss = 1.41586969, grad/param norm = 1.8647e-01, time/batch = 0.6777s	
3513/33150 (epoch 5.299), train_loss = 1.34120048, grad/param norm = 1.9222e-01, time/batch = 0.6757s	
3514/33150 (epoch 5.300), train_loss = 1.39322674, grad/param norm = 1.7009e-01, time/batch = 0.6821s	
3515/33150 (epoch 5.302), train_loss = 1.39742527, grad/param norm = 1.9149e-01, time/batch = 0.6805s	
3516/33150 (epoch 5.303), train_loss = 1.51648162, grad/param norm = 1.9791e-01, time/batch = 0.6730s	
3517/33150 (epoch 5.305), train_loss = 1.45282961, grad/param norm = 1.7839e-01, time/batch = 0.6707s	
3518/33150 (epoch 5.306), train_loss = 1.53051257, grad/param norm = 2.0587e-01, time/batch = 0.6695s	
3519/33150 (epoch 5.308), train_loss = 1.68570143, grad/param norm = 1.8930e-01, time/batch = 0.6679s	
3520/33150 (epoch 5.309), train_loss = 1.29405521, grad/param norm = 1.7293e-01, time/batch = 0.6794s	
3521/33150 (epoch 5.311), train_loss = 1.49694458, grad/param norm = 2.0139e-01, time/batch = 0.6970s	
3522/33150 (epoch 5.312), train_loss = 1.28290543, grad/param norm = 1.8314e-01, time/batch = 0.6752s	
3523/33150 (epoch 5.314), train_loss = 1.45732308, grad/param norm = 1.8931e-01, time/batch = 0.6763s	
3524/33150 (epoch 5.315), train_loss = 1.53872168, grad/param norm = 1.8068e-01, time/batch = 0.6898s	
3525/33150 (epoch 5.317), train_loss = 1.17880930, grad/param norm = 1.5731e-01, time/batch = 0.6845s	
3526/33150 (epoch 5.318), train_loss = 1.30449822, grad/param norm = 1.5704e-01, time/batch = 0.6701s	
3527/33150 (epoch 5.320), train_loss = 1.27553308, grad/param norm = 1.6934e-01, time/batch = 0.6625s	
3528/33150 (epoch 5.321), train_loss = 1.35363061, grad/param norm = 1.7609e-01, time/batch = 0.6646s	
3529/33150 (epoch 5.323), train_loss = 1.45447997, grad/param norm = 1.8163e-01, time/batch = 0.6644s	
3530/33150 (epoch 5.324), train_loss = 1.56117791, grad/param norm = 1.9810e-01, time/batch = 0.6639s	
3531/33150 (epoch 5.326), train_loss = 1.43857368, grad/param norm = 1.6887e-01, time/batch = 0.6687s	
3532/33150 (epoch 5.327), train_loss = 1.54586501, grad/param norm = 1.8899e-01, time/batch = 0.6655s	
3533/33150 (epoch 5.329), train_loss = 1.45800062, grad/param norm = 1.6871e-01, time/batch = 0.6704s	
3534/33150 (epoch 5.330), train_loss = 1.54218167, grad/param norm = 2.1494e-01, time/batch = 0.6840s	
3535/33150 (epoch 5.332), train_loss = 1.40517059, grad/param norm = 1.8004e-01, time/batch = 0.6678s	
3536/33150 (epoch 5.333), train_loss = 1.45425038, grad/param norm = 1.6684e-01, time/batch = 0.6661s	
3537/33150 (epoch 5.335), train_loss = 1.44738752, grad/param norm = 1.7742e-01, time/batch = 0.6822s	
3538/33150 (epoch 5.336), train_loss = 1.31249610, grad/param norm = 1.6912e-01, time/batch = 0.6876s	
3539/33150 (epoch 5.338), train_loss = 1.18353289, grad/param norm = 1.6863e-01, time/batch = 0.6821s	
3540/33150 (epoch 5.339), train_loss = 1.54385012, grad/param norm = 1.7912e-01, time/batch = 0.6807s	
3541/33150 (epoch 5.341), train_loss = 1.65890747, grad/param norm = 2.1516e-01, time/batch = 0.6707s	
3542/33150 (epoch 5.342), train_loss = 1.30751795, grad/param norm = 1.9261e-01, time/batch = 0.6738s	
3543/33150 (epoch 5.344), train_loss = 1.48901747, grad/param norm = 1.7994e-01, time/batch = 0.6707s	
3544/33150 (epoch 5.345), train_loss = 1.26721462, grad/param norm = 1.7488e-01, time/batch = 0.6748s	
3545/33150 (epoch 5.347), train_loss = 1.17068986, grad/param norm = 1.5893e-01, time/batch = 0.6807s	
3546/33150 (epoch 5.348), train_loss = 1.40350770, grad/param norm = 1.8555e-01, time/batch = 0.6937s	
3547/33150 (epoch 5.350), train_loss = 1.48942881, grad/param norm = 2.0367e-01, time/batch = 0.6807s	
3548/33150 (epoch 5.351), train_loss = 1.53070617, grad/param norm = 1.8724e-01, time/batch = 0.6680s	
3549/33150 (epoch 5.353), train_loss = 1.59405750, grad/param norm = 1.9975e-01, time/batch = 0.6721s	
3550/33150 (epoch 5.354), train_loss = 1.70158011, grad/param norm = 1.9715e-01, time/batch = 0.6716s	
3551/33150 (epoch 5.356), train_loss = 1.56473953, grad/param norm = 2.0680e-01, time/batch = 0.6702s	
3552/33150 (epoch 5.357), train_loss = 1.55371450, grad/param norm = 1.8827e-01, time/batch = 0.6850s	
3553/33150 (epoch 5.359), train_loss = 1.49172418, grad/param norm = 1.9022e-01, time/batch = 0.6800s	
3554/33150 (epoch 5.360), train_loss = 1.58218555, grad/param norm = 2.0427e-01, time/batch = 0.6710s	
3555/33150 (epoch 5.362), train_loss = 1.47009590, grad/param norm = 1.8362e-01, time/batch = 0.6959s	
3556/33150 (epoch 5.363), train_loss = 1.40002471, grad/param norm = 1.7183e-01, time/batch = 0.6912s	
3557/33150 (epoch 5.365), train_loss = 1.40878064, grad/param norm = 1.6366e-01, time/batch = 0.6921s	
3558/33150 (epoch 5.367), train_loss = 1.29595027, grad/param norm = 1.7283e-01, time/batch = 0.6996s	
3559/33150 (epoch 5.368), train_loss = 1.47838088, grad/param norm = 1.7967e-01, time/batch = 0.6940s	
3560/33150 (epoch 5.370), train_loss = 1.59103735, grad/param norm = 2.1631e-01, time/batch = 0.6989s	
3561/33150 (epoch 5.371), train_loss = 1.34344967, grad/param norm = 1.7952e-01, time/batch = 0.7031s	
3562/33150 (epoch 5.373), train_loss = 1.57930910, grad/param norm = 2.0477e-01, time/batch = 0.7009s	
3563/33150 (epoch 5.374), train_loss = 1.33294440, grad/param norm = 1.7089e-01, time/batch = 0.7001s	
3564/33150 (epoch 5.376), train_loss = 1.59021613, grad/param norm = 1.7752e-01, time/batch = 0.7026s	
3565/33150 (epoch 5.377), train_loss = 1.47007490, grad/param norm = 1.9527e-01, time/batch = 0.6945s	
3566/33150 (epoch 5.379), train_loss = 1.51338939, grad/param norm = 1.9731e-01, time/batch = 0.6785s	
3567/33150 (epoch 5.380), train_loss = 1.54937564, grad/param norm = 1.8277e-01, time/batch = 0.6834s	
3568/33150 (epoch 5.382), train_loss = 1.31440732, grad/param norm = 1.6620e-01, time/batch = 0.6692s	
3569/33150 (epoch 5.383), train_loss = 1.32295965, grad/param norm = 1.7757e-01, time/batch = 0.6731s	
3570/33150 (epoch 5.385), train_loss = 1.45364744, grad/param norm = 1.7199e-01, time/batch = 0.6890s	
3571/33150 (epoch 5.386), train_loss = 1.30088964, grad/param norm = 1.6594e-01, time/batch = 0.6672s	
3572/33150 (epoch 5.388), train_loss = 1.41572030, grad/param norm = 1.8269e-01, time/batch = 0.6657s	
3573/33150 (epoch 5.389), train_loss = 1.38462269, grad/param norm = 1.7901e-01, time/batch = 0.6655s	
3574/33150 (epoch 5.391), train_loss = 1.63301204, grad/param norm = 1.9531e-01, time/batch = 0.6800s	
3575/33150 (epoch 5.392), train_loss = 1.37737982, grad/param norm = 1.7557e-01, time/batch = 0.6877s	
3576/33150 (epoch 5.394), train_loss = 1.27055875, grad/param norm = 1.5910e-01, time/batch = 0.6786s	
3577/33150 (epoch 5.395), train_loss = 1.39495774, grad/param norm = 2.0213e-01, time/batch = 0.6822s	
3578/33150 (epoch 5.397), train_loss = 1.11940260, grad/param norm = 1.6077e-01, time/batch = 0.6872s	
3579/33150 (epoch 5.398), train_loss = 1.48420031, grad/param norm = 1.8888e-01, time/batch = 0.6821s	
3580/33150 (epoch 5.400), train_loss = 1.39508920, grad/param norm = 1.6241e-01, time/batch = 0.6866s	
3581/33150 (epoch 5.401), train_loss = 1.24279298, grad/param norm = 1.7065e-01, time/batch = 0.6807s	
3582/33150 (epoch 5.403), train_loss = 1.31124873, grad/param norm = 1.7576e-01, time/batch = 0.6847s	
3583/33150 (epoch 5.404), train_loss = 1.35704747, grad/param norm = 1.7155e-01, time/batch = 0.6787s	
3584/33150 (epoch 5.406), train_loss = 1.28140884, grad/param norm = 1.5274e-01, time/batch = 0.6806s	
3585/33150 (epoch 5.407), train_loss = 1.28478432, grad/param norm = 1.5681e-01, time/batch = 0.6623s	
3586/33150 (epoch 5.409), train_loss = 1.19165072, grad/param norm = 1.7483e-01, time/batch = 0.6612s	
3587/33150 (epoch 5.410), train_loss = 1.50389430, grad/param norm = 2.1500e-01, time/batch = 0.6626s	
3588/33150 (epoch 5.412), train_loss = 1.53819101, grad/param norm = 1.9831e-01, time/batch = 0.6650s	
3589/33150 (epoch 5.413), train_loss = 1.39955623, grad/param norm = 1.8672e-01, time/batch = 0.6857s	
3590/33150 (epoch 5.415), train_loss = 1.58124730, grad/param norm = 1.8447e-01, time/batch = 0.6865s	
3591/33150 (epoch 5.416), train_loss = 1.41138420, grad/param norm = 1.7079e-01, time/batch = 0.6927s	
3592/33150 (epoch 5.418), train_loss = 1.69653926, grad/param norm = 2.2906e-01, time/batch = 0.6700s	
3593/33150 (epoch 5.419), train_loss = 1.34447563, grad/param norm = 2.0288e-01, time/batch = 0.6730s	
3594/33150 (epoch 5.421), train_loss = 1.48065171, grad/param norm = 1.9072e-01, time/batch = 0.6790s	
3595/33150 (epoch 5.422), train_loss = 1.31943304, grad/param norm = 1.7344e-01, time/batch = 0.6806s	
3596/33150 (epoch 5.424), train_loss = 1.42379218, grad/param norm = 2.1453e-01, time/batch = 0.6647s	
3597/33150 (epoch 5.425), train_loss = 1.35437899, grad/param norm = 1.9881e-01, time/batch = 0.6626s	
3598/33150 (epoch 5.427), train_loss = 1.34685957, grad/param norm = 1.7271e-01, time/batch = 0.6632s	
3599/33150 (epoch 5.428), train_loss = 1.44589745, grad/param norm = 1.8092e-01, time/batch = 0.6631s	
3600/33150 (epoch 5.430), train_loss = 1.47098372, grad/param norm = 1.8011e-01, time/batch = 0.6615s	
3601/33150 (epoch 5.431), train_loss = 1.49974822, grad/param norm = 1.7930e-01, time/batch = 0.6669s	
3602/33150 (epoch 5.433), train_loss = 1.44886001, grad/param norm = 1.5825e-01, time/batch = 0.6678s	
3603/33150 (epoch 5.434), train_loss = 1.26016853, grad/param norm = 1.8365e-01, time/batch = 0.6655s	
3604/33150 (epoch 5.436), train_loss = 1.24071698, grad/param norm = 2.0140e-01, time/batch = 0.6679s	
3605/33150 (epoch 5.437), train_loss = 1.47762710, grad/param norm = 2.1782e-01, time/batch = 0.6651s	
3606/33150 (epoch 5.439), train_loss = 1.52612738, grad/param norm = 1.8827e-01, time/batch = 0.6681s	
3607/33150 (epoch 5.440), train_loss = 1.54871452, grad/param norm = 2.1524e-01, time/batch = 0.6732s	
3608/33150 (epoch 5.442), train_loss = 1.24857996, grad/param norm = 1.7843e-01, time/batch = 0.6668s	
3609/33150 (epoch 5.443), train_loss = 1.49951594, grad/param norm = 1.8248e-01, time/batch = 0.6657s	
3610/33150 (epoch 5.445), train_loss = 1.46590824, grad/param norm = 1.8939e-01, time/batch = 0.6630s	
3611/33150 (epoch 5.446), train_loss = 1.50628244, grad/param norm = 2.3019e-01, time/batch = 0.6708s	
3612/33150 (epoch 5.448), train_loss = 1.43919948, grad/param norm = 1.8312e-01, time/batch = 0.6668s	
3613/33150 (epoch 5.449), train_loss = 1.36536785, grad/param norm = 1.6086e-01, time/batch = 0.6623s	
3614/33150 (epoch 5.451), train_loss = 1.52694727, grad/param norm = 2.1037e-01, time/batch = 0.6644s	
3615/33150 (epoch 5.452), train_loss = 1.67010387, grad/param norm = 1.8440e-01, time/batch = 0.6633s	
3616/33150 (epoch 5.454), train_loss = 1.42047138, grad/param norm = 1.9718e-01, time/batch = 0.6720s	
3617/33150 (epoch 5.456), train_loss = 1.16618426, grad/param norm = 1.6794e-01, time/batch = 0.6667s	
3618/33150 (epoch 5.457), train_loss = 1.44854353, grad/param norm = 1.7878e-01, time/batch = 0.6691s	
3619/33150 (epoch 5.459), train_loss = 1.62746813, grad/param norm = 1.9482e-01, time/batch = 0.6735s	
3620/33150 (epoch 5.460), train_loss = 1.45448028, grad/param norm = 1.6085e-01, time/batch = 0.6744s	
3621/33150 (epoch 5.462), train_loss = 1.52923881, grad/param norm = 2.0535e-01, time/batch = 0.6798s	
3622/33150 (epoch 5.463), train_loss = 1.74811569, grad/param norm = 2.2471e-01, time/batch = 0.6823s	
3623/33150 (epoch 5.465), train_loss = 1.30281794, grad/param norm = 1.7814e-01, time/batch = 0.6774s	
3624/33150 (epoch 5.466), train_loss = 1.39706095, grad/param norm = 1.7731e-01, time/batch = 0.6771s	
3625/33150 (epoch 5.468), train_loss = 1.75710420, grad/param norm = 2.0103e-01, time/batch = 0.6663s	
3626/33150 (epoch 5.469), train_loss = 1.54125719, grad/param norm = 1.9974e-01, time/batch = 0.6758s	
3627/33150 (epoch 5.471), train_loss = 1.38841639, grad/param norm = 1.7887e-01, time/batch = 0.6620s	
3628/33150 (epoch 5.472), train_loss = 1.34613255, grad/param norm = 1.8268e-01, time/batch = 0.6649s	
3629/33150 (epoch 5.474), train_loss = 1.49297328, grad/param norm = 2.0018e-01, time/batch = 0.6617s	
3630/33150 (epoch 5.475), train_loss = 1.71351262, grad/param norm = 2.0680e-01, time/batch = 0.6712s	
3631/33150 (epoch 5.477), train_loss = 1.50037639, grad/param norm = 1.9980e-01, time/batch = 0.6652s	
3632/33150 (epoch 5.478), train_loss = 1.51438007, grad/param norm = 1.7920e-01, time/batch = 0.6603s	
3633/33150 (epoch 5.480), train_loss = 1.31465688, grad/param norm = 1.6813e-01, time/batch = 0.6646s	
3634/33150 (epoch 5.481), train_loss = 1.21044381, grad/param norm = 1.6231e-01, time/batch = 0.6669s	
3635/33150 (epoch 5.483), train_loss = 1.32100011, grad/param norm = 1.9824e-01, time/batch = 0.6640s	
3636/33150 (epoch 5.484), train_loss = 1.33545372, grad/param norm = 1.7907e-01, time/batch = 0.6631s	
3637/33150 (epoch 5.486), train_loss = 1.46199428, grad/param norm = 1.8854e-01, time/batch = 0.6666s	
3638/33150 (epoch 5.487), train_loss = 1.50619839, grad/param norm = 1.8901e-01, time/batch = 0.6722s	
3639/33150 (epoch 5.489), train_loss = 1.41523317, grad/param norm = 1.9453e-01, time/batch = 0.6732s	
3640/33150 (epoch 5.490), train_loss = 1.26234076, grad/param norm = 1.6902e-01, time/batch = 0.6721s	
3641/33150 (epoch 5.492), train_loss = 1.39017156, grad/param norm = 2.0415e-01, time/batch = 0.6707s	
3642/33150 (epoch 5.493), train_loss = 1.55435573, grad/param norm = 1.9522e-01, time/batch = 0.6791s	
3643/33150 (epoch 5.495), train_loss = 1.51707696, grad/param norm = 1.7010e-01, time/batch = 0.6686s	
3644/33150 (epoch 5.496), train_loss = 1.33036915, grad/param norm = 1.9970e-01, time/batch = 0.6662s	
3645/33150 (epoch 5.498), train_loss = 1.55436816, grad/param norm = 1.9294e-01, time/batch = 0.6668s	
3646/33150 (epoch 5.499), train_loss = 1.65219407, grad/param norm = 1.9507e-01, time/batch = 0.6735s	
3647/33150 (epoch 5.501), train_loss = 1.47714951, grad/param norm = 1.7477e-01, time/batch = 0.6732s	
3648/33150 (epoch 5.502), train_loss = 1.60574435, grad/param norm = 2.0077e-01, time/batch = 0.6676s	
3649/33150 (epoch 5.504), train_loss = 1.53868111, grad/param norm = 1.9451e-01, time/batch = 0.6664s	
3650/33150 (epoch 5.505), train_loss = 1.70814388, grad/param norm = 2.0596e-01, time/batch = 0.6658s	
3651/33150 (epoch 5.507), train_loss = 1.36425547, grad/param norm = 1.9584e-01, time/batch = 0.6669s	
3652/33150 (epoch 5.508), train_loss = 1.33582421, grad/param norm = 1.7165e-01, time/batch = 0.6650s	
3653/33150 (epoch 5.510), train_loss = 1.41906132, grad/param norm = 1.6868e-01, time/batch = 0.6686s	
3654/33150 (epoch 5.511), train_loss = 1.68138808, grad/param norm = 2.0240e-01, time/batch = 0.6762s	
3655/33150 (epoch 5.513), train_loss = 1.51230253, grad/param norm = 1.8850e-01, time/batch = 0.6694s	
3656/33150 (epoch 5.514), train_loss = 1.20441487, grad/param norm = 1.7633e-01, time/batch = 0.6698s	
3657/33150 (epoch 5.516), train_loss = 1.59193016, grad/param norm = 2.1064e-01, time/batch = 0.6691s	
3658/33150 (epoch 5.517), train_loss = 1.57745046, grad/param norm = 1.7349e-01, time/batch = 0.6673s	
3659/33150 (epoch 5.519), train_loss = 1.39347530, grad/param norm = 1.7790e-01, time/batch = 0.6676s	
3660/33150 (epoch 5.520), train_loss = 1.46716046, grad/param norm = 1.7110e-01, time/batch = 0.6657s	
3661/33150 (epoch 5.522), train_loss = 1.63788419, grad/param norm = 2.1754e-01, time/batch = 0.6712s	
3662/33150 (epoch 5.523), train_loss = 1.32929611, grad/param norm = 1.8599e-01, time/batch = 0.6698s	
3663/33150 (epoch 5.525), train_loss = 1.44752700, grad/param norm = 1.6384e-01, time/batch = 0.6681s	
3664/33150 (epoch 5.526), train_loss = 1.30645609, grad/param norm = 1.7040e-01, time/batch = 0.6730s	
3665/33150 (epoch 5.528), train_loss = 1.48583978, grad/param norm = 1.9197e-01, time/batch = 0.6728s	
3666/33150 (epoch 5.529), train_loss = 1.51315884, grad/param norm = 1.7882e-01, time/batch = 0.6681s	
3667/33150 (epoch 5.531), train_loss = 1.29040684, grad/param norm = 1.7741e-01, time/batch = 0.6691s	
3668/33150 (epoch 5.532), train_loss = 1.49504722, grad/param norm = 1.8850e-01, time/batch = 0.6702s	
3669/33150 (epoch 5.534), train_loss = 1.33581570, grad/param norm = 1.6454e-01, time/batch = 0.6692s	
3670/33150 (epoch 5.535), train_loss = 1.35235653, grad/param norm = 1.9310e-01, time/batch = 0.6697s	
3671/33150 (epoch 5.537), train_loss = 1.61368018, grad/param norm = 1.8936e-01, time/batch = 0.6708s	
3672/33150 (epoch 5.538), train_loss = 1.40534535, grad/param norm = 1.8300e-01, time/batch = 0.6694s	
3673/33150 (epoch 5.540), train_loss = 1.22874742, grad/param norm = 1.7306e-01, time/batch = 0.6683s	
3674/33150 (epoch 5.541), train_loss = 1.49609683, grad/param norm = 1.9655e-01, time/batch = 0.6690s	
3675/33150 (epoch 5.543), train_loss = 1.47277843, grad/param norm = 1.8454e-01, time/batch = 0.6706s	
3676/33150 (epoch 5.544), train_loss = 1.43673308, grad/param norm = 1.6566e-01, time/batch = 0.6708s	
3677/33150 (epoch 5.546), train_loss = 1.66931649, grad/param norm = 2.0367e-01, time/batch = 0.6721s	
3678/33150 (epoch 5.548), train_loss = 1.52152820, grad/param norm = 1.9311e-01, time/batch = 0.6876s	
3679/33150 (epoch 5.549), train_loss = 1.47663308, grad/param norm = 1.9321e-01, time/batch = 0.6895s	
3680/33150 (epoch 5.551), train_loss = 1.31484126, grad/param norm = 1.7921e-01, time/batch = 0.6777s	
3681/33150 (epoch 5.552), train_loss = 1.23515164, grad/param norm = 1.6338e-01, time/batch = 0.6643s	
3682/33150 (epoch 5.554), train_loss = 1.43812911, grad/param norm = 1.7352e-01, time/batch = 0.6635s	
3683/33150 (epoch 5.555), train_loss = 1.68238326, grad/param norm = 2.0392e-01, time/batch = 0.6667s	
3684/33150 (epoch 5.557), train_loss = 1.24855076, grad/param norm = 1.7728e-01, time/batch = 0.6693s	
3685/33150 (epoch 5.558), train_loss = 1.57847874, grad/param norm = 2.0508e-01, time/batch = 0.6878s	
3686/33150 (epoch 5.560), train_loss = 1.41733902, grad/param norm = 1.9322e-01, time/batch = 0.6724s	
3687/33150 (epoch 5.561), train_loss = 1.23568962, grad/param norm = 1.7166e-01, time/batch = 0.6605s	
3688/33150 (epoch 5.563), train_loss = 1.56938783, grad/param norm = 2.1937e-01, time/batch = 0.6629s	
3689/33150 (epoch 5.564), train_loss = 1.66562179, grad/param norm = 1.8794e-01, time/batch = 0.6627s	
3690/33150 (epoch 5.566), train_loss = 1.38329351, grad/param norm = 1.8011e-01, time/batch = 0.6676s	
3691/33150 (epoch 5.567), train_loss = 1.31847297, grad/param norm = 1.8357e-01, time/batch = 0.6654s	
3692/33150 (epoch 5.569), train_loss = 1.42695112, grad/param norm = 1.7494e-01, time/batch = 0.6653s	
3693/33150 (epoch 5.570), train_loss = 1.39526371, grad/param norm = 1.6618e-01, time/batch = 0.6710s	
3694/33150 (epoch 5.572), train_loss = 1.37264006, grad/param norm = 1.7623e-01, time/batch = 0.6689s	
3695/33150 (epoch 5.573), train_loss = 1.14838232, grad/param norm = 1.4966e-01, time/batch = 0.6653s	
3696/33150 (epoch 5.575), train_loss = 1.49364663, grad/param norm = 1.7868e-01, time/batch = 0.6643s	
3697/33150 (epoch 5.576), train_loss = 1.19878251, grad/param norm = 1.5072e-01, time/batch = 0.6717s	
3698/33150 (epoch 5.578), train_loss = 1.40105133, grad/param norm = 1.5607e-01, time/batch = 0.6786s	
3699/33150 (epoch 5.579), train_loss = 1.28742631, grad/param norm = 1.6598e-01, time/batch = 0.6690s	
3700/33150 (epoch 5.581), train_loss = 1.26059560, grad/param norm = 1.7578e-01, time/batch = 0.6680s	
3701/33150 (epoch 5.582), train_loss = 1.43275755, grad/param norm = 1.7076e-01, time/batch = 0.6680s	
3702/33150 (epoch 5.584), train_loss = 1.49162389, grad/param norm = 1.8318e-01, time/batch = 0.6673s	
3703/33150 (epoch 5.585), train_loss = 1.43351828, grad/param norm = 1.7119e-01, time/batch = 0.6633s	
3704/33150 (epoch 5.587), train_loss = 1.49528580, grad/param norm = 1.8193e-01, time/batch = 0.6682s	
3705/33150 (epoch 5.588), train_loss = 1.28038470, grad/param norm = 1.7284e-01, time/batch = 0.6666s	
3706/33150 (epoch 5.590), train_loss = 1.45982414, grad/param norm = 1.9688e-01, time/batch = 0.6687s	
3707/33150 (epoch 5.591), train_loss = 1.46272637, grad/param norm = 1.8275e-01, time/batch = 0.6688s	
3708/33150 (epoch 5.593), train_loss = 1.51976580, grad/param norm = 1.9397e-01, time/batch = 0.6693s	
3709/33150 (epoch 5.594), train_loss = 1.46603723, grad/param norm = 1.9661e-01, time/batch = 0.6672s	
3710/33150 (epoch 5.596), train_loss = 1.26256130, grad/param norm = 1.6656e-01, time/batch = 0.6689s	
3711/33150 (epoch 5.597), train_loss = 1.37027145, grad/param norm = 2.0693e-01, time/batch = 0.6696s	
3712/33150 (epoch 5.599), train_loss = 1.65294417, grad/param norm = 1.9630e-01, time/batch = 0.6700s	
3713/33150 (epoch 5.600), train_loss = 1.48665480, grad/param norm = 2.0024e-01, time/batch = 0.6697s	
3714/33150 (epoch 5.602), train_loss = 1.31667127, grad/param norm = 1.8620e-01, time/batch = 0.6703s	
3715/33150 (epoch 5.603), train_loss = 1.42425929, grad/param norm = 1.8970e-01, time/batch = 0.6908s	
3716/33150 (epoch 5.605), train_loss = 1.30350740, grad/param norm = 1.6565e-01, time/batch = 0.6866s	
3717/33150 (epoch 5.606), train_loss = 1.47798167, grad/param norm = 1.9783e-01, time/batch = 0.6832s	
3718/33150 (epoch 5.608), train_loss = 1.47087827, grad/param norm = 1.9143e-01, time/batch = 0.6836s	
3719/33150 (epoch 5.609), train_loss = 1.44334756, grad/param norm = 2.0698e-01, time/batch = 0.6876s	
3720/33150 (epoch 5.611), train_loss = 1.19884470, grad/param norm = 1.7393e-01, time/batch = 0.6835s	
3721/33150 (epoch 5.612), train_loss = 1.40852804, grad/param norm = 2.0045e-01, time/batch = 0.6800s	
3722/33150 (epoch 5.614), train_loss = 1.20450281, grad/param norm = 1.6346e-01, time/batch = 0.6701s	
3723/33150 (epoch 5.615), train_loss = 1.25007741, grad/param norm = 1.6946e-01, time/batch = 0.6699s	
3724/33150 (epoch 5.617), train_loss = 1.34972694, grad/param norm = 1.7735e-01, time/batch = 0.6741s	
3725/33150 (epoch 5.618), train_loss = 1.36062570, grad/param norm = 1.8231e-01, time/batch = 0.6858s	
3726/33150 (epoch 5.620), train_loss = 1.32888872, grad/param norm = 1.9136e-01, time/batch = 0.6739s	
3727/33150 (epoch 5.621), train_loss = 1.33126941, grad/param norm = 1.7839e-01, time/batch = 0.6701s	
3728/33150 (epoch 5.623), train_loss = 1.44843344, grad/param norm = 1.8412e-01, time/batch = 0.6791s	
3729/33150 (epoch 5.624), train_loss = 1.37549745, grad/param norm = 1.9299e-01, time/batch = 0.6652s	
3730/33150 (epoch 5.626), train_loss = 1.27242145, grad/param norm = 1.8606e-01, time/batch = 0.6689s	
3731/33150 (epoch 5.627), train_loss = 1.26037002, grad/param norm = 1.9208e-01, time/batch = 0.6694s	
3732/33150 (epoch 5.629), train_loss = 1.24005103, grad/param norm = 1.6333e-01, time/batch = 0.6667s	
3733/33150 (epoch 5.630), train_loss = 1.27576462, grad/param norm = 1.6395e-01, time/batch = 0.6696s	
3734/33150 (epoch 5.632), train_loss = 1.20986071, grad/param norm = 1.5586e-01, time/batch = 0.6659s	
3735/33150 (epoch 5.633), train_loss = 1.23453154, grad/param norm = 1.8648e-01, time/batch = 0.6649s	
3736/33150 (epoch 5.635), train_loss = 1.61730907, grad/param norm = 1.8483e-01, time/batch = 0.6652s	
3737/33150 (epoch 5.637), train_loss = 1.20644936, grad/param norm = 1.8262e-01, time/batch = 0.6701s	
3738/33150 (epoch 5.638), train_loss = 1.32780661, grad/param norm = 1.7952e-01, time/batch = 0.6679s	
3739/33150 (epoch 5.640), train_loss = 1.53724031, grad/param norm = 2.1273e-01, time/batch = 0.6673s	
3740/33150 (epoch 5.641), train_loss = 1.30843680, grad/param norm = 1.8125e-01, time/batch = 0.6656s	
3741/33150 (epoch 5.643), train_loss = 1.29681882, grad/param norm = 1.7382e-01, time/batch = 0.6716s	
3742/33150 (epoch 5.644), train_loss = 1.49621022, grad/param norm = 1.7228e-01, time/batch = 0.6680s	
3743/33150 (epoch 5.646), train_loss = 1.30024875, grad/param norm = 1.6979e-01, time/batch = 0.6661s	
3744/33150 (epoch 5.647), train_loss = 1.72795282, grad/param norm = 1.9839e-01, time/batch = 0.6670s	
3745/33150 (epoch 5.649), train_loss = 1.51551521, grad/param norm = 2.0907e-01, time/batch = 0.6699s	
3746/33150 (epoch 5.650), train_loss = 1.26654469, grad/param norm = 1.8444e-01, time/batch = 0.6681s	
3747/33150 (epoch 5.652), train_loss = 1.47711754, grad/param norm = 1.9135e-01, time/batch = 0.6676s	
3748/33150 (epoch 5.653), train_loss = 1.35428990, grad/param norm = 1.7002e-01, time/batch = 0.6681s	
3749/33150 (epoch 5.655), train_loss = 1.45918369, grad/param norm = 2.0230e-01, time/batch = 0.6660s	
3750/33150 (epoch 5.656), train_loss = 1.33372148, grad/param norm = 1.6737e-01, time/batch = 0.6656s	
3751/33150 (epoch 5.658), train_loss = 1.45544938, grad/param norm = 2.2300e-01, time/batch = 0.6668s	
3752/33150 (epoch 5.659), train_loss = 1.80669045, grad/param norm = 2.2949e-01, time/batch = 0.6720s	
3753/33150 (epoch 5.661), train_loss = 1.37834799, grad/param norm = 1.7252e-01, time/batch = 0.6789s	
3754/33150 (epoch 5.662), train_loss = 1.23613973, grad/param norm = 1.8109e-01, time/batch = 0.6780s	
3755/33150 (epoch 5.664), train_loss = 1.50328525, grad/param norm = 1.8176e-01, time/batch = 0.6668s	
3756/33150 (epoch 5.665), train_loss = 1.44829016, grad/param norm = 1.7957e-01, time/batch = 0.6658s	
3757/33150 (epoch 5.667), train_loss = 1.59397509, grad/param norm = 1.9014e-01, time/batch = 0.6825s	
3758/33150 (epoch 5.668), train_loss = 1.46278059, grad/param norm = 1.8543e-01, time/batch = 0.6871s	
3759/33150 (epoch 5.670), train_loss = 1.32419041, grad/param norm = 1.5551e-01, time/batch = 0.6803s	
3760/33150 (epoch 5.671), train_loss = 1.35341695, grad/param norm = 1.8505e-01, time/batch = 0.6687s	
3761/33150 (epoch 5.673), train_loss = 1.45535627, grad/param norm = 1.7071e-01, time/batch = 0.6685s	
3762/33150 (epoch 5.674), train_loss = 1.41493109, grad/param norm = 1.8258e-01, time/batch = 0.6660s	
3763/33150 (epoch 5.676), train_loss = 1.36218038, grad/param norm = 1.7684e-01, time/batch = 0.6664s	
3764/33150 (epoch 5.677), train_loss = 1.70506038, grad/param norm = 1.9603e-01, time/batch = 0.6663s	
3765/33150 (epoch 5.679), train_loss = 1.25030509, grad/param norm = 1.6452e-01, time/batch = 0.6654s	
3766/33150 (epoch 5.680), train_loss = 1.51800872, grad/param norm = 1.9006e-01, time/batch = 0.6690s	
3767/33150 (epoch 5.682), train_loss = 1.27525398, grad/param norm = 1.6852e-01, time/batch = 0.6868s	
3768/33150 (epoch 5.683), train_loss = 1.22795128, grad/param norm = 1.7771e-01, time/batch = 0.6888s	
3769/33150 (epoch 5.685), train_loss = 1.45199155, grad/param norm = 1.7578e-01, time/batch = 0.6917s	
3770/33150 (epoch 5.686), train_loss = 1.19530520, grad/param norm = 1.6215e-01, time/batch = 0.6878s	
3771/33150 (epoch 5.688), train_loss = 1.36658119, grad/param norm = 1.9153e-01, time/batch = 0.6684s	
3772/33150 (epoch 5.689), train_loss = 1.28127016, grad/param norm = 1.8015e-01, time/batch = 0.6664s	
3773/33150 (epoch 5.691), train_loss = 1.16884314, grad/param norm = 1.7011e-01, time/batch = 0.6669s	
3774/33150 (epoch 5.692), train_loss = 1.31437597, grad/param norm = 1.8868e-01, time/batch = 0.6685s	
3775/33150 (epoch 5.694), train_loss = 1.10411596, grad/param norm = 1.3731e-01, time/batch = 0.6805s	
3776/33150 (epoch 5.695), train_loss = 1.33061359, grad/param norm = 1.7027e-01, time/batch = 0.6679s	
3777/33150 (epoch 5.697), train_loss = 1.19863215, grad/param norm = 1.5836e-01, time/batch = 0.6632s	
3778/33150 (epoch 5.698), train_loss = 1.51435105, grad/param norm = 1.8597e-01, time/batch = 0.6660s	
3779/33150 (epoch 5.700), train_loss = 1.09506850, grad/param norm = 1.5985e-01, time/batch = 0.6748s	
3780/33150 (epoch 5.701), train_loss = 1.27918567, grad/param norm = 1.7186e-01, time/batch = 0.6628s	
3781/33150 (epoch 5.703), train_loss = 1.43556613, grad/param norm = 1.8922e-01, time/batch = 0.6650s	
3782/33150 (epoch 5.704), train_loss = 1.17352612, grad/param norm = 1.5828e-01, time/batch = 0.6666s	
3783/33150 (epoch 5.706), train_loss = 1.33398619, grad/param norm = 1.6070e-01, time/batch = 0.6619s	
3784/33150 (epoch 5.707), train_loss = 1.36211571, grad/param norm = 1.8466e-01, time/batch = 0.6652s	
3785/33150 (epoch 5.709), train_loss = 1.39346829, grad/param norm = 1.5982e-01, time/batch = 0.6667s	
3786/33150 (epoch 5.710), train_loss = 1.50566363, grad/param norm = 1.9645e-01, time/batch = 0.6657s	
3787/33150 (epoch 5.712), train_loss = 1.50782259, grad/param norm = 1.9550e-01, time/batch = 0.6676s	
3788/33150 (epoch 5.713), train_loss = 1.42234130, grad/param norm = 1.7906e-01, time/batch = 0.6666s	
3789/33150 (epoch 5.715), train_loss = 1.30262184, grad/param norm = 1.5731e-01, time/batch = 0.6674s	
3790/33150 (epoch 5.716), train_loss = 1.42133535, grad/param norm = 1.7772e-01, time/batch = 0.6681s	
3791/33150 (epoch 5.718), train_loss = 1.39801229, grad/param norm = 1.6580e-01, time/batch = 0.6701s	
3792/33150 (epoch 5.719), train_loss = 1.51825828, grad/param norm = 1.9920e-01, time/batch = 0.6636s	
3793/33150 (epoch 5.721), train_loss = 1.41594799, grad/param norm = 2.0616e-01, time/batch = 0.6684s	
3794/33150 (epoch 5.722), train_loss = 1.39473679, grad/param norm = 1.8418e-01, time/batch = 0.6668s	
3795/33150 (epoch 5.724), train_loss = 1.34886013, grad/param norm = 1.9319e-01, time/batch = 0.6659s	
3796/33150 (epoch 5.725), train_loss = 1.63471282, grad/param norm = 2.0973e-01, time/batch = 0.6691s	
3797/33150 (epoch 5.727), train_loss = 1.47983093, grad/param norm = 2.0929e-01, time/batch = 0.6756s	
3798/33150 (epoch 5.729), train_loss = 1.43997560, grad/param norm = 1.8116e-01, time/batch = 0.6901s	
3799/33150 (epoch 5.730), train_loss = 1.38289615, grad/param norm = 1.6923e-01, time/batch = 0.6706s	
3800/33150 (epoch 5.732), train_loss = 1.46838611, grad/param norm = 1.7028e-01, time/batch = 0.6698s	
3801/33150 (epoch 5.733), train_loss = 1.15251726, grad/param norm = 1.4917e-01, time/batch = 0.6700s	
3802/33150 (epoch 5.735), train_loss = 1.35596216, grad/param norm = 1.6518e-01, time/batch = 0.6694s	
3803/33150 (epoch 5.736), train_loss = 1.26228124, grad/param norm = 1.7307e-01, time/batch = 0.6724s	
3804/33150 (epoch 5.738), train_loss = 1.48613546, grad/param norm = 1.8356e-01, time/batch = 0.6662s	
3805/33150 (epoch 5.739), train_loss = 1.57519661, grad/param norm = 2.0460e-01, time/batch = 0.6647s	
3806/33150 (epoch 5.741), train_loss = 1.55145869, grad/param norm = 2.0432e-01, time/batch = 0.6628s	
3807/33150 (epoch 5.742), train_loss = 1.37925002, grad/param norm = 1.8334e-01, time/batch = 0.6970s	
3808/33150 (epoch 5.744), train_loss = 1.51104547, grad/param norm = 1.8568e-01, time/batch = 0.6854s	
3809/33150 (epoch 5.745), train_loss = 1.34580417, grad/param norm = 1.7043e-01, time/batch = 0.6864s	
3810/33150 (epoch 5.747), train_loss = 1.22507657, grad/param norm = 1.6513e-01, time/batch = 0.6790s	
3811/33150 (epoch 5.748), train_loss = 1.31658753, grad/param norm = 1.6464e-01, time/batch = 0.6858s	
3812/33150 (epoch 5.750), train_loss = 1.46085725, grad/param norm = 1.8919e-01, time/batch = 0.6824s	
3813/33150 (epoch 5.751), train_loss = 1.40427506, grad/param norm = 1.7997e-01, time/batch = 0.6766s	
3814/33150 (epoch 5.753), train_loss = 1.21905139, grad/param norm = 1.8883e-01, time/batch = 0.6810s	
3815/33150 (epoch 5.754), train_loss = 1.66554931, grad/param norm = 2.0963e-01, time/batch = 0.6829s	
3816/33150 (epoch 5.756), train_loss = 1.41863538, grad/param norm = 1.9181e-01, time/batch = 0.6737s	
3817/33150 (epoch 5.757), train_loss = 1.43997478, grad/param norm = 1.8049e-01, time/batch = 0.6779s	
3818/33150 (epoch 5.759), train_loss = 1.62193774, grad/param norm = 1.8274e-01, time/batch = 0.6604s	
3819/33150 (epoch 5.760), train_loss = 1.43390785, grad/param norm = 1.7184e-01, time/batch = 0.6605s	
3820/33150 (epoch 5.762), train_loss = 1.44885843, grad/param norm = 1.8107e-01, time/batch = 0.6598s	
3821/33150 (epoch 5.763), train_loss = 1.31729668, grad/param norm = 1.6998e-01, time/batch = 0.6658s	
3822/33150 (epoch 5.765), train_loss = 1.33922835, grad/param norm = 1.6610e-01, time/batch = 0.6598s	
3823/33150 (epoch 5.766), train_loss = 1.27427533, grad/param norm = 1.5353e-01, time/batch = 0.6601s	
3824/33150 (epoch 5.768), train_loss = 1.30230945, grad/param norm = 1.7001e-01, time/batch = 0.6591s	
3825/33150 (epoch 5.769), train_loss = 1.38295521, grad/param norm = 1.7917e-01, time/batch = 0.6611s	
3826/33150 (epoch 5.771), train_loss = 1.41255799, grad/param norm = 1.8429e-01, time/batch = 0.6629s	
3827/33150 (epoch 5.772), train_loss = 1.48076316, grad/param norm = 2.0902e-01, time/batch = 0.6633s	
3828/33150 (epoch 5.774), train_loss = 1.57391653, grad/param norm = 1.8722e-01, time/batch = 0.6645s	
3829/33150 (epoch 5.775), train_loss = 1.45733783, grad/param norm = 2.0041e-01, time/batch = 0.6637s	
3830/33150 (epoch 5.777), train_loss = 1.52408458, grad/param norm = 1.8927e-01, time/batch = 0.6664s	
3831/33150 (epoch 5.778), train_loss = 1.41362803, grad/param norm = 1.6090e-01, time/batch = 0.6723s	
3832/33150 (epoch 5.780), train_loss = 1.27233249, grad/param norm = 1.6562e-01, time/batch = 0.6728s	
3833/33150 (epoch 5.781), train_loss = 1.36881698, grad/param norm = 1.6682e-01, time/batch = 0.6829s	
3834/33150 (epoch 5.783), train_loss = 1.36538088, grad/param norm = 1.5471e-01, time/batch = 0.6792s	
3835/33150 (epoch 5.784), train_loss = 1.33013819, grad/param norm = 1.7426e-01, time/batch = 0.6878s	
3836/33150 (epoch 5.786), train_loss = 1.34899282, grad/param norm = 1.6158e-01, time/batch = 0.6882s	
3837/33150 (epoch 5.787), train_loss = 1.35908182, grad/param norm = 1.7175e-01, time/batch = 0.6831s	
3838/33150 (epoch 5.789), train_loss = 1.21413109, grad/param norm = 1.5658e-01, time/batch = 0.6787s	
3839/33150 (epoch 5.790), train_loss = 1.16416169, grad/param norm = 1.5504e-01, time/batch = 0.6709s	
3840/33150 (epoch 5.792), train_loss = 1.51365040, grad/param norm = 2.0807e-01, time/batch = 0.6625s	
3841/33150 (epoch 5.793), train_loss = 1.36401611, grad/param norm = 1.8379e-01, time/batch = 0.6660s	
3842/33150 (epoch 5.795), train_loss = 1.34407718, grad/param norm = 1.8088e-01, time/batch = 0.6662s	
3843/33150 (epoch 5.796), train_loss = 1.26375194, grad/param norm = 1.5360e-01, time/batch = 0.6686s	
3844/33150 (epoch 5.798), train_loss = 1.33318038, grad/param norm = 1.5381e-01, time/batch = 0.6650s	
3845/33150 (epoch 5.799), train_loss = 1.23113750, grad/param norm = 1.8513e-01, time/batch = 0.6652s	
3846/33150 (epoch 5.801), train_loss = 1.36273016, grad/param norm = 1.6158e-01, time/batch = 0.6760s	
3847/33150 (epoch 5.802), train_loss = 1.31326687, grad/param norm = 1.7819e-01, time/batch = 0.6827s	
3848/33150 (epoch 5.804), train_loss = 1.37812758, grad/param norm = 1.6992e-01, time/batch = 0.6693s	
3849/33150 (epoch 5.805), train_loss = 1.31863964, grad/param norm = 1.8099e-01, time/batch = 0.6622s	
3850/33150 (epoch 5.807), train_loss = 1.27684462, grad/param norm = 1.7815e-01, time/batch = 0.6630s	
3851/33150 (epoch 5.808), train_loss = 1.42853023, grad/param norm = 1.8051e-01, time/batch = 0.6740s	
3852/33150 (epoch 5.810), train_loss = 1.33422834, grad/param norm = 1.7370e-01, time/batch = 0.6698s	
3853/33150 (epoch 5.811), train_loss = 1.44715970, grad/param norm = 1.8621e-01, time/batch = 0.6946s	
3854/33150 (epoch 5.813), train_loss = 1.36052687, grad/param norm = 1.5818e-01, time/batch = 0.6973s	
3855/33150 (epoch 5.814), train_loss = 1.41281018, grad/param norm = 1.8186e-01, time/batch = 0.6977s	
3856/33150 (epoch 5.816), train_loss = 1.39161609, grad/param norm = 1.9574e-01, time/batch = 0.6890s	
3857/33150 (epoch 5.817), train_loss = 1.49231166, grad/param norm = 1.8077e-01, time/batch = 0.6890s	
3858/33150 (epoch 5.819), train_loss = 1.34722077, grad/param norm = 1.7274e-01, time/batch = 0.6959s	
3859/33150 (epoch 5.821), train_loss = 1.15515925, grad/param norm = 1.4452e-01, time/batch = 0.6813s	
3860/33150 (epoch 5.822), train_loss = 1.28178201, grad/param norm = 1.6528e-01, time/batch = 0.6645s	
3861/33150 (epoch 5.824), train_loss = 1.32550795, grad/param norm = 1.8753e-01, time/batch = 0.6664s	
3862/33150 (epoch 5.825), train_loss = 1.36448456, grad/param norm = 1.8124e-01, time/batch = 0.6640s	
3863/33150 (epoch 5.827), train_loss = 1.45817835, grad/param norm = 1.9777e-01, time/batch = 0.6658s	
3864/33150 (epoch 5.828), train_loss = 1.24438370, grad/param norm = 1.7979e-01, time/batch = 0.6667s	
3865/33150 (epoch 5.830), train_loss = 1.36782552, grad/param norm = 1.7924e-01, time/batch = 0.6655s	
3866/33150 (epoch 5.831), train_loss = 1.32398858, grad/param norm = 1.8241e-01, time/batch = 0.6660s	
3867/33150 (epoch 5.833), train_loss = 1.27157374, grad/param norm = 1.8312e-01, time/batch = 0.6742s	
3868/33150 (epoch 5.834), train_loss = 1.56249930, grad/param norm = 1.9487e-01, time/batch = 0.6727s	
3869/33150 (epoch 5.836), train_loss = 1.49593647, grad/param norm = 1.8939e-01, time/batch = 0.6917s	
3870/33150 (epoch 5.837), train_loss = 1.36185777, grad/param norm = 1.7595e-01, time/batch = 0.6791s	
3871/33150 (epoch 5.839), train_loss = 1.58065665, grad/param norm = 2.2932e-01, time/batch = 0.6638s	
3872/33150 (epoch 5.840), train_loss = 1.47324277, grad/param norm = 1.7660e-01, time/batch = 0.6656s	
3873/33150 (epoch 5.842), train_loss = 1.54301962, grad/param norm = 2.0944e-01, time/batch = 0.6640s	
3874/33150 (epoch 5.843), train_loss = 1.47922617, grad/param norm = 1.9984e-01, time/batch = 0.6651s	
3875/33150 (epoch 5.845), train_loss = 1.30824300, grad/param norm = 1.7410e-01, time/batch = 0.6639s	
3876/33150 (epoch 5.846), train_loss = 1.66121256, grad/param norm = 2.1563e-01, time/batch = 0.6675s	
3877/33150 (epoch 5.848), train_loss = 1.46329852, grad/param norm = 1.7203e-01, time/batch = 0.6697s	
3878/33150 (epoch 5.849), train_loss = 1.43017042, grad/param norm = 1.8150e-01, time/batch = 0.6666s	
3879/33150 (epoch 5.851), train_loss = 1.53037316, grad/param norm = 2.1617e-01, time/batch = 0.6714s	
3880/33150 (epoch 5.852), train_loss = 1.55754924, grad/param norm = 1.9115e-01, time/batch = 0.6647s	
3881/33150 (epoch 5.854), train_loss = 1.41622943, grad/param norm = 1.6775e-01, time/batch = 0.6662s	
3882/33150 (epoch 5.855), train_loss = 1.14358060, grad/param norm = 1.5064e-01, time/batch = 0.6653s	
3883/33150 (epoch 5.857), train_loss = 1.23177545, grad/param norm = 1.7163e-01, time/batch = 0.6644s	
3884/33150 (epoch 5.858), train_loss = 1.31839596, grad/param norm = 1.7882e-01, time/batch = 0.6644s	
3885/33150 (epoch 5.860), train_loss = 1.27987505, grad/param norm = 1.6256e-01, time/batch = 0.6639s	
3886/33150 (epoch 5.861), train_loss = 1.31141899, grad/param norm = 1.6333e-01, time/batch = 0.6691s	
3887/33150 (epoch 5.863), train_loss = 1.42385941, grad/param norm = 1.5907e-01, time/batch = 0.6663s	
3888/33150 (epoch 5.864), train_loss = 1.57066133, grad/param norm = 1.9024e-01, time/batch = 0.6663s	
3889/33150 (epoch 5.866), train_loss = 1.39507105, grad/param norm = 1.8630e-01, time/batch = 0.6646s	
3890/33150 (epoch 5.867), train_loss = 1.42841619, grad/param norm = 1.6132e-01, time/batch = 0.6674s	
3891/33150 (epoch 5.869), train_loss = 1.48835762, grad/param norm = 1.9931e-01, time/batch = 0.6658s	
3892/33150 (epoch 5.870), train_loss = 1.50883937, grad/param norm = 1.7604e-01, time/batch = 0.6658s	
3893/33150 (epoch 5.872), train_loss = 1.41736715, grad/param norm = 1.8346e-01, time/batch = 0.6636s	
3894/33150 (epoch 5.873), train_loss = 1.17974615, grad/param norm = 1.5671e-01, time/batch = 0.6658s	
3895/33150 (epoch 5.875), train_loss = 1.57133146, grad/param norm = 1.8321e-01, time/batch = 0.6711s	
3896/33150 (epoch 5.876), train_loss = 1.35870651, grad/param norm = 1.9867e-01, time/batch = 0.6826s	
3897/33150 (epoch 5.878), train_loss = 1.25943633, grad/param norm = 1.5673e-01, time/batch = 0.6737s	
3898/33150 (epoch 5.879), train_loss = 1.35203843, grad/param norm = 1.9168e-01, time/batch = 0.6793s	
3899/33150 (epoch 5.881), train_loss = 1.34324821, grad/param norm = 1.7302e-01, time/batch = 0.6702s	
3900/33150 (epoch 5.882), train_loss = 1.28188374, grad/param norm = 1.7270e-01, time/batch = 0.6809s	
3901/33150 (epoch 5.884), train_loss = 1.41806494, grad/param norm = 1.7456e-01, time/batch = 0.6804s	
3902/33150 (epoch 5.885), train_loss = 1.11394250, grad/param norm = 1.5969e-01, time/batch = 0.6757s	
3903/33150 (epoch 5.887), train_loss = 1.60999438, grad/param norm = 1.9359e-01, time/batch = 0.6716s	
3904/33150 (epoch 5.888), train_loss = 1.46182825, grad/param norm = 1.8337e-01, time/batch = 0.6695s	
3905/33150 (epoch 5.890), train_loss = 1.33889677, grad/param norm = 1.6038e-01, time/batch = 0.6713s	
3906/33150 (epoch 5.891), train_loss = 1.30160818, grad/param norm = 1.7870e-01, time/batch = 0.6710s	
3907/33150 (epoch 5.893), train_loss = 1.45768070, grad/param norm = 1.9173e-01, time/batch = 0.6687s	
3908/33150 (epoch 5.894), train_loss = 1.48141831, grad/param norm = 1.8457e-01, time/batch = 0.6682s	
3909/33150 (epoch 5.896), train_loss = 1.35563823, grad/param norm = 1.7051e-01, time/batch = 0.6665s	
3910/33150 (epoch 5.897), train_loss = 1.42192350, grad/param norm = 1.6094e-01, time/batch = 0.6666s	
3911/33150 (epoch 5.899), train_loss = 1.25562369, grad/param norm = 1.7526e-01, time/batch = 0.6654s	
3912/33150 (epoch 5.900), train_loss = 1.68074822, grad/param norm = 1.9612e-01, time/batch = 0.6781s	
3913/33150 (epoch 5.902), train_loss = 1.58633692, grad/param norm = 1.8360e-01, time/batch = 0.6659s	
3914/33150 (epoch 5.903), train_loss = 1.38961740, grad/param norm = 1.7001e-01, time/batch = 0.6622s	
3915/33150 (epoch 5.905), train_loss = 1.42752153, grad/param norm = 1.9211e-01, time/batch = 0.6666s	
3916/33150 (epoch 5.906), train_loss = 1.45984518, grad/param norm = 1.8259e-01, time/batch = 0.6677s	
3917/33150 (epoch 5.908), train_loss = 1.54620761, grad/param norm = 1.9085e-01, time/batch = 0.6720s	
3918/33150 (epoch 5.910), train_loss = 1.48600150, grad/param norm = 1.7587e-01, time/batch = 0.6661s	
3919/33150 (epoch 5.911), train_loss = 1.26111876, grad/param norm = 1.7583e-01, time/batch = 0.6666s	
3920/33150 (epoch 5.913), train_loss = 1.29518642, grad/param norm = 1.7803e-01, time/batch = 0.6669s	
3921/33150 (epoch 5.914), train_loss = 1.52505057, grad/param norm = 1.9622e-01, time/batch = 0.6662s	
3922/33150 (epoch 5.916), train_loss = 1.25839905, grad/param norm = 1.7677e-01, time/batch = 0.6674s	
3923/33150 (epoch 5.917), train_loss = 1.54844095, grad/param norm = 1.9083e-01, time/batch = 0.6698s	
3924/33150 (epoch 5.919), train_loss = 1.62226392, grad/param norm = 2.1063e-01, time/batch = 0.6694s	
3925/33150 (epoch 5.920), train_loss = 1.45274950, grad/param norm = 1.6613e-01, time/batch = 0.6678s	
3926/33150 (epoch 5.922), train_loss = 1.60152158, grad/param norm = 1.9695e-01, time/batch = 0.6674s	
3927/33150 (epoch 5.923), train_loss = 1.40379992, grad/param norm = 1.8961e-01, time/batch = 0.6682s	
3928/33150 (epoch 5.925), train_loss = 1.41511441, grad/param norm = 1.8208e-01, time/batch = 0.6711s	
3929/33150 (epoch 5.926), train_loss = 1.39579981, grad/param norm = 1.9024e-01, time/batch = 0.6672s	
3930/33150 (epoch 5.928), train_loss = 1.36659322, grad/param norm = 1.7563e-01, time/batch = 0.6660s	
3931/33150 (epoch 5.929), train_loss = 1.45278422, grad/param norm = 1.7094e-01, time/batch = 0.6693s	
3932/33150 (epoch 5.931), train_loss = 1.56925279, grad/param norm = 2.0349e-01, time/batch = 0.6743s	
3933/33150 (epoch 5.932), train_loss = 1.43863022, grad/param norm = 2.1161e-01, time/batch = 0.6688s	
3934/33150 (epoch 5.934), train_loss = 1.37109294, grad/param norm = 1.6202e-01, time/batch = 0.6681s	
3935/33150 (epoch 5.935), train_loss = 1.49843643, grad/param norm = 1.7389e-01, time/batch = 0.6691s	
3936/33150 (epoch 5.937), train_loss = 1.52263424, grad/param norm = 1.7875e-01, time/batch = 0.6714s	
3937/33150 (epoch 5.938), train_loss = 1.47958104, grad/param norm = 1.7350e-01, time/batch = 0.6714s	
3938/33150 (epoch 5.940), train_loss = 1.72969751, grad/param norm = 1.9623e-01, time/batch = 0.6691s	
3939/33150 (epoch 5.941), train_loss = 1.35834759, grad/param norm = 1.5373e-01, time/batch = 0.6694s	
3940/33150 (epoch 5.943), train_loss = 1.30055269, grad/param norm = 1.9820e-01, time/batch = 0.6713s	
3941/33150 (epoch 5.944), train_loss = 1.54948258, grad/param norm = 1.8815e-01, time/batch = 0.6708s	
3942/33150 (epoch 5.946), train_loss = 1.16031964, grad/param norm = 1.5937e-01, time/batch = 0.6693s	
3943/33150 (epoch 5.947), train_loss = 1.44183092, grad/param norm = 1.8156e-01, time/batch = 0.6675s	
3944/33150 (epoch 5.949), train_loss = 1.55996550, grad/param norm = 1.8827e-01, time/batch = 0.6762s	
3945/33150 (epoch 5.950), train_loss = 1.52301511, grad/param norm = 1.9576e-01, time/batch = 0.6863s	
3946/33150 (epoch 5.952), train_loss = 1.30455886, grad/param norm = 1.7001e-01, time/batch = 0.6934s	
3947/33150 (epoch 5.953), train_loss = 1.28717557, grad/param norm = 1.5580e-01, time/batch = 0.6928s	
3948/33150 (epoch 5.955), train_loss = 1.26790951, grad/param norm = 1.5142e-01, time/batch = 0.6972s	
3949/33150 (epoch 5.956), train_loss = 1.53219932, grad/param norm = 1.8833e-01, time/batch = 0.6717s	
3950/33150 (epoch 5.958), train_loss = 1.26719096, grad/param norm = 1.7452e-01, time/batch = 0.6668s	
3951/33150 (epoch 5.959), train_loss = 1.24796684, grad/param norm = 1.8933e-01, time/batch = 0.6896s	
3952/33150 (epoch 5.961), train_loss = 1.27089390, grad/param norm = 1.6574e-01, time/batch = 0.6790s	
3953/33150 (epoch 5.962), train_loss = 1.18527573, grad/param norm = 1.6165e-01, time/batch = 0.6674s	
3954/33150 (epoch 5.964), train_loss = 1.39946229, grad/param norm = 1.8138e-01, time/batch = 0.6650s	
3955/33150 (epoch 5.965), train_loss = 1.40392032, grad/param norm = 1.7928e-01, time/batch = 0.6634s	
3956/33150 (epoch 5.967), train_loss = 1.45694631, grad/param norm = 2.0077e-01, time/batch = 0.6707s	
3957/33150 (epoch 5.968), train_loss = 1.22721978, grad/param norm = 1.7579e-01, time/batch = 0.6661s	
3958/33150 (epoch 5.970), train_loss = 1.30733410, grad/param norm = 1.7464e-01, time/batch = 0.6643s	
3959/33150 (epoch 5.971), train_loss = 1.46690228, grad/param norm = 2.0513e-01, time/batch = 0.6652s	
3960/33150 (epoch 5.973), train_loss = 1.55778338, grad/param norm = 1.7315e-01, time/batch = 0.6673s	
3961/33150 (epoch 5.974), train_loss = 1.61878031, grad/param norm = 2.0270e-01, time/batch = 0.7017s	
3962/33150 (epoch 5.976), train_loss = 1.45132505, grad/param norm = 1.7369e-01, time/batch = 0.6801s	
3963/33150 (epoch 5.977), train_loss = 1.53664682, grad/param norm = 1.8274e-01, time/batch = 0.6672s	
3964/33150 (epoch 5.979), train_loss = 1.52856555, grad/param norm = 1.9221e-01, time/batch = 0.6712s	
3965/33150 (epoch 5.980), train_loss = 1.50967530, grad/param norm = 1.8364e-01, time/batch = 0.6722s	
3966/33150 (epoch 5.982), train_loss = 1.35597852, grad/param norm = 1.8549e-01, time/batch = 0.6703s	
3967/33150 (epoch 5.983), train_loss = 1.28101704, grad/param norm = 1.7591e-01, time/batch = 0.6691s	
3968/33150 (epoch 5.985), train_loss = 1.42921503, grad/param norm = 1.6973e-01, time/batch = 0.6781s	
3969/33150 (epoch 5.986), train_loss = 1.27524069, grad/param norm = 1.6574e-01, time/batch = 0.6742s	
3970/33150 (epoch 5.988), train_loss = 1.35709607, grad/param norm = 1.7508e-01, time/batch = 0.6750s	
3971/33150 (epoch 5.989), train_loss = 1.27476879, grad/param norm = 1.6986e-01, time/batch = 0.6794s	
3972/33150 (epoch 5.991), train_loss = 1.53884180, grad/param norm = 2.1887e-01, time/batch = 0.6664s	
3973/33150 (epoch 5.992), train_loss = 1.21005088, grad/param norm = 1.6184e-01, time/batch = 0.6804s	
3974/33150 (epoch 5.994), train_loss = 1.36037439, grad/param norm = 1.8396e-01, time/batch = 0.6641s	
3975/33150 (epoch 5.995), train_loss = 1.27721255, grad/param norm = 1.6453e-01, time/batch = 0.6658s	
3976/33150 (epoch 5.997), train_loss = 1.46537922, grad/param norm = 1.9494e-01, time/batch = 0.6627s	
3977/33150 (epoch 5.998), train_loss = 1.11910755, grad/param norm = 1.5989e-01, time/batch = 0.6688s	
3978/33150 (epoch 6.000), train_loss = 1.29010905, grad/param norm = 1.7893e-01, time/batch = 0.6643s	
3979/33150 (epoch 6.002), train_loss = 1.62686125, grad/param norm = 2.0542e-01, time/batch = 0.6708s	
3980/33150 (epoch 6.003), train_loss = 1.34860579, grad/param norm = 1.8484e-01, time/batch = 0.6678s	
3981/33150 (epoch 6.005), train_loss = 1.22661084, grad/param norm = 1.6953e-01, time/batch = 0.6680s	
3982/33150 (epoch 6.006), train_loss = 1.16141612, grad/param norm = 1.6271e-01, time/batch = 0.6678s	
3983/33150 (epoch 6.008), train_loss = 1.50033189, grad/param norm = 1.8983e-01, time/batch = 0.6686s	
3984/33150 (epoch 6.009), train_loss = 1.35957036, grad/param norm = 1.5669e-01, time/batch = 0.6657s	
3985/33150 (epoch 6.011), train_loss = 1.63274834, grad/param norm = 1.8456e-01, time/batch = 0.6682s	
3986/33150 (epoch 6.012), train_loss = 1.37795194, grad/param norm = 1.7843e-01, time/batch = 0.6649s	
3987/33150 (epoch 6.014), train_loss = 1.38739207, grad/param norm = 1.8692e-01, time/batch = 0.6651s	
3988/33150 (epoch 6.015), train_loss = 1.37552324, grad/param norm = 1.6648e-01, time/batch = 0.6657s	
3989/33150 (epoch 6.017), train_loss = 1.29789924, grad/param norm = 1.7258e-01, time/batch = 0.6637s	
3990/33150 (epoch 6.018), train_loss = 1.47195954, grad/param norm = 1.8358e-01, time/batch = 0.6669s	
3991/33150 (epoch 6.020), train_loss = 1.43727515, grad/param norm = 1.7635e-01, time/batch = 0.6734s	
3992/33150 (epoch 6.021), train_loss = 1.19436236, grad/param norm = 1.6870e-01, time/batch = 0.6695s	
3993/33150 (epoch 6.023), train_loss = 1.55227963, grad/param norm = 1.6322e-01, time/batch = 0.6679s	
3994/33150 (epoch 6.024), train_loss = 1.39263272, grad/param norm = 1.7504e-01, time/batch = 0.6765s	
3995/33150 (epoch 6.026), train_loss = 1.12508505, grad/param norm = 1.4989e-01, time/batch = 0.6672s	
3996/33150 (epoch 6.027), train_loss = 1.23042136, grad/param norm = 1.8634e-01, time/batch = 0.6631s	
3997/33150 (epoch 6.029), train_loss = 1.28877830, grad/param norm = 1.7495e-01, time/batch = 0.6657s	
3998/33150 (epoch 6.030), train_loss = 1.37366482, grad/param norm = 1.6893e-01, time/batch = 0.6636s	
3999/33150 (epoch 6.032), train_loss = 1.31639245, grad/param norm = 1.8652e-01, time/batch = 0.6650s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch6.03_1.5430.t7	
4000/33150 (epoch 6.033), train_loss = 1.35401204, grad/param norm = 1.9177e-01, time/batch = 0.6653s	
4001/33150 (epoch 6.035), train_loss = 1.79104273, grad/param norm = 2.1280e-01, time/batch = 0.6738s	
4002/33150 (epoch 6.036), train_loss = 1.47413120, grad/param norm = 1.9601e-01, time/batch = 0.6681s	
4003/33150 (epoch 6.038), train_loss = 1.72635112, grad/param norm = 2.1438e-01, time/batch = 0.6700s	
4004/33150 (epoch 6.039), train_loss = 1.38582229, grad/param norm = 1.5475e-01, time/batch = 0.6764s	
4005/33150 (epoch 6.041), train_loss = 1.42307641, grad/param norm = 1.7774e-01, time/batch = 0.6683s	
4006/33150 (epoch 6.042), train_loss = 1.25624347, grad/param norm = 1.5497e-01, time/batch = 0.6690s	
4007/33150 (epoch 6.044), train_loss = 1.31724045, grad/param norm = 1.5562e-01, time/batch = 0.6690s	
4008/33150 (epoch 6.045), train_loss = 1.37284136, grad/param norm = 1.6923e-01, time/batch = 0.6695s	
4009/33150 (epoch 6.047), train_loss = 1.32415830, grad/param norm = 1.8715e-01, time/batch = 0.6656s	
4010/33150 (epoch 6.048), train_loss = 1.56826304, grad/param norm = 2.0951e-01, time/batch = 0.6645s	
4011/33150 (epoch 6.050), train_loss = 1.38599893, grad/param norm = 1.7630e-01, time/batch = 0.6636s	
4012/33150 (epoch 6.051), train_loss = 1.41532572, grad/param norm = 1.8118e-01, time/batch = 0.6683s	
4013/33150 (epoch 6.053), train_loss = 1.33639136, grad/param norm = 1.7746e-01, time/batch = 0.6679s	
4014/33150 (epoch 6.054), train_loss = 1.38650098, grad/param norm = 1.6431e-01, time/batch = 0.6697s	
4015/33150 (epoch 6.056), train_loss = 1.25559810, grad/param norm = 1.5084e-01, time/batch = 0.6690s	
4016/33150 (epoch 6.057), train_loss = 1.40721624, grad/param norm = 1.7971e-01, time/batch = 0.6680s	
4017/33150 (epoch 6.059), train_loss = 1.31006359, grad/param norm = 1.8672e-01, time/batch = 0.6691s	
4018/33150 (epoch 6.060), train_loss = 1.28985182, grad/param norm = 1.6055e-01, time/batch = 0.6686s	
4019/33150 (epoch 6.062), train_loss = 1.39218301, grad/param norm = 1.7184e-01, time/batch = 0.6678s	
4020/33150 (epoch 6.063), train_loss = 1.31668614, grad/param norm = 1.5975e-01, time/batch = 0.6674s	
4021/33150 (epoch 6.065), train_loss = 1.37276278, grad/param norm = 1.7022e-01, time/batch = 0.6697s	
4022/33150 (epoch 6.066), train_loss = 1.29868580, grad/param norm = 1.7809e-01, time/batch = 0.6703s	
4023/33150 (epoch 6.068), train_loss = 1.35755924, grad/param norm = 1.6666e-01, time/batch = 0.6719s	
4024/33150 (epoch 6.069), train_loss = 1.46181772, grad/param norm = 1.9639e-01, time/batch = 0.6768s	
4025/33150 (epoch 6.071), train_loss = 1.44550295, grad/param norm = 1.7784e-01, time/batch = 0.6864s	
4026/33150 (epoch 6.072), train_loss = 1.26152116, grad/param norm = 1.6974e-01, time/batch = 0.6862s	
4027/33150 (epoch 6.074), train_loss = 1.19491269, grad/param norm = 1.6605e-01, time/batch = 0.6823s	
4028/33150 (epoch 6.075), train_loss = 1.36544990, grad/param norm = 1.7318e-01, time/batch = 0.7017s	
4029/33150 (epoch 6.077), train_loss = 1.49269930, grad/param norm = 2.0016e-01, time/batch = 0.6835s	
4030/33150 (epoch 6.078), train_loss = 1.55703062, grad/param norm = 1.9858e-01, time/batch = 0.6697s	
4031/33150 (epoch 6.080), train_loss = 1.48807944, grad/param norm = 1.6933e-01, time/batch = 0.6710s	
4032/33150 (epoch 6.081), train_loss = 1.32233077, grad/param norm = 2.0218e-01, time/batch = 0.6705s	
4033/33150 (epoch 6.083), train_loss = 1.05013127, grad/param norm = 1.7224e-01, time/batch = 0.6742s	
4034/33150 (epoch 6.084), train_loss = 1.22712426, grad/param norm = 1.7955e-01, time/batch = 0.6713s	
4035/33150 (epoch 6.086), train_loss = 1.33141892, grad/param norm = 1.7951e-01, time/batch = 0.6694s	
4036/33150 (epoch 6.087), train_loss = 1.25192948, grad/param norm = 1.6961e-01, time/batch = 0.6665s	
4037/33150 (epoch 6.089), train_loss = 1.26498124, grad/param norm = 1.9015e-01, time/batch = 0.6824s	
4038/33150 (epoch 6.090), train_loss = 1.32218618, grad/param norm = 2.0619e-01, time/batch = 0.6722s	
4039/33150 (epoch 6.092), train_loss = 1.40520963, grad/param norm = 1.7950e-01, time/batch = 0.6673s	
4040/33150 (epoch 6.094), train_loss = 1.48153141, grad/param norm = 1.8994e-01, time/batch = 0.6713s	
4041/33150 (epoch 6.095), train_loss = 1.20336801, grad/param norm = 1.5027e-01, time/batch = 0.6703s	
4042/33150 (epoch 6.097), train_loss = 1.44167162, grad/param norm = 1.8368e-01, time/batch = 0.6668s	
4043/33150 (epoch 6.098), train_loss = 1.61873991, grad/param norm = 1.8640e-01, time/batch = 0.6709s	
4044/33150 (epoch 6.100), train_loss = 1.55434822, grad/param norm = 1.8353e-01, time/batch = 0.6723s	
4045/33150 (epoch 6.101), train_loss = 1.27476305, grad/param norm = 1.7909e-01, time/batch = 0.6644s	
4046/33150 (epoch 6.103), train_loss = 1.41202932, grad/param norm = 1.7217e-01, time/batch = 0.6672s	
4047/33150 (epoch 6.104), train_loss = 1.35114583, grad/param norm = 1.8969e-01, time/batch = 0.6669s	
4048/33150 (epoch 6.106), train_loss = 1.56805918, grad/param norm = 1.9581e-01, time/batch = 0.6647s	
4049/33150 (epoch 6.107), train_loss = 1.62885470, grad/param norm = 1.9936e-01, time/batch = 0.6724s	
4050/33150 (epoch 6.109), train_loss = 1.30098362, grad/param norm = 1.7325e-01, time/batch = 0.6750s	
4051/33150 (epoch 6.110), train_loss = 1.45206481, grad/param norm = 1.8036e-01, time/batch = 0.6740s	
4052/33150 (epoch 6.112), train_loss = 1.26726236, grad/param norm = 1.6626e-01, time/batch = 0.6662s	
4053/33150 (epoch 6.113), train_loss = 1.28748040, grad/param norm = 1.9345e-01, time/batch = 0.6667s	
4054/33150 (epoch 6.115), train_loss = 1.53788668, grad/param norm = 2.1243e-01, time/batch = 0.6680s	
4055/33150 (epoch 6.116), train_loss = 1.25754843, grad/param norm = 1.7754e-01, time/batch = 0.6722s	
4056/33150 (epoch 6.118), train_loss = 1.46610008, grad/param norm = 1.9494e-01, time/batch = 0.6675s	
4057/33150 (epoch 6.119), train_loss = 1.44897574, grad/param norm = 1.9121e-01, time/batch = 0.6675s	
4058/33150 (epoch 6.121), train_loss = 1.31365703, grad/param norm = 1.6915e-01, time/batch = 0.6695s	
4059/33150 (epoch 6.122), train_loss = 1.54881051, grad/param norm = 2.0131e-01, time/batch = 0.6693s	
4060/33150 (epoch 6.124), train_loss = 1.10173510, grad/param norm = 1.6703e-01, time/batch = 0.6686s	
4061/33150 (epoch 6.125), train_loss = 1.42044918, grad/param norm = 1.6459e-01, time/batch = 0.6681s	
4062/33150 (epoch 6.127), train_loss = 1.26668204, grad/param norm = 1.5920e-01, time/batch = 0.6659s	
4063/33150 (epoch 6.128), train_loss = 1.40610876, grad/param norm = 1.8132e-01, time/batch = 0.6681s	
4064/33150 (epoch 6.130), train_loss = 1.42941515, grad/param norm = 1.7214e-01, time/batch = 0.6672s	
4065/33150 (epoch 6.131), train_loss = 1.60037261, grad/param norm = 1.9126e-01, time/batch = 0.6667s	
4066/33150 (epoch 6.133), train_loss = 1.26513475, grad/param norm = 1.6715e-01, time/batch = 0.6671s	
4067/33150 (epoch 6.134), train_loss = 1.48159330, grad/param norm = 1.9017e-01, time/batch = 0.6669s	
4068/33150 (epoch 6.136), train_loss = 1.35957927, grad/param norm = 1.6377e-01, time/batch = 0.6687s	
4069/33150 (epoch 6.137), train_loss = 1.46450437, grad/param norm = 1.8840e-01, time/batch = 0.6678s	
4070/33150 (epoch 6.139), train_loss = 1.39781546, grad/param norm = 1.7746e-01, time/batch = 0.6661s	
4071/33150 (epoch 6.140), train_loss = 1.51511699, grad/param norm = 1.8759e-01, time/batch = 0.6682s	
4072/33150 (epoch 6.142), train_loss = 1.45954695, grad/param norm = 2.0624e-01, time/batch = 0.6670s	
4073/33150 (epoch 6.143), train_loss = 1.42649386, grad/param norm = 1.9191e-01, time/batch = 0.6657s	
4074/33150 (epoch 6.145), train_loss = 1.41031674, grad/param norm = 1.9878e-01, time/batch = 0.6650s	
4075/33150 (epoch 6.146), train_loss = 1.55732767, grad/param norm = 2.3948e-01, time/batch = 0.6690s	
4076/33150 (epoch 6.148), train_loss = 1.44602018, grad/param norm = 1.7468e-01, time/batch = 0.6677s	
4077/33150 (epoch 6.149), train_loss = 1.42693027, grad/param norm = 1.9830e-01, time/batch = 0.6684s	
4078/33150 (epoch 6.151), train_loss = 1.64167845, grad/param norm = 1.9771e-01, time/batch = 0.6731s	
4079/33150 (epoch 6.152), train_loss = 1.29786564, grad/param norm = 1.5769e-01, time/batch = 0.6715s	
4080/33150 (epoch 6.154), train_loss = 1.36334956, grad/param norm = 1.6748e-01, time/batch = 0.6812s	
4081/33150 (epoch 6.155), train_loss = 1.24109070, grad/param norm = 1.6994e-01, time/batch = 0.6819s	
4082/33150 (epoch 6.157), train_loss = 1.31677961, grad/param norm = 1.9252e-01, time/batch = 0.6695s	
4083/33150 (epoch 6.158), train_loss = 1.25104166, grad/param norm = 1.7700e-01, time/batch = 0.6726s	
4084/33150 (epoch 6.160), train_loss = 1.48896020, grad/param norm = 1.7151e-01, time/batch = 0.6664s	
4085/33150 (epoch 6.161), train_loss = 1.37952774, grad/param norm = 1.9329e-01, time/batch = 0.6653s	
4086/33150 (epoch 6.163), train_loss = 1.32017917, grad/param norm = 1.6303e-01, time/batch = 0.6655s	
4087/33150 (epoch 6.164), train_loss = 1.49692472, grad/param norm = 1.7992e-01, time/batch = 0.6641s	
4088/33150 (epoch 6.166), train_loss = 1.39851300, grad/param norm = 1.7995e-01, time/batch = 0.6675s	
4089/33150 (epoch 6.167), train_loss = 1.39159785, grad/param norm = 1.6577e-01, time/batch = 0.6708s	
4090/33150 (epoch 6.169), train_loss = 1.54457640, grad/param norm = 2.1340e-01, time/batch = 0.6717s	
4091/33150 (epoch 6.170), train_loss = 1.35438772, grad/param norm = 1.7767e-01, time/batch = 0.6724s	
4092/33150 (epoch 6.172), train_loss = 1.51062759, grad/param norm = 1.9103e-01, time/batch = 0.6694s	
4093/33150 (epoch 6.173), train_loss = 1.49488600, grad/param norm = 2.0344e-01, time/batch = 0.6685s	
4094/33150 (epoch 6.175), train_loss = 1.29454280, grad/param norm = 1.8777e-01, time/batch = 0.6659s	
4095/33150 (epoch 6.176), train_loss = 1.40051993, grad/param norm = 1.8620e-01, time/batch = 0.6657s	
4096/33150 (epoch 6.178), train_loss = 1.55762117, grad/param norm = 1.8504e-01, time/batch = 0.6695s	
4097/33150 (epoch 6.179), train_loss = 1.40989157, grad/param norm = 1.5730e-01, time/batch = 0.6738s	
4098/33150 (epoch 6.181), train_loss = 1.39988336, grad/param norm = 2.0857e-01, time/batch = 0.6671s	
4099/33150 (epoch 6.183), train_loss = 1.42475936, grad/param norm = 2.1425e-01, time/batch = 0.6697s	
4100/33150 (epoch 6.184), train_loss = 1.56099967, grad/param norm = 1.9376e-01, time/batch = 0.6678s	
4101/33150 (epoch 6.186), train_loss = 1.53457784, grad/param norm = 1.9099e-01, time/batch = 0.6704s	
4102/33150 (epoch 6.187), train_loss = 1.38438134, grad/param norm = 1.8089e-01, time/batch = 0.6706s	
4103/33150 (epoch 6.189), train_loss = 1.22555953, grad/param norm = 1.8817e-01, time/batch = 0.6704s	
4104/33150 (epoch 6.190), train_loss = 1.31807815, grad/param norm = 1.8422e-01, time/batch = 0.6674s	
4105/33150 (epoch 6.192), train_loss = 1.40383925, grad/param norm = 1.8786e-01, time/batch = 0.6683s	
4106/33150 (epoch 6.193), train_loss = 1.38428218, grad/param norm = 1.6621e-01, time/batch = 0.6694s	
4107/33150 (epoch 6.195), train_loss = 1.71669642, grad/param norm = 1.9108e-01, time/batch = 0.6672s	
4108/33150 (epoch 6.196), train_loss = 1.50845238, grad/param norm = 1.7505e-01, time/batch = 0.6701s	
4109/33150 (epoch 6.198), train_loss = 1.26749013, grad/param norm = 1.8265e-01, time/batch = 0.6685s	
4110/33150 (epoch 6.199), train_loss = 1.48139571, grad/param norm = 1.8257e-01, time/batch = 0.6665s	
4111/33150 (epoch 6.201), train_loss = 1.21996108, grad/param norm = 1.4705e-01, time/batch = 0.6678s	
4112/33150 (epoch 6.202), train_loss = 1.17351551, grad/param norm = 1.5465e-01, time/batch = 0.6682s	
4113/33150 (epoch 6.204), train_loss = 1.35777424, grad/param norm = 1.6578e-01, time/batch = 0.6734s	
4114/33150 (epoch 6.205), train_loss = 1.50378396, grad/param norm = 1.9341e-01, time/batch = 0.6873s	
4115/33150 (epoch 6.207), train_loss = 1.40184840, grad/param norm = 1.7518e-01, time/batch = 0.6948s	
4116/33150 (epoch 6.208), train_loss = 1.44998251, grad/param norm = 1.6585e-01, time/batch = 0.6923s	
4117/33150 (epoch 6.210), train_loss = 1.23714418, grad/param norm = 1.5528e-01, time/batch = 0.6699s	
4118/33150 (epoch 6.211), train_loss = 1.42462075, grad/param norm = 1.8314e-01, time/batch = 0.6719s	
4119/33150 (epoch 6.213), train_loss = 1.52350170, grad/param norm = 1.8255e-01, time/batch = 0.6683s	
4120/33150 (epoch 6.214), train_loss = 1.33413409, grad/param norm = 1.6973e-01, time/batch = 0.6652s	
4121/33150 (epoch 6.216), train_loss = 1.32766814, grad/param norm = 1.7799e-01, time/batch = 0.6868s	
4122/33150 (epoch 6.217), train_loss = 1.30805323, grad/param norm = 1.6390e-01, time/batch = 0.6728s	
4123/33150 (epoch 6.219), train_loss = 1.27185990, grad/param norm = 1.6022e-01, time/batch = 0.6774s	
4124/33150 (epoch 6.220), train_loss = 1.24155728, grad/param norm = 1.5103e-01, time/batch = 0.6850s	
4125/33150 (epoch 6.222), train_loss = 1.44950905, grad/param norm = 1.7288e-01, time/batch = 0.6758s	
4126/33150 (epoch 6.223), train_loss = 1.32911124, grad/param norm = 1.6763e-01, time/batch = 0.6747s	
4127/33150 (epoch 6.225), train_loss = 1.58388359, grad/param norm = 1.8428e-01, time/batch = 0.6662s	
4128/33150 (epoch 6.226), train_loss = 1.32552694, grad/param norm = 1.6227e-01, time/batch = 0.6633s	
4129/33150 (epoch 6.228), train_loss = 1.36357427, grad/param norm = 1.7910e-01, time/batch = 0.6676s	
4130/33150 (epoch 6.229), train_loss = 1.38000236, grad/param norm = 1.7251e-01, time/batch = 0.6646s	
4131/33150 (epoch 6.231), train_loss = 1.48804058, grad/param norm = 1.8039e-01, time/batch = 0.6711s	
4132/33150 (epoch 6.232), train_loss = 1.41102197, grad/param norm = 2.0690e-01, time/batch = 0.6698s	
4133/33150 (epoch 6.234), train_loss = 1.33636902, grad/param norm = 1.8139e-01, time/batch = 0.6671s	
4134/33150 (epoch 6.235), train_loss = 1.41182624, grad/param norm = 1.9098e-01, time/batch = 0.6712s	
4135/33150 (epoch 6.237), train_loss = 1.34695794, grad/param norm = 1.8386e-01, time/batch = 0.6731s	
4136/33150 (epoch 6.238), train_loss = 1.53397706, grad/param norm = 2.0029e-01, time/batch = 0.6736s	
4137/33150 (epoch 6.240), train_loss = 1.40017760, grad/param norm = 1.6901e-01, time/batch = 0.6692s	
4138/33150 (epoch 6.241), train_loss = 1.51413049, grad/param norm = 1.9796e-01, time/batch = 0.6707s	
4139/33150 (epoch 6.243), train_loss = 1.51922327, grad/param norm = 1.8712e-01, time/batch = 0.6704s	
4140/33150 (epoch 6.244), train_loss = 1.32555395, grad/param norm = 1.5956e-01, time/batch = 0.6674s	
4141/33150 (epoch 6.246), train_loss = 1.41101776, grad/param norm = 1.8456e-01, time/batch = 0.6687s	
4142/33150 (epoch 6.247), train_loss = 1.24569481, grad/param norm = 1.6817e-01, time/batch = 0.6674s	
4143/33150 (epoch 6.249), train_loss = 1.53766992, grad/param norm = 1.8216e-01, time/batch = 0.6697s	
4144/33150 (epoch 6.250), train_loss = 1.41506323, grad/param norm = 1.5854e-01, time/batch = 0.6684s	
4145/33150 (epoch 6.252), train_loss = 1.39120425, grad/param norm = 1.5049e-01, time/batch = 0.6677s	
4146/33150 (epoch 6.253), train_loss = 1.46522801, grad/param norm = 1.8346e-01, time/batch = 0.6678s	
4147/33150 (epoch 6.255), train_loss = 1.37136994, grad/param norm = 1.6401e-01, time/batch = 0.6683s	
4148/33150 (epoch 6.256), train_loss = 1.45760001, grad/param norm = 1.7875e-01, time/batch = 0.6685s	
4149/33150 (epoch 6.258), train_loss = 1.35106459, grad/param norm = 1.8633e-01, time/batch = 0.6684s	
4150/33150 (epoch 6.259), train_loss = 1.15905380, grad/param norm = 1.7320e-01, time/batch = 0.6689s	
4151/33150 (epoch 6.261), train_loss = 1.20480527, grad/param norm = 1.6451e-01, time/batch = 0.6694s	
4152/33150 (epoch 6.262), train_loss = 1.43056445, grad/param norm = 1.8211e-01, time/batch = 0.6718s	
4153/33150 (epoch 6.264), train_loss = 1.07579081, grad/param norm = 1.5544e-01, time/batch = 0.6721s	
4154/33150 (epoch 6.265), train_loss = 1.39611132, grad/param norm = 1.7506e-01, time/batch = 0.6667s	
4155/33150 (epoch 6.267), train_loss = 1.53369039, grad/param norm = 1.8518e-01, time/batch = 0.6684s	
4156/33150 (epoch 6.268), train_loss = 1.30258358, grad/param norm = 1.6219e-01, time/batch = 0.6694s	
4157/33150 (epoch 6.270), train_loss = 1.59373189, grad/param norm = 1.6453e-01, time/batch = 0.6765s	
4158/33150 (epoch 6.271), train_loss = 1.51696234, grad/param norm = 1.8415e-01, time/batch = 0.6892s	
4159/33150 (epoch 6.273), train_loss = 1.45408758, grad/param norm = 1.7064e-01, time/batch = 0.6891s	
4160/33150 (epoch 6.275), train_loss = 1.48738837, grad/param norm = 1.7587e-01, time/batch = 0.6885s	
4161/33150 (epoch 6.276), train_loss = 1.36418299, grad/param norm = 1.6543e-01, time/batch = 0.6917s	
4162/33150 (epoch 6.278), train_loss = 1.51137703, grad/param norm = 1.8978e-01, time/batch = 0.6883s	
4163/33150 (epoch 6.279), train_loss = 1.36360531, grad/param norm = 1.6990e-01, time/batch = 0.6892s	
4164/33150 (epoch 6.281), train_loss = 1.48382586, grad/param norm = 1.8855e-01, time/batch = 0.6891s	
4165/33150 (epoch 6.282), train_loss = 1.39287843, grad/param norm = 1.6522e-01, time/batch = 0.6771s	
4166/33150 (epoch 6.284), train_loss = 1.34952091, grad/param norm = 1.6185e-01, time/batch = 0.6753s	
4167/33150 (epoch 6.285), train_loss = 1.43118739, grad/param norm = 1.8247e-01, time/batch = 0.6899s	
4168/33150 (epoch 6.287), train_loss = 1.32332303, grad/param norm = 1.6351e-01, time/batch = 0.6880s	
4169/33150 (epoch 6.288), train_loss = 1.60509085, grad/param norm = 1.9939e-01, time/batch = 0.6860s	
4170/33150 (epoch 6.290), train_loss = 1.23559661, grad/param norm = 1.7042e-01, time/batch = 0.6694s	
4171/33150 (epoch 6.291), train_loss = 1.27700953, grad/param norm = 1.7318e-01, time/batch = 0.6818s	
4172/33150 (epoch 6.293), train_loss = 1.43753108, grad/param norm = 1.6715e-01, time/batch = 0.6661s	
4173/33150 (epoch 6.294), train_loss = 1.10833441, grad/param norm = 1.6055e-01, time/batch = 0.6727s	
4174/33150 (epoch 6.296), train_loss = 1.31791359, grad/param norm = 1.7932e-01, time/batch = 0.6646s	
4175/33150 (epoch 6.297), train_loss = 1.34883618, grad/param norm = 1.7963e-01, time/batch = 0.6643s	
4176/33150 (epoch 6.299), train_loss = 1.27794387, grad/param norm = 1.8236e-01, time/batch = 0.6684s	
4177/33150 (epoch 6.300), train_loss = 1.32734376, grad/param norm = 1.5537e-01, time/batch = 0.6690s	
4178/33150 (epoch 6.302), train_loss = 1.32204146, grad/param norm = 1.7671e-01, time/batch = 0.6649s	
4179/33150 (epoch 6.303), train_loss = 1.44859189, grad/param norm = 1.8789e-01, time/batch = 0.6690s	
4180/33150 (epoch 6.305), train_loss = 1.39793592, grad/param norm = 1.6900e-01, time/batch = 0.6657s	
4181/33150 (epoch 6.306), train_loss = 1.44600370, grad/param norm = 1.9545e-01, time/batch = 0.6647s	
4182/33150 (epoch 6.308), train_loss = 1.62307562, grad/param norm = 1.8215e-01, time/batch = 0.6700s	
4183/33150 (epoch 6.309), train_loss = 1.23445043, grad/param norm = 1.6577e-01, time/batch = 0.6668s	
4184/33150 (epoch 6.311), train_loss = 1.40609154, grad/param norm = 1.8229e-01, time/batch = 0.6644s	
4185/33150 (epoch 6.312), train_loss = 1.21228536, grad/param norm = 1.6902e-01, time/batch = 0.6649s	
4186/33150 (epoch 6.314), train_loss = 1.39658886, grad/param norm = 1.8175e-01, time/batch = 0.6877s	
4187/33150 (epoch 6.315), train_loss = 1.47339482, grad/param norm = 1.7221e-01, time/batch = 0.6688s	
4188/33150 (epoch 6.317), train_loss = 1.11667577, grad/param norm = 1.4569e-01, time/batch = 0.6712s	
4189/33150 (epoch 6.318), train_loss = 1.25259957, grad/param norm = 1.5239e-01, time/batch = 0.6723s	
4190/33150 (epoch 6.320), train_loss = 1.21971204, grad/param norm = 1.6799e-01, time/batch = 0.6693s	
4191/33150 (epoch 6.321), train_loss = 1.29643647, grad/param norm = 1.6659e-01, time/batch = 0.6692s	
4192/33150 (epoch 6.323), train_loss = 1.38072280, grad/param norm = 1.6988e-01, time/batch = 0.6680s	
4193/33150 (epoch 6.324), train_loss = 1.48780432, grad/param norm = 1.8645e-01, time/batch = 0.6681s	
4194/33150 (epoch 6.326), train_loss = 1.39425536, grad/param norm = 1.6426e-01, time/batch = 0.6755s	
4195/33150 (epoch 6.327), train_loss = 1.47756081, grad/param norm = 1.6937e-01, time/batch = 0.6791s	
4196/33150 (epoch 6.329), train_loss = 1.40523201, grad/param norm = 1.5956e-01, time/batch = 0.6678s	
4197/33150 (epoch 6.330), train_loss = 1.44812135, grad/param norm = 1.9565e-01, time/batch = 0.6682s	
4198/33150 (epoch 6.332), train_loss = 1.34259223, grad/param norm = 1.6637e-01, time/batch = 0.6682s	
4199/33150 (epoch 6.333), train_loss = 1.40003529, grad/param norm = 1.5685e-01, time/batch = 0.6655s	
4200/33150 (epoch 6.335), train_loss = 1.36117923, grad/param norm = 1.7221e-01, time/batch = 0.6671s	
4201/33150 (epoch 6.336), train_loss = 1.25260432, grad/param norm = 1.6320e-01, time/batch = 0.6683s	
4202/33150 (epoch 6.338), train_loss = 1.13435691, grad/param norm = 1.6093e-01, time/batch = 0.6776s	
4203/33150 (epoch 6.339), train_loss = 1.48626048, grad/param norm = 1.7402e-01, time/batch = 0.6875s	
4204/33150 (epoch 6.341), train_loss = 1.58476237, grad/param norm = 2.0591e-01, time/batch = 0.6854s	
4205/33150 (epoch 6.342), train_loss = 1.23115811, grad/param norm = 1.7562e-01, time/batch = 0.6669s	
4206/33150 (epoch 6.344), train_loss = 1.42650878, grad/param norm = 1.7056e-01, time/batch = 0.6697s	
4207/33150 (epoch 6.345), train_loss = 1.23350318, grad/param norm = 1.6667e-01, time/batch = 0.6752s	
4208/33150 (epoch 6.347), train_loss = 1.11460029, grad/param norm = 1.5240e-01, time/batch = 0.6693s	
4209/33150 (epoch 6.348), train_loss = 1.36266695, grad/param norm = 1.7616e-01, time/batch = 0.6667s	
4210/33150 (epoch 6.350), train_loss = 1.39889325, grad/param norm = 1.8281e-01, time/batch = 0.6710s	
4211/33150 (epoch 6.351), train_loss = 1.46487148, grad/param norm = 1.7701e-01, time/batch = 0.6711s	
4212/33150 (epoch 6.353), train_loss = 1.51460775, grad/param norm = 1.9000e-01, time/batch = 0.6992s	
4213/33150 (epoch 6.354), train_loss = 1.64318041, grad/param norm = 1.8508e-01, time/batch = 0.6867s	
4214/33150 (epoch 6.356), train_loss = 1.50030852, grad/param norm = 1.8859e-01, time/batch = 0.6685s	
4215/33150 (epoch 6.357), train_loss = 1.49352037, grad/param norm = 1.7864e-01, time/batch = 0.6717s	
4216/33150 (epoch 6.359), train_loss = 1.44056696, grad/param norm = 1.8077e-01, time/batch = 0.6850s	
4217/33150 (epoch 6.360), train_loss = 1.52448890, grad/param norm = 1.9357e-01, time/batch = 0.6720s	
4218/33150 (epoch 6.362), train_loss = 1.41962526, grad/param norm = 1.7423e-01, time/batch = 0.6698s	
4219/33150 (epoch 6.363), train_loss = 1.35401368, grad/param norm = 1.7457e-01, time/batch = 0.6736s	
4220/33150 (epoch 6.365), train_loss = 1.35223331, grad/param norm = 1.5967e-01, time/batch = 0.6683s	
4221/33150 (epoch 6.367), train_loss = 1.24550282, grad/param norm = 1.6671e-01, time/batch = 0.6728s	
4222/33150 (epoch 6.368), train_loss = 1.39055684, grad/param norm = 1.6353e-01, time/batch = 0.6689s	
4223/33150 (epoch 6.370), train_loss = 1.50124780, grad/param norm = 1.9166e-01, time/batch = 0.6699s	
4224/33150 (epoch 6.371), train_loss = 1.27887077, grad/param norm = 1.7022e-01, time/batch = 0.6676s	
4225/33150 (epoch 6.373), train_loss = 1.50083390, grad/param norm = 1.9175e-01, time/batch = 0.6690s	
4226/33150 (epoch 6.374), train_loss = 1.29653946, grad/param norm = 1.6802e-01, time/batch = 0.6651s	
4227/33150 (epoch 6.376), train_loss = 1.52512984, grad/param norm = 1.6411e-01, time/batch = 0.6675s	
4228/33150 (epoch 6.377), train_loss = 1.39318862, grad/param norm = 1.8327e-01, time/batch = 0.6659s	
4229/33150 (epoch 6.379), train_loss = 1.45976687, grad/param norm = 1.9138e-01, time/batch = 0.6648s	
4230/33150 (epoch 6.380), train_loss = 1.48896536, grad/param norm = 1.7646e-01, time/batch = 0.6652s	
4231/33150 (epoch 6.382), train_loss = 1.25591200, grad/param norm = 1.5059e-01, time/batch = 0.6657s	
4232/33150 (epoch 6.383), train_loss = 1.26408679, grad/param norm = 1.7225e-01, time/batch = 0.6769s	
4233/33150 (epoch 6.385), train_loss = 1.39217682, grad/param norm = 1.6567e-01, time/batch = 0.6736s	
4234/33150 (epoch 6.386), train_loss = 1.24136235, grad/param norm = 1.6394e-01, time/batch = 0.6723s	
4235/33150 (epoch 6.388), train_loss = 1.35514454, grad/param norm = 1.7059e-01, time/batch = 0.6770s	
4236/33150 (epoch 6.389), train_loss = 1.32114989, grad/param norm = 1.6821e-01, time/batch = 0.6722s	
4237/33150 (epoch 6.391), train_loss = 1.55675692, grad/param norm = 1.8080e-01, time/batch = 0.6780s	
4238/33150 (epoch 6.392), train_loss = 1.31127064, grad/param norm = 1.6590e-01, time/batch = 0.6799s	
4239/33150 (epoch 6.394), train_loss = 1.20193465, grad/param norm = 1.4834e-01, time/batch = 0.6811s	
4240/33150 (epoch 6.395), train_loss = 1.31241321, grad/param norm = 1.9021e-01, time/batch = 0.6790s	
4241/33150 (epoch 6.397), train_loss = 1.07088490, grad/param norm = 1.4853e-01, time/batch = 0.6839s	
4242/33150 (epoch 6.398), train_loss = 1.42074729, grad/param norm = 1.8748e-01, time/batch = 0.6765s	
4243/33150 (epoch 6.400), train_loss = 1.34150398, grad/param norm = 1.5771e-01, time/batch = 0.6795s	
4244/33150 (epoch 6.401), train_loss = 1.17914457, grad/param norm = 1.5336e-01, time/batch = 0.6747s	
4245/33150 (epoch 6.403), train_loss = 1.25460506, grad/param norm = 1.6176e-01, time/batch = 0.6735s	
4246/33150 (epoch 6.404), train_loss = 1.30587243, grad/param norm = 1.5995e-01, time/batch = 0.6624s	
4247/33150 (epoch 6.406), train_loss = 1.21744352, grad/param norm = 1.4304e-01, time/batch = 0.6624s	
4248/33150 (epoch 6.407), train_loss = 1.22066595, grad/param norm = 1.4800e-01, time/batch = 0.6621s	
4249/33150 (epoch 6.409), train_loss = 1.14082625, grad/param norm = 1.6274e-01, time/batch = 0.6651s	
4250/33150 (epoch 6.410), train_loss = 1.43828741, grad/param norm = 1.9667e-01, time/batch = 0.6600s	
4251/33150 (epoch 6.412), train_loss = 1.45850444, grad/param norm = 1.8367e-01, time/batch = 0.6664s	
4252/33150 (epoch 6.413), train_loss = 1.33098260, grad/param norm = 1.7438e-01, time/batch = 0.6636s	
4253/33150 (epoch 6.415), train_loss = 1.50195887, grad/param norm = 1.6913e-01, time/batch = 0.6609s	
4254/33150 (epoch 6.416), train_loss = 1.32912871, grad/param norm = 1.6223e-01, time/batch = 0.6665s	
4255/33150 (epoch 6.418), train_loss = 1.61482435, grad/param norm = 2.2030e-01, time/batch = 0.6656s	
4256/33150 (epoch 6.419), train_loss = 1.26905366, grad/param norm = 1.7551e-01, time/batch = 0.6652s	
4257/33150 (epoch 6.421), train_loss = 1.40841194, grad/param norm = 1.7400e-01, time/batch = 0.6659s	
4258/33150 (epoch 6.422), train_loss = 1.25993317, grad/param norm = 1.6518e-01, time/batch = 0.6680s	
4259/33150 (epoch 6.424), train_loss = 1.35427930, grad/param norm = 1.9899e-01, time/batch = 0.6622s	
4260/33150 (epoch 6.425), train_loss = 1.29660479, grad/param norm = 1.8716e-01, time/batch = 0.6671s	
4261/33150 (epoch 6.427), train_loss = 1.29370441, grad/param norm = 1.6378e-01, time/batch = 0.6701s	
4262/33150 (epoch 6.428), train_loss = 1.36156404, grad/param norm = 1.6565e-01, time/batch = 0.6765s	
4263/33150 (epoch 6.430), train_loss = 1.41103374, grad/param norm = 1.7897e-01, time/batch = 0.6841s	
4264/33150 (epoch 6.431), train_loss = 1.44772604, grad/param norm = 1.7479e-01, time/batch = 0.6681s	
4265/33150 (epoch 6.433), train_loss = 1.38853896, grad/param norm = 1.5451e-01, time/batch = 0.6789s	
4266/33150 (epoch 6.434), train_loss = 1.22054842, grad/param norm = 1.8266e-01, time/batch = 0.6675s	
4267/33150 (epoch 6.436), train_loss = 1.17615085, grad/param norm = 1.6977e-01, time/batch = 0.6652s	
4268/33150 (epoch 6.437), train_loss = 1.40800607, grad/param norm = 2.0228e-01, time/batch = 0.6657s	
4269/33150 (epoch 6.439), train_loss = 1.47958758, grad/param norm = 1.8449e-01, time/batch = 0.6690s	
4270/33150 (epoch 6.440), train_loss = 1.49469045, grad/param norm = 2.0224e-01, time/batch = 0.6669s	
4271/33150 (epoch 6.442), train_loss = 1.19918877, grad/param norm = 1.7315e-01, time/batch = 0.6672s	
4272/33150 (epoch 6.443), train_loss = 1.45185981, grad/param norm = 1.7949e-01, time/batch = 0.6650s	
4273/33150 (epoch 6.445), train_loss = 1.40116099, grad/param norm = 1.7932e-01, time/batch = 0.6629s	
4274/33150 (epoch 6.446), train_loss = 1.44732672, grad/param norm = 2.1656e-01, time/batch = 0.6612s	
4275/33150 (epoch 6.448), train_loss = 1.40468480, grad/param norm = 1.7584e-01, time/batch = 0.6677s	
4276/33150 (epoch 6.449), train_loss = 1.30770785, grad/param norm = 1.5650e-01, time/batch = 0.6643s	
4277/33150 (epoch 6.451), train_loss = 1.45845812, grad/param norm = 1.9828e-01, time/batch = 0.6673s	
4278/33150 (epoch 6.452), train_loss = 1.61775875, grad/param norm = 1.7585e-01, time/batch = 0.6687s	
4279/33150 (epoch 6.454), train_loss = 1.35033314, grad/param norm = 1.8010e-01, time/batch = 0.6663s	
4280/33150 (epoch 6.456), train_loss = 1.10929245, grad/param norm = 1.6243e-01, time/batch = 0.6709s	
4281/33150 (epoch 6.457), train_loss = 1.38691268, grad/param norm = 1.7261e-01, time/batch = 0.6720s	
4282/33150 (epoch 6.459), train_loss = 1.56174581, grad/param norm = 1.9649e-01, time/batch = 0.6718s	
4283/33150 (epoch 6.460), train_loss = 1.38929111, grad/param norm = 1.5508e-01, time/batch = 0.6718s	
4284/33150 (epoch 6.462), train_loss = 1.50402674, grad/param norm = 2.1223e-01, time/batch = 0.6705s	
4285/33150 (epoch 6.463), train_loss = 1.70134206, grad/param norm = 2.1568e-01, time/batch = 0.6794s	
4286/33150 (epoch 6.465), train_loss = 1.25137907, grad/param norm = 1.5742e-01, time/batch = 0.6759s	
4287/33150 (epoch 6.466), train_loss = 1.33545263, grad/param norm = 1.7438e-01, time/batch = 0.6703s	
4288/33150 (epoch 6.468), train_loss = 1.68192551, grad/param norm = 1.9358e-01, time/batch = 0.6850s	
4289/33150 (epoch 6.469), train_loss = 1.46144053, grad/param norm = 1.8647e-01, time/batch = 0.6770s	
4290/33150 (epoch 6.471), train_loss = 1.32566583, grad/param norm = 1.7910e-01, time/batch = 0.6753s	
4291/33150 (epoch 6.472), train_loss = 1.29640894, grad/param norm = 1.6651e-01, time/batch = 0.6861s	
4292/33150 (epoch 6.474), train_loss = 1.44463927, grad/param norm = 1.9420e-01, time/batch = 0.6878s	
4293/33150 (epoch 6.475), train_loss = 1.65866895, grad/param norm = 1.8559e-01, time/batch = 0.6807s	
4294/33150 (epoch 6.477), train_loss = 1.44206521, grad/param norm = 1.9297e-01, time/batch = 0.6854s	
4295/33150 (epoch 6.478), train_loss = 1.46600894, grad/param norm = 1.7207e-01, time/batch = 0.6803s	
4296/33150 (epoch 6.480), train_loss = 1.27212967, grad/param norm = 1.6087e-01, time/batch = 0.6741s	
4297/33150 (epoch 6.481), train_loss = 1.17035362, grad/param norm = 1.5690e-01, time/batch = 0.6678s	
4298/33150 (epoch 6.483), train_loss = 1.28309509, grad/param norm = 1.9024e-01, time/batch = 0.6676s	
4299/33150 (epoch 6.484), train_loss = 1.27306054, grad/param norm = 1.6328e-01, time/batch = 0.6694s	
4300/33150 (epoch 6.486), train_loss = 1.39385822, grad/param norm = 1.7819e-01, time/batch = 0.6657s	
4301/33150 (epoch 6.487), train_loss = 1.46000291, grad/param norm = 1.7719e-01, time/batch = 0.6724s	
4302/33150 (epoch 6.489), train_loss = 1.35818151, grad/param norm = 1.7865e-01, time/batch = 0.6694s	
4303/33150 (epoch 6.490), train_loss = 1.20697439, grad/param norm = 1.5483e-01, time/batch = 0.6648s	
4304/33150 (epoch 6.492), train_loss = 1.33129684, grad/param norm = 1.9578e-01, time/batch = 0.6663s	
4305/33150 (epoch 6.493), train_loss = 1.49037759, grad/param norm = 1.8227e-01, time/batch = 0.6643s	
4306/33150 (epoch 6.495), train_loss = 1.46380249, grad/param norm = 1.6501e-01, time/batch = 0.6732s	
4307/33150 (epoch 6.496), train_loss = 1.27144760, grad/param norm = 1.8506e-01, time/batch = 0.6742s	
4308/33150 (epoch 6.498), train_loss = 1.50638136, grad/param norm = 1.9655e-01, time/batch = 0.6789s	
4309/33150 (epoch 6.499), train_loss = 1.58092913, grad/param norm = 1.9019e-01, time/batch = 0.6818s	
4310/33150 (epoch 6.501), train_loss = 1.41949125, grad/param norm = 1.6211e-01, time/batch = 0.6706s	
4311/33150 (epoch 6.502), train_loss = 1.56531637, grad/param norm = 1.9901e-01, time/batch = 0.6697s	
4312/33150 (epoch 6.504), train_loss = 1.46590298, grad/param norm = 1.8369e-01, time/batch = 0.6683s	
4313/33150 (epoch 6.505), train_loss = 1.65909960, grad/param norm = 2.0545e-01, time/batch = 0.6740s	
4314/33150 (epoch 6.507), train_loss = 1.31153746, grad/param norm = 1.9293e-01, time/batch = 0.6668s	
4315/33150 (epoch 6.508), train_loss = 1.28656628, grad/param norm = 1.6933e-01, time/batch = 0.6643s	
4316/33150 (epoch 6.510), train_loss = 1.36332706, grad/param norm = 1.6111e-01, time/batch = 0.6657s	
4317/33150 (epoch 6.511), train_loss = 1.61603578, grad/param norm = 1.9453e-01, time/batch = 0.6755s	
4318/33150 (epoch 6.513), train_loss = 1.45367391, grad/param norm = 1.8192e-01, time/batch = 0.6656s	
4319/33150 (epoch 6.514), train_loss = 1.16423351, grad/param norm = 1.7070e-01, time/batch = 0.6658s	
4320/33150 (epoch 6.516), train_loss = 1.53841769, grad/param norm = 2.1214e-01, time/batch = 0.6680s	
4321/33150 (epoch 6.517), train_loss = 1.51900367, grad/param norm = 1.7032e-01, time/batch = 0.6714s	
4322/33150 (epoch 6.519), train_loss = 1.33107478, grad/param norm = 1.6980e-01, time/batch = 0.6798s	
4323/33150 (epoch 6.520), train_loss = 1.40950087, grad/param norm = 1.6624e-01, time/batch = 0.6844s	
4324/33150 (epoch 6.522), train_loss = 1.57488667, grad/param norm = 2.0273e-01, time/batch = 0.6667s	
4325/33150 (epoch 6.523), train_loss = 1.26604792, grad/param norm = 1.7749e-01, time/batch = 0.6674s	
4326/33150 (epoch 6.525), train_loss = 1.39515131, grad/param norm = 1.5829e-01, time/batch = 0.6665s	
4327/33150 (epoch 6.526), train_loss = 1.24914933, grad/param norm = 1.5850e-01, time/batch = 0.6658s	
4328/33150 (epoch 6.528), train_loss = 1.44014628, grad/param norm = 1.9462e-01, time/batch = 0.6640s	
4329/33150 (epoch 6.529), train_loss = 1.45476176, grad/param norm = 1.6619e-01, time/batch = 0.6660s	
4330/33150 (epoch 6.531), train_loss = 1.21774966, grad/param norm = 1.6848e-01, time/batch = 0.6630s	
4331/33150 (epoch 6.532), train_loss = 1.42152245, grad/param norm = 1.8011e-01, time/batch = 0.6690s	
4332/33150 (epoch 6.534), train_loss = 1.28134118, grad/param norm = 1.5618e-01, time/batch = 0.6711s	
4333/33150 (epoch 6.535), train_loss = 1.29099690, grad/param norm = 1.8244e-01, time/batch = 0.6687s	
4334/33150 (epoch 6.537), train_loss = 1.55234563, grad/param norm = 1.8213e-01, time/batch = 0.6709s	
4335/33150 (epoch 6.538), train_loss = 1.34396480, grad/param norm = 1.7622e-01, time/batch = 0.6730s	
4336/33150 (epoch 6.540), train_loss = 1.17996883, grad/param norm = 1.7068e-01, time/batch = 0.6713s	
4337/33150 (epoch 6.541), train_loss = 1.43270904, grad/param norm = 1.8354e-01, time/batch = 0.6684s	
4338/33150 (epoch 6.543), train_loss = 1.42432597, grad/param norm = 1.7951e-01, time/batch = 0.6667s	
4339/33150 (epoch 6.544), train_loss = 1.37600937, grad/param norm = 1.6240e-01, time/batch = 0.6632s	
4340/33150 (epoch 6.546), train_loss = 1.60602122, grad/param norm = 1.9589e-01, time/batch = 0.6677s	
4341/33150 (epoch 6.548), train_loss = 1.45542578, grad/param norm = 1.8379e-01, time/batch = 0.6681s	
4342/33150 (epoch 6.549), train_loss = 1.39845415, grad/param norm = 1.8567e-01, time/batch = 0.6662s	
4343/33150 (epoch 6.551), train_loss = 1.27473567, grad/param norm = 1.7798e-01, time/batch = 0.6682s	
4344/33150 (epoch 6.552), train_loss = 1.16094197, grad/param norm = 1.4603e-01, time/batch = 0.6703s	
4345/33150 (epoch 6.554), train_loss = 1.39426864, grad/param norm = 1.7215e-01, time/batch = 0.6702s	
4346/33150 (epoch 6.555), train_loss = 1.62239434, grad/param norm = 2.4137e-01, time/batch = 0.6708s	
4347/33150 (epoch 6.557), train_loss = 1.19886020, grad/param norm = 1.6712e-01, time/batch = 0.6728s	
4348/33150 (epoch 6.558), train_loss = 1.50814248, grad/param norm = 1.9778e-01, time/batch = 0.6672s	
4349/33150 (epoch 6.560), train_loss = 1.34820901, grad/param norm = 1.7762e-01, time/batch = 0.6669s	
4350/33150 (epoch 6.561), train_loss = 1.17929265, grad/param norm = 1.6111e-01, time/batch = 0.6647s	
4351/33150 (epoch 6.563), train_loss = 1.51355385, grad/param norm = 2.1989e-01, time/batch = 0.6705s	
4352/33150 (epoch 6.564), train_loss = 1.59783862, grad/param norm = 1.8070e-01, time/batch = 0.6648s	
4353/33150 (epoch 6.566), train_loss = 1.33191663, grad/param norm = 1.7239e-01, time/batch = 0.6656s	
4354/33150 (epoch 6.567), train_loss = 1.27362980, grad/param norm = 1.6965e-01, time/batch = 0.6640s	
4355/33150 (epoch 6.569), train_loss = 1.36837945, grad/param norm = 1.6173e-01, time/batch = 0.6665s	
4356/33150 (epoch 6.570), train_loss = 1.35882856, grad/param norm = 1.6233e-01, time/batch = 0.6665s	
4357/33150 (epoch 6.572), train_loss = 1.29672698, grad/param norm = 1.5918e-01, time/batch = 0.6639s	
4358/33150 (epoch 6.573), train_loss = 1.09892100, grad/param norm = 1.4336e-01, time/batch = 0.6657s	
4359/33150 (epoch 6.575), train_loss = 1.42413951, grad/param norm = 1.7264e-01, time/batch = 0.6663s	
4360/33150 (epoch 6.576), train_loss = 1.14480697, grad/param norm = 1.4027e-01, time/batch = 0.6648s	
4361/33150 (epoch 6.578), train_loss = 1.33720670, grad/param norm = 1.4326e-01, time/batch = 0.6683s	
4362/33150 (epoch 6.579), train_loss = 1.22734642, grad/param norm = 1.5377e-01, time/batch = 0.6677s	
4363/33150 (epoch 6.581), train_loss = 1.21431551, grad/param norm = 1.7394e-01, time/batch = 0.6666s	
4364/33150 (epoch 6.582), train_loss = 1.38375844, grad/param norm = 1.6185e-01, time/batch = 0.6654s	
4365/33150 (epoch 6.584), train_loss = 1.43376758, grad/param norm = 1.7154e-01, time/batch = 0.6733s	
4366/33150 (epoch 6.585), train_loss = 1.37750568, grad/param norm = 1.6635e-01, time/batch = 0.6726s	
4367/33150 (epoch 6.587), train_loss = 1.43743165, grad/param norm = 1.7342e-01, time/batch = 0.6699s	
4368/33150 (epoch 6.588), train_loss = 1.23920975, grad/param norm = 1.6748e-01, time/batch = 0.6714s	
4369/33150 (epoch 6.590), train_loss = 1.39402239, grad/param norm = 1.8912e-01, time/batch = 0.6689s	
4370/33150 (epoch 6.591), train_loss = 1.39447940, grad/param norm = 1.6399e-01, time/batch = 0.6695s	
4371/33150 (epoch 6.593), train_loss = 1.46482053, grad/param norm = 1.8633e-01, time/batch = 0.6723s	
4372/33150 (epoch 6.594), train_loss = 1.40352086, grad/param norm = 1.8397e-01, time/batch = 0.6699s	
4373/33150 (epoch 6.596), train_loss = 1.22551210, grad/param norm = 1.6197e-01, time/batch = 0.6748s	
4374/33150 (epoch 6.597), train_loss = 1.30895077, grad/param norm = 1.9401e-01, time/batch = 0.6719s	
4375/33150 (epoch 6.599), train_loss = 1.58424705, grad/param norm = 1.8048e-01, time/batch = 0.6706s	
4376/33150 (epoch 6.600), train_loss = 1.43561994, grad/param norm = 2.0144e-01, time/batch = 0.6691s	
4377/33150 (epoch 6.602), train_loss = 1.26534504, grad/param norm = 1.6794e-01, time/batch = 0.6707s	
4378/33150 (epoch 6.603), train_loss = 1.38352205, grad/param norm = 1.8921e-01, time/batch = 0.6712s	
4379/33150 (epoch 6.605), train_loss = 1.25242954, grad/param norm = 1.5884e-01, time/batch = 0.6702s	
4380/33150 (epoch 6.606), train_loss = 1.41483218, grad/param norm = 1.9996e-01, time/batch = 0.6782s	
4381/33150 (epoch 6.608), train_loss = 1.41274425, grad/param norm = 1.7792e-01, time/batch = 0.6901s	
4382/33150 (epoch 6.609), train_loss = 1.36674621, grad/param norm = 1.9180e-01, time/batch = 0.6897s	
4383/33150 (epoch 6.611), train_loss = 1.15756102, grad/param norm = 1.7014e-01, time/batch = 0.6899s	
4384/33150 (epoch 6.612), train_loss = 1.35262812, grad/param norm = 1.8415e-01, time/batch = 0.6876s	
4385/33150 (epoch 6.614), train_loss = 1.16216920, grad/param norm = 1.5914e-01, time/batch = 0.6766s	
4386/33150 (epoch 6.615), train_loss = 1.20050870, grad/param norm = 1.5464e-01, time/batch = 0.6790s	
4387/33150 (epoch 6.617), train_loss = 1.30633330, grad/param norm = 1.7090e-01, time/batch = 0.6844s	
4388/33150 (epoch 6.618), train_loss = 1.32929431, grad/param norm = 1.8008e-01, time/batch = 0.6904s	
4389/33150 (epoch 6.620), train_loss = 1.28197789, grad/param norm = 1.7843e-01, time/batch = 0.6683s	
4390/33150 (epoch 6.621), train_loss = 1.27455710, grad/param norm = 1.6493e-01, time/batch = 0.6642s	
4391/33150 (epoch 6.623), train_loss = 1.39534310, grad/param norm = 1.7538e-01, time/batch = 0.6689s	
4392/33150 (epoch 6.624), train_loss = 1.31552062, grad/param norm = 1.9426e-01, time/batch = 0.6716s	
4393/33150 (epoch 6.626), train_loss = 1.22919816, grad/param norm = 1.6598e-01, time/batch = 0.6717s	
4394/33150 (epoch 6.627), train_loss = 1.20125422, grad/param norm = 1.7928e-01, time/batch = 0.6698s	
4395/33150 (epoch 6.629), train_loss = 1.19230372, grad/param norm = 1.5378e-01, time/batch = 0.6747s	
4396/33150 (epoch 6.630), train_loss = 1.22473700, grad/param norm = 1.5095e-01, time/batch = 0.6677s	
4397/33150 (epoch 6.632), train_loss = 1.16018660, grad/param norm = 1.6179e-01, time/batch = 0.6653s	
4398/33150 (epoch 6.633), train_loss = 1.19690769, grad/param norm = 1.8690e-01, time/batch = 0.6666s	
4399/33150 (epoch 6.635), train_loss = 1.55871107, grad/param norm = 1.7703e-01, time/batch = 0.6710s	
4400/33150 (epoch 6.637), train_loss = 1.14206336, grad/param norm = 1.6251e-01, time/batch = 0.6684s	
4401/33150 (epoch 6.638), train_loss = 1.28523194, grad/param norm = 1.6552e-01, time/batch = 0.6705s	
4402/33150 (epoch 6.640), train_loss = 1.47305803, grad/param norm = 1.8441e-01, time/batch = 0.6801s	
4403/33150 (epoch 6.641), train_loss = 1.24539373, grad/param norm = 1.6958e-01, time/batch = 0.6821s	
4404/33150 (epoch 6.643), train_loss = 1.25639738, grad/param norm = 1.6211e-01, time/batch = 0.6691s	
4405/33150 (epoch 6.644), train_loss = 1.44496060, grad/param norm = 1.6097e-01, time/batch = 0.6751s	
4406/33150 (epoch 6.646), train_loss = 1.25672543, grad/param norm = 1.6851e-01, time/batch = 0.6673s	
4407/33150 (epoch 6.647), train_loss = 1.66847982, grad/param norm = 1.9095e-01, time/batch = 0.6657s	
4408/33150 (epoch 6.649), train_loss = 1.45317877, grad/param norm = 1.9264e-01, time/batch = 0.6683s	
4409/33150 (epoch 6.650), train_loss = 1.20173585, grad/param norm = 1.6033e-01, time/batch = 0.6736s	
4410/33150 (epoch 6.652), train_loss = 1.42101986, grad/param norm = 1.8652e-01, time/batch = 0.6755s	
4411/33150 (epoch 6.653), train_loss = 1.31404803, grad/param norm = 1.6537e-01, time/batch = 0.6709s	
4412/33150 (epoch 6.655), train_loss = 1.41133155, grad/param norm = 1.9123e-01, time/batch = 0.6707s	
4413/33150 (epoch 6.656), train_loss = 1.29364168, grad/param norm = 1.5334e-01, time/batch = 0.6776s	
4414/33150 (epoch 6.658), train_loss = 1.39276297, grad/param norm = 2.1067e-01, time/batch = 0.6776s	
4415/33150 (epoch 6.659), train_loss = 1.71327027, grad/param norm = 2.4799e-01, time/batch = 0.6754s	
4416/33150 (epoch 6.661), train_loss = 1.31802745, grad/param norm = 1.6333e-01, time/batch = 0.6679s	
4417/33150 (epoch 6.662), train_loss = 1.18418383, grad/param norm = 2.0180e-01, time/batch = 0.6686s	
4418/33150 (epoch 6.664), train_loss = 1.44910529, grad/param norm = 1.7502e-01, time/batch = 0.6774s	
4419/33150 (epoch 6.665), train_loss = 1.38985112, grad/param norm = 1.7779e-01, time/batch = 0.6863s	
4420/33150 (epoch 6.667), train_loss = 1.52892874, grad/param norm = 1.8192e-01, time/batch = 0.6689s	
4421/33150 (epoch 6.668), train_loss = 1.41440145, grad/param norm = 1.7429e-01, time/batch = 0.6865s	
4422/33150 (epoch 6.670), train_loss = 1.27764034, grad/param norm = 1.4681e-01, time/batch = 0.6883s	
4423/33150 (epoch 6.671), train_loss = 1.28640630, grad/param norm = 1.6790e-01, time/batch = 0.6816s	
4424/33150 (epoch 6.673), train_loss = 1.41186105, grad/param norm = 1.5715e-01, time/batch = 0.6848s	
4425/33150 (epoch 6.674), train_loss = 1.35567362, grad/param norm = 1.7355e-01, time/batch = 0.6693s	
4426/33150 (epoch 6.676), train_loss = 1.30252629, grad/param norm = 1.7095e-01, time/batch = 0.6690s	
4427/33150 (epoch 6.677), train_loss = 1.66114109, grad/param norm = 1.8408e-01, time/batch = 0.6650s	
4428/33150 (epoch 6.679), train_loss = 1.20924398, grad/param norm = 1.5854e-01, time/batch = 0.6622s	
4429/33150 (epoch 6.680), train_loss = 1.46647174, grad/param norm = 1.7932e-01, time/batch = 0.6664s	
4430/33150 (epoch 6.682), train_loss = 1.22530417, grad/param norm = 1.5939e-01, time/batch = 0.6730s	
4431/33150 (epoch 6.683), train_loss = 1.16381652, grad/param norm = 1.6223e-01, time/batch = 0.6723s	
4432/33150 (epoch 6.685), train_loss = 1.39277012, grad/param norm = 1.7228e-01, time/batch = 0.6697s	
4433/33150 (epoch 6.686), train_loss = 1.14096646, grad/param norm = 1.4834e-01, time/batch = 0.6694s	
4434/33150 (epoch 6.688), train_loss = 1.29219261, grad/param norm = 1.6816e-01, time/batch = 0.6671s	
4435/33150 (epoch 6.689), train_loss = 1.21906975, grad/param norm = 1.6147e-01, time/batch = 0.6677s	
4436/33150 (epoch 6.691), train_loss = 1.12137574, grad/param norm = 1.6344e-01, time/batch = 0.6711s	
4437/33150 (epoch 6.692), train_loss = 1.25830807, grad/param norm = 1.8009e-01, time/batch = 0.6715s	
4438/33150 (epoch 6.694), train_loss = 1.05183624, grad/param norm = 1.3570e-01, time/batch = 0.6687s	
4439/33150 (epoch 6.695), train_loss = 1.27132305, grad/param norm = 1.6587e-01, time/batch = 0.6681s	
4440/33150 (epoch 6.697), train_loss = 1.14620858, grad/param norm = 1.5346e-01, time/batch = 0.6687s	
4441/33150 (epoch 6.698), train_loss = 1.43153890, grad/param norm = 1.7519e-01, time/batch = 0.6681s	
4442/33150 (epoch 6.700), train_loss = 1.04523214, grad/param norm = 1.5033e-01, time/batch = 0.6700s	
4443/33150 (epoch 6.701), train_loss = 1.21672740, grad/param norm = 1.5764e-01, time/batch = 0.6671s	
4444/33150 (epoch 6.703), train_loss = 1.35253893, grad/param norm = 1.7710e-01, time/batch = 0.6728s	
4445/33150 (epoch 6.704), train_loss = 1.12472517, grad/param norm = 1.5352e-01, time/batch = 0.6677s	
4446/33150 (epoch 6.706), train_loss = 1.27664627, grad/param norm = 1.5093e-01, time/batch = 0.6677s	
4447/33150 (epoch 6.707), train_loss = 1.31099086, grad/param norm = 1.7758e-01, time/batch = 0.6695s	
4448/33150 (epoch 6.709), train_loss = 1.34365601, grad/param norm = 1.5277e-01, time/batch = 0.6668s	
4449/33150 (epoch 6.710), train_loss = 1.43959049, grad/param norm = 1.9587e-01, time/batch = 0.6679s	
4450/33150 (epoch 6.712), train_loss = 1.44987175, grad/param norm = 1.8684e-01, time/batch = 0.6692s	
4451/33150 (epoch 6.713), train_loss = 1.36997760, grad/param norm = 1.7051e-01, time/batch = 0.6709s	
4452/33150 (epoch 6.715), train_loss = 1.25279704, grad/param norm = 1.4994e-01, time/batch = 0.6706s	
4453/33150 (epoch 6.716), train_loss = 1.37441170, grad/param norm = 1.6837e-01, time/batch = 0.6719s	
4454/33150 (epoch 6.718), train_loss = 1.35031742, grad/param norm = 1.5969e-01, time/batch = 0.6687s	
4455/33150 (epoch 6.719), train_loss = 1.46337928, grad/param norm = 1.9240e-01, time/batch = 0.6739s	
4456/33150 (epoch 6.721), train_loss = 1.34711027, grad/param norm = 1.9894e-01, time/batch = 0.6701s	
4457/33150 (epoch 6.722), train_loss = 1.34849597, grad/param norm = 1.7613e-01, time/batch = 0.6707s	
4458/33150 (epoch 6.724), train_loss = 1.28817960, grad/param norm = 1.7111e-01, time/batch = 0.6714s	
4459/33150 (epoch 6.725), train_loss = 1.57279568, grad/param norm = 2.0461e-01, time/batch = 0.6703s	
4460/33150 (epoch 6.727), train_loss = 1.41083797, grad/param norm = 2.1483e-01, time/batch = 0.6681s	
4461/33150 (epoch 6.729), train_loss = 1.37518615, grad/param norm = 1.6951e-01, time/batch = 0.6796s	
4462/33150 (epoch 6.730), train_loss = 1.35000158, grad/param norm = 1.7105e-01, time/batch = 0.6729s	
4463/33150 (epoch 6.732), train_loss = 1.43160457, grad/param norm = 1.6586e-01, time/batch = 0.6725s	
4464/33150 (epoch 6.733), train_loss = 1.10370567, grad/param norm = 1.3679e-01, time/batch = 0.6672s	
4465/33150 (epoch 6.735), train_loss = 1.29776007, grad/param norm = 1.5413e-01, time/batch = 0.6668s	
4466/33150 (epoch 6.736), train_loss = 1.22732369, grad/param norm = 1.6862e-01, time/batch = 0.6660s	
4467/33150 (epoch 6.738), train_loss = 1.43442362, grad/param norm = 1.7979e-01, time/batch = 0.6675s	
4468/33150 (epoch 6.739), train_loss = 1.50962614, grad/param norm = 2.0236e-01, time/batch = 0.6674s	
4469/33150 (epoch 6.741), train_loss = 1.49419317, grad/param norm = 1.8908e-01, time/batch = 0.6804s	
4470/33150 (epoch 6.742), train_loss = 1.31742698, grad/param norm = 1.7711e-01, time/batch = 0.6875s	
4471/33150 (epoch 6.744), train_loss = 1.47286558, grad/param norm = 1.7863e-01, time/batch = 0.6833s	
4472/33150 (epoch 6.745), train_loss = 1.28528474, grad/param norm = 1.5771e-01, time/batch = 0.6708s	
4473/33150 (epoch 6.747), train_loss = 1.15875596, grad/param norm = 1.5711e-01, time/batch = 0.6730s	
4474/33150 (epoch 6.748), train_loss = 1.27496952, grad/param norm = 1.5879e-01, time/batch = 0.6690s	
4475/33150 (epoch 6.750), train_loss = 1.41478271, grad/param norm = 1.8455e-01, time/batch = 0.6745s	
4476/33150 (epoch 6.751), train_loss = 1.34658629, grad/param norm = 1.7261e-01, time/batch = 0.6745s	
4477/33150 (epoch 6.753), train_loss = 1.16753196, grad/param norm = 1.8173e-01, time/batch = 0.6713s	
4478/33150 (epoch 6.754), train_loss = 1.61374201, grad/param norm = 1.9359e-01, time/batch = 0.6704s	
4479/33150 (epoch 6.756), train_loss = 1.36599237, grad/param norm = 1.8643e-01, time/batch = 0.6700s	
4480/33150 (epoch 6.757), train_loss = 1.38299051, grad/param norm = 1.6999e-01, time/batch = 0.6661s	
4481/33150 (epoch 6.759), train_loss = 1.57448399, grad/param norm = 1.7791e-01, time/batch = 0.6674s	
4482/33150 (epoch 6.760), train_loss = 1.38777833, grad/param norm = 1.6780e-01, time/batch = 0.6727s	
4483/33150 (epoch 6.762), train_loss = 1.40676228, grad/param norm = 1.7815e-01, time/batch = 0.6673s	
4484/33150 (epoch 6.763), train_loss = 1.29688443, grad/param norm = 1.6232e-01, time/batch = 0.6734s	
4485/33150 (epoch 6.765), train_loss = 1.29504216, grad/param norm = 1.6234e-01, time/batch = 0.6706s	
4486/33150 (epoch 6.766), train_loss = 1.22462410, grad/param norm = 1.4543e-01, time/batch = 0.6708s	
4487/33150 (epoch 6.768), train_loss = 1.26653438, grad/param norm = 1.6645e-01, time/batch = 0.6801s	
4488/33150 (epoch 6.769), train_loss = 1.33560163, grad/param norm = 1.7761e-01, time/batch = 0.6713s	
4489/33150 (epoch 6.771), train_loss = 1.36435091, grad/param norm = 1.7303e-01, time/batch = 0.6792s	
4490/33150 (epoch 6.772), train_loss = 1.43145468, grad/param norm = 2.0210e-01, time/batch = 0.6848s	
4491/33150 (epoch 6.774), train_loss = 1.51732588, grad/param norm = 1.7862e-01, time/batch = 0.6829s	
4492/33150 (epoch 6.775), train_loss = 1.39944144, grad/param norm = 1.9579e-01, time/batch = 0.6681s	
4493/33150 (epoch 6.777), train_loss = 1.45914239, grad/param norm = 1.8088e-01, time/batch = 0.6731s	
4494/33150 (epoch 6.778), train_loss = 1.34606757, grad/param norm = 1.4968e-01, time/batch = 0.6650s	
4495/33150 (epoch 6.780), train_loss = 1.22389511, grad/param norm = 1.6367e-01, time/batch = 0.6653s	
4496/33150 (epoch 6.781), train_loss = 1.31479470, grad/param norm = 1.6365e-01, time/batch = 0.6657s	
4497/33150 (epoch 6.783), train_loss = 1.31670578, grad/param norm = 1.5086e-01, time/batch = 0.6693s	
4498/33150 (epoch 6.784), train_loss = 1.27564476, grad/param norm = 1.6233e-01, time/batch = 0.6682s	
4499/33150 (epoch 6.786), train_loss = 1.30785224, grad/param norm = 1.5426e-01, time/batch = 0.6661s	
4500/33150 (epoch 6.787), train_loss = 1.31276219, grad/param norm = 1.6767e-01, time/batch = 0.6649s	
4501/33150 (epoch 6.789), train_loss = 1.16270397, grad/param norm = 1.4482e-01, time/batch = 0.6681s	
4502/33150 (epoch 6.790), train_loss = 1.12710152, grad/param norm = 1.6670e-01, time/batch = 0.6663s	
4503/33150 (epoch 6.792), train_loss = 1.44688358, grad/param norm = 1.9718e-01, time/batch = 0.6663s	
4504/33150 (epoch 6.793), train_loss = 1.30832225, grad/param norm = 1.7062e-01, time/batch = 0.6699s	
4505/33150 (epoch 6.795), train_loss = 1.28463981, grad/param norm = 1.7804e-01, time/batch = 0.6671s	
4506/33150 (epoch 6.796), train_loss = 1.21803738, grad/param norm = 1.5672e-01, time/batch = 0.6675s	
4507/33150 (epoch 6.798), train_loss = 1.27715988, grad/param norm = 1.5455e-01, time/batch = 0.6656s	
4508/33150 (epoch 6.799), train_loss = 1.16718360, grad/param norm = 1.7359e-01, time/batch = 0.6640s	
4509/33150 (epoch 6.801), train_loss = 1.32764311, grad/param norm = 1.5756e-01, time/batch = 0.6711s	
4510/33150 (epoch 6.802), train_loss = 1.25305516, grad/param norm = 1.7761e-01, time/batch = 0.6634s	
4511/33150 (epoch 6.804), train_loss = 1.31739604, grad/param norm = 1.6353e-01, time/batch = 0.6669s	
4512/33150 (epoch 6.805), train_loss = 1.26610570, grad/param norm = 1.7115e-01, time/batch = 0.6654s	
4513/33150 (epoch 6.807), train_loss = 1.23641284, grad/param norm = 1.7199e-01, time/batch = 0.6640s	
4514/33150 (epoch 6.808), train_loss = 1.37966571, grad/param norm = 1.7202e-01, time/batch = 0.6668s	
4515/33150 (epoch 6.810), train_loss = 1.29193786, grad/param norm = 1.7048e-01, time/batch = 0.6660s	
4516/33150 (epoch 6.811), train_loss = 1.40029317, grad/param norm = 1.7815e-01, time/batch = 0.6675s	
4517/33150 (epoch 6.813), train_loss = 1.29576140, grad/param norm = 1.5076e-01, time/batch = 0.6651s	
4518/33150 (epoch 6.814), train_loss = 1.34844667, grad/param norm = 1.8078e-01, time/batch = 0.6673s	
4519/33150 (epoch 6.816), train_loss = 1.33121353, grad/param norm = 1.8554e-01, time/batch = 0.6639s	
4520/33150 (epoch 6.817), train_loss = 1.44154287, grad/param norm = 1.7009e-01, time/batch = 0.6647s	
4521/33150 (epoch 6.819), train_loss = 1.30389466, grad/param norm = 1.6278e-01, time/batch = 0.6876s	
4522/33150 (epoch 6.821), train_loss = 1.11872320, grad/param norm = 1.3891e-01, time/batch = 0.6755s	
4523/33150 (epoch 6.822), train_loss = 1.21878923, grad/param norm = 1.4983e-01, time/batch = 0.6647s	
4524/33150 (epoch 6.824), train_loss = 1.28790536, grad/param norm = 1.7893e-01, time/batch = 0.6642s	
4525/33150 (epoch 6.825), train_loss = 1.31228926, grad/param norm = 1.7046e-01, time/batch = 0.6664s	
4526/33150 (epoch 6.827), train_loss = 1.40825126, grad/param norm = 1.8532e-01, time/batch = 0.6636s	
4527/33150 (epoch 6.828), train_loss = 1.20489942, grad/param norm = 1.7276e-01, time/batch = 0.6638s	
4528/33150 (epoch 6.830), train_loss = 1.32811753, grad/param norm = 1.7579e-01, time/batch = 0.6645s	
4529/33150 (epoch 6.831), train_loss = 1.28356751, grad/param norm = 1.8237e-01, time/batch = 0.6657s	
4530/33150 (epoch 6.833), train_loss = 1.21726542, grad/param norm = 1.7452e-01, time/batch = 0.6627s	
4531/33150 (epoch 6.834), train_loss = 1.50851111, grad/param norm = 1.8897e-01, time/batch = 0.6642s	
4532/33150 (epoch 6.836), train_loss = 1.43947849, grad/param norm = 1.8198e-01, time/batch = 0.6642s	
4533/33150 (epoch 6.837), train_loss = 1.31770124, grad/param norm = 1.6476e-01, time/batch = 0.6675s	
4534/33150 (epoch 6.839), train_loss = 1.50839357, grad/param norm = 2.1227e-01, time/batch = 0.6660s	
4535/33150 (epoch 6.840), train_loss = 1.42635706, grad/param norm = 1.7614e-01, time/batch = 0.6685s	
4536/33150 (epoch 6.842), train_loss = 1.50998244, grad/param norm = 2.1473e-01, time/batch = 0.6865s	
4537/33150 (epoch 6.843), train_loss = 1.44631659, grad/param norm = 1.9168e-01, time/batch = 0.6742s	
4538/33150 (epoch 6.845), train_loss = 1.25811333, grad/param norm = 1.6886e-01, time/batch = 0.6643s	
4539/33150 (epoch 6.846), train_loss = 1.61184048, grad/param norm = 2.1035e-01, time/batch = 0.6651s	
4540/33150 (epoch 6.848), train_loss = 1.40311562, grad/param norm = 1.6404e-01, time/batch = 0.6695s	
4541/33150 (epoch 6.849), train_loss = 1.38550275, grad/param norm = 1.7552e-01, time/batch = 0.6681s	
4542/33150 (epoch 6.851), train_loss = 1.47959816, grad/param norm = 2.0762e-01, time/batch = 0.6638s	
4543/33150 (epoch 6.852), train_loss = 1.49418502, grad/param norm = 1.8106e-01, time/batch = 0.6640s	
4544/33150 (epoch 6.854), train_loss = 1.35919712, grad/param norm = 1.6133e-01, time/batch = 0.6748s	
4545/33150 (epoch 6.855), train_loss = 1.10295946, grad/param norm = 1.4555e-01, time/batch = 0.6777s	
4546/33150 (epoch 6.857), train_loss = 1.15827752, grad/param norm = 1.5747e-01, time/batch = 0.6802s	
4547/33150 (epoch 6.858), train_loss = 1.26961796, grad/param norm = 1.6687e-01, time/batch = 0.6782s	
4548/33150 (epoch 6.860), train_loss = 1.22386691, grad/param norm = 1.5495e-01, time/batch = 0.6815s	
4549/33150 (epoch 6.861), train_loss = 1.26013550, grad/param norm = 1.6096e-01, time/batch = 0.6704s	
4550/33150 (epoch 6.863), train_loss = 1.37352880, grad/param norm = 1.5411e-01, time/batch = 0.6772s	
4551/33150 (epoch 6.864), train_loss = 1.50194966, grad/param norm = 1.8125e-01, time/batch = 0.6829s	
4552/33150 (epoch 6.866), train_loss = 1.34983703, grad/param norm = 1.8214e-01, time/batch = 0.6819s	
4553/33150 (epoch 6.867), train_loss = 1.38023761, grad/param norm = 1.5612e-01, time/batch = 0.6758s	
4554/33150 (epoch 6.869), train_loss = 1.42531622, grad/param norm = 1.9297e-01, time/batch = 0.6755s	
4555/33150 (epoch 6.870), train_loss = 1.44468497, grad/param norm = 1.6834e-01, time/batch = 0.6670s	
4556/33150 (epoch 6.872), train_loss = 1.35700722, grad/param norm = 1.7304e-01, time/batch = 0.6654s	
4557/33150 (epoch 6.873), train_loss = 1.14121462, grad/param norm = 1.4746e-01, time/batch = 0.6722s	
4558/33150 (epoch 6.875), train_loss = 1.51214589, grad/param norm = 1.7582e-01, time/batch = 0.6751s	
4559/33150 (epoch 6.876), train_loss = 1.28756742, grad/param norm = 1.8298e-01, time/batch = 0.6862s	
4560/33150 (epoch 6.878), train_loss = 1.20681612, grad/param norm = 1.4828e-01, time/batch = 0.6845s	
4561/33150 (epoch 6.879), train_loss = 1.26966853, grad/param norm = 1.7379e-01, time/batch = 0.6800s	
4562/33150 (epoch 6.881), train_loss = 1.28075609, grad/param norm = 1.6307e-01, time/batch = 0.6736s	
4563/33150 (epoch 6.882), train_loss = 1.21514879, grad/param norm = 1.6231e-01, time/batch = 0.6925s	
4564/33150 (epoch 6.884), train_loss = 1.36414568, grad/param norm = 1.7470e-01, time/batch = 0.6794s	
4565/33150 (epoch 6.885), train_loss = 1.06831705, grad/param norm = 1.5739e-01, time/batch = 0.6784s	
4566/33150 (epoch 6.887), train_loss = 1.56600025, grad/param norm = 1.8764e-01, time/batch = 0.6813s	
4567/33150 (epoch 6.888), train_loss = 1.41270355, grad/param norm = 1.7366e-01, time/batch = 0.6685s	
4568/33150 (epoch 6.890), train_loss = 1.29467445, grad/param norm = 1.5524e-01, time/batch = 0.6672s	
4569/33150 (epoch 6.891), train_loss = 1.24723536, grad/param norm = 1.7650e-01, time/batch = 0.6642s	
4570/33150 (epoch 6.893), train_loss = 1.41767318, grad/param norm = 1.8550e-01, time/batch = 0.6688s	
4571/33150 (epoch 6.894), train_loss = 1.42361495, grad/param norm = 1.7257e-01, time/batch = 0.6831s	
4572/33150 (epoch 6.896), train_loss = 1.29927335, grad/param norm = 1.5997e-01, time/batch = 0.6642s	
4573/33150 (epoch 6.897), train_loss = 1.37666753, grad/param norm = 1.5549e-01, time/batch = 0.6723s	
4574/33150 (epoch 6.899), train_loss = 1.20364837, grad/param norm = 1.6458e-01, time/batch = 0.6666s	
4575/33150 (epoch 6.900), train_loss = 1.63473803, grad/param norm = 1.8921e-01, time/batch = 0.6630s	
4576/33150 (epoch 6.902), train_loss = 1.52327618, grad/param norm = 1.7748e-01, time/batch = 0.6628s	
4577/33150 (epoch 6.903), train_loss = 1.34263404, grad/param norm = 1.6248e-01, time/batch = 0.6661s	
4578/33150 (epoch 6.905), train_loss = 1.36997142, grad/param norm = 1.7411e-01, time/batch = 0.6637s	
4579/33150 (epoch 6.906), train_loss = 1.41919740, grad/param norm = 1.8060e-01, time/batch = 0.6756s	
4580/33150 (epoch 6.908), train_loss = 1.48797168, grad/param norm = 1.7726e-01, time/batch = 0.6647s	
4581/33150 (epoch 6.910), train_loss = 1.42944177, grad/param norm = 1.6592e-01, time/batch = 0.6746s	
4582/33150 (epoch 6.911), train_loss = 1.19663619, grad/param norm = 1.5632e-01, time/batch = 0.6849s	
4583/33150 (epoch 6.913), train_loss = 1.24064660, grad/param norm = 1.6323e-01, time/batch = 0.6677s	
4584/33150 (epoch 6.914), train_loss = 1.46867144, grad/param norm = 1.9221e-01, time/batch = 0.6659s	
4585/33150 (epoch 6.916), train_loss = 1.21586954, grad/param norm = 1.7118e-01, time/batch = 0.6670s	
4586/33150 (epoch 6.917), train_loss = 1.48979646, grad/param norm = 1.8540e-01, time/batch = 0.6670s	
4587/33150 (epoch 6.919), train_loss = 1.57501551, grad/param norm = 2.1467e-01, time/batch = 0.6778s	
4588/33150 (epoch 6.920), train_loss = 1.42357629, grad/param norm = 1.6546e-01, time/batch = 0.6697s	
4589/33150 (epoch 6.922), train_loss = 1.53790574, grad/param norm = 1.8571e-01, time/batch = 0.6722s	
4590/33150 (epoch 6.923), train_loss = 1.36152384, grad/param norm = 1.8321e-01, time/batch = 0.6658s	
4591/33150 (epoch 6.925), train_loss = 1.36842477, grad/param norm = 1.7323e-01, time/batch = 0.6678s	
4592/33150 (epoch 6.926), train_loss = 1.33888195, grad/param norm = 1.8000e-01, time/batch = 0.6663s	
4593/33150 (epoch 6.928), train_loss = 1.31315845, grad/param norm = 1.6892e-01, time/batch = 0.6687s	
4594/33150 (epoch 6.929), train_loss = 1.40630620, grad/param norm = 1.7368e-01, time/batch = 0.6657s	
4595/33150 (epoch 6.931), train_loss = 1.51618923, grad/param norm = 1.9899e-01, time/batch = 0.6863s	
4596/33150 (epoch 6.932), train_loss = 1.37521225, grad/param norm = 2.0043e-01, time/batch = 0.6773s	
4597/33150 (epoch 6.934), train_loss = 1.33536286, grad/param norm = 1.5782e-01, time/batch = 0.6640s	
4598/33150 (epoch 6.935), train_loss = 1.45849733, grad/param norm = 1.6605e-01, time/batch = 0.6676s	
4599/33150 (epoch 6.937), train_loss = 1.47591564, grad/param norm = 1.7325e-01, time/batch = 0.6639s	
4600/33150 (epoch 6.938), train_loss = 1.43869118, grad/param norm = 1.6588e-01, time/batch = 0.6647s	
4601/33150 (epoch 6.940), train_loss = 1.67159505, grad/param norm = 1.8564e-01, time/batch = 0.6694s	
4602/33150 (epoch 6.941), train_loss = 1.30525713, grad/param norm = 1.5125e-01, time/batch = 0.6708s	
4603/33150 (epoch 6.943), train_loss = 1.23110224, grad/param norm = 1.9460e-01, time/batch = 0.6699s	
4604/33150 (epoch 6.944), train_loss = 1.49562192, grad/param norm = 1.9660e-01, time/batch = 0.6700s	
4605/33150 (epoch 6.946), train_loss = 1.11627442, grad/param norm = 1.5461e-01, time/batch = 0.6757s	
4606/33150 (epoch 6.947), train_loss = 1.39842980, grad/param norm = 1.7542e-01, time/batch = 0.6692s	
4607/33150 (epoch 6.949), train_loss = 1.50877812, grad/param norm = 1.7977e-01, time/batch = 0.6674s	
4608/33150 (epoch 6.950), train_loss = 1.46452821, grad/param norm = 1.8352e-01, time/batch = 0.6672s	
4609/33150 (epoch 6.952), train_loss = 1.25676056, grad/param norm = 1.5729e-01, time/batch = 0.6662s	
4610/33150 (epoch 6.953), train_loss = 1.24966141, grad/param norm = 1.4814e-01, time/batch = 0.6856s	
4611/33150 (epoch 6.955), train_loss = 1.22018166, grad/param norm = 1.4982e-01, time/batch = 0.6870s	
4612/33150 (epoch 6.956), train_loss = 1.46964947, grad/param norm = 1.8067e-01, time/batch = 0.6858s	
4613/33150 (epoch 6.958), train_loss = 1.21226171, grad/param norm = 1.6347e-01, time/batch = 0.6884s	
4614/33150 (epoch 6.959), train_loss = 1.20496278, grad/param norm = 1.8000e-01, time/batch = 0.6884s	
4615/33150 (epoch 6.961), train_loss = 1.20692425, grad/param norm = 1.5409e-01, time/batch = 0.6860s	
4616/33150 (epoch 6.962), train_loss = 1.13888798, grad/param norm = 1.4987e-01, time/batch = 0.6743s	
4617/33150 (epoch 6.964), train_loss = 1.34990685, grad/param norm = 1.7168e-01, time/batch = 0.6664s	
4618/33150 (epoch 6.965), train_loss = 1.34061518, grad/param norm = 1.7265e-01, time/batch = 0.6656s	
4619/33150 (epoch 6.967), train_loss = 1.40869365, grad/param norm = 1.9241e-01, time/batch = 0.6802s	
4620/33150 (epoch 6.968), train_loss = 1.16190859, grad/param norm = 1.5888e-01, time/batch = 0.6689s	
4621/33150 (epoch 6.970), train_loss = 1.26977489, grad/param norm = 1.6721e-01, time/batch = 0.6639s	
4622/33150 (epoch 6.971), train_loss = 1.40397059, grad/param norm = 1.9711e-01, time/batch = 0.6634s	
4623/33150 (epoch 6.973), train_loss = 1.51636654, grad/param norm = 1.6668e-01, time/batch = 0.6657s	
4624/33150 (epoch 6.974), train_loss = 1.56909693, grad/param norm = 1.9379e-01, time/batch = 0.6715s	
4625/33150 (epoch 6.976), train_loss = 1.39544725, grad/param norm = 1.6300e-01, time/batch = 0.6804s	
4626/33150 (epoch 6.977), train_loss = 1.48265854, grad/param norm = 1.7683e-01, time/batch = 0.6724s	
4627/33150 (epoch 6.979), train_loss = 1.47913848, grad/param norm = 1.8195e-01, time/batch = 0.6694s	
4628/33150 (epoch 6.980), train_loss = 1.46310781, grad/param norm = 1.7605e-01, time/batch = 0.6686s	
4629/33150 (epoch 6.982), train_loss = 1.30556580, grad/param norm = 1.7654e-01, time/batch = 0.6694s	
4630/33150 (epoch 6.983), train_loss = 1.21807370, grad/param norm = 1.7000e-01, time/batch = 0.6707s	
4631/33150 (epoch 6.985), train_loss = 1.36888368, grad/param norm = 1.5863e-01, time/batch = 0.6753s	
4632/33150 (epoch 6.986), train_loss = 1.21681891, grad/param norm = 1.5967e-01, time/batch = 0.6744s	
4633/33150 (epoch 6.988), train_loss = 1.30023531, grad/param norm = 1.6956e-01, time/batch = 0.6705s	
4634/33150 (epoch 6.989), train_loss = 1.22183795, grad/param norm = 1.7263e-01, time/batch = 0.6682s	
4635/33150 (epoch 6.991), train_loss = 1.48301746, grad/param norm = 2.0907e-01, time/batch = 0.6694s	
4636/33150 (epoch 6.992), train_loss = 1.17704797, grad/param norm = 1.6151e-01, time/batch = 0.6694s	
4637/33150 (epoch 6.994), train_loss = 1.30856456, grad/param norm = 1.7454e-01, time/batch = 0.6699s	
4638/33150 (epoch 6.995), train_loss = 1.22844141, grad/param norm = 1.6046e-01, time/batch = 0.6689s	
4639/33150 (epoch 6.997), train_loss = 1.40042823, grad/param norm = 1.8768e-01, time/batch = 0.6750s	
4640/33150 (epoch 6.998), train_loss = 1.07135275, grad/param norm = 1.5683e-01, time/batch = 0.6778s	
4641/33150 (epoch 7.000), train_loss = 1.22403518, grad/param norm = 1.7255e-01, time/batch = 0.6698s	
4642/33150 (epoch 7.002), train_loss = 1.60290076, grad/param norm = 1.9893e-01, time/batch = 0.6652s	
4643/33150 (epoch 7.003), train_loss = 1.28668849, grad/param norm = 1.7710e-01, time/batch = 0.6649s	
4644/33150 (epoch 7.005), train_loss = 1.18077163, grad/param norm = 1.6804e-01, time/batch = 0.6645s	
4645/33150 (epoch 7.006), train_loss = 1.12172896, grad/param norm = 1.6179e-01, time/batch = 0.6665s	
4646/33150 (epoch 7.008), train_loss = 1.47406028, grad/param norm = 1.8977e-01, time/batch = 0.6704s	
4647/33150 (epoch 7.009), train_loss = 1.30358786, grad/param norm = 1.4470e-01, time/batch = 0.6827s	
4648/33150 (epoch 7.011), train_loss = 1.56206543, grad/param norm = 1.7806e-01, time/batch = 0.6873s	
4649/33150 (epoch 7.012), train_loss = 1.34328392, grad/param norm = 1.8688e-01, time/batch = 0.6742s	
4650/33150 (epoch 7.014), train_loss = 1.32079055, grad/param norm = 1.8225e-01, time/batch = 0.6824s	
4651/33150 (epoch 7.015), train_loss = 1.31777442, grad/param norm = 1.6111e-01, time/batch = 0.6696s	
4652/33150 (epoch 7.017), train_loss = 1.24583879, grad/param norm = 1.6018e-01, time/batch = 0.6699s	
4653/33150 (epoch 7.018), train_loss = 1.40824619, grad/param norm = 1.7153e-01, time/batch = 0.6715s	
4654/33150 (epoch 7.020), train_loss = 1.39189100, grad/param norm = 1.6547e-01, time/batch = 0.6756s	
4655/33150 (epoch 7.021), train_loss = 1.14100095, grad/param norm = 1.6664e-01, time/batch = 0.6771s	
4656/33150 (epoch 7.023), train_loss = 1.50480283, grad/param norm = 1.5563e-01, time/batch = 0.6687s	
4657/33150 (epoch 7.024), train_loss = 1.33828564, grad/param norm = 1.6897e-01, time/batch = 0.6690s	
4658/33150 (epoch 7.026), train_loss = 1.07433223, grad/param norm = 1.4647e-01, time/batch = 0.6658s	
4659/33150 (epoch 7.027), train_loss = 1.16414669, grad/param norm = 1.7298e-01, time/batch = 0.6702s	
4660/33150 (epoch 7.029), train_loss = 1.23432321, grad/param norm = 1.6340e-01, time/batch = 0.6702s	
4661/33150 (epoch 7.030), train_loss = 1.31584204, grad/param norm = 1.5773e-01, time/batch = 0.6755s	
4662/33150 (epoch 7.032), train_loss = 1.24445523, grad/param norm = 1.7570e-01, time/batch = 0.6773s	
4663/33150 (epoch 7.033), train_loss = 1.30165389, grad/param norm = 1.8173e-01, time/batch = 0.6750s	
4664/33150 (epoch 7.035), train_loss = 1.56156291, grad/param norm = 1.8454e-01, time/batch = 0.6733s	
4665/33150 (epoch 7.036), train_loss = 1.43065206, grad/param norm = 1.9143e-01, time/batch = 0.6722s	
4666/33150 (epoch 7.038), train_loss = 1.66985427, grad/param norm = 2.0527e-01, time/batch = 0.6695s	
4667/33150 (epoch 7.039), train_loss = 1.34063578, grad/param norm = 1.4792e-01, time/batch = 0.6696s	
4668/33150 (epoch 7.041), train_loss = 1.36800404, grad/param norm = 1.7029e-01, time/batch = 0.6714s	
4669/33150 (epoch 7.042), train_loss = 1.22397427, grad/param norm = 1.5039e-01, time/batch = 0.6790s	
4670/33150 (epoch 7.044), train_loss = 1.26839430, grad/param norm = 1.4794e-01, time/batch = 0.6762s	
4671/33150 (epoch 7.045), train_loss = 1.32486323, grad/param norm = 1.6653e-01, time/batch = 0.6719s	
4672/33150 (epoch 7.047), train_loss = 1.27625407, grad/param norm = 1.7501e-01, time/batch = 0.6693s	
4673/33150 (epoch 7.048), train_loss = 1.50349316, grad/param norm = 2.0182e-01, time/batch = 0.6658s	
4674/33150 (epoch 7.050), train_loss = 1.32857332, grad/param norm = 1.6625e-01, time/batch = 0.6670s	
4675/33150 (epoch 7.051), train_loss = 1.34736609, grad/param norm = 1.7262e-01, time/batch = 0.6676s	
4676/33150 (epoch 7.053), train_loss = 1.28239033, grad/param norm = 1.7360e-01, time/batch = 0.6654s	
4677/33150 (epoch 7.054), train_loss = 1.34130028, grad/param norm = 1.5470e-01, time/batch = 0.6649s	
4678/33150 (epoch 7.056), train_loss = 1.22102312, grad/param norm = 1.4681e-01, time/batch = 0.6629s	
4679/33150 (epoch 7.057), train_loss = 1.34691422, grad/param norm = 1.7409e-01, time/batch = 0.6630s	
4680/33150 (epoch 7.059), train_loss = 1.25409269, grad/param norm = 1.7335e-01, time/batch = 0.6656s	
4681/33150 (epoch 7.060), train_loss = 1.24059477, grad/param norm = 1.5107e-01, time/batch = 0.6668s	
4682/33150 (epoch 7.062), train_loss = 1.32810724, grad/param norm = 1.6297e-01, time/batch = 0.6666s	
4683/33150 (epoch 7.063), train_loss = 1.27331333, grad/param norm = 1.5564e-01, time/batch = 0.6659s	
4684/33150 (epoch 7.065), train_loss = 1.31846076, grad/param norm = 1.5578e-01, time/batch = 0.6825s	
4685/33150 (epoch 7.066), train_loss = 1.24012598, grad/param norm = 1.6444e-01, time/batch = 0.6805s	
4686/33150 (epoch 7.068), train_loss = 1.31305362, grad/param norm = 1.6102e-01, time/batch = 0.6681s	
4687/33150 (epoch 7.069), train_loss = 1.40509404, grad/param norm = 1.8883e-01, time/batch = 0.6781s	
4688/33150 (epoch 7.071), train_loss = 1.38650334, grad/param norm = 1.6401e-01, time/batch = 0.6633s	
4689/33150 (epoch 7.072), train_loss = 1.21104954, grad/param norm = 1.5977e-01, time/batch = 0.6617s	
4690/33150 (epoch 7.074), train_loss = 1.14949435, grad/param norm = 1.6487e-01, time/batch = 0.6637s	
4691/33150 (epoch 7.075), train_loss = 1.30330939, grad/param norm = 1.6085e-01, time/batch = 0.6667s	
4692/33150 (epoch 7.077), train_loss = 1.42302849, grad/param norm = 1.8932e-01, time/batch = 0.6665s	
4693/33150 (epoch 7.078), train_loss = 1.51446934, grad/param norm = 1.9472e-01, time/batch = 0.6615s	
4694/33150 (epoch 7.080), train_loss = 1.43532951, grad/param norm = 1.6498e-01, time/batch = 0.6683s	
4695/33150 (epoch 7.081), train_loss = 1.26421422, grad/param norm = 1.8378e-01, time/batch = 0.6668s	
4696/33150 (epoch 7.083), train_loss = 0.98702804, grad/param norm = 1.5730e-01, time/batch = 0.6655s	
4697/33150 (epoch 7.084), train_loss = 1.16437659, grad/param norm = 1.7109e-01, time/batch = 0.6675s	
4698/33150 (epoch 7.086), train_loss = 1.28020838, grad/param norm = 1.7790e-01, time/batch = 0.6662s	
4699/33150 (epoch 7.087), train_loss = 1.21077459, grad/param norm = 1.7022e-01, time/batch = 0.6664s	
4700/33150 (epoch 7.089), train_loss = 1.22077260, grad/param norm = 1.7643e-01, time/batch = 0.6732s	
4701/33150 (epoch 7.090), train_loss = 1.27586029, grad/param norm = 1.9126e-01, time/batch = 0.6717s	
4702/33150 (epoch 7.092), train_loss = 1.32363846, grad/param norm = 1.6936e-01, time/batch = 0.6736s	
4703/33150 (epoch 7.094), train_loss = 1.42754118, grad/param norm = 1.8708e-01, time/batch = 0.6806s	
4704/33150 (epoch 7.095), train_loss = 1.15401242, grad/param norm = 1.4305e-01, time/batch = 0.6786s	
4705/33150 (epoch 7.097), train_loss = 1.37212428, grad/param norm = 1.7904e-01, time/batch = 0.6622s	
4706/33150 (epoch 7.098), train_loss = 1.58115617, grad/param norm = 1.9452e-01, time/batch = 0.6663s	
4707/33150 (epoch 7.100), train_loss = 1.51187672, grad/param norm = 1.6993e-01, time/batch = 0.6647s	
4708/33150 (epoch 7.101), train_loss = 1.22479765, grad/param norm = 1.7787e-01, time/batch = 0.6626s	
4709/33150 (epoch 7.103), train_loss = 1.35897170, grad/param norm = 1.6622e-01, time/batch = 0.6678s	
4710/33150 (epoch 7.104), train_loss = 1.30235460, grad/param norm = 1.8106e-01, time/batch = 0.6634s	
4711/33150 (epoch 7.106), train_loss = 1.51157165, grad/param norm = 1.8618e-01, time/batch = 0.6642s	
4712/33150 (epoch 7.107), train_loss = 1.57811443, grad/param norm = 1.9432e-01, time/batch = 0.6662s	
4713/33150 (epoch 7.109), train_loss = 1.24662370, grad/param norm = 1.6125e-01, time/batch = 0.6660s	
4714/33150 (epoch 7.110), train_loss = 1.39163163, grad/param norm = 1.7520e-01, time/batch = 0.6615s	
4715/33150 (epoch 7.112), train_loss = 1.21988650, grad/param norm = 1.6275e-01, time/batch = 0.6651s	
4716/33150 (epoch 7.113), train_loss = 1.24725010, grad/param norm = 1.8109e-01, time/batch = 0.6648s	
4717/33150 (epoch 7.115), train_loss = 1.50206763, grad/param norm = 1.9601e-01, time/batch = 0.6638s	
4718/33150 (epoch 7.116), train_loss = 1.20497044, grad/param norm = 1.7116e-01, time/batch = 0.6793s	
4719/33150 (epoch 7.118), train_loss = 1.41389326, grad/param norm = 1.8459e-01, time/batch = 0.6825s	
4720/33150 (epoch 7.119), train_loss = 1.39881486, grad/param norm = 1.8394e-01, time/batch = 0.6698s	
4721/33150 (epoch 7.121), train_loss = 1.26052884, grad/param norm = 1.6290e-01, time/batch = 0.6761s	
4722/33150 (epoch 7.122), train_loss = 1.50258722, grad/param norm = 1.8911e-01, time/batch = 0.6952s	
4723/33150 (epoch 7.124), train_loss = 1.05154476, grad/param norm = 1.4838e-01, time/batch = 0.6710s	
4724/33150 (epoch 7.125), train_loss = 1.38013835, grad/param norm = 1.6023e-01, time/batch = 0.6668s	
4725/33150 (epoch 7.127), train_loss = 1.22257910, grad/param norm = 1.5281e-01, time/batch = 0.6651s	
4726/33150 (epoch 7.128), train_loss = 1.34114487, grad/param norm = 1.7462e-01, time/batch = 0.6626s	
4727/33150 (epoch 7.130), train_loss = 1.36958665, grad/param norm = 1.6241e-01, time/batch = 0.6645s	
4728/33150 (epoch 7.131), train_loss = 1.55739285, grad/param norm = 1.8526e-01, time/batch = 0.6646s	
4729/33150 (epoch 7.133), train_loss = 1.23085327, grad/param norm = 1.6630e-01, time/batch = 0.6624s	
4730/33150 (epoch 7.134), train_loss = 1.43105088, grad/param norm = 1.7247e-01, time/batch = 0.6669s	
4731/33150 (epoch 7.136), train_loss = 1.32312142, grad/param norm = 1.6299e-01, time/batch = 0.6694s	
4732/33150 (epoch 7.137), train_loss = 1.41242592, grad/param norm = 1.7759e-01, time/batch = 0.6670s	
4733/33150 (epoch 7.139), train_loss = 1.34629435, grad/param norm = 1.6731e-01, time/batch = 0.6670s	
4734/33150 (epoch 7.140), train_loss = 1.47121963, grad/param norm = 1.8128e-01, time/batch = 0.6680s	
4735/33150 (epoch 7.142), train_loss = 1.42062417, grad/param norm = 2.0379e-01, time/batch = 0.6645s	
4736/33150 (epoch 7.143), train_loss = 1.36307664, grad/param norm = 1.8836e-01, time/batch = 0.6776s	
4737/33150 (epoch 7.145), train_loss = 1.35635136, grad/param norm = 1.9613e-01, time/batch = 0.6878s	
4738/33150 (epoch 7.146), train_loss = 1.50981785, grad/param norm = 2.1862e-01, time/batch = 0.6841s	
4739/33150 (epoch 7.148), train_loss = 1.39454290, grad/param norm = 1.7257e-01, time/batch = 0.6861s	
4740/33150 (epoch 7.149), train_loss = 1.37416847, grad/param norm = 1.9243e-01, time/batch = 0.6660s	
4741/33150 (epoch 7.151), train_loss = 1.58461670, grad/param norm = 1.8351e-01, time/batch = 0.6673s	
4742/33150 (epoch 7.152), train_loss = 1.26971901, grad/param norm = 1.5425e-01, time/batch = 0.6712s	
4743/33150 (epoch 7.154), train_loss = 1.31219770, grad/param norm = 1.6321e-01, time/batch = 0.6705s	
4744/33150 (epoch 7.155), train_loss = 1.19889901, grad/param norm = 1.6248e-01, time/batch = 0.6717s	
4745/33150 (epoch 7.157), train_loss = 1.26249527, grad/param norm = 1.7706e-01, time/batch = 0.6750s	
4746/33150 (epoch 7.158), train_loss = 1.20699000, grad/param norm = 1.7097e-01, time/batch = 0.6738s	
4747/33150 (epoch 7.160), train_loss = 1.43070940, grad/param norm = 1.6359e-01, time/batch = 0.6756s	
4748/33150 (epoch 7.161), train_loss = 1.31960009, grad/param norm = 1.7649e-01, time/batch = 0.6805s	
4749/33150 (epoch 7.163), train_loss = 1.26931382, grad/param norm = 1.5383e-01, time/batch = 0.6741s	
4750/33150 (epoch 7.164), train_loss = 1.44317172, grad/param norm = 1.7676e-01, time/batch = 0.6696s	
4751/33150 (epoch 7.166), train_loss = 1.34562726, grad/param norm = 1.7571e-01, time/batch = 0.6694s	
4752/33150 (epoch 7.167), train_loss = 1.34126178, grad/param norm = 1.6093e-01, time/batch = 0.6840s	
4753/33150 (epoch 7.169), train_loss = 1.48198669, grad/param norm = 2.0931e-01, time/batch = 0.6766s	
4754/33150 (epoch 7.170), train_loss = 1.29864115, grad/param norm = 1.8305e-01, time/batch = 0.6790s	
4755/33150 (epoch 7.172), train_loss = 1.46065164, grad/param norm = 1.8590e-01, time/batch = 0.6717s	
4756/33150 (epoch 7.173), train_loss = 1.42991728, grad/param norm = 1.9320e-01, time/batch = 0.6732s	
4757/33150 (epoch 7.175), train_loss = 1.24740125, grad/param norm = 1.7117e-01, time/batch = 0.6831s	
4758/33150 (epoch 7.176), train_loss = 1.35389821, grad/param norm = 1.7981e-01, time/batch = 0.6746s	
4759/33150 (epoch 7.178), train_loss = 1.51575145, grad/param norm = 1.7799e-01, time/batch = 0.6680s	
4760/33150 (epoch 7.179), train_loss = 1.35620905, grad/param norm = 1.5322e-01, time/batch = 0.6679s	
4761/33150 (epoch 7.181), train_loss = 1.35681268, grad/param norm = 1.9694e-01, time/batch = 0.6682s	
4762/33150 (epoch 7.183), train_loss = 1.35212156, grad/param norm = 1.8311e-01, time/batch = 0.6717s	
4763/33150 (epoch 7.184), train_loss = 1.51502721, grad/param norm = 1.8327e-01, time/batch = 0.6803s	
4764/33150 (epoch 7.186), train_loss = 1.47023273, grad/param norm = 1.8164e-01, time/batch = 0.6704s	
4765/33150 (epoch 7.187), train_loss = 1.33757941, grad/param norm = 1.7207e-01, time/batch = 0.6669s	
4766/33150 (epoch 7.189), train_loss = 1.17343320, grad/param norm = 1.7611e-01, time/batch = 0.6696s	
4767/33150 (epoch 7.190), train_loss = 1.26600423, grad/param norm = 1.7809e-01, time/batch = 0.6668s	
4768/33150 (epoch 7.192), train_loss = 1.34461070, grad/param norm = 1.7472e-01, time/batch = 0.6640s	
4769/33150 (epoch 7.193), train_loss = 1.35164955, grad/param norm = 1.6120e-01, time/batch = 0.6689s	
4770/33150 (epoch 7.195), train_loss = 1.65450395, grad/param norm = 1.8765e-01, time/batch = 0.6682s	
4771/33150 (epoch 7.196), train_loss = 1.46214360, grad/param norm = 1.6958e-01, time/batch = 0.6714s	
4772/33150 (epoch 7.198), train_loss = 1.20045069, grad/param norm = 1.7572e-01, time/batch = 0.6697s	
4773/33150 (epoch 7.199), train_loss = 1.43389962, grad/param norm = 1.7877e-01, time/batch = 0.6698s	
4774/33150 (epoch 7.201), train_loss = 1.17941119, grad/param norm = 1.4407e-01, time/batch = 0.6706s	
4775/33150 (epoch 7.202), train_loss = 1.13112119, grad/param norm = 1.5022e-01, time/batch = 0.6698s	
4776/33150 (epoch 7.204), train_loss = 1.30709585, grad/param norm = 1.6191e-01, time/batch = 0.6704s	
4777/33150 (epoch 7.205), train_loss = 1.43324967, grad/param norm = 1.7714e-01, time/batch = 0.6732s	
4778/33150 (epoch 7.207), train_loss = 1.35124865, grad/param norm = 1.6689e-01, time/batch = 0.6802s	
4779/33150 (epoch 7.208), train_loss = 1.39529702, grad/param norm = 1.5950e-01, time/batch = 0.6686s	
4780/33150 (epoch 7.210), train_loss = 1.19500465, grad/param norm = 1.4807e-01, time/batch = 0.6652s	
4781/33150 (epoch 7.211), train_loss = 1.37732505, grad/param norm = 1.8308e-01, time/batch = 0.6722s	
4782/33150 (epoch 7.213), train_loss = 1.45241913, grad/param norm = 1.7539e-01, time/batch = 0.6764s	
4783/33150 (epoch 7.214), train_loss = 1.27903436, grad/param norm = 1.6302e-01, time/batch = 0.6669s	
4784/33150 (epoch 7.216), train_loss = 1.26262402, grad/param norm = 1.6381e-01, time/batch = 0.6669s	
4785/33150 (epoch 7.217), train_loss = 1.26212273, grad/param norm = 1.6499e-01, time/batch = 0.6656s	
4786/33150 (epoch 7.219), train_loss = 1.21545641, grad/param norm = 1.5679e-01, time/batch = 0.6670s	
4787/33150 (epoch 7.220), train_loss = 1.20589653, grad/param norm = 1.4472e-01, time/batch = 0.6663s	
4788/33150 (epoch 7.222), train_loss = 1.40033417, grad/param norm = 1.6315e-01, time/batch = 0.6666s	
4789/33150 (epoch 7.223), train_loss = 1.27644290, grad/param norm = 1.6549e-01, time/batch = 0.6674s	
4790/33150 (epoch 7.225), train_loss = 1.52591408, grad/param norm = 1.7638e-01, time/batch = 0.6660s	
4791/33150 (epoch 7.226), train_loss = 1.28095581, grad/param norm = 1.5524e-01, time/batch = 0.6684s	
4792/33150 (epoch 7.228), train_loss = 1.31012687, grad/param norm = 1.6669e-01, time/batch = 0.6657s	
4793/33150 (epoch 7.229), train_loss = 1.33014452, grad/param norm = 1.6461e-01, time/batch = 0.6705s	
4794/33150 (epoch 7.231), train_loss = 1.44389492, grad/param norm = 1.7590e-01, time/batch = 0.6719s	
4795/33150 (epoch 7.232), train_loss = 1.35855777, grad/param norm = 1.8828e-01, time/batch = 0.6719s	
4796/33150 (epoch 7.234), train_loss = 1.28589039, grad/param norm = 1.8422e-01, time/batch = 0.6806s	
4797/33150 (epoch 7.235), train_loss = 1.36107148, grad/param norm = 1.6702e-01, time/batch = 0.6686s	
4798/33150 (epoch 7.237), train_loss = 1.30061978, grad/param norm = 1.7379e-01, time/batch = 0.6655s	
4799/33150 (epoch 7.238), train_loss = 1.46644692, grad/param norm = 1.9391e-01, time/batch = 0.6677s	
4800/33150 (epoch 7.240), train_loss = 1.34481988, grad/param norm = 1.6146e-01, time/batch = 0.6653s	
4801/33150 (epoch 7.241), train_loss = 1.47947973, grad/param norm = 1.9514e-01, time/batch = 0.6675s	
4802/33150 (epoch 7.243), train_loss = 1.45967821, grad/param norm = 1.8613e-01, time/batch = 0.6712s	
4803/33150 (epoch 7.244), train_loss = 1.28240125, grad/param norm = 1.5401e-01, time/batch = 0.6686s	
4804/33150 (epoch 7.246), train_loss = 1.36292547, grad/param norm = 1.7535e-01, time/batch = 0.6696s	
4805/33150 (epoch 7.247), train_loss = 1.19958802, grad/param norm = 1.6367e-01, time/batch = 0.6713s	
4806/33150 (epoch 7.249), train_loss = 1.46168292, grad/param norm = 1.6737e-01, time/batch = 0.6685s	
4807/33150 (epoch 7.250), train_loss = 1.37227684, grad/param norm = 1.5111e-01, time/batch = 0.6656s	
4808/33150 (epoch 7.252), train_loss = 1.34848194, grad/param norm = 1.4403e-01, time/batch = 0.6663s	
4809/33150 (epoch 7.253), train_loss = 1.41348231, grad/param norm = 1.7574e-01, time/batch = 0.6682s	
4810/33150 (epoch 7.255), train_loss = 1.31619919, grad/param norm = 1.5683e-01, time/batch = 0.6656s	
4811/33150 (epoch 7.256), train_loss = 1.40297154, grad/param norm = 1.7680e-01, time/batch = 0.6708s	
4812/33150 (epoch 7.258), train_loss = 1.28854569, grad/param norm = 1.8104e-01, time/batch = 0.6679s	
4813/33150 (epoch 7.259), train_loss = 1.12126308, grad/param norm = 1.6769e-01, time/batch = 0.6666s	
4814/33150 (epoch 7.261), train_loss = 1.16509015, grad/param norm = 1.7012e-01, time/batch = 0.6644s	
4815/33150 (epoch 7.262), train_loss = 1.38833704, grad/param norm = 1.7323e-01, time/batch = 0.6689s	
4816/33150 (epoch 7.264), train_loss = 1.03370171, grad/param norm = 1.4685e-01, time/batch = 0.6672s	
4817/33150 (epoch 7.265), train_loss = 1.36706370, grad/param norm = 1.7527e-01, time/batch = 0.6642s	
4818/33150 (epoch 7.267), train_loss = 1.49336831, grad/param norm = 1.8749e-01, time/batch = 0.6649s	
4819/33150 (epoch 7.268), train_loss = 1.27594154, grad/param norm = 1.5653e-01, time/batch = 0.6649s	
4820/33150 (epoch 7.270), train_loss = 1.53688433, grad/param norm = 1.5675e-01, time/batch = 0.6701s	
4821/33150 (epoch 7.271), train_loss = 1.46590426, grad/param norm = 1.7435e-01, time/batch = 0.6686s	
4822/33150 (epoch 7.273), train_loss = 1.40660868, grad/param norm = 1.5964e-01, time/batch = 0.6786s	
4823/33150 (epoch 7.275), train_loss = 1.44969038, grad/param norm = 1.8050e-01, time/batch = 0.6765s	
4824/33150 (epoch 7.276), train_loss = 1.31224882, grad/param norm = 1.6207e-01, time/batch = 0.6962s	
4825/33150 (epoch 7.278), train_loss = 1.44606130, grad/param norm = 1.8413e-01, time/batch = 0.6938s	
4826/33150 (epoch 7.279), train_loss = 1.31246786, grad/param norm = 1.5878e-01, time/batch = 0.6932s	
4827/33150 (epoch 7.281), train_loss = 1.42152701, grad/param norm = 1.8111e-01, time/batch = 0.7007s	
4828/33150 (epoch 7.282), train_loss = 1.33633337, grad/param norm = 1.5282e-01, time/batch = 0.6857s	
4829/33150 (epoch 7.284), train_loss = 1.28233475, grad/param norm = 1.5494e-01, time/batch = 0.6796s	
4830/33150 (epoch 7.285), train_loss = 1.38180942, grad/param norm = 1.7349e-01, time/batch = 0.6674s	
4831/33150 (epoch 7.287), train_loss = 1.26720849, grad/param norm = 1.5919e-01, time/batch = 0.6712s	
4832/33150 (epoch 7.288), train_loss = 1.54821441, grad/param norm = 1.8648e-01, time/batch = 0.6937s	
4833/33150 (epoch 7.290), train_loss = 1.19251705, grad/param norm = 1.6412e-01, time/batch = 0.6803s	
4834/33150 (epoch 7.291), train_loss = 1.21406875, grad/param norm = 1.5984e-01, time/batch = 0.6650s	
4835/33150 (epoch 7.293), train_loss = 1.39644225, grad/param norm = 1.5910e-01, time/batch = 0.6676s	
4836/33150 (epoch 7.294), train_loss = 1.05779329, grad/param norm = 1.4687e-01, time/batch = 0.6970s	
4837/33150 (epoch 7.296), train_loss = 1.26746608, grad/param norm = 1.5966e-01, time/batch = 0.6718s	
4838/33150 (epoch 7.297), train_loss = 1.28895838, grad/param norm = 1.7429e-01, time/batch = 0.6720s	
4839/33150 (epoch 7.299), train_loss = 1.23996062, grad/param norm = 1.7294e-01, time/batch = 0.6693s	
4840/33150 (epoch 7.300), train_loss = 1.27477366, grad/param norm = 1.5119e-01, time/batch = 0.6664s	
4841/33150 (epoch 7.302), train_loss = 1.27001642, grad/param norm = 1.6249e-01, time/batch = 0.6731s	
4842/33150 (epoch 7.303), train_loss = 1.39509038, grad/param norm = 1.8090e-01, time/batch = 0.6690s	
4843/33150 (epoch 7.305), train_loss = 1.35814099, grad/param norm = 1.6214e-01, time/batch = 0.6706s	
4844/33150 (epoch 7.306), train_loss = 1.38458095, grad/param norm = 1.7732e-01, time/batch = 0.6738s	
4845/33150 (epoch 7.308), train_loss = 1.57424943, grad/param norm = 1.7820e-01, time/batch = 0.6654s	
4846/33150 (epoch 7.309), train_loss = 1.18351301, grad/param norm = 1.5361e-01, time/batch = 0.6791s	
4847/33150 (epoch 7.311), train_loss = 1.33682910, grad/param norm = 1.7603e-01, time/batch = 0.6671s	
4848/33150 (epoch 7.312), train_loss = 1.14988875, grad/param norm = 1.6342e-01, time/batch = 0.6646s	
4849/33150 (epoch 7.314), train_loss = 1.34072005, grad/param norm = 1.7404e-01, time/batch = 0.6623s	
4850/33150 (epoch 7.315), train_loss = 1.42696233, grad/param norm = 1.7097e-01, time/batch = 0.6629s	
4851/33150 (epoch 7.317), train_loss = 1.06669203, grad/param norm = 1.3813e-01, time/batch = 0.6704s	
4852/33150 (epoch 7.318), train_loss = 1.20686124, grad/param norm = 1.4882e-01, time/batch = 0.6806s	
4853/33150 (epoch 7.320), train_loss = 1.17295233, grad/param norm = 1.6178e-01, time/batch = 0.6691s	
4854/33150 (epoch 7.321), train_loss = 1.24921204, grad/param norm = 1.5689e-01, time/batch = 0.6730s	
4855/33150 (epoch 7.323), train_loss = 1.31459775, grad/param norm = 1.5987e-01, time/batch = 0.6719s	
4856/33150 (epoch 7.324), train_loss = 1.43007615, grad/param norm = 1.8321e-01, time/batch = 0.6678s	
4857/33150 (epoch 7.326), train_loss = 1.35247634, grad/param norm = 1.5829e-01, time/batch = 0.6680s	
4858/33150 (epoch 7.327), train_loss = 1.42889745, grad/param norm = 1.5795e-01, time/batch = 0.6638s	
4859/33150 (epoch 7.329), train_loss = 1.36685462, grad/param norm = 1.5934e-01, time/batch = 0.6662s	
4860/33150 (epoch 7.330), train_loss = 1.37954427, grad/param norm = 1.8411e-01, time/batch = 0.6665s	
4861/33150 (epoch 7.332), train_loss = 1.29369067, grad/param norm = 1.5372e-01, time/batch = 0.6660s	
4862/33150 (epoch 7.333), train_loss = 1.35418678, grad/param norm = 1.5311e-01, time/batch = 0.6651s	
4863/33150 (epoch 7.335), train_loss = 1.29221335, grad/param norm = 1.6429e-01, time/batch = 0.6674s	
4864/33150 (epoch 7.336), train_loss = 1.20735816, grad/param norm = 1.5037e-01, time/batch = 0.6652s	
4865/33150 (epoch 7.338), train_loss = 1.08616369, grad/param norm = 1.5509e-01, time/batch = 0.6687s	
4866/33150 (epoch 7.339), train_loss = 1.43534833, grad/param norm = 1.6897e-01, time/batch = 0.6676s	
4867/33150 (epoch 7.341), train_loss = 1.53056894, grad/param norm = 1.9994e-01, time/batch = 0.6694s	
4868/33150 (epoch 7.342), train_loss = 1.17470911, grad/param norm = 1.6298e-01, time/batch = 0.6881s	
4869/33150 (epoch 7.344), train_loss = 1.37703682, grad/param norm = 1.6218e-01, time/batch = 0.6813s	
4870/33150 (epoch 7.345), train_loss = 1.20544668, grad/param norm = 1.6109e-01, time/batch = 0.6802s	
4871/33150 (epoch 7.347), train_loss = 1.07370421, grad/param norm = 1.4839e-01, time/batch = 0.6768s	
4872/33150 (epoch 7.348), train_loss = 1.32486086, grad/param norm = 1.7268e-01, time/batch = 0.6820s	
4873/33150 (epoch 7.350), train_loss = 1.32119928, grad/param norm = 1.7737e-01, time/batch = 0.6709s	
4874/33150 (epoch 7.351), train_loss = 1.41269884, grad/param norm = 1.6707e-01, time/batch = 0.6754s	
4875/33150 (epoch 7.353), train_loss = 1.44579628, grad/param norm = 1.8038e-01, time/batch = 0.6804s	
4876/33150 (epoch 7.354), train_loss = 1.59992280, grad/param norm = 1.8198e-01, time/batch = 0.6726s	
4877/33150 (epoch 7.356), train_loss = 1.44493763, grad/param norm = 1.8463e-01, time/batch = 0.6738s	
4878/33150 (epoch 7.357), train_loss = 1.44722647, grad/param norm = 1.7516e-01, time/batch = 0.6749s	
4879/33150 (epoch 7.359), train_loss = 1.39798914, grad/param norm = 1.7062e-01, time/batch = 0.6715s	
4880/33150 (epoch 7.360), train_loss = 1.47238450, grad/param norm = 1.8810e-01, time/batch = 0.6719s	
4881/33150 (epoch 7.362), train_loss = 1.38927389, grad/param norm = 1.7407e-01, time/batch = 0.6778s	
4882/33150 (epoch 7.363), train_loss = 1.30622994, grad/param norm = 1.6671e-01, time/batch = 0.6788s	
4883/33150 (epoch 7.365), train_loss = 1.30716182, grad/param norm = 1.5647e-01, time/batch = 0.6727s	
4884/33150 (epoch 7.367), train_loss = 1.20193927, grad/param norm = 1.5787e-01, time/batch = 0.6722s	
4885/33150 (epoch 7.368), train_loss = 1.32682168, grad/param norm = 1.6371e-01, time/batch = 0.6705s	
4886/33150 (epoch 7.370), train_loss = 1.42873097, grad/param norm = 1.8921e-01, time/batch = 0.6674s	
4887/33150 (epoch 7.371), train_loss = 1.22557821, grad/param norm = 1.5649e-01, time/batch = 0.6680s	
4888/33150 (epoch 7.373), train_loss = 1.43780542, grad/param norm = 1.8948e-01, time/batch = 0.6675s	
4889/33150 (epoch 7.374), train_loss = 1.26338860, grad/param norm = 1.6013e-01, time/batch = 0.6684s	
4890/33150 (epoch 7.376), train_loss = 1.47540076, grad/param norm = 1.5685e-01, time/batch = 0.6686s	
4891/33150 (epoch 7.377), train_loss = 1.33346414, grad/param norm = 1.7801e-01, time/batch = 0.6758s	
4892/33150 (epoch 7.379), train_loss = 1.41617043, grad/param norm = 1.8189e-01, time/batch = 0.6768s	
4893/33150 (epoch 7.380), train_loss = 1.44251430, grad/param norm = 1.6752e-01, time/batch = 0.6711s	
4894/33150 (epoch 7.382), train_loss = 1.21375385, grad/param norm = 1.4298e-01, time/batch = 0.6681s	
4895/33150 (epoch 7.383), train_loss = 1.21551849, grad/param norm = 1.5852e-01, time/batch = 0.6713s	
4896/33150 (epoch 7.385), train_loss = 1.34790124, grad/param norm = 1.6556e-01, time/batch = 0.6804s	
4897/33150 (epoch 7.386), train_loss = 1.18838505, grad/param norm = 1.6256e-01, time/batch = 0.6779s	
4898/33150 (epoch 7.388), train_loss = 1.30308954, grad/param norm = 1.6334e-01, time/batch = 0.6709s	
4899/33150 (epoch 7.389), train_loss = 1.27166488, grad/param norm = 1.6845e-01, time/batch = 0.6678s	
4900/33150 (epoch 7.391), train_loss = 1.50786964, grad/param norm = 1.7502e-01, time/batch = 0.6703s	
4901/33150 (epoch 7.392), train_loss = 1.25595147, grad/param norm = 1.5552e-01, time/batch = 0.6711s	
4902/33150 (epoch 7.394), train_loss = 1.14880796, grad/param norm = 1.3454e-01, time/batch = 0.6673s	
4903/33150 (epoch 7.395), train_loss = 1.24803768, grad/param norm = 1.8517e-01, time/batch = 0.6657s	
4904/33150 (epoch 7.397), train_loss = 1.02825544, grad/param norm = 1.3989e-01, time/batch = 0.6799s	
4905/33150 (epoch 7.398), train_loss = 1.35887736, grad/param norm = 1.8150e-01, time/batch = 0.6883s	
4906/33150 (epoch 7.400), train_loss = 1.28227068, grad/param norm = 1.5420e-01, time/batch = 0.6890s	
4907/33150 (epoch 7.401), train_loss = 1.12257987, grad/param norm = 1.4415e-01, time/batch = 0.6872s	
4908/33150 (epoch 7.403), train_loss = 1.20269116, grad/param norm = 1.4858e-01, time/batch = 0.6739s	
4909/33150 (epoch 7.404), train_loss = 1.26648788, grad/param norm = 1.5386e-01, time/batch = 0.6743s	
4910/33150 (epoch 7.406), train_loss = 1.17490777, grad/param norm = 1.3594e-01, time/batch = 0.6658s	
4911/33150 (epoch 7.407), train_loss = 1.17607906, grad/param norm = 1.4581e-01, time/batch = 0.6659s	
4912/33150 (epoch 7.409), train_loss = 1.09109041, grad/param norm = 1.5131e-01, time/batch = 0.6668s	
4913/33150 (epoch 7.410), train_loss = 1.38658512, grad/param norm = 1.8694e-01, time/batch = 0.6632s	
4914/33150 (epoch 7.412), train_loss = 1.40076404, grad/param norm = 1.7459e-01, time/batch = 0.6839s	
4915/33150 (epoch 7.413), train_loss = 1.26878378, grad/param norm = 1.6805e-01, time/batch = 0.6884s	
4916/33150 (epoch 7.415), train_loss = 1.44346888, grad/param norm = 1.6444e-01, time/batch = 0.6744s	
4917/33150 (epoch 7.416), train_loss = 1.26488103, grad/param norm = 1.5138e-01, time/batch = 0.6630s	
4918/33150 (epoch 7.418), train_loss = 1.54911407, grad/param norm = 2.2091e-01, time/batch = 0.6654s	
4919/33150 (epoch 7.419), train_loss = 1.21910657, grad/param norm = 1.6417e-01, time/batch = 0.6702s	
4920/33150 (epoch 7.421), train_loss = 1.35823531, grad/param norm = 1.6802e-01, time/batch = 0.6703s	
4921/33150 (epoch 7.422), train_loss = 1.22394431, grad/param norm = 1.6093e-01, time/batch = 0.6668s	
4922/33150 (epoch 7.424), train_loss = 1.28504662, grad/param norm = 1.7778e-01, time/batch = 0.6697s	
4923/33150 (epoch 7.425), train_loss = 1.26377539, grad/param norm = 1.8054e-01, time/batch = 0.6691s	
4924/33150 (epoch 7.427), train_loss = 1.24167419, grad/param norm = 1.5794e-01, time/batch = 0.6660s	
4925/33150 (epoch 7.428), train_loss = 1.30339610, grad/param norm = 1.6098e-01, time/batch = 0.6951s	
4926/33150 (epoch 7.430), train_loss = 1.35947975, grad/param norm = 1.7297e-01, time/batch = 0.6754s	
4927/33150 (epoch 7.431), train_loss = 1.41077733, grad/param norm = 1.8110e-01, time/batch = 0.6741s	
4928/33150 (epoch 7.433), train_loss = 1.32300601, grad/param norm = 1.5467e-01, time/batch = 0.6696s	
4929/33150 (epoch 7.434), train_loss = 1.17852232, grad/param norm = 1.7142e-01, time/batch = 0.6706s	
4930/33150 (epoch 7.436), train_loss = 1.13232891, grad/param norm = 1.6055e-01, time/batch = 0.6696s	
4931/33150 (epoch 7.437), train_loss = 1.35570757, grad/param norm = 1.9609e-01, time/batch = 0.6716s	
4932/33150 (epoch 7.439), train_loss = 1.44144694, grad/param norm = 1.8021e-01, time/batch = 0.6691s	
4933/33150 (epoch 7.440), train_loss = 1.44465476, grad/param norm = 1.8379e-01, time/batch = 0.6695s	
4934/33150 (epoch 7.442), train_loss = 1.15949286, grad/param norm = 1.7485e-01, time/batch = 0.6696s	
4935/33150 (epoch 7.443), train_loss = 1.41508976, grad/param norm = 1.7360e-01, time/batch = 0.6779s	
4936/33150 (epoch 7.445), train_loss = 1.34275016, grad/param norm = 1.7119e-01, time/batch = 0.6683s	
4937/33150 (epoch 7.446), train_loss = 1.38475126, grad/param norm = 2.0425e-01, time/batch = 0.6685s	
4938/33150 (epoch 7.448), train_loss = 1.37773479, grad/param norm = 1.7185e-01, time/batch = 0.6664s	
4939/33150 (epoch 7.449), train_loss = 1.26803802, grad/param norm = 1.5607e-01, time/batch = 0.6670s	
4940/33150 (epoch 7.451), train_loss = 1.40340262, grad/param norm = 1.9362e-01, time/batch = 0.6805s	
4941/33150 (epoch 7.452), train_loss = 1.57459871, grad/param norm = 1.6837e-01, time/batch = 0.6804s	
4942/33150 (epoch 7.454), train_loss = 1.29632530, grad/param norm = 1.6895e-01, time/batch = 0.6698s	
4943/33150 (epoch 7.456), train_loss = 1.06440882, grad/param norm = 1.4659e-01, time/batch = 0.6686s	
4944/33150 (epoch 7.457), train_loss = 1.33783029, grad/param norm = 1.6702e-01, time/batch = 0.6760s	
4945/33150 (epoch 7.459), train_loss = 1.50607204, grad/param norm = 1.9381e-01, time/batch = 0.6710s	
4946/33150 (epoch 7.460), train_loss = 1.34687122, grad/param norm = 1.5408e-01, time/batch = 0.6688s	
4947/33150 (epoch 7.462), train_loss = 1.45327243, grad/param norm = 1.9266e-01, time/batch = 0.6670s	
4948/33150 (epoch 7.463), train_loss = 1.65681906, grad/param norm = 2.0988e-01, time/batch = 0.6682s	
4949/33150 (epoch 7.465), train_loss = 1.21628619, grad/param norm = 1.5634e-01, time/batch = 0.6918s	
4950/33150 (epoch 7.466), train_loss = 1.27941404, grad/param norm = 1.6874e-01, time/batch = 0.6752s	
4951/33150 (epoch 7.468), train_loss = 1.63235508, grad/param norm = 1.8357e-01, time/batch = 0.6778s	
4952/33150 (epoch 7.469), train_loss = 1.40346912, grad/param norm = 1.7640e-01, time/batch = 0.6706s	
4953/33150 (epoch 7.471), train_loss = 1.27398296, grad/param norm = 1.6971e-01, time/batch = 0.6817s	
4954/33150 (epoch 7.472), train_loss = 1.25547107, grad/param norm = 1.5473e-01, time/batch = 0.6671s	
4955/33150 (epoch 7.474), train_loss = 1.41681547, grad/param norm = 1.8706e-01, time/batch = 0.6755s	
4956/33150 (epoch 7.475), train_loss = 1.61724701, grad/param norm = 1.7809e-01, time/batch = 0.6766s	
4957/33150 (epoch 7.477), train_loss = 1.38800754, grad/param norm = 1.8470e-01, time/batch = 0.6677s	
4958/33150 (epoch 7.478), train_loss = 1.42665691, grad/param norm = 1.6411e-01, time/batch = 0.6668s	
4959/33150 (epoch 7.480), train_loss = 1.24125598, grad/param norm = 1.5355e-01, time/batch = 0.6689s	
4960/33150 (epoch 7.481), train_loss = 1.13712376, grad/param norm = 1.5676e-01, time/batch = 0.6616s	
4961/33150 (epoch 7.483), train_loss = 1.25788425, grad/param norm = 1.8199e-01, time/batch = 0.6625s	
4962/33150 (epoch 7.484), train_loss = 1.22174708, grad/param norm = 1.5076e-01, time/batch = 0.6621s	
4963/33150 (epoch 7.486), train_loss = 1.32593653, grad/param norm = 1.6583e-01, time/batch = 0.6694s	
4964/33150 (epoch 7.487), train_loss = 1.41183281, grad/param norm = 1.6928e-01, time/batch = 0.6765s	
4965/33150 (epoch 7.489), train_loss = 1.32104666, grad/param norm = 1.6994e-01, time/batch = 0.6678s	
4966/33150 (epoch 7.490), train_loss = 1.16723957, grad/param norm = 1.5010e-01, time/batch = 0.6660s	
4967/33150 (epoch 7.492), train_loss = 1.27242379, grad/param norm = 1.7757e-01, time/batch = 0.6676s	
4968/33150 (epoch 7.493), train_loss = 1.44278967, grad/param norm = 1.8384e-01, time/batch = 0.6719s	
4969/33150 (epoch 7.495), train_loss = 1.41642479, grad/param norm = 1.6079e-01, time/batch = 0.6665s	
4970/33150 (epoch 7.496), train_loss = 1.22522047, grad/param norm = 1.7516e-01, time/batch = 0.6765s	
4971/33150 (epoch 7.498), train_loss = 1.46104246, grad/param norm = 1.9839e-01, time/batch = 0.6772s	
4972/33150 (epoch 7.499), train_loss = 1.53147079, grad/param norm = 1.9304e-01, time/batch = 0.6691s	
4973/33150 (epoch 7.501), train_loss = 1.37462611, grad/param norm = 1.6337e-01, time/batch = 0.6672s	
4974/33150 (epoch 7.502), train_loss = 1.52249999, grad/param norm = 1.8698e-01, time/batch = 0.6684s	
4975/33150 (epoch 7.504), train_loss = 1.41465388, grad/param norm = 1.7815e-01, time/batch = 0.6614s	
4976/33150 (epoch 7.505), train_loss = 1.60638640, grad/param norm = 1.9952e-01, time/batch = 0.6609s	
4977/33150 (epoch 7.507), train_loss = 1.26738172, grad/param norm = 1.8167e-01, time/batch = 0.6646s	
4978/33150 (epoch 7.508), train_loss = 1.23780244, grad/param norm = 1.6087e-01, time/batch = 0.6630s	
4979/33150 (epoch 7.510), train_loss = 1.31822385, grad/param norm = 1.6174e-01, time/batch = 0.6629s	
4980/33150 (epoch 7.511), train_loss = 1.56895970, grad/param norm = 1.8871e-01, time/batch = 0.6660s	
4981/33150 (epoch 7.513), train_loss = 1.39464518, grad/param norm = 1.7499e-01, time/batch = 0.6632s	
4982/33150 (epoch 7.514), train_loss = 1.12634820, grad/param norm = 1.6607e-01, time/batch = 0.6677s	
4983/33150 (epoch 7.516), train_loss = 1.50126001, grad/param norm = 2.0329e-01, time/batch = 0.6672s	
4984/33150 (epoch 7.517), train_loss = 1.47041137, grad/param norm = 1.6510e-01, time/batch = 0.6659s	
4985/33150 (epoch 7.519), train_loss = 1.27719696, grad/param norm = 1.6180e-01, time/batch = 0.6797s	
4986/33150 (epoch 7.520), train_loss = 1.36214574, grad/param norm = 1.6134e-01, time/batch = 0.6738s	
4987/33150 (epoch 7.522), train_loss = 1.53675615, grad/param norm = 2.0266e-01, time/batch = 0.6685s	
4988/33150 (epoch 7.523), train_loss = 1.22150900, grad/param norm = 1.8261e-01, time/batch = 0.6782s	
4989/33150 (epoch 7.525), train_loss = 1.35018621, grad/param norm = 1.5738e-01, time/batch = 0.6668s	
4990/33150 (epoch 7.526), train_loss = 1.21322510, grad/param norm = 1.5608e-01, time/batch = 0.6627s	
4991/33150 (epoch 7.528), train_loss = 1.39402879, grad/param norm = 1.9462e-01, time/batch = 0.6699s	
4992/33150 (epoch 7.529), train_loss = 1.41336345, grad/param norm = 1.6510e-01, time/batch = 0.6697s	
4993/33150 (epoch 7.531), train_loss = 1.16115467, grad/param norm = 1.6604e-01, time/batch = 0.6795s	
4994/33150 (epoch 7.532), train_loss = 1.36207032, grad/param norm = 1.7032e-01, time/batch = 0.6781s	
4995/33150 (epoch 7.534), train_loss = 1.24333916, grad/param norm = 1.4982e-01, time/batch = 0.6697s	
4996/33150 (epoch 7.535), train_loss = 1.23402521, grad/param norm = 1.7128e-01, time/batch = 0.6719s	
4997/33150 (epoch 7.537), train_loss = 1.49512570, grad/param norm = 1.8226e-01, time/batch = 0.6690s	
4998/33150 (epoch 7.538), train_loss = 1.30159751, grad/param norm = 1.7446e-01, time/batch = 0.6693s	
4999/33150 (epoch 7.540), train_loss = 1.14795526, grad/param norm = 1.6688e-01, time/batch = 0.6696s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch7.54_1.5533.t7	
5000/33150 (epoch 7.541), train_loss = 1.38458037, grad/param norm = 1.7322e-01, time/batch = 0.6693s	
5001/33150 (epoch 7.543), train_loss = 1.71656038, grad/param norm = 1.9816e-01, time/batch = 0.6924s	
5002/33150 (epoch 7.544), train_loss = 1.33324372, grad/param norm = 1.5945e-01, time/batch = 0.6726s	
5003/33150 (epoch 7.546), train_loss = 1.55138414, grad/param norm = 1.8846e-01, time/batch = 0.6800s	
5004/33150 (epoch 7.548), train_loss = 1.40124828, grad/param norm = 1.9406e-01, time/batch = 0.6739s	
5005/33150 (epoch 7.549), train_loss = 1.35310187, grad/param norm = 1.9981e-01, time/batch = 0.6714s	
5006/33150 (epoch 7.551), train_loss = 1.23523191, grad/param norm = 1.6896e-01, time/batch = 0.6693s	
5007/33150 (epoch 7.552), train_loss = 1.11671049, grad/param norm = 1.3888e-01, time/batch = 0.6708s	
5008/33150 (epoch 7.554), train_loss = 1.35096102, grad/param norm = 1.6511e-01, time/batch = 0.6734s	
5009/33150 (epoch 7.555), train_loss = 1.55569164, grad/param norm = 1.8618e-01, time/batch = 0.6998s	
5010/33150 (epoch 7.557), train_loss = 1.15978779, grad/param norm = 1.7142e-01, time/batch = 0.6705s	
5011/33150 (epoch 7.558), train_loss = 1.44099313, grad/param norm = 1.9317e-01, time/batch = 0.6727s	
5012/33150 (epoch 7.560), train_loss = 1.29635463, grad/param norm = 1.7272e-01, time/batch = 0.6691s	
5013/33150 (epoch 7.561), train_loss = 1.12924162, grad/param norm = 1.5024e-01, time/batch = 0.6700s	
5014/33150 (epoch 7.563), train_loss = 1.46330393, grad/param norm = 2.0919e-01, time/batch = 0.6671s	
5015/33150 (epoch 7.564), train_loss = 1.53040523, grad/param norm = 1.6945e-01, time/batch = 0.6681s	
5016/33150 (epoch 7.566), train_loss = 1.30835656, grad/param norm = 1.6766e-01, time/batch = 0.6673s	
5017/33150 (epoch 7.567), train_loss = 1.22900118, grad/param norm = 1.6082e-01, time/batch = 0.6702s	
5018/33150 (epoch 7.569), train_loss = 1.31939591, grad/param norm = 1.5547e-01, time/batch = 0.6675s	
5019/33150 (epoch 7.570), train_loss = 1.32645253, grad/param norm = 1.5155e-01, time/batch = 0.6690s	
5020/33150 (epoch 7.572), train_loss = 1.24517015, grad/param norm = 1.6648e-01, time/batch = 0.6666s	
5021/33150 (epoch 7.573), train_loss = 1.06153139, grad/param norm = 1.3884e-01, time/batch = 0.6672s	
5022/33150 (epoch 7.575), train_loss = 1.36575358, grad/param norm = 1.6378e-01, time/batch = 0.6649s	
5023/33150 (epoch 7.576), train_loss = 1.10782417, grad/param norm = 1.3376e-01, time/batch = 0.6683s	
5024/33150 (epoch 7.578), train_loss = 1.27711763, grad/param norm = 1.3631e-01, time/batch = 0.6711s	
5025/33150 (epoch 7.579), train_loss = 1.17753222, grad/param norm = 1.5160e-01, time/batch = 0.6804s	
5026/33150 (epoch 7.581), train_loss = 1.18701899, grad/param norm = 1.6850e-01, time/batch = 0.6723s	
5027/33150 (epoch 7.582), train_loss = 1.34533901, grad/param norm = 1.5772e-01, time/batch = 0.6654s	
5028/33150 (epoch 7.584), train_loss = 1.39302988, grad/param norm = 1.6394e-01, time/batch = 0.6675s	
5029/33150 (epoch 7.585), train_loss = 1.33792209, grad/param norm = 1.6391e-01, time/batch = 0.6686s	
5030/33150 (epoch 7.587), train_loss = 1.38392583, grad/param norm = 1.6726e-01, time/batch = 0.6694s	
5031/33150 (epoch 7.588), train_loss = 1.20587356, grad/param norm = 1.6659e-01, time/batch = 0.6658s	
5032/33150 (epoch 7.590), train_loss = 1.33480364, grad/param norm = 1.7917e-01, time/batch = 0.6671s	
5033/33150 (epoch 7.591), train_loss = 1.34552038, grad/param norm = 1.6039e-01, time/batch = 0.6636s	
5034/33150 (epoch 7.593), train_loss = 1.40766975, grad/param norm = 1.7498e-01, time/batch = 0.6659s	
5035/33150 (epoch 7.594), train_loss = 1.34916535, grad/param norm = 1.7084e-01, time/batch = 0.6679s	
5036/33150 (epoch 7.596), train_loss = 1.19025707, grad/param norm = 1.5588e-01, time/batch = 0.6697s	
5037/33150 (epoch 7.597), train_loss = 1.26207723, grad/param norm = 1.8767e-01, time/batch = 0.6708s	
5038/33150 (epoch 7.599), train_loss = 1.53729025, grad/param norm = 1.7868e-01, time/batch = 0.6782s	
5039/33150 (epoch 7.600), train_loss = 1.38993366, grad/param norm = 1.9331e-01, time/batch = 0.6768s	
5040/33150 (epoch 7.602), train_loss = 1.22273650, grad/param norm = 1.5801e-01, time/batch = 0.6789s	
5041/33150 (epoch 7.603), train_loss = 1.36096064, grad/param norm = 1.8845e-01, time/batch = 0.6734s	
5042/33150 (epoch 7.605), train_loss = 1.21231036, grad/param norm = 1.5518e-01, time/batch = 0.6747s	
5043/33150 (epoch 7.606), train_loss = 1.35519447, grad/param norm = 1.9573e-01, time/batch = 0.6726s	
5044/33150 (epoch 7.608), train_loss = 1.36420741, grad/param norm = 1.7400e-01, time/batch = 0.6713s	
5045/33150 (epoch 7.609), train_loss = 1.31179043, grad/param norm = 1.8093e-01, time/batch = 0.6732s	
5046/33150 (epoch 7.611), train_loss = 1.12066559, grad/param norm = 1.6514e-01, time/batch = 0.6725s	
5047/33150 (epoch 7.612), train_loss = 1.30803825, grad/param norm = 1.7152e-01, time/batch = 0.6733s	
5048/33150 (epoch 7.614), train_loss = 1.12366679, grad/param norm = 1.5321e-01, time/batch = 0.6723s	
5049/33150 (epoch 7.615), train_loss = 1.15104466, grad/param norm = 1.4636e-01, time/batch = 0.6697s	
5050/33150 (epoch 7.617), train_loss = 1.27576361, grad/param norm = 1.7105e-01, time/batch = 0.6704s	
5051/33150 (epoch 7.618), train_loss = 1.30023494, grad/param norm = 1.7447e-01, time/batch = 0.6780s	
5052/33150 (epoch 7.620), train_loss = 1.24259475, grad/param norm = 1.7427e-01, time/batch = 0.6824s	
5053/33150 (epoch 7.621), train_loss = 1.23287577, grad/param norm = 1.5906e-01, time/batch = 0.6870s	
5054/33150 (epoch 7.623), train_loss = 1.35740745, grad/param norm = 1.7571e-01, time/batch = 0.6817s	
5055/33150 (epoch 7.624), train_loss = 1.25590167, grad/param norm = 1.8740e-01, time/batch = 0.6859s	
5056/33150 (epoch 7.626), train_loss = 1.19652112, grad/param norm = 1.5649e-01, time/batch = 0.6831s	
5057/33150 (epoch 7.627), train_loss = 1.15916545, grad/param norm = 1.6276e-01, time/batch = 0.6832s	
5058/33150 (epoch 7.629), train_loss = 1.14392610, grad/param norm = 1.4742e-01, time/batch = 0.6736s	
5059/33150 (epoch 7.630), train_loss = 1.18197321, grad/param norm = 1.3929e-01, time/batch = 0.6641s	
5060/33150 (epoch 7.632), train_loss = 1.11079153, grad/param norm = 1.3883e-01, time/batch = 0.6636s	
5061/33150 (epoch 7.633), train_loss = 1.14415949, grad/param norm = 1.7154e-01, time/batch = 0.6630s	
5062/33150 (epoch 7.635), train_loss = 1.51527255, grad/param norm = 1.7132e-01, time/batch = 0.6645s	
5063/33150 (epoch 7.637), train_loss = 1.11587416, grad/param norm = 1.5985e-01, time/batch = 0.6699s	
5064/33150 (epoch 7.638), train_loss = 1.24165920, grad/param norm = 1.5814e-01, time/batch = 0.6696s	
5065/33150 (epoch 7.640), train_loss = 1.41167399, grad/param norm = 1.6797e-01, time/batch = 0.6706s	
5066/33150 (epoch 7.641), train_loss = 1.19241321, grad/param norm = 1.6269e-01, time/batch = 0.6702s	
5067/33150 (epoch 7.643), train_loss = 1.22080396, grad/param norm = 1.5875e-01, time/batch = 0.6662s	
5068/33150 (epoch 7.644), train_loss = 1.41014443, grad/param norm = 1.5824e-01, time/batch = 0.6699s	
5069/33150 (epoch 7.646), train_loss = 1.22811978, grad/param norm = 1.6647e-01, time/batch = 0.6803s	
5070/33150 (epoch 7.647), train_loss = 1.61210781, grad/param norm = 1.8775e-01, time/batch = 0.6710s	
5071/33150 (epoch 7.649), train_loss = 1.41161735, grad/param norm = 1.8560e-01, time/batch = 0.6676s	
5072/33150 (epoch 7.650), train_loss = 1.15031373, grad/param norm = 1.5179e-01, time/batch = 0.6684s	
5073/33150 (epoch 7.652), train_loss = 1.38183552, grad/param norm = 1.7829e-01, time/batch = 0.6661s	
5074/33150 (epoch 7.653), train_loss = 1.27294937, grad/param norm = 1.5281e-01, time/batch = 0.6795s	
5075/33150 (epoch 7.655), train_loss = 1.36843515, grad/param norm = 1.7790e-01, time/batch = 0.6781s	
5076/33150 (epoch 7.656), train_loss = 1.26150874, grad/param norm = 1.4764e-01, time/batch = 0.6656s	
5077/33150 (epoch 7.658), train_loss = 1.34416538, grad/param norm = 2.0050e-01, time/batch = 0.6673s	
5078/33150 (epoch 7.659), train_loss = 1.69429434, grad/param norm = 3.6103e-01, time/batch = 0.6669s	
5079/33150 (epoch 7.661), train_loss = 1.27110955, grad/param norm = 1.5691e-01, time/batch = 0.6664s	
5080/33150 (epoch 7.662), train_loss = 1.14035888, grad/param norm = 1.8947e-01, time/batch = 0.6694s	
5081/33150 (epoch 7.664), train_loss = 1.40470912, grad/param norm = 1.6138e-01, time/batch = 0.6748s	
5082/33150 (epoch 7.665), train_loss = 1.35203479, grad/param norm = 1.7944e-01, time/batch = 0.6813s	
5083/33150 (epoch 7.667), train_loss = 1.46618571, grad/param norm = 1.7237e-01, time/batch = 0.6857s	
5084/33150 (epoch 7.668), train_loss = 1.37312914, grad/param norm = 1.6560e-01, time/batch = 0.6845s	
5085/33150 (epoch 7.670), train_loss = 1.24513663, grad/param norm = 1.4761e-01, time/batch = 0.6797s	
5086/33150 (epoch 7.671), train_loss = 1.24732303, grad/param norm = 1.7314e-01, time/batch = 0.6687s	
5087/33150 (epoch 7.673), train_loss = 1.38436160, grad/param norm = 1.5068e-01, time/batch = 0.6668s	
5088/33150 (epoch 7.674), train_loss = 1.30552689, grad/param norm = 1.6335e-01, time/batch = 0.6702s	
5089/33150 (epoch 7.676), train_loss = 1.24922113, grad/param norm = 1.5982e-01, time/batch = 0.6702s	
5090/33150 (epoch 7.677), train_loss = 1.62432392, grad/param norm = 1.7729e-01, time/batch = 0.6688s	
5091/33150 (epoch 7.679), train_loss = 1.17442446, grad/param norm = 1.4574e-01, time/batch = 0.6686s	
5092/33150 (epoch 7.680), train_loss = 1.42384907, grad/param norm = 1.7046e-01, time/batch = 0.6680s	
5093/33150 (epoch 7.682), train_loss = 1.18114153, grad/param norm = 1.5113e-01, time/batch = 0.6694s	
5094/33150 (epoch 7.683), train_loss = 1.10802484, grad/param norm = 1.4471e-01, time/batch = 0.6658s	
5095/33150 (epoch 7.685), train_loss = 1.34193647, grad/param norm = 1.7131e-01, time/batch = 0.6659s	
5096/33150 (epoch 7.686), train_loss = 1.11500295, grad/param norm = 1.7708e-01, time/batch = 0.6669s	
5097/33150 (epoch 7.688), train_loss = 1.24166998, grad/param norm = 1.6506e-01, time/batch = 0.6680s	
5098/33150 (epoch 7.689), train_loss = 1.17784030, grad/param norm = 1.4616e-01, time/batch = 0.6752s	
5099/33150 (epoch 7.691), train_loss = 1.08308328, grad/param norm = 1.4881e-01, time/batch = 0.6844s	
5100/33150 (epoch 7.692), train_loss = 1.20140886, grad/param norm = 1.6171e-01, time/batch = 0.6706s	
5101/33150 (epoch 7.694), train_loss = 1.01639284, grad/param norm = 1.2894e-01, time/batch = 0.6674s	
5102/33150 (epoch 7.695), train_loss = 1.22836397, grad/param norm = 1.5900e-01, time/batch = 0.6654s	
5103/33150 (epoch 7.697), train_loss = 1.10348799, grad/param norm = 1.4148e-01, time/batch = 0.6677s	
5104/33150 (epoch 7.698), train_loss = 1.36907879, grad/param norm = 1.6953e-01, time/batch = 0.6669s	
5105/33150 (epoch 7.700), train_loss = 0.99645556, grad/param norm = 1.3966e-01, time/batch = 0.6787s	
5106/33150 (epoch 7.701), train_loss = 1.16982793, grad/param norm = 1.5295e-01, time/batch = 0.6738s	
5107/33150 (epoch 7.703), train_loss = 1.29698388, grad/param norm = 1.6441e-01, time/batch = 0.6792s	
5108/33150 (epoch 7.704), train_loss = 1.08310894, grad/param norm = 1.4854e-01, time/batch = 0.6769s	
5109/33150 (epoch 7.706), train_loss = 1.22946032, grad/param norm = 1.4689e-01, time/batch = 0.6679s	
5110/33150 (epoch 7.707), train_loss = 1.25936518, grad/param norm = 1.7311e-01, time/batch = 0.6779s	
5111/33150 (epoch 7.709), train_loss = 1.30159292, grad/param norm = 1.4637e-01, time/batch = 0.6690s	
5112/33150 (epoch 7.710), train_loss = 1.38414253, grad/param norm = 1.7769e-01, time/batch = 0.6715s	
5113/33150 (epoch 7.712), train_loss = 1.40489182, grad/param norm = 1.7326e-01, time/batch = 0.6765s	
5114/33150 (epoch 7.713), train_loss = 1.33543154, grad/param norm = 1.6850e-01, time/batch = 0.6787s	
5115/33150 (epoch 7.715), train_loss = 1.20741232, grad/param norm = 1.4275e-01, time/batch = 0.6657s	
5116/33150 (epoch 7.716), train_loss = 1.33616795, grad/param norm = 1.6514e-01, time/batch = 0.6672s	
5117/33150 (epoch 7.718), train_loss = 1.30459347, grad/param norm = 1.5264e-01, time/batch = 0.6684s	
5118/33150 (epoch 7.719), train_loss = 1.42203580, grad/param norm = 1.8547e-01, time/batch = 0.6684s	
5119/33150 (epoch 7.721), train_loss = 1.27880308, grad/param norm = 1.7689e-01, time/batch = 0.6684s	
5120/33150 (epoch 7.722), train_loss = 1.31018045, grad/param norm = 1.6817e-01, time/batch = 0.6676s	
5121/33150 (epoch 7.724), train_loss = 1.24412488, grad/param norm = 1.5021e-01, time/batch = 0.6707s	
5122/33150 (epoch 7.725), train_loss = 1.50760582, grad/param norm = 1.8277e-01, time/batch = 0.6736s	
5123/33150 (epoch 7.727), train_loss = 1.34977017, grad/param norm = 1.9472e-01, time/batch = 0.6679s	
5124/33150 (epoch 7.729), train_loss = 1.32043480, grad/param norm = 1.6428e-01, time/batch = 0.6672s	
5125/33150 (epoch 7.730), train_loss = 1.31163618, grad/param norm = 1.6591e-01, time/batch = 0.6684s	
5126/33150 (epoch 7.732), train_loss = 1.39118337, grad/param norm = 1.6266e-01, time/batch = 0.6698s	
5127/33150 (epoch 7.733), train_loss = 1.05798509, grad/param norm = 1.2579e-01, time/batch = 0.6703s	
5128/33150 (epoch 7.735), train_loss = 1.25969284, grad/param norm = 1.5108e-01, time/batch = 0.6712s	
5129/33150 (epoch 7.736), train_loss = 1.21092180, grad/param norm = 1.7639e-01, time/batch = 0.6684s	
5130/33150 (epoch 7.738), train_loss = 1.38354962, grad/param norm = 1.8196e-01, time/batch = 0.6701s	
5131/33150 (epoch 7.739), train_loss = 1.44868871, grad/param norm = 1.9189e-01, time/batch = 0.6722s	
5132/33150 (epoch 7.741), train_loss = 1.44753792, grad/param norm = 1.8091e-01, time/batch = 0.6703s	
5133/33150 (epoch 7.742), train_loss = 1.26008116, grad/param norm = 1.6982e-01, time/batch = 0.6664s	
5134/33150 (epoch 7.744), train_loss = 1.44783239, grad/param norm = 1.7563e-01, time/batch = 0.6709s	
5135/33150 (epoch 7.745), train_loss = 1.23978704, grad/param norm = 1.5421e-01, time/batch = 0.6710s	
5136/33150 (epoch 7.747), train_loss = 1.11739163, grad/param norm = 1.5261e-01, time/batch = 0.6675s	
5137/33150 (epoch 7.748), train_loss = 1.22600329, grad/param norm = 1.5363e-01, time/batch = 0.6773s	
5138/33150 (epoch 7.750), train_loss = 1.36878357, grad/param norm = 1.8014e-01, time/batch = 0.6692s	
5139/33150 (epoch 7.751), train_loss = 1.29403666, grad/param norm = 1.6731e-01, time/batch = 0.6727s	
5140/33150 (epoch 7.753), train_loss = 1.12990794, grad/param norm = 1.7093e-01, time/batch = 0.6711s	
5141/33150 (epoch 7.754), train_loss = 1.56051442, grad/param norm = 1.8346e-01, time/batch = 0.6723s	
5142/33150 (epoch 7.756), train_loss = 1.32209659, grad/param norm = 1.7673e-01, time/batch = 0.6774s	
5143/33150 (epoch 7.757), train_loss = 1.33737909, grad/param norm = 1.6595e-01, time/batch = 0.6759s	
5144/33150 (epoch 7.759), train_loss = 1.53449496, grad/param norm = 1.7357e-01, time/batch = 0.6692s	
5145/33150 (epoch 7.760), train_loss = 1.35213359, grad/param norm = 1.6267e-01, time/batch = 0.6677s	
5146/33150 (epoch 7.762), train_loss = 1.35716573, grad/param norm = 1.7856e-01, time/batch = 0.6664s	
5147/33150 (epoch 7.763), train_loss = 1.27452664, grad/param norm = 1.6218e-01, time/batch = 0.6719s	
5148/33150 (epoch 7.765), train_loss = 1.25117697, grad/param norm = 1.5319e-01, time/batch = 0.6797s	
5149/33150 (epoch 7.766), train_loss = 1.19235287, grad/param norm = 1.4621e-01, time/batch = 0.6666s	
5150/33150 (epoch 7.768), train_loss = 1.24035665, grad/param norm = 1.7127e-01, time/batch = 0.6664s	
5151/33150 (epoch 7.769), train_loss = 1.29445408, grad/param norm = 1.6945e-01, time/batch = 0.6676s	
5152/33150 (epoch 7.771), train_loss = 1.31787015, grad/param norm = 1.6772e-01, time/batch = 0.6691s	
5153/33150 (epoch 7.772), train_loss = 1.38527550, grad/param norm = 1.9579e-01, time/batch = 0.6677s	
5154/33150 (epoch 7.774), train_loss = 1.46802075, grad/param norm = 1.7381e-01, time/batch = 0.6654s	
5155/33150 (epoch 7.775), train_loss = 1.35304555, grad/param norm = 1.9558e-01, time/batch = 0.6677s	
5156/33150 (epoch 7.777), train_loss = 1.39921466, grad/param norm = 1.7837e-01, time/batch = 0.6647s	
5157/33150 (epoch 7.778), train_loss = 1.29841606, grad/param norm = 1.4950e-01, time/batch = 0.6663s	
5158/33150 (epoch 7.780), train_loss = 1.18758035, grad/param norm = 1.6021e-01, time/batch = 0.6658s	
5159/33150 (epoch 7.781), train_loss = 1.26548516, grad/param norm = 1.5614e-01, time/batch = 0.6642s	
5160/33150 (epoch 7.783), train_loss = 1.28155508, grad/param norm = 1.4371e-01, time/batch = 0.6711s	
5161/33150 (epoch 7.784), train_loss = 1.24008196, grad/param norm = 1.6035e-01, time/batch = 0.6693s	
5162/33150 (epoch 7.786), train_loss = 1.25955972, grad/param norm = 1.4548e-01, time/batch = 0.6772s	
5163/33150 (epoch 7.787), train_loss = 1.27079986, grad/param norm = 1.6234e-01, time/batch = 0.6789s	
5164/33150 (epoch 7.789), train_loss = 1.11274522, grad/param norm = 1.3544e-01, time/batch = 0.6677s	
5165/33150 (epoch 7.790), train_loss = 1.08239838, grad/param norm = 1.4871e-01, time/batch = 0.6674s	
5166/33150 (epoch 7.792), train_loss = 1.39657794, grad/param norm = 1.9648e-01, time/batch = 0.6650s	
5167/33150 (epoch 7.793), train_loss = 1.26938722, grad/param norm = 1.6440e-01, time/batch = 0.6661s	
5168/33150 (epoch 7.795), train_loss = 1.24105528, grad/param norm = 1.7608e-01, time/batch = 0.6712s	
5169/33150 (epoch 7.796), train_loss = 1.17657468, grad/param norm = 1.4867e-01, time/batch = 0.6705s	
5170/33150 (epoch 7.798), train_loss = 1.23005331, grad/param norm = 1.4843e-01, time/batch = 0.6812s	
5171/33150 (epoch 7.799), train_loss = 1.11989818, grad/param norm = 1.6321e-01, time/batch = 0.6788s	
5172/33150 (epoch 7.801), train_loss = 1.28884369, grad/param norm = 1.5511e-01, time/batch = 0.6874s	
5173/33150 (epoch 7.802), train_loss = 1.20165374, grad/param norm = 1.6993e-01, time/batch = 0.6845s	
5174/33150 (epoch 7.804), train_loss = 1.26846501, grad/param norm = 1.5482e-01, time/batch = 0.6889s	
5175/33150 (epoch 7.805), train_loss = 1.23524136, grad/param norm = 1.6509e-01, time/batch = 0.6764s	
5176/33150 (epoch 7.807), train_loss = 1.20165341, grad/param norm = 1.6485e-01, time/batch = 0.6671s	
5177/33150 (epoch 7.808), train_loss = 1.34405074, grad/param norm = 1.6325e-01, time/batch = 0.6781s	
5178/33150 (epoch 7.810), train_loss = 1.25518866, grad/param norm = 1.6553e-01, time/batch = 0.6764s	
5179/33150 (epoch 7.811), train_loss = 1.35676015, grad/param norm = 1.7136e-01, time/batch = 0.6739s	
5180/33150 (epoch 7.813), train_loss = 1.24061279, grad/param norm = 1.4156e-01, time/batch = 0.6873s	
5181/33150 (epoch 7.814), train_loss = 1.29349598, grad/param norm = 1.8104e-01, time/batch = 0.6718s	
5182/33150 (epoch 7.816), train_loss = 1.29130991, grad/param norm = 1.9527e-01, time/batch = 0.6660s	
5183/33150 (epoch 7.817), train_loss = 1.39221477, grad/param norm = 1.5885e-01, time/batch = 0.6653s	
5184/33150 (epoch 7.819), train_loss = 1.26650588, grad/param norm = 1.5483e-01, time/batch = 0.6690s	
5185/33150 (epoch 7.821), train_loss = 1.08466074, grad/param norm = 1.3127e-01, time/batch = 0.6657s	
5186/33150 (epoch 7.822), train_loss = 1.17717985, grad/param norm = 1.4620e-01, time/batch = 0.6650s	
5187/33150 (epoch 7.824), train_loss = 1.24417664, grad/param norm = 1.6970e-01, time/batch = 0.6690s	
5188/33150 (epoch 7.825), train_loss = 1.28726495, grad/param norm = 1.6393e-01, time/batch = 0.6681s	
5189/33150 (epoch 7.827), train_loss = 1.37292243, grad/param norm = 1.9782e-01, time/batch = 0.6695s	
5190/33150 (epoch 7.828), train_loss = 1.16567995, grad/param norm = 1.6854e-01, time/batch = 0.6789s	
5191/33150 (epoch 7.830), train_loss = 1.30130458, grad/param norm = 1.6593e-01, time/batch = 0.6785s	
5192/33150 (epoch 7.831), train_loss = 1.24286853, grad/param norm = 1.8162e-01, time/batch = 0.6825s	
5193/33150 (epoch 7.833), train_loss = 1.16901598, grad/param norm = 1.6988e-01, time/batch = 0.6872s	
5194/33150 (epoch 7.834), train_loss = 1.45675798, grad/param norm = 1.8134e-01, time/batch = 0.6824s	
5195/33150 (epoch 7.836), train_loss = 1.39834361, grad/param norm = 1.7869e-01, time/batch = 0.6714s	
5196/33150 (epoch 7.837), train_loss = 1.27680518, grad/param norm = 1.5431e-01, time/batch = 0.6793s	
5197/33150 (epoch 7.839), train_loss = 1.44691501, grad/param norm = 2.0880e-01, time/batch = 0.6768s	
5198/33150 (epoch 7.840), train_loss = 1.38565216, grad/param norm = 1.7126e-01, time/batch = 0.6775s	
5199/33150 (epoch 7.842), train_loss = 1.45872664, grad/param norm = 1.9398e-01, time/batch = 0.6821s	
5200/33150 (epoch 7.843), train_loss = 1.40735218, grad/param norm = 1.8356e-01, time/batch = 0.6790s	
5201/33150 (epoch 7.845), train_loss = 1.22009971, grad/param norm = 1.6693e-01, time/batch = 0.6822s	
5202/33150 (epoch 7.846), train_loss = 1.56610018, grad/param norm = 2.1485e-01, time/batch = 0.6677s	
5203/33150 (epoch 7.848), train_loss = 1.35505864, grad/param norm = 1.5822e-01, time/batch = 0.6784s	
5204/33150 (epoch 7.849), train_loss = 1.34053328, grad/param norm = 1.6885e-01, time/batch = 0.6643s	
5205/33150 (epoch 7.851), train_loss = 1.43487287, grad/param norm = 1.9980e-01, time/batch = 0.6643s	
5206/33150 (epoch 7.852), train_loss = 1.44455347, grad/param norm = 1.7552e-01, time/batch = 0.6707s	
5207/33150 (epoch 7.854), train_loss = 1.31260697, grad/param norm = 1.5839e-01, time/batch = 0.6803s	
5208/33150 (epoch 7.855), train_loss = 1.07305795, grad/param norm = 1.4213e-01, time/batch = 0.6665s	
5209/33150 (epoch 7.857), train_loss = 1.11208679, grad/param norm = 1.4964e-01, time/batch = 0.6669s	
5210/33150 (epoch 7.858), train_loss = 1.22856012, grad/param norm = 1.5610e-01, time/batch = 0.6679s	
5211/33150 (epoch 7.860), train_loss = 1.17696577, grad/param norm = 1.5212e-01, time/batch = 0.6664s	
5212/33150 (epoch 7.861), train_loss = 1.21293317, grad/param norm = 1.5512e-01, time/batch = 0.6666s	
5213/33150 (epoch 7.863), train_loss = 1.32700722, grad/param norm = 1.4750e-01, time/batch = 0.6664s	
5214/33150 (epoch 7.864), train_loss = 1.43646071, grad/param norm = 1.7353e-01, time/batch = 0.6672s	
5215/33150 (epoch 7.866), train_loss = 1.30436522, grad/param norm = 1.6906e-01, time/batch = 0.6667s	
5216/33150 (epoch 7.867), train_loss = 1.33890707, grad/param norm = 1.4901e-01, time/batch = 0.6682s	
5217/33150 (epoch 7.869), train_loss = 1.38371881, grad/param norm = 1.8603e-01, time/batch = 0.6689s	
5218/33150 (epoch 7.870), train_loss = 1.39336539, grad/param norm = 1.7121e-01, time/batch = 0.6708s	
5219/33150 (epoch 7.872), train_loss = 1.31079044, grad/param norm = 1.7069e-01, time/batch = 0.6628s	
5220/33150 (epoch 7.873), train_loss = 1.09976625, grad/param norm = 1.4122e-01, time/batch = 0.6646s	
5221/33150 (epoch 7.875), train_loss = 1.46484992, grad/param norm = 1.7144e-01, time/batch = 0.6744s	
5222/33150 (epoch 7.876), train_loss = 1.22703242, grad/param norm = 1.7213e-01, time/batch = 0.6808s	
5223/33150 (epoch 7.878), train_loss = 1.15875464, grad/param norm = 1.4251e-01, time/batch = 0.6685s	
5224/33150 (epoch 7.879), train_loss = 1.21478234, grad/param norm = 1.6308e-01, time/batch = 0.6696s	
5225/33150 (epoch 7.881), train_loss = 1.23003920, grad/param norm = 1.5088e-01, time/batch = 0.6672s	
5226/33150 (epoch 7.882), train_loss = 1.16278306, grad/param norm = 1.5002e-01, time/batch = 0.6672s	
5227/33150 (epoch 7.884), train_loss = 1.31096700, grad/param norm = 1.7624e-01, time/batch = 0.6682s	
5228/33150 (epoch 7.885), train_loss = 1.03037567, grad/param norm = 1.5440e-01, time/batch = 0.6645s	
5229/33150 (epoch 7.887), train_loss = 1.51442788, grad/param norm = 1.8030e-01, time/batch = 0.6663s	
5230/33150 (epoch 7.888), train_loss = 1.35981252, grad/param norm = 1.7045e-01, time/batch = 0.6661s	
5231/33150 (epoch 7.890), train_loss = 1.25440024, grad/param norm = 1.5790e-01, time/batch = 0.6688s	
5232/33150 (epoch 7.891), train_loss = 1.19775398, grad/param norm = 1.7529e-01, time/batch = 0.6676s	
5233/33150 (epoch 7.893), train_loss = 1.38362069, grad/param norm = 1.8062e-01, time/batch = 0.6703s	
5234/33150 (epoch 7.894), train_loss = 1.37521511, grad/param norm = 1.6497e-01, time/batch = 0.6667s	
5235/33150 (epoch 7.896), train_loss = 1.24428004, grad/param norm = 1.5396e-01, time/batch = 0.6644s	
5236/33150 (epoch 7.897), train_loss = 1.32591509, grad/param norm = 1.5196e-01, time/batch = 0.6652s	
5237/33150 (epoch 7.899), train_loss = 1.16506005, grad/param norm = 1.6815e-01, time/batch = 0.6658s	
5238/33150 (epoch 7.900), train_loss = 1.59406212, grad/param norm = 1.7566e-01, time/batch = 0.6656s	
5239/33150 (epoch 7.902), train_loss = 1.47913571, grad/param norm = 1.7473e-01, time/batch = 0.6697s	
5240/33150 (epoch 7.903), train_loss = 1.29695082, grad/param norm = 1.5603e-01, time/batch = 0.6702s	
5241/33150 (epoch 7.905), train_loss = 1.32126072, grad/param norm = 1.6548e-01, time/batch = 0.6813s	
5242/33150 (epoch 7.906), train_loss = 1.39324391, grad/param norm = 1.7863e-01, time/batch = 0.6782s	
5243/33150 (epoch 7.908), train_loss = 1.45032094, grad/param norm = 1.7169e-01, time/batch = 0.6724s	
5244/33150 (epoch 7.910), train_loss = 1.38459917, grad/param norm = 1.6143e-01, time/batch = 0.6704s	
5245/33150 (epoch 7.911), train_loss = 1.14451143, grad/param norm = 1.4539e-01, time/batch = 0.6707s	
5246/33150 (epoch 7.913), train_loss = 1.19580569, grad/param norm = 1.5819e-01, time/batch = 0.6694s	
5247/33150 (epoch 7.914), train_loss = 1.40640107, grad/param norm = 1.8979e-01, time/batch = 0.6761s	
5248/33150 (epoch 7.916), train_loss = 1.18509485, grad/param norm = 1.7859e-01, time/batch = 0.6738s	
5249/33150 (epoch 7.917), train_loss = 1.44928760, grad/param norm = 1.7773e-01, time/batch = 0.6648s	
5250/33150 (epoch 7.919), train_loss = 1.52322279, grad/param norm = 1.9262e-01, time/batch = 0.6670s	
5251/33150 (epoch 7.920), train_loss = 1.39496884, grad/param norm = 1.6461e-01, time/batch = 0.6700s	
5252/33150 (epoch 7.922), train_loss = 1.49069478, grad/param norm = 1.8240e-01, time/batch = 0.6688s	
5253/33150 (epoch 7.923), train_loss = 1.31257769, grad/param norm = 1.6973e-01, time/batch = 0.6676s	
5254/33150 (epoch 7.925), train_loss = 1.33409637, grad/param norm = 1.6566e-01, time/batch = 0.6668s	
5255/33150 (epoch 7.926), train_loss = 1.28768203, grad/param norm = 1.6946e-01, time/batch = 0.6683s	
5256/33150 (epoch 7.928), train_loss = 1.27739492, grad/param norm = 1.6791e-01, time/batch = 0.6802s	
5257/33150 (epoch 7.929), train_loss = 1.35926085, grad/param norm = 1.6628e-01, time/batch = 0.6699s	
5258/33150 (epoch 7.931), train_loss = 1.48086607, grad/param norm = 1.9885e-01, time/batch = 0.6639s	
5259/33150 (epoch 7.932), train_loss = 1.32038628, grad/param norm = 1.9037e-01, time/batch = 0.6648s	
5260/33150 (epoch 7.934), train_loss = 1.30886886, grad/param norm = 1.5681e-01, time/batch = 0.6783s	
5261/33150 (epoch 7.935), train_loss = 1.41738091, grad/param norm = 1.6262e-01, time/batch = 0.6910s	
5262/33150 (epoch 7.937), train_loss = 1.43488126, grad/param norm = 1.7013e-01, time/batch = 0.6988s	
5263/33150 (epoch 7.938), train_loss = 1.40033188, grad/param norm = 1.5888e-01, time/batch = 0.6800s	
5264/33150 (epoch 7.940), train_loss = 1.62087341, grad/param norm = 1.7776e-01, time/batch = 0.6726s	
5265/33150 (epoch 7.941), train_loss = 1.26280728, grad/param norm = 1.4869e-01, time/batch = 0.6728s	
5266/33150 (epoch 7.943), train_loss = 1.19427737, grad/param norm = 1.9043e-01, time/batch = 0.6655s	
5267/33150 (epoch 7.944), train_loss = 1.44467900, grad/param norm = 1.8465e-01, time/batch = 0.6845s	
5268/33150 (epoch 7.946), train_loss = 1.08425953, grad/param norm = 1.5152e-01, time/batch = 0.6789s	
5269/33150 (epoch 7.947), train_loss = 1.36123945, grad/param norm = 1.6885e-01, time/batch = 0.6640s	
5270/33150 (epoch 7.949), train_loss = 1.46182031, grad/param norm = 1.6319e-01, time/batch = 0.6720s	
5271/33150 (epoch 7.950), train_loss = 1.40963436, grad/param norm = 1.7986e-01, time/batch = 0.6802s	
5272/33150 (epoch 7.952), train_loss = 1.22276133, grad/param norm = 1.5238e-01, time/batch = 0.6677s	
5273/33150 (epoch 7.953), train_loss = 1.22233262, grad/param norm = 1.4820e-01, time/batch = 0.6626s	
5274/33150 (epoch 7.955), train_loss = 1.17908847, grad/param norm = 1.4638e-01, time/batch = 0.6869s	
5275/33150 (epoch 7.956), train_loss = 1.42226140, grad/param norm = 1.7594e-01, time/batch = 0.6780s	
5276/33150 (epoch 7.958), train_loss = 1.16019162, grad/param norm = 1.5585e-01, time/batch = 0.6674s	
5277/33150 (epoch 7.959), train_loss = 1.17986426, grad/param norm = 1.6944e-01, time/batch = 0.6814s	
5278/33150 (epoch 7.961), train_loss = 1.16910897, grad/param norm = 1.4827e-01, time/batch = 0.6656s	
5279/33150 (epoch 7.962), train_loss = 1.10834532, grad/param norm = 1.4119e-01, time/batch = 0.6677s	
5280/33150 (epoch 7.964), train_loss = 1.30753462, grad/param norm = 1.6603e-01, time/batch = 0.6688s	
5281/33150 (epoch 7.965), train_loss = 1.29619424, grad/param norm = 1.6625e-01, time/batch = 0.6750s	
5282/33150 (epoch 7.967), train_loss = 1.36028338, grad/param norm = 1.8227e-01, time/batch = 0.6694s	
5283/33150 (epoch 7.968), train_loss = 1.10888819, grad/param norm = 1.5243e-01, time/batch = 0.6697s	
5284/33150 (epoch 7.970), train_loss = 1.23693896, grad/param norm = 1.6716e-01, time/batch = 0.6680s	
5285/33150 (epoch 7.971), train_loss = 1.34952553, grad/param norm = 1.8940e-01, time/batch = 0.6659s	
5286/33150 (epoch 7.973), train_loss = 1.47924237, grad/param norm = 1.6285e-01, time/batch = 0.6679s	
5287/33150 (epoch 7.974), train_loss = 1.51879322, grad/param norm = 1.8754e-01, time/batch = 0.6693s	
5288/33150 (epoch 7.976), train_loss = 1.35463725, grad/param norm = 1.5633e-01, time/batch = 0.6670s	
5289/33150 (epoch 7.977), train_loss = 1.44175051, grad/param norm = 1.7545e-01, time/batch = 0.6676s	
5290/33150 (epoch 7.979), train_loss = 1.43998590, grad/param norm = 1.7516e-01, time/batch = 0.6679s	
5291/33150 (epoch 7.980), train_loss = 1.42567953, grad/param norm = 1.6489e-01, time/batch = 0.6764s	
5292/33150 (epoch 7.982), train_loss = 1.26402537, grad/param norm = 1.6717e-01, time/batch = 0.6783s	
5293/33150 (epoch 7.983), train_loss = 1.16903652, grad/param norm = 1.6150e-01, time/batch = 0.6740s	
5294/33150 (epoch 7.985), train_loss = 1.32349172, grad/param norm = 1.5497e-01, time/batch = 0.6671s	
5295/33150 (epoch 7.986), train_loss = 1.16563179, grad/param norm = 1.5339e-01, time/batch = 0.6789s	
5296/33150 (epoch 7.988), train_loss = 1.25274609, grad/param norm = 1.5798e-01, time/batch = 0.6670s	
5297/33150 (epoch 7.989), train_loss = 1.18197932, grad/param norm = 1.6345e-01, time/batch = 0.6686s	
5298/33150 (epoch 7.991), train_loss = 1.43659476, grad/param norm = 1.9652e-01, time/batch = 0.6690s	
5299/33150 (epoch 7.992), train_loss = 1.14338630, grad/param norm = 1.5343e-01, time/batch = 0.6658s	
5300/33150 (epoch 7.994), train_loss = 1.26414083, grad/param norm = 1.6929e-01, time/batch = 0.6768s	
5301/33150 (epoch 7.995), train_loss = 1.19129923, grad/param norm = 1.5309e-01, time/batch = 0.6753s	
5302/33150 (epoch 7.997), train_loss = 1.34237430, grad/param norm = 1.8560e-01, time/batch = 0.6664s	
5303/33150 (epoch 7.998), train_loss = 1.03438161, grad/param norm = 1.5210e-01, time/batch = 0.6660s	
5304/33150 (epoch 8.000), train_loss = 1.17495803, grad/param norm = 1.6677e-01, time/batch = 0.6652s	
5305/33150 (epoch 8.002), train_loss = 1.58261559, grad/param norm = 1.9479e-01, time/batch = 0.6693s	
5306/33150 (epoch 8.003), train_loss = 1.23469596, grad/param norm = 1.6823e-01, time/batch = 0.6695s	
5307/33150 (epoch 8.005), train_loss = 1.14526458, grad/param norm = 1.6080e-01, time/batch = 0.6684s	
5308/33150 (epoch 8.006), train_loss = 1.09288625, grad/param norm = 1.5558e-01, time/batch = 0.6713s	
5309/33150 (epoch 8.008), train_loss = 1.44787065, grad/param norm = 1.8249e-01, time/batch = 0.6646s	
5310/33150 (epoch 8.009), train_loss = 1.25961922, grad/param norm = 1.3831e-01, time/batch = 0.6646s	
5311/33150 (epoch 8.011), train_loss = 1.50091849, grad/param norm = 1.6792e-01, time/batch = 0.6641s	
5312/33150 (epoch 8.012), train_loss = 1.30127041, grad/param norm = 1.7999e-01, time/batch = 0.6653s	
5313/33150 (epoch 8.014), train_loss = 1.27808606, grad/param norm = 1.7638e-01, time/batch = 0.6673s	
5314/33150 (epoch 8.015), train_loss = 1.26747438, grad/param norm = 1.5813e-01, time/batch = 0.6636s	
5315/33150 (epoch 8.017), train_loss = 1.20625863, grad/param norm = 1.5080e-01, time/batch = 0.6894s	
5316/33150 (epoch 8.018), train_loss = 1.35051374, grad/param norm = 1.6301e-01, time/batch = 0.6885s	
5317/33150 (epoch 8.020), train_loss = 1.35160491, grad/param norm = 1.6722e-01, time/batch = 0.6873s	
5318/33150 (epoch 8.021), train_loss = 1.10192504, grad/param norm = 1.6046e-01, time/batch = 0.6867s	
5319/33150 (epoch 8.023), train_loss = 1.46506384, grad/param norm = 1.4941e-01, time/batch = 0.6874s	
5320/33150 (epoch 8.024), train_loss = 1.30628855, grad/param norm = 1.7037e-01, time/batch = 0.6883s	
5321/33150 (epoch 8.026), train_loss = 1.03115501, grad/param norm = 1.3532e-01, time/batch = 0.7004s	
5322/33150 (epoch 8.027), train_loss = 1.10671955, grad/param norm = 1.6396e-01, time/batch = 0.6978s	
5323/33150 (epoch 8.029), train_loss = 1.19369937, grad/param norm = 1.6102e-01, time/batch = 0.7007s	
5324/33150 (epoch 8.030), train_loss = 1.27382552, grad/param norm = 1.4769e-01, time/batch = 0.7035s	
5325/33150 (epoch 8.032), train_loss = 1.19884219, grad/param norm = 1.7656e-01, time/batch = 0.6977s	
5326/33150 (epoch 8.033), train_loss = 1.25428990, grad/param norm = 1.7480e-01, time/batch = 0.6666s	
5327/33150 (epoch 8.035), train_loss = 1.50681769, grad/param norm = 1.8437e-01, time/batch = 0.6658s	
5328/33150 (epoch 8.036), train_loss = 1.38200667, grad/param norm = 1.8323e-01, time/batch = 0.6648s	
5329/33150 (epoch 8.038), train_loss = 1.62684916, grad/param norm = 1.9390e-01, time/batch = 0.6672s	
5330/33150 (epoch 8.039), train_loss = 1.30271969, grad/param norm = 1.4326e-01, time/batch = 0.6651s	
5331/33150 (epoch 8.041), train_loss = 1.31953453, grad/param norm = 1.6075e-01, time/batch = 0.6623s	
5332/33150 (epoch 8.042), train_loss = 1.19992756, grad/param norm = 1.4594e-01, time/batch = 0.6656s	
5333/33150 (epoch 8.044), train_loss = 1.22852226, grad/param norm = 1.4235e-01, time/batch = 0.6647s	
5334/33150 (epoch 8.045), train_loss = 1.27497486, grad/param norm = 1.5174e-01, time/batch = 0.6703s	
5335/33150 (epoch 8.047), train_loss = 1.22272342, grad/param norm = 1.6701e-01, time/batch = 0.6724s	
5336/33150 (epoch 8.048), train_loss = 1.47088899, grad/param norm = 2.0375e-01, time/batch = 0.6755s	
5337/33150 (epoch 8.050), train_loss = 1.29661135, grad/param norm = 1.6651e-01, time/batch = 0.6632s	
5338/33150 (epoch 8.051), train_loss = 1.30177870, grad/param norm = 1.6970e-01, time/batch = 0.6646s	
5339/33150 (epoch 8.053), train_loss = 1.24355590, grad/param norm = 1.6689e-01, time/batch = 0.6671s	
5340/33150 (epoch 8.054), train_loss = 1.31343097, grad/param norm = 1.4683e-01, time/batch = 0.6703s	
5341/33150 (epoch 8.056), train_loss = 1.18104146, grad/param norm = 1.4134e-01, time/batch = 0.6694s	
5342/33150 (epoch 8.057), train_loss = 1.29592559, grad/param norm = 1.6860e-01, time/batch = 0.6712s	
5343/33150 (epoch 8.059), train_loss = 1.22241269, grad/param norm = 1.7150e-01, time/batch = 0.6693s	
5344/33150 (epoch 8.060), train_loss = 1.20885623, grad/param norm = 1.4915e-01, time/batch = 0.6675s	
5345/33150 (epoch 8.062), train_loss = 1.28119680, grad/param norm = 1.6144e-01, time/batch = 0.6684s	
5346/33150 (epoch 8.063), train_loss = 1.23990627, grad/param norm = 1.5524e-01, time/batch = 0.6675s	
5347/33150 (epoch 8.065), train_loss = 1.27778911, grad/param norm = 1.4928e-01, time/batch = 0.6704s	
5348/33150 (epoch 8.066), train_loss = 1.19887163, grad/param norm = 1.6094e-01, time/batch = 0.6798s	
5349/33150 (epoch 8.068), train_loss = 1.27239794, grad/param norm = 1.5771e-01, time/batch = 0.6810s	
5350/33150 (epoch 8.069), train_loss = 1.34942946, grad/param norm = 1.8110e-01, time/batch = 0.6869s	
5351/33150 (epoch 8.071), train_loss = 1.34511188, grad/param norm = 1.5809e-01, time/batch = 0.6810s	
5352/33150 (epoch 8.072), train_loss = 1.18359469, grad/param norm = 1.5454e-01, time/batch = 0.6691s	
5353/33150 (epoch 8.074), train_loss = 1.10916352, grad/param norm = 1.6314e-01, time/batch = 0.6636s	
5354/33150 (epoch 8.075), train_loss = 1.24368624, grad/param norm = 1.5427e-01, time/batch = 0.6628s	
5355/33150 (epoch 8.077), train_loss = 1.37495143, grad/param norm = 1.8467e-01, time/batch = 0.6648s	
5356/33150 (epoch 8.078), train_loss = 1.49146902, grad/param norm = 1.9494e-01, time/batch = 0.6676s	
5357/33150 (epoch 8.080), train_loss = 1.38607863, grad/param norm = 1.5467e-01, time/batch = 0.6664s	
5358/33150 (epoch 8.081), train_loss = 1.21708144, grad/param norm = 1.7661e-01, time/batch = 0.6703s	
5359/33150 (epoch 8.083), train_loss = 0.94589152, grad/param norm = 1.5705e-01, time/batch = 0.6653s	
5360/33150 (epoch 8.084), train_loss = 1.12254470, grad/param norm = 1.6856e-01, time/batch = 0.6680s	
5361/33150 (epoch 8.086), train_loss = 1.22411503, grad/param norm = 1.7644e-01, time/batch = 0.6905s	
5362/33150 (epoch 8.087), train_loss = 1.17368945, grad/param norm = 1.7328e-01, time/batch = 0.6804s	
5363/33150 (epoch 8.089), train_loss = 1.18646057, grad/param norm = 1.7488e-01, time/batch = 0.6687s	
5364/33150 (epoch 8.090), train_loss = 1.21842285, grad/param norm = 1.7498e-01, time/batch = 0.6696s	
5365/33150 (epoch 8.092), train_loss = 1.26367998, grad/param norm = 1.6571e-01, time/batch = 0.6731s	
5366/33150 (epoch 8.094), train_loss = 1.38954895, grad/param norm = 1.9417e-01, time/batch = 0.6747s	
5367/33150 (epoch 8.095), train_loss = 1.11873339, grad/param norm = 1.4763e-01, time/batch = 0.6657s	
5368/33150 (epoch 8.097), train_loss = 1.31066030, grad/param norm = 1.7051e-01, time/batch = 0.6700s	
5369/33150 (epoch 8.098), train_loss = 1.54378069, grad/param norm = 1.9217e-01, time/batch = 0.6685s	
5370/33150 (epoch 8.100), train_loss = 1.47214357, grad/param norm = 1.6107e-01, time/batch = 0.6701s	
5371/33150 (epoch 8.101), train_loss = 1.18884127, grad/param norm = 1.7405e-01, time/batch = 0.6774s	
5372/33150 (epoch 8.103), train_loss = 1.31845011, grad/param norm = 1.6235e-01, time/batch = 0.6795s	
5373/33150 (epoch 8.104), train_loss = 1.25427186, grad/param norm = 1.7587e-01, time/batch = 0.6644s	
5374/33150 (epoch 8.106), train_loss = 1.47031572, grad/param norm = 1.8009e-01, time/batch = 0.6630s	
5375/33150 (epoch 8.107), train_loss = 1.52467753, grad/param norm = 1.8444e-01, time/batch = 0.6611s	
5376/33150 (epoch 8.109), train_loss = 1.20314859, grad/param norm = 1.5160e-01, time/batch = 0.6617s	
5377/33150 (epoch 8.110), train_loss = 1.34156085, grad/param norm = 1.6447e-01, time/batch = 0.6624s	
5378/33150 (epoch 8.112), train_loss = 1.17851390, grad/param norm = 1.5726e-01, time/batch = 0.6685s	
5379/33150 (epoch 8.113), train_loss = 1.21986936, grad/param norm = 1.8465e-01, time/batch = 0.6803s	
5380/33150 (epoch 8.115), train_loss = 1.47286849, grad/param norm = 1.8286e-01, time/batch = 0.6684s	
5381/33150 (epoch 8.116), train_loss = 1.15738645, grad/param norm = 1.6686e-01, time/batch = 0.6640s	
5382/33150 (epoch 8.118), train_loss = 1.36783817, grad/param norm = 1.7890e-01, time/batch = 0.6679s	
5383/33150 (epoch 8.119), train_loss = 1.34323639, grad/param norm = 1.7150e-01, time/batch = 0.6664s	
5384/33150 (epoch 8.121), train_loss = 1.22030462, grad/param norm = 1.5857e-01, time/batch = 0.6662s	
5385/33150 (epoch 8.122), train_loss = 1.46904323, grad/param norm = 1.8012e-01, time/batch = 0.6683s	
5386/33150 (epoch 8.124), train_loss = 1.02088524, grad/param norm = 1.4589e-01, time/batch = 0.6663s	
5387/33150 (epoch 8.125), train_loss = 1.35191476, grad/param norm = 1.5560e-01, time/batch = 0.6660s	
5388/33150 (epoch 8.127), train_loss = 1.19356268, grad/param norm = 1.5209e-01, time/batch = 0.6678s	
5389/33150 (epoch 8.128), train_loss = 1.29350633, grad/param norm = 1.7147e-01, time/batch = 0.6665s	
5390/33150 (epoch 8.130), train_loss = 1.31671093, grad/param norm = 1.4910e-01, time/batch = 0.6685s	
5391/33150 (epoch 8.131), train_loss = 1.51104345, grad/param norm = 1.7869e-01, time/batch = 0.6711s	
5392/33150 (epoch 8.133), train_loss = 1.18793148, grad/param norm = 1.5803e-01, time/batch = 0.6875s	
5393/33150 (epoch 8.134), train_loss = 1.38737177, grad/param norm = 1.6157e-01, time/batch = 0.6790s	
5394/33150 (epoch 8.136), train_loss = 1.29760659, grad/param norm = 1.6140e-01, time/batch = 0.6792s	
5395/33150 (epoch 8.137), train_loss = 1.36727170, grad/param norm = 1.6663e-01, time/batch = 0.6706s	
5396/33150 (epoch 8.139), train_loss = 1.31866945, grad/param norm = 1.7255e-01, time/batch = 0.6651s	
5397/33150 (epoch 8.140), train_loss = 1.43411451, grad/param norm = 1.8249e-01, time/batch = 0.6640s	
5398/33150 (epoch 8.142), train_loss = 1.37459120, grad/param norm = 1.8605e-01, time/batch = 0.6673s	
5399/33150 (epoch 8.143), train_loss = 1.31275025, grad/param norm = 1.8208e-01, time/batch = 0.6625s	
5400/33150 (epoch 8.145), train_loss = 1.30340133, grad/param norm = 1.8015e-01, time/batch = 0.6627s	
5401/33150 (epoch 8.146), train_loss = 1.47483914, grad/param norm = 2.0957e-01, time/batch = 0.6648s	
5402/33150 (epoch 8.148), train_loss = 1.35558019, grad/param norm = 1.7082e-01, time/batch = 0.6657s	
5403/33150 (epoch 8.149), train_loss = 1.32494698, grad/param norm = 1.7553e-01, time/batch = 0.6645s	
5404/33150 (epoch 8.151), train_loss = 1.53398091, grad/param norm = 1.7028e-01, time/batch = 0.6652s	
5405/33150 (epoch 8.152), train_loss = 1.24059842, grad/param norm = 1.4965e-01, time/batch = 0.6655s	
5406/33150 (epoch 8.154), train_loss = 1.25469474, grad/param norm = 1.5205e-01, time/batch = 0.6645s	
5407/33150 (epoch 8.155), train_loss = 1.16076876, grad/param norm = 1.5716e-01, time/batch = 0.6647s	
5408/33150 (epoch 8.157), train_loss = 1.21677299, grad/param norm = 1.6553e-01, time/batch = 0.6653s	
5409/33150 (epoch 8.158), train_loss = 1.16954240, grad/param norm = 1.6504e-01, time/batch = 0.6733s	
5410/33150 (epoch 8.160), train_loss = 1.38256660, grad/param norm = 1.5789e-01, time/batch = 0.6675s	
5411/33150 (epoch 8.161), train_loss = 1.26817727, grad/param norm = 1.7146e-01, time/batch = 0.6718s	
5412/33150 (epoch 8.163), train_loss = 1.23120816, grad/param norm = 1.4817e-01, time/batch = 0.6725s	
5413/33150 (epoch 8.164), train_loss = 1.39348484, grad/param norm = 1.6764e-01, time/batch = 0.6808s	
5414/33150 (epoch 8.166), train_loss = 1.29259548, grad/param norm = 1.7270e-01, time/batch = 0.6747s	
5415/33150 (epoch 8.167), train_loss = 1.29217538, grad/param norm = 1.5891e-01, time/batch = 0.6696s	
5416/33150 (epoch 8.169), train_loss = 1.41773428, grad/param norm = 1.9829e-01, time/batch = 0.6683s	
5417/33150 (epoch 8.170), train_loss = 1.24740146, grad/param norm = 1.7702e-01, time/batch = 0.6672s	
5418/33150 (epoch 8.172), train_loss = 1.41986452, grad/param norm = 1.8327e-01, time/batch = 0.6659s	
5419/33150 (epoch 8.173), train_loss = 1.39562596, grad/param norm = 2.0682e-01, time/batch = 0.6649s	
5420/33150 (epoch 8.175), train_loss = 1.21043236, grad/param norm = 1.6916e-01, time/batch = 0.6672s	
5421/33150 (epoch 8.176), train_loss = 1.31480610, grad/param norm = 1.7607e-01, time/batch = 0.6680s	
5422/33150 (epoch 8.178), train_loss = 1.48757066, grad/param norm = 1.7027e-01, time/batch = 0.6698s	
5423/33150 (epoch 8.179), train_loss = 1.32298963, grad/param norm = 1.4996e-01, time/batch = 0.6698s	
5424/33150 (epoch 8.181), train_loss = 1.31853386, grad/param norm = 1.7970e-01, time/batch = 0.6672s	
5425/33150 (epoch 8.183), train_loss = 1.29340369, grad/param norm = 1.7245e-01, time/batch = 0.6655s	
5426/33150 (epoch 8.184), train_loss = 1.47190752, grad/param norm = 1.7700e-01, time/batch = 0.6666s	
5427/33150 (epoch 8.186), train_loss = 1.42669224, grad/param norm = 1.6906e-01, time/batch = 0.6699s	
5428/33150 (epoch 8.187), train_loss = 1.30846376, grad/param norm = 1.6773e-01, time/batch = 0.6801s	
5429/33150 (epoch 8.189), train_loss = 1.13334959, grad/param norm = 1.7605e-01, time/batch = 0.6762s	
5430/33150 (epoch 8.190), train_loss = 1.21750094, grad/param norm = 1.7286e-01, time/batch = 0.6755s	
5431/33150 (epoch 8.192), train_loss = 1.30523960, grad/param norm = 1.7620e-01, time/batch = 0.6733s	
5432/33150 (epoch 8.193), train_loss = 1.31430274, grad/param norm = 1.5487e-01, time/batch = 0.6722s	
5433/33150 (epoch 8.195), train_loss = 1.60620670, grad/param norm = 1.8707e-01, time/batch = 0.6675s	
5434/33150 (epoch 8.196), train_loss = 1.42764014, grad/param norm = 1.6140e-01, time/batch = 0.6672s	
5435/33150 (epoch 8.198), train_loss = 1.14526730, grad/param norm = 1.6633e-01, time/batch = 0.6660s	
5436/33150 (epoch 8.199), train_loss = 1.40764417, grad/param norm = 1.8437e-01, time/batch = 0.6633s	
5437/33150 (epoch 8.201), train_loss = 1.14648867, grad/param norm = 1.4158e-01, time/batch = 0.6635s	
5438/33150 (epoch 8.202), train_loss = 1.09525062, grad/param norm = 1.4322e-01, time/batch = 0.6794s	
5439/33150 (epoch 8.204), train_loss = 1.27742780, grad/param norm = 1.6333e-01, time/batch = 0.6883s	
5440/33150 (epoch 8.205), train_loss = 1.39682101, grad/param norm = 1.7701e-01, time/batch = 0.6924s	
5441/33150 (epoch 8.207), train_loss = 1.31116631, grad/param norm = 1.5451e-01, time/batch = 0.6941s	
5442/33150 (epoch 8.208), train_loss = 1.35079434, grad/param norm = 1.5659e-01, time/batch = 0.6869s	
5443/33150 (epoch 8.210), train_loss = 1.15763388, grad/param norm = 1.3782e-01, time/batch = 0.6796s	
5444/33150 (epoch 8.211), train_loss = 1.33360540, grad/param norm = 1.8135e-01, time/batch = 0.6851s	
5445/33150 (epoch 8.213), train_loss = 1.39708925, grad/param norm = 1.6454e-01, time/batch = 0.6940s	
5446/33150 (epoch 8.214), train_loss = 1.24414865, grad/param norm = 1.6247e-01, time/batch = 0.6905s	
5447/33150 (epoch 8.216), train_loss = 1.22421454, grad/param norm = 1.6101e-01, time/batch = 0.6887s	
5448/33150 (epoch 8.217), train_loss = 1.22876033, grad/param norm = 1.6618e-01, time/batch = 0.6894s	
5449/33150 (epoch 8.219), train_loss = 1.17352286, grad/param norm = 1.5429e-01, time/batch = 0.7031s	
5450/33150 (epoch 8.220), train_loss = 1.18033589, grad/param norm = 1.4396e-01, time/batch = 0.6838s	
5451/33150 (epoch 8.222), train_loss = 1.36085262, grad/param norm = 1.5970e-01, time/batch = 0.6710s	
5452/33150 (epoch 8.223), train_loss = 1.23420595, grad/param norm = 1.6098e-01, time/batch = 0.6672s	
5453/33150 (epoch 8.225), train_loss = 1.47298395, grad/param norm = 1.6772e-01, time/batch = 0.6672s	
5454/33150 (epoch 8.226), train_loss = 1.24230008, grad/param norm = 1.4742e-01, time/batch = 0.6688s	
5455/33150 (epoch 8.228), train_loss = 1.27086953, grad/param norm = 1.5926e-01, time/batch = 0.6649s	
5456/33150 (epoch 8.229), train_loss = 1.28266765, grad/param norm = 1.6377e-01, time/batch = 0.6824s	
5457/33150 (epoch 8.231), train_loss = 1.40712738, grad/param norm = 1.7065e-01, time/batch = 0.6688s	
5458/33150 (epoch 8.232), train_loss = 1.32706410, grad/param norm = 1.8873e-01, time/batch = 0.6653s	
5459/33150 (epoch 8.234), train_loss = 1.25950408, grad/param norm = 1.8242e-01, time/batch = 0.6767s	
5460/33150 (epoch 8.235), train_loss = 1.32582221, grad/param norm = 1.7108e-01, time/batch = 0.6761s	
5461/33150 (epoch 8.237), train_loss = 1.26454204, grad/param norm = 1.6463e-01, time/batch = 0.6739s	
5462/33150 (epoch 8.238), train_loss = 1.43343495, grad/param norm = 1.9738e-01, time/batch = 0.6682s	
5463/33150 (epoch 8.240), train_loss = 1.29259232, grad/param norm = 1.5635e-01, time/batch = 0.6649s	
5464/33150 (epoch 8.241), train_loss = 1.45169136, grad/param norm = 1.9172e-01, time/batch = 0.6655s	
5465/33150 (epoch 8.243), train_loss = 1.41153820, grad/param norm = 1.8123e-01, time/batch = 0.6660s	
5466/33150 (epoch 8.244), train_loss = 1.24997054, grad/param norm = 1.4722e-01, time/batch = 0.6664s	
5467/33150 (epoch 8.246), train_loss = 1.33444399, grad/param norm = 1.6907e-01, time/batch = 0.6701s	
5468/33150 (epoch 8.247), train_loss = 1.16195848, grad/param norm = 1.5501e-01, time/batch = 0.6845s	
5469/33150 (epoch 8.249), train_loss = 1.40039467, grad/param norm = 1.5694e-01, time/batch = 0.6876s	
5470/33150 (epoch 8.250), train_loss = 1.32957568, grad/param norm = 1.4206e-01, time/batch = 0.6701s	
5471/33150 (epoch 8.252), train_loss = 1.31650056, grad/param norm = 1.3975e-01, time/batch = 0.6705s	
5472/33150 (epoch 8.253), train_loss = 1.36632046, grad/param norm = 1.6844e-01, time/batch = 0.6808s	
5473/33150 (epoch 8.255), train_loss = 1.27340069, grad/param norm = 1.4923e-01, time/batch = 0.6786s	
5474/33150 (epoch 8.256), train_loss = 1.35890996, grad/param norm = 1.6388e-01, time/batch = 0.6994s	
5475/33150 (epoch 8.258), train_loss = 1.24479362, grad/param norm = 1.6923e-01, time/batch = 0.6845s	
5476/33150 (epoch 8.259), train_loss = 1.09370653, grad/param norm = 1.6432e-01, time/batch = 0.6739s	
5477/33150 (epoch 8.261), train_loss = 1.13204055, grad/param norm = 1.5679e-01, time/batch = 0.6695s	
5478/33150 (epoch 8.262), train_loss = 1.34251916, grad/param norm = 1.5426e-01, time/batch = 0.6748s	
5479/33150 (epoch 8.264), train_loss = 1.00229646, grad/param norm = 1.3588e-01, time/batch = 0.6691s	
5480/33150 (epoch 8.265), train_loss = 1.32614764, grad/param norm = 1.6787e-01, time/batch = 0.6656s	
5481/33150 (epoch 8.267), train_loss = 1.44265940, grad/param norm = 1.8538e-01, time/batch = 0.6676s	
5482/33150 (epoch 8.268), train_loss = 1.26438094, grad/param norm = 1.5661e-01, time/batch = 0.6703s	
5483/33150 (epoch 8.270), train_loss = 1.48725089, grad/param norm = 1.5267e-01, time/batch = 0.6727s	
5484/33150 (epoch 8.271), train_loss = 1.42610043, grad/param norm = 1.6590e-01, time/batch = 0.6716s	
5485/33150 (epoch 8.273), train_loss = 1.37922307, grad/param norm = 1.5882e-01, time/batch = 0.6683s	
5486/33150 (epoch 8.275), train_loss = 1.41150016, grad/param norm = 1.6629e-01, time/batch = 0.6725s	
5487/33150 (epoch 8.276), train_loss = 1.27060289, grad/param norm = 1.5802e-01, time/batch = 0.6801s	
5488/33150 (epoch 8.278), train_loss = 1.38037622, grad/param norm = 1.6969e-01, time/batch = 0.6680s	
5489/33150 (epoch 8.279), train_loss = 1.26385193, grad/param norm = 1.4897e-01, time/batch = 0.6656s	
5490/33150 (epoch 8.281), train_loss = 1.36808347, grad/param norm = 1.6810e-01, time/batch = 0.6671s	
5491/33150 (epoch 8.282), train_loss = 1.28977922, grad/param norm = 1.4269e-01, time/batch = 0.6695s	
5492/33150 (epoch 8.284), train_loss = 1.23357034, grad/param norm = 1.5253e-01, time/batch = 0.6648s	
5493/33150 (epoch 8.285), train_loss = 1.34450107, grad/param norm = 1.6474e-01, time/batch = 0.6634s	
5494/33150 (epoch 8.287), train_loss = 1.23157252, grad/param norm = 1.5634e-01, time/batch = 0.6641s	
5495/33150 (epoch 8.288), train_loss = 1.48586995, grad/param norm = 1.7413e-01, time/batch = 0.6639s	
5496/33150 (epoch 8.290), train_loss = 1.15494319, grad/param norm = 1.6174e-01, time/batch = 0.6641s	
5497/33150 (epoch 8.291), train_loss = 1.16078782, grad/param norm = 1.5558e-01, time/batch = 0.6664s	
5498/33150 (epoch 8.293), train_loss = 1.36153280, grad/param norm = 1.5363e-01, time/batch = 0.6658s	
5499/33150 (epoch 8.294), train_loss = 1.01619200, grad/param norm = 1.4518e-01, time/batch = 0.6638s	
5500/33150 (epoch 8.296), train_loss = 1.22944581, grad/param norm = 1.4954e-01, time/batch = 0.6631s	
5501/33150 (epoch 8.297), train_loss = 1.23326429, grad/param norm = 1.6894e-01, time/batch = 0.6714s	
5502/33150 (epoch 8.299), train_loss = 1.21152751, grad/param norm = 1.7541e-01, time/batch = 0.6813s	
5503/33150 (epoch 8.300), train_loss = 1.23469167, grad/param norm = 1.4860e-01, time/batch = 0.6873s	
5504/33150 (epoch 8.302), train_loss = 1.21778137, grad/param norm = 1.5675e-01, time/batch = 0.6802s	
5505/33150 (epoch 8.303), train_loss = 1.34088769, grad/param norm = 1.7131e-01, time/batch = 0.6842s	
5506/33150 (epoch 8.305), train_loss = 1.32190592, grad/param norm = 1.5790e-01, time/batch = 0.6829s	
5507/33150 (epoch 8.306), train_loss = 1.34652698, grad/param norm = 1.6592e-01, time/batch = 0.6797s	
5508/33150 (epoch 8.308), train_loss = 1.52815446, grad/param norm = 1.7244e-01, time/batch = 0.6813s	
5509/33150 (epoch 8.309), train_loss = 1.13603729, grad/param norm = 1.4533e-01, time/batch = 0.6737s	
5510/33150 (epoch 8.311), train_loss = 1.28020875, grad/param norm = 1.6866e-01, time/batch = 0.6703s	
5511/33150 (epoch 8.312), train_loss = 1.09835537, grad/param norm = 1.5930e-01, time/batch = 0.6725s	
5512/33150 (epoch 8.314), train_loss = 1.29558265, grad/param norm = 1.6660e-01, time/batch = 0.6808s	
5513/33150 (epoch 8.315), train_loss = 1.38326431, grad/param norm = 1.7123e-01, time/batch = 0.6740s	
5514/33150 (epoch 8.317), train_loss = 1.02681613, grad/param norm = 1.3120e-01, time/batch = 0.6675s	
5515/33150 (epoch 8.318), train_loss = 1.16571216, grad/param norm = 1.4516e-01, time/batch = 0.6632s	
5516/33150 (epoch 8.320), train_loss = 1.13399929, grad/param norm = 1.5497e-01, time/batch = 0.6630s	
5517/33150 (epoch 8.321), train_loss = 1.20805222, grad/param norm = 1.4842e-01, time/batch = 0.6632s	
5518/33150 (epoch 8.323), train_loss = 1.27199779, grad/param norm = 1.5550e-01, time/batch = 0.6645s	
5519/33150 (epoch 8.324), train_loss = 1.38583817, grad/param norm = 1.8349e-01, time/batch = 0.6773s	
5520/33150 (epoch 8.326), train_loss = 1.30536962, grad/param norm = 1.5252e-01, time/batch = 0.6671s	
5521/33150 (epoch 8.327), train_loss = 1.39396649, grad/param norm = 1.5815e-01, time/batch = 0.6643s	
5522/33150 (epoch 8.329), train_loss = 1.33357264, grad/param norm = 1.5467e-01, time/batch = 0.6646s	
5523/33150 (epoch 8.330), train_loss = 1.33103884, grad/param norm = 1.8009e-01, time/batch = 0.6643s	
5524/33150 (epoch 8.332), train_loss = 1.26654652, grad/param norm = 1.4849e-01, time/batch = 0.6622s	
5525/33150 (epoch 8.333), train_loss = 1.31424503, grad/param norm = 1.4923e-01, time/batch = 0.6632s	
5526/33150 (epoch 8.335), train_loss = 1.23653883, grad/param norm = 1.5586e-01, time/batch = 0.6799s	
5527/33150 (epoch 8.336), train_loss = 1.17322054, grad/param norm = 1.4388e-01, time/batch = 0.6870s	
5528/33150 (epoch 8.338), train_loss = 1.04569063, grad/param norm = 1.4984e-01, time/batch = 0.6888s	
5529/33150 (epoch 8.339), train_loss = 1.38710527, grad/param norm = 1.6322e-01, time/batch = 0.6813s	
5530/33150 (epoch 8.341), train_loss = 1.46960046, grad/param norm = 1.9365e-01, time/batch = 0.6657s	
5531/33150 (epoch 8.342), train_loss = 1.12602440, grad/param norm = 1.5503e-01, time/batch = 0.6661s	
5532/33150 (epoch 8.344), train_loss = 1.33267366, grad/param norm = 1.5970e-01, time/batch = 0.6640s	
5533/33150 (epoch 8.345), train_loss = 1.18746475, grad/param norm = 1.5936e-01, time/batch = 0.6639s	
5534/33150 (epoch 8.347), train_loss = 1.03816346, grad/param norm = 1.4793e-01, time/batch = 0.6790s	
5535/33150 (epoch 8.348), train_loss = 1.28193957, grad/param norm = 1.6362e-01, time/batch = 0.6730s	
5536/33150 (epoch 8.350), train_loss = 1.26534364, grad/param norm = 1.8037e-01, time/batch = 0.6659s	
5537/33150 (epoch 8.351), train_loss = 1.37415007, grad/param norm = 1.6832e-01, time/batch = 0.6675s	
5538/33150 (epoch 8.353), train_loss = 1.39399916, grad/param norm = 1.7675e-01, time/batch = 0.6626s	
5539/33150 (epoch 8.354), train_loss = 1.56523644, grad/param norm = 1.7996e-01, time/batch = 0.6690s	
5540/33150 (epoch 8.356), train_loss = 1.40962032, grad/param norm = 1.9093e-01, time/batch = 0.6841s	
5541/33150 (epoch 8.357), train_loss = 1.40613956, grad/param norm = 1.7065e-01, time/batch = 0.6696s	
5542/33150 (epoch 8.359), train_loss = 1.35130708, grad/param norm = 1.6323e-01, time/batch = 0.6758s	
5543/33150 (epoch 8.360), train_loss = 1.42124690, grad/param norm = 1.7940e-01, time/batch = 0.6690s	
5544/33150 (epoch 8.362), train_loss = 1.36183849, grad/param norm = 1.6838e-01, time/batch = 0.6722s	
5545/33150 (epoch 8.363), train_loss = 1.26014457, grad/param norm = 1.5541e-01, time/batch = 0.6765s	
5546/33150 (epoch 8.365), train_loss = 1.26721896, grad/param norm = 1.4996e-01, time/batch = 0.6810s	
5547/33150 (epoch 8.367), train_loss = 1.16712236, grad/param norm = 1.4907e-01, time/batch = 0.6768s	
5548/33150 (epoch 8.368), train_loss = 1.27452371, grad/param norm = 1.5285e-01, time/batch = 0.6811s	
5549/33150 (epoch 8.370), train_loss = 1.35874051, grad/param norm = 1.7588e-01, time/batch = 0.6671s	
5550/33150 (epoch 8.371), train_loss = 1.17517768, grad/param norm = 1.5401e-01, time/batch = 0.6691s	
5551/33150 (epoch 8.373), train_loss = 1.38475725, grad/param norm = 1.8820e-01, time/batch = 0.6668s	
5552/33150 (epoch 8.374), train_loss = 1.23387339, grad/param norm = 1.5259e-01, time/batch = 0.6721s	
5553/33150 (epoch 8.376), train_loss = 1.43973421, grad/param norm = 1.5739e-01, time/batch = 0.6656s	
5554/33150 (epoch 8.377), train_loss = 1.28604806, grad/param norm = 1.7390e-01, time/batch = 0.6617s	
5555/33150 (epoch 8.379), train_loss = 1.37837967, grad/param norm = 1.7561e-01, time/batch = 0.6684s	
5556/33150 (epoch 8.380), train_loss = 1.39758673, grad/param norm = 1.5792e-01, time/batch = 0.6680s	
5557/33150 (epoch 8.382), train_loss = 1.18004523, grad/param norm = 1.4425e-01, time/batch = 0.6704s	
5558/33150 (epoch 8.383), train_loss = 1.17916027, grad/param norm = 1.5400e-01, time/batch = 0.6676s	
5559/33150 (epoch 8.385), train_loss = 1.30333082, grad/param norm = 1.6208e-01, time/batch = 0.6661s	
5560/33150 (epoch 8.386), train_loss = 1.14143713, grad/param norm = 1.5242e-01, time/batch = 0.6683s	
5561/33150 (epoch 8.388), train_loss = 1.26378080, grad/param norm = 1.5846e-01, time/batch = 0.6818s	
5562/33150 (epoch 8.389), train_loss = 1.23408682, grad/param norm = 1.6215e-01, time/batch = 0.6729s	
5563/33150 (epoch 8.391), train_loss = 1.45892930, grad/param norm = 1.6572e-01, time/batch = 0.6679s	
5564/33150 (epoch 8.392), train_loss = 1.21967359, grad/param norm = 1.4968e-01, time/batch = 0.6683s	
5565/33150 (epoch 8.394), train_loss = 1.11325961, grad/param norm = 1.3158e-01, time/batch = 0.6723s	
5566/33150 (epoch 8.395), train_loss = 1.19531335, grad/param norm = 1.8092e-01, time/batch = 0.6675s	
5567/33150 (epoch 8.397), train_loss = 0.98664071, grad/param norm = 1.3325e-01, time/batch = 0.6666s	
5568/33150 (epoch 8.398), train_loss = 1.30671850, grad/param norm = 1.6937e-01, time/batch = 0.6690s	
5569/33150 (epoch 8.400), train_loss = 1.23367557, grad/param norm = 1.4911e-01, time/batch = 0.6688s	
5570/33150 (epoch 8.401), train_loss = 1.08494314, grad/param norm = 1.3797e-01, time/batch = 0.6689s	
5571/33150 (epoch 8.403), train_loss = 1.16652514, grad/param norm = 1.4519e-01, time/batch = 0.6714s	
5572/33150 (epoch 8.404), train_loss = 1.22410260, grad/param norm = 1.5034e-01, time/batch = 0.6736s	
5573/33150 (epoch 8.406), train_loss = 1.13971025, grad/param norm = 1.2722e-01, time/batch = 0.6722s	
5574/33150 (epoch 8.407), train_loss = 1.13721421, grad/param norm = 1.4182e-01, time/batch = 0.6692s	
5575/33150 (epoch 8.409), train_loss = 1.05648455, grad/param norm = 1.4619e-01, time/batch = 0.6699s	
5576/33150 (epoch 8.410), train_loss = 1.33826137, grad/param norm = 1.7740e-01, time/batch = 0.6664s	
5577/33150 (epoch 8.412), train_loss = 1.35365541, grad/param norm = 1.6516e-01, time/batch = 0.6687s	
5578/33150 (epoch 8.413), train_loss = 1.22076492, grad/param norm = 1.6607e-01, time/batch = 0.6714s	
5579/33150 (epoch 8.415), train_loss = 1.40409976, grad/param norm = 1.6118e-01, time/batch = 0.6680s	
5580/33150 (epoch 8.416), train_loss = 1.21356849, grad/param norm = 1.4642e-01, time/batch = 0.6686s	
5581/33150 (epoch 8.418), train_loss = 1.49411759, grad/param norm = 2.1494e-01, time/batch = 0.6675s	
5582/33150 (epoch 8.419), train_loss = 1.17955635, grad/param norm = 1.6348e-01, time/batch = 0.6652s	
5583/33150 (epoch 8.421), train_loss = 1.31242931, grad/param norm = 1.6689e-01, time/batch = 0.6671s	
5584/33150 (epoch 8.422), train_loss = 1.18947526, grad/param norm = 1.5133e-01, time/batch = 0.6664s	
5585/33150 (epoch 8.424), train_loss = 1.22715575, grad/param norm = 1.6596e-01, time/batch = 0.6646s	
5586/33150 (epoch 8.425), train_loss = 1.23393253, grad/param norm = 1.6309e-01, time/batch = 0.6673s	
5587/33150 (epoch 8.427), train_loss = 1.19276064, grad/param norm = 1.4733e-01, time/batch = 0.6676s	
5588/33150 (epoch 8.428), train_loss = 1.26632053, grad/param norm = 1.6108e-01, time/batch = 0.6636s	
5589/33150 (epoch 8.430), train_loss = 1.32574055, grad/param norm = 1.6924e-01, time/batch = 0.6657s	
5590/33150 (epoch 8.431), train_loss = 1.37379852, grad/param norm = 1.8391e-01, time/batch = 0.6669s	
5591/33150 (epoch 8.433), train_loss = 1.26473938, grad/param norm = 1.5509e-01, time/batch = 0.6675s	
5592/33150 (epoch 8.434), train_loss = 1.13248988, grad/param norm = 1.6142e-01, time/batch = 0.6687s	
5593/33150 (epoch 8.436), train_loss = 1.08995163, grad/param norm = 1.5217e-01, time/batch = 0.6694s	
5594/33150 (epoch 8.437), train_loss = 1.31293581, grad/param norm = 1.9305e-01, time/batch = 0.6685s	
5595/33150 (epoch 8.439), train_loss = 1.41016232, grad/param norm = 1.7736e-01, time/batch = 0.6798s	
5596/33150 (epoch 8.440), train_loss = 1.40037433, grad/param norm = 1.6940e-01, time/batch = 0.6746s	
5597/33150 (epoch 8.442), train_loss = 1.11816603, grad/param norm = 1.5902e-01, time/batch = 0.6675s	
5598/33150 (epoch 8.443), train_loss = 1.38249613, grad/param norm = 1.6824e-01, time/batch = 0.6665s	
5599/33150 (epoch 8.445), train_loss = 1.29512627, grad/param norm = 1.6991e-01, time/batch = 0.6712s	
5600/33150 (epoch 8.446), train_loss = 1.34150046, grad/param norm = 2.0323e-01, time/batch = 0.6727s	
5601/33150 (epoch 8.448), train_loss = 1.34750882, grad/param norm = 1.6888e-01, time/batch = 0.6677s	
5602/33150 (epoch 8.449), train_loss = 1.23846724, grad/param norm = 1.6068e-01, time/batch = 0.6651s	
5603/33150 (epoch 8.451), train_loss = 1.35871986, grad/param norm = 1.8186e-01, time/batch = 0.6647s	
5604/33150 (epoch 8.452), train_loss = 1.54045375, grad/param norm = 1.6587e-01, time/batch = 0.6630s	
5605/33150 (epoch 8.454), train_loss = 1.25225876, grad/param norm = 1.5973e-01, time/batch = 0.6647s	
5606/33150 (epoch 8.456), train_loss = 1.03446543, grad/param norm = 1.3971e-01, time/batch = 0.6663s	
5607/33150 (epoch 8.457), train_loss = 1.30095813, grad/param norm = 1.6430e-01, time/batch = 0.6678s	
5608/33150 (epoch 8.459), train_loss = 1.45970148, grad/param norm = 2.0093e-01, time/batch = 0.6682s	
5609/33150 (epoch 8.460), train_loss = 1.30480256, grad/param norm = 1.4985e-01, time/batch = 0.6682s	
5610/33150 (epoch 8.462), train_loss = 1.43289164, grad/param norm = 1.8348e-01, time/batch = 0.6866s	
5611/33150 (epoch 8.463), train_loss = 1.61461426, grad/param norm = 2.0297e-01, time/batch = 0.6751s	
5612/33150 (epoch 8.465), train_loss = 1.18039918, grad/param norm = 1.4799e-01, time/batch = 0.6662s	
5613/33150 (epoch 8.466), train_loss = 1.22882967, grad/param norm = 1.6256e-01, time/batch = 0.6682s	
5614/33150 (epoch 8.468), train_loss = 1.58886723, grad/param norm = 1.7166e-01, time/batch = 0.6651s	
5615/33150 (epoch 8.469), train_loss = 1.35042016, grad/param norm = 1.6794e-01, time/batch = 0.6669s	
5616/33150 (epoch 8.471), train_loss = 1.23549414, grad/param norm = 1.6012e-01, time/batch = 0.6842s	
5617/33150 (epoch 8.472), train_loss = 1.22075116, grad/param norm = 1.5032e-01, time/batch = 0.6847s	
5618/33150 (epoch 8.474), train_loss = 1.39773667, grad/param norm = 1.8082e-01, time/batch = 0.6799s	
5619/33150 (epoch 8.475), train_loss = 1.57190170, grad/param norm = 1.7709e-01, time/batch = 0.6879s	
5620/33150 (epoch 8.477), train_loss = 1.34603285, grad/param norm = 1.7966e-01, time/batch = 0.6784s	
5621/33150 (epoch 8.478), train_loss = 1.39589727, grad/param norm = 1.5839e-01, time/batch = 0.6757s	
5622/33150 (epoch 8.480), train_loss = 1.21934068, grad/param norm = 1.4993e-01, time/batch = 0.6939s	
5623/33150 (epoch 8.481), train_loss = 1.10784504, grad/param norm = 1.4921e-01, time/batch = 0.6869s	
5624/33150 (epoch 8.483), train_loss = 1.22854997, grad/param norm = 1.7162e-01, time/batch = 0.6721s	
5625/33150 (epoch 8.484), train_loss = 1.18395795, grad/param norm = 1.4840e-01, time/batch = 0.6662s	
5626/33150 (epoch 8.486), train_loss = 1.26626411, grad/param norm = 1.5913e-01, time/batch = 0.6689s	
5627/33150 (epoch 8.487), train_loss = 1.36294306, grad/param norm = 1.6391e-01, time/batch = 0.6664s	
5628/33150 (epoch 8.489), train_loss = 1.29328544, grad/param norm = 1.6447e-01, time/batch = 0.6682s	
5629/33150 (epoch 8.490), train_loss = 1.12343196, grad/param norm = 1.4426e-01, time/batch = 0.6690s	
5630/33150 (epoch 8.492), train_loss = 1.22940316, grad/param norm = 1.7551e-01, time/batch = 0.6697s	
5631/33150 (epoch 8.493), train_loss = 1.40021401, grad/param norm = 1.8009e-01, time/batch = 0.6702s	
5632/33150 (epoch 8.495), train_loss = 1.38158059, grad/param norm = 1.6201e-01, time/batch = 0.6686s	
5633/33150 (epoch 8.496), train_loss = 1.19040920, grad/param norm = 1.6273e-01, time/batch = 0.6811s	
5634/33150 (epoch 8.498), train_loss = 1.41505986, grad/param norm = 1.9957e-01, time/batch = 0.6677s	
5635/33150 (epoch 8.499), train_loss = 1.49442602, grad/param norm = 1.9599e-01, time/batch = 0.6644s	
5636/33150 (epoch 8.501), train_loss = 1.34038604, grad/param norm = 1.6085e-01, time/batch = 0.6637s	
5637/33150 (epoch 8.502), train_loss = 1.47291733, grad/param norm = 1.7901e-01, time/batch = 0.6634s	
5638/33150 (epoch 8.504), train_loss = 1.36546949, grad/param norm = 1.7113e-01, time/batch = 0.6677s	
5639/33150 (epoch 8.505), train_loss = 1.55625771, grad/param norm = 1.9209e-01, time/batch = 0.6735s	
5640/33150 (epoch 8.507), train_loss = 1.23216338, grad/param norm = 1.8021e-01, time/batch = 0.6801s	
5641/33150 (epoch 8.508), train_loss = 1.19719552, grad/param norm = 1.5669e-01, time/batch = 0.6683s	
5642/33150 (epoch 8.510), train_loss = 1.28122552, grad/param norm = 1.5934e-01, time/batch = 0.6656s	
5643/33150 (epoch 8.511), train_loss = 1.52796994, grad/param norm = 1.8444e-01, time/batch = 0.6653s	
5644/33150 (epoch 8.513), train_loss = 1.33959692, grad/param norm = 1.7325e-01, time/batch = 0.6659s	
5645/33150 (epoch 8.514), train_loss = 1.09290668, grad/param norm = 1.6042e-01, time/batch = 0.6690s	
5646/33150 (epoch 8.516), train_loss = 1.46148470, grad/param norm = 2.0230e-01, time/batch = 0.6665s	
5647/33150 (epoch 8.517), train_loss = 1.42010706, grad/param norm = 1.5748e-01, time/batch = 0.6685s	
5648/33150 (epoch 8.519), train_loss = 1.22748856, grad/param norm = 1.5336e-01, time/batch = 0.6782s	
5649/33150 (epoch 8.520), train_loss = 1.32822081, grad/param norm = 1.5757e-01, time/batch = 0.6702s	
5650/33150 (epoch 8.522), train_loss = 1.50553067, grad/param norm = 2.0589e-01, time/batch = 0.6651s	
5651/33150 (epoch 8.523), train_loss = 1.17425128, grad/param norm = 1.6929e-01, time/batch = 0.6706s	
5652/33150 (epoch 8.525), train_loss = 1.31200316, grad/param norm = 1.5652e-01, time/batch = 0.6712s	
5653/33150 (epoch 8.526), train_loss = 1.17963156, grad/param norm = 1.5539e-01, time/batch = 0.6692s	
5654/33150 (epoch 8.528), train_loss = 1.34996689, grad/param norm = 1.7546e-01, time/batch = 0.6765s	
5655/33150 (epoch 8.529), train_loss = 1.37632058, grad/param norm = 1.6320e-01, time/batch = 0.6783s	
5656/33150 (epoch 8.531), train_loss = 1.12127300, grad/param norm = 1.5721e-01, time/batch = 0.6700s	
5657/33150 (epoch 8.532), train_loss = 1.31926047, grad/param norm = 1.5871e-01, time/batch = 0.6675s	
5658/33150 (epoch 8.534), train_loss = 1.21127990, grad/param norm = 1.4488e-01, time/batch = 0.6676s	
5659/33150 (epoch 8.535), train_loss = 1.19791231, grad/param norm = 1.6993e-01, time/batch = 0.6661s	
5660/33150 (epoch 8.537), train_loss = 1.44700164, grad/param norm = 1.7195e-01, time/batch = 0.6690s	
5661/33150 (epoch 8.538), train_loss = 1.25709678, grad/param norm = 1.7879e-01, time/batch = 0.6732s	
5662/33150 (epoch 8.540), train_loss = 1.12059753, grad/param norm = 1.6172e-01, time/batch = 0.6814s	
5663/33150 (epoch 8.541), train_loss = 1.34421076, grad/param norm = 1.6854e-01, time/batch = 0.6851s	
5664/33150 (epoch 8.543), train_loss = 1.35653847, grad/param norm = 1.7126e-01, time/batch = 0.6679s	
5665/33150 (epoch 8.544), train_loss = 1.29275476, grad/param norm = 1.5265e-01, time/batch = 0.6692s	
5666/33150 (epoch 8.546), train_loss = 1.50705508, grad/param norm = 1.9094e-01, time/batch = 0.6698s	
5667/33150 (epoch 8.548), train_loss = 1.35259539, grad/param norm = 1.8498e-01, time/batch = 0.6703s	
5668/33150 (epoch 8.549), train_loss = 1.30097802, grad/param norm = 1.7602e-01, time/batch = 0.6708s	
5669/33150 (epoch 8.551), train_loss = 1.19808094, grad/param norm = 1.6503e-01, time/batch = 0.6737s	
5670/33150 (epoch 8.552), train_loss = 1.08105318, grad/param norm = 1.3619e-01, time/batch = 0.6743s	
5671/33150 (epoch 8.554), train_loss = 1.30244188, grad/param norm = 1.5415e-01, time/batch = 0.6683s	
5672/33150 (epoch 8.555), train_loss = 1.50503797, grad/param norm = 1.8019e-01, time/batch = 0.6894s	
5673/33150 (epoch 8.557), train_loss = 1.11171444, grad/param norm = 1.5903e-01, time/batch = 0.6783s	
5674/33150 (epoch 8.558), train_loss = 1.38956287, grad/param norm = 1.8455e-01, time/batch = 0.6763s	
5675/33150 (epoch 8.560), train_loss = 1.23574410, grad/param norm = 1.6069e-01, time/batch = 0.6758s	
5676/33150 (epoch 8.561), train_loss = 1.08055851, grad/param norm = 1.4733e-01, time/batch = 0.6707s	
5677/33150 (epoch 8.563), train_loss = 1.42182192, grad/param norm = 1.9933e-01, time/batch = 0.6774s	
5678/33150 (epoch 8.564), train_loss = 1.47661851, grad/param norm = 1.6548e-01, time/batch = 0.6685s	
5679/33150 (epoch 8.566), train_loss = 1.27313452, grad/param norm = 1.5924e-01, time/batch = 0.6687s	
5680/33150 (epoch 8.567), train_loss = 1.17902032, grad/param norm = 1.5699e-01, time/batch = 0.6690s	
5681/33150 (epoch 8.569), train_loss = 1.27924317, grad/param norm = 1.5185e-01, time/batch = 0.6689s	
5682/33150 (epoch 8.570), train_loss = 1.30067427, grad/param norm = 1.5085e-01, time/batch = 0.6645s	
5683/33150 (epoch 8.572), train_loss = 1.18366719, grad/param norm = 1.4704e-01, time/batch = 0.6658s	
5684/33150 (epoch 8.573), train_loss = 1.03246523, grad/param norm = 1.3547e-01, time/batch = 0.6669s	
5685/33150 (epoch 8.575), train_loss = 1.31030872, grad/param norm = 1.5924e-01, time/batch = 0.6688s	
5686/33150 (epoch 8.576), train_loss = 1.07479063, grad/param norm = 1.3133e-01, time/batch = 0.6666s	
5687/33150 (epoch 8.578), train_loss = 1.23792914, grad/param norm = 1.3839e-01, time/batch = 0.6692s	
5688/33150 (epoch 8.579), train_loss = 1.13581711, grad/param norm = 1.4830e-01, time/batch = 0.6780s	
5689/33150 (epoch 8.581), train_loss = 1.16322783, grad/param norm = 1.6234e-01, time/batch = 0.6848s	
5690/33150 (epoch 8.582), train_loss = 1.30640758, grad/param norm = 1.4831e-01, time/batch = 0.6682s	
5691/33150 (epoch 8.584), train_loss = 1.35928883, grad/param norm = 1.6086e-01, time/batch = 0.6684s	
5692/33150 (epoch 8.585), train_loss = 1.30034296, grad/param norm = 1.6596e-01, time/batch = 0.6674s	
5693/33150 (epoch 8.587), train_loss = 1.33409903, grad/param norm = 1.6155e-01, time/batch = 0.6676s	
5694/33150 (epoch 8.588), train_loss = 1.16993510, grad/param norm = 1.6169e-01, time/batch = 0.6660s	
5695/33150 (epoch 8.590), train_loss = 1.27886028, grad/param norm = 1.6824e-01, time/batch = 0.6656s	
5696/33150 (epoch 8.591), train_loss = 1.29746901, grad/param norm = 1.5847e-01, time/batch = 0.6737s	
5697/33150 (epoch 8.593), train_loss = 1.37063555, grad/param norm = 1.7122e-01, time/batch = 0.6660s	
5698/33150 (epoch 8.594), train_loss = 1.30859275, grad/param norm = 1.6623e-01, time/batch = 0.6667s	
5699/33150 (epoch 8.596), train_loss = 1.16770458, grad/param norm = 1.5585e-01, time/batch = 0.6668s	
5700/33150 (epoch 8.597), train_loss = 1.20977909, grad/param norm = 1.7832e-01, time/batch = 0.6647s	
5701/33150 (epoch 8.599), train_loss = 1.49658121, grad/param norm = 1.7556e-01, time/batch = 0.6680s	
5702/33150 (epoch 8.600), train_loss = 1.33968862, grad/param norm = 1.8703e-01, time/batch = 0.6659s	
5703/33150 (epoch 8.602), train_loss = 1.18831216, grad/param norm = 1.6057e-01, time/batch = 0.6743s	
5704/33150 (epoch 8.603), train_loss = 1.31711555, grad/param norm = 1.6654e-01, time/batch = 0.6807s	
5705/33150 (epoch 8.605), train_loss = 1.17374207, grad/param norm = 1.5168e-01, time/batch = 0.6864s	
5706/33150 (epoch 8.606), train_loss = 1.31107897, grad/param norm = 1.9104e-01, time/batch = 0.9474s	
5707/33150 (epoch 8.608), train_loss = 1.31714176, grad/param norm = 1.6596e-01, time/batch = 1.0223s	
5708/33150 (epoch 8.609), train_loss = 1.26393353, grad/param norm = 1.7455e-01, time/batch = 0.9857s	
5709/33150 (epoch 8.611), train_loss = 1.08987468, grad/param norm = 1.5344e-01, time/batch = 0.9740s	
5710/33150 (epoch 8.612), train_loss = 1.27547520, grad/param norm = 1.6938e-01, time/batch = 1.0147s	
5711/33150 (epoch 8.614), train_loss = 1.08929392, grad/param norm = 1.4945e-01, time/batch = 0.7125s	
5712/33150 (epoch 8.615), train_loss = 1.12065738, grad/param norm = 1.4389e-01, time/batch = 0.6650s	
5713/33150 (epoch 8.617), train_loss = 1.25523942, grad/param norm = 1.7723e-01, time/batch = 0.6674s	
5714/33150 (epoch 8.618), train_loss = 1.28045529, grad/param norm = 1.7209e-01, time/batch = 0.6943s	
5715/33150 (epoch 8.620), train_loss = 1.21653863, grad/param norm = 1.7020e-01, time/batch = 0.6864s	
5716/33150 (epoch 8.621), train_loss = 1.20504918, grad/param norm = 1.5465e-01, time/batch = 0.6666s	
5717/33150 (epoch 8.623), train_loss = 1.32652309, grad/param norm = 1.7774e-01, time/batch = 0.6658s	
5718/33150 (epoch 8.624), train_loss = 1.21564840, grad/param norm = 1.8417e-01, time/batch = 0.6706s	
5719/33150 (epoch 8.626), train_loss = 1.15962325, grad/param norm = 1.4816e-01, time/batch = 0.6668s	
5720/33150 (epoch 8.627), train_loss = 1.12048682, grad/param norm = 1.5984e-01, time/batch = 0.6616s	
5721/33150 (epoch 8.629), train_loss = 1.10229898, grad/param norm = 1.3795e-01, time/batch = 0.6656s	
5722/33150 (epoch 8.630), train_loss = 1.15159345, grad/param norm = 1.3671e-01, time/batch = 0.6741s	
5723/33150 (epoch 8.632), train_loss = 1.07937070, grad/param norm = 1.4101e-01, time/batch = 0.6817s	
5724/33150 (epoch 8.633), train_loss = 1.10620918, grad/param norm = 1.6070e-01, time/batch = 0.6790s	
5725/33150 (epoch 8.635), train_loss = 1.48357041, grad/param norm = 1.7092e-01, time/batch = 0.6837s	
5726/33150 (epoch 8.637), train_loss = 1.08678553, grad/param norm = 1.6116e-01, time/batch = 0.6855s	
5727/33150 (epoch 8.638), train_loss = 1.20632561, grad/param norm = 1.5664e-01, time/batch = 0.6962s	
5728/33150 (epoch 8.640), train_loss = 1.36468727, grad/param norm = 1.6242e-01, time/batch = 0.6931s	
5729/33150 (epoch 8.641), train_loss = 1.16227399, grad/param norm = 1.6144e-01, time/batch = 0.6874s	
5730/33150 (epoch 8.643), train_loss = 1.18244303, grad/param norm = 1.4784e-01, time/batch = 0.6822s	
5731/33150 (epoch 8.644), train_loss = 1.36984941, grad/param norm = 1.5245e-01, time/batch = 0.6883s	
5732/33150 (epoch 8.646), train_loss = 1.19724230, grad/param norm = 1.5855e-01, time/batch = 0.6834s	
5733/33150 (epoch 8.647), train_loss = 1.55256872, grad/param norm = 1.7833e-01, time/batch = 0.6669s	
5734/33150 (epoch 8.649), train_loss = 1.37874825, grad/param norm = 1.8050e-01, time/batch = 0.6652s	
5735/33150 (epoch 8.650), train_loss = 1.11442615, grad/param norm = 1.4386e-01, time/batch = 0.6614s	
5736/33150 (epoch 8.652), train_loss = 1.35024354, grad/param norm = 1.7316e-01, time/batch = 0.6647s	
5737/33150 (epoch 8.653), train_loss = 1.23155820, grad/param norm = 1.4183e-01, time/batch = 0.6674s	
5738/33150 (epoch 8.655), train_loss = 1.33749813, grad/param norm = 1.7733e-01, time/batch = 0.6662s	
5739/33150 (epoch 8.656), train_loss = 1.23537880, grad/param norm = 1.4711e-01, time/batch = 0.6677s	
5740/33150 (epoch 8.658), train_loss = 1.28427987, grad/param norm = 1.8638e-01, time/batch = 0.6682s	
5741/33150 (epoch 8.659), train_loss = 1.60248233, grad/param norm = 2.1350e-01, time/batch = 0.6776s	
5742/33150 (epoch 8.661), train_loss = 1.23249638, grad/param norm = 1.5858e-01, time/batch = 0.6701s	
5743/33150 (epoch 8.662), train_loss = 1.08030114, grad/param norm = 1.5460e-01, time/batch = 0.6680s	
5744/33150 (epoch 8.664), train_loss = 1.36685504, grad/param norm = 1.5183e-01, time/batch = 0.6658s	
5745/33150 (epoch 8.665), train_loss = 1.31521835, grad/param norm = 1.7405e-01, time/batch = 0.6772s	
5746/33150 (epoch 8.667), train_loss = 1.42548357, grad/param norm = 1.6549e-01, time/batch = 0.6791s	
5747/33150 (epoch 8.668), train_loss = 1.34117266, grad/param norm = 1.6299e-01, time/batch = 0.6666s	
5748/33150 (epoch 8.670), train_loss = 1.21636785, grad/param norm = 1.4692e-01, time/batch = 0.6682s	
5749/33150 (epoch 8.671), train_loss = 1.19397846, grad/param norm = 1.6573e-01, time/batch = 0.6655s	
5750/33150 (epoch 8.673), train_loss = 1.35225930, grad/param norm = 1.4358e-01, time/batch = 0.6649s	
5751/33150 (epoch 8.674), train_loss = 1.26425920, grad/param norm = 1.5476e-01, time/batch = 0.6694s	
5752/33150 (epoch 8.676), train_loss = 1.21349748, grad/param norm = 1.5115e-01, time/batch = 0.6694s	
5753/33150 (epoch 8.677), train_loss = 1.57715895, grad/param norm = 1.7156e-01, time/batch = 0.6681s	
5754/33150 (epoch 8.679), train_loss = 1.15110447, grad/param norm = 1.5150e-01, time/batch = 0.6687s	
5755/33150 (epoch 8.680), train_loss = 1.38290358, grad/param norm = 1.6527e-01, time/batch = 0.6667s	
5756/33150 (epoch 8.682), train_loss = 1.15033370, grad/param norm = 1.4970e-01, time/batch = 0.6688s	
5757/33150 (epoch 8.683), train_loss = 1.07056364, grad/param norm = 1.4040e-01, time/batch = 0.6843s	
5758/33150 (epoch 8.685), train_loss = 1.29832296, grad/param norm = 1.6456e-01, time/batch = 0.6692s	
5759/33150 (epoch 8.686), train_loss = 1.07747532, grad/param norm = 1.4728e-01, time/batch = 0.6705s	
5760/33150 (epoch 8.688), train_loss = 1.19952506, grad/param norm = 1.5763e-01, time/batch = 0.6792s	
5761/33150 (epoch 8.689), train_loss = 1.14021778, grad/param norm = 1.5104e-01, time/batch = 0.6786s	
5762/33150 (epoch 8.691), train_loss = 1.05226397, grad/param norm = 1.4529e-01, time/batch = 0.6687s	
5763/33150 (epoch 8.692), train_loss = 1.16211085, grad/param norm = 1.5822e-01, time/batch = 0.6665s	
5764/33150 (epoch 8.694), train_loss = 0.99044250, grad/param norm = 1.2489e-01, time/batch = 0.6665s	
5765/33150 (epoch 8.695), train_loss = 1.18902513, grad/param norm = 1.5084e-01, time/batch = 0.6647s	
5766/33150 (epoch 8.697), train_loss = 1.07039493, grad/param norm = 1.4392e-01, time/batch = 0.6649s	
5767/33150 (epoch 8.698), train_loss = 1.31983844, grad/param norm = 1.6129e-01, time/batch = 0.6647s	
5768/33150 (epoch 8.700), train_loss = 0.96702604, grad/param norm = 1.4129e-01, time/batch = 0.6671s	
5769/33150 (epoch 8.701), train_loss = 1.13720605, grad/param norm = 1.4961e-01, time/batch = 0.6640s	
5770/33150 (epoch 8.703), train_loss = 1.24033877, grad/param norm = 1.4905e-01, time/batch = 0.6678s	
5771/33150 (epoch 8.704), train_loss = 1.04380350, grad/param norm = 1.4353e-01, time/batch = 0.6674s	
5772/33150 (epoch 8.706), train_loss = 1.19163420, grad/param norm = 1.4157e-01, time/batch = 0.6789s	
5773/33150 (epoch 8.707), train_loss = 1.21744922, grad/param norm = 1.6621e-01, time/batch = 0.6858s	
5774/33150 (epoch 8.709), train_loss = 1.26285313, grad/param norm = 1.4184e-01, time/batch = 0.6744s	
5775/33150 (epoch 8.710), train_loss = 1.33107556, grad/param norm = 1.6829e-01, time/batch = 0.6803s	
5776/33150 (epoch 8.712), train_loss = 1.36886523, grad/param norm = 1.7119e-01, time/batch = 0.6727s	
5777/33150 (epoch 8.713), train_loss = 1.30657294, grad/param norm = 1.6648e-01, time/batch = 0.6653s	
5778/33150 (epoch 8.715), train_loss = 1.17932132, grad/param norm = 1.4159e-01, time/batch = 0.6696s	
5779/33150 (epoch 8.716), train_loss = 1.29867118, grad/param norm = 1.5715e-01, time/batch = 0.6697s	
5780/33150 (epoch 8.718), train_loss = 1.26293401, grad/param norm = 1.4396e-01, time/batch = 0.6634s	
5781/33150 (epoch 8.719), train_loss = 1.38407300, grad/param norm = 1.8119e-01, time/batch = 0.6649s	
5782/33150 (epoch 8.721), train_loss = 1.23845435, grad/param norm = 1.7154e-01, time/batch = 0.6632s	
5783/33150 (epoch 8.722), train_loss = 1.28747188, grad/param norm = 1.6275e-01, time/batch = 0.6682s	
5784/33150 (epoch 8.724), train_loss = 1.20852866, grad/param norm = 1.4560e-01, time/batch = 0.6629s	
5785/33150 (epoch 8.725), train_loss = 1.44884737, grad/param norm = 1.7948e-01, time/batch = 0.6635s	
5786/33150 (epoch 8.727), train_loss = 1.29381849, grad/param norm = 1.6990e-01, time/batch = 0.6657s	
5787/33150 (epoch 8.729), train_loss = 1.27354330, grad/param norm = 1.6269e-01, time/batch = 0.6635s	
5788/33150 (epoch 8.730), train_loss = 1.27879840, grad/param norm = 1.6461e-01, time/batch = 0.6634s	
5789/33150 (epoch 8.732), train_loss = 1.35667720, grad/param norm = 1.6049e-01, time/batch = 0.6753s	
5790/33150 (epoch 8.733), train_loss = 1.02685365, grad/param norm = 1.2100e-01, time/batch = 0.6801s	
5791/33150 (epoch 8.735), train_loss = 1.21825688, grad/param norm = 1.5021e-01, time/batch = 0.6863s	
5792/33150 (epoch 8.736), train_loss = 1.19194013, grad/param norm = 1.6925e-01, time/batch = 0.6862s	
5793/33150 (epoch 8.738), train_loss = 1.32632338, grad/param norm = 1.7087e-01, time/batch = 0.6894s	
5794/33150 (epoch 8.739), train_loss = 1.39944051, grad/param norm = 1.7999e-01, time/batch = 0.6732s	
5795/33150 (epoch 8.741), train_loss = 1.39936569, grad/param norm = 1.7663e-01, time/batch = 0.6690s	
5796/33150 (epoch 8.742), train_loss = 1.21937605, grad/param norm = 1.6338e-01, time/batch = 0.6694s	
5797/33150 (epoch 8.744), train_loss = 1.42169895, grad/param norm = 1.7184e-01, time/batch = 0.6631s	
5798/33150 (epoch 8.745), train_loss = 1.19641020, grad/param norm = 1.4743e-01, time/batch = 0.6838s	
5799/33150 (epoch 8.747), train_loss = 1.08237146, grad/param norm = 1.4662e-01, time/batch = 0.6790s	
5800/33150 (epoch 8.748), train_loss = 1.19336583, grad/param norm = 1.5287e-01, time/batch = 0.6698s	
5801/33150 (epoch 8.750), train_loss = 1.33443622, grad/param norm = 1.7471e-01, time/batch = 0.6625s	
5802/33150 (epoch 8.751), train_loss = 1.25344526, grad/param norm = 1.6209e-01, time/batch = 0.6682s	
5803/33150 (epoch 8.753), train_loss = 1.08480419, grad/param norm = 1.6168e-01, time/batch = 0.6688s	
5804/33150 (epoch 8.754), train_loss = 1.52084107, grad/param norm = 1.8540e-01, time/batch = 0.6679s	
5805/33150 (epoch 8.756), train_loss = 1.29797091, grad/param norm = 1.7263e-01, time/batch = 0.6685s	
5806/33150 (epoch 8.757), train_loss = 1.29144094, grad/param norm = 1.5597e-01, time/batch = 0.6666s	
5807/33150 (epoch 8.759), train_loss = 1.47453225, grad/param norm = 1.7163e-01, time/batch = 0.6708s	
5808/33150 (epoch 8.760), train_loss = 1.32514701, grad/param norm = 1.6691e-01, time/batch = 0.6665s	
5809/33150 (epoch 8.762), train_loss = 1.30825795, grad/param norm = 1.6515e-01, time/batch = 0.6648s	
5810/33150 (epoch 8.763), train_loss = 1.25107232, grad/param norm = 1.5412e-01, time/batch = 0.6706s	
5811/33150 (epoch 8.765), train_loss = 1.21739754, grad/param norm = 1.5092e-01, time/batch = 0.6708s	
5812/33150 (epoch 8.766), train_loss = 1.16448036, grad/param norm = 1.4352e-01, time/batch = 0.6692s	
5813/33150 (epoch 8.768), train_loss = 1.21017713, grad/param norm = 1.6501e-01, time/batch = 0.6758s	
5814/33150 (epoch 8.769), train_loss = 1.27234023, grad/param norm = 1.6765e-01, time/batch = 0.6693s	
5815/33150 (epoch 8.771), train_loss = 1.28743468, grad/param norm = 1.7371e-01, time/batch = 0.6694s	
5816/33150 (epoch 8.772), train_loss = 1.33717346, grad/param norm = 1.8263e-01, time/batch = 0.6722s	
5817/33150 (epoch 8.774), train_loss = 1.43118131, grad/param norm = 1.7070e-01, time/batch = 0.6758s	
5818/33150 (epoch 8.775), train_loss = 1.31651586, grad/param norm = 1.9573e-01, time/batch = 0.6841s	
5819/33150 (epoch 8.777), train_loss = 1.36455588, grad/param norm = 1.7914e-01, time/batch = 0.6721s	
5820/33150 (epoch 8.778), train_loss = 1.26222956, grad/param norm = 1.4880e-01, time/batch = 0.6706s	
5821/33150 (epoch 8.780), train_loss = 1.14911605, grad/param norm = 1.5554e-01, time/batch = 0.6726s	
5822/33150 (epoch 8.781), train_loss = 1.24211900, grad/param norm = 1.5714e-01, time/batch = 0.6689s	
5823/33150 (epoch 8.783), train_loss = 1.24860277, grad/param norm = 1.4158e-01, time/batch = 0.6684s	
5824/33150 (epoch 8.784), train_loss = 1.21820119, grad/param norm = 1.6147e-01, time/batch = 0.6614s	
5825/33150 (epoch 8.786), train_loss = 1.22055085, grad/param norm = 1.4953e-01, time/batch = 0.6637s	
5826/33150 (epoch 8.787), train_loss = 1.22373249, grad/param norm = 1.5670e-01, time/batch = 0.6655s	
5827/33150 (epoch 8.789), train_loss = 1.07943251, grad/param norm = 1.3403e-01, time/batch = 0.6661s	
5828/33150 (epoch 8.790), train_loss = 1.04592784, grad/param norm = 1.3109e-01, time/batch = 0.6686s	
5829/33150 (epoch 8.792), train_loss = 1.34270629, grad/param norm = 1.8734e-01, time/batch = 0.6721s	
5830/33150 (epoch 8.793), train_loss = 1.24128308, grad/param norm = 1.6306e-01, time/batch = 0.6800s	
5831/33150 (epoch 8.795), train_loss = 1.19852576, grad/param norm = 1.7136e-01, time/batch = 0.6782s	
5832/33150 (epoch 8.796), train_loss = 1.14139439, grad/param norm = 1.5651e-01, time/batch = 0.6680s	
5833/33150 (epoch 8.798), train_loss = 1.19207531, grad/param norm = 1.3691e-01, time/batch = 0.6657s	
5834/33150 (epoch 8.799), train_loss = 1.08236932, grad/param norm = 1.5935e-01, time/batch = 0.6666s	
5835/33150 (epoch 8.801), train_loss = 1.25649759, grad/param norm = 1.4944e-01, time/batch = 0.6675s	
5836/33150 (epoch 8.802), train_loss = 1.16398163, grad/param norm = 1.6755e-01, time/batch = 0.6659s	
5837/33150 (epoch 8.804), train_loss = 1.23536188, grad/param norm = 1.5971e-01, time/batch = 0.6809s	
5838/33150 (epoch 8.805), train_loss = 1.22095916, grad/param norm = 1.6408e-01, time/batch = 0.6714s	
5839/33150 (epoch 8.807), train_loss = 1.16142153, grad/param norm = 1.5149e-01, time/batch = 0.6640s	
5840/33150 (epoch 8.808), train_loss = 1.31605908, grad/param norm = 1.5996e-01, time/batch = 0.6657s	
5841/33150 (epoch 8.810), train_loss = 1.22086739, grad/param norm = 1.6179e-01, time/batch = 0.6678s	
5842/33150 (epoch 8.811), train_loss = 1.32698065, grad/param norm = 1.6660e-01, time/batch = 0.6649s	
5843/33150 (epoch 8.813), train_loss = 1.20910731, grad/param norm = 1.4427e-01, time/batch = 0.6673s	
5844/33150 (epoch 8.814), train_loss = 1.25672664, grad/param norm = 1.7351e-01, time/batch = 0.6668s	
5845/33150 (epoch 8.816), train_loss = 1.23932679, grad/param norm = 1.7109e-01, time/batch = 0.6677s	
5846/33150 (epoch 8.817), train_loss = 1.34250799, grad/param norm = 1.5243e-01, time/batch = 0.6691s	
5847/33150 (epoch 8.819), train_loss = 1.23159180, grad/param norm = 1.5378e-01, time/batch = 0.6686s	
5848/33150 (epoch 8.821), train_loss = 1.05750445, grad/param norm = 1.3065e-01, time/batch = 0.6646s	
5849/33150 (epoch 8.822), train_loss = 1.14008973, grad/param norm = 1.5063e-01, time/batch = 0.6659s	
5850/33150 (epoch 8.824), train_loss = 1.21166452, grad/param norm = 1.6511e-01, time/batch = 0.6663s	
5851/33150 (epoch 8.825), train_loss = 1.25992601, grad/param norm = 1.6039e-01, time/batch = 0.6675s	
5852/33150 (epoch 8.827), train_loss = 1.34968811, grad/param norm = 1.8471e-01, time/batch = 0.6659s	
5853/33150 (epoch 8.828), train_loss = 1.14243648, grad/param norm = 1.6339e-01, time/batch = 0.6677s	
5854/33150 (epoch 8.830), train_loss = 1.28914863, grad/param norm = 1.5817e-01, time/batch = 0.6636s	
5855/33150 (epoch 8.831), train_loss = 1.19726366, grad/param norm = 1.6889e-01, time/batch = 0.6648s	
5856/33150 (epoch 8.833), train_loss = 1.13437387, grad/param norm = 1.5967e-01, time/batch = 0.6653s	
5857/33150 (epoch 8.834), train_loss = 1.42319074, grad/param norm = 1.7319e-01, time/batch = 0.6636s	
5858/33150 (epoch 8.836), train_loss = 1.36972320, grad/param norm = 1.8498e-01, time/batch = 0.6667s	
5859/33150 (epoch 8.837), train_loss = 1.24446273, grad/param norm = 1.5069e-01, time/batch = 0.6694s	
5860/33150 (epoch 8.839), train_loss = 1.39616476, grad/param norm = 2.0328e-01, time/batch = 0.6800s	
5861/33150 (epoch 8.840), train_loss = 1.35694393, grad/param norm = 1.7457e-01, time/batch = 0.6678s	
5862/33150 (epoch 8.842), train_loss = 1.42667745, grad/param norm = 1.9395e-01, time/batch = 0.6674s	
5863/33150 (epoch 8.843), train_loss = 1.35887330, grad/param norm = 1.7573e-01, time/batch = 0.6670s	
5864/33150 (epoch 8.845), train_loss = 1.19291166, grad/param norm = 1.5634e-01, time/batch = 0.6683s	
5865/33150 (epoch 8.846), train_loss = 1.52399010, grad/param norm = 2.0843e-01, time/batch = 0.6700s	
5866/33150 (epoch 8.848), train_loss = 1.31639377, grad/param norm = 1.5632e-01, time/batch = 0.6621s	
5867/33150 (epoch 8.849), train_loss = 1.31504615, grad/param norm = 1.7178e-01, time/batch = 0.6631s	
5868/33150 (epoch 8.851), train_loss = 1.39244612, grad/param norm = 1.8041e-01, time/batch = 0.6644s	
5869/33150 (epoch 8.852), train_loss = 1.40462256, grad/param norm = 1.6449e-01, time/batch = 0.6658s	
5870/33150 (epoch 8.854), train_loss = 1.28039925, grad/param norm = 1.5100e-01, time/batch = 0.6652s	
5871/33150 (epoch 8.855), train_loss = 1.04631304, grad/param norm = 1.4094e-01, time/batch = 0.6679s	
5872/33150 (epoch 8.857), train_loss = 1.07989965, grad/param norm = 1.4113e-01, time/batch = 0.6652s	
5873/33150 (epoch 8.858), train_loss = 1.18951694, grad/param norm = 1.5063e-01, time/batch = 0.6659s	
5874/33150 (epoch 8.860), train_loss = 1.13413694, grad/param norm = 1.4564e-01, time/batch = 0.6655s	
5875/33150 (epoch 8.861), train_loss = 1.16815421, grad/param norm = 1.4888e-01, time/batch = 0.6659s	
5876/33150 (epoch 8.863), train_loss = 1.29216705, grad/param norm = 1.4462e-01, time/batch = 0.6667s	
5877/33150 (epoch 8.864), train_loss = 1.38535390, grad/param norm = 1.5872e-01, time/batch = 0.6653s	
5878/33150 (epoch 8.866), train_loss = 1.26027267, grad/param norm = 1.6187e-01, time/batch = 0.6630s	
5879/33150 (epoch 8.867), train_loss = 1.30466462, grad/param norm = 1.4331e-01, time/batch = 0.6627s	
5880/33150 (epoch 8.869), train_loss = 1.34395001, grad/param norm = 1.7665e-01, time/batch = 0.6701s	
5881/33150 (epoch 8.870), train_loss = 1.34574854, grad/param norm = 1.7166e-01, time/batch = 0.6891s	
5882/33150 (epoch 8.872), train_loss = 1.26092650, grad/param norm = 1.6799e-01, time/batch = 0.6800s	
5883/33150 (epoch 8.873), train_loss = 1.06256274, grad/param norm = 1.4182e-01, time/batch = 0.6756s	
5884/33150 (epoch 8.875), train_loss = 1.43677336, grad/param norm = 1.6771e-01, time/batch = 0.6660s	
5885/33150 (epoch 8.876), train_loss = 1.18544738, grad/param norm = 1.7428e-01, time/batch = 0.6746s	
5886/33150 (epoch 8.878), train_loss = 1.12034151, grad/param norm = 1.3960e-01, time/batch = 0.6897s	
5887/33150 (epoch 8.879), train_loss = 1.17908122, grad/param norm = 1.6549e-01, time/batch = 0.6994s	
5888/33150 (epoch 8.881), train_loss = 1.20242632, grad/param norm = 1.4727e-01, time/batch = 0.6877s	
5889/33150 (epoch 8.882), train_loss = 1.11816782, grad/param norm = 1.4412e-01, time/batch = 0.6745s	
5890/33150 (epoch 8.884), train_loss = 1.26329375, grad/param norm = 1.6262e-01, time/batch = 0.6651s	
5891/33150 (epoch 8.885), train_loss = 0.99895539, grad/param norm = 1.5318e-01, time/batch = 0.6660s	
5892/33150 (epoch 8.887), train_loss = 1.46320445, grad/param norm = 1.7433e-01, time/batch = 0.6632s	
5893/33150 (epoch 8.888), train_loss = 1.31129753, grad/param norm = 1.7079e-01, time/batch = 0.6652s	
5894/33150 (epoch 8.890), train_loss = 1.21522780, grad/param norm = 1.6251e-01, time/batch = 0.6639s	
5895/33150 (epoch 8.891), train_loss = 1.15187138, grad/param norm = 1.6566e-01, time/batch = 0.6635s	
5896/33150 (epoch 8.893), train_loss = 1.34680825, grad/param norm = 1.7386e-01, time/batch = 0.6692s	
5897/33150 (epoch 8.894), train_loss = 1.33567710, grad/param norm = 1.5921e-01, time/batch = 0.6789s	
5898/33150 (epoch 8.896), train_loss = 1.19618452, grad/param norm = 1.4623e-01, time/batch = 0.6645s	
5899/33150 (epoch 8.897), train_loss = 1.27369936, grad/param norm = 1.4704e-01, time/batch = 0.6716s	
5900/33150 (epoch 8.899), train_loss = 1.13225287, grad/param norm = 1.7151e-01, time/batch = 0.6631s	
5901/33150 (epoch 8.900), train_loss = 1.56044823, grad/param norm = 1.7689e-01, time/batch = 0.6699s	
5902/33150 (epoch 8.902), train_loss = 1.44575298, grad/param norm = 1.7344e-01, time/batch = 0.6668s	
5903/33150 (epoch 8.903), train_loss = 1.25994014, grad/param norm = 1.5297e-01, time/batch = 0.6691s	
5904/33150 (epoch 8.905), train_loss = 1.28305095, grad/param norm = 1.6043e-01, time/batch = 0.6674s	
5905/33150 (epoch 8.906), train_loss = 1.36412483, grad/param norm = 1.7456e-01, time/batch = 0.6674s	
5906/33150 (epoch 8.908), train_loss = 1.40883091, grad/param norm = 1.6525e-01, time/batch = 0.6636s	
5907/33150 (epoch 8.910), train_loss = 1.34386192, grad/param norm = 1.5186e-01, time/batch = 0.6633s	
5908/33150 (epoch 8.911), train_loss = 1.10711730, grad/param norm = 1.3927e-01, time/batch = 0.6686s	
5909/33150 (epoch 8.913), train_loss = 1.15652268, grad/param norm = 1.5002e-01, time/batch = 0.6804s	
5910/33150 (epoch 8.914), train_loss = 1.35633835, grad/param norm = 1.7986e-01, time/batch = 0.6664s	
5911/33150 (epoch 8.916), train_loss = 1.16249183, grad/param norm = 1.7943e-01, time/batch = 0.6690s	
5912/33150 (epoch 8.917), train_loss = 1.41781839, grad/param norm = 1.7691e-01, time/batch = 0.6702s	
5913/33150 (epoch 8.919), train_loss = 1.47099461, grad/param norm = 1.8414e-01, time/batch = 0.6669s	
5914/33150 (epoch 8.920), train_loss = 1.36043356, grad/param norm = 1.6089e-01, time/batch = 0.6690s	
5915/33150 (epoch 8.922), train_loss = 1.44864158, grad/param norm = 1.7519e-01, time/batch = 0.6668s	
5916/33150 (epoch 8.923), train_loss = 1.27049774, grad/param norm = 1.6270e-01, time/batch = 0.6681s	
5917/33150 (epoch 8.925), train_loss = 1.30669142, grad/param norm = 1.6246e-01, time/batch = 0.6706s	
5918/33150 (epoch 8.926), train_loss = 1.24868242, grad/param norm = 1.5899e-01, time/batch = 0.6695s	
5919/33150 (epoch 8.928), train_loss = 1.24211811, grad/param norm = 1.6646e-01, time/batch = 0.6714s	
5920/33150 (epoch 8.929), train_loss = 1.32197393, grad/param norm = 1.5305e-01, time/batch = 0.6694s	
5921/33150 (epoch 8.931), train_loss = 1.44629690, grad/param norm = 1.9141e-01, time/batch = 0.6700s	
5922/33150 (epoch 8.932), train_loss = 1.27428855, grad/param norm = 1.7671e-01, time/batch = 0.6715s	
5923/33150 (epoch 8.934), train_loss = 1.28206084, grad/param norm = 1.5158e-01, time/batch = 0.6799s	
5924/33150 (epoch 8.935), train_loss = 1.38207422, grad/param norm = 1.5934e-01, time/batch = 0.6691s	
5925/33150 (epoch 8.937), train_loss = 1.39506229, grad/param norm = 1.6667e-01, time/batch = 0.6674s	
5926/33150 (epoch 8.938), train_loss = 1.36236088, grad/param norm = 1.5422e-01, time/batch = 0.6711s	
5927/33150 (epoch 8.940), train_loss = 1.57436529, grad/param norm = 1.7402e-01, time/batch = 0.6820s	
5928/33150 (epoch 8.941), train_loss = 1.23162923, grad/param norm = 1.4500e-01, time/batch = 0.6792s	
5929/33150 (epoch 8.943), train_loss = 1.15208650, grad/param norm = 1.7590e-01, time/batch = 0.6891s	
5930/33150 (epoch 8.944), train_loss = 1.41430892, grad/param norm = 1.8021e-01, time/batch = 0.6817s	
5931/33150 (epoch 8.946), train_loss = 1.05416312, grad/param norm = 1.4580e-01, time/batch = 0.6722s	
5932/33150 (epoch 8.947), train_loss = 1.33214129, grad/param norm = 1.6503e-01, time/batch = 0.6794s	
5933/33150 (epoch 8.949), train_loss = 1.42348882, grad/param norm = 1.5773e-01, time/batch = 0.6742s	
5934/33150 (epoch 8.950), train_loss = 1.35984357, grad/param norm = 1.7348e-01, time/batch = 0.6907s	
5935/33150 (epoch 8.952), train_loss = 1.19343687, grad/param norm = 1.5075e-01, time/batch = 0.6673s	
5936/33150 (epoch 8.953), train_loss = 1.19841978, grad/param norm = 1.4682e-01, time/batch = 0.6810s	
5937/33150 (epoch 8.955), train_loss = 1.14514532, grad/param norm = 1.5136e-01, time/batch = 0.6661s	
5938/33150 (epoch 8.956), train_loss = 1.37024985, grad/param norm = 1.6269e-01, time/batch = 0.6770s	
5939/33150 (epoch 8.958), train_loss = 1.12205890, grad/param norm = 1.5055e-01, time/batch = 0.6796s	
5940/33150 (epoch 8.959), train_loss = 1.15672225, grad/param norm = 1.6386e-01, time/batch = 0.6854s	
5941/33150 (epoch 8.961), train_loss = 1.13953133, grad/param norm = 1.4902e-01, time/batch = 0.6868s	
5942/33150 (epoch 8.962), train_loss = 1.08674859, grad/param norm = 1.4000e-01, time/batch = 0.6933s	
5943/33150 (epoch 8.964), train_loss = 1.27347025, grad/param norm = 1.6330e-01, time/batch = 0.6843s	
5944/33150 (epoch 8.965), train_loss = 1.25300614, grad/param norm = 1.5864e-01, time/batch = 0.6827s	
5945/33150 (epoch 8.967), train_loss = 1.31210501, grad/param norm = 1.7291e-01, time/batch = 0.6870s	
5946/33150 (epoch 8.968), train_loss = 1.06794907, grad/param norm = 1.4493e-01, time/batch = 0.6861s	
5947/33150 (epoch 8.970), train_loss = 1.20616018, grad/param norm = 1.6062e-01, time/batch = 0.6831s	
5948/33150 (epoch 8.971), train_loss = 1.31106543, grad/param norm = 1.8478e-01, time/batch = 0.6852s	
5949/33150 (epoch 8.973), train_loss = 1.45021429, grad/param norm = 1.6500e-01, time/batch = 0.6806s	
5950/33150 (epoch 8.974), train_loss = 1.47220707, grad/param norm = 1.8383e-01, time/batch = 0.6730s	
5951/33150 (epoch 8.976), train_loss = 1.32433407, grad/param norm = 1.5493e-01, time/batch = 0.6926s	
5952/33150 (epoch 8.977), train_loss = 1.39850290, grad/param norm = 1.6961e-01, time/batch = 0.6921s	
5953/33150 (epoch 8.979), train_loss = 1.40578993, grad/param norm = 1.7731e-01, time/batch = 0.6830s	
5954/33150 (epoch 8.980), train_loss = 1.40279812, grad/param norm = 1.6678e-01, time/batch = 0.6871s	
5955/33150 (epoch 8.982), train_loss = 1.23312788, grad/param norm = 1.6390e-01, time/batch = 0.6856s	
5956/33150 (epoch 8.983), train_loss = 1.12682339, grad/param norm = 1.5284e-01, time/batch = 0.6846s	
5957/33150 (epoch 8.985), train_loss = 1.29237027, grad/param norm = 1.5329e-01, time/batch = 0.6848s	
5958/33150 (epoch 8.986), train_loss = 1.11825683, grad/param norm = 1.4543e-01, time/batch = 0.6859s	
5959/33150 (epoch 8.988), train_loss = 1.21673656, grad/param norm = 1.5619e-01, time/batch = 0.6856s	
5960/33150 (epoch 8.989), train_loss = 1.14473526, grad/param norm = 1.5739e-01, time/batch = 0.6859s	
5961/33150 (epoch 8.991), train_loss = 1.38171795, grad/param norm = 1.9754e-01, time/batch = 0.6891s	
5962/33150 (epoch 8.992), train_loss = 1.11529833, grad/param norm = 1.5280e-01, time/batch = 0.6817s	
5963/33150 (epoch 8.994), train_loss = 1.22478663, grad/param norm = 1.6062e-01, time/batch = 0.6839s	
5964/33150 (epoch 8.995), train_loss = 1.16783517, grad/param norm = 1.5313e-01, time/batch = 0.6729s	
5965/33150 (epoch 8.997), train_loss = 1.29442825, grad/param norm = 1.7801e-01, time/batch = 0.6770s	
5966/33150 (epoch 8.998), train_loss = 1.00788911, grad/param norm = 1.4485e-01, time/batch = 0.6750s	
5967/33150 (epoch 9.000), train_loss = 1.13549417, grad/param norm = 1.5899e-01, time/batch = 0.6720s	
5968/33150 (epoch 9.002), train_loss = 1.55817849, grad/param norm = 1.9038e-01, time/batch = 0.6767s	
5969/33150 (epoch 9.003), train_loss = 1.19376231, grad/param norm = 1.6372e-01, time/batch = 0.6872s	
5970/33150 (epoch 9.005), train_loss = 1.10860819, grad/param norm = 1.4918e-01, time/batch = 0.6864s	
5971/33150 (epoch 9.006), train_loss = 1.06622630, grad/param norm = 1.5187e-01, time/batch = 0.6860s	
5972/33150 (epoch 9.008), train_loss = 1.42514909, grad/param norm = 1.8689e-01, time/batch = 0.6860s	
5973/33150 (epoch 9.009), train_loss = 1.22012496, grad/param norm = 1.3631e-01, time/batch = 0.6974s	
5974/33150 (epoch 9.011), train_loss = 1.44736210, grad/param norm = 1.6460e-01, time/batch = 0.6819s	
5975/33150 (epoch 9.012), train_loss = 1.26104637, grad/param norm = 1.7696e-01, time/batch = 0.6790s	
5976/33150 (epoch 9.014), train_loss = 1.24775541, grad/param norm = 1.8359e-01, time/batch = 0.6757s	
5977/33150 (epoch 9.015), train_loss = 1.22226648, grad/param norm = 1.5402e-01, time/batch = 0.6770s	
5978/33150 (epoch 9.017), train_loss = 1.18453587, grad/param norm = 1.5128e-01, time/batch = 0.6858s	
5979/33150 (epoch 9.018), train_loss = 1.30758731, grad/param norm = 1.6080e-01, time/batch = 0.6728s	
5980/33150 (epoch 9.020), train_loss = 1.30962993, grad/param norm = 1.6236e-01, time/batch = 0.6809s	
5981/33150 (epoch 9.021), train_loss = 1.06735624, grad/param norm = 1.5897e-01, time/batch = 0.6833s	
5982/33150 (epoch 9.023), train_loss = 1.42986211, grad/param norm = 1.4892e-01, time/batch = 0.6905s	
5983/33150 (epoch 9.024), train_loss = 1.27564892, grad/param norm = 1.6077e-01, time/batch = 0.6861s	
5984/33150 (epoch 9.026), train_loss = 1.00573117, grad/param norm = 1.3020e-01, time/batch = 0.6793s	
5985/33150 (epoch 9.027), train_loss = 1.05206264, grad/param norm = 1.5005e-01, time/batch = 0.6877s	
5986/33150 (epoch 9.029), train_loss = 1.16409621, grad/param norm = 1.6734e-01, time/batch = 0.6852s	
5987/33150 (epoch 9.030), train_loss = 1.24295594, grad/param norm = 1.4355e-01, time/batch = 0.6843s	
5988/33150 (epoch 9.032), train_loss = 1.15337715, grad/param norm = 1.6307e-01, time/batch = 0.6651s	
5989/33150 (epoch 9.033), train_loss = 1.21346018, grad/param norm = 1.6380e-01, time/batch = 0.6666s	
5990/33150 (epoch 9.035), train_loss = 1.45120880, grad/param norm = 1.7751e-01, time/batch = 0.6706s	
5991/33150 (epoch 9.036), train_loss = 1.33780932, grad/param norm = 1.6974e-01, time/batch = 0.6723s	
5992/33150 (epoch 9.038), train_loss = 1.59050452, grad/param norm = 1.9537e-01, time/batch = 0.6793s	
5993/33150 (epoch 9.039), train_loss = 1.27625182, grad/param norm = 1.4273e-01, time/batch = 0.6779s	
5994/33150 (epoch 9.041), train_loss = 1.27973941, grad/param norm = 1.5715e-01, time/batch = 0.6652s	
5995/33150 (epoch 9.042), train_loss = 1.18969200, grad/param norm = 1.4853e-01, time/batch = 0.6661s	
5996/33150 (epoch 9.044), train_loss = 1.19604015, grad/param norm = 1.4154e-01, time/batch = 0.6661s	
5997/33150 (epoch 9.045), train_loss = 1.23268056, grad/param norm = 1.4556e-01, time/batch = 0.6650s	
5998/33150 (epoch 9.047), train_loss = 1.18425367, grad/param norm = 1.6848e-01, time/batch = 0.6953s	
5999/33150 (epoch 9.048), train_loss = 1.43030969, grad/param norm = 1.9443e-01, time/batch = 0.6861s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch9.05_1.4975.t7	
6000/33150 (epoch 9.050), train_loss = 1.25242909, grad/param norm = 1.6083e-01, time/batch = 0.6841s	
6001/33150 (epoch 9.051), train_loss = 1.36105492, grad/param norm = 1.9532e-01, time/batch = 0.6769s	
6002/33150 (epoch 9.053), train_loss = 1.21128669, grad/param norm = 1.6230e-01, time/batch = 0.6728s	
6003/33150 (epoch 9.054), train_loss = 1.28703483, grad/param norm = 1.4036e-01, time/batch = 0.6703s	
6004/33150 (epoch 9.056), train_loss = 1.15092589, grad/param norm = 1.4082e-01, time/batch = 0.6699s	
6005/33150 (epoch 9.057), train_loss = 1.25407665, grad/param norm = 1.6711e-01, time/batch = 0.6716s	
6006/33150 (epoch 9.059), train_loss = 1.18481974, grad/param norm = 1.5917e-01, time/batch = 0.6709s	
6007/33150 (epoch 9.060), train_loss = 1.17606649, grad/param norm = 1.4578e-01, time/batch = 0.6763s	
6008/33150 (epoch 9.062), train_loss = 1.23465187, grad/param norm = 1.5058e-01, time/batch = 0.6642s	
6009/33150 (epoch 9.063), train_loss = 1.20479649, grad/param norm = 1.5335e-01, time/batch = 0.6672s	
6010/33150 (epoch 9.065), train_loss = 1.23144908, grad/param norm = 1.4227e-01, time/batch = 0.6652s	
6011/33150 (epoch 9.066), train_loss = 1.16983236, grad/param norm = 1.5668e-01, time/batch = 0.6633s	
6012/33150 (epoch 9.068), train_loss = 1.25246561, grad/param norm = 1.6069e-01, time/batch = 0.6725s	
6013/33150 (epoch 9.069), train_loss = 1.32013612, grad/param norm = 1.7925e-01, time/batch = 0.6790s	
6014/33150 (epoch 9.071), train_loss = 1.30031110, grad/param norm = 1.5047e-01, time/batch = 0.6657s	
6015/33150 (epoch 9.072), train_loss = 1.15902891, grad/param norm = 1.4438e-01, time/batch = 0.6664s	
6016/33150 (epoch 9.074), train_loss = 1.07854815, grad/param norm = 1.6002e-01, time/batch = 0.6649s	
6017/33150 (epoch 9.075), train_loss = 1.19639122, grad/param norm = 1.4625e-01, time/batch = 0.6657s	
6018/33150 (epoch 9.077), train_loss = 1.33171760, grad/param norm = 2.0948e-01, time/batch = 0.6739s	
6019/33150 (epoch 9.078), train_loss = 1.46207221, grad/param norm = 2.0148e-01, time/batch = 0.6713s	
6020/33150 (epoch 9.080), train_loss = 1.34731418, grad/param norm = 1.5218e-01, time/batch = 0.6678s	
6021/33150 (epoch 9.081), train_loss = 1.17669885, grad/param norm = 1.6871e-01, time/batch = 0.6726s	
6022/33150 (epoch 9.083), train_loss = 0.92462499, grad/param norm = 1.6282e-01, time/batch = 0.6681s	
6023/33150 (epoch 9.084), train_loss = 1.08825288, grad/param norm = 1.6007e-01, time/batch = 0.6680s	
6024/33150 (epoch 9.086), train_loss = 1.18514345, grad/param norm = 1.6584e-01, time/batch = 0.6669s	
6025/33150 (epoch 9.087), train_loss = 1.13488143, grad/param norm = 1.6229e-01, time/batch = 0.6656s	
6026/33150 (epoch 9.089), train_loss = 1.16143525, grad/param norm = 1.6969e-01, time/batch = 0.6681s	
6027/33150 (epoch 9.090), train_loss = 1.17761141, grad/param norm = 1.6951e-01, time/batch = 0.6760s	
6028/33150 (epoch 9.092), train_loss = 1.21877317, grad/param norm = 1.6429e-01, time/batch = 0.6776s	
6029/33150 (epoch 9.094), train_loss = 1.34685960, grad/param norm = 1.9175e-01, time/batch = 0.6704s	
6030/33150 (epoch 9.095), train_loss = 1.08756956, grad/param norm = 1.4441e-01, time/batch = 0.6720s	
6031/33150 (epoch 9.097), train_loss = 1.25679691, grad/param norm = 1.6564e-01, time/batch = 0.6742s	
6032/33150 (epoch 9.098), train_loss = 1.50476137, grad/param norm = 1.8384e-01, time/batch = 0.6832s	
6033/33150 (epoch 9.100), train_loss = 1.44575353, grad/param norm = 1.6258e-01, time/batch = 0.6747s	
6034/33150 (epoch 9.101), train_loss = 1.15242734, grad/param norm = 1.7289e-01, time/batch = 0.6727s	
6035/33150 (epoch 9.103), train_loss = 1.28697435, grad/param norm = 1.6046e-01, time/batch = 0.6722s	
6036/33150 (epoch 9.104), train_loss = 1.21505858, grad/param norm = 1.7199e-01, time/batch = 0.6728s	
6037/33150 (epoch 9.106), train_loss = 1.42436001, grad/param norm = 1.7597e-01, time/batch = 0.6729s	
6038/33150 (epoch 9.107), train_loss = 1.49184609, grad/param norm = 1.8467e-01, time/batch = 0.6686s	
6039/33150 (epoch 9.109), train_loss = 1.17011785, grad/param norm = 1.4661e-01, time/batch = 0.6894s	
6040/33150 (epoch 9.110), train_loss = 1.29919849, grad/param norm = 1.5650e-01, time/batch = 0.6751s	
6041/33150 (epoch 9.112), train_loss = 1.14819323, grad/param norm = 1.5075e-01, time/batch = 0.7054s	
6042/33150 (epoch 9.113), train_loss = 1.19634590, grad/param norm = 1.7134e-01, time/batch = 0.9943s	
6043/33150 (epoch 9.115), train_loss = 1.44047521, grad/param norm = 1.7456e-01, time/batch = 0.9790s	
6044/33150 (epoch 9.116), train_loss = 1.12156390, grad/param norm = 1.5755e-01, time/batch = 0.9904s	
6045/33150 (epoch 9.118), train_loss = 1.32703750, grad/param norm = 1.7036e-01, time/batch = 0.9980s	
6046/33150 (epoch 9.119), train_loss = 1.30552835, grad/param norm = 1.7250e-01, time/batch = 1.0691s	
6047/33150 (epoch 9.121), train_loss = 1.19803376, grad/param norm = 1.6027e-01, time/batch = 1.8906s	
6048/33150 (epoch 9.122), train_loss = 1.44302419, grad/param norm = 1.8474e-01, time/batch = 1.8050s	
6049/33150 (epoch 9.124), train_loss = 0.99064726, grad/param norm = 1.2925e-01, time/batch = 7.3348s	
6050/33150 (epoch 9.125), train_loss = 1.33123583, grad/param norm = 1.5022e-01, time/batch = 18.7395s	
6051/33150 (epoch 9.127), train_loss = 1.16611635, grad/param norm = 1.5049e-01, time/batch = 17.6324s	
6052/33150 (epoch 9.128), train_loss = 1.25421334, grad/param norm = 1.6767e-01, time/batch = 17.8022s	
6053/33150 (epoch 9.130), train_loss = 1.27775586, grad/param norm = 1.4522e-01, time/batch = 16.9767s	
6054/33150 (epoch 9.131), train_loss = 1.47870834, grad/param norm = 1.7797e-01, time/batch = 18.3116s	
6055/33150 (epoch 9.133), train_loss = 1.15620076, grad/param norm = 1.5597e-01, time/batch = 19.2151s	
6056/33150 (epoch 9.134), train_loss = 1.36052498, grad/param norm = 1.5833e-01, time/batch = 18.2102s	
6057/33150 (epoch 9.136), train_loss = 1.26618552, grad/param norm = 1.6674e-01, time/batch = 19.4751s	
6058/33150 (epoch 9.137), train_loss = 1.33494252, grad/param norm = 1.6184e-01, time/batch = 17.7406s	
6059/33150 (epoch 9.139), train_loss = 1.29439051, grad/param norm = 1.7477e-01, time/batch = 15.4741s	
6060/33150 (epoch 9.140), train_loss = 1.40212682, grad/param norm = 1.7757e-01, time/batch = 18.4730s	
6061/33150 (epoch 9.142), train_loss = 1.33943559, grad/param norm = 1.7808e-01, time/batch = 19.0555s	
6062/33150 (epoch 9.143), train_loss = 1.27766936, grad/param norm = 1.7395e-01, time/batch = 16.7208s	
6063/33150 (epoch 9.145), train_loss = 1.25039777, grad/param norm = 1.7527e-01, time/batch = 18.1400s	
6064/33150 (epoch 9.146), train_loss = 1.43065222, grad/param norm = 2.0114e-01, time/batch = 16.2159s	
6065/33150 (epoch 9.148), train_loss = 1.32091716, grad/param norm = 1.6269e-01, time/batch = 18.9843s	
6066/33150 (epoch 9.149), train_loss = 1.29267292, grad/param norm = 1.7753e-01, time/batch = 16.0723s	
6067/33150 (epoch 9.151), train_loss = 1.48767452, grad/param norm = 1.6641e-01, time/batch = 18.4000s	
6068/33150 (epoch 9.152), train_loss = 1.21406261, grad/param norm = 1.4841e-01, time/batch = 18.8979s	
6069/33150 (epoch 9.154), train_loss = 1.21428739, grad/param norm = 1.4880e-01, time/batch = 16.3817s	
6070/33150 (epoch 9.155), train_loss = 1.12469417, grad/param norm = 1.5031e-01, time/batch = 15.4428s	
6071/33150 (epoch 9.157), train_loss = 1.18891457, grad/param norm = 1.7552e-01, time/batch = 15.5535s	
6072/33150 (epoch 9.158), train_loss = 1.14650379, grad/param norm = 1.5906e-01, time/batch = 15.1690s	
6073/33150 (epoch 9.160), train_loss = 1.34476698, grad/param norm = 1.5272e-01, time/batch = 15.4731s	
6074/33150 (epoch 9.161), train_loss = 1.22480564, grad/param norm = 1.7078e-01, time/batch = 15.3434s	
6075/33150 (epoch 9.163), train_loss = 1.19274692, grad/param norm = 1.4652e-01, time/batch = 15.0029s	
6076/33150 (epoch 9.164), train_loss = 1.36073133, grad/param norm = 1.6243e-01, time/batch = 14.9295s	
6077/33150 (epoch 9.166), train_loss = 1.24606013, grad/param norm = 1.6735e-01, time/batch = 15.1390s	
6078/33150 (epoch 9.167), train_loss = 1.25490935, grad/param norm = 1.5614e-01, time/batch = 16.1464s	
6079/33150 (epoch 9.169), train_loss = 1.36596664, grad/param norm = 1.9426e-01, time/batch = 17.1251s	
6080/33150 (epoch 9.170), train_loss = 1.20575077, grad/param norm = 1.7527e-01, time/batch = 16.0378s	
6081/33150 (epoch 9.172), train_loss = 1.39096194, grad/param norm = 1.8819e-01, time/batch = 16.2197s	
6082/33150 (epoch 9.173), train_loss = 1.36606862, grad/param norm = 2.1294e-01, time/batch = 16.4482s	
6083/33150 (epoch 9.175), train_loss = 1.16918948, grad/param norm = 1.6609e-01, time/batch = 16.8893s	
6084/33150 (epoch 9.176), train_loss = 1.28168932, grad/param norm = 1.7814e-01, time/batch = 15.2756s	
6085/33150 (epoch 9.178), train_loss = 1.45618792, grad/param norm = 1.6371e-01, time/batch = 16.8034s	
6086/33150 (epoch 9.179), train_loss = 1.29995502, grad/param norm = 1.4589e-01, time/batch = 17.9641s	
6087/33150 (epoch 9.181), train_loss = 1.28137150, grad/param norm = 1.8090e-01, time/batch = 17.2268s	
6088/33150 (epoch 9.183), train_loss = 1.25473343, grad/param norm = 1.7540e-01, time/batch = 16.6044s	
6089/33150 (epoch 9.184), train_loss = 1.44270340, grad/param norm = 1.7528e-01, time/batch = 16.2022s	
6090/33150 (epoch 9.186), train_loss = 1.38708115, grad/param norm = 1.6111e-01, time/batch = 16.2421s	
6091/33150 (epoch 9.187), train_loss = 1.28594568, grad/param norm = 1.6798e-01, time/batch = 16.7031s	
6092/33150 (epoch 9.189), train_loss = 1.10060537, grad/param norm = 1.7474e-01, time/batch = 15.5999s	
6093/33150 (epoch 9.190), train_loss = 1.18352083, grad/param norm = 1.7924e-01, time/batch = 15.2841s	
6094/33150 (epoch 9.192), train_loss = 1.25541107, grad/param norm = 1.6577e-01, time/batch = 16.0090s	
6095/33150 (epoch 9.193), train_loss = 1.28408080, grad/param norm = 1.5776e-01, time/batch = 15.4216s	
6096/33150 (epoch 9.195), train_loss = 1.58708423, grad/param norm = 1.8889e-01, time/batch = 14.8594s	
6097/33150 (epoch 9.196), train_loss = 1.39827301, grad/param norm = 1.5375e-01, time/batch = 16.5071s	
6098/33150 (epoch 9.198), train_loss = 1.10605157, grad/param norm = 1.6633e-01, time/batch = 17.1266s	
6099/33150 (epoch 9.199), train_loss = 1.36265370, grad/param norm = 1.6908e-01, time/batch = 16.2845s	
6100/33150 (epoch 9.201), train_loss = 1.11287412, grad/param norm = 1.3514e-01, time/batch = 17.7046s	
6101/33150 (epoch 9.202), train_loss = 1.06724877, grad/param norm = 1.3956e-01, time/batch = 17.4748s	
6102/33150 (epoch 9.204), train_loss = 1.24217947, grad/param norm = 1.5343e-01, time/batch = 15.7181s	
6103/33150 (epoch 9.205), train_loss = 1.36670614, grad/param norm = 1.8149e-01, time/batch = 17.2116s	
6104/33150 (epoch 9.207), train_loss = 1.28074992, grad/param norm = 1.4924e-01, time/batch = 17.7935s	
6105/33150 (epoch 9.208), train_loss = 1.31680253, grad/param norm = 1.5760e-01, time/batch = 17.5562s	
6106/33150 (epoch 9.210), train_loss = 1.13254288, grad/param norm = 1.3257e-01, time/batch = 17.1152s	
6107/33150 (epoch 9.211), train_loss = 1.30107364, grad/param norm = 1.7208e-01, time/batch = 16.2839s	
6108/33150 (epoch 9.213), train_loss = 1.35736723, grad/param norm = 1.6015e-01, time/batch = 19.5468s	
6109/33150 (epoch 9.214), train_loss = 1.21652777, grad/param norm = 1.6300e-01, time/batch = 18.1211s	
6110/33150 (epoch 9.216), train_loss = 1.19070849, grad/param norm = 1.7939e-01, time/batch = 18.1201s	
6111/33150 (epoch 9.217), train_loss = 1.18404174, grad/param norm = 1.5664e-01, time/batch = 16.8959s	
6112/33150 (epoch 9.219), train_loss = 1.14395552, grad/param norm = 1.5228e-01, time/batch = 16.8810s	
6113/33150 (epoch 9.220), train_loss = 1.16153048, grad/param norm = 1.3858e-01, time/batch = 18.2103s	
6114/33150 (epoch 9.222), train_loss = 1.32901265, grad/param norm = 1.5964e-01, time/batch = 17.8916s	
6115/33150 (epoch 9.223), train_loss = 1.20788910, grad/param norm = 1.5633e-01, time/batch = 17.9626s	
6116/33150 (epoch 9.225), train_loss = 1.42683041, grad/param norm = 1.6243e-01, time/batch = 16.7751s	
6117/33150 (epoch 9.226), train_loss = 1.21119367, grad/param norm = 1.3953e-01, time/batch = 33.3695s	
6118/33150 (epoch 9.228), train_loss = 1.23440270, grad/param norm = 1.5203e-01, time/batch = 30.9155s	
6119/33150 (epoch 9.229), train_loss = 1.24272881, grad/param norm = 1.6775e-01, time/batch = 41.4986s	
6120/33150 (epoch 9.231), train_loss = 1.36901241, grad/param norm = 1.6635e-01, time/batch = 66.0853s	
6121/33150 (epoch 9.232), train_loss = 1.29824841, grad/param norm = 1.7833e-01, time/batch = 36.0440s	
6122/33150 (epoch 9.234), train_loss = 1.23250812, grad/param norm = 1.7102e-01, time/batch = 34.7856s	
6123/33150 (epoch 9.235), train_loss = 1.29037858, grad/param norm = 1.6011e-01, time/batch = 37.3226s	
6124/33150 (epoch 9.237), train_loss = 1.23907222, grad/param norm = 1.7450e-01, time/batch = 35.5728s	
6125/33150 (epoch 9.238), train_loss = 1.39275315, grad/param norm = 1.9437e-01, time/batch = 29.9285s	
6126/33150 (epoch 9.240), train_loss = 1.25731006, grad/param norm = 1.5519e-01, time/batch = 17.2328s	
6127/33150 (epoch 9.241), train_loss = 1.41258782, grad/param norm = 1.7509e-01, time/batch = 16.3127s	
6128/33150 (epoch 9.243), train_loss = 1.36874215, grad/param norm = 1.7045e-01, time/batch = 18.5695s	
6129/33150 (epoch 9.244), train_loss = 1.22906261, grad/param norm = 1.4534e-01, time/batch = 16.4796s	
6130/33150 (epoch 9.246), train_loss = 1.29891093, grad/param norm = 1.5964e-01, time/batch = 17.2242s	
6131/33150 (epoch 9.247), train_loss = 1.12846872, grad/param norm = 1.4621e-01, time/batch = 16.8978s	
6132/33150 (epoch 9.249), train_loss = 1.36636088, grad/param norm = 1.5460e-01, time/batch = 18.1418s	
6133/33150 (epoch 9.250), train_loss = 1.29594970, grad/param norm = 1.3585e-01, time/batch = 15.9174s	
6134/33150 (epoch 9.252), train_loss = 1.28838764, grad/param norm = 1.3486e-01, time/batch = 19.1448s	
6135/33150 (epoch 9.253), train_loss = 1.32518985, grad/param norm = 1.6014e-01, time/batch = 18.1600s	
6136/33150 (epoch 9.255), train_loss = 1.23646387, grad/param norm = 1.4100e-01, time/batch = 17.3895s	
6137/33150 (epoch 9.256), train_loss = 1.31898225, grad/param norm = 1.5764e-01, time/batch = 17.1244s	
6138/33150 (epoch 9.258), train_loss = 1.21218330, grad/param norm = 1.7022e-01, time/batch = 17.3190s	
6139/33150 (epoch 9.259), train_loss = 1.07493801, grad/param norm = 1.5990e-01, time/batch = 17.7171s	
6140/33150 (epoch 9.261), train_loss = 1.10109204, grad/param norm = 1.4944e-01, time/batch = 16.2248s	
6141/33150 (epoch 9.262), train_loss = 1.31255774, grad/param norm = 1.5231e-01, time/batch = 19.3041s	
6142/33150 (epoch 9.264), train_loss = 0.99190704, grad/param norm = 1.3361e-01, time/batch = 16.8232s	
6143/33150 (epoch 9.265), train_loss = 1.29418506, grad/param norm = 1.6021e-01, time/batch = 16.6401s	
6144/33150 (epoch 9.267), train_loss = 1.39545521, grad/param norm = 1.7936e-01, time/batch = 18.3227s	
6145/33150 (epoch 9.268), train_loss = 1.25351388, grad/param norm = 1.5897e-01, time/batch = 17.2222s	
6146/33150 (epoch 9.270), train_loss = 1.44049151, grad/param norm = 1.4977e-01, time/batch = 16.5516s	
6147/33150 (epoch 9.271), train_loss = 1.38684009, grad/param norm = 1.6303e-01, time/batch = 19.1269s	
6148/33150 (epoch 9.273), train_loss = 1.37538575, grad/param norm = 1.6179e-01, time/batch = 15.9769s	
6149/33150 (epoch 9.275), train_loss = 1.37735330, grad/param norm = 1.5922e-01, time/batch = 18.1438s	
6150/33150 (epoch 9.276), train_loss = 1.22831118, grad/param norm = 1.4928e-01, time/batch = 16.5658s	
6151/33150 (epoch 9.278), train_loss = 1.32420805, grad/param norm = 1.5781e-01, time/batch = 19.0700s	
6152/33150 (epoch 9.279), train_loss = 1.23459898, grad/param norm = 1.4944e-01, time/batch = 19.7199s	
6153/33150 (epoch 9.281), train_loss = 1.32272160, grad/param norm = 1.5907e-01, time/batch = 16.4626s	
6154/33150 (epoch 9.282), train_loss = 1.25739299, grad/param norm = 1.4092e-01, time/batch = 19.5478s	
6155/33150 (epoch 9.284), train_loss = 1.19665253, grad/param norm = 1.5263e-01, time/batch = 19.9644s	
6156/33150 (epoch 9.285), train_loss = 1.31161069, grad/param norm = 1.5964e-01, time/batch = 16.4734s	
6157/33150 (epoch 9.287), train_loss = 1.19250044, grad/param norm = 1.5177e-01, time/batch = 15.8089s	
6158/33150 (epoch 9.288), train_loss = 1.43664638, grad/param norm = 1.6844e-01, time/batch = 17.2967s	
6159/33150 (epoch 9.290), train_loss = 1.11404619, grad/param norm = 1.5877e-01, time/batch = 15.8836s	
6160/33150 (epoch 9.291), train_loss = 1.11590456, grad/param norm = 1.5367e-01, time/batch = 17.1167s	
6161/33150 (epoch 9.293), train_loss = 1.33591051, grad/param norm = 1.6222e-01, time/batch = 18.4063s	
6162/33150 (epoch 9.294), train_loss = 0.98349797, grad/param norm = 1.4514e-01, time/batch = 18.5722s	
6163/33150 (epoch 9.296), train_loss = 1.19984852, grad/param norm = 1.4049e-01, time/batch = 16.9013s	
6164/33150 (epoch 9.297), train_loss = 1.18711499, grad/param norm = 1.5986e-01, time/batch = 19.3172s	
6165/33150 (epoch 9.299), train_loss = 1.18453928, grad/param norm = 1.7312e-01, time/batch = 18.3144s	
6166/33150 (epoch 9.300), train_loss = 1.19986326, grad/param norm = 1.4444e-01, time/batch = 17.4708s	
6167/33150 (epoch 9.302), train_loss = 1.17940324, grad/param norm = 1.4925e-01, time/batch = 17.8125s	
6168/33150 (epoch 9.303), train_loss = 1.28927258, grad/param norm = 1.5994e-01, time/batch = 20.3762s	
6169/33150 (epoch 9.305), train_loss = 1.28537854, grad/param norm = 1.5095e-01, time/batch = 18.2912s	
6170/33150 (epoch 9.306), train_loss = 1.31163605, grad/param norm = 1.6813e-01, time/batch = 15.7079s	
6171/33150 (epoch 9.308), train_loss = 1.48516469, grad/param norm = 1.6541e-01, time/batch = 17.6262s	
6172/33150 (epoch 9.309), train_loss = 1.09611505, grad/param norm = 1.4468e-01, time/batch = 17.6524s	
6173/33150 (epoch 9.311), train_loss = 1.23623401, grad/param norm = 1.5623e-01, time/batch = 16.6214s	
6174/33150 (epoch 9.312), train_loss = 1.05153179, grad/param norm = 1.5129e-01, time/batch = 17.1393s	
6175/33150 (epoch 9.314), train_loss = 1.25834015, grad/param norm = 1.6364e-01, time/batch = 19.2214s	
6176/33150 (epoch 9.315), train_loss = 1.34414858, grad/param norm = 1.6787e-01, time/batch = 16.8130s	
6177/33150 (epoch 9.317), train_loss = 0.99673900, grad/param norm = 1.2728e-01, time/batch = 16.5916s	
6178/33150 (epoch 9.318), train_loss = 1.12887142, grad/param norm = 1.4293e-01, time/batch = 16.6607s	
6179/33150 (epoch 9.320), train_loss = 1.08684056, grad/param norm = 1.4159e-01, time/batch = 17.3201s	
6180/33150 (epoch 9.321), train_loss = 1.17332044, grad/param norm = 1.4416e-01, time/batch = 15.2359s	
6181/33150 (epoch 9.323), train_loss = 1.23823009, grad/param norm = 1.5343e-01, time/batch = 17.5613s	
6182/33150 (epoch 9.324), train_loss = 1.34492161, grad/param norm = 1.8115e-01, time/batch = 19.4666s	
6183/33150 (epoch 9.326), train_loss = 1.26154074, grad/param norm = 1.4615e-01, time/batch = 18.0504s	
6184/33150 (epoch 9.327), train_loss = 1.35706915, grad/param norm = 1.4817e-01, time/batch = 16.8192s	
6185/33150 (epoch 9.329), train_loss = 1.30440384, grad/param norm = 1.5386e-01, time/batch = 16.6434s	
6186/33150 (epoch 9.330), train_loss = 1.28224619, grad/param norm = 1.8033e-01, time/batch = 19.0601s	
6187/33150 (epoch 9.332), train_loss = 1.23863183, grad/param norm = 1.4366e-01, time/batch = 17.2284s	
6188/33150 (epoch 9.333), train_loss = 1.28238331, grad/param norm = 1.4301e-01, time/batch = 18.7979s	
6189/33150 (epoch 9.335), train_loss = 1.20087390, grad/param norm = 1.5321e-01, time/batch = 18.4766s	
6190/33150 (epoch 9.336), train_loss = 1.15211504, grad/param norm = 1.4829e-01, time/batch = 15.8890s	
6191/33150 (epoch 9.338), train_loss = 1.01507496, grad/param norm = 1.4411e-01, time/batch = 16.9018s	
6192/33150 (epoch 9.339), train_loss = 1.35419787, grad/param norm = 1.6047e-01, time/batch = 18.1474s	
6193/33150 (epoch 9.341), train_loss = 1.41690544, grad/param norm = 1.8530e-01, time/batch = 17.1366s	
6194/33150 (epoch 9.342), train_loss = 1.09010518, grad/param norm = 1.5365e-01, time/batch = 15.8834s	
6195/33150 (epoch 9.344), train_loss = 1.29407676, grad/param norm = 1.5734e-01, time/batch = 17.7236s	
6196/33150 (epoch 9.345), train_loss = 1.16424867, grad/param norm = 1.5659e-01, time/batch = 18.7987s	
6197/33150 (epoch 9.347), train_loss = 1.00548972, grad/param norm = 1.4380e-01, time/batch = 16.4746s	
6198/33150 (epoch 9.348), train_loss = 1.24282335, grad/param norm = 1.5011e-01, time/batch = 18.3014s	
6199/33150 (epoch 9.350), train_loss = 1.21507290, grad/param norm = 1.7565e-01, time/batch = 16.9820s	
6200/33150 (epoch 9.351), train_loss = 1.33551336, grad/param norm = 1.6474e-01, time/batch = 18.8875s	
6201/33150 (epoch 9.353), train_loss = 1.36697548, grad/param norm = 1.8044e-01, time/batch = 19.1999s	
6202/33150 (epoch 9.354), train_loss = 1.53487565, grad/param norm = 1.7308e-01, time/batch = 16.9007s	
6203/33150 (epoch 9.356), train_loss = 1.36519121, grad/param norm = 1.8043e-01, time/batch = 18.1369s	
6204/33150 (epoch 9.357), train_loss = 1.36900490, grad/param norm = 1.6949e-01, time/batch = 17.6316s	
6205/33150 (epoch 9.359), train_loss = 1.30883390, grad/param norm = 1.5600e-01, time/batch = 20.2133s	
6206/33150 (epoch 9.360), train_loss = 1.37752146, grad/param norm = 1.8183e-01, time/batch = 17.3726s	
6207/33150 (epoch 9.362), train_loss = 1.34112360, grad/param norm = 1.6036e-01, time/batch = 17.7190s	
6208/33150 (epoch 9.363), train_loss = 1.23502256, grad/param norm = 1.4967e-01, time/batch = 19.9797s	
6209/33150 (epoch 9.365), train_loss = 1.23416296, grad/param norm = 1.4425e-01, time/batch = 18.0479s	
6210/33150 (epoch 9.367), train_loss = 1.14088747, grad/param norm = 1.4671e-01, time/batch = 18.1355s	
6211/33150 (epoch 9.368), train_loss = 1.23986638, grad/param norm = 1.4991e-01, time/batch = 18.3966s	
6212/33150 (epoch 9.370), train_loss = 1.29992089, grad/param norm = 1.6465e-01, time/batch = 18.6423s	
6213/33150 (epoch 9.371), train_loss = 1.13439499, grad/param norm = 1.5352e-01, time/batch = 17.8821s	
6214/33150 (epoch 9.373), train_loss = 1.33845464, grad/param norm = 1.8499e-01, time/batch = 17.7076s	
6215/33150 (epoch 9.374), train_loss = 1.21025256, grad/param norm = 1.4946e-01, time/batch = 16.6399s	
6216/33150 (epoch 9.376), train_loss = 1.40093756, grad/param norm = 1.5633e-01, time/batch = 15.0634s	
6217/33150 (epoch 9.377), train_loss = 1.23942931, grad/param norm = 1.6695e-01, time/batch = 15.1776s	
6218/33150 (epoch 9.379), train_loss = 1.33517087, grad/param norm = 1.6850e-01, time/batch = 15.0131s	
6219/33150 (epoch 9.380), train_loss = 1.34698136, grad/param norm = 1.5047e-01, time/batch = 15.0325s	
6220/33150 (epoch 9.382), train_loss = 1.14801751, grad/param norm = 1.4694e-01, time/batch = 15.0895s	
6221/33150 (epoch 9.383), train_loss = 1.14287201, grad/param norm = 1.5086e-01, time/batch = 15.4401s	
6222/33150 (epoch 9.385), train_loss = 1.27046243, grad/param norm = 1.6088e-01, time/batch = 15.7101s	
6223/33150 (epoch 9.386), train_loss = 1.10809230, grad/param norm = 1.4773e-01, time/batch = 18.5472s	
6224/33150 (epoch 9.388), train_loss = 1.22861838, grad/param norm = 1.5569e-01, time/batch = 17.7946s	
6225/33150 (epoch 9.389), train_loss = 1.20180053, grad/param norm = 1.5668e-01, time/batch = 17.2046s	
6226/33150 (epoch 9.391), train_loss = 1.42059451, grad/param norm = 1.5736e-01, time/batch = 18.2944s	
6227/33150 (epoch 9.392), train_loss = 1.19016577, grad/param norm = 1.4349e-01, time/batch = 15.4363s	
6228/33150 (epoch 9.394), train_loss = 1.08463622, grad/param norm = 1.2450e-01, time/batch = 16.0284s	
6229/33150 (epoch 9.395), train_loss = 1.14701939, grad/param norm = 1.7117e-01, time/batch = 17.2233s	
6230/33150 (epoch 9.397), train_loss = 0.95242426, grad/param norm = 1.2883e-01, time/batch = 16.7831s	
6231/33150 (epoch 9.398), train_loss = 1.26924148, grad/param norm = 1.6521e-01, time/batch = 15.7032s	
6232/33150 (epoch 9.400), train_loss = 1.19603418, grad/param norm = 1.4453e-01, time/batch = 16.0247s	
6233/33150 (epoch 9.401), train_loss = 1.05443457, grad/param norm = 1.3418e-01, time/batch = 17.0698s	
6234/33150 (epoch 9.403), train_loss = 1.13175789, grad/param norm = 1.4234e-01, time/batch = 18.2980s	
6235/33150 (epoch 9.404), train_loss = 1.19018343, grad/param norm = 1.4734e-01, time/batch = 16.8914s	
6236/33150 (epoch 9.406), train_loss = 1.11077092, grad/param norm = 1.2304e-01, time/batch = 16.0525s	
6237/33150 (epoch 9.407), train_loss = 1.10874311, grad/param norm = 1.3937e-01, time/batch = 16.3015s	
6238/33150 (epoch 9.409), train_loss = 1.02879346, grad/param norm = 1.4254e-01, time/batch = 18.1427s	
6239/33150 (epoch 9.410), train_loss = 1.29616048, grad/param norm = 1.6688e-01, time/batch = 15.9739s	
6240/33150 (epoch 9.412), train_loss = 1.30067136, grad/param norm = 1.5748e-01, time/batch = 16.8918s	
6241/33150 (epoch 9.413), train_loss = 1.18380402, grad/param norm = 1.6277e-01, time/batch = 15.7756s	
6242/33150 (epoch 9.415), train_loss = 1.36542059, grad/param norm = 1.5877e-01, time/batch = 16.5401s	
6243/33150 (epoch 9.416), train_loss = 1.16811764, grad/param norm = 1.4228e-01, time/batch = 17.9696s	
6244/33150 (epoch 9.418), train_loss = 1.44505676, grad/param norm = 1.9802e-01, time/batch = 16.3997s	
6245/33150 (epoch 9.419), train_loss = 1.14680462, grad/param norm = 1.6154e-01, time/batch = 15.8811s	
6246/33150 (epoch 9.421), train_loss = 1.27048911, grad/param norm = 1.5776e-01, time/batch = 15.2988s	
6247/33150 (epoch 9.422), train_loss = 1.16792364, grad/param norm = 1.4721e-01, time/batch = 18.0578s	
6248/33150 (epoch 9.424), train_loss = 1.18041300, grad/param norm = 1.6318e-01, time/batch = 18.0401s	
6249/33150 (epoch 9.425), train_loss = 1.20659609, grad/param norm = 1.4949e-01, time/batch = 16.5379s	
6250/33150 (epoch 9.427), train_loss = 1.16694901, grad/param norm = 1.4819e-01, time/batch = 16.3912s	
6251/33150 (epoch 9.428), train_loss = 1.23821725, grad/param norm = 1.5988e-01, time/batch = 16.6490s	
6252/33150 (epoch 9.430), train_loss = 1.28649123, grad/param norm = 1.6242e-01, time/batch = 17.1469s	
6253/33150 (epoch 9.431), train_loss = 1.33884538, grad/param norm = 1.6961e-01, time/batch = 15.7180s	
6254/33150 (epoch 9.433), train_loss = 1.21207669, grad/param norm = 1.4211e-01, time/batch = 17.2297s	
6255/33150 (epoch 9.434), train_loss = 1.09939081, grad/param norm = 1.5287e-01, time/batch = 17.6478s	
6256/33150 (epoch 9.436), train_loss = 1.04987931, grad/param norm = 1.4433e-01, time/batch = 17.4558s	
6257/33150 (epoch 9.437), train_loss = 1.26076504, grad/param norm = 1.8763e-01, time/batch = 16.4750s	
6258/33150 (epoch 9.439), train_loss = 1.37351233, grad/param norm = 1.7369e-01, time/batch = 16.5683s	
6259/33150 (epoch 9.440), train_loss = 1.36785277, grad/param norm = 1.6545e-01, time/batch = 17.5649s	
6260/33150 (epoch 9.442), train_loss = 1.09232476, grad/param norm = 1.6723e-01, time/batch = 16.1321s	
6261/33150 (epoch 9.443), train_loss = 1.35288065, grad/param norm = 1.6278e-01, time/batch = 18.0522s	
6262/33150 (epoch 9.445), train_loss = 1.25646524, grad/param norm = 1.6796e-01, time/batch = 17.5477s	
6263/33150 (epoch 9.446), train_loss = 1.29662915, grad/param norm = 1.9533e-01, time/batch = 18.2822s	
6264/33150 (epoch 9.448), train_loss = 1.32064949, grad/param norm = 1.6889e-01, time/batch = 18.0489s	
6265/33150 (epoch 9.449), train_loss = 1.21658970, grad/param norm = 1.5674e-01, time/batch = 19.8890s	
6266/33150 (epoch 9.451), train_loss = 1.32153750, grad/param norm = 1.7730e-01, time/batch = 15.7346s	
6267/33150 (epoch 9.452), train_loss = 1.50699454, grad/param norm = 1.6296e-01, time/batch = 17.2851s	
6268/33150 (epoch 9.454), train_loss = 1.21588898, grad/param norm = 1.5525e-01, time/batch = 17.1488s	
6269/33150 (epoch 9.456), train_loss = 1.01794879, grad/param norm = 1.3922e-01, time/batch = 18.3069s	
6270/33150 (epoch 9.457), train_loss = 1.25405827, grad/param norm = 1.6054e-01, time/batch = 17.5533s	
6271/33150 (epoch 9.459), train_loss = 1.41767796, grad/param norm = 1.9498e-01, time/batch = 17.8697s	
6272/33150 (epoch 9.460), train_loss = 1.26835387, grad/param norm = 1.4133e-01, time/batch = 18.0741s	
6273/33150 (epoch 9.462), train_loss = 1.39137662, grad/param norm = 1.8094e-01, time/batch = 17.9823s	
6274/33150 (epoch 9.463), train_loss = 1.57643716, grad/param norm = 1.9258e-01, time/batch = 16.8854s	
6275/33150 (epoch 9.465), train_loss = 1.16205281, grad/param norm = 1.4957e-01, time/batch = 17.1597s	
6276/33150 (epoch 9.466), train_loss = 1.18720156, grad/param norm = 1.5430e-01, time/batch = 18.2308s	
6277/33150 (epoch 9.468), train_loss = 1.56291366, grad/param norm = 1.6736e-01, time/batch = 16.8913s	
6278/33150 (epoch 9.469), train_loss = 1.29116792, grad/param norm = 1.6377e-01, time/batch = 17.5477s	
6279/33150 (epoch 9.471), train_loss = 1.20413569, grad/param norm = 1.5004e-01, time/batch = 17.2367s	
6280/33150 (epoch 9.472), train_loss = 1.20424352, grad/param norm = 1.4675e-01, time/batch = 15.9679s	
6281/33150 (epoch 9.474), train_loss = 1.38258515, grad/param norm = 1.8205e-01, time/batch = 16.7124s	
6282/33150 (epoch 9.475), train_loss = 1.53649671, grad/param norm = 1.7589e-01, time/batch = 18.8084s	
6283/33150 (epoch 9.477), train_loss = 1.30774897, grad/param norm = 1.6706e-01, time/batch = 18.8780s	
6284/33150 (epoch 9.478), train_loss = 1.37448230, grad/param norm = 1.5415e-01, time/batch = 17.6092s	
6285/33150 (epoch 9.480), train_loss = 1.19205864, grad/param norm = 1.4435e-01, time/batch = 18.7253s	
6286/33150 (epoch 9.481), train_loss = 1.08122492, grad/param norm = 1.4514e-01, time/batch = 17.2443s	
6287/33150 (epoch 9.483), train_loss = 1.20116616, grad/param norm = 1.6390e-01, time/batch = 17.2255s	
6288/33150 (epoch 9.484), train_loss = 1.16428631, grad/param norm = 1.4671e-01, time/batch = 17.8859s	
6289/33150 (epoch 9.486), train_loss = 1.22231609, grad/param norm = 1.5603e-01, time/batch = 18.6414s	
6290/33150 (epoch 9.487), train_loss = 1.32026960, grad/param norm = 1.6253e-01, time/batch = 18.6448s	
6291/33150 (epoch 9.489), train_loss = 1.26901763, grad/param norm = 1.6198e-01, time/batch = 15.9811s	
6292/33150 (epoch 9.490), train_loss = 1.08783580, grad/param norm = 1.3869e-01, time/batch = 18.5493s	
6293/33150 (epoch 9.492), train_loss = 1.19400104, grad/param norm = 1.7398e-01, time/batch = 19.0466s	
6294/33150 (epoch 9.493), train_loss = 1.35648425, grad/param norm = 1.7030e-01, time/batch = 17.4675s	
6295/33150 (epoch 9.495), train_loss = 1.34927946, grad/param norm = 1.6007e-01, time/batch = 18.7126s	
6296/33150 (epoch 9.496), train_loss = 1.16535548, grad/param norm = 1.6166e-01, time/batch = 17.2244s	
6297/33150 (epoch 9.498), train_loss = 1.36672977, grad/param norm = 1.8717e-01, time/batch = 16.2197s	
6298/33150 (epoch 9.499), train_loss = 1.45631605, grad/param norm = 1.8461e-01, time/batch = 16.3301s	
6299/33150 (epoch 9.501), train_loss = 1.30934329, grad/param norm = 1.5568e-01, time/batch = 18.0774s	
6300/33150 (epoch 9.502), train_loss = 1.43001434, grad/param norm = 1.7076e-01, time/batch = 18.0674s	
6301/33150 (epoch 9.504), train_loss = 1.33392889, grad/param norm = 1.6670e-01, time/batch = 15.4643s	
6302/33150 (epoch 9.505), train_loss = 1.51092055, grad/param norm = 1.8767e-01, time/batch = 17.6446s	
6303/33150 (epoch 9.507), train_loss = 1.20398936, grad/param norm = 1.7704e-01, time/batch = 17.0755s	
6304/33150 (epoch 9.508), train_loss = 1.16536167, grad/param norm = 1.4857e-01, time/batch = 17.4706s	
6305/33150 (epoch 9.510), train_loss = 1.24489846, grad/param norm = 1.5574e-01, time/batch = 16.7095s	
6306/33150 (epoch 9.511), train_loss = 1.48323964, grad/param norm = 1.8211e-01, time/batch = 17.5635s	
6307/33150 (epoch 9.513), train_loss = 1.30683454, grad/param norm = 1.8522e-01, time/batch = 18.7137s	
6308/33150 (epoch 9.514), train_loss = 1.06291212, grad/param norm = 1.5894e-01, time/batch = 18.5492s	
6309/33150 (epoch 9.516), train_loss = 1.40317109, grad/param norm = 1.9909e-01, time/batch = 17.5656s	
6310/33150 (epoch 9.517), train_loss = 1.38608158, grad/param norm = 1.5773e-01, time/batch = 18.1402s	
6311/33150 (epoch 9.519), train_loss = 1.18513937, grad/param norm = 1.5209e-01, time/batch = 16.5568s	
6312/33150 (epoch 9.520), train_loss = 1.29134390, grad/param norm = 1.4975e-01, time/batch = 17.1456s	
6313/33150 (epoch 9.522), train_loss = 1.46426275, grad/param norm = 2.1079e-01, time/batch = 16.6534s	
6314/33150 (epoch 9.523), train_loss = 1.13771531, grad/param norm = 1.5840e-01, time/batch = 17.7033s	
6315/33150 (epoch 9.525), train_loss = 1.28499386, grad/param norm = 1.5642e-01, time/batch = 17.1544s	
6316/33150 (epoch 9.526), train_loss = 1.15525922, grad/param norm = 1.5128e-01, time/batch = 17.3110s	
6317/33150 (epoch 9.528), train_loss = 1.31406921, grad/param norm = 1.6551e-01, time/batch = 17.5672s	
6318/33150 (epoch 9.529), train_loss = 1.32818824, grad/param norm = 1.5565e-01, time/batch = 30.7984s	
6319/33150 (epoch 9.531), train_loss = 1.08885013, grad/param norm = 1.6208e-01, time/batch = 18.3835s	
6320/33150 (epoch 9.532), train_loss = 1.28340065, grad/param norm = 1.5205e-01, time/batch = 15.5467s	
6321/33150 (epoch 9.534), train_loss = 1.18308330, grad/param norm = 1.3951e-01, time/batch = 17.3194s	
6322/33150 (epoch 9.535), train_loss = 1.16320363, grad/param norm = 1.6582e-01, time/batch = 17.4033s	
6323/33150 (epoch 9.537), train_loss = 1.40096129, grad/param norm = 1.6649e-01, time/batch = 17.4884s	
6324/33150 (epoch 9.538), train_loss = 1.22446511, grad/param norm = 1.8150e-01, time/batch = 15.5587s	
6325/33150 (epoch 9.540), train_loss = 1.08679980, grad/param norm = 1.5299e-01, time/batch = 17.5648s	
6326/33150 (epoch 9.541), train_loss = 1.32000493, grad/param norm = 1.6737e-01, time/batch = 17.4204s	
6327/33150 (epoch 9.543), train_loss = 1.32094734, grad/param norm = 1.5828e-01, time/batch = 16.2181s	
6328/33150 (epoch 9.544), train_loss = 1.25921603, grad/param norm = 1.4877e-01, time/batch = 17.3968s	
6329/33150 (epoch 9.546), train_loss = 1.45699828, grad/param norm = 1.7378e-01, time/batch = 19.2122s	
6330/33150 (epoch 9.548), train_loss = 1.30510166, grad/param norm = 1.6489e-01, time/batch = 17.3204s	
6331/33150 (epoch 9.549), train_loss = 1.26593686, grad/param norm = 1.6158e-01, time/batch = 15.2946s	
6332/33150 (epoch 9.551), train_loss = 1.16369587, grad/param norm = 1.7178e-01, time/batch = 18.8857s	
6333/33150 (epoch 9.552), train_loss = 1.04616271, grad/param norm = 1.3395e-01, time/batch = 18.2261s	
6334/33150 (epoch 9.554), train_loss = 1.27941904, grad/param norm = 1.5145e-01, time/batch = 16.4664s	
6335/33150 (epoch 9.555), train_loss = 1.45804184, grad/param norm = 1.6660e-01, time/batch = 18.0586s	
6336/33150 (epoch 9.557), train_loss = 1.07881838, grad/param norm = 1.4771e-01, time/batch = 17.4045s	
6337/33150 (epoch 9.558), train_loss = 1.35730212, grad/param norm = 1.7990e-01, time/batch = 17.8067s	
6338/33150 (epoch 9.560), train_loss = 1.18085763, grad/param norm = 1.4971e-01, time/batch = 17.2435s	
6339/33150 (epoch 9.561), train_loss = 1.05121762, grad/param norm = 1.4385e-01, time/batch = 18.8154s	
6340/33150 (epoch 9.563), train_loss = 1.37017091, grad/param norm = 1.8803e-01, time/batch = 19.7892s	
6341/33150 (epoch 9.564), train_loss = 1.43905000, grad/param norm = 1.6168e-01, time/batch = 16.7025s	
6342/33150 (epoch 9.566), train_loss = 1.24962449, grad/param norm = 1.6125e-01, time/batch = 15.8058s	
6343/33150 (epoch 9.567), train_loss = 1.14304374, grad/param norm = 1.5629e-01, time/batch = 18.9754s	
6344/33150 (epoch 9.569), train_loss = 1.24283501, grad/param norm = 1.4861e-01, time/batch = 17.6238s	
6345/33150 (epoch 9.570), train_loss = 1.28660646, grad/param norm = 1.5278e-01, time/batch = 17.2200s	
6346/33150 (epoch 9.572), train_loss = 1.14445671, grad/param norm = 1.5635e-01, time/batch = 18.8972s	
6347/33150 (epoch 9.573), train_loss = 1.00649641, grad/param norm = 1.3189e-01, time/batch = 17.8871s	
6348/33150 (epoch 9.575), train_loss = 1.26366057, grad/param norm = 1.6304e-01, time/batch = 16.1404s	
6349/33150 (epoch 9.576), train_loss = 1.04814920, grad/param norm = 1.2960e-01, time/batch = 19.4739s	
6350/33150 (epoch 9.578), train_loss = 1.20381900, grad/param norm = 1.4157e-01, time/batch = 18.8038s	
6351/33150 (epoch 9.579), train_loss = 1.10406168, grad/param norm = 1.4697e-01, time/batch = 16.8898s	
6352/33150 (epoch 9.581), train_loss = 1.13456313, grad/param norm = 1.5027e-01, time/batch = 17.7362s	
6353/33150 (epoch 9.582), train_loss = 1.27971646, grad/param norm = 1.4478e-01, time/batch = 16.9881s	
6354/33150 (epoch 9.584), train_loss = 1.31718260, grad/param norm = 1.5150e-01, time/batch = 17.4762s	
6355/33150 (epoch 9.585), train_loss = 1.26561909, grad/param norm = 1.6450e-01, time/batch = 17.4653s	
6356/33150 (epoch 9.587), train_loss = 1.28967849, grad/param norm = 1.5755e-01, time/batch = 17.7964s	
6357/33150 (epoch 9.588), train_loss = 1.14540649, grad/param norm = 1.5617e-01, time/batch = 16.6508s	
6358/33150 (epoch 9.590), train_loss = 1.25379957, grad/param norm = 1.6466e-01, time/batch = 16.5606s	
6359/33150 (epoch 9.591), train_loss = 1.25172189, grad/param norm = 1.5678e-01, time/batch = 18.8931s	
6360/33150 (epoch 9.593), train_loss = 1.33085085, grad/param norm = 1.7230e-01, time/batch = 18.5639s	
6361/33150 (epoch 9.594), train_loss = 1.26532520, grad/param norm = 1.5662e-01, time/batch = 17.4631s	
6362/33150 (epoch 9.596), train_loss = 1.13982780, grad/param norm = 1.5206e-01, time/batch = 17.8924s	
6363/33150 (epoch 9.597), train_loss = 1.15620331, grad/param norm = 1.7167e-01, time/batch = 19.0744s	
6364/33150 (epoch 9.599), train_loss = 1.46517394, grad/param norm = 1.7498e-01, time/batch = 17.8958s	
6365/33150 (epoch 9.600), train_loss = 1.30802455, grad/param norm = 2.1059e-01, time/batch = 16.9713s	
6366/33150 (epoch 9.602), train_loss = 1.15887608, grad/param norm = 1.5059e-01, time/batch = 17.9876s	
6367/33150 (epoch 9.603), train_loss = 1.28852795, grad/param norm = 1.6501e-01, time/batch = 17.4859s	
6368/33150 (epoch 9.605), train_loss = 1.13440669, grad/param norm = 1.4597e-01, time/batch = 17.2163s	
6369/33150 (epoch 9.606), train_loss = 1.27044123, grad/param norm = 1.8616e-01, time/batch = 15.3530s	
6370/33150 (epoch 9.608), train_loss = 1.28215645, grad/param norm = 1.6179e-01, time/batch = 15.4275s	
6371/33150 (epoch 9.609), train_loss = 1.22951163, grad/param norm = 1.6646e-01, time/batch = 15.0380s	
6372/33150 (epoch 9.611), train_loss = 1.05654998, grad/param norm = 1.5041e-01, time/batch = 15.4223s	
6373/33150 (epoch 9.612), train_loss = 1.24362012, grad/param norm = 1.5984e-01, time/batch = 15.4123s	
6374/33150 (epoch 9.614), train_loss = 1.06006927, grad/param norm = 1.4507e-01, time/batch = 15.6031s	
6375/33150 (epoch 9.615), train_loss = 1.09854869, grad/param norm = 1.4487e-01, time/batch = 17.5442s	
6376/33150 (epoch 9.617), train_loss = 1.22897550, grad/param norm = 1.7092e-01, time/batch = 16.8747s	
6377/33150 (epoch 9.618), train_loss = 1.25813400, grad/param norm = 1.7370e-01, time/batch = 16.5740s	
6378/33150 (epoch 9.620), train_loss = 1.18423251, grad/param norm = 1.6727e-01, time/batch = 16.7359s	
6379/33150 (epoch 9.621), train_loss = 1.19121102, grad/param norm = 1.5012e-01, time/batch = 15.4052s	
6380/33150 (epoch 9.623), train_loss = 1.29621141, grad/param norm = 1.7457e-01, time/batch = 15.8877s	
6381/33150 (epoch 9.624), train_loss = 1.17051665, grad/param norm = 1.7280e-01, time/batch = 16.6436s	
6382/33150 (epoch 9.626), train_loss = 1.12785664, grad/param norm = 1.4732e-01, time/batch = 17.1422s	
6383/33150 (epoch 9.627), train_loss = 1.09685047, grad/param norm = 1.5575e-01, time/batch = 16.7889s	
6384/33150 (epoch 9.629), train_loss = 1.06587371, grad/param norm = 1.3634e-01, time/batch = 17.2953s	
6385/33150 (epoch 9.630), train_loss = 1.12752981, grad/param norm = 1.4034e-01, time/batch = 18.2130s	
6386/33150 (epoch 9.632), train_loss = 1.05109683, grad/param norm = 1.4087e-01, time/batch = 16.7109s	
6387/33150 (epoch 9.633), train_loss = 1.08944839, grad/param norm = 1.6760e-01, time/batch = 18.3900s	
6388/33150 (epoch 9.635), train_loss = 1.44248534, grad/param norm = 1.6488e-01, time/batch = 17.8227s	
6389/33150 (epoch 9.637), train_loss = 1.05611021, grad/param norm = 1.5649e-01, time/batch = 18.0435s	
6390/33150 (epoch 9.638), train_loss = 1.17615655, grad/param norm = 1.5247e-01, time/batch = 19.2226s	
6391/33150 (epoch 9.640), train_loss = 1.33718281, grad/param norm = 1.6529e-01, time/batch = 17.4023s	
6392/33150 (epoch 9.641), train_loss = 1.12795515, grad/param norm = 1.5353e-01, time/batch = 18.0285s	
6393/33150 (epoch 9.643), train_loss = 1.15712606, grad/param norm = 1.4501e-01, time/batch = 16.8881s	
6394/33150 (epoch 9.644), train_loss = 1.34307004, grad/param norm = 1.5199e-01, time/batch = 18.7313s	
6395/33150 (epoch 9.646), train_loss = 1.17138349, grad/param norm = 1.5070e-01, time/batch = 18.2490s	
6396/33150 (epoch 9.647), train_loss = 1.52370743, grad/param norm = 1.7771e-01, time/batch = 16.7164s	
6397/33150 (epoch 9.649), train_loss = 1.35116559, grad/param norm = 1.7417e-01, time/batch = 18.8143s	
6398/33150 (epoch 9.650), train_loss = 1.08553161, grad/param norm = 1.4540e-01, time/batch = 17.3970s	
6399/33150 (epoch 9.652), train_loss = 1.32674591, grad/param norm = 1.6881e-01, time/batch = 17.7951s	
6400/33150 (epoch 9.653), train_loss = 1.20084345, grad/param norm = 1.4209e-01, time/batch = 17.3687s	
6401/33150 (epoch 9.655), train_loss = 1.30854271, grad/param norm = 1.8036e-01, time/batch = 18.1009s	
6402/33150 (epoch 9.656), train_loss = 1.21663041, grad/param norm = 1.4843e-01, time/batch = 18.9542s	
6403/33150 (epoch 9.658), train_loss = 1.23663547, grad/param norm = 1.8074e-01, time/batch = 15.7739s	
6404/33150 (epoch 9.659), train_loss = 1.54566333, grad/param norm = 2.2653e-01, time/batch = 16.6282s	
6405/33150 (epoch 9.661), train_loss = 1.19263093, grad/param norm = 1.5564e-01, time/batch = 17.5580s	
6406/33150 (epoch 9.662), train_loss = 1.03975161, grad/param norm = 1.5188e-01, time/batch = 18.1188s	
6407/33150 (epoch 9.664), train_loss = 1.35397619, grad/param norm = 1.5790e-01, time/batch = 17.4057s	
6408/33150 (epoch 9.665), train_loss = 1.29278990, grad/param norm = 1.7317e-01, time/batch = 16.8187s	
6409/33150 (epoch 9.667), train_loss = 1.39654445, grad/param norm = 1.6336e-01, time/batch = 18.7961s	
6410/33150 (epoch 9.668), train_loss = 1.30288900, grad/param norm = 1.5630e-01, time/batch = 17.1996s	
6411/33150 (epoch 9.670), train_loss = 1.18507896, grad/param norm = 1.4217e-01, time/batch = 18.5547s	
6412/33150 (epoch 9.671), train_loss = 1.16452574, grad/param norm = 1.6200e-01, time/batch = 19.7068s	
6413/33150 (epoch 9.673), train_loss = 1.32561729, grad/param norm = 1.4090e-01, time/batch = 17.6416s	
6414/33150 (epoch 9.674), train_loss = 1.22990098, grad/param norm = 1.4985e-01, time/batch = 17.4637s	
6415/33150 (epoch 9.676), train_loss = 1.17029693, grad/param norm = 1.4155e-01, time/batch = 17.8143s	
6416/33150 (epoch 9.677), train_loss = 1.52920355, grad/param norm = 1.6463e-01, time/batch = 16.6421s	
6417/33150 (epoch 9.679), train_loss = 1.13138999, grad/param norm = 1.6581e-01, time/batch = 18.5582s	
6418/33150 (epoch 9.680), train_loss = 1.34867892, grad/param norm = 1.6030e-01, time/batch = 17.8806s	
6419/33150 (epoch 9.682), train_loss = 1.13789724, grad/param norm = 1.5699e-01, time/batch = 17.9734s	
6420/33150 (epoch 9.683), train_loss = 1.03521591, grad/param norm = 1.3322e-01, time/batch = 17.2289s	
6421/33150 (epoch 9.685), train_loss = 1.26708683, grad/param norm = 1.5780e-01, time/batch = 17.9071s	
6422/33150 (epoch 9.686), train_loss = 1.04784928, grad/param norm = 1.4231e-01, time/batch = 16.8112s	
6423/33150 (epoch 9.688), train_loss = 1.16896388, grad/param norm = 1.5715e-01, time/batch = 16.2970s	
6424/33150 (epoch 9.689), train_loss = 1.11353915, grad/param norm = 1.5043e-01, time/batch = 15.8051s	
6425/33150 (epoch 9.691), train_loss = 1.02650071, grad/param norm = 1.3641e-01, time/batch = 16.3813s	
6426/33150 (epoch 9.692), train_loss = 1.13358885, grad/param norm = 1.5204e-01, time/batch = 16.1925s	
6427/33150 (epoch 9.694), train_loss = 0.96346635, grad/param norm = 1.2271e-01, time/batch = 15.5997s	
6428/33150 (epoch 9.695), train_loss = 1.16230551, grad/param norm = 1.4688e-01, time/batch = 15.8692s	
6429/33150 (epoch 9.697), train_loss = 1.03213246, grad/param norm = 1.2921e-01, time/batch = 17.2910s	
6430/33150 (epoch 9.698), train_loss = 1.27131001, grad/param norm = 1.5531e-01, time/batch = 16.8796s	
6431/33150 (epoch 9.700), train_loss = 0.93711836, grad/param norm = 1.3281e-01, time/batch = 17.1385s	
6432/33150 (epoch 9.701), train_loss = 1.11254082, grad/param norm = 1.5266e-01, time/batch = 17.8066s	
6433/33150 (epoch 9.703), train_loss = 1.19913104, grad/param norm = 1.4153e-01, time/batch = 17.2411s	
6434/33150 (epoch 9.704), train_loss = 1.00250650, grad/param norm = 1.3419e-01, time/batch = 17.2196s	
6435/33150 (epoch 9.706), train_loss = 1.16177909, grad/param norm = 1.3403e-01, time/batch = 16.9879s	
6436/33150 (epoch 9.707), train_loss = 1.17790800, grad/param norm = 1.5976e-01, time/batch = 17.9715s	
6437/33150 (epoch 9.709), train_loss = 1.23013678, grad/param norm = 1.3844e-01, time/batch = 16.7259s	
6438/33150 (epoch 9.710), train_loss = 1.28929964, grad/param norm = 1.6302e-01, time/batch = 16.2998s	
6439/33150 (epoch 9.712), train_loss = 1.33550914, grad/param norm = 1.6636e-01, time/batch = 18.4008s	
6440/33150 (epoch 9.713), train_loss = 1.27294107, grad/param norm = 1.6452e-01, time/batch = 18.3237s	
6441/33150 (epoch 9.715), train_loss = 1.15747910, grad/param norm = 1.4367e-01, time/batch = 16.6467s	
6442/33150 (epoch 9.716), train_loss = 1.26635454, grad/param norm = 1.5707e-01, time/batch = 17.5786s	
6443/33150 (epoch 9.718), train_loss = 1.24086846, grad/param norm = 1.4570e-01, time/batch = 17.5822s	
6444/33150 (epoch 9.719), train_loss = 1.33835991, grad/param norm = 1.7357e-01, time/batch = 16.7199s	
6445/33150 (epoch 9.721), train_loss = 1.22163262, grad/param norm = 1.6949e-01, time/batch = 15.7139s	
6446/33150 (epoch 9.722), train_loss = 1.26069455, grad/param norm = 1.5640e-01, time/batch = 17.5496s	
6447/33150 (epoch 9.724), train_loss = 1.17761123, grad/param norm = 1.4503e-01, time/batch = 18.2155s	
6448/33150 (epoch 9.725), train_loss = 1.40532660, grad/param norm = 1.7205e-01, time/batch = 17.4675s	
6449/33150 (epoch 9.727), train_loss = 1.26170650, grad/param norm = 1.7081e-01, time/batch = 19.4776s	
6450/33150 (epoch 9.729), train_loss = 1.23272394, grad/param norm = 1.5441e-01, time/batch = 17.6442s	
6451/33150 (epoch 9.730), train_loss = 1.24468763, grad/param norm = 1.6675e-01, time/batch = 16.8055s	
6452/33150 (epoch 9.732), train_loss = 1.32676308, grad/param norm = 1.6340e-01, time/batch = 18.3924s	
6453/33150 (epoch 9.733), train_loss = 0.99890742, grad/param norm = 1.1963e-01, time/batch = 17.7194s	
6454/33150 (epoch 9.735), train_loss = 1.18169125, grad/param norm = 1.4565e-01, time/batch = 17.2137s	
6455/33150 (epoch 9.736), train_loss = 1.16723029, grad/param norm = 1.6936e-01, time/batch = 17.8973s	
6456/33150 (epoch 9.738), train_loss = 1.28084616, grad/param norm = 1.6306e-01, time/batch = 17.1492s	
6457/33150 (epoch 9.739), train_loss = 1.36791837, grad/param norm = 1.8358e-01, time/batch = 18.7085s	
6458/33150 (epoch 9.741), train_loss = 1.36151233, grad/param norm = 1.7040e-01, time/batch = 16.6461s	
6459/33150 (epoch 9.742), train_loss = 1.17572628, grad/param norm = 1.5206e-01, time/batch = 16.6571s	
6460/33150 (epoch 9.744), train_loss = 1.38360490, grad/param norm = 1.6967e-01, time/batch = 18.2184s	
6461/33150 (epoch 9.745), train_loss = 1.16370235, grad/param norm = 1.3887e-01, time/batch = 17.0561s	
6462/33150 (epoch 9.747), train_loss = 1.05747877, grad/param norm = 1.5217e-01, time/batch = 18.1476s	
6463/33150 (epoch 9.748), train_loss = 1.16741343, grad/param norm = 1.5181e-01, time/batch = 18.1199s	
6464/33150 (epoch 9.750), train_loss = 1.31448411, grad/param norm = 1.6687e-01, time/batch = 16.9877s	
6465/33150 (epoch 9.751), train_loss = 1.22903914, grad/param norm = 1.5744e-01, time/batch = 17.0686s	
6466/33150 (epoch 9.753), train_loss = 1.05396244, grad/param norm = 1.6199e-01, time/batch = 18.4703s	
6467/33150 (epoch 9.754), train_loss = 1.48732582, grad/param norm = 1.8721e-01, time/batch = 18.9000s	
6468/33150 (epoch 9.756), train_loss = 1.27408241, grad/param norm = 1.6944e-01, time/batch = 16.7259s	
6469/33150 (epoch 9.757), train_loss = 1.25105263, grad/param norm = 1.5106e-01, time/batch = 19.7101s	
6470/33150 (epoch 9.759), train_loss = 1.41820937, grad/param norm = 1.6759e-01, time/batch = 18.1281s	
6471/33150 (epoch 9.760), train_loss = 1.29942184, grad/param norm = 1.6344e-01, time/batch = 16.8855s	
6472/33150 (epoch 9.762), train_loss = 1.27848441, grad/param norm = 1.7167e-01, time/batch = 18.3763s	
6473/33150 (epoch 9.763), train_loss = 1.23045788, grad/param norm = 1.5184e-01, time/batch = 18.1501s	
6474/33150 (epoch 9.765), train_loss = 1.18447834, grad/param norm = 1.4758e-01, time/batch = 16.0609s	
6475/33150 (epoch 9.766), train_loss = 1.13005900, grad/param norm = 1.3956e-01, time/batch = 17.3094s	
6476/33150 (epoch 9.768), train_loss = 1.17661740, grad/param norm = 1.5905e-01, time/batch = 18.0640s	
6477/33150 (epoch 9.769), train_loss = 1.24262817, grad/param norm = 1.5383e-01, time/batch = 19.3181s	
6478/33150 (epoch 9.771), train_loss = 1.25021888, grad/param norm = 1.5996e-01, time/batch = 16.2995s	
6479/33150 (epoch 9.772), train_loss = 1.30049464, grad/param norm = 1.7546e-01, time/batch = 18.7417s	
6480/33150 (epoch 9.774), train_loss = 1.40516690, grad/param norm = 1.6929e-01, time/batch = 18.8927s	
6481/33150 (epoch 9.775), train_loss = 1.28342968, grad/param norm = 1.9126e-01, time/batch = 17.1398s	
6482/33150 (epoch 9.777), train_loss = 1.32361462, grad/param norm = 1.7358e-01, time/batch = 19.3106s	
6483/33150 (epoch 9.778), train_loss = 1.23322411, grad/param norm = 1.4240e-01, time/batch = 18.7862s	
6484/33150 (epoch 9.780), train_loss = 1.10703670, grad/param norm = 1.4493e-01, time/batch = 16.4509s	
6485/33150 (epoch 9.781), train_loss = 1.21505457, grad/param norm = 1.6214e-01, time/batch = 16.4033s	
6486/33150 (epoch 9.783), train_loss = 1.22600606, grad/param norm = 1.4334e-01, time/batch = 19.2946s	
6487/33150 (epoch 9.784), train_loss = 1.19292832, grad/param norm = 1.6048e-01, time/batch = 17.9539s	
6488/33150 (epoch 9.786), train_loss = 1.19452734, grad/param norm = 1.4378e-01, time/batch = 16.4756s	
6489/33150 (epoch 9.787), train_loss = 1.18729965, grad/param norm = 1.5015e-01, time/batch = 18.3195s	
6490/33150 (epoch 9.789), train_loss = 1.04519570, grad/param norm = 1.3226e-01, time/batch = 16.3539s	
6491/33150 (epoch 9.790), train_loss = 1.02335134, grad/param norm = 1.3241e-01, time/batch = 15.3021s	
6492/33150 (epoch 9.792), train_loss = 1.30053937, grad/param norm = 1.8873e-01, time/batch = 18.2852s	
6493/33150 (epoch 9.793), train_loss = 1.21498325, grad/param norm = 1.6398e-01, time/batch = 16.6936s	
6494/33150 (epoch 9.795), train_loss = 1.15800534, grad/param norm = 1.6539e-01, time/batch = 19.5601s	
6495/33150 (epoch 9.796), train_loss = 1.11770849, grad/param norm = 1.4601e-01, time/batch = 16.7298s	
6496/33150 (epoch 9.798), train_loss = 1.16601416, grad/param norm = 1.3103e-01, time/batch = 17.3988s	
6497/33150 (epoch 9.799), train_loss = 1.04888834, grad/param norm = 1.5018e-01, time/batch = 17.9523s	
6498/33150 (epoch 9.801), train_loss = 1.21962928, grad/param norm = 1.4417e-01, time/batch = 16.2079s	
6499/33150 (epoch 9.802), train_loss = 1.12490473, grad/param norm = 1.6368e-01, time/batch = 19.1286s	
6500/33150 (epoch 9.804), train_loss = 1.20744903, grad/param norm = 1.6387e-01, time/batch = 19.5636s	
6501/33150 (epoch 9.805), train_loss = 1.19374001, grad/param norm = 1.6089e-01, time/batch = 18.0270s	
6502/33150 (epoch 9.807), train_loss = 1.13185858, grad/param norm = 1.5375e-01, time/batch = 16.3768s	
6503/33150 (epoch 9.808), train_loss = 1.28365990, grad/param norm = 1.6373e-01, time/batch = 18.6439s	
6504/33150 (epoch 9.810), train_loss = 1.19547809, grad/param norm = 1.5592e-01, time/batch = 17.6368s	
6505/33150 (epoch 9.811), train_loss = 1.28413087, grad/param norm = 1.5990e-01, time/batch = 17.3763s	
6506/33150 (epoch 9.813), train_loss = 1.18229741, grad/param norm = 1.4546e-01, time/batch = 17.2097s	
6507/33150 (epoch 9.814), train_loss = 1.22689205, grad/param norm = 1.6453e-01, time/batch = 19.8910s	
6508/33150 (epoch 9.816), train_loss = 1.19504071, grad/param norm = 1.5834e-01, time/batch = 16.9758s	
6509/33150 (epoch 9.817), train_loss = 1.30665366, grad/param norm = 1.4969e-01, time/batch = 19.0426s	
6510/33150 (epoch 9.819), train_loss = 1.18760097, grad/param norm = 1.5095e-01, time/batch = 19.4698s	
6511/33150 (epoch 9.821), train_loss = 1.03977419, grad/param norm = 1.3193e-01, time/batch = 18.5456s	
6512/33150 (epoch 9.822), train_loss = 1.11919979, grad/param norm = 1.5373e-01, time/batch = 18.8019s	
6513/33150 (epoch 9.824), train_loss = 1.17583313, grad/param norm = 1.6072e-01, time/batch = 16.5017s	
6514/33150 (epoch 9.825), train_loss = 1.22769760, grad/param norm = 1.5380e-01, time/batch = 18.3221s	
6515/33150 (epoch 9.827), train_loss = 1.30982470, grad/param norm = 1.7518e-01, time/batch = 17.2389s	
6516/33150 (epoch 9.828), train_loss = 1.10950379, grad/param norm = 1.6112e-01, time/batch = 18.8187s	
6517/33150 (epoch 9.830), train_loss = 1.27230784, grad/param norm = 1.5775e-01, time/batch = 17.5677s	
6518/33150 (epoch 9.831), train_loss = 1.16438053, grad/param norm = 1.6261e-01, time/batch = 16.0719s	
6519/33150 (epoch 9.833), train_loss = 1.10998087, grad/param norm = 1.6028e-01, time/batch = 17.1576s	
6520/33150 (epoch 9.834), train_loss = 1.38700810, grad/param norm = 1.6979e-01, time/batch = 19.0533s	
6521/33150 (epoch 9.836), train_loss = 1.32861126, grad/param norm = 1.7699e-01, time/batch = 18.5879s	
6522/33150 (epoch 9.837), train_loss = 1.21168539, grad/param norm = 1.4633e-01, time/batch = 26.7802s	
6523/33150 (epoch 9.839), train_loss = 1.34926358, grad/param norm = 2.2140e-01, time/batch = 15.6919s	
6524/33150 (epoch 9.840), train_loss = 1.31915028, grad/param norm = 1.7048e-01, time/batch = 15.1188s	
6525/33150 (epoch 9.842), train_loss = 1.40768429, grad/param norm = 1.8883e-01, time/batch = 14.9393s	
6526/33150 (epoch 9.843), train_loss = 1.32246558, grad/param norm = 1.6646e-01, time/batch = 15.1736s	
6527/33150 (epoch 9.845), train_loss = 1.16965951, grad/param norm = 1.5097e-01, time/batch = 15.0135s	
6528/33150 (epoch 9.846), train_loss = 1.47100250, grad/param norm = 1.8853e-01, time/batch = 15.0846s	
6529/33150 (epoch 9.848), train_loss = 1.28768604, grad/param norm = 1.5570e-01, time/batch = 15.1119s	
6530/33150 (epoch 9.849), train_loss = 1.28495651, grad/param norm = 1.6419e-01, time/batch = 16.7185s	
6531/33150 (epoch 9.851), train_loss = 1.34850636, grad/param norm = 1.7553e-01, time/batch = 17.7111s	
6532/33150 (epoch 9.852), train_loss = 1.37035980, grad/param norm = 1.5253e-01, time/batch = 16.2952s	
6533/33150 (epoch 9.854), train_loss = 1.25512957, grad/param norm = 1.4961e-01, time/batch = 16.8873s	
6534/33150 (epoch 9.855), train_loss = 1.03294032, grad/param norm = 1.3643e-01, time/batch = 16.6210s	
6535/33150 (epoch 9.857), train_loss = 1.05057836, grad/param norm = 1.3856e-01, time/batch = 17.2146s	
6536/33150 (epoch 9.858), train_loss = 1.15833849, grad/param norm = 1.4750e-01, time/batch = 15.6389s	
6537/33150 (epoch 9.860), train_loss = 1.09811980, grad/param norm = 1.3380e-01, time/batch = 18.1467s	
6538/33150 (epoch 9.861), train_loss = 1.13822850, grad/param norm = 1.4466e-01, time/batch = 17.5500s	
6539/33150 (epoch 9.863), train_loss = 1.26487618, grad/param norm = 1.4446e-01, time/batch = 15.7854s	
6540/33150 (epoch 9.864), train_loss = 1.34139974, grad/param norm = 1.5216e-01, time/batch = 16.0582s	
6541/33150 (epoch 9.866), train_loss = 1.23431861, grad/param norm = 1.5847e-01, time/batch = 16.8687s	
6542/33150 (epoch 9.867), train_loss = 1.27021054, grad/param norm = 1.4113e-01, time/batch = 18.6965s	
6543/33150 (epoch 9.869), train_loss = 1.30600573, grad/param norm = 1.6871e-01, time/batch = 16.4431s	
6544/33150 (epoch 9.870), train_loss = 1.29993930, grad/param norm = 1.6936e-01, time/batch = 18.6398s	
6545/33150 (epoch 9.872), train_loss = 1.22328968, grad/param norm = 1.6388e-01, time/batch = 16.6305s	
6546/33150 (epoch 9.873), train_loss = 1.03054091, grad/param norm = 1.3436e-01, time/batch = 16.7115s	
6547/33150 (epoch 9.875), train_loss = 1.40301498, grad/param norm = 1.6631e-01, time/batch = 16.8894s	
6548/33150 (epoch 9.876), train_loss = 1.14443506, grad/param norm = 1.6523e-01, time/batch = 17.9629s	
6549/33150 (epoch 9.878), train_loss = 1.09337371, grad/param norm = 1.3760e-01, time/batch = 17.2802s	
6550/33150 (epoch 9.879), train_loss = 1.13474516, grad/param norm = 1.5705e-01, time/batch = 16.4848s	
6551/33150 (epoch 9.881), train_loss = 1.16898903, grad/param norm = 1.4967e-01, time/batch = 18.4698s	
6552/33150 (epoch 9.882), train_loss = 1.07683580, grad/param norm = 1.4506e-01, time/batch = 17.3835s	
6553/33150 (epoch 9.884), train_loss = 1.22895027, grad/param norm = 1.6030e-01, time/batch = 16.0673s	
6554/33150 (epoch 9.885), train_loss = 0.96849781, grad/param norm = 1.4858e-01, time/batch = 16.2963s	
6555/33150 (epoch 9.887), train_loss = 1.42411676, grad/param norm = 1.6845e-01, time/batch = 16.8233s	
6556/33150 (epoch 9.888), train_loss = 1.26950845, grad/param norm = 1.6137e-01, time/batch = 15.9050s	
6557/33150 (epoch 9.890), train_loss = 1.18591365, grad/param norm = 1.6748e-01, time/batch = 16.0244s	
6558/33150 (epoch 9.891), train_loss = 1.12392745, grad/param norm = 1.5992e-01, time/batch = 16.7191s	
6559/33150 (epoch 9.893), train_loss = 1.31357027, grad/param norm = 1.7138e-01, time/batch = 15.6387s	
6560/33150 (epoch 9.894), train_loss = 1.29960356, grad/param norm = 1.5884e-01, time/batch = 16.0588s	
6561/33150 (epoch 9.896), train_loss = 1.17388645, grad/param norm = 1.4885e-01, time/batch = 15.9747s	
6562/33150 (epoch 9.897), train_loss = 1.24367423, grad/param norm = 1.4211e-01, time/batch = 17.8005s	
6563/33150 (epoch 9.899), train_loss = 1.10434895, grad/param norm = 1.6274e-01, time/batch = 17.6609s	
6564/33150 (epoch 9.900), train_loss = 1.51294444, grad/param norm = 1.6838e-01, time/batch = 16.0466s	
6565/33150 (epoch 9.902), train_loss = 1.40846044, grad/param norm = 1.6570e-01, time/batch = 18.8107s	
6566/33150 (epoch 9.903), train_loss = 1.22854856, grad/param norm = 1.4612e-01, time/batch = 18.2223s	
6567/33150 (epoch 9.905), train_loss = 1.24879156, grad/param norm = 1.5607e-01, time/batch = 17.3894s	
6568/33150 (epoch 9.906), train_loss = 1.32467467, grad/param norm = 1.6808e-01, time/batch = 15.2414s	
6569/33150 (epoch 9.908), train_loss = 1.37672251, grad/param norm = 1.6312e-01, time/batch = 19.3861s	
6570/33150 (epoch 9.910), train_loss = 1.31489058, grad/param norm = 1.4975e-01, time/batch = 18.1504s	
6571/33150 (epoch 9.911), train_loss = 1.07585286, grad/param norm = 1.3668e-01, time/batch = 17.7995s	
6572/33150 (epoch 9.913), train_loss = 1.12945174, grad/param norm = 1.4708e-01, time/batch = 18.1341s	
6573/33150 (epoch 9.914), train_loss = 1.32089864, grad/param norm = 1.7050e-01, time/batch = 20.1193s	
6574/33150 (epoch 9.916), train_loss = 1.13272244, grad/param norm = 1.6910e-01, time/batch = 16.3628s	
6575/33150 (epoch 9.917), train_loss = 1.38209115, grad/param norm = 1.7933e-01, time/batch = 17.9790s	
6576/33150 (epoch 9.919), train_loss = 1.42179641, grad/param norm = 1.8134e-01, time/batch = 17.4129s	
6577/33150 (epoch 9.920), train_loss = 1.32110558, grad/param norm = 1.5605e-01, time/batch = 17.0557s	
6578/33150 (epoch 9.922), train_loss = 1.41865000, grad/param norm = 1.7207e-01, time/batch = 17.1575s	
6579/33150 (epoch 9.923), train_loss = 1.23768813, grad/param norm = 1.6395e-01, time/batch = 18.8901s	
6580/33150 (epoch 9.925), train_loss = 1.26569958, grad/param norm = 1.5193e-01, time/batch = 16.3813s	
6581/33150 (epoch 9.926), train_loss = 1.21497928, grad/param norm = 1.5811e-01, time/batch = 17.9719s	
6582/33150 (epoch 9.928), train_loss = 1.20522115, grad/param norm = 1.6208e-01, time/batch = 17.0741s	
6583/33150 (epoch 9.929), train_loss = 1.30447368, grad/param norm = 1.6044e-01, time/batch = 19.0613s	
6584/33150 (epoch 9.931), train_loss = 1.41480804, grad/param norm = 1.8553e-01, time/batch = 16.9867s	
6585/33150 (epoch 9.932), train_loss = 1.23615579, grad/param norm = 1.6547e-01, time/batch = 18.5513s	
6586/33150 (epoch 9.934), train_loss = 1.25565533, grad/param norm = 1.5164e-01, time/batch = 19.7988s	
6587/33150 (epoch 9.935), train_loss = 1.36133429, grad/param norm = 1.5953e-01, time/batch = 17.2186s	
6588/33150 (epoch 9.937), train_loss = 1.37125173, grad/param norm = 1.6383e-01, time/batch = 16.8168s	
6589/33150 (epoch 9.938), train_loss = 1.33436171, grad/param norm = 1.5361e-01, time/batch = 18.5651s	
6590/33150 (epoch 9.940), train_loss = 1.54219565, grad/param norm = 1.7234e-01, time/batch = 18.1525s	
6591/33150 (epoch 9.941), train_loss = 1.20541754, grad/param norm = 1.4515e-01, time/batch = 16.0570s	
6592/33150 (epoch 9.943), train_loss = 1.12211924, grad/param norm = 1.6759e-01, time/batch = 17.5106s	
6593/33150 (epoch 9.944), train_loss = 1.37795029, grad/param norm = 1.7004e-01, time/batch = 17.0740s	
6594/33150 (epoch 9.946), train_loss = 1.02566449, grad/param norm = 1.3696e-01, time/batch = 17.4801s	
6595/33150 (epoch 9.947), train_loss = 1.29195958, grad/param norm = 1.6090e-01, time/batch = 17.2368s	
6596/33150 (epoch 9.949), train_loss = 1.38960298, grad/param norm = 1.5469e-01, time/batch = 18.4993s	
6597/33150 (epoch 9.950), train_loss = 1.30963445, grad/param norm = 1.6732e-01, time/batch = 17.1501s	
6598/33150 (epoch 9.952), train_loss = 1.15370046, grad/param norm = 1.4790e-01, time/batch = 17.8202s	
6599/33150 (epoch 9.953), train_loss = 1.17488966, grad/param norm = 1.4609e-01, time/batch = 16.5004s	
6600/33150 (epoch 9.955), train_loss = 1.10470281, grad/param norm = 1.4443e-01, time/batch = 18.2381s	
6601/33150 (epoch 9.956), train_loss = 1.32726207, grad/param norm = 1.5555e-01, time/batch = 15.8910s	
6602/33150 (epoch 9.958), train_loss = 1.09272884, grad/param norm = 1.5407e-01, time/batch = 17.6996s	
6603/33150 (epoch 9.959), train_loss = 1.13440516, grad/param norm = 1.6123e-01, time/batch = 17.6560s	
6604/33150 (epoch 9.961), train_loss = 1.11072287, grad/param norm = 1.4985e-01, time/batch = 16.8847s	
6605/33150 (epoch 9.962), train_loss = 1.06834254, grad/param norm = 1.4065e-01, time/batch = 15.3231s	
6606/33150 (epoch 9.964), train_loss = 1.25228451, grad/param norm = 1.6466e-01, time/batch = 18.6463s	
6607/33150 (epoch 9.965), train_loss = 1.21525948, grad/param norm = 1.4923e-01, time/batch = 16.6420s	
6608/33150 (epoch 9.967), train_loss = 1.27204281, grad/param norm = 1.7135e-01, time/batch = 15.9690s	
6609/33150 (epoch 9.968), train_loss = 1.03746630, grad/param norm = 1.3966e-01, time/batch = 16.2274s	
6610/33150 (epoch 9.970), train_loss = 1.17432141, grad/param norm = 1.5210e-01, time/batch = 17.4095s	
6611/33150 (epoch 9.971), train_loss = 1.27299709, grad/param norm = 1.7368e-01, time/batch = 18.3066s	
6612/33150 (epoch 9.973), train_loss = 1.43131548, grad/param norm = 1.6681e-01, time/batch = 16.3180s	
6613/33150 (epoch 9.974), train_loss = 1.43315142, grad/param norm = 1.7951e-01, time/batch = 17.4540s	
6614/33150 (epoch 9.976), train_loss = 1.29217251, grad/param norm = 1.5144e-01, time/batch = 18.9856s	
6615/33150 (epoch 9.977), train_loss = 1.36789581, grad/param norm = 1.6585e-01, time/batch = 16.8049s	
6616/33150 (epoch 9.979), train_loss = 1.37278994, grad/param norm = 1.7453e-01, time/batch = 19.8762s	
6617/33150 (epoch 9.980), train_loss = 1.37710785, grad/param norm = 1.5813e-01, time/batch = 16.4924s	
6618/33150 (epoch 9.982), train_loss = 1.21813657, grad/param norm = 1.6513e-01, time/batch = 17.3948s	
6619/33150 (epoch 9.983), train_loss = 1.09549274, grad/param norm = 1.5344e-01, time/batch = 15.9867s	
6620/33150 (epoch 9.985), train_loss = 1.26314327, grad/param norm = 1.4825e-01, time/batch = 18.0822s	
6621/33150 (epoch 9.986), train_loss = 1.08986310, grad/param norm = 1.4437e-01, time/batch = 18.4821s	
6622/33150 (epoch 9.988), train_loss = 1.17771897, grad/param norm = 1.5214e-01, time/batch = 15.6629s	
6623/33150 (epoch 9.989), train_loss = 1.11663643, grad/param norm = 1.5193e-01, time/batch = 16.5722s	
6624/33150 (epoch 9.991), train_loss = 1.33958222, grad/param norm = 1.8838e-01, time/batch = 18.1450s	
6625/33150 (epoch 9.992), train_loss = 1.09485737, grad/param norm = 1.5801e-01, time/batch = 16.0468s	
6626/33150 (epoch 9.994), train_loss = 1.19805907, grad/param norm = 1.6061e-01, time/batch = 16.2926s	
6627/33150 (epoch 9.995), train_loss = 1.14268423, grad/param norm = 1.4700e-01, time/batch = 17.4688s	
6628/33150 (epoch 9.997), train_loss = 1.25564427, grad/param norm = 1.7436e-01, time/batch = 17.3192s	
6629/33150 (epoch 9.998), train_loss = 0.98446899, grad/param norm = 1.4409e-01, time/batch = 17.6517s	
decayed learning rate by a factor 0.97 to 0.00194	
6630/33150 (epoch 10.000), train_loss = 1.10501184, grad/param norm = 1.5422e-01, time/batch = 17.2345s	
6631/33150 (epoch 10.002), train_loss = 1.53140766, grad/param norm = 1.7707e-01, time/batch = 18.9809s	
6632/33150 (epoch 10.003), train_loss = 1.15822092, grad/param norm = 1.6643e-01, time/batch = 16.7261s	
6633/33150 (epoch 10.005), train_loss = 1.07703604, grad/param norm = 1.4626e-01, time/batch = 16.5638s	
6634/33150 (epoch 10.006), train_loss = 1.04829162, grad/param norm = 1.5064e-01, time/batch = 19.1322s	
6635/33150 (epoch 10.008), train_loss = 1.38928917, grad/param norm = 1.8269e-01, time/batch = 18.6465s	
6636/33150 (epoch 10.009), train_loss = 1.18983815, grad/param norm = 1.3741e-01, time/batch = 18.7091s	
6637/33150 (epoch 10.011), train_loss = 1.40430833, grad/param norm = 1.6384e-01, time/batch = 20.2291s	
6638/33150 (epoch 10.012), train_loss = 1.23035106, grad/param norm = 1.8023e-01, time/batch = 17.1385s	
6639/33150 (epoch 10.014), train_loss = 1.20840538, grad/param norm = 1.6750e-01, time/batch = 16.9729s	
6640/33150 (epoch 10.015), train_loss = 1.17770335, grad/param norm = 1.5109e-01, time/batch = 18.7280s	
6641/33150 (epoch 10.017), train_loss = 1.15801810, grad/param norm = 1.4791e-01, time/batch = 18.4052s	
6642/33150 (epoch 10.018), train_loss = 1.26647087, grad/param norm = 1.5835e-01, time/batch = 16.3945s	
6643/33150 (epoch 10.020), train_loss = 1.28092790, grad/param norm = 1.5927e-01, time/batch = 16.0651s	
6644/33150 (epoch 10.021), train_loss = 1.04433348, grad/param norm = 1.5859e-01, time/batch = 18.7234s	
6645/33150 (epoch 10.023), train_loss = 1.39959606, grad/param norm = 1.5002e-01, time/batch = 18.0633s	
6646/33150 (epoch 10.024), train_loss = 1.25853350, grad/param norm = 1.6013e-01, time/batch = 16.9975s	
6647/33150 (epoch 10.026), train_loss = 0.97975838, grad/param norm = 1.2897e-01, time/batch = 18.0524s	
6648/33150 (epoch 10.027), train_loss = 1.02022337, grad/param norm = 1.5530e-01, time/batch = 15.9578s	
6649/33150 (epoch 10.029), train_loss = 1.13602194, grad/param norm = 1.6140e-01, time/batch = 17.0775s	
6650/33150 (epoch 10.030), train_loss = 1.20880779, grad/param norm = 1.3907e-01, time/batch = 17.1506s	
6651/33150 (epoch 10.032), train_loss = 1.12077573, grad/param norm = 1.6316e-01, time/batch = 19.9582s	
6652/33150 (epoch 10.033), train_loss = 1.17848390, grad/param norm = 1.5363e-01, time/batch = 16.2302s	
6653/33150 (epoch 10.035), train_loss = 1.40913923, grad/param norm = 1.7088e-01, time/batch = 18.8882s	
6654/33150 (epoch 10.036), train_loss = 1.28931443, grad/param norm = 1.6128e-01, time/batch = 17.7332s	
6655/33150 (epoch 10.038), train_loss = 1.55076870, grad/param norm = 1.8671e-01, time/batch = 17.1390s	
6656/33150 (epoch 10.039), train_loss = 1.25242836, grad/param norm = 1.3871e-01, time/batch = 16.9680s	
6657/33150 (epoch 10.041), train_loss = 1.25193210, grad/param norm = 1.5611e-01, time/batch = 17.9767s	
6658/33150 (epoch 10.042), train_loss = 1.16582915, grad/param norm = 1.4748e-01, time/batch = 19.2366s	
6659/33150 (epoch 10.044), train_loss = 1.17289313, grad/param norm = 1.4312e-01, time/batch = 16.2222s	
6660/33150 (epoch 10.045), train_loss = 1.20024136, grad/param norm = 1.4310e-01, time/batch = 17.2185s	
6661/33150 (epoch 10.047), train_loss = 1.14219463, grad/param norm = 1.5977e-01, time/batch = 18.2879s	
6662/33150 (epoch 10.048), train_loss = 1.37966615, grad/param norm = 1.8011e-01, time/batch = 18.3887s	
6663/33150 (epoch 10.050), train_loss = 1.21183987, grad/param norm = 1.6157e-01, time/batch = 16.8140s	
6664/33150 (epoch 10.051), train_loss = 1.24008080, grad/param norm = 1.5695e-01, time/batch = 18.1499s	
6665/33150 (epoch 10.053), train_loss = 1.17924326, grad/param norm = 1.5275e-01, time/batch = 17.4892s	
6666/33150 (epoch 10.054), train_loss = 1.25850025, grad/param norm = 1.3578e-01, time/batch = 15.7310s	
6667/33150 (epoch 10.056), train_loss = 1.12804474, grad/param norm = 1.3868e-01, time/batch = 17.4023s	
6668/33150 (epoch 10.057), train_loss = 1.23220184, grad/param norm = 1.7443e-01, time/batch = 19.5505s	
6669/33150 (epoch 10.059), train_loss = 1.14333983, grad/param norm = 1.5164e-01, time/batch = 17.3900s	
6670/33150 (epoch 10.060), train_loss = 1.14169539, grad/param norm = 1.4049e-01, time/batch = 17.9675s	
6671/33150 (epoch 10.062), train_loss = 1.20060104, grad/param norm = 1.4618e-01, time/batch = 19.9598s	
6672/33150 (epoch 10.063), train_loss = 1.16645373, grad/param norm = 1.4692e-01, time/batch = 16.8757s	
6673/33150 (epoch 10.065), train_loss = 1.19487955, grad/param norm = 1.3955e-01, time/batch = 16.0856s	
6674/33150 (epoch 10.066), train_loss = 1.13623863, grad/param norm = 1.4936e-01, time/batch = 18.7372s	
6675/33150 (epoch 10.068), train_loss = 1.21938424, grad/param norm = 1.5802e-01, time/batch = 17.8988s	
6676/33150 (epoch 10.069), train_loss = 1.29667613, grad/param norm = 1.7427e-01, time/batch = 16.2336s	
6677/33150 (epoch 10.071), train_loss = 1.26716067, grad/param norm = 1.4460e-01, time/batch = 16.2190s	
6678/33150 (epoch 10.072), train_loss = 1.14510665, grad/param norm = 1.4554e-01, time/batch = 15.1649s	
6679/33150 (epoch 10.074), train_loss = 1.05220526, grad/param norm = 1.5149e-01, time/batch = 14.7675s	
6680/33150 (epoch 10.075), train_loss = 1.15394585, grad/param norm = 1.4729e-01, time/batch = 14.9464s	
6681/33150 (epoch 10.077), train_loss = 1.27084501, grad/param norm = 1.7563e-01, time/batch = 15.3341s	
6682/33150 (epoch 10.078), train_loss = 1.42446944, grad/param norm = 1.9563e-01, time/batch = 14.7992s	
6683/33150 (epoch 10.080), train_loss = 1.31471074, grad/param norm = 1.5123e-01, time/batch = 15.6241s	
6684/33150 (epoch 10.081), train_loss = 1.13306200, grad/param norm = 1.5779e-01, time/batch = 16.0330s	
6685/33150 (epoch 10.083), train_loss = 0.90104015, grad/param norm = 1.5687e-01, time/batch = 17.8022s	
6686/33150 (epoch 10.084), train_loss = 1.05706616, grad/param norm = 1.5702e-01, time/batch = 17.2932s	
6687/33150 (epoch 10.086), train_loss = 1.15550244, grad/param norm = 1.6193e-01, time/batch = 17.6249s	
6688/33150 (epoch 10.087), train_loss = 1.08771403, grad/param norm = 1.4103e-01, time/batch = 17.3802s	
6689/33150 (epoch 10.089), train_loss = 1.12955360, grad/param norm = 1.5814e-01, time/batch = 16.3832s	
6690/33150 (epoch 10.090), train_loss = 1.14204450, grad/param norm = 1.6865e-01, time/batch = 18.6146s	
6691/33150 (epoch 10.092), train_loss = 1.17729854, grad/param norm = 1.5163e-01, time/batch = 17.2851s	
6692/33150 (epoch 10.094), train_loss = 1.30657015, grad/param norm = 1.9040e-01, time/batch = 18.1258s	
6693/33150 (epoch 10.095), train_loss = 1.05937778, grad/param norm = 1.4511e-01, time/batch = 19.2763s	
6694/33150 (epoch 10.097), train_loss = 1.22145456, grad/param norm = 1.6155e-01, time/batch = 15.8117s	
6695/33150 (epoch 10.098), train_loss = 1.47048859, grad/param norm = 1.7490e-01, time/batch = 17.3866s	
6696/33150 (epoch 10.100), train_loss = 1.41604397, grad/param norm = 1.6663e-01, time/batch = 15.9726s	
6697/33150 (epoch 10.101), train_loss = 1.12633608, grad/param norm = 1.6713e-01, time/batch = 17.8702s	
6698/33150 (epoch 10.103), train_loss = 1.26031690, grad/param norm = 1.6044e-01, time/batch = 15.8707s	
6699/33150 (epoch 10.104), train_loss = 1.17173576, grad/param norm = 1.7374e-01, time/batch = 17.9769s	
6700/33150 (epoch 10.106), train_loss = 1.39150354, grad/param norm = 1.7931e-01, time/batch = 16.7891s	
6701/33150 (epoch 10.107), train_loss = 1.45494181, grad/param norm = 1.8176e-01, time/batch = 16.4901s	
6702/33150 (epoch 10.109), train_loss = 1.14384206, grad/param norm = 1.4195e-01, time/batch = 16.5598s	
6703/33150 (epoch 10.110), train_loss = 1.26996363, grad/param norm = 1.4876e-01, time/batch = 17.2922s	
6704/33150 (epoch 10.112), train_loss = 1.12181769, grad/param norm = 1.4742e-01, time/batch = 16.8109s	
6705/33150 (epoch 10.113), train_loss = 1.17317960, grad/param norm = 1.5515e-01, time/batch = 17.2119s	
6706/33150 (epoch 10.115), train_loss = 1.41446138, grad/param norm = 1.8009e-01, time/batch = 18.5335s	
6707/33150 (epoch 10.116), train_loss = 1.10488568, grad/param norm = 1.5206e-01, time/batch = 15.4886s	
6708/33150 (epoch 10.118), train_loss = 1.28024722, grad/param norm = 1.6537e-01, time/batch = 16.7922s	
6709/33150 (epoch 10.119), train_loss = 1.26824382, grad/param norm = 1.6090e-01, time/batch = 16.8062s	
6710/33150 (epoch 10.121), train_loss = 1.16566924, grad/param norm = 1.4845e-01, time/batch = 17.4530s	
6711/33150 (epoch 10.122), train_loss = 1.41642894, grad/param norm = 1.9065e-01, time/batch = 17.6269s	
6712/33150 (epoch 10.124), train_loss = 0.96308693, grad/param norm = 1.2637e-01, time/batch = 15.8752s	
6713/33150 (epoch 10.125), train_loss = 1.31462055, grad/param norm = 1.5837e-01, time/batch = 16.9896s	
6714/33150 (epoch 10.127), train_loss = 1.13489327, grad/param norm = 1.4459e-01, time/batch = 17.3135s	
6715/33150 (epoch 10.128), train_loss = 1.22142303, grad/param norm = 1.6406e-01, time/batch = 17.5651s	
6716/33150 (epoch 10.130), train_loss = 1.24666182, grad/param norm = 1.3960e-01, time/batch = 18.8778s	
6717/33150 (epoch 10.131), train_loss = 1.44206759, grad/param norm = 1.7337e-01, time/batch = 17.3899s	
6718/33150 (epoch 10.133), train_loss = 1.13335125, grad/param norm = 1.6187e-01, time/batch = 17.7223s	
6719/33150 (epoch 10.134), train_loss = 1.34328533, grad/param norm = 1.5699e-01, time/batch = 16.7313s	
6720/33150 (epoch 10.136), train_loss = 1.25047810, grad/param norm = 1.7841e-01, time/batch = 17.8943s	
6721/33150 (epoch 10.137), train_loss = 1.29945229, grad/param norm = 1.5744e-01, time/batch = 18.0373s	
6722/33150 (epoch 10.139), train_loss = 1.27301104, grad/param norm = 1.7220e-01, time/batch = 17.2150s	
6723/33150 (epoch 10.140), train_loss = 1.37393524, grad/param norm = 1.6944e-01, time/batch = 17.5586s	
6724/33150 (epoch 10.142), train_loss = 1.31344334, grad/param norm = 1.7903e-01, time/batch = 19.3076s	
6725/33150 (epoch 10.143), train_loss = 1.24504408, grad/param norm = 1.6519e-01, time/batch = 17.6258s	
6726/33150 (epoch 10.145), train_loss = 1.22493086, grad/param norm = 1.8131e-01, time/batch = 17.8888s	
6727/33150 (epoch 10.146), train_loss = 1.38078255, grad/param norm = 1.9874e-01, time/batch = 17.3239s	
6728/33150 (epoch 10.148), train_loss = 1.29234254, grad/param norm = 1.5741e-01, time/batch = 17.4719s	
6729/33150 (epoch 10.149), train_loss = 1.25570128, grad/param norm = 1.5606e-01, time/batch = 32.3138s	
6730/33150 (epoch 10.151), train_loss = 1.43827669, grad/param norm = 1.6022e-01, time/batch = 16.6993s	
6731/33150 (epoch 10.152), train_loss = 1.18610858, grad/param norm = 1.4640e-01, time/batch = 16.8662s	
6732/33150 (epoch 10.154), train_loss = 1.18238867, grad/param norm = 1.4985e-01, time/batch = 19.3857s	
6733/33150 (epoch 10.155), train_loss = 1.08992123, grad/param norm = 1.4410e-01, time/batch = 18.7965s	
6734/33150 (epoch 10.157), train_loss = 1.16563969, grad/param norm = 1.7371e-01, time/batch = 16.7241s	
6735/33150 (epoch 10.158), train_loss = 1.13245750, grad/param norm = 1.6054e-01, time/batch = 16.5566s	
6736/33150 (epoch 10.160), train_loss = 1.30975413, grad/param norm = 1.5104e-01, time/batch = 18.9746s	
6737/33150 (epoch 10.161), train_loss = 1.19217346, grad/param norm = 1.7326e-01, time/batch = 17.5651s	
6738/33150 (epoch 10.163), train_loss = 1.16720811, grad/param norm = 1.4825e-01, time/batch = 16.3650s	
6739/33150 (epoch 10.164), train_loss = 1.31391606, grad/param norm = 1.5366e-01, time/batch = 18.6096s	
6740/33150 (epoch 10.166), train_loss = 1.19871768, grad/param norm = 1.6345e-01, time/batch = 18.4568s	
6741/33150 (epoch 10.167), train_loss = 1.22681404, grad/param norm = 1.5194e-01, time/batch = 16.8043s	
6742/33150 (epoch 10.169), train_loss = 1.31631323, grad/param norm = 1.8969e-01, time/batch = 18.1361s	
6743/33150 (epoch 10.170), train_loss = 1.15868907, grad/param norm = 1.6854e-01, time/batch = 16.8049s	
6744/33150 (epoch 10.172), train_loss = 1.35238329, grad/param norm = 1.8954e-01, time/batch = 19.0581s	
6745/33150 (epoch 10.173), train_loss = 1.31757584, grad/param norm = 1.9112e-01, time/batch = 15.5510s	
6746/33150 (epoch 10.175), train_loss = 1.12968114, grad/param norm = 1.6975e-01, time/batch = 19.2326s	
6747/33150 (epoch 10.176), train_loss = 1.25615259, grad/param norm = 1.7216e-01, time/batch = 17.8741s	
6748/33150 (epoch 10.178), train_loss = 1.42294033, grad/param norm = 1.6003e-01, time/batch = 16.1457s	
6749/33150 (epoch 10.179), train_loss = 1.27119429, grad/param norm = 1.4528e-01, time/batch = 18.7294s	
6750/33150 (epoch 10.181), train_loss = 1.23568351, grad/param norm = 1.6643e-01, time/batch = 17.2082s	
6751/33150 (epoch 10.183), train_loss = 1.22511284, grad/param norm = 1.7506e-01, time/batch = 17.8695s	
6752/33150 (epoch 10.184), train_loss = 1.41549268, grad/param norm = 1.7191e-01, time/batch = 18.8039s	
6753/33150 (epoch 10.186), train_loss = 1.34081532, grad/param norm = 1.5739e-01, time/batch = 18.5364s	
6754/33150 (epoch 10.187), train_loss = 1.26030864, grad/param norm = 1.6165e-01, time/batch = 18.2824s	
6755/33150 (epoch 10.189), train_loss = 1.05519645, grad/param norm = 1.5518e-01, time/batch = 18.6239s	
6756/33150 (epoch 10.190), train_loss = 1.12614080, grad/param norm = 1.5372e-01, time/batch = 19.2185s	
6757/33150 (epoch 10.192), train_loss = 1.22544413, grad/param norm = 1.7822e-01, time/batch = 15.8180s	
6758/33150 (epoch 10.193), train_loss = 1.26774066, grad/param norm = 1.5839e-01, time/batch = 16.6348s	
6759/33150 (epoch 10.195), train_loss = 1.54036513, grad/param norm = 1.8811e-01, time/batch = 19.5556s	
6760/33150 (epoch 10.196), train_loss = 1.37192110, grad/param norm = 1.4700e-01, time/batch = 17.7997s	
6761/33150 (epoch 10.198), train_loss = 1.07060327, grad/param norm = 1.6492e-01, time/batch = 17.6245s	
6762/33150 (epoch 10.199), train_loss = 1.33214805, grad/param norm = 1.7392e-01, time/batch = 19.4588s	
6763/33150 (epoch 10.201), train_loss = 1.07977601, grad/param norm = 1.3184e-01, time/batch = 15.6440s	
6764/33150 (epoch 10.202), train_loss = 1.04027011, grad/param norm = 1.3602e-01, time/batch = 16.6489s	
6765/33150 (epoch 10.204), train_loss = 1.22827955, grad/param norm = 1.5631e-01, time/batch = 16.8820s	
6766/33150 (epoch 10.205), train_loss = 1.31899881, grad/param norm = 1.7548e-01, time/batch = 18.6442s	
6767/33150 (epoch 10.207), train_loss = 1.25185967, grad/param norm = 1.4823e-01, time/batch = 16.3762s	
6768/33150 (epoch 10.208), train_loss = 1.29057176, grad/param norm = 1.5898e-01, time/batch = 16.4751s	
6769/33150 (epoch 10.210), train_loss = 1.10650151, grad/param norm = 1.2875e-01, time/batch = 18.0703s	
6770/33150 (epoch 10.211), train_loss = 1.27298599, grad/param norm = 1.7169e-01, time/batch = 18.7384s	
6771/33150 (epoch 10.213), train_loss = 1.33691557, grad/param norm = 1.6535e-01, time/batch = 16.9007s	
6772/33150 (epoch 10.214), train_loss = 1.18674494, grad/param norm = 1.5758e-01, time/batch = 18.5637s	
6773/33150 (epoch 10.216), train_loss = 1.15511719, grad/param norm = 1.5809e-01, time/batch = 18.0596s	
6774/33150 (epoch 10.217), train_loss = 1.15025043, grad/param norm = 1.4686e-01, time/batch = 17.9008s	
6775/33150 (epoch 10.219), train_loss = 1.12235970, grad/param norm = 1.5318e-01, time/batch = 16.4818s	
6776/33150 (epoch 10.220), train_loss = 1.14690476, grad/param norm = 1.4128e-01, time/batch = 17.4071s	
6777/33150 (epoch 10.222), train_loss = 1.29957156, grad/param norm = 1.5805e-01, time/batch = 18.6368s	
6778/33150 (epoch 10.223), train_loss = 1.18604004, grad/param norm = 1.5615e-01, time/batch = 17.1368s	
6779/33150 (epoch 10.225), train_loss = 1.39598161, grad/param norm = 1.5991e-01, time/batch = 17.2297s	
6780/33150 (epoch 10.226), train_loss = 1.17762825, grad/param norm = 1.4362e-01, time/batch = 19.7186s	
6781/33150 (epoch 10.228), train_loss = 1.20191368, grad/param norm = 1.5289e-01, time/batch = 17.9604s	
6782/33150 (epoch 10.229), train_loss = 1.20258552, grad/param norm = 1.6442e-01, time/batch = 17.9630s	
6783/33150 (epoch 10.231), train_loss = 1.33121285, grad/param norm = 1.7134e-01, time/batch = 18.3033s	
6784/33150 (epoch 10.232), train_loss = 1.26977012, grad/param norm = 1.7766e-01, time/batch = 19.5537s	
6785/33150 (epoch 10.234), train_loss = 1.20142784, grad/param norm = 1.6472e-01, time/batch = 16.9431s	
6786/33150 (epoch 10.235), train_loss = 1.25957511, grad/param norm = 1.6116e-01, time/batch = 18.8782s	
6787/33150 (epoch 10.237), train_loss = 1.19548293, grad/param norm = 1.6387e-01, time/batch = 19.6324s	
6788/33150 (epoch 10.238), train_loss = 1.35140726, grad/param norm = 1.8211e-01, time/batch = 17.1228s	
6789/33150 (epoch 10.240), train_loss = 1.22717147, grad/param norm = 1.5369e-01, time/batch = 17.3895s	
6790/33150 (epoch 10.241), train_loss = 1.37838878, grad/param norm = 1.7441e-01, time/batch = 18.5462s	
6791/33150 (epoch 10.243), train_loss = 1.33849061, grad/param norm = 1.6287e-01, time/batch = 17.2164s	
6792/33150 (epoch 10.244), train_loss = 1.20412027, grad/param norm = 1.4349e-01, time/batch = 16.5469s	
6793/33150 (epoch 10.246), train_loss = 1.27649718, grad/param norm = 1.5808e-01, time/batch = 18.8947s	
6794/33150 (epoch 10.247), train_loss = 1.09589782, grad/param norm = 1.4064e-01, time/batch = 19.6285s	
6795/33150 (epoch 10.249), train_loss = 1.32512842, grad/param norm = 1.5198e-01, time/batch = 15.9818s	
6796/33150 (epoch 10.250), train_loss = 1.26792471, grad/param norm = 1.3576e-01, time/batch = 17.4150s	
6797/33150 (epoch 10.252), train_loss = 1.26314263, grad/param norm = 1.3237e-01, time/batch = 17.1617s	
6798/33150 (epoch 10.253), train_loss = 1.28781818, grad/param norm = 1.5830e-01, time/batch = 16.1368s	
6799/33150 (epoch 10.255), train_loss = 1.21391772, grad/param norm = 1.3855e-01, time/batch = 17.1553s	
6800/33150 (epoch 10.256), train_loss = 1.28469382, grad/param norm = 1.5536e-01, time/batch = 15.8920s	
6801/33150 (epoch 10.258), train_loss = 1.17221149, grad/param norm = 1.5785e-01, time/batch = 19.3193s	
6802/33150 (epoch 10.259), train_loss = 1.05045407, grad/param norm = 1.5646e-01, time/batch = 16.7160s	
6803/33150 (epoch 10.261), train_loss = 1.07886016, grad/param norm = 1.4446e-01, time/batch = 17.4670s	
6804/33150 (epoch 10.262), train_loss = 1.29018931, grad/param norm = 1.6613e-01, time/batch = 19.8759s	
6805/33150 (epoch 10.264), train_loss = 0.98117685, grad/param norm = 1.3380e-01, time/batch = 15.8964s	
6806/33150 (epoch 10.265), train_loss = 1.27516809, grad/param norm = 1.6281e-01, time/batch = 19.7211s	
6807/33150 (epoch 10.267), train_loss = 1.34950007, grad/param norm = 1.7362e-01, time/batch = 18.9737s	
6808/33150 (epoch 10.268), train_loss = 1.22957610, grad/param norm = 1.5427e-01, time/batch = 17.7045s	
6809/33150 (epoch 10.270), train_loss = 1.40702621, grad/param norm = 1.5401e-01, time/batch = 17.8085s	
6810/33150 (epoch 10.271), train_loss = 1.35341885, grad/param norm = 1.6456e-01, time/batch = 19.0649s	
6811/33150 (epoch 10.273), train_loss = 1.35949165, grad/param norm = 1.5611e-01, time/batch = 19.0362s	
6812/33150 (epoch 10.275), train_loss = 1.33524932, grad/param norm = 1.5709e-01, time/batch = 18.6362s	
6813/33150 (epoch 10.276), train_loss = 1.19458047, grad/param norm = 1.4374e-01, time/batch = 17.5432s	
6814/33150 (epoch 10.278), train_loss = 1.28253694, grad/param norm = 1.4930e-01, time/batch = 19.8109s	
6815/33150 (epoch 10.279), train_loss = 1.20703139, grad/param norm = 1.4291e-01, time/batch = 16.8664s	
6816/33150 (epoch 10.281), train_loss = 1.28711347, grad/param norm = 1.5214e-01, time/batch = 20.0472s	
6817/33150 (epoch 10.282), train_loss = 1.22466257, grad/param norm = 1.4106e-01, time/batch = 18.4798s	
6818/33150 (epoch 10.284), train_loss = 1.16599116, grad/param norm = 1.4586e-01, time/batch = 16.8994s	
6819/33150 (epoch 10.285), train_loss = 1.27443847, grad/param norm = 1.5227e-01, time/batch = 17.4013s	
6820/33150 (epoch 10.287), train_loss = 1.15427277, grad/param norm = 1.5074e-01, time/batch = 18.4871s	
6821/33150 (epoch 10.288), train_loss = 1.40056710, grad/param norm = 1.7055e-01, time/batch = 17.7260s	
6822/33150 (epoch 10.290), train_loss = 1.07760780, grad/param norm = 1.5035e-01, time/batch = 16.9668s	
6823/33150 (epoch 10.291), train_loss = 1.06871878, grad/param norm = 1.4628e-01, time/batch = 18.8846s	
6824/33150 (epoch 10.293), train_loss = 1.31498402, grad/param norm = 1.6153e-01, time/batch = 19.0540s	
6825/33150 (epoch 10.294), train_loss = 0.95315833, grad/param norm = 1.5029e-01, time/batch = 16.6370s	
6826/33150 (epoch 10.296), train_loss = 1.18067711, grad/param norm = 1.4528e-01, time/batch = 17.7378s	
6827/33150 (epoch 10.297), train_loss = 1.14450689, grad/param norm = 1.5464e-01, time/batch = 17.7282s	
6828/33150 (epoch 10.299), train_loss = 1.14532213, grad/param norm = 1.5141e-01, time/batch = 16.0572s	
6829/33150 (epoch 10.300), train_loss = 1.17379679, grad/param norm = 1.4176e-01, time/batch = 17.4528s	
6830/33150 (epoch 10.302), train_loss = 1.15407002, grad/param norm = 1.4967e-01, time/batch = 16.5580s	
6831/33150 (epoch 10.303), train_loss = 1.24163256, grad/param norm = 1.5400e-01, time/batch = 17.2021s	
6832/33150 (epoch 10.305), train_loss = 1.26018982, grad/param norm = 1.4859e-01, time/batch = 15.1703s	
6833/33150 (epoch 10.306), train_loss = 1.28613339, grad/param norm = 1.6972e-01, time/batch = 14.9075s	
6834/33150 (epoch 10.308), train_loss = 1.45125892, grad/param norm = 1.5954e-01, time/batch = 15.2927s	
6835/33150 (epoch 10.309), train_loss = 1.05300443, grad/param norm = 1.3585e-01, time/batch = 15.5406s	
6836/33150 (epoch 10.311), train_loss = 1.19832688, grad/param norm = 1.5578e-01, time/batch = 15.2379s	
6837/33150 (epoch 10.312), train_loss = 1.00889109, grad/param norm = 1.4827e-01, time/batch = 15.9466s	
6838/33150 (epoch 10.314), train_loss = 1.22341627, grad/param norm = 1.5527e-01, time/batch = 18.1368s	
6839/33150 (epoch 10.315), train_loss = 1.30872379, grad/param norm = 1.6204e-01, time/batch = 16.3778s	
6840/33150 (epoch 10.317), train_loss = 0.96560220, grad/param norm = 1.2186e-01, time/batch = 16.8893s	
6841/33150 (epoch 10.318), train_loss = 1.08565334, grad/param norm = 1.4025e-01, time/batch = 17.5747s	
6842/33150 (epoch 10.320), train_loss = 1.05130938, grad/param norm = 1.3906e-01, time/batch = 17.0656s	
6843/33150 (epoch 10.321), train_loss = 1.14114484, grad/param norm = 1.4050e-01, time/batch = 15.9562s	
6844/33150 (epoch 10.323), train_loss = 1.20955058, grad/param norm = 1.5263e-01, time/batch = 16.6489s	
6845/33150 (epoch 10.324), train_loss = 1.29784294, grad/param norm = 1.7194e-01, time/batch = 15.4637s	
6846/33150 (epoch 10.326), train_loss = 1.21669086, grad/param norm = 1.3842e-01, time/batch = 15.7900s	
6847/33150 (epoch 10.327), train_loss = 1.32424565, grad/param norm = 1.4491e-01, time/batch = 15.4737s	
6848/33150 (epoch 10.329), train_loss = 1.27638159, grad/param norm = 1.5354e-01, time/batch = 16.9788s	
6849/33150 (epoch 10.330), train_loss = 1.24592091, grad/param norm = 1.7680e-01, time/batch = 16.4753s	
6850/33150 (epoch 10.332), train_loss = 1.19717480, grad/param norm = 1.3202e-01, time/batch = 16.3019s	
6851/33150 (epoch 10.333), train_loss = 1.25646331, grad/param norm = 1.3935e-01, time/batch = 16.2183s	
6852/33150 (epoch 10.335), train_loss = 1.16720979, grad/param norm = 1.4575e-01, time/batch = 15.0632s	
6853/33150 (epoch 10.336), train_loss = 1.13243216, grad/param norm = 1.5239e-01, time/batch = 17.7249s	
6854/33150 (epoch 10.338), train_loss = 0.99062934, grad/param norm = 1.4698e-01, time/batch = 16.1310s	
6855/33150 (epoch 10.339), train_loss = 1.32490129, grad/param norm = 1.5673e-01, time/batch = 17.5573s	
6856/33150 (epoch 10.341), train_loss = 1.37857127, grad/param norm = 1.7864e-01, time/batch = 17.2957s	
6857/33150 (epoch 10.342), train_loss = 1.06161452, grad/param norm = 1.5024e-01, time/batch = 16.5449s	
6858/33150 (epoch 10.344), train_loss = 1.27461000, grad/param norm = 1.6653e-01, time/batch = 17.7218s	
6859/33150 (epoch 10.345), train_loss = 1.13683648, grad/param norm = 1.5304e-01, time/batch = 17.0446s	
6860/33150 (epoch 10.347), train_loss = 0.96518033, grad/param norm = 1.3491e-01, time/batch = 15.3598s	
6861/33150 (epoch 10.348), train_loss = 1.22209926, grad/param norm = 1.5118e-01, time/batch = 15.6169s	
6862/33150 (epoch 10.350), train_loss = 1.17496140, grad/param norm = 1.7938e-01, time/batch = 18.2022s	
6863/33150 (epoch 10.351), train_loss = 1.30384736, grad/param norm = 1.5950e-01, time/batch = 15.4879s	
6864/33150 (epoch 10.353), train_loss = 1.33941063, grad/param norm = 1.7888e-01, time/batch = 16.3818s	
6865/33150 (epoch 10.354), train_loss = 1.49486617, grad/param norm = 1.6434e-01, time/batch = 15.3037s	
6866/33150 (epoch 10.356), train_loss = 1.31590441, grad/param norm = 1.7078e-01, time/batch = 17.5736s	
6867/33150 (epoch 10.357), train_loss = 1.32382994, grad/param norm = 1.6520e-01, time/batch = 16.9720s	
6868/33150 (epoch 10.359), train_loss = 1.26702000, grad/param norm = 1.5489e-01, time/batch = 17.7240s	
6869/33150 (epoch 10.360), train_loss = 1.32800956, grad/param norm = 1.7411e-01, time/batch = 15.9568s	
6870/33150 (epoch 10.362), train_loss = 1.31831688, grad/param norm = 1.5691e-01, time/batch = 17.0383s	
6871/33150 (epoch 10.363), train_loss = 1.20481944, grad/param norm = 1.4836e-01, time/batch = 16.9616s	
6872/33150 (epoch 10.365), train_loss = 1.19559931, grad/param norm = 1.3883e-01, time/batch = 17.5594s	
6873/33150 (epoch 10.367), train_loss = 1.11192591, grad/param norm = 1.5378e-01, time/batch = 18.1333s	
6874/33150 (epoch 10.368), train_loss = 1.21119057, grad/param norm = 1.5141e-01, time/batch = 18.7970s	
6875/33150 (epoch 10.370), train_loss = 1.26192667, grad/param norm = 1.6753e-01, time/batch = 15.4349s	
6876/33150 (epoch 10.371), train_loss = 1.09798038, grad/param norm = 1.4378e-01, time/batch = 15.4319s	
6877/33150 (epoch 10.373), train_loss = 1.29401759, grad/param norm = 1.7503e-01, time/batch = 19.8697s	
6878/33150 (epoch 10.374), train_loss = 1.19388015, grad/param norm = 1.5084e-01, time/batch = 17.4607s	
6879/33150 (epoch 10.376), train_loss = 1.35784583, grad/param norm = 1.5375e-01, time/batch = 17.4813s	
6880/33150 (epoch 10.377), train_loss = 1.20360627, grad/param norm = 1.7075e-01, time/batch = 18.5602s	
6881/33150 (epoch 10.379), train_loss = 1.30523094, grad/param norm = 1.6895e-01, time/batch = 18.0634s	
6882/33150 (epoch 10.380), train_loss = 1.30734798, grad/param norm = 1.4844e-01, time/batch = 16.8015s	
6883/33150 (epoch 10.382), train_loss = 1.12152516, grad/param norm = 1.4492e-01, time/batch = 17.0626s	
6884/33150 (epoch 10.383), train_loss = 1.10701441, grad/param norm = 1.4939e-01, time/batch = 18.4795s	
6885/33150 (epoch 10.385), train_loss = 1.23744560, grad/param norm = 1.5987e-01, time/batch = 15.4691s	
6886/33150 (epoch 10.386), train_loss = 1.07328350, grad/param norm = 1.4076e-01, time/batch = 17.4646s	
6887/33150 (epoch 10.388), train_loss = 1.20351567, grad/param norm = 1.5217e-01, time/batch = 18.9461s	
6888/33150 (epoch 10.389), train_loss = 1.17579125, grad/param norm = 1.5282e-01, time/batch = 18.1397s	
6889/33150 (epoch 10.391), train_loss = 1.38709469, grad/param norm = 1.5132e-01, time/batch = 17.3161s	
6890/33150 (epoch 10.392), train_loss = 1.16135934, grad/param norm = 1.4018e-01, time/batch = 19.7147s	
6891/33150 (epoch 10.394), train_loss = 1.05993236, grad/param norm = 1.2147e-01, time/batch = 16.6282s	
6892/33150 (epoch 10.395), train_loss = 1.09755195, grad/param norm = 1.5357e-01, time/batch = 17.3824s	
6893/33150 (epoch 10.397), train_loss = 0.91477415, grad/param norm = 1.2603e-01, time/batch = 18.4677s	
6894/33150 (epoch 10.398), train_loss = 1.21671753, grad/param norm = 1.6435e-01, time/batch = 18.5557s	
6895/33150 (epoch 10.400), train_loss = 1.16252243, grad/param norm = 1.4150e-01, time/batch = 16.8800s	
6896/33150 (epoch 10.401), train_loss = 1.03018998, grad/param norm = 1.3438e-01, time/batch = 19.0536s	
6897/33150 (epoch 10.403), train_loss = 1.09577827, grad/param norm = 1.3762e-01, time/batch = 16.9574s	
6898/33150 (epoch 10.404), train_loss = 1.16767387, grad/param norm = 1.4795e-01, time/batch = 18.0567s	
6899/33150 (epoch 10.406), train_loss = 1.08270515, grad/param norm = 1.1631e-01, time/batch = 16.3143s	
6900/33150 (epoch 10.407), train_loss = 1.07970981, grad/param norm = 1.3766e-01, time/batch = 18.8933s	
6901/33150 (epoch 10.409), train_loss = 1.00364197, grad/param norm = 1.4200e-01, time/batch = 18.6395s	
6902/33150 (epoch 10.410), train_loss = 1.26144458, grad/param norm = 1.6231e-01, time/batch = 17.0589s	
6903/33150 (epoch 10.412), train_loss = 1.25874057, grad/param norm = 1.4937e-01, time/batch = 18.7832s	
6904/33150 (epoch 10.413), train_loss = 1.14391803, grad/param norm = 1.5724e-01, time/batch = 16.3202s	
6905/33150 (epoch 10.415), train_loss = 1.32254885, grad/param norm = 1.5376e-01, time/batch = 17.3106s	
6906/33150 (epoch 10.416), train_loss = 1.12864048, grad/param norm = 1.4159e-01, time/batch = 17.4758s	
6907/33150 (epoch 10.418), train_loss = 1.41255727, grad/param norm = 1.9952e-01, time/batch = 18.2216s	
6908/33150 (epoch 10.419), train_loss = 1.11822939, grad/param norm = 1.6328e-01, time/batch = 17.5659s	
6909/33150 (epoch 10.421), train_loss = 1.23731508, grad/param norm = 1.5501e-01, time/batch = 16.0540s	
6910/33150 (epoch 10.422), train_loss = 1.14615647, grad/param norm = 1.4318e-01, time/batch = 18.2909s	
6911/33150 (epoch 10.424), train_loss = 1.14758767, grad/param norm = 1.5483e-01, time/batch = 16.9819s	
6912/33150 (epoch 10.425), train_loss = 1.17121830, grad/param norm = 1.4086e-01, time/batch = 16.0626s	
6913/33150 (epoch 10.427), train_loss = 1.14799362, grad/param norm = 1.4907e-01, time/batch = 18.4824s	
6914/33150 (epoch 10.428), train_loss = 1.20515616, grad/param norm = 1.5505e-01, time/batch = 18.4564s	
6915/33150 (epoch 10.430), train_loss = 1.25054442, grad/param norm = 1.5804e-01, time/batch = 18.5453s	
6916/33150 (epoch 10.431), train_loss = 1.30326598, grad/param norm = 1.6712e-01, time/batch = 17.4791s	
6917/33150 (epoch 10.433), train_loss = 1.17851653, grad/param norm = 1.3956e-01, time/batch = 16.8020s	
6918/33150 (epoch 10.434), train_loss = 1.07881264, grad/param norm = 1.5377e-01, time/batch = 19.8098s	
6919/33150 (epoch 10.436), train_loss = 1.03888778, grad/param norm = 1.4953e-01, time/batch = 16.9742s	
6920/33150 (epoch 10.437), train_loss = 1.21457924, grad/param norm = 1.7920e-01, time/batch = 18.9716s	
6921/33150 (epoch 10.439), train_loss = 1.33040909, grad/param norm = 1.6977e-01, time/batch = 17.8840s	
6922/33150 (epoch 10.440), train_loss = 1.33365349, grad/param norm = 1.6180e-01, time/batch = 16.2217s	
6923/33150 (epoch 10.442), train_loss = 1.06777617, grad/param norm = 1.4586e-01, time/batch = 17.3106s	
6924/33150 (epoch 10.443), train_loss = 1.32690553, grad/param norm = 1.6151e-01, time/batch = 18.3927s	
6925/33150 (epoch 10.445), train_loss = 1.21870271, grad/param norm = 1.6274e-01, time/batch = 17.3151s	
6926/33150 (epoch 10.446), train_loss = 1.24711516, grad/param norm = 1.8115e-01, time/batch = 16.8058s	
6927/33150 (epoch 10.448), train_loss = 1.29241734, grad/param norm = 1.6496e-01, time/batch = 19.5376s	
6928/33150 (epoch 10.449), train_loss = 1.19792067, grad/param norm = 1.4911e-01, time/batch = 18.4707s	
6929/33150 (epoch 10.451), train_loss = 1.28052398, grad/param norm = 1.6800e-01, time/batch = 15.6568s	
6930/33150 (epoch 10.452), train_loss = 1.47263625, grad/param norm = 1.6066e-01, time/batch = 18.6256s	
6931/33150 (epoch 10.454), train_loss = 1.18269069, grad/param norm = 1.5300e-01, time/batch = 18.3926s	
6932/33150 (epoch 10.456), train_loss = 1.00067517, grad/param norm = 1.3789e-01, time/batch = 24.3060s	
6933/33150 (epoch 10.457), train_loss = 1.21730334, grad/param norm = 1.5622e-01, time/batch = 25.7440s	
6934/33150 (epoch 10.459), train_loss = 1.39336572, grad/param norm = 1.9847e-01, time/batch = 19.3160s	
6935/33150 (epoch 10.460), train_loss = 1.25063398, grad/param norm = 1.4546e-01, time/batch = 16.5423s	
6936/33150 (epoch 10.462), train_loss = 1.33893820, grad/param norm = 1.7982e-01, time/batch = 19.2191s	
6937/33150 (epoch 10.463), train_loss = 1.54550990, grad/param norm = 1.9915e-01, time/batch = 16.5365s	
6938/33150 (epoch 10.465), train_loss = 1.13797245, grad/param norm = 1.4227e-01, time/batch = 16.9653s	
6939/33150 (epoch 10.466), train_loss = 1.14535806, grad/param norm = 1.4737e-01, time/batch = 19.7071s	
6940/33150 (epoch 10.468), train_loss = 1.53563883, grad/param norm = 1.6724e-01, time/batch = 18.2209s	
6941/33150 (epoch 10.469), train_loss = 1.24970603, grad/param norm = 1.6446e-01, time/batch = 17.9743s	
6942/33150 (epoch 10.471), train_loss = 1.16885325, grad/param norm = 1.4367e-01, time/batch = 18.2201s	
6943/33150 (epoch 10.472), train_loss = 1.18639978, grad/param norm = 1.4402e-01, time/batch = 16.5479s	
6944/33150 (epoch 10.474), train_loss = 1.35189599, grad/param norm = 1.8152e-01, time/batch = 18.7279s	
6945/33150 (epoch 10.475), train_loss = 1.49971476, grad/param norm = 1.6682e-01, time/batch = 16.9607s	
6946/33150 (epoch 10.477), train_loss = 1.28334784, grad/param norm = 1.6246e-01, time/batch = 19.8908s	
6947/33150 (epoch 10.478), train_loss = 1.35009349, grad/param norm = 1.4647e-01, time/batch = 17.8955s	
6948/33150 (epoch 10.480), train_loss = 1.15194231, grad/param norm = 1.4580e-01, time/batch = 16.5659s	
6949/33150 (epoch 10.481), train_loss = 1.05116238, grad/param norm = 1.4423e-01, time/batch = 18.6416s	
6950/33150 (epoch 10.483), train_loss = 1.16950650, grad/param norm = 1.5699e-01, time/batch = 17.2322s	
6951/33150 (epoch 10.484), train_loss = 1.15135678, grad/param norm = 1.5417e-01, time/batch = 18.2232s	
6952/33150 (epoch 10.486), train_loss = 1.19074164, grad/param norm = 1.6385e-01, time/batch = 17.8869s	
6953/33150 (epoch 10.487), train_loss = 1.28149926, grad/param norm = 1.6162e-01, time/batch = 19.1374s	
6954/33150 (epoch 10.489), train_loss = 1.23297370, grad/param norm = 1.5716e-01, time/batch = 19.1018s	
6955/33150 (epoch 10.490), train_loss = 1.05873321, grad/param norm = 1.3421e-01, time/batch = 17.3853s	
6956/33150 (epoch 10.492), train_loss = 1.16140814, grad/param norm = 1.6605e-01, time/batch = 18.0398s	
6957/33150 (epoch 10.493), train_loss = 1.31170890, grad/param norm = 1.6409e-01, time/batch = 15.1821s	
6958/33150 (epoch 10.495), train_loss = 1.32129178, grad/param norm = 1.5984e-01, time/batch = 17.4722s	
6959/33150 (epoch 10.496), train_loss = 1.13952533, grad/param norm = 1.5972e-01, time/batch = 16.4147s	
6960/33150 (epoch 10.498), train_loss = 1.32800239, grad/param norm = 1.8261e-01, time/batch = 20.2266s	
6961/33150 (epoch 10.499), train_loss = 1.41508802, grad/param norm = 1.7430e-01, time/batch = 18.2133s	
6962/33150 (epoch 10.501), train_loss = 1.27392391, grad/param norm = 1.5009e-01, time/batch = 15.9838s	
6963/33150 (epoch 10.502), train_loss = 1.39606915, grad/param norm = 1.6813e-01, time/batch = 17.8193s	
6964/33150 (epoch 10.504), train_loss = 1.29969918, grad/param norm = 1.6473e-01, time/batch = 19.2225s	
6965/33150 (epoch 10.505), train_loss = 1.46255787, grad/param norm = 1.8147e-01, time/batch = 15.8844s	
6966/33150 (epoch 10.507), train_loss = 1.16724023, grad/param norm = 1.5206e-01, time/batch = 17.9627s	
6967/33150 (epoch 10.508), train_loss = 1.14389687, grad/param norm = 1.5205e-01, time/batch = 16.9853s	
6968/33150 (epoch 10.510), train_loss = 1.21994449, grad/param norm = 1.5728e-01, time/batch = 18.5437s	
6969/33150 (epoch 10.511), train_loss = 1.44447517, grad/param norm = 1.7485e-01, time/batch = 19.4700s	
6970/33150 (epoch 10.513), train_loss = 1.26957649, grad/param norm = 1.7871e-01, time/batch = 18.9601s	
6971/33150 (epoch 10.514), train_loss = 1.03092421, grad/param norm = 1.5309e-01, time/batch = 17.1287s	
6972/33150 (epoch 10.516), train_loss = 1.35772581, grad/param norm = 1.9513e-01, time/batch = 18.5467s	
6973/33150 (epoch 10.517), train_loss = 1.35587989, grad/param norm = 1.5317e-01, time/batch = 17.3120s	
6974/33150 (epoch 10.519), train_loss = 1.14216398, grad/param norm = 1.4541e-01, time/batch = 18.2345s	
6975/33150 (epoch 10.520), train_loss = 1.24801559, grad/param norm = 1.4393e-01, time/batch = 17.3833s	
6976/33150 (epoch 10.522), train_loss = 1.42236907, grad/param norm = 2.0909e-01, time/batch = 17.0618s	
6977/33150 (epoch 10.523), train_loss = 1.11297150, grad/param norm = 1.6009e-01, time/batch = 18.3222s	
6978/33150 (epoch 10.525), train_loss = 1.25149003, grad/param norm = 1.5584e-01, time/batch = 17.7282s	
6979/33150 (epoch 10.526), train_loss = 1.13377183, grad/param norm = 1.4624e-01, time/batch = 17.4033s	
6980/33150 (epoch 10.528), train_loss = 1.28615056, grad/param norm = 1.6325e-01, time/batch = 18.7400s	
6981/33150 (epoch 10.529), train_loss = 1.28740637, grad/param norm = 1.5227e-01, time/batch = 17.2161s	
6982/33150 (epoch 10.531), train_loss = 1.06991941, grad/param norm = 1.6294e-01, time/batch = 16.2977s	
6983/33150 (epoch 10.532), train_loss = 1.25629934, grad/param norm = 1.5201e-01, time/batch = 15.2045s	
6984/33150 (epoch 10.534), train_loss = 1.15593072, grad/param norm = 1.3660e-01, time/batch = 15.4634s	
6985/33150 (epoch 10.535), train_loss = 1.13029705, grad/param norm = 1.6025e-01, time/batch = 15.1983s	
6986/33150 (epoch 10.537), train_loss = 1.35762903, grad/param norm = 1.6885e-01, time/batch = 15.3580s	
6987/33150 (epoch 10.538), train_loss = 1.19563139, grad/param norm = 1.7384e-01, time/batch = 15.6240s	
6988/33150 (epoch 10.540), train_loss = 1.05377083, grad/param norm = 1.4187e-01, time/batch = 16.7741s	
6989/33150 (epoch 10.541), train_loss = 1.29579211, grad/param norm = 1.6468e-01, time/batch = 16.4602s	
6990/33150 (epoch 10.543), train_loss = 1.28727484, grad/param norm = 1.5408e-01, time/batch = 16.7197s	
6991/33150 (epoch 10.544), train_loss = 1.23258934, grad/param norm = 1.4619e-01, time/batch = 17.6256s	
6992/33150 (epoch 10.546), train_loss = 1.40166527, grad/param norm = 1.7050e-01, time/batch = 17.5367s	
6993/33150 (epoch 10.548), train_loss = 1.27135633, grad/param norm = 1.5789e-01, time/batch = 17.7161s	
6994/33150 (epoch 10.549), train_loss = 1.21522289, grad/param norm = 1.5052e-01, time/batch = 17.5376s	
6995/33150 (epoch 10.551), train_loss = 1.13569509, grad/param norm = 1.6204e-01, time/batch = 17.5612s	
6996/33150 (epoch 10.552), train_loss = 1.01944852, grad/param norm = 1.2877e-01, time/batch = 15.7252s	
6997/33150 (epoch 10.554), train_loss = 1.25716923, grad/param norm = 1.4990e-01, time/batch = 17.2903s	
6998/33150 (epoch 10.555), train_loss = 1.42715650, grad/param norm = 1.7245e-01, time/batch = 17.0410s	
6999/33150 (epoch 10.557), train_loss = 1.05660993, grad/param norm = 1.5264e-01, time/batch = 16.6130s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch10.56_1.5494.t7	
7000/33150 (epoch 10.558), train_loss = 1.30967615, grad/param norm = 1.6730e-01, time/batch = 16.6987s	
7001/33150 (epoch 10.560), train_loss = 1.52382692, grad/param norm = 2.0458e-01, time/batch = 15.6117s	
7002/33150 (epoch 10.561), train_loss = 1.02964542, grad/param norm = 1.4732e-01, time/batch = 14.9791s	
7003/33150 (epoch 10.563), train_loss = 1.34489620, grad/param norm = 2.0453e-01, time/batch = 16.1524s	
7004/33150 (epoch 10.564), train_loss = 1.41375333, grad/param norm = 1.5597e-01, time/batch = 16.7290s	
7005/33150 (epoch 10.566), train_loss = 1.23655478, grad/param norm = 1.6166e-01, time/batch = 15.5981s	
7006/33150 (epoch 10.567), train_loss = 1.10117453, grad/param norm = 1.4243e-01, time/batch = 15.4366s	
7007/33150 (epoch 10.569), train_loss = 1.22093185, grad/param norm = 1.5948e-01, time/batch = 17.1189s	
7008/33150 (epoch 10.570), train_loss = 1.26255172, grad/param norm = 1.5390e-01, time/batch = 18.3820s	
7009/33150 (epoch 10.572), train_loss = 1.11258565, grad/param norm = 1.5511e-01, time/batch = 18.3761s	
7010/33150 (epoch 10.573), train_loss = 0.98824509, grad/param norm = 1.3202e-01, time/batch = 16.6445s	
7011/33150 (epoch 10.575), train_loss = 1.22580046, grad/param norm = 1.5662e-01, time/batch = 18.0754s	
7012/33150 (epoch 10.576), train_loss = 1.02103379, grad/param norm = 1.2733e-01, time/batch = 20.3084s	
7013/33150 (epoch 10.578), train_loss = 1.16621210, grad/param norm = 1.3448e-01, time/batch = 17.2205s	
7014/33150 (epoch 10.579), train_loss = 1.06708242, grad/param norm = 1.4276e-01, time/batch = 19.0609s	
7015/33150 (epoch 10.581), train_loss = 1.11425354, grad/param norm = 1.5132e-01, time/batch = 18.3082s	
7016/33150 (epoch 10.582), train_loss = 1.25837461, grad/param norm = 1.4488e-01, time/batch = 15.5620s	
7017/33150 (epoch 10.584), train_loss = 1.28510670, grad/param norm = 1.4225e-01, time/batch = 19.4604s	
7018/33150 (epoch 10.585), train_loss = 1.22236547, grad/param norm = 1.5350e-01, time/batch = 16.8905s	
7019/33150 (epoch 10.587), train_loss = 1.25909150, grad/param norm = 1.5557e-01, time/batch = 16.9604s	
7020/33150 (epoch 10.588), train_loss = 1.10717678, grad/param norm = 1.5511e-01, time/batch = 16.6586s	
7021/33150 (epoch 10.590), train_loss = 1.21517870, grad/param norm = 1.5571e-01, time/batch = 18.9809s	
7022/33150 (epoch 10.591), train_loss = 1.21218913, grad/param norm = 1.4666e-01, time/batch = 17.3702s	
7023/33150 (epoch 10.593), train_loss = 1.29343260, grad/param norm = 1.6156e-01, time/batch = 16.7973s	
7024/33150 (epoch 10.594), train_loss = 1.24324380, grad/param norm = 1.7478e-01, time/batch = 19.3822s	
7025/33150 (epoch 10.596), train_loss = 1.12088792, grad/param norm = 1.5098e-01, time/batch = 17.5449s	
7026/33150 (epoch 10.597), train_loss = 1.11596300, grad/param norm = 1.8208e-01, time/batch = 17.0511s	
7027/33150 (epoch 10.599), train_loss = 1.44077767, grad/param norm = 1.7615e-01, time/batch = 17.2155s	
7028/33150 (epoch 10.600), train_loss = 1.25697906, grad/param norm = 1.8155e-01, time/batch = 17.3961s	
7029/33150 (epoch 10.602), train_loss = 1.13067613, grad/param norm = 1.4004e-01, time/batch = 19.1223s	
7030/33150 (epoch 10.603), train_loss = 1.27289964, grad/param norm = 1.6618e-01, time/batch = 18.7856s	
7031/33150 (epoch 10.605), train_loss = 1.08967627, grad/param norm = 1.4057e-01, time/batch = 17.1237s	
7032/33150 (epoch 10.606), train_loss = 1.23105973, grad/param norm = 1.7717e-01, time/batch = 19.4625s	
7033/33150 (epoch 10.608), train_loss = 1.25282285, grad/param norm = 1.5627e-01, time/batch = 15.9589s	
7034/33150 (epoch 10.609), train_loss = 1.20503419, grad/param norm = 1.6642e-01, time/batch = 18.2182s	
7035/33150 (epoch 10.611), train_loss = 1.03029565, grad/param norm = 1.4233e-01, time/batch = 17.3793s	
7036/33150 (epoch 10.612), train_loss = 1.21531224, grad/param norm = 1.5895e-01, time/batch = 16.7188s	
7037/33150 (epoch 10.614), train_loss = 1.03337092, grad/param norm = 1.3786e-01, time/batch = 17.0573s	
7038/33150 (epoch 10.615), train_loss = 1.07610380, grad/param norm = 1.3998e-01, time/batch = 18.3061s	
7039/33150 (epoch 10.617), train_loss = 1.20533332, grad/param norm = 1.6772e-01, time/batch = 18.4663s	
7040/33150 (epoch 10.618), train_loss = 1.21763922, grad/param norm = 1.5843e-01, time/batch = 16.7926s	
7041/33150 (epoch 10.620), train_loss = 1.15030370, grad/param norm = 1.6330e-01, time/batch = 19.4658s	
7042/33150 (epoch 10.621), train_loss = 1.17315422, grad/param norm = 1.4985e-01, time/batch = 18.2230s	
7043/33150 (epoch 10.623), train_loss = 1.26855046, grad/param norm = 1.6749e-01, time/batch = 16.4647s	
7044/33150 (epoch 10.624), train_loss = 1.13105069, grad/param norm = 1.6730e-01, time/batch = 16.6260s	
7045/33150 (epoch 10.626), train_loss = 1.10422371, grad/param norm = 1.4287e-01, time/batch = 17.2319s	
7046/33150 (epoch 10.627), train_loss = 1.06287000, grad/param norm = 1.5624e-01, time/batch = 17.6299s	
7047/33150 (epoch 10.629), train_loss = 1.03809438, grad/param norm = 1.3403e-01, time/batch = 16.7199s	
7048/33150 (epoch 10.630), train_loss = 1.10667358, grad/param norm = 1.3899e-01, time/batch = 17.3974s	
7049/33150 (epoch 10.632), train_loss = 1.03203491, grad/param norm = 1.5607e-01, time/batch = 17.5678s	
7050/33150 (epoch 10.633), train_loss = 1.06789709, grad/param norm = 1.7078e-01, time/batch = 15.8181s	
7051/33150 (epoch 10.635), train_loss = 1.40912118, grad/param norm = 1.5993e-01, time/batch = 17.7285s	
7052/33150 (epoch 10.637), train_loss = 1.02419580, grad/param norm = 1.5691e-01, time/batch = 19.2221s	
7053/33150 (epoch 10.638), train_loss = 1.13959089, grad/param norm = 1.4181e-01, time/batch = 17.2938s	
7054/33150 (epoch 10.640), train_loss = 1.30939215, grad/param norm = 1.6703e-01, time/batch = 18.7248s	
7055/33150 (epoch 10.641), train_loss = 1.09676085, grad/param norm = 1.5763e-01, time/batch = 17.2176s	
7056/33150 (epoch 10.643), train_loss = 1.13095406, grad/param norm = 1.4454e-01, time/batch = 17.4055s	
7057/33150 (epoch 10.644), train_loss = 1.31590534, grad/param norm = 1.5122e-01, time/batch = 16.5388s	
7058/33150 (epoch 10.646), train_loss = 1.13992627, grad/param norm = 1.4630e-01, time/batch = 18.3048s	
7059/33150 (epoch 10.647), train_loss = 1.49257693, grad/param norm = 1.7674e-01, time/batch = 19.1346s	
7060/33150 (epoch 10.649), train_loss = 1.31731029, grad/param norm = 1.6745e-01, time/batch = 16.7231s	
7061/33150 (epoch 10.650), train_loss = 1.05640283, grad/param norm = 1.4262e-01, time/batch = 16.8275s	
7062/33150 (epoch 10.652), train_loss = 1.30346518, grad/param norm = 1.6345e-01, time/batch = 18.1486s	
7063/33150 (epoch 10.653), train_loss = 1.17359959, grad/param norm = 1.3949e-01, time/batch = 16.6265s	
7064/33150 (epoch 10.655), train_loss = 1.26939650, grad/param norm = 1.7449e-01, time/batch = 17.0691s	
7065/33150 (epoch 10.656), train_loss = 1.19172517, grad/param norm = 1.4553e-01, time/batch = 19.1298s	
7066/33150 (epoch 10.658), train_loss = 1.20144132, grad/param norm = 1.7612e-01, time/batch = 19.0523s	
7067/33150 (epoch 10.659), train_loss = 1.51179638, grad/param norm = 2.8713e-01, time/batch = 16.0602s	
7068/33150 (epoch 10.661), train_loss = 1.17636476, grad/param norm = 1.6269e-01, time/batch = 18.7246s	
7069/33150 (epoch 10.662), train_loss = 1.01080544, grad/param norm = 1.3909e-01, time/batch = 17.8926s	
7070/33150 (epoch 10.664), train_loss = 1.32482559, grad/param norm = 1.6260e-01, time/batch = 17.0592s	
7071/33150 (epoch 10.665), train_loss = 1.26954007, grad/param norm = 1.6956e-01, time/batch = 17.2129s	
7072/33150 (epoch 10.667), train_loss = 1.36817191, grad/param norm = 1.6537e-01, time/batch = 18.7353s	
7073/33150 (epoch 10.668), train_loss = 1.27346095, grad/param norm = 1.4976e-01, time/batch = 16.4842s	
7074/33150 (epoch 10.670), train_loss = 1.14872109, grad/param norm = 1.4748e-01, time/batch = 17.3191s	
7075/33150 (epoch 10.671), train_loss = 1.15015346, grad/param norm = 1.6314e-01, time/batch = 17.4782s	
7076/33150 (epoch 10.673), train_loss = 1.31075081, grad/param norm = 1.3685e-01, time/batch = 18.3894s	
7077/33150 (epoch 10.674), train_loss = 1.19393151, grad/param norm = 1.4546e-01, time/batch = 16.5652s	
7078/33150 (epoch 10.676), train_loss = 1.14329816, grad/param norm = 1.3885e-01, time/batch = 15.9882s	
7079/33150 (epoch 10.677), train_loss = 1.48504810, grad/param norm = 1.6066e-01, time/batch = 18.3081s	
7080/33150 (epoch 10.679), train_loss = 1.10340264, grad/param norm = 1.4220e-01, time/batch = 15.9367s	
7081/33150 (epoch 10.680), train_loss = 1.33477421, grad/param norm = 1.6167e-01, time/batch = 15.6507s	
7082/33150 (epoch 10.682), train_loss = 1.10795170, grad/param norm = 1.3991e-01, time/batch = 17.7427s	
7083/33150 (epoch 10.683), train_loss = 1.00377194, grad/param norm = 1.2910e-01, time/batch = 18.3207s	
7084/33150 (epoch 10.685), train_loss = 1.23172221, grad/param norm = 1.5289e-01, time/batch = 15.3153s	
7085/33150 (epoch 10.686), train_loss = 1.03449806, grad/param norm = 1.5834e-01, time/batch = 16.2227s	
7086/33150 (epoch 10.688), train_loss = 1.14552773, grad/param norm = 1.5841e-01, time/batch = 18.2323s	
7087/33150 (epoch 10.689), train_loss = 1.09005503, grad/param norm = 1.4054e-01, time/batch = 18.2264s	
7088/33150 (epoch 10.691), train_loss = 1.00340010, grad/param norm = 1.3157e-01, time/batch = 16.5618s	
7089/33150 (epoch 10.692), train_loss = 1.10130949, grad/param norm = 1.5052e-01, time/batch = 18.1584s	
7090/33150 (epoch 10.694), train_loss = 0.94860136, grad/param norm = 1.2197e-01, time/batch = 15.9056s	
7091/33150 (epoch 10.695), train_loss = 1.13114926, grad/param norm = 1.4637e-01, time/batch = 16.0734s	
7092/33150 (epoch 10.697), train_loss = 0.99467573, grad/param norm = 1.2161e-01, time/batch = 17.5598s	
7093/33150 (epoch 10.698), train_loss = 1.24423103, grad/param norm = 1.5931e-01, time/batch = 18.9750s	
7094/33150 (epoch 10.700), train_loss = 0.91799457, grad/param norm = 1.3052e-01, time/batch = 18.8752s	
7095/33150 (epoch 10.701), train_loss = 1.08463872, grad/param norm = 1.4977e-01, time/batch = 17.8130s	
7096/33150 (epoch 10.703), train_loss = 1.17248179, grad/param norm = 1.4361e-01, time/batch = 16.6300s	
7097/33150 (epoch 10.704), train_loss = 0.97915432, grad/param norm = 1.3007e-01, time/batch = 17.5680s	
7098/33150 (epoch 10.706), train_loss = 1.13224385, grad/param norm = 1.3297e-01, time/batch = 15.7335s	
7099/33150 (epoch 10.707), train_loss = 1.13763404, grad/param norm = 1.5585e-01, time/batch = 17.4852s	
7100/33150 (epoch 10.709), train_loss = 1.19650265, grad/param norm = 1.3643e-01, time/batch = 16.3178s	
7101/33150 (epoch 10.710), train_loss = 1.25642464, grad/param norm = 1.6145e-01, time/batch = 17.1480s	
7102/33150 (epoch 10.712), train_loss = 1.30113018, grad/param norm = 1.6957e-01, time/batch = 17.0637s	
7103/33150 (epoch 10.713), train_loss = 1.24260280, grad/param norm = 1.5806e-01, time/batch = 16.2120s	
7104/33150 (epoch 10.715), train_loss = 1.13126581, grad/param norm = 1.4155e-01, time/batch = 18.6396s	
7105/33150 (epoch 10.716), train_loss = 1.23105500, grad/param norm = 1.5231e-01, time/batch = 16.3921s	
7106/33150 (epoch 10.718), train_loss = 1.21165205, grad/param norm = 1.4560e-01, time/batch = 18.8831s	
7107/33150 (epoch 10.719), train_loss = 1.30236875, grad/param norm = 1.7069e-01, time/batch = 18.5487s	
7108/33150 (epoch 10.721), train_loss = 1.18602640, grad/param norm = 1.6167e-01, time/batch = 18.5407s	
7109/33150 (epoch 10.722), train_loss = 1.22744695, grad/param norm = 1.4854e-01, time/batch = 19.4722s	
7110/33150 (epoch 10.724), train_loss = 1.14478797, grad/param norm = 1.3843e-01, time/batch = 17.1454s	
7111/33150 (epoch 10.725), train_loss = 1.36348219, grad/param norm = 1.6891e-01, time/batch = 18.8657s	
7112/33150 (epoch 10.727), train_loss = 1.22026699, grad/param norm = 1.6026e-01, time/batch = 17.9724s	
7113/33150 (epoch 10.729), train_loss = 1.20048865, grad/param norm = 1.4600e-01, time/batch = 18.3180s	
7114/33150 (epoch 10.730), train_loss = 1.21040203, grad/param norm = 1.6324e-01, time/batch = 17.3821s	
7115/33150 (epoch 10.732), train_loss = 1.30633362, grad/param norm = 1.6329e-01, time/batch = 15.3970s	
7116/33150 (epoch 10.733), train_loss = 0.97600050, grad/param norm = 1.2001e-01, time/batch = 20.5445s	
7117/33150 (epoch 10.735), train_loss = 1.14837738, grad/param norm = 1.4467e-01, time/batch = 18.4751s	
7118/33150 (epoch 10.736), train_loss = 1.14454748, grad/param norm = 1.6671e-01, time/batch = 18.0364s	
7119/33150 (epoch 10.738), train_loss = 1.24787576, grad/param norm = 1.6430e-01, time/batch = 17.9564s	
7120/33150 (epoch 10.739), train_loss = 1.33948903, grad/param norm = 1.8034e-01, time/batch = 18.0323s	
7121/33150 (epoch 10.741), train_loss = 1.32853489, grad/param norm = 1.7795e-01, time/batch = 18.4467s	
7122/33150 (epoch 10.742), train_loss = 1.12904268, grad/param norm = 1.4494e-01, time/batch = 17.1244s	
7123/33150 (epoch 10.744), train_loss = 1.34190540, grad/param norm = 1.6468e-01, time/batch = 19.9742s	
7124/33150 (epoch 10.745), train_loss = 1.13325575, grad/param norm = 1.3586e-01, time/batch = 18.4668s	
7125/33150 (epoch 10.747), train_loss = 1.02816934, grad/param norm = 1.4935e-01, time/batch = 16.9862s	
7126/33150 (epoch 10.748), train_loss = 1.13024612, grad/param norm = 1.4562e-01, time/batch = 18.5674s	
7127/33150 (epoch 10.750), train_loss = 1.29129778, grad/param norm = 1.6509e-01, time/batch = 18.8859s	
7128/33150 (epoch 10.751), train_loss = 1.20273149, grad/param norm = 1.5274e-01, time/batch = 29.8807s	
7129/33150 (epoch 10.753), train_loss = 1.02333967, grad/param norm = 1.4617e-01, time/batch = 17.9504s	
7130/33150 (epoch 10.754), train_loss = 1.44646029, grad/param norm = 1.8393e-01, time/batch = 16.2748s	
7131/33150 (epoch 10.756), train_loss = 1.25047347, grad/param norm = 1.6750e-01, time/batch = 15.5981s	
7132/33150 (epoch 10.757), train_loss = 1.21959935, grad/param norm = 1.5249e-01, time/batch = 15.3710s	
7133/33150 (epoch 10.759), train_loss = 1.38656031, grad/param norm = 1.7712e-01, time/batch = 15.1987s	
7134/33150 (epoch 10.760), train_loss = 1.26369638, grad/param norm = 1.5922e-01, time/batch = 15.8541s	
7135/33150 (epoch 10.762), train_loss = 1.24036577, grad/param norm = 1.6880e-01, time/batch = 15.0888s	
7136/33150 (epoch 10.763), train_loss = 1.21008793, grad/param norm = 1.4787e-01, time/batch = 16.4825s	
7137/33150 (epoch 10.765), train_loss = 1.15744321, grad/param norm = 1.4750e-01, time/batch = 16.8182s	
7138/33150 (epoch 10.766), train_loss = 1.09230689, grad/param norm = 1.3869e-01, time/batch = 17.7201s	
7139/33150 (epoch 10.768), train_loss = 1.14686206, grad/param norm = 1.5758e-01, time/batch = 16.4777s	
7140/33150 (epoch 10.769), train_loss = 1.22622399, grad/param norm = 1.5287e-01, time/batch = 17.8927s	
7141/33150 (epoch 10.771), train_loss = 1.21279734, grad/param norm = 1.5770e-01, time/batch = 17.6214s	
7142/33150 (epoch 10.772), train_loss = 1.26569835, grad/param norm = 1.6869e-01, time/batch = 16.6497s	
7143/33150 (epoch 10.774), train_loss = 1.38210392, grad/param norm = 1.6685e-01, time/batch = 18.9766s	
7144/33150 (epoch 10.775), train_loss = 1.25632386, grad/param norm = 1.8582e-01, time/batch = 16.6496s	
7145/33150 (epoch 10.777), train_loss = 1.29070384, grad/param norm = 1.6505e-01, time/batch = 15.9824s	
7146/33150 (epoch 10.778), train_loss = 1.20580435, grad/param norm = 1.4118e-01, time/batch = 15.8255s	
7147/33150 (epoch 10.780), train_loss = 1.07809468, grad/param norm = 1.4267e-01, time/batch = 18.4817s	
7148/33150 (epoch 10.781), train_loss = 1.18307511, grad/param norm = 1.4553e-01, time/batch = 16.1317s	
7149/33150 (epoch 10.783), train_loss = 1.20075620, grad/param norm = 1.3807e-01, time/batch = 16.7247s	
7150/33150 (epoch 10.784), train_loss = 1.16267982, grad/param norm = 1.6093e-01, time/batch = 17.7093s	
7151/33150 (epoch 10.786), train_loss = 1.15957146, grad/param norm = 1.4279e-01, time/batch = 17.0476s	
7152/33150 (epoch 10.787), train_loss = 1.15379110, grad/param norm = 1.4501e-01, time/batch = 15.7028s	
7153/33150 (epoch 10.789), train_loss = 1.01778695, grad/param norm = 1.2709e-01, time/batch = 16.8103s	
7154/33150 (epoch 10.790), train_loss = 0.99033478, grad/param norm = 1.2133e-01, time/batch = 16.3066s	
7155/33150 (epoch 10.792), train_loss = 1.26238411, grad/param norm = 1.7652e-01, time/batch = 18.2032s	
7156/33150 (epoch 10.793), train_loss = 1.18828903, grad/param norm = 1.5530e-01, time/batch = 15.7178s	
7157/33150 (epoch 10.795), train_loss = 1.11504696, grad/param norm = 1.6143e-01, time/batch = 16.3985s	
7158/33150 (epoch 10.796), train_loss = 1.09850841, grad/param norm = 1.4875e-01, time/batch = 16.6278s	
7159/33150 (epoch 10.798), train_loss = 1.12975034, grad/param norm = 1.2633e-01, time/batch = 16.4604s	
7160/33150 (epoch 10.799), train_loss = 1.02543409, grad/param norm = 1.5709e-01, time/batch = 16.8032s	
7161/33150 (epoch 10.801), train_loss = 1.19194176, grad/param norm = 1.3958e-01, time/batch = 17.1908s	
7162/33150 (epoch 10.802), train_loss = 1.09444510, grad/param norm = 1.5255e-01, time/batch = 16.4527s	
7163/33150 (epoch 10.804), train_loss = 1.16641500, grad/param norm = 1.5966e-01, time/batch = 15.3914s	
7164/33150 (epoch 10.805), train_loss = 1.16504755, grad/param norm = 1.5554e-01, time/batch = 17.4679s	
7165/33150 (epoch 10.807), train_loss = 1.11912204, grad/param norm = 1.4703e-01, time/batch = 16.7362s	
7166/33150 (epoch 10.808), train_loss = 1.25269227, grad/param norm = 1.5573e-01, time/batch = 18.3087s	
7167/33150 (epoch 10.810), train_loss = 1.15773341, grad/param norm = 1.4750e-01, time/batch = 17.8944s	
7168/33150 (epoch 10.811), train_loss = 1.24762287, grad/param norm = 1.5917e-01, time/batch = 17.5616s	
7169/33150 (epoch 10.813), train_loss = 1.15603917, grad/param norm = 1.4458e-01, time/batch = 18.4046s	
7170/33150 (epoch 10.814), train_loss = 1.19724355, grad/param norm = 1.6716e-01, time/batch = 16.2073s	
7171/33150 (epoch 10.816), train_loss = 1.15939972, grad/param norm = 1.4779e-01, time/batch = 18.9718s	
7172/33150 (epoch 10.817), train_loss = 1.26853777, grad/param norm = 1.5160e-01, time/batch = 17.3111s	
7173/33150 (epoch 10.819), train_loss = 1.15712816, grad/param norm = 1.4680e-01, time/batch = 17.8867s	
7174/33150 (epoch 10.821), train_loss = 1.01370240, grad/param norm = 1.2873e-01, time/batch = 18.2135s	
7175/33150 (epoch 10.822), train_loss = 1.08658546, grad/param norm = 1.4697e-01, time/batch = 19.2123s	
7176/33150 (epoch 10.824), train_loss = 1.14051932, grad/param norm = 1.5903e-01, time/batch = 18.6239s	
7177/33150 (epoch 10.825), train_loss = 1.20096018, grad/param norm = 1.5394e-01, time/batch = 17.6501s	
7178/33150 (epoch 10.827), train_loss = 1.26802797, grad/param norm = 1.7099e-01, time/batch = 16.7342s	
7179/33150 (epoch 10.828), train_loss = 1.07222049, grad/param norm = 1.4935e-01, time/batch = 18.2390s	
7180/33150 (epoch 10.830), train_loss = 1.24215135, grad/param norm = 1.5064e-01, time/batch = 16.5433s	
7181/33150 (epoch 10.831), train_loss = 1.12735768, grad/param norm = 1.5932e-01, time/batch = 15.5702s	
7182/33150 (epoch 10.833), train_loss = 1.07247579, grad/param norm = 1.5141e-01, time/batch = 19.0607s	
7183/33150 (epoch 10.834), train_loss = 1.34812441, grad/param norm = 1.6617e-01, time/batch = 16.9818s	
7184/33150 (epoch 10.836), train_loss = 1.29708802, grad/param norm = 1.6960e-01, time/batch = 17.0602s	
7185/33150 (epoch 10.837), train_loss = 1.18956365, grad/param norm = 1.5865e-01, time/batch = 18.3114s	
7186/33150 (epoch 10.839), train_loss = 1.30808660, grad/param norm = 1.7938e-01, time/batch = 18.6383s	
7187/33150 (epoch 10.840), train_loss = 1.26469205, grad/param norm = 1.5905e-01, time/batch = 16.3770s	
7188/33150 (epoch 10.842), train_loss = 1.37124563, grad/param norm = 1.9100e-01, time/batch = 20.7162s	
7189/33150 (epoch 10.843), train_loss = 1.30039290, grad/param norm = 1.6852e-01, time/batch = 17.6359s	
7190/33150 (epoch 10.845), train_loss = 1.14462673, grad/param norm = 1.5189e-01, time/batch = 18.2941s	
7191/33150 (epoch 10.846), train_loss = 1.43271417, grad/param norm = 1.8342e-01, time/batch = 20.4618s	
7192/33150 (epoch 10.848), train_loss = 1.26712766, grad/param norm = 1.5603e-01, time/batch = 17.5672s	
7193/33150 (epoch 10.849), train_loss = 1.26035817, grad/param norm = 1.6489e-01, time/batch = 17.4618s	
7194/33150 (epoch 10.851), train_loss = 1.31678145, grad/param norm = 1.7226e-01, time/batch = 16.3764s	
7195/33150 (epoch 10.852), train_loss = 1.35018057, grad/param norm = 1.4722e-01, time/batch = 21.1965s	
7196/33150 (epoch 10.854), train_loss = 1.22651269, grad/param norm = 1.5099e-01, time/batch = 17.3750s	
7197/33150 (epoch 10.855), train_loss = 1.01708976, grad/param norm = 1.3457e-01, time/batch = 18.0509s	
7198/33150 (epoch 10.857), train_loss = 1.01348779, grad/param norm = 1.2963e-01, time/batch = 18.2380s	
7199/33150 (epoch 10.858), train_loss = 1.13347600, grad/param norm = 1.4125e-01, time/batch = 17.8178s	
7200/33150 (epoch 10.860), train_loss = 1.06692603, grad/param norm = 1.3558e-01, time/batch = 16.3458s	
7201/33150 (epoch 10.861), train_loss = 1.11171487, grad/param norm = 1.4804e-01, time/batch = 17.8202s	
7202/33150 (epoch 10.863), train_loss = 1.23126775, grad/param norm = 1.3756e-01, time/batch = 18.8049s	
7203/33150 (epoch 10.864), train_loss = 1.30689599, grad/param norm = 1.4524e-01, time/batch = 15.3016s	
7204/33150 (epoch 10.866), train_loss = 1.20910294, grad/param norm = 1.5411e-01, time/batch = 16.5793s	
7205/33150 (epoch 10.867), train_loss = 1.23443235, grad/param norm = 1.4326e-01, time/batch = 18.4048s	
7206/33150 (epoch 10.869), train_loss = 1.27469101, grad/param norm = 1.6283e-01, time/batch = 15.6444s	
7207/33150 (epoch 10.870), train_loss = 1.25929716, grad/param norm = 1.6499e-01, time/batch = 17.0455s	
7208/33150 (epoch 10.872), train_loss = 1.19032922, grad/param norm = 1.6023e-01, time/batch = 18.8212s	
7209/33150 (epoch 10.873), train_loss = 1.00239405, grad/param norm = 1.2773e-01, time/batch = 16.2258s	
7210/33150 (epoch 10.875), train_loss = 1.36766979, grad/param norm = 1.6732e-01, time/batch = 16.6476s	
7211/33150 (epoch 10.876), train_loss = 1.09949108, grad/param norm = 1.5531e-01, time/batch = 18.3095s	
7212/33150 (epoch 10.878), train_loss = 1.06682964, grad/param norm = 1.3581e-01, time/batch = 18.8136s	
7213/33150 (epoch 10.879), train_loss = 1.10412078, grad/param norm = 1.5025e-01, time/batch = 17.9597s	
7214/33150 (epoch 10.881), train_loss = 1.14526815, grad/param norm = 1.5355e-01, time/batch = 18.1422s	
7215/33150 (epoch 10.882), train_loss = 1.04321869, grad/param norm = 1.3563e-01, time/batch = 16.8718s	
7216/33150 (epoch 10.884), train_loss = 1.19188994, grad/param norm = 1.5378e-01, time/batch = 16.6310s	
7217/33150 (epoch 10.885), train_loss = 0.94242967, grad/param norm = 1.4478e-01, time/batch = 16.9040s	
7218/33150 (epoch 10.887), train_loss = 1.38981664, grad/param norm = 1.7359e-01, time/batch = 16.1497s	
7219/33150 (epoch 10.888), train_loss = 1.23364766, grad/param norm = 1.5784e-01, time/batch = 18.3974s	
7220/33150 (epoch 10.890), train_loss = 1.15484350, grad/param norm = 1.5989e-01, time/batch = 15.9893s	
7221/33150 (epoch 10.891), train_loss = 1.10630327, grad/param norm = 1.5303e-01, time/batch = 16.9822s	
7222/33150 (epoch 10.893), train_loss = 1.25553986, grad/param norm = 1.6584e-01, time/batch = 18.4733s	
7223/33150 (epoch 10.894), train_loss = 1.27935601, grad/param norm = 1.7490e-01, time/batch = 16.4846s	
7224/33150 (epoch 10.896), train_loss = 1.14718016, grad/param norm = 1.4600e-01, time/batch = 16.8932s	
7225/33150 (epoch 10.897), train_loss = 1.21354385, grad/param norm = 1.3965e-01, time/batch = 17.0801s	
7226/33150 (epoch 10.899), train_loss = 1.06611892, grad/param norm = 1.6287e-01, time/batch = 18.6419s	
7227/33150 (epoch 10.900), train_loss = 1.47472388, grad/param norm = 1.6436e-01, time/batch = 17.6445s	
7228/33150 (epoch 10.902), train_loss = 1.38335188, grad/param norm = 1.6112e-01, time/batch = 17.5563s	
7229/33150 (epoch 10.903), train_loss = 1.19990088, grad/param norm = 1.4362e-01, time/batch = 20.2862s	
7230/33150 (epoch 10.905), train_loss = 1.21541666, grad/param norm = 1.5035e-01, time/batch = 17.8118s	
7231/33150 (epoch 10.906), train_loss = 1.28753765, grad/param norm = 1.6211e-01, time/batch = 17.9774s	
7232/33150 (epoch 10.908), train_loss = 1.33958539, grad/param norm = 1.5824e-01, time/batch = 18.0575s	
7233/33150 (epoch 10.910), train_loss = 1.27655027, grad/param norm = 1.4522e-01, time/batch = 19.0535s	
7234/33150 (epoch 10.911), train_loss = 1.04345167, grad/param norm = 1.3343e-01, time/batch = 16.6920s	
7235/33150 (epoch 10.913), train_loss = 1.10173175, grad/param norm = 1.4143e-01, time/batch = 17.6577s	
7236/33150 (epoch 10.914), train_loss = 1.28639422, grad/param norm = 1.6837e-01, time/batch = 18.6486s	
7237/33150 (epoch 10.916), train_loss = 1.10339382, grad/param norm = 1.5427e-01, time/batch = 16.2345s	
7238/33150 (epoch 10.917), train_loss = 1.34770696, grad/param norm = 1.8702e-01, time/batch = 17.4805s	
7239/33150 (epoch 10.919), train_loss = 1.38609193, grad/param norm = 1.8685e-01, time/batch = 18.3231s	
7240/33150 (epoch 10.920), train_loss = 1.28475453, grad/param norm = 1.5098e-01, time/batch = 17.5443s	
7241/33150 (epoch 10.922), train_loss = 1.38488594, grad/param norm = 1.6895e-01, time/batch = 17.3255s	
7242/33150 (epoch 10.923), train_loss = 1.19713708, grad/param norm = 1.6333e-01, time/batch = 18.9931s	
7243/33150 (epoch 10.925), train_loss = 1.23871654, grad/param norm = 1.4609e-01, time/batch = 18.4051s	
7244/33150 (epoch 10.926), train_loss = 1.16822389, grad/param norm = 1.4015e-01, time/batch = 16.6499s	
7245/33150 (epoch 10.928), train_loss = 1.17219885, grad/param norm = 1.6048e-01, time/batch = 18.8114s	
7246/33150 (epoch 10.929), train_loss = 1.27087875, grad/param norm = 1.5601e-01, time/batch = 18.5711s	
7247/33150 (epoch 10.931), train_loss = 1.37398528, grad/param norm = 1.8277e-01, time/batch = 16.8913s	
7248/33150 (epoch 10.932), train_loss = 1.20898082, grad/param norm = 1.6954e-01, time/batch = 17.1490s	
7249/33150 (epoch 10.934), train_loss = 1.22416922, grad/param norm = 1.4910e-01, time/batch = 18.9866s	
7250/33150 (epoch 10.935), train_loss = 1.33381421, grad/param norm = 1.6340e-01, time/batch = 17.4061s	
7251/33150 (epoch 10.937), train_loss = 1.35492379, grad/param norm = 1.6395e-01, time/batch = 18.0680s	
7252/33150 (epoch 10.938), train_loss = 1.30251775, grad/param norm = 1.4883e-01, time/batch = 15.5667s	
7253/33150 (epoch 10.940), train_loss = 1.51242760, grad/param norm = 1.6992e-01, time/batch = 18.7932s	
7254/33150 (epoch 10.941), train_loss = 1.18222437, grad/param norm = 1.4466e-01, time/batch = 16.1534s	
7255/33150 (epoch 10.943), train_loss = 1.09743004, grad/param norm = 1.6681e-01, time/batch = 18.4642s	
7256/33150 (epoch 10.944), train_loss = 1.33270224, grad/param norm = 1.6613e-01, time/batch = 19.1447s	
7257/33150 (epoch 10.946), train_loss = 0.99850778, grad/param norm = 1.3363e-01, time/batch = 16.7093s	
7258/33150 (epoch 10.947), train_loss = 1.26355932, grad/param norm = 1.5418e-01, time/batch = 17.9585s	
7259/33150 (epoch 10.949), train_loss = 1.36522034, grad/param norm = 1.5110e-01, time/batch = 17.9057s	
7260/33150 (epoch 10.950), train_loss = 1.26077602, grad/param norm = 1.5638e-01, time/batch = 17.6270s	
7261/33150 (epoch 10.952), train_loss = 1.11634592, grad/param norm = 1.4602e-01, time/batch = 15.6387s	
7262/33150 (epoch 10.953), train_loss = 1.15396997, grad/param norm = 1.4263e-01, time/batch = 20.1319s	
7263/33150 (epoch 10.955), train_loss = 1.07474553, grad/param norm = 1.4193e-01, time/batch = 19.3943s	
7264/33150 (epoch 10.956), train_loss = 1.28498580, grad/param norm = 1.5943e-01, time/batch = 16.7144s	
7265/33150 (epoch 10.958), train_loss = 1.06005210, grad/param norm = 1.4576e-01, time/batch = 17.3761s	
7266/33150 (epoch 10.959), train_loss = 1.10372816, grad/param norm = 1.5444e-01, time/batch = 19.4658s	
7267/33150 (epoch 10.961), train_loss = 1.07953071, grad/param norm = 1.5680e-01, time/batch = 18.1185s	
7268/33150 (epoch 10.962), train_loss = 1.04528360, grad/param norm = 1.4179e-01, time/batch = 17.8044s	
7269/33150 (epoch 10.964), train_loss = 1.22459345, grad/param norm = 1.5962e-01, time/batch = 18.8864s	
7270/33150 (epoch 10.965), train_loss = 1.18622914, grad/param norm = 1.4391e-01, time/batch = 18.6321s	
7271/33150 (epoch 10.967), train_loss = 1.23353891, grad/param norm = 1.6473e-01, time/batch = 16.4101s	
7272/33150 (epoch 10.968), train_loss = 1.01295431, grad/param norm = 1.3183e-01, time/batch = 18.2327s	
7273/33150 (epoch 10.970), train_loss = 1.14137652, grad/param norm = 1.4147e-01, time/batch = 18.6532s	
7274/33150 (epoch 10.971), train_loss = 1.23214773, grad/param norm = 1.6996e-01, time/batch = 15.0697s	
7275/33150 (epoch 10.973), train_loss = 1.40591932, grad/param norm = 1.6456e-01, time/batch = 17.5746s	
7276/33150 (epoch 10.974), train_loss = 1.38123043, grad/param norm = 1.6846e-01, time/batch = 16.4800s	
7277/33150 (epoch 10.976), train_loss = 1.26673085, grad/param norm = 1.4779e-01, time/batch = 15.8818s	
7278/33150 (epoch 10.977), train_loss = 1.34590399, grad/param norm = 1.6374e-01, time/batch = 16.7236s	
7279/33150 (epoch 10.979), train_loss = 1.33854983, grad/param norm = 1.7358e-01, time/batch = 18.3021s	
7280/33150 (epoch 10.980), train_loss = 1.35235549, grad/param norm = 1.5739e-01, time/batch = 18.4846s	
7281/33150 (epoch 10.982), train_loss = 1.20309272, grad/param norm = 1.6842e-01, time/batch = 15.9597s	
7282/33150 (epoch 10.983), train_loss = 1.06006089, grad/param norm = 1.4769e-01, time/batch = 15.3894s	
7283/33150 (epoch 10.985), train_loss = 1.23245419, grad/param norm = 1.3992e-01, time/batch = 15.4453s	
7284/33150 (epoch 10.986), train_loss = 1.05310339, grad/param norm = 1.4251e-01, time/batch = 15.2874s	
7285/33150 (epoch 10.988), train_loss = 1.15365569, grad/param norm = 1.5073e-01, time/batch = 15.2494s	
7286/33150 (epoch 10.989), train_loss = 1.09229701, grad/param norm = 1.5573e-01, time/batch = 15.4817s	
7287/33150 (epoch 10.991), train_loss = 1.30243623, grad/param norm = 1.9195e-01, time/batch = 15.3508s	
7288/33150 (epoch 10.992), train_loss = 1.07172064, grad/param norm = 1.4933e-01, time/batch = 15.6083s	
7289/33150 (epoch 10.994), train_loss = 1.17072846, grad/param norm = 1.5518e-01, time/batch = 16.5218s	
7290/33150 (epoch 10.995), train_loss = 1.12681159, grad/param norm = 1.5334e-01, time/batch = 19.0322s	
7291/33150 (epoch 10.997), train_loss = 1.22595739, grad/param norm = 1.6428e-01, time/batch = 17.8020s	
7292/33150 (epoch 10.998), train_loss = 0.96486000, grad/param norm = 1.4100e-01, time/batch = 17.1174s	
decayed learning rate by a factor 0.97 to 0.0018818	
7293/33150 (epoch 11.000), train_loss = 1.06559814, grad/param norm = 1.5101e-01, time/batch = 17.5180s	
7294/33150 (epoch 11.002), train_loss = 1.51336717, grad/param norm = 1.7543e-01, time/batch = 16.6354s	
7295/33150 (epoch 11.003), train_loss = 1.11936443, grad/param norm = 1.5262e-01, time/batch = 17.1199s	
7296/33150 (epoch 11.005), train_loss = 1.04856393, grad/param norm = 1.4302e-01, time/batch = 16.6946s	
7297/33150 (epoch 11.006), train_loss = 1.03257266, grad/param norm = 1.4553e-01, time/batch = 19.2102s	
7298/33150 (epoch 11.008), train_loss = 1.34837062, grad/param norm = 1.7842e-01, time/batch = 18.4511s	
7299/33150 (epoch 11.009), train_loss = 1.18017893, grad/param norm = 1.4830e-01, time/batch = 15.8675s	
7300/33150 (epoch 11.011), train_loss = 1.36436490, grad/param norm = 1.6878e-01, time/batch = 15.5409s	
7301/33150 (epoch 11.012), train_loss = 1.21051060, grad/param norm = 2.1020e-01, time/batch = 16.8847s	
7302/33150 (epoch 11.014), train_loss = 1.17256406, grad/param norm = 1.5640e-01, time/batch = 17.1385s	
7303/33150 (epoch 11.015), train_loss = 1.14765039, grad/param norm = 1.4888e-01, time/batch = 17.2127s	
7304/33150 (epoch 11.017), train_loss = 1.13025313, grad/param norm = 1.4902e-01, time/batch = 16.9014s	
7305/33150 (epoch 11.018), train_loss = 1.23324658, grad/param norm = 1.5771e-01, time/batch = 16.6312s	
7306/33150 (epoch 11.020), train_loss = 1.25409664, grad/param norm = 1.5818e-01, time/batch = 16.2106s	
7307/33150 (epoch 11.021), train_loss = 1.01757963, grad/param norm = 1.4692e-01, time/batch = 16.5602s	
7308/33150 (epoch 11.023), train_loss = 1.37128053, grad/param norm = 1.4816e-01, time/batch = 18.1245s	
7309/33150 (epoch 11.024), train_loss = 1.23207590, grad/param norm = 1.5367e-01, time/batch = 16.2227s	
7310/33150 (epoch 11.026), train_loss = 0.96107827, grad/param norm = 1.2465e-01, time/batch = 16.2219s	
7311/33150 (epoch 11.027), train_loss = 0.98123900, grad/param norm = 1.3377e-01, time/batch = 19.2855s	
7312/33150 (epoch 11.029), train_loss = 1.10158205, grad/param norm = 1.5056e-01, time/batch = 16.2099s	
7313/33150 (epoch 11.030), train_loss = 1.17892316, grad/param norm = 1.3166e-01, time/batch = 17.4504s	
7314/33150 (epoch 11.032), train_loss = 1.10569980, grad/param norm = 1.6916e-01, time/batch = 17.8568s	
7315/33150 (epoch 11.033), train_loss = 1.13390302, grad/param norm = 1.4230e-01, time/batch = 17.7915s	
7316/33150 (epoch 11.035), train_loss = 1.38498738, grad/param norm = 1.7764e-01, time/batch = 17.8456s	
7317/33150 (epoch 11.036), train_loss = 1.25954953, grad/param norm = 1.6184e-01, time/batch = 17.1236s	
7318/33150 (epoch 11.038), train_loss = 1.50860261, grad/param norm = 1.8041e-01, time/batch = 17.6340s	
7319/33150 (epoch 11.039), train_loss = 1.22284508, grad/param norm = 1.3496e-01, time/batch = 18.6288s	
7320/33150 (epoch 11.041), train_loss = 1.22794763, grad/param norm = 1.5489e-01, time/batch = 18.0264s	
7321/33150 (epoch 11.042), train_loss = 1.13741747, grad/param norm = 1.4267e-01, time/batch = 17.8640s	
7322/33150 (epoch 11.044), train_loss = 1.13568906, grad/param norm = 1.3937e-01, time/batch = 19.1391s	
7323/33150 (epoch 11.045), train_loss = 1.17519062, grad/param norm = 1.3928e-01, time/batch = 16.8567s	
7324/33150 (epoch 11.047), train_loss = 1.11660681, grad/param norm = 1.5960e-01, time/batch = 17.3762s	
7325/33150 (epoch 11.048), train_loss = 1.34573664, grad/param norm = 1.8460e-01, time/batch = 18.3090s	
7326/33150 (epoch 11.050), train_loss = 1.18579052, grad/param norm = 1.5188e-01, time/batch = 16.0637s	
7327/33150 (epoch 11.051), train_loss = 1.20665893, grad/param norm = 1.5542e-01, time/batch = 16.9763s	
7328/33150 (epoch 11.053), train_loss = 1.14795180, grad/param norm = 1.4720e-01, time/batch = 16.2283s	
7329/33150 (epoch 11.054), train_loss = 1.24190366, grad/param norm = 1.3382e-01, time/batch = 17.7344s	
7330/33150 (epoch 11.056), train_loss = 1.11063075, grad/param norm = 1.3672e-01, time/batch = 16.3952s	
7331/33150 (epoch 11.057), train_loss = 1.19829177, grad/param norm = 1.6839e-01, time/batch = 17.7348s	
7332/33150 (epoch 11.059), train_loss = 1.10347257, grad/param norm = 1.4347e-01, time/batch = 18.2288s	
7333/33150 (epoch 11.060), train_loss = 1.11788956, grad/param norm = 1.3937e-01, time/batch = 19.8546s	
7334/33150 (epoch 11.062), train_loss = 1.16863752, grad/param norm = 1.4635e-01, time/batch = 29.5159s	
7335/33150 (epoch 11.063), train_loss = 1.13008365, grad/param norm = 1.4945e-01, time/batch = 17.6604s	
7336/33150 (epoch 11.065), train_loss = 1.16929160, grad/param norm = 1.3839e-01, time/batch = 16.7429s	
7337/33150 (epoch 11.066), train_loss = 1.10764045, grad/param norm = 1.4374e-01, time/batch = 15.3009s	
7338/33150 (epoch 11.068), train_loss = 1.19162918, grad/param norm = 1.5127e-01, time/batch = 17.5705s	
7339/33150 (epoch 11.069), train_loss = 1.26529249, grad/param norm = 1.6627e-01, time/batch = 17.6399s	
7340/33150 (epoch 11.071), train_loss = 1.24305390, grad/param norm = 1.4459e-01, time/batch = 16.4786s	
7341/33150 (epoch 11.072), train_loss = 1.12156463, grad/param norm = 1.4369e-01, time/batch = 17.9770s	
7342/33150 (epoch 11.074), train_loss = 1.02838748, grad/param norm = 1.4591e-01, time/batch = 16.8878s	
7343/33150 (epoch 11.075), train_loss = 1.11923463, grad/param norm = 1.4871e-01, time/batch = 16.3165s	
7344/33150 (epoch 11.077), train_loss = 1.23955482, grad/param norm = 2.1122e-01, time/batch = 16.9846s	
7345/33150 (epoch 11.078), train_loss = 1.39197882, grad/param norm = 1.8661e-01, time/batch = 18.0600s	
7346/33150 (epoch 11.080), train_loss = 1.29487545, grad/param norm = 1.4641e-01, time/batch = 17.8129s	
7347/33150 (epoch 11.081), train_loss = 1.09557375, grad/param norm = 1.5659e-01, time/batch = 17.3824s	
7348/33150 (epoch 11.083), train_loss = 0.88929299, grad/param norm = 1.6542e-01, time/batch = 18.5595s	
7349/33150 (epoch 11.084), train_loss = 1.04048879, grad/param norm = 1.6183e-01, time/batch = 16.6378s	
7350/33150 (epoch 11.086), train_loss = 1.11897015, grad/param norm = 1.5402e-01, time/batch = 16.7991s	
7351/33150 (epoch 11.087), train_loss = 1.05437619, grad/param norm = 1.4188e-01, time/batch = 16.8971s	
7352/33150 (epoch 11.089), train_loss = 1.08423693, grad/param norm = 1.4905e-01, time/batch = 18.5549s	
7353/33150 (epoch 11.090), train_loss = 1.10575259, grad/param norm = 1.5901e-01, time/batch = 16.7337s	
7354/33150 (epoch 11.092), train_loss = 1.14825742, grad/param norm = 1.5394e-01, time/batch = 17.0772s	
7355/33150 (epoch 11.094), train_loss = 1.27321717, grad/param norm = 1.7823e-01, time/batch = 17.9424s	
7356/33150 (epoch 11.095), train_loss = 1.02117920, grad/param norm = 1.3667e-01, time/batch = 18.7186s	
7357/33150 (epoch 11.097), train_loss = 1.16723468, grad/param norm = 1.5049e-01, time/batch = 16.4600s	
7358/33150 (epoch 11.098), train_loss = 1.42377589, grad/param norm = 1.6333e-01, time/batch = 18.4735s	
7359/33150 (epoch 11.100), train_loss = 1.38499803, grad/param norm = 1.7082e-01, time/batch = 18.5678s	
7360/33150 (epoch 11.101), train_loss = 1.09727064, grad/param norm = 1.7276e-01, time/batch = 15.8067s	
7361/33150 (epoch 11.103), train_loss = 1.22606953, grad/param norm = 1.5964e-01, time/batch = 18.6431s	
7362/33150 (epoch 11.104), train_loss = 1.12976446, grad/param norm = 1.6946e-01, time/batch = 17.5456s	
7363/33150 (epoch 11.106), train_loss = 1.36081571, grad/param norm = 1.7595e-01, time/batch = 16.5599s	
7364/33150 (epoch 11.107), train_loss = 1.44266035, grad/param norm = 2.1407e-01, time/batch = 16.4063s	
7365/33150 (epoch 11.109), train_loss = 1.12119858, grad/param norm = 1.3994e-01, time/batch = 17.8175s	
7366/33150 (epoch 11.110), train_loss = 1.26114498, grad/param norm = 1.6025e-01, time/batch = 17.5660s	
7367/33150 (epoch 11.112), train_loss = 1.10250424, grad/param norm = 1.4873e-01, time/batch = 16.2211s	
7368/33150 (epoch 11.113), train_loss = 1.16744316, grad/param norm = 1.6439e-01, time/batch = 16.8021s	
7369/33150 (epoch 11.115), train_loss = 1.38076351, grad/param norm = 1.7119e-01, time/batch = 16.6492s	
7370/33150 (epoch 11.116), train_loss = 1.08278795, grad/param norm = 1.4877e-01, time/batch = 19.1260s	
7371/33150 (epoch 11.118), train_loss = 1.24401282, grad/param norm = 1.6224e-01, time/batch = 17.7337s	
7372/33150 (epoch 11.119), train_loss = 1.23185827, grad/param norm = 1.6208e-01, time/batch = 18.4821s	
7373/33150 (epoch 11.121), train_loss = 1.13556122, grad/param norm = 1.5506e-01, time/batch = 19.5447s	
7374/33150 (epoch 11.122), train_loss = 1.39318519, grad/param norm = 1.8737e-01, time/batch = 17.2287s	
7375/33150 (epoch 11.124), train_loss = 0.94338582, grad/param norm = 1.2740e-01, time/batch = 18.4783s	
7376/33150 (epoch 11.125), train_loss = 1.28140055, grad/param norm = 1.5805e-01, time/batch = 18.4010s	
7377/33150 (epoch 11.127), train_loss = 1.10671606, grad/param norm = 1.3829e-01, time/batch = 17.1444s	
7378/33150 (epoch 11.128), train_loss = 1.19413252, grad/param norm = 1.5696e-01, time/batch = 18.5653s	
7379/33150 (epoch 11.130), train_loss = 1.21763332, grad/param norm = 1.3723e-01, time/batch = 16.7247s	
7380/33150 (epoch 11.131), train_loss = 1.40956427, grad/param norm = 1.6943e-01, time/batch = 18.2056s	
7381/33150 (epoch 11.133), train_loss = 1.11551224, grad/param norm = 1.6591e-01, time/batch = 18.7105s	
7382/33150 (epoch 11.134), train_loss = 1.31409819, grad/param norm = 1.5957e-01, time/batch = 16.7905s	
7383/33150 (epoch 11.136), train_loss = 1.22217855, grad/param norm = 1.7196e-01, time/batch = 18.8987s	
7384/33150 (epoch 11.137), train_loss = 1.26778356, grad/param norm = 1.5344e-01, time/batch = 16.3939s	
7385/33150 (epoch 11.139), train_loss = 1.25418860, grad/param norm = 1.7545e-01, time/batch = 16.9081s	
7386/33150 (epoch 11.140), train_loss = 1.36187633, grad/param norm = 1.7205e-01, time/batch = 18.6531s	
7387/33150 (epoch 11.142), train_loss = 1.28518597, grad/param norm = 1.8136e-01, time/batch = 17.8044s	
7388/33150 (epoch 11.143), train_loss = 1.21078294, grad/param norm = 1.6273e-01, time/batch = 18.2383s	
7389/33150 (epoch 11.145), train_loss = 1.19157062, grad/param norm = 1.7230e-01, time/batch = 18.4903s	
7390/33150 (epoch 11.146), train_loss = 1.35206811, grad/param norm = 1.9776e-01, time/batch = 17.5355s	
7391/33150 (epoch 11.148), train_loss = 1.27191090, grad/param norm = 1.4990e-01, time/batch = 18.9661s	
7392/33150 (epoch 11.149), train_loss = 1.23143225, grad/param norm = 1.5150e-01, time/batch = 18.0583s	
7393/33150 (epoch 11.151), train_loss = 1.39855885, grad/param norm = 1.6274e-01, time/batch = 18.6476s	
7394/33150 (epoch 11.152), train_loss = 1.16120162, grad/param norm = 1.4810e-01, time/batch = 17.5506s	
7395/33150 (epoch 11.154), train_loss = 1.15843873, grad/param norm = 1.4707e-01, time/batch = 18.4823s	
7396/33150 (epoch 11.155), train_loss = 1.06536498, grad/param norm = 1.4225e-01, time/batch = 17.6199s	
7397/33150 (epoch 11.157), train_loss = 1.12605308, grad/param norm = 1.6803e-01, time/batch = 16.3847s	
7398/33150 (epoch 11.158), train_loss = 1.09930321, grad/param norm = 1.5628e-01, time/batch = 16.6427s	
7399/33150 (epoch 11.160), train_loss = 1.28490443, grad/param norm = 1.5248e-01, time/batch = 17.9055s	
7400/33150 (epoch 11.161), train_loss = 1.15359052, grad/param norm = 1.7146e-01, time/batch = 18.2169s	
7401/33150 (epoch 11.163), train_loss = 1.14365458, grad/param norm = 1.5127e-01, time/batch = 16.5496s	
7402/33150 (epoch 11.164), train_loss = 1.28226193, grad/param norm = 1.5808e-01, time/batch = 18.7303s	
7403/33150 (epoch 11.166), train_loss = 1.16038403, grad/param norm = 1.6130e-01, time/batch = 20.2187s	
7404/33150 (epoch 11.167), train_loss = 1.20479219, grad/param norm = 1.4883e-01, time/batch = 16.8911s	
7405/33150 (epoch 11.169), train_loss = 1.28633992, grad/param norm = 1.9795e-01, time/batch = 18.5439s	
7406/33150 (epoch 11.170), train_loss = 1.13116134, grad/param norm = 1.7564e-01, time/batch = 18.5622s	
7407/33150 (epoch 11.172), train_loss = 1.30896786, grad/param norm = 1.7830e-01, time/batch = 17.0406s	
7408/33150 (epoch 11.173), train_loss = 1.28038865, grad/param norm = 1.8147e-01, time/batch = 18.1377s	
7409/33150 (epoch 11.175), train_loss = 1.10199153, grad/param norm = 1.6221e-01, time/batch = 18.5679s	
7410/33150 (epoch 11.176), train_loss = 1.23532014, grad/param norm = 1.6945e-01, time/batch = 17.0630s	
7411/33150 (epoch 11.178), train_loss = 1.39864341, grad/param norm = 1.6120e-01, time/batch = 18.6329s	
7412/33150 (epoch 11.179), train_loss = 1.25160810, grad/param norm = 1.4904e-01, time/batch = 18.1447s	
7413/33150 (epoch 11.181), train_loss = 1.21362020, grad/param norm = 1.6567e-01, time/batch = 16.2874s	
7414/33150 (epoch 11.183), train_loss = 1.18572856, grad/param norm = 1.6468e-01, time/batch = 18.4577s	
7415/33150 (epoch 11.184), train_loss = 1.39818696, grad/param norm = 1.7783e-01, time/batch = 18.3081s	
7416/33150 (epoch 11.186), train_loss = 1.30404608, grad/param norm = 1.5482e-01, time/batch = 17.9814s	
7417/33150 (epoch 11.187), train_loss = 1.23129510, grad/param norm = 1.6610e-01, time/batch = 17.4680s	
7418/33150 (epoch 11.189), train_loss = 1.01741966, grad/param norm = 1.4668e-01, time/batch = 19.4771s	
7419/33150 (epoch 11.190), train_loss = 1.08917958, grad/param norm = 1.5561e-01, time/batch = 17.9626s	
7420/33150 (epoch 11.192), train_loss = 1.18776830, grad/param norm = 1.8798e-01, time/batch = 16.4520s	
7421/33150 (epoch 11.193), train_loss = 1.24712626, grad/param norm = 1.5740e-01, time/batch = 19.3014s	
7422/33150 (epoch 11.195), train_loss = 1.51732598, grad/param norm = 1.8668e-01, time/batch = 17.8993s	
7423/33150 (epoch 11.196), train_loss = 1.34748783, grad/param norm = 1.5010e-01, time/batch = 19.6299s	
7424/33150 (epoch 11.198), train_loss = 1.03612859, grad/param norm = 1.5860e-01, time/batch = 17.6392s	
7425/33150 (epoch 11.199), train_loss = 1.30179258, grad/param norm = 1.6710e-01, time/batch = 19.9769s	
7426/33150 (epoch 11.201), train_loss = 1.05504490, grad/param norm = 1.2415e-01, time/batch = 17.2147s	
7427/33150 (epoch 11.202), train_loss = 1.01095559, grad/param norm = 1.3452e-01, time/batch = 17.7153s	
7428/33150 (epoch 11.204), train_loss = 1.20114971, grad/param norm = 1.5365e-01, time/batch = 19.3870s	
7429/33150 (epoch 11.205), train_loss = 1.27027895, grad/param norm = 1.6595e-01, time/batch = 16.8064s	
7430/33150 (epoch 11.207), train_loss = 1.22610322, grad/param norm = 1.4623e-01, time/batch = 17.1350s	
7431/33150 (epoch 11.208), train_loss = 1.26386778, grad/param norm = 1.5976e-01, time/batch = 18.0493s	
7432/33150 (epoch 11.210), train_loss = 1.08746463, grad/param norm = 1.3221e-01, time/batch = 19.8048s	
7433/33150 (epoch 11.211), train_loss = 1.24876502, grad/param norm = 1.7039e-01, time/batch = 18.6269s	
7434/33150 (epoch 11.213), train_loss = 1.30595404, grad/param norm = 1.6302e-01, time/batch = 17.3071s	
7435/33150 (epoch 11.214), train_loss = 1.15066542, grad/param norm = 1.5404e-01, time/batch = 16.9630s	
7436/33150 (epoch 11.216), train_loss = 1.13238227, grad/param norm = 1.4708e-01, time/batch = 17.5482s	
7437/33150 (epoch 11.217), train_loss = 1.12086731, grad/param norm = 1.4084e-01, time/batch = 15.4327s	
7438/33150 (epoch 11.219), train_loss = 1.09615705, grad/param norm = 1.5344e-01, time/batch = 15.8549s	
7439/33150 (epoch 11.220), train_loss = 1.12107388, grad/param norm = 1.2994e-01, time/batch = 15.2119s	
7440/33150 (epoch 11.222), train_loss = 1.27752154, grad/param norm = 1.5481e-01, time/batch = 15.2866s	
7441/33150 (epoch 11.223), train_loss = 1.16112698, grad/param norm = 1.4700e-01, time/batch = 15.4493s	
7442/33150 (epoch 11.225), train_loss = 1.35748111, grad/param norm = 1.5968e-01, time/batch = 15.1253s	
7443/33150 (epoch 11.226), train_loss = 1.14646163, grad/param norm = 1.4108e-01, time/batch = 16.7995s	
7444/33150 (epoch 11.228), train_loss = 1.17303470, grad/param norm = 1.5364e-01, time/batch = 16.7803s	
7445/33150 (epoch 11.229), train_loss = 1.15862173, grad/param norm = 1.5214e-01, time/batch = 16.2248s	
7446/33150 (epoch 11.231), train_loss = 1.30548506, grad/param norm = 1.6371e-01, time/batch = 16.1286s	
7447/33150 (epoch 11.232), train_loss = 1.24007389, grad/param norm = 1.7993e-01, time/batch = 17.3909s	
7448/33150 (epoch 11.234), train_loss = 1.18876284, grad/param norm = 1.7110e-01, time/batch = 16.2888s	
7449/33150 (epoch 11.235), train_loss = 1.23462655, grad/param norm = 1.5807e-01, time/batch = 16.8076s	
7450/33150 (epoch 11.237), train_loss = 1.17394157, grad/param norm = 1.8083e-01, time/batch = 16.9601s	
7451/33150 (epoch 11.238), train_loss = 1.30520614, grad/param norm = 1.7712e-01, time/batch = 17.5580s	
7452/33150 (epoch 11.240), train_loss = 1.20987180, grad/param norm = 1.5505e-01, time/batch = 16.4687s	
7453/33150 (epoch 11.241), train_loss = 1.35198849, grad/param norm = 1.6992e-01, time/batch = 18.2236s	
7454/33150 (epoch 11.243), train_loss = 1.29467343, grad/param norm = 1.5828e-01, time/batch = 15.6313s	
7455/33150 (epoch 11.244), train_loss = 1.18039092, grad/param norm = 1.4200e-01, time/batch = 17.9715s	
7456/33150 (epoch 11.246), train_loss = 1.23710208, grad/param norm = 1.5047e-01, time/batch = 18.2964s	
7457/33150 (epoch 11.247), train_loss = 1.06712090, grad/param norm = 1.3833e-01, time/batch = 16.3855s	
7458/33150 (epoch 11.249), train_loss = 1.28855000, grad/param norm = 1.4276e-01, time/batch = 15.9439s	
7459/33150 (epoch 11.250), train_loss = 1.23904003, grad/param norm = 1.3494e-01, time/batch = 17.5198s	
7460/33150 (epoch 11.252), train_loss = 1.23714946, grad/param norm = 1.3004e-01, time/batch = 17.7863s	
7461/33150 (epoch 11.253), train_loss = 1.25897500, grad/param norm = 1.5395e-01, time/batch = 16.5532s	
7462/33150 (epoch 11.255), train_loss = 1.19227720, grad/param norm = 1.3877e-01, time/batch = 16.1219s	
7463/33150 (epoch 11.256), train_loss = 1.25412913, grad/param norm = 1.5365e-01, time/batch = 17.0531s	
7464/33150 (epoch 11.258), train_loss = 1.15102211, grad/param norm = 1.8196e-01, time/batch = 17.3971s	
7465/33150 (epoch 11.259), train_loss = 1.03121915, grad/param norm = 1.4973e-01, time/batch = 16.1066s	
7466/33150 (epoch 11.261), train_loss = 1.05519481, grad/param norm = 1.4261e-01, time/batch = 15.6166s	
7467/33150 (epoch 11.262), train_loss = 1.26095544, grad/param norm = 1.6013e-01, time/batch = 17.2194s	
7468/33150 (epoch 11.264), train_loss = 0.95450438, grad/param norm = 1.3216e-01, time/batch = 17.5206s	
7469/33150 (epoch 11.265), train_loss = 1.25508536, grad/param norm = 1.6226e-01, time/batch = 15.8420s	
7470/33150 (epoch 11.267), train_loss = 1.34027303, grad/param norm = 1.9428e-01, time/batch = 15.7132s	
7471/33150 (epoch 11.268), train_loss = 1.23129121, grad/param norm = 1.5078e-01, time/batch = 15.4185s	
7472/33150 (epoch 11.270), train_loss = 1.37940303, grad/param norm = 1.5536e-01, time/batch = 16.8030s	
7473/33150 (epoch 11.271), train_loss = 1.33231127, grad/param norm = 1.6562e-01, time/batch = 16.0382s	
7474/33150 (epoch 11.273), train_loss = 1.33656927, grad/param norm = 1.5669e-01, time/batch = 15.4543s	
7475/33150 (epoch 11.275), train_loss = 1.31819442, grad/param norm = 1.5831e-01, time/batch = 16.5407s	
7476/33150 (epoch 11.276), train_loss = 1.16520705, grad/param norm = 1.3749e-01, time/batch = 18.0452s	
7477/33150 (epoch 11.278), train_loss = 1.25958154, grad/param norm = 1.4464e-01, time/batch = 16.6331s	
7478/33150 (epoch 11.279), train_loss = 1.17927809, grad/param norm = 1.3908e-01, time/batch = 16.2016s	
7479/33150 (epoch 11.281), train_loss = 1.25513309, grad/param norm = 1.4523e-01, time/batch = 17.3939s	
7480/33150 (epoch 11.282), train_loss = 1.20120248, grad/param norm = 1.3868e-01, time/batch = 15.2186s	
7481/33150 (epoch 11.284), train_loss = 1.14295574, grad/param norm = 1.3924e-01, time/batch = 16.3093s	
7482/33150 (epoch 11.285), train_loss = 1.23954297, grad/param norm = 1.4816e-01, time/batch = 17.2194s	
7483/33150 (epoch 11.287), train_loss = 1.13329320, grad/param norm = 1.4651e-01, time/batch = 17.3008s	
7484/33150 (epoch 11.288), train_loss = 1.37308113, grad/param norm = 1.6501e-01, time/batch = 16.7160s	
7485/33150 (epoch 11.290), train_loss = 1.04802920, grad/param norm = 1.5716e-01, time/batch = 16.0303s	
7486/33150 (epoch 11.291), train_loss = 1.05082399, grad/param norm = 1.6748e-01, time/batch = 16.0395s	
7487/33150 (epoch 11.293), train_loss = 1.28999121, grad/param norm = 1.5992e-01, time/batch = 17.2051s	
7488/33150 (epoch 11.294), train_loss = 0.93545090, grad/param norm = 1.5871e-01, time/batch = 17.2928s	
7489/33150 (epoch 11.296), train_loss = 1.15962758, grad/param norm = 1.4399e-01, time/batch = 17.2162s	
7490/33150 (epoch 11.297), train_loss = 1.11362680, grad/param norm = 1.5132e-01, time/batch = 17.5191s	
7491/33150 (epoch 11.299), train_loss = 1.12543901, grad/param norm = 1.4830e-01, time/batch = 16.7817s	
7492/33150 (epoch 11.300), train_loss = 1.13904736, grad/param norm = 1.3835e-01, time/batch = 18.0377s	
7493/33150 (epoch 11.302), train_loss = 1.12637751, grad/param norm = 1.3995e-01, time/batch = 17.7940s	
7494/33150 (epoch 11.303), train_loss = 1.20435880, grad/param norm = 1.4808e-01, time/batch = 17.1193s	
7495/33150 (epoch 11.305), train_loss = 1.23914330, grad/param norm = 1.4457e-01, time/batch = 16.5414s	
7496/33150 (epoch 11.306), train_loss = 1.24590339, grad/param norm = 1.6225e-01, time/batch = 17.1366s	
7497/33150 (epoch 11.308), train_loss = 1.42983784, grad/param norm = 1.5957e-01, time/batch = 18.8626s	
7498/33150 (epoch 11.309), train_loss = 1.02772820, grad/param norm = 1.3543e-01, time/batch = 16.4437s	
7499/33150 (epoch 11.311), train_loss = 1.16875446, grad/param norm = 1.4699e-01, time/batch = 16.9766s	
7500/33150 (epoch 11.312), train_loss = 0.97055979, grad/param norm = 1.4727e-01, time/batch = 18.4719s	
7501/33150 (epoch 11.314), train_loss = 1.18761715, grad/param norm = 1.4782e-01, time/batch = 16.2843s	
7502/33150 (epoch 11.315), train_loss = 1.27556442, grad/param norm = 1.5546e-01, time/batch = 16.8029s	
7503/33150 (epoch 11.317), train_loss = 0.94277334, grad/param norm = 1.1984e-01, time/batch = 17.0582s	
7504/33150 (epoch 11.318), train_loss = 1.06129302, grad/param norm = 1.3693e-01, time/batch = 18.1078s	
7505/33150 (epoch 11.320), train_loss = 1.02375485, grad/param norm = 1.3676e-01, time/batch = 16.4405s	
7506/33150 (epoch 11.321), train_loss = 1.10948331, grad/param norm = 1.3846e-01, time/batch = 17.3707s	
7507/33150 (epoch 11.323), train_loss = 1.18867890, grad/param norm = 1.5346e-01, time/batch = 15.7981s	
7508/33150 (epoch 11.324), train_loss = 1.26873129, grad/param norm = 1.8585e-01, time/batch = 16.8823s	
7509/33150 (epoch 11.326), train_loss = 1.18503098, grad/param norm = 1.3563e-01, time/batch = 15.2068s	
7510/33150 (epoch 11.327), train_loss = 1.30017357, grad/param norm = 1.4525e-01, time/batch = 16.9572s	
7511/33150 (epoch 11.329), train_loss = 1.24546019, grad/param norm = 1.5634e-01, time/batch = 17.9555s	
7512/33150 (epoch 11.330), train_loss = 1.20534525, grad/param norm = 1.6588e-01, time/batch = 15.2132s	
7513/33150 (epoch 11.332), train_loss = 1.17332156, grad/param norm = 1.2816e-01, time/batch = 16.2323s	
7514/33150 (epoch 11.333), train_loss = 1.22600243, grad/param norm = 1.3681e-01, time/batch = 15.0343s	
7515/33150 (epoch 11.335), train_loss = 1.13228296, grad/param norm = 1.4661e-01, time/batch = 16.9682s	
7516/33150 (epoch 11.336), train_loss = 1.10608119, grad/param norm = 1.5557e-01, time/batch = 15.1107s	
7517/33150 (epoch 11.338), train_loss = 0.97063187, grad/param norm = 1.4556e-01, time/batch = 16.8850s	
7518/33150 (epoch 11.339), train_loss = 1.29860299, grad/param norm = 1.5495e-01, time/batch = 16.3912s	
7519/33150 (epoch 11.341), train_loss = 1.34092593, grad/param norm = 1.8128e-01, time/batch = 16.7767s	
7520/33150 (epoch 11.342), train_loss = 1.03872966, grad/param norm = 1.5008e-01, time/batch = 15.3031s	
7521/33150 (epoch 11.344), train_loss = 1.24478723, grad/param norm = 1.6931e-01, time/batch = 16.4900s	
7522/33150 (epoch 11.345), train_loss = 1.11253918, grad/param norm = 1.4685e-01, time/batch = 15.6323s	
7523/33150 (epoch 11.347), train_loss = 0.93515337, grad/param norm = 1.2919e-01, time/batch = 15.9683s	
7524/33150 (epoch 11.348), train_loss = 1.19682075, grad/param norm = 1.4739e-01, time/batch = 16.3003s	
7525/33150 (epoch 11.350), train_loss = 1.14603298, grad/param norm = 1.8621e-01, time/batch = 15.9718s	
7526/33150 (epoch 11.351), train_loss = 1.28393002, grad/param norm = 1.6324e-01, time/batch = 16.2113s	
7527/33150 (epoch 11.353), train_loss = 1.30455951, grad/param norm = 1.7983e-01, time/batch = 16.9683s	
7528/33150 (epoch 11.354), train_loss = 1.46678029, grad/param norm = 1.6008e-01, time/batch = 17.2218s	
7529/33150 (epoch 11.356), train_loss = 1.29866016, grad/param norm = 1.7356e-01, time/batch = 15.7354s	
7530/33150 (epoch 11.357), train_loss = 1.28237950, grad/param norm = 1.6433e-01, time/batch = 16.8004s	
7531/33150 (epoch 11.359), train_loss = 1.22753868, grad/param norm = 1.5029e-01, time/batch = 15.0633s	
7532/33150 (epoch 11.360), train_loss = 1.28839085, grad/param norm = 1.8049e-01, time/batch = 17.7317s	
7533/33150 (epoch 11.362), train_loss = 1.29609579, grad/param norm = 1.5937e-01, time/batch = 17.2098s	
7534/33150 (epoch 11.363), train_loss = 1.17804584, grad/param norm = 1.4220e-01, time/batch = 16.7052s	
7535/33150 (epoch 11.365), train_loss = 1.17132909, grad/param norm = 1.3682e-01, time/batch = 16.4009s	
7536/33150 (epoch 11.367), train_loss = 1.08447209, grad/param norm = 1.4957e-01, time/batch = 17.8833s	
7537/33150 (epoch 11.368), train_loss = 1.18345017, grad/param norm = 1.5023e-01, time/batch = 17.7980s	
7538/33150 (epoch 11.370), train_loss = 1.23329413, grad/param norm = 1.6687e-01, time/batch = 16.4521s	
7539/33150 (epoch 11.371), train_loss = 1.06066512, grad/param norm = 1.3695e-01, time/batch = 19.2157s	
7540/33150 (epoch 11.373), train_loss = 1.25073439, grad/param norm = 1.6252e-01, time/batch = 18.8139s	
7541/33150 (epoch 11.374), train_loss = 1.17413424, grad/param norm = 1.4971e-01, time/batch = 29.8457s	
7542/33150 (epoch 11.376), train_loss = 1.31786464, grad/param norm = 1.5144e-01, time/batch = 19.4626s	
7543/33150 (epoch 11.377), train_loss = 1.16480218, grad/param norm = 1.6316e-01, time/batch = 17.2222s	
7544/33150 (epoch 11.379), train_loss = 1.27845314, grad/param norm = 1.6345e-01, time/batch = 16.5358s	
7545/33150 (epoch 11.380), train_loss = 1.27670974, grad/param norm = 1.4701e-01, time/batch = 16.4996s	
7546/33150 (epoch 11.382), train_loss = 1.09241524, grad/param norm = 1.4816e-01, time/batch = 18.6550s	
7547/33150 (epoch 11.383), train_loss = 1.08153330, grad/param norm = 1.4495e-01, time/batch = 15.8750s	
7548/33150 (epoch 11.385), train_loss = 1.20951992, grad/param norm = 1.5901e-01, time/batch = 17.0508s	
7549/33150 (epoch 11.386), train_loss = 1.05042960, grad/param norm = 1.3556e-01, time/batch = 17.4800s	
7550/33150 (epoch 11.388), train_loss = 1.16714494, grad/param norm = 1.4489e-01, time/batch = 17.0606s	
7551/33150 (epoch 11.389), train_loss = 1.13427164, grad/param norm = 1.4439e-01, time/batch = 17.1446s	
7552/33150 (epoch 11.391), train_loss = 1.35786300, grad/param norm = 1.5047e-01, time/batch = 18.5697s	
7553/33150 (epoch 11.392), train_loss = 1.13648200, grad/param norm = 1.3676e-01, time/batch = 18.2998s	
7554/33150 (epoch 11.394), train_loss = 1.04500368, grad/param norm = 1.2165e-01, time/batch = 17.0463s	
7555/33150 (epoch 11.395), train_loss = 1.06459913, grad/param norm = 1.4436e-01, time/batch = 17.5446s	
7556/33150 (epoch 11.397), train_loss = 0.89584276, grad/param norm = 1.3367e-01, time/batch = 18.7893s	
7557/33150 (epoch 11.398), train_loss = 1.18618437, grad/param norm = 1.6218e-01, time/batch = 16.6018s	
7558/33150 (epoch 11.400), train_loss = 1.12294439, grad/param norm = 1.3582e-01, time/batch = 17.8032s	
7559/33150 (epoch 11.401), train_loss = 1.01008905, grad/param norm = 1.3993e-01, time/batch = 17.2198s	
7560/33150 (epoch 11.403), train_loss = 1.07163385, grad/param norm = 1.3467e-01, time/batch = 15.1930s	
7561/33150 (epoch 11.404), train_loss = 1.14889496, grad/param norm = 1.4413e-01, time/batch = 17.1229s	
7562/33150 (epoch 11.406), train_loss = 1.06295422, grad/param norm = 1.1641e-01, time/batch = 17.5571s	
7563/33150 (epoch 11.407), train_loss = 1.04759180, grad/param norm = 1.3364e-01, time/batch = 18.9433s	
7564/33150 (epoch 11.409), train_loss = 0.97635338, grad/param norm = 1.3985e-01, time/batch = 16.5402s	
7565/33150 (epoch 11.410), train_loss = 1.22592611, grad/param norm = 1.5718e-01, time/batch = 17.1723s	
7566/33150 (epoch 11.412), train_loss = 1.21718594, grad/param norm = 1.4694e-01, time/batch = 15.7871s	
7567/33150 (epoch 11.413), train_loss = 1.12592743, grad/param norm = 1.5778e-01, time/batch = 15.2066s	
7568/33150 (epoch 11.415), train_loss = 1.28097930, grad/param norm = 1.4798e-01, time/batch = 15.5161s	
7569/33150 (epoch 11.416), train_loss = 1.09746549, grad/param norm = 1.3581e-01, time/batch = 15.3708s	
7570/33150 (epoch 11.418), train_loss = 1.38038977, grad/param norm = 1.9069e-01, time/batch = 17.8918s	
7571/33150 (epoch 11.419), train_loss = 1.10276081, grad/param norm = 1.5325e-01, time/batch = 15.5353s	
7572/33150 (epoch 11.421), train_loss = 1.19786274, grad/param norm = 1.4973e-01, time/batch = 16.7131s	
7573/33150 (epoch 11.422), train_loss = 1.12552972, grad/param norm = 1.4295e-01, time/batch = 17.2171s	
7574/33150 (epoch 11.424), train_loss = 1.11938554, grad/param norm = 1.5043e-01, time/batch = 15.9791s	
7575/33150 (epoch 11.425), train_loss = 1.15041009, grad/param norm = 1.4073e-01, time/batch = 16.3031s	
7576/33150 (epoch 11.427), train_loss = 1.12704905, grad/param norm = 1.4494e-01, time/batch = 15.8157s	
7577/33150 (epoch 11.428), train_loss = 1.19578787, grad/param norm = 1.6382e-01, time/batch = 15.7393s	
7578/33150 (epoch 11.430), train_loss = 1.22442447, grad/param norm = 1.5694e-01, time/batch = 18.2911s	
7579/33150 (epoch 11.431), train_loss = 1.27303613, grad/param norm = 1.7017e-01, time/batch = 16.6529s	
7580/33150 (epoch 11.433), train_loss = 1.15441274, grad/param norm = 1.3661e-01, time/batch = 18.1462s	
7581/33150 (epoch 11.434), train_loss = 1.04993048, grad/param norm = 1.4942e-01, time/batch = 18.5596s	
7582/33150 (epoch 11.436), train_loss = 1.03977737, grad/param norm = 1.5917e-01, time/batch = 16.0553s	
7583/33150 (epoch 11.437), train_loss = 1.17819978, grad/param norm = 1.6063e-01, time/batch = 16.8783s	
7584/33150 (epoch 11.439), train_loss = 1.29433904, grad/param norm = 1.6279e-01, time/batch = 18.1268s	
7585/33150 (epoch 11.440), train_loss = 1.29913322, grad/param norm = 1.5595e-01, time/batch = 16.0489s	
7586/33150 (epoch 11.442), train_loss = 1.03990494, grad/param norm = 1.3966e-01, time/batch = 15.8864s	
7587/33150 (epoch 11.443), train_loss = 1.30425670, grad/param norm = 1.5946e-01, time/batch = 17.0765s	
7588/33150 (epoch 11.445), train_loss = 1.18393301, grad/param norm = 1.6501e-01, time/batch = 18.3898s	
7589/33150 (epoch 11.446), train_loss = 1.20796478, grad/param norm = 1.8224e-01, time/batch = 16.7179s	
7590/33150 (epoch 11.448), train_loss = 1.26589383, grad/param norm = 1.6056e-01, time/batch = 17.2014s	
7591/33150 (epoch 11.449), train_loss = 1.17633868, grad/param norm = 1.4452e-01, time/batch = 17.9474s	
7592/33150 (epoch 11.451), train_loss = 1.24979876, grad/param norm = 1.5995e-01, time/batch = 18.3586s	
7593/33150 (epoch 11.452), train_loss = 1.45493547, grad/param norm = 1.6541e-01, time/batch = 15.7080s	
7594/33150 (epoch 11.454), train_loss = 1.15674999, grad/param norm = 1.4889e-01, time/batch = 15.5386s	
7595/33150 (epoch 11.456), train_loss = 0.99107113, grad/param norm = 1.3718e-01, time/batch = 16.7101s	
7596/33150 (epoch 11.457), train_loss = 1.18495027, grad/param norm = 1.5370e-01, time/batch = 15.7924s	
7597/33150 (epoch 11.459), train_loss = 1.35864491, grad/param norm = 1.8817e-01, time/batch = 15.4055s	
7598/33150 (epoch 11.460), train_loss = 1.21353521, grad/param norm = 1.3896e-01, time/batch = 15.0879s	
7599/33150 (epoch 11.462), train_loss = 1.29364839, grad/param norm = 1.7448e-01, time/batch = 14.9343s	
7600/33150 (epoch 11.463), train_loss = 1.49428998, grad/param norm = 1.9536e-01, time/batch = 15.6591s	
7601/33150 (epoch 11.465), train_loss = 1.11463022, grad/param norm = 1.4254e-01, time/batch = 15.2688s	
7602/33150 (epoch 11.466), train_loss = 1.10616157, grad/param norm = 1.3748e-01, time/batch = 15.6990s	
7603/33150 (epoch 11.468), train_loss = 1.49773232, grad/param norm = 1.6049e-01, time/batch = 15.2055s	
7604/33150 (epoch 11.469), train_loss = 1.20388037, grad/param norm = 1.5808e-01, time/batch = 15.2731s	
7605/33150 (epoch 11.471), train_loss = 1.14164901, grad/param norm = 1.4355e-01, time/batch = 19.6916s	
7606/33150 (epoch 11.472), train_loss = 1.16636123, grad/param norm = 1.4450e-01, time/batch = 16.4489s	
7607/33150 (epoch 11.474), train_loss = 1.31605448, grad/param norm = 1.8595e-01, time/batch = 16.3733s	
7608/33150 (epoch 11.475), train_loss = 1.47310865, grad/param norm = 1.6695e-01, time/batch = 16.4699s	
7609/33150 (epoch 11.477), train_loss = 1.26806699, grad/param norm = 1.6474e-01, time/batch = 17.2138s	
7610/33150 (epoch 11.478), train_loss = 1.32466111, grad/param norm = 1.5094e-01, time/batch = 16.6324s	
7611/33150 (epoch 11.480), train_loss = 1.12596165, grad/param norm = 1.4867e-01, time/batch = 16.3853s	
7612/33150 (epoch 11.481), train_loss = 1.01841321, grad/param norm = 1.4133e-01, time/batch = 15.8618s	
7613/33150 (epoch 11.483), train_loss = 1.14561604, grad/param norm = 1.5241e-01, time/batch = 16.8664s	
7614/33150 (epoch 11.484), train_loss = 1.13325353, grad/param norm = 1.5064e-01, time/batch = 17.4733s	
7615/33150 (epoch 11.486), train_loss = 1.14810021, grad/param norm = 1.6119e-01, time/batch = 16.8746s	
7616/33150 (epoch 11.487), train_loss = 1.24188917, grad/param norm = 1.5698e-01, time/batch = 17.7278s	
7617/33150 (epoch 11.489), train_loss = 1.19092241, grad/param norm = 1.5241e-01, time/batch = 16.8647s	
7618/33150 (epoch 11.490), train_loss = 1.03183735, grad/param norm = 1.3577e-01, time/batch = 16.9672s	
7619/33150 (epoch 11.492), train_loss = 1.12519088, grad/param norm = 1.5795e-01, time/batch = 17.4411s	
7620/33150 (epoch 11.493), train_loss = 1.28168333, grad/param norm = 1.6980e-01, time/batch = 19.0624s	
7621/33150 (epoch 11.495), train_loss = 1.29490989, grad/param norm = 1.5780e-01, time/batch = 16.7065s	
7622/33150 (epoch 11.496), train_loss = 1.11394143, grad/param norm = 1.4942e-01, time/batch = 17.7841s	
7623/33150 (epoch 11.498), train_loss = 1.29123051, grad/param norm = 1.7353e-01, time/batch = 17.3000s	
7624/33150 (epoch 11.499), train_loss = 1.37849589, grad/param norm = 1.6677e-01, time/batch = 16.7233s	
7625/33150 (epoch 11.501), train_loss = 1.24351721, grad/param norm = 1.4712e-01, time/batch = 16.3061s	
7626/33150 (epoch 11.502), train_loss = 1.36330412, grad/param norm = 1.6566e-01, time/batch = 18.2162s	
7627/33150 (epoch 11.504), train_loss = 1.26394046, grad/param norm = 1.5863e-01, time/batch = 16.2845s	
7628/33150 (epoch 11.505), train_loss = 1.42930039, grad/param norm = 1.8201e-01, time/batch = 16.9733s	
7629/33150 (epoch 11.507), train_loss = 1.13679915, grad/param norm = 1.4402e-01, time/batch = 18.2765s	
7630/33150 (epoch 11.508), train_loss = 1.12618939, grad/param norm = 1.5506e-01, time/batch = 17.6325s	
7631/33150 (epoch 11.510), train_loss = 1.19681193, grad/param norm = 1.5744e-01, time/batch = 17.2785s	
7632/33150 (epoch 11.511), train_loss = 1.40204591, grad/param norm = 1.7151e-01, time/batch = 16.2887s	
7633/33150 (epoch 11.513), train_loss = 1.24283193, grad/param norm = 1.7389e-01, time/batch = 16.1331s	
7634/33150 (epoch 11.514), train_loss = 1.01053096, grad/param norm = 1.6280e-01, time/batch = 17.2895s	
7635/33150 (epoch 11.516), train_loss = 1.32831202, grad/param norm = 1.9454e-01, time/batch = 17.4509s	
7636/33150 (epoch 11.517), train_loss = 1.32622365, grad/param norm = 1.5504e-01, time/batch = 15.5771s	
7637/33150 (epoch 11.519), train_loss = 1.11265112, grad/param norm = 1.4491e-01, time/batch = 17.5376s	
7638/33150 (epoch 11.520), train_loss = 1.21946184, grad/param norm = 1.4725e-01, time/batch = 17.2043s	
7639/33150 (epoch 11.522), train_loss = 1.38119851, grad/param norm = 2.0029e-01, time/batch = 16.3773s	
7640/33150 (epoch 11.523), train_loss = 1.08653275, grad/param norm = 1.6690e-01, time/batch = 15.5492s	
7641/33150 (epoch 11.525), train_loss = 1.23487386, grad/param norm = 1.5325e-01, time/batch = 17.3974s	
7642/33150 (epoch 11.526), train_loss = 1.10951829, grad/param norm = 1.4379e-01, time/batch = 17.6323s	
7643/33150 (epoch 11.528), train_loss = 1.27088609, grad/param norm = 1.6497e-01, time/batch = 16.5361s	
7644/33150 (epoch 11.529), train_loss = 1.24969931, grad/param norm = 1.5449e-01, time/batch = 16.6389s	
7645/33150 (epoch 11.531), train_loss = 1.04226429, grad/param norm = 1.5631e-01, time/batch = 17.4482s	
7646/33150 (epoch 11.532), train_loss = 1.22999956, grad/param norm = 1.5721e-01, time/batch = 15.5416s	
7647/33150 (epoch 11.534), train_loss = 1.12947827, grad/param norm = 1.3255e-01, time/batch = 17.0291s	
7648/33150 (epoch 11.535), train_loss = 1.10935104, grad/param norm = 1.6746e-01, time/batch = 15.6232s	
7649/33150 (epoch 11.537), train_loss = 1.32863167, grad/param norm = 1.7612e-01, time/batch = 17.2918s	
7650/33150 (epoch 11.538), train_loss = 1.16560787, grad/param norm = 1.6545e-01, time/batch = 16.2210s	
7651/33150 (epoch 11.540), train_loss = 1.03731099, grad/param norm = 1.4236e-01, time/batch = 18.5543s	
7652/33150 (epoch 11.541), train_loss = 1.28761947, grad/param norm = 1.7213e-01, time/batch = 16.7308s	
7653/33150 (epoch 11.543), train_loss = 1.24259343, grad/param norm = 1.4859e-01, time/batch = 15.8426s	
7654/33150 (epoch 11.544), train_loss = 1.20963126, grad/param norm = 1.4531e-01, time/batch = 17.7166s	
7655/33150 (epoch 11.546), train_loss = 1.35786014, grad/param norm = 1.6811e-01, time/batch = 17.6283s	
7656/33150 (epoch 11.548), train_loss = 1.24370257, grad/param norm = 1.5949e-01, time/batch = 16.9493s	
7657/33150 (epoch 11.549), train_loss = 1.18142336, grad/param norm = 1.5470e-01, time/batch = 16.3864s	
7658/33150 (epoch 11.551), train_loss = 1.10763994, grad/param norm = 1.5526e-01, time/batch = 18.6390s	
7659/33150 (epoch 11.552), train_loss = 0.98403440, grad/param norm = 1.2559e-01, time/batch = 16.4876s	
7660/33150 (epoch 11.554), train_loss = 1.23632343, grad/param norm = 1.4542e-01, time/batch = 15.8947s	
7661/33150 (epoch 11.555), train_loss = 1.38812024, grad/param norm = 1.6948e-01, time/batch = 16.3924s	
7662/33150 (epoch 11.557), train_loss = 1.02720220, grad/param norm = 1.4560e-01, time/batch = 17.8038s	
7663/33150 (epoch 11.558), train_loss = 1.29621271, grad/param norm = 1.8987e-01, time/batch = 16.7119s	
7664/33150 (epoch 11.560), train_loss = 1.12919847, grad/param norm = 1.4524e-01, time/batch = 15.9728s	
7665/33150 (epoch 11.561), train_loss = 1.00314966, grad/param norm = 1.4488e-01, time/batch = 16.7109s	
7666/33150 (epoch 11.563), train_loss = 1.29691039, grad/param norm = 2.0250e-01, time/batch = 17.8773s	
7667/33150 (epoch 11.564), train_loss = 1.38319972, grad/param norm = 1.6107e-01, time/batch = 16.6330s	
7668/33150 (epoch 11.566), train_loss = 1.20601947, grad/param norm = 1.5464e-01, time/batch = 15.6363s	
7669/33150 (epoch 11.567), train_loss = 1.07635598, grad/param norm = 1.3559e-01, time/batch = 17.6398s	
7670/33150 (epoch 11.569), train_loss = 1.20191637, grad/param norm = 1.4775e-01, time/batch = 17.8059s	
7671/33150 (epoch 11.570), train_loss = 1.23591041, grad/param norm = 1.4970e-01, time/batch = 16.0574s	
7672/33150 (epoch 11.572), train_loss = 1.07718829, grad/param norm = 1.4036e-01, time/batch = 17.1353s	
7673/33150 (epoch 11.573), train_loss = 0.97012985, grad/param norm = 1.2901e-01, time/batch = 15.8873s	
7674/33150 (epoch 11.575), train_loss = 1.18553728, grad/param norm = 1.5480e-01, time/batch = 15.5408s	
7675/33150 (epoch 11.576), train_loss = 0.99610736, grad/param norm = 1.2814e-01, time/batch = 16.3129s	
7676/33150 (epoch 11.578), train_loss = 1.12990172, grad/param norm = 1.3408e-01, time/batch = 16.9063s	
7677/33150 (epoch 11.579), train_loss = 1.03598422, grad/param norm = 1.4204e-01, time/batch = 15.9783s	
7678/33150 (epoch 11.581), train_loss = 1.08268734, grad/param norm = 1.4566e-01, time/batch = 15.7201s	
7679/33150 (epoch 11.582), train_loss = 1.24410468, grad/param norm = 1.4503e-01, time/batch = 16.1239s	
7680/33150 (epoch 11.584), train_loss = 1.26689857, grad/param norm = 1.4419e-01, time/batch = 16.1663s	
7681/33150 (epoch 11.585), train_loss = 1.20325836, grad/param norm = 1.5235e-01, time/batch = 16.2733s	
7682/33150 (epoch 11.587), train_loss = 1.23881407, grad/param norm = 1.5647e-01, time/batch = 17.4260s	
7683/33150 (epoch 11.588), train_loss = 1.07444783, grad/param norm = 1.5209e-01, time/batch = 17.4494s	
7684/33150 (epoch 11.590), train_loss = 1.18180920, grad/param norm = 1.5058e-01, time/batch = 18.6903s	
7685/33150 (epoch 11.591), train_loss = 1.18619301, grad/param norm = 1.5622e-01, time/batch = 16.8683s	
7686/33150 (epoch 11.593), train_loss = 1.26256605, grad/param norm = 1.5999e-01, time/batch = 15.1279s	
7687/33150 (epoch 11.594), train_loss = 1.21297038, grad/param norm = 1.6133e-01, time/batch = 17.1152s	
7688/33150 (epoch 11.596), train_loss = 1.09598147, grad/param norm = 1.4237e-01, time/batch = 16.7073s	
7689/33150 (epoch 11.597), train_loss = 1.07207503, grad/param norm = 1.6139e-01, time/batch = 16.3738s	
7690/33150 (epoch 11.599), train_loss = 1.40433367, grad/param norm = 1.7374e-01, time/batch = 17.0403s	
7691/33150 (epoch 11.600), train_loss = 1.21484757, grad/param norm = 1.7289e-01, time/batch = 16.7018s	
7692/33150 (epoch 11.602), train_loss = 1.11288112, grad/param norm = 1.4241e-01, time/batch = 16.3772s	
7693/33150 (epoch 11.603), train_loss = 1.24615367, grad/param norm = 1.6388e-01, time/batch = 15.7442s	
7694/33150 (epoch 11.605), train_loss = 1.06689480, grad/param norm = 1.4338e-01, time/batch = 15.3847s	
7695/33150 (epoch 11.606), train_loss = 1.20592998, grad/param norm = 1.7296e-01, time/batch = 18.6266s	
7696/33150 (epoch 11.608), train_loss = 1.22883686, grad/param norm = 1.6312e-01, time/batch = 16.3635s	
7697/33150 (epoch 11.609), train_loss = 1.18207543, grad/param norm = 1.6788e-01, time/batch = 18.8114s	
7698/33150 (epoch 11.611), train_loss = 1.00326393, grad/param norm = 1.3443e-01, time/batch = 18.0521s	
7699/33150 (epoch 11.612), train_loss = 1.19931616, grad/param norm = 1.6133e-01, time/batch = 16.6144s	
7700/33150 (epoch 11.614), train_loss = 1.01235767, grad/param norm = 1.4033e-01, time/batch = 16.6362s	
7701/33150 (epoch 11.615), train_loss = 1.05341732, grad/param norm = 1.3802e-01, time/batch = 18.8902s	
7702/33150 (epoch 11.617), train_loss = 1.18179707, grad/param norm = 1.6476e-01, time/batch = 17.7305s	
7703/33150 (epoch 11.618), train_loss = 1.18856405, grad/param norm = 1.5159e-01, time/batch = 17.9617s	
7704/33150 (epoch 11.620), train_loss = 1.10640848, grad/param norm = 1.6289e-01, time/batch = 18.7860s	
7705/33150 (epoch 11.621), train_loss = 1.15190716, grad/param norm = 1.4838e-01, time/batch = 17.6310s	
7706/33150 (epoch 11.623), train_loss = 1.23787140, grad/param norm = 1.5807e-01, time/batch = 17.3111s	
7707/33150 (epoch 11.624), train_loss = 1.09442782, grad/param norm = 1.5284e-01, time/batch = 18.0632s	
7708/33150 (epoch 11.626), train_loss = 1.08489309, grad/param norm = 1.4284e-01, time/batch = 19.7094s	
7709/33150 (epoch 11.627), train_loss = 1.03420997, grad/param norm = 1.4881e-01, time/batch = 17.7350s	
7710/33150 (epoch 11.629), train_loss = 1.01719347, grad/param norm = 1.3474e-01, time/batch = 17.6413s	
7711/33150 (epoch 11.630), train_loss = 1.08089153, grad/param norm = 1.3419e-01, time/batch = 15.4555s	
7712/33150 (epoch 11.632), train_loss = 0.99902401, grad/param norm = 1.3367e-01, time/batch = 16.8133s	
7713/33150 (epoch 11.633), train_loss = 1.02580453, grad/param norm = 1.5681e-01, time/batch = 16.2949s	
7714/33150 (epoch 11.635), train_loss = 1.37741540, grad/param norm = 1.5931e-01, time/batch = 16.7262s	
7715/33150 (epoch 11.637), train_loss = 0.99388977, grad/param norm = 1.5504e-01, time/batch = 16.4634s	
7716/33150 (epoch 11.638), train_loss = 1.11835113, grad/param norm = 1.4202e-01, time/batch = 15.7095s	
7717/33150 (epoch 11.640), train_loss = 1.28865592, grad/param norm = 1.6434e-01, time/batch = 16.4844s	
7718/33150 (epoch 11.641), train_loss = 1.06715514, grad/param norm = 1.5428e-01, time/batch = 16.3162s	
7719/33150 (epoch 11.643), train_loss = 1.10367494, grad/param norm = 1.4397e-01, time/batch = 16.8758s	
7720/33150 (epoch 11.644), train_loss = 1.29085420, grad/param norm = 1.4522e-01, time/batch = 15.7310s	
7721/33150 (epoch 11.646), train_loss = 1.11457298, grad/param norm = 1.4047e-01, time/batch = 17.0723s	
7722/33150 (epoch 11.647), train_loss = 1.45667368, grad/param norm = 1.7099e-01, time/batch = 16.4896s	
7723/33150 (epoch 11.649), train_loss = 1.28813140, grad/param norm = 1.7006e-01, time/batch = 16.6903s	
7724/33150 (epoch 11.650), train_loss = 1.02762224, grad/param norm = 1.3326e-01, time/batch = 17.4503s	
7725/33150 (epoch 11.652), train_loss = 1.27644190, grad/param norm = 1.6439e-01, time/batch = 17.6373s	
7726/33150 (epoch 11.653), train_loss = 1.15293131, grad/param norm = 1.4219e-01, time/batch = 17.2205s	
7727/33150 (epoch 11.655), train_loss = 1.23667120, grad/param norm = 1.7961e-01, time/batch = 16.4552s	
7728/33150 (epoch 11.656), train_loss = 1.16468982, grad/param norm = 1.4340e-01, time/batch = 17.1493s	
7729/33150 (epoch 11.658), train_loss = 1.17609075, grad/param norm = 1.7672e-01, time/batch = 18.0564s	
7730/33150 (epoch 11.659), train_loss = 1.53152796, grad/param norm = 4.4432e-01, time/batch = 16.1529s	
7731/33150 (epoch 11.661), train_loss = 1.17593790, grad/param norm = 1.6939e-01, time/batch = 17.8938s	
7732/33150 (epoch 11.662), train_loss = 1.01460705, grad/param norm = 1.6151e-01, time/batch = 18.2177s	
7733/33150 (epoch 11.664), train_loss = 1.29412397, grad/param norm = 1.5689e-01, time/batch = 17.3998s	
7734/33150 (epoch 11.665), train_loss = 1.25893819, grad/param norm = 1.6638e-01, time/batch = 16.4642s	
7735/33150 (epoch 11.667), train_loss = 1.34163431, grad/param norm = 1.6809e-01, time/batch = 15.3167s	
7736/33150 (epoch 11.668), train_loss = 1.24597176, grad/param norm = 1.5050e-01, time/batch = 17.8231s	
7737/33150 (epoch 11.670), train_loss = 1.11569300, grad/param norm = 1.4196e-01, time/batch = 16.4675s	
7738/33150 (epoch 11.671), train_loss = 1.12572320, grad/param norm = 1.5725e-01, time/batch = 15.7195s	
7739/33150 (epoch 11.673), train_loss = 1.27802164, grad/param norm = 1.3380e-01, time/batch = 17.5678s	
7740/33150 (epoch 11.674), train_loss = 1.16500881, grad/param norm = 1.3810e-01, time/batch = 19.3878s	
7741/33150 (epoch 11.676), train_loss = 1.13058128, grad/param norm = 1.3941e-01, time/batch = 17.0495s	
7742/33150 (epoch 11.677), train_loss = 1.44670261, grad/param norm = 1.5577e-01, time/batch = 18.3746s	
7743/33150 (epoch 11.679), train_loss = 1.09056692, grad/param norm = 1.4699e-01, time/batch = 17.5472s	
7744/33150 (epoch 11.680), train_loss = 1.31953760, grad/param norm = 1.5764e-01, time/batch = 17.9512s	
7745/33150 (epoch 11.682), train_loss = 1.10135490, grad/param norm = 1.5096e-01, time/batch = 18.6286s	
7746/33150 (epoch 11.683), train_loss = 0.97781626, grad/param norm = 1.2289e-01, time/batch = 18.7900s	
7747/33150 (epoch 11.685), train_loss = 1.19683052, grad/param norm = 1.4989e-01, time/batch = 18.5603s	
7748/33150 (epoch 11.686), train_loss = 1.01363690, grad/param norm = 1.4190e-01, time/batch = 18.6438s	
7749/33150 (epoch 11.688), train_loss = 1.10855182, grad/param norm = 1.4753e-01, time/batch = 17.5451s	
7750/33150 (epoch 11.689), train_loss = 1.06201942, grad/param norm = 1.3580e-01, time/batch = 19.5376s	
7751/33150 (epoch 11.691), train_loss = 0.97686962, grad/param norm = 1.3155e-01, time/batch = 30.4462s	
7752/33150 (epoch 11.692), train_loss = 1.06468667, grad/param norm = 1.4065e-01, time/batch = 16.5483s	
7753/33150 (epoch 11.694), train_loss = 0.93061912, grad/param norm = 1.2058e-01, time/batch = 15.1697s	
7754/33150 (epoch 11.695), train_loss = 1.10371370, grad/param norm = 1.4281e-01, time/batch = 15.2554s	
7755/33150 (epoch 11.697), train_loss = 0.96880549, grad/param norm = 1.2293e-01, time/batch = 15.1172s	
7756/33150 (epoch 11.698), train_loss = 1.20652137, grad/param norm = 1.5080e-01, time/batch = 15.7025s	
7757/33150 (epoch 11.700), train_loss = 0.89391996, grad/param norm = 1.3462e-01, time/batch = 15.4548s	
7758/33150 (epoch 11.701), train_loss = 1.06602056, grad/param norm = 1.4827e-01, time/batch = 16.2838s	
7759/33150 (epoch 11.703), train_loss = 1.14504941, grad/param norm = 1.4231e-01, time/batch = 15.5284s	
7760/33150 (epoch 11.704), train_loss = 0.95929831, grad/param norm = 1.2945e-01, time/batch = 15.1049s	
7761/33150 (epoch 11.706), train_loss = 1.10680472, grad/param norm = 1.3138e-01, time/batch = 15.6680s	
7762/33150 (epoch 11.707), train_loss = 1.11063458, grad/param norm = 1.5645e-01, time/batch = 16.0273s	
7763/33150 (epoch 11.709), train_loss = 1.16352197, grad/param norm = 1.3264e-01, time/batch = 17.2212s	
7764/33150 (epoch 11.710), train_loss = 1.22540329, grad/param norm = 1.6996e-01, time/batch = 17.4458s	
7765/33150 (epoch 11.712), train_loss = 1.27850403, grad/param norm = 1.7348e-01, time/batch = 16.0998s	
7766/33150 (epoch 11.713), train_loss = 1.22667947, grad/param norm = 1.6109e-01, time/batch = 16.4506s	
7767/33150 (epoch 11.715), train_loss = 1.10003930, grad/param norm = 1.3486e-01, time/batch = 17.8748s	
7768/33150 (epoch 11.716), train_loss = 1.20195878, grad/param norm = 1.5313e-01, time/batch = 18.4519s	
7769/33150 (epoch 11.718), train_loss = 1.18547123, grad/param norm = 1.4284e-01, time/batch = 16.6198s	
7770/33150 (epoch 11.719), train_loss = 1.28026274, grad/param norm = 1.7095e-01, time/batch = 16.4718s	
7771/33150 (epoch 11.721), train_loss = 1.16614653, grad/param norm = 1.6225e-01, time/batch = 18.5621s	
7772/33150 (epoch 11.722), train_loss = 1.21049013, grad/param norm = 1.4546e-01, time/batch = 16.1090s	
7773/33150 (epoch 11.724), train_loss = 1.11879852, grad/param norm = 1.3930e-01, time/batch = 17.2208s	
7774/33150 (epoch 11.725), train_loss = 1.33315877, grad/param norm = 1.7426e-01, time/batch = 16.5426s	
7775/33150 (epoch 11.727), train_loss = 1.19199800, grad/param norm = 1.6600e-01, time/batch = 17.1377s	
7776/33150 (epoch 11.729), train_loss = 1.17092410, grad/param norm = 1.4384e-01, time/batch = 16.0403s	
7777/33150 (epoch 11.730), train_loss = 1.17667196, grad/param norm = 1.5677e-01, time/batch = 18.6247s	
7778/33150 (epoch 11.732), train_loss = 1.27311723, grad/param norm = 1.6368e-01, time/batch = 17.3013s	
7779/33150 (epoch 11.733), train_loss = 0.95179844, grad/param norm = 1.1785e-01, time/batch = 15.2966s	
7780/33150 (epoch 11.735), train_loss = 1.12909229, grad/param norm = 1.4644e-01, time/batch = 17.2078s	
7781/33150 (epoch 11.736), train_loss = 1.12707913, grad/param norm = 1.6100e-01, time/batch = 18.0620s	
7782/33150 (epoch 11.738), train_loss = 1.19885509, grad/param norm = 1.5551e-01, time/batch = 16.8013s	
7783/33150 (epoch 11.739), train_loss = 1.31217100, grad/param norm = 1.6546e-01, time/batch = 16.9811s	
7784/33150 (epoch 11.741), train_loss = 1.29377543, grad/param norm = 1.6472e-01, time/batch = 17.5536s	
7785/33150 (epoch 11.742), train_loss = 1.09968977, grad/param norm = 1.5144e-01, time/batch = 17.8020s	
7786/33150 (epoch 11.744), train_loss = 1.31718222, grad/param norm = 1.6612e-01, time/batch = 16.0209s	
7787/33150 (epoch 11.745), train_loss = 1.10898115, grad/param norm = 1.3361e-01, time/batch = 16.8580s	
7788/33150 (epoch 11.747), train_loss = 1.00631904, grad/param norm = 1.5015e-01, time/batch = 15.3834s	
7789/33150 (epoch 11.748), train_loss = 1.09892262, grad/param norm = 1.4507e-01, time/batch = 17.2918s	
7790/33150 (epoch 11.750), train_loss = 1.25614374, grad/param norm = 1.6187e-01, time/batch = 15.5676s	
7791/33150 (epoch 11.751), train_loss = 1.18424241, grad/param norm = 1.5021e-01, time/batch = 17.7975s	
7792/33150 (epoch 11.753), train_loss = 1.00156526, grad/param norm = 1.5828e-01, time/batch = 17.5598s	
7793/33150 (epoch 11.754), train_loss = 1.41239655, grad/param norm = 1.9151e-01, time/batch = 16.7863s	
7794/33150 (epoch 11.756), train_loss = 1.23253883, grad/param norm = 1.6771e-01, time/batch = 16.7908s	
7795/33150 (epoch 11.757), train_loss = 1.19608286, grad/param norm = 1.5393e-01, time/batch = 17.3123s	
7796/33150 (epoch 11.759), train_loss = 1.35295509, grad/param norm = 1.6822e-01, time/batch = 16.6347s	
7797/33150 (epoch 11.760), train_loss = 1.22546587, grad/param norm = 1.9377e-01, time/batch = 16.4718s	
7798/33150 (epoch 11.762), train_loss = 1.23027375, grad/param norm = 1.8453e-01, time/batch = 17.5579s	
7799/33150 (epoch 11.763), train_loss = 1.18379911, grad/param norm = 1.4963e-01, time/batch = 16.8500s	
7800/33150 (epoch 11.765), train_loss = 1.14092505, grad/param norm = 1.4698e-01, time/batch = 15.6251s	
7801/33150 (epoch 11.766), train_loss = 1.06969620, grad/param norm = 1.3824e-01, time/batch = 15.3472s	
7802/33150 (epoch 11.768), train_loss = 1.11149080, grad/param norm = 1.4930e-01, time/batch = 16.2110s	
7803/33150 (epoch 11.769), train_loss = 1.20683783, grad/param norm = 1.5710e-01, time/batch = 15.3558s	
7804/33150 (epoch 11.771), train_loss = 1.19369085, grad/param norm = 1.5164e-01, time/batch = 14.9620s	
7805/33150 (epoch 11.772), train_loss = 1.24417534, grad/param norm = 1.7293e-01, time/batch = 15.1213s	
7806/33150 (epoch 11.774), train_loss = 1.35333581, grad/param norm = 1.6122e-01, time/batch = 18.0324s	
7807/33150 (epoch 11.775), train_loss = 1.23581178, grad/param norm = 1.8460e-01, time/batch = 18.7970s	
7808/33150 (epoch 11.777), train_loss = 1.27208338, grad/param norm = 1.7758e-01, time/batch = 18.3048s	
7809/33150 (epoch 11.778), train_loss = 1.18441700, grad/param norm = 1.4016e-01, time/batch = 18.5478s	
7810/33150 (epoch 11.780), train_loss = 1.05134766, grad/param norm = 1.4281e-01, time/batch = 18.1321s	
7811/33150 (epoch 11.781), train_loss = 1.15675954, grad/param norm = 1.4825e-01, time/batch = 16.6090s	
7812/33150 (epoch 11.783), train_loss = 1.17935310, grad/param norm = 1.3582e-01, time/batch = 15.8600s	
7813/33150 (epoch 11.784), train_loss = 1.13111035, grad/param norm = 1.5709e-01, time/batch = 19.0377s	
7814/33150 (epoch 11.786), train_loss = 1.12396209, grad/param norm = 1.3050e-01, time/batch = 17.5354s	
7815/33150 (epoch 11.787), train_loss = 1.12537121, grad/param norm = 1.4048e-01, time/batch = 17.5537s	
7816/33150 (epoch 11.789), train_loss = 0.99608890, grad/param norm = 1.2883e-01, time/batch = 19.6315s	
7817/33150 (epoch 11.790), train_loss = 0.97690741, grad/param norm = 1.1557e-01, time/batch = 17.7941s	
7818/33150 (epoch 11.792), train_loss = 1.22917154, grad/param norm = 1.6801e-01, time/batch = 16.1135s	
7819/33150 (epoch 11.793), train_loss = 1.15273278, grad/param norm = 1.5682e-01, time/batch = 17.2192s	
7820/33150 (epoch 11.795), train_loss = 1.09142735, grad/param norm = 1.6961e-01, time/batch = 19.0487s	
7821/33150 (epoch 11.796), train_loss = 1.09570236, grad/param norm = 1.5837e-01, time/batch = 15.6050s	
7822/33150 (epoch 11.798), train_loss = 1.10411353, grad/param norm = 1.2752e-01, time/batch = 15.6307s	
7823/33150 (epoch 11.799), train_loss = 0.98949462, grad/param norm = 1.4292e-01, time/batch = 18.7781s	
7824/33150 (epoch 11.801), train_loss = 1.17503008, grad/param norm = 1.4214e-01, time/batch = 17.4644s	
7825/33150 (epoch 11.802), train_loss = 1.07377556, grad/param norm = 1.4649e-01, time/batch = 16.3851s	
7826/33150 (epoch 11.804), train_loss = 1.12457477, grad/param norm = 1.4937e-01, time/batch = 18.8769s	
7827/33150 (epoch 11.805), train_loss = 1.14221939, grad/param norm = 1.5684e-01, time/batch = 19.4496s	
7828/33150 (epoch 11.807), train_loss = 1.10276303, grad/param norm = 1.4881e-01, time/batch = 16.3759s	
7829/33150 (epoch 11.808), train_loss = 1.22800847, grad/param norm = 1.6379e-01, time/batch = 18.0511s	
7830/33150 (epoch 11.810), train_loss = 1.13384874, grad/param norm = 1.4447e-01, time/batch = 18.2225s	
7831/33150 (epoch 11.811), train_loss = 1.20742934, grad/param norm = 1.5879e-01, time/batch = 15.3044s	
7832/33150 (epoch 11.813), train_loss = 1.13149949, grad/param norm = 1.3510e-01, time/batch = 15.1538s	
7833/33150 (epoch 11.814), train_loss = 1.17224836, grad/param norm = 1.6901e-01, time/batch = 16.6570s	
7834/33150 (epoch 11.816), train_loss = 1.12474401, grad/param norm = 1.4237e-01, time/batch = 15.8786s	
7835/33150 (epoch 11.817), train_loss = 1.23300863, grad/param norm = 1.5071e-01, time/batch = 15.4968s	
7836/33150 (epoch 11.819), train_loss = 1.13308133, grad/param norm = 1.4671e-01, time/batch = 15.9813s	
7837/33150 (epoch 11.821), train_loss = 1.00610529, grad/param norm = 1.3182e-01, time/batch = 17.5650s	
7838/33150 (epoch 11.822), train_loss = 1.06374112, grad/param norm = 1.4207e-01, time/batch = 17.9665s	
7839/33150 (epoch 11.824), train_loss = 1.12018122, grad/param norm = 1.5053e-01, time/batch = 17.1326s	
7840/33150 (epoch 11.825), train_loss = 1.16940853, grad/param norm = 1.5169e-01, time/batch = 15.9018s	
7841/33150 (epoch 11.827), train_loss = 1.24325056, grad/param norm = 1.9041e-01, time/batch = 18.7115s	
7842/33150 (epoch 11.828), train_loss = 1.03223174, grad/param norm = 1.4767e-01, time/batch = 15.6382s	
7843/33150 (epoch 11.830), train_loss = 1.21877177, grad/param norm = 1.4564e-01, time/batch = 15.3815s	
7844/33150 (epoch 11.831), train_loss = 1.09404859, grad/param norm = 1.5715e-01, time/batch = 15.6519s	
7845/33150 (epoch 11.833), train_loss = 1.04183154, grad/param norm = 1.4704e-01, time/batch = 17.9546s	
7846/33150 (epoch 11.834), train_loss = 1.30309157, grad/param norm = 1.6402e-01, time/batch = 15.4469s	
7847/33150 (epoch 11.836), train_loss = 1.25664583, grad/param norm = 1.6279e-01, time/batch = 17.4656s	
7848/33150 (epoch 11.837), train_loss = 1.16551691, grad/param norm = 1.5613e-01, time/batch = 16.4615s	
7849/33150 (epoch 11.839), train_loss = 1.26968349, grad/param norm = 1.9174e-01, time/batch = 15.9523s	
7850/33150 (epoch 11.840), train_loss = 1.22913788, grad/param norm = 1.5578e-01, time/batch = 18.1397s	
7851/33150 (epoch 11.842), train_loss = 1.34842042, grad/param norm = 1.8063e-01, time/batch = 18.0530s	
7852/33150 (epoch 11.843), train_loss = 1.28326931, grad/param norm = 1.6496e-01, time/batch = 17.2033s	
7853/33150 (epoch 11.845), train_loss = 1.12171391, grad/param norm = 1.5013e-01, time/batch = 16.9497s	
7854/33150 (epoch 11.846), train_loss = 1.39673215, grad/param norm = 1.9601e-01, time/batch = 18.7188s	
7855/33150 (epoch 11.848), train_loss = 1.24593220, grad/param norm = 1.5301e-01, time/batch = 18.8057s	
7856/33150 (epoch 11.849), train_loss = 1.24017737, grad/param norm = 1.6063e-01, time/batch = 16.4607s	
7857/33150 (epoch 11.851), train_loss = 1.27813848, grad/param norm = 1.6812e-01, time/batch = 16.1065s	
7858/33150 (epoch 11.852), train_loss = 1.32600591, grad/param norm = 1.4742e-01, time/batch = 15.8858s	
7859/33150 (epoch 11.854), train_loss = 1.18963908, grad/param norm = 1.5679e-01, time/batch = 17.6369s	
7860/33150 (epoch 11.855), train_loss = 1.00075226, grad/param norm = 1.3649e-01, time/batch = 16.8691s	
7861/33150 (epoch 11.857), train_loss = 0.99634473, grad/param norm = 1.3639e-01, time/batch = 17.8090s	
7862/33150 (epoch 11.858), train_loss = 1.10863194, grad/param norm = 1.4210e-01, time/batch = 16.5185s	
7863/33150 (epoch 11.860), train_loss = 1.04632022, grad/param norm = 1.3443e-01, time/batch = 15.7728s	
7864/33150 (epoch 11.861), train_loss = 1.08011986, grad/param norm = 1.3685e-01, time/batch = 15.7228s	
7865/33150 (epoch 11.863), train_loss = 1.20627542, grad/param norm = 1.3779e-01, time/batch = 17.5538s	
7866/33150 (epoch 11.864), train_loss = 1.27584217, grad/param norm = 1.4625e-01, time/batch = 17.8051s	
7867/33150 (epoch 11.866), train_loss = 1.19897511, grad/param norm = 1.5259e-01, time/batch = 16.8973s	
7868/33150 (epoch 11.867), train_loss = 1.20502325, grad/param norm = 1.3947e-01, time/batch = 16.6559s	
7869/33150 (epoch 11.869), train_loss = 1.24304727, grad/param norm = 1.5643e-01, time/batch = 18.2181s	
7870/33150 (epoch 11.870), train_loss = 1.22822380, grad/param norm = 1.6367e-01, time/batch = 16.7208s	
7871/33150 (epoch 11.872), train_loss = 1.16416272, grad/param norm = 1.6211e-01, time/batch = 17.4854s	
7872/33150 (epoch 11.873), train_loss = 0.98140916, grad/param norm = 1.3393e-01, time/batch = 17.2157s	
7873/33150 (epoch 11.875), train_loss = 1.34130789, grad/param norm = 1.6865e-01, time/batch = 19.7977s	
7874/33150 (epoch 11.876), train_loss = 1.06293963, grad/param norm = 1.5504e-01, time/batch = 15.6153s	
7875/33150 (epoch 11.878), train_loss = 1.03604105, grad/param norm = 1.3138e-01, time/batch = 18.5482s	
7876/33150 (epoch 11.879), train_loss = 1.08333200, grad/param norm = 1.5039e-01, time/batch = 17.9535s	
7877/33150 (epoch 11.881), train_loss = 1.10796920, grad/param norm = 1.4883e-01, time/batch = 17.8004s	
7878/33150 (epoch 11.882), train_loss = 0.99932385, grad/param norm = 1.2465e-01, time/batch = 18.7139s	
7879/33150 (epoch 11.884), train_loss = 1.16757228, grad/param norm = 1.6180e-01, time/batch = 17.8804s	
7880/33150 (epoch 11.885), train_loss = 0.92110602, grad/param norm = 1.4250e-01, time/batch = 18.2664s	
7881/33150 (epoch 11.887), train_loss = 1.35919194, grad/param norm = 1.7123e-01, time/batch = 16.7054s	
7882/33150 (epoch 11.888), train_loss = 1.20622729, grad/param norm = 1.5900e-01, time/batch = 16.8957s	
7883/33150 (epoch 11.890), train_loss = 1.12681346, grad/param norm = 1.5778e-01, time/batch = 17.5531s	
7884/33150 (epoch 11.891), train_loss = 1.06891747, grad/param norm = 1.4239e-01, time/batch = 15.2042s	
7885/33150 (epoch 11.893), train_loss = 1.21932995, grad/param norm = 1.5866e-01, time/batch = 18.2979s	
7886/33150 (epoch 11.894), train_loss = 1.23862142, grad/param norm = 1.5600e-01, time/batch = 17.6332s	
7887/33150 (epoch 11.896), train_loss = 1.12687319, grad/param norm = 1.4970e-01, time/batch = 16.6396s	
7888/33150 (epoch 11.897), train_loss = 1.19734807, grad/param norm = 1.4415e-01, time/batch = 16.5360s	
7889/33150 (epoch 11.899), train_loss = 1.04090876, grad/param norm = 1.6837e-01, time/batch = 17.1900s	
7890/33150 (epoch 11.900), train_loss = 1.45467594, grad/param norm = 1.6727e-01, time/batch = 18.0163s	
7891/33150 (epoch 11.902), train_loss = 1.33977944, grad/param norm = 1.5791e-01, time/batch = 16.6152s	
7892/33150 (epoch 11.903), train_loss = 1.17498890, grad/param norm = 1.4536e-01, time/batch = 16.1540s	
7893/33150 (epoch 11.905), train_loss = 1.19258741, grad/param norm = 1.4789e-01, time/batch = 17.1224s	
7894/33150 (epoch 11.906), train_loss = 1.26157122, grad/param norm = 1.6638e-01, time/batch = 16.6307s	
7895/33150 (epoch 11.908), train_loss = 1.31546012, grad/param norm = 1.6028e-01, time/batch = 16.4512s	
7896/33150 (epoch 11.910), train_loss = 1.25496106, grad/param norm = 1.4642e-01, time/batch = 18.5589s	
7897/33150 (epoch 11.911), train_loss = 1.00921284, grad/param norm = 1.2935e-01, time/batch = 17.7973s	
7898/33150 (epoch 11.913), train_loss = 1.09008565, grad/param norm = 1.4717e-01, time/batch = 15.4633s	
7899/33150 (epoch 11.914), train_loss = 1.25813340, grad/param norm = 1.7282e-01, time/batch = 14.7982s	
7900/33150 (epoch 11.916), train_loss = 1.08944757, grad/param norm = 1.5209e-01, time/batch = 15.4665s	
7901/33150 (epoch 11.917), train_loss = 1.29782596, grad/param norm = 1.7286e-01, time/batch = 16.3743s	
7902/33150 (epoch 11.919), train_loss = 1.34129378, grad/param norm = 1.7381e-01, time/batch = 15.9055s	
7903/33150 (epoch 11.920), train_loss = 1.25904682, grad/param norm = 1.5305e-01, time/batch = 16.0956s	
7904/33150 (epoch 11.922), train_loss = 1.35656545, grad/param norm = 1.7865e-01, time/batch = 16.0735s	
7905/33150 (epoch 11.923), train_loss = 1.17554825, grad/param norm = 1.6349e-01, time/batch = 17.4543s	
7906/33150 (epoch 11.925), train_loss = 1.20365111, grad/param norm = 1.3836e-01, time/batch = 18.2028s	
7907/33150 (epoch 11.926), train_loss = 1.14425511, grad/param norm = 1.3585e-01, time/batch = 18.8804s	
7908/33150 (epoch 11.928), train_loss = 1.14100277, grad/param norm = 1.5897e-01, time/batch = 17.5113s	
7909/33150 (epoch 11.929), train_loss = 1.24233328, grad/param norm = 1.4940e-01, time/batch = 17.0314s	
7910/33150 (epoch 11.931), train_loss = 1.33949864, grad/param norm = 1.7600e-01, time/batch = 17.7266s	
7911/33150 (epoch 11.932), train_loss = 1.19103448, grad/param norm = 1.7839e-01, time/batch = 17.6160s	
7912/33150 (epoch 11.934), train_loss = 1.20735241, grad/param norm = 1.4666e-01, time/batch = 15.9503s	
7913/33150 (epoch 11.935), train_loss = 1.29492896, grad/param norm = 1.5618e-01, time/batch = 16.3696s	
7914/33150 (epoch 11.937), train_loss = 1.32648661, grad/param norm = 1.5687e-01, time/batch = 15.7021s	
7915/33150 (epoch 11.938), train_loss = 1.26705798, grad/param norm = 1.4462e-01, time/batch = 15.2714s	
7916/33150 (epoch 11.940), train_loss = 1.47935859, grad/param norm = 1.6816e-01, time/batch = 14.9516s	
7917/33150 (epoch 11.941), train_loss = 1.17035117, grad/param norm = 1.4309e-01, time/batch = 14.9601s	
7918/33150 (epoch 11.943), train_loss = 1.08323984, grad/param norm = 1.7473e-01, time/batch = 16.3033s	
7919/33150 (epoch 11.944), train_loss = 1.31355328, grad/param norm = 1.7422e-01, time/batch = 15.2916s	
7920/33150 (epoch 11.946), train_loss = 0.97282428, grad/param norm = 1.3122e-01, time/batch = 15.2616s	
7921/33150 (epoch 11.947), train_loss = 1.22872271, grad/param norm = 1.4583e-01, time/batch = 15.9607s	
7922/33150 (epoch 11.949), train_loss = 1.33827947, grad/param norm = 1.5076e-01, time/batch = 16.6351s	
7923/33150 (epoch 11.950), train_loss = 1.23631020, grad/param norm = 1.5697e-01, time/batch = 16.0304s	
7924/33150 (epoch 11.952), train_loss = 1.08768539, grad/param norm = 1.4444e-01, time/batch = 16.5561s	
7925/33150 (epoch 11.953), train_loss = 1.13064088, grad/param norm = 1.4388e-01, time/batch = 15.3971s	
7926/33150 (epoch 11.955), train_loss = 1.05702076, grad/param norm = 1.4684e-01, time/batch = 16.9760s	
7927/33150 (epoch 11.956), train_loss = 1.24772960, grad/param norm = 1.4416e-01, time/batch = 15.3011s	
7928/33150 (epoch 11.958), train_loss = 1.04487611, grad/param norm = 1.4069e-01, time/batch = 15.9040s	
7929/33150 (epoch 11.959), train_loss = 1.09103681, grad/param norm = 1.5303e-01, time/batch = 17.3824s	
7930/33150 (epoch 11.961), train_loss = 1.04917212, grad/param norm = 1.4427e-01, time/batch = 16.5261s	
7931/33150 (epoch 11.962), train_loss = 1.02138911, grad/param norm = 1.3661e-01, time/batch = 17.6366s	
7932/33150 (epoch 11.964), train_loss = 1.19145582, grad/param norm = 1.5120e-01, time/batch = 18.2145s	
7933/33150 (epoch 11.965), train_loss = 1.16707923, grad/param norm = 1.4581e-01, time/batch = 16.5627s	
7934/33150 (epoch 11.967), train_loss = 1.18574323, grad/param norm = 1.5708e-01, time/batch = 16.6434s	
7935/33150 (epoch 11.968), train_loss = 0.99065179, grad/param norm = 1.2949e-01, time/batch = 18.0568s	
7936/33150 (epoch 11.970), train_loss = 1.12385183, grad/param norm = 1.4244e-01, time/batch = 19.0329s	
7937/33150 (epoch 11.971), train_loss = 1.19198114, grad/param norm = 1.6487e-01, time/batch = 16.9646s	
7938/33150 (epoch 11.973), train_loss = 1.37886381, grad/param norm = 1.6513e-01, time/batch = 18.5390s	
7939/33150 (epoch 11.974), train_loss = 1.33752409, grad/param norm = 1.6344e-01, time/batch = 17.9590s	
7940/33150 (epoch 11.976), train_loss = 1.22776469, grad/param norm = 1.4266e-01, time/batch = 16.6943s	
7941/33150 (epoch 11.977), train_loss = 1.32118799, grad/param norm = 1.6113e-01, time/batch = 17.0299s	
7942/33150 (epoch 11.979), train_loss = 1.30748065, grad/param norm = 1.7306e-01, time/batch = 15.9010s	
7943/33150 (epoch 11.980), train_loss = 1.33834358, grad/param norm = 1.5675e-01, time/batch = 17.7074s	
7944/33150 (epoch 11.982), train_loss = 1.17898870, grad/param norm = 1.8273e-01, time/batch = 16.0896s	
7945/33150 (epoch 11.983), train_loss = 1.03186241, grad/param norm = 1.4081e-01, time/batch = 17.0448s	
7946/33150 (epoch 11.985), train_loss = 1.20663387, grad/param norm = 1.3608e-01, time/batch = 16.8594s	
7947/33150 (epoch 11.986), train_loss = 1.03151416, grad/param norm = 1.4225e-01, time/batch = 17.7817s	
7948/33150 (epoch 11.988), train_loss = 1.12749482, grad/param norm = 1.5661e-01, time/batch = 15.1969s	
7949/33150 (epoch 11.989), train_loss = 1.06399572, grad/param norm = 1.5864e-01, time/batch = 16.3858s	
7950/33150 (epoch 11.991), train_loss = 1.26779919, grad/param norm = 2.0401e-01, time/batch = 16.5544s	
7951/33150 (epoch 11.992), train_loss = 1.05435906, grad/param norm = 1.5542e-01, time/batch = 16.5367s	
7952/33150 (epoch 11.994), train_loss = 1.15518775, grad/param norm = 1.6369e-01, time/batch = 15.7965s	
7953/33150 (epoch 11.995), train_loss = 1.10022065, grad/param norm = 1.4760e-01, time/batch = 16.4731s	
7954/33150 (epoch 11.997), train_loss = 1.18978588, grad/param norm = 1.5852e-01, time/batch = 17.8815s	
7955/33150 (epoch 11.998), train_loss = 0.94955349, grad/param norm = 1.4153e-01, time/batch = 15.6276s	
decayed learning rate by a factor 0.97 to 0.001825346	
7956/33150 (epoch 12.000), train_loss = 1.01495206, grad/param norm = 1.5266e-01, time/batch = 16.8978s	
7957/33150 (epoch 12.002), train_loss = 1.49568374, grad/param norm = 1.8157e-01, time/batch = 17.0500s	
7958/33150 (epoch 12.003), train_loss = 1.09319596, grad/param norm = 1.6024e-01, time/batch = 17.1433s	
7959/33150 (epoch 12.005), train_loss = 1.02275096, grad/param norm = 1.4312e-01, time/batch = 18.0441s	
7960/33150 (epoch 12.006), train_loss = 0.99675693, grad/param norm = 1.4313e-01, time/batch = 15.5537s	
7961/33150 (epoch 12.008), train_loss = 1.29561666, grad/param norm = 1.6596e-01, time/batch = 17.6199s	
7962/33150 (epoch 12.009), train_loss = 1.15679904, grad/param norm = 1.4820e-01, time/batch = 22.1483s	
7963/33150 (epoch 12.011), train_loss = 1.31341658, grad/param norm = 1.6158e-01, time/batch = 24.0529s	
7964/33150 (epoch 12.012), train_loss = 1.18148778, grad/param norm = 1.7201e-01, time/batch = 17.5455s	
7965/33150 (epoch 12.014), train_loss = 1.14433042, grad/param norm = 1.5941e-01, time/batch = 17.3693s	
7966/33150 (epoch 12.015), train_loss = 1.12062384, grad/param norm = 1.4708e-01, time/batch = 17.1421s	
7967/33150 (epoch 12.017), train_loss = 1.08941203, grad/param norm = 1.4717e-01, time/batch = 18.1105s	
7968/33150 (epoch 12.018), train_loss = 1.20049710, grad/param norm = 1.6243e-01, time/batch = 16.0495s	
7969/33150 (epoch 12.020), train_loss = 1.22644076, grad/param norm = 1.5850e-01, time/batch = 17.2201s	
7970/33150 (epoch 12.021), train_loss = 0.99700864, grad/param norm = 1.4713e-01, time/batch = 17.3956s	
7971/33150 (epoch 12.023), train_loss = 1.34243562, grad/param norm = 1.4373e-01, time/batch = 18.6441s	
7972/33150 (epoch 12.024), train_loss = 1.21039374, grad/param norm = 1.5475e-01, time/batch = 16.6489s	
7973/33150 (epoch 12.026), train_loss = 0.93468368, grad/param norm = 1.2406e-01, time/batch = 17.1498s	
7974/33150 (epoch 12.027), train_loss = 0.96189231, grad/param norm = 1.4031e-01, time/batch = 17.7948s	
7975/33150 (epoch 12.029), train_loss = 1.06851317, grad/param norm = 1.4047e-01, time/batch = 16.8173s	
7976/33150 (epoch 12.030), train_loss = 1.15250539, grad/param norm = 1.3064e-01, time/batch = 16.8099s	
7977/33150 (epoch 12.032), train_loss = 1.09622500, grad/param norm = 1.6304e-01, time/batch = 17.2477s	
7978/33150 (epoch 12.033), train_loss = 1.11129608, grad/param norm = 1.4322e-01, time/batch = 20.2068s	
7979/33150 (epoch 12.035), train_loss = 1.34009451, grad/param norm = 1.7077e-01, time/batch = 16.3775s	
7980/33150 (epoch 12.036), train_loss = 1.22436823, grad/param norm = 1.5647e-01, time/batch = 16.6172s	
7981/33150 (epoch 12.038), train_loss = 1.47401305, grad/param norm = 1.7936e-01, time/batch = 19.3034s	
7982/33150 (epoch 12.039), train_loss = 1.19334353, grad/param norm = 1.3414e-01, time/batch = 16.8648s	
7983/33150 (epoch 12.041), train_loss = 1.20732808, grad/param norm = 1.4842e-01, time/batch = 19.2154s	
7984/33150 (epoch 12.042), train_loss = 1.11712688, grad/param norm = 1.4312e-01, time/batch = 19.1209s	
7985/33150 (epoch 12.044), train_loss = 1.10175819, grad/param norm = 1.3695e-01, time/batch = 17.9627s	
7986/33150 (epoch 12.045), train_loss = 1.15220654, grad/param norm = 1.3968e-01, time/batch = 18.3079s	
7987/33150 (epoch 12.047), train_loss = 1.08982740, grad/param norm = 1.5538e-01, time/batch = 17.9774s	
7988/33150 (epoch 12.048), train_loss = 1.30556045, grad/param norm = 1.8044e-01, time/batch = 16.3852s	
7989/33150 (epoch 12.050), train_loss = 1.15954683, grad/param norm = 1.4793e-01, time/batch = 16.5581s	
7990/33150 (epoch 12.051), train_loss = 1.17473097, grad/param norm = 1.5134e-01, time/batch = 18.2989s	
7991/33150 (epoch 12.053), train_loss = 1.12305039, grad/param norm = 1.4443e-01, time/batch = 17.0597s	
7992/33150 (epoch 12.054), train_loss = 1.22852422, grad/param norm = 1.3583e-01, time/batch = 17.5451s	
7993/33150 (epoch 12.056), train_loss = 1.09583161, grad/param norm = 1.3597e-01, time/batch = 17.8939s	
7994/33150 (epoch 12.057), train_loss = 1.16044179, grad/param norm = 1.7645e-01, time/batch = 17.3049s	
7995/33150 (epoch 12.059), train_loss = 1.08013406, grad/param norm = 1.4952e-01, time/batch = 17.7816s	
7996/33150 (epoch 12.060), train_loss = 1.09181638, grad/param norm = 1.3790e-01, time/batch = 15.9587s	
7997/33150 (epoch 12.062), train_loss = 1.14532778, grad/param norm = 1.5171e-01, time/batch = 18.7061s	
7998/33150 (epoch 12.063), train_loss = 1.09872310, grad/param norm = 1.4379e-01, time/batch = 15.8019s	
7999/33150 (epoch 12.065), train_loss = 1.13929990, grad/param norm = 1.3093e-01, time/batch = 16.4667s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch12.07_1.5139.t7	
8000/33150 (epoch 12.066), train_loss = 1.07483405, grad/param norm = 1.4353e-01, time/batch = 17.7851s	
8001/33150 (epoch 12.068), train_loss = 1.35670230, grad/param norm = 1.7493e-01, time/batch = 18.1270s	
8002/33150 (epoch 12.069), train_loss = 1.24334425, grad/param norm = 1.7094e-01, time/batch = 15.9702s	
8003/33150 (epoch 12.071), train_loss = 1.21416288, grad/param norm = 1.4430e-01, time/batch = 16.9692s	
8004/33150 (epoch 12.072), train_loss = 1.10275225, grad/param norm = 1.4073e-01, time/batch = 19.0551s	
8005/33150 (epoch 12.074), train_loss = 1.00980916, grad/param norm = 1.4899e-01, time/batch = 16.3900s	
8006/33150 (epoch 12.075), train_loss = 1.09775684, grad/param norm = 1.5072e-01, time/batch = 18.5372s	
8007/33150 (epoch 12.077), train_loss = 1.20236621, grad/param norm = 1.8149e-01, time/batch = 17.3699s	
8008/33150 (epoch 12.078), train_loss = 1.35534982, grad/param norm = 1.8459e-01, time/batch = 17.3690s	
8009/33150 (epoch 12.080), train_loss = 1.27216484, grad/param norm = 1.4833e-01, time/batch = 16.2990s	
8010/33150 (epoch 12.081), train_loss = 1.07099148, grad/param norm = 1.5037e-01, time/batch = 18.2985s	
8011/33150 (epoch 12.083), train_loss = 0.85400151, grad/param norm = 1.5600e-01, time/batch = 17.8938s	
8012/33150 (epoch 12.084), train_loss = 1.02644892, grad/param norm = 1.6068e-01, time/batch = 16.8876s	
8013/33150 (epoch 12.086), train_loss = 1.09300619, grad/param norm = 1.5022e-01, time/batch = 17.2256s	
8014/33150 (epoch 12.087), train_loss = 1.02159165, grad/param norm = 1.3404e-01, time/batch = 16.8173s	
8015/33150 (epoch 12.089), train_loss = 1.05767486, grad/param norm = 1.5034e-01, time/batch = 16.3976s	
8016/33150 (epoch 12.090), train_loss = 1.08295898, grad/param norm = 1.5044e-01, time/batch = 16.0799s	
8017/33150 (epoch 12.092), train_loss = 1.11145153, grad/param norm = 1.4910e-01, time/batch = 15.7334s	
8018/33150 (epoch 12.094), train_loss = 1.23804191, grad/param norm = 1.7475e-01, time/batch = 17.7439s	
8019/33150 (epoch 12.095), train_loss = 0.99289066, grad/param norm = 1.3214e-01, time/batch = 16.0575s	
8020/33150 (epoch 12.097), train_loss = 1.13276006, grad/param norm = 1.5272e-01, time/batch = 15.2990s	
8021/33150 (epoch 12.098), train_loss = 1.39228066, grad/param norm = 1.6350e-01, time/batch = 18.3030s	
8022/33150 (epoch 12.100), train_loss = 1.35999654, grad/param norm = 1.6103e-01, time/batch = 17.3781s	
8023/33150 (epoch 12.101), train_loss = 1.07048309, grad/param norm = 1.6740e-01, time/batch = 17.1356s	
8024/33150 (epoch 12.103), train_loss = 1.19512291, grad/param norm = 1.5739e-01, time/batch = 18.0516s	
8025/33150 (epoch 12.104), train_loss = 1.09842567, grad/param norm = 1.6315e-01, time/batch = 17.9641s	
8026/33150 (epoch 12.106), train_loss = 1.33686922, grad/param norm = 1.6904e-01, time/batch = 16.1249s	
8027/33150 (epoch 12.107), train_loss = 1.41387261, grad/param norm = 1.8297e-01, time/batch = 17.1242s	
8028/33150 (epoch 12.109), train_loss = 1.10159041, grad/param norm = 1.4532e-01, time/batch = 18.6247s	
8029/33150 (epoch 12.110), train_loss = 1.24352551, grad/param norm = 1.5032e-01, time/batch = 17.8089s	
8030/33150 (epoch 12.112), train_loss = 1.06764899, grad/param norm = 1.4039e-01, time/batch = 16.0470s	
8031/33150 (epoch 12.113), train_loss = 1.14127881, grad/param norm = 1.6097e-01, time/batch = 17.7096s	
8032/33150 (epoch 12.115), train_loss = 1.35861075, grad/param norm = 1.7484e-01, time/batch = 18.5387s	
8033/33150 (epoch 12.116), train_loss = 1.07392888, grad/param norm = 1.4707e-01, time/batch = 15.3876s	
8034/33150 (epoch 12.118), train_loss = 1.21978937, grad/param norm = 1.6320e-01, time/batch = 19.1439s	
8035/33150 (epoch 12.119), train_loss = 1.21336514, grad/param norm = 1.6272e-01, time/batch = 16.7344s	
8036/33150 (epoch 12.121), train_loss = 1.10606671, grad/param norm = 1.4800e-01, time/batch = 16.7942s	
8037/33150 (epoch 12.122), train_loss = 1.38549662, grad/param norm = 1.9862e-01, time/batch = 16.4877s	
8038/33150 (epoch 12.124), train_loss = 0.93672104, grad/param norm = 1.2720e-01, time/batch = 18.7113s	
8039/33150 (epoch 12.125), train_loss = 1.25320283, grad/param norm = 1.5500e-01, time/batch = 18.6901s	
8040/33150 (epoch 12.127), train_loss = 1.09159034, grad/param norm = 1.4098e-01, time/batch = 17.0547s	
8041/33150 (epoch 12.128), train_loss = 1.17075679, grad/param norm = 1.5537e-01, time/batch = 15.1427s	
8042/33150 (epoch 12.130), train_loss = 1.19414536, grad/param norm = 1.3513e-01, time/batch = 17.1160s	
8043/33150 (epoch 12.131), train_loss = 1.38996479, grad/param norm = 1.7088e-01, time/batch = 16.8837s	
8044/33150 (epoch 12.133), train_loss = 1.08425697, grad/param norm = 1.3841e-01, time/batch = 16.1251s	
8045/33150 (epoch 12.134), train_loss = 1.29004906, grad/param norm = 1.5787e-01, time/batch = 17.4671s	
8046/33150 (epoch 12.136), train_loss = 1.19681486, grad/param norm = 1.7697e-01, time/batch = 16.0669s	
8047/33150 (epoch 12.137), train_loss = 1.24757374, grad/param norm = 1.5503e-01, time/batch = 16.9691s	
8048/33150 (epoch 12.139), train_loss = 1.23917947, grad/param norm = 1.7440e-01, time/batch = 16.5678s	
8049/33150 (epoch 12.140), train_loss = 1.32961259, grad/param norm = 1.6211e-01, time/batch = 18.6296s	
8050/33150 (epoch 12.142), train_loss = 1.25539303, grad/param norm = 1.6719e-01, time/batch = 17.4707s	
8051/33150 (epoch 12.143), train_loss = 1.19986103, grad/param norm = 1.6751e-01, time/batch = 17.4723s	
8052/33150 (epoch 12.145), train_loss = 1.16064316, grad/param norm = 1.7676e-01, time/batch = 16.9632s	
8053/33150 (epoch 12.146), train_loss = 1.32477951, grad/param norm = 1.8833e-01, time/batch = 17.7139s	
8054/33150 (epoch 12.148), train_loss = 1.26661651, grad/param norm = 1.5266e-01, time/batch = 16.8691s	
8055/33150 (epoch 12.149), train_loss = 1.19962959, grad/param norm = 1.4477e-01, time/batch = 17.0663s	
8056/33150 (epoch 12.151), train_loss = 1.36865187, grad/param norm = 1.5642e-01, time/batch = 18.5712s	
8057/33150 (epoch 12.152), train_loss = 1.12444743, grad/param norm = 1.4945e-01, time/batch = 16.1110s	
8058/33150 (epoch 12.154), train_loss = 1.13342066, grad/param norm = 1.5023e-01, time/batch = 17.3945s	
8059/33150 (epoch 12.155), train_loss = 1.03996178, grad/param norm = 1.4113e-01, time/batch = 15.8090s	
8060/33150 (epoch 12.157), train_loss = 1.09479267, grad/param norm = 1.6626e-01, time/batch = 18.3570s	
8061/33150 (epoch 12.158), train_loss = 1.07631359, grad/param norm = 1.5253e-01, time/batch = 17.1021s	
8062/33150 (epoch 12.160), train_loss = 1.25783289, grad/param norm = 1.5074e-01, time/batch = 15.1805s	
8063/33150 (epoch 12.161), train_loss = 1.11902243, grad/param norm = 1.7346e-01, time/batch = 17.4347s	
8064/33150 (epoch 12.163), train_loss = 1.11001802, grad/param norm = 1.4812e-01, time/batch = 15.8058s	
8065/33150 (epoch 12.164), train_loss = 1.24398331, grad/param norm = 1.6325e-01, time/batch = 16.8969s	
8066/33150 (epoch 12.166), train_loss = 1.13330153, grad/param norm = 1.6700e-01, time/batch = 17.8833s	
8067/33150 (epoch 12.167), train_loss = 1.18457331, grad/param norm = 1.5066e-01, time/batch = 17.7184s	
8068/33150 (epoch 12.169), train_loss = 1.27446540, grad/param norm = 2.0812e-01, time/batch = 15.2788s	
8069/33150 (epoch 12.170), train_loss = 1.09540333, grad/param norm = 1.7078e-01, time/batch = 15.5985s	
8070/33150 (epoch 12.172), train_loss = 1.27202545, grad/param norm = 1.7797e-01, time/batch = 15.2667s	
8071/33150 (epoch 12.173), train_loss = 1.25319723, grad/param norm = 1.8448e-01, time/batch = 15.5026s	
8072/33150 (epoch 12.175), train_loss = 1.09120123, grad/param norm = 1.5619e-01, time/batch = 17.6356s	
8073/33150 (epoch 12.176), train_loss = 1.20628026, grad/param norm = 1.6302e-01, time/batch = 16.4761s	
8074/33150 (epoch 12.178), train_loss = 1.37226295, grad/param norm = 1.5848e-01, time/batch = 17.4771s	
8075/33150 (epoch 12.179), train_loss = 1.21276764, grad/param norm = 1.4393e-01, time/batch = 15.8491s	
8076/33150 (epoch 12.181), train_loss = 1.18809370, grad/param norm = 1.5871e-01, time/batch = 17.4693s	
8077/33150 (epoch 12.183), train_loss = 1.14909151, grad/param norm = 1.6018e-01, time/batch = 18.6422s	
8078/33150 (epoch 12.184), train_loss = 1.36901556, grad/param norm = 1.6810e-01, time/batch = 17.2161s	
8079/33150 (epoch 12.186), train_loss = 1.26454777, grad/param norm = 1.4842e-01, time/batch = 15.3762s	
8080/33150 (epoch 12.187), train_loss = 1.20503315, grad/param norm = 1.5985e-01, time/batch = 15.4763s	
8081/33150 (epoch 12.189), train_loss = 0.98165836, grad/param norm = 1.5892e-01, time/batch = 17.2260s	
8082/33150 (epoch 12.190), train_loss = 1.06008599, grad/param norm = 1.5392e-01, time/batch = 16.1296s	
8083/33150 (epoch 12.192), train_loss = 1.15034123, grad/param norm = 1.6829e-01, time/batch = 17.7158s	
8084/33150 (epoch 12.193), train_loss = 1.22526487, grad/param norm = 1.5176e-01, time/batch = 19.0428s	
8085/33150 (epoch 12.195), train_loss = 1.47286263, grad/param norm = 1.7130e-01, time/batch = 16.8768s	
8086/33150 (epoch 12.196), train_loss = 1.32278198, grad/param norm = 1.5402e-01, time/batch = 16.3947s	
8087/33150 (epoch 12.198), train_loss = 1.01541083, grad/param norm = 1.5646e-01, time/batch = 17.2058s	
8088/33150 (epoch 12.199), train_loss = 1.27737811, grad/param norm = 1.7502e-01, time/batch = 16.3062s	
8089/33150 (epoch 12.201), train_loss = 1.03976395, grad/param norm = 1.2533e-01, time/batch = 16.4718s	
8090/33150 (epoch 12.202), train_loss = 0.97576417, grad/param norm = 1.3139e-01, time/batch = 18.6188s	
8091/33150 (epoch 12.204), train_loss = 1.18062153, grad/param norm = 1.5817e-01, time/batch = 18.6267s	
8092/33150 (epoch 12.205), train_loss = 1.23459098, grad/param norm = 1.5265e-01, time/batch = 18.2881s	
8093/33150 (epoch 12.207), train_loss = 1.19992634, grad/param norm = 1.4211e-01, time/batch = 17.6436s	
8094/33150 (epoch 12.208), train_loss = 1.22894633, grad/param norm = 1.5951e-01, time/batch = 18.8224s	
8095/33150 (epoch 12.210), train_loss = 1.06959508, grad/param norm = 1.3168e-01, time/batch = 18.6362s	
8096/33150 (epoch 12.211), train_loss = 1.22504580, grad/param norm = 1.6835e-01, time/batch = 16.3110s	
8097/33150 (epoch 12.213), train_loss = 1.26673539, grad/param norm = 1.5292e-01, time/batch = 17.3826s	
8098/33150 (epoch 12.214), train_loss = 1.12913632, grad/param norm = 1.5418e-01, time/batch = 19.7721s	
8099/33150 (epoch 12.216), train_loss = 1.11032092, grad/param norm = 1.5330e-01, time/batch = 17.2071s	
8100/33150 (epoch 12.217), train_loss = 1.09477880, grad/param norm = 1.3676e-01, time/batch = 17.1343s	
8101/33150 (epoch 12.219), train_loss = 1.06035792, grad/param norm = 1.5091e-01, time/batch = 17.2094s	
8102/33150 (epoch 12.220), train_loss = 1.10373682, grad/param norm = 1.3111e-01, time/batch = 17.8761s	
8103/33150 (epoch 12.222), train_loss = 1.25503061, grad/param norm = 1.6036e-01, time/batch = 17.0480s	
8104/33150 (epoch 12.223), train_loss = 1.13615641, grad/param norm = 1.4803e-01, time/batch = 15.9351s	
8105/33150 (epoch 12.225), train_loss = 1.33629630, grad/param norm = 1.5969e-01, time/batch = 18.4031s	
8106/33150 (epoch 12.226), train_loss = 1.12170287, grad/param norm = 1.4046e-01, time/batch = 15.3097s	
8107/33150 (epoch 12.228), train_loss = 1.14811837, grad/param norm = 1.4995e-01, time/batch = 17.4921s	
8108/33150 (epoch 12.229), train_loss = 1.12370146, grad/param norm = 1.5264e-01, time/batch = 16.2431s	
8109/33150 (epoch 12.231), train_loss = 1.29093204, grad/param norm = 1.6588e-01, time/batch = 17.5438s	
8110/33150 (epoch 12.232), train_loss = 1.21284057, grad/param norm = 1.7197e-01, time/batch = 15.4809s	
8111/33150 (epoch 12.234), train_loss = 1.15571785, grad/param norm = 1.6410e-01, time/batch = 17.1403s	
8112/33150 (epoch 12.235), train_loss = 1.19667233, grad/param norm = 1.6549e-01, time/batch = 18.4745s	
8113/33150 (epoch 12.237), train_loss = 1.15319471, grad/param norm = 1.6035e-01, time/batch = 16.8106s	
8114/33150 (epoch 12.238), train_loss = 1.26641989, grad/param norm = 1.8274e-01, time/batch = 16.9061s	
8115/33150 (epoch 12.240), train_loss = 1.17553634, grad/param norm = 1.4663e-01, time/batch = 15.3177s	
8116/33150 (epoch 12.241), train_loss = 1.32139326, grad/param norm = 1.6519e-01, time/batch = 18.4745s	
8117/33150 (epoch 12.243), train_loss = 1.27083968, grad/param norm = 1.6275e-01, time/batch = 17.6485s	
8118/33150 (epoch 12.244), train_loss = 1.15644759, grad/param norm = 1.4332e-01, time/batch = 16.2165s	
8119/33150 (epoch 12.246), train_loss = 1.22178891, grad/param norm = 1.5288e-01, time/batch = 18.3680s	
8120/33150 (epoch 12.247), train_loss = 1.05110544, grad/param norm = 1.4194e-01, time/batch = 17.2084s	
8121/33150 (epoch 12.249), train_loss = 1.27505205, grad/param norm = 1.5383e-01, time/batch = 16.3022s	
8122/33150 (epoch 12.250), train_loss = 1.21430401, grad/param norm = 1.3910e-01, time/batch = 16.8174s	
8123/33150 (epoch 12.252), train_loss = 1.21573709, grad/param norm = 1.2876e-01, time/batch = 17.9596s	
8124/33150 (epoch 12.253), train_loss = 1.23930691, grad/param norm = 1.5400e-01, time/batch = 18.2126s	
8125/33150 (epoch 12.255), train_loss = 1.16276719, grad/param norm = 1.3521e-01, time/batch = 17.7295s	
8126/33150 (epoch 12.256), train_loss = 1.21850096, grad/param norm = 1.5622e-01, time/batch = 19.9709s	
8127/33150 (epoch 12.258), train_loss = 1.13273180, grad/param norm = 1.7300e-01, time/batch = 18.2910s	
8128/33150 (epoch 12.259), train_loss = 1.01452678, grad/param norm = 1.4376e-01, time/batch = 17.1385s	
8129/33150 (epoch 12.261), train_loss = 1.03424058, grad/param norm = 1.4085e-01, time/batch = 17.3853s	
8130/33150 (epoch 12.262), train_loss = 1.22703065, grad/param norm = 1.5694e-01, time/batch = 16.9609s	
8131/33150 (epoch 12.264), train_loss = 0.93414711, grad/param norm = 1.3843e-01, time/batch = 18.9570s	
8132/33150 (epoch 12.265), train_loss = 1.22916196, grad/param norm = 1.6527e-01, time/batch = 16.3672s	
8133/33150 (epoch 12.267), train_loss = 1.29393134, grad/param norm = 1.7086e-01, time/batch = 18.1407s	
8134/33150 (epoch 12.268), train_loss = 1.21314350, grad/param norm = 1.5056e-01, time/batch = 18.3861s	
8135/33150 (epoch 12.270), train_loss = 1.36371914, grad/param norm = 1.6081e-01, time/batch = 17.5575s	
8136/33150 (epoch 12.271), train_loss = 1.30940289, grad/param norm = 1.6007e-01, time/batch = 18.1345s	
8137/33150 (epoch 12.273), train_loss = 1.30769935, grad/param norm = 1.5448e-01, time/batch = 15.8107s	
8138/33150 (epoch 12.275), train_loss = 1.32213611, grad/param norm = 1.6894e-01, time/batch = 17.8947s	
8139/33150 (epoch 12.276), train_loss = 1.14554465, grad/param norm = 1.4007e-01, time/batch = 17.3698s	
8140/33150 (epoch 12.278), train_loss = 1.24659218, grad/param norm = 1.5193e-01, time/batch = 17.7903s	
8141/33150 (epoch 12.279), train_loss = 1.16251684, grad/param norm = 1.4078e-01, time/batch = 19.0263s	
8142/33150 (epoch 12.281), train_loss = 1.22878123, grad/param norm = 1.4856e-01, time/batch = 17.0523s	
8143/33150 (epoch 12.282), train_loss = 1.17153139, grad/param norm = 1.3720e-01, time/batch = 18.9430s	
8144/33150 (epoch 12.284), train_loss = 1.11445784, grad/param norm = 1.3622e-01, time/batch = 15.9781s	
8145/33150 (epoch 12.285), train_loss = 1.21409705, grad/param norm = 1.4757e-01, time/batch = 17.3080s	
8146/33150 (epoch 12.287), train_loss = 1.11487996, grad/param norm = 1.3966e-01, time/batch = 19.8729s	
8147/33150 (epoch 12.288), train_loss = 1.34793979, grad/param norm = 1.6177e-01, time/batch = 16.5450s	
8148/33150 (epoch 12.290), train_loss = 1.01829981, grad/param norm = 1.5433e-01, time/batch = 16.9581s	
8149/33150 (epoch 12.291), train_loss = 1.01929789, grad/param norm = 1.6508e-01, time/batch = 18.7035s	
8150/33150 (epoch 12.293), train_loss = 1.25887425, grad/param norm = 1.5592e-01, time/batch = 17.6074s	
8151/33150 (epoch 12.294), train_loss = 0.90393033, grad/param norm = 1.4021e-01, time/batch = 17.8091s	
8152/33150 (epoch 12.296), train_loss = 1.13249156, grad/param norm = 1.4404e-01, time/batch = 15.9677s	
8153/33150 (epoch 12.297), train_loss = 1.08786881, grad/param norm = 1.4868e-01, time/batch = 17.7989s	
8154/33150 (epoch 12.299), train_loss = 1.11645554, grad/param norm = 1.5390e-01, time/batch = 17.9532s	
8155/33150 (epoch 12.300), train_loss = 1.10633047, grad/param norm = 1.3129e-01, time/batch = 17.7963s	
8156/33150 (epoch 12.302), train_loss = 1.10803204, grad/param norm = 1.4149e-01, time/batch = 18.8068s	
8157/33150 (epoch 12.303), train_loss = 1.16197132, grad/param norm = 1.4655e-01, time/batch = 17.7954s	
8158/33150 (epoch 12.305), train_loss = 1.22818700, grad/param norm = 1.4563e-01, time/batch = 18.7903s	
8159/33150 (epoch 12.306), train_loss = 1.23064177, grad/param norm = 1.6958e-01, time/batch = 18.3032s	
8160/33150 (epoch 12.308), train_loss = 1.41030460, grad/param norm = 1.6048e-01, time/batch = 23.3942s	
8161/33150 (epoch 12.309), train_loss = 1.00510453, grad/param norm = 1.3035e-01, time/batch = 26.6284s	
8162/33150 (epoch 12.311), train_loss = 1.14337713, grad/param norm = 1.4386e-01, time/batch = 18.8676s	
8163/33150 (epoch 12.312), train_loss = 0.94027117, grad/param norm = 1.4606e-01, time/batch = 16.5431s	
8164/33150 (epoch 12.314), train_loss = 1.16508684, grad/param norm = 1.4776e-01, time/batch = 19.8015s	
8165/33150 (epoch 12.315), train_loss = 1.24520789, grad/param norm = 1.5509e-01, time/batch = 18.6196s	
8166/33150 (epoch 12.317), train_loss = 0.92186091, grad/param norm = 1.1895e-01, time/batch = 16.6057s	
8167/33150 (epoch 12.318), train_loss = 1.04695946, grad/param norm = 1.4061e-01, time/batch = 17.1297s	
8168/33150 (epoch 12.320), train_loss = 1.00542917, grad/param norm = 1.3620e-01, time/batch = 19.8698s	
8169/33150 (epoch 12.321), train_loss = 1.08795608, grad/param norm = 1.3886e-01, time/batch = 15.3070s	
8170/33150 (epoch 12.323), train_loss = 1.16239789, grad/param norm = 1.4575e-01, time/batch = 17.9791s	
8171/33150 (epoch 12.324), train_loss = 1.25585847, grad/param norm = 1.8075e-01, time/batch = 16.9777s	
8172/33150 (epoch 12.326), train_loss = 1.16170627, grad/param norm = 1.3408e-01, time/batch = 18.3065s	
8173/33150 (epoch 12.327), train_loss = 1.27684666, grad/param norm = 1.4420e-01, time/batch = 16.2159s	
8174/33150 (epoch 12.329), train_loss = 1.21963044, grad/param norm = 1.5381e-01, time/batch = 16.1505s	
8175/33150 (epoch 12.330), train_loss = 1.17398640, grad/param norm = 1.6536e-01, time/batch = 18.1451s	
8176/33150 (epoch 12.332), train_loss = 1.15181273, grad/param norm = 1.2793e-01, time/batch = 16.9761s	
8177/33150 (epoch 12.333), train_loss = 1.20409769, grad/param norm = 1.3522e-01, time/batch = 16.2383s	
8178/33150 (epoch 12.335), train_loss = 1.10798856, grad/param norm = 1.4632e-01, time/batch = 15.6344s	
8179/33150 (epoch 12.336), train_loss = 1.08734544, grad/param norm = 1.5176e-01, time/batch = 17.9798s	
8180/33150 (epoch 12.338), train_loss = 0.94919107, grad/param norm = 1.4512e-01, time/batch = 17.5406s	
8181/33150 (epoch 12.339), train_loss = 1.28506789, grad/param norm = 1.6228e-01, time/batch = 16.4732s	
8182/33150 (epoch 12.341), train_loss = 1.31325251, grad/param norm = 1.8205e-01, time/batch = 18.4789s	
8183/33150 (epoch 12.342), train_loss = 1.02062448, grad/param norm = 1.5019e-01, time/batch = 16.7092s	
8184/33150 (epoch 12.344), train_loss = 1.21137076, grad/param norm = 1.7466e-01, time/batch = 17.2164s	
8185/33150 (epoch 12.345), train_loss = 1.09350212, grad/param norm = 1.6335e-01, time/batch = 18.1309s	
8186/33150 (epoch 12.347), train_loss = 0.92058165, grad/param norm = 1.2885e-01, time/batch = 18.4710s	
8187/33150 (epoch 12.348), train_loss = 1.17853416, grad/param norm = 1.4379e-01, time/batch = 15.8895s	
8188/33150 (epoch 12.350), train_loss = 1.11044576, grad/param norm = 1.6851e-01, time/batch = 16.8792s	
8189/33150 (epoch 12.351), train_loss = 1.25287146, grad/param norm = 1.5717e-01, time/batch = 18.7108s	
8190/33150 (epoch 12.353), train_loss = 1.27446866, grad/param norm = 1.7978e-01, time/batch = 17.4660s	
8191/33150 (epoch 12.354), train_loss = 1.43664736, grad/param norm = 1.5956e-01, time/batch = 16.5729s	
8192/33150 (epoch 12.356), train_loss = 1.27690955, grad/param norm = 1.6428e-01, time/batch = 17.6442s	
8193/33150 (epoch 12.357), train_loss = 1.25428238, grad/param norm = 1.6304e-01, time/batch = 18.8012s	
8194/33150 (epoch 12.359), train_loss = 1.19540690, grad/param norm = 1.4671e-01, time/batch = 17.1128s	
8195/33150 (epoch 12.360), train_loss = 1.25418389, grad/param norm = 1.6910e-01, time/batch = 16.7079s	
8196/33150 (epoch 12.362), train_loss = 1.26211560, grad/param norm = 1.6164e-01, time/batch = 16.9786s	
8197/33150 (epoch 12.363), train_loss = 1.16239002, grad/param norm = 1.3998e-01, time/batch = 18.8780s	
8198/33150 (epoch 12.365), train_loss = 1.15101803, grad/param norm = 1.3853e-01, time/batch = 17.6548s	
8199/33150 (epoch 12.367), train_loss = 1.06344837, grad/param norm = 1.4133e-01, time/batch = 18.5448s	
8200/33150 (epoch 12.368), train_loss = 1.16311704, grad/param norm = 1.5215e-01, time/batch = 17.4641s	
8201/33150 (epoch 12.370), train_loss = 1.19791151, grad/param norm = 1.5955e-01, time/batch = 17.1366s	
8202/33150 (epoch 12.371), train_loss = 1.03502245, grad/param norm = 1.4732e-01, time/batch = 18.2360s	
8203/33150 (epoch 12.373), train_loss = 1.21322994, grad/param norm = 1.6322e-01, time/batch = 18.0661s	
8204/33150 (epoch 12.374), train_loss = 1.14734781, grad/param norm = 1.4721e-01, time/batch = 16.8112s	
8205/33150 (epoch 12.376), train_loss = 1.28869065, grad/param norm = 1.5137e-01, time/batch = 16.2987s	
8206/33150 (epoch 12.377), train_loss = 1.12022839, grad/param norm = 1.4996e-01, time/batch = 17.7111s	
8207/33150 (epoch 12.379), train_loss = 1.25698561, grad/param norm = 1.6081e-01, time/batch = 18.2087s	
8208/33150 (epoch 12.380), train_loss = 1.25190050, grad/param norm = 1.4710e-01, time/batch = 16.4821s	
8209/33150 (epoch 12.382), train_loss = 1.07495452, grad/param norm = 1.4946e-01, time/batch = 18.7038s	
8210/33150 (epoch 12.383), train_loss = 1.06263528, grad/param norm = 1.4284e-01, time/batch = 17.9805s	
8211/33150 (epoch 12.385), train_loss = 1.18683125, grad/param norm = 1.6187e-01, time/batch = 16.2806s	
8212/33150 (epoch 12.386), train_loss = 1.02374385, grad/param norm = 1.3563e-01, time/batch = 18.2866s	
8213/33150 (epoch 12.388), train_loss = 1.14095322, grad/param norm = 1.4063e-01, time/batch = 20.0328s	
8214/33150 (epoch 12.389), train_loss = 1.10105185, grad/param norm = 1.3710e-01, time/batch = 17.6284s	
8215/33150 (epoch 12.391), train_loss = 1.32893170, grad/param norm = 1.4895e-01, time/batch = 16.3639s	
8216/33150 (epoch 12.392), train_loss = 1.12418991, grad/param norm = 1.4425e-01, time/batch = 17.5307s	
8217/33150 (epoch 12.394), train_loss = 1.02667050, grad/param norm = 1.1925e-01, time/batch = 16.9464s	
8218/33150 (epoch 12.395), train_loss = 1.04536970, grad/param norm = 1.5219e-01, time/batch = 18.0281s	
8219/33150 (epoch 12.397), train_loss = 0.87929687, grad/param norm = 1.3721e-01, time/batch = 15.4289s	
8220/33150 (epoch 12.398), train_loss = 1.16855022, grad/param norm = 1.6516e-01, time/batch = 15.5312s	
8221/33150 (epoch 12.400), train_loss = 1.09327914, grad/param norm = 1.3347e-01, time/batch = 15.8670s	
8222/33150 (epoch 12.401), train_loss = 0.98507414, grad/param norm = 1.3981e-01, time/batch = 17.7103s	
8223/33150 (epoch 12.403), train_loss = 1.05146165, grad/param norm = 1.4012e-01, time/batch = 16.2071s	
8224/33150 (epoch 12.404), train_loss = 1.14022123, grad/param norm = 1.4705e-01, time/batch = 18.5914s	
8225/33150 (epoch 12.406), train_loss = 1.04611947, grad/param norm = 1.1524e-01, time/batch = 16.9236s	
8226/33150 (epoch 12.407), train_loss = 1.02636548, grad/param norm = 1.3478e-01, time/batch = 17.2111s	
8227/33150 (epoch 12.409), train_loss = 0.94539281, grad/param norm = 1.3113e-01, time/batch = 17.8740s	
8228/33150 (epoch 12.410), train_loss = 1.19237651, grad/param norm = 1.5231e-01, time/batch = 15.7996s	
8229/33150 (epoch 12.412), train_loss = 1.18782044, grad/param norm = 1.4742e-01, time/batch = 16.8684s	
8230/33150 (epoch 12.413), train_loss = 1.09934921, grad/param norm = 1.5420e-01, time/batch = 16.8833s	
8231/33150 (epoch 12.415), train_loss = 1.25283864, grad/param norm = 1.4300e-01, time/batch = 18.7095s	
8232/33150 (epoch 12.416), train_loss = 1.06945908, grad/param norm = 1.3267e-01, time/batch = 16.8898s	
8233/33150 (epoch 12.418), train_loss = 1.34089993, grad/param norm = 1.8230e-01, time/batch = 17.3854s	
8234/33150 (epoch 12.419), train_loss = 1.09258500, grad/param norm = 1.5562e-01, time/batch = 17.9719s	
8235/33150 (epoch 12.421), train_loss = 1.17550997, grad/param norm = 1.7153e-01, time/batch = 15.8828s	
8236/33150 (epoch 12.422), train_loss = 1.09613413, grad/param norm = 1.4161e-01, time/batch = 16.7931s	
8237/33150 (epoch 12.424), train_loss = 1.09161780, grad/param norm = 1.4495e-01, time/batch = 18.0580s	
8238/33150 (epoch 12.425), train_loss = 1.13218538, grad/param norm = 1.4462e-01, time/batch = 16.4703s	
8239/33150 (epoch 12.427), train_loss = 1.11660345, grad/param norm = 1.4176e-01, time/batch = 16.5457s	
8240/33150 (epoch 12.428), train_loss = 1.16555328, grad/param norm = 1.5741e-01, time/batch = 17.3168s	
8241/33150 (epoch 12.430), train_loss = 1.19796226, grad/param norm = 1.6212e-01, time/batch = 15.6436s	
8242/33150 (epoch 12.431), train_loss = 1.25211986, grad/param norm = 1.7434e-01, time/batch = 15.0498s	
8243/33150 (epoch 12.433), train_loss = 1.11880569, grad/param norm = 1.3602e-01, time/batch = 14.8460s	
8244/33150 (epoch 12.434), train_loss = 1.02492738, grad/param norm = 1.4738e-01, time/batch = 16.8864s	
8245/33150 (epoch 12.436), train_loss = 1.02106475, grad/param norm = 1.5608e-01, time/batch = 17.9754s	
8246/33150 (epoch 12.437), train_loss = 1.15328916, grad/param norm = 1.7617e-01, time/batch = 16.1392s	
8247/33150 (epoch 12.439), train_loss = 1.25750474, grad/param norm = 1.5919e-01, time/batch = 17.5469s	
8248/33150 (epoch 12.440), train_loss = 1.26316857, grad/param norm = 1.5292e-01, time/batch = 16.4645s	
8249/33150 (epoch 12.442), train_loss = 1.02536947, grad/param norm = 1.4844e-01, time/batch = 15.8819s	
8250/33150 (epoch 12.443), train_loss = 1.27429381, grad/param norm = 1.5909e-01, time/batch = 16.5604s	
8251/33150 (epoch 12.445), train_loss = 1.15837781, grad/param norm = 1.5995e-01, time/batch = 15.7847s	
8252/33150 (epoch 12.446), train_loss = 1.16992595, grad/param norm = 1.7869e-01, time/batch = 18.1049s	
8253/33150 (epoch 12.448), train_loss = 1.24800779, grad/param norm = 1.5674e-01, time/batch = 16.5415s	
8254/33150 (epoch 12.449), train_loss = 1.15520536, grad/param norm = 1.4557e-01, time/batch = 17.2144s	
8255/33150 (epoch 12.451), train_loss = 1.23536315, grad/param norm = 1.6508e-01, time/batch = 16.9736s	
8256/33150 (epoch 12.452), train_loss = 1.42917774, grad/param norm = 1.6825e-01, time/batch = 16.2957s	
8257/33150 (epoch 12.454), train_loss = 1.12757484, grad/param norm = 1.4627e-01, time/batch = 15.5569s	
8258/33150 (epoch 12.456), train_loss = 0.96388467, grad/param norm = 1.3215e-01, time/batch = 15.9726s	
8259/33150 (epoch 12.457), train_loss = 1.15571500, grad/param norm = 1.4943e-01, time/batch = 17.3178s	
8260/33150 (epoch 12.459), train_loss = 1.32615684, grad/param norm = 1.8408e-01, time/batch = 16.5603s	
8261/33150 (epoch 12.460), train_loss = 1.19162258, grad/param norm = 1.3695e-01, time/batch = 16.9774s	
8262/33150 (epoch 12.462), train_loss = 1.27027795, grad/param norm = 1.8071e-01, time/batch = 16.6403s	
8263/33150 (epoch 12.463), train_loss = 1.45597660, grad/param norm = 2.1124e-01, time/batch = 16.0664s	
8264/33150 (epoch 12.465), train_loss = 1.08720455, grad/param norm = 1.4013e-01, time/batch = 15.3441s	
8265/33150 (epoch 12.466), train_loss = 1.08813763, grad/param norm = 1.3823e-01, time/batch = 15.5342s	
8266/33150 (epoch 12.468), train_loss = 1.46952810, grad/param norm = 1.5845e-01, time/batch = 15.7913s	
8267/33150 (epoch 12.469), train_loss = 1.18181179, grad/param norm = 1.5874e-01, time/batch = 16.7202s	
8268/33150 (epoch 12.471), train_loss = 1.11820377, grad/param norm = 1.4432e-01, time/batch = 16.0642s	
8269/33150 (epoch 12.472), train_loss = 1.14212876, grad/param norm = 1.4207e-01, time/batch = 15.1409s	
8270/33150 (epoch 12.474), train_loss = 1.28989988, grad/param norm = 2.0118e-01, time/batch = 16.8995s	
8271/33150 (epoch 12.475), train_loss = 1.44499520, grad/param norm = 1.6691e-01, time/batch = 15.2483s	
8272/33150 (epoch 12.477), train_loss = 1.24823734, grad/param norm = 1.6698e-01, time/batch = 16.0450s	
8273/33150 (epoch 12.478), train_loss = 1.28543647, grad/param norm = 1.4493e-01, time/batch = 17.7263s	
8274/33150 (epoch 12.480), train_loss = 1.10280148, grad/param norm = 1.4556e-01, time/batch = 17.8136s	
8275/33150 (epoch 12.481), train_loss = 1.00305585, grad/param norm = 1.5472e-01, time/batch = 15.4699s	
8276/33150 (epoch 12.483), train_loss = 1.11542821, grad/param norm = 1.4799e-01, time/batch = 16.8702s	
8277/33150 (epoch 12.484), train_loss = 1.10930881, grad/param norm = 1.5790e-01, time/batch = 18.5379s	
8278/33150 (epoch 12.486), train_loss = 1.12274504, grad/param norm = 1.5609e-01, time/batch = 15.9795s	
8279/33150 (epoch 12.487), train_loss = 1.21573110, grad/param norm = 1.5895e-01, time/batch = 16.8202s	
8280/33150 (epoch 12.489), train_loss = 1.17118219, grad/param norm = 1.5054e-01, time/batch = 19.6382s	
8281/33150 (epoch 12.490), train_loss = 1.00173010, grad/param norm = 1.3617e-01, time/batch = 16.1110s	
8282/33150 (epoch 12.492), train_loss = 1.10571012, grad/param norm = 1.6146e-01, time/batch = 15.9533s	
8283/33150 (epoch 12.493), train_loss = 1.26882936, grad/param norm = 1.7575e-01, time/batch = 18.2786s	
8284/33150 (epoch 12.495), train_loss = 1.27363070, grad/param norm = 1.5661e-01, time/batch = 18.9751s	
8285/33150 (epoch 12.496), train_loss = 1.07995800, grad/param norm = 1.4436e-01, time/batch = 16.6350s	
8286/33150 (epoch 12.498), train_loss = 1.27797594, grad/param norm = 1.9077e-01, time/batch = 18.1423s	
8287/33150 (epoch 12.499), train_loss = 1.34086213, grad/param norm = 1.6282e-01, time/batch = 16.0447s	
8288/33150 (epoch 12.501), train_loss = 1.20706088, grad/param norm = 1.4447e-01, time/batch = 18.3160s	
8289/33150 (epoch 12.502), train_loss = 1.33186684, grad/param norm = 1.6710e-01, time/batch = 16.7167s	
8290/33150 (epoch 12.504), train_loss = 1.22995653, grad/param norm = 1.6537e-01, time/batch = 15.2952s	
8291/33150 (epoch 12.505), train_loss = 1.40082529, grad/param norm = 1.8288e-01, time/batch = 18.9581s	
8292/33150 (epoch 12.507), train_loss = 1.11013119, grad/param norm = 1.4713e-01, time/batch = 15.9683s	
8293/33150 (epoch 12.508), train_loss = 1.11084136, grad/param norm = 1.4802e-01, time/batch = 18.7096s	
8294/33150 (epoch 12.510), train_loss = 1.18759717, grad/param norm = 1.5943e-01, time/batch = 17.5415s	
8295/33150 (epoch 12.511), train_loss = 1.35481493, grad/param norm = 1.6573e-01, time/batch = 16.5444s	
8296/33150 (epoch 12.513), train_loss = 1.21808041, grad/param norm = 1.6747e-01, time/batch = 17.3853s	
8297/33150 (epoch 12.514), train_loss = 0.98477871, grad/param norm = 1.4350e-01, time/batch = 17.6451s	
8298/33150 (epoch 12.516), train_loss = 1.30646328, grad/param norm = 1.8949e-01, time/batch = 19.8648s	
8299/33150 (epoch 12.517), train_loss = 1.29006354, grad/param norm = 1.5239e-01, time/batch = 16.8743s	
8300/33150 (epoch 12.519), train_loss = 1.08575754, grad/param norm = 1.3949e-01, time/batch = 17.4544s	
8301/33150 (epoch 12.520), train_loss = 1.18628419, grad/param norm = 1.4266e-01, time/batch = 19.8699s	
8302/33150 (epoch 12.522), train_loss = 1.34136337, grad/param norm = 1.9320e-01, time/batch = 17.7092s	
8303/33150 (epoch 12.523), train_loss = 1.06226750, grad/param norm = 1.5342e-01, time/batch = 17.9494s	
8304/33150 (epoch 12.525), train_loss = 1.22079247, grad/param norm = 1.5905e-01, time/batch = 17.1411s	
8305/33150 (epoch 12.526), train_loss = 1.08250747, grad/param norm = 1.4831e-01, time/batch = 18.2111s	
8306/33150 (epoch 12.528), train_loss = 1.24176987, grad/param norm = 1.5832e-01, time/batch = 16.4599s	
8307/33150 (epoch 12.529), train_loss = 1.21344244, grad/param norm = 1.5046e-01, time/batch = 16.7793s	
8308/33150 (epoch 12.531), train_loss = 1.01483907, grad/param norm = 1.4948e-01, time/batch = 18.8030s	
8309/33150 (epoch 12.532), train_loss = 1.19261593, grad/param norm = 1.5961e-01, time/batch = 16.8084s	
8310/33150 (epoch 12.534), train_loss = 1.11247449, grad/param norm = 1.3631e-01, time/batch = 17.3994s	
8311/33150 (epoch 12.535), train_loss = 1.08171685, grad/param norm = 1.5828e-01, time/batch = 19.7948s	
8312/33150 (epoch 12.537), train_loss = 1.28340061, grad/param norm = 1.5532e-01, time/batch = 15.7323s	
8313/33150 (epoch 12.538), train_loss = 1.12996154, grad/param norm = 1.5437e-01, time/batch = 17.4047s	
8314/33150 (epoch 12.540), train_loss = 1.01278762, grad/param norm = 1.4137e-01, time/batch = 17.2450s	
8315/33150 (epoch 12.541), train_loss = 1.27372157, grad/param norm = 1.7546e-01, time/batch = 18.4686s	
8316/33150 (epoch 12.543), train_loss = 1.21808847, grad/param norm = 1.4617e-01, time/batch = 16.4568s	
8317/33150 (epoch 12.544), train_loss = 1.19550696, grad/param norm = 1.4748e-01, time/batch = 17.1384s	
8318/33150 (epoch 12.546), train_loss = 1.32193686, grad/param norm = 1.6923e-01, time/batch = 17.3976s	
8319/33150 (epoch 12.548), train_loss = 1.22645361, grad/param norm = 1.6365e-01, time/batch = 18.3120s	
8320/33150 (epoch 12.549), train_loss = 1.15632624, grad/param norm = 1.5037e-01, time/batch = 18.0416s	
8321/33150 (epoch 12.551), train_loss = 1.07345829, grad/param norm = 1.4142e-01, time/batch = 15.6512s	
8322/33150 (epoch 12.552), train_loss = 0.95401862, grad/param norm = 1.2339e-01, time/batch = 18.7955s	
8323/33150 (epoch 12.554), train_loss = 1.21414339, grad/param norm = 1.4641e-01, time/batch = 15.4786s	
8324/33150 (epoch 12.555), train_loss = 1.36897871, grad/param norm = 1.8170e-01, time/batch = 16.7318s	
8325/33150 (epoch 12.557), train_loss = 0.99407129, grad/param norm = 1.3652e-01, time/batch = 18.7156s	
8326/33150 (epoch 12.558), train_loss = 1.26361066, grad/param norm = 1.9062e-01, time/batch = 15.9847s	
8327/33150 (epoch 12.560), train_loss = 1.10630035, grad/param norm = 1.4335e-01, time/batch = 16.7468s	
8328/33150 (epoch 12.561), train_loss = 0.98913426, grad/param norm = 1.4039e-01, time/batch = 16.3107s	
8329/33150 (epoch 12.563), train_loss = 1.26751799, grad/param norm = 1.9470e-01, time/batch = 17.4716s	
8330/33150 (epoch 12.564), train_loss = 1.35378443, grad/param norm = 1.6511e-01, time/batch = 16.8055s	
8331/33150 (epoch 12.566), train_loss = 1.17941211, grad/param norm = 1.5226e-01, time/batch = 17.3831s	
8332/33150 (epoch 12.567), train_loss = 1.04480320, grad/param norm = 1.3447e-01, time/batch = 16.9895s	
8333/33150 (epoch 12.569), train_loss = 1.18372619, grad/param norm = 1.5051e-01, time/batch = 16.4059s	
8334/33150 (epoch 12.570), train_loss = 1.21905468, grad/param norm = 1.4671e-01, time/batch = 15.6262s	
8335/33150 (epoch 12.572), train_loss = 1.07712603, grad/param norm = 1.4805e-01, time/batch = 16.8998s	
8336/33150 (epoch 12.573), train_loss = 0.94782997, grad/param norm = 1.2522e-01, time/batch = 18.7225s	
8337/33150 (epoch 12.575), train_loss = 1.15194405, grad/param norm = 1.6393e-01, time/batch = 17.2127s	
8338/33150 (epoch 12.576), train_loss = 0.97147316, grad/param norm = 1.2406e-01, time/batch = 18.9604s	
8339/33150 (epoch 12.578), train_loss = 1.09763224, grad/param norm = 1.3556e-01, time/batch = 18.8826s	
8340/33150 (epoch 12.579), train_loss = 1.00754380, grad/param norm = 1.4785e-01, time/batch = 17.4561s	
8341/33150 (epoch 12.581), train_loss = 1.05711250, grad/param norm = 1.4924e-01, time/batch = 17.6922s	
8342/33150 (epoch 12.582), train_loss = 1.22631151, grad/param norm = 1.4387e-01, time/batch = 16.7794s	
8343/33150 (epoch 12.584), train_loss = 1.24386759, grad/param norm = 1.4784e-01, time/batch = 17.5493s	
8344/33150 (epoch 12.585), train_loss = 1.18075238, grad/param norm = 1.5116e-01, time/batch = 16.8829s	
8345/33150 (epoch 12.587), train_loss = 1.21440858, grad/param norm = 1.5289e-01, time/batch = 19.2841s	
8346/33150 (epoch 12.588), train_loss = 1.05115443, grad/param norm = 1.4563e-01, time/batch = 18.0323s	
8347/33150 (epoch 12.590), train_loss = 1.16154341, grad/param norm = 1.4869e-01, time/batch = 17.0477s	
8348/33150 (epoch 12.591), train_loss = 1.15352605, grad/param norm = 1.4229e-01, time/batch = 19.5316s	
8349/33150 (epoch 12.593), train_loss = 1.22944533, grad/param norm = 1.5991e-01, time/batch = 17.8038s	
8350/33150 (epoch 12.594), train_loss = 1.18045609, grad/param norm = 1.5471e-01, time/batch = 16.3761s	
8351/33150 (epoch 12.596), train_loss = 1.08395765, grad/param norm = 1.4365e-01, time/batch = 15.6222s	
8352/33150 (epoch 12.597), train_loss = 1.04172733, grad/param norm = 1.6770e-01, time/batch = 17.0622s	
8353/33150 (epoch 12.599), train_loss = 1.35747100, grad/param norm = 1.6936e-01, time/batch = 19.0574s	
8354/33150 (epoch 12.600), train_loss = 1.19054874, grad/param norm = 1.7792e-01, time/batch = 16.2894s	
8355/33150 (epoch 12.602), train_loss = 1.09807906, grad/param norm = 1.4262e-01, time/batch = 18.4678s	
8356/33150 (epoch 12.603), train_loss = 1.21038181, grad/param norm = 1.5840e-01, time/batch = 18.3016s	
8357/33150 (epoch 12.605), train_loss = 1.03800880, grad/param norm = 1.4101e-01, time/batch = 15.6202s	
8358/33150 (epoch 12.606), train_loss = 1.20418414, grad/param norm = 1.7992e-01, time/batch = 16.6298s	
8359/33150 (epoch 12.608), train_loss = 1.20814669, grad/param norm = 1.6262e-01, time/batch = 17.6400s	
8360/33150 (epoch 12.609), train_loss = 1.15991352, grad/param norm = 1.6631e-01, time/batch = 17.4708s	
8361/33150 (epoch 12.611), train_loss = 0.99437450, grad/param norm = 1.4832e-01, time/batch = 22.9804s	
8362/33150 (epoch 12.612), train_loss = 1.16841673, grad/param norm = 1.6283e-01, time/batch = 20.7034s	
8363/33150 (epoch 12.614), train_loss = 0.99910808, grad/param norm = 1.4892e-01, time/batch = 17.4653s	
8364/33150 (epoch 12.615), train_loss = 1.04162666, grad/param norm = 1.4060e-01, time/batch = 18.3663s	
8365/33150 (epoch 12.617), train_loss = 1.14750916, grad/param norm = 1.6040e-01, time/batch = 16.0408s	
8366/33150 (epoch 12.618), train_loss = 1.15674513, grad/param norm = 1.3998e-01, time/batch = 18.4380s	
8367/33150 (epoch 12.620), train_loss = 1.08884156, grad/param norm = 1.6174e-01, time/batch = 29.3765s	
8368/33150 (epoch 12.621), train_loss = 1.13155626, grad/param norm = 1.4107e-01, time/batch = 17.5546s	
8369/33150 (epoch 12.623), train_loss = 1.21257787, grad/param norm = 1.5496e-01, time/batch = 19.1185s	
8370/33150 (epoch 12.624), train_loss = 1.07811112, grad/param norm = 1.5390e-01, time/batch = 15.2988s	
8371/33150 (epoch 12.626), train_loss = 1.07879466, grad/param norm = 1.4793e-01, time/batch = 16.3636s	
8372/33150 (epoch 12.627), train_loss = 1.02288649, grad/param norm = 1.5369e-01, time/batch = 16.1945s	
8373/33150 (epoch 12.629), train_loss = 0.99142225, grad/param norm = 1.2921e-01, time/batch = 15.7975s	
8374/33150 (epoch 12.630), train_loss = 1.05797371, grad/param norm = 1.3051e-01, time/batch = 16.8050s	
8375/33150 (epoch 12.632), train_loss = 0.97634803, grad/param norm = 1.3245e-01, time/batch = 14.8221s	
8376/33150 (epoch 12.633), train_loss = 0.99573279, grad/param norm = 1.5777e-01, time/batch = 15.2556s	
8377/33150 (epoch 12.635), train_loss = 1.35471689, grad/param norm = 1.5703e-01, time/batch = 15.5505s	
8378/33150 (epoch 12.637), train_loss = 0.96005442, grad/param norm = 1.4979e-01, time/batch = 17.9138s	
8379/33150 (epoch 12.638), train_loss = 1.09586012, grad/param norm = 1.3950e-01, time/batch = 16.5818s	
8380/33150 (epoch 12.640), train_loss = 1.25567688, grad/param norm = 1.5933e-01, time/batch = 16.6667s	
8381/33150 (epoch 12.641), train_loss = 1.03562066, grad/param norm = 1.5084e-01, time/batch = 15.6457s	
8382/33150 (epoch 12.643), train_loss = 1.07346017, grad/param norm = 1.3757e-01, time/batch = 17.7196s	
8383/33150 (epoch 12.644), train_loss = 1.27573244, grad/param norm = 1.4754e-01, time/batch = 17.3171s	
8384/33150 (epoch 12.646), train_loss = 1.09421584, grad/param norm = 1.4431e-01, time/batch = 15.7140s	
8385/33150 (epoch 12.647), train_loss = 1.41587907, grad/param norm = 1.6198e-01, time/batch = 15.4818s	
8386/33150 (epoch 12.649), train_loss = 1.25751657, grad/param norm = 1.6600e-01, time/batch = 16.6527s	
8387/33150 (epoch 12.650), train_loss = 1.01067548, grad/param norm = 1.3470e-01, time/batch = 17.2248s	
8388/33150 (epoch 12.652), train_loss = 1.27381486, grad/param norm = 1.7108e-01, time/batch = 16.1388s	
8389/33150 (epoch 12.653), train_loss = 1.12782632, grad/param norm = 1.3604e-01, time/batch = 18.1997s	
8390/33150 (epoch 12.655), train_loss = 1.20693770, grad/param norm = 1.8967e-01, time/batch = 16.9671s	
8391/33150 (epoch 12.656), train_loss = 1.13838327, grad/param norm = 1.3833e-01, time/batch = 17.1410s	
8392/33150 (epoch 12.658), train_loss = 1.15104714, grad/param norm = 1.8775e-01, time/batch = 16.4817s	
8393/33150 (epoch 12.659), train_loss = 1.62230922, grad/param norm = 6.5230e-01, time/batch = 17.5526s	
8394/33150 (epoch 12.661), train_loss = 1.15065107, grad/param norm = 1.6243e-01, time/batch = 15.8813s	
8395/33150 (epoch 12.662), train_loss = 0.99631491, grad/param norm = 1.5257e-01, time/batch = 15.6037s	
8396/33150 (epoch 12.664), train_loss = 1.28035460, grad/param norm = 1.5898e-01, time/batch = 17.6383s	
8397/33150 (epoch 12.665), train_loss = 1.23451093, grad/param norm = 1.6916e-01, time/batch = 16.8018s	
8398/33150 (epoch 12.667), train_loss = 1.30771065, grad/param norm = 1.5454e-01, time/batch = 16.9717s	
8399/33150 (epoch 12.668), train_loss = 1.21776127, grad/param norm = 1.4784e-01, time/batch = 16.2244s	
8400/33150 (epoch 12.670), train_loss = 1.10212152, grad/param norm = 1.3699e-01, time/batch = 15.4701s	
8401/33150 (epoch 12.671), train_loss = 1.10968768, grad/param norm = 1.5691e-01, time/batch = 18.8856s	
8402/33150 (epoch 12.673), train_loss = 1.25098226, grad/param norm = 1.3216e-01, time/batch = 16.4640s	
8403/33150 (epoch 12.674), train_loss = 1.14237637, grad/param norm = 1.4250e-01, time/batch = 18.2218s	
8404/33150 (epoch 12.676), train_loss = 1.10171298, grad/param norm = 1.3977e-01, time/batch = 16.2191s	
8405/33150 (epoch 12.677), train_loss = 1.42910849, grad/param norm = 1.6699e-01, time/batch = 17.2946s	
8406/33150 (epoch 12.679), train_loss = 1.08878686, grad/param norm = 1.3222e-01, time/batch = 15.7966s	
8407/33150 (epoch 12.680), train_loss = 1.30919864, grad/param norm = 1.5747e-01, time/batch = 16.5587s	
8408/33150 (epoch 12.682), train_loss = 1.07805511, grad/param norm = 1.4236e-01, time/batch = 16.7195s	
8409/33150 (epoch 12.683), train_loss = 0.96368028, grad/param norm = 1.4887e-01, time/batch = 15.5364s	
8410/33150 (epoch 12.685), train_loss = 1.17150803, grad/param norm = 1.5371e-01, time/batch = 16.2123s	
8411/33150 (epoch 12.686), train_loss = 1.00997119, grad/param norm = 1.5085e-01, time/batch = 18.3084s	
8412/33150 (epoch 12.688), train_loss = 1.07760031, grad/param norm = 1.3928e-01, time/batch = 16.9703s	
8413/33150 (epoch 12.689), train_loss = 1.05744026, grad/param norm = 1.3740e-01, time/batch = 16.4360s	
8414/33150 (epoch 12.691), train_loss = 0.96293567, grad/param norm = 1.3201e-01, time/batch = 17.8677s	
8415/33150 (epoch 12.692), train_loss = 1.03879222, grad/param norm = 1.3958e-01, time/batch = 17.3701s	
8416/33150 (epoch 12.694), train_loss = 0.91518649, grad/param norm = 1.2304e-01, time/batch = 17.4508s	
8417/33150 (epoch 12.695), train_loss = 1.08358574, grad/param norm = 1.4409e-01, time/batch = 17.6297s	
8418/33150 (epoch 12.697), train_loss = 0.95056741, grad/param norm = 1.2288e-01, time/batch = 18.2074s	
8419/33150 (epoch 12.698), train_loss = 1.18525891, grad/param norm = 1.6836e-01, time/batch = 17.4470s	
8420/33150 (epoch 12.700), train_loss = 0.86708648, grad/param norm = 1.2914e-01, time/batch = 16.5237s	
8421/33150 (epoch 12.701), train_loss = 1.02864311, grad/param norm = 1.3637e-01, time/batch = 18.6196s	
8422/33150 (epoch 12.703), train_loss = 1.11226228, grad/param norm = 1.4312e-01, time/batch = 19.7240s	
8423/33150 (epoch 12.704), train_loss = 0.93834438, grad/param norm = 1.2140e-01, time/batch = 16.9668s	
8424/33150 (epoch 12.706), train_loss = 1.09415006, grad/param norm = 1.3634e-01, time/batch = 20.3113s	
8425/33150 (epoch 12.707), train_loss = 1.07592157, grad/param norm = 1.4527e-01, time/batch = 16.3749s	
8426/33150 (epoch 12.709), train_loss = 1.13746128, grad/param norm = 1.2754e-01, time/batch = 17.2845s	
8427/33150 (epoch 12.710), train_loss = 1.18367034, grad/param norm = 1.6670e-01, time/batch = 19.5617s	
8428/33150 (epoch 12.712), train_loss = 1.24791883, grad/param norm = 1.6742e-01, time/batch = 18.4640s	
8429/33150 (epoch 12.713), train_loss = 1.20245799, grad/param norm = 1.5412e-01, time/batch = 16.6882s	
8430/33150 (epoch 12.715), train_loss = 1.08418815, grad/param norm = 1.3833e-01, time/batch = 16.0512s	
8431/33150 (epoch 12.716), train_loss = 1.17517987, grad/param norm = 1.5315e-01, time/batch = 18.4668s	
8432/33150 (epoch 12.718), train_loss = 1.16065537, grad/param norm = 1.4052e-01, time/batch = 18.6337s	
8433/33150 (epoch 12.719), train_loss = 1.25385960, grad/param norm = 1.7481e-01, time/batch = 16.4464s	
8434/33150 (epoch 12.721), train_loss = 1.13667795, grad/param norm = 1.7014e-01, time/batch = 17.8742s	
8435/33150 (epoch 12.722), train_loss = 1.18750374, grad/param norm = 1.4434e-01, time/batch = 18.5252s	
8436/33150 (epoch 12.724), train_loss = 1.09705676, grad/param norm = 1.4235e-01, time/batch = 17.0435s	
8437/33150 (epoch 12.725), train_loss = 1.29732916, grad/param norm = 1.7450e-01, time/batch = 18.0435s	
8438/33150 (epoch 12.727), train_loss = 1.16401815, grad/param norm = 1.6991e-01, time/batch = 17.2125s	
8439/33150 (epoch 12.729), train_loss = 1.14814828, grad/param norm = 1.4230e-01, time/batch = 18.2024s	
8440/33150 (epoch 12.730), train_loss = 1.14647482, grad/param norm = 1.5219e-01, time/batch = 16.3084s	
8441/33150 (epoch 12.732), train_loss = 1.24662849, grad/param norm = 1.6719e-01, time/batch = 19.3833s	
8442/33150 (epoch 12.733), train_loss = 0.93095343, grad/param norm = 1.1943e-01, time/batch = 18.1405s	
8443/33150 (epoch 12.735), train_loss = 1.09869250, grad/param norm = 1.4045e-01, time/batch = 17.5423s	
8444/33150 (epoch 12.736), train_loss = 1.10528789, grad/param norm = 1.6719e-01, time/batch = 20.2109s	
8445/33150 (epoch 12.738), train_loss = 1.17330687, grad/param norm = 1.5336e-01, time/batch = 17.5534s	
8446/33150 (epoch 12.739), train_loss = 1.28618230, grad/param norm = 1.5877e-01, time/batch = 16.2096s	
8447/33150 (epoch 12.741), train_loss = 1.27587269, grad/param norm = 1.7353e-01, time/batch = 16.2593s	
8448/33150 (epoch 12.742), train_loss = 1.07054502, grad/param norm = 1.5052e-01, time/batch = 16.8942s	
8449/33150 (epoch 12.744), train_loss = 1.28671328, grad/param norm = 1.6845e-01, time/batch = 16.3891s	
8450/33150 (epoch 12.745), train_loss = 1.09633200, grad/param norm = 1.3173e-01, time/batch = 15.9745s	
8451/33150 (epoch 12.747), train_loss = 0.98221795, grad/param norm = 1.5087e-01, time/batch = 18.5527s	
8452/33150 (epoch 12.748), train_loss = 1.06515753, grad/param norm = 1.3893e-01, time/batch = 16.9713s	
8453/33150 (epoch 12.750), train_loss = 1.23321728, grad/param norm = 1.6132e-01, time/batch = 16.7221s	
8454/33150 (epoch 12.751), train_loss = 1.15455569, grad/param norm = 1.4395e-01, time/batch = 15.8150s	
8455/33150 (epoch 12.753), train_loss = 0.98612322, grad/param norm = 1.5747e-01, time/batch = 18.4641s	
8456/33150 (epoch 12.754), train_loss = 1.38272724, grad/param norm = 1.9255e-01, time/batch = 19.4678s	
8457/33150 (epoch 12.756), train_loss = 1.19682453, grad/param norm = 1.6888e-01, time/batch = 16.3077s	
8458/33150 (epoch 12.757), train_loss = 1.16611110, grad/param norm = 1.5008e-01, time/batch = 18.0505s	
8459/33150 (epoch 12.759), train_loss = 1.32429484, grad/param norm = 1.6270e-01, time/batch = 16.8023s	
8460/33150 (epoch 12.760), train_loss = 1.20700268, grad/param norm = 1.6947e-01, time/batch = 17.0482s	
8461/33150 (epoch 12.762), train_loss = 1.19326078, grad/param norm = 1.6883e-01, time/batch = 17.9609s	
8462/33150 (epoch 12.763), train_loss = 1.17420464, grad/param norm = 1.5696e-01, time/batch = 18.8045s	
8463/33150 (epoch 12.765), train_loss = 1.12062278, grad/param norm = 1.4260e-01, time/batch = 16.4513s	
8464/33150 (epoch 12.766), train_loss = 1.03684122, grad/param norm = 1.4192e-01, time/batch = 15.6334s	
8465/33150 (epoch 12.768), train_loss = 1.08814988, grad/param norm = 1.5340e-01, time/batch = 15.9610s	
8466/33150 (epoch 12.769), train_loss = 1.17776658, grad/param norm = 1.4557e-01, time/batch = 17.6353s	
8467/33150 (epoch 12.771), train_loss = 1.16783291, grad/param norm = 1.4120e-01, time/batch = 16.6458s	
8468/33150 (epoch 12.772), train_loss = 1.22094343, grad/param norm = 1.6688e-01, time/batch = 16.8243s	
8469/33150 (epoch 12.774), train_loss = 1.31388297, grad/param norm = 1.5395e-01, time/batch = 18.3831s	
8470/33150 (epoch 12.775), train_loss = 1.23691758, grad/param norm = 2.1016e-01, time/batch = 19.1143s	
8471/33150 (epoch 12.777), train_loss = 1.24128171, grad/param norm = 1.7711e-01, time/batch = 16.8856s	
8472/33150 (epoch 12.778), train_loss = 1.15271327, grad/param norm = 1.2708e-01, time/batch = 17.5620s	
8473/33150 (epoch 12.780), train_loss = 1.02795525, grad/param norm = 1.3727e-01, time/batch = 18.4609s	
8474/33150 (epoch 12.781), train_loss = 1.13124396, grad/param norm = 1.3995e-01, time/batch = 17.2975s	
8475/33150 (epoch 12.783), train_loss = 1.15636144, grad/param norm = 1.3222e-01, time/batch = 18.3872s	
8476/33150 (epoch 12.784), train_loss = 1.11008612, grad/param norm = 1.5416e-01, time/batch = 18.3122s	
8477/33150 (epoch 12.786), train_loss = 1.09379190, grad/param norm = 1.2635e-01, time/batch = 17.0548s	
8478/33150 (epoch 12.787), train_loss = 1.09875546, grad/param norm = 1.4546e-01, time/batch = 17.6365s	
8479/33150 (epoch 12.789), train_loss = 0.97722916, grad/param norm = 1.3035e-01, time/batch = 16.2986s	
8480/33150 (epoch 12.790), train_loss = 0.96158320, grad/param norm = 1.2231e-01, time/batch = 16.3924s	
8481/33150 (epoch 12.792), train_loss = 1.18234209, grad/param norm = 1.6222e-01, time/batch = 16.3699s	
8482/33150 (epoch 12.793), train_loss = 1.14147676, grad/param norm = 1.6153e-01, time/batch = 15.2012s	
8483/33150 (epoch 12.795), train_loss = 1.06171719, grad/param norm = 1.5405e-01, time/batch = 16.8847s	
8484/33150 (epoch 12.796), train_loss = 1.06573315, grad/param norm = 1.5154e-01, time/batch = 16.7927s	
8485/33150 (epoch 12.798), train_loss = 1.07499077, grad/param norm = 1.2534e-01, time/batch = 17.8788s	
8486/33150 (epoch 12.799), train_loss = 0.98529915, grad/param norm = 1.6538e-01, time/batch = 16.2992s	
8487/33150 (epoch 12.801), train_loss = 1.14441172, grad/param norm = 1.3754e-01, time/batch = 15.5414s	
8488/33150 (epoch 12.802), train_loss = 1.04865635, grad/param norm = 1.4617e-01, time/batch = 15.7232s	
8489/33150 (epoch 12.804), train_loss = 1.10032237, grad/param norm = 1.5208e-01, time/batch = 15.4279s	
8490/33150 (epoch 12.805), train_loss = 1.12213615, grad/param norm = 1.5580e-01, time/batch = 15.3561s	
8491/33150 (epoch 12.807), train_loss = 1.08013144, grad/param norm = 1.3714e-01, time/batch = 19.3575s	
8492/33150 (epoch 12.808), train_loss = 1.20813892, grad/param norm = 1.5291e-01, time/batch = 15.8753s	
8493/33150 (epoch 12.810), train_loss = 1.09816855, grad/param norm = 1.4271e-01, time/batch = 19.2179s	
8494/33150 (epoch 12.811), train_loss = 1.17601988, grad/param norm = 1.5680e-01, time/batch = 18.2162s	
8495/33150 (epoch 12.813), train_loss = 1.10634314, grad/param norm = 1.3517e-01, time/batch = 17.3060s	
8496/33150 (epoch 12.814), train_loss = 1.14016546, grad/param norm = 1.6591e-01, time/batch = 18.2222s	
8497/33150 (epoch 12.816), train_loss = 1.11130314, grad/param norm = 1.4577e-01, time/batch = 18.5542s	
8498/33150 (epoch 12.817), train_loss = 1.20937973, grad/param norm = 1.4954e-01, time/batch = 17.2154s	
8499/33150 (epoch 12.819), train_loss = 1.10231408, grad/param norm = 1.4021e-01, time/batch = 15.7891s	
8500/33150 (epoch 12.821), train_loss = 0.98509000, grad/param norm = 1.2858e-01, time/batch = 16.5580s	
8501/33150 (epoch 12.822), train_loss = 1.04956769, grad/param norm = 1.4926e-01, time/batch = 17.8002s	
8502/33150 (epoch 12.824), train_loss = 1.09830737, grad/param norm = 1.4797e-01, time/batch = 16.1432s	
8503/33150 (epoch 12.825), train_loss = 1.14295255, grad/param norm = 1.5244e-01, time/batch = 17.3156s	
8504/33150 (epoch 12.827), train_loss = 1.20762217, grad/param norm = 1.7677e-01, time/batch = 18.3908s	
8505/33150 (epoch 12.828), train_loss = 1.00828570, grad/param norm = 1.5086e-01, time/batch = 17.5452s	
8506/33150 (epoch 12.830), train_loss = 1.20844130, grad/param norm = 1.5206e-01, time/batch = 16.1192s	
8507/33150 (epoch 12.831), train_loss = 1.07469873, grad/param norm = 1.5735e-01, time/batch = 17.4701s	
8508/33150 (epoch 12.833), train_loss = 1.01621863, grad/param norm = 1.4336e-01, time/batch = 17.8746s	
8509/33150 (epoch 12.834), train_loss = 1.27895053, grad/param norm = 1.6461e-01, time/batch = 16.7166s	
8510/33150 (epoch 12.836), train_loss = 1.23388941, grad/param norm = 1.6249e-01, time/batch = 18.8738s	
8511/33150 (epoch 12.837), train_loss = 1.14722125, grad/param norm = 1.5999e-01, time/batch = 16.1373s	
8512/33150 (epoch 12.839), train_loss = 1.22750956, grad/param norm = 1.7109e-01, time/batch = 17.2207s	
8513/33150 (epoch 12.840), train_loss = 1.21234417, grad/param norm = 1.5570e-01, time/batch = 18.6229s	
8514/33150 (epoch 12.842), train_loss = 1.32330756, grad/param norm = 2.0139e-01, time/batch = 16.6575s	
8515/33150 (epoch 12.843), train_loss = 1.26631050, grad/param norm = 1.5600e-01, time/batch = 18.1330s	
8516/33150 (epoch 12.845), train_loss = 1.09996284, grad/param norm = 1.4838e-01, time/batch = 18.4533s	
8517/33150 (epoch 12.846), train_loss = 1.36216527, grad/param norm = 1.9364e-01, time/batch = 17.3900s	
8518/33150 (epoch 12.848), train_loss = 1.22687839, grad/param norm = 1.5371e-01, time/batch = 16.5498s	
8519/33150 (epoch 12.849), train_loss = 1.21764806, grad/param norm = 1.6930e-01, time/batch = 16.9631s	
8520/33150 (epoch 12.851), train_loss = 1.24382994, grad/param norm = 1.6692e-01, time/batch = 18.2220s	
8521/33150 (epoch 12.852), train_loss = 1.30805694, grad/param norm = 1.4671e-01, time/batch = 16.7141s	
8522/33150 (epoch 12.854), train_loss = 1.16920662, grad/param norm = 1.5460e-01, time/batch = 18.4665s	
8523/33150 (epoch 12.855), train_loss = 0.98352612, grad/param norm = 1.3632e-01, time/batch = 18.3631s	
8524/33150 (epoch 12.857), train_loss = 0.97256479, grad/param norm = 1.3334e-01, time/batch = 17.0340s	
8525/33150 (epoch 12.858), train_loss = 1.09061327, grad/param norm = 1.5873e-01, time/batch = 18.8752s	
8526/33150 (epoch 12.860), train_loss = 1.01609110, grad/param norm = 1.3226e-01, time/batch = 16.0149s	
8527/33150 (epoch 12.861), train_loss = 1.05881220, grad/param norm = 1.4083e-01, time/batch = 15.5149s	
8528/33150 (epoch 12.863), train_loss = 1.18121311, grad/param norm = 1.3992e-01, time/batch = 15.5177s	
8529/33150 (epoch 12.864), train_loss = 1.24923772, grad/param norm = 1.5045e-01, time/batch = 15.1753s	
8530/33150 (epoch 12.866), train_loss = 1.18931570, grad/param norm = 1.5429e-01, time/batch = 15.0955s	
8531/33150 (epoch 12.867), train_loss = 1.17657432, grad/param norm = 1.2748e-01, time/batch = 15.5449s	
8532/33150 (epoch 12.869), train_loss = 1.20764937, grad/param norm = 1.5307e-01, time/batch = 15.3678s	
8533/33150 (epoch 12.870), train_loss = 1.20207710, grad/param norm = 1.6789e-01, time/batch = 15.2679s	
8534/33150 (epoch 12.872), train_loss = 1.12842828, grad/param norm = 1.6139e-01, time/batch = 15.0621s	
8535/33150 (epoch 12.873), train_loss = 0.96365151, grad/param norm = 1.3160e-01, time/batch = 15.1929s	
8536/33150 (epoch 12.875), train_loss = 1.30574301, grad/param norm = 1.6591e-01, time/batch = 16.3430s	
8537/33150 (epoch 12.876), train_loss = 1.03814474, grad/param norm = 1.5417e-01, time/batch = 15.8750s	
8538/33150 (epoch 12.878), train_loss = 1.01796375, grad/param norm = 1.2891e-01, time/batch = 16.1473s	
8539/33150 (epoch 12.879), train_loss = 1.05381869, grad/param norm = 1.4208e-01, time/batch = 16.2118s	
8540/33150 (epoch 12.881), train_loss = 1.08867860, grad/param norm = 1.5839e-01, time/batch = 20.2040s	
8541/33150 (epoch 12.882), train_loss = 0.97297361, grad/param norm = 1.3497e-01, time/batch = 15.6163s	
8542/33150 (epoch 12.884), train_loss = 1.12726882, grad/param norm = 1.5180e-01, time/batch = 16.9619s	
8543/33150 (epoch 12.885), train_loss = 0.90623955, grad/param norm = 1.3964e-01, time/batch = 15.7081s	
8544/33150 (epoch 12.887), train_loss = 1.31934638, grad/param norm = 1.7587e-01, time/batch = 16.0210s	
8545/33150 (epoch 12.888), train_loss = 1.19022457, grad/param norm = 1.7063e-01, time/batch = 16.3618s	
8546/33150 (epoch 12.890), train_loss = 1.08734100, grad/param norm = 1.4803e-01, time/batch = 18.3155s	
8547/33150 (epoch 12.891), train_loss = 1.04026801, grad/param norm = 1.4260e-01, time/batch = 17.1380s	
8548/33150 (epoch 12.893), train_loss = 1.19525624, grad/param norm = 1.6192e-01, time/batch = 17.6433s	
8549/33150 (epoch 12.894), train_loss = 1.21148595, grad/param norm = 1.5654e-01, time/batch = 16.8089s	
8550/33150 (epoch 12.896), train_loss = 1.09902205, grad/param norm = 1.3870e-01, time/batch = 18.0608s	
8551/33150 (epoch 12.897), train_loss = 1.17227626, grad/param norm = 1.4237e-01, time/batch = 16.8901s	
8552/33150 (epoch 12.899), train_loss = 1.01452556, grad/param norm = 1.6630e-01, time/batch = 16.4657s	
8553/33150 (epoch 12.900), train_loss = 1.42078335, grad/param norm = 1.6064e-01, time/batch = 16.9624s	
8554/33150 (epoch 12.902), train_loss = 1.31146850, grad/param norm = 1.5656e-01, time/batch = 15.3544s	
8555/33150 (epoch 12.903), train_loss = 1.15415648, grad/param norm = 1.5018e-01, time/batch = 16.1940s	
8556/33150 (epoch 12.905), train_loss = 1.16848453, grad/param norm = 1.4431e-01, time/batch = 18.1292s	
8557/33150 (epoch 12.906), train_loss = 1.23267630, grad/param norm = 1.6072e-01, time/batch = 15.6288s	
8558/33150 (epoch 12.908), train_loss = 1.29362112, grad/param norm = 1.6516e-01, time/batch = 16.6826s	
8559/33150 (epoch 12.910), train_loss = 1.23518246, grad/param norm = 1.4728e-01, time/batch = 17.3511s	
8560/33150 (epoch 12.911), train_loss = 0.97954244, grad/param norm = 1.2704e-01, time/batch = 16.5398s	
8561/33150 (epoch 12.913), train_loss = 1.07743028, grad/param norm = 1.5234e-01, time/batch = 17.1161s	
8562/33150 (epoch 12.914), train_loss = 1.23663646, grad/param norm = 1.7088e-01, time/batch = 16.5537s	
8563/33150 (epoch 12.916), train_loss = 1.06890802, grad/param norm = 1.5419e-01, time/batch = 18.2935s	
8564/33150 (epoch 12.917), train_loss = 1.27399730, grad/param norm = 1.8406e-01, time/batch = 15.7165s	
8565/33150 (epoch 12.919), train_loss = 1.30770271, grad/param norm = 1.8053e-01, time/batch = 18.2846s	
8566/33150 (epoch 12.920), train_loss = 1.23345031, grad/param norm = 1.5853e-01, time/batch = 15.1439s	
8567/33150 (epoch 12.922), train_loss = 1.32906291, grad/param norm = 1.8445e-01, time/batch = 17.8808s	
8568/33150 (epoch 12.923), train_loss = 1.15540092, grad/param norm = 1.6398e-01, time/batch = 16.3701s	
8569/33150 (epoch 12.925), train_loss = 1.18889505, grad/param norm = 1.3911e-01, time/batch = 17.0264s	
8570/33150 (epoch 12.926), train_loss = 1.13001941, grad/param norm = 1.4181e-01, time/batch = 16.0538s	
8571/33150 (epoch 12.928), train_loss = 1.11153347, grad/param norm = 1.5767e-01, time/batch = 16.4670s	
8572/33150 (epoch 12.929), train_loss = 1.21280901, grad/param norm = 1.4005e-01, time/batch = 17.1314s	
8573/33150 (epoch 12.931), train_loss = 1.30479064, grad/param norm = 1.7300e-01, time/batch = 14.9473s	
8574/33150 (epoch 12.932), train_loss = 1.16705693, grad/param norm = 1.8671e-01, time/batch = 16.2956s	
8575/33150 (epoch 12.934), train_loss = 1.19778952, grad/param norm = 1.4768e-01, time/batch = 17.0475s	
8576/33150 (epoch 12.935), train_loss = 1.27379504, grad/param norm = 1.5485e-01, time/batch = 18.0055s	
8577/33150 (epoch 12.937), train_loss = 1.28786557, grad/param norm = 1.4808e-01, time/batch = 27.8206s	
8578/33150 (epoch 12.938), train_loss = 1.23709248, grad/param norm = 1.4654e-01, time/batch = 18.6272s	
8579/33150 (epoch 12.940), train_loss = 1.45723671, grad/param norm = 1.6943e-01, time/batch = 16.8607s	
8580/33150 (epoch 12.941), train_loss = 1.15010974, grad/param norm = 1.3916e-01, time/batch = 17.7155s	
8581/33150 (epoch 12.943), train_loss = 1.07173333, grad/param norm = 1.7607e-01, time/batch = 17.2175s	
8582/33150 (epoch 12.944), train_loss = 1.28012030, grad/param norm = 1.8395e-01, time/batch = 16.6477s	
8583/33150 (epoch 12.946), train_loss = 0.96016331, grad/param norm = 1.2836e-01, time/batch = 15.9640s	
8584/33150 (epoch 12.947), train_loss = 1.19956674, grad/param norm = 1.4910e-01, time/batch = 18.6292s	
8585/33150 (epoch 12.949), train_loss = 1.30842057, grad/param norm = 1.4833e-01, time/batch = 17.8150s	
8586/33150 (epoch 12.950), train_loss = 1.19745283, grad/param norm = 1.5603e-01, time/batch = 16.5361s	
8587/33150 (epoch 12.952), train_loss = 1.06347551, grad/param norm = 1.4312e-01, time/batch = 18.1226s	
8588/33150 (epoch 12.953), train_loss = 1.12454634, grad/param norm = 1.4615e-01, time/batch = 16.5570s	
8589/33150 (epoch 12.955), train_loss = 1.02394781, grad/param norm = 1.3904e-01, time/batch = 17.8058s	
8590/33150 (epoch 12.956), train_loss = 1.22107799, grad/param norm = 1.4490e-01, time/batch = 17.5396s	
8591/33150 (epoch 12.958), train_loss = 1.01349031, grad/param norm = 1.3961e-01, time/batch = 17.5546s	
8592/33150 (epoch 12.959), train_loss = 1.07049691, grad/param norm = 1.5447e-01, time/batch = 16.8102s	
8593/33150 (epoch 12.961), train_loss = 1.03168481, grad/param norm = 1.5065e-01, time/batch = 16.4732s	
8594/33150 (epoch 12.962), train_loss = 0.99808879, grad/param norm = 1.3943e-01, time/batch = 16.1560s	
8595/33150 (epoch 12.964), train_loss = 1.16499797, grad/param norm = 1.4994e-01, time/batch = 19.7099s	
8596/33150 (epoch 12.965), train_loss = 1.14868871, grad/param norm = 1.4616e-01, time/batch = 16.0185s	
8597/33150 (epoch 12.967), train_loss = 1.15255382, grad/param norm = 1.5950e-01, time/batch = 15.6468s	
8598/33150 (epoch 12.968), train_loss = 0.96531055, grad/param norm = 1.2452e-01, time/batch = 17.6919s	
8599/33150 (epoch 12.970), train_loss = 1.09426272, grad/param norm = 1.3865e-01, time/batch = 15.6929s	
8600/33150 (epoch 12.971), train_loss = 1.16175871, grad/param norm = 1.6184e-01, time/batch = 16.0872s	
8601/33150 (epoch 12.973), train_loss = 1.34099591, grad/param norm = 1.6408e-01, time/batch = 16.0998s	
8602/33150 (epoch 12.974), train_loss = 1.30170507, grad/param norm = 1.6081e-01, time/batch = 16.7659s	
8603/33150 (epoch 12.976), train_loss = 1.20635296, grad/param norm = 1.4046e-01, time/batch = 18.2771s	
8604/33150 (epoch 12.977), train_loss = 1.30510731, grad/param norm = 1.6520e-01, time/batch = 16.9465s	
8605/33150 (epoch 12.979), train_loss = 1.28517538, grad/param norm = 1.8147e-01, time/batch = 18.8844s	
8606/33150 (epoch 12.980), train_loss = 1.30562512, grad/param norm = 1.5509e-01, time/batch = 16.3761s	
8607/33150 (epoch 12.982), train_loss = 1.14929086, grad/param norm = 1.7504e-01, time/batch = 16.3025s	
8608/33150 (epoch 12.983), train_loss = 1.00857030, grad/param norm = 1.4154e-01, time/batch = 17.0577s	
8609/33150 (epoch 12.985), train_loss = 1.19609548, grad/param norm = 1.4516e-01, time/batch = 17.3892s	
8610/33150 (epoch 12.986), train_loss = 0.99428345, grad/param norm = 1.3984e-01, time/batch = 17.2045s	
8611/33150 (epoch 12.988), train_loss = 1.09253904, grad/param norm = 1.4375e-01, time/batch = 16.9682s	
8612/33150 (epoch 12.989), train_loss = 1.04506535, grad/param norm = 1.7577e-01, time/batch = 17.2836s	
8613/33150 (epoch 12.991), train_loss = 1.24549216, grad/param norm = 1.9135e-01, time/batch = 16.9713s	
8614/33150 (epoch 12.992), train_loss = 1.02563499, grad/param norm = 1.4133e-01, time/batch = 16.6468s	
8615/33150 (epoch 12.994), train_loss = 1.13503968, grad/param norm = 1.4806e-01, time/batch = 17.3018s	
8616/33150 (epoch 12.995), train_loss = 1.07951318, grad/param norm = 1.4784e-01, time/batch = 15.3122s	
8617/33150 (epoch 12.997), train_loss = 1.17271008, grad/param norm = 1.6186e-01, time/batch = 18.2255s	
8618/33150 (epoch 12.998), train_loss = 0.93316173, grad/param norm = 1.3572e-01, time/batch = 16.3866s	
decayed learning rate by a factor 0.97 to 0.00177058562	
8619/33150 (epoch 13.000), train_loss = 0.97318112, grad/param norm = 1.5302e-01, time/batch = 17.7303s	
8620/33150 (epoch 13.002), train_loss = 1.47734944, grad/param norm = 1.7867e-01, time/batch = 15.5501s	
8621/33150 (epoch 13.003), train_loss = 1.08027279, grad/param norm = 1.7541e-01, time/batch = 16.2958s	
8622/33150 (epoch 13.005), train_loss = 1.01269739, grad/param norm = 1.4073e-01, time/batch = 15.9852s	
8623/33150 (epoch 13.006), train_loss = 0.99351866, grad/param norm = 1.4508e-01, time/batch = 17.7272s	
8624/33150 (epoch 13.008), train_loss = 1.26330134, grad/param norm = 1.5945e-01, time/batch = 15.6417s	
8625/33150 (epoch 13.009), train_loss = 1.12669248, grad/param norm = 1.5630e-01, time/batch = 16.1420s	
8626/33150 (epoch 13.011), train_loss = 1.28028726, grad/param norm = 1.5701e-01, time/batch = 16.6487s	
8627/33150 (epoch 13.012), train_loss = 1.16912302, grad/param norm = 2.4967e-01, time/batch = 16.3058s	
8628/33150 (epoch 13.014), train_loss = 1.12138059, grad/param norm = 1.5650e-01, time/batch = 16.8008s	
8629/33150 (epoch 13.015), train_loss = 1.10872431, grad/param norm = 1.5041e-01, time/batch = 15.6375s	
8630/33150 (epoch 13.017), train_loss = 1.07372270, grad/param norm = 1.4108e-01, time/batch = 16.3950s	
8631/33150 (epoch 13.018), train_loss = 1.17536790, grad/param norm = 1.6201e-01, time/batch = 16.8108s	
8632/33150 (epoch 13.020), train_loss = 1.21830137, grad/param norm = 1.6095e-01, time/batch = 15.4889s	
8633/33150 (epoch 13.021), train_loss = 0.99804661, grad/param norm = 1.5299e-01, time/batch = 16.8996s	
8634/33150 (epoch 13.023), train_loss = 1.31712447, grad/param norm = 1.4545e-01, time/batch = 15.6520s	
8635/33150 (epoch 13.024), train_loss = 1.18829509, grad/param norm = 1.5258e-01, time/batch = 19.4597s	
8636/33150 (epoch 13.026), train_loss = 0.92085492, grad/param norm = 1.2653e-01, time/batch = 16.6953s	
8637/33150 (epoch 13.027), train_loss = 0.93923244, grad/param norm = 1.4215e-01, time/batch = 18.3602s	
8638/33150 (epoch 13.029), train_loss = 1.04496679, grad/param norm = 1.4101e-01, time/batch = 18.8678s	
8639/33150 (epoch 13.030), train_loss = 1.11983112, grad/param norm = 1.2720e-01, time/batch = 15.8856s	
8640/33150 (epoch 13.032), train_loss = 1.08852881, grad/param norm = 1.6840e-01, time/batch = 18.6053s	
8641/33150 (epoch 13.033), train_loss = 1.09585216, grad/param norm = 1.4610e-01, time/batch = 17.5399s	
8642/33150 (epoch 13.035), train_loss = 1.31300299, grad/param norm = 1.7469e-01, time/batch = 16.8572s	
8643/33150 (epoch 13.036), train_loss = 1.19331953, grad/param norm = 1.5901e-01, time/batch = 17.4697s	
8644/33150 (epoch 13.038), train_loss = 1.44253828, grad/param norm = 1.7477e-01, time/batch = 18.7137s	
8645/33150 (epoch 13.039), train_loss = 1.16461947, grad/param norm = 1.3421e-01, time/batch = 17.4029s	
8646/33150 (epoch 13.041), train_loss = 1.18320795, grad/param norm = 1.4752e-01, time/batch = 16.1371s	
8647/33150 (epoch 13.042), train_loss = 1.10219893, grad/param norm = 1.4240e-01, time/batch = 17.6972s	
8648/33150 (epoch 13.044), train_loss = 1.08066247, grad/param norm = 1.3641e-01, time/batch = 18.3715s	
8649/33150 (epoch 13.045), train_loss = 1.13110545, grad/param norm = 1.3610e-01, time/batch = 15.3561s	
8650/33150 (epoch 13.047), train_loss = 1.06119483, grad/param norm = 1.5296e-01, time/batch = 16.6974s	
8651/33150 (epoch 13.048), train_loss = 1.25874599, grad/param norm = 1.6237e-01, time/batch = 17.3794s	
8652/33150 (epoch 13.050), train_loss = 1.13697296, grad/param norm = 1.4507e-01, time/batch = 18.6463s	
8653/33150 (epoch 13.051), train_loss = 1.14898467, grad/param norm = 1.5181e-01, time/batch = 16.7917s	
8654/33150 (epoch 13.053), train_loss = 1.08988450, grad/param norm = 1.3564e-01, time/batch = 17.2091s	
8655/33150 (epoch 13.054), train_loss = 1.21782869, grad/param norm = 1.3623e-01, time/batch = 18.6292s	
8656/33150 (epoch 13.056), train_loss = 1.08278124, grad/param norm = 1.3516e-01, time/batch = 15.9336s	
8657/33150 (epoch 13.057), train_loss = 1.13342849, grad/param norm = 1.7105e-01, time/batch = 16.3653s	
8658/33150 (epoch 13.059), train_loss = 1.05017352, grad/param norm = 1.4970e-01, time/batch = 18.4414s	
8659/33150 (epoch 13.060), train_loss = 1.07197126, grad/param norm = 1.3957e-01, time/batch = 16.3077s	
8660/33150 (epoch 13.062), train_loss = 1.10945831, grad/param norm = 1.4694e-01, time/batch = 16.8024s	
8661/33150 (epoch 13.063), train_loss = 1.07829349, grad/param norm = 1.4801e-01, time/batch = 17.5573s	
8662/33150 (epoch 13.065), train_loss = 1.11441516, grad/param norm = 1.3016e-01, time/batch = 17.2141s	
8663/33150 (epoch 13.066), train_loss = 1.05158420, grad/param norm = 1.3586e-01, time/batch = 16.3654s	
8664/33150 (epoch 13.068), train_loss = 1.15396885, grad/param norm = 1.5173e-01, time/batch = 16.2769s	
8665/33150 (epoch 13.069), train_loss = 1.22135203, grad/param norm = 1.6179e-01, time/batch = 16.3827s	
8666/33150 (epoch 13.071), train_loss = 1.19135151, grad/param norm = 1.4869e-01, time/batch = 17.2128s	
8667/33150 (epoch 13.072), train_loss = 1.08736955, grad/param norm = 1.3758e-01, time/batch = 16.1346s	
8668/33150 (epoch 13.074), train_loss = 0.98755756, grad/param norm = 1.4740e-01, time/batch = 17.5559s	
8669/33150 (epoch 13.075), train_loss = 1.07510817, grad/param norm = 1.5685e-01, time/batch = 16.6459s	
8670/33150 (epoch 13.077), train_loss = 1.16846049, grad/param norm = 1.7719e-01, time/batch = 17.7100s	
8671/33150 (epoch 13.078), train_loss = 1.32039885, grad/param norm = 1.7394e-01, time/batch = 16.8123s	
8672/33150 (epoch 13.080), train_loss = 1.24869467, grad/param norm = 1.4373e-01, time/batch = 16.7808s	
8673/33150 (epoch 13.081), train_loss = 1.05315299, grad/param norm = 1.5419e-01, time/batch = 15.6181s	
8674/33150 (epoch 13.083), train_loss = 0.83578388, grad/param norm = 1.4133e-01, time/batch = 15.8993s	
8675/33150 (epoch 13.084), train_loss = 1.00528121, grad/param norm = 1.6069e-01, time/batch = 16.3880s	
8676/33150 (epoch 13.086), train_loss = 1.06832309, grad/param norm = 1.5553e-01, time/batch = 16.6311s	
8677/33150 (epoch 13.087), train_loss = 0.99176475, grad/param norm = 1.3262e-01, time/batch = 15.4840s	
8678/33150 (epoch 13.089), train_loss = 1.03970465, grad/param norm = 1.4770e-01, time/batch = 15.1287s	
8679/33150 (epoch 13.090), train_loss = 1.06302501, grad/param norm = 1.6451e-01, time/batch = 17.0450s	
8680/33150 (epoch 13.092), train_loss = 1.09690820, grad/param norm = 1.5721e-01, time/batch = 16.3973s	
8681/33150 (epoch 13.094), train_loss = 1.20421837, grad/param norm = 1.6002e-01, time/batch = 15.7999s	
8682/33150 (epoch 13.095), train_loss = 0.96957362, grad/param norm = 1.2845e-01, time/batch = 15.9640s	
8683/33150 (epoch 13.097), train_loss = 1.09347134, grad/param norm = 1.4147e-01, time/batch = 16.9450s	
8684/33150 (epoch 13.098), train_loss = 1.36602055, grad/param norm = 1.6195e-01, time/batch = 15.4161s	
8685/33150 (epoch 13.100), train_loss = 1.33686198, grad/param norm = 1.5520e-01, time/batch = 15.5221s	
8686/33150 (epoch 13.101), train_loss = 1.03763250, grad/param norm = 1.5711e-01, time/batch = 15.4326s	
8687/33150 (epoch 13.103), train_loss = 1.16050474, grad/param norm = 1.5327e-01, time/batch = 15.3327s	
8688/33150 (epoch 13.104), train_loss = 1.06739302, grad/param norm = 1.6671e-01, time/batch = 15.3199s	
8689/33150 (epoch 13.106), train_loss = 1.29844589, grad/param norm = 1.7111e-01, time/batch = 15.6835s	
8690/33150 (epoch 13.107), train_loss = 1.38859657, grad/param norm = 1.7821e-01, time/batch = 15.5285s	
8691/33150 (epoch 13.109), train_loss = 1.08502972, grad/param norm = 1.3390e-01, time/batch = 15.6845s	
8692/33150 (epoch 13.110), train_loss = 1.21621749, grad/param norm = 1.4918e-01, time/batch = 16.9638s	
8693/33150 (epoch 13.112), train_loss = 1.04096047, grad/param norm = 1.3866e-01, time/batch = 15.6477s	
8694/33150 (epoch 13.113), train_loss = 1.10599704, grad/param norm = 1.4878e-01, time/batch = 18.7684s	
8695/33150 (epoch 13.115), train_loss = 1.33014195, grad/param norm = 1.7456e-01, time/batch = 16.6045s	
8696/33150 (epoch 13.116), train_loss = 1.06200043, grad/param norm = 1.4059e-01, time/batch = 17.4496s	
8697/33150 (epoch 13.118), train_loss = 1.20294250, grad/param norm = 1.6398e-01, time/batch = 17.2161s	
8698/33150 (epoch 13.119), train_loss = 1.19310226, grad/param norm = 1.7124e-01, time/batch = 18.4802s	
8699/33150 (epoch 13.121), train_loss = 1.08749602, grad/param norm = 1.5415e-01, time/batch = 15.6336s	
8700/33150 (epoch 13.122), train_loss = 1.35419075, grad/param norm = 1.8945e-01, time/batch = 15.1672s	
8701/33150 (epoch 13.124), train_loss = 0.91370613, grad/param norm = 1.2212e-01, time/batch = 16.3837s	
8702/33150 (epoch 13.125), train_loss = 1.23577330, grad/param norm = 1.5219e-01, time/batch = 17.6435s	
8703/33150 (epoch 13.127), train_loss = 1.06910068, grad/param norm = 1.3706e-01, time/batch = 16.5263s	
8704/33150 (epoch 13.128), train_loss = 1.15183213, grad/param norm = 1.5721e-01, time/batch = 16.3591s	
8705/33150 (epoch 13.130), train_loss = 1.17203104, grad/param norm = 1.4589e-01, time/batch = 18.9577s	
8706/33150 (epoch 13.131), train_loss = 1.36597480, grad/param norm = 1.6729e-01, time/batch = 17.9756s	
8707/33150 (epoch 13.133), train_loss = 1.06176291, grad/param norm = 1.3579e-01, time/batch = 17.0358s	
8708/33150 (epoch 13.134), train_loss = 1.26684019, grad/param norm = 1.5877e-01, time/batch = 17.0390s	
8709/33150 (epoch 13.136), train_loss = 1.16844090, grad/param norm = 1.6322e-01, time/batch = 18.4690s	
8710/33150 (epoch 13.137), train_loss = 1.22223632, grad/param norm = 1.5049e-01, time/batch = 16.3865s	
8711/33150 (epoch 13.139), train_loss = 1.21736779, grad/param norm = 1.6622e-01, time/batch = 15.7381s	
8712/33150 (epoch 13.140), train_loss = 1.30153846, grad/param norm = 1.6642e-01, time/batch = 18.6275s	
8713/33150 (epoch 13.142), train_loss = 1.23091132, grad/param norm = 1.5974e-01, time/batch = 15.6163s	
8714/33150 (epoch 13.143), train_loss = 1.16112737, grad/param norm = 1.5527e-01, time/batch = 16.4467s	
8715/33150 (epoch 13.145), train_loss = 1.12719587, grad/param norm = 1.7114e-01, time/batch = 17.6369s	
8716/33150 (epoch 13.146), train_loss = 1.28828389, grad/param norm = 1.7950e-01, time/batch = 18.6129s	
8717/33150 (epoch 13.148), train_loss = 1.25270395, grad/param norm = 1.5620e-01, time/batch = 16.7030s	
8718/33150 (epoch 13.149), train_loss = 1.16988983, grad/param norm = 1.4609e-01, time/batch = 15.2367s	
8719/33150 (epoch 13.151), train_loss = 1.33674141, grad/param norm = 1.5906e-01, time/batch = 16.0372s	
8720/33150 (epoch 13.152), train_loss = 1.10278658, grad/param norm = 1.4389e-01, time/batch = 17.1523s	
8721/33150 (epoch 13.154), train_loss = 1.11499936, grad/param norm = 1.4441e-01, time/batch = 15.9695s	
8722/33150 (epoch 13.155), train_loss = 1.01430830, grad/param norm = 1.3887e-01, time/batch = 17.3893s	
8723/33150 (epoch 13.157), train_loss = 1.07463797, grad/param norm = 1.5922e-01, time/batch = 16.6238s	
8724/33150 (epoch 13.158), train_loss = 1.05018707, grad/param norm = 1.4748e-01, time/batch = 16.4795s	
8725/33150 (epoch 13.160), train_loss = 1.23049916, grad/param norm = 1.5345e-01, time/batch = 15.7322s	
8726/33150 (epoch 13.161), train_loss = 1.08534848, grad/param norm = 1.8292e-01, time/batch = 16.3758s	
8727/33150 (epoch 13.163), train_loss = 1.09130877, grad/param norm = 1.4686e-01, time/batch = 17.3173s	
8728/33150 (epoch 13.164), train_loss = 1.21794559, grad/param norm = 1.6267e-01, time/batch = 16.2008s	
8729/33150 (epoch 13.166), train_loss = 1.10680646, grad/param norm = 1.6031e-01, time/batch = 17.1309s	
8730/33150 (epoch 13.167), train_loss = 1.15991670, grad/param norm = 1.4930e-01, time/batch = 20.2766s	
8731/33150 (epoch 13.169), train_loss = 1.21547215, grad/param norm = 1.8612e-01, time/batch = 16.8616s	
8732/33150 (epoch 13.170), train_loss = 1.06585526, grad/param norm = 1.7476e-01, time/batch = 17.2847s	
8733/33150 (epoch 13.172), train_loss = 1.24607227, grad/param norm = 1.7711e-01, time/batch = 17.9540s	
8734/33150 (epoch 13.173), train_loss = 1.21433078, grad/param norm = 1.8435e-01, time/batch = 17.6222s	
8735/33150 (epoch 13.175), train_loss = 1.05831883, grad/param norm = 1.5887e-01, time/batch = 16.3613s	
8736/33150 (epoch 13.176), train_loss = 1.19359469, grad/param norm = 1.7111e-01, time/batch = 17.4516s	
8737/33150 (epoch 13.178), train_loss = 1.33570985, grad/param norm = 1.5618e-01, time/batch = 15.6316s	
8738/33150 (epoch 13.179), train_loss = 1.18609462, grad/param norm = 1.4341e-01, time/batch = 16.4709s	
8739/33150 (epoch 13.181), train_loss = 1.15314261, grad/param norm = 1.5193e-01, time/batch = 17.4709s	
8740/33150 (epoch 13.183), train_loss = 1.12706194, grad/param norm = 1.6444e-01, time/batch = 17.6286s	
8741/33150 (epoch 13.184), train_loss = 1.34665421, grad/param norm = 1.5864e-01, time/batch = 17.8661s	
8742/33150 (epoch 13.186), train_loss = 1.24734945, grad/param norm = 1.4835e-01, time/batch = 16.2846s	
8743/33150 (epoch 13.187), train_loss = 1.17735643, grad/param norm = 1.5524e-01, time/batch = 17.3096s	
8744/33150 (epoch 13.189), train_loss = 0.94597367, grad/param norm = 1.4890e-01, time/batch = 16.1173s	
8745/33150 (epoch 13.190), train_loss = 1.04053956, grad/param norm = 1.5779e-01, time/batch = 16.8827s	
8746/33150 (epoch 13.192), train_loss = 1.16358516, grad/param norm = 2.1826e-01, time/batch = 15.3705s	
8747/33150 (epoch 13.193), train_loss = 1.19910701, grad/param norm = 1.4753e-01, time/batch = 17.4765s	
8748/33150 (epoch 13.195), train_loss = 1.44302023, grad/param norm = 1.7543e-01, time/batch = 16.6320s	
8749/33150 (epoch 13.196), train_loss = 1.28575708, grad/param norm = 1.5071e-01, time/batch = 15.3178s	
8750/33150 (epoch 13.198), train_loss = 0.98951153, grad/param norm = 1.5469e-01, time/batch = 15.8092s	
8751/33150 (epoch 13.199), train_loss = 1.24458946, grad/param norm = 1.6710e-01, time/batch = 17.6439s	
8752/33150 (epoch 13.201), train_loss = 1.03137351, grad/param norm = 1.3291e-01, time/batch = 17.5744s	
8753/33150 (epoch 13.202), train_loss = 0.95751303, grad/param norm = 1.2738e-01, time/batch = 17.1127s	
8754/33150 (epoch 13.204), train_loss = 1.14921848, grad/param norm = 1.5220e-01, time/batch = 17.3693s	
8755/33150 (epoch 13.205), train_loss = 1.21703227, grad/param norm = 1.5956e-01, time/batch = 17.2164s	
8756/33150 (epoch 13.207), train_loss = 1.18769915, grad/param norm = 1.4830e-01, time/batch = 17.1353s	
8757/33150 (epoch 13.208), train_loss = 1.21121840, grad/param norm = 1.7829e-01, time/batch = 17.4653s	
8758/33150 (epoch 13.210), train_loss = 1.04635167, grad/param norm = 1.3087e-01, time/batch = 16.3030s	
8759/33150 (epoch 13.211), train_loss = 1.21188290, grad/param norm = 1.7260e-01, time/batch = 16.3939s	
8760/33150 (epoch 13.213), train_loss = 1.21545029, grad/param norm = 1.4534e-01, time/batch = 17.1289s	
8761/33150 (epoch 13.214), train_loss = 1.10684125, grad/param norm = 1.5319e-01, time/batch = 16.8060s	
8762/33150 (epoch 13.216), train_loss = 1.09967308, grad/param norm = 1.6321e-01, time/batch = 19.1256s	
8763/33150 (epoch 13.217), train_loss = 1.07823436, grad/param norm = 1.3777e-01, time/batch = 16.3820s	
8764/33150 (epoch 13.219), train_loss = 1.03744821, grad/param norm = 1.4773e-01, time/batch = 17.7838s	
8765/33150 (epoch 13.220), train_loss = 1.07235210, grad/param norm = 1.3034e-01, time/batch = 17.9533s	
8766/33150 (epoch 13.222), train_loss = 1.23432062, grad/param norm = 1.5370e-01, time/batch = 16.4446s	
8767/33150 (epoch 13.223), train_loss = 1.11843820, grad/param norm = 1.5331e-01, time/batch = 16.5480s	
8768/33150 (epoch 13.225), train_loss = 1.31499028, grad/param norm = 1.6184e-01, time/batch = 17.5581s	
8769/33150 (epoch 13.226), train_loss = 1.10436938, grad/param norm = 1.4362e-01, time/batch = 17.5624s	
8770/33150 (epoch 13.228), train_loss = 1.12433655, grad/param norm = 1.4614e-01, time/batch = 16.7093s	
8771/33150 (epoch 13.229), train_loss = 1.10514268, grad/param norm = 1.4604e-01, time/batch = 19.5582s	
8772/33150 (epoch 13.231), train_loss = 1.26447877, grad/param norm = 1.6281e-01, time/batch = 17.5582s	
8773/33150 (epoch 13.232), train_loss = 1.19872977, grad/param norm = 1.9789e-01, time/batch = 18.3092s	
8774/33150 (epoch 13.234), train_loss = 1.14397761, grad/param norm = 1.6873e-01, time/batch = 17.5511s	
8775/33150 (epoch 13.235), train_loss = 1.17654127, grad/param norm = 1.5799e-01, time/batch = 18.1415s	
8776/33150 (epoch 13.237), train_loss = 1.12525613, grad/param norm = 1.7956e-01, time/batch = 15.8884s	
8777/33150 (epoch 13.238), train_loss = 1.23959270, grad/param norm = 1.7358e-01, time/batch = 16.4544s	
8778/33150 (epoch 13.240), train_loss = 1.16296684, grad/param norm = 1.5471e-01, time/batch = 17.7258s	
8779/33150 (epoch 13.241), train_loss = 1.30359104, grad/param norm = 1.6481e-01, time/batch = 17.0460s	
8780/33150 (epoch 13.243), train_loss = 1.25281319, grad/param norm = 1.6593e-01, time/batch = 15.5468s	
8781/33150 (epoch 13.244), train_loss = 1.13442559, grad/param norm = 1.4639e-01, time/batch = 17.1371s	
8782/33150 (epoch 13.246), train_loss = 1.20394779, grad/param norm = 1.5261e-01, time/batch = 16.4756s	
8783/33150 (epoch 13.247), train_loss = 1.04248215, grad/param norm = 1.4462e-01, time/batch = 15.4809s	
8784/33150 (epoch 13.249), train_loss = 1.24858214, grad/param norm = 1.4858e-01, time/batch = 16.0567s	
8785/33150 (epoch 13.250), train_loss = 1.18684511, grad/param norm = 1.2858e-01, time/batch = 16.2821s	
8786/33150 (epoch 13.252), train_loss = 1.19921659, grad/param norm = 1.2744e-01, time/batch = 17.3824s	
8787/33150 (epoch 13.253), train_loss = 1.20603443, grad/param norm = 1.4950e-01, time/batch = 19.4389s	
8788/33150 (epoch 13.255), train_loss = 1.14105473, grad/param norm = 1.3575e-01, time/batch = 28.1604s	
8789/33150 (epoch 13.256), train_loss = 1.19657728, grad/param norm = 1.5452e-01, time/batch = 17.6219s	
8790/33150 (epoch 13.258), train_loss = 1.10094927, grad/param norm = 1.6540e-01, time/batch = 16.9727s	
8791/33150 (epoch 13.259), train_loss = 0.98606995, grad/param norm = 1.5438e-01, time/batch = 19.6329s	
8792/33150 (epoch 13.261), train_loss = 1.00900024, grad/param norm = 1.3970e-01, time/batch = 18.3932s	
8793/33150 (epoch 13.262), train_loss = 1.20567368, grad/param norm = 1.5487e-01, time/batch = 17.9578s	
8794/33150 (epoch 13.264), train_loss = 0.91357258, grad/param norm = 1.3364e-01, time/batch = 16.8814s	
8795/33150 (epoch 13.265), train_loss = 1.20157227, grad/param norm = 1.5755e-01, time/batch = 17.4030s	
8796/33150 (epoch 13.267), train_loss = 1.26152558, grad/param norm = 1.8465e-01, time/batch = 17.4645s	
8797/33150 (epoch 13.268), train_loss = 1.20365221, grad/param norm = 1.5487e-01, time/batch = 15.7857s	
8798/33150 (epoch 13.270), train_loss = 1.34565422, grad/param norm = 1.6160e-01, time/batch = 18.3707s	
8799/33150 (epoch 13.271), train_loss = 1.28306938, grad/param norm = 1.5907e-01, time/batch = 16.5315s	
8800/33150 (epoch 13.273), train_loss = 1.28464883, grad/param norm = 1.5066e-01, time/batch = 17.3849s	
8801/33150 (epoch 13.275), train_loss = 1.29332046, grad/param norm = 1.6334e-01, time/batch = 16.8155s	
8802/33150 (epoch 13.276), train_loss = 1.13402171, grad/param norm = 1.4346e-01, time/batch = 16.3143s	
8803/33150 (epoch 13.278), train_loss = 1.22369489, grad/param norm = 1.5593e-01, time/batch = 15.1400s	
8804/33150 (epoch 13.279), train_loss = 1.15511522, grad/param norm = 1.4066e-01, time/batch = 16.1100s	
8805/33150 (epoch 13.281), train_loss = 1.21052431, grad/param norm = 1.4949e-01, time/batch = 16.8878s	
8806/33150 (epoch 13.282), train_loss = 1.14490817, grad/param norm = 1.3896e-01, time/batch = 16.9648s	
8807/33150 (epoch 13.284), train_loss = 1.08834309, grad/param norm = 1.3589e-01, time/batch = 16.5551s	
8808/33150 (epoch 13.285), train_loss = 1.19208086, grad/param norm = 1.4710e-01, time/batch = 16.8014s	
8809/33150 (epoch 13.287), train_loss = 1.09526663, grad/param norm = 1.3969e-01, time/batch = 17.0504s	
8810/33150 (epoch 13.288), train_loss = 1.32992472, grad/param norm = 1.5996e-01, time/batch = 16.8133s	
8811/33150 (epoch 13.290), train_loss = 0.99516760, grad/param norm = 1.4978e-01, time/batch = 16.0702s	
8812/33150 (epoch 13.291), train_loss = 1.00104166, grad/param norm = 1.4392e-01, time/batch = 17.3016s	
8813/33150 (epoch 13.293), train_loss = 1.22937310, grad/param norm = 1.5243e-01, time/batch = 16.0443s	
8814/33150 (epoch 13.294), train_loss = 0.87807743, grad/param norm = 1.3362e-01, time/batch = 16.6468s	
8815/33150 (epoch 13.296), train_loss = 1.11187820, grad/param norm = 1.4319e-01, time/batch = 15.7050s	
8816/33150 (epoch 13.297), train_loss = 1.06841562, grad/param norm = 1.5014e-01, time/batch = 17.2018s	
8817/33150 (epoch 13.299), train_loss = 1.09146592, grad/param norm = 1.4926e-01, time/batch = 16.9292s	
8818/33150 (epoch 13.300), train_loss = 1.07978501, grad/param norm = 1.2633e-01, time/batch = 16.5247s	
8819/33150 (epoch 13.302), train_loss = 1.09322650, grad/param norm = 1.4813e-01, time/batch = 16.6174s	
8820/33150 (epoch 13.303), train_loss = 1.13232046, grad/param norm = 1.4776e-01, time/batch = 16.4799s	
8821/33150 (epoch 13.305), train_loss = 1.21387471, grad/param norm = 1.4499e-01, time/batch = 16.4791s	
8822/33150 (epoch 13.306), train_loss = 1.19268631, grad/param norm = 1.5619e-01, time/batch = 15.9630s	
8823/33150 (epoch 13.308), train_loss = 1.39045321, grad/param norm = 1.6145e-01, time/batch = 16.6304s	
8824/33150 (epoch 13.309), train_loss = 0.98358222, grad/param norm = 1.2828e-01, time/batch = 16.3194s	
8825/33150 (epoch 13.311), train_loss = 1.11538242, grad/param norm = 1.4115e-01, time/batch = 17.5635s	
8826/33150 (epoch 13.312), train_loss = 0.91173765, grad/param norm = 1.4670e-01, time/batch = 17.7825s	
8827/33150 (epoch 13.314), train_loss = 1.13024425, grad/param norm = 1.4456e-01, time/batch = 17.4637s	
8828/33150 (epoch 13.315), train_loss = 1.20379016, grad/param norm = 1.5293e-01, time/batch = 16.8715s	
8829/33150 (epoch 13.317), train_loss = 0.90418783, grad/param norm = 1.1998e-01, time/batch = 17.1417s	
8830/33150 (epoch 13.318), train_loss = 1.01597562, grad/param norm = 1.3400e-01, time/batch = 16.9074s	
8831/33150 (epoch 13.320), train_loss = 0.97850725, grad/param norm = 1.2768e-01, time/batch = 15.8781s	
8832/33150 (epoch 13.321), train_loss = 1.07377302, grad/param norm = 1.3866e-01, time/batch = 17.6293s	
8833/33150 (epoch 13.323), train_loss = 1.14323463, grad/param norm = 1.4771e-01, time/batch = 16.3699s	
8834/33150 (epoch 13.324), train_loss = 1.23562955, grad/param norm = 1.8906e-01, time/batch = 18.3877s	
8835/33150 (epoch 13.326), train_loss = 1.13915120, grad/param norm = 1.3355e-01, time/batch = 17.5608s	
8836/33150 (epoch 13.327), train_loss = 1.25991867, grad/param norm = 1.4518e-01, time/batch = 17.2152s	
8837/33150 (epoch 13.329), train_loss = 1.19665164, grad/param norm = 1.5537e-01, time/batch = 20.5326s	
8838/33150 (epoch 13.330), train_loss = 1.14169130, grad/param norm = 1.6108e-01, time/batch = 17.9645s	
8839/33150 (epoch 13.332), train_loss = 1.13171241, grad/param norm = 1.2849e-01, time/batch = 17.1133s	
8840/33150 (epoch 13.333), train_loss = 1.17723373, grad/param norm = 1.3433e-01, time/batch = 17.6340s	
8841/33150 (epoch 13.335), train_loss = 1.08683022, grad/param norm = 1.4009e-01, time/batch = 16.1077s	
8842/33150 (epoch 13.336), train_loss = 1.05533253, grad/param norm = 1.5185e-01, time/batch = 15.8806s	
8843/33150 (epoch 13.338), train_loss = 0.93073554, grad/param norm = 1.4480e-01, time/batch = 15.4006s	
8844/33150 (epoch 13.339), train_loss = 1.25794806, grad/param norm = 1.5686e-01, time/batch = 15.2751s	
8845/33150 (epoch 13.341), train_loss = 1.29051905, grad/param norm = 1.9083e-01, time/batch = 15.0070s	
8846/33150 (epoch 13.342), train_loss = 1.01010585, grad/param norm = 1.4515e-01, time/batch = 14.9952s	
8847/33150 (epoch 13.344), train_loss = 1.17528877, grad/param norm = 1.5718e-01, time/batch = 15.5712s	
8848/33150 (epoch 13.345), train_loss = 1.08440124, grad/param norm = 1.4908e-01, time/batch = 15.3532s	
8849/33150 (epoch 13.347), train_loss = 0.91209358, grad/param norm = 1.3116e-01, time/batch = 15.4094s	
8850/33150 (epoch 13.348), train_loss = 1.15245468, grad/param norm = 1.4416e-01, time/batch = 15.4478s	
8851/33150 (epoch 13.350), train_loss = 1.08517233, grad/param norm = 1.7101e-01, time/batch = 15.4296s	
8852/33150 (epoch 13.351), train_loss = 1.23175340, grad/param norm = 1.5987e-01, time/batch = 15.1491s	
8853/33150 (epoch 13.353), train_loss = 1.23085064, grad/param norm = 1.6435e-01, time/batch = 16.8649s	
8854/33150 (epoch 13.354), train_loss = 1.40390396, grad/param norm = 1.6025e-01, time/batch = 15.7835s	
8855/33150 (epoch 13.356), train_loss = 1.24818278, grad/param norm = 1.6741e-01, time/batch = 15.6406s	
8856/33150 (epoch 13.357), train_loss = 1.23846903, grad/param norm = 1.6679e-01, time/batch = 18.2122s	
8857/33150 (epoch 13.359), train_loss = 1.18321549, grad/param norm = 1.5088e-01, time/batch = 16.5414s	
8858/33150 (epoch 13.360), train_loss = 1.21730342, grad/param norm = 1.6369e-01, time/batch = 15.4713s	
8859/33150 (epoch 13.362), train_loss = 1.24516026, grad/param norm = 1.5962e-01, time/batch = 16.6421s	
8860/33150 (epoch 13.363), train_loss = 1.14884754, grad/param norm = 1.3977e-01, time/batch = 17.3174s	
8861/33150 (epoch 13.365), train_loss = 1.12431071, grad/param norm = 1.3797e-01, time/batch = 15.8682s	
8862/33150 (epoch 13.367), train_loss = 1.04144193, grad/param norm = 1.3851e-01, time/batch = 17.5311s	
8863/33150 (epoch 13.368), train_loss = 1.13291065, grad/param norm = 1.5055e-01, time/batch = 16.5324s	
8864/33150 (epoch 13.370), train_loss = 1.17520817, grad/param norm = 1.5989e-01, time/batch = 16.2883s	
8865/33150 (epoch 13.371), train_loss = 1.01731288, grad/param norm = 1.4678e-01, time/batch = 16.9529s	
8866/33150 (epoch 13.373), train_loss = 1.19174785, grad/param norm = 1.6620e-01, time/batch = 16.1941s	
8867/33150 (epoch 13.374), train_loss = 1.12118616, grad/param norm = 1.4418e-01, time/batch = 16.1283s	
8868/33150 (epoch 13.376), train_loss = 1.26192778, grad/param norm = 1.4898e-01, time/batch = 16.8029s	
8869/33150 (epoch 13.377), train_loss = 1.09669128, grad/param norm = 1.6004e-01, time/batch = 15.8034s	
8870/33150 (epoch 13.379), train_loss = 1.23035097, grad/param norm = 1.6161e-01, time/batch = 17.0488s	
8871/33150 (epoch 13.380), train_loss = 1.21978006, grad/param norm = 1.3805e-01, time/batch = 17.6456s	
8872/33150 (epoch 13.382), train_loss = 1.05058112, grad/param norm = 1.4371e-01, time/batch = 17.2678s	
8873/33150 (epoch 13.383), train_loss = 1.04939968, grad/param norm = 1.4049e-01, time/batch = 17.4670s	
8874/33150 (epoch 13.385), train_loss = 1.15899031, grad/param norm = 1.5399e-01, time/batch = 19.4510s	
8875/33150 (epoch 13.386), train_loss = 0.99857669, grad/param norm = 1.3085e-01, time/batch = 16.6319s	
8876/33150 (epoch 13.388), train_loss = 1.11589989, grad/param norm = 1.4486e-01, time/batch = 15.9639s	
8877/33150 (epoch 13.389), train_loss = 1.07440407, grad/param norm = 1.3593e-01, time/batch = 16.8867s	
8878/33150 (epoch 13.391), train_loss = 1.30717042, grad/param norm = 1.5317e-01, time/batch = 17.5657s	
8879/33150 (epoch 13.392), train_loss = 1.09818872, grad/param norm = 1.4133e-01, time/batch = 16.2987s	
8880/33150 (epoch 13.394), train_loss = 1.00219034, grad/param norm = 1.1704e-01, time/batch = 15.4079s	
8881/33150 (epoch 13.395), train_loss = 1.01692161, grad/param norm = 1.4467e-01, time/batch = 17.5730s	
8882/33150 (epoch 13.397), train_loss = 0.84669277, grad/param norm = 1.3432e-01, time/batch = 16.4817s	
8883/33150 (epoch 13.398), train_loss = 1.15283185, grad/param norm = 1.6075e-01, time/batch = 17.0563s	
8884/33150 (epoch 13.400), train_loss = 1.05985566, grad/param norm = 1.2545e-01, time/batch = 15.4120s	
8885/33150 (epoch 13.401), train_loss = 0.95861186, grad/param norm = 1.3526e-01, time/batch = 16.6307s	
8886/33150 (epoch 13.403), train_loss = 1.03337382, grad/param norm = 1.3867e-01, time/batch = 16.5654s	
8887/33150 (epoch 13.404), train_loss = 1.12525179, grad/param norm = 1.4435e-01, time/batch = 15.6345s	
8888/33150 (epoch 13.406), train_loss = 1.02885781, grad/param norm = 1.1772e-01, time/batch = 17.8901s	
8889/33150 (epoch 13.407), train_loss = 0.99892129, grad/param norm = 1.3958e-01, time/batch = 17.6338s	
8890/33150 (epoch 13.409), train_loss = 0.92521929, grad/param norm = 1.3198e-01, time/batch = 15.5416s	
8891/33150 (epoch 13.410), train_loss = 1.16089944, grad/param norm = 1.5278e-01, time/batch = 18.2122s	
8892/33150 (epoch 13.412), train_loss = 1.16261758, grad/param norm = 1.4607e-01, time/batch = 16.4565s	
8893/33150 (epoch 13.413), train_loss = 1.08105155, grad/param norm = 1.5158e-01, time/batch = 16.7100s	
8894/33150 (epoch 13.415), train_loss = 1.22417791, grad/param norm = 1.4005e-01, time/batch = 15.6167s	
8895/33150 (epoch 13.416), train_loss = 1.05707579, grad/param norm = 1.3471e-01, time/batch = 17.8641s	
8896/33150 (epoch 13.418), train_loss = 1.31374191, grad/param norm = 1.8283e-01, time/batch = 17.1300s	
8897/33150 (epoch 13.419), train_loss = 1.07149157, grad/param norm = 1.5076e-01, time/batch = 18.2822s	
8898/33150 (epoch 13.421), train_loss = 1.15509917, grad/param norm = 1.6222e-01, time/batch = 17.2146s	
8899/33150 (epoch 13.422), train_loss = 1.08168777, grad/param norm = 1.4597e-01, time/batch = 17.4593s	
8900/33150 (epoch 13.424), train_loss = 1.07704876, grad/param norm = 1.4695e-01, time/batch = 16.5585s	
8901/33150 (epoch 13.425), train_loss = 1.12581091, grad/param norm = 1.4399e-01, time/batch = 17.1963s	
8902/33150 (epoch 13.427), train_loss = 1.10356063, grad/param norm = 1.3878e-01, time/batch = 17.6035s	
8903/33150 (epoch 13.428), train_loss = 1.14739796, grad/param norm = 1.5892e-01, time/batch = 18.9404s	
8904/33150 (epoch 13.430), train_loss = 1.16422332, grad/param norm = 1.5600e-01, time/batch = 17.8691s	
8905/33150 (epoch 13.431), train_loss = 1.22597890, grad/param norm = 1.7603e-01, time/batch = 17.2026s	
8906/33150 (epoch 13.433), train_loss = 1.08519292, grad/param norm = 1.3739e-01, time/batch = 17.9432s	
8907/33150 (epoch 13.434), train_loss = 1.01570428, grad/param norm = 1.4903e-01, time/batch = 17.1171s	
8908/33150 (epoch 13.436), train_loss = 1.02390617, grad/param norm = 1.6203e-01, time/batch = 17.3864s	
8909/33150 (epoch 13.437), train_loss = 1.12224448, grad/param norm = 1.7111e-01, time/batch = 18.1270s	
8910/33150 (epoch 13.439), train_loss = 1.24027725, grad/param norm = 1.5852e-01, time/batch = 15.4484s	
8911/33150 (epoch 13.440), train_loss = 1.23951882, grad/param norm = 1.5379e-01, time/batch = 15.7467s	
8912/33150 (epoch 13.442), train_loss = 1.00469904, grad/param norm = 1.3845e-01, time/batch = 15.5173s	
8913/33150 (epoch 13.443), train_loss = 1.24024735, grad/param norm = 1.5724e-01, time/batch = 16.2171s	
8914/33150 (epoch 13.445), train_loss = 1.14406579, grad/param norm = 1.6112e-01, time/batch = 17.4617s	
8915/33150 (epoch 13.446), train_loss = 1.14424412, grad/param norm = 1.8596e-01, time/batch = 16.7234s	
8916/33150 (epoch 13.448), train_loss = 1.21152731, grad/param norm = 1.5110e-01, time/batch = 17.7180s	
8917/33150 (epoch 13.449), train_loss = 1.13143533, grad/param norm = 1.4183e-01, time/batch = 19.3759s	
8918/33150 (epoch 13.451), train_loss = 1.21530816, grad/param norm = 1.6689e-01, time/batch = 16.0553s	
8919/33150 (epoch 13.452), train_loss = 1.40376249, grad/param norm = 1.7349e-01, time/batch = 18.9585s	
8920/33150 (epoch 13.454), train_loss = 1.10889501, grad/param norm = 1.4735e-01, time/batch = 18.8673s	
8921/33150 (epoch 13.456), train_loss = 0.96023934, grad/param norm = 1.3739e-01, time/batch = 16.3770s	
8922/33150 (epoch 13.457), train_loss = 1.14578763, grad/param norm = 1.5378e-01, time/batch = 15.1194s	
8923/33150 (epoch 13.459), train_loss = 1.29265153, grad/param norm = 1.8364e-01, time/batch = 17.0557s	
8924/33150 (epoch 13.460), train_loss = 1.16658469, grad/param norm = 1.3254e-01, time/batch = 15.7303s	
8925/33150 (epoch 13.462), train_loss = 1.23803377, grad/param norm = 2.0302e-01, time/batch = 15.4698s	
8926/33150 (epoch 13.463), train_loss = 1.42649274, grad/param norm = 1.9602e-01, time/batch = 17.7916s	
8927/33150 (epoch 13.465), train_loss = 1.07196131, grad/param norm = 1.3954e-01, time/batch = 17.7229s	
8928/33150 (epoch 13.466), train_loss = 1.06502769, grad/param norm = 1.3862e-01, time/batch = 17.7908s	
8929/33150 (epoch 13.468), train_loss = 1.44119582, grad/param norm = 1.6333e-01, time/batch = 16.7594s	
8930/33150 (epoch 13.469), train_loss = 1.14360505, grad/param norm = 1.5504e-01, time/batch = 17.2958s	
8931/33150 (epoch 13.471), train_loss = 1.08929467, grad/param norm = 1.4466e-01, time/batch = 18.8739s	
8932/33150 (epoch 13.472), train_loss = 1.12590670, grad/param norm = 1.4244e-01, time/batch = 17.1120s	
8933/33150 (epoch 13.474), train_loss = 1.26219092, grad/param norm = 1.7609e-01, time/batch = 19.2911s	
8934/33150 (epoch 13.475), train_loss = 1.40774624, grad/param norm = 1.5986e-01, time/batch = 18.5363s	
8935/33150 (epoch 13.477), train_loss = 1.23031980, grad/param norm = 1.6597e-01, time/batch = 16.9525s	
8936/33150 (epoch 13.478), train_loss = 1.25672006, grad/param norm = 1.4852e-01, time/batch = 16.8628s	
8937/33150 (epoch 13.480), train_loss = 1.08803723, grad/param norm = 1.4943e-01, time/batch = 18.4614s	
8938/33150 (epoch 13.481), train_loss = 0.97101613, grad/param norm = 1.5288e-01, time/batch = 17.5392s	
8939/33150 (epoch 13.483), train_loss = 1.08484875, grad/param norm = 1.3868e-01, time/batch = 17.1184s	
8940/33150 (epoch 13.484), train_loss = 1.08928673, grad/param norm = 1.5765e-01, time/batch = 15.3078s	
8941/33150 (epoch 13.486), train_loss = 1.10266426, grad/param norm = 1.5688e-01, time/batch = 17.5593s	
8942/33150 (epoch 13.487), train_loss = 1.18467642, grad/param norm = 1.5673e-01, time/batch = 15.8337s	
8943/33150 (epoch 13.489), train_loss = 1.15407226, grad/param norm = 1.6794e-01, time/batch = 16.6996s	
8944/33150 (epoch 13.490), train_loss = 0.98234193, grad/param norm = 1.3839e-01, time/batch = 15.3759s	
8945/33150 (epoch 13.492), train_loss = 1.08405163, grad/param norm = 1.5983e-01, time/batch = 18.4553s	
8946/33150 (epoch 13.493), train_loss = 1.23968746, grad/param norm = 1.6928e-01, time/batch = 16.2683s	
8947/33150 (epoch 13.495), train_loss = 1.25799861, grad/param norm = 1.5599e-01, time/batch = 17.3932s	
8948/33150 (epoch 13.496), train_loss = 1.05872116, grad/param norm = 1.4830e-01, time/batch = 17.2130s	
8949/33150 (epoch 13.498), train_loss = 1.26409557, grad/param norm = 1.8908e-01, time/batch = 17.0632s	
8950/33150 (epoch 13.499), train_loss = 1.31622594, grad/param norm = 1.6171e-01, time/batch = 16.8228s	
8951/33150 (epoch 13.501), train_loss = 1.18479309, grad/param norm = 1.5200e-01, time/batch = 17.3095s	
8952/33150 (epoch 13.502), train_loss = 1.30655625, grad/param norm = 1.6827e-01, time/batch = 17.5481s	
8953/33150 (epoch 13.504), train_loss = 1.20281268, grad/param norm = 1.5945e-01, time/batch = 16.3775s	
8954/33150 (epoch 13.505), train_loss = 1.37650654, grad/param norm = 1.8895e-01, time/batch = 18.1180s	
8955/33150 (epoch 13.507), train_loss = 1.07928153, grad/param norm = 1.4267e-01, time/batch = 17.5853s	
8956/33150 (epoch 13.508), train_loss = 1.09773046, grad/param norm = 1.4611e-01, time/batch = 16.7066s	
8957/33150 (epoch 13.510), train_loss = 1.16404833, grad/param norm = 1.5402e-01, time/batch = 17.5167s	
8958/33150 (epoch 13.511), train_loss = 1.33195058, grad/param norm = 1.7091e-01, time/batch = 18.2866s	
8959/33150 (epoch 13.513), train_loss = 1.18371684, grad/param norm = 1.6567e-01, time/batch = 17.9459s	
8960/33150 (epoch 13.514), train_loss = 0.96050995, grad/param norm = 1.4263e-01, time/batch = 17.6291s	
8961/33150 (epoch 13.516), train_loss = 1.27815959, grad/param norm = 1.8158e-01, time/batch = 16.7012s	
8962/33150 (epoch 13.517), train_loss = 1.25405539, grad/param norm = 1.4765e-01, time/batch = 20.5384s	
8963/33150 (epoch 13.519), train_loss = 1.06685251, grad/param norm = 1.3916e-01, time/batch = 16.1073s	
8964/33150 (epoch 13.520), train_loss = 1.16042776, grad/param norm = 1.4391e-01, time/batch = 17.2083s	
8965/33150 (epoch 13.522), train_loss = 1.31173237, grad/param norm = 1.8624e-01, time/batch = 17.1460s	
8966/33150 (epoch 13.523), train_loss = 1.05535223, grad/param norm = 1.5176e-01, time/batch = 19.2003s	
8967/33150 (epoch 13.525), train_loss = 1.20065776, grad/param norm = 1.5275e-01, time/batch = 17.8863s	
8968/33150 (epoch 13.526), train_loss = 1.05557082, grad/param norm = 1.3946e-01, time/batch = 17.5431s	
8969/33150 (epoch 13.528), train_loss = 1.21371496, grad/param norm = 1.5535e-01, time/batch = 18.3830s	
8970/33150 (epoch 13.529), train_loss = 1.17350151, grad/param norm = 1.4809e-01, time/batch = 15.0467s	
8971/33150 (epoch 13.531), train_loss = 0.99100703, grad/param norm = 1.5323e-01, time/batch = 17.7954s	
8972/33150 (epoch 13.532), train_loss = 1.17117036, grad/param norm = 1.5656e-01, time/batch = 18.2168s	
8973/33150 (epoch 13.534), train_loss = 1.09430779, grad/param norm = 1.3478e-01, time/batch = 15.6979s	
8974/33150 (epoch 13.535), train_loss = 1.05930779, grad/param norm = 1.6539e-01, time/batch = 17.7172s	
8975/33150 (epoch 13.537), train_loss = 1.25371948, grad/param norm = 1.5494e-01, time/batch = 16.6437s	
8976/33150 (epoch 13.538), train_loss = 1.10080711, grad/param norm = 1.5216e-01, time/batch = 16.9735s	
8977/33150 (epoch 13.540), train_loss = 0.99306005, grad/param norm = 1.4424e-01, time/batch = 16.0467s	
8978/33150 (epoch 13.541), train_loss = 1.24594471, grad/param norm = 1.6136e-01, time/batch = 18.7181s	
8979/33150 (epoch 13.543), train_loss = 1.18810835, grad/param norm = 1.4176e-01, time/batch = 19.1229s	
8980/33150 (epoch 13.544), train_loss = 1.17530495, grad/param norm = 1.4375e-01, time/batch = 17.0525s	
8981/33150 (epoch 13.546), train_loss = 1.27846137, grad/param norm = 1.6156e-01, time/batch = 18.2916s	
8982/33150 (epoch 13.548), train_loss = 1.19689161, grad/param norm = 1.5799e-01, time/batch = 18.7932s	
8983/33150 (epoch 13.549), train_loss = 1.11432527, grad/param norm = 1.3805e-01, time/batch = 18.0492s	
8984/33150 (epoch 13.551), train_loss = 1.05092110, grad/param norm = 1.3866e-01, time/batch = 17.5520s	
8985/33150 (epoch 13.552), train_loss = 0.93754868, grad/param norm = 1.2179e-01, time/batch = 18.3180s	
8986/33150 (epoch 13.554), train_loss = 1.19407342, grad/param norm = 1.4774e-01, time/batch = 16.7087s	
8987/33150 (epoch 13.555), train_loss = 1.33169173, grad/param norm = 1.6917e-01, time/batch = 16.5579s	
8988/33150 (epoch 13.557), train_loss = 0.97483372, grad/param norm = 1.4258e-01, time/batch = 19.7958s	
8989/33150 (epoch 13.558), train_loss = 1.22866811, grad/param norm = 1.8190e-01, time/batch = 17.2975s	
8990/33150 (epoch 13.560), train_loss = 1.08880094, grad/param norm = 1.4269e-01, time/batch = 16.2157s	
8991/33150 (epoch 13.561), train_loss = 0.97215538, grad/param norm = 1.4333e-01, time/batch = 19.0392s	
8992/33150 (epoch 13.563), train_loss = 1.23513973, grad/param norm = 2.1438e-01, time/batch = 17.1383s	
8993/33150 (epoch 13.564), train_loss = 1.33231016, grad/param norm = 1.6197e-01, time/batch = 17.5495s	
8994/33150 (epoch 13.566), train_loss = 1.15547961, grad/param norm = 1.5745e-01, time/batch = 18.2048s	
8995/33150 (epoch 13.567), train_loss = 1.02727583, grad/param norm = 1.3473e-01, time/batch = 19.2087s	
8996/33150 (epoch 13.569), train_loss = 1.16273956, grad/param norm = 1.4948e-01, time/batch = 19.4426s	
8997/33150 (epoch 13.570), train_loss = 1.20433150, grad/param norm = 1.4788e-01, time/batch = 30.8019s	
8998/33150 (epoch 13.572), train_loss = 1.05559420, grad/param norm = 1.3804e-01, time/batch = 18.9608s	
8999/33150 (epoch 13.573), train_loss = 0.92402111, grad/param norm = 1.2351e-01, time/batch = 15.6043s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch13.57_1.5574.t7	
9000/33150 (epoch 13.575), train_loss = 1.10942606, grad/param norm = 1.4322e-01, time/batch = 15.3999s	
9001/33150 (epoch 13.576), train_loss = 1.22628532, grad/param norm = 1.3990e-01, time/batch = 16.7999s	
9002/33150 (epoch 13.578), train_loss = 1.05725385, grad/param norm = 1.2874e-01, time/batch = 15.7812s	
9003/33150 (epoch 13.579), train_loss = 0.98063902, grad/param norm = 1.4679e-01, time/batch = 16.6064s	
9004/33150 (epoch 13.581), train_loss = 1.03738732, grad/param norm = 1.4752e-01, time/batch = 16.2115s	
9005/33150 (epoch 13.582), train_loss = 1.22028146, grad/param norm = 1.4998e-01, time/batch = 17.7712s	
9006/33150 (epoch 13.584), train_loss = 1.22239866, grad/param norm = 1.4921e-01, time/batch = 16.0467s	
9007/33150 (epoch 13.585), train_loss = 1.15865579, grad/param norm = 1.5337e-01, time/batch = 16.5389s	
9008/33150 (epoch 13.587), train_loss = 1.18908373, grad/param norm = 1.5058e-01, time/batch = 16.2950s	
9009/33150 (epoch 13.588), train_loss = 1.03966666, grad/param norm = 1.4477e-01, time/batch = 17.7967s	
9010/33150 (epoch 13.590), train_loss = 1.13380406, grad/param norm = 1.4735e-01, time/batch = 19.5265s	
9011/33150 (epoch 13.591), train_loss = 1.13181330, grad/param norm = 1.4071e-01, time/batch = 16.8260s	
9012/33150 (epoch 13.593), train_loss = 1.20255672, grad/param norm = 1.5278e-01, time/batch = 16.9031s	
9013/33150 (epoch 13.594), train_loss = 1.14726010, grad/param norm = 1.4614e-01, time/batch = 18.0618s	
9014/33150 (epoch 13.596), train_loss = 1.05783808, grad/param norm = 1.4385e-01, time/batch = 17.5465s	
9015/33150 (epoch 13.597), train_loss = 1.01565687, grad/param norm = 1.7015e-01, time/batch = 18.0653s	
9016/33150 (epoch 13.599), train_loss = 1.33348404, grad/param norm = 1.6947e-01, time/batch = 16.0476s	
9017/33150 (epoch 13.600), train_loss = 1.16295818, grad/param norm = 1.9349e-01, time/batch = 17.7832s	
9018/33150 (epoch 13.602), train_loss = 1.08840209, grad/param norm = 1.5491e-01, time/batch = 18.3845s	
9019/33150 (epoch 13.603), train_loss = 1.18829309, grad/param norm = 1.5334e-01, time/batch = 17.2001s	
9020/33150 (epoch 13.605), train_loss = 1.03305692, grad/param norm = 1.4956e-01, time/batch = 17.3017s	
9021/33150 (epoch 13.606), train_loss = 1.18045527, grad/param norm = 1.8109e-01, time/batch = 17.7076s	
9022/33150 (epoch 13.608), train_loss = 1.18462828, grad/param norm = 1.5618e-01, time/batch = 17.1095s	
9023/33150 (epoch 13.609), train_loss = 1.12517125, grad/param norm = 1.6551e-01, time/batch = 15.4631s	
9024/33150 (epoch 13.611), train_loss = 0.97877215, grad/param norm = 1.5458e-01, time/batch = 18.0195s	
9025/33150 (epoch 13.612), train_loss = 1.14842486, grad/param norm = 1.6156e-01, time/batch = 16.7326s	
9026/33150 (epoch 13.614), train_loss = 0.97889370, grad/param norm = 1.4793e-01, time/batch = 18.6192s	
9027/33150 (epoch 13.615), train_loss = 1.03790387, grad/param norm = 1.4334e-01, time/batch = 17.3853s	
9028/33150 (epoch 13.617), train_loss = 1.13949812, grad/param norm = 1.6518e-01, time/batch = 17.0527s	
9029/33150 (epoch 13.618), train_loss = 1.13635843, grad/param norm = 1.4465e-01, time/batch = 17.2872s	
9030/33150 (epoch 13.620), train_loss = 1.06190757, grad/param norm = 1.5886e-01, time/batch = 17.4611s	
9031/33150 (epoch 13.621), train_loss = 1.11290051, grad/param norm = 1.4697e-01, time/batch = 19.2947s	
9032/33150 (epoch 13.623), train_loss = 1.18433444, grad/param norm = 1.4464e-01, time/batch = 17.7982s	
9033/33150 (epoch 13.624), train_loss = 1.06614932, grad/param norm = 1.5792e-01, time/batch = 17.2007s	
9034/33150 (epoch 13.626), train_loss = 1.06884232, grad/param norm = 1.5580e-01, time/batch = 18.1160s	
9035/33150 (epoch 13.627), train_loss = 1.00509038, grad/param norm = 1.4611e-01, time/batch = 19.3715s	
9036/33150 (epoch 13.629), train_loss = 0.98947226, grad/param norm = 1.4209e-01, time/batch = 18.5273s	
9037/33150 (epoch 13.630), train_loss = 1.05059703, grad/param norm = 1.3465e-01, time/batch = 15.9379s	
9038/33150 (epoch 13.632), train_loss = 0.96486963, grad/param norm = 1.5560e-01, time/batch = 16.8965s	
9039/33150 (epoch 13.633), train_loss = 0.98325994, grad/param norm = 1.6625e-01, time/batch = 19.1283s	
9040/33150 (epoch 13.635), train_loss = 1.32117225, grad/param norm = 1.6394e-01, time/batch = 18.1283s	
9041/33150 (epoch 13.637), train_loss = 0.94347644, grad/param norm = 1.4968e-01, time/batch = 16.5342s	
9042/33150 (epoch 13.638), train_loss = 1.07630034, grad/param norm = 1.3856e-01, time/batch = 18.9671s	
9043/33150 (epoch 13.640), train_loss = 1.22986062, grad/param norm = 1.6781e-01, time/batch = 16.8118s	
9044/33150 (epoch 13.641), train_loss = 1.01438973, grad/param norm = 1.5088e-01, time/batch = 17.7264s	
9045/33150 (epoch 13.643), train_loss = 1.04297697, grad/param norm = 1.4036e-01, time/batch = 15.7289s	
9046/33150 (epoch 13.644), train_loss = 1.27469275, grad/param norm = 1.5341e-01, time/batch = 17.4795s	
9047/33150 (epoch 13.646), train_loss = 1.07330954, grad/param norm = 1.4748e-01, time/batch = 15.5702s	
9048/33150 (epoch 13.647), train_loss = 1.38868213, grad/param norm = 1.6251e-01, time/batch = 15.5887s	
9049/33150 (epoch 13.649), train_loss = 1.22449290, grad/param norm = 1.6950e-01, time/batch = 15.0990s	
9050/33150 (epoch 13.650), train_loss = 0.98836344, grad/param norm = 1.3020e-01, time/batch = 16.0471s	
9051/33150 (epoch 13.652), train_loss = 1.25682803, grad/param norm = 1.7294e-01, time/batch = 16.2186s	
9052/33150 (epoch 13.653), train_loss = 1.11507072, grad/param norm = 1.3836e-01, time/batch = 17.5249s	
9053/33150 (epoch 13.655), train_loss = 1.18762536, grad/param norm = 1.6897e-01, time/batch = 17.3849s	
9054/33150 (epoch 13.656), train_loss = 1.10981533, grad/param norm = 1.4351e-01, time/batch = 17.1183s	
9055/33150 (epoch 13.658), train_loss = 1.12745253, grad/param norm = 1.7241e-01, time/batch = 19.2820s	
9056/33150 (epoch 13.659), train_loss = 1.46779969, grad/param norm = 2.4720e-01, time/batch = 15.8018s	
9057/33150 (epoch 13.661), train_loss = 1.11795923, grad/param norm = 1.6802e-01, time/batch = 16.4595s	
9058/33150 (epoch 13.662), train_loss = 0.96184084, grad/param norm = 1.4622e-01, time/batch = 17.3901s	
9059/33150 (epoch 13.664), train_loss = 1.25302258, grad/param norm = 1.5710e-01, time/batch = 17.6285s	
9060/33150 (epoch 13.665), train_loss = 1.21842047, grad/param norm = 1.6583e-01, time/batch = 19.2927s	
9061/33150 (epoch 13.667), train_loss = 1.28014441, grad/param norm = 1.6783e-01, time/batch = 16.8128s	
9062/33150 (epoch 13.668), train_loss = 1.21316887, grad/param norm = 1.4998e-01, time/batch = 16.5684s	
9063/33150 (epoch 13.670), train_loss = 1.06410319, grad/param norm = 1.3804e-01, time/batch = 17.1590s	
9064/33150 (epoch 13.671), train_loss = 1.08139775, grad/param norm = 1.7362e-01, time/batch = 15.9592s	
9065/33150 (epoch 13.673), train_loss = 1.22844595, grad/param norm = 1.2851e-01, time/batch = 17.5436s	
9066/33150 (epoch 13.674), train_loss = 1.12878064, grad/param norm = 1.4182e-01, time/batch = 18.2212s	
9067/33150 (epoch 13.676), train_loss = 1.08215996, grad/param norm = 1.3786e-01, time/batch = 17.9582s	
9068/33150 (epoch 13.677), train_loss = 1.39235019, grad/param norm = 1.7063e-01, time/batch = 16.3858s	
9069/33150 (epoch 13.679), train_loss = 1.08513275, grad/param norm = 1.4425e-01, time/batch = 18.2949s	
9070/33150 (epoch 13.680), train_loss = 1.28510897, grad/param norm = 1.5695e-01, time/batch = 16.4751s	
9071/33150 (epoch 13.682), train_loss = 1.05529468, grad/param norm = 1.4778e-01, time/batch = 18.1487s	
9072/33150 (epoch 13.683), train_loss = 0.95107820, grad/param norm = 1.2977e-01, time/batch = 18.8775s	
9073/33150 (epoch 13.685), train_loss = 1.14894640, grad/param norm = 1.6776e-01, time/batch = 17.0665s	
9074/33150 (epoch 13.686), train_loss = 0.97370655, grad/param norm = 1.3719e-01, time/batch = 17.5484s	
9075/33150 (epoch 13.688), train_loss = 1.04542780, grad/param norm = 1.3812e-01, time/batch = 17.2092s	
9076/33150 (epoch 13.689), train_loss = 1.03316219, grad/param norm = 1.2967e-01, time/batch = 17.9483s	
9077/33150 (epoch 13.691), train_loss = 0.94625292, grad/param norm = 1.3085e-01, time/batch = 19.0183s	
9078/33150 (epoch 13.692), train_loss = 1.00706006, grad/param norm = 1.3212e-01, time/batch = 15.8644s	
9079/33150 (epoch 13.694), train_loss = 0.88859337, grad/param norm = 1.1975e-01, time/batch = 14.8816s	
9080/33150 (epoch 13.695), train_loss = 1.05453861, grad/param norm = 1.4113e-01, time/batch = 16.2998s	
9081/33150 (epoch 13.697), train_loss = 0.92413421, grad/param norm = 1.1831e-01, time/batch = 17.8606s	
9082/33150 (epoch 13.698), train_loss = 1.12973259, grad/param norm = 1.5497e-01, time/batch = 17.4640s	
9083/33150 (epoch 13.700), train_loss = 0.84002269, grad/param norm = 1.2384e-01, time/batch = 18.6150s	
9084/33150 (epoch 13.701), train_loss = 1.00066482, grad/param norm = 1.4008e-01, time/batch = 16.2507s	
9085/33150 (epoch 13.703), train_loss = 1.09426903, grad/param norm = 1.4593e-01, time/batch = 16.2424s	
9086/33150 (epoch 13.704), train_loss = 0.92538948, grad/param norm = 1.2299e-01, time/batch = 18.1480s	
9087/33150 (epoch 13.706), train_loss = 1.06874001, grad/param norm = 1.3999e-01, time/batch = 15.9796s	
9088/33150 (epoch 13.707), train_loss = 1.05515347, grad/param norm = 1.4604e-01, time/batch = 17.4670s	
9089/33150 (epoch 13.709), train_loss = 1.11371728, grad/param norm = 1.3229e-01, time/batch = 17.5620s	
9090/33150 (epoch 13.710), train_loss = 1.17070569, grad/param norm = 1.6532e-01, time/batch = 17.5577s	
9091/33150 (epoch 13.712), train_loss = 1.20543081, grad/param norm = 1.6293e-01, time/batch = 18.8883s	
9092/33150 (epoch 13.713), train_loss = 1.19280076, grad/param norm = 1.5602e-01, time/batch = 16.2127s	
9093/33150 (epoch 13.715), train_loss = 1.06979867, grad/param norm = 1.4369e-01, time/batch = 17.6468s	
9094/33150 (epoch 13.716), train_loss = 1.15353017, grad/param norm = 1.4956e-01, time/batch = 15.4862s	
9095/33150 (epoch 13.718), train_loss = 1.12746797, grad/param norm = 1.4083e-01, time/batch = 14.6411s	
9096/33150 (epoch 13.719), train_loss = 1.23410394, grad/param norm = 1.7839e-01, time/batch = 17.2920s	
9097/33150 (epoch 13.721), train_loss = 1.10985972, grad/param norm = 1.5340e-01, time/batch = 17.6452s	
9098/33150 (epoch 13.722), train_loss = 1.16117971, grad/param norm = 1.4375e-01, time/batch = 18.6434s	
9099/33150 (epoch 13.724), train_loss = 1.08131145, grad/param norm = 1.6588e-01, time/batch = 15.5013s	
9100/33150 (epoch 13.725), train_loss = 1.26619047, grad/param norm = 1.7740e-01, time/batch = 14.9433s	
9101/33150 (epoch 13.727), train_loss = 1.13301670, grad/param norm = 1.5630e-01, time/batch = 16.4525s	
9102/33150 (epoch 13.729), train_loss = 1.12408759, grad/param norm = 1.5001e-01, time/batch = 16.9506s	
9103/33150 (epoch 13.730), train_loss = 1.12312754, grad/param norm = 1.4984e-01, time/batch = 16.4728s	
9104/33150 (epoch 13.732), train_loss = 1.23162181, grad/param norm = 1.6849e-01, time/batch = 18.3176s	
9105/33150 (epoch 13.733), train_loss = 0.90931390, grad/param norm = 1.1748e-01, time/batch = 17.7335s	
9106/33150 (epoch 13.735), train_loss = 1.06666107, grad/param norm = 1.4081e-01, time/batch = 16.0521s	
9107/33150 (epoch 13.736), train_loss = 1.08503146, grad/param norm = 1.5790e-01, time/batch = 16.9817s	
9108/33150 (epoch 13.738), train_loss = 1.16098388, grad/param norm = 1.6397e-01, time/batch = 18.1331s	
9109/33150 (epoch 13.739), train_loss = 1.27230368, grad/param norm = 1.6231e-01, time/batch = 15.1067s	
9110/33150 (epoch 13.741), train_loss = 1.24718747, grad/param norm = 1.6699e-01, time/batch = 15.8773s	
9111/33150 (epoch 13.742), train_loss = 1.03823662, grad/param norm = 1.5392e-01, time/batch = 15.5293s	
9112/33150 (epoch 13.744), train_loss = 1.25883849, grad/param norm = 1.6704e-01, time/batch = 15.1090s	
9113/33150 (epoch 13.745), train_loss = 1.07603101, grad/param norm = 1.3612e-01, time/batch = 15.0267s	
9114/33150 (epoch 13.747), train_loss = 0.96207534, grad/param norm = 1.5222e-01, time/batch = 14.8812s	
9115/33150 (epoch 13.748), train_loss = 1.03962660, grad/param norm = 1.3695e-01, time/batch = 18.0535s	
9116/33150 (epoch 13.750), train_loss = 1.21032262, grad/param norm = 1.6456e-01, time/batch = 17.8628s	
9117/33150 (epoch 13.751), train_loss = 1.13042343, grad/param norm = 1.4361e-01, time/batch = 16.8090s	
9118/33150 (epoch 13.753), train_loss = 0.96388187, grad/param norm = 1.4079e-01, time/batch = 19.8722s	
9119/33150 (epoch 13.754), train_loss = 1.34953467, grad/param norm = 1.8104e-01, time/batch = 18.7988s	
9120/33150 (epoch 13.756), train_loss = 1.17874013, grad/param norm = 1.6461e-01, time/batch = 16.1551s	
9121/33150 (epoch 13.757), train_loss = 1.13902688, grad/param norm = 1.4814e-01, time/batch = 16.4011s	
9122/33150 (epoch 13.759), train_loss = 1.28466098, grad/param norm = 1.7555e-01, time/batch = 17.8802s	
9123/33150 (epoch 13.760), train_loss = 1.17751068, grad/param norm = 1.5801e-01, time/batch = 16.8773s	
9124/33150 (epoch 13.762), train_loss = 1.15372579, grad/param norm = 1.6048e-01, time/batch = 16.6342s	
9125/33150 (epoch 13.763), train_loss = 1.16099884, grad/param norm = 1.6095e-01, time/batch = 17.7238s	
9126/33150 (epoch 13.765), train_loss = 1.09859435, grad/param norm = 1.3603e-01, time/batch = 18.0660s	
9127/33150 (epoch 13.766), train_loss = 1.01718383, grad/param norm = 1.3816e-01, time/batch = 16.6095s	
9128/33150 (epoch 13.768), train_loss = 1.06889300, grad/param norm = 1.4264e-01, time/batch = 16.4691s	
9129/33150 (epoch 13.769), train_loss = 1.15409565, grad/param norm = 1.5770e-01, time/batch = 17.7949s	
9130/33150 (epoch 13.771), train_loss = 1.15129357, grad/param norm = 1.4580e-01, time/batch = 18.3710s	
9131/33150 (epoch 13.772), train_loss = 1.20061042, grad/param norm = 1.6637e-01, time/batch = 17.9525s	
9132/33150 (epoch 13.774), train_loss = 1.29876732, grad/param norm = 1.5648e-01, time/batch = 18.8709s	
9133/33150 (epoch 13.775), train_loss = 1.21102837, grad/param norm = 1.8386e-01, time/batch = 18.9561s	
9134/33150 (epoch 13.777), train_loss = 1.22300470, grad/param norm = 1.6519e-01, time/batch = 16.5473s	
9135/33150 (epoch 13.778), train_loss = 1.13764902, grad/param norm = 1.3180e-01, time/batch = 18.8088s	
9136/33150 (epoch 13.780), train_loss = 0.99453357, grad/param norm = 1.3528e-01, time/batch = 18.3946s	
9137/33150 (epoch 13.781), train_loss = 1.11448069, grad/param norm = 1.3692e-01, time/batch = 16.6277s	
9138/33150 (epoch 13.783), train_loss = 1.14370059, grad/param norm = 1.3634e-01, time/batch = 18.3270s	
9139/33150 (epoch 13.784), train_loss = 1.08995125, grad/param norm = 1.5605e-01, time/batch = 18.1463s	
9140/33150 (epoch 13.786), train_loss = 1.06785465, grad/param norm = 1.2763e-01, time/batch = 18.2197s	
9141/33150 (epoch 13.787), train_loss = 1.06633381, grad/param norm = 1.4364e-01, time/batch = 17.6324s	
9142/33150 (epoch 13.789), train_loss = 0.94657671, grad/param norm = 1.2980e-01, time/batch = 16.9787s	
9143/33150 (epoch 13.790), train_loss = 0.95053548, grad/param norm = 1.1908e-01, time/batch = 20.3818s	
9144/33150 (epoch 13.792), train_loss = 1.16639619, grad/param norm = 1.6865e-01, time/batch = 17.1393s	
9145/33150 (epoch 13.793), train_loss = 1.13076615, grad/param norm = 1.5725e-01, time/batch = 17.7068s	
9146/33150 (epoch 13.795), train_loss = 1.04684389, grad/param norm = 1.5100e-01, time/batch = 15.0055s	
9147/33150 (epoch 13.796), train_loss = 1.06370773, grad/param norm = 1.4952e-01, time/batch = 14.9084s	
9148/33150 (epoch 13.798), train_loss = 1.04678648, grad/param norm = 1.2599e-01, time/batch = 15.4231s	
9149/33150 (epoch 13.799), train_loss = 0.94932672, grad/param norm = 1.3416e-01, time/batch = 14.7930s	
9150/33150 (epoch 13.801), train_loss = 1.13532440, grad/param norm = 1.4085e-01, time/batch = 15.0909s	
9151/33150 (epoch 13.802), train_loss = 1.02295982, grad/param norm = 1.6008e-01, time/batch = 15.3235s	
9152/33150 (epoch 13.804), train_loss = 1.07691571, grad/param norm = 1.5046e-01, time/batch = 15.4867s	
9153/33150 (epoch 13.805), train_loss = 1.09397558, grad/param norm = 1.5388e-01, time/batch = 15.4281s	
9154/33150 (epoch 13.807), train_loss = 1.06035106, grad/param norm = 1.3721e-01, time/batch = 17.8700s	
9155/33150 (epoch 13.808), train_loss = 1.19738457, grad/param norm = 1.5439e-01, time/batch = 16.4739s	
9156/33150 (epoch 13.810), train_loss = 1.08254134, grad/param norm = 1.3949e-01, time/batch = 17.5447s	
9157/33150 (epoch 13.811), train_loss = 1.15018757, grad/param norm = 1.5866e-01, time/batch = 18.6175s	
9158/33150 (epoch 13.813), train_loss = 1.08636817, grad/param norm = 1.2885e-01, time/batch = 17.3788s	
9159/33150 (epoch 13.814), train_loss = 1.12419292, grad/param norm = 1.6823e-01, time/batch = 16.8781s	
9160/33150 (epoch 13.816), train_loss = 1.08351352, grad/param norm = 1.6010e-01, time/batch = 17.3800s	
9161/33150 (epoch 13.817), train_loss = 1.18176553, grad/param norm = 1.4612e-01, time/batch = 18.1257s	
9162/33150 (epoch 13.819), train_loss = 1.09017869, grad/param norm = 1.4334e-01, time/batch = 16.2959s	
9163/33150 (epoch 13.821), train_loss = 0.96894956, grad/param norm = 1.2483e-01, time/batch = 16.4518s	
9164/33150 (epoch 13.822), train_loss = 1.02902934, grad/param norm = 1.4654e-01, time/batch = 16.0395s	
9165/33150 (epoch 13.824), train_loss = 1.07704372, grad/param norm = 1.4825e-01, time/batch = 16.9754s	
9166/33150 (epoch 13.825), train_loss = 1.11112869, grad/param norm = 1.4867e-01, time/batch = 16.1405s	
9167/33150 (epoch 13.827), train_loss = 1.17327459, grad/param norm = 1.6380e-01, time/batch = 17.5509s	
9168/33150 (epoch 13.828), train_loss = 0.98723455, grad/param norm = 1.5628e-01, time/batch = 16.2993s	
9169/33150 (epoch 13.830), train_loss = 1.19485180, grad/param norm = 1.5301e-01, time/batch = 16.0334s	
9170/33150 (epoch 13.831), train_loss = 1.05724565, grad/param norm = 1.6254e-01, time/batch = 15.7880s	
9171/33150 (epoch 13.833), train_loss = 0.99483061, grad/param norm = 1.4548e-01, time/batch = 16.5559s	
9172/33150 (epoch 13.834), train_loss = 1.24712325, grad/param norm = 1.6613e-01, time/batch = 17.3884s	
9173/33150 (epoch 13.836), train_loss = 1.21480049, grad/param norm = 1.5106e-01, time/batch = 15.3812s	
9174/33150 (epoch 13.837), train_loss = 1.12436893, grad/param norm = 1.6516e-01, time/batch = 18.1288s	
9175/33150 (epoch 13.839), train_loss = 1.20830392, grad/param norm = 1.7114e-01, time/batch = 17.9543s	
9176/33150 (epoch 13.840), train_loss = 1.18228330, grad/param norm = 1.5028e-01, time/batch = 16.7708s	
9177/33150 (epoch 13.842), train_loss = 1.27827600, grad/param norm = 1.7151e-01, time/batch = 19.4683s	
9178/33150 (epoch 13.843), train_loss = 1.26010104, grad/param norm = 1.6843e-01, time/batch = 17.8817s	
9179/33150 (epoch 13.845), train_loss = 1.07216936, grad/param norm = 1.4903e-01, time/batch = 18.3838s	
9180/33150 (epoch 13.846), train_loss = 1.33432070, grad/param norm = 2.0413e-01, time/batch = 16.7034s	
9181/33150 (epoch 13.848), train_loss = 1.21002712, grad/param norm = 1.5448e-01, time/batch = 17.5417s	
9182/33150 (epoch 13.849), train_loss = 1.20414129, grad/param norm = 1.6686e-01, time/batch = 17.5518s	
9183/33150 (epoch 13.851), train_loss = 1.22318751, grad/param norm = 1.6351e-01, time/batch = 16.2010s	
9184/33150 (epoch 13.852), train_loss = 1.28808191, grad/param norm = 1.5073e-01, time/batch = 17.2954s	
9185/33150 (epoch 13.854), train_loss = 1.13736059, grad/param norm = 1.5939e-01, time/batch = 16.1505s	
9186/33150 (epoch 13.855), train_loss = 0.97922558, grad/param norm = 1.4002e-01, time/batch = 17.7528s	
9187/33150 (epoch 13.857), train_loss = 0.96097280, grad/param norm = 1.3153e-01, time/batch = 16.8826s	
9188/33150 (epoch 13.858), train_loss = 1.07211191, grad/param norm = 1.5175e-01, time/batch = 17.7955s	
9189/33150 (epoch 13.860), train_loss = 1.00760168, grad/param norm = 1.3523e-01, time/batch = 16.5532s	
9190/33150 (epoch 13.861), train_loss = 1.03376150, grad/param norm = 1.4681e-01, time/batch = 15.7090s	
9191/33150 (epoch 13.863), train_loss = 1.15807065, grad/param norm = 1.4569e-01, time/batch = 18.8846s	
9192/33150 (epoch 13.864), train_loss = 1.22361883, grad/param norm = 1.5288e-01, time/batch = 18.7726s	
9193/33150 (epoch 13.866), train_loss = 1.17691498, grad/param norm = 1.5947e-01, time/batch = 18.1182s	
9194/33150 (epoch 13.867), train_loss = 1.14785783, grad/param norm = 1.2714e-01, time/batch = 16.7217s	
9195/33150 (epoch 13.869), train_loss = 1.18376799, grad/param norm = 1.5077e-01, time/batch = 18.1342s	
9196/33150 (epoch 13.870), train_loss = 1.17108473, grad/param norm = 1.6820e-01, time/batch = 17.6233s	
9197/33150 (epoch 13.872), train_loss = 1.11206802, grad/param norm = 1.6351e-01, time/batch = 31.5733s	
9198/33150 (epoch 13.873), train_loss = 0.94086266, grad/param norm = 1.3430e-01, time/batch = 16.5614s	
9199/33150 (epoch 13.875), train_loss = 1.26136833, grad/param norm = 1.6122e-01, time/batch = 17.9593s	
9200/33150 (epoch 13.876), train_loss = 1.01878278, grad/param norm = 1.6986e-01, time/batch = 17.5466s	
9201/33150 (epoch 13.878), train_loss = 0.99802931, grad/param norm = 1.2799e-01, time/batch = 19.3928s	
9202/33150 (epoch 13.879), train_loss = 1.03870413, grad/param norm = 1.4739e-01, time/batch = 18.5533s	
9203/33150 (epoch 13.881), train_loss = 1.06402178, grad/param norm = 1.4716e-01, time/batch = 16.3123s	
9204/33150 (epoch 13.882), train_loss = 0.94239674, grad/param norm = 1.3462e-01, time/batch = 18.3007s	
9205/33150 (epoch 13.884), train_loss = 1.09932631, grad/param norm = 1.4570e-01, time/batch = 19.0579s	
9206/33150 (epoch 13.885), train_loss = 0.87985592, grad/param norm = 1.3561e-01, time/batch = 16.7283s	
9207/33150 (epoch 13.887), train_loss = 1.28523091, grad/param norm = 1.7066e-01, time/batch = 15.9669s	
9208/33150 (epoch 13.888), train_loss = 1.17114141, grad/param norm = 1.6253e-01, time/batch = 19.8044s	
9209/33150 (epoch 13.890), train_loss = 1.05463804, grad/param norm = 1.4377e-01, time/batch = 16.2850s	
9210/33150 (epoch 13.891), train_loss = 1.02254818, grad/param norm = 1.4678e-01, time/batch = 17.4811s	
9211/33150 (epoch 13.893), train_loss = 1.17941701, grad/param norm = 1.7554e-01, time/batch = 19.3040s	
9212/33150 (epoch 13.894), train_loss = 1.19266415, grad/param norm = 1.6572e-01, time/batch = 18.3922s	
9213/33150 (epoch 13.896), train_loss = 1.08347765, grad/param norm = 1.3983e-01, time/batch = 15.3910s	
9214/33150 (epoch 13.897), train_loss = 1.14325488, grad/param norm = 1.4122e-01, time/batch = 16.1709s	
9215/33150 (epoch 13.899), train_loss = 0.99190578, grad/param norm = 1.5048e-01, time/batch = 15.5397s	
9216/33150 (epoch 13.900), train_loss = 1.39124320, grad/param norm = 1.6300e-01, time/batch = 15.0815s	
9217/33150 (epoch 13.902), train_loss = 1.28970198, grad/param norm = 1.6213e-01, time/batch = 14.9486s	
9218/33150 (epoch 13.903), train_loss = 1.12360227, grad/param norm = 1.4646e-01, time/batch = 15.2962s	
9219/33150 (epoch 13.905), train_loss = 1.15534703, grad/param norm = 1.4868e-01, time/batch = 15.7882s	
9220/33150 (epoch 13.906), train_loss = 1.21669407, grad/param norm = 1.6864e-01, time/batch = 15.3653s	
9221/33150 (epoch 13.908), train_loss = 1.27224925, grad/param norm = 1.6353e-01, time/batch = 14.6449s	
9222/33150 (epoch 13.910), train_loss = 1.21869107, grad/param norm = 1.4683e-01, time/batch = 15.1213s	
9223/33150 (epoch 13.911), train_loss = 0.96615088, grad/param norm = 1.2500e-01, time/batch = 15.3007s	
9224/33150 (epoch 13.913), train_loss = 1.05159606, grad/param norm = 1.4260e-01, time/batch = 17.2870s	
9225/33150 (epoch 13.914), train_loss = 1.21155848, grad/param norm = 1.6516e-01, time/batch = 16.8354s	
9226/33150 (epoch 13.916), train_loss = 1.03548512, grad/param norm = 1.5171e-01, time/batch = 19.3533s	
9227/33150 (epoch 13.917), train_loss = 1.23544278, grad/param norm = 1.7794e-01, time/batch = 16.9442s	
9228/33150 (epoch 13.919), train_loss = 1.27853187, grad/param norm = 1.8258e-01, time/batch = 16.3651s	
9229/33150 (epoch 13.920), train_loss = 1.20837219, grad/param norm = 1.5582e-01, time/batch = 18.8531s	
9230/33150 (epoch 13.922), train_loss = 1.29907042, grad/param norm = 1.8074e-01, time/batch = 18.8548s	
9231/33150 (epoch 13.923), train_loss = 1.14311512, grad/param norm = 1.6475e-01, time/batch = 17.3597s	
9232/33150 (epoch 13.925), train_loss = 1.17528059, grad/param norm = 1.4248e-01, time/batch = 18.8909s	
9233/33150 (epoch 13.926), train_loss = 1.10222401, grad/param norm = 1.3879e-01, time/batch = 17.3768s	
9234/33150 (epoch 13.928), train_loss = 1.09193675, grad/param norm = 1.6139e-01, time/batch = 18.4563s	
9235/33150 (epoch 13.929), train_loss = 1.18808596, grad/param norm = 1.4187e-01, time/batch = 15.5927s	
9236/33150 (epoch 13.931), train_loss = 1.28501581, grad/param norm = 1.7391e-01, time/batch = 15.4709s	
9237/33150 (epoch 13.932), train_loss = 1.15296036, grad/param norm = 1.6403e-01, time/batch = 20.2104s	
9238/33150 (epoch 13.934), train_loss = 1.16460468, grad/param norm = 1.4790e-01, time/batch = 17.0339s	
9239/33150 (epoch 13.935), train_loss = 1.24302816, grad/param norm = 1.5206e-01, time/batch = 16.5405s	
9240/33150 (epoch 13.937), train_loss = 1.25869897, grad/param norm = 1.4244e-01, time/batch = 16.7899s	
9241/33150 (epoch 13.938), train_loss = 1.20387167, grad/param norm = 1.4344e-01, time/batch = 16.3112s	
9242/33150 (epoch 13.940), train_loss = 1.42492643, grad/param norm = 1.6783e-01, time/batch = 17.7216s	
9243/33150 (epoch 13.941), train_loss = 1.12443524, grad/param norm = 1.3565e-01, time/batch = 16.9651s	
9244/33150 (epoch 13.943), train_loss = 1.03943464, grad/param norm = 1.6415e-01, time/batch = 19.2214s	
9245/33150 (epoch 13.944), train_loss = 1.23818351, grad/param norm = 1.7338e-01, time/batch = 16.6955s	
9246/33150 (epoch 13.946), train_loss = 0.93553893, grad/param norm = 1.2522e-01, time/batch = 17.3947s	
9247/33150 (epoch 13.947), train_loss = 1.17025175, grad/param norm = 1.4248e-01, time/batch = 17.3191s	
9248/33150 (epoch 13.949), train_loss = 1.28007326, grad/param norm = 1.4818e-01, time/batch = 16.8079s	
9249/33150 (epoch 13.950), train_loss = 1.17262269, grad/param norm = 1.5894e-01, time/batch = 16.7295s	
9250/33150 (epoch 13.952), train_loss = 1.04420930, grad/param norm = 1.4930e-01, time/batch = 15.2190s	
9251/33150 (epoch 13.953), train_loss = 1.10515851, grad/param norm = 1.4408e-01, time/batch = 17.8055s	
9252/33150 (epoch 13.955), train_loss = 1.00876564, grad/param norm = 1.4369e-01, time/batch = 17.1878s	
9253/33150 (epoch 13.956), train_loss = 1.19015864, grad/param norm = 1.4687e-01, time/batch = 17.5643s	
9254/33150 (epoch 13.958), train_loss = 0.99598902, grad/param norm = 1.3387e-01, time/batch = 16.2206s	
9255/33150 (epoch 13.959), train_loss = 1.05333693, grad/param norm = 1.5141e-01, time/batch = 17.3060s	
9256/33150 (epoch 13.961), train_loss = 1.01305045, grad/param norm = 1.4579e-01, time/batch = 18.2122s	
9257/33150 (epoch 13.962), train_loss = 0.96730301, grad/param norm = 1.3425e-01, time/batch = 19.5450s	
9258/33150 (epoch 13.964), train_loss = 1.13919128, grad/param norm = 1.4704e-01, time/batch = 17.7124s	
9259/33150 (epoch 13.965), train_loss = 1.12699653, grad/param norm = 1.4192e-01, time/batch = 18.7932s	
9260/33150 (epoch 13.967), train_loss = 1.12221719, grad/param norm = 1.6543e-01, time/batch = 18.8805s	
9261/33150 (epoch 13.968), train_loss = 0.94752200, grad/param norm = 1.2916e-01, time/batch = 19.3689s	
9262/33150 (epoch 13.970), train_loss = 1.07315331, grad/param norm = 1.3853e-01, time/batch = 16.3131s	
9263/33150 (epoch 13.971), train_loss = 1.12942671, grad/param norm = 1.5646e-01, time/batch = 18.8929s	
9264/33150 (epoch 13.973), train_loss = 1.30790329, grad/param norm = 1.5905e-01, time/batch = 16.0609s	
9265/33150 (epoch 13.974), train_loss = 1.27949433, grad/param norm = 1.6215e-01, time/batch = 15.4302s	
9266/33150 (epoch 13.976), train_loss = 1.18610424, grad/param norm = 1.3884e-01, time/batch = 16.9794s	
9267/33150 (epoch 13.977), train_loss = 1.28721098, grad/param norm = 1.6147e-01, time/batch = 17.8245s	
9268/33150 (epoch 13.979), train_loss = 1.25688960, grad/param norm = 1.7626e-01, time/batch = 19.4519s	
9269/33150 (epoch 13.980), train_loss = 1.27718381, grad/param norm = 1.5004e-01, time/batch = 17.1481s	
9270/33150 (epoch 13.982), train_loss = 1.12947739, grad/param norm = 1.8537e-01, time/batch = 17.8098s	
9271/33150 (epoch 13.983), train_loss = 0.99038977, grad/param norm = 1.4516e-01, time/batch = 17.7938s	
9272/33150 (epoch 13.985), train_loss = 1.17313890, grad/param norm = 1.4131e-01, time/batch = 16.1989s	
9273/33150 (epoch 13.986), train_loss = 0.97062837, grad/param norm = 1.4046e-01, time/batch = 20.2906s	
9274/33150 (epoch 13.988), train_loss = 1.07380447, grad/param norm = 1.5869e-01, time/batch = 19.3951s	
9275/33150 (epoch 13.989), train_loss = 1.02123866, grad/param norm = 1.5387e-01, time/batch = 16.4790s	
9276/33150 (epoch 13.991), train_loss = 1.21507995, grad/param norm = 1.8551e-01, time/batch = 17.6269s	
9277/33150 (epoch 13.992), train_loss = 1.00468361, grad/param norm = 1.3551e-01, time/batch = 19.0567s	
9278/33150 (epoch 13.994), train_loss = 1.11851441, grad/param norm = 1.5355e-01, time/batch = 16.7224s	
9279/33150 (epoch 13.995), train_loss = 1.06416421, grad/param norm = 1.5710e-01, time/batch = 16.8227s	
9280/33150 (epoch 13.997), train_loss = 1.16784543, grad/param norm = 1.7924e-01, time/batch = 20.1921s	
9281/33150 (epoch 13.998), train_loss = 0.91066801, grad/param norm = 1.3172e-01, time/batch = 18.4749s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
9282/33150 (epoch 14.000), train_loss = 0.95949032, grad/param norm = 1.6597e-01, time/batch = 17.0261s	
9283/33150 (epoch 14.002), train_loss = 1.44501067, grad/param norm = 1.8198e-01, time/batch = 16.6353s	
9284/33150 (epoch 14.003), train_loss = 1.04522645, grad/param norm = 1.4457e-01, time/batch = 18.9736s	
9285/33150 (epoch 14.005), train_loss = 1.00604190, grad/param norm = 1.4762e-01, time/batch = 17.8100s	
9286/33150 (epoch 14.006), train_loss = 0.97027331, grad/param norm = 1.4673e-01, time/batch = 17.4759s	
9287/33150 (epoch 14.008), train_loss = 1.22706678, grad/param norm = 1.5190e-01, time/batch = 16.6429s	
9288/33150 (epoch 14.009), train_loss = 1.10155960, grad/param norm = 1.4198e-01, time/batch = 18.7173s	
9289/33150 (epoch 14.011), train_loss = 1.24056722, grad/param norm = 1.5676e-01, time/batch = 16.7285s	
9290/33150 (epoch 14.012), train_loss = 1.12104238, grad/param norm = 1.6937e-01, time/batch = 18.5711s	
9291/33150 (epoch 14.014), train_loss = 1.10973128, grad/param norm = 1.8445e-01, time/batch = 18.8074s	
9292/33150 (epoch 14.015), train_loss = 1.07621478, grad/param norm = 1.5311e-01, time/batch = 17.0613s	
9293/33150 (epoch 14.017), train_loss = 1.03861111, grad/param norm = 1.4419e-01, time/batch = 18.6453s	
9294/33150 (epoch 14.018), train_loss = 1.15510532, grad/param norm = 1.6455e-01, time/batch = 17.3910s	
9295/33150 (epoch 14.020), train_loss = 1.19463997, grad/param norm = 1.6100e-01, time/batch = 17.3052s	
9296/33150 (epoch 14.021), train_loss = 0.98626457, grad/param norm = 1.5480e-01, time/batch = 17.4876s	
9297/33150 (epoch 14.023), train_loss = 1.29670812, grad/param norm = 1.5211e-01, time/batch = 18.4742s	
9298/33150 (epoch 14.024), train_loss = 1.16658793, grad/param norm = 1.4956e-01, time/batch = 19.0286s	
9299/33150 (epoch 14.026), train_loss = 0.89382269, grad/param norm = 1.2228e-01, time/batch = 17.1323s	
9300/33150 (epoch 14.027), train_loss = 0.91500523, grad/param norm = 1.3039e-01, time/batch = 16.7989s	
9301/33150 (epoch 14.029), train_loss = 1.03045950, grad/param norm = 1.5585e-01, time/batch = 16.0443s	
9302/33150 (epoch 14.030), train_loss = 1.10061642, grad/param norm = 1.3032e-01, time/batch = 15.6386s	
9303/33150 (epoch 14.032), train_loss = 1.06420047, grad/param norm = 1.7050e-01, time/batch = 15.6205s	
9304/33150 (epoch 14.033), train_loss = 1.06785093, grad/param norm = 1.4271e-01, time/batch = 15.5649s	
9305/33150 (epoch 14.035), train_loss = 1.28097191, grad/param norm = 1.6547e-01, time/batch = 15.3934s	
9306/33150 (epoch 14.036), train_loss = 1.16040255, grad/param norm = 1.5399e-01, time/batch = 15.3132s	
9307/33150 (epoch 14.038), train_loss = 1.40647520, grad/param norm = 1.7607e-01, time/batch = 16.3889s	
9308/33150 (epoch 14.039), train_loss = 1.14023037, grad/param norm = 1.3392e-01, time/batch = 18.3855s	
9309/33150 (epoch 14.041), train_loss = 1.16404112, grad/param norm = 1.4839e-01, time/batch = 17.9531s	
9310/33150 (epoch 14.042), train_loss = 1.08004728, grad/param norm = 1.4176e-01, time/batch = 16.1611s	
9311/33150 (epoch 14.044), train_loss = 1.06840346, grad/param norm = 1.3577e-01, time/batch = 17.7154s	
9312/33150 (epoch 14.045), train_loss = 1.11852285, grad/param norm = 1.4349e-01, time/batch = 18.0430s	
9313/33150 (epoch 14.047), train_loss = 1.02872886, grad/param norm = 1.4441e-01, time/batch = 16.6336s	
9314/33150 (epoch 14.048), train_loss = 1.23244552, grad/param norm = 1.6487e-01, time/batch = 17.0487s	
9315/33150 (epoch 14.050), train_loss = 1.11781609, grad/param norm = 1.4263e-01, time/batch = 17.3056s	
9316/33150 (epoch 14.051), train_loss = 1.11886787, grad/param norm = 1.5133e-01, time/batch = 18.0328s	
9317/33150 (epoch 14.053), train_loss = 1.08145225, grad/param norm = 1.4696e-01, time/batch = 18.0520s	
9318/33150 (epoch 14.054), train_loss = 1.20429213, grad/param norm = 1.3488e-01, time/batch = 18.6395s	
9319/33150 (epoch 14.056), train_loss = 1.07445153, grad/param norm = 1.4398e-01, time/batch = 17.6336s	
9320/33150 (epoch 14.057), train_loss = 1.10559016, grad/param norm = 1.6126e-01, time/batch = 17.3854s	
9321/33150 (epoch 14.059), train_loss = 1.02923791, grad/param norm = 1.5254e-01, time/batch = 18.0288s	
9322/33150 (epoch 14.060), train_loss = 1.05286370, grad/param norm = 1.4029e-01, time/batch = 16.3899s	
9323/33150 (epoch 14.062), train_loss = 1.08432760, grad/param norm = 1.4171e-01, time/batch = 17.5584s	
9324/33150 (epoch 14.063), train_loss = 1.06250356, grad/param norm = 1.5510e-01, time/batch = 17.3596s	
9325/33150 (epoch 14.065), train_loss = 1.09411054, grad/param norm = 1.2832e-01, time/batch = 16.6575s	
9326/33150 (epoch 14.066), train_loss = 1.03016057, grad/param norm = 1.3693e-01, time/batch = 17.3955s	
9327/33150 (epoch 14.068), train_loss = 1.12485330, grad/param norm = 1.4390e-01, time/batch = 16.4726s	
9328/33150 (epoch 14.069), train_loss = 1.19514329, grad/param norm = 1.6588e-01, time/batch = 17.5553s	
9329/33150 (epoch 14.071), train_loss = 1.16257138, grad/param norm = 1.4874e-01, time/batch = 16.7981s	
9330/33150 (epoch 14.072), train_loss = 1.06062097, grad/param norm = 1.3760e-01, time/batch = 17.1313s	
9331/33150 (epoch 14.074), train_loss = 0.97107853, grad/param norm = 1.5536e-01, time/batch = 19.2920s	
9332/33150 (epoch 14.075), train_loss = 1.05620202, grad/param norm = 1.4909e-01, time/batch = 19.0527s	
9333/33150 (epoch 14.077), train_loss = 1.13281841, grad/param norm = 1.6273e-01, time/batch = 17.2931s	
9334/33150 (epoch 14.078), train_loss = 1.29242665, grad/param norm = 1.7001e-01, time/batch = 16.9671s	
9335/33150 (epoch 14.080), train_loss = 1.22772955, grad/param norm = 1.3770e-01, time/batch = 17.0667s	
9336/33150 (epoch 14.081), train_loss = 1.03650166, grad/param norm = 1.6053e-01, time/batch = 18.4627s	
9337/33150 (epoch 14.083), train_loss = 0.82941491, grad/param norm = 1.5751e-01, time/batch = 17.0325s	
9338/33150 (epoch 14.084), train_loss = 0.98404407, grad/param norm = 1.5483e-01, time/batch = 16.8651s	
9339/33150 (epoch 14.086), train_loss = 1.04610681, grad/param norm = 1.5632e-01, time/batch = 17.7252s	
9340/33150 (epoch 14.087), train_loss = 0.96813976, grad/param norm = 1.4733e-01, time/batch = 17.8540s	
9341/33150 (epoch 14.089), train_loss = 1.01849411, grad/param norm = 1.5200e-01, time/batch = 19.6305s	
9342/33150 (epoch 14.090), train_loss = 1.04145276, grad/param norm = 1.5080e-01, time/batch = 19.2039s	
9343/33150 (epoch 14.092), train_loss = 1.06547119, grad/param norm = 1.5289e-01, time/batch = 18.0494s	
9344/33150 (epoch 14.094), train_loss = 1.18941852, grad/param norm = 1.6960e-01, time/batch = 17.8944s	
9345/33150 (epoch 14.095), train_loss = 0.94682886, grad/param norm = 1.2743e-01, time/batch = 17.8790s	
9346/33150 (epoch 14.097), train_loss = 1.06381679, grad/param norm = 1.4619e-01, time/batch = 17.1560s	
9347/33150 (epoch 14.098), train_loss = 1.34760842, grad/param norm = 1.6544e-01, time/batch = 17.2926s	
9348/33150 (epoch 14.100), train_loss = 1.31096728, grad/param norm = 1.5647e-01, time/batch = 18.2135s	
9349/33150 (epoch 14.101), train_loss = 1.02937050, grad/param norm = 1.5944e-01, time/batch = 18.5491s	
9350/33150 (epoch 14.103), train_loss = 1.13320884, grad/param norm = 1.5384e-01, time/batch = 16.3912s	
9351/33150 (epoch 14.104), train_loss = 1.03325381, grad/param norm = 1.5371e-01, time/batch = 16.7882s	
9352/33150 (epoch 14.106), train_loss = 1.26828818, grad/param norm = 1.6822e-01, time/batch = 18.0587s	
9353/33150 (epoch 14.107), train_loss = 1.37663589, grad/param norm = 1.8262e-01, time/batch = 18.2893s	
9354/33150 (epoch 14.109), train_loss = 1.06841643, grad/param norm = 1.2741e-01, time/batch = 18.3752s	
9355/33150 (epoch 14.110), train_loss = 1.19040462, grad/param norm = 1.4680e-01, time/batch = 18.1282s	
9356/33150 (epoch 14.112), train_loss = 1.02368890, grad/param norm = 1.4307e-01, time/batch = 18.3573s	
9357/33150 (epoch 14.113), train_loss = 1.09336565, grad/param norm = 1.5199e-01, time/batch = 15.8153s	
9358/33150 (epoch 14.115), train_loss = 1.29553504, grad/param norm = 1.7005e-01, time/batch = 19.2109s	
9359/33150 (epoch 14.116), train_loss = 1.05181136, grad/param norm = 1.4136e-01, time/batch = 19.5521s	
9360/33150 (epoch 14.118), train_loss = 1.18831588, grad/param norm = 1.6355e-01, time/batch = 16.5504s	
9361/33150 (epoch 14.119), train_loss = 1.18816990, grad/param norm = 1.8521e-01, time/batch = 15.7818s	
9362/33150 (epoch 14.121), train_loss = 1.07053904, grad/param norm = 1.4975e-01, time/batch = 18.3096s	
9363/33150 (epoch 14.122), train_loss = 1.35352609, grad/param norm = 2.1733e-01, time/batch = 18.6319s	
9364/33150 (epoch 14.124), train_loss = 0.89672662, grad/param norm = 1.2275e-01, time/batch = 17.8760s	
9365/33150 (epoch 14.125), train_loss = 1.21077144, grad/param norm = 1.5235e-01, time/batch = 18.9669s	
9366/33150 (epoch 14.127), train_loss = 1.05124481, grad/param norm = 1.3573e-01, time/batch = 16.5456s	
9367/33150 (epoch 14.128), train_loss = 1.14095716, grad/param norm = 1.5710e-01, time/batch = 16.2938s	
9368/33150 (epoch 14.130), train_loss = 1.14605297, grad/param norm = 1.4617e-01, time/batch = 18.6312s	
9369/33150 (epoch 14.131), train_loss = 1.33995388, grad/param norm = 1.7400e-01, time/batch = 16.6559s	
9370/33150 (epoch 14.133), train_loss = 1.04626483, grad/param norm = 1.3907e-01, time/batch = 17.3775s	
9371/33150 (epoch 14.134), train_loss = 1.23476911, grad/param norm = 1.5771e-01, time/batch = 17.0450s	
9372/33150 (epoch 14.136), train_loss = 1.14976151, grad/param norm = 1.6483e-01, time/batch = 16.6451s	
9373/33150 (epoch 14.137), train_loss = 1.20262370, grad/param norm = 1.4721e-01, time/batch = 18.3007s	
9374/33150 (epoch 14.139), train_loss = 1.19622721, grad/param norm = 1.6394e-01, time/batch = 16.4493s	
9375/33150 (epoch 14.140), train_loss = 1.27324491, grad/param norm = 1.6197e-01, time/batch = 18.3771s	
9376/33150 (epoch 14.142), train_loss = 1.20566112, grad/param norm = 1.5913e-01, time/batch = 17.1343s	
9377/33150 (epoch 14.143), train_loss = 1.14537427, grad/param norm = 1.5549e-01, time/batch = 16.7248s	
9378/33150 (epoch 14.145), train_loss = 1.09267458, grad/param norm = 1.7514e-01, time/batch = 16.8085s	
9379/33150 (epoch 14.146), train_loss = 1.26088782, grad/param norm = 1.6919e-01, time/batch = 18.5551s	
9380/33150 (epoch 14.148), train_loss = 1.22723271, grad/param norm = 1.5146e-01, time/batch = 17.7049s	
9381/33150 (epoch 14.149), train_loss = 1.15320407, grad/param norm = 1.6531e-01, time/batch = 17.2952s	
9382/33150 (epoch 14.151), train_loss = 1.32242531, grad/param norm = 1.6235e-01, time/batch = 17.7956s	
9383/33150 (epoch 14.152), train_loss = 1.09022588, grad/param norm = 1.5072e-01, time/batch = 17.2094s	
9384/33150 (epoch 14.154), train_loss = 1.10715544, grad/param norm = 1.5038e-01, time/batch = 15.9644s	
9385/33150 (epoch 14.155), train_loss = 0.99868234, grad/param norm = 1.3407e-01, time/batch = 16.8920s	
9386/33150 (epoch 14.157), train_loss = 1.05770327, grad/param norm = 1.5012e-01, time/batch = 18.1483s	
9387/33150 (epoch 14.158), train_loss = 1.02672134, grad/param norm = 1.4626e-01, time/batch = 17.6330s	
9388/33150 (epoch 14.160), train_loss = 1.20511046, grad/param norm = 1.5325e-01, time/batch = 17.9591s	
9389/33150 (epoch 14.161), train_loss = 1.05803393, grad/param norm = 1.7799e-01, time/batch = 18.8083s	
9390/33150 (epoch 14.163), train_loss = 1.06397089, grad/param norm = 1.4819e-01, time/batch = 19.3579s	
9391/33150 (epoch 14.164), train_loss = 1.19005159, grad/param norm = 1.5957e-01, time/batch = 16.4507s	
9392/33150 (epoch 14.166), train_loss = 1.08166341, grad/param norm = 1.5772e-01, time/batch = 20.2032s	
9393/33150 (epoch 14.167), train_loss = 1.12902764, grad/param norm = 1.4304e-01, time/batch = 17.3106s	
9394/33150 (epoch 14.169), train_loss = 1.18887322, grad/param norm = 1.8849e-01, time/batch = 16.7199s	
9395/33150 (epoch 14.170), train_loss = 1.03164625, grad/param norm = 1.5560e-01, time/batch = 18.5499s	
9396/33150 (epoch 14.172), train_loss = 1.21205621, grad/param norm = 1.6821e-01, time/batch = 17.6492s	
9397/33150 (epoch 14.173), train_loss = 1.19383678, grad/param norm = 1.7864e-01, time/batch = 17.9776s	
9398/33150 (epoch 14.175), train_loss = 1.03707729, grad/param norm = 1.5406e-01, time/batch = 18.1426s	
9399/33150 (epoch 14.176), train_loss = 1.17024951, grad/param norm = 1.6657e-01, time/batch = 17.0528s	
9400/33150 (epoch 14.178), train_loss = 1.30227762, grad/param norm = 1.5830e-01, time/batch = 18.7972s	
9401/33150 (epoch 14.179), train_loss = 1.16679808, grad/param norm = 1.4548e-01, time/batch = 30.1871s	
9402/33150 (epoch 14.181), train_loss = 1.13697794, grad/param norm = 1.5992e-01, time/batch = 19.7121s	
9403/33150 (epoch 14.183), train_loss = 1.11214275, grad/param norm = 1.6458e-01, time/batch = 17.1482s	
9404/33150 (epoch 14.184), train_loss = 1.32070138, grad/param norm = 1.5275e-01, time/batch = 18.4089s	
9405/33150 (epoch 14.186), train_loss = 1.22258405, grad/param norm = 1.4833e-01, time/batch = 17.0282s	
9406/33150 (epoch 14.187), train_loss = 1.14330466, grad/param norm = 1.5970e-01, time/batch = 18.6262s	
9407/33150 (epoch 14.189), train_loss = 0.93442050, grad/param norm = 1.5144e-01, time/batch = 16.0475s	
9408/33150 (epoch 14.190), train_loss = 1.01122932, grad/param norm = 1.5065e-01, time/batch = 19.1462s	
9409/33150 (epoch 14.192), train_loss = 1.12654303, grad/param norm = 1.6220e-01, time/batch = 19.8839s	
9410/33150 (epoch 14.193), train_loss = 1.18163742, grad/param norm = 1.4590e-01, time/batch = 16.4860s	
9411/33150 (epoch 14.195), train_loss = 1.40885109, grad/param norm = 1.7298e-01, time/batch = 17.9595s	
9412/33150 (epoch 14.196), train_loss = 1.27142729, grad/param norm = 1.6202e-01, time/batch = 20.0409s	
9413/33150 (epoch 14.198), train_loss = 0.96327505, grad/param norm = 1.4189e-01, time/batch = 16.9792s	
9414/33150 (epoch 14.199), train_loss = 1.22219070, grad/param norm = 1.7530e-01, time/batch = 16.8037s	
9415/33150 (epoch 14.201), train_loss = 1.01785014, grad/param norm = 1.3515e-01, time/batch = 19.6390s	
9416/33150 (epoch 14.202), train_loss = 0.92883874, grad/param norm = 1.3148e-01, time/batch = 18.6251s	
9417/33150 (epoch 14.204), train_loss = 1.13321558, grad/param norm = 1.5394e-01, time/batch = 16.5635s	
9418/33150 (epoch 14.205), train_loss = 1.20074773, grad/param norm = 1.5238e-01, time/batch = 18.6544s	
9419/33150 (epoch 14.207), train_loss = 1.17251830, grad/param norm = 1.5138e-01, time/batch = 15.8935s	
9420/33150 (epoch 14.208), train_loss = 1.18521247, grad/param norm = 1.6603e-01, time/batch = 17.8938s	
9421/33150 (epoch 14.210), train_loss = 1.01939142, grad/param norm = 1.3124e-01, time/batch = 19.6302s	
9422/33150 (epoch 14.211), train_loss = 1.19395631, grad/param norm = 1.7028e-01, time/batch = 16.0451s	
9423/33150 (epoch 14.213), train_loss = 1.19684599, grad/param norm = 1.5248e-01, time/batch = 17.8408s	
9424/33150 (epoch 14.214), train_loss = 1.09550850, grad/param norm = 1.5859e-01, time/batch = 15.9661s	
9425/33150 (epoch 14.216), train_loss = 1.06903907, grad/param norm = 1.6069e-01, time/batch = 17.2332s	
9426/33150 (epoch 14.217), train_loss = 1.06345676, grad/param norm = 1.3718e-01, time/batch = 17.6461s	
9427/33150 (epoch 14.219), train_loss = 1.00117964, grad/param norm = 1.4435e-01, time/batch = 15.5477s	
9428/33150 (epoch 14.220), train_loss = 1.04749917, grad/param norm = 1.3348e-01, time/batch = 16.9856s	
9429/33150 (epoch 14.222), train_loss = 1.21613558, grad/param norm = 1.4853e-01, time/batch = 19.5474s	
9430/33150 (epoch 14.223), train_loss = 1.10161873, grad/param norm = 1.4959e-01, time/batch = 14.9837s	
9431/33150 (epoch 14.225), train_loss = 1.29218093, grad/param norm = 1.5882e-01, time/batch = 16.6505s	
9432/33150 (epoch 14.226), train_loss = 1.08413857, grad/param norm = 1.4076e-01, time/batch = 18.7935s	
9433/33150 (epoch 14.228), train_loss = 1.10029703, grad/param norm = 1.4667e-01, time/batch = 17.6558s	
9434/33150 (epoch 14.229), train_loss = 1.09472136, grad/param norm = 1.5408e-01, time/batch = 16.3015s	
9435/33150 (epoch 14.231), train_loss = 1.24537626, grad/param norm = 1.6787e-01, time/batch = 17.1185s	
9436/33150 (epoch 14.232), train_loss = 1.17509660, grad/param norm = 1.8889e-01, time/batch = 16.3215s	
9437/33150 (epoch 14.234), train_loss = 1.12866432, grad/param norm = 1.6849e-01, time/batch = 16.2938s	
9438/33150 (epoch 14.235), train_loss = 1.16574072, grad/param norm = 1.7512e-01, time/batch = 17.5375s	
9439/33150 (epoch 14.237), train_loss = 1.09381500, grad/param norm = 1.6275e-01, time/batch = 18.8779s	
9440/33150 (epoch 14.238), train_loss = 1.20813221, grad/param norm = 1.7818e-01, time/batch = 18.7266s	
9441/33150 (epoch 14.240), train_loss = 1.14754102, grad/param norm = 1.5087e-01, time/batch = 16.6308s	
9442/33150 (epoch 14.241), train_loss = 1.28388394, grad/param norm = 1.7300e-01, time/batch = 20.0579s	
9443/33150 (epoch 14.243), train_loss = 1.22096075, grad/param norm = 1.6567e-01, time/batch = 18.4757s	
9444/33150 (epoch 14.244), train_loss = 1.11764840, grad/param norm = 1.4558e-01, time/batch = 16.7041s	
9445/33150 (epoch 14.246), train_loss = 1.17762374, grad/param norm = 1.5024e-01, time/batch = 19.5552s	
9446/33150 (epoch 14.247), train_loss = 1.03733975, grad/param norm = 1.4663e-01, time/batch = 17.1291s	
9447/33150 (epoch 14.249), train_loss = 1.22182559, grad/param norm = 1.5097e-01, time/batch = 17.7955s	
9448/33150 (epoch 14.250), train_loss = 1.17346126, grad/param norm = 1.2924e-01, time/batch = 16.9653s	
9449/33150 (epoch 14.252), train_loss = 1.18155940, grad/param norm = 1.2897e-01, time/batch = 20.0537s	
9450/33150 (epoch 14.253), train_loss = 1.18565502, grad/param norm = 1.5961e-01, time/batch = 18.7103s	
9451/33150 (epoch 14.255), train_loss = 1.11909340, grad/param norm = 1.3297e-01, time/batch = 19.2934s	
9452/33150 (epoch 14.256), train_loss = 1.16726510, grad/param norm = 1.3990e-01, time/batch = 16.2891s	
9453/33150 (epoch 14.258), train_loss = 1.08726978, grad/param norm = 1.7868e-01, time/batch = 15.6461s	
9454/33150 (epoch 14.259), train_loss = 0.96354466, grad/param norm = 1.4534e-01, time/batch = 15.5462s	
9455/33150 (epoch 14.261), train_loss = 0.97756559, grad/param norm = 1.3632e-01, time/batch = 15.3700s	
9456/33150 (epoch 14.262), train_loss = 1.18252580, grad/param norm = 1.6576e-01, time/batch = 15.9019s	
9457/33150 (epoch 14.264), train_loss = 0.89330484, grad/param norm = 1.3371e-01, time/batch = 15.4004s	
9458/33150 (epoch 14.265), train_loss = 1.17950139, grad/param norm = 1.5055e-01, time/batch = 17.2966s	
9459/33150 (epoch 14.267), train_loss = 1.22423153, grad/param norm = 1.6966e-01, time/batch = 15.8210s	
9460/33150 (epoch 14.268), train_loss = 1.19060595, grad/param norm = 1.4663e-01, time/batch = 17.8675s	
9461/33150 (epoch 14.270), train_loss = 1.32310284, grad/param norm = 1.6883e-01, time/batch = 18.2180s	
9462/33150 (epoch 14.271), train_loss = 1.27059704, grad/param norm = 1.5867e-01, time/batch = 18.5512s	
9463/33150 (epoch 14.273), train_loss = 1.26624241, grad/param norm = 1.5356e-01, time/batch = 15.8202s	
9464/33150 (epoch 14.275), train_loss = 1.28425998, grad/param norm = 1.6766e-01, time/batch = 16.3973s	
9465/33150 (epoch 14.276), train_loss = 1.11818191, grad/param norm = 1.4763e-01, time/batch = 16.4592s	
9466/33150 (epoch 14.278), train_loss = 1.19031106, grad/param norm = 1.4820e-01, time/batch = 18.1244s	
9467/33150 (epoch 14.279), train_loss = 1.15323840, grad/param norm = 1.4254e-01, time/batch = 16.8170s	
9468/33150 (epoch 14.281), train_loss = 1.17765016, grad/param norm = 1.4850e-01, time/batch = 16.6086s	
9469/33150 (epoch 14.282), train_loss = 1.12506008, grad/param norm = 1.3977e-01, time/batch = 15.9513s	
9470/33150 (epoch 14.284), train_loss = 1.06895608, grad/param norm = 1.3348e-01, time/batch = 18.2123s	
9471/33150 (epoch 14.285), train_loss = 1.16587542, grad/param norm = 1.4629e-01, time/batch = 17.9737s	
9472/33150 (epoch 14.287), train_loss = 1.07571620, grad/param norm = 1.4069e-01, time/batch = 16.3803s	
9473/33150 (epoch 14.288), train_loss = 1.29310124, grad/param norm = 1.5862e-01, time/batch = 16.6426s	
9474/33150 (epoch 14.290), train_loss = 0.97928249, grad/param norm = 1.4883e-01, time/batch = 18.3149s	
9475/33150 (epoch 14.291), train_loss = 0.97106698, grad/param norm = 1.3547e-01, time/batch = 17.3828s	
9476/33150 (epoch 14.293), train_loss = 1.20254423, grad/param norm = 1.4639e-01, time/batch = 17.3811s	
9477/33150 (epoch 14.294), train_loss = 0.85047482, grad/param norm = 1.3378e-01, time/batch = 19.2897s	
9478/33150 (epoch 14.296), train_loss = 1.10460590, grad/param norm = 1.5745e-01, time/batch = 17.7131s	
9479/33150 (epoch 14.297), train_loss = 1.05290943, grad/param norm = 1.4618e-01, time/batch = 15.8929s	
9480/33150 (epoch 14.299), train_loss = 1.07781724, grad/param norm = 1.5648e-01, time/batch = 16.3866s	
9481/33150 (epoch 14.300), train_loss = 1.05635208, grad/param norm = 1.2555e-01, time/batch = 16.1586s	
9482/33150 (epoch 14.302), train_loss = 1.07192238, grad/param norm = 1.4453e-01, time/batch = 16.7132s	
9483/33150 (epoch 14.303), train_loss = 1.10563725, grad/param norm = 1.5048e-01, time/batch = 17.8095s	
9484/33150 (epoch 14.305), train_loss = 1.19126325, grad/param norm = 1.4178e-01, time/batch = 16.9769s	
9485/33150 (epoch 14.306), train_loss = 1.18444167, grad/param norm = 1.6580e-01, time/batch = 18.4763s	
9486/33150 (epoch 14.308), train_loss = 1.36953521, grad/param norm = 1.5611e-01, time/batch = 16.4556s	
9487/33150 (epoch 14.309), train_loss = 0.97174163, grad/param norm = 1.3703e-01, time/batch = 15.7289s	
9488/33150 (epoch 14.311), train_loss = 1.09712848, grad/param norm = 1.5135e-01, time/batch = 16.3782s	
9489/33150 (epoch 14.312), train_loss = 0.89747626, grad/param norm = 1.5025e-01, time/batch = 16.7197s	
9490/33150 (epoch 14.314), train_loss = 1.10029586, grad/param norm = 1.4516e-01, time/batch = 17.1473s	
9491/33150 (epoch 14.315), train_loss = 1.16730609, grad/param norm = 1.5623e-01, time/batch = 16.3184s	
9492/33150 (epoch 14.317), train_loss = 0.88519244, grad/param norm = 1.2168e-01, time/batch = 19.1332s	
9493/33150 (epoch 14.318), train_loss = 1.00175746, grad/param norm = 1.3250e-01, time/batch = 15.4594s	
9494/33150 (epoch 14.320), train_loss = 0.96028247, grad/param norm = 1.3029e-01, time/batch = 17.8776s	
9495/33150 (epoch 14.321), train_loss = 1.05141462, grad/param norm = 1.3488e-01, time/batch = 18.0294s	
9496/33150 (epoch 14.323), train_loss = 1.11899551, grad/param norm = 1.4499e-01, time/batch = 17.5664s	
9497/33150 (epoch 14.324), train_loss = 1.21661426, grad/param norm = 1.9051e-01, time/batch = 18.5666s	
9498/33150 (epoch 14.326), train_loss = 1.12269520, grad/param norm = 1.3420e-01, time/batch = 18.0534s	
9499/33150 (epoch 14.327), train_loss = 1.24603895, grad/param norm = 1.4648e-01, time/batch = 18.0558s	
9500/33150 (epoch 14.329), train_loss = 1.17488793, grad/param norm = 1.5263e-01, time/batch = 17.9542s	
9501/33150 (epoch 14.330), train_loss = 1.12753409, grad/param norm = 1.5780e-01, time/batch = 18.6412s	
9502/33150 (epoch 14.332), train_loss = 1.11288163, grad/param norm = 1.3526e-01, time/batch = 17.7830s	
9503/33150 (epoch 14.333), train_loss = 1.15261841, grad/param norm = 1.3757e-01, time/batch = 16.7130s	
9504/33150 (epoch 14.335), train_loss = 1.06040979, grad/param norm = 1.4036e-01, time/batch = 16.7877s	
9505/33150 (epoch 14.336), train_loss = 1.02904505, grad/param norm = 1.4243e-01, time/batch = 16.1626s	
9506/33150 (epoch 14.338), train_loss = 0.93107462, grad/param norm = 1.4509e-01, time/batch = 17.5559s	
9507/33150 (epoch 14.339), train_loss = 1.23555363, grad/param norm = 1.5958e-01, time/batch = 17.5634s	
9508/33150 (epoch 14.341), train_loss = 1.24335764, grad/param norm = 1.7745e-01, time/batch = 18.5588s	
9509/33150 (epoch 14.342), train_loss = 0.98860856, grad/param norm = 1.4555e-01, time/batch = 17.6257s	
9510/33150 (epoch 14.344), train_loss = 1.14507195, grad/param norm = 1.5641e-01, time/batch = 16.6406s	
9511/33150 (epoch 14.345), train_loss = 1.06152309, grad/param norm = 1.4230e-01, time/batch = 17.4663s	
9512/33150 (epoch 14.347), train_loss = 0.89149085, grad/param norm = 1.2400e-01, time/batch = 20.3648s	
9513/33150 (epoch 14.348), train_loss = 1.13516896, grad/param norm = 1.4594e-01, time/batch = 16.1340s	
9514/33150 (epoch 14.350), train_loss = 1.06060052, grad/param norm = 1.7959e-01, time/batch = 19.1412s	
9515/33150 (epoch 14.351), train_loss = 1.19012688, grad/param norm = 1.5467e-01, time/batch = 18.7209s	
9516/33150 (epoch 14.353), train_loss = 1.19947855, grad/param norm = 1.5902e-01, time/batch = 18.1301s	
9517/33150 (epoch 14.354), train_loss = 1.38566309, grad/param norm = 1.5970e-01, time/batch = 15.8101s	
9518/33150 (epoch 14.356), train_loss = 1.23207859, grad/param norm = 1.6703e-01, time/batch = 19.3823s	
9519/33150 (epoch 14.357), train_loss = 1.21760783, grad/param norm = 1.5921e-01, time/batch = 19.4706s	
9520/33150 (epoch 14.359), train_loss = 1.16263019, grad/param norm = 1.5070e-01, time/batch = 17.8658s	
9521/33150 (epoch 14.360), train_loss = 1.19397724, grad/param norm = 1.6521e-01, time/batch = 19.2303s	
9522/33150 (epoch 14.362), train_loss = 1.21981812, grad/param norm = 1.5170e-01, time/batch = 18.3785s	
9523/33150 (epoch 14.363), train_loss = 1.12737346, grad/param norm = 1.3951e-01, time/batch = 17.9610s	
9524/33150 (epoch 14.365), train_loss = 1.10704152, grad/param norm = 1.3438e-01, time/batch = 18.0721s	
9525/33150 (epoch 14.367), train_loss = 1.01980659, grad/param norm = 1.3415e-01, time/batch = 17.1452s	
9526/33150 (epoch 14.368), train_loss = 1.11716626, grad/param norm = 1.6244e-01, time/batch = 17.1980s	
9527/33150 (epoch 14.370), train_loss = 1.15638786, grad/param norm = 1.6604e-01, time/batch = 20.3632s	
9528/33150 (epoch 14.371), train_loss = 0.99868270, grad/param norm = 1.3893e-01, time/batch = 16.9545s	
9529/33150 (epoch 14.373), train_loss = 1.17576675, grad/param norm = 1.7457e-01, time/batch = 18.0447s	
9530/33150 (epoch 14.374), train_loss = 1.10008008, grad/param norm = 1.4340e-01, time/batch = 15.9012s	
9531/33150 (epoch 14.376), train_loss = 1.24490467, grad/param norm = 1.5457e-01, time/batch = 19.3945s	
9532/33150 (epoch 14.377), train_loss = 1.06038329, grad/param norm = 1.4790e-01, time/batch = 17.0663s	
9533/33150 (epoch 14.379), train_loss = 1.21429911, grad/param norm = 1.5669e-01, time/batch = 17.6439s	
9534/33150 (epoch 14.380), train_loss = 1.20244026, grad/param norm = 1.3893e-01, time/batch = 17.0618s	
9535/33150 (epoch 14.382), train_loss = 1.03769959, grad/param norm = 1.5048e-01, time/batch = 16.7170s	
9536/33150 (epoch 14.383), train_loss = 1.03559228, grad/param norm = 1.4025e-01, time/batch = 17.6274s	
9537/33150 (epoch 14.385), train_loss = 1.12360795, grad/param norm = 1.4482e-01, time/batch = 19.2157s	
9538/33150 (epoch 14.386), train_loss = 0.97248408, grad/param norm = 1.2536e-01, time/batch = 18.8044s	
9539/33150 (epoch 14.388), train_loss = 1.09301414, grad/param norm = 1.4232e-01, time/batch = 17.7192s	
9540/33150 (epoch 14.389), train_loss = 1.05682388, grad/param norm = 1.3502e-01, time/batch = 17.6398s	
9541/33150 (epoch 14.391), train_loss = 1.29362835, grad/param norm = 1.5778e-01, time/batch = 17.7883s	
9542/33150 (epoch 14.392), train_loss = 1.07477808, grad/param norm = 1.4195e-01, time/batch = 18.8822s	
9543/33150 (epoch 14.394), train_loss = 0.98533754, grad/param norm = 1.1902e-01, time/batch = 16.6293s	
9544/33150 (epoch 14.395), train_loss = 0.99335231, grad/param norm = 1.4457e-01, time/batch = 18.6362s	
9545/33150 (epoch 14.397), train_loss = 0.83360883, grad/param norm = 1.3678e-01, time/batch = 17.2930s	
9546/33150 (epoch 14.398), train_loss = 1.12739762, grad/param norm = 1.6679e-01, time/batch = 17.8859s	
9547/33150 (epoch 14.400), train_loss = 1.03322824, grad/param norm = 1.2610e-01, time/batch = 17.8994s	
9548/33150 (epoch 14.401), train_loss = 0.94068599, grad/param norm = 1.3303e-01, time/batch = 16.6480s	
9549/33150 (epoch 14.403), train_loss = 1.00699004, grad/param norm = 1.2937e-01, time/batch = 16.8958s	
9550/33150 (epoch 14.404), train_loss = 1.11967185, grad/param norm = 1.4536e-01, time/batch = 16.0492s	
9551/33150 (epoch 14.406), train_loss = 1.00893841, grad/param norm = 1.1934e-01, time/batch = 17.4103s	
9552/33150 (epoch 14.407), train_loss = 0.97744747, grad/param norm = 1.3683e-01, time/batch = 18.6463s	
9553/33150 (epoch 14.409), train_loss = 0.90356640, grad/param norm = 1.3179e-01, time/batch = 16.6334s	
9554/33150 (epoch 14.410), train_loss = 1.13871625, grad/param norm = 1.5326e-01, time/batch = 16.8926s	
9555/33150 (epoch 14.412), train_loss = 1.14090653, grad/param norm = 1.4633e-01, time/batch = 16.8997s	
9556/33150 (epoch 14.413), train_loss = 1.05032901, grad/param norm = 1.4552e-01, time/batch = 18.5485s	
9557/33150 (epoch 14.415), train_loss = 1.20301242, grad/param norm = 1.4122e-01, time/batch = 17.8043s	
9558/33150 (epoch 14.416), train_loss = 1.03701452, grad/param norm = 1.3304e-01, time/batch = 19.3985s	
9559/33150 (epoch 14.418), train_loss = 1.28020786, grad/param norm = 1.9422e-01, time/batch = 19.4502s	
9560/33150 (epoch 14.419), train_loss = 1.04443174, grad/param norm = 1.4286e-01, time/batch = 16.8737s	
9561/33150 (epoch 14.421), train_loss = 1.13028968, grad/param norm = 1.5013e-01, time/batch = 17.9830s	
9562/33150 (epoch 14.422), train_loss = 1.05658901, grad/param norm = 1.4840e-01, time/batch = 17.1153s	
9563/33150 (epoch 14.424), train_loss = 1.05067733, grad/param norm = 1.4371e-01, time/batch = 17.3796s	
9564/33150 (epoch 14.425), train_loss = 1.11036459, grad/param norm = 1.4328e-01, time/batch = 18.4652s	
9565/33150 (epoch 14.427), train_loss = 1.09485593, grad/param norm = 1.3421e-01, time/batch = 17.9964s	
9566/33150 (epoch 14.428), train_loss = 1.12349800, grad/param norm = 1.5460e-01, time/batch = 17.5621s	
9567/33150 (epoch 14.430), train_loss = 1.13300740, grad/param norm = 1.5362e-01, time/batch = 17.4778s	
9568/33150 (epoch 14.431), train_loss = 1.19942109, grad/param norm = 1.7245e-01, time/batch = 17.4653s	
9569/33150 (epoch 14.433), train_loss = 1.08008179, grad/param norm = 1.5669e-01, time/batch = 17.7233s	
9570/33150 (epoch 14.434), train_loss = 0.99391632, grad/param norm = 1.4639e-01, time/batch = 15.2878s	
9571/33150 (epoch 14.436), train_loss = 1.01672278, grad/param norm = 1.5757e-01, time/batch = 18.4655s	
9572/33150 (epoch 14.437), train_loss = 1.11064426, grad/param norm = 1.7144e-01, time/batch = 17.7362s	
9573/33150 (epoch 14.439), train_loss = 1.21227875, grad/param norm = 1.5773e-01, time/batch = 18.1289s	
9574/33150 (epoch 14.440), train_loss = 1.21310518, grad/param norm = 1.6037e-01, time/batch = 18.9601s	
9575/33150 (epoch 14.442), train_loss = 0.98466559, grad/param norm = 1.5450e-01, time/batch = 17.1435s	
9576/33150 (epoch 14.443), train_loss = 1.21439216, grad/param norm = 1.5266e-01, time/batch = 18.5741s	
9577/33150 (epoch 14.445), train_loss = 1.11571672, grad/param norm = 1.6209e-01, time/batch = 16.2119s	
9578/33150 (epoch 14.446), train_loss = 1.12000117, grad/param norm = 2.0389e-01, time/batch = 18.4835s	
9579/33150 (epoch 14.448), train_loss = 1.19602029, grad/param norm = 1.5643e-01, time/batch = 18.2073s	
9580/33150 (epoch 14.449), train_loss = 1.11376498, grad/param norm = 1.4061e-01, time/batch = 16.1295s	
9581/33150 (epoch 14.451), train_loss = 1.19819361, grad/param norm = 1.6876e-01, time/batch = 17.3803s	
9582/33150 (epoch 14.452), train_loss = 1.37221504, grad/param norm = 1.6250e-01, time/batch = 18.0507s	
9583/33150 (epoch 14.454), train_loss = 1.08816149, grad/param norm = 1.4739e-01, time/batch = 17.1375s	
9584/33150 (epoch 14.456), train_loss = 0.94950398, grad/param norm = 1.3590e-01, time/batch = 16.8057s	
9585/33150 (epoch 14.457), train_loss = 1.13075704, grad/param norm = 1.6096e-01, time/batch = 17.9771s	
9586/33150 (epoch 14.459), train_loss = 1.27726167, grad/param norm = 2.0202e-01, time/batch = 19.2259s	
9587/33150 (epoch 14.460), train_loss = 1.14529221, grad/param norm = 1.3162e-01, time/batch = 16.2969s	
9588/33150 (epoch 14.462), train_loss = 1.22453606, grad/param norm = 2.0266e-01, time/batch = 18.5451s	
9589/33150 (epoch 14.463), train_loss = 1.40870881, grad/param norm = 1.9572e-01, time/batch = 17.0546s	
9590/33150 (epoch 14.465), train_loss = 1.06393540, grad/param norm = 1.4466e-01, time/batch = 15.8792s	
9591/33150 (epoch 14.466), train_loss = 1.04051829, grad/param norm = 1.4295e-01, time/batch = 17.8064s	
9592/33150 (epoch 14.468), train_loss = 1.40875461, grad/param norm = 1.6517e-01, time/batch = 18.3146s	
9593/33150 (epoch 14.469), train_loss = 1.11773436, grad/param norm = 1.5728e-01, time/batch = 16.4907s	
9594/33150 (epoch 14.471), train_loss = 1.06987687, grad/param norm = 1.4986e-01, time/batch = 16.8048s	
9595/33150 (epoch 14.472), train_loss = 1.09841578, grad/param norm = 1.4489e-01, time/batch = 17.9089s	
9596/33150 (epoch 14.474), train_loss = 1.23291569, grad/param norm = 1.7276e-01, time/batch = 17.9774s	
9597/33150 (epoch 14.475), train_loss = 1.38614426, grad/param norm = 1.6433e-01, time/batch = 16.0569s	
9598/33150 (epoch 14.477), train_loss = 1.21658597, grad/param norm = 1.6405e-01, time/batch = 18.0651s	
9599/33150 (epoch 14.478), train_loss = 1.23247437, grad/param norm = 1.4688e-01, time/batch = 16.8912s	
9600/33150 (epoch 14.480), train_loss = 1.06453318, grad/param norm = 1.4939e-01, time/batch = 18.7266s	
9601/33150 (epoch 14.481), train_loss = 0.94335938, grad/param norm = 1.3738e-01, time/batch = 17.1214s	
9602/33150 (epoch 14.483), train_loss = 1.07552523, grad/param norm = 1.4209e-01, time/batch = 18.7063s	
9603/33150 (epoch 14.484), train_loss = 1.07133599, grad/param norm = 1.4862e-01, time/batch = 17.0602s	
9604/33150 (epoch 14.486), train_loss = 1.07685797, grad/param norm = 1.5909e-01, time/batch = 27.8590s	
9605/33150 (epoch 14.487), train_loss = 1.18112709, grad/param norm = 1.6320e-01, time/batch = 19.8385s	
9606/33150 (epoch 14.489), train_loss = 1.14131394, grad/param norm = 1.6480e-01, time/batch = 15.4946s	
9607/33150 (epoch 14.490), train_loss = 0.95466699, grad/param norm = 1.3866e-01, time/batch = 15.5587s	
9608/33150 (epoch 14.492), train_loss = 1.06022936, grad/param norm = 1.6091e-01, time/batch = 15.3861s	
9609/33150 (epoch 14.493), train_loss = 1.22487792, grad/param norm = 1.6734e-01, time/batch = 15.3894s	
9610/33150 (epoch 14.495), train_loss = 1.24883606, grad/param norm = 1.5937e-01, time/batch = 15.3461s	
9611/33150 (epoch 14.496), train_loss = 1.03571926, grad/param norm = 1.4712e-01, time/batch = 15.5495s	
9612/33150 (epoch 14.498), train_loss = 1.24814322, grad/param norm = 1.9590e-01, time/batch = 17.9782s	
9613/33150 (epoch 14.499), train_loss = 1.27836912, grad/param norm = 1.6098e-01, time/batch = 16.7189s	
9614/33150 (epoch 14.501), train_loss = 1.16683117, grad/param norm = 1.6258e-01, time/batch = 16.5607s	
9615/33150 (epoch 14.502), train_loss = 1.28187463, grad/param norm = 1.7001e-01, time/batch = 17.3877s	
9616/33150 (epoch 14.504), train_loss = 1.18456717, grad/param norm = 1.6155e-01, time/batch = 16.9819s	
9617/33150 (epoch 14.505), train_loss = 1.35140825, grad/param norm = 1.8298e-01, time/batch = 16.8928s	
9618/33150 (epoch 14.507), train_loss = 1.05566430, grad/param norm = 1.4328e-01, time/batch = 16.1301s	
9619/33150 (epoch 14.508), train_loss = 1.09708547, grad/param norm = 1.6009e-01, time/batch = 18.7944s	
9620/33150 (epoch 14.510), train_loss = 1.15655084, grad/param norm = 1.6222e-01, time/batch = 19.8694s	
9621/33150 (epoch 14.511), train_loss = 1.30562185, grad/param norm = 1.6947e-01, time/batch = 17.3666s	
9622/33150 (epoch 14.513), train_loss = 1.15739000, grad/param norm = 1.6699e-01, time/batch = 18.2294s	
9623/33150 (epoch 14.514), train_loss = 0.94565467, grad/param norm = 1.4283e-01, time/batch = 17.2075s	
9624/33150 (epoch 14.516), train_loss = 1.24725170, grad/param norm = 1.7425e-01, time/batch = 17.8761s	
9625/33150 (epoch 14.517), train_loss = 1.23363022, grad/param norm = 1.4750e-01, time/batch = 19.0373s	
9626/33150 (epoch 14.519), train_loss = 1.05251286, grad/param norm = 1.4047e-01, time/batch = 18.3937s	
9627/33150 (epoch 14.520), train_loss = 1.14678139, grad/param norm = 1.4611e-01, time/batch = 17.3801s	
9628/33150 (epoch 14.522), train_loss = 1.28272671, grad/param norm = 1.8586e-01, time/batch = 16.5508s	
9629/33150 (epoch 14.523), train_loss = 1.03433213, grad/param norm = 1.4900e-01, time/batch = 15.7232s	
9630/33150 (epoch 14.525), train_loss = 1.17563108, grad/param norm = 1.5314e-01, time/batch = 17.9772s	
9631/33150 (epoch 14.526), train_loss = 1.04701568, grad/param norm = 1.5676e-01, time/batch = 16.4616s	
9632/33150 (epoch 14.528), train_loss = 1.19152836, grad/param norm = 1.5788e-01, time/batch = 15.7205s	
9633/33150 (epoch 14.529), train_loss = 1.14999693, grad/param norm = 1.4524e-01, time/batch = 17.3058s	
9634/33150 (epoch 14.531), train_loss = 0.96521386, grad/param norm = 1.5249e-01, time/batch = 17.3695s	
9635/33150 (epoch 14.532), train_loss = 1.14536381, grad/param norm = 1.4659e-01, time/batch = 15.3154s	
9636/33150 (epoch 14.534), train_loss = 1.07926111, grad/param norm = 1.3403e-01, time/batch = 17.4897s	
9637/33150 (epoch 14.535), train_loss = 1.04606369, grad/param norm = 1.6023e-01, time/batch = 18.0634s	
9638/33150 (epoch 14.537), train_loss = 1.22934414, grad/param norm = 1.5945e-01, time/batch = 17.1222s	
9639/33150 (epoch 14.538), train_loss = 1.07588627, grad/param norm = 1.4912e-01, time/batch = 16.5527s	
9640/33150 (epoch 14.540), train_loss = 0.97742542, grad/param norm = 1.4691e-01, time/batch = 16.4608s	
9641/33150 (epoch 14.541), train_loss = 1.21841570, grad/param norm = 1.5771e-01, time/batch = 17.8787s	
9642/33150 (epoch 14.543), train_loss = 1.16937877, grad/param norm = 1.4935e-01, time/batch = 17.3100s	
9643/33150 (epoch 14.544), train_loss = 1.15463866, grad/param norm = 1.4391e-01, time/batch = 19.4653s	
9644/33150 (epoch 14.546), train_loss = 1.24272701, grad/param norm = 1.5954e-01, time/batch = 18.8847s	
9645/33150 (epoch 14.548), train_loss = 1.16934168, grad/param norm = 1.5802e-01, time/batch = 16.7148s	
9646/33150 (epoch 14.549), train_loss = 1.07562482, grad/param norm = 1.4680e-01, time/batch = 17.4764s	
9647/33150 (epoch 14.551), train_loss = 1.03077881, grad/param norm = 1.3766e-01, time/batch = 19.7059s	
9648/33150 (epoch 14.552), train_loss = 0.91107811, grad/param norm = 1.2073e-01, time/batch = 16.9824s	
9649/33150 (epoch 14.554), train_loss = 1.18258481, grad/param norm = 1.4676e-01, time/batch = 15.9561s	
9650/33150 (epoch 14.555), train_loss = 1.29148333, grad/param norm = 1.6086e-01, time/batch = 17.5563s	
9651/33150 (epoch 14.557), train_loss = 0.94774578, grad/param norm = 1.4123e-01, time/batch = 18.5678s	
9652/33150 (epoch 14.558), train_loss = 1.20315110, grad/param norm = 1.7600e-01, time/batch = 15.8144s	
9653/33150 (epoch 14.560), train_loss = 1.06428785, grad/param norm = 1.4507e-01, time/batch = 17.4797s	
9654/33150 (epoch 14.561), train_loss = 0.95534118, grad/param norm = 1.4301e-01, time/batch = 19.0726s	
9655/33150 (epoch 14.563), train_loss = 1.21632607, grad/param norm = 1.9433e-01, time/batch = 17.2250s	
9656/33150 (epoch 14.564), train_loss = 1.31578780, grad/param norm = 1.6133e-01, time/batch = 18.2242s	
9657/33150 (epoch 14.566), train_loss = 1.12737043, grad/param norm = 1.5255e-01, time/batch = 17.5558s	
9658/33150 (epoch 14.567), train_loss = 1.01291998, grad/param norm = 1.3567e-01, time/batch = 18.7149s	
9659/33150 (epoch 14.569), train_loss = 1.14897447, grad/param norm = 1.4926e-01, time/batch = 17.2061s	
9660/33150 (epoch 14.570), train_loss = 1.19487891, grad/param norm = 1.7705e-01, time/batch = 20.0362s	
9661/33150 (epoch 14.572), train_loss = 1.04952211, grad/param norm = 1.4573e-01, time/batch = 17.6284s	
9662/33150 (epoch 14.573), train_loss = 0.90754851, grad/param norm = 1.2355e-01, time/batch = 16.3816s	
9663/33150 (epoch 14.575), train_loss = 1.08163823, grad/param norm = 1.4842e-01, time/batch = 17.8060s	
9664/33150 (epoch 14.576), train_loss = 0.95295377, grad/param norm = 1.2552e-01, time/batch = 17.5587s	
9665/33150 (epoch 14.578), train_loss = 1.04166432, grad/param norm = 1.3391e-01, time/batch = 17.2092s	
9666/33150 (epoch 14.579), train_loss = 0.95664561, grad/param norm = 1.4810e-01, time/batch = 17.2817s	
9667/33150 (epoch 14.581), train_loss = 1.02376690, grad/param norm = 1.4678e-01, time/batch = 19.0387s	
9668/33150 (epoch 14.582), train_loss = 1.20334457, grad/param norm = 1.5031e-01, time/batch = 16.9010s	
9669/33150 (epoch 14.584), train_loss = 1.20495785, grad/param norm = 1.5455e-01, time/batch = 16.6201s	
9670/33150 (epoch 14.585), train_loss = 1.12843388, grad/param norm = 1.5205e-01, time/batch = 19.4360s	
9671/33150 (epoch 14.587), train_loss = 1.15959297, grad/param norm = 1.5152e-01, time/batch = 18.3901s	
9672/33150 (epoch 14.588), train_loss = 1.02838968, grad/param norm = 1.5669e-01, time/batch = 16.2176s	
9673/33150 (epoch 14.590), train_loss = 1.11909995, grad/param norm = 1.5197e-01, time/batch = 18.6234s	
9674/33150 (epoch 14.591), train_loss = 1.10211084, grad/param norm = 1.3780e-01, time/batch = 18.3913s	
9675/33150 (epoch 14.593), train_loss = 1.18026404, grad/param norm = 1.5305e-01, time/batch = 17.0517s	
9676/33150 (epoch 14.594), train_loss = 1.12628697, grad/param norm = 1.5223e-01, time/batch = 17.5767s	
9677/33150 (epoch 14.596), train_loss = 1.05163863, grad/param norm = 1.4677e-01, time/batch = 17.1218s	
9678/33150 (epoch 14.597), train_loss = 0.99263520, grad/param norm = 1.6483e-01, time/batch = 16.6204s	
9679/33150 (epoch 14.599), train_loss = 1.29967556, grad/param norm = 1.6872e-01, time/batch = 18.3672s	
9680/33150 (epoch 14.600), train_loss = 1.13055574, grad/param norm = 2.0034e-01, time/batch = 19.4683s	
9681/33150 (epoch 14.602), train_loss = 1.06626330, grad/param norm = 1.5342e-01, time/batch = 18.0488s	
9682/33150 (epoch 14.603), train_loss = 1.17900571, grad/param norm = 1.6085e-01, time/batch = 17.4598s	
9683/33150 (epoch 14.605), train_loss = 1.00116899, grad/param norm = 1.4822e-01, time/batch = 17.5251s	
9684/33150 (epoch 14.606), train_loss = 1.15001805, grad/param norm = 1.8195e-01, time/batch = 18.9752s	
9685/33150 (epoch 14.608), train_loss = 1.18050793, grad/param norm = 1.5946e-01, time/batch = 16.9508s	
9686/33150 (epoch 14.609), train_loss = 1.10319162, grad/param norm = 1.6151e-01, time/batch = 17.8082s	
9687/33150 (epoch 14.611), train_loss = 0.98178330, grad/param norm = 1.6768e-01, time/batch = 19.2174s	
9688/33150 (epoch 14.612), train_loss = 1.13459343, grad/param norm = 1.6495e-01, time/batch = 18.2229s	
9689/33150 (epoch 14.614), train_loss = 0.95976988, grad/param norm = 1.4919e-01, time/batch = 18.8387s	
9690/33150 (epoch 14.615), train_loss = 1.01202440, grad/param norm = 1.3696e-01, time/batch = 17.3000s	
9691/33150 (epoch 14.617), train_loss = 1.12140184, grad/param norm = 1.6314e-01, time/batch = 19.3473s	
9692/33150 (epoch 14.618), train_loss = 1.12487600, grad/param norm = 1.4907e-01, time/batch = 18.9427s	
9693/33150 (epoch 14.620), train_loss = 1.04494859, grad/param norm = 1.6086e-01, time/batch = 21.4878s	
9694/33150 (epoch 14.621), train_loss = 1.08848757, grad/param norm = 1.4295e-01, time/batch = 18.6129s	
9695/33150 (epoch 14.623), train_loss = 1.16393716, grad/param norm = 1.4610e-01, time/batch = 19.5994s	
9696/33150 (epoch 14.624), train_loss = 1.04780231, grad/param norm = 1.5273e-01, time/batch = 21.8402s	
9697/33150 (epoch 14.626), train_loss = 1.04087505, grad/param norm = 1.3887e-01, time/batch = 22.6715s	
9698/33150 (epoch 14.627), train_loss = 0.99591915, grad/param norm = 1.5822e-01, time/batch = 25.8085s	
9699/33150 (epoch 14.629), train_loss = 0.96741575, grad/param norm = 1.3914e-01, time/batch = 37.9572s	
9700/33150 (epoch 14.630), train_loss = 1.03054527, grad/param norm = 1.3449e-01, time/batch = 43.4456s	
9701/33150 (epoch 14.632), train_loss = 0.95118533, grad/param norm = 1.5865e-01, time/batch = 51.1310s	
9702/33150 (epoch 14.633), train_loss = 0.95445458, grad/param norm = 1.5869e-01, time/batch = 37.7645s	
9703/33150 (epoch 14.635), train_loss = 1.31855141, grad/param norm = 1.7156e-01, time/batch = 36.2785s	
9704/33150 (epoch 14.637), train_loss = 0.92285218, grad/param norm = 1.4789e-01, time/batch = 37.5604s	
9705/33150 (epoch 14.638), train_loss = 1.06630075, grad/param norm = 1.4696e-01, time/batch = 36.9943s	
9706/33150 (epoch 14.640), train_loss = 1.21326659, grad/param norm = 1.7628e-01, time/batch = 36.7445s	
9707/33150 (epoch 14.641), train_loss = 0.99623885, grad/param norm = 1.5135e-01, time/batch = 19.5290s	
9708/33150 (epoch 14.643), train_loss = 1.03281903, grad/param norm = 1.4450e-01, time/batch = 17.8068s	
9709/33150 (epoch 14.644), train_loss = 1.25979138, grad/param norm = 1.5847e-01, time/batch = 18.9797s	
9710/33150 (epoch 14.646), train_loss = 1.04844668, grad/param norm = 1.4491e-01, time/batch = 19.3776s	
9711/33150 (epoch 14.647), train_loss = 1.35243410, grad/param norm = 1.6750e-01, time/batch = 15.9715s	
9712/33150 (epoch 14.649), train_loss = 1.20415996, grad/param norm = 1.6682e-01, time/batch = 17.2117s	
9713/33150 (epoch 14.650), train_loss = 0.97078695, grad/param norm = 1.3022e-01, time/batch = 18.8018s	
9714/33150 (epoch 14.652), train_loss = 1.22842218, grad/param norm = 1.6793e-01, time/batch = 16.4748s	
9715/33150 (epoch 14.653), train_loss = 1.10748177, grad/param norm = 1.4072e-01, time/batch = 17.0522s	
9716/33150 (epoch 14.655), train_loss = 1.16516235, grad/param norm = 1.6811e-01, time/batch = 17.6428s	
9717/33150 (epoch 14.656), train_loss = 1.08799893, grad/param norm = 1.4524e-01, time/batch = 17.8625s	
9718/33150 (epoch 14.658), train_loss = 1.11872912, grad/param norm = 1.9724e-01, time/batch = 17.3913s	
9719/33150 (epoch 14.659), train_loss = 1.38960550, grad/param norm = 2.0222e-01, time/batch = 18.7240s	
9720/33150 (epoch 14.661), train_loss = 1.10218618, grad/param norm = 1.6107e-01, time/batch = 18.6938s	
9721/33150 (epoch 14.662), train_loss = 0.93835994, grad/param norm = 1.4048e-01, time/batch = 15.8735s	
9722/33150 (epoch 14.664), train_loss = 1.22923114, grad/param norm = 1.5793e-01, time/batch = 17.2196s	
9723/33150 (epoch 14.665), train_loss = 1.18926709, grad/param norm = 1.6685e-01, time/batch = 17.6210s	
9724/33150 (epoch 14.667), train_loss = 1.26391556, grad/param norm = 1.6761e-01, time/batch = 17.1222s	
9725/33150 (epoch 14.668), train_loss = 1.18953775, grad/param norm = 1.5271e-01, time/batch = 19.2862s	
9726/33150 (epoch 14.670), train_loss = 1.04150266, grad/param norm = 1.3491e-01, time/batch = 18.3864s	
9727/33150 (epoch 14.671), train_loss = 1.04400878, grad/param norm = 1.5022e-01, time/batch = 17.8756s	
9728/33150 (epoch 14.673), train_loss = 1.21739535, grad/param norm = 1.2973e-01, time/batch = 15.4664s	
9729/33150 (epoch 14.674), train_loss = 1.11112622, grad/param norm = 1.4740e-01, time/batch = 18.5483s	
9730/33150 (epoch 14.676), train_loss = 1.06015206, grad/param norm = 1.4092e-01, time/batch = 17.6233s	
9731/33150 (epoch 14.677), train_loss = 1.36136745, grad/param norm = 1.6243e-01, time/batch = 16.4053s	
9732/33150 (epoch 14.679), train_loss = 1.09416412, grad/param norm = 1.6354e-01, time/batch = 17.7218s	
9733/33150 (epoch 14.680), train_loss = 1.25033610, grad/param norm = 1.5049e-01, time/batch = 18.7225s	
9734/33150 (epoch 14.682), train_loss = 1.04592352, grad/param norm = 1.5345e-01, time/batch = 17.6302s	
9735/33150 (epoch 14.683), train_loss = 0.94395983, grad/param norm = 1.3593e-01, time/batch = 18.3791s	
9736/33150 (epoch 14.685), train_loss = 1.11746856, grad/param norm = 1.6379e-01, time/batch = 18.3851s	
9737/33150 (epoch 14.686), train_loss = 0.95100019, grad/param norm = 1.4820e-01, time/batch = 17.3114s	
9738/33150 (epoch 14.688), train_loss = 1.02373368, grad/param norm = 1.3976e-01, time/batch = 15.8900s	
9739/33150 (epoch 14.689), train_loss = 1.01931445, grad/param norm = 1.3062e-01, time/batch = 19.1262s	
9740/33150 (epoch 14.691), train_loss = 0.91529998, grad/param norm = 1.2770e-01, time/batch = 17.9700s	
9741/33150 (epoch 14.692), train_loss = 0.98879422, grad/param norm = 1.3034e-01, time/batch = 15.8948s	
9742/33150 (epoch 14.694), train_loss = 0.87165039, grad/param norm = 1.2864e-01, time/batch = 18.7161s	
9743/33150 (epoch 14.695), train_loss = 1.03286872, grad/param norm = 1.3931e-01, time/batch = 18.0437s	
9744/33150 (epoch 14.697), train_loss = 0.91349581, grad/param norm = 1.1541e-01, time/batch = 17.9574s	
9745/33150 (epoch 14.698), train_loss = 1.09589817, grad/param norm = 1.5015e-01, time/batch = 15.8569s	
9746/33150 (epoch 14.700), train_loss = 0.82782161, grad/param norm = 1.2775e-01, time/batch = 15.5718s	
9747/33150 (epoch 14.701), train_loss = 0.97031743, grad/param norm = 1.3524e-01, time/batch = 15.6655s	
9748/33150 (epoch 14.703), train_loss = 1.07921508, grad/param norm = 1.4584e-01, time/batch = 15.5839s	
9749/33150 (epoch 14.704), train_loss = 0.90687873, grad/param norm = 1.1832e-01, time/batch = 15.4266s	
9750/33150 (epoch 14.706), train_loss = 1.03869989, grad/param norm = 1.3778e-01, time/batch = 15.3619s	
9751/33150 (epoch 14.707), train_loss = 1.03473136, grad/param norm = 1.4991e-01, time/batch = 16.1936s	
9752/33150 (epoch 14.709), train_loss = 1.09223582, grad/param norm = 1.3001e-01, time/batch = 17.1106s	
9753/33150 (epoch 14.710), train_loss = 1.13224057, grad/param norm = 1.6657e-01, time/batch = 16.8054s	
9754/33150 (epoch 14.712), train_loss = 1.17927695, grad/param norm = 1.6311e-01, time/batch = 18.7121s	
9755/33150 (epoch 14.713), train_loss = 1.15899327, grad/param norm = 1.4613e-01, time/batch = 16.7500s	
9756/33150 (epoch 14.715), train_loss = 1.04330751, grad/param norm = 1.4286e-01, time/batch = 17.0388s	
9757/33150 (epoch 14.716), train_loss = 1.13559983, grad/param norm = 1.4905e-01, time/batch = 17.9655s	
9758/33150 (epoch 14.718), train_loss = 1.11549735, grad/param norm = 1.4424e-01, time/batch = 18.1283s	
9759/33150 (epoch 14.719), train_loss = 1.19967821, grad/param norm = 1.7187e-01, time/batch = 16.7105s	
9760/33150 (epoch 14.721), train_loss = 1.09288279, grad/param norm = 1.6762e-01, time/batch = 17.7224s	
9761/33150 (epoch 14.722), train_loss = 1.14153172, grad/param norm = 1.4586e-01, time/batch = 18.3937s	
9762/33150 (epoch 14.724), train_loss = 1.07289066, grad/param norm = 1.8009e-01, time/batch = 17.0285s	
9763/33150 (epoch 14.725), train_loss = 1.25045857, grad/param norm = 1.7786e-01, time/batch = 17.4706s	
9764/33150 (epoch 14.727), train_loss = 1.13625127, grad/param norm = 1.6561e-01, time/batch = 17.3166s	
9765/33150 (epoch 14.729), train_loss = 1.10363287, grad/param norm = 1.5339e-01, time/batch = 18.0586s	
9766/33150 (epoch 14.730), train_loss = 1.10943766, grad/param norm = 1.5327e-01, time/batch = 15.5625s	
9767/33150 (epoch 14.732), train_loss = 1.20325022, grad/param norm = 1.6971e-01, time/batch = 17.0467s	
9768/33150 (epoch 14.733), train_loss = 0.89430263, grad/param norm = 1.2237e-01, time/batch = 16.8952s	
9769/33150 (epoch 14.735), train_loss = 1.04416016, grad/param norm = 1.4190e-01, time/batch = 15.7016s	
9770/33150 (epoch 14.736), train_loss = 1.06123643, grad/param norm = 1.4922e-01, time/batch = 15.4598s	
9771/33150 (epoch 14.738), train_loss = 1.13462806, grad/param norm = 1.7114e-01, time/batch = 16.6361s	
9772/33150 (epoch 14.739), train_loss = 1.24007457, grad/param norm = 1.6586e-01, time/batch = 16.9776s	
9773/33150 (epoch 14.741), train_loss = 1.22823127, grad/param norm = 1.7329e-01, time/batch = 16.1335s	
9774/33150 (epoch 14.742), train_loss = 1.00942138, grad/param norm = 1.5210e-01, time/batch = 16.1100s	
9775/33150 (epoch 14.744), train_loss = 1.23179975, grad/param norm = 1.5640e-01, time/batch = 17.7035s	
9776/33150 (epoch 14.745), train_loss = 1.05924647, grad/param norm = 1.3835e-01, time/batch = 16.1301s	
9777/33150 (epoch 14.747), train_loss = 0.93909536, grad/param norm = 1.5851e-01, time/batch = 16.8952s	
9778/33150 (epoch 14.748), train_loss = 1.00917329, grad/param norm = 1.3742e-01, time/batch = 19.2847s	
9779/33150 (epoch 14.750), train_loss = 1.17984434, grad/param norm = 1.6363e-01, time/batch = 17.2993s	
9780/33150 (epoch 14.751), train_loss = 1.09816584, grad/param norm = 1.3833e-01, time/batch = 15.4636s	
9781/33150 (epoch 14.753), train_loss = 0.95234163, grad/param norm = 1.4499e-01, time/batch = 17.0572s	
9782/33150 (epoch 14.754), train_loss = 1.33002167, grad/param norm = 1.8110e-01, time/batch = 17.5566s	
9783/33150 (epoch 14.756), train_loss = 1.15869009, grad/param norm = 1.6896e-01, time/batch = 17.0460s	
9784/33150 (epoch 14.757), train_loss = 1.10960671, grad/param norm = 1.4065e-01, time/batch = 16.3880s	
9785/33150 (epoch 14.759), train_loss = 1.27233168, grad/param norm = 2.2843e-01, time/batch = 18.6987s	
9786/33150 (epoch 14.760), train_loss = 1.14660305, grad/param norm = 1.5768e-01, time/batch = 17.6335s	
9787/33150 (epoch 14.762), train_loss = 1.12883135, grad/param norm = 1.6426e-01, time/batch = 16.8739s	
9788/33150 (epoch 14.763), train_loss = 1.13911431, grad/param norm = 1.5438e-01, time/batch = 18.3976s	
9789/33150 (epoch 14.765), train_loss = 1.09503737, grad/param norm = 1.4332e-01, time/batch = 16.7881s	
9790/33150 (epoch 14.766), train_loss = 0.99890879, grad/param norm = 1.4337e-01, time/batch = 17.1324s	
9791/33150 (epoch 14.768), train_loss = 1.04181162, grad/param norm = 1.4349e-01, time/batch = 18.2246s	
9792/33150 (epoch 14.769), train_loss = 1.12935161, grad/param norm = 1.5213e-01, time/batch = 18.3901s	
9793/33150 (epoch 14.771), train_loss = 1.13103463, grad/param norm = 1.4889e-01, time/batch = 17.7206s	
9794/33150 (epoch 14.772), train_loss = 1.18013357, grad/param norm = 1.7238e-01, time/batch = 17.3832s	
9795/33150 (epoch 14.774), train_loss = 1.26766270, grad/param norm = 1.5493e-01, time/batch = 20.3720s	
9796/33150 (epoch 14.775), train_loss = 1.19820993, grad/param norm = 2.2492e-01, time/batch = 18.3792s	
9797/33150 (epoch 14.777), train_loss = 1.18963573, grad/param norm = 1.7293e-01, time/batch = 22.0488s	
9798/33150 (epoch 14.778), train_loss = 1.11063806, grad/param norm = 1.2832e-01, time/batch = 26.8631s	
9799/33150 (epoch 14.780), train_loss = 0.97861092, grad/param norm = 1.4350e-01, time/batch = 16.9621s	
9800/33150 (epoch 14.781), train_loss = 1.09465875, grad/param norm = 1.4196e-01, time/batch = 18.3843s	
9801/33150 (epoch 14.783), train_loss = 1.11985060, grad/param norm = 1.3667e-01, time/batch = 18.5546s	
9802/33150 (epoch 14.784), train_loss = 1.07459772, grad/param norm = 1.5806e-01, time/batch = 16.1293s	
9803/33150 (epoch 14.786), train_loss = 1.05688965, grad/param norm = 1.3422e-01, time/batch = 15.3177s	
9804/33150 (epoch 14.787), train_loss = 1.03718310, grad/param norm = 1.3644e-01, time/batch = 18.2189s	
9805/33150 (epoch 14.789), train_loss = 0.91891477, grad/param norm = 1.3259e-01, time/batch = 19.3080s	
9806/33150 (epoch 14.790), train_loss = 0.93510296, grad/param norm = 1.2226e-01, time/batch = 15.1297s	
9807/33150 (epoch 14.792), train_loss = 1.15044691, grad/param norm = 1.7021e-01, time/batch = 17.8017s	
9808/33150 (epoch 14.793), train_loss = 1.10361613, grad/param norm = 1.5164e-01, time/batch = 18.7992s	
9809/33150 (epoch 14.795), train_loss = 1.03323229, grad/param norm = 1.6785e-01, time/batch = 16.7852s	
9810/33150 (epoch 14.796), train_loss = 1.03878394, grad/param norm = 1.4605e-01, time/batch = 16.4663s	
9811/33150 (epoch 14.798), train_loss = 1.02324656, grad/param norm = 1.2563e-01, time/batch = 19.2057s	
9812/33150 (epoch 14.799), train_loss = 0.93469894, grad/param norm = 1.3844e-01, time/batch = 18.6165s	
9813/33150 (epoch 14.801), train_loss = 1.12268101, grad/param norm = 1.4134e-01, time/batch = 16.2751s	
9814/33150 (epoch 14.802), train_loss = 1.00980704, grad/param norm = 1.5753e-01, time/batch = 17.6346s	
9815/33150 (epoch 14.804), train_loss = 1.06428616, grad/param norm = 1.6544e-01, time/batch = 18.8714s	
9816/33150 (epoch 14.805), train_loss = 1.06933791, grad/param norm = 1.6440e-01, time/batch = 17.4644s	
9817/33150 (epoch 14.807), train_loss = 1.03973749, grad/param norm = 1.3015e-01, time/batch = 18.0454s	
9818/33150 (epoch 14.808), train_loss = 1.17642483, grad/param norm = 1.4731e-01, time/batch = 17.0704s	
9819/33150 (epoch 14.810), train_loss = 1.07222117, grad/param norm = 1.4547e-01, time/batch = 18.4692s	
9820/33150 (epoch 14.811), train_loss = 1.13541201, grad/param norm = 1.6102e-01, time/batch = 15.8807s	
9821/33150 (epoch 14.813), train_loss = 1.06618468, grad/param norm = 1.3036e-01, time/batch = 17.9670s	
9822/33150 (epoch 14.814), train_loss = 1.10673791, grad/param norm = 1.7204e-01, time/batch = 18.8831s	
9823/33150 (epoch 14.816), train_loss = 1.06069355, grad/param norm = 1.4398e-01, time/batch = 16.5513s	
9824/33150 (epoch 14.817), train_loss = 1.15749948, grad/param norm = 1.4456e-01, time/batch = 15.1326s	
9825/33150 (epoch 14.819), train_loss = 1.06857984, grad/param norm = 1.3283e-01, time/batch = 17.2263s	
9826/33150 (epoch 14.821), train_loss = 0.95305192, grad/param norm = 1.2466e-01, time/batch = 16.2334s	
9827/33150 (epoch 14.822), train_loss = 1.01302243, grad/param norm = 1.3417e-01, time/batch = 15.4720s	
9828/33150 (epoch 14.824), train_loss = 1.05888193, grad/param norm = 1.4850e-01, time/batch = 18.2175s	
9829/33150 (epoch 14.825), train_loss = 1.09503822, grad/param norm = 1.4823e-01, time/batch = 18.2243s	
9830/33150 (epoch 14.827), train_loss = 1.15895718, grad/param norm = 1.6970e-01, time/batch = 16.4402s	
9831/33150 (epoch 14.828), train_loss = 0.96137977, grad/param norm = 1.4329e-01, time/batch = 17.8864s	
9832/33150 (epoch 14.830), train_loss = 1.16028109, grad/param norm = 1.5172e-01, time/batch = 15.8085s	
9833/33150 (epoch 14.831), train_loss = 1.04039037, grad/param norm = 1.6336e-01, time/batch = 18.9511s	
9834/33150 (epoch 14.833), train_loss = 0.97863794, grad/param norm = 1.4279e-01, time/batch = 17.2111s	
9835/33150 (epoch 14.834), train_loss = 1.20402985, grad/param norm = 1.5683e-01, time/batch = 18.6314s	
9836/33150 (epoch 14.836), train_loss = 1.19377733, grad/param norm = 1.5151e-01, time/batch = 18.6085s	
9837/33150 (epoch 14.837), train_loss = 1.09614279, grad/param norm = 1.4831e-01, time/batch = 16.8864s	
9838/33150 (epoch 14.839), train_loss = 1.19200551, grad/param norm = 1.7857e-01, time/batch = 16.4556s	
9839/33150 (epoch 14.840), train_loss = 1.16261268, grad/param norm = 1.5508e-01, time/batch = 18.7079s	
9840/33150 (epoch 14.842), train_loss = 1.25706930, grad/param norm = 1.7449e-01, time/batch = 18.4497s	
9841/33150 (epoch 14.843), train_loss = 1.24452976, grad/param norm = 1.6612e-01, time/batch = 17.2147s	
9842/33150 (epoch 14.845), train_loss = 1.05013915, grad/param norm = 1.4702e-01, time/batch = 18.7030s	
9843/33150 (epoch 14.846), train_loss = 1.29836011, grad/param norm = 1.9681e-01, time/batch = 18.8733s	
9844/33150 (epoch 14.848), train_loss = 1.19046629, grad/param norm = 1.5637e-01, time/batch = 16.4615s	
9845/33150 (epoch 14.849), train_loss = 1.18967870, grad/param norm = 1.6400e-01, time/batch = 15.9616s	
9846/33150 (epoch 14.851), train_loss = 1.20406824, grad/param norm = 1.6893e-01, time/batch = 18.6333s	
9847/33150 (epoch 14.852), train_loss = 1.27511387, grad/param norm = 1.4882e-01, time/batch = 17.2951s	
9848/33150 (epoch 14.854), train_loss = 1.11350921, grad/param norm = 1.4852e-01, time/batch = 17.9533s	
9849/33150 (epoch 14.855), train_loss = 0.95950307, grad/param norm = 1.4958e-01, time/batch = 19.1354s	
9850/33150 (epoch 14.857), train_loss = 0.93569589, grad/param norm = 1.3520e-01, time/batch = 17.3900s	
9851/33150 (epoch 14.858), train_loss = 1.04633499, grad/param norm = 1.5445e-01, time/batch = 17.4740s	
9852/33150 (epoch 14.860), train_loss = 0.98610989, grad/param norm = 1.3018e-01, time/batch = 20.1349s	
9853/33150 (epoch 14.861), train_loss = 1.01641008, grad/param norm = 1.4529e-01, time/batch = 19.9653s	
9854/33150 (epoch 14.863), train_loss = 1.12823666, grad/param norm = 1.4549e-01, time/batch = 17.2869s	
9855/33150 (epoch 14.864), train_loss = 1.19446247, grad/param norm = 1.5397e-01, time/batch = 19.3696s	
9856/33150 (epoch 14.866), train_loss = 1.15212798, grad/param norm = 1.5403e-01, time/batch = 18.3742s	
9857/33150 (epoch 14.867), train_loss = 1.12880181, grad/param norm = 1.3031e-01, time/batch = 16.2926s	
9858/33150 (epoch 14.869), train_loss = 1.15281581, grad/param norm = 1.4545e-01, time/batch = 18.6377s	
9859/33150 (epoch 14.870), train_loss = 1.12551357, grad/param norm = 1.6481e-01, time/batch = 19.9492s	
9860/33150 (epoch 14.872), train_loss = 1.10625920, grad/param norm = 1.6521e-01, time/batch = 17.5101s	
9861/33150 (epoch 14.873), train_loss = 0.93042173, grad/param norm = 1.3765e-01, time/batch = 18.7156s	
9862/33150 (epoch 14.875), train_loss = 1.24141517, grad/param norm = 1.5399e-01, time/batch = 17.6383s	
9863/33150 (epoch 14.876), train_loss = 1.00135326, grad/param norm = 1.5210e-01, time/batch = 17.1459s	
9864/33150 (epoch 14.878), train_loss = 0.97457975, grad/param norm = 1.2751e-01, time/batch = 16.5572s	
9865/33150 (epoch 14.879), train_loss = 1.00048143, grad/param norm = 1.3771e-01, time/batch = 18.5594s	
9866/33150 (epoch 14.881), train_loss = 1.02610099, grad/param norm = 1.3906e-01, time/batch = 17.6338s	
9867/33150 (epoch 14.882), train_loss = 0.91839348, grad/param norm = 1.2764e-01, time/batch = 15.7929s	
9868/33150 (epoch 14.884), train_loss = 1.06958595, grad/param norm = 1.4276e-01, time/batch = 17.3193s	
9869/33150 (epoch 14.885), train_loss = 0.85874115, grad/param norm = 1.3236e-01, time/batch = 17.1215s	
9870/33150 (epoch 14.887), train_loss = 1.25876622, grad/param norm = 1.7123e-01, time/batch = 16.9768s	
9871/33150 (epoch 14.888), train_loss = 1.15334010, grad/param norm = 1.6479e-01, time/batch = 19.1422s	
9872/33150 (epoch 14.890), train_loss = 1.03083376, grad/param norm = 1.4301e-01, time/batch = 17.9786s	
9873/33150 (epoch 14.891), train_loss = 0.99624858, grad/param norm = 1.6230e-01, time/batch = 17.4006s	
9874/33150 (epoch 14.893), train_loss = 1.16428695, grad/param norm = 1.6327e-01, time/batch = 16.3828s	
9875/33150 (epoch 14.894), train_loss = 1.16834976, grad/param norm = 1.5746e-01, time/batch = 17.7232s	
9876/33150 (epoch 14.896), train_loss = 1.06350556, grad/param norm = 1.4686e-01, time/batch = 16.3233s	
9877/33150 (epoch 14.897), train_loss = 1.11826732, grad/param norm = 1.3522e-01, time/batch = 16.1311s	
9878/33150 (epoch 14.899), train_loss = 0.96717301, grad/param norm = 1.4984e-01, time/batch = 17.1350s	
9879/33150 (epoch 14.900), train_loss = 1.36341151, grad/param norm = 1.5690e-01, time/batch = 15.4018s	
9880/33150 (epoch 14.902), train_loss = 1.25094559, grad/param norm = 1.5454e-01, time/batch = 19.6237s	
9881/33150 (epoch 14.903), train_loss = 1.10566374, grad/param norm = 1.4315e-01, time/batch = 17.0298s	
9882/33150 (epoch 14.905), train_loss = 1.14060032, grad/param norm = 1.4344e-01, time/batch = 18.5511s	
9883/33150 (epoch 14.906), train_loss = 1.19206458, grad/param norm = 1.7320e-01, time/batch = 17.9647s	
9884/33150 (epoch 14.908), train_loss = 1.25705119, grad/param norm = 1.6942e-01, time/batch = 16.6274s	
9885/33150 (epoch 14.910), train_loss = 1.19235479, grad/param norm = 1.4869e-01, time/batch = 18.3805s	
9886/33150 (epoch 14.911), train_loss = 0.95567694, grad/param norm = 1.2583e-01, time/batch = 16.9826s	
9887/33150 (epoch 14.913), train_loss = 1.03631232, grad/param norm = 1.4175e-01, time/batch = 15.2080s	
9888/33150 (epoch 14.914), train_loss = 1.17991751, grad/param norm = 1.5998e-01, time/batch = 15.8025s	
9889/33150 (epoch 14.916), train_loss = 1.02207840, grad/param norm = 1.6312e-01, time/batch = 17.4752s	
9890/33150 (epoch 14.917), train_loss = 1.19952746, grad/param norm = 1.6872e-01, time/batch = 19.3869s	
9891/33150 (epoch 14.919), train_loss = 1.25210011, grad/param norm = 1.8876e-01, time/batch = 15.9694s	
9892/33150 (epoch 14.920), train_loss = 1.19508582, grad/param norm = 1.5404e-01, time/batch = 17.5718s	
9893/33150 (epoch 14.922), train_loss = 1.28131651, grad/param norm = 1.8889e-01, time/batch = 18.5728s	
9894/33150 (epoch 14.923), train_loss = 1.12259779, grad/param norm = 1.6196e-01, time/batch = 17.7080s	
9895/33150 (epoch 14.925), train_loss = 1.17419781, grad/param norm = 1.4861e-01, time/batch = 16.2168s	
9896/33150 (epoch 14.926), train_loss = 1.07684611, grad/param norm = 1.4302e-01, time/batch = 15.7378s	
9897/33150 (epoch 14.928), train_loss = 1.05797050, grad/param norm = 1.5523e-01, time/batch = 18.7810s	
9898/33150 (epoch 14.929), train_loss = 1.16231486, grad/param norm = 1.4529e-01, time/batch = 16.7878s	
9899/33150 (epoch 14.931), train_loss = 1.26549630, grad/param norm = 1.7830e-01, time/batch = 18.3856s	
9900/33150 (epoch 14.932), train_loss = 1.12751465, grad/param norm = 1.6763e-01, time/batch = 15.7840s	
9901/33150 (epoch 14.934), train_loss = 1.14511824, grad/param norm = 1.4746e-01, time/batch = 16.8612s	
9902/33150 (epoch 14.935), train_loss = 1.21789241, grad/param norm = 1.4978e-01, time/batch = 15.5007s	
9903/33150 (epoch 14.937), train_loss = 1.23484388, grad/param norm = 1.4527e-01, time/batch = 14.9296s	
9904/33150 (epoch 14.938), train_loss = 1.17765192, grad/param norm = 1.4730e-01, time/batch = 14.9913s	
9905/33150 (epoch 14.940), train_loss = 1.38963583, grad/param norm = 1.7169e-01, time/batch = 14.8853s	
9906/33150 (epoch 14.941), train_loss = 1.09844236, grad/param norm = 1.3260e-01, time/batch = 15.3022s	
9907/33150 (epoch 14.943), train_loss = 1.00542090, grad/param norm = 1.5010e-01, time/batch = 16.0344s	
9908/33150 (epoch 14.944), train_loss = 1.21239211, grad/param norm = 1.7192e-01, time/batch = 14.9807s	
9909/33150 (epoch 14.946), train_loss = 0.91944218, grad/param norm = 1.2545e-01, time/batch = 15.6939s	
9910/33150 (epoch 14.947), train_loss = 1.14359532, grad/param norm = 1.3761e-01, time/batch = 16.5096s	
9911/33150 (epoch 14.949), train_loss = 1.25304328, grad/param norm = 1.4778e-01, time/batch = 17.1110s	
9912/33150 (epoch 14.950), train_loss = 1.15912498, grad/param norm = 1.5553e-01, time/batch = 17.0511s	
9913/33150 (epoch 14.952), train_loss = 1.01091732, grad/param norm = 1.4160e-01, time/batch = 15.6238s	
9914/33150 (epoch 14.953), train_loss = 1.07680545, grad/param norm = 1.4335e-01, time/batch = 16.8684s	
9915/33150 (epoch 14.955), train_loss = 0.97832219, grad/param norm = 1.3899e-01, time/batch = 18.7047s	
9916/33150 (epoch 14.956), train_loss = 1.16470881, grad/param norm = 1.4400e-01, time/batch = 17.7787s	
9917/33150 (epoch 14.958), train_loss = 0.98321494, grad/param norm = 1.2985e-01, time/batch = 16.8818s	
9918/33150 (epoch 14.959), train_loss = 1.03545186, grad/param norm = 1.5306e-01, time/batch = 18.8867s	
9919/33150 (epoch 14.961), train_loss = 0.98821104, grad/param norm = 1.5017e-01, time/batch = 18.6207s	
9920/33150 (epoch 14.962), train_loss = 0.94892740, grad/param norm = 1.3370e-01, time/batch = 17.7067s	
9921/33150 (epoch 14.964), train_loss = 1.11361936, grad/param norm = 1.4762e-01, time/batch = 18.0377s	
9922/33150 (epoch 14.965), train_loss = 1.10304402, grad/param norm = 1.4461e-01, time/batch = 16.8062s	
9923/33150 (epoch 14.967), train_loss = 1.10053894, grad/param norm = 1.6562e-01, time/batch = 16.3087s	
9924/33150 (epoch 14.968), train_loss = 0.93741138, grad/param norm = 1.3227e-01, time/batch = 15.2813s	
9925/33150 (epoch 14.970), train_loss = 1.05238989, grad/param norm = 1.3608e-01, time/batch = 17.8697s	
9926/33150 (epoch 14.971), train_loss = 1.10152771, grad/param norm = 1.5524e-01, time/batch = 16.1828s	
9927/33150 (epoch 14.973), train_loss = 1.27641391, grad/param norm = 1.5833e-01, time/batch = 15.8679s	
9928/33150 (epoch 14.974), train_loss = 1.26065082, grad/param norm = 1.5792e-01, time/batch = 16.7784s	
9929/33150 (epoch 14.976), train_loss = 1.16525321, grad/param norm = 1.3597e-01, time/batch = 17.2065s	
9930/33150 (epoch 14.977), train_loss = 1.27360105, grad/param norm = 1.6683e-01, time/batch = 16.6318s	
9931/33150 (epoch 14.979), train_loss = 1.22958575, grad/param norm = 1.7953e-01, time/batch = 17.8930s	
9932/33150 (epoch 14.980), train_loss = 1.26437803, grad/param norm = 1.5045e-01, time/batch = 17.2991s	
9933/33150 (epoch 14.982), train_loss = 1.12207019, grad/param norm = 2.0159e-01, time/batch = 16.4651s	
9934/33150 (epoch 14.983), train_loss = 0.97817938, grad/param norm = 1.4972e-01, time/batch = 15.2955s	
9935/33150 (epoch 14.985), train_loss = 1.15863425, grad/param norm = 1.3994e-01, time/batch = 17.7028s	
9936/33150 (epoch 14.986), train_loss = 0.96580677, grad/param norm = 1.4320e-01, time/batch = 18.0598s	
9937/33150 (epoch 14.988), train_loss = 1.05126648, grad/param norm = 1.4617e-01, time/batch = 16.3626s	
9938/33150 (epoch 14.989), train_loss = 1.01270209, grad/param norm = 1.6067e-01, time/batch = 16.9180s	
9939/33150 (epoch 14.991), train_loss = 1.18434139, grad/param norm = 1.8854e-01, time/batch = 17.6381s	
9940/33150 (epoch 14.992), train_loss = 0.98487045, grad/param norm = 1.3573e-01, time/batch = 18.2255s	
9941/33150 (epoch 14.994), train_loss = 1.10629757, grad/param norm = 1.5416e-01, time/batch = 16.3105s	
9942/33150 (epoch 14.995), train_loss = 1.05123045, grad/param norm = 1.5500e-01, time/batch = 18.1378s	
9943/33150 (epoch 14.997), train_loss = 1.13612301, grad/param norm = 1.8305e-01, time/batch = 17.8792s	
9944/33150 (epoch 14.998), train_loss = 0.90248600, grad/param norm = 1.3703e-01, time/batch = 16.6426s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
9945/33150 (epoch 15.000), train_loss = 0.93466619, grad/param norm = 1.4225e-01, time/batch = 16.1446s	
9946/33150 (epoch 15.002), train_loss = 1.42497322, grad/param norm = 1.7953e-01, time/batch = 17.9049s	
9947/33150 (epoch 15.003), train_loss = 1.03151414, grad/param norm = 1.4789e-01, time/batch = 15.9870s	
9948/33150 (epoch 15.005), train_loss = 0.99595284, grad/param norm = 1.4802e-01, time/batch = 15.7360s	
9949/33150 (epoch 15.006), train_loss = 0.95068265, grad/param norm = 1.4470e-01, time/batch = 16.8206s	
9950/33150 (epoch 15.008), train_loss = 1.20367923, grad/param norm = 1.5514e-01, time/batch = 16.7957s	
9951/33150 (epoch 15.009), train_loss = 1.08833704, grad/param norm = 1.5494e-01, time/batch = 16.9582s	
9952/33150 (epoch 15.011), train_loss = 1.22462062, grad/param norm = 1.6024e-01, time/batch = 16.3004s	
9953/33150 (epoch 15.012), train_loss = 1.09958992, grad/param norm = 1.6711e-01, time/batch = 16.9709s	
9954/33150 (epoch 15.014), train_loss = 1.05951743, grad/param norm = 1.5253e-01, time/batch = 17.0574s	
9955/33150 (epoch 15.015), train_loss = 1.03941052, grad/param norm = 1.5776e-01, time/batch = 16.4594s	
9956/33150 (epoch 15.017), train_loss = 1.00717767, grad/param norm = 1.3235e-01, time/batch = 16.7176s	
9957/33150 (epoch 15.018), train_loss = 1.13086821, grad/param norm = 1.6476e-01, time/batch = 17.2862s	
9958/33150 (epoch 15.020), train_loss = 1.17464800, grad/param norm = 1.6283e-01, time/batch = 17.1467s	
9959/33150 (epoch 15.021), train_loss = 0.97630054, grad/param norm = 1.5839e-01, time/batch = 16.8017s	
9960/33150 (epoch 15.023), train_loss = 1.27303184, grad/param norm = 1.5219e-01, time/batch = 18.0526s	
9961/33150 (epoch 15.024), train_loss = 1.15328280, grad/param norm = 1.4915e-01, time/batch = 17.7232s	
9962/33150 (epoch 15.026), train_loss = 0.87231675, grad/param norm = 1.1871e-01, time/batch = 16.8130s	
9963/33150 (epoch 15.027), train_loss = 0.89378320, grad/param norm = 1.2862e-01, time/batch = 16.8948s	
9964/33150 (epoch 15.029), train_loss = 1.00257924, grad/param norm = 1.4719e-01, time/batch = 18.9575s	
9965/33150 (epoch 15.030), train_loss = 1.07421051, grad/param norm = 1.2738e-01, time/batch = 16.8028s	
9966/33150 (epoch 15.032), train_loss = 1.04291090, grad/param norm = 1.8171e-01, time/batch = 17.1451s	
9967/33150 (epoch 15.033), train_loss = 1.05594480, grad/param norm = 1.5201e-01, time/batch = 16.5269s	
9968/33150 (epoch 15.035), train_loss = 1.25276795, grad/param norm = 1.5915e-01, time/batch = 17.4712s	
9969/33150 (epoch 15.036), train_loss = 1.13908390, grad/param norm = 1.5645e-01, time/batch = 16.0276s	
9970/33150 (epoch 15.038), train_loss = 1.37620738, grad/param norm = 1.8534e-01, time/batch = 15.7729s	
9971/33150 (epoch 15.039), train_loss = 1.12403092, grad/param norm = 1.3995e-01, time/batch = 15.5460s	
9972/33150 (epoch 15.041), train_loss = 1.14268445, grad/param norm = 1.4930e-01, time/batch = 17.0356s	
9973/33150 (epoch 15.042), train_loss = 1.06529594, grad/param norm = 1.4253e-01, time/batch = 16.0817s	
9974/33150 (epoch 15.044), train_loss = 1.06273544, grad/param norm = 1.3892e-01, time/batch = 17.0440s	
9975/33150 (epoch 15.045), train_loss = 1.10633843, grad/param norm = 1.3984e-01, time/batch = 17.5409s	
9976/33150 (epoch 15.047), train_loss = 1.00011131, grad/param norm = 1.4212e-01, time/batch = 16.1118s	
9977/33150 (epoch 15.048), train_loss = 1.20598318, grad/param norm = 1.6621e-01, time/batch = 17.2940s	
9978/33150 (epoch 15.050), train_loss = 1.10625764, grad/param norm = 1.5959e-01, time/batch = 16.3870s	
9979/33150 (epoch 15.051), train_loss = 1.09853485, grad/param norm = 1.4803e-01, time/batch = 15.9570s	
9980/33150 (epoch 15.053), train_loss = 1.05991651, grad/param norm = 1.4004e-01, time/batch = 15.8021s	
9981/33150 (epoch 15.054), train_loss = 1.18973677, grad/param norm = 1.3533e-01, time/batch = 17.3097s	
9982/33150 (epoch 15.056), train_loss = 1.04675684, grad/param norm = 1.4202e-01, time/batch = 18.7880s	
9983/33150 (epoch 15.057), train_loss = 1.09536080, grad/param norm = 1.5914e-01, time/batch = 17.3792s	
9984/33150 (epoch 15.059), train_loss = 1.01600507, grad/param norm = 1.5025e-01, time/batch = 17.1505s	
9985/33150 (epoch 15.060), train_loss = 1.03519809, grad/param norm = 1.3650e-01, time/batch = 15.8845s	
9986/33150 (epoch 15.062), train_loss = 1.06279009, grad/param norm = 1.4134e-01, time/batch = 16.2170s	
9987/33150 (epoch 15.063), train_loss = 1.04412961, grad/param norm = 1.4647e-01, time/batch = 15.9466s	
9988/33150 (epoch 15.065), train_loss = 1.07520077, grad/param norm = 1.3374e-01, time/batch = 16.6140s	
9989/33150 (epoch 15.066), train_loss = 1.00821986, grad/param norm = 1.4010e-01, time/batch = 17.8772s	
9990/33150 (epoch 15.068), train_loss = 1.10194895, grad/param norm = 1.4565e-01, time/batch = 17.6991s	
9991/33150 (epoch 15.069), train_loss = 1.17298841, grad/param norm = 1.6153e-01, time/batch = 17.0545s	
9992/33150 (epoch 15.071), train_loss = 1.12922896, grad/param norm = 1.4839e-01, time/batch = 18.7873s	
9993/33150 (epoch 15.072), train_loss = 1.05879548, grad/param norm = 1.4740e-01, time/batch = 17.4891s	
9994/33150 (epoch 15.074), train_loss = 0.94757627, grad/param norm = 1.6371e-01, time/batch = 15.5607s	
9995/33150 (epoch 15.075), train_loss = 1.04151529, grad/param norm = 1.5748e-01, time/batch = 15.8664s	
9996/33150 (epoch 15.077), train_loss = 1.10038195, grad/param norm = 1.5654e-01, time/batch = 15.8979s	
9997/33150 (epoch 15.078), train_loss = 1.25838358, grad/param norm = 1.7121e-01, time/batch = 15.7565s	
9998/33150 (epoch 15.080), train_loss = 1.20897616, grad/param norm = 1.3468e-01, time/batch = 17.7368s	
9999/33150 (epoch 15.081), train_loss = 1.00584795, grad/param norm = 1.5285e-01, time/batch = 16.8962s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch15.08_1.5301.t7	
10000/33150 (epoch 15.083), train_loss = 0.81106335, grad/param norm = 1.5120e-01, time/batch = 18.0601s	
10001/33150 (epoch 15.084), train_loss = 1.24589112, grad/param norm = 1.7649e-01, time/batch = 17.1270s	
10002/33150 (epoch 15.086), train_loss = 1.03576170, grad/param norm = 1.7175e-01, time/batch = 16.2650s	
10003/33150 (epoch 15.087), train_loss = 0.94621549, grad/param norm = 1.5503e-01, time/batch = 15.7531s	
10004/33150 (epoch 15.089), train_loss = 0.99853925, grad/param norm = 1.5366e-01, time/batch = 20.0406s	
10005/33150 (epoch 15.090), train_loss = 1.01927895, grad/param norm = 1.5048e-01, time/batch = 17.1428s	
10006/33150 (epoch 15.092), train_loss = 1.03668968, grad/param norm = 1.5780e-01, time/batch = 16.5538s	
10007/33150 (epoch 15.094), train_loss = 1.15326954, grad/param norm = 1.6261e-01, time/batch = 16.4583s	
10008/33150 (epoch 15.095), train_loss = 0.93731939, grad/param norm = 1.3453e-01, time/batch = 18.6242s	
10009/33150 (epoch 15.097), train_loss = 1.03697494, grad/param norm = 1.5342e-01, time/batch = 16.4774s	
10010/33150 (epoch 15.098), train_loss = 1.31763023, grad/param norm = 1.6595e-01, time/batch = 17.2189s	
10011/33150 (epoch 15.100), train_loss = 1.29226066, grad/param norm = 1.5998e-01, time/batch = 18.5629s	
10012/33150 (epoch 15.101), train_loss = 1.01881164, grad/param norm = 1.6933e-01, time/batch = 16.7232s	
10013/33150 (epoch 15.103), train_loss = 1.10615226, grad/param norm = 1.5585e-01, time/batch = 15.8909s	
10014/33150 (epoch 15.104), train_loss = 1.00671715, grad/param norm = 1.5974e-01, time/batch = 16.7896s	
10015/33150 (epoch 15.106), train_loss = 1.23260314, grad/param norm = 1.6562e-01, time/batch = 17.3061s	
10016/33150 (epoch 15.107), train_loss = 1.33150851, grad/param norm = 1.6348e-01, time/batch = 18.0348s	
10017/33150 (epoch 15.109), train_loss = 1.04824923, grad/param norm = 1.2739e-01, time/batch = 15.5735s	
10018/33150 (epoch 15.110), train_loss = 1.17562025, grad/param norm = 1.4566e-01, time/batch = 18.9670s	
10019/33150 (epoch 15.112), train_loss = 1.00258384, grad/param norm = 1.4149e-01, time/batch = 17.6482s	
10020/33150 (epoch 15.113), train_loss = 1.07273002, grad/param norm = 1.5867e-01, time/batch = 15.6987s	
10021/33150 (epoch 15.115), train_loss = 1.26837068, grad/param norm = 1.6672e-01, time/batch = 17.8032s	
10022/33150 (epoch 15.116), train_loss = 1.04872112, grad/param norm = 1.4659e-01, time/batch = 19.7199s	
10023/33150 (epoch 15.118), train_loss = 1.16970461, grad/param norm = 1.6105e-01, time/batch = 17.7165s	
10024/33150 (epoch 15.119), train_loss = 1.16659543, grad/param norm = 1.7215e-01, time/batch = 16.3933s	
10025/33150 (epoch 15.121), train_loss = 1.04425138, grad/param norm = 1.4378e-01, time/batch = 18.4844s	
10026/33150 (epoch 15.122), train_loss = 1.31085436, grad/param norm = 1.9646e-01, time/batch = 15.7984s	
10027/33150 (epoch 15.124), train_loss = 0.87953565, grad/param norm = 1.2022e-01, time/batch = 17.2904s	
10028/33150 (epoch 15.125), train_loss = 1.18160096, grad/param norm = 1.5318e-01, time/batch = 17.6553s	
10029/33150 (epoch 15.127), train_loss = 1.04235223, grad/param norm = 1.4028e-01, time/batch = 18.2204s	
10030/33150 (epoch 15.128), train_loss = 1.12225862, grad/param norm = 1.5929e-01, time/batch = 15.8916s	
10031/33150 (epoch 15.130), train_loss = 1.11271614, grad/param norm = 1.4288e-01, time/batch = 16.9003s	
10032/33150 (epoch 15.131), train_loss = 1.32941670, grad/param norm = 1.8396e-01, time/batch = 16.4056s	
10033/33150 (epoch 15.133), train_loss = 1.01854022, grad/param norm = 1.3439e-01, time/batch = 18.3829s	
10034/33150 (epoch 15.134), train_loss = 1.21178132, grad/param norm = 1.5910e-01, time/batch = 17.9684s	
10035/33150 (epoch 15.136), train_loss = 1.12793248, grad/param norm = 1.6245e-01, time/batch = 19.8026s	
10036/33150 (epoch 15.137), train_loss = 1.19597037, grad/param norm = 1.5007e-01, time/batch = 18.2108s	
10037/33150 (epoch 15.139), train_loss = 1.17951422, grad/param norm = 1.7383e-01, time/batch = 18.1455s	
10038/33150 (epoch 15.140), train_loss = 1.24771748, grad/param norm = 1.6775e-01, time/batch = 19.2253s	
10039/33150 (epoch 15.142), train_loss = 1.18850385, grad/param norm = 1.6054e-01, time/batch = 19.5708s	
10040/33150 (epoch 15.143), train_loss = 1.12296314, grad/param norm = 1.6167e-01, time/batch = 17.4759s	
10041/33150 (epoch 15.145), train_loss = 1.06781530, grad/param norm = 1.7484e-01, time/batch = 19.1378s	
10042/33150 (epoch 15.146), train_loss = 1.23539281, grad/param norm = 1.7315e-01, time/batch = 18.6353s	
10043/33150 (epoch 15.148), train_loss = 1.20596667, grad/param norm = 1.4875e-01, time/batch = 17.3157s	
10044/33150 (epoch 15.149), train_loss = 1.13659459, grad/param norm = 1.4984e-01, time/batch = 17.1442s	
10045/33150 (epoch 15.151), train_loss = 1.28929852, grad/param norm = 1.5505e-01, time/batch = 19.4677s	
10046/33150 (epoch 15.152), train_loss = 1.05745505, grad/param norm = 1.4813e-01, time/batch = 15.0396s	
10047/33150 (epoch 15.154), train_loss = 1.08407890, grad/param norm = 1.5033e-01, time/batch = 15.9764s	
10048/33150 (epoch 15.155), train_loss = 0.97501611, grad/param norm = 1.4110e-01, time/batch = 15.9855s	
10049/33150 (epoch 15.157), train_loss = 1.03812643, grad/param norm = 1.5139e-01, time/batch = 16.2207s	
10050/33150 (epoch 15.158), train_loss = 1.00926585, grad/param norm = 1.4909e-01, time/batch = 17.0440s	
10051/33150 (epoch 15.160), train_loss = 1.17957438, grad/param norm = 1.5900e-01, time/batch = 16.7233s	
10052/33150 (epoch 15.161), train_loss = 1.04046529, grad/param norm = 1.7067e-01, time/batch = 17.7178s	
10053/33150 (epoch 15.163), train_loss = 1.04440245, grad/param norm = 1.4508e-01, time/batch = 16.3072s	
10054/33150 (epoch 15.164), train_loss = 1.16710259, grad/param norm = 1.6662e-01, time/batch = 17.2944s	
10055/33150 (epoch 15.166), train_loss = 1.07556367, grad/param norm = 1.5938e-01, time/batch = 18.4610s	
10056/33150 (epoch 15.167), train_loss = 1.11399616, grad/param norm = 1.4507e-01, time/batch = 17.0454s	
10057/33150 (epoch 15.169), train_loss = 1.15785334, grad/param norm = 1.8457e-01, time/batch = 16.4734s	
10058/33150 (epoch 15.170), train_loss = 1.01161521, grad/param norm = 1.6288e-01, time/batch = 16.4719s	
10059/33150 (epoch 15.172), train_loss = 1.20108764, grad/param norm = 1.7015e-01, time/batch = 16.2159s	
10060/33150 (epoch 15.173), train_loss = 1.16770574, grad/param norm = 1.8299e-01, time/batch = 16.2253s	
10061/33150 (epoch 15.175), train_loss = 1.02093074, grad/param norm = 1.4881e-01, time/batch = 16.8139s	
10062/33150 (epoch 15.176), train_loss = 1.14067008, grad/param norm = 1.6242e-01, time/batch = 17.4873s	
10063/33150 (epoch 15.178), train_loss = 1.27280677, grad/param norm = 1.6237e-01, time/batch = 17.3907s	
10064/33150 (epoch 15.179), train_loss = 1.14684736, grad/param norm = 1.4757e-01, time/batch = 16.3819s	
10065/33150 (epoch 15.181), train_loss = 1.11614958, grad/param norm = 1.5886e-01, time/batch = 17.9564s	
10066/33150 (epoch 15.183), train_loss = 1.09337947, grad/param norm = 1.6902e-01, time/batch = 17.3100s	
10067/33150 (epoch 15.184), train_loss = 1.30661461, grad/param norm = 1.5209e-01, time/batch = 17.8016s	
10068/33150 (epoch 15.186), train_loss = 1.19868515, grad/param norm = 1.4567e-01, time/batch = 15.9690s	
10069/33150 (epoch 15.187), train_loss = 1.13375309, grad/param norm = 1.5947e-01, time/batch = 17.6093s	
10070/33150 (epoch 15.189), train_loss = 0.90468145, grad/param norm = 1.5704e-01, time/batch = 18.4546s	
10071/33150 (epoch 15.190), train_loss = 0.98080670, grad/param norm = 1.4356e-01, time/batch = 17.0266s	
10072/33150 (epoch 15.192), train_loss = 1.12607979, grad/param norm = 1.8721e-01, time/batch = 16.8918s	
10073/33150 (epoch 15.193), train_loss = 1.15695659, grad/param norm = 1.4517e-01, time/batch = 18.7332s	
10074/33150 (epoch 15.195), train_loss = 1.39143871, grad/param norm = 1.8386e-01, time/batch = 16.4110s	
10075/33150 (epoch 15.196), train_loss = 1.24561720, grad/param norm = 1.6032e-01, time/batch = 16.6237s	
10076/33150 (epoch 15.198), train_loss = 0.94578082, grad/param norm = 1.4932e-01, time/batch = 18.0539s	
10077/33150 (epoch 15.199), train_loss = 1.20246571, grad/param norm = 1.7200e-01, time/batch = 18.6410s	
10078/33150 (epoch 15.201), train_loss = 1.00218735, grad/param norm = 1.3235e-01, time/batch = 17.4588s	
10079/33150 (epoch 15.202), train_loss = 0.90786820, grad/param norm = 1.3493e-01, time/batch = 17.8958s	
10080/33150 (epoch 15.204), train_loss = 1.12184669, grad/param norm = 1.5148e-01, time/batch = 17.3013s	
10081/33150 (epoch 15.205), train_loss = 1.17787775, grad/param norm = 1.5277e-01, time/batch = 17.9721s	
10082/33150 (epoch 15.207), train_loss = 1.14829096, grad/param norm = 1.5110e-01, time/batch = 16.0019s	
10083/33150 (epoch 15.208), train_loss = 1.16339570, grad/param norm = 1.5559e-01, time/batch = 18.0669s	
10084/33150 (epoch 15.210), train_loss = 1.00791041, grad/param norm = 1.3334e-01, time/batch = 19.2967s	
10085/33150 (epoch 15.211), train_loss = 1.15787317, grad/param norm = 1.7057e-01, time/batch = 16.5428s	
10086/33150 (epoch 15.213), train_loss = 1.17140669, grad/param norm = 1.5044e-01, time/batch = 19.1221s	
10087/33150 (epoch 15.214), train_loss = 1.07387080, grad/param norm = 1.5264e-01, time/batch = 18.7991s	
10088/33150 (epoch 15.216), train_loss = 1.04852538, grad/param norm = 1.6305e-01, time/batch = 17.1340s	
10089/33150 (epoch 15.217), train_loss = 1.04406283, grad/param norm = 1.3643e-01, time/batch = 18.1197s	
10090/33150 (epoch 15.219), train_loss = 0.97635096, grad/param norm = 1.3941e-01, time/batch = 19.2908s	
10091/33150 (epoch 15.220), train_loss = 1.02149227, grad/param norm = 1.2979e-01, time/batch = 17.2346s	
10092/33150 (epoch 15.222), train_loss = 1.19912630, grad/param norm = 1.4191e-01, time/batch = 17.1540s	
10093/33150 (epoch 15.223), train_loss = 1.09346145, grad/param norm = 1.6148e-01, time/batch = 17.9649s	
10094/33150 (epoch 15.225), train_loss = 1.26274001, grad/param norm = 1.5835e-01, time/batch = 18.1498s	
10095/33150 (epoch 15.226), train_loss = 1.06088024, grad/param norm = 1.3961e-01, time/batch = 16.5622s	
10096/33150 (epoch 15.228), train_loss = 1.07896920, grad/param norm = 1.4497e-01, time/batch = 16.9027s	
10097/33150 (epoch 15.229), train_loss = 1.07970074, grad/param norm = 1.5124e-01, time/batch = 19.4735s	
10098/33150 (epoch 15.231), train_loss = 1.23630791, grad/param norm = 1.6940e-01, time/batch = 16.6431s	
10099/33150 (epoch 15.232), train_loss = 1.14219528, grad/param norm = 1.7965e-01, time/batch = 17.3716s	
10100/33150 (epoch 15.234), train_loss = 1.10592513, grad/param norm = 1.7085e-01, time/batch = 17.7169s	
10101/33150 (epoch 15.235), train_loss = 1.13907007, grad/param norm = 1.8413e-01, time/batch = 18.7225s	
10102/33150 (epoch 15.237), train_loss = 1.09459894, grad/param norm = 2.0345e-01, time/batch = 17.8018s	
10103/33150 (epoch 15.238), train_loss = 1.20361897, grad/param norm = 2.0087e-01, time/batch = 16.8152s	
10104/33150 (epoch 15.240), train_loss = 1.16406297, grad/param norm = 1.6553e-01, time/batch = 16.4888s	
10105/33150 (epoch 15.241), train_loss = 1.26511414, grad/param norm = 1.7159e-01, time/batch = 15.6167s	
10106/33150 (epoch 15.243), train_loss = 1.19147049, grad/param norm = 1.6221e-01, time/batch = 18.9669s	
10107/33150 (epoch 15.244), train_loss = 1.08331802, grad/param norm = 1.3871e-01, time/batch = 18.2032s	
10108/33150 (epoch 15.246), train_loss = 1.15892457, grad/param norm = 1.4748e-01, time/batch = 18.4711s	
10109/33150 (epoch 15.247), train_loss = 1.04256112, grad/param norm = 1.5625e-01, time/batch = 15.4669s	
10110/33150 (epoch 15.249), train_loss = 1.20512133, grad/param norm = 1.5712e-01, time/batch = 18.3194s	
10111/33150 (epoch 15.250), train_loss = 1.15595905, grad/param norm = 1.3244e-01, time/batch = 19.0550s	
10112/33150 (epoch 15.252), train_loss = 1.16190736, grad/param norm = 1.2963e-01, time/batch = 16.1469s	
10113/33150 (epoch 15.253), train_loss = 1.14849232, grad/param norm = 1.5415e-01, time/batch = 18.8109s	
10114/33150 (epoch 15.255), train_loss = 1.09216029, grad/param norm = 1.3403e-01, time/batch = 17.7346s	
10115/33150 (epoch 15.256), train_loss = 1.15361409, grad/param norm = 1.4531e-01, time/batch = 17.1968s	
10116/33150 (epoch 15.258), train_loss = 1.05663399, grad/param norm = 1.6478e-01, time/batch = 17.3794s	
10117/33150 (epoch 15.259), train_loss = 0.94640003, grad/param norm = 1.5103e-01, time/batch = 18.3938s	
10118/33150 (epoch 15.261), train_loss = 0.96420609, grad/param norm = 1.5509e-01, time/batch = 17.7273s	
10119/33150 (epoch 15.262), train_loss = 1.16825066, grad/param norm = 1.6778e-01, time/batch = 16.5588s	
10120/33150 (epoch 15.264), train_loss = 0.88173979, grad/param norm = 1.3771e-01, time/batch = 18.4802s	
10121/33150 (epoch 15.265), train_loss = 1.16490511, grad/param norm = 1.5765e-01, time/batch = 16.3192s	
10122/33150 (epoch 15.267), train_loss = 1.19769414, grad/param norm = 1.7453e-01, time/batch = 16.3919s	
10123/33150 (epoch 15.268), train_loss = 1.18362696, grad/param norm = 1.5673e-01, time/batch = 16.3225s	
10124/33150 (epoch 15.270), train_loss = 1.30815809, grad/param norm = 1.7026e-01, time/batch = 18.5438s	
10125/33150 (epoch 15.271), train_loss = 1.25822429, grad/param norm = 1.5954e-01, time/batch = 17.8099s	
10126/33150 (epoch 15.273), train_loss = 1.24658550, grad/param norm = 1.5662e-01, time/batch = 16.0632s	
10127/33150 (epoch 15.275), train_loss = 1.25345419, grad/param norm = 1.5731e-01, time/batch = 15.6094s	
10128/33150 (epoch 15.276), train_loss = 1.11237463, grad/param norm = 1.5549e-01, time/batch = 18.2103s	
10129/33150 (epoch 15.278), train_loss = 1.17297220, grad/param norm = 1.5082e-01, time/batch = 16.9554s	
10130/33150 (epoch 15.279), train_loss = 1.14143313, grad/param norm = 1.4264e-01, time/batch = 16.9751s	
10131/33150 (epoch 15.281), train_loss = 1.16276488, grad/param norm = 1.5483e-01, time/batch = 19.2170s	
10132/33150 (epoch 15.282), train_loss = 1.12269001, grad/param norm = 1.4548e-01, time/batch = 17.8833s	
10133/33150 (epoch 15.284), train_loss = 1.04399518, grad/param norm = 1.3340e-01, time/batch = 16.6985s	
10134/33150 (epoch 15.285), train_loss = 1.13369208, grad/param norm = 1.3808e-01, time/batch = 16.8855s	
10135/33150 (epoch 15.287), train_loss = 1.04322466, grad/param norm = 1.3973e-01, time/batch = 20.0507s	
10136/33150 (epoch 15.288), train_loss = 1.27237332, grad/param norm = 1.5773e-01, time/batch = 15.4030s	
10137/33150 (epoch 15.290), train_loss = 0.95973479, grad/param norm = 1.4858e-01, time/batch = 18.5548s	
10138/33150 (epoch 15.291), train_loss = 0.94659910, grad/param norm = 1.3742e-01, time/batch = 16.8897s	
10139/33150 (epoch 15.293), train_loss = 1.19254832, grad/param norm = 1.5088e-01, time/batch = 16.9659s	
10140/33150 (epoch 15.294), train_loss = 0.83723282, grad/param norm = 1.3895e-01, time/batch = 15.9723s	
10141/33150 (epoch 15.296), train_loss = 1.08854169, grad/param norm = 1.5405e-01, time/batch = 18.0612s	
10142/33150 (epoch 15.297), train_loss = 1.03762619, grad/param norm = 1.4237e-01, time/batch = 17.9105s	
10143/33150 (epoch 15.299), train_loss = 1.06459217, grad/param norm = 1.7450e-01, time/batch = 15.7372s	
10144/33150 (epoch 15.300), train_loss = 1.03724300, grad/param norm = 1.3254e-01, time/batch = 18.6475s	
10145/33150 (epoch 15.302), train_loss = 1.05488510, grad/param norm = 1.4236e-01, time/batch = 17.3117s	
10146/33150 (epoch 15.303), train_loss = 1.08929333, grad/param norm = 1.6537e-01, time/batch = 17.9667s	
10147/33150 (epoch 15.305), train_loss = 1.16535368, grad/param norm = 1.4907e-01, time/batch = 16.5570s	
10148/33150 (epoch 15.306), train_loss = 1.16535461, grad/param norm = 1.8206e-01, time/batch = 19.8780s	
10149/33150 (epoch 15.308), train_loss = 1.34944722, grad/param norm = 1.5833e-01, time/batch = 18.8826s	
10150/33150 (epoch 15.309), train_loss = 0.94706907, grad/param norm = 1.3016e-01, time/batch = 17.1208s	
10151/33150 (epoch 15.311), train_loss = 1.07685352, grad/param norm = 1.5348e-01, time/batch = 16.6218s	
10152/33150 (epoch 15.312), train_loss = 0.88564999, grad/param norm = 1.4399e-01, time/batch = 18.7192s	
10153/33150 (epoch 15.314), train_loss = 1.07274318, grad/param norm = 1.4608e-01, time/batch = 18.2846s	
10154/33150 (epoch 15.315), train_loss = 1.15013772, grad/param norm = 1.5310e-01, time/batch = 18.9766s	
10155/33150 (epoch 15.317), train_loss = 0.87260485, grad/param norm = 1.2438e-01, time/batch = 16.6547s	
10156/33150 (epoch 15.318), train_loss = 0.99747016, grad/param norm = 1.3705e-01, time/batch = 16.7198s	
10157/33150 (epoch 15.320), train_loss = 0.94221100, grad/param norm = 1.3283e-01, time/batch = 17.9747s	
10158/33150 (epoch 15.321), train_loss = 1.04395024, grad/param norm = 1.4067e-01, time/batch = 17.7864s	
10159/33150 (epoch 15.323), train_loss = 1.11066910, grad/param norm = 1.5277e-01, time/batch = 18.0338s	
10160/33150 (epoch 15.324), train_loss = 1.19063295, grad/param norm = 1.7177e-01, time/batch = 16.9655s	
10161/33150 (epoch 15.326), train_loss = 1.10203837, grad/param norm = 1.3754e-01, time/batch = 18.5518s	
10162/33150 (epoch 15.327), train_loss = 1.22881138, grad/param norm = 1.4690e-01, time/batch = 20.2114s	
10163/33150 (epoch 15.329), train_loss = 1.14751459, grad/param norm = 1.4733e-01, time/batch = 16.7156s	
10164/33150 (epoch 15.330), train_loss = 1.11058213, grad/param norm = 1.6198e-01, time/batch = 17.7158s	
10165/33150 (epoch 15.332), train_loss = 1.08692148, grad/param norm = 1.3356e-01, time/batch = 18.2963s	
10166/33150 (epoch 15.333), train_loss = 1.13146220, grad/param norm = 1.3920e-01, time/batch = 16.6198s	
10167/33150 (epoch 15.335), train_loss = 1.04632853, grad/param norm = 1.4650e-01, time/batch = 16.6569s	
10168/33150 (epoch 15.336), train_loss = 1.01869364, grad/param norm = 1.5591e-01, time/batch = 15.7981s	
10169/33150 (epoch 15.338), train_loss = 0.90837910, grad/param norm = 1.3822e-01, time/batch = 17.4605s	
10170/33150 (epoch 15.339), train_loss = 1.20636456, grad/param norm = 1.5730e-01, time/batch = 16.3087s	
10171/33150 (epoch 15.341), train_loss = 1.21871099, grad/param norm = 1.8501e-01, time/batch = 17.9855s	
10172/33150 (epoch 15.342), train_loss = 0.97631464, grad/param norm = 1.4944e-01, time/batch = 18.8695s	
10173/33150 (epoch 15.344), train_loss = 1.11928741, grad/param norm = 1.5571e-01, time/batch = 18.0573s	
10174/33150 (epoch 15.345), train_loss = 1.05537083, grad/param norm = 1.3748e-01, time/batch = 17.5560s	
10175/33150 (epoch 15.347), train_loss = 0.88280990, grad/param norm = 1.2405e-01, time/batch = 17.5658s	
10176/33150 (epoch 15.348), train_loss = 1.12070297, grad/param norm = 1.5051e-01, time/batch = 17.2150s	
10177/33150 (epoch 15.350), train_loss = 1.03524877, grad/param norm = 1.6100e-01, time/batch = 16.2253s	
10178/33150 (epoch 15.351), train_loss = 1.18346519, grad/param norm = 1.6579e-01, time/batch = 18.3175s	
10179/33150 (epoch 15.353), train_loss = 1.16991617, grad/param norm = 1.6059e-01, time/batch = 17.7091s	
10180/33150 (epoch 15.354), train_loss = 1.37100959, grad/param norm = 1.6506e-01, time/batch = 16.8208s	
10181/33150 (epoch 15.356), train_loss = 1.23123519, grad/param norm = 1.7456e-01, time/batch = 16.7273s	
10182/33150 (epoch 15.357), train_loss = 1.20135603, grad/param norm = 1.6029e-01, time/batch = 18.8086s	
10183/33150 (epoch 15.359), train_loss = 1.13815981, grad/param norm = 1.4708e-01, time/batch = 17.2933s	
10184/33150 (epoch 15.360), train_loss = 1.17559839, grad/param norm = 1.6591e-01, time/batch = 16.0535s	
10185/33150 (epoch 15.362), train_loss = 1.19900422, grad/param norm = 1.4947e-01, time/batch = 15.6147s	
10186/33150 (epoch 15.363), train_loss = 1.12074022, grad/param norm = 1.4242e-01, time/batch = 19.2250s	
10187/33150 (epoch 15.365), train_loss = 1.09742007, grad/param norm = 1.3717e-01, time/batch = 15.8055s	
10188/33150 (epoch 15.367), train_loss = 1.01612304, grad/param norm = 1.4170e-01, time/batch = 18.1344s	
10189/33150 (epoch 15.368), train_loss = 1.09079205, grad/param norm = 1.5903e-01, time/batch = 19.0586s	
10190/33150 (epoch 15.370), train_loss = 1.13888411, grad/param norm = 1.7466e-01, time/batch = 17.1899s	
10191/33150 (epoch 15.371), train_loss = 0.98625482, grad/param norm = 1.3772e-01, time/batch = 16.3789s	
10192/33150 (epoch 15.373), train_loss = 1.15269565, grad/param norm = 1.6107e-01, time/batch = 19.0544s	
10193/33150 (epoch 15.374), train_loss = 1.06442745, grad/param norm = 1.3788e-01, time/batch = 19.1169s	
10194/33150 (epoch 15.376), train_loss = 1.22605243, grad/param norm = 1.5483e-01, time/batch = 17.2086s	
10195/33150 (epoch 15.377), train_loss = 1.04246111, grad/param norm = 1.5882e-01, time/batch = 17.5680s	
10196/33150 (epoch 15.379), train_loss = 1.19949258, grad/param norm = 1.6221e-01, time/batch = 18.1327s	
10197/33150 (epoch 15.380), train_loss = 1.18482569, grad/param norm = 1.3671e-01, time/batch = 15.7209s	
10198/33150 (epoch 15.382), train_loss = 1.02972887, grad/param norm = 1.5397e-01, time/batch = 16.9737s	
10199/33150 (epoch 15.383), train_loss = 0.99891945, grad/param norm = 1.3852e-01, time/batch = 18.1436s	
10200/33150 (epoch 15.385), train_loss = 1.09595580, grad/param norm = 1.4393e-01, time/batch = 18.2997s	
10201/33150 (epoch 15.386), train_loss = 0.95236781, grad/param norm = 1.2431e-01, time/batch = 30.2544s	
10202/33150 (epoch 15.388), train_loss = 1.07515071, grad/param norm = 1.4760e-01, time/batch = 17.4676s	
10203/33150 (epoch 15.389), train_loss = 1.03759093, grad/param norm = 1.3273e-01, time/batch = 15.2853s	
10204/33150 (epoch 15.391), train_loss = 1.27130226, grad/param norm = 1.5902e-01, time/batch = 15.2892s	
10205/33150 (epoch 15.392), train_loss = 1.04390494, grad/param norm = 1.3429e-01, time/batch = 15.4594s	
10206/33150 (epoch 15.394), train_loss = 0.96353295, grad/param norm = 1.2160e-01, time/batch = 15.4719s	
10207/33150 (epoch 15.395), train_loss = 0.97887588, grad/param norm = 1.5167e-01, time/batch = 15.9586s	
10208/33150 (epoch 15.397), train_loss = 0.80532687, grad/param norm = 1.3495e-01, time/batch = 16.4861s	
10209/33150 (epoch 15.398), train_loss = 1.11255218, grad/param norm = 1.6421e-01, time/batch = 15.8724s	
10210/33150 (epoch 15.400), train_loss = 1.01470767, grad/param norm = 1.2421e-01, time/batch = 18.1437s	
10211/33150 (epoch 15.401), train_loss = 0.91401486, grad/param norm = 1.2937e-01, time/batch = 15.8823s	
10212/33150 (epoch 15.403), train_loss = 0.99084480, grad/param norm = 1.2956e-01, time/batch = 18.6382s	
10213/33150 (epoch 15.404), train_loss = 1.10084746, grad/param norm = 1.5213e-01, time/batch = 18.4608s	
10214/33150 (epoch 15.406), train_loss = 0.99777337, grad/param norm = 1.1808e-01, time/batch = 16.6078s	
10215/33150 (epoch 15.407), train_loss = 0.95918623, grad/param norm = 1.3876e-01, time/batch = 18.9747s	
10216/33150 (epoch 15.409), train_loss = 0.88580326, grad/param norm = 1.3592e-01, time/batch = 16.7237s	
10217/33150 (epoch 15.410), train_loss = 1.11268735, grad/param norm = 1.5225e-01, time/batch = 17.8728s	
10218/33150 (epoch 15.412), train_loss = 1.11877422, grad/param norm = 1.4833e-01, time/batch = 16.3268s	
10219/33150 (epoch 15.413), train_loss = 1.03228771, grad/param norm = 1.4766e-01, time/batch = 16.3219s	
10220/33150 (epoch 15.415), train_loss = 1.18190575, grad/param norm = 1.4507e-01, time/batch = 15.9692s	
10221/33150 (epoch 15.416), train_loss = 1.01493951, grad/param norm = 1.3397e-01, time/batch = 16.1571s	
10222/33150 (epoch 15.418), train_loss = 1.25100837, grad/param norm = 1.9894e-01, time/batch = 15.8891s	
10223/33150 (epoch 15.419), train_loss = 1.03368685, grad/param norm = 1.4766e-01, time/batch = 16.8723s	
10224/33150 (epoch 15.421), train_loss = 1.11686780, grad/param norm = 1.6413e-01, time/batch = 16.9148s	
10225/33150 (epoch 15.422), train_loss = 1.04078358, grad/param norm = 1.3873e-01, time/batch = 15.5486s	
10226/33150 (epoch 15.424), train_loss = 1.05149640, grad/param norm = 1.5262e-01, time/batch = 17.8860s	
10227/33150 (epoch 15.425), train_loss = 1.10473752, grad/param norm = 1.4188e-01, time/batch = 15.6604s	
10228/33150 (epoch 15.427), train_loss = 1.08035694, grad/param norm = 1.3732e-01, time/batch = 16.7215s	
10229/33150 (epoch 15.428), train_loss = 1.10045009, grad/param norm = 1.5242e-01, time/batch = 15.4623s	
10230/33150 (epoch 15.430), train_loss = 1.11500725, grad/param norm = 1.5796e-01, time/batch = 18.3054s	
10231/33150 (epoch 15.431), train_loss = 1.19506503, grad/param norm = 1.8903e-01, time/batch = 16.8028s	
10232/33150 (epoch 15.433), train_loss = 1.06149808, grad/param norm = 1.3795e-01, time/batch = 16.4656s	
10233/33150 (epoch 15.434), train_loss = 0.97438804, grad/param norm = 1.4944e-01, time/batch = 17.1494s	
10234/33150 (epoch 15.436), train_loss = 1.00354398, grad/param norm = 1.6161e-01, time/batch = 18.3748s	
10235/33150 (epoch 15.437), train_loss = 1.09497565, grad/param norm = 1.7751e-01, time/batch = 15.8039s	
10236/33150 (epoch 15.439), train_loss = 1.20218769, grad/param norm = 1.5713e-01, time/batch = 17.8864s	
10237/33150 (epoch 15.440), train_loss = 1.18909769, grad/param norm = 1.6498e-01, time/batch = 15.2084s	
10238/33150 (epoch 15.442), train_loss = 0.95784061, grad/param norm = 1.4408e-01, time/batch = 16.3905s	
10239/33150 (epoch 15.443), train_loss = 1.17677104, grad/param norm = 1.4802e-01, time/batch = 15.8089s	
10240/33150 (epoch 15.445), train_loss = 1.09822311, grad/param norm = 1.5927e-01, time/batch = 17.5609s	
10241/33150 (epoch 15.446), train_loss = 1.10469231, grad/param norm = 1.7836e-01, time/batch = 16.1716s	
10242/33150 (epoch 15.448), train_loss = 1.17458844, grad/param norm = 1.5396e-01, time/batch = 17.7394s	
10243/33150 (epoch 15.449), train_loss = 1.09370249, grad/param norm = 1.3357e-01, time/batch = 16.6399s	
10244/33150 (epoch 15.451), train_loss = 1.17829024, grad/param norm = 1.7262e-01, time/batch = 17.8889s	
10245/33150 (epoch 15.452), train_loss = 1.34238273, grad/param norm = 1.6185e-01, time/batch = 18.4014s	
10246/33150 (epoch 15.454), train_loss = 1.07469548, grad/param norm = 1.4631e-01, time/batch = 16.2018s	
10247/33150 (epoch 15.456), train_loss = 0.94185507, grad/param norm = 1.3418e-01, time/batch = 18.0648s	
10248/33150 (epoch 15.457), train_loss = 1.11408422, grad/param norm = 1.5636e-01, time/batch = 16.9018s	
10249/33150 (epoch 15.459), train_loss = 1.24475890, grad/param norm = 2.1665e-01, time/batch = 15.9500s	
10250/33150 (epoch 15.460), train_loss = 1.13282909, grad/param norm = 1.3891e-01, time/batch = 15.7272s	
10251/33150 (epoch 15.462), train_loss = 1.20609976, grad/param norm = 1.8749e-01, time/batch = 17.8960s	
10252/33150 (epoch 15.463), train_loss = 1.40555527, grad/param norm = 2.2000e-01, time/batch = 16.2173s	
10253/33150 (epoch 15.465), train_loss = 1.04858644, grad/param norm = 1.3926e-01, time/batch = 16.7936s	
10254/33150 (epoch 15.466), train_loss = 1.00893557, grad/param norm = 1.3043e-01, time/batch = 17.4873s	
10255/33150 (epoch 15.468), train_loss = 1.37741648, grad/param norm = 1.6523e-01, time/batch = 18.2310s	
10256/33150 (epoch 15.469), train_loss = 1.10490581, grad/param norm = 1.6435e-01, time/batch = 16.8129s	
10257/33150 (epoch 15.471), train_loss = 1.04869725, grad/param norm = 1.4295e-01, time/batch = 16.4712s	
10258/33150 (epoch 15.472), train_loss = 1.08665285, grad/param norm = 1.3941e-01, time/batch = 17.2066s	
10259/33150 (epoch 15.474), train_loss = 1.21042073, grad/param norm = 1.8643e-01, time/batch = 18.3188s	
10260/33150 (epoch 15.475), train_loss = 1.36596865, grad/param norm = 1.6512e-01, time/batch = 16.7878s	
10261/33150 (epoch 15.477), train_loss = 1.19213695, grad/param norm = 1.6107e-01, time/batch = 19.0567s	
10262/33150 (epoch 15.478), train_loss = 1.20708662, grad/param norm = 1.4372e-01, time/batch = 16.0164s	
10263/33150 (epoch 15.480), train_loss = 1.04392742, grad/param norm = 1.5507e-01, time/batch = 18.6216s	
10264/33150 (epoch 15.481), train_loss = 0.93897431, grad/param norm = 1.4528e-01, time/batch = 16.5515s	
10265/33150 (epoch 15.483), train_loss = 1.05145845, grad/param norm = 1.4825e-01, time/batch = 17.6356s	
10266/33150 (epoch 15.484), train_loss = 1.05463651, grad/param norm = 1.5296e-01, time/batch = 17.4020s	
10267/33150 (epoch 15.486), train_loss = 1.06550495, grad/param norm = 1.6656e-01, time/batch = 17.2020s	
10268/33150 (epoch 15.487), train_loss = 1.14004246, grad/param norm = 1.6275e-01, time/batch = 19.4647s	
10269/33150 (epoch 15.489), train_loss = 1.12114731, grad/param norm = 1.6179e-01, time/batch = 17.4713s	
10270/33150 (epoch 15.490), train_loss = 0.93819607, grad/param norm = 1.4162e-01, time/batch = 16.2272s	
10271/33150 (epoch 15.492), train_loss = 1.03886116, grad/param norm = 1.5895e-01, time/batch = 17.5771s	
10272/33150 (epoch 15.493), train_loss = 1.21123534, grad/param norm = 1.6729e-01, time/batch = 18.0438s	
10273/33150 (epoch 15.495), train_loss = 1.22413476, grad/param norm = 1.5492e-01, time/batch = 16.1410s	
10274/33150 (epoch 15.496), train_loss = 1.01826888, grad/param norm = 1.4647e-01, time/batch = 16.2035s	
10275/33150 (epoch 15.498), train_loss = 1.22571134, grad/param norm = 1.7286e-01, time/batch = 17.7211s	
10276/33150 (epoch 15.499), train_loss = 1.24365861, grad/param norm = 1.5436e-01, time/batch = 16.3927s	
10277/33150 (epoch 15.501), train_loss = 1.14423450, grad/param norm = 1.5449e-01, time/batch = 16.5589s	
10278/33150 (epoch 15.502), train_loss = 1.26604425, grad/param norm = 1.6559e-01, time/batch = 18.6534s	
10279/33150 (epoch 15.504), train_loss = 1.17013964, grad/param norm = 1.6054e-01, time/batch = 17.8211s	
10280/33150 (epoch 15.505), train_loss = 1.32829138, grad/param norm = 1.8719e-01, time/batch = 18.8114s	
10281/33150 (epoch 15.507), train_loss = 1.04179268, grad/param norm = 1.4418e-01, time/batch = 16.2186s	
10282/33150 (epoch 15.508), train_loss = 1.07165653, grad/param norm = 1.4901e-01, time/batch = 17.8963s	
10283/33150 (epoch 15.510), train_loss = 1.12556712, grad/param norm = 1.5761e-01, time/batch = 16.2963s	
10284/33150 (epoch 15.511), train_loss = 1.28000158, grad/param norm = 1.6521e-01, time/batch = 17.2870s	
10285/33150 (epoch 15.513), train_loss = 1.12912357, grad/param norm = 1.6214e-01, time/batch = 18.8686s	
10286/33150 (epoch 15.514), train_loss = 0.91735018, grad/param norm = 1.4128e-01, time/batch = 17.2847s	
10287/33150 (epoch 15.516), train_loss = 1.22143096, grad/param norm = 1.7627e-01, time/batch = 17.5525s	
10288/33150 (epoch 15.517), train_loss = 1.21405924, grad/param norm = 1.5125e-01, time/batch = 17.9739s	
10289/33150 (epoch 15.519), train_loss = 1.02458532, grad/param norm = 1.4334e-01, time/batch = 17.8896s	
10290/33150 (epoch 15.520), train_loss = 1.12928649, grad/param norm = 1.4042e-01, time/batch = 17.7148s	
10291/33150 (epoch 15.522), train_loss = 1.26611035, grad/param norm = 1.8973e-01, time/batch = 16.5558s	
10292/33150 (epoch 15.523), train_loss = 1.02644213, grad/param norm = 1.4813e-01, time/batch = 18.1459s	
10293/33150 (epoch 15.525), train_loss = 1.16716696, grad/param norm = 1.6196e-01, time/batch = 18.4001s	
10294/33150 (epoch 15.526), train_loss = 1.02527364, grad/param norm = 1.3950e-01, time/batch = 16.5354s	
10295/33150 (epoch 15.528), train_loss = 1.15310582, grad/param norm = 1.5769e-01, time/batch = 17.2362s	
10296/33150 (epoch 15.529), train_loss = 1.11297166, grad/param norm = 1.4896e-01, time/batch = 17.8813s	
10297/33150 (epoch 15.531), train_loss = 0.94810111, grad/param norm = 1.4920e-01, time/batch = 18.3893s	
10298/33150 (epoch 15.532), train_loss = 1.12945830, grad/param norm = 1.5152e-01, time/batch = 16.3815s	
10299/33150 (epoch 15.534), train_loss = 1.06384025, grad/param norm = 1.3073e-01, time/batch = 18.3994s	
10300/33150 (epoch 15.535), train_loss = 1.01427169, grad/param norm = 1.5356e-01, time/batch = 19.0548s	
10301/33150 (epoch 15.537), train_loss = 1.20789851, grad/param norm = 1.5641e-01, time/batch = 15.8855s	
10302/33150 (epoch 15.538), train_loss = 1.05785255, grad/param norm = 1.4681e-01, time/batch = 16.1521s	
10303/33150 (epoch 15.540), train_loss = 0.94599445, grad/param norm = 1.4137e-01, time/batch = 18.1463s	
10304/33150 (epoch 15.541), train_loss = 1.19314934, grad/param norm = 1.6031e-01, time/batch = 15.2300s	
10305/33150 (epoch 15.543), train_loss = 1.14786639, grad/param norm = 1.4754e-01, time/batch = 15.3907s	
10306/33150 (epoch 15.544), train_loss = 1.12835091, grad/param norm = 1.4340e-01, time/batch = 17.4799s	
10307/33150 (epoch 15.546), train_loss = 1.21031085, grad/param norm = 1.6156e-01, time/batch = 17.2283s	
10308/33150 (epoch 15.548), train_loss = 1.13875889, grad/param norm = 1.5762e-01, time/batch = 16.2895s	
10309/33150 (epoch 15.549), train_loss = 1.05576154, grad/param norm = 1.5297e-01, time/batch = 19.5431s	
10310/33150 (epoch 15.551), train_loss = 1.02428821, grad/param norm = 1.4431e-01, time/batch = 16.9063s	
10311/33150 (epoch 15.552), train_loss = 0.89215155, grad/param norm = 1.2218e-01, time/batch = 17.1334s	
10312/33150 (epoch 15.554), train_loss = 1.17216260, grad/param norm = 1.5061e-01, time/batch = 15.5498s	
10313/33150 (epoch 15.555), train_loss = 1.27321416, grad/param norm = 1.5794e-01, time/batch = 17.9836s	
10314/33150 (epoch 15.557), train_loss = 0.92166213, grad/param norm = 1.3998e-01, time/batch = 19.7942s	
10315/33150 (epoch 15.558), train_loss = 1.17890559, grad/param norm = 1.7120e-01, time/batch = 16.2255s	
10316/33150 (epoch 15.560), train_loss = 1.04799860, grad/param norm = 1.5052e-01, time/batch = 18.1301s	
10317/33150 (epoch 15.561), train_loss = 0.95028298, grad/param norm = 1.5043e-01, time/batch = 16.0450s	
10318/33150 (epoch 15.563), train_loss = 1.17718363, grad/param norm = 1.7795e-01, time/batch = 18.3726s	
10319/33150 (epoch 15.564), train_loss = 1.28465207, grad/param norm = 1.5946e-01, time/batch = 17.5538s	
10320/33150 (epoch 15.566), train_loss = 1.09654509, grad/param norm = 1.4990e-01, time/batch = 19.3787s	
10321/33150 (epoch 15.567), train_loss = 0.99621653, grad/param norm = 1.3534e-01, time/batch = 18.5328s	
10322/33150 (epoch 15.569), train_loss = 1.12997071, grad/param norm = 1.5185e-01, time/batch = 16.6208s	
10323/33150 (epoch 15.570), train_loss = 1.16783940, grad/param norm = 1.5188e-01, time/batch = 18.0462s	
10324/33150 (epoch 15.572), train_loss = 1.02867575, grad/param norm = 1.4672e-01, time/batch = 18.7159s	
10325/33150 (epoch 15.573), train_loss = 0.89369707, grad/param norm = 1.2696e-01, time/batch = 16.5448s	
10326/33150 (epoch 15.575), train_loss = 1.04603743, grad/param norm = 1.3886e-01, time/batch = 17.4829s	
10327/33150 (epoch 15.576), train_loss = 0.95182071, grad/param norm = 1.3214e-01, time/batch = 17.0604s	
10328/33150 (epoch 15.578), train_loss = 1.01433871, grad/param norm = 1.3263e-01, time/batch = 17.3902s	
10329/33150 (epoch 15.579), train_loss = 0.93720541, grad/param norm = 1.3672e-01, time/batch = 16.1446s	
10330/33150 (epoch 15.581), train_loss = 1.00662767, grad/param norm = 1.4664e-01, time/batch = 16.3138s	
10331/33150 (epoch 15.582), train_loss = 1.18170929, grad/param norm = 1.4471e-01, time/batch = 18.4818s	
10332/33150 (epoch 15.584), train_loss = 1.18122953, grad/param norm = 1.5354e-01, time/batch = 15.3808s	
10333/33150 (epoch 15.585), train_loss = 1.10560856, grad/param norm = 1.5001e-01, time/batch = 17.4603s	
10334/33150 (epoch 15.587), train_loss = 1.14215306, grad/param norm = 1.4862e-01, time/batch = 17.7114s	
10335/33150 (epoch 15.588), train_loss = 1.01125511, grad/param norm = 1.4583e-01, time/batch = 17.3826s	
10336/33150 (epoch 15.590), train_loss = 1.10376868, grad/param norm = 1.4838e-01, time/batch = 18.1322s	
10337/33150 (epoch 15.591), train_loss = 1.07855492, grad/param norm = 1.4027e-01, time/batch = 18.8658s	
10338/33150 (epoch 15.593), train_loss = 1.16450437, grad/param norm = 1.5389e-01, time/batch = 19.3050s	
10339/33150 (epoch 15.594), train_loss = 1.10265283, grad/param norm = 1.5307e-01, time/batch = 15.4390s	
10340/33150 (epoch 15.596), train_loss = 1.02951319, grad/param norm = 1.4782e-01, time/batch = 17.4013s	
10341/33150 (epoch 15.597), train_loss = 0.98432228, grad/param norm = 1.6949e-01, time/batch = 16.8160s	
10342/33150 (epoch 15.599), train_loss = 1.27064622, grad/param norm = 1.7284e-01, time/batch = 18.0555s	
10343/33150 (epoch 15.600), train_loss = 1.11042362, grad/param norm = 1.9273e-01, time/batch = 17.1247s	
10344/33150 (epoch 15.602), train_loss = 1.03825566, grad/param norm = 1.4602e-01, time/batch = 18.2179s	
10345/33150 (epoch 15.603), train_loss = 1.16596869, grad/param norm = 1.5318e-01, time/batch = 19.2145s	
10346/33150 (epoch 15.605), train_loss = 0.98959054, grad/param norm = 1.5638e-01, time/batch = 15.6407s	
10347/33150 (epoch 15.606), train_loss = 1.13754955, grad/param norm = 1.8174e-01, time/batch = 17.8957s	
10348/33150 (epoch 15.608), train_loss = 1.16891058, grad/param norm = 1.5752e-01, time/batch = 17.3246s	
10349/33150 (epoch 15.609), train_loss = 1.08959963, grad/param norm = 1.6040e-01, time/batch = 15.5653s	
10350/33150 (epoch 15.611), train_loss = 0.96713666, grad/param norm = 1.5945e-01, time/batch = 16.7254s	
10351/33150 (epoch 15.612), train_loss = 1.11199743, grad/param norm = 1.6833e-01, time/batch = 16.4917s	
10352/33150 (epoch 15.614), train_loss = 0.93729335, grad/param norm = 1.4412e-01, time/batch = 18.8090s	
10353/33150 (epoch 15.615), train_loss = 0.99703056, grad/param norm = 1.3999e-01, time/batch = 16.4682s	
10354/33150 (epoch 15.617), train_loss = 1.10111552, grad/param norm = 1.5708e-01, time/batch = 16.3103s	
10355/33150 (epoch 15.618), train_loss = 1.10672287, grad/param norm = 1.5912e-01, time/batch = 18.8032s	
10356/33150 (epoch 15.620), train_loss = 1.03345960, grad/param norm = 1.5537e-01, time/batch = 16.1478s	
10357/33150 (epoch 15.621), train_loss = 1.08109240, grad/param norm = 1.4116e-01, time/batch = 18.0633s	
10358/33150 (epoch 15.623), train_loss = 1.14564164, grad/param norm = 1.4603e-01, time/batch = 16.2170s	
10359/33150 (epoch 15.624), train_loss = 1.03058774, grad/param norm = 1.5285e-01, time/batch = 16.0520s	
10360/33150 (epoch 15.626), train_loss = 1.03492857, grad/param norm = 1.4298e-01, time/batch = 15.3556s	
10361/33150 (epoch 15.627), train_loss = 0.97093103, grad/param norm = 1.4672e-01, time/batch = 15.2418s	
10362/33150 (epoch 15.629), train_loss = 0.96117779, grad/param norm = 1.4173e-01, time/batch = 15.0604s	
10363/33150 (epoch 15.630), train_loss = 1.01801679, grad/param norm = 1.3066e-01, time/batch = 14.8378s	
10364/33150 (epoch 15.632), train_loss = 0.93155391, grad/param norm = 1.4262e-01, time/batch = 15.4805s	
10365/33150 (epoch 15.633), train_loss = 0.94337243, grad/param norm = 1.6669e-01, time/batch = 17.5263s	
10366/33150 (epoch 15.635), train_loss = 1.28318698, grad/param norm = 1.6216e-01, time/batch = 16.7169s	
10367/33150 (epoch 15.637), train_loss = 0.90932658, grad/param norm = 1.4584e-01, time/batch = 16.5647s	
10368/33150 (epoch 15.638), train_loss = 1.04778144, grad/param norm = 1.4442e-01, time/batch = 16.8857s	
10369/33150 (epoch 15.640), train_loss = 1.18020651, grad/param norm = 1.5874e-01, time/batch = 16.7083s	
10370/33150 (epoch 15.641), train_loss = 0.97210322, grad/param norm = 1.3940e-01, time/batch = 18.1443s	
10371/33150 (epoch 15.643), train_loss = 1.01551875, grad/param norm = 1.4714e-01, time/batch = 16.2076s	
10372/33150 (epoch 15.644), train_loss = 1.23587796, grad/param norm = 1.5126e-01, time/batch = 19.6264s	
10373/33150 (epoch 15.646), train_loss = 1.02834577, grad/param norm = 1.4711e-01, time/batch = 18.0664s	
10374/33150 (epoch 15.647), train_loss = 1.32165474, grad/param norm = 1.6393e-01, time/batch = 16.3748s	
10375/33150 (epoch 15.649), train_loss = 1.16881028, grad/param norm = 1.6017e-01, time/batch = 15.5623s	
10376/33150 (epoch 15.650), train_loss = 0.95924805, grad/param norm = 1.3461e-01, time/batch = 18.1406s	
10377/33150 (epoch 15.652), train_loss = 1.22170072, grad/param norm = 1.7414e-01, time/batch = 18.2115s	
10378/33150 (epoch 15.653), train_loss = 1.09139348, grad/param norm = 1.3815e-01, time/batch = 17.0523s	
10379/33150 (epoch 15.655), train_loss = 1.15152903, grad/param norm = 1.7871e-01, time/batch = 16.9600s	
10380/33150 (epoch 15.656), train_loss = 1.07122316, grad/param norm = 1.5830e-01, time/batch = 15.3754s	
10381/33150 (epoch 15.658), train_loss = 1.08252777, grad/param norm = 1.7806e-01, time/batch = 16.3169s	
10382/33150 (epoch 15.659), train_loss = 1.38548019, grad/param norm = 2.8147e-01, time/batch = 16.2102s	
10383/33150 (epoch 15.661), train_loss = 1.06716152, grad/param norm = 1.5372e-01, time/batch = 15.9918s	
10384/33150 (epoch 15.662), train_loss = 0.93095700, grad/param norm = 1.4407e-01, time/batch = 18.2142s	
10385/33150 (epoch 15.664), train_loss = 1.21732611, grad/param norm = 1.6562e-01, time/batch = 15.4732s	
10386/33150 (epoch 15.665), train_loss = 1.16545406, grad/param norm = 1.7199e-01, time/batch = 17.3095s	
10387/33150 (epoch 15.667), train_loss = 1.22388009, grad/param norm = 1.8026e-01, time/batch = 17.4796s	
10388/33150 (epoch 15.668), train_loss = 1.17661374, grad/param norm = 1.5713e-01, time/batch = 16.4767s	
10389/33150 (epoch 15.670), train_loss = 1.02137088, grad/param norm = 1.3584e-01, time/batch = 16.8683s	
10390/33150 (epoch 15.671), train_loss = 1.01545169, grad/param norm = 1.4736e-01, time/batch = 17.1273s	
10391/33150 (epoch 15.673), train_loss = 1.19431199, grad/param norm = 1.3482e-01, time/batch = 15.9073s	
10392/33150 (epoch 15.674), train_loss = 1.08091457, grad/param norm = 1.4100e-01, time/batch = 16.4716s	
10393/33150 (epoch 15.676), train_loss = 1.05471599, grad/param norm = 1.4381e-01, time/batch = 17.4025s	
10394/33150 (epoch 15.677), train_loss = 1.32036621, grad/param norm = 1.7697e-01, time/batch = 16.8076s	
10395/33150 (epoch 15.679), train_loss = 1.07005293, grad/param norm = 1.3869e-01, time/batch = 17.6216s	
10396/33150 (epoch 15.680), train_loss = 1.22525392, grad/param norm = 1.4961e-01, time/batch = 17.0292s	
10397/33150 (epoch 15.682), train_loss = 1.03176222, grad/param norm = 1.4809e-01, time/batch = 17.4431s	
10398/33150 (epoch 15.683), train_loss = 0.93661117, grad/param norm = 1.3444e-01, time/batch = 19.0559s	
10399/33150 (epoch 15.685), train_loss = 1.09578075, grad/param norm = 1.6488e-01, time/batch = 16.8870s	
10400/33150 (epoch 15.686), train_loss = 0.94722796, grad/param norm = 1.8616e-01, time/batch = 18.9599s	
10401/33150 (epoch 15.688), train_loss = 1.00359843, grad/param norm = 1.4180e-01, time/batch = 19.9533s	
10402/33150 (epoch 15.689), train_loss = 1.00232837, grad/param norm = 1.3138e-01, time/batch = 15.3101s	
10403/33150 (epoch 15.691), train_loss = 0.90256596, grad/param norm = 1.3038e-01, time/batch = 17.3772s	
10404/33150 (epoch 15.692), train_loss = 0.98200956, grad/param norm = 1.4162e-01, time/batch = 18.7311s	
10405/33150 (epoch 15.694), train_loss = 0.84697604, grad/param norm = 1.1907e-01, time/batch = 17.0565s	
10406/33150 (epoch 15.695), train_loss = 1.00261543, grad/param norm = 1.3884e-01, time/batch = 17.5531s	
10407/33150 (epoch 15.697), train_loss = 0.90744192, grad/param norm = 1.2276e-01, time/batch = 18.1487s	
10408/33150 (epoch 15.698), train_loss = 1.08012260, grad/param norm = 1.5688e-01, time/batch = 18.8037s	
10409/33150 (epoch 15.700), train_loss = 0.80716507, grad/param norm = 1.2569e-01, time/batch = 29.8974s	
10410/33150 (epoch 15.701), train_loss = 0.95343712, grad/param norm = 1.3547e-01, time/batch = 18.5522s	
10411/33150 (epoch 15.703), train_loss = 1.04477399, grad/param norm = 1.3973e-01, time/batch = 17.5534s	
10412/33150 (epoch 15.704), train_loss = 0.90139982, grad/param norm = 1.2271e-01, time/batch = 15.4826s	
10413/33150 (epoch 15.706), train_loss = 1.02193871, grad/param norm = 1.3524e-01, time/batch = 15.6944s	
10414/33150 (epoch 15.707), train_loss = 1.01705415, grad/param norm = 1.5124e-01, time/batch = 16.7928s	
10415/33150 (epoch 15.709), train_loss = 1.06924827, grad/param norm = 1.2917e-01, time/batch = 15.6113s	
10416/33150 (epoch 15.710), train_loss = 1.11694164, grad/param norm = 1.6237e-01, time/batch = 16.2988s	
10417/33150 (epoch 15.712), train_loss = 1.14177519, grad/param norm = 1.4418e-01, time/batch = 16.0450s	
10418/33150 (epoch 15.713), train_loss = 1.12693946, grad/param norm = 1.3917e-01, time/batch = 15.2879s	
10419/33150 (epoch 15.715), train_loss = 1.02498658, grad/param norm = 1.3873e-01, time/batch = 15.3810s	
10420/33150 (epoch 15.716), train_loss = 1.11469431, grad/param norm = 1.4991e-01, time/batch = 15.6535s	
10421/33150 (epoch 15.718), train_loss = 1.08804224, grad/param norm = 1.4361e-01, time/batch = 16.0635s	
10422/33150 (epoch 15.719), train_loss = 1.19832657, grad/param norm = 1.6932e-01, time/batch = 17.8077s	
10423/33150 (epoch 15.721), train_loss = 1.06096824, grad/param norm = 1.5008e-01, time/batch = 16.3069s	
10424/33150 (epoch 15.722), train_loss = 1.11691284, grad/param norm = 1.5000e-01, time/batch = 16.7481s	
10425/33150 (epoch 15.724), train_loss = 1.06362705, grad/param norm = 1.6068e-01, time/batch = 16.9698s	
10426/33150 (epoch 15.725), train_loss = 1.21512533, grad/param norm = 1.8100e-01, time/batch = 16.7200s	
10427/33150 (epoch 15.727), train_loss = 1.10918653, grad/param norm = 1.7210e-01, time/batch = 18.2228s	
10428/33150 (epoch 15.729), train_loss = 1.07739496, grad/param norm = 1.5267e-01, time/batch = 19.3931s	
10429/33150 (epoch 15.730), train_loss = 1.08928448, grad/param norm = 1.4737e-01, time/batch = 17.4689s	
10430/33150 (epoch 15.732), train_loss = 1.18580477, grad/param norm = 1.6280e-01, time/batch = 17.3858s	
10431/33150 (epoch 15.733), train_loss = 0.88270490, grad/param norm = 1.2126e-01, time/batch = 16.9648s	
10432/33150 (epoch 15.735), train_loss = 1.02311091, grad/param norm = 1.3958e-01, time/batch = 17.9653s	
10433/33150 (epoch 15.736), train_loss = 1.03792795, grad/param norm = 1.5053e-01, time/batch = 16.7156s	
10434/33150 (epoch 15.738), train_loss = 1.11231704, grad/param norm = 1.5973e-01, time/batch = 17.4853s	
10435/33150 (epoch 15.739), train_loss = 1.21842475, grad/param norm = 1.6723e-01, time/batch = 18.3176s	
10436/33150 (epoch 15.741), train_loss = 1.19339231, grad/param norm = 1.6133e-01, time/batch = 15.3083s	
10437/33150 (epoch 15.742), train_loss = 0.98744332, grad/param norm = 1.5516e-01, time/batch = 15.2420s	
10438/33150 (epoch 15.744), train_loss = 1.20710667, grad/param norm = 1.6415e-01, time/batch = 18.0601s	
10439/33150 (epoch 15.745), train_loss = 1.02779189, grad/param norm = 1.3187e-01, time/batch = 16.4813s	
10440/33150 (epoch 15.747), train_loss = 0.90712147, grad/param norm = 1.5770e-01, time/batch = 16.6368s	
10441/33150 (epoch 15.748), train_loss = 0.99210866, grad/param norm = 1.3611e-01, time/batch = 18.4681s	
10442/33150 (epoch 15.750), train_loss = 1.15389417, grad/param norm = 1.6364e-01, time/batch = 17.8974s	
10443/33150 (epoch 15.751), train_loss = 1.08843433, grad/param norm = 1.3730e-01, time/batch = 17.7075s	
10444/33150 (epoch 15.753), train_loss = 0.93908607, grad/param norm = 1.4775e-01, time/batch = 16.0726s	
10445/33150 (epoch 15.754), train_loss = 1.31535761, grad/param norm = 1.8494e-01, time/batch = 16.6446s	
10446/33150 (epoch 15.756), train_loss = 1.13097607, grad/param norm = 1.6882e-01, time/batch = 16.5623s	
10447/33150 (epoch 15.757), train_loss = 1.10365263, grad/param norm = 1.6225e-01, time/batch = 16.3936s	
10448/33150 (epoch 15.759), train_loss = 1.24801870, grad/param norm = 1.9422e-01, time/batch = 15.8950s	
10449/33150 (epoch 15.760), train_loss = 1.13162169, grad/param norm = 2.2243e-01, time/batch = 16.9791s	
10450/33150 (epoch 15.762), train_loss = 1.11888448, grad/param norm = 1.7211e-01, time/batch = 17.7195s	
10451/33150 (epoch 15.763), train_loss = 1.12776019, grad/param norm = 1.5113e-01, time/batch = 16.0752s	
10452/33150 (epoch 15.765), train_loss = 1.05169520, grad/param norm = 1.4252e-01, time/batch = 15.8065s	
10453/33150 (epoch 15.766), train_loss = 0.98919568, grad/param norm = 1.3861e-01, time/batch = 18.2353s	
10454/33150 (epoch 15.768), train_loss = 1.02669165, grad/param norm = 1.4199e-01, time/batch = 17.1334s	
10455/33150 (epoch 15.769), train_loss = 1.11363471, grad/param norm = 1.5228e-01, time/batch = 18.0484s	
10456/33150 (epoch 15.771), train_loss = 1.11465449, grad/param norm = 1.6300e-01, time/batch = 18.2389s	
10457/33150 (epoch 15.772), train_loss = 1.15723867, grad/param norm = 1.6962e-01, time/batch = 16.9712s	
10458/33150 (epoch 15.774), train_loss = 1.25763798, grad/param norm = 1.5687e-01, time/batch = 15.4950s	
10459/33150 (epoch 15.775), train_loss = 1.15651338, grad/param norm = 1.9138e-01, time/batch = 18.8168s	
10460/33150 (epoch 15.777), train_loss = 1.17334248, grad/param norm = 1.7061e-01, time/batch = 16.4755s	
10461/33150 (epoch 15.778), train_loss = 1.09205258, grad/param norm = 1.2995e-01, time/batch = 16.3089s	
10462/33150 (epoch 15.780), train_loss = 0.96866296, grad/param norm = 1.4195e-01, time/batch = 19.2878s	
10463/33150 (epoch 15.781), train_loss = 1.07898083, grad/param norm = 1.4024e-01, time/batch = 17.5728s	
10464/33150 (epoch 15.783), train_loss = 1.09969466, grad/param norm = 1.3342e-01, time/batch = 18.2152s	
10465/33150 (epoch 15.784), train_loss = 1.06340732, grad/param norm = 1.6672e-01, time/batch = 18.2091s	
10466/33150 (epoch 15.786), train_loss = 1.05157918, grad/param norm = 1.3903e-01, time/batch = 18.5424s	
10467/33150 (epoch 15.787), train_loss = 1.01412514, grad/param norm = 1.3864e-01, time/batch = 18.0446s	
10468/33150 (epoch 15.789), train_loss = 0.90836655, grad/param norm = 1.3371e-01, time/batch = 16.8683s	
10469/33150 (epoch 15.790), train_loss = 0.92054025, grad/param norm = 1.2155e-01, time/batch = 19.4676s	
10470/33150 (epoch 15.792), train_loss = 1.12370495, grad/param norm = 1.6763e-01, time/batch = 15.6333s	
10471/33150 (epoch 15.793), train_loss = 1.09463937, grad/param norm = 1.5650e-01, time/batch = 16.8860s	
10472/33150 (epoch 15.795), train_loss = 1.01957634, grad/param norm = 1.6218e-01, time/batch = 18.1419s	
10473/33150 (epoch 15.796), train_loss = 1.02773508, grad/param norm = 1.4663e-01, time/batch = 17.0319s	
10474/33150 (epoch 15.798), train_loss = 0.99895555, grad/param norm = 1.2760e-01, time/batch = 17.7938s	
10475/33150 (epoch 15.799), train_loss = 0.91906451, grad/param norm = 1.4244e-01, time/batch = 16.9842s	
10476/33150 (epoch 15.801), train_loss = 1.10613809, grad/param norm = 1.3883e-01, time/batch = 19.1384s	
10477/33150 (epoch 15.802), train_loss = 0.97414479, grad/param norm = 1.4658e-01, time/batch = 20.1275s	
10478/33150 (epoch 15.804), train_loss = 1.02867144, grad/param norm = 1.4108e-01, time/batch = 15.3630s	
10479/33150 (epoch 15.805), train_loss = 1.04058265, grad/param norm = 1.5767e-01, time/batch = 17.4626s	
10480/33150 (epoch 15.807), train_loss = 1.03216805, grad/param norm = 1.3844e-01, time/batch = 19.4714s	
10481/33150 (epoch 15.808), train_loss = 1.17181853, grad/param norm = 1.5780e-01, time/batch = 17.1568s	
10482/33150 (epoch 15.810), train_loss = 1.06113951, grad/param norm = 1.4373e-01, time/batch = 18.6222s	
10483/33150 (epoch 15.811), train_loss = 1.12564300, grad/param norm = 1.6356e-01, time/batch = 16.9598s	
10484/33150 (epoch 15.813), train_loss = 1.04919602, grad/param norm = 1.3097e-01, time/batch = 18.7007s	
10485/33150 (epoch 15.814), train_loss = 1.07800316, grad/param norm = 1.7221e-01, time/batch = 16.8228s	
10486/33150 (epoch 15.816), train_loss = 1.05296908, grad/param norm = 1.5671e-01, time/batch = 19.0542s	
10487/33150 (epoch 15.817), train_loss = 1.13239780, grad/param norm = 1.3914e-01, time/batch = 18.3211s	
10488/33150 (epoch 15.819), train_loss = 1.05448664, grad/param norm = 1.3186e-01, time/batch = 16.3771s	
10489/33150 (epoch 15.821), train_loss = 0.94100873, grad/param norm = 1.2690e-01, time/batch = 18.2035s	
10490/33150 (epoch 15.822), train_loss = 0.99429865, grad/param norm = 1.3889e-01, time/batch = 16.7328s	
10491/33150 (epoch 15.824), train_loss = 1.04584727, grad/param norm = 1.5753e-01, time/batch = 15.7820s	
10492/33150 (epoch 15.825), train_loss = 1.06850414, grad/param norm = 1.5462e-01, time/batch = 15.6644s	
10493/33150 (epoch 15.827), train_loss = 1.12213339, grad/param norm = 1.6153e-01, time/batch = 18.0659s	
10494/33150 (epoch 15.828), train_loss = 0.94594226, grad/param norm = 1.4238e-01, time/batch = 16.4189s	
10495/33150 (epoch 15.830), train_loss = 1.14385048, grad/param norm = 1.5285e-01, time/batch = 14.6690s	
10496/33150 (epoch 15.831), train_loss = 1.00968947, grad/param norm = 1.5798e-01, time/batch = 14.9718s	
10497/33150 (epoch 15.833), train_loss = 0.95720738, grad/param norm = 1.4599e-01, time/batch = 16.3188s	
10498/33150 (epoch 15.834), train_loss = 1.18471312, grad/param norm = 1.6580e-01, time/batch = 17.2445s	
10499/33150 (epoch 15.836), train_loss = 1.17907058, grad/param norm = 1.4849e-01, time/batch = 16.3904s	
10500/33150 (epoch 15.837), train_loss = 1.06168611, grad/param norm = 1.4147e-01, time/batch = 17.9699s	
10501/33150 (epoch 15.839), train_loss = 1.15846561, grad/param norm = 1.7593e-01, time/batch = 16.5590s	
10502/33150 (epoch 15.840), train_loss = 1.13460740, grad/param norm = 1.6200e-01, time/batch = 16.8033s	
10503/33150 (epoch 15.842), train_loss = 1.22506617, grad/param norm = 1.6443e-01, time/batch = 17.5726s	
10504/33150 (epoch 15.843), train_loss = 1.21834399, grad/param norm = 1.7281e-01, time/batch = 16.6425s	
10505/33150 (epoch 15.845), train_loss = 1.03362004, grad/param norm = 1.4211e-01, time/batch = 18.0619s	
10506/33150 (epoch 15.846), train_loss = 1.27684028, grad/param norm = 2.1658e-01, time/batch = 15.9050s	
10507/33150 (epoch 15.848), train_loss = 1.17834787, grad/param norm = 1.5884e-01, time/batch = 17.9795s	
10508/33150 (epoch 15.849), train_loss = 1.17991035, grad/param norm = 1.7691e-01, time/batch = 17.0822s	
10509/33150 (epoch 15.851), train_loss = 1.17989302, grad/param norm = 1.7481e-01, time/batch = 15.6291s	
10510/33150 (epoch 15.852), train_loss = 1.24897723, grad/param norm = 1.5257e-01, time/batch = 18.4035s	
10511/33150 (epoch 15.854), train_loss = 1.09360858, grad/param norm = 1.4454e-01, time/batch = 16.1604s	
10512/33150 (epoch 15.855), train_loss = 0.95015996, grad/param norm = 1.4055e-01, time/batch = 16.8879s	
10513/33150 (epoch 15.857), train_loss = 0.92270513, grad/param norm = 1.3890e-01, time/batch = 15.4598s	
10514/33150 (epoch 15.858), train_loss = 1.02204462, grad/param norm = 1.4281e-01, time/batch = 15.4529s	
10515/33150 (epoch 15.860), train_loss = 0.97491190, grad/param norm = 1.3411e-01, time/batch = 15.7961s	
10516/33150 (epoch 15.861), train_loss = 0.98768627, grad/param norm = 1.4257e-01, time/batch = 15.2899s	
10517/33150 (epoch 15.863), train_loss = 1.10322593, grad/param norm = 1.4309e-01, time/batch = 15.2681s	
10518/33150 (epoch 15.864), train_loss = 1.17529790, grad/param norm = 1.4293e-01, time/batch = 15.0379s	
10519/33150 (epoch 15.866), train_loss = 1.13770137, grad/param norm = 1.5534e-01, time/batch = 15.2274s	
10520/33150 (epoch 15.867), train_loss = 1.10240240, grad/param norm = 1.3505e-01, time/batch = 15.2619s	
10521/33150 (epoch 15.869), train_loss = 1.12134029, grad/param norm = 1.4877e-01, time/batch = 15.8083s	
10522/33150 (epoch 15.870), train_loss = 1.08891960, grad/param norm = 1.6483e-01, time/batch = 17.5442s	
10523/33150 (epoch 15.872), train_loss = 1.08297827, grad/param norm = 1.5900e-01, time/batch = 18.0376s	
10524/33150 (epoch 15.873), train_loss = 0.91492667, grad/param norm = 1.3734e-01, time/batch = 16.1151s	
10525/33150 (epoch 15.875), train_loss = 1.21766924, grad/param norm = 1.5306e-01, time/batch = 16.8871s	
10526/33150 (epoch 15.876), train_loss = 0.98528601, grad/param norm = 1.5960e-01, time/batch = 16.6367s	
10527/33150 (epoch 15.878), train_loss = 0.96409745, grad/param norm = 1.3055e-01, time/batch = 16.2243s	
10528/33150 (epoch 15.879), train_loss = 1.00244013, grad/param norm = 1.5213e-01, time/batch = 16.8787s	
10529/33150 (epoch 15.881), train_loss = 1.00858599, grad/param norm = 1.4821e-01, time/batch = 17.7077s	
10530/33150 (epoch 15.882), train_loss = 0.90499024, grad/param norm = 1.3387e-01, time/batch = 16.9545s	
10531/33150 (epoch 15.884), train_loss = 1.05578793, grad/param norm = 1.4364e-01, time/batch = 16.4496s	
10532/33150 (epoch 15.885), train_loss = 0.84381996, grad/param norm = 1.3226e-01, time/batch = 16.7243s	
10533/33150 (epoch 15.887), train_loss = 1.23915773, grad/param norm = 1.7593e-01, time/batch = 17.0646s	
10534/33150 (epoch 15.888), train_loss = 1.13012216, grad/param norm = 1.6466e-01, time/batch = 18.1240s	
10535/33150 (epoch 15.890), train_loss = 1.01332931, grad/param norm = 1.4307e-01, time/batch = 16.0547s	
10536/33150 (epoch 15.891), train_loss = 0.96883380, grad/param norm = 1.5543e-01, time/batch = 17.3717s	
10537/33150 (epoch 15.893), train_loss = 1.14991039, grad/param norm = 1.7290e-01, time/batch = 16.0460s	
10538/33150 (epoch 15.894), train_loss = 1.14353584, grad/param norm = 1.5019e-01, time/batch = 16.1214s	
10539/33150 (epoch 15.896), train_loss = 1.03982860, grad/param norm = 1.4022e-01, time/batch = 18.1386s	
10540/33150 (epoch 15.897), train_loss = 1.09869226, grad/param norm = 1.3829e-01, time/batch = 16.9629s	
10541/33150 (epoch 15.899), train_loss = 0.94321381, grad/param norm = 1.6558e-01, time/batch = 17.3612s	
10542/33150 (epoch 15.900), train_loss = 1.33544962, grad/param norm = 1.6718e-01, time/batch = 16.7872s	
10543/33150 (epoch 15.902), train_loss = 1.23923352, grad/param norm = 1.6465e-01, time/batch = 16.6255s	
10544/33150 (epoch 15.903), train_loss = 1.08541388, grad/param norm = 1.4618e-01, time/batch = 18.2083s	
10545/33150 (epoch 15.905), train_loss = 1.12087818, grad/param norm = 1.3771e-01, time/batch = 16.7209s	
10546/33150 (epoch 15.906), train_loss = 1.16192443, grad/param norm = 1.7216e-01, time/batch = 17.3031s	
10547/33150 (epoch 15.908), train_loss = 1.23764250, grad/param norm = 1.6597e-01, time/batch = 19.1388s	
10548/33150 (epoch 15.910), train_loss = 1.17214976, grad/param norm = 1.4854e-01, time/batch = 17.5526s	
10549/33150 (epoch 15.911), train_loss = 0.93362012, grad/param norm = 1.2685e-01, time/batch = 16.7200s	
10550/33150 (epoch 15.913), train_loss = 1.01481782, grad/param norm = 1.3727e-01, time/batch = 15.4027s	
10551/33150 (epoch 15.914), train_loss = 1.15223075, grad/param norm = 1.6634e-01, time/batch = 18.8074s	
10552/33150 (epoch 15.916), train_loss = 0.99373311, grad/param norm = 1.5131e-01, time/batch = 16.7147s	
10553/33150 (epoch 15.917), train_loss = 1.16682176, grad/param norm = 1.6431e-01, time/batch = 15.7368s	
10554/33150 (epoch 15.919), train_loss = 1.22905799, grad/param norm = 1.7926e-01, time/batch = 17.5570s	
10555/33150 (epoch 15.920), train_loss = 1.18478382, grad/param norm = 1.5780e-01, time/batch = 17.2883s	
10556/33150 (epoch 15.922), train_loss = 1.25404622, grad/param norm = 1.8360e-01, time/batch = 16.1384s	
10557/33150 (epoch 15.923), train_loss = 1.11089501, grad/param norm = 1.6251e-01, time/batch = 18.0609s	
10558/33150 (epoch 15.925), train_loss = 1.15955912, grad/param norm = 1.5392e-01, time/batch = 18.4651s	
10559/33150 (epoch 15.926), train_loss = 1.05449449, grad/param norm = 1.4368e-01, time/batch = 15.7109s	
10560/33150 (epoch 15.928), train_loss = 1.03946086, grad/param norm = 1.4848e-01, time/batch = 16.8936s	
10561/33150 (epoch 15.929), train_loss = 1.14130177, grad/param norm = 1.4659e-01, time/batch = 17.7287s	
10562/33150 (epoch 15.931), train_loss = 1.24975279, grad/param norm = 1.8044e-01, time/batch = 17.7270s	
10563/33150 (epoch 15.932), train_loss = 1.10501258, grad/param norm = 1.5998e-01, time/batch = 18.0564s	
10564/33150 (epoch 15.934), train_loss = 1.12208664, grad/param norm = 1.4894e-01, time/batch = 17.5559s	
10565/33150 (epoch 15.935), train_loss = 1.18873678, grad/param norm = 1.4945e-01, time/batch = 20.0435s	
10566/33150 (epoch 15.937), train_loss = 1.21349666, grad/param norm = 1.4136e-01, time/batch = 16.1369s	
10567/33150 (epoch 15.938), train_loss = 1.15935678, grad/param norm = 1.4994e-01, time/batch = 18.5389s	
10568/33150 (epoch 15.940), train_loss = 1.36191911, grad/param norm = 1.7578e-01, time/batch = 17.8800s	
10569/33150 (epoch 15.941), train_loss = 1.07407763, grad/param norm = 1.2849e-01, time/batch = 17.0583s	
10570/33150 (epoch 15.943), train_loss = 0.98458257, grad/param norm = 1.5241e-01, time/batch = 16.4703s	
10571/33150 (epoch 15.944), train_loss = 1.20472889, grad/param norm = 1.7576e-01, time/batch = 17.6498s	
10572/33150 (epoch 15.946), train_loss = 0.90169909, grad/param norm = 1.2431e-01, time/batch = 17.1391s	
10573/33150 (epoch 15.947), train_loss = 1.13023806, grad/param norm = 1.4466e-01, time/batch = 16.2974s	
10574/33150 (epoch 15.949), train_loss = 1.23863816, grad/param norm = 1.5824e-01, time/batch = 19.2159s	
10575/33150 (epoch 15.950), train_loss = 1.14131981, grad/param norm = 1.8697e-01, time/batch = 18.8021s	
10576/33150 (epoch 15.952), train_loss = 1.01006046, grad/param norm = 1.4814e-01, time/batch = 16.4842s	
10577/33150 (epoch 15.953), train_loss = 1.05105578, grad/param norm = 1.4153e-01, time/batch = 17.8766s	
10578/33150 (epoch 15.955), train_loss = 0.96655959, grad/param norm = 1.3867e-01, time/batch = 17.9822s	
10579/33150 (epoch 15.956), train_loss = 1.15955597, grad/param norm = 1.6421e-01, time/batch = 16.7769s	
10580/33150 (epoch 15.958), train_loss = 0.96445711, grad/param norm = 1.2910e-01, time/batch = 17.2303s	
10581/33150 (epoch 15.959), train_loss = 1.02729984, grad/param norm = 1.5093e-01, time/batch = 19.6151s	
10582/33150 (epoch 15.961), train_loss = 0.94980427, grad/param norm = 1.3089e-01, time/batch = 18.3043s	
10583/33150 (epoch 15.962), train_loss = 0.92686000, grad/param norm = 1.2917e-01, time/batch = 15.6836s	
10584/33150 (epoch 15.964), train_loss = 1.08555556, grad/param norm = 1.4332e-01, time/batch = 19.3800s	
10585/33150 (epoch 15.965), train_loss = 1.06896009, grad/param norm = 1.3731e-01, time/batch = 17.7385s	
10586/33150 (epoch 15.967), train_loss = 1.08250628, grad/param norm = 1.6051e-01, time/batch = 15.7137s	
10587/33150 (epoch 15.968), train_loss = 0.90875889, grad/param norm = 1.2830e-01, time/batch = 17.0540s	
10588/33150 (epoch 15.970), train_loss = 1.03666767, grad/param norm = 1.4485e-01, time/batch = 17.5650s	
10589/33150 (epoch 15.971), train_loss = 1.06756442, grad/param norm = 1.4989e-01, time/batch = 18.7185s	
10590/33150 (epoch 15.973), train_loss = 1.25004888, grad/param norm = 1.7095e-01, time/batch = 16.0478s	
10591/33150 (epoch 15.974), train_loss = 1.24791891, grad/param norm = 1.6113e-01, time/batch = 17.7383s	
10592/33150 (epoch 15.976), train_loss = 1.14896169, grad/param norm = 1.3796e-01, time/batch = 15.8171s	
10593/33150 (epoch 15.977), train_loss = 1.24193274, grad/param norm = 1.6004e-01, time/batch = 15.9859s	
10594/33150 (epoch 15.979), train_loss = 1.21071449, grad/param norm = 1.8405e-01, time/batch = 17.0471s	
10595/33150 (epoch 15.980), train_loss = 1.25177335, grad/param norm = 1.5167e-01, time/batch = 18.7177s	
10596/33150 (epoch 15.982), train_loss = 1.08992342, grad/param norm = 1.7080e-01, time/batch = 16.6272s	
10597/33150 (epoch 15.983), train_loss = 0.95369001, grad/param norm = 1.4540e-01, time/batch = 16.0590s	
10598/33150 (epoch 15.985), train_loss = 1.15479223, grad/param norm = 1.4200e-01, time/batch = 17.4797s	
10599/33150 (epoch 15.986), train_loss = 0.93690050, grad/param norm = 1.3554e-01, time/batch = 17.1212s	
10600/33150 (epoch 15.988), train_loss = 1.03457515, grad/param norm = 1.4299e-01, time/batch = 16.8007s	
10601/33150 (epoch 15.989), train_loss = 1.00567656, grad/param norm = 1.6657e-01, time/batch = 19.0582s	
10602/33150 (epoch 15.991), train_loss = 1.17182037, grad/param norm = 2.0343e-01, time/batch = 16.9019s	
10603/33150 (epoch 15.992), train_loss = 0.97550948, grad/param norm = 1.3641e-01, time/batch = 17.8131s	
10604/33150 (epoch 15.994), train_loss = 1.09025642, grad/param norm = 1.6291e-01, time/batch = 17.1435s	
10605/33150 (epoch 15.995), train_loss = 1.03123217, grad/param norm = 1.5381e-01, time/batch = 17.8685s	
10606/33150 (epoch 15.997), train_loss = 1.11064520, grad/param norm = 1.7434e-01, time/batch = 16.7255s	
10607/33150 (epoch 15.998), train_loss = 0.89283373, grad/param norm = 1.3340e-01, time/batch = 16.3847s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
10608/33150 (epoch 16.000), train_loss = 0.92539721, grad/param norm = 1.5516e-01, time/batch = 16.9690s	
10609/33150 (epoch 16.002), train_loss = 1.38960359, grad/param norm = 1.7877e-01, time/batch = 17.1029s	
10610/33150 (epoch 16.003), train_loss = 1.00629773, grad/param norm = 1.4624e-01, time/batch = 17.9563s	
10611/33150 (epoch 16.005), train_loss = 0.98240743, grad/param norm = 1.5508e-01, time/batch = 17.5483s	
10612/33150 (epoch 16.006), train_loss = 0.93270601, grad/param norm = 1.4739e-01, time/batch = 18.1223s	
10613/33150 (epoch 16.008), train_loss = 1.17864104, grad/param norm = 1.5010e-01, time/batch = 16.8120s	
10614/33150 (epoch 16.009), train_loss = 1.06529360, grad/param norm = 1.3684e-01, time/batch = 16.8840s	
10615/33150 (epoch 16.011), train_loss = 1.19634599, grad/param norm = 1.5725e-01, time/batch = 16.5678s	
10616/33150 (epoch 16.012), train_loss = 1.07922611, grad/param norm = 1.8150e-01, time/batch = 18.5502s	
10617/33150 (epoch 16.014), train_loss = 1.06381261, grad/param norm = 1.8696e-01, time/batch = 23.5449s	
10618/33150 (epoch 16.015), train_loss = 1.01865915, grad/param norm = 1.6580e-01, time/batch = 24.8809s	
10619/33150 (epoch 16.017), train_loss = 1.00015027, grad/param norm = 1.4582e-01, time/batch = 19.0543s	
10620/33150 (epoch 16.018), train_loss = 1.11106631, grad/param norm = 1.6368e-01, time/batch = 15.6307s	
10621/33150 (epoch 16.020), train_loss = 1.16452436, grad/param norm = 1.7168e-01, time/batch = 17.2267s	
10622/33150 (epoch 16.021), train_loss = 0.94743837, grad/param norm = 1.5520e-01, time/batch = 16.5990s	
10623/33150 (epoch 16.023), train_loss = 1.25023504, grad/param norm = 1.4630e-01, time/batch = 16.9730s	
10624/33150 (epoch 16.024), train_loss = 1.14211561, grad/param norm = 1.5464e-01, time/batch = 16.9007s	
10625/33150 (epoch 16.026), train_loss = 0.85605939, grad/param norm = 1.2273e-01, time/batch = 19.5395s	
10626/33150 (epoch 16.027), train_loss = 0.87866525, grad/param norm = 1.2830e-01, time/batch = 16.6551s	
10627/33150 (epoch 16.029), train_loss = 0.98447834, grad/param norm = 1.4486e-01, time/batch = 15.9834s	
10628/33150 (epoch 16.030), train_loss = 1.06866301, grad/param norm = 1.3424e-01, time/batch = 15.7406s	
10629/33150 (epoch 16.032), train_loss = 1.02479284, grad/param norm = 1.6437e-01, time/batch = 16.6284s	
10630/33150 (epoch 16.033), train_loss = 1.03372749, grad/param norm = 1.4947e-01, time/batch = 17.2898s	
10631/33150 (epoch 16.035), train_loss = 1.24238737, grad/param norm = 1.7824e-01, time/batch = 16.4797s	
10632/33150 (epoch 16.036), train_loss = 1.11817851, grad/param norm = 1.6116e-01, time/batch = 17.4010s	
10633/33150 (epoch 16.038), train_loss = 1.36712827, grad/param norm = 2.0007e-01, time/batch = 17.3194s	
10634/33150 (epoch 16.039), train_loss = 1.11407076, grad/param norm = 1.4395e-01, time/batch = 16.5547s	
10635/33150 (epoch 16.041), train_loss = 1.12343420, grad/param norm = 1.5149e-01, time/batch = 16.7900s	
10636/33150 (epoch 16.042), train_loss = 1.04170213, grad/param norm = 1.4466e-01, time/batch = 17.6374s	
10637/33150 (epoch 16.044), train_loss = 1.05728423, grad/param norm = 1.4481e-01, time/batch = 18.5549s	
10638/33150 (epoch 16.045), train_loss = 1.09059509, grad/param norm = 1.3979e-01, time/batch = 19.2857s	
10639/33150 (epoch 16.047), train_loss = 0.97213622, grad/param norm = 1.4566e-01, time/batch = 18.5505s	
10640/33150 (epoch 16.048), train_loss = 1.18566886, grad/param norm = 1.6573e-01, time/batch = 17.8101s	
10641/33150 (epoch 16.050), train_loss = 1.09097288, grad/param norm = 1.5510e-01, time/batch = 16.5583s	
10642/33150 (epoch 16.051), train_loss = 1.08307582, grad/param norm = 1.5039e-01, time/batch = 16.2277s	
10643/33150 (epoch 16.053), train_loss = 1.02856194, grad/param norm = 1.3934e-01, time/batch = 17.4547s	
10644/33150 (epoch 16.054), train_loss = 1.19548488, grad/param norm = 1.4383e-01, time/batch = 16.3060s	
10645/33150 (epoch 16.056), train_loss = 1.04004236, grad/param norm = 1.4912e-01, time/batch = 17.7979s	
10646/33150 (epoch 16.057), train_loss = 1.07582647, grad/param norm = 1.6578e-01, time/batch = 19.4457s	
10647/33150 (epoch 16.059), train_loss = 0.98715742, grad/param norm = 1.4423e-01, time/batch = 16.5516s	
10648/33150 (epoch 16.060), train_loss = 1.01650788, grad/param norm = 1.3428e-01, time/batch = 17.9545s	
10649/33150 (epoch 16.062), train_loss = 1.03835247, grad/param norm = 1.4211e-01, time/batch = 18.3823s	
10650/33150 (epoch 16.063), train_loss = 1.03127948, grad/param norm = 1.4997e-01, time/batch = 19.3914s	
10651/33150 (epoch 16.065), train_loss = 1.05138185, grad/param norm = 1.3514e-01, time/batch = 16.5548s	
10652/33150 (epoch 16.066), train_loss = 0.98629338, grad/param norm = 1.3703e-01, time/batch = 17.8063s	
10653/33150 (epoch 16.068), train_loss = 1.07793615, grad/param norm = 1.4759e-01, time/batch = 15.9025s	
10654/33150 (epoch 16.069), train_loss = 1.14405704, grad/param norm = 1.6337e-01, time/batch = 16.0279s	
10655/33150 (epoch 16.071), train_loss = 1.11565049, grad/param norm = 1.4998e-01, time/batch = 16.7432s	
10656/33150 (epoch 16.072), train_loss = 1.04495269, grad/param norm = 1.4410e-01, time/batch = 16.3935s	
10657/33150 (epoch 16.074), train_loss = 0.94184377, grad/param norm = 1.5540e-01, time/batch = 19.0590s	
10658/33150 (epoch 16.075), train_loss = 1.01503817, grad/param norm = 1.6164e-01, time/batch = 15.8948s	
10659/33150 (epoch 16.077), train_loss = 1.08580964, grad/param norm = 1.6522e-01, time/batch = 16.9687s	
10660/33150 (epoch 16.078), train_loss = 1.23115659, grad/param norm = 1.7140e-01, time/batch = 18.7073s	
10661/33150 (epoch 16.080), train_loss = 1.18763412, grad/param norm = 1.3245e-01, time/batch = 16.4658s	
10662/33150 (epoch 16.081), train_loss = 0.98045702, grad/param norm = 1.5480e-01, time/batch = 17.5645s	
10663/33150 (epoch 16.083), train_loss = 0.80624147, grad/param norm = 1.5177e-01, time/batch = 19.2996s	
10664/33150 (epoch 16.084), train_loss = 0.95493794, grad/param norm = 1.5771e-01, time/batch = 16.8926s	
10665/33150 (epoch 16.086), train_loss = 1.01671334, grad/param norm = 1.5526e-01, time/batch = 18.3838s	
10666/33150 (epoch 16.087), train_loss = 0.94097546, grad/param norm = 1.3879e-01, time/batch = 17.3931s	
10667/33150 (epoch 16.089), train_loss = 0.98258005, grad/param norm = 1.6399e-01, time/batch = 19.0566s	
10668/33150 (epoch 16.090), train_loss = 0.99094721, grad/param norm = 1.4455e-01, time/batch = 16.7095s	
10669/33150 (epoch 16.092), train_loss = 1.00842002, grad/param norm = 1.5678e-01, time/batch = 17.1507s	
10670/33150 (epoch 16.094), train_loss = 1.11965854, grad/param norm = 1.5472e-01, time/batch = 15.7951s	
10671/33150 (epoch 16.095), train_loss = 0.91772533, grad/param norm = 1.2370e-01, time/batch = 16.4654s	
10672/33150 (epoch 16.097), train_loss = 1.00884278, grad/param norm = 1.5927e-01, time/batch = 15.2889s	
10673/33150 (epoch 16.098), train_loss = 1.31402155, grad/param norm = 1.6809e-01, time/batch = 15.3807s	
10674/33150 (epoch 16.100), train_loss = 1.27359826, grad/param norm = 1.6794e-01, time/batch = 14.8747s	
10675/33150 (epoch 16.101), train_loss = 0.99956653, grad/param norm = 1.6443e-01, time/batch = 15.2144s	
10676/33150 (epoch 16.103), train_loss = 1.07817635, grad/param norm = 1.5121e-01, time/batch = 15.1423s	
10677/33150 (epoch 16.104), train_loss = 0.98146903, grad/param norm = 1.5362e-01, time/batch = 16.3185s	
10678/33150 (epoch 16.106), train_loss = 1.19644071, grad/param norm = 1.6100e-01, time/batch = 17.8738s	
10679/33150 (epoch 16.107), train_loss = 1.31207653, grad/param norm = 1.6312e-01, time/batch = 16.6971s	
10680/33150 (epoch 16.109), train_loss = 1.03132008, grad/param norm = 1.2884e-01, time/batch = 16.3004s	
10681/33150 (epoch 16.110), train_loss = 1.16689006, grad/param norm = 1.5015e-01, time/batch = 15.4650s	
10682/33150 (epoch 16.112), train_loss = 0.97990578, grad/param norm = 1.4285e-01, time/batch = 15.2942s	
10683/33150 (epoch 16.113), train_loss = 1.05138842, grad/param norm = 1.6699e-01, time/batch = 15.9367s	
10684/33150 (epoch 16.115), train_loss = 1.25746086, grad/param norm = 1.8027e-01, time/batch = 14.8646s	
10685/33150 (epoch 16.116), train_loss = 1.04131137, grad/param norm = 1.4823e-01, time/batch = 14.7844s	
10686/33150 (epoch 16.118), train_loss = 1.15727165, grad/param norm = 1.7628e-01, time/batch = 15.8197s	
10687/33150 (epoch 16.119), train_loss = 1.15400029, grad/param norm = 1.8364e-01, time/batch = 15.0563s	
10688/33150 (epoch 16.121), train_loss = 1.02399731, grad/param norm = 1.4015e-01, time/batch = 16.3033s	
10689/33150 (epoch 16.122), train_loss = 1.28070587, grad/param norm = 1.7689e-01, time/batch = 16.7274s	
10690/33150 (epoch 16.124), train_loss = 0.87823688, grad/param norm = 1.2619e-01, time/batch = 16.2330s	
10691/33150 (epoch 16.125), train_loss = 1.16503499, grad/param norm = 1.5276e-01, time/batch = 15.3991s	
10692/33150 (epoch 16.127), train_loss = 1.04714708, grad/param norm = 1.4535e-01, time/batch = 17.7236s	
10693/33150 (epoch 16.128), train_loss = 1.11094410, grad/param norm = 1.6007e-01, time/batch = 16.4626s	
10694/33150 (epoch 16.130), train_loss = 1.10002305, grad/param norm = 1.4492e-01, time/batch = 16.6223s	
10695/33150 (epoch 16.131), train_loss = 1.33113951, grad/param norm = 2.0033e-01, time/batch = 16.4791s	
10696/33150 (epoch 16.133), train_loss = 0.99491465, grad/param norm = 1.3221e-01, time/batch = 17.0612s	
10697/33150 (epoch 16.134), train_loss = 1.18608975, grad/param norm = 1.5286e-01, time/batch = 16.5568s	
10698/33150 (epoch 16.136), train_loss = 1.11021595, grad/param norm = 1.6844e-01, time/batch = 15.7294s	
10699/33150 (epoch 16.137), train_loss = 1.18880118, grad/param norm = 1.5481e-01, time/batch = 16.7206s	
10700/33150 (epoch 16.139), train_loss = 1.15996497, grad/param norm = 1.7472e-01, time/batch = 18.5631s	
10701/33150 (epoch 16.140), train_loss = 1.22677522, grad/param norm = 1.5911e-01, time/batch = 17.1309s	
10702/33150 (epoch 16.142), train_loss = 1.17439215, grad/param norm = 1.6142e-01, time/batch = 16.3900s	
10703/33150 (epoch 16.143), train_loss = 1.10634184, grad/param norm = 1.5729e-01, time/batch = 17.2030s	
10704/33150 (epoch 16.145), train_loss = 1.04133620, grad/param norm = 1.6452e-01, time/batch = 18.4761s	
10705/33150 (epoch 16.146), train_loss = 1.21730957, grad/param norm = 1.8234e-01, time/batch = 15.8665s	
10706/33150 (epoch 16.148), train_loss = 1.17616935, grad/param norm = 1.3809e-01, time/batch = 17.5662s	
10707/33150 (epoch 16.149), train_loss = 1.11716658, grad/param norm = 1.4231e-01, time/batch = 18.2369s	
10708/33150 (epoch 16.151), train_loss = 1.26453739, grad/param norm = 1.5218e-01, time/batch = 16.8900s	
10709/33150 (epoch 16.152), train_loss = 1.03635360, grad/param norm = 1.4247e-01, time/batch = 17.0561s	
10710/33150 (epoch 16.154), train_loss = 1.08220892, grad/param norm = 1.5687e-01, time/batch = 16.6286s	
10711/33150 (epoch 16.155), train_loss = 0.94647442, grad/param norm = 1.3692e-01, time/batch = 17.4689s	
10712/33150 (epoch 16.157), train_loss = 1.02582409, grad/param norm = 1.5598e-01, time/batch = 16.8894s	
10713/33150 (epoch 16.158), train_loss = 1.00547608, grad/param norm = 1.4685e-01, time/batch = 18.6505s	
10714/33150 (epoch 16.160), train_loss = 1.14528542, grad/param norm = 1.6002e-01, time/batch = 16.5504s	
10715/33150 (epoch 16.161), train_loss = 1.00499893, grad/param norm = 1.9311e-01, time/batch = 16.4668s	
10716/33150 (epoch 16.163), train_loss = 1.02066299, grad/param norm = 1.5039e-01, time/batch = 17.5605s	
10717/33150 (epoch 16.164), train_loss = 1.15654184, grad/param norm = 1.7323e-01, time/batch = 17.9064s	
10718/33150 (epoch 16.166), train_loss = 1.06206895, grad/param norm = 1.6028e-01, time/batch = 17.1397s	
10719/33150 (epoch 16.167), train_loss = 1.08624794, grad/param norm = 1.4053e-01, time/batch = 17.6286s	
10720/33150 (epoch 16.169), train_loss = 1.15320092, grad/param norm = 2.0124e-01, time/batch = 17.5677s	
10721/33150 (epoch 16.170), train_loss = 0.98622285, grad/param norm = 1.6159e-01, time/batch = 19.1447s	
10722/33150 (epoch 16.172), train_loss = 1.17287143, grad/param norm = 1.7326e-01, time/batch = 15.5543s	
10723/33150 (epoch 16.173), train_loss = 1.15764313, grad/param norm = 1.9554e-01, time/batch = 18.0584s	
10724/33150 (epoch 16.175), train_loss = 1.01227259, grad/param norm = 1.5588e-01, time/batch = 16.6521s	
10725/33150 (epoch 16.176), train_loss = 1.13457362, grad/param norm = 1.7109e-01, time/batch = 17.5583s	
10726/33150 (epoch 16.178), train_loss = 1.25359798, grad/param norm = 1.6356e-01, time/batch = 15.8927s	
10727/33150 (epoch 16.179), train_loss = 1.13871562, grad/param norm = 1.4444e-01, time/batch = 18.5393s	
10728/33150 (epoch 16.181), train_loss = 1.10727085, grad/param norm = 1.6460e-01, time/batch = 19.5519s	
10729/33150 (epoch 16.183), train_loss = 1.06366418, grad/param norm = 1.6222e-01, time/batch = 15.9731s	
10730/33150 (epoch 16.184), train_loss = 1.28839787, grad/param norm = 1.5701e-01, time/batch = 18.3825s	
10731/33150 (epoch 16.186), train_loss = 1.18798862, grad/param norm = 1.4494e-01, time/batch = 15.9678s	
10732/33150 (epoch 16.187), train_loss = 1.11670755, grad/param norm = 1.5798e-01, time/batch = 17.2286s	
10733/33150 (epoch 16.189), train_loss = 0.88238454, grad/param norm = 1.4939e-01, time/batch = 17.2320s	
10734/33150 (epoch 16.190), train_loss = 0.97141359, grad/param norm = 1.5095e-01, time/batch = 19.7086s	
10735/33150 (epoch 16.192), train_loss = 1.10153125, grad/param norm = 1.7279e-01, time/batch = 18.3054s	
10736/33150 (epoch 16.193), train_loss = 1.13072164, grad/param norm = 1.4598e-01, time/batch = 16.1559s	
10737/33150 (epoch 16.195), train_loss = 1.36855797, grad/param norm = 1.8728e-01, time/batch = 19.1545s	
10738/33150 (epoch 16.196), train_loss = 1.23484579, grad/param norm = 1.5991e-01, time/batch = 19.0619s	
10739/33150 (epoch 16.198), train_loss = 0.95045797, grad/param norm = 1.7350e-01, time/batch = 15.7085s	
10740/33150 (epoch 16.199), train_loss = 1.17760712, grad/param norm = 1.8604e-01, time/batch = 15.8928s	
10741/33150 (epoch 16.201), train_loss = 0.98776791, grad/param norm = 1.3565e-01, time/batch = 16.9913s	
10742/33150 (epoch 16.202), train_loss = 0.88742102, grad/param norm = 1.4251e-01, time/batch = 18.5528s	
10743/33150 (epoch 16.204), train_loss = 1.10471065, grad/param norm = 1.5970e-01, time/batch = 18.2438s	
10744/33150 (epoch 16.205), train_loss = 1.17076552, grad/param norm = 1.6672e-01, time/batch = 18.7091s	
10745/33150 (epoch 16.207), train_loss = 1.12760137, grad/param norm = 1.4827e-01, time/batch = 18.0642s	
10746/33150 (epoch 16.208), train_loss = 1.13894348, grad/param norm = 1.6159e-01, time/batch = 16.6398s	
10747/33150 (epoch 16.210), train_loss = 0.99098924, grad/param norm = 1.3255e-01, time/batch = 17.7388s	
10748/33150 (epoch 16.211), train_loss = 1.13180579, grad/param norm = 1.7085e-01, time/batch = 18.3113s	
10749/33150 (epoch 16.213), train_loss = 1.16217575, grad/param norm = 1.6035e-01, time/batch = 17.3860s	
10750/33150 (epoch 16.214), train_loss = 1.05918342, grad/param norm = 1.4886e-01, time/batch = 17.4709s	
10751/33150 (epoch 16.216), train_loss = 1.02467634, grad/param norm = 1.6575e-01, time/batch = 18.1451s	
10752/33150 (epoch 16.217), train_loss = 1.02971627, grad/param norm = 1.3580e-01, time/batch = 17.6307s	
10753/33150 (epoch 16.219), train_loss = 0.96820716, grad/param norm = 1.4758e-01, time/batch = 17.6444s	
10754/33150 (epoch 16.220), train_loss = 0.99203464, grad/param norm = 1.2712e-01, time/batch = 17.9035s	
10755/33150 (epoch 16.222), train_loss = 1.17883979, grad/param norm = 1.4489e-01, time/batch = 19.5493s	
10756/33150 (epoch 16.223), train_loss = 1.07245228, grad/param norm = 1.5801e-01, time/batch = 6.4394s	
10757/33150 (epoch 16.225), train_loss = 1.24431090, grad/param norm = 1.5958e-01, time/batch = 0.6966s	
10758/33150 (epoch 16.226), train_loss = 1.04772886, grad/param norm = 1.4039e-01, time/batch = 0.6844s	
10759/33150 (epoch 16.228), train_loss = 1.06666642, grad/param norm = 1.4325e-01, time/batch = 0.6851s	
10760/33150 (epoch 16.229), train_loss = 1.06130758, grad/param norm = 1.4905e-01, time/batch = 0.6775s	
10761/33150 (epoch 16.231), train_loss = 1.22222492, grad/param norm = 1.6232e-01, time/batch = 0.6775s	
10762/33150 (epoch 16.232), train_loss = 1.12617552, grad/param norm = 1.8529e-01, time/batch = 0.6703s	
10763/33150 (epoch 16.234), train_loss = 1.09066929, grad/param norm = 1.6729e-01, time/batch = 0.6745s	
10764/33150 (epoch 16.235), train_loss = 1.11764179, grad/param norm = 1.6154e-01, time/batch = 0.6754s	
10765/33150 (epoch 16.237), train_loss = 1.07693904, grad/param norm = 1.9167e-01, time/batch = 0.6841s	
10766/33150 (epoch 16.238), train_loss = 1.16854269, grad/param norm = 1.8623e-01, time/batch = 0.6772s	
10767/33150 (epoch 16.240), train_loss = 1.14769362, grad/param norm = 1.5384e-01, time/batch = 0.6739s	
10768/33150 (epoch 16.241), train_loss = 1.24003139, grad/param norm = 1.6315e-01, time/batch = 0.6711s	
10769/33150 (epoch 16.243), train_loss = 1.17521243, grad/param norm = 1.6071e-01, time/batch = 0.6716s	
10770/33150 (epoch 16.244), train_loss = 1.06249158, grad/param norm = 1.3914e-01, time/batch = 0.6795s	
10771/33150 (epoch 16.246), train_loss = 1.15083923, grad/param norm = 1.4395e-01, time/batch = 0.6748s	
10772/33150 (epoch 16.247), train_loss = 1.02876651, grad/param norm = 1.5360e-01, time/batch = 0.6714s	
10773/33150 (epoch 16.249), train_loss = 1.15834723, grad/param norm = 1.4535e-01, time/batch = 0.6780s	
10774/33150 (epoch 16.250), train_loss = 1.14224647, grad/param norm = 1.3373e-01, time/batch = 0.6845s	
10775/33150 (epoch 16.252), train_loss = 1.14782949, grad/param norm = 1.3044e-01, time/batch = 0.6738s	
10776/33150 (epoch 16.253), train_loss = 1.13446483, grad/param norm = 1.6965e-01, time/batch = 0.6690s	
10777/33150 (epoch 16.255), train_loss = 1.07629302, grad/param norm = 1.3564e-01, time/batch = 0.6696s	
10778/33150 (epoch 16.256), train_loss = 1.14218533, grad/param norm = 1.4752e-01, time/batch = 0.6705s	
10779/33150 (epoch 16.258), train_loss = 1.04399729, grad/param norm = 1.6906e-01, time/batch = 0.6742s	
10780/33150 (epoch 16.259), train_loss = 0.91722419, grad/param norm = 1.5230e-01, time/batch = 0.6905s	
10781/33150 (epoch 16.261), train_loss = 0.94859262, grad/param norm = 1.3136e-01, time/batch = 0.6855s	
10782/33150 (epoch 16.262), train_loss = 1.14471113, grad/param norm = 1.5745e-01, time/batch = 0.6808s	
10783/33150 (epoch 16.264), train_loss = 0.86719450, grad/param norm = 1.3373e-01, time/batch = 0.6729s	
10784/33150 (epoch 16.265), train_loss = 1.13467889, grad/param norm = 1.4402e-01, time/batch = 0.6803s	
10785/33150 (epoch 16.267), train_loss = 1.17276568, grad/param norm = 1.8554e-01, time/batch = 0.6684s	
10786/33150 (epoch 16.268), train_loss = 1.17250639, grad/param norm = 1.5372e-01, time/batch = 0.6707s	
10787/33150 (epoch 16.270), train_loss = 1.28901605, grad/param norm = 1.6594e-01, time/batch = 0.6681s	
10788/33150 (epoch 16.271), train_loss = 1.23329922, grad/param norm = 1.6206e-01, time/batch = 0.6818s	
10789/33150 (epoch 16.273), train_loss = 1.23049184, grad/param norm = 1.6064e-01, time/batch = 0.6855s	
10790/33150 (epoch 16.275), train_loss = 1.23624281, grad/param norm = 1.5891e-01, time/batch = 0.6915s	
10791/33150 (epoch 16.276), train_loss = 1.08452238, grad/param norm = 1.5198e-01, time/batch = 0.6859s	
10792/33150 (epoch 16.278), train_loss = 1.16435846, grad/param norm = 1.5762e-01, time/batch = 0.6908s	
10793/33150 (epoch 16.279), train_loss = 1.13707663, grad/param norm = 1.4562e-01, time/batch = 0.6840s	
10794/33150 (epoch 16.281), train_loss = 1.13291061, grad/param norm = 1.5071e-01, time/batch = 0.6935s	
10795/33150 (epoch 16.282), train_loss = 1.09975353, grad/param norm = 1.3841e-01, time/batch = 0.6796s	
10796/33150 (epoch 16.284), train_loss = 1.02910497, grad/param norm = 1.3549e-01, time/batch = 0.6828s	
10797/33150 (epoch 16.285), train_loss = 1.11925929, grad/param norm = 1.4104e-01, time/batch = 0.6841s	
10798/33150 (epoch 16.287), train_loss = 1.02620583, grad/param norm = 1.4010e-01, time/batch = 0.6811s	
10799/33150 (epoch 16.288), train_loss = 1.24581016, grad/param norm = 1.5396e-01, time/batch = 0.6705s	
10800/33150 (epoch 16.290), train_loss = 0.94947370, grad/param norm = 1.6067e-01, time/batch = 0.6692s	
10801/33150 (epoch 16.291), train_loss = 0.92596628, grad/param norm = 1.4522e-01, time/batch = 0.6694s	
10802/33150 (epoch 16.293), train_loss = 1.16309090, grad/param norm = 1.5200e-01, time/batch = 0.6729s	
10803/33150 (epoch 16.294), train_loss = 0.83305158, grad/param norm = 1.3185e-01, time/batch = 0.6857s	
10804/33150 (epoch 16.296), train_loss = 1.06812341, grad/param norm = 1.4808e-01, time/batch = 0.6752s	
10805/33150 (epoch 16.297), train_loss = 1.03335034, grad/param norm = 1.4793e-01, time/batch = 0.6731s	
10806/33150 (epoch 16.299), train_loss = 1.03070333, grad/param norm = 1.6921e-01, time/batch = 0.6700s	
10807/33150 (epoch 16.300), train_loss = 1.03299544, grad/param norm = 1.3604e-01, time/batch = 0.6705s	
10808/33150 (epoch 16.302), train_loss = 1.02834448, grad/param norm = 1.3908e-01, time/batch = 0.6715s	
10809/33150 (epoch 16.303), train_loss = 1.06255437, grad/param norm = 1.4884e-01, time/batch = 0.6726s	
10810/33150 (epoch 16.305), train_loss = 1.15379434, grad/param norm = 1.4952e-01, time/batch = 0.6716s	
10811/33150 (epoch 16.306), train_loss = 1.12793283, grad/param norm = 1.5178e-01, time/batch = 0.6767s	
10812/33150 (epoch 16.308), train_loss = 1.32996330, grad/param norm = 1.6416e-01, time/batch = 0.6745s	
10813/33150 (epoch 16.309), train_loss = 0.93426721, grad/param norm = 1.3186e-01, time/batch = 0.6738s	
10814/33150 (epoch 16.311), train_loss = 1.05721919, grad/param norm = 1.5361e-01, time/batch = 0.6697s	
10815/33150 (epoch 16.312), train_loss = 0.86864385, grad/param norm = 1.4082e-01, time/batch = 0.6701s	
10816/33150 (epoch 16.314), train_loss = 1.05446834, grad/param norm = 1.4579e-01, time/batch = 0.6695s	
10817/33150 (epoch 16.315), train_loss = 1.12345009, grad/param norm = 1.5845e-01, time/batch = 0.6699s	
10818/33150 (epoch 16.317), train_loss = 0.85100697, grad/param norm = 1.1750e-01, time/batch = 0.6686s	
10819/33150 (epoch 16.318), train_loss = 0.98213847, grad/param norm = 1.3823e-01, time/batch = 0.6694s	
10820/33150 (epoch 16.320), train_loss = 0.92755558, grad/param norm = 1.3495e-01, time/batch = 0.6687s	
10821/33150 (epoch 16.321), train_loss = 1.02401662, grad/param norm = 1.3737e-01, time/batch = 0.6768s	
10822/33150 (epoch 16.323), train_loss = 1.08920956, grad/param norm = 1.5160e-01, time/batch = 0.6864s	
10823/33150 (epoch 16.324), train_loss = 1.19844584, grad/param norm = 1.9200e-01, time/batch = 0.6761s	
10824/33150 (epoch 16.326), train_loss = 1.09803477, grad/param norm = 1.3324e-01, time/batch = 0.6693s	
10825/33150 (epoch 16.327), train_loss = 1.21987400, grad/param norm = 1.5516e-01, time/batch = 0.6680s	
10826/33150 (epoch 16.329), train_loss = 1.13126421, grad/param norm = 1.4530e-01, time/batch = 0.6677s	
10827/33150 (epoch 16.330), train_loss = 1.10055011, grad/param norm = 1.6830e-01, time/batch = 0.6698s	
10828/33150 (epoch 16.332), train_loss = 1.07466987, grad/param norm = 1.4044e-01, time/batch = 0.6724s	
10829/33150 (epoch 16.333), train_loss = 1.11755624, grad/param norm = 1.3861e-01, time/batch = 0.6666s	
10830/33150 (epoch 16.335), train_loss = 1.02693620, grad/param norm = 1.4985e-01, time/batch = 0.6672s	
10831/33150 (epoch 16.336), train_loss = 0.98681485, grad/param norm = 1.4410e-01, time/batch = 0.6684s	
10832/33150 (epoch 16.338), train_loss = 0.89378992, grad/param norm = 1.4085e-01, time/batch = 0.6691s	
10833/33150 (epoch 16.339), train_loss = 1.18825240, grad/param norm = 1.6364e-01, time/batch = 0.6686s	
10834/33150 (epoch 16.341), train_loss = 1.19230361, grad/param norm = 1.8814e-01, time/batch = 0.6693s	
10835/33150 (epoch 16.342), train_loss = 0.95623045, grad/param norm = 1.4142e-01, time/batch = 0.6669s	
10836/33150 (epoch 16.344), train_loss = 1.10032647, grad/param norm = 1.6251e-01, time/batch = 0.6724s	
10837/33150 (epoch 16.345), train_loss = 1.04111931, grad/param norm = 1.3855e-01, time/batch = 0.6856s	
10838/33150 (epoch 16.347), train_loss = 0.86703357, grad/param norm = 1.2978e-01, time/batch = 0.6916s	
10839/33150 (epoch 16.348), train_loss = 1.09372504, grad/param norm = 1.4493e-01, time/batch = 0.6854s	
10840/33150 (epoch 16.350), train_loss = 1.02125303, grad/param norm = 1.7053e-01, time/batch = 0.6870s	
10841/33150 (epoch 16.351), train_loss = 1.16142312, grad/param norm = 1.6359e-01, time/batch = 0.6740s	
10842/33150 (epoch 16.353), train_loss = 1.14834746, grad/param norm = 1.6439e-01, time/batch = 0.6724s	
10843/33150 (epoch 16.354), train_loss = 1.35147167, grad/param norm = 1.6787e-01, time/batch = 0.6761s	
10844/33150 (epoch 16.356), train_loss = 1.21589207, grad/param norm = 1.7276e-01, time/batch = 0.6722s	
10845/33150 (epoch 16.357), train_loss = 1.18078536, grad/param norm = 1.6157e-01, time/batch = 0.6715s	
10846/33150 (epoch 16.359), train_loss = 1.12881210, grad/param norm = 1.5160e-01, time/batch = 0.6737s	
10847/33150 (epoch 16.360), train_loss = 1.16446568, grad/param norm = 1.7531e-01, time/batch = 0.6688s	
10848/33150 (epoch 16.362), train_loss = 1.18236475, grad/param norm = 1.5678e-01, time/batch = 0.6695s	
10849/33150 (epoch 16.363), train_loss = 1.10722111, grad/param norm = 1.4204e-01, time/batch = 0.6708s	
10850/33150 (epoch 16.365), train_loss = 1.08938198, grad/param norm = 1.4184e-01, time/batch = 0.6707s	
10851/33150 (epoch 16.367), train_loss = 1.00125467, grad/param norm = 1.4929e-01, time/batch = 0.6756s	
10852/33150 (epoch 16.368), train_loss = 1.06963858, grad/param norm = 1.5718e-01, time/batch = 0.6831s	
10853/33150 (epoch 16.370), train_loss = 1.10773553, grad/param norm = 1.5923e-01, time/batch = 0.6914s	
10854/33150 (epoch 16.371), train_loss = 0.97843266, grad/param norm = 1.3454e-01, time/batch = 0.6919s	
10855/33150 (epoch 16.373), train_loss = 1.14038083, grad/param norm = 1.7089e-01, time/batch = 0.6870s	
10856/33150 (epoch 16.374), train_loss = 1.05262697, grad/param norm = 1.4283e-01, time/batch = 0.6856s	
10857/33150 (epoch 16.376), train_loss = 1.21265200, grad/param norm = 1.5882e-01, time/batch = 0.6876s	
10858/33150 (epoch 16.377), train_loss = 1.02938821, grad/param norm = 1.6009e-01, time/batch = 0.6736s	
10859/33150 (epoch 16.379), train_loss = 1.17469553, grad/param norm = 1.5677e-01, time/batch = 0.6774s	
10860/33150 (epoch 16.380), train_loss = 1.15752297, grad/param norm = 1.3372e-01, time/batch = 0.6705s	
10861/33150 (epoch 16.382), train_loss = 1.00164621, grad/param norm = 1.4979e-01, time/batch = 0.6685s	
10862/33150 (epoch 16.383), train_loss = 0.98474116, grad/param norm = 1.3758e-01, time/batch = 0.6666s	
10863/33150 (epoch 16.385), train_loss = 1.07517464, grad/param norm = 1.4548e-01, time/batch = 0.6700s	
10864/33150 (epoch 16.386), train_loss = 0.93218795, grad/param norm = 1.2408e-01, time/batch = 0.6730s	
10865/33150 (epoch 16.388), train_loss = 1.04504483, grad/param norm = 1.3879e-01, time/batch = 0.6699s	
10866/33150 (epoch 16.389), train_loss = 1.01151935, grad/param norm = 1.3353e-01, time/batch = 0.6724s	
10867/33150 (epoch 16.391), train_loss = 1.24558435, grad/param norm = 1.5385e-01, time/batch = 0.6731s	
10868/33150 (epoch 16.392), train_loss = 1.02966481, grad/param norm = 1.3568e-01, time/batch = 0.6693s	
10869/33150 (epoch 16.394), train_loss = 0.94240999, grad/param norm = 1.2578e-01, time/batch = 0.6747s	
10870/33150 (epoch 16.395), train_loss = 0.95015029, grad/param norm = 1.4945e-01, time/batch = 0.6758s	
10871/33150 (epoch 16.397), train_loss = 0.78525406, grad/param norm = 1.3621e-01, time/batch = 0.6866s	
10872/33150 (epoch 16.398), train_loss = 1.09628139, grad/param norm = 1.5794e-01, time/batch = 0.6783s	
10873/33150 (epoch 16.400), train_loss = 1.00616545, grad/param norm = 1.2995e-01, time/batch = 0.6778s	
10874/33150 (epoch 16.401), train_loss = 0.89545952, grad/param norm = 1.2720e-01, time/batch = 0.6760s	
10875/33150 (epoch 16.403), train_loss = 0.96271042, grad/param norm = 1.2780e-01, time/batch = 0.6769s	
10876/33150 (epoch 16.404), train_loss = 1.07903994, grad/param norm = 1.5615e-01, time/batch = 0.6773s	
10877/33150 (epoch 16.406), train_loss = 0.98243487, grad/param norm = 1.1989e-01, time/batch = 0.6733s	
10878/33150 (epoch 16.407), train_loss = 0.93600108, grad/param norm = 1.3462e-01, time/batch = 0.6741s	
10879/33150 (epoch 16.409), train_loss = 0.86944086, grad/param norm = 1.4552e-01, time/batch = 0.6753s	
10880/33150 (epoch 16.410), train_loss = 1.10243464, grad/param norm = 1.5829e-01, time/batch = 0.6709s	
10881/33150 (epoch 16.412), train_loss = 1.10849119, grad/param norm = 1.4817e-01, time/batch = 0.6740s	
10882/33150 (epoch 16.413), train_loss = 1.01027586, grad/param norm = 1.4118e-01, time/batch = 0.6728s	
10883/33150 (epoch 16.415), train_loss = 1.16022767, grad/param norm = 1.4791e-01, time/batch = 0.6750s	
10884/33150 (epoch 16.416), train_loss = 0.99800567, grad/param norm = 1.3416e-01, time/batch = 0.6718s	
10885/33150 (epoch 16.418), train_loss = 1.20565104, grad/param norm = 1.9010e-01, time/batch = 0.6828s	
10886/33150 (epoch 16.419), train_loss = 1.01001246, grad/param norm = 1.4305e-01, time/batch = 0.6898s	
10887/33150 (epoch 16.421), train_loss = 1.10031406, grad/param norm = 1.6341e-01, time/batch = 0.6699s	
10888/33150 (epoch 16.422), train_loss = 1.03060904, grad/param norm = 1.4524e-01, time/batch = 0.6722s	
10889/33150 (epoch 16.424), train_loss = 1.02309620, grad/param norm = 1.5350e-01, time/batch = 0.6723s	
10890/33150 (epoch 16.425), train_loss = 1.09937244, grad/param norm = 1.4205e-01, time/batch = 0.6719s	
10891/33150 (epoch 16.427), train_loss = 1.06660612, grad/param norm = 1.3888e-01, time/batch = 0.6746s	
10892/33150 (epoch 16.428), train_loss = 1.07841936, grad/param norm = 1.5698e-01, time/batch = 0.6783s	
10893/33150 (epoch 16.430), train_loss = 1.09135133, grad/param norm = 1.5471e-01, time/batch = 0.6723s	
10894/33150 (epoch 16.431), train_loss = 1.16851555, grad/param norm = 2.1680e-01, time/batch = 0.6715s	
10895/33150 (epoch 16.433), train_loss = 1.05882149, grad/param norm = 1.4995e-01, time/batch = 0.6695s	
10896/33150 (epoch 16.434), train_loss = 0.94627400, grad/param norm = 1.4552e-01, time/batch = 0.6697s	
10897/33150 (epoch 16.436), train_loss = 0.99210345, grad/param norm = 1.5200e-01, time/batch = 0.6707s	
10898/33150 (epoch 16.437), train_loss = 1.08997271, grad/param norm = 1.8746e-01, time/batch = 0.6721s	
10899/33150 (epoch 16.439), train_loss = 1.18449895, grad/param norm = 1.5325e-01, time/batch = 0.6702s	
10900/33150 (epoch 16.440), train_loss = 1.17481513, grad/param norm = 1.6276e-01, time/batch = 0.6804s	
10901/33150 (epoch 16.442), train_loss = 0.95090954, grad/param norm = 1.3499e-01, time/batch = 0.6851s	
10902/33150 (epoch 16.443), train_loss = 1.14892853, grad/param norm = 1.5179e-01, time/batch = 0.6951s	
10903/33150 (epoch 16.445), train_loss = 1.07976955, grad/param norm = 1.6463e-01, time/batch = 0.6757s	
10904/33150 (epoch 16.446), train_loss = 1.10302453, grad/param norm = 1.8384e-01, time/batch = 0.6729s	
10905/33150 (epoch 16.448), train_loss = 1.16071079, grad/param norm = 1.6558e-01, time/batch = 0.6785s	
10906/33150 (epoch 16.449), train_loss = 1.08152303, grad/param norm = 1.3856e-01, time/batch = 0.6887s	
10907/33150 (epoch 16.451), train_loss = 1.14896268, grad/param norm = 1.6967e-01, time/batch = 0.6934s	
10908/33150 (epoch 16.452), train_loss = 1.32992066, grad/param norm = 1.6771e-01, time/batch = 0.6932s	
10909/33150 (epoch 16.454), train_loss = 1.04466048, grad/param norm = 1.3830e-01, time/batch = 0.6897s	
10910/33150 (epoch 16.456), train_loss = 0.93672888, grad/param norm = 1.3400e-01, time/batch = 0.6933s	
10911/33150 (epoch 16.457), train_loss = 1.09533674, grad/param norm = 1.5697e-01, time/batch = 0.6961s	
10912/33150 (epoch 16.459), train_loss = 1.20481700, grad/param norm = 1.8721e-01, time/batch = 0.6937s	
10913/33150 (epoch 16.460), train_loss = 1.09827252, grad/param norm = 1.2824e-01, time/batch = 0.6946s	
10914/33150 (epoch 16.462), train_loss = 1.18532076, grad/param norm = 1.8021e-01, time/batch = 0.6882s	
10915/33150 (epoch 16.463), train_loss = 1.34824538, grad/param norm = 1.8781e-01, time/batch = 0.6895s	
10916/33150 (epoch 16.465), train_loss = 1.03943238, grad/param norm = 1.4326e-01, time/batch = 0.6706s	
10917/33150 (epoch 16.466), train_loss = 0.99841862, grad/param norm = 1.3691e-01, time/batch = 0.6737s	
10918/33150 (epoch 16.468), train_loss = 1.36643983, grad/param norm = 1.6539e-01, time/batch = 0.6703s	
10919/33150 (epoch 16.469), train_loss = 1.08463550, grad/param norm = 1.6490e-01, time/batch = 0.6769s	
10920/33150 (epoch 16.471), train_loss = 1.01788152, grad/param norm = 1.3406e-01, time/batch = 0.6786s	
10921/33150 (epoch 16.472), train_loss = 1.07622992, grad/param norm = 1.4048e-01, time/batch = 0.6732s	
10922/33150 (epoch 16.474), train_loss = 1.18681950, grad/param norm = 1.7487e-01, time/batch = 0.6751s	
10923/33150 (epoch 16.475), train_loss = 1.34266969, grad/param norm = 1.6664e-01, time/batch = 0.6729s	
10924/33150 (epoch 16.477), train_loss = 1.17853891, grad/param norm = 1.6070e-01, time/batch = 0.6716s	
10925/33150 (epoch 16.478), train_loss = 1.18994673, grad/param norm = 1.5049e-01, time/batch = 0.6760s	
10926/33150 (epoch 16.480), train_loss = 1.03854126, grad/param norm = 1.5360e-01, time/batch = 0.6930s	
10927/33150 (epoch 16.481), train_loss = 0.92345323, grad/param norm = 1.7640e-01, time/batch = 0.6910s	
10928/33150 (epoch 16.483), train_loss = 1.03504716, grad/param norm = 1.4479e-01, time/batch = 0.6803s	
10929/33150 (epoch 16.484), train_loss = 1.03378859, grad/param norm = 1.5060e-01, time/batch = 0.6733s	
10930/33150 (epoch 16.486), train_loss = 1.05281407, grad/param norm = 1.6202e-01, time/batch = 0.6706s	
10931/33150 (epoch 16.487), train_loss = 1.10914014, grad/param norm = 1.5196e-01, time/batch = 0.6735s	
10932/33150 (epoch 16.489), train_loss = 1.10903724, grad/param norm = 1.6660e-01, time/batch = 0.6851s	
10933/33150 (epoch 16.490), train_loss = 0.91798398, grad/param norm = 1.3783e-01, time/batch = 0.6830s	
10934/33150 (epoch 16.492), train_loss = 1.01485685, grad/param norm = 1.5771e-01, time/batch = 0.6694s	
10935/33150 (epoch 16.493), train_loss = 1.18899764, grad/param norm = 1.6490e-01, time/batch = 0.6728s	
10936/33150 (epoch 16.495), train_loss = 1.21232240, grad/param norm = 1.5866e-01, time/batch = 0.6971s	
10937/33150 (epoch 16.496), train_loss = 1.02803914, grad/param norm = 1.4635e-01, time/batch = 0.6724s	
10938/33150 (epoch 16.498), train_loss = 1.20843782, grad/param norm = 1.9847e-01, time/batch = 0.6732s	
10939/33150 (epoch 16.499), train_loss = 1.22238975, grad/param norm = 1.5959e-01, time/batch = 0.6700s	
10940/33150 (epoch 16.501), train_loss = 1.13471683, grad/param norm = 1.5714e-01, time/batch = 0.6712s	
10941/33150 (epoch 16.502), train_loss = 1.23332948, grad/param norm = 1.6323e-01, time/batch = 0.6724s	
10942/33150 (epoch 16.504), train_loss = 1.14226955, grad/param norm = 1.5601e-01, time/batch = 0.6694s	
10943/33150 (epoch 16.505), train_loss = 1.30920450, grad/param norm = 1.8764e-01, time/batch = 0.6677s	
10944/33150 (epoch 16.507), train_loss = 1.02646341, grad/param norm = 1.4317e-01, time/batch = 0.6888s	
10945/33150 (epoch 16.508), train_loss = 1.06192617, grad/param norm = 1.7113e-01, time/batch = 0.6907s	
10946/33150 (epoch 16.510), train_loss = 1.11562233, grad/param norm = 1.4759e-01, time/batch = 0.6912s	
10947/33150 (epoch 16.511), train_loss = 1.26329566, grad/param norm = 1.6899e-01, time/batch = 0.6887s	
10948/33150 (epoch 16.513), train_loss = 1.10751067, grad/param norm = 1.5778e-01, time/batch = 0.6796s	
10949/33150 (epoch 16.514), train_loss = 0.90140563, grad/param norm = 1.3732e-01, time/batch = 0.6868s	
10950/33150 (epoch 16.516), train_loss = 1.19997027, grad/param norm = 1.8250e-01, time/batch = 0.6786s	
10951/33150 (epoch 16.517), train_loss = 1.20013750, grad/param norm = 1.5528e-01, time/batch = 0.6732s	
10952/33150 (epoch 16.519), train_loss = 1.00550499, grad/param norm = 1.3507e-01, time/batch = 0.6735s	
10953/33150 (epoch 16.520), train_loss = 1.11160956, grad/param norm = 1.4522e-01, time/batch = 0.6749s	
10954/33150 (epoch 16.522), train_loss = 1.25029483, grad/param norm = 1.8086e-01, time/batch = 0.6773s	
10955/33150 (epoch 16.523), train_loss = 1.01761012, grad/param norm = 1.5160e-01, time/batch = 0.6789s	
10956/33150 (epoch 16.525), train_loss = 1.15283076, grad/param norm = 1.5982e-01, time/batch = 0.6717s	
10957/33150 (epoch 16.526), train_loss = 1.00949113, grad/param norm = 1.4777e-01, time/batch = 0.6728s	
10958/33150 (epoch 16.528), train_loss = 1.13926858, grad/param norm = 1.5550e-01, time/batch = 0.6723s	
10959/33150 (epoch 16.529), train_loss = 1.09273395, grad/param norm = 1.4306e-01, time/batch = 0.6851s	
10960/33150 (epoch 16.531), train_loss = 0.92473521, grad/param norm = 1.5323e-01, time/batch = 0.6759s	
10961/33150 (epoch 16.532), train_loss = 1.12147813, grad/param norm = 1.5391e-01, time/batch = 0.6719s	
10962/33150 (epoch 16.534), train_loss = 1.04695908, grad/param norm = 1.2877e-01, time/batch = 0.9399s	
10963/33150 (epoch 16.535), train_loss = 1.00277445, grad/param norm = 1.6740e-01, time/batch = 0.9875s	
10964/33150 (epoch 16.537), train_loss = 1.19055116, grad/param norm = 1.5783e-01, time/batch = 0.9892s	
10965/33150 (epoch 16.538), train_loss = 1.03394577, grad/param norm = 1.4914e-01, time/batch = 0.9805s	
10966/33150 (epoch 16.540), train_loss = 0.94158484, grad/param norm = 1.4521e-01, time/batch = 0.9908s	
10967/33150 (epoch 16.541), train_loss = 1.17242439, grad/param norm = 1.6116e-01, time/batch = 1.6722s	
10968/33150 (epoch 16.543), train_loss = 1.11790278, grad/param norm = 1.3920e-01, time/batch = 1.8241s	
10969/33150 (epoch 16.544), train_loss = 1.12410560, grad/param norm = 1.4668e-01, time/batch = 2.9347s	
10970/33150 (epoch 16.546), train_loss = 1.17050528, grad/param norm = 1.5791e-01, time/batch = 19.2370s	
10971/33150 (epoch 16.548), train_loss = 1.10940351, grad/param norm = 1.5237e-01, time/batch = 15.9232s	
10972/33150 (epoch 16.549), train_loss = 1.02341893, grad/param norm = 1.5236e-01, time/batch = 18.3674s	
10973/33150 (epoch 16.551), train_loss = 0.99384882, grad/param norm = 1.3929e-01, time/batch = 18.0518s	
10974/33150 (epoch 16.552), train_loss = 0.87138008, grad/param norm = 1.1718e-01, time/batch = 17.7970s	
10975/33150 (epoch 16.554), train_loss = 1.17406795, grad/param norm = 1.5871e-01, time/batch = 19.7923s	
10976/33150 (epoch 16.555), train_loss = 1.23089752, grad/param norm = 1.5302e-01, time/batch = 17.7226s	
10977/33150 (epoch 16.557), train_loss = 0.91075391, grad/param norm = 1.3987e-01, time/batch = 17.3774s	
10978/33150 (epoch 16.558), train_loss = 1.16032468, grad/param norm = 1.7559e-01, time/batch = 4.1650s	
10979/33150 (epoch 16.560), train_loss = 1.03243306, grad/param norm = 1.4881e-01, time/batch = 0.6702s	
10980/33150 (epoch 16.561), train_loss = 0.93680736, grad/param norm = 1.5355e-01, time/batch = 0.6696s	
10981/33150 (epoch 16.563), train_loss = 1.16270852, grad/param norm = 1.8451e-01, time/batch = 0.6740s	
10982/33150 (epoch 16.564), train_loss = 1.26401307, grad/param norm = 1.5883e-01, time/batch = 0.6729s	
10983/33150 (epoch 16.566), train_loss = 1.06851637, grad/param norm = 1.4468e-01, time/batch = 0.6727s	
10984/33150 (epoch 16.567), train_loss = 0.98596766, grad/param norm = 1.4696e-01, time/batch = 0.6868s	
10985/33150 (epoch 16.569), train_loss = 1.11989641, grad/param norm = 1.5863e-01, time/batch = 0.6870s	
10986/33150 (epoch 16.570), train_loss = 1.14081873, grad/param norm = 1.5010e-01, time/batch = 0.6724s	
10987/33150 (epoch 16.572), train_loss = 1.01478554, grad/param norm = 1.4561e-01, time/batch = 0.6769s	
10988/33150 (epoch 16.573), train_loss = 0.86985430, grad/param norm = 1.2301e-01, time/batch = 0.6723s	
10989/33150 (epoch 16.575), train_loss = 1.04159407, grad/param norm = 1.4184e-01, time/batch = 0.6727s	
10990/33150 (epoch 16.576), train_loss = 0.94415193, grad/param norm = 1.3497e-01, time/batch = 0.6740s	
10991/33150 (epoch 16.578), train_loss = 0.99948628, grad/param norm = 1.3595e-01, time/batch = 0.6733s	
10992/33150 (epoch 16.579), train_loss = 0.92338327, grad/param norm = 1.4504e-01, time/batch = 0.6761s	
10993/33150 (epoch 16.581), train_loss = 0.99212954, grad/param norm = 1.4459e-01, time/batch = 0.6748s	
10994/33150 (epoch 16.582), train_loss = 1.17136853, grad/param norm = 1.4579e-01, time/batch = 0.6697s	
10995/33150 (epoch 16.584), train_loss = 1.18099190, grad/param norm = 1.7268e-01, time/batch = 0.6714s	
10996/33150 (epoch 16.585), train_loss = 1.08977745, grad/param norm = 1.7386e-01, time/batch = 0.6714s	
10997/33150 (epoch 16.587), train_loss = 1.11521105, grad/param norm = 1.5001e-01, time/batch = 0.6718s	
10998/33150 (epoch 16.588), train_loss = 0.98654594, grad/param norm = 1.4999e-01, time/batch = 0.6748s	
10999/33150 (epoch 16.590), train_loss = 1.08262775, grad/param norm = 1.5311e-01, time/batch = 0.6745s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch16.59_1.5891.t7	
11000/33150 (epoch 16.591), train_loss = 1.06935009, grad/param norm = 1.4572e-01, time/batch = 0.6756s	
11001/33150 (epoch 16.593), train_loss = 1.49382254, grad/param norm = 1.9701e-01, time/batch = 0.6800s	
11002/33150 (epoch 16.594), train_loss = 1.08422519, grad/param norm = 1.5265e-01, time/batch = 0.6718s	
11003/33150 (epoch 16.596), train_loss = 1.00992073, grad/param norm = 1.4288e-01, time/batch = 0.6711s	
11004/33150 (epoch 16.597), train_loss = 0.96730226, grad/param norm = 1.7350e-01, time/batch = 0.6722s	
11005/33150 (epoch 16.599), train_loss = 1.23683810, grad/param norm = 1.6964e-01, time/batch = 0.6760s	
11006/33150 (epoch 16.600), train_loss = 1.09662674, grad/param norm = 1.9677e-01, time/batch = 0.6818s	
11007/33150 (epoch 16.602), train_loss = 1.01498869, grad/param norm = 1.4741e-01, time/batch = 0.6978s	
11008/33150 (epoch 16.603), train_loss = 1.15240784, grad/param norm = 1.5731e-01, time/batch = 0.6755s	
11009/33150 (epoch 16.605), train_loss = 0.97216178, grad/param norm = 1.5440e-01, time/batch = 0.6715s	
11010/33150 (epoch 16.606), train_loss = 1.10402446, grad/param norm = 1.8017e-01, time/batch = 0.6722s	
11011/33150 (epoch 16.608), train_loss = 1.14288957, grad/param norm = 1.5251e-01, time/batch = 0.6789s	
11012/33150 (epoch 16.609), train_loss = 1.06667154, grad/param norm = 1.6111e-01, time/batch = 0.6693s	
11013/33150 (epoch 16.611), train_loss = 0.95603517, grad/param norm = 1.6214e-01, time/batch = 0.6706s	
11014/33150 (epoch 16.612), train_loss = 1.08640406, grad/param norm = 1.5989e-01, time/batch = 0.6747s	
11015/33150 (epoch 16.614), train_loss = 0.92028939, grad/param norm = 1.4477e-01, time/batch = 0.6724s	
11016/33150 (epoch 16.615), train_loss = 0.98291547, grad/param norm = 1.4384e-01, time/batch = 0.6745s	
11017/33150 (epoch 16.617), train_loss = 1.07810850, grad/param norm = 1.5743e-01, time/batch = 0.6767s	
11018/33150 (epoch 16.618), train_loss = 1.09363730, grad/param norm = 1.5383e-01, time/batch = 0.6761s	
11019/33150 (epoch 16.620), train_loss = 1.01530729, grad/param norm = 1.5384e-01, time/batch = 0.6732s	
11020/33150 (epoch 16.621), train_loss = 1.06007434, grad/param norm = 1.4044e-01, time/batch = 0.6795s	
11021/33150 (epoch 16.623), train_loss = 1.13467567, grad/param norm = 1.5201e-01, time/batch = 0.6741s	
11022/33150 (epoch 16.624), train_loss = 1.01055876, grad/param norm = 1.5036e-01, time/batch = 0.6716s	
11023/33150 (epoch 16.626), train_loss = 1.02113396, grad/param norm = 1.5090e-01, time/batch = 0.6684s	
11024/33150 (epoch 16.627), train_loss = 0.95801163, grad/param norm = 1.4506e-01, time/batch = 0.6668s	
11025/33150 (epoch 16.629), train_loss = 0.94525761, grad/param norm = 1.4221e-01, time/batch = 0.6698s	
11026/33150 (epoch 16.630), train_loss = 0.99696699, grad/param norm = 1.3037e-01, time/batch = 0.6707s	
11027/33150 (epoch 16.632), train_loss = 0.92177134, grad/param norm = 1.3102e-01, time/batch = 0.6703s	
11028/33150 (epoch 16.633), train_loss = 0.94184689, grad/param norm = 1.6795e-01, time/batch = 0.6692s	
11029/33150 (epoch 16.635), train_loss = 1.24909266, grad/param norm = 1.5829e-01, time/batch = 0.6739s	
11030/33150 (epoch 16.637), train_loss = 0.89745925, grad/param norm = 1.4292e-01, time/batch = 0.6744s	
11031/33150 (epoch 16.638), train_loss = 1.03424292, grad/param norm = 1.5113e-01, time/batch = 0.6740s	
11032/33150 (epoch 16.640), train_loss = 1.14726234, grad/param norm = 1.5207e-01, time/batch = 0.6755s	
11033/33150 (epoch 16.641), train_loss = 0.95035682, grad/param norm = 1.3997e-01, time/batch = 0.6738s	
11034/33150 (epoch 16.643), train_loss = 0.99853916, grad/param norm = 1.4256e-01, time/batch = 0.6728s	
11035/33150 (epoch 16.644), train_loss = 1.21753129, grad/param norm = 1.5962e-01, time/batch = 0.6709s	
11036/33150 (epoch 16.646), train_loss = 1.01647033, grad/param norm = 1.3652e-01, time/batch = 0.6682s	
11037/33150 (epoch 16.647), train_loss = 1.30924875, grad/param norm = 1.6610e-01, time/batch = 0.6689s	
11038/33150 (epoch 16.649), train_loss = 1.14227121, grad/param norm = 1.5585e-01, time/batch = 0.6709s	
11039/33150 (epoch 16.650), train_loss = 0.95466564, grad/param norm = 1.3228e-01, time/batch = 0.6695s	
11040/33150 (epoch 16.652), train_loss = 1.19198392, grad/param norm = 1.6477e-01, time/batch = 0.6696s	
11041/33150 (epoch 16.653), train_loss = 1.07479358, grad/param norm = 1.4249e-01, time/batch = 0.6806s	
11042/33150 (epoch 16.655), train_loss = 1.13383707, grad/param norm = 1.7114e-01, time/batch = 0.6725s	
11043/33150 (epoch 16.656), train_loss = 1.04250642, grad/param norm = 1.4606e-01, time/batch = 0.6747s	
11044/33150 (epoch 16.658), train_loss = 1.05953376, grad/param norm = 1.6209e-01, time/batch = 0.6740s	
11045/33150 (epoch 16.659), train_loss = 1.34437963, grad/param norm = 2.1717e-01, time/batch = 0.6766s	
11046/33150 (epoch 16.661), train_loss = 1.06906854, grad/param norm = 1.6381e-01, time/batch = 0.6709s	
11047/33150 (epoch 16.662), train_loss = 0.92389605, grad/param norm = 1.5460e-01, time/batch = 0.6756s	
11048/33150 (epoch 16.664), train_loss = 1.19291725, grad/param norm = 1.6568e-01, time/batch = 0.6739s	
11049/33150 (epoch 16.665), train_loss = 1.15033672, grad/param norm = 1.7484e-01, time/batch = 0.6721s	
11050/33150 (epoch 16.667), train_loss = 1.21461397, grad/param norm = 1.6754e-01, time/batch = 0.6890s	
11051/33150 (epoch 16.668), train_loss = 1.15721796, grad/param norm = 1.5334e-01, time/batch = 0.6954s	
11052/33150 (epoch 16.670), train_loss = 1.00617814, grad/param norm = 1.3503e-01, time/batch = 0.6950s	
11053/33150 (epoch 16.671), train_loss = 1.01348055, grad/param norm = 1.6119e-01, time/batch = 0.6820s	
11054/33150 (epoch 16.673), train_loss = 1.19007569, grad/param norm = 1.4119e-01, time/batch = 0.6768s	
11055/33150 (epoch 16.674), train_loss = 1.07069924, grad/param norm = 1.5913e-01, time/batch = 0.6750s	
11056/33150 (epoch 16.676), train_loss = 1.04353173, grad/param norm = 1.4083e-01, time/batch = 0.6766s	
11057/33150 (epoch 16.677), train_loss = 1.29994649, grad/param norm = 1.6862e-01, time/batch = 0.6780s	
11058/33150 (epoch 16.679), train_loss = 1.04867981, grad/param norm = 1.3668e-01, time/batch = 0.6777s	
11059/33150 (epoch 16.680), train_loss = 1.20139427, grad/param norm = 1.4910e-01, time/batch = 0.6830s	
11060/33150 (epoch 16.682), train_loss = 1.01863838, grad/param norm = 1.4591e-01, time/batch = 0.6726s	
11061/33150 (epoch 16.683), train_loss = 0.92370372, grad/param norm = 1.3307e-01, time/batch = 0.6756s	
11062/33150 (epoch 16.685), train_loss = 1.07058602, grad/param norm = 1.5924e-01, time/batch = 0.6760s	
11063/33150 (epoch 16.686), train_loss = 0.92123308, grad/param norm = 1.4578e-01, time/batch = 0.6749s	
11064/33150 (epoch 16.688), train_loss = 0.98810079, grad/param norm = 1.4281e-01, time/batch = 0.7035s	
11065/33150 (epoch 16.689), train_loss = 0.98403968, grad/param norm = 1.3101e-01, time/batch = 0.6936s	
11066/33150 (epoch 16.691), train_loss = 0.87556964, grad/param norm = 1.3188e-01, time/batch = 0.6748s	
11067/33150 (epoch 16.692), train_loss = 0.95336421, grad/param norm = 1.3409e-01, time/batch = 0.6721s	
11068/33150 (epoch 16.694), train_loss = 0.83720403, grad/param norm = 1.3113e-01, time/batch = 0.6704s	
11069/33150 (epoch 16.695), train_loss = 0.97898808, grad/param norm = 1.3285e-01, time/batch = 0.6722s	
11070/33150 (epoch 16.697), train_loss = 0.88933849, grad/param norm = 1.1888e-01, time/batch = 0.6685s	
11071/33150 (epoch 16.698), train_loss = 1.03303349, grad/param norm = 1.4947e-01, time/batch = 0.6780s	
11072/33150 (epoch 16.700), train_loss = 0.79019203, grad/param norm = 1.2275e-01, time/batch = 0.6710s	
11073/33150 (epoch 16.701), train_loss = 0.94011261, grad/param norm = 1.4352e-01, time/batch = 0.6676s	
11074/33150 (epoch 16.703), train_loss = 1.03006608, grad/param norm = 1.3725e-01, time/batch = 0.6691s	
11075/33150 (epoch 16.704), train_loss = 0.88784521, grad/param norm = 1.2650e-01, time/batch = 0.6726s	
11076/33150 (epoch 16.706), train_loss = 1.00160833, grad/param norm = 1.3660e-01, time/batch = 0.6714s	
11077/33150 (epoch 16.707), train_loss = 1.00371180, grad/param norm = 1.4746e-01, time/batch = 0.6695s	
11078/33150 (epoch 16.709), train_loss = 1.04885233, grad/param norm = 1.3242e-01, time/batch = 0.6702s	
11079/33150 (epoch 16.710), train_loss = 1.08194815, grad/param norm = 1.6303e-01, time/batch = 0.6738s	
11080/33150 (epoch 16.712), train_loss = 1.12748719, grad/param norm = 1.4767e-01, time/batch = 0.6744s	
11081/33150 (epoch 16.713), train_loss = 1.11148918, grad/param norm = 1.4371e-01, time/batch = 0.6727s	
11082/33150 (epoch 16.715), train_loss = 1.00271928, grad/param norm = 1.3022e-01, time/batch = 0.6721s	
11083/33150 (epoch 16.716), train_loss = 1.09204130, grad/param norm = 1.5006e-01, time/batch = 0.6927s	
11084/33150 (epoch 16.718), train_loss = 1.07767659, grad/param norm = 1.4748e-01, time/batch = 0.6947s	
11085/33150 (epoch 16.719), train_loss = 1.17032906, grad/param norm = 1.7216e-01, time/batch = 0.6856s	
11086/33150 (epoch 16.721), train_loss = 1.05054814, grad/param norm = 1.5465e-01, time/batch = 0.6726s	
11087/33150 (epoch 16.722), train_loss = 1.09463102, grad/param norm = 1.4917e-01, time/batch = 0.6739s	
11088/33150 (epoch 16.724), train_loss = 1.03796191, grad/param norm = 1.5803e-01, time/batch = 0.6843s	
11089/33150 (epoch 16.725), train_loss = 1.18253602, grad/param norm = 1.8578e-01, time/batch = 0.6734s	
11090/33150 (epoch 16.727), train_loss = 1.09303750, grad/param norm = 1.6857e-01, time/batch = 0.6732s	
11091/33150 (epoch 16.729), train_loss = 1.05234102, grad/param norm = 1.5537e-01, time/batch = 0.6742s	
11092/33150 (epoch 16.730), train_loss = 1.08402284, grad/param norm = 1.5612e-01, time/batch = 0.6757s	
11093/33150 (epoch 16.732), train_loss = 1.16494856, grad/param norm = 1.6224e-01, time/batch = 0.6788s	
11094/33150 (epoch 16.733), train_loss = 0.86240080, grad/param norm = 1.1661e-01, time/batch = 0.6740s	
11095/33150 (epoch 16.735), train_loss = 0.99183702, grad/param norm = 1.4149e-01, time/batch = 0.6708s	
11096/33150 (epoch 16.736), train_loss = 1.01195885, grad/param norm = 1.4159e-01, time/batch = 0.6734s	
11097/33150 (epoch 16.738), train_loss = 1.08763908, grad/param norm = 1.5818e-01, time/batch = 0.6874s	
11098/33150 (epoch 16.739), train_loss = 1.19147659, grad/param norm = 1.6917e-01, time/batch = 0.6704s	
11099/33150 (epoch 16.741), train_loss = 1.17132959, grad/param norm = 1.6462e-01, time/batch = 0.6718s	
11100/33150 (epoch 16.742), train_loss = 0.97680259, grad/param norm = 1.5284e-01, time/batch = 0.6710s	
11101/33150 (epoch 16.744), train_loss = 1.19469509, grad/param norm = 1.5724e-01, time/batch = 0.6725s	
11102/33150 (epoch 16.745), train_loss = 1.01066258, grad/param norm = 1.3886e-01, time/batch = 0.6718s	
11103/33150 (epoch 16.747), train_loss = 0.87961485, grad/param norm = 1.5305e-01, time/batch = 0.6875s	
11104/33150 (epoch 16.748), train_loss = 0.97653735, grad/param norm = 1.4305e-01, time/batch = 0.6733s	
11105/33150 (epoch 16.750), train_loss = 1.12277103, grad/param norm = 1.5773e-01, time/batch = 0.6703s	
11106/33150 (epoch 16.751), train_loss = 1.08126964, grad/param norm = 1.4290e-01, time/batch = 0.6766s	
11107/33150 (epoch 16.753), train_loss = 0.91448596, grad/param norm = 1.4701e-01, time/batch = 0.6748s	
11108/33150 (epoch 16.754), train_loss = 1.28333441, grad/param norm = 1.8324e-01, time/batch = 0.6751s	
11109/33150 (epoch 16.756), train_loss = 1.11854574, grad/param norm = 1.8786e-01, time/batch = 0.6758s	
11110/33150 (epoch 16.757), train_loss = 1.08021693, grad/param norm = 1.4737e-01, time/batch = 0.6711s	
11111/33150 (epoch 16.759), train_loss = 1.23296531, grad/param norm = 2.0470e-01, time/batch = 0.6768s	
11112/33150 (epoch 16.760), train_loss = 1.10690033, grad/param norm = 1.6114e-01, time/batch = 0.6763s	
11113/33150 (epoch 16.762), train_loss = 1.08697522, grad/param norm = 1.7375e-01, time/batch = 0.6717s	
11114/33150 (epoch 16.763), train_loss = 1.11206822, grad/param norm = 1.5684e-01, time/batch = 0.6704s	
11115/33150 (epoch 16.765), train_loss = 1.05311337, grad/param norm = 1.4700e-01, time/batch = 0.6734s	
11116/33150 (epoch 16.766), train_loss = 0.97700944, grad/param norm = 1.4494e-01, time/batch = 0.6841s	
11117/33150 (epoch 16.768), train_loss = 1.00727189, grad/param norm = 1.4167e-01, time/batch = 0.6940s	
11118/33150 (epoch 16.769), train_loss = 1.09323415, grad/param norm = 1.6497e-01, time/batch = 0.6761s	
11119/33150 (epoch 16.771), train_loss = 1.10868790, grad/param norm = 1.6258e-01, time/batch = 0.6673s	
11120/33150 (epoch 16.772), train_loss = 1.15085738, grad/param norm = 1.7681e-01, time/batch = 0.6672s	
11121/33150 (epoch 16.774), train_loss = 1.23681389, grad/param norm = 1.5356e-01, time/batch = 0.6949s	
11122/33150 (epoch 16.775), train_loss = 1.15424734, grad/param norm = 1.9813e-01, time/batch = 0.6674s	
11123/33150 (epoch 16.777), train_loss = 1.14411295, grad/param norm = 1.7272e-01, time/batch = 0.6702s	
11124/33150 (epoch 16.778), train_loss = 1.08412033, grad/param norm = 1.3315e-01, time/batch = 0.6689s	
11125/33150 (epoch 16.780), train_loss = 0.93070818, grad/param norm = 1.3459e-01, time/batch = 0.6712s	
11126/33150 (epoch 16.781), train_loss = 1.05855439, grad/param norm = 1.4116e-01, time/batch = 0.6670s	
11127/33150 (epoch 16.783), train_loss = 1.08557048, grad/param norm = 1.3874e-01, time/batch = 0.6648s	
11128/33150 (epoch 16.784), train_loss = 1.04374051, grad/param norm = 1.6293e-01, time/batch = 0.6684s	
11129/33150 (epoch 16.786), train_loss = 1.02955895, grad/param norm = 1.3810e-01, time/batch = 0.6678s	
11130/33150 (epoch 16.787), train_loss = 0.99095861, grad/param norm = 1.3058e-01, time/batch = 0.6701s	
11131/33150 (epoch 16.789), train_loss = 0.89999525, grad/param norm = 1.3724e-01, time/batch = 0.6715s	
11132/33150 (epoch 16.790), train_loss = 0.91170769, grad/param norm = 1.2549e-01, time/batch = 0.6687s	
11133/33150 (epoch 16.792), train_loss = 1.09460811, grad/param norm = 1.6891e-01, time/batch = 0.6725s	
11134/33150 (epoch 16.793), train_loss = 1.07012544, grad/param norm = 1.5625e-01, time/batch = 0.6828s	
11135/33150 (epoch 16.795), train_loss = 0.99743134, grad/param norm = 1.5342e-01, time/batch = 0.6867s	
11136/33150 (epoch 16.796), train_loss = 1.01022218, grad/param norm = 1.4896e-01, time/batch = 0.6893s	
11137/33150 (epoch 16.798), train_loss = 0.97293464, grad/param norm = 1.2671e-01, time/batch = 0.6887s	
11138/33150 (epoch 16.799), train_loss = 0.90512612, grad/param norm = 1.3965e-01, time/batch = 0.6895s	
11139/33150 (epoch 16.801), train_loss = 1.08667656, grad/param norm = 1.4364e-01, time/batch = 0.6940s	
11140/33150 (epoch 16.802), train_loss = 0.96310300, grad/param norm = 1.6578e-01, time/batch = 0.7020s	
11141/33150 (epoch 16.804), train_loss = 1.01881342, grad/param norm = 1.4519e-01, time/batch = 0.6963s	
11142/33150 (epoch 16.805), train_loss = 1.01540921, grad/param norm = 1.5989e-01, time/batch = 0.6914s	
11143/33150 (epoch 16.807), train_loss = 1.01073899, grad/param norm = 1.3534e-01, time/batch = 0.6917s	
11144/33150 (epoch 16.808), train_loss = 1.15171401, grad/param norm = 1.6226e-01, time/batch = 0.6858s	
11145/33150 (epoch 16.810), train_loss = 1.03720286, grad/param norm = 1.4808e-01, time/batch = 0.6766s	
11146/33150 (epoch 16.811), train_loss = 1.10775657, grad/param norm = 1.6934e-01, time/batch = 0.6894s	
11147/33150 (epoch 16.813), train_loss = 1.02064798, grad/param norm = 1.2967e-01, time/batch = 0.6729s	
11148/33150 (epoch 16.814), train_loss = 1.05806216, grad/param norm = 1.6930e-01, time/batch = 0.6784s	
11149/33150 (epoch 16.816), train_loss = 1.02747701, grad/param norm = 1.4348e-01, time/batch = 0.6757s	
11150/33150 (epoch 16.817), train_loss = 1.10338512, grad/param norm = 1.3840e-01, time/batch = 0.6720s	
11151/33150 (epoch 16.819), train_loss = 1.04950629, grad/param norm = 1.3714e-01, time/batch = 0.6717s	
11152/33150 (epoch 16.821), train_loss = 0.93807246, grad/param norm = 1.2910e-01, time/batch = 0.6732s	
11153/33150 (epoch 16.822), train_loss = 0.97262945, grad/param norm = 1.4455e-01, time/batch = 0.6784s	
11154/33150 (epoch 16.824), train_loss = 1.01646192, grad/param norm = 1.5355e-01, time/batch = 0.6883s	
11155/33150 (epoch 16.825), train_loss = 1.05539859, grad/param norm = 1.4584e-01, time/batch = 0.6650s	
11156/33150 (epoch 16.827), train_loss = 1.10917117, grad/param norm = 1.7944e-01, time/batch = 0.6668s	
11157/33150 (epoch 16.828), train_loss = 0.92145693, grad/param norm = 1.5170e-01, time/batch = 0.6684s	
11158/33150 (epoch 16.830), train_loss = 1.13548032, grad/param norm = 1.6272e-01, time/batch = 0.6695s	
11159/33150 (epoch 16.831), train_loss = 0.98817907, grad/param norm = 1.5989e-01, time/batch = 0.6881s	
11160/33150 (epoch 16.833), train_loss = 0.95427497, grad/param norm = 1.4858e-01, time/batch = 0.6787s	
11161/33150 (epoch 16.834), train_loss = 1.16346895, grad/param norm = 1.6298e-01, time/batch = 0.6718s	
11162/33150 (epoch 16.836), train_loss = 1.17288786, grad/param norm = 1.4856e-01, time/batch = 0.6714s	
11163/33150 (epoch 16.837), train_loss = 1.05310184, grad/param norm = 1.4789e-01, time/batch = 0.6802s	
11164/33150 (epoch 16.839), train_loss = 1.13079412, grad/param norm = 1.7009e-01, time/batch = 0.6705s	
11165/33150 (epoch 16.840), train_loss = 1.11201223, grad/param norm = 1.6118e-01, time/batch = 0.6710s	
11166/33150 (epoch 16.842), train_loss = 1.18739241, grad/param norm = 1.6290e-01, time/batch = 0.6712s	
11167/33150 (epoch 16.843), train_loss = 1.18857033, grad/param norm = 1.6283e-01, time/batch = 0.6719s	
11168/33150 (epoch 16.845), train_loss = 1.01760081, grad/param norm = 1.4339e-01, time/batch = 0.6754s	
11169/33150 (epoch 16.846), train_loss = 1.24775938, grad/param norm = 1.9583e-01, time/batch = 0.6744s	
11170/33150 (epoch 16.848), train_loss = 1.15841419, grad/param norm = 1.6290e-01, time/batch = 0.6739s	
11171/33150 (epoch 16.849), train_loss = 1.16732509, grad/param norm = 1.7662e-01, time/batch = 0.6782s	
11172/33150 (epoch 16.851), train_loss = 1.15794648, grad/param norm = 1.6432e-01, time/batch = 0.6757s	
11173/33150 (epoch 16.852), train_loss = 1.21938015, grad/param norm = 1.5188e-01, time/batch = 0.6755s	
11174/33150 (epoch 16.854), train_loss = 1.07630215, grad/param norm = 1.4374e-01, time/batch = 0.6737s	
11175/33150 (epoch 16.855), train_loss = 0.93038891, grad/param norm = 1.3625e-01, time/batch = 0.6708s	
11176/33150 (epoch 16.857), train_loss = 0.92440211, grad/param norm = 1.4411e-01, time/batch = 0.6721s	
11177/33150 (epoch 16.858), train_loss = 1.01295364, grad/param norm = 1.4825e-01, time/batch = 0.6738s	
11178/33150 (epoch 16.860), train_loss = 0.94628258, grad/param norm = 1.3061e-01, time/batch = 0.6734s	
11179/33150 (epoch 16.861), train_loss = 0.97072143, grad/param norm = 1.4265e-01, time/batch = 0.6716s	
11180/33150 (epoch 16.863), train_loss = 1.09364134, grad/param norm = 1.4931e-01, time/batch = 0.6744s	
11181/33150 (epoch 16.864), train_loss = 1.16883612, grad/param norm = 1.5207e-01, time/batch = 0.6730s	
11182/33150 (epoch 16.866), train_loss = 1.11989492, grad/param norm = 1.5565e-01, time/batch = 0.6750s	
11183/33150 (epoch 16.867), train_loss = 1.08745277, grad/param norm = 1.3670e-01, time/batch = 0.6890s	
11184/33150 (epoch 16.869), train_loss = 1.10239823, grad/param norm = 1.5218e-01, time/batch = 0.6850s	
11185/33150 (epoch 16.870), train_loss = 1.07062417, grad/param norm = 1.6380e-01, time/batch = 0.6875s	
11186/33150 (epoch 16.872), train_loss = 1.07659160, grad/param norm = 1.6972e-01, time/batch = 0.6879s	
11187/33150 (epoch 16.873), train_loss = 0.88941157, grad/param norm = 1.3224e-01, time/batch = 0.6799s	
11188/33150 (epoch 16.875), train_loss = 1.19659760, grad/param norm = 1.5797e-01, time/batch = 0.6821s	
11189/33150 (epoch 16.876), train_loss = 0.96288779, grad/param norm = 1.5465e-01, time/batch = 0.6804s	
11190/33150 (epoch 16.878), train_loss = 0.93920279, grad/param norm = 1.3207e-01, time/batch = 0.6814s	
11191/33150 (epoch 16.879), train_loss = 0.97123143, grad/param norm = 1.3877e-01, time/batch = 0.6780s	
11192/33150 (epoch 16.881), train_loss = 0.98805066, grad/param norm = 1.3739e-01, time/batch = 0.6854s	
11193/33150 (epoch 16.882), train_loss = 0.88766736, grad/param norm = 1.3822e-01, time/batch = 0.6722s	
11194/33150 (epoch 16.884), train_loss = 1.03661921, grad/param norm = 1.4267e-01, time/batch = 0.6705s	
11195/33150 (epoch 16.885), train_loss = 0.83140458, grad/param norm = 1.3960e-01, time/batch = 0.6710s	
11196/33150 (epoch 16.887), train_loss = 1.20458886, grad/param norm = 1.6452e-01, time/batch = 0.6724s	
11197/33150 (epoch 16.888), train_loss = 1.10726119, grad/param norm = 1.6834e-01, time/batch = 0.6709s	
11198/33150 (epoch 16.890), train_loss = 0.98440698, grad/param norm = 1.4327e-01, time/batch = 0.6740s	
11199/33150 (epoch 16.891), train_loss = 0.95601631, grad/param norm = 1.5854e-01, time/batch = 0.6819s	
11200/33150 (epoch 16.893), train_loss = 1.11645245, grad/param norm = 1.6029e-01, time/batch = 0.6777s	
11201/33150 (epoch 16.894), train_loss = 1.13436663, grad/param norm = 1.6739e-01, time/batch = 0.6805s	
11202/33150 (epoch 16.896), train_loss = 1.02423211, grad/param norm = 1.4006e-01, time/batch = 0.6749s	
11203/33150 (epoch 16.897), train_loss = 1.08589950, grad/param norm = 1.3719e-01, time/batch = 0.6680s	
11204/33150 (epoch 16.899), train_loss = 0.91621191, grad/param norm = 1.5354e-01, time/batch = 0.6688s	
11205/33150 (epoch 16.900), train_loss = 1.29550754, grad/param norm = 1.6133e-01, time/batch = 0.6673s	
11206/33150 (epoch 16.902), train_loss = 1.22381884, grad/param norm = 1.5591e-01, time/batch = 0.6695s	
11207/33150 (epoch 16.903), train_loss = 1.07923015, grad/param norm = 1.6042e-01, time/batch = 0.6705s	
11208/33150 (epoch 16.905), train_loss = 1.11682110, grad/param norm = 1.4185e-01, time/batch = 0.6682s	
11209/33150 (epoch 16.906), train_loss = 1.12616389, grad/param norm = 1.6966e-01, time/batch = 0.6677s	
11210/33150 (epoch 16.908), train_loss = 1.20349916, grad/param norm = 1.6518e-01, time/batch = 0.6670s	
11211/33150 (epoch 16.910), train_loss = 1.14072533, grad/param norm = 1.4841e-01, time/batch = 0.6707s	
11212/33150 (epoch 16.911), train_loss = 0.91737609, grad/param norm = 1.3507e-01, time/batch = 0.6687s	
11213/33150 (epoch 16.913), train_loss = 1.00803859, grad/param norm = 1.4306e-01, time/batch = 0.6695s	
11214/33150 (epoch 16.914), train_loss = 1.12832002, grad/param norm = 1.5828e-01, time/batch = 0.6699s	
11215/33150 (epoch 16.916), train_loss = 0.98754906, grad/param norm = 1.6501e-01, time/batch = 0.6690s	
11216/33150 (epoch 16.917), train_loss = 1.13465823, grad/param norm = 1.5945e-01, time/batch = 0.6695s	
11217/33150 (epoch 16.919), train_loss = 1.20358420, grad/param norm = 1.7434e-01, time/batch = 0.6715s	
11218/33150 (epoch 16.920), train_loss = 1.18086517, grad/param norm = 1.5792e-01, time/batch = 0.6691s	
11219/33150 (epoch 16.922), train_loss = 1.22373036, grad/param norm = 1.8072e-01, time/batch = 0.6865s	
11220/33150 (epoch 16.923), train_loss = 1.08306461, grad/param norm = 1.5861e-01, time/batch = 0.6714s	
11221/33150 (epoch 16.925), train_loss = 1.16104174, grad/param norm = 1.5965e-01, time/batch = 0.6725s	
11222/33150 (epoch 16.926), train_loss = 1.04931363, grad/param norm = 1.4640e-01, time/batch = 0.6735s	
11223/33150 (epoch 16.928), train_loss = 1.02531099, grad/param norm = 1.5109e-01, time/batch = 0.6744s	
11224/33150 (epoch 16.929), train_loss = 1.12154108, grad/param norm = 1.5954e-01, time/batch = 0.6723s	
11225/33150 (epoch 16.931), train_loss = 1.22987235, grad/param norm = 1.8364e-01, time/batch = 0.6790s	
11226/33150 (epoch 16.932), train_loss = 1.08414682, grad/param norm = 1.7140e-01, time/batch = 0.6931s	
11227/33150 (epoch 16.934), train_loss = 1.10239848, grad/param norm = 1.5077e-01, time/batch = 0.6934s	
11228/33150 (epoch 16.935), train_loss = 1.16998367, grad/param norm = 1.4947e-01, time/batch = 0.6936s	
11229/33150 (epoch 16.937), train_loss = 1.18228457, grad/param norm = 1.3876e-01, time/batch = 0.6880s	
11230/33150 (epoch 16.938), train_loss = 1.12845031, grad/param norm = 1.5234e-01, time/batch = 0.6884s	
11231/33150 (epoch 16.940), train_loss = 1.33038664, grad/param norm = 1.7517e-01, time/batch = 0.6901s	
11232/33150 (epoch 16.941), train_loss = 1.06253700, grad/param norm = 1.3884e-01, time/batch = 0.6744s	
11233/33150 (epoch 16.943), train_loss = 0.95716510, grad/param norm = 1.4670e-01, time/batch = 0.6788s	
11234/33150 (epoch 16.944), train_loss = 1.17668838, grad/param norm = 1.6363e-01, time/batch = 0.6719s	
11235/33150 (epoch 16.946), train_loss = 0.88560599, grad/param norm = 1.2808e-01, time/batch = 0.6744s	
11236/33150 (epoch 16.947), train_loss = 1.09597374, grad/param norm = 1.3819e-01, time/batch = 0.6743s	
11237/33150 (epoch 16.949), train_loss = 1.20793817, grad/param norm = 1.5502e-01, time/batch = 0.6769s	
11238/33150 (epoch 16.950), train_loss = 1.11254715, grad/param norm = 1.7116e-01, time/batch = 0.6794s	
11239/33150 (epoch 16.952), train_loss = 0.97694823, grad/param norm = 1.4023e-01, time/batch = 0.6804s	
11240/33150 (epoch 16.953), train_loss = 1.02235952, grad/param norm = 1.3922e-01, time/batch = 0.6774s	
11241/33150 (epoch 16.955), train_loss = 0.94187364, grad/param norm = 1.4208e-01, time/batch = 0.6778s	
11242/33150 (epoch 16.956), train_loss = 1.14038866, grad/param norm = 1.6459e-01, time/batch = 0.6809s	
11243/33150 (epoch 16.958), train_loss = 0.95098403, grad/param norm = 1.3520e-01, time/batch = 0.6752s	
11244/33150 (epoch 16.959), train_loss = 1.00795332, grad/param norm = 1.5216e-01, time/batch = 0.6778s	
11245/33150 (epoch 16.961), train_loss = 0.95738876, grad/param norm = 1.5451e-01, time/batch = 0.6736s	
11246/33150 (epoch 16.962), train_loss = 0.92223994, grad/param norm = 1.3463e-01, time/batch = 0.6721s	
11247/33150 (epoch 16.964), train_loss = 1.06702054, grad/param norm = 1.4521e-01, time/batch = 0.6764s	
11248/33150 (epoch 16.965), train_loss = 1.05599114, grad/param norm = 1.4077e-01, time/batch = 0.6739s	
11249/33150 (epoch 16.967), train_loss = 1.06547534, grad/param norm = 1.6455e-01, time/batch = 0.6796s	
11250/33150 (epoch 16.968), train_loss = 0.89704707, grad/param norm = 1.4073e-01, time/batch = 0.6815s	
11251/33150 (epoch 16.970), train_loss = 1.01665283, grad/param norm = 1.4388e-01, time/batch = 0.6837s	
11252/33150 (epoch 16.971), train_loss = 1.05579093, grad/param norm = 1.5360e-01, time/batch = 0.6821s	
11253/33150 (epoch 16.973), train_loss = 1.22595135, grad/param norm = 1.8903e-01, time/batch = 0.6754s	
11254/33150 (epoch 16.974), train_loss = 1.22026570, grad/param norm = 1.5752e-01, time/batch = 0.6751s	
11255/33150 (epoch 16.976), train_loss = 1.13527341, grad/param norm = 1.4163e-01, time/batch = 0.6764s	
11256/33150 (epoch 16.977), train_loss = 1.23474912, grad/param norm = 1.6040e-01, time/batch = 0.6736s	
11257/33150 (epoch 16.979), train_loss = 1.17552316, grad/param norm = 1.7552e-01, time/batch = 0.6717s	
11258/33150 (epoch 16.980), train_loss = 1.23960659, grad/param norm = 1.5733e-01, time/batch = 0.6713s	
11259/33150 (epoch 16.982), train_loss = 1.07241527, grad/param norm = 1.7495e-01, time/batch = 0.6709s	
11260/33150 (epoch 16.983), train_loss = 0.95115876, grad/param norm = 1.5710e-01, time/batch = 0.6722s	
11261/33150 (epoch 16.985), train_loss = 1.13989024, grad/param norm = 1.4358e-01, time/batch = 0.6715s	
11262/33150 (epoch 16.986), train_loss = 0.92957141, grad/param norm = 1.4183e-01, time/batch = 0.6740s	
11263/33150 (epoch 16.988), train_loss = 1.02796948, grad/param norm = 1.8105e-01, time/batch = 0.6727s	
11264/33150 (epoch 16.989), train_loss = 0.99021982, grad/param norm = 1.7243e-01, time/batch = 0.6879s	
11265/33150 (epoch 16.991), train_loss = 1.17007707, grad/param norm = 2.1130e-01, time/batch = 0.6831s	
11266/33150 (epoch 16.992), train_loss = 0.96687290, grad/param norm = 1.4016e-01, time/batch = 0.6728s	
11267/33150 (epoch 16.994), train_loss = 1.06957365, grad/param norm = 1.5128e-01, time/batch = 0.6824s	
11268/33150 (epoch 16.995), train_loss = 1.02113957, grad/param norm = 1.5951e-01, time/batch = 0.6708s	
11269/33150 (epoch 16.997), train_loss = 1.07141129, grad/param norm = 1.6484e-01, time/batch = 0.6737s	
11270/33150 (epoch 16.998), train_loss = 0.87784258, grad/param norm = 1.3235e-01, time/batch = 0.6720s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
11271/33150 (epoch 17.000), train_loss = 0.91571542, grad/param norm = 1.5843e-01, time/batch = 0.6779s	
11272/33150 (epoch 17.002), train_loss = 1.37392530, grad/param norm = 1.8298e-01, time/batch = 0.6766s	
11273/33150 (epoch 17.003), train_loss = 0.99350905, grad/param norm = 1.5075e-01, time/batch = 0.6718s	
11274/33150 (epoch 17.005), train_loss = 0.95543401, grad/param norm = 1.4541e-01, time/batch = 0.6751s	
11275/33150 (epoch 17.006), train_loss = 0.93112594, grad/param norm = 1.5453e-01, time/batch = 0.6742s	
11276/33150 (epoch 17.008), train_loss = 1.16235939, grad/param norm = 1.4857e-01, time/batch = 0.6727s	
11277/33150 (epoch 17.009), train_loss = 1.06014232, grad/param norm = 1.3999e-01, time/batch = 0.6722s	
11278/33150 (epoch 17.011), train_loss = 1.18583397, grad/param norm = 1.5861e-01, time/batch = 0.6709s	
11279/33150 (epoch 17.012), train_loss = 1.05424668, grad/param norm = 2.1713e-01, time/batch = 0.6716s	
11280/33150 (epoch 17.014), train_loss = 1.03035054, grad/param norm = 1.5852e-01, time/batch = 0.6736s	
11281/33150 (epoch 17.015), train_loss = 1.00695550, grad/param norm = 1.5241e-01, time/batch = 0.6737s	
11282/33150 (epoch 17.017), train_loss = 0.98620966, grad/param norm = 1.4710e-01, time/batch = 0.6728s	
11283/33150 (epoch 17.018), train_loss = 1.09401617, grad/param norm = 1.6046e-01, time/batch = 0.6721s	
11284/33150 (epoch 17.020), train_loss = 1.14050863, grad/param norm = 1.7719e-01, time/batch = 0.6715s	
11285/33150 (epoch 17.021), train_loss = 0.94083619, grad/param norm = 1.6480e-01, time/batch = 0.6710s	
11286/33150 (epoch 17.023), train_loss = 1.23356245, grad/param norm = 1.4740e-01, time/batch = 0.6717s	
11287/33150 (epoch 17.024), train_loss = 1.12271692, grad/param norm = 1.5884e-01, time/batch = 0.6714s	
11288/33150 (epoch 17.026), train_loss = 0.84297239, grad/param norm = 1.2112e-01, time/batch = 0.6687s	
11289/33150 (epoch 17.027), train_loss = 0.86923504, grad/param norm = 1.3013e-01, time/batch = 0.6695s	
11290/33150 (epoch 17.029), train_loss = 0.97050850, grad/param norm = 1.5043e-01, time/batch = 0.6734s	
11291/33150 (epoch 17.030), train_loss = 1.05344191, grad/param norm = 1.3914e-01, time/batch = 0.6736s	
11292/33150 (epoch 17.032), train_loss = 0.99948124, grad/param norm = 1.6235e-01, time/batch = 0.6747s	
11293/33150 (epoch 17.033), train_loss = 1.01330637, grad/param norm = 1.5519e-01, time/batch = 0.6717s	
11294/33150 (epoch 17.035), train_loss = 1.20869567, grad/param norm = 1.7074e-01, time/batch = 0.6726s	
11295/33150 (epoch 17.036), train_loss = 1.09951005, grad/param norm = 1.5501e-01, time/batch = 0.6763s	
11296/33150 (epoch 17.038), train_loss = 1.33382635, grad/param norm = 1.8075e-01, time/batch = 0.6940s	
11297/33150 (epoch 17.039), train_loss = 1.10330947, grad/param norm = 1.4065e-01, time/batch = 0.6834s	
11298/33150 (epoch 17.041), train_loss = 1.10297815, grad/param norm = 1.5483e-01, time/batch = 0.6747s	
11299/33150 (epoch 17.042), train_loss = 1.02839091, grad/param norm = 1.4143e-01, time/batch = 0.6756s	
11300/33150 (epoch 17.044), train_loss = 1.05480577, grad/param norm = 1.5020e-01, time/batch = 0.6770s	
11301/33150 (epoch 17.045), train_loss = 1.07568808, grad/param norm = 1.7125e-01, time/batch = 0.6765s	
11302/33150 (epoch 17.047), train_loss = 0.94728728, grad/param norm = 1.4591e-01, time/batch = 0.6728s	
11303/33150 (epoch 17.048), train_loss = 1.17311018, grad/param norm = 1.8388e-01, time/batch = 0.6718s	
11304/33150 (epoch 17.050), train_loss = 1.08926467, grad/param norm = 1.6534e-01, time/batch = 0.6710s	
11305/33150 (epoch 17.051), train_loss = 1.06749300, grad/param norm = 1.4581e-01, time/batch = 0.6768s	
11306/33150 (epoch 17.053), train_loss = 1.02818925, grad/param norm = 1.5394e-01, time/batch = 0.6699s	
11307/33150 (epoch 17.054), train_loss = 1.17647060, grad/param norm = 1.3442e-01, time/batch = 0.6748s	
11308/33150 (epoch 17.056), train_loss = 1.03187632, grad/param norm = 1.5240e-01, time/batch = 0.6744s	
11309/33150 (epoch 17.057), train_loss = 1.07188413, grad/param norm = 1.7456e-01, time/batch = 0.6725s	
11310/33150 (epoch 17.059), train_loss = 0.98715268, grad/param norm = 1.6159e-01, time/batch = 0.6721s	
11311/33150 (epoch 17.060), train_loss = 0.99553208, grad/param norm = 1.3365e-01, time/batch = 0.6749s	
11312/33150 (epoch 17.062), train_loss = 1.02607076, grad/param norm = 1.4851e-01, time/batch = 0.6706s	
11313/33150 (epoch 17.063), train_loss = 0.99788370, grad/param norm = 1.4511e-01, time/batch = 0.6721s	
11314/33150 (epoch 17.065), train_loss = 1.03238837, grad/param norm = 1.5200e-01, time/batch = 0.6734s	
11315/33150 (epoch 17.066), train_loss = 0.97751411, grad/param norm = 1.4849e-01, time/batch = 0.6845s	
11316/33150 (epoch 17.068), train_loss = 1.06980712, grad/param norm = 1.4594e-01, time/batch = 0.6932s	
11317/33150 (epoch 17.069), train_loss = 1.12338537, grad/param norm = 1.6973e-01, time/batch = 0.6870s	
11318/33150 (epoch 17.071), train_loss = 1.10334988, grad/param norm = 1.5304e-01, time/batch = 0.6972s	
11319/33150 (epoch 17.072), train_loss = 1.03090765, grad/param norm = 1.4045e-01, time/batch = 0.7033s	
11320/33150 (epoch 17.074), train_loss = 0.92721582, grad/param norm = 1.5798e-01, time/batch = 0.6776s	
11321/33150 (epoch 17.075), train_loss = 1.00113932, grad/param norm = 1.5962e-01, time/batch = 0.6778s	
11322/33150 (epoch 17.077), train_loss = 1.06130479, grad/param norm = 1.7196e-01, time/batch = 0.6751s	
11323/33150 (epoch 17.078), train_loss = 1.20207281, grad/param norm = 1.7245e-01, time/batch = 0.6754s	
11324/33150 (epoch 17.080), train_loss = 1.17214432, grad/param norm = 1.3670e-01, time/batch = 0.6754s	
11325/33150 (epoch 17.081), train_loss = 0.96753620, grad/param norm = 1.6137e-01, time/batch = 0.7046s	
11326/33150 (epoch 17.083), train_loss = 0.79248693, grad/param norm = 1.5578e-01, time/batch = 0.6790s	
11327/33150 (epoch 17.084), train_loss = 0.92765501, grad/param norm = 1.5028e-01, time/batch = 0.6771s	
11328/33150 (epoch 17.086), train_loss = 1.00314393, grad/param norm = 1.6107e-01, time/batch = 0.6710s	
11329/33150 (epoch 17.087), train_loss = 0.91293643, grad/param norm = 1.3108e-01, time/batch = 0.6751s	
11330/33150 (epoch 17.089), train_loss = 0.96078223, grad/param norm = 1.5498e-01, time/batch = 0.7002s	
11331/33150 (epoch 17.090), train_loss = 0.97836089, grad/param norm = 1.4513e-01, time/batch = 0.6838s	
11332/33150 (epoch 17.092), train_loss = 0.99397765, grad/param norm = 1.5535e-01, time/batch = 0.6753s	
11333/33150 (epoch 17.094), train_loss = 1.10151655, grad/param norm = 1.6308e-01, time/batch = 0.6710s	
11334/33150 (epoch 17.095), train_loss = 0.91757087, grad/param norm = 1.3401e-01, time/batch = 0.6722s	
11335/33150 (epoch 17.097), train_loss = 0.99244021, grad/param norm = 1.5187e-01, time/batch = 0.6727s	
11336/33150 (epoch 17.098), train_loss = 1.29260793, grad/param norm = 1.6933e-01, time/batch = 0.6738s	
11337/33150 (epoch 17.100), train_loss = 1.24028165, grad/param norm = 1.5570e-01, time/batch = 0.6666s	
11338/33150 (epoch 17.101), train_loss = 0.98628752, grad/param norm = 1.5982e-01, time/batch = 0.6669s	
11339/33150 (epoch 17.103), train_loss = 1.05087277, grad/param norm = 1.4998e-01, time/batch = 0.6673s	
11340/33150 (epoch 17.104), train_loss = 0.96584226, grad/param norm = 1.5527e-01, time/batch = 0.6670s	
11341/33150 (epoch 17.106), train_loss = 1.18190091, grad/param norm = 1.8872e-01, time/batch = 0.6719s	
11342/33150 (epoch 17.107), train_loss = 1.28711826, grad/param norm = 1.6166e-01, time/batch = 0.6674s	
11343/33150 (epoch 17.109), train_loss = 1.01203932, grad/param norm = 1.2894e-01, time/batch = 0.6687s	
11344/33150 (epoch 17.110), train_loss = 1.14963164, grad/param norm = 1.4279e-01, time/batch = 0.6807s	
11345/33150 (epoch 17.112), train_loss = 0.96023101, grad/param norm = 1.4396e-01, time/batch = 0.6692s	
11346/33150 (epoch 17.113), train_loss = 1.03657808, grad/param norm = 1.6238e-01, time/batch = 0.6709s	
11347/33150 (epoch 17.115), train_loss = 1.23708262, grad/param norm = 1.7655e-01, time/batch = 0.6720s	
11348/33150 (epoch 17.116), train_loss = 1.01492577, grad/param norm = 1.3394e-01, time/batch = 0.6695s	
11349/33150 (epoch 17.118), train_loss = 1.14252101, grad/param norm = 1.7231e-01, time/batch = 0.6713s	
11350/33150 (epoch 17.119), train_loss = 1.14317181, grad/param norm = 1.6749e-01, time/batch = 0.6709s	
11351/33150 (epoch 17.121), train_loss = 1.00435417, grad/param norm = 1.4970e-01, time/batch = 0.6794s	
11352/33150 (epoch 17.122), train_loss = 1.26504220, grad/param norm = 1.8550e-01, time/batch = 0.6751s	
11353/33150 (epoch 17.124), train_loss = 0.86229395, grad/param norm = 1.2075e-01, time/batch = 0.6757s	
11354/33150 (epoch 17.125), train_loss = 1.15914750, grad/param norm = 1.5452e-01, time/batch = 0.6706s	
11355/33150 (epoch 17.127), train_loss = 1.02373761, grad/param norm = 1.3492e-01, time/batch = 0.6700s	
11356/33150 (epoch 17.128), train_loss = 1.09496164, grad/param norm = 1.5999e-01, time/batch = 0.6698s	
11357/33150 (epoch 17.130), train_loss = 1.09450072, grad/param norm = 1.5081e-01, time/batch = 0.6770s	
11358/33150 (epoch 17.131), train_loss = 1.29254360, grad/param norm = 1.7406e-01, time/batch = 0.6731s	
11359/33150 (epoch 17.133), train_loss = 0.97590403, grad/param norm = 1.3907e-01, time/batch = 0.6725s	
11360/33150 (epoch 17.134), train_loss = 1.16494128, grad/param norm = 1.5886e-01, time/batch = 0.6696s	
11361/33150 (epoch 17.136), train_loss = 1.07425298, grad/param norm = 1.6749e-01, time/batch = 0.6716s	
11362/33150 (epoch 17.137), train_loss = 1.17433864, grad/param norm = 1.6259e-01, time/batch = 0.6768s	
11363/33150 (epoch 17.139), train_loss = 1.13969920, grad/param norm = 1.6129e-01, time/batch = 0.6742s	
11364/33150 (epoch 17.140), train_loss = 1.22374573, grad/param norm = 1.7836e-01, time/batch = 0.6775s	
11365/33150 (epoch 17.142), train_loss = 1.15289569, grad/param norm = 1.6967e-01, time/batch = 0.6888s	
11366/33150 (epoch 17.143), train_loss = 1.09210608, grad/param norm = 1.6092e-01, time/batch = 0.6784s	
11367/33150 (epoch 17.145), train_loss = 1.03366105, grad/param norm = 1.6896e-01, time/batch = 0.6755s	
11368/33150 (epoch 17.146), train_loss = 1.19551964, grad/param norm = 1.7729e-01, time/batch = 0.6826s	
11369/33150 (epoch 17.148), train_loss = 1.16433554, grad/param norm = 1.4081e-01, time/batch = 0.6709s	
11370/33150 (epoch 17.149), train_loss = 1.09539444, grad/param norm = 1.6539e-01, time/batch = 0.6698s	
11371/33150 (epoch 17.151), train_loss = 1.25316015, grad/param norm = 1.6164e-01, time/batch = 0.6721s	
11372/33150 (epoch 17.152), train_loss = 1.02482115, grad/param norm = 1.3972e-01, time/batch = 0.6736s	
11373/33150 (epoch 17.154), train_loss = 1.06251639, grad/param norm = 1.5272e-01, time/batch = 0.6719s	
11374/33150 (epoch 17.155), train_loss = 0.93061069, grad/param norm = 1.4384e-01, time/batch = 0.6748s	
11375/33150 (epoch 17.157), train_loss = 1.00867973, grad/param norm = 1.5890e-01, time/batch = 0.6725s	
11376/33150 (epoch 17.158), train_loss = 0.98987473, grad/param norm = 1.4270e-01, time/batch = 0.6709s	
11377/33150 (epoch 17.160), train_loss = 1.11544492, grad/param norm = 1.5653e-01, time/batch = 0.6708s	
11378/33150 (epoch 17.161), train_loss = 0.97699152, grad/param norm = 1.5767e-01, time/batch = 0.6736s	
11379/33150 (epoch 17.163), train_loss = 0.99307629, grad/param norm = 1.5113e-01, time/batch = 0.6749s	
11380/33150 (epoch 17.164), train_loss = 1.12842309, grad/param norm = 1.7519e-01, time/batch = 0.6760s	
11381/33150 (epoch 17.166), train_loss = 1.04565609, grad/param norm = 1.5447e-01, time/batch = 0.6807s	
11382/33150 (epoch 17.167), train_loss = 1.08711998, grad/param norm = 1.4455e-01, time/batch = 0.6748s	
11383/33150 (epoch 17.169), train_loss = 1.11636581, grad/param norm = 1.8797e-01, time/batch = 0.6767s	
11384/33150 (epoch 17.170), train_loss = 0.95474147, grad/param norm = 1.4249e-01, time/batch = 0.6737s	
11385/33150 (epoch 17.172), train_loss = 1.16818342, grad/param norm = 1.6603e-01, time/batch = 0.6723s	
11386/33150 (epoch 17.173), train_loss = 1.12864251, grad/param norm = 1.7616e-01, time/batch = 0.6741s	
11387/33150 (epoch 17.175), train_loss = 1.00365233, grad/param norm = 1.7240e-01, time/batch = 0.6716s	
11388/33150 (epoch 17.176), train_loss = 1.12170467, grad/param norm = 1.7168e-01, time/batch = 0.6697s	
11389/33150 (epoch 17.178), train_loss = 1.23331198, grad/param norm = 1.5704e-01, time/batch = 0.6740s	
11390/33150 (epoch 17.179), train_loss = 1.12123445, grad/param norm = 1.4826e-01, time/batch = 0.6739s	
11391/33150 (epoch 17.181), train_loss = 1.08838631, grad/param norm = 1.6037e-01, time/batch = 0.6772s	
11392/33150 (epoch 17.183), train_loss = 1.04748163, grad/param norm = 1.6134e-01, time/batch = 0.6876s	
11393/33150 (epoch 17.184), train_loss = 1.26817228, grad/param norm = 1.5672e-01, time/batch = 0.6817s	
11394/33150 (epoch 17.186), train_loss = 1.17193593, grad/param norm = 1.5403e-01, time/batch = 0.6688s	
11395/33150 (epoch 17.187), train_loss = 1.10034720, grad/param norm = 1.5145e-01, time/batch = 0.6693s	
11396/33150 (epoch 17.189), train_loss = 0.86867259, grad/param norm = 1.6580e-01, time/batch = 0.6686s	
11397/33150 (epoch 17.190), train_loss = 0.95315157, grad/param norm = 1.4713e-01, time/batch = 0.6668s	
11398/33150 (epoch 17.192), train_loss = 1.08110563, grad/param norm = 1.7440e-01, time/batch = 0.6718s	
11399/33150 (epoch 17.193), train_loss = 1.12845501, grad/param norm = 1.5464e-01, time/batch = 0.6668s	
11400/33150 (epoch 17.195), train_loss = 1.32781327, grad/param norm = 1.8264e-01, time/batch = 0.6652s	
11401/33150 (epoch 17.196), train_loss = 1.20589497, grad/param norm = 1.5793e-01, time/batch = 0.6710s	
11402/33150 (epoch 17.198), train_loss = 0.92699829, grad/param norm = 1.5375e-01, time/batch = 0.6677s	
11403/33150 (epoch 17.199), train_loss = 1.17090516, grad/param norm = 1.8683e-01, time/batch = 0.6797s	
11404/33150 (epoch 17.201), train_loss = 0.97109118, grad/param norm = 1.3293e-01, time/batch = 0.6922s	
11405/33150 (epoch 17.202), train_loss = 0.86374911, grad/param norm = 1.4479e-01, time/batch = 0.6997s	
11406/33150 (epoch 17.204), train_loss = 1.08979205, grad/param norm = 1.5410e-01, time/batch = 0.7024s	
11407/33150 (epoch 17.205), train_loss = 1.15236310, grad/param norm = 1.6299e-01, time/batch = 0.7057s	
11408/33150 (epoch 17.207), train_loss = 1.11011523, grad/param norm = 1.4754e-01, time/batch = 0.6876s	
11409/33150 (epoch 17.208), train_loss = 1.13299823, grad/param norm = 1.5948e-01, time/batch = 0.6781s	
11410/33150 (epoch 17.210), train_loss = 0.97617142, grad/param norm = 1.3256e-01, time/batch = 0.6979s	
11411/33150 (epoch 17.211), train_loss = 1.11705765, grad/param norm = 1.7602e-01, time/batch = 0.6824s	
11412/33150 (epoch 17.213), train_loss = 1.13739320, grad/param norm = 1.5242e-01, time/batch = 0.6754s	
11413/33150 (epoch 17.214), train_loss = 1.05014258, grad/param norm = 1.4721e-01, time/batch = 0.6814s	
11414/33150 (epoch 17.216), train_loss = 0.99327277, grad/param norm = 1.4964e-01, time/batch = 0.6728s	
11415/33150 (epoch 17.217), train_loss = 1.00772329, grad/param norm = 1.3422e-01, time/batch = 0.6708s	
11416/33150 (epoch 17.219), train_loss = 0.94589868, grad/param norm = 1.3667e-01, time/batch = 0.6800s	
11417/33150 (epoch 17.220), train_loss = 0.98739237, grad/param norm = 1.3085e-01, time/batch = 0.6746s	
11418/33150 (epoch 17.222), train_loss = 1.16753592, grad/param norm = 1.5153e-01, time/batch = 0.6712s	
11419/33150 (epoch 17.223), train_loss = 1.07223707, grad/param norm = 1.6601e-01, time/batch = 0.6739s	
11420/33150 (epoch 17.225), train_loss = 1.22038602, grad/param norm = 1.5723e-01, time/batch = 0.6702s	
11421/33150 (epoch 17.226), train_loss = 1.03706432, grad/param norm = 1.4388e-01, time/batch = 0.6718s	
11422/33150 (epoch 17.228), train_loss = 1.05538642, grad/param norm = 1.4626e-01, time/batch = 0.6697s	
11423/33150 (epoch 17.229), train_loss = 1.04404449, grad/param norm = 1.4113e-01, time/batch = 0.6711s	
11424/33150 (epoch 17.231), train_loss = 1.20350703, grad/param norm = 1.6087e-01, time/batch = 0.6742s	
11425/33150 (epoch 17.232), train_loss = 1.10762477, grad/param norm = 1.9610e-01, time/batch = 0.6793s	
11426/33150 (epoch 17.234), train_loss = 1.08030698, grad/param norm = 1.7683e-01, time/batch = 0.6754s	
11427/33150 (epoch 17.235), train_loss = 1.10419789, grad/param norm = 1.7569e-01, time/batch = 0.6737s	
11428/33150 (epoch 17.237), train_loss = 1.07176865, grad/param norm = 1.8710e-01, time/batch = 0.6712s	
11429/33150 (epoch 17.238), train_loss = 1.14161550, grad/param norm = 1.9306e-01, time/batch = 0.6738s	
11430/33150 (epoch 17.240), train_loss = 1.12094935, grad/param norm = 1.5837e-01, time/batch = 0.6752s	
11431/33150 (epoch 17.241), train_loss = 1.20981615, grad/param norm = 1.6165e-01, time/batch = 0.6735s	
11432/33150 (epoch 17.243), train_loss = 1.17033077, grad/param norm = 1.7562e-01, time/batch = 0.6769s	
11433/33150 (epoch 17.244), train_loss = 1.03837052, grad/param norm = 1.3319e-01, time/batch = 0.6763s	
11434/33150 (epoch 17.246), train_loss = 1.13372594, grad/param norm = 1.4750e-01, time/batch = 0.6732s	
11435/33150 (epoch 17.247), train_loss = 1.01968942, grad/param norm = 1.5330e-01, time/batch = 0.6742s	
11436/33150 (epoch 17.249), train_loss = 1.15038736, grad/param norm = 1.4668e-01, time/batch = 0.6694s	
11437/33150 (epoch 17.250), train_loss = 1.12854995, grad/param norm = 1.3369e-01, time/batch = 0.6702s	
11438/33150 (epoch 17.252), train_loss = 1.13092142, grad/param norm = 1.3071e-01, time/batch = 0.6753s	
11439/33150 (epoch 17.253), train_loss = 1.08326668, grad/param norm = 1.5061e-01, time/batch = 0.6761s	
11440/33150 (epoch 17.255), train_loss = 1.05859744, grad/param norm = 1.4237e-01, time/batch = 0.6730s	
11441/33150 (epoch 17.256), train_loss = 1.12706579, grad/param norm = 1.4176e-01, time/batch = 0.6737s	
11442/33150 (epoch 17.258), train_loss = 1.02404415, grad/param norm = 1.5346e-01, time/batch = 0.6741s	
11443/33150 (epoch 17.259), train_loss = 0.89992079, grad/param norm = 1.5181e-01, time/batch = 0.7011s	
11444/33150 (epoch 17.261), train_loss = 0.93453149, grad/param norm = 1.3494e-01, time/batch = 0.6939s	
11445/33150 (epoch 17.262), train_loss = 1.13565933, grad/param norm = 1.6357e-01, time/batch = 0.6835s	
11446/33150 (epoch 17.264), train_loss = 0.85672908, grad/param norm = 1.3853e-01, time/batch = 0.6767s	
11447/33150 (epoch 17.265), train_loss = 1.11958521, grad/param norm = 1.4896e-01, time/batch = 0.6840s	
11448/33150 (epoch 17.267), train_loss = 1.14742258, grad/param norm = 1.7259e-01, time/batch = 0.6772s	
11449/33150 (epoch 17.268), train_loss = 1.14947994, grad/param norm = 1.4455e-01, time/batch = 0.6744s	
11450/33150 (epoch 17.270), train_loss = 1.25320370, grad/param norm = 1.5901e-01, time/batch = 0.6749s	
11451/33150 (epoch 17.271), train_loss = 1.21350792, grad/param norm = 1.5440e-01, time/batch = 0.6754s	
11452/33150 (epoch 17.273), train_loss = 1.20623563, grad/param norm = 1.5660e-01, time/batch = 0.6779s	
11453/33150 (epoch 17.275), train_loss = 1.22188909, grad/param norm = 1.6184e-01, time/batch = 0.6722s	
11454/33150 (epoch 17.276), train_loss = 1.07495364, grad/param norm = 1.5035e-01, time/batch = 0.6750s	
11455/33150 (epoch 17.278), train_loss = 1.14783127, grad/param norm = 1.6247e-01, time/batch = 0.6720s	
11456/33150 (epoch 17.279), train_loss = 1.13004968, grad/param norm = 1.4683e-01, time/batch = 0.6718s	
11457/33150 (epoch 17.281), train_loss = 1.10376805, grad/param norm = 1.4820e-01, time/batch = 0.6712s	
11458/33150 (epoch 17.282), train_loss = 1.08920405, grad/param norm = 1.4174e-01, time/batch = 0.6721s	
11459/33150 (epoch 17.284), train_loss = 1.01204642, grad/param norm = 1.3641e-01, time/batch = 0.6799s	
11460/33150 (epoch 17.285), train_loss = 1.10588709, grad/param norm = 1.4145e-01, time/batch = 0.6971s	
11461/33150 (epoch 17.287), train_loss = 1.00112342, grad/param norm = 1.4088e-01, time/batch = 0.6968s	
11462/33150 (epoch 17.288), train_loss = 1.22550878, grad/param norm = 1.5284e-01, time/batch = 0.6958s	
11463/33150 (epoch 17.290), train_loss = 0.92341703, grad/param norm = 1.5131e-01, time/batch = 0.7094s	
11464/33150 (epoch 17.291), train_loss = 0.89338730, grad/param norm = 1.3798e-01, time/batch = 0.7061s	
11465/33150 (epoch 17.293), train_loss = 1.13428632, grad/param norm = 1.4760e-01, time/batch = 0.7032s	
11466/33150 (epoch 17.294), train_loss = 0.81065459, grad/param norm = 1.2811e-01, time/batch = 0.7032s	
11467/33150 (epoch 17.296), train_loss = 1.05260619, grad/param norm = 1.4877e-01, time/batch = 0.7083s	
11468/33150 (epoch 17.297), train_loss = 1.01257400, grad/param norm = 1.4323e-01, time/batch = 0.7041s	
11469/33150 (epoch 17.299), train_loss = 1.01949243, grad/param norm = 1.8024e-01, time/batch = 0.7056s	
11470/33150 (epoch 17.300), train_loss = 1.00880840, grad/param norm = 1.4053e-01, time/batch = 0.6899s	
11471/33150 (epoch 17.302), train_loss = 1.01714061, grad/param norm = 1.3580e-01, time/batch = 0.6694s	
11472/33150 (epoch 17.303), train_loss = 1.04603550, grad/param norm = 1.6544e-01, time/batch = 0.6731s	
11473/33150 (epoch 17.305), train_loss = 1.13860190, grad/param norm = 1.5437e-01, time/batch = 0.6707s	
11474/33150 (epoch 17.306), train_loss = 1.11540884, grad/param norm = 1.7212e-01, time/batch = 0.6691s	
11475/33150 (epoch 17.308), train_loss = 1.29920650, grad/param norm = 1.6377e-01, time/batch = 0.6693s	
11476/33150 (epoch 17.309), train_loss = 0.90950822, grad/param norm = 1.3435e-01, time/batch = 0.6726s	
11477/33150 (epoch 17.311), train_loss = 1.03830754, grad/param norm = 1.7916e-01, time/batch = 0.6710s	
11478/33150 (epoch 17.312), train_loss = 0.86281599, grad/param norm = 1.4637e-01, time/batch = 0.6697s	
11479/33150 (epoch 17.314), train_loss = 1.02810435, grad/param norm = 1.5145e-01, time/batch = 0.6715s	
11480/33150 (epoch 17.315), train_loss = 1.10394194, grad/param norm = 1.5929e-01, time/batch = 0.6694s	
11481/33150 (epoch 17.317), train_loss = 0.83733416, grad/param norm = 1.1743e-01, time/batch = 0.6689s	
11482/33150 (epoch 17.318), train_loss = 0.95408140, grad/param norm = 1.2830e-01, time/batch = 0.6705s	
11483/33150 (epoch 17.320), train_loss = 0.92160095, grad/param norm = 1.3406e-01, time/batch = 0.6704s	
11484/33150 (epoch 17.321), train_loss = 1.00647335, grad/param norm = 1.3608e-01, time/batch = 0.6696s	
11485/33150 (epoch 17.323), train_loss = 1.06921137, grad/param norm = 1.5343e-01, time/batch = 0.6707s	
11486/33150 (epoch 17.324), train_loss = 1.15149149, grad/param norm = 1.7532e-01, time/batch = 0.6727s	
11487/33150 (epoch 17.326), train_loss = 1.08757264, grad/param norm = 1.3911e-01, time/batch = 0.6775s	
11488/33150 (epoch 17.327), train_loss = 1.19308169, grad/param norm = 1.5274e-01, time/batch = 0.6806s	
11489/33150 (epoch 17.329), train_loss = 1.11496454, grad/param norm = 1.4908e-01, time/batch = 0.6780s	
11490/33150 (epoch 17.330), train_loss = 1.08005492, grad/param norm = 1.7031e-01, time/batch = 0.6712s	
11491/33150 (epoch 17.332), train_loss = 1.04705477, grad/param norm = 1.3628e-01, time/batch = 0.6803s	
11492/33150 (epoch 17.333), train_loss = 1.10621242, grad/param norm = 1.4409e-01, time/batch = 0.6930s	
11493/33150 (epoch 17.335), train_loss = 1.00941953, grad/param norm = 1.5200e-01, time/batch = 0.6887s	
11494/33150 (epoch 17.336), train_loss = 0.98752359, grad/param norm = 1.5465e-01, time/batch = 0.6827s	
11495/33150 (epoch 17.338), train_loss = 0.87973777, grad/param norm = 1.3717e-01, time/batch = 0.6822s	
11496/33150 (epoch 17.339), train_loss = 1.16310410, grad/param norm = 1.5785e-01, time/batch = 0.6899s	
11497/33150 (epoch 17.341), train_loss = 1.16523879, grad/param norm = 1.8344e-01, time/batch = 0.6745s	
11498/33150 (epoch 17.342), train_loss = 0.95284826, grad/param norm = 1.5286e-01, time/batch = 0.6720s	
11499/33150 (epoch 17.344), train_loss = 1.08686033, grad/param norm = 1.5984e-01, time/batch = 0.6716s	
11500/33150 (epoch 17.345), train_loss = 1.02462516, grad/param norm = 1.4271e-01, time/batch = 0.6736s	
11501/33150 (epoch 17.347), train_loss = 0.85978746, grad/param norm = 1.2685e-01, time/batch = 0.6733s	
11502/33150 (epoch 17.348), train_loss = 1.09802162, grad/param norm = 1.5880e-01, time/batch = 0.6756s	
11503/33150 (epoch 17.350), train_loss = 0.99085806, grad/param norm = 1.5709e-01, time/batch = 0.6829s	
11504/33150 (epoch 17.351), train_loss = 1.13503470, grad/param norm = 1.7010e-01, time/batch = 0.6680s	
11505/33150 (epoch 17.353), train_loss = 1.11446357, grad/param norm = 1.5339e-01, time/batch = 0.6700s	
11506/33150 (epoch 17.354), train_loss = 1.33740461, grad/param norm = 1.7388e-01, time/batch = 0.6742s	
11507/33150 (epoch 17.356), train_loss = 1.20547375, grad/param norm = 1.6496e-01, time/batch = 0.6726s	
11508/33150 (epoch 17.357), train_loss = 1.14144838, grad/param norm = 1.6388e-01, time/batch = 0.6767s	
11509/33150 (epoch 17.359), train_loss = 1.11453891, grad/param norm = 1.5830e-01, time/batch = 0.6713s	
11510/33150 (epoch 17.360), train_loss = 1.15374304, grad/param norm = 1.7424e-01, time/batch = 0.6697s	
11511/33150 (epoch 17.362), train_loss = 1.15628860, grad/param norm = 1.5879e-01, time/batch = 0.6741s	
11512/33150 (epoch 17.363), train_loss = 1.09470537, grad/param norm = 1.4294e-01, time/batch = 0.6702s	
11513/33150 (epoch 17.365), train_loss = 1.06110188, grad/param norm = 1.4228e-01, time/batch = 0.6766s	
11514/33150 (epoch 17.367), train_loss = 0.98179414, grad/param norm = 1.4145e-01, time/batch = 0.6718s	
11515/33150 (epoch 17.368), train_loss = 1.06400435, grad/param norm = 1.6872e-01, time/batch = 0.6733s	
11516/33150 (epoch 17.370), train_loss = 1.09206572, grad/param norm = 1.8125e-01, time/batch = 0.6761s	
11517/33150 (epoch 17.371), train_loss = 0.95977674, grad/param norm = 1.3920e-01, time/batch = 0.6770s	
11518/33150 (epoch 17.373), train_loss = 1.12426539, grad/param norm = 1.5108e-01, time/batch = 0.6711s	
11519/33150 (epoch 17.374), train_loss = 1.03777986, grad/param norm = 1.4226e-01, time/batch = 0.6813s	
11520/33150 (epoch 17.376), train_loss = 1.20601447, grad/param norm = 1.5852e-01, time/batch = 0.6700s	
11521/33150 (epoch 17.377), train_loss = 1.01224186, grad/param norm = 1.6084e-01, time/batch = 0.6677s	
11522/33150 (epoch 17.379), train_loss = 1.15547974, grad/param norm = 1.5637e-01, time/batch = 0.6630s	
11523/33150 (epoch 17.380), train_loss = 1.15199960, grad/param norm = 1.4847e-01, time/batch = 0.6683s	
11524/33150 (epoch 17.382), train_loss = 0.99829380, grad/param norm = 1.6282e-01, time/batch = 0.6674s	
11525/33150 (epoch 17.383), train_loss = 0.98324062, grad/param norm = 1.4457e-01, time/batch = 0.6668s	
11526/33150 (epoch 17.385), train_loss = 1.04757262, grad/param norm = 1.4517e-01, time/batch = 0.6690s	
11527/33150 (epoch 17.386), train_loss = 0.91740244, grad/param norm = 1.2725e-01, time/batch = 0.6707s	
11528/33150 (epoch 17.388), train_loss = 1.01570138, grad/param norm = 1.3630e-01, time/batch = 0.6706s	
11529/33150 (epoch 17.389), train_loss = 0.99333956, grad/param norm = 1.3179e-01, time/batch = 0.6697s	
11530/33150 (epoch 17.391), train_loss = 1.23641671, grad/param norm = 1.5987e-01, time/batch = 0.6687s	
11531/33150 (epoch 17.392), train_loss = 1.01145207, grad/param norm = 1.3389e-01, time/batch = 0.6692s	
11532/33150 (epoch 17.394), train_loss = 0.92087815, grad/param norm = 1.2404e-01, time/batch = 0.6691s	
11533/33150 (epoch 17.395), train_loss = 0.93972479, grad/param norm = 1.7168e-01, time/batch = 0.6709s	
11534/33150 (epoch 17.397), train_loss = 0.77183398, grad/param norm = 1.3622e-01, time/batch = 0.6758s	
11535/33150 (epoch 17.398), train_loss = 1.09058393, grad/param norm = 1.7061e-01, time/batch = 0.6770s	
11536/33150 (epoch 17.400), train_loss = 0.99365270, grad/param norm = 1.2656e-01, time/batch = 0.6736s	
11537/33150 (epoch 17.401), train_loss = 0.88381342, grad/param norm = 1.2447e-01, time/batch = 0.6677s	
11538/33150 (epoch 17.403), train_loss = 0.95016352, grad/param norm = 1.3530e-01, time/batch = 0.6723s	
11539/33150 (epoch 17.404), train_loss = 1.04601449, grad/param norm = 1.4254e-01, time/batch = 0.6658s	
11540/33150 (epoch 17.406), train_loss = 0.96431427, grad/param norm = 1.1733e-01, time/batch = 0.6702s	
11541/33150 (epoch 17.407), train_loss = 0.92035419, grad/param norm = 1.4061e-01, time/batch = 0.6705s	
11542/33150 (epoch 17.409), train_loss = 0.84734847, grad/param norm = 1.3000e-01, time/batch = 0.6729s	
11543/33150 (epoch 17.410), train_loss = 1.07823614, grad/param norm = 1.5148e-01, time/batch = 0.6722s	
11544/33150 (epoch 17.412), train_loss = 1.09787982, grad/param norm = 1.4845e-01, time/batch = 0.6730s	
11545/33150 (epoch 17.413), train_loss = 0.99033612, grad/param norm = 1.3979e-01, time/batch = 0.6727s	
11546/33150 (epoch 17.415), train_loss = 1.13090939, grad/param norm = 1.4663e-01, time/batch = 0.6720s	
11547/33150 (epoch 17.416), train_loss = 0.97869839, grad/param norm = 1.3479e-01, time/batch = 0.6719s	
11548/33150 (epoch 17.418), train_loss = 1.19971775, grad/param norm = 2.0900e-01, time/batch = 0.6767s	
11549/33150 (epoch 17.419), train_loss = 0.98865440, grad/param norm = 1.5617e-01, time/batch = 0.6719s	
11550/33150 (epoch 17.421), train_loss = 1.07442838, grad/param norm = 1.7832e-01, time/batch = 0.6762s	
11551/33150 (epoch 17.422), train_loss = 1.00981781, grad/param norm = 1.4230e-01, time/batch = 0.6742s	
11552/33150 (epoch 17.424), train_loss = 0.99677670, grad/param norm = 1.5050e-01, time/batch = 0.6719s	
11553/33150 (epoch 17.425), train_loss = 1.08719482, grad/param norm = 1.4358e-01, time/batch = 0.6736s	
11554/33150 (epoch 17.427), train_loss = 1.04549574, grad/param norm = 1.3951e-01, time/batch = 0.6725s	
11555/33150 (epoch 17.428), train_loss = 1.05962938, grad/param norm = 1.5684e-01, time/batch = 0.6747s	
11556/33150 (epoch 17.430), train_loss = 1.06664905, grad/param norm = 1.5191e-01, time/batch = 0.6729s	
11557/33150 (epoch 17.431), train_loss = 1.14346424, grad/param norm = 1.8023e-01, time/batch = 0.6758s	
11558/33150 (epoch 17.433), train_loss = 1.05590203, grad/param norm = 1.4498e-01, time/batch = 0.6708s	
11559/33150 (epoch 17.434), train_loss = 0.93604061, grad/param norm = 1.5212e-01, time/batch = 0.6707s	
11560/33150 (epoch 17.436), train_loss = 0.98855020, grad/param norm = 1.4994e-01, time/batch = 0.6703s	
11561/33150 (epoch 17.437), train_loss = 1.06825606, grad/param norm = 1.7758e-01, time/batch = 0.6702s	
11562/33150 (epoch 17.439), train_loss = 1.18133818, grad/param norm = 1.6236e-01, time/batch = 0.6689s	
11563/33150 (epoch 17.440), train_loss = 1.15277092, grad/param norm = 1.6299e-01, time/batch = 0.6707s	
11564/33150 (epoch 17.442), train_loss = 0.92594298, grad/param norm = 1.3175e-01, time/batch = 0.6664s	
11565/33150 (epoch 17.443), train_loss = 1.12168993, grad/param norm = 1.4969e-01, time/batch = 0.6711s	
11566/33150 (epoch 17.445), train_loss = 1.06443503, grad/param norm = 1.5515e-01, time/batch = 0.6796s	
11567/33150 (epoch 17.446), train_loss = 1.08116036, grad/param norm = 1.6765e-01, time/batch = 0.6754s	
11568/33150 (epoch 17.448), train_loss = 1.15147666, grad/param norm = 1.5790e-01, time/batch = 0.6719s	
11569/33150 (epoch 17.449), train_loss = 1.06143415, grad/param norm = 1.3542e-01, time/batch = 0.6694s	
11570/33150 (epoch 17.451), train_loss = 1.12052079, grad/param norm = 1.6689e-01, time/batch = 0.6674s	
11571/33150 (epoch 17.452), train_loss = 1.30527281, grad/param norm = 1.5967e-01, time/batch = 0.6679s	
11572/33150 (epoch 17.454), train_loss = 1.04124927, grad/param norm = 1.4200e-01, time/batch = 0.6684s	
11573/33150 (epoch 17.456), train_loss = 0.92086803, grad/param norm = 1.3054e-01, time/batch = 0.6687s	
11574/33150 (epoch 17.457), train_loss = 1.07815575, grad/param norm = 1.5745e-01, time/batch = 0.6667s	
11575/33150 (epoch 17.459), train_loss = 1.19657594, grad/param norm = 2.4670e-01, time/batch = 0.6654s	
11576/33150 (epoch 17.460), train_loss = 1.09400919, grad/param norm = 1.3241e-01, time/batch = 0.6660s	
11577/33150 (epoch 17.462), train_loss = 1.17034272, grad/param norm = 1.8776e-01, time/batch = 0.6655s	
11578/33150 (epoch 17.463), train_loss = 1.33752984, grad/param norm = 1.7918e-01, time/batch = 0.6671s	
11579/33150 (epoch 17.465), train_loss = 1.00776850, grad/param norm = 1.3958e-01, time/batch = 0.6681s	
11580/33150 (epoch 17.466), train_loss = 0.97799840, grad/param norm = 1.3434e-01, time/batch = 0.6839s	
11581/33150 (epoch 17.468), train_loss = 1.33509480, grad/param norm = 1.6256e-01, time/batch = 0.6935s	
11582/33150 (epoch 17.469), train_loss = 1.07572985, grad/param norm = 1.6897e-01, time/batch = 0.6877s	
11583/33150 (epoch 17.471), train_loss = 1.00590572, grad/param norm = 1.3869e-01, time/batch = 0.7066s	
11584/33150 (epoch 17.472), train_loss = 1.06393924, grad/param norm = 1.3809e-01, time/batch = 0.6785s	
11585/33150 (epoch 17.474), train_loss = 1.18214153, grad/param norm = 1.9017e-01, time/batch = 0.6848s	
11586/33150 (epoch 17.475), train_loss = 1.33655355, grad/param norm = 1.6180e-01, time/batch = 0.6777s	
11587/33150 (epoch 17.477), train_loss = 1.17448338, grad/param norm = 1.7381e-01, time/batch = 0.6950s	
11588/33150 (epoch 17.478), train_loss = 1.15400984, grad/param norm = 1.4745e-01, time/batch = 0.6824s	
11589/33150 (epoch 17.480), train_loss = 1.01733324, grad/param norm = 1.4418e-01, time/batch = 0.6738s	
11590/33150 (epoch 17.481), train_loss = 0.90667220, grad/param norm = 1.3778e-01, time/batch = 0.6696s	
11591/33150 (epoch 17.483), train_loss = 1.01093156, grad/param norm = 1.3966e-01, time/batch = 0.6695s	
11592/33150 (epoch 17.484), train_loss = 1.01686591, grad/param norm = 1.4857e-01, time/batch = 0.6698s	
11593/33150 (epoch 17.486), train_loss = 1.04129052, grad/param norm = 1.6475e-01, time/batch = 0.6677s	
11594/33150 (epoch 17.487), train_loss = 1.09097525, grad/param norm = 1.5424e-01, time/batch = 0.6688s	
11595/33150 (epoch 17.489), train_loss = 1.08310493, grad/param norm = 1.5705e-01, time/batch = 0.6680s	
11596/33150 (epoch 17.490), train_loss = 0.90109834, grad/param norm = 1.3730e-01, time/batch = 0.6692s	
11597/33150 (epoch 17.492), train_loss = 0.99145946, grad/param norm = 1.5476e-01, time/batch = 0.6696s	
11598/33150 (epoch 17.493), train_loss = 1.16576064, grad/param norm = 1.6214e-01, time/batch = 0.6664s	
11599/33150 (epoch 17.495), train_loss = 1.18795245, grad/param norm = 1.5281e-01, time/batch = 0.6733s	
11600/33150 (epoch 17.496), train_loss = 1.00328085, grad/param norm = 1.4722e-01, time/batch = 0.6696s	
11601/33150 (epoch 17.498), train_loss = 1.19404882, grad/param norm = 1.7938e-01, time/batch = 0.6709s	
11602/33150 (epoch 17.499), train_loss = 1.19460149, grad/param norm = 1.5154e-01, time/batch = 0.6748s	
11603/33150 (epoch 17.501), train_loss = 1.12175164, grad/param norm = 1.5488e-01, time/batch = 0.6720s	
11604/33150 (epoch 17.502), train_loss = 1.21233938, grad/param norm = 1.6870e-01, time/batch = 0.6683s	
11605/33150 (epoch 17.504), train_loss = 1.13640995, grad/param norm = 1.6310e-01, time/batch = 0.6700s	
11606/33150 (epoch 17.505), train_loss = 1.26902015, grad/param norm = 1.7962e-01, time/batch = 0.6731s	
11607/33150 (epoch 17.507), train_loss = 1.02813171, grad/param norm = 1.4826e-01, time/batch = 0.6860s	
11608/33150 (epoch 17.508), train_loss = 1.04002127, grad/param norm = 1.5644e-01, time/batch = 0.6811s	
11609/33150 (epoch 17.510), train_loss = 1.09597859, grad/param norm = 1.5637e-01, time/batch = 0.6871s	
11610/33150 (epoch 17.511), train_loss = 1.24508805, grad/param norm = 1.6739e-01, time/batch = 0.6897s	
11611/33150 (epoch 17.513), train_loss = 1.09718473, grad/param norm = 1.6889e-01, time/batch = 0.6913s	
11612/33150 (epoch 17.514), train_loss = 0.89096786, grad/param norm = 1.4937e-01, time/batch = 0.6876s	
11613/33150 (epoch 17.516), train_loss = 1.18010565, grad/param norm = 1.8975e-01, time/batch = 0.6810s	
11614/33150 (epoch 17.517), train_loss = 1.18481389, grad/param norm = 1.5323e-01, time/batch = 0.6874s	
11615/33150 (epoch 17.519), train_loss = 0.98732494, grad/param norm = 1.4349e-01, time/batch = 0.6874s	
11616/33150 (epoch 17.520), train_loss = 1.09506613, grad/param norm = 1.4249e-01, time/batch = 0.6787s	
11617/33150 (epoch 17.522), train_loss = 1.24351320, grad/param norm = 1.9116e-01, time/batch = 0.6855s	
11618/33150 (epoch 17.523), train_loss = 1.00006739, grad/param norm = 1.4075e-01, time/batch = 0.6712s	
11619/33150 (epoch 17.525), train_loss = 1.14117841, grad/param norm = 1.5980e-01, time/batch = 0.6695s	
11620/33150 (epoch 17.526), train_loss = 1.00894528, grad/param norm = 1.7450e-01, time/batch = 0.6732s	
11621/33150 (epoch 17.528), train_loss = 1.12211053, grad/param norm = 1.6173e-01, time/batch = 0.6734s	
11622/33150 (epoch 17.529), train_loss = 1.06104410, grad/param norm = 1.4458e-01, time/batch = 0.6691s	
11623/33150 (epoch 17.531), train_loss = 0.90590337, grad/param norm = 1.5290e-01, time/batch = 0.6729s	
11624/33150 (epoch 17.532), train_loss = 1.09853191, grad/param norm = 1.4430e-01, time/batch = 0.6776s	
11625/33150 (epoch 17.534), train_loss = 1.02865395, grad/param norm = 1.2659e-01, time/batch = 0.6735s	
11626/33150 (epoch 17.535), train_loss = 0.99048540, grad/param norm = 1.5709e-01, time/batch = 0.6747s	
11627/33150 (epoch 17.537), train_loss = 1.16425411, grad/param norm = 1.6088e-01, time/batch = 0.6725s	
11628/33150 (epoch 17.538), train_loss = 1.01508850, grad/param norm = 1.4392e-01, time/batch = 0.6719s	
11629/33150 (epoch 17.540), train_loss = 0.93309844, grad/param norm = 1.4506e-01, time/batch = 0.6762s	
11630/33150 (epoch 17.541), train_loss = 1.16268277, grad/param norm = 1.6991e-01, time/batch = 0.6801s	
11631/33150 (epoch 17.543), train_loss = 1.10652426, grad/param norm = 1.4993e-01, time/batch = 0.6731s	
11632/33150 (epoch 17.544), train_loss = 1.10576218, grad/param norm = 1.5041e-01, time/batch = 0.6919s	
11633/33150 (epoch 17.546), train_loss = 1.15177768, grad/param norm = 1.6500e-01, time/batch = 0.6865s	
11634/33150 (epoch 17.548), train_loss = 1.09179819, grad/param norm = 1.5679e-01, time/batch = 0.6717s	
11635/33150 (epoch 17.549), train_loss = 1.01513676, grad/param norm = 1.5095e-01, time/batch = 0.6784s	
11636/33150 (epoch 17.551), train_loss = 0.98617774, grad/param norm = 1.4434e-01, time/batch = 0.6909s	
11637/33150 (epoch 17.552), train_loss = 0.85092149, grad/param norm = 1.1658e-01, time/batch = 0.6729s	
11638/33150 (epoch 17.554), train_loss = 1.14967252, grad/param norm = 1.5661e-01, time/batch = 0.6725s	
11639/33150 (epoch 17.555), train_loss = 1.21996228, grad/param norm = 1.5896e-01, time/batch = 0.6751s	
11640/33150 (epoch 17.557), train_loss = 0.90293230, grad/param norm = 1.4520e-01, time/batch = 0.6751s	
11641/33150 (epoch 17.558), train_loss = 1.14640736, grad/param norm = 1.8552e-01, time/batch = 0.6824s	
11642/33150 (epoch 17.560), train_loss = 1.02332502, grad/param norm = 1.5155e-01, time/batch = 0.6844s	
11643/33150 (epoch 17.561), train_loss = 0.91081184, grad/param norm = 1.4935e-01, time/batch = 0.6720s	
11644/33150 (epoch 17.563), train_loss = 1.13224531, grad/param norm = 1.7847e-01, time/batch = 0.6749s	
11645/33150 (epoch 17.564), train_loss = 1.22532169, grad/param norm = 1.6289e-01, time/batch = 0.6787s	
11646/33150 (epoch 17.566), train_loss = 1.05596527, grad/param norm = 1.4945e-01, time/batch = 0.6912s	
11647/33150 (epoch 17.567), train_loss = 0.97138755, grad/param norm = 1.3962e-01, time/batch = 0.6773s	
11648/33150 (epoch 17.569), train_loss = 1.08760471, grad/param norm = 1.4152e-01, time/batch = 0.6729s	
11649/33150 (epoch 17.570), train_loss = 1.13043075, grad/param norm = 1.4840e-01, time/batch = 0.6714s	
11650/33150 (epoch 17.572), train_loss = 0.98715466, grad/param norm = 1.4277e-01, time/batch = 0.6796s	
11651/33150 (epoch 17.573), train_loss = 0.86302839, grad/param norm = 1.2507e-01, time/batch = 0.6768s	
11652/33150 (epoch 17.575), train_loss = 1.02901774, grad/param norm = 1.4505e-01, time/batch = 0.6706s	
11653/33150 (epoch 17.576), train_loss = 0.93296613, grad/param norm = 1.3355e-01, time/batch = 0.6722s	
11654/33150 (epoch 17.578), train_loss = 0.97707834, grad/param norm = 1.3963e-01, time/batch = 0.6734s	
11655/33150 (epoch 17.579), train_loss = 0.90110610, grad/param norm = 1.3591e-01, time/batch = 0.6724s	
11656/33150 (epoch 17.581), train_loss = 0.97964364, grad/param norm = 1.4441e-01, time/batch = 0.6725s	
11657/33150 (epoch 17.582), train_loss = 1.16614171, grad/param norm = 1.4341e-01, time/batch = 0.6712s	
11658/33150 (epoch 17.584), train_loss = 1.16589262, grad/param norm = 1.6957e-01, time/batch = 0.6678s	
11659/33150 (epoch 17.585), train_loss = 1.07440495, grad/param norm = 1.5345e-01, time/batch = 0.6720s	
11660/33150 (epoch 17.587), train_loss = 1.09434959, grad/param norm = 1.4725e-01, time/batch = 0.6781s	
11661/33150 (epoch 17.588), train_loss = 0.96568972, grad/param norm = 1.4428e-01, time/batch = 0.6900s	
11662/33150 (epoch 17.590), train_loss = 1.07534748, grad/param norm = 1.5296e-01, time/batch = 0.6778s	
11663/33150 (epoch 17.591), train_loss = 1.04296261, grad/param norm = 1.4689e-01, time/batch = 0.6772s	
11664/33150 (epoch 17.593), train_loss = 1.14676527, grad/param norm = 1.6246e-01, time/batch = 0.6732s	
11665/33150 (epoch 17.594), train_loss = 1.06236818, grad/param norm = 1.5447e-01, time/batch = 0.6724s	
11666/33150 (epoch 17.596), train_loss = 0.98655396, grad/param norm = 1.4319e-01, time/batch = 0.6731s	
11667/33150 (epoch 17.597), train_loss = 0.94036596, grad/param norm = 2.0717e-01, time/batch = 0.6749s	
11668/33150 (epoch 17.599), train_loss = 1.22270485, grad/param norm = 1.7764e-01, time/batch = 0.6842s	
11669/33150 (epoch 17.600), train_loss = 1.07836590, grad/param norm = 1.9163e-01, time/batch = 0.6939s	
11670/33150 (epoch 17.602), train_loss = 0.99757485, grad/param norm = 1.4087e-01, time/batch = 0.6952s	
11671/33150 (epoch 17.603), train_loss = 1.13492536, grad/param norm = 1.5667e-01, time/batch = 0.7074s	
11672/33150 (epoch 17.605), train_loss = 0.96004272, grad/param norm = 1.5327e-01, time/batch = 0.6807s	
11673/33150 (epoch 17.606), train_loss = 1.09398618, grad/param norm = 1.9893e-01, time/batch = 0.6779s	
11674/33150 (epoch 17.608), train_loss = 1.13964984, grad/param norm = 1.6311e-01, time/batch = 0.6841s	
11675/33150 (epoch 17.609), train_loss = 1.04256253, grad/param norm = 1.6002e-01, time/batch = 0.6928s	
11676/33150 (epoch 17.611), train_loss = 0.95475984, grad/param norm = 1.8116e-01, time/batch = 0.6939s	
11677/33150 (epoch 17.612), train_loss = 1.08966123, grad/param norm = 1.6805e-01, time/batch = 0.6944s	
11678/33150 (epoch 17.614), train_loss = 0.91848425, grad/param norm = 1.4576e-01, time/batch = 0.6848s	
11679/33150 (epoch 17.615), train_loss = 0.95429802, grad/param norm = 1.4243e-01, time/batch = 0.6844s	
11680/33150 (epoch 17.617), train_loss = 1.06411085, grad/param norm = 1.5864e-01, time/batch = 0.6768s	
11681/33150 (epoch 17.618), train_loss = 1.07877434, grad/param norm = 1.5792e-01, time/batch = 0.6833s	
11682/33150 (epoch 17.620), train_loss = 0.99204355, grad/param norm = 1.4511e-01, time/batch = 0.6793s	
11683/33150 (epoch 17.621), train_loss = 1.04529981, grad/param norm = 1.3826e-01, time/batch = 0.6778s	
11684/33150 (epoch 17.623), train_loss = 1.10746681, grad/param norm = 1.4510e-01, time/batch = 0.6803s	
11685/33150 (epoch 17.624), train_loss = 0.99096728, grad/param norm = 1.4777e-01, time/batch = 0.6748s	
11686/33150 (epoch 17.626), train_loss = 0.99602769, grad/param norm = 1.4217e-01, time/batch = 0.6756s	
11687/33150 (epoch 17.627), train_loss = 0.95299962, grad/param norm = 1.4728e-01, time/batch = 0.6862s	
11688/33150 (epoch 17.629), train_loss = 0.93632157, grad/param norm = 1.4483e-01, time/batch = 0.6814s	
11689/33150 (epoch 17.630), train_loss = 0.98490151, grad/param norm = 1.3333e-01, time/batch = 0.6788s	
11690/33150 (epoch 17.632), train_loss = 0.89729446, grad/param norm = 1.2079e-01, time/batch = 0.6971s	
11691/33150 (epoch 17.633), train_loss = 0.93894310, grad/param norm = 1.8756e-01, time/batch = 0.6733s	
11692/33150 (epoch 17.635), train_loss = 1.22575077, grad/param norm = 1.5906e-01, time/batch = 0.6704s	
11693/33150 (epoch 17.637), train_loss = 0.87780478, grad/param norm = 1.3961e-01, time/batch = 0.6728s	
11694/33150 (epoch 17.638), train_loss = 1.01302093, grad/param norm = 1.4262e-01, time/batch = 0.6732s	
11695/33150 (epoch 17.640), train_loss = 1.12842219, grad/param norm = 1.5985e-01, time/batch = 0.6762s	
11696/33150 (epoch 17.641), train_loss = 0.93159233, grad/param norm = 1.4034e-01, time/batch = 0.6750s	
11697/33150 (epoch 17.643), train_loss = 0.99187410, grad/param norm = 1.5433e-01, time/batch = 0.6760s	
11698/33150 (epoch 17.644), train_loss = 1.20263165, grad/param norm = 1.6197e-01, time/batch = 0.6767s	
11699/33150 (epoch 17.646), train_loss = 1.01183341, grad/param norm = 1.4646e-01, time/batch = 0.6762s	
11700/33150 (epoch 17.647), train_loss = 1.27675740, grad/param norm = 1.5818e-01, time/batch = 0.6745s	
11701/33150 (epoch 17.649), train_loss = 1.13474436, grad/param norm = 1.6406e-01, time/batch = 0.6736s	
11702/33150 (epoch 17.650), train_loss = 0.93843722, grad/param norm = 1.3072e-01, time/batch = 0.6737s	
11703/33150 (epoch 17.652), train_loss = 1.17445401, grad/param norm = 1.6881e-01, time/batch = 0.6741s	
11704/33150 (epoch 17.653), train_loss = 1.05439315, grad/param norm = 1.3661e-01, time/batch = 0.6785s	
11705/33150 (epoch 17.655), train_loss = 1.12307803, grad/param norm = 1.7484e-01, time/batch = 0.6836s	
11706/33150 (epoch 17.656), train_loss = 1.02541198, grad/param norm = 1.4330e-01, time/batch = 0.6696s	
11707/33150 (epoch 17.658), train_loss = 1.03558812, grad/param norm = 1.9032e-01, time/batch = 0.6706s	
11708/33150 (epoch 17.659), train_loss = 1.33797414, grad/param norm = 2.6427e-01, time/batch = 0.6699s	
11709/33150 (epoch 17.661), train_loss = 1.04331684, grad/param norm = 1.5624e-01, time/batch = 0.6693s	
11710/33150 (epoch 17.662), train_loss = 0.91737706, grad/param norm = 1.3668e-01, time/batch = 0.6696s	
11711/33150 (epoch 17.664), train_loss = 1.17817149, grad/param norm = 1.6333e-01, time/batch = 0.6732s	
11712/33150 (epoch 17.665), train_loss = 1.12626460, grad/param norm = 1.8399e-01, time/batch = 0.6751s	
11713/33150 (epoch 17.667), train_loss = 1.17945501, grad/param norm = 1.6458e-01, time/batch = 0.6725s	
11714/33150 (epoch 17.668), train_loss = 1.12770380, grad/param norm = 1.6192e-01, time/batch = 0.6734s	
11715/33150 (epoch 17.670), train_loss = 0.97924406, grad/param norm = 1.3498e-01, time/batch = 0.6737s	
11716/33150 (epoch 17.671), train_loss = 0.99182889, grad/param norm = 1.6243e-01, time/batch = 0.6707s	
11717/33150 (epoch 17.673), train_loss = 1.16708189, grad/param norm = 1.3929e-01, time/batch = 0.6718s	
11718/33150 (epoch 17.674), train_loss = 1.06325194, grad/param norm = 1.5340e-01, time/batch = 0.6693s	
11719/33150 (epoch 17.676), train_loss = 1.02995748, grad/param norm = 1.4557e-01, time/batch = 0.6805s	
11720/33150 (epoch 17.677), train_loss = 1.25834252, grad/param norm = 1.6200e-01, time/batch = 0.6791s	
11721/33150 (epoch 17.679), train_loss = 1.03605336, grad/param norm = 1.3661e-01, time/batch = 0.6730s	
11722/33150 (epoch 17.680), train_loss = 1.17920805, grad/param norm = 1.4605e-01, time/batch = 0.6747s	
11723/33150 (epoch 17.682), train_loss = 1.00805195, grad/param norm = 1.4419e-01, time/batch = 0.6730s	
11724/33150 (epoch 17.683), train_loss = 0.90221527, grad/param norm = 1.2675e-01, time/batch = 0.6753s	
11725/33150 (epoch 17.685), train_loss = 1.05374737, grad/param norm = 1.7285e-01, time/batch = 0.6745s	
11726/33150 (epoch 17.686), train_loss = 0.91171367, grad/param norm = 1.4515e-01, time/batch = 0.6723s	
11727/33150 (epoch 17.688), train_loss = 0.97276526, grad/param norm = 1.5276e-01, time/batch = 0.6791s	
11728/33150 (epoch 17.689), train_loss = 0.97925141, grad/param norm = 1.4483e-01, time/batch = 0.6712s	
11729/33150 (epoch 17.691), train_loss = 0.86331342, grad/param norm = 1.4154e-01, time/batch = 0.6724s	
11730/33150 (epoch 17.692), train_loss = 0.94832438, grad/param norm = 1.4595e-01, time/batch = 0.6722s	
11731/33150 (epoch 17.694), train_loss = 0.81672364, grad/param norm = 1.2222e-01, time/batch = 0.6745s	
11732/33150 (epoch 17.695), train_loss = 0.96069253, grad/param norm = 1.3061e-01, time/batch = 0.6712s	
11733/33150 (epoch 17.697), train_loss = 0.87884776, grad/param norm = 1.3730e-01, time/batch = 0.6712s	
11734/33150 (epoch 17.698), train_loss = 1.01726931, grad/param norm = 1.6192e-01, time/batch = 0.6697s	
11735/33150 (epoch 17.700), train_loss = 0.79221120, grad/param norm = 1.2291e-01, time/batch = 0.6692s	
11736/33150 (epoch 17.701), train_loss = 0.91954402, grad/param norm = 1.3896e-01, time/batch = 0.6717s	
11737/33150 (epoch 17.703), train_loss = 1.02242212, grad/param norm = 1.4370e-01, time/batch = 0.6702s	
11738/33150 (epoch 17.704), train_loss = 0.87651863, grad/param norm = 1.3029e-01, time/batch = 0.6815s	
11739/33150 (epoch 17.706), train_loss = 1.00023068, grad/param norm = 1.4145e-01, time/batch = 0.6984s	
11740/33150 (epoch 17.707), train_loss = 0.98229374, grad/param norm = 1.4597e-01, time/batch = 0.6808s	
11741/33150 (epoch 17.709), train_loss = 1.03700359, grad/param norm = 1.3129e-01, time/batch = 0.6747s	
11742/33150 (epoch 17.710), train_loss = 1.06681623, grad/param norm = 1.6575e-01, time/batch = 0.6814s	
11743/33150 (epoch 17.712), train_loss = 1.11222436, grad/param norm = 1.4476e-01, time/batch = 0.6786s	
11744/33150 (epoch 17.713), train_loss = 1.09097605, grad/param norm = 1.4652e-01, time/batch = 0.6952s	
11745/33150 (epoch 17.715), train_loss = 0.97722101, grad/param norm = 1.3467e-01, time/batch = 0.6692s	
11746/33150 (epoch 17.716), train_loss = 1.08410865, grad/param norm = 1.5608e-01, time/batch = 0.6659s	
11747/33150 (epoch 17.718), train_loss = 1.05871438, grad/param norm = 1.5246e-01, time/batch = 0.6833s	
11748/33150 (epoch 17.719), train_loss = 1.15115679, grad/param norm = 1.7283e-01, time/batch = 0.6904s	
11749/33150 (epoch 17.721), train_loss = 1.01817798, grad/param norm = 1.4911e-01, time/batch = 0.6915s	
11750/33150 (epoch 17.722), train_loss = 1.07193022, grad/param norm = 1.4886e-01, time/batch = 0.6789s	
11751/33150 (epoch 17.724), train_loss = 1.02327506, grad/param norm = 1.5880e-01, time/batch = 0.6945s	
11752/33150 (epoch 17.725), train_loss = 1.17209559, grad/param norm = 1.9440e-01, time/batch = 0.6919s	
11753/33150 (epoch 17.727), train_loss = 1.09477421, grad/param norm = 1.8129e-01, time/batch = 0.6847s	
11754/33150 (epoch 17.729), train_loss = 1.03551987, grad/param norm = 1.5430e-01, time/batch = 0.6839s	
11755/33150 (epoch 17.730), train_loss = 1.07337411, grad/param norm = 1.5586e-01, time/batch = 0.6679s	
11756/33150 (epoch 17.732), train_loss = 1.14431601, grad/param norm = 1.8018e-01, time/batch = 0.6794s	
11757/33150 (epoch 17.733), train_loss = 0.85442972, grad/param norm = 1.1976e-01, time/batch = 0.6908s	
11758/33150 (epoch 17.735), train_loss = 0.97147580, grad/param norm = 1.4591e-01, time/batch = 0.6807s	
11759/33150 (epoch 17.736), train_loss = 0.98846996, grad/param norm = 1.4760e-01, time/batch = 0.6930s	
11760/33150 (epoch 17.738), train_loss = 1.06484029, grad/param norm = 1.5540e-01, time/batch = 0.6669s	
11761/33150 (epoch 17.739), train_loss = 1.17748541, grad/param norm = 1.6903e-01, time/batch = 0.6668s	
11762/33150 (epoch 17.741), train_loss = 1.15639470, grad/param norm = 1.6514e-01, time/batch = 0.6650s	
11763/33150 (epoch 17.742), train_loss = 0.95962334, grad/param norm = 1.5203e-01, time/batch = 0.6699s	
11764/33150 (epoch 17.744), train_loss = 1.16906700, grad/param norm = 1.6104e-01, time/batch = 0.6667s	
11765/33150 (epoch 17.745), train_loss = 0.99698504, grad/param norm = 1.3611e-01, time/batch = 0.6653s	
11766/33150 (epoch 17.747), train_loss = 0.86800274, grad/param norm = 1.5445e-01, time/batch = 0.6684s	
11767/33150 (epoch 17.748), train_loss = 0.95560310, grad/param norm = 1.4273e-01, time/batch = 0.6708s	
11768/33150 (epoch 17.750), train_loss = 1.10583255, grad/param norm = 1.5597e-01, time/batch = 0.6909s	
11769/33150 (epoch 17.751), train_loss = 1.06700316, grad/param norm = 1.4385e-01, time/batch = 0.6734s	
11770/33150 (epoch 17.753), train_loss = 0.90395691, grad/param norm = 1.7729e-01, time/batch = 0.6693s	
11771/33150 (epoch 17.754), train_loss = 1.28754990, grad/param norm = 2.1266e-01, time/batch = 0.6724s	
11772/33150 (epoch 17.756), train_loss = 1.09908101, grad/param norm = 1.7764e-01, time/batch = 0.6902s	
11773/33150 (epoch 17.757), train_loss = 1.06282182, grad/param norm = 1.5596e-01, time/batch = 0.6932s	
11774/33150 (epoch 17.759), train_loss = 1.19953450, grad/param norm = 1.7242e-01, time/batch = 0.6811s	
11775/33150 (epoch 17.760), train_loss = 1.08222807, grad/param norm = 1.6867e-01, time/batch = 0.6717s	
11776/33150 (epoch 17.762), train_loss = 1.07296402, grad/param norm = 1.7432e-01, time/batch = 0.6681s	
11777/33150 (epoch 17.763), train_loss = 1.10028311, grad/param norm = 1.5317e-01, time/batch = 0.6766s	
11778/33150 (epoch 17.765), train_loss = 1.02778932, grad/param norm = 1.4124e-01, time/batch = 0.6957s	
11779/33150 (epoch 17.766), train_loss = 0.96941715, grad/param norm = 1.5614e-01, time/batch = 0.6884s	
11780/33150 (epoch 17.768), train_loss = 1.00020590, grad/param norm = 1.5292e-01, time/batch = 0.6691s	
11781/33150 (epoch 17.769), train_loss = 1.09313725, grad/param norm = 1.5543e-01, time/batch = 0.6776s	
11782/33150 (epoch 17.771), train_loss = 1.07991084, grad/param norm = 1.5378e-01, time/batch = 0.6818s	
11783/33150 (epoch 17.772), train_loss = 1.12000807, grad/param norm = 1.7380e-01, time/batch = 0.6843s	
11784/33150 (epoch 17.774), train_loss = 1.22102445, grad/param norm = 1.5381e-01, time/batch = 0.6681s	
11785/33150 (epoch 17.775), train_loss = 1.11212622, grad/param norm = 1.7787e-01, time/batch = 0.6674s	
11786/33150 (epoch 17.777), train_loss = 1.12059091, grad/param norm = 1.7164e-01, time/batch = 0.6683s	
11787/33150 (epoch 17.778), train_loss = 1.06441092, grad/param norm = 1.3199e-01, time/batch = 0.6691s	
11788/33150 (epoch 17.780), train_loss = 0.90849789, grad/param norm = 1.3573e-01, time/batch = 0.6706s	
11789/33150 (epoch 17.781), train_loss = 1.04758406, grad/param norm = 1.4419e-01, time/batch = 0.6686s	
11790/33150 (epoch 17.783), train_loss = 1.06529872, grad/param norm = 1.3608e-01, time/batch = 0.6668s	
11791/33150 (epoch 17.784), train_loss = 1.02853503, grad/param norm = 1.5686e-01, time/batch = 0.6673s	
11792/33150 (epoch 17.786), train_loss = 1.01865408, grad/param norm = 1.4029e-01, time/batch = 0.6719s	
11793/33150 (epoch 17.787), train_loss = 0.97678023, grad/param norm = 1.3827e-01, time/batch = 0.6726s	
11794/33150 (epoch 17.789), train_loss = 0.87092515, grad/param norm = 1.3436e-01, time/batch = 0.6653s	
11795/33150 (epoch 17.790), train_loss = 0.90246018, grad/param norm = 1.2264e-01, time/batch = 0.6690s	
11796/33150 (epoch 17.792), train_loss = 1.07998678, grad/param norm = 1.7415e-01, time/batch = 0.6709s	
11797/33150 (epoch 17.793), train_loss = 1.05085697, grad/param norm = 1.6141e-01, time/batch = 0.6803s	
11798/33150 (epoch 17.795), train_loss = 0.99265904, grad/param norm = 1.5970e-01, time/batch = 0.6818s	
11799/33150 (epoch 17.796), train_loss = 0.99351581, grad/param norm = 1.4099e-01, time/batch = 0.6746s	
11800/33150 (epoch 17.798), train_loss = 0.96502572, grad/param norm = 1.2690e-01, time/batch = 0.6715s	
11801/33150 (epoch 17.799), train_loss = 0.89265194, grad/param norm = 1.4498e-01, time/batch = 0.6703s	
11802/33150 (epoch 17.801), train_loss = 1.08055312, grad/param norm = 1.5345e-01, time/batch = 0.6720s	
11803/33150 (epoch 17.802), train_loss = 0.94399409, grad/param norm = 1.4804e-01, time/batch = 0.6720s	
11804/33150 (epoch 17.804), train_loss = 1.00021852, grad/param norm = 1.4203e-01, time/batch = 0.6718s	
11805/33150 (epoch 17.805), train_loss = 0.98650791, grad/param norm = 1.5001e-01, time/batch = 0.6710s	
11806/33150 (epoch 17.807), train_loss = 1.00205549, grad/param norm = 1.4254e-01, time/batch = 0.6698s	
11807/33150 (epoch 17.808), train_loss = 1.13232272, grad/param norm = 1.6216e-01, time/batch = 0.6718s	
11808/33150 (epoch 17.810), train_loss = 1.02550043, grad/param norm = 1.5170e-01, time/batch = 0.6695s	
11809/33150 (epoch 17.811), train_loss = 1.07171073, grad/param norm = 1.6815e-01, time/batch = 0.6681s	
11810/33150 (epoch 17.813), train_loss = 0.99907133, grad/param norm = 1.2905e-01, time/batch = 0.6687s	
11811/33150 (epoch 17.814), train_loss = 1.02846738, grad/param norm = 1.6634e-01, time/batch = 0.6695s	
11812/33150 (epoch 17.816), train_loss = 1.01358220, grad/param norm = 1.5540e-01, time/batch = 0.6854s	
11813/33150 (epoch 17.817), train_loss = 1.09570453, grad/param norm = 1.4657e-01, time/batch = 0.6760s	
11814/33150 (epoch 17.819), train_loss = 1.03649320, grad/param norm = 1.3511e-01, time/batch = 0.6677s	
11815/33150 (epoch 17.821), train_loss = 0.93332177, grad/param norm = 1.3931e-01, time/batch = 0.6702s	
11816/33150 (epoch 17.822), train_loss = 0.97193066, grad/param norm = 1.4326e-01, time/batch = 0.6692s	
11817/33150 (epoch 17.824), train_loss = 0.99475419, grad/param norm = 1.4830e-01, time/batch = 0.6714s	
11818/33150 (epoch 17.825), train_loss = 1.05097376, grad/param norm = 1.4801e-01, time/batch = 0.6672s	
11819/33150 (epoch 17.827), train_loss = 1.11812957, grad/param norm = 2.5156e-01, time/batch = 0.6693s	
11820/33150 (epoch 17.828), train_loss = 0.89924924, grad/param norm = 1.4189e-01, time/batch = 0.6707s	
11821/33150 (epoch 17.830), train_loss = 1.12140921, grad/param norm = 1.6439e-01, time/batch = 0.6667s	
11822/33150 (epoch 17.831), train_loss = 0.96966713, grad/param norm = 1.5716e-01, time/batch = 0.6725s	
11823/33150 (epoch 17.833), train_loss = 0.95696184, grad/param norm = 1.5224e-01, time/batch = 0.6701s	
11824/33150 (epoch 17.834), train_loss = 1.14736971, grad/param norm = 1.6180e-01, time/batch = 0.6670s	
11825/33150 (epoch 17.836), train_loss = 1.15345506, grad/param norm = 1.5099e-01, time/batch = 0.6715s	
11826/33150 (epoch 17.837), train_loss = 1.03164738, grad/param norm = 1.4506e-01, time/batch = 0.6672s	
11827/33150 (epoch 17.839), train_loss = 1.11504264, grad/param norm = 1.8099e-01, time/batch = 0.6675s	
11828/33150 (epoch 17.840), train_loss = 1.09903031, grad/param norm = 1.5521e-01, time/batch = 0.6704s	
11829/33150 (epoch 17.842), train_loss = 1.16216385, grad/param norm = 1.6701e-01, time/batch = 0.6735s	
11830/33150 (epoch 17.843), train_loss = 1.15709286, grad/param norm = 1.6076e-01, time/batch = 0.6764s	
11831/33150 (epoch 17.845), train_loss = 0.99099469, grad/param norm = 1.4021e-01, time/batch = 0.6887s	
11832/33150 (epoch 17.846), train_loss = 1.23250896, grad/param norm = 2.0094e-01, time/batch = 0.6886s	
11833/33150 (epoch 17.848), train_loss = 1.15112186, grad/param norm = 1.7043e-01, time/batch = 0.6737s	
11834/33150 (epoch 17.849), train_loss = 1.16625539, grad/param norm = 1.5915e-01, time/batch = 0.6721s	
11835/33150 (epoch 17.851), train_loss = 1.13129762, grad/param norm = 1.6596e-01, time/batch = 0.6723s	
11836/33150 (epoch 17.852), train_loss = 1.19922799, grad/param norm = 1.5221e-01, time/batch = 0.6692s	
11837/33150 (epoch 17.854), train_loss = 1.05403106, grad/param norm = 1.4270e-01, time/batch = 0.6780s	
11838/33150 (epoch 17.855), train_loss = 0.92033410, grad/param norm = 1.4362e-01, time/batch = 0.6739s	
11839/33150 (epoch 17.857), train_loss = 0.91059576, grad/param norm = 1.4661e-01, time/batch = 0.6709s	
11840/33150 (epoch 17.858), train_loss = 0.99722442, grad/param norm = 1.5149e-01, time/batch = 0.6827s	
11841/33150 (epoch 17.860), train_loss = 0.92705372, grad/param norm = 1.3771e-01, time/batch = 0.6773s	
11842/33150 (epoch 17.861), train_loss = 0.94064819, grad/param norm = 1.3649e-01, time/batch = 0.6688s	
11843/33150 (epoch 17.863), train_loss = 1.06449929, grad/param norm = 1.4655e-01, time/batch = 0.6687s	
11844/33150 (epoch 17.864), train_loss = 1.14684853, grad/param norm = 1.5252e-01, time/batch = 0.6737s	
11845/33150 (epoch 17.866), train_loss = 1.10221298, grad/param norm = 1.4706e-01, time/batch = 0.6888s	
11846/33150 (epoch 17.867), train_loss = 1.07412795, grad/param norm = 1.4292e-01, time/batch = 0.6901s	
11847/33150 (epoch 17.869), train_loss = 1.08243674, grad/param norm = 1.5647e-01, time/batch = 0.6945s	
11848/33150 (epoch 17.870), train_loss = 1.04660121, grad/param norm = 1.6413e-01, time/batch = 0.7041s	
11849/33150 (epoch 17.872), train_loss = 1.06271230, grad/param norm = 1.5754e-01, time/batch = 0.6755s	
11850/33150 (epoch 17.873), train_loss = 0.88305001, grad/param norm = 1.3169e-01, time/batch = 0.6743s	
11851/33150 (epoch 17.875), train_loss = 1.18689024, grad/param norm = 1.5924e-01, time/batch = 0.6899s	
11852/33150 (epoch 17.876), train_loss = 0.94380751, grad/param norm = 1.4839e-01, time/batch = 0.6887s	
11853/33150 (epoch 17.878), train_loss = 0.94736657, grad/param norm = 1.4204e-01, time/batch = 0.6724s	
11854/33150 (epoch 17.879), train_loss = 0.96955866, grad/param norm = 1.4611e-01, time/batch = 0.6720s	
11855/33150 (epoch 17.881), train_loss = 0.95988984, grad/param norm = 1.4341e-01, time/batch = 0.6698s	
11856/33150 (epoch 17.882), train_loss = 0.86249151, grad/param norm = 1.3019e-01, time/batch = 0.6802s	
11857/33150 (epoch 17.884), train_loss = 1.01232518, grad/param norm = 1.4283e-01, time/batch = 0.6836s	
11858/33150 (epoch 17.885), train_loss = 0.80844888, grad/param norm = 1.3127e-01, time/batch = 0.6691s	
11859/33150 (epoch 17.887), train_loss = 1.18828805, grad/param norm = 1.8628e-01, time/batch = 0.6842s	
11860/33150 (epoch 17.888), train_loss = 1.09224479, grad/param norm = 1.6437e-01, time/batch = 0.6935s	
11861/33150 (epoch 17.890), train_loss = 0.97001628, grad/param norm = 1.4936e-01, time/batch = 0.6865s	
11862/33150 (epoch 17.891), train_loss = 0.94166972, grad/param norm = 1.3496e-01, time/batch = 0.6698s	
11863/33150 (epoch 17.893), train_loss = 1.10672983, grad/param norm = 1.6116e-01, time/batch = 0.6697s	
11864/33150 (epoch 17.894), train_loss = 1.11389366, grad/param norm = 1.6301e-01, time/batch = 0.6713s	
11865/33150 (epoch 17.896), train_loss = 1.00507710, grad/param norm = 1.4306e-01, time/batch = 0.6686s	
11866/33150 (epoch 17.897), train_loss = 1.07210534, grad/param norm = 1.4016e-01, time/batch = 0.6730s	
11867/33150 (epoch 17.899), train_loss = 0.89724178, grad/param norm = 1.6191e-01, time/batch = 0.6789s	
11868/33150 (epoch 17.900), train_loss = 1.26916248, grad/param norm = 1.6344e-01, time/batch = 0.6730s	
11869/33150 (epoch 17.902), train_loss = 1.22933492, grad/param norm = 1.6258e-01, time/batch = 0.6740s	
11870/33150 (epoch 17.903), train_loss = 1.06436727, grad/param norm = 1.5403e-01, time/batch = 0.6755s	
11871/33150 (epoch 17.905), train_loss = 1.09083691, grad/param norm = 1.4020e-01, time/batch = 0.6765s	
11872/33150 (epoch 17.906), train_loss = 1.10636295, grad/param norm = 1.6933e-01, time/batch = 0.6781s	
11873/33150 (epoch 17.908), train_loss = 1.18262440, grad/param norm = 1.6257e-01, time/batch = 0.6734s	
11874/33150 (epoch 17.910), train_loss = 1.12223479, grad/param norm = 1.5833e-01, time/batch = 0.6771s	
11875/33150 (epoch 17.911), train_loss = 0.88174426, grad/param norm = 1.2631e-01, time/batch = 0.6764s	
11876/33150 (epoch 17.913), train_loss = 0.98698918, grad/param norm = 1.3827e-01, time/batch = 0.6754s	
11877/33150 (epoch 17.914), train_loss = 1.11589938, grad/param norm = 1.5819e-01, time/batch = 0.6754s	
11878/33150 (epoch 17.916), train_loss = 0.95890940, grad/param norm = 1.4919e-01, time/batch = 0.6720s	
11879/33150 (epoch 17.917), train_loss = 1.11965555, grad/param norm = 1.6800e-01, time/batch = 0.6673s	
11880/33150 (epoch 17.919), train_loss = 1.18829972, grad/param norm = 1.7912e-01, time/batch = 0.6703s	
11881/33150 (epoch 17.920), train_loss = 1.15739013, grad/param norm = 1.5156e-01, time/batch = 0.6744s	
11882/33150 (epoch 17.922), train_loss = 1.18455545, grad/param norm = 1.6867e-01, time/batch = 0.6727s	
11883/33150 (epoch 17.923), train_loss = 1.05846335, grad/param norm = 1.6439e-01, time/batch = 0.6718s	
11884/33150 (epoch 17.925), train_loss = 1.14913343, grad/param norm = 1.4938e-01, time/batch = 0.6823s	
11885/33150 (epoch 17.926), train_loss = 1.01959134, grad/param norm = 1.3943e-01, time/batch = 0.6838s	
11886/33150 (epoch 17.928), train_loss = 1.01034702, grad/param norm = 1.5003e-01, time/batch = 0.6885s	
11887/33150 (epoch 17.929), train_loss = 1.09505558, grad/param norm = 1.5255e-01, time/batch = 0.6770s	
11888/33150 (epoch 17.931), train_loss = 1.20791994, grad/param norm = 1.9224e-01, time/batch = 0.6765s	
11889/33150 (epoch 17.932), train_loss = 1.06733009, grad/param norm = 1.6965e-01, time/batch = 0.6840s	
11890/33150 (epoch 17.934), train_loss = 1.08539977, grad/param norm = 1.5120e-01, time/batch = 0.6917s	
11891/33150 (epoch 17.935), train_loss = 1.14875001, grad/param norm = 1.4858e-01, time/batch = 0.6825s	
11892/33150 (epoch 17.937), train_loss = 1.16069886, grad/param norm = 1.4156e-01, time/batch = 0.6734s	
11893/33150 (epoch 17.938), train_loss = 1.10368850, grad/param norm = 1.4922e-01, time/batch = 0.6750s	
11894/33150 (epoch 17.940), train_loss = 1.31432155, grad/param norm = 1.8161e-01, time/batch = 0.6803s	
11895/33150 (epoch 17.941), train_loss = 1.05295109, grad/param norm = 1.3722e-01, time/batch = 0.6763s	
11896/33150 (epoch 17.943), train_loss = 0.94591043, grad/param norm = 1.5407e-01, time/batch = 0.6715s	
11897/33150 (epoch 17.944), train_loss = 1.16294277, grad/param norm = 1.6305e-01, time/batch = 0.6678s	
11898/33150 (epoch 17.946), train_loss = 0.88985411, grad/param norm = 1.4507e-01, time/batch = 0.6695s	
11899/33150 (epoch 17.947), train_loss = 1.08316386, grad/param norm = 1.4477e-01, time/batch = 0.6688s	
11900/33150 (epoch 17.949), train_loss = 1.18315354, grad/param norm = 1.5524e-01, time/batch = 0.6696s	
11901/33150 (epoch 17.950), train_loss = 1.09324718, grad/param norm = 1.6583e-01, time/batch = 0.6691s	
11902/33150 (epoch 17.952), train_loss = 0.97310693, grad/param norm = 1.4405e-01, time/batch = 0.6683s	
11903/33150 (epoch 17.953), train_loss = 1.00916656, grad/param norm = 1.4005e-01, time/batch = 0.6694s	
11904/33150 (epoch 17.955), train_loss = 0.93064514, grad/param norm = 1.5595e-01, time/batch = 0.6714s	
11905/33150 (epoch 17.956), train_loss = 1.10509340, grad/param norm = 1.4789e-01, time/batch = 0.6727s	
11906/33150 (epoch 17.958), train_loss = 0.94743639, grad/param norm = 1.3374e-01, time/batch = 0.6699s	
11907/33150 (epoch 17.959), train_loss = 0.99321328, grad/param norm = 1.4796e-01, time/batch = 0.6713s	
11908/33150 (epoch 17.961), train_loss = 0.93671838, grad/param norm = 1.5064e-01, time/batch = 0.6716s	
11909/33150 (epoch 17.962), train_loss = 0.91715211, grad/param norm = 1.3583e-01, time/batch = 0.6703s	
11910/33150 (epoch 17.964), train_loss = 1.05339204, grad/param norm = 1.4188e-01, time/batch = 0.6714s	
11911/33150 (epoch 17.965), train_loss = 1.03942351, grad/param norm = 1.4008e-01, time/batch = 0.6767s	
11912/33150 (epoch 17.967), train_loss = 1.04032746, grad/param norm = 1.5267e-01, time/batch = 0.6725s	
11913/33150 (epoch 17.968), train_loss = 0.87786786, grad/param norm = 1.3040e-01, time/batch = 0.6706s	
11914/33150 (epoch 17.970), train_loss = 0.99049216, grad/param norm = 1.4230e-01, time/batch = 0.6710s	
11915/33150 (epoch 17.971), train_loss = 1.03972812, grad/param norm = 1.5388e-01, time/batch = 0.6761s	
11916/33150 (epoch 17.973), train_loss = 1.19504938, grad/param norm = 1.6561e-01, time/batch = 0.6737s	
11917/33150 (epoch 17.974), train_loss = 1.20444548, grad/param norm = 1.6052e-01, time/batch = 0.6705s	
11918/33150 (epoch 17.976), train_loss = 1.11277469, grad/param norm = 1.4069e-01, time/batch = 0.6708s	
11919/33150 (epoch 17.977), train_loss = 1.22489967, grad/param norm = 1.6777e-01, time/batch = 0.6704s	
11920/33150 (epoch 17.979), train_loss = 1.16666409, grad/param norm = 1.8108e-01, time/batch = 0.6698s	
11921/33150 (epoch 17.980), train_loss = 1.21645926, grad/param norm = 1.5923e-01, time/batch = 0.6725s	
11922/33150 (epoch 17.982), train_loss = 1.05304803, grad/param norm = 1.6775e-01, time/batch = 0.6714s	
11923/33150 (epoch 17.983), train_loss = 0.93300256, grad/param norm = 1.5082e-01, time/batch = 0.6682s	
11924/33150 (epoch 17.985), train_loss = 1.12728778, grad/param norm = 1.4339e-01, time/batch = 0.6900s	
11925/33150 (epoch 17.986), train_loss = 0.90498834, grad/param norm = 1.3863e-01, time/batch = 0.6881s	
11926/33150 (epoch 17.988), train_loss = 1.01110613, grad/param norm = 1.6076e-01, time/batch = 0.6763s	
11927/33150 (epoch 17.989), train_loss = 0.98755036, grad/param norm = 1.6934e-01, time/batch = 0.6670s	
11928/33150 (epoch 17.991), train_loss = 1.15047594, grad/param norm = 1.8867e-01, time/batch = 0.6662s	
11929/33150 (epoch 17.992), train_loss = 0.95838859, grad/param norm = 1.4434e-01, time/batch = 0.6671s	
11930/33150 (epoch 17.994), train_loss = 1.05189205, grad/param norm = 1.5206e-01, time/batch = 0.6679s	
11931/33150 (epoch 17.995), train_loss = 1.01002781, grad/param norm = 1.7300e-01, time/batch = 0.6705s	
11932/33150 (epoch 17.997), train_loss = 1.06194786, grad/param norm = 1.7696e-01, time/batch = 0.6711s	
11933/33150 (epoch 17.998), train_loss = 0.86820247, grad/param norm = 1.3214e-01, time/batch = 0.6782s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
11934/33150 (epoch 18.000), train_loss = 0.90032382, grad/param norm = 1.4078e-01, time/batch = 0.6909s	
11935/33150 (epoch 18.002), train_loss = 1.35465419, grad/param norm = 1.8373e-01, time/batch = 0.6986s	
11936/33150 (epoch 18.003), train_loss = 0.97882952, grad/param norm = 1.5755e-01, time/batch = 0.6825s	
11937/33150 (epoch 18.005), train_loss = 0.93574504, grad/param norm = 1.4137e-01, time/batch = 0.6899s	
11938/33150 (epoch 18.006), train_loss = 0.89449871, grad/param norm = 1.5203e-01, time/batch = 0.6769s	
11939/33150 (epoch 18.008), train_loss = 1.15237420, grad/param norm = 1.6127e-01, time/batch = 0.6850s	
11940/33150 (epoch 18.009), train_loss = 1.03811155, grad/param norm = 1.4427e-01, time/batch = 0.6799s	
11941/33150 (epoch 18.011), train_loss = 1.16362255, grad/param norm = 1.5822e-01, time/batch = 0.6728s	
11942/33150 (epoch 18.012), train_loss = 1.03448647, grad/param norm = 1.9920e-01, time/batch = 0.6711s	
11943/33150 (epoch 18.014), train_loss = 1.01948235, grad/param norm = 1.7835e-01, time/batch = 0.6707s	
11944/33150 (epoch 18.015), train_loss = 0.99173432, grad/param norm = 1.5819e-01, time/batch = 0.6715s	
11945/33150 (epoch 18.017), train_loss = 0.96988223, grad/param norm = 1.4658e-01, time/batch = 0.6697s	
11946/33150 (epoch 18.018), train_loss = 1.09316970, grad/param norm = 1.6907e-01, time/batch = 0.6690s	
11947/33150 (epoch 18.020), train_loss = 1.12547905, grad/param norm = 1.6556e-01, time/batch = 0.6709s	
11948/33150 (epoch 18.021), train_loss = 0.92649671, grad/param norm = 1.5698e-01, time/batch = 0.6703s	
11949/33150 (epoch 18.023), train_loss = 1.21807565, grad/param norm = 1.5175e-01, time/batch = 0.6724s	
11950/33150 (epoch 18.024), train_loss = 1.10249867, grad/param norm = 1.6062e-01, time/batch = 0.6741s	
11951/33150 (epoch 18.026), train_loss = 0.83332933, grad/param norm = 1.2278e-01, time/batch = 0.6744s	
11952/33150 (epoch 18.027), train_loss = 0.85110438, grad/param norm = 1.3085e-01, time/batch = 0.6752s	
11953/33150 (epoch 18.029), train_loss = 0.96635754, grad/param norm = 1.5945e-01, time/batch = 0.6761s	
11954/33150 (epoch 18.030), train_loss = 1.02923322, grad/param norm = 1.3521e-01, time/batch = 0.6731s	
11955/33150 (epoch 18.032), train_loss = 0.95574577, grad/param norm = 1.4827e-01, time/batch = 0.6781s	
11956/33150 (epoch 18.033), train_loss = 0.99956774, grad/param norm = 1.5214e-01, time/batch = 0.6750s	
11957/33150 (epoch 18.035), train_loss = 1.21346329, grad/param norm = 1.7982e-01, time/batch = 0.6699s	
11958/33150 (epoch 18.036), train_loss = 1.09045632, grad/param norm = 1.6210e-01, time/batch = 0.6698s	
11959/33150 (epoch 18.038), train_loss = 1.32517037, grad/param norm = 1.9839e-01, time/batch = 0.6722s	
11960/33150 (epoch 18.039), train_loss = 1.09995034, grad/param norm = 1.3847e-01, time/batch = 0.6722s	
11961/33150 (epoch 18.041), train_loss = 1.07966205, grad/param norm = 1.5021e-01, time/batch = 0.6718s	
11962/33150 (epoch 18.042), train_loss = 1.01432137, grad/param norm = 1.4931e-01, time/batch = 0.6773s	
11963/33150 (epoch 18.044), train_loss = 1.03333511, grad/param norm = 1.3851e-01, time/batch = 0.6804s	
11964/33150 (epoch 18.045), train_loss = 1.05593657, grad/param norm = 1.3759e-01, time/batch = 0.6756s	
11965/33150 (epoch 18.047), train_loss = 0.92880236, grad/param norm = 1.4227e-01, time/batch = 0.6728s	
11966/33150 (epoch 18.048), train_loss = 1.14725054, grad/param norm = 1.7843e-01, time/batch = 0.6704s	
11967/33150 (epoch 18.050), train_loss = 1.05362976, grad/param norm = 1.5198e-01, time/batch = 0.6697s	
11968/33150 (epoch 18.051), train_loss = 1.06198451, grad/param norm = 1.5633e-01, time/batch = 0.6779s	
11969/33150 (epoch 18.053), train_loss = 1.01344642, grad/param norm = 1.3906e-01, time/batch = 0.6828s	
11970/33150 (epoch 18.054), train_loss = 1.17563232, grad/param norm = 1.4233e-01, time/batch = 0.6733s	
11971/33150 (epoch 18.056), train_loss = 1.01850870, grad/param norm = 1.5490e-01, time/batch = 0.6767s	
11972/33150 (epoch 18.057), train_loss = 1.04537923, grad/param norm = 1.6098e-01, time/batch = 0.6749s	
11973/33150 (epoch 18.059), train_loss = 0.96112619, grad/param norm = 1.4846e-01, time/batch = 0.6728s	
11974/33150 (epoch 18.060), train_loss = 0.97992373, grad/param norm = 1.3575e-01, time/batch = 0.6820s	
11975/33150 (epoch 18.062), train_loss = 1.01118508, grad/param norm = 1.4779e-01, time/batch = 0.6747s	
11976/33150 (epoch 18.063), train_loss = 0.98612830, grad/param norm = 1.6444e-01, time/batch = 0.6755s	
11977/33150 (epoch 18.065), train_loss = 1.01092411, grad/param norm = 1.4041e-01, time/batch = 0.6757s	
11978/33150 (epoch 18.066), train_loss = 0.95400136, grad/param norm = 1.3703e-01, time/batch = 0.6734s	
11979/33150 (epoch 18.068), train_loss = 1.05748617, grad/param norm = 1.4313e-01, time/batch = 0.6725s	
11980/33150 (epoch 18.069), train_loss = 1.10946577, grad/param norm = 1.7009e-01, time/batch = 0.6754s	
11981/33150 (epoch 18.071), train_loss = 1.08575873, grad/param norm = 1.5328e-01, time/batch = 0.6730s	
11982/33150 (epoch 18.072), train_loss = 1.02200927, grad/param norm = 1.4843e-01, time/batch = 0.6729s	
11983/33150 (epoch 18.074), train_loss = 0.92351627, grad/param norm = 1.5672e-01, time/batch = 0.6838s	
11984/33150 (epoch 18.075), train_loss = 0.98880916, grad/param norm = 1.5593e-01, time/batch = 0.6801s	
11985/33150 (epoch 18.077), train_loss = 1.04353948, grad/param norm = 1.7987e-01, time/batch = 0.6772s	
11986/33150 (epoch 18.078), train_loss = 1.17398772, grad/param norm = 1.7799e-01, time/batch = 0.6732s	
11987/33150 (epoch 18.080), train_loss = 1.17049699, grad/param norm = 1.4411e-01, time/batch = 0.6727s	
11988/33150 (epoch 18.081), train_loss = 0.95302818, grad/param norm = 1.8140e-01, time/batch = 0.6738s	
11989/33150 (epoch 18.083), train_loss = 0.77398612, grad/param norm = 1.4689e-01, time/batch = 0.6799s	
11990/33150 (epoch 18.084), train_loss = 0.90254408, grad/param norm = 1.4888e-01, time/batch = 0.6781s	
11991/33150 (epoch 18.086), train_loss = 0.97677261, grad/param norm = 1.6631e-01, time/batch = 0.6772s	
11992/33150 (epoch 18.087), train_loss = 0.91712206, grad/param norm = 1.3854e-01, time/batch = 0.6809s	
11993/33150 (epoch 18.089), train_loss = 0.94673001, grad/param norm = 1.7797e-01, time/batch = 0.6842s	
11994/33150 (epoch 18.090), train_loss = 0.97290896, grad/param norm = 1.4741e-01, time/batch = 0.7000s	
11995/33150 (epoch 18.092), train_loss = 0.97649373, grad/param norm = 1.7559e-01, time/batch = 0.6951s	
11996/33150 (epoch 18.094), train_loss = 1.07317054, grad/param norm = 1.5023e-01, time/batch = 0.6841s	
11997/33150 (epoch 18.095), train_loss = 0.90243954, grad/param norm = 1.2867e-01, time/batch = 0.6783s	
11998/33150 (epoch 18.097), train_loss = 0.96761608, grad/param norm = 1.5793e-01, time/batch = 0.6899s	
11999/33150 (epoch 18.098), train_loss = 1.26016955, grad/param norm = 1.6097e-01, time/batch = 0.6752s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch18.10_1.5629.t7	
12000/33150 (epoch 18.100), train_loss = 1.23109510, grad/param norm = 1.6698e-01, time/batch = 0.6702s	
12001/33150 (epoch 18.101), train_loss = 1.24720291, grad/param norm = 1.9073e-01, time/batch = 0.6826s	
12002/33150 (epoch 18.103), train_loss = 1.05095889, grad/param norm = 1.5571e-01, time/batch = 0.6708s	
12003/33150 (epoch 18.104), train_loss = 0.94618506, grad/param norm = 1.6099e-01, time/batch = 0.6682s	
12004/33150 (epoch 18.106), train_loss = 1.16253413, grad/param norm = 1.6236e-01, time/batch = 0.6715s	
12005/33150 (epoch 18.107), train_loss = 1.26893573, grad/param norm = 1.7488e-01, time/batch = 0.6738s	
12006/33150 (epoch 18.109), train_loss = 1.00193504, grad/param norm = 1.3163e-01, time/batch = 0.6686s	
12007/33150 (epoch 18.110), train_loss = 1.14694767, grad/param norm = 1.5886e-01, time/batch = 0.6761s	
12008/33150 (epoch 18.112), train_loss = 0.95938388, grad/param norm = 1.4995e-01, time/batch = 0.6745s	
12009/33150 (epoch 18.113), train_loss = 1.01265423, grad/param norm = 1.6221e-01, time/batch = 0.6714s	
12010/33150 (epoch 18.115), train_loss = 1.20972266, grad/param norm = 1.6264e-01, time/batch = 0.6749s	
12011/33150 (epoch 18.116), train_loss = 1.00199583, grad/param norm = 1.3960e-01, time/batch = 0.6769s	
12012/33150 (epoch 18.118), train_loss = 1.11265753, grad/param norm = 1.6266e-01, time/batch = 0.6845s	
12013/33150 (epoch 18.119), train_loss = 1.11213827, grad/param norm = 1.6031e-01, time/batch = 0.6936s	
12014/33150 (epoch 18.121), train_loss = 1.00893874, grad/param norm = 1.5342e-01, time/batch = 0.6892s	
12015/33150 (epoch 18.122), train_loss = 1.24818163, grad/param norm = 1.8072e-01, time/batch = 0.6859s	
12016/33150 (epoch 18.124), train_loss = 0.87087528, grad/param norm = 1.3050e-01, time/batch = 0.6717s	
12017/33150 (epoch 18.125), train_loss = 1.12438607, grad/param norm = 1.4873e-01, time/batch = 0.6756s	
12018/33150 (epoch 18.127), train_loss = 1.01643597, grad/param norm = 1.4657e-01, time/batch = 0.6747s	
12019/33150 (epoch 18.128), train_loss = 1.07626803, grad/param norm = 1.6484e-01, time/batch = 0.6861s	
12020/33150 (epoch 18.130), train_loss = 1.08467621, grad/param norm = 1.5093e-01, time/batch = 0.6899s	
12021/33150 (epoch 18.131), train_loss = 1.28646097, grad/param norm = 1.8612e-01, time/batch = 0.6744s	
12022/33150 (epoch 18.133), train_loss = 0.96994237, grad/param norm = 1.3996e-01, time/batch = 0.6831s	
12023/33150 (epoch 18.134), train_loss = 1.13910041, grad/param norm = 1.5012e-01, time/batch = 0.6882s	
12024/33150 (epoch 18.136), train_loss = 1.04317273, grad/param norm = 1.5449e-01, time/batch = 0.6856s	
12025/33150 (epoch 18.137), train_loss = 1.14842431, grad/param norm = 1.6029e-01, time/batch = 0.6930s	
12026/33150 (epoch 18.139), train_loss = 1.11950261, grad/param norm = 1.6521e-01, time/batch = 0.6927s	
12027/33150 (epoch 18.140), train_loss = 1.21538690, grad/param norm = 1.7207e-01, time/batch = 0.6951s	
12028/33150 (epoch 18.142), train_loss = 1.13767302, grad/param norm = 1.7428e-01, time/batch = 0.7019s	
12029/33150 (epoch 18.143), train_loss = 1.07669393, grad/param norm = 1.7055e-01, time/batch = 0.6775s	
12030/33150 (epoch 18.145), train_loss = 1.01519067, grad/param norm = 1.6704e-01, time/batch = 0.6775s	
12031/33150 (epoch 18.146), train_loss = 1.17655995, grad/param norm = 1.8143e-01, time/batch = 0.6740s	
12032/33150 (epoch 18.148), train_loss = 1.14543357, grad/param norm = 1.4144e-01, time/batch = 0.6750s	
12033/33150 (epoch 18.149), train_loss = 1.07579699, grad/param norm = 1.4467e-01, time/batch = 0.6818s	
12034/33150 (epoch 18.151), train_loss = 1.22643103, grad/param norm = 1.5548e-01, time/batch = 0.6904s	
12035/33150 (epoch 18.152), train_loss = 1.00263812, grad/param norm = 1.3664e-01, time/batch = 0.6890s	
12036/33150 (epoch 18.154), train_loss = 1.03931226, grad/param norm = 1.5668e-01, time/batch = 0.6870s	
12037/33150 (epoch 18.155), train_loss = 0.90406921, grad/param norm = 1.3954e-01, time/batch = 0.6905s	
12038/33150 (epoch 18.157), train_loss = 1.00104747, grad/param norm = 1.6006e-01, time/batch = 0.6789s	
12039/33150 (epoch 18.158), train_loss = 0.99221971, grad/param norm = 1.4567e-01, time/batch = 0.6833s	
12040/33150 (epoch 18.160), train_loss = 1.09061976, grad/param norm = 1.5449e-01, time/batch = 0.6805s	
12041/33150 (epoch 18.161), train_loss = 0.98669192, grad/param norm = 3.1959e-01, time/batch = 0.6860s	
12042/33150 (epoch 18.163), train_loss = 0.99268311, grad/param norm = 1.5544e-01, time/batch = 0.6855s	
12043/33150 (epoch 18.164), train_loss = 1.11251970, grad/param norm = 1.7454e-01, time/batch = 0.6923s	
12044/33150 (epoch 18.166), train_loss = 1.04174670, grad/param norm = 1.6875e-01, time/batch = 0.6756s	
12045/33150 (epoch 18.167), train_loss = 1.07837944, grad/param norm = 1.4580e-01, time/batch = 0.6756s	
12046/33150 (epoch 18.169), train_loss = 1.10044909, grad/param norm = 1.9224e-01, time/batch = 0.6762s	
12047/33150 (epoch 18.170), train_loss = 0.94290111, grad/param norm = 1.5132e-01, time/batch = 0.6851s	
12048/33150 (epoch 18.172), train_loss = 1.12981010, grad/param norm = 1.6257e-01, time/batch = 0.6853s	
12049/33150 (epoch 18.173), train_loss = 1.11446192, grad/param norm = 1.8489e-01, time/batch = 0.6772s	
12050/33150 (epoch 18.175), train_loss = 0.98016617, grad/param norm = 1.4826e-01, time/batch = 0.6918s	
12051/33150 (epoch 18.176), train_loss = 1.09302412, grad/param norm = 1.6618e-01, time/batch = 0.6897s	
12052/33150 (epoch 18.178), train_loss = 1.22474844, grad/param norm = 1.7236e-01, time/batch = 0.6733s	
12053/33150 (epoch 18.179), train_loss = 1.10744145, grad/param norm = 1.4849e-01, time/batch = 0.6712s	
12054/33150 (epoch 18.181), train_loss = 1.06894444, grad/param norm = 1.6008e-01, time/batch = 0.6822s	
12055/33150 (epoch 18.183), train_loss = 1.02540571, grad/param norm = 1.6491e-01, time/batch = 0.6711s	
12056/33150 (epoch 18.184), train_loss = 1.25439322, grad/param norm = 1.6069e-01, time/batch = 0.6711s	
12057/33150 (epoch 18.186), train_loss = 1.16253413, grad/param norm = 1.5419e-01, time/batch = 0.6733s	
12058/33150 (epoch 18.187), train_loss = 1.09135549, grad/param norm = 1.6521e-01, time/batch = 0.6735s	
12059/33150 (epoch 18.189), train_loss = 0.85250850, grad/param norm = 1.5895e-01, time/batch = 0.6711s	
12060/33150 (epoch 18.190), train_loss = 0.94142715, grad/param norm = 1.5637e-01, time/batch = 0.6719s	
12061/33150 (epoch 18.192), train_loss = 1.08135446, grad/param norm = 1.8317e-01, time/batch = 0.6791s	
12062/33150 (epoch 18.193), train_loss = 1.11325320, grad/param norm = 1.5223e-01, time/batch = 0.6858s	
12063/33150 (epoch 18.195), train_loss = 1.31689844, grad/param norm = 2.0245e-01, time/batch = 0.6726s	
12064/33150 (epoch 18.196), train_loss = 1.19169107, grad/param norm = 1.5824e-01, time/batch = 0.6706s	
12065/33150 (epoch 18.198), train_loss = 0.91966660, grad/param norm = 1.4962e-01, time/batch = 0.6695s	
12066/33150 (epoch 18.199), train_loss = 1.15607990, grad/param norm = 2.1733e-01, time/batch = 0.6708s	
12067/33150 (epoch 18.201), train_loss = 0.96388467, grad/param norm = 1.3861e-01, time/batch = 0.6686s	
12068/33150 (epoch 18.202), train_loss = 0.84582915, grad/param norm = 1.4441e-01, time/batch = 0.6730s	
12069/33150 (epoch 18.204), train_loss = 1.07615462, grad/param norm = 1.5382e-01, time/batch = 0.6714s	
12070/33150 (epoch 18.205), train_loss = 1.14718976, grad/param norm = 1.7536e-01, time/batch = 0.6737s	
12071/33150 (epoch 18.207), train_loss = 1.10772935, grad/param norm = 1.5606e-01, time/batch = 0.6732s	
12072/33150 (epoch 18.208), train_loss = 1.12091101, grad/param norm = 1.7026e-01, time/batch = 0.6734s	
12073/33150 (epoch 18.210), train_loss = 0.97681765, grad/param norm = 1.3285e-01, time/batch = 0.6735s	
12074/33150 (epoch 18.211), train_loss = 1.09319620, grad/param norm = 1.7781e-01, time/batch = 0.6708s	
12075/33150 (epoch 18.213), train_loss = 1.11179787, grad/param norm = 1.5269e-01, time/batch = 0.6692s	
12076/33150 (epoch 18.214), train_loss = 1.04470866, grad/param norm = 1.5845e-01, time/batch = 0.6854s	
12077/33150 (epoch 18.216), train_loss = 0.99049157, grad/param norm = 1.6620e-01, time/batch = 0.6910s	
12078/33150 (epoch 18.217), train_loss = 0.99938327, grad/param norm = 1.3945e-01, time/batch = 0.6717s	
12079/33150 (epoch 18.219), train_loss = 0.93001925, grad/param norm = 1.3596e-01, time/batch = 0.6717s	
12080/33150 (epoch 18.220), train_loss = 0.96709771, grad/param norm = 1.3332e-01, time/batch = 0.6730s	
12081/33150 (epoch 18.222), train_loss = 1.15742714, grad/param norm = 1.5055e-01, time/batch = 0.6860s	
12082/33150 (epoch 18.223), train_loss = 1.04446735, grad/param norm = 1.5759e-01, time/batch = 0.6746s	
12083/33150 (epoch 18.225), train_loss = 1.19082216, grad/param norm = 1.5358e-01, time/batch = 0.6734s	
12084/33150 (epoch 18.226), train_loss = 1.02387340, grad/param norm = 1.4272e-01, time/batch = 0.6703s	
12085/33150 (epoch 18.228), train_loss = 1.03596036, grad/param norm = 1.4742e-01, time/batch = 0.6708s	
12086/33150 (epoch 18.229), train_loss = 1.03085229, grad/param norm = 1.4667e-01, time/batch = 0.6738s	
12087/33150 (epoch 18.231), train_loss = 1.18750038, grad/param norm = 1.6319e-01, time/batch = 0.6732s	
12088/33150 (epoch 18.232), train_loss = 1.08897155, grad/param norm = 1.7768e-01, time/batch = 0.6719s	
12089/33150 (epoch 18.234), train_loss = 1.05880277, grad/param norm = 1.6559e-01, time/batch = 0.6716s	
12090/33150 (epoch 18.235), train_loss = 1.09038449, grad/param norm = 1.7970e-01, time/batch = 0.6726s	
12091/33150 (epoch 18.237), train_loss = 1.04728486, grad/param norm = 1.6297e-01, time/batch = 0.6848s	
12092/33150 (epoch 18.238), train_loss = 1.11381329, grad/param norm = 1.7501e-01, time/batch = 0.6807s	
12093/33150 (epoch 18.240), train_loss = 1.09313733, grad/param norm = 1.5428e-01, time/batch = 0.6928s	
12094/33150 (epoch 18.241), train_loss = 1.19265160, grad/param norm = 1.7174e-01, time/batch = 0.6779s	
12095/33150 (epoch 18.243), train_loss = 1.13601753, grad/param norm = 1.7451e-01, time/batch = 0.6858s	
12096/33150 (epoch 18.244), train_loss = 1.02729521, grad/param norm = 1.3827e-01, time/batch = 0.6786s	
12097/33150 (epoch 18.246), train_loss = 1.12756383, grad/param norm = 1.4620e-01, time/batch = 0.6859s	
12098/33150 (epoch 18.247), train_loss = 1.00689622, grad/param norm = 1.5261e-01, time/batch = 0.6794s	
12099/33150 (epoch 18.249), train_loss = 1.13369000, grad/param norm = 1.4396e-01, time/batch = 0.6749s	
12100/33150 (epoch 18.250), train_loss = 1.11453685, grad/param norm = 1.3624e-01, time/batch = 0.6884s	
12101/33150 (epoch 18.252), train_loss = 1.11548365, grad/param norm = 1.3196e-01, time/batch = 0.6935s	
12102/33150 (epoch 18.253), train_loss = 1.06896803, grad/param norm = 1.5772e-01, time/batch = 0.6902s	
12103/33150 (epoch 18.255), train_loss = 1.03918215, grad/param norm = 1.4161e-01, time/batch = 0.6952s	
12104/33150 (epoch 18.256), train_loss = 1.10297042, grad/param norm = 1.3671e-01, time/batch = 0.6725s	
12105/33150 (epoch 18.258), train_loss = 1.01123158, grad/param norm = 1.6829e-01, time/batch = 0.6968s	
12106/33150 (epoch 18.259), train_loss = 0.89902003, grad/param norm = 1.7434e-01, time/batch = 0.6855s	
12107/33150 (epoch 18.261), train_loss = 0.91692616, grad/param norm = 1.3340e-01, time/batch = 0.6855s	
12108/33150 (epoch 18.262), train_loss = 1.11266294, grad/param norm = 1.5944e-01, time/batch = 0.6804s	
12109/33150 (epoch 18.264), train_loss = 0.83278244, grad/param norm = 1.2886e-01, time/batch = 0.6801s	
12110/33150 (epoch 18.265), train_loss = 1.09943394, grad/param norm = 1.4867e-01, time/batch = 0.6760s	
12111/33150 (epoch 18.267), train_loss = 1.12936494, grad/param norm = 1.7057e-01, time/batch = 0.6760s	
12112/33150 (epoch 18.268), train_loss = 1.14587076, grad/param norm = 1.5371e-01, time/batch = 0.6819s	
12113/33150 (epoch 18.270), train_loss = 1.24530846, grad/param norm = 1.7721e-01, time/batch = 0.6901s	
12114/33150 (epoch 18.271), train_loss = 1.20491744, grad/param norm = 1.6516e-01, time/batch = 0.6926s	
12115/33150 (epoch 18.273), train_loss = 1.18853234, grad/param norm = 1.5980e-01, time/batch = 0.6888s	
12116/33150 (epoch 18.275), train_loss = 1.20559484, grad/param norm = 1.6070e-01, time/batch = 0.6924s	
12117/33150 (epoch 18.276), train_loss = 1.06579262, grad/param norm = 1.5677e-01, time/batch = 0.6875s	
12118/33150 (epoch 18.278), train_loss = 1.13364292, grad/param norm = 1.5747e-01, time/batch = 0.6809s	
12119/33150 (epoch 18.279), train_loss = 1.09808612, grad/param norm = 1.4810e-01, time/batch = 0.6660s	
12120/33150 (epoch 18.281), train_loss = 1.10020963, grad/param norm = 1.4844e-01, time/batch = 0.6815s	
12121/33150 (epoch 18.282), train_loss = 1.06302450, grad/param norm = 1.3053e-01, time/batch = 0.6821s	
12122/33150 (epoch 18.284), train_loss = 1.00518344, grad/param norm = 1.3999e-01, time/batch = 0.6795s	
12123/33150 (epoch 18.285), train_loss = 1.08352428, grad/param norm = 1.4105e-01, time/batch = 0.6754s	
12124/33150 (epoch 18.287), train_loss = 0.96915719, grad/param norm = 1.3204e-01, time/batch = 0.6719s	
12125/33150 (epoch 18.288), train_loss = 1.19164956, grad/param norm = 1.5141e-01, time/batch = 0.6717s	
12126/33150 (epoch 18.290), train_loss = 0.90552189, grad/param norm = 1.4901e-01, time/batch = 0.6740s	
12127/33150 (epoch 18.291), train_loss = 0.89456026, grad/param norm = 1.5215e-01, time/batch = 0.6737s	
12128/33150 (epoch 18.293), train_loss = 1.12015431, grad/param norm = 1.4877e-01, time/batch = 0.6728s	
12129/33150 (epoch 18.294), train_loss = 0.80555401, grad/param norm = 1.3463e-01, time/batch = 0.6749s	
12130/33150 (epoch 18.296), train_loss = 1.03464762, grad/param norm = 1.4839e-01, time/batch = 0.6756s	
12131/33150 (epoch 18.297), train_loss = 0.99001001, grad/param norm = 1.4324e-01, time/batch = 0.6781s	
12132/33150 (epoch 18.299), train_loss = 0.98841345, grad/param norm = 1.5367e-01, time/batch = 0.6738s	
12133/33150 (epoch 18.300), train_loss = 0.99334408, grad/param norm = 1.3229e-01, time/batch = 0.6699s	
12134/33150 (epoch 18.302), train_loss = 1.00643489, grad/param norm = 1.3876e-01, time/batch = 0.6706s	
12135/33150 (epoch 18.303), train_loss = 1.03135567, grad/param norm = 1.5953e-01, time/batch = 0.6689s	
12136/33150 (epoch 18.305), train_loss = 1.11793659, grad/param norm = 1.4773e-01, time/batch = 0.6697s	
12137/33150 (epoch 18.306), train_loss = 1.10589158, grad/param norm = 1.9121e-01, time/batch = 0.6684s	
12138/33150 (epoch 18.308), train_loss = 1.28962792, grad/param norm = 1.6562e-01, time/batch = 0.6698s	
12139/33150 (epoch 18.309), train_loss = 0.89011042, grad/param norm = 1.3429e-01, time/batch = 0.6689s	
12140/33150 (epoch 18.311), train_loss = 1.00513399, grad/param norm = 1.5487e-01, time/batch = 0.6679s	
12141/33150 (epoch 18.312), train_loss = 0.84479958, grad/param norm = 1.4276e-01, time/batch = 0.6710s	
12142/33150 (epoch 18.314), train_loss = 1.00777293, grad/param norm = 1.5066e-01, time/batch = 0.6706s	
12143/33150 (epoch 18.315), train_loss = 1.07568639, grad/param norm = 1.5439e-01, time/batch = 0.6767s	
12144/33150 (epoch 18.317), train_loss = 0.82018576, grad/param norm = 1.1776e-01, time/batch = 0.6748s	
12145/33150 (epoch 18.318), train_loss = 0.93946111, grad/param norm = 1.3248e-01, time/batch = 0.6682s	
12146/33150 (epoch 18.320), train_loss = 0.90844912, grad/param norm = 1.4575e-01, time/batch = 0.6990s	
12147/33150 (epoch 18.321), train_loss = 0.99462825, grad/param norm = 1.3650e-01, time/batch = 0.6721s	
12148/33150 (epoch 18.323), train_loss = 1.06697337, grad/param norm = 1.6096e-01, time/batch = 0.6874s	
12149/33150 (epoch 18.324), train_loss = 1.14469474, grad/param norm = 1.9382e-01, time/batch = 0.6795s	
12150/33150 (epoch 18.326), train_loss = 1.09227037, grad/param norm = 1.4305e-01, time/batch = 0.6862s	
12151/33150 (epoch 18.327), train_loss = 1.16913638, grad/param norm = 1.4767e-01, time/batch = 0.6758s	
12152/33150 (epoch 18.329), train_loss = 1.09884323, grad/param norm = 1.4621e-01, time/batch = 0.6695s	
12153/33150 (epoch 18.330), train_loss = 1.05231865, grad/param norm = 1.6653e-01, time/batch = 0.6677s	
12154/33150 (epoch 18.332), train_loss = 1.03493756, grad/param norm = 1.4125e-01, time/batch = 0.6689s	
12155/33150 (epoch 18.333), train_loss = 1.08566481, grad/param norm = 1.3491e-01, time/batch = 0.6694s	
12156/33150 (epoch 18.335), train_loss = 0.98962411, grad/param norm = 1.4486e-01, time/batch = 0.6705s	
12157/33150 (epoch 18.336), train_loss = 0.97025056, grad/param norm = 1.4688e-01, time/batch = 0.6692s	
12158/33150 (epoch 18.338), train_loss = 0.86295244, grad/param norm = 1.3902e-01, time/batch = 0.6747s	
12159/33150 (epoch 18.339), train_loss = 1.13970352, grad/param norm = 1.5191e-01, time/batch = 0.6823s	
12160/33150 (epoch 18.341), train_loss = 1.13543638, grad/param norm = 1.7343e-01, time/batch = 0.6723s	
12161/33150 (epoch 18.342), train_loss = 0.92790563, grad/param norm = 1.4932e-01, time/batch = 0.6741s	
12162/33150 (epoch 18.344), train_loss = 1.08364220, grad/param norm = 1.6124e-01, time/batch = 0.6659s	
12163/33150 (epoch 18.345), train_loss = 1.00622496, grad/param norm = 1.4743e-01, time/batch = 0.6657s	
12164/33150 (epoch 18.347), train_loss = 0.85765270, grad/param norm = 1.2853e-01, time/batch = 0.6741s	
12165/33150 (epoch 18.348), train_loss = 1.07192356, grad/param norm = 1.4533e-01, time/batch = 0.6849s	
12166/33150 (epoch 18.350), train_loss = 0.97177495, grad/param norm = 1.6414e-01, time/batch = 0.6667s	
12167/33150 (epoch 18.351), train_loss = 1.10913307, grad/param norm = 1.5837e-01, time/batch = 0.6667s	
12168/33150 (epoch 18.353), train_loss = 1.09558970, grad/param norm = 1.6569e-01, time/batch = 0.6659s	
12169/33150 (epoch 18.354), train_loss = 1.32923025, grad/param norm = 1.6884e-01, time/batch = 0.6662s	
12170/33150 (epoch 18.356), train_loss = 1.17963110, grad/param norm = 1.6589e-01, time/batch = 0.6687s	
12171/33150 (epoch 18.357), train_loss = 1.12431644, grad/param norm = 1.6314e-01, time/batch = 0.6738s	
12172/33150 (epoch 18.359), train_loss = 1.10244626, grad/param norm = 1.5984e-01, time/batch = 0.6732s	
12173/33150 (epoch 18.360), train_loss = 1.12322977, grad/param norm = 1.7553e-01, time/batch = 0.6735s	
12174/33150 (epoch 18.362), train_loss = 1.13633205, grad/param norm = 1.5124e-01, time/batch = 0.6747s	
12175/33150 (epoch 18.363), train_loss = 1.07595588, grad/param norm = 1.4417e-01, time/batch = 0.6740s	
12176/33150 (epoch 18.365), train_loss = 1.04670371, grad/param norm = 1.4680e-01, time/batch = 0.6681s	
12177/33150 (epoch 18.367), train_loss = 0.97605178, grad/param norm = 1.4586e-01, time/batch = 0.6700s	
12178/33150 (epoch 18.368), train_loss = 1.05976440, grad/param norm = 1.9009e-01, time/batch = 0.6680s	
12179/33150 (epoch 18.370), train_loss = 1.08473587, grad/param norm = 1.9959e-01, time/batch = 0.6715s	
12180/33150 (epoch 18.371), train_loss = 0.95290193, grad/param norm = 1.5669e-01, time/batch = 0.6786s	
12181/33150 (epoch 18.373), train_loss = 1.12157657, grad/param norm = 1.8445e-01, time/batch = 0.6721s	
12182/33150 (epoch 18.374), train_loss = 1.02378314, grad/param norm = 1.4941e-01, time/batch = 0.6743s	
12183/33150 (epoch 18.376), train_loss = 1.19390118, grad/param norm = 1.6007e-01, time/batch = 0.6694s	
12184/33150 (epoch 18.377), train_loss = 1.00839918, grad/param norm = 1.6706e-01, time/batch = 0.6705s	
12185/33150 (epoch 18.379), train_loss = 1.13484823, grad/param norm = 1.6262e-01, time/batch = 0.6750s	
12186/33150 (epoch 18.380), train_loss = 1.12665721, grad/param norm = 1.3800e-01, time/batch = 0.6724s	
12187/33150 (epoch 18.382), train_loss = 0.99000308, grad/param norm = 1.6683e-01, time/batch = 0.6706s	
12188/33150 (epoch 18.383), train_loss = 0.96573843, grad/param norm = 1.4408e-01, time/batch = 0.6759s	
12189/33150 (epoch 18.385), train_loss = 1.04575648, grad/param norm = 1.6875e-01, time/batch = 0.6906s	
12190/33150 (epoch 18.386), train_loss = 0.90250657, grad/param norm = 1.2165e-01, time/batch = 0.6917s	
12191/33150 (epoch 18.388), train_loss = 1.00190748, grad/param norm = 1.3852e-01, time/batch = 0.6952s	
12192/33150 (epoch 18.389), train_loss = 0.98245228, grad/param norm = 1.3322e-01, time/batch = 0.6735s	
12193/33150 (epoch 18.391), train_loss = 1.21379578, grad/param norm = 1.5102e-01, time/batch = 0.6716s	
12194/33150 (epoch 18.392), train_loss = 1.00276733, grad/param norm = 1.3936e-01, time/batch = 0.6933s	
12195/33150 (epoch 18.394), train_loss = 0.90670487, grad/param norm = 1.1992e-01, time/batch = 0.6746s	
12196/33150 (epoch 18.395), train_loss = 0.92289446, grad/param norm = 1.4758e-01, time/batch = 0.6719s	
12197/33150 (epoch 18.397), train_loss = 0.74908951, grad/param norm = 1.3517e-01, time/batch = 0.6738s	
12198/33150 (epoch 18.398), train_loss = 1.08128069, grad/param norm = 1.7994e-01, time/batch = 0.6743s	
12199/33150 (epoch 18.400), train_loss = 0.99008597, grad/param norm = 1.3509e-01, time/batch = 0.6764s	
12200/33150 (epoch 18.401), train_loss = 0.87287339, grad/param norm = 1.3356e-01, time/batch = 0.6762s	
12201/33150 (epoch 18.403), train_loss = 0.92474975, grad/param norm = 1.2859e-01, time/batch = 0.6734s	
12202/33150 (epoch 18.404), train_loss = 1.03536623, grad/param norm = 1.4982e-01, time/batch = 0.6717s	
12203/33150 (epoch 18.406), train_loss = 0.95170965, grad/param norm = 1.1985e-01, time/batch = 0.6730s	
12204/33150 (epoch 18.407), train_loss = 0.91385124, grad/param norm = 1.4208e-01, time/batch = 0.6734s	
12205/33150 (epoch 18.409), train_loss = 0.84018728, grad/param norm = 1.3468e-01, time/batch = 0.6741s	
12206/33150 (epoch 18.410), train_loss = 1.05658362, grad/param norm = 1.5657e-01, time/batch = 0.6759s	
12207/33150 (epoch 18.412), train_loss = 1.07983083, grad/param norm = 1.4569e-01, time/batch = 0.6736s	
12208/33150 (epoch 18.413), train_loss = 0.97543718, grad/param norm = 1.3985e-01, time/batch = 0.6734s	
12209/33150 (epoch 18.415), train_loss = 1.10625445, grad/param norm = 1.4156e-01, time/batch = 0.6716s	
12210/33150 (epoch 18.416), train_loss = 0.96231713, grad/param norm = 1.3740e-01, time/batch = 0.6758s	
12211/33150 (epoch 18.418), train_loss = 1.17875131, grad/param norm = 2.0599e-01, time/batch = 0.6754s	
12212/33150 (epoch 18.419), train_loss = 0.99210522, grad/param norm = 1.4965e-01, time/batch = 0.6722s	
12213/33150 (epoch 18.421), train_loss = 1.05947440, grad/param norm = 1.6322e-01, time/batch = 0.6846s	
12214/33150 (epoch 18.422), train_loss = 0.99914986, grad/param norm = 1.4599e-01, time/batch = 0.6749s	
12215/33150 (epoch 18.424), train_loss = 0.98907238, grad/param norm = 1.5502e-01, time/batch = 0.6742s	
12216/33150 (epoch 18.425), train_loss = 1.06851669, grad/param norm = 1.3788e-01, time/batch = 0.6729s	
12217/33150 (epoch 18.427), train_loss = 1.02701960, grad/param norm = 1.3645e-01, time/batch = 0.6744s	
12218/33150 (epoch 18.428), train_loss = 1.04598425, grad/param norm = 1.5859e-01, time/batch = 0.6738s	
12219/33150 (epoch 18.430), train_loss = 1.05550414, grad/param norm = 1.5737e-01, time/batch = 0.6733s	
12220/33150 (epoch 18.431), train_loss = 1.11097788, grad/param norm = 1.6822e-01, time/batch = 0.6735s	
12221/33150 (epoch 18.433), train_loss = 1.04230778, grad/param norm = 1.4239e-01, time/batch = 0.6745s	
12222/33150 (epoch 18.434), train_loss = 0.91628627, grad/param norm = 1.4414e-01, time/batch = 0.6721s	
12223/33150 (epoch 18.436), train_loss = 0.97126562, grad/param norm = 1.5040e-01, time/batch = 0.6725s	
12224/33150 (epoch 18.437), train_loss = 1.08130273, grad/param norm = 1.9670e-01, time/batch = 0.6714s	
12225/33150 (epoch 18.439), train_loss = 1.16865330, grad/param norm = 1.5721e-01, time/batch = 0.6721s	
12226/33150 (epoch 18.440), train_loss = 1.13649166, grad/param norm = 1.6151e-01, time/batch = 0.6730s	
12227/33150 (epoch 18.442), train_loss = 0.91403665, grad/param norm = 1.3459e-01, time/batch = 0.6819s	
12228/33150 (epoch 18.443), train_loss = 1.11294506, grad/param norm = 1.5240e-01, time/batch = 0.6853s	
12229/33150 (epoch 18.445), train_loss = 1.04990369, grad/param norm = 1.6228e-01, time/batch = 0.6772s	
12230/33150 (epoch 18.446), train_loss = 1.08361971, grad/param norm = 1.8468e-01, time/batch = 0.6725s	
12231/33150 (epoch 18.448), train_loss = 1.12922946, grad/param norm = 1.5847e-01, time/batch = 0.6716s	
12232/33150 (epoch 18.449), train_loss = 1.05286489, grad/param norm = 1.3276e-01, time/batch = 0.6744s	
12233/33150 (epoch 18.451), train_loss = 1.10015314, grad/param norm = 1.8185e-01, time/batch = 0.6746s	
12234/33150 (epoch 18.452), train_loss = 1.28772524, grad/param norm = 1.6329e-01, time/batch = 0.6749s	
12235/33150 (epoch 18.454), train_loss = 1.03184016, grad/param norm = 1.4555e-01, time/batch = 0.6737s	
12236/33150 (epoch 18.456), train_loss = 0.91850483, grad/param norm = 1.2957e-01, time/batch = 0.6704s	
12237/33150 (epoch 18.457), train_loss = 1.06289544, grad/param norm = 1.5322e-01, time/batch = 0.6703s	
12238/33150 (epoch 18.459), train_loss = 1.16986968, grad/param norm = 2.1718e-01, time/batch = 0.6778s	
12239/33150 (epoch 18.460), train_loss = 1.08850922, grad/param norm = 1.3936e-01, time/batch = 0.6724s	
12240/33150 (epoch 18.462), train_loss = 1.15632689, grad/param norm = 2.1017e-01, time/batch = 0.6677s	
12241/33150 (epoch 18.463), train_loss = 1.31203359, grad/param norm = 1.7915e-01, time/batch = 0.6721s	
12242/33150 (epoch 18.465), train_loss = 1.00903526, grad/param norm = 1.5691e-01, time/batch = 0.6755s	
12243/33150 (epoch 18.466), train_loss = 0.96804200, grad/param norm = 1.4222e-01, time/batch = 0.6855s	
12244/33150 (epoch 18.468), train_loss = 1.31607697, grad/param norm = 1.5970e-01, time/batch = 0.6749s	
12245/33150 (epoch 18.469), train_loss = 1.04451407, grad/param norm = 1.6492e-01, time/batch = 0.6700s	
12246/33150 (epoch 18.471), train_loss = 0.98248463, grad/param norm = 1.3556e-01, time/batch = 0.6688s	
12247/33150 (epoch 18.472), train_loss = 1.05146726, grad/param norm = 1.4391e-01, time/batch = 0.6723s	
12248/33150 (epoch 18.474), train_loss = 1.15952302, grad/param norm = 1.9241e-01, time/batch = 0.6711s	
12249/33150 (epoch 18.475), train_loss = 1.30917828, grad/param norm = 1.6620e-01, time/batch = 0.6720s	
12250/33150 (epoch 18.477), train_loss = 1.16887421, grad/param norm = 1.6895e-01, time/batch = 0.6708s	
12251/33150 (epoch 18.478), train_loss = 1.14359922, grad/param norm = 1.5533e-01, time/batch = 0.6724s	
12252/33150 (epoch 18.480), train_loss = 1.00595665, grad/param norm = 1.4782e-01, time/batch = 0.6704s	
12253/33150 (epoch 18.481), train_loss = 0.89231801, grad/param norm = 1.4988e-01, time/batch = 0.6699s	
12254/33150 (epoch 18.483), train_loss = 0.99269209, grad/param norm = 1.5108e-01, time/batch = 0.6715s	
12255/33150 (epoch 18.484), train_loss = 0.99876088, grad/param norm = 1.4690e-01, time/batch = 0.6735s	
12256/33150 (epoch 18.486), train_loss = 1.01835392, grad/param norm = 1.5811e-01, time/batch = 0.6920s	
12257/33150 (epoch 18.487), train_loss = 1.07027144, grad/param norm = 1.4930e-01, time/batch = 0.6795s	
12258/33150 (epoch 18.489), train_loss = 1.05500520, grad/param norm = 1.5627e-01, time/batch = 0.6853s	
12259/33150 (epoch 18.490), train_loss = 0.88503341, grad/param norm = 1.3730e-01, time/batch = 0.6744s	
12260/33150 (epoch 18.492), train_loss = 0.99298952, grad/param norm = 1.7135e-01, time/batch = 0.6816s	
12261/33150 (epoch 18.493), train_loss = 1.13854020, grad/param norm = 1.5881e-01, time/batch = 0.6733s	
12262/33150 (epoch 18.495), train_loss = 1.17150803, grad/param norm = 1.5268e-01, time/batch = 0.6741s	
12263/33150 (epoch 18.496), train_loss = 1.01295556, grad/param norm = 1.5535e-01, time/batch = 0.6754s	
12264/33150 (epoch 18.498), train_loss = 1.19668183, grad/param norm = 2.1354e-01, time/batch = 0.6744s	
12265/33150 (epoch 18.499), train_loss = 1.17898971, grad/param norm = 1.5650e-01, time/batch = 0.6736s	
12266/33150 (epoch 18.501), train_loss = 1.09324529, grad/param norm = 1.5644e-01, time/batch = 0.6739s	
12267/33150 (epoch 18.502), train_loss = 1.20211969, grad/param norm = 1.7578e-01, time/batch = 0.6748s	
12268/33150 (epoch 18.504), train_loss = 1.12528708, grad/param norm = 1.6295e-01, time/batch = 0.6713s	
12269/33150 (epoch 18.505), train_loss = 1.24619848, grad/param norm = 1.8745e-01, time/batch = 0.6697s	
12270/33150 (epoch 18.507), train_loss = 1.01758765, grad/param norm = 1.5794e-01, time/batch = 0.6701s	
12271/33150 (epoch 18.508), train_loss = 1.01813548, grad/param norm = 1.5671e-01, time/batch = 0.6714s	
12272/33150 (epoch 18.510), train_loss = 1.08778662, grad/param norm = 1.5674e-01, time/batch = 0.6719s	
12273/33150 (epoch 18.511), train_loss = 1.19753654, grad/param norm = 1.6087e-01, time/batch = 0.6734s	
12274/33150 (epoch 18.513), train_loss = 1.06474539, grad/param norm = 1.4302e-01, time/batch = 0.6851s	
12275/33150 (epoch 18.514), train_loss = 0.88597311, grad/param norm = 1.4746e-01, time/batch = 0.6797s	
12276/33150 (epoch 18.516), train_loss = 1.15042156, grad/param norm = 1.9168e-01, time/batch = 0.6980s	
12277/33150 (epoch 18.517), train_loss = 1.17055450, grad/param norm = 1.5307e-01, time/batch = 0.6922s	
12278/33150 (epoch 18.519), train_loss = 0.97703687, grad/param norm = 1.3555e-01, time/batch = 0.6909s	
12279/33150 (epoch 18.520), train_loss = 1.07541374, grad/param norm = 1.4220e-01, time/batch = 1.1310s	
12280/33150 (epoch 18.522), train_loss = 1.22816419, grad/param norm = 1.8258e-01, time/batch = 1.2088s	
12281/33150 (epoch 18.523), train_loss = 0.98689490, grad/param norm = 1.4782e-01, time/batch = 0.6734s	
12282/33150 (epoch 18.525), train_loss = 1.13819292, grad/param norm = 1.6597e-01, time/batch = 0.6946s	
12283/33150 (epoch 18.526), train_loss = 0.98415717, grad/param norm = 1.5562e-01, time/batch = 0.7001s	
12284/33150 (epoch 18.528), train_loss = 1.09652139, grad/param norm = 1.5695e-01, time/batch = 0.6945s	
12285/33150 (epoch 18.529), train_loss = 1.03912079, grad/param norm = 1.4528e-01, time/batch = 0.6926s	
12286/33150 (epoch 18.531), train_loss = 0.88811621, grad/param norm = 1.5534e-01, time/batch = 0.6836s	
12287/33150 (epoch 18.532), train_loss = 1.07976469, grad/param norm = 1.5327e-01, time/batch = 0.7336s	
12288/33150 (epoch 18.534), train_loss = 1.01989289, grad/param norm = 1.3230e-01, time/batch = 0.6833s	
12289/33150 (epoch 18.535), train_loss = 0.97447007, grad/param norm = 1.6592e-01, time/batch = 0.6661s	
12290/33150 (epoch 18.537), train_loss = 1.15799804, grad/param norm = 1.6660e-01, time/batch = 0.6700s	
12291/33150 (epoch 18.538), train_loss = 0.99180420, grad/param norm = 1.4507e-01, time/batch = 0.7046s	
12292/33150 (epoch 18.540), train_loss = 0.91691503, grad/param norm = 1.3848e-01, time/batch = 0.6754s	
12293/33150 (epoch 18.541), train_loss = 1.15060188, grad/param norm = 1.6207e-01, time/batch = 0.6775s	
12294/33150 (epoch 18.543), train_loss = 1.07844981, grad/param norm = 1.5019e-01, time/batch = 0.7705s	
12295/33150 (epoch 18.544), train_loss = 1.11562321, grad/param norm = 1.6251e-01, time/batch = 0.6780s	
12296/33150 (epoch 18.546), train_loss = 1.11194281, grad/param norm = 1.6039e-01, time/batch = 0.6844s	
12297/33150 (epoch 18.548), train_loss = 1.08064967, grad/param norm = 1.6899e-01, time/batch = 0.6727s	
12298/33150 (epoch 18.549), train_loss = 1.00520694, grad/param norm = 1.6194e-01, time/batch = 0.6686s	
12299/33150 (epoch 18.551), train_loss = 0.96444622, grad/param norm = 1.3984e-01, time/batch = 0.6701s	
12300/33150 (epoch 18.552), train_loss = 0.84093366, grad/param norm = 1.2389e-01, time/batch = 0.6847s	
12301/33150 (epoch 18.554), train_loss = 1.14233825, grad/param norm = 1.6053e-01, time/batch = 0.6767s	
12302/33150 (epoch 18.555), train_loss = 1.18820438, grad/param norm = 1.5976e-01, time/batch = 0.6694s	
12303/33150 (epoch 18.557), train_loss = 0.88096365, grad/param norm = 1.4856e-01, time/batch = 0.6669s	
12304/33150 (epoch 18.558), train_loss = 1.13736068, grad/param norm = 1.8444e-01, time/batch = 0.6690s	
12305/33150 (epoch 18.560), train_loss = 1.00741436, grad/param norm = 1.5100e-01, time/batch = 0.6712s	
12306/33150 (epoch 18.561), train_loss = 0.89431828, grad/param norm = 1.5211e-01, time/batch = 0.6679s	
12307/33150 (epoch 18.563), train_loss = 1.12514921, grad/param norm = 1.8126e-01, time/batch = 0.6712s	
12308/33150 (epoch 18.564), train_loss = 1.20993011, grad/param norm = 1.6456e-01, time/batch = 0.6835s	
12309/33150 (epoch 18.566), train_loss = 1.02216465, grad/param norm = 1.5203e-01, time/batch = 0.6910s	
12310/33150 (epoch 18.567), train_loss = 0.95513078, grad/param norm = 1.3855e-01, time/batch = 0.6912s	
12311/33150 (epoch 18.569), train_loss = 1.05836360, grad/param norm = 1.4204e-01, time/batch = 0.6895s	
12312/33150 (epoch 18.570), train_loss = 1.11238082, grad/param norm = 1.5117e-01, time/batch = 0.6809s	
12313/33150 (epoch 18.572), train_loss = 0.96810956, grad/param norm = 1.4555e-01, time/batch = 0.6781s	
12314/33150 (epoch 18.573), train_loss = 0.84607605, grad/param norm = 1.2215e-01, time/batch = 0.6778s	
12315/33150 (epoch 18.575), train_loss = 1.01540658, grad/param norm = 1.4918e-01, time/batch = 0.6853s	
12316/33150 (epoch 18.576), train_loss = 0.91621013, grad/param norm = 1.3039e-01, time/batch = 0.6692s	
12317/33150 (epoch 18.578), train_loss = 0.95995704, grad/param norm = 1.4216e-01, time/batch = 0.6718s	
12318/33150 (epoch 18.579), train_loss = 0.88273269, grad/param norm = 1.3984e-01, time/batch = 0.6686s	
12319/33150 (epoch 18.581), train_loss = 0.96772529, grad/param norm = 1.4227e-01, time/batch = 0.6720s	
12320/33150 (epoch 18.582), train_loss = 1.15318861, grad/param norm = 1.4712e-01, time/batch = 0.6739s	
12321/33150 (epoch 18.584), train_loss = 1.14665323, grad/param norm = 1.6609e-01, time/batch = 0.7020s	
12322/33150 (epoch 18.585), train_loss = 1.04949816, grad/param norm = 1.4779e-01, time/batch = 0.6966s	
12323/33150 (epoch 18.587), train_loss = 1.07392567, grad/param norm = 1.4683e-01, time/batch = 0.6892s	
12324/33150 (epoch 18.588), train_loss = 0.96034232, grad/param norm = 1.4799e-01, time/batch = 0.6727s	
12325/33150 (epoch 18.590), train_loss = 1.05248450, grad/param norm = 1.5312e-01, time/batch = 0.6732s	
12326/33150 (epoch 18.591), train_loss = 1.03445487, grad/param norm = 1.4754e-01, time/batch = 0.6749s	
12327/33150 (epoch 18.593), train_loss = 1.12316891, grad/param norm = 1.6147e-01, time/batch = 0.6733s	
12328/33150 (epoch 18.594), train_loss = 1.06298556, grad/param norm = 1.7215e-01, time/batch = 0.6701s	
12329/33150 (epoch 18.596), train_loss = 0.97881883, grad/param norm = 1.4603e-01, time/batch = 0.6820s	
12330/33150 (epoch 18.597), train_loss = 0.92735072, grad/param norm = 1.6876e-01, time/batch = 0.6809s	
12331/33150 (epoch 18.599), train_loss = 1.20503779, grad/param norm = 1.7155e-01, time/batch = 0.6755s	
12332/33150 (epoch 18.600), train_loss = 1.07572828, grad/param norm = 2.2466e-01, time/batch = 0.6686s	
12333/33150 (epoch 18.602), train_loss = 1.01117407, grad/param norm = 1.6111e-01, time/batch = 0.6685s	
12334/33150 (epoch 18.603), train_loss = 1.12768262, grad/param norm = 1.6027e-01, time/batch = 0.6679s	
12335/33150 (epoch 18.605), train_loss = 0.95184909, grad/param norm = 1.6034e-01, time/batch = 0.6736s	
12336/33150 (epoch 18.606), train_loss = 1.06015456, grad/param norm = 1.8766e-01, time/batch = 0.6735s	
12337/33150 (epoch 18.608), train_loss = 1.13389925, grad/param norm = 1.6230e-01, time/batch = 0.6743s	
12338/33150 (epoch 18.609), train_loss = 1.03081861, grad/param norm = 1.7155e-01, time/batch = 0.6722s	
12339/33150 (epoch 18.611), train_loss = 0.92729077, grad/param norm = 1.4936e-01, time/batch = 0.6721s	
12340/33150 (epoch 18.612), train_loss = 1.07820107, grad/param norm = 1.6517e-01, time/batch = 0.6750s	
12341/33150 (epoch 18.614), train_loss = 0.89658063, grad/param norm = 1.3910e-01, time/batch = 0.6733s	
12342/33150 (epoch 18.615), train_loss = 0.93551084, grad/param norm = 1.4738e-01, time/batch = 0.6756s	
12343/33150 (epoch 18.617), train_loss = 1.03653209, grad/param norm = 1.5446e-01, time/batch = 0.6773s	
12344/33150 (epoch 18.618), train_loss = 1.06822344, grad/param norm = 1.5783e-01, time/batch = 0.6758s	
12345/33150 (epoch 18.620), train_loss = 0.97459901, grad/param norm = 1.5276e-01, time/batch = 0.6839s	
12346/33150 (epoch 18.621), train_loss = 1.04100505, grad/param norm = 1.4302e-01, time/batch = 0.6764s	
12347/33150 (epoch 18.623), train_loss = 1.09360979, grad/param norm = 1.4426e-01, time/batch = 0.6778s	
12348/33150 (epoch 18.624), train_loss = 0.99648681, grad/param norm = 1.4845e-01, time/batch = 0.6798s	
12349/33150 (epoch 18.626), train_loss = 0.98661719, grad/param norm = 1.5334e-01, time/batch = 0.6840s	
12350/33150 (epoch 18.627), train_loss = 0.94436554, grad/param norm = 1.4900e-01, time/batch = 0.6773s	
12351/33150 (epoch 18.629), train_loss = 0.91101590, grad/param norm = 1.4668e-01, time/batch = 0.6887s	
12352/33150 (epoch 18.630), train_loss = 0.97723356, grad/param norm = 1.4553e-01, time/batch = 0.6879s	
12353/33150 (epoch 18.632), train_loss = 0.89716316, grad/param norm = 1.3590e-01, time/batch = 0.6744s	
12354/33150 (epoch 18.633), train_loss = 0.91164003, grad/param norm = 1.6988e-01, time/batch = 0.6833s	
12355/33150 (epoch 18.635), train_loss = 1.20036518, grad/param norm = 1.5403e-01, time/batch = 0.6719s	
12356/33150 (epoch 18.637), train_loss = 0.88869637, grad/param norm = 1.4577e-01, time/batch = 0.6773s	
12357/33150 (epoch 18.638), train_loss = 1.00026337, grad/param norm = 1.5187e-01, time/batch = 0.6747s	
12358/33150 (epoch 18.640), train_loss = 1.11454336, grad/param norm = 1.7059e-01, time/batch = 0.6714s	
12359/33150 (epoch 18.641), train_loss = 0.92051733, grad/param norm = 1.4712e-01, time/batch = 0.6743s	
12360/33150 (epoch 18.643), train_loss = 0.98050573, grad/param norm = 1.5111e-01, time/batch = 0.6817s	
12361/33150 (epoch 18.644), train_loss = 1.18473015, grad/param norm = 1.6001e-01, time/batch = 0.6877s	
12362/33150 (epoch 18.646), train_loss = 0.99494755, grad/param norm = 1.3993e-01, time/batch = 0.6808s	
12363/33150 (epoch 18.647), train_loss = 1.25297772, grad/param norm = 1.6005e-01, time/batch = 0.6847s	
12364/33150 (epoch 18.649), train_loss = 1.12492720, grad/param norm = 1.6860e-01, time/batch = 0.6905s	
12365/33150 (epoch 18.650), train_loss = 0.92495835, grad/param norm = 1.3521e-01, time/batch = 0.6972s	
12366/33150 (epoch 18.652), train_loss = 1.15379993, grad/param norm = 1.6094e-01, time/batch = 0.6860s	
12367/33150 (epoch 18.653), train_loss = 1.04137088, grad/param norm = 1.3980e-01, time/batch = 0.6837s	
12368/33150 (epoch 18.655), train_loss = 1.08573917, grad/param norm = 1.6161e-01, time/batch = 0.6875s	
12369/33150 (epoch 18.656), train_loss = 1.00233368, grad/param norm = 1.5199e-01, time/batch = 0.6929s	
12370/33150 (epoch 18.658), train_loss = 1.01276616, grad/param norm = 1.7533e-01, time/batch = 0.6810s	
12371/33150 (epoch 18.659), train_loss = 1.31268441, grad/param norm = 2.2249e-01, time/batch = 0.6894s	
12372/33150 (epoch 18.661), train_loss = 1.03331622, grad/param norm = 1.6233e-01, time/batch = 0.6937s	
12373/33150 (epoch 18.662), train_loss = 0.93038868, grad/param norm = 1.6097e-01, time/batch = 0.6902s	
12374/33150 (epoch 18.664), train_loss = 1.16438758, grad/param norm = 1.5924e-01, time/batch = 0.6991s	
12375/33150 (epoch 18.665), train_loss = 1.10631498, grad/param norm = 1.6301e-01, time/batch = 0.6935s	
12376/33150 (epoch 18.667), train_loss = 1.18284910, grad/param norm = 1.8701e-01, time/batch = 0.6922s	
12377/33150 (epoch 18.668), train_loss = 1.11987450, grad/param norm = 1.5596e-01, time/batch = 0.6876s	
12378/33150 (epoch 18.670), train_loss = 0.97459779, grad/param norm = 1.3753e-01, time/batch = 0.6866s	
12379/33150 (epoch 18.671), train_loss = 0.96905815, grad/param norm = 1.5686e-01, time/batch = 0.6921s	
12380/33150 (epoch 18.673), train_loss = 1.17197996, grad/param norm = 1.4523e-01, time/batch = 0.6948s	
12381/33150 (epoch 18.674), train_loss = 1.04397723, grad/param norm = 1.4293e-01, time/batch = 0.6967s	
12382/33150 (epoch 18.676), train_loss = 1.01699433, grad/param norm = 1.4569e-01, time/batch = 0.6855s	
12383/33150 (epoch 18.677), train_loss = 1.25047505, grad/param norm = 1.7696e-01, time/batch = 0.6829s	
12384/33150 (epoch 18.679), train_loss = 1.02389143, grad/param norm = 1.3281e-01, time/batch = 0.6793s	
12385/33150 (epoch 18.680), train_loss = 1.16730312, grad/param norm = 1.4927e-01, time/batch = 0.6699s	
12386/33150 (epoch 18.682), train_loss = 1.00289002, grad/param norm = 1.4558e-01, time/batch = 0.6767s	
12387/33150 (epoch 18.683), train_loss = 0.89489377, grad/param norm = 1.3319e-01, time/batch = 0.6779s	
12388/33150 (epoch 18.685), train_loss = 1.03577193, grad/param norm = 1.6748e-01, time/batch = 0.6824s	
12389/33150 (epoch 18.686), train_loss = 0.90465269, grad/param norm = 1.3823e-01, time/batch = 0.6819s	
12390/33150 (epoch 18.688), train_loss = 0.95706276, grad/param norm = 1.4539e-01, time/batch = 0.6824s	
12391/33150 (epoch 18.689), train_loss = 0.94962922, grad/param norm = 1.3408e-01, time/batch = 0.6919s	
12392/33150 (epoch 18.691), train_loss = 0.84491900, grad/param norm = 1.3944e-01, time/batch = 0.6872s	
12393/33150 (epoch 18.692), train_loss = 0.92266850, grad/param norm = 1.3283e-01, time/batch = 0.6875s	
12394/33150 (epoch 18.694), train_loss = 0.80250714, grad/param norm = 1.2621e-01, time/batch = 0.6900s	
12395/33150 (epoch 18.695), train_loss = 0.96390614, grad/param norm = 1.4059e-01, time/batch = 0.6898s	
12396/33150 (epoch 18.697), train_loss = 0.87408071, grad/param norm = 1.2751e-01, time/batch = 0.6883s	
12397/33150 (epoch 18.698), train_loss = 0.98932041, grad/param norm = 1.4409e-01, time/batch = 0.6909s	
12398/33150 (epoch 18.700), train_loss = 0.77326186, grad/param norm = 1.2282e-01, time/batch = 0.6953s	
12399/33150 (epoch 18.701), train_loss = 0.90053651, grad/param norm = 1.4066e-01, time/batch = 0.6880s	
12400/33150 (epoch 18.703), train_loss = 1.00923665, grad/param norm = 1.4721e-01, time/batch = 0.6900s	
12401/33150 (epoch 18.704), train_loss = 0.86734872, grad/param norm = 1.3632e-01, time/batch = 0.6901s	
12402/33150 (epoch 18.706), train_loss = 0.97770229, grad/param norm = 1.4002e-01, time/batch = 0.6865s	
12403/33150 (epoch 18.707), train_loss = 0.96665882, grad/param norm = 1.4003e-01, time/batch = 0.6901s	
12404/33150 (epoch 18.709), train_loss = 1.01612246, grad/param norm = 1.2816e-01, time/batch = 0.6865s	
12405/33150 (epoch 18.710), train_loss = 1.03516739, grad/param norm = 1.5729e-01, time/batch = 0.6895s	
12406/33150 (epoch 18.712), train_loss = 1.08975127, grad/param norm = 1.4395e-01, time/batch = 0.6904s	
12407/33150 (epoch 18.713), train_loss = 1.07662445, grad/param norm = 1.3940e-01, time/batch = 0.6937s	
12408/33150 (epoch 18.715), train_loss = 0.96240040, grad/param norm = 1.4363e-01, time/batch = 0.6878s	
12409/33150 (epoch 18.716), train_loss = 1.07492929, grad/param norm = 1.5502e-01, time/batch = 0.6834s	
12410/33150 (epoch 18.718), train_loss = 1.03428660, grad/param norm = 1.4529e-01, time/batch = 0.6906s	
12411/33150 (epoch 18.719), train_loss = 1.13334700, grad/param norm = 1.7062e-01, time/batch = 0.6926s	
12412/33150 (epoch 18.721), train_loss = 1.00931580, grad/param norm = 1.5760e-01, time/batch = 0.6942s	
12413/33150 (epoch 18.722), train_loss = 1.04581421, grad/param norm = 1.4483e-01, time/batch = 0.6953s	
12414/33150 (epoch 18.724), train_loss = 1.00137753, grad/param norm = 1.4326e-01, time/batch = 0.6843s	
12415/33150 (epoch 18.725), train_loss = 1.15949328, grad/param norm = 1.8054e-01, time/batch = 0.6872s	
12416/33150 (epoch 18.727), train_loss = 1.07763185, grad/param norm = 1.8565e-01, time/batch = 0.6820s	
12417/33150 (epoch 18.729), train_loss = 1.02619495, grad/param norm = 1.5794e-01, time/batch = 0.6899s	
12418/33150 (epoch 18.730), train_loss = 1.06632914, grad/param norm = 1.6168e-01, time/batch = 0.6875s	
12419/33150 (epoch 18.732), train_loss = 1.14143833, grad/param norm = 1.7838e-01, time/batch = 0.6908s	
12420/33150 (epoch 18.733), train_loss = 0.84869770, grad/param norm = 1.2344e-01, time/batch = 0.6928s	
12421/33150 (epoch 18.735), train_loss = 0.95023102, grad/param norm = 1.4461e-01, time/batch = 0.6934s	
12422/33150 (epoch 18.736), train_loss = 0.97789186, grad/param norm = 1.4806e-01, time/batch = 0.6879s	
12423/33150 (epoch 18.738), train_loss = 1.05413482, grad/param norm = 1.6997e-01, time/batch = 0.6927s	
12424/33150 (epoch 18.739), train_loss = 1.15202787, grad/param norm = 1.6753e-01, time/batch = 0.6883s	
12425/33150 (epoch 18.741), train_loss = 1.14266812, grad/param norm = 1.6989e-01, time/batch = 0.6907s	
12426/33150 (epoch 18.742), train_loss = 0.92824188, grad/param norm = 1.4473e-01, time/batch = 0.6793s	
12427/33150 (epoch 18.744), train_loss = 1.14965460, grad/param norm = 1.6310e-01, time/batch = 0.6856s	
12428/33150 (epoch 18.745), train_loss = 0.98231951, grad/param norm = 1.3669e-01, time/batch = 0.6872s	
12429/33150 (epoch 18.747), train_loss = 0.83758510, grad/param norm = 1.5272e-01, time/batch = 0.6931s	
12430/33150 (epoch 18.748), train_loss = 0.96217709, grad/param norm = 1.4137e-01, time/batch = 0.6970s	
12431/33150 (epoch 18.750), train_loss = 1.08510267, grad/param norm = 1.5918e-01, time/batch = 0.6838s	
12432/33150 (epoch 18.751), train_loss = 1.06439698, grad/param norm = 1.5334e-01, time/batch = 0.6948s	
12433/33150 (epoch 18.753), train_loss = 0.88399633, grad/param norm = 1.4331e-01, time/batch = 0.6897s	
12434/33150 (epoch 18.754), train_loss = 1.26439701, grad/param norm = 2.0170e-01, time/batch = 0.6846s	
12435/33150 (epoch 18.756), train_loss = 1.07456044, grad/param norm = 1.7868e-01, time/batch = 0.6901s	
12436/33150 (epoch 18.757), train_loss = 1.04685923, grad/param norm = 1.5553e-01, time/batch = 0.6871s	
12437/33150 (epoch 18.759), train_loss = 1.18405065, grad/param norm = 2.1004e-01, time/batch = 0.6841s	
12438/33150 (epoch 18.760), train_loss = 1.07545424, grad/param norm = 1.6836e-01, time/batch = 0.6882s	
12439/33150 (epoch 18.762), train_loss = 1.04559752, grad/param norm = 1.6570e-01, time/batch = 0.6811s	
12440/33150 (epoch 18.763), train_loss = 1.07832168, grad/param norm = 1.6753e-01, time/batch = 0.6864s	
12441/33150 (epoch 18.765), train_loss = 1.03074116, grad/param norm = 1.5119e-01, time/batch = 0.6891s	
12442/33150 (epoch 18.766), train_loss = 0.96368643, grad/param norm = 1.7025e-01, time/batch = 0.6859s	
12443/33150 (epoch 18.768), train_loss = 0.97350524, grad/param norm = 1.5104e-01, time/batch = 0.6842s	
12444/33150 (epoch 18.769), train_loss = 1.08054653, grad/param norm = 1.6082e-01, time/batch = 0.6905s	
12445/33150 (epoch 18.771), train_loss = 1.07173873, grad/param norm = 1.5323e-01, time/batch = 0.6894s	
12446/33150 (epoch 18.772), train_loss = 1.11158018, grad/param norm = 1.7450e-01, time/batch = 0.6887s	
12447/33150 (epoch 18.774), train_loss = 1.20462309, grad/param norm = 1.5646e-01, time/batch = 0.6803s	
12448/33150 (epoch 18.775), train_loss = 1.10588885, grad/param norm = 2.2411e-01, time/batch = 0.6857s	
12449/33150 (epoch 18.777), train_loss = 1.10575649, grad/param norm = 1.7513e-01, time/batch = 0.6857s	
12450/33150 (epoch 18.778), train_loss = 1.06793435, grad/param norm = 1.4057e-01, time/batch = 0.6907s	
12451/33150 (epoch 18.780), train_loss = 0.88419332, grad/param norm = 1.2620e-01, time/batch = 0.6964s	
12452/33150 (epoch 18.781), train_loss = 1.03284216, grad/param norm = 1.4619e-01, time/batch = 0.6996s	
12453/33150 (epoch 18.783), train_loss = 1.04798674, grad/param norm = 1.3742e-01, time/batch = 0.6969s	
12454/33150 (epoch 18.784), train_loss = 1.02990545, grad/param norm = 1.7037e-01, time/batch = 0.6933s	
12455/33150 (epoch 18.786), train_loss = 1.01789232, grad/param norm = 1.5234e-01, time/batch = 0.6812s	
12456/33150 (epoch 18.787), train_loss = 0.96688900, grad/param norm = 1.4094e-01, time/batch = 0.6945s	
12457/33150 (epoch 18.789), train_loss = 0.86640870, grad/param norm = 1.4268e-01, time/batch = 0.6912s	
12458/33150 (epoch 18.790), train_loss = 0.89349826, grad/param norm = 1.2377e-01, time/batch = 0.6933s	
12459/33150 (epoch 18.792), train_loss = 1.06691583, grad/param norm = 1.7774e-01, time/batch = 0.7040s	
12460/33150 (epoch 18.793), train_loss = 1.02996375, grad/param norm = 1.6821e-01, time/batch = 0.6966s	
12461/33150 (epoch 18.795), train_loss = 0.97714416, grad/param norm = 1.5050e-01, time/batch = 0.6889s	
12462/33150 (epoch 18.796), train_loss = 0.98387722, grad/param norm = 1.4283e-01, time/batch = 0.6890s	
12463/33150 (epoch 18.798), train_loss = 0.96049686, grad/param norm = 1.3240e-01, time/batch = 0.6750s	
12464/33150 (epoch 18.799), train_loss = 0.87706129, grad/param norm = 1.4643e-01, time/batch = 0.6852s	
12465/33150 (epoch 18.801), train_loss = 1.06264478, grad/param norm = 1.5229e-01, time/batch = 0.6836s	
12466/33150 (epoch 18.802), train_loss = 0.91263198, grad/param norm = 1.3636e-01, time/batch = 0.6699s	
12467/33150 (epoch 18.804), train_loss = 0.98596874, grad/param norm = 1.5204e-01, time/batch = 0.6763s	
12468/33150 (epoch 18.805), train_loss = 0.97531983, grad/param norm = 1.7249e-01, time/batch = 0.6863s	
12469/33150 (epoch 18.807), train_loss = 0.97794654, grad/param norm = 1.3906e-01, time/batch = 0.6725s	
12470/33150 (epoch 18.808), train_loss = 1.12115330, grad/param norm = 1.6722e-01, time/batch = 0.6747s	
12471/33150 (epoch 18.810), train_loss = 1.00253752, grad/param norm = 1.5472e-01, time/batch = 0.6869s	
12472/33150 (epoch 18.811), train_loss = 1.06488984, grad/param norm = 1.6828e-01, time/batch = 0.6798s	
12473/33150 (epoch 18.813), train_loss = 0.98809028, grad/param norm = 1.3391e-01, time/batch = 0.6739s	
12474/33150 (epoch 18.814), train_loss = 1.01093956, grad/param norm = 1.6669e-01, time/batch = 0.6718s	
12475/33150 (epoch 18.816), train_loss = 1.00032717, grad/param norm = 1.7110e-01, time/batch = 0.6708s	
12476/33150 (epoch 18.817), train_loss = 1.07561075, grad/param norm = 1.4288e-01, time/batch = 0.6726s	
12477/33150 (epoch 18.819), train_loss = 1.01958158, grad/param norm = 1.4382e-01, time/batch = 0.6998s	
12478/33150 (epoch 18.821), train_loss = 0.92226989, grad/param norm = 1.3994e-01, time/batch = 0.6784s	
12479/33150 (epoch 18.822), train_loss = 0.96402979, grad/param norm = 1.4106e-01, time/batch = 0.6843s	
12480/33150 (epoch 18.824), train_loss = 0.98232873, grad/param norm = 1.4881e-01, time/batch = 0.6792s	
12481/33150 (epoch 18.825), train_loss = 1.04617253, grad/param norm = 1.5385e-01, time/batch = 0.6861s	
12482/33150 (epoch 18.827), train_loss = 1.11418860, grad/param norm = 2.2000e-01, time/batch = 0.6866s	
12483/33150 (epoch 18.828), train_loss = 0.89562431, grad/param norm = 1.4850e-01, time/batch = 0.6715s	
12484/33150 (epoch 18.830), train_loss = 1.10479823, grad/param norm = 1.6204e-01, time/batch = 0.6784s	
12485/33150 (epoch 18.831), train_loss = 0.97085277, grad/param norm = 1.6175e-01, time/batch = 0.6747s	
12486/33150 (epoch 18.833), train_loss = 0.95915078, grad/param norm = 1.6481e-01, time/batch = 0.6747s	
12487/33150 (epoch 18.834), train_loss = 1.12399050, grad/param norm = 1.6362e-01, time/batch = 0.6749s	
12488/33150 (epoch 18.836), train_loss = 1.14936625, grad/param norm = 1.5111e-01, time/batch = 0.6719s	
12489/33150 (epoch 18.837), train_loss = 1.02032235, grad/param norm = 1.6429e-01, time/batch = 0.6705s	
12490/33150 (epoch 18.839), train_loss = 1.10069349, grad/param norm = 1.8050e-01, time/batch = 0.6790s	
12491/33150 (epoch 18.840), train_loss = 1.07964544, grad/param norm = 1.5088e-01, time/batch = 0.6725s	
12492/33150 (epoch 18.842), train_loss = 1.15875133, grad/param norm = 1.7527e-01, time/batch = 0.6690s	
12493/33150 (epoch 18.843), train_loss = 1.11721366, grad/param norm = 1.5729e-01, time/batch = 0.6734s	
12494/33150 (epoch 18.845), train_loss = 0.97731902, grad/param norm = 1.4677e-01, time/batch = 0.6768s	
12495/33150 (epoch 18.846), train_loss = 1.21866348, grad/param norm = 2.1266e-01, time/batch = 0.6724s	
12496/33150 (epoch 18.848), train_loss = 1.12546982, grad/param norm = 1.6516e-01, time/batch = 0.6714s	
12497/33150 (epoch 18.849), train_loss = 1.15572995, grad/param norm = 1.5945e-01, time/batch = 0.6724s	
12498/33150 (epoch 18.851), train_loss = 1.11437073, grad/param norm = 1.7310e-01, time/batch = 0.6754s	
12499/33150 (epoch 18.852), train_loss = 1.17810862, grad/param norm = 1.4953e-01, time/batch = 0.6793s	
12500/33150 (epoch 18.854), train_loss = 1.03831973, grad/param norm = 1.4539e-01, time/batch = 0.6849s	
12501/33150 (epoch 18.855), train_loss = 0.89719693, grad/param norm = 1.3581e-01, time/batch = 0.6749s	
12502/33150 (epoch 18.857), train_loss = 0.89032015, grad/param norm = 1.4067e-01, time/batch = 0.6858s	
12503/33150 (epoch 18.858), train_loss = 0.99030590, grad/param norm = 1.6084e-01, time/batch = 0.6723s	
12504/33150 (epoch 18.860), train_loss = 0.91838179, grad/param norm = 1.3960e-01, time/batch = 0.6686s	
12505/33150 (epoch 18.861), train_loss = 0.92529186, grad/param norm = 1.4508e-01, time/batch = 0.6804s	
12506/33150 (epoch 18.863), train_loss = 1.04634934, grad/param norm = 1.4495e-01, time/batch = 0.6804s	
12507/33150 (epoch 18.864), train_loss = 1.14305218, grad/param norm = 1.5940e-01, time/batch = 0.6776s	
12508/33150 (epoch 18.866), train_loss = 1.08966178, grad/param norm = 1.4990e-01, time/batch = 0.6704s	
12509/33150 (epoch 18.867), train_loss = 1.05822363, grad/param norm = 1.4592e-01, time/batch = 0.6745s	
12510/33150 (epoch 18.869), train_loss = 1.08284339, grad/param norm = 1.5381e-01, time/batch = 0.6905s	
12511/33150 (epoch 18.870), train_loss = 1.01775052, grad/param norm = 1.6193e-01, time/batch = 0.6726s	
12512/33150 (epoch 18.872), train_loss = 1.04522276, grad/param norm = 1.4940e-01, time/batch = 0.6723s	
12513/33150 (epoch 18.873), train_loss = 0.88897600, grad/param norm = 1.3562e-01, time/batch = 0.6693s	
12514/33150 (epoch 18.875), train_loss = 1.17215552, grad/param norm = 1.5784e-01, time/batch = 0.6887s	
12515/33150 (epoch 18.876), train_loss = 0.91807914, grad/param norm = 1.5072e-01, time/batch = 0.6798s	
12516/33150 (epoch 18.878), train_loss = 0.93046425, grad/param norm = 1.4415e-01, time/batch = 0.6676s	
12517/33150 (epoch 18.879), train_loss = 0.94877270, grad/param norm = 1.4030e-01, time/batch = 0.6819s	
12518/33150 (epoch 18.881), train_loss = 0.95002511, grad/param norm = 1.4284e-01, time/batch = 0.6651s	
12519/33150 (epoch 18.882), train_loss = 0.85243726, grad/param norm = 1.3518e-01, time/batch = 0.6711s	
12520/33150 (epoch 18.884), train_loss = 1.00573364, grad/param norm = 1.4113e-01, time/batch = 0.6679s	
12521/33150 (epoch 18.885), train_loss = 0.80774374, grad/param norm = 1.5131e-01, time/batch = 0.6694s	
12522/33150 (epoch 18.887), train_loss = 1.16902855, grad/param norm = 1.8572e-01, time/batch = 0.6677s	
12523/33150 (epoch 18.888), train_loss = 1.06116877, grad/param norm = 1.5052e-01, time/batch = 0.6673s	
12524/33150 (epoch 18.890), train_loss = 0.94826340, grad/param norm = 1.4314e-01, time/batch = 0.6817s	
12525/33150 (epoch 18.891), train_loss = 0.92084013, grad/param norm = 1.4675e-01, time/batch = 0.6854s	
12526/33150 (epoch 18.893), train_loss = 1.09077374, grad/param norm = 1.6647e-01, time/batch = 0.6694s	
12527/33150 (epoch 18.894), train_loss = 1.09125230, grad/param norm = 1.6528e-01, time/batch = 0.6762s	
12528/33150 (epoch 18.896), train_loss = 0.99673834, grad/param norm = 1.4509e-01, time/batch = 0.6731s	
12529/33150 (epoch 18.897), train_loss = 1.06421760, grad/param norm = 1.4147e-01, time/batch = 0.6852s	
12530/33150 (epoch 18.899), train_loss = 0.87612656, grad/param norm = 1.7299e-01, time/batch = 0.6762s	
12531/33150 (epoch 18.900), train_loss = 1.25618172, grad/param norm = 1.6510e-01, time/batch = 0.6887s	
12532/33150 (epoch 18.902), train_loss = 1.20081116, grad/param norm = 1.6182e-01, time/batch = 0.6745s	
12533/33150 (epoch 18.903), train_loss = 1.05334043, grad/param norm = 1.5874e-01, time/batch = 0.6737s	
12534/33150 (epoch 18.905), train_loss = 1.06578253, grad/param norm = 1.3759e-01, time/batch = 0.6704s	
12535/33150 (epoch 18.906), train_loss = 1.07923731, grad/param norm = 1.6764e-01, time/batch = 0.6690s	
12536/33150 (epoch 18.908), train_loss = 1.16622519, grad/param norm = 1.7010e-01, time/batch = 0.6758s	
12537/33150 (epoch 18.910), train_loss = 1.10190418, grad/param norm = 1.6205e-01, time/batch = 0.6721s	
12538/33150 (epoch 18.911), train_loss = 0.88859247, grad/param norm = 1.3108e-01, time/batch = 0.6849s	
12539/33150 (epoch 18.913), train_loss = 0.97647311, grad/param norm = 1.4377e-01, time/batch = 0.6921s	
12540/33150 (epoch 18.914), train_loss = 1.10928510, grad/param norm = 1.6179e-01, time/batch = 0.6911s	
12541/33150 (epoch 18.916), train_loss = 0.94107211, grad/param norm = 1.4575e-01, time/batch = 0.6777s	
12542/33150 (epoch 18.917), train_loss = 1.08649051, grad/param norm = 1.5820e-01, time/batch = 0.6810s	
12543/33150 (epoch 18.919), train_loss = 1.17803480, grad/param norm = 1.9178e-01, time/batch = 0.6914s	
12544/33150 (epoch 18.920), train_loss = 1.15406400, grad/param norm = 1.5798e-01, time/batch = 0.6971s	
12545/33150 (epoch 18.922), train_loss = 1.18049059, grad/param norm = 1.8506e-01, time/batch = 0.6762s	
12546/33150 (epoch 18.923), train_loss = 1.04635923, grad/param norm = 1.7123e-01, time/batch = 0.6671s	
12547/33150 (epoch 18.925), train_loss = 1.15034051, grad/param norm = 1.5810e-01, time/batch = 0.6674s	
12548/33150 (epoch 18.926), train_loss = 1.00737739, grad/param norm = 1.4100e-01, time/batch = 0.6695s	
12549/33150 (epoch 18.928), train_loss = 0.99256209, grad/param norm = 1.5423e-01, time/batch = 0.6714s	
12550/33150 (epoch 18.929), train_loss = 1.07844024, grad/param norm = 1.4286e-01, time/batch = 0.6674s	
12551/33150 (epoch 18.931), train_loss = 1.20445886, grad/param norm = 1.8962e-01, time/batch = 0.6809s	
12552/33150 (epoch 18.932), train_loss = 1.04653377, grad/param norm = 1.5712e-01, time/batch = 0.6832s	
12553/33150 (epoch 18.934), train_loss = 1.05630805, grad/param norm = 1.4539e-01, time/batch = 0.6735s	
12554/33150 (epoch 18.935), train_loss = 1.13335967, grad/param norm = 1.5310e-01, time/batch = 0.6870s	
12555/33150 (epoch 18.937), train_loss = 1.14559438, grad/param norm = 1.4491e-01, time/batch = 0.6726s	
12556/33150 (epoch 18.938), train_loss = 1.09815559, grad/param norm = 1.5769e-01, time/batch = 0.6853s	
12557/33150 (epoch 18.940), train_loss = 1.29724195, grad/param norm = 1.7891e-01, time/batch = 0.6793s	
12558/33150 (epoch 18.941), train_loss = 1.03402570, grad/param norm = 1.4202e-01, time/batch = 0.6856s	
12559/33150 (epoch 18.943), train_loss = 0.92464308, grad/param norm = 1.5004e-01, time/batch = 0.6872s	
12560/33150 (epoch 18.944), train_loss = 1.14250276, grad/param norm = 1.6244e-01, time/batch = 0.6903s	
12561/33150 (epoch 18.946), train_loss = 0.87431229, grad/param norm = 1.3751e-01, time/batch = 0.6936s	
12562/33150 (epoch 18.947), train_loss = 1.06112965, grad/param norm = 1.3960e-01, time/batch = 0.6895s	
12563/33150 (epoch 18.949), train_loss = 1.16803002, grad/param norm = 1.5642e-01, time/batch = 0.6757s	
12564/33150 (epoch 18.950), train_loss = 1.07791996, grad/param norm = 1.7393e-01, time/batch = 0.6717s	
12565/33150 (epoch 18.952), train_loss = 0.95802570, grad/param norm = 1.4623e-01, time/batch = 0.6822s	
12566/33150 (epoch 18.953), train_loss = 0.99659090, grad/param norm = 1.4128e-01, time/batch = 0.6859s	
12567/33150 (epoch 18.955), train_loss = 0.89287973, grad/param norm = 1.3349e-01, time/batch = 0.6834s	
12568/33150 (epoch 18.956), train_loss = 1.09296114, grad/param norm = 1.4847e-01, time/batch = 0.6842s	
12569/33150 (epoch 18.958), train_loss = 0.92774714, grad/param norm = 1.3476e-01, time/batch = 0.6879s	
12570/33150 (epoch 18.959), train_loss = 0.96989498, grad/param norm = 1.5013e-01, time/batch = 0.6815s	
12571/33150 (epoch 18.961), train_loss = 0.93051879, grad/param norm = 1.3954e-01, time/batch = 0.6852s	
12572/33150 (epoch 18.962), train_loss = 0.90222822, grad/param norm = 1.3258e-01, time/batch = 0.6821s	
12573/33150 (epoch 18.964), train_loss = 1.05026150, grad/param norm = 1.4902e-01, time/batch = 0.6858s	
12574/33150 (epoch 18.965), train_loss = 1.03121217, grad/param norm = 1.4778e-01, time/batch = 0.6896s	
12575/33150 (epoch 18.967), train_loss = 1.03875823, grad/param norm = 1.6001e-01, time/batch = 0.6775s	
12576/33150 (epoch 18.968), train_loss = 0.86616155, grad/param norm = 1.1757e-01, time/batch = 0.6725s	
12577/33150 (epoch 18.970), train_loss = 0.97758795, grad/param norm = 1.3975e-01, time/batch = 0.6732s	
12578/33150 (epoch 18.971), train_loss = 1.01520612, grad/param norm = 1.5565e-01, time/batch = 0.6776s	
12579/33150 (epoch 18.973), train_loss = 1.17103069, grad/param norm = 1.7037e-01, time/batch = 0.6812s	
12580/33150 (epoch 18.974), train_loss = 1.18361180, grad/param norm = 1.6332e-01, time/batch = 0.6870s	
12581/33150 (epoch 18.976), train_loss = 1.11155410, grad/param norm = 1.4437e-01, time/batch = 0.6791s	
12582/33150 (epoch 18.977), train_loss = 1.20286149, grad/param norm = 1.6517e-01, time/batch = 0.6732s	
12583/33150 (epoch 18.979), train_loss = 1.13558475, grad/param norm = 1.7551e-01, time/batch = 0.6830s	
12584/33150 (epoch 18.980), train_loss = 1.19914891, grad/param norm = 1.6749e-01, time/batch = 0.7013s	
12585/33150 (epoch 18.982), train_loss = 1.02972677, grad/param norm = 1.7095e-01, time/batch = 0.7096s	
12586/33150 (epoch 18.983), train_loss = 0.92867541, grad/param norm = 1.5429e-01, time/batch = 0.7032s	
12587/33150 (epoch 18.985), train_loss = 1.11723650, grad/param norm = 1.4244e-01, time/batch = 0.7076s	
12588/33150 (epoch 18.986), train_loss = 0.89721090, grad/param norm = 1.4519e-01, time/batch = 0.7018s	
12589/33150 (epoch 18.988), train_loss = 1.00871217, grad/param norm = 1.6955e-01, time/batch = 0.6859s	
12590/33150 (epoch 18.989), train_loss = 0.96713870, grad/param norm = 1.4445e-01, time/batch = 0.6965s	
12591/33150 (epoch 18.991), train_loss = 1.13720973, grad/param norm = 2.1074e-01, time/batch = 0.6855s	
12592/33150 (epoch 18.992), train_loss = 0.96162016, grad/param norm = 1.4509e-01, time/batch = 0.6740s	
12593/33150 (epoch 18.994), train_loss = 1.04980366, grad/param norm = 1.6736e-01, time/batch = 0.6736s	
12594/33150 (epoch 18.995), train_loss = 0.99172523, grad/param norm = 1.5736e-01, time/batch = 0.6767s	
12595/33150 (epoch 18.997), train_loss = 1.04082253, grad/param norm = 1.8070e-01, time/batch = 0.6670s	
12596/33150 (epoch 18.998), train_loss = 0.84684933, grad/param norm = 1.3898e-01, time/batch = 0.6712s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
12597/33150 (epoch 19.000), train_loss = 0.88021415, grad/param norm = 1.4455e-01, time/batch = 0.6755s	
12598/33150 (epoch 19.002), train_loss = 1.33371570, grad/param norm = 1.7311e-01, time/batch = 0.6802s	
12599/33150 (epoch 19.003), train_loss = 0.96693828, grad/param norm = 1.5932e-01, time/batch = 0.6762s	
12600/33150 (epoch 19.005), train_loss = 0.91576490, grad/param norm = 1.3463e-01, time/batch = 0.6915s	
12601/33150 (epoch 19.006), train_loss = 0.88842889, grad/param norm = 1.4775e-01, time/batch = 0.6961s	
12602/33150 (epoch 19.008), train_loss = 1.13946357, grad/param norm = 1.6581e-01, time/batch = 0.6877s	
12603/33150 (epoch 19.009), train_loss = 1.02144563, grad/param norm = 1.5052e-01, time/batch = 0.6784s	
12604/33150 (epoch 19.011), train_loss = 1.14940990, grad/param norm = 1.6630e-01, time/batch = 0.6721s	
12605/33150 (epoch 19.012), train_loss = 1.01923470, grad/param norm = 1.7160e-01, time/batch = 0.6836s	
12606/33150 (epoch 19.014), train_loss = 0.98269656, grad/param norm = 1.5785e-01, time/batch = 0.6687s	
12607/33150 (epoch 19.015), train_loss = 0.98123846, grad/param norm = 1.5474e-01, time/batch = 0.6741s	
12608/33150 (epoch 19.017), train_loss = 0.94619410, grad/param norm = 1.4160e-01, time/batch = 0.6758s	
12609/33150 (epoch 19.018), train_loss = 1.06573370, grad/param norm = 1.6641e-01, time/batch = 0.6672s	
12610/33150 (epoch 19.020), train_loss = 1.10458190, grad/param norm = 1.6946e-01, time/batch = 0.6745s	
12611/33150 (epoch 19.021), train_loss = 0.92264052, grad/param norm = 1.5737e-01, time/batch = 0.6901s	
12612/33150 (epoch 19.023), train_loss = 1.21085041, grad/param norm = 1.4803e-01, time/batch = 0.6830s	
12613/33150 (epoch 19.024), train_loss = 1.09288566, grad/param norm = 1.6301e-01, time/batch = 0.6854s	
12614/33150 (epoch 19.026), train_loss = 0.82699178, grad/param norm = 1.2283e-01, time/batch = 0.6929s	
12615/33150 (epoch 19.027), train_loss = 0.83090935, grad/param norm = 1.2527e-01, time/batch = 0.6819s	
12616/33150 (epoch 19.029), train_loss = 0.94897743, grad/param norm = 1.4725e-01, time/batch = 0.6876s	
12617/33150 (epoch 19.030), train_loss = 1.02318350, grad/param norm = 1.4259e-01, time/batch = 0.6786s	
12618/33150 (epoch 19.032), train_loss = 0.95486845, grad/param norm = 1.6983e-01, time/batch = 0.6792s	
12619/33150 (epoch 19.033), train_loss = 0.96907808, grad/param norm = 1.4416e-01, time/batch = 0.6747s	
12620/33150 (epoch 19.035), train_loss = 1.19873895, grad/param norm = 1.8371e-01, time/batch = 0.6744s	
12621/33150 (epoch 19.036), train_loss = 1.07664593, grad/param norm = 1.5474e-01, time/batch = 0.6752s	
12622/33150 (epoch 19.038), train_loss = 1.31295056, grad/param norm = 1.9424e-01, time/batch = 0.6754s	
12623/33150 (epoch 19.039), train_loss = 1.08795395, grad/param norm = 1.4025e-01, time/batch = 0.6816s	
12624/33150 (epoch 19.041), train_loss = 1.06654628, grad/param norm = 1.4766e-01, time/batch = 0.6857s	
12625/33150 (epoch 19.042), train_loss = 0.99978961, grad/param norm = 1.4090e-01, time/batch = 0.6834s	
12626/33150 (epoch 19.044), train_loss = 1.01226056, grad/param norm = 1.4048e-01, time/batch = 0.6921s	
12627/33150 (epoch 19.045), train_loss = 1.05151561, grad/param norm = 1.4788e-01, time/batch = 0.6948s	
12628/33150 (epoch 19.047), train_loss = 0.91027370, grad/param norm = 1.5385e-01, time/batch = 0.6919s	
12629/33150 (epoch 19.048), train_loss = 1.11641985, grad/param norm = 1.7052e-01, time/batch = 0.6824s	
12630/33150 (epoch 19.050), train_loss = 1.04357351, grad/param norm = 1.5624e-01, time/batch = 0.6799s	
12631/33150 (epoch 19.051), train_loss = 1.04013777, grad/param norm = 1.4427e-01, time/batch = 0.6848s	
12632/33150 (epoch 19.053), train_loss = 0.99929991, grad/param norm = 1.3802e-01, time/batch = 0.6850s	
12633/33150 (epoch 19.054), train_loss = 1.15832525, grad/param norm = 1.4827e-01, time/batch = 0.6869s	
12634/33150 (epoch 19.056), train_loss = 1.01069172, grad/param norm = 1.4828e-01, time/batch = 0.6797s	
12635/33150 (epoch 19.057), train_loss = 1.02514662, grad/param norm = 1.5496e-01, time/batch = 0.6854s	
12636/33150 (epoch 19.059), train_loss = 0.94731867, grad/param norm = 1.6092e-01, time/batch = 0.6779s	
12637/33150 (epoch 19.060), train_loss = 0.95842714, grad/param norm = 1.2991e-01, time/batch = 0.6794s	
12638/33150 (epoch 19.062), train_loss = 0.99833653, grad/param norm = 1.6040e-01, time/batch = 0.6768s	
12639/33150 (epoch 19.063), train_loss = 0.97769468, grad/param norm = 1.6255e-01, time/batch = 0.6940s	
12640/33150 (epoch 19.065), train_loss = 0.98962063, grad/param norm = 1.3530e-01, time/batch = 0.7014s	
12641/33150 (epoch 19.066), train_loss = 0.95320859, grad/param norm = 1.4736e-01, time/batch = 0.7012s	
12642/33150 (epoch 19.068), train_loss = 1.04280889, grad/param norm = 1.4243e-01, time/batch = 0.6795s	
12643/33150 (epoch 19.069), train_loss = 1.09148251, grad/param norm = 1.7788e-01, time/batch = 0.6768s	
12644/33150 (epoch 19.071), train_loss = 1.06596619, grad/param norm = 1.5722e-01, time/batch = 0.6825s	
12645/33150 (epoch 19.072), train_loss = 0.99347373, grad/param norm = 1.4633e-01, time/batch = 0.6901s	
12646/33150 (epoch 19.074), train_loss = 0.89578211, grad/param norm = 1.5088e-01, time/batch = 0.6855s	
12647/33150 (epoch 19.075), train_loss = 0.98518436, grad/param norm = 1.6339e-01, time/batch = 0.6815s	
12648/33150 (epoch 19.077), train_loss = 1.02553171, grad/param norm = 1.8977e-01, time/batch = 0.6812s	
12649/33150 (epoch 19.078), train_loss = 1.16107550, grad/param norm = 1.7443e-01, time/batch = 0.6759s	
12650/33150 (epoch 19.080), train_loss = 1.14317982, grad/param norm = 1.4231e-01, time/batch = 0.6762s	
12651/33150 (epoch 19.081), train_loss = 0.92450217, grad/param norm = 1.6670e-01, time/batch = 0.6741s	
12652/33150 (epoch 19.083), train_loss = 0.77603671, grad/param norm = 1.5257e-01, time/batch = 0.6755s	
12653/33150 (epoch 19.084), train_loss = 0.90272610, grad/param norm = 1.7943e-01, time/batch = 0.6742s	
12654/33150 (epoch 19.086), train_loss = 0.96061018, grad/param norm = 1.7235e-01, time/batch = 0.6787s	
12655/33150 (epoch 19.087), train_loss = 0.89651559, grad/param norm = 1.3073e-01, time/batch = 0.6771s	
12656/33150 (epoch 19.089), train_loss = 0.93203585, grad/param norm = 1.5798e-01, time/batch = 0.6880s	
12657/33150 (epoch 19.090), train_loss = 0.96515504, grad/param norm = 1.4720e-01, time/batch = 0.6860s	
12658/33150 (epoch 19.092), train_loss = 0.96603090, grad/param norm = 1.5487e-01, time/batch = 0.6819s	
12659/33150 (epoch 19.094), train_loss = 1.07205868, grad/param norm = 1.5807e-01, time/batch = 0.6768s	
12660/33150 (epoch 19.095), train_loss = 0.89037527, grad/param norm = 1.2431e-01, time/batch = 0.6794s	
12661/33150 (epoch 19.097), train_loss = 0.95932822, grad/param norm = 1.6188e-01, time/batch = 0.6912s	
12662/33150 (epoch 19.098), train_loss = 1.24814216, grad/param norm = 1.6487e-01, time/batch = 0.6806s	
12663/33150 (epoch 19.100), train_loss = 1.20802357, grad/param norm = 1.6502e-01, time/batch = 0.6818s	
12664/33150 (epoch 19.101), train_loss = 0.95722088, grad/param norm = 1.6284e-01, time/batch = 0.6797s	
12665/33150 (epoch 19.103), train_loss = 1.02161675, grad/param norm = 1.4069e-01, time/batch = 0.6806s	
12666/33150 (epoch 19.104), train_loss = 0.93032355, grad/param norm = 1.9000e-01, time/batch = 0.6808s	
12667/33150 (epoch 19.106), train_loss = 1.13729605, grad/param norm = 2.0682e-01, time/batch = 0.6817s	
12668/33150 (epoch 19.107), train_loss = 1.26110176, grad/param norm = 1.7615e-01, time/batch = 0.6771s	
12669/33150 (epoch 19.109), train_loss = 0.98862043, grad/param norm = 1.4503e-01, time/batch = 0.6782s	
12670/33150 (epoch 19.110), train_loss = 1.13459961, grad/param norm = 1.6294e-01, time/batch = 0.6822s	
12671/33150 (epoch 19.112), train_loss = 0.94303265, grad/param norm = 1.4971e-01, time/batch = 0.6983s	
12672/33150 (epoch 19.113), train_loss = 1.00941292, grad/param norm = 1.6538e-01, time/batch = 0.6909s	
12673/33150 (epoch 19.115), train_loss = 1.18616406, grad/param norm = 1.5881e-01, time/batch = 0.6791s	
12674/33150 (epoch 19.116), train_loss = 0.99868661, grad/param norm = 1.3654e-01, time/batch = 0.6791s	
12675/33150 (epoch 19.118), train_loss = 1.10503275, grad/param norm = 2.1391e-01, time/batch = 0.6792s	
12676/33150 (epoch 19.119), train_loss = 1.11133808, grad/param norm = 1.8524e-01, time/batch = 0.6790s	
12677/33150 (epoch 19.121), train_loss = 1.00923732, grad/param norm = 1.4765e-01, time/batch = 0.6827s	
12678/33150 (epoch 19.122), train_loss = 1.22334284, grad/param norm = 1.8239e-01, time/batch = 0.6820s	
12679/33150 (epoch 19.124), train_loss = 0.85513064, grad/param norm = 1.2561e-01, time/batch = 0.6835s	
12680/33150 (epoch 19.125), train_loss = 1.09490516, grad/param norm = 1.4322e-01, time/batch = 0.6830s	
12681/33150 (epoch 19.127), train_loss = 1.00588457, grad/param norm = 1.4299e-01, time/batch = 0.6823s	
12682/33150 (epoch 19.128), train_loss = 1.05622939, grad/param norm = 1.6457e-01, time/batch = 0.6796s	
12683/33150 (epoch 19.130), train_loss = 1.07264704, grad/param norm = 1.5238e-01, time/batch = 0.6786s	
12684/33150 (epoch 19.131), train_loss = 1.26223914, grad/param norm = 1.7697e-01, time/batch = 0.6945s	
12685/33150 (epoch 19.133), train_loss = 0.95577743, grad/param norm = 1.3552e-01, time/batch = 0.6903s	
12686/33150 (epoch 19.134), train_loss = 1.13081069, grad/param norm = 1.6609e-01, time/batch = 0.6828s	
12687/33150 (epoch 19.136), train_loss = 1.03896262, grad/param norm = 1.6530e-01, time/batch = 0.6725s	
12688/33150 (epoch 19.137), train_loss = 1.14991110, grad/param norm = 1.6863e-01, time/batch = 0.6784s	
12689/33150 (epoch 19.139), train_loss = 1.10260801, grad/param norm = 1.6989e-01, time/batch = 0.6798s	
12690/33150 (epoch 19.140), train_loss = 1.19062382, grad/param norm = 1.6712e-01, time/batch = 0.6758s	
12691/33150 (epoch 19.142), train_loss = 1.12073812, grad/param norm = 1.6220e-01, time/batch = 0.6734s	
12692/33150 (epoch 19.143), train_loss = 1.04145968, grad/param norm = 1.6942e-01, time/batch = 0.6677s	
12693/33150 (epoch 19.145), train_loss = 0.99786189, grad/param norm = 1.5976e-01, time/batch = 0.6684s	
12694/33150 (epoch 19.146), train_loss = 1.15100765, grad/param norm = 1.8146e-01, time/batch = 0.6673s	
12695/33150 (epoch 19.148), train_loss = 1.13769153, grad/param norm = 1.4585e-01, time/batch = 0.6701s	
12696/33150 (epoch 19.149), train_loss = 1.06153863, grad/param norm = 1.5759e-01, time/batch = 0.6691s	
12697/33150 (epoch 19.151), train_loss = 1.21540658, grad/param norm = 1.6323e-01, time/batch = 0.6814s	
12698/33150 (epoch 19.152), train_loss = 0.98405480, grad/param norm = 1.3951e-01, time/batch = 0.6718s	
12699/33150 (epoch 19.154), train_loss = 1.01356536, grad/param norm = 1.5655e-01, time/batch = 0.6757s	
12700/33150 (epoch 19.155), train_loss = 0.89067947, grad/param norm = 1.5383e-01, time/batch = 0.6736s	
12701/33150 (epoch 19.157), train_loss = 0.98499744, grad/param norm = 1.6008e-01, time/batch = 0.6738s	
12702/33150 (epoch 19.158), train_loss = 0.97163447, grad/param norm = 1.5199e-01, time/batch = 0.6711s	
12703/33150 (epoch 19.160), train_loss = 1.06836317, grad/param norm = 1.5152e-01, time/batch = 0.6700s	
12704/33150 (epoch 19.161), train_loss = 0.95741461, grad/param norm = 1.5589e-01, time/batch = 0.6743s	
12705/33150 (epoch 19.163), train_loss = 0.95533710, grad/param norm = 1.5122e-01, time/batch = 0.6781s	
12706/33150 (epoch 19.164), train_loss = 1.08888997, grad/param norm = 1.6866e-01, time/batch = 0.6722s	
12707/33150 (epoch 19.166), train_loss = 1.01680228, grad/param norm = 1.6565e-01, time/batch = 0.6731s	
12708/33150 (epoch 19.167), train_loss = 1.06606961, grad/param norm = 1.5022e-01, time/batch = 0.6880s	
12709/33150 (epoch 19.169), train_loss = 1.09050082, grad/param norm = 2.0190e-01, time/batch = 0.6730s	
12710/33150 (epoch 19.170), train_loss = 0.93263549, grad/param norm = 1.6050e-01, time/batch = 0.6713s	
12711/33150 (epoch 19.172), train_loss = 1.14360174, grad/param norm = 1.9193e-01, time/batch = 0.6743s	
12712/33150 (epoch 19.173), train_loss = 1.11505729, grad/param norm = 1.9823e-01, time/batch = 0.6739s	
12713/33150 (epoch 19.175), train_loss = 0.96496822, grad/param norm = 1.5541e-01, time/batch = 0.6922s	
12714/33150 (epoch 19.176), train_loss = 1.09598756, grad/param norm = 1.6989e-01, time/batch = 0.6917s	
12715/33150 (epoch 19.178), train_loss = 1.19850760, grad/param norm = 1.7115e-01, time/batch = 0.7026s	
12716/33150 (epoch 19.179), train_loss = 1.10117512, grad/param norm = 1.4829e-01, time/batch = 0.7098s	
12717/33150 (epoch 19.181), train_loss = 1.05554303, grad/param norm = 1.6332e-01, time/batch = 0.6964s	
12718/33150 (epoch 19.183), train_loss = 1.01609774, grad/param norm = 1.5744e-01, time/batch = 0.6753s	
12719/33150 (epoch 19.184), train_loss = 1.24580365, grad/param norm = 1.6861e-01, time/batch = 0.6779s	
12720/33150 (epoch 19.186), train_loss = 1.14520757, grad/param norm = 1.5548e-01, time/batch = 0.6908s	
12721/33150 (epoch 19.187), train_loss = 1.08885995, grad/param norm = 1.6860e-01, time/batch = 0.7013s	
12722/33150 (epoch 19.189), train_loss = 0.83052873, grad/param norm = 1.4308e-01, time/batch = 0.6907s	
12723/33150 (epoch 19.190), train_loss = 0.92825568, grad/param norm = 1.5319e-01, time/batch = 0.6831s	
12724/33150 (epoch 19.192), train_loss = 1.05301085, grad/param norm = 1.7568e-01, time/batch = 0.6954s	
12725/33150 (epoch 19.193), train_loss = 1.11167395, grad/param norm = 1.6685e-01, time/batch = 0.6901s	
12726/33150 (epoch 19.195), train_loss = 1.28893266, grad/param norm = 1.9900e-01, time/batch = 0.6780s	
12727/33150 (epoch 19.196), train_loss = 1.15218693, grad/param norm = 1.5353e-01, time/batch = 0.6706s	
12728/33150 (epoch 19.198), train_loss = 0.90200056, grad/param norm = 1.6481e-01, time/batch = 0.6724s	
12729/33150 (epoch 19.199), train_loss = 1.13933762, grad/param norm = 1.9982e-01, time/batch = 0.6746s	
12730/33150 (epoch 19.201), train_loss = 0.95189842, grad/param norm = 1.3819e-01, time/batch = 0.6719s	
12731/33150 (epoch 19.202), train_loss = 0.82897396, grad/param norm = 1.4272e-01, time/batch = 0.6778s	
12732/33150 (epoch 19.204), train_loss = 1.05762137, grad/param norm = 1.5777e-01, time/batch = 0.6890s	
12733/33150 (epoch 19.205), train_loss = 1.12888470, grad/param norm = 1.6659e-01, time/batch = 0.6871s	
12734/33150 (epoch 19.207), train_loss = 1.07609233, grad/param norm = 1.5184e-01, time/batch = 0.6863s	
12735/33150 (epoch 19.208), train_loss = 1.10414247, grad/param norm = 1.5491e-01, time/batch = 0.6778s	
12736/33150 (epoch 19.210), train_loss = 0.96624408, grad/param norm = 1.3654e-01, time/batch = 0.6901s	
12737/33150 (epoch 19.211), train_loss = 1.07922522, grad/param norm = 1.7517e-01, time/batch = 0.6750s	
12738/33150 (epoch 19.213), train_loss = 1.08980052, grad/param norm = 1.4140e-01, time/batch = 0.6847s	
12739/33150 (epoch 19.214), train_loss = 1.02883076, grad/param norm = 1.5373e-01, time/batch = 0.6795s	
12740/33150 (epoch 19.216), train_loss = 0.95351674, grad/param norm = 1.4569e-01, time/batch = 0.6732s	
12741/33150 (epoch 19.217), train_loss = 0.99438253, grad/param norm = 1.4027e-01, time/batch = 0.6777s	
12742/33150 (epoch 19.219), train_loss = 0.91529726, grad/param norm = 1.4787e-01, time/batch = 0.6732s	
12743/33150 (epoch 19.220), train_loss = 0.95208262, grad/param norm = 1.3064e-01, time/batch = 0.6726s	
12744/33150 (epoch 19.222), train_loss = 1.13001971, grad/param norm = 1.4748e-01, time/batch = 0.6774s	
12745/33150 (epoch 19.223), train_loss = 1.06119390, grad/param norm = 1.7415e-01, time/batch = 0.6716s	
12746/33150 (epoch 19.225), train_loss = 1.17476534, grad/param norm = 1.6418e-01, time/batch = 0.6699s	
12747/33150 (epoch 19.226), train_loss = 1.02108313, grad/param norm = 1.5037e-01, time/batch = 0.6724s	
12748/33150 (epoch 19.228), train_loss = 1.02548689, grad/param norm = 1.4646e-01, time/batch = 0.6701s	
12749/33150 (epoch 19.229), train_loss = 1.03238389, grad/param norm = 1.5125e-01, time/batch = 0.6773s	
12750/33150 (epoch 19.231), train_loss = 1.17323255, grad/param norm = 1.7518e-01, time/batch = 0.6709s	
12751/33150 (epoch 19.232), train_loss = 1.08952781, grad/param norm = 1.8514e-01, time/batch = 0.6712s	
12752/33150 (epoch 19.234), train_loss = 1.05130255, grad/param norm = 1.7234e-01, time/batch = 0.6795s	
12753/33150 (epoch 19.235), train_loss = 1.09572275, grad/param norm = 1.8174e-01, time/batch = 0.6857s	
12754/33150 (epoch 19.237), train_loss = 1.04655660, grad/param norm = 2.0541e-01, time/batch = 0.6860s	
12755/33150 (epoch 19.238), train_loss = 1.09145980, grad/param norm = 1.8179e-01, time/batch = 0.6780s	
12756/33150 (epoch 19.240), train_loss = 1.07476881, grad/param norm = 1.5298e-01, time/batch = 0.6740s	
12757/33150 (epoch 19.241), train_loss = 1.16329938, grad/param norm = 1.7784e-01, time/batch = 0.6861s	
12758/33150 (epoch 19.243), train_loss = 1.11932495, grad/param norm = 1.7443e-01, time/batch = 0.6773s	
12759/33150 (epoch 19.244), train_loss = 1.02790311, grad/param norm = 1.4363e-01, time/batch = 0.6755s	
12760/33150 (epoch 19.246), train_loss = 1.11036965, grad/param norm = 1.4237e-01, time/batch = 0.6760s	
12761/33150 (epoch 19.247), train_loss = 0.99398310, grad/param norm = 1.6027e-01, time/batch = 0.6741s	
12762/33150 (epoch 19.249), train_loss = 1.12477209, grad/param norm = 1.5381e-01, time/batch = 0.6742s	
12763/33150 (epoch 19.250), train_loss = 1.09949321, grad/param norm = 1.3820e-01, time/batch = 0.6694s	
12764/33150 (epoch 19.252), train_loss = 1.09586536, grad/param norm = 1.3528e-01, time/batch = 0.6724s	
12765/33150 (epoch 19.253), train_loss = 1.04473598, grad/param norm = 1.5257e-01, time/batch = 0.6824s	
12766/33150 (epoch 19.255), train_loss = 1.02874414, grad/param norm = 1.4345e-01, time/batch = 0.6690s	
12767/33150 (epoch 19.256), train_loss = 1.09139856, grad/param norm = 1.4539e-01, time/batch = 0.6791s	
12768/33150 (epoch 19.258), train_loss = 0.99803508, grad/param norm = 1.6292e-01, time/batch = 0.6836s	
12769/33150 (epoch 19.259), train_loss = 0.87080994, grad/param norm = 1.4799e-01, time/batch = 0.6828s	
12770/33150 (epoch 19.261), train_loss = 0.91785026, grad/param norm = 1.3902e-01, time/batch = 0.6799s	
12771/33150 (epoch 19.262), train_loss = 1.10030635, grad/param norm = 1.5856e-01, time/batch = 0.6769s	
12772/33150 (epoch 19.264), train_loss = 0.82451040, grad/param norm = 1.3101e-01, time/batch = 0.6907s	
12773/33150 (epoch 19.265), train_loss = 1.08604259, grad/param norm = 1.5008e-01, time/batch = 0.6814s	
12774/33150 (epoch 19.267), train_loss = 1.11195359, grad/param norm = 1.7352e-01, time/batch = 0.6803s	
12775/33150 (epoch 19.268), train_loss = 1.13028775, grad/param norm = 1.5297e-01, time/batch = 0.6825s	
12776/33150 (epoch 19.270), train_loss = 1.21304026, grad/param norm = 1.6311e-01, time/batch = 0.6775s	
12777/33150 (epoch 19.271), train_loss = 1.18960570, grad/param norm = 1.8613e-01, time/batch = 0.6718s	
12778/33150 (epoch 19.273), train_loss = 1.16303849, grad/param norm = 1.5570e-01, time/batch = 0.6687s	
12779/33150 (epoch 19.275), train_loss = 1.18492318, grad/param norm = 1.6421e-01, time/batch = 0.6704s	
12780/33150 (epoch 19.276), train_loss = 1.04246991, grad/param norm = 1.5644e-01, time/batch = 0.6679s	
12781/33150 (epoch 19.278), train_loss = 1.12130909, grad/param norm = 1.5839e-01, time/batch = 0.6700s	
12782/33150 (epoch 19.279), train_loss = 1.08499019, grad/param norm = 1.4480e-01, time/batch = 0.6692s	
12783/33150 (epoch 19.281), train_loss = 1.07527630, grad/param norm = 1.4837e-01, time/batch = 0.6689s	
12784/33150 (epoch 19.282), train_loss = 1.05916148, grad/param norm = 1.3403e-01, time/batch = 0.6708s	
12785/33150 (epoch 19.284), train_loss = 0.99128813, grad/param norm = 1.4427e-01, time/batch = 0.6734s	
12786/33150 (epoch 19.285), train_loss = 1.07207639, grad/param norm = 1.4016e-01, time/batch = 0.6895s	
12787/33150 (epoch 19.287), train_loss = 0.94740711, grad/param norm = 1.3425e-01, time/batch = 0.6767s	
12788/33150 (epoch 19.288), train_loss = 1.16782201, grad/param norm = 1.5264e-01, time/batch = 0.6750s	
12789/33150 (epoch 19.290), train_loss = 0.89404870, grad/param norm = 1.5219e-01, time/batch = 0.6826s	
12790/33150 (epoch 19.291), train_loss = 0.88021611, grad/param norm = 1.5919e-01, time/batch = 0.6810s	
12791/33150 (epoch 19.293), train_loss = 1.10226317, grad/param norm = 1.4802e-01, time/batch = 0.6737s	
12792/33150 (epoch 19.294), train_loss = 0.79708851, grad/param norm = 1.3898e-01, time/batch = 0.6727s	
12793/33150 (epoch 19.296), train_loss = 1.02447315, grad/param norm = 1.4982e-01, time/batch = 0.6738s	
12794/33150 (epoch 19.297), train_loss = 0.98107548, grad/param norm = 1.4283e-01, time/batch = 0.6702s	
12795/33150 (epoch 19.299), train_loss = 0.97451745, grad/param norm = 1.7609e-01, time/batch = 0.6866s	
12796/33150 (epoch 19.300), train_loss = 0.97703586, grad/param norm = 1.3585e-01, time/batch = 0.6799s	
12797/33150 (epoch 19.302), train_loss = 0.99535048, grad/param norm = 1.4401e-01, time/batch = 0.6858s	
12798/33150 (epoch 19.303), train_loss = 1.01106827, grad/param norm = 1.5520e-01, time/batch = 0.6897s	
12799/33150 (epoch 19.305), train_loss = 1.09860157, grad/param norm = 1.4421e-01, time/batch = 0.6863s	
12800/33150 (epoch 19.306), train_loss = 1.09145867, grad/param norm = 1.5917e-01, time/batch = 0.6873s	
12801/33150 (epoch 19.308), train_loss = 1.26393657, grad/param norm = 1.6544e-01, time/batch = 0.6917s	
12802/33150 (epoch 19.309), train_loss = 0.87241489, grad/param norm = 1.3062e-01, time/batch = 0.6929s	
12803/33150 (epoch 19.311), train_loss = 0.99798779, grad/param norm = 1.5794e-01, time/batch = 0.6950s	
12804/33150 (epoch 19.312), train_loss = 0.82940403, grad/param norm = 1.4904e-01, time/batch = 0.6919s	
12805/33150 (epoch 19.314), train_loss = 1.00568202, grad/param norm = 1.6049e-01, time/batch = 0.6974s	
12806/33150 (epoch 19.315), train_loss = 1.06026915, grad/param norm = 1.4772e-01, time/batch = 0.6853s	
12807/33150 (epoch 19.317), train_loss = 0.81000246, grad/param norm = 1.1743e-01, time/batch = 0.6697s	
12808/33150 (epoch 19.318), train_loss = 0.93598023, grad/param norm = 1.3940e-01, time/batch = 0.6706s	
12809/33150 (epoch 19.320), train_loss = 0.89330036, grad/param norm = 1.3907e-01, time/batch = 0.6685s	
12810/33150 (epoch 19.321), train_loss = 0.97303745, grad/param norm = 1.3520e-01, time/batch = 0.6740s	
12811/33150 (epoch 19.323), train_loss = 1.04120446, grad/param norm = 1.5812e-01, time/batch = 0.6736s	
12812/33150 (epoch 19.324), train_loss = 1.11735829, grad/param norm = 1.8507e-01, time/batch = 0.6931s	
12813/33150 (epoch 19.326), train_loss = 1.06553104, grad/param norm = 1.4204e-01, time/batch = 0.6839s	
12814/33150 (epoch 19.327), train_loss = 1.15395794, grad/param norm = 1.5023e-01, time/batch = 0.6762s	
12815/33150 (epoch 19.329), train_loss = 1.09179206, grad/param norm = 1.4606e-01, time/batch = 0.6777s	
12816/33150 (epoch 19.330), train_loss = 1.03393916, grad/param norm = 1.5910e-01, time/batch = 0.6910s	
12817/33150 (epoch 19.332), train_loss = 1.02735196, grad/param norm = 1.3855e-01, time/batch = 0.6775s	
12818/33150 (epoch 19.333), train_loss = 1.07731804, grad/param norm = 1.4439e-01, time/batch = 0.6752s	
12819/33150 (epoch 19.335), train_loss = 0.98206408, grad/param norm = 1.4706e-01, time/batch = 0.6772s	
12820/33150 (epoch 19.336), train_loss = 0.96175107, grad/param norm = 1.6060e-01, time/batch = 0.6729s	
12821/33150 (epoch 19.338), train_loss = 0.84854251, grad/param norm = 1.3798e-01, time/batch = 0.6737s	
12822/33150 (epoch 19.339), train_loss = 1.12487891, grad/param norm = 1.6148e-01, time/batch = 0.6815s	
12823/33150 (epoch 19.341), train_loss = 1.11569976, grad/param norm = 1.7665e-01, time/batch = 0.6842s	
12824/33150 (epoch 19.342), train_loss = 0.92122017, grad/param norm = 1.4970e-01, time/batch = 0.6761s	
12825/33150 (epoch 19.344), train_loss = 1.06256230, grad/param norm = 1.5870e-01, time/batch = 0.6757s	
12826/33150 (epoch 19.345), train_loss = 1.00437143, grad/param norm = 1.5195e-01, time/batch = 0.6732s	
12827/33150 (epoch 19.347), train_loss = 0.86063486, grad/param norm = 1.6865e-01, time/batch = 0.6766s	
12828/33150 (epoch 19.348), train_loss = 1.05538021, grad/param norm = 1.4263e-01, time/batch = 0.6839s	
12829/33150 (epoch 19.350), train_loss = 0.96183074, grad/param norm = 1.7752e-01, time/batch = 0.6767s	
12830/33150 (epoch 19.351), train_loss = 1.10502553, grad/param norm = 1.6141e-01, time/batch = 0.6753s	
12831/33150 (epoch 19.353), train_loss = 1.07804537, grad/param norm = 1.6445e-01, time/batch = 0.6762s	
12832/33150 (epoch 19.354), train_loss = 1.31313105, grad/param norm = 1.7343e-01, time/batch = 0.6777s	
12833/33150 (epoch 19.356), train_loss = 1.15761839, grad/param norm = 1.6210e-01, time/batch = 0.6770s	
12834/33150 (epoch 19.357), train_loss = 1.10447791, grad/param norm = 1.7165e-01, time/batch = 0.6780s	
12835/33150 (epoch 19.359), train_loss = 1.09645849, grad/param norm = 1.6205e-01, time/batch = 0.6748s	
12836/33150 (epoch 19.360), train_loss = 1.10959534, grad/param norm = 1.8356e-01, time/batch = 0.6705s	
12837/33150 (epoch 19.362), train_loss = 1.13393710, grad/param norm = 1.5629e-01, time/batch = 0.6749s	
12838/33150 (epoch 19.363), train_loss = 1.04586273, grad/param norm = 1.4090e-01, time/batch = 0.6767s	
12839/33150 (epoch 19.365), train_loss = 1.02638069, grad/param norm = 1.4879e-01, time/batch = 0.6804s	
12840/33150 (epoch 19.367), train_loss = 0.96803030, grad/param norm = 1.4714e-01, time/batch = 0.6777s	
12841/33150 (epoch 19.368), train_loss = 1.03879106, grad/param norm = 1.8906e-01, time/batch = 0.6787s	
12842/33150 (epoch 19.370), train_loss = 1.05652919, grad/param norm = 1.6785e-01, time/batch = 0.6803s	
12843/33150 (epoch 19.371), train_loss = 0.93095717, grad/param norm = 1.3346e-01, time/batch = 0.6810s	
12844/33150 (epoch 19.373), train_loss = 1.10343337, grad/param norm = 1.4873e-01, time/batch = 0.6731s	
12845/33150 (epoch 19.374), train_loss = 0.99316936, grad/param norm = 1.3952e-01, time/batch = 0.6850s	
12846/33150 (epoch 19.376), train_loss = 1.17379683, grad/param norm = 1.5877e-01, time/batch = 0.6800s	
12847/33150 (epoch 19.377), train_loss = 0.98391908, grad/param norm = 1.5716e-01, time/batch = 0.6775s	
12848/33150 (epoch 19.379), train_loss = 1.11516270, grad/param norm = 1.6236e-01, time/batch = 0.6789s	
12849/33150 (epoch 19.380), train_loss = 1.11066087, grad/param norm = 1.4144e-01, time/batch = 0.6878s	
12850/33150 (epoch 19.382), train_loss = 0.99040479, grad/param norm = 1.6417e-01, time/batch = 0.6793s	
12851/33150 (epoch 19.383), train_loss = 0.95661596, grad/param norm = 1.5442e-01, time/batch = 0.6816s	
12852/33150 (epoch 19.385), train_loss = 1.01163878, grad/param norm = 1.4926e-01, time/batch = 0.6975s	
12853/33150 (epoch 19.386), train_loss = 0.88618711, grad/param norm = 1.2794e-01, time/batch = 0.6804s	
12854/33150 (epoch 19.388), train_loss = 0.97588297, grad/param norm = 1.3562e-01, time/batch = 0.6828s	
12855/33150 (epoch 19.389), train_loss = 0.96796170, grad/param norm = 1.3322e-01, time/batch = 0.6670s	
12856/33150 (epoch 19.391), train_loss = 1.20632187, grad/param norm = 1.5200e-01, time/batch = 0.6775s	
12857/33150 (epoch 19.392), train_loss = 0.99122522, grad/param norm = 1.4149e-01, time/batch = 0.6688s	
12858/33150 (epoch 19.394), train_loss = 0.89245985, grad/param norm = 1.2645e-01, time/batch = 0.6763s	
12859/33150 (epoch 19.395), train_loss = 0.89935546, grad/param norm = 1.4928e-01, time/batch = 0.6734s	
12860/33150 (epoch 19.397), train_loss = 0.73249580, grad/param norm = 1.3236e-01, time/batch = 0.6852s	
12861/33150 (epoch 19.398), train_loss = 1.04937600, grad/param norm = 1.6249e-01, time/batch = 0.6729s	
12862/33150 (epoch 19.400), train_loss = 0.98124484, grad/param norm = 1.3774e-01, time/batch = 0.6851s	
12863/33150 (epoch 19.401), train_loss = 0.85302984, grad/param norm = 1.2914e-01, time/batch = 0.6678s	
12864/33150 (epoch 19.403), train_loss = 0.90859524, grad/param norm = 1.3180e-01, time/batch = 0.6690s	
12865/33150 (epoch 19.404), train_loss = 1.01926941, grad/param norm = 1.5844e-01, time/batch = 0.6705s	
12866/33150 (epoch 19.406), train_loss = 0.93643864, grad/param norm = 1.1958e-01, time/batch = 0.6719s	
12867/33150 (epoch 19.407), train_loss = 0.89482296, grad/param norm = 1.4059e-01, time/batch = 0.6714s	
12868/33150 (epoch 19.409), train_loss = 0.82291756, grad/param norm = 1.3794e-01, time/batch = 0.6727s	
12869/33150 (epoch 19.410), train_loss = 1.04340326, grad/param norm = 1.5622e-01, time/batch = 0.6728s	
12870/33150 (epoch 19.412), train_loss = 1.06439746, grad/param norm = 1.5116e-01, time/batch = 0.6712s	
12871/33150 (epoch 19.413), train_loss = 0.96135926, grad/param norm = 1.4907e-01, time/batch = 0.6739s	
12872/33150 (epoch 19.415), train_loss = 1.08371923, grad/param norm = 1.3956e-01, time/batch = 0.6754s	
12873/33150 (epoch 19.416), train_loss = 0.93911442, grad/param norm = 1.3654e-01, time/batch = 0.6830s	
12874/33150 (epoch 19.418), train_loss = 1.17177437, grad/param norm = 2.8856e-01, time/batch = 0.6875s	
12875/33150 (epoch 19.419), train_loss = 0.98347753, grad/param norm = 1.4798e-01, time/batch = 0.6849s	
12876/33150 (epoch 19.421), train_loss = 1.02652785, grad/param norm = 1.5754e-01, time/batch = 0.6751s	
12877/33150 (epoch 19.422), train_loss = 0.97867735, grad/param norm = 1.5951e-01, time/batch = 0.6751s	
12878/33150 (epoch 19.424), train_loss = 0.98039656, grad/param norm = 1.4662e-01, time/batch = 0.6767s	
12879/33150 (epoch 19.425), train_loss = 1.05836700, grad/param norm = 1.4448e-01, time/batch = 0.6737s	
12880/33150 (epoch 19.427), train_loss = 1.02272973, grad/param norm = 1.4092e-01, time/batch = 0.6733s	
12881/33150 (epoch 19.428), train_loss = 1.01775272, grad/param norm = 1.5610e-01, time/batch = 0.6733s	
12882/33150 (epoch 19.430), train_loss = 1.02408057, grad/param norm = 1.5940e-01, time/batch = 0.6703s	
12883/33150 (epoch 19.431), train_loss = 1.09426247, grad/param norm = 1.7904e-01, time/batch = 0.6721s	
12884/33150 (epoch 19.433), train_loss = 1.01388644, grad/param norm = 1.4181e-01, time/batch = 0.6721s	
12885/33150 (epoch 19.434), train_loss = 0.90526540, grad/param norm = 1.4589e-01, time/batch = 0.6895s	
12886/33150 (epoch 19.436), train_loss = 0.96577153, grad/param norm = 1.4494e-01, time/batch = 0.6713s	
12887/33150 (epoch 19.437), train_loss = 1.05218880, grad/param norm = 1.8629e-01, time/batch = 0.6721s	
12888/33150 (epoch 19.439), train_loss = 1.15842170, grad/param norm = 1.5837e-01, time/batch = 0.6705s	
12889/33150 (epoch 19.440), train_loss = 1.12583211, grad/param norm = 1.7911e-01, time/batch = 0.6823s	
12890/33150 (epoch 19.442), train_loss = 0.89478372, grad/param norm = 1.3632e-01, time/batch = 0.6886s	
12891/33150 (epoch 19.443), train_loss = 1.10290909, grad/param norm = 1.5628e-01, time/batch = 0.6919s	
12892/33150 (epoch 19.445), train_loss = 1.03548624, grad/param norm = 1.5001e-01, time/batch = 0.6818s	
12893/33150 (epoch 19.446), train_loss = 1.06807390, grad/param norm = 1.8596e-01, time/batch = 0.6711s	
12894/33150 (epoch 19.448), train_loss = 1.13423615, grad/param norm = 1.6705e-01, time/batch = 0.6826s	
12895/33150 (epoch 19.449), train_loss = 1.05359101, grad/param norm = 1.3846e-01, time/batch = 0.6855s	
12896/33150 (epoch 19.451), train_loss = 1.07599233, grad/param norm = 1.9095e-01, time/batch = 0.6930s	
12897/33150 (epoch 19.452), train_loss = 1.26431500, grad/param norm = 1.6076e-01, time/batch = 0.6786s	
12898/33150 (epoch 19.454), train_loss = 1.02964680, grad/param norm = 1.5174e-01, time/batch = 0.6828s	
12899/33150 (epoch 19.456), train_loss = 0.90468916, grad/param norm = 1.2912e-01, time/batch = 0.6812s	
12900/33150 (epoch 19.457), train_loss = 1.04729770, grad/param norm = 1.5491e-01, time/batch = 0.6718s	
12901/33150 (epoch 19.459), train_loss = 1.16649249, grad/param norm = 2.4360e-01, time/batch = 0.6869s	
12902/33150 (epoch 19.460), train_loss = 1.07790571, grad/param norm = 1.3773e-01, time/batch = 0.6765s	
12903/33150 (epoch 19.462), train_loss = 1.11462162, grad/param norm = 1.8344e-01, time/batch = 0.6754s	
12904/33150 (epoch 19.463), train_loss = 1.28154762, grad/param norm = 1.7540e-01, time/batch = 0.6824s	
12905/33150 (epoch 19.465), train_loss = 0.99276697, grad/param norm = 1.4534e-01, time/batch = 0.6783s	
12906/33150 (epoch 19.466), train_loss = 0.93988284, grad/param norm = 1.3156e-01, time/batch = 0.6889s	
12907/33150 (epoch 19.468), train_loss = 1.29273425, grad/param norm = 1.6237e-01, time/batch = 0.6879s	
12908/33150 (epoch 19.469), train_loss = 1.03029953, grad/param norm = 1.5586e-01, time/batch = 0.6876s	
12909/33150 (epoch 19.471), train_loss = 0.96212898, grad/param norm = 1.4350e-01, time/batch = 0.6812s	
12910/33150 (epoch 19.472), train_loss = 1.03826929, grad/param norm = 1.4197e-01, time/batch = 0.6927s	
12911/33150 (epoch 19.474), train_loss = 1.14325694, grad/param norm = 1.9230e-01, time/batch = 0.6883s	
12912/33150 (epoch 19.475), train_loss = 1.29728784, grad/param norm = 1.6448e-01, time/batch = 0.6811s	
12913/33150 (epoch 19.477), train_loss = 1.14565539, grad/param norm = 1.7503e-01, time/batch = 0.6768s	
12914/33150 (epoch 19.478), train_loss = 1.12434001, grad/param norm = 1.5490e-01, time/batch = 0.6729s	
12915/33150 (epoch 19.480), train_loss = 0.97407320, grad/param norm = 1.5057e-01, time/batch = 0.6757s	
12916/33150 (epoch 19.481), train_loss = 0.88360892, grad/param norm = 1.4775e-01, time/batch = 0.6715s	
12917/33150 (epoch 19.483), train_loss = 0.96852278, grad/param norm = 1.3937e-01, time/batch = 0.6695s	
12918/33150 (epoch 19.484), train_loss = 0.97257610, grad/param norm = 1.5021e-01, time/batch = 0.6691s	
12919/33150 (epoch 19.486), train_loss = 0.99756590, grad/param norm = 1.5363e-01, time/batch = 0.6710s	
12920/33150 (epoch 19.487), train_loss = 1.05840571, grad/param norm = 1.7019e-01, time/batch = 0.6732s	
12921/33150 (epoch 19.489), train_loss = 1.02418122, grad/param norm = 1.5399e-01, time/batch = 0.6775s	
12922/33150 (epoch 19.490), train_loss = 0.87672704, grad/param norm = 1.4120e-01, time/batch = 0.6711s	
12923/33150 (epoch 19.492), train_loss = 0.97399031, grad/param norm = 1.6108e-01, time/batch = 0.6813s	
12924/33150 (epoch 19.493), train_loss = 1.13759302, grad/param norm = 1.7680e-01, time/batch = 0.6707s	
12925/33150 (epoch 19.495), train_loss = 1.14910145, grad/param norm = 1.6106e-01, time/batch = 0.6721s	
12926/33150 (epoch 19.496), train_loss = 0.99092304, grad/param norm = 1.5510e-01, time/batch = 0.6707s	
12927/33150 (epoch 19.498), train_loss = 1.17413415, grad/param norm = 1.8189e-01, time/batch = 0.6705s	
12928/33150 (epoch 19.499), train_loss = 1.15579335, grad/param norm = 1.6988e-01, time/batch = 0.6711s	
12929/33150 (epoch 19.501), train_loss = 1.08975549, grad/param norm = 1.6119e-01, time/batch = 0.6731s	
12930/33150 (epoch 19.502), train_loss = 1.18088852, grad/param norm = 1.8834e-01, time/batch = 0.6713s	
12931/33150 (epoch 19.504), train_loss = 1.11016732, grad/param norm = 1.5640e-01, time/batch = 0.6726s	
12932/33150 (epoch 19.505), train_loss = 1.23511082, grad/param norm = 1.9125e-01, time/batch = 0.6785s	
12933/33150 (epoch 19.507), train_loss = 1.01382766, grad/param norm = 1.4887e-01, time/batch = 0.6782s	
12934/33150 (epoch 19.508), train_loss = 1.00619738, grad/param norm = 1.5819e-01, time/batch = 0.6764s	
12935/33150 (epoch 19.510), train_loss = 1.07052159, grad/param norm = 1.5146e-01, time/batch = 0.6859s	
12936/33150 (epoch 19.511), train_loss = 1.18962146, grad/param norm = 1.7131e-01, time/batch = 0.6820s	
12937/33150 (epoch 19.513), train_loss = 1.06319284, grad/param norm = 1.5966e-01, time/batch = 0.6730s	
12938/33150 (epoch 19.514), train_loss = 0.88883218, grad/param norm = 1.5842e-01, time/batch = 0.6781s	
12939/33150 (epoch 19.516), train_loss = 1.12512726, grad/param norm = 1.9052e-01, time/batch = 0.6726s	
12940/33150 (epoch 19.517), train_loss = 1.15147232, grad/param norm = 1.5604e-01, time/batch = 0.6737s	
12941/33150 (epoch 19.519), train_loss = 0.96590114, grad/param norm = 1.4815e-01, time/batch = 0.6788s	
12942/33150 (epoch 19.520), train_loss = 1.05173443, grad/param norm = 1.4035e-01, time/batch = 0.6797s	
12943/33150 (epoch 19.522), train_loss = 1.19611413, grad/param norm = 1.8932e-01, time/batch = 0.6744s	
12944/33150 (epoch 19.523), train_loss = 0.96413409, grad/param norm = 1.4185e-01, time/batch = 0.6799s	
12945/33150 (epoch 19.525), train_loss = 1.11842647, grad/param norm = 1.6544e-01, time/batch = 0.6908s	
12946/33150 (epoch 19.526), train_loss = 0.97702548, grad/param norm = 1.6497e-01, time/batch = 0.6741s	
12947/33150 (epoch 19.528), train_loss = 1.09297114, grad/param norm = 1.6054e-01, time/batch = 0.6894s	
12948/33150 (epoch 19.529), train_loss = 1.02631857, grad/param norm = 1.4473e-01, time/batch = 0.6761s	
12949/33150 (epoch 19.531), train_loss = 0.87079588, grad/param norm = 1.5101e-01, time/batch = 0.6751s	
12950/33150 (epoch 19.532), train_loss = 1.07337824, grad/param norm = 1.5697e-01, time/batch = 0.6758s	
12951/33150 (epoch 19.534), train_loss = 1.00378990, grad/param norm = 1.3484e-01, time/batch = 0.6751s	
12952/33150 (epoch 19.535), train_loss = 0.97398423, grad/param norm = 1.7397e-01, time/batch = 0.6735s	
12953/33150 (epoch 19.537), train_loss = 1.13498682, grad/param norm = 1.7516e-01, time/batch = 0.6766s	
12954/33150 (epoch 19.538), train_loss = 0.97840457, grad/param norm = 1.4927e-01, time/batch = 0.6753s	
12955/33150 (epoch 19.540), train_loss = 0.89114417, grad/param norm = 1.3940e-01, time/batch = 0.6753s	
12956/33150 (epoch 19.541), train_loss = 1.13068676, grad/param norm = 1.5890e-01, time/batch = 0.6838s	
12957/33150 (epoch 19.543), train_loss = 1.07110420, grad/param norm = 1.5002e-01, time/batch = 0.6862s	
12958/33150 (epoch 19.544), train_loss = 1.10204758, grad/param norm = 1.6864e-01, time/batch = 0.6779s	
12959/33150 (epoch 19.546), train_loss = 1.07973145, grad/param norm = 1.6134e-01, time/batch = 0.6789s	
12960/33150 (epoch 19.548), train_loss = 1.04531702, grad/param norm = 1.6858e-01, time/batch = 0.6869s	
12961/33150 (epoch 19.549), train_loss = 0.98240461, grad/param norm = 1.5733e-01, time/batch = 0.6742s	
12962/33150 (epoch 19.551), train_loss = 0.94855200, grad/param norm = 1.4084e-01, time/batch = 0.6778s	
12963/33150 (epoch 19.552), train_loss = 0.83054396, grad/param norm = 1.3193e-01, time/batch = 0.6740s	
12964/33150 (epoch 19.554), train_loss = 1.11084089, grad/param norm = 1.5250e-01, time/batch = 0.6737s	
12965/33150 (epoch 19.555), train_loss = 1.17452144, grad/param norm = 1.5638e-01, time/batch = 0.6751s	
12966/33150 (epoch 19.557), train_loss = 0.85736348, grad/param norm = 1.4517e-01, time/batch = 0.6714s	
12967/33150 (epoch 19.558), train_loss = 1.11585789, grad/param norm = 1.8006e-01, time/batch = 0.6791s	
12968/33150 (epoch 19.560), train_loss = 1.01014756, grad/param norm = 1.7601e-01, time/batch = 0.6740s	
12969/33150 (epoch 19.561), train_loss = 0.88621271, grad/param norm = 1.5235e-01, time/batch = 0.6785s	
12970/33150 (epoch 19.563), train_loss = 1.10287270, grad/param norm = 1.9418e-01, time/batch = 0.6984s	
12971/33150 (epoch 19.564), train_loss = 1.17875550, grad/param norm = 1.5820e-01, time/batch = 0.6870s	
12972/33150 (epoch 19.566), train_loss = 1.01297593, grad/param norm = 1.4601e-01, time/batch = 0.6721s	
12973/33150 (epoch 19.567), train_loss = 0.94103785, grad/param norm = 1.4639e-01, time/batch = 0.6705s	
12974/33150 (epoch 19.569), train_loss = 1.05089112, grad/param norm = 1.5163e-01, time/batch = 0.6816s	
12975/33150 (epoch 19.570), train_loss = 1.10577382, grad/param norm = 1.4883e-01, time/batch = 0.6775s	
12976/33150 (epoch 19.572), train_loss = 0.95753482, grad/param norm = 1.6506e-01, time/batch = 0.6762s	
12977/33150 (epoch 19.573), train_loss = 0.83284414, grad/param norm = 1.2573e-01, time/batch = 0.6843s	
12978/33150 (epoch 19.575), train_loss = 1.01551972, grad/param norm = 1.5406e-01, time/batch = 0.6929s	
12979/33150 (epoch 19.576), train_loss = 0.90070657, grad/param norm = 1.2920e-01, time/batch = 0.6893s	
12980/33150 (epoch 19.578), train_loss = 0.94841257, grad/param norm = 1.4606e-01, time/batch = 0.6833s	
12981/33150 (epoch 19.579), train_loss = 0.86334287, grad/param norm = 1.3482e-01, time/batch = 0.6796s	
12982/33150 (epoch 19.581), train_loss = 0.96483232, grad/param norm = 1.5292e-01, time/batch = 0.6860s	
12983/33150 (epoch 19.582), train_loss = 1.13771804, grad/param norm = 1.4564e-01, time/batch = 0.6738s	
12984/33150 (epoch 19.584), train_loss = 1.13231944, grad/param norm = 1.6356e-01, time/batch = 0.6740s	
12985/33150 (epoch 19.585), train_loss = 1.04251695, grad/param norm = 1.4878e-01, time/batch = 0.6745s	
12986/33150 (epoch 19.587), train_loss = 1.05118509, grad/param norm = 1.4499e-01, time/batch = 0.6710s	
12987/33150 (epoch 19.588), train_loss = 0.94141735, grad/param norm = 1.5162e-01, time/batch = 0.6895s	
12988/33150 (epoch 19.590), train_loss = 1.04984371, grad/param norm = 1.6388e-01, time/batch = 0.7002s	
12989/33150 (epoch 19.591), train_loss = 1.01003630, grad/param norm = 1.5616e-01, time/batch = 0.7018s	
12990/33150 (epoch 19.593), train_loss = 1.10726731, grad/param norm = 1.5877e-01, time/batch = 0.6960s	
12991/33150 (epoch 19.594), train_loss = 1.02903752, grad/param norm = 1.5438e-01, time/batch = 0.6840s	
12992/33150 (epoch 19.596), train_loss = 0.96860238, grad/param norm = 1.4513e-01, time/batch = 0.6776s	
12993/33150 (epoch 19.597), train_loss = 0.90882454, grad/param norm = 1.6959e-01, time/batch = 0.6860s	
12994/33150 (epoch 19.599), train_loss = 1.18725554, grad/param norm = 1.7645e-01, time/batch = 0.6779s	
12995/33150 (epoch 19.600), train_loss = 1.05643658, grad/param norm = 2.2926e-01, time/batch = 0.6749s	
12996/33150 (epoch 19.602), train_loss = 0.98940720, grad/param norm = 1.5452e-01, time/batch = 0.6846s	
12997/33150 (epoch 19.603), train_loss = 1.11829706, grad/param norm = 1.7610e-01, time/batch = 0.6865s	
12998/33150 (epoch 19.605), train_loss = 0.93613348, grad/param norm = 1.5307e-01, time/batch = 0.6831s	
12999/33150 (epoch 19.606), train_loss = 1.03312364, grad/param norm = 1.8774e-01, time/batch = 0.6881s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch19.61_1.6137.t7	
13000/33150 (epoch 19.608), train_loss = 1.11700442, grad/param norm = 1.6573e-01, time/batch = 0.6937s	
13001/33150 (epoch 19.609), train_loss = 1.47983577, grad/param norm = 2.1173e-01, time/batch = 0.6797s	
13002/33150 (epoch 19.611), train_loss = 0.92689505, grad/param norm = 1.7182e-01, time/batch = 0.6747s	
13003/33150 (epoch 19.612), train_loss = 1.05598208, grad/param norm = 1.6533e-01, time/batch = 0.6764s	
13004/33150 (epoch 19.614), train_loss = 0.90075237, grad/param norm = 1.4299e-01, time/batch = 0.6761s	
13005/33150 (epoch 19.615), train_loss = 0.92145404, grad/param norm = 1.4806e-01, time/batch = 0.6764s	
13006/33150 (epoch 19.617), train_loss = 1.03343725, grad/param norm = 1.5754e-01, time/batch = 0.6933s	
13007/33150 (epoch 19.618), train_loss = 1.05659387, grad/param norm = 1.6799e-01, time/batch = 0.6818s	
13008/33150 (epoch 19.620), train_loss = 0.95169016, grad/param norm = 1.5997e-01, time/batch = 0.6822s	
13009/33150 (epoch 19.621), train_loss = 1.01665958, grad/param norm = 1.4285e-01, time/batch = 0.6790s	
13010/33150 (epoch 19.623), train_loss = 1.09911097, grad/param norm = 1.5481e-01, time/batch = 0.6855s	
13011/33150 (epoch 19.624), train_loss = 0.97053544, grad/param norm = 1.4507e-01, time/batch = 0.6745s	
13012/33150 (epoch 19.626), train_loss = 0.97623803, grad/param norm = 1.4870e-01, time/batch = 0.6718s	
13013/33150 (epoch 19.627), train_loss = 0.93249462, grad/param norm = 1.4540e-01, time/batch = 0.6767s	
13014/33150 (epoch 19.629), train_loss = 0.89367425, grad/param norm = 1.4909e-01, time/batch = 0.6869s	
13015/33150 (epoch 19.630), train_loss = 0.96772178, grad/param norm = 1.4105e-01, time/batch = 0.6737s	
13016/33150 (epoch 19.632), train_loss = 0.87959307, grad/param norm = 1.3061e-01, time/batch = 0.6708s	
13017/33150 (epoch 19.633), train_loss = 0.88925963, grad/param norm = 1.7023e-01, time/batch = 0.6680s	
13018/33150 (epoch 19.635), train_loss = 1.19105222, grad/param norm = 1.5710e-01, time/batch = 0.6726s	
13019/33150 (epoch 19.637), train_loss = 0.88140432, grad/param norm = 1.5207e-01, time/batch = 0.6719s	
13020/33150 (epoch 19.638), train_loss = 0.98751755, grad/param norm = 1.4766e-01, time/batch = 0.6728s	
13021/33150 (epoch 19.640), train_loss = 1.09324428, grad/param norm = 1.6359e-01, time/batch = 0.6706s	
13022/33150 (epoch 19.641), train_loss = 0.89024331, grad/param norm = 1.4350e-01, time/batch = 0.6851s	
13023/33150 (epoch 19.643), train_loss = 0.96707097, grad/param norm = 1.5213e-01, time/batch = 0.6769s	
13024/33150 (epoch 19.644), train_loss = 1.18211930, grad/param norm = 1.6778e-01, time/batch = 0.6774s	
13025/33150 (epoch 19.646), train_loss = 0.97674264, grad/param norm = 1.4238e-01, time/batch = 0.6717s	
13026/33150 (epoch 19.647), train_loss = 1.23845561, grad/param norm = 1.6695e-01, time/batch = 0.6717s	
13027/33150 (epoch 19.649), train_loss = 1.12207345, grad/param norm = 1.7382e-01, time/batch = 0.6742s	
13028/33150 (epoch 19.650), train_loss = 0.91222686, grad/param norm = 1.3253e-01, time/batch = 0.6858s	
13029/33150 (epoch 19.652), train_loss = 1.13820777, grad/param norm = 1.7264e-01, time/batch = 0.6918s	
13030/33150 (epoch 19.653), train_loss = 1.04594092, grad/param norm = 1.4253e-01, time/batch = 0.6934s	
13031/33150 (epoch 19.655), train_loss = 1.07874031, grad/param norm = 1.6444e-01, time/batch = 0.6963s	
13032/33150 (epoch 19.656), train_loss = 0.97788532, grad/param norm = 1.4994e-01, time/batch = 0.6919s	
13033/33150 (epoch 19.658), train_loss = 1.00039484, grad/param norm = 2.1183e-01, time/batch = 0.6846s	
13034/33150 (epoch 19.659), train_loss = 1.30414263, grad/param norm = 2.6936e-01, time/batch = 0.6743s	
13035/33150 (epoch 19.661), train_loss = 1.02404775, grad/param norm = 1.5879e-01, time/batch = 0.6765s	
13036/33150 (epoch 19.662), train_loss = 0.91878837, grad/param norm = 1.5203e-01, time/batch = 0.6742s	
13037/33150 (epoch 19.664), train_loss = 1.15822851, grad/param norm = 1.6014e-01, time/batch = 0.6740s	
13038/33150 (epoch 19.665), train_loss = 1.10197918, grad/param norm = 1.6313e-01, time/batch = 0.6744s	
13039/33150 (epoch 19.667), train_loss = 1.16581862, grad/param norm = 1.8241e-01, time/batch = 0.6778s	
13040/33150 (epoch 19.668), train_loss = 1.11904420, grad/param norm = 1.6178e-01, time/batch = 0.6751s	
13041/33150 (epoch 19.670), train_loss = 0.95015579, grad/param norm = 1.4045e-01, time/batch = 0.6788s	
13042/33150 (epoch 19.671), train_loss = 0.95770290, grad/param norm = 1.5587e-01, time/batch = 0.6883s	
13043/33150 (epoch 19.673), train_loss = 1.15189659, grad/param norm = 1.4417e-01, time/batch = 0.6712s	
13044/33150 (epoch 19.674), train_loss = 1.02963465, grad/param norm = 1.5321e-01, time/batch = 0.6722s	
13045/33150 (epoch 19.676), train_loss = 1.00490875, grad/param norm = 1.4775e-01, time/batch = 0.6823s	
13046/33150 (epoch 19.677), train_loss = 1.22161463, grad/param norm = 1.5623e-01, time/batch = 0.6835s	
13047/33150 (epoch 19.679), train_loss = 1.01519694, grad/param norm = 1.3588e-01, time/batch = 0.6748s	
13048/33150 (epoch 19.680), train_loss = 1.15482893, grad/param norm = 1.5958e-01, time/batch = 0.6788s	
13049/33150 (epoch 19.682), train_loss = 0.99056968, grad/param norm = 1.4177e-01, time/batch = 0.6752s	
13050/33150 (epoch 19.683), train_loss = 0.88368235, grad/param norm = 1.3196e-01, time/batch = 0.6726s	
13051/33150 (epoch 19.685), train_loss = 1.01467417, grad/param norm = 1.7747e-01, time/batch = 0.6841s	
13052/33150 (epoch 19.686), train_loss = 0.88960748, grad/param norm = 1.4108e-01, time/batch = 0.6801s	
13053/33150 (epoch 19.688), train_loss = 0.94349834, grad/param norm = 1.4546e-01, time/batch = 0.6760s	
13054/33150 (epoch 19.689), train_loss = 0.93510642, grad/param norm = 1.3496e-01, time/batch = 0.6733s	
13055/33150 (epoch 19.691), train_loss = 0.83356569, grad/param norm = 1.4649e-01, time/batch = 0.6814s	
13056/33150 (epoch 19.692), train_loss = 0.91747476, grad/param norm = 1.4444e-01, time/batch = 0.6965s	
13057/33150 (epoch 19.694), train_loss = 0.79155572, grad/param norm = 1.2704e-01, time/batch = 0.6875s	
13058/33150 (epoch 19.695), train_loss = 0.95205048, grad/param norm = 1.3839e-01, time/batch = 0.6816s	
13059/33150 (epoch 19.697), train_loss = 0.86944653, grad/param norm = 1.3601e-01, time/batch = 0.6764s	
13060/33150 (epoch 19.698), train_loss = 0.96668311, grad/param norm = 1.4397e-01, time/batch = 0.6850s	
13061/33150 (epoch 19.700), train_loss = 0.76639232, grad/param norm = 1.2366e-01, time/batch = 0.6742s	
13062/33150 (epoch 19.701), train_loss = 0.89270653, grad/param norm = 1.3775e-01, time/batch = 0.6805s	
13063/33150 (epoch 19.703), train_loss = 0.99118332, grad/param norm = 1.5101e-01, time/batch = 0.6720s	
13064/33150 (epoch 19.704), train_loss = 0.85286590, grad/param norm = 1.4045e-01, time/batch = 0.6917s	
13065/33150 (epoch 19.706), train_loss = 0.96800643, grad/param norm = 1.4622e-01, time/batch = 0.6940s	
13066/33150 (epoch 19.707), train_loss = 0.95590567, grad/param norm = 1.5357e-01, time/batch = 0.6909s	
13067/33150 (epoch 19.709), train_loss = 1.00147375, grad/param norm = 1.2799e-01, time/batch = 0.6765s	
13068/33150 (epoch 19.710), train_loss = 1.03290646, grad/param norm = 1.7766e-01, time/batch = 0.6853s	
13069/33150 (epoch 19.712), train_loss = 1.06847184, grad/param norm = 1.5052e-01, time/batch = 0.6746s	
13070/33150 (epoch 19.713), train_loss = 1.05881718, grad/param norm = 1.3766e-01, time/batch = 0.6719s	
13071/33150 (epoch 19.715), train_loss = 0.94881573, grad/param norm = 1.3144e-01, time/batch = 0.6743s	
13072/33150 (epoch 19.716), train_loss = 1.03828447, grad/param norm = 1.5180e-01, time/batch = 0.6768s	
13073/33150 (epoch 19.718), train_loss = 1.04372710, grad/param norm = 1.6870e-01, time/batch = 0.6757s	
13074/33150 (epoch 19.719), train_loss = 1.12121609, grad/param norm = 1.7790e-01, time/batch = 0.6789s	
13075/33150 (epoch 19.721), train_loss = 0.99346242, grad/param norm = 1.7082e-01, time/batch = 0.6843s	
13076/33150 (epoch 19.722), train_loss = 1.03284574, grad/param norm = 1.3876e-01, time/batch = 0.6780s	
13077/33150 (epoch 19.724), train_loss = 0.97367283, grad/param norm = 1.4108e-01, time/batch = 0.6752s	
13078/33150 (epoch 19.725), train_loss = 1.13672514, grad/param norm = 1.7898e-01, time/batch = 0.6794s	
13079/33150 (epoch 19.727), train_loss = 1.07175836, grad/param norm = 1.8821e-01, time/batch = 0.6748s	
13080/33150 (epoch 19.729), train_loss = 1.00011312, grad/param norm = 1.6052e-01, time/batch = 0.6737s	
13081/33150 (epoch 19.730), train_loss = 1.05453749, grad/param norm = 1.6129e-01, time/batch = 0.6734s	
13082/33150 (epoch 19.732), train_loss = 1.11145883, grad/param norm = 1.5929e-01, time/batch = 0.6715s	
13083/33150 (epoch 19.733), train_loss = 0.83431577, grad/param norm = 1.1776e-01, time/batch = 0.6713s	
13084/33150 (epoch 19.735), train_loss = 0.92884047, grad/param norm = 1.4712e-01, time/batch = 0.6756s	
13085/33150 (epoch 19.736), train_loss = 0.97700623, grad/param norm = 1.6447e-01, time/batch = 0.6740s	
13086/33150 (epoch 19.738), train_loss = 1.03483042, grad/param norm = 1.7245e-01, time/batch = 0.6741s	
13087/33150 (epoch 19.739), train_loss = 1.14112107, grad/param norm = 1.7076e-01, time/batch = 0.6704s	
13088/33150 (epoch 19.741), train_loss = 1.11357409, grad/param norm = 1.5364e-01, time/batch = 0.6875s	
13089/33150 (epoch 19.742), train_loss = 0.91609584, grad/param norm = 1.4812e-01, time/batch = 0.6700s	
13090/33150 (epoch 19.744), train_loss = 1.13089592, grad/param norm = 1.7340e-01, time/batch = 0.6691s	
13091/33150 (epoch 19.745), train_loss = 0.97915359, grad/param norm = 1.4614e-01, time/batch = 0.6727s	
13092/33150 (epoch 19.747), train_loss = 0.82114012, grad/param norm = 1.5400e-01, time/batch = 0.6772s	
13093/33150 (epoch 19.748), train_loss = 0.94279408, grad/param norm = 1.4037e-01, time/batch = 0.6716s	
13094/33150 (epoch 19.750), train_loss = 1.08826024, grad/param norm = 1.6509e-01, time/batch = 0.6733s	
13095/33150 (epoch 19.751), train_loss = 1.03430193, grad/param norm = 1.4590e-01, time/batch = 0.6734s	
13096/33150 (epoch 19.753), train_loss = 0.87442496, grad/param norm = 1.5703e-01, time/batch = 0.6736s	
13097/33150 (epoch 19.754), train_loss = 1.25529106, grad/param norm = 2.1334e-01, time/batch = 0.6747s	
13098/33150 (epoch 19.756), train_loss = 1.03407966, grad/param norm = 1.6833e-01, time/batch = 0.6748s	
13099/33150 (epoch 19.757), train_loss = 1.02471455, grad/param norm = 1.4731e-01, time/batch = 0.6727s	
13100/33150 (epoch 19.759), train_loss = 1.14906315, grad/param norm = 1.7762e-01, time/batch = 0.6920s	
13101/33150 (epoch 19.760), train_loss = 1.05898272, grad/param norm = 2.4224e-01, time/batch = 0.6768s	
13102/33150 (epoch 19.762), train_loss = 1.04944792, grad/param norm = 1.8139e-01, time/batch = 0.6784s	
13103/33150 (epoch 19.763), train_loss = 1.08181445, grad/param norm = 1.6375e-01, time/batch = 0.6786s	
13104/33150 (epoch 19.765), train_loss = 1.01691922, grad/param norm = 1.5519e-01, time/batch = 0.7004s	
13105/33150 (epoch 19.766), train_loss = 0.94021159, grad/param norm = 1.6379e-01, time/batch = 0.6774s	
13106/33150 (epoch 19.768), train_loss = 0.96004021, grad/param norm = 1.4292e-01, time/batch = 0.6781s	
13107/33150 (epoch 19.769), train_loss = 1.07395582, grad/param norm = 1.6779e-01, time/batch = 0.6781s	
13108/33150 (epoch 19.771), train_loss = 1.05194799, grad/param norm = 1.6556e-01, time/batch = 0.6762s	
13109/33150 (epoch 19.772), train_loss = 1.10036416, grad/param norm = 1.6659e-01, time/batch = 0.6770s	
13110/33150 (epoch 19.774), train_loss = 1.19892495, grad/param norm = 1.5949e-01, time/batch = 0.6733s	
13111/33150 (epoch 19.775), train_loss = 1.08662376, grad/param norm = 1.9886e-01, time/batch = 0.6773s	
13112/33150 (epoch 19.777), train_loss = 1.08447664, grad/param norm = 1.6782e-01, time/batch = 0.6874s	
13113/33150 (epoch 19.778), train_loss = 1.04108754, grad/param norm = 1.3592e-01, time/batch = 0.6737s	
13114/33150 (epoch 19.780), train_loss = 0.86585164, grad/param norm = 1.3325e-01, time/batch = 0.6720s	
13115/33150 (epoch 19.781), train_loss = 1.00947735, grad/param norm = 1.4030e-01, time/batch = 0.6731s	
13116/33150 (epoch 19.783), train_loss = 1.03757533, grad/param norm = 1.4317e-01, time/batch = 0.6698s	
13117/33150 (epoch 19.784), train_loss = 1.01603697, grad/param norm = 1.8287e-01, time/batch = 0.6692s	
13118/33150 (epoch 19.786), train_loss = 0.99614959, grad/param norm = 1.3868e-01, time/batch = 0.6688s	
13119/33150 (epoch 19.787), train_loss = 0.95242863, grad/param norm = 1.3638e-01, time/batch = 0.6738s	
13120/33150 (epoch 19.789), train_loss = 0.86284787, grad/param norm = 1.4267e-01, time/batch = 0.6697s	
13121/33150 (epoch 19.790), train_loss = 0.88246565, grad/param norm = 1.2417e-01, time/batch = 0.6747s	
13122/33150 (epoch 19.792), train_loss = 1.05123708, grad/param norm = 1.6376e-01, time/batch = 0.6733s	
13123/33150 (epoch 19.793), train_loss = 1.01755349, grad/param norm = 1.6686e-01, time/batch = 0.6879s	
13124/33150 (epoch 19.795), train_loss = 0.97082593, grad/param norm = 1.6141e-01, time/batch = 0.6693s	
13125/33150 (epoch 19.796), train_loss = 0.97119619, grad/param norm = 1.4596e-01, time/batch = 0.6708s	
13126/33150 (epoch 19.798), train_loss = 0.94630191, grad/param norm = 1.2925e-01, time/batch = 0.6737s	
13127/33150 (epoch 19.799), train_loss = 0.85884981, grad/param norm = 1.4810e-01, time/batch = 0.6880s	
13128/33150 (epoch 19.801), train_loss = 1.05572503, grad/param norm = 1.6503e-01, time/batch = 0.6777s	
13129/33150 (epoch 19.802), train_loss = 0.91763539, grad/param norm = 1.4481e-01, time/batch = 0.6747s	
13130/33150 (epoch 19.804), train_loss = 0.96784466, grad/param norm = 1.3466e-01, time/batch = 0.6759s	
13131/33150 (epoch 19.805), train_loss = 0.95007079, grad/param norm = 1.5462e-01, time/batch = 0.6782s	
13132/33150 (epoch 19.807), train_loss = 0.96788150, grad/param norm = 1.3841e-01, time/batch = 0.6720s	
13133/33150 (epoch 19.808), train_loss = 1.09204719, grad/param norm = 1.7034e-01, time/batch = 0.6735s	
13134/33150 (epoch 19.810), train_loss = 0.97693065, grad/param norm = 1.5150e-01, time/batch = 0.6789s	
13135/33150 (epoch 19.811), train_loss = 1.05020173, grad/param norm = 1.8881e-01, time/batch = 0.6747s	
13136/33150 (epoch 19.813), train_loss = 0.96689967, grad/param norm = 1.3384e-01, time/batch = 0.6767s	
13137/33150 (epoch 19.814), train_loss = 1.00164215, grad/param norm = 1.6690e-01, time/batch = 0.6767s	
13138/33150 (epoch 19.816), train_loss = 0.99337641, grad/param norm = 1.5800e-01, time/batch = 0.6848s	
13139/33150 (epoch 19.817), train_loss = 1.06081201, grad/param norm = 1.4781e-01, time/batch = 0.6810s	
13140/33150 (epoch 19.819), train_loss = 1.01429875, grad/param norm = 1.5621e-01, time/batch = 0.6789s	
13141/33150 (epoch 19.821), train_loss = 0.89901136, grad/param norm = 1.3608e-01, time/batch = 0.6764s	
13142/33150 (epoch 19.822), train_loss = 0.94602212, grad/param norm = 1.4168e-01, time/batch = 0.6803s	
13143/33150 (epoch 19.824), train_loss = 0.96243301, grad/param norm = 1.5224e-01, time/batch = 0.6841s	
13144/33150 (epoch 19.825), train_loss = 1.02152703, grad/param norm = 1.4714e-01, time/batch = 0.6939s	
13145/33150 (epoch 19.827), train_loss = 1.07745966, grad/param norm = 1.9264e-01, time/batch = 0.6965s	
13146/33150 (epoch 19.828), train_loss = 0.88287549, grad/param norm = 1.4597e-01, time/batch = 0.6887s	
13147/33150 (epoch 19.830), train_loss = 1.09118082, grad/param norm = 1.6929e-01, time/batch = 0.7040s	
13148/33150 (epoch 19.831), train_loss = 0.95251861, grad/param norm = 1.7028e-01, time/batch = 0.6991s	
13149/33150 (epoch 19.833), train_loss = 0.93822171, grad/param norm = 1.4969e-01, time/batch = 0.6880s	
13150/33150 (epoch 19.834), train_loss = 1.12412309, grad/param norm = 1.6807e-01, time/batch = 0.6970s	
13151/33150 (epoch 19.836), train_loss = 1.13325161, grad/param norm = 1.4511e-01, time/batch = 0.6931s	
13152/33150 (epoch 19.837), train_loss = 1.00888898, grad/param norm = 1.4906e-01, time/batch = 0.6809s	
13153/33150 (epoch 19.839), train_loss = 1.08219380, grad/param norm = 1.5669e-01, time/batch = 0.6862s	
13154/33150 (epoch 19.840), train_loss = 1.07791081, grad/param norm = 1.4767e-01, time/batch = 0.6897s	
13155/33150 (epoch 19.842), train_loss = 1.14703608, grad/param norm = 1.8666e-01, time/batch = 0.6778s	
13156/33150 (epoch 19.843), train_loss = 1.10306159, grad/param norm = 1.6097e-01, time/batch = 0.6683s	
13157/33150 (epoch 19.845), train_loss = 0.95949818, grad/param norm = 1.4408e-01, time/batch = 0.6773s	
13158/33150 (epoch 19.846), train_loss = 1.21696930, grad/param norm = 2.1249e-01, time/batch = 0.6802s	
13159/33150 (epoch 19.848), train_loss = 1.10341701, grad/param norm = 1.6110e-01, time/batch = 0.6733s	
13160/33150 (epoch 19.849), train_loss = 1.15921248, grad/param norm = 1.7129e-01, time/batch = 0.6772s	
13161/33150 (epoch 19.851), train_loss = 1.11380997, grad/param norm = 1.7474e-01, time/batch = 0.6730s	
13162/33150 (epoch 19.852), train_loss = 1.16436133, grad/param norm = 1.5128e-01, time/batch = 0.6714s	
13163/33150 (epoch 19.854), train_loss = 1.01608219, grad/param norm = 1.4573e-01, time/batch = 0.6700s	
13164/33150 (epoch 19.855), train_loss = 0.87402354, grad/param norm = 1.3071e-01, time/batch = 0.6695s	
13165/33150 (epoch 19.857), train_loss = 0.88792083, grad/param norm = 1.5469e-01, time/batch = 0.6698s	
13166/33150 (epoch 19.858), train_loss = 0.97237230, grad/param norm = 1.5013e-01, time/batch = 0.6746s	
13167/33150 (epoch 19.860), train_loss = 0.89700724, grad/param norm = 1.2626e-01, time/batch = 0.6732s	
13168/33150 (epoch 19.861), train_loss = 0.91095678, grad/param norm = 1.4638e-01, time/batch = 0.6959s	
13169/33150 (epoch 19.863), train_loss = 1.01824381, grad/param norm = 1.3576e-01, time/batch = 0.6775s	
13170/33150 (epoch 19.864), train_loss = 1.11709269, grad/param norm = 1.5093e-01, time/batch = 0.6833s	
13171/33150 (epoch 19.866), train_loss = 1.07624677, grad/param norm = 1.5279e-01, time/batch = 0.6754s	
13172/33150 (epoch 19.867), train_loss = 1.03281081, grad/param norm = 1.3771e-01, time/batch = 0.6891s	
13173/33150 (epoch 19.869), train_loss = 1.07001035, grad/param norm = 1.7213e-01, time/batch = 0.6805s	
13174/33150 (epoch 19.870), train_loss = 1.01508386, grad/param norm = 1.6969e-01, time/batch = 0.6753s	
13175/33150 (epoch 19.872), train_loss = 1.04153907, grad/param norm = 1.5474e-01, time/batch = 0.6698s	
13176/33150 (epoch 19.873), train_loss = 0.87073195, grad/param norm = 1.3717e-01, time/batch = 0.6692s	
13177/33150 (epoch 19.875), train_loss = 1.14787776, grad/param norm = 1.5362e-01, time/batch = 0.6702s	
13178/33150 (epoch 19.876), train_loss = 0.89809440, grad/param norm = 1.4150e-01, time/batch = 0.6713s	
13179/33150 (epoch 19.878), train_loss = 0.91100350, grad/param norm = 1.3511e-01, time/batch = 0.6776s	
13180/33150 (epoch 19.879), train_loss = 0.94895828, grad/param norm = 1.5812e-01, time/batch = 0.6693s	
13181/33150 (epoch 19.881), train_loss = 0.94130427, grad/param norm = 1.4690e-01, time/batch = 0.6677s	
13182/33150 (epoch 19.882), train_loss = 0.84268076, grad/param norm = 1.3651e-01, time/batch = 0.6712s	
13183/33150 (epoch 19.884), train_loss = 0.99094303, grad/param norm = 1.5333e-01, time/batch = 0.6763s	
13184/33150 (epoch 19.885), train_loss = 0.79983699, grad/param norm = 1.5123e-01, time/batch = 0.6749s	
13185/33150 (epoch 19.887), train_loss = 1.14759899, grad/param norm = 1.7280e-01, time/batch = 0.6733s	
13186/33150 (epoch 19.888), train_loss = 1.05645032, grad/param norm = 1.6115e-01, time/batch = 0.6829s	
13187/33150 (epoch 19.890), train_loss = 0.93116442, grad/param norm = 1.4316e-01, time/batch = 0.6813s	
13188/33150 (epoch 19.891), train_loss = 0.90141021, grad/param norm = 1.4135e-01, time/batch = 0.6780s	
13189/33150 (epoch 19.893), train_loss = 1.08046047, grad/param norm = 1.6562e-01, time/batch = 0.6859s	
13190/33150 (epoch 19.894), train_loss = 1.08401575, grad/param norm = 1.7153e-01, time/batch = 0.6774s	
13191/33150 (epoch 19.896), train_loss = 0.97598357, grad/param norm = 1.4663e-01, time/batch = 0.6792s	
13192/33150 (epoch 19.897), train_loss = 1.05169468, grad/param norm = 1.4206e-01, time/batch = 0.6752s	
13193/33150 (epoch 19.899), train_loss = 0.86997977, grad/param norm = 1.6281e-01, time/batch = 0.6747s	
13194/33150 (epoch 19.900), train_loss = 1.22735309, grad/param norm = 1.7029e-01, time/batch = 0.6753s	
13195/33150 (epoch 19.902), train_loss = 1.20188480, grad/param norm = 1.6402e-01, time/batch = 0.6765s	
13196/33150 (epoch 19.903), train_loss = 1.03602127, grad/param norm = 1.5373e-01, time/batch = 0.6766s	
13197/33150 (epoch 19.905), train_loss = 1.04827266, grad/param norm = 1.3439e-01, time/batch = 0.6775s	
13198/33150 (epoch 19.906), train_loss = 1.06015337, grad/param norm = 1.7534e-01, time/batch = 0.6754s	
13199/33150 (epoch 19.908), train_loss = 1.14362791, grad/param norm = 1.5822e-01, time/batch = 0.6758s	
13200/33150 (epoch 19.910), train_loss = 1.09613726, grad/param norm = 1.6201e-01, time/batch = 0.7003s	
13201/33150 (epoch 19.911), train_loss = 0.86768420, grad/param norm = 1.3459e-01, time/batch = 0.6925s	
13202/33150 (epoch 19.913), train_loss = 0.95541097, grad/param norm = 1.6243e-01, time/batch = 0.6982s	
13203/33150 (epoch 19.914), train_loss = 1.09846027, grad/param norm = 1.6133e-01, time/batch = 0.6978s	
13204/33150 (epoch 19.916), train_loss = 0.92480864, grad/param norm = 1.4836e-01, time/batch = 0.6976s	
13205/33150 (epoch 19.917), train_loss = 1.08275695, grad/param norm = 1.7000e-01, time/batch = 0.7060s	
13206/33150 (epoch 19.919), train_loss = 1.15898016, grad/param norm = 1.8388e-01, time/batch = 0.7044s	
13207/33150 (epoch 19.920), train_loss = 1.13730348, grad/param norm = 1.5989e-01, time/batch = 0.7087s	
13208/33150 (epoch 19.922), train_loss = 1.15790537, grad/param norm = 1.7895e-01, time/batch = 0.7050s	
13209/33150 (epoch 19.923), train_loss = 1.02861969, grad/param norm = 1.6724e-01, time/batch = 0.7120s	
13210/33150 (epoch 19.925), train_loss = 1.12903040, grad/param norm = 1.5754e-01, time/batch = 0.7022s	
13211/33150 (epoch 19.926), train_loss = 0.98961333, grad/param norm = 1.4905e-01, time/batch = 0.6763s	
13212/33150 (epoch 19.928), train_loss = 0.97993834, grad/param norm = 1.5510e-01, time/batch = 0.6837s	
13213/33150 (epoch 19.929), train_loss = 1.06259335, grad/param norm = 1.4784e-01, time/batch = 0.6761s	
13214/33150 (epoch 19.931), train_loss = 1.16564865, grad/param norm = 1.6591e-01, time/batch = 0.6765s	
13215/33150 (epoch 19.932), train_loss = 1.03815973, grad/param norm = 1.5438e-01, time/batch = 0.6741s	
13216/33150 (epoch 19.934), train_loss = 1.04406436, grad/param norm = 1.4980e-01, time/batch = 0.6759s	
13217/33150 (epoch 19.935), train_loss = 1.11961069, grad/param norm = 1.5302e-01, time/batch = 0.6756s	
13218/33150 (epoch 19.937), train_loss = 1.13629060, grad/param norm = 1.4539e-01, time/batch = 0.6756s	
13219/33150 (epoch 19.938), train_loss = 1.07289471, grad/param norm = 1.5611e-01, time/batch = 0.6789s	
13220/33150 (epoch 19.940), train_loss = 1.28854106, grad/param norm = 1.8435e-01, time/batch = 0.6792s	
13221/33150 (epoch 19.941), train_loss = 1.02101072, grad/param norm = 1.3790e-01, time/batch = 0.6728s	
13222/33150 (epoch 19.943), train_loss = 0.90961575, grad/param norm = 1.5763e-01, time/batch = 0.6796s	
13223/33150 (epoch 19.944), train_loss = 1.13036718, grad/param norm = 1.6756e-01, time/batch = 0.6807s	
13224/33150 (epoch 19.946), train_loss = 0.85515302, grad/param norm = 1.3456e-01, time/batch = 0.6789s	
13225/33150 (epoch 19.947), train_loss = 1.04022440, grad/param norm = 1.4427e-01, time/batch = 0.6829s	
13226/33150 (epoch 19.949), train_loss = 1.15253788, grad/param norm = 1.6308e-01, time/batch = 0.6870s	
13227/33150 (epoch 19.950), train_loss = 1.06085689, grad/param norm = 1.6255e-01, time/batch = 0.6655s	
13228/33150 (epoch 19.952), train_loss = 0.94757919, grad/param norm = 1.5106e-01, time/batch = 0.6643s	
13229/33150 (epoch 19.953), train_loss = 0.98100071, grad/param norm = 1.4303e-01, time/batch = 0.6645s	
13230/33150 (epoch 19.955), train_loss = 0.88356942, grad/param norm = 1.4301e-01, time/batch = 0.6675s	
13231/33150 (epoch 19.956), train_loss = 1.08711600, grad/param norm = 1.5801e-01, time/batch = 0.6754s	
13232/33150 (epoch 19.958), train_loss = 0.92152636, grad/param norm = 1.3826e-01, time/batch = 0.6917s	
13233/33150 (epoch 19.959), train_loss = 0.95687231, grad/param norm = 1.5504e-01, time/batch = 0.6918s	
13234/33150 (epoch 19.961), train_loss = 0.91896961, grad/param norm = 1.4080e-01, time/batch = 0.6861s	
13235/33150 (epoch 19.962), train_loss = 0.89174254, grad/param norm = 1.4226e-01, time/batch = 0.7042s	
13236/33150 (epoch 19.964), train_loss = 1.03683752, grad/param norm = 1.4746e-01, time/batch = 0.6872s	
13237/33150 (epoch 19.965), train_loss = 1.04109872, grad/param norm = 1.5703e-01, time/batch = 0.6679s	
13238/33150 (epoch 19.967), train_loss = 1.00868916, grad/param norm = 1.6116e-01, time/batch = 0.6713s	
13239/33150 (epoch 19.968), train_loss = 0.86324345, grad/param norm = 1.2687e-01, time/batch = 0.6708s	
13240/33150 (epoch 19.970), train_loss = 0.95901496, grad/param norm = 1.4745e-01, time/batch = 0.6655s	
13241/33150 (epoch 19.971), train_loss = 0.99859559, grad/param norm = 1.5039e-01, time/batch = 0.6690s	
13242/33150 (epoch 19.973), train_loss = 1.13585072, grad/param norm = 1.6710e-01, time/batch = 0.6688s	
13243/33150 (epoch 19.974), train_loss = 1.17646065, grad/param norm = 1.6186e-01, time/batch = 0.6706s	
13244/33150 (epoch 19.976), train_loss = 1.09587016, grad/param norm = 1.4195e-01, time/batch = 0.6821s	
13245/33150 (epoch 19.977), train_loss = 1.17874403, grad/param norm = 1.6395e-01, time/batch = 0.6849s	
13246/33150 (epoch 19.979), train_loss = 1.11645435, grad/param norm = 1.7175e-01, time/batch = 0.6740s	
13247/33150 (epoch 19.980), train_loss = 1.17517941, grad/param norm = 1.5897e-01, time/batch = 0.6754s	
13248/33150 (epoch 19.982), train_loss = 1.01751218, grad/param norm = 1.6861e-01, time/batch = 0.6778s	
13249/33150 (epoch 19.983), train_loss = 0.90757938, grad/param norm = 1.4667e-01, time/batch = 0.6764s	
13250/33150 (epoch 19.985), train_loss = 1.10408631, grad/param norm = 1.4440e-01, time/batch = 0.6752s	
13251/33150 (epoch 19.986), train_loss = 0.87909718, grad/param norm = 1.4788e-01, time/batch = 0.6781s	
13252/33150 (epoch 19.988), train_loss = 0.98053128, grad/param norm = 1.7493e-01, time/batch = 0.6842s	
13253/33150 (epoch 19.989), train_loss = 0.96418825, grad/param norm = 1.4094e-01, time/batch = 0.6891s	
13254/33150 (epoch 19.991), train_loss = 1.11097356, grad/param norm = 1.9747e-01, time/batch = 0.6791s	
13255/33150 (epoch 19.992), train_loss = 0.94006640, grad/param norm = 1.4827e-01, time/batch = 0.6764s	
13256/33150 (epoch 19.994), train_loss = 1.01975566, grad/param norm = 1.5969e-01, time/batch = 0.6808s	
13257/33150 (epoch 19.995), train_loss = 0.97584284, grad/param norm = 1.6489e-01, time/batch = 0.6715s	
13258/33150 (epoch 19.997), train_loss = 1.03472818, grad/param norm = 1.8124e-01, time/batch = 0.6692s	
13259/33150 (epoch 19.998), train_loss = 0.84284164, grad/param norm = 1.6140e-01, time/batch = 0.6822s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
13260/33150 (epoch 20.000), train_loss = 0.86587111, grad/param norm = 1.4194e-01, time/batch = 0.6806s	
13261/33150 (epoch 20.002), train_loss = 1.31071744, grad/param norm = 1.8015e-01, time/batch = 0.6699s	
13262/33150 (epoch 20.003), train_loss = 0.95028520, grad/param norm = 1.7492e-01, time/batch = 0.6720s	
13263/33150 (epoch 20.005), train_loss = 0.90177141, grad/param norm = 1.4010e-01, time/batch = 0.6700s	
13264/33150 (epoch 20.006), train_loss = 0.87619285, grad/param norm = 1.4913e-01, time/batch = 0.6760s	
13265/33150 (epoch 20.008), train_loss = 1.13253945, grad/param norm = 1.7225e-01, time/batch = 0.6729s	
13266/33150 (epoch 20.009), train_loss = 1.00164726, grad/param norm = 1.3535e-01, time/batch = 0.6715s	
13267/33150 (epoch 20.011), train_loss = 1.12689263, grad/param norm = 1.6245e-01, time/batch = 0.6909s	
13268/33150 (epoch 20.012), train_loss = 1.01351349, grad/param norm = 1.9630e-01, time/batch = 0.6760s	
13269/33150 (epoch 20.014), train_loss = 0.98351205, grad/param norm = 1.7260e-01, time/batch = 0.6733s	
13270/33150 (epoch 20.015), train_loss = 0.95547197, grad/param norm = 1.5439e-01, time/batch = 0.6738s	
13271/33150 (epoch 20.017), train_loss = 0.93574938, grad/param norm = 1.4281e-01, time/batch = 0.6751s	
13272/33150 (epoch 20.018), train_loss = 1.06064807, grad/param norm = 1.7199e-01, time/batch = 0.6739s	
13273/33150 (epoch 20.020), train_loss = 1.10667356, grad/param norm = 1.6962e-01, time/batch = 0.6763s	
13274/33150 (epoch 20.021), train_loss = 0.90854957, grad/param norm = 1.5192e-01, time/batch = 0.6734s	
13275/33150 (epoch 20.023), train_loss = 1.18900771, grad/param norm = 1.5135e-01, time/batch = 0.6736s	
13276/33150 (epoch 20.024), train_loss = 1.09757036, grad/param norm = 1.7327e-01, time/batch = 0.6751s	
13277/33150 (epoch 20.026), train_loss = 0.80866025, grad/param norm = 1.1930e-01, time/batch = 0.6778s	
13278/33150 (epoch 20.027), train_loss = 0.82182894, grad/param norm = 1.2557e-01, time/batch = 0.6740s	
13279/33150 (epoch 20.029), train_loss = 0.93242671, grad/param norm = 1.5684e-01, time/batch = 0.6712s	
13280/33150 (epoch 20.030), train_loss = 1.00022952, grad/param norm = 1.4157e-01, time/batch = 0.6743s	
13281/33150 (epoch 20.032), train_loss = 0.91278392, grad/param norm = 1.4437e-01, time/batch = 0.6745s	
13282/33150 (epoch 20.033), train_loss = 0.96145847, grad/param norm = 1.4984e-01, time/batch = 0.6753s	
13283/33150 (epoch 20.035), train_loss = 1.17584655, grad/param norm = 1.8790e-01, time/batch = 0.6712s	
13284/33150 (epoch 20.036), train_loss = 1.05974424, grad/param norm = 1.6200e-01, time/batch = 0.6739s	
13285/33150 (epoch 20.038), train_loss = 1.29893357, grad/param norm = 1.8187e-01, time/batch = 0.6723s	
13286/33150 (epoch 20.039), train_loss = 1.06752128, grad/param norm = 1.4010e-01, time/batch = 0.6729s	
13287/33150 (epoch 20.041), train_loss = 1.03963515, grad/param norm = 1.4502e-01, time/batch = 0.6781s	
13288/33150 (epoch 20.042), train_loss = 0.99356816, grad/param norm = 1.4357e-01, time/batch = 0.6746s	
13289/33150 (epoch 20.044), train_loss = 0.99259179, grad/param norm = 1.4187e-01, time/batch = 0.6724s	
13290/33150 (epoch 20.045), train_loss = 1.04344209, grad/param norm = 1.4797e-01, time/batch = 0.6716s	
13291/33150 (epoch 20.047), train_loss = 0.90013443, grad/param norm = 1.4639e-01, time/batch = 0.6722s	
13292/33150 (epoch 20.048), train_loss = 1.08459614, grad/param norm = 1.8396e-01, time/batch = 0.6707s	
13293/33150 (epoch 20.050), train_loss = 1.01246238, grad/param norm = 1.4546e-01, time/batch = 0.6837s	
13294/33150 (epoch 20.051), train_loss = 1.01818493, grad/param norm = 1.4607e-01, time/batch = 0.6798s	
13295/33150 (epoch 20.053), train_loss = 0.98965738, grad/param norm = 1.4951e-01, time/batch = 0.6687s	
13296/33150 (epoch 20.054), train_loss = 1.13894483, grad/param norm = 1.4393e-01, time/batch = 0.6718s	
13297/33150 (epoch 20.056), train_loss = 1.00457107, grad/param norm = 1.5537e-01, time/batch = 0.6730s	
13298/33150 (epoch 20.057), train_loss = 1.01051665, grad/param norm = 1.6217e-01, time/batch = 0.6684s	
13299/33150 (epoch 20.059), train_loss = 0.94226154, grad/param norm = 1.5207e-01, time/batch = 0.6687s	
13300/33150 (epoch 20.060), train_loss = 0.95055331, grad/param norm = 1.3566e-01, time/batch = 0.6699s	
13301/33150 (epoch 20.062), train_loss = 0.98028375, grad/param norm = 1.5243e-01, time/batch = 0.6700s	
13302/33150 (epoch 20.063), train_loss = 0.94676982, grad/param norm = 1.4699e-01, time/batch = 0.6702s	
13303/33150 (epoch 20.065), train_loss = 0.97986076, grad/param norm = 1.3832e-01, time/batch = 0.6737s	
13304/33150 (epoch 20.066), train_loss = 0.92559032, grad/param norm = 1.4394e-01, time/batch = 0.6685s	
13305/33150 (epoch 20.068), train_loss = 1.03880380, grad/param norm = 1.4641e-01, time/batch = 0.6707s	
13306/33150 (epoch 20.069), train_loss = 1.07955013, grad/param norm = 1.7542e-01, time/batch = 0.6706s	
13307/33150 (epoch 20.071), train_loss = 1.05638335, grad/param norm = 1.5900e-01, time/batch = 0.6728s	
13308/33150 (epoch 20.072), train_loss = 0.98672685, grad/param norm = 1.3985e-01, time/batch = 0.6850s	
13309/33150 (epoch 20.074), train_loss = 0.87821161, grad/param norm = 1.5511e-01, time/batch = 0.6792s	
13310/33150 (epoch 20.075), train_loss = 0.95410039, grad/param norm = 1.4648e-01, time/batch = 0.6709s	
13311/33150 (epoch 20.077), train_loss = 1.02041210, grad/param norm = 2.0132e-01, time/batch = 0.6740s	
13312/33150 (epoch 20.078), train_loss = 1.13074624, grad/param norm = 1.7724e-01, time/batch = 0.6747s	
13313/33150 (epoch 20.080), train_loss = 1.13662705, grad/param norm = 1.4922e-01, time/batch = 0.6746s	
13314/33150 (epoch 20.081), train_loss = 0.92706963, grad/param norm = 1.9921e-01, time/batch = 0.6789s	
13315/33150 (epoch 20.083), train_loss = 0.76449665, grad/param norm = 1.4915e-01, time/batch = 0.6826s	
13316/33150 (epoch 20.084), train_loss = 0.89014365, grad/param norm = 1.6821e-01, time/batch = 0.6738s	
13317/33150 (epoch 20.086), train_loss = 0.95320735, grad/param norm = 1.6761e-01, time/batch = 0.6739s	
13318/33150 (epoch 20.087), train_loss = 0.88660202, grad/param norm = 1.5956e-01, time/batch = 0.6815s	
13319/33150 (epoch 20.089), train_loss = 0.90410249, grad/param norm = 1.4322e-01, time/batch = 0.6877s	
13320/33150 (epoch 20.090), train_loss = 0.96633202, grad/param norm = 1.5960e-01, time/batch = 0.6900s	
13321/33150 (epoch 20.092), train_loss = 0.96193775, grad/param norm = 1.8021e-01, time/batch = 0.6958s	
13322/33150 (epoch 20.094), train_loss = 1.06380181, grad/param norm = 1.6201e-01, time/batch = 0.6855s	
13323/33150 (epoch 20.095), train_loss = 0.89408240, grad/param norm = 1.3214e-01, time/batch = 0.6688s	
13324/33150 (epoch 20.097), train_loss = 0.92934883, grad/param norm = 1.7000e-01, time/batch = 0.6700s	
13325/33150 (epoch 20.098), train_loss = 1.22866699, grad/param norm = 1.5725e-01, time/batch = 0.6710s	
13326/33150 (epoch 20.100), train_loss = 1.18255836, grad/param norm = 1.7244e-01, time/batch = 0.6729s	
13327/33150 (epoch 20.101), train_loss = 0.94314746, grad/param norm = 1.5267e-01, time/batch = 0.6768s	
13328/33150 (epoch 20.103), train_loss = 1.01651849, grad/param norm = 1.4855e-01, time/batch = 0.6904s	
13329/33150 (epoch 20.104), train_loss = 0.90887219, grad/param norm = 1.4468e-01, time/batch = 0.6742s	
13330/33150 (epoch 20.106), train_loss = 1.10879966, grad/param norm = 1.6604e-01, time/batch = 0.6715s	
13331/33150 (epoch 20.107), train_loss = 1.22988351, grad/param norm = 1.8696e-01, time/batch = 0.6730s	
13332/33150 (epoch 20.109), train_loss = 0.97589846, grad/param norm = 1.3216e-01, time/batch = 0.6807s	
13333/33150 (epoch 20.110), train_loss = 1.12563483, grad/param norm = 1.6762e-01, time/batch = 0.6952s	
13334/33150 (epoch 20.112), train_loss = 0.94089914, grad/param norm = 1.5565e-01, time/batch = 0.6815s	
13335/33150 (epoch 20.113), train_loss = 0.98974591, grad/param norm = 1.6168e-01, time/batch = 0.6832s	
13336/33150 (epoch 20.115), train_loss = 1.18060270, grad/param norm = 1.6114e-01, time/batch = 0.6881s	
13337/33150 (epoch 20.116), train_loss = 0.98667344, grad/param norm = 1.4901e-01, time/batch = 0.6861s	
13338/33150 (epoch 20.118), train_loss = 1.07961548, grad/param norm = 1.7974e-01, time/batch = 0.6813s	
13339/33150 (epoch 20.119), train_loss = 1.10120602, grad/param norm = 1.9569e-01, time/batch = 0.6734s	
13340/33150 (epoch 20.121), train_loss = 0.99303583, grad/param norm = 1.4687e-01, time/batch = 0.6833s	
13341/33150 (epoch 20.122), train_loss = 1.23545912, grad/param norm = 2.1019e-01, time/batch = 0.6802s	
13342/33150 (epoch 20.124), train_loss = 0.84957718, grad/param norm = 1.2703e-01, time/batch = 0.6712s	
13343/33150 (epoch 20.125), train_loss = 1.08553319, grad/param norm = 1.5433e-01, time/batch = 0.6734s	
13344/33150 (epoch 20.127), train_loss = 0.99437812, grad/param norm = 1.4879e-01, time/batch = 0.6728s	
13345/33150 (epoch 20.128), train_loss = 1.03591613, grad/param norm = 1.6619e-01, time/batch = 0.6696s	
13346/33150 (epoch 20.130), train_loss = 1.05522051, grad/param norm = 1.4993e-01, time/batch = 0.6696s	
13347/33150 (epoch 20.131), train_loss = 1.23387723, grad/param norm = 1.6840e-01, time/batch = 0.6745s	
13348/33150 (epoch 20.133), train_loss = 0.94859883, grad/param norm = 1.4221e-01, time/batch = 0.6704s	
13349/33150 (epoch 20.134), train_loss = 1.12687800, grad/param norm = 1.5737e-01, time/batch = 0.6720s	
13350/33150 (epoch 20.136), train_loss = 1.02110972, grad/param norm = 1.7578e-01, time/batch = 0.6748s	
13351/33150 (epoch 20.137), train_loss = 1.12019543, grad/param norm = 1.6342e-01, time/batch = 0.6753s	
13352/33150 (epoch 20.139), train_loss = 1.08664146, grad/param norm = 1.6895e-01, time/batch = 0.6857s	
13353/33150 (epoch 20.140), train_loss = 1.17716224, grad/param norm = 1.6051e-01, time/batch = 0.6795s	
13354/33150 (epoch 20.142), train_loss = 1.10413796, grad/param norm = 1.7963e-01, time/batch = 0.6722s	
13355/33150 (epoch 20.143), train_loss = 1.03888810, grad/param norm = 1.8440e-01, time/batch = 0.6689s	
13356/33150 (epoch 20.145), train_loss = 0.99935226, grad/param norm = 1.7341e-01, time/batch = 0.6742s	
13357/33150 (epoch 20.146), train_loss = 1.14607766, grad/param norm = 1.7895e-01, time/batch = 0.6710s	
13358/33150 (epoch 20.148), train_loss = 1.14001473, grad/param norm = 1.4756e-01, time/batch = 0.6710s	
13359/33150 (epoch 20.149), train_loss = 1.04354915, grad/param norm = 1.4737e-01, time/batch = 0.6737s	
13360/33150 (epoch 20.151), train_loss = 1.17483573, grad/param norm = 1.5570e-01, time/batch = 0.6759s	
13361/33150 (epoch 20.152), train_loss = 0.98411497, grad/param norm = 1.4195e-01, time/batch = 0.6765s	
13362/33150 (epoch 20.154), train_loss = 1.01437880, grad/param norm = 1.6879e-01, time/batch = 0.6823s	
13363/33150 (epoch 20.155), train_loss = 0.86680351, grad/param norm = 1.4151e-01, time/batch = 0.6768s	
13364/33150 (epoch 20.157), train_loss = 0.98455085, grad/param norm = 1.6327e-01, time/batch = 0.6716s	
13365/33150 (epoch 20.158), train_loss = 0.95594071, grad/param norm = 1.4574e-01, time/batch = 0.6772s	
13366/33150 (epoch 20.160), train_loss = 1.07139398, grad/param norm = 1.5923e-01, time/batch = 0.6755s	
13367/33150 (epoch 20.161), train_loss = 0.94303495, grad/param norm = 1.6375e-01, time/batch = 0.6735s	
13368/33150 (epoch 20.163), train_loss = 0.93877276, grad/param norm = 1.4912e-01, time/batch = 0.6812s	
13369/33150 (epoch 20.164), train_loss = 1.06616750, grad/param norm = 1.6792e-01, time/batch = 0.6718s	
13370/33150 (epoch 20.166), train_loss = 1.00099835, grad/param norm = 1.6035e-01, time/batch = 0.6710s	
13371/33150 (epoch 20.167), train_loss = 1.04116769, grad/param norm = 1.5390e-01, time/batch = 0.6948s	
13372/33150 (epoch 20.169), train_loss = 1.05477271, grad/param norm = 1.8984e-01, time/batch = 0.6824s	
13373/33150 (epoch 20.170), train_loss = 0.91967135, grad/param norm = 1.6323e-01, time/batch = 0.6895s	
13374/33150 (epoch 20.172), train_loss = 1.12917089, grad/param norm = 1.8685e-01, time/batch = 0.6919s	
13375/33150 (epoch 20.173), train_loss = 1.08453098, grad/param norm = 1.7759e-01, time/batch = 0.6871s	
13376/33150 (epoch 20.175), train_loss = 0.95464272, grad/param norm = 1.5361e-01, time/batch = 0.6814s	
13377/33150 (epoch 20.176), train_loss = 1.07814977, grad/param norm = 1.6616e-01, time/batch = 0.6814s	
13378/33150 (epoch 20.178), train_loss = 1.21077063, grad/param norm = 1.7809e-01, time/batch = 0.6832s	
13379/33150 (epoch 20.179), train_loss = 1.07908238, grad/param norm = 1.4741e-01, time/batch = 0.6852s	
13380/33150 (epoch 20.181), train_loss = 1.03405759, grad/param norm = 1.7469e-01, time/batch = 0.6811s	
13381/33150 (epoch 20.183), train_loss = 1.01376948, grad/param norm = 1.7907e-01, time/batch = 0.6809s	
13382/33150 (epoch 20.184), train_loss = 1.22687630, grad/param norm = 1.7975e-01, time/batch = 0.6724s	
13383/33150 (epoch 20.186), train_loss = 1.14620683, grad/param norm = 1.5762e-01, time/batch = 0.6725s	
13384/33150 (epoch 20.187), train_loss = 1.06150801, grad/param norm = 1.6440e-01, time/batch = 0.6715s	
13385/33150 (epoch 20.189), train_loss = 0.82146689, grad/param norm = 1.4398e-01, time/batch = 0.6736s	
13386/33150 (epoch 20.190), train_loss = 0.92206428, grad/param norm = 1.9129e-01, time/batch = 0.6852s	
13387/33150 (epoch 20.192), train_loss = 1.02983700, grad/param norm = 1.8065e-01, time/batch = 0.6926s	
13388/33150 (epoch 20.193), train_loss = 1.11154352, grad/param norm = 1.7846e-01, time/batch = 0.6883s	
13389/33150 (epoch 20.195), train_loss = 1.27234834, grad/param norm = 1.9811e-01, time/batch = 0.6753s	
13390/33150 (epoch 20.196), train_loss = 1.14238894, grad/param norm = 1.6748e-01, time/batch = 0.6737s	
13391/33150 (epoch 20.198), train_loss = 0.89872453, grad/param norm = 1.5046e-01, time/batch = 0.6750s	
13392/33150 (epoch 20.199), train_loss = 1.12651454, grad/param norm = 2.0840e-01, time/batch = 0.6708s	
13393/33150 (epoch 20.201), train_loss = 0.93961216, grad/param norm = 1.3328e-01, time/batch = 0.6745s	
13394/33150 (epoch 20.202), train_loss = 0.82092152, grad/param norm = 1.4918e-01, time/batch = 0.6739s	
13395/33150 (epoch 20.204), train_loss = 1.04706778, grad/param norm = 1.6919e-01, time/batch = 0.6701s	
13396/33150 (epoch 20.205), train_loss = 1.10396005, grad/param norm = 1.7541e-01, time/batch = 0.6706s	
13397/33150 (epoch 20.207), train_loss = 1.05676687, grad/param norm = 1.4895e-01, time/batch = 0.6710s	
13398/33150 (epoch 20.208), train_loss = 1.09214077, grad/param norm = 1.6148e-01, time/batch = 0.6705s	
13399/33150 (epoch 20.210), train_loss = 0.95625664, grad/param norm = 1.3661e-01, time/batch = 0.6783s	
13400/33150 (epoch 20.211), train_loss = 1.07082144, grad/param norm = 1.7086e-01, time/batch = 0.6876s	
13401/33150 (epoch 20.213), train_loss = 1.07932309, grad/param norm = 1.6069e-01, time/batch = 0.6923s	
13402/33150 (epoch 20.214), train_loss = 1.01792898, grad/param norm = 1.5339e-01, time/batch = 0.6905s	
13403/33150 (epoch 20.216), train_loss = 0.95429034, grad/param norm = 1.5356e-01, time/batch = 0.6890s	
13404/33150 (epoch 20.217), train_loss = 0.98625967, grad/param norm = 1.4384e-01, time/batch = 0.6765s	
13405/33150 (epoch 20.219), train_loss = 0.90645511, grad/param norm = 1.3857e-01, time/batch = 0.6710s	
13406/33150 (epoch 20.220), train_loss = 0.94825685, grad/param norm = 1.3389e-01, time/batch = 0.6686s	
13407/33150 (epoch 20.222), train_loss = 1.12599782, grad/param norm = 1.4652e-01, time/batch = 0.6697s	
13408/33150 (epoch 20.223), train_loss = 1.04100572, grad/param norm = 1.7257e-01, time/batch = 0.6882s	
13409/33150 (epoch 20.225), train_loss = 1.15406355, grad/param norm = 1.6532e-01, time/batch = 0.6918s	
13410/33150 (epoch 20.226), train_loss = 1.00773923, grad/param norm = 1.4109e-01, time/batch = 0.6930s	
13411/33150 (epoch 20.228), train_loss = 1.00662007, grad/param norm = 1.5187e-01, time/batch = 0.6748s	
13412/33150 (epoch 20.229), train_loss = 1.01151069, grad/param norm = 1.4641e-01, time/batch = 0.6760s	
13413/33150 (epoch 20.231), train_loss = 1.16529681, grad/param norm = 1.7864e-01, time/batch = 0.6771s	
13414/33150 (epoch 20.232), train_loss = 1.05810139, grad/param norm = 1.7158e-01, time/batch = 0.6740s	
13415/33150 (epoch 20.234), train_loss = 1.02443191, grad/param norm = 1.6579e-01, time/batch = 0.6841s	
13416/33150 (epoch 20.235), train_loss = 1.06458600, grad/param norm = 1.7753e-01, time/batch = 0.6824s	
13417/33150 (epoch 20.237), train_loss = 1.05554877, grad/param norm = 2.2241e-01, time/batch = 0.6763s	
13418/33150 (epoch 20.238), train_loss = 1.08379800, grad/param norm = 1.8325e-01, time/batch = 0.6741s	
13419/33150 (epoch 20.240), train_loss = 1.07047854, grad/param norm = 1.6266e-01, time/batch = 0.6749s	
13420/33150 (epoch 20.241), train_loss = 1.15538927, grad/param norm = 1.7287e-01, time/batch = 0.6778s	
13421/33150 (epoch 20.243), train_loss = 1.10682522, grad/param norm = 1.7602e-01, time/batch = 0.6775s	
13422/33150 (epoch 20.244), train_loss = 1.02645421, grad/param norm = 1.4989e-01, time/batch = 0.6764s	
13423/33150 (epoch 20.246), train_loss = 1.09461828, grad/param norm = 1.4315e-01, time/batch = 0.6811s	
13424/33150 (epoch 20.247), train_loss = 0.97091301, grad/param norm = 1.4853e-01, time/batch = 0.6763s	
13425/33150 (epoch 20.249), train_loss = 1.12044729, grad/param norm = 1.5405e-01, time/batch = 0.6785s	
13426/33150 (epoch 20.250), train_loss = 1.07993218, grad/param norm = 1.4094e-01, time/batch = 0.6741s	
13427/33150 (epoch 20.252), train_loss = 1.07797180, grad/param norm = 1.3337e-01, time/batch = 0.6771s	
13428/33150 (epoch 20.253), train_loss = 1.02134132, grad/param norm = 1.4867e-01, time/batch = 0.6747s	
13429/33150 (epoch 20.255), train_loss = 1.00718447, grad/param norm = 1.4376e-01, time/batch = 0.6806s	
13430/33150 (epoch 20.256), train_loss = 1.10067470, grad/param norm = 1.4364e-01, time/batch = 0.6859s	
13431/33150 (epoch 20.258), train_loss = 0.98941780, grad/param norm = 1.6379e-01, time/batch = 0.6753s	
13432/33150 (epoch 20.259), train_loss = 0.85817402, grad/param norm = 1.6128e-01, time/batch = 0.6756s	
13433/33150 (epoch 20.261), train_loss = 0.90822030, grad/param norm = 1.3350e-01, time/batch = 0.6723s	
13434/33150 (epoch 20.262), train_loss = 1.10222812, grad/param norm = 1.8986e-01, time/batch = 0.6952s	
13435/33150 (epoch 20.264), train_loss = 0.80779703, grad/param norm = 1.3648e-01, time/batch = 0.6844s	
13436/33150 (epoch 20.265), train_loss = 1.07018151, grad/param norm = 1.5013e-01, time/batch = 0.6908s	
13437/33150 (epoch 20.267), train_loss = 1.08343924, grad/param norm = 1.5786e-01, time/batch = 0.6767s	
13438/33150 (epoch 20.268), train_loss = 1.11934775, grad/param norm = 1.4849e-01, time/batch = 0.6743s	
13439/33150 (epoch 20.270), train_loss = 1.20849316, grad/param norm = 1.6202e-01, time/batch = 0.6768s	
13440/33150 (epoch 20.271), train_loss = 1.16451350, grad/param norm = 1.6935e-01, time/batch = 0.6776s	
13441/33150 (epoch 20.273), train_loss = 1.15002214, grad/param norm = 1.5153e-01, time/batch = 0.6927s	
13442/33150 (epoch 20.275), train_loss = 1.17763481, grad/param norm = 1.6713e-01, time/batch = 0.6906s	
13443/33150 (epoch 20.276), train_loss = 1.03000969, grad/param norm = 1.5892e-01, time/batch = 0.6896s	
13444/33150 (epoch 20.278), train_loss = 1.10082913, grad/param norm = 1.5107e-01, time/batch = 0.6920s	
13445/33150 (epoch 20.279), train_loss = 1.07383207, grad/param norm = 1.5035e-01, time/batch = 0.6910s	
13446/33150 (epoch 20.281), train_loss = 1.06042133, grad/param norm = 1.5149e-01, time/batch = 0.6759s	
13447/33150 (epoch 20.282), train_loss = 1.04310069, grad/param norm = 1.3510e-01, time/batch = 0.6887s	
13448/33150 (epoch 20.284), train_loss = 0.97337180, grad/param norm = 1.4130e-01, time/batch = 0.6895s	
13449/33150 (epoch 20.285), train_loss = 1.06400121, grad/param norm = 1.4287e-01, time/batch = 0.6682s	
13450/33150 (epoch 20.287), train_loss = 0.92755073, grad/param norm = 1.3486e-01, time/batch = 0.6773s	
13451/33150 (epoch 20.288), train_loss = 1.14580004, grad/param norm = 1.6064e-01, time/batch = 0.6753s	
13452/33150 (epoch 20.290), train_loss = 0.88454989, grad/param norm = 1.5372e-01, time/batch = 0.6666s	
13453/33150 (epoch 20.291), train_loss = 0.86940759, grad/param norm = 1.4645e-01, time/batch = 0.6729s	
13454/33150 (epoch 20.293), train_loss = 1.07841066, grad/param norm = 1.4951e-01, time/batch = 0.6673s	
13455/33150 (epoch 20.294), train_loss = 0.78280688, grad/param norm = 1.3160e-01, time/batch = 0.6682s	
13456/33150 (epoch 20.296), train_loss = 1.00783025, grad/param norm = 1.5554e-01, time/batch = 0.6719s	
13457/33150 (epoch 20.297), train_loss = 0.97106786, grad/param norm = 1.5355e-01, time/batch = 0.6744s	
13458/33150 (epoch 20.299), train_loss = 0.95538663, grad/param norm = 1.6454e-01, time/batch = 0.6728s	
13459/33150 (epoch 20.300), train_loss = 0.96553120, grad/param norm = 1.3255e-01, time/batch = 0.6837s	
13460/33150 (epoch 20.302), train_loss = 0.98125927, grad/param norm = 1.4329e-01, time/batch = 0.6779s	
13461/33150 (epoch 20.303), train_loss = 0.99988143, grad/param norm = 1.6855e-01, time/batch = 0.6772s	
13462/33150 (epoch 20.305), train_loss = 1.09576475, grad/param norm = 1.3926e-01, time/batch = 0.6727s	
13463/33150 (epoch 20.306), train_loss = 1.07665292, grad/param norm = 1.7842e-01, time/batch = 0.6740s	
13464/33150 (epoch 20.308), train_loss = 1.25019364, grad/param norm = 1.6369e-01, time/batch = 0.6714s	
13465/33150 (epoch 20.309), train_loss = 0.85417466, grad/param norm = 1.3206e-01, time/batch = 0.6706s	
13466/33150 (epoch 20.311), train_loss = 0.98689173, grad/param norm = 1.6028e-01, time/batch = 0.6716s	
13467/33150 (epoch 20.312), train_loss = 0.81594116, grad/param norm = 1.4494e-01, time/batch = 0.6722s	
13468/33150 (epoch 20.314), train_loss = 0.98492275, grad/param norm = 1.6139e-01, time/batch = 0.6773s	
13469/33150 (epoch 20.315), train_loss = 1.04924707, grad/param norm = 1.5636e-01, time/batch = 0.6737s	
13470/33150 (epoch 20.317), train_loss = 0.79987743, grad/param norm = 1.1702e-01, time/batch = 0.6704s	
13471/33150 (epoch 20.318), train_loss = 0.92372498, grad/param norm = 1.4170e-01, time/batch = 0.6766s	
13472/33150 (epoch 20.320), train_loss = 0.88815284, grad/param norm = 1.5075e-01, time/batch = 0.6742s	
13473/33150 (epoch 20.321), train_loss = 0.96645739, grad/param norm = 1.3420e-01, time/batch = 0.6749s	
13474/33150 (epoch 20.323), train_loss = 1.01198560, grad/param norm = 1.5204e-01, time/batch = 0.6853s	
13475/33150 (epoch 20.324), train_loss = 1.09115627, grad/param norm = 1.8507e-01, time/batch = 0.6817s	
13476/33150 (epoch 20.326), train_loss = 1.05617064, grad/param norm = 1.4766e-01, time/batch = 0.6729s	
13477/33150 (epoch 20.327), train_loss = 1.15161412, grad/param norm = 1.5135e-01, time/batch = 0.6729s	
13478/33150 (epoch 20.329), train_loss = 1.07521392, grad/param norm = 1.5379e-01, time/batch = 0.6722s	
13479/33150 (epoch 20.330), train_loss = 1.01700812, grad/param norm = 1.5977e-01, time/batch = 0.6744s	
13480/33150 (epoch 20.332), train_loss = 1.00841184, grad/param norm = 1.3734e-01, time/batch = 0.6714s	
13481/33150 (epoch 20.333), train_loss = 1.05909790, grad/param norm = 1.4365e-01, time/batch = 0.6768s	
13482/33150 (epoch 20.335), train_loss = 0.96379869, grad/param norm = 1.5240e-01, time/batch = 0.6769s	
13483/33150 (epoch 20.336), train_loss = 0.94825218, grad/param norm = 1.4605e-01, time/batch = 0.6753s	
13484/33150 (epoch 20.338), train_loss = 0.83231710, grad/param norm = 1.3589e-01, time/batch = 0.6744s	
13485/33150 (epoch 20.339), train_loss = 1.09935422, grad/param norm = 1.5349e-01, time/batch = 0.6723s	
13486/33150 (epoch 20.341), train_loss = 1.10003710, grad/param norm = 2.0259e-01, time/batch = 0.6708s	
13487/33150 (epoch 20.342), train_loss = 0.92389251, grad/param norm = 1.5750e-01, time/batch = 0.6729s	
13488/33150 (epoch 20.344), train_loss = 1.04385254, grad/param norm = 1.7008e-01, time/batch = 0.6766s	
13489/33150 (epoch 20.345), train_loss = 0.98370522, grad/param norm = 1.4509e-01, time/batch = 0.6850s	
13490/33150 (epoch 20.347), train_loss = 0.83463707, grad/param norm = 1.4134e-01, time/batch = 0.6717s	
13491/33150 (epoch 20.348), train_loss = 1.02731863, grad/param norm = 1.3952e-01, time/batch = 0.6734s	
13492/33150 (epoch 20.350), train_loss = 0.93083308, grad/param norm = 1.5219e-01, time/batch = 0.6703s	
13493/33150 (epoch 20.351), train_loss = 1.08769692, grad/param norm = 1.9203e-01, time/batch = 0.6749s	
13494/33150 (epoch 20.353), train_loss = 1.06710247, grad/param norm = 1.6369e-01, time/batch = 0.6706s	
13495/33150 (epoch 20.354), train_loss = 1.28715475, grad/param norm = 1.7349e-01, time/batch = 0.6711s	
13496/33150 (epoch 20.356), train_loss = 1.14191102, grad/param norm = 1.7705e-01, time/batch = 0.6873s	
13497/33150 (epoch 20.357), train_loss = 1.08227248, grad/param norm = 1.8156e-01, time/batch = 0.6912s	
13498/33150 (epoch 20.359), train_loss = 1.08762892, grad/param norm = 1.6441e-01, time/batch = 0.6929s	
13499/33150 (epoch 20.360), train_loss = 1.09684360, grad/param norm = 1.8530e-01, time/batch = 0.6907s	
13500/33150 (epoch 20.362), train_loss = 1.10901392, grad/param norm = 1.5135e-01, time/batch = 0.6714s	
13501/33150 (epoch 20.363), train_loss = 1.03204520, grad/param norm = 1.4704e-01, time/batch = 0.6760s	
13502/33150 (epoch 20.365), train_loss = 1.01394151, grad/param norm = 1.4344e-01, time/batch = 0.6780s	
13503/33150 (epoch 20.367), train_loss = 0.96775281, grad/param norm = 1.5141e-01, time/batch = 0.6822s	
13504/33150 (epoch 20.368), train_loss = 1.01700918, grad/param norm = 1.6609e-01, time/batch = 0.6841s	
13505/33150 (epoch 20.370), train_loss = 1.02899882, grad/param norm = 1.6369e-01, time/batch = 0.6788s	
13506/33150 (epoch 20.371), train_loss = 0.92340838, grad/param norm = 1.4489e-01, time/batch = 0.6721s	
13507/33150 (epoch 20.373), train_loss = 1.08478598, grad/param norm = 1.6791e-01, time/batch = 0.6746s	
13508/33150 (epoch 20.374), train_loss = 0.99441509, grad/param norm = 1.5632e-01, time/batch = 0.6811s	
13509/33150 (epoch 20.376), train_loss = 1.15430755, grad/param norm = 1.6214e-01, time/batch = 0.6842s	
13510/33150 (epoch 20.377), train_loss = 0.98236682, grad/param norm = 1.6267e-01, time/batch = 0.6743s	
13511/33150 (epoch 20.379), train_loss = 1.09642979, grad/param norm = 1.6476e-01, time/batch = 0.6798s	
13512/33150 (epoch 20.380), train_loss = 1.10516252, grad/param norm = 1.5124e-01, time/batch = 0.6802s	
13513/33150 (epoch 20.382), train_loss = 0.96104047, grad/param norm = 1.5889e-01, time/batch = 0.6818s	
13514/33150 (epoch 20.383), train_loss = 0.94951077, grad/param norm = 1.4569e-01, time/batch = 0.6785s	
13515/33150 (epoch 20.385), train_loss = 1.00278554, grad/param norm = 1.5636e-01, time/batch = 0.6765s	
13516/33150 (epoch 20.386), train_loss = 0.87032640, grad/param norm = 1.2263e-01, time/batch = 0.6798s	
13517/33150 (epoch 20.388), train_loss = 0.95699357, grad/param norm = 1.3150e-01, time/batch = 0.6803s	
13518/33150 (epoch 20.389), train_loss = 0.95996528, grad/param norm = 1.4325e-01, time/batch = 0.6848s	
13519/33150 (epoch 20.391), train_loss = 1.18805048, grad/param norm = 1.5809e-01, time/batch = 0.6793s	
13520/33150 (epoch 20.392), train_loss = 0.97963200, grad/param norm = 1.4612e-01, time/batch = 0.6832s	
13521/33150 (epoch 20.394), train_loss = 0.87117915, grad/param norm = 1.2619e-01, time/batch = 0.6719s	
13522/33150 (epoch 20.395), train_loss = 0.88139056, grad/param norm = 1.5859e-01, time/batch = 0.6672s	
13523/33150 (epoch 20.397), train_loss = 0.71060329, grad/param norm = 1.2942e-01, time/batch = 0.6689s	
13524/33150 (epoch 20.398), train_loss = 1.04766835, grad/param norm = 1.9410e-01, time/batch = 0.6670s	
13525/33150 (epoch 20.400), train_loss = 0.96911709, grad/param norm = 1.3627e-01, time/batch = 0.6699s	
13526/33150 (epoch 20.401), train_loss = 0.84104121, grad/param norm = 1.3058e-01, time/batch = 0.6703s	
13527/33150 (epoch 20.403), train_loss = 0.88851107, grad/param norm = 1.3149e-01, time/batch = 0.6679s	
13528/33150 (epoch 20.404), train_loss = 1.00267368, grad/param norm = 1.5348e-01, time/batch = 0.6969s	
13529/33150 (epoch 20.406), train_loss = 0.93462511, grad/param norm = 1.2266e-01, time/batch = 0.6895s	
13530/33150 (epoch 20.407), train_loss = 0.87698650, grad/param norm = 1.3804e-01, time/batch = 0.6828s	
13531/33150 (epoch 20.409), train_loss = 0.81624620, grad/param norm = 1.3756e-01, time/batch = 0.6735s	
13532/33150 (epoch 20.410), train_loss = 1.02919026, grad/param norm = 1.5630e-01, time/batch = 0.6753s	
13533/33150 (epoch 20.412), train_loss = 1.06471032, grad/param norm = 1.4838e-01, time/batch = 0.6878s	
13534/33150 (epoch 20.413), train_loss = 0.94446799, grad/param norm = 1.4512e-01, time/batch = 0.6708s	
13535/33150 (epoch 20.415), train_loss = 1.05419252, grad/param norm = 1.4045e-01, time/batch = 0.6703s	
13536/33150 (epoch 20.416), train_loss = 0.92742922, grad/param norm = 1.3961e-01, time/batch = 0.6705s	
13537/33150 (epoch 20.418), train_loss = 1.12802657, grad/param norm = 1.8205e-01, time/batch = 0.6698s	
13538/33150 (epoch 20.419), train_loss = 0.96079086, grad/param norm = 1.5142e-01, time/batch = 0.6715s	
13539/33150 (epoch 20.421), train_loss = 1.02945302, grad/param norm = 1.8183e-01, time/batch = 0.6735s	
13540/33150 (epoch 20.422), train_loss = 0.97240600, grad/param norm = 1.4562e-01, time/batch = 0.6691s	
13541/33150 (epoch 20.424), train_loss = 0.95952338, grad/param norm = 1.4803e-01, time/batch = 0.6715s	
13542/33150 (epoch 20.425), train_loss = 1.04963337, grad/param norm = 1.4836e-01, time/batch = 0.6761s	
13543/33150 (epoch 20.427), train_loss = 1.00163966, grad/param norm = 1.3556e-01, time/batch = 0.6734s	
13544/33150 (epoch 20.428), train_loss = 1.01424437, grad/param norm = 1.7105e-01, time/batch = 0.6747s	
13545/33150 (epoch 20.430), train_loss = 1.01554084, grad/param norm = 1.5890e-01, time/batch = 0.6803s	
13546/33150 (epoch 20.431), train_loss = 1.07109870, grad/param norm = 1.7299e-01, time/batch = 0.6787s	
13547/33150 (epoch 20.433), train_loss = 1.01087263, grad/param norm = 1.4318e-01, time/batch = 0.6786s	
13548/33150 (epoch 20.434), train_loss = 0.88398335, grad/param norm = 1.5019e-01, time/batch = 0.6721s	
13549/33150 (epoch 20.436), train_loss = 0.95903284, grad/param norm = 1.5035e-01, time/batch = 0.6750s	
13550/33150 (epoch 20.437), train_loss = 1.03366937, grad/param norm = 1.9872e-01, time/batch = 0.6744s	
13551/33150 (epoch 20.439), train_loss = 1.14182513, grad/param norm = 1.5660e-01, time/batch = 0.6824s	
13552/33150 (epoch 20.440), train_loss = 1.10385414, grad/param norm = 1.6826e-01, time/batch = 0.6756s	
13553/33150 (epoch 20.442), train_loss = 0.90371392, grad/param norm = 1.5430e-01, time/batch = 0.6757s	
13554/33150 (epoch 20.443), train_loss = 1.08251179, grad/param norm = 1.5774e-01, time/batch = 0.6746s	
13555/33150 (epoch 20.445), train_loss = 1.02695860, grad/param norm = 1.6665e-01, time/batch = 0.6757s	
13556/33150 (epoch 20.446), train_loss = 1.04002578, grad/param norm = 1.8155e-01, time/batch = 0.6756s	
13557/33150 (epoch 20.448), train_loss = 1.12783117, grad/param norm = 1.7025e-01, time/batch = 0.6745s	
13558/33150 (epoch 20.449), train_loss = 1.03577014, grad/param norm = 1.4355e-01, time/batch = 0.6741s	
13559/33150 (epoch 20.451), train_loss = 1.06730203, grad/param norm = 1.8426e-01, time/batch = 0.6787s	
13560/33150 (epoch 20.452), train_loss = 1.25247484, grad/param norm = 1.6381e-01, time/batch = 0.6795s	
13561/33150 (epoch 20.454), train_loss = 1.03403005, grad/param norm = 1.6006e-01, time/batch = 0.6771s	
13562/33150 (epoch 20.456), train_loss = 0.90079682, grad/param norm = 1.3444e-01, time/batch = 0.6844s	
13563/33150 (epoch 20.457), train_loss = 1.02137444, grad/param norm = 1.5162e-01, time/batch = 0.6826s	
13564/33150 (epoch 20.459), train_loss = 1.14904089, grad/param norm = 2.5957e-01, time/batch = 0.6820s	
13565/33150 (epoch 20.460), train_loss = 1.07256816, grad/param norm = 1.4050e-01, time/batch = 0.6863s	
13566/33150 (epoch 20.462), train_loss = 1.11412516, grad/param norm = 1.9477e-01, time/batch = 0.6771s	
13567/33150 (epoch 20.463), train_loss = 1.26953174, grad/param norm = 1.9511e-01, time/batch = 0.6772s	
13568/33150 (epoch 20.465), train_loss = 0.98019406, grad/param norm = 1.4276e-01, time/batch = 0.6745s	
13569/33150 (epoch 20.466), train_loss = 0.94618805, grad/param norm = 1.5233e-01, time/batch = 0.6737s	
13570/33150 (epoch 20.468), train_loss = 1.27393651, grad/param norm = 1.6375e-01, time/batch = 0.6730s	
13571/33150 (epoch 20.469), train_loss = 1.01714428, grad/param norm = 1.6061e-01, time/batch = 0.6775s	
13572/33150 (epoch 20.471), train_loss = 0.95346872, grad/param norm = 1.3840e-01, time/batch = 0.6795s	
13573/33150 (epoch 20.472), train_loss = 1.03592333, grad/param norm = 1.5013e-01, time/batch = 0.6736s	
13574/33150 (epoch 20.474), train_loss = 1.12989369, grad/param norm = 1.8998e-01, time/batch = 0.6740s	
13575/33150 (epoch 20.475), train_loss = 1.29366536, grad/param norm = 1.6657e-01, time/batch = 0.6725s	
13576/33150 (epoch 20.477), train_loss = 1.14015971, grad/param norm = 1.7178e-01, time/batch = 0.6726s	
13577/33150 (epoch 20.478), train_loss = 1.09964962, grad/param norm = 1.4894e-01, time/batch = 0.6830s	
13578/33150 (epoch 20.480), train_loss = 0.96209451, grad/param norm = 1.5455e-01, time/batch = 0.6712s	
13579/33150 (epoch 20.481), train_loss = 0.86278064, grad/param norm = 1.4429e-01, time/batch = 0.6717s	
13580/33150 (epoch 20.483), train_loss = 0.95699009, grad/param norm = 1.4820e-01, time/batch = 0.6710s	
13581/33150 (epoch 20.484), train_loss = 0.96305663, grad/param norm = 1.6380e-01, time/batch = 0.6719s	
13582/33150 (epoch 20.486), train_loss = 0.97944065, grad/param norm = 1.5527e-01, time/batch = 0.6731s	
13583/33150 (epoch 20.487), train_loss = 1.03827518, grad/param norm = 1.5650e-01, time/batch = 0.6752s	
13584/33150 (epoch 20.489), train_loss = 1.01132091, grad/param norm = 1.5696e-01, time/batch = 0.6857s	
13585/33150 (epoch 20.490), train_loss = 0.85801921, grad/param norm = 1.3909e-01, time/batch = 0.6928s	
13586/33150 (epoch 20.492), train_loss = 0.97147861, grad/param norm = 1.6570e-01, time/batch = 0.6929s	
13587/33150 (epoch 20.493), train_loss = 1.09976105, grad/param norm = 1.6342e-01, time/batch = 0.7083s	
13588/33150 (epoch 20.495), train_loss = 1.13288127, grad/param norm = 1.5336e-01, time/batch = 0.6923s	
13589/33150 (epoch 20.496), train_loss = 0.99669339, grad/param norm = 1.5181e-01, time/batch = 0.6805s	
13590/33150 (epoch 20.498), train_loss = 1.15341934, grad/param norm = 1.8024e-01, time/batch = 0.6744s	
13591/33150 (epoch 20.499), train_loss = 1.13616375, grad/param norm = 1.6560e-01, time/batch = 0.6931s	
13592/33150 (epoch 20.501), train_loss = 1.06871948, grad/param norm = 1.5996e-01, time/batch = 0.6863s	
13593/33150 (epoch 20.502), train_loss = 1.16053431, grad/param norm = 1.7196e-01, time/batch = 0.7064s	
13594/33150 (epoch 20.504), train_loss = 1.10470677, grad/param norm = 1.6873e-01, time/batch = 0.6825s	
13595/33150 (epoch 20.505), train_loss = 1.21657206, grad/param norm = 1.8688e-01, time/batch = 0.6850s	
13596/33150 (epoch 20.507), train_loss = 1.00895720, grad/param norm = 1.5205e-01, time/batch = 0.6721s	
13597/33150 (epoch 20.508), train_loss = 0.98124028, grad/param norm = 1.4978e-01, time/batch = 0.6735s	
13598/33150 (epoch 20.510), train_loss = 1.05667572, grad/param norm = 1.5123e-01, time/batch = 0.6712s	
13599/33150 (epoch 20.511), train_loss = 1.16555757, grad/param norm = 1.7100e-01, time/batch = 0.6779s	
13600/33150 (epoch 20.513), train_loss = 1.04395186, grad/param norm = 1.6073e-01, time/batch = 0.6770s	
13601/33150 (epoch 20.514), train_loss = 0.86064510, grad/param norm = 1.3998e-01, time/batch = 0.6758s	
13602/33150 (epoch 20.516), train_loss = 1.09673276, grad/param norm = 1.8699e-01, time/batch = 0.6761s	
13603/33150 (epoch 20.517), train_loss = 1.13665416, grad/param norm = 1.5304e-01, time/batch = 0.6676s	
13604/33150 (epoch 20.519), train_loss = 0.94818948, grad/param norm = 1.5709e-01, time/batch = 0.6742s	
13605/33150 (epoch 20.520), train_loss = 1.03884096, grad/param norm = 1.4235e-01, time/batch = 0.6790s	
13606/33150 (epoch 20.522), train_loss = 1.16410191, grad/param norm = 1.7115e-01, time/batch = 0.6847s	
13607/33150 (epoch 20.523), train_loss = 0.95771189, grad/param norm = 1.3986e-01, time/batch = 0.6793s	
13608/33150 (epoch 20.525), train_loss = 1.10777781, grad/param norm = 1.7896e-01, time/batch = 0.6748s	
13609/33150 (epoch 20.526), train_loss = 0.96838338, grad/param norm = 1.6303e-01, time/batch = 0.6767s	
13610/33150 (epoch 20.528), train_loss = 1.07729368, grad/param norm = 1.5460e-01, time/batch = 0.6829s	
13611/33150 (epoch 20.529), train_loss = 1.00106017, grad/param norm = 1.5162e-01, time/batch = 0.6839s	
13612/33150 (epoch 20.531), train_loss = 0.86770341, grad/param norm = 1.7087e-01, time/batch = 0.6769s	
13613/33150 (epoch 20.532), train_loss = 1.08300251, grad/param norm = 1.7288e-01, time/batch = 0.6744s	
13614/33150 (epoch 20.534), train_loss = 0.98411150, grad/param norm = 1.3136e-01, time/batch = 0.6760s	
13615/33150 (epoch 20.535), train_loss = 0.95357843, grad/param norm = 1.7877e-01, time/batch = 0.6755s	
13616/33150 (epoch 20.537), train_loss = 1.11270212, grad/param norm = 1.5953e-01, time/batch = 0.6756s	
13617/33150 (epoch 20.538), train_loss = 0.97150015, grad/param norm = 1.4866e-01, time/batch = 0.6752s	
13618/33150 (epoch 20.540), train_loss = 0.87819924, grad/param norm = 1.4330e-01, time/batch = 0.6730s	
13619/33150 (epoch 20.541), train_loss = 1.12228425, grad/param norm = 1.5634e-01, time/batch = 0.6715s	
13620/33150 (epoch 20.543), train_loss = 1.05258070, grad/param norm = 1.6740e-01, time/batch = 0.6814s	
13621/33150 (epoch 20.544), train_loss = 1.08062584, grad/param norm = 1.5172e-01, time/batch = 0.6867s	
13622/33150 (epoch 20.546), train_loss = 1.06854971, grad/param norm = 1.5790e-01, time/batch = 0.6772s	
13623/33150 (epoch 20.548), train_loss = 1.03804898, grad/param norm = 1.7788e-01, time/batch = 0.6762s	
13624/33150 (epoch 20.549), train_loss = 0.97308276, grad/param norm = 1.5456e-01, time/batch = 0.6747s	
13625/33150 (epoch 20.551), train_loss = 0.93447235, grad/param norm = 1.3821e-01, time/batch = 0.6751s	
13626/33150 (epoch 20.552), train_loss = 0.81697754, grad/param norm = 1.2373e-01, time/batch = 0.6736s	
13627/33150 (epoch 20.554), train_loss = 1.10142860, grad/param norm = 1.5459e-01, time/batch = 0.6802s	
13628/33150 (epoch 20.555), train_loss = 1.16755961, grad/param norm = 1.9777e-01, time/batch = 0.6767s	
13629/33150 (epoch 20.557), train_loss = 0.84278200, grad/param norm = 1.5273e-01, time/batch = 0.6793s	
13630/33150 (epoch 20.558), train_loss = 1.10825427, grad/param norm = 2.0099e-01, time/batch = 0.6763s	
13631/33150 (epoch 20.560), train_loss = 0.99314980, grad/param norm = 1.5563e-01, time/batch = 0.6739s	
13632/33150 (epoch 20.561), train_loss = 0.87453701, grad/param norm = 1.4714e-01, time/batch = 0.6749s	
13633/33150 (epoch 20.563), train_loss = 1.08436490, grad/param norm = 1.7538e-01, time/batch = 0.6764s	
13634/33150 (epoch 20.564), train_loss = 1.18143465, grad/param norm = 1.7313e-01, time/batch = 0.6734s	
13635/33150 (epoch 20.566), train_loss = 0.99800766, grad/param norm = 1.4954e-01, time/batch = 0.6826s	
13636/33150 (epoch 20.567), train_loss = 0.93157052, grad/param norm = 1.5022e-01, time/batch = 0.6845s	
13637/33150 (epoch 20.569), train_loss = 1.06253550, grad/param norm = 1.6829e-01, time/batch = 0.6729s	
13638/33150 (epoch 20.570), train_loss = 1.08767204, grad/param norm = 1.5321e-01, time/batch = 0.6745s	
13639/33150 (epoch 20.572), train_loss = 0.95017357, grad/param norm = 1.6935e-01, time/batch = 0.6702s	
13640/33150 (epoch 20.573), train_loss = 0.82675399, grad/param norm = 1.2587e-01, time/batch = 0.6721s	
13641/33150 (epoch 20.575), train_loss = 1.00333216, grad/param norm = 1.5841e-01, time/batch = 0.6732s	
13642/33150 (epoch 20.576), train_loss = 0.88134374, grad/param norm = 1.2407e-01, time/batch = 0.6727s	
13643/33150 (epoch 20.578), train_loss = 0.94169896, grad/param norm = 1.5434e-01, time/batch = 0.6718s	
13644/33150 (epoch 20.579), train_loss = 0.85599663, grad/param norm = 1.2896e-01, time/batch = 0.6735s	
13645/33150 (epoch 20.581), train_loss = 0.93823673, grad/param norm = 1.4565e-01, time/batch = 0.6709s	
13646/33150 (epoch 20.582), train_loss = 1.11909142, grad/param norm = 1.4978e-01, time/batch = 0.6706s	
13647/33150 (epoch 20.584), train_loss = 1.10554050, grad/param norm = 1.5822e-01, time/batch = 0.6741s	
13648/33150 (epoch 20.585), train_loss = 1.01401170, grad/param norm = 1.5260e-01, time/batch = 0.6681s	
13649/33150 (epoch 20.587), train_loss = 1.02736647, grad/param norm = 1.4458e-01, time/batch = 0.6667s	
13650/33150 (epoch 20.588), train_loss = 0.94598539, grad/param norm = 1.6013e-01, time/batch = 0.6804s	
13651/33150 (epoch 20.590), train_loss = 1.03540470, grad/param norm = 1.5869e-01, time/batch = 0.6827s	
13652/33150 (epoch 20.591), train_loss = 1.00112663, grad/param norm = 1.5374e-01, time/batch = 0.6686s	
13653/33150 (epoch 20.593), train_loss = 1.08183335, grad/param norm = 1.6460e-01, time/batch = 0.6717s	
13654/33150 (epoch 20.594), train_loss = 1.01625579, grad/param norm = 1.5467e-01, time/batch = 0.6797s	
13655/33150 (epoch 20.596), train_loss = 0.96574007, grad/param norm = 1.5482e-01, time/batch = 0.6746s	
13656/33150 (epoch 20.597), train_loss = 0.88711066, grad/param norm = 1.7092e-01, time/batch = 0.6753s	
13657/33150 (epoch 20.599), train_loss = 1.17191327, grad/param norm = 1.9566e-01, time/batch = 0.6735s	
13658/33150 (epoch 20.600), train_loss = 1.03709127, grad/param norm = 1.9103e-01, time/batch = 0.6742s	
13659/33150 (epoch 20.602), train_loss = 0.98395454, grad/param norm = 1.6667e-01, time/batch = 0.6737s	
13660/33150 (epoch 20.603), train_loss = 1.08558299, grad/param norm = 1.4955e-01, time/batch = 0.6764s	
13661/33150 (epoch 20.605), train_loss = 0.92882783, grad/param norm = 1.5109e-01, time/batch = 0.6729s	
13662/33150 (epoch 20.606), train_loss = 1.01919280, grad/param norm = 2.0226e-01, time/batch = 0.6735s	
13663/33150 (epoch 20.608), train_loss = 1.09823363, grad/param norm = 1.6137e-01, time/batch = 0.6768s	
13664/33150 (epoch 20.609), train_loss = 1.00292304, grad/param norm = 1.6355e-01, time/batch = 0.6752s	
13665/33150 (epoch 20.611), train_loss = 0.90921313, grad/param norm = 1.4630e-01, time/batch = 0.6855s	
13666/33150 (epoch 20.612), train_loss = 1.03741959, grad/param norm = 1.6306e-01, time/batch = 0.6797s	
13667/33150 (epoch 20.614), train_loss = 0.90511634, grad/param norm = 1.4501e-01, time/batch = 0.6752s	
13668/33150 (epoch 20.615), train_loss = 0.90849552, grad/param norm = 1.4360e-01, time/batch = 0.6770s	
13669/33150 (epoch 20.617), train_loss = 1.03240133, grad/param norm = 1.6953e-01, time/batch = 0.6784s	
13670/33150 (epoch 20.618), train_loss = 1.03299160, grad/param norm = 1.5710e-01, time/batch = 0.6753s	
13671/33150 (epoch 20.620), train_loss = 0.93530811, grad/param norm = 1.4558e-01, time/batch = 0.6776s	
13672/33150 (epoch 20.621), train_loss = 1.00906623, grad/param norm = 1.4257e-01, time/batch = 0.6852s	
13673/33150 (epoch 20.623), train_loss = 1.07667728, grad/param norm = 1.5049e-01, time/batch = 0.6925s	
13674/33150 (epoch 20.624), train_loss = 0.96215426, grad/param norm = 1.5190e-01, time/batch = 0.6955s	
13675/33150 (epoch 20.626), train_loss = 0.96005317, grad/param norm = 1.6258e-01, time/batch = 0.6787s	
13676/33150 (epoch 20.627), train_loss = 0.92372788, grad/param norm = 1.6208e-01, time/batch = 0.6735s	
13677/33150 (epoch 20.629), train_loss = 0.88322512, grad/param norm = 1.5529e-01, time/batch = 0.6776s	
13678/33150 (epoch 20.630), train_loss = 0.94965368, grad/param norm = 1.5280e-01, time/batch = 0.6764s	
13679/33150 (epoch 20.632), train_loss = 0.87732946, grad/param norm = 1.3270e-01, time/batch = 0.6779s	
13680/33150 (epoch 20.633), train_loss = 0.87369177, grad/param norm = 1.7311e-01, time/batch = 0.6737s	
13681/33150 (epoch 20.635), train_loss = 1.18455155, grad/param norm = 1.6835e-01, time/batch = 0.6731s	
13682/33150 (epoch 20.637), train_loss = 0.87444695, grad/param norm = 1.5043e-01, time/batch = 0.6733s	
13683/33150 (epoch 20.638), train_loss = 0.97259546, grad/param norm = 1.5262e-01, time/batch = 0.6976s	
13684/33150 (epoch 20.640), train_loss = 1.08570669, grad/param norm = 1.6085e-01, time/batch = 0.6797s	
13685/33150 (epoch 20.641), train_loss = 0.88436322, grad/param norm = 1.4907e-01, time/batch = 0.6960s	
13686/33150 (epoch 20.643), train_loss = 0.95312045, grad/param norm = 1.5603e-01, time/batch = 0.6932s	
13687/33150 (epoch 20.644), train_loss = 1.14875428, grad/param norm = 1.5749e-01, time/batch = 0.6763s	
13688/33150 (epoch 20.646), train_loss = 0.96853899, grad/param norm = 1.4714e-01, time/batch = 0.6867s	
13689/33150 (epoch 20.647), train_loss = 1.21656558, grad/param norm = 1.6599e-01, time/batch = 0.6779s	
13690/33150 (epoch 20.649), train_loss = 1.10487155, grad/param norm = 1.6423e-01, time/batch = 0.6708s	
13691/33150 (epoch 20.650), train_loss = 0.89013490, grad/param norm = 1.3136e-01, time/batch = 0.6707s	
13692/33150 (epoch 20.652), train_loss = 1.13339228, grad/param norm = 1.6335e-01, time/batch = 0.6708s	
13693/33150 (epoch 20.653), train_loss = 1.02888621, grad/param norm = 1.4594e-01, time/batch = 0.6781s	
13694/33150 (epoch 20.655), train_loss = 1.05599963, grad/param norm = 1.5444e-01, time/batch = 0.6777s	
13695/33150 (epoch 20.656), train_loss = 0.95903381, grad/param norm = 1.5129e-01, time/batch = 0.6736s	
13696/33150 (epoch 20.658), train_loss = 0.96629590, grad/param norm = 1.5890e-01, time/batch = 0.6692s	
13697/33150 (epoch 20.659), train_loss = 1.29488724, grad/param norm = 2.6219e-01, time/batch = 0.6713s	
13698/33150 (epoch 20.661), train_loss = 1.01313734, grad/param norm = 1.7370e-01, time/batch = 0.6737s	
13699/33150 (epoch 20.662), train_loss = 0.92259169, grad/param norm = 1.7215e-01, time/batch = 0.6850s	
13700/33150 (epoch 20.664), train_loss = 1.15274098, grad/param norm = 1.6790e-01, time/batch = 0.6743s	
13701/33150 (epoch 20.665), train_loss = 1.07422067, grad/param norm = 1.6264e-01, time/batch = 0.6737s	
13702/33150 (epoch 20.667), train_loss = 1.13023131, grad/param norm = 1.6646e-01, time/batch = 0.6746s	
13703/33150 (epoch 20.668), train_loss = 1.11482968, grad/param norm = 1.7196e-01, time/batch = 0.6739s	
13704/33150 (epoch 20.670), train_loss = 0.95547392, grad/param norm = 1.4384e-01, time/batch = 0.6726s	
13705/33150 (epoch 20.671), train_loss = 0.95539230, grad/param norm = 1.5843e-01, time/batch = 0.6717s	
13706/33150 (epoch 20.673), train_loss = 1.13805043, grad/param norm = 1.3939e-01, time/batch = 0.6730s	
13707/33150 (epoch 20.674), train_loss = 1.01639923, grad/param norm = 1.5695e-01, time/batch = 0.6721s	
13708/33150 (epoch 20.676), train_loss = 0.98222711, grad/param norm = 1.4468e-01, time/batch = 0.6731s	
13709/33150 (epoch 20.677), train_loss = 1.19644397, grad/param norm = 1.6511e-01, time/batch = 0.6746s	
13710/33150 (epoch 20.679), train_loss = 1.01045562, grad/param norm = 1.4040e-01, time/batch = 0.6740s	
13711/33150 (epoch 20.680), train_loss = 1.14674456, grad/param norm = 1.5453e-01, time/batch = 0.6759s	
13712/33150 (epoch 20.682), train_loss = 0.98115740, grad/param norm = 1.4247e-01, time/batch = 0.6732s	
13713/33150 (epoch 20.683), train_loss = 0.87267661, grad/param norm = 1.3472e-01, time/batch = 0.6733s	
13714/33150 (epoch 20.685), train_loss = 0.99943911, grad/param norm = 1.7251e-01, time/batch = 0.6737s	
13715/33150 (epoch 20.686), train_loss = 0.87858552, grad/param norm = 1.5549e-01, time/batch = 0.6718s	
13716/33150 (epoch 20.688), train_loss = 0.91227884, grad/param norm = 1.4234e-01, time/batch = 0.6723s	
13717/33150 (epoch 20.689), train_loss = 0.92500119, grad/param norm = 1.4364e-01, time/batch = 0.6716s	
13718/33150 (epoch 20.691), train_loss = 0.80400980, grad/param norm = 1.3049e-01, time/batch = 0.6700s	
13719/33150 (epoch 20.692), train_loss = 0.90036977, grad/param norm = 1.4331e-01, time/batch = 0.6689s	
13720/33150 (epoch 20.694), train_loss = 0.79679405, grad/param norm = 1.3387e-01, time/batch = 0.6716s	
13721/33150 (epoch 20.695), train_loss = 0.93748406, grad/param norm = 1.3149e-01, time/batch = 0.6727s	
13722/33150 (epoch 20.697), train_loss = 0.85595661, grad/param norm = 1.3042e-01, time/batch = 0.6770s	
13723/33150 (epoch 20.698), train_loss = 0.95691082, grad/param norm = 1.6074e-01, time/batch = 0.6749s	
13724/33150 (epoch 20.700), train_loss = 0.75705251, grad/param norm = 1.2199e-01, time/batch = 0.6759s	
13725/33150 (epoch 20.701), train_loss = 0.86731449, grad/param norm = 1.3783e-01, time/batch = 0.6907s	
13726/33150 (epoch 20.703), train_loss = 0.98166262, grad/param norm = 1.4976e-01, time/batch = 0.7040s	
13727/33150 (epoch 20.704), train_loss = 0.84502430, grad/param norm = 1.3819e-01, time/batch = 0.6919s	
13728/33150 (epoch 20.706), train_loss = 0.96286558, grad/param norm = 1.5511e-01, time/batch = 0.6822s	
13729/33150 (epoch 20.707), train_loss = 0.93449922, grad/param norm = 1.4196e-01, time/batch = 0.6732s	
13730/33150 (epoch 20.709), train_loss = 0.99325801, grad/param norm = 1.3393e-01, time/batch = 0.6743s	
13731/33150 (epoch 20.710), train_loss = 1.00055160, grad/param norm = 1.8184e-01, time/batch = 0.6808s	
13732/33150 (epoch 20.712), train_loss = 1.05146802, grad/param norm = 1.3773e-01, time/batch = 0.6742s	
13733/33150 (epoch 20.713), train_loss = 1.04608786, grad/param norm = 1.4152e-01, time/batch = 0.6709s	
13734/33150 (epoch 20.715), train_loss = 0.93605008, grad/param norm = 1.4293e-01, time/batch = 0.6685s	
13735/33150 (epoch 20.716), train_loss = 1.03228761, grad/param norm = 1.5340e-01, time/batch = 0.6697s	
13736/33150 (epoch 20.718), train_loss = 1.02308998, grad/param norm = 1.5791e-01, time/batch = 0.6717s	
13737/33150 (epoch 20.719), train_loss = 1.11364987, grad/param norm = 1.8685e-01, time/batch = 0.6720s	
13738/33150 (epoch 20.721), train_loss = 0.97500859, grad/param norm = 1.6366e-01, time/batch = 0.6699s	
13739/33150 (epoch 20.722), train_loss = 1.01689439, grad/param norm = 1.4822e-01, time/batch = 0.6701s	
13740/33150 (epoch 20.724), train_loss = 0.96548384, grad/param norm = 1.5039e-01, time/batch = 0.6679s	
13741/33150 (epoch 20.725), train_loss = 1.11868470, grad/param norm = 1.8229e-01, time/batch = 0.6699s	
13742/33150 (epoch 20.727), train_loss = 1.04762054, grad/param norm = 1.9509e-01, time/batch = 0.6763s	
13743/33150 (epoch 20.729), train_loss = 0.98767459, grad/param norm = 1.6064e-01, time/batch = 0.6852s	
13744/33150 (epoch 20.730), train_loss = 1.04173718, grad/param norm = 1.5377e-01, time/batch = 0.6743s	
13745/33150 (epoch 20.732), train_loss = 1.10175884, grad/param norm = 1.7367e-01, time/batch = 0.6708s	
13746/33150 (epoch 20.733), train_loss = 0.82935781, grad/param norm = 1.2284e-01, time/batch = 0.6669s	
13747/33150 (epoch 20.735), train_loss = 0.91458090, grad/param norm = 1.4088e-01, time/batch = 0.6704s	
13748/33150 (epoch 20.736), train_loss = 0.96289543, grad/param norm = 1.5660e-01, time/batch = 0.6698s	
13749/33150 (epoch 20.738), train_loss = 1.01724799, grad/param norm = 1.5622e-01, time/batch = 0.6773s	
13750/33150 (epoch 20.739), train_loss = 1.10852006, grad/param norm = 1.6432e-01, time/batch = 0.6709s	
13751/33150 (epoch 20.741), train_loss = 1.10659381, grad/param norm = 1.6381e-01, time/batch = 0.6677s	
13752/33150 (epoch 20.742), train_loss = 0.89246742, grad/param norm = 1.5477e-01, time/batch = 0.6643s	
13753/33150 (epoch 20.744), train_loss = 1.11717201, grad/param norm = 1.6665e-01, time/batch = 0.6701s	
13754/33150 (epoch 20.745), train_loss = 0.95998438, grad/param norm = 1.3784e-01, time/batch = 0.6693s	
13755/33150 (epoch 20.747), train_loss = 0.80201037, grad/param norm = 1.4203e-01, time/batch = 0.6667s	
13756/33150 (epoch 20.748), train_loss = 0.92474167, grad/param norm = 1.4531e-01, time/batch = 0.6678s	
13757/33150 (epoch 20.750), train_loss = 1.06358655, grad/param norm = 1.6939e-01, time/batch = 0.6711s	
13758/33150 (epoch 20.751), train_loss = 1.00698662, grad/param norm = 1.4908e-01, time/batch = 0.6851s	
13759/33150 (epoch 20.753), train_loss = 0.86118527, grad/param norm = 1.5881e-01, time/batch = 0.6744s	
13760/33150 (epoch 20.754), train_loss = 1.23429067, grad/param norm = 1.8302e-01, time/batch = 0.6692s	
13761/33150 (epoch 20.756), train_loss = 1.03716218, grad/param norm = 2.1656e-01, time/batch = 0.6912s	
13762/33150 (epoch 20.757), train_loss = 1.02350945, grad/param norm = 1.5806e-01, time/batch = 0.6935s	
13763/33150 (epoch 20.759), train_loss = 1.15258938, grad/param norm = 2.0743e-01, time/batch = 0.7051s	
13764/33150 (epoch 20.760), train_loss = 1.04064834, grad/param norm = 1.5474e-01, time/batch = 0.6760s	
13765/33150 (epoch 20.762), train_loss = 1.03142472, grad/param norm = 1.8582e-01, time/batch = 0.6857s	
13766/33150 (epoch 20.763), train_loss = 1.04197426, grad/param norm = 1.6608e-01, time/batch = 0.6717s	
13767/33150 (epoch 20.765), train_loss = 1.00983288, grad/param norm = 1.5291e-01, time/batch = 0.6697s	
13768/33150 (epoch 20.766), train_loss = 0.93510476, grad/param norm = 1.6432e-01, time/batch = 0.6848s	
13769/33150 (epoch 20.768), train_loss = 0.93470207, grad/param norm = 1.4908e-01, time/batch = 0.6884s	
13770/33150 (epoch 20.769), train_loss = 1.05326707, grad/param norm = 1.6180e-01, time/batch = 0.6752s	
13771/33150 (epoch 20.771), train_loss = 1.04151213, grad/param norm = 1.8629e-01, time/batch = 0.6738s	
13772/33150 (epoch 20.772), train_loss = 1.08328203, grad/param norm = 1.7272e-01, time/batch = 0.6738s	
13773/33150 (epoch 20.774), train_loss = 1.18822070, grad/param norm = 1.6224e-01, time/batch = 0.6684s	
13774/33150 (epoch 20.775), train_loss = 1.07029634, grad/param norm = 2.0965e-01, time/batch = 0.6735s	
13775/33150 (epoch 20.777), train_loss = 1.06233641, grad/param norm = 1.9215e-01, time/batch = 0.6703s	
13776/33150 (epoch 20.778), train_loss = 1.02493664, grad/param norm = 1.3262e-01, time/batch = 0.6754s	
13777/33150 (epoch 20.780), train_loss = 0.86293355, grad/param norm = 1.3506e-01, time/batch = 0.6708s	
13778/33150 (epoch 20.781), train_loss = 1.00552241, grad/param norm = 1.4664e-01, time/batch = 0.6747s	
13779/33150 (epoch 20.783), train_loss = 1.02854084, grad/param norm = 1.5019e-01, time/batch = 0.6734s	
13780/33150 (epoch 20.784), train_loss = 0.99644058, grad/param norm = 1.5927e-01, time/batch = 0.6737s	
13781/33150 (epoch 20.786), train_loss = 0.99498072, grad/param norm = 1.4287e-01, time/batch = 0.6742s	
13782/33150 (epoch 20.787), train_loss = 0.93595891, grad/param norm = 1.4217e-01, time/batch = 0.6754s	
13783/33150 (epoch 20.789), train_loss = 0.85148670, grad/param norm = 1.4539e-01, time/batch = 0.6774s	
13784/33150 (epoch 20.790), train_loss = 0.88371055, grad/param norm = 1.2897e-01, time/batch = 0.6744s	
13785/33150 (epoch 20.792), train_loss = 1.04584746, grad/param norm = 1.7892e-01, time/batch = 0.6764s	
13786/33150 (epoch 20.793), train_loss = 0.98713822, grad/param norm = 1.7086e-01, time/batch = 0.6749s	
13787/33150 (epoch 20.795), train_loss = 0.95353970, grad/param norm = 1.5039e-01, time/batch = 0.6736s	
13788/33150 (epoch 20.796), train_loss = 0.96249130, grad/param norm = 1.4351e-01, time/batch = 0.6750s	
13789/33150 (epoch 20.798), train_loss = 0.92841063, grad/param norm = 1.2656e-01, time/batch = 0.6808s	
13790/33150 (epoch 20.799), train_loss = 0.84009750, grad/param norm = 1.3974e-01, time/batch = 0.6882s	
13791/33150 (epoch 20.801), train_loss = 1.03115888, grad/param norm = 1.4969e-01, time/batch = 0.6833s	
13792/33150 (epoch 20.802), train_loss = 0.90799008, grad/param norm = 1.4433e-01, time/batch = 0.6856s	
13793/33150 (epoch 20.804), train_loss = 0.94155616, grad/param norm = 1.3239e-01, time/batch = 0.6755s	
13794/33150 (epoch 20.805), train_loss = 0.92958557, grad/param norm = 1.7246e-01, time/batch = 0.6710s	
13795/33150 (epoch 20.807), train_loss = 0.94634804, grad/param norm = 1.3814e-01, time/batch = 0.6722s	
13796/33150 (epoch 20.808), train_loss = 1.08685003, grad/param norm = 1.6736e-01, time/batch = 0.6735s	
13797/33150 (epoch 20.810), train_loss = 0.95810312, grad/param norm = 1.5251e-01, time/batch = 0.6753s	
13798/33150 (epoch 20.811), train_loss = 1.03161528, grad/param norm = 1.8146e-01, time/batch = 0.6715s	
13799/33150 (epoch 20.813), train_loss = 0.97033414, grad/param norm = 1.4293e-01, time/batch = 0.6713s	
13800/33150 (epoch 20.814), train_loss = 0.97465963, grad/param norm = 1.6775e-01, time/batch = 0.6716s	
13801/33150 (epoch 20.816), train_loss = 0.96673328, grad/param norm = 1.3887e-01, time/batch = 0.6758s	
13802/33150 (epoch 20.817), train_loss = 1.04726059, grad/param norm = 1.4894e-01, time/batch = 0.6796s	
13803/33150 (epoch 20.819), train_loss = 0.98989801, grad/param norm = 1.4751e-01, time/batch = 0.6749s	
13804/33150 (epoch 20.821), train_loss = 0.89346585, grad/param norm = 1.4254e-01, time/batch = 0.6756s	
13805/33150 (epoch 20.822), train_loss = 0.94133333, grad/param norm = 1.4832e-01, time/batch = 0.6743s	
13806/33150 (epoch 20.824), train_loss = 0.95791008, grad/param norm = 1.4761e-01, time/batch = 0.6815s	
13807/33150 (epoch 20.825), train_loss = 1.01641395, grad/param norm = 1.5364e-01, time/batch = 0.6846s	
13808/33150 (epoch 20.827), train_loss = 1.05933731, grad/param norm = 1.6301e-01, time/batch = 0.6783s	
13809/33150 (epoch 20.828), train_loss = 0.88183495, grad/param norm = 1.5600e-01, time/batch = 0.6734s	
13810/33150 (epoch 20.830), train_loss = 1.08502864, grad/param norm = 1.7260e-01, time/batch = 0.6729s	
13811/33150 (epoch 20.831), train_loss = 0.94079891, grad/param norm = 1.6995e-01, time/batch = 0.6738s	
13812/33150 (epoch 20.833), train_loss = 0.91837931, grad/param norm = 1.4940e-01, time/batch = 0.6779s	
13813/33150 (epoch 20.834), train_loss = 1.09961703, grad/param norm = 1.6998e-01, time/batch = 0.6750s	
13814/33150 (epoch 20.836), train_loss = 1.12531037, grad/param norm = 1.5181e-01, time/batch = 0.6884s	
13815/33150 (epoch 20.837), train_loss = 0.99153047, grad/param norm = 1.5482e-01, time/batch = 0.6820s	
13816/33150 (epoch 20.839), train_loss = 1.08501659, grad/param norm = 1.7572e-01, time/batch = 0.6731s	
13817/33150 (epoch 20.840), train_loss = 1.06373828, grad/param norm = 1.5369e-01, time/batch = 0.6730s	
13818/33150 (epoch 20.842), train_loss = 1.12073450, grad/param norm = 1.7205e-01, time/batch = 0.6718s	
13819/33150 (epoch 20.843), train_loss = 1.09626311, grad/param norm = 1.6951e-01, time/batch = 0.6736s	
13820/33150 (epoch 20.845), train_loss = 0.93759909, grad/param norm = 1.4966e-01, time/batch = 0.6754s	
13821/33150 (epoch 20.846), train_loss = 1.19319922, grad/param norm = 1.9555e-01, time/batch = 0.6783s	
13822/33150 (epoch 20.848), train_loss = 1.09676021, grad/param norm = 1.6866e-01, time/batch = 0.6728s	
13823/33150 (epoch 20.849), train_loss = 1.14676047, grad/param norm = 1.7100e-01, time/batch = 0.6708s	
13824/33150 (epoch 20.851), train_loss = 1.09137365, grad/param norm = 1.8032e-01, time/batch = 0.6706s	
13825/33150 (epoch 20.852), train_loss = 1.14770926, grad/param norm = 1.5198e-01, time/batch = 0.6727s	
13826/33150 (epoch 20.854), train_loss = 1.01374438, grad/param norm = 1.4883e-01, time/batch = 0.6730s	
13827/33150 (epoch 20.855), train_loss = 0.85617692, grad/param norm = 1.3227e-01, time/batch = 0.6841s	
13828/33150 (epoch 20.857), train_loss = 0.86878377, grad/param norm = 1.5083e-01, time/batch = 0.6977s	
13829/33150 (epoch 20.858), train_loss = 0.96552084, grad/param norm = 1.5410e-01, time/batch = 0.6855s	
13830/33150 (epoch 20.860), train_loss = 0.88861505, grad/param norm = 1.3805e-01, time/batch = 0.6798s	
13831/33150 (epoch 20.861), train_loss = 0.90035220, grad/param norm = 1.6535e-01, time/batch = 0.6837s	
13832/33150 (epoch 20.863), train_loss = 1.01150521, grad/param norm = 1.4241e-01, time/batch = 0.6954s	
13833/33150 (epoch 20.864), train_loss = 1.09438524, grad/param norm = 1.5462e-01, time/batch = 0.6931s	
13834/33150 (epoch 20.866), train_loss = 1.06446724, grad/param norm = 1.5253e-01, time/batch = 0.6933s	
13835/33150 (epoch 20.867), train_loss = 1.04647941, grad/param norm = 1.5278e-01, time/batch = 0.6904s	
13836/33150 (epoch 20.869), train_loss = 1.06105767, grad/param norm = 1.6931e-01, time/batch = 0.6893s	
13837/33150 (epoch 20.870), train_loss = 0.98862651, grad/param norm = 1.6741e-01, time/batch = 0.6895s	
13838/33150 (epoch 20.872), train_loss = 1.02430955, grad/param norm = 1.5704e-01, time/batch = 0.6776s	
13839/33150 (epoch 20.873), train_loss = 0.86541618, grad/param norm = 1.3752e-01, time/batch = 0.6723s	
13840/33150 (epoch 20.875), train_loss = 1.13252605, grad/param norm = 1.5884e-01, time/batch = 0.6709s	
13841/33150 (epoch 20.876), train_loss = 0.88426380, grad/param norm = 1.4361e-01, time/batch = 0.6782s	
13842/33150 (epoch 20.878), train_loss = 0.89873785, grad/param norm = 1.3031e-01, time/batch = 0.6765s	
13843/33150 (epoch 20.879), train_loss = 0.92295467, grad/param norm = 1.4698e-01, time/batch = 0.6695s	
13844/33150 (epoch 20.881), train_loss = 0.93285596, grad/param norm = 1.5347e-01, time/batch = 0.6705s	
13845/33150 (epoch 20.882), train_loss = 0.83905220, grad/param norm = 1.4720e-01, time/batch = 0.6721s	
13846/33150 (epoch 20.884), train_loss = 0.97845733, grad/param norm = 1.4825e-01, time/batch = 0.6747s	
13847/33150 (epoch 20.885), train_loss = 0.77242956, grad/param norm = 1.4282e-01, time/batch = 0.6741s	
13848/33150 (epoch 20.887), train_loss = 1.10651424, grad/param norm = 1.7801e-01, time/batch = 0.6724s	
13849/33150 (epoch 20.888), train_loss = 1.04479658, grad/param norm = 1.6239e-01, time/batch = 0.6872s	
13850/33150 (epoch 20.890), train_loss = 0.92278658, grad/param norm = 1.4858e-01, time/batch = 0.6916s	
13851/33150 (epoch 20.891), train_loss = 0.90269817, grad/param norm = 1.4823e-01, time/batch = 0.6890s	
13852/33150 (epoch 20.893), train_loss = 1.06343162, grad/param norm = 1.5640e-01, time/batch = 0.6737s	
13853/33150 (epoch 20.894), train_loss = 1.04763190, grad/param norm = 1.5783e-01, time/batch = 0.6748s	
13854/33150 (epoch 20.896), train_loss = 0.96545331, grad/param norm = 1.4559e-01, time/batch = 0.6755s	
13855/33150 (epoch 20.897), train_loss = 1.03501786, grad/param norm = 1.3948e-01, time/batch = 0.6749s	
13856/33150 (epoch 20.899), train_loss = 0.84725367, grad/param norm = 1.5988e-01, time/batch = 0.6772s	
13857/33150 (epoch 20.900), train_loss = 1.22030535, grad/param norm = 1.7657e-01, time/batch = 0.6787s	
13858/33150 (epoch 20.902), train_loss = 1.19179485, grad/param norm = 1.7057e-01, time/batch = 0.6757s	
13859/33150 (epoch 20.903), train_loss = 1.01216276, grad/param norm = 1.6318e-01, time/batch = 0.6801s	
13860/33150 (epoch 20.905), train_loss = 1.03644028, grad/param norm = 1.3639e-01, time/batch = 0.6813s	
13861/33150 (epoch 20.906), train_loss = 1.03532628, grad/param norm = 1.6910e-01, time/batch = 0.6809s	
13862/33150 (epoch 20.908), train_loss = 1.14592989, grad/param norm = 1.6456e-01, time/batch = 0.7057s	
13863/33150 (epoch 20.910), train_loss = 1.07736685, grad/param norm = 1.6258e-01, time/batch = 0.6887s	
13864/33150 (epoch 20.911), train_loss = 0.86294443, grad/param norm = 1.4130e-01, time/batch = 0.6755s	
13865/33150 (epoch 20.913), train_loss = 0.93654588, grad/param norm = 1.6677e-01, time/batch = 0.6873s	
13866/33150 (epoch 20.914), train_loss = 1.09958149, grad/param norm = 1.7586e-01, time/batch = 0.6781s	
13867/33150 (epoch 20.916), train_loss = 0.91548751, grad/param norm = 1.6369e-01, time/batch = 0.6702s	
13868/33150 (epoch 20.917), train_loss = 1.05097028, grad/param norm = 1.7181e-01, time/batch = 0.6686s	
13869/33150 (epoch 20.919), train_loss = 1.13962758, grad/param norm = 1.8716e-01, time/batch = 0.6711s	
13870/33150 (epoch 20.920), train_loss = 1.11734253, grad/param norm = 1.5787e-01, time/batch = 0.6713s	
13871/33150 (epoch 20.922), train_loss = 1.14661731, grad/param norm = 1.7286e-01, time/batch = 0.6754s	
13872/33150 (epoch 20.923), train_loss = 1.01197430, grad/param norm = 1.6042e-01, time/batch = 0.6723s	
13873/33150 (epoch 20.925), train_loss = 1.11582109, grad/param norm = 1.5735e-01, time/batch = 0.6720s	
13874/33150 (epoch 20.926), train_loss = 0.97535684, grad/param norm = 1.5116e-01, time/batch = 0.6757s	
13875/33150 (epoch 20.928), train_loss = 0.96734042, grad/param norm = 1.5014e-01, time/batch = 0.6756s	
13876/33150 (epoch 20.929), train_loss = 1.04823687, grad/param norm = 1.4845e-01, time/batch = 0.6718s	
13877/33150 (epoch 20.931), train_loss = 1.16025768, grad/param norm = 1.6969e-01, time/batch = 0.6732s	
13878/33150 (epoch 20.932), train_loss = 1.01321638, grad/param norm = 1.5921e-01, time/batch = 0.6746s	
13879/33150 (epoch 20.934), train_loss = 1.02165354, grad/param norm = 1.4854e-01, time/batch = 0.6921s	
13880/33150 (epoch 20.935), train_loss = 1.12290461, grad/param norm = 1.6240e-01, time/batch = 0.6859s	
13881/33150 (epoch 20.937), train_loss = 1.11746613, grad/param norm = 1.4057e-01, time/batch = 0.6819s	
13882/33150 (epoch 20.938), train_loss = 1.05247626, grad/param norm = 1.5058e-01, time/batch = 0.6783s	
13883/33150 (epoch 20.940), train_loss = 1.26851485, grad/param norm = 1.7861e-01, time/batch = 0.6844s	
13884/33150 (epoch 20.941), train_loss = 1.00975092, grad/param norm = 1.3675e-01, time/batch = 0.6794s	
13885/33150 (epoch 20.943), train_loss = 0.89403984, grad/param norm = 1.5646e-01, time/batch = 0.6725s	
13886/33150 (epoch 20.944), train_loss = 1.11513243, grad/param norm = 1.6135e-01, time/batch = 0.6732s	
13887/33150 (epoch 20.946), train_loss = 0.85076927, grad/param norm = 1.6463e-01, time/batch = 0.6772s	
13888/33150 (epoch 20.947), train_loss = 1.03724010, grad/param norm = 1.5245e-01, time/batch = 0.6818s	
13889/33150 (epoch 20.949), train_loss = 1.13747059, grad/param norm = 1.6611e-01, time/batch = 0.6889s	
13890/33150 (epoch 20.950), train_loss = 1.05551492, grad/param norm = 1.6505e-01, time/batch = 0.6892s	
13891/33150 (epoch 20.952), train_loss = 0.92285152, grad/param norm = 1.5185e-01, time/batch = 0.6885s	
13892/33150 (epoch 20.953), train_loss = 0.97150234, grad/param norm = 1.4275e-01, time/batch = 0.6914s	
13893/33150 (epoch 20.955), train_loss = 0.86831543, grad/param norm = 1.4536e-01, time/batch = 0.6889s	
13894/33150 (epoch 20.956), train_loss = 1.06759564, grad/param norm = 1.5050e-01, time/batch = 0.6821s	
13895/33150 (epoch 20.958), train_loss = 0.90561695, grad/param norm = 1.4115e-01, time/batch = 0.6818s	
13896/33150 (epoch 20.959), train_loss = 0.95719014, grad/param norm = 1.5163e-01, time/batch = 0.6685s	
13897/33150 (epoch 20.961), train_loss = 0.91239388, grad/param norm = 1.7464e-01, time/batch = 0.6684s	
13898/33150 (epoch 20.962), train_loss = 0.87215155, grad/param norm = 1.3858e-01, time/batch = 0.6784s	
13899/33150 (epoch 20.964), train_loss = 1.01696949, grad/param norm = 1.4411e-01, time/batch = 0.6750s	
13900/33150 (epoch 20.965), train_loss = 1.01202072, grad/param norm = 1.6935e-01, time/batch = 0.6773s	
13901/33150 (epoch 20.967), train_loss = 0.99969660, grad/param norm = 1.7571e-01, time/batch = 0.6758s	
13902/33150 (epoch 20.968), train_loss = 0.84682256, grad/param norm = 1.2820e-01, time/batch = 0.6765s	
13903/33150 (epoch 20.970), train_loss = 0.95360423, grad/param norm = 1.4534e-01, time/batch = 0.6743s	
13904/33150 (epoch 20.971), train_loss = 0.99976901, grad/param norm = 1.6166e-01, time/batch = 0.6740s	
13905/33150 (epoch 20.973), train_loss = 1.11325171, grad/param norm = 1.6453e-01, time/batch = 0.6757s	
13906/33150 (epoch 20.974), train_loss = 1.14932044, grad/param norm = 1.7188e-01, time/batch = 0.6733s	
13907/33150 (epoch 20.976), train_loss = 1.08681954, grad/param norm = 1.3919e-01, time/batch = 0.6812s	
13908/33150 (epoch 20.977), train_loss = 1.15224390, grad/param norm = 1.5728e-01, time/batch = 0.6768s	
13909/33150 (epoch 20.979), train_loss = 1.09998795, grad/param norm = 1.7981e-01, time/batch = 0.6851s	
13910/33150 (epoch 20.980), train_loss = 1.16617229, grad/param norm = 1.6523e-01, time/batch = 0.6817s	
13911/33150 (epoch 20.982), train_loss = 1.00205246, grad/param norm = 1.6895e-01, time/batch = 0.6778s	
13912/33150 (epoch 20.983), train_loss = 0.90205334, grad/param norm = 1.5973e-01, time/batch = 0.6756s	
13913/33150 (epoch 20.985), train_loss = 1.09497601, grad/param norm = 1.4611e-01, time/batch = 0.6750s	
13914/33150 (epoch 20.986), train_loss = 0.85934708, grad/param norm = 1.3801e-01, time/batch = 0.6774s	
13915/33150 (epoch 20.988), train_loss = 0.96827718, grad/param norm = 1.7989e-01, time/batch = 0.6793s	
13916/33150 (epoch 20.989), train_loss = 0.95675384, grad/param norm = 1.6439e-01, time/batch = 0.6771s	
13917/33150 (epoch 20.991), train_loss = 1.07392268, grad/param norm = 1.9825e-01, time/batch = 0.6740s	
13918/33150 (epoch 20.992), train_loss = 0.93125402, grad/param norm = 1.5341e-01, time/batch = 0.6728s	
13919/33150 (epoch 20.994), train_loss = 1.02147481, grad/param norm = 1.5345e-01, time/batch = 0.6737s	
13920/33150 (epoch 20.995), train_loss = 0.96946744, grad/param norm = 1.5526e-01, time/batch = 0.6750s	
13921/33150 (epoch 20.997), train_loss = 1.01331536, grad/param norm = 1.7073e-01, time/batch = 0.6754s	
13922/33150 (epoch 20.998), train_loss = 0.82058731, grad/param norm = 1.3095e-01, time/batch = 0.6798s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
13923/33150 (epoch 21.000), train_loss = 0.85449105, grad/param norm = 1.6326e-01, time/batch = 0.6815s	
13924/33150 (epoch 21.002), train_loss = 1.29792706, grad/param norm = 1.7679e-01, time/batch = 0.6855s	
13925/33150 (epoch 21.003), train_loss = 0.93276099, grad/param norm = 1.7727e-01, time/batch = 0.6758s	
13926/33150 (epoch 21.005), train_loss = 0.88156252, grad/param norm = 1.3862e-01, time/batch = 0.6743s	
13927/33150 (epoch 21.006), train_loss = 0.87437335, grad/param norm = 1.5555e-01, time/batch = 0.6708s	
13928/33150 (epoch 21.008), train_loss = 1.11709982, grad/param norm = 1.6731e-01, time/batch = 0.6740s	
13929/33150 (epoch 21.009), train_loss = 1.00061532, grad/param norm = 1.5031e-01, time/batch = 0.6736s	
13930/33150 (epoch 21.011), train_loss = 1.11229114, grad/param norm = 1.6323e-01, time/batch = 0.6713s	
13931/33150 (epoch 21.012), train_loss = 1.00373675, grad/param norm = 1.7278e-01, time/batch = 0.6790s	
13932/33150 (epoch 21.014), train_loss = 0.94823484, grad/param norm = 1.5391e-01, time/batch = 0.6768s	
13933/33150 (epoch 21.015), train_loss = 0.95136274, grad/param norm = 1.5298e-01, time/batch = 0.6718s	
13934/33150 (epoch 21.017), train_loss = 0.91609258, grad/param norm = 1.5154e-01, time/batch = 0.6721s	
13935/33150 (epoch 21.018), train_loss = 1.02713628, grad/param norm = 1.6999e-01, time/batch = 0.6741s	
13936/33150 (epoch 21.020), train_loss = 1.08315785, grad/param norm = 1.8080e-01, time/batch = 0.6693s	
13937/33150 (epoch 21.021), train_loss = 0.90079453, grad/param norm = 1.5149e-01, time/batch = 0.6847s	
13938/33150 (epoch 21.023), train_loss = 1.18138781, grad/param norm = 1.5466e-01, time/batch = 0.6924s	
13939/33150 (epoch 21.024), train_loss = 1.06763595, grad/param norm = 1.6788e-01, time/batch = 0.6903s	
13940/33150 (epoch 21.026), train_loss = 0.81305930, grad/param norm = 1.3137e-01, time/batch = 0.7009s	
13941/33150 (epoch 21.027), train_loss = 0.81503984, grad/param norm = 1.2763e-01, time/batch = 0.6909s	
13942/33150 (epoch 21.029), train_loss = 0.92680037, grad/param norm = 1.4838e-01, time/batch = 0.6964s	
13943/33150 (epoch 21.030), train_loss = 0.96860511, grad/param norm = 1.3255e-01, time/batch = 0.6643s	
13944/33150 (epoch 21.032), train_loss = 0.90942983, grad/param norm = 1.5208e-01, time/batch = 0.6713s	
13945/33150 (epoch 21.033), train_loss = 0.93174397, grad/param norm = 1.4783e-01, time/batch = 0.6777s	
13946/33150 (epoch 21.035), train_loss = 1.16281276, grad/param norm = 1.9077e-01, time/batch = 0.6855s	
13947/33150 (epoch 21.036), train_loss = 1.05390154, grad/param norm = 1.5809e-01, time/batch = 0.6730s	
13948/33150 (epoch 21.038), train_loss = 1.28127624, grad/param norm = 1.9308e-01, time/batch = 0.6730s	
13949/33150 (epoch 21.039), train_loss = 1.07094372, grad/param norm = 1.4370e-01, time/batch = 0.6703s	
13950/33150 (epoch 21.041), train_loss = 1.02329427, grad/param norm = 1.4755e-01, time/batch = 0.6712s	
13951/33150 (epoch 21.042), train_loss = 0.97567998, grad/param norm = 1.5318e-01, time/batch = 0.6748s	
13952/33150 (epoch 21.044), train_loss = 0.97520637, grad/param norm = 1.3741e-01, time/batch = 0.6823s	
13953/33150 (epoch 21.045), train_loss = 1.02617504, grad/param norm = 1.3821e-01, time/batch = 0.6838s	
13954/33150 (epoch 21.047), train_loss = 0.88876998, grad/param norm = 1.6230e-01, time/batch = 0.6738s	
13955/33150 (epoch 21.048), train_loss = 1.05998125, grad/param norm = 1.6887e-01, time/batch = 0.6711s	
13956/33150 (epoch 21.050), train_loss = 1.01813004, grad/param norm = 1.7206e-01, time/batch = 0.6729s	
13957/33150 (epoch 21.051), train_loss = 1.00718304, grad/param norm = 1.4152e-01, time/batch = 0.6727s	
13958/33150 (epoch 21.053), train_loss = 0.96839693, grad/param norm = 1.4444e-01, time/batch = 0.6709s	
13959/33150 (epoch 21.054), train_loss = 1.12582837, grad/param norm = 1.4714e-01, time/batch = 0.6807s	
13960/33150 (epoch 21.056), train_loss = 0.98864414, grad/param norm = 1.5285e-01, time/batch = 0.6727s	
13961/33150 (epoch 21.057), train_loss = 0.99619599, grad/param norm = 1.5644e-01, time/batch = 0.6723s	
13962/33150 (epoch 21.059), train_loss = 0.92860605, grad/param norm = 1.5408e-01, time/batch = 0.6742s	
13963/33150 (epoch 21.060), train_loss = 0.93436214, grad/param norm = 1.3460e-01, time/batch = 0.6706s	
13964/33150 (epoch 21.062), train_loss = 0.97152218, grad/param norm = 1.5230e-01, time/batch = 0.6697s	
13965/33150 (epoch 21.063), train_loss = 0.92108835, grad/param norm = 1.3760e-01, time/batch = 0.6701s	
13966/33150 (epoch 21.065), train_loss = 0.95145897, grad/param norm = 1.3645e-01, time/batch = 0.6723s	
13967/33150 (epoch 21.066), train_loss = 0.91750944, grad/param norm = 1.4611e-01, time/batch = 0.6738s	
13968/33150 (epoch 21.068), train_loss = 1.02297361, grad/param norm = 1.4399e-01, time/batch = 0.6789s	
13969/33150 (epoch 21.069), train_loss = 1.05873647, grad/param norm = 1.7721e-01, time/batch = 0.6795s	
13970/33150 (epoch 21.071), train_loss = 1.03191723, grad/param norm = 1.4941e-01, time/batch = 0.6708s	
13971/33150 (epoch 21.072), train_loss = 0.97022877, grad/param norm = 1.4348e-01, time/batch = 0.6726s	
13972/33150 (epoch 21.074), train_loss = 0.86752653, grad/param norm = 1.4726e-01, time/batch = 0.6811s	
13973/33150 (epoch 21.075), train_loss = 0.93877147, grad/param norm = 1.5593e-01, time/batch = 0.6818s	
13974/33150 (epoch 21.077), train_loss = 1.00279259, grad/param norm = 1.9864e-01, time/batch = 0.6715s	
13975/33150 (epoch 21.078), train_loss = 1.11044215, grad/param norm = 1.6614e-01, time/batch = 0.6902s	
13976/33150 (epoch 21.080), train_loss = 1.12312678, grad/param norm = 1.5470e-01, time/batch = 0.6871s	
13977/33150 (epoch 21.081), train_loss = 0.89454253, grad/param norm = 1.6311e-01, time/batch = 0.6874s	
13978/33150 (epoch 21.083), train_loss = 0.74932480, grad/param norm = 1.3813e-01, time/batch = 0.6903s	
13979/33150 (epoch 21.084), train_loss = 0.87306927, grad/param norm = 1.7291e-01, time/batch = 0.6899s	
13980/33150 (epoch 21.086), train_loss = 0.95171814, grad/param norm = 1.7834e-01, time/batch = 0.6869s	
13981/33150 (epoch 21.087), train_loss = 0.87288441, grad/param norm = 1.4980e-01, time/batch = 0.6914s	
13982/33150 (epoch 21.089), train_loss = 0.89344552, grad/param norm = 1.4610e-01, time/batch = 0.6847s	
13983/33150 (epoch 21.090), train_loss = 0.95213932, grad/param norm = 1.5400e-01, time/batch = 0.6910s	
13984/33150 (epoch 21.092), train_loss = 0.93228575, grad/param norm = 1.5200e-01, time/batch = 0.6910s	
13985/33150 (epoch 21.094), train_loss = 1.05851149, grad/param norm = 1.6135e-01, time/batch = 0.6735s	
13986/33150 (epoch 21.095), train_loss = 0.87600804, grad/param norm = 1.3344e-01, time/batch = 0.6750s	
13987/33150 (epoch 21.097), train_loss = 0.90450728, grad/param norm = 1.4886e-01, time/batch = 0.6854s	
13988/33150 (epoch 21.098), train_loss = 1.22623043, grad/param norm = 1.7330e-01, time/batch = 0.6781s	
13989/33150 (epoch 21.100), train_loss = 1.16099280, grad/param norm = 1.6370e-01, time/batch = 0.6742s	
13990/33150 (epoch 21.101), train_loss = 0.93621393, grad/param norm = 1.5156e-01, time/batch = 0.6793s	
13991/33150 (epoch 21.103), train_loss = 0.99273614, grad/param norm = 1.4937e-01, time/batch = 0.6789s	
13992/33150 (epoch 21.104), train_loss = 0.90767451, grad/param norm = 1.6068e-01, time/batch = 0.6758s	
13993/33150 (epoch 21.106), train_loss = 1.11281431, grad/param norm = 1.7188e-01, time/batch = 0.6793s	
13994/33150 (epoch 21.107), train_loss = 1.21820099, grad/param norm = 1.6871e-01, time/batch = 0.6731s	
13995/33150 (epoch 21.109), train_loss = 0.96019906, grad/param norm = 1.3206e-01, time/batch = 0.6710s	
13996/33150 (epoch 21.110), train_loss = 1.10431651, grad/param norm = 1.6996e-01, time/batch = 0.6741s	
13997/33150 (epoch 21.112), train_loss = 0.91826875, grad/param norm = 1.4393e-01, time/batch = 0.6719s	
13998/33150 (epoch 21.113), train_loss = 0.97096457, grad/param norm = 1.6031e-01, time/batch = 0.6700s	
13999/33150 (epoch 21.115), train_loss = 1.17184308, grad/param norm = 1.6512e-01, time/batch = 0.6678s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch21.12_1.6041.t7	
14000/33150 (epoch 21.116), train_loss = 0.96848402, grad/param norm = 1.3244e-01, time/batch = 0.6683s	
14001/33150 (epoch 21.118), train_loss = 1.30468892, grad/param norm = 2.0367e-01, time/batch = 0.6796s	
14002/33150 (epoch 21.119), train_loss = 1.08483836, grad/param norm = 1.7681e-01, time/batch = 0.6735s	
14003/33150 (epoch 21.121), train_loss = 0.99435395, grad/param norm = 1.5190e-01, time/batch = 0.6754s	
14004/33150 (epoch 21.122), train_loss = 1.19323714, grad/param norm = 1.9458e-01, time/batch = 0.6770s	
14005/33150 (epoch 21.124), train_loss = 0.82569832, grad/param norm = 1.2387e-01, time/batch = 0.6762s	
14006/33150 (epoch 21.125), train_loss = 1.07214844, grad/param norm = 1.5083e-01, time/batch = 0.6781s	
14007/33150 (epoch 21.127), train_loss = 0.98203637, grad/param norm = 1.4522e-01, time/batch = 0.6837s	
14008/33150 (epoch 21.128), train_loss = 1.02954357, grad/param norm = 1.6048e-01, time/batch = 0.6793s	
14009/33150 (epoch 21.130), train_loss = 1.04415110, grad/param norm = 1.5732e-01, time/batch = 0.6798s	
14010/33150 (epoch 21.131), train_loss = 1.22092598, grad/param norm = 1.6481e-01, time/batch = 0.6817s	
14011/33150 (epoch 21.133), train_loss = 0.92264100, grad/param norm = 1.3428e-01, time/batch = 0.6793s	
14012/33150 (epoch 21.134), train_loss = 1.11205222, grad/param norm = 1.5750e-01, time/batch = 0.6891s	
14013/33150 (epoch 21.136), train_loss = 0.99666466, grad/param norm = 1.5075e-01, time/batch = 0.6726s	
14014/33150 (epoch 21.137), train_loss = 1.10291416, grad/param norm = 1.6318e-01, time/batch = 0.6692s	
14015/33150 (epoch 21.139), train_loss = 1.07220333, grad/param norm = 1.7139e-01, time/batch = 0.6741s	
14016/33150 (epoch 21.140), train_loss = 1.15677727, grad/param norm = 1.6245e-01, time/batch = 0.6899s	
14017/33150 (epoch 21.142), train_loss = 1.08065182, grad/param norm = 1.6637e-01, time/batch = 0.6936s	
14018/33150 (epoch 21.143), train_loss = 1.01899003, grad/param norm = 1.6926e-01, time/batch = 0.6870s	
14019/33150 (epoch 21.145), train_loss = 0.97288623, grad/param norm = 1.6674e-01, time/batch = 0.6836s	
14020/33150 (epoch 21.146), train_loss = 1.11992404, grad/param norm = 1.8854e-01, time/batch = 0.6761s	
14021/33150 (epoch 21.148), train_loss = 1.12284255, grad/param norm = 1.5311e-01, time/batch = 0.6850s	
14022/33150 (epoch 21.149), train_loss = 1.02868174, grad/param norm = 1.7284e-01, time/batch = 0.6924s	
14023/33150 (epoch 21.151), train_loss = 1.16285063, grad/param norm = 1.5647e-01, time/batch = 0.6822s	
14024/33150 (epoch 21.152), train_loss = 0.97848519, grad/param norm = 1.4976e-01, time/batch = 0.6742s	
14025/33150 (epoch 21.154), train_loss = 0.99938178, grad/param norm = 1.6630e-01, time/batch = 0.6817s	
14026/33150 (epoch 21.155), train_loss = 0.86311373, grad/param norm = 1.5107e-01, time/batch = 0.6719s	
14027/33150 (epoch 21.157), train_loss = 0.96726925, grad/param norm = 1.7615e-01, time/batch = 0.6719s	
14028/33150 (epoch 21.158), train_loss = 0.94788140, grad/param norm = 1.4938e-01, time/batch = 0.6748s	
14029/33150 (epoch 21.160), train_loss = 1.06139421, grad/param norm = 1.5818e-01, time/batch = 0.6983s	
14030/33150 (epoch 21.161), train_loss = 0.94738831, grad/param norm = 1.7315e-01, time/batch = 0.6919s	
14031/33150 (epoch 21.163), train_loss = 0.92281932, grad/param norm = 1.5288e-01, time/batch = 0.6921s	
14032/33150 (epoch 21.164), train_loss = 1.05991664, grad/param norm = 1.6557e-01, time/batch = 0.6848s	
14033/33150 (epoch 21.166), train_loss = 0.99517185, grad/param norm = 1.6384e-01, time/batch = 0.6851s	
14034/33150 (epoch 21.167), train_loss = 1.01373046, grad/param norm = 1.5167e-01, time/batch = 0.6760s	
14035/33150 (epoch 21.169), train_loss = 1.05276939, grad/param norm = 2.0761e-01, time/batch = 0.6793s	
14036/33150 (epoch 21.170), train_loss = 0.91553242, grad/param norm = 1.6430e-01, time/batch = 0.6855s	
14037/33150 (epoch 21.172), train_loss = 1.11628059, grad/param norm = 1.6949e-01, time/batch = 0.6809s	
14038/33150 (epoch 21.173), train_loss = 1.06137367, grad/param norm = 1.7409e-01, time/batch = 0.6754s	
14039/33150 (epoch 21.175), train_loss = 0.94600707, grad/param norm = 1.5930e-01, time/batch = 0.6787s	
14040/33150 (epoch 21.176), train_loss = 1.07504639, grad/param norm = 1.7956e-01, time/batch = 0.6702s	
14041/33150 (epoch 21.178), train_loss = 1.19290924, grad/param norm = 1.7740e-01, time/batch = 0.6726s	
14042/33150 (epoch 21.179), train_loss = 1.06462120, grad/param norm = 1.4158e-01, time/batch = 0.6702s	
14043/33150 (epoch 21.181), train_loss = 1.00752025, grad/param norm = 1.7822e-01, time/batch = 0.6742s	
14044/33150 (epoch 21.183), train_loss = 0.99797450, grad/param norm = 1.6904e-01, time/batch = 0.6728s	
14045/33150 (epoch 21.184), train_loss = 1.21718534, grad/param norm = 1.6153e-01, time/batch = 0.6725s	
14046/33150 (epoch 21.186), train_loss = 1.13220516, grad/param norm = 1.5678e-01, time/batch = 0.6779s	
14047/33150 (epoch 21.187), train_loss = 1.05801570, grad/param norm = 1.7275e-01, time/batch = 0.6759s	
14048/33150 (epoch 21.189), train_loss = 0.80506602, grad/param norm = 1.4607e-01, time/batch = 0.6730s	
14049/33150 (epoch 21.190), train_loss = 0.92168634, grad/param norm = 1.9614e-01, time/batch = 0.6764s	
14050/33150 (epoch 21.192), train_loss = 1.02578129, grad/param norm = 1.7952e-01, time/batch = 0.6811s	
14051/33150 (epoch 21.193), train_loss = 1.09712357, grad/param norm = 1.7125e-01, time/batch = 0.6946s	
14052/33150 (epoch 21.195), train_loss = 1.25906801, grad/param norm = 2.3319e-01, time/batch = 0.6770s	
14053/33150 (epoch 21.196), train_loss = 1.12243964, grad/param norm = 1.5075e-01, time/batch = 0.6731s	
14054/33150 (epoch 21.198), train_loss = 0.89334426, grad/param norm = 1.6092e-01, time/batch = 0.6727s	
14055/33150 (epoch 21.199), train_loss = 1.12919706, grad/param norm = 2.1737e-01, time/batch = 0.6708s	
14056/33150 (epoch 21.201), train_loss = 0.92958194, grad/param norm = 1.3341e-01, time/batch = 0.6729s	
14057/33150 (epoch 21.202), train_loss = 0.80618396, grad/param norm = 1.4279e-01, time/batch = 0.6700s	
14058/33150 (epoch 21.204), train_loss = 1.03948539, grad/param norm = 1.5935e-01, time/batch = 0.6744s	
14059/33150 (epoch 21.205), train_loss = 1.09740028, grad/param norm = 1.6355e-01, time/batch = 0.6747s	
14060/33150 (epoch 21.207), train_loss = 1.06442682, grad/param norm = 1.5861e-01, time/batch = 0.6730s	
14061/33150 (epoch 21.208), train_loss = 1.08032997, grad/param norm = 1.6881e-01, time/batch = 0.6729s	
14062/33150 (epoch 21.210), train_loss = 0.93789708, grad/param norm = 1.3460e-01, time/batch = 0.6766s	
14063/33150 (epoch 21.211), train_loss = 1.03597662, grad/param norm = 1.6402e-01, time/batch = 0.6689s	
14064/33150 (epoch 21.213), train_loss = 1.06171971, grad/param norm = 1.4837e-01, time/batch = 0.6739s	
14065/33150 (epoch 21.214), train_loss = 1.00387560, grad/param norm = 1.4475e-01, time/batch = 0.6771s	
14066/33150 (epoch 21.216), train_loss = 0.94211968, grad/param norm = 1.6923e-01, time/batch = 0.6738s	
14067/33150 (epoch 21.217), train_loss = 0.98112800, grad/param norm = 1.4976e-01, time/batch = 0.6757s	
14068/33150 (epoch 21.219), train_loss = 0.90665539, grad/param norm = 1.4383e-01, time/batch = 0.6743s	
14069/33150 (epoch 21.220), train_loss = 0.93563101, grad/param norm = 1.3038e-01, time/batch = 0.6686s	
14070/33150 (epoch 21.222), train_loss = 1.12035828, grad/param norm = 1.5723e-01, time/batch = 0.6734s	
14071/33150 (epoch 21.223), train_loss = 1.02184453, grad/param norm = 1.7852e-01, time/batch = 0.6716s	
14072/33150 (epoch 21.225), train_loss = 1.15275059, grad/param norm = 1.6452e-01, time/batch = 0.6719s	
14073/33150 (epoch 21.226), train_loss = 0.99452309, grad/param norm = 1.4181e-01, time/batch = 0.6745s	
14074/33150 (epoch 21.228), train_loss = 0.98693316, grad/param norm = 1.5500e-01, time/batch = 0.6757s	
14075/33150 (epoch 21.229), train_loss = 1.01100800, grad/param norm = 1.5015e-01, time/batch = 0.6749s	
14076/33150 (epoch 21.231), train_loss = 1.14409380, grad/param norm = 1.7397e-01, time/batch = 0.6739s	
14077/33150 (epoch 21.232), train_loss = 1.03403406, grad/param norm = 1.7054e-01, time/batch = 0.6733s	
14078/33150 (epoch 21.234), train_loss = 1.01041982, grad/param norm = 1.5809e-01, time/batch = 0.6732s	
14079/33150 (epoch 21.235), train_loss = 1.05873175, grad/param norm = 1.8054e-01, time/batch = 0.6730s	
14080/33150 (epoch 21.237), train_loss = 1.03498424, grad/param norm = 1.9056e-01, time/batch = 0.6751s	
14081/33150 (epoch 21.238), train_loss = 1.05454147, grad/param norm = 1.7257e-01, time/batch = 0.6819s	
14082/33150 (epoch 21.240), train_loss = 1.06217133, grad/param norm = 1.6140e-01, time/batch = 0.6772s	
14083/33150 (epoch 21.241), train_loss = 1.12863047, grad/param norm = 1.7526e-01, time/batch = 0.6789s	
14084/33150 (epoch 21.243), train_loss = 1.10343671, grad/param norm = 1.8082e-01, time/batch = 0.6815s	
14085/33150 (epoch 21.244), train_loss = 1.01658629, grad/param norm = 1.5233e-01, time/batch = 0.6820s	
14086/33150 (epoch 21.246), train_loss = 1.07670911, grad/param norm = 1.4856e-01, time/batch = 0.6834s	
14087/33150 (epoch 21.247), train_loss = 0.96863203, grad/param norm = 1.5140e-01, time/batch = 0.6801s	
14088/33150 (epoch 21.249), train_loss = 1.13270510, grad/param norm = 1.4946e-01, time/batch = 0.6756s	
14089/33150 (epoch 21.250), train_loss = 1.07945754, grad/param norm = 1.3561e-01, time/batch = 0.6778s	
14090/33150 (epoch 21.252), train_loss = 1.07001072, grad/param norm = 1.3724e-01, time/batch = 0.6740s	
14091/33150 (epoch 21.253), train_loss = 1.00875819, grad/param norm = 1.5432e-01, time/batch = 0.6769s	
14092/33150 (epoch 21.255), train_loss = 0.99103672, grad/param norm = 1.4298e-01, time/batch = 0.6785s	
14093/33150 (epoch 21.256), train_loss = 1.07998266, grad/param norm = 1.3907e-01, time/batch = 0.6774s	
14094/33150 (epoch 21.258), train_loss = 0.96833374, grad/param norm = 1.6917e-01, time/batch = 0.6776s	
14095/33150 (epoch 21.259), train_loss = 0.83624209, grad/param norm = 1.5890e-01, time/batch = 0.6766s	
14096/33150 (epoch 21.261), train_loss = 0.90365359, grad/param norm = 1.3918e-01, time/batch = 0.6760s	
14097/33150 (epoch 21.262), train_loss = 1.09179976, grad/param norm = 1.6000e-01, time/batch = 0.6781s	
14098/33150 (epoch 21.264), train_loss = 0.79392154, grad/param norm = 1.3183e-01, time/batch = 0.6767s	
14099/33150 (epoch 21.265), train_loss = 1.05432267, grad/param norm = 1.6040e-01, time/batch = 0.6816s	
14100/33150 (epoch 21.267), train_loss = 1.08644892, grad/param norm = 1.9452e-01, time/batch = 0.6871s	
14101/33150 (epoch 21.268), train_loss = 1.11523620, grad/param norm = 1.5358e-01, time/batch = 0.6748s	
14102/33150 (epoch 21.270), train_loss = 1.19678649, grad/param norm = 1.6903e-01, time/batch = 0.6737s	
14103/33150 (epoch 21.271), train_loss = 1.15568016, grad/param norm = 1.9311e-01, time/batch = 0.6753s	
14104/33150 (epoch 21.273), train_loss = 1.13293088, grad/param norm = 1.5468e-01, time/batch = 0.6895s	
14105/33150 (epoch 21.275), train_loss = 1.15853634, grad/param norm = 1.6574e-01, time/batch = 0.6938s	
14106/33150 (epoch 21.276), train_loss = 1.01210599, grad/param norm = 1.5614e-01, time/batch = 0.6808s	
14107/33150 (epoch 21.278), train_loss = 1.10225382, grad/param norm = 1.5261e-01, time/batch = 0.6704s	
14108/33150 (epoch 21.279), train_loss = 1.06696933, grad/param norm = 1.5224e-01, time/batch = 0.6713s	
14109/33150 (epoch 21.281), train_loss = 1.04443235, grad/param norm = 1.5384e-01, time/batch = 0.6813s	
14110/33150 (epoch 21.282), train_loss = 1.02680545, grad/param norm = 1.3325e-01, time/batch = 0.6835s	
14111/33150 (epoch 21.284), train_loss = 0.95813310, grad/param norm = 1.5259e-01, time/batch = 0.6730s	
14112/33150 (epoch 21.285), train_loss = 1.04580929, grad/param norm = 1.4569e-01, time/batch = 0.6756s	
14113/33150 (epoch 21.287), train_loss = 0.92191445, grad/param norm = 1.4165e-01, time/batch = 0.6706s	
14114/33150 (epoch 21.288), train_loss = 1.13521247, grad/param norm = 1.6316e-01, time/batch = 0.6852s	
14115/33150 (epoch 21.290), train_loss = 0.87185434, grad/param norm = 1.5314e-01, time/batch = 0.6779s	
14116/33150 (epoch 21.291), train_loss = 0.86035964, grad/param norm = 1.5315e-01, time/batch = 0.6686s	
14117/33150 (epoch 21.293), train_loss = 1.06110298, grad/param norm = 1.5297e-01, time/batch = 0.6670s	
14118/33150 (epoch 21.294), train_loss = 0.78250406, grad/param norm = 1.5118e-01, time/batch = 0.6716s	
14119/33150 (epoch 21.296), train_loss = 0.99282430, grad/param norm = 1.4933e-01, time/batch = 0.6759s	
14120/33150 (epoch 21.297), train_loss = 0.95117550, grad/param norm = 1.4216e-01, time/batch = 0.6714s	
14121/33150 (epoch 21.299), train_loss = 0.93202690, grad/param norm = 1.5761e-01, time/batch = 0.6744s	
14122/33150 (epoch 21.300), train_loss = 0.94808765, grad/param norm = 1.3003e-01, time/batch = 0.6987s	
14123/33150 (epoch 21.302), train_loss = 0.97385811, grad/param norm = 1.4881e-01, time/batch = 0.6923s	
14124/33150 (epoch 21.303), train_loss = 0.98157937, grad/param norm = 1.5427e-01, time/batch = 0.6759s	
14125/33150 (epoch 21.305), train_loss = 1.07053065, grad/param norm = 1.3900e-01, time/batch = 0.6725s	
14126/33150 (epoch 21.306), train_loss = 1.07721909, grad/param norm = 1.7009e-01, time/batch = 0.6877s	
14127/33150 (epoch 21.308), train_loss = 1.24315480, grad/param norm = 1.6713e-01, time/batch = 0.6655s	
14128/33150 (epoch 21.309), train_loss = 0.84060746, grad/param norm = 1.2521e-01, time/batch = 0.6756s	
14129/33150 (epoch 21.311), train_loss = 0.97675549, grad/param norm = 1.5700e-01, time/batch = 0.6851s	
14130/33150 (epoch 21.312), train_loss = 0.81531256, grad/param norm = 1.4457e-01, time/batch = 0.6707s	
14131/33150 (epoch 21.314), train_loss = 0.96553091, grad/param norm = 1.5675e-01, time/batch = 0.6733s	
14132/33150 (epoch 21.315), train_loss = 1.03730164, grad/param norm = 1.4632e-01, time/batch = 0.6694s	
14133/33150 (epoch 21.317), train_loss = 0.80312390, grad/param norm = 1.3028e-01, time/batch = 0.6700s	
14134/33150 (epoch 21.318), train_loss = 0.91171517, grad/param norm = 1.3975e-01, time/batch = 0.6720s	
14135/33150 (epoch 21.320), train_loss = 0.86808999, grad/param norm = 1.3900e-01, time/batch = 0.6682s	
14136/33150 (epoch 21.321), train_loss = 0.96242949, grad/param norm = 1.3742e-01, time/batch = 0.6678s	
14137/33150 (epoch 21.323), train_loss = 0.99431475, grad/param norm = 1.4854e-01, time/batch = 0.6691s	
14138/33150 (epoch 21.324), train_loss = 1.09103927, grad/param norm = 1.8570e-01, time/batch = 0.6687s	
14139/33150 (epoch 21.326), train_loss = 1.03951795, grad/param norm = 1.4770e-01, time/batch = 0.6682s	
14140/33150 (epoch 21.327), train_loss = 1.12597021, grad/param norm = 1.4674e-01, time/batch = 0.6722s	
14141/33150 (epoch 21.329), train_loss = 1.07187667, grad/param norm = 1.4318e-01, time/batch = 0.6713s	
14142/33150 (epoch 21.330), train_loss = 1.00131122, grad/param norm = 1.6021e-01, time/batch = 0.6679s	
14143/33150 (epoch 21.332), train_loss = 0.99796692, grad/param norm = 1.3031e-01, time/batch = 0.6780s	
14144/33150 (epoch 21.333), train_loss = 1.04419049, grad/param norm = 1.3885e-01, time/batch = 0.6852s	
14145/33150 (epoch 21.335), train_loss = 0.94053971, grad/param norm = 1.4844e-01, time/batch = 0.6699s	
14146/33150 (epoch 21.336), train_loss = 0.92934539, grad/param norm = 1.5877e-01, time/batch = 0.6725s	
14147/33150 (epoch 21.338), train_loss = 0.82703061, grad/param norm = 1.4252e-01, time/batch = 0.6702s	
14148/33150 (epoch 21.339), train_loss = 1.09422585, grad/param norm = 1.6582e-01, time/batch = 0.6732s	
14149/33150 (epoch 21.341), train_loss = 1.05767857, grad/param norm = 1.6977e-01, time/batch = 0.6738s	
14150/33150 (epoch 21.342), train_loss = 0.90220493, grad/param norm = 1.4205e-01, time/batch = 0.6726s	
14151/33150 (epoch 21.344), train_loss = 1.02918409, grad/param norm = 1.6270e-01, time/batch = 0.6741s	
14152/33150 (epoch 21.345), train_loss = 0.96416072, grad/param norm = 1.4895e-01, time/batch = 0.6741s	
14153/33150 (epoch 21.347), train_loss = 0.80354051, grad/param norm = 1.3750e-01, time/batch = 0.6734s	
14154/33150 (epoch 21.348), train_loss = 1.01439977, grad/param norm = 1.4286e-01, time/batch = 0.6742s	
14155/33150 (epoch 21.350), train_loss = 0.91596828, grad/param norm = 1.6072e-01, time/batch = 0.6748s	
14156/33150 (epoch 21.351), train_loss = 1.07562926, grad/param norm = 1.6984e-01, time/batch = 0.6717s	
14157/33150 (epoch 21.353), train_loss = 1.05550977, grad/param norm = 1.7188e-01, time/batch = 0.6714s	
14158/33150 (epoch 21.354), train_loss = 1.26201113, grad/param norm = 1.6787e-01, time/batch = 0.6805s	
14159/33150 (epoch 21.356), train_loss = 1.12448895, grad/param norm = 1.7028e-01, time/batch = 0.6775s	
14160/33150 (epoch 21.357), train_loss = 1.08036906, grad/param norm = 1.8509e-01, time/batch = 0.6728s	
14161/33150 (epoch 21.359), train_loss = 1.08802030, grad/param norm = 1.7030e-01, time/batch = 0.6733s	
14162/33150 (epoch 21.360), train_loss = 1.07773655, grad/param norm = 1.9510e-01, time/batch = 0.6755s	
14163/33150 (epoch 21.362), train_loss = 1.11676485, grad/param norm = 1.5702e-01, time/batch = 0.6733s	
14164/33150 (epoch 21.363), train_loss = 1.00521916, grad/param norm = 1.4240e-01, time/batch = 0.6712s	
14165/33150 (epoch 21.365), train_loss = 1.00529581, grad/param norm = 1.4426e-01, time/batch = 0.6705s	
14166/33150 (epoch 21.367), train_loss = 0.95446830, grad/param norm = 1.4859e-01, time/batch = 0.6707s	
14167/33150 (epoch 21.368), train_loss = 0.99969003, grad/param norm = 1.5590e-01, time/batch = 0.6741s	
14168/33150 (epoch 21.370), train_loss = 1.02391178, grad/param norm = 1.6951e-01, time/batch = 0.6743s	
14169/33150 (epoch 21.371), train_loss = 0.91072151, grad/param norm = 1.4336e-01, time/batch = 0.6716s	
14170/33150 (epoch 21.373), train_loss = 1.08278017, grad/param norm = 1.8477e-01, time/batch = 0.6712s	
14171/33150 (epoch 21.374), train_loss = 0.97521696, grad/param norm = 1.4663e-01, time/batch = 0.6765s	
14172/33150 (epoch 21.376), train_loss = 1.12784231, grad/param norm = 1.6108e-01, time/batch = 0.6722s	
14173/33150 (epoch 21.377), train_loss = 0.95866865, grad/param norm = 1.5298e-01, time/batch = 0.6754s	
14174/33150 (epoch 21.379), train_loss = 1.07439065, grad/param norm = 1.5767e-01, time/batch = 0.6725s	
14175/33150 (epoch 21.380), train_loss = 1.09015929, grad/param norm = 1.5027e-01, time/batch = 0.6680s	
14176/33150 (epoch 21.382), train_loss = 0.95745693, grad/param norm = 1.4775e-01, time/batch = 0.6724s	
14177/33150 (epoch 21.383), train_loss = 0.94774592, grad/param norm = 1.5262e-01, time/batch = 0.6696s	
14178/33150 (epoch 21.385), train_loss = 0.97752894, grad/param norm = 1.5500e-01, time/batch = 0.6708s	
14179/33150 (epoch 21.386), train_loss = 0.86605042, grad/param norm = 1.3109e-01, time/batch = 0.6750s	
14180/33150 (epoch 21.388), train_loss = 0.95352056, grad/param norm = 1.3807e-01, time/batch = 0.6813s	
14181/33150 (epoch 21.389), train_loss = 0.93081046, grad/param norm = 1.4263e-01, time/batch = 0.6730s	
14182/33150 (epoch 21.391), train_loss = 1.17128273, grad/param norm = 1.5824e-01, time/batch = 0.6788s	
14183/33150 (epoch 21.392), train_loss = 0.96463631, grad/param norm = 1.4369e-01, time/batch = 0.6762s	
14184/33150 (epoch 21.394), train_loss = 0.85317119, grad/param norm = 1.2564e-01, time/batch = 0.6732s	
14185/33150 (epoch 21.395), train_loss = 0.85902798, grad/param norm = 1.4185e-01, time/batch = 0.6756s	
14186/33150 (epoch 21.397), train_loss = 0.69407070, grad/param norm = 1.2763e-01, time/batch = 0.6725s	
14187/33150 (epoch 21.398), train_loss = 1.02270428, grad/param norm = 1.7449e-01, time/batch = 0.6696s	
14188/33150 (epoch 21.400), train_loss = 0.94915048, grad/param norm = 1.3765e-01, time/batch = 0.6850s	
14189/33150 (epoch 21.401), train_loss = 0.82892660, grad/param norm = 1.2464e-01, time/batch = 0.6767s	
14190/33150 (epoch 21.403), train_loss = 0.86784884, grad/param norm = 1.3535e-01, time/batch = 0.6697s	
14191/33150 (epoch 21.404), train_loss = 0.99437630, grad/param norm = 1.5583e-01, time/batch = 0.6714s	
14192/33150 (epoch 21.406), train_loss = 0.92782478, grad/param norm = 1.2214e-01, time/batch = 0.6794s	
14193/33150 (epoch 21.407), train_loss = 0.86588973, grad/param norm = 1.3933e-01, time/batch = 0.6921s	
14194/33150 (epoch 21.409), train_loss = 0.80932962, grad/param norm = 1.3693e-01, time/batch = 0.6931s	
14195/33150 (epoch 21.410), train_loss = 1.00854551, grad/param norm = 1.5277e-01, time/batch = 0.6806s	
14196/33150 (epoch 21.412), train_loss = 1.05769320, grad/param norm = 1.5578e-01, time/batch = 0.7036s	
14197/33150 (epoch 21.413), train_loss = 0.92899635, grad/param norm = 1.4796e-01, time/batch = 0.6855s	
14198/33150 (epoch 21.415), train_loss = 1.04404790, grad/param norm = 1.4420e-01, time/batch = 0.6727s	
14199/33150 (epoch 21.416), train_loss = 0.91513421, grad/param norm = 1.4091e-01, time/batch = 0.6707s	
14200/33150 (epoch 21.418), train_loss = 1.10892344, grad/param norm = 1.8450e-01, time/batch = 0.6920s	
14201/33150 (epoch 21.419), train_loss = 0.93518451, grad/param norm = 1.4230e-01, time/batch = 0.6778s	
14202/33150 (epoch 21.421), train_loss = 0.99176536, grad/param norm = 1.6130e-01, time/batch = 0.6893s	
14203/33150 (epoch 21.422), train_loss = 0.94267428, grad/param norm = 1.4246e-01, time/batch = 0.6764s	
14204/33150 (epoch 21.424), train_loss = 0.94539423, grad/param norm = 1.5835e-01, time/batch = 0.6699s	
14205/33150 (epoch 21.425), train_loss = 1.05043441, grad/param norm = 1.5583e-01, time/batch = 0.6697s	
14206/33150 (epoch 21.427), train_loss = 0.97564993, grad/param norm = 1.3379e-01, time/batch = 0.6722s	
14207/33150 (epoch 21.428), train_loss = 0.98766867, grad/param norm = 1.5859e-01, time/batch = 0.6826s	
14208/33150 (epoch 21.430), train_loss = 0.99236132, grad/param norm = 1.5294e-01, time/batch = 0.6762s	
14209/33150 (epoch 21.431), train_loss = 1.06279628, grad/param norm = 1.7601e-01, time/batch = 0.6742s	
14210/33150 (epoch 21.433), train_loss = 0.98969444, grad/param norm = 1.4232e-01, time/batch = 0.6698s	
14211/33150 (epoch 21.434), train_loss = 0.87641557, grad/param norm = 1.4597e-01, time/batch = 0.6753s	
14212/33150 (epoch 21.436), train_loss = 0.95759731, grad/param norm = 1.4981e-01, time/batch = 0.6894s	
14213/33150 (epoch 21.437), train_loss = 1.01742548, grad/param norm = 1.8528e-01, time/batch = 0.6786s	
14214/33150 (epoch 21.439), train_loss = 1.13879757, grad/param norm = 1.5913e-01, time/batch = 0.6728s	
14215/33150 (epoch 21.440), train_loss = 1.08613290, grad/param norm = 1.6302e-01, time/batch = 0.6778s	
14216/33150 (epoch 21.442), train_loss = 0.87652866, grad/param norm = 1.4523e-01, time/batch = 0.6728s	
14217/33150 (epoch 21.443), train_loss = 1.06309417, grad/param norm = 1.5074e-01, time/batch = 0.6821s	
14218/33150 (epoch 21.445), train_loss = 1.01557777, grad/param norm = 1.6722e-01, time/batch = 0.6799s	
14219/33150 (epoch 21.446), train_loss = 1.02322984, grad/param norm = 1.8919e-01, time/batch = 0.6725s	
14220/33150 (epoch 21.448), train_loss = 1.10853578, grad/param norm = 1.6890e-01, time/batch = 0.6689s	
14221/33150 (epoch 21.449), train_loss = 1.02886019, grad/param norm = 1.3686e-01, time/batch = 0.6733s	
14222/33150 (epoch 21.451), train_loss = 1.04683216, grad/param norm = 1.8884e-01, time/batch = 0.6765s	
14223/33150 (epoch 21.452), train_loss = 1.22380720, grad/param norm = 1.6256e-01, time/batch = 0.6698s	
14224/33150 (epoch 21.454), train_loss = 1.01881572, grad/param norm = 1.6314e-01, time/batch = 0.6733s	
14225/33150 (epoch 21.456), train_loss = 0.89285638, grad/param norm = 1.3643e-01, time/batch = 0.6733s	
14226/33150 (epoch 21.457), train_loss = 1.01160562, grad/param norm = 1.5026e-01, time/batch = 0.6735s	
14227/33150 (epoch 21.459), train_loss = 1.14509339, grad/param norm = 2.2631e-01, time/batch = 0.6697s	
14228/33150 (epoch 21.460), train_loss = 1.04347992, grad/param norm = 1.3167e-01, time/batch = 0.6760s	
14229/33150 (epoch 21.462), train_loss = 1.08655329, grad/param norm = 1.8653e-01, time/batch = 0.6966s	
14230/33150 (epoch 21.463), train_loss = 1.25125248, grad/param norm = 1.8900e-01, time/batch = 0.6918s	
14231/33150 (epoch 21.465), train_loss = 0.98586338, grad/param norm = 1.4676e-01, time/batch = 0.6812s	
14232/33150 (epoch 21.466), train_loss = 0.92279157, grad/param norm = 1.3788e-01, time/batch = 0.6859s	
14233/33150 (epoch 21.468), train_loss = 1.25229260, grad/param norm = 1.6268e-01, time/batch = 0.6867s	
14234/33150 (epoch 21.469), train_loss = 1.00210578, grad/param norm = 1.6137e-01, time/batch = 0.6664s	
14235/33150 (epoch 21.471), train_loss = 0.94042010, grad/param norm = 1.3820e-01, time/batch = 0.6678s	
14236/33150 (epoch 21.472), train_loss = 1.02087589, grad/param norm = 1.5029e-01, time/batch = 0.6693s	
14237/33150 (epoch 21.474), train_loss = 1.10425813, grad/param norm = 1.7838e-01, time/batch = 0.6931s	
14238/33150 (epoch 21.475), train_loss = 1.27899987, grad/param norm = 1.7424e-01, time/batch = 0.6930s	
14239/33150 (epoch 21.477), train_loss = 1.12774216, grad/param norm = 1.8545e-01, time/batch = 0.6928s	
14240/33150 (epoch 21.478), train_loss = 1.08631269, grad/param norm = 1.4813e-01, time/batch = 0.6934s	
14241/33150 (epoch 21.480), train_loss = 0.95103595, grad/param norm = 1.5206e-01, time/batch = 0.6959s	
14242/33150 (epoch 21.481), train_loss = 0.86262750, grad/param norm = 1.4885e-01, time/batch = 0.6952s	
14243/33150 (epoch 21.483), train_loss = 0.96257525, grad/param norm = 1.5184e-01, time/batch = 0.6878s	
14244/33150 (epoch 21.484), train_loss = 0.94666668, grad/param norm = 1.6504e-01, time/batch = 0.6727s	
14245/33150 (epoch 21.486), train_loss = 0.96150105, grad/param norm = 1.5338e-01, time/batch = 0.6708s	
14246/33150 (epoch 21.487), train_loss = 1.03003719, grad/param norm = 1.6986e-01, time/batch = 0.6777s	
14247/33150 (epoch 21.489), train_loss = 0.99478209, grad/param norm = 1.5443e-01, time/batch = 0.6837s	
14248/33150 (epoch 21.490), train_loss = 0.84421430, grad/param norm = 1.5098e-01, time/batch = 0.6695s	
14249/33150 (epoch 21.492), train_loss = 0.96384047, grad/param norm = 1.5952e-01, time/batch = 0.6729s	
14250/33150 (epoch 21.493), train_loss = 1.08807449, grad/param norm = 1.6163e-01, time/batch = 0.6742s	
14251/33150 (epoch 21.495), train_loss = 1.09437004, grad/param norm = 1.5026e-01, time/batch = 0.6748s	
14252/33150 (epoch 21.496), train_loss = 0.98278314, grad/param norm = 1.5962e-01, time/batch = 0.6766s	
14253/33150 (epoch 21.498), train_loss = 1.13259051, grad/param norm = 1.8231e-01, time/batch = 0.6786s	
14254/33150 (epoch 21.499), train_loss = 1.11457562, grad/param norm = 1.5493e-01, time/batch = 0.6763s	
14255/33150 (epoch 21.501), train_loss = 1.05423741, grad/param norm = 1.5356e-01, time/batch = 0.6778s	
14256/33150 (epoch 21.502), train_loss = 1.14910097, grad/param norm = 1.8288e-01, time/batch = 0.6729s	
14257/33150 (epoch 21.504), train_loss = 1.07916995, grad/param norm = 1.6135e-01, time/batch = 0.6731s	
14258/33150 (epoch 21.505), train_loss = 1.18795486, grad/param norm = 1.8075e-01, time/batch = 0.6850s	
14259/33150 (epoch 21.507), train_loss = 0.98823413, grad/param norm = 1.4709e-01, time/batch = 0.6735s	
14260/33150 (epoch 21.508), train_loss = 0.97005828, grad/param norm = 1.5247e-01, time/batch = 0.6709s	
14261/33150 (epoch 21.510), train_loss = 1.05432688, grad/param norm = 1.5391e-01, time/batch = 0.6839s	
14262/33150 (epoch 21.511), train_loss = 1.13810704, grad/param norm = 1.6317e-01, time/batch = 0.6716s	
14263/33150 (epoch 21.513), train_loss = 1.01951057, grad/param norm = 1.5219e-01, time/batch = 0.6701s	
14264/33150 (epoch 21.514), train_loss = 0.84949267, grad/param norm = 1.4812e-01, time/batch = 0.6672s	
14265/33150 (epoch 21.516), train_loss = 1.06762493, grad/param norm = 1.8946e-01, time/batch = 0.6751s	
14266/33150 (epoch 21.517), train_loss = 1.12681548, grad/param norm = 1.5789e-01, time/batch = 0.6851s	
14267/33150 (epoch 21.519), train_loss = 0.93960196, grad/param norm = 1.4185e-01, time/batch = 0.6683s	
14268/33150 (epoch 21.520), train_loss = 1.02380147, grad/param norm = 1.4230e-01, time/batch = 0.6719s	
14269/33150 (epoch 21.522), train_loss = 1.15032270, grad/param norm = 1.8741e-01, time/batch = 0.6694s	
14270/33150 (epoch 21.523), train_loss = 0.94237481, grad/param norm = 1.5680e-01, time/batch = 0.6703s	
14271/33150 (epoch 21.525), train_loss = 1.08978518, grad/param norm = 1.6814e-01, time/batch = 0.6702s	
14272/33150 (epoch 21.526), train_loss = 0.94403000, grad/param norm = 1.5990e-01, time/batch = 0.6723s	
14273/33150 (epoch 21.528), train_loss = 1.05634785, grad/param norm = 1.5865e-01, time/batch = 0.6890s	
14274/33150 (epoch 21.529), train_loss = 0.98829850, grad/param norm = 1.5087e-01, time/batch = 0.6768s	
14275/33150 (epoch 21.531), train_loss = 0.85348127, grad/param norm = 1.6939e-01, time/batch = 0.6718s	
14276/33150 (epoch 21.532), train_loss = 1.02570297, grad/param norm = 1.5177e-01, time/batch = 0.6696s	
14277/33150 (epoch 21.534), train_loss = 0.97489870, grad/param norm = 1.2946e-01, time/batch = 0.6711s	
14278/33150 (epoch 21.535), train_loss = 0.94352143, grad/param norm = 2.0334e-01, time/batch = 0.6710s	
14279/33150 (epoch 21.537), train_loss = 1.09292031, grad/param norm = 1.7317e-01, time/batch = 0.6757s	
14280/33150 (epoch 21.538), train_loss = 0.95578202, grad/param norm = 1.4564e-01, time/batch = 0.6844s	
14281/33150 (epoch 21.540), train_loss = 0.87255488, grad/param norm = 1.4418e-01, time/batch = 0.6897s	
14282/33150 (epoch 21.541), train_loss = 1.10197131, grad/param norm = 1.5480e-01, time/batch = 0.6920s	
14283/33150 (epoch 21.543), train_loss = 1.01680792, grad/param norm = 1.4660e-01, time/batch = 0.6904s	
14284/33150 (epoch 21.544), train_loss = 1.07281828, grad/param norm = 1.5618e-01, time/batch = 0.6858s	
14285/33150 (epoch 21.546), train_loss = 1.05673310, grad/param norm = 1.7044e-01, time/batch = 0.6718s	
14286/33150 (epoch 21.548), train_loss = 1.01220248, grad/param norm = 1.7184e-01, time/batch = 0.6796s	
14287/33150 (epoch 21.549), train_loss = 0.96386122, grad/param norm = 1.6403e-01, time/batch = 0.6844s	
14288/33150 (epoch 21.551), train_loss = 0.91436025, grad/param norm = 1.3945e-01, time/batch = 0.6740s	
14289/33150 (epoch 21.552), train_loss = 0.80490676, grad/param norm = 1.3002e-01, time/batch = 0.6775s	
14290/33150 (epoch 21.554), train_loss = 1.08303726, grad/param norm = 1.5013e-01, time/batch = 0.6747s	
14291/33150 (epoch 21.555), train_loss = 1.13146963, grad/param norm = 1.6368e-01, time/batch = 0.6746s	
14292/33150 (epoch 21.557), train_loss = 0.81882593, grad/param norm = 1.4747e-01, time/batch = 0.6734s	
14293/33150 (epoch 21.558), train_loss = 1.09104886, grad/param norm = 2.0567e-01, time/batch = 0.6778s	
14294/33150 (epoch 21.560), train_loss = 0.98628493, grad/param norm = 1.6288e-01, time/batch = 0.6726s	
14295/33150 (epoch 21.561), train_loss = 0.85978289, grad/param norm = 1.4937e-01, time/batch = 0.6854s	
14296/33150 (epoch 21.563), train_loss = 1.08860331, grad/param norm = 2.2047e-01, time/batch = 0.6847s	
14297/33150 (epoch 21.564), train_loss = 1.15909968, grad/param norm = 1.6343e-01, time/batch = 0.6730s	
14298/33150 (epoch 21.566), train_loss = 0.97692213, grad/param norm = 1.5228e-01, time/batch = 0.6763s	
14299/33150 (epoch 21.567), train_loss = 0.91618278, grad/param norm = 1.4973e-01, time/batch = 0.6779s	
14300/33150 (epoch 21.569), train_loss = 1.05118764, grad/param norm = 1.6525e-01, time/batch = 0.6755s	
14301/33150 (epoch 21.570), train_loss = 1.08633340, grad/param norm = 1.6167e-01, time/batch = 0.6782s	
14302/33150 (epoch 21.572), train_loss = 0.92824796, grad/param norm = 1.7248e-01, time/batch = 0.6825s	
14303/33150 (epoch 21.573), train_loss = 0.81905401, grad/param norm = 1.3029e-01, time/batch = 0.6782s	
14304/33150 (epoch 21.575), train_loss = 1.01033238, grad/param norm = 1.6674e-01, time/batch = 0.6716s	
14305/33150 (epoch 21.576), train_loss = 0.85991338, grad/param norm = 1.2536e-01, time/batch = 0.6729s	
14306/33150 (epoch 21.578), train_loss = 0.93848500, grad/param norm = 1.5685e-01, time/batch = 0.6709s	
14307/33150 (epoch 21.579), train_loss = 0.85283200, grad/param norm = 1.4749e-01, time/batch = 0.6711s	
14308/33150 (epoch 21.581), train_loss = 0.92009344, grad/param norm = 1.5185e-01, time/batch = 0.6711s	
14309/33150 (epoch 21.582), train_loss = 1.11751074, grad/param norm = 1.4651e-01, time/batch = 0.6721s	
14310/33150 (epoch 21.584), train_loss = 1.07945771, grad/param norm = 1.5445e-01, time/batch = 0.6751s	
14311/33150 (epoch 21.585), train_loss = 1.01381322, grad/param norm = 1.5477e-01, time/batch = 0.6753s	
14312/33150 (epoch 21.587), train_loss = 1.03294365, grad/param norm = 1.5993e-01, time/batch = 0.6729s	
14313/33150 (epoch 21.588), train_loss = 0.90903780, grad/param norm = 1.5737e-01, time/batch = 0.6798s	
14314/33150 (epoch 21.590), train_loss = 1.02240527, grad/param norm = 1.6761e-01, time/batch = 0.6849s	
14315/33150 (epoch 21.591), train_loss = 0.97899961, grad/param norm = 1.5000e-01, time/batch = 0.6814s	
14316/33150 (epoch 21.593), train_loss = 1.06045561, grad/param norm = 1.6135e-01, time/batch = 0.6739s	
14317/33150 (epoch 21.594), train_loss = 1.00698998, grad/param norm = 1.6629e-01, time/batch = 0.6761s	
14318/33150 (epoch 21.596), train_loss = 0.95123332, grad/param norm = 1.4638e-01, time/batch = 0.6727s	
14319/33150 (epoch 21.597), train_loss = 0.86688054, grad/param norm = 1.5989e-01, time/batch = 0.6888s	
14320/33150 (epoch 21.599), train_loss = 1.17233759, grad/param norm = 1.8331e-01, time/batch = 0.6705s	
14321/33150 (epoch 21.600), train_loss = 1.01570711, grad/param norm = 2.0814e-01, time/batch = 0.6729s	
14322/33150 (epoch 21.602), train_loss = 0.97152678, grad/param norm = 1.5545e-01, time/batch = 0.6725s	
14323/33150 (epoch 21.603), train_loss = 1.07385702, grad/param norm = 1.7029e-01, time/batch = 0.6719s	
14324/33150 (epoch 21.605), train_loss = 0.90892842, grad/param norm = 1.5172e-01, time/batch = 0.6779s	
14325/33150 (epoch 21.606), train_loss = 1.00695127, grad/param norm = 1.9849e-01, time/batch = 0.6788s	
14326/33150 (epoch 21.608), train_loss = 1.08194586, grad/param norm = 1.5657e-01, time/batch = 0.6803s	
14327/33150 (epoch 21.609), train_loss = 0.97559773, grad/param norm = 1.5768e-01, time/batch = 0.7046s	
14328/33150 (epoch 21.611), train_loss = 0.90150890, grad/param norm = 1.5124e-01, time/batch = 0.6977s	
14329/33150 (epoch 21.612), train_loss = 1.01375552, grad/param norm = 1.6393e-01, time/batch = 0.6947s	
14330/33150 (epoch 21.614), train_loss = 0.89883286, grad/param norm = 1.5181e-01, time/batch = 0.6954s	
14331/33150 (epoch 21.615), train_loss = 0.89158750, grad/param norm = 1.5375e-01, time/batch = 0.6939s	
14332/33150 (epoch 21.617), train_loss = 1.01633376, grad/param norm = 1.6573e-01, time/batch = 0.6987s	
14333/33150 (epoch 21.618), train_loss = 1.03980940, grad/param norm = 1.7008e-01, time/batch = 0.6932s	
14334/33150 (epoch 21.620), train_loss = 0.91092986, grad/param norm = 1.5222e-01, time/batch = 0.6926s	
14335/33150 (epoch 21.621), train_loss = 0.99820778, grad/param norm = 1.4476e-01, time/batch = 0.6905s	
14336/33150 (epoch 21.623), train_loss = 1.06830301, grad/param norm = 1.5605e-01, time/batch = 0.6724s	
14337/33150 (epoch 21.624), train_loss = 0.93334570, grad/param norm = 1.4540e-01, time/batch = 0.6705s	
14338/33150 (epoch 21.626), train_loss = 0.94825579, grad/param norm = 1.5371e-01, time/batch = 0.6702s	
14339/33150 (epoch 21.627), train_loss = 0.89469541, grad/param norm = 1.4281e-01, time/batch = 0.6851s	
14340/33150 (epoch 21.629), train_loss = 0.85620209, grad/param norm = 1.4047e-01, time/batch = 0.6785s	
14341/33150 (epoch 21.630), train_loss = 0.94798826, grad/param norm = 1.5396e-01, time/batch = 0.6745s	
14342/33150 (epoch 21.632), train_loss = 0.86088251, grad/param norm = 1.3351e-01, time/batch = 0.6717s	
14343/33150 (epoch 21.633), train_loss = 0.86265581, grad/param norm = 1.7509e-01, time/batch = 0.6718s	
14344/33150 (epoch 21.635), train_loss = 1.16071216, grad/param norm = 1.5319e-01, time/batch = 0.6745s	
14345/33150 (epoch 21.637), train_loss = 0.84928506, grad/param norm = 1.5333e-01, time/batch = 0.6713s	
14346/33150 (epoch 21.638), train_loss = 0.95391575, grad/param norm = 1.4449e-01, time/batch = 0.6733s	
14347/33150 (epoch 21.640), train_loss = 1.05430076, grad/param norm = 1.5916e-01, time/batch = 0.6705s	
14348/33150 (epoch 21.641), train_loss = 0.86686585, grad/param norm = 1.5148e-01, time/batch = 0.6693s	
14349/33150 (epoch 21.643), train_loss = 0.94823124, grad/param norm = 1.5398e-01, time/batch = 0.6736s	
14350/33150 (epoch 21.644), train_loss = 1.14120612, grad/param norm = 1.5970e-01, time/batch = 0.6699s	
14351/33150 (epoch 21.646), train_loss = 0.95588981, grad/param norm = 1.5150e-01, time/batch = 0.6741s	
14352/33150 (epoch 21.647), train_loss = 1.20569677, grad/param norm = 1.7610e-01, time/batch = 0.6746s	
14353/33150 (epoch 21.649), train_loss = 1.07515393, grad/param norm = 1.7170e-01, time/batch = 0.6762s	
14354/33150 (epoch 21.650), train_loss = 0.87410440, grad/param norm = 1.3295e-01, time/batch = 0.6915s	
14355/33150 (epoch 21.652), train_loss = 1.11074225, grad/param norm = 1.6910e-01, time/batch = 0.6949s	
14356/33150 (epoch 21.653), train_loss = 1.01026347, grad/param norm = 1.3942e-01, time/batch = 0.6915s	
14357/33150 (epoch 21.655), train_loss = 1.04879187, grad/param norm = 1.7824e-01, time/batch = 0.6702s	
14358/33150 (epoch 21.656), train_loss = 0.95796452, grad/param norm = 1.5185e-01, time/batch = 0.6717s	
14359/33150 (epoch 21.658), train_loss = 0.96568267, grad/param norm = 1.7140e-01, time/batch = 0.6674s	
14360/33150 (epoch 21.659), train_loss = 1.27725045, grad/param norm = 2.1991e-01, time/batch = 0.6658s	
14361/33150 (epoch 21.661), train_loss = 0.99966701, grad/param norm = 1.7764e-01, time/batch = 0.6694s	
14362/33150 (epoch 21.662), train_loss = 0.90403028, grad/param norm = 1.7763e-01, time/batch = 0.6680s	
14363/33150 (epoch 21.664), train_loss = 1.14291623, grad/param norm = 1.6962e-01, time/batch = 0.6677s	
14364/33150 (epoch 21.665), train_loss = 1.06739037, grad/param norm = 1.5677e-01, time/batch = 0.6695s	
14365/33150 (epoch 21.667), train_loss = 1.11623536, grad/param norm = 1.6768e-01, time/batch = 0.6678s	
14366/33150 (epoch 21.668), train_loss = 1.08238611, grad/param norm = 1.5706e-01, time/batch = 0.6692s	
14367/33150 (epoch 21.670), train_loss = 0.93605261, grad/param norm = 1.4566e-01, time/batch = 0.6708s	
14368/33150 (epoch 21.671), train_loss = 0.94815057, grad/param norm = 1.5335e-01, time/batch = 0.6813s	
14369/33150 (epoch 21.673), train_loss = 1.13222246, grad/param norm = 1.4284e-01, time/batch = 0.6904s	
14370/33150 (epoch 21.674), train_loss = 1.01071200, grad/param norm = 1.4784e-01, time/batch = 0.6914s	
14371/33150 (epoch 21.676), train_loss = 0.97595193, grad/param norm = 1.4615e-01, time/batch = 0.6946s	
14372/33150 (epoch 21.677), train_loss = 1.18407598, grad/param norm = 1.6247e-01, time/batch = 0.6721s	
14373/33150 (epoch 21.679), train_loss = 1.00276367, grad/param norm = 1.4371e-01, time/batch = 0.6898s	
14374/33150 (epoch 21.680), train_loss = 1.11991106, grad/param norm = 1.6188e-01, time/batch = 0.6744s	
14375/33150 (epoch 21.682), train_loss = 0.97601220, grad/param norm = 1.4998e-01, time/batch = 0.6685s	
14376/33150 (epoch 21.683), train_loss = 0.85334282, grad/param norm = 1.2651e-01, time/batch = 0.6705s	
14377/33150 (epoch 21.685), train_loss = 0.98111628, grad/param norm = 1.7451e-01, time/batch = 0.6971s	
14378/33150 (epoch 21.686), train_loss = 0.87353578, grad/param norm = 1.5770e-01, time/batch = 0.7070s	
14379/33150 (epoch 21.688), train_loss = 0.88533914, grad/param norm = 1.3691e-01, time/batch = 0.6857s	
14380/33150 (epoch 21.689), train_loss = 0.92580058, grad/param norm = 1.5218e-01, time/batch = 0.6742s	
14381/33150 (epoch 21.691), train_loss = 0.79381382, grad/param norm = 1.3208e-01, time/batch = 0.6736s	
14382/33150 (epoch 21.692), train_loss = 0.89316029, grad/param norm = 1.4446e-01, time/batch = 0.6709s	
14383/33150 (epoch 21.694), train_loss = 0.79298899, grad/param norm = 1.3894e-01, time/batch = 0.6721s	
14384/33150 (epoch 21.695), train_loss = 0.93335585, grad/param norm = 1.3427e-01, time/batch = 0.6727s	
14385/33150 (epoch 21.697), train_loss = 0.83710594, grad/param norm = 1.2664e-01, time/batch = 0.6712s	
14386/33150 (epoch 21.698), train_loss = 0.92704666, grad/param norm = 1.4524e-01, time/batch = 0.6738s	
14387/33150 (epoch 21.700), train_loss = 0.74618449, grad/param norm = 1.3073e-01, time/batch = 0.6781s	
14388/33150 (epoch 21.701), train_loss = 0.84875130, grad/param norm = 1.3483e-01, time/batch = 0.6864s	
14389/33150 (epoch 21.703), train_loss = 0.96956760, grad/param norm = 1.4800e-01, time/batch = 0.6865s	
14390/33150 (epoch 21.704), train_loss = 0.83231939, grad/param norm = 1.3445e-01, time/batch = 0.6757s	
14391/33150 (epoch 21.706), train_loss = 0.94888702, grad/param norm = 1.5580e-01, time/batch = 0.6708s	
14392/33150 (epoch 21.707), train_loss = 0.93182052, grad/param norm = 1.4940e-01, time/batch = 0.6710s	
14393/33150 (epoch 21.709), train_loss = 0.97269957, grad/param norm = 1.3416e-01, time/batch = 0.6740s	
14394/33150 (epoch 21.710), train_loss = 0.98844518, grad/param norm = 1.7036e-01, time/batch = 0.6961s	
14395/33150 (epoch 21.712), train_loss = 1.04780761, grad/param norm = 1.6773e-01, time/batch = 0.6842s	
14396/33150 (epoch 21.713), train_loss = 1.02908909, grad/param norm = 1.4790e-01, time/batch = 0.6807s	
14397/33150 (epoch 21.715), train_loss = 0.92173913, grad/param norm = 1.3585e-01, time/batch = 0.6745s	
14398/33150 (epoch 21.716), train_loss = 1.01780025, grad/param norm = 1.5690e-01, time/batch = 0.6903s	
14399/33150 (epoch 21.718), train_loss = 1.00261406, grad/param norm = 1.5387e-01, time/batch = 0.6698s	
14400/33150 (epoch 21.719), train_loss = 1.08886474, grad/param norm = 1.7625e-01, time/batch = 0.6659s	
14401/33150 (epoch 21.721), train_loss = 0.95808417, grad/param norm = 1.5566e-01, time/batch = 0.6679s	
14402/33150 (epoch 21.722), train_loss = 1.00114009, grad/param norm = 1.4417e-01, time/batch = 0.6694s	
14403/33150 (epoch 21.724), train_loss = 0.95435304, grad/param norm = 1.4518e-01, time/batch = 0.6679s	
14404/33150 (epoch 21.725), train_loss = 1.09736134, grad/param norm = 1.8753e-01, time/batch = 0.6673s	
14405/33150 (epoch 21.727), train_loss = 1.04581661, grad/param norm = 1.9962e-01, time/batch = 0.6695s	
14406/33150 (epoch 21.729), train_loss = 0.96013728, grad/param norm = 1.5199e-01, time/batch = 0.6699s	
14407/33150 (epoch 21.730), train_loss = 1.03214022, grad/param norm = 1.6415e-01, time/batch = 0.6724s	
14408/33150 (epoch 21.732), train_loss = 1.08488592, grad/param norm = 1.7609e-01, time/batch = 0.6726s	
14409/33150 (epoch 21.733), train_loss = 0.80894817, grad/param norm = 1.2199e-01, time/batch = 0.6691s	
14410/33150 (epoch 21.735), train_loss = 0.90400037, grad/param norm = 1.4297e-01, time/batch = 0.6680s	
14411/33150 (epoch 21.736), train_loss = 0.94988271, grad/param norm = 1.5557e-01, time/batch = 0.6733s	
14412/33150 (epoch 21.738), train_loss = 0.99196009, grad/param norm = 1.5325e-01, time/batch = 0.6769s	
14413/33150 (epoch 21.739), train_loss = 1.09095033, grad/param norm = 1.6886e-01, time/batch = 0.6855s	
14414/33150 (epoch 21.741), train_loss = 1.09210588, grad/param norm = 1.6484e-01, time/batch = 0.6691s	
14415/33150 (epoch 21.742), train_loss = 0.86989886, grad/param norm = 1.5634e-01, time/batch = 0.6705s	
14416/33150 (epoch 21.744), train_loss = 1.09912116, grad/param norm = 1.7705e-01, time/batch = 0.6737s	
14417/33150 (epoch 21.745), train_loss = 0.94100640, grad/param norm = 1.4017e-01, time/batch = 0.6698s	
14418/33150 (epoch 21.747), train_loss = 0.77853401, grad/param norm = 1.4071e-01, time/batch = 0.6720s	
14419/33150 (epoch 21.748), train_loss = 0.90223496, grad/param norm = 1.4123e-01, time/batch = 0.6750s	
14420/33150 (epoch 21.750), train_loss = 1.02780167, grad/param norm = 1.5305e-01, time/batch = 0.6774s	
14421/33150 (epoch 21.751), train_loss = 1.00131609, grad/param norm = 1.5135e-01, time/batch = 0.7037s	
14422/33150 (epoch 21.753), train_loss = 0.84062853, grad/param norm = 1.5920e-01, time/batch = 0.6908s	
14423/33150 (epoch 21.754), train_loss = 1.21362299, grad/param norm = 1.9823e-01, time/batch = 0.6868s	
14424/33150 (epoch 21.756), train_loss = 1.01540878, grad/param norm = 1.7715e-01, time/batch = 0.6852s	
14425/33150 (epoch 21.757), train_loss = 1.00887321, grad/param norm = 1.6244e-01, time/batch = 0.6783s	
14426/33150 (epoch 21.759), train_loss = 1.12878681, grad/param norm = 1.7408e-01, time/batch = 0.6885s	
14427/33150 (epoch 21.760), train_loss = 1.01893422, grad/param norm = 1.4911e-01, time/batch = 0.6851s	
14428/33150 (epoch 21.762), train_loss = 1.02709800, grad/param norm = 1.8863e-01, time/batch = 0.6860s	
14429/33150 (epoch 21.763), train_loss = 1.04741500, grad/param norm = 1.6163e-01, time/batch = 0.6804s	
14430/33150 (epoch 21.765), train_loss = 0.98361232, grad/param norm = 1.4697e-01, time/batch = 0.6829s	
14431/33150 (epoch 21.766), train_loss = 0.91697025, grad/param norm = 1.6405e-01, time/batch = 0.6867s	
14432/33150 (epoch 21.768), train_loss = 0.92199203, grad/param norm = 1.4521e-01, time/batch = 0.6815s	
14433/33150 (epoch 21.769), train_loss = 1.03878443, grad/param norm = 1.6545e-01, time/batch = 0.6714s	
14434/33150 (epoch 21.771), train_loss = 1.00734835, grad/param norm = 1.4704e-01, time/batch = 0.6700s	
14435/33150 (epoch 21.772), train_loss = 1.07194317, grad/param norm = 1.6319e-01, time/batch = 0.6711s	
14436/33150 (epoch 21.774), train_loss = 1.18528960, grad/param norm = 1.6342e-01, time/batch = 0.6708s	
14437/33150 (epoch 21.775), train_loss = 1.05864869, grad/param norm = 1.9951e-01, time/batch = 0.6708s	
14438/33150 (epoch 21.777), train_loss = 1.05344644, grad/param norm = 1.5674e-01, time/batch = 0.6738s	
14439/33150 (epoch 21.778), train_loss = 1.02005114, grad/param norm = 1.4707e-01, time/batch = 0.6702s	
14440/33150 (epoch 21.780), train_loss = 0.84058102, grad/param norm = 1.3094e-01, time/batch = 0.6694s	
14441/33150 (epoch 21.781), train_loss = 0.98706292, grad/param norm = 1.4020e-01, time/batch = 0.6727s	
14442/33150 (epoch 21.783), train_loss = 1.00137658, grad/param norm = 1.4822e-01, time/batch = 0.6756s	
14443/33150 (epoch 21.784), train_loss = 0.99499780, grad/param norm = 1.9163e-01, time/batch = 0.6728s	
14444/33150 (epoch 21.786), train_loss = 0.97552344, grad/param norm = 1.4676e-01, time/batch = 0.6724s	
14445/33150 (epoch 21.787), train_loss = 0.92344175, grad/param norm = 1.3845e-01, time/batch = 0.6684s	
14446/33150 (epoch 21.789), train_loss = 0.82995194, grad/param norm = 1.5181e-01, time/batch = 0.6694s	
14447/33150 (epoch 21.790), train_loss = 0.87485188, grad/param norm = 1.2774e-01, time/batch = 0.6740s	
14448/33150 (epoch 21.792), train_loss = 1.04041895, grad/param norm = 1.8275e-01, time/batch = 0.6679s	
14449/33150 (epoch 21.793), train_loss = 0.97588518, grad/param norm = 1.6882e-01, time/batch = 0.6708s	
14450/33150 (epoch 21.795), train_loss = 0.95626898, grad/param norm = 1.6138e-01, time/batch = 0.6706s	
14451/33150 (epoch 21.796), train_loss = 0.93976858, grad/param norm = 1.4729e-01, time/batch = 0.6708s	
14452/33150 (epoch 21.798), train_loss = 0.92332603, grad/param norm = 1.2477e-01, time/batch = 0.6711s	
14453/33150 (epoch 21.799), train_loss = 0.81594323, grad/param norm = 1.3768e-01, time/batch = 0.6700s	
14454/33150 (epoch 21.801), train_loss = 1.01160704, grad/param norm = 1.5416e-01, time/batch = 0.6679s	
14455/33150 (epoch 21.802), train_loss = 0.89149433, grad/param norm = 1.5045e-01, time/batch = 0.6706s	
14456/33150 (epoch 21.804), train_loss = 0.94884524, grad/param norm = 1.4799e-01, time/batch = 0.6720s	
14457/33150 (epoch 21.805), train_loss = 0.92140505, grad/param norm = 1.6356e-01, time/batch = 0.6907s	
14458/33150 (epoch 21.807), train_loss = 0.94220313, grad/param norm = 1.4280e-01, time/batch = 0.6871s	
14459/33150 (epoch 21.808), train_loss = 1.08004221, grad/param norm = 1.7824e-01, time/batch = 0.7029s	
14460/33150 (epoch 21.810), train_loss = 0.93938957, grad/param norm = 1.5484e-01, time/batch = 0.6756s	
14461/33150 (epoch 21.811), train_loss = 1.01825905, grad/param norm = 1.8140e-01, time/batch = 0.6922s	
14462/33150 (epoch 21.813), train_loss = 0.95181523, grad/param norm = 1.3787e-01, time/batch = 0.6794s	
14463/33150 (epoch 21.814), train_loss = 0.94976892, grad/param norm = 1.6647e-01, time/batch = 0.6899s	
14464/33150 (epoch 21.816), train_loss = 0.96043623, grad/param norm = 1.5362e-01, time/batch = 0.6847s	
14465/33150 (epoch 21.817), train_loss = 1.03877047, grad/param norm = 1.5323e-01, time/batch = 0.6699s	
14466/33150 (epoch 21.819), train_loss = 0.97639241, grad/param norm = 1.4152e-01, time/batch = 0.6718s	
14467/33150 (epoch 21.821), train_loss = 0.86265138, grad/param norm = 1.3115e-01, time/batch = 0.7053s	
14468/33150 (epoch 21.822), train_loss = 0.92394355, grad/param norm = 1.4327e-01, time/batch = 0.6881s	
14469/33150 (epoch 21.824), train_loss = 0.94299463, grad/param norm = 1.4336e-01, time/batch = 0.6707s	
14470/33150 (epoch 21.825), train_loss = 1.00660843, grad/param norm = 1.5543e-01, time/batch = 0.6679s	
14471/33150 (epoch 21.827), train_loss = 1.03148784, grad/param norm = 1.5708e-01, time/batch = 0.6811s	
14472/33150 (epoch 21.828), train_loss = 0.86949055, grad/param norm = 1.6076e-01, time/batch = 0.6876s	
14473/33150 (epoch 21.830), train_loss = 1.06694809, grad/param norm = 1.6876e-01, time/batch = 0.6735s	
14474/33150 (epoch 21.831), train_loss = 0.91348204, grad/param norm = 1.5881e-01, time/batch = 0.6672s	
14475/33150 (epoch 21.833), train_loss = 0.90545563, grad/param norm = 1.4322e-01, time/batch = 0.6683s	
14476/33150 (epoch 21.834), train_loss = 1.09435267, grad/param norm = 1.6889e-01, time/batch = 0.6703s	
14477/33150 (epoch 21.836), train_loss = 1.10201079, grad/param norm = 1.4126e-01, time/batch = 0.6700s	
14478/33150 (epoch 21.837), train_loss = 0.97235461, grad/param norm = 1.6085e-01, time/batch = 0.6766s	
14479/33150 (epoch 21.839), train_loss = 1.05040220, grad/param norm = 1.7060e-01, time/batch = 0.6735s	
14480/33150 (epoch 21.840), train_loss = 1.05146754, grad/param norm = 1.5292e-01, time/batch = 0.6841s	
14481/33150 (epoch 21.842), train_loss = 1.11021799, grad/param norm = 1.7401e-01, time/batch = 0.6930s	
14482/33150 (epoch 21.843), train_loss = 1.09139338, grad/param norm = 1.6802e-01, time/batch = 0.6926s	
14483/33150 (epoch 21.845), train_loss = 0.92348955, grad/param norm = 1.4414e-01, time/batch = 0.6730s	
14484/33150 (epoch 21.846), train_loss = 1.18287825, grad/param norm = 1.9885e-01, time/batch = 0.6719s	
14485/33150 (epoch 21.848), train_loss = 1.08971313, grad/param norm = 1.7995e-01, time/batch = 0.6923s	
14486/33150 (epoch 21.849), train_loss = 1.11600367, grad/param norm = 1.6677e-01, time/batch = 0.6820s	
14487/33150 (epoch 21.851), train_loss = 1.07089829, grad/param norm = 1.7370e-01, time/batch = 0.6696s	
14488/33150 (epoch 21.852), train_loss = 1.14186924, grad/param norm = 1.4932e-01, time/batch = 0.6711s	
14489/33150 (epoch 21.854), train_loss = 0.99713525, grad/param norm = 1.4193e-01, time/batch = 0.6763s	
14490/33150 (epoch 21.855), train_loss = 0.85868859, grad/param norm = 1.3426e-01, time/batch = 0.6722s	
14491/33150 (epoch 21.857), train_loss = 0.85528456, grad/param norm = 1.4148e-01, time/batch = 0.6758s	
14492/33150 (epoch 21.858), train_loss = 0.94763121, grad/param norm = 1.5619e-01, time/batch = 0.6718s	
14493/33150 (epoch 21.860), train_loss = 0.86962131, grad/param norm = 1.3057e-01, time/batch = 0.6715s	
14494/33150 (epoch 21.861), train_loss = 0.88096540, grad/param norm = 1.4257e-01, time/batch = 0.6704s	
14495/33150 (epoch 21.863), train_loss = 0.99399384, grad/param norm = 1.4323e-01, time/batch = 0.6707s	
14496/33150 (epoch 21.864), train_loss = 1.08016130, grad/param norm = 1.5327e-01, time/batch = 0.6701s	
14497/33150 (epoch 21.866), train_loss = 1.03856626, grad/param norm = 1.4434e-01, time/batch = 0.6709s	
14498/33150 (epoch 21.867), train_loss = 1.02688005, grad/param norm = 1.4821e-01, time/batch = 0.6737s	
14499/33150 (epoch 21.869), train_loss = 1.04557933, grad/param norm = 1.8169e-01, time/batch = 0.6718s	
14500/33150 (epoch 21.870), train_loss = 0.96941095, grad/param norm = 1.6290e-01, time/batch = 0.6725s	
14501/33150 (epoch 21.872), train_loss = 1.00408775, grad/param norm = 1.5280e-01, time/batch = 0.6757s	
14502/33150 (epoch 21.873), train_loss = 0.84093176, grad/param norm = 1.3020e-01, time/batch = 0.6876s	
14503/33150 (epoch 21.875), train_loss = 1.12118508, grad/param norm = 1.5092e-01, time/batch = 0.6735s	
14504/33150 (epoch 21.876), train_loss = 0.86100852, grad/param norm = 1.3777e-01, time/batch = 0.6691s	
14505/33150 (epoch 21.878), train_loss = 0.88091614, grad/param norm = 1.3133e-01, time/batch = 0.6683s	
14506/33150 (epoch 21.879), train_loss = 0.90988873, grad/param norm = 1.4481e-01, time/batch = 0.6688s	
14507/33150 (epoch 21.881), train_loss = 0.90934953, grad/param norm = 1.5961e-01, time/batch = 0.6673s	
14508/33150 (epoch 21.882), train_loss = 0.81473153, grad/param norm = 1.4248e-01, time/batch = 0.6720s	
14509/33150 (epoch 21.884), train_loss = 0.95844856, grad/param norm = 1.4115e-01, time/batch = 0.6687s	
14510/33150 (epoch 21.885), train_loss = 0.76523248, grad/param norm = 1.4252e-01, time/batch = 0.6683s	
14511/33150 (epoch 21.887), train_loss = 1.09950150, grad/param norm = 1.7000e-01, time/batch = 0.6720s	
14512/33150 (epoch 21.888), train_loss = 1.03303376, grad/param norm = 1.5703e-01, time/batch = 0.6722s	
14513/33150 (epoch 21.890), train_loss = 0.90947796, grad/param norm = 1.5688e-01, time/batch = 0.6733s	
14514/33150 (epoch 21.891), train_loss = 0.87802436, grad/param norm = 1.4687e-01, time/batch = 0.6717s	
14515/33150 (epoch 21.893), train_loss = 1.05188965, grad/param norm = 1.6946e-01, time/batch = 0.6747s	
14516/33150 (epoch 21.894), train_loss = 1.02826344, grad/param norm = 1.5035e-01, time/batch = 0.6762s	
14517/33150 (epoch 21.896), train_loss = 0.95651200, grad/param norm = 1.5620e-01, time/batch = 0.6766s	
14518/33150 (epoch 21.897), train_loss = 1.02066679, grad/param norm = 1.3736e-01, time/batch = 0.6722s	
14519/33150 (epoch 21.899), train_loss = 0.83761618, grad/param norm = 1.6117e-01, time/batch = 0.6706s	
14520/33150 (epoch 21.900), train_loss = 1.19252849, grad/param norm = 1.7126e-01, time/batch = 0.6845s	
14521/33150 (epoch 21.902), train_loss = 1.18044479, grad/param norm = 1.7062e-01, time/batch = 0.6822s	
14522/33150 (epoch 21.903), train_loss = 0.99977229, grad/param norm = 1.5785e-01, time/batch = 0.6767s	
14523/33150 (epoch 21.905), train_loss = 1.01191706, grad/param norm = 1.3591e-01, time/batch = 0.6794s	
14524/33150 (epoch 21.906), train_loss = 1.01813922, grad/param norm = 1.5877e-01, time/batch = 0.6783s	
14525/33150 (epoch 21.908), train_loss = 1.12131430, grad/param norm = 1.5879e-01, time/batch = 0.6773s	
14526/33150 (epoch 21.910), train_loss = 1.07451885, grad/param norm = 1.5862e-01, time/batch = 0.6790s	
14527/33150 (epoch 21.911), train_loss = 0.85202449, grad/param norm = 1.4307e-01, time/batch = 0.6764s	
14528/33150 (epoch 21.913), train_loss = 0.91746074, grad/param norm = 1.6174e-01, time/batch = 0.6786s	
14529/33150 (epoch 21.914), train_loss = 1.07484457, grad/param norm = 1.8172e-01, time/batch = 0.6780s	
14530/33150 (epoch 21.916), train_loss = 0.90124460, grad/param norm = 1.5399e-01, time/batch = 0.6776s	
14531/33150 (epoch 21.917), train_loss = 1.05303396, grad/param norm = 1.7729e-01, time/batch = 0.6805s	
14532/33150 (epoch 21.919), train_loss = 1.13104408, grad/param norm = 1.9156e-01, time/batch = 0.6763s	
14533/33150 (epoch 21.920), train_loss = 1.10159419, grad/param norm = 1.6229e-01, time/batch = 0.6754s	
14534/33150 (epoch 21.922), train_loss = 1.14041489, grad/param norm = 1.8383e-01, time/batch = 0.6748s	
14535/33150 (epoch 21.923), train_loss = 1.00666615, grad/param norm = 1.6540e-01, time/batch = 0.6852s	
14536/33150 (epoch 21.925), train_loss = 1.08956786, grad/param norm = 1.4859e-01, time/batch = 0.6775s	
14537/33150 (epoch 21.926), train_loss = 0.95700578, grad/param norm = 1.5117e-01, time/batch = 0.6745s	
14538/33150 (epoch 21.928), train_loss = 0.95166692, grad/param norm = 1.5559e-01, time/batch = 0.6754s	
14539/33150 (epoch 21.929), train_loss = 1.04574159, grad/param norm = 1.5208e-01, time/batch = 0.6791s	
14540/33150 (epoch 21.931), train_loss = 1.13439720, grad/param norm = 1.7530e-01, time/batch = 0.6754s	
14541/33150 (epoch 21.932), train_loss = 0.98969156, grad/param norm = 1.6801e-01, time/batch = 0.6752s	
14542/33150 (epoch 21.934), train_loss = 1.02232674, grad/param norm = 1.4871e-01, time/batch = 0.6766s	
14543/33150 (epoch 21.935), train_loss = 1.11053539, grad/param norm = 1.5630e-01, time/batch = 0.6758s	
14544/33150 (epoch 21.937), train_loss = 1.10475105, grad/param norm = 1.4006e-01, time/batch = 0.6761s	
14545/33150 (epoch 21.938), train_loss = 1.04367415, grad/param norm = 1.6438e-01, time/batch = 0.6932s	
14546/33150 (epoch 21.940), train_loss = 1.27112476, grad/param norm = 1.8418e-01, time/batch = 0.6927s	
14547/33150 (epoch 21.941), train_loss = 0.99021406, grad/param norm = 1.3493e-01, time/batch = 0.6796s	
14548/33150 (epoch 21.943), train_loss = 0.88461557, grad/param norm = 1.6951e-01, time/batch = 0.6812s	
14549/33150 (epoch 21.944), train_loss = 1.09221362, grad/param norm = 1.6063e-01, time/batch = 0.6799s	
14550/33150 (epoch 21.946), train_loss = 0.85001281, grad/param norm = 1.3601e-01, time/batch = 0.6836s	
14551/33150 (epoch 21.947), train_loss = 1.01322858, grad/param norm = 1.5885e-01, time/batch = 0.6716s	
14552/33150 (epoch 21.949), train_loss = 1.12402969, grad/param norm = 1.6485e-01, time/batch = 0.6754s	
14553/33150 (epoch 21.950), train_loss = 1.04741115, grad/param norm = 1.5357e-01, time/batch = 0.6783s	
14554/33150 (epoch 21.952), train_loss = 0.89957920, grad/param norm = 1.4664e-01, time/batch = 0.6745s	
14555/33150 (epoch 21.953), train_loss = 0.94763484, grad/param norm = 1.4101e-01, time/batch = 0.6746s	
14556/33150 (epoch 21.955), train_loss = 0.86461529, grad/param norm = 1.4519e-01, time/batch = 0.6769s	
14557/33150 (epoch 21.956), train_loss = 1.05949871, grad/param norm = 1.5195e-01, time/batch = 0.6764s	
14558/33150 (epoch 21.958), train_loss = 0.88884392, grad/param norm = 1.3745e-01, time/batch = 0.6748s	
14559/33150 (epoch 21.959), train_loss = 0.94348168, grad/param norm = 1.5043e-01, time/batch = 0.6761s	
14560/33150 (epoch 21.961), train_loss = 0.88860010, grad/param norm = 1.3918e-01, time/batch = 0.6770s	
14561/33150 (epoch 21.962), train_loss = 0.85852278, grad/param norm = 1.4247e-01, time/batch = 0.6847s	
14562/33150 (epoch 21.964), train_loss = 0.99548220, grad/param norm = 1.4406e-01, time/batch = 0.6923s	
14563/33150 (epoch 21.965), train_loss = 0.99636321, grad/param norm = 1.5743e-01, time/batch = 0.6745s	
14564/33150 (epoch 21.967), train_loss = 0.98616640, grad/param norm = 1.7353e-01, time/batch = 0.6731s	
14565/33150 (epoch 21.968), train_loss = 0.83905200, grad/param norm = 1.3538e-01, time/batch = 0.6739s	
14566/33150 (epoch 21.970), train_loss = 0.93662461, grad/param norm = 1.5223e-01, time/batch = 0.6752s	
14567/33150 (epoch 21.971), train_loss = 0.98153119, grad/param norm = 1.6134e-01, time/batch = 0.6732s	
14568/33150 (epoch 21.973), train_loss = 1.10394594, grad/param norm = 1.6613e-01, time/batch = 0.6743s	
14569/33150 (epoch 21.974), train_loss = 1.13619132, grad/param norm = 1.5817e-01, time/batch = 0.6715s	
14570/33150 (epoch 21.976), train_loss = 1.06304033, grad/param norm = 1.3918e-01, time/batch = 0.6732s	
14571/33150 (epoch 21.977), train_loss = 1.13778490, grad/param norm = 1.6042e-01, time/batch = 0.6749s	
14572/33150 (epoch 21.979), train_loss = 1.08684642, grad/param norm = 1.8270e-01, time/batch = 0.6761s	
14573/33150 (epoch 21.980), train_loss = 1.15704392, grad/param norm = 1.6754e-01, time/batch = 0.6769s	
14574/33150 (epoch 21.982), train_loss = 0.98664685, grad/param norm = 1.6715e-01, time/batch = 0.6839s	
14575/33150 (epoch 21.983), train_loss = 0.88906158, grad/param norm = 1.6060e-01, time/batch = 0.6852s	
14576/33150 (epoch 21.985), train_loss = 1.08234840, grad/param norm = 1.4929e-01, time/batch = 0.6768s	
14577/33150 (epoch 21.986), train_loss = 0.83613352, grad/param norm = 1.4130e-01, time/batch = 0.6867s	
14578/33150 (epoch 21.988), train_loss = 0.95887751, grad/param norm = 1.9220e-01, time/batch = 0.6758s	
14579/33150 (epoch 21.989), train_loss = 0.94360501, grad/param norm = 1.7954e-01, time/batch = 0.6735s	
14580/33150 (epoch 21.991), train_loss = 1.08121326, grad/param norm = 2.2262e-01, time/batch = 0.6750s	
14581/33150 (epoch 21.992), train_loss = 0.92388216, grad/param norm = 1.5340e-01, time/batch = 0.6824s	
14582/33150 (epoch 21.994), train_loss = 1.00647362, grad/param norm = 1.5567e-01, time/batch = 0.6854s	
14583/33150 (epoch 21.995), train_loss = 0.94711649, grad/param norm = 1.4826e-01, time/batch = 0.6740s	
14584/33150 (epoch 21.997), train_loss = 1.00430295, grad/param norm = 1.8366e-01, time/batch = 0.6707s	
14585/33150 (epoch 21.998), train_loss = 0.82263367, grad/param norm = 1.4174e-01, time/batch = 0.6746s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
14586/33150 (epoch 22.000), train_loss = 0.83035174, grad/param norm = 1.4925e-01, time/batch = 0.6733s	
14587/33150 (epoch 22.002), train_loss = 1.27145359, grad/param norm = 1.7965e-01, time/batch = 0.6776s	
14588/33150 (epoch 22.003), train_loss = 0.89424682, grad/param norm = 1.5990e-01, time/batch = 0.6721s	
14589/33150 (epoch 22.005), train_loss = 0.86343018, grad/param norm = 1.3692e-01, time/batch = 0.6756s	
14590/33150 (epoch 22.006), train_loss = 0.85258286, grad/param norm = 1.4992e-01, time/batch = 0.6723s	
14591/33150 (epoch 22.008), train_loss = 1.10033299, grad/param norm = 1.6696e-01, time/batch = 0.6816s	
14592/33150 (epoch 22.009), train_loss = 0.98893846, grad/param norm = 1.5308e-01, time/batch = 0.6775s	
14593/33150 (epoch 22.011), train_loss = 1.07971938, grad/param norm = 1.5540e-01, time/batch = 0.6741s	
14594/33150 (epoch 22.012), train_loss = 0.99498764, grad/param norm = 1.6647e-01, time/batch = 0.6734s	
14595/33150 (epoch 22.014), train_loss = 0.93451693, grad/param norm = 1.7506e-01, time/batch = 0.6773s	
14596/33150 (epoch 22.015), train_loss = 0.91900880, grad/param norm = 1.5519e-01, time/batch = 0.6802s	
14597/33150 (epoch 22.017), train_loss = 0.89908636, grad/param norm = 1.3769e-01, time/batch = 0.6739s	
14598/33150 (epoch 22.018), train_loss = 1.01737061, grad/param norm = 1.7700e-01, time/batch = 0.6760s	
14599/33150 (epoch 22.020), train_loss = 1.07634582, grad/param norm = 1.7386e-01, time/batch = 0.6744s	
14600/33150 (epoch 22.021), train_loss = 0.88195920, grad/param norm = 1.5220e-01, time/batch = 0.6788s	
14601/33150 (epoch 22.023), train_loss = 1.15790541, grad/param norm = 1.4871e-01, time/batch = 0.6841s	
14602/33150 (epoch 22.024), train_loss = 1.06244579, grad/param norm = 1.7174e-01, time/batch = 0.6772s	
14603/33150 (epoch 22.026), train_loss = 0.78877116, grad/param norm = 1.2752e-01, time/batch = 0.6754s	
14604/33150 (epoch 22.027), train_loss = 0.80267289, grad/param norm = 1.2669e-01, time/batch = 0.6711s	
14605/33150 (epoch 22.029), train_loss = 0.91959776, grad/param norm = 1.4722e-01, time/batch = 0.6687s	
14606/33150 (epoch 22.030), train_loss = 0.96664727, grad/param norm = 1.3599e-01, time/batch = 0.6689s	
14607/33150 (epoch 22.032), train_loss = 0.89599030, grad/param norm = 1.6313e-01, time/batch = 0.6711s	
14608/33150 (epoch 22.033), train_loss = 0.91981773, grad/param norm = 1.4833e-01, time/batch = 0.6833s	
14609/33150 (epoch 22.035), train_loss = 1.14484430, grad/param norm = 1.7580e-01, time/batch = 0.6872s	
14610/33150 (epoch 22.036), train_loss = 1.03099587, grad/param norm = 1.6346e-01, time/batch = 0.6887s	
14611/33150 (epoch 22.038), train_loss = 1.25313516, grad/param norm = 1.8048e-01, time/batch = 0.6916s	
14612/33150 (epoch 22.039), train_loss = 1.04702536, grad/param norm = 1.4196e-01, time/batch = 0.6926s	
14613/33150 (epoch 22.041), train_loss = 1.01051921, grad/param norm = 1.4395e-01, time/batch = 0.6911s	
14614/33150 (epoch 22.042), train_loss = 0.95251833, grad/param norm = 1.4785e-01, time/batch = 0.6894s	
14615/33150 (epoch 22.044), train_loss = 0.95952299, grad/param norm = 1.4013e-01, time/batch = 0.6742s	
14616/33150 (epoch 22.045), train_loss = 1.01040725, grad/param norm = 1.4452e-01, time/batch = 0.6676s	
14617/33150 (epoch 22.047), train_loss = 0.86047253, grad/param norm = 1.4141e-01, time/batch = 0.6684s	
14618/33150 (epoch 22.048), train_loss = 1.05357738, grad/param norm = 1.7282e-01, time/batch = 0.6708s	
14619/33150 (epoch 22.050), train_loss = 1.00126500, grad/param norm = 1.6715e-01, time/batch = 0.6712s	
14620/33150 (epoch 22.051), train_loss = 0.99883686, grad/param norm = 1.4746e-01, time/batch = 0.6684s	
14621/33150 (epoch 22.053), train_loss = 0.96977887, grad/param norm = 1.5140e-01, time/batch = 0.6744s	
14622/33150 (epoch 22.054), train_loss = 1.10732211, grad/param norm = 1.4997e-01, time/batch = 0.6744s	
14623/33150 (epoch 22.056), train_loss = 0.96811839, grad/param norm = 1.4045e-01, time/batch = 0.6738s	
14624/33150 (epoch 22.057), train_loss = 0.99530490, grad/param norm = 1.7421e-01, time/batch = 0.6728s	
14625/33150 (epoch 22.059), train_loss = 0.91886239, grad/param norm = 1.5189e-01, time/batch = 0.6737s	
14626/33150 (epoch 22.060), train_loss = 0.90984195, grad/param norm = 1.3077e-01, time/batch = 0.6677s	
14627/33150 (epoch 22.062), train_loss = 0.96267951, grad/param norm = 1.5535e-01, time/batch = 0.6682s	
14628/33150 (epoch 22.063), train_loss = 0.92239782, grad/param norm = 1.4521e-01, time/batch = 0.6711s	
14629/33150 (epoch 22.065), train_loss = 0.94707464, grad/param norm = 1.4812e-01, time/batch = 0.6702s	
14630/33150 (epoch 22.066), train_loss = 0.90448517, grad/param norm = 1.4368e-01, time/batch = 0.6713s	
14631/33150 (epoch 22.068), train_loss = 1.00887541, grad/param norm = 1.4577e-01, time/batch = 0.6791s	
14632/33150 (epoch 22.069), train_loss = 1.04165267, grad/param norm = 1.8106e-01, time/batch = 0.6754s	
14633/33150 (epoch 22.071), train_loss = 1.01874924, grad/param norm = 1.5349e-01, time/batch = 0.6934s	
14634/33150 (epoch 22.072), train_loss = 0.96727087, grad/param norm = 1.5235e-01, time/batch = 0.6936s	
14635/33150 (epoch 22.074), train_loss = 0.86263220, grad/param norm = 1.9249e-01, time/batch = 0.6954s	
14636/33150 (epoch 22.075), train_loss = 0.91567574, grad/param norm = 1.6202e-01, time/batch = 0.6692s	
14637/33150 (epoch 22.077), train_loss = 0.95755839, grad/param norm = 1.8132e-01, time/batch = 0.6685s	
14638/33150 (epoch 22.078), train_loss = 1.10706021, grad/param norm = 1.7628e-01, time/batch = 0.6698s	
14639/33150 (epoch 22.080), train_loss = 1.11082648, grad/param norm = 1.5297e-01, time/batch = 0.6969s	
14640/33150 (epoch 22.081), train_loss = 0.88669868, grad/param norm = 1.6352e-01, time/batch = 0.6844s	
14641/33150 (epoch 22.083), train_loss = 0.74631237, grad/param norm = 1.5711e-01, time/batch = 0.6979s	
14642/33150 (epoch 22.084), train_loss = 0.86076927, grad/param norm = 1.8326e-01, time/batch = 0.6837s	
14643/33150 (epoch 22.086), train_loss = 0.92704849, grad/param norm = 1.7022e-01, time/batch = 0.6778s	
14644/33150 (epoch 22.087), train_loss = 0.86684552, grad/param norm = 1.5055e-01, time/batch = 0.6787s	
14645/33150 (epoch 22.089), train_loss = 0.88174230, grad/param norm = 1.4819e-01, time/batch = 0.6710s	
14646/33150 (epoch 22.090), train_loss = 0.94483893, grad/param norm = 1.5598e-01, time/batch = 0.6657s	
14647/33150 (epoch 22.092), train_loss = 0.92189924, grad/param norm = 1.6067e-01, time/batch = 0.6675s	
14648/33150 (epoch 22.094), train_loss = 1.04622792, grad/param norm = 1.7706e-01, time/batch = 0.6851s	
14649/33150 (epoch 22.095), train_loss = 0.88114749, grad/param norm = 1.4065e-01, time/batch = 0.6754s	
14650/33150 (epoch 22.097), train_loss = 0.88863042, grad/param norm = 1.5651e-01, time/batch = 0.6718s	
14651/33150 (epoch 22.098), train_loss = 1.21186967, grad/param norm = 1.6642e-01, time/batch = 0.6683s	
14652/33150 (epoch 22.100), train_loss = 1.15012513, grad/param norm = 1.6529e-01, time/batch = 0.6663s	
14653/33150 (epoch 22.101), train_loss = 0.91008679, grad/param norm = 1.4533e-01, time/batch = 0.6684s	
14654/33150 (epoch 22.103), train_loss = 0.98516607, grad/param norm = 1.4714e-01, time/batch = 0.6688s	
14655/33150 (epoch 22.104), train_loss = 0.90255462, grad/param norm = 1.7422e-01, time/batch = 0.6769s	
14656/33150 (epoch 22.106), train_loss = 1.10364358, grad/param norm = 1.6723e-01, time/batch = 0.6734s	
14657/33150 (epoch 22.107), train_loss = 1.19271147, grad/param norm = 1.7903e-01, time/batch = 0.6694s	
14658/33150 (epoch 22.109), train_loss = 0.94876789, grad/param norm = 1.3491e-01, time/batch = 0.6710s	
14659/33150 (epoch 22.110), train_loss = 1.09465730, grad/param norm = 1.6950e-01, time/batch = 0.6697s	
14660/33150 (epoch 22.112), train_loss = 0.90604015, grad/param norm = 1.5176e-01, time/batch = 0.6713s	
14661/33150 (epoch 22.113), train_loss = 0.93910680, grad/param norm = 1.6368e-01, time/batch = 0.6729s	
14662/33150 (epoch 22.115), train_loss = 1.16608727, grad/param norm = 1.8233e-01, time/batch = 0.6723s	
14663/33150 (epoch 22.116), train_loss = 0.95507084, grad/param norm = 1.4009e-01, time/batch = 0.6714s	
14664/33150 (epoch 22.118), train_loss = 1.05934540, grad/param norm = 1.8391e-01, time/batch = 0.6697s	
14665/33150 (epoch 22.119), train_loss = 1.06037869, grad/param norm = 1.8729e-01, time/batch = 0.6758s	
14666/33150 (epoch 22.121), train_loss = 0.95365243, grad/param norm = 1.4552e-01, time/batch = 0.6803s	
14667/33150 (epoch 22.122), train_loss = 1.18009179, grad/param norm = 2.1718e-01, time/batch = 0.6929s	
14668/33150 (epoch 22.124), train_loss = 0.83050964, grad/param norm = 1.3408e-01, time/batch = 0.6886s	
14669/33150 (epoch 22.125), train_loss = 1.06786406, grad/param norm = 1.5437e-01, time/batch = 0.6738s	
14670/33150 (epoch 22.127), train_loss = 0.95742279, grad/param norm = 1.4250e-01, time/batch = 0.6786s	
14671/33150 (epoch 22.128), train_loss = 1.02705622, grad/param norm = 1.8571e-01, time/batch = 0.6761s	
14672/33150 (epoch 22.130), train_loss = 1.02113718, grad/param norm = 1.5794e-01, time/batch = 0.6764s	
14673/33150 (epoch 22.131), train_loss = 1.21539476, grad/param norm = 1.7139e-01, time/batch = 0.6884s	
14674/33150 (epoch 22.133), train_loss = 0.90920056, grad/param norm = 1.4342e-01, time/batch = 0.6759s	
14675/33150 (epoch 22.134), train_loss = 1.09604344, grad/param norm = 1.5215e-01, time/batch = 0.6728s	
14676/33150 (epoch 22.136), train_loss = 0.99142035, grad/param norm = 1.7839e-01, time/batch = 0.6754s	
14677/33150 (epoch 22.137), train_loss = 1.09075402, grad/param norm = 1.6583e-01, time/batch = 0.6778s	
14678/33150 (epoch 22.139), train_loss = 1.06707409, grad/param norm = 1.6498e-01, time/batch = 0.6869s	
14679/33150 (epoch 22.140), train_loss = 1.14415438, grad/param norm = 1.6584e-01, time/batch = 0.6697s	
14680/33150 (epoch 22.142), train_loss = 1.07316795, grad/param norm = 1.6151e-01, time/batch = 0.6708s	
14681/33150 (epoch 22.143), train_loss = 1.00809868, grad/param norm = 1.6895e-01, time/batch = 0.6787s	
14682/33150 (epoch 22.145), train_loss = 0.96176081, grad/param norm = 1.4982e-01, time/batch = 0.6857s	
14683/33150 (epoch 22.146), train_loss = 1.08935168, grad/param norm = 1.8134e-01, time/batch = 0.6752s	
14684/33150 (epoch 22.148), train_loss = 1.11152391, grad/param norm = 1.5646e-01, time/batch = 0.6702s	
14685/33150 (epoch 22.149), train_loss = 1.00016898, grad/param norm = 1.4530e-01, time/batch = 0.6693s	
14686/33150 (epoch 22.151), train_loss = 1.15868909, grad/param norm = 1.6338e-01, time/batch = 0.6682s	
14687/33150 (epoch 22.152), train_loss = 0.97617590, grad/param norm = 1.4908e-01, time/batch = 0.6729s	
14688/33150 (epoch 22.154), train_loss = 0.97393573, grad/param norm = 1.6373e-01, time/batch = 0.6707s	
14689/33150 (epoch 22.155), train_loss = 0.84382874, grad/param norm = 1.4277e-01, time/batch = 0.6748s	
14690/33150 (epoch 22.157), train_loss = 0.96186385, grad/param norm = 1.6723e-01, time/batch = 0.6730s	
14691/33150 (epoch 22.158), train_loss = 0.92677566, grad/param norm = 1.4640e-01, time/batch = 0.6746s	
14692/33150 (epoch 22.160), train_loss = 1.04571149, grad/param norm = 1.6003e-01, time/batch = 0.6761s	
14693/33150 (epoch 22.161), train_loss = 0.91624276, grad/param norm = 1.5808e-01, time/batch = 0.6746s	
14694/33150 (epoch 22.163), train_loss = 0.89841246, grad/param norm = 1.4308e-01, time/batch = 0.6734s	
14695/33150 (epoch 22.164), train_loss = 1.04121283, grad/param norm = 1.6271e-01, time/batch = 0.6743s	
14696/33150 (epoch 22.166), train_loss = 0.97098021, grad/param norm = 1.5579e-01, time/batch = 0.6733s	
14697/33150 (epoch 22.167), train_loss = 1.00771640, grad/param norm = 1.5980e-01, time/batch = 0.6713s	
14698/33150 (epoch 22.169), train_loss = 1.01433684, grad/param norm = 1.8415e-01, time/batch = 0.6719s	
14699/33150 (epoch 22.170), train_loss = 0.89418109, grad/param norm = 1.7727e-01, time/batch = 0.6716s	
14700/33150 (epoch 22.172), train_loss = 1.10428390, grad/param norm = 1.7609e-01, time/batch = 0.6707s	
14701/33150 (epoch 22.173), train_loss = 1.04727542, grad/param norm = 1.7715e-01, time/batch = 0.6763s	
14702/33150 (epoch 22.175), train_loss = 0.94720996, grad/param norm = 1.7485e-01, time/batch = 0.6727s	
14703/33150 (epoch 22.176), train_loss = 1.06624802, grad/param norm = 2.0056e-01, time/batch = 0.6714s	
14704/33150 (epoch 22.178), train_loss = 1.18550293, grad/param norm = 1.7456e-01, time/batch = 0.6735s	
14705/33150 (epoch 22.179), train_loss = 1.05496671, grad/param norm = 1.5295e-01, time/batch = 0.6717s	
14706/33150 (epoch 22.181), train_loss = 0.99816422, grad/param norm = 1.6528e-01, time/batch = 0.6721s	
14707/33150 (epoch 22.183), train_loss = 0.96633009, grad/param norm = 1.6848e-01, time/batch = 0.6744s	
14708/33150 (epoch 22.184), train_loss = 1.22205208, grad/param norm = 1.7284e-01, time/batch = 0.6689s	
14709/33150 (epoch 22.186), train_loss = 1.12270345, grad/param norm = 1.5843e-01, time/batch = 0.6717s	
14710/33150 (epoch 22.187), train_loss = 1.03250371, grad/param norm = 1.6857e-01, time/batch = 0.6729s	
14711/33150 (epoch 22.189), train_loss = 0.79373877, grad/param norm = 1.4137e-01, time/batch = 0.6694s	
14712/33150 (epoch 22.190), train_loss = 0.90795583, grad/param norm = 2.1483e-01, time/batch = 0.6741s	
14713/33150 (epoch 22.192), train_loss = 1.00752465, grad/param norm = 1.7659e-01, time/batch = 0.6728s	
14714/33150 (epoch 22.193), train_loss = 1.09096697, grad/param norm = 1.6977e-01, time/batch = 0.6865s	
14715/33150 (epoch 22.195), train_loss = 1.23025921, grad/param norm = 1.9689e-01, time/batch = 0.6765s	
14716/33150 (epoch 22.196), train_loss = 1.12362401, grad/param norm = 1.9184e-01, time/batch = 0.6851s	
14717/33150 (epoch 22.198), train_loss = 0.87442288, grad/param norm = 1.5499e-01, time/batch = 0.6735s	
14718/33150 (epoch 22.199), train_loss = 1.10671095, grad/param norm = 2.0066e-01, time/batch = 0.6704s	
14719/33150 (epoch 22.201), train_loss = 0.91456292, grad/param norm = 1.3225e-01, time/batch = 0.6727s	
14720/33150 (epoch 22.202), train_loss = 0.78351052, grad/param norm = 1.4176e-01, time/batch = 0.6699s	
14721/33150 (epoch 22.204), train_loss = 1.02455021, grad/param norm = 1.5751e-01, time/batch = 0.6810s	
14722/33150 (epoch 22.205), train_loss = 1.09291334, grad/param norm = 1.7117e-01, time/batch = 0.6938s	
14723/33150 (epoch 22.207), train_loss = 1.04446923, grad/param norm = 1.6148e-01, time/batch = 0.6930s	
14724/33150 (epoch 22.208), train_loss = 1.05421723, grad/param norm = 1.5616e-01, time/batch = 0.6849s	
14725/33150 (epoch 22.210), train_loss = 0.92695764, grad/param norm = 1.3509e-01, time/batch = 0.6729s	
14726/33150 (epoch 22.211), train_loss = 1.02122745, grad/param norm = 1.7506e-01, time/batch = 0.6787s	
14727/33150 (epoch 22.213), train_loss = 1.05402218, grad/param norm = 1.5038e-01, time/batch = 0.7002s	
14728/33150 (epoch 22.214), train_loss = 0.97800154, grad/param norm = 1.5403e-01, time/batch = 0.6760s	
14729/33150 (epoch 22.216), train_loss = 0.91575176, grad/param norm = 1.5029e-01, time/batch = 0.6819s	
14730/33150 (epoch 22.217), train_loss = 0.96746012, grad/param norm = 1.4635e-01, time/batch = 0.6793s	
14731/33150 (epoch 22.219), train_loss = 0.88307382, grad/param norm = 1.4402e-01, time/batch = 0.6844s	
14732/33150 (epoch 22.220), train_loss = 0.93351610, grad/param norm = 1.3916e-01, time/batch = 0.6726s	
14733/33150 (epoch 22.222), train_loss = 1.10701488, grad/param norm = 1.5928e-01, time/batch = 0.6712s	
14734/33150 (epoch 22.223), train_loss = 1.00473288, grad/param norm = 1.7505e-01, time/batch = 0.6754s	
14735/33150 (epoch 22.225), train_loss = 1.13836019, grad/param norm = 1.6207e-01, time/batch = 0.6736s	
14736/33150 (epoch 22.226), train_loss = 0.97843005, grad/param norm = 1.4068e-01, time/batch = 0.6740s	
14737/33150 (epoch 22.228), train_loss = 0.98706466, grad/param norm = 1.5588e-01, time/batch = 0.6788s	
14738/33150 (epoch 22.229), train_loss = 0.99824731, grad/param norm = 1.5914e-01, time/batch = 0.6727s	
14739/33150 (epoch 22.231), train_loss = 1.13576962, grad/param norm = 1.7897e-01, time/batch = 0.6728s	
14740/33150 (epoch 22.232), train_loss = 1.01719815, grad/param norm = 1.9419e-01, time/batch = 0.6714s	
14741/33150 (epoch 22.234), train_loss = 1.01145956, grad/param norm = 1.9795e-01, time/batch = 0.6727s	
14742/33150 (epoch 22.235), train_loss = 1.03617172, grad/param norm = 1.7251e-01, time/batch = 0.6754s	
14743/33150 (epoch 22.237), train_loss = 1.02312680, grad/param norm = 1.8484e-01, time/batch = 0.6763s	
14744/33150 (epoch 22.238), train_loss = 1.04035448, grad/param norm = 1.7064e-01, time/batch = 0.6760s	
14745/33150 (epoch 22.240), train_loss = 1.05207730, grad/param norm = 1.8152e-01, time/batch = 0.6838s	
14746/33150 (epoch 22.241), train_loss = 1.11735151, grad/param norm = 1.7887e-01, time/batch = 0.6806s	
14747/33150 (epoch 22.243), train_loss = 1.09038638, grad/param norm = 1.8233e-01, time/batch = 0.6768s	
14748/33150 (epoch 22.244), train_loss = 1.00235223, grad/param norm = 1.5802e-01, time/batch = 0.6718s	
14749/33150 (epoch 22.246), train_loss = 1.06447666, grad/param norm = 1.5026e-01, time/batch = 0.6747s	
14750/33150 (epoch 22.247), train_loss = 0.94913359, grad/param norm = 1.5700e-01, time/batch = 0.6710s	
14751/33150 (epoch 22.249), train_loss = 1.10225505, grad/param norm = 1.4699e-01, time/batch = 0.6769s	
14752/33150 (epoch 22.250), train_loss = 1.06238619, grad/param norm = 1.3976e-01, time/batch = 0.6732s	
14753/33150 (epoch 22.252), train_loss = 1.05842156, grad/param norm = 1.3546e-01, time/batch = 0.6729s	
14754/33150 (epoch 22.253), train_loss = 0.99208289, grad/param norm = 1.6437e-01, time/batch = 0.6693s	
14755/33150 (epoch 22.255), train_loss = 0.97664698, grad/param norm = 1.3945e-01, time/batch = 0.6706s	
14756/33150 (epoch 22.256), train_loss = 1.05904312, grad/param norm = 1.4361e-01, time/batch = 0.6769s	
14757/33150 (epoch 22.258), train_loss = 0.96959509, grad/param norm = 1.7754e-01, time/batch = 0.6817s	
14758/33150 (epoch 22.259), train_loss = 0.83190190, grad/param norm = 1.6636e-01, time/batch = 0.6712s	
14759/33150 (epoch 22.261), train_loss = 0.88166134, grad/param norm = 1.3523e-01, time/batch = 0.6719s	
14760/33150 (epoch 22.262), train_loss = 1.07451421, grad/param norm = 1.7131e-01, time/batch = 0.6853s	
14761/33150 (epoch 22.264), train_loss = 0.78107348, grad/param norm = 1.4078e-01, time/batch = 0.6826s	
14762/33150 (epoch 22.265), train_loss = 1.04405216, grad/param norm = 1.5857e-01, time/batch = 0.6817s	
14763/33150 (epoch 22.267), train_loss = 1.06571269, grad/param norm = 1.6300e-01, time/batch = 0.6935s	
14764/33150 (epoch 22.268), train_loss = 1.08899311, grad/param norm = 1.5368e-01, time/batch = 0.6981s	
14765/33150 (epoch 22.270), train_loss = 1.18113199, grad/param norm = 1.7357e-01, time/batch = 0.6912s	
14766/33150 (epoch 22.271), train_loss = 1.12628212, grad/param norm = 1.8281e-01, time/batch = 0.6802s	
14767/33150 (epoch 22.273), train_loss = 1.11369130, grad/param norm = 1.5852e-01, time/batch = 0.6785s	
14768/33150 (epoch 22.275), train_loss = 1.13520733, grad/param norm = 1.6268e-01, time/batch = 0.6847s	
14769/33150 (epoch 22.276), train_loss = 1.00510356, grad/param norm = 1.5957e-01, time/batch = 0.6736s	
14770/33150 (epoch 22.278), train_loss = 1.10562150, grad/param norm = 1.6350e-01, time/batch = 0.6725s	
14771/33150 (epoch 22.279), train_loss = 1.06925163, grad/param norm = 1.7039e-01, time/batch = 0.6760s	
14772/33150 (epoch 22.281), train_loss = 1.03773967, grad/param norm = 1.5239e-01, time/batch = 0.6743s	
14773/33150 (epoch 22.282), train_loss = 1.03076023, grad/param norm = 1.4289e-01, time/batch = 0.6829s	
14774/33150 (epoch 22.284), train_loss = 0.94975253, grad/param norm = 1.4813e-01, time/batch = 0.6880s	
14775/33150 (epoch 22.285), train_loss = 1.02163316, grad/param norm = 1.4570e-01, time/batch = 0.6870s	
14776/33150 (epoch 22.287), train_loss = 0.89974786, grad/param norm = 1.5578e-01, time/batch = 0.6861s	
14777/33150 (epoch 22.288), train_loss = 1.10522201, grad/param norm = 1.5308e-01, time/batch = 0.6905s	
14778/33150 (epoch 22.290), train_loss = 0.85293311, grad/param norm = 1.3929e-01, time/batch = 0.6960s	
14779/33150 (epoch 22.291), train_loss = 0.84551810, grad/param norm = 1.4418e-01, time/batch = 0.6972s	
14780/33150 (epoch 22.293), train_loss = 1.04894915, grad/param norm = 1.5493e-01, time/batch = 0.6911s	
14781/33150 (epoch 22.294), train_loss = 0.76341016, grad/param norm = 1.3951e-01, time/batch = 0.6725s	
14782/33150 (epoch 22.296), train_loss = 0.98892557, grad/param norm = 1.5005e-01, time/batch = 0.6688s	
14783/33150 (epoch 22.297), train_loss = 0.94120243, grad/param norm = 1.4279e-01, time/batch = 0.6742s	
14784/33150 (epoch 22.299), train_loss = 0.91352805, grad/param norm = 1.5167e-01, time/batch = 0.6713s	
14785/33150 (epoch 22.300), train_loss = 0.94788985, grad/param norm = 1.4061e-01, time/batch = 0.6755s	
14786/33150 (epoch 22.302), train_loss = 0.95759182, grad/param norm = 1.4564e-01, time/batch = 0.6788s	
14787/33150 (epoch 22.303), train_loss = 0.96156018, grad/param norm = 1.4554e-01, time/batch = 0.6706s	
14788/33150 (epoch 22.305), train_loss = 1.06934053, grad/param norm = 1.4039e-01, time/batch = 0.6701s	
14789/33150 (epoch 22.306), train_loss = 1.06392065, grad/param norm = 1.6914e-01, time/batch = 0.6715s	
14790/33150 (epoch 22.308), train_loss = 1.22755789, grad/param norm = 1.7393e-01, time/batch = 0.6685s	
14791/33150 (epoch 22.309), train_loss = 0.83839957, grad/param norm = 1.4589e-01, time/batch = 0.6699s	
14792/33150 (epoch 22.311), train_loss = 0.95653379, grad/param norm = 1.6585e-01, time/batch = 0.6713s	
14793/33150 (epoch 22.312), train_loss = 0.80889615, grad/param norm = 1.4355e-01, time/batch = 0.6709s	
14794/33150 (epoch 22.314), train_loss = 0.95678089, grad/param norm = 1.5960e-01, time/batch = 0.6705s	
14795/33150 (epoch 22.315), train_loss = 1.02836893, grad/param norm = 1.5755e-01, time/batch = 0.6759s	
14796/33150 (epoch 22.317), train_loss = 0.80483451, grad/param norm = 1.2851e-01, time/batch = 0.6706s	
14797/33150 (epoch 22.318), train_loss = 0.88829167, grad/param norm = 1.3638e-01, time/batch = 0.6694s	
14798/33150 (epoch 22.320), train_loss = 0.84829478, grad/param norm = 1.3741e-01, time/batch = 0.6699s	
14799/33150 (epoch 22.321), train_loss = 0.95762989, grad/param norm = 1.3745e-01, time/batch = 0.6767s	
14800/33150 (epoch 22.323), train_loss = 0.97814970, grad/param norm = 1.5918e-01, time/batch = 0.6835s	
14801/33150 (epoch 22.324), train_loss = 1.06208005, grad/param norm = 1.7799e-01, time/batch = 0.6739s	
14802/33150 (epoch 22.326), train_loss = 1.02696920, grad/param norm = 1.5115e-01, time/batch = 0.6756s	
14803/33150 (epoch 22.327), train_loss = 1.11881442, grad/param norm = 1.5945e-01, time/batch = 0.6738s	
14804/33150 (epoch 22.329), train_loss = 1.05755048, grad/param norm = 1.4869e-01, time/batch = 0.6796s	
14805/33150 (epoch 22.330), train_loss = 0.98436157, grad/param norm = 1.6461e-01, time/batch = 0.6756s	
14806/33150 (epoch 22.332), train_loss = 0.98031347, grad/param norm = 1.2966e-01, time/batch = 0.6734s	
14807/33150 (epoch 22.333), train_loss = 1.04249666, grad/param norm = 1.4514e-01, time/batch = 0.6760s	
14808/33150 (epoch 22.335), train_loss = 0.92816725, grad/param norm = 1.5146e-01, time/batch = 0.6763s	
14809/33150 (epoch 22.336), train_loss = 0.91369854, grad/param norm = 1.5961e-01, time/batch = 0.6770s	
14810/33150 (epoch 22.338), train_loss = 0.81250989, grad/param norm = 1.4912e-01, time/batch = 0.6928s	
14811/33150 (epoch 22.339), train_loss = 1.07070574, grad/param norm = 1.5683e-01, time/batch = 0.6936s	
14812/33150 (epoch 22.341), train_loss = 1.04627323, grad/param norm = 1.8288e-01, time/batch = 0.7097s	
14813/33150 (epoch 22.342), train_loss = 0.89255974, grad/param norm = 1.4876e-01, time/batch = 0.6816s	
14814/33150 (epoch 22.344), train_loss = 0.99904898, grad/param norm = 1.6331e-01, time/batch = 0.6817s	
14815/33150 (epoch 22.345), train_loss = 0.95113110, grad/param norm = 1.4220e-01, time/batch = 0.6713s	
14816/33150 (epoch 22.347), train_loss = 0.78996661, grad/param norm = 1.4528e-01, time/batch = 0.6709s	
14817/33150 (epoch 22.348), train_loss = 1.00198716, grad/param norm = 1.4512e-01, time/batch = 0.6812s	
14818/33150 (epoch 22.350), train_loss = 0.89488069, grad/param norm = 1.6074e-01, time/batch = 0.6738s	
14819/33150 (epoch 22.351), train_loss = 1.06044397, grad/param norm = 1.7373e-01, time/batch = 0.6812s	
14820/33150 (epoch 22.353), train_loss = 1.02584320, grad/param norm = 1.6139e-01, time/batch = 0.6725s	
14821/33150 (epoch 22.354), train_loss = 1.24951782, grad/param norm = 1.6990e-01, time/batch = 0.6735s	
14822/33150 (epoch 22.356), train_loss = 1.10801911, grad/param norm = 1.6571e-01, time/batch = 0.6759s	
14823/33150 (epoch 22.357), train_loss = 1.06267607, grad/param norm = 1.7600e-01, time/batch = 0.6725s	
14824/33150 (epoch 22.359), train_loss = 1.07036725, grad/param norm = 1.6465e-01, time/batch = 0.6872s	
14825/33150 (epoch 22.360), train_loss = 1.05417034, grad/param norm = 1.8101e-01, time/batch = 0.6858s	
14826/33150 (epoch 22.362), train_loss = 1.10455545, grad/param norm = 1.6293e-01, time/batch = 0.6738s	
14827/33150 (epoch 22.363), train_loss = 1.00118773, grad/param norm = 1.4533e-01, time/batch = 0.6724s	
14828/33150 (epoch 22.365), train_loss = 0.98748073, grad/param norm = 1.5392e-01, time/batch = 0.6785s	
14829/33150 (epoch 22.367), train_loss = 0.94436610, grad/param norm = 1.4865e-01, time/batch = 0.6791s	
14830/33150 (epoch 22.368), train_loss = 0.99648140, grad/param norm = 1.8236e-01, time/batch = 0.6770s	
14831/33150 (epoch 22.370), train_loss = 1.00578151, grad/param norm = 1.5499e-01, time/batch = 0.6855s	
14832/33150 (epoch 22.371), train_loss = 0.90793017, grad/param norm = 1.5152e-01, time/batch = 0.6820s	
14833/33150 (epoch 22.373), train_loss = 1.06125370, grad/param norm = 1.7796e-01, time/batch = 0.6814s	
14834/33150 (epoch 22.374), train_loss = 0.96486757, grad/param norm = 1.5302e-01, time/batch = 0.6756s	
14835/33150 (epoch 22.376), train_loss = 1.10728784, grad/param norm = 1.6013e-01, time/batch = 0.6764s	
14836/33150 (epoch 22.377), train_loss = 0.95649614, grad/param norm = 1.7800e-01, time/batch = 0.6741s	
14837/33150 (epoch 22.379), train_loss = 1.06388447, grad/param norm = 1.5978e-01, time/batch = 0.6758s	
14838/33150 (epoch 22.380), train_loss = 1.06938977, grad/param norm = 1.4949e-01, time/batch = 0.6745s	
14839/33150 (epoch 22.382), train_loss = 0.94921471, grad/param norm = 1.4701e-01, time/batch = 0.6854s	
14840/33150 (epoch 22.383), train_loss = 0.93933015, grad/param norm = 1.5518e-01, time/batch = 0.6842s	
14841/33150 (epoch 22.385), train_loss = 0.96367896, grad/param norm = 1.5050e-01, time/batch = 0.6690s	
14842/33150 (epoch 22.386), train_loss = 0.85665283, grad/param norm = 1.3552e-01, time/batch = 0.6764s	
14843/33150 (epoch 22.388), train_loss = 0.93260223, grad/param norm = 1.3694e-01, time/batch = 0.6863s	
14844/33150 (epoch 22.389), train_loss = 0.92756856, grad/param norm = 1.5464e-01, time/batch = 0.6929s	
14845/33150 (epoch 22.391), train_loss = 1.16316648, grad/param norm = 1.7337e-01, time/batch = 0.6931s	
14846/33150 (epoch 22.392), train_loss = 0.94388359, grad/param norm = 1.4693e-01, time/batch = 0.6883s	
14847/33150 (epoch 22.394), train_loss = 0.83254207, grad/param norm = 1.2573e-01, time/batch = 0.6684s	
14848/33150 (epoch 22.395), train_loss = 0.84501775, grad/param norm = 1.4702e-01, time/batch = 0.6679s	
14849/33150 (epoch 22.397), train_loss = 0.68439749, grad/param norm = 1.3166e-01, time/batch = 0.6703s	
14850/33150 (epoch 22.398), train_loss = 1.00971319, grad/param norm = 1.8446e-01, time/batch = 0.6687s	
14851/33150 (epoch 22.400), train_loss = 0.94915781, grad/param norm = 1.3930e-01, time/batch = 0.6716s	
14852/33150 (epoch 22.401), train_loss = 0.82584320, grad/param norm = 1.2463e-01, time/batch = 0.6689s	
14853/33150 (epoch 22.403), train_loss = 0.84408449, grad/param norm = 1.5235e-01, time/batch = 0.6749s	
14854/33150 (epoch 22.404), train_loss = 0.98139991, grad/param norm = 1.5811e-01, time/batch = 0.6854s	
14855/33150 (epoch 22.406), train_loss = 0.92413188, grad/param norm = 1.2637e-01, time/batch = 0.6790s	
14856/33150 (epoch 22.407), train_loss = 0.84679514, grad/param norm = 1.3624e-01, time/batch = 0.6783s	
14857/33150 (epoch 22.409), train_loss = 0.79355232, grad/param norm = 1.3032e-01, time/batch = 0.6772s	
14858/33150 (epoch 22.410), train_loss = 0.99232397, grad/param norm = 1.5355e-01, time/batch = 0.6792s	
14859/33150 (epoch 22.412), train_loss = 1.04735204, grad/param norm = 1.5670e-01, time/batch = 0.6803s	
14860/33150 (epoch 22.413), train_loss = 0.90777482, grad/param norm = 1.4986e-01, time/batch = 0.6727s	
14861/33150 (epoch 22.415), train_loss = 1.02146202, grad/param norm = 1.4305e-01, time/batch = 0.6841s	
14862/33150 (epoch 22.416), train_loss = 0.90997406, grad/param norm = 1.4274e-01, time/batch = 0.6730s	
14863/33150 (epoch 22.418), train_loss = 1.06831421, grad/param norm = 1.9057e-01, time/batch = 0.6712s	
14864/33150 (epoch 22.419), train_loss = 0.92896059, grad/param norm = 1.4230e-01, time/batch = 0.6724s	
14865/33150 (epoch 22.421), train_loss = 0.99442782, grad/param norm = 1.9304e-01, time/batch = 0.6718s	
14866/33150 (epoch 22.422), train_loss = 0.93310973, grad/param norm = 1.4258e-01, time/batch = 0.6724s	
14867/33150 (epoch 22.424), train_loss = 0.92143514, grad/param norm = 1.5350e-01, time/batch = 0.6711s	
14868/33150 (epoch 22.425), train_loss = 1.03125644, grad/param norm = 1.6406e-01, time/batch = 0.6777s	
14869/33150 (epoch 22.427), train_loss = 0.97166245, grad/param norm = 1.4175e-01, time/batch = 0.6846s	
14870/33150 (epoch 22.428), train_loss = 0.97920562, grad/param norm = 1.5608e-01, time/batch = 0.6731s	
14871/33150 (epoch 22.430), train_loss = 0.97896086, grad/param norm = 1.5098e-01, time/batch = 0.6760s	
14872/33150 (epoch 22.431), train_loss = 1.04255631, grad/param norm = 1.6527e-01, time/batch = 0.6811s	
14873/33150 (epoch 22.433), train_loss = 0.97627782, grad/param norm = 1.4236e-01, time/batch = 0.6773s	
14874/33150 (epoch 22.434), train_loss = 0.86363736, grad/param norm = 1.4956e-01, time/batch = 0.6746s	
14875/33150 (epoch 22.436), train_loss = 0.93512463, grad/param norm = 1.4292e-01, time/batch = 0.6714s	
14876/33150 (epoch 22.437), train_loss = 0.99079019, grad/param norm = 1.7551e-01, time/batch = 0.6689s	
14877/33150 (epoch 22.439), train_loss = 1.12251322, grad/param norm = 1.5486e-01, time/batch = 0.6694s	
14878/33150 (epoch 22.440), train_loss = 1.07509816, grad/param norm = 1.6811e-01, time/batch = 0.6702s	
14879/33150 (epoch 22.442), train_loss = 0.86420689, grad/param norm = 1.4483e-01, time/batch = 0.6686s	
14880/33150 (epoch 22.443), train_loss = 1.03791950, grad/param norm = 1.5168e-01, time/batch = 0.6693s	
14881/33150 (epoch 22.445), train_loss = 1.00540098, grad/param norm = 1.7053e-01, time/batch = 0.6712s	
14882/33150 (epoch 22.446), train_loss = 1.00511199, grad/param norm = 2.1291e-01, time/batch = 0.6686s	
14883/33150 (epoch 22.448), train_loss = 1.08778981, grad/param norm = 1.7010e-01, time/batch = 0.6735s	
14884/33150 (epoch 22.449), train_loss = 1.01410626, grad/param norm = 1.4205e-01, time/batch = 0.6743s	
14885/33150 (epoch 22.451), train_loss = 1.02261104, grad/param norm = 1.7883e-01, time/batch = 0.6756s	
14886/33150 (epoch 22.452), train_loss = 1.20655988, grad/param norm = 1.6665e-01, time/batch = 0.6787s	
14887/33150 (epoch 22.454), train_loss = 1.00603500, grad/param norm = 1.6800e-01, time/batch = 0.6754s	
14888/33150 (epoch 22.456), train_loss = 0.87417194, grad/param norm = 1.3567e-01, time/batch = 0.6772s	
14889/33150 (epoch 22.457), train_loss = 0.99411313, grad/param norm = 1.5366e-01, time/batch = 0.6760s	
14890/33150 (epoch 22.459), train_loss = 1.11865729, grad/param norm = 2.1851e-01, time/batch = 0.6740s	
14891/33150 (epoch 22.460), train_loss = 1.03546046, grad/param norm = 1.4338e-01, time/batch = 0.6782s	
14892/33150 (epoch 22.462), train_loss = 1.07538030, grad/param norm = 1.8202e-01, time/batch = 0.6856s	
14893/33150 (epoch 22.463), train_loss = 1.21474791, grad/param norm = 1.8194e-01, time/batch = 0.6733s	
14894/33150 (epoch 22.465), train_loss = 0.97995804, grad/param norm = 1.5169e-01, time/batch = 0.6700s	
14895/33150 (epoch 22.466), train_loss = 0.91487252, grad/param norm = 1.4200e-01, time/batch = 0.6718s	
14896/33150 (epoch 22.468), train_loss = 1.23056159, grad/param norm = 1.6112e-01, time/batch = 0.6693s	
14897/33150 (epoch 22.469), train_loss = 0.98825356, grad/param norm = 1.5525e-01, time/batch = 0.6751s	
14898/33150 (epoch 22.471), train_loss = 0.92086361, grad/param norm = 1.4208e-01, time/batch = 0.6902s	
14899/33150 (epoch 22.472), train_loss = 1.02473605, grad/param norm = 1.5668e-01, time/batch = 0.6920s	
14900/33150 (epoch 22.474), train_loss = 1.11797023, grad/param norm = 2.0671e-01, time/batch = 0.6962s	
14901/33150 (epoch 22.475), train_loss = 1.24461615, grad/param norm = 1.6332e-01, time/batch = 0.6904s	
14902/33150 (epoch 22.477), train_loss = 1.11005860, grad/param norm = 1.7783e-01, time/batch = 0.6823s	
14903/33150 (epoch 22.478), train_loss = 1.08576012, grad/param norm = 1.5644e-01, time/batch = 0.7002s	
14904/33150 (epoch 22.480), train_loss = 0.93670434, grad/param norm = 1.5715e-01, time/batch = 0.6976s	
14905/33150 (epoch 22.481), train_loss = 0.84203569, grad/param norm = 1.5414e-01, time/batch = 0.6904s	
14906/33150 (epoch 22.483), train_loss = 0.94774952, grad/param norm = 1.5238e-01, time/batch = 0.6707s	
14907/33150 (epoch 22.484), train_loss = 0.93827504, grad/param norm = 1.6237e-01, time/batch = 0.6713s	
14908/33150 (epoch 22.486), train_loss = 0.92940063, grad/param norm = 1.5202e-01, time/batch = 0.6808s	
14909/33150 (epoch 22.487), train_loss = 1.00772332, grad/param norm = 1.6531e-01, time/batch = 0.6899s	
14910/33150 (epoch 22.489), train_loss = 0.99694983, grad/param norm = 1.7272e-01, time/batch = 0.6822s	
14911/33150 (epoch 22.490), train_loss = 0.83300105, grad/param norm = 1.4399e-01, time/batch = 0.6710s	
14912/33150 (epoch 22.492), train_loss = 0.93785280, grad/param norm = 1.6009e-01, time/batch = 0.6762s	
14913/33150 (epoch 22.493), train_loss = 1.06665883, grad/param norm = 1.6334e-01, time/batch = 0.6852s	
14914/33150 (epoch 22.495), train_loss = 1.07968046, grad/param norm = 1.5611e-01, time/batch = 0.6756s	
14915/33150 (epoch 22.496), train_loss = 0.98269362, grad/param norm = 1.6219e-01, time/batch = 0.6709s	
14916/33150 (epoch 22.498), train_loss = 1.12986796, grad/param norm = 2.1548e-01, time/batch = 0.6730s	
14917/33150 (epoch 22.499), train_loss = 1.10382399, grad/param norm = 1.6841e-01, time/batch = 0.6852s	
14918/33150 (epoch 22.501), train_loss = 1.04843618, grad/param norm = 1.6222e-01, time/batch = 0.6782s	
14919/33150 (epoch 22.502), train_loss = 1.12859228, grad/param norm = 1.8262e-01, time/batch = 0.6800s	
14920/33150 (epoch 22.504), train_loss = 1.07225182, grad/param norm = 1.7712e-01, time/batch = 0.6760s	
14921/33150 (epoch 22.505), train_loss = 1.18315328, grad/param norm = 1.9543e-01, time/batch = 0.6715s	
14922/33150 (epoch 22.507), train_loss = 0.98288149, grad/param norm = 1.6790e-01, time/batch = 0.6712s	
14923/33150 (epoch 22.508), train_loss = 0.96089535, grad/param norm = 1.5814e-01, time/batch = 0.6894s	
14924/33150 (epoch 22.510), train_loss = 1.03645711, grad/param norm = 1.5150e-01, time/batch = 0.6779s	
14925/33150 (epoch 22.511), train_loss = 1.11285441, grad/param norm = 1.6431e-01, time/batch = 0.6856s	
14926/33150 (epoch 22.513), train_loss = 1.01678236, grad/param norm = 1.6785e-01, time/batch = 0.6793s	
14927/33150 (epoch 22.514), train_loss = 0.84346915, grad/param norm = 1.4623e-01, time/batch = 0.6755s	
14928/33150 (epoch 22.516), train_loss = 1.04119054, grad/param norm = 1.7966e-01, time/batch = 0.6848s	
14929/33150 (epoch 22.517), train_loss = 1.11082148, grad/param norm = 1.6214e-01, time/batch = 0.6744s	
14930/33150 (epoch 22.519), train_loss = 0.90669462, grad/param norm = 1.4362e-01, time/batch = 0.6700s	
14931/33150 (epoch 22.520), train_loss = 1.01088425, grad/param norm = 1.4801e-01, time/batch = 0.6801s	
14932/33150 (epoch 22.522), train_loss = 1.12268760, grad/param norm = 1.6994e-01, time/batch = 0.6808s	
14933/33150 (epoch 22.523), train_loss = 0.91716148, grad/param norm = 1.3664e-01, time/batch = 0.6713s	
14934/33150 (epoch 22.525), train_loss = 1.07180304, grad/param norm = 1.7972e-01, time/batch = 0.6727s	
14935/33150 (epoch 22.526), train_loss = 0.93452998, grad/param norm = 1.6800e-01, time/batch = 0.6760s	
14936/33150 (epoch 22.528), train_loss = 1.04030971, grad/param norm = 1.5189e-01, time/batch = 0.6713s	
14937/33150 (epoch 22.529), train_loss = 0.98213540, grad/param norm = 1.5616e-01, time/batch = 0.6761s	
14938/33150 (epoch 22.531), train_loss = 0.83785116, grad/param norm = 1.5812e-01, time/batch = 0.6715s	
14939/33150 (epoch 22.532), train_loss = 1.03872807, grad/param norm = 1.6844e-01, time/batch = 0.6712s	
14940/33150 (epoch 22.534), train_loss = 0.96911692, grad/param norm = 1.3526e-01, time/batch = 0.6801s	
14941/33150 (epoch 22.535), train_loss = 0.92604177, grad/param norm = 1.9203e-01, time/batch = 0.6881s	
14942/33150 (epoch 22.537), train_loss = 1.05410560, grad/param norm = 1.6773e-01, time/batch = 0.6873s	
14943/33150 (epoch 22.538), train_loss = 0.94815855, grad/param norm = 1.6187e-01, time/batch = 0.6800s	
14944/33150 (epoch 22.540), train_loss = 0.85988781, grad/param norm = 1.4139e-01, time/batch = 0.6923s	
14945/33150 (epoch 22.541), train_loss = 1.09004833, grad/param norm = 1.6395e-01, time/batch = 0.6943s	
14946/33150 (epoch 22.543), train_loss = 0.99555842, grad/param norm = 1.5727e-01, time/batch = 0.6975s	
14947/33150 (epoch 22.544), train_loss = 1.05427297, grad/param norm = 1.5349e-01, time/batch = 0.6888s	
14948/33150 (epoch 22.546), train_loss = 1.03555281, grad/param norm = 1.7021e-01, time/batch = 0.6767s	
14949/33150 (epoch 22.548), train_loss = 0.99344288, grad/param norm = 1.6997e-01, time/batch = 0.6733s	
14950/33150 (epoch 22.549), train_loss = 0.92660430, grad/param norm = 1.4597e-01, time/batch = 0.6758s	
14951/33150 (epoch 22.551), train_loss = 0.89864454, grad/param norm = 1.3952e-01, time/batch = 0.6732s	
14952/33150 (epoch 22.552), train_loss = 0.78815331, grad/param norm = 1.3129e-01, time/batch = 0.6712s	
14953/33150 (epoch 22.554), train_loss = 1.07416754, grad/param norm = 1.6205e-01, time/batch = 0.6721s	
14954/33150 (epoch 22.555), train_loss = 1.11255406, grad/param norm = 1.5919e-01, time/batch = 0.6954s	
14955/33150 (epoch 22.557), train_loss = 0.81819672, grad/param norm = 1.5659e-01, time/batch = 0.6972s	
14956/33150 (epoch 22.558), train_loss = 1.07093098, grad/param norm = 1.9163e-01, time/batch = 0.7068s	
14957/33150 (epoch 22.560), train_loss = 0.95644694, grad/param norm = 1.4948e-01, time/batch = 0.6961s	
14958/33150 (epoch 22.561), train_loss = 0.85638814, grad/param norm = 1.6219e-01, time/batch = 0.6952s	
14959/33150 (epoch 22.563), train_loss = 1.07419720, grad/param norm = 2.1289e-01, time/batch = 0.7093s	
14960/33150 (epoch 22.564), train_loss = 1.15293760, grad/param norm = 1.6455e-01, time/batch = 0.7044s	
14961/33150 (epoch 22.566), train_loss = 0.95775484, grad/param norm = 1.5234e-01, time/batch = 0.7063s	
14962/33150 (epoch 22.567), train_loss = 0.90612238, grad/param norm = 1.5035e-01, time/batch = 0.7078s	
14963/33150 (epoch 22.569), train_loss = 1.02649695, grad/param norm = 1.5212e-01, time/batch = 0.7070s	
14964/33150 (epoch 22.570), train_loss = 1.05972010, grad/param norm = 1.5628e-01, time/batch = 0.7103s	
14965/33150 (epoch 22.572), train_loss = 0.90467627, grad/param norm = 1.6384e-01, time/batch = 0.6979s	
14966/33150 (epoch 22.573), train_loss = 0.80738058, grad/param norm = 1.2716e-01, time/batch = 0.7073s	
14967/33150 (epoch 22.575), train_loss = 0.97990379, grad/param norm = 1.6367e-01, time/batch = 0.6723s	
14968/33150 (epoch 22.576), train_loss = 0.84995993, grad/param norm = 1.2931e-01, time/batch = 0.6715s	
14969/33150 (epoch 22.578), train_loss = 0.91998096, grad/param norm = 1.5175e-01, time/batch = 0.6712s	
14970/33150 (epoch 22.579), train_loss = 0.84132419, grad/param norm = 1.4354e-01, time/batch = 0.6708s	
14971/33150 (epoch 22.581), train_loss = 0.92239386, grad/param norm = 1.6930e-01, time/batch = 0.6769s	
14972/33150 (epoch 22.582), train_loss = 1.11040623, grad/param norm = 1.4960e-01, time/batch = 0.6769s	
14973/33150 (epoch 22.584), train_loss = 1.06756544, grad/param norm = 1.6656e-01, time/batch = 0.6749s	
14974/33150 (epoch 22.585), train_loss = 0.99532928, grad/param norm = 1.5683e-01, time/batch = 0.6753s	
14975/33150 (epoch 22.587), train_loss = 1.00429604, grad/param norm = 1.4707e-01, time/batch = 0.6719s	
14976/33150 (epoch 22.588), train_loss = 0.90317215, grad/param norm = 1.6079e-01, time/batch = 0.6727s	
14977/33150 (epoch 22.590), train_loss = 1.01047881, grad/param norm = 1.5975e-01, time/batch = 0.6708s	
14978/33150 (epoch 22.591), train_loss = 0.97061982, grad/param norm = 1.6833e-01, time/batch = 0.6715s	
14979/33150 (epoch 22.593), train_loss = 1.05381366, grad/param norm = 1.6727e-01, time/batch = 0.6750s	
14980/33150 (epoch 22.594), train_loss = 0.99502812, grad/param norm = 1.7010e-01, time/batch = 0.6851s	
14981/33150 (epoch 22.596), train_loss = 0.93737436, grad/param norm = 1.4700e-01, time/batch = 0.6725s	
14982/33150 (epoch 22.597), train_loss = 0.88679132, grad/param norm = 2.6225e-01, time/batch = 0.6696s	
14983/33150 (epoch 22.599), train_loss = 1.16469898, grad/param norm = 2.0434e-01, time/batch = 0.6739s	
14984/33150 (epoch 22.600), train_loss = 0.98929030, grad/param norm = 2.2562e-01, time/batch = 0.6678s	
14985/33150 (epoch 22.602), train_loss = 0.97497514, grad/param norm = 1.6683e-01, time/batch = 0.6762s	
14986/33150 (epoch 22.603), train_loss = 1.07161383, grad/param norm = 1.7140e-01, time/batch = 0.6900s	
14987/33150 (epoch 22.605), train_loss = 0.91290168, grad/param norm = 1.5531e-01, time/batch = 0.6911s	
14988/33150 (epoch 22.606), train_loss = 0.95307125, grad/param norm = 1.7792e-01, time/batch = 0.6888s	
14989/33150 (epoch 22.608), train_loss = 1.05850873, grad/param norm = 1.4998e-01, time/batch = 0.7003s	
14990/33150 (epoch 22.609), train_loss = 0.97890896, grad/param norm = 1.7819e-01, time/batch = 0.6875s	
14991/33150 (epoch 22.611), train_loss = 0.88791660, grad/param norm = 1.4640e-01, time/batch = 0.6723s	
14992/33150 (epoch 22.612), train_loss = 0.99357239, grad/param norm = 1.5874e-01, time/batch = 0.6970s	
14993/33150 (epoch 22.614), train_loss = 0.88738120, grad/param norm = 1.4695e-01, time/batch = 0.6821s	
14994/33150 (epoch 22.615), train_loss = 0.88050043, grad/param norm = 1.4812e-01, time/batch = 0.6936s	
14995/33150 (epoch 22.617), train_loss = 1.01009238, grad/param norm = 1.9129e-01, time/batch = 0.6842s	
14996/33150 (epoch 22.618), train_loss = 1.02329486, grad/param norm = 1.6519e-01, time/batch = 0.6944s	
14997/33150 (epoch 22.620), train_loss = 0.91039469, grad/param norm = 1.5461e-01, time/batch = 0.6946s	
14998/33150 (epoch 22.621), train_loss = 0.98870850, grad/param norm = 1.5383e-01, time/batch = 0.6890s	
14999/33150 (epoch 22.623), train_loss = 1.06236127, grad/param norm = 1.6072e-01, time/batch = 0.6743s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch22.62_1.6514.t7	
15000/33150 (epoch 22.624), train_loss = 0.94729483, grad/param norm = 1.6084e-01, time/batch = 0.6730s	
15001/33150 (epoch 22.626), train_loss = 1.28822398, grad/param norm = 1.6224e-01, time/batch = 0.6822s	
15002/33150 (epoch 22.627), train_loss = 0.89237556, grad/param norm = 1.5372e-01, time/batch = 0.6766s	
15003/33150 (epoch 22.629), train_loss = 0.83624595, grad/param norm = 1.4350e-01, time/batch = 0.6783s	
15004/33150 (epoch 22.630), train_loss = 0.93142889, grad/param norm = 1.4571e-01, time/batch = 0.6792s	
15005/33150 (epoch 22.632), train_loss = 0.85431911, grad/param norm = 1.3071e-01, time/batch = 0.6730s	
15006/33150 (epoch 22.633), train_loss = 0.86240511, grad/param norm = 2.0732e-01, time/batch = 0.6715s	
15007/33150 (epoch 22.635), train_loss = 1.16824850, grad/param norm = 1.8033e-01, time/batch = 0.6698s	
15008/33150 (epoch 22.637), train_loss = 0.84853282, grad/param norm = 1.5093e-01, time/batch = 0.6813s	
15009/33150 (epoch 22.638), train_loss = 0.93140442, grad/param norm = 1.4695e-01, time/batch = 0.6727s	
15010/33150 (epoch 22.640), train_loss = 1.05986339, grad/param norm = 1.6635e-01, time/batch = 0.6709s	
15011/33150 (epoch 22.641), train_loss = 0.86603684, grad/param norm = 1.6609e-01, time/batch = 0.6683s	
15012/33150 (epoch 22.643), train_loss = 0.94902414, grad/param norm = 1.6130e-01, time/batch = 0.6704s	
15013/33150 (epoch 22.644), train_loss = 1.13411925, grad/param norm = 1.6889e-01, time/batch = 0.6710s	
15014/33150 (epoch 22.646), train_loss = 0.93688753, grad/param norm = 1.4651e-01, time/batch = 0.6834s	
15015/33150 (epoch 22.647), train_loss = 1.18737087, grad/param norm = 1.7589e-01, time/batch = 0.6820s	
15016/33150 (epoch 22.649), train_loss = 1.05647955, grad/param norm = 1.6544e-01, time/batch = 0.6739s	
15017/33150 (epoch 22.650), train_loss = 0.86297114, grad/param norm = 1.3405e-01, time/batch = 0.6730s	
15018/33150 (epoch 22.652), train_loss = 1.09214571, grad/param norm = 1.6107e-01, time/batch = 0.6755s	
15019/33150 (epoch 22.653), train_loss = 1.00483217, grad/param norm = 1.4290e-01, time/batch = 0.6737s	
15020/33150 (epoch 22.655), train_loss = 1.03012791, grad/param norm = 1.6951e-01, time/batch = 0.6763s	
15021/33150 (epoch 22.656), train_loss = 0.93736336, grad/param norm = 1.5209e-01, time/batch = 0.6761s	
15022/33150 (epoch 22.658), train_loss = 0.94372790, grad/param norm = 1.6155e-01, time/batch = 0.6731s	
15023/33150 (epoch 22.659), train_loss = 1.25578739, grad/param norm = 2.6639e-01, time/batch = 0.6719s	
15024/33150 (epoch 22.661), train_loss = 0.97922757, grad/param norm = 1.6370e-01, time/batch = 0.6731s	
15025/33150 (epoch 22.662), train_loss = 0.89713603, grad/param norm = 1.5456e-01, time/batch = 0.6737s	
15026/33150 (epoch 22.664), train_loss = 1.12730216, grad/param norm = 1.8144e-01, time/batch = 0.6891s	
15027/33150 (epoch 22.665), train_loss = 1.06430428, grad/param norm = 1.7224e-01, time/batch = 0.6863s	
15028/33150 (epoch 22.667), train_loss = 1.11635047, grad/param norm = 1.7423e-01, time/batch = 0.6881s	
15029/33150 (epoch 22.668), train_loss = 1.09577188, grad/param norm = 1.6714e-01, time/batch = 0.6866s	
15030/33150 (epoch 22.670), train_loss = 0.91590230, grad/param norm = 1.3166e-01, time/batch = 0.6814s	
15031/33150 (epoch 22.671), train_loss = 0.93199855, grad/param norm = 1.6005e-01, time/batch = 0.6908s	
15032/33150 (epoch 22.673), train_loss = 1.11838817, grad/param norm = 1.4520e-01, time/batch = 0.6847s	
15033/33150 (epoch 22.674), train_loss = 0.99848235, grad/param norm = 1.5788e-01, time/batch = 0.6866s	
15034/33150 (epoch 22.676), train_loss = 0.96652531, grad/param norm = 1.4644e-01, time/batch = 0.6868s	
15035/33150 (epoch 22.677), train_loss = 1.16922423, grad/param norm = 1.6819e-01, time/batch = 0.6784s	
15036/33150 (epoch 22.679), train_loss = 0.99516571, grad/param norm = 1.4632e-01, time/batch = 0.6772s	
15037/33150 (epoch 22.680), train_loss = 1.10490713, grad/param norm = 1.5526e-01, time/batch = 0.6819s	
15038/33150 (epoch 22.682), train_loss = 0.96539289, grad/param norm = 1.4612e-01, time/batch = 0.6703s	
15039/33150 (epoch 22.683), train_loss = 0.85279274, grad/param norm = 1.3248e-01, time/batch = 0.6852s	
15040/33150 (epoch 22.685), train_loss = 0.96105635, grad/param norm = 1.7691e-01, time/batch = 0.6792s	
15041/33150 (epoch 22.686), train_loss = 0.85322244, grad/param norm = 1.4692e-01, time/batch = 0.6731s	
15042/33150 (epoch 22.688), train_loss = 0.87739040, grad/param norm = 1.4854e-01, time/batch = 0.6733s	
15043/33150 (epoch 22.689), train_loss = 0.91635223, grad/param norm = 1.4964e-01, time/batch = 0.6729s	
15044/33150 (epoch 22.691), train_loss = 0.77647945, grad/param norm = 1.3089e-01, time/batch = 0.6713s	
15045/33150 (epoch 22.692), train_loss = 0.88693709, grad/param norm = 1.4760e-01, time/batch = 0.6726s	
15046/33150 (epoch 22.694), train_loss = 0.77764813, grad/param norm = 1.3208e-01, time/batch = 0.6731s	
15047/33150 (epoch 22.695), train_loss = 0.91988989, grad/param norm = 1.4080e-01, time/batch = 0.6742s	
15048/33150 (epoch 22.697), train_loss = 0.83112915, grad/param norm = 1.2906e-01, time/batch = 0.6703s	
15049/33150 (epoch 22.698), train_loss = 0.89057018, grad/param norm = 1.4038e-01, time/batch = 0.6729s	
15050/33150 (epoch 22.700), train_loss = 0.74292887, grad/param norm = 1.2076e-01, time/batch = 0.6755s	
15051/33150 (epoch 22.701), train_loss = 0.84691929, grad/param norm = 1.3596e-01, time/batch = 0.6840s	
15052/33150 (epoch 22.703), train_loss = 0.95878497, grad/param norm = 1.5570e-01, time/batch = 0.6756s	
15053/33150 (epoch 22.704), train_loss = 0.82374839, grad/param norm = 1.3245e-01, time/batch = 0.6704s	
15054/33150 (epoch 22.706), train_loss = 0.92453292, grad/param norm = 1.4323e-01, time/batch = 0.6700s	
15055/33150 (epoch 22.707), train_loss = 0.91180218, grad/param norm = 1.4777e-01, time/batch = 0.6721s	
15056/33150 (epoch 22.709), train_loss = 0.96185600, grad/param norm = 1.3489e-01, time/batch = 0.6705s	
15057/33150 (epoch 22.710), train_loss = 0.97260709, grad/param norm = 1.6616e-01, time/batch = 0.6736s	
15058/33150 (epoch 22.712), train_loss = 1.02888121, grad/param norm = 1.6184e-01, time/batch = 0.6756s	
15059/33150 (epoch 22.713), train_loss = 1.01488515, grad/param norm = 1.4676e-01, time/batch = 0.6682s	
15060/33150 (epoch 22.715), train_loss = 0.92232920, grad/param norm = 1.3826e-01, time/batch = 0.6686s	
15061/33150 (epoch 22.716), train_loss = 1.00518047, grad/param norm = 1.5717e-01, time/batch = 0.6713s	
15062/33150 (epoch 22.718), train_loss = 0.99843393, grad/param norm = 1.5334e-01, time/batch = 0.6684s	
15063/33150 (epoch 22.719), train_loss = 1.06572395, grad/param norm = 1.6600e-01, time/batch = 0.6690s	
15064/33150 (epoch 22.721), train_loss = 0.95319308, grad/param norm = 1.7472e-01, time/batch = 0.6875s	
15065/33150 (epoch 22.722), train_loss = 0.99132332, grad/param norm = 1.4739e-01, time/batch = 0.6937s	
15066/33150 (epoch 22.724), train_loss = 0.94987268, grad/param norm = 1.4719e-01, time/batch = 0.7021s	
15067/33150 (epoch 22.725), train_loss = 1.08683282, grad/param norm = 1.8458e-01, time/batch = 0.6982s	
15068/33150 (epoch 22.727), train_loss = 1.02832166, grad/param norm = 1.9072e-01, time/batch = 0.6782s	
15069/33150 (epoch 22.729), train_loss = 0.95749375, grad/param norm = 1.5252e-01, time/batch = 0.6708s	
15070/33150 (epoch 22.730), train_loss = 1.02458865, grad/param norm = 1.7504e-01, time/batch = 0.6876s	
15071/33150 (epoch 22.732), train_loss = 1.07234604, grad/param norm = 1.7929e-01, time/batch = 0.7009s	
15072/33150 (epoch 22.733), train_loss = 0.81181296, grad/param norm = 1.3019e-01, time/batch = 0.6980s	
15073/33150 (epoch 22.735), train_loss = 0.89010793, grad/param norm = 1.5190e-01, time/batch = 0.6916s	
15074/33150 (epoch 22.736), train_loss = 0.94590451, grad/param norm = 1.6232e-01, time/batch = 0.6927s	
15075/33150 (epoch 22.738), train_loss = 0.97928075, grad/param norm = 1.6345e-01, time/batch = 0.6801s	
15076/33150 (epoch 22.739), train_loss = 1.07290860, grad/param norm = 1.7123e-01, time/batch = 0.6795s	
15077/33150 (epoch 22.741), train_loss = 1.07138095, grad/param norm = 1.6572e-01, time/batch = 0.6811s	
15078/33150 (epoch 22.742), train_loss = 0.87524221, grad/param norm = 1.7567e-01, time/batch = 0.6802s	
15079/33150 (epoch 22.744), train_loss = 1.07845100, grad/param norm = 1.6992e-01, time/batch = 0.6770s	
15080/33150 (epoch 22.745), train_loss = 0.93877846, grad/param norm = 1.3618e-01, time/batch = 0.6743s	
15081/33150 (epoch 22.747), train_loss = 0.76815620, grad/param norm = 1.4489e-01, time/batch = 0.6783s	
15082/33150 (epoch 22.748), train_loss = 0.88996721, grad/param norm = 1.4646e-01, time/batch = 0.6979s	
15083/33150 (epoch 22.750), train_loss = 1.02126744, grad/param norm = 1.6715e-01, time/batch = 0.6847s	
15084/33150 (epoch 22.751), train_loss = 0.97659548, grad/param norm = 1.5142e-01, time/batch = 0.6742s	
15085/33150 (epoch 22.753), train_loss = 0.82357887, grad/param norm = 1.4721e-01, time/batch = 0.6847s	
15086/33150 (epoch 22.754), train_loss = 1.19681097, grad/param norm = 2.0035e-01, time/batch = 0.6723s	
15087/33150 (epoch 22.756), train_loss = 0.99998349, grad/param norm = 1.7581e-01, time/batch = 0.6732s	
15088/33150 (epoch 22.757), train_loss = 0.99965249, grad/param norm = 1.6211e-01, time/batch = 0.6694s	
15089/33150 (epoch 22.759), train_loss = 1.11687863, grad/param norm = 1.7811e-01, time/batch = 0.6693s	
15090/33150 (epoch 22.760), train_loss = 1.02334134, grad/param norm = 1.6030e-01, time/batch = 0.6689s	
15091/33150 (epoch 22.762), train_loss = 0.99390284, grad/param norm = 1.7480e-01, time/batch = 0.6759s	
15092/33150 (epoch 22.763), train_loss = 1.02722892, grad/param norm = 1.6827e-01, time/batch = 0.6860s	
15093/33150 (epoch 22.765), train_loss = 0.97307229, grad/param norm = 1.4883e-01, time/batch = 0.6782s	
15094/33150 (epoch 22.766), train_loss = 0.91162143, grad/param norm = 1.9927e-01, time/batch = 0.6715s	
15095/33150 (epoch 22.768), train_loss = 0.91629937, grad/param norm = 1.5704e-01, time/batch = 0.6713s	
15096/33150 (epoch 22.769), train_loss = 1.03417721, grad/param norm = 1.9108e-01, time/batch = 0.6703s	
15097/33150 (epoch 22.771), train_loss = 0.99971473, grad/param norm = 1.6147e-01, time/batch = 0.6681s	
15098/33150 (epoch 22.772), train_loss = 1.05229984, grad/param norm = 1.7403e-01, time/batch = 0.6725s	
15099/33150 (epoch 22.774), train_loss = 1.16661128, grad/param norm = 1.6422e-01, time/batch = 0.6721s	
15100/33150 (epoch 22.775), train_loss = 1.04505928, grad/param norm = 1.9537e-01, time/batch = 0.6669s	
15101/33150 (epoch 22.777), train_loss = 1.03446609, grad/param norm = 1.6212e-01, time/batch = 0.6659s	
15102/33150 (epoch 22.778), train_loss = 1.00048665, grad/param norm = 1.3955e-01, time/batch = 0.6677s	
15103/33150 (epoch 22.780), train_loss = 0.83982910, grad/param norm = 1.3964e-01, time/batch = 0.6717s	
15104/33150 (epoch 22.781), train_loss = 0.97870690, grad/param norm = 1.4190e-01, time/batch = 0.6706s	
15105/33150 (epoch 22.783), train_loss = 0.98288542, grad/param norm = 1.4860e-01, time/batch = 0.6691s	
15106/33150 (epoch 22.784), train_loss = 0.97350774, grad/param norm = 1.7206e-01, time/batch = 0.6725s	
15107/33150 (epoch 22.786), train_loss = 0.96309734, grad/param norm = 1.3933e-01, time/batch = 0.6710s	
15108/33150 (epoch 22.787), train_loss = 0.91954537, grad/param norm = 1.4202e-01, time/batch = 0.6756s	
15109/33150 (epoch 22.789), train_loss = 0.81916131, grad/param norm = 1.4936e-01, time/batch = 0.6764s	
15110/33150 (epoch 22.790), train_loss = 0.87358823, grad/param norm = 1.3937e-01, time/batch = 0.6719s	
15111/33150 (epoch 22.792), train_loss = 1.01691450, grad/param norm = 1.8187e-01, time/batch = 0.6851s	
15112/33150 (epoch 22.793), train_loss = 0.95214589, grad/param norm = 1.6293e-01, time/batch = 0.6809s	
15113/33150 (epoch 22.795), train_loss = 0.94735500, grad/param norm = 1.7372e-01, time/batch = 0.6731s	
15114/33150 (epoch 22.796), train_loss = 0.93278043, grad/param norm = 1.4458e-01, time/batch = 0.6707s	
15115/33150 (epoch 22.798), train_loss = 0.91732970, grad/param norm = 1.3833e-01, time/batch = 0.6730s	
15116/33150 (epoch 22.799), train_loss = 0.81624184, grad/param norm = 1.5532e-01, time/batch = 0.6735s	
15117/33150 (epoch 22.801), train_loss = 0.99524703, grad/param norm = 1.5146e-01, time/batch = 0.6753s	
15118/33150 (epoch 22.802), train_loss = 0.88124111, grad/param norm = 1.4781e-01, time/batch = 0.6749s	
15119/33150 (epoch 22.804), train_loss = 0.93515948, grad/param norm = 1.5828e-01, time/batch = 0.6752s	
15120/33150 (epoch 22.805), train_loss = 0.91081926, grad/param norm = 1.7133e-01, time/batch = 0.6738s	
15121/33150 (epoch 22.807), train_loss = 0.90964257, grad/param norm = 1.2943e-01, time/batch = 0.6764s	
15122/33150 (epoch 22.808), train_loss = 1.04823999, grad/param norm = 1.5502e-01, time/batch = 0.6745s	
15123/33150 (epoch 22.810), train_loss = 0.91679532, grad/param norm = 1.5612e-01, time/batch = 0.6758s	
15124/33150 (epoch 22.811), train_loss = 1.01135017, grad/param norm = 1.8062e-01, time/batch = 0.6759s	
15125/33150 (epoch 22.813), train_loss = 0.93964740, grad/param norm = 1.3817e-01, time/batch = 0.6775s	
15126/33150 (epoch 22.814), train_loss = 0.93684832, grad/param norm = 1.6539e-01, time/batch = 0.6851s	
15127/33150 (epoch 22.816), train_loss = 0.94266942, grad/param norm = 1.6420e-01, time/batch = 0.6809s	
15128/33150 (epoch 22.817), train_loss = 1.03077809, grad/param norm = 1.5388e-01, time/batch = 0.6785s	
15129/33150 (epoch 22.819), train_loss = 0.97301632, grad/param norm = 1.4528e-01, time/batch = 0.6739s	
15130/33150 (epoch 22.821), train_loss = 0.86438898, grad/param norm = 1.3812e-01, time/batch = 0.6772s	
15131/33150 (epoch 22.822), train_loss = 0.91225078, grad/param norm = 1.5549e-01, time/batch = 0.6793s	
15132/33150 (epoch 22.824), train_loss = 0.94309969, grad/param norm = 1.5023e-01, time/batch = 0.6721s	
15133/33150 (epoch 22.825), train_loss = 0.98597991, grad/param norm = 1.5421e-01, time/batch = 0.6753s	
15134/33150 (epoch 22.827), train_loss = 1.03152960, grad/param norm = 1.8147e-01, time/batch = 0.6733s	
15135/33150 (epoch 22.828), train_loss = 0.87287271, grad/param norm = 1.7267e-01, time/batch = 0.6761s	
15136/33150 (epoch 22.830), train_loss = 1.05751336, grad/param norm = 1.7650e-01, time/batch = 0.6782s	
15137/33150 (epoch 22.831), train_loss = 0.90609194, grad/param norm = 1.6657e-01, time/batch = 0.6789s	
15138/33150 (epoch 22.833), train_loss = 0.89228394, grad/param norm = 1.4666e-01, time/batch = 0.6762s	
15139/33150 (epoch 22.834), train_loss = 1.07930247, grad/param norm = 1.6636e-01, time/batch = 0.6763s	
15140/33150 (epoch 22.836), train_loss = 1.07939960, grad/param norm = 1.4382e-01, time/batch = 0.6801s	
15141/33150 (epoch 22.837), train_loss = 0.95262810, grad/param norm = 1.5237e-01, time/batch = 0.6860s	
15142/33150 (epoch 22.839), train_loss = 1.03584927, grad/param norm = 1.6822e-01, time/batch = 0.6768s	
15143/33150 (epoch 22.840), train_loss = 1.03939846, grad/param norm = 1.5456e-01, time/batch = 0.6812s	
15144/33150 (epoch 22.842), train_loss = 1.11192222, grad/param norm = 1.7461e-01, time/batch = 0.6745s	
15145/33150 (epoch 22.843), train_loss = 1.06822039, grad/param norm = 1.6170e-01, time/batch = 0.6883s	
15146/33150 (epoch 22.845), train_loss = 0.90122409, grad/param norm = 1.3744e-01, time/batch = 0.6793s	
15147/33150 (epoch 22.846), train_loss = 1.14543665, grad/param norm = 1.9677e-01, time/batch = 0.6706s	
15148/33150 (epoch 22.848), train_loss = 1.07458416, grad/param norm = 1.6702e-01, time/batch = 0.6755s	
15149/33150 (epoch 22.849), train_loss = 1.09993034, grad/param norm = 1.6720e-01, time/batch = 0.6764s	
15150/33150 (epoch 22.851), train_loss = 1.05171578, grad/param norm = 1.6618e-01, time/batch = 0.6752s	
15151/33150 (epoch 22.852), train_loss = 1.12625423, grad/param norm = 1.5117e-01, time/batch = 0.6757s	
15152/33150 (epoch 22.854), train_loss = 0.99859397, grad/param norm = 1.6250e-01, time/batch = 0.6864s	
15153/33150 (epoch 22.855), train_loss = 0.83647242, grad/param norm = 1.3282e-01, time/batch = 0.6930s	
15154/33150 (epoch 22.857), train_loss = 0.83627124, grad/param norm = 1.3734e-01, time/batch = 0.6837s	
15155/33150 (epoch 22.858), train_loss = 0.92691339, grad/param norm = 1.4934e-01, time/batch = 0.6849s	
15156/33150 (epoch 22.860), train_loss = 0.86892210, grad/param norm = 1.4380e-01, time/batch = 0.6725s	
15157/33150 (epoch 22.861), train_loss = 0.86679805, grad/param norm = 1.4186e-01, time/batch = 0.6707s	
15158/33150 (epoch 22.863), train_loss = 0.98882159, grad/param norm = 1.4372e-01, time/batch = 0.6863s	
15159/33150 (epoch 22.864), train_loss = 1.06370617, grad/param norm = 1.5376e-01, time/batch = 0.6738s	
15160/33150 (epoch 22.866), train_loss = 1.03038966, grad/param norm = 1.5241e-01, time/batch = 0.6669s	
15161/33150 (epoch 22.867), train_loss = 1.01996544, grad/param norm = 1.4733e-01, time/batch = 0.6735s	
15162/33150 (epoch 22.869), train_loss = 1.03281342, grad/param norm = 1.7058e-01, time/batch = 0.6711s	
15163/33150 (epoch 22.870), train_loss = 0.96088456, grad/param norm = 1.5580e-01, time/batch = 0.6737s	
15164/33150 (epoch 22.872), train_loss = 1.00200554, grad/param norm = 1.5712e-01, time/batch = 0.6849s	
15165/33150 (epoch 22.873), train_loss = 0.83170722, grad/param norm = 1.3395e-01, time/batch = 0.6941s	
15166/33150 (epoch 22.875), train_loss = 1.11078229, grad/param norm = 1.5836e-01, time/batch = 0.6928s	
15167/33150 (epoch 22.876), train_loss = 0.85207726, grad/param norm = 1.5209e-01, time/batch = 0.6921s	
15168/33150 (epoch 22.878), train_loss = 0.87598005, grad/param norm = 1.3395e-01, time/batch = 0.6979s	
15169/33150 (epoch 22.879), train_loss = 0.90362255, grad/param norm = 1.4645e-01, time/batch = 0.6939s	
15170/33150 (epoch 22.881), train_loss = 0.89665991, grad/param norm = 1.5518e-01, time/batch = 0.6854s	
15171/33150 (epoch 22.882), train_loss = 0.80562757, grad/param norm = 1.4210e-01, time/batch = 0.6838s	
15172/33150 (epoch 22.884), train_loss = 0.94856322, grad/param norm = 1.4853e-01, time/batch = 0.6761s	
15173/33150 (epoch 22.885), train_loss = 0.76073199, grad/param norm = 1.4496e-01, time/batch = 0.6815s	
15174/33150 (epoch 22.887), train_loss = 1.07929182, grad/param norm = 1.7604e-01, time/batch = 0.6846s	
15175/33150 (epoch 22.888), train_loss = 1.02049831, grad/param norm = 1.7001e-01, time/batch = 0.6744s	
15176/33150 (epoch 22.890), train_loss = 0.90877985, grad/param norm = 1.6199e-01, time/batch = 0.6870s	
15177/33150 (epoch 22.891), train_loss = 0.86576126, grad/param norm = 1.4428e-01, time/batch = 0.6761s	
15178/33150 (epoch 22.893), train_loss = 1.03653499, grad/param norm = 1.6235e-01, time/batch = 0.6742s	
15179/33150 (epoch 22.894), train_loss = 1.01825081, grad/param norm = 1.5890e-01, time/batch = 0.6836s	
15180/33150 (epoch 22.896), train_loss = 0.94952582, grad/param norm = 1.5362e-01, time/batch = 0.6737s	
15181/33150 (epoch 22.897), train_loss = 1.00428461, grad/param norm = 1.3597e-01, time/batch = 0.6739s	
15182/33150 (epoch 22.899), train_loss = 0.82652427, grad/param norm = 1.8759e-01, time/batch = 0.6826s	
15183/33150 (epoch 22.900), train_loss = 1.19033523, grad/param norm = 1.7553e-01, time/batch = 0.6703s	
15184/33150 (epoch 22.902), train_loss = 1.16154261, grad/param norm = 1.6409e-01, time/batch = 0.6682s	
15185/33150 (epoch 22.903), train_loss = 0.99373139, grad/param norm = 1.6870e-01, time/batch = 0.6689s	
15186/33150 (epoch 22.905), train_loss = 1.00144865, grad/param norm = 1.3890e-01, time/batch = 0.6681s	
15187/33150 (epoch 22.906), train_loss = 1.01296124, grad/param norm = 1.5825e-01, time/batch = 0.6671s	
15188/33150 (epoch 22.908), train_loss = 1.10475434, grad/param norm = 1.6258e-01, time/batch = 0.6691s	
15189/33150 (epoch 22.910), train_loss = 1.07301941, grad/param norm = 1.7767e-01, time/batch = 0.6847s	
15190/33150 (epoch 22.911), train_loss = 0.84569117, grad/param norm = 1.4126e-01, time/batch = 0.6745s	
15191/33150 (epoch 22.913), train_loss = 0.90261750, grad/param norm = 1.6138e-01, time/batch = 0.6703s	
15192/33150 (epoch 22.914), train_loss = 1.05603418, grad/param norm = 1.7864e-01, time/batch = 0.6729s	
15193/33150 (epoch 22.916), train_loss = 0.87952091, grad/param norm = 1.5666e-01, time/batch = 0.6731s	
15194/33150 (epoch 22.917), train_loss = 1.02390708, grad/param norm = 1.7862e-01, time/batch = 0.6720s	
15195/33150 (epoch 22.919), train_loss = 1.12530808, grad/param norm = 1.8839e-01, time/batch = 0.6697s	
15196/33150 (epoch 22.920), train_loss = 1.08571476, grad/param norm = 1.6307e-01, time/batch = 0.6713s	
15197/33150 (epoch 22.922), train_loss = 1.11209520, grad/param norm = 1.8309e-01, time/batch = 0.6723s	
15198/33150 (epoch 22.923), train_loss = 0.98759441, grad/param norm = 1.7398e-01, time/batch = 0.6744s	
15199/33150 (epoch 22.925), train_loss = 1.08736591, grad/param norm = 1.5886e-01, time/batch = 0.6721s	
15200/33150 (epoch 22.926), train_loss = 0.94316388, grad/param norm = 1.5054e-01, time/batch = 0.6710s	
15201/33150 (epoch 22.928), train_loss = 0.93663950, grad/param norm = 1.4684e-01, time/batch = 0.6732s	
15202/33150 (epoch 22.929), train_loss = 1.02693207, grad/param norm = 1.4909e-01, time/batch = 0.6720s	
15203/33150 (epoch 22.931), train_loss = 1.11662578, grad/param norm = 1.7594e-01, time/batch = 0.6787s	
15204/33150 (epoch 22.932), train_loss = 0.98423850, grad/param norm = 1.6761e-01, time/batch = 0.6801s	
15205/33150 (epoch 22.934), train_loss = 1.01006761, grad/param norm = 1.5162e-01, time/batch = 0.6732s	
15206/33150 (epoch 22.935), train_loss = 1.09158514, grad/param norm = 1.6506e-01, time/batch = 0.6749s	
15207/33150 (epoch 22.937), train_loss = 1.10184304, grad/param norm = 1.4868e-01, time/batch = 0.6773s	
15208/33150 (epoch 22.938), train_loss = 1.02798357, grad/param norm = 1.5689e-01, time/batch = 0.6779s	
15209/33150 (epoch 22.940), train_loss = 1.26364003, grad/param norm = 1.8982e-01, time/batch = 0.6787s	
15210/33150 (epoch 22.941), train_loss = 0.99317367, grad/param norm = 1.4215e-01, time/batch = 0.6769s	
15211/33150 (epoch 22.943), train_loss = 0.86997440, grad/param norm = 1.7041e-01, time/batch = 0.6833s	
15212/33150 (epoch 22.944), train_loss = 1.08890479, grad/param norm = 1.6863e-01, time/batch = 0.6874s	
15213/33150 (epoch 22.946), train_loss = 0.83757768, grad/param norm = 1.3510e-01, time/batch = 0.6917s	
15214/33150 (epoch 22.947), train_loss = 1.02217805, grad/param norm = 1.6302e-01, time/batch = 0.6910s	
15215/33150 (epoch 22.949), train_loss = 1.11188333, grad/param norm = 1.6854e-01, time/batch = 0.6874s	
15216/33150 (epoch 22.950), train_loss = 1.05049138, grad/param norm = 1.8104e-01, time/batch = 0.6869s	
15217/33150 (epoch 22.952), train_loss = 0.89501824, grad/param norm = 1.5490e-01, time/batch = 0.6886s	
15218/33150 (epoch 22.953), train_loss = 0.93280421, grad/param norm = 1.5356e-01, time/batch = 0.6794s	
15219/33150 (epoch 22.955), train_loss = 0.85365029, grad/param norm = 1.6363e-01, time/batch = 0.6821s	
15220/33150 (epoch 22.956), train_loss = 1.05026032, grad/param norm = 1.5175e-01, time/batch = 0.6822s	
15221/33150 (epoch 22.958), train_loss = 0.88612247, grad/param norm = 1.3848e-01, time/batch = 0.6688s	
15222/33150 (epoch 22.959), train_loss = 0.92889091, grad/param norm = 1.4788e-01, time/batch = 0.6706s	
15223/33150 (epoch 22.961), train_loss = 0.89454162, grad/param norm = 1.5828e-01, time/batch = 0.6692s	
15224/33150 (epoch 22.962), train_loss = 0.84268105, grad/param norm = 1.3965e-01, time/batch = 0.6734s	
15225/33150 (epoch 22.964), train_loss = 0.98562796, grad/param norm = 1.4559e-01, time/batch = 0.6761s	
15226/33150 (epoch 22.965), train_loss = 0.98344473, grad/param norm = 1.6003e-01, time/batch = 0.6772s	
15227/33150 (epoch 22.967), train_loss = 0.97621908, grad/param norm = 1.6628e-01, time/batch = 0.6700s	
15228/33150 (epoch 22.968), train_loss = 0.82971613, grad/param norm = 1.3363e-01, time/batch = 0.6720s	
15229/33150 (epoch 22.970), train_loss = 0.91713501, grad/param norm = 1.4734e-01, time/batch = 0.6713s	
15230/33150 (epoch 22.971), train_loss = 0.96356751, grad/param norm = 1.5310e-01, time/batch = 0.6714s	
15231/33150 (epoch 22.973), train_loss = 1.09487487, grad/param norm = 1.6819e-01, time/batch = 0.6725s	
15232/33150 (epoch 22.974), train_loss = 1.10987248, grad/param norm = 1.6142e-01, time/batch = 0.6752s	
15233/33150 (epoch 22.976), train_loss = 1.05473156, grad/param norm = 1.4893e-01, time/batch = 0.6851s	
15234/33150 (epoch 22.977), train_loss = 1.12354952, grad/param norm = 1.5570e-01, time/batch = 0.6989s	
15235/33150 (epoch 22.979), train_loss = 1.08888723, grad/param norm = 1.9711e-01, time/batch = 0.6946s	
15236/33150 (epoch 22.980), train_loss = 1.12729467, grad/param norm = 1.6771e-01, time/batch = 0.6946s	
15237/33150 (epoch 22.982), train_loss = 0.97613414, grad/param norm = 2.2322e-01, time/batch = 0.6813s	
15238/33150 (epoch 22.983), train_loss = 0.89434475, grad/param norm = 1.6729e-01, time/batch = 0.6826s	
15239/33150 (epoch 22.985), train_loss = 1.06739438, grad/param norm = 1.4902e-01, time/batch = 0.6739s	
15240/33150 (epoch 22.986), train_loss = 0.81957802, grad/param norm = 1.3827e-01, time/batch = 0.6891s	
15241/33150 (epoch 22.988), train_loss = 0.94217989, grad/param norm = 1.8469e-01, time/batch = 0.6966s	
15242/33150 (epoch 22.989), train_loss = 0.92782777, grad/param norm = 1.5805e-01, time/batch = 0.7030s	
15243/33150 (epoch 22.991), train_loss = 1.04608479, grad/param norm = 1.8441e-01, time/batch = 0.7050s	
15244/33150 (epoch 22.992), train_loss = 0.91190727, grad/param norm = 1.4865e-01, time/batch = 0.6859s	
15245/33150 (epoch 22.994), train_loss = 0.98788889, grad/param norm = 1.6557e-01, time/batch = 0.6812s	
15246/33150 (epoch 22.995), train_loss = 0.94802019, grad/param norm = 1.6868e-01, time/batch = 0.6639s	
15247/33150 (epoch 22.997), train_loss = 0.99021025, grad/param norm = 1.7268e-01, time/batch = 0.6683s	
15248/33150 (epoch 22.998), train_loss = 0.80094772, grad/param norm = 1.3717e-01, time/batch = 0.6675s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
15249/33150 (epoch 23.000), train_loss = 0.81862844, grad/param norm = 1.6027e-01, time/batch = 0.6693s	
15250/33150 (epoch 23.002), train_loss = 1.26580447, grad/param norm = 1.7803e-01, time/batch = 0.6716s	
15251/33150 (epoch 23.003), train_loss = 0.88728987, grad/param norm = 1.5515e-01, time/batch = 0.6829s	
15252/33150 (epoch 23.005), train_loss = 0.86826321, grad/param norm = 1.4077e-01, time/batch = 0.6948s	
15253/33150 (epoch 23.006), train_loss = 0.84846706, grad/param norm = 1.5711e-01, time/batch = 0.6833s	
15254/33150 (epoch 23.008), train_loss = 1.09053509, grad/param norm = 1.7213e-01, time/batch = 0.6725s	
15255/33150 (epoch 23.009), train_loss = 0.98207935, grad/param norm = 1.4934e-01, time/batch = 0.6701s	
15256/33150 (epoch 23.011), train_loss = 1.07744086, grad/param norm = 1.6021e-01, time/batch = 0.6707s	
15257/33150 (epoch 23.012), train_loss = 0.97745467, grad/param norm = 1.8174e-01, time/batch = 0.6759s	
15258/33150 (epoch 23.014), train_loss = 0.91187145, grad/param norm = 1.6110e-01, time/batch = 0.6670s	
15259/33150 (epoch 23.015), train_loss = 0.90832347, grad/param norm = 1.5789e-01, time/batch = 0.6701s	
15260/33150 (epoch 23.017), train_loss = 0.88570810, grad/param norm = 1.5130e-01, time/batch = 0.6708s	
15261/33150 (epoch 23.018), train_loss = 1.00847970, grad/param norm = 1.7708e-01, time/batch = 0.6707s	
15262/33150 (epoch 23.020), train_loss = 1.06770189, grad/param norm = 1.8048e-01, time/batch = 0.6732s	
15263/33150 (epoch 23.021), train_loss = 0.88111791, grad/param norm = 1.6059e-01, time/batch = 0.6691s	
15264/33150 (epoch 23.023), train_loss = 1.13526780, grad/param norm = 1.4729e-01, time/batch = 0.6699s	
15265/33150 (epoch 23.024), train_loss = 1.05036102, grad/param norm = 1.6952e-01, time/batch = 0.6722s	
15266/33150 (epoch 23.026), train_loss = 0.78576302, grad/param norm = 1.2528e-01, time/batch = 0.6760s	
15267/33150 (epoch 23.027), train_loss = 0.78772539, grad/param norm = 1.2352e-01, time/batch = 0.6703s	
15268/33150 (epoch 23.029), train_loss = 0.90600474, grad/param norm = 1.4457e-01, time/batch = 0.6759s	
15269/33150 (epoch 23.030), train_loss = 0.96354383, grad/param norm = 1.4790e-01, time/batch = 0.6838s	
15270/33150 (epoch 23.032), train_loss = 0.89294231, grad/param norm = 1.6959e-01, time/batch = 0.6833s	
15271/33150 (epoch 23.033), train_loss = 0.90174189, grad/param norm = 1.5062e-01, time/batch = 0.6740s	
15272/33150 (epoch 23.035), train_loss = 1.13366086, grad/param norm = 1.7339e-01, time/batch = 0.6837s	
15273/33150 (epoch 23.036), train_loss = 1.02733151, grad/param norm = 1.6411e-01, time/batch = 0.6745s	
15274/33150 (epoch 23.038), train_loss = 1.22980895, grad/param norm = 1.9278e-01, time/batch = 0.6721s	
15275/33150 (epoch 23.039), train_loss = 1.03837569, grad/param norm = 1.4843e-01, time/batch = 0.6715s	
15276/33150 (epoch 23.041), train_loss = 0.99091878, grad/param norm = 1.5182e-01, time/batch = 0.6710s	
15277/33150 (epoch 23.042), train_loss = 0.93527090, grad/param norm = 1.4957e-01, time/batch = 0.6689s	
15278/33150 (epoch 23.044), train_loss = 0.94836369, grad/param norm = 1.4279e-01, time/batch = 0.6699s	
15279/33150 (epoch 23.045), train_loss = 1.00791167, grad/param norm = 1.4404e-01, time/batch = 0.6690s	
15280/33150 (epoch 23.047), train_loss = 0.85496108, grad/param norm = 1.4202e-01, time/batch = 0.6700s	
15281/33150 (epoch 23.048), train_loss = 1.05769925, grad/param norm = 1.8305e-01, time/batch = 0.6783s	
15282/33150 (epoch 23.050), train_loss = 0.98956379, grad/param norm = 1.9097e-01, time/batch = 0.6850s	
15283/33150 (epoch 23.051), train_loss = 0.97520957, grad/param norm = 1.4219e-01, time/batch = 0.6702s	
15284/33150 (epoch 23.053), train_loss = 0.95559067, grad/param norm = 1.8101e-01, time/batch = 0.6734s	
15285/33150 (epoch 23.054), train_loss = 1.09145004, grad/param norm = 1.4491e-01, time/batch = 0.6722s	
15286/33150 (epoch 23.056), train_loss = 0.96816933, grad/param norm = 1.5236e-01, time/batch = 0.6734s	
15287/33150 (epoch 23.057), train_loss = 0.98547441, grad/param norm = 1.6073e-01, time/batch = 0.6745s	
15288/33150 (epoch 23.059), train_loss = 0.91146863, grad/param norm = 1.5915e-01, time/batch = 0.6774s	
15289/33150 (epoch 23.060), train_loss = 0.90824796, grad/param norm = 1.4273e-01, time/batch = 0.6809s	
15290/33150 (epoch 23.062), train_loss = 0.95863039, grad/param norm = 1.7212e-01, time/batch = 0.6748s	
15291/33150 (epoch 23.063), train_loss = 0.91283691, grad/param norm = 1.5569e-01, time/batch = 0.6730s	
15292/33150 (epoch 23.065), train_loss = 0.93967934, grad/param norm = 1.6234e-01, time/batch = 0.6706s	
15293/33150 (epoch 23.066), train_loss = 0.89248566, grad/param norm = 1.4682e-01, time/batch = 0.6687s	
15294/33150 (epoch 23.068), train_loss = 1.01490599, grad/param norm = 1.4663e-01, time/batch = 0.6687s	
15295/33150 (epoch 23.069), train_loss = 1.00433575, grad/param norm = 1.6898e-01, time/batch = 0.6711s	
15296/33150 (epoch 23.071), train_loss = 0.98878058, grad/param norm = 1.5252e-01, time/batch = 0.6796s	
15297/33150 (epoch 23.072), train_loss = 0.96614057, grad/param norm = 1.5345e-01, time/batch = 0.6826s	
15298/33150 (epoch 23.074), train_loss = 0.85736761, grad/param norm = 1.5907e-01, time/batch = 0.6740s	
15299/33150 (epoch 23.075), train_loss = 0.90051882, grad/param norm = 1.5485e-01, time/batch = 0.6724s	
15300/33150 (epoch 23.077), train_loss = 0.94726701, grad/param norm = 2.0950e-01, time/batch = 0.6721s	
15301/33150 (epoch 23.078), train_loss = 1.09047390, grad/param norm = 1.8015e-01, time/batch = 0.6745s	
15302/33150 (epoch 23.080), train_loss = 1.09644808, grad/param norm = 1.6626e-01, time/batch = 0.6756s	
15303/33150 (epoch 23.081), train_loss = 0.86659945, grad/param norm = 1.7507e-01, time/batch = 0.6730s	
15304/33150 (epoch 23.083), train_loss = 0.73722976, grad/param norm = 1.7878e-01, time/batch = 0.6749s	
15305/33150 (epoch 23.084), train_loss = 0.83768900, grad/param norm = 1.7793e-01, time/batch = 0.6719s	
15306/33150 (epoch 23.086), train_loss = 0.92223058, grad/param norm = 1.7297e-01, time/batch = 0.6737s	
15307/33150 (epoch 23.087), train_loss = 0.85399400, grad/param norm = 1.6171e-01, time/batch = 0.6702s	
15308/33150 (epoch 23.089), train_loss = 0.87275888, grad/param norm = 1.4363e-01, time/batch = 0.6742s	
15309/33150 (epoch 23.090), train_loss = 0.93575519, grad/param norm = 1.6030e-01, time/batch = 0.6733s	
15310/33150 (epoch 23.092), train_loss = 0.90196021, grad/param norm = 1.5499e-01, time/batch = 0.6730s	
15311/33150 (epoch 23.094), train_loss = 1.03720444, grad/param norm = 1.9199e-01, time/batch = 0.6750s	
15312/33150 (epoch 23.095), train_loss = 0.88108108, grad/param norm = 1.3745e-01, time/batch = 0.6807s	
15313/33150 (epoch 23.097), train_loss = 0.86924674, grad/param norm = 1.6306e-01, time/batch = 0.6742s	
15314/33150 (epoch 23.098), train_loss = 1.20059670, grad/param norm = 1.6582e-01, time/batch = 0.6728s	
15315/33150 (epoch 23.100), train_loss = 1.13006938, grad/param norm = 1.6780e-01, time/batch = 0.6743s	
15316/33150 (epoch 23.101), train_loss = 0.90084760, grad/param norm = 1.4431e-01, time/batch = 0.6841s	
15317/33150 (epoch 23.103), train_loss = 0.97801827, grad/param norm = 1.5611e-01, time/batch = 0.6663s	
15318/33150 (epoch 23.104), train_loss = 0.89578032, grad/param norm = 1.8624e-01, time/batch = 0.6676s	
15319/33150 (epoch 23.106), train_loss = 1.09632589, grad/param norm = 1.8292e-01, time/batch = 0.6714s	
15320/33150 (epoch 23.107), train_loss = 1.18519807, grad/param norm = 1.7956e-01, time/batch = 0.6705s	
15321/33150 (epoch 23.109), train_loss = 0.94918177, grad/param norm = 1.4356e-01, time/batch = 0.6773s	
15322/33150 (epoch 23.110), train_loss = 1.08080612, grad/param norm = 1.6989e-01, time/batch = 0.6806s	
15323/33150 (epoch 23.112), train_loss = 0.89007298, grad/param norm = 1.4458e-01, time/batch = 0.6697s	
15324/33150 (epoch 23.113), train_loss = 0.92727082, grad/param norm = 1.6254e-01, time/batch = 0.6671s	
15325/33150 (epoch 23.115), train_loss = 1.15206759, grad/param norm = 1.7953e-01, time/batch = 0.6734s	
15326/33150 (epoch 23.116), train_loss = 0.97044735, grad/param norm = 1.5104e-01, time/batch = 0.6747s	
15327/33150 (epoch 23.118), train_loss = 1.04133097, grad/param norm = 1.6582e-01, time/batch = 0.6754s	
15328/33150 (epoch 23.119), train_loss = 1.05840265, grad/param norm = 2.2480e-01, time/batch = 0.6790s	
15329/33150 (epoch 23.121), train_loss = 0.94558717, grad/param norm = 1.6300e-01, time/batch = 0.6921s	
15330/33150 (epoch 23.122), train_loss = 1.17684799, grad/param norm = 2.1908e-01, time/batch = 0.6907s	
15331/33150 (epoch 23.124), train_loss = 0.81531777, grad/param norm = 1.2329e-01, time/batch = 0.6873s	
15332/33150 (epoch 23.125), train_loss = 1.04799026, grad/param norm = 1.5021e-01, time/batch = 0.6751s	
15333/33150 (epoch 23.127), train_loss = 0.95950492, grad/param norm = 1.5224e-01, time/batch = 0.6717s	
15334/33150 (epoch 23.128), train_loss = 1.02402584, grad/param norm = 1.7207e-01, time/batch = 0.6715s	
15335/33150 (epoch 23.130), train_loss = 1.01540355, grad/param norm = 1.6629e-01, time/batch = 0.6805s	
15336/33150 (epoch 23.131), train_loss = 1.20309506, grad/param norm = 1.6574e-01, time/batch = 0.6975s	
15337/33150 (epoch 23.133), train_loss = 0.90352319, grad/param norm = 1.4500e-01, time/batch = 0.6736s	
15338/33150 (epoch 23.134), train_loss = 1.09254909, grad/param norm = 1.6607e-01, time/batch = 0.6774s	
15339/33150 (epoch 23.136), train_loss = 0.98927259, grad/param norm = 1.9559e-01, time/batch = 0.6801s	
15340/33150 (epoch 23.137), train_loss = 1.05936787, grad/param norm = 1.6359e-01, time/batch = 0.6782s	
15341/33150 (epoch 23.139), train_loss = 1.05612131, grad/param norm = 1.6961e-01, time/batch = 0.6728s	
15342/33150 (epoch 23.140), train_loss = 1.12242795, grad/param norm = 1.7086e-01, time/batch = 0.6759s	
15343/33150 (epoch 23.142), train_loss = 1.08059669, grad/param norm = 1.6758e-01, time/batch = 0.6974s	
15344/33150 (epoch 23.143), train_loss = 1.00132789, grad/param norm = 1.6959e-01, time/batch = 0.6748s	
15345/33150 (epoch 23.145), train_loss = 0.95120249, grad/param norm = 1.5982e-01, time/batch = 0.6751s	
15346/33150 (epoch 23.146), train_loss = 1.10596909, grad/param norm = 2.1187e-01, time/batch = 0.6761s	
15347/33150 (epoch 23.148), train_loss = 1.12074283, grad/param norm = 1.6551e-01, time/batch = 0.6768s	
15348/33150 (epoch 23.149), train_loss = 0.99237818, grad/param norm = 1.5186e-01, time/batch = 0.6753s	
15349/33150 (epoch 23.151), train_loss = 1.14204724, grad/param norm = 1.6022e-01, time/batch = 0.6754s	
15350/33150 (epoch 23.152), train_loss = 0.96563109, grad/param norm = 1.5163e-01, time/batch = 0.6822s	
15351/33150 (epoch 23.154), train_loss = 0.95420171, grad/param norm = 1.5782e-01, time/batch = 0.6727s	
15352/33150 (epoch 23.155), train_loss = 0.84237973, grad/param norm = 1.5103e-01, time/batch = 0.6751s	
15353/33150 (epoch 23.157), train_loss = 0.95310524, grad/param norm = 1.5941e-01, time/batch = 0.6772s	
15354/33150 (epoch 23.158), train_loss = 0.92354297, grad/param norm = 1.4777e-01, time/batch = 0.6823s	
15355/33150 (epoch 23.160), train_loss = 1.03155015, grad/param norm = 1.5920e-01, time/batch = 0.6825s	
15356/33150 (epoch 23.161), train_loss = 0.91052549, grad/param norm = 1.6313e-01, time/batch = 0.6843s	
15357/33150 (epoch 23.163), train_loss = 0.88685176, grad/param norm = 1.5036e-01, time/batch = 0.6906s	
15358/33150 (epoch 23.164), train_loss = 1.02157115, grad/param norm = 1.6242e-01, time/batch = 0.6807s	
15359/33150 (epoch 23.166), train_loss = 0.96539513, grad/param norm = 1.6918e-01, time/batch = 0.6834s	
15360/33150 (epoch 23.167), train_loss = 1.00737100, grad/param norm = 1.6960e-01, time/batch = 0.6871s	
15361/33150 (epoch 23.169), train_loss = 1.00761830, grad/param norm = 2.0548e-01, time/batch = 0.6846s	
15362/33150 (epoch 23.170), train_loss = 0.88329391, grad/param norm = 1.6312e-01, time/batch = 0.6930s	
15363/33150 (epoch 23.172), train_loss = 1.07813796, grad/param norm = 1.6520e-01, time/batch = 0.6941s	
15364/33150 (epoch 23.173), train_loss = 1.02862655, grad/param norm = 1.7584e-01, time/batch = 0.6728s	
15365/33150 (epoch 23.175), train_loss = 0.93169705, grad/param norm = 1.8971e-01, time/batch = 0.6730s	
15366/33150 (epoch 23.176), train_loss = 1.04575946, grad/param norm = 1.6583e-01, time/batch = 0.6716s	
15367/33150 (epoch 23.178), train_loss = 1.17046451, grad/param norm = 1.7488e-01, time/batch = 0.6711s	
15368/33150 (epoch 23.179), train_loss = 1.03317450, grad/param norm = 1.5000e-01, time/batch = 0.6713s	
15369/33150 (epoch 23.181), train_loss = 0.98598993, grad/param norm = 1.6099e-01, time/batch = 0.6718s	
15370/33150 (epoch 23.183), train_loss = 0.97645775, grad/param norm = 1.8480e-01, time/batch = 0.6698s	
15371/33150 (epoch 23.184), train_loss = 1.19802564, grad/param norm = 1.6641e-01, time/batch = 0.6732s	
15372/33150 (epoch 23.186), train_loss = 1.11552936, grad/param norm = 1.5867e-01, time/batch = 0.6748s	
15373/33150 (epoch 23.187), train_loss = 1.01429619, grad/param norm = 1.6646e-01, time/batch = 0.6725s	
15374/33150 (epoch 23.189), train_loss = 0.77146413, grad/param norm = 1.4664e-01, time/batch = 0.6739s	
15375/33150 (epoch 23.190), train_loss = 0.88964852, grad/param norm = 1.6303e-01, time/batch = 0.6729s	
15376/33150 (epoch 23.192), train_loss = 1.00674489, grad/param norm = 2.0275e-01, time/batch = 0.6765s	
15377/33150 (epoch 23.193), train_loss = 1.06861200, grad/param norm = 1.6464e-01, time/batch = 0.7005s	
15378/33150 (epoch 23.195), train_loss = 1.20841013, grad/param norm = 1.9459e-01, time/batch = 0.6848s	
15379/33150 (epoch 23.196), train_loss = 1.10364468, grad/param norm = 1.6337e-01, time/batch = 0.6899s	
15380/33150 (epoch 23.198), train_loss = 0.85811782, grad/param norm = 1.5068e-01, time/batch = 0.6754s	
15381/33150 (epoch 23.199), train_loss = 1.09322614, grad/param norm = 1.9721e-01, time/batch = 0.6942s	
15382/33150 (epoch 23.201), train_loss = 0.91616786, grad/param norm = 1.3249e-01, time/batch = 0.6687s	
15383/33150 (epoch 23.202), train_loss = 0.79510442, grad/param norm = 1.4577e-01, time/batch = 0.6724s	
15384/33150 (epoch 23.204), train_loss = 1.02937997, grad/param norm = 1.6787e-01, time/batch = 0.6782s	
15385/33150 (epoch 23.205), train_loss = 1.05998201, grad/param norm = 1.6566e-01, time/batch = 0.6679s	
15386/33150 (epoch 23.207), train_loss = 1.03544082, grad/param norm = 1.6861e-01, time/batch = 0.6688s	
15387/33150 (epoch 23.208), train_loss = 1.05112204, grad/param norm = 1.6425e-01, time/batch = 0.6688s	
15388/33150 (epoch 23.210), train_loss = 0.90979669, grad/param norm = 1.3422e-01, time/batch = 0.6684s	
15389/33150 (epoch 23.211), train_loss = 1.01521283, grad/param norm = 1.7704e-01, time/batch = 0.6687s	
15390/33150 (epoch 23.213), train_loss = 1.04541429, grad/param norm = 1.5754e-01, time/batch = 0.6670s	
15391/33150 (epoch 23.214), train_loss = 0.97094685, grad/param norm = 1.4925e-01, time/batch = 0.6691s	
15392/33150 (epoch 23.216), train_loss = 0.91362936, grad/param norm = 1.5478e-01, time/batch = 0.6701s	
15393/33150 (epoch 23.217), train_loss = 0.96988569, grad/param norm = 1.4805e-01, time/batch = 0.6789s	
15394/33150 (epoch 23.219), train_loss = 0.86941187, grad/param norm = 1.3801e-01, time/batch = 0.6830s	
15395/33150 (epoch 23.220), train_loss = 0.92095411, grad/param norm = 1.3686e-01, time/batch = 0.6737s	
15396/33150 (epoch 23.222), train_loss = 1.09022513, grad/param norm = 1.5795e-01, time/batch = 0.6744s	
15397/33150 (epoch 23.223), train_loss = 0.98887506, grad/param norm = 1.6544e-01, time/batch = 0.6707s	
15398/33150 (epoch 23.225), train_loss = 1.11567710, grad/param norm = 1.5635e-01, time/batch = 0.6715s	
15399/33150 (epoch 23.226), train_loss = 0.97808235, grad/param norm = 1.4097e-01, time/batch = 0.6720s	
15400/33150 (epoch 23.228), train_loss = 0.97107385, grad/param norm = 1.5629e-01, time/batch = 0.6720s	
15401/33150 (epoch 23.229), train_loss = 0.97797360, grad/param norm = 1.4932e-01, time/batch = 0.6721s	
15402/33150 (epoch 23.231), train_loss = 1.11061082, grad/param norm = 1.8810e-01, time/batch = 0.6741s	
15403/33150 (epoch 23.232), train_loss = 1.02130744, grad/param norm = 1.7540e-01, time/batch = 0.6684s	
15404/33150 (epoch 23.234), train_loss = 0.97974691, grad/param norm = 1.5353e-01, time/batch = 0.6686s	
15405/33150 (epoch 23.235), train_loss = 1.02722468, grad/param norm = 1.7002e-01, time/batch = 0.6713s	
15406/33150 (epoch 23.237), train_loss = 1.02688945, grad/param norm = 2.3269e-01, time/batch = 0.6698s	
15407/33150 (epoch 23.238), train_loss = 1.02904920, grad/param norm = 1.6736e-01, time/batch = 0.6713s	
15408/33150 (epoch 23.240), train_loss = 1.01910693, grad/param norm = 1.6390e-01, time/batch = 0.6716s	
15409/33150 (epoch 23.241), train_loss = 1.08262387, grad/param norm = 1.7541e-01, time/batch = 0.6725s	
15410/33150 (epoch 23.243), train_loss = 1.07689100, grad/param norm = 1.8102e-01, time/batch = 0.6716s	
15411/33150 (epoch 23.244), train_loss = 0.99022449, grad/param norm = 1.5112e-01, time/batch = 0.6742s	
15412/33150 (epoch 23.246), train_loss = 1.05164874, grad/param norm = 1.4838e-01, time/batch = 0.6724s	
15413/33150 (epoch 23.247), train_loss = 0.93421059, grad/param norm = 1.4667e-01, time/batch = 0.6699s	
15414/33150 (epoch 23.249), train_loss = 1.10389042, grad/param norm = 1.5041e-01, time/batch = 0.6714s	
15415/33150 (epoch 23.250), train_loss = 1.04517299, grad/param norm = 1.3716e-01, time/batch = 0.6730s	
15416/33150 (epoch 23.252), train_loss = 1.04524524, grad/param norm = 1.3613e-01, time/batch = 0.6739s	
15417/33150 (epoch 23.253), train_loss = 0.97237416, grad/param norm = 1.5849e-01, time/batch = 0.6923s	
15418/33150 (epoch 23.255), train_loss = 0.95320913, grad/param norm = 1.3622e-01, time/batch = 0.6912s	
15419/33150 (epoch 23.256), train_loss = 1.05032312, grad/param norm = 1.4229e-01, time/batch = 0.7087s	
15420/33150 (epoch 23.258), train_loss = 0.94128979, grad/param norm = 1.5738e-01, time/batch = 0.6884s	
15421/33150 (epoch 23.259), train_loss = 0.81291253, grad/param norm = 1.4516e-01, time/batch = 0.6806s	
15422/33150 (epoch 23.261), train_loss = 0.87450458, grad/param norm = 1.4228e-01, time/batch = 0.6727s	
15423/33150 (epoch 23.262), train_loss = 1.06403612, grad/param norm = 1.7650e-01, time/batch = 0.6855s	
15424/33150 (epoch 23.264), train_loss = 0.77051840, grad/param norm = 1.3328e-01, time/batch = 0.6741s	
15425/33150 (epoch 23.265), train_loss = 1.02881850, grad/param norm = 1.6000e-01, time/batch = 0.6717s	
15426/33150 (epoch 23.267), train_loss = 1.04975371, grad/param norm = 1.8018e-01, time/batch = 0.6758s	
15427/33150 (epoch 23.268), train_loss = 1.08812292, grad/param norm = 1.5308e-01, time/batch = 0.6738s	
15428/33150 (epoch 23.270), train_loss = 1.17929688, grad/param norm = 1.7470e-01, time/batch = 0.6722s	
15429/33150 (epoch 23.271), train_loss = 1.10592126, grad/param norm = 1.8924e-01, time/batch = 0.6716s	
15430/33150 (epoch 23.273), train_loss = 1.09773305, grad/param norm = 1.5614e-01, time/batch = 0.6706s	
15431/33150 (epoch 23.275), train_loss = 1.11446679, grad/param norm = 1.6666e-01, time/batch = 0.6768s	
15432/33150 (epoch 23.276), train_loss = 0.99764041, grad/param norm = 1.6048e-01, time/batch = 0.6688s	
15433/33150 (epoch 23.278), train_loss = 1.09119871, grad/param norm = 1.5444e-01, time/batch = 0.6668s	
15434/33150 (epoch 23.279), train_loss = 1.05075008, grad/param norm = 1.6440e-01, time/batch = 0.6724s	
15435/33150 (epoch 23.281), train_loss = 1.02458283, grad/param norm = 1.5799e-01, time/batch = 0.6813s	
15436/33150 (epoch 23.282), train_loss = 1.00549923, grad/param norm = 1.3797e-01, time/batch = 0.6724s	
15437/33150 (epoch 23.284), train_loss = 0.93257808, grad/param norm = 1.4099e-01, time/batch = 0.6753s	
15438/33150 (epoch 23.285), train_loss = 1.01635196, grad/param norm = 1.4832e-01, time/batch = 0.6799s	
15439/33150 (epoch 23.287), train_loss = 0.88861699, grad/param norm = 1.3922e-01, time/batch = 0.6765s	
15440/33150 (epoch 23.288), train_loss = 1.09606851, grad/param norm = 1.5855e-01, time/batch = 0.6754s	
15441/33150 (epoch 23.290), train_loss = 0.84912340, grad/param norm = 1.4961e-01, time/batch = 0.6752s	
15442/33150 (epoch 23.291), train_loss = 0.84312427, grad/param norm = 1.5707e-01, time/batch = 0.6732s	
15443/33150 (epoch 23.293), train_loss = 1.04108474, grad/param norm = 1.5414e-01, time/batch = 0.6738s	
15444/33150 (epoch 23.294), train_loss = 0.75186400, grad/param norm = 1.5047e-01, time/batch = 0.6740s	
15445/33150 (epoch 23.296), train_loss = 0.97155365, grad/param norm = 1.5053e-01, time/batch = 0.6759s	
15446/33150 (epoch 23.297), train_loss = 0.93352101, grad/param norm = 1.6040e-01, time/batch = 0.6883s	
15447/33150 (epoch 23.299), train_loss = 0.90455150, grad/param norm = 1.6387e-01, time/batch = 0.6740s	
15448/33150 (epoch 23.300), train_loss = 0.92595360, grad/param norm = 1.3107e-01, time/batch = 0.6758s	
15449/33150 (epoch 23.302), train_loss = 0.95149998, grad/param norm = 1.5533e-01, time/batch = 0.6799s	
15450/33150 (epoch 23.303), train_loss = 0.95257159, grad/param norm = 1.5265e-01, time/batch = 0.6730s	
15451/33150 (epoch 23.305), train_loss = 1.06370560, grad/param norm = 1.5846e-01, time/batch = 0.6691s	
15452/33150 (epoch 23.306), train_loss = 1.06140284, grad/param norm = 1.7702e-01, time/batch = 0.6689s	
15453/33150 (epoch 23.308), train_loss = 1.22708621, grad/param norm = 1.7525e-01, time/batch = 0.6702s	
15454/33150 (epoch 23.309), train_loss = 0.81486529, grad/param norm = 1.2977e-01, time/batch = 0.6683s	
15455/33150 (epoch 23.311), train_loss = 0.95319843, grad/param norm = 1.7584e-01, time/batch = 0.6702s	
15456/33150 (epoch 23.312), train_loss = 0.79869819, grad/param norm = 1.5136e-01, time/batch = 0.6722s	
15457/33150 (epoch 23.314), train_loss = 0.93655875, grad/param norm = 1.5966e-01, time/batch = 0.6851s	
15458/33150 (epoch 23.315), train_loss = 1.02821254, grad/param norm = 1.6067e-01, time/batch = 0.6783s	
15459/33150 (epoch 23.317), train_loss = 0.78256149, grad/param norm = 1.2298e-01, time/batch = 0.6834s	
15460/33150 (epoch 23.318), train_loss = 0.88954519, grad/param norm = 1.3562e-01, time/batch = 0.6808s	
15461/33150 (epoch 23.320), train_loss = 0.83352052, grad/param norm = 1.5159e-01, time/batch = 0.6745s	
15462/33150 (epoch 23.321), train_loss = 0.95087435, grad/param norm = 1.3968e-01, time/batch = 0.6712s	
15463/33150 (epoch 23.323), train_loss = 0.95490359, grad/param norm = 1.5738e-01, time/batch = 0.6807s	
15464/33150 (epoch 23.324), train_loss = 1.03984520, grad/param norm = 1.7537e-01, time/batch = 0.6709s	
15465/33150 (epoch 23.326), train_loss = 1.01213750, grad/param norm = 1.5501e-01, time/batch = 0.6754s	
15466/33150 (epoch 23.327), train_loss = 1.09322009, grad/param norm = 1.6630e-01, time/batch = 0.6809s	
15467/33150 (epoch 23.329), train_loss = 1.03082400, grad/param norm = 1.4604e-01, time/batch = 0.6721s	
15468/33150 (epoch 23.330), train_loss = 0.97529176, grad/param norm = 1.7366e-01, time/batch = 0.6719s	
15469/33150 (epoch 23.332), train_loss = 0.97637161, grad/param norm = 1.3125e-01, time/batch = 0.6723s	
15470/33150 (epoch 23.333), train_loss = 1.03078875, grad/param norm = 1.3769e-01, time/batch = 0.6795s	
15471/33150 (epoch 23.335), train_loss = 0.92517092, grad/param norm = 1.6298e-01, time/batch = 0.6821s	
15472/33150 (epoch 23.336), train_loss = 0.90224472, grad/param norm = 1.6255e-01, time/batch = 0.6942s	
15473/33150 (epoch 23.338), train_loss = 0.80388560, grad/param norm = 1.4375e-01, time/batch = 0.6866s	
15474/33150 (epoch 23.339), train_loss = 1.05547262, grad/param norm = 1.7004e-01, time/batch = 0.6764s	
15475/33150 (epoch 23.341), train_loss = 1.02989536, grad/param norm = 1.7605e-01, time/batch = 0.6759s	
15476/33150 (epoch 23.342), train_loss = 0.88617888, grad/param norm = 1.5621e-01, time/batch = 0.6735s	
15477/33150 (epoch 23.344), train_loss = 0.99498794, grad/param norm = 1.9406e-01, time/batch = 0.6725s	
15478/33150 (epoch 23.345), train_loss = 0.93507614, grad/param norm = 1.4312e-01, time/batch = 0.6810s	
15479/33150 (epoch 23.347), train_loss = 0.78647446, grad/param norm = 1.3286e-01, time/batch = 0.6780s	
15480/33150 (epoch 23.348), train_loss = 0.98820840, grad/param norm = 1.4746e-01, time/batch = 0.6702s	
15481/33150 (epoch 23.350), train_loss = 0.88891942, grad/param norm = 1.8969e-01, time/batch = 0.6690s	
15482/33150 (epoch 23.351), train_loss = 1.04720472, grad/param norm = 1.6318e-01, time/batch = 0.6713s	
15483/33150 (epoch 23.353), train_loss = 1.02812178, grad/param norm = 1.7645e-01, time/batch = 0.6700s	
15484/33150 (epoch 23.354), train_loss = 1.23179881, grad/param norm = 1.6988e-01, time/batch = 0.6676s	
15485/33150 (epoch 23.356), train_loss = 1.09465751, grad/param norm = 1.6442e-01, time/batch = 0.6680s	
15486/33150 (epoch 23.357), train_loss = 1.02487322, grad/param norm = 1.5782e-01, time/batch = 0.6803s	
15487/33150 (epoch 23.359), train_loss = 1.04733328, grad/param norm = 1.7087e-01, time/batch = 0.6700s	
15488/33150 (epoch 23.360), train_loss = 1.03557365, grad/param norm = 1.8210e-01, time/batch = 0.6667s	
15489/33150 (epoch 23.362), train_loss = 1.07957351, grad/param norm = 1.5774e-01, time/batch = 0.6739s	
15490/33150 (epoch 23.363), train_loss = 0.97484628, grad/param norm = 1.4777e-01, time/batch = 0.6726s	
15491/33150 (epoch 23.365), train_loss = 0.97213600, grad/param norm = 1.4181e-01, time/batch = 0.6750s	
15492/33150 (epoch 23.367), train_loss = 0.94251130, grad/param norm = 1.5540e-01, time/batch = 0.6742s	
15493/33150 (epoch 23.368), train_loss = 0.97237246, grad/param norm = 1.7091e-01, time/batch = 0.6739s	
15494/33150 (epoch 23.370), train_loss = 0.99730725, grad/param norm = 1.7080e-01, time/batch = 0.6712s	
15495/33150 (epoch 23.371), train_loss = 0.89412120, grad/param norm = 1.4737e-01, time/batch = 0.6725s	
15496/33150 (epoch 23.373), train_loss = 1.02728006, grad/param norm = 1.5999e-01, time/batch = 0.6735s	
15497/33150 (epoch 23.374), train_loss = 0.94270010, grad/param norm = 1.4887e-01, time/batch = 0.6723s	
15498/33150 (epoch 23.376), train_loss = 1.09505632, grad/param norm = 1.6614e-01, time/batch = 0.6738s	
15499/33150 (epoch 23.377), train_loss = 0.93271090, grad/param norm = 1.6692e-01, time/batch = 0.6734s	
15500/33150 (epoch 23.379), train_loss = 1.06657987, grad/param norm = 1.7340e-01, time/batch = 0.6732s	
15501/33150 (epoch 23.380), train_loss = 1.06306810, grad/param norm = 1.5158e-01, time/batch = 0.6864s	
15502/33150 (epoch 23.382), train_loss = 0.92958212, grad/param norm = 1.5163e-01, time/batch = 0.6794s	
15503/33150 (epoch 23.383), train_loss = 0.90326081, grad/param norm = 1.4113e-01, time/batch = 0.6718s	
15504/33150 (epoch 23.385), train_loss = 0.96374706, grad/param norm = 1.5710e-01, time/batch = 0.6731s	
15505/33150 (epoch 23.386), train_loss = 0.84568507, grad/param norm = 1.4323e-01, time/batch = 0.6832s	
15506/33150 (epoch 23.388), train_loss = 0.92510804, grad/param norm = 1.4454e-01, time/batch = 0.6935s	
15507/33150 (epoch 23.389), train_loss = 0.91200611, grad/param norm = 1.4310e-01, time/batch = 0.6869s	
15508/33150 (epoch 23.391), train_loss = 1.14861620, grad/param norm = 1.7149e-01, time/batch = 0.6887s	
15509/33150 (epoch 23.392), train_loss = 0.93322500, grad/param norm = 1.4353e-01, time/batch = 0.6729s	
15510/33150 (epoch 23.394), train_loss = 0.81402303, grad/param norm = 1.2284e-01, time/batch = 0.6743s	
15511/33150 (epoch 23.395), train_loss = 0.82249065, grad/param norm = 1.4697e-01, time/batch = 0.6731s	
15512/33150 (epoch 23.397), train_loss = 0.68418405, grad/param norm = 1.3247e-01, time/batch = 0.6896s	
15513/33150 (epoch 23.398), train_loss = 0.98974792, grad/param norm = 1.6996e-01, time/batch = 0.6780s	
15514/33150 (epoch 23.400), train_loss = 0.93233278, grad/param norm = 1.3648e-01, time/batch = 0.6768s	
15515/33150 (epoch 23.401), train_loss = 0.81022371, grad/param norm = 1.2004e-01, time/batch = 0.6772s	
15516/33150 (epoch 23.403), train_loss = 0.83647850, grad/param norm = 1.3782e-01, time/batch = 0.6854s	
15517/33150 (epoch 23.404), train_loss = 0.97305037, grad/param norm = 1.6297e-01, time/batch = 0.6815s	
15518/33150 (epoch 23.406), train_loss = 0.91483724, grad/param norm = 1.2915e-01, time/batch = 0.6880s	
15519/33150 (epoch 23.407), train_loss = 0.84304357, grad/param norm = 1.4642e-01, time/batch = 0.6932s	
15520/33150 (epoch 23.409), train_loss = 0.80202521, grad/param norm = 1.5492e-01, time/batch = 0.6929s	
15521/33150 (epoch 23.410), train_loss = 0.97953385, grad/param norm = 1.4953e-01, time/batch = 0.6955s	
15522/33150 (epoch 23.412), train_loss = 1.03498643, grad/param norm = 1.5715e-01, time/batch = 0.6943s	
15523/33150 (epoch 23.413), train_loss = 0.89518439, grad/param norm = 1.5442e-01, time/batch = 0.6939s	
15524/33150 (epoch 23.415), train_loss = 1.00240805, grad/param norm = 1.4575e-01, time/batch = 0.6954s	
15525/33150 (epoch 23.416), train_loss = 0.90259112, grad/param norm = 1.4356e-01, time/batch = 0.6917s	
15526/33150 (epoch 23.418), train_loss = 1.05437522, grad/param norm = 1.8773e-01, time/batch = 0.6835s	
15527/33150 (epoch 23.419), train_loss = 0.91445108, grad/param norm = 1.4732e-01, time/batch = 0.6741s	
15528/33150 (epoch 23.421), train_loss = 0.97640708, grad/param norm = 2.5610e-01, time/batch = 0.6738s	
15529/33150 (epoch 23.422), train_loss = 0.92555271, grad/param norm = 1.4872e-01, time/batch = 0.6724s	
15530/33150 (epoch 23.424), train_loss = 0.92026211, grad/param norm = 1.7739e-01, time/batch = 0.6840s	
15531/33150 (epoch 23.425), train_loss = 1.02750063, grad/param norm = 1.5738e-01, time/batch = 0.6822s	
15532/33150 (epoch 23.427), train_loss = 0.95700372, grad/param norm = 1.4187e-01, time/batch = 0.6720s	
15533/33150 (epoch 23.428), train_loss = 0.97271894, grad/param norm = 1.5961e-01, time/batch = 0.6783s	
15534/33150 (epoch 23.430), train_loss = 0.97546115, grad/param norm = 1.6251e-01, time/batch = 0.6716s	
15535/33150 (epoch 23.431), train_loss = 1.04536799, grad/param norm = 1.7728e-01, time/batch = 0.6696s	
15536/33150 (epoch 23.433), train_loss = 0.96641158, grad/param norm = 1.5084e-01, time/batch = 0.6726s	
15537/33150 (epoch 23.434), train_loss = 0.85689719, grad/param norm = 1.4594e-01, time/batch = 0.6711s	
15538/33150 (epoch 23.436), train_loss = 0.94093500, grad/param norm = 1.5090e-01, time/batch = 0.6723s	
15539/33150 (epoch 23.437), train_loss = 0.99687537, grad/param norm = 2.1033e-01, time/batch = 0.6718s	
15540/33150 (epoch 23.439), train_loss = 1.11549708, grad/param norm = 1.5841e-01, time/batch = 0.6724s	
15541/33150 (epoch 23.440), train_loss = 1.05073274, grad/param norm = 1.5762e-01, time/batch = 0.6753s	
15542/33150 (epoch 23.442), train_loss = 0.85106388, grad/param norm = 1.3602e-01, time/batch = 0.6756s	
15543/33150 (epoch 23.443), train_loss = 1.03955608, grad/param norm = 1.6010e-01, time/batch = 0.6737s	
15544/33150 (epoch 23.445), train_loss = 0.99833236, grad/param norm = 1.7394e-01, time/batch = 0.6828s	
15545/33150 (epoch 23.446), train_loss = 0.99532467, grad/param norm = 1.8865e-01, time/batch = 0.6857s	
15546/33150 (epoch 23.448), train_loss = 1.07152653, grad/param norm = 1.6745e-01, time/batch = 0.6793s	
15547/33150 (epoch 23.449), train_loss = 1.00009887, grad/param norm = 1.4462e-01, time/batch = 0.6731s	
15548/33150 (epoch 23.451), train_loss = 0.99029625, grad/param norm = 1.7157e-01, time/batch = 0.6736s	
15549/33150 (epoch 23.452), train_loss = 1.18958927, grad/param norm = 1.6415e-01, time/batch = 0.6783s	
15550/33150 (epoch 23.454), train_loss = 1.00499104, grad/param norm = 1.6939e-01, time/batch = 0.6761s	
15551/33150 (epoch 23.456), train_loss = 0.86734922, grad/param norm = 1.4793e-01, time/batch = 0.6783s	
15552/33150 (epoch 23.457), train_loss = 0.98988499, grad/param norm = 1.6663e-01, time/batch = 0.6748s	
15553/33150 (epoch 23.459), train_loss = 1.11123889, grad/param norm = 2.3538e-01, time/batch = 0.6734s	
15554/33150 (epoch 23.460), train_loss = 1.02698225, grad/param norm = 1.3867e-01, time/batch = 0.6684s	
15555/33150 (epoch 23.462), train_loss = 1.04644624, grad/param norm = 1.7402e-01, time/batch = 0.6815s	
15556/33150 (epoch 23.463), train_loss = 1.20897927, grad/param norm = 1.8671e-01, time/batch = 0.6802s	
15557/33150 (epoch 23.465), train_loss = 0.98259309, grad/param norm = 1.5348e-01, time/batch = 0.6721s	
15558/33150 (epoch 23.466), train_loss = 0.91418330, grad/param norm = 1.4499e-01, time/batch = 0.6705s	
15559/33150 (epoch 23.468), train_loss = 1.19721625, grad/param norm = 1.6201e-01, time/batch = 0.6705s	
15560/33150 (epoch 23.469), train_loss = 0.97650328, grad/param norm = 1.6761e-01, time/batch = 0.6719s	
15561/33150 (epoch 23.471), train_loss = 0.91425091, grad/param norm = 1.4495e-01, time/batch = 0.6715s	
15562/33150 (epoch 23.472), train_loss = 1.00734452, grad/param norm = 1.5721e-01, time/batch = 0.6717s	
15563/33150 (epoch 23.474), train_loss = 1.08853000, grad/param norm = 1.8872e-01, time/batch = 0.6717s	
15564/33150 (epoch 23.475), train_loss = 1.23738833, grad/param norm = 1.8698e-01, time/batch = 0.6735s	
15565/33150 (epoch 23.477), train_loss = 1.11224998, grad/param norm = 1.8303e-01, time/batch = 0.6728s	
15566/33150 (epoch 23.478), train_loss = 1.06880918, grad/param norm = 1.5238e-01, time/batch = 0.6730s	
15567/33150 (epoch 23.480), train_loss = 0.92233589, grad/param norm = 1.5671e-01, time/batch = 0.6759s	
15568/33150 (epoch 23.481), train_loss = 0.82793738, grad/param norm = 1.4576e-01, time/batch = 0.6750s	
15569/33150 (epoch 23.483), train_loss = 0.92839165, grad/param norm = 1.5223e-01, time/batch = 0.6817s	
15570/33150 (epoch 23.484), train_loss = 0.92273515, grad/param norm = 1.5849e-01, time/batch = 0.6710s	
15571/33150 (epoch 23.486), train_loss = 0.91778013, grad/param norm = 1.5176e-01, time/batch = 0.6720s	
15572/33150 (epoch 23.487), train_loss = 1.00793222, grad/param norm = 1.7780e-01, time/batch = 0.6720s	
15573/33150 (epoch 23.489), train_loss = 0.97489066, grad/param norm = 1.6791e-01, time/batch = 0.6760s	
15574/33150 (epoch 23.490), train_loss = 0.82710358, grad/param norm = 1.5465e-01, time/batch = 0.6722s	
15575/33150 (epoch 23.492), train_loss = 0.93931179, grad/param norm = 1.7319e-01, time/batch = 0.6727s	
15576/33150 (epoch 23.493), train_loss = 1.06323247, grad/param norm = 1.6563e-01, time/batch = 0.6714s	
15577/33150 (epoch 23.495), train_loss = 1.07347390, grad/param norm = 1.5930e-01, time/batch = 0.6736s	
15578/33150 (epoch 23.496), train_loss = 0.96573844, grad/param norm = 1.5227e-01, time/batch = 0.6774s	
15579/33150 (epoch 23.498), train_loss = 1.09041745, grad/param norm = 1.8527e-01, time/batch = 0.6850s	
15580/33150 (epoch 23.499), train_loss = 1.08482137, grad/param norm = 1.5582e-01, time/batch = 0.6771s	
15581/33150 (epoch 23.501), train_loss = 1.03097257, grad/param norm = 1.6868e-01, time/batch = 0.6783s	
15582/33150 (epoch 23.502), train_loss = 1.11176561, grad/param norm = 1.9780e-01, time/batch = 0.6707s	
15583/33150 (epoch 23.504), train_loss = 1.05925801, grad/param norm = 1.6831e-01, time/batch = 0.6771s	
15584/33150 (epoch 23.505), train_loss = 1.16594103, grad/param norm = 1.8546e-01, time/batch = 0.6827s	
15585/33150 (epoch 23.507), train_loss = 0.96179599, grad/param norm = 1.6034e-01, time/batch = 0.6847s	
15586/33150 (epoch 23.508), train_loss = 0.94337613, grad/param norm = 1.5632e-01, time/batch = 0.6976s	
15587/33150 (epoch 23.510), train_loss = 1.04396887, grad/param norm = 1.5431e-01, time/batch = 0.6904s	
15588/33150 (epoch 23.511), train_loss = 1.09791481, grad/param norm = 1.5822e-01, time/batch = 0.6795s	
15589/33150 (epoch 23.513), train_loss = 1.01278744, grad/param norm = 1.6313e-01, time/batch = 0.6840s	
15590/33150 (epoch 23.514), train_loss = 0.81910900, grad/param norm = 1.4775e-01, time/batch = 0.6856s	
15591/33150 (epoch 23.516), train_loss = 1.00722590, grad/param norm = 1.7441e-01, time/batch = 0.6852s	
15592/33150 (epoch 23.517), train_loss = 1.10040197, grad/param norm = 1.7447e-01, time/batch = 0.6875s	
15593/33150 (epoch 23.519), train_loss = 0.92678208, grad/param norm = 1.8322e-01, time/batch = 0.6892s	
15594/33150 (epoch 23.520), train_loss = 0.99790316, grad/param norm = 1.4718e-01, time/batch = 0.6878s	
15595/33150 (epoch 23.522), train_loss = 1.09940097, grad/param norm = 1.8051e-01, time/batch = 0.6942s	
15596/33150 (epoch 23.523), train_loss = 0.90749087, grad/param norm = 1.5226e-01, time/batch = 0.6761s	
15597/33150 (epoch 23.525), train_loss = 1.05770886, grad/param norm = 1.7714e-01, time/batch = 0.6745s	
15598/33150 (epoch 23.526), train_loss = 0.92373982, grad/param norm = 1.5690e-01, time/batch = 0.6766s	
15599/33150 (epoch 23.528), train_loss = 1.04379095, grad/param norm = 1.6388e-01, time/batch = 0.6930s	
15600/33150 (epoch 23.529), train_loss = 0.97156667, grad/param norm = 1.6028e-01, time/batch = 0.6776s	
15601/33150 (epoch 23.531), train_loss = 0.82850957, grad/param norm = 1.6865e-01, time/batch = 0.6778s	
15602/33150 (epoch 23.532), train_loss = 1.00908762, grad/param norm = 1.6849e-01, time/batch = 0.6775s	
15603/33150 (epoch 23.534), train_loss = 0.96450067, grad/param norm = 1.3464e-01, time/batch = 0.6744s	
15604/33150 (epoch 23.535), train_loss = 0.90424753, grad/param norm = 1.7160e-01, time/batch = 0.6795s	
15605/33150 (epoch 23.537), train_loss = 1.05328835, grad/param norm = 1.7995e-01, time/batch = 0.6712s	
15606/33150 (epoch 23.538), train_loss = 0.93040552, grad/param norm = 1.5454e-01, time/batch = 0.6771s	
15607/33150 (epoch 23.540), train_loss = 0.85554822, grad/param norm = 1.4952e-01, time/batch = 0.6741s	
15608/33150 (epoch 23.541), train_loss = 1.07900803, grad/param norm = 1.6671e-01, time/batch = 0.6806s	
15609/33150 (epoch 23.543), train_loss = 0.98568836, grad/param norm = 1.5364e-01, time/batch = 0.6796s	
15610/33150 (epoch 23.544), train_loss = 1.04518848, grad/param norm = 1.5878e-01, time/batch = 0.6795s	
15611/33150 (epoch 23.546), train_loss = 1.03836511, grad/param norm = 1.7057e-01, time/batch = 0.6811s	
15612/33150 (epoch 23.548), train_loss = 0.98527906, grad/param norm = 1.7617e-01, time/batch = 0.6795s	
15613/33150 (epoch 23.549), train_loss = 0.92964593, grad/param norm = 1.6768e-01, time/batch = 0.6750s	
15614/33150 (epoch 23.551), train_loss = 0.89573648, grad/param norm = 1.4272e-01, time/batch = 0.6822s	
15615/33150 (epoch 23.552), train_loss = 0.77743175, grad/param norm = 1.3368e-01, time/batch = 0.6751s	
15616/33150 (epoch 23.554), train_loss = 1.05877916, grad/param norm = 1.5216e-01, time/batch = 0.6745s	
15617/33150 (epoch 23.555), train_loss = 1.09411287, grad/param norm = 1.7727e-01, time/batch = 0.6726s	
15618/33150 (epoch 23.557), train_loss = 0.79861607, grad/param norm = 1.5613e-01, time/batch = 0.6724s	
15619/33150 (epoch 23.558), train_loss = 1.03708364, grad/param norm = 1.6988e-01, time/batch = 0.6735s	
15620/33150 (epoch 23.560), train_loss = 0.94001564, grad/param norm = 1.6845e-01, time/batch = 0.6710s	
15621/33150 (epoch 23.561), train_loss = 0.84509452, grad/param norm = 1.5694e-01, time/batch = 0.6808s	
15622/33150 (epoch 23.563), train_loss = 1.05529394, grad/param norm = 2.0411e-01, time/batch = 0.6785s	
15623/33150 (epoch 23.564), train_loss = 1.13766667, grad/param norm = 1.6482e-01, time/batch = 0.7004s	
15624/33150 (epoch 23.566), train_loss = 0.92825424, grad/param norm = 1.5592e-01, time/batch = 0.6937s	
15625/33150 (epoch 23.567), train_loss = 0.88830301, grad/param norm = 1.5180e-01, time/batch = 0.6886s	
15626/33150 (epoch 23.569), train_loss = 1.02034647, grad/param norm = 1.6192e-01, time/batch = 0.6827s	
15627/33150 (epoch 23.570), train_loss = 1.06737073, grad/param norm = 1.6723e-01, time/batch = 0.6774s	
15628/33150 (epoch 23.572), train_loss = 0.89102800, grad/param norm = 1.5576e-01, time/batch = 0.6818s	
15629/33150 (epoch 23.573), train_loss = 0.79043530, grad/param norm = 1.2963e-01, time/batch = 0.6739s	
15630/33150 (epoch 23.575), train_loss = 0.97207951, grad/param norm = 1.7039e-01, time/batch = 0.6702s	
15631/33150 (epoch 23.576), train_loss = 0.85376796, grad/param norm = 1.3254e-01, time/batch = 0.6728s	
15632/33150 (epoch 23.578), train_loss = 0.91531759, grad/param norm = 1.5624e-01, time/batch = 0.6744s	
15633/33150 (epoch 23.579), train_loss = 0.82774756, grad/param norm = 1.4265e-01, time/batch = 0.6734s	
15634/33150 (epoch 23.581), train_loss = 0.89331407, grad/param norm = 1.4420e-01, time/batch = 0.6782s	
15635/33150 (epoch 23.582), train_loss = 1.10016904, grad/param norm = 1.4666e-01, time/batch = 0.6735s	
15636/33150 (epoch 23.584), train_loss = 1.06392055, grad/param norm = 1.8150e-01, time/batch = 0.6755s	
15637/33150 (epoch 23.585), train_loss = 0.98441970, grad/param norm = 1.5923e-01, time/batch = 0.6790s	
15638/33150 (epoch 23.587), train_loss = 0.98452649, grad/param norm = 1.4805e-01, time/batch = 0.6870s	
15639/33150 (epoch 23.588), train_loss = 0.89761547, grad/param norm = 1.6005e-01, time/batch = 0.6767s	
15640/33150 (epoch 23.590), train_loss = 1.00765383, grad/param norm = 1.6462e-01, time/batch = 0.6757s	
15641/33150 (epoch 23.591), train_loss = 0.95518513, grad/param norm = 1.7036e-01, time/batch = 0.6776s	
15642/33150 (epoch 23.593), train_loss = 1.03093814, grad/param norm = 1.6977e-01, time/batch = 0.6734s	
15643/33150 (epoch 23.594), train_loss = 0.97644725, grad/param norm = 1.6682e-01, time/batch = 0.6746s	
15644/33150 (epoch 23.596), train_loss = 0.94112865, grad/param norm = 1.5482e-01, time/batch = 0.6744s	
15645/33150 (epoch 23.597), train_loss = 0.86839901, grad/param norm = 2.7195e-01, time/batch = 0.6723s	
15646/33150 (epoch 23.599), train_loss = 1.15464449, grad/param norm = 1.9954e-01, time/batch = 0.6764s	
15647/33150 (epoch 23.600), train_loss = 0.98063273, grad/param norm = 2.1588e-01, time/batch = 0.6753s	
15648/33150 (epoch 23.602), train_loss = 0.95794579, grad/param norm = 1.6872e-01, time/batch = 0.6755s	
15649/33150 (epoch 23.603), train_loss = 1.08291725, grad/param norm = 1.8021e-01, time/batch = 0.6739s	
15650/33150 (epoch 23.605), train_loss = 0.88575410, grad/param norm = 1.5358e-01, time/batch = 0.6710s	
15651/33150 (epoch 23.606), train_loss = 0.97567463, grad/param norm = 2.0549e-01, time/batch = 0.6888s	
15652/33150 (epoch 23.608), train_loss = 1.04400597, grad/param norm = 1.5266e-01, time/batch = 0.6859s	
15653/33150 (epoch 23.609), train_loss = 0.95304261, grad/param norm = 1.6944e-01, time/batch = 0.6793s	
15654/33150 (epoch 23.611), train_loss = 0.88313508, grad/param norm = 1.6030e-01, time/batch = 0.6685s	
15655/33150 (epoch 23.612), train_loss = 0.99023729, grad/param norm = 1.9010e-01, time/batch = 0.6682s	
15656/33150 (epoch 23.614), train_loss = 0.88158591, grad/param norm = 1.4532e-01, time/batch = 0.6719s	
15657/33150 (epoch 23.615), train_loss = 0.85587548, grad/param norm = 1.3906e-01, time/batch = 0.6716s	
15658/33150 (epoch 23.617), train_loss = 1.00200218, grad/param norm = 1.8031e-01, time/batch = 0.6689s	
15659/33150 (epoch 23.618), train_loss = 1.02970430, grad/param norm = 1.9750e-01, time/batch = 0.6869s	
15660/33150 (epoch 23.620), train_loss = 0.89009245, grad/param norm = 1.4302e-01, time/batch = 0.6846s	
15661/33150 (epoch 23.621), train_loss = 0.95604881, grad/param norm = 1.4997e-01, time/batch = 0.6851s	
15662/33150 (epoch 23.623), train_loss = 1.05313099, grad/param norm = 1.6796e-01, time/batch = 0.6858s	
15663/33150 (epoch 23.624), train_loss = 0.93191908, grad/param norm = 1.5950e-01, time/batch = 0.6878s	
15664/33150 (epoch 23.626), train_loss = 0.94444212, grad/param norm = 1.8401e-01, time/batch = 0.6870s	
15665/33150 (epoch 23.627), train_loss = 0.88185846, grad/param norm = 1.5642e-01, time/batch = 0.6971s	
15666/33150 (epoch 23.629), train_loss = 0.82601787, grad/param norm = 1.4978e-01, time/batch = 0.6921s	
15667/33150 (epoch 23.630), train_loss = 0.91622583, grad/param norm = 1.4068e-01, time/batch = 0.6864s	
15668/33150 (epoch 23.632), train_loss = 0.84133028, grad/param norm = 1.3871e-01, time/batch = 0.6824s	
15669/33150 (epoch 23.633), train_loss = 0.84350624, grad/param norm = 1.7800e-01, time/batch = 0.6750s	
15670/33150 (epoch 23.635), train_loss = 1.16182412, grad/param norm = 1.7843e-01, time/batch = 0.6753s	
15671/33150 (epoch 23.637), train_loss = 0.82239217, grad/param norm = 1.5246e-01, time/batch = 0.6720s	
15672/33150 (epoch 23.638), train_loss = 0.93557129, grad/param norm = 1.5428e-01, time/batch = 0.6736s	
15673/33150 (epoch 23.640), train_loss = 1.03951560, grad/param norm = 1.6481e-01, time/batch = 0.6721s	
15674/33150 (epoch 23.641), train_loss = 0.85750833, grad/param norm = 1.6000e-01, time/batch = 0.6812s	
15675/33150 (epoch 23.643), train_loss = 0.94481334, grad/param norm = 1.4939e-01, time/batch = 0.6714s	
15676/33150 (epoch 23.644), train_loss = 1.12735812, grad/param norm = 1.7481e-01, time/batch = 0.6758s	
15677/33150 (epoch 23.646), train_loss = 0.93658027, grad/param norm = 1.5047e-01, time/batch = 0.6845s	
15678/33150 (epoch 23.647), train_loss = 1.19001112, grad/param norm = 1.7701e-01, time/batch = 0.6799s	
15679/33150 (epoch 23.649), train_loss = 1.05845353, grad/param norm = 1.9319e-01, time/batch = 0.6741s	
15680/33150 (epoch 23.650), train_loss = 0.84678833, grad/param norm = 1.3637e-01, time/batch = 0.6743s	
15681/33150 (epoch 23.652), train_loss = 1.07716497, grad/param norm = 1.6905e-01, time/batch = 0.6880s	
15682/33150 (epoch 23.653), train_loss = 0.99424619, grad/param norm = 1.4504e-01, time/batch = 0.6965s	
15683/33150 (epoch 23.655), train_loss = 1.01535648, grad/param norm = 1.6640e-01, time/batch = 0.6882s	
15684/33150 (epoch 23.656), train_loss = 0.92485783, grad/param norm = 1.4510e-01, time/batch = 0.6934s	
15685/33150 (epoch 23.658), train_loss = 0.94281677, grad/param norm = 1.7229e-01, time/batch = 0.6673s	
15686/33150 (epoch 23.659), train_loss = 1.25118327, grad/param norm = 2.3984e-01, time/batch = 0.6666s	
15687/33150 (epoch 23.661), train_loss = 0.97410038, grad/param norm = 1.7826e-01, time/batch = 0.6682s	
15688/33150 (epoch 23.662), train_loss = 0.88795900, grad/param norm = 1.5564e-01, time/batch = 0.6708s	
15689/33150 (epoch 23.664), train_loss = 1.12224256, grad/param norm = 1.8407e-01, time/batch = 0.6685s	
15690/33150 (epoch 23.665), train_loss = 1.04413725, grad/param norm = 1.6661e-01, time/batch = 0.6672s	
15691/33150 (epoch 23.667), train_loss = 1.10760502, grad/param norm = 1.9098e-01, time/batch = 0.6708s	
15692/33150 (epoch 23.668), train_loss = 1.09709827, grad/param norm = 1.7062e-01, time/batch = 0.6703s	
15693/33150 (epoch 23.670), train_loss = 0.90223686, grad/param norm = 1.3432e-01, time/batch = 0.6778s	
15694/33150 (epoch 23.671), train_loss = 0.92504212, grad/param norm = 1.5730e-01, time/batch = 0.6958s	
15695/33150 (epoch 23.673), train_loss = 1.08570792, grad/param norm = 1.4070e-01, time/batch = 0.6912s	
15696/33150 (epoch 23.674), train_loss = 0.98973292, grad/param norm = 1.5137e-01, time/batch = 0.6750s	
15697/33150 (epoch 23.676), train_loss = 0.94421271, grad/param norm = 1.5152e-01, time/batch = 0.6747s	
15698/33150 (epoch 23.677), train_loss = 1.14486886, grad/param norm = 1.7700e-01, time/batch = 0.6745s	
15699/33150 (epoch 23.679), train_loss = 0.98468700, grad/param norm = 1.4715e-01, time/batch = 0.6815s	
15700/33150 (epoch 23.680), train_loss = 1.08741032, grad/param norm = 1.7469e-01, time/batch = 0.6789s	
15701/33150 (epoch 23.682), train_loss = 0.96350885, grad/param norm = 1.5741e-01, time/batch = 0.6746s	
15702/33150 (epoch 23.683), train_loss = 0.84205150, grad/param norm = 1.3461e-01, time/batch = 0.6850s	
15703/33150 (epoch 23.685), train_loss = 0.94752329, grad/param norm = 1.6796e-01, time/batch = 0.6770s	
15704/33150 (epoch 23.686), train_loss = 0.84158926, grad/param norm = 1.5121e-01, time/batch = 0.6763s	
15705/33150 (epoch 23.688), train_loss = 0.86819523, grad/param norm = 1.4629e-01, time/batch = 0.6790s	
15706/33150 (epoch 23.689), train_loss = 0.89153217, grad/param norm = 1.4937e-01, time/batch = 0.6763s	
15707/33150 (epoch 23.691), train_loss = 0.76887381, grad/param norm = 1.4096e-01, time/batch = 0.6777s	
15708/33150 (epoch 23.692), train_loss = 0.87394326, grad/param norm = 1.5509e-01, time/batch = 0.6743s	
15709/33150 (epoch 23.694), train_loss = 0.76880295, grad/param norm = 1.3420e-01, time/batch = 0.6709s	
15710/33150 (epoch 23.695), train_loss = 0.91305600, grad/param norm = 1.4528e-01, time/batch = 0.6743s	
15711/33150 (epoch 23.697), train_loss = 0.82546974, grad/param norm = 1.3405e-01, time/batch = 0.6787s	
15712/33150 (epoch 23.698), train_loss = 0.88854657, grad/param norm = 1.8863e-01, time/batch = 0.6745s	
15713/33150 (epoch 23.700), train_loss = 0.72472954, grad/param norm = 1.2605e-01, time/batch = 0.6771s	
15714/33150 (epoch 23.701), train_loss = 0.84700366, grad/param norm = 1.3441e-01, time/batch = 0.6750s	
15715/33150 (epoch 23.703), train_loss = 0.94262294, grad/param norm = 1.4869e-01, time/batch = 0.6777s	
15716/33150 (epoch 23.704), train_loss = 0.81736480, grad/param norm = 1.4413e-01, time/batch = 0.6804s	
15717/33150 (epoch 23.706), train_loss = 0.91647049, grad/param norm = 1.4408e-01, time/batch = 0.6738s	
15718/33150 (epoch 23.707), train_loss = 0.91720167, grad/param norm = 1.6115e-01, time/batch = 0.6813s	
15719/33150 (epoch 23.709), train_loss = 0.95182484, grad/param norm = 1.3693e-01, time/batch = 0.6866s	
15720/33150 (epoch 23.710), train_loss = 0.94532283, grad/param norm = 1.7065e-01, time/batch = 0.6783s	
15721/33150 (epoch 23.712), train_loss = 1.01048868, grad/param norm = 1.5997e-01, time/batch = 0.6796s	
15722/33150 (epoch 23.713), train_loss = 1.00022802, grad/param norm = 1.4337e-01, time/batch = 0.6795s	
15723/33150 (epoch 23.715), train_loss = 0.90983868, grad/param norm = 1.4130e-01, time/batch = 0.6762s	
15724/33150 (epoch 23.716), train_loss = 1.00474564, grad/param norm = 1.6741e-01, time/batch = 0.6699s	
15725/33150 (epoch 23.718), train_loss = 0.98893957, grad/param norm = 1.5376e-01, time/batch = 0.6777s	
15726/33150 (epoch 23.719), train_loss = 1.05621406, grad/param norm = 1.8375e-01, time/batch = 0.6847s	
15727/33150 (epoch 23.721), train_loss = 0.93099723, grad/param norm = 1.6809e-01, time/batch = 0.6721s	
15728/33150 (epoch 23.722), train_loss = 0.97090427, grad/param norm = 1.4316e-01, time/batch = 0.6712s	
15729/33150 (epoch 23.724), train_loss = 0.92387998, grad/param norm = 1.6741e-01, time/batch = 0.6731s	
15730/33150 (epoch 23.725), train_loss = 1.06873745, grad/param norm = 1.9134e-01, time/batch = 0.6721s	
15731/33150 (epoch 23.727), train_loss = 1.01022906, grad/param norm = 1.7140e-01, time/batch = 0.6764s	
15732/33150 (epoch 23.729), train_loss = 0.93724572, grad/param norm = 1.5376e-01, time/batch = 0.6779s	
15733/33150 (epoch 23.730), train_loss = 0.99360450, grad/param norm = 1.6247e-01, time/batch = 0.6715s	
15734/33150 (epoch 23.732), train_loss = 1.04518966, grad/param norm = 1.6589e-01, time/batch = 0.6751s	
15735/33150 (epoch 23.733), train_loss = 0.79060826, grad/param norm = 1.2922e-01, time/batch = 0.6729s	
15736/33150 (epoch 23.735), train_loss = 0.86777732, grad/param norm = 1.4395e-01, time/batch = 0.6724s	
15737/33150 (epoch 23.736), train_loss = 0.92881422, grad/param norm = 1.6347e-01, time/batch = 0.6727s	
15738/33150 (epoch 23.738), train_loss = 0.98138883, grad/param norm = 1.6753e-01, time/batch = 0.6715s	
15739/33150 (epoch 23.739), train_loss = 1.05238088, grad/param norm = 1.7188e-01, time/batch = 0.6725s	
15740/33150 (epoch 23.741), train_loss = 1.05573132, grad/param norm = 1.7727e-01, time/batch = 0.6814s	
15741/33150 (epoch 23.742), train_loss = 0.84342464, grad/param norm = 1.5662e-01, time/batch = 0.6834s	
15742/33150 (epoch 23.744), train_loss = 1.05848124, grad/param norm = 1.7970e-01, time/batch = 0.6720s	
15743/33150 (epoch 23.745), train_loss = 0.92583343, grad/param norm = 1.4377e-01, time/batch = 0.6707s	
15744/33150 (epoch 23.747), train_loss = 0.75314982, grad/param norm = 1.4323e-01, time/batch = 0.6720s	
15745/33150 (epoch 23.748), train_loss = 0.88564764, grad/param norm = 1.5692e-01, time/batch = 0.6718s	
15746/33150 (epoch 23.750), train_loss = 1.00163426, grad/param norm = 1.5907e-01, time/batch = 0.6715s	
15747/33150 (epoch 23.751), train_loss = 0.98251140, grad/param norm = 1.5705e-01, time/batch = 0.6759s	
15748/33150 (epoch 23.753), train_loss = 0.81895802, grad/param norm = 1.4512e-01, time/batch = 0.6849s	
15749/33150 (epoch 23.754), train_loss = 1.17147844, grad/param norm = 2.0432e-01, time/batch = 0.6706s	
15750/33150 (epoch 23.756), train_loss = 0.96935101, grad/param norm = 1.7978e-01, time/batch = 0.6692s	
15751/33150 (epoch 23.757), train_loss = 0.99086178, grad/param norm = 1.7497e-01, time/batch = 0.6687s	
15752/33150 (epoch 23.759), train_loss = 1.09399494, grad/param norm = 1.8246e-01, time/batch = 0.6715s	
15753/33150 (epoch 23.760), train_loss = 1.02124419, grad/param norm = 1.6044e-01, time/batch = 0.6716s	
15754/33150 (epoch 23.762), train_loss = 0.99724799, grad/param norm = 1.7877e-01, time/batch = 0.6710s	
15755/33150 (epoch 23.763), train_loss = 1.03648180, grad/param norm = 1.6892e-01, time/batch = 0.6849s	
15756/33150 (epoch 23.765), train_loss = 0.94415216, grad/param norm = 1.4476e-01, time/batch = 0.6794s	
15757/33150 (epoch 23.766), train_loss = 0.90015015, grad/param norm = 1.7699e-01, time/batch = 0.6711s	
15758/33150 (epoch 23.768), train_loss = 0.90120682, grad/param norm = 1.4403e-01, time/batch = 0.6708s	
15759/33150 (epoch 23.769), train_loss = 0.99822687, grad/param norm = 1.7399e-01, time/batch = 0.6739s	
15760/33150 (epoch 23.771), train_loss = 0.98353131, grad/param norm = 1.6120e-01, time/batch = 0.6693s	
15761/33150 (epoch 23.772), train_loss = 1.04868025, grad/param norm = 1.6881e-01, time/batch = 0.6726s	
15762/33150 (epoch 23.774), train_loss = 1.12558088, grad/param norm = 1.5937e-01, time/batch = 0.6741s	
15763/33150 (epoch 23.775), train_loss = 1.05276773, grad/param norm = 2.3129e-01, time/batch = 0.6787s	
15764/33150 (epoch 23.777), train_loss = 1.04519484, grad/param norm = 1.7652e-01, time/batch = 0.6720s	
15765/33150 (epoch 23.778), train_loss = 0.98326654, grad/param norm = 1.4659e-01, time/batch = 0.6724s	
15766/33150 (epoch 23.780), train_loss = 0.82980551, grad/param norm = 1.3663e-01, time/batch = 0.6772s	
15767/33150 (epoch 23.781), train_loss = 0.96189771, grad/param norm = 1.3862e-01, time/batch = 0.6722s	
15768/33150 (epoch 23.783), train_loss = 0.96804492, grad/param norm = 1.5023e-01, time/batch = 0.6710s	
15769/33150 (epoch 23.784), train_loss = 0.93564715, grad/param norm = 1.4896e-01, time/batch = 0.6740s	
15770/33150 (epoch 23.786), train_loss = 0.95306452, grad/param norm = 1.4503e-01, time/batch = 0.6915s	
15771/33150 (epoch 23.787), train_loss = 0.89806998, grad/param norm = 1.4163e-01, time/batch = 0.6906s	
15772/33150 (epoch 23.789), train_loss = 0.80915809, grad/param norm = 1.5092e-01, time/batch = 0.6906s	
15773/33150 (epoch 23.790), train_loss = 0.85784903, grad/param norm = 1.4102e-01, time/batch = 0.6763s	
15774/33150 (epoch 23.792), train_loss = 1.00793349, grad/param norm = 1.8070e-01, time/batch = 0.6930s	
15775/33150 (epoch 23.793), train_loss = 0.93899825, grad/param norm = 1.6531e-01, time/batch = 0.6751s	
15776/33150 (epoch 23.795), train_loss = 0.92766005, grad/param norm = 1.6485e-01, time/batch = 0.6787s	
15777/33150 (epoch 23.796), train_loss = 0.90635382, grad/param norm = 1.3565e-01, time/batch = 0.6935s	
15778/33150 (epoch 23.798), train_loss = 0.89974078, grad/param norm = 1.2829e-01, time/batch = 0.6716s	
15779/33150 (epoch 23.799), train_loss = 0.80744840, grad/param norm = 1.5635e-01, time/batch = 0.6741s	
15780/33150 (epoch 23.801), train_loss = 0.98329733, grad/param norm = 1.5882e-01, time/batch = 0.6849s	
15781/33150 (epoch 23.802), train_loss = 0.88333200, grad/param norm = 1.6714e-01, time/batch = 0.6836s	
15782/33150 (epoch 23.804), train_loss = 0.92684445, grad/param norm = 1.4537e-01, time/batch = 0.6737s	
15783/33150 (epoch 23.805), train_loss = 0.89545752, grad/param norm = 1.6396e-01, time/batch = 0.6815s	
15784/33150 (epoch 23.807), train_loss = 0.91944887, grad/param norm = 1.3980e-01, time/batch = 0.6930s	
15785/33150 (epoch 23.808), train_loss = 1.05363103, grad/param norm = 1.7081e-01, time/batch = 0.6763s	
15786/33150 (epoch 23.810), train_loss = 0.89225065, grad/param norm = 1.5130e-01, time/batch = 0.6712s	
15787/33150 (epoch 23.811), train_loss = 0.98941686, grad/param norm = 1.7909e-01, time/batch = 0.6731s	
15788/33150 (epoch 23.813), train_loss = 0.93066122, grad/param norm = 1.4805e-01, time/batch = 0.6771s	
15789/33150 (epoch 23.814), train_loss = 0.92373823, grad/param norm = 1.7337e-01, time/batch = 0.6952s	
15790/33150 (epoch 23.816), train_loss = 0.92940423, grad/param norm = 1.7808e-01, time/batch = 0.6781s	
15791/33150 (epoch 23.817), train_loss = 1.01594582, grad/param norm = 1.4876e-01, time/batch = 0.6811s	
15792/33150 (epoch 23.819), train_loss = 0.97404316, grad/param norm = 1.6134e-01, time/batch = 0.6816s	
15793/33150 (epoch 23.821), train_loss = 0.86539451, grad/param norm = 1.4336e-01, time/batch = 0.6718s	
15794/33150 (epoch 23.822), train_loss = 0.89557130, grad/param norm = 1.4302e-01, time/batch = 0.6739s	
15795/33150 (epoch 23.824), train_loss = 0.93628978, grad/param norm = 1.5550e-01, time/batch = 0.6752s	
15796/33150 (epoch 23.825), train_loss = 0.97991599, grad/param norm = 1.6701e-01, time/batch = 0.6738s	
15797/33150 (epoch 23.827), train_loss = 1.03305396, grad/param norm = 1.7756e-01, time/batch = 0.6753s	
15798/33150 (epoch 23.828), train_loss = 0.85015494, grad/param norm = 1.5603e-01, time/batch = 0.6755s	
15799/33150 (epoch 23.830), train_loss = 1.04631028, grad/param norm = 1.7325e-01, time/batch = 0.6714s	
15800/33150 (epoch 23.831), train_loss = 0.90095733, grad/param norm = 1.6796e-01, time/batch = 0.6705s	
15801/33150 (epoch 23.833), train_loss = 0.87356096, grad/param norm = 1.4666e-01, time/batch = 0.6708s	
15802/33150 (epoch 23.834), train_loss = 1.06225102, grad/param norm = 1.6201e-01, time/batch = 0.6695s	
15803/33150 (epoch 23.836), train_loss = 1.08257927, grad/param norm = 1.4924e-01, time/batch = 0.6783s	
15804/33150 (epoch 23.837), train_loss = 0.93033877, grad/param norm = 1.5391e-01, time/batch = 0.6855s	
15805/33150 (epoch 23.839), train_loss = 1.00658072, grad/param norm = 1.5752e-01, time/batch = 0.6958s	
15806/33150 (epoch 23.840), train_loss = 1.03037326, grad/param norm = 1.4853e-01, time/batch = 0.6881s	
15807/33150 (epoch 23.842), train_loss = 1.09256625, grad/param norm = 1.7315e-01, time/batch = 0.6756s	
15808/33150 (epoch 23.843), train_loss = 1.06990887, grad/param norm = 1.6762e-01, time/batch = 0.6751s	
15809/33150 (epoch 23.845), train_loss = 0.89718438, grad/param norm = 1.3820e-01, time/batch = 0.6704s	
15810/33150 (epoch 23.846), train_loss = 1.13303618, grad/param norm = 2.1009e-01, time/batch = 0.6738s	
15811/33150 (epoch 23.848), train_loss = 1.07242299, grad/param norm = 1.7691e-01, time/batch = 0.6837s	
15812/33150 (epoch 23.849), train_loss = 1.09053704, grad/param norm = 1.7134e-01, time/batch = 0.6747s	
15813/33150 (epoch 23.851), train_loss = 1.04010961, grad/param norm = 1.7126e-01, time/batch = 0.6764s	
15814/33150 (epoch 23.852), train_loss = 1.12644086, grad/param norm = 1.5753e-01, time/batch = 0.6789s	
15815/33150 (epoch 23.854), train_loss = 0.99132565, grad/param norm = 1.5451e-01, time/batch = 0.6839s	
15816/33150 (epoch 23.855), train_loss = 0.84660302, grad/param norm = 1.4879e-01, time/batch = 0.6803s	
15817/33150 (epoch 23.857), train_loss = 0.82297766, grad/param norm = 1.3716e-01, time/batch = 0.6829s	
15818/33150 (epoch 23.858), train_loss = 0.92703841, grad/param norm = 1.5737e-01, time/batch = 0.6854s	
15819/33150 (epoch 23.860), train_loss = 0.86010068, grad/param norm = 1.3499e-01, time/batch = 0.6850s	
15820/33150 (epoch 23.861), train_loss = 0.86587994, grad/param norm = 1.4866e-01, time/batch = 0.6902s	
15821/33150 (epoch 23.863), train_loss = 0.96695823, grad/param norm = 1.3795e-01, time/batch = 0.6795s	
15822/33150 (epoch 23.864), train_loss = 1.04246285, grad/param norm = 1.5185e-01, time/batch = 0.6807s	
15823/33150 (epoch 23.866), train_loss = 1.01813537, grad/param norm = 1.5532e-01, time/batch = 0.6806s	
15824/33150 (epoch 23.867), train_loss = 1.01742093, grad/param norm = 1.5590e-01, time/batch = 0.6872s	
15825/33150 (epoch 23.869), train_loss = 1.01329420, grad/param norm = 1.5825e-01, time/batch = 0.6916s	
15826/33150 (epoch 23.870), train_loss = 0.94245416, grad/param norm = 1.7399e-01, time/batch = 0.6930s	
15827/33150 (epoch 23.872), train_loss = 1.00297888, grad/param norm = 1.8068e-01, time/batch = 0.6932s	
15828/33150 (epoch 23.873), train_loss = 0.81866743, grad/param norm = 1.3346e-01, time/batch = 0.6942s	
15829/33150 (epoch 23.875), train_loss = 1.09384139, grad/param norm = 1.7061e-01, time/batch = 0.6930s	
15830/33150 (epoch 23.876), train_loss = 0.85461720, grad/param norm = 1.6903e-01, time/batch = 0.6826s	
15831/33150 (epoch 23.878), train_loss = 0.87766842, grad/param norm = 1.4047e-01, time/batch = 0.6768s	
15832/33150 (epoch 23.879), train_loss = 0.88826462, grad/param norm = 1.4430e-01, time/batch = 0.6758s	
15833/33150 (epoch 23.881), train_loss = 0.88442366, grad/param norm = 1.4888e-01, time/batch = 0.6852s	
15834/33150 (epoch 23.882), train_loss = 0.78100608, grad/param norm = 1.3919e-01, time/batch = 0.6727s	
15835/33150 (epoch 23.884), train_loss = 0.93453454, grad/param norm = 1.4036e-01, time/batch = 0.6717s	
15836/33150 (epoch 23.885), train_loss = 0.75119632, grad/param norm = 1.5883e-01, time/batch = 0.6713s	
15837/33150 (epoch 23.887), train_loss = 1.07214905, grad/param norm = 1.9881e-01, time/batch = 0.6714s	
15838/33150 (epoch 23.888), train_loss = 1.02189165, grad/param norm = 1.6930e-01, time/batch = 0.6707s	
15839/33150 (epoch 23.890), train_loss = 0.89039759, grad/param norm = 1.6591e-01, time/batch = 0.6721s	
15840/33150 (epoch 23.891), train_loss = 0.86595931, grad/param norm = 1.4815e-01, time/batch = 0.6711s	
15841/33150 (epoch 23.893), train_loss = 1.02143289, grad/param norm = 1.6373e-01, time/batch = 0.6785s	
15842/33150 (epoch 23.894), train_loss = 1.02125202, grad/param norm = 1.6651e-01, time/batch = 0.6842s	
15843/33150 (epoch 23.896), train_loss = 0.93925810, grad/param norm = 1.5075e-01, time/batch = 0.6822s	
15844/33150 (epoch 23.897), train_loss = 1.00694431, grad/param norm = 1.4802e-01, time/batch = 0.6817s	
15845/33150 (epoch 23.899), train_loss = 0.80518373, grad/param norm = 1.7069e-01, time/batch = 0.6807s	
15846/33150 (epoch 23.900), train_loss = 1.16783883, grad/param norm = 1.8059e-01, time/batch = 0.6824s	
15847/33150 (epoch 23.902), train_loss = 1.13801550, grad/param norm = 1.5727e-01, time/batch = 0.6817s	
15848/33150 (epoch 23.903), train_loss = 0.97241285, grad/param norm = 1.5498e-01, time/batch = 0.6831s	
15849/33150 (epoch 23.905), train_loss = 0.97845155, grad/param norm = 1.3503e-01, time/batch = 0.6734s	
15850/33150 (epoch 23.906), train_loss = 1.00078479, grad/param norm = 1.6127e-01, time/batch = 0.6725s	
15851/33150 (epoch 23.908), train_loss = 1.09354887, grad/param norm = 1.6246e-01, time/batch = 0.6790s	
15852/33150 (epoch 23.910), train_loss = 1.05747382, grad/param norm = 1.6763e-01, time/batch = 0.6734s	
15853/33150 (epoch 23.911), train_loss = 0.83252373, grad/param norm = 1.4274e-01, time/batch = 0.6697s	
15854/33150 (epoch 23.913), train_loss = 0.89107573, grad/param norm = 1.7282e-01, time/batch = 0.6734s	
15855/33150 (epoch 23.914), train_loss = 1.04972129, grad/param norm = 1.8350e-01, time/batch = 0.6717s	
15856/33150 (epoch 23.916), train_loss = 0.89490767, grad/param norm = 1.6736e-01, time/batch = 0.6666s	
15857/33150 (epoch 23.917), train_loss = 1.01194124, grad/param norm = 1.8329e-01, time/batch = 0.6762s	
15858/33150 (epoch 23.919), train_loss = 1.09933920, grad/param norm = 1.8324e-01, time/batch = 0.6920s	
15859/33150 (epoch 23.920), train_loss = 1.06746467, grad/param norm = 1.6105e-01, time/batch = 0.6883s	
15860/33150 (epoch 23.922), train_loss = 1.10732294, grad/param norm = 1.7861e-01, time/batch = 0.6953s	
15861/33150 (epoch 23.923), train_loss = 0.97111054, grad/param norm = 1.7126e-01, time/batch = 0.6757s	
15862/33150 (epoch 23.925), train_loss = 1.07645013, grad/param norm = 1.5848e-01, time/batch = 0.6722s	
15863/33150 (epoch 23.926), train_loss = 0.92719120, grad/param norm = 1.4694e-01, time/batch = 0.7005s	
15864/33150 (epoch 23.928), train_loss = 0.92378162, grad/param norm = 1.5618e-01, time/batch = 0.6801s	
15865/33150 (epoch 23.929), train_loss = 1.02329356, grad/param norm = 1.5880e-01, time/batch = 0.6777s	
15866/33150 (epoch 23.931), train_loss = 1.09880615, grad/param norm = 1.6623e-01, time/batch = 0.6788s	
15867/33150 (epoch 23.932), train_loss = 0.97526907, grad/param norm = 1.8116e-01, time/batch = 0.6740s	
15868/33150 (epoch 23.934), train_loss = 0.99878035, grad/param norm = 1.4822e-01, time/batch = 0.6707s	
15869/33150 (epoch 23.935), train_loss = 1.07796679, grad/param norm = 1.6090e-01, time/batch = 0.6694s	
15870/33150 (epoch 23.937), train_loss = 1.08565050, grad/param norm = 1.5321e-01, time/batch = 0.6687s	
15871/33150 (epoch 23.938), train_loss = 1.00520519, grad/param norm = 1.5707e-01, time/batch = 0.6705s	
15872/33150 (epoch 23.940), train_loss = 1.22768275, grad/param norm = 1.8808e-01, time/batch = 0.6697s	
15873/33150 (epoch 23.941), train_loss = 0.97295574, grad/param norm = 1.3455e-01, time/batch = 0.6734s	
15874/33150 (epoch 23.943), train_loss = 0.84974154, grad/param norm = 1.7603e-01, time/batch = 0.6715s	
15875/33150 (epoch 23.944), train_loss = 1.06400489, grad/param norm = 1.7332e-01, time/batch = 0.6714s	
15876/33150 (epoch 23.946), train_loss = 0.84181073, grad/param norm = 1.4219e-01, time/batch = 0.6690s	
15877/33150 (epoch 23.947), train_loss = 1.00400842, grad/param norm = 1.4535e-01, time/batch = 0.6716s	
15878/33150 (epoch 23.949), train_loss = 1.08585726, grad/param norm = 1.6152e-01, time/batch = 0.6689s	
15879/33150 (epoch 23.950), train_loss = 1.04219205, grad/param norm = 2.0410e-01, time/batch = 0.6750s	
15880/33150 (epoch 23.952), train_loss = 0.88334458, grad/param norm = 1.4905e-01, time/batch = 0.6712s	
15881/33150 (epoch 23.953), train_loss = 0.91868823, grad/param norm = 1.5329e-01, time/batch = 0.6714s	
15882/33150 (epoch 23.955), train_loss = 0.83969753, grad/param norm = 1.4357e-01, time/batch = 0.6787s	
15883/33150 (epoch 23.956), train_loss = 1.05010893, grad/param norm = 1.6390e-01, time/batch = 0.6772s	
15884/33150 (epoch 23.958), train_loss = 0.87430441, grad/param norm = 1.4319e-01, time/batch = 0.6740s	
15885/33150 (epoch 23.959), train_loss = 0.92105758, grad/param norm = 1.5114e-01, time/batch = 0.6728s	
15886/33150 (epoch 23.961), train_loss = 0.88964483, grad/param norm = 1.6096e-01, time/batch = 0.6781s	
15887/33150 (epoch 23.962), train_loss = 0.83658754, grad/param norm = 1.4191e-01, time/batch = 0.6758s	
15888/33150 (epoch 23.964), train_loss = 0.95721485, grad/param norm = 1.4051e-01, time/batch = 0.6726s	
15889/33150 (epoch 23.965), train_loss = 0.95513373, grad/param norm = 1.5489e-01, time/batch = 0.6839s	
15890/33150 (epoch 23.967), train_loss = 0.96500048, grad/param norm = 1.9422e-01, time/batch = 0.6705s	
15891/33150 (epoch 23.968), train_loss = 0.81750015, grad/param norm = 1.7060e-01, time/batch = 0.6857s	
15892/33150 (epoch 23.970), train_loss = 0.92155039, grad/param norm = 1.5225e-01, time/batch = 0.6920s	
15893/33150 (epoch 23.971), train_loss = 0.96834727, grad/param norm = 1.6243e-01, time/batch = 0.6695s	
15894/33150 (epoch 23.973), train_loss = 1.08452620, grad/param norm = 1.7666e-01, time/batch = 0.6738s	
15895/33150 (epoch 23.974), train_loss = 1.11575850, grad/param norm = 1.7612e-01, time/batch = 0.6706s	
15896/33150 (epoch 23.976), train_loss = 1.03219313, grad/param norm = 1.4231e-01, time/batch = 0.6704s	
15897/33150 (epoch 23.977), train_loss = 1.10756568, grad/param norm = 1.6234e-01, time/batch = 0.6718s	
15898/33150 (epoch 23.979), train_loss = 1.04250089, grad/param norm = 1.8213e-01, time/batch = 0.6695s	
15899/33150 (epoch 23.980), train_loss = 1.11815672, grad/param norm = 1.6719e-01, time/batch = 0.6716s	
15900/33150 (epoch 23.982), train_loss = 0.96568197, grad/param norm = 1.8297e-01, time/batch = 0.6722s	
15901/33150 (epoch 23.983), train_loss = 0.87823629, grad/param norm = 1.6371e-01, time/batch = 0.6759s	
15902/33150 (epoch 23.985), train_loss = 1.05162794, grad/param norm = 1.4362e-01, time/batch = 0.6855s	
15903/33150 (epoch 23.986), train_loss = 0.81105598, grad/param norm = 1.5099e-01, time/batch = 0.6784s	
15904/33150 (epoch 23.988), train_loss = 0.93189277, grad/param norm = 1.7138e-01, time/batch = 0.6721s	
15905/33150 (epoch 23.989), train_loss = 0.92115440, grad/param norm = 1.5948e-01, time/batch = 0.6754s	
15906/33150 (epoch 23.991), train_loss = 1.05404019, grad/param norm = 2.6602e-01, time/batch = 0.6789s	
15907/33150 (epoch 23.992), train_loss = 0.91419306, grad/param norm = 1.5359e-01, time/batch = 0.6748s	
15908/33150 (epoch 23.994), train_loss = 0.96544791, grad/param norm = 1.5680e-01, time/batch = 0.6703s	
15909/33150 (epoch 23.995), train_loss = 0.93218575, grad/param norm = 1.5252e-01, time/batch = 0.6766s	
15910/33150 (epoch 23.997), train_loss = 0.96997353, grad/param norm = 1.6808e-01, time/batch = 0.6721s	
15911/33150 (epoch 23.998), train_loss = 0.78878182, grad/param norm = 1.4098e-01, time/batch = 0.6777s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
15912/33150 (epoch 24.000), train_loss = 0.80840356, grad/param norm = 1.7102e-01, time/batch = 0.6772s	
15913/33150 (epoch 24.002), train_loss = 1.26583322, grad/param norm = 1.8909e-01, time/batch = 0.6792s	
15914/33150 (epoch 24.003), train_loss = 0.88621153, grad/param norm = 1.8300e-01, time/batch = 0.6920s	
15915/33150 (epoch 24.005), train_loss = 0.84057749, grad/param norm = 1.3568e-01, time/batch = 0.6846s	
15916/33150 (epoch 24.006), train_loss = 0.83449836, grad/param norm = 1.5430e-01, time/batch = 0.6818s	
15917/33150 (epoch 24.008), train_loss = 1.05568397, grad/param norm = 1.5977e-01, time/batch = 0.6707s	
15918/33150 (epoch 24.009), train_loss = 0.97720397, grad/param norm = 1.5482e-01, time/batch = 0.6828s	
15919/33150 (epoch 24.011), train_loss = 1.06145834, grad/param norm = 1.5439e-01, time/batch = 0.6694s	
15920/33150 (epoch 24.012), train_loss = 0.94314685, grad/param norm = 1.5517e-01, time/batch = 0.6680s	
15921/33150 (epoch 24.014), train_loss = 0.89512924, grad/param norm = 1.4850e-01, time/batch = 0.6941s	
15922/33150 (epoch 24.015), train_loss = 0.88875043, grad/param norm = 1.4713e-01, time/batch = 0.6821s	
15923/33150 (epoch 24.017), train_loss = 0.87238809, grad/param norm = 1.4179e-01, time/batch = 0.6723s	
15924/33150 (epoch 24.018), train_loss = 0.99110117, grad/param norm = 1.7135e-01, time/batch = 0.6727s	
15925/33150 (epoch 24.020), train_loss = 1.05906238, grad/param norm = 1.7852e-01, time/batch = 0.6711s	
15926/33150 (epoch 24.021), train_loss = 0.86300351, grad/param norm = 1.6169e-01, time/batch = 0.6673s	
15927/33150 (epoch 24.023), train_loss = 1.13803162, grad/param norm = 1.5946e-01, time/batch = 0.6687s	
15928/33150 (epoch 24.024), train_loss = 1.03975543, grad/param norm = 1.7664e-01, time/batch = 0.6714s	
15929/33150 (epoch 24.026), train_loss = 0.77697119, grad/param norm = 1.2905e-01, time/batch = 0.6695s	
15930/33150 (epoch 24.027), train_loss = 0.78175438, grad/param norm = 1.3263e-01, time/batch = 0.6710s	
15931/33150 (epoch 24.029), train_loss = 0.90554807, grad/param norm = 1.4971e-01, time/batch = 0.6740s	
15932/33150 (epoch 24.030), train_loss = 0.93967421, grad/param norm = 1.3936e-01, time/batch = 0.6710s	
15933/33150 (epoch 24.032), train_loss = 0.87271136, grad/param norm = 1.6677e-01, time/batch = 0.6753s	
15934/33150 (epoch 24.033), train_loss = 0.90047344, grad/param norm = 1.5884e-01, time/batch = 0.6717s	
15935/33150 (epoch 24.035), train_loss = 1.12178692, grad/param norm = 1.7647e-01, time/batch = 0.6695s	
15936/33150 (epoch 24.036), train_loss = 1.00893940, grad/param norm = 1.6636e-01, time/batch = 0.6701s	
15937/33150 (epoch 24.038), train_loss = 1.20379588, grad/param norm = 1.7533e-01, time/batch = 0.6703s	
15938/33150 (epoch 24.039), train_loss = 1.03198043, grad/param norm = 1.4743e-01, time/batch = 0.6694s	
15939/33150 (epoch 24.041), train_loss = 0.97944115, grad/param norm = 1.5527e-01, time/batch = 0.6723s	
15940/33150 (epoch 24.042), train_loss = 0.93121728, grad/param norm = 1.6087e-01, time/batch = 0.6793s	
15941/33150 (epoch 24.044), train_loss = 0.94510491, grad/param norm = 1.5161e-01, time/batch = 0.6850s	
15942/33150 (epoch 24.045), train_loss = 0.98582835, grad/param norm = 1.4494e-01, time/batch = 0.6731s	
15943/33150 (epoch 24.047), train_loss = 0.84256496, grad/param norm = 1.4062e-01, time/batch = 0.6766s	
15944/33150 (epoch 24.048), train_loss = 1.04481876, grad/param norm = 1.8087e-01, time/batch = 0.6742s	
15945/33150 (epoch 24.050), train_loss = 0.97106658, grad/param norm = 1.6611e-01, time/batch = 0.6756s	
15946/33150 (epoch 24.051), train_loss = 0.97395505, grad/param norm = 1.4611e-01, time/batch = 0.6902s	
15947/33150 (epoch 24.053), train_loss = 0.94479055, grad/param norm = 1.6926e-01, time/batch = 0.6897s	
15948/33150 (epoch 24.054), train_loss = 1.08033516, grad/param norm = 1.4964e-01, time/batch = 0.6867s	
15949/33150 (epoch 24.056), train_loss = 0.96257718, grad/param norm = 1.5851e-01, time/batch = 0.6704s	
15950/33150 (epoch 24.057), train_loss = 0.98392982, grad/param norm = 1.6994e-01, time/batch = 0.6805s	
15951/33150 (epoch 24.059), train_loss = 0.89980046, grad/param norm = 1.5157e-01, time/batch = 0.6870s	
15952/33150 (epoch 24.060), train_loss = 0.88915325, grad/param norm = 1.4186e-01, time/batch = 0.6703s	
15953/33150 (epoch 24.062), train_loss = 0.93874265, grad/param norm = 1.5934e-01, time/batch = 0.6783s	
15954/33150 (epoch 24.063), train_loss = 0.92617850, grad/param norm = 1.7218e-01, time/batch = 0.6709s	
15955/33150 (epoch 24.065), train_loss = 0.93052516, grad/param norm = 1.4549e-01, time/batch = 0.6721s	
15956/33150 (epoch 24.066), train_loss = 0.88052478, grad/param norm = 1.4230e-01, time/batch = 0.6730s	
15957/33150 (epoch 24.068), train_loss = 1.00570304, grad/param norm = 1.4835e-01, time/batch = 0.6750s	
15958/33150 (epoch 24.069), train_loss = 0.98556458, grad/param norm = 1.7575e-01, time/batch = 0.6709s	
15959/33150 (epoch 24.071), train_loss = 0.98206764, grad/param norm = 1.4564e-01, time/batch = 0.6729s	
15960/33150 (epoch 24.072), train_loss = 0.94470702, grad/param norm = 1.5158e-01, time/batch = 0.6750s	
15961/33150 (epoch 24.074), train_loss = 0.85476932, grad/param norm = 1.7381e-01, time/batch = 0.6757s	
15962/33150 (epoch 24.075), train_loss = 0.90034059, grad/param norm = 1.6783e-01, time/batch = 0.6844s	
15963/33150 (epoch 24.077), train_loss = 0.94260173, grad/param norm = 2.0838e-01, time/batch = 0.6747s	
15964/33150 (epoch 24.078), train_loss = 1.08328635, grad/param norm = 1.8094e-01, time/batch = 0.6746s	
15965/33150 (epoch 24.080), train_loss = 1.07353527, grad/param norm = 1.5328e-01, time/batch = 0.6824s	
15966/33150 (epoch 24.081), train_loss = 0.86029357, grad/param norm = 1.6368e-01, time/batch = 0.6869s	
15967/33150 (epoch 24.083), train_loss = 0.72665887, grad/param norm = 1.5851e-01, time/batch = 0.6789s	
15968/33150 (epoch 24.084), train_loss = 0.83972617, grad/param norm = 1.6360e-01, time/batch = 0.6761s	
15969/33150 (epoch 24.086), train_loss = 0.89181843, grad/param norm = 1.7144e-01, time/batch = 0.6717s	
15970/33150 (epoch 24.087), train_loss = 0.84674720, grad/param norm = 1.7005e-01, time/batch = 0.6800s	
15971/33150 (epoch 24.089), train_loss = 0.86777757, grad/param norm = 1.4832e-01, time/batch = 0.6723s	
15972/33150 (epoch 24.090), train_loss = 0.92654673, grad/param norm = 1.6642e-01, time/batch = 0.6697s	
15973/33150 (epoch 24.092), train_loss = 0.90065070, grad/param norm = 1.6120e-01, time/batch = 0.6791s	
15974/33150 (epoch 24.094), train_loss = 1.01712775, grad/param norm = 1.7369e-01, time/batch = 0.6860s	
15975/33150 (epoch 24.095), train_loss = 0.87740097, grad/param norm = 1.4597e-01, time/batch = 0.6853s	
15976/33150 (epoch 24.097), train_loss = 0.85929753, grad/param norm = 1.6294e-01, time/batch = 0.6771s	
15977/33150 (epoch 24.098), train_loss = 1.18738832, grad/param norm = 1.7581e-01, time/batch = 0.6720s	
15978/33150 (epoch 24.100), train_loss = 1.12922605, grad/param norm = 1.7197e-01, time/batch = 0.6829s	
15979/33150 (epoch 24.101), train_loss = 0.88749635, grad/param norm = 1.4676e-01, time/batch = 0.6673s	
15980/33150 (epoch 24.103), train_loss = 0.96694969, grad/param norm = 1.5103e-01, time/batch = 0.6676s	
15981/33150 (epoch 24.104), train_loss = 0.87839848, grad/param norm = 1.7111e-01, time/batch = 0.6703s	
15982/33150 (epoch 24.106), train_loss = 1.08041898, grad/param norm = 1.8145e-01, time/batch = 0.6733s	
15983/33150 (epoch 24.107), train_loss = 1.18360358, grad/param norm = 1.8397e-01, time/batch = 0.6737s	
15984/33150 (epoch 24.109), train_loss = 0.93687729, grad/param norm = 1.3934e-01, time/batch = 0.6820s	
15985/33150 (epoch 24.110), train_loss = 1.07393817, grad/param norm = 1.9072e-01, time/batch = 0.6823s	
15986/33150 (epoch 24.112), train_loss = 0.89268560, grad/param norm = 1.5102e-01, time/batch = 0.6741s	
15987/33150 (epoch 24.113), train_loss = 0.90828722, grad/param norm = 1.5938e-01, time/batch = 0.6730s	
15988/33150 (epoch 24.115), train_loss = 1.13701140, grad/param norm = 1.8746e-01, time/batch = 0.6736s	
15989/33150 (epoch 24.116), train_loss = 0.96107448, grad/param norm = 1.5627e-01, time/batch = 0.6727s	
15990/33150 (epoch 24.118), train_loss = 1.01538826, grad/param norm = 1.6489e-01, time/batch = 0.6732s	
15991/33150 (epoch 24.119), train_loss = 1.04632878, grad/param norm = 1.9304e-01, time/batch = 0.6705s	
15992/33150 (epoch 24.121), train_loss = 0.92152854, grad/param norm = 1.5185e-01, time/batch = 0.6736s	
15993/33150 (epoch 24.122), train_loss = 1.14804395, grad/param norm = 2.0784e-01, time/batch = 0.6767s	
15994/33150 (epoch 24.124), train_loss = 0.81178108, grad/param norm = 1.3584e-01, time/batch = 0.6757s	
15995/33150 (epoch 24.125), train_loss = 1.05156665, grad/param norm = 1.6120e-01, time/batch = 0.6766s	
15996/33150 (epoch 24.127), train_loss = 0.94372886, grad/param norm = 1.3990e-01, time/batch = 0.6753s	
15997/33150 (epoch 24.128), train_loss = 1.00977820, grad/param norm = 1.8132e-01, time/batch = 0.6809s	
15998/33150 (epoch 24.130), train_loss = 0.99888064, grad/param norm = 1.6734e-01, time/batch = 0.6747s	
15999/33150 (epoch 24.131), train_loss = 1.17926191, grad/param norm = 1.6675e-01, time/batch = 0.6841s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch24.13_1.6318.t7	
16000/33150 (epoch 24.133), train_loss = 0.87990488, grad/param norm = 1.5061e-01, time/batch = 0.6821s	
16001/33150 (epoch 24.134), train_loss = 1.38460233, grad/param norm = 1.8830e-01, time/batch = 0.6791s	
16002/33150 (epoch 24.136), train_loss = 0.96779919, grad/param norm = 1.6400e-01, time/batch = 0.6755s	
16003/33150 (epoch 24.137), train_loss = 1.06524942, grad/param norm = 1.6769e-01, time/batch = 0.6936s	
16004/33150 (epoch 24.139), train_loss = 1.05034085, grad/param norm = 1.7543e-01, time/batch = 0.6785s	
16005/33150 (epoch 24.140), train_loss = 1.10344239, grad/param norm = 1.7072e-01, time/batch = 0.6734s	
16006/33150 (epoch 24.142), train_loss = 1.06697414, grad/param norm = 1.8484e-01, time/batch = 0.6675s	
16007/33150 (epoch 24.143), train_loss = 0.99500317, grad/param norm = 1.8503e-01, time/batch = 0.6699s	
16008/33150 (epoch 24.145), train_loss = 0.96551808, grad/param norm = 2.1590e-01, time/batch = 0.6752s	
16009/33150 (epoch 24.146), train_loss = 1.07374073, grad/param norm = 2.1043e-01, time/batch = 0.6724s	
16010/33150 (epoch 24.148), train_loss = 1.10848605, grad/param norm = 1.5468e-01, time/batch = 0.6762s	
16011/33150 (epoch 24.149), train_loss = 0.98685150, grad/param norm = 1.5258e-01, time/batch = 0.6722s	
16012/33150 (epoch 24.151), train_loss = 1.14598920, grad/param norm = 1.6519e-01, time/batch = 0.6747s	
16013/33150 (epoch 24.152), train_loss = 0.96855137, grad/param norm = 1.5379e-01, time/batch = 0.6716s	
16014/33150 (epoch 24.154), train_loss = 0.92705348, grad/param norm = 1.6362e-01, time/batch = 0.6735s	
16015/33150 (epoch 24.155), train_loss = 0.82031224, grad/param norm = 1.4468e-01, time/batch = 0.6726s	
16016/33150 (epoch 24.157), train_loss = 0.94440563, grad/param norm = 1.6637e-01, time/batch = 0.6736s	
16017/33150 (epoch 24.158), train_loss = 0.90331090, grad/param norm = 1.4091e-01, time/batch = 0.6883s	
16018/33150 (epoch 24.160), train_loss = 1.02773364, grad/param norm = 1.6311e-01, time/batch = 0.6822s	
16019/33150 (epoch 24.161), train_loss = 0.90304057, grad/param norm = 1.7233e-01, time/batch = 0.6745s	
16020/33150 (epoch 24.163), train_loss = 0.87254304, grad/param norm = 1.4857e-01, time/batch = 0.6765s	
16021/33150 (epoch 24.164), train_loss = 1.02543809, grad/param norm = 1.7327e-01, time/batch = 0.6754s	
16022/33150 (epoch 24.166), train_loss = 0.95209764, grad/param norm = 1.6316e-01, time/batch = 0.6761s	
16023/33150 (epoch 24.167), train_loss = 0.98700298, grad/param norm = 1.5866e-01, time/batch = 0.6791s	
16024/33150 (epoch 24.169), train_loss = 0.99658620, grad/param norm = 1.9446e-01, time/batch = 0.6790s	
16025/33150 (epoch 24.170), train_loss = 0.88431134, grad/param norm = 2.0536e-01, time/batch = 0.6926s	
16026/33150 (epoch 24.172), train_loss = 1.07591476, grad/param norm = 1.9045e-01, time/batch = 0.6939s	
16027/33150 (epoch 24.173), train_loss = 1.03112352, grad/param norm = 1.8641e-01, time/batch = 0.6880s	
16028/33150 (epoch 24.175), train_loss = 0.92067630, grad/param norm = 1.5749e-01, time/batch = 0.6837s	
16029/33150 (epoch 24.176), train_loss = 1.02897542, grad/param norm = 1.7222e-01, time/batch = 0.6741s	
16030/33150 (epoch 24.178), train_loss = 1.16613791, grad/param norm = 1.7532e-01, time/batch = 0.6807s	
16031/33150 (epoch 24.179), train_loss = 1.02731843, grad/param norm = 1.5306e-01, time/batch = 0.6884s	
16032/33150 (epoch 24.181), train_loss = 0.97327243, grad/param norm = 1.6469e-01, time/batch = 0.6781s	
16033/33150 (epoch 24.183), train_loss = 0.95214914, grad/param norm = 1.7052e-01, time/batch = 0.6815s	
16034/33150 (epoch 24.184), train_loss = 1.17946982, grad/param norm = 1.6965e-01, time/batch = 0.6853s	
16035/33150 (epoch 24.186), train_loss = 1.09458556, grad/param norm = 1.6406e-01, time/batch = 0.6823s	
16036/33150 (epoch 24.187), train_loss = 1.00287630, grad/param norm = 1.6232e-01, time/batch = 0.6664s	
16037/33150 (epoch 24.189), train_loss = 0.77344958, grad/param norm = 1.4736e-01, time/batch = 0.6659s	
16038/33150 (epoch 24.190), train_loss = 0.87343277, grad/param norm = 1.5391e-01, time/batch = 0.6724s	
16039/33150 (epoch 24.192), train_loss = 0.98562470, grad/param norm = 1.8362e-01, time/batch = 0.6748s	
16040/33150 (epoch 24.193), train_loss = 1.05810173, grad/param norm = 1.6171e-01, time/batch = 0.6704s	
16041/33150 (epoch 24.195), train_loss = 1.19521368, grad/param norm = 1.9765e-01, time/batch = 0.6705s	
16042/33150 (epoch 24.196), train_loss = 1.08628305, grad/param norm = 1.6541e-01, time/batch = 0.6681s	
16043/33150 (epoch 24.198), train_loss = 0.83774264, grad/param norm = 1.4212e-01, time/batch = 0.6696s	
16044/33150 (epoch 24.199), train_loss = 1.09718422, grad/param norm = 2.3526e-01, time/batch = 0.6721s	
16045/33150 (epoch 24.201), train_loss = 0.89475000, grad/param norm = 1.2983e-01, time/batch = 0.6719s	
16046/33150 (epoch 24.202), train_loss = 0.78442330, grad/param norm = 1.4531e-01, time/batch = 0.6742s	
16047/33150 (epoch 24.204), train_loss = 1.01701050, grad/param norm = 1.6171e-01, time/batch = 0.6753s	
16048/33150 (epoch 24.205), train_loss = 1.05092820, grad/param norm = 1.6626e-01, time/batch = 0.6766s	
16049/33150 (epoch 24.207), train_loss = 1.02655825, grad/param norm = 1.6010e-01, time/batch = 0.6856s	
16050/33150 (epoch 24.208), train_loss = 1.04119740, grad/param norm = 1.8096e-01, time/batch = 0.6682s	
16051/33150 (epoch 24.210), train_loss = 0.91086003, grad/param norm = 1.3978e-01, time/batch = 0.6690s	
16052/33150 (epoch 24.211), train_loss = 1.00031105, grad/param norm = 1.7728e-01, time/batch = 0.6699s	
16053/33150 (epoch 24.213), train_loss = 1.03553556, grad/param norm = 1.6022e-01, time/batch = 0.6724s	
16054/33150 (epoch 24.214), train_loss = 0.95942345, grad/param norm = 1.5639e-01, time/batch = 0.6734s	
16055/33150 (epoch 24.216), train_loss = 0.90194861, grad/param norm = 1.6122e-01, time/batch = 0.6694s	
16056/33150 (epoch 24.217), train_loss = 0.94424928, grad/param norm = 1.3861e-01, time/batch = 0.6713s	
16057/33150 (epoch 24.219), train_loss = 0.87893102, grad/param norm = 1.5664e-01, time/batch = 0.6697s	
16058/33150 (epoch 24.220), train_loss = 0.91104603, grad/param norm = 1.4291e-01, time/batch = 0.6720s	
16059/33150 (epoch 24.222), train_loss = 1.08550162, grad/param norm = 1.5852e-01, time/batch = 0.6720s	
16060/33150 (epoch 24.223), train_loss = 0.97963275, grad/param norm = 1.6902e-01, time/batch = 0.6702s	
16061/33150 (epoch 24.225), train_loss = 1.10358067, grad/param norm = 1.5813e-01, time/batch = 0.6705s	
16062/33150 (epoch 24.226), train_loss = 0.96166324, grad/param norm = 1.4877e-01, time/batch = 0.6736s	
16063/33150 (epoch 24.228), train_loss = 0.95515062, grad/param norm = 1.5658e-01, time/batch = 0.6810s	
16064/33150 (epoch 24.229), train_loss = 0.97389926, grad/param norm = 1.5899e-01, time/batch = 0.6830s	
16065/33150 (epoch 24.231), train_loss = 1.10014234, grad/param norm = 1.9739e-01, time/batch = 0.6780s	
16066/33150 (epoch 24.232), train_loss = 0.99752905, grad/param norm = 1.7662e-01, time/batch = 0.6773s	
16067/33150 (epoch 24.234), train_loss = 0.95525079, grad/param norm = 1.5969e-01, time/batch = 0.6721s	
16068/33150 (epoch 24.235), train_loss = 1.02948330, grad/param norm = 1.9041e-01, time/batch = 0.6707s	
16069/33150 (epoch 24.237), train_loss = 0.99666976, grad/param norm = 1.9174e-01, time/batch = 0.6716s	
16070/33150 (epoch 24.238), train_loss = 1.02581378, grad/param norm = 1.7669e-01, time/batch = 0.6680s	
16071/33150 (epoch 24.240), train_loss = 1.03108697, grad/param norm = 1.8874e-01, time/batch = 0.6730s	
16072/33150 (epoch 24.241), train_loss = 1.08436923, grad/param norm = 1.9042e-01, time/batch = 0.6721s	
16073/33150 (epoch 24.243), train_loss = 1.07778758, grad/param norm = 1.8978e-01, time/batch = 0.6714s	
16074/33150 (epoch 24.244), train_loss = 0.96314658, grad/param norm = 1.5254e-01, time/batch = 0.6796s	
16075/33150 (epoch 24.246), train_loss = 1.03818759, grad/param norm = 1.5685e-01, time/batch = 0.6811s	
16076/33150 (epoch 24.247), train_loss = 0.93073631, grad/param norm = 1.4905e-01, time/batch = 0.6734s	
16077/33150 (epoch 24.249), train_loss = 1.08479966, grad/param norm = 1.9901e-01, time/batch = 0.6734s	
16078/33150 (epoch 24.250), train_loss = 1.05021952, grad/param norm = 1.5039e-01, time/batch = 0.6729s	
16079/33150 (epoch 24.252), train_loss = 1.04149145, grad/param norm = 1.3936e-01, time/batch = 0.6717s	
16080/33150 (epoch 24.253), train_loss = 0.95693811, grad/param norm = 1.6408e-01, time/batch = 0.6713s	
16081/33150 (epoch 24.255), train_loss = 0.94674626, grad/param norm = 1.3985e-01, time/batch = 0.6762s	
16082/33150 (epoch 24.256), train_loss = 1.05365585, grad/param norm = 1.5279e-01, time/batch = 0.6766s	
16083/33150 (epoch 24.258), train_loss = 0.92484639, grad/param norm = 1.7838e-01, time/batch = 0.6759s	
16084/33150 (epoch 24.259), train_loss = 0.80228326, grad/param norm = 1.4984e-01, time/batch = 0.6899s	
16085/33150 (epoch 24.261), train_loss = 0.86287950, grad/param norm = 1.3374e-01, time/batch = 0.6893s	
16086/33150 (epoch 24.262), train_loss = 1.05270675, grad/param norm = 1.7303e-01, time/batch = 0.6902s	
16087/33150 (epoch 24.264), train_loss = 0.76082500, grad/param norm = 1.6508e-01, time/batch = 0.6925s	
16088/33150 (epoch 24.265), train_loss = 1.01101324, grad/param norm = 1.5662e-01, time/batch = 0.6862s	
16089/33150 (epoch 24.267), train_loss = 1.03791605, grad/param norm = 1.9253e-01, time/batch = 0.6779s	
16090/33150 (epoch 24.268), train_loss = 1.07409344, grad/param norm = 1.4972e-01, time/batch = 0.6884s	
16091/33150 (epoch 24.270), train_loss = 1.15491898, grad/param norm = 1.6402e-01, time/batch = 0.6820s	
16092/33150 (epoch 24.271), train_loss = 1.08603951, grad/param norm = 1.7948e-01, time/batch = 0.6882s	
16093/33150 (epoch 24.273), train_loss = 1.08946401, grad/param norm = 1.5426e-01, time/batch = 0.6846s	
16094/33150 (epoch 24.275), train_loss = 1.10464940, grad/param norm = 1.6757e-01, time/batch = 0.6823s	
16095/33150 (epoch 24.276), train_loss = 1.00141194, grad/param norm = 1.6832e-01, time/batch = 0.6758s	
16096/33150 (epoch 24.278), train_loss = 1.08668168, grad/param norm = 1.5459e-01, time/batch = 0.6683s	
16097/33150 (epoch 24.279), train_loss = 1.04060256, grad/param norm = 1.6131e-01, time/batch = 0.6709s	
16098/33150 (epoch 24.281), train_loss = 1.00522147, grad/param norm = 1.5054e-01, time/batch = 0.6850s	
16099/33150 (epoch 24.282), train_loss = 1.00496735, grad/param norm = 1.4051e-01, time/batch = 0.6845s	
16100/33150 (epoch 24.284), train_loss = 0.92624884, grad/param norm = 1.4902e-01, time/batch = 0.6859s	
16101/33150 (epoch 24.285), train_loss = 0.99045997, grad/param norm = 1.5010e-01, time/batch = 0.6902s	
16102/33150 (epoch 24.287), train_loss = 0.87980765, grad/param norm = 1.4688e-01, time/batch = 0.6869s	
16103/33150 (epoch 24.288), train_loss = 1.06986121, grad/param norm = 1.5439e-01, time/batch = 0.6768s	
16104/33150 (epoch 24.290), train_loss = 0.84846331, grad/param norm = 1.5955e-01, time/batch = 0.6714s	
16105/33150 (epoch 24.291), train_loss = 0.81544393, grad/param norm = 1.4496e-01, time/batch = 0.6689s	
16106/33150 (epoch 24.293), train_loss = 1.02933085, grad/param norm = 1.5650e-01, time/batch = 0.6687s	
16107/33150 (epoch 24.294), train_loss = 0.73943860, grad/param norm = 1.3744e-01, time/batch = 0.6688s	
16108/33150 (epoch 24.296), train_loss = 0.96230254, grad/param norm = 1.4992e-01, time/batch = 0.6694s	
16109/33150 (epoch 24.297), train_loss = 0.91879815, grad/param norm = 1.5088e-01, time/batch = 0.6673s	
16110/33150 (epoch 24.299), train_loss = 0.90108702, grad/param norm = 1.6109e-01, time/batch = 0.6692s	
16111/33150 (epoch 24.300), train_loss = 0.91831501, grad/param norm = 1.3426e-01, time/batch = 0.6730s	
16112/33150 (epoch 24.302), train_loss = 0.93878831, grad/param norm = 1.4872e-01, time/batch = 0.6774s	
16113/33150 (epoch 24.303), train_loss = 0.94322555, grad/param norm = 1.5172e-01, time/batch = 0.6900s	
16114/33150 (epoch 24.305), train_loss = 1.03697564, grad/param norm = 1.5447e-01, time/batch = 0.6914s	
16115/33150 (epoch 24.306), train_loss = 1.03935836, grad/param norm = 1.9735e-01, time/batch = 0.6871s	
16116/33150 (epoch 24.308), train_loss = 1.21062073, grad/param norm = 1.7448e-01, time/batch = 0.7077s	
16117/33150 (epoch 24.309), train_loss = 0.80846877, grad/param norm = 1.3543e-01, time/batch = 0.6760s	
16118/33150 (epoch 24.311), train_loss = 0.93663556, grad/param norm = 1.5717e-01, time/batch = 0.6722s	
16119/33150 (epoch 24.312), train_loss = 0.78631360, grad/param norm = 1.4673e-01, time/batch = 0.6716s	
16120/33150 (epoch 24.314), train_loss = 0.93666010, grad/param norm = 1.7690e-01, time/batch = 0.6753s	
16121/33150 (epoch 24.315), train_loss = 1.01393537, grad/param norm = 1.5907e-01, time/batch = 0.6775s	
16122/33150 (epoch 24.317), train_loss = 0.78907095, grad/param norm = 1.2814e-01, time/batch = 0.6731s	
16123/33150 (epoch 24.318), train_loss = 0.88535084, grad/param norm = 1.3445e-01, time/batch = 0.6797s	
16124/33150 (epoch 24.320), train_loss = 0.81558322, grad/param norm = 1.3182e-01, time/batch = 0.6904s	
16125/33150 (epoch 24.321), train_loss = 0.93945379, grad/param norm = 1.3808e-01, time/batch = 0.6717s	
16126/33150 (epoch 24.323), train_loss = 0.96037448, grad/param norm = 1.5989e-01, time/batch = 0.6871s	
16127/33150 (epoch 24.324), train_loss = 1.03405837, grad/param norm = 1.8475e-01, time/batch = 0.6889s	
16128/33150 (epoch 24.326), train_loss = 0.99592460, grad/param norm = 1.5441e-01, time/batch = 0.6717s	
16129/33150 (epoch 24.327), train_loss = 1.09202475, grad/param norm = 1.5594e-01, time/batch = 0.6749s	
16130/33150 (epoch 24.329), train_loss = 1.02110910, grad/param norm = 1.4797e-01, time/batch = 0.6774s	
16131/33150 (epoch 24.330), train_loss = 0.95599973, grad/param norm = 1.8085e-01, time/batch = 0.6762s	
16132/33150 (epoch 24.332), train_loss = 0.96596410, grad/param norm = 1.3713e-01, time/batch = 0.6757s	
16133/33150 (epoch 24.333), train_loss = 1.01819137, grad/param norm = 1.3471e-01, time/batch = 0.6792s	
16134/33150 (epoch 24.335), train_loss = 0.91457788, grad/param norm = 1.5499e-01, time/batch = 0.6790s	
16135/33150 (epoch 24.336), train_loss = 0.88811536, grad/param norm = 1.6059e-01, time/batch = 0.6783s	
16136/33150 (epoch 24.338), train_loss = 0.81183677, grad/param norm = 1.4920e-01, time/batch = 0.6743s	
16137/33150 (epoch 24.339), train_loss = 1.04169205, grad/param norm = 1.5614e-01, time/batch = 0.6725s	
16138/33150 (epoch 24.341), train_loss = 1.01222692, grad/param norm = 1.7747e-01, time/batch = 0.6709s	
16139/33150 (epoch 24.342), train_loss = 0.86762637, grad/param norm = 1.5451e-01, time/batch = 0.6781s	
16140/33150 (epoch 24.344), train_loss = 0.98162440, grad/param norm = 1.9211e-01, time/batch = 0.6694s	
16141/33150 (epoch 24.345), train_loss = 0.93070216, grad/param norm = 1.4757e-01, time/batch = 0.6848s	
16142/33150 (epoch 24.347), train_loss = 0.77320222, grad/param norm = 1.4214e-01, time/batch = 0.6838s	
16143/33150 (epoch 24.348), train_loss = 0.97242663, grad/param norm = 1.5450e-01, time/batch = 0.6702s	
16144/33150 (epoch 24.350), train_loss = 0.85817130, grad/param norm = 1.7436e-01, time/batch = 0.6713s	
16145/33150 (epoch 24.351), train_loss = 1.03156351, grad/param norm = 1.5725e-01, time/batch = 0.6693s	
16146/33150 (epoch 24.353), train_loss = 1.00953763, grad/param norm = 1.7302e-01, time/batch = 0.6680s	
16147/33150 (epoch 24.354), train_loss = 1.21232899, grad/param norm = 1.6639e-01, time/batch = 0.6691s	
16148/33150 (epoch 24.356), train_loss = 1.07636456, grad/param norm = 1.8753e-01, time/batch = 0.6695s	
16149/33150 (epoch 24.357), train_loss = 1.00989200, grad/param norm = 1.6653e-01, time/batch = 0.6687s	
16150/33150 (epoch 24.359), train_loss = 1.03325397, grad/param norm = 1.5987e-01, time/batch = 0.6697s	
16151/33150 (epoch 24.360), train_loss = 1.05234718, grad/param norm = 1.9445e-01, time/batch = 0.6731s	
16152/33150 (epoch 24.362), train_loss = 1.09707776, grad/param norm = 1.8080e-01, time/batch = 0.6718s	
16153/33150 (epoch 24.363), train_loss = 0.97546015, grad/param norm = 1.4911e-01, time/batch = 0.6715s	
16154/33150 (epoch 24.365), train_loss = 0.96540605, grad/param norm = 1.4656e-01, time/batch = 0.6699s	
16155/33150 (epoch 24.367), train_loss = 0.93370333, grad/param norm = 1.5116e-01, time/batch = 0.6761s	
16156/33150 (epoch 24.368), train_loss = 0.98097969, grad/param norm = 1.9607e-01, time/batch = 0.6850s	
16157/33150 (epoch 24.370), train_loss = 0.99538630, grad/param norm = 1.6262e-01, time/batch = 0.6786s	
16158/33150 (epoch 24.371), train_loss = 0.87351780, grad/param norm = 1.4203e-01, time/batch = 0.6713s	
16159/33150 (epoch 24.373), train_loss = 1.04506181, grad/param norm = 1.8546e-01, time/batch = 0.6722s	
16160/33150 (epoch 24.374), train_loss = 0.93382293, grad/param norm = 1.4506e-01, time/batch = 0.6914s	
16161/33150 (epoch 24.376), train_loss = 1.08817197, grad/param norm = 1.7143e-01, time/batch = 0.6983s	
16162/33150 (epoch 24.377), train_loss = 0.90459869, grad/param norm = 1.4718e-01, time/batch = 0.6883s	
16163/33150 (epoch 24.379), train_loss = 1.05054434, grad/param norm = 1.7574e-01, time/batch = 0.6969s	
16164/33150 (epoch 24.380), train_loss = 1.03913893, grad/param norm = 1.4380e-01, time/batch = 0.6776s	
16165/33150 (epoch 24.382), train_loss = 0.94337804, grad/param norm = 1.6529e-01, time/batch = 0.6827s	
16166/33150 (epoch 24.383), train_loss = 0.89008323, grad/param norm = 1.5335e-01, time/batch = 0.6725s	
16167/33150 (epoch 24.385), train_loss = 0.94843005, grad/param norm = 1.4992e-01, time/batch = 0.6711s	
16168/33150 (epoch 24.386), train_loss = 0.83424034, grad/param norm = 1.3667e-01, time/batch = 0.6725s	
16169/33150 (epoch 24.388), train_loss = 0.90389124, grad/param norm = 1.4138e-01, time/batch = 0.6727s	
16170/33150 (epoch 24.389), train_loss = 0.90513533, grad/param norm = 1.4458e-01, time/batch = 0.6713s	
16171/33150 (epoch 24.391), train_loss = 1.13386860, grad/param norm = 1.6781e-01, time/batch = 0.6729s	
16172/33150 (epoch 24.392), train_loss = 0.92183276, grad/param norm = 1.4716e-01, time/batch = 0.6743s	
16173/33150 (epoch 24.394), train_loss = 0.80116284, grad/param norm = 1.2488e-01, time/batch = 0.6689s	
16174/33150 (epoch 24.395), train_loss = 0.80684142, grad/param norm = 1.4884e-01, time/batch = 0.6721s	
16175/33150 (epoch 24.397), train_loss = 0.66702943, grad/param norm = 1.3259e-01, time/batch = 0.6851s	
16176/33150 (epoch 24.398), train_loss = 0.98320821, grad/param norm = 1.8337e-01, time/batch = 0.6772s	
16177/33150 (epoch 24.400), train_loss = 0.92932937, grad/param norm = 1.3685e-01, time/batch = 0.6730s	
16178/33150 (epoch 24.401), train_loss = 0.81341016, grad/param norm = 1.2846e-01, time/batch = 0.6711s	
16179/33150 (epoch 24.403), train_loss = 0.81748353, grad/param norm = 1.2830e-01, time/batch = 0.6703s	
16180/33150 (epoch 24.404), train_loss = 0.97238426, grad/param norm = 1.6643e-01, time/batch = 0.6691s	
16181/33150 (epoch 24.406), train_loss = 0.90891469, grad/param norm = 1.2985e-01, time/batch = 0.6733s	
16182/33150 (epoch 24.407), train_loss = 0.83142970, grad/param norm = 1.4025e-01, time/batch = 0.6679s	
16183/33150 (epoch 24.409), train_loss = 0.78428539, grad/param norm = 1.3334e-01, time/batch = 0.6701s	
16184/33150 (epoch 24.410), train_loss = 0.98087784, grad/param norm = 1.6253e-01, time/batch = 0.6695s	
16185/33150 (epoch 24.412), train_loss = 1.01008729, grad/param norm = 1.5386e-01, time/batch = 0.6703s	
16186/33150 (epoch 24.413), train_loss = 0.87467593, grad/param norm = 1.5242e-01, time/batch = 0.6737s	
16187/33150 (epoch 24.415), train_loss = 0.97794186, grad/param norm = 1.4357e-01, time/batch = 0.6721s	
16188/33150 (epoch 24.416), train_loss = 0.88595800, grad/param norm = 1.4494e-01, time/batch = 0.6800s	
16189/33150 (epoch 24.418), train_loss = 1.03036751, grad/param norm = 1.8270e-01, time/batch = 0.6789s	
16190/33150 (epoch 24.419), train_loss = 0.90718159, grad/param norm = 1.4894e-01, time/batch = 0.6847s	
16191/33150 (epoch 24.421), train_loss = 0.96043299, grad/param norm = 1.9065e-01, time/batch = 0.6778s	
16192/33150 (epoch 24.422), train_loss = 0.91007085, grad/param norm = 1.5339e-01, time/batch = 0.6739s	
16193/33150 (epoch 24.424), train_loss = 0.89662593, grad/param norm = 1.5028e-01, time/batch = 0.6731s	
16194/33150 (epoch 24.425), train_loss = 1.01825056, grad/param norm = 1.6045e-01, time/batch = 0.6732s	
16195/33150 (epoch 24.427), train_loss = 0.94540337, grad/param norm = 1.3991e-01, time/batch = 0.6778s	
16196/33150 (epoch 24.428), train_loss = 0.96083147, grad/param norm = 1.6471e-01, time/batch = 0.6750s	
16197/33150 (epoch 24.430), train_loss = 0.96760584, grad/param norm = 1.5663e-01, time/batch = 0.6729s	
16198/33150 (epoch 24.431), train_loss = 1.03302551, grad/param norm = 1.6857e-01, time/batch = 0.6748s	
16199/33150 (epoch 24.433), train_loss = 0.95083728, grad/param norm = 1.5097e-01, time/batch = 0.6730s	
16200/33150 (epoch 24.434), train_loss = 0.84522654, grad/param norm = 1.4494e-01, time/batch = 0.6736s	
16201/33150 (epoch 24.436), train_loss = 0.92298713, grad/param norm = 1.4167e-01, time/batch = 0.6867s	
16202/33150 (epoch 24.437), train_loss = 0.98310727, grad/param norm = 1.9823e-01, time/batch = 0.6955s	
16203/33150 (epoch 24.439), train_loss = 1.10146950, grad/param norm = 1.5964e-01, time/batch = 0.6789s	
16204/33150 (epoch 24.440), train_loss = 1.03878600, grad/param norm = 1.6550e-01, time/batch = 0.6991s	
16205/33150 (epoch 24.442), train_loss = 0.83329705, grad/param norm = 1.3630e-01, time/batch = 0.6865s	
16206/33150 (epoch 24.443), train_loss = 1.01479083, grad/param norm = 1.5233e-01, time/batch = 0.6809s	
16207/33150 (epoch 24.445), train_loss = 0.97926043, grad/param norm = 1.6052e-01, time/batch = 0.6711s	
16208/33150 (epoch 24.446), train_loss = 0.97587604, grad/param norm = 1.7378e-01, time/batch = 0.7859s	
16209/33150 (epoch 24.448), train_loss = 1.05712931, grad/param norm = 1.6280e-01, time/batch = 1.0092s	
16210/33150 (epoch 24.449), train_loss = 0.98908107, grad/param norm = 1.4534e-01, time/batch = 0.9783s	
16211/33150 (epoch 24.451), train_loss = 0.97037866, grad/param norm = 1.8535e-01, time/batch = 0.9856s	
16212/33150 (epoch 24.452), train_loss = 1.17933004, grad/param norm = 1.6575e-01, time/batch = 0.9747s	
16213/33150 (epoch 24.454), train_loss = 0.98714707, grad/param norm = 1.6207e-01, time/batch = 0.8762s	
16214/33150 (epoch 24.456), train_loss = 0.86008975, grad/param norm = 1.5072e-01, time/batch = 0.6666s	
16215/33150 (epoch 24.457), train_loss = 0.97937134, grad/param norm = 1.7482e-01, time/batch = 0.6857s	
16216/33150 (epoch 24.459), train_loss = 1.08513681, grad/param norm = 2.1580e-01, time/batch = 0.6862s	
16217/33150 (epoch 24.460), train_loss = 1.01311412, grad/param norm = 1.4381e-01, time/batch = 0.6815s	
16218/33150 (epoch 24.462), train_loss = 1.05576964, grad/param norm = 2.0368e-01, time/batch = 0.6758s	
16219/33150 (epoch 24.463), train_loss = 1.20493024, grad/param norm = 2.0150e-01, time/batch = 0.6685s	
16220/33150 (epoch 24.465), train_loss = 0.97694019, grad/param norm = 1.5073e-01, time/batch = 0.6640s	
16221/33150 (epoch 24.466), train_loss = 0.91716580, grad/param norm = 1.5269e-01, time/batch = 0.6828s	
16222/33150 (epoch 24.468), train_loss = 1.18980553, grad/param norm = 1.6585e-01, time/batch = 0.6755s	
16223/33150 (epoch 24.469), train_loss = 0.96193562, grad/param norm = 1.5394e-01, time/batch = 0.6802s	
16224/33150 (epoch 24.471), train_loss = 0.90134097, grad/param norm = 1.4878e-01, time/batch = 0.7044s	
16225/33150 (epoch 24.472), train_loss = 0.99424738, grad/param norm = 1.4846e-01, time/batch = 0.6969s	
16226/33150 (epoch 24.474), train_loss = 1.07919583, grad/param norm = 2.0126e-01, time/batch = 0.6906s	
16227/33150 (epoch 24.475), train_loss = 1.20514675, grad/param norm = 1.6763e-01, time/batch = 0.6843s	
16228/33150 (epoch 24.477), train_loss = 1.09393750, grad/param norm = 1.7928e-01, time/batch = 0.6733s	
16229/33150 (epoch 24.478), train_loss = 1.05614896, grad/param norm = 1.5957e-01, time/batch = 0.6898s	
16230/33150 (epoch 24.480), train_loss = 0.90898958, grad/param norm = 1.5994e-01, time/batch = 0.6879s	
16231/33150 (epoch 24.481), train_loss = 0.82467302, grad/param norm = 1.5712e-01, time/batch = 0.6916s	
16232/33150 (epoch 24.483), train_loss = 0.91675734, grad/param norm = 1.6810e-01, time/batch = 0.6918s	
16233/33150 (epoch 24.484), train_loss = 0.91262349, grad/param norm = 1.5818e-01, time/batch = 0.6906s	
16234/33150 (epoch 24.486), train_loss = 0.89575779, grad/param norm = 1.5238e-01, time/batch = 0.6897s	
16235/33150 (epoch 24.487), train_loss = 0.99071099, grad/param norm = 1.6779e-01, time/batch = 0.6898s	
16236/33150 (epoch 24.489), train_loss = 0.95925699, grad/param norm = 1.6457e-01, time/batch = 0.6874s	
16237/33150 (epoch 24.490), train_loss = 0.81545252, grad/param norm = 1.4261e-01, time/batch = 0.6850s	
16238/33150 (epoch 24.492), train_loss = 0.91648778, grad/param norm = 1.6272e-01, time/batch = 0.6792s	
16239/33150 (epoch 24.493), train_loss = 1.05735383, grad/param norm = 1.6777e-01, time/batch = 0.6688s	
16240/33150 (epoch 24.495), train_loss = 1.05203013, grad/param norm = 1.5219e-01, time/batch = 0.6730s	
16241/33150 (epoch 24.496), train_loss = 0.95720186, grad/param norm = 1.6767e-01, time/batch = 0.6809s	
16242/33150 (epoch 24.498), train_loss = 1.08684228, grad/param norm = 2.0450e-01, time/batch = 0.6823s	
16243/33150 (epoch 24.499), train_loss = 1.07239492, grad/param norm = 1.6862e-01, time/batch = 0.6676s	
16244/33150 (epoch 24.501), train_loss = 1.02217977, grad/param norm = 1.7257e-01, time/batch = 0.6675s	
16245/33150 (epoch 24.502), train_loss = 1.10217608, grad/param norm = 2.2405e-01, time/batch = 0.6714s	
16246/33150 (epoch 24.504), train_loss = 1.04524297, grad/param norm = 1.6960e-01, time/batch = 0.6789s	
16247/33150 (epoch 24.505), train_loss = 1.14082288, grad/param norm = 1.8280e-01, time/batch = 0.6737s	
16248/33150 (epoch 24.507), train_loss = 0.94445152, grad/param norm = 1.6411e-01, time/batch = 0.6828s	
16249/33150 (epoch 24.508), train_loss = 0.92123345, grad/param norm = 1.6332e-01, time/batch = 0.6911s	
16250/33150 (epoch 24.510), train_loss = 1.02883973, grad/param norm = 1.4735e-01, time/batch = 0.6861s	
16251/33150 (epoch 24.511), train_loss = 1.09383992, grad/param norm = 1.6386e-01, time/batch = 0.6848s	
16252/33150 (epoch 24.513), train_loss = 1.00504976, grad/param norm = 1.6201e-01, time/batch = 0.6790s	
16253/33150 (epoch 24.514), train_loss = 0.80740736, grad/param norm = 1.5419e-01, time/batch = 0.6782s	
16254/33150 (epoch 24.516), train_loss = 0.99533381, grad/param norm = 1.7287e-01, time/batch = 0.6716s	
16255/33150 (epoch 24.517), train_loss = 1.07726260, grad/param norm = 1.6727e-01, time/batch = 0.6700s	
16256/33150 (epoch 24.519), train_loss = 0.89713608, grad/param norm = 1.5991e-01, time/batch = 0.6786s	
16257/33150 (epoch 24.520), train_loss = 0.98324050, grad/param norm = 1.5347e-01, time/batch = 0.6785s	
16258/33150 (epoch 24.522), train_loss = 1.08851411, grad/param norm = 1.7751e-01, time/batch = 0.6686s	
16259/33150 (epoch 24.523), train_loss = 0.87563857, grad/param norm = 1.4859e-01, time/batch = 0.6682s	
16260/33150 (epoch 24.525), train_loss = 1.03829772, grad/param norm = 1.6933e-01, time/batch = 0.6775s	
16261/33150 (epoch 24.526), train_loss = 0.90340691, grad/param norm = 1.6980e-01, time/batch = 0.6732s	
16262/33150 (epoch 24.528), train_loss = 1.03192341, grad/param norm = 1.6769e-01, time/batch = 0.6742s	
16263/33150 (epoch 24.529), train_loss = 0.97786652, grad/param norm = 1.8251e-01, time/batch = 0.6800s	
16264/33150 (epoch 24.531), train_loss = 0.81853534, grad/param norm = 1.6701e-01, time/batch = 0.6727s	
16265/33150 (epoch 24.532), train_loss = 0.99900635, grad/param norm = 1.6744e-01, time/batch = 0.6690s	
16266/33150 (epoch 24.534), train_loss = 0.94485767, grad/param norm = 1.3313e-01, time/batch = 0.6770s	
16267/33150 (epoch 24.535), train_loss = 0.89350402, grad/param norm = 1.8719e-01, time/batch = 0.6745s	
16268/33150 (epoch 24.537), train_loss = 1.02036425, grad/param norm = 1.6716e-01, time/batch = 0.6776s	
16269/33150 (epoch 24.538), train_loss = 0.92367557, grad/param norm = 1.6620e-01, time/batch = 0.6782s	
16270/33150 (epoch 24.540), train_loss = 0.84718725, grad/param norm = 1.4739e-01, time/batch = 0.6872s	
16271/33150 (epoch 24.541), train_loss = 1.05035951, grad/param norm = 1.7099e-01, time/batch = 0.6827s	
16272/33150 (epoch 24.543), train_loss = 0.97245539, grad/param norm = 1.5522e-01, time/batch = 0.6823s	
16273/33150 (epoch 24.544), train_loss = 1.04094784, grad/param norm = 1.6241e-01, time/batch = 0.6792s	
16274/33150 (epoch 24.546), train_loss = 1.02383318, grad/param norm = 1.8117e-01, time/batch = 0.6839s	
16275/33150 (epoch 24.548), train_loss = 0.95331299, grad/param norm = 1.7896e-01, time/batch = 0.6856s	
16276/33150 (epoch 24.549), train_loss = 0.92970251, grad/param norm = 1.7299e-01, time/batch = 0.6746s	
16277/33150 (epoch 24.551), train_loss = 0.88224848, grad/param norm = 1.3809e-01, time/batch = 0.6820s	
16278/33150 (epoch 24.552), train_loss = 0.77380901, grad/param norm = 1.3946e-01, time/batch = 0.6825s	
16279/33150 (epoch 24.554), train_loss = 1.04594895, grad/param norm = 1.5992e-01, time/batch = 0.6716s	
16280/33150 (epoch 24.555), train_loss = 1.07749161, grad/param norm = 2.0968e-01, time/batch = 0.6693s	
16281/33150 (epoch 24.557), train_loss = 0.78208515, grad/param norm = 1.5074e-01, time/batch = 0.6765s	
16282/33150 (epoch 24.558), train_loss = 1.03559903, grad/param norm = 1.8375e-01, time/batch = 0.6732s	
16283/33150 (epoch 24.560), train_loss = 0.92959460, grad/param norm = 1.6146e-01, time/batch = 0.6724s	
16284/33150 (epoch 24.561), train_loss = 0.82816583, grad/param norm = 1.5176e-01, time/batch = 0.6799s	
16285/33150 (epoch 24.563), train_loss = 1.04310893, grad/param norm = 2.7907e-01, time/batch = 0.6763s	
16286/33150 (epoch 24.564), train_loss = 1.12003421, grad/param norm = 1.6103e-01, time/batch = 0.6837s	
16287/33150 (epoch 24.566), train_loss = 0.91678610, grad/param norm = 1.5740e-01, time/batch = 0.6893s	
16288/33150 (epoch 24.567), train_loss = 0.88499598, grad/param norm = 1.4767e-01, time/batch = 0.6886s	
16289/33150 (epoch 24.569), train_loss = 1.01995090, grad/param norm = 1.6025e-01, time/batch = 0.6851s	
16290/33150 (epoch 24.570), train_loss = 1.04085537, grad/param norm = 1.6154e-01, time/batch = 0.6678s	
16291/33150 (epoch 24.572), train_loss = 0.87554308, grad/param norm = 1.8936e-01, time/batch = 0.6760s	
16292/33150 (epoch 24.573), train_loss = 0.79343759, grad/param norm = 1.3154e-01, time/batch = 0.6785s	
16293/33150 (epoch 24.575), train_loss = 0.95896085, grad/param norm = 1.5834e-01, time/batch = 0.6687s	
16294/33150 (epoch 24.576), train_loss = 0.85246520, grad/param norm = 1.3875e-01, time/batch = 0.6747s	
16295/33150 (epoch 24.578), train_loss = 0.90560063, grad/param norm = 1.5219e-01, time/batch = 0.6766s	
16296/33150 (epoch 24.579), train_loss = 0.82548079, grad/param norm = 1.4738e-01, time/batch = 0.6836s	
16297/33150 (epoch 24.581), train_loss = 0.88143615, grad/param norm = 1.5251e-01, time/batch = 0.6881s	
16298/33150 (epoch 24.582), train_loss = 1.09666415, grad/param norm = 1.4741e-01, time/batch = 0.6917s	
16299/33150 (epoch 24.584), train_loss = 1.04953068, grad/param norm = 1.7932e-01, time/batch = 0.6872s	
16300/33150 (epoch 24.585), train_loss = 0.96389592, grad/param norm = 1.4994e-01, time/batch = 0.6839s	
16301/33150 (epoch 24.587), train_loss = 0.97162446, grad/param norm = 1.5031e-01, time/batch = 0.6855s	
16302/33150 (epoch 24.588), train_loss = 0.88677097, grad/param norm = 1.5685e-01, time/batch = 0.6851s	
16303/33150 (epoch 24.590), train_loss = 0.99597166, grad/param norm = 1.7090e-01, time/batch = 0.6920s	
16304/33150 (epoch 24.591), train_loss = 0.93626432, grad/param norm = 1.6372e-01, time/batch = 0.6897s	
16305/33150 (epoch 24.593), train_loss = 1.01409267, grad/param norm = 1.7268e-01, time/batch = 0.6900s	
16306/33150 (epoch 24.594), train_loss = 0.96887153, grad/param norm = 1.7344e-01, time/batch = 0.6885s	
16307/33150 (epoch 24.596), train_loss = 0.94245466, grad/param norm = 1.6408e-01, time/batch = 0.6876s	
16308/33150 (epoch 24.597), train_loss = 0.84749985, grad/param norm = 1.8264e-01, time/batch = 0.6808s	
16309/33150 (epoch 24.599), train_loss = 1.12900112, grad/param norm = 2.0247e-01, time/batch = 0.6866s	
16310/33150 (epoch 24.600), train_loss = 0.97017625, grad/param norm = 2.4718e-01, time/batch = 0.6813s	
16311/33150 (epoch 24.602), train_loss = 0.94769992, grad/param norm = 1.6000e-01, time/batch = 0.6837s	
16312/33150 (epoch 24.603), train_loss = 1.04713345, grad/param norm = 1.5322e-01, time/batch = 0.6900s	
16313/33150 (epoch 24.605), train_loss = 0.87193716, grad/param norm = 1.5322e-01, time/batch = 0.6853s	
16314/33150 (epoch 24.606), train_loss = 0.93042289, grad/param norm = 1.9819e-01, time/batch = 0.6824s	
16315/33150 (epoch 24.608), train_loss = 1.03373090, grad/param norm = 1.4461e-01, time/batch = 0.6898s	
16316/33150 (epoch 24.609), train_loss = 0.95198569, grad/param norm = 1.7915e-01, time/batch = 0.6757s	
16317/33150 (epoch 24.611), train_loss = 0.87105244, grad/param norm = 1.5490e-01, time/batch = 0.6849s	
16318/33150 (epoch 24.612), train_loss = 0.96702915, grad/param norm = 1.5926e-01, time/batch = 0.6827s	
16319/33150 (epoch 24.614), train_loss = 0.88079069, grad/param norm = 1.3967e-01, time/batch = 0.6915s	
16320/33150 (epoch 24.615), train_loss = 0.84326991, grad/param norm = 1.3689e-01, time/batch = 0.6934s	
16321/33150 (epoch 24.617), train_loss = 0.99602900, grad/param norm = 1.8531e-01, time/batch = 0.6899s	
16322/33150 (epoch 24.618), train_loss = 1.00856224, grad/param norm = 1.6681e-01, time/batch = 0.6901s	
16323/33150 (epoch 24.620), train_loss = 0.89127030, grad/param norm = 1.7178e-01, time/batch = 0.6859s	
16324/33150 (epoch 24.621), train_loss = 0.94287988, grad/param norm = 1.5088e-01, time/batch = 0.6875s	
16325/33150 (epoch 24.623), train_loss = 1.03830325, grad/param norm = 1.7442e-01, time/batch = 0.6771s	
16326/33150 (epoch 24.624), train_loss = 0.91063961, grad/param norm = 1.4969e-01, time/batch = 0.6943s	
16327/33150 (epoch 24.626), train_loss = 0.93174634, grad/param norm = 1.5886e-01, time/batch = 0.6815s	
16328/33150 (epoch 24.627), train_loss = 0.86227775, grad/param norm = 1.5639e-01, time/batch = 0.6808s	
16329/33150 (epoch 24.629), train_loss = 0.81510748, grad/param norm = 1.4417e-01, time/batch = 0.6710s	
16330/33150 (epoch 24.630), train_loss = 0.91560485, grad/param norm = 1.4856e-01, time/batch = 0.6767s	
16331/33150 (epoch 24.632), train_loss = 0.83540212, grad/param norm = 1.3537e-01, time/batch = 0.6827s	
16332/33150 (epoch 24.633), train_loss = 0.84203065, grad/param norm = 1.8425e-01, time/batch = 0.6805s	
16333/33150 (epoch 24.635), train_loss = 1.11455146, grad/param norm = 1.6861e-01, time/batch = 0.6803s	
16334/33150 (epoch 24.637), train_loss = 0.81610617, grad/param norm = 1.5128e-01, time/batch = 0.6802s	
16335/33150 (epoch 24.638), train_loss = 0.91621963, grad/param norm = 1.4983e-01, time/batch = 0.6820s	
16336/33150 (epoch 24.640), train_loss = 1.01901663, grad/param norm = 1.6103e-01, time/batch = 0.6716s	
16337/33150 (epoch 24.641), train_loss = 0.84297265, grad/param norm = 1.5412e-01, time/batch = 0.6782s	
16338/33150 (epoch 24.643), train_loss = 0.93461475, grad/param norm = 1.5353e-01, time/batch = 0.6772s	
16339/33150 (epoch 24.644), train_loss = 1.12177524, grad/param norm = 1.7663e-01, time/batch = 0.6829s	
16340/33150 (epoch 24.646), train_loss = 0.93468023, grad/param norm = 1.7009e-01, time/batch = 0.6864s	
16341/33150 (epoch 24.647), train_loss = 1.17352385, grad/param norm = 1.8819e-01, time/batch = 0.6836s	
16342/33150 (epoch 24.649), train_loss = 1.03906955, grad/param norm = 1.7693e-01, time/batch = 0.6809s	
16343/33150 (epoch 24.650), train_loss = 0.84323832, grad/param norm = 1.4188e-01, time/batch = 0.6700s	
16344/33150 (epoch 24.652), train_loss = 1.06688322, grad/param norm = 1.6661e-01, time/batch = 0.6769s	
16345/33150 (epoch 24.653), train_loss = 1.00567189, grad/param norm = 1.5540e-01, time/batch = 0.6742s	
16346/33150 (epoch 24.655), train_loss = 0.99877202, grad/param norm = 1.6888e-01, time/batch = 0.6754s	
16347/33150 (epoch 24.656), train_loss = 0.91378691, grad/param norm = 1.5128e-01, time/batch = 0.6760s	
16348/33150 (epoch 24.658), train_loss = 0.94212278, grad/param norm = 1.8602e-01, time/batch = 0.6757s	
16349/33150 (epoch 24.659), train_loss = 1.23405900, grad/param norm = 4.0038e-01, time/batch = 0.6786s	
16350/33150 (epoch 24.661), train_loss = 0.96861124, grad/param norm = 1.7552e-01, time/batch = 0.6744s	
16351/33150 (epoch 24.662), train_loss = 0.89808792, grad/param norm = 1.7507e-01, time/batch = 0.6667s	
16352/33150 (epoch 24.664), train_loss = 1.09397279, grad/param norm = 1.9671e-01, time/batch = 0.6779s	
16353/33150 (epoch 24.665), train_loss = 1.03757230, grad/param norm = 1.7239e-01, time/batch = 0.6717s	
16354/33150 (epoch 24.667), train_loss = 1.09601867, grad/param norm = 1.9588e-01, time/batch = 0.6841s	
16355/33150 (epoch 24.668), train_loss = 1.09416907, grad/param norm = 1.8201e-01, time/batch = 0.6840s	
16356/33150 (epoch 24.670), train_loss = 0.90709367, grad/param norm = 1.4772e-01, time/batch = 0.6630s	
16357/33150 (epoch 24.671), train_loss = 0.93205428, grad/param norm = 1.7674e-01, time/batch = 0.6617s	
16358/33150 (epoch 24.673), train_loss = 1.09580579, grad/param norm = 1.5394e-01, time/batch = 0.6689s	
16359/33150 (epoch 24.674), train_loss = 1.00839032, grad/param norm = 1.8484e-01, time/batch = 0.6806s	
16360/33150 (epoch 24.676), train_loss = 0.95164585, grad/param norm = 1.5987e-01, time/batch = 0.6708s	
16361/33150 (epoch 24.677), train_loss = 1.12733266, grad/param norm = 1.6531e-01, time/batch = 0.6747s	
16362/33150 (epoch 24.679), train_loss = 0.96586740, grad/param norm = 1.5138e-01, time/batch = 0.6674s	
16363/33150 (epoch 24.680), train_loss = 1.09048703, grad/param norm = 1.7677e-01, time/batch = 0.6672s	
16364/33150 (epoch 24.682), train_loss = 0.94373790, grad/param norm = 1.5716e-01, time/batch = 0.6675s	
16365/33150 (epoch 24.683), train_loss = 0.83919451, grad/param norm = 1.4708e-01, time/batch = 0.6670s	
16366/33150 (epoch 24.685), train_loss = 0.93880313, grad/param norm = 1.8261e-01, time/batch = 0.6702s	
16367/33150 (epoch 24.686), train_loss = 0.83121845, grad/param norm = 1.6137e-01, time/batch = 0.6648s	
16368/33150 (epoch 24.688), train_loss = 0.86590429, grad/param norm = 1.5572e-01, time/batch = 0.6741s	
16369/33150 (epoch 24.689), train_loss = 0.88264758, grad/param norm = 1.4762e-01, time/batch = 0.6666s	
16370/33150 (epoch 24.691), train_loss = 0.76601985, grad/param norm = 1.3861e-01, time/batch = 0.6661s	
16371/33150 (epoch 24.692), train_loss = 0.86306077, grad/param norm = 1.4543e-01, time/batch = 0.6682s	
16372/33150 (epoch 24.694), train_loss = 0.76714940, grad/param norm = 1.4419e-01, time/batch = 0.6665s	
16373/33150 (epoch 24.695), train_loss = 0.89618341, grad/param norm = 1.4132e-01, time/batch = 0.6754s	
16374/33150 (epoch 24.697), train_loss = 0.82170861, grad/param norm = 1.3389e-01, time/batch = 0.6686s	
16375/33150 (epoch 24.698), train_loss = 0.88141891, grad/param norm = 1.7131e-01, time/batch = 0.6876s	
16376/33150 (epoch 24.700), train_loss = 0.72853680, grad/param norm = 1.3009e-01, time/batch = 0.6868s	
16377/33150 (epoch 24.701), train_loss = 0.83843735, grad/param norm = 1.3858e-01, time/batch = 0.6901s	
16378/33150 (epoch 24.703), train_loss = 0.92857210, grad/param norm = 1.4639e-01, time/batch = 0.6868s	
16379/33150 (epoch 24.704), train_loss = 0.82282982, grad/param norm = 1.4642e-01, time/batch = 0.6744s	
16380/33150 (epoch 24.706), train_loss = 0.90822639, grad/param norm = 1.5234e-01, time/batch = 0.6892s	
16381/33150 (epoch 24.707), train_loss = 0.89469561, grad/param norm = 1.5925e-01, time/batch = 0.6776s	
16382/33150 (epoch 24.709), train_loss = 0.93744603, grad/param norm = 1.3629e-01, time/batch = 0.6999s	
16383/33150 (epoch 24.710), train_loss = 0.93727584, grad/param norm = 1.6493e-01, time/batch = 0.6775s	
16384/33150 (epoch 24.712), train_loss = 0.99804727, grad/param norm = 1.5472e-01, time/batch = 0.6686s	
16385/33150 (epoch 24.713), train_loss = 0.98499968, grad/param norm = 1.4636e-01, time/batch = 0.6766s	
16386/33150 (epoch 24.715), train_loss = 0.90622405, grad/param norm = 1.4770e-01, time/batch = 0.6726s	
16387/33150 (epoch 24.716), train_loss = 0.98987728, grad/param norm = 1.6806e-01, time/batch = 0.6711s	
16388/33150 (epoch 24.718), train_loss = 0.97209142, grad/param norm = 1.4886e-01, time/batch = 0.6787s	
16389/33150 (epoch 24.719), train_loss = 1.04087849, grad/param norm = 1.7493e-01, time/batch = 0.6780s	
16390/33150 (epoch 24.721), train_loss = 0.92809504, grad/param norm = 1.8643e-01, time/batch = 0.6789s	
16391/33150 (epoch 24.722), train_loss = 0.96481708, grad/param norm = 1.5398e-01, time/batch = 0.6699s	
16392/33150 (epoch 24.724), train_loss = 0.91878048, grad/param norm = 1.5991e-01, time/batch = 0.6868s	
16393/33150 (epoch 24.725), train_loss = 1.06584504, grad/param norm = 1.9953e-01, time/batch = 0.6785s	
16394/33150 (epoch 24.727), train_loss = 1.00700601, grad/param norm = 1.9311e-01, time/batch = 0.6821s	
16395/33150 (epoch 24.729), train_loss = 0.94698281, grad/param norm = 1.5949e-01, time/batch = 0.6686s	
16396/33150 (epoch 24.730), train_loss = 0.98019844, grad/param norm = 1.6770e-01, time/batch = 0.6690s	
16397/33150 (epoch 24.732), train_loss = 1.03742572, grad/param norm = 1.6856e-01, time/batch = 0.6733s	
16398/33150 (epoch 24.733), train_loss = 0.78908435, grad/param norm = 1.2438e-01, time/batch = 0.6706s	
16399/33150 (epoch 24.735), train_loss = 0.85496504, grad/param norm = 1.4482e-01, time/batch = 0.6692s	
16400/33150 (epoch 24.736), train_loss = 0.92774424, grad/param norm = 1.5982e-01, time/batch = 0.6692s	
16401/33150 (epoch 24.738), train_loss = 0.97209911, grad/param norm = 1.7431e-01, time/batch = 0.6761s	
16402/33150 (epoch 24.739), train_loss = 1.04960676, grad/param norm = 1.6770e-01, time/batch = 0.6728s	
16403/33150 (epoch 24.741), train_loss = 1.04775884, grad/param norm = 1.7194e-01, time/batch = 0.6706s	
16404/33150 (epoch 24.742), train_loss = 0.81832051, grad/param norm = 1.6263e-01, time/batch = 0.6806s	
16405/33150 (epoch 24.744), train_loss = 1.03550594, grad/param norm = 1.7202e-01, time/batch = 0.6779s	
16406/33150 (epoch 24.745), train_loss = 0.91351836, grad/param norm = 1.4652e-01, time/batch = 0.6665s	
16407/33150 (epoch 24.747), train_loss = 0.74652845, grad/param norm = 1.4260e-01, time/batch = 0.6691s	
16408/33150 (epoch 24.748), train_loss = 0.87190432, grad/param norm = 1.5377e-01, time/batch = 0.6685s	
16409/33150 (epoch 24.750), train_loss = 0.99052337, grad/param norm = 1.6970e-01, time/batch = 0.6683s	
16410/33150 (epoch 24.751), train_loss = 0.97030723, grad/param norm = 1.6911e-01, time/batch = 0.6730s	
16411/33150 (epoch 24.753), train_loss = 0.81157904, grad/param norm = 1.4846e-01, time/batch = 0.6720s	
16412/33150 (epoch 24.754), train_loss = 1.15880285, grad/param norm = 1.9281e-01, time/batch = 0.6691s	
16413/33150 (epoch 24.756), train_loss = 0.96842289, grad/param norm = 1.8031e-01, time/batch = 0.6718s	
16414/33150 (epoch 24.757), train_loss = 0.97901078, grad/param norm = 1.6943e-01, time/batch = 0.6719s	
16415/33150 (epoch 24.759), train_loss = 1.08269314, grad/param norm = 2.1678e-01, time/batch = 0.6666s	
16416/33150 (epoch 24.760), train_loss = 0.99443754, grad/param norm = 1.5145e-01, time/batch = 0.6748s	
16417/33150 (epoch 24.762), train_loss = 0.98031384, grad/param norm = 1.7584e-01, time/batch = 0.6698s	
16418/33150 (epoch 24.763), train_loss = 1.00962138, grad/param norm = 1.6269e-01, time/batch = 0.6809s	
16419/33150 (epoch 24.765), train_loss = 0.94763635, grad/param norm = 1.5529e-01, time/batch = 0.6733s	
16420/33150 (epoch 24.766), train_loss = 0.86694093, grad/param norm = 1.7058e-01, time/batch = 0.6666s	
16421/33150 (epoch 24.768), train_loss = 0.89401110, grad/param norm = 1.4872e-01, time/batch = 0.6676s	
16422/33150 (epoch 24.769), train_loss = 0.98631793, grad/param norm = 1.6863e-01, time/batch = 0.6675s	
16423/33150 (epoch 24.771), train_loss = 0.97970436, grad/param norm = 1.6785e-01, time/batch = 0.6652s	
16424/33150 (epoch 24.772), train_loss = 1.04240992, grad/param norm = 1.8094e-01, time/batch = 0.6676s	
16425/33150 (epoch 24.774), train_loss = 1.12721343, grad/param norm = 1.6406e-01, time/batch = 0.6680s	
16426/33150 (epoch 24.775), train_loss = 1.03076956, grad/param norm = 2.1923e-01, time/batch = 0.6666s	
16427/33150 (epoch 24.777), train_loss = 1.02321454, grad/param norm = 1.6188e-01, time/batch = 0.6748s	
16428/33150 (epoch 24.778), train_loss = 0.97431578, grad/param norm = 1.4849e-01, time/batch = 0.6707s	
16429/33150 (epoch 24.780), train_loss = 0.82691415, grad/param norm = 1.4242e-01, time/batch = 0.6686s	
16430/33150 (epoch 24.781), train_loss = 0.94711438, grad/param norm = 1.4236e-01, time/batch = 0.6723s	
16431/33150 (epoch 24.783), train_loss = 0.94997759, grad/param norm = 1.5590e-01, time/batch = 0.6702s	
16432/33150 (epoch 24.784), train_loss = 0.94330890, grad/param norm = 1.6084e-01, time/batch = 0.6814s	
16433/33150 (epoch 24.786), train_loss = 0.93711518, grad/param norm = 1.4489e-01, time/batch = 0.6725s	
16434/33150 (epoch 24.787), train_loss = 0.88101905, grad/param norm = 1.3251e-01, time/batch = 0.6672s	
16435/33150 (epoch 24.789), train_loss = 0.79207278, grad/param norm = 1.4415e-01, time/batch = 0.6716s	
16436/33150 (epoch 24.790), train_loss = 0.85279792, grad/param norm = 1.3997e-01, time/batch = 0.6672s	
16437/33150 (epoch 24.792), train_loss = 0.98083466, grad/param norm = 1.7437e-01, time/batch = 0.6789s	
16438/33150 (epoch 24.793), train_loss = 0.92718058, grad/param norm = 1.7924e-01, time/batch = 0.6812s	
16439/33150 (epoch 24.795), train_loss = 0.92253230, grad/param norm = 1.7876e-01, time/batch = 0.6769s	
16440/33150 (epoch 24.796), train_loss = 0.89718721, grad/param norm = 1.3773e-01, time/batch = 0.6695s	
16441/33150 (epoch 24.798), train_loss = 0.89770477, grad/param norm = 1.3566e-01, time/batch = 0.6715s	
16442/33150 (epoch 24.799), train_loss = 0.78925238, grad/param norm = 1.7004e-01, time/batch = 0.6728s	
16443/33150 (epoch 24.801), train_loss = 0.96640396, grad/param norm = 1.5077e-01, time/batch = 0.6838s	
16444/33150 (epoch 24.802), train_loss = 0.86899914, grad/param norm = 1.5008e-01, time/batch = 0.6752s	
16445/33150 (epoch 24.804), train_loss = 0.92392689, grad/param norm = 1.6245e-01, time/batch = 0.6731s	
16446/33150 (epoch 24.805), train_loss = 0.88413508, grad/param norm = 1.7260e-01, time/batch = 0.6789s	
16447/33150 (epoch 24.807), train_loss = 0.90492419, grad/param norm = 1.3697e-01, time/batch = 0.6632s	
16448/33150 (epoch 24.808), train_loss = 1.04319931, grad/param norm = 1.6100e-01, time/batch = 0.6656s	
16449/33150 (epoch 24.810), train_loss = 0.89033256, grad/param norm = 1.7096e-01, time/batch = 0.6660s	
16450/33150 (epoch 24.811), train_loss = 0.98523368, grad/param norm = 1.7373e-01, time/batch = 0.6675s	
16451/33150 (epoch 24.813), train_loss = 0.91220458, grad/param norm = 1.3788e-01, time/batch = 0.6706s	
16452/33150 (epoch 24.814), train_loss = 0.90513454, grad/param norm = 1.6536e-01, time/batch = 0.6814s	
16453/33150 (epoch 24.816), train_loss = 0.92868434, grad/param norm = 1.6998e-01, time/batch = 0.6837s	
16454/33150 (epoch 24.817), train_loss = 1.01328044, grad/param norm = 1.6343e-01, time/batch = 0.6649s	
16455/33150 (epoch 24.819), train_loss = 0.95181486, grad/param norm = 1.5218e-01, time/batch = 0.6673s	
16456/33150 (epoch 24.821), train_loss = 0.84056060, grad/param norm = 1.4546e-01, time/batch = 0.6865s	
16457/33150 (epoch 24.822), train_loss = 0.87780501, grad/param norm = 1.3907e-01, time/batch = 0.6705s	
16458/33150 (epoch 24.824), train_loss = 0.94355685, grad/param norm = 1.7165e-01, time/batch = 0.6660s	
16459/33150 (epoch 24.825), train_loss = 0.97939852, grad/param norm = 1.7375e-01, time/batch = 0.6662s	
16460/33150 (epoch 24.827), train_loss = 1.01286778, grad/param norm = 1.7403e-01, time/batch = 0.6623s	
16461/33150 (epoch 24.828), train_loss = 0.85332748, grad/param norm = 1.5759e-01, time/batch = 0.6686s	
16462/33150 (epoch 24.830), train_loss = 1.03572610, grad/param norm = 1.7827e-01, time/batch = 0.6671s	
16463/33150 (epoch 24.831), train_loss = 0.88431264, grad/param norm = 1.5189e-01, time/batch = 0.6815s	
16464/33150 (epoch 24.833), train_loss = 0.86734591, grad/param norm = 1.5428e-01, time/batch = 0.6881s	
16465/33150 (epoch 24.834), train_loss = 1.05406775, grad/param norm = 1.6844e-01, time/batch = 0.6730s	
16466/33150 (epoch 24.836), train_loss = 1.06133940, grad/param norm = 1.4556e-01, time/batch = 0.6848s	
16467/33150 (epoch 24.837), train_loss = 0.91662948, grad/param norm = 1.5152e-01, time/batch = 0.6813s	
16468/33150 (epoch 24.839), train_loss = 1.00991775, grad/param norm = 1.9683e-01, time/batch = 0.6749s	
16469/33150 (epoch 24.840), train_loss = 1.02395608, grad/param norm = 1.5907e-01, time/batch = 0.6644s	
16470/33150 (epoch 24.842), train_loss = 1.08854305, grad/param norm = 1.8415e-01, time/batch = 0.6647s	
16471/33150 (epoch 24.843), train_loss = 1.04141206, grad/param norm = 1.7037e-01, time/batch = 0.6831s	
16472/33150 (epoch 24.845), train_loss = 0.88501316, grad/param norm = 1.4882e-01, time/batch = 0.6814s	
16473/33150 (epoch 24.846), train_loss = 1.13044824, grad/param norm = 2.1779e-01, time/batch = 0.6764s	
16474/33150 (epoch 24.848), train_loss = 1.04737308, grad/param norm = 1.6682e-01, time/batch = 0.6712s	
16475/33150 (epoch 24.849), train_loss = 1.07364351, grad/param norm = 1.7342e-01, time/batch = 0.6763s	
16476/33150 (epoch 24.851), train_loss = 1.05040115, grad/param norm = 1.9995e-01, time/batch = 0.6707s	
16477/33150 (epoch 24.852), train_loss = 1.11257540, grad/param norm = 1.5691e-01, time/batch = 0.6718s	
16478/33150 (epoch 24.854), train_loss = 0.98630222, grad/param norm = 1.6991e-01, time/batch = 0.6689s	
16479/33150 (epoch 24.855), train_loss = 0.82120768, grad/param norm = 1.4536e-01, time/batch = 0.6727s	
16480/33150 (epoch 24.857), train_loss = 0.81565369, grad/param norm = 1.4712e-01, time/batch = 0.6852s	
16481/33150 (epoch 24.858), train_loss = 0.89762230, grad/param norm = 1.4523e-01, time/batch = 0.6771s	
16482/33150 (epoch 24.860), train_loss = 0.83965808, grad/param norm = 1.3213e-01, time/batch = 0.6836s	
16483/33150 (epoch 24.861), train_loss = 0.84698738, grad/param norm = 1.3897e-01, time/batch = 0.6818s	
16484/33150 (epoch 24.863), train_loss = 0.96346170, grad/param norm = 1.5961e-01, time/batch = 0.6768s	
16485/33150 (epoch 24.864), train_loss = 1.02259627, grad/param norm = 1.5278e-01, time/batch = 0.6732s	
16486/33150 (epoch 24.866), train_loss = 1.01153430, grad/param norm = 1.5273e-01, time/batch = 0.6652s	
16487/33150 (epoch 24.867), train_loss = 0.99215232, grad/param norm = 1.4553e-01, time/batch = 0.6746s	
16488/33150 (epoch 24.869), train_loss = 0.99261062, grad/param norm = 1.6809e-01, time/batch = 0.6648s	
16489/33150 (epoch 24.870), train_loss = 0.91445864, grad/param norm = 1.5070e-01, time/batch = 0.6639s	
16490/33150 (epoch 24.872), train_loss = 0.98576981, grad/param norm = 1.6879e-01, time/batch = 0.6922s	
16491/33150 (epoch 24.873), train_loss = 0.81380928, grad/param norm = 1.3910e-01, time/batch = 0.6695s	
16492/33150 (epoch 24.875), train_loss = 1.08970296, grad/param norm = 1.9205e-01, time/batch = 0.6803s	
16493/33150 (epoch 24.876), train_loss = 0.83184517, grad/param norm = 1.5764e-01, time/batch = 0.6686s	
16494/33150 (epoch 24.878), train_loss = 0.87440629, grad/param norm = 1.3876e-01, time/batch = 0.6768s	
16495/33150 (epoch 24.879), train_loss = 0.88271072, grad/param norm = 1.5660e-01, time/batch = 0.6804s	
16496/33150 (epoch 24.881), train_loss = 0.86494756, grad/param norm = 1.5355e-01, time/batch = 0.6815s	
16497/33150 (epoch 24.882), train_loss = 0.76863183, grad/param norm = 1.3446e-01, time/batch = 0.6773s	
16498/33150 (epoch 24.884), train_loss = 0.91855824, grad/param norm = 1.4426e-01, time/batch = 0.6680s	
16499/33150 (epoch 24.885), train_loss = 0.73107772, grad/param norm = 1.3935e-01, time/batch = 0.6847s	
16500/33150 (epoch 24.887), train_loss = 1.06381055, grad/param norm = 1.7994e-01, time/batch = 0.6806s	
16501/33150 (epoch 24.888), train_loss = 0.99104205, grad/param norm = 1.7441e-01, time/batch = 0.6692s	
16502/33150 (epoch 24.890), train_loss = 0.87370780, grad/param norm = 1.7220e-01, time/batch = 0.6684s	
16503/33150 (epoch 24.891), train_loss = 0.84090299, grad/param norm = 1.3611e-01, time/batch = 0.6690s	
16504/33150 (epoch 24.893), train_loss = 1.00370066, grad/param norm = 1.6743e-01, time/batch = 0.6682s	
16505/33150 (epoch 24.894), train_loss = 1.00193677, grad/param norm = 1.7292e-01, time/batch = 0.6668s	
16506/33150 (epoch 24.896), train_loss = 0.93662457, grad/param norm = 1.7072e-01, time/batch = 0.6680s	
16507/33150 (epoch 24.897), train_loss = 0.99248338, grad/param norm = 1.5203e-01, time/batch = 0.6688s	
16508/33150 (epoch 24.899), train_loss = 0.80146496, grad/param norm = 1.6876e-01, time/batch = 0.6656s	
16509/33150 (epoch 24.900), train_loss = 1.15197784, grad/param norm = 1.8861e-01, time/batch = 0.6716s	
16510/33150 (epoch 24.902), train_loss = 1.14232776, grad/param norm = 1.6953e-01, time/batch = 0.6664s	
16511/33150 (epoch 24.903), train_loss = 0.96428351, grad/param norm = 1.7093e-01, time/batch = 0.6827s	
16512/33150 (epoch 24.905), train_loss = 0.97165844, grad/param norm = 1.4088e-01, time/batch = 0.6738s	
16513/33150 (epoch 24.906), train_loss = 0.97750929, grad/param norm = 1.6042e-01, time/batch = 0.6679s	
16514/33150 (epoch 24.908), train_loss = 1.07155734, grad/param norm = 1.5887e-01, time/batch = 0.6651s	
16515/33150 (epoch 24.910), train_loss = 1.03232714, grad/param norm = 1.6569e-01, time/batch = 0.6655s	
16516/33150 (epoch 24.911), train_loss = 0.83615597, grad/param norm = 1.5826e-01, time/batch = 0.6647s	
16517/33150 (epoch 24.913), train_loss = 0.86877000, grad/param norm = 1.5725e-01, time/batch = 0.6671s	
16518/33150 (epoch 24.914), train_loss = 1.04818821, grad/param norm = 2.2270e-01, time/batch = 0.6635s	
16519/33150 (epoch 24.916), train_loss = 0.88243384, grad/param norm = 1.6786e-01, time/batch = 0.6695s	
16520/33150 (epoch 24.917), train_loss = 0.99835032, grad/param norm = 1.9962e-01, time/batch = 0.6732s	
16521/33150 (epoch 24.919), train_loss = 1.09772630, grad/param norm = 1.9778e-01, time/batch = 0.6736s	
16522/33150 (epoch 24.920), train_loss = 1.07071092, grad/param norm = 1.6763e-01, time/batch = 0.6759s	
16523/33150 (epoch 24.922), train_loss = 1.09223293, grad/param norm = 1.7555e-01, time/batch = 0.6862s	
16524/33150 (epoch 24.923), train_loss = 0.97142175, grad/param norm = 1.7283e-01, time/batch = 0.6710s	
16525/33150 (epoch 24.925), train_loss = 1.05073291, grad/param norm = 1.6041e-01, time/batch = 0.6676s	
16526/33150 (epoch 24.926), train_loss = 0.92016601, grad/param norm = 1.4914e-01, time/batch = 0.6648s	
16527/33150 (epoch 24.928), train_loss = 0.91490198, grad/param norm = 1.5019e-01, time/batch = 0.6668s	
16528/33150 (epoch 24.929), train_loss = 1.00908543, grad/param norm = 1.6942e-01, time/batch = 0.6686s	
16529/33150 (epoch 24.931), train_loss = 1.08603509, grad/param norm = 2.0554e-01, time/batch = 0.6713s	
16530/33150 (epoch 24.932), train_loss = 0.96040898, grad/param norm = 1.7502e-01, time/batch = 0.6769s	
16531/33150 (epoch 24.934), train_loss = 0.99649872, grad/param norm = 1.5597e-01, time/batch = 0.6801s	
16532/33150 (epoch 24.935), train_loss = 1.05386259, grad/param norm = 1.6078e-01, time/batch = 0.6724s	
16533/33150 (epoch 24.937), train_loss = 1.08004210, grad/param norm = 1.6006e-01, time/batch = 0.6797s	
16534/33150 (epoch 24.938), train_loss = 1.00671333, grad/param norm = 1.6215e-01, time/batch = 0.6709s	
16535/33150 (epoch 24.940), train_loss = 1.21135399, grad/param norm = 1.8808e-01, time/batch = 0.6842s	
16536/33150 (epoch 24.941), train_loss = 0.97496351, grad/param norm = 1.4129e-01, time/batch = 0.6716s	
16537/33150 (epoch 24.943), train_loss = 0.83399594, grad/param norm = 1.6403e-01, time/batch = 0.6745s	
16538/33150 (epoch 24.944), train_loss = 1.04181332, grad/param norm = 1.6624e-01, time/batch = 0.6734s	
16539/33150 (epoch 24.946), train_loss = 0.83040033, grad/param norm = 1.4521e-01, time/batch = 0.6698s	
16540/33150 (epoch 24.947), train_loss = 0.99592880, grad/param norm = 1.4745e-01, time/batch = 0.6702s	
16541/33150 (epoch 24.949), train_loss = 1.07959858, grad/param norm = 1.6841e-01, time/batch = 0.6709s	
16542/33150 (epoch 24.950), train_loss = 1.01786596, grad/param norm = 1.7581e-01, time/batch = 0.6717s	
16543/33150 (epoch 24.952), train_loss = 0.87533436, grad/param norm = 1.6079e-01, time/batch = 0.6773s	
16544/33150 (epoch 24.953), train_loss = 0.91844340, grad/param norm = 1.5254e-01, time/batch = 0.7436s	
16545/33150 (epoch 24.955), train_loss = 0.84169628, grad/param norm = 1.6599e-01, time/batch = 1.0028s	
16546/33150 (epoch 24.956), train_loss = 1.03910751, grad/param norm = 1.7581e-01, time/batch = 1.0029s	
16547/33150 (epoch 24.958), train_loss = 0.86388439, grad/param norm = 1.4346e-01, time/batch = 0.9971s	
16548/33150 (epoch 24.959), train_loss = 0.90614870, grad/param norm = 1.5267e-01, time/batch = 0.9818s	
16549/33150 (epoch 24.961), train_loss = 0.87498597, grad/param norm = 1.6741e-01, time/batch = 1.1183s	
16550/33150 (epoch 24.962), train_loss = 0.82321676, grad/param norm = 1.4580e-01, time/batch = 1.8836s	
16551/33150 (epoch 24.964), train_loss = 0.95462481, grad/param norm = 1.4817e-01, time/batch = 1.9144s	
16552/33150 (epoch 24.965), train_loss = 0.94260693, grad/param norm = 1.8082e-01, time/batch = 10.8430s	
16553/33150 (epoch 24.967), train_loss = 0.94994639, grad/param norm = 1.9106e-01, time/batch = 17.7463s	
16554/33150 (epoch 24.968), train_loss = 0.80331970, grad/param norm = 1.4554e-01, time/batch = 18.5536s	
16555/33150 (epoch 24.970), train_loss = 0.90861662, grad/param norm = 1.6110e-01, time/batch = 16.1327s	
16556/33150 (epoch 24.971), train_loss = 0.95909606, grad/param norm = 1.5879e-01, time/batch = 16.8859s	
16557/33150 (epoch 24.973), train_loss = 1.06891540, grad/param norm = 1.7739e-01, time/batch = 15.5427s	
16558/33150 (epoch 24.974), train_loss = 1.09847992, grad/param norm = 1.7315e-01, time/batch = 17.0553s	
16559/33150 (epoch 24.976), train_loss = 1.03215346, grad/param norm = 1.5652e-01, time/batch = 15.2187s	
16560/33150 (epoch 24.977), train_loss = 1.09778613, grad/param norm = 1.6399e-01, time/batch = 18.3026s	
16561/33150 (epoch 24.979), train_loss = 1.05369451, grad/param norm = 1.9447e-01, time/batch = 15.8962s	
16562/33150 (epoch 24.980), train_loss = 1.10813673, grad/param norm = 1.6886e-01, time/batch = 16.8096s	
16563/33150 (epoch 24.982), train_loss = 0.95296825, grad/param norm = 1.6791e-01, time/batch = 16.3165s	
16564/33150 (epoch 24.983), train_loss = 0.85428379, grad/param norm = 1.5540e-01, time/batch = 16.9112s	
16565/33150 (epoch 24.985), train_loss = 1.05251267, grad/param norm = 1.4462e-01, time/batch = 15.6292s	
16566/33150 (epoch 24.986), train_loss = 0.81323265, grad/param norm = 1.5359e-01, time/batch = 16.1470s	
16567/33150 (epoch 24.988), train_loss = 0.91728895, grad/param norm = 1.8510e-01, time/batch = 15.6427s	
16568/33150 (epoch 24.989), train_loss = 0.89690487, grad/param norm = 1.5184e-01, time/batch = 17.9060s	
16569/33150 (epoch 24.991), train_loss = 1.04481812, grad/param norm = 2.3449e-01, time/batch = 16.4789s	
16570/33150 (epoch 24.992), train_loss = 0.89337116, grad/param norm = 1.4333e-01, time/batch = 16.8846s	
16571/33150 (epoch 24.994), train_loss = 0.96989755, grad/param norm = 1.5906e-01, time/batch = 17.1573s	
16572/33150 (epoch 24.995), train_loss = 0.92553171, grad/param norm = 1.5151e-01, time/batch = 19.6357s	
16573/33150 (epoch 24.997), train_loss = 0.96142924, grad/param norm = 1.9305e-01, time/batch = 16.2111s	
16574/33150 (epoch 24.998), train_loss = 0.78589508, grad/param norm = 1.3952e-01, time/batch = 18.6356s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
16575/33150 (epoch 25.000), train_loss = 0.78634757, grad/param norm = 1.6444e-01, time/batch = 19.2272s	
16576/33150 (epoch 25.002), train_loss = 1.24665135, grad/param norm = 1.8125e-01, time/batch = 17.3147s	
16577/33150 (epoch 25.003), train_loss = 0.85485185, grad/param norm = 1.4915e-01, time/batch = 17.9807s	
16578/33150 (epoch 25.005), train_loss = 0.83375663, grad/param norm = 1.4054e-01, time/batch = 17.9770s	
16579/33150 (epoch 25.006), train_loss = 0.82620241, grad/param norm = 1.5003e-01, time/batch = 18.2324s	
16580/33150 (epoch 25.008), train_loss = 1.05889699, grad/param norm = 1.8066e-01, time/batch = 16.2749s	
16581/33150 (epoch 25.009), train_loss = 0.98196766, grad/param norm = 1.6240e-01, time/batch = 16.0544s	
16582/33150 (epoch 25.011), train_loss = 1.05990170, grad/param norm = 1.5768e-01, time/batch = 19.3988s	
16583/33150 (epoch 25.012), train_loss = 0.96591513, grad/param norm = 3.6904e-01, time/batch = 16.5609s	
16584/33150 (epoch 25.014), train_loss = 0.90661093, grad/param norm = 1.8448e-01, time/batch = 19.0484s	
16585/33150 (epoch 25.015), train_loss = 0.87853284, grad/param norm = 1.5762e-01, time/batch = 18.8845s	
16586/33150 (epoch 25.017), train_loss = 0.85552369, grad/param norm = 1.4620e-01, time/batch = 17.8743s	
16587/33150 (epoch 25.018), train_loss = 0.99491117, grad/param norm = 1.8411e-01, time/batch = 17.2210s	
16588/33150 (epoch 25.020), train_loss = 1.05010262, grad/param norm = 1.8600e-01, time/batch = 18.3863s	
16589/33150 (epoch 25.021), train_loss = 0.84827413, grad/param norm = 1.5272e-01, time/batch = 18.6263s	
16590/33150 (epoch 25.023), train_loss = 1.10972265, grad/param norm = 1.4977e-01, time/batch = 31.7194s	
16591/33150 (epoch 25.024), train_loss = 1.02627776, grad/param norm = 1.8331e-01, time/batch = 17.7407s	
16592/33150 (epoch 25.026), train_loss = 0.76663346, grad/param norm = 1.3035e-01, time/batch = 17.2231s	
16593/33150 (epoch 25.027), train_loss = 0.77373610, grad/param norm = 1.3056e-01, time/batch = 19.9323s	
16594/33150 (epoch 25.029), train_loss = 0.89543130, grad/param norm = 1.6180e-01, time/batch = 16.4662s	
16595/33150 (epoch 25.030), train_loss = 0.92800434, grad/param norm = 1.5332e-01, time/batch = 18.3947s	
16596/33150 (epoch 25.032), train_loss = 0.87337211, grad/param norm = 1.7572e-01, time/batch = 16.1411s	
16597/33150 (epoch 25.033), train_loss = 0.89643881, grad/param norm = 1.5951e-01, time/batch = 18.0587s	
16598/33150 (epoch 25.035), train_loss = 1.13134341, grad/param norm = 1.9685e-01, time/batch = 19.8902s	
16599/33150 (epoch 25.036), train_loss = 1.01433514, grad/param norm = 1.8271e-01, time/batch = 16.0706s	
16600/33150 (epoch 25.038), train_loss = 1.19265284, grad/param norm = 1.8825e-01, time/batch = 18.1555s	
16601/33150 (epoch 25.039), train_loss = 1.00743245, grad/param norm = 1.4099e-01, time/batch = 17.9775s	
16602/33150 (epoch 25.041), train_loss = 0.96688909, grad/param norm = 1.5503e-01, time/batch = 18.2157s	
16603/33150 (epoch 25.042), train_loss = 0.90787896, grad/param norm = 1.5006e-01, time/batch = 17.2926s	
16604/33150 (epoch 25.044), train_loss = 0.91953729, grad/param norm = 1.3782e-01, time/batch = 18.8207s	
16605/33150 (epoch 25.045), train_loss = 1.00061348, grad/param norm = 1.4749e-01, time/batch = 17.4002s	
16606/33150 (epoch 25.047), train_loss = 0.84458039, grad/param norm = 1.6282e-01, time/batch = 15.7196s	
16607/33150 (epoch 25.048), train_loss = 1.03384086, grad/param norm = 1.8800e-01, time/batch = 18.3182s	
16608/33150 (epoch 25.050), train_loss = 0.95344286, grad/param norm = 1.7691e-01, time/batch = 17.0722s	
16609/33150 (epoch 25.051), train_loss = 0.96016206, grad/param norm = 1.6703e-01, time/batch = 16.9793s	
16610/33150 (epoch 25.053), train_loss = 0.94628208, grad/param norm = 1.7358e-01, time/batch = 17.4914s	
16611/33150 (epoch 25.054), train_loss = 1.08237995, grad/param norm = 1.5266e-01, time/batch = 17.3848s	
16612/33150 (epoch 25.056), train_loss = 0.95409202, grad/param norm = 1.5609e-01, time/batch = 17.6467s	
16613/33150 (epoch 25.057), train_loss = 0.95952870, grad/param norm = 1.6017e-01, time/batch = 16.0813s	
16614/33150 (epoch 25.059), train_loss = 0.89065321, grad/param norm = 1.5529e-01, time/batch = 17.8974s	
16615/33150 (epoch 25.060), train_loss = 0.88023940, grad/param norm = 1.3962e-01, time/batch = 17.9920s	
16616/33150 (epoch 25.062), train_loss = 0.92578214, grad/param norm = 1.5857e-01, time/batch = 16.1453s	
16617/33150 (epoch 25.063), train_loss = 0.89860267, grad/param norm = 1.6953e-01, time/batch = 16.0589s	
16618/33150 (epoch 25.065), train_loss = 0.91341921, grad/param norm = 1.5771e-01, time/batch = 17.1521s	
16619/33150 (epoch 25.066), train_loss = 0.87854053, grad/param norm = 1.4624e-01, time/batch = 17.7260s	
16620/33150 (epoch 25.068), train_loss = 0.99720578, grad/param norm = 1.5178e-01, time/batch = 16.0522s	
16621/33150 (epoch 25.069), train_loss = 0.98457318, grad/param norm = 1.7770e-01, time/batch = 17.3968s	
16622/33150 (epoch 25.071), train_loss = 0.97039696, grad/param norm = 1.5332e-01, time/batch = 17.8233s	
16623/33150 (epoch 25.072), train_loss = 0.94719292, grad/param norm = 1.7890e-01, time/batch = 16.7222s	
16624/33150 (epoch 25.074), train_loss = 0.82714917, grad/param norm = 1.7251e-01, time/batch = 18.3777s	
16625/33150 (epoch 25.075), train_loss = 0.88377487, grad/param norm = 1.7090e-01, time/batch = 16.4809s	
16626/33150 (epoch 25.077), train_loss = 0.92968172, grad/param norm = 1.8899e-01, time/batch = 16.0573s	
16627/33150 (epoch 25.078), train_loss = 1.07129972, grad/param norm = 1.8522e-01, time/batch = 16.9668s	
16628/33150 (epoch 25.080), train_loss = 1.05581493, grad/param norm = 1.5155e-01, time/batch = 18.3066s	
16629/33150 (epoch 25.081), train_loss = 0.84940908, grad/param norm = 1.7444e-01, time/batch = 18.4754s	
16630/33150 (epoch 25.083), train_loss = 0.71795123, grad/param norm = 1.5186e-01, time/batch = 16.7249s	
16631/33150 (epoch 25.084), train_loss = 0.80820364, grad/param norm = 1.5928e-01, time/batch = 17.8935s	
16632/33150 (epoch 25.086), train_loss = 0.88566508, grad/param norm = 1.7022e-01, time/batch = 19.3153s	
16633/33150 (epoch 25.087), train_loss = 0.83572765, grad/param norm = 1.5044e-01, time/batch = 17.3114s	
16634/33150 (epoch 25.089), train_loss = 0.86023470, grad/param norm = 1.5942e-01, time/batch = 17.8840s	
16635/33150 (epoch 25.090), train_loss = 0.92116918, grad/param norm = 1.5545e-01, time/batch = 19.7111s	
16636/33150 (epoch 25.092), train_loss = 0.89024781, grad/param norm = 1.6427e-01, time/batch = 18.7998s	
16637/33150 (epoch 25.094), train_loss = 1.00199593, grad/param norm = 1.7569e-01, time/batch = 16.3915s	
16638/33150 (epoch 25.095), train_loss = 0.86574534, grad/param norm = 1.4069e-01, time/batch = 17.3079s	
16639/33150 (epoch 25.097), train_loss = 0.83686750, grad/param norm = 1.6112e-01, time/batch = 16.6441s	
16640/33150 (epoch 25.098), train_loss = 1.16968312, grad/param norm = 1.7531e-01, time/batch = 16.5715s	
16641/33150 (epoch 25.100), train_loss = 1.13112311, grad/param norm = 1.7740e-01, time/batch = 17.5733s	
16642/33150 (epoch 25.101), train_loss = 0.88492106, grad/param norm = 1.6167e-01, time/batch = 17.8121s	
16643/33150 (epoch 25.103), train_loss = 0.96120539, grad/param norm = 1.6349e-01, time/batch = 17.8105s	
16644/33150 (epoch 25.104), train_loss = 0.87356253, grad/param norm = 1.7677e-01, time/batch = 16.0481s	
16645/33150 (epoch 25.106), train_loss = 1.05806369, grad/param norm = 2.0491e-01, time/batch = 18.0033s	
16646/33150 (epoch 25.107), train_loss = 1.16879958, grad/param norm = 1.8725e-01, time/batch = 19.1474s	
16647/33150 (epoch 25.109), train_loss = 0.93258388, grad/param norm = 1.3973e-01, time/batch = 16.5548s	
16648/33150 (epoch 25.110), train_loss = 1.06538638, grad/param norm = 1.9132e-01, time/batch = 19.3031s	
16649/33150 (epoch 25.112), train_loss = 0.87506658, grad/param norm = 1.5560e-01, time/batch = 18.4811s	
16650/33150 (epoch 25.113), train_loss = 0.91201016, grad/param norm = 1.7729e-01, time/batch = 16.1439s	
16651/33150 (epoch 25.115), train_loss = 1.14021127, grad/param norm = 1.9310e-01, time/batch = 17.9839s	
16652/33150 (epoch 25.116), train_loss = 0.95425984, grad/param norm = 1.4702e-01, time/batch = 17.2063s	
16653/33150 (epoch 25.118), train_loss = 1.01341913, grad/param norm = 1.7576e-01, time/batch = 18.3741s	
16654/33150 (epoch 25.119), train_loss = 1.02772630, grad/param norm = 2.0480e-01, time/batch = 16.2387s	
16655/33150 (epoch 25.121), train_loss = 0.91124254, grad/param norm = 1.4931e-01, time/batch = 18.4682s	
16656/33150 (epoch 25.122), train_loss = 1.12884325, grad/param norm = 2.2665e-01, time/batch = 17.4132s	
16657/33150 (epoch 25.124), train_loss = 0.80666071, grad/param norm = 1.3715e-01, time/batch = 16.3885s	
16658/33150 (epoch 25.125), train_loss = 1.05685604, grad/param norm = 1.6346e-01, time/batch = 16.5723s	
16659/33150 (epoch 25.127), train_loss = 0.94794416, grad/param norm = 1.5744e-01, time/batch = 18.5651s	
16660/33150 (epoch 25.128), train_loss = 1.00900590, grad/param norm = 1.7008e-01, time/batch = 16.7373s	
16661/33150 (epoch 25.130), train_loss = 0.97466971, grad/param norm = 1.5684e-01, time/batch = 15.0806s	
16662/33150 (epoch 25.131), train_loss = 1.16734004, grad/param norm = 1.7694e-01, time/batch = 17.1426s	
16663/33150 (epoch 25.133), train_loss = 0.88361567, grad/param norm = 1.5017e-01, time/batch = 17.1646s	
16664/33150 (epoch 25.134), train_loss = 1.08459377, grad/param norm = 1.7184e-01, time/batch = 16.7299s	
16665/33150 (epoch 25.136), train_loss = 0.94936705, grad/param norm = 1.7201e-01, time/batch = 18.3944s	
16666/33150 (epoch 25.137), train_loss = 1.04751483, grad/param norm = 1.6550e-01, time/batch = 18.7182s	
16667/33150 (epoch 25.139), train_loss = 1.03740594, grad/param norm = 1.6203e-01, time/batch = 17.0563s	
16668/33150 (epoch 25.140), train_loss = 1.09993814, grad/param norm = 1.7371e-01, time/batch = 15.4142s	
16669/33150 (epoch 25.142), train_loss = 1.05246974, grad/param norm = 1.7281e-01, time/batch = 17.2992s	
16670/33150 (epoch 25.143), train_loss = 0.97682918, grad/param norm = 1.8874e-01, time/batch = 17.6542s	
16671/33150 (epoch 25.145), train_loss = 0.94392895, grad/param norm = 1.8556e-01, time/batch = 16.7252s	
16672/33150 (epoch 25.146), train_loss = 1.06871132, grad/param norm = 2.0530e-01, time/batch = 17.6274s	
16673/33150 (epoch 25.148), train_loss = 1.07168873, grad/param norm = 1.5042e-01, time/batch = 19.4690s	
16674/33150 (epoch 25.149), train_loss = 0.98853982, grad/param norm = 1.6317e-01, time/batch = 17.7120s	
16675/33150 (epoch 25.151), train_loss = 1.12736988, grad/param norm = 1.6585e-01, time/batch = 17.3221s	
16676/33150 (epoch 25.152), train_loss = 0.93911251, grad/param norm = 1.5211e-01, time/batch = 18.6413s	
16677/33150 (epoch 25.154), train_loss = 0.92120486, grad/param norm = 1.6893e-01, time/batch = 17.3007s	
16678/33150 (epoch 25.155), train_loss = 0.81613957, grad/param norm = 1.5677e-01, time/batch = 17.2253s	
16679/33150 (epoch 25.157), train_loss = 0.94178891, grad/param norm = 1.6932e-01, time/batch = 18.4687s	
16680/33150 (epoch 25.158), train_loss = 0.91228970, grad/param norm = 1.5674e-01, time/batch = 18.7325s	
16681/33150 (epoch 25.160), train_loss = 1.00782329, grad/param norm = 1.6489e-01, time/batch = 15.7865s	
16682/33150 (epoch 25.161), train_loss = 0.89504422, grad/param norm = 1.7494e-01, time/batch = 15.5638s	
16683/33150 (epoch 25.163), train_loss = 0.84931577, grad/param norm = 1.5905e-01, time/batch = 15.4673s	
16684/33150 (epoch 25.164), train_loss = 0.99856064, grad/param norm = 1.5718e-01, time/batch = 18.7205s	
16685/33150 (epoch 25.166), train_loss = 0.92873125, grad/param norm = 1.5426e-01, time/batch = 17.8960s	
16686/33150 (epoch 25.167), train_loss = 0.96992383, grad/param norm = 1.4821e-01, time/batch = 16.2296s	
16687/33150 (epoch 25.169), train_loss = 0.98436351, grad/param norm = 1.8905e-01, time/batch = 19.2153s	
16688/33150 (epoch 25.170), train_loss = 0.87555754, grad/param norm = 1.8315e-01, time/batch = 16.4013s	
16689/33150 (epoch 25.172), train_loss = 1.04568654, grad/param norm = 1.8249e-01, time/batch = 17.3141s	
16690/33150 (epoch 25.173), train_loss = 1.01788091, grad/param norm = 2.1173e-01, time/batch = 17.7190s	
16691/33150 (epoch 25.175), train_loss = 0.91847485, grad/param norm = 1.6564e-01, time/batch = 17.4715s	
16692/33150 (epoch 25.176), train_loss = 1.02347136, grad/param norm = 1.7456e-01, time/batch = 17.1440s	
16693/33150 (epoch 25.178), train_loss = 1.13976057, grad/param norm = 1.7634e-01, time/batch = 16.2928s	
16694/33150 (epoch 25.179), train_loss = 1.02043652, grad/param norm = 1.5753e-01, time/batch = 15.4858s	
16695/33150 (epoch 25.181), train_loss = 0.96324710, grad/param norm = 1.6377e-01, time/batch = 15.0125s	
16696/33150 (epoch 25.183), train_loss = 0.94357093, grad/param norm = 1.7393e-01, time/batch = 15.0408s	
16697/33150 (epoch 25.184), train_loss = 1.17890472, grad/param norm = 1.7567e-01, time/batch = 15.2845s	
16698/33150 (epoch 25.186), train_loss = 1.08706059, grad/param norm = 1.6154e-01, time/batch = 15.1963s	
16699/33150 (epoch 25.187), train_loss = 0.99041324, grad/param norm = 1.7293e-01, time/batch = 15.2684s	
16700/33150 (epoch 25.189), train_loss = 0.76127233, grad/param norm = 1.6777e-01, time/batch = 15.6022s	
16701/33150 (epoch 25.190), train_loss = 0.88908798, grad/param norm = 2.4269e-01, time/batch = 17.9065s	
16702/33150 (epoch 25.192), train_loss = 0.98530627, grad/param norm = 1.8379e-01, time/batch = 17.8778s	
16703/33150 (epoch 25.193), train_loss = 1.05746299, grad/param norm = 1.8055e-01, time/batch = 17.0461s	
16704/33150 (epoch 25.195), train_loss = 1.18788835, grad/param norm = 1.9806e-01, time/batch = 16.6393s	
16705/33150 (epoch 25.196), train_loss = 1.07143776, grad/param norm = 1.7099e-01, time/batch = 15.9425s	
16706/33150 (epoch 25.198), train_loss = 0.85088174, grad/param norm = 1.8068e-01, time/batch = 17.3814s	
16707/33150 (epoch 25.199), train_loss = 1.06071939, grad/param norm = 2.2344e-01, time/batch = 17.6248s	
16708/33150 (epoch 25.201), train_loss = 0.89416800, grad/param norm = 1.2922e-01, time/batch = 16.2369s	
16709/33150 (epoch 25.202), train_loss = 0.77486300, grad/param norm = 1.4824e-01, time/batch = 18.4822s	
16710/33150 (epoch 25.204), train_loss = 1.00261729, grad/param norm = 1.5804e-01, time/batch = 16.0415s	
16711/33150 (epoch 25.205), train_loss = 1.02523867, grad/param norm = 1.7343e-01, time/batch = 18.1426s	
16712/33150 (epoch 25.207), train_loss = 1.01068526, grad/param norm = 1.6473e-01, time/batch = 19.3056s	
16713/33150 (epoch 25.208), train_loss = 1.03744007, grad/param norm = 1.6628e-01, time/batch = 16.2139s	
16714/33150 (epoch 25.210), train_loss = 0.90868347, grad/param norm = 1.4247e-01, time/batch = 18.5710s	
16715/33150 (epoch 25.211), train_loss = 0.98435516, grad/param norm = 1.7261e-01, time/batch = 18.5633s	
16716/33150 (epoch 25.213), train_loss = 1.02376643, grad/param norm = 1.5702e-01, time/batch = 16.9619s	
16717/33150 (epoch 25.214), train_loss = 0.95460466, grad/param norm = 1.7710e-01, time/batch = 16.2286s	
16718/33150 (epoch 25.216), train_loss = 0.90123700, grad/param norm = 1.6917e-01, time/batch = 17.8125s	
16719/33150 (epoch 25.217), train_loss = 0.93577774, grad/param norm = 1.5174e-01, time/batch = 18.5604s	
16720/33150 (epoch 25.219), train_loss = 0.86344918, grad/param norm = 1.5766e-01, time/batch = 15.2971s	
16721/33150 (epoch 25.220), train_loss = 0.89048775, grad/param norm = 1.3944e-01, time/batch = 16.2851s	
16722/33150 (epoch 25.222), train_loss = 1.08411513, grad/param norm = 1.6499e-01, time/batch = 16.7348s	
16723/33150 (epoch 25.223), train_loss = 0.96387499, grad/param norm = 1.7801e-01, time/batch = 15.6442s	
16724/33150 (epoch 25.225), train_loss = 1.08515443, grad/param norm = 1.7146e-01, time/batch = 16.6406s	
16725/33150 (epoch 25.226), train_loss = 0.96023101, grad/param norm = 1.5426e-01, time/batch = 16.2264s	
16726/33150 (epoch 25.228), train_loss = 0.94986481, grad/param norm = 1.7056e-01, time/batch = 17.1459s	
16727/33150 (epoch 25.229), train_loss = 0.95295690, grad/param norm = 1.5609e-01, time/batch = 17.3004s	
16728/33150 (epoch 25.231), train_loss = 1.06527753, grad/param norm = 1.7891e-01, time/batch = 18.3837s	
16729/33150 (epoch 25.232), train_loss = 0.98642241, grad/param norm = 1.7883e-01, time/batch = 16.6370s	
16730/33150 (epoch 25.234), train_loss = 0.96131604, grad/param norm = 2.0035e-01, time/batch = 18.2938s	
16731/33150 (epoch 25.235), train_loss = 1.00825639, grad/param norm = 1.8238e-01, time/batch = 17.1398s	
16732/33150 (epoch 25.237), train_loss = 0.97637858, grad/param norm = 1.8574e-01, time/batch = 19.2238s	
16733/33150 (epoch 25.238), train_loss = 1.01721079, grad/param norm = 1.9602e-01, time/batch = 18.3977s	
16734/33150 (epoch 25.240), train_loss = 0.99574441, grad/param norm = 1.5237e-01, time/batch = 16.3738s	
16735/33150 (epoch 25.241), train_loss = 1.05998535, grad/param norm = 1.7624e-01, time/batch = 19.2042s	
16736/33150 (epoch 25.243), train_loss = 1.04424413, grad/param norm = 1.7442e-01, time/batch = 19.3025s	
16737/33150 (epoch 25.244), train_loss = 0.95721441, grad/param norm = 1.5466e-01, time/batch = 16.3900s	
16738/33150 (epoch 25.246), train_loss = 1.02741787, grad/param norm = 1.5355e-01, time/batch = 15.1696s	
16739/33150 (epoch 25.247), train_loss = 0.92187413, grad/param norm = 1.6379e-01, time/batch = 18.3839s	
16740/33150 (epoch 25.249), train_loss = 1.09541347, grad/param norm = 1.6595e-01, time/batch = 18.1340s	
16741/33150 (epoch 25.250), train_loss = 1.02478316, grad/param norm = 1.4392e-01, time/batch = 16.9753s	
16742/33150 (epoch 25.252), train_loss = 1.02902870, grad/param norm = 1.4687e-01, time/batch = 17.0536s	
16743/33150 (epoch 25.253), train_loss = 0.94795205, grad/param norm = 1.7615e-01, time/batch = 17.4047s	
16744/33150 (epoch 25.255), train_loss = 0.94935663, grad/param norm = 1.4633e-01, time/batch = 16.1440s	
16745/33150 (epoch 25.256), train_loss = 1.05445810, grad/param norm = 1.5593e-01, time/batch = 17.7248s	
16746/33150 (epoch 25.258), train_loss = 0.90125265, grad/param norm = 1.6852e-01, time/batch = 16.4075s	
16747/33150 (epoch 25.259), train_loss = 0.79827837, grad/param norm = 1.4785e-01, time/batch = 18.4717s	
16748/33150 (epoch 25.261), train_loss = 0.85980327, grad/param norm = 1.3608e-01, time/batch = 15.7564s	
16749/33150 (epoch 25.262), train_loss = 1.05605360, grad/param norm = 1.7140e-01, time/batch = 18.2379s	
16750/33150 (epoch 25.264), train_loss = 0.75783527, grad/param norm = 1.4529e-01, time/batch = 17.1488s	
16751/33150 (epoch 25.265), train_loss = 1.00041073, grad/param norm = 1.6498e-01, time/batch = 16.4831s	
16752/33150 (epoch 25.267), train_loss = 1.02990249, grad/param norm = 1.7727e-01, time/batch = 17.4065s	
16753/33150 (epoch 25.268), train_loss = 1.05705176, grad/param norm = 1.4976e-01, time/batch = 18.0642s	
16754/33150 (epoch 25.270), train_loss = 1.16253937, grad/param norm = 1.8870e-01, time/batch = 18.4670s	
16755/33150 (epoch 25.271), train_loss = 1.08195125, grad/param norm = 1.7912e-01, time/batch = 17.3868s	
16756/33150 (epoch 25.273), train_loss = 1.07251117, grad/param norm = 1.5922e-01, time/batch = 19.8059s	
16757/33150 (epoch 25.275), train_loss = 1.10415150, grad/param norm = 1.7488e-01, time/batch = 18.3798s	
16758/33150 (epoch 25.276), train_loss = 0.99453301, grad/param norm = 1.8223e-01, time/batch = 16.6365s	
16759/33150 (epoch 25.278), train_loss = 1.08636577, grad/param norm = 1.6281e-01, time/batch = 16.4954s	
16760/33150 (epoch 25.279), train_loss = 1.02926734, grad/param norm = 1.5278e-01, time/batch = 17.0615s	
16761/33150 (epoch 25.281), train_loss = 1.00678458, grad/param norm = 1.6334e-01, time/batch = 16.5491s	
16762/33150 (epoch 25.282), train_loss = 1.00419352, grad/param norm = 1.4197e-01, time/batch = 18.2173s	
16763/33150 (epoch 25.284), train_loss = 0.90753211, grad/param norm = 1.4571e-01, time/batch = 17.8125s	
16764/33150 (epoch 25.285), train_loss = 0.98311873, grad/param norm = 1.5212e-01, time/batch = 18.7155s	
16765/33150 (epoch 25.287), train_loss = 0.87470089, grad/param norm = 1.5525e-01, time/batch = 17.9839s	
16766/33150 (epoch 25.288), train_loss = 1.07613637, grad/param norm = 1.6682e-01, time/batch = 18.0547s	
16767/33150 (epoch 25.290), train_loss = 0.83698673, grad/param norm = 1.5335e-01, time/batch = 19.0580s	
16768/33150 (epoch 25.291), train_loss = 0.80977792, grad/param norm = 1.4307e-01, time/batch = 16.8029s	
16769/33150 (epoch 25.293), train_loss = 1.01804953, grad/param norm = 1.6445e-01, time/batch = 18.6290s	
16770/33150 (epoch 25.294), train_loss = 0.73640892, grad/param norm = 1.3680e-01, time/batch = 17.3168s	
16771/33150 (epoch 25.296), train_loss = 0.96032825, grad/param norm = 1.3901e-01, time/batch = 17.3178s	
16772/33150 (epoch 25.297), train_loss = 0.92043188, grad/param norm = 1.6327e-01, time/batch = 16.9580s	
16773/33150 (epoch 25.299), train_loss = 0.91067443, grad/param norm = 1.8351e-01, time/batch = 16.9003s	
16774/33150 (epoch 25.300), train_loss = 0.91661641, grad/param norm = 1.3570e-01, time/batch = 17.1594s	
16775/33150 (epoch 25.302), train_loss = 0.93355159, grad/param norm = 1.4593e-01, time/batch = 17.3817s	
16776/33150 (epoch 25.303), train_loss = 0.93129806, grad/param norm = 1.4437e-01, time/batch = 18.5677s	
16777/33150 (epoch 25.305), train_loss = 1.01387396, grad/param norm = 1.5848e-01, time/batch = 17.2374s	
16778/33150 (epoch 25.306), train_loss = 1.04281484, grad/param norm = 2.0992e-01, time/batch = 16.6421s	
16779/33150 (epoch 25.308), train_loss = 1.19435368, grad/param norm = 1.7879e-01, time/batch = 15.9079s	
16780/33150 (epoch 25.309), train_loss = 0.79642933, grad/param norm = 1.4189e-01, time/batch = 17.7207s	
16781/33150 (epoch 25.311), train_loss = 0.92065466, grad/param norm = 1.7546e-01, time/batch = 18.0516s	
16782/33150 (epoch 25.312), train_loss = 0.77312923, grad/param norm = 1.3884e-01, time/batch = 17.2301s	
16783/33150 (epoch 25.314), train_loss = 0.91604727, grad/param norm = 1.6618e-01, time/batch = 19.2245s	
16784/33150 (epoch 25.315), train_loss = 1.00315002, grad/param norm = 1.4967e-01, time/batch = 19.0702s	
16785/33150 (epoch 25.317), train_loss = 0.76998089, grad/param norm = 1.2432e-01, time/batch = 17.3034s	
16786/33150 (epoch 25.318), train_loss = 0.87995156, grad/param norm = 1.3619e-01, time/batch = 18.1449s	
16787/33150 (epoch 25.320), train_loss = 0.81324706, grad/param norm = 1.3597e-01, time/batch = 18.1435s	
16788/33150 (epoch 25.321), train_loss = 0.93244105, grad/param norm = 1.4166e-01, time/batch = 17.7131s	
16789/33150 (epoch 25.323), train_loss = 0.93232130, grad/param norm = 1.5330e-01, time/batch = 18.6377s	
16790/33150 (epoch 25.324), train_loss = 1.01011996, grad/param norm = 1.7804e-01, time/batch = 18.2354s	
16791/33150 (epoch 25.326), train_loss = 0.98737243, grad/param norm = 1.5673e-01, time/batch = 17.1632s	
16792/33150 (epoch 25.327), train_loss = 1.07921755, grad/param norm = 1.6303e-01, time/batch = 17.7347s	
16793/33150 (epoch 25.329), train_loss = 1.00179875, grad/param norm = 1.4627e-01, time/batch = 18.3943s	
16794/33150 (epoch 25.330), train_loss = 0.95613122, grad/param norm = 1.7663e-01, time/batch = 15.2268s	
16795/33150 (epoch 25.332), train_loss = 0.95272602, grad/param norm = 1.4203e-01, time/batch = 27.9359s	
16796/33150 (epoch 25.333), train_loss = 1.00012145, grad/param norm = 1.3593e-01, time/batch = 18.5582s	
16797/33150 (epoch 25.335), train_loss = 0.91786371, grad/param norm = 1.8902e-01, time/batch = 17.6510s	
16798/33150 (epoch 25.336), train_loss = 0.87851827, grad/param norm = 1.6311e-01, time/batch = 16.8018s	
16799/33150 (epoch 25.338), train_loss = 0.80902444, grad/param norm = 1.5225e-01, time/batch = 17.8937s	
16800/33150 (epoch 25.339), train_loss = 1.03799927, grad/param norm = 1.5974e-01, time/batch = 17.8847s	
16801/33150 (epoch 25.341), train_loss = 0.99480317, grad/param norm = 1.7618e-01, time/batch = 16.2314s	
16802/33150 (epoch 25.342), train_loss = 0.86746279, grad/param norm = 1.7241e-01, time/batch = 18.3040s	
16803/33150 (epoch 25.344), train_loss = 0.96610544, grad/param norm = 1.7455e-01, time/batch = 18.0536s	
16804/33150 (epoch 25.345), train_loss = 0.92330417, grad/param norm = 1.5195e-01, time/batch = 16.5671s	
16805/33150 (epoch 25.347), train_loss = 0.76171359, grad/param norm = 1.3702e-01, time/batch = 16.4879s	
16806/33150 (epoch 25.348), train_loss = 0.97174210, grad/param norm = 1.4947e-01, time/batch = 19.3907s	
16807/33150 (epoch 25.350), train_loss = 0.87036429, grad/param norm = 1.8122e-01, time/batch = 18.2366s	
16808/33150 (epoch 25.351), train_loss = 1.03416008, grad/param norm = 1.6533e-01, time/batch = 18.2059s	
16809/33150 (epoch 25.353), train_loss = 0.99425096, grad/param norm = 1.6775e-01, time/batch = 19.5644s	
16810/33150 (epoch 25.354), train_loss = 1.20476685, grad/param norm = 1.6213e-01, time/batch = 18.2336s	
16811/33150 (epoch 25.356), train_loss = 1.05648438, grad/param norm = 1.7639e-01, time/batch = 16.3733s	
16812/33150 (epoch 25.357), train_loss = 0.99358470, grad/param norm = 1.7997e-01, time/batch = 17.7445s	
16813/33150 (epoch 25.359), train_loss = 1.02214148, grad/param norm = 1.5817e-01, time/batch = 18.7338s	
16814/33150 (epoch 25.360), train_loss = 1.01542403, grad/param norm = 1.7418e-01, time/batch = 17.1399s	
16815/33150 (epoch 25.362), train_loss = 1.07289408, grad/param norm = 1.7661e-01, time/batch = 17.6492s	
16816/33150 (epoch 25.363), train_loss = 0.96378650, grad/param norm = 1.4531e-01, time/batch = 16.9668s	
16817/33150 (epoch 25.365), train_loss = 0.95280507, grad/param norm = 1.5491e-01, time/batch = 18.6405s	
16818/33150 (epoch 25.367), train_loss = 0.90786744, grad/param norm = 1.4819e-01, time/batch = 17.2234s	
16819/33150 (epoch 25.368), train_loss = 0.96812603, grad/param norm = 1.9831e-01, time/batch = 18.6092s	
16820/33150 (epoch 25.370), train_loss = 0.97360078, grad/param norm = 1.7144e-01, time/batch = 18.2309s	
16821/33150 (epoch 25.371), train_loss = 0.86294561, grad/param norm = 1.4929e-01, time/batch = 17.3031s	
16822/33150 (epoch 25.373), train_loss = 1.01752266, grad/param norm = 1.8106e-01, time/batch = 16.3194s	
16823/33150 (epoch 25.374), train_loss = 0.93057012, grad/param norm = 1.5746e-01, time/batch = 17.9030s	
16824/33150 (epoch 25.376), train_loss = 1.07349595, grad/param norm = 1.7071e-01, time/batch = 16.8846s	
16825/33150 (epoch 25.377), train_loss = 0.89919169, grad/param norm = 1.5767e-01, time/batch = 16.8992s	
16826/33150 (epoch 25.379), train_loss = 1.04118967, grad/param norm = 1.7652e-01, time/batch = 16.7998s	
16827/33150 (epoch 25.380), train_loss = 1.03726584, grad/param norm = 1.4675e-01, time/batch = 16.5505s	
16828/33150 (epoch 25.382), train_loss = 0.91399754, grad/param norm = 1.4702e-01, time/batch = 16.7141s	
16829/33150 (epoch 25.383), train_loss = 0.89921620, grad/param norm = 1.5759e-01, time/batch = 15.7157s	
16830/33150 (epoch 25.385), train_loss = 0.93599546, grad/param norm = 1.6627e-01, time/batch = 16.9556s	
16831/33150 (epoch 25.386), train_loss = 0.82115153, grad/param norm = 1.4264e-01, time/batch = 17.5582s	
16832/33150 (epoch 25.388), train_loss = 0.89920231, grad/param norm = 1.5824e-01, time/batch = 16.9486s	
16833/33150 (epoch 25.389), train_loss = 0.88298027, grad/param norm = 1.4653e-01, time/batch = 18.8192s	
16834/33150 (epoch 25.391), train_loss = 1.12865242, grad/param norm = 1.6793e-01, time/batch = 19.1583s	
16835/33150 (epoch 25.392), train_loss = 0.92702870, grad/param norm = 1.5861e-01, time/batch = 17.3781s	
16836/33150 (epoch 25.394), train_loss = 0.80142401, grad/param norm = 1.3415e-01, time/batch = 19.9650s	
16837/33150 (epoch 25.395), train_loss = 0.79397459, grad/param norm = 1.4530e-01, time/batch = 17.7289s	
16838/33150 (epoch 25.397), train_loss = 0.67031576, grad/param norm = 1.3601e-01, time/batch = 16.9987s	
16839/33150 (epoch 25.398), train_loss = 0.96403923, grad/param norm = 1.6818e-01, time/batch = 16.4860s	
16840/33150 (epoch 25.400), train_loss = 0.91728903, grad/param norm = 1.3327e-01, time/batch = 15.0804s	
16841/33150 (epoch 25.401), train_loss = 0.81496187, grad/param norm = 1.3512e-01, time/batch = 18.4013s	
16842/33150 (epoch 25.403), train_loss = 0.80309292, grad/param norm = 1.3014e-01, time/batch = 15.7416s	
16843/33150 (epoch 25.404), train_loss = 0.95489437, grad/param norm = 1.5858e-01, time/batch = 17.8002s	
16844/33150 (epoch 25.406), train_loss = 0.89483538, grad/param norm = 1.2792e-01, time/batch = 18.6490s	
16845/33150 (epoch 25.407), train_loss = 0.82892231, grad/param norm = 1.4290e-01, time/batch = 17.0546s	
16846/33150 (epoch 25.409), train_loss = 0.78475125, grad/param norm = 1.3797e-01, time/batch = 14.8964s	
16847/33150 (epoch 25.410), train_loss = 0.96743655, grad/param norm = 1.6365e-01, time/batch = 14.9653s	
16848/33150 (epoch 25.412), train_loss = 1.00960700, grad/param norm = 1.5906e-01, time/batch = 14.9661s	
16849/33150 (epoch 25.413), train_loss = 0.86754224, grad/param norm = 1.5451e-01, time/batch = 15.4339s	
16850/33150 (epoch 25.415), train_loss = 0.96688262, grad/param norm = 1.4890e-01, time/batch = 15.3458s	
16851/33150 (epoch 25.416), train_loss = 0.87644589, grad/param norm = 1.4357e-01, time/batch = 15.4454s	
16852/33150 (epoch 25.418), train_loss = 1.02642783, grad/param norm = 1.9330e-01, time/batch = 15.3949s	
16853/33150 (epoch 25.419), train_loss = 0.90928740, grad/param norm = 1.5189e-01, time/batch = 16.6167s	
16854/33150 (epoch 25.421), train_loss = 0.94069761, grad/param norm = 1.7072e-01, time/batch = 17.7234s	
16855/33150 (epoch 25.422), train_loss = 0.89805686, grad/param norm = 1.6281e-01, time/batch = 16.4626s	
16856/33150 (epoch 25.424), train_loss = 0.88620093, grad/param norm = 1.6042e-01, time/batch = 17.8119s	
16857/33150 (epoch 25.425), train_loss = 1.01015147, grad/param norm = 1.6348e-01, time/batch = 17.6265s	
16858/33150 (epoch 25.427), train_loss = 0.93394451, grad/param norm = 1.3334e-01, time/batch = 16.4442s	
16859/33150 (epoch 25.428), train_loss = 0.95024865, grad/param norm = 1.6077e-01, time/batch = 17.5219s	
16860/33150 (epoch 25.430), train_loss = 0.95804393, grad/param norm = 1.5918e-01, time/batch = 16.6317s	
16861/33150 (epoch 25.431), train_loss = 1.02451629, grad/param norm = 1.6912e-01, time/batch = 17.7878s	
16862/33150 (epoch 25.433), train_loss = 0.92166956, grad/param norm = 1.5272e-01, time/batch = 16.6432s	
16863/33150 (epoch 25.434), train_loss = 0.83026319, grad/param norm = 1.4888e-01, time/batch = 17.6258s	
16864/33150 (epoch 25.436), train_loss = 0.92652748, grad/param norm = 1.4635e-01, time/batch = 15.5222s	
16865/33150 (epoch 25.437), train_loss = 0.96256024, grad/param norm = 1.7848e-01, time/batch = 17.6370s	
16866/33150 (epoch 25.439), train_loss = 1.09801241, grad/param norm = 1.6206e-01, time/batch = 16.5645s	
16867/33150 (epoch 25.440), train_loss = 1.03236322, grad/param norm = 1.6486e-01, time/batch = 16.1073s	
16868/33150 (epoch 25.442), train_loss = 0.83592971, grad/param norm = 1.7047e-01, time/batch = 17.7924s	
16869/33150 (epoch 25.443), train_loss = 1.00790265, grad/param norm = 1.6313e-01, time/batch = 17.0683s	
16870/33150 (epoch 25.445), train_loss = 0.97102345, grad/param norm = 1.7788e-01, time/batch = 18.4405s	
16871/33150 (epoch 25.446), train_loss = 0.97843913, grad/param norm = 1.9098e-01, time/batch = 17.3824s	
16872/33150 (epoch 25.448), train_loss = 1.04709154, grad/param norm = 1.6495e-01, time/batch = 18.2077s	
16873/33150 (epoch 25.449), train_loss = 0.97282768, grad/param norm = 1.4378e-01, time/batch = 18.1380s	
16874/33150 (epoch 25.451), train_loss = 0.96648909, grad/param norm = 2.0172e-01, time/batch = 17.6228s	
16875/33150 (epoch 25.452), train_loss = 1.14616411, grad/param norm = 1.6762e-01, time/batch = 18.6992s	
16876/33150 (epoch 25.454), train_loss = 0.97588129, grad/param norm = 1.7153e-01, time/batch = 16.4370s	
16877/33150 (epoch 25.456), train_loss = 0.84470232, grad/param norm = 1.4681e-01, time/batch = 16.3756s	
16878/33150 (epoch 25.457), train_loss = 0.95432968, grad/param norm = 1.5404e-01, time/batch = 16.3700s	
16879/33150 (epoch 25.459), train_loss = 1.07403991, grad/param norm = 2.1706e-01, time/batch = 18.5216s	
16880/33150 (epoch 25.460), train_loss = 0.99927010, grad/param norm = 1.3849e-01, time/batch = 17.9779s	
16881/33150 (epoch 25.462), train_loss = 1.03368215, grad/param norm = 1.9273e-01, time/batch = 17.0345s	
16882/33150 (epoch 25.463), train_loss = 1.17846239, grad/param norm = 2.1014e-01, time/batch = 16.9624s	
16883/33150 (epoch 25.465), train_loss = 0.97895194, grad/param norm = 1.5999e-01, time/batch = 19.2291s	
16884/33150 (epoch 25.466), train_loss = 0.89398801, grad/param norm = 1.5909e-01, time/batch = 18.0647s	
16885/33150 (epoch 25.468), train_loss = 1.18345850, grad/param norm = 1.6572e-01, time/batch = 18.0698s	
16886/33150 (epoch 25.469), train_loss = 0.94355176, grad/param norm = 1.6113e-01, time/batch = 16.6420s	
16887/33150 (epoch 25.471), train_loss = 0.88182043, grad/param norm = 1.4632e-01, time/batch = 18.1416s	
16888/33150 (epoch 25.472), train_loss = 0.97701692, grad/param norm = 1.7126e-01, time/batch = 16.9740s	
16889/33150 (epoch 25.474), train_loss = 1.06409572, grad/param norm = 2.0105e-01, time/batch = 17.4924s	
16890/33150 (epoch 25.475), train_loss = 1.19905083, grad/param norm = 1.7909e-01, time/batch = 18.1482s	
16891/33150 (epoch 25.477), train_loss = 1.07624940, grad/param norm = 1.7961e-01, time/batch = 15.9607s	
16892/33150 (epoch 25.478), train_loss = 1.05609506, grad/param norm = 1.6227e-01, time/batch = 16.9672s	
16893/33150 (epoch 25.480), train_loss = 0.89721554, grad/param norm = 1.6119e-01, time/batch = 20.2033s	
16894/33150 (epoch 25.481), train_loss = 0.81122505, grad/param norm = 1.5428e-01, time/batch = 17.4608s	
16895/33150 (epoch 25.483), train_loss = 0.90071848, grad/param norm = 1.4464e-01, time/batch = 16.4123s	
16896/33150 (epoch 25.484), train_loss = 0.89684698, grad/param norm = 1.5765e-01, time/batch = 19.1385s	
16897/33150 (epoch 25.486), train_loss = 0.87919137, grad/param norm = 1.4143e-01, time/batch = 18.7864s	
16898/33150 (epoch 25.487), train_loss = 0.98444605, grad/param norm = 1.7011e-01, time/batch = 17.7121s	
16899/33150 (epoch 25.489), train_loss = 0.94563696, grad/param norm = 1.6514e-01, time/batch = 17.5373s	
16900/33150 (epoch 25.490), train_loss = 0.81331550, grad/param norm = 1.4553e-01, time/batch = 16.7895s	
16901/33150 (epoch 25.492), train_loss = 0.90714251, grad/param norm = 1.6059e-01, time/batch = 15.7887s	
16902/33150 (epoch 25.493), train_loss = 1.04257857, grad/param norm = 1.7105e-01, time/batch = 16.0414s	
16903/33150 (epoch 25.495), train_loss = 1.03741141, grad/param norm = 1.6568e-01, time/batch = 17.8828s	
16904/33150 (epoch 25.496), train_loss = 0.94187585, grad/param norm = 1.5503e-01, time/batch = 17.8658s	
16905/33150 (epoch 25.498), train_loss = 1.06775322, grad/param norm = 2.0451e-01, time/batch = 15.3049s	
16906/33150 (epoch 25.499), train_loss = 1.06365326, grad/param norm = 1.8936e-01, time/batch = 15.8267s	
16907/33150 (epoch 25.501), train_loss = 1.00777599, grad/param norm = 1.7877e-01, time/batch = 15.1574s	
16908/33150 (epoch 25.502), train_loss = 1.08144191, grad/param norm = 1.7444e-01, time/batch = 14.9687s	
16909/33150 (epoch 25.504), train_loss = 1.02254533, grad/param norm = 1.7640e-01, time/batch = 15.4612s	
16910/33150 (epoch 25.505), train_loss = 1.12853832, grad/param norm = 1.8168e-01, time/batch = 17.3883s	
16911/33150 (epoch 25.507), train_loss = 0.93011507, grad/param norm = 1.7444e-01, time/batch = 19.6236s	
16912/33150 (epoch 25.508), train_loss = 0.92385201, grad/param norm = 1.7273e-01, time/batch = 17.8019s	
16913/33150 (epoch 25.510), train_loss = 1.03192114, grad/param norm = 1.4951e-01, time/batch = 18.9731s	
16914/33150 (epoch 25.511), train_loss = 1.08606004, grad/param norm = 1.6546e-01, time/batch = 19.8837s	
16915/33150 (epoch 25.513), train_loss = 0.97972194, grad/param norm = 1.6061e-01, time/batch = 15.9747s	
16916/33150 (epoch 25.514), train_loss = 0.79043952, grad/param norm = 1.4674e-01, time/batch = 16.8037s	
16917/33150 (epoch 25.516), train_loss = 0.98848459, grad/param norm = 1.8898e-01, time/batch = 19.2950s	
16918/33150 (epoch 25.517), train_loss = 1.06908292, grad/param norm = 1.7518e-01, time/batch = 18.1414s	
16919/33150 (epoch 25.519), train_loss = 0.88883232, grad/param norm = 1.6236e-01, time/batch = 17.7142s	
16920/33150 (epoch 25.520), train_loss = 0.96358279, grad/param norm = 1.5765e-01, time/batch = 16.3157s	
16921/33150 (epoch 25.522), train_loss = 1.07905042, grad/param norm = 1.8379e-01, time/batch = 18.3194s	
16922/33150 (epoch 25.523), train_loss = 0.86763605, grad/param norm = 1.5131e-01, time/batch = 16.8916s	
16923/33150 (epoch 25.525), train_loss = 1.02242242, grad/param norm = 1.6817e-01, time/batch = 17.7269s	
16924/33150 (epoch 25.526), train_loss = 0.89982308, grad/param norm = 1.6462e-01, time/batch = 18.4113s	
16925/33150 (epoch 25.528), train_loss = 1.01800837, grad/param norm = 1.6266e-01, time/batch = 15.2117s	
16926/33150 (epoch 25.529), train_loss = 0.95826006, grad/param norm = 1.6025e-01, time/batch = 15.9726s	
16927/33150 (epoch 25.531), train_loss = 0.80545029, grad/param norm = 1.7287e-01, time/batch = 17.8208s	
16928/33150 (epoch 25.532), train_loss = 0.99305514, grad/param norm = 1.8840e-01, time/batch = 16.9851s	
16929/33150 (epoch 25.534), train_loss = 0.94360918, grad/param norm = 1.3501e-01, time/batch = 16.6565s	
16930/33150 (epoch 25.535), train_loss = 0.89550502, grad/param norm = 1.8458e-01, time/batch = 16.5033s	
16931/33150 (epoch 25.537), train_loss = 1.00671600, grad/param norm = 1.7220e-01, time/batch = 17.6509s	
16932/33150 (epoch 25.538), train_loss = 0.89954575, grad/param norm = 1.5305e-01, time/batch = 15.9837s	
16933/33150 (epoch 25.540), train_loss = 0.84208648, grad/param norm = 1.5677e-01, time/batch = 16.0558s	
16934/33150 (epoch 25.541), train_loss = 1.05918562, grad/param norm = 1.6519e-01, time/batch = 15.6255s	
16935/33150 (epoch 25.543), train_loss = 0.94973966, grad/param norm = 1.4627e-01, time/batch = 18.6376s	
16936/33150 (epoch 25.544), train_loss = 1.04194928, grad/param norm = 1.5984e-01, time/batch = 17.8946s	
16937/33150 (epoch 25.546), train_loss = 1.00067424, grad/param norm = 1.7145e-01, time/batch = 17.8969s	
16938/33150 (epoch 25.548), train_loss = 0.92920408, grad/param norm = 1.5732e-01, time/batch = 17.8201s	
16939/33150 (epoch 25.549), train_loss = 0.91125546, grad/param norm = 1.6712e-01, time/batch = 17.3021s	
16940/33150 (epoch 25.551), train_loss = 0.88246295, grad/param norm = 1.4724e-01, time/batch = 18.4819s	
16941/33150 (epoch 25.552), train_loss = 0.75227950, grad/param norm = 1.2666e-01, time/batch = 18.3042s	
16942/33150 (epoch 25.554), train_loss = 1.02528777, grad/param norm = 1.5428e-01, time/batch = 17.1503s	
16943/33150 (epoch 25.555), train_loss = 1.06727717, grad/param norm = 1.6757e-01, time/batch = 17.0434s	
16944/33150 (epoch 25.557), train_loss = 0.77549860, grad/param norm = 1.4971e-01, time/batch = 19.4800s	
16945/33150 (epoch 25.558), train_loss = 1.01602923, grad/param norm = 1.7143e-01, time/batch = 18.1472s	
16946/33150 (epoch 25.560), train_loss = 0.92360857, grad/param norm = 1.6864e-01, time/batch = 16.7345s	
16947/33150 (epoch 25.561), train_loss = 0.81351225, grad/param norm = 1.4734e-01, time/batch = 18.4778s	
16948/33150 (epoch 25.563), train_loss = 1.03777438, grad/param norm = 2.0845e-01, time/batch = 18.3187s	
16949/33150 (epoch 25.564), train_loss = 1.11873809, grad/param norm = 1.7644e-01, time/batch = 15.1338s	
16950/33150 (epoch 25.566), train_loss = 0.90403065, grad/param norm = 1.5820e-01, time/batch = 16.3832s	
16951/33150 (epoch 25.567), train_loss = 0.87156335, grad/param norm = 1.5003e-01, time/batch = 17.3971s	
16952/33150 (epoch 25.569), train_loss = 0.99692923, grad/param norm = 1.6718e-01, time/batch = 19.3177s	
16953/33150 (epoch 25.570), train_loss = 1.03153486, grad/param norm = 1.6099e-01, time/batch = 16.4706s	
16954/33150 (epoch 25.572), train_loss = 0.86922424, grad/param norm = 1.8157e-01, time/batch = 17.9904s	
16955/33150 (epoch 25.573), train_loss = 0.78657269, grad/param norm = 1.3601e-01, time/batch = 19.8875s	
16956/33150 (epoch 25.575), train_loss = 0.94032567, grad/param norm = 1.6165e-01, time/batch = 16.8072s	
16957/33150 (epoch 25.576), train_loss = 0.82681931, grad/param norm = 1.3438e-01, time/batch = 18.3128s	
16958/33150 (epoch 25.578), train_loss = 0.89794100, grad/param norm = 1.5752e-01, time/batch = 18.6339s	
16959/33150 (epoch 25.579), train_loss = 0.81753405, grad/param norm = 1.6272e-01, time/batch = 17.1177s	
16960/33150 (epoch 25.581), train_loss = 0.86734059, grad/param norm = 1.5259e-01, time/batch = 18.7260s	
16961/33150 (epoch 25.582), train_loss = 1.07780474, grad/param norm = 1.4855e-01, time/batch = 18.0783s	
16962/33150 (epoch 25.584), train_loss = 1.02020119, grad/param norm = 1.5945e-01, time/batch = 18.4760s	
16963/33150 (epoch 25.585), train_loss = 0.96487267, grad/param norm = 1.7432e-01, time/batch = 17.8644s	
16964/33150 (epoch 25.587), train_loss = 0.96045843, grad/param norm = 1.6037e-01, time/batch = 17.5722s	
16965/33150 (epoch 25.588), train_loss = 0.87803441, grad/param norm = 1.5871e-01, time/batch = 17.6965s	
16966/33150 (epoch 25.590), train_loss = 0.99084588, grad/param norm = 1.6325e-01, time/batch = 16.4681s	
16967/33150 (epoch 25.591), train_loss = 0.93198332, grad/param norm = 1.5442e-01, time/batch = 16.5727s	
16968/33150 (epoch 25.593), train_loss = 0.99863312, grad/param norm = 1.6237e-01, time/batch = 15.4881s	
16969/33150 (epoch 25.594), train_loss = 0.95677045, grad/param norm = 1.7141e-01, time/batch = 17.4787s	
16970/33150 (epoch 25.596), train_loss = 0.93992394, grad/param norm = 1.6551e-01, time/batch = 17.7111s	
16971/33150 (epoch 25.597), train_loss = 0.83538220, grad/param norm = 2.2095e-01, time/batch = 18.0676s	
16972/33150 (epoch 25.599), train_loss = 1.10316452, grad/param norm = 1.8714e-01, time/batch = 18.2369s	
16973/33150 (epoch 25.600), train_loss = 0.98164619, grad/param norm = 2.3596e-01, time/batch = 16.3757s	
16974/33150 (epoch 25.602), train_loss = 0.95528226, grad/param norm = 1.6435e-01, time/batch = 18.3976s	
16975/33150 (epoch 25.603), train_loss = 1.04176189, grad/param norm = 1.7061e-01, time/batch = 17.0662s	
16976/33150 (epoch 25.605), train_loss = 0.86509615, grad/param norm = 1.4940e-01, time/batch = 16.9010s	
16977/33150 (epoch 25.606), train_loss = 0.91339372, grad/param norm = 1.8722e-01, time/batch = 15.9022s	
16978/33150 (epoch 25.608), train_loss = 1.01822797, grad/param norm = 1.4770e-01, time/batch = 18.3014s	
16979/33150 (epoch 25.609), train_loss = 0.93099988, grad/param norm = 1.9503e-01, time/batch = 17.3142s	
16980/33150 (epoch 25.611), train_loss = 0.86126381, grad/param norm = 1.6618e-01, time/batch = 17.3233s	
16981/33150 (epoch 25.612), train_loss = 0.96390689, grad/param norm = 1.7210e-01, time/batch = 18.5571s	
16982/33150 (epoch 25.614), train_loss = 0.87113154, grad/param norm = 1.4547e-01, time/batch = 17.9870s	
16983/33150 (epoch 25.615), train_loss = 0.83994387, grad/param norm = 1.4397e-01, time/batch = 16.2231s	
16984/33150 (epoch 25.617), train_loss = 0.99101920, grad/param norm = 1.9441e-01, time/batch = 15.1645s	
16985/33150 (epoch 25.618), train_loss = 1.00168172, grad/param norm = 1.7340e-01, time/batch = 16.1768s	
16986/33150 (epoch 25.620), train_loss = 0.88437919, grad/param norm = 1.4782e-01, time/batch = 16.0561s	
16987/33150 (epoch 25.621), train_loss = 0.94881816, grad/param norm = 1.6572e-01, time/batch = 16.1442s	
16988/33150 (epoch 25.623), train_loss = 1.02431035, grad/param norm = 1.5971e-01, time/batch = 16.5791s	
16989/33150 (epoch 25.624), train_loss = 0.89153309, grad/param norm = 1.5511e-01, time/batch = 18.3212s	
16990/33150 (epoch 25.626), train_loss = 0.92350715, grad/param norm = 1.5731e-01, time/batch = 18.5614s	
16991/33150 (epoch 25.627), train_loss = 0.84033160, grad/param norm = 1.5490e-01, time/batch = 16.3936s	
16992/33150 (epoch 25.629), train_loss = 0.81640359, grad/param norm = 1.4892e-01, time/batch = 16.9043s	
16993/33150 (epoch 25.630), train_loss = 0.90305415, grad/param norm = 1.4412e-01, time/batch = 18.9803s	
16994/33150 (epoch 25.632), train_loss = 0.81454695, grad/param norm = 1.3423e-01, time/batch = 16.2241s	
16995/33150 (epoch 25.633), train_loss = 0.83091452, grad/param norm = 2.0338e-01, time/batch = 18.8044s	
16996/33150 (epoch 25.635), train_loss = 1.12192566, grad/param norm = 1.8280e-01, time/batch = 17.3827s	
16997/33150 (epoch 25.637), train_loss = 0.81611808, grad/param norm = 1.6668e-01, time/batch = 17.5426s	
16998/33150 (epoch 25.638), train_loss = 0.91625243, grad/param norm = 1.5399e-01, time/batch = 17.3738s	
16999/33150 (epoch 25.640), train_loss = 1.00378009, grad/param norm = 1.7542e-01, time/batch = 18.8713s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch25.64_1.6793.t7	
17000/33150 (epoch 25.641), train_loss = 0.84032592, grad/param norm = 1.8149e-01, time/batch = 17.8875s	
17001/33150 (epoch 25.643), train_loss = 1.21235633, grad/param norm = 1.9699e-01, time/batch = 16.8512s	
17002/33150 (epoch 25.644), train_loss = 1.09723839, grad/param norm = 1.6709e-01, time/batch = 15.5071s	
17003/33150 (epoch 25.646), train_loss = 0.91165756, grad/param norm = 1.5383e-01, time/batch = 17.4468s	
17004/33150 (epoch 25.647), train_loss = 1.16576928, grad/param norm = 1.8025e-01, time/batch = 16.5372s	
17005/33150 (epoch 25.649), train_loss = 1.03427036, grad/param norm = 1.7649e-01, time/batch = 18.7794s	
17006/33150 (epoch 25.650), train_loss = 0.84141007, grad/param norm = 1.4532e-01, time/batch = 16.6970s	
17007/33150 (epoch 25.652), train_loss = 1.06623210, grad/param norm = 1.8267e-01, time/batch = 15.8074s	
17008/33150 (epoch 25.653), train_loss = 0.98535392, grad/param norm = 1.5342e-01, time/batch = 17.3864s	
17009/33150 (epoch 25.655), train_loss = 0.98976933, grad/param norm = 1.8248e-01, time/batch = 17.3794s	
17010/33150 (epoch 25.656), train_loss = 0.90070151, grad/param norm = 1.4471e-01, time/batch = 17.0322s	
17011/33150 (epoch 25.658), train_loss = 0.93812847, grad/param norm = 1.7530e-01, time/batch = 19.3695s	
17012/33150 (epoch 25.659), train_loss = 1.23403384, grad/param norm = 2.3671e-01, time/batch = 17.5501s	
17013/33150 (epoch 25.661), train_loss = 0.94852718, grad/param norm = 1.7849e-01, time/batch = 17.1377s	
17014/33150 (epoch 25.662), train_loss = 0.89390079, grad/param norm = 1.8077e-01, time/batch = 18.1186s	
17015/33150 (epoch 25.664), train_loss = 1.08681635, grad/param norm = 1.7793e-01, time/batch = 16.7221s	
17016/33150 (epoch 25.665), train_loss = 1.02594914, grad/param norm = 1.6469e-01, time/batch = 17.1349s	
17017/33150 (epoch 25.667), train_loss = 1.07993675, grad/param norm = 1.8674e-01, time/batch = 17.4037s	
17018/33150 (epoch 25.668), train_loss = 1.07290746, grad/param norm = 1.7018e-01, time/batch = 18.0773s	
17019/33150 (epoch 25.670), train_loss = 0.90147694, grad/param norm = 1.4767e-01, time/batch = 17.8156s	
17020/33150 (epoch 25.671), train_loss = 0.92326697, grad/param norm = 1.6530e-01, time/batch = 16.1350s	
17021/33150 (epoch 25.673), train_loss = 1.07276271, grad/param norm = 1.5184e-01, time/batch = 15.3157s	
17022/33150 (epoch 25.674), train_loss = 0.98861081, grad/param norm = 1.9186e-01, time/batch = 17.9690s	
17023/33150 (epoch 25.676), train_loss = 0.93752569, grad/param norm = 1.5494e-01, time/batch = 16.9519s	
17024/33150 (epoch 25.677), train_loss = 1.12458659, grad/param norm = 1.7708e-01, time/batch = 16.3877s	
17025/33150 (epoch 25.679), train_loss = 0.95392310, grad/param norm = 1.5243e-01, time/batch = 17.4740s	
17026/33150 (epoch 25.680), train_loss = 1.07196282, grad/param norm = 1.8135e-01, time/batch = 19.1313s	
17027/33150 (epoch 25.682), train_loss = 0.92775967, grad/param norm = 1.4393e-01, time/batch = 15.6129s	
17028/33150 (epoch 25.683), train_loss = 0.82127523, grad/param norm = 1.4112e-01, time/batch = 17.0631s	
17029/33150 (epoch 25.685), train_loss = 0.92617623, grad/param norm = 1.6627e-01, time/batch = 16.7449s	
17030/33150 (epoch 25.686), train_loss = 0.81597205, grad/param norm = 1.4323e-01, time/batch = 16.8881s	
17031/33150 (epoch 25.688), train_loss = 0.85462102, grad/param norm = 1.5183e-01, time/batch = 18.4747s	
17032/33150 (epoch 25.689), train_loss = 0.86207292, grad/param norm = 1.3785e-01, time/batch = 17.0643s	
17033/33150 (epoch 25.691), train_loss = 0.76202144, grad/param norm = 1.4284e-01, time/batch = 17.7323s	
17034/33150 (epoch 25.692), train_loss = 0.85729105, grad/param norm = 1.5376e-01, time/batch = 16.5589s	
17035/33150 (epoch 25.694), train_loss = 0.74846172, grad/param norm = 1.3980e-01, time/batch = 18.7859s	
17036/33150 (epoch 25.695), train_loss = 0.89113456, grad/param norm = 1.4068e-01, time/batch = 17.3082s	
17037/33150 (epoch 25.697), train_loss = 0.80794255, grad/param norm = 1.3338e-01, time/batch = 16.3120s	
17038/33150 (epoch 25.698), train_loss = 0.85374159, grad/param norm = 1.6145e-01, time/batch = 16.0494s	
17039/33150 (epoch 25.700), train_loss = 0.71077575, grad/param norm = 1.2603e-01, time/batch = 17.4632s	
17040/33150 (epoch 25.701), train_loss = 0.82397291, grad/param norm = 1.3515e-01, time/batch = 17.1475s	
17041/33150 (epoch 25.703), train_loss = 0.93412508, grad/param norm = 1.7723e-01, time/batch = 15.3975s	
17042/33150 (epoch 25.704), train_loss = 0.80350155, grad/param norm = 1.4085e-01, time/batch = 16.9164s	
17043/33150 (epoch 25.706), train_loss = 0.89777839, grad/param norm = 1.5544e-01, time/batch = 18.4764s	
17044/33150 (epoch 25.707), train_loss = 0.88454376, grad/param norm = 1.5665e-01, time/batch = 16.4792s	
17045/33150 (epoch 25.709), train_loss = 0.92033250, grad/param norm = 1.3341e-01, time/batch = 17.7299s	
17046/33150 (epoch 25.710), train_loss = 0.91352998, grad/param norm = 1.6537e-01, time/batch = 17.9852s	
17047/33150 (epoch 25.712), train_loss = 0.98248356, grad/param norm = 1.5145e-01, time/batch = 18.7101s	
17048/33150 (epoch 25.713), train_loss = 0.97294751, grad/param norm = 1.4119e-01, time/batch = 16.4718s	
17049/33150 (epoch 25.715), train_loss = 0.89630100, grad/param norm = 1.5381e-01, time/batch = 18.5612s	
17050/33150 (epoch 25.716), train_loss = 0.97889128, grad/param norm = 1.6106e-01, time/batch = 18.6480s	
17051/33150 (epoch 25.718), train_loss = 0.96530572, grad/param norm = 1.5332e-01, time/batch = 17.6268s	
17052/33150 (epoch 25.719), train_loss = 1.02625456, grad/param norm = 1.7940e-01, time/batch = 19.6415s	
17053/33150 (epoch 25.721), train_loss = 0.90734288, grad/param norm = 1.7579e-01, time/batch = 19.9637s	
17054/33150 (epoch 25.722), train_loss = 0.94774554, grad/param norm = 1.4256e-01, time/batch = 15.8524s	
17055/33150 (epoch 25.724), train_loss = 0.91283527, grad/param norm = 1.4215e-01, time/batch = 16.9058s	
17056/33150 (epoch 25.725), train_loss = 1.05051314, grad/param norm = 2.0189e-01, time/batch = 18.7382s	
17057/33150 (epoch 25.727), train_loss = 0.99600662, grad/param norm = 1.8640e-01, time/batch = 18.0475s	
17058/33150 (epoch 25.729), train_loss = 0.93028273, grad/param norm = 1.5266e-01, time/batch = 18.4650s	
17059/33150 (epoch 25.730), train_loss = 0.95567411, grad/param norm = 1.7871e-01, time/batch = 18.7305s	
17060/33150 (epoch 25.732), train_loss = 1.01973748, grad/param norm = 1.6414e-01, time/batch = 19.5473s	
17061/33150 (epoch 25.733), train_loss = 0.77675395, grad/param norm = 1.2432e-01, time/batch = 16.8075s	
17062/33150 (epoch 25.735), train_loss = 0.84749870, grad/param norm = 1.4372e-01, time/batch = 17.8121s	
17063/33150 (epoch 25.736), train_loss = 0.91852839, grad/param norm = 1.5375e-01, time/batch = 19.4706s	
17064/33150 (epoch 25.738), train_loss = 0.94405505, grad/param norm = 1.7366e-01, time/batch = 15.8854s	
17065/33150 (epoch 25.739), train_loss = 1.03289372, grad/param norm = 1.9921e-01, time/batch = 18.7225s	
17066/33150 (epoch 25.741), train_loss = 1.01690210, grad/param norm = 1.6381e-01, time/batch = 18.1495s	
17067/33150 (epoch 25.742), train_loss = 0.82488001, grad/param norm = 1.8262e-01, time/batch = 16.8102s	
17068/33150 (epoch 25.744), train_loss = 1.04082102, grad/param norm = 1.7614e-01, time/batch = 17.4017s	
17069/33150 (epoch 25.745), train_loss = 0.89960063, grad/param norm = 1.4082e-01, time/batch = 18.5654s	
17070/33150 (epoch 25.747), train_loss = 0.72392060, grad/param norm = 1.4335e-01, time/batch = 17.8110s	
17071/33150 (epoch 25.748), train_loss = 0.84498239, grad/param norm = 1.4277e-01, time/batch = 16.2210s	
17072/33150 (epoch 25.750), train_loss = 0.97624081, grad/param norm = 1.6201e-01, time/batch = 16.2223s	
17073/33150 (epoch 25.751), train_loss = 0.95187025, grad/param norm = 1.5553e-01, time/batch = 18.0572s	
17074/33150 (epoch 25.753), train_loss = 0.79270069, grad/param norm = 1.7817e-01, time/batch = 16.5490s	
17075/33150 (epoch 25.754), train_loss = 1.13487233, grad/param norm = 2.0036e-01, time/batch = 18.2190s	
17076/33150 (epoch 25.756), train_loss = 0.96142009, grad/param norm = 2.1054e-01, time/batch = 16.9114s	
17077/33150 (epoch 25.757), train_loss = 0.96263574, grad/param norm = 1.6623e-01, time/batch = 18.3791s	
17078/33150 (epoch 25.759), train_loss = 1.08002915, grad/param norm = 2.0475e-01, time/batch = 15.2206s	
17079/33150 (epoch 25.760), train_loss = 0.99675529, grad/param norm = 1.5978e-01, time/batch = 17.7361s	
17080/33150 (epoch 25.762), train_loss = 0.96652850, grad/param norm = 1.6769e-01, time/batch = 18.7198s	
17081/33150 (epoch 25.763), train_loss = 0.98976143, grad/param norm = 1.6213e-01, time/batch = 16.8946s	
17082/33150 (epoch 25.765), train_loss = 0.92669342, grad/param norm = 1.4520e-01, time/batch = 16.9650s	
17083/33150 (epoch 25.766), train_loss = 0.86418185, grad/param norm = 1.5331e-01, time/batch = 18.2324s	
17084/33150 (epoch 25.768), train_loss = 0.88063588, grad/param norm = 1.5277e-01, time/batch = 17.7292s	
17085/33150 (epoch 25.769), train_loss = 0.97349082, grad/param norm = 1.7017e-01, time/batch = 15.9003s	
17086/33150 (epoch 25.771), train_loss = 0.96435849, grad/param norm = 1.7241e-01, time/batch = 20.1256s	
17087/33150 (epoch 25.772), train_loss = 1.02953585, grad/param norm = 1.7582e-01, time/batch = 18.3184s	
17088/33150 (epoch 25.774), train_loss = 1.10499489, grad/param norm = 1.6557e-01, time/batch = 16.2188s	
17089/33150 (epoch 25.775), train_loss = 1.00872921, grad/param norm = 1.9038e-01, time/batch = 17.7274s	
17090/33150 (epoch 25.777), train_loss = 1.01658140, grad/param norm = 1.6754e-01, time/batch = 18.4727s	
17091/33150 (epoch 25.778), train_loss = 0.95572766, grad/param norm = 1.5094e-01, time/batch = 16.3951s	
17092/33150 (epoch 25.780), train_loss = 0.81822698, grad/param norm = 1.4340e-01, time/batch = 17.9021s	
17093/33150 (epoch 25.781), train_loss = 0.93789076, grad/param norm = 1.5094e-01, time/batch = 18.8101s	
17094/33150 (epoch 25.783), train_loss = 0.94804152, grad/param norm = 1.5884e-01, time/batch = 18.1264s	
17095/33150 (epoch 25.784), train_loss = 0.94076968, grad/param norm = 1.7549e-01, time/batch = 15.9860s	
17096/33150 (epoch 25.786), train_loss = 0.92800323, grad/param norm = 1.4817e-01, time/batch = 17.8238s	
17097/33150 (epoch 25.787), train_loss = 0.87571840, grad/param norm = 1.3237e-01, time/batch = 15.7159s	
17098/33150 (epoch 25.789), train_loss = 0.77826815, grad/param norm = 1.5069e-01, time/batch = 15.9684s	
17099/33150 (epoch 25.790), train_loss = 0.83462288, grad/param norm = 1.3332e-01, time/batch = 16.3235s	
17100/33150 (epoch 25.792), train_loss = 0.96277988, grad/param norm = 1.6974e-01, time/batch = 16.4878s	
17101/33150 (epoch 25.793), train_loss = 0.91447304, grad/param norm = 1.7150e-01, time/batch = 18.7112s	
17102/33150 (epoch 25.795), train_loss = 0.91256501, grad/param norm = 1.7686e-01, time/batch = 15.9000s	
17103/33150 (epoch 25.796), train_loss = 0.89958202, grad/param norm = 1.5837e-01, time/batch = 16.5760s	
17104/33150 (epoch 25.798), train_loss = 0.88474068, grad/param norm = 1.3116e-01, time/batch = 17.4148s	
17105/33150 (epoch 25.799), train_loss = 0.77593074, grad/param norm = 1.5501e-01, time/batch = 17.3198s	
17106/33150 (epoch 25.801), train_loss = 0.95787305, grad/param norm = 1.6323e-01, time/batch = 18.3895s	
17107/33150 (epoch 25.802), train_loss = 0.86035975, grad/param norm = 1.6291e-01, time/batch = 17.2271s	
17108/33150 (epoch 25.804), train_loss = 0.91176136, grad/param norm = 1.4986e-01, time/batch = 18.2223s	
17109/33150 (epoch 25.805), train_loss = 0.87592162, grad/param norm = 1.7813e-01, time/batch = 16.8895s	
17110/33150 (epoch 25.807), train_loss = 0.89936933, grad/param norm = 1.5007e-01, time/batch = 18.5657s	
17111/33150 (epoch 25.808), train_loss = 1.03550382, grad/param norm = 1.5961e-01, time/batch = 19.3206s	
17112/33150 (epoch 25.810), train_loss = 0.87829962, grad/param norm = 1.5670e-01, time/batch = 17.3055s	
17113/33150 (epoch 25.811), train_loss = 0.97937961, grad/param norm = 1.7605e-01, time/batch = 17.9519s	
17114/33150 (epoch 25.813), train_loss = 0.89596600, grad/param norm = 1.3188e-01, time/batch = 16.2356s	
17115/33150 (epoch 25.814), train_loss = 0.88965595, grad/param norm = 1.7031e-01, time/batch = 16.9009s	
17116/33150 (epoch 25.816), train_loss = 0.91708367, grad/param norm = 2.0239e-01, time/batch = 16.9795s	
17117/33150 (epoch 25.817), train_loss = 0.98255031, grad/param norm = 1.5615e-01, time/batch = 18.6404s	
17118/33150 (epoch 25.819), train_loss = 0.95542624, grad/param norm = 1.6878e-01, time/batch = 18.6516s	
17119/33150 (epoch 25.821), train_loss = 0.82897642, grad/param norm = 1.4573e-01, time/batch = 16.6398s	
17120/33150 (epoch 25.822), train_loss = 0.87841561, grad/param norm = 1.4682e-01, time/batch = 18.2056s	
17121/33150 (epoch 25.824), train_loss = 0.92817317, grad/param norm = 1.5776e-01, time/batch = 18.1462s	
17122/33150 (epoch 25.825), train_loss = 0.95996632, grad/param norm = 1.7583e-01, time/batch = 16.3963s	
17123/33150 (epoch 25.827), train_loss = 1.00953850, grad/param norm = 1.8086e-01, time/batch = 15.5642s	
17124/33150 (epoch 25.828), train_loss = 0.84364548, grad/param norm = 1.7524e-01, time/batch = 18.6377s	
17125/33150 (epoch 25.830), train_loss = 1.02426366, grad/param norm = 1.7751e-01, time/batch = 16.4650s	
17126/33150 (epoch 25.831), train_loss = 0.88047817, grad/param norm = 1.5980e-01, time/batch = 15.8929s	
17127/33150 (epoch 25.833), train_loss = 0.86979677, grad/param norm = 1.5697e-01, time/batch = 19.0555s	
17128/33150 (epoch 25.834), train_loss = 1.02755890, grad/param norm = 1.6070e-01, time/batch = 16.5522s	
17129/33150 (epoch 25.836), train_loss = 1.04588739, grad/param norm = 1.4895e-01, time/batch = 16.1186s	
17130/33150 (epoch 25.837), train_loss = 0.90458753, grad/param norm = 1.6319e-01, time/batch = 17.5582s	
17131/33150 (epoch 25.839), train_loss = 0.99588641, grad/param norm = 1.7074e-01, time/batch = 14.9838s	
17132/33150 (epoch 25.840), train_loss = 1.00540093, grad/param norm = 1.6515e-01, time/batch = 18.8811s	
17133/33150 (epoch 25.842), train_loss = 1.07909772, grad/param norm = 1.8532e-01, time/batch = 17.3126s	
17134/33150 (epoch 25.843), train_loss = 1.04362658, grad/param norm = 1.6631e-01, time/batch = 16.2327s	
17135/33150 (epoch 25.845), train_loss = 0.86762558, grad/param norm = 1.4312e-01, time/batch = 18.3249s	
17136/33150 (epoch 25.846), train_loss = 1.10040430, grad/param norm = 1.9751e-01, time/batch = 16.1623s	
17137/33150 (epoch 25.848), train_loss = 1.03292318, grad/param norm = 1.7104e-01, time/batch = 18.4890s	
17138/33150 (epoch 25.849), train_loss = 1.05884252, grad/param norm = 1.7013e-01, time/batch = 17.5670s	
17139/33150 (epoch 25.851), train_loss = 1.01118116, grad/param norm = 1.7653e-01, time/batch = 18.2259s	
17140/33150 (epoch 25.852), train_loss = 1.09896261, grad/param norm = 1.6260e-01, time/batch = 16.3555s	
17141/33150 (epoch 25.854), train_loss = 0.97140883, grad/param norm = 1.6114e-01, time/batch = 17.5292s	
17142/33150 (epoch 25.855), train_loss = 0.82081746, grad/param norm = 1.4910e-01, time/batch = 17.9833s	
17143/33150 (epoch 25.857), train_loss = 0.80104152, grad/param norm = 1.4602e-01, time/batch = 17.7844s	
17144/33150 (epoch 25.858), train_loss = 0.89724230, grad/param norm = 1.4813e-01, time/batch = 19.9622s	
17145/33150 (epoch 25.860), train_loss = 0.84355508, grad/param norm = 1.4051e-01, time/batch = 17.4872s	
17146/33150 (epoch 25.861), train_loss = 0.83597507, grad/param norm = 1.5074e-01, time/batch = 17.6272s	
17147/33150 (epoch 25.863), train_loss = 0.93997742, grad/param norm = 1.4891e-01, time/batch = 15.4442s	
17148/33150 (epoch 25.864), train_loss = 0.99828742, grad/param norm = 1.6695e-01, time/batch = 15.5340s	
17149/33150 (epoch 25.866), train_loss = 1.00115343, grad/param norm = 1.5593e-01, time/batch = 15.4350s	
17150/33150 (epoch 25.867), train_loss = 0.99583527, grad/param norm = 1.6020e-01, time/batch = 15.4858s	
17151/33150 (epoch 25.869), train_loss = 0.99068667, grad/param norm = 1.6926e-01, time/batch = 15.5055s	
17152/33150 (epoch 25.870), train_loss = 0.90057010, grad/param norm = 1.5820e-01, time/batch = 16.0035s	
17153/33150 (epoch 25.872), train_loss = 0.96327965, grad/param norm = 1.6022e-01, time/batch = 16.8043s	
17154/33150 (epoch 25.873), train_loss = 0.80067702, grad/param norm = 1.4227e-01, time/batch = 15.5478s	
17155/33150 (epoch 25.875), train_loss = 1.05398024, grad/param norm = 1.6295e-01, time/batch = 16.3777s	
17156/33150 (epoch 25.876), train_loss = 0.82525212, grad/param norm = 1.5902e-01, time/batch = 17.4605s	
17157/33150 (epoch 25.878), train_loss = 0.86119785, grad/param norm = 1.4052e-01, time/batch = 16.8063s	
17158/33150 (epoch 25.879), train_loss = 0.87164905, grad/param norm = 1.4130e-01, time/batch = 16.0694s	
17159/33150 (epoch 25.881), train_loss = 0.86347542, grad/param norm = 1.4831e-01, time/batch = 18.0635s	
17160/33150 (epoch 25.882), train_loss = 0.76538286, grad/param norm = 1.4287e-01, time/batch = 16.3285s	
17161/33150 (epoch 25.884), train_loss = 0.92091137, grad/param norm = 1.4465e-01, time/batch = 15.1368s	
17162/33150 (epoch 25.885), train_loss = 0.73517696, grad/param norm = 1.6413e-01, time/batch = 16.8068s	
17163/33150 (epoch 25.887), train_loss = 1.03135943, grad/param norm = 1.8349e-01, time/batch = 17.4817s	
17164/33150 (epoch 25.888), train_loss = 0.97593879, grad/param norm = 1.5750e-01, time/batch = 16.2871s	
17165/33150 (epoch 25.890), train_loss = 0.86823252, grad/param norm = 1.5817e-01, time/batch = 16.4897s	
17166/33150 (epoch 25.891), train_loss = 0.85029202, grad/param norm = 1.5665e-01, time/batch = 16.7486s	
17167/33150 (epoch 25.893), train_loss = 0.99613294, grad/param norm = 1.9628e-01, time/batch = 15.7657s	
17168/33150 (epoch 25.894), train_loss = 0.98639625, grad/param norm = 1.6886e-01, time/batch = 17.7220s	
17169/33150 (epoch 25.896), train_loss = 0.92325395, grad/param norm = 1.5359e-01, time/batch = 16.1552s	
17170/33150 (epoch 25.897), train_loss = 0.96338883, grad/param norm = 1.4879e-01, time/batch = 15.9861s	
17171/33150 (epoch 25.899), train_loss = 0.78625833, grad/param norm = 1.6995e-01, time/batch = 18.8764s	
17172/33150 (epoch 25.900), train_loss = 1.12859825, grad/param norm = 1.8265e-01, time/batch = 18.6425s	
17173/33150 (epoch 25.902), train_loss = 1.13097289, grad/param norm = 1.7391e-01, time/batch = 17.2841s	
17174/33150 (epoch 25.903), train_loss = 0.94824198, grad/param norm = 1.6731e-01, time/batch = 17.0652s	
17175/33150 (epoch 25.905), train_loss = 0.95010030, grad/param norm = 1.4215e-01, time/batch = 16.6346s	
17176/33150 (epoch 25.906), train_loss = 0.96665166, grad/param norm = 1.8047e-01, time/batch = 16.9782s	
17177/33150 (epoch 25.908), train_loss = 1.07845791, grad/param norm = 1.7275e-01, time/batch = 18.8600s	
17178/33150 (epoch 25.910), train_loss = 1.01962719, grad/param norm = 1.8105e-01, time/batch = 17.5333s	
17179/33150 (epoch 25.911), train_loss = 0.81089125, grad/param norm = 1.4314e-01, time/batch = 18.2105s	
17180/33150 (epoch 25.913), train_loss = 0.86125975, grad/param norm = 1.7865e-01, time/batch = 20.1312s	
17181/33150 (epoch 25.914), train_loss = 1.02122770, grad/param norm = 1.7720e-01, time/batch = 18.7081s	
17182/33150 (epoch 25.916), train_loss = 0.86547329, grad/param norm = 1.6720e-01, time/batch = 16.3870s	
17183/33150 (epoch 25.917), train_loss = 0.99990509, grad/param norm = 1.8651e-01, time/batch = 17.8814s	
17184/33150 (epoch 25.919), train_loss = 1.08865282, grad/param norm = 2.0660e-01, time/batch = 17.6377s	
17185/33150 (epoch 25.920), train_loss = 1.06039985, grad/param norm = 1.6915e-01, time/batch = 17.5465s	
17186/33150 (epoch 25.922), train_loss = 1.07685526, grad/param norm = 1.7137e-01, time/batch = 18.2277s	
17187/33150 (epoch 25.923), train_loss = 0.95778626, grad/param norm = 1.7115e-01, time/batch = 17.1320s	
17188/33150 (epoch 25.925), train_loss = 1.03768494, grad/param norm = 1.6595e-01, time/batch = 16.9847s	
17189/33150 (epoch 25.926), train_loss = 0.92821238, grad/param norm = 1.5523e-01, time/batch = 17.6482s	
17190/33150 (epoch 25.928), train_loss = 0.89926638, grad/param norm = 1.5265e-01, time/batch = 17.3989s	
17191/33150 (epoch 25.929), train_loss = 1.00542032, grad/param norm = 1.5407e-01, time/batch = 17.3882s	
17192/33150 (epoch 25.931), train_loss = 1.06248535, grad/param norm = 1.8740e-01, time/batch = 16.7096s	
17193/33150 (epoch 25.932), train_loss = 0.94897030, grad/param norm = 1.6688e-01, time/batch = 19.1398s	
17194/33150 (epoch 25.934), train_loss = 0.98291035, grad/param norm = 1.5411e-01, time/batch = 17.2062s	
17195/33150 (epoch 25.935), train_loss = 1.05454306, grad/param norm = 1.6566e-01, time/batch = 17.1093s	
17196/33150 (epoch 25.937), train_loss = 1.06966508, grad/param norm = 1.4918e-01, time/batch = 16.8998s	
17197/33150 (epoch 25.938), train_loss = 0.99874480, grad/param norm = 1.5657e-01, time/batch = 19.8564s	
17198/33150 (epoch 25.940), train_loss = 1.21093645, grad/param norm = 2.1580e-01, time/batch = 20.4042s	
17199/33150 (epoch 25.941), train_loss = 0.95378376, grad/param norm = 1.3993e-01, time/batch = 25.4811s	
17200/33150 (epoch 25.943), train_loss = 0.80629685, grad/param norm = 1.7115e-01, time/batch = 16.7293s	
17201/33150 (epoch 25.944), train_loss = 1.03462953, grad/param norm = 1.7359e-01, time/batch = 15.5256s	
17202/33150 (epoch 25.946), train_loss = 0.81016402, grad/param norm = 1.4770e-01, time/batch = 15.7944s	
17203/33150 (epoch 25.947), train_loss = 0.98462998, grad/param norm = 1.4775e-01, time/batch = 18.8773s	
17204/33150 (epoch 25.949), train_loss = 1.06312982, grad/param norm = 1.6997e-01, time/batch = 16.5668s	
17205/33150 (epoch 25.950), train_loss = 0.99469214, grad/param norm = 2.1899e-01, time/batch = 15.3016s	
17206/33150 (epoch 25.952), train_loss = 0.87437352, grad/param norm = 1.5184e-01, time/batch = 17.4858s	
17207/33150 (epoch 25.953), train_loss = 0.90372888, grad/param norm = 1.4832e-01, time/batch = 18.7398s	
17208/33150 (epoch 25.955), train_loss = 0.82210540, grad/param norm = 1.4753e-01, time/batch = 16.3811s	
17209/33150 (epoch 25.956), train_loss = 1.03143007, grad/param norm = 1.7719e-01, time/batch = 17.1568s	
17210/33150 (epoch 25.958), train_loss = 0.85439244, grad/param norm = 1.4637e-01, time/batch = 18.7174s	
17211/33150 (epoch 25.959), train_loss = 0.89791174, grad/param norm = 1.5930e-01, time/batch = 18.4428s	
17212/33150 (epoch 25.961), train_loss = 0.87079942, grad/param norm = 1.5383e-01, time/batch = 16.8942s	
17213/33150 (epoch 25.962), train_loss = 0.81841409, grad/param norm = 1.4560e-01, time/batch = 17.8996s	
17214/33150 (epoch 25.964), train_loss = 0.94302545, grad/param norm = 1.4972e-01, time/batch = 19.0577s	
17215/33150 (epoch 25.965), train_loss = 0.93228422, grad/param norm = 1.5206e-01, time/batch = 15.9762s	
17216/33150 (epoch 25.967), train_loss = 0.94322078, grad/param norm = 2.0564e-01, time/batch = 15.4725s	
17217/33150 (epoch 25.968), train_loss = 0.78286666, grad/param norm = 1.3239e-01, time/batch = 18.2280s	
17218/33150 (epoch 25.970), train_loss = 0.89317454, grad/param norm = 1.4871e-01, time/batch = 18.3770s	
17219/33150 (epoch 25.971), train_loss = 0.93372107, grad/param norm = 1.5197e-01, time/batch = 16.2993s	
17220/33150 (epoch 25.973), train_loss = 1.06231670, grad/param norm = 1.8595e-01, time/batch = 17.8276s	
17221/33150 (epoch 25.974), train_loss = 1.08353711, grad/param norm = 1.7098e-01, time/batch = 17.7979s	
17222/33150 (epoch 25.976), train_loss = 1.03131172, grad/param norm = 1.4967e-01, time/batch = 16.8098s	
17223/33150 (epoch 25.977), train_loss = 1.09034281, grad/param norm = 1.6172e-01, time/batch = 18.2277s	
17224/33150 (epoch 25.979), train_loss = 1.03470773, grad/param norm = 1.7354e-01, time/batch = 19.1387s	
17225/33150 (epoch 25.980), train_loss = 1.09558935, grad/param norm = 1.9373e-01, time/batch = 18.0561s	
17226/33150 (epoch 25.982), train_loss = 0.94729604, grad/param norm = 1.7908e-01, time/batch = 15.4883s	
17227/33150 (epoch 25.983), train_loss = 0.84604677, grad/param norm = 1.5740e-01, time/batch = 17.2208s	
17228/33150 (epoch 25.985), train_loss = 1.02953729, grad/param norm = 1.4589e-01, time/batch = 15.7280s	
17229/33150 (epoch 25.986), train_loss = 0.80411121, grad/param norm = 1.5388e-01, time/batch = 15.7363s	
17230/33150 (epoch 25.988), train_loss = 0.92444914, grad/param norm = 1.7535e-01, time/batch = 17.5598s	
17231/33150 (epoch 25.989), train_loss = 0.89108758, grad/param norm = 1.4917e-01, time/batch = 17.4848s	
17232/33150 (epoch 25.991), train_loss = 1.00972974, grad/param norm = 1.8743e-01, time/batch = 18.1338s	
17233/33150 (epoch 25.992), train_loss = 0.89471207, grad/param norm = 1.5212e-01, time/batch = 17.3024s	
17234/33150 (epoch 25.994), train_loss = 0.96014021, grad/param norm = 1.6749e-01, time/batch = 16.9141s	
17235/33150 (epoch 25.995), train_loss = 0.92005847, grad/param norm = 1.7224e-01, time/batch = 17.3966s	
17236/33150 (epoch 25.997), train_loss = 0.95328448, grad/param norm = 1.7178e-01, time/batch = 16.4703s	
17237/33150 (epoch 25.998), train_loss = 0.78075891, grad/param norm = 1.3709e-01, time/batch = 16.7446s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
17238/33150 (epoch 26.000), train_loss = 0.79812612, grad/param norm = 1.7526e-01, time/batch = 18.7427s	
17239/33150 (epoch 26.002), train_loss = 1.25439176, grad/param norm = 1.9675e-01, time/batch = 16.1463s	
17240/33150 (epoch 26.003), train_loss = 0.86216902, grad/param norm = 1.7483e-01, time/batch = 17.3105s	
17241/33150 (epoch 26.005), train_loss = 0.82895477, grad/param norm = 1.3700e-01, time/batch = 18.0777s	
17242/33150 (epoch 26.006), train_loss = 0.81796583, grad/param norm = 1.5571e-01, time/batch = 16.9743s	
17243/33150 (epoch 26.008), train_loss = 1.04920810, grad/param norm = 1.8720e-01, time/batch = 16.1264s	
17244/33150 (epoch 26.009), train_loss = 0.96730421, grad/param norm = 1.8171e-01, time/batch = 16.1596s	
17245/33150 (epoch 26.011), train_loss = 1.05241032, grad/param norm = 1.7049e-01, time/batch = 17.9072s	
17246/33150 (epoch 26.012), train_loss = 0.96082413, grad/param norm = 1.8769e-01, time/batch = 17.5616s	
17247/33150 (epoch 26.014), train_loss = 0.88453031, grad/param norm = 1.5737e-01, time/batch = 17.8045s	
17248/33150 (epoch 26.015), train_loss = 0.87930194, grad/param norm = 1.5823e-01, time/batch = 18.2241s	
17249/33150 (epoch 26.017), train_loss = 0.84894606, grad/param norm = 1.5175e-01, time/batch = 19.3140s	
17250/33150 (epoch 26.018), train_loss = 0.95516634, grad/param norm = 1.6249e-01, time/batch = 17.6254s	
17251/33150 (epoch 26.020), train_loss = 1.02980896, grad/param norm = 1.7100e-01, time/batch = 19.3072s	
17252/33150 (epoch 26.021), train_loss = 0.83933444, grad/param norm = 1.6358e-01, time/batch = 17.0649s	
17253/33150 (epoch 26.023), train_loss = 1.11950757, grad/param norm = 1.6577e-01, time/batch = 17.3973s	
17254/33150 (epoch 26.024), train_loss = 1.00188483, grad/param norm = 1.7648e-01, time/batch = 16.9737s	
17255/33150 (epoch 26.026), train_loss = 0.75759503, grad/param norm = 1.4037e-01, time/batch = 18.2985s	
17256/33150 (epoch 26.027), train_loss = 0.75972087, grad/param norm = 1.3300e-01, time/batch = 15.7910s	
17257/33150 (epoch 26.029), train_loss = 0.88378201, grad/param norm = 1.5255e-01, time/batch = 19.1299s	
17258/33150 (epoch 26.030), train_loss = 0.90976667, grad/param norm = 1.3945e-01, time/batch = 19.6394s	
17259/33150 (epoch 26.032), train_loss = 0.85487879, grad/param norm = 1.7937e-01, time/batch = 16.9709s	
17260/33150 (epoch 26.033), train_loss = 0.88063231, grad/param norm = 1.5751e-01, time/batch = 18.5455s	
17261/33150 (epoch 26.035), train_loss = 1.10158415, grad/param norm = 1.8721e-01, time/batch = 19.1328s	
17262/33150 (epoch 26.036), train_loss = 0.98620434, grad/param norm = 1.6326e-01, time/batch = 19.3143s	
17263/33150 (epoch 26.038), train_loss = 1.17162666, grad/param norm = 1.7923e-01, time/batch = 17.0563s	
17264/33150 (epoch 26.039), train_loss = 1.01447705, grad/param norm = 1.5349e-01, time/batch = 19.3203s	
17265/33150 (epoch 26.041), train_loss = 0.95370598, grad/param norm = 1.6253e-01, time/batch = 18.5533s	
17266/33150 (epoch 26.042), train_loss = 0.90513200, grad/param norm = 1.4806e-01, time/batch = 16.9798s	
17267/33150 (epoch 26.044), train_loss = 0.92106317, grad/param norm = 1.4526e-01, time/batch = 16.9086s	
17268/33150 (epoch 26.045), train_loss = 0.98898696, grad/param norm = 1.4343e-01, time/batch = 17.5684s	
17269/33150 (epoch 26.047), train_loss = 0.83632723, grad/param norm = 1.5604e-01, time/batch = 18.4665s	
17270/33150 (epoch 26.048), train_loss = 1.03249836, grad/param norm = 1.8267e-01, time/batch = 17.2776s	
17271/33150 (epoch 26.050), train_loss = 0.93126098, grad/param norm = 1.6331e-01, time/batch = 18.8270s	
17272/33150 (epoch 26.051), train_loss = 0.94244333, grad/param norm = 1.4558e-01, time/batch = 18.4826s	
17273/33150 (epoch 26.053), train_loss = 0.93486209, grad/param norm = 1.4845e-01, time/batch = 16.4621s	
17274/33150 (epoch 26.054), train_loss = 1.07469280, grad/param norm = 1.5013e-01, time/batch = 18.9787s	
17275/33150 (epoch 26.056), train_loss = 0.93256717, grad/param norm = 1.5350e-01, time/batch = 18.9780s	
17276/33150 (epoch 26.057), train_loss = 0.96156956, grad/param norm = 1.6382e-01, time/batch = 16.8037s	
17277/33150 (epoch 26.059), train_loss = 0.86598009, grad/param norm = 1.5178e-01, time/batch = 17.4006s	
17278/33150 (epoch 26.060), train_loss = 0.85543430, grad/param norm = 1.3926e-01, time/batch = 19.2162s	
17279/33150 (epoch 26.062), train_loss = 0.92507405, grad/param norm = 1.5937e-01, time/batch = 16.0510s	
17280/33150 (epoch 26.063), train_loss = 0.88834093, grad/param norm = 1.6955e-01, time/batch = 17.6442s	
17281/33150 (epoch 26.065), train_loss = 0.92425451, grad/param norm = 1.8182e-01, time/batch = 19.2999s	
17282/33150 (epoch 26.066), train_loss = 0.87601522, grad/param norm = 1.5278e-01, time/batch = 18.3145s	
17283/33150 (epoch 26.068), train_loss = 1.00436104, grad/param norm = 1.6244e-01, time/batch = 16.1140s	
17284/33150 (epoch 26.069), train_loss = 0.96608733, grad/param norm = 1.7171e-01, time/batch = 17.2297s	
17285/33150 (epoch 26.071), train_loss = 0.94003305, grad/param norm = 1.4541e-01, time/batch = 19.0633s	
17286/33150 (epoch 26.072), train_loss = 0.94963558, grad/param norm = 1.6802e-01, time/batch = 16.6425s	
17287/33150 (epoch 26.074), train_loss = 0.83218589, grad/param norm = 1.9691e-01, time/batch = 15.6981s	
17288/33150 (epoch 26.075), train_loss = 0.86674253, grad/param norm = 1.7601e-01, time/batch = 18.3096s	
17289/33150 (epoch 26.077), train_loss = 0.91760933, grad/param norm = 2.2533e-01, time/batch = 18.9716s	
17290/33150 (epoch 26.078), train_loss = 1.05992195, grad/param norm = 1.8869e-01, time/batch = 16.7851s	
17291/33150 (epoch 26.080), train_loss = 1.05166794, grad/param norm = 1.6206e-01, time/batch = 19.1466s	
17292/33150 (epoch 26.081), train_loss = 0.84671886, grad/param norm = 1.8533e-01, time/batch = 18.9727s	
17293/33150 (epoch 26.083), train_loss = 0.73190107, grad/param norm = 1.8147e-01, time/batch = 15.7225s	
17294/33150 (epoch 26.084), train_loss = 0.82358457, grad/param norm = 1.6709e-01, time/batch = 19.3853s	
17295/33150 (epoch 26.086), train_loss = 0.87608215, grad/param norm = 1.7415e-01, time/batch = 18.1542s	
17296/33150 (epoch 26.087), train_loss = 0.82274507, grad/param norm = 1.5632e-01, time/batch = 18.4772s	
17297/33150 (epoch 26.089), train_loss = 0.85651553, grad/param norm = 1.5969e-01, time/batch = 17.0547s	
17298/33150 (epoch 26.090), train_loss = 0.90044489, grad/param norm = 1.7422e-01, time/batch = 18.4615s	
17299/33150 (epoch 26.092), train_loss = 0.87387825, grad/param norm = 1.6793e-01, time/batch = 19.0399s	
17300/33150 (epoch 26.094), train_loss = 0.97267310, grad/param norm = 1.6351e-01, time/batch = 17.3894s	
17301/33150 (epoch 26.095), train_loss = 0.86063245, grad/param norm = 1.4078e-01, time/batch = 16.7934s	
17302/33150 (epoch 26.097), train_loss = 0.82942591, grad/param norm = 1.7805e-01, time/batch = 17.4631s	
17303/33150 (epoch 26.098), train_loss = 1.15887776, grad/param norm = 1.9456e-01, time/batch = 15.1604s	
17304/33150 (epoch 26.100), train_loss = 1.11822523, grad/param norm = 1.8356e-01, time/batch = 15.2651s	
17305/33150 (epoch 26.101), train_loss = 0.85669371, grad/param norm = 1.5362e-01, time/batch = 15.7886s	
17306/33150 (epoch 26.103), train_loss = 0.95232257, grad/param norm = 1.5532e-01, time/batch = 16.8500s	
17307/33150 (epoch 26.104), train_loss = 0.86843941, grad/param norm = 1.6372e-01, time/batch = 16.0249s	
17308/33150 (epoch 26.106), train_loss = 1.04494444, grad/param norm = 1.7213e-01, time/batch = 15.5692s	
17309/33150 (epoch 26.107), train_loss = 1.14698401, grad/param norm = 2.0687e-01, time/batch = 17.2834s	
17310/33150 (epoch 26.109), train_loss = 0.91972218, grad/param norm = 1.3600e-01, time/batch = 17.3012s	
17311/33150 (epoch 26.110), train_loss = 1.04598892, grad/param norm = 1.7287e-01, time/batch = 17.2208s	
17312/33150 (epoch 26.112), train_loss = 0.86883173, grad/param norm = 1.6901e-01, time/batch = 16.8027s	
17313/33150 (epoch 26.113), train_loss = 0.91212644, grad/param norm = 1.8852e-01, time/batch = 17.6360s	
17314/33150 (epoch 26.115), train_loss = 1.12293493, grad/param norm = 1.9490e-01, time/batch = 16.9609s	
17315/33150 (epoch 26.116), train_loss = 0.95881052, grad/param norm = 1.5301e-01, time/batch = 17.4523s	
17316/33150 (epoch 26.118), train_loss = 0.99685860, grad/param norm = 1.8711e-01, time/batch = 17.0437s	
17317/33150 (epoch 26.119), train_loss = 1.01126559, grad/param norm = 1.8801e-01, time/batch = 17.2819s	
17318/33150 (epoch 26.121), train_loss = 0.90614919, grad/param norm = 1.5542e-01, time/batch = 16.7040s	
17319/33150 (epoch 26.122), train_loss = 1.11496897, grad/param norm = 1.9920e-01, time/batch = 18.6444s	
17320/33150 (epoch 26.124), train_loss = 0.79045158, grad/param norm = 1.3078e-01, time/batch = 17.2219s	
17321/33150 (epoch 26.125), train_loss = 1.03454076, grad/param norm = 1.5747e-01, time/batch = 16.1304s	
17322/33150 (epoch 26.127), train_loss = 0.94886272, grad/param norm = 1.6314e-01, time/batch = 17.8854s	
17323/33150 (epoch 26.128), train_loss = 1.00833665, grad/param norm = 1.8517e-01, time/batch = 18.3758s	
17324/33150 (epoch 26.130), train_loss = 0.96313910, grad/param norm = 1.7922e-01, time/batch = 16.2781s	
17325/33150 (epoch 26.131), train_loss = 1.16433585, grad/param norm = 1.7372e-01, time/batch = 16.5363s	
17326/33150 (epoch 26.133), train_loss = 0.86659048, grad/param norm = 1.5202e-01, time/batch = 17.8810s	
17327/33150 (epoch 26.134), train_loss = 1.07201699, grad/param norm = 1.6910e-01, time/batch = 18.3999s	
17328/33150 (epoch 26.136), train_loss = 0.93218510, grad/param norm = 1.8334e-01, time/batch = 16.7138s	
17329/33150 (epoch 26.137), train_loss = 1.03393866, grad/param norm = 1.6951e-01, time/batch = 16.2999s	
17330/33150 (epoch 26.139), train_loss = 1.02160515, grad/param norm = 1.8017e-01, time/batch = 15.3858s	
17331/33150 (epoch 26.140), train_loss = 1.09620903, grad/param norm = 1.8343e-01, time/batch = 15.8525s	
17332/33150 (epoch 26.142), train_loss = 1.02661290, grad/param norm = 1.5589e-01, time/batch = 16.7213s	
17333/33150 (epoch 26.143), train_loss = 0.96862708, grad/param norm = 1.9230e-01, time/batch = 18.7971s	
17334/33150 (epoch 26.145), train_loss = 0.93806739, grad/param norm = 1.7824e-01, time/batch = 18.9721s	
17335/33150 (epoch 26.146), train_loss = 1.05450169, grad/param norm = 2.0549e-01, time/batch = 15.6027s	
17336/33150 (epoch 26.148), train_loss = 1.06309078, grad/param norm = 1.5536e-01, time/batch = 16.8925s	
17337/33150 (epoch 26.149), train_loss = 0.98613625, grad/param norm = 1.7931e-01, time/batch = 18.0491s	
17338/33150 (epoch 26.151), train_loss = 1.12431732, grad/param norm = 1.9261e-01, time/batch = 16.1288s	
17339/33150 (epoch 26.152), train_loss = 0.92520228, grad/param norm = 1.5481e-01, time/batch = 16.1431s	
17340/33150 (epoch 26.154), train_loss = 0.91636018, grad/param norm = 1.7915e-01, time/batch = 17.9652s	
17341/33150 (epoch 26.155), train_loss = 0.80261272, grad/param norm = 1.5579e-01, time/batch = 17.4023s	
17342/33150 (epoch 26.157), train_loss = 0.93312052, grad/param norm = 1.8106e-01, time/batch = 16.1481s	
17343/33150 (epoch 26.158), train_loss = 0.89815088, grad/param norm = 1.4834e-01, time/batch = 15.9704s	
17344/33150 (epoch 26.160), train_loss = 1.00773967, grad/param norm = 1.7186e-01, time/batch = 15.4598s	
17345/33150 (epoch 26.161), train_loss = 0.88887434, grad/param norm = 1.9959e-01, time/batch = 15.8795s	
17346/33150 (epoch 26.163), train_loss = 0.85317541, grad/param norm = 1.6186e-01, time/batch = 17.5555s	
17347/33150 (epoch 26.164), train_loss = 1.00655060, grad/param norm = 1.8119e-01, time/batch = 17.7763s	
17348/33150 (epoch 26.166), train_loss = 0.92642057, grad/param norm = 1.7184e-01, time/batch = 17.2372s	
17349/33150 (epoch 26.167), train_loss = 0.94826418, grad/param norm = 1.5145e-01, time/batch = 17.3955s	
17350/33150 (epoch 26.169), train_loss = 0.96673234, grad/param norm = 1.8942e-01, time/batch = 18.5529s	
17351/33150 (epoch 26.170), train_loss = 0.87703243, grad/param norm = 1.8806e-01, time/batch = 17.3898s	
17352/33150 (epoch 26.172), train_loss = 1.01885567, grad/param norm = 1.7477e-01, time/batch = 17.5512s	
17353/33150 (epoch 26.173), train_loss = 1.02742052, grad/param norm = 2.2987e-01, time/batch = 16.8918s	
17354/33150 (epoch 26.175), train_loss = 0.91405983, grad/param norm = 1.9130e-01, time/batch = 17.3106s	
17355/33150 (epoch 26.176), train_loss = 1.01848819, grad/param norm = 1.7600e-01, time/batch = 17.4896s	
17356/33150 (epoch 26.178), train_loss = 1.15063210, grad/param norm = 1.9022e-01, time/batch = 17.1277s	
17357/33150 (epoch 26.179), train_loss = 1.01127432, grad/param norm = 1.6034e-01, time/batch = 18.2828s	
17358/33150 (epoch 26.181), train_loss = 0.96572736, grad/param norm = 1.8187e-01, time/batch = 19.3145s	
17359/33150 (epoch 26.183), train_loss = 0.93540269, grad/param norm = 1.8133e-01, time/batch = 17.2038s	
17360/33150 (epoch 26.184), train_loss = 1.16595341, grad/param norm = 1.7378e-01, time/batch = 18.0530s	
17361/33150 (epoch 26.186), train_loss = 1.07370497, grad/param norm = 1.5442e-01, time/batch = 19.9578s	
17362/33150 (epoch 26.187), train_loss = 0.95658655, grad/param norm = 1.6648e-01, time/batch = 17.1256s	
17363/33150 (epoch 26.189), train_loss = 0.74982863, grad/param norm = 1.4810e-01, time/batch = 18.4857s	
17364/33150 (epoch 26.190), train_loss = 0.87315995, grad/param norm = 2.0883e-01, time/batch = 19.4024s	
17365/33150 (epoch 26.192), train_loss = 0.96152191, grad/param norm = 1.7746e-01, time/batch = 16.3103s	
17366/33150 (epoch 26.193), train_loss = 1.03123719, grad/param norm = 1.6856e-01, time/batch = 16.3175s	
17367/33150 (epoch 26.195), train_loss = 1.17773442, grad/param norm = 1.9854e-01, time/batch = 18.8317s	
17368/33150 (epoch 26.196), train_loss = 1.05824082, grad/param norm = 1.7431e-01, time/batch = 18.8151s	
17369/33150 (epoch 26.198), train_loss = 0.83326860, grad/param norm = 1.6161e-01, time/batch = 16.6274s	
17370/33150 (epoch 26.199), train_loss = 1.05945779, grad/param norm = 2.1502e-01, time/batch = 16.4607s	
17371/33150 (epoch 26.201), train_loss = 0.88782994, grad/param norm = 1.3427e-01, time/batch = 17.2937s	
17372/33150 (epoch 26.202), train_loss = 0.76274095, grad/param norm = 1.4790e-01, time/batch = 17.7331s	
17373/33150 (epoch 26.204), train_loss = 1.00682848, grad/param norm = 1.7003e-01, time/batch = 18.5723s	
17374/33150 (epoch 26.205), train_loss = 1.02361053, grad/param norm = 1.9002e-01, time/batch = 18.7293s	
17375/33150 (epoch 26.207), train_loss = 0.99941691, grad/param norm = 1.6777e-01, time/batch = 18.1514s	
17376/33150 (epoch 26.208), train_loss = 1.02659651, grad/param norm = 1.7546e-01, time/batch = 18.5488s	
17377/33150 (epoch 26.210), train_loss = 0.89356490, grad/param norm = 1.4101e-01, time/batch = 16.3087s	
17378/33150 (epoch 26.211), train_loss = 0.98682612, grad/param norm = 1.9415e-01, time/batch = 18.6313s	
17379/33150 (epoch 26.213), train_loss = 1.00084402, grad/param norm = 1.5152e-01, time/batch = 18.0499s	
17380/33150 (epoch 26.214), train_loss = 0.94331760, grad/param norm = 1.6398e-01, time/batch = 18.1278s	
17381/33150 (epoch 26.216), train_loss = 0.88133343, grad/param norm = 1.6908e-01, time/batch = 19.5453s	
17382/33150 (epoch 26.217), train_loss = 0.91735366, grad/param norm = 1.4170e-01, time/batch = 16.7308s	
17383/33150 (epoch 26.219), train_loss = 0.86800164, grad/param norm = 1.5550e-01, time/batch = 19.3979s	
17384/33150 (epoch 26.220), train_loss = 0.90850268, grad/param norm = 1.6458e-01, time/batch = 18.3989s	
17385/33150 (epoch 26.222), train_loss = 1.07850951, grad/param norm = 1.7676e-01, time/batch = 18.3093s	
17386/33150 (epoch 26.223), train_loss = 0.95589248, grad/param norm = 1.7810e-01, time/batch = 18.3106s	
17387/33150 (epoch 26.225), train_loss = 1.06911972, grad/param norm = 1.6131e-01, time/batch = 16.3802s	
17388/33150 (epoch 26.226), train_loss = 0.93906327, grad/param norm = 1.5054e-01, time/batch = 18.4541s	
17389/33150 (epoch 26.228), train_loss = 0.93734547, grad/param norm = 1.7424e-01, time/batch = 17.6296s	
17390/33150 (epoch 26.229), train_loss = 0.95046212, grad/param norm = 1.6078e-01, time/batch = 17.4556s	
17391/33150 (epoch 26.231), train_loss = 1.05240063, grad/param norm = 1.7333e-01, time/batch = 19.1407s	
17392/33150 (epoch 26.232), train_loss = 0.97768860, grad/param norm = 1.7767e-01, time/batch = 17.4025s	
17393/33150 (epoch 26.234), train_loss = 0.94823670, grad/param norm = 1.6171e-01, time/batch = 18.7246s	
17394/33150 (epoch 26.235), train_loss = 1.00160802, grad/param norm = 1.9975e-01, time/batch = 16.1422s	
17395/33150 (epoch 26.237), train_loss = 0.97263044, grad/param norm = 2.0950e-01, time/batch = 17.5579s	
17396/33150 (epoch 26.238), train_loss = 1.00406814, grad/param norm = 1.7416e-01, time/batch = 16.0637s	
17397/33150 (epoch 26.240), train_loss = 1.02082660, grad/param norm = 1.6472e-01, time/batch = 17.4020s	
17398/33150 (epoch 26.241), train_loss = 1.05681412, grad/param norm = 1.9003e-01, time/batch = 18.6588s	
17399/33150 (epoch 26.243), train_loss = 1.03204565, grad/param norm = 1.8070e-01, time/batch = 15.4824s	
17400/33150 (epoch 26.244), train_loss = 0.94000282, grad/param norm = 1.4914e-01, time/batch = 17.2469s	
17401/33150 (epoch 26.246), train_loss = 1.01655354, grad/param norm = 1.6403e-01, time/batch = 19.7228s	
17402/33150 (epoch 26.247), train_loss = 0.91288557, grad/param norm = 1.5813e-01, time/batch = 20.0124s	
17403/33150 (epoch 26.249), train_loss = 1.07320704, grad/param norm = 1.7040e-01, time/batch = 28.8805s	
17404/33150 (epoch 26.250), train_loss = 1.02204005, grad/param norm = 1.4931e-01, time/batch = 19.5558s	
17405/33150 (epoch 26.252), train_loss = 1.01613494, grad/param norm = 1.4702e-01, time/batch = 16.6282s	
17406/33150 (epoch 26.253), train_loss = 0.94728608, grad/param norm = 1.6520e-01, time/batch = 17.6220s	
17407/33150 (epoch 26.255), train_loss = 0.93449087, grad/param norm = 1.4692e-01, time/batch = 18.2201s	
17408/33150 (epoch 26.256), train_loss = 1.03712776, grad/param norm = 1.6590e-01, time/batch = 17.2007s	
17409/33150 (epoch 26.258), train_loss = 0.89379531, grad/param norm = 1.6858e-01, time/batch = 17.3980s	
17410/33150 (epoch 26.259), train_loss = 0.79336011, grad/param norm = 1.5396e-01, time/batch = 16.8070s	
17411/33150 (epoch 26.261), train_loss = 0.84570995, grad/param norm = 1.3694e-01, time/batch = 18.9810s	
17412/33150 (epoch 26.262), train_loss = 1.05696930, grad/param norm = 2.0351e-01, time/batch = 16.3650s	
17413/33150 (epoch 26.264), train_loss = 0.74391208, grad/param norm = 1.3888e-01, time/batch = 18.8960s	
17414/33150 (epoch 26.265), train_loss = 0.99897502, grad/param norm = 1.7319e-01, time/batch = 18.5677s	
17415/33150 (epoch 26.267), train_loss = 1.00219266, grad/param norm = 1.8035e-01, time/batch = 17.8017s	
17416/33150 (epoch 26.268), train_loss = 1.04940776, grad/param norm = 1.5465e-01, time/batch = 19.6356s	
17417/33150 (epoch 26.270), train_loss = 1.12758050, grad/param norm = 1.6977e-01, time/batch = 17.8892s	
17418/33150 (epoch 26.271), train_loss = 1.06178889, grad/param norm = 2.0420e-01, time/batch = 17.2825s	
17419/33150 (epoch 26.273), train_loss = 1.06375257, grad/param norm = 1.5065e-01, time/batch = 17.9073s	
17420/33150 (epoch 26.275), train_loss = 1.08989479, grad/param norm = 1.7465e-01, time/batch = 18.2227s	
17421/33150 (epoch 26.276), train_loss = 0.98304246, grad/param norm = 1.6939e-01, time/batch = 18.1214s	
17422/33150 (epoch 26.278), train_loss = 1.07754885, grad/param norm = 1.5769e-01, time/batch = 16.9811s	
17423/33150 (epoch 26.279), train_loss = 1.01418139, grad/param norm = 1.5151e-01, time/batch = 17.5331s	
17424/33150 (epoch 26.281), train_loss = 0.98625765, grad/param norm = 1.5618e-01, time/batch = 17.7204s	
17425/33150 (epoch 26.282), train_loss = 0.99939547, grad/param norm = 1.4383e-01, time/batch = 16.3062s	
17426/33150 (epoch 26.284), train_loss = 0.90428602, grad/param norm = 1.6224e-01, time/batch = 18.1505s	
17427/33150 (epoch 26.285), train_loss = 0.98723394, grad/param norm = 1.5915e-01, time/batch = 17.1418s	
17428/33150 (epoch 26.287), train_loss = 0.85906212, grad/param norm = 1.6349e-01, time/batch = 17.6474s	
17429/33150 (epoch 26.288), train_loss = 1.07199815, grad/param norm = 1.7489e-01, time/batch = 17.6383s	
17430/33150 (epoch 26.290), train_loss = 0.83726449, grad/param norm = 1.6547e-01, time/batch = 17.2226s	
17431/33150 (epoch 26.291), train_loss = 0.81118632, grad/param norm = 1.9183e-01, time/batch = 18.3822s	
17432/33150 (epoch 26.293), train_loss = 1.00311916, grad/param norm = 1.6189e-01, time/batch = 17.0579s	
17433/33150 (epoch 26.294), train_loss = 0.74065735, grad/param norm = 1.5521e-01, time/batch = 18.8699s	
17434/33150 (epoch 26.296), train_loss = 0.95934730, grad/param norm = 1.4762e-01, time/batch = 19.5472s	
17435/33150 (epoch 26.297), train_loss = 0.91290093, grad/param norm = 1.6608e-01, time/batch = 16.6246s	
17436/33150 (epoch 26.299), train_loss = 0.88827486, grad/param norm = 1.6110e-01, time/batch = 16.7373s	
17437/33150 (epoch 26.300), train_loss = 0.89447326, grad/param norm = 1.3746e-01, time/batch = 17.1499s	
17438/33150 (epoch 26.302), train_loss = 0.92137292, grad/param norm = 1.4739e-01, time/batch = 19.2063s	
17439/33150 (epoch 26.303), train_loss = 0.91491807, grad/param norm = 1.4800e-01, time/batch = 17.3141s	
17440/33150 (epoch 26.305), train_loss = 0.99278135, grad/param norm = 1.4722e-01, time/batch = 17.2052s	
17441/33150 (epoch 26.306), train_loss = 1.00918278, grad/param norm = 2.1129e-01, time/batch = 16.8784s	
17442/33150 (epoch 26.308), train_loss = 1.19300511, grad/param norm = 1.8619e-01, time/batch = 17.4636s	
17443/33150 (epoch 26.309), train_loss = 0.78489337, grad/param norm = 1.3714e-01, time/batch = 17.9581s	
17444/33150 (epoch 26.311), train_loss = 0.92098756, grad/param norm = 1.6107e-01, time/batch = 18.1234s	
17445/33150 (epoch 26.312), train_loss = 0.77873188, grad/param norm = 1.5757e-01, time/batch = 17.3014s	
17446/33150 (epoch 26.314), train_loss = 0.91633512, grad/param norm = 1.6719e-01, time/batch = 17.5784s	
17447/33150 (epoch 26.315), train_loss = 0.99352705, grad/param norm = 1.4976e-01, time/batch = 17.2499s	
17448/33150 (epoch 26.317), train_loss = 0.77375284, grad/param norm = 1.2649e-01, time/batch = 18.3132s	
17449/33150 (epoch 26.318), train_loss = 0.86558359, grad/param norm = 1.4507e-01, time/batch = 16.8883s	
17450/33150 (epoch 26.320), train_loss = 0.80263104, grad/param norm = 1.3489e-01, time/batch = 19.4764s	
17451/33150 (epoch 26.321), train_loss = 0.92255357, grad/param norm = 1.3617e-01, time/batch = 19.2174s	
17452/33150 (epoch 26.323), train_loss = 0.91762074, grad/param norm = 1.5407e-01, time/batch = 16.0358s	
17453/33150 (epoch 26.324), train_loss = 1.00469826, grad/param norm = 1.8957e-01, time/batch = 18.8761s	
17454/33150 (epoch 26.326), train_loss = 0.97095930, grad/param norm = 1.5002e-01, time/batch = 17.7147s	
17455/33150 (epoch 26.327), train_loss = 1.05405426, grad/param norm = 1.5244e-01, time/batch = 15.7646s	
17456/33150 (epoch 26.329), train_loss = 0.99166485, grad/param norm = 1.4164e-01, time/batch = 14.9280s	
17457/33150 (epoch 26.330), train_loss = 0.94282144, grad/param norm = 1.7468e-01, time/batch = 14.7786s	
17458/33150 (epoch 26.332), train_loss = 0.93745491, grad/param norm = 1.3921e-01, time/batch = 14.9267s	
17459/33150 (epoch 26.333), train_loss = 1.00580361, grad/param norm = 1.4278e-01, time/batch = 15.0560s	
17460/33150 (epoch 26.335), train_loss = 0.87894986, grad/param norm = 1.6571e-01, time/batch = 15.8651s	
17461/33150 (epoch 26.336), train_loss = 0.86770217, grad/param norm = 1.5864e-01, time/batch = 17.2998s	
17462/33150 (epoch 26.338), train_loss = 0.80372659, grad/param norm = 1.5826e-01, time/batch = 16.8825s	
17463/33150 (epoch 26.339), train_loss = 1.02407214, grad/param norm = 1.6911e-01, time/batch = 16.9436s	
17464/33150 (epoch 26.341), train_loss = 0.97424428, grad/param norm = 1.8244e-01, time/batch = 15.8800s	
17465/33150 (epoch 26.342), train_loss = 0.85575825, grad/param norm = 1.5752e-01, time/batch = 15.3738s	
17466/33150 (epoch 26.344), train_loss = 0.95395322, grad/param norm = 1.7289e-01, time/batch = 17.3087s	
17467/33150 (epoch 26.345), train_loss = 0.91917719, grad/param norm = 1.5057e-01, time/batch = 15.1521s	
17468/33150 (epoch 26.347), train_loss = 0.75970800, grad/param norm = 1.3802e-01, time/batch = 17.8125s	
17469/33150 (epoch 26.348), train_loss = 0.96340619, grad/param norm = 1.5859e-01, time/batch = 16.9745s	
17470/33150 (epoch 26.350), train_loss = 0.83787435, grad/param norm = 1.5380e-01, time/batch = 17.1290s	
17471/33150 (epoch 26.351), train_loss = 1.02715893, grad/param norm = 1.6278e-01, time/batch = 15.7388s	
17472/33150 (epoch 26.353), train_loss = 0.98131290, grad/param norm = 1.6589e-01, time/batch = 17.5494s	
17473/33150 (epoch 26.354), train_loss = 1.18376926, grad/param norm = 1.6536e-01, time/batch = 16.4554s	
17474/33150 (epoch 26.356), train_loss = 1.04204771, grad/param norm = 1.6573e-01, time/batch = 15.3286s	
17475/33150 (epoch 26.357), train_loss = 0.96887335, grad/param norm = 1.7008e-01, time/batch = 16.9468s	
17476/33150 (epoch 26.359), train_loss = 1.01072275, grad/param norm = 1.6467e-01, time/batch = 17.5599s	
17477/33150 (epoch 26.360), train_loss = 1.01026279, grad/param norm = 1.8639e-01, time/batch = 16.6246s	
17478/33150 (epoch 26.362), train_loss = 1.06947000, grad/param norm = 1.8237e-01, time/batch = 15.8546s	
17479/33150 (epoch 26.363), train_loss = 0.96362854, grad/param norm = 1.5171e-01, time/batch = 17.1308s	
17480/33150 (epoch 26.365), train_loss = 0.93399014, grad/param norm = 1.5165e-01, time/batch = 16.8580s	
17481/33150 (epoch 26.367), train_loss = 0.91066123, grad/param norm = 1.7168e-01, time/batch = 17.2025s	
17482/33150 (epoch 26.368), train_loss = 0.93474334, grad/param norm = 1.7949e-01, time/batch = 17.0397s	
17483/33150 (epoch 26.370), train_loss = 0.96148270, grad/param norm = 1.6358e-01, time/batch = 18.5468s	
17484/33150 (epoch 26.371), train_loss = 0.84330538, grad/param norm = 1.4533e-01, time/batch = 16.8744s	
17485/33150 (epoch 26.373), train_loss = 1.00955036, grad/param norm = 1.8312e-01, time/batch = 16.5473s	
17486/33150 (epoch 26.374), train_loss = 0.91669273, grad/param norm = 1.4557e-01, time/batch = 18.3759s	
17487/33150 (epoch 26.376), train_loss = 1.05921035, grad/param norm = 1.6748e-01, time/batch = 19.0586s	
17488/33150 (epoch 26.377), train_loss = 0.89199188, grad/param norm = 1.6168e-01, time/batch = 15.7522s	
17489/33150 (epoch 26.379), train_loss = 1.03253795, grad/param norm = 1.9058e-01, time/batch = 16.6151s	
17490/33150 (epoch 26.380), train_loss = 1.00363585, grad/param norm = 1.3338e-01, time/batch = 18.8104s	
17491/33150 (epoch 26.382), train_loss = 0.91797893, grad/param norm = 1.4967e-01, time/batch = 17.4624s	
17492/33150 (epoch 26.383), train_loss = 0.88487800, grad/param norm = 1.6474e-01, time/batch = 17.9746s	
17493/33150 (epoch 26.385), train_loss = 0.91458551, grad/param norm = 1.5030e-01, time/batch = 18.3687s	
17494/33150 (epoch 26.386), train_loss = 0.82310432, grad/param norm = 1.4016e-01, time/batch = 15.7219s	
17495/33150 (epoch 26.388), train_loss = 0.88683222, grad/param norm = 1.5626e-01, time/batch = 16.7931s	
17496/33150 (epoch 26.389), train_loss = 0.87575799, grad/param norm = 1.3864e-01, time/batch = 18.7758s	
17497/33150 (epoch 26.391), train_loss = 1.13923443, grad/param norm = 1.9904e-01, time/batch = 18.6334s	
17498/33150 (epoch 26.392), train_loss = 0.91856792, grad/param norm = 1.5794e-01, time/batch = 16.3913s	
17499/33150 (epoch 26.394), train_loss = 0.79969675, grad/param norm = 1.3751e-01, time/batch = 16.6472s	
17500/33150 (epoch 26.395), train_loss = 0.78632672, grad/param norm = 1.5138e-01, time/batch = 18.4694s	
17501/33150 (epoch 26.397), train_loss = 0.66181249, grad/param norm = 1.3186e-01, time/batch = 17.4845s	
17502/33150 (epoch 26.398), train_loss = 0.95325590, grad/param norm = 1.7694e-01, time/batch = 17.7407s	
17503/33150 (epoch 26.400), train_loss = 0.91172283, grad/param norm = 1.4669e-01, time/batch = 18.3992s	
17504/33150 (epoch 26.401), train_loss = 0.81341566, grad/param norm = 1.3208e-01, time/batch = 18.4918s	
17505/33150 (epoch 26.403), train_loss = 0.79191942, grad/param norm = 1.3307e-01, time/batch = 15.9737s	
17506/33150 (epoch 26.404), train_loss = 0.94259864, grad/param norm = 1.5032e-01, time/batch = 18.3950s	
17507/33150 (epoch 26.406), train_loss = 0.89054217, grad/param norm = 1.3329e-01, time/batch = 16.2226s	
17508/33150 (epoch 26.407), train_loss = 0.81869384, grad/param norm = 1.3652e-01, time/batch = 16.7175s	
17509/33150 (epoch 26.409), train_loss = 0.78436818, grad/param norm = 1.4977e-01, time/batch = 16.0450s	
17510/33150 (epoch 26.410), train_loss = 0.96272001, grad/param norm = 1.6680e-01, time/batch = 17.3182s	
17511/33150 (epoch 26.412), train_loss = 0.99884478, grad/param norm = 1.5157e-01, time/batch = 17.9190s	
17512/33150 (epoch 26.413), train_loss = 0.85028542, grad/param norm = 1.5350e-01, time/batch = 15.5523s	
17513/33150 (epoch 26.415), train_loss = 0.95271926, grad/param norm = 1.4529e-01, time/batch = 17.7417s	
17514/33150 (epoch 26.416), train_loss = 0.86092164, grad/param norm = 1.3268e-01, time/batch = 17.8816s	
17515/33150 (epoch 26.418), train_loss = 1.01103495, grad/param norm = 2.0769e-01, time/batch = 16.8876s	
17516/33150 (epoch 26.419), train_loss = 0.89187713, grad/param norm = 1.4925e-01, time/batch = 17.3893s	
17517/33150 (epoch 26.421), train_loss = 0.94633975, grad/param norm = 1.9144e-01, time/batch = 16.3899s	
17518/33150 (epoch 26.422), train_loss = 0.88895525, grad/param norm = 1.5204e-01, time/batch = 18.3246s	
17519/33150 (epoch 26.424), train_loss = 0.88751494, grad/param norm = 1.7580e-01, time/batch = 16.8060s	
17520/33150 (epoch 26.425), train_loss = 0.99831386, grad/param norm = 1.6374e-01, time/batch = 18.3264s	
17521/33150 (epoch 26.427), train_loss = 0.93184418, grad/param norm = 1.4204e-01, time/batch = 17.5523s	
17522/33150 (epoch 26.428), train_loss = 0.93415241, grad/param norm = 1.6592e-01, time/batch = 16.8901s	
17523/33150 (epoch 26.430), train_loss = 0.95463204, grad/param norm = 1.5460e-01, time/batch = 17.4753s	
17524/33150 (epoch 26.431), train_loss = 1.00177457, grad/param norm = 1.7272e-01, time/batch = 18.7104s	
17525/33150 (epoch 26.433), train_loss = 0.92858665, grad/param norm = 1.5550e-01, time/batch = 18.2199s	
17526/33150 (epoch 26.434), train_loss = 0.83222961, grad/param norm = 1.7492e-01, time/batch = 17.3174s	
17527/33150 (epoch 26.436), train_loss = 0.90977841, grad/param norm = 1.4983e-01, time/batch = 16.7467s	
17528/33150 (epoch 26.437), train_loss = 0.94105829, grad/param norm = 1.8033e-01, time/batch = 17.8175s	
17529/33150 (epoch 26.439), train_loss = 1.07830177, grad/param norm = 1.6226e-01, time/batch = 15.4595s	
17530/33150 (epoch 26.440), train_loss = 1.01595144, grad/param norm = 1.6242e-01, time/batch = 16.9813s	
17531/33150 (epoch 26.442), train_loss = 0.82738082, grad/param norm = 1.5400e-01, time/batch = 18.1468s	
17532/33150 (epoch 26.443), train_loss = 0.99428189, grad/param norm = 1.6902e-01, time/batch = 16.8250s	
17533/33150 (epoch 26.445), train_loss = 0.94357245, grad/param norm = 1.6371e-01, time/batch = 15.6467s	
17534/33150 (epoch 26.446), train_loss = 0.97171953, grad/param norm = 1.8835e-01, time/batch = 16.3691s	
17535/33150 (epoch 26.448), train_loss = 1.03346332, grad/param norm = 1.6070e-01, time/batch = 17.1409s	
17536/33150 (epoch 26.449), train_loss = 0.97089318, grad/param norm = 1.4912e-01, time/batch = 15.9026s	
17537/33150 (epoch 26.451), train_loss = 0.94441754, grad/param norm = 1.8017e-01, time/batch = 18.0658s	
17538/33150 (epoch 26.452), train_loss = 1.13030592, grad/param norm = 1.6760e-01, time/batch = 19.3955s	
17539/33150 (epoch 26.454), train_loss = 0.94798401, grad/param norm = 1.7183e-01, time/batch = 17.9695s	
17540/33150 (epoch 26.456), train_loss = 0.83352701, grad/param norm = 1.5098e-01, time/batch = 18.8745s	
17541/33150 (epoch 26.457), train_loss = 0.93687548, grad/param norm = 1.5531e-01, time/batch = 16.1512s	
17542/33150 (epoch 26.459), train_loss = 1.04632653, grad/param norm = 2.0526e-01, time/batch = 18.3160s	
17543/33150 (epoch 26.460), train_loss = 0.98041449, grad/param norm = 1.3920e-01, time/batch = 16.3199s	
17544/33150 (epoch 26.462), train_loss = 1.04088148, grad/param norm = 2.4557e-01, time/batch = 16.8114s	
17545/33150 (epoch 26.463), train_loss = 1.16701088, grad/param norm = 2.0331e-01, time/batch = 19.3893s	
17546/33150 (epoch 26.465), train_loss = 0.96456119, grad/param norm = 1.6229e-01, time/batch = 17.3936s	
17547/33150 (epoch 26.466), train_loss = 0.90321287, grad/param norm = 1.6860e-01, time/batch = 17.3900s	
17548/33150 (epoch 26.468), train_loss = 1.16822948, grad/param norm = 1.6509e-01, time/batch = 19.0722s	
17549/33150 (epoch 26.469), train_loss = 0.92501757, grad/param norm = 1.6682e-01, time/batch = 18.1487s	
17550/33150 (epoch 26.471), train_loss = 0.87928685, grad/param norm = 1.5334e-01, time/batch = 16.3163s	
17551/33150 (epoch 26.472), train_loss = 0.97915361, grad/param norm = 1.7888e-01, time/batch = 16.1684s	
17552/33150 (epoch 26.474), train_loss = 1.03981875, grad/param norm = 2.0331e-01, time/batch = 14.9729s	
17553/33150 (epoch 26.475), train_loss = 1.17224242, grad/param norm = 1.7150e-01, time/batch = 16.5374s	
17554/33150 (epoch 26.477), train_loss = 1.06872579, grad/param norm = 1.9926e-01, time/batch = 16.3885s	
17555/33150 (epoch 26.478), train_loss = 1.02252821, grad/param norm = 1.5721e-01, time/batch = 17.9957s	
17556/33150 (epoch 26.480), train_loss = 0.87663643, grad/param norm = 1.5309e-01, time/batch = 19.5563s	
17557/33150 (epoch 26.481), train_loss = 0.79841844, grad/param norm = 1.5297e-01, time/batch = 18.2894s	
17558/33150 (epoch 26.483), train_loss = 0.89736450, grad/param norm = 1.7182e-01, time/batch = 19.6360s	
17559/33150 (epoch 26.484), train_loss = 0.89407743, grad/param norm = 1.6312e-01, time/batch = 19.2837s	
17560/33150 (epoch 26.486), train_loss = 0.87562561, grad/param norm = 1.5237e-01, time/batch = 17.0578s	
17561/33150 (epoch 26.487), train_loss = 0.97554669, grad/param norm = 1.6377e-01, time/batch = 17.0665s	
17562/33150 (epoch 26.489), train_loss = 0.93310316, grad/param norm = 1.6045e-01, time/batch = 17.5650s	
17563/33150 (epoch 26.490), train_loss = 0.80383535, grad/param norm = 1.5179e-01, time/batch = 17.1415s	
17564/33150 (epoch 26.492), train_loss = 0.92502947, grad/param norm = 2.1487e-01, time/batch = 16.4939s	
17565/33150 (epoch 26.493), train_loss = 1.02828018, grad/param norm = 1.6323e-01, time/batch = 19.5560s	
17566/33150 (epoch 26.495), train_loss = 1.03301127, grad/param norm = 1.5180e-01, time/batch = 18.3098s	
17567/33150 (epoch 26.496), train_loss = 0.94070137, grad/param norm = 1.6103e-01, time/batch = 16.5646s	
17568/33150 (epoch 26.498), train_loss = 1.04143581, grad/param norm = 1.9047e-01, time/batch = 19.2147s	
17569/33150 (epoch 26.499), train_loss = 1.05717461, grad/param norm = 1.7454e-01, time/batch = 17.2426s	
17570/33150 (epoch 26.501), train_loss = 1.01797390, grad/param norm = 1.8088e-01, time/batch = 16.6331s	
17571/33150 (epoch 26.502), train_loss = 1.07816808, grad/param norm = 1.9039e-01, time/batch = 19.4558s	
17572/33150 (epoch 26.504), train_loss = 1.00780329, grad/param norm = 1.6926e-01, time/batch = 19.4751s	
17573/33150 (epoch 26.505), train_loss = 1.12473504, grad/param norm = 2.0347e-01, time/batch = 15.9570s	
17574/33150 (epoch 26.507), train_loss = 0.91153047, grad/param norm = 1.7190e-01, time/batch = 16.2337s	
17575/33150 (epoch 26.508), train_loss = 0.89198987, grad/param norm = 1.7027e-01, time/batch = 18.7131s	
17576/33150 (epoch 26.510), train_loss = 1.01133471, grad/param norm = 1.4535e-01, time/batch = 19.0365s	
17577/33150 (epoch 26.511), train_loss = 1.07150954, grad/param norm = 1.6616e-01, time/batch = 16.6465s	
17578/33150 (epoch 26.513), train_loss = 0.98387284, grad/param norm = 1.7341e-01, time/batch = 17.4429s	
17579/33150 (epoch 26.514), train_loss = 0.78777864, grad/param norm = 1.6071e-01, time/batch = 16.3782s	
17580/33150 (epoch 26.516), train_loss = 0.95759700, grad/param norm = 1.8032e-01, time/batch = 17.5633s	
17581/33150 (epoch 26.517), train_loss = 1.05599804, grad/param norm = 1.7037e-01, time/batch = 19.0514s	
17582/33150 (epoch 26.519), train_loss = 0.86928296, grad/param norm = 1.5257e-01, time/batch = 17.1591s	
17583/33150 (epoch 26.520), train_loss = 0.96553450, grad/param norm = 1.6376e-01, time/batch = 17.5530s	
17584/33150 (epoch 26.522), train_loss = 1.06441251, grad/param norm = 1.8040e-01, time/batch = 15.6544s	
17585/33150 (epoch 26.523), train_loss = 0.85623488, grad/param norm = 1.6382e-01, time/batch = 17.2041s	
17586/33150 (epoch 26.525), train_loss = 1.01921820, grad/param norm = 1.7361e-01, time/batch = 17.0421s	
17587/33150 (epoch 26.526), train_loss = 0.87259881, grad/param norm = 1.5876e-01, time/batch = 16.0535s	
17588/33150 (epoch 26.528), train_loss = 1.01178457, grad/param norm = 1.6584e-01, time/batch = 18.2240s	
17589/33150 (epoch 26.529), train_loss = 0.96314144, grad/param norm = 1.6691e-01, time/batch = 18.3055s	
17590/33150 (epoch 26.531), train_loss = 0.78848484, grad/param norm = 1.6949e-01, time/batch = 17.4550s	
17591/33150 (epoch 26.532), train_loss = 0.96921587, grad/param norm = 1.7714e-01, time/batch = 17.8860s	
17592/33150 (epoch 26.534), train_loss = 0.94158152, grad/param norm = 1.4037e-01, time/batch = 18.3938s	
17593/33150 (epoch 26.535), train_loss = 0.86573832, grad/param norm = 1.7650e-01, time/batch = 19.3651s	
17594/33150 (epoch 26.537), train_loss = 1.00282140, grad/param norm = 2.1710e-01, time/batch = 16.9005s	
17595/33150 (epoch 26.538), train_loss = 0.89482083, grad/param norm = 1.6359e-01, time/batch = 19.7971s	
17596/33150 (epoch 26.540), train_loss = 0.84015814, grad/param norm = 1.5614e-01, time/batch = 17.8075s	
17597/33150 (epoch 26.541), train_loss = 1.05361445, grad/param norm = 1.7561e-01, time/batch = 16.6360s	
17598/33150 (epoch 26.543), train_loss = 0.95878733, grad/param norm = 1.6607e-01, time/batch = 17.7227s	
17599/33150 (epoch 26.544), train_loss = 1.02855564, grad/param norm = 1.5996e-01, time/batch = 17.3133s	
17600/33150 (epoch 26.546), train_loss = 0.97850731, grad/param norm = 1.7079e-01, time/batch = 16.8886s	
17601/33150 (epoch 26.548), train_loss = 0.92620608, grad/param norm = 1.6796e-01, time/batch = 15.4669s	
17602/33150 (epoch 26.549), train_loss = 0.88112603, grad/param norm = 1.6391e-01, time/batch = 15.9695s	
17603/33150 (epoch 26.551), train_loss = 0.86827293, grad/param norm = 1.4326e-01, time/batch = 16.7190s	
17604/33150 (epoch 26.552), train_loss = 0.74836140, grad/param norm = 1.2775e-01, time/batch = 16.8863s	
17605/33150 (epoch 26.554), train_loss = 0.99906890, grad/param norm = 1.6934e-01, time/batch = 18.1523s	
17606/33150 (epoch 26.555), train_loss = 1.04290678, grad/param norm = 1.7954e-01, time/batch = 17.2393s	
17607/33150 (epoch 26.557), train_loss = 0.77141606, grad/param norm = 1.6574e-01, time/batch = 18.7861s	
17608/33150 (epoch 26.558), train_loss = 1.00295441, grad/param norm = 2.1220e-01, time/batch = 27.9633s	
17609/33150 (epoch 26.560), train_loss = 0.91431900, grad/param norm = 1.6505e-01, time/batch = 15.4578s	
17610/33150 (epoch 26.561), train_loss = 0.81426567, grad/param norm = 1.5618e-01, time/batch = 14.8706s	
17611/33150 (epoch 26.563), train_loss = 1.00891638, grad/param norm = 2.4125e-01, time/batch = 14.8525s	
17612/33150 (epoch 26.564), train_loss = 1.11700867, grad/param norm = 1.6739e-01, time/batch = 15.1379s	
17613/33150 (epoch 26.566), train_loss = 0.88181168, grad/param norm = 1.4272e-01, time/batch = 15.0682s	
17614/33150 (epoch 26.567), train_loss = 0.86427649, grad/param norm = 1.5544e-01, time/batch = 15.1219s	
17615/33150 (epoch 26.569), train_loss = 0.99027915, grad/param norm = 1.7003e-01, time/batch = 15.3928s	
17616/33150 (epoch 26.570), train_loss = 1.00926159, grad/param norm = 1.6366e-01, time/batch = 15.2636s	
17617/33150 (epoch 26.572), train_loss = 0.87140699, grad/param norm = 2.1038e-01, time/batch = 17.6385s	
17618/33150 (epoch 26.573), train_loss = 0.77975218, grad/param norm = 1.2887e-01, time/batch = 17.1965s	
17619/33150 (epoch 26.575), train_loss = 0.93872357, grad/param norm = 1.6248e-01, time/batch = 17.1995s	
17620/33150 (epoch 26.576), train_loss = 0.81900383, grad/param norm = 1.3732e-01, time/batch = 18.6266s	
17621/33150 (epoch 26.578), train_loss = 0.88083541, grad/param norm = 1.5450e-01, time/batch = 18.1147s	
17622/33150 (epoch 26.579), train_loss = 0.80454111, grad/param norm = 1.5494e-01, time/batch = 17.5298s	
17623/33150 (epoch 26.581), train_loss = 0.85694532, grad/param norm = 1.6191e-01, time/batch = 17.5234s	
17624/33150 (epoch 26.582), train_loss = 1.08184123, grad/param norm = 1.5163e-01, time/batch = 16.1189s	
17625/33150 (epoch 26.584), train_loss = 1.01149985, grad/param norm = 1.7459e-01, time/batch = 15.9408s	
17626/33150 (epoch 26.585), train_loss = 0.95691070, grad/param norm = 1.7495e-01, time/batch = 16.2939s	
17627/33150 (epoch 26.587), train_loss = 0.95563708, grad/param norm = 1.5670e-01, time/batch = 15.8756s	
17628/33150 (epoch 26.588), train_loss = 0.87236006, grad/param norm = 1.6580e-01, time/batch = 15.9383s	
17629/33150 (epoch 26.590), train_loss = 0.98448531, grad/param norm = 1.6180e-01, time/batch = 15.9934s	
17630/33150 (epoch 26.591), train_loss = 0.91894381, grad/param norm = 1.5569e-01, time/batch = 15.3010s	
17631/33150 (epoch 26.593), train_loss = 0.99085784, grad/param norm = 1.6347e-01, time/batch = 15.5441s	
17632/33150 (epoch 26.594), train_loss = 0.93873329, grad/param norm = 1.6812e-01, time/batch = 14.9166s	
17633/33150 (epoch 26.596), train_loss = 0.92718763, grad/param norm = 1.6436e-01, time/batch = 16.1955s	
17634/33150 (epoch 26.597), train_loss = 0.83737497, grad/param norm = 2.0921e-01, time/batch = 16.7037s	
17635/33150 (epoch 26.599), train_loss = 1.10323666, grad/param norm = 1.9313e-01, time/batch = 18.1858s	
17636/33150 (epoch 26.600), train_loss = 0.93976049, grad/param norm = 2.3394e-01, time/batch = 16.5515s	
17637/33150 (epoch 26.602), train_loss = 0.93211247, grad/param norm = 1.5910e-01, time/batch = 15.8990s	
17638/33150 (epoch 26.603), train_loss = 1.03635635, grad/param norm = 1.6898e-01, time/batch = 16.8536s	
17639/33150 (epoch 26.605), train_loss = 0.85487509, grad/param norm = 1.5311e-01, time/batch = 15.5306s	
17640/33150 (epoch 26.606), train_loss = 0.90118007, grad/param norm = 1.9972e-01, time/batch = 16.5243s	
17641/33150 (epoch 26.608), train_loss = 1.00643697, grad/param norm = 1.4462e-01, time/batch = 17.6898s	
17642/33150 (epoch 26.609), train_loss = 0.92695631, grad/param norm = 1.7293e-01, time/batch = 16.2460s	
17643/33150 (epoch 26.611), train_loss = 0.84593299, grad/param norm = 1.5501e-01, time/batch = 17.7014s	
17644/33150 (epoch 26.612), train_loss = 0.93922259, grad/param norm = 1.7149e-01, time/batch = 15.5315s	
17645/33150 (epoch 26.614), train_loss = 0.85683143, grad/param norm = 1.4637e-01, time/batch = 17.0356s	
17646/33150 (epoch 26.615), train_loss = 0.84671573, grad/param norm = 1.7082e-01, time/batch = 16.5242s	
17647/33150 (epoch 26.617), train_loss = 0.96843934, grad/param norm = 1.8668e-01, time/batch = 16.0646s	
17648/33150 (epoch 26.618), train_loss = 1.00150473, grad/param norm = 1.8620e-01, time/batch = 16.7976s	
17649/33150 (epoch 26.620), train_loss = 0.87148955, grad/param norm = 1.4208e-01, time/batch = 16.2361s	
17650/33150 (epoch 26.621), train_loss = 0.93576526, grad/param norm = 1.5203e-01, time/batch = 16.5671s	
17651/33150 (epoch 26.623), train_loss = 1.01811137, grad/param norm = 1.7980e-01, time/batch = 15.4950s	
17652/33150 (epoch 26.624), train_loss = 0.89595166, grad/param norm = 1.5530e-01, time/batch = 14.9446s	
17653/33150 (epoch 26.626), train_loss = 0.91680503, grad/param norm = 1.7648e-01, time/batch = 16.5596s	
17654/33150 (epoch 26.627), train_loss = 0.84217950, grad/param norm = 1.5991e-01, time/batch = 16.3133s	
17655/33150 (epoch 26.629), train_loss = 0.80603571, grad/param norm = 1.6626e-01, time/batch = 16.3815s	
17656/33150 (epoch 26.630), train_loss = 0.90221768, grad/param norm = 1.4219e-01, time/batch = 16.0326s	
17657/33150 (epoch 26.632), train_loss = 0.80448059, grad/param norm = 1.4099e-01, time/batch = 16.1761s	
17658/33150 (epoch 26.633), train_loss = 0.83232261, grad/param norm = 2.0792e-01, time/batch = 15.8848s	
17659/33150 (epoch 26.635), train_loss = 1.10364422, grad/param norm = 1.7508e-01, time/batch = 17.4809s	
17660/33150 (epoch 26.637), train_loss = 0.79602208, grad/param norm = 1.5162e-01, time/batch = 17.4627s	
17661/33150 (epoch 26.638), train_loss = 0.90652752, grad/param norm = 1.5913e-01, time/batch = 17.8825s	
17662/33150 (epoch 26.640), train_loss = 1.00560732, grad/param norm = 1.7481e-01, time/batch = 16.5328s	
17663/33150 (epoch 26.641), train_loss = 0.83447923, grad/param norm = 1.8760e-01, time/batch = 17.0826s	
17664/33150 (epoch 26.643), train_loss = 0.92529239, grad/param norm = 1.5260e-01, time/batch = 15.1708s	
17665/33150 (epoch 26.644), train_loss = 1.06961878, grad/param norm = 1.6457e-01, time/batch = 16.5539s	
17666/33150 (epoch 26.646), train_loss = 0.90922790, grad/param norm = 1.6708e-01, time/batch = 16.4690s	
17667/33150 (epoch 26.647), train_loss = 1.13842494, grad/param norm = 1.8366e-01, time/batch = 18.0642s	
17668/33150 (epoch 26.649), train_loss = 1.00731993, grad/param norm = 1.8078e-01, time/batch = 18.8676s	
17669/33150 (epoch 26.650), train_loss = 0.84226067, grad/param norm = 1.5190e-01, time/batch = 17.8778s	
17670/33150 (epoch 26.652), train_loss = 1.06014226, grad/param norm = 1.8449e-01, time/batch = 17.6258s	
17671/33150 (epoch 26.653), train_loss = 0.97245521, grad/param norm = 1.5365e-01, time/batch = 15.3773s	
17672/33150 (epoch 26.655), train_loss = 0.97344311, grad/param norm = 1.7007e-01, time/batch = 17.3019s	
17673/33150 (epoch 26.656), train_loss = 0.89226281, grad/param norm = 1.4738e-01, time/batch = 17.4724s	
17674/33150 (epoch 26.658), train_loss = 0.91957441, grad/param norm = 2.0248e-01, time/batch = 15.6829s	
17675/33150 (epoch 26.659), train_loss = 1.19529541, grad/param norm = 2.3571e-01, time/batch = 17.3470s	
17676/33150 (epoch 26.661), train_loss = 0.95172036, grad/param norm = 1.7867e-01, time/batch = 17.5435s	
17677/33150 (epoch 26.662), train_loss = 0.88022200, grad/param norm = 1.6480e-01, time/batch = 16.2791s	
17678/33150 (epoch 26.664), train_loss = 1.09135908, grad/param norm = 2.0397e-01, time/batch = 19.8857s	
17679/33150 (epoch 26.665), train_loss = 1.01567424, grad/param norm = 1.6464e-01, time/batch = 16.4704s	
17680/33150 (epoch 26.667), train_loss = 1.05300770, grad/param norm = 1.8969e-01, time/batch = 17.9582s	
17681/33150 (epoch 26.668), train_loss = 1.05444795, grad/param norm = 1.7281e-01, time/batch = 16.9039s	
17682/33150 (epoch 26.670), train_loss = 0.89460330, grad/param norm = 1.4208e-01, time/batch = 16.2237s	
17683/33150 (epoch 26.671), train_loss = 0.90406832, grad/param norm = 1.6731e-01, time/batch = 16.8156s	
17684/33150 (epoch 26.673), train_loss = 1.05926361, grad/param norm = 1.4446e-01, time/batch = 18.5582s	
17685/33150 (epoch 26.674), train_loss = 0.98780666, grad/param norm = 1.6659e-01, time/batch = 20.2822s	
17686/33150 (epoch 26.676), train_loss = 0.94220270, grad/param norm = 1.5735e-01, time/batch = 17.7817s	
17687/33150 (epoch 26.677), train_loss = 1.09592437, grad/param norm = 1.6016e-01, time/batch = 19.7038s	
17688/33150 (epoch 26.679), train_loss = 0.94613400, grad/param norm = 1.5344e-01, time/batch = 18.7272s	
17689/33150 (epoch 26.680), train_loss = 1.06482237, grad/param norm = 1.8612e-01, time/batch = 16.8201s	
17690/33150 (epoch 26.682), train_loss = 0.93386025, grad/param norm = 1.5517e-01, time/batch = 16.9748s	
17691/33150 (epoch 26.683), train_loss = 0.81480143, grad/param norm = 1.4732e-01, time/batch = 15.6727s	
17692/33150 (epoch 26.685), train_loss = 0.90435712, grad/param norm = 1.8227e-01, time/batch = 17.3462s	
17693/33150 (epoch 26.686), train_loss = 0.81529354, grad/param norm = 1.4187e-01, time/batch = 16.2099s	
17694/33150 (epoch 26.688), train_loss = 0.84968378, grad/param norm = 1.5453e-01, time/batch = 17.3800s	
17695/33150 (epoch 26.689), train_loss = 0.86613576, grad/param norm = 1.5513e-01, time/batch = 18.7820s	
17696/33150 (epoch 26.691), train_loss = 0.75707929, grad/param norm = 1.3991e-01, time/batch = 15.9727s	
17697/33150 (epoch 26.692), train_loss = 0.84039241, grad/param norm = 1.6043e-01, time/batch = 18.3029s	
17698/33150 (epoch 26.694), train_loss = 0.73950741, grad/param norm = 1.5380e-01, time/batch = 17.8213s	
17699/33150 (epoch 26.695), train_loss = 0.88872208, grad/param norm = 1.4343e-01, time/batch = 16.0419s	
17700/33150 (epoch 26.697), train_loss = 0.79922795, grad/param norm = 1.3153e-01, time/batch = 16.4145s	
17701/33150 (epoch 26.698), train_loss = 0.84793845, grad/param norm = 1.6666e-01, time/batch = 16.8280s	
17702/33150 (epoch 26.700), train_loss = 0.71879215, grad/param norm = 1.2882e-01, time/batch = 18.0616s	
17703/33150 (epoch 26.701), train_loss = 0.82090821, grad/param norm = 1.4009e-01, time/batch = 15.7359s	
17704/33150 (epoch 26.703), train_loss = 0.92497121, grad/param norm = 1.6035e-01, time/batch = 18.4752s	
17705/33150 (epoch 26.704), train_loss = 0.79749077, grad/param norm = 1.3544e-01, time/batch = 17.8199s	
17706/33150 (epoch 26.706), train_loss = 0.88113082, grad/param norm = 1.4047e-01, time/batch = 16.5519s	
17707/33150 (epoch 26.707), train_loss = 0.87975483, grad/param norm = 1.5363e-01, time/batch = 16.2360s	
17708/33150 (epoch 26.709), train_loss = 0.92377254, grad/param norm = 1.4472e-01, time/batch = 17.9827s	
17709/33150 (epoch 26.710), train_loss = 0.91917566, grad/param norm = 1.6843e-01, time/batch = 16.3954s	
17710/33150 (epoch 26.712), train_loss = 0.98969980, grad/param norm = 1.6811e-01, time/batch = 15.9942s	
17711/33150 (epoch 26.713), train_loss = 0.95822444, grad/param norm = 1.5255e-01, time/batch = 18.1617s	
17712/33150 (epoch 26.715), train_loss = 0.88352207, grad/param norm = 1.4574e-01, time/batch = 17.4839s	
17713/33150 (epoch 26.716), train_loss = 0.96656219, grad/param norm = 1.7379e-01, time/batch = 16.9792s	
17714/33150 (epoch 26.718), train_loss = 0.95204057, grad/param norm = 1.5808e-01, time/batch = 17.4589s	
17715/33150 (epoch 26.719), train_loss = 1.01792600, grad/param norm = 2.0029e-01, time/batch = 18.9504s	
17716/33150 (epoch 26.721), train_loss = 0.90665365, grad/param norm = 1.8423e-01, time/batch = 19.0410s	
17717/33150 (epoch 26.722), train_loss = 0.94208752, grad/param norm = 1.4296e-01, time/batch = 16.4764s	
17718/33150 (epoch 26.724), train_loss = 0.91047700, grad/param norm = 1.6532e-01, time/batch = 19.2939s	
17719/33150 (epoch 26.725), train_loss = 1.02970767, grad/param norm = 2.0430e-01, time/batch = 19.0654s	
17720/33150 (epoch 26.727), train_loss = 0.99229449, grad/param norm = 1.8022e-01, time/batch = 16.8042s	
17721/33150 (epoch 26.729), train_loss = 0.92060502, grad/param norm = 1.7046e-01, time/batch = 20.2951s	
17722/33150 (epoch 26.730), train_loss = 0.93509540, grad/param norm = 1.6658e-01, time/batch = 19.2250s	
17723/33150 (epoch 26.732), train_loss = 1.01114873, grad/param norm = 1.7412e-01, time/batch = 17.3919s	
17724/33150 (epoch 26.733), train_loss = 0.77207032, grad/param norm = 1.3215e-01, time/batch = 16.8670s	
17725/33150 (epoch 26.735), train_loss = 0.84065754, grad/param norm = 1.4943e-01, time/batch = 19.8917s	
17726/33150 (epoch 26.736), train_loss = 0.89926414, grad/param norm = 1.5382e-01, time/batch = 17.0527s	
17727/33150 (epoch 26.738), train_loss = 0.93972239, grad/param norm = 1.6246e-01, time/batch = 18.4652s	
17728/33150 (epoch 26.739), train_loss = 1.02444468, grad/param norm = 1.9966e-01, time/batch = 19.2308s	
17729/33150 (epoch 26.741), train_loss = 1.00930843, grad/param norm = 1.7005e-01, time/batch = 19.0589s	
17730/33150 (epoch 26.742), train_loss = 0.79534162, grad/param norm = 1.4732e-01, time/batch = 17.1224s	
17731/33150 (epoch 26.744), train_loss = 1.02882193, grad/param norm = 1.7518e-01, time/batch = 20.1307s	
17732/33150 (epoch 26.745), train_loss = 0.88582956, grad/param norm = 1.4919e-01, time/batch = 17.9550s	
17733/33150 (epoch 26.747), train_loss = 0.73030882, grad/param norm = 1.4954e-01, time/batch = 16.6465s	
17734/33150 (epoch 26.748), train_loss = 0.83215480, grad/param norm = 1.5736e-01, time/batch = 18.4737s	
17735/33150 (epoch 26.750), train_loss = 0.96574671, grad/param norm = 1.5867e-01, time/batch = 17.3294s	
17736/33150 (epoch 26.751), train_loss = 0.94028606, grad/param norm = 1.5967e-01, time/batch = 17.2250s	
17737/33150 (epoch 26.753), train_loss = 0.79124351, grad/param norm = 1.5953e-01, time/batch = 16.8258s	
17738/33150 (epoch 26.754), train_loss = 1.13347050, grad/param norm = 2.1200e-01, time/batch = 18.1301s	
17739/33150 (epoch 26.756), train_loss = 0.93603461, grad/param norm = 1.8323e-01, time/batch = 17.1648s	
17740/33150 (epoch 26.757), train_loss = 0.93752655, grad/param norm = 1.6201e-01, time/batch = 15.2972s	
17741/33150 (epoch 26.759), train_loss = 1.06262978, grad/param norm = 1.8958e-01, time/batch = 17.1460s	
17742/33150 (epoch 26.760), train_loss = 0.99712841, grad/param norm = 1.8799e-01, time/batch = 19.0655s	
17743/33150 (epoch 26.762), train_loss = 0.96461365, grad/param norm = 1.9092e-01, time/batch = 16.0461s	
17744/33150 (epoch 26.763), train_loss = 0.96984195, grad/param norm = 1.7772e-01, time/batch = 18.3945s	
17745/33150 (epoch 26.765), train_loss = 0.92435420, grad/param norm = 1.5880e-01, time/batch = 19.8759s	
17746/33150 (epoch 26.766), train_loss = 0.84260187, grad/param norm = 1.6603e-01, time/batch = 17.7968s	
17747/33150 (epoch 26.768), train_loss = 0.86160238, grad/param norm = 1.4434e-01, time/batch = 15.9862s	
17748/33150 (epoch 26.769), train_loss = 0.96776902, grad/param norm = 1.6444e-01, time/batch = 16.1595s	
17749/33150 (epoch 26.771), train_loss = 0.96025001, grad/param norm = 1.8748e-01, time/batch = 19.2301s	
17750/33150 (epoch 26.772), train_loss = 0.98959201, grad/param norm = 1.6569e-01, time/batch = 16.8125s	
17751/33150 (epoch 26.774), train_loss = 1.09395487, grad/param norm = 1.7195e-01, time/batch = 19.1471s	
17752/33150 (epoch 26.775), train_loss = 0.99995874, grad/param norm = 2.0317e-01, time/batch = 15.8140s	
17753/33150 (epoch 26.777), train_loss = 1.01510947, grad/param norm = 1.7266e-01, time/batch = 18.1489s	
17754/33150 (epoch 26.778), train_loss = 0.94149498, grad/param norm = 1.5385e-01, time/batch = 17.7848s	
17755/33150 (epoch 26.780), train_loss = 0.81042909, grad/param norm = 1.4144e-01, time/batch = 19.2278s	
17756/33150 (epoch 26.781), train_loss = 0.92304799, grad/param norm = 1.4790e-01, time/batch = 18.8186s	
17757/33150 (epoch 26.783), train_loss = 0.93176657, grad/param norm = 1.5510e-01, time/batch = 16.4549s	
17758/33150 (epoch 26.784), train_loss = 0.92315533, grad/param norm = 1.5151e-01, time/batch = 18.2227s	
17759/33150 (epoch 26.786), train_loss = 0.93097043, grad/param norm = 1.5379e-01, time/batch = 19.8218s	
17760/33150 (epoch 26.787), train_loss = 0.86248840, grad/param norm = 1.3202e-01, time/batch = 15.8582s	
17761/33150 (epoch 26.789), train_loss = 0.78142132, grad/param norm = 1.5023e-01, time/batch = 17.2398s	
17762/33150 (epoch 26.790), train_loss = 0.83240598, grad/param norm = 1.4539e-01, time/batch = 19.2253s	
17763/33150 (epoch 26.792), train_loss = 0.96280675, grad/param norm = 1.7820e-01, time/batch = 17.9612s	
17764/33150 (epoch 26.793), train_loss = 0.90182795, grad/param norm = 1.7947e-01, time/batch = 17.0466s	
17765/33150 (epoch 26.795), train_loss = 0.88470612, grad/param norm = 1.6670e-01, time/batch = 16.3697s	
17766/33150 (epoch 26.796), train_loss = 0.89424860, grad/param norm = 1.4228e-01, time/batch = 15.5840s	
17767/33150 (epoch 26.798), train_loss = 0.87427595, grad/param norm = 1.4036e-01, time/batch = 15.4038s	
17768/33150 (epoch 26.799), train_loss = 0.78265993, grad/param norm = 1.9680e-01, time/batch = 15.3096s	
17769/33150 (epoch 26.801), train_loss = 0.93247971, grad/param norm = 1.5500e-01, time/batch = 15.2908s	
17770/33150 (epoch 26.802), train_loss = 0.86461964, grad/param norm = 1.6395e-01, time/batch = 14.7347s	
17771/33150 (epoch 26.804), train_loss = 0.89304383, grad/param norm = 1.5743e-01, time/batch = 15.1241s	
17772/33150 (epoch 26.805), train_loss = 0.87919679, grad/param norm = 1.7112e-01, time/batch = 14.6460s	
17773/33150 (epoch 26.807), train_loss = 0.88520360, grad/param norm = 1.3782e-01, time/batch = 15.2065s	
17774/33150 (epoch 26.808), train_loss = 1.02122074, grad/param norm = 1.6147e-01, time/batch = 14.9043s	
17775/33150 (epoch 26.810), train_loss = 0.85367718, grad/param norm = 1.5886e-01, time/batch = 15.4633s	
17776/33150 (epoch 26.811), train_loss = 0.95605908, grad/param norm = 1.7589e-01, time/batch = 15.2253s	
17777/33150 (epoch 26.813), train_loss = 0.88349539, grad/param norm = 1.3454e-01, time/batch = 15.8623s	
17778/33150 (epoch 26.814), train_loss = 0.86923691, grad/param norm = 1.7170e-01, time/batch = 18.1053s	
17779/33150 (epoch 26.816), train_loss = 0.90395974, grad/param norm = 1.6915e-01, time/batch = 15.1667s	
17780/33150 (epoch 26.817), train_loss = 0.98660172, grad/param norm = 1.7842e-01, time/batch = 15.9723s	
17781/33150 (epoch 26.819), train_loss = 0.92917826, grad/param norm = 1.6017e-01, time/batch = 17.1178s	
17782/33150 (epoch 26.821), train_loss = 0.82878216, grad/param norm = 1.5372e-01, time/batch = 16.2782s	
17783/33150 (epoch 26.822), train_loss = 0.86781051, grad/param norm = 1.5525e-01, time/batch = 15.6701s	
17784/33150 (epoch 26.824), train_loss = 0.90812154, grad/param norm = 1.4761e-01, time/batch = 17.7057s	
17785/33150 (epoch 26.825), train_loss = 0.93622633, grad/param norm = 1.6572e-01, time/batch = 17.1250s	
17786/33150 (epoch 26.827), train_loss = 0.99104278, grad/param norm = 1.6262e-01, time/batch = 15.6918s	
17787/33150 (epoch 26.828), train_loss = 0.82918316, grad/param norm = 1.6141e-01, time/batch = 18.6231s	
17788/33150 (epoch 26.830), train_loss = 1.00340586, grad/param norm = 1.8246e-01, time/batch = 15.9115s	
17789/33150 (epoch 26.831), train_loss = 0.86609310, grad/param norm = 1.5843e-01, time/batch = 17.6878s	
17790/33150 (epoch 26.833), train_loss = 0.85542602, grad/param norm = 1.5829e-01, time/batch = 15.5137s	
17791/33150 (epoch 26.834), train_loss = 1.01086191, grad/param norm = 1.5787e-01, time/batch = 17.5103s	
17792/33150 (epoch 26.836), train_loss = 1.03315284, grad/param norm = 1.4494e-01, time/batch = 17.3477s	
17793/33150 (epoch 26.837), train_loss = 0.88335945, grad/param norm = 1.6165e-01, time/batch = 15.4587s	
17794/33150 (epoch 26.839), train_loss = 0.99064186, grad/param norm = 1.8632e-01, time/batch = 15.4223s	
17795/33150 (epoch 26.840), train_loss = 0.99939219, grad/param norm = 1.5913e-01, time/batch = 16.5140s	
17796/33150 (epoch 26.842), train_loss = 1.06977153, grad/param norm = 1.8657e-01, time/batch = 15.8246s	
17797/33150 (epoch 26.843), train_loss = 1.03315033, grad/param norm = 1.8081e-01, time/batch = 16.2511s	
17798/33150 (epoch 26.845), train_loss = 0.86211686, grad/param norm = 1.4985e-01, time/batch = 15.2903s	
17799/33150 (epoch 26.846), train_loss = 1.08968247, grad/param norm = 2.4110e-01, time/batch = 17.5356s	
17800/33150 (epoch 26.848), train_loss = 1.02025490, grad/param norm = 1.8421e-01, time/batch = 17.5088s	
17801/33150 (epoch 26.849), train_loss = 1.05345501, grad/param norm = 1.7259e-01, time/batch = 15.2582s	
17802/33150 (epoch 26.851), train_loss = 1.00805124, grad/param norm = 1.8666e-01, time/batch = 16.4239s	
17803/33150 (epoch 26.852), train_loss = 1.08550443, grad/param norm = 1.6102e-01, time/batch = 17.4434s	
17804/33150 (epoch 26.854), train_loss = 0.95525756, grad/param norm = 1.6305e-01, time/batch = 16.3751s	
17805/33150 (epoch 26.855), train_loss = 0.81492268, grad/param norm = 1.5536e-01, time/batch = 16.5293s	
17806/33150 (epoch 26.857), train_loss = 0.79828771, grad/param norm = 1.5664e-01, time/batch = 16.9198s	
17807/33150 (epoch 26.858), train_loss = 0.87860566, grad/param norm = 1.4919e-01, time/batch = 17.8751s	
17808/33150 (epoch 26.860), train_loss = 0.82860586, grad/param norm = 1.4521e-01, time/batch = 15.0705s	
17809/33150 (epoch 26.861), train_loss = 0.84896295, grad/param norm = 1.5364e-01, time/batch = 17.3431s	
17810/33150 (epoch 26.863), train_loss = 0.92746370, grad/param norm = 1.4611e-01, time/batch = 16.4534s	
17811/33150 (epoch 26.864), train_loss = 0.97157557, grad/param norm = 1.6059e-01, time/batch = 15.7043s	
17812/33150 (epoch 26.866), train_loss = 0.98589253, grad/param norm = 1.5902e-01, time/batch = 15.1781s	
17813/33150 (epoch 26.867), train_loss = 0.97013955, grad/param norm = 1.4484e-01, time/batch = 16.9576s	
17814/33150 (epoch 26.869), train_loss = 0.98785205, grad/param norm = 1.9482e-01, time/batch = 15.3661s	
17815/33150 (epoch 26.870), train_loss = 0.89168896, grad/param norm = 1.6299e-01, time/batch = 15.6348s	
17816/33150 (epoch 26.872), train_loss = 0.96009196, grad/param norm = 1.6337e-01, time/batch = 16.9699s	
17817/33150 (epoch 26.873), train_loss = 0.78029760, grad/param norm = 1.3121e-01, time/batch = 15.5122s	
17818/33150 (epoch 26.875), train_loss = 1.04238842, grad/param norm = 1.5609e-01, time/batch = 15.8801s	
17819/33150 (epoch 26.876), train_loss = 0.79891207, grad/param norm = 1.5275e-01, time/batch = 28.9882s	
17820/33150 (epoch 26.878), train_loss = 0.85600640, grad/param norm = 1.4101e-01, time/batch = 16.1013s	
17821/33150 (epoch 26.879), train_loss = 0.86050021, grad/param norm = 1.5876e-01, time/batch = 17.0219s	
17822/33150 (epoch 26.881), train_loss = 0.86078669, grad/param norm = 1.7323e-01, time/batch = 18.0375s	
17823/33150 (epoch 26.882), train_loss = 0.75366359, grad/param norm = 1.3803e-01, time/batch = 16.7045s	
17824/33150 (epoch 26.884), train_loss = 0.90773200, grad/param norm = 1.6796e-01, time/batch = 17.1072s	
17825/33150 (epoch 26.885), train_loss = 0.71988161, grad/param norm = 1.6125e-01, time/batch = 15.4466s	
17826/33150 (epoch 26.887), train_loss = 1.03315512, grad/param norm = 1.7889e-01, time/batch = 14.8450s	
17827/33150 (epoch 26.888), train_loss = 0.96932456, grad/param norm = 1.6762e-01, time/batch = 15.2001s	
17828/33150 (epoch 26.890), train_loss = 0.87103081, grad/param norm = 1.6776e-01, time/batch = 18.1866s	
17829/33150 (epoch 26.891), train_loss = 0.83394120, grad/param norm = 1.6038e-01, time/batch = 15.5100s	
17830/33150 (epoch 26.893), train_loss = 0.98460065, grad/param norm = 1.7148e-01, time/batch = 17.3188s	
17831/33150 (epoch 26.894), train_loss = 0.95777619, grad/param norm = 1.6027e-01, time/batch = 17.2279s	
17832/33150 (epoch 26.896), train_loss = 0.91144587, grad/param norm = 1.5138e-01, time/batch = 16.7159s	
17833/33150 (epoch 26.897), train_loss = 0.96867959, grad/param norm = 1.4701e-01, time/batch = 17.4623s	
17834/33150 (epoch 26.899), train_loss = 0.78476147, grad/param norm = 1.8213e-01, time/batch = 18.9475s	
17835/33150 (epoch 26.900), train_loss = 1.13675564, grad/param norm = 1.9333e-01, time/batch = 17.8739s	
17836/33150 (epoch 26.902), train_loss = 1.11490179, grad/param norm = 1.6819e-01, time/batch = 17.4742s	
17837/33150 (epoch 26.903), train_loss = 0.93335002, grad/param norm = 1.5982e-01, time/batch = 18.5534s	
17838/33150 (epoch 26.905), train_loss = 0.94366449, grad/param norm = 1.4209e-01, time/batch = 18.4649s	
17839/33150 (epoch 26.906), train_loss = 0.95225294, grad/param norm = 1.6608e-01, time/batch = 16.0999s	
17840/33150 (epoch 26.908), train_loss = 1.04950565, grad/param norm = 1.7122e-01, time/batch = 18.3112s	
17841/33150 (epoch 26.910), train_loss = 1.01912565, grad/param norm = 1.6620e-01, time/batch = 19.3060s	
17842/33150 (epoch 26.911), train_loss = 0.80148194, grad/param norm = 1.4478e-01, time/batch = 17.0440s	
17843/33150 (epoch 26.913), train_loss = 0.84375674, grad/param norm = 1.4629e-01, time/batch = 19.4583s	
17844/33150 (epoch 26.914), train_loss = 0.99419215, grad/param norm = 1.8166e-01, time/batch = 19.9613s	
17845/33150 (epoch 26.916), train_loss = 0.85759938, grad/param norm = 1.6439e-01, time/batch = 17.7924s	
17846/33150 (epoch 26.917), train_loss = 0.97728807, grad/param norm = 1.7530e-01, time/batch = 18.2216s	
17847/33150 (epoch 26.919), train_loss = 1.05896461, grad/param norm = 1.8735e-01, time/batch = 19.3779s	
17848/33150 (epoch 26.920), train_loss = 1.03149574, grad/param norm = 1.5928e-01, time/batch = 16.5449s	
17849/33150 (epoch 26.922), train_loss = 1.06968125, grad/param norm = 1.7928e-01, time/batch = 18.6163s	
17850/33150 (epoch 26.923), train_loss = 0.94606043, grad/param norm = 1.7849e-01, time/batch = 17.9573s	
17851/33150 (epoch 26.925), train_loss = 1.02214851, grad/param norm = 1.6630e-01, time/batch = 18.9668s	
17852/33150 (epoch 26.926), train_loss = 0.89816931, grad/param norm = 1.4559e-01, time/batch = 16.3100s	
17853/33150 (epoch 26.928), train_loss = 0.88493159, grad/param norm = 1.5078e-01, time/batch = 17.3760s	
17854/33150 (epoch 26.929), train_loss = 0.98478659, grad/param norm = 1.6190e-01, time/batch = 16.7965s	
17855/33150 (epoch 26.931), train_loss = 1.06878992, grad/param norm = 2.0566e-01, time/batch = 17.5397s	
17856/33150 (epoch 26.932), train_loss = 0.93808121, grad/param norm = 1.5768e-01, time/batch = 16.5781s	
17857/33150 (epoch 26.934), train_loss = 0.98032666, grad/param norm = 1.5576e-01, time/batch = 18.3172s	
17858/33150 (epoch 26.935), train_loss = 1.03535374, grad/param norm = 1.6130e-01, time/batch = 17.8159s	
17859/33150 (epoch 26.937), train_loss = 1.04548964, grad/param norm = 1.5505e-01, time/batch = 16.6382s	
17860/33150 (epoch 26.938), train_loss = 0.98350410, grad/param norm = 1.5827e-01, time/batch = 17.2055s	
17861/33150 (epoch 26.940), train_loss = 1.20128794, grad/param norm = 1.9871e-01, time/batch = 18.8861s	
17862/33150 (epoch 26.941), train_loss = 0.94539976, grad/param norm = 1.3783e-01, time/batch = 17.8157s	
17863/33150 (epoch 26.943), train_loss = 0.79744973, grad/param norm = 1.5636e-01, time/batch = 16.5686s	
17864/33150 (epoch 26.944), train_loss = 1.01217900, grad/param norm = 1.7405e-01, time/batch = 18.3187s	
17865/33150 (epoch 26.946), train_loss = 0.80614126, grad/param norm = 1.3067e-01, time/batch = 17.7879s	
17866/33150 (epoch 26.947), train_loss = 0.97254160, grad/param norm = 1.4606e-01, time/batch = 18.1336s	
17867/33150 (epoch 26.949), train_loss = 1.05412127, grad/param norm = 1.6395e-01, time/batch = 16.2304s	
17868/33150 (epoch 26.950), train_loss = 0.98554557, grad/param norm = 2.0514e-01, time/batch = 19.1458s	
17869/33150 (epoch 26.952), train_loss = 0.85990487, grad/param norm = 1.4697e-01, time/batch = 15.4760s	
17870/33150 (epoch 26.953), train_loss = 0.90091710, grad/param norm = 1.5683e-01, time/batch = 17.7176s	
17871/33150 (epoch 26.955), train_loss = 0.82919258, grad/param norm = 1.7268e-01, time/batch = 19.6371s	
17872/33150 (epoch 26.956), train_loss = 1.01669622, grad/param norm = 1.7017e-01, time/batch = 16.3961s	
17873/33150 (epoch 26.958), train_loss = 0.84980021, grad/param norm = 1.4290e-01, time/batch = 15.2176s	
17874/33150 (epoch 26.959), train_loss = 0.89055413, grad/param norm = 1.5489e-01, time/batch = 17.0485s	
17875/33150 (epoch 26.961), train_loss = 0.86202725, grad/param norm = 1.5138e-01, time/batch = 18.7195s	
17876/33150 (epoch 26.962), train_loss = 0.82212041, grad/param norm = 1.8073e-01, time/batch = 16.4023s	
17877/33150 (epoch 26.964), train_loss = 0.92713652, grad/param norm = 1.5533e-01, time/batch = 17.9880s	
17878/33150 (epoch 26.965), train_loss = 0.92694113, grad/param norm = 1.6692e-01, time/batch = 17.2405s	
17879/33150 (epoch 26.967), train_loss = 0.91313137, grad/param norm = 1.7183e-01, time/batch = 15.8915s	
17880/33150 (epoch 26.968), train_loss = 0.79109354, grad/param norm = 1.4338e-01, time/batch = 16.5798s	
17881/33150 (epoch 26.970), train_loss = 0.87364599, grad/param norm = 1.4851e-01, time/batch = 17.4079s	
17882/33150 (epoch 26.971), train_loss = 0.93088967, grad/param norm = 1.5743e-01, time/batch = 17.8154s	
17883/33150 (epoch 26.973), train_loss = 1.03858773, grad/param norm = 1.6685e-01, time/batch = 16.5729s	
17884/33150 (epoch 26.974), train_loss = 1.06912032, grad/param norm = 1.6712e-01, time/batch = 17.9766s	
17885/33150 (epoch 26.976), train_loss = 1.02036362, grad/param norm = 1.5685e-01, time/batch = 16.6381s	
17886/33150 (epoch 26.977), train_loss = 1.05892731, grad/param norm = 1.6196e-01, time/batch = 16.7099s	
17887/33150 (epoch 26.979), train_loss = 1.02393918, grad/param norm = 1.9413e-01, time/batch = 16.0673s	
17888/33150 (epoch 26.980), train_loss = 1.08734883, grad/param norm = 1.6354e-01, time/batch = 16.4070s	
17889/33150 (epoch 26.982), train_loss = 0.94415498, grad/param norm = 1.8398e-01, time/batch = 18.2139s	
17890/33150 (epoch 26.983), train_loss = 0.84342628, grad/param norm = 1.6091e-01, time/batch = 17.0604s	
17891/33150 (epoch 26.985), train_loss = 1.04268607, grad/param norm = 1.6638e-01, time/batch = 17.9047s	
17892/33150 (epoch 26.986), train_loss = 0.80113349, grad/param norm = 1.6321e-01, time/batch = 18.9918s	
17893/33150 (epoch 26.988), train_loss = 0.92572146, grad/param norm = 2.0446e-01, time/batch = 16.5634s	
17894/33150 (epoch 26.989), train_loss = 0.89827206, grad/param norm = 1.5962e-01, time/batch = 17.5744s	
17895/33150 (epoch 26.991), train_loss = 1.03743528, grad/param norm = 2.5816e-01, time/batch = 18.0785s	
17896/33150 (epoch 26.992), train_loss = 0.89417420, grad/param norm = 1.4986e-01, time/batch = 18.6456s	
17897/33150 (epoch 26.994), train_loss = 0.96302357, grad/param norm = 1.6549e-01, time/batch = 15.1374s	
17898/33150 (epoch 26.995), train_loss = 0.91988402, grad/param norm = 1.6967e-01, time/batch = 15.7152s	
17899/33150 (epoch 26.997), train_loss = 0.93606286, grad/param norm = 2.0147e-01, time/batch = 18.4945s	
17900/33150 (epoch 26.998), train_loss = 0.77185590, grad/param norm = 1.5286e-01, time/batch = 17.1173s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
17901/33150 (epoch 27.000), train_loss = 0.76612731, grad/param norm = 1.4828e-01, time/batch = 16.8293s	
17902/33150 (epoch 27.002), train_loss = 1.23518340, grad/param norm = 1.9102e-01, time/batch = 17.8872s	
17903/33150 (epoch 27.003), train_loss = 0.84027148, grad/param norm = 1.5334e-01, time/batch = 19.0557s	
17904/33150 (epoch 27.005), train_loss = 0.83659820, grad/param norm = 1.5774e-01, time/batch = 17.0538s	
17905/33150 (epoch 27.006), train_loss = 0.80618407, grad/param norm = 1.4868e-01, time/batch = 17.6457s	
17906/33150 (epoch 27.008), train_loss = 1.02499198, grad/param norm = 1.7819e-01, time/batch = 16.7308s	
17907/33150 (epoch 27.009), train_loss = 0.95179053, grad/param norm = 1.5599e-01, time/batch = 17.7685s	
17908/33150 (epoch 27.011), train_loss = 1.04132304, grad/param norm = 1.5757e-01, time/batch = 18.3993s	
17909/33150 (epoch 27.012), train_loss = 0.94090338, grad/param norm = 1.6954e-01, time/batch = 16.9925s	
17910/33150 (epoch 27.014), train_loss = 0.86326125, grad/param norm = 1.6312e-01, time/batch = 17.9735s	
17911/33150 (epoch 27.015), train_loss = 0.86445335, grad/param norm = 1.6158e-01, time/batch = 17.2220s	
17912/33150 (epoch 27.017), train_loss = 0.83878109, grad/param norm = 1.5129e-01, time/batch = 17.0488s	
17913/33150 (epoch 27.018), train_loss = 0.96196407, grad/param norm = 1.8769e-01, time/batch = 17.7330s	
17914/33150 (epoch 27.020), train_loss = 1.01025610, grad/param norm = 1.7882e-01, time/batch = 16.8890s	
17915/33150 (epoch 27.021), train_loss = 0.81859858, grad/param norm = 1.5445e-01, time/batch = 18.4864s	
17916/33150 (epoch 27.023), train_loss = 1.10874398, grad/param norm = 1.6287e-01, time/batch = 16.2119s	
17917/33150 (epoch 27.024), train_loss = 0.98171701, grad/param norm = 1.7068e-01, time/batch = 17.0540s	
17918/33150 (epoch 27.026), train_loss = 0.75016959, grad/param norm = 1.3356e-01, time/batch = 18.1456s	
17919/33150 (epoch 27.027), train_loss = 0.75180958, grad/param norm = 1.2962e-01, time/batch = 17.2373s	
17920/33150 (epoch 27.029), train_loss = 0.86977061, grad/param norm = 1.4459e-01, time/batch = 16.5415s	
17921/33150 (epoch 27.030), train_loss = 0.89968203, grad/param norm = 1.3782e-01, time/batch = 16.2119s	
17922/33150 (epoch 27.032), train_loss = 0.84760984, grad/param norm = 1.7217e-01, time/batch = 16.1380s	
17923/33150 (epoch 27.033), train_loss = 0.87407486, grad/param norm = 1.7082e-01, time/batch = 16.5419s	
17924/33150 (epoch 27.035), train_loss = 1.09460032, grad/param norm = 1.8930e-01, time/batch = 16.7656s	
17925/33150 (epoch 27.036), train_loss = 0.98223338, grad/param norm = 1.8117e-01, time/batch = 14.8023s	
17926/33150 (epoch 27.038), train_loss = 1.13787438, grad/param norm = 1.9410e-01, time/batch = 14.8174s	
17927/33150 (epoch 27.039), train_loss = 1.00512082, grad/param norm = 1.4805e-01, time/batch = 14.9186s	
17928/33150 (epoch 27.041), train_loss = 0.93579773, grad/param norm = 1.5267e-01, time/batch = 15.7500s	
17929/33150 (epoch 27.042), train_loss = 0.89634802, grad/param norm = 1.5846e-01, time/batch = 15.3894s	
17930/33150 (epoch 27.044), train_loss = 0.90740004, grad/param norm = 1.3526e-01, time/batch = 15.4228s	
17931/33150 (epoch 27.045), train_loss = 0.97593794, grad/param norm = 1.5315e-01, time/batch = 15.3467s	
17932/33150 (epoch 27.047), train_loss = 0.83291721, grad/param norm = 1.6880e-01, time/batch = 16.1728s	
17933/33150 (epoch 27.048), train_loss = 1.04546922, grad/param norm = 2.2463e-01, time/batch = 15.4044s	
17934/33150 (epoch 27.050), train_loss = 0.91712891, grad/param norm = 1.7222e-01, time/batch = 15.8436s	
17935/33150 (epoch 27.051), train_loss = 0.93638344, grad/param norm = 1.5609e-01, time/batch = 15.8928s	
17936/33150 (epoch 27.053), train_loss = 0.92578493, grad/param norm = 1.4931e-01, time/batch = 16.2566s	
17937/33150 (epoch 27.054), train_loss = 1.05995960, grad/param norm = 1.5396e-01, time/batch = 16.0706s	
17938/33150 (epoch 27.056), train_loss = 0.92362855, grad/param norm = 1.5949e-01, time/batch = 15.1455s	
17939/33150 (epoch 27.057), train_loss = 0.95771545, grad/param norm = 1.6924e-01, time/batch = 15.4926s	
17940/33150 (epoch 27.059), train_loss = 0.87792001, grad/param norm = 1.7207e-01, time/batch = 15.4929s	
17941/33150 (epoch 27.060), train_loss = 0.85110120, grad/param norm = 1.3985e-01, time/batch = 15.5397s	
17942/33150 (epoch 27.062), train_loss = 0.91336483, grad/param norm = 1.5872e-01, time/batch = 16.4483s	
17943/33150 (epoch 27.063), train_loss = 0.88295138, grad/param norm = 2.3222e-01, time/batch = 16.7073s	
17944/33150 (epoch 27.065), train_loss = 0.89205425, grad/param norm = 1.4318e-01, time/batch = 15.5498s	
17945/33150 (epoch 27.066), train_loss = 0.87418681, grad/param norm = 1.5920e-01, time/batch = 16.0356s	
17946/33150 (epoch 27.068), train_loss = 0.98690377, grad/param norm = 1.6415e-01, time/batch = 15.0908s	
17947/33150 (epoch 27.069), train_loss = 0.97533994, grad/param norm = 1.8777e-01, time/batch = 15.3284s	
17948/33150 (epoch 27.071), train_loss = 0.94317733, grad/param norm = 1.4881e-01, time/batch = 15.0350s	
17949/33150 (epoch 27.072), train_loss = 0.92527834, grad/param norm = 1.5626e-01, time/batch = 15.2115s	
17950/33150 (epoch 27.074), train_loss = 0.80059506, grad/param norm = 1.6290e-01, time/batch = 15.1132s	
17951/33150 (epoch 27.075), train_loss = 0.86040771, grad/param norm = 1.7555e-01, time/batch = 15.3866s	
17952/33150 (epoch 27.077), train_loss = 0.92800830, grad/param norm = 2.1356e-01, time/batch = 15.3696s	
17953/33150 (epoch 27.078), train_loss = 1.05692277, grad/param norm = 1.9365e-01, time/batch = 15.3780s	
17954/33150 (epoch 27.080), train_loss = 1.04781538, grad/param norm = 1.6013e-01, time/batch = 15.0062s	
17955/33150 (epoch 27.081), train_loss = 0.80668441, grad/param norm = 1.6113e-01, time/batch = 15.3763s	
17956/33150 (epoch 27.083), train_loss = 0.72114055, grad/param norm = 1.7988e-01, time/batch = 15.3168s	
17957/33150 (epoch 27.084), train_loss = 0.80744173, grad/param norm = 1.5226e-01, time/batch = 14.8822s	
17958/33150 (epoch 27.086), train_loss = 0.87818079, grad/param norm = 2.1297e-01, time/batch = 14.8026s	
17959/33150 (epoch 27.087), train_loss = 0.83217387, grad/param norm = 1.6349e-01, time/batch = 15.4507s	
17960/33150 (epoch 27.089), train_loss = 0.85320495, grad/param norm = 1.5694e-01, time/batch = 15.1323s	
17961/33150 (epoch 27.090), train_loss = 0.89280626, grad/param norm = 1.6178e-01, time/batch = 15.1914s	
17962/33150 (epoch 27.092), train_loss = 0.88290566, grad/param norm = 1.9348e-01, time/batch = 15.9308s	
17963/33150 (epoch 27.094), train_loss = 0.98086709, grad/param norm = 1.8483e-01, time/batch = 16.2935s	
17964/33150 (epoch 27.095), train_loss = 0.86328342, grad/param norm = 1.4956e-01, time/batch = 17.3792s	
17965/33150 (epoch 27.097), train_loss = 0.80681662, grad/param norm = 1.6949e-01, time/batch = 16.3301s	
17966/33150 (epoch 27.098), train_loss = 1.14588392, grad/param norm = 1.8213e-01, time/batch = 15.6863s	
17967/33150 (epoch 27.100), train_loss = 1.10777810, grad/param norm = 1.7967e-01, time/batch = 15.6748s	
17968/33150 (epoch 27.101), train_loss = 0.85912420, grad/param norm = 1.5353e-01, time/batch = 15.5078s	
17969/33150 (epoch 27.103), train_loss = 0.94239766, grad/param norm = 1.6656e-01, time/batch = 15.4877s	
17970/33150 (epoch 27.104), train_loss = 0.85609346, grad/param norm = 1.5853e-01, time/batch = 15.0491s	
17971/33150 (epoch 27.106), train_loss = 1.03986311, grad/param norm = 1.8451e-01, time/batch = 16.4449s	
17972/33150 (epoch 27.107), train_loss = 1.13560578, grad/param norm = 1.9868e-01, time/batch = 19.1913s	
17973/33150 (epoch 27.109), train_loss = 0.90423262, grad/param norm = 1.3856e-01, time/batch = 16.2699s	
17974/33150 (epoch 27.110), train_loss = 1.03459588, grad/param norm = 1.7009e-01, time/batch = 16.4469s	
17975/33150 (epoch 27.112), train_loss = 0.86413736, grad/param norm = 1.6898e-01, time/batch = 14.9887s	
17976/33150 (epoch 27.113), train_loss = 0.89232704, grad/param norm = 1.7326e-01, time/batch = 14.7055s	
17977/33150 (epoch 27.115), train_loss = 1.10339133, grad/param norm = 1.9246e-01, time/batch = 14.4774s	
17978/33150 (epoch 27.116), train_loss = 0.93699843, grad/param norm = 1.4765e-01, time/batch = 15.0326s	
17979/33150 (epoch 27.118), train_loss = 0.98503081, grad/param norm = 1.8493e-01, time/batch = 14.6360s	
17980/33150 (epoch 27.119), train_loss = 0.99729124, grad/param norm = 1.7661e-01, time/batch = 14.6409s	
17981/33150 (epoch 27.121), train_loss = 0.90049477, grad/param norm = 1.6353e-01, time/batch = 14.6485s	
17982/33150 (epoch 27.122), train_loss = 1.11672723, grad/param norm = 2.3691e-01, time/batch = 14.8252s	
17983/33150 (epoch 27.124), train_loss = 0.79156147, grad/param norm = 1.4085e-01, time/batch = 14.7313s	
17984/33150 (epoch 27.125), train_loss = 1.03069969, grad/param norm = 1.6402e-01, time/batch = 14.4965s	
17985/33150 (epoch 27.127), train_loss = 0.94017130, grad/param norm = 1.6322e-01, time/batch = 14.5590s	
17986/33150 (epoch 27.128), train_loss = 0.99932458, grad/param norm = 1.8216e-01, time/batch = 14.7121s	
17987/33150 (epoch 27.130), train_loss = 0.95252353, grad/param norm = 1.7663e-01, time/batch = 14.5865s	
17988/33150 (epoch 27.131), train_loss = 1.17619152, grad/param norm = 1.8360e-01, time/batch = 14.3887s	
17989/33150 (epoch 27.133), train_loss = 0.87828590, grad/param norm = 1.6657e-01, time/batch = 14.5866s	
17990/33150 (epoch 27.134), train_loss = 1.06261359, grad/param norm = 1.6647e-01, time/batch = 14.6163s	
17991/33150 (epoch 27.136), train_loss = 0.92853315, grad/param norm = 1.7905e-01, time/batch = 14.9092s	
17992/33150 (epoch 27.137), train_loss = 1.01504779, grad/param norm = 1.6228e-01, time/batch = 14.4008s	
17993/33150 (epoch 27.139), train_loss = 1.00097615, grad/param norm = 1.7041e-01, time/batch = 14.6782s	
17994/33150 (epoch 27.140), train_loss = 1.08604673, grad/param norm = 1.7499e-01, time/batch = 15.1089s	
17995/33150 (epoch 27.142), train_loss = 1.02250961, grad/param norm = 1.6998e-01, time/batch = 14.9490s	
17996/33150 (epoch 27.143), train_loss = 0.94925142, grad/param norm = 2.0034e-01, time/batch = 14.7376s	
17997/33150 (epoch 27.145), train_loss = 0.91768745, grad/param norm = 2.0791e-01, time/batch = 14.7094s	
17998/33150 (epoch 27.146), train_loss = 1.03468939, grad/param norm = 2.0342e-01, time/batch = 14.8516s	
17999/33150 (epoch 27.148), train_loss = 1.06604800, grad/param norm = 1.6171e-01, time/batch = 14.7127s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch27.15_1.6629.t7	
18000/33150 (epoch 27.149), train_loss = 0.97413231, grad/param norm = 1.7220e-01, time/batch = 14.7411s	
18001/33150 (epoch 27.151), train_loss = 1.47615000, grad/param norm = 2.0081e-01, time/batch = 15.0511s	
18002/33150 (epoch 27.152), train_loss = 0.91430066, grad/param norm = 1.5148e-01, time/batch = 14.8817s	
18003/33150 (epoch 27.154), train_loss = 0.90918003, grad/param norm = 1.6535e-01, time/batch = 14.9089s	
18004/33150 (epoch 27.155), train_loss = 0.79693227, grad/param norm = 1.5845e-01, time/batch = 14.7274s	
18005/33150 (epoch 27.157), train_loss = 0.93080050, grad/param norm = 1.8433e-01, time/batch = 14.6287s	
18006/33150 (epoch 27.158), train_loss = 0.89082836, grad/param norm = 1.6133e-01, time/batch = 14.7234s	
18007/33150 (epoch 27.160), train_loss = 0.99745532, grad/param norm = 1.6707e-01, time/batch = 14.8771s	
18008/33150 (epoch 27.161), train_loss = 0.87564080, grad/param norm = 1.7596e-01, time/batch = 14.5938s	
18009/33150 (epoch 27.163), train_loss = 0.83304633, grad/param norm = 1.5111e-01, time/batch = 14.9932s	
18010/33150 (epoch 27.164), train_loss = 0.99374108, grad/param norm = 1.7165e-01, time/batch = 15.0906s	
18011/33150 (epoch 27.166), train_loss = 0.91516839, grad/param norm = 1.7485e-01, time/batch = 14.7228s	
18012/33150 (epoch 27.167), train_loss = 0.94462550, grad/param norm = 1.4748e-01, time/batch = 14.4521s	
18013/33150 (epoch 27.169), train_loss = 0.98501017, grad/param norm = 2.1460e-01, time/batch = 14.5530s	
18014/33150 (epoch 27.170), train_loss = 0.88195120, grad/param norm = 2.3371e-01, time/batch = 14.9973s	
18015/33150 (epoch 27.172), train_loss = 1.02051476, grad/param norm = 1.7604e-01, time/batch = 14.6773s	
18016/33150 (epoch 27.173), train_loss = 0.99563357, grad/param norm = 1.9780e-01, time/batch = 14.3148s	
18017/33150 (epoch 27.175), train_loss = 0.89620873, grad/param norm = 1.7557e-01, time/batch = 14.6132s	
18018/33150 (epoch 27.176), train_loss = 0.99957676, grad/param norm = 1.7702e-01, time/batch = 14.8393s	
18019/33150 (epoch 27.178), train_loss = 1.12424011, grad/param norm = 1.7006e-01, time/batch = 14.6291s	
18020/33150 (epoch 27.179), train_loss = 1.00488060, grad/param norm = 1.5570e-01, time/batch = 14.4751s	
18021/33150 (epoch 27.181), train_loss = 0.93992899, grad/param norm = 1.6900e-01, time/batch = 14.5239s	
18022/33150 (epoch 27.183), train_loss = 0.93411163, grad/param norm = 1.7581e-01, time/batch = 14.6301s	
18023/33150 (epoch 27.184), train_loss = 1.17087218, grad/param norm = 1.8366e-01, time/batch = 14.6282s	
18024/33150 (epoch 27.186), train_loss = 1.08444722, grad/param norm = 1.6690e-01, time/batch = 14.9431s	
18025/33150 (epoch 27.187), train_loss = 0.95448516, grad/param norm = 2.0652e-01, time/batch = 15.0235s	
18026/33150 (epoch 27.189), train_loss = 0.75374913, grad/param norm = 1.9089e-01, time/batch = 15.4357s	
18027/33150 (epoch 27.190), train_loss = 0.86489417, grad/param norm = 1.7427e-01, time/batch = 14.8364s	
18028/33150 (epoch 27.192), train_loss = 0.97598273, grad/param norm = 2.0376e-01, time/batch = 14.8059s	
18029/33150 (epoch 27.193), train_loss = 1.03608066, grad/param norm = 1.8061e-01, time/batch = 14.8271s	
18030/33150 (epoch 27.195), train_loss = 1.14128423, grad/param norm = 1.7777e-01, time/batch = 27.5892s	
18031/33150 (epoch 27.196), train_loss = 1.06688620, grad/param norm = 1.7709e-01, time/batch = 14.6384s	
18032/33150 (epoch 27.198), train_loss = 0.82049109, grad/param norm = 1.5862e-01, time/batch = 14.5764s	
18033/33150 (epoch 27.199), train_loss = 1.04507506, grad/param norm = 2.4088e-01, time/batch = 14.7143s	
18034/33150 (epoch 27.201), train_loss = 0.88223404, grad/param norm = 1.4362e-01, time/batch = 14.8813s	
18035/33150 (epoch 27.202), train_loss = 0.75883784, grad/param norm = 1.4636e-01, time/batch = 15.1104s	
18036/33150 (epoch 27.204), train_loss = 1.02001833, grad/param norm = 1.7697e-01, time/batch = 15.0168s	
18037/33150 (epoch 27.205), train_loss = 0.98119663, grad/param norm = 1.5218e-01, time/batch = 15.2098s	
18038/33150 (epoch 27.207), train_loss = 0.99852845, grad/param norm = 1.6387e-01, time/batch = 14.7914s	
18039/33150 (epoch 27.208), train_loss = 1.01278143, grad/param norm = 1.7007e-01, time/batch = 14.9952s	
18040/33150 (epoch 27.210), train_loss = 0.89455901, grad/param norm = 1.4307e-01, time/batch = 14.7807s	
18041/33150 (epoch 27.211), train_loss = 0.96110747, grad/param norm = 1.7904e-01, time/batch = 15.0350s	
18042/33150 (epoch 27.213), train_loss = 1.00401843, grad/param norm = 1.6233e-01, time/batch = 14.7085s	
18043/33150 (epoch 27.214), train_loss = 0.93400079, grad/param norm = 1.7714e-01, time/batch = 14.6771s	
18044/33150 (epoch 27.216), train_loss = 0.88621370, grad/param norm = 1.8665e-01, time/batch = 14.7311s	
18045/33150 (epoch 27.217), train_loss = 0.91559091, grad/param norm = 1.4392e-01, time/batch = 15.1832s	
18046/33150 (epoch 27.219), train_loss = 0.87646670, grad/param norm = 1.6768e-01, time/batch = 14.7956s	
18047/33150 (epoch 27.220), train_loss = 0.89388234, grad/param norm = 1.5126e-01, time/batch = 14.8827s	
18048/33150 (epoch 27.222), train_loss = 1.07858226, grad/param norm = 1.7818e-01, time/batch = 14.7949s	
18049/33150 (epoch 27.223), train_loss = 0.93787547, grad/param norm = 1.6383e-01, time/batch = 15.3380s	
18050/33150 (epoch 27.225), train_loss = 1.07137955, grad/param norm = 1.7013e-01, time/batch = 15.3279s	
18051/33150 (epoch 27.226), train_loss = 0.93529531, grad/param norm = 1.5609e-01, time/batch = 14.8651s	
18052/33150 (epoch 27.228), train_loss = 0.93515991, grad/param norm = 1.6114e-01, time/batch = 14.9925s	
18053/33150 (epoch 27.229), train_loss = 0.93984592, grad/param norm = 1.6708e-01, time/batch = 15.4026s	
18054/33150 (epoch 27.231), train_loss = 1.03920146, grad/param norm = 1.6964e-01, time/batch = 14.8666s	
18055/33150 (epoch 27.232), train_loss = 0.93599014, grad/param norm = 1.8073e-01, time/batch = 14.8720s	
18056/33150 (epoch 27.234), train_loss = 0.96944511, grad/param norm = 1.9081e-01, time/batch = 14.7354s	
18057/33150 (epoch 27.235), train_loss = 1.01218667, grad/param norm = 2.0787e-01, time/batch = 15.0712s	
18058/33150 (epoch 27.237), train_loss = 0.96578965, grad/param norm = 3.0035e-01, time/batch = 14.6486s	
18059/33150 (epoch 27.238), train_loss = 1.00774521, grad/param norm = 1.9586e-01, time/batch = 14.7711s	
18060/33150 (epoch 27.240), train_loss = 0.99181566, grad/param norm = 1.6920e-01, time/batch = 14.8125s	
18061/33150 (epoch 27.241), train_loss = 1.04797199, grad/param norm = 1.9665e-01, time/batch = 15.1554s	
18062/33150 (epoch 27.243), train_loss = 1.00696493, grad/param norm = 1.6547e-01, time/batch = 15.0325s	
18063/33150 (epoch 27.244), train_loss = 0.94301874, grad/param norm = 1.9228e-01, time/batch = 14.7667s	
18064/33150 (epoch 27.246), train_loss = 1.02059583, grad/param norm = 1.8392e-01, time/batch = 14.7700s	
18065/33150 (epoch 27.247), train_loss = 0.90299756, grad/param norm = 1.5575e-01, time/batch = 14.5682s	
18066/33150 (epoch 27.249), train_loss = 1.06712462, grad/param norm = 1.8516e-01, time/batch = 14.4956s	
18067/33150 (epoch 27.250), train_loss = 1.00878646, grad/param norm = 1.5453e-01, time/batch = 14.5612s	
18068/33150 (epoch 27.252), train_loss = 1.01035990, grad/param norm = 1.5328e-01, time/batch = 14.4072s	
18069/33150 (epoch 27.253), train_loss = 0.93142585, grad/param norm = 1.7843e-01, time/batch = 14.7079s	
18070/33150 (epoch 27.255), train_loss = 0.93414325, grad/param norm = 1.4835e-01, time/batch = 14.9628s	
18071/33150 (epoch 27.256), train_loss = 1.02991086, grad/param norm = 1.5286e-01, time/batch = 15.1677s	
18072/33150 (epoch 27.258), train_loss = 0.89691526, grad/param norm = 2.1359e-01, time/batch = 14.6222s	
18073/33150 (epoch 27.259), train_loss = 0.78496860, grad/param norm = 1.5735e-01, time/batch = 14.5927s	
18074/33150 (epoch 27.261), train_loss = 0.84181093, grad/param norm = 1.4246e-01, time/batch = 14.5631s	
18075/33150 (epoch 27.262), train_loss = 1.04765790, grad/param norm = 1.8738e-01, time/batch = 15.0016s	
18076/33150 (epoch 27.264), train_loss = 0.73083673, grad/param norm = 1.3585e-01, time/batch = 14.7148s	
18077/33150 (epoch 27.265), train_loss = 0.97618330, grad/param norm = 1.6050e-01, time/batch = 15.3562s	
18078/33150 (epoch 27.267), train_loss = 1.00547587, grad/param norm = 1.7528e-01, time/batch = 14.7947s	
18079/33150 (epoch 27.268), train_loss = 1.04577362, grad/param norm = 1.5315e-01, time/batch = 14.8000s	
18080/33150 (epoch 27.270), train_loss = 1.13518469, grad/param norm = 1.7728e-01, time/batch = 14.7775s	
18081/33150 (epoch 27.271), train_loss = 1.03941687, grad/param norm = 1.7084e-01, time/batch = 15.1277s	
18082/33150 (epoch 27.273), train_loss = 1.07140242, grad/param norm = 1.8060e-01, time/batch = 14.8567s	
18083/33150 (epoch 27.275), train_loss = 1.09453144, grad/param norm = 1.8043e-01, time/batch = 14.9429s	
18084/33150 (epoch 27.276), train_loss = 0.96616488, grad/param norm = 1.6688e-01, time/batch = 14.7177s	
18085/33150 (epoch 27.278), train_loss = 1.05264974, grad/param norm = 1.4925e-01, time/batch = 14.9620s	
18086/33150 (epoch 27.279), train_loss = 1.00232343, grad/param norm = 1.5221e-01, time/batch = 14.9541s	
18087/33150 (epoch 27.281), train_loss = 0.98117792, grad/param norm = 1.7392e-01, time/batch = 14.8098s	
18088/33150 (epoch 27.282), train_loss = 0.97827245, grad/param norm = 1.3960e-01, time/batch = 14.9532s	
18089/33150 (epoch 27.284), train_loss = 0.87355235, grad/param norm = 1.4806e-01, time/batch = 15.1562s	
18090/33150 (epoch 27.285), train_loss = 0.97284702, grad/param norm = 1.6013e-01, time/batch = 14.6017s	
18091/33150 (epoch 27.287), train_loss = 0.84582966, grad/param norm = 1.4050e-01, time/batch = 14.7945s	
18092/33150 (epoch 27.288), train_loss = 1.04103553, grad/param norm = 1.5846e-01, time/batch = 14.7841s	
18093/33150 (epoch 27.290), train_loss = 0.82930951, grad/param norm = 1.5404e-01, time/batch = 14.6910s	
18094/33150 (epoch 27.291), train_loss = 0.78771332, grad/param norm = 1.5198e-01, time/batch = 14.7057s	
18095/33150 (epoch 27.293), train_loss = 0.98463056, grad/param norm = 1.5906e-01, time/batch = 14.7000s	
18096/33150 (epoch 27.294), train_loss = 0.72819929, grad/param norm = 1.4744e-01, time/batch = 14.4676s	
18097/33150 (epoch 27.296), train_loss = 0.94859259, grad/param norm = 1.5804e-01, time/batch = 14.8038s	
18098/33150 (epoch 27.297), train_loss = 0.89757086, grad/param norm = 1.7893e-01, time/batch = 14.8721s	
18099/33150 (epoch 27.299), train_loss = 0.89426355, grad/param norm = 1.9418e-01, time/batch = 14.5325s	
18100/33150 (epoch 27.300), train_loss = 0.88967173, grad/param norm = 1.3183e-01, time/batch = 14.8232s	
18101/33150 (epoch 27.302), train_loss = 0.92461741, grad/param norm = 1.5572e-01, time/batch = 14.8863s	
18102/33150 (epoch 27.303), train_loss = 0.90105479, grad/param norm = 1.5760e-01, time/batch = 14.9603s	
18103/33150 (epoch 27.305), train_loss = 0.98986059, grad/param norm = 1.5623e-01, time/batch = 14.9651s	
18104/33150 (epoch 27.306), train_loss = 1.01082161, grad/param norm = 1.8571e-01, time/batch = 14.8839s	
18105/33150 (epoch 27.308), train_loss = 1.17977220, grad/param norm = 1.7691e-01, time/batch = 14.9032s	
18106/33150 (epoch 27.309), train_loss = 0.79311784, grad/param norm = 1.4796e-01, time/batch = 14.9207s	
18107/33150 (epoch 27.311), train_loss = 0.92274987, grad/param norm = 1.8332e-01, time/batch = 14.7089s	
18108/33150 (epoch 27.312), train_loss = 0.75535775, grad/param norm = 1.3775e-01, time/batch = 14.8811s	
18109/33150 (epoch 27.314), train_loss = 0.88845414, grad/param norm = 1.5835e-01, time/batch = 15.0281s	
18110/33150 (epoch 27.315), train_loss = 0.98486518, grad/param norm = 1.5157e-01, time/batch = 14.9573s	
18111/33150 (epoch 27.317), train_loss = 0.76974829, grad/param norm = 1.3706e-01, time/batch = 15.2025s	
18112/33150 (epoch 27.318), train_loss = 0.86138025, grad/param norm = 1.3862e-01, time/batch = 14.7039s	
18113/33150 (epoch 27.320), train_loss = 0.80192843, grad/param norm = 1.4550e-01, time/batch = 14.6763s	
18114/33150 (epoch 27.321), train_loss = 0.92210441, grad/param norm = 1.5228e-01, time/batch = 14.9774s	
18115/33150 (epoch 27.323), train_loss = 0.89728159, grad/param norm = 1.4713e-01, time/batch = 14.6524s	
18116/33150 (epoch 27.324), train_loss = 0.97802446, grad/param norm = 1.9973e-01, time/batch = 14.5488s	
18117/33150 (epoch 27.326), train_loss = 0.95884112, grad/param norm = 1.5420e-01, time/batch = 14.7133s	
18118/33150 (epoch 27.327), train_loss = 1.03790515, grad/param norm = 1.5505e-01, time/batch = 14.6200s	
18119/33150 (epoch 27.329), train_loss = 0.98895059, grad/param norm = 1.6944e-01, time/batch = 14.5711s	
18120/33150 (epoch 27.330), train_loss = 0.94728221, grad/param norm = 1.8273e-01, time/batch = 14.7102s	
18121/33150 (epoch 27.332), train_loss = 0.93195266, grad/param norm = 1.4449e-01, time/batch = 14.7038s	
18122/33150 (epoch 27.333), train_loss = 0.98970016, grad/param norm = 1.4078e-01, time/batch = 14.7210s	
18123/33150 (epoch 27.335), train_loss = 0.87422856, grad/param norm = 1.4516e-01, time/batch = 14.6402s	
18124/33150 (epoch 27.336), train_loss = 0.85513610, grad/param norm = 1.5867e-01, time/batch = 14.6311s	
18125/33150 (epoch 27.338), train_loss = 0.80222102, grad/param norm = 1.5654e-01, time/batch = 14.5837s	
18126/33150 (epoch 27.339), train_loss = 1.02149376, grad/param norm = 1.6635e-01, time/batch = 14.5319s	
18127/33150 (epoch 27.341), train_loss = 0.96761704, grad/param norm = 1.7662e-01, time/batch = 15.0176s	
18128/33150 (epoch 27.342), train_loss = 0.85138214, grad/param norm = 1.4914e-01, time/batch = 14.3690s	
18129/33150 (epoch 27.344), train_loss = 0.93680558, grad/param norm = 1.7282e-01, time/batch = 15.0892s	
18130/33150 (epoch 27.345), train_loss = 0.91361723, grad/param norm = 1.6100e-01, time/batch = 14.5859s	
18131/33150 (epoch 27.347), train_loss = 0.75646334, grad/param norm = 1.5191e-01, time/batch = 14.6929s	
18132/33150 (epoch 27.348), train_loss = 0.95619319, grad/param norm = 1.5962e-01, time/batch = 14.5111s	
18133/33150 (epoch 27.350), train_loss = 0.84022556, grad/param norm = 1.6445e-01, time/batch = 14.5341s	
18134/33150 (epoch 27.351), train_loss = 1.01861705, grad/param norm = 1.7265e-01, time/batch = 14.6163s	
18135/33150 (epoch 27.353), train_loss = 0.96442683, grad/param norm = 1.8153e-01, time/batch = 14.7700s	
18136/33150 (epoch 27.354), train_loss = 1.17863125, grad/param norm = 1.7040e-01, time/batch = 14.7454s	
18137/33150 (epoch 27.356), train_loss = 1.02368219, grad/param norm = 1.6745e-01, time/batch = 14.5487s	
18138/33150 (epoch 27.357), train_loss = 0.97393215, grad/param norm = 1.7347e-01, time/batch = 14.7214s	
18139/33150 (epoch 27.359), train_loss = 1.00361812, grad/param norm = 1.7072e-01, time/batch = 14.3799s	
18140/33150 (epoch 27.360), train_loss = 0.99297565, grad/param norm = 1.8907e-01, time/batch = 14.4861s	
18141/33150 (epoch 27.362), train_loss = 1.06453046, grad/param norm = 1.8930e-01, time/batch = 14.5467s	
18142/33150 (epoch 27.363), train_loss = 0.95573441, grad/param norm = 1.5633e-01, time/batch = 14.8726s	
18143/33150 (epoch 27.365), train_loss = 0.92956286, grad/param norm = 1.4363e-01, time/batch = 14.7207s	
18144/33150 (epoch 27.367), train_loss = 0.88674184, grad/param norm = 1.5062e-01, time/batch = 14.8661s	
18145/33150 (epoch 27.368), train_loss = 0.92854738, grad/param norm = 1.7848e-01, time/batch = 14.7509s	
18146/33150 (epoch 27.370), train_loss = 0.95317170, grad/param norm = 1.7235e-01, time/batch = 15.0421s	
18147/33150 (epoch 27.371), train_loss = 0.82735450, grad/param norm = 1.5962e-01, time/batch = 14.8841s	
18148/33150 (epoch 27.373), train_loss = 0.99508176, grad/param norm = 1.8146e-01, time/batch = 15.1263s	
18149/33150 (epoch 27.374), train_loss = 0.90267527, grad/param norm = 1.4234e-01, time/batch = 14.8787s	
18150/33150 (epoch 27.376), train_loss = 1.05486426, grad/param norm = 1.7693e-01, time/batch = 14.9625s	
18151/33150 (epoch 27.377), train_loss = 0.87967423, grad/param norm = 1.5815e-01, time/batch = 14.8136s	
18152/33150 (epoch 27.379), train_loss = 1.00808556, grad/param norm = 1.8172e-01, time/batch = 15.3668s	
18153/33150 (epoch 27.380), train_loss = 1.00145627, grad/param norm = 1.5208e-01, time/batch = 14.8605s	
18154/33150 (epoch 27.382), train_loss = 0.89949445, grad/param norm = 1.5902e-01, time/batch = 14.7706s	
18155/33150 (epoch 27.383), train_loss = 0.86570009, grad/param norm = 1.5244e-01, time/batch = 14.8175s	
18156/33150 (epoch 27.385), train_loss = 0.90219287, grad/param norm = 1.6116e-01, time/batch = 14.7910s	
18157/33150 (epoch 27.386), train_loss = 0.80909828, grad/param norm = 1.4028e-01, time/batch = 14.6432s	
18158/33150 (epoch 27.388), train_loss = 0.88331338, grad/param norm = 1.7132e-01, time/batch = 15.3661s	
18159/33150 (epoch 27.389), train_loss = 0.86819623, grad/param norm = 1.4095e-01, time/batch = 14.6412s	
18160/33150 (epoch 27.391), train_loss = 1.10213792, grad/param norm = 1.6951e-01, time/batch = 14.8061s	
18161/33150 (epoch 27.392), train_loss = 0.90748231, grad/param norm = 1.6126e-01, time/batch = 14.8883s	
18162/33150 (epoch 27.394), train_loss = 0.80115394, grad/param norm = 1.4241e-01, time/batch = 15.2773s	
18163/33150 (epoch 27.395), train_loss = 0.78207186, grad/param norm = 1.6685e-01, time/batch = 14.8923s	
18164/33150 (epoch 27.397), train_loss = 0.65694788, grad/param norm = 1.3310e-01, time/batch = 14.8609s	
18165/33150 (epoch 27.398), train_loss = 0.93776393, grad/param norm = 1.6646e-01, time/batch = 14.7112s	
18166/33150 (epoch 27.400), train_loss = 0.90572060, grad/param norm = 1.3966e-01, time/batch = 14.9644s	
18167/33150 (epoch 27.401), train_loss = 0.81033433, grad/param norm = 1.4260e-01, time/batch = 14.7947s	
18168/33150 (epoch 27.403), train_loss = 0.78792860, grad/param norm = 1.3932e-01, time/batch = 14.7874s	
18169/33150 (epoch 27.404), train_loss = 0.93964701, grad/param norm = 1.5654e-01, time/batch = 14.7088s	
18170/33150 (epoch 27.406), train_loss = 0.88247261, grad/param norm = 1.3433e-01, time/batch = 14.9992s	
18171/33150 (epoch 27.407), train_loss = 0.81843393, grad/param norm = 1.4897e-01, time/batch = 14.4359s	
18172/33150 (epoch 27.409), train_loss = 0.77418433, grad/param norm = 1.4096e-01, time/batch = 14.6024s	
18173/33150 (epoch 27.410), train_loss = 0.94901744, grad/param norm = 1.6531e-01, time/batch = 14.6235s	
18174/33150 (epoch 27.412), train_loss = 0.97622516, grad/param norm = 1.6162e-01, time/batch = 14.6111s	
18175/33150 (epoch 27.413), train_loss = 0.83295535, grad/param norm = 1.4485e-01, time/batch = 14.4403s	
18176/33150 (epoch 27.415), train_loss = 0.94653880, grad/param norm = 1.4969e-01, time/batch = 14.4687s	
18177/33150 (epoch 27.416), train_loss = 0.87690987, grad/param norm = 1.4772e-01, time/batch = 14.6235s	
18178/33150 (epoch 27.418), train_loss = 0.99931822, grad/param norm = 2.6519e-01, time/batch = 14.7832s	
18179/33150 (epoch 27.419), train_loss = 0.89518448, grad/param norm = 1.6315e-01, time/batch = 14.5648s	
18180/33150 (epoch 27.421), train_loss = 0.91596317, grad/param norm = 1.6566e-01, time/batch = 14.3931s	
18181/33150 (epoch 27.422), train_loss = 0.87461455, grad/param norm = 1.3951e-01, time/batch = 14.7959s	
18182/33150 (epoch 27.424), train_loss = 0.86705299, grad/param norm = 1.4739e-01, time/batch = 14.6893s	
18183/33150 (epoch 27.425), train_loss = 0.99363643, grad/param norm = 1.5993e-01, time/batch = 14.6398s	
18184/33150 (epoch 27.427), train_loss = 0.91954344, grad/param norm = 1.3777e-01, time/batch = 14.5017s	
18185/33150 (epoch 27.428), train_loss = 0.91752840, grad/param norm = 1.5895e-01, time/batch = 14.9309s	
18186/33150 (epoch 27.430), train_loss = 0.93649282, grad/param norm = 1.6925e-01, time/batch = 14.7406s	
18187/33150 (epoch 27.431), train_loss = 1.00225158, grad/param norm = 1.9743e-01, time/batch = 14.4660s	
18188/33150 (epoch 27.433), train_loss = 0.90779406, grad/param norm = 1.5804e-01, time/batch = 14.5933s	
18189/33150 (epoch 27.434), train_loss = 0.80777305, grad/param norm = 1.5021e-01, time/batch = 14.3732s	
18190/33150 (epoch 27.436), train_loss = 0.92240114, grad/param norm = 1.5879e-01, time/batch = 14.7879s	
18191/33150 (epoch 27.437), train_loss = 0.94074593, grad/param norm = 1.9196e-01, time/batch = 14.6126s	
18192/33150 (epoch 27.439), train_loss = 1.07413542, grad/param norm = 1.6744e-01, time/batch = 14.5820s	
18193/33150 (epoch 27.440), train_loss = 1.00855133, grad/param norm = 2.1446e-01, time/batch = 14.9833s	
18194/33150 (epoch 27.442), train_loss = 0.81911848, grad/param norm = 1.5318e-01, time/batch = 14.8627s	
18195/33150 (epoch 27.443), train_loss = 0.96228807, grad/param norm = 1.6087e-01, time/batch = 14.6378s	
18196/33150 (epoch 27.445), train_loss = 0.93392241, grad/param norm = 1.6572e-01, time/batch = 14.6168s	
18197/33150 (epoch 27.446), train_loss = 0.96064965, grad/param norm = 1.8442e-01, time/batch = 14.9425s	
18198/33150 (epoch 27.448), train_loss = 1.03594478, grad/param norm = 1.6846e-01, time/batch = 14.6547s	
18199/33150 (epoch 27.449), train_loss = 0.94640897, grad/param norm = 1.5135e-01, time/batch = 14.9820s	
18200/33150 (epoch 27.451), train_loss = 0.92415842, grad/param norm = 1.8352e-01, time/batch = 14.8331s	
18201/33150 (epoch 27.452), train_loss = 1.11789726, grad/param norm = 1.7011e-01, time/batch = 14.5507s	
18202/33150 (epoch 27.454), train_loss = 0.93142306, grad/param norm = 1.6633e-01, time/batch = 14.9931s	
18203/33150 (epoch 27.456), train_loss = 0.83267647, grad/param norm = 1.4136e-01, time/batch = 14.8447s	
18204/33150 (epoch 27.457), train_loss = 0.94474993, grad/param norm = 1.6082e-01, time/batch = 14.7659s	
18205/33150 (epoch 27.459), train_loss = 1.03391313, grad/param norm = 1.9136e-01, time/batch = 14.6423s	
18206/33150 (epoch 27.460), train_loss = 0.97311636, grad/param norm = 1.3684e-01, time/batch = 14.6074s	
18207/33150 (epoch 27.462), train_loss = 1.05096703, grad/param norm = 2.2181e-01, time/batch = 14.7104s	
18208/33150 (epoch 27.463), train_loss = 1.17596947, grad/param norm = 2.3875e-01, time/batch = 14.5525s	
18209/33150 (epoch 27.465), train_loss = 0.97343724, grad/param norm = 1.6916e-01, time/batch = 14.5094s	
18210/33150 (epoch 27.466), train_loss = 0.89252892, grad/param norm = 1.7213e-01, time/batch = 14.9459s	
18211/33150 (epoch 27.468), train_loss = 1.16746973, grad/param norm = 1.8083e-01, time/batch = 15.0036s	
18212/33150 (epoch 27.469), train_loss = 0.93179472, grad/param norm = 1.6713e-01, time/batch = 14.7720s	
18213/33150 (epoch 27.471), train_loss = 0.87438593, grad/param norm = 1.5751e-01, time/batch = 14.9234s	
18214/33150 (epoch 27.472), train_loss = 0.95851896, grad/param norm = 1.8718e-01, time/batch = 15.0299s	
18215/33150 (epoch 27.474), train_loss = 1.04205018, grad/param norm = 2.2314e-01, time/batch = 15.0172s	
18216/33150 (epoch 27.475), train_loss = 1.17680257, grad/param norm = 1.8120e-01, time/batch = 15.0194s	
18217/33150 (epoch 27.477), train_loss = 1.05869643, grad/param norm = 2.0015e-01, time/batch = 14.5488s	
18218/33150 (epoch 27.478), train_loss = 1.02425828, grad/param norm = 1.6505e-01, time/batch = 14.8382s	
18219/33150 (epoch 27.480), train_loss = 0.87884042, grad/param norm = 1.6239e-01, time/batch = 14.5455s	
18220/33150 (epoch 27.481), train_loss = 0.79735321, grad/param norm = 1.6765e-01, time/batch = 14.4331s	
18221/33150 (epoch 27.483), train_loss = 0.89291332, grad/param norm = 1.6333e-01, time/batch = 14.5565s	
18222/33150 (epoch 27.484), train_loss = 0.89343310, grad/param norm = 1.6726e-01, time/batch = 14.6340s	
18223/33150 (epoch 27.486), train_loss = 0.86611169, grad/param norm = 1.6105e-01, time/batch = 14.4645s	
18224/33150 (epoch 27.487), train_loss = 0.96443229, grad/param norm = 1.8423e-01, time/batch = 14.6570s	
18225/33150 (epoch 27.489), train_loss = 0.92923999, grad/param norm = 1.5472e-01, time/batch = 14.5111s	
18226/33150 (epoch 27.490), train_loss = 0.80964376, grad/param norm = 1.5909e-01, time/batch = 14.6103s	
18227/33150 (epoch 27.492), train_loss = 0.89071809, grad/param norm = 1.5967e-01, time/batch = 14.6639s	
18228/33150 (epoch 27.493), train_loss = 1.01851253, grad/param norm = 1.7958e-01, time/batch = 14.7645s	
18229/33150 (epoch 27.495), train_loss = 1.01167165, grad/param norm = 1.5574e-01, time/batch = 15.2102s	
18230/33150 (epoch 27.496), train_loss = 0.91218300, grad/param norm = 1.6625e-01, time/batch = 14.6318s	
18231/33150 (epoch 27.498), train_loss = 1.04466461, grad/param norm = 1.9468e-01, time/batch = 14.9364s	
18232/33150 (epoch 27.499), train_loss = 1.03997086, grad/param norm = 1.7001e-01, time/batch = 14.8903s	
18233/33150 (epoch 27.501), train_loss = 0.99016626, grad/param norm = 1.7505e-01, time/batch = 15.2907s	
18234/33150 (epoch 27.502), train_loss = 1.06246182, grad/param norm = 1.8283e-01, time/batch = 15.1032s	
18235/33150 (epoch 27.504), train_loss = 1.01690224, grad/param norm = 1.8655e-01, time/batch = 14.9597s	
18236/33150 (epoch 27.505), train_loss = 1.11060018, grad/param norm = 1.7920e-01, time/batch = 14.6329s	
18237/33150 (epoch 27.507), train_loss = 0.91557189, grad/param norm = 1.7149e-01, time/batch = 14.7135s	
18238/33150 (epoch 27.508), train_loss = 0.87926080, grad/param norm = 1.7121e-01, time/batch = 14.7720s	
18239/33150 (epoch 27.510), train_loss = 1.00218523, grad/param norm = 1.4992e-01, time/batch = 15.0786s	
18240/33150 (epoch 27.511), train_loss = 1.05463624, grad/param norm = 1.6084e-01, time/batch = 14.9961s	
18241/33150 (epoch 27.513), train_loss = 0.98431936, grad/param norm = 1.7667e-01, time/batch = 16.2776s	
18242/33150 (epoch 27.514), train_loss = 0.78905395, grad/param norm = 1.4760e-01, time/batch = 15.8475s	
18243/33150 (epoch 27.516), train_loss = 0.95391936, grad/param norm = 1.7967e-01, time/batch = 15.9927s	
18244/33150 (epoch 27.517), train_loss = 1.03926338, grad/param norm = 1.8607e-01, time/batch = 15.1629s	
18245/33150 (epoch 27.519), train_loss = 0.86574506, grad/param norm = 1.5649e-01, time/batch = 14.9841s	
18246/33150 (epoch 27.520), train_loss = 0.94774784, grad/param norm = 1.6151e-01, time/batch = 14.8925s	
18247/33150 (epoch 27.522), train_loss = 1.05194659, grad/param norm = 1.8098e-01, time/batch = 14.7380s	
18248/33150 (epoch 27.523), train_loss = 0.85498705, grad/param norm = 1.6337e-01, time/batch = 14.9326s	
18249/33150 (epoch 27.525), train_loss = 0.99553889, grad/param norm = 1.7588e-01, time/batch = 14.6416s	
18250/33150 (epoch 27.526), train_loss = 0.86732443, grad/param norm = 1.6325e-01, time/batch = 14.9076s	
18251/33150 (epoch 27.528), train_loss = 0.99312164, grad/param norm = 1.6191e-01, time/batch = 14.9120s	
18252/33150 (epoch 27.529), train_loss = 0.96176362, grad/param norm = 1.8432e-01, time/batch = 15.2228s	
18253/33150 (epoch 27.531), train_loss = 0.78702327, grad/param norm = 1.7937e-01, time/batch = 15.3586s	
18254/33150 (epoch 27.532), train_loss = 0.95811765, grad/param norm = 1.7450e-01, time/batch = 15.6650s	
18255/33150 (epoch 27.534), train_loss = 0.93094014, grad/param norm = 1.4734e-01, time/batch = 14.8181s	
18256/33150 (epoch 27.535), train_loss = 0.88046388, grad/param norm = 1.9421e-01, time/batch = 15.0041s	
18257/33150 (epoch 27.537), train_loss = 0.97837356, grad/param norm = 1.9012e-01, time/batch = 17.0211s	
18258/33150 (epoch 27.538), train_loss = 0.86255465, grad/param norm = 1.4920e-01, time/batch = 15.8561s	
18259/33150 (epoch 27.540), train_loss = 0.83012145, grad/param norm = 1.5868e-01, time/batch = 15.4375s	
18260/33150 (epoch 27.541), train_loss = 1.04262804, grad/param norm = 1.7613e-01, time/batch = 15.3358s	
18261/33150 (epoch 27.543), train_loss = 0.96277136, grad/param norm = 1.6964e-01, time/batch = 15.8612s	
18262/33150 (epoch 27.544), train_loss = 1.02610032, grad/param norm = 1.7018e-01, time/batch = 14.9417s	
18263/33150 (epoch 27.546), train_loss = 0.96459673, grad/param norm = 1.7843e-01, time/batch = 14.8320s	
18264/33150 (epoch 27.548), train_loss = 0.88698856, grad/param norm = 1.6151e-01, time/batch = 14.6985s	
18265/33150 (epoch 27.549), train_loss = 0.88184171, grad/param norm = 1.6369e-01, time/batch = 15.5184s	
18266/33150 (epoch 27.551), train_loss = 0.87577660, grad/param norm = 1.4441e-01, time/batch = 15.2792s	
18267/33150 (epoch 27.552), train_loss = 0.73715302, grad/param norm = 1.3374e-01, time/batch = 17.4593s	
18268/33150 (epoch 27.554), train_loss = 0.99152262, grad/param norm = 1.5866e-01, time/batch = 14.9602s	
18269/33150 (epoch 27.555), train_loss = 1.04224969, grad/param norm = 1.7041e-01, time/batch = 15.0959s	
18270/33150 (epoch 27.557), train_loss = 0.74774562, grad/param norm = 1.5827e-01, time/batch = 27.7856s	
18271/33150 (epoch 27.558), train_loss = 0.98760782, grad/param norm = 1.9623e-01, time/batch = 14.9854s	
18272/33150 (epoch 27.560), train_loss = 0.88245975, grad/param norm = 1.5785e-01, time/batch = 14.8272s	
18273/33150 (epoch 27.561), train_loss = 0.79320498, grad/param norm = 1.5407e-01, time/batch = 15.0741s	
18274/33150 (epoch 27.563), train_loss = 0.99764013, grad/param norm = 1.9483e-01, time/batch = 14.6502s	
18275/33150 (epoch 27.564), train_loss = 1.08440668, grad/param norm = 1.6459e-01, time/batch = 14.4772s	
18276/33150 (epoch 27.566), train_loss = 0.88866898, grad/param norm = 1.6911e-01, time/batch = 14.5585s	
18277/33150 (epoch 27.567), train_loss = 0.86632070, grad/param norm = 1.7197e-01, time/batch = 14.9805s	
18278/33150 (epoch 27.569), train_loss = 0.97871058, grad/param norm = 1.6385e-01, time/batch = 14.6411s	
18279/33150 (epoch 27.570), train_loss = 1.00270394, grad/param norm = 1.6198e-01, time/batch = 14.5585s	
18280/33150 (epoch 27.572), train_loss = 0.86088726, grad/param norm = 1.6842e-01, time/batch = 14.5679s	
18281/33150 (epoch 27.573), train_loss = 0.76247503, grad/param norm = 1.2542e-01, time/batch = 15.4628s	
18282/33150 (epoch 27.575), train_loss = 0.91836938, grad/param norm = 1.6157e-01, time/batch = 14.8819s	
18283/33150 (epoch 27.576), train_loss = 0.82438401, grad/param norm = 1.4302e-01, time/batch = 14.8914s	
18284/33150 (epoch 27.578), train_loss = 0.86488476, grad/param norm = 1.4845e-01, time/batch = 14.8189s	
18285/33150 (epoch 27.579), train_loss = 0.80216623, grad/param norm = 1.4974e-01, time/batch = 15.2971s	
18286/33150 (epoch 27.581), train_loss = 0.84810161, grad/param norm = 1.5352e-01, time/batch = 15.2287s	
18287/33150 (epoch 27.582), train_loss = 1.06614705, grad/param norm = 1.5073e-01, time/batch = 14.8060s	
18288/33150 (epoch 27.584), train_loss = 1.00784898, grad/param norm = 1.7100e-01, time/batch = 14.8884s	
18289/33150 (epoch 27.585), train_loss = 0.94848835, grad/param norm = 1.5888e-01, time/batch = 15.3039s	
18290/33150 (epoch 27.587), train_loss = 0.93603015, grad/param norm = 1.5132e-01, time/batch = 15.4327s	
18291/33150 (epoch 27.588), train_loss = 0.86174885, grad/param norm = 1.5583e-01, time/batch = 16.2875s	
18292/33150 (epoch 27.590), train_loss = 0.97327695, grad/param norm = 1.6213e-01, time/batch = 16.2044s	
18293/33150 (epoch 27.591), train_loss = 0.90931166, grad/param norm = 1.5635e-01, time/batch = 16.3539s	
18294/33150 (epoch 27.593), train_loss = 0.98108785, grad/param norm = 1.7515e-01, time/batch = 16.1255s	
18295/33150 (epoch 27.594), train_loss = 0.92745906, grad/param norm = 1.8857e-01, time/batch = 14.6609s	
18296/33150 (epoch 27.596), train_loss = 0.91114801, grad/param norm = 1.5757e-01, time/batch = 16.1981s	
18297/33150 (epoch 27.597), train_loss = 0.83133399, grad/param norm = 2.1449e-01, time/batch = 16.1174s	
18298/33150 (epoch 27.599), train_loss = 1.10562647, grad/param norm = 2.0532e-01, time/batch = 15.2125s	
18299/33150 (epoch 27.600), train_loss = 0.94552880, grad/param norm = 2.3443e-01, time/batch = 14.6937s	
18300/33150 (epoch 27.602), train_loss = 0.91725275, grad/param norm = 1.5845e-01, time/batch = 15.1532s	
18301/33150 (epoch 27.603), train_loss = 1.03536550, grad/param norm = 1.7251e-01, time/batch = 15.3587s	
18302/33150 (epoch 27.605), train_loss = 0.84391705, grad/param norm = 1.7048e-01, time/batch = 15.2920s	
18303/33150 (epoch 27.606), train_loss = 0.85820960, grad/param norm = 1.7361e-01, time/batch = 15.8635s	
18304/33150 (epoch 27.608), train_loss = 1.00639115, grad/param norm = 1.5320e-01, time/batch = 15.3687s	
18305/33150 (epoch 27.609), train_loss = 0.91952038, grad/param norm = 1.8117e-01, time/batch = 15.7017s	
18306/33150 (epoch 27.611), train_loss = 0.83904053, grad/param norm = 1.6779e-01, time/batch = 16.2831s	
18307/33150 (epoch 27.612), train_loss = 0.94794962, grad/param norm = 1.7486e-01, time/batch = 17.3682s	
18308/33150 (epoch 27.614), train_loss = 0.84008888, grad/param norm = 1.4144e-01, time/batch = 15.0143s	
18309/33150 (epoch 27.615), train_loss = 0.82831485, grad/param norm = 1.4832e-01, time/batch = 14.7533s	
18310/33150 (epoch 27.617), train_loss = 0.97064377, grad/param norm = 1.9243e-01, time/batch = 15.5371s	
18311/33150 (epoch 27.618), train_loss = 0.97774955, grad/param norm = 2.0968e-01, time/batch = 15.5321s	
18312/33150 (epoch 27.620), train_loss = 0.86843055, grad/param norm = 1.5771e-01, time/batch = 16.4704s	
18313/33150 (epoch 27.621), train_loss = 0.92527074, grad/param norm = 1.4970e-01, time/batch = 16.1228s	
18314/33150 (epoch 27.623), train_loss = 1.00149288, grad/param norm = 1.5653e-01, time/batch = 15.6412s	
18315/33150 (epoch 27.624), train_loss = 0.88402838, grad/param norm = 1.5432e-01, time/batch = 15.5963s	
18316/33150 (epoch 27.626), train_loss = 0.90393934, grad/param norm = 1.6535e-01, time/batch = 15.1504s	
18317/33150 (epoch 27.627), train_loss = 0.84348800, grad/param norm = 2.2775e-01, time/batch = 16.8517s	
18318/33150 (epoch 27.629), train_loss = 0.79343461, grad/param norm = 1.4927e-01, time/batch = 16.0397s	
18319/33150 (epoch 27.630), train_loss = 0.89520006, grad/param norm = 1.5345e-01, time/batch = 16.2033s	
18320/33150 (epoch 27.632), train_loss = 0.79595597, grad/param norm = 1.3757e-01, time/batch = 16.2112s	
18321/33150 (epoch 27.633), train_loss = 0.81394404, grad/param norm = 1.7842e-01, time/batch = 16.4446s	
18322/33150 (epoch 27.635), train_loss = 1.07435654, grad/param norm = 1.6840e-01, time/batch = 16.7914s	
18323/33150 (epoch 27.637), train_loss = 0.77921450, grad/param norm = 1.5876e-01, time/batch = 15.6766s	
18324/33150 (epoch 27.638), train_loss = 0.88982331, grad/param norm = 1.4978e-01, time/batch = 15.1874s	
18325/33150 (epoch 27.640), train_loss = 0.98492110, grad/param norm = 1.6934e-01, time/batch = 15.8087s	
18326/33150 (epoch 27.641), train_loss = 0.81586323, grad/param norm = 1.7543e-01, time/batch = 16.8028s	
18327/33150 (epoch 27.643), train_loss = 0.92140570, grad/param norm = 1.5869e-01, time/batch = 15.3618s	
18328/33150 (epoch 27.644), train_loss = 1.05789160, grad/param norm = 1.5493e-01, time/batch = 16.1133s	
18329/33150 (epoch 27.646), train_loss = 0.90374976, grad/param norm = 2.1385e-01, time/batch = 15.5614s	
18330/33150 (epoch 27.647), train_loss = 1.12538655, grad/param norm = 1.8157e-01, time/batch = 15.8868s	
18331/33150 (epoch 27.649), train_loss = 0.99299902, grad/param norm = 1.7939e-01, time/batch = 14.7704s	
18332/33150 (epoch 27.650), train_loss = 0.83211913, grad/param norm = 1.4568e-01, time/batch = 16.4399s	
18333/33150 (epoch 27.652), train_loss = 1.05023833, grad/param norm = 1.9118e-01, time/batch = 16.9498s	
18334/33150 (epoch 27.653), train_loss = 0.97122165, grad/param norm = 1.6052e-01, time/batch = 15.5393s	
18335/33150 (epoch 27.655), train_loss = 0.97025804, grad/param norm = 1.8152e-01, time/batch = 14.8759s	
18336/33150 (epoch 27.656), train_loss = 0.88675700, grad/param norm = 1.3908e-01, time/batch = 15.0360s	
18337/33150 (epoch 27.658), train_loss = 0.90192808, grad/param norm = 1.7096e-01, time/batch = 16.1115s	
18338/33150 (epoch 27.659), train_loss = 1.16309057, grad/param norm = 2.6070e-01, time/batch = 14.7635s	
18339/33150 (epoch 27.661), train_loss = 0.92816032, grad/param norm = 1.8243e-01, time/batch = 16.1144s	
18340/33150 (epoch 27.662), train_loss = 0.88660050, grad/param norm = 1.9689e-01, time/batch = 16.0638s	
18341/33150 (epoch 27.664), train_loss = 1.03605559, grad/param norm = 1.8406e-01, time/batch = 17.5878s	
18342/33150 (epoch 27.665), train_loss = 1.01339109, grad/param norm = 1.7306e-01, time/batch = 16.4323s	
18343/33150 (epoch 27.667), train_loss = 1.06355654, grad/param norm = 2.0487e-01, time/batch = 16.5356s	
18344/33150 (epoch 27.668), train_loss = 1.05026631, grad/param norm = 1.7483e-01, time/batch = 16.9491s	
18345/33150 (epoch 27.670), train_loss = 0.86919351, grad/param norm = 1.4208e-01, time/batch = 16.8595s	
18346/33150 (epoch 27.671), train_loss = 0.89340634, grad/param norm = 1.5356e-01, time/batch = 15.3257s	
18347/33150 (epoch 27.673), train_loss = 1.06574009, grad/param norm = 1.5160e-01, time/batch = 17.3546s	
18348/33150 (epoch 27.674), train_loss = 0.97981324, grad/param norm = 1.7142e-01, time/batch = 16.1783s	
18349/33150 (epoch 27.676), train_loss = 0.92932317, grad/param norm = 1.6096e-01, time/batch = 15.3721s	
18350/33150 (epoch 27.677), train_loss = 1.10245127, grad/param norm = 1.8425e-01, time/batch = 17.2668s	
18351/33150 (epoch 27.679), train_loss = 0.93331033, grad/param norm = 1.5659e-01, time/batch = 17.4611s	
18352/33150 (epoch 27.680), train_loss = 1.04796106, grad/param norm = 1.8985e-01, time/batch = 16.1675s	
18353/33150 (epoch 27.682), train_loss = 0.91871533, grad/param norm = 1.5815e-01, time/batch = 17.0501s	
18354/33150 (epoch 27.683), train_loss = 0.79967184, grad/param norm = 1.4233e-01, time/batch = 15.6464s	
18355/33150 (epoch 27.685), train_loss = 0.89551862, grad/param norm = 1.8306e-01, time/batch = 19.2010s	
18356/33150 (epoch 27.686), train_loss = 0.80133631, grad/param norm = 1.5209e-01, time/batch = 15.4610s	
18357/33150 (epoch 27.688), train_loss = 0.82871275, grad/param norm = 1.5166e-01, time/batch = 15.0450s	
18358/33150 (epoch 27.689), train_loss = 0.84776233, grad/param norm = 1.4096e-01, time/batch = 16.4644s	
18359/33150 (epoch 27.691), train_loss = 0.74983832, grad/param norm = 1.4967e-01, time/batch = 15.7772s	
18360/33150 (epoch 27.692), train_loss = 0.83170638, grad/param norm = 1.6629e-01, time/batch = 15.0321s	
18361/33150 (epoch 27.694), train_loss = 0.72599874, grad/param norm = 1.4528e-01, time/batch = 19.2090s	
18362/33150 (epoch 27.695), train_loss = 0.87613776, grad/param norm = 1.4451e-01, time/batch = 17.0316s	
18363/33150 (epoch 27.697), train_loss = 0.79295276, grad/param norm = 1.3661e-01, time/batch = 17.4487s	
18364/33150 (epoch 27.698), train_loss = 0.85716828, grad/param norm = 2.3799e-01, time/batch = 16.3768s	
18365/33150 (epoch 27.700), train_loss = 0.71448689, grad/param norm = 1.3346e-01, time/batch = 15.2227s	
18366/33150 (epoch 27.701), train_loss = 0.81129734, grad/param norm = 1.4310e-01, time/batch = 17.8715s	
18367/33150 (epoch 27.703), train_loss = 0.91724238, grad/param norm = 1.7167e-01, time/batch = 15.5218s	
18368/33150 (epoch 27.704), train_loss = 0.79857514, grad/param norm = 1.5241e-01, time/batch = 15.5412s	
18369/33150 (epoch 27.706), train_loss = 0.87171255, grad/param norm = 1.5526e-01, time/batch = 16.0226s	
18370/33150 (epoch 27.707), train_loss = 0.87082345, grad/param norm = 1.5721e-01, time/batch = 14.9821s	
18371/33150 (epoch 27.709), train_loss = 0.90832783, grad/param norm = 1.3591e-01, time/batch = 15.0568s	
18372/33150 (epoch 27.710), train_loss = 0.89860805, grad/param norm = 1.6171e-01, time/batch = 15.0596s	
18373/33150 (epoch 27.712), train_loss = 0.97603015, grad/param norm = 1.6030e-01, time/batch = 15.0336s	
18374/33150 (epoch 27.713), train_loss = 0.95232204, grad/param norm = 1.5382e-01, time/batch = 15.0158s	
18375/33150 (epoch 27.715), train_loss = 0.87834443, grad/param norm = 1.4368e-01, time/batch = 14.7023s	
18376/33150 (epoch 27.716), train_loss = 0.96456185, grad/param norm = 1.6163e-01, time/batch = 15.3022s	
18377/33150 (epoch 27.718), train_loss = 0.94308045, grad/param norm = 1.5632e-01, time/batch = 14.8134s	
18378/33150 (epoch 27.719), train_loss = 1.02006272, grad/param norm = 1.8178e-01, time/batch = 15.6004s	
18379/33150 (epoch 27.721), train_loss = 0.88876450, grad/param norm = 1.7070e-01, time/batch = 15.3950s	
18380/33150 (epoch 27.722), train_loss = 0.94429874, grad/param norm = 1.5744e-01, time/batch = 18.5134s	
18381/33150 (epoch 27.724), train_loss = 0.92107172, grad/param norm = 1.7724e-01, time/batch = 18.5414s	
18382/33150 (epoch 27.725), train_loss = 1.02283343, grad/param norm = 2.0905e-01, time/batch = 17.4529s	
18383/33150 (epoch 27.727), train_loss = 0.99336302, grad/param norm = 2.0442e-01, time/batch = 16.4492s	
18384/33150 (epoch 27.729), train_loss = 0.91687037, grad/param norm = 1.6569e-01, time/batch = 16.1409s	
18385/33150 (epoch 27.730), train_loss = 0.92336001, grad/param norm = 1.6523e-01, time/batch = 19.3498s	
18386/33150 (epoch 27.732), train_loss = 0.99876530, grad/param norm = 1.7244e-01, time/batch = 15.6197s	
18387/33150 (epoch 27.733), train_loss = 0.77849725, grad/param norm = 1.3055e-01, time/batch = 17.9400s	
18388/33150 (epoch 27.735), train_loss = 0.82589494, grad/param norm = 1.4109e-01, time/batch = 18.0471s	
18389/33150 (epoch 27.736), train_loss = 0.90221552, grad/param norm = 1.5995e-01, time/batch = 16.0489s	
18390/33150 (epoch 27.738), train_loss = 0.92293756, grad/param norm = 1.7062e-01, time/batch = 15.8596s	
18391/33150 (epoch 27.739), train_loss = 1.03188323, grad/param norm = 1.9942e-01, time/batch = 18.4147s	
18392/33150 (epoch 27.741), train_loss = 1.01325233, grad/param norm = 1.8359e-01, time/batch = 15.1494s	
18393/33150 (epoch 27.742), train_loss = 0.77913620, grad/param norm = 1.4772e-01, time/batch = 16.0966s	
18394/33150 (epoch 27.744), train_loss = 1.01888472, grad/param norm = 1.8148e-01, time/batch = 15.5929s	
18395/33150 (epoch 27.745), train_loss = 0.87734009, grad/param norm = 1.3836e-01, time/batch = 17.4830s	
18396/33150 (epoch 27.747), train_loss = 0.72283297, grad/param norm = 1.6063e-01, time/batch = 16.9645s	
18397/33150 (epoch 27.748), train_loss = 0.81911837, grad/param norm = 1.5164e-01, time/batch = 16.9765s	
18398/33150 (epoch 27.750), train_loss = 0.94891361, grad/param norm = 1.6686e-01, time/batch = 16.1274s	
18399/33150 (epoch 27.751), train_loss = 0.91669148, grad/param norm = 1.5553e-01, time/batch = 16.8153s	
18400/33150 (epoch 27.753), train_loss = 0.78672972, grad/param norm = 1.8211e-01, time/batch = 15.2619s	
18401/33150 (epoch 27.754), train_loss = 1.12711940, grad/param norm = 2.2409e-01, time/batch = 15.5558s	
18402/33150 (epoch 27.756), train_loss = 0.92753389, grad/param norm = 1.8662e-01, time/batch = 16.2943s	
18403/33150 (epoch 27.757), train_loss = 0.93309695, grad/param norm = 1.5719e-01, time/batch = 17.4654s	
18404/33150 (epoch 27.759), train_loss = 1.05768258, grad/param norm = 2.1607e-01, time/batch = 15.8891s	
18405/33150 (epoch 27.760), train_loss = 0.97294588, grad/param norm = 1.7368e-01, time/batch = 16.9032s	
18406/33150 (epoch 27.762), train_loss = 0.93940843, grad/param norm = 1.8756e-01, time/batch = 17.8762s	
18407/33150 (epoch 27.763), train_loss = 0.95187969, grad/param norm = 1.6190e-01, time/batch = 16.8706s	
18408/33150 (epoch 27.765), train_loss = 0.91323820, grad/param norm = 1.4753e-01, time/batch = 17.0479s	
18409/33150 (epoch 27.766), train_loss = 0.83295332, grad/param norm = 1.6007e-01, time/batch = 17.0355s	
18410/33150 (epoch 27.768), train_loss = 0.84199838, grad/param norm = 1.4564e-01, time/batch = 17.2120s	
18411/33150 (epoch 27.769), train_loss = 0.95480854, grad/param norm = 1.6972e-01, time/batch = 15.5530s	
18412/33150 (epoch 27.771), train_loss = 0.93712327, grad/param norm = 2.0101e-01, time/batch = 14.9614s	
18413/33150 (epoch 27.772), train_loss = 0.99836522, grad/param norm = 1.8425e-01, time/batch = 15.6040s	
18414/33150 (epoch 27.774), train_loss = 1.07557962, grad/param norm = 1.7452e-01, time/batch = 15.3519s	
18415/33150 (epoch 27.775), train_loss = 0.98920213, grad/param norm = 2.2251e-01, time/batch = 15.4471s	
18416/33150 (epoch 27.777), train_loss = 0.99984401, grad/param norm = 1.6733e-01, time/batch = 14.8209s	
18417/33150 (epoch 27.778), train_loss = 0.93944040, grad/param norm = 1.5912e-01, time/batch = 17.0639s	
18418/33150 (epoch 27.780), train_loss = 0.81084752, grad/param norm = 1.5558e-01, time/batch = 15.8828s	
18419/33150 (epoch 27.781), train_loss = 0.93177555, grad/param norm = 1.5885e-01, time/batch = 15.3081s	
18420/33150 (epoch 27.783), train_loss = 0.92410085, grad/param norm = 1.5667e-01, time/batch = 15.2230s	
18421/33150 (epoch 27.784), train_loss = 0.93157315, grad/param norm = 1.7208e-01, time/batch = 16.8876s	
18422/33150 (epoch 27.786), train_loss = 0.90427823, grad/param norm = 1.5429e-01, time/batch = 15.1147s	
18423/33150 (epoch 27.787), train_loss = 0.85744303, grad/param norm = 1.3728e-01, time/batch = 16.7821s	
18424/33150 (epoch 27.789), train_loss = 0.76157055, grad/param norm = 1.5445e-01, time/batch = 14.7468s	
18425/33150 (epoch 27.790), train_loss = 0.82844405, grad/param norm = 1.5001e-01, time/batch = 16.2110s	
18426/33150 (epoch 27.792), train_loss = 0.93873760, grad/param norm = 1.7526e-01, time/batch = 15.2273s	
18427/33150 (epoch 27.793), train_loss = 0.89292334, grad/param norm = 1.6957e-01, time/batch = 16.3276s	
18428/33150 (epoch 27.795), train_loss = 0.88133739, grad/param norm = 1.6512e-01, time/batch = 18.9736s	
18429/33150 (epoch 27.796), train_loss = 0.88538018, grad/param norm = 1.4197e-01, time/batch = 15.9804s	
18430/33150 (epoch 27.798), train_loss = 0.86590486, grad/param norm = 1.5358e-01, time/batch = 16.9653s	
18431/33150 (epoch 27.799), train_loss = 0.76388809, grad/param norm = 1.8103e-01, time/batch = 17.7288s	
18432/33150 (epoch 27.801), train_loss = 0.92907514, grad/param norm = 1.6697e-01, time/batch = 17.8695s	
18433/33150 (epoch 27.802), train_loss = 0.86045302, grad/param norm = 1.7724e-01, time/batch = 16.1113s	
18434/33150 (epoch 27.804), train_loss = 0.88908935, grad/param norm = 1.5965e-01, time/batch = 17.8706s	
18435/33150 (epoch 27.805), train_loss = 0.84581344, grad/param norm = 1.5228e-01, time/batch = 17.1258s	
18436/33150 (epoch 27.807), train_loss = 0.89300038, grad/param norm = 1.5411e-01, time/batch = 17.7833s	
18437/33150 (epoch 27.808), train_loss = 1.00127359, grad/param norm = 1.7506e-01, time/batch = 17.7929s	
18438/33150 (epoch 27.810), train_loss = 0.85500931, grad/param norm = 1.7658e-01, time/batch = 17.5604s	
18439/33150 (epoch 27.811), train_loss = 0.94689789, grad/param norm = 1.8032e-01, time/batch = 18.2004s	
18440/33150 (epoch 27.813), train_loss = 0.88193535, grad/param norm = 1.5007e-01, time/batch = 16.3137s	
18441/33150 (epoch 27.814), train_loss = 0.86317309, grad/param norm = 1.9145e-01, time/batch = 17.3910s	
18442/33150 (epoch 27.816), train_loss = 0.89742640, grad/param norm = 1.7266e-01, time/batch = 17.2918s	
18443/33150 (epoch 27.817), train_loss = 0.96560171, grad/param norm = 1.5822e-01, time/batch = 16.7137s	
18444/33150 (epoch 27.819), train_loss = 0.94088163, grad/param norm = 1.5976e-01, time/batch = 16.6504s	
18445/33150 (epoch 27.821), train_loss = 0.81053941, grad/param norm = 1.5122e-01, time/batch = 17.6313s	
18446/33150 (epoch 27.822), train_loss = 0.84728375, grad/param norm = 1.3457e-01, time/batch = 18.5478s	
18447/33150 (epoch 27.824), train_loss = 0.90404764, grad/param norm = 1.5573e-01, time/batch = 16.8845s	
18448/33150 (epoch 27.825), train_loss = 0.95063715, grad/param norm = 1.7610e-01, time/batch = 16.5673s	
18449/33150 (epoch 27.827), train_loss = 0.98309876, grad/param norm = 1.9393e-01, time/batch = 17.0446s	
18450/33150 (epoch 27.828), train_loss = 0.81422152, grad/param norm = 1.5651e-01, time/batch = 16.0433s	
18451/33150 (epoch 27.830), train_loss = 0.99485874, grad/param norm = 1.9456e-01, time/batch = 17.7940s	
18452/33150 (epoch 27.831), train_loss = 0.84697238, grad/param norm = 1.5751e-01, time/batch = 18.7188s	
18453/33150 (epoch 27.833), train_loss = 0.83371785, grad/param norm = 1.6020e-01, time/batch = 18.5305s	
18454/33150 (epoch 27.834), train_loss = 0.99497777, grad/param norm = 1.5760e-01, time/batch = 18.4491s	
18455/33150 (epoch 27.836), train_loss = 1.02351797, grad/param norm = 1.4555e-01, time/batch = 17.6423s	
18456/33150 (epoch 27.837), train_loss = 0.87304571, grad/param norm = 1.6452e-01, time/batch = 17.4743s	
18457/33150 (epoch 27.839), train_loss = 0.97541425, grad/param norm = 1.7546e-01, time/batch = 16.3987s	
18458/33150 (epoch 27.840), train_loss = 0.98717092, grad/param norm = 1.5037e-01, time/batch = 19.3808s	
18459/33150 (epoch 27.842), train_loss = 1.06220198, grad/param norm = 2.0586e-01, time/batch = 16.0372s	
18460/33150 (epoch 27.843), train_loss = 1.00652107, grad/param norm = 1.7531e-01, time/batch = 17.0854s	
18461/33150 (epoch 27.845), train_loss = 0.84925162, grad/param norm = 1.4888e-01, time/batch = 18.3006s	
18462/33150 (epoch 27.846), train_loss = 1.09976446, grad/param norm = 2.4034e-01, time/batch = 16.7338s	
18463/33150 (epoch 27.848), train_loss = 1.00457954, grad/param norm = 1.8189e-01, time/batch = 16.7422s	
18464/33150 (epoch 27.849), train_loss = 1.04705435, grad/param norm = 1.7900e-01, time/batch = 16.0498s	
18465/33150 (epoch 27.851), train_loss = 1.00457341, grad/param norm = 2.0317e-01, time/batch = 15.7947s	
18466/33150 (epoch 27.852), train_loss = 1.07501353, grad/param norm = 1.7994e-01, time/batch = 18.3737s	
18467/33150 (epoch 27.854), train_loss = 0.94396824, grad/param norm = 1.4681e-01, time/batch = 17.4622s	
18468/33150 (epoch 27.855), train_loss = 0.81346945, grad/param norm = 1.6114e-01, time/batch = 16.8837s	
18469/33150 (epoch 27.857), train_loss = 0.77320562, grad/param norm = 1.5086e-01, time/batch = 17.6936s	
18470/33150 (epoch 27.858), train_loss = 0.87729988, grad/param norm = 1.7986e-01, time/batch = 18.7092s	
18471/33150 (epoch 27.860), train_loss = 0.82961528, grad/param norm = 1.5596e-01, time/batch = 15.8685s	
18472/33150 (epoch 27.861), train_loss = 0.82346524, grad/param norm = 1.4955e-01, time/batch = 16.4710s	
18473/33150 (epoch 27.863), train_loss = 0.91002641, grad/param norm = 1.5321e-01, time/batch = 17.7162s	
18474/33150 (epoch 27.864), train_loss = 0.96537170, grad/param norm = 1.5513e-01, time/batch = 19.2020s	
18475/33150 (epoch 27.866), train_loss = 0.98431007, grad/param norm = 1.6413e-01, time/batch = 16.9715s	
18476/33150 (epoch 27.867), train_loss = 0.97406108, grad/param norm = 1.6991e-01, time/batch = 17.4692s	
18477/33150 (epoch 27.869), train_loss = 0.97331009, grad/param norm = 1.7763e-01, time/batch = 16.6284s	
18478/33150 (epoch 27.870), train_loss = 0.87414540, grad/param norm = 1.6721e-01, time/batch = 17.3856s	
18479/33150 (epoch 27.872), train_loss = 0.95381593, grad/param norm = 1.6173e-01, time/batch = 16.1273s	
18480/33150 (epoch 27.873), train_loss = 0.76781135, grad/param norm = 1.3290e-01, time/batch = 17.9782s	
18481/33150 (epoch 27.875), train_loss = 1.04393992, grad/param norm = 1.8460e-01, time/batch = 16.5231s	
18482/33150 (epoch 27.876), train_loss = 0.79364277, grad/param norm = 1.6445e-01, time/batch = 16.2294s	
18483/33150 (epoch 27.878), train_loss = 0.84769962, grad/param norm = 1.4390e-01, time/batch = 18.5350s	
18484/33150 (epoch 27.879), train_loss = 0.84909460, grad/param norm = 1.4286e-01, time/batch = 18.0444s	
18485/33150 (epoch 27.881), train_loss = 0.84414583, grad/param norm = 1.6802e-01, time/batch = 15.7096s	
18486/33150 (epoch 27.882), train_loss = 0.75407800, grad/param norm = 1.5066e-01, time/batch = 17.4796s	
18487/33150 (epoch 27.884), train_loss = 0.89090131, grad/param norm = 1.4812e-01, time/batch = 16.4753s	
18488/33150 (epoch 27.885), train_loss = 0.69987007, grad/param norm = 1.5539e-01, time/batch = 25.6859s	
18489/33150 (epoch 27.887), train_loss = 1.02374385, grad/param norm = 1.8867e-01, time/batch = 22.3961s	
18490/33150 (epoch 27.888), train_loss = 0.96401966, grad/param norm = 1.7060e-01, time/batch = 18.2872s	
18491/33150 (epoch 27.890), train_loss = 0.84517837, grad/param norm = 1.5590e-01, time/batch = 17.0358s	
18492/33150 (epoch 27.891), train_loss = 0.82155755, grad/param norm = 1.6565e-01, time/batch = 18.4703s	
18493/33150 (epoch 27.893), train_loss = 0.97466809, grad/param norm = 1.8095e-01, time/batch = 16.6251s	
18494/33150 (epoch 27.894), train_loss = 0.95032537, grad/param norm = 1.6003e-01, time/batch = 16.5448s	
18495/33150 (epoch 27.896), train_loss = 0.91663037, grad/param norm = 1.6712e-01, time/batch = 17.3026s	
18496/33150 (epoch 27.897), train_loss = 0.94890136, grad/param norm = 1.5048e-01, time/batch = 18.6412s	
18497/33150 (epoch 27.899), train_loss = 0.77905795, grad/param norm = 1.9340e-01, time/batch = 15.2494s	
18498/33150 (epoch 27.900), train_loss = 1.11640199, grad/param norm = 2.0018e-01, time/batch = 16.4556s	
18499/33150 (epoch 27.902), train_loss = 1.10825355, grad/param norm = 1.7299e-01, time/batch = 18.5575s	
18500/33150 (epoch 27.903), train_loss = 0.92452948, grad/param norm = 1.6395e-01, time/batch = 16.8824s	
18501/33150 (epoch 27.905), train_loss = 0.94659249, grad/param norm = 1.4948e-01, time/batch = 15.7310s	
18502/33150 (epoch 27.906), train_loss = 0.95056450, grad/param norm = 1.9590e-01, time/batch = 17.7214s	
18503/33150 (epoch 27.908), train_loss = 1.02474497, grad/param norm = 1.6629e-01, time/batch = 16.7200s	
18504/33150 (epoch 27.910), train_loss = 0.99187630, grad/param norm = 1.6308e-01, time/batch = 17.3038s	
18505/33150 (epoch 27.911), train_loss = 0.80071124, grad/param norm = 1.3804e-01, time/batch = 16.3793s	
18506/33150 (epoch 27.913), train_loss = 0.85009926, grad/param norm = 1.7945e-01, time/batch = 17.3739s	
18507/33150 (epoch 27.914), train_loss = 0.98116851, grad/param norm = 1.7940e-01, time/batch = 17.5473s	
18508/33150 (epoch 27.916), train_loss = 0.85379868, grad/param norm = 1.5566e-01, time/batch = 15.3850s	
18509/33150 (epoch 27.917), train_loss = 0.96860435, grad/param norm = 1.7274e-01, time/batch = 16.2097s	
18510/33150 (epoch 27.919), train_loss = 1.06304565, grad/param norm = 2.0686e-01, time/batch = 16.5609s	
18511/33150 (epoch 27.920), train_loss = 1.01447264, grad/param norm = 1.6103e-01, time/batch = 19.3014s	
18512/33150 (epoch 27.922), train_loss = 1.08302689, grad/param norm = 1.8209e-01, time/batch = 17.2703s	
18513/33150 (epoch 27.923), train_loss = 0.94655440, grad/param norm = 1.8975e-01, time/batch = 17.7942s	
18514/33150 (epoch 27.925), train_loss = 1.01357126, grad/param norm = 1.6699e-01, time/batch = 19.3708s	
18515/33150 (epoch 27.926), train_loss = 0.90849601, grad/param norm = 1.5116e-01, time/batch = 18.2739s	
18516/33150 (epoch 27.928), train_loss = 0.87716905, grad/param norm = 1.6007e-01, time/batch = 15.5524s	
18517/33150 (epoch 27.929), train_loss = 0.97415242, grad/param norm = 1.6317e-01, time/batch = 17.8928s	
18518/33150 (epoch 27.931), train_loss = 1.04238662, grad/param norm = 1.9541e-01, time/batch = 16.7869s	
18519/33150 (epoch 27.932), train_loss = 0.93617863, grad/param norm = 1.6459e-01, time/batch = 16.5516s	
18520/33150 (epoch 27.934), train_loss = 0.97106144, grad/param norm = 1.5306e-01, time/batch = 17.2147s	
18521/33150 (epoch 27.935), train_loss = 1.02511673, grad/param norm = 1.7120e-01, time/batch = 18.1526s	
18522/33150 (epoch 27.937), train_loss = 1.04716720, grad/param norm = 1.6505e-01, time/batch = 16.7130s	
18523/33150 (epoch 27.938), train_loss = 0.96952074, grad/param norm = 1.6173e-01, time/batch = 17.9650s	
18524/33150 (epoch 27.940), train_loss = 1.17964498, grad/param norm = 2.1270e-01, time/batch = 16.1348s	
18525/33150 (epoch 27.941), train_loss = 0.94613026, grad/param norm = 1.4928e-01, time/batch = 17.9627s	
18526/33150 (epoch 27.943), train_loss = 0.78724316, grad/param norm = 1.6277e-01, time/batch = 16.7403s	
18527/33150 (epoch 27.944), train_loss = 1.01215722, grad/param norm = 1.8100e-01, time/batch = 18.6347s	
18528/33150 (epoch 27.946), train_loss = 0.81363418, grad/param norm = 1.5670e-01, time/batch = 19.1844s	
18529/33150 (epoch 27.947), train_loss = 0.96056967, grad/param norm = 1.6751e-01, time/batch = 16.2023s	
18530/33150 (epoch 27.949), train_loss = 1.03103925, grad/param norm = 1.6436e-01, time/batch = 18.2990s	
18531/33150 (epoch 27.950), train_loss = 0.97249616, grad/param norm = 1.8407e-01, time/batch = 19.3026s	
18532/33150 (epoch 27.952), train_loss = 0.85317130, grad/param norm = 1.5222e-01, time/batch = 15.8667s	
18533/33150 (epoch 27.953), train_loss = 0.88787079, grad/param norm = 1.5751e-01, time/batch = 19.7767s	
18534/33150 (epoch 27.955), train_loss = 0.80747076, grad/param norm = 1.5547e-01, time/batch = 17.5423s	
18535/33150 (epoch 27.956), train_loss = 1.00334085, grad/param norm = 1.6687e-01, time/batch = 17.5328s	
18536/33150 (epoch 27.958), train_loss = 0.84413191, grad/param norm = 1.5353e-01, time/batch = 18.6302s	
18537/33150 (epoch 27.959), train_loss = 0.88448195, grad/param norm = 1.5355e-01, time/batch = 18.7881s	
18538/33150 (epoch 27.961), train_loss = 0.86459490, grad/param norm = 1.7751e-01, time/batch = 18.7989s	
18539/33150 (epoch 27.962), train_loss = 0.79672227, grad/param norm = 1.5544e-01, time/batch = 15.7990s	
18540/33150 (epoch 27.964), train_loss = 0.92703376, grad/param norm = 1.5798e-01, time/batch = 17.4591s	
18541/33150 (epoch 27.965), train_loss = 0.90993593, grad/param norm = 1.5501e-01, time/batch = 17.8801s	
18542/33150 (epoch 27.967), train_loss = 0.91522341, grad/param norm = 1.7002e-01, time/batch = 16.3105s	
18543/33150 (epoch 27.968), train_loss = 0.76231345, grad/param norm = 1.3142e-01, time/batch = 16.5539s	
18544/33150 (epoch 27.970), train_loss = 0.87081308, grad/param norm = 1.5857e-01, time/batch = 15.8007s	
18545/33150 (epoch 27.971), train_loss = 0.92008237, grad/param norm = 1.6444e-01, time/batch = 19.2892s	
18546/33150 (epoch 27.973), train_loss = 1.02959707, grad/param norm = 1.6843e-01, time/batch = 16.6971s	
18547/33150 (epoch 27.974), train_loss = 1.05215794, grad/param norm = 1.5992e-01, time/batch = 18.4760s	
18548/33150 (epoch 27.976), train_loss = 1.01687981, grad/param norm = 1.5306e-01, time/batch = 17.9633s	
18549/33150 (epoch 27.977), train_loss = 1.06272654, grad/param norm = 1.7407e-01, time/batch = 17.6225s	
18550/33150 (epoch 27.979), train_loss = 1.00768871, grad/param norm = 1.8066e-01, time/batch = 17.3959s	
18551/33150 (epoch 27.980), train_loss = 1.07324684, grad/param norm = 1.7681e-01, time/batch = 16.2359s	
18552/33150 (epoch 27.982), train_loss = 0.92875219, grad/param norm = 1.7545e-01, time/batch = 17.2972s	
18553/33150 (epoch 27.983), train_loss = 0.82801280, grad/param norm = 1.6444e-01, time/batch = 17.2023s	
18554/33150 (epoch 27.985), train_loss = 1.02105749, grad/param norm = 1.5364e-01, time/batch = 16.7278s	
18555/33150 (epoch 27.986), train_loss = 0.79017410, grad/param norm = 1.5299e-01, time/batch = 18.7184s	
18556/33150 (epoch 27.988), train_loss = 0.88750537, grad/param norm = 1.7240e-01, time/batch = 15.5497s	
18557/33150 (epoch 27.989), train_loss = 0.87822578, grad/param norm = 1.6270e-01, time/batch = 17.8890s	
18558/33150 (epoch 27.991), train_loss = 0.99142550, grad/param norm = 2.3095e-01, time/batch = 16.6376s	
18559/33150 (epoch 27.992), train_loss = 0.89160654, grad/param norm = 1.6441e-01, time/batch = 18.1220s	
18560/33150 (epoch 27.994), train_loss = 0.95689272, grad/param norm = 1.6549e-01, time/batch = 16.3072s	
18561/33150 (epoch 27.995), train_loss = 0.89166267, grad/param norm = 1.5993e-01, time/batch = 18.1266s	
18562/33150 (epoch 27.997), train_loss = 0.90752055, grad/param norm = 1.5502e-01, time/batch = 17.3013s	
18563/33150 (epoch 27.998), train_loss = 0.77523196, grad/param norm = 1.4190e-01, time/batch = 15.6391s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
18564/33150 (epoch 28.000), train_loss = 0.75792850, grad/param norm = 1.5408e-01, time/batch = 16.0421s	
18565/33150 (epoch 28.002), train_loss = 1.22484983, grad/param norm = 1.9112e-01, time/batch = 15.9530s	
18566/33150 (epoch 28.003), train_loss = 0.82996403, grad/param norm = 1.6468e-01, time/batch = 18.2790s	
18567/33150 (epoch 28.005), train_loss = 0.81121140, grad/param norm = 1.4184e-01, time/batch = 18.1398s	
18568/33150 (epoch 28.006), train_loss = 0.80261800, grad/param norm = 1.5768e-01, time/batch = 16.9769s	
18569/33150 (epoch 28.008), train_loss = 1.01263185, grad/param norm = 1.8073e-01, time/batch = 16.5602s	
18570/33150 (epoch 28.009), train_loss = 0.94139009, grad/param norm = 1.5477e-01, time/batch = 16.1908s	
18571/33150 (epoch 28.011), train_loss = 1.02771471, grad/param norm = 1.6315e-01, time/batch = 16.6570s	
18572/33150 (epoch 28.012), train_loss = 0.92585267, grad/param norm = 1.7225e-01, time/batch = 17.8783s	
18573/33150 (epoch 28.014), train_loss = 0.86630289, grad/param norm = 1.8374e-01, time/batch = 16.0701s	
18574/33150 (epoch 28.015), train_loss = 0.84887169, grad/param norm = 1.6761e-01, time/batch = 16.3059s	
18575/33150 (epoch 28.017), train_loss = 0.82456357, grad/param norm = 1.4648e-01, time/batch = 17.2301s	
18576/33150 (epoch 28.018), train_loss = 0.94925502, grad/param norm = 1.8540e-01, time/batch = 17.3713s	
18577/33150 (epoch 28.020), train_loss = 1.00415352, grad/param norm = 1.7716e-01, time/batch = 16.4669s	
18578/33150 (epoch 28.021), train_loss = 0.83061583, grad/param norm = 1.5320e-01, time/batch = 17.6312s	
18579/33150 (epoch 28.023), train_loss = 1.08885379, grad/param norm = 1.5416e-01, time/batch = 15.4659s	
18580/33150 (epoch 28.024), train_loss = 0.97389189, grad/param norm = 1.7224e-01, time/batch = 18.2947s	
18581/33150 (epoch 28.026), train_loss = 0.74123875, grad/param norm = 1.3274e-01, time/batch = 17.5571s	
18582/33150 (epoch 28.027), train_loss = 0.74830219, grad/param norm = 1.3758e-01, time/batch = 18.2127s	
18583/33150 (epoch 28.029), train_loss = 0.86109898, grad/param norm = 1.5239e-01, time/batch = 16.7250s	
18584/33150 (epoch 28.030), train_loss = 0.88158371, grad/param norm = 1.3258e-01, time/batch = 15.8786s	
18585/33150 (epoch 28.032), train_loss = 0.81888099, grad/param norm = 1.7869e-01, time/batch = 16.2205s	
18586/33150 (epoch 28.033), train_loss = 0.85818809, grad/param norm = 1.5214e-01, time/batch = 19.2109s	
18587/33150 (epoch 28.035), train_loss = 1.09003413, grad/param norm = 1.9135e-01, time/batch = 16.6344s	
18588/33150 (epoch 28.036), train_loss = 0.97493861, grad/param norm = 1.8192e-01, time/batch = 16.9754s	
18589/33150 (epoch 28.038), train_loss = 1.13670024, grad/param norm = 2.0161e-01, time/batch = 16.1604s	
18590/33150 (epoch 28.039), train_loss = 0.98294812, grad/param norm = 1.4371e-01, time/batch = 19.2843s	
18591/33150 (epoch 28.041), train_loss = 0.92296827, grad/param norm = 1.4915e-01, time/batch = 15.7958s	
18592/33150 (epoch 28.042), train_loss = 0.86364192, grad/param norm = 1.4131e-01, time/batch = 17.5555s	
18593/33150 (epoch 28.044), train_loss = 0.89245072, grad/param norm = 1.4054e-01, time/batch = 15.9700s	
18594/33150 (epoch 28.045), train_loss = 0.98037700, grad/param norm = 1.5081e-01, time/batch = 17.7215s	
18595/33150 (epoch 28.047), train_loss = 0.81863143, grad/param norm = 1.4636e-01, time/batch = 16.9728s	
18596/33150 (epoch 28.048), train_loss = 1.01426538, grad/param norm = 1.9081e-01, time/batch = 19.0350s	
18597/33150 (epoch 28.050), train_loss = 0.91962170, grad/param norm = 1.8485e-01, time/batch = 19.1187s	
18598/33150 (epoch 28.051), train_loss = 0.93315061, grad/param norm = 1.5322e-01, time/batch = 15.7889s	
18599/33150 (epoch 28.053), train_loss = 0.93867605, grad/param norm = 1.7334e-01, time/batch = 17.5364s	
18600/33150 (epoch 28.054), train_loss = 1.05386435, grad/param norm = 1.5755e-01, time/batch = 17.3816s	
18601/33150 (epoch 28.056), train_loss = 0.91895513, grad/param norm = 1.5971e-01, time/batch = 16.5559s	
18602/33150 (epoch 28.057), train_loss = 0.95770293, grad/param norm = 1.6538e-01, time/batch = 17.0548s	
18603/33150 (epoch 28.059), train_loss = 0.86064413, grad/param norm = 1.5872e-01, time/batch = 15.8151s	
18604/33150 (epoch 28.060), train_loss = 0.84237537, grad/param norm = 1.4454e-01, time/batch = 17.5482s	
18605/33150 (epoch 28.062), train_loss = 0.90610084, grad/param norm = 1.6715e-01, time/batch = 15.5452s	
18606/33150 (epoch 28.063), train_loss = 0.86474170, grad/param norm = 1.6620e-01, time/batch = 17.8841s	
18607/33150 (epoch 28.065), train_loss = 0.87882632, grad/param norm = 1.5912e-01, time/batch = 17.2947s	
18608/33150 (epoch 28.066), train_loss = 0.87642053, grad/param norm = 1.6603e-01, time/batch = 16.9718s	
18609/33150 (epoch 28.068), train_loss = 0.96703905, grad/param norm = 1.5419e-01, time/batch = 16.5574s	
18610/33150 (epoch 28.069), train_loss = 0.94577789, grad/param norm = 1.7772e-01, time/batch = 16.5567s	
18611/33150 (epoch 28.071), train_loss = 0.92988123, grad/param norm = 1.4513e-01, time/batch = 17.7427s	
18612/33150 (epoch 28.072), train_loss = 0.91681149, grad/param norm = 1.5953e-01, time/batch = 15.8873s	
18613/33150 (epoch 28.074), train_loss = 0.78227738, grad/param norm = 1.6839e-01, time/batch = 17.6295s	
18614/33150 (epoch 28.075), train_loss = 0.84881002, grad/param norm = 1.7605e-01, time/batch = 15.8846s	
18615/33150 (epoch 28.077), train_loss = 0.90525839, grad/param norm = 2.1149e-01, time/batch = 16.6451s	
18616/33150 (epoch 28.078), train_loss = 1.06022703, grad/param norm = 1.9614e-01, time/batch = 16.1454s	
18617/33150 (epoch 28.080), train_loss = 1.03914004, grad/param norm = 1.6298e-01, time/batch = 16.3749s	
18618/33150 (epoch 28.081), train_loss = 0.80371749, grad/param norm = 1.7393e-01, time/batch = 18.7252s	
18619/33150 (epoch 28.083), train_loss = 0.68499338, grad/param norm = 1.7048e-01, time/batch = 15.4789s	
18620/33150 (epoch 28.084), train_loss = 0.78701400, grad/param norm = 1.6492e-01, time/batch = 15.7324s	
18621/33150 (epoch 28.086), train_loss = 0.82893694, grad/param norm = 1.5402e-01, time/batch = 16.7854s	
18622/33150 (epoch 28.087), train_loss = 0.81321866, grad/param norm = 1.5832e-01, time/batch = 16.0260s	
18623/33150 (epoch 28.089), train_loss = 0.83288662, grad/param norm = 1.5434e-01, time/batch = 15.1378s	
18624/33150 (epoch 28.090), train_loss = 0.88317040, grad/param norm = 1.7605e-01, time/batch = 17.1373s	
18625/33150 (epoch 28.092), train_loss = 0.84609276, grad/param norm = 1.7070e-01, time/batch = 18.6993s	
18626/33150 (epoch 28.094), train_loss = 0.95937261, grad/param norm = 1.7892e-01, time/batch = 17.1991s	
18627/33150 (epoch 28.095), train_loss = 0.85245111, grad/param norm = 1.4981e-01, time/batch = 18.6855s	
18628/33150 (epoch 28.097), train_loss = 0.80087796, grad/param norm = 1.7539e-01, time/batch = 16.1330s	
18629/33150 (epoch 28.098), train_loss = 1.12755057, grad/param norm = 1.8070e-01, time/batch = 17.4538s	
18630/33150 (epoch 28.100), train_loss = 1.09949122, grad/param norm = 1.8425e-01, time/batch = 17.6238s	
18631/33150 (epoch 28.101), train_loss = 0.84726477, grad/param norm = 1.5752e-01, time/batch = 19.2109s	
18632/33150 (epoch 28.103), train_loss = 0.94298797, grad/param norm = 1.7156e-01, time/batch = 17.7960s	
18633/33150 (epoch 28.104), train_loss = 0.83770266, grad/param norm = 1.8656e-01, time/batch = 16.7086s	
18634/33150 (epoch 28.106), train_loss = 1.01521322, grad/param norm = 1.7545e-01, time/batch = 18.6151s	
18635/33150 (epoch 28.107), train_loss = 1.11500972, grad/param norm = 1.8702e-01, time/batch = 17.2135s	
18636/33150 (epoch 28.109), train_loss = 0.89754218, grad/param norm = 1.4092e-01, time/batch = 17.6273s	
18637/33150 (epoch 28.110), train_loss = 1.03300009, grad/param norm = 1.8070e-01, time/batch = 16.9742s	
18638/33150 (epoch 28.112), train_loss = 0.86667676, grad/param norm = 1.7121e-01, time/batch = 16.5730s	
18639/33150 (epoch 28.113), train_loss = 0.89562369, grad/param norm = 1.8053e-01, time/batch = 16.3077s	
18640/33150 (epoch 28.115), train_loss = 1.09489049, grad/param norm = 1.8741e-01, time/batch = 17.2166s	
18641/33150 (epoch 28.116), train_loss = 0.91839601, grad/param norm = 1.3991e-01, time/batch = 17.8107s	
18642/33150 (epoch 28.118), train_loss = 0.96444972, grad/param norm = 1.7267e-01, time/batch = 15.8969s	
18643/33150 (epoch 28.119), train_loss = 0.97124883, grad/param norm = 1.8448e-01, time/batch = 17.8573s	
18644/33150 (epoch 28.121), train_loss = 0.87227378, grad/param norm = 1.4905e-01, time/batch = 16.8990s	
18645/33150 (epoch 28.122), train_loss = 1.07250377, grad/param norm = 1.8317e-01, time/batch = 17.1389s	
18646/33150 (epoch 28.124), train_loss = 0.78174398, grad/param norm = 1.3308e-01, time/batch = 18.8810s	
18647/33150 (epoch 28.125), train_loss = 1.02380906, grad/param norm = 1.6014e-01, time/batch = 14.9735s	
18648/33150 (epoch 28.127), train_loss = 0.93386298, grad/param norm = 1.5874e-01, time/batch = 17.7933s	
18649/33150 (epoch 28.128), train_loss = 0.96764193, grad/param norm = 1.7682e-01, time/batch = 17.6363s	
18650/33150 (epoch 28.130), train_loss = 0.93391687, grad/param norm = 1.8083e-01, time/batch = 18.1279s	
18651/33150 (epoch 28.131), train_loss = 1.14815386, grad/param norm = 1.8071e-01, time/batch = 16.8876s	
18652/33150 (epoch 28.133), train_loss = 0.86263149, grad/param norm = 1.6324e-01, time/batch = 18.0460s	
18653/33150 (epoch 28.134), train_loss = 1.06362000, grad/param norm = 1.7794e-01, time/batch = 17.9550s	
18654/33150 (epoch 28.136), train_loss = 0.91433129, grad/param norm = 1.8355e-01, time/batch = 16.8609s	
18655/33150 (epoch 28.137), train_loss = 0.99936748, grad/param norm = 1.6178e-01, time/batch = 19.0274s	
18656/33150 (epoch 28.139), train_loss = 0.98661748, grad/param norm = 1.8456e-01, time/batch = 16.1385s	
18657/33150 (epoch 28.140), train_loss = 1.08192186, grad/param norm = 1.9311e-01, time/batch = 16.5630s	
18658/33150 (epoch 28.142), train_loss = 1.00200402, grad/param norm = 1.6326e-01, time/batch = 17.9573s	
18659/33150 (epoch 28.143), train_loss = 0.93376319, grad/param norm = 2.1782e-01, time/batch = 16.8903s	
18660/33150 (epoch 28.145), train_loss = 0.90435294, grad/param norm = 2.3304e-01, time/batch = 17.3160s	
18661/33150 (epoch 28.146), train_loss = 1.02242196, grad/param norm = 1.9812e-01, time/batch = 16.4651s	
18662/33150 (epoch 28.148), train_loss = 1.05568509, grad/param norm = 1.6458e-01, time/batch = 15.7304s	
18663/33150 (epoch 28.149), train_loss = 0.98012257, grad/param norm = 1.7399e-01, time/batch = 15.4892s	
18664/33150 (epoch 28.151), train_loss = 1.11500033, grad/param norm = 1.7756e-01, time/batch = 16.1446s	
18665/33150 (epoch 28.152), train_loss = 0.89889276, grad/param norm = 1.5725e-01, time/batch = 15.3134s	
18666/33150 (epoch 28.154), train_loss = 0.89865551, grad/param norm = 1.8972e-01, time/batch = 18.4661s	
18667/33150 (epoch 28.155), train_loss = 0.77878658, grad/param norm = 1.5392e-01, time/batch = 18.5517s	
18668/33150 (epoch 28.157), train_loss = 0.91035924, grad/param norm = 1.7709e-01, time/batch = 16.6453s	
18669/33150 (epoch 28.158), train_loss = 0.88485417, grad/param norm = 1.5547e-01, time/batch = 17.2264s	
18670/33150 (epoch 28.160), train_loss = 0.99203917, grad/param norm = 1.7508e-01, time/batch = 16.6199s	
18671/33150 (epoch 28.161), train_loss = 0.87567996, grad/param norm = 2.2259e-01, time/batch = 16.0480s	
18672/33150 (epoch 28.163), train_loss = 0.82634087, grad/param norm = 1.7392e-01, time/batch = 16.3072s	
18673/33150 (epoch 28.164), train_loss = 0.97825738, grad/param norm = 1.7497e-01, time/batch = 14.9919s	
18674/33150 (epoch 28.166), train_loss = 0.90043376, grad/param norm = 1.6084e-01, time/batch = 16.6791s	
18675/33150 (epoch 28.167), train_loss = 0.93982926, grad/param norm = 1.5402e-01, time/batch = 17.0484s	
18676/33150 (epoch 28.169), train_loss = 0.97890716, grad/param norm = 2.1419e-01, time/batch = 18.8642s	
18677/33150 (epoch 28.170), train_loss = 0.86511197, grad/param norm = 2.0371e-01, time/batch = 18.2874s	
18678/33150 (epoch 28.172), train_loss = 1.01460370, grad/param norm = 2.2584e-01, time/batch = 16.9647s	
18679/33150 (epoch 28.173), train_loss = 1.00852102, grad/param norm = 2.1632e-01, time/batch = 17.0507s	
18680/33150 (epoch 28.175), train_loss = 0.90403098, grad/param norm = 2.1333e-01, time/batch = 15.0518s	
18681/33150 (epoch 28.176), train_loss = 0.99802931, grad/param norm = 1.9507e-01, time/batch = 14.9994s	
18682/33150 (epoch 28.178), train_loss = 1.12487444, grad/param norm = 1.8527e-01, time/batch = 14.6326s	
18683/33150 (epoch 28.179), train_loss = 1.00544176, grad/param norm = 1.6817e-01, time/batch = 14.7721s	
18684/33150 (epoch 28.181), train_loss = 0.93861015, grad/param norm = 1.8850e-01, time/batch = 14.3782s	
18685/33150 (epoch 28.183), train_loss = 0.91769880, grad/param norm = 1.9728e-01, time/batch = 16.9680s	
18686/33150 (epoch 28.184), train_loss = 1.16897915, grad/param norm = 1.8633e-01, time/batch = 15.1342s	
18687/33150 (epoch 28.186), train_loss = 1.08378891, grad/param norm = 1.7157e-01, time/batch = 17.6357s	
18688/33150 (epoch 28.187), train_loss = 0.94231728, grad/param norm = 1.7350e-01, time/batch = 17.6491s	
18689/33150 (epoch 28.189), train_loss = 0.74873448, grad/param norm = 1.7392e-01, time/batch = 15.1514s	
18690/33150 (epoch 28.190), train_loss = 0.84651461, grad/param norm = 1.7810e-01, time/batch = 16.2244s	
18691/33150 (epoch 28.192), train_loss = 0.95657359, grad/param norm = 1.8644e-01, time/batch = 16.4054s	
18692/33150 (epoch 28.193), train_loss = 1.03542970, grad/param norm = 1.8230e-01, time/batch = 19.3772s	
18693/33150 (epoch 28.195), train_loss = 1.15075957, grad/param norm = 2.1688e-01, time/batch = 16.3057s	
18694/33150 (epoch 28.196), train_loss = 1.04079819, grad/param norm = 1.5282e-01, time/batch = 17.7245s	
18695/33150 (epoch 28.198), train_loss = 0.82343119, grad/param norm = 1.7503e-01, time/batch = 17.9686s	
18696/33150 (epoch 28.199), train_loss = 1.01337686, grad/param norm = 2.0776e-01, time/batch = 18.6306s	
18697/33150 (epoch 28.201), train_loss = 0.88089752, grad/param norm = 1.4342e-01, time/batch = 31.5349s	
18698/33150 (epoch 28.202), train_loss = 0.75116931, grad/param norm = 1.4545e-01, time/batch = 18.8622s	
18699/33150 (epoch 28.204), train_loss = 0.99737088, grad/param norm = 1.7650e-01, time/batch = 16.6279s	
18700/33150 (epoch 28.205), train_loss = 0.98090696, grad/param norm = 1.7636e-01, time/batch = 18.8828s	
18701/33150 (epoch 28.207), train_loss = 0.98302145, grad/param norm = 1.6735e-01, time/batch = 17.6425s	
18702/33150 (epoch 28.208), train_loss = 1.00401913, grad/param norm = 1.7149e-01, time/batch = 16.8149s	
18703/33150 (epoch 28.210), train_loss = 0.88885358, grad/param norm = 1.4884e-01, time/batch = 15.7446s	
18704/33150 (epoch 28.211), train_loss = 0.94965083, grad/param norm = 1.9611e-01, time/batch = 18.1332s	
18705/33150 (epoch 28.213), train_loss = 1.00229722, grad/param norm = 1.6255e-01, time/batch = 16.7833s	
18706/33150 (epoch 28.214), train_loss = 0.91175816, grad/param norm = 1.5421e-01, time/batch = 17.1094s	
18707/33150 (epoch 28.216), train_loss = 0.87147874, grad/param norm = 1.7288e-01, time/batch = 19.6824s	
18708/33150 (epoch 28.217), train_loss = 0.90672704, grad/param norm = 1.5112e-01, time/batch = 16.4528s	
18709/33150 (epoch 28.219), train_loss = 0.85871757, grad/param norm = 1.6159e-01, time/batch = 15.9792s	
18710/33150 (epoch 28.220), train_loss = 0.87794126, grad/param norm = 1.6450e-01, time/batch = 15.5658s	
18711/33150 (epoch 28.222), train_loss = 1.06002030, grad/param norm = 1.7240e-01, time/batch = 16.8115s	
18712/33150 (epoch 28.223), train_loss = 0.92925148, grad/param norm = 1.6373e-01, time/batch = 19.7088s	
18713/33150 (epoch 28.225), train_loss = 1.04998192, grad/param norm = 1.6548e-01, time/batch = 15.4681s	
18714/33150 (epoch 28.226), train_loss = 0.93948372, grad/param norm = 1.6699e-01, time/batch = 17.2212s	
18715/33150 (epoch 28.228), train_loss = 0.91743263, grad/param norm = 1.7073e-01, time/batch = 17.7989s	
18716/33150 (epoch 28.229), train_loss = 0.92965259, grad/param norm = 1.6226e-01, time/batch = 18.1214s	
18717/33150 (epoch 28.231), train_loss = 1.03534838, grad/param norm = 1.9161e-01, time/batch = 18.1941s	
18718/33150 (epoch 28.232), train_loss = 0.95386786, grad/param norm = 1.7624e-01, time/batch = 18.1384s	
18719/33150 (epoch 28.234), train_loss = 0.94836669, grad/param norm = 1.8250e-01, time/batch = 19.8659s	
18720/33150 (epoch 28.235), train_loss = 0.98227167, grad/param norm = 1.8557e-01, time/batch = 16.2099s	
18721/33150 (epoch 28.237), train_loss = 0.95358830, grad/param norm = 1.8935e-01, time/batch = 15.6317s	
18722/33150 (epoch 28.238), train_loss = 0.99869066, grad/param norm = 1.9237e-01, time/batch = 19.7994s	
18723/33150 (epoch 28.240), train_loss = 0.98447126, grad/param norm = 1.6322e-01, time/batch = 15.9368s	
18724/33150 (epoch 28.241), train_loss = 1.03609811, grad/param norm = 1.9271e-01, time/batch = 16.2227s	
18725/33150 (epoch 28.243), train_loss = 0.99392193, grad/param norm = 1.7371e-01, time/batch = 16.7137s	
18726/33150 (epoch 28.244), train_loss = 0.93822553, grad/param norm = 1.6493e-01, time/batch = 17.6216s	
18727/33150 (epoch 28.246), train_loss = 0.99785674, grad/param norm = 1.5907e-01, time/batch = 16.4471s	
18728/33150 (epoch 28.247), train_loss = 0.89090366, grad/param norm = 1.6819e-01, time/batch = 19.3662s	
18729/33150 (epoch 28.249), train_loss = 1.06737345, grad/param norm = 1.6315e-01, time/batch = 17.6283s	
18730/33150 (epoch 28.250), train_loss = 0.99087946, grad/param norm = 1.6193e-01, time/batch = 16.5500s	
18731/33150 (epoch 28.252), train_loss = 1.00730836, grad/param norm = 1.5554e-01, time/batch = 16.6342s	
18732/33150 (epoch 28.253), train_loss = 0.91910616, grad/param norm = 1.7445e-01, time/batch = 16.0706s	
18733/33150 (epoch 28.255), train_loss = 0.92961231, grad/param norm = 1.5050e-01, time/batch = 18.9516s	
18734/33150 (epoch 28.256), train_loss = 1.03749583, grad/param norm = 1.6320e-01, time/batch = 16.1537s	
18735/33150 (epoch 28.258), train_loss = 0.88027808, grad/param norm = 1.7347e-01, time/batch = 18.2215s	
18736/33150 (epoch 28.259), train_loss = 0.75881199, grad/param norm = 1.4422e-01, time/batch = 16.0564s	
18737/33150 (epoch 28.261), train_loss = 0.83205150, grad/param norm = 1.3967e-01, time/batch = 16.7172s	
18738/33150 (epoch 28.262), train_loss = 1.04039838, grad/param norm = 2.0373e-01, time/batch = 18.2117s	
18739/33150 (epoch 28.264), train_loss = 0.73027546, grad/param norm = 1.4895e-01, time/batch = 17.6392s	
18740/33150 (epoch 28.265), train_loss = 0.97091055, grad/param norm = 1.7031e-01, time/batch = 17.2903s	
18741/33150 (epoch 28.267), train_loss = 1.00358350, grad/param norm = 1.8389e-01, time/batch = 17.2163s	
18742/33150 (epoch 28.268), train_loss = 1.03435778, grad/param norm = 1.5147e-01, time/batch = 18.2862s	
18743/33150 (epoch 28.270), train_loss = 1.12709865, grad/param norm = 1.7890e-01, time/batch = 16.6224s	
18744/33150 (epoch 28.271), train_loss = 1.03528657, grad/param norm = 1.6911e-01, time/batch = 16.6306s	
18745/33150 (epoch 28.273), train_loss = 1.04963205, grad/param norm = 1.6086e-01, time/batch = 18.3802s	
18746/33150 (epoch 28.275), train_loss = 1.08468636, grad/param norm = 1.8071e-01, time/batch = 15.9655s	
18747/33150 (epoch 28.276), train_loss = 0.97145188, grad/param norm = 1.7599e-01, time/batch = 17.3737s	
18748/33150 (epoch 28.278), train_loss = 1.05604590, grad/param norm = 1.7429e-01, time/batch = 15.8252s	
18749/33150 (epoch 28.279), train_loss = 0.99786339, grad/param norm = 1.4964e-01, time/batch = 17.8937s	
18750/33150 (epoch 28.281), train_loss = 0.94959780, grad/param norm = 1.6864e-01, time/batch = 17.6482s	
18751/33150 (epoch 28.282), train_loss = 0.96244412, grad/param norm = 1.3707e-01, time/batch = 16.3900s	
18752/33150 (epoch 28.284), train_loss = 0.86894898, grad/param norm = 1.5892e-01, time/batch = 17.7070s	
18753/33150 (epoch 28.285), train_loss = 0.97584246, grad/param norm = 1.7547e-01, time/batch = 17.7204s	
18754/33150 (epoch 28.287), train_loss = 0.83129959, grad/param norm = 1.6012e-01, time/batch = 17.8547s	
18755/33150 (epoch 28.288), train_loss = 1.03256127, grad/param norm = 1.7110e-01, time/batch = 17.3055s	
18756/33150 (epoch 28.290), train_loss = 0.82195792, grad/param norm = 1.6326e-01, time/batch = 16.2950s	
18757/33150 (epoch 28.291), train_loss = 0.77904483, grad/param norm = 1.4158e-01, time/batch = 17.6445s	
18758/33150 (epoch 28.293), train_loss = 0.96799499, grad/param norm = 1.6829e-01, time/batch = 16.3670s	
18759/33150 (epoch 28.294), train_loss = 0.71898464, grad/param norm = 1.4432e-01, time/batch = 15.6981s	
18760/33150 (epoch 28.296), train_loss = 0.92922729, grad/param norm = 1.5388e-01, time/batch = 18.6370s	
18761/33150 (epoch 28.297), train_loss = 0.87864483, grad/param norm = 1.5944e-01, time/batch = 18.1976s	
18762/33150 (epoch 28.299), train_loss = 0.89085737, grad/param norm = 1.8958e-01, time/batch = 16.8809s	
18763/33150 (epoch 28.300), train_loss = 0.88047141, grad/param norm = 1.4292e-01, time/batch = 19.5579s	
18764/33150 (epoch 28.302), train_loss = 0.92886734, grad/param norm = 1.6739e-01, time/batch = 17.3867s	
18765/33150 (epoch 28.303), train_loss = 0.90078891, grad/param norm = 1.6689e-01, time/batch = 16.1289s	
18766/33150 (epoch 28.305), train_loss = 0.97647157, grad/param norm = 1.5588e-01, time/batch = 17.3170s	
18767/33150 (epoch 28.306), train_loss = 0.99370690, grad/param norm = 2.1285e-01, time/batch = 16.7355s	
18768/33150 (epoch 28.308), train_loss = 1.16760318, grad/param norm = 1.8093e-01, time/batch = 18.1936s	
18769/33150 (epoch 28.309), train_loss = 0.77372448, grad/param norm = 1.4221e-01, time/batch = 17.0402s	
18770/33150 (epoch 28.311), train_loss = 0.90791848, grad/param norm = 1.7346e-01, time/batch = 18.3784s	
18771/33150 (epoch 28.312), train_loss = 0.74139643, grad/param norm = 1.4898e-01, time/batch = 16.7236s	
18772/33150 (epoch 28.314), train_loss = 0.89386419, grad/param norm = 1.7121e-01, time/batch = 15.9747s	
18773/33150 (epoch 28.315), train_loss = 0.98026369, grad/param norm = 1.6272e-01, time/batch = 19.2118s	
18774/33150 (epoch 28.317), train_loss = 0.76087256, grad/param norm = 1.3606e-01, time/batch = 15.3857s	
18775/33150 (epoch 28.318), train_loss = 0.85288640, grad/param norm = 1.4414e-01, time/batch = 16.9737s	
18776/33150 (epoch 28.320), train_loss = 0.78353720, grad/param norm = 1.3654e-01, time/batch = 17.1124s	
18777/33150 (epoch 28.321), train_loss = 0.91614071, grad/param norm = 1.4972e-01, time/batch = 17.3783s	
18778/33150 (epoch 28.323), train_loss = 0.89490290, grad/param norm = 1.4995e-01, time/batch = 17.5891s	
18779/33150 (epoch 28.324), train_loss = 0.97128237, grad/param norm = 1.8917e-01, time/batch = 17.8034s	
18780/33150 (epoch 28.326), train_loss = 0.95416118, grad/param norm = 1.5946e-01, time/batch = 18.5466s	
18781/33150 (epoch 28.327), train_loss = 1.02418534, grad/param norm = 1.5956e-01, time/batch = 16.8053s	
18782/33150 (epoch 28.329), train_loss = 0.96436056, grad/param norm = 1.5592e-01, time/batch = 16.4603s	
18783/33150 (epoch 28.330), train_loss = 0.93371516, grad/param norm = 1.8123e-01, time/batch = 17.8840s	
18784/33150 (epoch 28.332), train_loss = 0.92098499, grad/param norm = 1.4734e-01, time/batch = 18.8073s	
18785/33150 (epoch 28.333), train_loss = 0.96977105, grad/param norm = 1.3861e-01, time/batch = 16.5618s	
18786/33150 (epoch 28.335), train_loss = 0.85862731, grad/param norm = 1.4920e-01, time/batch = 16.6332s	
18787/33150 (epoch 28.336), train_loss = 0.85264449, grad/param norm = 1.8055e-01, time/batch = 17.2039s	
18788/33150 (epoch 28.338), train_loss = 0.78457067, grad/param norm = 1.6161e-01, time/batch = 17.3917s	
18789/33150 (epoch 28.339), train_loss = 1.01140317, grad/param norm = 1.6929e-01, time/batch = 15.6513s	
18790/33150 (epoch 28.341), train_loss = 0.94740936, grad/param norm = 1.8174e-01, time/batch = 16.0600s	
18791/33150 (epoch 28.342), train_loss = 0.85220883, grad/param norm = 1.7977e-01, time/batch = 17.9594s	
18792/33150 (epoch 28.344), train_loss = 0.93633897, grad/param norm = 1.9393e-01, time/batch = 16.8890s	
18793/33150 (epoch 28.345), train_loss = 0.90405673, grad/param norm = 1.5420e-01, time/batch = 14.9858s	
18794/33150 (epoch 28.347), train_loss = 0.74271681, grad/param norm = 1.4287e-01, time/batch = 15.9019s	
18795/33150 (epoch 28.348), train_loss = 0.95549065, grad/param norm = 1.5921e-01, time/batch = 16.8640s	
18796/33150 (epoch 28.350), train_loss = 0.83087004, grad/param norm = 1.6384e-01, time/batch = 17.9542s	
18797/33150 (epoch 28.351), train_loss = 1.00681834, grad/param norm = 1.7069e-01, time/batch = 17.7120s	
18798/33150 (epoch 28.353), train_loss = 0.94928240, grad/param norm = 1.5123e-01, time/batch = 16.5646s	
18799/33150 (epoch 28.354), train_loss = 1.16497253, grad/param norm = 1.6728e-01, time/batch = 17.3746s	
18800/33150 (epoch 28.356), train_loss = 1.02436919, grad/param norm = 1.7518e-01, time/batch = 15.5495s	
18801/33150 (epoch 28.357), train_loss = 0.96026876, grad/param norm = 1.7416e-01, time/batch = 17.2411s	
18802/33150 (epoch 28.359), train_loss = 0.99599495, grad/param norm = 1.6779e-01, time/batch = 15.7394s	
18803/33150 (epoch 28.360), train_loss = 0.98289767, grad/param norm = 1.9578e-01, time/batch = 18.5494s	
18804/33150 (epoch 28.362), train_loss = 1.03342214, grad/param norm = 1.7685e-01, time/batch = 17.4027s	
18805/33150 (epoch 28.363), train_loss = 0.94814962, grad/param norm = 1.5458e-01, time/batch = 16.0344s	
18806/33150 (epoch 28.365), train_loss = 0.90422068, grad/param norm = 1.4769e-01, time/batch = 17.9766s	
18807/33150 (epoch 28.367), train_loss = 0.89466695, grad/param norm = 1.5198e-01, time/batch = 15.4051s	
18808/33150 (epoch 28.368), train_loss = 0.92093200, grad/param norm = 2.3305e-01, time/batch = 16.2507s	
18809/33150 (epoch 28.370), train_loss = 0.94591621, grad/param norm = 1.9343e-01, time/batch = 16.8097s	
18810/33150 (epoch 28.371), train_loss = 0.83143904, grad/param norm = 1.6800e-01, time/batch = 16.2873s	
18811/33150 (epoch 28.373), train_loss = 0.98918206, grad/param norm = 2.1090e-01, time/batch = 15.5576s	
18812/33150 (epoch 28.374), train_loss = 0.89715184, grad/param norm = 1.4182e-01, time/batch = 17.2945s	
18813/33150 (epoch 28.376), train_loss = 1.03980571, grad/param norm = 1.6858e-01, time/batch = 18.4621s	
18814/33150 (epoch 28.377), train_loss = 0.88515754, grad/param norm = 1.8562e-01, time/batch = 16.1220s	
18815/33150 (epoch 28.379), train_loss = 1.00127093, grad/param norm = 1.8639e-01, time/batch = 18.2105s	
18816/33150 (epoch 28.380), train_loss = 0.97660792, grad/param norm = 1.4254e-01, time/batch = 19.2006s	
18817/33150 (epoch 28.382), train_loss = 0.91120306, grad/param norm = 1.6449e-01, time/batch = 16.4716s	
18818/33150 (epoch 28.383), train_loss = 0.85006412, grad/param norm = 1.5071e-01, time/batch = 16.6361s	
18819/33150 (epoch 28.385), train_loss = 0.89888014, grad/param norm = 1.6896e-01, time/batch = 17.4011s	
18820/33150 (epoch 28.386), train_loss = 0.81044250, grad/param norm = 1.4430e-01, time/batch = 19.1189s	
18821/33150 (epoch 28.388), train_loss = 0.86389853, grad/param norm = 1.5353e-01, time/batch = 18.2951s	
18822/33150 (epoch 28.389), train_loss = 0.85692912, grad/param norm = 1.4230e-01, time/batch = 18.2897s	
18823/33150 (epoch 28.391), train_loss = 1.08793840, grad/param norm = 1.7850e-01, time/batch = 19.2219s	
18824/33150 (epoch 28.392), train_loss = 0.90015265, grad/param norm = 1.6475e-01, time/batch = 15.3712s	
18825/33150 (epoch 28.394), train_loss = 0.78231653, grad/param norm = 1.3644e-01, time/batch = 15.6056s	
18826/33150 (epoch 28.395), train_loss = 0.75873511, grad/param norm = 1.4243e-01, time/batch = 19.5368s	
18827/33150 (epoch 28.397), train_loss = 0.64395197, grad/param norm = 1.3250e-01, time/batch = 17.1266s	
18828/33150 (epoch 28.398), train_loss = 0.92340649, grad/param norm = 1.6007e-01, time/batch = 17.7890s	
18829/33150 (epoch 28.400), train_loss = 0.89566853, grad/param norm = 1.3918e-01, time/batch = 17.8676s	
18830/33150 (epoch 28.401), train_loss = 0.80938873, grad/param norm = 1.3734e-01, time/batch = 17.7285s	
18831/33150 (epoch 28.403), train_loss = 0.77813286, grad/param norm = 1.3737e-01, time/batch = 15.9739s	
18832/33150 (epoch 28.404), train_loss = 0.93464200, grad/param norm = 1.5055e-01, time/batch = 16.7230s	
18833/33150 (epoch 28.406), train_loss = 0.87748350, grad/param norm = 1.3817e-01, time/batch = 17.5370s	
18834/33150 (epoch 28.407), train_loss = 0.80427866, grad/param norm = 1.4896e-01, time/batch = 17.0425s	
18835/33150 (epoch 28.409), train_loss = 0.75477431, grad/param norm = 1.4297e-01, time/batch = 16.2792s	
18836/33150 (epoch 28.410), train_loss = 0.94872792, grad/param norm = 1.6884e-01, time/batch = 16.8799s	
18837/33150 (epoch 28.412), train_loss = 0.96185780, grad/param norm = 1.5698e-01, time/batch = 17.3938s	
18838/33150 (epoch 28.413), train_loss = 0.84378142, grad/param norm = 1.6869e-01, time/batch = 16.6062s	
18839/33150 (epoch 28.415), train_loss = 0.94780752, grad/param norm = 1.5805e-01, time/batch = 16.8751s	
18840/33150 (epoch 28.416), train_loss = 0.85429272, grad/param norm = 1.4757e-01, time/batch = 18.3142s	
18841/33150 (epoch 28.418), train_loss = 0.99772936, grad/param norm = 2.4958e-01, time/batch = 16.7812s	
18842/33150 (epoch 28.419), train_loss = 0.88756931, grad/param norm = 1.5491e-01, time/batch = 18.0460s	
18843/33150 (epoch 28.421), train_loss = 0.92503579, grad/param norm = 2.0194e-01, time/batch = 17.9733s	
18844/33150 (epoch 28.422), train_loss = 0.87233953, grad/param norm = 1.6740e-01, time/batch = 17.2254s	
18845/33150 (epoch 28.424), train_loss = 0.86718899, grad/param norm = 1.7130e-01, time/batch = 16.3016s	
18846/33150 (epoch 28.425), train_loss = 0.98546024, grad/param norm = 1.6316e-01, time/batch = 15.9566s	
18847/33150 (epoch 28.427), train_loss = 0.91054806, grad/param norm = 1.5018e-01, time/batch = 18.3055s	
18848/33150 (epoch 28.428), train_loss = 0.93273629, grad/param norm = 1.7087e-01, time/batch = 15.6459s	
18849/33150 (epoch 28.430), train_loss = 0.92546217, grad/param norm = 1.6338e-01, time/batch = 18.3050s	
18850/33150 (epoch 28.431), train_loss = 0.99013746, grad/param norm = 1.8140e-01, time/batch = 16.6479s	
18851/33150 (epoch 28.433), train_loss = 0.90549504, grad/param norm = 1.6965e-01, time/batch = 18.7850s	
18852/33150 (epoch 28.434), train_loss = 0.80431979, grad/param norm = 1.5030e-01, time/batch = 16.8004s	
18853/33150 (epoch 28.436), train_loss = 0.89915725, grad/param norm = 1.5441e-01, time/batch = 15.5529s	
18854/33150 (epoch 28.437), train_loss = 0.94186204, grad/param norm = 1.8836e-01, time/batch = 18.2917s	
18855/33150 (epoch 28.439), train_loss = 1.06742645, grad/param norm = 1.6468e-01, time/batch = 16.8746s	
18856/33150 (epoch 28.440), train_loss = 0.98225317, grad/param norm = 1.5248e-01, time/batch = 17.2341s	
18857/33150 (epoch 28.442), train_loss = 0.80657525, grad/param norm = 1.5731e-01, time/batch = 17.3012s	
18858/33150 (epoch 28.443), train_loss = 0.97459674, grad/param norm = 1.7807e-01, time/batch = 17.8868s	
18859/33150 (epoch 28.445), train_loss = 0.94445179, grad/param norm = 1.7543e-01, time/batch = 16.4035s	
18860/33150 (epoch 28.446), train_loss = 0.95063105, grad/param norm = 1.9628e-01, time/batch = 18.6324s	
18861/33150 (epoch 28.448), train_loss = 1.02557624, grad/param norm = 1.7796e-01, time/batch = 16.6466s	
18862/33150 (epoch 28.449), train_loss = 0.93798218, grad/param norm = 1.5412e-01, time/batch = 15.5627s	
18863/33150 (epoch 28.451), train_loss = 0.91580408, grad/param norm = 1.7138e-01, time/batch = 18.0217s	
18864/33150 (epoch 28.452), train_loss = 1.09615963, grad/param norm = 1.7018e-01, time/batch = 15.6171s	
18865/33150 (epoch 28.454), train_loss = 0.92752793, grad/param norm = 1.6830e-01, time/batch = 17.3010s	
18866/33150 (epoch 28.456), train_loss = 0.83042759, grad/param norm = 1.4948e-01, time/batch = 16.7098s	
18867/33150 (epoch 28.457), train_loss = 0.92635183, grad/param norm = 1.5292e-01, time/batch = 17.4689s	
18868/33150 (epoch 28.459), train_loss = 1.03907912, grad/param norm = 2.2398e-01, time/batch = 15.8940s	
18869/33150 (epoch 28.460), train_loss = 0.96177133, grad/param norm = 1.4553e-01, time/batch = 15.3059s	
18870/33150 (epoch 28.462), train_loss = 1.01110581, grad/param norm = 2.0776e-01, time/batch = 16.6561s	
18871/33150 (epoch 28.463), train_loss = 1.14023107, grad/param norm = 2.2054e-01, time/batch = 17.0504s	
18872/33150 (epoch 28.465), train_loss = 0.95071382, grad/param norm = 1.5940e-01, time/batch = 18.9571s	
18873/33150 (epoch 28.466), train_loss = 0.89915039, grad/param norm = 1.7745e-01, time/batch = 17.5344s	
18874/33150 (epoch 28.468), train_loss = 1.12640266, grad/param norm = 1.5917e-01, time/batch = 16.4557s	
18875/33150 (epoch 28.469), train_loss = 0.92211067, grad/param norm = 1.8541e-01, time/batch = 18.7934s	
18876/33150 (epoch 28.471), train_loss = 0.85679389, grad/param norm = 1.4932e-01, time/batch = 16.7263s	
18877/33150 (epoch 28.472), train_loss = 0.94747425, grad/param norm = 1.8256e-01, time/batch = 16.8677s	
18878/33150 (epoch 28.474), train_loss = 1.01254741, grad/param norm = 2.0199e-01, time/batch = 16.4739s	
18879/33150 (epoch 28.475), train_loss = 1.16927164, grad/param norm = 1.8530e-01, time/batch = 18.2107s	
18880/33150 (epoch 28.477), train_loss = 1.04719464, grad/param norm = 1.8885e-01, time/batch = 16.0331s	
18881/33150 (epoch 28.478), train_loss = 1.00152049, grad/param norm = 1.6054e-01, time/batch = 16.2996s	
18882/33150 (epoch 28.480), train_loss = 0.86691381, grad/param norm = 1.6170e-01, time/batch = 15.4621s	
18883/33150 (epoch 28.481), train_loss = 0.79660561, grad/param norm = 1.6744e-01, time/batch = 17.7104s	
18884/33150 (epoch 28.483), train_loss = 0.87762814, grad/param norm = 1.6012e-01, time/batch = 17.2846s	
18885/33150 (epoch 28.484), train_loss = 0.88147589, grad/param norm = 1.6709e-01, time/batch = 16.2111s	
18886/33150 (epoch 28.486), train_loss = 0.85298213, grad/param norm = 1.6462e-01, time/batch = 19.4462s	
18887/33150 (epoch 28.487), train_loss = 0.94975925, grad/param norm = 1.7291e-01, time/batch = 17.1219s	
18888/33150 (epoch 28.489), train_loss = 0.92593602, grad/param norm = 1.7634e-01, time/batch = 16.8224s	
18889/33150 (epoch 28.490), train_loss = 0.77875844, grad/param norm = 1.4257e-01, time/batch = 17.1178s	
18890/33150 (epoch 28.492), train_loss = 0.89543176, grad/param norm = 1.7645e-01, time/batch = 16.5529s	
18891/33150 (epoch 28.493), train_loss = 1.00447761, grad/param norm = 1.6401e-01, time/batch = 18.2024s	
18892/33150 (epoch 28.495), train_loss = 1.00307040, grad/param norm = 1.6534e-01, time/batch = 17.6440s	
18893/33150 (epoch 28.496), train_loss = 0.91330672, grad/param norm = 1.6775e-01, time/batch = 18.0449s	
18894/33150 (epoch 28.498), train_loss = 1.04009008, grad/param norm = 2.1548e-01, time/batch = 15.9521s	
18895/33150 (epoch 28.499), train_loss = 1.04552785, grad/param norm = 1.9516e-01, time/batch = 15.4827s	
18896/33150 (epoch 28.501), train_loss = 0.99190149, grad/param norm = 1.8779e-01, time/batch = 18.7041s	
18897/33150 (epoch 28.502), train_loss = 1.04985199, grad/param norm = 1.8115e-01, time/batch = 16.5626s	
18898/33150 (epoch 28.504), train_loss = 0.98604305, grad/param norm = 1.7612e-01, time/batch = 17.3862s	
18899/33150 (epoch 28.505), train_loss = 1.09369180, grad/param norm = 1.8155e-01, time/batch = 16.0194s	
18900/33150 (epoch 28.507), train_loss = 0.89783102, grad/param norm = 2.0658e-01, time/batch = 17.1210s	
18901/33150 (epoch 28.508), train_loss = 0.89087671, grad/param norm = 1.6837e-01, time/batch = 15.5700s	
18902/33150 (epoch 28.510), train_loss = 0.99964523, grad/param norm = 1.4785e-01, time/batch = 19.1267s	
18903/33150 (epoch 28.511), train_loss = 1.04421553, grad/param norm = 1.6259e-01, time/batch = 18.2983s	
18904/33150 (epoch 28.513), train_loss = 0.97762023, grad/param norm = 1.8021e-01, time/batch = 25.0714s	
18905/33150 (epoch 28.514), train_loss = 0.79401640, grad/param norm = 1.5342e-01, time/batch = 21.4264s	
18906/33150 (epoch 28.516), train_loss = 0.94865025, grad/param norm = 1.8151e-01, time/batch = 17.6218s	
18907/33150 (epoch 28.517), train_loss = 1.01830184, grad/param norm = 1.6567e-01, time/batch = 16.3846s	
18908/33150 (epoch 28.519), train_loss = 0.86088993, grad/param norm = 1.6806e-01, time/batch = 16.3072s	
18909/33150 (epoch 28.520), train_loss = 0.95345067, grad/param norm = 1.6385e-01, time/batch = 15.8085s	
18910/33150 (epoch 28.522), train_loss = 1.03788935, grad/param norm = 1.7646e-01, time/batch = 16.7216s	
18911/33150 (epoch 28.523), train_loss = 0.82844047, grad/param norm = 1.4833e-01, time/batch = 16.3024s	
18912/33150 (epoch 28.525), train_loss = 0.98764058, grad/param norm = 1.6949e-01, time/batch = 16.9048s	
18913/33150 (epoch 28.526), train_loss = 0.84390810, grad/param norm = 1.5428e-01, time/batch = 19.2858s	
18914/33150 (epoch 28.528), train_loss = 0.98648904, grad/param norm = 1.7075e-01, time/batch = 15.5581s	
18915/33150 (epoch 28.529), train_loss = 0.93321585, grad/param norm = 1.8285e-01, time/batch = 17.2028s	
18916/33150 (epoch 28.531), train_loss = 0.78010617, grad/param norm = 1.7455e-01, time/batch = 16.8147s	
18917/33150 (epoch 28.532), train_loss = 0.95485754, grad/param norm = 1.8932e-01, time/batch = 15.8710s	
18918/33150 (epoch 28.534), train_loss = 0.91268069, grad/param norm = 1.3571e-01, time/batch = 16.9573s	
18919/33150 (epoch 28.535), train_loss = 0.86249119, grad/param norm = 1.7775e-01, time/batch = 17.0703s	
18920/33150 (epoch 28.537), train_loss = 0.97308852, grad/param norm = 1.8759e-01, time/batch = 18.5388s	
18921/33150 (epoch 28.538), train_loss = 0.85263604, grad/param norm = 1.5245e-01, time/batch = 16.1358s	
18922/33150 (epoch 28.540), train_loss = 0.83349013, grad/param norm = 1.7016e-01, time/batch = 16.2216s	
18923/33150 (epoch 28.541), train_loss = 1.01987075, grad/param norm = 1.7419e-01, time/batch = 16.1258s	
18924/33150 (epoch 28.543), train_loss = 0.94809349, grad/param norm = 1.6211e-01, time/batch = 17.4390s	
18925/33150 (epoch 28.544), train_loss = 1.00505218, grad/param norm = 1.6585e-01, time/batch = 16.9859s	
18926/33150 (epoch 28.546), train_loss = 0.94811649, grad/param norm = 1.7871e-01, time/batch = 16.9670s	
18927/33150 (epoch 28.548), train_loss = 0.89026030, grad/param norm = 1.7450e-01, time/batch = 15.6193s	
18928/33150 (epoch 28.549), train_loss = 0.87253483, grad/param norm = 1.5957e-01, time/batch = 15.5933s	
18929/33150 (epoch 28.551), train_loss = 0.85990797, grad/param norm = 1.5014e-01, time/batch = 15.3690s	
18930/33150 (epoch 28.552), train_loss = 0.72766388, grad/param norm = 1.2827e-01, time/batch = 15.3816s	
18931/33150 (epoch 28.554), train_loss = 0.97337133, grad/param norm = 1.5863e-01, time/batch = 15.2515s	
18932/33150 (epoch 28.555), train_loss = 1.01753113, grad/param norm = 1.8134e-01, time/batch = 15.1018s	
18933/33150 (epoch 28.557), train_loss = 0.74745477, grad/param norm = 1.6825e-01, time/batch = 15.8058s	
18934/33150 (epoch 28.558), train_loss = 0.99264855, grad/param norm = 2.4811e-01, time/batch = 17.3881s	
18935/33150 (epoch 28.560), train_loss = 0.88096270, grad/param norm = 1.5892e-01, time/batch = 17.1217s	
18936/33150 (epoch 28.561), train_loss = 0.77938561, grad/param norm = 1.7559e-01, time/batch = 16.8751s	
18937/33150 (epoch 28.563), train_loss = 0.99411994, grad/param norm = 2.2524e-01, time/batch = 17.7019s	
18938/33150 (epoch 28.564), train_loss = 1.08282351, grad/param norm = 1.7348e-01, time/batch = 17.3798s	
18939/33150 (epoch 28.566), train_loss = 0.86693029, grad/param norm = 1.5522e-01, time/batch = 17.4519s	
18940/33150 (epoch 28.567), train_loss = 0.84597034, grad/param norm = 1.5803e-01, time/batch = 17.3882s	
18941/33150 (epoch 28.569), train_loss = 0.96388785, grad/param norm = 2.8172e-01, time/batch = 17.0373s	
18942/33150 (epoch 28.570), train_loss = 0.98507752, grad/param norm = 1.6794e-01, time/batch = 16.4432s	
18943/33150 (epoch 28.572), train_loss = 0.87037546, grad/param norm = 1.8561e-01, time/batch = 17.1266s	
18944/33150 (epoch 28.573), train_loss = 0.77635312, grad/param norm = 1.3744e-01, time/batch = 17.5406s	
18945/33150 (epoch 28.575), train_loss = 0.90942337, grad/param norm = 1.7177e-01, time/batch = 19.6109s	
18946/33150 (epoch 28.576), train_loss = 0.80681598, grad/param norm = 1.4241e-01, time/batch = 16.0946s	
18947/33150 (epoch 28.578), train_loss = 0.85239142, grad/param norm = 1.5108e-01, time/batch = 16.7846s	
18948/33150 (epoch 28.579), train_loss = 0.80647588, grad/param norm = 1.5247e-01, time/batch = 17.7174s	
18949/33150 (epoch 28.581), train_loss = 0.83014449, grad/param norm = 1.5620e-01, time/batch = 16.8714s	
18950/33150 (epoch 28.582), train_loss = 1.06378152, grad/param norm = 1.5742e-01, time/batch = 16.9721s	
18951/33150 (epoch 28.584), train_loss = 0.99911169, grad/param norm = 1.7601e-01, time/batch = 17.4718s	
18952/33150 (epoch 28.585), train_loss = 0.92870637, grad/param norm = 1.5960e-01, time/batch = 17.7130s	
18953/33150 (epoch 28.587), train_loss = 0.94234238, grad/param norm = 1.6929e-01, time/batch = 15.9587s	
18954/33150 (epoch 28.588), train_loss = 0.85603173, grad/param norm = 1.7457e-01, time/batch = 15.4074s	
18955/33150 (epoch 28.590), train_loss = 0.95075055, grad/param norm = 1.6467e-01, time/batch = 18.1366s	
18956/33150 (epoch 28.591), train_loss = 0.91560266, grad/param norm = 1.5251e-01, time/batch = 17.6223s	
18957/33150 (epoch 28.593), train_loss = 1.00641041, grad/param norm = 2.0024e-01, time/batch = 16.1450s	
18958/33150 (epoch 28.594), train_loss = 0.90185145, grad/param norm = 1.5971e-01, time/batch = 18.0589s	
18959/33150 (epoch 28.596), train_loss = 0.92632326, grad/param norm = 1.7529e-01, time/batch = 17.7165s	
18960/33150 (epoch 28.597), train_loss = 0.84076732, grad/param norm = 2.6607e-01, time/batch = 17.1345s	
18961/33150 (epoch 28.599), train_loss = 1.10855171, grad/param norm = 2.0351e-01, time/batch = 17.9670s	
18962/33150 (epoch 28.600), train_loss = 0.91858146, grad/param norm = 2.3110e-01, time/batch = 19.1135s	
18963/33150 (epoch 28.602), train_loss = 0.92782171, grad/param norm = 1.7621e-01, time/batch = 15.6916s	
18964/33150 (epoch 28.603), train_loss = 1.03767060, grad/param norm = 1.7615e-01, time/batch = 18.5447s	
18965/33150 (epoch 28.605), train_loss = 0.82795767, grad/param norm = 1.4858e-01, time/batch = 17.5562s	
18966/33150 (epoch 28.606), train_loss = 0.86254067, grad/param norm = 2.0386e-01, time/batch = 18.7119s	
18967/33150 (epoch 28.608), train_loss = 1.00197279, grad/param norm = 1.5115e-01, time/batch = 15.6927s	
18968/33150 (epoch 28.609), train_loss = 0.90666795, grad/param norm = 1.8222e-01, time/batch = 17.2902s	
18969/33150 (epoch 28.611), train_loss = 0.81535140, grad/param norm = 1.4365e-01, time/batch = 19.5387s	
18970/33150 (epoch 28.612), train_loss = 0.91953504, grad/param norm = 1.7775e-01, time/batch = 15.5412s	
18971/33150 (epoch 28.614), train_loss = 0.84014576, grad/param norm = 1.5670e-01, time/batch = 16.9584s	
18972/33150 (epoch 28.615), train_loss = 0.81365610, grad/param norm = 1.4616e-01, time/batch = 18.6245s	
18973/33150 (epoch 28.617), train_loss = 0.94179674, grad/param norm = 1.7480e-01, time/batch = 18.1145s	
18974/33150 (epoch 28.618), train_loss = 0.98557316, grad/param norm = 1.8919e-01, time/batch = 16.7214s	
18975/33150 (epoch 28.620), train_loss = 0.87039907, grad/param norm = 1.5252e-01, time/batch = 16.8934s	
18976/33150 (epoch 28.621), train_loss = 0.91053204, grad/param norm = 1.4714e-01, time/batch = 16.0382s	
18977/33150 (epoch 28.623), train_loss = 0.98589219, grad/param norm = 1.5372e-01, time/batch = 18.0396s	
18978/33150 (epoch 28.624), train_loss = 0.87923351, grad/param norm = 1.5442e-01, time/batch = 16.3987s	
18979/33150 (epoch 28.626), train_loss = 0.89109435, grad/param norm = 1.6260e-01, time/batch = 16.1532s	
18980/33150 (epoch 28.627), train_loss = 0.82969858, grad/param norm = 1.5755e-01, time/batch = 18.2902s	
18981/33150 (epoch 28.629), train_loss = 0.78660314, grad/param norm = 1.6848e-01, time/batch = 16.4561s	
18982/33150 (epoch 28.630), train_loss = 0.88394711, grad/param norm = 1.5327e-01, time/batch = 17.3963s	
18983/33150 (epoch 28.632), train_loss = 0.77921400, grad/param norm = 1.3429e-01, time/batch = 16.9513s	
18984/33150 (epoch 28.633), train_loss = 0.80324239, grad/param norm = 1.8255e-01, time/batch = 16.4528s	
18985/33150 (epoch 28.635), train_loss = 1.05974511, grad/param norm = 1.7720e-01, time/batch = 17.3079s	
18986/33150 (epoch 28.637), train_loss = 0.75630508, grad/param norm = 1.4421e-01, time/batch = 15.5586s	
18987/33150 (epoch 28.638), train_loss = 0.88190316, grad/param norm = 1.5632e-01, time/batch = 16.3894s	
18988/33150 (epoch 28.640), train_loss = 0.98270774, grad/param norm = 1.7310e-01, time/batch = 15.9599s	
18989/33150 (epoch 28.641), train_loss = 0.79780116, grad/param norm = 1.6188e-01, time/batch = 17.4573s	
18990/33150 (epoch 28.643), train_loss = 0.90957722, grad/param norm = 1.5455e-01, time/batch = 18.7096s	
18991/33150 (epoch 28.644), train_loss = 1.06721538, grad/param norm = 1.6992e-01, time/batch = 16.4650s	
18992/33150 (epoch 28.646), train_loss = 0.86975258, grad/param norm = 1.5029e-01, time/batch = 15.8742s	
18993/33150 (epoch 28.647), train_loss = 1.11029557, grad/param norm = 1.8079e-01, time/batch = 17.2296s	
18994/33150 (epoch 28.649), train_loss = 0.98159254, grad/param norm = 1.7982e-01, time/batch = 17.6316s	
18995/33150 (epoch 28.650), train_loss = 0.81890160, grad/param norm = 1.4941e-01, time/batch = 16.3988s	
18996/33150 (epoch 28.652), train_loss = 1.03882581, grad/param norm = 2.0074e-01, time/batch = 15.8935s	
18997/33150 (epoch 28.653), train_loss = 0.96471022, grad/param norm = 1.5529e-01, time/batch = 16.5626s	
18998/33150 (epoch 28.655), train_loss = 0.95707254, grad/param norm = 1.8603e-01, time/batch = 16.6461s	
18999/33150 (epoch 28.656), train_loss = 0.89759347, grad/param norm = 1.5678e-01, time/batch = 16.7952s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch28.66_1.7150.t7	
19000/33150 (epoch 28.658), train_loss = 0.89057930, grad/param norm = 1.7615e-01, time/batch = 18.2239s	
19001/33150 (epoch 28.659), train_loss = 2.01337357, grad/param norm = 7.0554e-01, time/batch = 15.8846s	
19002/33150 (epoch 28.661), train_loss = 0.92853684, grad/param norm = 1.8499e-01, time/batch = 19.4427s	
19003/33150 (epoch 28.662), train_loss = 0.89773918, grad/param norm = 1.9629e-01, time/batch = 16.2827s	
19004/33150 (epoch 28.664), train_loss = 1.03535434, grad/param norm = 1.9508e-01, time/batch = 17.6967s	
19005/33150 (epoch 28.665), train_loss = 0.98916484, grad/param norm = 1.6985e-01, time/batch = 16.6391s	
19006/33150 (epoch 28.667), train_loss = 1.03546437, grad/param norm = 1.9564e-01, time/batch = 17.2842s	
19007/33150 (epoch 28.668), train_loss = 1.05663919, grad/param norm = 1.9320e-01, time/batch = 18.9510s	
19008/33150 (epoch 28.670), train_loss = 0.87727878, grad/param norm = 1.8207e-01, time/batch = 16.2959s	
19009/33150 (epoch 28.671), train_loss = 0.88622532, grad/param norm = 1.8614e-01, time/batch = 16.7315s	
19010/33150 (epoch 28.673), train_loss = 1.05673377, grad/param norm = 1.5374e-01, time/batch = 19.1300s	
19011/33150 (epoch 28.674), train_loss = 0.99424323, grad/param norm = 1.7554e-01, time/batch = 15.8081s	
19012/33150 (epoch 28.676), train_loss = 0.92440439, grad/param norm = 1.6140e-01, time/batch = 17.1477s	
19013/33150 (epoch 28.677), train_loss = 1.08268653, grad/param norm = 1.7341e-01, time/batch = 15.3980s	
19014/33150 (epoch 28.679), train_loss = 0.91580280, grad/param norm = 1.5546e-01, time/batch = 17.1176s	
19015/33150 (epoch 28.680), train_loss = 1.05249548, grad/param norm = 1.9207e-01, time/batch = 15.9592s	
19016/33150 (epoch 28.682), train_loss = 0.90834002, grad/param norm = 1.4887e-01, time/batch = 18.1253s	
19017/33150 (epoch 28.683), train_loss = 0.79725971, grad/param norm = 1.4750e-01, time/batch = 18.8715s	
19018/33150 (epoch 28.685), train_loss = 0.88954083, grad/param norm = 1.8733e-01, time/batch = 17.3796s	
19019/33150 (epoch 28.686), train_loss = 0.79718981, grad/param norm = 1.5138e-01, time/batch = 18.0626s	
19020/33150 (epoch 28.688), train_loss = 0.82708605, grad/param norm = 1.6598e-01, time/batch = 16.4823s	
19021/33150 (epoch 28.689), train_loss = 0.84858196, grad/param norm = 1.6211e-01, time/batch = 18.3829s	
19022/33150 (epoch 28.691), train_loss = 0.73658116, grad/param norm = 1.3948e-01, time/batch = 18.5491s	
19023/33150 (epoch 28.692), train_loss = 0.82376250, grad/param norm = 1.6054e-01, time/batch = 16.2280s	
19024/33150 (epoch 28.694), train_loss = 0.72573691, grad/param norm = 1.4424e-01, time/batch = 18.1308s	
19025/33150 (epoch 28.695), train_loss = 0.86264610, grad/param norm = 1.4656e-01, time/batch = 16.0419s	
19026/33150 (epoch 28.697), train_loss = 0.78410032, grad/param norm = 1.3343e-01, time/batch = 18.2022s	
19027/33150 (epoch 28.698), train_loss = 0.83625183, grad/param norm = 1.7793e-01, time/batch = 16.0997s	
19028/33150 (epoch 28.700), train_loss = 0.69904492, grad/param norm = 1.2476e-01, time/batch = 15.8062s	
19029/33150 (epoch 28.701), train_loss = 0.80739564, grad/param norm = 1.4633e-01, time/batch = 15.7134s	
19030/33150 (epoch 28.703), train_loss = 0.90975370, grad/param norm = 1.7291e-01, time/batch = 15.1357s	
19031/33150 (epoch 28.704), train_loss = 0.78420327, grad/param norm = 1.3922e-01, time/batch = 17.6236s	
19032/33150 (epoch 28.706), train_loss = 0.85397895, grad/param norm = 1.4010e-01, time/batch = 15.9816s	
19033/33150 (epoch 28.707), train_loss = 0.85621458, grad/param norm = 1.5304e-01, time/batch = 16.3855s	
19034/33150 (epoch 28.709), train_loss = 0.90898850, grad/param norm = 1.4231e-01, time/batch = 16.1507s	
19035/33150 (epoch 28.710), train_loss = 0.89615786, grad/param norm = 1.6737e-01, time/batch = 19.0401s	
19036/33150 (epoch 28.712), train_loss = 0.97301342, grad/param norm = 1.5536e-01, time/batch = 16.2002s	
19037/33150 (epoch 28.713), train_loss = 0.94302398, grad/param norm = 1.4863e-01, time/batch = 17.2944s	
19038/33150 (epoch 28.715), train_loss = 0.87107259, grad/param norm = 1.5528e-01, time/batch = 17.9490s	
19039/33150 (epoch 28.716), train_loss = 0.95467824, grad/param norm = 1.7651e-01, time/batch = 16.0253s	
19040/33150 (epoch 28.718), train_loss = 0.93475743, grad/param norm = 1.6454e-01, time/batch = 17.1398s	
19041/33150 (epoch 28.719), train_loss = 1.00439088, grad/param norm = 2.0943e-01, time/batch = 17.9752s	
19042/33150 (epoch 28.721), train_loss = 0.88659640, grad/param norm = 1.6189e-01, time/batch = 17.8805s	
19043/33150 (epoch 28.722), train_loss = 0.92143740, grad/param norm = 1.4686e-01, time/batch = 16.5661s	
19044/33150 (epoch 28.724), train_loss = 0.89429818, grad/param norm = 1.6687e-01, time/batch = 16.0589s	
19045/33150 (epoch 28.725), train_loss = 1.00732830, grad/param norm = 2.0332e-01, time/batch = 18.7093s	
19046/33150 (epoch 28.727), train_loss = 0.97353026, grad/param norm = 1.7160e-01, time/batch = 15.5595s	
19047/33150 (epoch 28.729), train_loss = 0.91210325, grad/param norm = 1.6700e-01, time/batch = 15.9750s	
19048/33150 (epoch 28.730), train_loss = 0.90744531, grad/param norm = 1.7069e-01, time/batch = 16.9771s	
19049/33150 (epoch 28.732), train_loss = 0.98035389, grad/param norm = 1.6998e-01, time/batch = 17.9645s	
19050/33150 (epoch 28.733), train_loss = 0.76013393, grad/param norm = 1.3077e-01, time/batch = 17.1228s	
19051/33150 (epoch 28.735), train_loss = 0.82654011, grad/param norm = 1.4982e-01, time/batch = 17.6166s	
19052/33150 (epoch 28.736), train_loss = 0.89021626, grad/param norm = 1.5997e-01, time/batch = 17.5549s	
19053/33150 (epoch 28.738), train_loss = 0.91597389, grad/param norm = 1.9138e-01, time/batch = 16.2098s	
19054/33150 (epoch 28.739), train_loss = 1.01023259, grad/param norm = 1.9629e-01, time/batch = 16.3857s	
19055/33150 (epoch 28.741), train_loss = 0.98839054, grad/param norm = 1.6762e-01, time/batch = 17.4650s	
19056/33150 (epoch 28.742), train_loss = 0.78003013, grad/param norm = 1.6256e-01, time/batch = 17.6300s	
19057/33150 (epoch 28.744), train_loss = 0.99878807, grad/param norm = 1.8819e-01, time/batch = 15.5470s	
19058/33150 (epoch 28.745), train_loss = 0.87348548, grad/param norm = 1.4620e-01, time/batch = 16.5652s	
19059/33150 (epoch 28.747), train_loss = 0.70942520, grad/param norm = 1.5463e-01, time/batch = 17.6372s	
19060/33150 (epoch 28.748), train_loss = 0.80638482, grad/param norm = 1.5905e-01, time/batch = 16.4525s	
19061/33150 (epoch 28.750), train_loss = 0.95771609, grad/param norm = 1.7224e-01, time/batch = 17.8930s	
19062/33150 (epoch 28.751), train_loss = 0.91184365, grad/param norm = 1.5457e-01, time/batch = 17.2957s	
19063/33150 (epoch 28.753), train_loss = 0.77067312, grad/param norm = 1.6763e-01, time/batch = 17.7040s	
19064/33150 (epoch 28.754), train_loss = 1.11507091, grad/param norm = 2.1756e-01, time/batch = 18.0569s	
19065/33150 (epoch 28.756), train_loss = 0.92973403, grad/param norm = 1.8471e-01, time/batch = 17.7988s	
19066/33150 (epoch 28.757), train_loss = 0.93750878, grad/param norm = 1.7519e-01, time/batch = 19.9474s	
19067/33150 (epoch 28.759), train_loss = 1.05809382, grad/param norm = 2.0170e-01, time/batch = 15.9691s	
19068/33150 (epoch 28.760), train_loss = 0.96819957, grad/param norm = 1.7300e-01, time/batch = 16.7935s	
19069/33150 (epoch 28.762), train_loss = 0.93347097, grad/param norm = 1.7740e-01, time/batch = 18.2258s	
19070/33150 (epoch 28.763), train_loss = 0.95750282, grad/param norm = 1.7241e-01, time/batch = 16.5371s	
19071/33150 (epoch 28.765), train_loss = 0.88403598, grad/param norm = 1.4189e-01, time/batch = 16.8072s	
19072/33150 (epoch 28.766), train_loss = 0.82537021, grad/param norm = 1.7082e-01, time/batch = 17.2242s	
19073/33150 (epoch 28.768), train_loss = 0.85038498, grad/param norm = 1.5620e-01, time/batch = 18.1284s	
19074/33150 (epoch 28.769), train_loss = 0.96445461, grad/param norm = 1.8022e-01, time/batch = 16.9756s	
19075/33150 (epoch 28.771), train_loss = 0.92342302, grad/param norm = 1.8232e-01, time/batch = 16.8786s	
19076/33150 (epoch 28.772), train_loss = 0.97537782, grad/param norm = 1.8721e-01, time/batch = 18.9539s	
19077/33150 (epoch 28.774), train_loss = 1.06503505, grad/param norm = 1.7099e-01, time/batch = 17.8761s	
19078/33150 (epoch 28.775), train_loss = 0.98802149, grad/param norm = 2.2043e-01, time/batch = 17.8813s	
19079/33150 (epoch 28.777), train_loss = 0.98258493, grad/param norm = 1.7504e-01, time/batch = 17.3112s	
19080/33150 (epoch 28.778), train_loss = 0.93178020, grad/param norm = 1.6490e-01, time/batch = 15.6971s	
19081/33150 (epoch 28.780), train_loss = 0.79421036, grad/param norm = 1.4441e-01, time/batch = 16.9285s	
19082/33150 (epoch 28.781), train_loss = 0.92140460, grad/param norm = 1.5987e-01, time/batch = 15.7321s	
19083/33150 (epoch 28.783), train_loss = 0.93745387, grad/param norm = 1.6893e-01, time/batch = 18.9520s	
19084/33150 (epoch 28.784), train_loss = 0.91883796, grad/param norm = 1.7252e-01, time/batch = 17.1281s	
19085/33150 (epoch 28.786), train_loss = 0.90659105, grad/param norm = 1.5454e-01, time/batch = 19.4496s	
19086/33150 (epoch 28.787), train_loss = 0.84901663, grad/param norm = 1.3959e-01, time/batch = 15.8005s	
19087/33150 (epoch 28.789), train_loss = 0.76765393, grad/param norm = 1.5444e-01, time/batch = 18.1932s	
19088/33150 (epoch 28.790), train_loss = 0.80893516, grad/param norm = 1.4922e-01, time/batch = 15.6324s	
19089/33150 (epoch 28.792), train_loss = 0.94229680, grad/param norm = 1.8271e-01, time/batch = 18.3848s	
19090/33150 (epoch 28.793), train_loss = 0.88683121, grad/param norm = 1.7573e-01, time/batch = 18.6363s	
19091/33150 (epoch 28.795), train_loss = 0.86427773, grad/param norm = 1.7451e-01, time/batch = 15.8891s	
19092/33150 (epoch 28.796), train_loss = 0.87942677, grad/param norm = 1.5325e-01, time/batch = 19.7780s	
19093/33150 (epoch 28.798), train_loss = 0.85484948, grad/param norm = 1.4078e-01, time/batch = 16.2265s	
19094/33150 (epoch 28.799), train_loss = 0.77441747, grad/param norm = 1.8343e-01, time/batch = 17.7776s	
19095/33150 (epoch 28.801), train_loss = 0.91993678, grad/param norm = 1.8010e-01, time/batch = 17.7673s	
19096/33150 (epoch 28.802), train_loss = 0.83629255, grad/param norm = 1.5074e-01, time/batch = 17.7964s	
19097/33150 (epoch 28.804), train_loss = 0.88133508, grad/param norm = 1.5617e-01, time/batch = 17.6185s	
19098/33150 (epoch 28.805), train_loss = 0.83725332, grad/param norm = 1.6659e-01, time/batch = 15.4679s	
19099/33150 (epoch 28.807), train_loss = 0.88771149, grad/param norm = 1.4995e-01, time/batch = 17.8696s	
19100/33150 (epoch 28.808), train_loss = 1.01284853, grad/param norm = 1.6552e-01, time/batch = 17.0657s	
19101/33150 (epoch 28.810), train_loss = 0.84049285, grad/param norm = 1.6602e-01, time/batch = 16.1247s	
19102/33150 (epoch 28.811), train_loss = 0.94313374, grad/param norm = 1.8508e-01, time/batch = 17.1267s	
19103/33150 (epoch 28.813), train_loss = 0.87336880, grad/param norm = 1.4340e-01, time/batch = 17.2834s	
19104/33150 (epoch 28.814), train_loss = 0.85894038, grad/param norm = 1.9551e-01, time/batch = 18.3713s	
19105/33150 (epoch 28.816), train_loss = 0.89806551, grad/param norm = 1.7569e-01, time/batch = 30.6908s	
19106/33150 (epoch 28.817), train_loss = 0.95915725, grad/param norm = 1.6906e-01, time/batch = 16.5414s	
19107/33150 (epoch 28.819), train_loss = 0.92961464, grad/param norm = 1.7472e-01, time/batch = 17.3528s	
19108/33150 (epoch 28.821), train_loss = 0.79815831, grad/param norm = 1.4649e-01, time/batch = 17.2135s	
19109/33150 (epoch 28.822), train_loss = 0.85125789, grad/param norm = 1.6612e-01, time/batch = 15.6304s	
19110/33150 (epoch 28.824), train_loss = 0.89016755, grad/param norm = 1.5703e-01, time/batch = 18.4699s	
19111/33150 (epoch 28.825), train_loss = 0.92113627, grad/param norm = 1.6554e-01, time/batch = 15.7942s	
19112/33150 (epoch 28.827), train_loss = 0.96295998, grad/param norm = 2.2225e-01, time/batch = 16.5421s	
19113/33150 (epoch 28.828), train_loss = 0.80542953, grad/param norm = 1.5912e-01, time/batch = 15.6293s	
19114/33150 (epoch 28.830), train_loss = 0.97361271, grad/param norm = 1.8075e-01, time/batch = 18.6964s	
19115/33150 (epoch 28.831), train_loss = 0.83690940, grad/param norm = 1.6435e-01, time/batch = 17.1349s	
19116/33150 (epoch 28.833), train_loss = 0.82675230, grad/param norm = 1.5952e-01, time/batch = 18.0538s	
19117/33150 (epoch 28.834), train_loss = 0.98766486, grad/param norm = 1.5061e-01, time/batch = 18.2953s	
19118/33150 (epoch 28.836), train_loss = 1.01127292, grad/param norm = 1.4727e-01, time/batch = 15.8906s	
19119/33150 (epoch 28.837), train_loss = 0.86812199, grad/param norm = 1.6936e-01, time/batch = 18.6918s	
19120/33150 (epoch 28.839), train_loss = 0.96332671, grad/param norm = 1.9438e-01, time/batch = 15.7143s	
19121/33150 (epoch 28.840), train_loss = 0.99247054, grad/param norm = 1.6575e-01, time/batch = 17.5461s	
19122/33150 (epoch 28.842), train_loss = 1.04288318, grad/param norm = 1.8579e-01, time/batch = 16.9681s	
19123/33150 (epoch 28.843), train_loss = 1.01221028, grad/param norm = 1.9099e-01, time/batch = 17.6366s	
19124/33150 (epoch 28.845), train_loss = 0.84375340, grad/param norm = 1.5318e-01, time/batch = 16.7080s	
19125/33150 (epoch 28.846), train_loss = 1.09402646, grad/param norm = 2.4953e-01, time/batch = 15.8841s	
19126/33150 (epoch 28.848), train_loss = 1.00215799, grad/param norm = 1.7773e-01, time/batch = 17.2324s	
19127/33150 (epoch 28.849), train_loss = 1.02074217, grad/param norm = 1.6755e-01, time/batch = 17.6442s	
19128/33150 (epoch 28.851), train_loss = 0.98219149, grad/param norm = 1.9644e-01, time/batch = 17.3756s	
19129/33150 (epoch 28.852), train_loss = 1.06548597, grad/param norm = 1.5898e-01, time/batch = 18.3078s	
19130/33150 (epoch 28.854), train_loss = 0.94011277, grad/param norm = 1.6355e-01, time/batch = 18.3764s	
19131/33150 (epoch 28.855), train_loss = 0.80271233, grad/param norm = 1.5806e-01, time/batch = 17.1280s	
19132/33150 (epoch 28.857), train_loss = 0.76283746, grad/param norm = 1.5015e-01, time/batch = 17.7808s	
19133/33150 (epoch 28.858), train_loss = 0.86619740, grad/param norm = 1.4483e-01, time/batch = 17.1357s	
19134/33150 (epoch 28.860), train_loss = 0.82712628, grad/param norm = 1.4995e-01, time/batch = 17.2814s	
19135/33150 (epoch 28.861), train_loss = 0.81328888, grad/param norm = 1.5123e-01, time/batch = 17.4737s	
19136/33150 (epoch 28.863), train_loss = 0.90265958, grad/param norm = 1.4042e-01, time/batch = 17.1299s	
19137/33150 (epoch 28.864), train_loss = 0.94925804, grad/param norm = 1.5685e-01, time/batch = 18.2071s	
19138/33150 (epoch 28.866), train_loss = 0.96038846, grad/param norm = 1.5505e-01, time/batch = 18.5142s	
19139/33150 (epoch 28.867), train_loss = 0.95495404, grad/param norm = 1.5035e-01, time/batch = 19.0205s	
19140/33150 (epoch 28.869), train_loss = 0.95517151, grad/param norm = 1.9650e-01, time/batch = 16.6095s	
19141/33150 (epoch 28.870), train_loss = 0.85113825, grad/param norm = 1.6068e-01, time/batch = 17.8522s	
19142/33150 (epoch 28.872), train_loss = 0.95286155, grad/param norm = 1.5831e-01, time/batch = 16.5354s	
19143/33150 (epoch 28.873), train_loss = 0.74774675, grad/param norm = 1.3573e-01, time/batch = 15.0208s	
19144/33150 (epoch 28.875), train_loss = 1.04257523, grad/param norm = 1.6352e-01, time/batch = 15.0052s	
19145/33150 (epoch 28.876), train_loss = 0.78207803, grad/param norm = 1.6343e-01, time/batch = 14.9626s	
19146/33150 (epoch 28.878), train_loss = 0.84568061, grad/param norm = 1.4600e-01, time/batch = 16.7858s	
19147/33150 (epoch 28.879), train_loss = 0.84959658, grad/param norm = 1.4626e-01, time/batch = 16.9718s	
19148/33150 (epoch 28.881), train_loss = 0.83317249, grad/param norm = 1.5817e-01, time/batch = 18.0551s	
19149/33150 (epoch 28.882), train_loss = 0.72941448, grad/param norm = 1.3137e-01, time/batch = 15.1342s	
19150/33150 (epoch 28.884), train_loss = 0.88337817, grad/param norm = 1.5979e-01, time/batch = 15.3807s	
19151/33150 (epoch 28.885), train_loss = 0.68800568, grad/param norm = 1.4481e-01, time/batch = 18.7130s	
19152/33150 (epoch 28.887), train_loss = 1.01433256, grad/param norm = 1.8880e-01, time/batch = 19.0401s	
19153/33150 (epoch 28.888), train_loss = 0.94447989, grad/param norm = 1.7058e-01, time/batch = 17.2955s	
19154/33150 (epoch 28.890), train_loss = 0.85414372, grad/param norm = 1.8709e-01, time/batch = 18.9537s	
19155/33150 (epoch 28.891), train_loss = 0.81303619, grad/param norm = 1.6271e-01, time/batch = 15.9647s	
19156/33150 (epoch 28.893), train_loss = 0.96814736, grad/param norm = 1.8281e-01, time/batch = 15.6419s	
19157/33150 (epoch 28.894), train_loss = 0.95733732, grad/param norm = 1.9710e-01, time/batch = 15.9583s	
19158/33150 (epoch 28.896), train_loss = 0.89510595, grad/param norm = 1.5940e-01, time/batch = 16.8110s	
19159/33150 (epoch 28.897), train_loss = 0.95571995, grad/param norm = 1.5903e-01, time/batch = 17.5323s	
19160/33150 (epoch 28.899), train_loss = 0.77987020, grad/param norm = 1.9896e-01, time/batch = 15.8233s	
19161/33150 (epoch 28.900), train_loss = 1.10979789, grad/param norm = 1.9989e-01, time/batch = 15.4862s	
19162/33150 (epoch 28.902), train_loss = 1.11248165, grad/param norm = 1.8328e-01, time/batch = 16.3074s	
19163/33150 (epoch 28.903), train_loss = 0.91704825, grad/param norm = 1.8606e-01, time/batch = 15.7268s	
19164/33150 (epoch 28.905), train_loss = 0.93692700, grad/param norm = 1.5466e-01, time/batch = 16.3989s	
19165/33150 (epoch 28.906), train_loss = 0.95694495, grad/param norm = 2.1266e-01, time/batch = 17.7203s	
19166/33150 (epoch 28.908), train_loss = 1.02960205, grad/param norm = 1.7106e-01, time/batch = 16.7045s	
19167/33150 (epoch 28.910), train_loss = 0.99916987, grad/param norm = 1.6922e-01, time/batch = 17.1396s	
19168/33150 (epoch 28.911), train_loss = 0.78734736, grad/param norm = 1.4009e-01, time/batch = 16.3986s	
19169/33150 (epoch 28.913), train_loss = 0.84485995, grad/param norm = 1.7025e-01, time/batch = 19.0452s	
19170/33150 (epoch 28.914), train_loss = 0.97347126, grad/param norm = 1.9006e-01, time/batch = 16.9655s	
19171/33150 (epoch 28.916), train_loss = 0.85095390, grad/param norm = 1.7676e-01, time/batch = 16.8829s	
19172/33150 (epoch 28.917), train_loss = 0.94895266, grad/param norm = 1.8822e-01, time/batch = 15.2167s	
19173/33150 (epoch 28.919), train_loss = 1.05568969, grad/param norm = 2.1970e-01, time/batch = 18.7824s	
19174/33150 (epoch 28.920), train_loss = 1.00788614, grad/param norm = 1.6197e-01, time/batch = 16.3577s	
19175/33150 (epoch 28.922), train_loss = 1.05669511, grad/param norm = 1.9122e-01, time/batch = 17.5526s	
19176/33150 (epoch 28.923), train_loss = 0.92749106, grad/param norm = 1.8970e-01, time/batch = 16.8737s	
19177/33150 (epoch 28.925), train_loss = 1.01222545, grad/param norm = 1.7422e-01, time/batch = 17.2052s	
19178/33150 (epoch 28.926), train_loss = 0.90485139, grad/param norm = 1.6834e-01, time/batch = 17.7196s	
19179/33150 (epoch 28.928), train_loss = 0.87641510, grad/param norm = 1.5433e-01, time/batch = 16.6379s	
19180/33150 (epoch 28.929), train_loss = 0.99121867, grad/param norm = 1.6071e-01, time/batch = 18.5467s	
19181/33150 (epoch 28.931), train_loss = 1.04120645, grad/param norm = 1.9522e-01, time/batch = 17.2097s	
19182/33150 (epoch 28.932), train_loss = 0.92656117, grad/param norm = 1.7094e-01, time/batch = 16.6518s	
19183/33150 (epoch 28.934), train_loss = 0.94932082, grad/param norm = 1.5009e-01, time/batch = 16.4503s	
19184/33150 (epoch 28.935), train_loss = 1.01934829, grad/param norm = 1.8189e-01, time/batch = 17.0318s	
19185/33150 (epoch 28.937), train_loss = 1.02983879, grad/param norm = 1.5853e-01, time/batch = 18.6261s	
19186/33150 (epoch 28.938), train_loss = 0.96051941, grad/param norm = 1.5676e-01, time/batch = 16.3965s	
19187/33150 (epoch 28.940), train_loss = 1.17225296, grad/param norm = 2.1181e-01, time/batch = 17.5285s	
19188/33150 (epoch 28.941), train_loss = 0.93854788, grad/param norm = 1.3802e-01, time/batch = 15.6393s	
19189/33150 (epoch 28.943), train_loss = 0.78008377, grad/param norm = 1.6166e-01, time/batch = 16.8076s	
19190/33150 (epoch 28.944), train_loss = 0.99603187, grad/param norm = 1.6610e-01, time/batch = 16.8135s	
19191/33150 (epoch 28.946), train_loss = 0.80603187, grad/param norm = 1.5367e-01, time/batch = 17.3611s	
19192/33150 (epoch 28.947), train_loss = 0.95788126, grad/param norm = 1.5577e-01, time/batch = 16.4029s	
19193/33150 (epoch 28.949), train_loss = 1.03946056, grad/param norm = 1.6411e-01, time/batch = 16.6451s	
19194/33150 (epoch 28.950), train_loss = 0.97886049, grad/param norm = 2.2820e-01, time/batch = 17.9832s	
19195/33150 (epoch 28.952), train_loss = 0.85014023, grad/param norm = 1.5034e-01, time/batch = 16.7844s	
19196/33150 (epoch 28.953), train_loss = 0.87480742, grad/param norm = 1.5611e-01, time/batch = 15.7222s	
19197/33150 (epoch 28.955), train_loss = 0.81469401, grad/param norm = 1.6810e-01, time/batch = 15.3142s	
19198/33150 (epoch 28.956), train_loss = 0.99186699, grad/param norm = 1.5511e-01, time/batch = 15.3073s	
19199/33150 (epoch 28.958), train_loss = 0.82398896, grad/param norm = 1.4877e-01, time/batch = 15.4778s	
19200/33150 (epoch 28.959), train_loss = 0.88386864, grad/param norm = 1.5302e-01, time/batch = 18.4759s	
19201/33150 (epoch 28.961), train_loss = 0.84824285, grad/param norm = 1.6541e-01, time/batch = 18.7138s	
19202/33150 (epoch 28.962), train_loss = 0.81121531, grad/param norm = 1.9302e-01, time/batch = 16.5550s	
19203/33150 (epoch 28.964), train_loss = 0.91589966, grad/param norm = 1.6109e-01, time/batch = 17.8034s	
19204/33150 (epoch 28.965), train_loss = 0.90677750, grad/param norm = 1.8805e-01, time/batch = 18.4737s	
19205/33150 (epoch 28.967), train_loss = 0.90272089, grad/param norm = 1.8595e-01, time/batch = 17.1489s	
19206/33150 (epoch 28.968), train_loss = 0.75674031, grad/param norm = 1.4175e-01, time/batch = 16.6544s	
19207/33150 (epoch 28.970), train_loss = 0.85038757, grad/param norm = 1.5426e-01, time/batch = 17.6439s	
19208/33150 (epoch 28.971), train_loss = 0.92622679, grad/param norm = 1.6912e-01, time/batch = 19.2193s	
19209/33150 (epoch 28.973), train_loss = 1.02419003, grad/param norm = 1.8828e-01, time/batch = 16.1239s	
19210/33150 (epoch 28.974), train_loss = 1.04599780, grad/param norm = 1.6321e-01, time/batch = 17.2993s	
19211/33150 (epoch 28.976), train_loss = 1.00585225, grad/param norm = 1.5262e-01, time/batch = 16.4862s	
19212/33150 (epoch 28.977), train_loss = 1.04463274, grad/param norm = 1.7383e-01, time/batch = 15.2397s	
19213/33150 (epoch 28.979), train_loss = 1.00549704, grad/param norm = 1.9581e-01, time/batch = 15.6295s	
19214/33150 (epoch 28.980), train_loss = 1.06034241, grad/param norm = 1.7842e-01, time/batch = 15.2406s	
19215/33150 (epoch 28.982), train_loss = 0.92770512, grad/param norm = 2.1918e-01, time/batch = 15.2867s	
19216/33150 (epoch 28.983), train_loss = 0.82400707, grad/param norm = 1.5866e-01, time/batch = 15.1408s	
19217/33150 (epoch 28.985), train_loss = 1.03062909, grad/param norm = 1.7152e-01, time/batch = 15.7348s	
19218/33150 (epoch 28.986), train_loss = 0.78367873, grad/param norm = 1.5875e-01, time/batch = 15.9057s	
19219/33150 (epoch 28.988), train_loss = 0.88598499, grad/param norm = 2.1075e-01, time/batch = 18.7252s	
19220/33150 (epoch 28.989), train_loss = 0.88002381, grad/param norm = 1.5723e-01, time/batch = 16.5542s	
19221/33150 (epoch 28.991), train_loss = 0.98965826, grad/param norm = 2.3526e-01, time/batch = 17.5569s	
19222/33150 (epoch 28.992), train_loss = 0.89167591, grad/param norm = 1.6475e-01, time/batch = 16.9693s	
19223/33150 (epoch 28.994), train_loss = 0.94837523, grad/param norm = 1.7501e-01, time/batch = 17.1388s	
19224/33150 (epoch 28.995), train_loss = 0.87009251, grad/param norm = 1.6175e-01, time/batch = 16.0743s	
19225/33150 (epoch 28.997), train_loss = 0.91170588, grad/param norm = 1.6852e-01, time/batch = 15.9964s	
19226/33150 (epoch 28.998), train_loss = 0.75954646, grad/param norm = 1.5243e-01, time/batch = 17.5688s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
19227/33150 (epoch 29.000), train_loss = 0.76157172, grad/param norm = 1.6980e-01, time/batch = 16.2052s	
19228/33150 (epoch 29.002), train_loss = 1.20144617, grad/param norm = 1.8832e-01, time/batch = 15.6456s	
19229/33150 (epoch 29.003), train_loss = 0.81552467, grad/param norm = 1.5824e-01, time/batch = 16.8927s	
19230/33150 (epoch 29.005), train_loss = 0.79462099, grad/param norm = 1.4392e-01, time/batch = 17.5613s	
19231/33150 (epoch 29.006), train_loss = 0.77387035, grad/param norm = 1.4459e-01, time/batch = 15.7185s	
19232/33150 (epoch 29.008), train_loss = 0.98247469, grad/param norm = 1.6289e-01, time/batch = 15.6440s	
19233/33150 (epoch 29.009), train_loss = 0.94008766, grad/param norm = 1.6083e-01, time/batch = 15.5670s	
19234/33150 (epoch 29.011), train_loss = 1.01496099, grad/param norm = 1.7517e-01, time/batch = 16.3167s	
19235/33150 (epoch 29.012), train_loss = 0.91100972, grad/param norm = 1.7172e-01, time/batch = 15.0645s	
19236/33150 (epoch 29.014), train_loss = 0.83643249, grad/param norm = 1.6711e-01, time/batch = 17.5578s	
19237/33150 (epoch 29.015), train_loss = 0.84563765, grad/param norm = 1.6676e-01, time/batch = 16.0013s	
19238/33150 (epoch 29.017), train_loss = 0.81991715, grad/param norm = 1.5024e-01, time/batch = 15.6605s	
19239/33150 (epoch 29.018), train_loss = 0.92134578, grad/param norm = 1.7444e-01, time/batch = 16.2417s	
19240/33150 (epoch 29.020), train_loss = 0.99823440, grad/param norm = 1.7994e-01, time/batch = 14.6642s	
19241/33150 (epoch 29.021), train_loss = 0.81931349, grad/param norm = 1.6423e-01, time/batch = 15.4045s	
19242/33150 (epoch 29.023), train_loss = 1.07787285, grad/param norm = 1.5408e-01, time/batch = 15.3235s	
19243/33150 (epoch 29.024), train_loss = 0.95808047, grad/param norm = 1.8482e-01, time/batch = 16.5827s	
19244/33150 (epoch 29.026), train_loss = 0.73073431, grad/param norm = 1.4049e-01, time/batch = 18.1453s	
19245/33150 (epoch 29.027), train_loss = 0.73899152, grad/param norm = 1.3386e-01, time/batch = 16.7993s	
19246/33150 (epoch 29.029), train_loss = 0.86709156, grad/param norm = 1.7124e-01, time/batch = 15.6995s	
19247/33150 (epoch 29.030), train_loss = 0.87364169, grad/param norm = 1.3582e-01, time/batch = 16.3152s	
19248/33150 (epoch 29.032), train_loss = 0.81792446, grad/param norm = 1.6565e-01, time/batch = 16.8813s	
19249/33150 (epoch 29.033), train_loss = 0.83455051, grad/param norm = 1.5397e-01, time/batch = 16.3135s	
19250/33150 (epoch 29.035), train_loss = 1.08869656, grad/param norm = 2.2556e-01, time/batch = 15.6479s	
19251/33150 (epoch 29.036), train_loss = 0.96731630, grad/param norm = 1.8038e-01, time/batch = 18.5519s	
19252/33150 (epoch 29.038), train_loss = 1.11825741, grad/param norm = 1.9326e-01, time/batch = 17.6309s	
19253/33150 (epoch 29.039), train_loss = 0.97550489, grad/param norm = 1.5297e-01, time/batch = 17.1258s	
19254/33150 (epoch 29.041), train_loss = 0.91839697, grad/param norm = 1.5861e-01, time/batch = 17.3026s	
19255/33150 (epoch 29.042), train_loss = 0.86301523, grad/param norm = 1.5621e-01, time/batch = 19.4592s	
19256/33150 (epoch 29.044), train_loss = 0.88785210, grad/param norm = 1.4682e-01, time/batch = 16.9815s	
19257/33150 (epoch 29.045), train_loss = 0.96243396, grad/param norm = 1.5044e-01, time/batch = 15.6562s	
19258/33150 (epoch 29.047), train_loss = 0.79967401, grad/param norm = 1.4760e-01, time/batch = 18.7334s	
19259/33150 (epoch 29.048), train_loss = 0.99724832, grad/param norm = 1.8239e-01, time/batch = 16.9634s	
19260/33150 (epoch 29.050), train_loss = 0.89569260, grad/param norm = 1.7181e-01, time/batch = 15.6609s	
19261/33150 (epoch 29.051), train_loss = 0.92754794, grad/param norm = 1.4367e-01, time/batch = 17.0807s	
19262/33150 (epoch 29.053), train_loss = 0.92342807, grad/param norm = 1.7436e-01, time/batch = 17.1449s	
19263/33150 (epoch 29.054), train_loss = 1.06223186, grad/param norm = 1.6727e-01, time/batch = 16.8800s	
19264/33150 (epoch 29.056), train_loss = 0.90530517, grad/param norm = 1.6008e-01, time/batch = 16.4746s	
19265/33150 (epoch 29.057), train_loss = 0.94374602, grad/param norm = 1.5518e-01, time/batch = 16.5593s	
19266/33150 (epoch 29.059), train_loss = 0.85426146, grad/param norm = 1.6477e-01, time/batch = 16.8729s	
19267/33150 (epoch 29.060), train_loss = 0.83685679, grad/param norm = 1.5004e-01, time/batch = 15.7761s	
19268/33150 (epoch 29.062), train_loss = 0.88929913, grad/param norm = 1.5236e-01, time/batch = 17.1487s	
19269/33150 (epoch 29.063), train_loss = 0.86122885, grad/param norm = 1.6338e-01, time/batch = 17.8797s	
19270/33150 (epoch 29.065), train_loss = 0.86832493, grad/param norm = 1.4415e-01, time/batch = 17.6380s	
19271/33150 (epoch 29.066), train_loss = 0.86949619, grad/param norm = 1.6205e-01, time/batch = 17.9837s	
19272/33150 (epoch 29.068), train_loss = 0.96366079, grad/param norm = 1.6405e-01, time/batch = 18.2947s	
19273/33150 (epoch 29.069), train_loss = 0.94749797, grad/param norm = 1.7288e-01, time/batch = 15.7388s	
19274/33150 (epoch 29.071), train_loss = 0.91729690, grad/param norm = 1.4988e-01, time/batch = 16.0198s	
19275/33150 (epoch 29.072), train_loss = 0.92041129, grad/param norm = 1.6398e-01, time/batch = 15.5449s	
19276/33150 (epoch 29.074), train_loss = 0.78899794, grad/param norm = 1.8280e-01, time/batch = 15.6201s	
19277/33150 (epoch 29.075), train_loss = 0.82558114, grad/param norm = 1.5935e-01, time/batch = 16.1905s	
19278/33150 (epoch 29.077), train_loss = 0.90582245, grad/param norm = 2.1786e-01, time/batch = 22.7112s	
19279/33150 (epoch 29.078), train_loss = 1.04603577, grad/param norm = 1.9051e-01, time/batch = 36.1895s	
19280/33150 (epoch 29.080), train_loss = 1.03447863, grad/param norm = 1.6656e-01, time/batch = 30.1336s	
19281/33150 (epoch 29.081), train_loss = 0.79907851, grad/param norm = 1.6201e-01, time/batch = 37.6552s	
19282/33150 (epoch 29.083), train_loss = 0.69280966, grad/param norm = 1.6264e-01, time/batch = 32.5142s	
19283/33150 (epoch 29.084), train_loss = 0.78801270, grad/param norm = 1.7963e-01, time/batch = 35.0177s	
19284/33150 (epoch 29.086), train_loss = 0.83957693, grad/param norm = 1.9084e-01, time/batch = 37.6931s	
19285/33150 (epoch 29.087), train_loss = 0.79770685, grad/param norm = 1.4933e-01, time/batch = 34.1936s	
19286/33150 (epoch 29.089), train_loss = 0.84051015, grad/param norm = 1.6347e-01, time/batch = 32.7353s	
19287/33150 (epoch 29.090), train_loss = 0.87234636, grad/param norm = 1.8018e-01, time/batch = 32.1310s	
19288/33150 (epoch 29.092), train_loss = 0.85041586, grad/param norm = 1.7558e-01, time/batch = 24.2441s	
19289/33150 (epoch 29.094), train_loss = 0.94138313, grad/param norm = 1.8997e-01, time/batch = 15.2270s	
19290/33150 (epoch 29.095), train_loss = 0.84237130, grad/param norm = 1.5157e-01, time/batch = 15.7115s	
19291/33150 (epoch 29.097), train_loss = 0.78589813, grad/param norm = 1.8642e-01, time/batch = 16.2202s	
19292/33150 (epoch 29.098), train_loss = 1.12340110, grad/param norm = 1.9038e-01, time/batch = 17.0650s	
19293/33150 (epoch 29.100), train_loss = 1.10388618, grad/param norm = 2.0280e-01, time/batch = 15.5666s	
19294/33150 (epoch 29.101), train_loss = 0.85056852, grad/param norm = 1.6468e-01, time/batch = 17.2383s	
19295/33150 (epoch 29.103), train_loss = 0.93274265, grad/param norm = 1.7264e-01, time/batch = 15.8985s	
19296/33150 (epoch 29.104), train_loss = 0.83435973, grad/param norm = 1.7472e-01, time/batch = 15.7227s	
19297/33150 (epoch 29.106), train_loss = 1.01451404, grad/param norm = 1.9388e-01, time/batch = 17.4870s	
19298/33150 (epoch 29.107), train_loss = 1.09568637, grad/param norm = 1.9571e-01, time/batch = 17.0726s	
19299/33150 (epoch 29.109), train_loss = 0.88126934, grad/param norm = 1.3902e-01, time/batch = 17.9833s	
19300/33150 (epoch 29.110), train_loss = 1.03030212, grad/param norm = 1.8022e-01, time/batch = 18.1394s	
19301/33150 (epoch 29.112), train_loss = 0.84457712, grad/param norm = 1.6565e-01, time/batch = 18.9042s	
19302/33150 (epoch 29.113), train_loss = 0.87476850, grad/param norm = 1.7550e-01, time/batch = 16.4020s	
19303/33150 (epoch 29.115), train_loss = 1.07794630, grad/param norm = 1.7637e-01, time/batch = 16.9711s	
19304/33150 (epoch 29.116), train_loss = 0.92934574, grad/param norm = 1.5482e-01, time/batch = 19.1500s	
19305/33150 (epoch 29.118), train_loss = 0.94434395, grad/param norm = 1.8130e-01, time/batch = 17.3168s	
19306/33150 (epoch 29.119), train_loss = 0.96882903, grad/param norm = 2.1978e-01, time/batch = 17.7837s	
19307/33150 (epoch 29.121), train_loss = 0.88399377, grad/param norm = 1.5403e-01, time/batch = 31.2393s	
19308/33150 (epoch 29.122), train_loss = 1.06589064, grad/param norm = 2.0496e-01, time/batch = 16.7771s	
19309/33150 (epoch 29.124), train_loss = 0.76421180, grad/param norm = 1.3125e-01, time/batch = 15.4464s	
19310/33150 (epoch 29.125), train_loss = 1.02104512, grad/param norm = 1.6570e-01, time/batch = 17.7349s	
19311/33150 (epoch 29.127), train_loss = 0.91796947, grad/param norm = 1.6184e-01, time/batch = 18.4830s	
19312/33150 (epoch 29.128), train_loss = 0.96871229, grad/param norm = 1.8872e-01, time/batch = 16.9053s	
19313/33150 (epoch 29.130), train_loss = 0.91988056, grad/param norm = 1.7235e-01, time/batch = 16.0376s	
19314/33150 (epoch 29.131), train_loss = 1.12315601, grad/param norm = 1.7026e-01, time/batch = 18.8197s	
19315/33150 (epoch 29.133), train_loss = 0.84649607, grad/param norm = 1.5948e-01, time/batch = 14.8960s	
19316/33150 (epoch 29.134), train_loss = 1.03346772, grad/param norm = 1.6205e-01, time/batch = 17.4504s	
19317/33150 (epoch 29.136), train_loss = 0.91068196, grad/param norm = 1.7641e-01, time/batch = 18.7258s	
19318/33150 (epoch 29.137), train_loss = 0.98113131, grad/param norm = 1.5882e-01, time/batch = 17.3262s	
19319/33150 (epoch 29.139), train_loss = 0.97860865, grad/param norm = 1.7514e-01, time/batch = 18.4707s	
19320/33150 (epoch 29.140), train_loss = 1.09016942, grad/param norm = 1.8502e-01, time/batch = 18.4552s	
19321/33150 (epoch 29.142), train_loss = 0.99711650, grad/param norm = 1.6982e-01, time/batch = 17.8833s	
19322/33150 (epoch 29.143), train_loss = 0.93053859, grad/param norm = 1.9146e-01, time/batch = 19.3672s	
19323/33150 (epoch 29.145), train_loss = 0.91717431, grad/param norm = 2.0105e-01, time/batch = 17.1935s	
19324/33150 (epoch 29.146), train_loss = 1.00169912, grad/param norm = 1.9358e-01, time/batch = 16.8675s	
19325/33150 (epoch 29.148), train_loss = 1.05029253, grad/param norm = 1.5780e-01, time/batch = 19.1367s	
19326/33150 (epoch 29.149), train_loss = 0.96172377, grad/param norm = 1.9329e-01, time/batch = 16.1456s	
19327/33150 (epoch 29.151), train_loss = 1.10587002, grad/param norm = 1.8762e-01, time/batch = 19.9828s	
19328/33150 (epoch 29.152), train_loss = 0.88845639, grad/param norm = 1.5799e-01, time/batch = 17.2384s	
19329/33150 (epoch 29.154), train_loss = 0.88504484, grad/param norm = 1.9909e-01, time/batch = 16.6484s	
19330/33150 (epoch 29.155), train_loss = 0.76932199, grad/param norm = 1.5426e-01, time/batch = 16.6551s	
19331/33150 (epoch 29.157), train_loss = 0.88574114, grad/param norm = 1.6748e-01, time/batch = 17.2257s	
19332/33150 (epoch 29.158), train_loss = 0.87586745, grad/param norm = 1.5294e-01, time/batch = 17.3222s	
19333/33150 (epoch 29.160), train_loss = 0.99513768, grad/param norm = 1.8033e-01, time/batch = 16.3022s	
19334/33150 (epoch 29.161), train_loss = 0.85790925, grad/param norm = 2.0362e-01, time/batch = 16.6557s	
19335/33150 (epoch 29.163), train_loss = 0.80927558, grad/param norm = 1.5518e-01, time/batch = 17.9575s	
19336/33150 (epoch 29.164), train_loss = 0.96334701, grad/param norm = 1.7742e-01, time/batch = 15.8039s	
19337/33150 (epoch 29.166), train_loss = 0.90557657, grad/param norm = 1.6074e-01, time/batch = 17.8110s	
19338/33150 (epoch 29.167), train_loss = 0.93520546, grad/param norm = 1.5054e-01, time/batch = 17.0674s	
19339/33150 (epoch 29.169), train_loss = 0.96337813, grad/param norm = 2.0965e-01, time/batch = 18.8922s	
19340/33150 (epoch 29.170), train_loss = 0.86160830, grad/param norm = 1.9383e-01, time/batch = 16.7228s	
19341/33150 (epoch 29.172), train_loss = 1.01083602, grad/param norm = 2.1616e-01, time/batch = 15.1238s	
19342/33150 (epoch 29.173), train_loss = 0.98185738, grad/param norm = 2.1348e-01, time/batch = 15.6448s	
19343/33150 (epoch 29.175), train_loss = 0.88421103, grad/param norm = 1.5816e-01, time/batch = 17.5646s	
19344/33150 (epoch 29.176), train_loss = 1.00249267, grad/param norm = 2.0560e-01, time/batch = 16.9023s	
19345/33150 (epoch 29.178), train_loss = 1.11692200, grad/param norm = 1.9769e-01, time/batch = 17.1415s	
19346/33150 (epoch 29.179), train_loss = 0.97780586, grad/param norm = 1.6052e-01, time/batch = 16.6339s	
19347/33150 (epoch 29.181), train_loss = 0.92485043, grad/param norm = 1.8075e-01, time/batch = 16.3945s	
19348/33150 (epoch 29.183), train_loss = 0.92826663, grad/param norm = 1.9661e-01, time/batch = 18.9804s	
19349/33150 (epoch 29.184), train_loss = 1.15197050, grad/param norm = 1.7918e-01, time/batch = 16.4211s	
19350/33150 (epoch 29.186), train_loss = 1.07539266, grad/param norm = 1.7325e-01, time/batch = 17.3248s	
19351/33150 (epoch 29.187), train_loss = 0.94799056, grad/param norm = 1.9469e-01, time/batch = 15.6405s	
19352/33150 (epoch 29.189), train_loss = 0.74875020, grad/param norm = 1.7638e-01, time/batch = 17.7424s	
19353/33150 (epoch 29.190), train_loss = 0.84610832, grad/param norm = 1.9178e-01, time/batch = 18.4078s	
19354/33150 (epoch 29.192), train_loss = 0.95479932, grad/param norm = 1.8266e-01, time/batch = 15.9760s	
19355/33150 (epoch 29.193), train_loss = 1.02074060, grad/param norm = 1.8551e-01, time/batch = 18.3876s	
19356/33150 (epoch 29.195), train_loss = 1.13821794, grad/param norm = 1.9878e-01, time/batch = 16.2090s	
19357/33150 (epoch 29.196), train_loss = 1.02533363, grad/param norm = 1.5871e-01, time/batch = 17.5432s	
19358/33150 (epoch 29.198), train_loss = 0.80095565, grad/param norm = 1.5417e-01, time/batch = 17.1534s	
19359/33150 (epoch 29.199), train_loss = 1.01507242, grad/param norm = 2.2171e-01, time/batch = 16.1418s	
19360/33150 (epoch 29.201), train_loss = 0.87042463, grad/param norm = 1.4080e-01, time/batch = 18.2095s	
19361/33150 (epoch 29.202), train_loss = 0.73504012, grad/param norm = 1.4935e-01, time/batch = 16.8918s	
19362/33150 (epoch 29.204), train_loss = 0.97527733, grad/param norm = 1.7513e-01, time/batch = 16.1632s	
19363/33150 (epoch 29.205), train_loss = 0.96056505, grad/param norm = 1.7340e-01, time/batch = 15.3881s	
19364/33150 (epoch 29.207), train_loss = 0.96828536, grad/param norm = 1.5970e-01, time/batch = 16.3880s	
19365/33150 (epoch 29.208), train_loss = 0.99251764, grad/param norm = 1.6147e-01, time/batch = 15.6199s	
19366/33150 (epoch 29.210), train_loss = 0.87263983, grad/param norm = 1.5176e-01, time/batch = 16.5565s	
19367/33150 (epoch 29.211), train_loss = 0.94509792, grad/param norm = 1.8516e-01, time/batch = 15.8074s	
19368/33150 (epoch 29.213), train_loss = 0.99214778, grad/param norm = 1.6101e-01, time/batch = 17.1375s	
19369/33150 (epoch 29.214), train_loss = 0.89887215, grad/param norm = 1.5320e-01, time/batch = 18.7052s	
19370/33150 (epoch 29.216), train_loss = 0.84188237, grad/param norm = 1.8163e-01, time/batch = 17.9695s	
19371/33150 (epoch 29.217), train_loss = 0.89959422, grad/param norm = 1.6131e-01, time/batch = 17.4753s	
19372/33150 (epoch 29.219), train_loss = 0.85946128, grad/param norm = 1.7156e-01, time/batch = 15.5425s	
19373/33150 (epoch 29.220), train_loss = 0.86951274, grad/param norm = 1.4755e-01, time/batch = 19.1235s	
19374/33150 (epoch 29.222), train_loss = 1.04812918, grad/param norm = 1.7357e-01, time/batch = 16.7217s	
19375/33150 (epoch 29.223), train_loss = 0.91295451, grad/param norm = 1.6063e-01, time/batch = 16.4721s	
19376/33150 (epoch 29.225), train_loss = 1.05949935, grad/param norm = 1.7338e-01, time/batch = 16.3908s	
19377/33150 (epoch 29.226), train_loss = 0.92852321, grad/param norm = 1.7254e-01, time/batch = 15.8970s	
19378/33150 (epoch 29.228), train_loss = 0.91477483, grad/param norm = 1.7054e-01, time/batch = 16.6284s	
19379/33150 (epoch 29.229), train_loss = 0.92922117, grad/param norm = 1.7533e-01, time/batch = 16.0718s	
19380/33150 (epoch 29.231), train_loss = 1.02672205, grad/param norm = 1.8881e-01, time/batch = 18.1485s	
19381/33150 (epoch 29.232), train_loss = 0.95236707, grad/param norm = 2.1672e-01, time/batch = 16.8168s	
19382/33150 (epoch 29.234), train_loss = 0.94291210, grad/param norm = 1.7276e-01, time/batch = 17.3071s	
19383/33150 (epoch 29.235), train_loss = 0.97005386, grad/param norm = 1.7796e-01, time/batch = 17.3044s	
19384/33150 (epoch 29.237), train_loss = 0.95643876, grad/param norm = 2.1904e-01, time/batch = 18.4766s	
19385/33150 (epoch 29.238), train_loss = 0.99627872, grad/param norm = 1.8272e-01, time/batch = 17.6282s	
19386/33150 (epoch 29.240), train_loss = 0.97677780, grad/param norm = 1.6354e-01, time/batch = 16.7050s	
19387/33150 (epoch 29.241), train_loss = 1.01184980, grad/param norm = 1.8318e-01, time/batch = 15.6429s	
19388/33150 (epoch 29.243), train_loss = 0.98300347, grad/param norm = 1.7645e-01, time/batch = 16.9661s	
19389/33150 (epoch 29.244), train_loss = 0.91932409, grad/param norm = 1.5172e-01, time/batch = 15.7892s	
19390/33150 (epoch 29.246), train_loss = 0.98110491, grad/param norm = 1.6082e-01, time/batch = 17.3918s	
19391/33150 (epoch 29.247), train_loss = 0.88581946, grad/param norm = 1.6500e-01, time/batch = 16.7432s	
19392/33150 (epoch 29.249), train_loss = 1.03478152, grad/param norm = 1.7670e-01, time/batch = 15.5570s	
19393/33150 (epoch 29.250), train_loss = 0.97353850, grad/param norm = 1.4869e-01, time/batch = 15.9688s	
19394/33150 (epoch 29.252), train_loss = 0.98814236, grad/param norm = 1.5539e-01, time/batch = 16.6565s	
19395/33150 (epoch 29.253), train_loss = 0.89551167, grad/param norm = 1.5923e-01, time/batch = 18.2171s	
19396/33150 (epoch 29.255), train_loss = 0.91921133, grad/param norm = 1.4796e-01, time/batch = 16.5381s	
19397/33150 (epoch 29.256), train_loss = 1.03763701, grad/param norm = 1.6066e-01, time/batch = 17.4898s	
19398/33150 (epoch 29.258), train_loss = 0.88299268, grad/param norm = 1.9353e-01, time/batch = 16.2169s	
19399/33150 (epoch 29.259), train_loss = 0.77507907, grad/param norm = 1.6802e-01, time/batch = 17.3872s	
19400/33150 (epoch 29.261), train_loss = 0.82195990, grad/param norm = 1.3741e-01, time/batch = 15.4563s	
19401/33150 (epoch 29.262), train_loss = 1.02983126, grad/param norm = 2.2103e-01, time/batch = 17.1597s	
19402/33150 (epoch 29.264), train_loss = 0.72850637, grad/param norm = 1.5077e-01, time/batch = 15.8982s	
19403/33150 (epoch 29.265), train_loss = 0.96409155, grad/param norm = 1.7176e-01, time/batch = 15.8712s	
19404/33150 (epoch 29.267), train_loss = 0.98783133, grad/param norm = 1.7504e-01, time/batch = 16.8216s	
19405/33150 (epoch 29.268), train_loss = 1.02209319, grad/param norm = 1.4932e-01, time/batch = 19.4857s	
19406/33150 (epoch 29.270), train_loss = 1.10013168, grad/param norm = 1.6631e-01, time/batch = 15.7448s	
19407/33150 (epoch 29.271), train_loss = 1.04423413, grad/param norm = 1.9988e-01, time/batch = 17.4792s	
19408/33150 (epoch 29.273), train_loss = 1.04293287, grad/param norm = 1.6457e-01, time/batch = 17.6425s	
19409/33150 (epoch 29.275), train_loss = 1.08504504, grad/param norm = 1.7707e-01, time/batch = 18.3178s	
19410/33150 (epoch 29.276), train_loss = 0.96109953, grad/param norm = 1.7158e-01, time/batch = 15.8718s	
19411/33150 (epoch 29.278), train_loss = 1.03463381, grad/param norm = 1.6563e-01, time/batch = 16.9900s	
19412/33150 (epoch 29.279), train_loss = 0.99325197, grad/param norm = 1.4965e-01, time/batch = 18.4642s	
19413/33150 (epoch 29.281), train_loss = 0.94393875, grad/param norm = 1.6146e-01, time/batch = 16.7859s	
19414/33150 (epoch 29.282), train_loss = 0.95650637, grad/param norm = 1.4001e-01, time/batch = 16.3141s	
19415/33150 (epoch 29.284), train_loss = 0.85218051, grad/param norm = 1.6321e-01, time/batch = 18.7195s	
19416/33150 (epoch 29.285), train_loss = 0.96690506, grad/param norm = 1.6595e-01, time/batch = 18.5616s	
19417/33150 (epoch 29.287), train_loss = 0.82167102, grad/param norm = 1.5950e-01, time/batch = 15.7061s	
19418/33150 (epoch 29.288), train_loss = 1.02511535, grad/param norm = 1.7196e-01, time/batch = 16.5665s	
19419/33150 (epoch 29.290), train_loss = 0.81742989, grad/param norm = 1.7902e-01, time/batch = 17.9814s	
19420/33150 (epoch 29.291), train_loss = 0.77478047, grad/param norm = 1.5491e-01, time/batch = 18.6469s	
19421/33150 (epoch 29.293), train_loss = 0.95269713, grad/param norm = 1.6472e-01, time/batch = 16.3095s	
19422/33150 (epoch 29.294), train_loss = 0.72150054, grad/param norm = 1.5623e-01, time/batch = 15.6202s	
19423/33150 (epoch 29.296), train_loss = 0.91703855, grad/param norm = 1.4547e-01, time/batch = 16.7143s	
19424/33150 (epoch 29.297), train_loss = 0.87230151, grad/param norm = 1.6486e-01, time/batch = 17.3830s	
19425/33150 (epoch 29.299), train_loss = 0.86670744, grad/param norm = 1.9003e-01, time/batch = 16.6259s	
19426/33150 (epoch 29.300), train_loss = 0.87201771, grad/param norm = 1.3954e-01, time/batch = 18.0710s	
19427/33150 (epoch 29.302), train_loss = 0.91461808, grad/param norm = 1.7168e-01, time/batch = 19.1406s	
19428/33150 (epoch 29.303), train_loss = 0.89530302, grad/param norm = 1.6560e-01, time/batch = 15.8723s	
19429/33150 (epoch 29.305), train_loss = 0.98595947, grad/param norm = 1.6669e-01, time/batch = 17.8872s	
19430/33150 (epoch 29.306), train_loss = 0.99497825, grad/param norm = 2.2775e-01, time/batch = 17.7033s	
19431/33150 (epoch 29.308), train_loss = 1.14924728, grad/param norm = 1.8007e-01, time/batch = 16.7855s	
19432/33150 (epoch 29.309), train_loss = 0.77098849, grad/param norm = 1.4240e-01, time/batch = 15.8951s	
19433/33150 (epoch 29.311), train_loss = 0.89227756, grad/param norm = 1.6122e-01, time/batch = 16.4014s	
19434/33150 (epoch 29.312), train_loss = 0.73661787, grad/param norm = 1.6368e-01, time/batch = 18.3149s	
19435/33150 (epoch 29.314), train_loss = 0.88755692, grad/param norm = 1.7462e-01, time/batch = 15.4749s	
19436/33150 (epoch 29.315), train_loss = 0.97895069, grad/param norm = 1.5616e-01, time/batch = 17.1465s	
19437/33150 (epoch 29.317), train_loss = 0.75077024, grad/param norm = 1.3685e-01, time/batch = 18.1529s	
19438/33150 (epoch 29.318), train_loss = 0.85620892, grad/param norm = 1.5324e-01, time/batch = 16.4795s	
19439/33150 (epoch 29.320), train_loss = 0.78392647, grad/param norm = 1.4547e-01, time/batch = 17.3947s	
19440/33150 (epoch 29.321), train_loss = 0.91487952, grad/param norm = 1.5449e-01, time/batch = 15.3961s	
19441/33150 (epoch 29.323), train_loss = 0.87915226, grad/param norm = 1.5951e-01, time/batch = 16.3128s	
19442/33150 (epoch 29.324), train_loss = 0.95719801, grad/param norm = 1.9332e-01, time/batch = 15.7248s	
19443/33150 (epoch 29.326), train_loss = 0.93261525, grad/param norm = 1.5872e-01, time/batch = 18.7967s	
19444/33150 (epoch 29.327), train_loss = 1.01062787, grad/param norm = 1.7228e-01, time/batch = 18.0609s	
19445/33150 (epoch 29.329), train_loss = 0.96011694, grad/param norm = 1.6238e-01, time/batch = 15.9809s	
19446/33150 (epoch 29.330), train_loss = 0.92969445, grad/param norm = 1.8318e-01, time/batch = 16.3941s	
19447/33150 (epoch 29.332), train_loss = 0.91036163, grad/param norm = 1.4786e-01, time/batch = 16.5617s	
19448/33150 (epoch 29.333), train_loss = 0.96573832, grad/param norm = 1.4573e-01, time/batch = 16.9887s	
19449/33150 (epoch 29.335), train_loss = 0.85148602, grad/param norm = 1.5455e-01, time/batch = 15.5533s	
19450/33150 (epoch 29.336), train_loss = 0.84278375, grad/param norm = 1.8998e-01, time/batch = 17.7358s	
19451/33150 (epoch 29.338), train_loss = 0.78829405, grad/param norm = 1.6598e-01, time/batch = 16.5798s	
19452/33150 (epoch 29.339), train_loss = 0.99599674, grad/param norm = 1.6638e-01, time/batch = 17.4552s	
19453/33150 (epoch 29.341), train_loss = 0.93093053, grad/param norm = 1.7034e-01, time/batch = 16.3027s	
19454/33150 (epoch 29.342), train_loss = 0.85157332, grad/param norm = 1.6266e-01, time/batch = 17.5346s	
19455/33150 (epoch 29.344), train_loss = 0.92643050, grad/param norm = 1.7670e-01, time/batch = 18.3946s	
19456/33150 (epoch 29.345), train_loss = 0.89501141, grad/param norm = 1.6102e-01, time/batch = 16.3122s	
19457/33150 (epoch 29.347), train_loss = 0.74566942, grad/param norm = 1.4287e-01, time/batch = 18.0674s	
19458/33150 (epoch 29.348), train_loss = 0.94710710, grad/param norm = 1.6643e-01, time/batch = 18.7927s	
19459/33150 (epoch 29.350), train_loss = 0.83115879, grad/param norm = 1.7319e-01, time/batch = 15.9698s	
19460/33150 (epoch 29.351), train_loss = 0.99276917, grad/param norm = 1.6838e-01, time/batch = 16.9711s	
19461/33150 (epoch 29.353), train_loss = 0.94599854, grad/param norm = 1.5694e-01, time/batch = 19.0499s	
19462/33150 (epoch 29.354), train_loss = 1.14863069, grad/param norm = 1.7092e-01, time/batch = 16.0603s	
19463/33150 (epoch 29.356), train_loss = 1.01736173, grad/param norm = 1.8245e-01, time/batch = 15.6540s	
19464/33150 (epoch 29.357), train_loss = 0.95110588, grad/param norm = 1.6874e-01, time/batch = 15.4013s	
19465/33150 (epoch 29.359), train_loss = 0.98676934, grad/param norm = 1.6263e-01, time/batch = 16.1593s	
19466/33150 (epoch 29.360), train_loss = 0.96378345, grad/param norm = 1.8383e-01, time/batch = 16.8849s	
19467/33150 (epoch 29.362), train_loss = 1.03430643, grad/param norm = 1.8592e-01, time/batch = 15.8625s	
19468/33150 (epoch 29.363), train_loss = 0.94507314, grad/param norm = 1.6174e-01, time/batch = 17.0556s	
19469/33150 (epoch 29.365), train_loss = 0.89799335, grad/param norm = 1.4497e-01, time/batch = 16.5559s	
19470/33150 (epoch 29.367), train_loss = 0.86875685, grad/param norm = 1.5718e-01, time/batch = 16.5437s	
19471/33150 (epoch 29.368), train_loss = 0.90959371, grad/param norm = 1.8688e-01, time/batch = 16.1488s	
19472/33150 (epoch 29.370), train_loss = 0.94460256, grad/param norm = 1.7338e-01, time/batch = 16.5542s	
19473/33150 (epoch 29.371), train_loss = 0.82280108, grad/param norm = 1.6594e-01, time/batch = 16.4963s	
19474/33150 (epoch 29.373), train_loss = 0.96493752, grad/param norm = 1.8168e-01, time/batch = 16.2196s	
19475/33150 (epoch 29.374), train_loss = 0.89939495, grad/param norm = 1.4989e-01, time/batch = 15.3811s	
19476/33150 (epoch 29.376), train_loss = 1.01347598, grad/param norm = 1.6130e-01, time/batch = 16.7293s	
19477/33150 (epoch 29.377), train_loss = 0.84802660, grad/param norm = 1.5863e-01, time/batch = 16.3896s	
19478/33150 (epoch 29.379), train_loss = 0.98029876, grad/param norm = 1.8272e-01, time/batch = 15.9781s	
19479/33150 (epoch 29.380), train_loss = 0.97297165, grad/param norm = 1.5615e-01, time/batch = 16.7205s	
19480/33150 (epoch 29.382), train_loss = 0.90061190, grad/param norm = 1.6140e-01, time/batch = 16.0714s	
19481/33150 (epoch 29.383), train_loss = 0.86080290, grad/param norm = 1.8227e-01, time/batch = 16.0527s	
19482/33150 (epoch 29.385), train_loss = 0.87695999, grad/param norm = 1.5965e-01, time/batch = 16.1362s	
19483/33150 (epoch 29.386), train_loss = 0.79776007, grad/param norm = 1.4599e-01, time/batch = 15.6069s	
19484/33150 (epoch 29.388), train_loss = 0.85731420, grad/param norm = 1.5713e-01, time/batch = 16.7336s	
19485/33150 (epoch 29.389), train_loss = 0.85184408, grad/param norm = 1.4640e-01, time/batch = 17.2035s	
19486/33150 (epoch 29.391), train_loss = 1.07588415, grad/param norm = 1.7515e-01, time/batch = 17.1305s	
19487/33150 (epoch 29.392), train_loss = 0.88664396, grad/param norm = 1.6843e-01, time/batch = 15.6509s	
19488/33150 (epoch 29.394), train_loss = 0.77211212, grad/param norm = 1.3080e-01, time/batch = 16.5550s	
19489/33150 (epoch 29.395), train_loss = 0.74210879, grad/param norm = 1.5763e-01, time/batch = 16.2083s	
19490/33150 (epoch 29.397), train_loss = 0.63525885, grad/param norm = 1.3499e-01, time/batch = 16.5666s	
19491/33150 (epoch 29.398), train_loss = 0.91400514, grad/param norm = 1.5633e-01, time/batch = 16.6632s	
19492/33150 (epoch 29.400), train_loss = 0.88494249, grad/param norm = 1.4040e-01, time/batch = 15.8034s	
19493/33150 (epoch 29.401), train_loss = 0.79981005, grad/param norm = 1.4904e-01, time/batch = 16.8985s	
19494/33150 (epoch 29.403), train_loss = 0.76911814, grad/param norm = 1.4237e-01, time/batch = 15.1391s	
19495/33150 (epoch 29.404), train_loss = 0.93134486, grad/param norm = 1.6715e-01, time/batch = 16.0589s	
19496/33150 (epoch 29.406), train_loss = 0.86336095, grad/param norm = 1.3783e-01, time/batch = 16.7152s	
19497/33150 (epoch 29.407), train_loss = 0.79129602, grad/param norm = 1.4446e-01, time/batch = 15.7427s	
19498/33150 (epoch 29.409), train_loss = 0.74850258, grad/param norm = 1.5012e-01, time/batch = 16.4627s	
19499/33150 (epoch 29.410), train_loss = 0.93116266, grad/param norm = 1.6693e-01, time/batch = 17.6163s	
19500/33150 (epoch 29.412), train_loss = 0.95432738, grad/param norm = 1.6734e-01, time/batch = 15.9757s	
19501/33150 (epoch 29.413), train_loss = 0.80880994, grad/param norm = 1.5567e-01, time/batch = 15.9826s	
19502/33150 (epoch 29.415), train_loss = 0.93161690, grad/param norm = 1.5455e-01, time/batch = 18.2301s	
19503/33150 (epoch 29.416), train_loss = 0.85761488, grad/param norm = 1.5331e-01, time/batch = 16.6319s	
19504/33150 (epoch 29.418), train_loss = 0.97069113, grad/param norm = 2.2189e-01, time/batch = 16.1310s	
19505/33150 (epoch 29.419), train_loss = 0.88661366, grad/param norm = 1.6180e-01, time/batch = 15.9835s	
19506/33150 (epoch 29.421), train_loss = 0.89638948, grad/param norm = 2.1128e-01, time/batch = 17.2178s	
19507/33150 (epoch 29.422), train_loss = 0.87279896, grad/param norm = 1.4717e-01, time/batch = 16.0553s	
19508/33150 (epoch 29.424), train_loss = 0.85710954, grad/param norm = 1.6370e-01, time/batch = 17.7105s	
19509/33150 (epoch 29.425), train_loss = 0.98224273, grad/param norm = 1.6254e-01, time/batch = 16.9662s	
19510/33150 (epoch 29.427), train_loss = 0.89348976, grad/param norm = 1.3958e-01, time/batch = 17.6301s	
19511/33150 (epoch 29.428), train_loss = 0.91581344, grad/param norm = 1.6095e-01, time/batch = 18.2092s	
19512/33150 (epoch 29.430), train_loss = 0.91926097, grad/param norm = 1.6475e-01, time/batch = 17.9738s	
19513/33150 (epoch 29.431), train_loss = 0.97694941, grad/param norm = 1.8268e-01, time/batch = 16.5401s	
19514/33150 (epoch 29.433), train_loss = 0.90690522, grad/param norm = 1.8007e-01, time/batch = 15.7183s	
19515/33150 (epoch 29.434), train_loss = 0.79924593, grad/param norm = 1.5617e-01, time/batch = 17.8172s	
19516/33150 (epoch 29.436), train_loss = 0.89699364, grad/param norm = 1.5459e-01, time/batch = 16.5588s	
19517/33150 (epoch 29.437), train_loss = 0.91827912, grad/param norm = 1.6299e-01, time/batch = 23.5334s	
19518/33150 (epoch 29.439), train_loss = 1.05544928, grad/param norm = 1.5721e-01, time/batch = 21.3477s	
19519/33150 (epoch 29.440), train_loss = 0.96345462, grad/param norm = 1.5942e-01, time/batch = 16.7360s	
19520/33150 (epoch 29.442), train_loss = 0.80155669, grad/param norm = 1.5821e-01, time/batch = 16.2148s	
19521/33150 (epoch 29.443), train_loss = 0.94707715, grad/param norm = 1.6365e-01, time/batch = 15.7959s	
19522/33150 (epoch 29.445), train_loss = 0.93328025, grad/param norm = 1.7695e-01, time/batch = 16.0782s	
19523/33150 (epoch 29.446), train_loss = 0.93360281, grad/param norm = 1.9659e-01, time/batch = 16.9791s	
19524/33150 (epoch 29.448), train_loss = 1.00567236, grad/param norm = 1.6574e-01, time/batch = 15.6347s	
19525/33150 (epoch 29.449), train_loss = 0.92848299, grad/param norm = 1.5738e-01, time/batch = 17.4633s	
19526/33150 (epoch 29.451), train_loss = 0.90968254, grad/param norm = 2.0155e-01, time/batch = 15.0690s	
19527/33150 (epoch 29.452), train_loss = 1.09489761, grad/param norm = 1.7638e-01, time/batch = 16.4749s	
19528/33150 (epoch 29.454), train_loss = 0.90822126, grad/param norm = 1.7064e-01, time/batch = 15.8960s	
19529/33150 (epoch 29.456), train_loss = 0.81981422, grad/param norm = 1.5082e-01, time/batch = 15.9146s	
19530/33150 (epoch 29.457), train_loss = 0.93302208, grad/param norm = 1.7827e-01, time/batch = 16.3965s	
19531/33150 (epoch 29.459), train_loss = 1.02807628, grad/param norm = 2.4695e-01, time/batch = 16.6283s	
19532/33150 (epoch 29.460), train_loss = 0.95447889, grad/param norm = 1.5074e-01, time/batch = 16.2152s	
19533/33150 (epoch 29.462), train_loss = 1.00753746, grad/param norm = 1.8457e-01, time/batch = 17.8110s	
19534/33150 (epoch 29.463), train_loss = 1.14490017, grad/param norm = 2.2173e-01, time/batch = 16.7932s	
19535/33150 (epoch 29.465), train_loss = 0.95694673, grad/param norm = 1.6710e-01, time/batch = 15.8043s	
19536/33150 (epoch 29.466), train_loss = 0.88920830, grad/param norm = 1.6264e-01, time/batch = 15.1299s	
19537/33150 (epoch 29.468), train_loss = 1.12616357, grad/param norm = 1.6909e-01, time/batch = 15.2833s	
19538/33150 (epoch 29.469), train_loss = 0.90052791, grad/param norm = 1.7093e-01, time/batch = 16.7149s	
19539/33150 (epoch 29.471), train_loss = 0.84703193, grad/param norm = 1.4974e-01, time/batch = 16.1464s	
19540/33150 (epoch 29.472), train_loss = 0.94230779, grad/param norm = 1.6698e-01, time/batch = 15.5148s	
19541/33150 (epoch 29.474), train_loss = 0.99646191, grad/param norm = 2.1458e-01, time/batch = 16.6325s	
19542/33150 (epoch 29.475), train_loss = 1.14777404, grad/param norm = 1.7839e-01, time/batch = 15.7802s	
19543/33150 (epoch 29.477), train_loss = 1.05127552, grad/param norm = 1.9511e-01, time/batch = 17.0353s	
19544/33150 (epoch 29.478), train_loss = 0.98395610, grad/param norm = 1.5557e-01, time/batch = 14.9773s	
19545/33150 (epoch 29.480), train_loss = 0.86027925, grad/param norm = 1.5366e-01, time/batch = 15.1432s	
19546/33150 (epoch 29.481), train_loss = 0.78304477, grad/param norm = 1.6200e-01, time/batch = 15.2776s	
19547/33150 (epoch 29.483), train_loss = 0.87172780, grad/param norm = 1.6262e-01, time/batch = 15.4792s	
19548/33150 (epoch 29.484), train_loss = 0.86420598, grad/param norm = 1.6871e-01, time/batch = 15.8221s	
19549/33150 (epoch 29.486), train_loss = 0.85948025, grad/param norm = 1.6868e-01, time/batch = 16.5358s	
19550/33150 (epoch 29.487), train_loss = 0.94090111, grad/param norm = 1.8965e-01, time/batch = 16.8742s	
19551/33150 (epoch 29.489), train_loss = 0.90876496, grad/param norm = 1.7264e-01, time/batch = 17.3125s	
19552/33150 (epoch 29.490), train_loss = 0.76397256, grad/param norm = 1.3548e-01, time/batch = 15.7255s	
19553/33150 (epoch 29.492), train_loss = 0.87454442, grad/param norm = 1.6663e-01, time/batch = 15.8898s	
19554/33150 (epoch 29.493), train_loss = 0.99271257, grad/param norm = 1.6570e-01, time/batch = 15.4617s	
19555/33150 (epoch 29.495), train_loss = 0.99267322, grad/param norm = 1.5781e-01, time/batch = 15.5603s	
19556/33150 (epoch 29.496), train_loss = 0.90223995, grad/param norm = 1.5848e-01, time/batch = 15.6898s	
19557/33150 (epoch 29.498), train_loss = 1.02958095, grad/param norm = 2.3772e-01, time/batch = 16.4015s	
19558/33150 (epoch 29.499), train_loss = 1.03077771, grad/param norm = 1.6784e-01, time/batch = 16.3131s	
19559/33150 (epoch 29.501), train_loss = 0.97598306, grad/param norm = 1.8740e-01, time/batch = 16.0698s	
19560/33150 (epoch 29.502), train_loss = 1.03149817, grad/param norm = 1.8377e-01, time/batch = 17.1440s	
19561/33150 (epoch 29.504), train_loss = 0.98434678, grad/param norm = 1.7402e-01, time/batch = 15.4610s	
19562/33150 (epoch 29.505), train_loss = 1.08387433, grad/param norm = 2.0360e-01, time/batch = 15.9651s	
19563/33150 (epoch 29.507), train_loss = 0.89449584, grad/param norm = 1.7078e-01, time/batch = 16.3582s	
19564/33150 (epoch 29.508), train_loss = 0.87382088, grad/param norm = 1.6353e-01, time/batch = 14.7168s	
19565/33150 (epoch 29.510), train_loss = 0.98607497, grad/param norm = 1.4290e-01, time/batch = 15.2851s	
19566/33150 (epoch 29.511), train_loss = 1.04149539, grad/param norm = 1.6018e-01, time/batch = 15.2074s	
19567/33150 (epoch 29.513), train_loss = 0.94916239, grad/param norm = 1.7237e-01, time/batch = 16.3212s	
19568/33150 (epoch 29.514), train_loss = 0.79626073, grad/param norm = 1.8129e-01, time/batch = 15.0545s	
19569/33150 (epoch 29.516), train_loss = 0.94376665, grad/param norm = 1.7911e-01, time/batch = 15.1594s	
19570/33150 (epoch 29.517), train_loss = 1.02130983, grad/param norm = 1.8752e-01, time/batch = 16.3950s	
19571/33150 (epoch 29.519), train_loss = 0.86105242, grad/param norm = 2.3126e-01, time/batch = 16.9706s	
19572/33150 (epoch 29.520), train_loss = 0.94439281, grad/param norm = 1.6410e-01, time/batch = 15.3460s	
19573/33150 (epoch 29.522), train_loss = 1.02397050, grad/param norm = 1.8610e-01, time/batch = 16.6146s	
19574/33150 (epoch 29.523), train_loss = 0.82694036, grad/param norm = 1.5781e-01, time/batch = 16.6169s	
19575/33150 (epoch 29.525), train_loss = 0.98252300, grad/param norm = 1.6967e-01, time/batch = 16.6287s	
19576/33150 (epoch 29.526), train_loss = 0.84493626, grad/param norm = 1.4639e-01, time/batch = 16.5522s	
19577/33150 (epoch 29.528), train_loss = 0.96571072, grad/param norm = 1.7099e-01, time/batch = 16.1434s	
19578/33150 (epoch 29.529), train_loss = 0.94638970, grad/param norm = 1.7915e-01, time/batch = 16.3668s	
19579/33150 (epoch 29.531), train_loss = 0.77250176, grad/param norm = 1.7805e-01, time/batch = 16.8774s	
19580/33150 (epoch 29.532), train_loss = 0.95518679, grad/param norm = 1.9705e-01, time/batch = 17.4006s	
19581/33150 (epoch 29.534), train_loss = 0.90136815, grad/param norm = 1.3746e-01, time/batch = 15.7274s	
19582/33150 (epoch 29.535), train_loss = 0.84914738, grad/param norm = 2.1187e-01, time/batch = 16.0559s	
19583/33150 (epoch 29.537), train_loss = 0.96077291, grad/param norm = 1.9481e-01, time/batch = 15.3185s	
19584/33150 (epoch 29.538), train_loss = 0.83152528, grad/param norm = 1.6043e-01, time/batch = 16.1992s	
19585/33150 (epoch 29.540), train_loss = 0.81346303, grad/param norm = 1.6036e-01, time/batch = 16.7286s	
19586/33150 (epoch 29.541), train_loss = 1.02567711, grad/param norm = 1.7709e-01, time/batch = 16.7249s	
19587/33150 (epoch 29.543), train_loss = 0.93951504, grad/param norm = 1.6373e-01, time/batch = 15.7394s	
19588/33150 (epoch 29.544), train_loss = 1.00072638, grad/param norm = 1.6031e-01, time/batch = 15.8182s	
19589/33150 (epoch 29.546), train_loss = 0.91511400, grad/param norm = 1.7345e-01, time/batch = 16.1485s	
19590/33150 (epoch 29.548), train_loss = 0.87250470, grad/param norm = 1.9060e-01, time/batch = 15.7250s	
19591/33150 (epoch 29.549), train_loss = 0.84365214, grad/param norm = 1.5051e-01, time/batch = 15.8668s	
19592/33150 (epoch 29.551), train_loss = 0.84183255, grad/param norm = 1.4194e-01, time/batch = 16.7963s	
19593/33150 (epoch 29.552), train_loss = 0.72195548, grad/param norm = 1.3710e-01, time/batch = 16.7282s	
19594/33150 (epoch 29.554), train_loss = 0.97238756, grad/param norm = 1.7314e-01, time/batch = 16.3914s	
19595/33150 (epoch 29.555), train_loss = 1.01706898, grad/param norm = 1.8184e-01, time/batch = 17.0740s	
19596/33150 (epoch 29.557), train_loss = 0.74028979, grad/param norm = 1.6480e-01, time/batch = 15.3116s	
19597/33150 (epoch 29.558), train_loss = 0.97616902, grad/param norm = 2.0817e-01, time/batch = 16.1451s	
19598/33150 (epoch 29.560), train_loss = 0.87947171, grad/param norm = 1.6674e-01, time/batch = 16.0527s	
19599/33150 (epoch 29.561), train_loss = 0.77808960, grad/param norm = 1.6630e-01, time/batch = 18.4881s	
19600/33150 (epoch 29.563), train_loss = 0.97449867, grad/param norm = 2.0117e-01, time/batch = 15.9608s	
19601/33150 (epoch 29.564), train_loss = 1.06223058, grad/param norm = 1.6746e-01, time/batch = 15.3735s	
19602/33150 (epoch 29.566), train_loss = 0.85441516, grad/param norm = 1.6799e-01, time/batch = 16.3131s	
19603/33150 (epoch 29.567), train_loss = 0.83409275, grad/param norm = 1.6111e-01, time/batch = 15.3156s	
19604/33150 (epoch 29.569), train_loss = 0.97041046, grad/param norm = 1.9914e-01, time/batch = 17.5570s	
19605/33150 (epoch 29.570), train_loss = 0.98098047, grad/param norm = 1.6713e-01, time/batch = 16.3080s	
19606/33150 (epoch 29.572), train_loss = 0.85342489, grad/param norm = 1.7508e-01, time/batch = 17.6371s	
19607/33150 (epoch 29.573), train_loss = 0.76698788, grad/param norm = 1.3950e-01, time/batch = 17.0625s	
19608/33150 (epoch 29.575), train_loss = 0.88775455, grad/param norm = 1.7487e-01, time/batch = 16.1389s	
19609/33150 (epoch 29.576), train_loss = 0.80055502, grad/param norm = 1.4366e-01, time/batch = 15.3924s	
19610/33150 (epoch 29.578), train_loss = 0.83059859, grad/param norm = 1.4460e-01, time/batch = 15.9870s	
19611/33150 (epoch 29.579), train_loss = 0.78620563, grad/param norm = 1.4760e-01, time/batch = 15.8770s	
19612/33150 (epoch 29.581), train_loss = 0.82619059, grad/param norm = 1.5896e-01, time/batch = 17.4611s	
19613/33150 (epoch 29.582), train_loss = 1.03305996, grad/param norm = 1.5276e-01, time/batch = 16.8732s	
19614/33150 (epoch 29.584), train_loss = 0.98690081, grad/param norm = 1.7582e-01, time/batch = 17.5516s	
19615/33150 (epoch 29.585), train_loss = 0.92185110, grad/param norm = 1.5902e-01, time/batch = 16.7144s	
19616/33150 (epoch 29.587), train_loss = 0.92127194, grad/param norm = 1.5975e-01, time/batch = 15.7163s	
19617/33150 (epoch 29.588), train_loss = 0.85072366, grad/param norm = 1.7454e-01, time/batch = 17.3844s	
19618/33150 (epoch 29.590), train_loss = 0.95680017, grad/param norm = 1.6084e-01, time/batch = 14.9228s	
19619/33150 (epoch 29.591), train_loss = 0.90301588, grad/param norm = 1.5634e-01, time/batch = 15.4139s	
19620/33150 (epoch 29.593), train_loss = 0.97748627, grad/param norm = 1.7820e-01, time/batch = 15.9440s	
19621/33150 (epoch 29.594), train_loss = 0.89591464, grad/param norm = 1.8506e-01, time/batch = 18.0429s	
19622/33150 (epoch 29.596), train_loss = 0.89825163, grad/param norm = 1.6397e-01, time/batch = 15.3153s	
19623/33150 (epoch 29.597), train_loss = 0.80540044, grad/param norm = 1.9792e-01, time/batch = 15.2231s	
19624/33150 (epoch 29.599), train_loss = 1.08202931, grad/param norm = 1.8764e-01, time/batch = 16.4246s	
19625/33150 (epoch 29.600), train_loss = 0.94753662, grad/param norm = 3.0293e-01, time/batch = 16.3716s	
19626/33150 (epoch 29.602), train_loss = 0.90623438, grad/param norm = 1.7001e-01, time/batch = 17.8150s	
19627/33150 (epoch 29.603), train_loss = 1.04416745, grad/param norm = 2.1726e-01, time/batch = 16.0874s	
19628/33150 (epoch 29.605), train_loss = 0.82177727, grad/param norm = 1.5917e-01, time/batch = 16.5278s	
19629/33150 (epoch 29.606), train_loss = 0.83737634, grad/param norm = 1.9935e-01, time/batch = 16.8538s	
19630/33150 (epoch 29.608), train_loss = 0.99810861, grad/param norm = 1.6670e-01, time/batch = 15.2398s	
19631/33150 (epoch 29.609), train_loss = 0.90543111, grad/param norm = 1.7898e-01, time/batch = 15.2950s	
19632/33150 (epoch 29.611), train_loss = 0.81311924, grad/param norm = 1.5667e-01, time/batch = 16.5640s	
19633/33150 (epoch 29.612), train_loss = 0.91008000, grad/param norm = 1.7525e-01, time/batch = 15.3577s	
19634/33150 (epoch 29.614), train_loss = 0.82692594, grad/param norm = 1.5746e-01, time/batch = 16.4428s	
19635/33150 (epoch 29.615), train_loss = 0.81519608, grad/param norm = 1.6141e-01, time/batch = 15.7020s	
19636/33150 (epoch 29.617), train_loss = 0.91277735, grad/param norm = 1.6532e-01, time/batch = 15.8983s	
19637/33150 (epoch 29.618), train_loss = 0.95069926, grad/param norm = 1.7374e-01, time/batch = 15.6166s	
19638/33150 (epoch 29.620), train_loss = 0.85005882, grad/param norm = 1.4983e-01, time/batch = 16.2828s	
19639/33150 (epoch 29.621), train_loss = 0.90212536, grad/param norm = 1.5865e-01, time/batch = 17.3940s	
19640/33150 (epoch 29.623), train_loss = 0.98031650, grad/param norm = 1.6027e-01, time/batch = 16.8790s	
19641/33150 (epoch 29.624), train_loss = 0.86114949, grad/param norm = 1.4976e-01, time/batch = 15.4298s	
19642/33150 (epoch 29.626), train_loss = 0.89573177, grad/param norm = 1.7021e-01, time/batch = 15.4119s	
19643/33150 (epoch 29.627), train_loss = 0.82180668, grad/param norm = 1.6271e-01, time/batch = 15.2617s	
19644/33150 (epoch 29.629), train_loss = 0.76965993, grad/param norm = 1.7160e-01, time/batch = 17.1735s	
19645/33150 (epoch 29.630), train_loss = 0.88145647, grad/param norm = 1.5591e-01, time/batch = 15.5555s	
19646/33150 (epoch 29.632), train_loss = 0.76885995, grad/param norm = 1.3287e-01, time/batch = 14.9881s	
19647/33150 (epoch 29.633), train_loss = 0.82053815, grad/param norm = 2.2551e-01, time/batch = 15.0573s	
19648/33150 (epoch 29.635), train_loss = 1.04790602, grad/param norm = 1.6858e-01, time/batch = 15.9727s	
19649/33150 (epoch 29.637), train_loss = 0.76106312, grad/param norm = 1.7088e-01, time/batch = 16.6280s	
19650/33150 (epoch 29.638), train_loss = 0.88131963, grad/param norm = 1.6709e-01, time/batch = 15.9441s	
19651/33150 (epoch 29.640), train_loss = 0.96307606, grad/param norm = 1.6516e-01, time/batch = 16.8841s	
19652/33150 (epoch 29.641), train_loss = 0.78467860, grad/param norm = 1.6196e-01, time/batch = 15.8434s	
19653/33150 (epoch 29.643), train_loss = 0.90743627, grad/param norm = 1.6565e-01, time/batch = 15.0506s	
19654/33150 (epoch 29.644), train_loss = 1.04938408, grad/param norm = 1.6278e-01, time/batch = 15.2418s	
19655/33150 (epoch 29.646), train_loss = 0.86607933, grad/param norm = 1.4788e-01, time/batch = 18.0287s	
19656/33150 (epoch 29.647), train_loss = 1.09749853, grad/param norm = 1.7895e-01, time/batch = 16.9026s	
19657/33150 (epoch 29.649), train_loss = 0.97829489, grad/param norm = 1.9349e-01, time/batch = 16.9830s	
19658/33150 (epoch 29.650), train_loss = 0.81236665, grad/param norm = 1.4636e-01, time/batch = 15.3315s	
19659/33150 (epoch 29.652), train_loss = 1.02972802, grad/param norm = 1.8403e-01, time/batch = 15.8737s	
19660/33150 (epoch 29.653), train_loss = 0.95022937, grad/param norm = 1.5594e-01, time/batch = 17.1154s	
19661/33150 (epoch 29.655), train_loss = 0.93043002, grad/param norm = 1.7126e-01, time/batch = 16.6132s	
19662/33150 (epoch 29.656), train_loss = 0.88694570, grad/param norm = 1.7122e-01, time/batch = 16.6189s	
19663/33150 (epoch 29.658), train_loss = 0.88635838, grad/param norm = 2.0197e-01, time/batch = 17.3105s	
19664/33150 (epoch 29.659), train_loss = 1.21363837, grad/param norm = 4.5663e-01, time/batch = 15.5444s	
19665/33150 (epoch 29.661), train_loss = 0.91320885, grad/param norm = 1.8158e-01, time/batch = 15.7368s	
19666/33150 (epoch 29.662), train_loss = 0.90185600, grad/param norm = 2.2133e-01, time/batch = 17.8182s	
19667/33150 (epoch 29.664), train_loss = 1.02674201, grad/param norm = 1.9000e-01, time/batch = 16.6315s	
19668/33150 (epoch 29.665), train_loss = 1.00035368, grad/param norm = 1.8855e-01, time/batch = 16.7394s	
19669/33150 (epoch 29.667), train_loss = 1.03041949, grad/param norm = 1.9216e-01, time/batch = 16.3135s	
19670/33150 (epoch 29.668), train_loss = 1.03251143, grad/param norm = 1.8163e-01, time/batch = 17.9654s	
19671/33150 (epoch 29.670), train_loss = 0.86757397, grad/param norm = 1.5146e-01, time/batch = 15.4635s	
19672/33150 (epoch 29.671), train_loss = 0.87402277, grad/param norm = 1.6572e-01, time/batch = 17.1188s	
19673/33150 (epoch 29.673), train_loss = 1.04004539, grad/param norm = 1.5209e-01, time/batch = 17.0734s	
19674/33150 (epoch 29.674), train_loss = 0.97862956, grad/param norm = 1.8996e-01, time/batch = 15.9952s	
19675/33150 (epoch 29.676), train_loss = 0.92941886, grad/param norm = 1.6703e-01, time/batch = 16.9812s	
19676/33150 (epoch 29.677), train_loss = 1.07034387, grad/param norm = 1.7071e-01, time/batch = 16.3153s	
19677/33150 (epoch 29.679), train_loss = 0.90062199, grad/param norm = 1.4189e-01, time/batch = 18.4702s	
19678/33150 (epoch 29.680), train_loss = 1.03670478, grad/param norm = 1.9303e-01, time/batch = 16.5371s	
19679/33150 (epoch 29.682), train_loss = 0.91251059, grad/param norm = 1.5796e-01, time/batch = 17.9024s	
19680/33150 (epoch 29.683), train_loss = 0.78386534, grad/param norm = 1.4171e-01, time/batch = 17.7402s	
19681/33150 (epoch 29.685), train_loss = 0.90325751, grad/param norm = 1.9049e-01, time/batch = 16.8128s	
19682/33150 (epoch 29.686), train_loss = 0.79208806, grad/param norm = 1.4333e-01, time/batch = 15.9688s	
19683/33150 (epoch 29.688), train_loss = 0.80669777, grad/param norm = 1.5205e-01, time/batch = 17.3048s	
19684/33150 (epoch 29.689), train_loss = 0.82810240, grad/param norm = 1.4528e-01, time/batch = 16.0620s	
19685/33150 (epoch 29.691), train_loss = 0.73966939, grad/param norm = 1.5163e-01, time/batch = 14.7856s	
19686/33150 (epoch 29.692), train_loss = 0.81206592, grad/param norm = 1.6072e-01, time/batch = 14.4912s	
19687/33150 (epoch 29.694), train_loss = 0.71762633, grad/param norm = 1.4034e-01, time/batch = 15.1617s	
19688/33150 (epoch 29.695), train_loss = 0.85443157, grad/param norm = 1.4983e-01, time/batch = 16.0563s	
19689/33150 (epoch 29.697), train_loss = 0.77247010, grad/param norm = 1.3128e-01, time/batch = 15.7802s	
19690/33150 (epoch 29.698), train_loss = 0.81915622, grad/param norm = 1.7617e-01, time/batch = 17.0721s	
19691/33150 (epoch 29.700), train_loss = 0.69635587, grad/param norm = 1.3547e-01, time/batch = 14.9432s	
19692/33150 (epoch 29.701), train_loss = 0.80426187, grad/param norm = 1.5318e-01, time/batch = 16.8113s	
19693/33150 (epoch 29.703), train_loss = 0.89356840, grad/param norm = 1.6781e-01, time/batch = 16.2272s	
19694/33150 (epoch 29.704), train_loss = 0.77248732, grad/param norm = 1.4100e-01, time/batch = 17.3185s	
19695/33150 (epoch 29.706), train_loss = 0.85317230, grad/param norm = 1.4870e-01, time/batch = 17.8817s	
19696/33150 (epoch 29.707), train_loss = 0.85445975, grad/param norm = 1.6926e-01, time/batch = 16.0388s	
19697/33150 (epoch 29.709), train_loss = 0.89513606, grad/param norm = 1.3857e-01, time/batch = 17.5698s	
19698/33150 (epoch 29.710), train_loss = 0.88698376, grad/param norm = 1.7494e-01, time/batch = 16.2313s	
19699/33150 (epoch 29.712), train_loss = 0.95940683, grad/param norm = 1.7309e-01, time/batch = 15.2302s	
19700/33150 (epoch 29.713), train_loss = 0.93405413, grad/param norm = 1.4537e-01, time/batch = 16.3039s	
19701/33150 (epoch 29.715), train_loss = 0.87073393, grad/param norm = 1.4735e-01, time/batch = 16.9031s	
19702/33150 (epoch 29.716), train_loss = 0.93420145, grad/param norm = 1.5841e-01, time/batch = 15.9906s	
19703/33150 (epoch 29.718), train_loss = 0.92581391, grad/param norm = 1.7255e-01, time/batch = 15.2769s	
19704/33150 (epoch 29.719), train_loss = 0.98446209, grad/param norm = 1.7779e-01, time/batch = 15.1143s	
19705/33150 (epoch 29.721), train_loss = 0.89197900, grad/param norm = 1.7858e-01, time/batch = 17.3902s	
19706/33150 (epoch 29.722), train_loss = 0.92256991, grad/param norm = 1.4470e-01, time/batch = 15.4203s	
19707/33150 (epoch 29.724), train_loss = 0.87391827, grad/param norm = 1.6291e-01, time/batch = 15.6435s	
19708/33150 (epoch 29.725), train_loss = 0.97853621, grad/param norm = 1.9571e-01, time/batch = 16.0733s	
19709/33150 (epoch 29.727), train_loss = 0.96327638, grad/param norm = 1.8499e-01, time/batch = 16.2153s	
19710/33150 (epoch 29.729), train_loss = 0.88668704, grad/param norm = 1.5462e-01, time/batch = 16.8113s	
19711/33150 (epoch 29.730), train_loss = 0.89099943, grad/param norm = 1.5957e-01, time/batch = 14.9919s	
19712/33150 (epoch 29.732), train_loss = 0.95957539, grad/param norm = 1.6713e-01, time/batch = 16.3607s	
19713/33150 (epoch 29.733), train_loss = 0.75892692, grad/param norm = 1.3027e-01, time/batch = 18.0496s	
19714/33150 (epoch 29.735), train_loss = 0.82099641, grad/param norm = 1.5893e-01, time/batch = 16.4776s	
19715/33150 (epoch 29.736), train_loss = 0.87903330, grad/param norm = 1.5908e-01, time/batch = 15.6457s	
19716/33150 (epoch 29.738), train_loss = 0.90542387, grad/param norm = 1.6871e-01, time/batch = 18.9518s	
19717/33150 (epoch 29.739), train_loss = 0.99061707, grad/param norm = 1.9347e-01, time/batch = 17.0730s	
19718/33150 (epoch 29.741), train_loss = 0.97747847, grad/param norm = 1.8231e-01, time/batch = 16.5464s	
19719/33150 (epoch 29.742), train_loss = 0.77192081, grad/param norm = 1.5259e-01, time/batch = 15.6453s	
19720/33150 (epoch 29.744), train_loss = 0.98629613, grad/param norm = 2.0013e-01, time/batch = 16.4022s	
19721/33150 (epoch 29.745), train_loss = 0.86337955, grad/param norm = 1.4573e-01, time/batch = 16.4612s	
19722/33150 (epoch 29.747), train_loss = 0.69548272, grad/param norm = 1.6609e-01, time/batch = 17.2952s	
19723/33150 (epoch 29.748), train_loss = 0.79565274, grad/param norm = 1.5218e-01, time/batch = 17.5637s	
19724/33150 (epoch 29.750), train_loss = 0.92318732, grad/param norm = 1.6229e-01, time/batch = 15.3799s	
19725/33150 (epoch 29.751), train_loss = 0.89449398, grad/param norm = 1.4669e-01, time/batch = 16.9379s	
19726/33150 (epoch 29.753), train_loss = 0.76768463, grad/param norm = 1.6668e-01, time/batch = 16.7992s	
19727/33150 (epoch 29.754), train_loss = 1.08834400, grad/param norm = 2.0869e-01, time/batch = 17.0633s	
19728/33150 (epoch 29.756), train_loss = 0.91614238, grad/param norm = 1.9553e-01, time/batch = 17.6416s	
19729/33150 (epoch 29.757), train_loss = 0.92827616, grad/param norm = 1.7587e-01, time/batch = 15.6433s	
19730/33150 (epoch 29.759), train_loss = 1.04551877, grad/param norm = 1.9377e-01, time/batch = 16.4010s	
19731/33150 (epoch 29.760), train_loss = 0.95048793, grad/param norm = 1.7047e-01, time/batch = 15.2308s	
19732/33150 (epoch 29.762), train_loss = 0.94034152, grad/param norm = 1.9874e-01, time/batch = 15.0443s	
19733/33150 (epoch 29.763), train_loss = 0.94509983, grad/param norm = 1.7024e-01, time/batch = 15.7204s	
19734/33150 (epoch 29.765), train_loss = 0.88520841, grad/param norm = 1.5269e-01, time/batch = 16.9425s	
19735/33150 (epoch 29.766), train_loss = 0.81263659, grad/param norm = 1.5709e-01, time/batch = 16.3778s	
19736/33150 (epoch 29.768), train_loss = 0.83392958, grad/param norm = 1.5235e-01, time/batch = 22.4577s	
19737/33150 (epoch 29.769), train_loss = 0.95317183, grad/param norm = 1.7041e-01, time/batch = 26.7121s	
19738/33150 (epoch 29.771), train_loss = 0.91613926, grad/param norm = 1.8972e-01, time/batch = 16.0591s	
19739/33150 (epoch 29.772), train_loss = 0.97170452, grad/param norm = 1.8974e-01, time/batch = 15.4681s	
19740/33150 (epoch 29.774), train_loss = 1.05569273, grad/param norm = 1.8252e-01, time/batch = 16.9536s	
19741/33150 (epoch 29.775), train_loss = 0.96746268, grad/param norm = 1.9756e-01, time/batch = 17.3668s	
19742/33150 (epoch 29.777), train_loss = 0.97318614, grad/param norm = 1.6522e-01, time/batch = 15.9615s	
19743/33150 (epoch 29.778), train_loss = 0.92087585, grad/param norm = 1.5356e-01, time/batch = 16.4811s	
19744/33150 (epoch 29.780), train_loss = 0.79580664, grad/param norm = 1.5807e-01, time/batch = 17.6130s	
19745/33150 (epoch 29.781), train_loss = 0.90346868, grad/param norm = 1.5220e-01, time/batch = 17.3922s	
19746/33150 (epoch 29.783), train_loss = 0.92491176, grad/param norm = 1.5577e-01, time/batch = 16.0499s	
19747/33150 (epoch 29.784), train_loss = 0.90508061, grad/param norm = 1.6259e-01, time/batch = 15.8913s	
19748/33150 (epoch 29.786), train_loss = 0.88193580, grad/param norm = 1.4851e-01, time/batch = 19.1495s	
19749/33150 (epoch 29.787), train_loss = 0.83811533, grad/param norm = 1.5054e-01, time/batch = 15.4691s	
19750/33150 (epoch 29.789), train_loss = 0.75901024, grad/param norm = 1.6032e-01, time/batch = 16.7247s	
19751/33150 (epoch 29.790), train_loss = 0.79237000, grad/param norm = 1.5080e-01, time/batch = 17.2173s	
19752/33150 (epoch 29.792), train_loss = 0.92247750, grad/param norm = 1.8054e-01, time/batch = 18.0509s	
19753/33150 (epoch 29.793), train_loss = 0.88078367, grad/param norm = 1.8863e-01, time/batch = 16.1163s	
19754/33150 (epoch 29.795), train_loss = 0.85362765, grad/param norm = 1.7489e-01, time/batch = 16.1225s	
19755/33150 (epoch 29.796), train_loss = 0.86716006, grad/param norm = 1.4024e-01, time/batch = 15.6331s	
19756/33150 (epoch 29.798), train_loss = 0.84421997, grad/param norm = 1.3950e-01, time/batch = 15.1624s	
19757/33150 (epoch 29.799), train_loss = 0.75397659, grad/param norm = 1.5819e-01, time/batch = 14.9367s	
19758/33150 (epoch 29.801), train_loss = 0.90930590, grad/param norm = 1.6342e-01, time/batch = 15.3735s	
19759/33150 (epoch 29.802), train_loss = 0.83545984, grad/param norm = 1.5121e-01, time/batch = 15.4709s	
19760/33150 (epoch 29.804), train_loss = 0.87842964, grad/param norm = 1.5988e-01, time/batch = 15.6323s	
19761/33150 (epoch 29.805), train_loss = 0.83938538, grad/param norm = 1.6457e-01, time/batch = 14.8913s	
19762/33150 (epoch 29.807), train_loss = 0.87261225, grad/param norm = 1.4842e-01, time/batch = 15.2755s	
19763/33150 (epoch 29.808), train_loss = 0.99609622, grad/param norm = 1.7194e-01, time/batch = 15.4042s	
19764/33150 (epoch 29.810), train_loss = 0.83948249, grad/param norm = 1.7325e-01, time/batch = 16.0559s	
19765/33150 (epoch 29.811), train_loss = 0.94762478, grad/param norm = 1.7578e-01, time/batch = 16.6963s	
19766/33150 (epoch 29.813), train_loss = 0.86256018, grad/param norm = 1.4557e-01, time/batch = 16.5502s	
19767/33150 (epoch 29.814), train_loss = 0.83928810, grad/param norm = 1.9040e-01, time/batch = 18.7737s	
19768/33150 (epoch 29.816), train_loss = 0.87525794, grad/param norm = 1.9169e-01, time/batch = 17.0389s	
19769/33150 (epoch 29.817), train_loss = 0.95273054, grad/param norm = 1.6769e-01, time/batch = 18.1060s	
19770/33150 (epoch 29.819), train_loss = 0.91745407, grad/param norm = 1.7028e-01, time/batch = 18.2229s	
19771/33150 (epoch 29.821), train_loss = 0.79314081, grad/param norm = 1.5454e-01, time/batch = 17.5356s	
19772/33150 (epoch 29.822), train_loss = 0.84666642, grad/param norm = 1.5795e-01, time/batch = 16.8027s	
19773/33150 (epoch 29.824), train_loss = 0.89630411, grad/param norm = 1.6696e-01, time/batch = 16.7396s	
19774/33150 (epoch 29.825), train_loss = 0.91937367, grad/param norm = 1.7103e-01, time/batch = 16.6377s	
19775/33150 (epoch 29.827), train_loss = 0.95572258, grad/param norm = 1.7789e-01, time/batch = 16.7307s	
19776/33150 (epoch 29.828), train_loss = 0.80054701, grad/param norm = 1.5832e-01, time/batch = 18.4586s	
19777/33150 (epoch 29.830), train_loss = 0.96013845, grad/param norm = 1.8361e-01, time/batch = 18.2090s	
19778/33150 (epoch 29.831), train_loss = 0.82771122, grad/param norm = 1.6324e-01, time/batch = 16.3755s	
19779/33150 (epoch 29.833), train_loss = 0.80633628, grad/param norm = 1.7345e-01, time/batch = 18.1105s	
19780/33150 (epoch 29.834), train_loss = 0.97162389, grad/param norm = 1.6240e-01, time/batch = 18.1232s	
19781/33150 (epoch 29.836), train_loss = 0.98608693, grad/param norm = 1.4422e-01, time/batch = 18.9534s	
19782/33150 (epoch 29.837), train_loss = 0.85542222, grad/param norm = 2.0717e-01, time/batch = 18.1281s	
19783/33150 (epoch 29.839), train_loss = 0.95740373, grad/param norm = 1.8404e-01, time/batch = 17.5523s	
19784/33150 (epoch 29.840), train_loss = 0.98249180, grad/param norm = 1.6349e-01, time/batch = 18.1393s	
19785/33150 (epoch 29.842), train_loss = 1.03620898, grad/param norm = 1.9227e-01, time/batch = 15.9322s	
19786/33150 (epoch 29.843), train_loss = 0.98490983, grad/param norm = 1.7689e-01, time/batch = 17.7185s	
19787/33150 (epoch 29.845), train_loss = 0.84071264, grad/param norm = 1.5985e-01, time/batch = 16.7164s	
19788/33150 (epoch 29.846), train_loss = 1.10045638, grad/param norm = 2.4837e-01, time/batch = 18.1249s	
19789/33150 (epoch 29.848), train_loss = 0.98160004, grad/param norm = 1.7159e-01, time/batch = 17.6358s	
19790/33150 (epoch 29.849), train_loss = 1.00745186, grad/param norm = 1.7130e-01, time/batch = 19.6449s	
19791/33150 (epoch 29.851), train_loss = 0.95569938, grad/param norm = 1.9736e-01, time/batch = 17.4812s	
19792/33150 (epoch 29.852), train_loss = 1.05134513, grad/param norm = 1.6465e-01, time/batch = 16.1325s	
19793/33150 (epoch 29.854), train_loss = 0.92759292, grad/param norm = 1.5551e-01, time/batch = 18.7993s	
19794/33150 (epoch 29.855), train_loss = 0.78538520, grad/param norm = 1.6471e-01, time/batch = 18.9549s	
19795/33150 (epoch 29.857), train_loss = 0.74822348, grad/param norm = 1.5737e-01, time/batch = 15.6078s	
19796/33150 (epoch 29.858), train_loss = 0.85828574, grad/param norm = 1.4634e-01, time/batch = 16.7085s	
19797/33150 (epoch 29.860), train_loss = 0.82823868, grad/param norm = 1.6286e-01, time/batch = 15.0490s	
19798/33150 (epoch 29.861), train_loss = 0.81325529, grad/param norm = 1.5475e-01, time/batch = 18.6149s	
19799/33150 (epoch 29.863), train_loss = 0.88714796, grad/param norm = 1.4052e-01, time/batch = 16.1228s	
19800/33150 (epoch 29.864), train_loss = 0.92796493, grad/param norm = 1.6250e-01, time/batch = 19.2186s	
19801/33150 (epoch 29.866), train_loss = 0.96484462, grad/param norm = 1.6791e-01, time/batch = 18.8690s	
19802/33150 (epoch 29.867), train_loss = 0.93645654, grad/param norm = 1.4995e-01, time/batch = 16.2030s	
19803/33150 (epoch 29.869), train_loss = 0.93253127, grad/param norm = 1.7087e-01, time/batch = 18.8894s	
19804/33150 (epoch 29.870), train_loss = 0.85240616, grad/param norm = 1.6153e-01, time/batch = 17.0522s	
19805/33150 (epoch 29.872), train_loss = 0.94916254, grad/param norm = 1.7382e-01, time/batch = 15.7146s	
19806/33150 (epoch 29.873), train_loss = 0.74800865, grad/param norm = 1.4585e-01, time/batch = 15.4772s	
19807/33150 (epoch 29.875), train_loss = 1.02232651, grad/param norm = 1.7559e-01, time/batch = 18.3048s	
19808/33150 (epoch 29.876), train_loss = 0.77347678, grad/param norm = 1.4722e-01, time/batch = 18.3196s	
19809/33150 (epoch 29.878), train_loss = 0.83496460, grad/param norm = 1.5446e-01, time/batch = 17.1204s	
19810/33150 (epoch 29.879), train_loss = 0.83532429, grad/param norm = 1.4889e-01, time/batch = 19.5391s	
19811/33150 (epoch 29.881), train_loss = 0.81602339, grad/param norm = 1.5972e-01, time/batch = 18.8905s	
19812/33150 (epoch 29.882), train_loss = 0.72307444, grad/param norm = 1.4109e-01, time/batch = 16.1461s	
19813/33150 (epoch 29.884), train_loss = 0.86368584, grad/param norm = 1.5169e-01, time/batch = 17.6148s	
19814/33150 (epoch 29.885), train_loss = 0.67432639, grad/param norm = 1.5747e-01, time/batch = 16.7054s	
19815/33150 (epoch 29.887), train_loss = 0.99323297, grad/param norm = 1.7662e-01, time/batch = 18.9530s	
19816/33150 (epoch 29.888), train_loss = 0.93607716, grad/param norm = 1.6016e-01, time/batch = 16.9721s	
19817/33150 (epoch 29.890), train_loss = 0.83539195, grad/param norm = 1.6966e-01, time/batch = 17.4685s	
19818/33150 (epoch 29.891), train_loss = 0.78778715, grad/param norm = 1.6024e-01, time/batch = 16.5211s	
19819/33150 (epoch 29.893), train_loss = 0.96034395, grad/param norm = 1.7403e-01, time/batch = 17.2054s	
19820/33150 (epoch 29.894), train_loss = 0.93410807, grad/param norm = 1.7072e-01, time/batch = 19.2156s	
19821/33150 (epoch 29.896), train_loss = 0.89168725, grad/param norm = 1.5584e-01, time/batch = 17.5467s	
19822/33150 (epoch 29.897), train_loss = 0.93198438, grad/param norm = 1.4687e-01, time/batch = 15.5677s	
19823/33150 (epoch 29.899), train_loss = 0.75133201, grad/param norm = 1.8700e-01, time/batch = 15.8734s	
19824/33150 (epoch 29.900), train_loss = 1.10468747, grad/param norm = 2.2467e-01, time/batch = 18.4944s	
19825/33150 (epoch 29.902), train_loss = 1.09132627, grad/param norm = 1.7915e-01, time/batch = 17.0996s	
19826/33150 (epoch 29.903), train_loss = 0.90202034, grad/param norm = 1.6362e-01, time/batch = 16.2118s	
19827/33150 (epoch 29.905), train_loss = 0.91564702, grad/param norm = 1.4724e-01, time/batch = 17.2182s	
19828/33150 (epoch 29.906), train_loss = 0.93169805, grad/param norm = 1.9475e-01, time/batch = 17.4582s	
19829/33150 (epoch 29.908), train_loss = 0.99436487, grad/param norm = 1.6470e-01, time/batch = 18.7904s	
19830/33150 (epoch 29.910), train_loss = 0.98146210, grad/param norm = 1.6405e-01, time/batch = 15.1968s	
19831/33150 (epoch 29.911), train_loss = 0.78670557, grad/param norm = 1.4639e-01, time/batch = 16.7928s	
19832/33150 (epoch 29.913), train_loss = 0.83854968, grad/param norm = 1.8458e-01, time/batch = 17.1167s	
19833/33150 (epoch 29.914), train_loss = 0.94421083, grad/param norm = 1.6955e-01, time/batch = 17.9463s	
19834/33150 (epoch 29.916), train_loss = 0.84779022, grad/param norm = 1.6583e-01, time/batch = 18.7164s	
19835/33150 (epoch 29.917), train_loss = 0.94826745, grad/param norm = 1.9587e-01, time/batch = 18.1259s	
19836/33150 (epoch 29.919), train_loss = 1.03636299, grad/param norm = 2.0329e-01, time/batch = 16.8959s	
19837/33150 (epoch 29.920), train_loss = 0.99518111, grad/param norm = 1.5842e-01, time/batch = 17.4542s	
19838/33150 (epoch 29.922), train_loss = 1.04800831, grad/param norm = 1.8919e-01, time/batch = 15.9656s	
19839/33150 (epoch 29.923), train_loss = 0.93197290, grad/param norm = 1.8799e-01, time/batch = 16.9043s	
19840/33150 (epoch 29.925), train_loss = 1.00599114, grad/param norm = 1.7390e-01, time/batch = 15.8841s	
19841/33150 (epoch 29.926), train_loss = 0.88327228, grad/param norm = 1.5992e-01, time/batch = 16.8036s	
19842/33150 (epoch 29.928), train_loss = 0.86535122, grad/param norm = 1.5557e-01, time/batch = 16.3873s	
19843/33150 (epoch 29.929), train_loss = 0.97086504, grad/param norm = 1.6676e-01, time/batch = 15.3150s	
19844/33150 (epoch 29.931), train_loss = 1.03193429, grad/param norm = 1.9098e-01, time/batch = 15.2029s	
19845/33150 (epoch 29.932), train_loss = 0.92395025, grad/param norm = 1.6162e-01, time/batch = 14.9773s	
19846/33150 (epoch 29.934), train_loss = 0.93288936, grad/param norm = 1.5025e-01, time/batch = 14.9015s	
19847/33150 (epoch 29.935), train_loss = 0.99477784, grad/param norm = 1.6608e-01, time/batch = 15.7944s	
19848/33150 (epoch 29.937), train_loss = 1.02264562, grad/param norm = 1.6015e-01, time/batch = 15.7956s	
19849/33150 (epoch 29.938), train_loss = 0.93817891, grad/param norm = 1.6365e-01, time/batch = 18.5624s	
19850/33150 (epoch 29.940), train_loss = 1.14463448, grad/param norm = 1.8084e-01, time/batch = 15.9470s	
19851/33150 (epoch 29.941), train_loss = 0.93052780, grad/param norm = 1.4162e-01, time/batch = 17.4766s	
19852/33150 (epoch 29.943), train_loss = 0.75035591, grad/param norm = 1.5743e-01, time/batch = 17.0506s	
19853/33150 (epoch 29.944), train_loss = 0.99746340, grad/param norm = 2.2463e-01, time/batch = 17.7890s	
19854/33150 (epoch 29.946), train_loss = 0.79154702, grad/param norm = 1.6803e-01, time/batch = 18.3653s	
19855/33150 (epoch 29.947), train_loss = 0.93084412, grad/param norm = 1.4712e-01, time/batch = 16.7076s	
19856/33150 (epoch 29.949), train_loss = 1.03946554, grad/param norm = 1.8008e-01, time/batch = 18.1214s	
19857/33150 (epoch 29.950), train_loss = 0.96538960, grad/param norm = 2.5693e-01, time/batch = 17.2237s	
19858/33150 (epoch 29.952), train_loss = 0.85048951, grad/param norm = 1.5537e-01, time/batch = 15.9461s	
19859/33150 (epoch 29.953), train_loss = 0.87922356, grad/param norm = 1.5802e-01, time/batch = 16.8023s	
19860/33150 (epoch 29.955), train_loss = 0.80864734, grad/param norm = 1.6732e-01, time/batch = 18.7925s	
19861/33150 (epoch 29.956), train_loss = 0.98736058, grad/param norm = 1.7832e-01, time/batch = 17.3739s	
19862/33150 (epoch 29.958), train_loss = 0.81326992, grad/param norm = 1.4809e-01, time/batch = 16.3765s	
19863/33150 (epoch 29.959), train_loss = 0.86965486, grad/param norm = 1.5588e-01, time/batch = 18.0512s	
19864/33150 (epoch 29.961), train_loss = 0.84439686, grad/param norm = 1.7130e-01, time/batch = 15.3172s	
19865/33150 (epoch 29.962), train_loss = 0.78072574, grad/param norm = 1.5521e-01, time/batch = 16.1213s	
19866/33150 (epoch 29.964), train_loss = 0.89887289, grad/param norm = 1.6624e-01, time/batch = 16.4645s	
19867/33150 (epoch 29.965), train_loss = 0.88435708, grad/param norm = 1.6628e-01, time/batch = 16.2067s	
19868/33150 (epoch 29.967), train_loss = 0.88420327, grad/param norm = 2.0342e-01, time/batch = 16.7199s	
19869/33150 (epoch 29.968), train_loss = 0.75886555, grad/param norm = 1.3311e-01, time/batch = 17.2934s	
19870/33150 (epoch 29.970), train_loss = 0.84482151, grad/param norm = 1.5038e-01, time/batch = 17.8624s	
19871/33150 (epoch 29.971), train_loss = 0.89902559, grad/param norm = 1.5434e-01, time/batch = 16.6228s	
19872/33150 (epoch 29.973), train_loss = 1.01412153, grad/param norm = 1.7171e-01, time/batch = 15.7827s	
19873/33150 (epoch 29.974), train_loss = 1.03654251, grad/param norm = 1.6690e-01, time/batch = 15.5941s	
19874/33150 (epoch 29.976), train_loss = 1.01336094, grad/param norm = 1.5425e-01, time/batch = 16.4573s	
19875/33150 (epoch 29.977), train_loss = 1.03721628, grad/param norm = 1.7747e-01, time/batch = 16.0597s	
19876/33150 (epoch 29.979), train_loss = 0.99860299, grad/param norm = 1.9904e-01, time/batch = 15.7798s	
19877/33150 (epoch 29.980), train_loss = 1.04814063, grad/param norm = 1.7593e-01, time/batch = 18.2123s	
19878/33150 (epoch 29.982), train_loss = 0.91989235, grad/param norm = 1.9740e-01, time/batch = 17.3033s	
19879/33150 (epoch 29.983), train_loss = 0.82633767, grad/param norm = 1.6536e-01, time/batch = 16.0042s	
19880/33150 (epoch 29.985), train_loss = 1.00774327, grad/param norm = 1.5749e-01, time/batch = 17.2176s	
19881/33150 (epoch 29.986), train_loss = 0.76393522, grad/param norm = 1.5334e-01, time/batch = 15.8933s	
19882/33150 (epoch 29.988), train_loss = 0.86800113, grad/param norm = 1.6668e-01, time/batch = 16.1575s	
19883/33150 (epoch 29.989), train_loss = 0.85980931, grad/param norm = 1.5090e-01, time/batch = 15.9620s	
19884/33150 (epoch 29.991), train_loss = 0.96271354, grad/param norm = 2.2958e-01, time/batch = 17.3815s	
19885/33150 (epoch 29.992), train_loss = 0.86883629, grad/param norm = 1.5984e-01, time/batch = 18.3562s	
19886/33150 (epoch 29.994), train_loss = 0.92748722, grad/param norm = 1.6220e-01, time/batch = 16.0422s	
19887/33150 (epoch 29.995), train_loss = 0.88088389, grad/param norm = 1.6824e-01, time/batch = 16.2894s	
19888/33150 (epoch 29.997), train_loss = 0.91478308, grad/param norm = 1.9122e-01, time/batch = 15.3466s	
19889/33150 (epoch 29.998), train_loss = 0.74991821, grad/param norm = 1.4661e-01, time/batch = 15.7376s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
19890/33150 (epoch 30.000), train_loss = 0.75539883, grad/param norm = 1.7676e-01, time/batch = 15.6293s	
19891/33150 (epoch 30.002), train_loss = 1.21172540, grad/param norm = 1.9246e-01, time/batch = 16.8055s	
19892/33150 (epoch 30.003), train_loss = 0.80635314, grad/param norm = 1.4733e-01, time/batch = 18.1040s	
19893/33150 (epoch 30.005), train_loss = 0.78877584, grad/param norm = 1.4593e-01, time/batch = 18.5624s	
19894/33150 (epoch 30.006), train_loss = 0.76344771, grad/param norm = 1.5708e-01, time/batch = 15.7879s	
19895/33150 (epoch 30.008), train_loss = 0.97743963, grad/param norm = 1.7751e-01, time/batch = 15.5463s	
19896/33150 (epoch 30.009), train_loss = 0.93297668, grad/param norm = 1.7747e-01, time/batch = 15.1997s	
19897/33150 (epoch 30.011), train_loss = 1.01014328, grad/param norm = 1.8247e-01, time/batch = 15.2977s	
19898/33150 (epoch 30.012), train_loss = 0.90057170, grad/param norm = 2.5426e-01, time/batch = 15.3567s	
19899/33150 (epoch 30.014), train_loss = 0.83913476, grad/param norm = 1.6894e-01, time/batch = 15.0187s	
19900/33150 (epoch 30.015), train_loss = 0.82877265, grad/param norm = 1.6721e-01, time/batch = 15.5836s	
19901/33150 (epoch 30.017), train_loss = 0.81159146, grad/param norm = 1.5414e-01, time/batch = 16.3630s	
19902/33150 (epoch 30.018), train_loss = 0.91674250, grad/param norm = 1.8522e-01, time/batch = 17.0440s	
19903/33150 (epoch 30.020), train_loss = 0.98277689, grad/param norm = 1.7880e-01, time/batch = 17.0621s	
19904/33150 (epoch 30.021), train_loss = 0.81933858, grad/param norm = 1.7194e-01, time/batch = 17.7954s	
19905/33150 (epoch 30.023), train_loss = 1.07973333, grad/param norm = 1.5962e-01, time/batch = 16.5434s	
19906/33150 (epoch 30.024), train_loss = 0.95717617, grad/param norm = 1.8907e-01, time/batch = 16.3106s	
19907/33150 (epoch 30.026), train_loss = 0.71867249, grad/param norm = 1.4435e-01, time/batch = 18.3746s	
19908/33150 (epoch 30.027), train_loss = 0.73504250, grad/param norm = 1.3546e-01, time/batch = 17.2113s	
19909/33150 (epoch 30.029), train_loss = 0.84546356, grad/param norm = 1.6020e-01, time/batch = 19.3777s	
19910/33150 (epoch 30.030), train_loss = 0.86023234, grad/param norm = 1.3133e-01, time/batch = 15.8129s	
19911/33150 (epoch 30.032), train_loss = 0.80088324, grad/param norm = 1.6463e-01, time/batch = 17.7915s	
19912/33150 (epoch 30.033), train_loss = 0.83468742, grad/param norm = 1.6609e-01, time/batch = 16.8713s	
19913/33150 (epoch 30.035), train_loss = 1.06796784, grad/param norm = 1.8502e-01, time/batch = 17.9792s	
19914/33150 (epoch 30.036), train_loss = 0.94010778, grad/param norm = 1.6550e-01, time/batch = 15.8831s	
19915/33150 (epoch 30.038), train_loss = 1.11151295, grad/param norm = 2.1062e-01, time/batch = 16.6322s	
19916/33150 (epoch 30.039), train_loss = 0.97425980, grad/param norm = 1.5248e-01, time/batch = 16.9633s	
19917/33150 (epoch 30.041), train_loss = 0.90586462, grad/param norm = 1.6314e-01, time/batch = 18.1407s	
19918/33150 (epoch 30.042), train_loss = 0.85324740, grad/param norm = 1.5587e-01, time/batch = 17.7211s	
19919/33150 (epoch 30.044), train_loss = 0.88035935, grad/param norm = 1.5263e-01, time/batch = 16.7266s	
19920/33150 (epoch 30.045), train_loss = 0.94748239, grad/param norm = 1.4218e-01, time/batch = 17.3872s	
19921/33150 (epoch 30.047), train_loss = 0.81156275, grad/param norm = 1.7695e-01, time/batch = 19.2162s	
19922/33150 (epoch 30.048), train_loss = 1.00310609, grad/param norm = 2.3105e-01, time/batch = 16.2015s	
19923/33150 (epoch 30.050), train_loss = 0.87821468, grad/param norm = 1.9531e-01, time/batch = 18.1688s	
19924/33150 (epoch 30.051), train_loss = 0.92403304, grad/param norm = 1.6044e-01, time/batch = 17.0574s	
19925/33150 (epoch 30.053), train_loss = 0.90558801, grad/param norm = 1.6493e-01, time/batch = 16.8633s	
19926/33150 (epoch 30.054), train_loss = 1.03761177, grad/param norm = 1.5757e-01, time/batch = 17.3882s	
19927/33150 (epoch 30.056), train_loss = 0.88925025, grad/param norm = 1.5397e-01, time/batch = 16.7238s	
19928/33150 (epoch 30.057), train_loss = 0.93932351, grad/param norm = 1.5906e-01, time/batch = 17.4754s	
19929/33150 (epoch 30.059), train_loss = 0.82271658, grad/param norm = 1.5677e-01, time/batch = 16.1994s	
19930/33150 (epoch 30.060), train_loss = 0.82160622, grad/param norm = 1.4808e-01, time/batch = 18.5623s	
19931/33150 (epoch 30.062), train_loss = 0.89059064, grad/param norm = 1.6349e-01, time/batch = 18.1328s	
19932/33150 (epoch 30.063), train_loss = 0.83991287, grad/param norm = 1.6207e-01, time/batch = 18.7982s	
19933/33150 (epoch 30.065), train_loss = 0.86284921, grad/param norm = 1.6266e-01, time/batch = 17.3072s	
19934/33150 (epoch 30.066), train_loss = 0.86982058, grad/param norm = 1.6430e-01, time/batch = 18.8093s	
19935/33150 (epoch 30.068), train_loss = 0.94680444, grad/param norm = 1.5777e-01, time/batch = 18.5385s	
19936/33150 (epoch 30.069), train_loss = 0.93530602, grad/param norm = 1.8860e-01, time/batch = 17.0283s	
19937/33150 (epoch 30.071), train_loss = 0.91845155, grad/param norm = 1.5666e-01, time/batch = 18.7160s	
19938/33150 (epoch 30.072), train_loss = 0.90864679, grad/param norm = 1.5204e-01, time/batch = 18.9660s	
19939/33150 (epoch 30.074), train_loss = 0.77785432, grad/param norm = 1.6393e-01, time/batch = 15.6371s	
19940/33150 (epoch 30.075), train_loss = 0.81964229, grad/param norm = 1.6749e-01, time/batch = 19.1268s	
19941/33150 (epoch 30.077), train_loss = 0.89409412, grad/param norm = 2.2978e-01, time/batch = 17.5383s	
19942/33150 (epoch 30.078), train_loss = 1.03307805, grad/param norm = 2.0755e-01, time/batch = 17.9671s	
19943/33150 (epoch 30.080), train_loss = 1.02416791, grad/param norm = 1.5182e-01, time/batch = 19.9406s	
19944/33150 (epoch 30.081), train_loss = 0.78288891, grad/param norm = 1.9181e-01, time/batch = 16.2022s	
19945/33150 (epoch 30.083), train_loss = 0.69992935, grad/param norm = 2.0637e-01, time/batch = 17.7886s	
19946/33150 (epoch 30.084), train_loss = 0.77958068, grad/param norm = 1.7417e-01, time/batch = 32.6975s	
19947/33150 (epoch 30.086), train_loss = 0.83651687, grad/param norm = 1.6834e-01, time/batch = 16.2364s	
19948/33150 (epoch 30.087), train_loss = 0.78768329, grad/param norm = 1.5944e-01, time/batch = 16.2161s	
19949/33150 (epoch 30.089), train_loss = 0.81799768, grad/param norm = 1.5850e-01, time/batch = 18.0715s	
19950/33150 (epoch 30.090), train_loss = 0.86157652, grad/param norm = 1.9443e-01, time/batch = 18.3752s	
19951/33150 (epoch 30.092), train_loss = 0.84099027, grad/param norm = 1.8042e-01, time/batch = 19.6213s	
19952/33150 (epoch 30.094), train_loss = 0.93556477, grad/param norm = 1.8863e-01, time/batch = 15.7901s	
19953/33150 (epoch 30.095), train_loss = 0.83890457, grad/param norm = 1.5052e-01, time/batch = 19.1954s	
19954/33150 (epoch 30.097), train_loss = 0.75796302, grad/param norm = 1.7624e-01, time/batch = 18.9702s	
19955/33150 (epoch 30.098), train_loss = 1.13382325, grad/param norm = 2.0685e-01, time/batch = 16.2691s	
19956/33150 (epoch 30.100), train_loss = 1.07081948, grad/param norm = 1.8211e-01, time/batch = 20.7554s	
19957/33150 (epoch 30.101), train_loss = 0.83219403, grad/param norm = 1.5974e-01, time/batch = 17.3804s	
19958/33150 (epoch 30.103), train_loss = 0.92426927, grad/param norm = 1.5920e-01, time/batch = 17.3798s	
19959/33150 (epoch 30.104), train_loss = 0.83539193, grad/param norm = 1.9710e-01, time/batch = 17.9582s	
19960/33150 (epoch 30.106), train_loss = 1.00146808, grad/param norm = 1.7036e-01, time/batch = 19.5543s	
19961/33150 (epoch 30.107), train_loss = 1.07635121, grad/param norm = 1.9221e-01, time/batch = 16.4571s	
19962/33150 (epoch 30.109), train_loss = 0.87859428, grad/param norm = 1.3432e-01, time/batch = 16.5562s	
19963/33150 (epoch 30.110), train_loss = 1.01411969, grad/param norm = 1.9695e-01, time/batch = 18.3940s	
19964/33150 (epoch 30.112), train_loss = 0.83994887, grad/param norm = 1.6952e-01, time/batch = 16.5408s	
19965/33150 (epoch 30.113), train_loss = 0.87298053, grad/param norm = 1.8847e-01, time/batch = 17.0532s	
19966/33150 (epoch 30.115), train_loss = 1.07260298, grad/param norm = 1.9157e-01, time/batch = 18.9743s	
19967/33150 (epoch 30.116), train_loss = 0.92225499, grad/param norm = 1.5265e-01, time/batch = 16.4007s	
19968/33150 (epoch 30.118), train_loss = 0.93644682, grad/param norm = 1.7792e-01, time/batch = 18.3821s	
19969/33150 (epoch 30.119), train_loss = 0.95820638, grad/param norm = 2.1624e-01, time/batch = 18.6241s	
19970/33150 (epoch 30.121), train_loss = 0.87213443, grad/param norm = 1.6241e-01, time/batch = 18.7143s	
19971/33150 (epoch 30.122), train_loss = 1.05670938, grad/param norm = 2.0465e-01, time/batch = 19.0457s	
19972/33150 (epoch 30.124), train_loss = 0.75808544, grad/param norm = 1.2764e-01, time/batch = 15.8664s	
19973/33150 (epoch 30.125), train_loss = 1.01019262, grad/param norm = 1.7626e-01, time/batch = 17.1550s	
19974/33150 (epoch 30.127), train_loss = 0.91857919, grad/param norm = 1.8466e-01, time/batch = 16.8060s	
19975/33150 (epoch 30.128), train_loss = 0.94847320, grad/param norm = 1.8327e-01, time/batch = 16.9665s	
19976/33150 (epoch 30.130), train_loss = 0.90537196, grad/param norm = 1.7620e-01, time/batch = 16.5522s	
19977/33150 (epoch 30.131), train_loss = 1.12054579, grad/param norm = 1.8078e-01, time/batch = 15.8248s	
19978/33150 (epoch 30.133), train_loss = 0.83793965, grad/param norm = 1.5968e-01, time/batch = 17.5601s	
19979/33150 (epoch 30.134), train_loss = 1.04643785, grad/param norm = 1.7843e-01, time/batch = 16.9498s	
19980/33150 (epoch 30.136), train_loss = 0.91174030, grad/param norm = 1.7228e-01, time/batch = 17.9684s	
19981/33150 (epoch 30.137), train_loss = 0.99488027, grad/param norm = 1.7110e-01, time/batch = 16.9026s	
19982/33150 (epoch 30.139), train_loss = 0.95979514, grad/param norm = 1.7485e-01, time/batch = 17.4556s	
19983/33150 (epoch 30.140), train_loss = 1.07380997, grad/param norm = 1.8620e-01, time/batch = 17.1414s	
19984/33150 (epoch 30.142), train_loss = 0.99729504, grad/param norm = 1.9442e-01, time/batch = 18.3836s	
19985/33150 (epoch 30.143), train_loss = 0.93023834, grad/param norm = 2.0868e-01, time/batch = 17.6180s	
19986/33150 (epoch 30.145), train_loss = 0.89468459, grad/param norm = 1.8103e-01, time/batch = 16.7261s	
19987/33150 (epoch 30.146), train_loss = 1.00216189, grad/param norm = 1.9501e-01, time/batch = 18.3820s	
19988/33150 (epoch 30.148), train_loss = 1.04476672, grad/param norm = 1.5631e-01, time/batch = 15.9700s	
19989/33150 (epoch 30.149), train_loss = 0.96356425, grad/param norm = 2.1274e-01, time/batch = 15.9569s	
19990/33150 (epoch 30.151), train_loss = 1.08162776, grad/param norm = 1.8001e-01, time/batch = 16.6295s	
19991/33150 (epoch 30.152), train_loss = 0.85918783, grad/param norm = 1.5662e-01, time/batch = 17.0601s	
19992/33150 (epoch 30.154), train_loss = 0.86523122, grad/param norm = 1.7556e-01, time/batch = 17.1370s	
19993/33150 (epoch 30.155), train_loss = 0.78458217, grad/param norm = 1.6352e-01, time/batch = 17.7822s	
19994/33150 (epoch 30.157), train_loss = 0.88458111, grad/param norm = 1.7892e-01, time/batch = 17.2117s	
19995/33150 (epoch 30.158), train_loss = 0.87575684, grad/param norm = 1.6730e-01, time/batch = 17.4772s	
19996/33150 (epoch 30.160), train_loss = 0.97510883, grad/param norm = 1.7618e-01, time/batch = 16.6216s	
19997/33150 (epoch 30.161), train_loss = 0.85418561, grad/param norm = 1.9700e-01, time/batch = 18.3889s	
19998/33150 (epoch 30.163), train_loss = 0.79387891, grad/param norm = 1.5868e-01, time/batch = 16.2906s	
19999/33150 (epoch 30.164), train_loss = 0.94579249, grad/param norm = 2.0225e-01, time/batch = 15.5219s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch30.17_1.7114.t7	
20000/33150 (epoch 30.166), train_loss = 0.88736849, grad/param norm = 1.6548e-01, time/batch = 15.5860s	
20001/33150 (epoch 30.167), train_loss = 1.35541678, grad/param norm = 2.0034e-01, time/batch = 16.7165s	
20002/33150 (epoch 30.169), train_loss = 0.96479462, grad/param norm = 2.2331e-01, time/batch = 16.6991s	
20003/33150 (epoch 30.170), train_loss = 0.84619796, grad/param norm = 2.0452e-01, time/batch = 17.3135s	
20004/33150 (epoch 30.172), train_loss = 1.00444416, grad/param norm = 1.9551e-01, time/batch = 18.0647s	
20005/33150 (epoch 30.173), train_loss = 0.95455822, grad/param norm = 1.8691e-01, time/batch = 16.7286s	
20006/33150 (epoch 30.175), train_loss = 0.88556670, grad/param norm = 1.9065e-01, time/batch = 16.4536s	
20007/33150 (epoch 30.176), train_loss = 0.98401943, grad/param norm = 1.8655e-01, time/batch = 16.2324s	
20008/33150 (epoch 30.178), train_loss = 1.11086754, grad/param norm = 2.3046e-01, time/batch = 19.0539s	
20009/33150 (epoch 30.179), train_loss = 0.97486763, grad/param norm = 1.6768e-01, time/batch = 16.5499s	
20010/33150 (epoch 30.181), train_loss = 0.92394527, grad/param norm = 1.8853e-01, time/batch = 17.2149s	
20011/33150 (epoch 30.183), train_loss = 0.91728377, grad/param norm = 2.0008e-01, time/batch = 18.1476s	
20012/33150 (epoch 30.184), train_loss = 1.13542846, grad/param norm = 1.8945e-01, time/batch = 16.7147s	
20013/33150 (epoch 30.186), train_loss = 1.05230362, grad/param norm = 1.6844e-01, time/batch = 15.6348s	
20014/33150 (epoch 30.187), train_loss = 0.92022143, grad/param norm = 1.8731e-01, time/batch = 17.2989s	
20015/33150 (epoch 30.189), train_loss = 0.72725117, grad/param norm = 1.6034e-01, time/batch = 17.5563s	
20016/33150 (epoch 30.190), train_loss = 0.82090046, grad/param norm = 1.7394e-01, time/batch = 15.2765s	
20017/33150 (epoch 30.192), train_loss = 0.93115677, grad/param norm = 1.7474e-01, time/batch = 16.1308s	
20018/33150 (epoch 30.193), train_loss = 1.00480151, grad/param norm = 1.8985e-01, time/batch = 16.2900s	
20019/33150 (epoch 30.195), train_loss = 1.12415071, grad/param norm = 1.8773e-01, time/batch = 17.5995s	
20020/33150 (epoch 30.196), train_loss = 1.03852195, grad/param norm = 1.6026e-01, time/batch = 15.1419s	
20021/33150 (epoch 30.198), train_loss = 0.79035381, grad/param norm = 1.6347e-01, time/batch = 17.5566s	
20022/33150 (epoch 30.199), train_loss = 1.00506791, grad/param norm = 2.0219e-01, time/batch = 17.0502s	
20023/33150 (epoch 30.201), train_loss = 0.85457884, grad/param norm = 1.4054e-01, time/batch = 16.4521s	
20024/33150 (epoch 30.202), train_loss = 0.72707143, grad/param norm = 1.4963e-01, time/batch = 16.4722s	
20025/33150 (epoch 30.204), train_loss = 0.97577299, grad/param norm = 1.7657e-01, time/batch = 17.9609s	
20026/33150 (epoch 30.205), train_loss = 0.94692168, grad/param norm = 1.7755e-01, time/batch = 17.2195s	
20027/33150 (epoch 30.207), train_loss = 0.95715018, grad/param norm = 1.5646e-01, time/batch = 15.6167s	
20028/33150 (epoch 30.208), train_loss = 0.98176167, grad/param norm = 1.8022e-01, time/batch = 19.0463s	
20029/33150 (epoch 30.210), train_loss = 0.85279588, grad/param norm = 1.4260e-01, time/batch = 17.7897s	
20030/33150 (epoch 30.211), train_loss = 0.93610824, grad/param norm = 2.0540e-01, time/batch = 17.2822s	
20031/33150 (epoch 30.213), train_loss = 0.98275363, grad/param norm = 1.6355e-01, time/batch = 18.0331s	
20032/33150 (epoch 30.214), train_loss = 0.88887070, grad/param norm = 1.5945e-01, time/batch = 16.9600s	
20033/33150 (epoch 30.216), train_loss = 0.84474302, grad/param norm = 1.8035e-01, time/batch = 17.5432s	
20034/33150 (epoch 30.217), train_loss = 0.88633457, grad/param norm = 1.5289e-01, time/batch = 16.5163s	
20035/33150 (epoch 30.219), train_loss = 0.85426457, grad/param norm = 1.7709e-01, time/batch = 15.7718s	
20036/33150 (epoch 30.220), train_loss = 0.86298361, grad/param norm = 1.4672e-01, time/batch = 18.7827s	
20037/33150 (epoch 30.222), train_loss = 1.03450851, grad/param norm = 1.7995e-01, time/batch = 17.1336s	
20038/33150 (epoch 30.223), train_loss = 0.91796216, grad/param norm = 1.6442e-01, time/batch = 17.1351s	
20039/33150 (epoch 30.225), train_loss = 1.03847592, grad/param norm = 1.6201e-01, time/batch = 16.7264s	
20040/33150 (epoch 30.226), train_loss = 0.90747060, grad/param norm = 1.5684e-01, time/batch = 19.1160s	
20041/33150 (epoch 30.228), train_loss = 0.89604127, grad/param norm = 1.7789e-01, time/batch = 16.8498s	
20042/33150 (epoch 30.229), train_loss = 0.90662222, grad/param norm = 1.7298e-01, time/batch = 16.7947s	
20043/33150 (epoch 30.231), train_loss = 1.02288477, grad/param norm = 1.8926e-01, time/batch = 16.7284s	
20044/33150 (epoch 30.232), train_loss = 0.92972993, grad/param norm = 1.8947e-01, time/batch = 16.3704s	
20045/33150 (epoch 30.234), train_loss = 0.94347029, grad/param norm = 1.9363e-01, time/batch = 17.0472s	
20046/33150 (epoch 30.235), train_loss = 0.96974011, grad/param norm = 2.1596e-01, time/batch = 17.4645s	
20047/33150 (epoch 30.237), train_loss = 0.93617493, grad/param norm = 1.7153e-01, time/batch = 17.7074s	
20048/33150 (epoch 30.238), train_loss = 1.00789272, grad/param norm = 2.0130e-01, time/batch = 16.6016s	
20049/33150 (epoch 30.240), train_loss = 0.95549408, grad/param norm = 1.6647e-01, time/batch = 17.2022s	
20050/33150 (epoch 30.241), train_loss = 1.00302712, grad/param norm = 1.8131e-01, time/batch = 17.3757s	
20051/33150 (epoch 30.243), train_loss = 0.98294581, grad/param norm = 1.8013e-01, time/batch = 17.1294s	
20052/33150 (epoch 30.244), train_loss = 0.91938172, grad/param norm = 1.6211e-01, time/batch = 17.9625s	
20053/33150 (epoch 30.246), train_loss = 0.99174891, grad/param norm = 1.7577e-01, time/batch = 15.6933s	
20054/33150 (epoch 30.247), train_loss = 0.87032647, grad/param norm = 1.6333e-01, time/batch = 17.7011s	
20055/33150 (epoch 30.249), train_loss = 1.03300510, grad/param norm = 1.6782e-01, time/batch = 15.8775s	
20056/33150 (epoch 30.250), train_loss = 0.96074120, grad/param norm = 1.5240e-01, time/batch = 17.4667s	
20057/33150 (epoch 30.252), train_loss = 0.99096802, grad/param norm = 1.5515e-01, time/batch = 18.8653s	
20058/33150 (epoch 30.253), train_loss = 0.89697843, grad/param norm = 1.7813e-01, time/batch = 15.5185s	
20059/33150 (epoch 30.255), train_loss = 0.92652408, grad/param norm = 1.5119e-01, time/batch = 17.5335s	
20060/33150 (epoch 30.256), train_loss = 1.02409080, grad/param norm = 1.6855e-01, time/batch = 15.5260s	
20061/33150 (epoch 30.258), train_loss = 0.86808535, grad/param norm = 1.7671e-01, time/batch = 18.1975s	
20062/33150 (epoch 30.259), train_loss = 0.75484238, grad/param norm = 1.6833e-01, time/batch = 16.6308s	
20063/33150 (epoch 30.261), train_loss = 0.82068179, grad/param norm = 1.4920e-01, time/batch = 18.0517s	
20064/33150 (epoch 30.262), train_loss = 1.00401736, grad/param norm = 1.8687e-01, time/batch = 16.1303s	
20065/33150 (epoch 30.264), train_loss = 0.72327603, grad/param norm = 1.3985e-01, time/batch = 16.7122s	
20066/33150 (epoch 30.265), train_loss = 0.94187672, grad/param norm = 1.6481e-01, time/batch = 18.4591s	
20067/33150 (epoch 30.267), train_loss = 1.00467246, grad/param norm = 2.2630e-01, time/batch = 19.3743s	
20068/33150 (epoch 30.268), train_loss = 1.01780855, grad/param norm = 1.5789e-01, time/batch = 17.9551s	
20069/33150 (epoch 30.270), train_loss = 1.10758155, grad/param norm = 1.7708e-01, time/batch = 16.7993s	
20070/33150 (epoch 30.271), train_loss = 1.02522553, grad/param norm = 1.7715e-01, time/batch = 17.2739s	
20071/33150 (epoch 30.273), train_loss = 1.04945398, grad/param norm = 1.6881e-01, time/batch = 16.9280s	
20072/33150 (epoch 30.275), train_loss = 1.07600132, grad/param norm = 1.8154e-01, time/batch = 15.2037s	
20073/33150 (epoch 30.276), train_loss = 0.94000098, grad/param norm = 1.6965e-01, time/batch = 18.2115s	
20074/33150 (epoch 30.278), train_loss = 1.03414195, grad/param norm = 1.6689e-01, time/batch = 18.9618s	
20075/33150 (epoch 30.279), train_loss = 0.98023571, grad/param norm = 1.4815e-01, time/batch = 17.7900s	
20076/33150 (epoch 30.281), train_loss = 0.91884527, grad/param norm = 1.6282e-01, time/batch = 16.2951s	
20077/33150 (epoch 30.282), train_loss = 0.94147251, grad/param norm = 1.3483e-01, time/batch = 18.1393s	
20078/33150 (epoch 30.284), train_loss = 0.84243385, grad/param norm = 1.5343e-01, time/batch = 17.4487s	
20079/33150 (epoch 30.285), train_loss = 0.94149339, grad/param norm = 1.6555e-01, time/batch = 16.5281s	
20080/33150 (epoch 30.287), train_loss = 0.81724500, grad/param norm = 1.5560e-01, time/batch = 17.4798s	
20081/33150 (epoch 30.288), train_loss = 1.01773644, grad/param norm = 1.5899e-01, time/batch = 17.2217s	
20082/33150 (epoch 30.290), train_loss = 0.78967409, grad/param norm = 1.5583e-01, time/batch = 16.8819s	
20083/33150 (epoch 30.291), train_loss = 0.75526320, grad/param norm = 1.5984e-01, time/batch = 17.5505s	
20084/33150 (epoch 30.293), train_loss = 0.93588172, grad/param norm = 1.7671e-01, time/batch = 18.5594s	
20085/33150 (epoch 30.294), train_loss = 0.71302198, grad/param norm = 1.3963e-01, time/batch = 17.2247s	
20086/33150 (epoch 30.296), train_loss = 0.91416242, grad/param norm = 1.4733e-01, time/batch = 15.0300s	
20087/33150 (epoch 30.297), train_loss = 0.86297868, grad/param norm = 1.7359e-01, time/batch = 18.5320s	
20088/33150 (epoch 30.299), train_loss = 0.87185727, grad/param norm = 1.8485e-01, time/batch = 17.0377s	
20089/33150 (epoch 30.300), train_loss = 0.86413492, grad/param norm = 1.3843e-01, time/batch = 15.5272s	
20090/33150 (epoch 30.302), train_loss = 0.90894099, grad/param norm = 1.6788e-01, time/batch = 17.0171s	
20091/33150 (epoch 30.303), train_loss = 0.87809090, grad/param norm = 1.6751e-01, time/batch = 16.7998s	
20092/33150 (epoch 30.305), train_loss = 0.96496437, grad/param norm = 1.6122e-01, time/batch = 17.8683s	
20093/33150 (epoch 30.306), train_loss = 0.98707798, grad/param norm = 1.8505e-01, time/batch = 15.6292s	
20094/33150 (epoch 30.308), train_loss = 1.13344054, grad/param norm = 1.7729e-01, time/batch = 18.3035s	
20095/33150 (epoch 30.309), train_loss = 0.77212119, grad/param norm = 1.4661e-01, time/batch = 16.4670s	
20096/33150 (epoch 30.311), train_loss = 0.89597157, grad/param norm = 1.9005e-01, time/batch = 17.2109s	
20097/33150 (epoch 30.312), train_loss = 0.73044772, grad/param norm = 1.3591e-01, time/batch = 15.5554s	
20098/33150 (epoch 30.314), train_loss = 0.89124801, grad/param norm = 1.8211e-01, time/batch = 16.8227s	
20099/33150 (epoch 30.315), train_loss = 0.96363507, grad/param norm = 1.5396e-01, time/batch = 17.7285s	
20100/33150 (epoch 30.317), train_loss = 0.73741045, grad/param norm = 1.3247e-01, time/batch = 15.2191s	
20101/33150 (epoch 30.318), train_loss = 0.84128604, grad/param norm = 1.4634e-01, time/batch = 17.8867s	
20102/33150 (epoch 30.320), train_loss = 0.77188596, grad/param norm = 1.4826e-01, time/batch = 18.3828s	
20103/33150 (epoch 30.321), train_loss = 0.88819918, grad/param norm = 1.4209e-01, time/batch = 15.8125s	
20104/33150 (epoch 30.323), train_loss = 0.87342424, grad/param norm = 1.6185e-01, time/batch = 17.3035s	
20105/33150 (epoch 30.324), train_loss = 0.95019971, grad/param norm = 2.2279e-01, time/batch = 17.6433s	
20106/33150 (epoch 30.326), train_loss = 0.93771087, grad/param norm = 1.5774e-01, time/batch = 17.3920s	
20107/33150 (epoch 30.327), train_loss = 1.00570088, grad/param norm = 1.7444e-01, time/batch = 17.0455s	
20108/33150 (epoch 30.329), train_loss = 0.95301566, grad/param norm = 1.6381e-01, time/batch = 17.8822s	
20109/33150 (epoch 30.330), train_loss = 0.90950310, grad/param norm = 2.0426e-01, time/batch = 17.4712s	
20110/33150 (epoch 30.332), train_loss = 0.89615471, grad/param norm = 1.5264e-01, time/batch = 17.1166s	
20111/33150 (epoch 30.333), train_loss = 0.95661021, grad/param norm = 1.4807e-01, time/batch = 18.0499s	
20112/33150 (epoch 30.335), train_loss = 0.83761035, grad/param norm = 1.5571e-01, time/batch = 16.5722s	
20113/33150 (epoch 30.336), train_loss = 0.82551433, grad/param norm = 1.7024e-01, time/batch = 16.1300s	
20114/33150 (epoch 30.338), train_loss = 0.77420266, grad/param norm = 1.6677e-01, time/batch = 16.3856s	
20115/33150 (epoch 30.339), train_loss = 0.99081162, grad/param norm = 1.7141e-01, time/batch = 18.7986s	
20116/33150 (epoch 30.341), train_loss = 0.91818195, grad/param norm = 1.9374e-01, time/batch = 16.0407s	
20117/33150 (epoch 30.342), train_loss = 0.83636790, grad/param norm = 1.7169e-01, time/batch = 15.7815s	
20118/33150 (epoch 30.344), train_loss = 0.89911112, grad/param norm = 1.6033e-01, time/batch = 18.3772s	
20119/33150 (epoch 30.345), train_loss = 0.88665330, grad/param norm = 1.5190e-01, time/batch = 17.3686s	
20120/33150 (epoch 30.347), train_loss = 0.74380953, grad/param norm = 1.8752e-01, time/batch = 17.6688s	
20121/33150 (epoch 30.348), train_loss = 0.94459075, grad/param norm = 1.5860e-01, time/batch = 16.7832s	
20122/33150 (epoch 30.350), train_loss = 0.81383007, grad/param norm = 1.6557e-01, time/batch = 16.3787s	
20123/33150 (epoch 30.351), train_loss = 0.99241410, grad/param norm = 1.6454e-01, time/batch = 17.5366s	
20124/33150 (epoch 30.353), train_loss = 0.94027427, grad/param norm = 1.9257e-01, time/batch = 16.7794s	
20125/33150 (epoch 30.354), train_loss = 1.13023735, grad/param norm = 1.6808e-01, time/batch = 16.9444s	
20126/33150 (epoch 30.356), train_loss = 0.99766035, grad/param norm = 1.6646e-01, time/batch = 19.3685s	
20127/33150 (epoch 30.357), train_loss = 0.94705837, grad/param norm = 1.7446e-01, time/batch = 17.2958s	
20128/33150 (epoch 30.359), train_loss = 0.96630826, grad/param norm = 1.6812e-01, time/batch = 16.8002s	
20129/33150 (epoch 30.360), train_loss = 0.94311563, grad/param norm = 1.8886e-01, time/batch = 16.3696s	
20130/33150 (epoch 30.362), train_loss = 1.03701616, grad/param norm = 1.9163e-01, time/batch = 17.5540s	
20131/33150 (epoch 30.363), train_loss = 0.93863403, grad/param norm = 1.5478e-01, time/batch = 15.5928s	
20132/33150 (epoch 30.365), train_loss = 0.88752762, grad/param norm = 1.5237e-01, time/batch = 18.0302s	
20133/33150 (epoch 30.367), train_loss = 0.85973034, grad/param norm = 1.5418e-01, time/batch = 17.1333s	
20134/33150 (epoch 30.368), train_loss = 0.90373015, grad/param norm = 1.9191e-01, time/batch = 16.3894s	
20135/33150 (epoch 30.370), train_loss = 0.92847745, grad/param norm = 1.7151e-01, time/batch = 15.6282s	
20136/33150 (epoch 30.371), train_loss = 0.82825738, grad/param norm = 1.8877e-01, time/batch = 16.3839s	
20137/33150 (epoch 30.373), train_loss = 0.94289110, grad/param norm = 1.6661e-01, time/batch = 16.2923s	
20138/33150 (epoch 30.374), train_loss = 0.88803691, grad/param norm = 1.4409e-01, time/batch = 15.2508s	
20139/33150 (epoch 30.376), train_loss = 1.00900381, grad/param norm = 1.6615e-01, time/batch = 14.9632s	
20140/33150 (epoch 30.377), train_loss = 0.84063434, grad/param norm = 1.5117e-01, time/batch = 16.9660s	
20141/33150 (epoch 30.379), train_loss = 0.97061700, grad/param norm = 1.7849e-01, time/batch = 16.4689s	
20142/33150 (epoch 30.380), train_loss = 0.96653366, grad/param norm = 1.4899e-01, time/batch = 15.2747s	
20143/33150 (epoch 30.382), train_loss = 0.89871404, grad/param norm = 1.6163e-01, time/batch = 16.4659s	
20144/33150 (epoch 30.383), train_loss = 0.83392452, grad/param norm = 1.6058e-01, time/batch = 17.3164s	
20145/33150 (epoch 30.385), train_loss = 0.86466362, grad/param norm = 1.6102e-01, time/batch = 14.8432s	
20146/33150 (epoch 30.386), train_loss = 0.79452771, grad/param norm = 1.4551e-01, time/batch = 28.7878s	
20147/33150 (epoch 30.388), train_loss = 0.84422025, grad/param norm = 1.5615e-01, time/batch = 16.7029s	
20148/33150 (epoch 30.389), train_loss = 0.83144702, grad/param norm = 1.4046e-01, time/batch = 15.9270s	
20149/33150 (epoch 30.391), train_loss = 1.06093390, grad/param norm = 1.7637e-01, time/batch = 15.4908s	
20150/33150 (epoch 30.392), train_loss = 0.87717598, grad/param norm = 1.7534e-01, time/batch = 16.1824s	
20151/33150 (epoch 30.394), train_loss = 0.77476899, grad/param norm = 1.4177e-01, time/batch = 15.5723s	
20152/33150 (epoch 30.395), train_loss = 0.74401029, grad/param norm = 1.4980e-01, time/batch = 15.3460s	
20153/33150 (epoch 30.397), train_loss = 0.62970659, grad/param norm = 1.4218e-01, time/batch = 15.3129s	
20154/33150 (epoch 30.398), train_loss = 0.90772274, grad/param norm = 1.8217e-01, time/batch = 15.0830s	
20155/33150 (epoch 30.400), train_loss = 0.87454495, grad/param norm = 1.3375e-01, time/batch = 15.0739s	
20156/33150 (epoch 30.401), train_loss = 0.78986078, grad/param norm = 1.4200e-01, time/batch = 15.0716s	
20157/33150 (epoch 30.403), train_loss = 0.75173802, grad/param norm = 1.3591e-01, time/batch = 15.0662s	
20158/33150 (epoch 30.404), train_loss = 0.91582886, grad/param norm = 1.6775e-01, time/batch = 15.7779s	
20159/33150 (epoch 30.406), train_loss = 0.84498720, grad/param norm = 1.3415e-01, time/batch = 15.9362s	
20160/33150 (epoch 30.407), train_loss = 0.79218860, grad/param norm = 1.6010e-01, time/batch = 15.1876s	
20161/33150 (epoch 30.409), train_loss = 0.73850378, grad/param norm = 1.4743e-01, time/batch = 16.8687s	
20162/33150 (epoch 30.410), train_loss = 0.92457845, grad/param norm = 1.7042e-01, time/batch = 15.5077s	
20163/33150 (epoch 30.412), train_loss = 0.95791412, grad/param norm = 1.7113e-01, time/batch = 16.0101s	
20164/33150 (epoch 30.413), train_loss = 0.81190532, grad/param norm = 1.5920e-01, time/batch = 15.5893s	
20165/33150 (epoch 30.415), train_loss = 0.92402759, grad/param norm = 1.6084e-01, time/batch = 17.2907s	
20166/33150 (epoch 30.416), train_loss = 0.84085085, grad/param norm = 1.5528e-01, time/batch = 16.1037s	
20167/33150 (epoch 30.418), train_loss = 0.95265172, grad/param norm = 1.9936e-01, time/batch = 17.9027s	
20168/33150 (epoch 30.419), train_loss = 0.88122735, grad/param norm = 1.5421e-01, time/batch = 16.5529s	
20169/33150 (epoch 30.421), train_loss = 0.87812311, grad/param norm = 1.8173e-01, time/batch = 17.5308s	
20170/33150 (epoch 30.422), train_loss = 0.85581579, grad/param norm = 1.4373e-01, time/batch = 16.4594s	
20171/33150 (epoch 30.424), train_loss = 0.85127462, grad/param norm = 1.6463e-01, time/batch = 16.0432s	
20172/33150 (epoch 30.425), train_loss = 0.98230773, grad/param norm = 1.6855e-01, time/batch = 18.0198s	
20173/33150 (epoch 30.427), train_loss = 0.89383980, grad/param norm = 1.4657e-01, time/batch = 17.6260s	
20174/33150 (epoch 30.428), train_loss = 0.89805765, grad/param norm = 1.7227e-01, time/batch = 16.6939s	
20175/33150 (epoch 30.430), train_loss = 0.91073657, grad/param norm = 1.8759e-01, time/batch = 16.7691s	
20176/33150 (epoch 30.431), train_loss = 0.96630635, grad/param norm = 1.7510e-01, time/batch = 17.1893s	
20177/33150 (epoch 30.433), train_loss = 0.88006719, grad/param norm = 1.6794e-01, time/batch = 17.7799s	
20178/33150 (epoch 30.434), train_loss = 0.78234318, grad/param norm = 1.6383e-01, time/batch = 16.6948s	
20179/33150 (epoch 30.436), train_loss = 0.89348735, grad/param norm = 1.5250e-01, time/batch = 18.3049s	
20180/33150 (epoch 30.437), train_loss = 0.91116455, grad/param norm = 1.8757e-01, time/batch = 18.0510s	
20181/33150 (epoch 30.439), train_loss = 1.05017617, grad/param norm = 1.6980e-01, time/batch = 17.7861s	
20182/33150 (epoch 30.440), train_loss = 0.95568424, grad/param norm = 1.6840e-01, time/batch = 25.3004s	
20183/33150 (epoch 30.442), train_loss = 0.78373988, grad/param norm = 1.4324e-01, time/batch = 17.7153s	
20184/33150 (epoch 30.443), train_loss = 0.94436495, grad/param norm = 1.7642e-01, time/batch = 15.6081s	
20185/33150 (epoch 30.445), train_loss = 0.92847998, grad/param norm = 2.0354e-01, time/batch = 18.2911s	
20186/33150 (epoch 30.446), train_loss = 0.91879159, grad/param norm = 1.8435e-01, time/batch = 18.0448s	
20187/33150 (epoch 30.448), train_loss = 1.01534349, grad/param norm = 1.7903e-01, time/batch = 19.2968s	
20188/33150 (epoch 30.449), train_loss = 0.91500860, grad/param norm = 1.4903e-01, time/batch = 16.9422s	
20189/33150 (epoch 30.451), train_loss = 0.90276264, grad/param norm = 1.8761e-01, time/batch = 18.6214s	
20190/33150 (epoch 30.452), train_loss = 1.07636451, grad/param norm = 1.6915e-01, time/batch = 18.2272s	
20191/33150 (epoch 30.454), train_loss = 0.89956807, grad/param norm = 1.6638e-01, time/batch = 17.2105s	
20192/33150 (epoch 30.456), train_loss = 0.81365286, grad/param norm = 1.5399e-01, time/batch = 19.3817s	
20193/33150 (epoch 30.457), train_loss = 0.92948294, grad/param norm = 1.7210e-01, time/batch = 18.6191s	
20194/33150 (epoch 30.459), train_loss = 1.00711969, grad/param norm = 2.8812e-01, time/batch = 17.3721s	
20195/33150 (epoch 30.460), train_loss = 0.96264458, grad/param norm = 1.5523e-01, time/batch = 17.9519s	
20196/33150 (epoch 30.462), train_loss = 1.01046482, grad/param norm = 2.2380e-01, time/batch = 19.9416s	
20197/33150 (epoch 30.463), train_loss = 1.13119185, grad/param norm = 2.2340e-01, time/batch = 18.3635s	
20198/33150 (epoch 30.465), train_loss = 0.94393752, grad/param norm = 1.6304e-01, time/batch = 18.1230s	
20199/33150 (epoch 30.466), train_loss = 0.88004756, grad/param norm = 1.7068e-01, time/batch = 19.8658s	
20200/33150 (epoch 30.468), train_loss = 1.11372383, grad/param norm = 1.7687e-01, time/batch = 16.4589s	
20201/33150 (epoch 30.469), train_loss = 0.89082156, grad/param norm = 1.6773e-01, time/batch = 16.7825s	
20202/33150 (epoch 30.471), train_loss = 0.85358920, grad/param norm = 1.6584e-01, time/batch = 19.6285s	
20203/33150 (epoch 30.472), train_loss = 0.92588957, grad/param norm = 2.0472e-01, time/batch = 19.6146s	
20204/33150 (epoch 30.474), train_loss = 1.00139411, grad/param norm = 2.3002e-01, time/batch = 16.0982s	
20205/33150 (epoch 30.475), train_loss = 1.15420150, grad/param norm = 1.9580e-01, time/batch = 17.2208s	
20206/33150 (epoch 30.477), train_loss = 1.03197773, grad/param norm = 1.9738e-01, time/batch = 19.0567s	
20207/33150 (epoch 30.478), train_loss = 0.97437474, grad/param norm = 1.6026e-01, time/batch = 18.2904s	
20208/33150 (epoch 30.480), train_loss = 0.86059922, grad/param norm = 1.6517e-01, time/batch = 16.7300s	
20209/33150 (epoch 30.481), train_loss = 0.78205576, grad/param norm = 1.6263e-01, time/batch = 18.1153s	
20210/33150 (epoch 30.483), train_loss = 0.87399628, grad/param norm = 1.6495e-01, time/batch = 19.1298s	
20211/33150 (epoch 30.484), train_loss = 0.84793268, grad/param norm = 1.6278e-01, time/batch = 17.4478s	
20212/33150 (epoch 30.486), train_loss = 0.83486090, grad/param norm = 1.5654e-01, time/batch = 19.2102s	
20213/33150 (epoch 30.487), train_loss = 0.94609866, grad/param norm = 1.7653e-01, time/batch = 16.1332s	
20214/33150 (epoch 30.489), train_loss = 0.92189622, grad/param norm = 1.6816e-01, time/batch = 16.6215s	
20215/33150 (epoch 30.490), train_loss = 0.76337449, grad/param norm = 1.4678e-01, time/batch = 17.1546s	
20216/33150 (epoch 30.492), train_loss = 0.85968811, grad/param norm = 1.7759e-01, time/batch = 18.4577s	
20217/33150 (epoch 30.493), train_loss = 0.98331572, grad/param norm = 1.7034e-01, time/batch = 15.0393s	
20218/33150 (epoch 30.495), train_loss = 0.97419091, grad/param norm = 1.5747e-01, time/batch = 16.1284s	
20219/33150 (epoch 30.496), train_loss = 0.87178554, grad/param norm = 1.5334e-01, time/batch = 19.0435s	
20220/33150 (epoch 30.498), train_loss = 1.01598978, grad/param norm = 1.9092e-01, time/batch = 17.6367s	
20221/33150 (epoch 30.499), train_loss = 1.02152779, grad/param norm = 1.7467e-01, time/batch = 17.2017s	
20222/33150 (epoch 30.501), train_loss = 0.96447623, grad/param norm = 1.9230e-01, time/batch = 16.5719s	
20223/33150 (epoch 30.502), train_loss = 1.02607156, grad/param norm = 1.9234e-01, time/batch = 18.8694s	
20224/33150 (epoch 30.504), train_loss = 0.96893593, grad/param norm = 1.6952e-01, time/batch = 17.6356s	
20225/33150 (epoch 30.505), train_loss = 1.06863275, grad/param norm = 1.9377e-01, time/batch = 15.8152s	
20226/33150 (epoch 30.507), train_loss = 0.85750336, grad/param norm = 1.5792e-01, time/batch = 16.2325s	
20227/33150 (epoch 30.508), train_loss = 0.86060092, grad/param norm = 1.8921e-01, time/batch = 16.2242s	
20228/33150 (epoch 30.510), train_loss = 0.98657259, grad/param norm = 1.4682e-01, time/batch = 17.2976s	
20229/33150 (epoch 30.511), train_loss = 1.02038368, grad/param norm = 1.7257e-01, time/batch = 16.9496s	
20230/33150 (epoch 30.513), train_loss = 0.95274887, grad/param norm = 1.8421e-01, time/batch = 19.3732s	
20231/33150 (epoch 30.514), train_loss = 0.77853061, grad/param norm = 1.5455e-01, time/batch = 17.9374s	
20232/33150 (epoch 30.516), train_loss = 0.91975762, grad/param norm = 1.8013e-01, time/batch = 18.7411s	
20233/33150 (epoch 30.517), train_loss = 1.00621956, grad/param norm = 1.7473e-01, time/batch = 18.7912s	
20234/33150 (epoch 30.519), train_loss = 0.83426887, grad/param norm = 1.4658e-01, time/batch = 19.7573s	
20235/33150 (epoch 30.520), train_loss = 0.93484254, grad/param norm = 1.6560e-01, time/batch = 20.3497s	
20236/33150 (epoch 30.522), train_loss = 1.01315609, grad/param norm = 2.1220e-01, time/batch = 21.2766s	
20237/33150 (epoch 30.523), train_loss = 0.81567787, grad/param norm = 1.5257e-01, time/batch = 19.2047s	
20238/33150 (epoch 30.525), train_loss = 0.96344717, grad/param norm = 1.8309e-01, time/batch = 21.1008s	
20239/33150 (epoch 30.526), train_loss = 0.82825523, grad/param norm = 1.4849e-01, time/batch = 22.1054s	
20240/33150 (epoch 30.528), train_loss = 0.94998490, grad/param norm = 1.6247e-01, time/batch = 20.3742s	
20241/33150 (epoch 30.529), train_loss = 0.92629733, grad/param norm = 1.7146e-01, time/batch = 22.4492s	
20242/33150 (epoch 30.531), train_loss = 0.78281641, grad/param norm = 1.8884e-01, time/batch = 21.2222s	
20243/33150 (epoch 30.532), train_loss = 0.94188445, grad/param norm = 1.8599e-01, time/batch = 20.2078s	
20244/33150 (epoch 30.534), train_loss = 0.90122866, grad/param norm = 1.3998e-01, time/batch = 25.1817s	
20245/33150 (epoch 30.535), train_loss = 0.85504846, grad/param norm = 1.9325e-01, time/batch = 17.8977s	
20246/33150 (epoch 30.537), train_loss = 0.95240687, grad/param norm = 1.8526e-01, time/batch = 16.2164s	
20247/33150 (epoch 30.538), train_loss = 0.83111805, grad/param norm = 1.5774e-01, time/batch = 17.3003s	
20248/33150 (epoch 30.540), train_loss = 0.81504355, grad/param norm = 1.6841e-01, time/batch = 17.3840s	
20249/33150 (epoch 30.541), train_loss = 0.99700059, grad/param norm = 1.7161e-01, time/batch = 17.8032s	
20250/33150 (epoch 30.543), train_loss = 0.92804039, grad/param norm = 1.7256e-01, time/batch = 18.8728s	
20251/33150 (epoch 30.544), train_loss = 1.00699173, grad/param norm = 1.8629e-01, time/batch = 17.1221s	
20252/33150 (epoch 30.546), train_loss = 0.91338249, grad/param norm = 1.8059e-01, time/batch = 19.7009s	
20253/33150 (epoch 30.548), train_loss = 0.87268146, grad/param norm = 1.8277e-01, time/batch = 16.8810s	
20254/33150 (epoch 30.549), train_loss = 0.86456826, grad/param norm = 1.5499e-01, time/batch = 16.9598s	
20255/33150 (epoch 30.551), train_loss = 0.84482707, grad/param norm = 1.4908e-01, time/batch = 17.0152s	
20256/33150 (epoch 30.552), train_loss = 0.71953896, grad/param norm = 1.3856e-01, time/batch = 16.1220s	
20257/33150 (epoch 30.554), train_loss = 0.97056971, grad/param norm = 1.7879e-01, time/batch = 18.8753s	
20258/33150 (epoch 30.555), train_loss = 1.00824731, grad/param norm = 1.8937e-01, time/batch = 17.1403s	
20259/33150 (epoch 30.557), train_loss = 0.72945685, grad/param norm = 1.6903e-01, time/batch = 15.5310s	
20260/33150 (epoch 30.558), train_loss = 0.97217881, grad/param norm = 2.2625e-01, time/batch = 16.6192s	
20261/33150 (epoch 30.560), train_loss = 0.87385639, grad/param norm = 1.6883e-01, time/batch = 15.1410s	
20262/33150 (epoch 30.561), train_loss = 0.76245634, grad/param norm = 1.5600e-01, time/batch = 15.1572s	
20263/33150 (epoch 30.563), train_loss = 0.96884640, grad/param norm = 2.3248e-01, time/batch = 16.0558s	
20264/33150 (epoch 30.564), train_loss = 1.05129530, grad/param norm = 1.7066e-01, time/batch = 15.2081s	
20265/33150 (epoch 30.566), train_loss = 0.84806798, grad/param norm = 1.6105e-01, time/batch = 18.8769s	
20266/33150 (epoch 30.567), train_loss = 0.84761295, grad/param norm = 1.6438e-01, time/batch = 18.4709s	
20267/33150 (epoch 30.569), train_loss = 0.94392348, grad/param norm = 1.7764e-01, time/batch = 17.3765s	
20268/33150 (epoch 30.570), train_loss = 0.96384365, grad/param norm = 1.5879e-01, time/batch = 18.9643s	
20269/33150 (epoch 30.572), train_loss = 0.84043569, grad/param norm = 1.8835e-01, time/batch = 18.6434s	
20270/33150 (epoch 30.573), train_loss = 0.75866515, grad/param norm = 1.3011e-01, time/batch = 18.1236s	
20271/33150 (epoch 30.575), train_loss = 0.88774458, grad/param norm = 1.8871e-01, time/batch = 18.1861s	
20272/33150 (epoch 30.576), train_loss = 0.79851282, grad/param norm = 1.4535e-01, time/batch = 18.7909s	
20273/33150 (epoch 30.578), train_loss = 0.82564083, grad/param norm = 1.5381e-01, time/batch = 18.0486s	
20274/33150 (epoch 30.579), train_loss = 0.79059558, grad/param norm = 1.7517e-01, time/batch = 17.0408s	
20275/33150 (epoch 30.581), train_loss = 0.82056004, grad/param norm = 1.7345e-01, time/batch = 15.1256s	
20276/33150 (epoch 30.582), train_loss = 1.04208712, grad/param norm = 1.6592e-01, time/batch = 16.3056s	
20277/33150 (epoch 30.584), train_loss = 0.99286795, grad/param norm = 1.8173e-01, time/batch = 17.6997s	
20278/33150 (epoch 30.585), train_loss = 0.91263132, grad/param norm = 1.5550e-01, time/batch = 17.0650s	
20279/33150 (epoch 30.587), train_loss = 0.91802556, grad/param norm = 1.7904e-01, time/batch = 16.4646s	
20280/33150 (epoch 30.588), train_loss = 0.84229669, grad/param norm = 1.6167e-01, time/batch = 18.7673s	
20281/33150 (epoch 30.590), train_loss = 0.94350025, grad/param norm = 1.7290e-01, time/batch = 17.3816s	
20282/33150 (epoch 30.591), train_loss = 0.91080372, grad/param norm = 1.8125e-01, time/batch = 16.1282s	
20283/33150 (epoch 30.593), train_loss = 0.97592682, grad/param norm = 1.9184e-01, time/batch = 15.8759s	
20284/33150 (epoch 30.594), train_loss = 0.88482640, grad/param norm = 1.6494e-01, time/batch = 16.6404s	
20285/33150 (epoch 30.596), train_loss = 0.88733164, grad/param norm = 1.6334e-01, time/batch = 17.9742s	
20286/33150 (epoch 30.597), train_loss = 0.80392489, grad/param norm = 2.1051e-01, time/batch = 17.8871s	
20287/33150 (epoch 30.599), train_loss = 1.06505695, grad/param norm = 1.9633e-01, time/batch = 17.3783s	
20288/33150 (epoch 30.600), train_loss = 0.93190470, grad/param norm = 3.4875e-01, time/batch = 17.8856s	
20289/33150 (epoch 30.602), train_loss = 0.91104588, grad/param norm = 1.8854e-01, time/batch = 18.5432s	
20290/33150 (epoch 30.603), train_loss = 1.01723138, grad/param norm = 1.8529e-01, time/batch = 17.0622s	
20291/33150 (epoch 30.605), train_loss = 0.80680364, grad/param norm = 1.5485e-01, time/batch = 16.6341s	
20292/33150 (epoch 30.606), train_loss = 0.81472197, grad/param norm = 1.8209e-01, time/batch = 18.2195s	
20293/33150 (epoch 30.608), train_loss = 0.97515086, grad/param norm = 1.5862e-01, time/batch = 17.4744s	
20294/33150 (epoch 30.609), train_loss = 0.89599991, grad/param norm = 1.9664e-01, time/batch = 17.7100s	
20295/33150 (epoch 30.611), train_loss = 0.79437571, grad/param norm = 1.5578e-01, time/batch = 17.4647s	
20296/33150 (epoch 30.612), train_loss = 0.89737305, grad/param norm = 1.6756e-01, time/batch = 18.3742s	
20297/33150 (epoch 30.614), train_loss = 0.80837901, grad/param norm = 1.4965e-01, time/batch = 18.3087s	
20298/33150 (epoch 30.615), train_loss = 0.81291616, grad/param norm = 1.7893e-01, time/batch = 17.0378s	
20299/33150 (epoch 30.617), train_loss = 0.94024541, grad/param norm = 2.3699e-01, time/batch = 18.3066s	
20300/33150 (epoch 30.618), train_loss = 0.95719537, grad/param norm = 1.8024e-01, time/batch = 16.8901s	
20301/33150 (epoch 30.620), train_loss = 0.86472756, grad/param norm = 1.7201e-01, time/batch = 17.5232s	
20302/33150 (epoch 30.621), train_loss = 0.89794265, grad/param norm = 1.5465e-01, time/batch = 19.4503s	
20303/33150 (epoch 30.623), train_loss = 0.96063080, grad/param norm = 1.5651e-01, time/batch = 18.8738s	
20304/33150 (epoch 30.624), train_loss = 0.86299588, grad/param norm = 1.7482e-01, time/batch = 16.5996s	
20305/33150 (epoch 30.626), train_loss = 0.89020565, grad/param norm = 1.7128e-01, time/batch = 16.3938s	
20306/33150 (epoch 30.627), train_loss = 0.82273932, grad/param norm = 1.6003e-01, time/batch = 16.7136s	
20307/33150 (epoch 30.629), train_loss = 0.77719089, grad/param norm = 1.6915e-01, time/batch = 17.3887s	
20308/33150 (epoch 30.630), train_loss = 0.88181781, grad/param norm = 1.5860e-01, time/batch = 16.5558s	
20309/33150 (epoch 30.632), train_loss = 0.78097279, grad/param norm = 1.3934e-01, time/batch = 17.3981s	
20310/33150 (epoch 30.633), train_loss = 0.79813799, grad/param norm = 1.9452e-01, time/batch = 17.9679s	
20311/33150 (epoch 30.635), train_loss = 1.04881528, grad/param norm = 1.7148e-01, time/batch = 17.2048s	
20312/33150 (epoch 30.637), train_loss = 0.73267765, grad/param norm = 1.5727e-01, time/batch = 16.7990s	
20313/33150 (epoch 30.638), train_loss = 0.86539158, grad/param norm = 1.5794e-01, time/batch = 19.3683s	
20314/33150 (epoch 30.640), train_loss = 0.96137401, grad/param norm = 1.6963e-01, time/batch = 18.0428s	
20315/33150 (epoch 30.641), train_loss = 0.77726174, grad/param norm = 1.7375e-01, time/batch = 16.8731s	
20316/33150 (epoch 30.643), train_loss = 0.89526028, grad/param norm = 1.6178e-01, time/batch = 18.6266s	
20317/33150 (epoch 30.644), train_loss = 1.05107012, grad/param norm = 1.8096e-01, time/batch = 15.6269s	
20318/33150 (epoch 30.646), train_loss = 0.85462102, grad/param norm = 1.5018e-01, time/batch = 17.1236s	
20319/33150 (epoch 30.647), train_loss = 1.07310825, grad/param norm = 1.7835e-01, time/batch = 16.2937s	
20320/33150 (epoch 30.649), train_loss = 0.96356294, grad/param norm = 1.8095e-01, time/batch = 16.9734s	
20321/33150 (epoch 30.650), train_loss = 0.82428716, grad/param norm = 1.6316e-01, time/batch = 17.4656s	
20322/33150 (epoch 30.652), train_loss = 1.01191665, grad/param norm = 1.9238e-01, time/batch = 16.3837s	
20323/33150 (epoch 30.653), train_loss = 0.93514203, grad/param norm = 1.6254e-01, time/batch = 16.9686s	
20324/33150 (epoch 30.655), train_loss = 0.92969132, grad/param norm = 1.8891e-01, time/batch = 18.1312s	
20325/33150 (epoch 30.656), train_loss = 0.87216913, grad/param norm = 1.4739e-01, time/batch = 15.7920s	
20326/33150 (epoch 30.658), train_loss = 0.88862356, grad/param norm = 1.8201e-01, time/batch = 17.6320s	
20327/33150 (epoch 30.659), train_loss = 1.19378727, grad/param norm = 3.7446e-01, time/batch = 15.9615s	
20328/33150 (epoch 30.661), train_loss = 0.91511220, grad/param norm = 1.9630e-01, time/batch = 16.8009s	
20329/33150 (epoch 30.662), train_loss = 0.86996694, grad/param norm = 1.7114e-01, time/batch = 17.3612s	
20330/33150 (epoch 30.664), train_loss = 1.02913368, grad/param norm = 2.0534e-01, time/batch = 19.1972s	
20331/33150 (epoch 30.665), train_loss = 0.98897990, grad/param norm = 1.8753e-01, time/batch = 17.1260s	
20332/33150 (epoch 30.667), train_loss = 1.00867787, grad/param norm = 1.9574e-01, time/batch = 16.7949s	
20333/33150 (epoch 30.668), train_loss = 1.04104803, grad/param norm = 1.8546e-01, time/batch = 18.7880s	
20334/33150 (epoch 30.670), train_loss = 0.84713153, grad/param norm = 1.5137e-01, time/batch = 18.0402s	
20335/33150 (epoch 30.671), train_loss = 0.86939837, grad/param norm = 1.6396e-01, time/batch = 17.5465s	
20336/33150 (epoch 30.673), train_loss = 1.01697237, grad/param norm = 1.5722e-01, time/batch = 18.0452s	
20337/33150 (epoch 30.674), train_loss = 0.98235160, grad/param norm = 1.9805e-01, time/batch = 20.0357s	
20338/33150 (epoch 30.676), train_loss = 0.91066892, grad/param norm = 1.5979e-01, time/batch = 17.4626s	
20339/33150 (epoch 30.677), train_loss = 1.04888587, grad/param norm = 1.7677e-01, time/batch = 16.3509s	
20340/33150 (epoch 30.679), train_loss = 0.90690791, grad/param norm = 1.5213e-01, time/batch = 18.7071s	
20341/33150 (epoch 30.680), train_loss = 1.02464243, grad/param norm = 1.8908e-01, time/batch = 18.0588s	
20342/33150 (epoch 30.682), train_loss = 0.89642055, grad/param norm = 1.5525e-01, time/batch = 15.8781s	
20343/33150 (epoch 30.683), train_loss = 0.78984567, grad/param norm = 1.5068e-01, time/batch = 17.7157s	
20344/33150 (epoch 30.685), train_loss = 0.87342318, grad/param norm = 1.8079e-01, time/batch = 18.3739s	
20345/33150 (epoch 30.686), train_loss = 0.79739760, grad/param norm = 1.7428e-01, time/batch = 16.6269s	
20346/33150 (epoch 30.688), train_loss = 0.81063888, grad/param norm = 1.6484e-01, time/batch = 16.2192s	
20347/33150 (epoch 30.689), train_loss = 0.81310292, grad/param norm = 1.4658e-01, time/batch = 18.9588s	
20348/33150 (epoch 30.691), train_loss = 0.73157140, grad/param norm = 1.6533e-01, time/batch = 17.3819s	
20349/33150 (epoch 30.692), train_loss = 0.80827362, grad/param norm = 1.7709e-01, time/batch = 20.1392s	
20350/33150 (epoch 30.694), train_loss = 0.71067637, grad/param norm = 1.4409e-01, time/batch = 28.9680s	
20351/33150 (epoch 30.695), train_loss = 0.85269411, grad/param norm = 1.5066e-01, time/batch = 18.1065s	
20352/33150 (epoch 30.697), train_loss = 0.77027200, grad/param norm = 1.3568e-01, time/batch = 18.7887s	
20353/33150 (epoch 30.698), train_loss = 0.79951060, grad/param norm = 1.6061e-01, time/batch = 18.2233s	
20354/33150 (epoch 30.700), train_loss = 0.69204365, grad/param norm = 1.3377e-01, time/batch = 18.7961s	
20355/33150 (epoch 30.701), train_loss = 0.78839917, grad/param norm = 1.6177e-01, time/batch = 16.2004s	
20356/33150 (epoch 30.703), train_loss = 0.88038892, grad/param norm = 1.7044e-01, time/batch = 17.6379s	
20357/33150 (epoch 30.704), train_loss = 0.77528266, grad/param norm = 1.4795e-01, time/batch = 19.1265s	
20358/33150 (epoch 30.706), train_loss = 0.84117711, grad/param norm = 1.4579e-01, time/batch = 16.1400s	
20359/33150 (epoch 30.707), train_loss = 0.84873230, grad/param norm = 1.6964e-01, time/batch = 17.9708s	
20360/33150 (epoch 30.709), train_loss = 0.88286471, grad/param norm = 1.3543e-01, time/batch = 19.2941s	
20361/33150 (epoch 30.710), train_loss = 0.87379225, grad/param norm = 1.6848e-01, time/batch = 15.1049s	
20362/33150 (epoch 30.712), train_loss = 0.94896444, grad/param norm = 1.5220e-01, time/batch = 16.8774s	
20363/33150 (epoch 30.713), train_loss = 0.92473447, grad/param norm = 1.5512e-01, time/batch = 19.1987s	
20364/33150 (epoch 30.715), train_loss = 0.85864410, grad/param norm = 1.5592e-01, time/batch = 16.4650s	
20365/33150 (epoch 30.716), train_loss = 0.93632152, grad/param norm = 1.9844e-01, time/batch = 15.3699s	
20366/33150 (epoch 30.718), train_loss = 0.90901785, grad/param norm = 1.7008e-01, time/batch = 18.2123s	
20367/33150 (epoch 30.719), train_loss = 0.99602159, grad/param norm = 2.0341e-01, time/batch = 18.5402s	
20368/33150 (epoch 30.721), train_loss = 0.86055297, grad/param norm = 1.7328e-01, time/batch = 17.7135s	
20369/33150 (epoch 30.722), train_loss = 0.91190789, grad/param norm = 1.4349e-01, time/batch = 17.4639s	
20370/33150 (epoch 30.724), train_loss = 0.87518413, grad/param norm = 1.7252e-01, time/batch = 17.0356s	
20371/33150 (epoch 30.725), train_loss = 0.97476870, grad/param norm = 2.1310e-01, time/batch = 20.6131s	
20372/33150 (epoch 30.727), train_loss = 0.95679206, grad/param norm = 1.8142e-01, time/batch = 17.5365s	
20373/33150 (epoch 30.729), train_loss = 0.88911859, grad/param norm = 1.6418e-01, time/batch = 19.0413s	
20374/33150 (epoch 30.730), train_loss = 0.89815558, grad/param norm = 1.7215e-01, time/batch = 19.5416s	
20375/33150 (epoch 30.732), train_loss = 0.96686702, grad/param norm = 1.8275e-01, time/batch = 16.7862s	
20376/33150 (epoch 30.733), train_loss = 0.75260293, grad/param norm = 1.3281e-01, time/batch = 18.5395s	
20377/33150 (epoch 30.735), train_loss = 0.82353939, grad/param norm = 1.5991e-01, time/batch = 17.3044s	
20378/33150 (epoch 30.736), train_loss = 0.86692176, grad/param norm = 1.6802e-01, time/batch = 17.7141s	
20379/33150 (epoch 30.738), train_loss = 0.89935977, grad/param norm = 1.8799e-01, time/batch = 17.1295s	
20380/33150 (epoch 30.739), train_loss = 0.98908983, grad/param norm = 1.9708e-01, time/batch = 19.8621s	
20381/33150 (epoch 30.741), train_loss = 0.96186897, grad/param norm = 1.8451e-01, time/batch = 16.8810s	
20382/33150 (epoch 30.742), train_loss = 0.76086277, grad/param norm = 1.6319e-01, time/batch = 16.1260s	
20383/33150 (epoch 30.744), train_loss = 0.97278096, grad/param norm = 1.7494e-01, time/batch = 18.0505s	
20384/33150 (epoch 30.745), train_loss = 0.85165955, grad/param norm = 1.4260e-01, time/batch = 16.3137s	
20385/33150 (epoch 30.747), train_loss = 0.67336063, grad/param norm = 1.4879e-01, time/batch = 16.8864s	
20386/33150 (epoch 30.748), train_loss = 0.77054589, grad/param norm = 1.4522e-01, time/batch = 19.5339s	
20387/33150 (epoch 30.750), train_loss = 0.92778827, grad/param norm = 1.6093e-01, time/batch = 17.4417s	
20388/33150 (epoch 30.751), train_loss = 0.88748681, grad/param norm = 1.5393e-01, time/batch = 18.6220s	
20389/33150 (epoch 30.753), train_loss = 0.76876139, grad/param norm = 1.9320e-01, time/batch = 17.4600s	
20390/33150 (epoch 30.754), train_loss = 1.08029064, grad/param norm = 2.2341e-01, time/batch = 17.9621s	
20391/33150 (epoch 30.756), train_loss = 0.90291811, grad/param norm = 1.8876e-01, time/batch = 18.2005s	
20392/33150 (epoch 30.757), train_loss = 0.90934289, grad/param norm = 1.6905e-01, time/batch = 17.8745s	
20393/33150 (epoch 30.759), train_loss = 1.02275245, grad/param norm = 1.9768e-01, time/batch = 18.6995s	
20394/33150 (epoch 30.760), train_loss = 0.94748831, grad/param norm = 1.7817e-01, time/batch = 17.9619s	
20395/33150 (epoch 30.762), train_loss = 0.91701753, grad/param norm = 1.8133e-01, time/batch = 15.6214s	
20396/33150 (epoch 30.763), train_loss = 0.93594934, grad/param norm = 1.7404e-01, time/batch = 17.4623s	
20397/33150 (epoch 30.765), train_loss = 0.87211316, grad/param norm = 1.5362e-01, time/batch = 18.3766s	
20398/33150 (epoch 30.766), train_loss = 0.80442835, grad/param norm = 1.5590e-01, time/batch = 17.3801s	
20399/33150 (epoch 30.768), train_loss = 0.81859670, grad/param norm = 1.5077e-01, time/batch = 16.1910s	
20400/33150 (epoch 30.769), train_loss = 0.94718734, grad/param norm = 1.6151e-01, time/batch = 18.3804s	
20401/33150 (epoch 30.771), train_loss = 0.91228931, grad/param norm = 1.6854e-01, time/batch = 18.0547s	
20402/33150 (epoch 30.772), train_loss = 0.95355667, grad/param norm = 1.9423e-01, time/batch = 17.8790s	
20403/33150 (epoch 30.774), train_loss = 1.04058545, grad/param norm = 1.7634e-01, time/batch = 18.3830s	
20404/33150 (epoch 30.775), train_loss = 0.96407260, grad/param norm = 2.2005e-01, time/batch = 16.2985s	
20405/33150 (epoch 30.777), train_loss = 0.97588760, grad/param norm = 1.7502e-01, time/batch = 17.0344s	
20406/33150 (epoch 30.778), train_loss = 0.90365609, grad/param norm = 1.5788e-01, time/batch = 17.7116s	
20407/33150 (epoch 30.780), train_loss = 0.77582299, grad/param norm = 1.5319e-01, time/batch = 19.4606s	
20408/33150 (epoch 30.781), train_loss = 0.90782943, grad/param norm = 1.6602e-01, time/batch = 16.6509s	
20409/33150 (epoch 30.783), train_loss = 0.91292584, grad/param norm = 1.5938e-01, time/batch = 16.7023s	
20410/33150 (epoch 30.784), train_loss = 0.90515934, grad/param norm = 1.7209e-01, time/batch = 19.0460s	
20411/33150 (epoch 30.786), train_loss = 0.88802237, grad/param norm = 1.7383e-01, time/batch = 17.4660s	
20412/33150 (epoch 30.787), train_loss = 0.83644588, grad/param norm = 1.5320e-01, time/batch = 16.8132s	
20413/33150 (epoch 30.789), train_loss = 0.76029435, grad/param norm = 1.5409e-01, time/batch = 16.3130s	
20414/33150 (epoch 30.790), train_loss = 0.78775982, grad/param norm = 1.7164e-01, time/batch = 19.4580s	
20415/33150 (epoch 30.792), train_loss = 0.92972579, grad/param norm = 1.9975e-01, time/batch = 17.6329s	
20416/33150 (epoch 30.793), train_loss = 0.85988866, grad/param norm = 1.8186e-01, time/batch = 15.9592s	
20417/33150 (epoch 30.795), train_loss = 0.83992295, grad/param norm = 1.8663e-01, time/batch = 18.3081s	
20418/33150 (epoch 30.796), train_loss = 0.85728327, grad/param norm = 1.3793e-01, time/batch = 16.9658s	
20419/33150 (epoch 30.798), train_loss = 0.83501702, grad/param norm = 1.4152e-01, time/batch = 16.5339s	
20420/33150 (epoch 30.799), train_loss = 0.74993776, grad/param norm = 1.8394e-01, time/batch = 18.7174s	
20421/33150 (epoch 30.801), train_loss = 0.90423946, grad/param norm = 1.8722e-01, time/batch = 16.8897s	
20422/33150 (epoch 30.802), train_loss = 0.84341192, grad/param norm = 1.7442e-01, time/batch = 17.8696s	
20423/33150 (epoch 30.804), train_loss = 0.86140644, grad/param norm = 1.5455e-01, time/batch = 19.2730s	
20424/33150 (epoch 30.805), train_loss = 0.84992188, grad/param norm = 1.9376e-01, time/batch = 18.9489s	
20425/33150 (epoch 30.807), train_loss = 0.85347898, grad/param norm = 1.4931e-01, time/batch = 18.2889s	
20426/33150 (epoch 30.808), train_loss = 0.97882522, grad/param norm = 1.6685e-01, time/batch = 17.0633s	
20427/33150 (epoch 30.810), train_loss = 0.81679500, grad/param norm = 1.7559e-01, time/batch = 19.0372s	
20428/33150 (epoch 30.811), train_loss = 0.93793334, grad/param norm = 1.9126e-01, time/batch = 16.3833s	
20429/33150 (epoch 30.813), train_loss = 0.86861809, grad/param norm = 1.6643e-01, time/batch = 17.0456s	
20430/33150 (epoch 30.814), train_loss = 0.84953243, grad/param norm = 2.0903e-01, time/batch = 17.3891s	
20431/33150 (epoch 30.816), train_loss = 0.86552037, grad/param norm = 1.8015e-01, time/batch = 18.6090s	
20432/33150 (epoch 30.817), train_loss = 0.95464008, grad/param norm = 1.7296e-01, time/batch = 18.0457s	
20433/33150 (epoch 30.819), train_loss = 0.91008357, grad/param norm = 1.7444e-01, time/batch = 16.9438s	
20434/33150 (epoch 30.821), train_loss = 0.79309927, grad/param norm = 1.5137e-01, time/batch = 18.7874s	
20435/33150 (epoch 30.822), train_loss = 0.83357092, grad/param norm = 1.6810e-01, time/batch = 18.3690s	
20436/33150 (epoch 30.824), train_loss = 0.87493355, grad/param norm = 1.5887e-01, time/batch = 19.4378s	
20437/33150 (epoch 30.825), train_loss = 0.90038675, grad/param norm = 1.6993e-01, time/batch = 17.3897s	
20438/33150 (epoch 30.827), train_loss = 0.94153305, grad/param norm = 1.9635e-01, time/batch = 17.6025s	
20439/33150 (epoch 30.828), train_loss = 0.79614212, grad/param norm = 1.5856e-01, time/batch = 17.8486s	
20440/33150 (epoch 30.830), train_loss = 0.96624002, grad/param norm = 1.9834e-01, time/batch = 17.8934s	
20441/33150 (epoch 30.831), train_loss = 0.82188780, grad/param norm = 1.5906e-01, time/batch = 19.3635s	
20442/33150 (epoch 30.833), train_loss = 0.81227320, grad/param norm = 1.6947e-01, time/batch = 16.5661s	
20443/33150 (epoch 30.834), train_loss = 0.96583783, grad/param norm = 1.5775e-01, time/batch = 17.1479s	
20444/33150 (epoch 30.836), train_loss = 0.99949999, grad/param norm = 1.5356e-01, time/batch = 18.2982s	
20445/33150 (epoch 30.837), train_loss = 0.83397782, grad/param norm = 1.6263e-01, time/batch = 16.8802s	
20446/33150 (epoch 30.839), train_loss = 0.94937218, grad/param norm = 1.6568e-01, time/batch = 16.6464s	
20447/33150 (epoch 30.840), train_loss = 0.95044952, grad/param norm = 1.5980e-01, time/batch = 19.2081s	
20448/33150 (epoch 30.842), train_loss = 1.00213448, grad/param norm = 1.8956e-01, time/batch = 19.1215s	
20449/33150 (epoch 30.843), train_loss = 0.99362983, grad/param norm = 1.8783e-01, time/batch = 16.3732s	
20450/33150 (epoch 30.845), train_loss = 0.82274366, grad/param norm = 1.6298e-01, time/batch = 16.3095s	
20451/33150 (epoch 30.846), train_loss = 1.09055065, grad/param norm = 2.2440e-01, time/batch = 17.2168s	
20452/33150 (epoch 30.848), train_loss = 0.98291690, grad/param norm = 1.8379e-01, time/batch = 16.9681s	
20453/33150 (epoch 30.849), train_loss = 1.00517976, grad/param norm = 1.6862e-01, time/batch = 16.0523s	
20454/33150 (epoch 30.851), train_loss = 0.94828166, grad/param norm = 1.8162e-01, time/batch = 16.6035s	
20455/33150 (epoch 30.852), train_loss = 1.01306395, grad/param norm = 1.5724e-01, time/batch = 19.0469s	
20456/33150 (epoch 30.854), train_loss = 0.93020056, grad/param norm = 1.8891e-01, time/batch = 15.9723s	
20457/33150 (epoch 30.855), train_loss = 0.79404238, grad/param norm = 1.7064e-01, time/batch = 16.8779s	
20458/33150 (epoch 30.857), train_loss = 0.75081905, grad/param norm = 1.5430e-01, time/batch = 20.5252s	
20459/33150 (epoch 30.858), train_loss = 0.84956233, grad/param norm = 1.4606e-01, time/batch = 17.4591s	
20460/33150 (epoch 30.860), train_loss = 0.81398312, grad/param norm = 1.6398e-01, time/batch = 17.7074s	
20461/33150 (epoch 30.861), train_loss = 0.79775435, grad/param norm = 1.4851e-01, time/batch = 19.7087s	
20462/33150 (epoch 30.863), train_loss = 0.87509391, grad/param norm = 1.4925e-01, time/batch = 17.8779s	
20463/33150 (epoch 30.864), train_loss = 0.91554487, grad/param norm = 1.5991e-01, time/batch = 18.8569s	
20464/33150 (epoch 30.866), train_loss = 0.96171022, grad/param norm = 1.9046e-01, time/batch = 18.9491s	
20465/33150 (epoch 30.867), train_loss = 0.94521396, grad/param norm = 1.5823e-01, time/batch = 17.7068s	
20466/33150 (epoch 30.869), train_loss = 0.92287797, grad/param norm = 1.8184e-01, time/batch = 16.2785s	
20467/33150 (epoch 30.870), train_loss = 0.85325665, grad/param norm = 2.0624e-01, time/batch = 17.2773s	
20468/33150 (epoch 30.872), train_loss = 0.91739459, grad/param norm = 1.6398e-01, time/batch = 17.9648s	
20469/33150 (epoch 30.873), train_loss = 0.74258435, grad/param norm = 1.3484e-01, time/batch = 17.8733s	
20470/33150 (epoch 30.875), train_loss = 1.00560341, grad/param norm = 1.6315e-01, time/batch = 18.3459s	
20471/33150 (epoch 30.876), train_loss = 0.75330190, grad/param norm = 1.6304e-01, time/batch = 20.1041s	
20472/33150 (epoch 30.878), train_loss = 0.82538150, grad/param norm = 1.5194e-01, time/batch = 17.6170s	
20473/33150 (epoch 30.879), train_loss = 0.83182407, grad/param norm = 1.4242e-01, time/batch = 18.7780s	
20474/33150 (epoch 30.881), train_loss = 0.80782985, grad/param norm = 1.5753e-01, time/batch = 19.2845s	
20475/33150 (epoch 30.882), train_loss = 0.71452311, grad/param norm = 1.3763e-01, time/batch = 18.8747s	
20476/33150 (epoch 30.884), train_loss = 0.84988619, grad/param norm = 1.4438e-01, time/batch = 17.2834s	
20477/33150 (epoch 30.885), train_loss = 0.67767899, grad/param norm = 1.5837e-01, time/batch = 17.7087s	
20478/33150 (epoch 30.887), train_loss = 0.98975609, grad/param norm = 1.8248e-01, time/batch = 18.1142s	
20479/33150 (epoch 30.888), train_loss = 0.92321972, grad/param norm = 1.8571e-01, time/batch = 17.1380s	
20480/33150 (epoch 30.890), train_loss = 0.83184265, grad/param norm = 1.6883e-01, time/batch = 17.3962s	
20481/33150 (epoch 30.891), train_loss = 0.79129359, grad/param norm = 1.4678e-01, time/batch = 18.9558s	
20482/33150 (epoch 30.893), train_loss = 0.94101258, grad/param norm = 1.7898e-01, time/batch = 17.2929s	
20483/33150 (epoch 30.894), train_loss = 0.91825170, grad/param norm = 1.5019e-01, time/batch = 15.8703s	
20484/33150 (epoch 30.896), train_loss = 0.87492931, grad/param norm = 1.5225e-01, time/batch = 16.9550s	
20485/33150 (epoch 30.897), train_loss = 0.91955657, grad/param norm = 1.5116e-01, time/batch = 17.7135s	
20486/33150 (epoch 30.899), train_loss = 0.74890484, grad/param norm = 1.7531e-01, time/batch = 16.9539s	
20487/33150 (epoch 30.900), train_loss = 1.06615258, grad/param norm = 1.8749e-01, time/batch = 16.1505s	
20488/33150 (epoch 30.902), train_loss = 1.08793365, grad/param norm = 1.7623e-01, time/batch = 19.1925s	
20489/33150 (epoch 30.903), train_loss = 0.90633302, grad/param norm = 1.7657e-01, time/batch = 17.2984s	
20490/33150 (epoch 30.905), train_loss = 0.90385041, grad/param norm = 1.5369e-01, time/batch = 17.8092s	
20491/33150 (epoch 30.906), train_loss = 0.90907134, grad/param norm = 1.7828e-01, time/batch = 17.2823s	
20492/33150 (epoch 30.908), train_loss = 0.99103945, grad/param norm = 1.7734e-01, time/batch = 19.2896s	
20493/33150 (epoch 30.910), train_loss = 0.96780482, grad/param norm = 1.7200e-01, time/batch = 17.3808s	
20494/33150 (epoch 30.911), train_loss = 0.77130832, grad/param norm = 1.4640e-01, time/batch = 18.5460s	
20495/33150 (epoch 30.913), train_loss = 0.82413025, grad/param norm = 1.5774e-01, time/batch = 20.7034s	
20496/33150 (epoch 30.914), train_loss = 0.93897172, grad/param norm = 1.7054e-01, time/batch = 17.4549s	
20497/33150 (epoch 30.916), train_loss = 0.83689781, grad/param norm = 1.7659e-01, time/batch = 19.7887s	
20498/33150 (epoch 30.917), train_loss = 0.95273323, grad/param norm = 1.9017e-01, time/batch = 18.0382s	
20499/33150 (epoch 30.919), train_loss = 1.01751872, grad/param norm = 2.1470e-01, time/batch = 16.8652s	
20500/33150 (epoch 30.920), train_loss = 0.98168287, grad/param norm = 1.7788e-01, time/batch = 18.2943s	
20501/33150 (epoch 30.922), train_loss = 1.04762242, grad/param norm = 1.9201e-01, time/batch = 16.6277s	
20502/33150 (epoch 30.923), train_loss = 0.91056010, grad/param norm = 1.9872e-01, time/batch = 16.9681s	
20503/33150 (epoch 30.925), train_loss = 0.99623490, grad/param norm = 1.7110e-01, time/batch = 15.7881s	
20504/33150 (epoch 30.926), train_loss = 0.87105489, grad/param norm = 1.6084e-01, time/batch = 19.7977s	
20505/33150 (epoch 30.928), train_loss = 0.86388878, grad/param norm = 1.8179e-01, time/batch = 16.2252s	
20506/33150 (epoch 30.929), train_loss = 0.95423302, grad/param norm = 1.6327e-01, time/batch = 16.1392s	
20507/33150 (epoch 30.931), train_loss = 1.04519701, grad/param norm = 2.0206e-01, time/batch = 18.1228s	
20508/33150 (epoch 30.932), train_loss = 0.92269206, grad/param norm = 1.7302e-01, time/batch = 18.8035s	
20509/33150 (epoch 30.934), train_loss = 0.94105750, grad/param norm = 1.6176e-01, time/batch = 16.6963s	
20510/33150 (epoch 30.935), train_loss = 0.99116800, grad/param norm = 1.7148e-01, time/batch = 15.7301s	
20511/33150 (epoch 30.937), train_loss = 1.02439421, grad/param norm = 1.7996e-01, time/batch = 18.5464s	
20512/33150 (epoch 30.938), train_loss = 0.95268644, grad/param norm = 1.8470e-01, time/batch = 18.8089s	
20513/33150 (epoch 30.940), train_loss = 1.14250888, grad/param norm = 1.9638e-01, time/batch = 16.8646s	
20514/33150 (epoch 30.941), train_loss = 0.92352089, grad/param norm = 1.4591e-01, time/batch = 18.0551s	
20515/33150 (epoch 30.943), train_loss = 0.76226912, grad/param norm = 1.6848e-01, time/batch = 17.4792s	
20516/33150 (epoch 30.944), train_loss = 0.97189682, grad/param norm = 1.7149e-01, time/batch = 16.3645s	
20517/33150 (epoch 30.946), train_loss = 0.77850059, grad/param norm = 1.3160e-01, time/batch = 15.7965s	
20518/33150 (epoch 30.947), train_loss = 0.94452636, grad/param norm = 2.0996e-01, time/batch = 16.7246s	
20519/33150 (epoch 30.949), train_loss = 0.99785622, grad/param norm = 1.6267e-01, time/batch = 16.6497s	
20520/33150 (epoch 30.950), train_loss = 0.95017108, grad/param norm = 1.7300e-01, time/batch = 15.2800s	
20521/33150 (epoch 30.952), train_loss = 0.84233259, grad/param norm = 1.7004e-01, time/batch = 16.7242s	
20522/33150 (epoch 30.953), train_loss = 0.86605477, grad/param norm = 1.5185e-01, time/batch = 17.5626s	
20523/33150 (epoch 30.955), train_loss = 0.79898282, grad/param norm = 1.9946e-01, time/batch = 16.3876s	
20524/33150 (epoch 30.956), train_loss = 0.97208073, grad/param norm = 1.5375e-01, time/batch = 16.9698s	
20525/33150 (epoch 30.958), train_loss = 0.80357257, grad/param norm = 1.4882e-01, time/batch = 18.4576s	
20526/33150 (epoch 30.959), train_loss = 0.86384338, grad/param norm = 1.4856e-01, time/batch = 16.8070s	
20527/33150 (epoch 30.961), train_loss = 0.84342269, grad/param norm = 1.7527e-01, time/batch = 15.8884s	
20528/33150 (epoch 30.962), train_loss = 0.78755527, grad/param norm = 1.6372e-01, time/batch = 18.5435s	
20529/33150 (epoch 30.964), train_loss = 0.90956462, grad/param norm = 1.6480e-01, time/batch = 16.4639s	
20530/33150 (epoch 30.965), train_loss = 0.87300284, grad/param norm = 1.6266e-01, time/batch = 16.3687s	
20531/33150 (epoch 30.967), train_loss = 0.86526262, grad/param norm = 1.6771e-01, time/batch = 17.4555s	
20532/33150 (epoch 30.968), train_loss = 0.74753592, grad/param norm = 1.2927e-01, time/batch = 17.2353s	
20533/33150 (epoch 30.970), train_loss = 0.83144162, grad/param norm = 1.5009e-01, time/batch = 17.8873s	
20534/33150 (epoch 30.971), train_loss = 0.90044782, grad/param norm = 1.7210e-01, time/batch = 16.4614s	
20535/33150 (epoch 30.973), train_loss = 0.97972112, grad/param norm = 1.5862e-01, time/batch = 18.8797s	
20536/33150 (epoch 30.974), train_loss = 1.02158124, grad/param norm = 1.8118e-01, time/batch = 17.1883s	
20537/33150 (epoch 30.976), train_loss = 0.99063225, grad/param norm = 1.5237e-01, time/batch = 16.1808s	
20538/33150 (epoch 30.977), train_loss = 1.02396602, grad/param norm = 1.6673e-01, time/batch = 17.0384s	
20539/33150 (epoch 30.979), train_loss = 0.98632498, grad/param norm = 1.9989e-01, time/batch = 18.7043s	
20540/33150 (epoch 30.980), train_loss = 1.03313856, grad/param norm = 1.7667e-01, time/batch = 18.0399s	
20541/33150 (epoch 30.982), train_loss = 0.91014411, grad/param norm = 1.8330e-01, time/batch = 18.4577s	
20542/33150 (epoch 30.983), train_loss = 0.81584437, grad/param norm = 1.6441e-01, time/batch = 19.1278s	
20543/33150 (epoch 30.985), train_loss = 1.01414732, grad/param norm = 1.7531e-01, time/batch = 17.8771s	
20544/33150 (epoch 30.986), train_loss = 0.75381783, grad/param norm = 1.4517e-01, time/batch = 16.3748s	
20545/33150 (epoch 30.988), train_loss = 0.85635916, grad/param norm = 2.0713e-01, time/batch = 16.8848s	
20546/33150 (epoch 30.989), train_loss = 0.87032146, grad/param norm = 1.7267e-01, time/batch = 17.7984s	
20547/33150 (epoch 30.991), train_loss = 0.95082371, grad/param norm = 2.3200e-01, time/batch = 17.4703s	
20548/33150 (epoch 30.992), train_loss = 0.87629412, grad/param norm = 1.7042e-01, time/batch = 15.9525s	
20549/33150 (epoch 30.994), train_loss = 0.92140367, grad/param norm = 1.7310e-01, time/batch = 15.4417s	
20550/33150 (epoch 30.995), train_loss = 0.86409545, grad/param norm = 1.6564e-01, time/batch = 15.4738s	
20551/33150 (epoch 30.997), train_loss = 0.89260870, grad/param norm = 1.7234e-01, time/batch = 20.3054s	
20552/33150 (epoch 30.998), train_loss = 0.75068889, grad/param norm = 1.5827e-01, time/batch = 24.5922s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
20553/33150 (epoch 31.000), train_loss = 0.76346456, grad/param norm = 1.9590e-01, time/batch = 16.8747s	
20554/33150 (epoch 31.002), train_loss = 1.20474881, grad/param norm = 1.8938e-01, time/batch = 15.7024s	
20555/33150 (epoch 31.003), train_loss = 0.80535247, grad/param norm = 1.8254e-01, time/batch = 16.9784s	
20556/33150 (epoch 31.005), train_loss = 0.76641456, grad/param norm = 1.4445e-01, time/batch = 18.8135s	
20557/33150 (epoch 31.006), train_loss = 0.76455681, grad/param norm = 1.5979e-01, time/batch = 16.0845s	
20558/33150 (epoch 31.008), train_loss = 0.95541677, grad/param norm = 1.7210e-01, time/batch = 16.4709s	
20559/33150 (epoch 31.009), train_loss = 0.92940529, grad/param norm = 1.5745e-01, time/batch = 15.9044s	
20560/33150 (epoch 31.011), train_loss = 0.99471478, grad/param norm = 1.7832e-01, time/batch = 18.3095s	
20561/33150 (epoch 31.012), train_loss = 0.88066284, grad/param norm = 1.8083e-01, time/batch = 15.9655s	
20562/33150 (epoch 31.014), train_loss = 0.81301557, grad/param norm = 1.8909e-01, time/batch = 18.4796s	
20563/33150 (epoch 31.015), train_loss = 0.81275980, grad/param norm = 1.6422e-01, time/batch = 16.8992s	
20564/33150 (epoch 31.017), train_loss = 0.81169313, grad/param norm = 1.5203e-01, time/batch = 17.1399s	
20565/33150 (epoch 31.018), train_loss = 0.90298675, grad/param norm = 1.7314e-01, time/batch = 16.4634s	
20566/33150 (epoch 31.020), train_loss = 0.98007956, grad/param norm = 1.8440e-01, time/batch = 17.5425s	
20567/33150 (epoch 31.021), train_loss = 0.81533545, grad/param norm = 1.7629e-01, time/batch = 19.7039s	
20568/33150 (epoch 31.023), train_loss = 1.07822699, grad/param norm = 1.5919e-01, time/batch = 16.6202s	
20569/33150 (epoch 31.024), train_loss = 0.95269675, grad/param norm = 1.8905e-01, time/batch = 19.7155s	
20570/33150 (epoch 31.026), train_loss = 0.71425258, grad/param norm = 1.3844e-01, time/batch = 17.2992s	
20571/33150 (epoch 31.027), train_loss = 0.72262732, grad/param norm = 1.4119e-01, time/batch = 18.1855s	
20572/33150 (epoch 31.029), train_loss = 0.83914657, grad/param norm = 1.6143e-01, time/batch = 18.6269s	
20573/33150 (epoch 31.030), train_loss = 0.85046402, grad/param norm = 1.3871e-01, time/batch = 18.6371s	
20574/33150 (epoch 31.032), train_loss = 0.79366075, grad/param norm = 1.6486e-01, time/batch = 17.4744s	
20575/33150 (epoch 31.033), train_loss = 0.82030799, grad/param norm = 1.5193e-01, time/batch = 16.9633s	
20576/33150 (epoch 31.035), train_loss = 1.07487975, grad/param norm = 2.8085e-01, time/batch = 17.8550s	
20577/33150 (epoch 31.036), train_loss = 0.94208951, grad/param norm = 1.7144e-01, time/batch = 16.3013s	
20578/33150 (epoch 31.038), train_loss = 1.08531564, grad/param norm = 1.9792e-01, time/batch = 16.8736s	
20579/33150 (epoch 31.039), train_loss = 0.96857422, grad/param norm = 1.4777e-01, time/batch = 17.3888s	
20580/33150 (epoch 31.041), train_loss = 0.88930608, grad/param norm = 1.5664e-01, time/batch = 15.5661s	
20581/33150 (epoch 31.042), train_loss = 0.84243156, grad/param norm = 1.6865e-01, time/batch = 17.1334s	
20582/33150 (epoch 31.044), train_loss = 0.87671280, grad/param norm = 1.5351e-01, time/batch = 16.4598s	
20583/33150 (epoch 31.045), train_loss = 0.94266686, grad/param norm = 1.4438e-01, time/batch = 18.0563s	
20584/33150 (epoch 31.047), train_loss = 0.80155817, grad/param norm = 1.8551e-01, time/batch = 16.1888s	
20585/33150 (epoch 31.048), train_loss = 1.00141178, grad/param norm = 1.9745e-01, time/batch = 16.5383s	
20586/33150 (epoch 31.050), train_loss = 0.89929104, grad/param norm = 2.0996e-01, time/batch = 15.8884s	
20587/33150 (epoch 31.051), train_loss = 0.90316606, grad/param norm = 1.4894e-01, time/batch = 15.2130s	
20588/33150 (epoch 31.053), train_loss = 0.90730052, grad/param norm = 1.8316e-01, time/batch = 15.9210s	
20589/33150 (epoch 31.054), train_loss = 1.04326707, grad/param norm = 1.7106e-01, time/batch = 15.5196s	
20590/33150 (epoch 31.056), train_loss = 0.88936495, grad/param norm = 1.6160e-01, time/batch = 15.1175s	
20591/33150 (epoch 31.057), train_loss = 0.92385105, grad/param norm = 1.5448e-01, time/batch = 14.9605s	
20592/33150 (epoch 31.059), train_loss = 0.83003816, grad/param norm = 1.6419e-01, time/batch = 17.5465s	
20593/33150 (epoch 31.060), train_loss = 0.81303020, grad/param norm = 1.4290e-01, time/batch = 16.2228s	
20594/33150 (epoch 31.062), train_loss = 0.88425501, grad/param norm = 1.6254e-01, time/batch = 17.1402s	
20595/33150 (epoch 31.063), train_loss = 0.83744954, grad/param norm = 1.8372e-01, time/batch = 17.3153s	
20596/33150 (epoch 31.065), train_loss = 0.85540360, grad/param norm = 1.4566e-01, time/batch = 15.6481s	
20597/33150 (epoch 31.066), train_loss = 0.86552338, grad/param norm = 1.6500e-01, time/batch = 16.5602s	
20598/33150 (epoch 31.068), train_loss = 0.94448407, grad/param norm = 1.8268e-01, time/batch = 16.6226s	
20599/33150 (epoch 31.069), train_loss = 0.92226573, grad/param norm = 1.9669e-01, time/batch = 17.6453s	
20600/33150 (epoch 31.071), train_loss = 0.91676001, grad/param norm = 1.6914e-01, time/batch = 16.2212s	
20601/33150 (epoch 31.072), train_loss = 0.91552453, grad/param norm = 1.8429e-01, time/batch = 17.0675s	
20602/33150 (epoch 31.074), train_loss = 0.76950498, grad/param norm = 1.9854e-01, time/batch = 17.6530s	
20603/33150 (epoch 31.075), train_loss = 0.81055053, grad/param norm = 1.6951e-01, time/batch = 16.2279s	
20604/33150 (epoch 31.077), train_loss = 0.88023465, grad/param norm = 2.0803e-01, time/batch = 16.1508s	
20605/33150 (epoch 31.078), train_loss = 1.04022132, grad/param norm = 2.1462e-01, time/batch = 17.9758s	
20606/33150 (epoch 31.080), train_loss = 1.02258153, grad/param norm = 1.7313e-01, time/batch = 17.4736s	
20607/33150 (epoch 31.081), train_loss = 0.77658635, grad/param norm = 1.8678e-01, time/batch = 15.5430s	
20608/33150 (epoch 31.083), train_loss = 0.68570781, grad/param norm = 2.1228e-01, time/batch = 15.2262s	
20609/33150 (epoch 31.084), train_loss = 0.76115973, grad/param norm = 1.7546e-01, time/batch = 15.4786s	
20610/33150 (epoch 31.086), train_loss = 0.83187715, grad/param norm = 1.9552e-01, time/batch = 16.7047s	
20611/33150 (epoch 31.087), train_loss = 0.78311655, grad/param norm = 1.7757e-01, time/batch = 16.9653s	
20612/33150 (epoch 31.089), train_loss = 0.81508930, grad/param norm = 1.6203e-01, time/batch = 16.4499s	
20613/33150 (epoch 31.090), train_loss = 0.84159757, grad/param norm = 1.7499e-01, time/batch = 15.4873s	
20614/33150 (epoch 31.092), train_loss = 0.83682849, grad/param norm = 1.7623e-01, time/batch = 16.2918s	
20615/33150 (epoch 31.094), train_loss = 0.90996329, grad/param norm = 1.8259e-01, time/batch = 17.0529s	
20616/33150 (epoch 31.095), train_loss = 0.81578432, grad/param norm = 1.5382e-01, time/batch = 17.7134s	
20617/33150 (epoch 31.097), train_loss = 0.76022688, grad/param norm = 1.7225e-01, time/batch = 16.1331s	
20618/33150 (epoch 31.098), train_loss = 1.11066706, grad/param norm = 1.8605e-01, time/batch = 17.0427s	
20619/33150 (epoch 31.100), train_loss = 1.07121837, grad/param norm = 1.7745e-01, time/batch = 17.9535s	
20620/33150 (epoch 31.101), train_loss = 0.83298457, grad/param norm = 1.6275e-01, time/batch = 17.5548s	
20621/33150 (epoch 31.103), train_loss = 0.90128128, grad/param norm = 1.5352e-01, time/batch = 17.2759s	
20622/33150 (epoch 31.104), train_loss = 0.80599337, grad/param norm = 1.5928e-01, time/batch = 16.8114s	
20623/33150 (epoch 31.106), train_loss = 0.99679436, grad/param norm = 1.9221e-01, time/batch = 17.3937s	
20624/33150 (epoch 31.107), train_loss = 1.07850489, grad/param norm = 1.9084e-01, time/batch = 17.3942s	
20625/33150 (epoch 31.109), train_loss = 0.87124529, grad/param norm = 1.3149e-01, time/batch = 15.8680s	
20626/33150 (epoch 31.110), train_loss = 1.00928883, grad/param norm = 1.7855e-01, time/batch = 19.1304s	
20627/33150 (epoch 31.112), train_loss = 0.82126047, grad/param norm = 1.8654e-01, time/batch = 18.1359s	
20628/33150 (epoch 31.113), train_loss = 0.86150843, grad/param norm = 1.9125e-01, time/batch = 15.8702s	
20629/33150 (epoch 31.115), train_loss = 1.07687958, grad/param norm = 2.2409e-01, time/batch = 17.6345s	
20630/33150 (epoch 31.116), train_loss = 0.92145561, grad/param norm = 1.7741e-01, time/batch = 17.1124s	
20631/33150 (epoch 31.118), train_loss = 0.92964279, grad/param norm = 2.0100e-01, time/batch = 18.3780s	
20632/33150 (epoch 31.119), train_loss = 0.96911844, grad/param norm = 2.5826e-01, time/batch = 16.3000s	
20633/33150 (epoch 31.121), train_loss = 0.86873416, grad/param norm = 1.6385e-01, time/batch = 16.8793s	
20634/33150 (epoch 31.122), train_loss = 1.06939008, grad/param norm = 2.4816e-01, time/batch = 17.2093s	
20635/33150 (epoch 31.124), train_loss = 0.77089568, grad/param norm = 1.4262e-01, time/batch = 16.9591s	
20636/33150 (epoch 31.125), train_loss = 1.00053144, grad/param norm = 1.7091e-01, time/batch = 18.1410s	
20637/33150 (epoch 31.127), train_loss = 0.89988754, grad/param norm = 1.5963e-01, time/batch = 17.7119s	
20638/33150 (epoch 31.128), train_loss = 0.94306448, grad/param norm = 1.7174e-01, time/batch = 18.6191s	
20639/33150 (epoch 31.130), train_loss = 0.91010913, grad/param norm = 1.8809e-01, time/batch = 15.5491s	
20640/33150 (epoch 31.131), train_loss = 1.09671925, grad/param norm = 1.7428e-01, time/batch = 18.6906s	
20641/33150 (epoch 31.133), train_loss = 0.83149862, grad/param norm = 1.6423e-01, time/batch = 18.1379s	
20642/33150 (epoch 31.134), train_loss = 1.03137671, grad/param norm = 1.8196e-01, time/batch = 15.8734s	
20643/33150 (epoch 31.136), train_loss = 0.90937507, grad/param norm = 1.9517e-01, time/batch = 17.3839s	
20644/33150 (epoch 31.137), train_loss = 0.98577711, grad/param norm = 1.7036e-01, time/batch = 17.0517s	
20645/33150 (epoch 31.139), train_loss = 0.95552823, grad/param norm = 1.7546e-01, time/batch = 16.1182s	
20646/33150 (epoch 31.140), train_loss = 1.07358649, grad/param norm = 1.7848e-01, time/batch = 16.8210s	
20647/33150 (epoch 31.142), train_loss = 0.98111985, grad/param norm = 1.8781e-01, time/batch = 18.6312s	
20648/33150 (epoch 31.143), train_loss = 0.90185838, grad/param norm = 1.7959e-01, time/batch = 18.3022s	
20649/33150 (epoch 31.145), train_loss = 0.87998867, grad/param norm = 1.6802e-01, time/batch = 16.7262s	
20650/33150 (epoch 31.146), train_loss = 0.98939394, grad/param norm = 2.1080e-01, time/batch = 18.6273s	
20651/33150 (epoch 31.148), train_loss = 1.03653248, grad/param norm = 1.6949e-01, time/batch = 20.3650s	
20652/33150 (epoch 31.149), train_loss = 0.95267217, grad/param norm = 1.8878e-01, time/batch = 16.8033s	
20653/33150 (epoch 31.151), train_loss = 1.07659542, grad/param norm = 1.9019e-01, time/batch = 16.6511s	
20654/33150 (epoch 31.152), train_loss = 0.84767924, grad/param norm = 1.4844e-01, time/batch = 18.6994s	
20655/33150 (epoch 31.154), train_loss = 0.85701491, grad/param norm = 1.7904e-01, time/batch = 17.2924s	
20656/33150 (epoch 31.155), train_loss = 0.74716325, grad/param norm = 1.4786e-01, time/batch = 14.8655s	
20657/33150 (epoch 31.157), train_loss = 0.86947852, grad/param norm = 1.7396e-01, time/batch = 14.4115s	
20658/33150 (epoch 31.158), train_loss = 0.85189523, grad/param norm = 1.5040e-01, time/batch = 15.0022s	
20659/33150 (epoch 31.160), train_loss = 0.97881181, grad/param norm = 1.7071e-01, time/batch = 14.4125s	
20660/33150 (epoch 31.161), train_loss = 0.84233611, grad/param norm = 1.8437e-01, time/batch = 15.0451s	
20661/33150 (epoch 31.163), train_loss = 0.78061475, grad/param norm = 1.5481e-01, time/batch = 14.5727s	
20662/33150 (epoch 31.164), train_loss = 0.93493294, grad/param norm = 1.7192e-01, time/batch = 14.3502s	
20663/33150 (epoch 31.166), train_loss = 0.87843892, grad/param norm = 1.6697e-01, time/batch = 14.3381s	
20664/33150 (epoch 31.167), train_loss = 0.93106449, grad/param norm = 1.5798e-01, time/batch = 15.2100s	
20665/33150 (epoch 31.169), train_loss = 0.93688474, grad/param norm = 1.9428e-01, time/batch = 15.0536s	
20666/33150 (epoch 31.170), train_loss = 0.84810521, grad/param norm = 1.8973e-01, time/batch = 14.3408s	
20667/33150 (epoch 31.172), train_loss = 0.97111728, grad/param norm = 1.9573e-01, time/batch = 14.2608s	
20668/33150 (epoch 31.173), train_loss = 0.95118125, grad/param norm = 1.8543e-01, time/batch = 14.7281s	
20669/33150 (epoch 31.175), train_loss = 0.87389576, grad/param norm = 1.8335e-01, time/batch = 14.1002s	
20670/33150 (epoch 31.176), train_loss = 0.97316383, grad/param norm = 1.8490e-01, time/batch = 14.0959s	
20671/33150 (epoch 31.178), train_loss = 1.09931786, grad/param norm = 2.0245e-01, time/batch = 14.2599s	
20672/33150 (epoch 31.179), train_loss = 0.96541184, grad/param norm = 1.6110e-01, time/batch = 14.6573s	
20673/33150 (epoch 31.181), train_loss = 0.91788669, grad/param norm = 1.8798e-01, time/batch = 14.5827s	
20674/33150 (epoch 31.183), train_loss = 0.91534758, grad/param norm = 2.0658e-01, time/batch = 14.5031s	
20675/33150 (epoch 31.184), train_loss = 1.14705005, grad/param norm = 1.9264e-01, time/batch = 14.5832s	
20676/33150 (epoch 31.186), train_loss = 1.05167688, grad/param norm = 1.7768e-01, time/batch = 14.8920s	
20677/33150 (epoch 31.187), train_loss = 0.92065272, grad/param norm = 1.8627e-01, time/batch = 14.5010s	
20678/33150 (epoch 31.189), train_loss = 0.72651439, grad/param norm = 1.8193e-01, time/batch = 14.7894s	
20679/33150 (epoch 31.190), train_loss = 0.80981577, grad/param norm = 1.7095e-01, time/batch = 14.7812s	
20680/33150 (epoch 31.192), train_loss = 0.93198437, grad/param norm = 1.8283e-01, time/batch = 14.4803s	
20681/33150 (epoch 31.193), train_loss = 0.98162014, grad/param norm = 1.7084e-01, time/batch = 14.9830s	
20682/33150 (epoch 31.195), train_loss = 1.11343186, grad/param norm = 2.0131e-01, time/batch = 14.2522s	
20683/33150 (epoch 31.196), train_loss = 1.02619288, grad/param norm = 1.6606e-01, time/batch = 15.0715s	
20684/33150 (epoch 31.198), train_loss = 0.79443293, grad/param norm = 1.5931e-01, time/batch = 16.7934s	
20685/33150 (epoch 31.199), train_loss = 0.97764721, grad/param norm = 1.9331e-01, time/batch = 18.4624s	
20686/33150 (epoch 31.201), train_loss = 0.85261888, grad/param norm = 1.4964e-01, time/batch = 15.8180s	
20687/33150 (epoch 31.202), train_loss = 0.72639872, grad/param norm = 1.4360e-01, time/batch = 17.1309s	
20688/33150 (epoch 31.204), train_loss = 0.97955536, grad/param norm = 1.8611e-01, time/batch = 16.3274s	
20689/33150 (epoch 31.205), train_loss = 0.95207968, grad/param norm = 1.8344e-01, time/batch = 16.3915s	
20690/33150 (epoch 31.207), train_loss = 0.95021489, grad/param norm = 1.6607e-01, time/batch = 17.1878s	
20691/33150 (epoch 31.208), train_loss = 0.98298211, grad/param norm = 1.6370e-01, time/batch = 16.2890s	
20692/33150 (epoch 31.210), train_loss = 0.86595314, grad/param norm = 1.6616e-01, time/batch = 18.6429s	
20693/33150 (epoch 31.211), train_loss = 0.93180236, grad/param norm = 1.8701e-01, time/batch = 19.5563s	
20694/33150 (epoch 31.213), train_loss = 0.98161425, grad/param norm = 1.6569e-01, time/batch = 17.1309s	
20695/33150 (epoch 31.214), train_loss = 0.87701550, grad/param norm = 1.7218e-01, time/batch = 16.9696s	
20696/33150 (epoch 31.216), train_loss = 0.84111435, grad/param norm = 2.0046e-01, time/batch = 16.9155s	
20697/33150 (epoch 31.217), train_loss = 0.89009003, grad/param norm = 1.6021e-01, time/batch = 19.5366s	
20698/33150 (epoch 31.219), train_loss = 0.83723273, grad/param norm = 1.5704e-01, time/batch = 15.8820s	
20699/33150 (epoch 31.220), train_loss = 0.86115225, grad/param norm = 1.4336e-01, time/batch = 16.4559s	
20700/33150 (epoch 31.222), train_loss = 1.01508417, grad/param norm = 1.7720e-01, time/batch = 16.6364s	
20701/33150 (epoch 31.223), train_loss = 0.88421837, grad/param norm = 1.6331e-01, time/batch = 15.6899s	
20702/33150 (epoch 31.225), train_loss = 1.03181627, grad/param norm = 1.6732e-01, time/batch = 16.0543s	
20703/33150 (epoch 31.226), train_loss = 0.91170741, grad/param norm = 1.9224e-01, time/batch = 17.8583s	
20704/33150 (epoch 31.228), train_loss = 0.89063606, grad/param norm = 1.9116e-01, time/batch = 18.2113s	
20705/33150 (epoch 31.229), train_loss = 0.89784602, grad/param norm = 1.7003e-01, time/batch = 16.0634s	
20706/33150 (epoch 31.231), train_loss = 1.00056710, grad/param norm = 1.7957e-01, time/batch = 17.2391s	
20707/33150 (epoch 31.232), train_loss = 0.91656350, grad/param norm = 1.9656e-01, time/batch = 16.0779s	
20708/33150 (epoch 31.234), train_loss = 0.94385717, grad/param norm = 1.7627e-01, time/batch = 15.2486s	
20709/33150 (epoch 31.235), train_loss = 0.94723276, grad/param norm = 1.6640e-01, time/batch = 15.5702s	
20710/33150 (epoch 31.237), train_loss = 0.91907073, grad/param norm = 1.8807e-01, time/batch = 18.2248s	
20711/33150 (epoch 31.238), train_loss = 0.98812296, grad/param norm = 1.8348e-01, time/batch = 16.2268s	
20712/33150 (epoch 31.240), train_loss = 0.93610510, grad/param norm = 1.5719e-01, time/batch = 15.7191s	
20713/33150 (epoch 31.241), train_loss = 0.99271976, grad/param norm = 1.8131e-01, time/batch = 16.7140s	
20714/33150 (epoch 31.243), train_loss = 0.97972508, grad/param norm = 1.8579e-01, time/batch = 16.5785s	
20715/33150 (epoch 31.244), train_loss = 0.91799760, grad/param norm = 1.6501e-01, time/batch = 17.0619s	
20716/33150 (epoch 31.246), train_loss = 0.98784040, grad/param norm = 1.7299e-01, time/batch = 15.8877s	
20717/33150 (epoch 31.247), train_loss = 0.86805862, grad/param norm = 1.6814e-01, time/batch = 17.2242s	
20718/33150 (epoch 31.249), train_loss = 1.02150867, grad/param norm = 1.6290e-01, time/batch = 15.9808s	
20719/33150 (epoch 31.250), train_loss = 0.94984172, grad/param norm = 1.5850e-01, time/batch = 16.3902s	
20720/33150 (epoch 31.252), train_loss = 0.97410794, grad/param norm = 1.5775e-01, time/batch = 16.3669s	
20721/33150 (epoch 31.253), train_loss = 0.89922379, grad/param norm = 1.8346e-01, time/batch = 18.2145s	
20722/33150 (epoch 31.255), train_loss = 0.90552633, grad/param norm = 1.5545e-01, time/batch = 18.4601s	
20723/33150 (epoch 31.256), train_loss = 1.02172732, grad/param norm = 1.7036e-01, time/batch = 16.0480s	
20724/33150 (epoch 31.258), train_loss = 0.85478814, grad/param norm = 1.7681e-01, time/batch = 17.4700s	
20725/33150 (epoch 31.259), train_loss = 0.74136791, grad/param norm = 1.5547e-01, time/batch = 16.8195s	
20726/33150 (epoch 31.261), train_loss = 0.80693644, grad/param norm = 1.4889e-01, time/batch = 15.9621s	
20727/33150 (epoch 31.262), train_loss = 1.00712030, grad/param norm = 1.8518e-01, time/batch = 16.7367s	
20728/33150 (epoch 31.264), train_loss = 0.70866744, grad/param norm = 1.3449e-01, time/batch = 17.9637s	
20729/33150 (epoch 31.265), train_loss = 0.93533035, grad/param norm = 1.7573e-01, time/batch = 16.6439s	
20730/33150 (epoch 31.267), train_loss = 0.99086593, grad/param norm = 1.8021e-01, time/batch = 16.2895s	
20731/33150 (epoch 31.268), train_loss = 1.00905347, grad/param norm = 1.6126e-01, time/batch = 17.9665s	
20732/33150 (epoch 31.270), train_loss = 1.09577934, grad/param norm = 1.6820e-01, time/batch = 15.8274s	
20733/33150 (epoch 31.271), train_loss = 1.02926644, grad/param norm = 2.1645e-01, time/batch = 17.3132s	
20734/33150 (epoch 31.273), train_loss = 1.02503720, grad/param norm = 1.6257e-01, time/batch = 15.2456s	
20735/33150 (epoch 31.275), train_loss = 1.05764827, grad/param norm = 1.8531e-01, time/batch = 15.2076s	
20736/33150 (epoch 31.276), train_loss = 0.93676311, grad/param norm = 1.7413e-01, time/batch = 16.7385s	
20737/33150 (epoch 31.278), train_loss = 1.02414738, grad/param norm = 1.6938e-01, time/batch = 16.5454s	
20738/33150 (epoch 31.279), train_loss = 0.97638143, grad/param norm = 1.5477e-01, time/batch = 15.9883s	
20739/33150 (epoch 31.281), train_loss = 0.90696982, grad/param norm = 1.6566e-01, time/batch = 17.8187s	
20740/33150 (epoch 31.282), train_loss = 0.93407034, grad/param norm = 1.3689e-01, time/batch = 16.8959s	
20741/33150 (epoch 31.284), train_loss = 0.82414529, grad/param norm = 1.5654e-01, time/batch = 16.8874s	
20742/33150 (epoch 31.285), train_loss = 0.94095560, grad/param norm = 1.6127e-01, time/batch = 17.2136s	
20743/33150 (epoch 31.287), train_loss = 0.80456006, grad/param norm = 1.5892e-01, time/batch = 17.3129s	
20744/33150 (epoch 31.288), train_loss = 1.01269915, grad/param norm = 1.6891e-01, time/batch = 15.7010s	
20745/33150 (epoch 31.290), train_loss = 0.77760025, grad/param norm = 1.4618e-01, time/batch = 17.3133s	
20746/33150 (epoch 31.291), train_loss = 0.75519000, grad/param norm = 1.5242e-01, time/batch = 19.4728s	
20747/33150 (epoch 31.293), train_loss = 0.92091970, grad/param norm = 1.7151e-01, time/batch = 18.8801s	
20748/33150 (epoch 31.294), train_loss = 0.70545241, grad/param norm = 1.3658e-01, time/batch = 18.3663s	
20749/33150 (epoch 31.296), train_loss = 0.90422231, grad/param norm = 1.4805e-01, time/batch = 17.6297s	
20750/33150 (epoch 31.297), train_loss = 0.84787665, grad/param norm = 1.5090e-01, time/batch = 17.7317s	
20751/33150 (epoch 31.299), train_loss = 0.87037719, grad/param norm = 1.9392e-01, time/batch = 15.6375s	
20752/33150 (epoch 31.300), train_loss = 0.85717414, grad/param norm = 1.3733e-01, time/batch = 17.8884s	
20753/33150 (epoch 31.302), train_loss = 0.90533768, grad/param norm = 1.8572e-01, time/batch = 16.2255s	
20754/33150 (epoch 31.303), train_loss = 0.86211861, grad/param norm = 1.6350e-01, time/batch = 17.4507s	
20755/33150 (epoch 31.305), train_loss = 0.95804967, grad/param norm = 1.5849e-01, time/batch = 18.8726s	
20756/33150 (epoch 31.306), train_loss = 0.96373101, grad/param norm = 2.1266e-01, time/batch = 18.1368s	
20757/33150 (epoch 31.308), train_loss = 1.12984940, grad/param norm = 1.8232e-01, time/batch = 18.2189s	
20758/33150 (epoch 31.309), train_loss = 0.75349995, grad/param norm = 1.3548e-01, time/batch = 17.7866s	
20759/33150 (epoch 31.311), train_loss = 0.88116054, grad/param norm = 1.7075e-01, time/batch = 18.8656s	
20760/33150 (epoch 31.312), train_loss = 0.73250802, grad/param norm = 1.5555e-01, time/batch = 18.3105s	
20761/33150 (epoch 31.314), train_loss = 0.86964964, grad/param norm = 1.7156e-01, time/batch = 17.4536s	
20762/33150 (epoch 31.315), train_loss = 0.96166406, grad/param norm = 1.6614e-01, time/batch = 18.7267s	
20763/33150 (epoch 31.317), train_loss = 0.72706793, grad/param norm = 1.4329e-01, time/batch = 20.2050s	
20764/33150 (epoch 31.318), train_loss = 0.82850011, grad/param norm = 1.4560e-01, time/batch = 20.4628s	
20765/33150 (epoch 31.320), train_loss = 0.77085999, grad/param norm = 1.5972e-01, time/batch = 24.1963s	
20766/33150 (epoch 31.321), train_loss = 0.89291902, grad/param norm = 1.5751e-01, time/batch = 19.8545s	
20767/33150 (epoch 31.323), train_loss = 0.85891724, grad/param norm = 1.7063e-01, time/batch = 15.4797s	
20768/33150 (epoch 31.324), train_loss = 0.93232718, grad/param norm = 1.9738e-01, time/batch = 16.3276s	
20769/33150 (epoch 31.326), train_loss = 0.91952680, grad/param norm = 1.5977e-01, time/batch = 16.0976s	
20770/33150 (epoch 31.327), train_loss = 0.99781512, grad/param norm = 1.6917e-01, time/batch = 15.3831s	
20771/33150 (epoch 31.329), train_loss = 0.94382787, grad/param norm = 1.6058e-01, time/batch = 15.5250s	
20772/33150 (epoch 31.330), train_loss = 0.88453311, grad/param norm = 1.6336e-01, time/batch = 15.6287s	
20773/33150 (epoch 31.332), train_loss = 0.88120434, grad/param norm = 1.6271e-01, time/batch = 16.8845s	
20774/33150 (epoch 31.333), train_loss = 0.94645892, grad/param norm = 1.4207e-01, time/batch = 17.0482s	
20775/33150 (epoch 31.335), train_loss = 0.82846136, grad/param norm = 1.4394e-01, time/batch = 16.9512s	
20776/33150 (epoch 31.336), train_loss = 0.81440826, grad/param norm = 1.7766e-01, time/batch = 17.4710s	
20777/33150 (epoch 31.338), train_loss = 0.77569503, grad/param norm = 1.9265e-01, time/batch = 17.2111s	
20778/33150 (epoch 31.339), train_loss = 0.98563556, grad/param norm = 1.8131e-01, time/batch = 16.9399s	
20779/33150 (epoch 31.341), train_loss = 0.91187906, grad/param norm = 1.8701e-01, time/batch = 17.3139s	
20780/33150 (epoch 31.342), train_loss = 0.83993866, grad/param norm = 1.6844e-01, time/batch = 16.7027s	
20781/33150 (epoch 31.344), train_loss = 0.90928248, grad/param norm = 1.7514e-01, time/batch = 17.1886s	
20782/33150 (epoch 31.345), train_loss = 0.88168369, grad/param norm = 1.6786e-01, time/batch = 17.4634s	
20783/33150 (epoch 31.347), train_loss = 0.75307779, grad/param norm = 1.6057e-01, time/batch = 17.0481s	
20784/33150 (epoch 31.348), train_loss = 0.93706986, grad/param norm = 1.7128e-01, time/batch = 18.2725s	
20785/33150 (epoch 31.350), train_loss = 0.80821817, grad/param norm = 1.6343e-01, time/batch = 16.4720s	
20786/33150 (epoch 31.351), train_loss = 0.98004851, grad/param norm = 1.7640e-01, time/batch = 17.0603s	
20787/33150 (epoch 31.353), train_loss = 0.93790511, grad/param norm = 1.8325e-01, time/batch = 15.7112s	
20788/33150 (epoch 31.354), train_loss = 1.11908366, grad/param norm = 1.7074e-01, time/batch = 16.0556s	
20789/33150 (epoch 31.356), train_loss = 0.99603007, grad/param norm = 1.8097e-01, time/batch = 15.4648s	
20790/33150 (epoch 31.357), train_loss = 0.93119185, grad/param norm = 1.8034e-01, time/batch = 16.3987s	
20791/33150 (epoch 31.359), train_loss = 0.95512866, grad/param norm = 1.6150e-01, time/batch = 17.9586s	
20792/33150 (epoch 31.360), train_loss = 0.95484640, grad/param norm = 2.0417e-01, time/batch = 16.0597s	
20793/33150 (epoch 31.362), train_loss = 1.02423433, grad/param norm = 1.8074e-01, time/batch = 16.8782s	
20794/33150 (epoch 31.363), train_loss = 0.93107498, grad/param norm = 1.6255e-01, time/batch = 15.4560s	
20795/33150 (epoch 31.365), train_loss = 0.87816065, grad/param norm = 1.4766e-01, time/batch = 16.2182s	
20796/33150 (epoch 31.367), train_loss = 0.85244115, grad/param norm = 1.5260e-01, time/batch = 15.8117s	
20797/33150 (epoch 31.368), train_loss = 0.88489501, grad/param norm = 1.8179e-01, time/batch = 18.6548s	
20798/33150 (epoch 31.370), train_loss = 0.92324649, grad/param norm = 1.7847e-01, time/batch = 17.5582s	
20799/33150 (epoch 31.371), train_loss = 0.80521845, grad/param norm = 1.5922e-01, time/batch = 15.3843s	
20800/33150 (epoch 31.373), train_loss = 0.94322587, grad/param norm = 1.8333e-01, time/batch = 16.1963s	
20801/33150 (epoch 31.374), train_loss = 0.88923198, grad/param norm = 1.5310e-01, time/batch = 17.0281s	
20802/33150 (epoch 31.376), train_loss = 0.98583229, grad/param norm = 1.6269e-01, time/batch = 17.7056s	
20803/33150 (epoch 31.377), train_loss = 0.82815592, grad/param norm = 1.6938e-01, time/batch = 16.4709s	
20804/33150 (epoch 31.379), train_loss = 0.95905278, grad/param norm = 2.0477e-01, time/batch = 18.3896s	
20805/33150 (epoch 31.380), train_loss = 0.95698099, grad/param norm = 1.5930e-01, time/batch = 16.8020s	
20806/33150 (epoch 31.382), train_loss = 0.89194139, grad/param norm = 1.6711e-01, time/batch = 16.7895s	
20807/33150 (epoch 31.383), train_loss = 0.83471862, grad/param norm = 1.6571e-01, time/batch = 16.4897s	
20808/33150 (epoch 31.385), train_loss = 0.86046184, grad/param norm = 1.7928e-01, time/batch = 17.6418s	
20809/33150 (epoch 31.386), train_loss = 0.78079910, grad/param norm = 1.4249e-01, time/batch = 18.1375s	
20810/33150 (epoch 31.388), train_loss = 0.83332642, grad/param norm = 1.6957e-01, time/batch = 16.3933s	
20811/33150 (epoch 31.389), train_loss = 0.82861813, grad/param norm = 1.4879e-01, time/batch = 16.7735s	
20812/33150 (epoch 31.391), train_loss = 1.05001339, grad/param norm = 1.8176e-01, time/batch = 19.0586s	
20813/33150 (epoch 31.392), train_loss = 0.86495468, grad/param norm = 1.7213e-01, time/batch = 16.5628s	
20814/33150 (epoch 31.394), train_loss = 0.75998456, grad/param norm = 1.3839e-01, time/batch = 17.9677s	
20815/33150 (epoch 31.395), train_loss = 0.72350893, grad/param norm = 1.4507e-01, time/batch = 18.2398s	
20816/33150 (epoch 31.397), train_loss = 0.62176916, grad/param norm = 1.3572e-01, time/batch = 18.6294s	
20817/33150 (epoch 31.398), train_loss = 0.89143464, grad/param norm = 1.6231e-01, time/batch = 17.2999s	
20818/33150 (epoch 31.400), train_loss = 0.88057950, grad/param norm = 1.4516e-01, time/batch = 17.6543s	
20819/33150 (epoch 31.401), train_loss = 0.77391743, grad/param norm = 1.3584e-01, time/batch = 19.6237s	
20820/33150 (epoch 31.403), train_loss = 0.74836111, grad/param norm = 1.2912e-01, time/batch = 16.8172s	
20821/33150 (epoch 31.404), train_loss = 0.91450993, grad/param norm = 1.6515e-01, time/batch = 18.5590s	
20822/33150 (epoch 31.406), train_loss = 0.84046354, grad/param norm = 1.2707e-01, time/batch = 17.8873s	
20823/33150 (epoch 31.407), train_loss = 0.78348752, grad/param norm = 1.4928e-01, time/batch = 16.7658s	
20824/33150 (epoch 31.409), train_loss = 0.72847612, grad/param norm = 1.3985e-01, time/batch = 17.5591s	
20825/33150 (epoch 31.410), train_loss = 0.91706331, grad/param norm = 1.6656e-01, time/batch = 19.3836s	
20826/33150 (epoch 31.412), train_loss = 0.93234287, grad/param norm = 1.5772e-01, time/batch = 17.2234s	
20827/33150 (epoch 31.413), train_loss = 0.80319234, grad/param norm = 1.6112e-01, time/batch = 17.8011s	
20828/33150 (epoch 31.415), train_loss = 0.92726582, grad/param norm = 1.6211e-01, time/batch = 18.7080s	
20829/33150 (epoch 31.416), train_loss = 0.83056177, grad/param norm = 1.5082e-01, time/batch = 18.5480s	
20830/33150 (epoch 31.418), train_loss = 0.92614073, grad/param norm = 1.8530e-01, time/batch = 17.4432s	
20831/33150 (epoch 31.419), train_loss = 0.87395445, grad/param norm = 1.5913e-01, time/batch = 19.2923s	
20832/33150 (epoch 31.421), train_loss = 0.88227302, grad/param norm = 2.0562e-01, time/batch = 19.1297s	
20833/33150 (epoch 31.422), train_loss = 0.84458434, grad/param norm = 1.6556e-01, time/batch = 16.5473s	
20834/33150 (epoch 31.424), train_loss = 0.82865804, grad/param norm = 1.6446e-01, time/batch = 17.7256s	
20835/33150 (epoch 31.425), train_loss = 0.97617490, grad/param norm = 1.6859e-01, time/batch = 17.3633s	
20836/33150 (epoch 31.427), train_loss = 0.88321228, grad/param norm = 1.5407e-01, time/batch = 17.7953s	
20837/33150 (epoch 31.428), train_loss = 0.88269746, grad/param norm = 1.6362e-01, time/batch = 16.3938s	
20838/33150 (epoch 31.430), train_loss = 0.90368760, grad/param norm = 1.5912e-01, time/batch = 18.4615s	
20839/33150 (epoch 31.431), train_loss = 0.95471573, grad/param norm = 2.0838e-01, time/batch = 16.6243s	
20840/33150 (epoch 31.433), train_loss = 0.86988417, grad/param norm = 1.6929e-01, time/batch = 16.5408s	
20841/33150 (epoch 31.434), train_loss = 0.76156120, grad/param norm = 1.4254e-01, time/batch = 18.6262s	
20842/33150 (epoch 31.436), train_loss = 0.88032321, grad/param norm = 1.5694e-01, time/batch = 20.2113s	
20843/33150 (epoch 31.437), train_loss = 0.89894753, grad/param norm = 1.7243e-01, time/batch = 16.5533s	
20844/33150 (epoch 31.439), train_loss = 1.05243051, grad/param norm = 1.7867e-01, time/batch = 16.8133s	
20845/33150 (epoch 31.440), train_loss = 0.95354681, grad/param norm = 1.7260e-01, time/batch = 19.2003s	
20846/33150 (epoch 31.442), train_loss = 0.77839905, grad/param norm = 1.6593e-01, time/batch = 17.2995s	
20847/33150 (epoch 31.443), train_loss = 0.93470827, grad/param norm = 1.7894e-01, time/batch = 17.2055s	
20848/33150 (epoch 31.445), train_loss = 0.90260504, grad/param norm = 1.7121e-01, time/batch = 18.6208s	
20849/33150 (epoch 31.446), train_loss = 0.94383820, grad/param norm = 2.1483e-01, time/batch = 19.3160s	
20850/33150 (epoch 31.448), train_loss = 1.00100576, grad/param norm = 1.6522e-01, time/batch = 16.9774s	
20851/33150 (epoch 31.449), train_loss = 0.90510836, grad/param norm = 1.5284e-01, time/batch = 17.1480s	
20852/33150 (epoch 31.451), train_loss = 0.91585783, grad/param norm = 1.9377e-01, time/batch = 17.8623s	
20853/33150 (epoch 31.452), train_loss = 1.05836883, grad/param norm = 1.7194e-01, time/batch = 18.1295s	
20854/33150 (epoch 31.454), train_loss = 0.90042286, grad/param norm = 1.8758e-01, time/batch = 18.0440s	
20855/33150 (epoch 31.456), train_loss = 0.81320489, grad/param norm = 1.5677e-01, time/batch = 15.6204s	
20856/33150 (epoch 31.457), train_loss = 0.91978427, grad/param norm = 1.6234e-01, time/batch = 17.3087s	
20857/33150 (epoch 31.459), train_loss = 1.00810209, grad/param norm = 2.7182e-01, time/batch = 16.8762s	
20858/33150 (epoch 31.460), train_loss = 0.94840472, grad/param norm = 1.4981e-01, time/batch = 19.6345s	
20859/33150 (epoch 31.462), train_loss = 0.99653762, grad/param norm = 2.4592e-01, time/batch = 16.8923s	
20860/33150 (epoch 31.463), train_loss = 1.10453614, grad/param norm = 2.1340e-01, time/batch = 17.4596s	
20861/33150 (epoch 31.465), train_loss = 0.95297619, grad/param norm = 1.6195e-01, time/batch = 19.5508s	
20862/33150 (epoch 31.466), train_loss = 0.85992666, grad/param norm = 1.5557e-01, time/batch = 17.9744s	
20863/33150 (epoch 31.468), train_loss = 1.11242168, grad/param norm = 1.8024e-01, time/batch = 17.3841s	
20864/33150 (epoch 31.469), train_loss = 0.87117563, grad/param norm = 1.7054e-01, time/batch = 18.7053s	
20865/33150 (epoch 31.471), train_loss = 0.81953137, grad/param norm = 1.4827e-01, time/batch = 18.8775s	
20866/33150 (epoch 31.472), train_loss = 0.90785342, grad/param norm = 1.6338e-01, time/batch = 17.5555s	
20867/33150 (epoch 31.474), train_loss = 0.98386388, grad/param norm = 2.2555e-01, time/batch = 17.2023s	
20868/33150 (epoch 31.475), train_loss = 1.14161851, grad/param norm = 1.9700e-01, time/batch = 17.5247s	
20869/33150 (epoch 31.477), train_loss = 1.00364210, grad/param norm = 1.8353e-01, time/batch = 17.4843s	
20870/33150 (epoch 31.478), train_loss = 0.95950656, grad/param norm = 1.5422e-01, time/batch = 17.0526s	
20871/33150 (epoch 31.480), train_loss = 0.83930782, grad/param norm = 1.5939e-01, time/batch = 18.3705s	
20872/33150 (epoch 31.481), train_loss = 0.77413568, grad/param norm = 1.9600e-01, time/batch = 19.2328s	
20873/33150 (epoch 31.483), train_loss = 0.88742226, grad/param norm = 1.8696e-01, time/batch = 17.8841s	
20874/33150 (epoch 31.484), train_loss = 0.84545203, grad/param norm = 1.6634e-01, time/batch = 17.9626s	
20875/33150 (epoch 31.486), train_loss = 0.82302986, grad/param norm = 1.6121e-01, time/batch = 18.8025s	
20876/33150 (epoch 31.487), train_loss = 0.93838511, grad/param norm = 1.7738e-01, time/batch = 18.8784s	
20877/33150 (epoch 31.489), train_loss = 0.89786610, grad/param norm = 1.7063e-01, time/batch = 18.4570s	
20878/33150 (epoch 31.490), train_loss = 0.73796813, grad/param norm = 1.3424e-01, time/batch = 18.5441s	
20879/33150 (epoch 31.492), train_loss = 0.85497588, grad/param norm = 1.8751e-01, time/batch = 18.7257s	
20880/33150 (epoch 31.493), train_loss = 0.96107154, grad/param norm = 1.6953e-01, time/batch = 17.6226s	
20881/33150 (epoch 31.495), train_loss = 0.96040009, grad/param norm = 1.5639e-01, time/batch = 18.0363s	
20882/33150 (epoch 31.496), train_loss = 0.86324983, grad/param norm = 1.5290e-01, time/batch = 20.3681s	
20883/33150 (epoch 31.498), train_loss = 1.00233633, grad/param norm = 2.0788e-01, time/batch = 16.3702s	
20884/33150 (epoch 31.499), train_loss = 1.00834138, grad/param norm = 1.7132e-01, time/batch = 19.1315s	
20885/33150 (epoch 31.501), train_loss = 0.96234728, grad/param norm = 1.8016e-01, time/batch = 17.1495s	
20886/33150 (epoch 31.502), train_loss = 1.01382885, grad/param norm = 1.9347e-01, time/batch = 18.4617s	
20887/33150 (epoch 31.504), train_loss = 0.96792720, grad/param norm = 1.8005e-01, time/batch = 17.0573s	
20888/33150 (epoch 31.505), train_loss = 1.04664532, grad/param norm = 1.8862e-01, time/batch = 18.3033s	
20889/33150 (epoch 31.507), train_loss = 0.87350891, grad/param norm = 1.8470e-01, time/batch = 19.9529s	
20890/33150 (epoch 31.508), train_loss = 0.87086015, grad/param norm = 1.7956e-01, time/batch = 16.1092s	
20891/33150 (epoch 31.510), train_loss = 0.96409535, grad/param norm = 1.4676e-01, time/batch = 18.4664s	
20892/33150 (epoch 31.511), train_loss = 1.01058761, grad/param norm = 1.6689e-01, time/batch = 19.0455s	
20893/33150 (epoch 31.513), train_loss = 0.93542473, grad/param norm = 1.7608e-01, time/batch = 16.6428s	
20894/33150 (epoch 31.514), train_loss = 0.78820791, grad/param norm = 1.5506e-01, time/batch = 18.9739s	
20895/33150 (epoch 31.516), train_loss = 0.92019856, grad/param norm = 1.9997e-01, time/batch = 15.0407s	
20896/33150 (epoch 31.517), train_loss = 0.99725659, grad/param norm = 1.7336e-01, time/batch = 16.3860s	
20897/33150 (epoch 31.519), train_loss = 0.82473498, grad/param norm = 1.4388e-01, time/batch = 17.0598s	
20898/33150 (epoch 31.520), train_loss = 0.92503649, grad/param norm = 1.5399e-01, time/batch = 16.3057s	
20899/33150 (epoch 31.522), train_loss = 0.99938301, grad/param norm = 1.8964e-01, time/batch = 17.0708s	
20900/33150 (epoch 31.523), train_loss = 0.80685300, grad/param norm = 1.6498e-01, time/batch = 16.1232s	
20901/33150 (epoch 31.525), train_loss = 0.95643764, grad/param norm = 1.7939e-01, time/batch = 19.9387s	
20902/33150 (epoch 31.526), train_loss = 0.82744357, grad/param norm = 1.5205e-01, time/batch = 18.1373s	
20903/33150 (epoch 31.528), train_loss = 0.94103186, grad/param norm = 1.7447e-01, time/batch = 17.8844s	
20904/33150 (epoch 31.529), train_loss = 0.93055070, grad/param norm = 1.9086e-01, time/batch = 16.6498s	
20905/33150 (epoch 31.531), train_loss = 0.77170342, grad/param norm = 1.9451e-01, time/batch = 18.3241s	
20906/33150 (epoch 31.532), train_loss = 0.92870539, grad/param norm = 1.8465e-01, time/batch = 19.7086s	
20907/33150 (epoch 31.534), train_loss = 0.88896385, grad/param norm = 1.4814e-01, time/batch = 15.8671s	
20908/33150 (epoch 31.535), train_loss = 0.84924653, grad/param norm = 1.9941e-01, time/batch = 17.5454s	
20909/33150 (epoch 31.537), train_loss = 0.94339113, grad/param norm = 2.0880e-01, time/batch = 18.5432s	
20910/33150 (epoch 31.538), train_loss = 0.80514672, grad/param norm = 1.5067e-01, time/batch = 17.2224s	
20911/33150 (epoch 31.540), train_loss = 0.79198458, grad/param norm = 1.4737e-01, time/batch = 19.2942s	
20912/33150 (epoch 31.541), train_loss = 0.98717287, grad/param norm = 1.6678e-01, time/batch = 17.6510s	
20913/33150 (epoch 31.543), train_loss = 0.92178042, grad/param norm = 1.7280e-01, time/batch = 18.1368s	
20914/33150 (epoch 31.544), train_loss = 0.98039403, grad/param norm = 1.6903e-01, time/batch = 16.9779s	
20915/33150 (epoch 31.546), train_loss = 0.89600103, grad/param norm = 1.6970e-01, time/batch = 18.8957s	
20916/33150 (epoch 31.548), train_loss = 0.84866976, grad/param norm = 1.7678e-01, time/batch = 17.9832s	
20917/33150 (epoch 31.549), train_loss = 0.85110029, grad/param norm = 1.6284e-01, time/batch = 16.4523s	
20918/33150 (epoch 31.551), train_loss = 0.84534511, grad/param norm = 1.5050e-01, time/batch = 14.9128s	
20919/33150 (epoch 31.552), train_loss = 0.72139421, grad/param norm = 1.4269e-01, time/batch = 15.3161s	
20920/33150 (epoch 31.554), train_loss = 0.95729170, grad/param norm = 1.6764e-01, time/batch = 15.3745s	
20921/33150 (epoch 31.555), train_loss = 0.99293732, grad/param norm = 2.0021e-01, time/batch = 15.4559s	
20922/33150 (epoch 31.557), train_loss = 0.73981993, grad/param norm = 1.8551e-01, time/batch = 16.0608s	
20923/33150 (epoch 31.558), train_loss = 0.94341788, grad/param norm = 2.6618e-01, time/batch = 16.3528s	
20924/33150 (epoch 31.560), train_loss = 0.83724683, grad/param norm = 1.6384e-01, time/batch = 16.6302s	
20925/33150 (epoch 31.561), train_loss = 0.76742367, grad/param norm = 1.7650e-01, time/batch = 15.4554s	
20926/33150 (epoch 31.563), train_loss = 0.94577547, grad/param norm = 1.9464e-01, time/batch = 15.9533s	
20927/33150 (epoch 31.564), train_loss = 1.03483652, grad/param norm = 1.7140e-01, time/batch = 18.1305s	
20928/33150 (epoch 31.566), train_loss = 0.84861158, grad/param norm = 1.6615e-01, time/batch = 16.1418s	
20929/33150 (epoch 31.567), train_loss = 0.83417032, grad/param norm = 1.6108e-01, time/batch = 18.2185s	
20930/33150 (epoch 31.569), train_loss = 0.94324415, grad/param norm = 2.1746e-01, time/batch = 16.9535s	
20931/33150 (epoch 31.570), train_loss = 0.95904757, grad/param norm = 1.6702e-01, time/batch = 17.6229s	
20932/33150 (epoch 31.572), train_loss = 0.83959683, grad/param norm = 1.7612e-01, time/batch = 17.2923s	
20933/33150 (epoch 31.573), train_loss = 0.75156705, grad/param norm = 1.4109e-01, time/batch = 17.7482s	
20934/33150 (epoch 31.575), train_loss = 0.86183493, grad/param norm = 1.7462e-01, time/batch = 19.2196s	
20935/33150 (epoch 31.576), train_loss = 0.78687205, grad/param norm = 1.5336e-01, time/batch = 17.6246s	
20936/33150 (epoch 31.578), train_loss = 0.81714173, grad/param norm = 1.5475e-01, time/batch = 16.4849s	
20937/33150 (epoch 31.579), train_loss = 0.77454245, grad/param norm = 1.4345e-01, time/batch = 16.0666s	
20938/33150 (epoch 31.581), train_loss = 0.81343391, grad/param norm = 1.6225e-01, time/batch = 16.7845s	
20939/33150 (epoch 31.582), train_loss = 1.03377995, grad/param norm = 1.6386e-01, time/batch = 19.6202s	
20940/33150 (epoch 31.584), train_loss = 0.97959420, grad/param norm = 1.8367e-01, time/batch = 16.7126s	
20941/33150 (epoch 31.585), train_loss = 0.90612581, grad/param norm = 1.5700e-01, time/batch = 17.9537s	
20942/33150 (epoch 31.587), train_loss = 0.90784135, grad/param norm = 1.6281e-01, time/batch = 16.5533s	
20943/33150 (epoch 31.588), train_loss = 0.82558432, grad/param norm = 1.6098e-01, time/batch = 18.1273s	
20944/33150 (epoch 31.590), train_loss = 0.93913092, grad/param norm = 1.6985e-01, time/batch = 16.0492s	
20945/33150 (epoch 31.591), train_loss = 0.90522848, grad/param norm = 1.9484e-01, time/batch = 16.7212s	
20946/33150 (epoch 31.593), train_loss = 0.95392453, grad/param norm = 1.9080e-01, time/batch = 17.8748s	
20947/33150 (epoch 31.594), train_loss = 0.86600074, grad/param norm = 1.6478e-01, time/batch = 16.0544s	
20948/33150 (epoch 31.596), train_loss = 0.86975265, grad/param norm = 1.5767e-01, time/batch = 16.7210s	
20949/33150 (epoch 31.597), train_loss = 0.79794778, grad/param norm = 2.0419e-01, time/batch = 17.9649s	
20950/33150 (epoch 31.599), train_loss = 1.04684275, grad/param norm = 1.8859e-01, time/batch = 16.0003s	
20951/33150 (epoch 31.600), train_loss = 0.91096226, grad/param norm = 2.4232e-01, time/batch = 17.9823s	
20952/33150 (epoch 31.602), train_loss = 0.90103072, grad/param norm = 1.8305e-01, time/batch = 16.1234s	
20953/33150 (epoch 31.603), train_loss = 1.00731501, grad/param norm = 1.7829e-01, time/batch = 17.0589s	
20954/33150 (epoch 31.605), train_loss = 0.78767748, grad/param norm = 1.4657e-01, time/batch = 17.0727s	
20955/33150 (epoch 31.606), train_loss = 0.82303521, grad/param norm = 2.0466e-01, time/batch = 17.7233s	
20956/33150 (epoch 31.608), train_loss = 0.97128407, grad/param norm = 1.5453e-01, time/batch = 17.6365s	
20957/33150 (epoch 31.609), train_loss = 0.88579884, grad/param norm = 1.9025e-01, time/batch = 15.7750s	
20958/33150 (epoch 31.611), train_loss = 0.79566030, grad/param norm = 1.5543e-01, time/batch = 18.4593s	
20959/33150 (epoch 31.612), train_loss = 0.87410295, grad/param norm = 1.7239e-01, time/batch = 16.7154s	
20960/33150 (epoch 31.614), train_loss = 0.81349531, grad/param norm = 1.6706e-01, time/batch = 16.6601s	
20961/33150 (epoch 31.615), train_loss = 0.79578936, grad/param norm = 1.6367e-01, time/batch = 17.5586s	
20962/33150 (epoch 31.617), train_loss = 0.92381595, grad/param norm = 1.9777e-01, time/batch = 18.0386s	
20963/33150 (epoch 31.618), train_loss = 0.95638910, grad/param norm = 2.0459e-01, time/batch = 17.6290s	
20964/33150 (epoch 31.620), train_loss = 0.86335845, grad/param norm = 1.6631e-01, time/batch = 19.0478s	
20965/33150 (epoch 31.621), train_loss = 0.87538132, grad/param norm = 1.4986e-01, time/batch = 18.3868s	
20966/33150 (epoch 31.623), train_loss = 0.95663221, grad/param norm = 1.5335e-01, time/batch = 15.7925s	
20967/33150 (epoch 31.624), train_loss = 0.84402274, grad/param norm = 1.7245e-01, time/batch = 18.6311s	
20968/33150 (epoch 31.626), train_loss = 0.88797226, grad/param norm = 1.9541e-01, time/batch = 19.3865s	
20969/33150 (epoch 31.627), train_loss = 0.82181813, grad/param norm = 1.8698e-01, time/batch = 27.8511s	
20970/33150 (epoch 31.629), train_loss = 0.76544096, grad/param norm = 1.7772e-01, time/batch = 19.7530s	
20971/33150 (epoch 31.630), train_loss = 0.86866928, grad/param norm = 1.6614e-01, time/batch = 15.3007s	
20972/33150 (epoch 31.632), train_loss = 0.75900695, grad/param norm = 1.3963e-01, time/batch = 15.0478s	
20973/33150 (epoch 31.633), train_loss = 0.79706269, grad/param norm = 1.8486e-01, time/batch = 15.8925s	
20974/33150 (epoch 31.635), train_loss = 1.02662023, grad/param norm = 1.6662e-01, time/batch = 16.0441s	
20975/33150 (epoch 31.637), train_loss = 0.73995965, grad/param norm = 1.6580e-01, time/batch = 16.2080s	
20976/33150 (epoch 31.638), train_loss = 0.88007927, grad/param norm = 2.0098e-01, time/batch = 15.9319s	
20977/33150 (epoch 31.640), train_loss = 0.97707157, grad/param norm = 1.9968e-01, time/batch = 17.1887s	
20978/33150 (epoch 31.641), train_loss = 0.76206067, grad/param norm = 1.7622e-01, time/batch = 16.5357s	
20979/33150 (epoch 31.643), train_loss = 0.89601072, grad/param norm = 1.5791e-01, time/batch = 15.7137s	
20980/33150 (epoch 31.644), train_loss = 1.02373754, grad/param norm = 1.6323e-01, time/batch = 16.3876s	
20981/33150 (epoch 31.646), train_loss = 0.86545330, grad/param norm = 1.7312e-01, time/batch = 17.5525s	
20982/33150 (epoch 31.647), train_loss = 1.08479191, grad/param norm = 1.8418e-01, time/batch = 16.8025s	
20983/33150 (epoch 31.649), train_loss = 0.94612514, grad/param norm = 1.9055e-01, time/batch = 15.8058s	
20984/33150 (epoch 31.650), train_loss = 0.80156214, grad/param norm = 1.6329e-01, time/batch = 19.2881s	
20985/33150 (epoch 31.652), train_loss = 1.00850249, grad/param norm = 2.2826e-01, time/batch = 19.1283s	
20986/33150 (epoch 31.653), train_loss = 0.91615638, grad/param norm = 1.5947e-01, time/batch = 17.5449s	
20987/33150 (epoch 31.655), train_loss = 0.91805784, grad/param norm = 1.7523e-01, time/batch = 18.4646s	
20988/33150 (epoch 31.656), train_loss = 0.85468446, grad/param norm = 1.4713e-01, time/batch = 17.5623s	
20989/33150 (epoch 31.658), train_loss = 0.86885893, grad/param norm = 1.6222e-01, time/batch = 17.2764s	
20990/33150 (epoch 31.659), train_loss = 1.16078292, grad/param norm = 3.1914e-01, time/batch = 16.8900s	
20991/33150 (epoch 31.661), train_loss = 0.88321196, grad/param norm = 1.6839e-01, time/batch = 17.9669s	
20992/33150 (epoch 31.662), train_loss = 0.86698473, grad/param norm = 1.9548e-01, time/batch = 19.3782s	
20993/33150 (epoch 31.664), train_loss = 1.02005426, grad/param norm = 1.8322e-01, time/batch = 15.8896s	
20994/33150 (epoch 31.665), train_loss = 0.97875383, grad/param norm = 1.9355e-01, time/batch = 19.5473s	
20995/33150 (epoch 31.667), train_loss = 1.00869205, grad/param norm = 2.1684e-01, time/batch = 17.4605s	
20996/33150 (epoch 31.668), train_loss = 1.03397671, grad/param norm = 1.9061e-01, time/batch = 16.1493s	
20997/33150 (epoch 31.670), train_loss = 0.84017708, grad/param norm = 1.5219e-01, time/batch = 17.3867s	
20998/33150 (epoch 31.671), train_loss = 0.83982411, grad/param norm = 1.6726e-01, time/batch = 17.2217s	
20999/33150 (epoch 31.673), train_loss = 1.01532159, grad/param norm = 1.5665e-01, time/batch = 15.8020s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch31.67_1.7520.t7	
21000/33150 (epoch 31.674), train_loss = 0.96345921, grad/param norm = 1.9873e-01, time/batch = 15.7416s	
21001/33150 (epoch 31.676), train_loss = 1.41657750, grad/param norm = 2.2718e-01, time/batch = 18.0540s	
21002/33150 (epoch 31.677), train_loss = 1.07020113, grad/param norm = 2.0425e-01, time/batch = 17.0218s	
21003/33150 (epoch 31.679), train_loss = 0.89596881, grad/param norm = 1.5061e-01, time/batch = 17.6296s	
21004/33150 (epoch 31.680), train_loss = 1.02903379, grad/param norm = 1.8668e-01, time/batch = 18.3808s	
21005/33150 (epoch 31.682), train_loss = 0.90147716, grad/param norm = 1.4995e-01, time/batch = 18.2264s	
21006/33150 (epoch 31.683), train_loss = 0.77569913, grad/param norm = 1.4426e-01, time/batch = 15.7310s	
21007/33150 (epoch 31.685), train_loss = 0.88579267, grad/param norm = 1.8173e-01, time/batch = 18.5488s	
21008/33150 (epoch 31.686), train_loss = 0.79040221, grad/param norm = 1.7600e-01, time/batch = 18.2907s	
21009/33150 (epoch 31.688), train_loss = 0.82261708, grad/param norm = 1.7322e-01, time/batch = 17.7173s	
21010/33150 (epoch 31.689), train_loss = 0.81145969, grad/param norm = 1.6157e-01, time/batch = 15.6810s	
21011/33150 (epoch 31.691), train_loss = 0.72147903, grad/param norm = 1.5187e-01, time/batch = 19.2139s	
21012/33150 (epoch 31.692), train_loss = 0.80533649, grad/param norm = 2.0550e-01, time/batch = 17.9572s	
21013/33150 (epoch 31.694), train_loss = 0.70655730, grad/param norm = 1.4877e-01, time/batch = 16.0632s	
21014/33150 (epoch 31.695), train_loss = 0.84408962, grad/param norm = 1.5436e-01, time/batch = 18.9764s	
21015/33150 (epoch 31.697), train_loss = 0.77245919, grad/param norm = 1.3819e-01, time/batch = 17.9731s	
21016/33150 (epoch 31.698), train_loss = 0.80845105, grad/param norm = 1.8226e-01, time/batch = 17.5503s	
21017/33150 (epoch 31.700), train_loss = 0.67715187, grad/param norm = 1.3272e-01, time/batch = 19.3933s	
21018/33150 (epoch 31.701), train_loss = 0.76565737, grad/param norm = 1.4261e-01, time/batch = 17.2330s	
21019/33150 (epoch 31.703), train_loss = 0.88010823, grad/param norm = 1.7511e-01, time/batch = 17.7965s	
21020/33150 (epoch 31.704), train_loss = 0.78242106, grad/param norm = 1.5534e-01, time/batch = 19.7233s	
21021/33150 (epoch 31.706), train_loss = 0.83909507, grad/param norm = 1.5647e-01, time/batch = 17.5192s	
21022/33150 (epoch 31.707), train_loss = 0.83997072, grad/param norm = 1.7398e-01, time/batch = 17.9611s	
21023/33150 (epoch 31.709), train_loss = 0.88752778, grad/param norm = 1.3776e-01, time/batch = 18.5583s	
21024/33150 (epoch 31.710), train_loss = 0.88199677, grad/param norm = 1.8052e-01, time/batch = 18.3861s	
21025/33150 (epoch 31.712), train_loss = 0.95053571, grad/param norm = 1.4851e-01, time/batch = 17.3796s	
21026/33150 (epoch 31.713), train_loss = 0.91366491, grad/param norm = 1.5095e-01, time/batch = 16.1478s	
21027/33150 (epoch 31.715), train_loss = 0.84679617, grad/param norm = 1.5027e-01, time/batch = 16.8843s	
21028/33150 (epoch 31.716), train_loss = 0.92714902, grad/param norm = 1.6983e-01, time/batch = 16.5698s	
21029/33150 (epoch 31.718), train_loss = 0.90512057, grad/param norm = 1.7165e-01, time/batch = 16.4718s	
21030/33150 (epoch 31.719), train_loss = 0.97178356, grad/param norm = 1.9571e-01, time/batch = 17.3816s	
21031/33150 (epoch 31.721), train_loss = 0.88638289, grad/param norm = 1.9999e-01, time/batch = 19.0664s	
21032/33150 (epoch 31.722), train_loss = 0.91595331, grad/param norm = 1.5824e-01, time/batch = 18.2928s	
21033/33150 (epoch 31.724), train_loss = 0.85733249, grad/param norm = 1.7200e-01, time/batch = 16.9717s	
21034/33150 (epoch 31.725), train_loss = 0.96445836, grad/param norm = 2.0570e-01, time/batch = 19.2970s	
21035/33150 (epoch 31.727), train_loss = 0.94338008, grad/param norm = 2.0986e-01, time/batch = 18.2213s	
21036/33150 (epoch 31.729), train_loss = 0.90314426, grad/param norm = 1.8218e-01, time/batch = 16.2934s	
21037/33150 (epoch 31.730), train_loss = 0.88796335, grad/param norm = 1.7683e-01, time/batch = 19.3841s	
21038/33150 (epoch 31.732), train_loss = 0.94786907, grad/param norm = 1.8693e-01, time/batch = 19.2889s	
21039/33150 (epoch 31.733), train_loss = 0.75087369, grad/param norm = 1.3187e-01, time/batch = 16.2796s	
21040/33150 (epoch 31.735), train_loss = 0.82058107, grad/param norm = 1.5886e-01, time/batch = 17.8866s	
21041/33150 (epoch 31.736), train_loss = 0.85746969, grad/param norm = 1.6773e-01, time/batch = 16.6457s	
21042/33150 (epoch 31.738), train_loss = 0.89780614, grad/param norm = 1.7800e-01, time/batch = 17.7927s	
21043/33150 (epoch 31.739), train_loss = 0.97312314, grad/param norm = 1.8514e-01, time/batch = 17.0668s	
21044/33150 (epoch 31.741), train_loss = 0.93856029, grad/param norm = 1.8152e-01, time/batch = 17.3795s	
21045/33150 (epoch 31.742), train_loss = 0.77480317, grad/param norm = 1.6329e-01, time/batch = 17.5599s	
21046/33150 (epoch 31.744), train_loss = 0.96484387, grad/param norm = 1.9674e-01, time/batch = 15.2040s	
21047/33150 (epoch 31.745), train_loss = 0.84368628, grad/param norm = 1.4473e-01, time/batch = 14.7872s	
21048/33150 (epoch 31.747), train_loss = 0.66911756, grad/param norm = 1.4886e-01, time/batch = 16.4090s	
21049/33150 (epoch 31.748), train_loss = 0.78032458, grad/param norm = 1.7241e-01, time/batch = 18.9779s	
21050/33150 (epoch 31.750), train_loss = 0.91279627, grad/param norm = 1.6821e-01, time/batch = 18.2139s	
21051/33150 (epoch 31.751), train_loss = 0.87221240, grad/param norm = 1.4929e-01, time/batch = 18.1256s	
21052/33150 (epoch 31.753), train_loss = 0.76918042, grad/param norm = 2.2720e-01, time/batch = 17.2957s	
21053/33150 (epoch 31.754), train_loss = 1.08326406, grad/param norm = 2.1566e-01, time/batch = 16.6446s	
21054/33150 (epoch 31.756), train_loss = 0.90407846, grad/param norm = 2.2397e-01, time/batch = 18.1509s	
21055/33150 (epoch 31.757), train_loss = 0.92959857, grad/param norm = 1.8201e-01, time/batch = 18.7948s	
21056/33150 (epoch 31.759), train_loss = 1.04351399, grad/param norm = 2.3367e-01, time/batch = 16.6350s	
21057/33150 (epoch 31.760), train_loss = 0.92116665, grad/param norm = 1.5936e-01, time/batch = 16.8705s	
21058/33150 (epoch 31.762), train_loss = 0.92549290, grad/param norm = 2.0483e-01, time/batch = 20.1215s	
21059/33150 (epoch 31.763), train_loss = 0.90898250, grad/param norm = 1.6166e-01, time/batch = 17.7947s	
21060/33150 (epoch 31.765), train_loss = 0.87701776, grad/param norm = 1.6524e-01, time/batch = 18.1214s	
21061/33150 (epoch 31.766), train_loss = 0.81194051, grad/param norm = 1.6972e-01, time/batch = 18.6345s	
21062/33150 (epoch 31.768), train_loss = 0.80030676, grad/param norm = 1.4390e-01, time/batch = 18.4422s	
21063/33150 (epoch 31.769), train_loss = 0.95406472, grad/param norm = 1.9517e-01, time/batch = 17.6988s	
21064/33150 (epoch 31.771), train_loss = 0.90092822, grad/param norm = 2.0496e-01, time/batch = 15.8028s	
21065/33150 (epoch 31.772), train_loss = 0.94096160, grad/param norm = 1.8512e-01, time/batch = 16.4555s	
21066/33150 (epoch 31.774), train_loss = 1.02923039, grad/param norm = 1.8321e-01, time/batch = 16.1284s	
21067/33150 (epoch 31.775), train_loss = 0.95451848, grad/param norm = 2.2542e-01, time/batch = 15.0305s	
21068/33150 (epoch 31.777), train_loss = 0.96161896, grad/param norm = 1.7219e-01, time/batch = 15.1059s	
21069/33150 (epoch 31.778), train_loss = 0.89218022, grad/param norm = 1.5714e-01, time/batch = 15.2800s	
21070/33150 (epoch 31.780), train_loss = 0.76201081, grad/param norm = 1.5515e-01, time/batch = 15.7070s	
21071/33150 (epoch 31.781), train_loss = 0.90270384, grad/param norm = 1.6972e-01, time/batch = 16.0521s	
21072/33150 (epoch 31.783), train_loss = 0.90487385, grad/param norm = 1.6114e-01, time/batch = 17.0657s	
21073/33150 (epoch 31.784), train_loss = 0.88856092, grad/param norm = 1.7309e-01, time/batch = 17.7215s	
21074/33150 (epoch 31.786), train_loss = 0.87763808, grad/param norm = 1.6385e-01, time/batch = 15.8054s	
21075/33150 (epoch 31.787), train_loss = 0.81352496, grad/param norm = 1.5630e-01, time/batch = 17.1391s	
21076/33150 (epoch 31.789), train_loss = 0.75763607, grad/param norm = 1.6845e-01, time/batch = 18.9709s	
21077/33150 (epoch 31.790), train_loss = 0.76243004, grad/param norm = 1.4948e-01, time/batch = 16.5394s	
21078/33150 (epoch 31.792), train_loss = 0.90318678, grad/param norm = 1.9893e-01, time/batch = 17.8021s	
21079/33150 (epoch 31.793), train_loss = 0.86810011, grad/param norm = 1.8370e-01, time/batch = 18.2106s	
21080/33150 (epoch 31.795), train_loss = 0.83088957, grad/param norm = 1.6764e-01, time/batch = 18.0662s	
21081/33150 (epoch 31.796), train_loss = 0.84794748, grad/param norm = 1.4743e-01, time/batch = 16.2136s	
21082/33150 (epoch 31.798), train_loss = 0.82498210, grad/param norm = 1.4421e-01, time/batch = 17.5550s	
21083/33150 (epoch 31.799), train_loss = 0.75779525, grad/param norm = 2.2289e-01, time/batch = 17.2560s	
21084/33150 (epoch 31.801), train_loss = 0.89107201, grad/param norm = 1.8136e-01, time/batch = 17.3803s	
21085/33150 (epoch 31.802), train_loss = 0.83755728, grad/param norm = 1.7290e-01, time/batch = 17.8005s	
21086/33150 (epoch 31.804), train_loss = 0.86469970, grad/param norm = 1.5605e-01, time/batch = 19.1376s	
21087/33150 (epoch 31.805), train_loss = 0.83794357, grad/param norm = 1.8463e-01, time/batch = 17.7956s	
21088/33150 (epoch 31.807), train_loss = 0.85845725, grad/param norm = 1.5603e-01, time/batch = 17.1524s	
21089/33150 (epoch 31.808), train_loss = 0.97643359, grad/param norm = 1.6373e-01, time/batch = 16.8203s	
21090/33150 (epoch 31.810), train_loss = 0.81297360, grad/param norm = 1.6068e-01, time/batch = 16.3989s	
21091/33150 (epoch 31.811), train_loss = 0.92026193, grad/param norm = 1.9490e-01, time/batch = 15.3854s	
21092/33150 (epoch 31.813), train_loss = 0.84789942, grad/param norm = 1.4737e-01, time/batch = 15.5434s	
21093/33150 (epoch 31.814), train_loss = 0.81062717, grad/param norm = 1.9394e-01, time/batch = 16.3157s	
21094/33150 (epoch 31.816), train_loss = 0.87064499, grad/param norm = 1.9632e-01, time/batch = 16.0662s	
21095/33150 (epoch 31.817), train_loss = 0.94127436, grad/param norm = 1.6267e-01, time/batch = 16.2215s	
21096/33150 (epoch 31.819), train_loss = 0.89898927, grad/param norm = 1.7425e-01, time/batch = 18.1458s	
21097/33150 (epoch 31.821), train_loss = 0.78007416, grad/param norm = 1.4624e-01, time/batch = 17.8187s	
21098/33150 (epoch 31.822), train_loss = 0.81814358, grad/param norm = 1.5345e-01, time/batch = 16.5485s	
21099/33150 (epoch 31.824), train_loss = 0.87992862, grad/param norm = 1.6967e-01, time/batch = 16.1380s	
21100/33150 (epoch 31.825), train_loss = 0.90159906, grad/param norm = 1.7394e-01, time/batch = 17.8096s	
21101/33150 (epoch 31.827), train_loss = 0.92810759, grad/param norm = 1.8601e-01, time/batch = 16.9687s	
21102/33150 (epoch 31.828), train_loss = 0.79632520, grad/param norm = 1.7287e-01, time/batch = 17.0411s	
21103/33150 (epoch 31.830), train_loss = 0.95398518, grad/param norm = 1.9008e-01, time/batch = 17.4585s	
21104/33150 (epoch 31.831), train_loss = 0.80594897, grad/param norm = 1.6632e-01, time/batch = 17.5495s	
21105/33150 (epoch 31.833), train_loss = 0.79369643, grad/param norm = 1.6870e-01, time/batch = 17.1285s	
21106/33150 (epoch 31.834), train_loss = 0.96503832, grad/param norm = 1.7261e-01, time/batch = 17.8089s	
21107/33150 (epoch 31.836), train_loss = 0.97630382, grad/param norm = 1.4907e-01, time/batch = 18.3053s	
21108/33150 (epoch 31.837), train_loss = 0.81676181, grad/param norm = 1.5789e-01, time/batch = 17.4825s	
21109/33150 (epoch 31.839), train_loss = 0.95299934, grad/param norm = 2.1233e-01, time/batch = 16.6189s	
21110/33150 (epoch 31.840), train_loss = 0.94661361, grad/param norm = 1.6824e-01, time/batch = 18.3885s	
21111/33150 (epoch 31.842), train_loss = 0.99625283, grad/param norm = 2.0283e-01, time/batch = 18.1293s	
21112/33150 (epoch 31.843), train_loss = 0.95617192, grad/param norm = 1.6668e-01, time/batch = 16.8881s	
21113/33150 (epoch 31.845), train_loss = 0.83135633, grad/param norm = 1.8090e-01, time/batch = 18.0584s	
21114/33150 (epoch 31.846), train_loss = 1.07228246, grad/param norm = 2.3426e-01, time/batch = 17.3959s	
21115/33150 (epoch 31.848), train_loss = 0.98406252, grad/param norm = 1.9035e-01, time/batch = 17.8812s	
21116/33150 (epoch 31.849), train_loss = 1.00038301, grad/param norm = 1.6795e-01, time/batch = 17.8811s	
21117/33150 (epoch 31.851), train_loss = 0.93698993, grad/param norm = 1.7502e-01, time/batch = 17.5554s	
21118/33150 (epoch 31.852), train_loss = 1.00919220, grad/param norm = 1.5660e-01, time/batch = 19.4689s	
21119/33150 (epoch 31.854), train_loss = 0.91730826, grad/param norm = 1.6926e-01, time/batch = 15.5674s	
21120/33150 (epoch 31.855), train_loss = 0.77262572, grad/param norm = 1.5584e-01, time/batch = 18.5470s	
21121/33150 (epoch 31.857), train_loss = 0.73460808, grad/param norm = 1.7103e-01, time/batch = 18.2163s	
21122/33150 (epoch 31.858), train_loss = 0.84996711, grad/param norm = 1.6229e-01, time/batch = 16.7036s	
21123/33150 (epoch 31.860), train_loss = 0.79333858, grad/param norm = 1.5446e-01, time/batch = 17.2965s	
21124/33150 (epoch 31.861), train_loss = 0.79611105, grad/param norm = 1.5128e-01, time/batch = 15.9740s	
21125/33150 (epoch 31.863), train_loss = 0.86766362, grad/param norm = 1.5752e-01, time/batch = 17.5655s	
21126/33150 (epoch 31.864), train_loss = 0.90231474, grad/param norm = 1.6317e-01, time/batch = 16.9494s	
21127/33150 (epoch 31.866), train_loss = 0.95130547, grad/param norm = 1.7988e-01, time/batch = 17.9793s	
21128/33150 (epoch 31.867), train_loss = 0.91718034, grad/param norm = 1.5481e-01, time/batch = 18.1285s	
21129/33150 (epoch 31.869), train_loss = 0.90665196, grad/param norm = 1.7833e-01, time/batch = 16.9785s	
21130/33150 (epoch 31.870), train_loss = 0.82937412, grad/param norm = 1.8396e-01, time/batch = 16.7245s	
21131/33150 (epoch 31.872), train_loss = 0.91901204, grad/param norm = 1.7058e-01, time/batch = 18.8704s	
21132/33150 (epoch 31.873), train_loss = 0.72448907, grad/param norm = 1.4202e-01, time/batch = 17.9668s	
21133/33150 (epoch 31.875), train_loss = 0.99539346, grad/param norm = 1.6217e-01, time/batch = 17.4717s	
21134/33150 (epoch 31.876), train_loss = 0.74519336, grad/param norm = 1.4494e-01, time/batch = 17.2177s	
21135/33150 (epoch 31.878), train_loss = 0.82174008, grad/param norm = 1.5276e-01, time/batch = 16.4833s	
21136/33150 (epoch 31.879), train_loss = 0.82592670, grad/param norm = 1.5261e-01, time/batch = 16.5610s	
21137/33150 (epoch 31.881), train_loss = 0.80928071, grad/param norm = 1.6751e-01, time/batch = 16.4717s	
21138/33150 (epoch 31.882), train_loss = 0.70768047, grad/param norm = 1.5361e-01, time/batch = 20.2050s	
21139/33150 (epoch 31.884), train_loss = 0.82545038, grad/param norm = 1.5142e-01, time/batch = 17.5349s	
21140/33150 (epoch 31.885), train_loss = 0.67256071, grad/param norm = 1.5849e-01, time/batch = 19.9661s	
21141/33150 (epoch 31.887), train_loss = 0.97482475, grad/param norm = 1.8199e-01, time/batch = 19.2121s	
21142/33150 (epoch 31.888), train_loss = 0.90226977, grad/param norm = 1.6448e-01, time/batch = 18.1380s	
21143/33150 (epoch 31.890), train_loss = 0.82621969, grad/param norm = 1.7524e-01, time/batch = 15.8490s	
21144/33150 (epoch 31.891), train_loss = 0.77454556, grad/param norm = 1.4813e-01, time/batch = 18.9760s	
21145/33150 (epoch 31.893), train_loss = 0.92581075, grad/param norm = 2.1976e-01, time/batch = 17.7985s	
21146/33150 (epoch 31.894), train_loss = 0.92145656, grad/param norm = 1.7980e-01, time/batch = 16.5460s	
21147/33150 (epoch 31.896), train_loss = 0.86069614, grad/param norm = 1.5754e-01, time/batch = 15.8890s	
21148/33150 (epoch 31.897), train_loss = 0.91624222, grad/param norm = 1.5422e-01, time/batch = 18.3201s	
21149/33150 (epoch 31.899), train_loss = 0.73163424, grad/param norm = 1.9216e-01, time/batch = 17.9527s	
21150/33150 (epoch 31.900), train_loss = 1.06078002, grad/param norm = 1.8780e-01, time/batch = 17.2230s	
21151/33150 (epoch 31.902), train_loss = 1.08459393, grad/param norm = 1.7109e-01, time/batch = 18.3878s	
21152/33150 (epoch 31.903), train_loss = 0.89596204, grad/param norm = 1.8209e-01, time/batch = 17.9009s	
21153/33150 (epoch 31.905), train_loss = 0.90290541, grad/param norm = 1.5943e-01, time/batch = 17.9452s	
21154/33150 (epoch 31.906), train_loss = 0.89415046, grad/param norm = 1.8190e-01, time/batch = 17.9801s	
21155/33150 (epoch 31.908), train_loss = 0.96792765, grad/param norm = 1.7145e-01, time/batch = 18.4723s	
21156/33150 (epoch 31.910), train_loss = 0.95675049, grad/param norm = 1.7892e-01, time/batch = 16.7194s	
21157/33150 (epoch 31.911), train_loss = 0.76750158, grad/param norm = 1.4622e-01, time/batch = 20.0463s	
21158/33150 (epoch 31.913), train_loss = 0.81448421, grad/param norm = 1.7174e-01, time/batch = 18.7215s	
21159/33150 (epoch 31.914), train_loss = 0.91931184, grad/param norm = 1.7503e-01, time/batch = 17.3805s	
21160/33150 (epoch 31.916), train_loss = 0.83135524, grad/param norm = 1.6979e-01, time/batch = 17.0399s	
21161/33150 (epoch 31.917), train_loss = 0.93607175, grad/param norm = 2.0425e-01, time/batch = 19.8727s	
21162/33150 (epoch 31.919), train_loss = 1.01241800, grad/param norm = 2.0686e-01, time/batch = 18.4640s	
21163/33150 (epoch 31.920), train_loss = 0.97316892, grad/param norm = 1.7710e-01, time/batch = 18.6305s	
21164/33150 (epoch 31.922), train_loss = 1.02427213, grad/param norm = 1.8997e-01, time/batch = 19.2076s	
21165/33150 (epoch 31.923), train_loss = 0.89583559, grad/param norm = 1.9055e-01, time/batch = 19.3711s	
21166/33150 (epoch 31.925), train_loss = 0.99098621, grad/param norm = 1.7993e-01, time/batch = 31.3750s	
21167/33150 (epoch 31.926), train_loss = 0.86342672, grad/param norm = 1.6723e-01, time/batch = 19.7917s	
21168/33150 (epoch 31.928), train_loss = 0.85270567, grad/param norm = 1.6009e-01, time/batch = 16.2248s	
21169/33150 (epoch 31.929), train_loss = 0.96283347, grad/param norm = 2.0029e-01, time/batch = 16.4142s	
21170/33150 (epoch 31.931), train_loss = 1.03742909, grad/param norm = 2.2391e-01, time/batch = 18.1208s	
21171/33150 (epoch 31.932), train_loss = 0.90773336, grad/param norm = 1.6739e-01, time/batch = 18.3644s	
21172/33150 (epoch 31.934), train_loss = 0.91787284, grad/param norm = 1.5975e-01, time/batch = 15.5660s	
21173/33150 (epoch 31.935), train_loss = 0.98967385, grad/param norm = 1.7983e-01, time/batch = 19.0575s	
21174/33150 (epoch 31.937), train_loss = 1.00997149, grad/param norm = 1.5623e-01, time/batch = 17.8192s	
21175/33150 (epoch 31.938), train_loss = 0.93005447, grad/param norm = 1.6839e-01, time/batch = 16.9725s	
21176/33150 (epoch 31.940), train_loss = 1.12598546, grad/param norm = 2.2338e-01, time/batch = 16.6313s	
21177/33150 (epoch 31.941), train_loss = 0.92525930, grad/param norm = 1.4952e-01, time/batch = 19.3878s	
21178/33150 (epoch 31.943), train_loss = 0.74450206, grad/param norm = 1.6045e-01, time/batch = 17.6417s	
21179/33150 (epoch 31.944), train_loss = 0.95554983, grad/param norm = 1.8023e-01, time/batch = 17.3903s	
21180/33150 (epoch 31.946), train_loss = 0.78291768, grad/param norm = 1.3993e-01, time/batch = 19.9561s	
21181/33150 (epoch 31.947), train_loss = 0.93464152, grad/param norm = 1.8728e-01, time/batch = 18.1331s	
21182/33150 (epoch 31.949), train_loss = 0.99846802, grad/param norm = 1.6180e-01, time/batch = 16.4618s	
21183/33150 (epoch 31.950), train_loss = 0.94760643, grad/param norm = 1.8665e-01, time/batch = 17.0465s	
21184/33150 (epoch 31.952), train_loss = 0.84424827, grad/param norm = 1.6665e-01, time/batch = 16.5469s	
21185/33150 (epoch 31.953), train_loss = 0.86752815, grad/param norm = 1.5681e-01, time/batch = 18.1495s	
21186/33150 (epoch 31.955), train_loss = 0.79443023, grad/param norm = 1.8109e-01, time/batch = 16.3935s	
21187/33150 (epoch 31.956), train_loss = 0.97110697, grad/param norm = 1.8212e-01, time/batch = 18.3139s	
21188/33150 (epoch 31.958), train_loss = 0.79097288, grad/param norm = 1.4087e-01, time/batch = 17.8844s	
21189/33150 (epoch 31.959), train_loss = 0.85286395, grad/param norm = 1.4825e-01, time/batch = 15.8120s	
21190/33150 (epoch 31.961), train_loss = 0.82416220, grad/param norm = 1.7088e-01, time/batch = 17.5632s	
21191/33150 (epoch 31.962), train_loss = 0.76516797, grad/param norm = 1.4607e-01, time/batch = 18.8918s	
21192/33150 (epoch 31.964), train_loss = 0.88730436, grad/param norm = 1.6949e-01, time/batch = 16.5655s	
21193/33150 (epoch 31.965), train_loss = 0.86526952, grad/param norm = 1.6447e-01, time/batch = 17.4858s	
21194/33150 (epoch 31.967), train_loss = 0.86763130, grad/param norm = 2.0775e-01, time/batch = 16.4565s	
21195/33150 (epoch 31.968), train_loss = 0.74285506, grad/param norm = 1.3281e-01, time/batch = 16.3069s	
21196/33150 (epoch 31.970), train_loss = 0.83063437, grad/param norm = 1.6765e-01, time/batch = 17.2370s	
21197/33150 (epoch 31.971), train_loss = 0.88925215, grad/param norm = 1.5719e-01, time/batch = 18.4766s	
21198/33150 (epoch 31.973), train_loss = 0.96284513, grad/param norm = 1.6780e-01, time/batch = 17.4591s	
21199/33150 (epoch 31.974), train_loss = 1.01264823, grad/param norm = 2.0067e-01, time/batch = 17.0427s	
21200/33150 (epoch 31.976), train_loss = 0.98034555, grad/param norm = 1.5838e-01, time/batch = 16.8653s	
21201/33150 (epoch 31.977), train_loss = 0.99678445, grad/param norm = 1.6987e-01, time/batch = 17.6300s	
21202/33150 (epoch 31.979), train_loss = 0.97665443, grad/param norm = 2.0265e-01, time/batch = 18.2994s	
21203/33150 (epoch 31.980), train_loss = 1.03022119, grad/param norm = 1.8133e-01, time/batch = 17.7852s	
21204/33150 (epoch 31.982), train_loss = 0.88134261, grad/param norm = 1.9954e-01, time/batch = 18.2970s	
21205/33150 (epoch 31.983), train_loss = 0.81212813, grad/param norm = 1.6475e-01, time/batch = 18.1340s	
21206/33150 (epoch 31.985), train_loss = 1.01459227, grad/param norm = 1.8063e-01, time/batch = 17.7817s	
21207/33150 (epoch 31.986), train_loss = 0.75024018, grad/param norm = 1.5452e-01, time/batch = 18.9768s	
21208/33150 (epoch 31.988), train_loss = 0.85391386, grad/param norm = 2.2229e-01, time/batch = 19.3039s	
21209/33150 (epoch 31.989), train_loss = 0.86163075, grad/param norm = 1.5465e-01, time/batch = 15.9789s	
21210/33150 (epoch 31.991), train_loss = 0.94080750, grad/param norm = 2.4499e-01, time/batch = 18.5548s	
21211/33150 (epoch 31.992), train_loss = 0.85142245, grad/param norm = 1.6068e-01, time/batch = 19.2921s	
21212/33150 (epoch 31.994), train_loss = 0.91027584, grad/param norm = 1.6113e-01, time/batch = 17.9514s	
21213/33150 (epoch 31.995), train_loss = 0.86858600, grad/param norm = 1.7434e-01, time/batch = 17.5558s	
21214/33150 (epoch 31.997), train_loss = 0.87454849, grad/param norm = 1.5782e-01, time/batch = 19.2043s	
21215/33150 (epoch 31.998), train_loss = 0.75257825, grad/param norm = 1.5806e-01, time/batch = 18.0369s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
21216/33150 (epoch 32.000), train_loss = 0.73985981, grad/param norm = 1.7168e-01, time/batch = 17.2061s	
21217/33150 (epoch 32.002), train_loss = 1.19539755, grad/param norm = 1.7923e-01, time/batch = 17.0477s	
21218/33150 (epoch 32.003), train_loss = 0.78823989, grad/param norm = 1.5159e-01, time/batch = 15.2700s	
21219/33150 (epoch 32.005), train_loss = 0.76438749, grad/param norm = 1.4831e-01, time/batch = 15.1269s	
21220/33150 (epoch 32.006), train_loss = 0.76001884, grad/param norm = 1.6112e-01, time/batch = 15.0438s	
21221/33150 (epoch 32.008), train_loss = 0.93214686, grad/param norm = 1.7421e-01, time/batch = 15.1902s	
21222/33150 (epoch 32.009), train_loss = 0.91953645, grad/param norm = 1.6241e-01, time/batch = 16.1369s	
21223/33150 (epoch 32.011), train_loss = 0.98079422, grad/param norm = 1.6735e-01, time/batch = 15.5278s	
21224/33150 (epoch 32.012), train_loss = 0.87482465, grad/param norm = 2.2860e-01, time/batch = 17.3514s	
21225/33150 (epoch 32.014), train_loss = 0.81913121, grad/param norm = 1.7047e-01, time/batch = 18.8777s	
21226/33150 (epoch 32.015), train_loss = 0.80661065, grad/param norm = 1.7820e-01, time/batch = 17.1231s	
21227/33150 (epoch 32.017), train_loss = 0.79981272, grad/param norm = 1.4625e-01, time/batch = 15.8838s	
21228/33150 (epoch 32.018), train_loss = 0.90216092, grad/param norm = 1.7664e-01, time/batch = 17.7950s	
21229/33150 (epoch 32.020), train_loss = 0.98169051, grad/param norm = 2.0012e-01, time/batch = 17.7090s	
21230/33150 (epoch 32.021), train_loss = 0.77269949, grad/param norm = 1.5188e-01, time/batch = 15.7218s	
21231/33150 (epoch 32.023), train_loss = 1.05749540, grad/param norm = 1.6872e-01, time/batch = 17.5452s	
21232/33150 (epoch 32.024), train_loss = 0.91956909, grad/param norm = 1.7730e-01, time/batch = 17.2080s	
21233/33150 (epoch 32.026), train_loss = 0.70452967, grad/param norm = 1.3875e-01, time/batch = 17.2149s	
21234/33150 (epoch 32.027), train_loss = 0.71455920, grad/param norm = 1.3020e-01, time/batch = 17.3761s	
21235/33150 (epoch 32.029), train_loss = 0.82785453, grad/param norm = 1.5767e-01, time/batch = 16.1371s	
21236/33150 (epoch 32.030), train_loss = 0.84718900, grad/param norm = 1.3803e-01, time/batch = 16.3136s	
21237/33150 (epoch 32.032), train_loss = 0.77594819, grad/param norm = 1.8272e-01, time/batch = 16.4625s	
21238/33150 (epoch 32.033), train_loss = 0.80859698, grad/param norm = 1.5106e-01, time/batch = 16.9358s	
21239/33150 (epoch 32.035), train_loss = 1.05657241, grad/param norm = 1.8605e-01, time/batch = 16.5547s	
21240/33150 (epoch 32.036), train_loss = 0.95275477, grad/param norm = 1.8884e-01, time/batch = 15.9801s	
21241/33150 (epoch 32.038), train_loss = 1.07154940, grad/param norm = 1.7898e-01, time/batch = 18.1313s	
21242/33150 (epoch 32.039), train_loss = 0.95068459, grad/param norm = 1.5075e-01, time/batch = 16.9780s	
21243/33150 (epoch 32.041), train_loss = 0.88744235, grad/param norm = 1.6554e-01, time/batch = 19.4618s	
21244/33150 (epoch 32.042), train_loss = 0.81727593, grad/param norm = 1.5185e-01, time/batch = 16.1204s	
21245/33150 (epoch 32.044), train_loss = 0.87730128, grad/param norm = 1.4794e-01, time/batch = 18.3737s	
21246/33150 (epoch 32.045), train_loss = 0.93773572, grad/param norm = 1.4144e-01, time/batch = 15.0540s	
21247/33150 (epoch 32.047), train_loss = 0.79324040, grad/param norm = 1.7140e-01, time/batch = 16.3055s	
21248/33150 (epoch 32.048), train_loss = 0.99038846, grad/param norm = 1.8705e-01, time/batch = 15.4812s	
21249/33150 (epoch 32.050), train_loss = 0.89172277, grad/param norm = 1.8547e-01, time/batch = 16.8876s	
21250/33150 (epoch 32.051), train_loss = 0.90400201, grad/param norm = 1.6386e-01, time/batch = 18.2176s	
21251/33150 (epoch 32.053), train_loss = 0.89691243, grad/param norm = 1.7427e-01, time/batch = 16.3793s	
21252/33150 (epoch 32.054), train_loss = 1.03468625, grad/param norm = 1.6400e-01, time/batch = 17.5445s	
21253/33150 (epoch 32.056), train_loss = 0.88563424, grad/param norm = 1.6858e-01, time/batch = 18.1181s	
21254/33150 (epoch 32.057), train_loss = 0.92910493, grad/param norm = 1.6652e-01, time/batch = 16.7785s	
21255/33150 (epoch 32.059), train_loss = 0.80496081, grad/param norm = 1.5917e-01, time/batch = 17.1398s	
21256/33150 (epoch 32.060), train_loss = 0.80830999, grad/param norm = 1.5577e-01, time/batch = 19.0317s	
21257/33150 (epoch 32.062), train_loss = 0.87554766, grad/param norm = 1.6209e-01, time/batch = 18.8644s	
21258/33150 (epoch 32.063), train_loss = 0.82000630, grad/param norm = 1.6636e-01, time/batch = 16.8922s	
21259/33150 (epoch 32.065), train_loss = 0.84670669, grad/param norm = 1.5438e-01, time/batch = 16.4751s	
21260/33150 (epoch 32.066), train_loss = 0.84938448, grad/param norm = 1.7054e-01, time/batch = 19.2189s	
21261/33150 (epoch 32.068), train_loss = 0.93437121, grad/param norm = 1.5948e-01, time/batch = 16.8254s	
21262/33150 (epoch 32.069), train_loss = 0.92967537, grad/param norm = 1.8657e-01, time/batch = 17.0498s	
21263/33150 (epoch 32.071), train_loss = 0.90439134, grad/param norm = 1.6976e-01, time/batch = 19.6238s	
21264/33150 (epoch 32.072), train_loss = 0.91205678, grad/param norm = 1.6651e-01, time/batch = 18.4440s	
21265/33150 (epoch 32.074), train_loss = 0.76573690, grad/param norm = 2.3006e-01, time/batch = 20.0360s	
21266/33150 (epoch 32.075), train_loss = 0.81674814, grad/param norm = 1.8509e-01, time/batch = 17.9043s	
21267/33150 (epoch 32.077), train_loss = 0.90091888, grad/param norm = 2.1956e-01, time/batch = 18.7239s	
21268/33150 (epoch 32.078), train_loss = 1.03647650, grad/param norm = 2.2580e-01, time/batch = 17.1931s	
21269/33150 (epoch 32.080), train_loss = 1.03168857, grad/param norm = 1.7742e-01, time/batch = 16.8141s	
21270/33150 (epoch 32.081), train_loss = 0.77788955, grad/param norm = 1.5843e-01, time/batch = 15.7150s	
21271/33150 (epoch 32.083), train_loss = 0.68726226, grad/param norm = 1.9393e-01, time/batch = 17.3818s	
21272/33150 (epoch 32.084), train_loss = 0.75392593, grad/param norm = 1.5162e-01, time/batch = 17.3927s	
21273/33150 (epoch 32.086), train_loss = 0.81566584, grad/param norm = 1.8715e-01, time/batch = 17.3926s	
21274/33150 (epoch 32.087), train_loss = 0.77372345, grad/param norm = 1.5147e-01, time/batch = 17.6274s	
21275/33150 (epoch 32.089), train_loss = 0.81685736, grad/param norm = 1.8032e-01, time/batch = 16.0963s	
21276/33150 (epoch 32.090), train_loss = 0.84335256, grad/param norm = 1.8428e-01, time/batch = 17.2180s	
21277/33150 (epoch 32.092), train_loss = 0.83460988, grad/param norm = 1.8589e-01, time/batch = 18.9539s	
21278/33150 (epoch 32.094), train_loss = 0.91996746, grad/param norm = 2.0209e-01, time/batch = 16.7001s	
21279/33150 (epoch 32.095), train_loss = 0.82422992, grad/param norm = 1.5753e-01, time/batch = 18.7021s	
21280/33150 (epoch 32.097), train_loss = 0.75185721, grad/param norm = 1.6651e-01, time/batch = 19.2992s	
21281/33150 (epoch 32.098), train_loss = 1.10694908, grad/param norm = 1.9545e-01, time/batch = 16.8676s	
21282/33150 (epoch 32.100), train_loss = 1.06289867, grad/param norm = 1.9461e-01, time/batch = 18.6155s	
21283/33150 (epoch 32.101), train_loss = 0.83841424, grad/param norm = 1.7758e-01, time/batch = 17.9683s	
21284/33150 (epoch 32.103), train_loss = 0.90084156, grad/param norm = 1.6687e-01, time/batch = 20.1184s	
21285/33150 (epoch 32.104), train_loss = 0.82144788, grad/param norm = 1.9222e-01, time/batch = 15.9916s	
21286/33150 (epoch 32.106), train_loss = 0.98744082, grad/param norm = 1.8944e-01, time/batch = 17.7208s	
21287/33150 (epoch 32.107), train_loss = 1.07384159, grad/param norm = 2.1306e-01, time/batch = 18.1372s	
21288/33150 (epoch 32.109), train_loss = 0.86924240, grad/param norm = 1.3710e-01, time/batch = 17.0545s	
21289/33150 (epoch 32.110), train_loss = 0.99213542, grad/param norm = 1.7781e-01, time/batch = 17.1322s	
21290/33150 (epoch 32.112), train_loss = 0.81094526, grad/param norm = 1.6334e-01, time/batch = 17.3049s	
21291/33150 (epoch 32.113), train_loss = 0.85678727, grad/param norm = 1.9337e-01, time/batch = 18.0428s	
21292/33150 (epoch 32.115), train_loss = 1.07079364, grad/param norm = 2.0244e-01, time/batch = 17.8630s	
21293/33150 (epoch 32.116), train_loss = 0.90286698, grad/param norm = 1.5728e-01, time/batch = 17.7230s	
21294/33150 (epoch 32.118), train_loss = 0.92423659, grad/param norm = 1.8076e-01, time/batch = 17.8984s	
21295/33150 (epoch 32.119), train_loss = 0.95134552, grad/param norm = 2.1450e-01, time/batch = 16.6392s	
21296/33150 (epoch 32.121), train_loss = 0.84762485, grad/param norm = 1.6847e-01, time/batch = 19.8001s	
21297/33150 (epoch 32.122), train_loss = 1.03559118, grad/param norm = 2.0396e-01, time/batch = 16.4686s	
21298/33150 (epoch 32.124), train_loss = 0.74337665, grad/param norm = 1.3760e-01, time/batch = 16.5937s	
21299/33150 (epoch 32.125), train_loss = 1.00520884, grad/param norm = 1.7167e-01, time/batch = 17.6219s	
21300/33150 (epoch 32.127), train_loss = 0.90311681, grad/param norm = 1.6969e-01, time/batch = 16.9031s	
21301/33150 (epoch 32.128), train_loss = 0.94123038, grad/param norm = 1.8968e-01, time/batch = 19.4512s	
21302/33150 (epoch 32.130), train_loss = 0.88342614, grad/param norm = 1.6120e-01, time/batch = 15.9794s	
21303/33150 (epoch 32.131), train_loss = 1.09084565, grad/param norm = 1.7141e-01, time/batch = 16.4655s	
21304/33150 (epoch 32.133), train_loss = 0.82915954, grad/param norm = 1.5745e-01, time/batch = 16.2283s	
21305/33150 (epoch 32.134), train_loss = 1.01177429, grad/param norm = 1.8037e-01, time/batch = 16.8031s	
21306/33150 (epoch 32.136), train_loss = 0.90204418, grad/param norm = 1.9423e-01, time/batch = 17.7027s	
21307/33150 (epoch 32.137), train_loss = 0.97003138, grad/param norm = 1.6761e-01, time/batch = 16.4509s	
21308/33150 (epoch 32.139), train_loss = 0.95335608, grad/param norm = 1.7646e-01, time/batch = 17.1353s	
21309/33150 (epoch 32.140), train_loss = 1.07309057, grad/param norm = 1.9150e-01, time/batch = 16.3726s	
21310/33150 (epoch 32.142), train_loss = 0.96381097, grad/param norm = 1.9129e-01, time/batch = 18.4678s	
21311/33150 (epoch 32.143), train_loss = 0.88848583, grad/param norm = 1.8601e-01, time/batch = 18.7292s	
21312/33150 (epoch 32.145), train_loss = 0.86479838, grad/param norm = 1.7794e-01, time/batch = 16.5406s	
21313/33150 (epoch 32.146), train_loss = 0.97696679, grad/param norm = 2.1291e-01, time/batch = 17.9691s	
21314/33150 (epoch 32.148), train_loss = 1.02960603, grad/param norm = 1.5934e-01, time/batch = 17.6390s	
21315/33150 (epoch 32.149), train_loss = 0.92892477, grad/param norm = 1.6996e-01, time/batch = 17.4590s	
21316/33150 (epoch 32.151), train_loss = 1.05800639, grad/param norm = 1.7748e-01, time/batch = 16.5496s	
21317/33150 (epoch 32.152), train_loss = 0.84414389, grad/param norm = 1.5337e-01, time/batch = 16.8875s	
21318/33150 (epoch 32.154), train_loss = 0.84899269, grad/param norm = 1.6375e-01, time/batch = 17.0686s	
21319/33150 (epoch 32.155), train_loss = 0.75184283, grad/param norm = 1.5204e-01, time/batch = 16.1183s	
21320/33150 (epoch 32.157), train_loss = 0.86776621, grad/param norm = 1.7272e-01, time/batch = 18.4724s	
21321/33150 (epoch 32.158), train_loss = 0.85558281, grad/param norm = 1.5627e-01, time/batch = 18.0557s	
21322/33150 (epoch 32.160), train_loss = 0.95721369, grad/param norm = 1.6783e-01, time/batch = 17.2209s	
21323/33150 (epoch 32.161), train_loss = 0.83210938, grad/param norm = 1.9607e-01, time/batch = 16.5623s	
21324/33150 (epoch 32.163), train_loss = 0.77838287, grad/param norm = 1.5542e-01, time/batch = 18.3074s	
21325/33150 (epoch 32.164), train_loss = 0.92618035, grad/param norm = 1.6414e-01, time/batch = 20.0300s	
21326/33150 (epoch 32.166), train_loss = 0.86908659, grad/param norm = 1.6150e-01, time/batch = 17.7901s	
21327/33150 (epoch 32.167), train_loss = 0.91487850, grad/param norm = 1.6337e-01, time/batch = 18.3758s	
21328/33150 (epoch 32.169), train_loss = 0.94046641, grad/param norm = 1.9682e-01, time/batch = 20.2178s	
21329/33150 (epoch 32.170), train_loss = 0.83122627, grad/param norm = 1.8574e-01, time/batch = 17.0581s	
21330/33150 (epoch 32.172), train_loss = 0.96688860, grad/param norm = 2.1764e-01, time/batch = 18.3708s	
21331/33150 (epoch 32.173), train_loss = 0.95321551, grad/param norm = 2.0740e-01, time/batch = 17.0213s	
21332/33150 (epoch 32.175), train_loss = 0.85382440, grad/param norm = 1.8417e-01, time/batch = 18.1771s	
21333/33150 (epoch 32.176), train_loss = 0.97010460, grad/param norm = 1.9526e-01, time/batch = 19.5196s	
21334/33150 (epoch 32.178), train_loss = 1.08206010, grad/param norm = 1.9830e-01, time/batch = 17.0401s	
21335/33150 (epoch 32.179), train_loss = 0.96784471, grad/param norm = 1.6958e-01, time/batch = 18.4499s	
21336/33150 (epoch 32.181), train_loss = 0.90857119, grad/param norm = 1.8698e-01, time/batch = 6.7096s	
21337/33150 (epoch 32.183), train_loss = 0.89770084, grad/param norm = 2.0005e-01, time/batch = 0.6528s	
21338/33150 (epoch 32.184), train_loss = 1.13258880, grad/param norm = 1.9273e-01, time/batch = 0.6544s	
21339/33150 (epoch 32.186), train_loss = 1.03676871, grad/param norm = 1.8098e-01, time/batch = 0.6556s	
21340/33150 (epoch 32.187), train_loss = 0.91737775, grad/param norm = 1.8763e-01, time/batch = 0.6546s	
21341/33150 (epoch 32.189), train_loss = 0.70323793, grad/param norm = 1.6168e-01, time/batch = 0.6574s	
21342/33150 (epoch 32.190), train_loss = 0.80358853, grad/param norm = 1.6009e-01, time/batch = 0.6571s	
21343/33150 (epoch 32.192), train_loss = 0.92645435, grad/param norm = 2.0785e-01, time/batch = 0.6733s	
21344/33150 (epoch 32.193), train_loss = 0.98266011, grad/param norm = 1.8087e-01, time/batch = 0.9538s	
21345/33150 (epoch 32.195), train_loss = 1.10997764, grad/param norm = 1.9888e-01, time/batch = 0.9658s	
21346/33150 (epoch 32.196), train_loss = 1.03631386, grad/param norm = 1.9183e-01, time/batch = 0.9591s	
21347/33150 (epoch 32.198), train_loss = 0.79299095, grad/param norm = 2.0844e-01, time/batch = 0.9785s	
21348/33150 (epoch 32.199), train_loss = 0.97449537, grad/param norm = 2.1481e-01, time/batch = 0.9539s	
21349/33150 (epoch 32.201), train_loss = 0.84558051, grad/param norm = 1.4710e-01, time/batch = 1.7275s	
21350/33150 (epoch 32.202), train_loss = 0.72620508, grad/param norm = 1.6426e-01, time/batch = 1.8391s	
21351/33150 (epoch 32.204), train_loss = 0.95921804, grad/param norm = 1.8595e-01, time/batch = 4.4944s	
21352/33150 (epoch 32.205), train_loss = 0.95037659, grad/param norm = 2.1465e-01, time/batch = 17.8003s	
21353/33150 (epoch 32.207), train_loss = 0.95089174, grad/param norm = 1.5765e-01, time/batch = 18.2951s	
21354/33150 (epoch 32.208), train_loss = 0.95896461, grad/param norm = 1.6334e-01, time/batch = 17.7926s	
21355/33150 (epoch 32.210), train_loss = 0.85513499, grad/param norm = 1.5408e-01, time/batch = 19.4645s	
21356/33150 (epoch 32.211), train_loss = 0.91578206, grad/param norm = 1.8045e-01, time/batch = 17.9587s	
21357/33150 (epoch 32.213), train_loss = 0.95776542, grad/param norm = 1.6211e-01, time/batch = 18.0321s	
21358/33150 (epoch 32.214), train_loss = 0.87626792, grad/param norm = 1.7901e-01, time/batch = 19.6779s	
21359/33150 (epoch 32.216), train_loss = 0.82097567, grad/param norm = 1.8777e-01, time/batch = 19.3836s	
21360/33150 (epoch 32.217), train_loss = 0.87846501, grad/param norm = 1.8404e-01, time/batch = 17.6992s	
21361/33150 (epoch 32.219), train_loss = 0.82646296, grad/param norm = 1.5717e-01, time/batch = 17.9507s	
21362/33150 (epoch 32.220), train_loss = 0.86229345, grad/param norm = 1.5114e-01, time/batch = 18.7741s	
21363/33150 (epoch 32.222), train_loss = 1.01246232, grad/param norm = 1.8787e-01, time/batch = 16.1246s	
21364/33150 (epoch 32.223), train_loss = 0.88099747, grad/param norm = 1.6842e-01, time/batch = 18.0423s	
21365/33150 (epoch 32.225), train_loss = 1.01273965, grad/param norm = 1.5672e-01, time/batch = 17.3229s	
21366/33150 (epoch 32.226), train_loss = 0.88825157, grad/param norm = 1.8474e-01, time/batch = 18.4653s	
21367/33150 (epoch 32.228), train_loss = 0.87297826, grad/param norm = 1.7450e-01, time/batch = 3.8031s	
21368/33150 (epoch 32.229), train_loss = 0.89758681, grad/param norm = 1.7671e-01, time/batch = 0.6815s	
21369/33150 (epoch 32.231), train_loss = 0.99327437, grad/param norm = 1.9771e-01, time/batch = 0.6718s	
21370/33150 (epoch 32.232), train_loss = 0.91648576, grad/param norm = 1.9163e-01, time/batch = 0.6581s	
21371/33150 (epoch 32.234), train_loss = 0.93198364, grad/param norm = 1.9780e-01, time/batch = 0.6613s	
21372/33150 (epoch 32.235), train_loss = 0.96916865, grad/param norm = 2.3807e-01, time/batch = 0.6634s	
21373/33150 (epoch 32.237), train_loss = 0.91093706, grad/param norm = 1.9733e-01, time/batch = 0.6633s	
21374/33150 (epoch 32.238), train_loss = 0.97937621, grad/param norm = 1.9142e-01, time/batch = 0.6625s	
21375/33150 (epoch 32.240), train_loss = 0.94473608, grad/param norm = 1.8741e-01, time/batch = 0.6581s	
21376/33150 (epoch 32.241), train_loss = 1.00189704, grad/param norm = 2.0840e-01, time/batch = 0.6565s	
21377/33150 (epoch 32.243), train_loss = 0.97538678, grad/param norm = 1.8561e-01, time/batch = 0.6597s	
21378/33150 (epoch 32.244), train_loss = 0.90713284, grad/param norm = 1.7609e-01, time/batch = 0.6608s	
21379/33150 (epoch 32.246), train_loss = 0.97526281, grad/param norm = 1.6868e-01, time/batch = 0.6584s	
21380/33150 (epoch 32.247), train_loss = 0.85060999, grad/param norm = 1.6153e-01, time/batch = 0.6593s	
21381/33150 (epoch 32.249), train_loss = 1.02594069, grad/param norm = 2.8829e-01, time/batch = 0.6606s	
21382/33150 (epoch 32.250), train_loss = 0.96147765, grad/param norm = 1.6659e-01, time/batch = 0.6633s	
21383/33150 (epoch 32.252), train_loss = 0.96276911, grad/param norm = 1.5808e-01, time/batch = 0.6610s	
21384/33150 (epoch 32.253), train_loss = 0.88573852, grad/param norm = 1.6848e-01, time/batch = 0.6595s	
21385/33150 (epoch 32.255), train_loss = 0.90343365, grad/param norm = 1.4899e-01, time/batch = 0.6614s	
21386/33150 (epoch 32.256), train_loss = 1.01647444, grad/param norm = 1.7325e-01, time/batch = 0.6624s	
21387/33150 (epoch 32.258), train_loss = 0.84821696, grad/param norm = 1.8777e-01, time/batch = 0.6705s	
21388/33150 (epoch 32.259), train_loss = 0.74615011, grad/param norm = 1.8052e-01, time/batch = 0.6587s	
21389/33150 (epoch 32.261), train_loss = 0.79235820, grad/param norm = 1.5476e-01, time/batch = 0.6655s	
21390/33150 (epoch 32.262), train_loss = 0.98833801, grad/param norm = 1.7891e-01, time/batch = 0.6592s	
21391/33150 (epoch 32.264), train_loss = 0.69904348, grad/param norm = 1.3323e-01, time/batch = 0.6564s	
21392/33150 (epoch 32.265), train_loss = 0.92355300, grad/param norm = 1.7518e-01, time/batch = 0.6595s	
21393/33150 (epoch 32.267), train_loss = 0.98641238, grad/param norm = 2.0194e-01, time/batch = 0.6589s	
21394/33150 (epoch 32.268), train_loss = 1.01342059, grad/param norm = 1.6521e-01, time/batch = 0.6553s	
21395/33150 (epoch 32.270), train_loss = 1.09658054, grad/param norm = 1.6772e-01, time/batch = 0.6579s	
21396/33150 (epoch 32.271), train_loss = 1.01101602, grad/param norm = 2.2153e-01, time/batch = 0.6572s	
21397/33150 (epoch 32.273), train_loss = 1.03856848, grad/param norm = 1.8783e-01, time/batch = 0.6584s	
21398/33150 (epoch 32.275), train_loss = 1.06236300, grad/param norm = 1.9055e-01, time/batch = 0.6579s	
21399/33150 (epoch 32.276), train_loss = 0.92134177, grad/param norm = 1.6901e-01, time/batch = 0.6563s	
21400/33150 (epoch 32.278), train_loss = 1.02665167, grad/param norm = 1.7667e-01, time/batch = 0.6535s	
21401/33150 (epoch 32.279), train_loss = 0.96346407, grad/param norm = 1.5348e-01, time/batch = 0.6551s	
21402/33150 (epoch 32.281), train_loss = 0.90410651, grad/param norm = 1.6680e-01, time/batch = 0.6576s	
21403/33150 (epoch 32.282), train_loss = 0.93243157, grad/param norm = 1.3883e-01, time/batch = 0.6690s	
21404/33150 (epoch 32.284), train_loss = 0.82838935, grad/param norm = 1.5761e-01, time/batch = 0.6660s	
21405/33150 (epoch 32.285), train_loss = 0.92636144, grad/param norm = 1.7318e-01, time/batch = 0.6579s	
21406/33150 (epoch 32.287), train_loss = 0.82188268, grad/param norm = 1.8480e-01, time/batch = 0.6582s	
21407/33150 (epoch 32.288), train_loss = 0.98721551, grad/param norm = 1.6883e-01, time/batch = 0.6698s	
21408/33150 (epoch 32.290), train_loss = 0.77988352, grad/param norm = 1.5666e-01, time/batch = 0.6772s	
21409/33150 (epoch 32.291), train_loss = 0.76049228, grad/param norm = 1.5754e-01, time/batch = 0.6613s	
21410/33150 (epoch 32.293), train_loss = 0.90841028, grad/param norm = 1.6533e-01, time/batch = 0.6650s	
21411/33150 (epoch 32.294), train_loss = 0.71203804, grad/param norm = 1.5294e-01, time/batch = 0.6506s	
21412/33150 (epoch 32.296), train_loss = 0.89385267, grad/param norm = 1.4555e-01, time/batch = 0.6542s	
21413/33150 (epoch 32.297), train_loss = 0.84113766, grad/param norm = 1.6170e-01, time/batch = 0.6624s	
21414/33150 (epoch 32.299), train_loss = 0.87391333, grad/param norm = 1.8943e-01, time/batch = 0.6675s	
21415/33150 (epoch 32.300), train_loss = 0.84663750, grad/param norm = 1.4788e-01, time/batch = 0.6596s	
21416/33150 (epoch 32.302), train_loss = 0.88318483, grad/param norm = 1.6805e-01, time/batch = 0.6569s	
21417/33150 (epoch 32.303), train_loss = 0.85901297, grad/param norm = 1.7362e-01, time/batch = 0.6590s	
21418/33150 (epoch 32.305), train_loss = 0.95312026, grad/param norm = 1.6144e-01, time/batch = 0.6704s	
21419/33150 (epoch 32.306), train_loss = 0.95393037, grad/param norm = 1.7848e-01, time/batch = 0.6605s	
21420/33150 (epoch 32.308), train_loss = 1.12261913, grad/param norm = 1.9960e-01, time/batch = 0.6498s	
21421/33150 (epoch 32.309), train_loss = 0.74824924, grad/param norm = 1.4424e-01, time/batch = 0.6560s	
21422/33150 (epoch 32.311), train_loss = 0.87524204, grad/param norm = 1.8692e-01, time/batch = 0.6547s	
21423/33150 (epoch 32.312), train_loss = 0.72120844, grad/param norm = 1.4909e-01, time/batch = 0.6551s	
21424/33150 (epoch 32.314), train_loss = 0.86955860, grad/param norm = 1.7627e-01, time/batch = 0.6539s	
21425/33150 (epoch 32.315), train_loss = 0.94727207, grad/param norm = 1.5580e-01, time/batch = 0.6522s	
21426/33150 (epoch 32.317), train_loss = 0.71942675, grad/param norm = 1.3393e-01, time/batch = 0.6542s	
21427/33150 (epoch 32.318), train_loss = 0.82251068, grad/param norm = 1.4853e-01, time/batch = 0.6550s	
21428/33150 (epoch 32.320), train_loss = 0.76301724, grad/param norm = 1.4973e-01, time/batch = 0.6579s	
21429/33150 (epoch 32.321), train_loss = 0.88460783, grad/param norm = 1.5566e-01, time/batch = 0.6559s	
21430/33150 (epoch 32.323), train_loss = 0.84696269, grad/param norm = 1.6346e-01, time/batch = 0.6561s	
21431/33150 (epoch 32.324), train_loss = 0.91582223, grad/param norm = 2.0358e-01, time/batch = 0.6575s	
21432/33150 (epoch 32.326), train_loss = 0.91152037, grad/param norm = 1.5680e-01, time/batch = 0.6595s	
21433/33150 (epoch 32.327), train_loss = 0.98525285, grad/param norm = 1.9343e-01, time/batch = 0.6695s	
21434/33150 (epoch 32.329), train_loss = 0.92408350, grad/param norm = 1.6104e-01, time/batch = 0.6651s	
21435/33150 (epoch 32.330), train_loss = 0.87743960, grad/param norm = 1.8889e-01, time/batch = 0.6592s	
21436/33150 (epoch 32.332), train_loss = 0.87535154, grad/param norm = 1.5022e-01, time/batch = 0.6582s	
21437/33150 (epoch 32.333), train_loss = 0.94931404, grad/param norm = 1.5153e-01, time/batch = 0.6574s	
21438/33150 (epoch 32.335), train_loss = 0.81760858, grad/param norm = 1.5638e-01, time/batch = 0.6565s	
21439/33150 (epoch 32.336), train_loss = 0.80422341, grad/param norm = 1.7123e-01, time/batch = 0.6567s	
21440/33150 (epoch 32.338), train_loss = 0.74499176, grad/param norm = 1.6123e-01, time/batch = 0.6541s	
21441/33150 (epoch 32.339), train_loss = 0.97537270, grad/param norm = 1.7238e-01, time/batch = 0.6588s	
21442/33150 (epoch 32.341), train_loss = 0.90744006, grad/param norm = 2.0806e-01, time/batch = 0.6562s	
21443/33150 (epoch 32.342), train_loss = 0.82432102, grad/param norm = 1.6602e-01, time/batch = 0.6540s	
21444/33150 (epoch 32.344), train_loss = 0.88889449, grad/param norm = 1.6751e-01, time/batch = 0.6544s	
21445/33150 (epoch 32.345), train_loss = 0.86968197, grad/param norm = 1.6322e-01, time/batch = 0.6579s	
21446/33150 (epoch 32.347), train_loss = 0.73642301, grad/param norm = 1.7386e-01, time/batch = 0.6529s	
21447/33150 (epoch 32.348), train_loss = 0.91897056, grad/param norm = 1.7446e-01, time/batch = 0.6561s	
21448/33150 (epoch 32.350), train_loss = 0.80230006, grad/param norm = 1.8204e-01, time/batch = 0.6547s	
21449/33150 (epoch 32.351), train_loss = 0.95688648, grad/param norm = 1.8612e-01, time/batch = 0.6520s	
21450/33150 (epoch 32.353), train_loss = 0.92667223, grad/param norm = 1.6534e-01, time/batch = 0.6549s	
21451/33150 (epoch 32.354), train_loss = 1.10308596, grad/param norm = 1.6944e-01, time/batch = 0.6569s	
21452/33150 (epoch 32.356), train_loss = 0.98227169, grad/param norm = 1.7754e-01, time/batch = 0.6722s	
21453/33150 (epoch 32.357), train_loss = 0.93612778, grad/param norm = 1.9419e-01, time/batch = 0.6759s	
21454/33150 (epoch 32.359), train_loss = 0.96118407, grad/param norm = 1.6992e-01, time/batch = 0.6683s	
21455/33150 (epoch 32.360), train_loss = 0.94564416, grad/param norm = 2.2440e-01, time/batch = 0.6629s	
21456/33150 (epoch 32.362), train_loss = 1.02285617, grad/param norm = 1.8065e-01, time/batch = 0.6589s	
21457/33150 (epoch 32.363), train_loss = 0.92081207, grad/param norm = 1.5493e-01, time/batch = 0.6558s	
21458/33150 (epoch 32.365), train_loss = 0.87975602, grad/param norm = 1.5947e-01, time/batch = 0.6599s	
21459/33150 (epoch 32.367), train_loss = 0.84517774, grad/param norm = 1.5745e-01, time/batch = 0.6606s	
21460/33150 (epoch 32.368), train_loss = 0.87275992, grad/param norm = 1.8593e-01, time/batch = 0.6576s	
21461/33150 (epoch 32.370), train_loss = 0.91235221, grad/param norm = 2.1046e-01, time/batch = 0.6615s	
21462/33150 (epoch 32.371), train_loss = 0.80245461, grad/param norm = 1.6505e-01, time/batch = 0.6606s	
21463/33150 (epoch 32.373), train_loss = 0.92295390, grad/param norm = 2.1122e-01, time/batch = 0.6737s	
21464/33150 (epoch 32.374), train_loss = 0.87385706, grad/param norm = 1.4712e-01, time/batch = 0.6690s	
21465/33150 (epoch 32.376), train_loss = 0.97868476, grad/param norm = 1.6580e-01, time/batch = 0.6601s	
21466/33150 (epoch 32.377), train_loss = 0.82404939, grad/param norm = 1.7779e-01, time/batch = 0.6591s	
21467/33150 (epoch 32.379), train_loss = 0.94757511, grad/param norm = 2.0200e-01, time/batch = 0.6809s	
21468/33150 (epoch 32.380), train_loss = 0.95101168, grad/param norm = 1.4506e-01, time/batch = 0.6721s	
21469/33150 (epoch 32.382), train_loss = 0.89306470, grad/param norm = 1.6628e-01, time/batch = 0.6584s	
21470/33150 (epoch 32.383), train_loss = 0.82498444, grad/param norm = 1.8467e-01, time/batch = 0.6581s	
21471/33150 (epoch 32.385), train_loss = 0.87055108, grad/param norm = 1.8822e-01, time/batch = 0.6583s	
21472/33150 (epoch 32.386), train_loss = 0.79437224, grad/param norm = 1.5985e-01, time/batch = 0.6551s	
21473/33150 (epoch 32.388), train_loss = 0.82427662, grad/param norm = 1.6435e-01, time/batch = 0.6785s	
21474/33150 (epoch 32.389), train_loss = 0.83389363, grad/param norm = 1.6381e-01, time/batch = 0.6615s	
21475/33150 (epoch 32.391), train_loss = 1.03559632, grad/param norm = 1.8639e-01, time/batch = 0.6674s	
21476/33150 (epoch 32.392), train_loss = 0.85372052, grad/param norm = 1.6675e-01, time/batch = 0.6690s	
21477/33150 (epoch 32.394), train_loss = 0.76205665, grad/param norm = 1.4613e-01, time/batch = 0.6761s	
21478/33150 (epoch 32.395), train_loss = 0.72356559, grad/param norm = 1.4923e-01, time/batch = 0.6771s	
21479/33150 (epoch 32.397), train_loss = 0.62750216, grad/param norm = 1.5985e-01, time/batch = 0.6735s	
21480/33150 (epoch 32.398), train_loss = 0.88157294, grad/param norm = 1.6125e-01, time/batch = 0.6766s	
21481/33150 (epoch 32.400), train_loss = 0.86257503, grad/param norm = 1.4031e-01, time/batch = 0.6784s	
21482/33150 (epoch 32.401), train_loss = 0.75572265, grad/param norm = 1.3530e-01, time/batch = 0.6760s	
21483/33150 (epoch 32.403), train_loss = 0.74991499, grad/param norm = 1.4411e-01, time/batch = 0.6729s	
21484/33150 (epoch 32.404), train_loss = 0.89979696, grad/param norm = 1.6930e-01, time/batch = 0.6742s	
21485/33150 (epoch 32.406), train_loss = 0.83495666, grad/param norm = 1.3521e-01, time/batch = 0.6619s	
21486/33150 (epoch 32.407), train_loss = 0.76611208, grad/param norm = 1.5287e-01, time/batch = 0.6551s	
21487/33150 (epoch 32.409), train_loss = 0.72515340, grad/param norm = 1.3621e-01, time/batch = 0.6636s	
21488/33150 (epoch 32.410), train_loss = 0.91467911, grad/param norm = 1.6899e-01, time/batch = 0.6643s	
21489/33150 (epoch 32.412), train_loss = 0.92547648, grad/param norm = 1.5376e-01, time/batch = 0.6598s	
21490/33150 (epoch 32.413), train_loss = 0.78781502, grad/param norm = 1.5516e-01, time/batch = 0.6581s	
21491/33150 (epoch 32.415), train_loss = 0.91204793, grad/param norm = 1.6186e-01, time/batch = 0.6574s	
21492/33150 (epoch 32.416), train_loss = 0.81238533, grad/param norm = 1.5012e-01, time/batch = 0.6617s	
21493/33150 (epoch 32.418), train_loss = 0.93127911, grad/param norm = 1.9810e-01, time/batch = 0.6685s	
21494/33150 (epoch 32.419), train_loss = 0.86840091, grad/param norm = 1.6281e-01, time/batch = 0.6648s	
21495/33150 (epoch 32.421), train_loss = 0.88377577, grad/param norm = 1.9627e-01, time/batch = 0.6615s	
21496/33150 (epoch 32.422), train_loss = 0.82897973, grad/param norm = 1.6750e-01, time/batch = 0.6568s	
21497/33150 (epoch 32.424), train_loss = 0.82802049, grad/param norm = 1.7698e-01, time/batch = 0.6598s	
21498/33150 (epoch 32.425), train_loss = 0.95566210, grad/param norm = 1.6745e-01, time/batch = 0.6599s	
21499/33150 (epoch 32.427), train_loss = 0.88614883, grad/param norm = 1.5103e-01, time/batch = 0.6559s	
21500/33150 (epoch 32.428), train_loss = 0.86472530, grad/param norm = 1.5703e-01, time/batch = 0.6520s	
21501/33150 (epoch 32.430), train_loss = 0.89806357, grad/param norm = 1.8630e-01, time/batch = 0.6592s	
21502/33150 (epoch 32.431), train_loss = 0.94398093, grad/param norm = 1.9656e-01, time/batch = 0.6570s	
21503/33150 (epoch 32.433), train_loss = 0.86653688, grad/param norm = 1.6167e-01, time/batch = 0.6539s	
21504/33150 (epoch 32.434), train_loss = 0.76757111, grad/param norm = 1.5479e-01, time/batch = 0.6590s	
21505/33150 (epoch 32.436), train_loss = 0.87055252, grad/param norm = 1.5524e-01, time/batch = 0.6579s	
21506/33150 (epoch 32.437), train_loss = 0.89132338, grad/param norm = 1.9847e-01, time/batch = 0.6550s	
21507/33150 (epoch 32.439), train_loss = 1.03848634, grad/param norm = 1.6498e-01, time/batch = 0.6614s	
21508/33150 (epoch 32.440), train_loss = 0.92949815, grad/param norm = 1.7955e-01, time/batch = 0.6587s	
21509/33150 (epoch 32.442), train_loss = 0.78179657, grad/param norm = 1.6343e-01, time/batch = 0.6663s	
21510/33150 (epoch 32.443), train_loss = 0.92076062, grad/param norm = 1.8788e-01, time/batch = 0.6580s	
21511/33150 (epoch 32.445), train_loss = 0.88636100, grad/param norm = 1.8840e-01, time/batch = 0.6573s	
21512/33150 (epoch 32.446), train_loss = 0.92118702, grad/param norm = 2.1649e-01, time/batch = 0.6553s	
21513/33150 (epoch 32.448), train_loss = 0.99002378, grad/param norm = 1.8189e-01, time/batch = 0.6572s	
21514/33150 (epoch 32.449), train_loss = 0.89149977, grad/param norm = 1.5111e-01, time/batch = 0.6524s	
21515/33150 (epoch 32.451), train_loss = 0.91168531, grad/param norm = 2.0520e-01, time/batch = 0.6568s	
21516/33150 (epoch 32.452), train_loss = 1.05970394, grad/param norm = 1.8207e-01, time/batch = 0.6566s	
21517/33150 (epoch 32.454), train_loss = 0.86833728, grad/param norm = 1.5593e-01, time/batch = 0.6562s	
21518/33150 (epoch 32.456), train_loss = 0.81402749, grad/param norm = 1.5664e-01, time/batch = 0.6580s	
21519/33150 (epoch 32.457), train_loss = 0.90995592, grad/param norm = 1.7018e-01, time/batch = 0.6580s	
21520/33150 (epoch 32.459), train_loss = 1.00354612, grad/param norm = 2.9933e-01, time/batch = 0.6583s	
21521/33150 (epoch 32.460), train_loss = 0.94456016, grad/param norm = 1.4756e-01, time/batch = 0.6604s	
21522/33150 (epoch 32.462), train_loss = 0.98359107, grad/param norm = 2.0902e-01, time/batch = 0.6574s	
21523/33150 (epoch 32.463), train_loss = 1.14700336, grad/param norm = 2.7967e-01, time/batch = 0.6581s	
21524/33150 (epoch 32.465), train_loss = 0.93920942, grad/param norm = 1.6796e-01, time/batch = 0.6575s	
21525/33150 (epoch 32.466), train_loss = 0.85894733, grad/param norm = 1.6016e-01, time/batch = 0.6561s	
21526/33150 (epoch 32.468), train_loss = 1.10221186, grad/param norm = 1.7582e-01, time/batch = 0.6588s	
21527/33150 (epoch 32.469), train_loss = 0.85428466, grad/param norm = 1.7008e-01, time/batch = 0.6594s	
21528/33150 (epoch 32.471), train_loss = 0.82404484, grad/param norm = 1.5778e-01, time/batch = 0.6579s	
21529/33150 (epoch 32.472), train_loss = 0.91942897, grad/param norm = 1.9353e-01, time/batch = 0.6549s	
21530/33150 (epoch 32.474), train_loss = 0.97771194, grad/param norm = 2.3055e-01, time/batch = 0.6566s	
21531/33150 (epoch 32.475), train_loss = 1.13457676, grad/param norm = 1.9724e-01, time/batch = 0.6566s	
21532/33150 (epoch 32.477), train_loss = 0.97992490, grad/param norm = 1.8411e-01, time/batch = 0.6565s	
21533/33150 (epoch 32.478), train_loss = 0.94564182, grad/param norm = 1.6459e-01, time/batch = 0.6558s	
21534/33150 (epoch 32.480), train_loss = 0.85142778, grad/param norm = 1.8343e-01, time/batch = 0.6572s	
21535/33150 (epoch 32.481), train_loss = 0.76028023, grad/param norm = 1.5824e-01, time/batch = 0.6570s	
21536/33150 (epoch 32.483), train_loss = 0.86809038, grad/param norm = 1.6767e-01, time/batch = 0.6645s	
21537/33150 (epoch 32.484), train_loss = 0.83493489, grad/param norm = 1.6824e-01, time/batch = 0.6546s	
21538/33150 (epoch 32.486), train_loss = 0.81276809, grad/param norm = 1.5867e-01, time/batch = 0.6574s	
21539/33150 (epoch 32.487), train_loss = 0.93132986, grad/param norm = 1.7147e-01, time/batch = 0.6552s	
21540/33150 (epoch 32.489), train_loss = 0.88634930, grad/param norm = 1.6074e-01, time/batch = 0.6546s	
21541/33150 (epoch 32.490), train_loss = 0.73597635, grad/param norm = 1.6027e-01, time/batch = 0.6574s	
21542/33150 (epoch 32.492), train_loss = 0.84732120, grad/param norm = 1.7572e-01, time/batch = 0.6750s	
21543/33150 (epoch 32.493), train_loss = 0.97195563, grad/param norm = 1.7077e-01, time/batch = 0.6717s	
21544/33150 (epoch 32.495), train_loss = 0.96176431, grad/param norm = 1.6060e-01, time/batch = 0.6781s	
21545/33150 (epoch 32.496), train_loss = 0.85906735, grad/param norm = 1.4776e-01, time/batch = 0.6607s	
21546/33150 (epoch 32.498), train_loss = 1.00382023, grad/param norm = 2.5898e-01, time/batch = 0.6628s	
21547/33150 (epoch 32.499), train_loss = 0.99351170, grad/param norm = 1.6524e-01, time/batch = 0.6833s	
21548/33150 (epoch 32.501), train_loss = 0.94558489, grad/param norm = 1.8835e-01, time/batch = 0.6791s	
21549/33150 (epoch 32.502), train_loss = 1.00742467, grad/param norm = 1.9552e-01, time/batch = 0.6657s	
21550/33150 (epoch 32.504), train_loss = 0.96446860, grad/param norm = 1.7490e-01, time/batch = 0.6715s	
21551/33150 (epoch 32.505), train_loss = 1.04321859, grad/param norm = 1.8635e-01, time/batch = 0.6673s	
21552/33150 (epoch 32.507), train_loss = 0.83895679, grad/param norm = 1.7012e-01, time/batch = 0.6608s	
21553/33150 (epoch 32.508), train_loss = 0.84932117, grad/param norm = 2.0773e-01, time/batch = 0.6612s	
21554/33150 (epoch 32.510), train_loss = 0.96728703, grad/param norm = 1.5882e-01, time/batch = 0.6632s	
21555/33150 (epoch 32.511), train_loss = 1.01960896, grad/param norm = 1.9460e-01, time/batch = 0.6580s	
21556/33150 (epoch 32.513), train_loss = 0.93179149, grad/param norm = 1.9102e-01, time/batch = 0.6588s	
21557/33150 (epoch 32.514), train_loss = 0.78796639, grad/param norm = 1.6631e-01, time/batch = 0.6598s	
21558/33150 (epoch 32.516), train_loss = 0.92108963, grad/param norm = 2.0588e-01, time/batch = 0.6707s	
21559/33150 (epoch 32.517), train_loss = 0.98297752, grad/param norm = 2.0414e-01, time/batch = 0.6699s	
21560/33150 (epoch 32.519), train_loss = 0.83314806, grad/param norm = 2.0050e-01, time/batch = 0.6638s	
21561/33150 (epoch 32.520), train_loss = 0.92580680, grad/param norm = 1.6089e-01, time/batch = 0.6633s	
21562/33150 (epoch 32.522), train_loss = 0.98596932, grad/param norm = 1.7689e-01, time/batch = 0.6584s	
21563/33150 (epoch 32.523), train_loss = 0.79602043, grad/param norm = 1.5361e-01, time/batch = 0.6604s	
21564/33150 (epoch 32.525), train_loss = 0.94966503, grad/param norm = 1.7335e-01, time/batch = 0.6572s	
21565/33150 (epoch 32.526), train_loss = 0.82369401, grad/param norm = 1.6696e-01, time/batch = 0.6582s	
21566/33150 (epoch 32.528), train_loss = 0.91833789, grad/param norm = 1.6927e-01, time/batch = 0.6597s	
21567/33150 (epoch 32.529), train_loss = 0.89821217, grad/param norm = 1.6446e-01, time/batch = 0.6559s	
21568/33150 (epoch 32.531), train_loss = 0.77126406, grad/param norm = 1.9980e-01, time/batch = 0.6573s	
21569/33150 (epoch 32.532), train_loss = 0.93058538, grad/param norm = 2.0252e-01, time/batch = 0.6562s	
21570/33150 (epoch 32.534), train_loss = 0.89043849, grad/param norm = 1.5870e-01, time/batch = 0.6593s	
21571/33150 (epoch 32.535), train_loss = 0.82560907, grad/param norm = 2.0632e-01, time/batch = 0.6669s	
21572/33150 (epoch 32.537), train_loss = 0.92853275, grad/param norm = 1.8990e-01, time/batch = 0.6690s	
21573/33150 (epoch 32.538), train_loss = 0.81667044, grad/param norm = 1.6590e-01, time/batch = 0.6777s	
21574/33150 (epoch 32.540), train_loss = 0.79453608, grad/param norm = 1.7329e-01, time/batch = 0.6562s	
21575/33150 (epoch 32.541), train_loss = 0.97026851, grad/param norm = 1.6867e-01, time/batch = 0.6552s	
21576/33150 (epoch 32.543), train_loss = 0.92116044, grad/param norm = 1.7821e-01, time/batch = 0.6571s	
21577/33150 (epoch 32.544), train_loss = 0.96553821, grad/param norm = 1.6298e-01, time/batch = 0.6555s	
21578/33150 (epoch 32.546), train_loss = 0.89805270, grad/param norm = 1.8316e-01, time/batch = 0.6568s	
21579/33150 (epoch 32.548), train_loss = 0.85325085, grad/param norm = 1.8625e-01, time/batch = 0.6555s	
21580/33150 (epoch 32.549), train_loss = 0.83257754, grad/param norm = 1.7405e-01, time/batch = 0.6575s	
21581/33150 (epoch 32.551), train_loss = 0.82178965, grad/param norm = 1.5240e-01, time/batch = 0.6570s	
21582/33150 (epoch 32.552), train_loss = 0.70274541, grad/param norm = 1.4347e-01, time/batch = 0.6597s	
21583/33150 (epoch 32.554), train_loss = 0.94361486, grad/param norm = 1.5328e-01, time/batch = 0.6593s	
21584/33150 (epoch 32.555), train_loss = 0.99457229, grad/param norm = 1.9302e-01, time/batch = 0.6518s	
21585/33150 (epoch 32.557), train_loss = 0.72805146, grad/param norm = 1.8016e-01, time/batch = 0.6523s	
21586/33150 (epoch 32.558), train_loss = 0.94631874, grad/param norm = 2.4423e-01, time/batch = 0.6536s	
21587/33150 (epoch 32.560), train_loss = 0.83850596, grad/param norm = 1.7136e-01, time/batch = 0.6498s	
21588/33150 (epoch 32.561), train_loss = 0.75937607, grad/param norm = 1.7937e-01, time/batch = 0.6672s	
21589/33150 (epoch 32.563), train_loss = 0.93662760, grad/param norm = 1.8073e-01, time/batch = 0.6603s	
21590/33150 (epoch 32.564), train_loss = 1.02163686, grad/param norm = 1.6830e-01, time/batch = 0.6565s	
21591/33150 (epoch 32.566), train_loss = 0.83247017, grad/param norm = 1.6059e-01, time/batch = 0.6522s	
21592/33150 (epoch 32.567), train_loss = 0.83010863, grad/param norm = 1.6468e-01, time/batch = 0.6516s	
21593/33150 (epoch 32.569), train_loss = 0.93859142, grad/param norm = 1.9446e-01, time/batch = 0.6553s	
21594/33150 (epoch 32.570), train_loss = 0.94024157, grad/param norm = 1.6406e-01, time/batch = 0.6529s	
21595/33150 (epoch 32.572), train_loss = 0.81346986, grad/param norm = 2.0594e-01, time/batch = 0.6537s	
21596/33150 (epoch 32.573), train_loss = 0.74741752, grad/param norm = 1.3796e-01, time/batch = 0.6553s	
21597/33150 (epoch 32.575), train_loss = 0.85406858, grad/param norm = 1.7335e-01, time/batch = 0.6552s	
21598/33150 (epoch 32.576), train_loss = 0.78054379, grad/param norm = 1.5017e-01, time/batch = 0.6550s	
21599/33150 (epoch 32.578), train_loss = 0.80004252, grad/param norm = 1.4482e-01, time/batch = 0.6593s	
21600/33150 (epoch 32.579), train_loss = 0.77589891, grad/param norm = 1.5549e-01, time/batch = 0.6569s	
21601/33150 (epoch 32.581), train_loss = 0.80262817, grad/param norm = 1.6616e-01, time/batch = 0.6566s	
21602/33150 (epoch 32.582), train_loss = 1.01504887, grad/param norm = 1.6414e-01, time/batch = 0.6603s	
21603/33150 (epoch 32.584), train_loss = 0.98427388, grad/param norm = 1.9421e-01, time/batch = 0.6602s	
21604/33150 (epoch 32.585), train_loss = 0.88775796, grad/param norm = 1.6636e-01, time/batch = 0.6564s	
21605/33150 (epoch 32.587), train_loss = 0.89110995, grad/param norm = 1.6157e-01, time/batch = 0.6591s	
21606/33150 (epoch 32.588), train_loss = 0.81019661, grad/param norm = 1.5410e-01, time/batch = 0.6713s	
21607/33150 (epoch 32.590), train_loss = 0.93169608, grad/param norm = 1.7285e-01, time/batch = 0.6639s	
21608/33150 (epoch 32.591), train_loss = 0.88067272, grad/param norm = 1.6652e-01, time/batch = 0.6605s	
21609/33150 (epoch 32.593), train_loss = 0.94555426, grad/param norm = 1.9092e-01, time/batch = 0.6675s	
21610/33150 (epoch 32.594), train_loss = 0.86562160, grad/param norm = 1.6994e-01, time/batch = 0.6553s	
21611/33150 (epoch 32.596), train_loss = 0.86385159, grad/param norm = 1.6661e-01, time/batch = 0.6566s	
21612/33150 (epoch 32.597), train_loss = 0.78996238, grad/param norm = 2.2758e-01, time/batch = 0.6597s	
21613/33150 (epoch 32.599), train_loss = 1.04447515, grad/param norm = 2.1344e-01, time/batch = 0.6551s	
21614/33150 (epoch 32.600), train_loss = 0.90174421, grad/param norm = 2.5553e-01, time/batch = 0.6541s	
21615/33150 (epoch 32.602), train_loss = 0.89588257, grad/param norm = 1.9665e-01, time/batch = 0.6537s	
21616/33150 (epoch 32.603), train_loss = 1.01559557, grad/param norm = 1.9669e-01, time/batch = 0.6546s	
21617/33150 (epoch 32.605), train_loss = 0.78955181, grad/param norm = 1.5639e-01, time/batch = 0.6516s	
21618/33150 (epoch 32.606), train_loss = 0.81698895, grad/param norm = 2.0239e-01, time/batch = 0.6542s	
21619/33150 (epoch 32.608), train_loss = 0.96063715, grad/param norm = 1.4627e-01, time/batch = 0.6579s	
21620/33150 (epoch 32.609), train_loss = 0.89362711, grad/param norm = 2.7540e-01, time/batch = 0.6570s	
21621/33150 (epoch 32.611), train_loss = 0.79655118, grad/param norm = 1.7366e-01, time/batch = 0.6646s	
21622/33150 (epoch 32.612), train_loss = 0.87853656, grad/param norm = 1.7991e-01, time/batch = 0.6620s	
21623/33150 (epoch 32.614), train_loss = 0.79475168, grad/param norm = 1.4810e-01, time/batch = 0.6691s	
21624/33150 (epoch 32.615), train_loss = 0.79404499, grad/param norm = 1.8025e-01, time/batch = 0.6618s	
21625/33150 (epoch 32.617), train_loss = 0.92921477, grad/param norm = 2.0637e-01, time/batch = 0.6729s	
21626/33150 (epoch 32.618), train_loss = 0.93899887, grad/param norm = 1.8705e-01, time/batch = 0.6578s	
21627/33150 (epoch 32.620), train_loss = 0.84107590, grad/param norm = 1.8448e-01, time/batch = 0.6537s	
21628/33150 (epoch 32.621), train_loss = 0.88685415, grad/param norm = 1.6781e-01, time/batch = 0.6566s	
21629/33150 (epoch 32.623), train_loss = 0.94148567, grad/param norm = 1.5296e-01, time/batch = 0.6566s	
21630/33150 (epoch 32.624), train_loss = 0.83647325, grad/param norm = 1.5854e-01, time/batch = 0.6547s	
21631/33150 (epoch 32.626), train_loss = 0.88676901, grad/param norm = 2.5737e-01, time/batch = 0.6572s	
21632/33150 (epoch 32.627), train_loss = 0.83755619, grad/param norm = 1.6796e-01, time/batch = 0.6615s	
21633/33150 (epoch 32.629), train_loss = 0.75298289, grad/param norm = 1.7264e-01, time/batch = 0.6747s	
21634/33150 (epoch 32.630), train_loss = 0.87218725, grad/param norm = 1.6972e-01, time/batch = 0.6793s	
21635/33150 (epoch 32.632), train_loss = 0.76004947, grad/param norm = 1.4495e-01, time/batch = 0.6714s	
21636/33150 (epoch 32.633), train_loss = 0.78369848, grad/param norm = 1.9311e-01, time/batch = 0.6565s	
21637/33150 (epoch 32.635), train_loss = 1.02182889, grad/param norm = 1.6330e-01, time/batch = 0.6597s	
21638/33150 (epoch 32.637), train_loss = 0.73513107, grad/param norm = 1.6963e-01, time/batch = 0.6563s	
21639/33150 (epoch 32.638), train_loss = 0.86682752, grad/param norm = 1.7661e-01, time/batch = 0.6581s	
21640/33150 (epoch 32.640), train_loss = 0.94655780, grad/param norm = 1.6995e-01, time/batch = 0.6568s	
21641/33150 (epoch 32.641), train_loss = 0.75543230, grad/param norm = 1.7557e-01, time/batch = 0.6556s	
21642/33150 (epoch 32.643), train_loss = 0.88273867, grad/param norm = 1.5651e-01, time/batch = 0.6554s	
21643/33150 (epoch 32.644), train_loss = 1.02089603, grad/param norm = 1.7021e-01, time/batch = 0.6679s	
21644/33150 (epoch 32.646), train_loss = 0.85188968, grad/param norm = 1.6322e-01, time/batch = 0.6718s	
21645/33150 (epoch 32.647), train_loss = 1.05871785, grad/param norm = 1.7635e-01, time/batch = 0.6557s	
21646/33150 (epoch 32.649), train_loss = 0.93834567, grad/param norm = 1.9756e-01, time/batch = 0.6662s	
21647/33150 (epoch 32.650), train_loss = 0.79454080, grad/param norm = 1.6349e-01, time/batch = 0.6669s	
21648/33150 (epoch 32.652), train_loss = 0.99275759, grad/param norm = 2.0248e-01, time/batch = 0.6728s	
21649/33150 (epoch 32.653), train_loss = 0.91752617, grad/param norm = 1.5439e-01, time/batch = 0.6708s	
21650/33150 (epoch 32.655), train_loss = 0.89938828, grad/param norm = 1.7512e-01, time/batch = 0.6723s	
21651/33150 (epoch 32.656), train_loss = 0.84637207, grad/param norm = 1.4716e-01, time/batch = 0.6743s	
21652/33150 (epoch 32.658), train_loss = 0.86415937, grad/param norm = 1.8794e-01, time/batch = 0.6664s	
21653/33150 (epoch 32.659), train_loss = 1.13957009, grad/param norm = 2.1981e-01, time/batch = 0.6709s	
21654/33150 (epoch 32.661), train_loss = 0.88546545, grad/param norm = 1.9150e-01, time/batch = 0.6727s	
21655/33150 (epoch 32.662), train_loss = 0.86113891, grad/param norm = 1.7147e-01, time/batch = 0.6713s	
21656/33150 (epoch 32.664), train_loss = 0.98251342, grad/param norm = 1.7910e-01, time/batch = 0.6747s	
21657/33150 (epoch 32.665), train_loss = 0.97919814, grad/param norm = 1.8572e-01, time/batch = 0.6704s	
21658/33150 (epoch 32.667), train_loss = 0.97060050, grad/param norm = 1.9299e-01, time/batch = 0.6619s	
21659/33150 (epoch 32.668), train_loss = 1.02825859, grad/param norm = 1.8141e-01, time/batch = 0.6563s	
21660/33150 (epoch 32.670), train_loss = 0.83457650, grad/param norm = 1.5885e-01, time/batch = 0.6573s	
21661/33150 (epoch 32.671), train_loss = 0.82790288, grad/param norm = 1.6362e-01, time/batch = 0.6571s	
21662/33150 (epoch 32.673), train_loss = 1.00384730, grad/param norm = 1.5646e-01, time/batch = 0.6567s	
21663/33150 (epoch 32.674), train_loss = 0.94178343, grad/param norm = 1.9386e-01, time/batch = 0.6578s	
21664/33150 (epoch 32.676), train_loss = 0.89071086, grad/param norm = 1.6083e-01, time/batch = 0.6613s	
21665/33150 (epoch 32.677), train_loss = 1.03500685, grad/param norm = 1.9966e-01, time/batch = 0.6587s	
21666/33150 (epoch 32.679), train_loss = 0.88881597, grad/param norm = 1.5714e-01, time/batch = 0.6573s	
21667/33150 (epoch 32.680), train_loss = 1.01363457, grad/param norm = 1.9261e-01, time/batch = 0.6577s	
21668/33150 (epoch 32.682), train_loss = 0.88001129, grad/param norm = 1.5942e-01, time/batch = 0.6689s	
21669/33150 (epoch 32.683), train_loss = 0.77215240, grad/param norm = 1.4838e-01, time/batch = 0.6636s	
21670/33150 (epoch 32.685), train_loss = 0.86526023, grad/param norm = 2.0355e-01, time/batch = 0.6678s	
21671/33150 (epoch 32.686), train_loss = 0.77510108, grad/param norm = 1.5150e-01, time/batch = 0.6628s	
21672/33150 (epoch 32.688), train_loss = 0.79995679, grad/param norm = 1.8728e-01, time/batch = 0.6596s	
21673/33150 (epoch 32.689), train_loss = 0.80774815, grad/param norm = 1.6111e-01, time/batch = 0.6548s	
21674/33150 (epoch 32.691), train_loss = 0.71408211, grad/param norm = 1.3773e-01, time/batch = 0.6546s	
21675/33150 (epoch 32.692), train_loss = 0.79423527, grad/param norm = 1.6855e-01, time/batch = 0.6550s	
21676/33150 (epoch 32.694), train_loss = 0.71027944, grad/param norm = 1.6132e-01, time/batch = 0.6539s	
21677/33150 (epoch 32.695), train_loss = 0.83523428, grad/param norm = 1.5431e-01, time/batch = 0.6543s	
21678/33150 (epoch 32.697), train_loss = 0.76814796, grad/param norm = 1.4870e-01, time/batch = 0.6588s	
21679/33150 (epoch 32.698), train_loss = 0.80578950, grad/param norm = 1.8668e-01, time/batch = 0.6574s	
21680/33150 (epoch 32.700), train_loss = 0.68184820, grad/param norm = 1.3760e-01, time/batch = 0.6576s	
21681/33150 (epoch 32.701), train_loss = 0.76643923, grad/param norm = 1.4418e-01, time/batch = 0.6628s	
21682/33150 (epoch 32.703), train_loss = 0.86777324, grad/param norm = 1.8306e-01, time/batch = 0.6574s	
21683/33150 (epoch 32.704), train_loss = 0.76997805, grad/param norm = 1.4897e-01, time/batch = 0.6693s	
21684/33150 (epoch 32.706), train_loss = 0.82511925, grad/param norm = 1.4400e-01, time/batch = 0.6646s	
21685/33150 (epoch 32.707), train_loss = 0.83249126, grad/param norm = 1.6267e-01, time/batch = 0.6562s	
21686/33150 (epoch 32.709), train_loss = 0.88607099, grad/param norm = 1.4372e-01, time/batch = 0.6555s	
21687/33150 (epoch 32.710), train_loss = 0.86638857, grad/param norm = 1.7082e-01, time/batch = 0.6547s	
21688/33150 (epoch 32.712), train_loss = 0.93807080, grad/param norm = 1.5313e-01, time/batch = 0.6543s	
21689/33150 (epoch 32.713), train_loss = 0.91692755, grad/param norm = 1.5733e-01, time/batch = 0.6559s	
21690/33150 (epoch 32.715), train_loss = 0.83933259, grad/param norm = 1.5498e-01, time/batch = 0.6547s	
21691/33150 (epoch 32.716), train_loss = 0.90212866, grad/param norm = 1.5834e-01, time/batch = 0.6555s	
21692/33150 (epoch 32.718), train_loss = 0.88731156, grad/param norm = 1.5910e-01, time/batch = 0.6557s	
21693/33150 (epoch 32.719), train_loss = 0.96913466, grad/param norm = 1.8177e-01, time/batch = 0.6586s	
21694/33150 (epoch 32.721), train_loss = 0.84889142, grad/param norm = 1.7765e-01, time/batch = 0.6576s	
21695/33150 (epoch 32.722), train_loss = 0.89384858, grad/param norm = 1.4069e-01, time/batch = 0.6774s	
21696/33150 (epoch 32.724), train_loss = 0.84323795, grad/param norm = 1.9189e-01, time/batch = 0.6695s	
21697/33150 (epoch 32.725), train_loss = 0.96478634, grad/param norm = 2.3470e-01, time/batch = 0.6670s	
21698/33150 (epoch 32.727), train_loss = 0.93814618, grad/param norm = 2.0156e-01, time/batch = 0.6613s	
21699/33150 (epoch 32.729), train_loss = 0.86350788, grad/param norm = 1.6256e-01, time/batch = 0.6654s	
21700/33150 (epoch 32.730), train_loss = 0.87848136, grad/param norm = 1.6750e-01, time/batch = 0.6611s	
21701/33150 (epoch 32.732), train_loss = 0.93936125, grad/param norm = 1.8041e-01, time/batch = 0.6576s	
21702/33150 (epoch 32.733), train_loss = 0.75102940, grad/param norm = 1.3614e-01, time/batch = 0.6567s	
21703/33150 (epoch 32.735), train_loss = 0.80318207, grad/param norm = 1.5867e-01, time/batch = 0.6586s	
21704/33150 (epoch 32.736), train_loss = 0.85244533, grad/param norm = 1.6739e-01, time/batch = 0.6597s	
21705/33150 (epoch 32.738), train_loss = 0.88746387, grad/param norm = 1.9828e-01, time/batch = 0.6565s	
21706/33150 (epoch 32.739), train_loss = 0.96475201, grad/param norm = 1.9221e-01, time/batch = 0.6575s	
21707/33150 (epoch 32.741), train_loss = 0.93867414, grad/param norm = 1.8618e-01, time/batch = 0.6575s	
21708/33150 (epoch 32.742), train_loss = 0.75837780, grad/param norm = 1.7911e-01, time/batch = 0.6665s	
21709/33150 (epoch 32.744), train_loss = 0.95329447, grad/param norm = 1.8782e-01, time/batch = 0.6629s	
21710/33150 (epoch 32.745), train_loss = 0.83701174, grad/param norm = 1.4574e-01, time/batch = 0.6592s	
21711/33150 (epoch 32.747), train_loss = 0.66689175, grad/param norm = 1.4798e-01, time/batch = 0.6560s	
21712/33150 (epoch 32.748), train_loss = 0.75957747, grad/param norm = 1.6927e-01, time/batch = 0.6608s	
21713/33150 (epoch 32.750), train_loss = 0.90876069, grad/param norm = 1.8046e-01, time/batch = 0.6606s	
21714/33150 (epoch 32.751), train_loss = 0.86620843, grad/param norm = 1.6207e-01, time/batch = 0.6617s	
21715/33150 (epoch 32.753), train_loss = 0.76846506, grad/param norm = 1.9695e-01, time/batch = 0.6569s	
21716/33150 (epoch 32.754), train_loss = 1.06118113, grad/param norm = 1.9728e-01, time/batch = 0.6570s	
21717/33150 (epoch 32.756), train_loss = 0.87168226, grad/param norm = 2.1285e-01, time/batch = 0.6583s	
21718/33150 (epoch 32.757), train_loss = 0.90304637, grad/param norm = 1.6734e-01, time/batch = 0.6669s	
21719/33150 (epoch 32.759), train_loss = 1.02378341, grad/param norm = 2.0511e-01, time/batch = 0.6559s	
21720/33150 (epoch 32.760), train_loss = 0.92198541, grad/param norm = 1.8793e-01, time/batch = 0.6536s	
21721/33150 (epoch 32.762), train_loss = 0.91367473, grad/param norm = 1.9330e-01, time/batch = 0.6571s	
21722/33150 (epoch 32.763), train_loss = 0.92275266, grad/param norm = 1.7766e-01, time/batch = 0.6588s	
21723/33150 (epoch 32.765), train_loss = 0.85744946, grad/param norm = 1.5402e-01, time/batch = 0.6726s	
21724/33150 (epoch 32.766), train_loss = 0.77889611, grad/param norm = 1.6028e-01, time/batch = 0.6765s	
21725/33150 (epoch 32.768), train_loss = 0.80028437, grad/param norm = 1.5931e-01, time/batch = 0.6916s	
21726/33150 (epoch 32.769), train_loss = 0.93708822, grad/param norm = 1.7626e-01, time/batch = 0.6673s	
21727/33150 (epoch 32.771), train_loss = 0.88805178, grad/param norm = 1.6607e-01, time/batch = 0.6574s	
21728/33150 (epoch 32.772), train_loss = 0.92887233, grad/param norm = 1.8846e-01, time/batch = 0.6570s	
21729/33150 (epoch 32.774), train_loss = 1.02370384, grad/param norm = 1.7515e-01, time/batch = 0.6661s	
21730/33150 (epoch 32.775), train_loss = 0.94262836, grad/param norm = 2.2562e-01, time/batch = 0.6548s	
21731/33150 (epoch 32.777), train_loss = 0.95175388, grad/param norm = 1.7864e-01, time/batch = 0.6534s	
21732/33150 (epoch 32.778), train_loss = 0.89082256, grad/param norm = 1.5880e-01, time/batch = 0.6596s	
21733/33150 (epoch 32.780), train_loss = 0.76514695, grad/param norm = 1.5592e-01, time/batch = 0.6695s	
21734/33150 (epoch 32.781), train_loss = 0.88665235, grad/param norm = 1.6567e-01, time/batch = 0.6551s	
21735/33150 (epoch 32.783), train_loss = 0.88101964, grad/param norm = 1.6041e-01, time/batch = 0.6504s	
21736/33150 (epoch 32.784), train_loss = 0.86828892, grad/param norm = 1.7951e-01, time/batch = 0.6531s	
21737/33150 (epoch 32.786), train_loss = 0.86594920, grad/param norm = 1.6349e-01, time/batch = 0.6553s	
21738/33150 (epoch 32.787), train_loss = 0.80531645, grad/param norm = 1.4614e-01, time/batch = 0.6567s	
21739/33150 (epoch 32.789), train_loss = 0.74694694, grad/param norm = 1.5164e-01, time/batch = 0.6552s	
21740/33150 (epoch 32.790), train_loss = 0.76005285, grad/param norm = 1.7171e-01, time/batch = 0.6570s	
21741/33150 (epoch 32.792), train_loss = 0.88964446, grad/param norm = 1.7942e-01, time/batch = 0.6631s	
21742/33150 (epoch 32.793), train_loss = 0.85308585, grad/param norm = 1.9091e-01, time/batch = 0.6735s	
21743/33150 (epoch 32.795), train_loss = 0.83503370, grad/param norm = 2.0664e-01, time/batch = 0.6744s	
21744/33150 (epoch 32.796), train_loss = 0.85024715, grad/param norm = 1.4232e-01, time/batch = 0.6693s	
21745/33150 (epoch 32.798), train_loss = 0.80631042, grad/param norm = 1.3628e-01, time/batch = 0.6722s	
21746/33150 (epoch 32.799), train_loss = 0.74448044, grad/param norm = 2.0575e-01, time/batch = 0.6746s	
21747/33150 (epoch 32.801), train_loss = 0.90022931, grad/param norm = 1.9246e-01, time/batch = 0.6668s	
21748/33150 (epoch 32.802), train_loss = 0.81273048, grad/param norm = 1.5433e-01, time/batch = 0.6691s	
21749/33150 (epoch 32.804), train_loss = 0.86212669, grad/param norm = 1.7079e-01, time/batch = 0.6602s	
21750/33150 (epoch 32.805), train_loss = 0.82302403, grad/param norm = 1.8031e-01, time/batch = 0.6630s	
21751/33150 (epoch 32.807), train_loss = 0.85282513, grad/param norm = 1.5482e-01, time/batch = 0.6808s	
21752/33150 (epoch 32.808), train_loss = 0.96250222, grad/param norm = 1.7649e-01, time/batch = 0.6672s	
21753/33150 (epoch 32.810), train_loss = 0.79514023, grad/param norm = 1.6780e-01, time/batch = 0.6612s	
21754/33150 (epoch 32.811), train_loss = 0.91331242, grad/param norm = 1.8647e-01, time/batch = 0.6611s	
21755/33150 (epoch 32.813), train_loss = 0.84393531, grad/param norm = 1.5626e-01, time/batch = 0.6579s	
21756/33150 (epoch 32.814), train_loss = 0.81098924, grad/param norm = 2.0208e-01, time/batch = 0.6745s	
21757/33150 (epoch 32.816), train_loss = 0.84765607, grad/param norm = 1.7453e-01, time/batch = 0.6688s	
21758/33150 (epoch 32.817), train_loss = 0.93570996, grad/param norm = 1.8061e-01, time/batch = 0.6668s	
21759/33150 (epoch 32.819), train_loss = 0.90677055, grad/param norm = 1.7691e-01, time/batch = 0.6664s	
21760/33150 (epoch 32.821), train_loss = 0.76698001, grad/param norm = 1.4617e-01, time/batch = 0.6737s	
21761/33150 (epoch 32.822), train_loss = 0.81431291, grad/param norm = 1.6431e-01, time/batch = 0.6571s	
21762/33150 (epoch 32.824), train_loss = 0.88457592, grad/param norm = 1.9483e-01, time/batch = 0.6542s	
21763/33150 (epoch 32.825), train_loss = 0.89661025, grad/param norm = 1.8716e-01, time/batch = 0.6642s	
21764/33150 (epoch 32.827), train_loss = 0.93709203, grad/param norm = 2.0346e-01, time/batch = 0.6622s	
21765/33150 (epoch 32.828), train_loss = 0.79709232, grad/param norm = 1.8120e-01, time/batch = 0.6625s	
21766/33150 (epoch 32.830), train_loss = 0.94518510, grad/param norm = 1.9361e-01, time/batch = 0.6605s	
21767/33150 (epoch 32.831), train_loss = 0.80627099, grad/param norm = 1.6796e-01, time/batch = 0.6596s	
21768/33150 (epoch 32.833), train_loss = 0.79271817, grad/param norm = 1.6339e-01, time/batch = 0.6605s	
21769/33150 (epoch 32.834), train_loss = 0.94890665, grad/param norm = 1.6553e-01, time/batch = 0.6617s	
21770/33150 (epoch 32.836), train_loss = 0.97411437, grad/param norm = 1.4936e-01, time/batch = 0.6580s	
21771/33150 (epoch 32.837), train_loss = 0.84036661, grad/param norm = 2.0173e-01, time/batch = 0.6592s	
21772/33150 (epoch 32.839), train_loss = 0.93769379, grad/param norm = 1.9222e-01, time/batch = 0.6654s	
21773/33150 (epoch 32.840), train_loss = 0.93706852, grad/param norm = 1.6425e-01, time/batch = 0.6627s	
21774/33150 (epoch 32.842), train_loss = 0.98511078, grad/param norm = 2.1806e-01, time/batch = 0.6563s	
21775/33150 (epoch 32.843), train_loss = 0.95664627, grad/param norm = 1.8120e-01, time/batch = 0.6564s	
21776/33150 (epoch 32.845), train_loss = 0.80985006, grad/param norm = 1.5775e-01, time/batch = 0.6568s	
21777/33150 (epoch 32.846), train_loss = 1.05494313, grad/param norm = 2.3764e-01, time/batch = 0.6578s	
21778/33150 (epoch 32.848), train_loss = 0.95574278, grad/param norm = 1.8124e-01, time/batch = 0.6597s	
21779/33150 (epoch 32.849), train_loss = 0.98952898, grad/param norm = 1.6838e-01, time/batch = 0.6599s	
21780/33150 (epoch 32.851), train_loss = 0.92870579, grad/param norm = 2.0504e-01, time/batch = 0.6611s	
21781/33150 (epoch 32.852), train_loss = 1.01016220, grad/param norm = 1.6185e-01, time/batch = 0.6614s	
21782/33150 (epoch 32.854), train_loss = 0.91102889, grad/param norm = 1.9075e-01, time/batch = 0.6578s	
21783/33150 (epoch 32.855), train_loss = 0.76899503, grad/param norm = 1.8355e-01, time/batch = 0.6607s	
21784/33150 (epoch 32.857), train_loss = 0.73583031, grad/param norm = 1.7000e-01, time/batch = 0.6602s	
21785/33150 (epoch 32.858), train_loss = 0.83819714, grad/param norm = 1.5275e-01, time/batch = 0.6575s	
21786/33150 (epoch 32.860), train_loss = 0.80219524, grad/param norm = 1.5937e-01, time/batch = 0.6602s	
21787/33150 (epoch 32.861), train_loss = 0.78683229, grad/param norm = 1.5725e-01, time/batch = 0.6592s	
21788/33150 (epoch 32.863), train_loss = 0.86386424, grad/param norm = 1.6927e-01, time/batch = 0.6594s	
21789/33150 (epoch 32.864), train_loss = 0.90360937, grad/param norm = 1.7098e-01, time/batch = 0.6590s	
21790/33150 (epoch 32.866), train_loss = 0.94725310, grad/param norm = 1.7849e-01, time/batch = 0.6633s	
21791/33150 (epoch 32.867), train_loss = 0.91172821, grad/param norm = 1.5475e-01, time/batch = 0.6608s	
21792/33150 (epoch 32.869), train_loss = 0.90303646, grad/param norm = 1.8874e-01, time/batch = 0.6632s	
21793/33150 (epoch 32.870), train_loss = 0.84952187, grad/param norm = 1.8907e-01, time/batch = 0.6692s	
21794/33150 (epoch 32.872), train_loss = 0.90649149, grad/param norm = 1.8071e-01, time/batch = 0.6654s	
21795/33150 (epoch 32.873), train_loss = 0.71257472, grad/param norm = 1.4239e-01, time/batch = 0.6610s	
21796/33150 (epoch 32.875), train_loss = 0.98890466, grad/param norm = 1.8234e-01, time/batch = 0.6598s	
21797/33150 (epoch 32.876), train_loss = 0.74267565, grad/param norm = 1.9355e-01, time/batch = 0.6586s	
21798/33150 (epoch 32.878), train_loss = 0.82259813, grad/param norm = 1.6058e-01, time/batch = 0.6577s	
21799/33150 (epoch 32.879), train_loss = 0.80415424, grad/param norm = 1.4086e-01, time/batch = 0.6594s	
21800/33150 (epoch 32.881), train_loss = 0.80148173, grad/param norm = 1.7782e-01, time/batch = 0.6607s	
21801/33150 (epoch 32.882), train_loss = 0.69736793, grad/param norm = 1.4512e-01, time/batch = 0.6589s	
21802/33150 (epoch 32.884), train_loss = 0.83067660, grad/param norm = 1.5936e-01, time/batch = 0.6582s	
21803/33150 (epoch 32.885), train_loss = 0.66002154, grad/param norm = 1.7031e-01, time/batch = 0.7196s	
21804/33150 (epoch 32.887), train_loss = 0.96458665, grad/param norm = 2.0013e-01, time/batch = 0.9635s	
21805/33150 (epoch 32.888), train_loss = 0.89953765, grad/param norm = 1.7134e-01, time/batch = 0.9658s	
21806/33150 (epoch 32.890), train_loss = 0.81164693, grad/param norm = 1.8860e-01, time/batch = 0.9700s	
21807/33150 (epoch 32.891), train_loss = 0.77174527, grad/param norm = 1.6539e-01, time/batch = 0.9757s	
21808/33150 (epoch 32.893), train_loss = 0.92779417, grad/param norm = 1.8194e-01, time/batch = 0.9855s	
21809/33150 (epoch 32.894), train_loss = 0.91007772, grad/param norm = 1.7792e-01, time/batch = 1.8056s	
21810/33150 (epoch 32.896), train_loss = 0.85082778, grad/param norm = 1.4996e-01, time/batch = 3.2532s	
21811/33150 (epoch 32.897), train_loss = 0.90642712, grad/param norm = 1.6259e-01, time/batch = 0.7051s	
21812/33150 (epoch 32.899), train_loss = 0.71840813, grad/param norm = 1.6932e-01, time/batch = 0.6962s	
21813/33150 (epoch 32.900), train_loss = 1.06255238, grad/param norm = 1.9785e-01, time/batch = 0.6962s	
21814/33150 (epoch 32.902), train_loss = 1.09037844, grad/param norm = 1.7708e-01, time/batch = 0.6763s	
21815/33150 (epoch 32.903), train_loss = 0.86913354, grad/param norm = 1.6246e-01, time/batch = 0.6819s	
21816/33150 (epoch 32.905), train_loss = 0.86704978, grad/param norm = 1.5207e-01, time/batch = 0.6876s	
21817/33150 (epoch 32.906), train_loss = 0.89022154, grad/param norm = 1.8237e-01, time/batch = 0.6713s	
21818/33150 (epoch 32.908), train_loss = 0.96384245, grad/param norm = 1.8452e-01, time/batch = 0.6744s	
21819/33150 (epoch 32.910), train_loss = 0.93669321, grad/param norm = 1.6878e-01, time/batch = 0.6919s	
21820/33150 (epoch 32.911), train_loss = 0.76880032, grad/param norm = 1.5638e-01, time/batch = 0.6913s	
21821/33150 (epoch 32.913), train_loss = 0.81108062, grad/param norm = 1.7977e-01, time/batch = 0.6770s	
21822/33150 (epoch 32.914), train_loss = 0.90833072, grad/param norm = 1.8279e-01, time/batch = 0.6720s	
21823/33150 (epoch 32.916), train_loss = 0.82726983, grad/param norm = 1.6708e-01, time/batch = 0.6708s	
21824/33150 (epoch 32.917), train_loss = 0.91569662, grad/param norm = 1.7045e-01, time/batch = 0.6729s	
21825/33150 (epoch 32.919), train_loss = 0.99697933, grad/param norm = 1.9337e-01, time/batch = 0.6742s	
21826/33150 (epoch 32.920), train_loss = 0.96001005, grad/param norm = 1.7470e-01, time/batch = 0.6788s	
21827/33150 (epoch 32.922), train_loss = 1.01211766, grad/param norm = 2.0174e-01, time/batch = 0.6764s	
21828/33150 (epoch 32.923), train_loss = 0.88812848, grad/param norm = 1.9338e-01, time/batch = 0.6759s	
21829/33150 (epoch 32.925), train_loss = 0.97253541, grad/param norm = 1.6731e-01, time/batch = 0.6772s	
21830/33150 (epoch 32.926), train_loss = 0.84855548, grad/param norm = 1.5443e-01, time/batch = 0.6784s	
21831/33150 (epoch 32.928), train_loss = 0.83634310, grad/param norm = 1.7032e-01, time/batch = 0.6796s	
21832/33150 (epoch 32.929), train_loss = 0.94648968, grad/param norm = 1.8855e-01, time/batch = 0.6762s	
21833/33150 (epoch 32.931), train_loss = 1.00518191, grad/param norm = 2.0540e-01, time/batch = 0.6772s	
21834/33150 (epoch 32.932), train_loss = 0.90403489, grad/param norm = 1.8015e-01, time/batch = 0.6697s	
21835/33150 (epoch 32.934), train_loss = 0.90361214, grad/param norm = 1.5699e-01, time/batch = 0.6708s	
21836/33150 (epoch 32.935), train_loss = 0.97248793, grad/param norm = 1.7543e-01, time/batch = 0.6704s	
21837/33150 (epoch 32.937), train_loss = 1.00792823, grad/param norm = 1.7652e-01, time/batch = 0.6683s	
21838/33150 (epoch 32.938), train_loss = 0.90516837, grad/param norm = 1.5736e-01, time/batch = 0.6778s	
21839/33150 (epoch 32.940), train_loss = 1.08760912, grad/param norm = 1.9108e-01, time/batch = 0.6926s	
21840/33150 (epoch 32.941), train_loss = 0.92206194, grad/param norm = 1.5856e-01, time/batch = 0.6873s	
21841/33150 (epoch 32.943), train_loss = 0.73788182, grad/param norm = 1.8224e-01, time/batch = 0.6787s	
21842/33150 (epoch 32.944), train_loss = 0.95199246, grad/param norm = 2.3285e-01, time/batch = 0.6743s	
21843/33150 (epoch 32.946), train_loss = 0.78745236, grad/param norm = 1.5434e-01, time/batch = 0.6846s	
21844/33150 (epoch 32.947), train_loss = 0.92487254, grad/param norm = 1.6544e-01, time/batch = 0.6819s	
21845/33150 (epoch 32.949), train_loss = 0.99324846, grad/param norm = 1.7717e-01, time/batch = 0.6773s	
21846/33150 (epoch 32.950), train_loss = 0.93697425, grad/param norm = 1.9743e-01, time/batch = 0.6742s	
21847/33150 (epoch 32.952), train_loss = 0.81413385, grad/param norm = 1.5239e-01, time/batch = 0.6730s	
21848/33150 (epoch 32.953), train_loss = 0.85474495, grad/param norm = 1.5516e-01, time/batch = 0.6726s	
21849/33150 (epoch 32.955), train_loss = 0.78440639, grad/param norm = 1.7381e-01, time/batch = 0.6725s	
21850/33150 (epoch 32.956), train_loss = 0.96287732, grad/param norm = 1.8442e-01, time/batch = 0.6712s	
21851/33150 (epoch 32.958), train_loss = 0.79973058, grad/param norm = 1.5952e-01, time/batch = 0.6723s	
21852/33150 (epoch 32.959), train_loss = 0.85444482, grad/param norm = 1.5667e-01, time/batch = 0.6726s	
21853/33150 (epoch 32.961), train_loss = 0.81870503, grad/param norm = 1.8210e-01, time/batch = 0.6721s	
21854/33150 (epoch 32.962), train_loss = 0.76459086, grad/param norm = 1.5301e-01, time/batch = 0.6719s	
21855/33150 (epoch 32.964), train_loss = 0.89294161, grad/param norm = 1.7712e-01, time/batch = 0.6715s	
21856/33150 (epoch 32.965), train_loss = 0.85413938, grad/param norm = 1.7644e-01, time/batch = 0.6684s	
21857/33150 (epoch 32.967), train_loss = 0.84121677, grad/param norm = 1.7322e-01, time/batch = 0.6700s	
21858/33150 (epoch 32.968), train_loss = 0.74173901, grad/param norm = 1.3539e-01, time/batch = 0.6746s	
21859/33150 (epoch 32.970), train_loss = 0.82237531, grad/param norm = 1.6715e-01, time/batch = 0.6727s	
21860/33150 (epoch 32.971), train_loss = 0.87618219, grad/param norm = 1.7964e-01, time/batch = 0.6743s	
21861/33150 (epoch 32.973), train_loss = 0.96281261, grad/param norm = 1.9108e-01, time/batch = 0.6727s	
21862/33150 (epoch 32.974), train_loss = 1.00672392, grad/param norm = 1.7321e-01, time/batch = 0.6721s	
21863/33150 (epoch 32.976), train_loss = 0.97028461, grad/param norm = 1.5748e-01, time/batch = 0.6724s	
21864/33150 (epoch 32.977), train_loss = 1.01523289, grad/param norm = 1.8818e-01, time/batch = 0.6713s	
21865/33150 (epoch 32.979), train_loss = 0.96684929, grad/param norm = 2.0508e-01, time/batch = 0.6729s	
21866/33150 (epoch 32.980), train_loss = 1.03216487, grad/param norm = 1.9566e-01, time/batch = 0.6694s	
21867/33150 (epoch 32.982), train_loss = 0.88256334, grad/param norm = 1.8171e-01, time/batch = 0.6705s	
21868/33150 (epoch 32.983), train_loss = 0.80558399, grad/param norm = 1.7482e-01, time/batch = 0.6735s	
21869/33150 (epoch 32.985), train_loss = 1.00309708, grad/param norm = 1.7382e-01, time/batch = 0.6720s	
21870/33150 (epoch 32.986), train_loss = 0.74303708, grad/param norm = 1.4791e-01, time/batch = 0.6731s	
21871/33150 (epoch 32.988), train_loss = 0.83982296, grad/param norm = 2.1618e-01, time/batch = 0.6715s	
21872/33150 (epoch 32.989), train_loss = 0.86183473, grad/param norm = 1.6405e-01, time/batch = 0.6715s	
21873/33150 (epoch 32.991), train_loss = 0.95133264, grad/param norm = 2.2845e-01, time/batch = 0.6697s	
21874/33150 (epoch 32.992), train_loss = 0.85051678, grad/param norm = 1.6732e-01, time/batch = 0.6692s	
21875/33150 (epoch 32.994), train_loss = 0.90799143, grad/param norm = 1.7049e-01, time/batch = 0.6796s	
21876/33150 (epoch 32.995), train_loss = 0.86272234, grad/param norm = 1.6132e-01, time/batch = 0.6839s	
21877/33150 (epoch 32.997), train_loss = 0.87948074, grad/param norm = 1.7726e-01, time/batch = 0.6773s	
21878/33150 (epoch 32.998), train_loss = 0.76395479, grad/param norm = 1.8061e-01, time/batch = 0.6809s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
21879/33150 (epoch 33.000), train_loss = 0.73900312, grad/param norm = 1.6045e-01, time/batch = 0.6820s	
21880/33150 (epoch 33.002), train_loss = 1.18821560, grad/param norm = 1.9159e-01, time/batch = 0.6743s	
21881/33150 (epoch 33.003), train_loss = 0.79695473, grad/param norm = 1.6803e-01, time/batch = 0.6838s	
21882/33150 (epoch 33.005), train_loss = 0.73855199, grad/param norm = 1.3948e-01, time/batch = 0.6850s	
21883/33150 (epoch 33.006), train_loss = 0.74518160, grad/param norm = 1.7117e-01, time/batch = 0.6898s	
21884/33150 (epoch 33.008), train_loss = 0.92073588, grad/param norm = 1.7577e-01, time/batch = 0.6883s	
21885/33150 (epoch 33.009), train_loss = 0.91375327, grad/param norm = 1.6056e-01, time/batch = 0.6896s	
21886/33150 (epoch 33.011), train_loss = 0.95876192, grad/param norm = 1.6921e-01, time/batch = 0.6920s	
21887/33150 (epoch 33.012), train_loss = 0.87240083, grad/param norm = 1.8769e-01, time/batch = 0.6920s	
21888/33150 (epoch 33.014), train_loss = 0.79569986, grad/param norm = 1.7194e-01, time/batch = 0.6900s	
21889/33150 (epoch 33.015), train_loss = 0.78654235, grad/param norm = 1.7335e-01, time/batch = 0.6895s	
21890/33150 (epoch 33.017), train_loss = 0.80343117, grad/param norm = 1.6422e-01, time/batch = 0.6816s	
21891/33150 (epoch 33.018), train_loss = 0.88764275, grad/param norm = 1.7522e-01, time/batch = 0.6859s	
21892/33150 (epoch 33.020), train_loss = 0.95986676, grad/param norm = 1.8937e-01, time/batch = 0.6884s	
21893/33150 (epoch 33.021), train_loss = 0.77604875, grad/param norm = 1.6566e-01, time/batch = 0.6896s	
21894/33150 (epoch 33.023), train_loss = 1.05447129, grad/param norm = 1.7109e-01, time/batch = 0.6872s	
21895/33150 (epoch 33.024), train_loss = 0.92168585, grad/param norm = 2.0215e-01, time/batch = 0.6922s	
21896/33150 (epoch 33.026), train_loss = 0.69891430, grad/param norm = 1.3557e-01, time/batch = 0.6850s	
21897/33150 (epoch 33.027), train_loss = 0.69608053, grad/param norm = 1.3197e-01, time/batch = 0.6800s	
21898/33150 (epoch 33.029), train_loss = 0.81473501, grad/param norm = 1.5113e-01, time/batch = 0.6826s	
21899/33150 (epoch 33.030), train_loss = 0.84201685, grad/param norm = 1.3744e-01, time/batch = 0.6869s	
21900/33150 (epoch 33.032), train_loss = 0.77357437, grad/param norm = 1.6834e-01, time/batch = 0.6872s	
21901/33150 (epoch 33.033), train_loss = 0.80507730, grad/param norm = 1.5804e-01, time/batch = 0.6867s	
21902/33150 (epoch 33.035), train_loss = 1.05601088, grad/param norm = 2.0186e-01, time/batch = 0.6848s	
21903/33150 (epoch 33.036), train_loss = 0.94237925, grad/param norm = 1.7328e-01, time/batch = 0.6823s	
21904/33150 (epoch 33.038), train_loss = 1.05782820, grad/param norm = 1.8041e-01, time/batch = 0.6772s	
21905/33150 (epoch 33.039), train_loss = 0.95318093, grad/param norm = 1.5110e-01, time/batch = 0.6774s	
21906/33150 (epoch 33.041), train_loss = 0.86946745, grad/param norm = 1.5386e-01, time/batch = 0.6775s	
21907/33150 (epoch 33.042), train_loss = 0.82032080, grad/param norm = 1.7070e-01, time/batch = 0.6838s	
21908/33150 (epoch 33.044), train_loss = 0.86331881, grad/param norm = 1.5736e-01, time/batch = 0.6830s	
21909/33150 (epoch 33.045), train_loss = 0.93789851, grad/param norm = 1.4226e-01, time/batch = 0.6827s	
21910/33150 (epoch 33.047), train_loss = 0.78184180, grad/param norm = 1.5846e-01, time/batch = 0.6834s	
21911/33150 (epoch 33.048), train_loss = 0.97694035, grad/param norm = 2.0090e-01, time/batch = 0.6770s	
21912/33150 (epoch 33.050), train_loss = 0.87379495, grad/param norm = 1.6710e-01, time/batch = 0.6870s	
21913/33150 (epoch 33.051), train_loss = 0.90397337, grad/param norm = 1.5640e-01, time/batch = 0.6882s	
21914/33150 (epoch 33.053), train_loss = 0.89516446, grad/param norm = 1.8299e-01, time/batch = 0.6863s	
21915/33150 (epoch 33.054), train_loss = 1.02553914, grad/param norm = 1.9545e-01, time/batch = 0.6847s	
21916/33150 (epoch 33.056), train_loss = 0.87432979, grad/param norm = 1.6482e-01, time/batch = 0.6883s	
21917/33150 (epoch 33.057), train_loss = 0.91579200, grad/param norm = 1.5590e-01, time/batch = 0.6849s	
21918/33150 (epoch 33.059), train_loss = 0.81059898, grad/param norm = 1.9828e-01, time/batch = 0.6779s	
21919/33150 (epoch 33.060), train_loss = 0.78858755, grad/param norm = 1.4437e-01, time/batch = 0.6831s	
21920/33150 (epoch 33.062), train_loss = 0.87662927, grad/param norm = 1.7714e-01, time/batch = 0.6762s	
21921/33150 (epoch 33.063), train_loss = 0.81161904, grad/param norm = 1.6498e-01, time/batch = 0.6829s	
21922/33150 (epoch 33.065), train_loss = 0.82681311, grad/param norm = 1.4526e-01, time/batch = 0.6820s	
21923/33150 (epoch 33.066), train_loss = 0.84027175, grad/param norm = 1.6918e-01, time/batch = 0.6812s	
21924/33150 (epoch 33.068), train_loss = 0.93828926, grad/param norm = 1.9124e-01, time/batch = 0.6838s	
21925/33150 (epoch 33.069), train_loss = 0.92308156, grad/param norm = 1.8888e-01, time/batch = 0.6853s	
21926/33150 (epoch 33.071), train_loss = 0.89090373, grad/param norm = 1.5963e-01, time/batch = 0.6771s	
21927/33150 (epoch 33.072), train_loss = 0.91181561, grad/param norm = 1.7306e-01, time/batch = 0.6789s	
21928/33150 (epoch 33.074), train_loss = 0.78184246, grad/param norm = 1.7365e-01, time/batch = 0.6863s	
21929/33150 (epoch 33.075), train_loss = 0.79884631, grad/param norm = 1.7354e-01, time/batch = 0.6767s	
21930/33150 (epoch 33.077), train_loss = 0.87346547, grad/param norm = 1.9869e-01, time/batch = 0.6732s	
21931/33150 (epoch 33.078), train_loss = 1.01935205, grad/param norm = 2.1262e-01, time/batch = 0.6795s	
21932/33150 (epoch 33.080), train_loss = 1.00117050, grad/param norm = 1.6559e-01, time/batch = 0.6766s	
21933/33150 (epoch 33.081), train_loss = 0.76431961, grad/param norm = 1.7553e-01, time/batch = 0.6781s	
21934/33150 (epoch 33.083), train_loss = 0.67353041, grad/param norm = 1.9010e-01, time/batch = 0.6799s	
21935/33150 (epoch 33.084), train_loss = 0.74664339, grad/param norm = 1.7097e-01, time/batch = 0.6757s	
21936/33150 (epoch 33.086), train_loss = 0.80254052, grad/param norm = 1.8907e-01, time/batch = 0.6807s	
21937/33150 (epoch 33.087), train_loss = 0.73997631, grad/param norm = 1.4767e-01, time/batch = 0.6741s	
21938/33150 (epoch 33.089), train_loss = 0.80775128, grad/param norm = 1.7229e-01, time/batch = 0.6749s	
21939/33150 (epoch 33.090), train_loss = 0.83296852, grad/param norm = 1.8917e-01, time/batch = 0.6768s	
21940/33150 (epoch 33.092), train_loss = 0.82512147, grad/param norm = 1.7995e-01, time/batch = 0.6733s	
21941/33150 (epoch 33.094), train_loss = 0.89546659, grad/param norm = 2.1434e-01, time/batch = 0.6748s	
21942/33150 (epoch 33.095), train_loss = 0.80263135, grad/param norm = 1.6199e-01, time/batch = 0.6803s	
21943/33150 (epoch 33.097), train_loss = 0.75240988, grad/param norm = 1.7245e-01, time/batch = 0.6841s	
21944/33150 (epoch 33.098), train_loss = 1.10138327, grad/param norm = 1.9467e-01, time/batch = 0.6759s	
21945/33150 (epoch 33.100), train_loss = 1.06360025, grad/param norm = 1.9124e-01, time/batch = 0.6829s	
21946/33150 (epoch 33.101), train_loss = 0.81923296, grad/param norm = 1.6103e-01, time/batch = 0.6802s	
21947/33150 (epoch 33.103), train_loss = 0.89110399, grad/param norm = 1.6514e-01, time/batch = 0.6852s	
21948/33150 (epoch 33.104), train_loss = 0.82149379, grad/param norm = 1.9475e-01, time/batch = 0.6813s	
21949/33150 (epoch 33.106), train_loss = 0.97079071, grad/param norm = 1.8460e-01, time/batch = 0.6877s	
21950/33150 (epoch 33.107), train_loss = 1.07894027, grad/param norm = 1.9781e-01, time/batch = 0.6835s	
21951/33150 (epoch 33.109), train_loss = 0.85329861, grad/param norm = 1.4209e-01, time/batch = 0.6898s	
21952/33150 (epoch 33.110), train_loss = 0.98839657, grad/param norm = 2.1496e-01, time/batch = 0.6802s	
21953/33150 (epoch 33.112), train_loss = 0.82172394, grad/param norm = 1.8145e-01, time/batch = 0.6833s	
21954/33150 (epoch 33.113), train_loss = 0.84457854, grad/param norm = 1.7698e-01, time/batch = 0.6905s	
21955/33150 (epoch 33.115), train_loss = 1.05448228, grad/param norm = 2.0485e-01, time/batch = 0.6829s	
21956/33150 (epoch 33.116), train_loss = 0.91264008, grad/param norm = 1.8774e-01, time/batch = 0.6871s	
21957/33150 (epoch 33.118), train_loss = 0.90318889, grad/param norm = 1.8840e-01, time/batch = 0.6816s	
21958/33150 (epoch 33.119), train_loss = 0.92179630, grad/param norm = 2.2108e-01, time/batch = 0.6781s	
21959/33150 (epoch 33.121), train_loss = 0.83645827, grad/param norm = 1.5075e-01, time/batch = 0.6799s	
21960/33150 (epoch 33.122), train_loss = 1.03707338, grad/param norm = 2.2881e-01, time/batch = 0.6752s	
21961/33150 (epoch 33.124), train_loss = 0.73968378, grad/param norm = 1.4399e-01, time/batch = 0.6799s	
21962/33150 (epoch 33.125), train_loss = 0.99806093, grad/param norm = 1.7373e-01, time/batch = 0.6781s	
21963/33150 (epoch 33.127), train_loss = 0.89863100, grad/param norm = 1.8074e-01, time/batch = 0.6843s	
21964/33150 (epoch 33.128), train_loss = 0.90135806, grad/param norm = 1.7066e-01, time/batch = 0.6769s	
21965/33150 (epoch 33.130), train_loss = 0.89188925, grad/param norm = 1.7871e-01, time/batch = 0.6851s	
21966/33150 (epoch 33.131), train_loss = 1.08176158, grad/param norm = 1.8354e-01, time/batch = 0.6815s	
21967/33150 (epoch 33.133), train_loss = 0.81849466, grad/param norm = 1.6301e-01, time/batch = 0.6809s	
21968/33150 (epoch 33.134), train_loss = 1.00807558, grad/param norm = 1.8287e-01, time/batch = 0.6794s	
21969/33150 (epoch 33.136), train_loss = 0.89897837, grad/param norm = 2.0839e-01, time/batch = 0.6757s	
21970/33150 (epoch 33.137), train_loss = 0.96370449, grad/param norm = 1.6842e-01, time/batch = 0.6725s	
21971/33150 (epoch 33.139), train_loss = 0.94364832, grad/param norm = 1.8391e-01, time/batch = 0.6789s	
21972/33150 (epoch 33.140), train_loss = 1.06183447, grad/param norm = 1.9179e-01, time/batch = 0.6837s	
21973/33150 (epoch 33.142), train_loss = 0.94106681, grad/param norm = 1.9225e-01, time/batch = 0.6860s	
21974/33150 (epoch 33.143), train_loss = 0.87813284, grad/param norm = 1.9381e-01, time/batch = 0.6910s	
21975/33150 (epoch 33.145), train_loss = 0.85849731, grad/param norm = 1.8540e-01, time/batch = 0.6793s	
21976/33150 (epoch 33.146), train_loss = 0.96823651, grad/param norm = 1.9738e-01, time/batch = 0.6822s	
21977/33150 (epoch 33.148), train_loss = 1.01352761, grad/param norm = 1.5954e-01, time/batch = 0.6757s	
21978/33150 (epoch 33.149), train_loss = 0.92872991, grad/param norm = 2.2320e-01, time/batch = 0.6687s	
21979/33150 (epoch 33.151), train_loss = 1.05895435, grad/param norm = 1.9374e-01, time/batch = 0.6793s	
21980/33150 (epoch 33.152), train_loss = 0.82337505, grad/param norm = 1.4564e-01, time/batch = 0.6762s	
21981/33150 (epoch 33.154), train_loss = 0.83115444, grad/param norm = 1.9353e-01, time/batch = 0.6909s	
21982/33150 (epoch 33.155), train_loss = 0.76109386, grad/param norm = 1.6172e-01, time/batch = 0.6984s	
21983/33150 (epoch 33.157), train_loss = 0.85731940, grad/param norm = 1.6740e-01, time/batch = 0.6932s	
21984/33150 (epoch 33.158), train_loss = 0.85261387, grad/param norm = 1.5463e-01, time/batch = 0.6841s	
21985/33150 (epoch 33.160), train_loss = 0.95907157, grad/param norm = 1.8213e-01, time/batch = 0.6831s	
21986/33150 (epoch 33.161), train_loss = 0.83599056, grad/param norm = 2.1551e-01, time/batch = 0.6825s	
21987/33150 (epoch 33.163), train_loss = 0.76659012, grad/param norm = 1.5233e-01, time/batch = 0.6928s	
21988/33150 (epoch 33.164), train_loss = 0.89965295, grad/param norm = 1.6206e-01, time/batch = 0.6872s	
21989/33150 (epoch 33.166), train_loss = 0.86836384, grad/param norm = 1.6767e-01, time/batch = 0.6719s	
21990/33150 (epoch 33.167), train_loss = 0.90083270, grad/param norm = 1.5673e-01, time/batch = 0.6825s	
21991/33150 (epoch 33.169), train_loss = 0.92097052, grad/param norm = 2.2921e-01, time/batch = 0.6928s	
21992/33150 (epoch 33.170), train_loss = 0.81274491, grad/param norm = 2.0533e-01, time/batch = 0.6954s	
21993/33150 (epoch 33.172), train_loss = 0.94646874, grad/param norm = 2.1409e-01, time/batch = 0.6809s	
21994/33150 (epoch 33.173), train_loss = 0.95279249, grad/param norm = 2.3274e-01, time/batch = 0.6870s	
21995/33150 (epoch 33.175), train_loss = 0.86490157, grad/param norm = 2.1632e-01, time/batch = 0.6795s	
21996/33150 (epoch 33.176), train_loss = 0.95587868, grad/param norm = 1.9284e-01, time/batch = 0.6847s	
21997/33150 (epoch 33.178), train_loss = 1.06063807, grad/param norm = 1.9286e-01, time/batch = 0.6659s	
21998/33150 (epoch 33.179), train_loss = 0.96382298, grad/param norm = 1.6297e-01, time/batch = 0.6623s	
21999/33150 (epoch 33.181), train_loss = 0.90760200, grad/param norm = 2.2062e-01, time/batch = 0.6675s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch33.18_1.7366.t7	
22000/33150 (epoch 33.183), train_loss = 0.90393180, grad/param norm = 2.2167e-01, time/batch = 0.6862s	
22001/33150 (epoch 33.184), train_loss = 1.41152359, grad/param norm = 2.2631e-01, time/batch = 0.6729s	
22002/33150 (epoch 33.186), train_loss = 1.04813275, grad/param norm = 1.7866e-01, time/batch = 0.6686s	
22003/33150 (epoch 33.187), train_loss = 0.90965060, grad/param norm = 1.8228e-01, time/batch = 0.6704s	
22004/33150 (epoch 33.189), train_loss = 0.70614280, grad/param norm = 1.6748e-01, time/batch = 0.6788s	
22005/33150 (epoch 33.190), train_loss = 0.79505454, grad/param norm = 2.1195e-01, time/batch = 0.6827s	
22006/33150 (epoch 33.192), train_loss = 0.93244435, grad/param norm = 2.1625e-01, time/batch = 0.6830s	
22007/33150 (epoch 33.193), train_loss = 0.97048545, grad/param norm = 1.8712e-01, time/batch = 0.6800s	
22008/33150 (epoch 33.195), train_loss = 1.10864996, grad/param norm = 2.1031e-01, time/batch = 0.6874s	
22009/33150 (epoch 33.196), train_loss = 1.01661557, grad/param norm = 1.6640e-01, time/batch = 0.6749s	
22010/33150 (epoch 33.198), train_loss = 0.78873300, grad/param norm = 1.6379e-01, time/batch = 0.6759s	
22011/33150 (epoch 33.199), train_loss = 0.95837310, grad/param norm = 2.0224e-01, time/batch = 0.6702s	
22012/33150 (epoch 33.201), train_loss = 0.84490787, grad/param norm = 1.5800e-01, time/batch = 0.6714s	
22013/33150 (epoch 33.202), train_loss = 0.71664550, grad/param norm = 1.5634e-01, time/batch = 0.6872s	
22014/33150 (epoch 33.204), train_loss = 0.93176150, grad/param norm = 1.7736e-01, time/batch = 0.6750s	
22015/33150 (epoch 33.205), train_loss = 0.93848387, grad/param norm = 1.9011e-01, time/batch = 0.6734s	
22016/33150 (epoch 33.207), train_loss = 0.93535558, grad/param norm = 1.6372e-01, time/batch = 0.6828s	
22017/33150 (epoch 33.208), train_loss = 0.96701494, grad/param norm = 1.9963e-01, time/batch = 0.6747s	
22018/33150 (epoch 33.210), train_loss = 0.83862212, grad/param norm = 1.5159e-01, time/batch = 0.6826s	
22019/33150 (epoch 33.211), train_loss = 0.89863232, grad/param norm = 1.8736e-01, time/batch = 0.6759s	
22020/33150 (epoch 33.213), train_loss = 0.96275122, grad/param norm = 1.6860e-01, time/batch = 0.6718s	
22021/33150 (epoch 33.214), train_loss = 0.87280028, grad/param norm = 1.8108e-01, time/batch = 0.6731s	
22022/33150 (epoch 33.216), train_loss = 0.81203973, grad/param norm = 1.7823e-01, time/batch = 0.6824s	
22023/33150 (epoch 33.217), train_loss = 0.87840288, grad/param norm = 1.7878e-01, time/batch = 0.6758s	
22024/33150 (epoch 33.219), train_loss = 0.81823159, grad/param norm = 1.5987e-01, time/batch = 0.6750s	
22025/33150 (epoch 33.220), train_loss = 0.86243693, grad/param norm = 1.5552e-01, time/batch = 0.6783s	
22026/33150 (epoch 33.222), train_loss = 0.99548831, grad/param norm = 1.7893e-01, time/batch = 0.6799s	
22027/33150 (epoch 33.223), train_loss = 0.88304830, grad/param norm = 1.7472e-01, time/batch = 0.6786s	
22028/33150 (epoch 33.225), train_loss = 1.00994177, grad/param norm = 1.7174e-01, time/batch = 0.6757s	
22029/33150 (epoch 33.226), train_loss = 0.87435392, grad/param norm = 1.6432e-01, time/batch = 0.6739s	
22030/33150 (epoch 33.228), train_loss = 0.87266833, grad/param norm = 1.8180e-01, time/batch = 0.6810s	
22031/33150 (epoch 33.229), train_loss = 0.89177276, grad/param norm = 1.7862e-01, time/batch = 0.6905s	
22032/33150 (epoch 33.231), train_loss = 0.99091188, grad/param norm = 1.8912e-01, time/batch = 0.6736s	
22033/33150 (epoch 33.232), train_loss = 0.88474982, grad/param norm = 1.7157e-01, time/batch = 0.6741s	
22034/33150 (epoch 33.234), train_loss = 0.92795655, grad/param norm = 1.8566e-01, time/batch = 0.6729s	
22035/33150 (epoch 33.235), train_loss = 0.94464969, grad/param norm = 1.8701e-01, time/batch = 0.6704s	
22036/33150 (epoch 33.237), train_loss = 0.92433040, grad/param norm = 2.2835e-01, time/batch = 0.6706s	
22037/33150 (epoch 33.238), train_loss = 0.96765689, grad/param norm = 1.7928e-01, time/batch = 0.6754s	
22038/33150 (epoch 33.240), train_loss = 0.92728053, grad/param norm = 1.8058e-01, time/batch = 0.6672s	
22039/33150 (epoch 33.241), train_loss = 0.98273648, grad/param norm = 1.8478e-01, time/batch = 0.6655s	
22040/33150 (epoch 33.243), train_loss = 0.96414529, grad/param norm = 1.9996e-01, time/batch = 0.6706s	
22041/33150 (epoch 33.244), train_loss = 0.91455514, grad/param norm = 1.7859e-01, time/batch = 0.6709s	
22042/33150 (epoch 33.246), train_loss = 0.99307163, grad/param norm = 1.8923e-01, time/batch = 0.6724s	
22043/33150 (epoch 33.247), train_loss = 0.85169504, grad/param norm = 1.7018e-01, time/batch = 0.6817s	
22044/33150 (epoch 33.249), train_loss = 1.01325431, grad/param norm = 1.6336e-01, time/batch = 0.6706s	
22045/33150 (epoch 33.250), train_loss = 0.94381701, grad/param norm = 1.5750e-01, time/batch = 0.6742s	
22046/33150 (epoch 33.252), train_loss = 0.95312896, grad/param norm = 1.5388e-01, time/batch = 0.6832s	
22047/33150 (epoch 33.253), train_loss = 0.87786320, grad/param norm = 1.6866e-01, time/batch = 0.6837s	
22048/33150 (epoch 33.255), train_loss = 0.87984331, grad/param norm = 1.4680e-01, time/batch = 0.6725s	
22049/33150 (epoch 33.256), train_loss = 1.01664051, grad/param norm = 1.7168e-01, time/batch = 0.6696s	
22050/33150 (epoch 33.258), train_loss = 0.82791088, grad/param norm = 1.7051e-01, time/batch = 0.6726s	
22051/33150 (epoch 33.259), train_loss = 0.74361997, grad/param norm = 1.8284e-01, time/batch = 0.6683s	
22052/33150 (epoch 33.261), train_loss = 0.79658317, grad/param norm = 1.5783e-01, time/batch = 0.6859s	
22053/33150 (epoch 33.262), train_loss = 0.99478792, grad/param norm = 1.9332e-01, time/batch = 0.6677s	
22054/33150 (epoch 33.264), train_loss = 0.69152613, grad/param norm = 1.4139e-01, time/batch = 0.6708s	
22055/33150 (epoch 33.265), train_loss = 0.91234298, grad/param norm = 1.6801e-01, time/batch = 0.6808s	
22056/33150 (epoch 33.267), train_loss = 0.99611716, grad/param norm = 2.1291e-01, time/batch = 0.6682s	
22057/33150 (epoch 33.268), train_loss = 1.00511557, grad/param norm = 1.7205e-01, time/batch = 0.6692s	
22058/33150 (epoch 33.270), train_loss = 1.07032663, grad/param norm = 1.6192e-01, time/batch = 0.6700s	
22059/33150 (epoch 33.271), train_loss = 1.00241597, grad/param norm = 2.0833e-01, time/batch = 0.6789s	
22060/33150 (epoch 33.273), train_loss = 1.02249661, grad/param norm = 1.8634e-01, time/batch = 0.6831s	
22061/33150 (epoch 33.275), train_loss = 1.03293604, grad/param norm = 1.6907e-01, time/batch = 0.6893s	
22062/33150 (epoch 33.276), train_loss = 0.91484469, grad/param norm = 1.7641e-01, time/batch = 0.6876s	
22063/33150 (epoch 33.278), train_loss = 1.02278671, grad/param norm = 1.7215e-01, time/batch = 0.6686s	
22064/33150 (epoch 33.279), train_loss = 0.97423729, grad/param norm = 1.5872e-01, time/batch = 0.6774s	
22065/33150 (epoch 33.281), train_loss = 0.89498262, grad/param norm = 1.6451e-01, time/batch = 0.6759s	
22066/33150 (epoch 33.282), train_loss = 0.92981062, grad/param norm = 1.4462e-01, time/batch = 0.6994s	
22067/33150 (epoch 33.284), train_loss = 0.82065687, grad/param norm = 1.7916e-01, time/batch = 0.6892s	
22068/33150 (epoch 33.285), train_loss = 0.93665267, grad/param norm = 1.8768e-01, time/batch = 0.6713s	
22069/33150 (epoch 33.287), train_loss = 0.82279638, grad/param norm = 1.6405e-01, time/batch = 0.6682s	
22070/33150 (epoch 33.288), train_loss = 0.98036674, grad/param norm = 1.7231e-01, time/batch = 0.6741s	
22071/33150 (epoch 33.290), train_loss = 0.75606578, grad/param norm = 1.4571e-01, time/batch = 0.6885s	
22072/33150 (epoch 33.291), train_loss = 0.74834260, grad/param norm = 2.2819e-01, time/batch = 0.6737s	
22073/33150 (epoch 33.293), train_loss = 0.89429031, grad/param norm = 1.8193e-01, time/batch = 0.6717s	
22074/33150 (epoch 33.294), train_loss = 0.69925551, grad/param norm = 1.5920e-01, time/batch = 0.6745s	
22075/33150 (epoch 33.296), train_loss = 0.89026792, grad/param norm = 1.5518e-01, time/batch = 0.6819s	
22076/33150 (epoch 33.297), train_loss = 0.84494470, grad/param norm = 2.1338e-01, time/batch = 0.6815s	
22077/33150 (epoch 33.299), train_loss = 0.85950263, grad/param norm = 1.9266e-01, time/batch = 0.6711s	
22078/33150 (epoch 33.300), train_loss = 0.84041206, grad/param norm = 1.4368e-01, time/batch = 0.6818s	
22079/33150 (epoch 33.302), train_loss = 0.88564643, grad/param norm = 1.8020e-01, time/batch = 0.6696s	
22080/33150 (epoch 33.303), train_loss = 0.85709478, grad/param norm = 1.7551e-01, time/batch = 0.6754s	
22081/33150 (epoch 33.305), train_loss = 0.94723021, grad/param norm = 1.6615e-01, time/batch = 0.6729s	
22082/33150 (epoch 33.306), train_loss = 0.94355171, grad/param norm = 1.8193e-01, time/batch = 0.6782s	
22083/33150 (epoch 33.308), train_loss = 1.11186260, grad/param norm = 1.7721e-01, time/batch = 0.6685s	
22084/33150 (epoch 33.309), train_loss = 0.74504204, grad/param norm = 1.5307e-01, time/batch = 0.6676s	
22085/33150 (epoch 33.311), train_loss = 0.86291477, grad/param norm = 1.7121e-01, time/batch = 0.6726s	
22086/33150 (epoch 33.312), train_loss = 0.72092000, grad/param norm = 1.5315e-01, time/batch = 0.6730s	
22087/33150 (epoch 33.314), train_loss = 0.87464985, grad/param norm = 1.8198e-01, time/batch = 0.6691s	
22088/33150 (epoch 33.315), train_loss = 0.94328822, grad/param norm = 1.6510e-01, time/batch = 0.6702s	
22089/33150 (epoch 33.317), train_loss = 0.70354127, grad/param norm = 1.3326e-01, time/batch = 0.6708s	
22090/33150 (epoch 33.318), train_loss = 0.82157564, grad/param norm = 1.4667e-01, time/batch = 0.6815s	
22091/33150 (epoch 33.320), train_loss = 0.74889499, grad/param norm = 1.4773e-01, time/batch = 0.6756s	
22092/33150 (epoch 33.321), train_loss = 0.86389360, grad/param norm = 1.5296e-01, time/batch = 0.6714s	
22093/33150 (epoch 33.323), train_loss = 0.84312846, grad/param norm = 1.7158e-01, time/batch = 0.6672s	
22094/33150 (epoch 33.324), train_loss = 0.90017506, grad/param norm = 1.9276e-01, time/batch = 0.6715s	
22095/33150 (epoch 33.326), train_loss = 0.90325020, grad/param norm = 1.6990e-01, time/batch = 0.6696s	
22096/33150 (epoch 33.327), train_loss = 0.95359975, grad/param norm = 1.6670e-01, time/batch = 0.6667s	
22097/33150 (epoch 33.329), train_loss = 0.91337496, grad/param norm = 1.5233e-01, time/batch = 0.6738s	
22098/33150 (epoch 33.330), train_loss = 0.85806944, grad/param norm = 1.6335e-01, time/batch = 0.6714s	
22099/33150 (epoch 33.332), train_loss = 0.87040536, grad/param norm = 1.6035e-01, time/batch = 0.6723s	
22100/33150 (epoch 33.333), train_loss = 0.93092866, grad/param norm = 1.4529e-01, time/batch = 0.6718s	
22101/33150 (epoch 33.335), train_loss = 0.81389448, grad/param norm = 1.5959e-01, time/batch = 0.6732s	
22102/33150 (epoch 33.336), train_loss = 0.78865956, grad/param norm = 1.6156e-01, time/batch = 0.6760s	
22103/33150 (epoch 33.338), train_loss = 0.75174504, grad/param norm = 1.7489e-01, time/batch = 0.6833s	
22104/33150 (epoch 33.339), train_loss = 0.96536035, grad/param norm = 2.0340e-01, time/batch = 0.6857s	
22105/33150 (epoch 33.341), train_loss = 0.88915204, grad/param norm = 1.9806e-01, time/batch = 0.6835s	
22106/33150 (epoch 33.342), train_loss = 0.82266306, grad/param norm = 1.6428e-01, time/batch = 0.6892s	
22107/33150 (epoch 33.344), train_loss = 0.87886277, grad/param norm = 1.7894e-01, time/batch = 0.7019s	
22108/33150 (epoch 33.345), train_loss = 0.86583779, grad/param norm = 1.6274e-01, time/batch = 0.6950s	
22109/33150 (epoch 33.347), train_loss = 0.72946578, grad/param norm = 1.7475e-01, time/batch = 0.6908s	
22110/33150 (epoch 33.348), train_loss = 0.90964200, grad/param norm = 1.5484e-01, time/batch = 0.6916s	
22111/33150 (epoch 33.350), train_loss = 0.78066739, grad/param norm = 1.6946e-01, time/batch = 0.6817s	
22112/33150 (epoch 33.351), train_loss = 0.95454230, grad/param norm = 1.8024e-01, time/batch = 0.6865s	
22113/33150 (epoch 33.353), train_loss = 0.92548362, grad/param norm = 1.6739e-01, time/batch = 0.6683s	
22114/33150 (epoch 33.354), train_loss = 1.10009723, grad/param norm = 1.7814e-01, time/batch = 0.6756s	
22115/33150 (epoch 33.356), train_loss = 0.96037644, grad/param norm = 1.6043e-01, time/batch = 0.6848s	
22116/33150 (epoch 33.357), train_loss = 0.90544130, grad/param norm = 1.7129e-01, time/batch = 0.6731s	
22117/33150 (epoch 33.359), train_loss = 0.95330690, grad/param norm = 1.7840e-01, time/batch = 0.6703s	
22118/33150 (epoch 33.360), train_loss = 0.93152867, grad/param norm = 1.9206e-01, time/batch = 0.6711s	
22119/33150 (epoch 33.362), train_loss = 1.03119261, grad/param norm = 1.8459e-01, time/batch = 0.6753s	
22120/33150 (epoch 33.363), train_loss = 0.91225878, grad/param norm = 1.5773e-01, time/batch = 0.6723s	
22121/33150 (epoch 33.365), train_loss = 0.87577544, grad/param norm = 1.7430e-01, time/batch = 0.6714s	
22122/33150 (epoch 33.367), train_loss = 0.83664063, grad/param norm = 1.5460e-01, time/batch = 0.6702s	
22123/33150 (epoch 33.368), train_loss = 0.87126214, grad/param norm = 1.9096e-01, time/batch = 0.6720s	
22124/33150 (epoch 33.370), train_loss = 0.90932764, grad/param norm = 1.9395e-01, time/batch = 0.6750s	
22125/33150 (epoch 33.371), train_loss = 0.81373985, grad/param norm = 1.8206e-01, time/batch = 0.6758s	
22126/33150 (epoch 33.373), train_loss = 0.92525068, grad/param norm = 1.9343e-01, time/batch = 0.6778s	
22127/33150 (epoch 33.374), train_loss = 0.87842820, grad/param norm = 1.5806e-01, time/batch = 0.6752s	
22128/33150 (epoch 33.376), train_loss = 0.98398766, grad/param norm = 1.7252e-01, time/batch = 0.6734s	
22129/33150 (epoch 33.377), train_loss = 0.80657828, grad/param norm = 1.7691e-01, time/batch = 0.6789s	
22130/33150 (epoch 33.379), train_loss = 0.93465289, grad/param norm = 2.0982e-01, time/batch = 0.6808s	
22131/33150 (epoch 33.380), train_loss = 0.94346276, grad/param norm = 1.5230e-01, time/batch = 0.6793s	
22132/33150 (epoch 33.382), train_loss = 0.87014354, grad/param norm = 1.6836e-01, time/batch = 0.6985s	
22133/33150 (epoch 33.383), train_loss = 0.81604097, grad/param norm = 1.6236e-01, time/batch = 0.6829s	
22134/33150 (epoch 33.385), train_loss = 0.85273916, grad/param norm = 1.7665e-01, time/batch = 0.6679s	
22135/33150 (epoch 33.386), train_loss = 0.78032138, grad/param norm = 1.5183e-01, time/batch = 0.6702s	
22136/33150 (epoch 33.388), train_loss = 0.81730384, grad/param norm = 1.6392e-01, time/batch = 0.6699s	
22137/33150 (epoch 33.389), train_loss = 0.81497318, grad/param norm = 1.5768e-01, time/batch = 0.6664s	
22138/33150 (epoch 33.391), train_loss = 1.03631253, grad/param norm = 1.8892e-01, time/batch = 0.6693s	
22139/33150 (epoch 33.392), train_loss = 0.84029178, grad/param norm = 1.7506e-01, time/batch = 0.6674s	
22140/33150 (epoch 33.394), train_loss = 0.75999847, grad/param norm = 1.3963e-01, time/batch = 0.6654s	
22141/33150 (epoch 33.395), train_loss = 0.72188352, grad/param norm = 1.4866e-01, time/batch = 0.6697s	
22142/33150 (epoch 33.397), train_loss = 0.61108819, grad/param norm = 1.3960e-01, time/batch = 0.6726s	
22143/33150 (epoch 33.398), train_loss = 0.87370390, grad/param norm = 1.6620e-01, time/batch = 0.6670s	
22144/33150 (epoch 33.400), train_loss = 0.85628582, grad/param norm = 1.4102e-01, time/batch = 0.6789s	
22145/33150 (epoch 33.401), train_loss = 0.75110286, grad/param norm = 1.4277e-01, time/batch = 0.6801s	
22146/33150 (epoch 33.403), train_loss = 0.74106482, grad/param norm = 1.3793e-01, time/batch = 0.6669s	
22147/33150 (epoch 33.404), train_loss = 0.89216371, grad/param norm = 1.6959e-01, time/batch = 0.6729s	
22148/33150 (epoch 33.406), train_loss = 0.82753347, grad/param norm = 1.3345e-01, time/batch = 0.6884s	
22149/33150 (epoch 33.407), train_loss = 0.75832102, grad/param norm = 1.5230e-01, time/batch = 0.6930s	
22150/33150 (epoch 33.409), train_loss = 0.72305314, grad/param norm = 1.6635e-01, time/batch = 0.6860s	
22151/33150 (epoch 33.410), train_loss = 0.90141920, grad/param norm = 1.6936e-01, time/batch = 0.6833s	
22152/33150 (epoch 33.412), train_loss = 0.92039277, grad/param norm = 1.5595e-01, time/batch = 0.6748s	
22153/33150 (epoch 33.413), train_loss = 0.78517141, grad/param norm = 1.5690e-01, time/batch = 0.6764s	
22154/33150 (epoch 33.415), train_loss = 0.91592547, grad/param norm = 1.6442e-01, time/batch = 0.6743s	
22155/33150 (epoch 33.416), train_loss = 0.80862622, grad/param norm = 1.4760e-01, time/batch = 0.6778s	
22156/33150 (epoch 33.418), train_loss = 0.93110489, grad/param norm = 2.3869e-01, time/batch = 0.7002s	
22157/33150 (epoch 33.419), train_loss = 0.86840115, grad/param norm = 1.7087e-01, time/batch = 0.6751s	
22158/33150 (epoch 33.421), train_loss = 0.86832203, grad/param norm = 1.7578e-01, time/batch = 0.6767s	
22159/33150 (epoch 33.422), train_loss = 0.82473054, grad/param norm = 1.5235e-01, time/batch = 0.6821s	
22160/33150 (epoch 33.424), train_loss = 0.82969189, grad/param norm = 1.7921e-01, time/batch = 0.6770s	
22161/33150 (epoch 33.425), train_loss = 0.95236998, grad/param norm = 1.6769e-01, time/batch = 0.6727s	
22162/33150 (epoch 33.427), train_loss = 0.86380423, grad/param norm = 1.5062e-01, time/batch = 0.6714s	
22163/33150 (epoch 33.428), train_loss = 0.86156307, grad/param norm = 1.6702e-01, time/batch = 0.6746s	
22164/33150 (epoch 33.430), train_loss = 0.89824006, grad/param norm = 1.7230e-01, time/batch = 0.6799s	
22165/33150 (epoch 33.431), train_loss = 0.93209368, grad/param norm = 1.8197e-01, time/batch = 0.6932s	
22166/33150 (epoch 33.433), train_loss = 0.84791317, grad/param norm = 1.5948e-01, time/batch = 0.6852s	
22167/33150 (epoch 33.434), train_loss = 0.75821732, grad/param norm = 1.5248e-01, time/batch = 0.6802s	
22168/33150 (epoch 33.436), train_loss = 0.87172222, grad/param norm = 1.5370e-01, time/batch = 0.6750s	
22169/33150 (epoch 33.437), train_loss = 0.88519729, grad/param norm = 1.8357e-01, time/batch = 0.6860s	
22170/33150 (epoch 33.439), train_loss = 1.03063698, grad/param norm = 1.7636e-01, time/batch = 0.6701s	
22171/33150 (epoch 33.440), train_loss = 0.93009789, grad/param norm = 1.8639e-01, time/batch = 0.6740s	
22172/33150 (epoch 33.442), train_loss = 0.76155502, grad/param norm = 1.5857e-01, time/batch = 0.6924s	
22173/33150 (epoch 33.443), train_loss = 0.90290936, grad/param norm = 1.7411e-01, time/batch = 0.6844s	
22174/33150 (epoch 33.445), train_loss = 0.88482340, grad/param norm = 1.8095e-01, time/batch = 0.6824s	
22175/33150 (epoch 33.446), train_loss = 0.92089259, grad/param norm = 2.1838e-01, time/batch = 0.6857s	
22176/33150 (epoch 33.448), train_loss = 0.99042346, grad/param norm = 1.8179e-01, time/batch = 0.6847s	
22177/33150 (epoch 33.449), train_loss = 0.88822685, grad/param norm = 1.5342e-01, time/batch = 0.6797s	
22178/33150 (epoch 33.451), train_loss = 0.88928999, grad/param norm = 2.0191e-01, time/batch = 0.6737s	
22179/33150 (epoch 33.452), train_loss = 1.05104396, grad/param norm = 1.8346e-01, time/batch = 0.6712s	
22180/33150 (epoch 33.454), train_loss = 0.87792617, grad/param norm = 1.8509e-01, time/batch = 0.6676s	
22181/33150 (epoch 33.456), train_loss = 0.80672642, grad/param norm = 1.6299e-01, time/batch = 0.6756s	
22182/33150 (epoch 33.457), train_loss = 0.90089268, grad/param norm = 1.7120e-01, time/batch = 0.6716s	
22183/33150 (epoch 33.459), train_loss = 1.00312928, grad/param norm = 2.4269e-01, time/batch = 0.6683s	
22184/33150 (epoch 33.460), train_loss = 0.93956870, grad/param norm = 1.5213e-01, time/batch = 0.6673s	
22185/33150 (epoch 33.462), train_loss = 0.98265995, grad/param norm = 2.0220e-01, time/batch = 0.6681s	
22186/33150 (epoch 33.463), train_loss = 1.11235455, grad/param norm = 2.3447e-01, time/batch = 0.6657s	
22187/33150 (epoch 33.465), train_loss = 0.94480873, grad/param norm = 1.6236e-01, time/batch = 0.6693s	
22188/33150 (epoch 33.466), train_loss = 0.85046051, grad/param norm = 1.7195e-01, time/batch = 0.6789s	
22189/33150 (epoch 33.468), train_loss = 1.10210659, grad/param norm = 1.8301e-01, time/batch = 0.6787s	
22190/33150 (epoch 33.469), train_loss = 0.84839797, grad/param norm = 1.7757e-01, time/batch = 0.6707s	
22191/33150 (epoch 33.471), train_loss = 0.82222092, grad/param norm = 1.6193e-01, time/batch = 0.6701s	
22192/33150 (epoch 33.472), train_loss = 0.89944905, grad/param norm = 1.7486e-01, time/batch = 0.6695s	
22193/33150 (epoch 33.474), train_loss = 0.94728884, grad/param norm = 2.0063e-01, time/batch = 0.6691s	
22194/33150 (epoch 33.475), train_loss = 1.12269705, grad/param norm = 1.8637e-01, time/batch = 0.6726s	
22195/33150 (epoch 33.477), train_loss = 0.96674506, grad/param norm = 1.8939e-01, time/batch = 0.6709s	
22196/33150 (epoch 33.478), train_loss = 0.93394295, grad/param norm = 1.6024e-01, time/batch = 0.6703s	
22197/33150 (epoch 33.480), train_loss = 0.83187907, grad/param norm = 1.7578e-01, time/batch = 0.6722s	
22198/33150 (epoch 33.481), train_loss = 0.76265258, grad/param norm = 1.6951e-01, time/batch = 0.6742s	
22199/33150 (epoch 33.483), train_loss = 0.85690351, grad/param norm = 1.7330e-01, time/batch = 0.6729s	
22200/33150 (epoch 33.484), train_loss = 0.82149773, grad/param norm = 1.7298e-01, time/batch = 0.6735s	
22201/33150 (epoch 33.486), train_loss = 0.80944658, grad/param norm = 1.7370e-01, time/batch = 0.6910s	
22202/33150 (epoch 33.487), train_loss = 0.91271027, grad/param norm = 1.7104e-01, time/batch = 0.6912s	
22203/33150 (epoch 33.489), train_loss = 0.88437776, grad/param norm = 1.8159e-01, time/batch = 0.6834s	
22204/33150 (epoch 33.490), train_loss = 0.71779736, grad/param norm = 1.3108e-01, time/batch = 0.6871s	
22205/33150 (epoch 33.492), train_loss = 0.83548456, grad/param norm = 1.8883e-01, time/batch = 0.6801s	
22206/33150 (epoch 33.493), train_loss = 0.94563118, grad/param norm = 1.6799e-01, time/batch = 0.6788s	
22207/33150 (epoch 33.495), train_loss = 0.95114951, grad/param norm = 1.5904e-01, time/batch = 0.6831s	
22208/33150 (epoch 33.496), train_loss = 0.85835663, grad/param norm = 1.5591e-01, time/batch = 0.6755s	
22209/33150 (epoch 33.498), train_loss = 0.98937115, grad/param norm = 2.3226e-01, time/batch = 0.6843s	
22210/33150 (epoch 33.499), train_loss = 0.99399077, grad/param norm = 1.7480e-01, time/batch = 0.6821s	
22211/33150 (epoch 33.501), train_loss = 0.94789746, grad/param norm = 1.9463e-01, time/batch = 0.6761s	
22212/33150 (epoch 33.502), train_loss = 1.00136513, grad/param norm = 2.1788e-01, time/batch = 0.6704s	
22213/33150 (epoch 33.504), train_loss = 0.96183069, grad/param norm = 1.8405e-01, time/batch = 0.6673s	
22214/33150 (epoch 33.505), train_loss = 1.02554916, grad/param norm = 1.8239e-01, time/batch = 0.6674s	
22215/33150 (epoch 33.507), train_loss = 0.83954333, grad/param norm = 1.7852e-01, time/batch = 0.6697s	
22216/33150 (epoch 33.508), train_loss = 0.84681152, grad/param norm = 1.8364e-01, time/batch = 0.6691s	
22217/33150 (epoch 33.510), train_loss = 0.96550282, grad/param norm = 1.5205e-01, time/batch = 0.6754s	
22218/33150 (epoch 33.511), train_loss = 0.99704356, grad/param norm = 1.8354e-01, time/batch = 0.6741s	
22219/33150 (epoch 33.513), train_loss = 0.92341571, grad/param norm = 2.0726e-01, time/batch = 0.6706s	
22220/33150 (epoch 33.514), train_loss = 0.79056487, grad/param norm = 1.7659e-01, time/batch = 0.6760s	
22221/33150 (epoch 33.516), train_loss = 0.91161648, grad/param norm = 1.9937e-01, time/batch = 0.6899s	
22222/33150 (epoch 33.517), train_loss = 0.97817453, grad/param norm = 1.7826e-01, time/batch = 0.6700s	
22223/33150 (epoch 33.519), train_loss = 0.82132202, grad/param norm = 1.5786e-01, time/batch = 0.6706s	
22224/33150 (epoch 33.520), train_loss = 0.91466948, grad/param norm = 1.7365e-01, time/batch = 0.6698s	
22225/33150 (epoch 33.522), train_loss = 0.99978158, grad/param norm = 2.7002e-01, time/batch = 0.6704s	
22226/33150 (epoch 33.523), train_loss = 0.80125366, grad/param norm = 1.8086e-01, time/batch = 0.6700s	
22227/33150 (epoch 33.525), train_loss = 0.93386232, grad/param norm = 1.8070e-01, time/batch = 0.6685s	
22228/33150 (epoch 33.526), train_loss = 0.82050520, grad/param norm = 1.8355e-01, time/batch = 0.6660s	
22229/33150 (epoch 33.528), train_loss = 0.89676564, grad/param norm = 1.6631e-01, time/batch = 0.6666s	
22230/33150 (epoch 33.529), train_loss = 0.89855399, grad/param norm = 1.8471e-01, time/batch = 0.6695s	
22231/33150 (epoch 33.531), train_loss = 0.75200184, grad/param norm = 1.9330e-01, time/batch = 0.6733s	
22232/33150 (epoch 33.532), train_loss = 0.92096968, grad/param norm = 2.4980e-01, time/batch = 0.6765s	
22233/33150 (epoch 33.534), train_loss = 0.89913347, grad/param norm = 1.6812e-01, time/batch = 0.6824s	
22234/33150 (epoch 33.535), train_loss = 0.83792545, grad/param norm = 2.1695e-01, time/batch = 0.6793s	
22235/33150 (epoch 33.537), train_loss = 0.93284091, grad/param norm = 2.2856e-01, time/batch = 0.6727s	
22236/33150 (epoch 33.538), train_loss = 0.79912672, grad/param norm = 1.6821e-01, time/batch = 0.6878s	
22237/33150 (epoch 33.540), train_loss = 0.78669503, grad/param norm = 1.6775e-01, time/batch = 0.6923s	
22238/33150 (epoch 33.541), train_loss = 0.97905412, grad/param norm = 1.7514e-01, time/batch = 0.7012s	
22239/33150 (epoch 33.543), train_loss = 0.90326661, grad/param norm = 1.8649e-01, time/batch = 0.6843s	
22240/33150 (epoch 33.544), train_loss = 0.95441663, grad/param norm = 1.7066e-01, time/batch = 0.6787s	
22241/33150 (epoch 33.546), train_loss = 0.87618782, grad/param norm = 1.9031e-01, time/batch = 0.6737s	
22242/33150 (epoch 33.548), train_loss = 0.85244680, grad/param norm = 1.7857e-01, time/batch = 0.6891s	
22243/33150 (epoch 33.549), train_loss = 0.81943689, grad/param norm = 1.6035e-01, time/batch = 0.6811s	
22244/33150 (epoch 33.551), train_loss = 0.81527858, grad/param norm = 1.5622e-01, time/batch = 0.6669s	
22245/33150 (epoch 33.552), train_loss = 0.69213344, grad/param norm = 1.3137e-01, time/batch = 0.6893s	
22246/33150 (epoch 33.554), train_loss = 0.93925644, grad/param norm = 1.9071e-01, time/batch = 0.6733s	
22247/33150 (epoch 33.555), train_loss = 0.98942858, grad/param norm = 2.0261e-01, time/batch = 0.6734s	
22248/33150 (epoch 33.557), train_loss = 0.73000542, grad/param norm = 1.8217e-01, time/batch = 0.6704s	
22249/33150 (epoch 33.558), train_loss = 0.92640337, grad/param norm = 2.1375e-01, time/batch = 0.6729s	
22250/33150 (epoch 33.560), train_loss = 0.83001422, grad/param norm = 1.6075e-01, time/batch = 0.6774s	
22251/33150 (epoch 33.561), train_loss = 0.74119304, grad/param norm = 1.6430e-01, time/batch = 0.6773s	
22252/33150 (epoch 33.563), train_loss = 0.94577099, grad/param norm = 2.6953e-01, time/batch = 0.6717s	
22253/33150 (epoch 33.564), train_loss = 0.99336651, grad/param norm = 1.5624e-01, time/batch = 0.6789s	
22254/33150 (epoch 33.566), train_loss = 0.81906310, grad/param norm = 1.6835e-01, time/batch = 0.6815s	
22255/33150 (epoch 33.567), train_loss = 0.82399035, grad/param norm = 1.7042e-01, time/batch = 0.6825s	
22256/33150 (epoch 33.569), train_loss = 0.90105545, grad/param norm = 1.8042e-01, time/batch = 0.6721s	
22257/33150 (epoch 33.570), train_loss = 0.93551299, grad/param norm = 1.6389e-01, time/batch = 0.6903s	
22258/33150 (epoch 33.572), train_loss = 0.80423035, grad/param norm = 1.6576e-01, time/batch = 0.6694s	
22259/33150 (epoch 33.573), train_loss = 0.73084245, grad/param norm = 1.4106e-01, time/batch = 0.6759s	
22260/33150 (epoch 33.575), train_loss = 0.84905665, grad/param norm = 1.9061e-01, time/batch = 0.6775s	
22261/33150 (epoch 33.576), train_loss = 0.76961079, grad/param norm = 1.4355e-01, time/batch = 0.6753s	
22262/33150 (epoch 33.578), train_loss = 0.80150672, grad/param norm = 1.4728e-01, time/batch = 0.6741s	
22263/33150 (epoch 33.579), train_loss = 0.76613494, grad/param norm = 1.6558e-01, time/batch = 0.6719s	
22264/33150 (epoch 33.581), train_loss = 0.79183651, grad/param norm = 1.7004e-01, time/batch = 0.6729s	
22265/33150 (epoch 33.582), train_loss = 0.99935242, grad/param norm = 1.5696e-01, time/batch = 0.6715s	
22266/33150 (epoch 33.584), train_loss = 0.97348052, grad/param norm = 2.1216e-01, time/batch = 0.6702s	
22267/33150 (epoch 33.585), train_loss = 0.89986720, grad/param norm = 1.8821e-01, time/batch = 0.6714s	
22268/33150 (epoch 33.587), train_loss = 0.88635058, grad/param norm = 1.5593e-01, time/batch = 0.6707s	
22269/33150 (epoch 33.588), train_loss = 0.81518383, grad/param norm = 1.6944e-01, time/batch = 0.6827s	
22270/33150 (epoch 33.590), train_loss = 0.92147548, grad/param norm = 1.8120e-01, time/batch = 0.6712s	
22271/33150 (epoch 33.591), train_loss = 0.88085052, grad/param norm = 1.7237e-01, time/batch = 0.6728s	
22272/33150 (epoch 33.593), train_loss = 0.94374597, grad/param norm = 2.0015e-01, time/batch = 0.6733s	
22273/33150 (epoch 33.594), train_loss = 0.84014043, grad/param norm = 1.6264e-01, time/batch = 0.6754s	
22274/33150 (epoch 33.596), train_loss = 0.84751341, grad/param norm = 1.6707e-01, time/batch = 0.6904s	
22275/33150 (epoch 33.597), train_loss = 0.77458793, grad/param norm = 1.8795e-01, time/batch = 0.6697s	
22276/33150 (epoch 33.599), train_loss = 1.05147601, grad/param norm = 2.6221e-01, time/batch = 0.6859s	
22277/33150 (epoch 33.600), train_loss = 0.88777357, grad/param norm = 2.4873e-01, time/batch = 0.6836s	
22278/33150 (epoch 33.602), train_loss = 0.87991425, grad/param norm = 1.7482e-01, time/batch = 0.6769s	
22279/33150 (epoch 33.603), train_loss = 0.97929363, grad/param norm = 1.8314e-01, time/batch = 0.6751s	
22280/33150 (epoch 33.605), train_loss = 0.78889016, grad/param norm = 1.5631e-01, time/batch = 0.6819s	
22281/33150 (epoch 33.606), train_loss = 0.83105476, grad/param norm = 2.2604e-01, time/batch = 0.6907s	
22282/33150 (epoch 33.608), train_loss = 0.95188758, grad/param norm = 1.5192e-01, time/batch = 0.6692s	
22283/33150 (epoch 33.609), train_loss = 0.87520643, grad/param norm = 2.1232e-01, time/batch = 0.6697s	
22284/33150 (epoch 33.611), train_loss = 0.78259845, grad/param norm = 1.7128e-01, time/batch = 0.6699s	
22285/33150 (epoch 33.612), train_loss = 0.86532935, grad/param norm = 1.7856e-01, time/batch = 0.6744s	
22286/33150 (epoch 33.614), train_loss = 0.79623807, grad/param norm = 1.5096e-01, time/batch = 0.6729s	
22287/33150 (epoch 33.615), train_loss = 0.77802921, grad/param norm = 1.6564e-01, time/batch = 0.6747s	
22288/33150 (epoch 33.617), train_loss = 0.89933365, grad/param norm = 1.9674e-01, time/batch = 0.6741s	
22289/33150 (epoch 33.618), train_loss = 0.92803232, grad/param norm = 2.0268e-01, time/batch = 0.6714s	
22290/33150 (epoch 33.620), train_loss = 0.84155503, grad/param norm = 1.7950e-01, time/batch = 0.6730s	
22291/33150 (epoch 33.621), train_loss = 0.87992792, grad/param norm = 1.5340e-01, time/batch = 0.6809s	
22292/33150 (epoch 33.623), train_loss = 0.93383607, grad/param norm = 1.4899e-01, time/batch = 0.6825s	
22293/33150 (epoch 33.624), train_loss = 0.84200658, grad/param norm = 1.8230e-01, time/batch = 0.6725s	
22294/33150 (epoch 33.626), train_loss = 0.87388501, grad/param norm = 1.7200e-01, time/batch = 0.6700s	
22295/33150 (epoch 33.627), train_loss = 0.82973828, grad/param norm = 1.7759e-01, time/batch = 0.6703s	
22296/33150 (epoch 33.629), train_loss = 0.75550265, grad/param norm = 1.7600e-01, time/batch = 0.6734s	
22297/33150 (epoch 33.630), train_loss = 0.86116000, grad/param norm = 1.8583e-01, time/batch = 0.6725s	
22298/33150 (epoch 33.632), train_loss = 0.74897092, grad/param norm = 1.4371e-01, time/batch = 0.6786s	
22299/33150 (epoch 33.633), train_loss = 0.79925714, grad/param norm = 1.9684e-01, time/batch = 0.6710s	
22300/33150 (epoch 33.635), train_loss = 1.01126051, grad/param norm = 1.7279e-01, time/batch = 0.6766s	
22301/33150 (epoch 33.637), train_loss = 0.71479043, grad/param norm = 1.5716e-01, time/batch = 0.6690s	
22302/33150 (epoch 33.638), train_loss = 0.84851231, grad/param norm = 1.7167e-01, time/batch = 0.6697s	
22303/33150 (epoch 33.640), train_loss = 0.95459301, grad/param norm = 1.8701e-01, time/batch = 0.6747s	
22304/33150 (epoch 33.641), train_loss = 0.74207981, grad/param norm = 1.8225e-01, time/batch = 0.6921s	
22305/33150 (epoch 33.643), train_loss = 0.88372751, grad/param norm = 1.6250e-01, time/batch = 0.6777s	
22306/33150 (epoch 33.644), train_loss = 1.02027933, grad/param norm = 1.7264e-01, time/batch = 0.6830s	
22307/33150 (epoch 33.646), train_loss = 0.83676403, grad/param norm = 1.5811e-01, time/batch = 0.6782s	
22308/33150 (epoch 33.647), train_loss = 1.06224026, grad/param norm = 1.8260e-01, time/batch = 0.6806s	
22309/33150 (epoch 33.649), train_loss = 0.92800808, grad/param norm = 1.8527e-01, time/batch = 0.6742s	
22310/33150 (epoch 33.650), train_loss = 0.78629196, grad/param norm = 1.6036e-01, time/batch = 0.6711s	
22311/33150 (epoch 33.652), train_loss = 0.99874490, grad/param norm = 2.0267e-01, time/batch = 0.6693s	
22312/33150 (epoch 33.653), train_loss = 0.91979196, grad/param norm = 1.6942e-01, time/batch = 0.6673s	
22313/33150 (epoch 33.655), train_loss = 0.90791418, grad/param norm = 1.9318e-01, time/batch = 0.6710s	
22314/33150 (epoch 33.656), train_loss = 0.83626527, grad/param norm = 1.4888e-01, time/batch = 0.6699s	
22315/33150 (epoch 33.658), train_loss = 0.84951648, grad/param norm = 1.7800e-01, time/batch = 0.6730s	
22316/33150 (epoch 33.659), train_loss = 1.11139956, grad/param norm = 3.1429e-01, time/batch = 0.6706s	
22317/33150 (epoch 33.661), train_loss = 0.88190831, grad/param norm = 1.7939e-01, time/batch = 0.6678s	
22318/33150 (epoch 33.662), train_loss = 0.84942357, grad/param norm = 1.8377e-01, time/batch = 0.6690s	
22319/33150 (epoch 33.664), train_loss = 0.99104992, grad/param norm = 1.9155e-01, time/batch = 0.6689s	
22320/33150 (epoch 33.665), train_loss = 0.96534014, grad/param norm = 2.0612e-01, time/batch = 0.6709s	
22321/33150 (epoch 33.667), train_loss = 0.96149821, grad/param norm = 1.8093e-01, time/batch = 0.6831s	
22322/33150 (epoch 33.668), train_loss = 1.02898358, grad/param norm = 1.9682e-01, time/batch = 0.6765s	
22323/33150 (epoch 33.670), train_loss = 0.81337086, grad/param norm = 1.4780e-01, time/batch = 0.6772s	
22324/33150 (epoch 33.671), train_loss = 0.80632275, grad/param norm = 1.7492e-01, time/batch = 0.6818s	
22325/33150 (epoch 33.673), train_loss = 0.98938068, grad/param norm = 1.5276e-01, time/batch = 0.6855s	
22326/33150 (epoch 33.674), train_loss = 0.94396501, grad/param norm = 1.9207e-01, time/batch = 0.6903s	
22327/33150 (epoch 33.676), train_loss = 0.87857898, grad/param norm = 1.6528e-01, time/batch = 0.6884s	
22328/33150 (epoch 33.677), train_loss = 1.02412865, grad/param norm = 2.0055e-01, time/batch = 0.6852s	
22329/33150 (epoch 33.679), train_loss = 0.88269936, grad/param norm = 1.5050e-01, time/batch = 0.6663s	
22330/33150 (epoch 33.680), train_loss = 0.99919569, grad/param norm = 1.7999e-01, time/batch = 0.6690s	
22331/33150 (epoch 33.682), train_loss = 0.88380917, grad/param norm = 1.6785e-01, time/batch = 0.6921s	
22332/33150 (epoch 33.683), train_loss = 0.75394852, grad/param norm = 1.5850e-01, time/batch = 0.6920s	
22333/33150 (epoch 33.685), train_loss = 0.84579361, grad/param norm = 1.7952e-01, time/batch = 0.6810s	
22334/33150 (epoch 33.686), train_loss = 0.75638962, grad/param norm = 1.6016e-01, time/batch = 0.6754s	
22335/33150 (epoch 33.688), train_loss = 0.77584101, grad/param norm = 1.7481e-01, time/batch = 0.6759s	
22336/33150 (epoch 33.689), train_loss = 0.79629817, grad/param norm = 1.5461e-01, time/batch = 0.6852s	
22337/33150 (epoch 33.691), train_loss = 0.70070681, grad/param norm = 1.5079e-01, time/batch = 0.6702s	
22338/33150 (epoch 33.692), train_loss = 0.78676352, grad/param norm = 1.6268e-01, time/batch = 0.6745s	
22339/33150 (epoch 33.694), train_loss = 0.69611530, grad/param norm = 1.6524e-01, time/batch = 0.6693s	
22340/33150 (epoch 33.695), train_loss = 0.82070090, grad/param norm = 1.4598e-01, time/batch = 0.6734s	
22341/33150 (epoch 33.697), train_loss = 0.77939248, grad/param norm = 1.7122e-01, time/batch = 0.6720s	
22342/33150 (epoch 33.698), train_loss = 0.79110974, grad/param norm = 1.6936e-01, time/batch = 0.6714s	
22343/33150 (epoch 33.700), train_loss = 0.67100732, grad/param norm = 1.3315e-01, time/batch = 0.6725s	
22344/33150 (epoch 33.701), train_loss = 0.77074346, grad/param norm = 1.6184e-01, time/batch = 0.6683s	
22345/33150 (epoch 33.703), train_loss = 0.86485991, grad/param norm = 1.9077e-01, time/batch = 0.6757s	
22346/33150 (epoch 33.704), train_loss = 0.76872737, grad/param norm = 1.5581e-01, time/batch = 0.6766s	
22347/33150 (epoch 33.706), train_loss = 0.82085263, grad/param norm = 1.5049e-01, time/batch = 0.6704s	
22348/33150 (epoch 33.707), train_loss = 0.82523656, grad/param norm = 1.7071e-01, time/batch = 0.6722s	
22349/33150 (epoch 33.709), train_loss = 0.88007291, grad/param norm = 1.4709e-01, time/batch = 0.6744s	
22350/33150 (epoch 33.710), train_loss = 0.86803508, grad/param norm = 1.8942e-01, time/batch = 0.6836s	
22351/33150 (epoch 33.712), train_loss = 0.93010297, grad/param norm = 1.5680e-01, time/batch = 0.6788s	
22352/33150 (epoch 33.713), train_loss = 0.89478573, grad/param norm = 1.5347e-01, time/batch = 0.6726s	
22353/33150 (epoch 33.715), train_loss = 0.84115551, grad/param norm = 1.4915e-01, time/batch = 0.6793s	
22354/33150 (epoch 33.716), train_loss = 0.92609882, grad/param norm = 1.7366e-01, time/batch = 0.6963s	
22355/33150 (epoch 33.718), train_loss = 0.88758071, grad/param norm = 1.8802e-01, time/batch = 0.6903s	
22356/33150 (epoch 33.719), train_loss = 0.96467036, grad/param norm = 2.3041e-01, time/batch = 0.6709s	
22357/33150 (epoch 33.721), train_loss = 0.86317447, grad/param norm = 1.9567e-01, time/batch = 0.6766s	
22358/33150 (epoch 33.722), train_loss = 0.89528193, grad/param norm = 1.6141e-01, time/batch = 0.6715s	
22359/33150 (epoch 33.724), train_loss = 0.84609364, grad/param norm = 1.7851e-01, time/batch = 0.6695s	
22360/33150 (epoch 33.725), train_loss = 0.93750151, grad/param norm = 2.0630e-01, time/batch = 0.6737s	
22361/33150 (epoch 33.727), train_loss = 0.92824572, grad/param norm = 1.9831e-01, time/batch = 0.6774s	
22362/33150 (epoch 33.729), train_loss = 0.87327604, grad/param norm = 1.8441e-01, time/batch = 0.6733s	
22363/33150 (epoch 33.730), train_loss = 0.89355391, grad/param norm = 1.8221e-01, time/batch = 0.6747s	
22364/33150 (epoch 33.732), train_loss = 0.92760618, grad/param norm = 1.8311e-01, time/batch = 0.6728s	
22365/33150 (epoch 33.733), train_loss = 0.75310593, grad/param norm = 1.5271e-01, time/batch = 0.6742s	
22366/33150 (epoch 33.735), train_loss = 0.80400665, grad/param norm = 1.6214e-01, time/batch = 0.6755s	
22367/33150 (epoch 33.736), train_loss = 0.83845350, grad/param norm = 1.9402e-01, time/batch = 0.6739s	
22368/33150 (epoch 33.738), train_loss = 0.87363229, grad/param norm = 1.8745e-01, time/batch = 0.6769s	
22369/33150 (epoch 33.739), train_loss = 0.95441986, grad/param norm = 1.8396e-01, time/batch = 0.6757s	
22370/33150 (epoch 33.741), train_loss = 0.93537351, grad/param norm = 2.0047e-01, time/batch = 0.6724s	
22371/33150 (epoch 33.742), train_loss = 0.75056109, grad/param norm = 1.5470e-01, time/batch = 0.6749s	
22372/33150 (epoch 33.744), train_loss = 0.94212165, grad/param norm = 1.7635e-01, time/batch = 0.6730s	
22373/33150 (epoch 33.745), train_loss = 0.82946784, grad/param norm = 1.4746e-01, time/batch = 0.6699s	
22374/33150 (epoch 33.747), train_loss = 0.66678203, grad/param norm = 1.6009e-01, time/batch = 0.6723s	
22375/33150 (epoch 33.748), train_loss = 0.74531891, grad/param norm = 1.5497e-01, time/batch = 0.6722s	
22376/33150 (epoch 33.750), train_loss = 0.90391303, grad/param norm = 1.7432e-01, time/batch = 0.6739s	
22377/33150 (epoch 33.751), train_loss = 0.85803877, grad/param norm = 1.5501e-01, time/batch = 0.6685s	
22378/33150 (epoch 33.753), train_loss = 0.76000163, grad/param norm = 2.0189e-01, time/batch = 0.6681s	
22379/33150 (epoch 33.754), train_loss = 1.06559491, grad/param norm = 2.3119e-01, time/batch = 0.6730s	
22380/33150 (epoch 33.756), train_loss = 0.88039089, grad/param norm = 2.1660e-01, time/batch = 0.6665s	
22381/33150 (epoch 33.757), train_loss = 0.89790914, grad/param norm = 1.7333e-01, time/batch = 0.6728s	
22382/33150 (epoch 33.759), train_loss = 1.01262045, grad/param norm = 2.1593e-01, time/batch = 0.6706s	
22383/33150 (epoch 33.760), train_loss = 0.90264200, grad/param norm = 1.7992e-01, time/batch = 0.6688s	
22384/33150 (epoch 33.762), train_loss = 0.89375379, grad/param norm = 1.9702e-01, time/batch = 0.6791s	
22385/33150 (epoch 33.763), train_loss = 0.90420996, grad/param norm = 1.7311e-01, time/batch = 0.6747s	
22386/33150 (epoch 33.765), train_loss = 0.86126538, grad/param norm = 1.6514e-01, time/batch = 0.6729s	
22387/33150 (epoch 33.766), train_loss = 0.75720577, grad/param norm = 1.6173e-01, time/batch = 0.6695s	
22388/33150 (epoch 33.768), train_loss = 0.79802281, grad/param norm = 1.5579e-01, time/batch = 0.6712s	
22389/33150 (epoch 33.769), train_loss = 0.93342351, grad/param norm = 1.7405e-01, time/batch = 0.6692s	
22390/33150 (epoch 33.771), train_loss = 0.88387690, grad/param norm = 1.8955e-01, time/batch = 0.6754s	
22391/33150 (epoch 33.772), train_loss = 0.91109586, grad/param norm = 1.7913e-01, time/batch = 0.6746s	
22392/33150 (epoch 33.774), train_loss = 1.00889653, grad/param norm = 1.7695e-01, time/batch = 0.6750s	
22393/33150 (epoch 33.775), train_loss = 0.93301899, grad/param norm = 2.2954e-01, time/batch = 0.6827s	
22394/33150 (epoch 33.777), train_loss = 0.93986157, grad/param norm = 1.7870e-01, time/batch = 0.6946s	
22395/33150 (epoch 33.778), train_loss = 0.86749374, grad/param norm = 1.5022e-01, time/batch = 0.6714s	
22396/33150 (epoch 33.780), train_loss = 0.75418082, grad/param norm = 1.8027e-01, time/batch = 0.6710s	
22397/33150 (epoch 33.781), train_loss = 0.87520106, grad/param norm = 1.5970e-01, time/batch = 0.6699s	
22398/33150 (epoch 33.783), train_loss = 0.87185443, grad/param norm = 1.6393e-01, time/batch = 0.6707s	
22399/33150 (epoch 33.784), train_loss = 0.86440907, grad/param norm = 1.9015e-01, time/batch = 0.6765s	
22400/33150 (epoch 33.786), train_loss = 0.84723413, grad/param norm = 1.6410e-01, time/batch = 0.6852s	
22401/33150 (epoch 33.787), train_loss = 0.79640726, grad/param norm = 1.5197e-01, time/batch = 0.6809s	
22402/33150 (epoch 33.789), train_loss = 0.74127673, grad/param norm = 1.5880e-01, time/batch = 0.6724s	
22403/33150 (epoch 33.790), train_loss = 0.75020759, grad/param norm = 1.5998e-01, time/batch = 0.6739s	
22404/33150 (epoch 33.792), train_loss = 0.88201710, grad/param norm = 1.8698e-01, time/batch = 0.6681s	
22405/33150 (epoch 33.793), train_loss = 0.84777653, grad/param norm = 1.8407e-01, time/batch = 0.6677s	
22406/33150 (epoch 33.795), train_loss = 0.81693265, grad/param norm = 1.8080e-01, time/batch = 0.6693s	
22407/33150 (epoch 33.796), train_loss = 0.83786026, grad/param norm = 1.5148e-01, time/batch = 0.6707s	
22408/33150 (epoch 33.798), train_loss = 0.80290645, grad/param norm = 1.3412e-01, time/batch = 0.6813s	
22409/33150 (epoch 33.799), train_loss = 0.73969139, grad/param norm = 1.6900e-01, time/batch = 0.6884s	
22410/33150 (epoch 33.801), train_loss = 0.87440480, grad/param norm = 1.5916e-01, time/batch = 0.6783s	
22411/33150 (epoch 33.802), train_loss = 0.81595650, grad/param norm = 1.5646e-01, time/batch = 0.6776s	
22412/33150 (epoch 33.804), train_loss = 0.85211808, grad/param norm = 1.8599e-01, time/batch = 0.6792s	
22413/33150 (epoch 33.805), train_loss = 0.81973642, grad/param norm = 1.9482e-01, time/batch = 0.6906s	
22414/33150 (epoch 33.807), train_loss = 0.83612031, grad/param norm = 1.5041e-01, time/batch = 0.6908s	
22415/33150 (epoch 33.808), train_loss = 0.96213055, grad/param norm = 1.7341e-01, time/batch = 0.7034s	
22416/33150 (epoch 33.810), train_loss = 0.79764598, grad/param norm = 1.6247e-01, time/batch = 0.6876s	
22417/33150 (epoch 33.811), train_loss = 0.90006029, grad/param norm = 1.9101e-01, time/batch = 0.6720s	
22418/33150 (epoch 33.813), train_loss = 0.83258184, grad/param norm = 1.5239e-01, time/batch = 0.6810s	
22419/33150 (epoch 33.814), train_loss = 0.81034852, grad/param norm = 1.9817e-01, time/batch = 0.6784s	
22420/33150 (epoch 33.816), train_loss = 0.83847015, grad/param norm = 1.7154e-01, time/batch = 0.6908s	
22421/33150 (epoch 33.817), train_loss = 0.91861414, grad/param norm = 1.6560e-01, time/batch = 0.6762s	
22422/33150 (epoch 33.819), train_loss = 0.89759329, grad/param norm = 1.7862e-01, time/batch = 0.6714s	
22423/33150 (epoch 33.821), train_loss = 0.75774278, grad/param norm = 1.4396e-01, time/batch = 0.6686s	
22424/33150 (epoch 33.822), train_loss = 0.80009945, grad/param norm = 1.5585e-01, time/batch = 0.6734s	
22425/33150 (epoch 33.824), train_loss = 0.88758494, grad/param norm = 1.7983e-01, time/batch = 0.6716s	
22426/33150 (epoch 33.825), train_loss = 0.88862789, grad/param norm = 1.7449e-01, time/batch = 0.6725s	
22427/33150 (epoch 33.827), train_loss = 0.91998865, grad/param norm = 1.9712e-01, time/batch = 0.6753s	
22428/33150 (epoch 33.828), train_loss = 0.78037155, grad/param norm = 1.5864e-01, time/batch = 0.6762s	
22429/33150 (epoch 33.830), train_loss = 0.92577965, grad/param norm = 1.8674e-01, time/batch = 0.6686s	
22430/33150 (epoch 33.831), train_loss = 0.79560051, grad/param norm = 1.5963e-01, time/batch = 0.6810s	
22431/33150 (epoch 33.833), train_loss = 0.80480279, grad/param norm = 1.8836e-01, time/batch = 0.6795s	
22432/33150 (epoch 33.834), train_loss = 0.94790097, grad/param norm = 1.6829e-01, time/batch = 0.6729s	
22433/33150 (epoch 33.836), train_loss = 0.97313502, grad/param norm = 1.5931e-01, time/batch = 0.6764s	
22434/33150 (epoch 33.837), train_loss = 0.82000342, grad/param norm = 1.8356e-01, time/batch = 0.6758s	
22435/33150 (epoch 33.839), train_loss = 0.92035421, grad/param norm = 1.6951e-01, time/batch = 0.6715s	
22436/33150 (epoch 33.840), train_loss = 0.93070240, grad/param norm = 1.7812e-01, time/batch = 0.6726s	
22437/33150 (epoch 33.842), train_loss = 0.97431818, grad/param norm = 2.2734e-01, time/batch = 0.6720s	
22438/33150 (epoch 33.843), train_loss = 0.95366875, grad/param norm = 1.9573e-01, time/batch = 0.6759s	
22439/33150 (epoch 33.845), train_loss = 0.80490969, grad/param norm = 1.8023e-01, time/batch = 0.6816s	
22440/33150 (epoch 33.846), train_loss = 1.07465017, grad/param norm = 2.9836e-01, time/batch = 0.6772s	
22441/33150 (epoch 33.848), train_loss = 0.96838569, grad/param norm = 2.0603e-01, time/batch = 0.6785s	
22442/33150 (epoch 33.849), train_loss = 0.99655252, grad/param norm = 1.8678e-01, time/batch = 0.6745s	
22443/33150 (epoch 33.851), train_loss = 0.92554126, grad/param norm = 1.8283e-01, time/batch = 0.6746s	
22444/33150 (epoch 33.852), train_loss = 1.00432982, grad/param norm = 1.6888e-01, time/batch = 0.6753s	
22445/33150 (epoch 33.854), train_loss = 0.91703717, grad/param norm = 1.9305e-01, time/batch = 0.6783s	
22446/33150 (epoch 33.855), train_loss = 0.76340564, grad/param norm = 1.6661e-01, time/batch = 0.6736s	
22447/33150 (epoch 33.857), train_loss = 0.71579176, grad/param norm = 1.5707e-01, time/batch = 0.6853s	
22448/33150 (epoch 33.858), train_loss = 0.84090996, grad/param norm = 1.6021e-01, time/batch = 0.6772s	
22449/33150 (epoch 33.860), train_loss = 0.79832458, grad/param norm = 1.8606e-01, time/batch = 0.6690s	
22450/33150 (epoch 33.861), train_loss = 0.78740932, grad/param norm = 1.5528e-01, time/batch = 0.6697s	
22451/33150 (epoch 33.863), train_loss = 0.85365457, grad/param norm = 1.6337e-01, time/batch = 0.6725s	
22452/33150 (epoch 33.864), train_loss = 0.90526433, grad/param norm = 1.7225e-01, time/batch = 0.6712s	
22453/33150 (epoch 33.866), train_loss = 0.94671110, grad/param norm = 1.8455e-01, time/batch = 0.6783s	
22454/33150 (epoch 33.867), train_loss = 0.89098232, grad/param norm = 1.5202e-01, time/batch = 0.6814s	
22455/33150 (epoch 33.869), train_loss = 0.87967808, grad/param norm = 1.8112e-01, time/batch = 0.6828s	
22456/33150 (epoch 33.870), train_loss = 0.83504448, grad/param norm = 2.1768e-01, time/batch = 0.6792s	
22457/33150 (epoch 33.872), train_loss = 0.90657338, grad/param norm = 2.0048e-01, time/batch = 0.6720s	
22458/33150 (epoch 33.873), train_loss = 0.70779645, grad/param norm = 1.4433e-01, time/batch = 0.6856s	
22459/33150 (epoch 33.875), train_loss = 0.96771346, grad/param norm = 1.7937e-01, time/batch = 0.6710s	
22460/33150 (epoch 33.876), train_loss = 0.72489182, grad/param norm = 1.6208e-01, time/batch = 0.6722s	
22461/33150 (epoch 33.878), train_loss = 0.81535316, grad/param norm = 1.5185e-01, time/batch = 0.6723s	
22462/33150 (epoch 33.879), train_loss = 0.80479133, grad/param norm = 1.5243e-01, time/batch = 0.6732s	
22463/33150 (epoch 33.881), train_loss = 0.78478016, grad/param norm = 1.5211e-01, time/batch = 0.6800s	
22464/33150 (epoch 33.882), train_loss = 0.70078946, grad/param norm = 1.7305e-01, time/batch = 0.6794s	
22465/33150 (epoch 33.884), train_loss = 0.83044393, grad/param norm = 1.6157e-01, time/batch = 0.6759s	
22466/33150 (epoch 33.885), train_loss = 0.64551428, grad/param norm = 1.6063e-01, time/batch = 0.6737s	
22467/33150 (epoch 33.887), train_loss = 0.94781357, grad/param norm = 1.7704e-01, time/batch = 0.6749s	
22468/33150 (epoch 33.888), train_loss = 0.90251793, grad/param norm = 1.9544e-01, time/batch = 0.6860s	
22469/33150 (epoch 33.890), train_loss = 0.79560309, grad/param norm = 1.7783e-01, time/batch = 0.6740s	
22470/33150 (epoch 33.891), train_loss = 0.76051863, grad/param norm = 1.5321e-01, time/batch = 0.6745s	
22471/33150 (epoch 33.893), train_loss = 0.90356087, grad/param norm = 1.7472e-01, time/batch = 0.6768s	
22472/33150 (epoch 33.894), train_loss = 0.89260299, grad/param norm = 1.6106e-01, time/batch = 0.6770s	
22473/33150 (epoch 33.896), train_loss = 0.85030622, grad/param norm = 1.5640e-01, time/batch = 0.6809s	
22474/33150 (epoch 33.897), train_loss = 0.92131278, grad/param norm = 1.8768e-01, time/batch = 0.6734s	
22475/33150 (epoch 33.899), train_loss = 0.72157377, grad/param norm = 1.9894e-01, time/batch = 0.6741s	
22476/33150 (epoch 33.900), train_loss = 1.03382403, grad/param norm = 2.0142e-01, time/batch = 0.6736s	
22477/33150 (epoch 33.902), train_loss = 1.06319996, grad/param norm = 1.8035e-01, time/batch = 0.6754s	
22478/33150 (epoch 33.903), train_loss = 0.89111231, grad/param norm = 1.8288e-01, time/batch = 0.6739s	
22479/33150 (epoch 33.905), train_loss = 0.87740880, grad/param norm = 1.5616e-01, time/batch = 0.6787s	
22480/33150 (epoch 33.906), train_loss = 0.87907895, grad/param norm = 1.7812e-01, time/batch = 0.6795s	
22481/33150 (epoch 33.908), train_loss = 0.95121602, grad/param norm = 1.9063e-01, time/batch = 0.6715s	
22482/33150 (epoch 33.910), train_loss = 0.94501639, grad/param norm = 1.8519e-01, time/batch = 0.6715s	
22483/33150 (epoch 33.911), train_loss = 0.75626823, grad/param norm = 1.5120e-01, time/batch = 0.6690s	
22484/33150 (epoch 33.913), train_loss = 0.80505911, grad/param norm = 1.6976e-01, time/batch = 0.6711s	
22485/33150 (epoch 33.914), train_loss = 0.88214210, grad/param norm = 1.7020e-01, time/batch = 0.6745s	
22486/33150 (epoch 33.916), train_loss = 0.82739067, grad/param norm = 1.8623e-01, time/batch = 0.6699s	
22487/33150 (epoch 33.917), train_loss = 0.90932334, grad/param norm = 1.7592e-01, time/batch = 0.6787s	
22488/33150 (epoch 33.919), train_loss = 1.00341469, grad/param norm = 2.3582e-01, time/batch = 0.6836s	
22489/33150 (epoch 33.920), train_loss = 0.95799916, grad/param norm = 1.6504e-01, time/batch = 0.6758s	
22490/33150 (epoch 33.922), train_loss = 1.03196965, grad/param norm = 2.1686e-01, time/batch = 0.6776s	
22491/33150 (epoch 33.923), train_loss = 0.86721428, grad/param norm = 1.7574e-01, time/batch = 0.6846s	
22492/33150 (epoch 33.925), train_loss = 0.96480262, grad/param norm = 1.8444e-01, time/batch = 0.6794s	
22493/33150 (epoch 33.926), train_loss = 0.85411900, grad/param norm = 1.7632e-01, time/batch = 0.6811s	
22494/33150 (epoch 33.928), train_loss = 0.83009278, grad/param norm = 1.5659e-01, time/batch = 0.6827s	
22495/33150 (epoch 33.929), train_loss = 0.94479211, grad/param norm = 1.7481e-01, time/batch = 0.6707s	
22496/33150 (epoch 33.931), train_loss = 0.98884820, grad/param norm = 1.7829e-01, time/batch = 0.6698s	
22497/33150 (epoch 33.932), train_loss = 0.89487830, grad/param norm = 1.7013e-01, time/batch = 0.6704s	
22498/33150 (epoch 33.934), train_loss = 0.88761083, grad/param norm = 1.5135e-01, time/batch = 0.6735s	
22499/33150 (epoch 33.935), train_loss = 0.96765342, grad/param norm = 1.8304e-01, time/batch = 0.6705s	
22500/33150 (epoch 33.937), train_loss = 0.99558688, grad/param norm = 1.6939e-01, time/batch = 0.6752s	
22501/33150 (epoch 33.938), train_loss = 0.90823927, grad/param norm = 1.7658e-01, time/batch = 0.6912s	
22502/33150 (epoch 33.940), train_loss = 1.08530564, grad/param norm = 2.0769e-01, time/batch = 0.6852s	
22503/33150 (epoch 33.941), train_loss = 0.90903341, grad/param norm = 1.5461e-01, time/batch = 0.6936s	
22504/33150 (epoch 33.943), train_loss = 0.74227188, grad/param norm = 1.8478e-01, time/batch = 0.6904s	
22505/33150 (epoch 33.944), train_loss = 0.93087296, grad/param norm = 1.8762e-01, time/batch = 0.6900s	
22506/33150 (epoch 33.946), train_loss = 0.77083779, grad/param norm = 1.7474e-01, time/batch = 0.6891s	
22507/33150 (epoch 33.947), train_loss = 0.91150220, grad/param norm = 1.7377e-01, time/batch = 0.6876s	
22508/33150 (epoch 33.949), train_loss = 0.97788177, grad/param norm = 1.5421e-01, time/batch = 0.6735s	
22509/33150 (epoch 33.950), train_loss = 0.92538257, grad/param norm = 1.6690e-01, time/batch = 0.6784s	
22510/33150 (epoch 33.952), train_loss = 0.80708802, grad/param norm = 1.5736e-01, time/batch = 0.6743s	
22511/33150 (epoch 33.953), train_loss = 0.85928008, grad/param norm = 1.5695e-01, time/batch = 0.6792s	
22512/33150 (epoch 33.955), train_loss = 0.77378668, grad/param norm = 1.7312e-01, time/batch = 0.6811s	
22513/33150 (epoch 33.956), train_loss = 0.93539696, grad/param norm = 1.7414e-01, time/batch = 0.6823s	
22514/33150 (epoch 33.958), train_loss = 0.77983361, grad/param norm = 1.4564e-01, time/batch = 0.6814s	
22515/33150 (epoch 33.959), train_loss = 0.85971863, grad/param norm = 1.6563e-01, time/batch = 0.6715s	
22516/33150 (epoch 33.961), train_loss = 0.80363556, grad/param norm = 1.8751e-01, time/batch = 0.6697s	
22517/33150 (epoch 33.962), train_loss = 0.76382277, grad/param norm = 1.5566e-01, time/batch = 0.6894s	
22518/33150 (epoch 33.964), train_loss = 0.87637755, grad/param norm = 1.8397e-01, time/batch = 0.6790s	
22519/33150 (epoch 33.965), train_loss = 0.84642864, grad/param norm = 1.6859e-01, time/batch = 0.6752s	
22520/33150 (epoch 33.967), train_loss = 0.84441123, grad/param norm = 1.8314e-01, time/batch = 0.6756s	
22521/33150 (epoch 33.968), train_loss = 0.73174973, grad/param norm = 1.4382e-01, time/batch = 0.6808s	
22522/33150 (epoch 33.970), train_loss = 0.81264667, grad/param norm = 1.6593e-01, time/batch = 0.6817s	
22523/33150 (epoch 33.971), train_loss = 0.86799500, grad/param norm = 1.7136e-01, time/batch = 0.6754s	
22524/33150 (epoch 33.973), train_loss = 0.94036306, grad/param norm = 1.6846e-01, time/batch = 0.6684s	
22525/33150 (epoch 33.974), train_loss = 1.00193734, grad/param norm = 1.9033e-01, time/batch = 0.6719s	
22526/33150 (epoch 33.976), train_loss = 0.98112615, grad/param norm = 1.6373e-01, time/batch = 0.6751s	
22527/33150 (epoch 33.977), train_loss = 0.99148656, grad/param norm = 1.7761e-01, time/batch = 0.6789s	
22528/33150 (epoch 33.979), train_loss = 0.94736445, grad/param norm = 2.0979e-01, time/batch = 0.6763s	
22529/33150 (epoch 33.980), train_loss = 1.02044098, grad/param norm = 1.9339e-01, time/batch = 0.6727s	
22530/33150 (epoch 33.982), train_loss = 0.87856822, grad/param norm = 2.1190e-01, time/batch = 0.6716s	
22531/33150 (epoch 33.983), train_loss = 0.78605789, grad/param norm = 1.6598e-01, time/batch = 0.6746s	
22532/33150 (epoch 33.985), train_loss = 0.99511869, grad/param norm = 1.7734e-01, time/batch = 0.6750s	
22533/33150 (epoch 33.986), train_loss = 0.73306806, grad/param norm = 1.4793e-01, time/batch = 0.6714s	
22534/33150 (epoch 33.988), train_loss = 0.83462227, grad/param norm = 1.9210e-01, time/batch = 0.6741s	
22535/33150 (epoch 33.989), train_loss = 0.85599616, grad/param norm = 1.7283e-01, time/batch = 0.6852s	
22536/33150 (epoch 33.991), train_loss = 0.93836417, grad/param norm = 2.8212e-01, time/batch = 0.6752s	
22537/33150 (epoch 33.992), train_loss = 0.85748162, grad/param norm = 1.6406e-01, time/batch = 0.6697s	
22538/33150 (epoch 33.994), train_loss = 0.89998104, grad/param norm = 1.7149e-01, time/batch = 0.6682s	
22539/33150 (epoch 33.995), train_loss = 0.84833098, grad/param norm = 1.6898e-01, time/batch = 0.6710s	
22540/33150 (epoch 33.997), train_loss = 0.87076302, grad/param norm = 1.8489e-01, time/batch = 0.6741s	
22541/33150 (epoch 33.998), train_loss = 0.74490236, grad/param norm = 1.9032e-01, time/batch = 0.6735s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
22542/33150 (epoch 34.000), train_loss = 0.73155990, grad/param norm = 1.5802e-01, time/batch = 0.6811s	
22543/33150 (epoch 34.002), train_loss = 1.18634432, grad/param norm = 1.9428e-01, time/batch = 0.6849s	
22544/33150 (epoch 34.003), train_loss = 0.79113799, grad/param norm = 1.6369e-01, time/batch = 0.6876s	
22545/33150 (epoch 34.005), train_loss = 0.73304781, grad/param norm = 1.4070e-01, time/batch = 0.6759s	
22546/33150 (epoch 34.006), train_loss = 0.72195189, grad/param norm = 1.6115e-01, time/batch = 0.6700s	
22547/33150 (epoch 34.008), train_loss = 0.92059456, grad/param norm = 1.7794e-01, time/batch = 0.6748s	
22548/33150 (epoch 34.009), train_loss = 0.89501454, grad/param norm = 1.6301e-01, time/batch = 0.6692s	
22549/33150 (epoch 34.011), train_loss = 0.96421457, grad/param norm = 1.7342e-01, time/batch = 0.6710s	
22550/33150 (epoch 34.012), train_loss = 0.85240408, grad/param norm = 1.8981e-01, time/batch = 0.6688s	
22551/33150 (epoch 34.014), train_loss = 0.78388072, grad/param norm = 1.5851e-01, time/batch = 0.6698s	
22552/33150 (epoch 34.015), train_loss = 0.79930562, grad/param norm = 1.7243e-01, time/batch = 0.6718s	
22553/33150 (epoch 34.017), train_loss = 0.79355908, grad/param norm = 1.5339e-01, time/batch = 0.6797s	
22554/33150 (epoch 34.018), train_loss = 0.89109307, grad/param norm = 1.8319e-01, time/batch = 0.6857s	
22555/33150 (epoch 34.020), train_loss = 0.95071122, grad/param norm = 1.8337e-01, time/batch = 0.6847s	
22556/33150 (epoch 34.021), train_loss = 0.76312400, grad/param norm = 1.6779e-01, time/batch = 0.6797s	
22557/33150 (epoch 34.023), train_loss = 1.03872780, grad/param norm = 1.6678e-01, time/batch = 0.6894s	
22558/33150 (epoch 34.024), train_loss = 0.90751543, grad/param norm = 1.7910e-01, time/batch = 0.6715s	
22559/33150 (epoch 34.026), train_loss = 0.68724228, grad/param norm = 1.4245e-01, time/batch = 0.6800s	
22560/33150 (epoch 34.027), train_loss = 0.69496635, grad/param norm = 1.4245e-01, time/batch = 0.6731s	
22561/33150 (epoch 34.029), train_loss = 0.82222706, grad/param norm = 1.8263e-01, time/batch = 0.6755s	
22562/33150 (epoch 34.030), train_loss = 0.83843119, grad/param norm = 1.4507e-01, time/batch = 0.6736s	
22563/33150 (epoch 34.032), train_loss = 0.76004939, grad/param norm = 1.7818e-01, time/batch = 0.6737s	
22564/33150 (epoch 34.033), train_loss = 0.79719606, grad/param norm = 1.6780e-01, time/batch = 0.6730s	
22565/33150 (epoch 34.035), train_loss = 1.04566971, grad/param norm = 1.9630e-01, time/batch = 0.6752s	
22566/33150 (epoch 34.036), train_loss = 0.92635752, grad/param norm = 1.8557e-01, time/batch = 0.6720s	
22567/33150 (epoch 34.038), train_loss = 1.03827046, grad/param norm = 1.7063e-01, time/batch = 0.6743s	
22568/33150 (epoch 34.039), train_loss = 0.95080400, grad/param norm = 1.5834e-01, time/batch = 0.6842s	
22569/33150 (epoch 34.041), train_loss = 0.86860081, grad/param norm = 1.5480e-01, time/batch = 0.6886s	
22570/33150 (epoch 34.042), train_loss = 0.81943828, grad/param norm = 1.7216e-01, time/batch = 0.6889s	
22571/33150 (epoch 34.044), train_loss = 0.86503909, grad/param norm = 1.5701e-01, time/batch = 0.6885s	
22572/33150 (epoch 34.045), train_loss = 0.92738041, grad/param norm = 1.4688e-01, time/batch = 0.6845s	
22573/33150 (epoch 34.047), train_loss = 0.77347302, grad/param norm = 1.6074e-01, time/batch = 0.6772s	
22574/33150 (epoch 34.048), train_loss = 0.96294842, grad/param norm = 2.0423e-01, time/batch = 0.6723s	
22575/33150 (epoch 34.050), train_loss = 0.86362044, grad/param norm = 1.9208e-01, time/batch = 0.6773s	
22576/33150 (epoch 34.051), train_loss = 0.89447673, grad/param norm = 1.5422e-01, time/batch = 0.6953s	
22577/33150 (epoch 34.053), train_loss = 0.89579454, grad/param norm = 1.8451e-01, time/batch = 0.6871s	
22578/33150 (epoch 34.054), train_loss = 1.01103639, grad/param norm = 1.6911e-01, time/batch = 0.6847s	
22579/33150 (epoch 34.056), train_loss = 0.86199245, grad/param norm = 1.7112e-01, time/batch = 0.6799s	
22580/33150 (epoch 34.057), train_loss = 0.91141543, grad/param norm = 1.7399e-01, time/batch = 0.6728s	
22581/33150 (epoch 34.059), train_loss = 0.80122065, grad/param norm = 1.7398e-01, time/batch = 0.6811s	
22582/33150 (epoch 34.060), train_loss = 0.78157713, grad/param norm = 1.5356e-01, time/batch = 0.6839s	
22583/33150 (epoch 34.062), train_loss = 0.85939511, grad/param norm = 1.6547e-01, time/batch = 0.6829s	
22584/33150 (epoch 34.063), train_loss = 0.78887352, grad/param norm = 1.6800e-01, time/batch = 0.6743s	
22585/33150 (epoch 34.065), train_loss = 0.82573273, grad/param norm = 1.5949e-01, time/batch = 0.6697s	
22586/33150 (epoch 34.066), train_loss = 0.84295745, grad/param norm = 1.6676e-01, time/batch = 0.6722s	
22587/33150 (epoch 34.068), train_loss = 0.91914471, grad/param norm = 1.7772e-01, time/batch = 0.6699s	
22588/33150 (epoch 34.069), train_loss = 0.92336853, grad/param norm = 1.9192e-01, time/batch = 0.6684s	
22589/33150 (epoch 34.071), train_loss = 0.88296813, grad/param norm = 1.6643e-01, time/batch = 0.6869s	
22590/33150 (epoch 34.072), train_loss = 0.90150928, grad/param norm = 1.6020e-01, time/batch = 0.6854s	
22591/33150 (epoch 34.074), train_loss = 0.75268175, grad/param norm = 1.5926e-01, time/batch = 0.6812s	
22592/33150 (epoch 34.075), train_loss = 0.78714480, grad/param norm = 1.7265e-01, time/batch = 0.6865s	
22593/33150 (epoch 34.077), train_loss = 0.88153119, grad/param norm = 1.9827e-01, time/batch = 0.6702s	
22594/33150 (epoch 34.078), train_loss = 1.00501223, grad/param norm = 1.9979e-01, time/batch = 0.6812s	
22595/33150 (epoch 34.080), train_loss = 1.00681898, grad/param norm = 1.7828e-01, time/batch = 0.6779s	
22596/33150 (epoch 34.081), train_loss = 0.75509143, grad/param norm = 1.6562e-01, time/batch = 0.6805s	
22597/33150 (epoch 34.083), train_loss = 0.67194892, grad/param norm = 1.8565e-01, time/batch = 0.6658s	
22598/33150 (epoch 34.084), train_loss = 0.73378205, grad/param norm = 1.7797e-01, time/batch = 0.6696s	
22599/33150 (epoch 34.086), train_loss = 0.79664095, grad/param norm = 1.9197e-01, time/batch = 0.6719s	
22600/33150 (epoch 34.087), train_loss = 0.75972302, grad/param norm = 1.9357e-01, time/batch = 0.6734s	
22601/33150 (epoch 34.089), train_loss = 0.80471908, grad/param norm = 1.7340e-01, time/batch = 0.6766s	
22602/33150 (epoch 34.090), train_loss = 0.81585727, grad/param norm = 1.7824e-01, time/batch = 0.6744s	
22603/33150 (epoch 34.092), train_loss = 0.81181834, grad/param norm = 1.8524e-01, time/batch = 0.6691s	
22604/33150 (epoch 34.094), train_loss = 0.89351175, grad/param norm = 1.9539e-01, time/batch = 0.6741s	
22605/33150 (epoch 34.095), train_loss = 0.79876522, grad/param norm = 1.6338e-01, time/batch = 0.6747s	
22606/33150 (epoch 34.097), train_loss = 0.74260778, grad/param norm = 1.7632e-01, time/batch = 0.6702s	
22607/33150 (epoch 34.098), train_loss = 1.08965759, grad/param norm = 1.9454e-01, time/batch = 0.6864s	
22608/33150 (epoch 34.100), train_loss = 1.06491809, grad/param norm = 1.9902e-01, time/batch = 0.6736s	
22609/33150 (epoch 34.101), train_loss = 0.82916416, grad/param norm = 1.8688e-01, time/batch = 0.6707s	
22610/33150 (epoch 34.103), train_loss = 0.88463212, grad/param norm = 1.5812e-01, time/batch = 0.6680s	
22611/33150 (epoch 34.104), train_loss = 0.80617395, grad/param norm = 1.7511e-01, time/batch = 0.6757s	
22612/33150 (epoch 34.106), train_loss = 0.95323720, grad/param norm = 1.7153e-01, time/batch = 0.6647s	
22613/33150 (epoch 34.107), train_loss = 1.05478547, grad/param norm = 2.2633e-01, time/batch = 0.6694s	
22614/33150 (epoch 34.109), train_loss = 0.85100241, grad/param norm = 1.4099e-01, time/batch = 0.6684s	
22615/33150 (epoch 34.110), train_loss = 0.99520682, grad/param norm = 2.0311e-01, time/batch = 0.6795s	
22616/33150 (epoch 34.112), train_loss = 0.79431058, grad/param norm = 1.7237e-01, time/batch = 0.6780s	
22617/33150 (epoch 34.113), train_loss = 0.83374165, grad/param norm = 1.7701e-01, time/batch = 0.6704s	
22618/33150 (epoch 34.115), train_loss = 1.04563359, grad/param norm = 1.9722e-01, time/batch = 0.6755s	
22619/33150 (epoch 34.116), train_loss = 0.89774061, grad/param norm = 1.6471e-01, time/batch = 0.6828s	
22620/33150 (epoch 34.118), train_loss = 0.88849732, grad/param norm = 1.7066e-01, time/batch = 0.6753s	
22621/33150 (epoch 34.119), train_loss = 0.91298309, grad/param norm = 2.0392e-01, time/batch = 0.6855s	
22622/33150 (epoch 34.121), train_loss = 0.83383239, grad/param norm = 1.5961e-01, time/batch = 0.6865s	
22623/33150 (epoch 34.122), train_loss = 1.03569628, grad/param norm = 1.9730e-01, time/batch = 0.6843s	
22624/33150 (epoch 34.124), train_loss = 0.73881524, grad/param norm = 1.6823e-01, time/batch = 0.6825s	
22625/33150 (epoch 34.125), train_loss = 0.98181693, grad/param norm = 1.7735e-01, time/batch = 0.6811s	
22626/33150 (epoch 34.127), train_loss = 0.89327437, grad/param norm = 1.8256e-01, time/batch = 0.6764s	
22627/33150 (epoch 34.128), train_loss = 0.90913390, grad/param norm = 1.7777e-01, time/batch = 0.6651s	
22628/33150 (epoch 34.130), train_loss = 0.88265980, grad/param norm = 1.8629e-01, time/batch = 0.6674s	
22629/33150 (epoch 34.131), train_loss = 1.07493250, grad/param norm = 2.0927e-01, time/batch = 0.6710s	
22630/33150 (epoch 34.133), train_loss = 0.80973218, grad/param norm = 1.6565e-01, time/batch = 0.6882s	
22631/33150 (epoch 34.134), train_loss = 0.99492777, grad/param norm = 1.8983e-01, time/batch = 0.6841s	
22632/33150 (epoch 34.136), train_loss = 0.89753959, grad/param norm = 1.9570e-01, time/batch = 0.6809s	
22633/33150 (epoch 34.137), train_loss = 0.94104670, grad/param norm = 1.6120e-01, time/batch = 0.6762s	
22634/33150 (epoch 34.139), train_loss = 0.92997717, grad/param norm = 1.8476e-01, time/batch = 0.6751s	
22635/33150 (epoch 34.140), train_loss = 1.06370835, grad/param norm = 1.8845e-01, time/batch = 0.7052s	
22636/33150 (epoch 34.142), train_loss = 0.94940603, grad/param norm = 2.1025e-01, time/batch = 0.6762s	
22637/33150 (epoch 34.143), train_loss = 0.87585177, grad/param norm = 1.9209e-01, time/batch = 0.6659s	
22638/33150 (epoch 34.145), train_loss = 0.84525583, grad/param norm = 1.7743e-01, time/batch = 0.6674s	
22639/33150 (epoch 34.146), train_loss = 0.96979455, grad/param norm = 1.9770e-01, time/batch = 0.6664s	
22640/33150 (epoch 34.148), train_loss = 1.01564282, grad/param norm = 1.6944e-01, time/batch = 0.6690s	
22641/33150 (epoch 34.149), train_loss = 0.90721977, grad/param norm = 1.8582e-01, time/batch = 0.6881s	
22642/33150 (epoch 34.151), train_loss = 1.04515452, grad/param norm = 1.8324e-01, time/batch = 0.6837s	
22643/33150 (epoch 34.152), train_loss = 0.82764942, grad/param norm = 1.5087e-01, time/batch = 0.6686s	
22644/33150 (epoch 34.154), train_loss = 0.82498590, grad/param norm = 1.7418e-01, time/batch = 0.6716s	
22645/33150 (epoch 34.155), train_loss = 0.73556219, grad/param norm = 1.5600e-01, time/batch = 0.6817s	
22646/33150 (epoch 34.157), train_loss = 0.85461948, grad/param norm = 1.7439e-01, time/batch = 0.6738s	
22647/33150 (epoch 34.158), train_loss = 0.85281427, grad/param norm = 1.5440e-01, time/batch = 0.6718s	
22648/33150 (epoch 34.160), train_loss = 0.94604465, grad/param norm = 1.7632e-01, time/batch = 0.6700s	
22649/33150 (epoch 34.161), train_loss = 0.82146790, grad/param norm = 2.1218e-01, time/batch = 0.6699s	
22650/33150 (epoch 34.163), train_loss = 0.76832196, grad/param norm = 1.6011e-01, time/batch = 0.6683s	
22651/33150 (epoch 34.164), train_loss = 0.89978509, grad/param norm = 1.8632e-01, time/batch = 0.6702s	
22652/33150 (epoch 34.166), train_loss = 0.86001500, grad/param norm = 1.7458e-01, time/batch = 0.6836s	
22653/33150 (epoch 34.167), train_loss = 0.90409020, grad/param norm = 1.6043e-01, time/batch = 0.6752s	
22654/33150 (epoch 34.169), train_loss = 0.89826808, grad/param norm = 2.0258e-01, time/batch = 0.6780s	
22655/33150 (epoch 34.170), train_loss = 0.81194158, grad/param norm = 1.9316e-01, time/batch = 0.6723s	
22656/33150 (epoch 34.172), train_loss = 0.93285177, grad/param norm = 2.0121e-01, time/batch = 0.6697s	
22657/33150 (epoch 34.173), train_loss = 0.92668728, grad/param norm = 1.9670e-01, time/batch = 0.6678s	
22658/33150 (epoch 34.175), train_loss = 0.84598026, grad/param norm = 2.1950e-01, time/batch = 0.6655s	
22659/33150 (epoch 34.176), train_loss = 0.95351259, grad/param norm = 1.8807e-01, time/batch = 0.6763s	
22660/33150 (epoch 34.178), train_loss = 1.09540402, grad/param norm = 2.1176e-01, time/batch = 0.6801s	
22661/33150 (epoch 34.179), train_loss = 0.94602713, grad/param norm = 1.7012e-01, time/batch = 0.6692s	
22662/33150 (epoch 34.181), train_loss = 0.90478978, grad/param norm = 2.0613e-01, time/batch = 0.6684s	
22663/33150 (epoch 34.183), train_loss = 0.87401458, grad/param norm = 1.9735e-01, time/batch = 0.6698s	
22664/33150 (epoch 34.184), train_loss = 1.11927038, grad/param norm = 1.7431e-01, time/batch = 0.6684s	
22665/33150 (epoch 34.186), train_loss = 1.02054448, grad/param norm = 1.6055e-01, time/batch = 0.6690s	
22666/33150 (epoch 34.187), train_loss = 0.90654866, grad/param norm = 2.0745e-01, time/batch = 0.6906s	
22667/33150 (epoch 34.189), train_loss = 0.70262998, grad/param norm = 1.6353e-01, time/batch = 0.6780s	
22668/33150 (epoch 34.190), train_loss = 0.79344786, grad/param norm = 1.8063e-01, time/batch = 0.6848s	
22669/33150 (epoch 34.192), train_loss = 0.90252811, grad/param norm = 1.8623e-01, time/batch = 0.6865s	
22670/33150 (epoch 34.193), train_loss = 0.96795338, grad/param norm = 1.7501e-01, time/batch = 0.6798s	
22671/33150 (epoch 34.195), train_loss = 1.09928458, grad/param norm = 2.0170e-01, time/batch = 0.6886s	
22672/33150 (epoch 34.196), train_loss = 1.01753606, grad/param norm = 1.8019e-01, time/batch = 0.6866s	
22673/33150 (epoch 34.198), train_loss = 0.76702556, grad/param norm = 1.4860e-01, time/batch = 0.6847s	
22674/33150 (epoch 34.199), train_loss = 0.97725694, grad/param norm = 2.2206e-01, time/batch = 0.6825s	
22675/33150 (epoch 34.201), train_loss = 0.83368260, grad/param norm = 1.5423e-01, time/batch = 0.6850s	
22676/33150 (epoch 34.202), train_loss = 0.70426403, grad/param norm = 1.5661e-01, time/batch = 0.6846s	
22677/33150 (epoch 34.204), train_loss = 0.93849485, grad/param norm = 1.8688e-01, time/batch = 0.6818s	
22678/33150 (epoch 34.205), train_loss = 0.93699792, grad/param norm = 1.8771e-01, time/batch = 0.6885s	
22679/33150 (epoch 34.207), train_loss = 0.93038934, grad/param norm = 1.6655e-01, time/batch = 0.7049s	
22680/33150 (epoch 34.208), train_loss = 0.95695394, grad/param norm = 1.7944e-01, time/batch = 0.6817s	
22681/33150 (epoch 34.210), train_loss = 0.83590422, grad/param norm = 1.6728e-01, time/batch = 0.6846s	
22682/33150 (epoch 34.211), train_loss = 0.88523054, grad/param norm = 1.8889e-01, time/batch = 0.6677s	
22683/33150 (epoch 34.213), train_loss = 0.96370671, grad/param norm = 1.7701e-01, time/batch = 0.6890s	
22684/33150 (epoch 34.214), train_loss = 0.85185990, grad/param norm = 1.6525e-01, time/batch = 0.7134s	
22685/33150 (epoch 34.216), train_loss = 0.79196894, grad/param norm = 1.8512e-01, time/batch = 0.6683s	
22686/33150 (epoch 34.217), train_loss = 0.88790350, grad/param norm = 2.0274e-01, time/batch = 0.6698s	
22687/33150 (epoch 34.219), train_loss = 0.82501980, grad/param norm = 1.7510e-01, time/batch = 0.6700s	
22688/33150 (epoch 34.220), train_loss = 0.83758716, grad/param norm = 1.4127e-01, time/batch = 0.6759s	
22689/33150 (epoch 34.222), train_loss = 0.97303636, grad/param norm = 1.7934e-01, time/batch = 0.6821s	
22690/33150 (epoch 34.223), train_loss = 0.87688400, grad/param norm = 1.7297e-01, time/batch = 0.6714s	
22691/33150 (epoch 34.225), train_loss = 0.99808454, grad/param norm = 1.7583e-01, time/batch = 0.6692s	
22692/33150 (epoch 34.226), train_loss = 0.88025213, grad/param norm = 2.0236e-01, time/batch = 0.6681s	
22693/33150 (epoch 34.228), train_loss = 0.85938069, grad/param norm = 1.8975e-01, time/batch = 0.6695s	
22694/33150 (epoch 34.229), train_loss = 0.88141789, grad/param norm = 1.7822e-01, time/batch = 0.6683s	
22695/33150 (epoch 34.231), train_loss = 0.98251000, grad/param norm = 1.8351e-01, time/batch = 0.6757s	
22696/33150 (epoch 34.232), train_loss = 0.88619991, grad/param norm = 1.8492e-01, time/batch = 0.6723s	
22697/33150 (epoch 34.234), train_loss = 0.90642519, grad/param norm = 1.6790e-01, time/batch = 0.6869s	
22698/33150 (epoch 34.235), train_loss = 0.94228717, grad/param norm = 2.0185e-01, time/batch = 0.6816s	
22699/33150 (epoch 34.237), train_loss = 0.91073529, grad/param norm = 1.8949e-01, time/batch = 0.6822s	
22700/33150 (epoch 34.238), train_loss = 0.95477328, grad/param norm = 1.9249e-01, time/batch = 0.6753s	
22701/33150 (epoch 34.240), train_loss = 0.91877955, grad/param norm = 1.6250e-01, time/batch = 0.6770s	
22702/33150 (epoch 34.241), train_loss = 0.97404088, grad/param norm = 2.0795e-01, time/batch = 0.6783s	
22703/33150 (epoch 34.243), train_loss = 0.96673976, grad/param norm = 1.8869e-01, time/batch = 0.6775s	
22704/33150 (epoch 34.244), train_loss = 0.89052399, grad/param norm = 1.6842e-01, time/batch = 0.6792s	
22705/33150 (epoch 34.246), train_loss = 0.97056872, grad/param norm = 1.6344e-01, time/batch = 0.6733s	
22706/33150 (epoch 34.247), train_loss = 0.83822938, grad/param norm = 1.7056e-01, time/batch = 0.6674s	
22707/33150 (epoch 34.249), train_loss = 0.99564187, grad/param norm = 1.5807e-01, time/batch = 0.6690s	
22708/33150 (epoch 34.250), train_loss = 0.93335077, grad/param norm = 1.5823e-01, time/batch = 0.6703s	
22709/33150 (epoch 34.252), train_loss = 0.95247573, grad/param norm = 1.6336e-01, time/batch = 0.6665s	
22710/33150 (epoch 34.253), train_loss = 0.86573086, grad/param norm = 1.6421e-01, time/batch = 0.6708s	
22711/33150 (epoch 34.255), train_loss = 0.88063537, grad/param norm = 1.4645e-01, time/batch = 0.6718s	
22712/33150 (epoch 34.256), train_loss = 1.01313110, grad/param norm = 1.8872e-01, time/batch = 0.6693s	
22713/33150 (epoch 34.258), train_loss = 0.83040219, grad/param norm = 1.7137e-01, time/batch = 0.6742s	
22714/33150 (epoch 34.259), train_loss = 0.72800839, grad/param norm = 1.6241e-01, time/batch = 0.6719s	
22715/33150 (epoch 34.261), train_loss = 0.78247064, grad/param norm = 1.5130e-01, time/batch = 0.6687s	
22716/33150 (epoch 34.262), train_loss = 0.99084724, grad/param norm = 2.0717e-01, time/batch = 0.6700s	
22717/33150 (epoch 34.264), train_loss = 0.68976191, grad/param norm = 1.4813e-01, time/batch = 0.6721s	
22718/33150 (epoch 34.265), train_loss = 0.90903840, grad/param norm = 1.6798e-01, time/batch = 0.6690s	
22719/33150 (epoch 34.267), train_loss = 0.96286203, grad/param norm = 2.0252e-01, time/batch = 0.6811s	
22720/33150 (epoch 34.268), train_loss = 0.99289267, grad/param norm = 1.6144e-01, time/batch = 0.6765s	
22721/33150 (epoch 34.270), train_loss = 1.08785357, grad/param norm = 1.8968e-01, time/batch = 0.6728s	
22722/33150 (epoch 34.271), train_loss = 0.97215942, grad/param norm = 1.9240e-01, time/batch = 0.6797s	
22723/33150 (epoch 34.273), train_loss = 1.01203859, grad/param norm = 1.8978e-01, time/batch = 0.6851s	
22724/33150 (epoch 34.275), train_loss = 1.01733318, grad/param norm = 1.7936e-01, time/batch = 0.6852s	
22725/33150 (epoch 34.276), train_loss = 0.88861343, grad/param norm = 1.6681e-01, time/batch = 0.6887s	
22726/33150 (epoch 34.278), train_loss = 1.00204072, grad/param norm = 1.7355e-01, time/batch = 0.6827s	
22727/33150 (epoch 34.279), train_loss = 0.96848374, grad/param norm = 1.6039e-01, time/batch = 0.6830s	
22728/33150 (epoch 34.281), train_loss = 0.88345939, grad/param norm = 1.7943e-01, time/batch = 0.6864s	
22729/33150 (epoch 34.282), train_loss = 0.92455115, grad/param norm = 1.4236e-01, time/batch = 0.6818s	
22730/33150 (epoch 34.284), train_loss = 0.81531657, grad/param norm = 1.6003e-01, time/batch = 0.6684s	
22731/33150 (epoch 34.285), train_loss = 0.91650300, grad/param norm = 1.6431e-01, time/batch = 0.6713s	
22732/33150 (epoch 34.287), train_loss = 0.80039219, grad/param norm = 1.6428e-01, time/batch = 0.6708s	
22733/33150 (epoch 34.288), train_loss = 0.96142352, grad/param norm = 1.5943e-01, time/batch = 0.6703s	
22734/33150 (epoch 34.290), train_loss = 0.75710516, grad/param norm = 1.4464e-01, time/batch = 0.6691s	
22735/33150 (epoch 34.291), train_loss = 0.72744497, grad/param norm = 1.5721e-01, time/batch = 0.6865s	
22736/33150 (epoch 34.293), train_loss = 0.87344273, grad/param norm = 1.7835e-01, time/batch = 0.6941s	
22737/33150 (epoch 34.294), train_loss = 0.70201252, grad/param norm = 1.7628e-01, time/batch = 0.6908s	
22738/33150 (epoch 34.296), train_loss = 0.87863255, grad/param norm = 1.5097e-01, time/batch = 0.6909s	
22739/33150 (epoch 34.297), train_loss = 0.84083252, grad/param norm = 1.8034e-01, time/batch = 0.6995s	
22740/33150 (epoch 34.299), train_loss = 0.84092842, grad/param norm = 1.8608e-01, time/batch = 0.6916s	
22741/33150 (epoch 34.300), train_loss = 0.83133166, grad/param norm = 1.5130e-01, time/batch = 0.7089s	
22742/33150 (epoch 34.302), train_loss = 0.88021801, grad/param norm = 2.0277e-01, time/batch = 0.7048s	
22743/33150 (epoch 34.303), train_loss = 0.84615552, grad/param norm = 1.6850e-01, time/batch = 0.7072s	
22744/33150 (epoch 34.305), train_loss = 0.94341959, grad/param norm = 1.6730e-01, time/batch = 0.7049s	
22745/33150 (epoch 34.306), train_loss = 0.95295161, grad/param norm = 2.0429e-01, time/batch = 0.7028s	
22746/33150 (epoch 34.308), train_loss = 1.10176166, grad/param norm = 1.8345e-01, time/batch = 0.6682s	
22747/33150 (epoch 34.309), train_loss = 0.73547743, grad/param norm = 1.4295e-01, time/batch = 0.6708s	
22748/33150 (epoch 34.311), train_loss = 0.86576328, grad/param norm = 1.9295e-01, time/batch = 0.6712s	
22749/33150 (epoch 34.312), train_loss = 0.71059166, grad/param norm = 1.4465e-01, time/batch = 0.6703s	
22750/33150 (epoch 34.314), train_loss = 0.85049529, grad/param norm = 1.7298e-01, time/batch = 0.6728s	
22751/33150 (epoch 34.315), train_loss = 0.93489297, grad/param norm = 1.7377e-01, time/batch = 0.6770s	
22752/33150 (epoch 34.317), train_loss = 0.69855033, grad/param norm = 1.3392e-01, time/batch = 0.6823s	
22753/33150 (epoch 34.318), train_loss = 0.80900613, grad/param norm = 1.4139e-01, time/batch = 0.6741s	
22754/33150 (epoch 34.320), train_loss = 0.75023935, grad/param norm = 1.6402e-01, time/batch = 0.6699s	
22755/33150 (epoch 34.321), train_loss = 0.86047374, grad/param norm = 1.6652e-01, time/batch = 0.6716s	
22756/33150 (epoch 34.323), train_loss = 0.84788993, grad/param norm = 1.7415e-01, time/batch = 0.6722s	
22757/33150 (epoch 34.324), train_loss = 0.89981457, grad/param norm = 2.3257e-01, time/batch = 0.6701s	
22758/33150 (epoch 34.326), train_loss = 0.88710707, grad/param norm = 1.5875e-01, time/batch = 0.6669s	
22759/33150 (epoch 34.327), train_loss = 0.98182242, grad/param norm = 1.7808e-01, time/batch = 0.6683s	
22760/33150 (epoch 34.329), train_loss = 0.91808881, grad/param norm = 1.6915e-01, time/batch = 0.6689s	
22761/33150 (epoch 34.330), train_loss = 0.86097865, grad/param norm = 1.6942e-01, time/batch = 0.6724s	
22762/33150 (epoch 34.332), train_loss = 0.86272119, grad/param norm = 1.6285e-01, time/batch = 0.6686s	
22763/33150 (epoch 34.333), train_loss = 0.93522530, grad/param norm = 1.5325e-01, time/batch = 0.6720s	
22764/33150 (epoch 34.335), train_loss = 0.80435055, grad/param norm = 1.4675e-01, time/batch = 0.6742s	
22765/33150 (epoch 34.336), train_loss = 0.80114488, grad/param norm = 2.2415e-01, time/batch = 0.6841s	
22766/33150 (epoch 34.338), train_loss = 0.74319620, grad/param norm = 1.6643e-01, time/batch = 0.6839s	
22767/33150 (epoch 34.339), train_loss = 0.95610035, grad/param norm = 1.7552e-01, time/batch = 0.6853s	
22768/33150 (epoch 34.341), train_loss = 0.89350048, grad/param norm = 2.0163e-01, time/batch = 0.6730s	
22769/33150 (epoch 34.342), train_loss = 0.83059560, grad/param norm = 1.7250e-01, time/batch = 0.6740s	
22770/33150 (epoch 34.344), train_loss = 0.86591073, grad/param norm = 1.7178e-01, time/batch = 0.6820s	
22771/33150 (epoch 34.345), train_loss = 0.84332104, grad/param norm = 1.6003e-01, time/batch = 0.6787s	
22772/33150 (epoch 34.347), train_loss = 0.72602692, grad/param norm = 1.7158e-01, time/batch = 0.6729s	
22773/33150 (epoch 34.348), train_loss = 0.89536366, grad/param norm = 1.6228e-01, time/batch = 0.6806s	
22774/33150 (epoch 34.350), train_loss = 0.78651338, grad/param norm = 1.8935e-01, time/batch = 0.6737s	
22775/33150 (epoch 34.351), train_loss = 0.93408116, grad/param norm = 1.7305e-01, time/batch = 0.6841s	
22776/33150 (epoch 34.353), train_loss = 0.91612846, grad/param norm = 1.6241e-01, time/batch = 0.6777s	
22777/33150 (epoch 34.354), train_loss = 1.08281214, grad/param norm = 1.7386e-01, time/batch = 0.6762s	
22778/33150 (epoch 34.356), train_loss = 0.94950128, grad/param norm = 1.6271e-01, time/batch = 0.6742s	
22779/33150 (epoch 34.357), train_loss = 0.90592319, grad/param norm = 2.0543e-01, time/batch = 0.6841s	
22780/33150 (epoch 34.359), train_loss = 0.94375492, grad/param norm = 1.6915e-01, time/batch = 0.6843s	
22781/33150 (epoch 34.360), train_loss = 0.93144126, grad/param norm = 1.9643e-01, time/batch = 0.6829s	
22782/33150 (epoch 34.362), train_loss = 1.00058210, grad/param norm = 1.7223e-01, time/batch = 0.6830s	
22783/33150 (epoch 34.363), train_loss = 0.88834712, grad/param norm = 1.5509e-01, time/batch = 0.6749s	
22784/33150 (epoch 34.365), train_loss = 0.85836764, grad/param norm = 1.5915e-01, time/batch = 0.6701s	
22785/33150 (epoch 34.367), train_loss = 0.83748300, grad/param norm = 1.6965e-01, time/batch = 0.6790s	
22786/33150 (epoch 34.368), train_loss = 0.86909340, grad/param norm = 2.0669e-01, time/batch = 0.6771s	
22787/33150 (epoch 34.370), train_loss = 0.90910577, grad/param norm = 1.8936e-01, time/batch = 0.6925s	
22788/33150 (epoch 34.371), train_loss = 0.78985744, grad/param norm = 1.5533e-01, time/batch = 0.6789s	
22789/33150 (epoch 34.373), train_loss = 0.92439687, grad/param norm = 1.9390e-01, time/batch = 0.6730s	
22790/33150 (epoch 34.374), train_loss = 0.86972754, grad/param norm = 1.6486e-01, time/batch = 0.6670s	
22791/33150 (epoch 34.376), train_loss = 0.96259156, grad/param norm = 1.6831e-01, time/batch = 0.6652s	
22792/33150 (epoch 34.377), train_loss = 0.79411117, grad/param norm = 1.6966e-01, time/batch = 0.6686s	
22793/33150 (epoch 34.379), train_loss = 0.92338116, grad/param norm = 1.8551e-01, time/batch = 0.6686s	
22794/33150 (epoch 34.380), train_loss = 0.92304824, grad/param norm = 1.4053e-01, time/batch = 0.6640s	
22795/33150 (epoch 34.382), train_loss = 0.88223506, grad/param norm = 1.9478e-01, time/batch = 0.6664s	
22796/33150 (epoch 34.383), train_loss = 0.81442356, grad/param norm = 1.5664e-01, time/batch = 0.6691s	
22797/33150 (epoch 34.385), train_loss = 0.83901568, grad/param norm = 1.9064e-01, time/batch = 0.6681s	
22798/33150 (epoch 34.386), train_loss = 0.77614215, grad/param norm = 1.5619e-01, time/batch = 0.6683s	
22799/33150 (epoch 34.388), train_loss = 0.79797639, grad/param norm = 1.6618e-01, time/batch = 0.6731s	
22800/33150 (epoch 34.389), train_loss = 0.81786278, grad/param norm = 1.6563e-01, time/batch = 0.6775s	
22801/33150 (epoch 34.391), train_loss = 1.01658829, grad/param norm = 1.8337e-01, time/batch = 0.6813s	
22802/33150 (epoch 34.392), train_loss = 0.84250429, grad/param norm = 1.7351e-01, time/batch = 0.6752s	
22803/33150 (epoch 34.394), train_loss = 0.74428341, grad/param norm = 1.4287e-01, time/batch = 0.6728s	
22804/33150 (epoch 34.395), train_loss = 0.71146787, grad/param norm = 1.6615e-01, time/batch = 0.6756s	
22805/33150 (epoch 34.397), train_loss = 0.60657980, grad/param norm = 1.5511e-01, time/batch = 0.6748s	
22806/33150 (epoch 34.398), train_loss = 0.87448173, grad/param norm = 1.6836e-01, time/batch = 0.6733s	
22807/33150 (epoch 34.400), train_loss = 0.85193048, grad/param norm = 1.4590e-01, time/batch = 0.6745s	
22808/33150 (epoch 34.401), train_loss = 0.74401963, grad/param norm = 1.4015e-01, time/batch = 0.6727s	
22809/33150 (epoch 34.403), train_loss = 0.74324810, grad/param norm = 1.4195e-01, time/batch = 0.6694s	
22810/33150 (epoch 34.404), train_loss = 0.88876203, grad/param norm = 1.6748e-01, time/batch = 0.6721s	
22811/33150 (epoch 34.406), train_loss = 0.81153023, grad/param norm = 1.3144e-01, time/batch = 0.6778s	
22812/33150 (epoch 34.407), train_loss = 0.75245131, grad/param norm = 1.5434e-01, time/batch = 0.6746s	
22813/33150 (epoch 34.409), train_loss = 0.71152844, grad/param norm = 1.4243e-01, time/batch = 0.6726s	
22814/33150 (epoch 34.410), train_loss = 0.89327625, grad/param norm = 1.7085e-01, time/batch = 0.6719s	
22815/33150 (epoch 34.412), train_loss = 0.92232233, grad/param norm = 1.5605e-01, time/batch = 0.6817s	
22816/33150 (epoch 34.413), train_loss = 0.76468085, grad/param norm = 1.6033e-01, time/batch = 0.6787s	
22817/33150 (epoch 34.415), train_loss = 0.89977036, grad/param norm = 1.6280e-01, time/batch = 0.6793s	
22818/33150 (epoch 34.416), train_loss = 0.80087028, grad/param norm = 1.5766e-01, time/batch = 0.6738s	
22819/33150 (epoch 34.418), train_loss = 0.90015952, grad/param norm = 2.1471e-01, time/batch = 0.6761s	
22820/33150 (epoch 34.419), train_loss = 0.86416124, grad/param norm = 1.6954e-01, time/batch = 0.6787s	
22821/33150 (epoch 34.421), train_loss = 0.86374042, grad/param norm = 1.7209e-01, time/batch = 0.6812s	
22822/33150 (epoch 34.422), train_loss = 0.83476796, grad/param norm = 1.6303e-01, time/batch = 0.6759s	
22823/33150 (epoch 34.424), train_loss = 0.81172452, grad/param norm = 1.6853e-01, time/batch = 0.6770s	
22824/33150 (epoch 34.425), train_loss = 0.95286885, grad/param norm = 1.7257e-01, time/batch = 0.6775s	
22825/33150 (epoch 34.427), train_loss = 0.86264453, grad/param norm = 1.5140e-01, time/batch = 0.6749s	
22826/33150 (epoch 34.428), train_loss = 0.85036584, grad/param norm = 1.6583e-01, time/batch = 0.6724s	
22827/33150 (epoch 34.430), train_loss = 0.89023054, grad/param norm = 2.0331e-01, time/batch = 0.6706s	
22828/33150 (epoch 34.431), train_loss = 0.92624623, grad/param norm = 1.9762e-01, time/batch = 0.6704s	
22829/33150 (epoch 34.433), train_loss = 0.85553571, grad/param norm = 1.6802e-01, time/batch = 0.6734s	
22830/33150 (epoch 34.434), train_loss = 0.74785126, grad/param norm = 1.4805e-01, time/batch = 0.6704s	
22831/33150 (epoch 34.436), train_loss = 0.86908862, grad/param norm = 1.4855e-01, time/batch = 0.6775s	
22832/33150 (epoch 34.437), train_loss = 0.88444454, grad/param norm = 2.0427e-01, time/batch = 0.6746s	
22833/33150 (epoch 34.439), train_loss = 1.01498115, grad/param norm = 1.7569e-01, time/batch = 0.6808s	
22834/33150 (epoch 34.440), train_loss = 0.91887818, grad/param norm = 1.8185e-01, time/batch = 0.6830s	
22835/33150 (epoch 34.442), train_loss = 0.75990242, grad/param norm = 1.6630e-01, time/batch = 0.6734s	
22836/33150 (epoch 34.443), train_loss = 0.89482691, grad/param norm = 1.7573e-01, time/batch = 0.6731s	
22837/33150 (epoch 34.445), train_loss = 0.86715396, grad/param norm = 1.7693e-01, time/batch = 0.6715s	
22838/33150 (epoch 34.446), train_loss = 0.89916230, grad/param norm = 2.0996e-01, time/batch = 0.6722s	
22839/33150 (epoch 34.448), train_loss = 0.95164558, grad/param norm = 1.6808e-01, time/batch = 0.6701s	
22840/33150 (epoch 34.449), train_loss = 0.86621190, grad/param norm = 1.4805e-01, time/batch = 0.6722s	
22841/33150 (epoch 34.451), train_loss = 0.88070645, grad/param norm = 1.9300e-01, time/batch = 0.6744s	
22842/33150 (epoch 34.452), train_loss = 1.05292407, grad/param norm = 1.8747e-01, time/batch = 0.6712s	
22843/33150 (epoch 34.454), train_loss = 0.84927132, grad/param norm = 1.6950e-01, time/batch = 0.6742s	
22844/33150 (epoch 34.456), train_loss = 0.80188100, grad/param norm = 1.5848e-01, time/batch = 0.6767s	
22845/33150 (epoch 34.457), train_loss = 0.89235580, grad/param norm = 1.8061e-01, time/batch = 0.6797s	
22846/33150 (epoch 34.459), train_loss = 0.98710971, grad/param norm = 2.2430e-01, time/batch = 0.6767s	
22847/33150 (epoch 34.460), train_loss = 0.92854205, grad/param norm = 1.4876e-01, time/batch = 0.6706s	
22848/33150 (epoch 34.462), train_loss = 0.96879297, grad/param norm = 2.0986e-01, time/batch = 0.6692s	
22849/33150 (epoch 34.463), train_loss = 1.10862528, grad/param norm = 2.1833e-01, time/batch = 0.6725s	
22850/33150 (epoch 34.465), train_loss = 0.93154385, grad/param norm = 1.7086e-01, time/batch = 0.6746s	
22851/33150 (epoch 34.466), train_loss = 0.84834999, grad/param norm = 1.6941e-01, time/batch = 0.6747s	
22852/33150 (epoch 34.468), train_loss = 1.07569584, grad/param norm = 1.7228e-01, time/batch = 0.6728s	
22853/33150 (epoch 34.469), train_loss = 0.82675743, grad/param norm = 1.8186e-01, time/batch = 0.6718s	
22854/33150 (epoch 34.471), train_loss = 0.81676505, grad/param norm = 1.7012e-01, time/batch = 0.6905s	
22855/33150 (epoch 34.472), train_loss = 0.89294482, grad/param norm = 1.8059e-01, time/batch = 0.6826s	
22856/33150 (epoch 34.474), train_loss = 0.95878368, grad/param norm = 2.3975e-01, time/batch = 0.6765s	
22857/33150 (epoch 34.475), train_loss = 1.12241899, grad/param norm = 1.8853e-01, time/batch = 0.6665s	
22858/33150 (epoch 34.477), train_loss = 0.96253196, grad/param norm = 1.8104e-01, time/batch = 0.6702s	
22859/33150 (epoch 34.478), train_loss = 0.92552414, grad/param norm = 1.6725e-01, time/batch = 0.6705s	
22860/33150 (epoch 34.480), train_loss = 0.81964997, grad/param norm = 1.7572e-01, time/batch = 0.6777s	
22861/33150 (epoch 34.481), train_loss = 0.74522724, grad/param norm = 1.5289e-01, time/batch = 0.6860s	
22862/33150 (epoch 34.483), train_loss = 0.85560325, grad/param norm = 1.7422e-01, time/batch = 0.6767s	
22863/33150 (epoch 34.484), train_loss = 0.81087328, grad/param norm = 1.7227e-01, time/batch = 0.6759s	
22864/33150 (epoch 34.486), train_loss = 0.80490247, grad/param norm = 1.6662e-01, time/batch = 0.6736s	
22865/33150 (epoch 34.487), train_loss = 0.92227026, grad/param norm = 1.8068e-01, time/batch = 0.6729s	
22866/33150 (epoch 34.489), train_loss = 0.87165921, grad/param norm = 1.7122e-01, time/batch = 0.6761s	
22867/33150 (epoch 34.490), train_loss = 0.71446904, grad/param norm = 1.4881e-01, time/batch = 0.6719s	
22868/33150 (epoch 34.492), train_loss = 0.84090268, grad/param norm = 1.8915e-01, time/batch = 0.6747s	
22869/33150 (epoch 34.493), train_loss = 0.94859769, grad/param norm = 1.7473e-01, time/batch = 0.6686s	
22870/33150 (epoch 34.495), train_loss = 0.92983295, grad/param norm = 1.5084e-01, time/batch = 0.6710s	
22871/33150 (epoch 34.496), train_loss = 0.85938774, grad/param norm = 1.5575e-01, time/batch = 0.6714s	
22872/33150 (epoch 34.498), train_loss = 0.96390766, grad/param norm = 2.0110e-01, time/batch = 0.6717s	
22873/33150 (epoch 34.499), train_loss = 0.96790976, grad/param norm = 1.7386e-01, time/batch = 0.6722s	
22874/33150 (epoch 34.501), train_loss = 0.92871552, grad/param norm = 2.0227e-01, time/batch = 0.6823s	
22875/33150 (epoch 34.502), train_loss = 0.97699097, grad/param norm = 1.8904e-01, time/batch = 0.6743s	
22876/33150 (epoch 34.504), train_loss = 0.94260156, grad/param norm = 1.7547e-01, time/batch = 0.6770s	
22877/33150 (epoch 34.505), train_loss = 1.01736617, grad/param norm = 2.1433e-01, time/batch = 0.6716s	
22878/33150 (epoch 34.507), train_loss = 0.83120598, grad/param norm = 2.0874e-01, time/batch = 0.6823s	
22879/33150 (epoch 34.508), train_loss = 0.83186872, grad/param norm = 1.6784e-01, time/batch = 0.6777s	
22880/33150 (epoch 34.510), train_loss = 0.93848107, grad/param norm = 1.5166e-01, time/batch = 0.6705s	
22881/33150 (epoch 34.511), train_loss = 0.97951254, grad/param norm = 1.7293e-01, time/batch = 0.6717s	
22882/33150 (epoch 34.513), train_loss = 0.91616185, grad/param norm = 1.9920e-01, time/batch = 0.6746s	
22883/33150 (epoch 34.514), train_loss = 0.77082247, grad/param norm = 1.6801e-01, time/batch = 0.6757s	
22884/33150 (epoch 34.516), train_loss = 0.90975733, grad/param norm = 1.9698e-01, time/batch = 0.6720s	
22885/33150 (epoch 34.517), train_loss = 0.97414252, grad/param norm = 1.9303e-01, time/batch = 0.6693s	
22886/33150 (epoch 34.519), train_loss = 0.81267071, grad/param norm = 1.5175e-01, time/batch = 0.6669s	
22887/33150 (epoch 34.520), train_loss = 0.89828509, grad/param norm = 1.7680e-01, time/batch = 0.6676s	
22888/33150 (epoch 34.522), train_loss = 0.95241679, grad/param norm = 2.0745e-01, time/batch = 0.6668s	
22889/33150 (epoch 34.523), train_loss = 0.77376633, grad/param norm = 1.5637e-01, time/batch = 0.6803s	
22890/33150 (epoch 34.525), train_loss = 0.93034677, grad/param norm = 1.7727e-01, time/batch = 0.6751s	
22891/33150 (epoch 34.526), train_loss = 0.79939671, grad/param norm = 1.7099e-01, time/batch = 0.6843s	
22892/33150 (epoch 34.528), train_loss = 0.90003716, grad/param norm = 1.7985e-01, time/batch = 0.6702s	
22893/33150 (epoch 34.529), train_loss = 0.87330115, grad/param norm = 1.6555e-01, time/batch = 0.6779s	
22894/33150 (epoch 34.531), train_loss = 0.75228075, grad/param norm = 1.9987e-01, time/batch = 0.6843s	
22895/33150 (epoch 34.532), train_loss = 0.89649978, grad/param norm = 2.0647e-01, time/batch = 0.6724s	
22896/33150 (epoch 34.534), train_loss = 0.87294959, grad/param norm = 1.5280e-01, time/batch = 0.6708s	
22897/33150 (epoch 34.535), train_loss = 0.83330131, grad/param norm = 2.2536e-01, time/batch = 0.6730s	
22898/33150 (epoch 34.537), train_loss = 0.92159276, grad/param norm = 1.9611e-01, time/batch = 0.6758s	
22899/33150 (epoch 34.538), train_loss = 0.79272715, grad/param norm = 1.6301e-01, time/batch = 0.6736s	
22900/33150 (epoch 34.540), train_loss = 0.77576762, grad/param norm = 1.6453e-01, time/batch = 0.6752s	
22901/33150 (epoch 34.541), train_loss = 0.96531682, grad/param norm = 1.9230e-01, time/batch = 0.6708s	
22902/33150 (epoch 34.543), train_loss = 0.90864236, grad/param norm = 2.0406e-01, time/batch = 0.6698s	
22903/33150 (epoch 34.544), train_loss = 0.93918409, grad/param norm = 1.7396e-01, time/batch = 0.6780s	
22904/33150 (epoch 34.546), train_loss = 0.86041077, grad/param norm = 1.6885e-01, time/batch = 0.6721s	
22905/33150 (epoch 34.548), train_loss = 0.85595791, grad/param norm = 2.1372e-01, time/batch = 0.6698s	
22906/33150 (epoch 34.549), train_loss = 0.82527118, grad/param norm = 1.7562e-01, time/batch = 0.6728s	
22907/33150 (epoch 34.551), train_loss = 0.81119488, grad/param norm = 1.4815e-01, time/batch = 0.6722s	
22908/33150 (epoch 34.552), train_loss = 0.69205067, grad/param norm = 1.3831e-01, time/batch = 0.6814s	
22909/33150 (epoch 34.554), train_loss = 0.92393371, grad/param norm = 1.6572e-01, time/batch = 0.6771s	
22910/33150 (epoch 34.555), train_loss = 0.98406069, grad/param norm = 1.9954e-01, time/batch = 0.6899s	
22911/33150 (epoch 34.557), train_loss = 0.71537347, grad/param norm = 1.6606e-01, time/batch = 0.6792s	
22912/33150 (epoch 34.558), train_loss = 0.91529339, grad/param norm = 2.0740e-01, time/batch = 0.6745s	
22913/33150 (epoch 34.560), train_loss = 0.80740713, grad/param norm = 1.7674e-01, time/batch = 0.6743s	
22914/33150 (epoch 34.561), train_loss = 0.73751421, grad/param norm = 1.6588e-01, time/batch = 0.6743s	
22915/33150 (epoch 34.563), train_loss = 0.92079902, grad/param norm = 1.8470e-01, time/batch = 0.6680s	
22916/33150 (epoch 34.564), train_loss = 0.98027783, grad/param norm = 1.5612e-01, time/batch = 0.6792s	
22917/33150 (epoch 34.566), train_loss = 0.80256183, grad/param norm = 1.6413e-01, time/batch = 0.6764s	
22918/33150 (epoch 34.567), train_loss = 0.82078523, grad/param norm = 1.5635e-01, time/batch = 0.6757s	
22919/33150 (epoch 34.569), train_loss = 0.90171757, grad/param norm = 1.7406e-01, time/batch = 0.6765s	
22920/33150 (epoch 34.570), train_loss = 0.92509464, grad/param norm = 1.6532e-01, time/batch = 0.6736s	
22921/33150 (epoch 34.572), train_loss = 0.80367967, grad/param norm = 1.6227e-01, time/batch = 0.6710s	
22922/33150 (epoch 34.573), train_loss = 0.74354244, grad/param norm = 1.4804e-01, time/batch = 0.6742s	
22923/33150 (epoch 34.575), train_loss = 0.84274444, grad/param norm = 1.6931e-01, time/batch = 0.6822s	
22924/33150 (epoch 34.576), train_loss = 0.77642285, grad/param norm = 1.6018e-01, time/batch = 0.6710s	
22925/33150 (epoch 34.578), train_loss = 0.80103594, grad/param norm = 1.4808e-01, time/batch = 0.6741s	
22926/33150 (epoch 34.579), train_loss = 0.75680305, grad/param norm = 1.5365e-01, time/batch = 0.6745s	
22927/33150 (epoch 34.581), train_loss = 0.79968757, grad/param norm = 1.7452e-01, time/batch = 0.6726s	
22928/33150 (epoch 34.582), train_loss = 0.99723781, grad/param norm = 1.5798e-01, time/batch = 0.6736s	
22929/33150 (epoch 34.584), train_loss = 0.94902937, grad/param norm = 1.8543e-01, time/batch = 0.6750s	
22930/33150 (epoch 34.585), train_loss = 0.87279826, grad/param norm = 1.5651e-01, time/batch = 0.6698s	
22931/33150 (epoch 34.587), train_loss = 0.87579195, grad/param norm = 1.6238e-01, time/batch = 0.6762s	
22932/33150 (epoch 34.588), train_loss = 0.80976982, grad/param norm = 1.7492e-01, time/batch = 0.6740s	
22933/33150 (epoch 34.590), train_loss = 0.91821866, grad/param norm = 1.6979e-01, time/batch = 0.6716s	
22934/33150 (epoch 34.591), train_loss = 0.87162367, grad/param norm = 1.6991e-01, time/batch = 0.6725s	
22935/33150 (epoch 34.593), train_loss = 0.93130598, grad/param norm = 1.9176e-01, time/batch = 0.6904s	
22936/33150 (epoch 34.594), train_loss = 0.84181160, grad/param norm = 1.7695e-01, time/batch = 0.6755s	
22937/33150 (epoch 34.596), train_loss = 0.84222748, grad/param norm = 1.6866e-01, time/batch = 0.6773s	
22938/33150 (epoch 34.597), train_loss = 0.77447277, grad/param norm = 2.2989e-01, time/batch = 0.6812s	
22939/33150 (epoch 34.599), train_loss = 1.02674295, grad/param norm = 2.0756e-01, time/batch = 0.6722s	
22940/33150 (epoch 34.600), train_loss = 0.87135187, grad/param norm = 2.4670e-01, time/batch = 0.6738s	
22941/33150 (epoch 34.602), train_loss = 0.86550488, grad/param norm = 1.8038e-01, time/batch = 0.6740s	
22942/33150 (epoch 34.603), train_loss = 0.97704301, grad/param norm = 1.7592e-01, time/batch = 0.6833s	
22943/33150 (epoch 34.605), train_loss = 0.77233088, grad/param norm = 1.4509e-01, time/batch = 0.6887s	
22944/33150 (epoch 34.606), train_loss = 0.79556138, grad/param norm = 1.9883e-01, time/batch = 0.6907s	
22945/33150 (epoch 34.608), train_loss = 0.95157603, grad/param norm = 1.5963e-01, time/batch = 0.6672s	
22946/33150 (epoch 34.609), train_loss = 0.87603461, grad/param norm = 2.1271e-01, time/batch = 0.6694s	
22947/33150 (epoch 34.611), train_loss = 0.77692684, grad/param norm = 1.7635e-01, time/batch = 0.6652s	
22948/33150 (epoch 34.612), train_loss = 0.85611290, grad/param norm = 1.7787e-01, time/batch = 0.6661s	
22949/33150 (epoch 34.614), train_loss = 0.78689119, grad/param norm = 1.5465e-01, time/batch = 0.6670s	
22950/33150 (epoch 34.615), train_loss = 0.76680775, grad/param norm = 1.5295e-01, time/batch = 0.6662s	
22951/33150 (epoch 34.617), train_loss = 0.89269717, grad/param norm = 2.0796e-01, time/batch = 0.6639s	
22952/33150 (epoch 34.618), train_loss = 0.91501169, grad/param norm = 1.7468e-01, time/batch = 0.6828s	
22953/33150 (epoch 34.620), train_loss = 0.84219143, grad/param norm = 1.8764e-01, time/batch = 0.6869s	
22954/33150 (epoch 34.621), train_loss = 0.87165916, grad/param norm = 1.6486e-01, time/batch = 0.6892s	
22955/33150 (epoch 34.623), train_loss = 0.91933371, grad/param norm = 1.5573e-01, time/batch = 0.6745s	
22956/33150 (epoch 34.624), train_loss = 0.82810855, grad/param norm = 1.8964e-01, time/batch = 0.6685s	
22957/33150 (epoch 34.626), train_loss = 0.85784110, grad/param norm = 1.5825e-01, time/batch = 0.6790s	
22958/33150 (epoch 34.627), train_loss = 0.81726459, grad/param norm = 1.6418e-01, time/batch = 0.6943s	
22959/33150 (epoch 34.629), train_loss = 0.74289417, grad/param norm = 1.6112e-01, time/batch = 0.6882s	
22960/33150 (epoch 34.630), train_loss = 0.86403004, grad/param norm = 1.7465e-01, time/batch = 0.6725s	
22961/33150 (epoch 34.632), train_loss = 0.73775882, grad/param norm = 1.3419e-01, time/batch = 0.6718s	
22962/33150 (epoch 34.633), train_loss = 0.77442157, grad/param norm = 1.9177e-01, time/batch = 0.6745s	
22963/33150 (epoch 34.635), train_loss = 1.00947550, grad/param norm = 1.7829e-01, time/batch = 0.6752s	
22964/33150 (epoch 34.637), train_loss = 0.72222506, grad/param norm = 1.7815e-01, time/batch = 0.6719s	
22965/33150 (epoch 34.638), train_loss = 0.85202125, grad/param norm = 1.5691e-01, time/batch = 0.6679s	
22966/33150 (epoch 34.640), train_loss = 0.94590763, grad/param norm = 1.8109e-01, time/batch = 0.6706s	
22967/33150 (epoch 34.641), train_loss = 0.73201037, grad/param norm = 1.6339e-01, time/batch = 0.6849s	
22968/33150 (epoch 34.643), train_loss = 0.86937985, grad/param norm = 1.6975e-01, time/batch = 0.6761s	
22969/33150 (epoch 34.644), train_loss = 1.00878873, grad/param norm = 1.6825e-01, time/batch = 0.6678s	
22970/33150 (epoch 34.646), train_loss = 0.83496847, grad/param norm = 1.5835e-01, time/batch = 0.6741s	
22971/33150 (epoch 34.647), train_loss = 1.05739801, grad/param norm = 1.8381e-01, time/batch = 0.6771s	
22972/33150 (epoch 34.649), train_loss = 0.91788234, grad/param norm = 2.0348e-01, time/batch = 0.6707s	
22973/33150 (epoch 34.650), train_loss = 0.76966934, grad/param norm = 1.5577e-01, time/batch = 0.6707s	
22974/33150 (epoch 34.652), train_loss = 0.98011546, grad/param norm = 2.0238e-01, time/batch = 0.6700s	
22975/33150 (epoch 34.653), train_loss = 0.90637493, grad/param norm = 1.6716e-01, time/batch = 0.6719s	
22976/33150 (epoch 34.655), train_loss = 0.88698166, grad/param norm = 1.8432e-01, time/batch = 0.6738s	
22977/33150 (epoch 34.656), train_loss = 0.82412210, grad/param norm = 1.4726e-01, time/batch = 0.6752s	
22978/33150 (epoch 34.658), train_loss = 0.84730505, grad/param norm = 1.8985e-01, time/batch = 0.6731s	
22979/33150 (epoch 34.659), train_loss = 1.11079194, grad/param norm = 3.2756e-01, time/batch = 0.6706s	
22980/33150 (epoch 34.661), train_loss = 0.86708084, grad/param norm = 1.7961e-01, time/batch = 0.6728s	
22981/33150 (epoch 34.662), train_loss = 0.84689545, grad/param norm = 1.8454e-01, time/batch = 0.6740s	
22982/33150 (epoch 34.664), train_loss = 0.97742497, grad/param norm = 1.8178e-01, time/batch = 0.6823s	
22983/33150 (epoch 34.665), train_loss = 0.95911469, grad/param norm = 2.0817e-01, time/batch = 0.6741s	
22984/33150 (epoch 34.667), train_loss = 0.96709686, grad/param norm = 1.8593e-01, time/batch = 0.6732s	
22985/33150 (epoch 34.668), train_loss = 1.02730650, grad/param norm = 2.0820e-01, time/batch = 0.6731s	
22986/33150 (epoch 34.670), train_loss = 0.80814007, grad/param norm = 1.5697e-01, time/batch = 0.6726s	
22987/33150 (epoch 34.671), train_loss = 0.79049224, grad/param norm = 1.6961e-01, time/batch = 0.6793s	
22988/33150 (epoch 34.673), train_loss = 0.99892166, grad/param norm = 1.6270e-01, time/batch = 0.6703s	
22989/33150 (epoch 34.674), train_loss = 0.92075451, grad/param norm = 1.9094e-01, time/batch = 0.6735s	
22990/33150 (epoch 34.676), train_loss = 0.87464460, grad/param norm = 1.7359e-01, time/batch = 0.6720s	
22991/33150 (epoch 34.677), train_loss = 1.01335413, grad/param norm = 1.9324e-01, time/batch = 0.6733s	
22992/33150 (epoch 34.679), train_loss = 0.86960500, grad/param norm = 1.5661e-01, time/batch = 0.6713s	
22993/33150 (epoch 34.680), train_loss = 1.00287248, grad/param norm = 1.9160e-01, time/batch = 0.6699s	
22994/33150 (epoch 34.682), train_loss = 0.87174938, grad/param norm = 1.6745e-01, time/batch = 0.6732s	
22995/33150 (epoch 34.683), train_loss = 0.73759457, grad/param norm = 1.4223e-01, time/batch = 0.6718s	
22996/33150 (epoch 34.685), train_loss = 0.83400743, grad/param norm = 1.8409e-01, time/batch = 0.6771s	
22997/33150 (epoch 34.686), train_loss = 0.74428013, grad/param norm = 1.4340e-01, time/batch = 0.6792s	
22998/33150 (epoch 34.688), train_loss = 0.77183919, grad/param norm = 1.7731e-01, time/batch = 0.6767s	
22999/33150 (epoch 34.689), train_loss = 0.80180148, grad/param norm = 1.6440e-01, time/batch = 0.6724s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch34.69_1.7862.t7	
23000/33150 (epoch 34.691), train_loss = 0.68471176, grad/param norm = 1.3125e-01, time/batch = 0.6723s	
23001/33150 (epoch 34.692), train_loss = 1.39187633, grad/param norm = 2.3325e-01, time/batch = 0.6815s	
23002/33150 (epoch 34.694), train_loss = 0.69289495, grad/param norm = 1.5815e-01, time/batch = 0.6740s	
23003/33150 (epoch 34.695), train_loss = 0.82131478, grad/param norm = 1.6241e-01, time/batch = 0.6705s	
23004/33150 (epoch 34.697), train_loss = 0.75191311, grad/param norm = 1.4115e-01, time/batch = 0.6731s	
23005/33150 (epoch 34.698), train_loss = 0.79027320, grad/param norm = 1.8591e-01, time/batch = 0.6710s	
23006/33150 (epoch 34.700), train_loss = 0.65866384, grad/param norm = 1.3491e-01, time/batch = 0.6717s	
23007/33150 (epoch 34.701), train_loss = 0.75613840, grad/param norm = 1.4815e-01, time/batch = 0.6734s	
23008/33150 (epoch 34.703), train_loss = 0.86790668, grad/param norm = 1.7483e-01, time/batch = 0.6791s	
23009/33150 (epoch 34.704), train_loss = 0.74717583, grad/param norm = 1.4123e-01, time/batch = 0.6798s	
23010/33150 (epoch 34.706), train_loss = 0.80594268, grad/param norm = 1.4806e-01, time/batch = 0.6773s	
23011/33150 (epoch 34.707), train_loss = 0.82054033, grad/param norm = 1.6290e-01, time/batch = 0.6727s	
23012/33150 (epoch 34.709), train_loss = 0.87658461, grad/param norm = 1.4613e-01, time/batch = 0.6698s	
23013/33150 (epoch 34.710), train_loss = 0.86459418, grad/param norm = 1.8793e-01, time/batch = 0.6720s	
23014/33150 (epoch 34.712), train_loss = 0.92337733, grad/param norm = 1.6764e-01, time/batch = 0.6726s	
23015/33150 (epoch 34.713), train_loss = 0.89137512, grad/param norm = 1.5206e-01, time/batch = 0.6700s	
23016/33150 (epoch 34.715), train_loss = 0.83343564, grad/param norm = 1.6403e-01, time/batch = 0.6701s	
23017/33150 (epoch 34.716), train_loss = 0.90157733, grad/param norm = 1.7350e-01, time/batch = 0.6858s	
23018/33150 (epoch 34.718), train_loss = 0.87793899, grad/param norm = 1.7427e-01, time/batch = 0.6741s	
23019/33150 (epoch 34.719), train_loss = 0.93776754, grad/param norm = 1.9703e-01, time/batch = 0.6847s	
23020/33150 (epoch 34.721), train_loss = 0.83800178, grad/param norm = 1.8242e-01, time/batch = 0.6845s	
23021/33150 (epoch 34.722), train_loss = 0.88316765, grad/param norm = 1.6523e-01, time/batch = 0.6854s	
23022/33150 (epoch 34.724), train_loss = 0.84371611, grad/param norm = 1.9443e-01, time/batch = 0.6897s	
23023/33150 (epoch 34.725), train_loss = 0.94405236, grad/param norm = 2.2230e-01, time/batch = 0.6938s	
23024/33150 (epoch 34.727), train_loss = 0.92459289, grad/param norm = 2.0789e-01, time/batch = 0.6977s	
23025/33150 (epoch 34.729), train_loss = 0.86581444, grad/param norm = 1.7394e-01, time/batch = 0.6825s	
23026/33150 (epoch 34.730), train_loss = 0.86560446, grad/param norm = 1.7007e-01, time/batch = 0.6860s	
23027/33150 (epoch 34.732), train_loss = 0.91212164, grad/param norm = 1.7025e-01, time/batch = 0.6842s	
23028/33150 (epoch 34.733), train_loss = 0.73937682, grad/param norm = 1.3259e-01, time/batch = 0.6820s	
23029/33150 (epoch 34.735), train_loss = 0.79517841, grad/param norm = 1.6475e-01, time/batch = 0.6818s	
23030/33150 (epoch 34.736), train_loss = 0.83734122, grad/param norm = 1.6580e-01, time/batch = 0.6727s	
23031/33150 (epoch 34.738), train_loss = 0.87859165, grad/param norm = 2.0709e-01, time/batch = 0.6821s	
23032/33150 (epoch 34.739), train_loss = 0.96442110, grad/param norm = 1.9617e-01, time/batch = 0.6693s	
23033/33150 (epoch 34.741), train_loss = 0.91040252, grad/param norm = 2.0060e-01, time/batch = 0.6753s	
23034/33150 (epoch 34.742), train_loss = 0.73100193, grad/param norm = 1.7657e-01, time/batch = 0.6690s	
23035/33150 (epoch 34.744), train_loss = 0.93034647, grad/param norm = 1.9719e-01, time/batch = 0.6777s	
23036/33150 (epoch 34.745), train_loss = 0.81682019, grad/param norm = 1.4647e-01, time/batch = 0.6805s	
23037/33150 (epoch 34.747), train_loss = 0.66115132, grad/param norm = 1.5434e-01, time/batch = 0.6735s	
23038/33150 (epoch 34.748), train_loss = 0.74155959, grad/param norm = 1.7628e-01, time/batch = 0.6729s	
23039/33150 (epoch 34.750), train_loss = 0.89617490, grad/param norm = 1.9273e-01, time/batch = 0.6726s	
23040/33150 (epoch 34.751), train_loss = 0.85835301, grad/param norm = 1.6166e-01, time/batch = 0.6720s	
23041/33150 (epoch 34.753), train_loss = 0.73767305, grad/param norm = 1.6906e-01, time/batch = 0.6758s	
23042/33150 (epoch 34.754), train_loss = 1.04095871, grad/param norm = 2.2260e-01, time/batch = 0.6773s	
23043/33150 (epoch 34.756), train_loss = 0.87484815, grad/param norm = 2.2905e-01, time/batch = 0.6739s	
23044/33150 (epoch 34.757), train_loss = 0.88679685, grad/param norm = 1.6915e-01, time/batch = 0.6712s	
23045/33150 (epoch 34.759), train_loss = 1.00521870, grad/param norm = 2.0934e-01, time/batch = 0.6746s	
23046/33150 (epoch 34.760), train_loss = 0.90475714, grad/param norm = 1.8848e-01, time/batch = 0.6712s	
23047/33150 (epoch 34.762), train_loss = 0.87068068, grad/param norm = 1.9668e-01, time/batch = 0.6713s	
23048/33150 (epoch 34.763), train_loss = 0.91947274, grad/param norm = 1.6992e-01, time/batch = 0.6727s	
23049/33150 (epoch 34.765), train_loss = 0.84992197, grad/param norm = 1.6522e-01, time/batch = 0.6775s	
23050/33150 (epoch 34.766), train_loss = 0.76251628, grad/param norm = 1.7444e-01, time/batch = 0.6781s	
23051/33150 (epoch 34.768), train_loss = 0.78245503, grad/param norm = 1.5205e-01, time/batch = 0.6843s	
23052/33150 (epoch 34.769), train_loss = 0.93637423, grad/param norm = 1.9032e-01, time/batch = 0.6741s	
23053/33150 (epoch 34.771), train_loss = 0.90147189, grad/param norm = 1.8104e-01, time/batch = 0.6718s	
23054/33150 (epoch 34.772), train_loss = 0.91915218, grad/param norm = 2.0070e-01, time/batch = 0.6720s	
23055/33150 (epoch 34.774), train_loss = 0.99942347, grad/param norm = 1.7044e-01, time/batch = 0.6692s	
23056/33150 (epoch 34.775), train_loss = 0.91364036, grad/param norm = 1.8908e-01, time/batch = 0.6702s	
23057/33150 (epoch 34.777), train_loss = 0.93874581, grad/param norm = 1.8534e-01, time/batch = 0.6689s	
23058/33150 (epoch 34.778), train_loss = 0.87029090, grad/param norm = 1.7307e-01, time/batch = 0.6720s	
23059/33150 (epoch 34.780), train_loss = 0.73825969, grad/param norm = 1.5477e-01, time/batch = 0.6800s	
23060/33150 (epoch 34.781), train_loss = 0.85728673, grad/param norm = 1.7068e-01, time/batch = 0.6884s	
23061/33150 (epoch 34.783), train_loss = 0.87435781, grad/param norm = 1.6607e-01, time/batch = 0.6922s	
23062/33150 (epoch 34.784), train_loss = 0.85391557, grad/param norm = 1.9440e-01, time/batch = 0.6906s	
23063/33150 (epoch 34.786), train_loss = 0.85743946, grad/param norm = 1.6696e-01, time/batch = 0.6889s	
23064/33150 (epoch 34.787), train_loss = 0.79376942, grad/param norm = 1.4744e-01, time/batch = 0.6822s	
23065/33150 (epoch 34.789), train_loss = 0.74551560, grad/param norm = 1.5843e-01, time/batch = 0.6816s	
23066/33150 (epoch 34.790), train_loss = 0.73289960, grad/param norm = 1.4586e-01, time/batch = 0.6763s	
23067/33150 (epoch 34.792), train_loss = 0.85673565, grad/param norm = 1.8437e-01, time/batch = 0.6690s	
23068/33150 (epoch 34.793), train_loss = 0.84375390, grad/param norm = 1.9085e-01, time/batch = 0.6689s	
23069/33150 (epoch 34.795), train_loss = 0.80594981, grad/param norm = 1.9292e-01, time/batch = 0.6696s	
23070/33150 (epoch 34.796), train_loss = 0.82860163, grad/param norm = 1.5418e-01, time/batch = 0.6687s	
23071/33150 (epoch 34.798), train_loss = 0.79223550, grad/param norm = 1.3627e-01, time/batch = 0.6694s	
23072/33150 (epoch 34.799), train_loss = 0.71661521, grad/param norm = 1.7451e-01, time/batch = 0.6684s	
23073/33150 (epoch 34.801), train_loss = 0.86374663, grad/param norm = 1.7251e-01, time/batch = 0.6686s	
23074/33150 (epoch 34.802), train_loss = 0.81406340, grad/param norm = 1.7063e-01, time/batch = 0.6693s	
23075/33150 (epoch 34.804), train_loss = 0.83484741, grad/param norm = 1.6743e-01, time/batch = 0.6842s	
23076/33150 (epoch 34.805), train_loss = 0.79682596, grad/param norm = 1.7437e-01, time/batch = 0.6869s	
23077/33150 (epoch 34.807), train_loss = 0.84372564, grad/param norm = 1.6274e-01, time/batch = 0.6764s	
23078/33150 (epoch 34.808), train_loss = 0.96868500, grad/param norm = 1.7316e-01, time/batch = 0.6722s	
23079/33150 (epoch 34.810), train_loss = 0.79477473, grad/param norm = 1.8528e-01, time/batch = 0.6738s	
23080/33150 (epoch 34.811), train_loss = 0.90745796, grad/param norm = 2.0153e-01, time/batch = 0.6815s	
23081/33150 (epoch 34.813), train_loss = 0.82410624, grad/param norm = 1.6049e-01, time/batch = 0.6726s	
23082/33150 (epoch 34.814), train_loss = 0.79733890, grad/param norm = 1.8095e-01, time/batch = 0.6709s	
23083/33150 (epoch 34.816), train_loss = 0.83113298, grad/param norm = 1.8616e-01, time/batch = 0.6687s	
23084/33150 (epoch 34.817), train_loss = 0.89522588, grad/param norm = 1.5850e-01, time/batch = 0.6731s	
23085/33150 (epoch 34.819), train_loss = 0.88261791, grad/param norm = 1.7090e-01, time/batch = 0.6743s	
23086/33150 (epoch 34.821), train_loss = 0.76639565, grad/param norm = 1.5321e-01, time/batch = 0.6715s	
23087/33150 (epoch 34.822), train_loss = 0.79918863, grad/param norm = 1.6336e-01, time/batch = 0.6754s	
23088/33150 (epoch 34.824), train_loss = 0.85840614, grad/param norm = 1.7556e-01, time/batch = 0.6721s	
23089/33150 (epoch 34.825), train_loss = 0.88622323, grad/param norm = 1.7798e-01, time/batch = 0.6730s	
23090/33150 (epoch 34.827), train_loss = 0.91115386, grad/param norm = 1.9989e-01, time/batch = 0.6738s	
23091/33150 (epoch 34.828), train_loss = 0.77435150, grad/param norm = 1.8093e-01, time/batch = 0.6748s	
23092/33150 (epoch 34.830), train_loss = 0.93432545, grad/param norm = 1.9854e-01, time/batch = 0.6746s	
23093/33150 (epoch 34.831), train_loss = 0.79572637, grad/param norm = 1.6882e-01, time/batch = 0.6773s	
23094/33150 (epoch 34.833), train_loss = 0.77366186, grad/param norm = 1.7152e-01, time/batch = 0.6759s	
23095/33150 (epoch 34.834), train_loss = 0.93802422, grad/param norm = 1.6180e-01, time/batch = 0.6741s	
23096/33150 (epoch 34.836), train_loss = 0.96618766, grad/param norm = 1.6792e-01, time/batch = 0.6781s	
23097/33150 (epoch 34.837), train_loss = 0.81208499, grad/param norm = 1.7598e-01, time/batch = 0.6757s	
23098/33150 (epoch 34.839), train_loss = 0.90689634, grad/param norm = 1.8090e-01, time/batch = 0.6694s	
23099/33150 (epoch 34.840), train_loss = 0.90741887, grad/param norm = 1.6912e-01, time/batch = 0.6700s	
23100/33150 (epoch 34.842), train_loss = 0.94953162, grad/param norm = 2.2145e-01, time/batch = 0.6756s	
23101/33150 (epoch 34.843), train_loss = 0.94738965, grad/param norm = 1.9089e-01, time/batch = 0.6814s	
23102/33150 (epoch 34.845), train_loss = 0.79194020, grad/param norm = 1.5483e-01, time/batch = 0.6738s	
23103/33150 (epoch 34.846), train_loss = 1.04575525, grad/param norm = 2.5661e-01, time/batch = 0.6718s	
23104/33150 (epoch 34.848), train_loss = 0.94866210, grad/param norm = 1.9807e-01, time/batch = 0.6720s	
23105/33150 (epoch 34.849), train_loss = 0.97033650, grad/param norm = 1.6761e-01, time/batch = 0.6730s	
23106/33150 (epoch 34.851), train_loss = 0.91062695, grad/param norm = 1.8036e-01, time/batch = 0.6734s	
23107/33150 (epoch 34.852), train_loss = 0.98868780, grad/param norm = 1.6150e-01, time/batch = 0.6721s	
23108/33150 (epoch 34.854), train_loss = 0.90521025, grad/param norm = 1.8834e-01, time/batch = 0.6716s	
23109/33150 (epoch 34.855), train_loss = 0.75464347, grad/param norm = 1.5505e-01, time/batch = 0.6757s	
23110/33150 (epoch 34.857), train_loss = 0.71694516, grad/param norm = 1.5840e-01, time/batch = 0.6881s	
23111/33150 (epoch 34.858), train_loss = 0.82078147, grad/param norm = 1.5569e-01, time/batch = 0.7006s	
23112/33150 (epoch 34.860), train_loss = 0.80121025, grad/param norm = 2.4671e-01, time/batch = 0.6881s	
23113/33150 (epoch 34.861), train_loss = 0.77553811, grad/param norm = 1.4886e-01, time/batch = 0.6843s	
23114/33150 (epoch 34.863), train_loss = 0.84838632, grad/param norm = 1.6719e-01, time/batch = 0.7032s	
23115/33150 (epoch 34.864), train_loss = 0.89316115, grad/param norm = 1.7839e-01, time/batch = 0.6881s	
23116/33150 (epoch 34.866), train_loss = 0.92481875, grad/param norm = 1.8277e-01, time/batch = 0.6904s	
23117/33150 (epoch 34.867), train_loss = 0.88994827, grad/param norm = 1.5745e-01, time/batch = 0.6781s	
23118/33150 (epoch 34.869), train_loss = 0.87352635, grad/param norm = 1.7965e-01, time/batch = 0.6735s	
23119/33150 (epoch 34.870), train_loss = 0.81815325, grad/param norm = 1.8667e-01, time/batch = 0.6777s	
23120/33150 (epoch 34.872), train_loss = 0.88986046, grad/param norm = 1.7206e-01, time/batch = 0.6821s	
23121/33150 (epoch 34.873), train_loss = 0.70606819, grad/param norm = 1.4567e-01, time/batch = 0.6919s	
23122/33150 (epoch 34.875), train_loss = 0.95561596, grad/param norm = 1.5664e-01, time/batch = 0.6905s	
23123/33150 (epoch 34.876), train_loss = 0.72419824, grad/param norm = 1.4602e-01, time/batch = 0.6875s	
23124/33150 (epoch 34.878), train_loss = 0.81236190, grad/param norm = 1.5176e-01, time/batch = 0.6827s	
23125/33150 (epoch 34.879), train_loss = 0.80164058, grad/param norm = 1.4886e-01, time/batch = 0.6894s	
23126/33150 (epoch 34.881), train_loss = 0.78982362, grad/param norm = 1.8202e-01, time/batch = 0.6888s	
23127/33150 (epoch 34.882), train_loss = 0.67588496, grad/param norm = 1.6539e-01, time/batch = 0.6864s	
23128/33150 (epoch 34.884), train_loss = 0.81714255, grad/param norm = 1.5969e-01, time/batch = 0.6719s	
23129/33150 (epoch 34.885), train_loss = 0.66294474, grad/param norm = 1.8021e-01, time/batch = 0.6657s	
23130/33150 (epoch 34.887), train_loss = 0.94204529, grad/param norm = 1.8087e-01, time/batch = 0.6672s	
23131/33150 (epoch 34.888), train_loss = 0.87056448, grad/param norm = 1.5834e-01, time/batch = 0.6762s	
23132/33150 (epoch 34.890), train_loss = 0.79158038, grad/param norm = 2.1641e-01, time/batch = 0.6712s	
23133/33150 (epoch 34.891), train_loss = 0.77082678, grad/param norm = 1.6485e-01, time/batch = 0.6674s	
23134/33150 (epoch 34.893), train_loss = 0.91003025, grad/param norm = 1.8410e-01, time/batch = 0.6701s	
23135/33150 (epoch 34.894), train_loss = 0.88911534, grad/param norm = 1.5639e-01, time/batch = 0.6811s	
23136/33150 (epoch 34.896), train_loss = 0.84486491, grad/param norm = 1.5851e-01, time/batch = 0.6761s	
23137/33150 (epoch 34.897), train_loss = 0.90348333, grad/param norm = 1.7114e-01, time/batch = 0.6711s	
23138/33150 (epoch 34.899), train_loss = 0.71669444, grad/param norm = 1.9442e-01, time/batch = 0.6758s	
23139/33150 (epoch 34.900), train_loss = 1.02609766, grad/param norm = 2.1003e-01, time/batch = 0.6802s	
23140/33150 (epoch 34.902), train_loss = 1.05989588, grad/param norm = 1.7238e-01, time/batch = 0.6724s	
23141/33150 (epoch 34.903), train_loss = 0.87866975, grad/param norm = 1.7979e-01, time/batch = 0.6732s	
23142/33150 (epoch 34.905), train_loss = 0.86591047, grad/param norm = 1.5385e-01, time/batch = 0.6691s	
23143/33150 (epoch 34.906), train_loss = 0.87928437, grad/param norm = 1.8966e-01, time/batch = 0.6708s	
23144/33150 (epoch 34.908), train_loss = 0.94300816, grad/param norm = 1.9162e-01, time/batch = 0.6752s	
23145/33150 (epoch 34.910), train_loss = 0.94162509, grad/param norm = 1.9103e-01, time/batch = 0.6669s	
23146/33150 (epoch 34.911), train_loss = 0.74906964, grad/param norm = 1.4917e-01, time/batch = 0.6674s	
23147/33150 (epoch 34.913), train_loss = 0.81112803, grad/param norm = 1.8187e-01, time/batch = 0.6662s	
23148/33150 (epoch 34.914), train_loss = 0.88042242, grad/param norm = 1.9750e-01, time/batch = 0.6658s	
23149/33150 (epoch 34.916), train_loss = 0.81179855, grad/param norm = 1.8480e-01, time/batch = 0.6690s	
23150/33150 (epoch 34.917), train_loss = 0.88312536, grad/param norm = 1.7016e-01, time/batch = 0.6721s	
23151/33150 (epoch 34.919), train_loss = 0.99067551, grad/param norm = 2.1572e-01, time/batch = 0.6686s	
23152/33150 (epoch 34.920), train_loss = 0.96047129, grad/param norm = 1.7716e-01, time/batch = 0.6699s	
23153/33150 (epoch 34.922), train_loss = 1.00682629, grad/param norm = 2.1316e-01, time/batch = 0.6779s	
23154/33150 (epoch 34.923), train_loss = 0.85565022, grad/param norm = 1.7231e-01, time/batch = 0.6797s	
23155/33150 (epoch 34.925), train_loss = 0.95939530, grad/param norm = 1.8264e-01, time/batch = 0.6711s	
23156/33150 (epoch 34.926), train_loss = 0.83482556, grad/param norm = 1.7191e-01, time/batch = 0.6664s	
23157/33150 (epoch 34.928), train_loss = 0.83673713, grad/param norm = 1.6390e-01, time/batch = 0.6695s	
23158/33150 (epoch 34.929), train_loss = 0.92595379, grad/param norm = 1.8400e-01, time/batch = 0.6690s	
23159/33150 (epoch 34.931), train_loss = 0.99296690, grad/param norm = 1.9380e-01, time/batch = 0.6685s	
23160/33150 (epoch 34.932), train_loss = 0.89948732, grad/param norm = 1.8389e-01, time/batch = 0.6674s	
23161/33150 (epoch 34.934), train_loss = 0.88925710, grad/param norm = 1.6153e-01, time/batch = 0.6731s	
23162/33150 (epoch 34.935), train_loss = 0.94733674, grad/param norm = 1.7063e-01, time/batch = 0.6705s	
23163/33150 (epoch 34.937), train_loss = 0.98732685, grad/param norm = 1.6183e-01, time/batch = 0.6666s	
23164/33150 (epoch 34.938), train_loss = 0.89887386, grad/param norm = 1.6477e-01, time/batch = 0.6686s	
23165/33150 (epoch 34.940), train_loss = 1.07635572, grad/param norm = 1.9252e-01, time/batch = 0.6680s	
23166/33150 (epoch 34.941), train_loss = 0.90630966, grad/param norm = 1.5266e-01, time/batch = 0.6720s	
23167/33150 (epoch 34.943), train_loss = 0.73984375, grad/param norm = 1.8988e-01, time/batch = 0.6737s	
23168/33150 (epoch 34.944), train_loss = 0.92211196, grad/param norm = 2.0279e-01, time/batch = 0.6799s	
23169/33150 (epoch 34.946), train_loss = 0.76361586, grad/param norm = 1.4987e-01, time/batch = 0.6781s	
23170/33150 (epoch 34.947), train_loss = 0.90698540, grad/param norm = 1.8027e-01, time/batch = 0.6732s	
23171/33150 (epoch 34.949), train_loss = 0.97926309, grad/param norm = 1.7502e-01, time/batch = 0.6750s	
23172/33150 (epoch 34.950), train_loss = 0.93295688, grad/param norm = 1.9576e-01, time/batch = 0.6737s	
23173/33150 (epoch 34.952), train_loss = 0.79877926, grad/param norm = 1.6832e-01, time/batch = 0.6777s	
23174/33150 (epoch 34.953), train_loss = 0.86268484, grad/param norm = 1.5384e-01, time/batch = 0.6789s	
23175/33150 (epoch 34.955), train_loss = 0.74286141, grad/param norm = 1.4968e-01, time/batch = 0.6747s	
23176/33150 (epoch 34.956), train_loss = 0.94318317, grad/param norm = 1.8678e-01, time/batch = 0.6771s	
23177/33150 (epoch 34.958), train_loss = 0.77962452, grad/param norm = 1.6364e-01, time/batch = 0.6727s	
23178/33150 (epoch 34.959), train_loss = 0.84995323, grad/param norm = 1.5551e-01, time/batch = 0.6693s	
23179/33150 (epoch 34.961), train_loss = 0.80102141, grad/param norm = 1.7068e-01, time/batch = 0.6722s	
23180/33150 (epoch 34.962), train_loss = 0.74838857, grad/param norm = 1.5086e-01, time/batch = 0.6751s	
23181/33150 (epoch 34.964), train_loss = 0.85626911, grad/param norm = 1.7292e-01, time/batch = 0.6797s	
23182/33150 (epoch 34.965), train_loss = 0.85182135, grad/param norm = 1.8228e-01, time/batch = 0.6706s	
23183/33150 (epoch 34.967), train_loss = 0.83812287, grad/param norm = 2.2514e-01, time/batch = 0.6707s	
23184/33150 (epoch 34.968), train_loss = 0.72401734, grad/param norm = 1.3712e-01, time/batch = 0.6717s	
23185/33150 (epoch 34.970), train_loss = 0.81225335, grad/param norm = 1.5662e-01, time/batch = 0.6728s	
23186/33150 (epoch 34.971), train_loss = 0.86106036, grad/param norm = 1.6005e-01, time/batch = 0.6740s	
23187/33150 (epoch 34.973), train_loss = 0.92826289, grad/param norm = 1.6857e-01, time/batch = 0.6724s	
23188/33150 (epoch 34.974), train_loss = 0.99423623, grad/param norm = 1.7326e-01, time/batch = 0.6742s	
23189/33150 (epoch 34.976), train_loss = 0.95249371, grad/param norm = 1.6170e-01, time/batch = 0.6729s	
23190/33150 (epoch 34.977), train_loss = 0.97653354, grad/param norm = 1.7225e-01, time/batch = 0.6687s	
23191/33150 (epoch 34.979), train_loss = 0.94504047, grad/param norm = 2.1822e-01, time/batch = 0.6705s	
23192/33150 (epoch 34.980), train_loss = 1.02528231, grad/param norm = 1.9023e-01, time/batch = 0.6764s	
23193/33150 (epoch 34.982), train_loss = 0.86600214, grad/param norm = 1.9124e-01, time/batch = 0.6665s	
23194/33150 (epoch 34.983), train_loss = 0.77900271, grad/param norm = 1.6325e-01, time/batch = 0.6724s	
23195/33150 (epoch 34.985), train_loss = 0.98623465, grad/param norm = 1.8391e-01, time/batch = 0.6711s	
23196/33150 (epoch 34.986), train_loss = 0.72887768, grad/param norm = 1.6088e-01, time/batch = 0.6671s	
23197/33150 (epoch 34.988), train_loss = 0.82058135, grad/param norm = 1.8033e-01, time/batch = 0.6675s	
23198/33150 (epoch 34.989), train_loss = 0.84467329, grad/param norm = 1.5997e-01, time/batch = 0.6873s	
23199/33150 (epoch 34.991), train_loss = 0.92948353, grad/param norm = 2.4707e-01, time/batch = 0.6893s	
23200/33150 (epoch 34.992), train_loss = 0.84296697, grad/param norm = 1.7990e-01, time/batch = 0.6872s	
23201/33150 (epoch 34.994), train_loss = 0.88641619, grad/param norm = 1.5733e-01, time/batch = 0.6768s	
23202/33150 (epoch 34.995), train_loss = 0.84691093, grad/param norm = 1.6629e-01, time/batch = 0.6817s	
23203/33150 (epoch 34.997), train_loss = 0.86354077, grad/param norm = 2.2053e-01, time/batch = 0.6769s	
23204/33150 (epoch 34.998), train_loss = 0.73672433, grad/param norm = 1.5508e-01, time/batch = 0.6715s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
23205/33150 (epoch 35.000), train_loss = 0.74013406, grad/param norm = 1.8340e-01, time/batch = 0.6732s	
23206/33150 (epoch 35.002), train_loss = 1.17466534, grad/param norm = 1.9128e-01, time/batch = 0.6718s	
23207/33150 (epoch 35.003), train_loss = 0.77101602, grad/param norm = 1.6215e-01, time/batch = 0.6745s	
23208/33150 (epoch 35.005), train_loss = 0.74339633, grad/param norm = 1.6127e-01, time/batch = 0.6733s	
23209/33150 (epoch 35.006), train_loss = 0.73650181, grad/param norm = 1.6253e-01, time/batch = 0.6757s	
23210/33150 (epoch 35.008), train_loss = 0.90999440, grad/param norm = 1.9180e-01, time/batch = 0.6881s	
23211/33150 (epoch 35.009), train_loss = 0.89472124, grad/param norm = 1.6521e-01, time/batch = 0.6840s	
23212/33150 (epoch 35.011), train_loss = 0.95090269, grad/param norm = 1.7526e-01, time/batch = 0.6769s	
23213/33150 (epoch 35.012), train_loss = 0.86717707, grad/param norm = 2.0720e-01, time/batch = 0.6738s	
23214/33150 (epoch 35.014), train_loss = 0.77262499, grad/param norm = 1.5930e-01, time/batch = 0.6690s	
23215/33150 (epoch 35.015), train_loss = 0.78016361, grad/param norm = 1.7801e-01, time/batch = 0.6740s	
23216/33150 (epoch 35.017), train_loss = 0.79498664, grad/param norm = 1.5132e-01, time/batch = 0.6762s	
23217/33150 (epoch 35.018), train_loss = 0.88314158, grad/param norm = 1.9701e-01, time/batch = 0.6820s	
23218/33150 (epoch 35.020), train_loss = 0.94089276, grad/param norm = 2.2272e-01, time/batch = 0.6763s	
23219/33150 (epoch 35.021), train_loss = 0.76660559, grad/param norm = 1.5815e-01, time/batch = 0.6792s	
23220/33150 (epoch 35.023), train_loss = 1.03002176, grad/param norm = 1.6683e-01, time/batch = 0.6711s	
23221/33150 (epoch 35.024), train_loss = 0.91320841, grad/param norm = 2.2097e-01, time/batch = 0.6758s	
23222/33150 (epoch 35.026), train_loss = 0.68993004, grad/param norm = 1.4527e-01, time/batch = 0.6736s	
23223/33150 (epoch 35.027), train_loss = 0.68290084, grad/param norm = 1.3410e-01, time/batch = 0.6721s	
23224/33150 (epoch 35.029), train_loss = 0.80016579, grad/param norm = 1.7198e-01, time/batch = 0.6724s	
23225/33150 (epoch 35.030), train_loss = 0.81909540, grad/param norm = 1.4052e-01, time/batch = 0.6758s	
23226/33150 (epoch 35.032), train_loss = 0.75200661, grad/param norm = 2.1198e-01, time/batch = 0.6774s	
23227/33150 (epoch 35.033), train_loss = 0.78634170, grad/param norm = 1.6448e-01, time/batch = 0.6725s	
23228/33150 (epoch 35.035), train_loss = 1.03755624, grad/param norm = 2.2778e-01, time/batch = 0.6749s	
23229/33150 (epoch 35.036), train_loss = 0.93049444, grad/param norm = 1.9059e-01, time/batch = 0.6729s	
23230/33150 (epoch 35.038), train_loss = 1.05258632, grad/param norm = 1.9034e-01, time/batch = 0.6758s	
23231/33150 (epoch 35.039), train_loss = 0.93450410, grad/param norm = 1.5777e-01, time/batch = 0.6755s	
23232/33150 (epoch 35.041), train_loss = 0.86394868, grad/param norm = 1.6890e-01, time/batch = 0.6737s	
23233/33150 (epoch 35.042), train_loss = 0.79396195, grad/param norm = 1.7871e-01, time/batch = 0.6784s	
23234/33150 (epoch 35.044), train_loss = 0.85262884, grad/param norm = 1.5384e-01, time/batch = 0.6812s	
23235/33150 (epoch 35.045), train_loss = 0.91593345, grad/param norm = 1.4013e-01, time/batch = 0.6764s	
23236/33150 (epoch 35.047), train_loss = 0.77026595, grad/param norm = 1.6328e-01, time/batch = 0.6732s	
23237/33150 (epoch 35.048), train_loss = 0.96798390, grad/param norm = 2.3680e-01, time/batch = 0.6733s	
23238/33150 (epoch 35.050), train_loss = 0.85441280, grad/param norm = 2.0190e-01, time/batch = 0.6741s	
23239/33150 (epoch 35.051), train_loss = 0.86480468, grad/param norm = 1.4129e-01, time/batch = 0.6785s	
23240/33150 (epoch 35.053), train_loss = 0.88052048, grad/param norm = 1.9660e-01, time/batch = 0.6751s	
23241/33150 (epoch 35.054), train_loss = 1.00221357, grad/param norm = 1.6683e-01, time/batch = 0.6732s	
23242/33150 (epoch 35.056), train_loss = 0.84918989, grad/param norm = 1.6829e-01, time/batch = 0.6730s	
23243/33150 (epoch 35.057), train_loss = 0.90344907, grad/param norm = 1.5193e-01, time/batch = 0.6708s	
23244/33150 (epoch 35.059), train_loss = 0.77328637, grad/param norm = 1.6752e-01, time/batch = 0.6694s	
23245/33150 (epoch 35.060), train_loss = 0.76901498, grad/param norm = 1.4984e-01, time/batch = 0.6661s	
23246/33150 (epoch 35.062), train_loss = 0.87505193, grad/param norm = 1.8417e-01, time/batch = 0.6713s	
23247/33150 (epoch 35.063), train_loss = 0.78629822, grad/param norm = 1.6123e-01, time/batch = 0.6693s	
23248/33150 (epoch 35.065), train_loss = 0.84184254, grad/param norm = 1.6310e-01, time/batch = 0.6712s	
23249/33150 (epoch 35.066), train_loss = 0.83687216, grad/param norm = 1.6375e-01, time/batch = 0.7009s	
23250/33150 (epoch 35.068), train_loss = 0.91042610, grad/param norm = 1.6739e-01, time/batch = 0.6866s	
23251/33150 (epoch 35.069), train_loss = 0.91442791, grad/param norm = 1.9514e-01, time/batch = 0.6841s	
23252/33150 (epoch 35.071), train_loss = 0.87122016, grad/param norm = 1.6202e-01, time/batch = 0.6699s	
23253/33150 (epoch 35.072), train_loss = 0.89676117, grad/param norm = 1.8786e-01, time/batch = 0.6708s	
23254/33150 (epoch 35.074), train_loss = 0.74486923, grad/param norm = 1.7246e-01, time/batch = 0.6787s	
23255/33150 (epoch 35.075), train_loss = 0.77016765, grad/param norm = 1.7291e-01, time/batch = 0.6807s	
23256/33150 (epoch 35.077), train_loss = 0.89844632, grad/param norm = 2.3192e-01, time/batch = 0.6686s	
23257/33150 (epoch 35.078), train_loss = 0.99010291, grad/param norm = 2.0834e-01, time/batch = 0.6682s	
23258/33150 (epoch 35.080), train_loss = 0.99613239, grad/param norm = 1.7167e-01, time/batch = 0.6709s	
23259/33150 (epoch 35.081), train_loss = 0.74901412, grad/param norm = 1.6276e-01, time/batch = 0.6688s	
23260/33150 (epoch 35.083), train_loss = 0.65304706, grad/param norm = 1.7999e-01, time/batch = 0.6646s	
23261/33150 (epoch 35.084), train_loss = 0.74525797, grad/param norm = 2.0328e-01, time/batch = 0.6694s	
23262/33150 (epoch 35.086), train_loss = 0.77529834, grad/param norm = 1.6922e-01, time/batch = 0.6721s	
23263/33150 (epoch 35.087), train_loss = 0.73397822, grad/param norm = 1.6087e-01, time/batch = 0.6700s	
23264/33150 (epoch 35.089), train_loss = 0.79445949, grad/param norm = 1.6321e-01, time/batch = 0.6727s	
23265/33150 (epoch 35.090), train_loss = 0.81511639, grad/param norm = 1.5629e-01, time/batch = 0.6768s	
23266/33150 (epoch 35.092), train_loss = 0.81194323, grad/param norm = 1.8365e-01, time/batch = 0.6818s	
23267/33150 (epoch 35.094), train_loss = 0.88457284, grad/param norm = 2.0751e-01, time/batch = 0.6717s	
23268/33150 (epoch 35.095), train_loss = 0.77537590, grad/param norm = 1.8332e-01, time/batch = 0.6680s	
23269/33150 (epoch 35.097), train_loss = 0.73312852, grad/param norm = 1.7297e-01, time/batch = 0.6697s	
23270/33150 (epoch 35.098), train_loss = 1.07618704, grad/param norm = 1.9168e-01, time/batch = 0.6710s	
23271/33150 (epoch 35.100), train_loss = 1.04568212, grad/param norm = 1.8233e-01, time/batch = 0.6694s	
23272/33150 (epoch 35.101), train_loss = 0.80323443, grad/param norm = 1.5877e-01, time/batch = 0.6733s	
23273/33150 (epoch 35.103), train_loss = 0.87557610, grad/param norm = 1.6740e-01, time/batch = 0.6729s	
23274/33150 (epoch 35.104), train_loss = 0.78365350, grad/param norm = 1.7146e-01, time/batch = 0.6687s	
23275/33150 (epoch 35.106), train_loss = 0.96676594, grad/param norm = 1.8650e-01, time/batch = 0.6683s	
23276/33150 (epoch 35.107), train_loss = 1.04676961, grad/param norm = 2.1298e-01, time/batch = 0.6705s	
23277/33150 (epoch 35.109), train_loss = 0.85303929, grad/param norm = 1.5108e-01, time/batch = 0.6699s	
23278/33150 (epoch 35.110), train_loss = 0.96950143, grad/param norm = 1.9183e-01, time/batch = 0.6696s	
23279/33150 (epoch 35.112), train_loss = 0.78254935, grad/param norm = 1.7205e-01, time/batch = 0.6694s	
23280/33150 (epoch 35.113), train_loss = 0.81940888, grad/param norm = 1.7737e-01, time/batch = 0.6694s	
23281/33150 (epoch 35.115), train_loss = 1.02653798, grad/param norm = 2.0730e-01, time/batch = 0.6722s	
23282/33150 (epoch 35.116), train_loss = 0.90068824, grad/param norm = 1.7926e-01, time/batch = 0.6699s	
23283/33150 (epoch 35.118), train_loss = 0.88539247, grad/param norm = 1.9075e-01, time/batch = 0.6681s	
23284/33150 (epoch 35.119), train_loss = 0.89030310, grad/param norm = 1.8772e-01, time/batch = 0.6697s	
23285/33150 (epoch 35.121), train_loss = 0.83728489, grad/param norm = 1.6445e-01, time/batch = 0.6723s	
23286/33150 (epoch 35.122), train_loss = 1.00649056, grad/param norm = 2.0703e-01, time/batch = 0.6727s	
23287/33150 (epoch 35.124), train_loss = 0.72380757, grad/param norm = 1.4883e-01, time/batch = 0.6879s	
23288/33150 (epoch 35.125), train_loss = 0.96900530, grad/param norm = 1.6052e-01, time/batch = 0.7077s	
23289/33150 (epoch 35.127), train_loss = 0.88133260, grad/param norm = 1.6566e-01, time/batch = 0.6966s	
23290/33150 (epoch 35.128), train_loss = 0.89501613, grad/param norm = 1.7024e-01, time/batch = 0.6800s	
23291/33150 (epoch 35.130), train_loss = 0.86747927, grad/param norm = 1.7087e-01, time/batch = 0.6767s	
23292/33150 (epoch 35.131), train_loss = 1.05317373, grad/param norm = 1.7842e-01, time/batch = 0.6726s	
23293/33150 (epoch 35.133), train_loss = 0.81206133, grad/param norm = 1.7341e-01, time/batch = 0.6887s	
23294/33150 (epoch 35.134), train_loss = 0.96956849, grad/param norm = 1.7342e-01, time/batch = 0.6933s	
23295/33150 (epoch 35.136), train_loss = 0.90025677, grad/param norm = 2.0767e-01, time/batch = 0.6819s	
23296/33150 (epoch 35.137), train_loss = 0.93667024, grad/param norm = 1.6295e-01, time/batch = 0.6742s	
23297/33150 (epoch 35.139), train_loss = 0.91552192, grad/param norm = 1.7423e-01, time/batch = 0.6693s	
23298/33150 (epoch 35.140), train_loss = 1.04867925, grad/param norm = 1.8740e-01, time/batch = 0.6689s	
23299/33150 (epoch 35.142), train_loss = 0.92958896, grad/param norm = 2.0315e-01, time/batch = 0.6701s	
23300/33150 (epoch 35.143), train_loss = 0.85404627, grad/param norm = 1.8677e-01, time/batch = 0.6697s	
23301/33150 (epoch 35.145), train_loss = 0.83420384, grad/param norm = 1.7849e-01, time/batch = 0.6756s	
23302/33150 (epoch 35.146), train_loss = 0.95851114, grad/param norm = 2.1730e-01, time/batch = 0.6725s	
23303/33150 (epoch 35.148), train_loss = 1.00363376, grad/param norm = 1.6524e-01, time/batch = 0.6708s	
23304/33150 (epoch 35.149), train_loss = 0.90803172, grad/param norm = 1.9877e-01, time/batch = 0.6720s	
23305/33150 (epoch 35.151), train_loss = 1.03845838, grad/param norm = 1.8817e-01, time/batch = 0.6734s	
23306/33150 (epoch 35.152), train_loss = 0.81031667, grad/param norm = 1.5191e-01, time/batch = 0.6756s	
23307/33150 (epoch 35.154), train_loss = 0.81235267, grad/param norm = 1.6870e-01, time/batch = 0.6775s	
23308/33150 (epoch 35.155), train_loss = 0.76236785, grad/param norm = 1.8192e-01, time/batch = 0.6714s	
23309/33150 (epoch 35.157), train_loss = 0.85727303, grad/param norm = 1.7850e-01, time/batch = 0.6716s	
23310/33150 (epoch 35.158), train_loss = 0.84136427, grad/param norm = 1.6879e-01, time/batch = 0.6666s	
23311/33150 (epoch 35.160), train_loss = 0.94372087, grad/param norm = 1.8810e-01, time/batch = 0.6663s	
23312/33150 (epoch 35.161), train_loss = 0.82224388, grad/param norm = 1.9780e-01, time/batch = 0.6685s	
23313/33150 (epoch 35.163), train_loss = 0.76137391, grad/param norm = 1.5473e-01, time/batch = 0.6679s	
23314/33150 (epoch 35.164), train_loss = 0.90011234, grad/param norm = 1.5956e-01, time/batch = 0.6785s	
23315/33150 (epoch 35.166), train_loss = 0.82724768, grad/param norm = 1.5515e-01, time/batch = 0.6771s	
23316/33150 (epoch 35.167), train_loss = 0.90069920, grad/param norm = 1.7147e-01, time/batch = 0.6695s	
23317/33150 (epoch 35.169), train_loss = 0.88699578, grad/param norm = 1.8968e-01, time/batch = 0.6674s	
23318/33150 (epoch 35.170), train_loss = 0.78925470, grad/param norm = 1.8497e-01, time/batch = 0.6689s	
23319/33150 (epoch 35.172), train_loss = 0.92479349, grad/param norm = 2.0080e-01, time/batch = 0.6648s	
23320/33150 (epoch 35.173), train_loss = 0.90347484, grad/param norm = 1.9367e-01, time/batch = 0.6663s	
23321/33150 (epoch 35.175), train_loss = 0.82467100, grad/param norm = 1.7806e-01, time/batch = 0.6687s	
23322/33150 (epoch 35.176), train_loss = 0.93390191, grad/param norm = 2.1539e-01, time/batch = 0.6745s	
23323/33150 (epoch 35.178), train_loss = 1.06480440, grad/param norm = 2.1342e-01, time/batch = 0.6704s	
23324/33150 (epoch 35.179), train_loss = 0.95012759, grad/param norm = 1.7337e-01, time/batch = 0.6683s	
23325/33150 (epoch 35.181), train_loss = 0.88895945, grad/param norm = 1.9854e-01, time/batch = 0.6682s	
23326/33150 (epoch 35.183), train_loss = 0.85528310, grad/param norm = 1.8843e-01, time/batch = 0.6711s	
23327/33150 (epoch 35.184), train_loss = 1.09968357, grad/param norm = 1.7907e-01, time/batch = 0.6737s	
23328/33150 (epoch 35.186), train_loss = 1.01749417, grad/param norm = 1.8213e-01, time/batch = 0.6709s	
23329/33150 (epoch 35.187), train_loss = 0.89414402, grad/param norm = 1.8617e-01, time/batch = 0.6719s	
23330/33150 (epoch 35.189), train_loss = 0.70403959, grad/param norm = 1.7805e-01, time/batch = 0.6711s	
23331/33150 (epoch 35.190), train_loss = 0.78571921, grad/param norm = 2.2722e-01, time/batch = 0.6683s	
23332/33150 (epoch 35.192), train_loss = 0.91167611, grad/param norm = 2.0192e-01, time/batch = 0.6712s	
23333/33150 (epoch 35.193), train_loss = 0.93574022, grad/param norm = 1.7055e-01, time/batch = 0.6710s	
23334/33150 (epoch 35.195), train_loss = 1.08109919, grad/param norm = 2.2150e-01, time/batch = 0.6713s	
23335/33150 (epoch 35.196), train_loss = 1.01518403, grad/param norm = 1.7759e-01, time/batch = 0.6822s	
23336/33150 (epoch 35.198), train_loss = 0.76749392, grad/param norm = 1.5317e-01, time/batch = 0.6725s	
23337/33150 (epoch 35.199), train_loss = 0.94511041, grad/param norm = 2.1006e-01, time/batch = 0.6701s	
23338/33150 (epoch 35.201), train_loss = 0.83223226, grad/param norm = 1.6241e-01, time/batch = 0.6692s	
23339/33150 (epoch 35.202), train_loss = 0.70109458, grad/param norm = 1.5280e-01, time/batch = 0.6736s	
23340/33150 (epoch 35.204), train_loss = 0.91123955, grad/param norm = 1.8090e-01, time/batch = 0.6743s	
23341/33150 (epoch 35.205), train_loss = 0.90806691, grad/param norm = 1.7496e-01, time/batch = 0.6733s	
23342/33150 (epoch 35.207), train_loss = 0.92366155, grad/param norm = 1.7038e-01, time/batch = 0.6693s	
23343/33150 (epoch 35.208), train_loss = 0.94118306, grad/param norm = 1.7648e-01, time/batch = 0.6690s	
23344/33150 (epoch 35.210), train_loss = 0.83003167, grad/param norm = 1.6631e-01, time/batch = 0.6680s	
23345/33150 (epoch 35.211), train_loss = 0.87869674, grad/param norm = 1.9018e-01, time/batch = 0.6672s	
23346/33150 (epoch 35.213), train_loss = 0.94980028, grad/param norm = 1.6491e-01, time/batch = 0.6802s	
23347/33150 (epoch 35.214), train_loss = 0.83981481, grad/param norm = 1.7036e-01, time/batch = 0.6917s	
23348/33150 (epoch 35.216), train_loss = 0.80150535, grad/param norm = 1.9251e-01, time/batch = 0.6798s	
23349/33150 (epoch 35.217), train_loss = 0.85418376, grad/param norm = 1.6966e-01, time/batch = 0.6780s	
23350/33150 (epoch 35.219), train_loss = 0.80584744, grad/param norm = 1.5833e-01, time/batch = 0.6657s	
23351/33150 (epoch 35.220), train_loss = 0.84266281, grad/param norm = 1.4837e-01, time/batch = 0.6786s	
23352/33150 (epoch 35.222), train_loss = 0.97100776, grad/param norm = 1.9083e-01, time/batch = 0.6641s	
23353/33150 (epoch 35.223), train_loss = 0.87174637, grad/param norm = 1.8058e-01, time/batch = 0.6658s	
23354/33150 (epoch 35.225), train_loss = 0.98334415, grad/param norm = 1.6712e-01, time/batch = 0.6659s	
23355/33150 (epoch 35.226), train_loss = 0.85225230, grad/param norm = 1.6147e-01, time/batch = 0.6650s	
23356/33150 (epoch 35.228), train_loss = 0.84856748, grad/param norm = 1.9535e-01, time/batch = 0.6662s	
23357/33150 (epoch 35.229), train_loss = 0.86949457, grad/param norm = 1.6538e-01, time/batch = 0.6697s	
23358/33150 (epoch 35.231), train_loss = 0.96099980, grad/param norm = 2.1074e-01, time/batch = 0.6648s	
23359/33150 (epoch 35.232), train_loss = 0.86380652, grad/param norm = 1.7077e-01, time/batch = 0.6651s	
23360/33150 (epoch 35.234), train_loss = 0.89683195, grad/param norm = 1.6844e-01, time/batch = 0.6631s	
23361/33150 (epoch 35.235), train_loss = 0.92536923, grad/param norm = 1.6217e-01, time/batch = 0.6672s	
23362/33150 (epoch 35.237), train_loss = 0.90069276, grad/param norm = 2.4660e-01, time/batch = 0.6676s	
23363/33150 (epoch 35.238), train_loss = 0.93901383, grad/param norm = 1.8936e-01, time/batch = 0.6785s	
23364/33150 (epoch 35.240), train_loss = 0.90512015, grad/param norm = 1.8604e-01, time/batch = 0.6775s	
23365/33150 (epoch 35.241), train_loss = 0.96591106, grad/param norm = 2.0472e-01, time/batch = 0.6686s	
23366/33150 (epoch 35.243), train_loss = 0.95668521, grad/param norm = 1.9306e-01, time/batch = 0.6704s	
23367/33150 (epoch 35.244), train_loss = 0.88224439, grad/param norm = 1.6778e-01, time/batch = 0.6725s	
23368/33150 (epoch 35.246), train_loss = 0.98166477, grad/param norm = 1.8891e-01, time/batch = 0.6867s	
23369/33150 (epoch 35.247), train_loss = 0.83159775, grad/param norm = 1.5749e-01, time/batch = 0.6779s	
23370/33150 (epoch 35.249), train_loss = 1.02174001, grad/param norm = 1.8490e-01, time/batch = 0.6737s	
23371/33150 (epoch 35.250), train_loss = 0.93738934, grad/param norm = 1.6736e-01, time/batch = 0.6736s	
23372/33150 (epoch 35.252), train_loss = 0.93657705, grad/param norm = 1.6321e-01, time/batch = 0.6718s	
23373/33150 (epoch 35.253), train_loss = 0.86878545, grad/param norm = 2.0789e-01, time/batch = 0.6748s	
23374/33150 (epoch 35.255), train_loss = 0.85866188, grad/param norm = 1.4168e-01, time/batch = 0.6726s	
23375/33150 (epoch 35.256), train_loss = 0.99349798, grad/param norm = 1.6725e-01, time/batch = 0.6820s	
23376/33150 (epoch 35.258), train_loss = 0.82342818, grad/param norm = 2.0168e-01, time/batch = 0.6907s	
23377/33150 (epoch 35.259), train_loss = 0.72363310, grad/param norm = 1.8494e-01, time/batch = 0.6844s	
23378/33150 (epoch 35.261), train_loss = 0.78462519, grad/param norm = 1.5181e-01, time/batch = 0.6857s	
23379/33150 (epoch 35.262), train_loss = 0.99574720, grad/param norm = 1.9291e-01, time/batch = 0.6968s	
23380/33150 (epoch 35.264), train_loss = 0.67646954, grad/param norm = 1.4042e-01, time/batch = 0.6835s	
23381/33150 (epoch 35.265), train_loss = 0.89673864, grad/param norm = 1.8460e-01, time/batch = 0.6744s	
23382/33150 (epoch 35.267), train_loss = 0.98800805, grad/param norm = 2.2709e-01, time/batch = 0.6767s	
23383/33150 (epoch 35.268), train_loss = 0.99240747, grad/param norm = 1.6403e-01, time/batch = 0.6736s	
23384/33150 (epoch 35.270), train_loss = 1.07254688, grad/param norm = 1.7664e-01, time/batch = 0.6704s	
23385/33150 (epoch 35.271), train_loss = 0.95622925, grad/param norm = 1.7944e-01, time/batch = 0.6680s	
23386/33150 (epoch 35.273), train_loss = 0.99752050, grad/param norm = 1.6912e-01, time/batch = 0.6712s	
23387/33150 (epoch 35.275), train_loss = 1.01181039, grad/param norm = 1.8551e-01, time/batch = 0.6776s	
23388/33150 (epoch 35.276), train_loss = 0.88709064, grad/param norm = 1.8318e-01, time/batch = 0.6724s	
23389/33150 (epoch 35.278), train_loss = 0.98836114, grad/param norm = 1.6015e-01, time/batch = 0.6712s	
23390/33150 (epoch 35.279), train_loss = 0.94817763, grad/param norm = 1.6555e-01, time/batch = 0.6743s	
23391/33150 (epoch 35.281), train_loss = 0.88241802, grad/param norm = 1.7124e-01, time/batch = 0.6719s	
23392/33150 (epoch 35.282), train_loss = 0.92499006, grad/param norm = 1.5407e-01, time/batch = 0.6755s	
23393/33150 (epoch 35.284), train_loss = 0.81386405, grad/param norm = 1.7482e-01, time/batch = 0.6834s	
23394/33150 (epoch 35.285), train_loss = 0.92267180, grad/param norm = 1.8985e-01, time/batch = 0.6937s	
23395/33150 (epoch 35.287), train_loss = 0.79403192, grad/param norm = 1.9285e-01, time/batch = 0.6887s	
23396/33150 (epoch 35.288), train_loss = 0.95716561, grad/param norm = 1.6576e-01, time/batch = 0.6794s	
23397/33150 (epoch 35.290), train_loss = 0.75306044, grad/param norm = 1.4944e-01, time/batch = 0.6706s	
23398/33150 (epoch 35.291), train_loss = 0.72389376, grad/param norm = 1.5477e-01, time/batch = 0.6820s	
23399/33150 (epoch 35.293), train_loss = 0.86304013, grad/param norm = 1.6730e-01, time/batch = 0.6690s	
23400/33150 (epoch 35.294), train_loss = 0.68156989, grad/param norm = 1.4124e-01, time/batch = 0.6676s	
23401/33150 (epoch 35.296), train_loss = 0.87102548, grad/param norm = 1.5591e-01, time/batch = 0.6683s	
23402/33150 (epoch 35.297), train_loss = 0.83338500, grad/param norm = 1.7704e-01, time/batch = 0.6693s	
23403/33150 (epoch 35.299), train_loss = 0.85752275, grad/param norm = 2.3845e-01, time/batch = 0.6720s	
23404/33150 (epoch 35.300), train_loss = 0.82630551, grad/param norm = 1.4949e-01, time/batch = 0.6689s	
23405/33150 (epoch 35.302), train_loss = 0.85616973, grad/param norm = 1.6161e-01, time/batch = 0.6734s	
23406/33150 (epoch 35.303), train_loss = 0.83275494, grad/param norm = 1.7868e-01, time/batch = 0.6719s	
23407/33150 (epoch 35.305), train_loss = 0.92835246, grad/param norm = 1.6868e-01, time/batch = 0.6703s	
23408/33150 (epoch 35.306), train_loss = 0.93478273, grad/param norm = 1.7168e-01, time/batch = 0.6813s	
23409/33150 (epoch 35.308), train_loss = 1.09783207, grad/param norm = 1.8369e-01, time/batch = 0.6895s	
23410/33150 (epoch 35.309), train_loss = 0.73977508, grad/param norm = 1.5268e-01, time/batch = 0.6878s	
23411/33150 (epoch 35.311), train_loss = 0.85829742, grad/param norm = 1.8313e-01, time/batch = 0.6879s	
23412/33150 (epoch 35.312), train_loss = 0.70948768, grad/param norm = 1.5375e-01, time/batch = 0.6871s	
23413/33150 (epoch 35.314), train_loss = 0.84707198, grad/param norm = 1.7026e-01, time/batch = 0.6782s	
23414/33150 (epoch 35.315), train_loss = 0.92457145, grad/param norm = 1.6401e-01, time/batch = 0.6833s	
23415/33150 (epoch 35.317), train_loss = 0.69118321, grad/param norm = 1.2761e-01, time/batch = 0.6887s	
23416/33150 (epoch 35.318), train_loss = 0.80685451, grad/param norm = 1.5168e-01, time/batch = 0.6840s	
23417/33150 (epoch 35.320), train_loss = 0.74615635, grad/param norm = 1.6897e-01, time/batch = 0.6856s	
23418/33150 (epoch 35.321), train_loss = 0.84596736, grad/param norm = 1.5811e-01, time/batch = 0.6797s	
23419/33150 (epoch 35.323), train_loss = 0.82824591, grad/param norm = 1.7258e-01, time/batch = 0.6674s	
23420/33150 (epoch 35.324), train_loss = 0.89238043, grad/param norm = 2.0864e-01, time/batch = 0.6707s	
23421/33150 (epoch 35.326), train_loss = 0.87132966, grad/param norm = 1.5826e-01, time/batch = 0.6758s	
23422/33150 (epoch 35.327), train_loss = 0.95407899, grad/param norm = 1.8222e-01, time/batch = 0.6821s	
23423/33150 (epoch 35.329), train_loss = 0.91103244, grad/param norm = 1.5936e-01, time/batch = 0.6738s	
23424/33150 (epoch 35.330), train_loss = 0.84719651, grad/param norm = 1.8261e-01, time/batch = 0.6788s	
23425/33150 (epoch 35.332), train_loss = 0.85843910, grad/param norm = 1.6153e-01, time/batch = 0.6694s	
23426/33150 (epoch 35.333), train_loss = 0.93164057, grad/param norm = 1.5385e-01, time/batch = 0.6677s	
23427/33150 (epoch 35.335), train_loss = 0.79525403, grad/param norm = 1.5815e-01, time/batch = 0.6703s	
23428/33150 (epoch 35.336), train_loss = 0.79064382, grad/param norm = 1.8419e-01, time/batch = 0.6684s	
23429/33150 (epoch 35.338), train_loss = 0.73177913, grad/param norm = 1.6439e-01, time/batch = 0.6718s	
23430/33150 (epoch 35.339), train_loss = 0.95194259, grad/param norm = 1.8339e-01, time/batch = 0.6752s	
23431/33150 (epoch 35.341), train_loss = 0.88597008, grad/param norm = 1.9347e-01, time/batch = 0.6700s	
23432/33150 (epoch 35.342), train_loss = 0.80711125, grad/param norm = 1.7313e-01, time/batch = 0.6732s	
23433/33150 (epoch 35.344), train_loss = 0.86671169, grad/param norm = 1.7344e-01, time/batch = 0.6696s	
23434/33150 (epoch 35.345), train_loss = 0.83687916, grad/param norm = 1.6883e-01, time/batch = 0.6647s	
23435/33150 (epoch 35.347), train_loss = 0.71629282, grad/param norm = 1.6319e-01, time/batch = 0.6711s	
23436/33150 (epoch 35.348), train_loss = 0.89722782, grad/param norm = 1.7435e-01, time/batch = 0.6740s	
23437/33150 (epoch 35.350), train_loss = 0.77292363, grad/param norm = 1.7026e-01, time/batch = 0.6816s	
23438/33150 (epoch 35.351), train_loss = 0.93501026, grad/param norm = 1.7661e-01, time/batch = 0.6727s	
23439/33150 (epoch 35.353), train_loss = 0.90616519, grad/param norm = 1.6835e-01, time/batch = 0.6701s	
23440/33150 (epoch 35.354), train_loss = 1.07829358, grad/param norm = 1.7763e-01, time/batch = 0.6683s	
23441/33150 (epoch 35.356), train_loss = 0.94509994, grad/param norm = 1.6589e-01, time/batch = 0.6734s	
23442/33150 (epoch 35.357), train_loss = 0.88270523, grad/param norm = 1.7204e-01, time/batch = 0.6736s	
23443/33150 (epoch 35.359), train_loss = 0.93344500, grad/param norm = 1.7097e-01, time/batch = 0.6692s	
23444/33150 (epoch 35.360), train_loss = 0.91306725, grad/param norm = 2.0418e-01, time/batch = 0.6713s	
23445/33150 (epoch 35.362), train_loss = 0.99522159, grad/param norm = 1.7373e-01, time/batch = 0.6721s	
23446/33150 (epoch 35.363), train_loss = 0.90268035, grad/param norm = 1.6194e-01, time/batch = 0.6695s	
23447/33150 (epoch 35.365), train_loss = 0.84859194, grad/param norm = 1.5582e-01, time/batch = 0.6725s	
23448/33150 (epoch 35.367), train_loss = 0.82535317, grad/param norm = 1.5984e-01, time/batch = 0.6731s	
23449/33150 (epoch 35.368), train_loss = 0.85642835, grad/param norm = 2.0063e-01, time/batch = 0.6702s	
23450/33150 (epoch 35.370), train_loss = 0.90302878, grad/param norm = 1.9672e-01, time/batch = 0.6740s	
23451/33150 (epoch 35.371), train_loss = 0.78718870, grad/param norm = 1.6587e-01, time/batch = 0.6771s	
23452/33150 (epoch 35.373), train_loss = 0.88925864, grad/param norm = 1.7977e-01, time/batch = 0.6749s	
23453/33150 (epoch 35.374), train_loss = 0.87052963, grad/param norm = 1.5147e-01, time/batch = 0.6763s	
23454/33150 (epoch 35.376), train_loss = 0.95917346, grad/param norm = 1.6590e-01, time/batch = 0.6761s	
23455/33150 (epoch 35.377), train_loss = 0.79595617, grad/param norm = 1.7885e-01, time/batch = 0.6737s	
23456/33150 (epoch 35.379), train_loss = 0.90893239, grad/param norm = 1.9180e-01, time/batch = 0.6724s	
23457/33150 (epoch 35.380), train_loss = 0.91611544, grad/param norm = 1.4626e-01, time/batch = 0.6762s	
23458/33150 (epoch 35.382), train_loss = 0.86822643, grad/param norm = 1.6185e-01, time/batch = 0.6730s	
23459/33150 (epoch 35.383), train_loss = 0.78704402, grad/param norm = 1.5320e-01, time/batch = 0.6748s	
23460/33150 (epoch 35.385), train_loss = 0.82500886, grad/param norm = 1.7484e-01, time/batch = 0.6738s	
23461/33150 (epoch 35.386), train_loss = 0.76154081, grad/param norm = 1.4509e-01, time/batch = 0.6763s	
23462/33150 (epoch 35.388), train_loss = 0.79964461, grad/param norm = 1.6845e-01, time/batch = 0.6754s	
23463/33150 (epoch 35.389), train_loss = 0.79572099, grad/param norm = 1.5073e-01, time/batch = 0.6777s	
23464/33150 (epoch 35.391), train_loss = 1.03074037, grad/param norm = 1.9619e-01, time/batch = 0.6886s	
23465/33150 (epoch 35.392), train_loss = 0.82612143, grad/param norm = 1.6747e-01, time/batch = 0.6913s	
23466/33150 (epoch 35.394), train_loss = 0.72921296, grad/param norm = 1.4012e-01, time/batch = 0.6852s	
23467/33150 (epoch 35.395), train_loss = 0.71200711, grad/param norm = 1.6463e-01, time/batch = 0.6839s	
23468/33150 (epoch 35.397), train_loss = 0.59642686, grad/param norm = 1.3833e-01, time/batch = 0.6743s	
23469/33150 (epoch 35.398), train_loss = 0.87864919, grad/param norm = 1.8770e-01, time/batch = 0.6697s	
23470/33150 (epoch 35.400), train_loss = 0.84822104, grad/param norm = 1.3869e-01, time/batch = 0.6702s	
23471/33150 (epoch 35.401), train_loss = 0.72721671, grad/param norm = 1.3474e-01, time/batch = 0.6739s	
23472/33150 (epoch 35.403), train_loss = 0.73254745, grad/param norm = 1.4780e-01, time/batch = 0.6720s	
23473/33150 (epoch 35.404), train_loss = 0.87724253, grad/param norm = 1.6494e-01, time/batch = 0.6760s	
23474/33150 (epoch 35.406), train_loss = 0.81287474, grad/param norm = 1.4108e-01, time/batch = 0.6710s	
23475/33150 (epoch 35.407), train_loss = 0.73596875, grad/param norm = 1.4865e-01, time/batch = 0.6742s	
23476/33150 (epoch 35.409), train_loss = 0.69977261, grad/param norm = 1.6072e-01, time/batch = 0.6735s	
23477/33150 (epoch 35.410), train_loss = 0.87331226, grad/param norm = 1.6445e-01, time/batch = 0.6680s	
23478/33150 (epoch 35.412), train_loss = 0.90801111, grad/param norm = 1.5639e-01, time/batch = 0.6733s	
23479/33150 (epoch 35.413), train_loss = 0.76277325, grad/param norm = 1.5141e-01, time/batch = 0.6753s	
23480/33150 (epoch 35.415), train_loss = 0.89368383, grad/param norm = 1.6111e-01, time/batch = 0.6725s	
23481/33150 (epoch 35.416), train_loss = 0.79653537, grad/param norm = 1.5298e-01, time/batch = 0.6831s	
23482/33150 (epoch 35.418), train_loss = 0.89503715, grad/param norm = 2.2828e-01, time/batch = 0.6771s	
23483/33150 (epoch 35.419), train_loss = 0.85649108, grad/param norm = 1.8865e-01, time/batch = 0.6703s	
23484/33150 (epoch 35.421), train_loss = 0.85741825, grad/param norm = 1.9753e-01, time/batch = 0.6760s	
23485/33150 (epoch 35.422), train_loss = 0.80559344, grad/param norm = 1.4985e-01, time/batch = 0.6703s	
23486/33150 (epoch 35.424), train_loss = 0.79954572, grad/param norm = 1.6955e-01, time/batch = 0.6691s	
23487/33150 (epoch 35.425), train_loss = 0.95123676, grad/param norm = 1.9193e-01, time/batch = 0.6686s	
23488/33150 (epoch 35.427), train_loss = 0.86173127, grad/param norm = 1.5902e-01, time/batch = 0.6692s	
23489/33150 (epoch 35.428), train_loss = 0.84779191, grad/param norm = 1.6861e-01, time/batch = 0.6703s	
23490/33150 (epoch 35.430), train_loss = 0.89298186, grad/param norm = 1.9347e-01, time/batch = 0.6704s	
23491/33150 (epoch 35.431), train_loss = 0.92449750, grad/param norm = 2.0008e-01, time/batch = 0.6823s	
23492/33150 (epoch 35.433), train_loss = 0.85124945, grad/param norm = 1.7251e-01, time/batch = 0.6751s	
23493/33150 (epoch 35.434), train_loss = 0.74086002, grad/param norm = 1.5506e-01, time/batch = 0.6687s	
23494/33150 (epoch 35.436), train_loss = 0.86661963, grad/param norm = 1.5447e-01, time/batch = 0.6707s	
23495/33150 (epoch 35.437), train_loss = 0.87716958, grad/param norm = 2.3846e-01, time/batch = 0.6681s	
23496/33150 (epoch 35.439), train_loss = 1.01404471, grad/param norm = 1.6963e-01, time/batch = 0.6692s	
23497/33150 (epoch 35.440), train_loss = 0.91139127, grad/param norm = 1.9210e-01, time/batch = 0.6678s	
23498/33150 (epoch 35.442), train_loss = 0.75778015, grad/param norm = 1.6220e-01, time/batch = 0.6674s	
23499/33150 (epoch 35.443), train_loss = 0.88772118, grad/param norm = 1.7721e-01, time/batch = 0.6694s	
23500/33150 (epoch 35.445), train_loss = 0.85698720, grad/param norm = 2.1637e-01, time/batch = 0.6712s	
23501/33150 (epoch 35.446), train_loss = 0.91018007, grad/param norm = 2.2648e-01, time/batch = 0.6697s	
23502/33150 (epoch 35.448), train_loss = 0.96248080, grad/param norm = 1.7581e-01, time/batch = 0.6702s	
23503/33150 (epoch 35.449), train_loss = 0.87300881, grad/param norm = 1.5377e-01, time/batch = 0.6691s	
23504/33150 (epoch 35.451), train_loss = 0.88105633, grad/param norm = 2.2659e-01, time/batch = 0.6695s	
23505/33150 (epoch 35.452), train_loss = 1.03923050, grad/param norm = 1.8128e-01, time/batch = 0.6681s	
23506/33150 (epoch 35.454), train_loss = 0.84078079, grad/param norm = 1.5885e-01, time/batch = 0.6697s	
23507/33150 (epoch 35.456), train_loss = 0.78985425, grad/param norm = 1.5559e-01, time/batch = 0.6690s	
23508/33150 (epoch 35.457), train_loss = 0.87845210, grad/param norm = 1.8120e-01, time/batch = 0.6901s	
23509/33150 (epoch 35.459), train_loss = 0.98561326, grad/param norm = 2.4453e-01, time/batch = 0.6822s	
23510/33150 (epoch 35.460), train_loss = 0.91689578, grad/param norm = 1.5166e-01, time/batch = 0.6858s	
23511/33150 (epoch 35.462), train_loss = 0.95778269, grad/param norm = 2.2941e-01, time/batch = 0.6840s	
23512/33150 (epoch 35.463), train_loss = 1.07910638, grad/param norm = 2.0234e-01, time/batch = 0.6832s	
23513/33150 (epoch 35.465), train_loss = 0.92227679, grad/param norm = 1.6431e-01, time/batch = 0.6812s	
23514/33150 (epoch 35.466), train_loss = 0.82149033, grad/param norm = 1.4925e-01, time/batch = 0.6831s	
23515/33150 (epoch 35.468), train_loss = 1.06971151, grad/param norm = 1.7675e-01, time/batch = 0.6760s	
23516/33150 (epoch 35.469), train_loss = 0.80319227, grad/param norm = 1.7545e-01, time/batch = 0.6761s	
23517/33150 (epoch 35.471), train_loss = 0.81590131, grad/param norm = 1.6926e-01, time/batch = 0.6861s	
23518/33150 (epoch 35.472), train_loss = 0.88744649, grad/param norm = 1.7175e-01, time/batch = 0.6714s	
23519/33150 (epoch 35.474), train_loss = 0.94138063, grad/param norm = 2.1124e-01, time/batch = 0.6718s	
23520/33150 (epoch 35.475), train_loss = 1.10687602, grad/param norm = 1.9060e-01, time/batch = 0.6722s	
23521/33150 (epoch 35.477), train_loss = 0.94168226, grad/param norm = 1.8034e-01, time/batch = 0.6767s	
23522/33150 (epoch 35.478), train_loss = 0.91303545, grad/param norm = 1.6549e-01, time/batch = 0.6689s	
23523/33150 (epoch 35.480), train_loss = 0.80935738, grad/param norm = 1.6661e-01, time/batch = 0.6714s	
23524/33150 (epoch 35.481), train_loss = 0.73667414, grad/param norm = 1.5013e-01, time/batch = 0.6701s	
23525/33150 (epoch 35.483), train_loss = 0.83659384, grad/param norm = 1.5673e-01, time/batch = 0.6761s	
23526/33150 (epoch 35.484), train_loss = 0.78560858, grad/param norm = 1.7331e-01, time/batch = 0.6808s	
23527/33150 (epoch 35.486), train_loss = 0.79222203, grad/param norm = 1.7186e-01, time/batch = 0.6709s	
23528/33150 (epoch 35.487), train_loss = 0.91888678, grad/param norm = 1.7030e-01, time/batch = 0.6680s	
23529/33150 (epoch 35.489), train_loss = 0.87660412, grad/param norm = 1.7848e-01, time/batch = 0.6702s	
23530/33150 (epoch 35.490), train_loss = 0.71274496, grad/param norm = 1.4757e-01, time/batch = 0.6696s	
23531/33150 (epoch 35.492), train_loss = 0.82837769, grad/param norm = 1.8167e-01, time/batch = 0.6680s	
23532/33150 (epoch 35.493), train_loss = 0.93295266, grad/param norm = 1.6992e-01, time/batch = 0.6683s	
23533/33150 (epoch 35.495), train_loss = 0.92157337, grad/param norm = 1.5590e-01, time/batch = 0.6677s	
23534/33150 (epoch 35.496), train_loss = 0.84549222, grad/param norm = 1.6374e-01, time/batch = 0.6701s	
23535/33150 (epoch 35.498), train_loss = 0.96102957, grad/param norm = 2.5726e-01, time/batch = 0.6730s	
23536/33150 (epoch 35.499), train_loss = 0.96307652, grad/param norm = 1.6723e-01, time/batch = 0.6693s	
23537/33150 (epoch 35.501), train_loss = 0.92424766, grad/param norm = 2.0104e-01, time/batch = 0.6694s	
23538/33150 (epoch 35.502), train_loss = 0.97121695, grad/param norm = 1.9710e-01, time/batch = 0.6711s	
23539/33150 (epoch 35.504), train_loss = 0.96209219, grad/param norm = 1.9763e-01, time/batch = 0.6681s	
23540/33150 (epoch 35.505), train_loss = 0.98982805, grad/param norm = 1.8569e-01, time/batch = 0.6794s	
23541/33150 (epoch 35.507), train_loss = 0.80239595, grad/param norm = 1.7316e-01, time/batch = 0.6776s	
23542/33150 (epoch 35.508), train_loss = 0.82590803, grad/param norm = 1.7670e-01, time/batch = 0.6703s	
23543/33150 (epoch 35.510), train_loss = 0.94544979, grad/param norm = 1.6169e-01, time/batch = 0.6693s	
23544/33150 (epoch 35.511), train_loss = 0.99453130, grad/param norm = 1.7668e-01, time/batch = 0.6679s	
23545/33150 (epoch 35.513), train_loss = 0.90197407, grad/param norm = 2.0182e-01, time/batch = 0.6646s	
23546/33150 (epoch 35.514), train_loss = 0.77136223, grad/param norm = 1.9447e-01, time/batch = 0.6673s	
23547/33150 (epoch 35.516), train_loss = 0.89874179, grad/param norm = 2.1388e-01, time/batch = 0.6650s	
23548/33150 (epoch 35.517), train_loss = 0.95470609, grad/param norm = 1.8147e-01, time/batch = 0.6621s	
23549/33150 (epoch 35.519), train_loss = 0.81389436, grad/param norm = 1.7996e-01, time/batch = 0.6773s	
23550/33150 (epoch 35.520), train_loss = 0.89617833, grad/param norm = 1.6614e-01, time/batch = 0.6715s	
23551/33150 (epoch 35.522), train_loss = 0.94389643, grad/param norm = 1.9961e-01, time/batch = 0.6645s	
23552/33150 (epoch 35.523), train_loss = 0.77765128, grad/param norm = 1.7533e-01, time/batch = 0.6761s	
23553/33150 (epoch 35.525), train_loss = 0.91793091, grad/param norm = 1.6575e-01, time/batch = 0.6870s	
23554/33150 (epoch 35.526), train_loss = 0.79766024, grad/param norm = 1.6926e-01, time/batch = 0.6941s	
23555/33150 (epoch 35.528), train_loss = 0.88684147, grad/param norm = 1.8521e-01, time/batch = 0.6841s	
23556/33150 (epoch 35.529), train_loss = 0.86931589, grad/param norm = 1.7087e-01, time/batch = 0.6909s	
23557/33150 (epoch 35.531), train_loss = 0.75070460, grad/param norm = 1.7865e-01, time/batch = 0.6762s	
23558/33150 (epoch 35.532), train_loss = 0.89376587, grad/param norm = 2.0867e-01, time/batch = 0.6879s	
23559/33150 (epoch 35.534), train_loss = 0.87338744, grad/param norm = 1.5462e-01, time/batch = 0.6938s	
23560/33150 (epoch 35.535), train_loss = 0.82282278, grad/param norm = 2.1339e-01, time/batch = 0.6744s	
23561/33150 (epoch 35.537), train_loss = 0.91455892, grad/param norm = 2.4220e-01, time/batch = 0.6697s	
23562/33150 (epoch 35.538), train_loss = 0.77485837, grad/param norm = 1.5426e-01, time/batch = 0.6692s	
23563/33150 (epoch 35.540), train_loss = 0.78388015, grad/param norm = 1.7563e-01, time/batch = 0.6930s	
23564/33150 (epoch 35.541), train_loss = 0.96546878, grad/param norm = 1.7277e-01, time/batch = 0.6753s	
23565/33150 (epoch 35.543), train_loss = 0.88806660, grad/param norm = 1.7073e-01, time/batch = 0.6725s	
23566/33150 (epoch 35.544), train_loss = 0.93826621, grad/param norm = 1.9155e-01, time/batch = 0.6732s	
23567/33150 (epoch 35.546), train_loss = 0.84145435, grad/param norm = 1.7335e-01, time/batch = 0.6699s	
23568/33150 (epoch 35.548), train_loss = 0.84666576, grad/param norm = 2.0724e-01, time/batch = 0.6737s	
23569/33150 (epoch 35.549), train_loss = 0.82539171, grad/param norm = 1.7396e-01, time/batch = 0.6762s	
23570/33150 (epoch 35.551), train_loss = 0.80378846, grad/param norm = 1.6074e-01, time/batch = 0.6815s	
23571/33150 (epoch 35.552), train_loss = 0.68970409, grad/param norm = 1.4147e-01, time/batch = 0.6755s	
23572/33150 (epoch 35.554), train_loss = 0.93089556, grad/param norm = 1.7345e-01, time/batch = 0.6803s	
23573/33150 (epoch 35.555), train_loss = 0.96452307, grad/param norm = 1.9955e-01, time/batch = 0.6767s	
23574/33150 (epoch 35.557), train_loss = 0.73935199, grad/param norm = 1.8840e-01, time/batch = 0.6697s	
23575/33150 (epoch 35.558), train_loss = 0.91269441, grad/param norm = 2.2698e-01, time/batch = 0.6697s	
23576/33150 (epoch 35.560), train_loss = 0.80816898, grad/param norm = 1.6412e-01, time/batch = 0.6772s	
23577/33150 (epoch 35.561), train_loss = 0.72993337, grad/param norm = 1.7107e-01, time/batch = 0.6810s	
23578/33150 (epoch 35.563), train_loss = 0.92772328, grad/param norm = 2.2021e-01, time/batch = 0.6735s	
23579/33150 (epoch 35.564), train_loss = 0.97749525, grad/param norm = 1.6967e-01, time/batch = 0.6717s	
23580/33150 (epoch 35.566), train_loss = 0.81524095, grad/param norm = 1.8084e-01, time/batch = 0.6880s	
23581/33150 (epoch 35.567), train_loss = 0.81398534, grad/param norm = 1.7974e-01, time/batch = 0.6832s	
23582/33150 (epoch 35.569), train_loss = 0.88827453, grad/param norm = 1.6873e-01, time/batch = 0.6787s	
23583/33150 (epoch 35.570), train_loss = 0.91510480, grad/param norm = 1.6192e-01, time/batch = 0.6787s	
23584/33150 (epoch 35.572), train_loss = 0.79602184, grad/param norm = 1.5908e-01, time/batch = 0.6767s	
23585/33150 (epoch 35.573), train_loss = 0.73272508, grad/param norm = 1.4754e-01, time/batch = 0.6801s	
23586/33150 (epoch 35.575), train_loss = 0.83316270, grad/param norm = 1.7421e-01, time/batch = 0.6750s	
23587/33150 (epoch 35.576), train_loss = 0.75672297, grad/param norm = 1.5698e-01, time/batch = 0.6743s	
23588/33150 (epoch 35.578), train_loss = 0.79988429, grad/param norm = 1.7571e-01, time/batch = 0.6744s	
23589/33150 (epoch 35.579), train_loss = 0.75059898, grad/param norm = 1.5749e-01, time/batch = 0.6767s	
23590/33150 (epoch 35.581), train_loss = 0.77521082, grad/param norm = 1.7324e-01, time/batch = 0.6771s	
23591/33150 (epoch 35.582), train_loss = 0.98662850, grad/param norm = 1.6729e-01, time/batch = 0.6768s	
23592/33150 (epoch 35.584), train_loss = 0.94304836, grad/param norm = 1.8348e-01, time/batch = 0.6760s	
23593/33150 (epoch 35.585), train_loss = 0.86778261, grad/param norm = 1.5651e-01, time/batch = 0.6763s	
23594/33150 (epoch 35.587), train_loss = 0.86784257, grad/param norm = 1.6921e-01, time/batch = 0.6755s	
23595/33150 (epoch 35.588), train_loss = 0.79151647, grad/param norm = 1.6832e-01, time/batch = 0.6722s	
23596/33150 (epoch 35.590), train_loss = 0.90420142, grad/param norm = 1.6751e-01, time/batch = 0.6734s	
23597/33150 (epoch 35.591), train_loss = 0.86884525, grad/param norm = 1.7426e-01, time/batch = 0.6726s	
23598/33150 (epoch 35.593), train_loss = 0.92774808, grad/param norm = 2.0848e-01, time/batch = 0.6692s	
23599/33150 (epoch 35.594), train_loss = 0.83196972, grad/param norm = 1.7284e-01, time/batch = 0.6688s	
23600/33150 (epoch 35.596), train_loss = 0.83034312, grad/param norm = 1.7619e-01, time/batch = 0.6676s	
23601/33150 (epoch 35.597), train_loss = 0.77262791, grad/param norm = 2.8527e-01, time/batch = 0.6710s	
23602/33150 (epoch 35.599), train_loss = 1.02065592, grad/param norm = 2.1044e-01, time/batch = 0.6686s	
23603/33150 (epoch 35.600), train_loss = 0.87261402, grad/param norm = 2.3099e-01, time/batch = 0.6722s	
23604/33150 (epoch 35.602), train_loss = 0.88190310, grad/param norm = 1.9778e-01, time/batch = 0.6818s	
23605/33150 (epoch 35.603), train_loss = 0.97056481, grad/param norm = 1.8076e-01, time/batch = 0.6721s	
23606/33150 (epoch 35.605), train_loss = 0.76664623, grad/param norm = 1.5811e-01, time/batch = 0.6701s	
23607/33150 (epoch 35.606), train_loss = 0.81519666, grad/param norm = 2.2695e-01, time/batch = 0.6744s	
23608/33150 (epoch 35.608), train_loss = 0.94073083, grad/param norm = 1.5244e-01, time/batch = 0.6724s	
23609/33150 (epoch 35.609), train_loss = 0.86442242, grad/param norm = 1.9940e-01, time/batch = 0.6720s	
23610/33150 (epoch 35.611), train_loss = 0.77372621, grad/param norm = 1.7277e-01, time/batch = 0.6690s	
23611/33150 (epoch 35.612), train_loss = 0.83308542, grad/param norm = 1.7576e-01, time/batch = 0.6698s	
23612/33150 (epoch 35.614), train_loss = 0.78614003, grad/param norm = 1.5483e-01, time/batch = 0.6703s	
23613/33150 (epoch 35.615), train_loss = 0.75448069, grad/param norm = 1.7904e-01, time/batch = 0.6719s	
23614/33150 (epoch 35.617), train_loss = 0.88226941, grad/param norm = 1.9177e-01, time/batch = 0.6677s	
23615/33150 (epoch 35.618), train_loss = 0.90523289, grad/param norm = 1.9186e-01, time/batch = 0.6667s	
23616/33150 (epoch 35.620), train_loss = 0.83736085, grad/param norm = 1.7290e-01, time/batch = 0.6695s	
23617/33150 (epoch 35.621), train_loss = 0.87357901, grad/param norm = 1.6368e-01, time/batch = 0.6729s	
23618/33150 (epoch 35.623), train_loss = 0.92096084, grad/param norm = 1.6699e-01, time/batch = 0.6787s	
23619/33150 (epoch 35.624), train_loss = 0.82530946, grad/param norm = 1.6977e-01, time/batch = 0.6810s	
23620/33150 (epoch 35.626), train_loss = 0.85174368, grad/param norm = 1.6107e-01, time/batch = 0.6871s	
23621/33150 (epoch 35.627), train_loss = 0.80402366, grad/param norm = 1.7773e-01, time/batch = 0.6841s	
23622/33150 (epoch 35.629), train_loss = 0.73855479, grad/param norm = 1.7428e-01, time/batch = 0.6776s	
23623/33150 (epoch 35.630), train_loss = 0.84688431, grad/param norm = 1.5891e-01, time/batch = 0.6823s	
23624/33150 (epoch 35.632), train_loss = 0.73565689, grad/param norm = 1.5727e-01, time/batch = 0.6736s	
23625/33150 (epoch 35.633), train_loss = 0.77017432, grad/param norm = 1.6181e-01, time/batch = 0.6784s	
23626/33150 (epoch 35.635), train_loss = 0.99574985, grad/param norm = 1.7133e-01, time/batch = 0.6730s	
23627/33150 (epoch 35.637), train_loss = 0.70272509, grad/param norm = 1.7817e-01, time/batch = 0.6683s	
23628/33150 (epoch 35.638), train_loss = 0.84346268, grad/param norm = 1.7355e-01, time/batch = 0.6723s	
23629/33150 (epoch 35.640), train_loss = 0.93423289, grad/param norm = 1.8490e-01, time/batch = 0.6705s	
23630/33150 (epoch 35.641), train_loss = 0.71861703, grad/param norm = 1.5893e-01, time/batch = 0.6702s	
23631/33150 (epoch 35.643), train_loss = 0.87377303, grad/param norm = 1.6579e-01, time/batch = 0.6715s	
23632/33150 (epoch 35.644), train_loss = 0.99477333, grad/param norm = 1.5853e-01, time/batch = 0.6673s	
23633/33150 (epoch 35.646), train_loss = 0.83506324, grad/param norm = 1.5708e-01, time/batch = 0.6669s	
23634/33150 (epoch 35.647), train_loss = 1.03490796, grad/param norm = 1.8584e-01, time/batch = 0.6772s	
23635/33150 (epoch 35.649), train_loss = 0.89882208, grad/param norm = 1.8800e-01, time/batch = 0.6706s	
23636/33150 (epoch 35.650), train_loss = 0.76257226, grad/param norm = 1.6159e-01, time/batch = 0.6674s	
23637/33150 (epoch 35.652), train_loss = 0.95709468, grad/param norm = 1.8966e-01, time/batch = 0.6703s	
23638/33150 (epoch 35.653), train_loss = 0.89902096, grad/param norm = 1.5825e-01, time/batch = 0.6694s	
23639/33150 (epoch 35.655), train_loss = 0.88241754, grad/param norm = 2.0830e-01, time/batch = 0.6676s	
23640/33150 (epoch 35.656), train_loss = 0.82410148, grad/param norm = 1.6722e-01, time/batch = 0.6689s	
23641/33150 (epoch 35.658), train_loss = 0.81980353, grad/param norm = 1.6620e-01, time/batch = 0.6910s	
23642/33150 (epoch 35.659), train_loss = 1.11797913, grad/param norm = 3.0961e-01, time/batch = 0.6891s	
23643/33150 (epoch 35.661), train_loss = 0.85896136, grad/param norm = 1.8691e-01, time/batch = 0.6809s	
23644/33150 (epoch 35.662), train_loss = 0.84695838, grad/param norm = 1.8420e-01, time/batch = 0.6803s	
23645/33150 (epoch 35.664), train_loss = 0.97696678, grad/param norm = 1.9561e-01, time/batch = 0.6656s	
23646/33150 (epoch 35.665), train_loss = 0.94240958, grad/param norm = 1.9882e-01, time/batch = 0.6694s	
23647/33150 (epoch 35.667), train_loss = 0.95566674, grad/param norm = 1.9359e-01, time/batch = 0.6829s	
23648/33150 (epoch 35.668), train_loss = 1.01458521, grad/param norm = 1.8665e-01, time/batch = 0.6928s	
23649/33150 (epoch 35.670), train_loss = 0.79929792, grad/param norm = 1.4154e-01, time/batch = 0.6709s	
23650/33150 (epoch 35.671), train_loss = 0.78644133, grad/param norm = 1.7154e-01, time/batch = 0.6685s	
23651/33150 (epoch 35.673), train_loss = 0.98726463, grad/param norm = 1.6177e-01, time/batch = 0.6684s	
23652/33150 (epoch 35.674), train_loss = 0.91169732, grad/param norm = 1.8644e-01, time/batch = 0.6701s	
23653/33150 (epoch 35.676), train_loss = 0.86521450, grad/param norm = 1.7212e-01, time/batch = 0.6682s	
23654/33150 (epoch 35.677), train_loss = 1.00606151, grad/param norm = 1.9813e-01, time/batch = 0.6714s	
23655/33150 (epoch 35.679), train_loss = 0.86686314, grad/param norm = 1.5810e-01, time/batch = 0.6707s	
23656/33150 (epoch 35.680), train_loss = 0.97999687, grad/param norm = 1.8961e-01, time/batch = 0.6680s	
23657/33150 (epoch 35.682), train_loss = 0.87115140, grad/param norm = 1.7219e-01, time/batch = 0.6665s	
23658/33150 (epoch 35.683), train_loss = 0.74281433, grad/param norm = 1.5351e-01, time/batch = 0.6701s	
23659/33150 (epoch 35.685), train_loss = 0.82810652, grad/param norm = 1.9064e-01, time/batch = 0.6691s	
23660/33150 (epoch 35.686), train_loss = 0.74168115, grad/param norm = 1.6479e-01, time/batch = 0.6714s	
23661/33150 (epoch 35.688), train_loss = 0.76194977, grad/param norm = 1.6637e-01, time/batch = 0.6712s	
23662/33150 (epoch 35.689), train_loss = 0.80423542, grad/param norm = 1.6619e-01, time/batch = 0.6801s	
23663/33150 (epoch 35.691), train_loss = 0.69441463, grad/param norm = 1.6274e-01, time/batch = 0.6834s	
23664/33150 (epoch 35.692), train_loss = 0.79878931, grad/param norm = 1.7688e-01, time/batch = 0.6840s	
23665/33150 (epoch 35.694), train_loss = 0.69476355, grad/param norm = 1.6671e-01, time/batch = 0.6685s	
23666/33150 (epoch 35.695), train_loss = 0.81344428, grad/param norm = 1.5235e-01, time/batch = 0.6663s	
23667/33150 (epoch 35.697), train_loss = 0.75242338, grad/param norm = 1.4553e-01, time/batch = 0.6709s	
23668/33150 (epoch 35.698), train_loss = 0.78291325, grad/param norm = 1.7894e-01, time/batch = 0.6711s	
23669/33150 (epoch 35.700), train_loss = 0.65653607, grad/param norm = 1.3262e-01, time/batch = 0.6677s	
23670/33150 (epoch 35.701), train_loss = 0.74019141, grad/param norm = 1.4147e-01, time/batch = 0.6680s	
23671/33150 (epoch 35.703), train_loss = 0.84850003, grad/param norm = 1.7502e-01, time/batch = 0.6729s	
23672/33150 (epoch 35.704), train_loss = 0.75097330, grad/param norm = 1.4826e-01, time/batch = 0.6720s	
23673/33150 (epoch 35.706), train_loss = 0.81170843, grad/param norm = 1.7085e-01, time/batch = 0.6834s	
23674/33150 (epoch 35.707), train_loss = 0.83871595, grad/param norm = 1.7545e-01, time/batch = 0.6857s	
23675/33150 (epoch 35.709), train_loss = 0.86341868, grad/param norm = 1.5160e-01, time/batch = 0.6855s	
23676/33150 (epoch 35.710), train_loss = 0.85761849, grad/param norm = 1.9251e-01, time/batch = 0.6692s	
23677/33150 (epoch 35.712), train_loss = 0.91080738, grad/param norm = 1.4796e-01, time/batch = 0.6815s	
23678/33150 (epoch 35.713), train_loss = 0.87948097, grad/param norm = 1.5702e-01, time/batch = 0.6697s	
23679/33150 (epoch 35.715), train_loss = 0.82117510, grad/param norm = 1.5343e-01, time/batch = 0.6699s	
23680/33150 (epoch 35.716), train_loss = 0.89385023, grad/param norm = 1.6572e-01, time/batch = 0.6691s	
23681/33150 (epoch 35.718), train_loss = 0.87335872, grad/param norm = 1.6713e-01, time/batch = 0.6722s	
23682/33150 (epoch 35.719), train_loss = 0.93660452, grad/param norm = 2.0659e-01, time/batch = 0.6731s	
23683/33150 (epoch 35.721), train_loss = 0.83935130, grad/param norm = 2.0004e-01, time/batch = 0.6698s	
23684/33150 (epoch 35.722), train_loss = 0.88774557, grad/param norm = 1.6665e-01, time/batch = 0.6709s	
23685/33150 (epoch 35.724), train_loss = 0.82760464, grad/param norm = 1.7825e-01, time/batch = 0.6702s	
23686/33150 (epoch 35.725), train_loss = 0.92006593, grad/param norm = 2.1142e-01, time/batch = 0.6706s	
23687/33150 (epoch 35.727), train_loss = 0.91118555, grad/param norm = 1.8072e-01, time/batch = 0.6720s	
23688/33150 (epoch 35.729), train_loss = 0.86702866, grad/param norm = 1.8169e-01, time/batch = 0.6734s	
23689/33150 (epoch 35.730), train_loss = 0.85539081, grad/param norm = 1.6571e-01, time/batch = 0.6725s	
23690/33150 (epoch 35.732), train_loss = 0.91123035, grad/param norm = 1.8598e-01, time/batch = 0.6740s	
23691/33150 (epoch 35.733), train_loss = 0.74843653, grad/param norm = 1.4318e-01, time/batch = 0.6729s	
23692/33150 (epoch 35.735), train_loss = 0.78734187, grad/param norm = 1.6300e-01, time/batch = 0.6710s	
23693/33150 (epoch 35.736), train_loss = 0.81843868, grad/param norm = 1.5904e-01, time/batch = 0.6728s	
23694/33150 (epoch 35.738), train_loss = 0.86539241, grad/param norm = 2.0263e-01, time/batch = 0.6764s	
23695/33150 (epoch 35.739), train_loss = 0.96390842, grad/param norm = 1.8993e-01, time/batch = 0.6752s	
23696/33150 (epoch 35.741), train_loss = 0.89103213, grad/param norm = 1.8941e-01, time/batch = 0.6811s	
23697/33150 (epoch 35.742), train_loss = 0.73320342, grad/param norm = 1.5712e-01, time/batch = 0.6769s	
23698/33150 (epoch 35.744), train_loss = 0.91762479, grad/param norm = 1.7180e-01, time/batch = 0.6774s	
23699/33150 (epoch 35.745), train_loss = 0.81434369, grad/param norm = 1.4660e-01, time/batch = 0.6711s	
23700/33150 (epoch 35.747), train_loss = 0.64413208, grad/param norm = 1.6005e-01, time/batch = 0.6728s	
23701/33150 (epoch 35.748), train_loss = 0.72937822, grad/param norm = 1.6242e-01, time/batch = 0.6745s	
23702/33150 (epoch 35.750), train_loss = 0.88836171, grad/param norm = 1.7770e-01, time/batch = 0.6737s	
23703/33150 (epoch 35.751), train_loss = 0.84427319, grad/param norm = 1.5017e-01, time/batch = 0.6714s	
23704/33150 (epoch 35.753), train_loss = 0.73598455, grad/param norm = 1.7761e-01, time/batch = 0.6724s	
23705/33150 (epoch 35.754), train_loss = 1.03911428, grad/param norm = 2.2250e-01, time/batch = 0.6718s	
23706/33150 (epoch 35.756), train_loss = 0.85022487, grad/param norm = 2.2917e-01, time/batch = 0.6709s	
23707/33150 (epoch 35.757), train_loss = 0.88765412, grad/param norm = 1.7581e-01, time/batch = 0.6817s	
23708/33150 (epoch 35.759), train_loss = 0.98570776, grad/param norm = 2.0448e-01, time/batch = 0.6812s	
23709/33150 (epoch 35.760), train_loss = 0.88555880, grad/param norm = 1.7587e-01, time/batch = 0.6774s	
23710/33150 (epoch 35.762), train_loss = 0.87139539, grad/param norm = 1.8963e-01, time/batch = 0.6671s	
23711/33150 (epoch 35.763), train_loss = 0.88559955, grad/param norm = 1.6128e-01, time/batch = 0.6699s	
23712/33150 (epoch 35.765), train_loss = 0.84889106, grad/param norm = 1.6438e-01, time/batch = 0.6698s	
23713/33150 (epoch 35.766), train_loss = 0.74661224, grad/param norm = 1.8477e-01, time/batch = 0.6709s	
23714/33150 (epoch 35.768), train_loss = 0.78869885, grad/param norm = 1.5742e-01, time/batch = 0.6746s	
23715/33150 (epoch 35.769), train_loss = 0.92128525, grad/param norm = 1.9296e-01, time/batch = 0.6761s	
23716/33150 (epoch 35.771), train_loss = 0.87150676, grad/param norm = 1.8453e-01, time/batch = 0.6769s	
23717/33150 (epoch 35.772), train_loss = 0.92018251, grad/param norm = 2.0574e-01, time/batch = 0.6755s	
23718/33150 (epoch 35.774), train_loss = 1.00692622, grad/param norm = 1.7477e-01, time/batch = 0.6729s	
23719/33150 (epoch 35.775), train_loss = 0.92352592, grad/param norm = 2.7101e-01, time/batch = 0.6737s	
23720/33150 (epoch 35.777), train_loss = 0.91306840, grad/param norm = 1.7418e-01, time/batch = 0.6743s	
23721/33150 (epoch 35.778), train_loss = 0.85497504, grad/param norm = 1.5086e-01, time/batch = 0.6858s	
23722/33150 (epoch 35.780), train_loss = 0.73511173, grad/param norm = 1.4895e-01, time/batch = 0.6827s	
23723/33150 (epoch 35.781), train_loss = 0.87168498, grad/param norm = 1.8034e-01, time/batch = 0.6849s	
23724/33150 (epoch 35.783), train_loss = 0.86280487, grad/param norm = 1.6143e-01, time/batch = 0.6906s	
23725/33150 (epoch 35.784), train_loss = 0.85086210, grad/param norm = 1.8493e-01, time/batch = 0.6833s	
23726/33150 (epoch 35.786), train_loss = 0.84248579, grad/param norm = 1.5838e-01, time/batch = 0.6835s	
23727/33150 (epoch 35.787), train_loss = 0.77803347, grad/param norm = 1.4304e-01, time/batch = 0.6795s	
23728/33150 (epoch 35.789), train_loss = 0.73313083, grad/param norm = 1.5066e-01, time/batch = 0.6814s	
23729/33150 (epoch 35.790), train_loss = 0.73437744, grad/param norm = 1.5371e-01, time/batch = 0.6873s	
23730/33150 (epoch 35.792), train_loss = 0.86715167, grad/param norm = 2.0660e-01, time/batch = 0.6895s	
23731/33150 (epoch 35.793), train_loss = 0.83814865, grad/param norm = 2.2086e-01, time/batch = 0.6922s	
23732/33150 (epoch 35.795), train_loss = 0.80973463, grad/param norm = 1.8901e-01, time/batch = 0.6718s	
23733/33150 (epoch 35.796), train_loss = 0.81654613, grad/param norm = 1.4986e-01, time/batch = 0.6772s	
23734/33150 (epoch 35.798), train_loss = 0.79393772, grad/param norm = 1.3820e-01, time/batch = 0.6844s	
23735/33150 (epoch 35.799), train_loss = 0.71758013, grad/param norm = 1.7757e-01, time/batch = 0.6846s	
23736/33150 (epoch 35.801), train_loss = 0.87012716, grad/param norm = 1.7148e-01, time/batch = 0.6832s	
23737/33150 (epoch 35.802), train_loss = 0.79637028, grad/param norm = 1.6138e-01, time/batch = 0.6817s	
23738/33150 (epoch 35.804), train_loss = 0.82995556, grad/param norm = 1.6551e-01, time/batch = 0.6858s	
23739/33150 (epoch 35.805), train_loss = 0.80446969, grad/param norm = 1.8230e-01, time/batch = 0.6729s	
23740/33150 (epoch 35.807), train_loss = 0.82906740, grad/param norm = 1.5309e-01, time/batch = 0.6700s	
23741/33150 (epoch 35.808), train_loss = 0.95535887, grad/param norm = 1.7528e-01, time/batch = 0.6795s	
23742/33150 (epoch 35.810), train_loss = 0.78718098, grad/param norm = 1.8010e-01, time/batch = 0.6708s	
23743/33150 (epoch 35.811), train_loss = 0.88333386, grad/param norm = 2.1906e-01, time/batch = 0.6711s	
23744/33150 (epoch 35.813), train_loss = 0.82222347, grad/param norm = 1.7899e-01, time/batch = 0.6702s	
23745/33150 (epoch 35.814), train_loss = 0.78993870, grad/param norm = 1.7629e-01, time/batch = 0.6699s	
23746/33150 (epoch 35.816), train_loss = 0.82455002, grad/param norm = 1.8183e-01, time/batch = 0.6713s	
23747/33150 (epoch 35.817), train_loss = 0.89600615, grad/param norm = 1.7854e-01, time/batch = 0.6697s	
23748/33150 (epoch 35.819), train_loss = 0.87146841, grad/param norm = 1.6941e-01, time/batch = 0.6701s	
23749/33150 (epoch 35.821), train_loss = 0.74936506, grad/param norm = 1.4322e-01, time/batch = 0.6739s	
23750/33150 (epoch 35.822), train_loss = 0.78702532, grad/param norm = 1.5863e-01, time/batch = 0.6758s	
23751/33150 (epoch 35.824), train_loss = 0.86105753, grad/param norm = 1.8948e-01, time/batch = 0.6705s	
23752/33150 (epoch 35.825), train_loss = 0.88913804, grad/param norm = 1.8658e-01, time/batch = 0.6714s	
23753/33150 (epoch 35.827), train_loss = 0.89615344, grad/param norm = 1.8773e-01, time/batch = 0.6691s	
23754/33150 (epoch 35.828), train_loss = 0.76358883, grad/param norm = 1.7853e-01, time/batch = 0.6683s	
23755/33150 (epoch 35.830), train_loss = 0.90920527, grad/param norm = 1.8919e-01, time/batch = 0.6785s	
23756/33150 (epoch 35.831), train_loss = 0.79007554, grad/param norm = 1.6513e-01, time/batch = 0.6795s	
23757/33150 (epoch 35.833), train_loss = 0.76459794, grad/param norm = 1.4926e-01, time/batch = 0.6702s	
23758/33150 (epoch 35.834), train_loss = 0.92725852, grad/param norm = 1.6111e-01, time/batch = 0.6712s	
23759/33150 (epoch 35.836), train_loss = 0.95917333, grad/param norm = 1.5512e-01, time/batch = 0.6726s	
23760/33150 (epoch 35.837), train_loss = 0.80124790, grad/param norm = 2.1474e-01, time/batch = 0.6698s	
23761/33150 (epoch 35.839), train_loss = 0.93076090, grad/param norm = 2.0078e-01, time/batch = 0.6763s	
23762/33150 (epoch 35.840), train_loss = 0.91611870, grad/param norm = 1.7664e-01, time/batch = 0.6713s	
23763/33150 (epoch 35.842), train_loss = 0.94427925, grad/param norm = 2.1363e-01, time/batch = 0.6696s	
23764/33150 (epoch 35.843), train_loss = 0.94405681, grad/param norm = 1.9672e-01, time/batch = 0.6728s	
23765/33150 (epoch 35.845), train_loss = 0.79651230, grad/param norm = 1.7182e-01, time/batch = 0.6704s	
23766/33150 (epoch 35.846), train_loss = 1.05645311, grad/param norm = 2.7665e-01, time/batch = 0.6794s	
23767/33150 (epoch 35.848), train_loss = 0.92397062, grad/param norm = 1.9197e-01, time/batch = 0.6717s	
23768/33150 (epoch 35.849), train_loss = 0.96087939, grad/param norm = 1.7471e-01, time/batch = 0.6726s	
23769/33150 (epoch 35.851), train_loss = 0.90923385, grad/param norm = 2.0717e-01, time/batch = 0.6718s	
23770/33150 (epoch 35.852), train_loss = 0.99621464, grad/param norm = 1.8252e-01, time/batch = 0.6707s	
23771/33150 (epoch 35.854), train_loss = 0.89956813, grad/param norm = 1.8943e-01, time/batch = 0.6829s	
23772/33150 (epoch 35.855), train_loss = 0.76032918, grad/param norm = 1.6900e-01, time/batch = 0.6734s	
23773/33150 (epoch 35.857), train_loss = 0.72310740, grad/param norm = 1.8214e-01, time/batch = 0.6674s	
23774/33150 (epoch 35.858), train_loss = 0.83033891, grad/param norm = 1.6792e-01, time/batch = 0.6702s	
23775/33150 (epoch 35.860), train_loss = 0.79118936, grad/param norm = 1.6937e-01, time/batch = 0.6688s	
23776/33150 (epoch 35.861), train_loss = 0.76513820, grad/param norm = 1.4725e-01, time/batch = 0.6694s	
23777/33150 (epoch 35.863), train_loss = 0.83369042, grad/param norm = 1.6214e-01, time/batch = 0.6693s	
23778/33150 (epoch 35.864), train_loss = 0.87653315, grad/param norm = 1.6676e-01, time/batch = 0.6669s	
23779/33150 (epoch 35.866), train_loss = 0.91882101, grad/param norm = 1.6905e-01, time/batch = 0.6685s	
23780/33150 (epoch 35.867), train_loss = 0.86449118, grad/param norm = 1.5568e-01, time/batch = 0.6692s	
23781/33150 (epoch 35.869), train_loss = 0.84913418, grad/param norm = 1.7305e-01, time/batch = 0.6676s	
23782/33150 (epoch 35.870), train_loss = 0.81389533, grad/param norm = 1.9023e-01, time/batch = 0.6715s	
23783/33150 (epoch 35.872), train_loss = 0.88900140, grad/param norm = 1.7615e-01, time/batch = 0.6743s	
23784/33150 (epoch 35.873), train_loss = 0.69926849, grad/param norm = 1.4911e-01, time/batch = 0.6701s	
23785/33150 (epoch 35.875), train_loss = 0.94130994, grad/param norm = 1.6840e-01, time/batch = 0.6797s	
23786/33150 (epoch 35.876), train_loss = 0.70098203, grad/param norm = 1.4675e-01, time/batch = 0.6802s	
23787/33150 (epoch 35.878), train_loss = 0.80087136, grad/param norm = 1.5183e-01, time/batch = 0.6739s	
23788/33150 (epoch 35.879), train_loss = 0.78878974, grad/param norm = 1.4498e-01, time/batch = 0.6742s	
23789/33150 (epoch 35.881), train_loss = 0.78481745, grad/param norm = 1.6356e-01, time/batch = 0.6696s	
23790/33150 (epoch 35.882), train_loss = 0.67418425, grad/param norm = 1.5589e-01, time/batch = 0.6695s	
23791/33150 (epoch 35.884), train_loss = 0.80938891, grad/param norm = 1.5901e-01, time/batch = 0.6710s	
23792/33150 (epoch 35.885), train_loss = 0.63740404, grad/param norm = 1.6509e-01, time/batch = 0.6689s	
23793/33150 (epoch 35.887), train_loss = 0.94042424, grad/param norm = 1.8551e-01, time/batch = 0.6726s	
23794/33150 (epoch 35.888), train_loss = 0.86946152, grad/param norm = 1.8896e-01, time/batch = 0.6739s	
23795/33150 (epoch 35.890), train_loss = 0.78484004, grad/param norm = 1.8352e-01, time/batch = 0.6741s	
23796/33150 (epoch 35.891), train_loss = 0.74311417, grad/param norm = 1.5311e-01, time/batch = 0.6699s	
23797/33150 (epoch 35.893), train_loss = 0.89425305, grad/param norm = 1.7562e-01, time/batch = 0.6708s	
23798/33150 (epoch 35.894), train_loss = 0.88937598, grad/param norm = 1.5825e-01, time/batch = 0.6703s	
23799/33150 (epoch 35.896), train_loss = 0.84353809, grad/param norm = 1.7891e-01, time/batch = 0.6708s	
23800/33150 (epoch 35.897), train_loss = 0.88918212, grad/param norm = 1.7830e-01, time/batch = 0.6817s	
23801/33150 (epoch 35.899), train_loss = 0.72855401, grad/param norm = 1.7894e-01, time/batch = 0.6814s	
23802/33150 (epoch 35.900), train_loss = 1.02363091, grad/param norm = 2.0687e-01, time/batch = 0.6714s	
23803/33150 (epoch 35.902), train_loss = 1.05402906, grad/param norm = 1.7692e-01, time/batch = 0.6709s	
23804/33150 (epoch 35.903), train_loss = 0.85935701, grad/param norm = 1.6767e-01, time/batch = 0.6702s	
23805/33150 (epoch 35.905), train_loss = 0.85161993, grad/param norm = 1.7315e-01, time/batch = 0.6751s	
23806/33150 (epoch 35.906), train_loss = 0.86242712, grad/param norm = 1.8788e-01, time/batch = 0.6705s	
23807/33150 (epoch 35.908), train_loss = 0.93419327, grad/param norm = 2.0610e-01, time/batch = 0.6710s	
23808/33150 (epoch 35.910), train_loss = 0.93356949, grad/param norm = 1.8077e-01, time/batch = 0.6693s	
23809/33150 (epoch 35.911), train_loss = 0.72805479, grad/param norm = 1.4278e-01, time/batch = 0.6700s	
23810/33150 (epoch 35.913), train_loss = 0.79751784, grad/param norm = 1.9207e-01, time/batch = 0.6738s	
23811/33150 (epoch 35.914), train_loss = 0.86793308, grad/param norm = 2.1858e-01, time/batch = 0.6869s	
23812/33150 (epoch 35.916), train_loss = 0.79835137, grad/param norm = 1.9011e-01, time/batch = 0.6728s	
23813/33150 (epoch 35.917), train_loss = 0.89720283, grad/param norm = 1.9878e-01, time/batch = 0.6684s	
23814/33150 (epoch 35.919), train_loss = 0.99960679, grad/param norm = 2.1874e-01, time/batch = 0.6718s	
23815/33150 (epoch 35.920), train_loss = 0.95335428, grad/param norm = 1.9582e-01, time/batch = 0.6818s	
23816/33150 (epoch 35.922), train_loss = 0.99471753, grad/param norm = 1.9834e-01, time/batch = 0.6732s	
23817/33150 (epoch 35.923), train_loss = 0.87374023, grad/param norm = 1.9559e-01, time/batch = 0.6673s	
23818/33150 (epoch 35.925), train_loss = 0.96028482, grad/param norm = 1.7539e-01, time/batch = 0.6872s	
23819/33150 (epoch 35.926), train_loss = 0.84052819, grad/param norm = 1.9023e-01, time/batch = 0.6851s	
23820/33150 (epoch 35.928), train_loss = 0.83632521, grad/param norm = 1.8301e-01, time/batch = 0.6827s	
23821/33150 (epoch 35.929), train_loss = 0.92605416, grad/param norm = 1.7127e-01, time/batch = 0.6744s	
23822/33150 (epoch 35.931), train_loss = 0.98127205, grad/param norm = 2.2083e-01, time/batch = 0.6704s	
23823/33150 (epoch 35.932), train_loss = 0.88497122, grad/param norm = 2.3971e-01, time/batch = 0.6714s	
23824/33150 (epoch 35.934), train_loss = 0.88226798, grad/param norm = 1.6504e-01, time/batch = 0.6683s	
23825/33150 (epoch 35.935), train_loss = 0.95740086, grad/param norm = 1.8999e-01, time/batch = 0.6697s	
23826/33150 (epoch 35.937), train_loss = 0.98213563, grad/param norm = 1.9497e-01, time/batch = 0.6857s	
23827/33150 (epoch 35.938), train_loss = 0.90623962, grad/param norm = 1.7154e-01, time/batch = 0.6890s	
23828/33150 (epoch 35.940), train_loss = 1.10109962, grad/param norm = 2.1926e-01, time/batch = 0.6759s	
23829/33150 (epoch 35.941), train_loss = 0.90462036, grad/param norm = 1.6118e-01, time/batch = 0.6771s	
23830/33150 (epoch 35.943), train_loss = 0.70902917, grad/param norm = 1.6054e-01, time/batch = 0.6817s	
23831/33150 (epoch 35.944), train_loss = 0.91288952, grad/param norm = 1.9049e-01, time/batch = 0.6757s	
23832/33150 (epoch 35.946), train_loss = 0.74804704, grad/param norm = 1.4025e-01, time/batch = 0.6730s	
23833/33150 (epoch 35.947), train_loss = 0.88601523, grad/param norm = 1.6671e-01, time/batch = 0.6711s	
23834/33150 (epoch 35.949), train_loss = 0.96626492, grad/param norm = 2.2408e-01, time/batch = 0.6883s	
23835/33150 (epoch 35.950), train_loss = 0.93124428, grad/param norm = 2.0075e-01, time/batch = 0.6764s	
23836/33150 (epoch 35.952), train_loss = 0.79054567, grad/param norm = 1.6287e-01, time/batch = 0.6689s	
23837/33150 (epoch 35.953), train_loss = 0.85664718, grad/param norm = 1.5940e-01, time/batch = 0.6708s	
23838/33150 (epoch 35.955), train_loss = 0.76617042, grad/param norm = 1.9374e-01, time/batch = 0.6827s	
23839/33150 (epoch 35.956), train_loss = 0.93156647, grad/param norm = 1.9578e-01, time/batch = 0.6759s	
23840/33150 (epoch 35.958), train_loss = 0.77701088, grad/param norm = 1.6298e-01, time/batch = 0.6761s	
23841/33150 (epoch 35.959), train_loss = 0.84163470, grad/param norm = 1.6212e-01, time/batch = 0.6708s	
23842/33150 (epoch 35.961), train_loss = 0.78672045, grad/param norm = 1.7597e-01, time/batch = 0.6722s	
23843/33150 (epoch 35.962), train_loss = 0.73501135, grad/param norm = 1.4900e-01, time/batch = 0.6727s	
23844/33150 (epoch 35.964), train_loss = 0.84572099, grad/param norm = 1.7242e-01, time/batch = 0.6793s	
23845/33150 (epoch 35.965), train_loss = 0.83536504, grad/param norm = 1.6406e-01, time/batch = 0.6808s	
23846/33150 (epoch 35.967), train_loss = 0.83378855, grad/param norm = 1.7419e-01, time/batch = 0.6756s	
23847/33150 (epoch 35.968), train_loss = 0.71033686, grad/param norm = 1.5181e-01, time/batch = 0.6738s	
23848/33150 (epoch 35.970), train_loss = 0.80608511, grad/param norm = 1.6391e-01, time/batch = 0.6736s	
23849/33150 (epoch 35.971), train_loss = 0.84922435, grad/param norm = 1.6634e-01, time/batch = 0.6712s	
23850/33150 (epoch 35.973), train_loss = 0.95277217, grad/param norm = 2.0026e-01, time/batch = 0.6718s	
23851/33150 (epoch 35.974), train_loss = 0.97583971, grad/param norm = 1.7442e-01, time/batch = 0.6700s	
23852/33150 (epoch 35.976), train_loss = 0.94972981, grad/param norm = 1.7066e-01, time/batch = 0.6681s	
23853/33150 (epoch 35.977), train_loss = 0.98250029, grad/param norm = 2.0281e-01, time/batch = 0.6680s	
23854/33150 (epoch 35.979), train_loss = 0.94318671, grad/param norm = 1.9830e-01, time/batch = 0.6707s	
23855/33150 (epoch 35.980), train_loss = 1.00648648, grad/param norm = 1.9125e-01, time/batch = 0.6694s	
23856/33150 (epoch 35.982), train_loss = 0.85225443, grad/param norm = 1.7827e-01, time/batch = 0.6708s	
23857/33150 (epoch 35.983), train_loss = 0.77388224, grad/param norm = 1.6278e-01, time/batch = 0.6673s	
23858/33150 (epoch 35.985), train_loss = 0.95930543, grad/param norm = 1.6058e-01, time/batch = 0.6708s	
23859/33150 (epoch 35.986), train_loss = 0.72702971, grad/param norm = 1.7335e-01, time/batch = 0.6823s	
23860/33150 (epoch 35.988), train_loss = 0.83565311, grad/param norm = 2.1796e-01, time/batch = 0.6857s	
23861/33150 (epoch 35.989), train_loss = 0.86507897, grad/param norm = 2.1546e-01, time/batch = 0.6915s	
23862/33150 (epoch 35.991), train_loss = 0.91689095, grad/param norm = 2.2901e-01, time/batch = 0.6909s	
23863/33150 (epoch 35.992), train_loss = 0.85052122, grad/param norm = 1.8046e-01, time/batch = 0.6923s	
23864/33150 (epoch 35.994), train_loss = 0.87971090, grad/param norm = 1.6839e-01, time/batch = 0.6958s	
23865/33150 (epoch 35.995), train_loss = 0.84693721, grad/param norm = 2.0570e-01, time/batch = 0.6902s	
23866/33150 (epoch 35.997), train_loss = 0.86993454, grad/param norm = 1.9041e-01, time/batch = 0.6901s	
23867/33150 (epoch 35.998), train_loss = 0.74229418, grad/param norm = 1.8163e-01, time/batch = 0.6898s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
23868/33150 (epoch 36.000), train_loss = 0.73805624, grad/param norm = 1.7830e-01, time/batch = 0.6872s	
23869/33150 (epoch 36.002), train_loss = 1.15074818, grad/param norm = 1.7932e-01, time/batch = 0.6748s	
23870/33150 (epoch 36.003), train_loss = 0.77370903, grad/param norm = 1.8639e-01, time/batch = 0.6701s	
23871/33150 (epoch 36.005), train_loss = 0.72891843, grad/param norm = 1.5224e-01, time/batch = 0.6726s	
23872/33150 (epoch 36.006), train_loss = 0.71550986, grad/param norm = 1.6594e-01, time/batch = 0.6711s	
23873/33150 (epoch 36.008), train_loss = 0.90297046, grad/param norm = 1.7645e-01, time/batch = 0.6748s	
23874/33150 (epoch 36.009), train_loss = 0.88212254, grad/param norm = 1.6146e-01, time/batch = 0.6819s	
23875/33150 (epoch 36.011), train_loss = 0.94164257, grad/param norm = 1.7427e-01, time/batch = 0.6723s	
23876/33150 (epoch 36.012), train_loss = 0.85332625, grad/param norm = 2.3688e-01, time/batch = 0.6684s	
23877/33150 (epoch 36.014), train_loss = 0.78285204, grad/param norm = 1.8217e-01, time/batch = 0.6657s	
23878/33150 (epoch 36.015), train_loss = 0.77182143, grad/param norm = 1.6905e-01, time/batch = 0.6697s	
23879/33150 (epoch 36.017), train_loss = 0.78426200, grad/param norm = 1.6296e-01, time/batch = 0.6710s	
23880/33150 (epoch 36.018), train_loss = 0.86612003, grad/param norm = 2.0097e-01, time/batch = 0.6685s	
23881/33150 (epoch 36.020), train_loss = 0.93720209, grad/param norm = 2.0461e-01, time/batch = 0.6695s	
23882/33150 (epoch 36.021), train_loss = 0.76198295, grad/param norm = 1.6295e-01, time/batch = 0.6706s	
23883/33150 (epoch 36.023), train_loss = 1.02401245, grad/param norm = 1.6342e-01, time/batch = 0.6713s	
23884/33150 (epoch 36.024), train_loss = 0.90586529, grad/param norm = 2.2948e-01, time/batch = 0.6706s	
23885/33150 (epoch 36.026), train_loss = 0.67665763, grad/param norm = 1.3987e-01, time/batch = 0.6729s	
23886/33150 (epoch 36.027), train_loss = 0.68286748, grad/param norm = 1.4073e-01, time/batch = 0.6707s	
23887/33150 (epoch 36.029), train_loss = 0.80164205, grad/param norm = 1.7729e-01, time/batch = 0.6727s	
23888/33150 (epoch 36.030), train_loss = 0.82699159, grad/param norm = 1.5059e-01, time/batch = 0.6759s	
23889/33150 (epoch 36.032), train_loss = 0.75413276, grad/param norm = 1.7788e-01, time/batch = 0.6806s	
23890/33150 (epoch 36.033), train_loss = 0.78226127, grad/param norm = 1.5724e-01, time/batch = 0.6724s	
23891/33150 (epoch 36.035), train_loss = 1.02862155, grad/param norm = 1.9669e-01, time/batch = 0.6725s	
23892/33150 (epoch 36.036), train_loss = 0.91123346, grad/param norm = 1.7390e-01, time/batch = 0.6875s	
23893/33150 (epoch 36.038), train_loss = 1.02959901, grad/param norm = 1.8981e-01, time/batch = 0.6903s	
23894/33150 (epoch 36.039), train_loss = 0.93129875, grad/param norm = 1.6365e-01, time/batch = 0.6862s	
23895/33150 (epoch 36.041), train_loss = 0.84998152, grad/param norm = 1.6069e-01, time/batch = 0.6805s	
23896/33150 (epoch 36.042), train_loss = 0.80223311, grad/param norm = 1.8243e-01, time/batch = 0.6931s	
23897/33150 (epoch 36.044), train_loss = 0.83974895, grad/param norm = 1.7361e-01, time/batch = 0.6758s	
23898/33150 (epoch 36.045), train_loss = 0.90985413, grad/param norm = 1.4729e-01, time/batch = 0.6656s	
23899/33150 (epoch 36.047), train_loss = 0.76631266, grad/param norm = 1.5959e-01, time/batch = 0.6641s	
23900/33150 (epoch 36.048), train_loss = 0.96621250, grad/param norm = 2.2573e-01, time/batch = 0.6652s	
23901/33150 (epoch 36.050), train_loss = 0.85596832, grad/param norm = 1.9954e-01, time/batch = 0.6669s	
23902/33150 (epoch 36.051), train_loss = 0.87882622, grad/param norm = 1.5789e-01, time/batch = 0.6681s	
23903/33150 (epoch 36.053), train_loss = 0.87307847, grad/param norm = 1.6815e-01, time/batch = 0.6798s	
23904/33150 (epoch 36.054), train_loss = 0.99877577, grad/param norm = 1.7966e-01, time/batch = 0.6756s	
23905/33150 (epoch 36.056), train_loss = 0.84163006, grad/param norm = 1.8022e-01, time/batch = 0.6685s	
23906/33150 (epoch 36.057), train_loss = 0.90161468, grad/param norm = 1.5557e-01, time/batch = 0.6791s	
23907/33150 (epoch 36.059), train_loss = 0.78919127, grad/param norm = 1.8254e-01, time/batch = 0.6886s	
23908/33150 (epoch 36.060), train_loss = 0.75995916, grad/param norm = 1.5443e-01, time/batch = 0.6859s	
23909/33150 (epoch 36.062), train_loss = 0.85577768, grad/param norm = 1.8081e-01, time/batch = 0.6892s	
23910/33150 (epoch 36.063), train_loss = 0.76662744, grad/param norm = 1.6066e-01, time/batch = 0.6699s	
23911/33150 (epoch 36.065), train_loss = 0.82101679, grad/param norm = 1.5832e-01, time/batch = 0.6729s	
23912/33150 (epoch 36.066), train_loss = 0.82620864, grad/param norm = 1.6492e-01, time/batch = 0.6704s	
23913/33150 (epoch 36.068), train_loss = 0.90312569, grad/param norm = 1.7108e-01, time/batch = 0.6764s	
23914/33150 (epoch 36.069), train_loss = 0.89956327, grad/param norm = 1.8498e-01, time/batch = 0.6813s	
23915/33150 (epoch 36.071), train_loss = 0.86797660, grad/param norm = 1.6758e-01, time/batch = 0.6708s	
23916/33150 (epoch 36.072), train_loss = 0.88573450, grad/param norm = 1.9788e-01, time/batch = 0.6708s	
23917/33150 (epoch 36.074), train_loss = 0.74093080, grad/param norm = 1.6873e-01, time/batch = 0.6747s	
23918/33150 (epoch 36.075), train_loss = 0.75956768, grad/param norm = 1.6438e-01, time/batch = 0.6844s	
23919/33150 (epoch 36.077), train_loss = 0.88994945, grad/param norm = 3.3554e-01, time/batch = 0.6779s	
23920/33150 (epoch 36.078), train_loss = 1.00030195, grad/param norm = 2.1935e-01, time/batch = 0.6693s	
23921/33150 (epoch 36.080), train_loss = 0.99485930, grad/param norm = 1.7397e-01, time/batch = 0.7095s	
23922/33150 (epoch 36.081), train_loss = 0.76062376, grad/param norm = 1.8649e-01, time/batch = 0.6899s	
23923/33150 (epoch 36.083), train_loss = 0.66253401, grad/param norm = 2.1361e-01, time/batch = 0.6719s	
23924/33150 (epoch 36.084), train_loss = 0.72808611, grad/param norm = 1.8226e-01, time/batch = 0.6700s	
23925/33150 (epoch 36.086), train_loss = 0.77303695, grad/param norm = 1.8695e-01, time/batch = 0.6708s	
23926/33150 (epoch 36.087), train_loss = 0.73127670, grad/param norm = 1.7769e-01, time/batch = 0.6741s	
23927/33150 (epoch 36.089), train_loss = 0.77853162, grad/param norm = 1.7231e-01, time/batch = 0.6663s	
23928/33150 (epoch 36.090), train_loss = 0.81802366, grad/param norm = 1.9397e-01, time/batch = 0.6746s	
23929/33150 (epoch 36.092), train_loss = 0.79893402, grad/param norm = 1.8905e-01, time/batch = 0.6674s	
23930/33150 (epoch 36.094), train_loss = 0.89208716, grad/param norm = 1.8964e-01, time/batch = 0.6666s	
23931/33150 (epoch 36.095), train_loss = 0.77213619, grad/param norm = 1.5514e-01, time/batch = 0.6711s	
23932/33150 (epoch 36.097), train_loss = 0.72993995, grad/param norm = 1.6398e-01, time/batch = 0.6727s	
23933/33150 (epoch 36.098), train_loss = 1.07323950, grad/param norm = 2.0070e-01, time/batch = 0.6817s	
23934/33150 (epoch 36.100), train_loss = 1.05070089, grad/param norm = 2.2600e-01, time/batch = 0.6669s	
23935/33150 (epoch 36.101), train_loss = 0.81327026, grad/param norm = 1.7724e-01, time/batch = 0.6659s	
23936/33150 (epoch 36.103), train_loss = 0.87081224, grad/param norm = 1.5434e-01, time/batch = 0.6637s	
23937/33150 (epoch 36.104), train_loss = 0.78015798, grad/param norm = 1.8706e-01, time/batch = 0.6661s	
23938/33150 (epoch 36.106), train_loss = 0.94669690, grad/param norm = 1.7428e-01, time/batch = 0.6688s	
23939/33150 (epoch 36.107), train_loss = 1.02152441, grad/param norm = 1.9083e-01, time/batch = 0.6676s	
23940/33150 (epoch 36.109), train_loss = 0.83290385, grad/param norm = 1.4379e-01, time/batch = 0.6665s	
23941/33150 (epoch 36.110), train_loss = 0.96532356, grad/param norm = 1.8436e-01, time/batch = 0.6717s	
23942/33150 (epoch 36.112), train_loss = 0.76818655, grad/param norm = 1.6225e-01, time/batch = 0.6702s	
23943/33150 (epoch 36.113), train_loss = 0.82164860, grad/param norm = 1.9302e-01, time/batch = 0.6672s	
23944/33150 (epoch 36.115), train_loss = 1.01646712, grad/param norm = 2.0125e-01, time/batch = 0.6720s	
23945/33150 (epoch 36.116), train_loss = 0.89047644, grad/param norm = 1.6612e-01, time/batch = 0.6727s	
23946/33150 (epoch 36.118), train_loss = 0.88263495, grad/param norm = 1.7354e-01, time/batch = 0.6739s	
23947/33150 (epoch 36.119), train_loss = 0.89062579, grad/param norm = 1.9868e-01, time/batch = 0.6793s	
23948/33150 (epoch 36.121), train_loss = 0.83225021, grad/param norm = 1.6913e-01, time/batch = 0.6812s	
23949/33150 (epoch 36.122), train_loss = 1.01807586, grad/param norm = 2.2270e-01, time/batch = 0.6814s	
23950/33150 (epoch 36.124), train_loss = 0.72515389, grad/param norm = 1.6698e-01, time/batch = 0.6935s	
23951/33150 (epoch 36.125), train_loss = 0.96432212, grad/param norm = 1.7590e-01, time/batch = 0.6935s	
23952/33150 (epoch 36.127), train_loss = 0.89333005, grad/param norm = 1.8855e-01, time/batch = 0.6769s	
23953/33150 (epoch 36.128), train_loss = 0.89861976, grad/param norm = 1.9811e-01, time/batch = 0.6737s	
23954/33150 (epoch 36.130), train_loss = 0.86544548, grad/param norm = 1.7158e-01, time/batch = 0.6773s	
23955/33150 (epoch 36.131), train_loss = 1.04547134, grad/param norm = 1.9034e-01, time/batch = 0.6783s	
23956/33150 (epoch 36.133), train_loss = 0.80283359, grad/param norm = 1.5787e-01, time/batch = 0.6767s	
23957/33150 (epoch 36.134), train_loss = 0.96816063, grad/param norm = 1.7430e-01, time/batch = 0.6800s	
23958/33150 (epoch 36.136), train_loss = 0.88667209, grad/param norm = 1.9939e-01, time/batch = 0.6827s	
23959/33150 (epoch 36.137), train_loss = 0.93468198, grad/param norm = 1.6791e-01, time/batch = 0.6894s	
23960/33150 (epoch 36.139), train_loss = 0.91566498, grad/param norm = 1.7908e-01, time/batch = 0.6869s	
23961/33150 (epoch 36.140), train_loss = 1.04748039, grad/param norm = 2.0112e-01, time/batch = 0.6907s	
23962/33150 (epoch 36.142), train_loss = 0.91696430, grad/param norm = 2.0791e-01, time/batch = 0.6864s	
23963/33150 (epoch 36.143), train_loss = 0.87944222, grad/param norm = 2.2244e-01, time/batch = 0.6861s	
23964/33150 (epoch 36.145), train_loss = 0.82597367, grad/param norm = 1.7327e-01, time/batch = 0.6767s	
23965/33150 (epoch 36.146), train_loss = 0.97219487, grad/param norm = 2.1801e-01, time/batch = 0.6746s	
23966/33150 (epoch 36.148), train_loss = 0.99308068, grad/param norm = 1.6296e-01, time/batch = 0.6747s	
23967/33150 (epoch 36.149), train_loss = 0.88289871, grad/param norm = 1.8966e-01, time/batch = 0.6749s	
23968/33150 (epoch 36.151), train_loss = 1.02732453, grad/param norm = 2.0666e-01, time/batch = 0.6726s	
23969/33150 (epoch 36.152), train_loss = 0.80721735, grad/param norm = 1.6172e-01, time/batch = 0.6722s	
23970/33150 (epoch 36.154), train_loss = 0.82833220, grad/param norm = 2.2799e-01, time/batch = 0.6745s	
23971/33150 (epoch 36.155), train_loss = 0.74846891, grad/param norm = 1.7341e-01, time/batch = 0.6718s	
23972/33150 (epoch 36.157), train_loss = 0.85177804, grad/param norm = 1.8450e-01, time/batch = 0.6777s	
23973/33150 (epoch 36.158), train_loss = 0.84101060, grad/param norm = 1.5795e-01, time/batch = 0.6805s	
23974/33150 (epoch 36.160), train_loss = 0.93572292, grad/param norm = 2.1574e-01, time/batch = 0.6708s	
23975/33150 (epoch 36.161), train_loss = 0.82594602, grad/param norm = 2.3650e-01, time/batch = 0.6709s	
23976/33150 (epoch 36.163), train_loss = 0.75135585, grad/param norm = 1.4937e-01, time/batch = 0.6711s	
23977/33150 (epoch 36.164), train_loss = 0.88796118, grad/param norm = 1.7810e-01, time/batch = 0.6711s	
23978/33150 (epoch 36.166), train_loss = 0.83781379, grad/param norm = 1.8138e-01, time/batch = 0.6709s	
23979/33150 (epoch 36.167), train_loss = 0.88599457, grad/param norm = 1.5485e-01, time/batch = 0.6741s	
23980/33150 (epoch 36.169), train_loss = 0.87880342, grad/param norm = 1.9562e-01, time/batch = 0.6739s	
23981/33150 (epoch 36.170), train_loss = 0.78852730, grad/param norm = 2.2501e-01, time/batch = 0.6775s	
23982/33150 (epoch 36.172), train_loss = 0.91449462, grad/param norm = 2.0599e-01, time/batch = 0.6756s	
23983/33150 (epoch 36.173), train_loss = 0.88511027, grad/param norm = 2.0932e-01, time/batch = 0.6745s	
23984/33150 (epoch 36.175), train_loss = 0.85047094, grad/param norm = 1.9810e-01, time/batch = 0.6753s	
23985/33150 (epoch 36.176), train_loss = 0.91501119, grad/param norm = 1.8560e-01, time/batch = 0.6758s	
23986/33150 (epoch 36.178), train_loss = 1.05106686, grad/param norm = 2.2969e-01, time/batch = 0.6718s	
23987/33150 (epoch 36.179), train_loss = 0.94402972, grad/param norm = 1.8872e-01, time/batch = 0.6713s	
23988/33150 (epoch 36.181), train_loss = 0.88094944, grad/param norm = 1.9268e-01, time/batch = 0.6752s	
23989/33150 (epoch 36.183), train_loss = 0.87374774, grad/param norm = 2.0263e-01, time/batch = 0.6743s	
23990/33150 (epoch 36.184), train_loss = 1.11253296, grad/param norm = 2.0823e-01, time/batch = 0.6740s	
23991/33150 (epoch 36.186), train_loss = 1.00613718, grad/param norm = 1.5745e-01, time/batch = 0.6704s	
23992/33150 (epoch 36.187), train_loss = 0.87615249, grad/param norm = 1.7175e-01, time/batch = 0.6736s	
23993/33150 (epoch 36.189), train_loss = 0.70034532, grad/param norm = 1.7415e-01, time/batch = 0.6724s	
23994/33150 (epoch 36.190), train_loss = 0.79140060, grad/param norm = 1.8416e-01, time/batch = 0.6779s	
23995/33150 (epoch 36.192), train_loss = 0.89046749, grad/param norm = 1.8847e-01, time/batch = 0.6904s	
23996/33150 (epoch 36.193), train_loss = 0.94075000, grad/param norm = 1.7240e-01, time/batch = 0.7020s	
23997/33150 (epoch 36.195), train_loss = 1.07950310, grad/param norm = 2.0443e-01, time/batch = 0.7019s	
23998/33150 (epoch 36.196), train_loss = 0.99475102, grad/param norm = 1.8083e-01, time/batch = 0.6749s	
23999/33150 (epoch 36.198), train_loss = 0.76344175, grad/param norm = 1.6181e-01, time/batch = 0.6764s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch36.20_1.7694.t7	
24000/33150 (epoch 36.199), train_loss = 0.94888663, grad/param norm = 2.0727e-01, time/batch = 0.6910s	
24001/33150 (epoch 36.201), train_loss = 1.34308800, grad/param norm = 2.3443e-01, time/batch = 0.6787s	
24002/33150 (epoch 36.202), train_loss = 0.70645661, grad/param norm = 1.7495e-01, time/batch = 0.6712s	
24003/33150 (epoch 36.204), train_loss = 0.89804262, grad/param norm = 1.7491e-01, time/batch = 0.6713s	
24004/33150 (epoch 36.205), train_loss = 0.90668047, grad/param norm = 1.9659e-01, time/batch = 0.6718s	
24005/33150 (epoch 36.207), train_loss = 0.90062260, grad/param norm = 1.6534e-01, time/batch = 0.6694s	
24006/33150 (epoch 36.208), train_loss = 0.94403523, grad/param norm = 1.9813e-01, time/batch = 0.6691s	
24007/33150 (epoch 36.210), train_loss = 0.82161296, grad/param norm = 1.6539e-01, time/batch = 0.6681s	
24008/33150 (epoch 36.211), train_loss = 0.87327043, grad/param norm = 2.0137e-01, time/batch = 0.6909s	
24009/33150 (epoch 36.213), train_loss = 0.93778063, grad/param norm = 1.8115e-01, time/batch = 0.6978s	
24010/33150 (epoch 36.214), train_loss = 0.84408579, grad/param norm = 1.7306e-01, time/batch = 0.6988s	
24011/33150 (epoch 36.216), train_loss = 0.78885844, grad/param norm = 1.7717e-01, time/batch = 0.6955s	
24012/33150 (epoch 36.217), train_loss = 0.86207024, grad/param norm = 1.7951e-01, time/batch = 0.6957s	
24013/33150 (epoch 36.219), train_loss = 0.79573883, grad/param norm = 1.6460e-01, time/batch = 0.6967s	
24014/33150 (epoch 36.220), train_loss = 0.82408163, grad/param norm = 1.4906e-01, time/batch = 0.6851s	
24015/33150 (epoch 36.222), train_loss = 0.95489872, grad/param norm = 1.7291e-01, time/batch = 0.6735s	
24016/33150 (epoch 36.223), train_loss = 0.86323028, grad/param norm = 1.8330e-01, time/batch = 0.6720s	
24017/33150 (epoch 36.225), train_loss = 0.96965124, grad/param norm = 1.7219e-01, time/batch = 0.6744s	
24018/33150 (epoch 36.226), train_loss = 0.83960017, grad/param norm = 1.6388e-01, time/batch = 0.6758s	
24019/33150 (epoch 36.228), train_loss = 0.85225366, grad/param norm = 1.9803e-01, time/batch = 0.6774s	
24020/33150 (epoch 36.229), train_loss = 0.86771475, grad/param norm = 1.8806e-01, time/batch = 0.6792s	
24021/33150 (epoch 36.231), train_loss = 0.96237980, grad/param norm = 2.1225e-01, time/batch = 0.6791s	
24022/33150 (epoch 36.232), train_loss = 0.83980682, grad/param norm = 1.6477e-01, time/batch = 0.6743s	
24023/33150 (epoch 36.234), train_loss = 0.89852278, grad/param norm = 1.7614e-01, time/batch = 0.6711s	
24024/33150 (epoch 36.235), train_loss = 0.92397710, grad/param norm = 1.7223e-01, time/batch = 0.6693s	
24025/33150 (epoch 36.237), train_loss = 0.89568621, grad/param norm = 3.0694e-01, time/batch = 0.6718s	
24026/33150 (epoch 36.238), train_loss = 0.92418294, grad/param norm = 1.8677e-01, time/batch = 0.6817s	
24027/33150 (epoch 36.240), train_loss = 0.88263391, grad/param norm = 1.6953e-01, time/batch = 0.6772s	
24028/33150 (epoch 36.241), train_loss = 0.95364783, grad/param norm = 2.1500e-01, time/batch = 0.6727s	
24029/33150 (epoch 36.243), train_loss = 0.93843622, grad/param norm = 1.8575e-01, time/batch = 0.6708s	
24030/33150 (epoch 36.244), train_loss = 0.88553013, grad/param norm = 1.8588e-01, time/batch = 0.6817s	
24031/33150 (epoch 36.246), train_loss = 0.96763693, grad/param norm = 1.7978e-01, time/batch = 0.6727s	
24032/33150 (epoch 36.247), train_loss = 0.82787269, grad/param norm = 1.6839e-01, time/batch = 0.6702s	
24033/33150 (epoch 36.249), train_loss = 0.99368976, grad/param norm = 1.6982e-01, time/batch = 0.6688s	
24034/33150 (epoch 36.250), train_loss = 0.91026602, grad/param norm = 1.6033e-01, time/batch = 0.6716s	
24035/33150 (epoch 36.252), train_loss = 0.92843424, grad/param norm = 1.5438e-01, time/batch = 0.6737s	
24036/33150 (epoch 36.253), train_loss = 0.85379724, grad/param norm = 1.7450e-01, time/batch = 0.6772s	
24037/33150 (epoch 36.255), train_loss = 0.85613701, grad/param norm = 1.5183e-01, time/batch = 0.6752s	
24038/33150 (epoch 36.256), train_loss = 0.99098189, grad/param norm = 1.7617e-01, time/batch = 0.6712s	
24039/33150 (epoch 36.258), train_loss = 0.82112514, grad/param norm = 1.8671e-01, time/batch = 0.6744s	
24040/33150 (epoch 36.259), train_loss = 0.72127567, grad/param norm = 2.1748e-01, time/batch = 0.6759s	
24041/33150 (epoch 36.261), train_loss = 0.78298279, grad/param norm = 1.5805e-01, time/batch = 0.6843s	
24042/33150 (epoch 36.262), train_loss = 0.98723306, grad/param norm = 1.8943e-01, time/batch = 0.6728s	
24043/33150 (epoch 36.264), train_loss = 0.67355248, grad/param norm = 1.5329e-01, time/batch = 0.6711s	
24044/33150 (epoch 36.265), train_loss = 0.88024932, grad/param norm = 1.6596e-01, time/batch = 0.6712s	
24045/33150 (epoch 36.267), train_loss = 0.97938516, grad/param norm = 2.3864e-01, time/batch = 0.6705s	
24046/33150 (epoch 36.268), train_loss = 0.98386327, grad/param norm = 1.6841e-01, time/batch = 0.6738s	
24047/33150 (epoch 36.270), train_loss = 1.05544795, grad/param norm = 1.7987e-01, time/batch = 0.6697s	
24048/33150 (epoch 36.271), train_loss = 0.95942731, grad/param norm = 2.0698e-01, time/batch = 0.6703s	
24049/33150 (epoch 36.273), train_loss = 0.99241053, grad/param norm = 1.8124e-01, time/batch = 0.6721s	
24050/33150 (epoch 36.275), train_loss = 1.01209635, grad/param norm = 1.7811e-01, time/batch = 0.6754s	
24051/33150 (epoch 36.276), train_loss = 0.88673830, grad/param norm = 1.8283e-01, time/batch = 0.6744s	
24052/33150 (epoch 36.278), train_loss = 0.97717925, grad/param norm = 1.6929e-01, time/batch = 0.6723s	
24053/33150 (epoch 36.279), train_loss = 0.94896954, grad/param norm = 1.6101e-01, time/batch = 0.6749s	
24054/33150 (epoch 36.281), train_loss = 0.88463820, grad/param norm = 1.7940e-01, time/batch = 0.6732s	
24055/33150 (epoch 36.282), train_loss = 0.91652666, grad/param norm = 1.4392e-01, time/batch = 0.6784s	
24056/33150 (epoch 36.284), train_loss = 0.79647985, grad/param norm = 1.7595e-01, time/batch = 0.6805s	
24057/33150 (epoch 36.285), train_loss = 0.92594279, grad/param norm = 1.9207e-01, time/batch = 0.6735s	
24058/33150 (epoch 36.287), train_loss = 0.77879935, grad/param norm = 1.7281e-01, time/batch = 0.6741s	
24059/33150 (epoch 36.288), train_loss = 0.95383559, grad/param norm = 1.7935e-01, time/batch = 0.6734s	
24060/33150 (epoch 36.290), train_loss = 0.74586211, grad/param norm = 1.7446e-01, time/batch = 0.6708s	
24061/33150 (epoch 36.291), train_loss = 0.73141382, grad/param norm = 1.7502e-01, time/batch = 0.6731s	
24062/33150 (epoch 36.293), train_loss = 0.84972355, grad/param norm = 1.8150e-01, time/batch = 0.6690s	
24063/33150 (epoch 36.294), train_loss = 0.67966949, grad/param norm = 1.4585e-01, time/batch = 0.6686s	
24064/33150 (epoch 36.296), train_loss = 0.86983276, grad/param norm = 1.7124e-01, time/batch = 0.6704s	
24065/33150 (epoch 36.297), train_loss = 0.81400271, grad/param norm = 1.5853e-01, time/batch = 0.6702s	
24066/33150 (epoch 36.299), train_loss = 0.82842689, grad/param norm = 2.0075e-01, time/batch = 0.6780s	
24067/33150 (epoch 36.300), train_loss = 0.83050799, grad/param norm = 1.6295e-01, time/batch = 0.6879s	
24068/33150 (epoch 36.302), train_loss = 0.84122271, grad/param norm = 1.6767e-01, time/batch = 0.6899s	
24069/33150 (epoch 36.303), train_loss = 0.82963034, grad/param norm = 1.7926e-01, time/batch = 0.6854s	
24070/33150 (epoch 36.305), train_loss = 0.90630886, grad/param norm = 1.5973e-01, time/batch = 0.6825s	
24071/33150 (epoch 36.306), train_loss = 0.93123298, grad/param norm = 2.0901e-01, time/batch = 0.6769s	
24072/33150 (epoch 36.308), train_loss = 1.08843404, grad/param norm = 1.8305e-01, time/batch = 0.6673s	
24073/33150 (epoch 36.309), train_loss = 0.72544250, grad/param norm = 1.5658e-01, time/batch = 0.6799s	
24074/33150 (epoch 36.311), train_loss = 0.86273653, grad/param norm = 1.9615e-01, time/batch = 0.6874s	
24075/33150 (epoch 36.312), train_loss = 0.70268047, grad/param norm = 1.4441e-01, time/batch = 0.6831s	
24076/33150 (epoch 36.314), train_loss = 0.84788158, grad/param norm = 1.7512e-01, time/batch = 0.6793s	
24077/33150 (epoch 36.315), train_loss = 0.92253817, grad/param norm = 1.6556e-01, time/batch = 0.6640s	
24078/33150 (epoch 36.317), train_loss = 0.69177873, grad/param norm = 1.3783e-01, time/batch = 0.6635s	
24079/33150 (epoch 36.318), train_loss = 0.80311800, grad/param norm = 1.5079e-01, time/batch = 0.6663s	
24080/33150 (epoch 36.320), train_loss = 0.74731520, grad/param norm = 1.8399e-01, time/batch = 0.6644s	
24081/33150 (epoch 36.321), train_loss = 0.83738134, grad/param norm = 1.5513e-01, time/batch = 0.6700s	
24082/33150 (epoch 36.323), train_loss = 0.81953228, grad/param norm = 1.7025e-01, time/batch = 0.6663s	
24083/33150 (epoch 36.324), train_loss = 0.86973067, grad/param norm = 2.0364e-01, time/batch = 0.6624s	
24084/33150 (epoch 36.326), train_loss = 0.85954368, grad/param norm = 1.6248e-01, time/batch = 0.6667s	
24085/33150 (epoch 36.327), train_loss = 0.95361258, grad/param norm = 1.8051e-01, time/batch = 0.6818s	
24086/33150 (epoch 36.329), train_loss = 0.91198852, grad/param norm = 1.8889e-01, time/batch = 0.6744s	
24087/33150 (epoch 36.330), train_loss = 0.83310639, grad/param norm = 1.7271e-01, time/batch = 0.6775s	
24088/33150 (epoch 36.332), train_loss = 0.85235802, grad/param norm = 1.7150e-01, time/batch = 0.6720s	
24089/33150 (epoch 36.333), train_loss = 0.91988432, grad/param norm = 1.5520e-01, time/batch = 0.6722s	
24090/33150 (epoch 36.335), train_loss = 0.79587917, grad/param norm = 1.6921e-01, time/batch = 0.6774s	
24091/33150 (epoch 36.336), train_loss = 0.77306459, grad/param norm = 1.8223e-01, time/batch = 0.6748s	
24092/33150 (epoch 36.338), train_loss = 0.74341757, grad/param norm = 1.7541e-01, time/batch = 0.6738s	
24093/33150 (epoch 36.339), train_loss = 0.93122668, grad/param norm = 1.7855e-01, time/batch = 0.6743s	
24094/33150 (epoch 36.341), train_loss = 0.85848543, grad/param norm = 1.8692e-01, time/batch = 0.6781s	
24095/33150 (epoch 36.342), train_loss = 0.82000150, grad/param norm = 1.8955e-01, time/batch = 0.6690s	
24096/33150 (epoch 36.344), train_loss = 0.84621679, grad/param norm = 1.6142e-01, time/batch = 0.6714s	
24097/33150 (epoch 36.345), train_loss = 0.83109102, grad/param norm = 1.8842e-01, time/batch = 0.6705s	
24098/33150 (epoch 36.347), train_loss = 0.71178490, grad/param norm = 1.6987e-01, time/batch = 0.6688s	
24099/33150 (epoch 36.348), train_loss = 0.88855522, grad/param norm = 1.6388e-01, time/batch = 0.6772s	
24100/33150 (epoch 36.350), train_loss = 0.76781506, grad/param norm = 1.6381e-01, time/batch = 0.6820s	
24101/33150 (epoch 36.351), train_loss = 0.92944046, grad/param norm = 1.7303e-01, time/batch = 0.6765s	
24102/33150 (epoch 36.353), train_loss = 0.89275118, grad/param norm = 1.7269e-01, time/batch = 0.6707s	
24103/33150 (epoch 36.354), train_loss = 1.07816384, grad/param norm = 1.9202e-01, time/batch = 0.6865s	
24104/33150 (epoch 36.356), train_loss = 0.94519741, grad/param norm = 1.7882e-01, time/batch = 0.6794s	
24105/33150 (epoch 36.357), train_loss = 0.88502255, grad/param norm = 1.8917e-01, time/batch = 0.6667s	
24106/33150 (epoch 36.359), train_loss = 0.94174058, grad/param norm = 1.7401e-01, time/batch = 0.6658s	
24107/33150 (epoch 36.360), train_loss = 0.90161356, grad/param norm = 1.9636e-01, time/batch = 0.6665s	
24108/33150 (epoch 36.362), train_loss = 0.97297687, grad/param norm = 1.6674e-01, time/batch = 0.6689s	
24109/33150 (epoch 36.363), train_loss = 0.89661332, grad/param norm = 1.5790e-01, time/batch = 0.6712s	
24110/33150 (epoch 36.365), train_loss = 0.85043802, grad/param norm = 1.6126e-01, time/batch = 0.6698s	
24111/33150 (epoch 36.367), train_loss = 0.81617491, grad/param norm = 1.5433e-01, time/batch = 0.6697s	
24112/33150 (epoch 36.368), train_loss = 0.84351126, grad/param norm = 2.0893e-01, time/batch = 0.6688s	
24113/33150 (epoch 36.370), train_loss = 0.87433926, grad/param norm = 1.7987e-01, time/batch = 0.6676s	
24114/33150 (epoch 36.371), train_loss = 0.77953792, grad/param norm = 1.9236e-01, time/batch = 0.6740s	
24115/33150 (epoch 36.373), train_loss = 0.90996600, grad/param norm = 3.2006e-01, time/batch = 0.6852s	
24116/33150 (epoch 36.374), train_loss = 0.87644702, grad/param norm = 1.8092e-01, time/batch = 0.6780s	
24117/33150 (epoch 36.376), train_loss = 0.94101565, grad/param norm = 1.5603e-01, time/batch = 0.6695s	
24118/33150 (epoch 36.377), train_loss = 0.78609386, grad/param norm = 1.8274e-01, time/batch = 0.6716s	
24119/33150 (epoch 36.379), train_loss = 0.92089729, grad/param norm = 1.9830e-01, time/batch = 0.6729s	
24120/33150 (epoch 36.380), train_loss = 0.91385082, grad/param norm = 1.6251e-01, time/batch = 0.6768s	
24121/33150 (epoch 36.382), train_loss = 0.85544577, grad/param norm = 1.7883e-01, time/batch = 0.6736s	
24122/33150 (epoch 36.383), train_loss = 0.78311339, grad/param norm = 1.6656e-01, time/batch = 0.6722s	
24123/33150 (epoch 36.385), train_loss = 0.83423433, grad/param norm = 1.9568e-01, time/batch = 0.6767s	
24124/33150 (epoch 36.386), train_loss = 0.76472462, grad/param norm = 1.5628e-01, time/batch = 0.6807s	
24125/33150 (epoch 36.388), train_loss = 0.77797739, grad/param norm = 1.5785e-01, time/batch = 0.6683s	
24126/33150 (epoch 36.389), train_loss = 0.79574751, grad/param norm = 1.5453e-01, time/batch = 0.6676s	
24127/33150 (epoch 36.391), train_loss = 1.00301374, grad/param norm = 1.9222e-01, time/batch = 0.6711s	
24128/33150 (epoch 36.392), train_loss = 0.81511334, grad/param norm = 1.7608e-01, time/batch = 0.6778s	
24129/33150 (epoch 36.394), train_loss = 0.72897055, grad/param norm = 1.4148e-01, time/batch = 0.6781s	
24130/33150 (epoch 36.395), train_loss = 0.70448548, grad/param norm = 1.6562e-01, time/batch = 0.6810s	
24131/33150 (epoch 36.397), train_loss = 0.59599273, grad/param norm = 1.4078e-01, time/batch = 0.6713s	
24132/33150 (epoch 36.398), train_loss = 0.86072782, grad/param norm = 1.7776e-01, time/batch = 0.6727s	
24133/33150 (epoch 36.400), train_loss = 0.83041071, grad/param norm = 1.4704e-01, time/batch = 0.6684s	
24134/33150 (epoch 36.401), train_loss = 0.71501042, grad/param norm = 1.3512e-01, time/batch = 0.6678s	
24135/33150 (epoch 36.403), train_loss = 0.73093233, grad/param norm = 1.5108e-01, time/batch = 0.6776s	
24136/33150 (epoch 36.404), train_loss = 0.86787872, grad/param norm = 1.6129e-01, time/batch = 0.6715s	
24137/33150 (epoch 36.406), train_loss = 0.79511604, grad/param norm = 1.4086e-01, time/batch = 0.6713s	
24138/33150 (epoch 36.407), train_loss = 0.71971965, grad/param norm = 1.4707e-01, time/batch = 0.6726s	
24139/33150 (epoch 36.409), train_loss = 0.68736260, grad/param norm = 1.4608e-01, time/batch = 0.6876s	
24140/33150 (epoch 36.410), train_loss = 0.87215821, grad/param norm = 1.8177e-01, time/batch = 0.6762s	
24141/33150 (epoch 36.412), train_loss = 0.90755947, grad/param norm = 1.5759e-01, time/batch = 0.6883s	
24142/33150 (epoch 36.413), train_loss = 0.74838711, grad/param norm = 1.6166e-01, time/batch = 0.6825s	
24143/33150 (epoch 36.415), train_loss = 0.88508635, grad/param norm = 1.5764e-01, time/batch = 0.6760s	
24144/33150 (epoch 36.416), train_loss = 0.79804941, grad/param norm = 1.5933e-01, time/batch = 0.6820s	
24145/33150 (epoch 36.418), train_loss = 0.88833484, grad/param norm = 2.7116e-01, time/batch = 0.6871s	
24146/33150 (epoch 36.419), train_loss = 0.83956170, grad/param norm = 1.6892e-01, time/batch = 0.6683s	
24147/33150 (epoch 36.421), train_loss = 0.87510388, grad/param norm = 1.9393e-01, time/batch = 0.6718s	
24148/33150 (epoch 36.422), train_loss = 0.81399170, grad/param norm = 1.5781e-01, time/batch = 0.6690s	
24149/33150 (epoch 36.424), train_loss = 0.79599781, grad/param norm = 1.8046e-01, time/batch = 0.6694s	
24150/33150 (epoch 36.425), train_loss = 0.94085066, grad/param norm = 1.9308e-01, time/batch = 0.6687s	
24151/33150 (epoch 36.427), train_loss = 0.84261145, grad/param norm = 1.5616e-01, time/batch = 0.6704s	
24152/33150 (epoch 36.428), train_loss = 0.83653783, grad/param norm = 1.7777e-01, time/batch = 0.6692s	
24153/33150 (epoch 36.430), train_loss = 0.88347114, grad/param norm = 1.8724e-01, time/batch = 0.6711s	
24154/33150 (epoch 36.431), train_loss = 0.91430859, grad/param norm = 1.9565e-01, time/batch = 0.6673s	
24155/33150 (epoch 36.433), train_loss = 0.84788522, grad/param norm = 1.7262e-01, time/batch = 0.6709s	
24156/33150 (epoch 36.434), train_loss = 0.74385980, grad/param norm = 1.6219e-01, time/batch = 0.6688s	
24157/33150 (epoch 36.436), train_loss = 0.85680272, grad/param norm = 1.4800e-01, time/batch = 0.6643s	
24158/33150 (epoch 36.437), train_loss = 0.86249777, grad/param norm = 2.0304e-01, time/batch = 0.6684s	
24159/33150 (epoch 36.439), train_loss = 0.99472458, grad/param norm = 1.6952e-01, time/batch = 0.6815s	
24160/33150 (epoch 36.440), train_loss = 0.89936333, grad/param norm = 1.7866e-01, time/batch = 0.6737s	
24161/33150 (epoch 36.442), train_loss = 0.72111513, grad/param norm = 1.4902e-01, time/batch = 0.6686s	
24162/33150 (epoch 36.443), train_loss = 0.89354727, grad/param norm = 1.9361e-01, time/batch = 0.6891s	
24163/33150 (epoch 36.445), train_loss = 0.84615282, grad/param norm = 1.7975e-01, time/batch = 0.6885s	
24164/33150 (epoch 36.446), train_loss = 0.88212605, grad/param norm = 2.0069e-01, time/batch = 0.6836s	
24165/33150 (epoch 36.448), train_loss = 0.95626097, grad/param norm = 1.8799e-01, time/batch = 0.6724s	
24166/33150 (epoch 36.449), train_loss = 0.85014040, grad/param norm = 1.4993e-01, time/batch = 0.6819s	
24167/33150 (epoch 36.451), train_loss = 0.87630035, grad/param norm = 1.9368e-01, time/batch = 0.6867s	
24168/33150 (epoch 36.452), train_loss = 1.03285259, grad/param norm = 1.8001e-01, time/batch = 0.6832s	
24169/33150 (epoch 36.454), train_loss = 0.83834215, grad/param norm = 1.7332e-01, time/batch = 0.6810s	
24170/33150 (epoch 36.456), train_loss = 0.79389609, grad/param norm = 1.6372e-01, time/batch = 0.6720s	
24171/33150 (epoch 36.457), train_loss = 0.87408406, grad/param norm = 1.9480e-01, time/batch = 0.6720s	
24172/33150 (epoch 36.459), train_loss = 0.98913806, grad/param norm = 2.5841e-01, time/batch = 0.6683s	
24173/33150 (epoch 36.460), train_loss = 0.91142145, grad/param norm = 1.5067e-01, time/batch = 0.6781s	
24174/33150 (epoch 36.462), train_loss = 0.96562576, grad/param norm = 2.0457e-01, time/batch = 0.6820s	
24175/33150 (epoch 36.463), train_loss = 1.09310574, grad/param norm = 2.3439e-01, time/batch = 0.6684s	
24176/33150 (epoch 36.465), train_loss = 0.91859260, grad/param norm = 1.6470e-01, time/batch = 0.6709s	
24177/33150 (epoch 36.466), train_loss = 0.83013825, grad/param norm = 1.7000e-01, time/batch = 0.6701s	
24178/33150 (epoch 36.468), train_loss = 1.06119681, grad/param norm = 1.7217e-01, time/batch = 0.6705s	
24179/33150 (epoch 36.469), train_loss = 0.79849071, grad/param norm = 1.7322e-01, time/batch = 0.6705s	
24180/33150 (epoch 36.471), train_loss = 0.80127511, grad/param norm = 1.6564e-01, time/batch = 0.6752s	
24181/33150 (epoch 36.472), train_loss = 0.88280790, grad/param norm = 1.7429e-01, time/batch = 0.6771s	
24182/33150 (epoch 36.474), train_loss = 0.92834508, grad/param norm = 2.1984e-01, time/batch = 0.6796s	
24183/33150 (epoch 36.475), train_loss = 1.10265487, grad/param norm = 1.9048e-01, time/batch = 0.6712s	
24184/33150 (epoch 36.477), train_loss = 0.93713599, grad/param norm = 1.7934e-01, time/batch = 0.6709s	
24185/33150 (epoch 36.478), train_loss = 0.90771409, grad/param norm = 1.7039e-01, time/batch = 0.6657s	
24186/33150 (epoch 36.480), train_loss = 0.80611479, grad/param norm = 1.7896e-01, time/batch = 0.6686s	
24187/33150 (epoch 36.481), train_loss = 0.74067738, grad/param norm = 1.6808e-01, time/batch = 0.6726s	
24188/33150 (epoch 36.483), train_loss = 0.82722352, grad/param norm = 1.7875e-01, time/batch = 0.6765s	
24189/33150 (epoch 36.484), train_loss = 0.79063173, grad/param norm = 1.6975e-01, time/batch = 0.6804s	
24190/33150 (epoch 36.486), train_loss = 0.79324004, grad/param norm = 1.8616e-01, time/batch = 0.6681s	
24191/33150 (epoch 36.487), train_loss = 0.90495791, grad/param norm = 1.7787e-01, time/batch = 0.6740s	
24192/33150 (epoch 36.489), train_loss = 0.87616820, grad/param norm = 1.9367e-01, time/batch = 0.6706s	
24193/33150 (epoch 36.490), train_loss = 0.69374023, grad/param norm = 1.5968e-01, time/batch = 0.6685s	
24194/33150 (epoch 36.492), train_loss = 0.82562434, grad/param norm = 1.7678e-01, time/batch = 0.6670s	
24195/33150 (epoch 36.493), train_loss = 0.91983544, grad/param norm = 1.7450e-01, time/batch = 0.6684s	
24196/33150 (epoch 36.495), train_loss = 0.90864980, grad/param norm = 1.5685e-01, time/batch = 0.6679s	
24197/33150 (epoch 36.496), train_loss = 0.83479459, grad/param norm = 1.6711e-01, time/batch = 0.6703s	
24198/33150 (epoch 36.498), train_loss = 0.93797468, grad/param norm = 2.5698e-01, time/batch = 0.6697s	
24199/33150 (epoch 36.499), train_loss = 0.97187215, grad/param norm = 1.7504e-01, time/batch = 0.6688s	
24200/33150 (epoch 36.501), train_loss = 0.91044152, grad/param norm = 2.0267e-01, time/batch = 0.6676s	
24201/33150 (epoch 36.502), train_loss = 0.97395809, grad/param norm = 2.2067e-01, time/batch = 0.6737s	
24202/33150 (epoch 36.504), train_loss = 0.95562606, grad/param norm = 2.0460e-01, time/batch = 0.6708s	
24203/33150 (epoch 36.505), train_loss = 0.98263697, grad/param norm = 1.8525e-01, time/batch = 0.6807s	
24204/33150 (epoch 36.507), train_loss = 0.80228728, grad/param norm = 1.6776e-01, time/batch = 0.6780s	
24205/33150 (epoch 36.508), train_loss = 0.79860627, grad/param norm = 1.6573e-01, time/batch = 0.6714s	
24206/33150 (epoch 36.510), train_loss = 0.93326952, grad/param norm = 1.6021e-01, time/batch = 0.6722s	
24207/33150 (epoch 36.511), train_loss = 0.98050807, grad/param norm = 1.8447e-01, time/batch = 0.6728s	
24208/33150 (epoch 36.513), train_loss = 0.88589868, grad/param norm = 1.9064e-01, time/batch = 0.6715s	
24209/33150 (epoch 36.514), train_loss = 0.76338175, grad/param norm = 2.2510e-01, time/batch = 0.6676s	
24210/33150 (epoch 36.516), train_loss = 0.89051545, grad/param norm = 2.0235e-01, time/batch = 0.6719s	
24211/33150 (epoch 36.517), train_loss = 0.94835368, grad/param norm = 1.9942e-01, time/batch = 0.6698s	
24212/33150 (epoch 36.519), train_loss = 0.79555883, grad/param norm = 1.7029e-01, time/batch = 0.6787s	
24213/33150 (epoch 36.520), train_loss = 0.88001695, grad/param norm = 1.6864e-01, time/batch = 0.6870s	
24214/33150 (epoch 36.522), train_loss = 0.96589030, grad/param norm = 2.8670e-01, time/batch = 0.6724s	
24215/33150 (epoch 36.523), train_loss = 0.76773420, grad/param norm = 1.7815e-01, time/batch = 0.6784s	
24216/33150 (epoch 36.525), train_loss = 0.91743486, grad/param norm = 2.0005e-01, time/batch = 0.6703s	
24217/33150 (epoch 36.526), train_loss = 0.79652679, grad/param norm = 1.6495e-01, time/batch = 0.6770s	
24218/33150 (epoch 36.528), train_loss = 0.88580766, grad/param norm = 1.8435e-01, time/batch = 0.6819s	
24219/33150 (epoch 36.529), train_loss = 0.87840562, grad/param norm = 1.8870e-01, time/batch = 0.6761s	
24220/33150 (epoch 36.531), train_loss = 0.74152587, grad/param norm = 2.1290e-01, time/batch = 0.6741s	
24221/33150 (epoch 36.532), train_loss = 0.90052248, grad/param norm = 2.4783e-01, time/batch = 0.6879s	
24222/33150 (epoch 36.534), train_loss = 0.85395532, grad/param norm = 1.5908e-01, time/batch = 0.6730s	
24223/33150 (epoch 36.535), train_loss = 0.79793515, grad/param norm = 1.9539e-01, time/batch = 0.6713s	
24224/33150 (epoch 36.537), train_loss = 0.89043824, grad/param norm = 2.1644e-01, time/batch = 0.6724s	
24225/33150 (epoch 36.538), train_loss = 0.77166477, grad/param norm = 1.6250e-01, time/batch = 0.6723s	
24226/33150 (epoch 36.540), train_loss = 0.76167391, grad/param norm = 1.6516e-01, time/batch = 0.6725s	
24227/33150 (epoch 36.541), train_loss = 0.95504290, grad/param norm = 1.9131e-01, time/batch = 0.6700s	
24228/33150 (epoch 36.543), train_loss = 0.88976792, grad/param norm = 1.9012e-01, time/batch = 0.6712s	
24229/33150 (epoch 36.544), train_loss = 0.93247349, grad/param norm = 1.6332e-01, time/batch = 0.6719s	
24230/33150 (epoch 36.546), train_loss = 0.82973117, grad/param norm = 1.8509e-01, time/batch = 0.6753s	
24231/33150 (epoch 36.548), train_loss = 0.83461697, grad/param norm = 1.8723e-01, time/batch = 0.6709s	
24232/33150 (epoch 36.549), train_loss = 0.82082441, grad/param norm = 1.8069e-01, time/batch = 0.6736s	
24233/33150 (epoch 36.551), train_loss = 0.78191712, grad/param norm = 1.4927e-01, time/batch = 0.6819s	
24234/33150 (epoch 36.552), train_loss = 0.68769677, grad/param norm = 1.4898e-01, time/batch = 0.6858s	
24235/33150 (epoch 36.554), train_loss = 0.91594090, grad/param norm = 1.7321e-01, time/batch = 0.6810s	
24236/33150 (epoch 36.555), train_loss = 0.97370423, grad/param norm = 2.0588e-01, time/batch = 0.6809s	
24237/33150 (epoch 36.557), train_loss = 0.71058513, grad/param norm = 1.7755e-01, time/batch = 0.6908s	
24238/33150 (epoch 36.558), train_loss = 0.90095451, grad/param norm = 2.5731e-01, time/batch = 0.6914s	
24239/33150 (epoch 36.560), train_loss = 0.79599785, grad/param norm = 1.9093e-01, time/batch = 0.6847s	
24240/33150 (epoch 36.561), train_loss = 0.72473447, grad/param norm = 1.7827e-01, time/batch = 0.6684s	
24241/33150 (epoch 36.563), train_loss = 0.90897489, grad/param norm = 2.2967e-01, time/batch = 0.6695s	
24242/33150 (epoch 36.564), train_loss = 0.96006662, grad/param norm = 1.7045e-01, time/batch = 0.6678s	
24243/33150 (epoch 36.566), train_loss = 0.78722390, grad/param norm = 1.7303e-01, time/batch = 0.6859s	
24244/33150 (epoch 36.567), train_loss = 0.81536441, grad/param norm = 1.6748e-01, time/batch = 0.6691s	
24245/33150 (epoch 36.569), train_loss = 0.87892306, grad/param norm = 1.9899e-01, time/batch = 0.6713s	
24246/33150 (epoch 36.570), train_loss = 0.90948317, grad/param norm = 1.5985e-01, time/batch = 0.6676s	
24247/33150 (epoch 36.572), train_loss = 0.80720673, grad/param norm = 2.2486e-01, time/batch = 0.6800s	
24248/33150 (epoch 36.573), train_loss = 0.72697441, grad/param norm = 1.4660e-01, time/batch = 0.6787s	
24249/33150 (epoch 36.575), train_loss = 0.82182809, grad/param norm = 1.8736e-01, time/batch = 0.6680s	
24250/33150 (epoch 36.576), train_loss = 0.75814118, grad/param norm = 1.4899e-01, time/batch = 0.6765s	
24251/33150 (epoch 36.578), train_loss = 0.79783685, grad/param norm = 1.5596e-01, time/batch = 0.6904s	
24252/33150 (epoch 36.579), train_loss = 0.73759379, grad/param norm = 1.5045e-01, time/batch = 0.6795s	
24253/33150 (epoch 36.581), train_loss = 0.77414552, grad/param norm = 1.7014e-01, time/batch = 0.6856s	
24254/33150 (epoch 36.582), train_loss = 0.97445864, grad/param norm = 1.5602e-01, time/batch = 0.6659s	
24255/33150 (epoch 36.584), train_loss = 0.93153275, grad/param norm = 1.8482e-01, time/batch = 0.6660s	
24256/33150 (epoch 36.585), train_loss = 0.86455459, grad/param norm = 1.9659e-01, time/batch = 0.6689s	
24257/33150 (epoch 36.587), train_loss = 0.84416808, grad/param norm = 1.4900e-01, time/batch = 0.6659s	
24258/33150 (epoch 36.588), train_loss = 0.78993781, grad/param norm = 1.6589e-01, time/batch = 0.6675s	
24259/33150 (epoch 36.590), train_loss = 0.89629920, grad/param norm = 1.7293e-01, time/batch = 0.6658s	
24260/33150 (epoch 36.591), train_loss = 0.85859985, grad/param norm = 1.8363e-01, time/batch = 0.6734s	
24261/33150 (epoch 36.593), train_loss = 0.91771099, grad/param norm = 1.8805e-01, time/batch = 0.6743s	
24262/33150 (epoch 36.594), train_loss = 0.83502135, grad/param norm = 1.8436e-01, time/batch = 0.6814s	
24263/33150 (epoch 36.596), train_loss = 0.81551091, grad/param norm = 1.6763e-01, time/batch = 0.6791s	
24264/33150 (epoch 36.597), train_loss = 0.77466072, grad/param norm = 2.4448e-01, time/batch = 0.6767s	
24265/33150 (epoch 36.599), train_loss = 1.01371971, grad/param norm = 2.8253e-01, time/batch = 0.6800s	
24266/33150 (epoch 36.600), train_loss = 0.88036654, grad/param norm = 2.5376e-01, time/batch = 0.6843s	
24267/33150 (epoch 36.602), train_loss = 0.87145612, grad/param norm = 2.3540e-01, time/batch = 0.7040s	
24268/33150 (epoch 36.603), train_loss = 0.96838212, grad/param norm = 1.9698e-01, time/batch = 0.7028s	
24269/33150 (epoch 36.605), train_loss = 0.76089191, grad/param norm = 1.5603e-01, time/batch = 0.6959s	
24270/33150 (epoch 36.606), train_loss = 0.80263526, grad/param norm = 2.3892e-01, time/batch = 0.6879s	
24271/33150 (epoch 36.608), train_loss = 0.94207448, grad/param norm = 1.8623e-01, time/batch = 0.6875s	
24272/33150 (epoch 36.609), train_loss = 0.86349600, grad/param norm = 2.4515e-01, time/batch = 0.7013s	
24273/33150 (epoch 36.611), train_loss = 0.77185877, grad/param norm = 1.7264e-01, time/batch = 0.6795s	
24274/33150 (epoch 36.612), train_loss = 0.84599669, grad/param norm = 1.8685e-01, time/batch = 0.6794s	
24275/33150 (epoch 36.614), train_loss = 0.78391881, grad/param norm = 1.6397e-01, time/batch = 0.6712s	
24276/33150 (epoch 36.615), train_loss = 0.77132187, grad/param norm = 2.3972e-01, time/batch = 0.6821s	
24277/33150 (epoch 36.617), train_loss = 0.89069413, grad/param norm = 2.2028e-01, time/batch = 0.6884s	
24278/33150 (epoch 36.618), train_loss = 0.89939838, grad/param norm = 1.7767e-01, time/batch = 0.6737s	
24279/33150 (epoch 36.620), train_loss = 0.83762368, grad/param norm = 1.9587e-01, time/batch = 0.6701s	
24280/33150 (epoch 36.621), train_loss = 0.89322730, grad/param norm = 1.8928e-01, time/batch = 0.6746s	
24281/33150 (epoch 36.623), train_loss = 0.91196775, grad/param norm = 1.6080e-01, time/batch = 0.6726s	
24282/33150 (epoch 36.624), train_loss = 0.82443621, grad/param norm = 1.7997e-01, time/batch = 0.6663s	
24283/33150 (epoch 36.626), train_loss = 0.84827704, grad/param norm = 1.6955e-01, time/batch = 0.6717s	
24284/33150 (epoch 36.627), train_loss = 0.81433181, grad/param norm = 1.7726e-01, time/batch = 0.6859s	
24285/33150 (epoch 36.629), train_loss = 0.72870040, grad/param norm = 1.7074e-01, time/batch = 0.6710s	
24286/33150 (epoch 36.630), train_loss = 0.84134501, grad/param norm = 1.7681e-01, time/batch = 0.6693s	
24287/33150 (epoch 36.632), train_loss = 0.74324899, grad/param norm = 1.4414e-01, time/batch = 0.6639s	
24288/33150 (epoch 36.633), train_loss = 0.77605366, grad/param norm = 1.9473e-01, time/batch = 0.6632s	
24289/33150 (epoch 36.635), train_loss = 0.99542251, grad/param norm = 1.8799e-01, time/batch = 0.6645s	
24290/33150 (epoch 36.637), train_loss = 0.70398501, grad/param norm = 1.7262e-01, time/batch = 0.6681s	
24291/33150 (epoch 36.638), train_loss = 0.84203065, grad/param norm = 1.9026e-01, time/batch = 0.6781s	
24292/33150 (epoch 36.640), train_loss = 0.93205726, grad/param norm = 1.9996e-01, time/batch = 0.6809s	
24293/33150 (epoch 36.641), train_loss = 0.71738633, grad/param norm = 1.8519e-01, time/batch = 0.6678s	
24294/33150 (epoch 36.643), train_loss = 0.86918165, grad/param norm = 1.7933e-01, time/batch = 0.6657s	
24295/33150 (epoch 36.644), train_loss = 0.98995347, grad/param norm = 1.6334e-01, time/batch = 0.6671s	
24296/33150 (epoch 36.646), train_loss = 0.84321947, grad/param norm = 1.8697e-01, time/batch = 0.6752s	
24297/33150 (epoch 36.647), train_loss = 1.04277925, grad/param norm = 1.9698e-01, time/batch = 0.6789s	
24298/33150 (epoch 36.649), train_loss = 0.89545856, grad/param norm = 1.9896e-01, time/batch = 0.6715s	
24299/33150 (epoch 36.650), train_loss = 0.74940315, grad/param norm = 1.5679e-01, time/batch = 0.6698s	
24300/33150 (epoch 36.652), train_loss = 0.96685887, grad/param norm = 2.3572e-01, time/batch = 0.6683s	
24301/33150 (epoch 36.653), train_loss = 0.89980549, grad/param norm = 1.7374e-01, time/batch = 0.6718s	
24302/33150 (epoch 36.655), train_loss = 0.88903049, grad/param norm = 2.0593e-01, time/batch = 0.6669s	
24303/33150 (epoch 36.656), train_loss = 0.80748141, grad/param norm = 1.5745e-01, time/batch = 0.6678s	
24304/33150 (epoch 36.658), train_loss = 0.81941172, grad/param norm = 1.8099e-01, time/batch = 0.6696s	
24305/33150 (epoch 36.659), train_loss = 1.10823116, grad/param norm = 2.7002e-01, time/batch = 0.6667s	
24306/33150 (epoch 36.661), train_loss = 0.85453307, grad/param norm = 1.8793e-01, time/batch = 0.6768s	
24307/33150 (epoch 36.662), train_loss = 0.83618184, grad/param norm = 1.8978e-01, time/batch = 0.6815s	
24308/33150 (epoch 36.664), train_loss = 0.96651220, grad/param norm = 1.8887e-01, time/batch = 0.6724s	
24309/33150 (epoch 36.665), train_loss = 0.92786534, grad/param norm = 1.9936e-01, time/batch = 0.6741s	
24310/33150 (epoch 36.667), train_loss = 0.94721574, grad/param norm = 2.0596e-01, time/batch = 0.6710s	
24311/33150 (epoch 36.668), train_loss = 1.01762691, grad/param norm = 2.1513e-01, time/batch = 0.6729s	
24312/33150 (epoch 36.670), train_loss = 0.81076655, grad/param norm = 1.7183e-01, time/batch = 0.6723s	
24313/33150 (epoch 36.671), train_loss = 0.78833937, grad/param norm = 1.8316e-01, time/batch = 0.6735s	
24314/33150 (epoch 36.673), train_loss = 0.97724807, grad/param norm = 1.5611e-01, time/batch = 0.6758s	
24315/33150 (epoch 36.674), train_loss = 0.92715339, grad/param norm = 2.1250e-01, time/batch = 0.6752s	
24316/33150 (epoch 36.676), train_loss = 0.87253398, grad/param norm = 1.8457e-01, time/batch = 0.6756s	
24317/33150 (epoch 36.677), train_loss = 0.99382529, grad/param norm = 2.1265e-01, time/batch = 0.6767s	
24318/33150 (epoch 36.679), train_loss = 0.85663120, grad/param norm = 1.6076e-01, time/batch = 0.6733s	
24319/33150 (epoch 36.680), train_loss = 0.97955620, grad/param norm = 2.0047e-01, time/batch = 0.6780s	
24320/33150 (epoch 36.682), train_loss = 0.86325100, grad/param norm = 1.8361e-01, time/batch = 0.6753s	
24321/33150 (epoch 36.683), train_loss = 0.72798449, grad/param norm = 1.4774e-01, time/batch = 0.6756s	
24322/33150 (epoch 36.685), train_loss = 0.83311939, grad/param norm = 2.1127e-01, time/batch = 0.6736s	
24323/33150 (epoch 36.686), train_loss = 0.72540562, grad/param norm = 1.4698e-01, time/batch = 0.6729s	
24324/33150 (epoch 36.688), train_loss = 0.76031957, grad/param norm = 1.7043e-01, time/batch = 0.6725s	
24325/33150 (epoch 36.689), train_loss = 0.78281365, grad/param norm = 1.5365e-01, time/batch = 0.6733s	
24326/33150 (epoch 36.691), train_loss = 0.68993376, grad/param norm = 1.5555e-01, time/batch = 0.6744s	
24327/33150 (epoch 36.692), train_loss = 0.78558541, grad/param norm = 1.9562e-01, time/batch = 0.6701s	
24328/33150 (epoch 36.694), train_loss = 0.68653078, grad/param norm = 1.5464e-01, time/batch = 0.6720s	
24329/33150 (epoch 36.695), train_loss = 0.79163945, grad/param norm = 1.4788e-01, time/batch = 0.6738s	
24330/33150 (epoch 36.697), train_loss = 0.75899562, grad/param norm = 1.6010e-01, time/batch = 0.6772s	
24331/33150 (epoch 36.698), train_loss = 0.77071882, grad/param norm = 1.7939e-01, time/batch = 0.6700s	
24332/33150 (epoch 36.700), train_loss = 0.65996048, grad/param norm = 1.3973e-01, time/batch = 0.6687s	
24333/33150 (epoch 36.701), train_loss = 0.73546548, grad/param norm = 1.4930e-01, time/batch = 0.6680s	
24334/33150 (epoch 36.703), train_loss = 0.84705246, grad/param norm = 1.7940e-01, time/batch = 0.6685s	
24335/33150 (epoch 36.704), train_loss = 0.73049106, grad/param norm = 1.4989e-01, time/batch = 0.6731s	
24336/33150 (epoch 36.706), train_loss = 0.78750566, grad/param norm = 1.4205e-01, time/batch = 0.6815s	
24337/33150 (epoch 36.707), train_loss = 0.81621506, grad/param norm = 1.7237e-01, time/batch = 0.6752s	
24338/33150 (epoch 36.709), train_loss = 0.86073771, grad/param norm = 1.6517e-01, time/batch = 0.6676s	
24339/33150 (epoch 36.710), train_loss = 0.85481835, grad/param norm = 1.9297e-01, time/batch = 0.6872s	
24340/33150 (epoch 36.712), train_loss = 0.91548848, grad/param norm = 1.6821e-01, time/batch = 0.6890s	
24341/33150 (epoch 36.713), train_loss = 0.87559875, grad/param norm = 1.5633e-01, time/batch = 0.6782s	
24342/33150 (epoch 36.715), train_loss = 0.83278750, grad/param norm = 1.8254e-01, time/batch = 0.6858s	
24343/33150 (epoch 36.716), train_loss = 0.88188899, grad/param norm = 1.7003e-01, time/batch = 0.6760s	
24344/33150 (epoch 36.718), train_loss = 0.85157962, grad/param norm = 1.6545e-01, time/batch = 0.6764s	
24345/33150 (epoch 36.719), train_loss = 0.92716034, grad/param norm = 2.0938e-01, time/batch = 0.6723s	
24346/33150 (epoch 36.721), train_loss = 0.82427573, grad/param norm = 1.8965e-01, time/batch = 0.6732s	
24347/33150 (epoch 36.722), train_loss = 0.88157681, grad/param norm = 1.6292e-01, time/batch = 0.6763s	
24348/33150 (epoch 36.724), train_loss = 0.82028932, grad/param norm = 2.0330e-01, time/batch = 0.6742s	
24349/33150 (epoch 36.725), train_loss = 0.90456046, grad/param norm = 2.1065e-01, time/batch = 0.6709s	
24350/33150 (epoch 36.727), train_loss = 0.91710341, grad/param norm = 2.2333e-01, time/batch = 0.6730s	
24351/33150 (epoch 36.729), train_loss = 0.86601391, grad/param norm = 1.9014e-01, time/batch = 0.6727s	
24352/33150 (epoch 36.730), train_loss = 0.86460260, grad/param norm = 1.8831e-01, time/batch = 0.6731s	
24353/33150 (epoch 36.732), train_loss = 0.90146205, grad/param norm = 2.2787e-01, time/batch = 0.6717s	
24354/33150 (epoch 36.733), train_loss = 0.73521980, grad/param norm = 1.3229e-01, time/batch = 0.6697s	
24355/33150 (epoch 36.735), train_loss = 0.78652254, grad/param norm = 1.7326e-01, time/batch = 0.6740s	
24356/33150 (epoch 36.736), train_loss = 0.80217099, grad/param norm = 1.9508e-01, time/batch = 0.6714s	
24357/33150 (epoch 36.738), train_loss = 0.86714529, grad/param norm = 2.1955e-01, time/batch = 0.6723s	
24358/33150 (epoch 36.739), train_loss = 0.94051215, grad/param norm = 1.9241e-01, time/batch = 0.6720s	
24359/33150 (epoch 36.741), train_loss = 0.88543034, grad/param norm = 2.0227e-01, time/batch = 0.6741s	
24360/33150 (epoch 36.742), train_loss = 0.73702892, grad/param norm = 1.7842e-01, time/batch = 0.6714s	
24361/33150 (epoch 36.744), train_loss = 0.92403442, grad/param norm = 1.9142e-01, time/batch = 0.6770s	
24362/33150 (epoch 36.745), train_loss = 0.80065060, grad/param norm = 1.5270e-01, time/batch = 0.6732s	
24363/33150 (epoch 36.747), train_loss = 0.64197525, grad/param norm = 1.6520e-01, time/batch = 0.6723s	
24364/33150 (epoch 36.748), train_loss = 0.72516373, grad/param norm = 1.8075e-01, time/batch = 0.6717s	
24365/33150 (epoch 36.750), train_loss = 0.88589429, grad/param norm = 1.7194e-01, time/batch = 0.6802s	
24366/33150 (epoch 36.751), train_loss = 0.83326227, grad/param norm = 1.6251e-01, time/batch = 0.6753s	
24367/33150 (epoch 36.753), train_loss = 0.75060952, grad/param norm = 2.6349e-01, time/batch = 0.6707s	
24368/33150 (epoch 36.754), train_loss = 1.03548006, grad/param norm = 2.5785e-01, time/batch = 0.6716s	
24369/33150 (epoch 36.756), train_loss = 0.85110249, grad/param norm = 2.0911e-01, time/batch = 0.6718s	
24370/33150 (epoch 36.757), train_loss = 0.87368934, grad/param norm = 1.6379e-01, time/batch = 0.6705s	
24371/33150 (epoch 36.759), train_loss = 0.99516490, grad/param norm = 2.3172e-01, time/batch = 0.6731s	
24372/33150 (epoch 36.760), train_loss = 0.90140980, grad/param norm = 1.9707e-01, time/batch = 0.6724s	
24373/33150 (epoch 36.762), train_loss = 0.87103668, grad/param norm = 1.9808e-01, time/batch = 0.6742s	
24374/33150 (epoch 36.763), train_loss = 0.89294785, grad/param norm = 1.8367e-01, time/batch = 0.6745s	
24375/33150 (epoch 36.765), train_loss = 0.83914298, grad/param norm = 1.6753e-01, time/batch = 0.6843s	
24376/33150 (epoch 36.766), train_loss = 0.73981927, grad/param norm = 1.6965e-01, time/batch = 0.6972s	
24377/33150 (epoch 36.768), train_loss = 0.76721231, grad/param norm = 1.5408e-01, time/batch = 0.6812s	
24378/33150 (epoch 36.769), train_loss = 0.92326761, grad/param norm = 1.9744e-01, time/batch = 0.6744s	
24379/33150 (epoch 36.771), train_loss = 0.87669515, grad/param norm = 1.8957e-01, time/batch = 0.6703s	
24380/33150 (epoch 36.772), train_loss = 0.90240214, grad/param norm = 1.9470e-01, time/batch = 0.6808s	
24381/33150 (epoch 36.774), train_loss = 0.98414653, grad/param norm = 1.7388e-01, time/batch = 0.6804s	
24382/33150 (epoch 36.775), train_loss = 0.89023161, grad/param norm = 2.0799e-01, time/batch = 0.6742s	
24383/33150 (epoch 36.777), train_loss = 0.92160887, grad/param norm = 1.9328e-01, time/batch = 0.6726s	
24384/33150 (epoch 36.778), train_loss = 0.85296346, grad/param norm = 1.7920e-01, time/batch = 0.6729s	
24385/33150 (epoch 36.780), train_loss = 0.72611613, grad/param norm = 1.6126e-01, time/batch = 0.6736s	
24386/33150 (epoch 36.781), train_loss = 0.85844164, grad/param norm = 1.9104e-01, time/batch = 0.6710s	
24387/33150 (epoch 36.783), train_loss = 0.85831218, grad/param norm = 1.7649e-01, time/batch = 0.6909s	
24388/33150 (epoch 36.784), train_loss = 0.85665726, grad/param norm = 1.8621e-01, time/batch = 0.6895s	
24389/33150 (epoch 36.786), train_loss = 0.83641362, grad/param norm = 1.6013e-01, time/batch = 0.6754s	
24390/33150 (epoch 36.787), train_loss = 0.77931097, grad/param norm = 1.5157e-01, time/batch = 0.6717s	
24391/33150 (epoch 36.789), train_loss = 0.72922386, grad/param norm = 1.5022e-01, time/batch = 0.6843s	
24392/33150 (epoch 36.790), train_loss = 0.73268547, grad/param norm = 1.5803e-01, time/batch = 0.6701s	
24393/33150 (epoch 36.792), train_loss = 0.85827179, grad/param norm = 2.1883e-01, time/batch = 0.6705s	
24394/33150 (epoch 36.793), train_loss = 0.82558780, grad/param norm = 2.0106e-01, time/batch = 0.6692s	
24395/33150 (epoch 36.795), train_loss = 0.79497107, grad/param norm = 1.6669e-01, time/batch = 0.6715s	
24396/33150 (epoch 36.796), train_loss = 0.82490928, grad/param norm = 1.6264e-01, time/batch = 0.6788s	
24397/33150 (epoch 36.798), train_loss = 0.78960760, grad/param norm = 1.5503e-01, time/batch = 0.6913s	
24398/33150 (epoch 36.799), train_loss = 0.71507125, grad/param norm = 2.1134e-01, time/batch = 0.6857s	
24399/33150 (epoch 36.801), train_loss = 0.87717603, grad/param norm = 1.9235e-01, time/batch = 0.6873s	
24400/33150 (epoch 36.802), train_loss = 0.79645936, grad/param norm = 1.5948e-01, time/batch = 0.6899s	
24401/33150 (epoch 36.804), train_loss = 0.83073953, grad/param norm = 1.9040e-01, time/batch = 0.6953s	
24402/33150 (epoch 36.805), train_loss = 0.79364706, grad/param norm = 1.9771e-01, time/batch = 0.6903s	
24403/33150 (epoch 36.807), train_loss = 0.82081910, grad/param norm = 1.5228e-01, time/batch = 0.6764s	
24404/33150 (epoch 36.808), train_loss = 0.93912668, grad/param norm = 1.9039e-01, time/batch = 0.6748s	
24405/33150 (epoch 36.810), train_loss = 0.77498961, grad/param norm = 1.8801e-01, time/batch = 0.6721s	
24406/33150 (epoch 36.811), train_loss = 0.87457868, grad/param norm = 1.9920e-01, time/batch = 0.6705s	
24407/33150 (epoch 36.813), train_loss = 0.80555899, grad/param norm = 1.7074e-01, time/batch = 0.6736s	
24408/33150 (epoch 36.814), train_loss = 0.79515365, grad/param norm = 1.8684e-01, time/batch = 0.6727s	
24409/33150 (epoch 36.816), train_loss = 0.81491439, grad/param norm = 1.9176e-01, time/batch = 0.6774s	
24410/33150 (epoch 36.817), train_loss = 0.88373556, grad/param norm = 1.6423e-01, time/batch = 0.6808s	
24411/33150 (epoch 36.819), train_loss = 0.85823042, grad/param norm = 1.7035e-01, time/batch = 0.6766s	
24412/33150 (epoch 36.821), train_loss = 0.75144188, grad/param norm = 1.5107e-01, time/batch = 0.6738s	
24413/33150 (epoch 36.822), train_loss = 0.78404760, grad/param norm = 1.6731e-01, time/batch = 0.6709s	
24414/33150 (epoch 36.824), train_loss = 0.84990721, grad/param norm = 1.7367e-01, time/batch = 0.6724s	
24415/33150 (epoch 36.825), train_loss = 0.88802396, grad/param norm = 1.8091e-01, time/batch = 0.6721s	
24416/33150 (epoch 36.827), train_loss = 0.90594959, grad/param norm = 2.0998e-01, time/batch = 0.6748s	
24417/33150 (epoch 36.828), train_loss = 0.75213402, grad/param norm = 1.7037e-01, time/batch = 0.6726s	
24418/33150 (epoch 36.830), train_loss = 0.91006266, grad/param norm = 1.9748e-01, time/batch = 0.6743s	
24419/33150 (epoch 36.831), train_loss = 0.78168461, grad/param norm = 1.6142e-01, time/batch = 0.6741s	
24420/33150 (epoch 36.833), train_loss = 0.75137876, grad/param norm = 1.5800e-01, time/batch = 0.6746s	
24421/33150 (epoch 36.834), train_loss = 0.91482792, grad/param norm = 1.6475e-01, time/batch = 0.6741s	
24422/33150 (epoch 36.836), train_loss = 0.94495434, grad/param norm = 1.6064e-01, time/batch = 0.6737s	
24423/33150 (epoch 36.837), train_loss = 0.78233993, grad/param norm = 1.8063e-01, time/batch = 0.6730s	
24424/33150 (epoch 36.839), train_loss = 0.92657298, grad/param norm = 2.3734e-01, time/batch = 0.6740s	
24425/33150 (epoch 36.840), train_loss = 0.89816554, grad/param norm = 1.8153e-01, time/batch = 0.6753s	
24426/33150 (epoch 36.842), train_loss = 0.93370781, grad/param norm = 2.1327e-01, time/batch = 0.6850s	
24427/33150 (epoch 36.843), train_loss = 0.94495583, grad/param norm = 1.8933e-01, time/batch = 0.6848s	
24428/33150 (epoch 36.845), train_loss = 0.78564850, grad/param norm = 1.6362e-01, time/batch = 0.6881s	
24429/33150 (epoch 36.846), train_loss = 1.03531420, grad/param norm = 2.8439e-01, time/batch = 0.6952s	
24430/33150 (epoch 36.848), train_loss = 0.94578745, grad/param norm = 2.0706e-01, time/batch = 0.6833s	
24431/33150 (epoch 36.849), train_loss = 0.95366727, grad/param norm = 1.8366e-01, time/batch = 0.6855s	
24432/33150 (epoch 36.851), train_loss = 0.89153276, grad/param norm = 1.7822e-01, time/batch = 0.6901s	
24433/33150 (epoch 36.852), train_loss = 0.97935592, grad/param norm = 1.7265e-01, time/batch = 0.6931s	
24434/33150 (epoch 36.854), train_loss = 0.89907804, grad/param norm = 1.9053e-01, time/batch = 0.6902s	
24435/33150 (epoch 36.855), train_loss = 0.76222435, grad/param norm = 1.7504e-01, time/batch = 0.6852s	
24436/33150 (epoch 36.857), train_loss = 0.70624900, grad/param norm = 1.8108e-01, time/batch = 0.6759s	
24437/33150 (epoch 36.858), train_loss = 0.83114504, grad/param norm = 1.8505e-01, time/batch = 0.6804s	
24438/33150 (epoch 36.860), train_loss = 0.77756007, grad/param norm = 1.6635e-01, time/batch = 0.6776s	
24439/33150 (epoch 36.861), train_loss = 0.75319986, grad/param norm = 1.4518e-01, time/batch = 0.6868s	
24440/33150 (epoch 36.863), train_loss = 0.82978774, grad/param norm = 1.6993e-01, time/batch = 0.6871s	
24441/33150 (epoch 36.864), train_loss = 0.86671940, grad/param norm = 1.6287e-01, time/batch = 0.6839s	
24442/33150 (epoch 36.866), train_loss = 0.90567965, grad/param norm = 1.7565e-01, time/batch = 0.7035s	
24443/33150 (epoch 36.867), train_loss = 0.86198628, grad/param norm = 1.5977e-01, time/batch = 0.6952s	
24444/33150 (epoch 36.869), train_loss = 0.85523296, grad/param norm = 1.8476e-01, time/batch = 0.6857s	
24445/33150 (epoch 36.870), train_loss = 0.80357012, grad/param norm = 1.7844e-01, time/batch = 0.6863s	
24446/33150 (epoch 36.872), train_loss = 0.89129364, grad/param norm = 1.9913e-01, time/batch = 0.6979s	
24447/33150 (epoch 36.873), train_loss = 0.68917522, grad/param norm = 1.4999e-01, time/batch = 0.6949s	
24448/33150 (epoch 36.875), train_loss = 0.93615095, grad/param norm = 1.6280e-01, time/batch = 0.6926s	
24449/33150 (epoch 36.876), train_loss = 0.70436272, grad/param norm = 1.4392e-01, time/batch = 0.6824s	
24450/33150 (epoch 36.878), train_loss = 0.79381039, grad/param norm = 1.4773e-01, time/batch = 0.6739s	
24451/33150 (epoch 36.879), train_loss = 0.77735568, grad/param norm = 1.4939e-01, time/batch = 0.6757s	
24452/33150 (epoch 36.881), train_loss = 0.77977014, grad/param norm = 2.0838e-01, time/batch = 0.6844s	
24453/33150 (epoch 36.882), train_loss = 0.65896467, grad/param norm = 1.5067e-01, time/batch = 0.6824s	
24454/33150 (epoch 36.884), train_loss = 0.79264705, grad/param norm = 1.5487e-01, time/batch = 0.6747s	
24455/33150 (epoch 36.885), train_loss = 0.63341485, grad/param norm = 1.6207e-01, time/batch = 0.6886s	
24456/33150 (epoch 36.887), train_loss = 0.91427321, grad/param norm = 1.8694e-01, time/batch = 0.6911s	
24457/33150 (epoch 36.888), train_loss = 0.85790209, grad/param norm = 1.7920e-01, time/batch = 0.6889s	
24458/33150 (epoch 36.890), train_loss = 0.77588111, grad/param norm = 2.1512e-01, time/batch = 0.6867s	
24459/33150 (epoch 36.891), train_loss = 0.76009009, grad/param norm = 1.7233e-01, time/batch = 0.6842s	
24460/33150 (epoch 36.893), train_loss = 0.89031333, grad/param norm = 1.9461e-01, time/batch = 0.6678s	
24461/33150 (epoch 36.894), train_loss = 0.86627431, grad/param norm = 1.5370e-01, time/batch = 0.6734s	
24462/33150 (epoch 36.896), train_loss = 0.81902257, grad/param norm = 1.4830e-01, time/batch = 0.6720s	
24463/33150 (epoch 36.897), train_loss = 0.88642396, grad/param norm = 1.6963e-01, time/batch = 0.6735s	
24464/33150 (epoch 36.899), train_loss = 0.70419327, grad/param norm = 1.9312e-01, time/batch = 0.6736s	
24465/33150 (epoch 36.900), train_loss = 1.00107397, grad/param norm = 1.9198e-01, time/batch = 0.6703s	
24466/33150 (epoch 36.902), train_loss = 1.05379414, grad/param norm = 1.8505e-01, time/batch = 0.6673s	
24467/33150 (epoch 36.903), train_loss = 0.84792243, grad/param norm = 1.8001e-01, time/batch = 0.6718s	
24468/33150 (epoch 36.905), train_loss = 0.84430053, grad/param norm = 1.6000e-01, time/batch = 0.6696s	
24469/33150 (epoch 36.906), train_loss = 0.85644132, grad/param norm = 1.8633e-01, time/batch = 0.6702s	
24470/33150 (epoch 36.908), train_loss = 0.91552916, grad/param norm = 1.8643e-01, time/batch = 0.6795s	
24471/33150 (epoch 36.910), train_loss = 0.92772801, grad/param norm = 1.9677e-01, time/batch = 0.6754s	
24472/33150 (epoch 36.911), train_loss = 0.73165494, grad/param norm = 1.5488e-01, time/batch = 0.6864s	
24473/33150 (epoch 36.913), train_loss = 0.79049564, grad/param norm = 1.7530e-01, time/batch = 0.6896s	
24474/33150 (epoch 36.914), train_loss = 0.86320228, grad/param norm = 1.8987e-01, time/batch = 0.6744s	
24475/33150 (epoch 36.916), train_loss = 0.78240281, grad/param norm = 1.6666e-01, time/batch = 0.6745s	
24476/33150 (epoch 36.917), train_loss = 0.87271968, grad/param norm = 1.6112e-01, time/batch = 0.6806s	
24477/33150 (epoch 36.919), train_loss = 0.97868192, grad/param norm = 2.6179e-01, time/batch = 0.6706s	
24478/33150 (epoch 36.920), train_loss = 0.94710751, grad/param norm = 1.9320e-01, time/batch = 0.6774s	
24479/33150 (epoch 36.922), train_loss = 0.99216440, grad/param norm = 2.1056e-01, time/batch = 0.6760s	
24480/33150 (epoch 36.923), train_loss = 0.86500797, grad/param norm = 2.0680e-01, time/batch = 0.6699s	
24481/33150 (epoch 36.925), train_loss = 0.94029511, grad/param norm = 1.6251e-01, time/batch = 0.6692s	
24482/33150 (epoch 36.926), train_loss = 0.83406463, grad/param norm = 1.8908e-01, time/batch = 0.6679s	
24483/33150 (epoch 36.928), train_loss = 0.81463706, grad/param norm = 1.7786e-01, time/batch = 0.6724s	
24484/33150 (epoch 36.929), train_loss = 0.91204603, grad/param norm = 1.6906e-01, time/batch = 0.6802s	
24485/33150 (epoch 36.931), train_loss = 0.95603343, grad/param norm = 1.8326e-01, time/batch = 0.6999s	
24486/33150 (epoch 36.932), train_loss = 0.86455913, grad/param norm = 1.8361e-01, time/batch = 0.6897s	
24487/33150 (epoch 36.934), train_loss = 0.87157769, grad/param norm = 1.5490e-01, time/batch = 0.6879s	
24488/33150 (epoch 36.935), train_loss = 0.94098232, grad/param norm = 1.7827e-01, time/batch = 0.6916s	
24489/33150 (epoch 36.937), train_loss = 0.97179105, grad/param norm = 1.7934e-01, time/batch = 0.6890s	
24490/33150 (epoch 36.938), train_loss = 0.87248109, grad/param norm = 1.7483e-01, time/batch = 0.7055s	
24491/33150 (epoch 36.940), train_loss = 1.07097883, grad/param norm = 2.0757e-01, time/batch = 0.7027s	
24492/33150 (epoch 36.941), train_loss = 0.89180311, grad/param norm = 1.6678e-01, time/batch = 0.7040s	
24493/33150 (epoch 36.943), train_loss = 0.70589995, grad/param norm = 1.5809e-01, time/batch = 0.7075s	
24494/33150 (epoch 36.944), train_loss = 0.90262580, grad/param norm = 1.9561e-01, time/batch = 0.7060s	
24495/33150 (epoch 36.946), train_loss = 0.74592858, grad/param norm = 1.6034e-01, time/batch = 0.6788s	
24496/33150 (epoch 36.947), train_loss = 0.88328956, grad/param norm = 1.7595e-01, time/batch = 0.6707s	
24497/33150 (epoch 36.949), train_loss = 0.96044533, grad/param norm = 1.7959e-01, time/batch = 0.6677s	
24498/33150 (epoch 36.950), train_loss = 0.93887176, grad/param norm = 1.9700e-01, time/batch = 0.6704s	
24499/33150 (epoch 36.952), train_loss = 0.77848052, grad/param norm = 1.6181e-01, time/batch = 0.6721s	
24500/33150 (epoch 36.953), train_loss = 0.85932482, grad/param norm = 1.6276e-01, time/batch = 0.6714s	
24501/33150 (epoch 36.955), train_loss = 0.75444461, grad/param norm = 2.5425e-01, time/batch = 0.6720s	
24502/33150 (epoch 36.956), train_loss = 0.93708611, grad/param norm = 1.9956e-01, time/batch = 0.6707s	
24503/33150 (epoch 36.958), train_loss = 0.77607061, grad/param norm = 1.6355e-01, time/batch = 0.6818s	
24504/33150 (epoch 36.959), train_loss = 0.83858607, grad/param norm = 1.5670e-01, time/batch = 0.6818s	
24505/33150 (epoch 36.961), train_loss = 0.78405311, grad/param norm = 1.7212e-01, time/batch = 0.6756s	
24506/33150 (epoch 36.962), train_loss = 0.74067109, grad/param norm = 1.5925e-01, time/batch = 0.6659s	
24507/33150 (epoch 36.964), train_loss = 0.84570884, grad/param norm = 1.8147e-01, time/batch = 0.6669s	
24508/33150 (epoch 36.965), train_loss = 0.82660062, grad/param norm = 1.6943e-01, time/batch = 0.6696s	
24509/33150 (epoch 36.967), train_loss = 0.83012547, grad/param norm = 1.7170e-01, time/batch = 0.6683s	
24510/33150 (epoch 36.968), train_loss = 0.71245277, grad/param norm = 1.4551e-01, time/batch = 0.6659s	
24511/33150 (epoch 36.970), train_loss = 0.80494525, grad/param norm = 1.7462e-01, time/batch = 0.6660s	
24512/33150 (epoch 36.971), train_loss = 0.84537257, grad/param norm = 1.6959e-01, time/batch = 0.6718s	
24513/33150 (epoch 36.973), train_loss = 0.92631356, grad/param norm = 1.8371e-01, time/batch = 0.6704s	
24514/33150 (epoch 36.974), train_loss = 0.96883204, grad/param norm = 1.9440e-01, time/batch = 0.6733s	
24515/33150 (epoch 36.976), train_loss = 0.94586984, grad/param norm = 1.8072e-01, time/batch = 0.6880s	
24516/33150 (epoch 36.977), train_loss = 0.96429991, grad/param norm = 1.7944e-01, time/batch = 0.6867s	
24517/33150 (epoch 36.979), train_loss = 0.93752884, grad/param norm = 2.1792e-01, time/batch = 0.6904s	
24518/33150 (epoch 36.980), train_loss = 1.00321868, grad/param norm = 1.9271e-01, time/batch = 0.6892s	
24519/33150 (epoch 36.982), train_loss = 0.83843765, grad/param norm = 1.8388e-01, time/batch = 0.7019s	
24520/33150 (epoch 36.983), train_loss = 0.75639973, grad/param norm = 1.7033e-01, time/batch = 0.6999s	
24521/33150 (epoch 36.985), train_loss = 0.95913674, grad/param norm = 1.7618e-01, time/batch = 0.6957s	
24522/33150 (epoch 36.986), train_loss = 0.72267814, grad/param norm = 1.4482e-01, time/batch = 0.6859s	
24523/33150 (epoch 36.988), train_loss = 0.81034041, grad/param norm = 2.1091e-01, time/batch = 0.6830s	
24524/33150 (epoch 36.989), train_loss = 0.82647354, grad/param norm = 1.5466e-01, time/batch = 0.6843s	
24525/33150 (epoch 36.991), train_loss = 0.90937121, grad/param norm = 2.6452e-01, time/batch = 0.6852s	
24526/33150 (epoch 36.992), train_loss = 0.84987939, grad/param norm = 1.9359e-01, time/batch = 0.6896s	
24527/33150 (epoch 36.994), train_loss = 0.86630759, grad/param norm = 1.6421e-01, time/batch = 0.6866s	
24528/33150 (epoch 36.995), train_loss = 0.82641216, grad/param norm = 1.7441e-01, time/batch = 0.6849s	
24529/33150 (epoch 36.997), train_loss = 0.85057158, grad/param norm = 2.1267e-01, time/batch = 0.6831s	
24530/33150 (epoch 36.998), train_loss = 0.72465322, grad/param norm = 1.7698e-01, time/batch = 0.6836s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
24531/33150 (epoch 37.000), train_loss = 0.74834961, grad/param norm = 1.9493e-01, time/batch = 0.6843s	
24532/33150 (epoch 37.002), train_loss = 1.16932558, grad/param norm = 1.9862e-01, time/batch = 0.6829s	
24533/33150 (epoch 37.003), train_loss = 0.76683729, grad/param norm = 1.6651e-01, time/batch = 0.6821s	
24534/33150 (epoch 37.005), train_loss = 0.73304772, grad/param norm = 1.4429e-01, time/batch = 0.6812s	
24535/33150 (epoch 37.006), train_loss = 0.71174704, grad/param norm = 1.6912e-01, time/batch = 0.6809s	
24536/33150 (epoch 37.008), train_loss = 0.88992951, grad/param norm = 1.8071e-01, time/batch = 0.6844s	
24537/33150 (epoch 37.009), train_loss = 0.88093377, grad/param norm = 1.6207e-01, time/batch = 0.6874s	
24538/33150 (epoch 37.011), train_loss = 0.93313489, grad/param norm = 1.8710e-01, time/batch = 0.6894s	
24539/33150 (epoch 37.012), train_loss = 0.83518945, grad/param norm = 2.2109e-01, time/batch = 0.6837s	
24540/33150 (epoch 37.014), train_loss = 0.76284138, grad/param norm = 1.7011e-01, time/batch = 0.6750s	
24541/33150 (epoch 37.015), train_loss = 0.77450749, grad/param norm = 1.8665e-01, time/batch = 0.6884s	
24542/33150 (epoch 37.017), train_loss = 0.76512641, grad/param norm = 1.5377e-01, time/batch = 0.6839s	
24543/33150 (epoch 37.018), train_loss = 0.86754766, grad/param norm = 1.8331e-01, time/batch = 0.6800s	
24544/33150 (epoch 37.020), train_loss = 0.93262533, grad/param norm = 2.1802e-01, time/batch = 0.6792s	
24545/33150 (epoch 37.021), train_loss = 0.75101592, grad/param norm = 1.7455e-01, time/batch = 0.6803s	
24546/33150 (epoch 37.023), train_loss = 1.03098839, grad/param norm = 1.7797e-01, time/batch = 0.6835s	
24547/33150 (epoch 37.024), train_loss = 0.90119454, grad/param norm = 1.8372e-01, time/batch = 0.6766s	
24548/33150 (epoch 37.026), train_loss = 0.68361794, grad/param norm = 1.5899e-01, time/batch = 0.6809s	
24549/33150 (epoch 37.027), train_loss = 0.67437571, grad/param norm = 1.4600e-01, time/batch = 0.6838s	
24550/33150 (epoch 37.029), train_loss = 0.77727356, grad/param norm = 1.6011e-01, time/batch = 0.6891s	
24551/33150 (epoch 37.030), train_loss = 0.81448081, grad/param norm = 1.5243e-01, time/batch = 0.6858s	
24552/33150 (epoch 37.032), train_loss = 0.74737924, grad/param norm = 1.9757e-01, time/batch = 0.6831s	
24553/33150 (epoch 37.033), train_loss = 0.76725828, grad/param norm = 1.5889e-01, time/batch = 0.6833s	
24554/33150 (epoch 37.035), train_loss = 1.01067992, grad/param norm = 1.8920e-01, time/batch = 0.7036s	
24555/33150 (epoch 37.036), train_loss = 0.91464788, grad/param norm = 1.8495e-01, time/batch = 0.6683s	
24556/33150 (epoch 37.038), train_loss = 1.03788629, grad/param norm = 1.9173e-01, time/batch = 0.6662s	
24557/33150 (epoch 37.039), train_loss = 0.91391145, grad/param norm = 1.7224e-01, time/batch = 0.6667s	
24558/33150 (epoch 37.041), train_loss = 0.83266042, grad/param norm = 1.5881e-01, time/batch = 0.6726s	
24559/33150 (epoch 37.042), train_loss = 0.79032956, grad/param norm = 1.7815e-01, time/batch = 0.6898s	
24560/33150 (epoch 37.044), train_loss = 0.84373088, grad/param norm = 1.7375e-01, time/batch = 0.6958s	
24561/33150 (epoch 37.045), train_loss = 0.90619859, grad/param norm = 1.5275e-01, time/batch = 0.6962s	
24562/33150 (epoch 37.047), train_loss = 0.76451811, grad/param norm = 1.4896e-01, time/batch = 0.6973s	
24563/33150 (epoch 37.048), train_loss = 0.95172389, grad/param norm = 2.1002e-01, time/batch = 0.6945s	
24564/33150 (epoch 37.050), train_loss = 0.83301389, grad/param norm = 1.7784e-01, time/batch = 0.6880s	
24565/33150 (epoch 37.051), train_loss = 0.87054570, grad/param norm = 1.7391e-01, time/batch = 0.6952s	
24566/33150 (epoch 37.053), train_loss = 0.87917130, grad/param norm = 1.6927e-01, time/batch = 0.6909s	
24567/33150 (epoch 37.054), train_loss = 0.98971123, grad/param norm = 1.7861e-01, time/batch = 0.6894s	
24568/33150 (epoch 37.056), train_loss = 0.83053462, grad/param norm = 1.7511e-01, time/batch = 0.6905s	
24569/33150 (epoch 37.057), train_loss = 0.90048000, grad/param norm = 1.6726e-01, time/batch = 0.6920s	
24570/33150 (epoch 37.059), train_loss = 0.76432944, grad/param norm = 1.6552e-01, time/batch = 0.6904s	
24571/33150 (epoch 37.060), train_loss = 0.75119554, grad/param norm = 1.4846e-01, time/batch = 0.6953s	
24572/33150 (epoch 37.062), train_loss = 0.84091177, grad/param norm = 1.8035e-01, time/batch = 0.6938s	
24573/33150 (epoch 37.063), train_loss = 0.76713582, grad/param norm = 1.6079e-01, time/batch = 0.6930s	
24574/33150 (epoch 37.065), train_loss = 0.81657615, grad/param norm = 1.6015e-01, time/batch = 0.6899s	
24575/33150 (epoch 37.066), train_loss = 0.81917588, grad/param norm = 1.6079e-01, time/batch = 0.6871s	
24576/33150 (epoch 37.068), train_loss = 0.88766076, grad/param norm = 1.7499e-01, time/batch = 0.6870s	
24577/33150 (epoch 37.069), train_loss = 0.88767571, grad/param norm = 2.0237e-01, time/batch = 0.6929s	
24578/33150 (epoch 37.071), train_loss = 0.86685454, grad/param norm = 1.6701e-01, time/batch = 0.6940s	
24579/33150 (epoch 37.072), train_loss = 0.87900757, grad/param norm = 1.9154e-01, time/batch = 0.6963s	
24580/33150 (epoch 37.074), train_loss = 0.73916618, grad/param norm = 2.0013e-01, time/batch = 0.6974s	
24581/33150 (epoch 37.075), train_loss = 0.75266442, grad/param norm = 1.6714e-01, time/batch = 0.6953s	
24582/33150 (epoch 37.077), train_loss = 0.89178940, grad/param norm = 2.4366e-01, time/batch = 0.6887s	
24583/33150 (epoch 37.078), train_loss = 0.97242114, grad/param norm = 1.9607e-01, time/batch = 0.6791s	
24584/33150 (epoch 37.080), train_loss = 0.98942739, grad/param norm = 1.7829e-01, time/batch = 0.6768s	
24585/33150 (epoch 37.081), train_loss = 0.75678862, grad/param norm = 1.8978e-01, time/batch = 0.6803s	
24586/33150 (epoch 37.083), train_loss = 0.63921178, grad/param norm = 2.1854e-01, time/batch = 0.6691s	
24587/33150 (epoch 37.084), train_loss = 0.72920762, grad/param norm = 1.9786e-01, time/batch = 0.6710s	
24588/33150 (epoch 37.086), train_loss = 0.77763175, grad/param norm = 2.1077e-01, time/batch = 0.6716s	
24589/33150 (epoch 37.087), train_loss = 0.72245929, grad/param norm = 1.6886e-01, time/batch = 0.6679s	
24590/33150 (epoch 37.089), train_loss = 0.77322766, grad/param norm = 1.6390e-01, time/batch = 0.6680s	
24591/33150 (epoch 37.090), train_loss = 0.80114288, grad/param norm = 1.6379e-01, time/batch = 0.6681s	
24592/33150 (epoch 37.092), train_loss = 0.77898201, grad/param norm = 1.7502e-01, time/batch = 0.6703s	
24593/33150 (epoch 37.094), train_loss = 0.86625784, grad/param norm = 1.8713e-01, time/batch = 0.6644s	
24594/33150 (epoch 37.095), train_loss = 0.76332095, grad/param norm = 1.5546e-01, time/batch = 0.6670s	
24595/33150 (epoch 37.097), train_loss = 0.71804910, grad/param norm = 1.5577e-01, time/batch = 0.6661s	
24596/33150 (epoch 37.098), train_loss = 1.06305884, grad/param norm = 1.8928e-01, time/batch = 0.6657s	
24597/33150 (epoch 37.100), train_loss = 1.04179307, grad/param norm = 1.9128e-01, time/batch = 0.6675s	
24598/33150 (epoch 37.101), train_loss = 0.81285965, grad/param norm = 1.8469e-01, time/batch = 0.6670s	
24599/33150 (epoch 37.103), train_loss = 0.85486415, grad/param norm = 1.6327e-01, time/batch = 0.6661s	
24600/33150 (epoch 37.104), train_loss = 0.78502980, grad/param norm = 1.8090e-01, time/batch = 0.6692s	
24601/33150 (epoch 37.106), train_loss = 0.93826614, grad/param norm = 1.8158e-01, time/batch = 0.6706s	
24602/33150 (epoch 37.107), train_loss = 1.03938540, grad/param norm = 2.2920e-01, time/batch = 0.6824s	
24603/33150 (epoch 37.109), train_loss = 0.83293624, grad/param norm = 1.5325e-01, time/batch = 0.6905s	
24604/33150 (epoch 37.110), train_loss = 0.95884236, grad/param norm = 1.9792e-01, time/batch = 0.7004s	
24605/33150 (epoch 37.112), train_loss = 0.76993973, grad/param norm = 1.7535e-01, time/batch = 0.6840s	
24606/33150 (epoch 37.113), train_loss = 0.82056508, grad/param norm = 1.9862e-01, time/batch = 0.6713s	
24607/33150 (epoch 37.115), train_loss = 1.01427372, grad/param norm = 2.3770e-01, time/batch = 0.6681s	
24608/33150 (epoch 37.116), train_loss = 0.90831649, grad/param norm = 1.8097e-01, time/batch = 0.6670s	
24609/33150 (epoch 37.118), train_loss = 0.88149249, grad/param norm = 2.0336e-01, time/batch = 0.6832s	
24610/33150 (epoch 37.119), train_loss = 0.87199978, grad/param norm = 2.0300e-01, time/batch = 0.6896s	
24611/33150 (epoch 37.121), train_loss = 0.82137327, grad/param norm = 1.6435e-01, time/batch = 0.6657s	
24612/33150 (epoch 37.122), train_loss = 1.00682542, grad/param norm = 2.4444e-01, time/batch = 0.6726s	
24613/33150 (epoch 37.124), train_loss = 0.71342258, grad/param norm = 1.5902e-01, time/batch = 0.6714s	
24614/33150 (epoch 37.125), train_loss = 0.96640815, grad/param norm = 1.7492e-01, time/batch = 0.6739s	
24615/33150 (epoch 37.127), train_loss = 0.88577043, grad/param norm = 1.7707e-01, time/batch = 0.7001s	
24616/33150 (epoch 37.128), train_loss = 0.88589029, grad/param norm = 1.9834e-01, time/batch = 0.6731s	
24617/33150 (epoch 37.130), train_loss = 0.84955861, grad/param norm = 1.6421e-01, time/batch = 0.6677s	
24618/33150 (epoch 37.131), train_loss = 1.03440673, grad/param norm = 1.8506e-01, time/batch = 0.6725s	
24619/33150 (epoch 37.133), train_loss = 0.80566314, grad/param norm = 1.6646e-01, time/batch = 0.6758s	
24620/33150 (epoch 37.134), train_loss = 0.96128642, grad/param norm = 1.8042e-01, time/batch = 0.6743s	
24621/33150 (epoch 37.136), train_loss = 0.88357998, grad/param norm = 2.0213e-01, time/batch = 0.6712s	
24622/33150 (epoch 37.137), train_loss = 0.92181670, grad/param norm = 1.7036e-01, time/batch = 0.6729s	
24623/33150 (epoch 37.139), train_loss = 0.91643379, grad/param norm = 2.2098e-01, time/batch = 0.6768s	
24624/33150 (epoch 37.140), train_loss = 1.02564273, grad/param norm = 2.1958e-01, time/batch = 0.6803s	
24625/33150 (epoch 37.142), train_loss = 0.90643523, grad/param norm = 1.8490e-01, time/batch = 0.6820s	
24626/33150 (epoch 37.143), train_loss = 0.86109386, grad/param norm = 2.1047e-01, time/batch = 0.6767s	
24627/33150 (epoch 37.145), train_loss = 0.81289060, grad/param norm = 1.9487e-01, time/batch = 0.6723s	
24628/33150 (epoch 37.146), train_loss = 0.95783560, grad/param norm = 2.0661e-01, time/batch = 0.6821s	
24629/33150 (epoch 37.148), train_loss = 0.99608650, grad/param norm = 1.6620e-01, time/batch = 0.6727s	
24630/33150 (epoch 37.149), train_loss = 0.86852013, grad/param norm = 1.8138e-01, time/batch = 0.6814s	
24631/33150 (epoch 37.151), train_loss = 1.02612231, grad/param norm = 1.9853e-01, time/batch = 0.6730s	
24632/33150 (epoch 37.152), train_loss = 0.78775714, grad/param norm = 1.4984e-01, time/batch = 0.6695s	
24633/33150 (epoch 37.154), train_loss = 0.80806885, grad/param norm = 2.0283e-01, time/batch = 0.6709s	
24634/33150 (epoch 37.155), train_loss = 0.73058303, grad/param norm = 1.6765e-01, time/batch = 0.6674s	
24635/33150 (epoch 37.157), train_loss = 0.85558815, grad/param norm = 1.9808e-01, time/batch = 0.6689s	
24636/33150 (epoch 37.158), train_loss = 0.82873596, grad/param norm = 1.7569e-01, time/batch = 0.6682s	
24637/33150 (epoch 37.160), train_loss = 0.91679646, grad/param norm = 1.6935e-01, time/batch = 0.6692s	
24638/33150 (epoch 37.161), train_loss = 0.82583285, grad/param norm = 2.0923e-01, time/batch = 0.6673s	
24639/33150 (epoch 37.163), train_loss = 0.76163774, grad/param norm = 1.6251e-01, time/batch = 0.6799s	
24640/33150 (epoch 37.164), train_loss = 0.88271016, grad/param norm = 1.7001e-01, time/batch = 0.6753s	
24641/33150 (epoch 37.166), train_loss = 0.82532643, grad/param norm = 1.7112e-01, time/batch = 0.6761s	
24642/33150 (epoch 37.167), train_loss = 0.87819672, grad/param norm = 1.6284e-01, time/batch = 0.6706s	
24643/33150 (epoch 37.169), train_loss = 0.85907991, grad/param norm = 2.1427e-01, time/batch = 0.6703s	
24644/33150 (epoch 37.170), train_loss = 0.78208834, grad/param norm = 1.8579e-01, time/batch = 0.6711s	
24645/33150 (epoch 37.172), train_loss = 0.90972801, grad/param norm = 2.2588e-01, time/batch = 0.6683s	
24646/33150 (epoch 37.173), train_loss = 0.87443335, grad/param norm = 1.8204e-01, time/batch = 0.6695s	
24647/33150 (epoch 37.175), train_loss = 0.82805772, grad/param norm = 2.0542e-01, time/batch = 0.6675s	
24648/33150 (epoch 37.176), train_loss = 0.90519104, grad/param norm = 1.9281e-01, time/batch = 0.6696s	
24649/33150 (epoch 37.178), train_loss = 1.05051435, grad/param norm = 2.2405e-01, time/batch = 0.6722s	
24650/33150 (epoch 37.179), train_loss = 0.92072490, grad/param norm = 1.6073e-01, time/batch = 0.6710s	
24651/33150 (epoch 37.181), train_loss = 0.88442243, grad/param norm = 2.1634e-01, time/batch = 0.6703s	
24652/33150 (epoch 37.183), train_loss = 0.85877408, grad/param norm = 2.1597e-01, time/batch = 0.6716s	
24653/33150 (epoch 37.184), train_loss = 1.10488541, grad/param norm = 1.9611e-01, time/batch = 0.6727s	
24654/33150 (epoch 37.186), train_loss = 1.02013255, grad/param norm = 1.6930e-01, time/batch = 0.6678s	
24655/33150 (epoch 37.187), train_loss = 0.88509888, grad/param norm = 1.7918e-01, time/batch = 0.6675s	
24656/33150 (epoch 37.189), train_loss = 0.68800309, grad/param norm = 1.7329e-01, time/batch = 0.6727s	
24657/33150 (epoch 37.190), train_loss = 0.77346515, grad/param norm = 1.8188e-01, time/batch = 0.6704s	
24658/33150 (epoch 37.192), train_loss = 0.89000064, grad/param norm = 1.8819e-01, time/batch = 0.6739s	
24659/33150 (epoch 37.193), train_loss = 0.94452431, grad/param norm = 1.8456e-01, time/batch = 0.6764s	
24660/33150 (epoch 37.195), train_loss = 1.05851848, grad/param norm = 1.8819e-01, time/batch = 0.6685s	
24661/33150 (epoch 37.196), train_loss = 0.97410124, grad/param norm = 1.7310e-01, time/batch = 0.6694s	
24662/33150 (epoch 37.198), train_loss = 0.75760774, grad/param norm = 1.5427e-01, time/batch = 0.6690s	
24663/33150 (epoch 37.199), train_loss = 0.94896491, grad/param norm = 2.2191e-01, time/batch = 0.6759s	
24664/33150 (epoch 37.201), train_loss = 0.83163177, grad/param norm = 1.8050e-01, time/batch = 0.6724s	
24665/33150 (epoch 37.202), train_loss = 0.68635663, grad/param norm = 1.5570e-01, time/batch = 0.6688s	
24666/33150 (epoch 37.204), train_loss = 0.90243917, grad/param norm = 1.9268e-01, time/batch = 0.6687s	
24667/33150 (epoch 37.205), train_loss = 0.89463570, grad/param norm = 1.8912e-01, time/batch = 0.6680s	
24668/33150 (epoch 37.207), train_loss = 0.90590375, grad/param norm = 1.7509e-01, time/batch = 0.6683s	
24669/33150 (epoch 37.208), train_loss = 0.92943921, grad/param norm = 1.8258e-01, time/batch = 0.6720s	
24670/33150 (epoch 37.210), train_loss = 0.81720256, grad/param norm = 1.6318e-01, time/batch = 0.6793s	
24671/33150 (epoch 37.211), train_loss = 0.85974607, grad/param norm = 1.9676e-01, time/batch = 0.6676s	
24672/33150 (epoch 37.213), train_loss = 0.93802350, grad/param norm = 1.8767e-01, time/batch = 0.6667s	
24673/33150 (epoch 37.214), train_loss = 0.83901331, grad/param norm = 1.7921e-01, time/batch = 0.6674s	
24674/33150 (epoch 37.216), train_loss = 0.76378063, grad/param norm = 1.7667e-01, time/batch = 0.6669s	
24675/33150 (epoch 37.217), train_loss = 0.86005899, grad/param norm = 1.8367e-01, time/batch = 0.6676s	
24676/33150 (epoch 37.219), train_loss = 0.78907668, grad/param norm = 1.7484e-01, time/batch = 0.6685s	
24677/33150 (epoch 37.220), train_loss = 0.81921869, grad/param norm = 1.4769e-01, time/batch = 0.6663s	
24678/33150 (epoch 37.222), train_loss = 0.96274891, grad/param norm = 1.9326e-01, time/batch = 0.6667s	
24679/33150 (epoch 37.223), train_loss = 0.86118953, grad/param norm = 1.8221e-01, time/batch = 0.6675s	
24680/33150 (epoch 37.225), train_loss = 0.97095345, grad/param norm = 1.6831e-01, time/batch = 0.6671s	
24681/33150 (epoch 37.226), train_loss = 0.82888430, grad/param norm = 1.6424e-01, time/batch = 0.6708s	
24682/33150 (epoch 37.228), train_loss = 0.83231764, grad/param norm = 1.9251e-01, time/batch = 0.6671s	
24683/33150 (epoch 37.229), train_loss = 0.85709320, grad/param norm = 1.8355e-01, time/batch = 0.6701s	
24684/33150 (epoch 37.231), train_loss = 0.96484934, grad/param norm = 2.0620e-01, time/batch = 0.6768s	
24685/33150 (epoch 37.232), train_loss = 0.85026984, grad/param norm = 1.9732e-01, time/batch = 0.6661s	
24686/33150 (epoch 37.234), train_loss = 0.88842438, grad/param norm = 1.9855e-01, time/batch = 0.6672s	
24687/33150 (epoch 37.235), train_loss = 0.91925507, grad/param norm = 2.3467e-01, time/batch = 0.6688s	
24688/33150 (epoch 37.237), train_loss = 0.90601264, grad/param norm = 2.8606e-01, time/batch = 0.6687s	
24689/33150 (epoch 37.238), train_loss = 0.91880562, grad/param norm = 2.0437e-01, time/batch = 0.6705s	
24690/33150 (epoch 37.240), train_loss = 0.89794256, grad/param norm = 1.8816e-01, time/batch = 0.6689s	
24691/33150 (epoch 37.241), train_loss = 0.94663995, grad/param norm = 2.0550e-01, time/batch = 0.6856s	
24692/33150 (epoch 37.243), train_loss = 0.93581186, grad/param norm = 1.8939e-01, time/batch = 0.6845s	
24693/33150 (epoch 37.244), train_loss = 0.89147045, grad/param norm = 1.8156e-01, time/batch = 0.6962s	
24694/33150 (epoch 37.246), train_loss = 0.95743758, grad/param norm = 1.7382e-01, time/batch = 0.6676s	
24695/33150 (epoch 37.247), train_loss = 0.81647456, grad/param norm = 1.6960e-01, time/batch = 0.6625s	
24696/33150 (epoch 37.249), train_loss = 0.97589987, grad/param norm = 1.7725e-01, time/batch = 0.6626s	
24697/33150 (epoch 37.250), train_loss = 0.92304802, grad/param norm = 1.6680e-01, time/batch = 0.6617s	
24698/33150 (epoch 37.252), train_loss = 0.92699322, grad/param norm = 1.6024e-01, time/batch = 0.6597s	
24699/33150 (epoch 37.253), train_loss = 0.83943309, grad/param norm = 1.7158e-01, time/batch = 0.6646s	
24700/33150 (epoch 37.255), train_loss = 0.85151474, grad/param norm = 1.4910e-01, time/batch = 0.6676s	
24701/33150 (epoch 37.256), train_loss = 0.97733609, grad/param norm = 1.8020e-01, time/batch = 0.6916s	
24702/33150 (epoch 37.258), train_loss = 0.81015316, grad/param norm = 1.6932e-01, time/batch = 0.6727s	
24703/33150 (epoch 37.259), train_loss = 0.72862010, grad/param norm = 2.0344e-01, time/batch = 0.6816s	
24704/33150 (epoch 37.261), train_loss = 0.77891652, grad/param norm = 1.5816e-01, time/batch = 0.6811s	
24705/33150 (epoch 37.262), train_loss = 0.99384356, grad/param norm = 2.1608e-01, time/batch = 0.6679s	
24706/33150 (epoch 37.264), train_loss = 0.68535941, grad/param norm = 1.5615e-01, time/batch = 0.6670s	
24707/33150 (epoch 37.265), train_loss = 0.87543580, grad/param norm = 1.9349e-01, time/batch = 0.6654s	
24708/33150 (epoch 37.267), train_loss = 0.97018784, grad/param norm = 2.3066e-01, time/batch = 0.6722s	
24709/33150 (epoch 37.268), train_loss = 0.99639883, grad/param norm = 1.7278e-01, time/batch = 0.6664s	
24710/33150 (epoch 37.270), train_loss = 1.06098779, grad/param norm = 1.7198e-01, time/batch = 0.6693s	
24711/33150 (epoch 37.271), train_loss = 0.93041610, grad/param norm = 1.9272e-01, time/batch = 0.6700s	
24712/33150 (epoch 37.273), train_loss = 0.97545271, grad/param norm = 1.7013e-01, time/batch = 0.6698s	
24713/33150 (epoch 37.275), train_loss = 0.99002037, grad/param norm = 2.0081e-01, time/batch = 0.6646s	
24714/33150 (epoch 37.276), train_loss = 0.87102228, grad/param norm = 1.7129e-01, time/batch = 0.6642s	
24715/33150 (epoch 37.278), train_loss = 0.98833685, grad/param norm = 1.8861e-01, time/batch = 0.6660s	
24716/33150 (epoch 37.279), train_loss = 0.94146022, grad/param norm = 1.6693e-01, time/batch = 0.6638s	
24717/33150 (epoch 37.281), train_loss = 0.86916745, grad/param norm = 1.6604e-01, time/batch = 0.6654s	
24718/33150 (epoch 37.282), train_loss = 0.92723604, grad/param norm = 1.6056e-01, time/batch = 0.6674s	
24719/33150 (epoch 37.284), train_loss = 0.80054794, grad/param norm = 1.6790e-01, time/batch = 0.6650s	
24720/33150 (epoch 37.285), train_loss = 0.91506049, grad/param norm = 1.9851e-01, time/batch = 0.6643s	
24721/33150 (epoch 37.287), train_loss = 0.78094869, grad/param norm = 1.8429e-01, time/batch = 0.6664s	
24722/33150 (epoch 37.288), train_loss = 0.94922268, grad/param norm = 1.7399e-01, time/batch = 0.6647s	
24723/33150 (epoch 37.290), train_loss = 0.74469789, grad/param norm = 1.7678e-01, time/batch = 0.6662s	
24724/33150 (epoch 37.291), train_loss = 0.73996333, grad/param norm = 1.8875e-01, time/batch = 0.6634s	
24725/33150 (epoch 37.293), train_loss = 0.85575138, grad/param norm = 1.9710e-01, time/batch = 0.6642s	
24726/33150 (epoch 37.294), train_loss = 0.68787345, grad/param norm = 1.4907e-01, time/batch = 0.6645s	
24727/33150 (epoch 37.296), train_loss = 0.87282402, grad/param norm = 1.7583e-01, time/batch = 0.6621s	
24728/33150 (epoch 37.297), train_loss = 0.81368870, grad/param norm = 1.7118e-01, time/batch = 0.6628s	
24729/33150 (epoch 37.299), train_loss = 0.81584200, grad/param norm = 2.0066e-01, time/batch = 0.6647s	
24730/33150 (epoch 37.300), train_loss = 0.80780386, grad/param norm = 1.5036e-01, time/batch = 0.6672s	
24731/33150 (epoch 37.302), train_loss = 0.86188296, grad/param norm = 1.8504e-01, time/batch = 0.6701s	
24732/33150 (epoch 37.303), train_loss = 0.82945926, grad/param norm = 1.6944e-01, time/batch = 0.6732s	
24733/33150 (epoch 37.305), train_loss = 0.91468513, grad/param norm = 1.8312e-01, time/batch = 0.6803s	
24734/33150 (epoch 37.306), train_loss = 0.93001901, grad/param norm = 2.1143e-01, time/batch = 0.6733s	
24735/33150 (epoch 37.308), train_loss = 1.06937666, grad/param norm = 1.9346e-01, time/batch = 0.6704s	
24736/33150 (epoch 37.309), train_loss = 0.71218967, grad/param norm = 1.4606e-01, time/batch = 0.6704s	
24737/33150 (epoch 37.311), train_loss = 0.85371841, grad/param norm = 1.9173e-01, time/batch = 0.6721s	
24738/33150 (epoch 37.312), train_loss = 0.69750060, grad/param norm = 1.6423e-01, time/batch = 0.6671s	
24739/33150 (epoch 37.314), train_loss = 0.82895648, grad/param norm = 1.7944e-01, time/batch = 0.6653s	
24740/33150 (epoch 37.315), train_loss = 0.90553716, grad/param norm = 1.7019e-01, time/batch = 0.6667s	
24741/33150 (epoch 37.317), train_loss = 0.68571489, grad/param norm = 1.4158e-01, time/batch = 0.6677s	
24742/33150 (epoch 37.318), train_loss = 0.79096560, grad/param norm = 1.5459e-01, time/batch = 0.6769s	
24743/33150 (epoch 37.320), train_loss = 0.74709462, grad/param norm = 1.7813e-01, time/batch = 0.6845s	
24744/33150 (epoch 37.321), train_loss = 0.82716629, grad/param norm = 1.5180e-01, time/batch = 0.6796s	
24745/33150 (epoch 37.323), train_loss = 0.80300141, grad/param norm = 1.6938e-01, time/batch = 0.6798s	
24746/33150 (epoch 37.324), train_loss = 0.86727620, grad/param norm = 2.1206e-01, time/batch = 0.6716s	
24747/33150 (epoch 37.326), train_loss = 0.85224411, grad/param norm = 1.6381e-01, time/batch = 0.6789s	
24748/33150 (epoch 37.327), train_loss = 0.94770023, grad/param norm = 1.8988e-01, time/batch = 0.6635s	
24749/33150 (epoch 37.329), train_loss = 0.91038513, grad/param norm = 1.7005e-01, time/batch = 0.6676s	
24750/33150 (epoch 37.330), train_loss = 0.81225422, grad/param norm = 1.7071e-01, time/batch = 0.6649s	
24751/33150 (epoch 37.332), train_loss = 0.84835748, grad/param norm = 1.7464e-01, time/batch = 0.6656s	
24752/33150 (epoch 37.333), train_loss = 0.91127296, grad/param norm = 1.5807e-01, time/batch = 0.6754s	
24753/33150 (epoch 37.335), train_loss = 0.79168242, grad/param norm = 1.6646e-01, time/batch = 0.6669s	
24754/33150 (epoch 37.336), train_loss = 0.77801776, grad/param norm = 2.0331e-01, time/batch = 0.6671s	
24755/33150 (epoch 37.338), train_loss = 0.73669204, grad/param norm = 1.7508e-01, time/batch = 0.6657s	
24756/33150 (epoch 37.339), train_loss = 0.92580214, grad/param norm = 1.8716e-01, time/batch = 0.6677s	
24757/33150 (epoch 37.341), train_loss = 0.86026160, grad/param norm = 2.0509e-01, time/batch = 0.6647s	
24758/33150 (epoch 37.342), train_loss = 0.81064592, grad/param norm = 1.7847e-01, time/batch = 0.6703s	
24759/33150 (epoch 37.344), train_loss = 0.83765947, grad/param norm = 1.7908e-01, time/batch = 0.6700s	
24760/33150 (epoch 37.345), train_loss = 0.81705975, grad/param norm = 1.6627e-01, time/batch = 0.6686s	
24761/33150 (epoch 37.347), train_loss = 0.70310351, grad/param norm = 1.6771e-01, time/batch = 0.6726s	
24762/33150 (epoch 37.348), train_loss = 0.88340528, grad/param norm = 1.8027e-01, time/batch = 0.6707s	
24763/33150 (epoch 37.350), train_loss = 0.76171022, grad/param norm = 1.6855e-01, time/batch = 0.6711s	
24764/33150 (epoch 37.351), train_loss = 0.91691101, grad/param norm = 1.7904e-01, time/batch = 0.6714s	
24765/33150 (epoch 37.353), train_loss = 0.88888654, grad/param norm = 1.6340e-01, time/batch = 0.6753s	
24766/33150 (epoch 37.354), train_loss = 1.06386752, grad/param norm = 1.7631e-01, time/batch = 0.6738s	
24767/33150 (epoch 37.356), train_loss = 0.92900561, grad/param norm = 1.7643e-01, time/batch = 0.6733s	
24768/33150 (epoch 37.357), train_loss = 0.87026210, grad/param norm = 1.8274e-01, time/batch = 0.6712s	
24769/33150 (epoch 37.359), train_loss = 0.93636843, grad/param norm = 1.8987e-01, time/batch = 0.6757s	
24770/33150 (epoch 37.360), train_loss = 0.88919535, grad/param norm = 1.8797e-01, time/batch = 0.6751s	
24771/33150 (epoch 37.362), train_loss = 0.96485221, grad/param norm = 1.7174e-01, time/batch = 0.6730s	
24772/33150 (epoch 37.363), train_loss = 0.89753483, grad/param norm = 1.7893e-01, time/batch = 0.6680s	
24773/33150 (epoch 37.365), train_loss = 0.83992879, grad/param norm = 1.6589e-01, time/batch = 0.6677s	
24774/33150 (epoch 37.367), train_loss = 0.80541446, grad/param norm = 1.5431e-01, time/batch = 0.6670s	
24775/33150 (epoch 37.368), train_loss = 0.83781095, grad/param norm = 2.0679e-01, time/batch = 0.6683s	
24776/33150 (epoch 37.370), train_loss = 0.90210900, grad/param norm = 3.3916e-01, time/batch = 0.6674s	
24777/33150 (epoch 37.371), train_loss = 0.79368456, grad/param norm = 2.0980e-01, time/batch = 0.6674s	
24778/33150 (epoch 37.373), train_loss = 0.90020926, grad/param norm = 1.8164e-01, time/batch = 0.6704s	
24779/33150 (epoch 37.374), train_loss = 0.86930984, grad/param norm = 1.5552e-01, time/batch = 0.6823s	
24780/33150 (epoch 37.376), train_loss = 0.93988789, grad/param norm = 1.7380e-01, time/batch = 0.6809s	
24781/33150 (epoch 37.377), train_loss = 0.79205812, grad/param norm = 2.2497e-01, time/batch = 0.6854s	
24782/33150 (epoch 37.379), train_loss = 0.90296389, grad/param norm = 2.0511e-01, time/batch = 0.6823s	
24783/33150 (epoch 37.380), train_loss = 0.91217881, grad/param norm = 1.5364e-01, time/batch = 0.6946s	
24784/33150 (epoch 37.382), train_loss = 0.87106712, grad/param norm = 1.7717e-01, time/batch = 0.6935s	
24785/33150 (epoch 37.383), train_loss = 0.79651537, grad/param norm = 1.8967e-01, time/batch = 0.6836s	
24786/33150 (epoch 37.385), train_loss = 0.81833918, grad/param norm = 1.9165e-01, time/batch = 0.6707s	
24787/33150 (epoch 37.386), train_loss = 0.75151177, grad/param norm = 1.5843e-01, time/batch = 0.6661s	
24788/33150 (epoch 37.388), train_loss = 0.78280534, grad/param norm = 1.7576e-01, time/batch = 0.6680s	
24789/33150 (epoch 37.389), train_loss = 0.78836870, grad/param norm = 1.5094e-01, time/batch = 0.6684s	
24790/33150 (epoch 37.391), train_loss = 0.98278219, grad/param norm = 1.8153e-01, time/batch = 0.6658s	
24791/33150 (epoch 37.392), train_loss = 0.80289510, grad/param norm = 1.7028e-01, time/batch = 0.6733s	
24792/33150 (epoch 37.394), train_loss = 0.73003563, grad/param norm = 1.4318e-01, time/batch = 0.6676s	
24793/33150 (epoch 37.395), train_loss = 0.67786790, grad/param norm = 1.5583e-01, time/batch = 0.6708s	
24794/33150 (epoch 37.397), train_loss = 0.59466073, grad/param norm = 1.5062e-01, time/batch = 0.6797s	
24795/33150 (epoch 37.398), train_loss = 0.84618872, grad/param norm = 1.6923e-01, time/batch = 0.6701s	
24796/33150 (epoch 37.400), train_loss = 0.82425988, grad/param norm = 1.3939e-01, time/batch = 0.6781s	
24797/33150 (epoch 37.401), train_loss = 0.72157201, grad/param norm = 1.4078e-01, time/batch = 0.6776s	
24798/33150 (epoch 37.403), train_loss = 0.72985653, grad/param norm = 1.5870e-01, time/batch = 0.6719s	
24799/33150 (epoch 37.404), train_loss = 0.85653502, grad/param norm = 1.6072e-01, time/batch = 0.6798s	
24800/33150 (epoch 37.406), train_loss = 0.80190245, grad/param norm = 1.3555e-01, time/batch = 0.6800s	
24801/33150 (epoch 37.407), train_loss = 0.72547672, grad/param norm = 1.4953e-01, time/batch = 0.6807s	
24802/33150 (epoch 37.409), train_loss = 0.67872899, grad/param norm = 1.6362e-01, time/batch = 0.6695s	
24803/33150 (epoch 37.410), train_loss = 0.86094229, grad/param norm = 1.7183e-01, time/batch = 0.6689s	
24804/33150 (epoch 37.412), train_loss = 0.90411707, grad/param norm = 1.5177e-01, time/batch = 0.6667s	
24805/33150 (epoch 37.413), train_loss = 0.73913921, grad/param norm = 1.4944e-01, time/batch = 0.6645s	
24806/33150 (epoch 37.415), train_loss = 0.88322397, grad/param norm = 1.7091e-01, time/batch = 0.6673s	
24807/33150 (epoch 37.416), train_loss = 0.77911445, grad/param norm = 1.4815e-01, time/batch = 0.6659s	
24808/33150 (epoch 37.418), train_loss = 0.87415311, grad/param norm = 2.1441e-01, time/batch = 0.6676s	
24809/33150 (epoch 37.419), train_loss = 0.82783184, grad/param norm = 1.6114e-01, time/batch = 0.6689s	
24810/33150 (epoch 37.421), train_loss = 0.86336182, grad/param norm = 2.4265e-01, time/batch = 0.6669s	
24811/33150 (epoch 37.422), train_loss = 0.81231805, grad/param norm = 1.8536e-01, time/batch = 0.6799s	
24812/33150 (epoch 37.424), train_loss = 0.77981860, grad/param norm = 1.7218e-01, time/batch = 0.6765s	
24813/33150 (epoch 37.425), train_loss = 0.91382276, grad/param norm = 1.7441e-01, time/batch = 0.6665s	
24814/33150 (epoch 37.427), train_loss = 0.84507276, grad/param norm = 1.5423e-01, time/batch = 0.6666s	
24815/33150 (epoch 37.428), train_loss = 0.82602755, grad/param norm = 1.7114e-01, time/batch = 0.6708s	
24816/33150 (epoch 37.430), train_loss = 0.87096677, grad/param norm = 1.8971e-01, time/batch = 0.6683s	
24817/33150 (epoch 37.431), train_loss = 0.89469470, grad/param norm = 1.7606e-01, time/batch = 0.6677s	
24818/33150 (epoch 37.433), train_loss = 0.82549742, grad/param norm = 1.6607e-01, time/batch = 0.6669s	
24819/33150 (epoch 37.434), train_loss = 0.72747012, grad/param norm = 1.4879e-01, time/batch = 0.6672s	
24820/33150 (epoch 37.436), train_loss = 0.84966611, grad/param norm = 1.5171e-01, time/batch = 0.6691s	
24821/33150 (epoch 37.437), train_loss = 0.86419962, grad/param norm = 2.0964e-01, time/batch = 0.6694s	
24822/33150 (epoch 37.439), train_loss = 1.00469624, grad/param norm = 1.6702e-01, time/batch = 0.6790s	
24823/33150 (epoch 37.440), train_loss = 0.89015147, grad/param norm = 1.8003e-01, time/batch = 0.6670s	
24824/33150 (epoch 37.442), train_loss = 0.72830843, grad/param norm = 1.7988e-01, time/batch = 0.6640s	
24825/33150 (epoch 37.443), train_loss = 0.87129634, grad/param norm = 1.9220e-01, time/batch = 0.6662s	
24826/33150 (epoch 37.445), train_loss = 0.84909903, grad/param norm = 2.2432e-01, time/batch = 0.6841s	
24827/33150 (epoch 37.446), train_loss = 0.88955211, grad/param norm = 2.4580e-01, time/batch = 0.6736s	
24828/33150 (epoch 37.448), train_loss = 0.93652501, grad/param norm = 1.7622e-01, time/batch = 0.6645s	
24829/33150 (epoch 37.449), train_loss = 0.85362714, grad/param norm = 1.5665e-01, time/batch = 0.6640s	
24830/33150 (epoch 37.451), train_loss = 0.89295743, grad/param norm = 2.2931e-01, time/batch = 0.6693s	
24831/33150 (epoch 37.452), train_loss = 1.03914023, grad/param norm = 2.0017e-01, time/batch = 0.6728s	
24832/33150 (epoch 37.454), train_loss = 0.82896006, grad/param norm = 1.6669e-01, time/batch = 0.6673s	
24833/33150 (epoch 37.456), train_loss = 0.79448782, grad/param norm = 1.6509e-01, time/batch = 0.6666s	
24834/33150 (epoch 37.457), train_loss = 0.86347908, grad/param norm = 1.8587e-01, time/batch = 0.6695s	
24835/33150 (epoch 37.459), train_loss = 0.98040495, grad/param norm = 2.5257e-01, time/batch = 0.6706s	
24836/33150 (epoch 37.460), train_loss = 0.91220335, grad/param norm = 1.6024e-01, time/batch = 0.6692s	
24837/33150 (epoch 37.462), train_loss = 0.96350254, grad/param norm = 2.0865e-01, time/batch = 0.6709s	
24838/33150 (epoch 37.463), train_loss = 1.07939901, grad/param norm = 2.6327e-01, time/batch = 0.6704s	
24839/33150 (epoch 37.465), train_loss = 0.91800341, grad/param norm = 1.6807e-01, time/batch = 0.6802s	
24840/33150 (epoch 37.466), train_loss = 0.82233367, grad/param norm = 1.6466e-01, time/batch = 0.6869s	
24841/33150 (epoch 37.468), train_loss = 1.06943823, grad/param norm = 1.9021e-01, time/batch = 0.6790s	
24842/33150 (epoch 37.469), train_loss = 0.79949442, grad/param norm = 1.7942e-01, time/batch = 0.6708s	
24843/33150 (epoch 37.471), train_loss = 0.80653601, grad/param norm = 1.7424e-01, time/batch = 0.6830s	
24844/33150 (epoch 37.472), train_loss = 0.86732987, grad/param norm = 1.5552e-01, time/batch = 0.6729s	
24845/33150 (epoch 37.474), train_loss = 0.93442280, grad/param norm = 2.6046e-01, time/batch = 0.6940s	
24846/33150 (epoch 37.475), train_loss = 1.10449035, grad/param norm = 2.0029e-01, time/batch = 0.6840s	
24847/33150 (epoch 37.477), train_loss = 0.90373019, grad/param norm = 1.6294e-01, time/batch = 0.6849s	
24848/33150 (epoch 37.478), train_loss = 0.88974582, grad/param norm = 1.6910e-01, time/batch = 0.6866s	
24849/33150 (epoch 37.480), train_loss = 0.79052393, grad/param norm = 1.7289e-01, time/batch = 0.6861s	
24850/33150 (epoch 37.481), train_loss = 0.73571935, grad/param norm = 1.6225e-01, time/batch = 0.6841s	
24851/33150 (epoch 37.483), train_loss = 0.81630443, grad/param norm = 1.6774e-01, time/batch = 0.6770s	
24852/33150 (epoch 37.484), train_loss = 0.77473803, grad/param norm = 1.6581e-01, time/batch = 0.6698s	
24853/33150 (epoch 37.486), train_loss = 0.79314480, grad/param norm = 2.0159e-01, time/batch = 0.6688s	
24854/33150 (epoch 37.487), train_loss = 0.91166989, grad/param norm = 1.8106e-01, time/batch = 0.6677s	
24855/33150 (epoch 37.489), train_loss = 0.86048741, grad/param norm = 1.7992e-01, time/batch = 0.6732s	
24856/33150 (epoch 37.490), train_loss = 0.69252963, grad/param norm = 1.5341e-01, time/batch = 0.6798s	
24857/33150 (epoch 37.492), train_loss = 0.81628063, grad/param norm = 1.7791e-01, time/batch = 0.6698s	
24858/33150 (epoch 37.493), train_loss = 0.90471085, grad/param norm = 1.9369e-01, time/batch = 0.6686s	
24859/33150 (epoch 37.495), train_loss = 0.89970223, grad/param norm = 1.5967e-01, time/batch = 0.6681s	
24860/33150 (epoch 37.496), train_loss = 0.84562582, grad/param norm = 1.6834e-01, time/batch = 0.6688s	
24861/33150 (epoch 37.498), train_loss = 0.92966664, grad/param norm = 2.0325e-01, time/batch = 0.6714s	
24862/33150 (epoch 37.499), train_loss = 0.95395794, grad/param norm = 1.8446e-01, time/batch = 0.6653s	
24863/33150 (epoch 37.501), train_loss = 0.89012982, grad/param norm = 1.8799e-01, time/batch = 0.6666s	
24864/33150 (epoch 37.502), train_loss = 0.95043929, grad/param norm = 1.9901e-01, time/batch = 0.6655s	
24865/33150 (epoch 37.504), train_loss = 0.96208292, grad/param norm = 2.0057e-01, time/batch = 0.6670s	
24866/33150 (epoch 37.505), train_loss = 0.97475227, grad/param norm = 1.8706e-01, time/batch = 0.6692s	
24867/33150 (epoch 37.507), train_loss = 0.79791647, grad/param norm = 1.6909e-01, time/batch = 0.6725s	
24868/33150 (epoch 37.508), train_loss = 0.80314050, grad/param norm = 2.1037e-01, time/batch = 0.6694s	
24869/33150 (epoch 37.510), train_loss = 0.91766227, grad/param norm = 1.5416e-01, time/batch = 0.6867s	
24870/33150 (epoch 37.511), train_loss = 0.96676930, grad/param norm = 1.8576e-01, time/batch = 0.6915s	
24871/33150 (epoch 37.513), train_loss = 0.89798580, grad/param norm = 2.6967e-01, time/batch = 0.6987s	
24872/33150 (epoch 37.514), train_loss = 0.76020849, grad/param norm = 2.3608e-01, time/batch = 0.6811s	
24873/33150 (epoch 37.516), train_loss = 0.89198874, grad/param norm = 2.2974e-01, time/batch = 0.6723s	
24874/33150 (epoch 37.517), train_loss = 0.92730551, grad/param norm = 1.9534e-01, time/batch = 0.6874s	
24875/33150 (epoch 37.519), train_loss = 0.80655023, grad/param norm = 1.6691e-01, time/batch = 0.6858s	
24876/33150 (epoch 37.520), train_loss = 0.87575926, grad/param norm = 1.7254e-01, time/batch = 0.6835s	
24877/33150 (epoch 37.522), train_loss = 0.92418396, grad/param norm = 1.9339e-01, time/batch = 0.6757s	
24878/33150 (epoch 37.523), train_loss = 0.74757364, grad/param norm = 1.6558e-01, time/batch = 0.6761s	
24879/33150 (epoch 37.525), train_loss = 0.89049858, grad/param norm = 1.7872e-01, time/batch = 0.6745s	
24880/33150 (epoch 37.526), train_loss = 0.78235794, grad/param norm = 1.5952e-01, time/batch = 0.6786s	
24881/33150 (epoch 37.528), train_loss = 0.87286890, grad/param norm = 1.9359e-01, time/batch = 0.6906s	
24882/33150 (epoch 37.529), train_loss = 0.85266414, grad/param norm = 1.6930e-01, time/batch = 0.6720s	
24883/33150 (epoch 37.531), train_loss = 0.73973836, grad/param norm = 1.8143e-01, time/batch = 0.6686s	
24884/33150 (epoch 37.532), train_loss = 0.88857966, grad/param norm = 2.7192e-01, time/batch = 0.6682s	
24885/33150 (epoch 37.534), train_loss = 0.85332073, grad/param norm = 1.6318e-01, time/batch = 0.6686s	
24886/33150 (epoch 37.535), train_loss = 0.78234728, grad/param norm = 1.8861e-01, time/batch = 0.6734s	
24887/33150 (epoch 37.537), train_loss = 0.88899369, grad/param norm = 2.2061e-01, time/batch = 0.6725s	
24888/33150 (epoch 37.538), train_loss = 0.78007078, grad/param norm = 1.6964e-01, time/batch = 0.6778s	
24889/33150 (epoch 37.540), train_loss = 0.78195531, grad/param norm = 1.9172e-01, time/batch = 0.6779s	
24890/33150 (epoch 37.541), train_loss = 0.94003143, grad/param norm = 1.7740e-01, time/batch = 0.6811s	
24891/33150 (epoch 37.543), train_loss = 0.85418274, grad/param norm = 1.7311e-01, time/batch = 0.6767s	
24892/33150 (epoch 37.544), train_loss = 0.91397715, grad/param norm = 1.6449e-01, time/batch = 0.6740s	
24893/33150 (epoch 37.546), train_loss = 0.82507391, grad/param norm = 1.9687e-01, time/batch = 0.6828s	
24894/33150 (epoch 37.548), train_loss = 0.83560634, grad/param norm = 1.9683e-01, time/batch = 0.6895s	
24895/33150 (epoch 37.549), train_loss = 0.82661454, grad/param norm = 2.1821e-01, time/batch = 0.6840s	
24896/33150 (epoch 37.551), train_loss = 0.76696456, grad/param norm = 1.4542e-01, time/batch = 0.6864s	
24897/33150 (epoch 37.552), train_loss = 0.68638277, grad/param norm = 1.5485e-01, time/batch = 0.6875s	
24898/33150 (epoch 37.554), train_loss = 0.92315768, grad/param norm = 1.8872e-01, time/batch = 0.6819s	
24899/33150 (epoch 37.555), train_loss = 0.96991246, grad/param norm = 2.2771e-01, time/batch = 0.6812s	
24900/33150 (epoch 37.557), train_loss = 0.72510380, grad/param norm = 1.9663e-01, time/batch = 0.6800s	
24901/33150 (epoch 37.558), train_loss = 0.89807927, grad/param norm = 2.7505e-01, time/batch = 0.6792s	
24902/33150 (epoch 37.560), train_loss = 0.77225635, grad/param norm = 1.6846e-01, time/batch = 0.6794s	
24903/33150 (epoch 37.561), train_loss = 0.72453693, grad/param norm = 1.7518e-01, time/batch = 0.6908s	
24904/33150 (epoch 37.563), train_loss = 0.90557184, grad/param norm = 1.8839e-01, time/batch = 0.6875s	
24905/33150 (epoch 37.564), train_loss = 0.94503336, grad/param norm = 1.6789e-01, time/batch = 0.6756s	
24906/33150 (epoch 37.566), train_loss = 0.78819585, grad/param norm = 1.7729e-01, time/batch = 0.6692s	
24907/33150 (epoch 37.567), train_loss = 0.81398060, grad/param norm = 1.7680e-01, time/batch = 0.6683s	
24908/33150 (epoch 37.569), train_loss = 0.87866740, grad/param norm = 2.1276e-01, time/batch = 0.6669s	
24909/33150 (epoch 37.570), train_loss = 0.91075302, grad/param norm = 1.6827e-01, time/batch = 0.6697s	
24910/33150 (epoch 37.572), train_loss = 0.81971351, grad/param norm = 2.1213e-01, time/batch = 0.6680s	
24911/33150 (epoch 37.573), train_loss = 0.72505798, grad/param norm = 1.5359e-01, time/batch = 0.6715s	
24912/33150 (epoch 37.575), train_loss = 0.82586086, grad/param norm = 1.9343e-01, time/batch = 0.6692s	
24913/33150 (epoch 37.576), train_loss = 0.75140351, grad/param norm = 1.6015e-01, time/batch = 0.6691s	
24914/33150 (epoch 37.578), train_loss = 0.77638733, grad/param norm = 1.4996e-01, time/batch = 0.6698s	
24915/33150 (epoch 37.579), train_loss = 0.75047800, grad/param norm = 1.7926e-01, time/batch = 0.6695s	
24916/33150 (epoch 37.581), train_loss = 0.76441579, grad/param norm = 1.7132e-01, time/batch = 0.6659s	
24917/33150 (epoch 37.582), train_loss = 0.97196115, grad/param norm = 1.6071e-01, time/batch = 0.6710s	
24918/33150 (epoch 37.584), train_loss = 0.93355688, grad/param norm = 2.1634e-01, time/batch = 0.6663s	
24919/33150 (epoch 37.585), train_loss = 0.85734904, grad/param norm = 1.7224e-01, time/batch = 0.6659s	
24920/33150 (epoch 37.587), train_loss = 0.84515608, grad/param norm = 1.7604e-01, time/batch = 0.6661s	
24921/33150 (epoch 37.588), train_loss = 0.79457600, grad/param norm = 1.7834e-01, time/batch = 0.6721s	
24922/33150 (epoch 37.590), train_loss = 0.88205539, grad/param norm = 1.7387e-01, time/batch = 0.6718s	
24923/33150 (epoch 37.591), train_loss = 0.87247125, grad/param norm = 1.9289e-01, time/batch = 0.6702s	
24924/33150 (epoch 37.593), train_loss = 0.90502690, grad/param norm = 1.8357e-01, time/batch = 0.6806s	
24925/33150 (epoch 37.594), train_loss = 0.82963371, grad/param norm = 1.8618e-01, time/batch = 0.6741s	
24926/33150 (epoch 37.596), train_loss = 0.82240863, grad/param norm = 1.8111e-01, time/batch = 0.6694s	
24927/33150 (epoch 37.597), train_loss = 0.75380737, grad/param norm = 2.4128e-01, time/batch = 0.6673s	
24928/33150 (epoch 37.599), train_loss = 1.02407408, grad/param norm = 2.3602e-01, time/batch = 0.6692s	
24929/33150 (epoch 37.600), train_loss = 0.86537572, grad/param norm = 2.5788e-01, time/batch = 0.6690s	
24930/33150 (epoch 37.602), train_loss = 0.85760609, grad/param norm = 2.1293e-01, time/batch = 0.6676s	
24931/33150 (epoch 37.603), train_loss = 0.95532238, grad/param norm = 1.7158e-01, time/batch = 0.6662s	
24932/33150 (epoch 37.605), train_loss = 0.75937932, grad/param norm = 1.6310e-01, time/batch = 0.6690s	
24933/33150 (epoch 37.606), train_loss = 0.80171743, grad/param norm = 2.0820e-01, time/batch = 0.6802s	
24934/33150 (epoch 37.608), train_loss = 0.93258969, grad/param norm = 1.6323e-01, time/batch = 0.6902s	
24935/33150 (epoch 37.609), train_loss = 0.85691043, grad/param norm = 2.6585e-01, time/batch = 0.6798s	
24936/33150 (epoch 37.611), train_loss = 0.75745497, grad/param norm = 1.8361e-01, time/batch = 0.6820s	
24937/33150 (epoch 37.612), train_loss = 0.83373304, grad/param norm = 1.9384e-01, time/batch = 0.6712s	
24938/33150 (epoch 37.614), train_loss = 0.79126681, grad/param norm = 1.7207e-01, time/batch = 0.6772s	
24939/33150 (epoch 37.615), train_loss = 0.76892536, grad/param norm = 1.7840e-01, time/batch = 0.6766s	
24940/33150 (epoch 37.617), train_loss = 0.87938186, grad/param norm = 1.9591e-01, time/batch = 0.6658s	
24941/33150 (epoch 37.618), train_loss = 0.88216858, grad/param norm = 1.9161e-01, time/batch = 0.6659s	
24942/33150 (epoch 37.620), train_loss = 0.82241613, grad/param norm = 1.8598e-01, time/batch = 0.6626s	
24943/33150 (epoch 37.621), train_loss = 0.87073214, grad/param norm = 1.6784e-01, time/batch = 0.6733s	
24944/33150 (epoch 37.623), train_loss = 0.90927340, grad/param norm = 1.7405e-01, time/batch = 0.6705s	
24945/33150 (epoch 37.624), train_loss = 0.82591193, grad/param norm = 1.8402e-01, time/batch = 0.6673s	
24946/33150 (epoch 37.626), train_loss = 0.85324641, grad/param norm = 1.7318e-01, time/batch = 0.6707s	
24947/33150 (epoch 37.627), train_loss = 0.82064575, grad/param norm = 1.9358e-01, time/batch = 0.6718s	
24948/33150 (epoch 37.629), train_loss = 0.73259343, grad/param norm = 1.7767e-01, time/batch = 0.6732s	
24949/33150 (epoch 37.630), train_loss = 0.83993105, grad/param norm = 1.7142e-01, time/batch = 0.6794s	
24950/33150 (epoch 37.632), train_loss = 0.73607741, grad/param norm = 1.4498e-01, time/batch = 0.6900s	
24951/33150 (epoch 37.633), train_loss = 0.76756521, grad/param norm = 1.8617e-01, time/batch = 0.6693s	
24952/33150 (epoch 37.635), train_loss = 0.99933411, grad/param norm = 2.0530e-01, time/batch = 0.6662s	
24953/33150 (epoch 37.637), train_loss = 0.69160991, grad/param norm = 1.9151e-01, time/batch = 0.6726s	
24954/33150 (epoch 37.638), train_loss = 0.82794928, grad/param norm = 1.6491e-01, time/batch = 0.6697s	
24955/33150 (epoch 37.640), train_loss = 0.92242076, grad/param norm = 2.1222e-01, time/batch = 0.6673s	
24956/33150 (epoch 37.641), train_loss = 0.72442999, grad/param norm = 1.7557e-01, time/batch = 0.6773s	
24957/33150 (epoch 37.643), train_loss = 0.86102371, grad/param norm = 1.7599e-01, time/batch = 0.6807s	
24958/33150 (epoch 37.644), train_loss = 0.99655134, grad/param norm = 1.6962e-01, time/batch = 0.6861s	
24959/33150 (epoch 37.646), train_loss = 0.82540024, grad/param norm = 1.6017e-01, time/batch = 0.6905s	
24960/33150 (epoch 37.647), train_loss = 1.03147068, grad/param norm = 2.0015e-01, time/batch = 0.6826s	
24961/33150 (epoch 37.649), train_loss = 0.90450429, grad/param norm = 2.2178e-01, time/batch = 0.6818s	
24962/33150 (epoch 37.650), train_loss = 0.75658009, grad/param norm = 1.8344e-01, time/batch = 0.6767s	
24963/33150 (epoch 37.652), train_loss = 0.94877150, grad/param norm = 1.9530e-01, time/batch = 0.6767s	
24964/33150 (epoch 37.653), train_loss = 0.90215416, grad/param norm = 1.7984e-01, time/batch = 0.6814s	
24965/33150 (epoch 37.655), train_loss = 0.89388304, grad/param norm = 2.1130e-01, time/batch = 0.6728s	
24966/33150 (epoch 37.656), train_loss = 0.80291806, grad/param norm = 1.6256e-01, time/batch = 0.6789s	
24967/33150 (epoch 37.658), train_loss = 0.81355690, grad/param norm = 1.5780e-01, time/batch = 0.6797s	
24968/33150 (epoch 37.659), train_loss = 1.07403590, grad/param norm = 2.6390e-01, time/batch = 0.6804s	
24969/33150 (epoch 37.661), train_loss = 0.84700695, grad/param norm = 2.0177e-01, time/batch = 0.6730s	
24970/33150 (epoch 37.662), train_loss = 0.81253072, grad/param norm = 1.6473e-01, time/batch = 0.6920s	
24971/33150 (epoch 37.664), train_loss = 0.95336428, grad/param norm = 1.8224e-01, time/batch = 0.6792s	
24972/33150 (epoch 37.665), train_loss = 0.91647749, grad/param norm = 1.9757e-01, time/batch = 0.6727s	
24973/33150 (epoch 37.667), train_loss = 0.93971487, grad/param norm = 2.0856e-01, time/batch = 0.6720s	
24974/33150 (epoch 37.668), train_loss = 1.01081535, grad/param norm = 1.9807e-01, time/batch = 0.6724s	
24975/33150 (epoch 37.670), train_loss = 0.80273892, grad/param norm = 1.6345e-01, time/batch = 0.6703s	
24976/33150 (epoch 37.671), train_loss = 0.78454688, grad/param norm = 1.7685e-01, time/batch = 0.6700s	
24977/33150 (epoch 37.673), train_loss = 0.97804477, grad/param norm = 1.5983e-01, time/batch = 0.6733s	
24978/33150 (epoch 37.674), train_loss = 0.90968738, grad/param norm = 1.9939e-01, time/batch = 0.6885s	
24979/33150 (epoch 37.676), train_loss = 0.85044994, grad/param norm = 1.5635e-01, time/batch = 0.6751s	
24980/33150 (epoch 37.677), train_loss = 0.99858530, grad/param norm = 2.3424e-01, time/batch = 0.6705s	
24981/33150 (epoch 37.679), train_loss = 0.84917706, grad/param norm = 1.6965e-01, time/batch = 0.6718s	
24982/33150 (epoch 37.680), train_loss = 0.96098007, grad/param norm = 1.8766e-01, time/batch = 0.6699s	
24983/33150 (epoch 37.682), train_loss = 0.86548190, grad/param norm = 1.8872e-01, time/batch = 0.6729s	
24984/33150 (epoch 37.683), train_loss = 0.73611768, grad/param norm = 1.5373e-01, time/batch = 0.6699s	
24985/33150 (epoch 37.685), train_loss = 0.82136854, grad/param norm = 2.0122e-01, time/batch = 0.6701s	
24986/33150 (epoch 37.686), train_loss = 0.71887296, grad/param norm = 1.5091e-01, time/batch = 0.6709s	
24987/33150 (epoch 37.688), train_loss = 0.74126571, grad/param norm = 1.7533e-01, time/batch = 0.6715s	
24988/33150 (epoch 37.689), train_loss = 0.78136692, grad/param norm = 1.6054e-01, time/batch = 0.6703s	
24989/33150 (epoch 37.691), train_loss = 0.66555369, grad/param norm = 1.2812e-01, time/batch = 0.6712s	
24990/33150 (epoch 37.692), train_loss = 0.77276748, grad/param norm = 1.6621e-01, time/batch = 0.6682s	
24991/33150 (epoch 37.694), train_loss = 0.68033674, grad/param norm = 1.4641e-01, time/batch = 0.6816s	
24992/33150 (epoch 37.695), train_loss = 0.79686059, grad/param norm = 1.5138e-01, time/batch = 0.6805s	
24993/33150 (epoch 37.697), train_loss = 0.74672098, grad/param norm = 1.4214e-01, time/batch = 0.6805s	
24994/33150 (epoch 37.698), train_loss = 0.76108562, grad/param norm = 1.8326e-01, time/batch = 0.6709s	
24995/33150 (epoch 37.700), train_loss = 0.65340466, grad/param norm = 1.3580e-01, time/batch = 0.6732s	
24996/33150 (epoch 37.701), train_loss = 0.72809062, grad/param norm = 1.4315e-01, time/batch = 0.6722s	
24997/33150 (epoch 37.703), train_loss = 0.83361365, grad/param norm = 1.8076e-01, time/batch = 0.6729s	
24998/33150 (epoch 37.704), train_loss = 0.71884896, grad/param norm = 1.4309e-01, time/batch = 0.6734s	
24999/33150 (epoch 37.706), train_loss = 0.78371384, grad/param norm = 1.4440e-01, time/batch = 0.6720s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch37.71_1.8097.t7	
25000/33150 (epoch 37.707), train_loss = 0.82334054, grad/param norm = 1.8138e-01, time/batch = 0.6683s	
25001/33150 (epoch 37.709), train_loss = 1.27424970, grad/param norm = 1.7963e-01, time/batch = 0.6782s	
25002/33150 (epoch 37.710), train_loss = 0.84851532, grad/param norm = 1.9826e-01, time/batch = 0.6743s	
25003/33150 (epoch 37.712), train_loss = 0.91574308, grad/param norm = 1.7009e-01, time/batch = 0.6770s	
25004/33150 (epoch 37.713), train_loss = 0.87250864, grad/param norm = 1.5900e-01, time/batch = 0.6726s	
25005/33150 (epoch 37.715), train_loss = 0.81384146, grad/param norm = 1.5773e-01, time/batch = 0.6700s	
25006/33150 (epoch 37.716), train_loss = 0.88640262, grad/param norm = 1.7727e-01, time/batch = 0.6706s	
25007/33150 (epoch 37.718), train_loss = 0.84072090, grad/param norm = 1.5844e-01, time/batch = 0.6723s	
25008/33150 (epoch 37.719), train_loss = 0.91715469, grad/param norm = 2.0841e-01, time/batch = 0.6724s	
25009/33150 (epoch 37.721), train_loss = 0.81921187, grad/param norm = 2.1034e-01, time/batch = 0.6816s	
25010/33150 (epoch 37.722), train_loss = 0.87412339, grad/param norm = 1.7088e-01, time/batch = 0.6855s	
25011/33150 (epoch 37.724), train_loss = 0.81739972, grad/param norm = 2.0361e-01, time/batch = 0.6791s	
25012/33150 (epoch 37.725), train_loss = 0.91865479, grad/param norm = 2.0444e-01, time/batch = 0.6778s	
25013/33150 (epoch 37.727), train_loss = 0.89572631, grad/param norm = 1.8897e-01, time/batch = 0.6661s	
25014/33150 (epoch 37.729), train_loss = 0.84284359, grad/param norm = 1.8212e-01, time/batch = 0.6659s	
25015/33150 (epoch 37.730), train_loss = 0.85251655, grad/param norm = 1.6867e-01, time/batch = 0.6694s	
25016/33150 (epoch 37.732), train_loss = 0.89940629, grad/param norm = 1.7906e-01, time/batch = 0.6700s	
25017/33150 (epoch 37.733), train_loss = 0.73450378, grad/param norm = 1.3345e-01, time/batch = 0.6681s	
25018/33150 (epoch 37.735), train_loss = 0.78214527, grad/param norm = 1.6624e-01, time/batch = 0.6691s	
25019/33150 (epoch 37.736), train_loss = 0.79669330, grad/param norm = 1.8226e-01, time/batch = 0.6661s	
25020/33150 (epoch 37.738), train_loss = 0.84470751, grad/param norm = 2.0136e-01, time/batch = 0.6648s	
25021/33150 (epoch 37.739), train_loss = 0.95747312, grad/param norm = 2.0209e-01, time/batch = 0.6664s	
25022/33150 (epoch 37.741), train_loss = 0.87769127, grad/param norm = 2.0218e-01, time/batch = 0.6671s	
25023/33150 (epoch 37.742), train_loss = 0.74086136, grad/param norm = 1.7951e-01, time/batch = 0.6668s	
25024/33150 (epoch 37.744), train_loss = 0.90555272, grad/param norm = 1.8976e-01, time/batch = 0.6687s	
25025/33150 (epoch 37.745), train_loss = 0.79154861, grad/param norm = 1.4921e-01, time/batch = 0.6636s	
25026/33150 (epoch 37.747), train_loss = 0.63971608, grad/param norm = 1.6972e-01, time/batch = 0.6660s	
25027/33150 (epoch 37.748), train_loss = 0.72841393, grad/param norm = 1.8116e-01, time/batch = 0.6727s	
25028/33150 (epoch 37.750), train_loss = 0.87373576, grad/param norm = 1.8091e-01, time/batch = 0.6800s	
25029/33150 (epoch 37.751), train_loss = 0.82069665, grad/param norm = 1.5914e-01, time/batch = 0.6771s	
25030/33150 (epoch 37.753), train_loss = 0.74197096, grad/param norm = 1.8506e-01, time/batch = 0.6681s	
25031/33150 (epoch 37.754), train_loss = 1.02411372, grad/param norm = 2.1733e-01, time/batch = 0.6693s	
25032/33150 (epoch 37.756), train_loss = 0.82925337, grad/param norm = 2.2625e-01, time/batch = 0.6698s	
25033/33150 (epoch 37.757), train_loss = 0.88842820, grad/param norm = 1.7293e-01, time/batch = 0.6684s	
25034/33150 (epoch 37.759), train_loss = 0.98387158, grad/param norm = 2.2056e-01, time/batch = 0.6692s	
25035/33150 (epoch 37.760), train_loss = 0.86823195, grad/param norm = 1.7297e-01, time/batch = 0.6683s	
25036/33150 (epoch 37.762), train_loss = 0.85678590, grad/param norm = 2.4354e-01, time/batch = 0.6791s	
25037/33150 (epoch 37.763), train_loss = 0.87404341, grad/param norm = 1.8114e-01, time/batch = 0.6869s	
25038/33150 (epoch 37.765), train_loss = 0.83287496, grad/param norm = 1.7024e-01, time/batch = 0.6752s	
25039/33150 (epoch 37.766), train_loss = 0.75770694, grad/param norm = 2.0730e-01, time/batch = 0.6815s	
25040/33150 (epoch 37.768), train_loss = 0.77104834, grad/param norm = 1.5964e-01, time/batch = 0.6670s	
25041/33150 (epoch 37.769), train_loss = 0.91587626, grad/param norm = 1.8498e-01, time/batch = 0.6699s	
25042/33150 (epoch 37.771), train_loss = 0.85997029, grad/param norm = 1.6518e-01, time/batch = 0.6776s	
25043/33150 (epoch 37.772), train_loss = 0.88765370, grad/param norm = 2.1125e-01, time/batch = 0.6845s	
25044/33150 (epoch 37.774), train_loss = 0.98724223, grad/param norm = 1.7518e-01, time/batch = 0.6774s	
25045/33150 (epoch 37.775), train_loss = 0.90571959, grad/param norm = 2.5455e-01, time/batch = 0.6986s	
25046/33150 (epoch 37.777), train_loss = 0.90647238, grad/param norm = 1.9084e-01, time/batch = 0.6915s	
25047/33150 (epoch 37.778), train_loss = 0.84714395, grad/param norm = 1.6177e-01, time/batch = 0.6739s	
25048/33150 (epoch 37.780), train_loss = 0.72112061, grad/param norm = 1.5530e-01, time/batch = 0.6686s	
25049/33150 (epoch 37.781), train_loss = 0.84074396, grad/param norm = 1.6346e-01, time/batch = 0.6698s	
25050/33150 (epoch 37.783), train_loss = 0.85927887, grad/param norm = 1.8169e-01, time/batch = 0.6723s	
25051/33150 (epoch 37.784), train_loss = 0.84160321, grad/param norm = 1.8974e-01, time/batch = 0.6720s	
25052/33150 (epoch 37.786), train_loss = 0.83801448, grad/param norm = 1.7655e-01, time/batch = 0.6735s	
25053/33150 (epoch 37.787), train_loss = 0.76720148, grad/param norm = 1.5468e-01, time/batch = 0.6705s	
25054/33150 (epoch 37.789), train_loss = 0.72431191, grad/param norm = 1.4878e-01, time/batch = 0.6670s	
25055/33150 (epoch 37.790), train_loss = 0.71788599, grad/param norm = 1.6866e-01, time/batch = 0.6665s	
25056/33150 (epoch 37.792), train_loss = 0.83469193, grad/param norm = 1.8762e-01, time/batch = 0.6658s	
25057/33150 (epoch 37.793), train_loss = 0.81699079, grad/param norm = 2.0928e-01, time/batch = 0.6682s	
25058/33150 (epoch 37.795), train_loss = 0.79204918, grad/param norm = 1.8150e-01, time/batch = 0.6779s	
25059/33150 (epoch 37.796), train_loss = 0.81035238, grad/param norm = 1.5954e-01, time/batch = 0.6813s	
25060/33150 (epoch 37.798), train_loss = 0.78637203, grad/param norm = 1.5031e-01, time/batch = 0.6683s	
25061/33150 (epoch 37.799), train_loss = 0.69487314, grad/param norm = 1.9679e-01, time/batch = 0.6711s	
25062/33150 (epoch 37.801), train_loss = 0.85381023, grad/param norm = 1.6385e-01, time/batch = 0.6728s	
25063/33150 (epoch 37.802), train_loss = 0.79924233, grad/param norm = 1.6098e-01, time/batch = 0.6764s	
25064/33150 (epoch 37.804), train_loss = 0.81259079, grad/param norm = 1.7388e-01, time/batch = 0.6707s	
25065/33150 (epoch 37.805), train_loss = 0.78748712, grad/param norm = 1.8284e-01, time/batch = 0.6776s	
25066/33150 (epoch 37.807), train_loss = 0.82260326, grad/param norm = 1.7553e-01, time/batch = 0.6769s	
25067/33150 (epoch 37.808), train_loss = 0.92681253, grad/param norm = 1.7943e-01, time/batch = 0.6729s	
25068/33150 (epoch 37.810), train_loss = 0.75532279, grad/param norm = 1.6127e-01, time/batch = 0.6737s	
25069/33150 (epoch 37.811), train_loss = 0.87712028, grad/param norm = 2.2192e-01, time/batch = 0.6699s	
25070/33150 (epoch 37.813), train_loss = 0.80533266, grad/param norm = 1.8721e-01, time/batch = 0.6705s	
25071/33150 (epoch 37.814), train_loss = 0.79292480, grad/param norm = 2.0741e-01, time/batch = 0.6745s	
25072/33150 (epoch 37.816), train_loss = 0.80703574, grad/param norm = 1.8606e-01, time/batch = 0.6699s	
25073/33150 (epoch 37.817), train_loss = 0.88493898, grad/param norm = 1.6860e-01, time/batch = 0.6701s	
25074/33150 (epoch 37.819), train_loss = 0.85001455, grad/param norm = 1.6396e-01, time/batch = 0.6735s	
25075/33150 (epoch 37.821), train_loss = 0.74383273, grad/param norm = 1.5112e-01, time/batch = 0.6889s	
25076/33150 (epoch 37.822), train_loss = 0.78455610, grad/param norm = 1.8908e-01, time/batch = 0.6767s	
25077/33150 (epoch 37.824), train_loss = 0.85246187, grad/param norm = 2.0037e-01, time/batch = 0.6839s	
25078/33150 (epoch 37.825), train_loss = 0.87525073, grad/param norm = 1.8624e-01, time/batch = 0.6704s	
25079/33150 (epoch 37.827), train_loss = 0.89697747, grad/param norm = 1.7973e-01, time/batch = 0.6817s	
25080/33150 (epoch 37.828), train_loss = 0.76185389, grad/param norm = 1.6608e-01, time/batch = 0.6706s	
25081/33150 (epoch 37.830), train_loss = 0.89603010, grad/param norm = 1.9216e-01, time/batch = 0.6715s	
25082/33150 (epoch 37.831), train_loss = 0.76905491, grad/param norm = 1.7141e-01, time/batch = 0.6710s	
25083/33150 (epoch 37.833), train_loss = 0.75547350, grad/param norm = 1.6704e-01, time/batch = 0.6700s	
25084/33150 (epoch 37.834), train_loss = 0.91437062, grad/param norm = 1.6388e-01, time/batch = 0.6696s	
25085/33150 (epoch 37.836), train_loss = 0.94364663, grad/param norm = 1.7397e-01, time/batch = 0.6720s	
25086/33150 (epoch 37.837), train_loss = 0.80211725, grad/param norm = 2.1833e-01, time/batch = 0.6706s	
25087/33150 (epoch 37.839), train_loss = 0.89722068, grad/param norm = 1.9431e-01, time/batch = 0.6704s	
25088/33150 (epoch 37.840), train_loss = 0.89618002, grad/param norm = 1.8570e-01, time/batch = 0.6705s	
25089/33150 (epoch 37.842), train_loss = 0.92177312, grad/param norm = 1.9999e-01, time/batch = 0.6689s	
25090/33150 (epoch 37.843), train_loss = 0.92235098, grad/param norm = 1.7840e-01, time/batch = 0.6711s	
25091/33150 (epoch 37.845), train_loss = 0.77884752, grad/param norm = 1.7655e-01, time/batch = 0.6682s	
25092/33150 (epoch 37.846), train_loss = 1.00609003, grad/param norm = 2.8282e-01, time/batch = 0.6706s	
25093/33150 (epoch 37.848), train_loss = 0.92160357, grad/param norm = 1.9960e-01, time/batch = 0.6733s	
25094/33150 (epoch 37.849), train_loss = 0.93047076, grad/param norm = 1.7597e-01, time/batch = 0.6680s	
25095/33150 (epoch 37.851), train_loss = 0.90101393, grad/param norm = 2.5210e-01, time/batch = 0.6708s	
25096/33150 (epoch 37.852), train_loss = 0.97289615, grad/param norm = 1.7262e-01, time/batch = 0.6872s	
25097/33150 (epoch 37.854), train_loss = 0.89033020, grad/param norm = 2.0358e-01, time/batch = 0.6672s	
25098/33150 (epoch 37.855), train_loss = 0.76069841, grad/param norm = 1.9867e-01, time/batch = 0.6669s	
25099/33150 (epoch 37.857), train_loss = 0.70132209, grad/param norm = 1.8521e-01, time/batch = 0.6665s	
25100/33150 (epoch 37.858), train_loss = 0.82524416, grad/param norm = 2.0813e-01, time/batch = 0.6659s	
25101/33150 (epoch 37.860), train_loss = 0.77203007, grad/param norm = 1.6637e-01, time/batch = 0.6756s	
25102/33150 (epoch 37.861), train_loss = 0.74254132, grad/param norm = 1.5186e-01, time/batch = 0.6797s	
25103/33150 (epoch 37.863), train_loss = 0.81973373, grad/param norm = 1.7650e-01, time/batch = 0.6719s	
25104/33150 (epoch 37.864), train_loss = 0.85310935, grad/param norm = 1.6575e-01, time/batch = 0.6711s	
25105/33150 (epoch 37.866), train_loss = 0.92014218, grad/param norm = 1.8493e-01, time/batch = 0.6738s	
25106/33150 (epoch 37.867), train_loss = 0.85165751, grad/param norm = 1.6085e-01, time/batch = 0.6710s	
25107/33150 (epoch 37.869), train_loss = 0.84073116, grad/param norm = 1.7703e-01, time/batch = 0.6694s	
25108/33150 (epoch 37.870), train_loss = 0.79195919, grad/param norm = 1.8014e-01, time/batch = 0.6716s	
25109/33150 (epoch 37.872), train_loss = 0.90041876, grad/param norm = 2.1789e-01, time/batch = 0.6702s	
25110/33150 (epoch 37.873), train_loss = 0.68896946, grad/param norm = 1.4675e-01, time/batch = 0.6707s	
25111/33150 (epoch 37.875), train_loss = 0.94513364, grad/param norm = 1.6550e-01, time/batch = 0.6736s	
25112/33150 (epoch 37.876), train_loss = 0.69459182, grad/param norm = 1.6774e-01, time/batch = 0.6727s	
25113/33150 (epoch 37.878), train_loss = 0.79276327, grad/param norm = 1.6892e-01, time/batch = 0.6719s	
25114/33150 (epoch 37.879), train_loss = 0.78015604, grad/param norm = 1.5792e-01, time/batch = 0.6714s	
25115/33150 (epoch 37.881), train_loss = 0.77619463, grad/param norm = 1.7963e-01, time/batch = 0.6697s	
25116/33150 (epoch 37.882), train_loss = 0.65201063, grad/param norm = 1.4370e-01, time/batch = 0.6699s	
25117/33150 (epoch 37.884), train_loss = 0.80270755, grad/param norm = 2.0179e-01, time/batch = 0.6718s	
25118/33150 (epoch 37.885), train_loss = 0.63373621, grad/param norm = 1.7402e-01, time/batch = 0.6833s	
25119/33150 (epoch 37.887), train_loss = 0.90412436, grad/param norm = 1.7661e-01, time/batch = 0.6718s	
25120/33150 (epoch 37.888), train_loss = 0.85578791, grad/param norm = 1.8349e-01, time/batch = 0.6681s	
25121/33150 (epoch 37.890), train_loss = 0.75331268, grad/param norm = 1.9038e-01, time/batch = 0.6689s	
25122/33150 (epoch 37.891), train_loss = 0.75097343, grad/param norm = 1.7159e-01, time/batch = 0.6678s	
25123/33150 (epoch 37.893), train_loss = 0.89456585, grad/param norm = 1.8387e-01, time/batch = 0.6678s	
25124/33150 (epoch 37.894), train_loss = 0.86979648, grad/param norm = 1.8386e-01, time/batch = 0.6677s	
25125/33150 (epoch 37.896), train_loss = 0.82303049, grad/param norm = 1.5452e-01, time/batch = 0.6889s	
25126/33150 (epoch 37.897), train_loss = 0.88715198, grad/param norm = 1.8054e-01, time/batch = 0.6863s	
25127/33150 (epoch 37.899), train_loss = 0.69936033, grad/param norm = 1.8651e-01, time/batch = 0.6883s	
25128/33150 (epoch 37.900), train_loss = 1.01413531, grad/param norm = 2.4970e-01, time/batch = 0.6839s	
25129/33150 (epoch 37.902), train_loss = 1.04543656, grad/param norm = 1.8714e-01, time/batch = 0.6825s	
25130/33150 (epoch 37.903), train_loss = 0.85753705, grad/param norm = 1.7675e-01, time/batch = 0.6784s	
25131/33150 (epoch 37.905), train_loss = 0.83614581, grad/param norm = 1.6339e-01, time/batch = 0.6843s	
25132/33150 (epoch 37.906), train_loss = 0.84778543, grad/param norm = 1.8921e-01, time/batch = 0.6842s	
25133/33150 (epoch 37.908), train_loss = 0.91993183, grad/param norm = 1.8636e-01, time/batch = 0.6869s	
25134/33150 (epoch 37.910), train_loss = 0.91658528, grad/param norm = 1.8326e-01, time/batch = 0.6848s	
25135/33150 (epoch 37.911), train_loss = 0.71228237, grad/param norm = 1.4702e-01, time/batch = 0.6742s	
25136/33150 (epoch 37.913), train_loss = 0.79193692, grad/param norm = 1.7575e-01, time/batch = 0.6770s	
25137/33150 (epoch 37.914), train_loss = 0.85159986, grad/param norm = 1.8236e-01, time/batch = 0.6695s	
25138/33150 (epoch 37.916), train_loss = 0.78339283, grad/param norm = 1.7161e-01, time/batch = 0.6761s	
25139/33150 (epoch 37.917), train_loss = 0.85625058, grad/param norm = 1.6758e-01, time/batch = 0.6832s	
25140/33150 (epoch 37.919), train_loss = 0.97773738, grad/param norm = 2.7758e-01, time/batch = 0.6712s	
25141/33150 (epoch 37.920), train_loss = 0.94392712, grad/param norm = 2.0515e-01, time/batch = 0.6700s	
25142/33150 (epoch 37.922), train_loss = 0.98262011, grad/param norm = 2.3233e-01, time/batch = 0.6762s	
25143/33150 (epoch 37.923), train_loss = 0.86683381, grad/param norm = 1.7910e-01, time/batch = 0.6731s	
25144/33150 (epoch 37.925), train_loss = 0.93275630, grad/param norm = 1.7372e-01, time/batch = 0.6711s	
25145/33150 (epoch 37.926), train_loss = 0.82948587, grad/param norm = 1.7793e-01, time/batch = 0.6897s	
25146/33150 (epoch 37.928), train_loss = 0.81980577, grad/param norm = 1.9049e-01, time/batch = 0.6942s	
25147/33150 (epoch 37.929), train_loss = 0.90319292, grad/param norm = 1.8612e-01, time/batch = 0.6896s	
25148/33150 (epoch 37.931), train_loss = 0.94696396, grad/param norm = 1.8201e-01, time/batch = 0.6915s	
25149/33150 (epoch 37.932), train_loss = 0.87366683, grad/param norm = 1.8195e-01, time/batch = 0.6930s	
25150/33150 (epoch 37.934), train_loss = 0.87503544, grad/param norm = 1.6872e-01, time/batch = 0.6799s	
25151/33150 (epoch 37.935), train_loss = 0.93360541, grad/param norm = 1.8166e-01, time/batch = 0.6733s	
25152/33150 (epoch 37.937), train_loss = 0.98054951, grad/param norm = 1.7392e-01, time/batch = 0.6698s	
25153/33150 (epoch 37.938), train_loss = 0.86864831, grad/param norm = 1.8217e-01, time/batch = 0.6715s	
25154/33150 (epoch 37.940), train_loss = 1.06130074, grad/param norm = 2.0956e-01, time/batch = 0.6711s	
25155/33150 (epoch 37.941), train_loss = 0.90143118, grad/param norm = 1.6135e-01, time/batch = 0.6708s	
25156/33150 (epoch 37.943), train_loss = 0.69887463, grad/param norm = 1.7308e-01, time/batch = 0.6692s	
25157/33150 (epoch 37.944), train_loss = 0.89669219, grad/param norm = 1.8975e-01, time/batch = 0.6685s	
25158/33150 (epoch 37.946), train_loss = 0.75014587, grad/param norm = 1.4740e-01, time/batch = 0.6703s	
25159/33150 (epoch 37.947), train_loss = 0.87647769, grad/param norm = 1.8216e-01, time/batch = 0.6696s	
25160/33150 (epoch 37.949), train_loss = 0.94185590, grad/param norm = 1.5835e-01, time/batch = 0.6766s	
25161/33150 (epoch 37.950), train_loss = 0.90561091, grad/param norm = 1.7794e-01, time/batch = 0.6797s	
25162/33150 (epoch 37.952), train_loss = 0.77398091, grad/param norm = 1.6705e-01, time/batch = 0.6697s	
25163/33150 (epoch 37.953), train_loss = 0.84714535, grad/param norm = 1.6453e-01, time/batch = 0.6701s	
25164/33150 (epoch 37.955), train_loss = 0.73765701, grad/param norm = 1.7260e-01, time/batch = 0.6707s	
25165/33150 (epoch 37.956), train_loss = 0.90762321, grad/param norm = 1.8463e-01, time/batch = 0.6737s	
25166/33150 (epoch 37.958), train_loss = 0.75991338, grad/param norm = 1.6540e-01, time/batch = 0.6723s	
25167/33150 (epoch 37.959), train_loss = 0.83554759, grad/param norm = 1.6369e-01, time/batch = 0.6745s	
25168/33150 (epoch 37.961), train_loss = 0.76731415, grad/param norm = 1.8392e-01, time/batch = 0.6781s	
25169/33150 (epoch 37.962), train_loss = 0.70442672, grad/param norm = 1.5431e-01, time/batch = 0.6735s	
25170/33150 (epoch 37.964), train_loss = 0.83181922, grad/param norm = 1.9881e-01, time/batch = 0.6711s	
25171/33150 (epoch 37.965), train_loss = 0.81813049, grad/param norm = 1.6809e-01, time/batch = 0.6725s	
25172/33150 (epoch 37.967), train_loss = 0.82553527, grad/param norm = 2.0075e-01, time/batch = 0.6752s	
25173/33150 (epoch 37.968), train_loss = 0.70637454, grad/param norm = 1.4492e-01, time/batch = 0.6721s	
25174/33150 (epoch 37.970), train_loss = 0.80038046, grad/param norm = 1.6505e-01, time/batch = 0.6681s	
25175/33150 (epoch 37.971), train_loss = 0.82906493, grad/param norm = 1.9710e-01, time/batch = 0.6787s	
25176/33150 (epoch 37.973), train_loss = 0.94122552, grad/param norm = 1.9245e-01, time/batch = 0.6780s	
25177/33150 (epoch 37.974), train_loss = 0.97302476, grad/param norm = 1.8989e-01, time/batch = 0.6661s	
25178/33150 (epoch 37.976), train_loss = 0.93321858, grad/param norm = 1.6530e-01, time/batch = 0.6700s	
25179/33150 (epoch 37.977), train_loss = 0.95921430, grad/param norm = 1.8233e-01, time/batch = 0.6703s	
25180/33150 (epoch 37.979), train_loss = 0.91239527, grad/param norm = 2.0746e-01, time/batch = 0.6774s	
25181/33150 (epoch 37.980), train_loss = 0.99137492, grad/param norm = 1.9817e-01, time/batch = 0.6768s	
25182/33150 (epoch 37.982), train_loss = 0.84345039, grad/param norm = 1.9171e-01, time/batch = 0.6704s	
25183/33150 (epoch 37.983), train_loss = 0.76490974, grad/param norm = 1.7312e-01, time/batch = 0.6737s	
25184/33150 (epoch 37.985), train_loss = 0.95381569, grad/param norm = 1.6870e-01, time/batch = 0.6711s	
25185/33150 (epoch 37.986), train_loss = 0.71837625, grad/param norm = 1.5733e-01, time/batch = 0.6731s	
25186/33150 (epoch 37.988), train_loss = 0.80140475, grad/param norm = 2.7534e-01, time/batch = 0.6680s	
25187/33150 (epoch 37.989), train_loss = 0.81978562, grad/param norm = 1.7577e-01, time/batch = 0.6680s	
25188/33150 (epoch 37.991), train_loss = 0.90142466, grad/param norm = 2.7895e-01, time/batch = 0.6912s	
25189/33150 (epoch 37.992), train_loss = 0.83596427, grad/param norm = 1.7160e-01, time/batch = 0.6881s	
25190/33150 (epoch 37.994), train_loss = 0.86063127, grad/param norm = 1.7147e-01, time/batch = 0.6866s	
25191/33150 (epoch 37.995), train_loss = 0.82916088, grad/param norm = 2.0256e-01, time/batch = 0.6793s	
25192/33150 (epoch 37.997), train_loss = 0.85430638, grad/param norm = 2.1681e-01, time/batch = 0.6721s	
25193/33150 (epoch 37.998), train_loss = 0.73515007, grad/param norm = 1.6912e-01, time/batch = 0.6774s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
25194/33150 (epoch 38.000), train_loss = 0.74113155, grad/param norm = 1.8586e-01, time/batch = 0.6671s	
25195/33150 (epoch 38.002), train_loss = 1.14906470, grad/param norm = 2.0927e-01, time/batch = 0.6677s	
25196/33150 (epoch 38.003), train_loss = 0.76010749, grad/param norm = 1.8449e-01, time/batch = 0.6703s	
25197/33150 (epoch 38.005), train_loss = 0.73395726, grad/param norm = 1.6806e-01, time/batch = 0.6712s	
25198/33150 (epoch 38.006), train_loss = 0.70954874, grad/param norm = 1.6215e-01, time/batch = 0.6708s	
25199/33150 (epoch 38.008), train_loss = 0.90166133, grad/param norm = 2.0429e-01, time/batch = 0.6847s	
25200/33150 (epoch 38.009), train_loss = 0.86830841, grad/param norm = 1.7492e-01, time/batch = 0.6841s	
25201/33150 (epoch 38.011), train_loss = 0.92607585, grad/param norm = 1.7221e-01, time/batch = 0.6759s	
25202/33150 (epoch 38.012), train_loss = 0.82422951, grad/param norm = 1.8846e-01, time/batch = 0.6836s	
25203/33150 (epoch 38.014), train_loss = 0.76667213, grad/param norm = 1.7843e-01, time/batch = 0.6979s	
25204/33150 (epoch 38.015), train_loss = 0.74454275, grad/param norm = 1.7147e-01, time/batch = 0.6892s	
25205/33150 (epoch 38.017), train_loss = 0.77009638, grad/param norm = 1.7977e-01, time/batch = 0.6747s	
25206/33150 (epoch 38.018), train_loss = 0.84574683, grad/param norm = 2.1289e-01, time/batch = 0.6695s	
25207/33150 (epoch 38.020), train_loss = 0.92681271, grad/param norm = 2.2320e-01, time/batch = 0.6660s	
25208/33150 (epoch 38.021), train_loss = 0.75493206, grad/param norm = 1.9277e-01, time/batch = 0.6668s	
25209/33150 (epoch 38.023), train_loss = 1.00677762, grad/param norm = 1.8541e-01, time/batch = 0.6653s	
25210/33150 (epoch 38.024), train_loss = 0.90077576, grad/param norm = 1.9334e-01, time/batch = 0.6653s	
25211/33150 (epoch 38.026), train_loss = 0.66588852, grad/param norm = 1.4115e-01, time/batch = 0.6697s	
25212/33150 (epoch 38.027), train_loss = 0.67795286, grad/param norm = 1.5056e-01, time/batch = 0.6691s	
25213/33150 (epoch 38.029), train_loss = 0.77401431, grad/param norm = 1.8024e-01, time/batch = 0.6803s	
25214/33150 (epoch 38.030), train_loss = 0.80677287, grad/param norm = 1.4591e-01, time/batch = 0.6916s	
25215/33150 (epoch 38.032), train_loss = 0.73838807, grad/param norm = 1.9641e-01, time/batch = 0.6888s	
25216/33150 (epoch 38.033), train_loss = 0.75959929, grad/param norm = 1.6647e-01, time/batch = 0.6931s	
25217/33150 (epoch 38.035), train_loss = 1.00359383, grad/param norm = 1.9772e-01, time/batch = 0.6703s	
25218/33150 (epoch 38.036), train_loss = 0.90858402, grad/param norm = 1.9877e-01, time/batch = 0.6766s	
25219/33150 (epoch 38.038), train_loss = 1.02371526, grad/param norm = 2.3223e-01, time/batch = 0.6754s	
25220/33150 (epoch 38.039), train_loss = 0.91208658, grad/param norm = 1.6280e-01, time/batch = 0.6795s	
25221/33150 (epoch 38.041), train_loss = 0.84079096, grad/param norm = 1.7863e-01, time/batch = 0.6753s	
25222/33150 (epoch 38.042), train_loss = 0.78824616, grad/param norm = 1.8139e-01, time/batch = 0.6743s	
25223/33150 (epoch 38.044), train_loss = 0.84115316, grad/param norm = 1.8915e-01, time/batch = 0.6700s	
25224/33150 (epoch 38.045), train_loss = 0.89445569, grad/param norm = 1.4530e-01, time/batch = 0.6768s	
25225/33150 (epoch 38.047), train_loss = 0.76548115, grad/param norm = 1.6384e-01, time/batch = 0.6716s	
25226/33150 (epoch 38.048), train_loss = 0.93691773, grad/param norm = 2.2772e-01, time/batch = 0.6711s	
25227/33150 (epoch 38.050), train_loss = 0.83197382, grad/param norm = 2.0622e-01, time/batch = 0.6722s	
25228/33150 (epoch 38.051), train_loss = 0.85850289, grad/param norm = 1.5001e-01, time/batch = 0.6704s	
25229/33150 (epoch 38.053), train_loss = 0.86829581, grad/param norm = 1.7134e-01, time/batch = 0.6728s	
25230/33150 (epoch 38.054), train_loss = 0.98117618, grad/param norm = 1.7724e-01, time/batch = 0.6673s	
25231/33150 (epoch 38.056), train_loss = 0.83525959, grad/param norm = 1.7583e-01, time/batch = 0.6701s	
25232/33150 (epoch 38.057), train_loss = 0.89788856, grad/param norm = 1.7776e-01, time/batch = 0.6698s	
25233/33150 (epoch 38.059), train_loss = 0.75496046, grad/param norm = 1.6749e-01, time/batch = 0.6684s	
25234/33150 (epoch 38.060), train_loss = 0.74434297, grad/param norm = 1.5051e-01, time/batch = 0.6790s	
25235/33150 (epoch 38.062), train_loss = 0.82880759, grad/param norm = 1.7537e-01, time/batch = 0.6768s	
25236/33150 (epoch 38.063), train_loss = 0.76966733, grad/param norm = 1.8996e-01, time/batch = 0.6730s	
25237/33150 (epoch 38.065), train_loss = 0.80703957, grad/param norm = 1.5489e-01, time/batch = 0.6695s	
25238/33150 (epoch 38.066), train_loss = 0.80696498, grad/param norm = 1.6223e-01, time/batch = 0.6729s	
25239/33150 (epoch 38.068), train_loss = 0.88533924, grad/param norm = 1.6897e-01, time/batch = 0.6695s	
25240/33150 (epoch 38.069), train_loss = 0.88518878, grad/param norm = 2.0688e-01, time/batch = 0.6715s	
25241/33150 (epoch 38.071), train_loss = 0.86629307, grad/param norm = 1.8139e-01, time/batch = 0.6716s	
25242/33150 (epoch 38.072), train_loss = 0.86537693, grad/param norm = 1.7548e-01, time/batch = 0.6691s	
25243/33150 (epoch 38.074), train_loss = 0.71838529, grad/param norm = 1.8537e-01, time/batch = 0.6749s	
25244/33150 (epoch 38.075), train_loss = 0.73341992, grad/param norm = 1.6900e-01, time/batch = 0.6703s	
25245/33150 (epoch 38.077), train_loss = 0.87632730, grad/param norm = 2.4997e-01, time/batch = 0.6682s	
25246/33150 (epoch 38.078), train_loss = 0.97284883, grad/param norm = 2.1652e-01, time/batch = 0.6690s	
25247/33150 (epoch 38.080), train_loss = 0.97039636, grad/param norm = 1.8314e-01, time/batch = 0.6691s	
25248/33150 (epoch 38.081), train_loss = 0.74653909, grad/param norm = 1.9371e-01, time/batch = 0.6713s	
25249/33150 (epoch 38.083), train_loss = 0.60855229, grad/param norm = 1.6021e-01, time/batch = 0.6803s	
25250/33150 (epoch 38.084), train_loss = 0.70630599, grad/param norm = 1.6722e-01, time/batch = 0.6730s	
25251/33150 (epoch 38.086), train_loss = 0.76355412, grad/param norm = 1.9574e-01, time/batch = 0.6737s	
25252/33150 (epoch 38.087), train_loss = 0.72360234, grad/param norm = 1.6592e-01, time/batch = 0.6728s	
25253/33150 (epoch 38.089), train_loss = 0.78922556, grad/param norm = 1.9109e-01, time/batch = 0.6768s	
25254/33150 (epoch 38.090), train_loss = 0.79434956, grad/param norm = 1.6526e-01, time/batch = 0.6722s	
25255/33150 (epoch 38.092), train_loss = 0.77695304, grad/param norm = 1.9125e-01, time/batch = 0.6687s	
25256/33150 (epoch 38.094), train_loss = 0.87310336, grad/param norm = 1.9146e-01, time/batch = 0.6692s	
25257/33150 (epoch 38.095), train_loss = 0.76389576, grad/param norm = 1.5569e-01, time/batch = 0.6699s	
25258/33150 (epoch 38.097), train_loss = 0.71740706, grad/param norm = 1.6295e-01, time/batch = 0.6667s	
25259/33150 (epoch 38.098), train_loss = 1.05655376, grad/param norm = 1.9551e-01, time/batch = 0.6698s	
25260/33150 (epoch 38.100), train_loss = 1.02795628, grad/param norm = 1.9395e-01, time/batch = 0.6683s	
25261/33150 (epoch 38.101), train_loss = 0.78795754, grad/param norm = 1.7627e-01, time/batch = 0.6692s	
25262/33150 (epoch 38.103), train_loss = 0.84191847, grad/param norm = 1.7455e-01, time/batch = 0.6697s	
25263/33150 (epoch 38.104), train_loss = 0.77213889, grad/param norm = 1.8185e-01, time/batch = 0.6678s	
25264/33150 (epoch 38.106), train_loss = 0.92874163, grad/param norm = 1.8648e-01, time/batch = 0.6683s	
25265/33150 (epoch 38.107), train_loss = 1.02380366, grad/param norm = 1.9887e-01, time/batch = 0.6805s	
25266/33150 (epoch 38.109), train_loss = 0.82118722, grad/param norm = 1.5548e-01, time/batch = 0.6797s	
25267/33150 (epoch 38.110), train_loss = 0.93042141, grad/param norm = 1.9385e-01, time/batch = 0.6789s	
25268/33150 (epoch 38.112), train_loss = 0.75533066, grad/param norm = 1.6885e-01, time/batch = 0.6696s	
25269/33150 (epoch 38.113), train_loss = 0.81126238, grad/param norm = 1.7315e-01, time/batch = 0.6786s	
25270/33150 (epoch 38.115), train_loss = 1.01791535, grad/param norm = 2.1578e-01, time/batch = 0.6661s	
25271/33150 (epoch 38.116), train_loss = 0.89640809, grad/param norm = 1.6999e-01, time/batch = 0.6667s	
25272/33150 (epoch 38.118), train_loss = 0.86217506, grad/param norm = 1.7650e-01, time/batch = 0.6714s	
25273/33150 (epoch 38.119), train_loss = 0.88175239, grad/param norm = 2.0450e-01, time/batch = 0.6675s	
25274/33150 (epoch 38.121), train_loss = 0.81833383, grad/param norm = 1.6805e-01, time/batch = 0.6682s	
25275/33150 (epoch 38.122), train_loss = 0.98148316, grad/param norm = 2.0083e-01, time/batch = 0.6648s	
25276/33150 (epoch 38.124), train_loss = 0.69751883, grad/param norm = 1.4019e-01, time/batch = 0.6640s	
25277/33150 (epoch 38.125), train_loss = 0.95200583, grad/param norm = 2.0658e-01, time/batch = 0.6632s	
25278/33150 (epoch 38.127), train_loss = 0.86562624, grad/param norm = 1.7250e-01, time/batch = 0.6721s	
25279/33150 (epoch 38.128), train_loss = 0.88538000, grad/param norm = 1.9218e-01, time/batch = 0.6801s	
25280/33150 (epoch 38.130), train_loss = 0.84013460, grad/param norm = 1.7292e-01, time/batch = 0.6670s	
25281/33150 (epoch 38.131), train_loss = 1.03009389, grad/param norm = 1.8474e-01, time/batch = 0.6692s	
25282/33150 (epoch 38.133), train_loss = 0.78666791, grad/param norm = 1.5577e-01, time/batch = 0.6657s	
25283/33150 (epoch 38.134), train_loss = 0.95832924, grad/param norm = 1.8613e-01, time/batch = 0.6675s	
25284/33150 (epoch 38.136), train_loss = 0.87363798, grad/param norm = 2.1562e-01, time/batch = 0.6980s	
25285/33150 (epoch 38.137), train_loss = 0.91030510, grad/param norm = 1.6933e-01, time/batch = 0.6895s	
25286/33150 (epoch 38.139), train_loss = 0.91382932, grad/param norm = 1.8766e-01, time/batch = 0.6814s	
25287/33150 (epoch 38.140), train_loss = 1.02071473, grad/param norm = 1.9893e-01, time/batch = 0.6862s	
25288/33150 (epoch 38.142), train_loss = 0.90777047, grad/param norm = 1.8958e-01, time/batch = 0.6867s	
25289/33150 (epoch 38.143), train_loss = 0.85603878, grad/param norm = 2.0938e-01, time/batch = 0.6808s	
25290/33150 (epoch 38.145), train_loss = 0.80292998, grad/param norm = 1.6913e-01, time/batch = 0.6843s	
25291/33150 (epoch 38.146), train_loss = 0.94680680, grad/param norm = 2.1214e-01, time/batch = 0.6738s	
25292/33150 (epoch 38.148), train_loss = 0.99551220, grad/param norm = 1.6194e-01, time/batch = 0.6674s	
25293/33150 (epoch 38.149), train_loss = 0.87224792, grad/param norm = 2.1407e-01, time/batch = 0.6763s	
25294/33150 (epoch 38.151), train_loss = 1.01662347, grad/param norm = 2.1359e-01, time/batch = 0.6779s	
25295/33150 (epoch 38.152), train_loss = 0.79816210, grad/param norm = 1.6387e-01, time/batch = 0.6691s	
25296/33150 (epoch 38.154), train_loss = 0.81884895, grad/param norm = 1.9948e-01, time/batch = 0.6698s	
25297/33150 (epoch 38.155), train_loss = 0.74077045, grad/param norm = 1.6842e-01, time/batch = 0.6695s	
25298/33150 (epoch 38.157), train_loss = 0.82615013, grad/param norm = 1.8602e-01, time/batch = 0.6679s	
25299/33150 (epoch 38.158), train_loss = 0.82513208, grad/param norm = 1.6688e-01, time/batch = 0.6653s	
25300/33150 (epoch 38.160), train_loss = 0.91183139, grad/param norm = 1.8475e-01, time/batch = 0.6760s	
25301/33150 (epoch 38.161), train_loss = 0.80213242, grad/param norm = 1.8296e-01, time/batch = 0.6667s	
25302/33150 (epoch 38.163), train_loss = 0.74033609, grad/param norm = 1.5260e-01, time/batch = 0.6846s	
25303/33150 (epoch 38.164), train_loss = 0.87909076, grad/param norm = 1.7228e-01, time/batch = 0.6892s	
25304/33150 (epoch 38.166), train_loss = 0.81506810, grad/param norm = 1.8869e-01, time/batch = 0.6829s	
25305/33150 (epoch 38.167), train_loss = 0.88028887, grad/param norm = 1.6236e-01, time/batch = 0.6996s	
25306/33150 (epoch 38.169), train_loss = 0.84852319, grad/param norm = 2.0676e-01, time/batch = 0.6906s	
25307/33150 (epoch 38.170), train_loss = 0.76264328, grad/param norm = 2.0002e-01, time/batch = 0.6915s	
25308/33150 (epoch 38.172), train_loss = 0.90558326, grad/param norm = 2.1317e-01, time/batch = 0.6902s	
25309/33150 (epoch 38.173), train_loss = 0.86734253, grad/param norm = 1.9960e-01, time/batch = 0.6905s	
25310/33150 (epoch 38.175), train_loss = 0.82370526, grad/param norm = 2.2876e-01, time/batch = 0.6719s	
25311/33150 (epoch 38.176), train_loss = 0.90395543, grad/param norm = 1.9848e-01, time/batch = 0.6741s	
25312/33150 (epoch 38.178), train_loss = 1.02695496, grad/param norm = 2.3972e-01, time/batch = 0.6809s	
25313/33150 (epoch 38.179), train_loss = 0.92173919, grad/param norm = 1.7646e-01, time/batch = 0.6742s	
25314/33150 (epoch 38.181), train_loss = 0.87396196, grad/param norm = 2.2176e-01, time/batch = 0.6679s	
25315/33150 (epoch 38.183), train_loss = 0.84271108, grad/param norm = 1.9069e-01, time/batch = 0.6724s	
25316/33150 (epoch 38.184), train_loss = 1.07203546, grad/param norm = 1.8317e-01, time/batch = 0.6641s	
25317/33150 (epoch 38.186), train_loss = 1.01352705, grad/param norm = 1.8748e-01, time/batch = 0.6704s	
25318/33150 (epoch 38.187), train_loss = 0.87189142, grad/param norm = 1.7999e-01, time/batch = 0.6665s	
25319/33150 (epoch 38.189), train_loss = 0.68136898, grad/param norm = 1.7471e-01, time/batch = 0.6677s	
25320/33150 (epoch 38.190), train_loss = 0.76636675, grad/param norm = 1.9158e-01, time/batch = 0.6697s	
25321/33150 (epoch 38.192), train_loss = 0.87809126, grad/param norm = 1.9066e-01, time/batch = 0.6679s	
25322/33150 (epoch 38.193), train_loss = 0.91430951, grad/param norm = 1.8870e-01, time/batch = 0.6717s	
25323/33150 (epoch 38.195), train_loss = 1.03911057, grad/param norm = 1.9264e-01, time/batch = 0.6805s	
25324/33150 (epoch 38.196), train_loss = 0.96410469, grad/param norm = 1.8135e-01, time/batch = 0.6727s	
25325/33150 (epoch 38.198), train_loss = 0.75879003, grad/param norm = 1.5550e-01, time/batch = 0.6773s	
25326/33150 (epoch 38.199), train_loss = 0.95014001, grad/param norm = 3.0271e-01, time/batch = 0.6727s	
25327/33150 (epoch 38.201), train_loss = 0.81663260, grad/param norm = 1.7497e-01, time/batch = 0.6754s	
25328/33150 (epoch 38.202), train_loss = 0.68542141, grad/param norm = 1.7000e-01, time/batch = 0.6765s	
25329/33150 (epoch 38.204), train_loss = 0.88820701, grad/param norm = 1.9282e-01, time/batch = 0.6698s	
25330/33150 (epoch 38.205), train_loss = 0.89665747, grad/param norm = 1.9110e-01, time/batch = 0.6737s	
25331/33150 (epoch 38.207), train_loss = 0.89126343, grad/param norm = 1.7823e-01, time/batch = 0.6739s	
25332/33150 (epoch 38.208), train_loss = 0.92824648, grad/param norm = 2.1087e-01, time/batch = 0.6729s	
25333/33150 (epoch 38.210), train_loss = 0.81047367, grad/param norm = 1.6885e-01, time/batch = 0.6729s	
25334/33150 (epoch 38.211), train_loss = 0.84483435, grad/param norm = 1.9054e-01, time/batch = 0.6698s	
25335/33150 (epoch 38.213), train_loss = 0.92565829, grad/param norm = 1.9181e-01, time/batch = 0.6701s	
25336/33150 (epoch 38.214), train_loss = 0.82724796, grad/param norm = 1.5829e-01, time/batch = 0.6672s	
25337/33150 (epoch 38.216), train_loss = 0.77898327, grad/param norm = 1.9737e-01, time/batch = 0.6735s	
25338/33150 (epoch 38.217), train_loss = 0.85332088, grad/param norm = 1.8738e-01, time/batch = 0.6797s	
25339/33150 (epoch 38.219), train_loss = 0.79905404, grad/param norm = 1.7639e-01, time/batch = 0.6682s	
25340/33150 (epoch 38.220), train_loss = 0.82351648, grad/param norm = 1.4530e-01, time/batch = 0.6663s	
25341/33150 (epoch 38.222), train_loss = 0.94773787, grad/param norm = 1.8643e-01, time/batch = 0.6679s	
25342/33150 (epoch 38.223), train_loss = 0.84072331, grad/param norm = 1.7437e-01, time/batch = 0.6675s	
25343/33150 (epoch 38.225), train_loss = 0.96746705, grad/param norm = 1.8853e-01, time/batch = 0.6716s	
25344/33150 (epoch 38.226), train_loss = 0.82322415, grad/param norm = 1.8791e-01, time/batch = 0.6707s	
25345/33150 (epoch 38.228), train_loss = 0.82594713, grad/param norm = 1.9547e-01, time/batch = 0.6709s	
25346/33150 (epoch 38.229), train_loss = 0.83083396, grad/param norm = 1.6863e-01, time/batch = 0.6687s	
25347/33150 (epoch 38.231), train_loss = 0.95233117, grad/param norm = 2.3545e-01, time/batch = 0.6772s	
25348/33150 (epoch 38.232), train_loss = 0.83042191, grad/param norm = 1.7385e-01, time/batch = 0.6773s	
25349/33150 (epoch 38.234), train_loss = 0.89142064, grad/param norm = 1.8187e-01, time/batch = 0.6673s	
25350/33150 (epoch 38.235), train_loss = 0.91651372, grad/param norm = 2.0576e-01, time/batch = 0.6822s	
25351/33150 (epoch 38.237), train_loss = 0.87570288, grad/param norm = 2.0761e-01, time/batch = 0.6715s	
25352/33150 (epoch 38.238), train_loss = 0.91126256, grad/param norm = 2.0185e-01, time/batch = 0.6773s	
25353/33150 (epoch 38.240), train_loss = 0.86787533, grad/param norm = 1.7659e-01, time/batch = 0.6825s	
25354/33150 (epoch 38.241), train_loss = 0.93053651, grad/param norm = 1.9605e-01, time/batch = 0.6690s	
25355/33150 (epoch 38.243), train_loss = 0.92706989, grad/param norm = 1.8004e-01, time/batch = 0.6637s	
25356/33150 (epoch 38.244), train_loss = 0.87587488, grad/param norm = 1.7240e-01, time/batch = 0.6654s	
25357/33150 (epoch 38.246), train_loss = 0.94757525, grad/param norm = 1.9022e-01, time/batch = 0.6662s	
25358/33150 (epoch 38.247), train_loss = 0.79934695, grad/param norm = 1.6131e-01, time/batch = 0.6703s	
25359/33150 (epoch 38.249), train_loss = 0.98150996, grad/param norm = 1.7108e-01, time/batch = 0.6675s	
25360/33150 (epoch 38.250), train_loss = 0.91424916, grad/param norm = 1.7401e-01, time/batch = 0.6673s	
25361/33150 (epoch 38.252), train_loss = 0.90981054, grad/param norm = 1.6175e-01, time/batch = 0.6707s	
25362/33150 (epoch 38.253), train_loss = 0.84070410, grad/param norm = 1.8186e-01, time/batch = 0.6729s	
25363/33150 (epoch 38.255), train_loss = 0.83579249, grad/param norm = 1.4674e-01, time/batch = 0.6736s	
25364/33150 (epoch 38.256), train_loss = 0.95498164, grad/param norm = 1.8314e-01, time/batch = 0.6664s	
25365/33150 (epoch 38.258), train_loss = 0.81146230, grad/param norm = 2.1665e-01, time/batch = 0.6680s	
25366/33150 (epoch 38.259), train_loss = 0.70377219, grad/param norm = 1.7115e-01, time/batch = 0.6695s	
25367/33150 (epoch 38.261), train_loss = 0.77337554, grad/param norm = 1.5395e-01, time/batch = 0.6774s	
25368/33150 (epoch 38.262), train_loss = 0.97752984, grad/param norm = 1.9184e-01, time/batch = 0.6732s	
25369/33150 (epoch 38.264), train_loss = 0.67412002, grad/param norm = 1.5405e-01, time/batch = 0.6657s	
25370/33150 (epoch 38.265), train_loss = 0.87059623, grad/param norm = 1.7944e-01, time/batch = 0.6597s	
25371/33150 (epoch 38.267), train_loss = 0.97788924, grad/param norm = 2.5384e-01, time/batch = 0.6648s	
25372/33150 (epoch 38.268), train_loss = 0.97327647, grad/param norm = 1.6758e-01, time/batch = 0.6637s	
25373/33150 (epoch 38.270), train_loss = 1.04354935, grad/param norm = 1.7297e-01, time/batch = 0.6653s	
25374/33150 (epoch 38.271), train_loss = 0.92124752, grad/param norm = 1.9367e-01, time/batch = 0.6612s	
25375/33150 (epoch 38.273), train_loss = 0.98216241, grad/param norm = 2.0560e-01, time/batch = 0.6634s	
25376/33150 (epoch 38.275), train_loss = 0.98986900, grad/param norm = 1.8308e-01, time/batch = 0.6614s	
25377/33150 (epoch 38.276), train_loss = 0.86368560, grad/param norm = 1.7174e-01, time/batch = 0.6635s	
25378/33150 (epoch 38.278), train_loss = 0.98705603, grad/param norm = 1.8290e-01, time/batch = 0.6598s	
25379/33150 (epoch 38.279), train_loss = 0.93494814, grad/param norm = 1.5849e-01, time/batch = 0.6615s	
25380/33150 (epoch 38.281), train_loss = 0.87813527, grad/param norm = 1.7126e-01, time/batch = 0.6607s	
25381/33150 (epoch 38.282), train_loss = 0.91855130, grad/param norm = 1.5498e-01, time/batch = 0.6636s	
25382/33150 (epoch 38.284), train_loss = 0.79182716, grad/param norm = 1.6765e-01, time/batch = 0.6798s	
25383/33150 (epoch 38.285), train_loss = 0.90061524, grad/param norm = 1.9738e-01, time/batch = 0.6831s	
25384/33150 (epoch 38.287), train_loss = 0.75924443, grad/param norm = 1.7297e-01, time/batch = 0.6854s	
25385/33150 (epoch 38.288), train_loss = 0.92529872, grad/param norm = 1.6129e-01, time/batch = 0.6823s	
25386/33150 (epoch 38.290), train_loss = 0.73863590, grad/param norm = 1.6037e-01, time/batch = 0.6835s	
25387/33150 (epoch 38.291), train_loss = 0.71808546, grad/param norm = 1.8492e-01, time/batch = 0.6824s	
25388/33150 (epoch 38.293), train_loss = 0.83255159, grad/param norm = 1.7390e-01, time/batch = 0.6675s	
25389/33150 (epoch 38.294), train_loss = 0.66953882, grad/param norm = 1.7866e-01, time/batch = 0.6822s	
25390/33150 (epoch 38.296), train_loss = 0.85245775, grad/param norm = 1.6172e-01, time/batch = 0.6748s	
25391/33150 (epoch 38.297), train_loss = 0.79955268, grad/param norm = 1.7981e-01, time/batch = 0.6902s	
25392/33150 (epoch 38.299), train_loss = 0.81332229, grad/param norm = 1.9153e-01, time/batch = 0.6905s	
25393/33150 (epoch 38.300), train_loss = 0.81481172, grad/param norm = 1.5867e-01, time/batch = 0.6904s	
25394/33150 (epoch 38.302), train_loss = 0.82057957, grad/param norm = 1.4855e-01, time/batch = 0.6685s	
25395/33150 (epoch 38.303), train_loss = 0.82098475, grad/param norm = 1.8021e-01, time/batch = 0.6718s	
25396/33150 (epoch 38.305), train_loss = 0.89540874, grad/param norm = 1.6252e-01, time/batch = 0.6723s	
25397/33150 (epoch 38.306), train_loss = 0.91019528, grad/param norm = 1.7434e-01, time/batch = 0.6801s	
25398/33150 (epoch 38.308), train_loss = 1.05808504, grad/param norm = 2.0235e-01, time/batch = 0.6746s	
25399/33150 (epoch 38.309), train_loss = 0.71034112, grad/param norm = 1.4752e-01, time/batch = 0.6726s	
25400/33150 (epoch 38.311), train_loss = 0.84084690, grad/param norm = 1.7602e-01, time/batch = 0.6715s	
25401/33150 (epoch 38.312), train_loss = 0.69554577, grad/param norm = 1.7715e-01, time/batch = 0.6715s	
25402/33150 (epoch 38.314), train_loss = 0.81974643, grad/param norm = 1.7972e-01, time/batch = 0.6713s	
25403/33150 (epoch 38.315), train_loss = 0.90218273, grad/param norm = 1.6341e-01, time/batch = 0.6715s	
25404/33150 (epoch 38.317), train_loss = 0.68157723, grad/param norm = 1.3644e-01, time/batch = 0.6692s	
25405/33150 (epoch 38.318), train_loss = 0.79217202, grad/param norm = 1.6316e-01, time/batch = 0.6665s	
25406/33150 (epoch 38.320), train_loss = 0.71765871, grad/param norm = 1.6895e-01, time/batch = 0.6703s	
25407/33150 (epoch 38.321), train_loss = 0.82206077, grad/param norm = 1.5380e-01, time/batch = 0.6726s	
25408/33150 (epoch 38.323), train_loss = 0.79885301, grad/param norm = 1.7038e-01, time/batch = 0.6893s	
25409/33150 (epoch 38.324), train_loss = 0.85087158, grad/param norm = 2.2226e-01, time/batch = 0.6724s	
25410/33150 (epoch 38.326), train_loss = 0.84133476, grad/param norm = 1.7291e-01, time/batch = 0.6706s	
25411/33150 (epoch 38.327), train_loss = 0.93365728, grad/param norm = 1.7340e-01, time/batch = 0.6681s	
25412/33150 (epoch 38.329), train_loss = 0.90160642, grad/param norm = 1.8107e-01, time/batch = 0.6646s	
25413/33150 (epoch 38.330), train_loss = 0.80745409, grad/param norm = 1.7062e-01, time/batch = 0.6863s	
25414/33150 (epoch 38.332), train_loss = 0.82622973, grad/param norm = 1.7323e-01, time/batch = 0.6756s	
25415/33150 (epoch 38.333), train_loss = 0.91304610, grad/param norm = 1.6132e-01, time/batch = 0.6883s	
25416/33150 (epoch 38.335), train_loss = 0.77795983, grad/param norm = 1.7325e-01, time/batch = 0.6751s	
25417/33150 (epoch 38.336), train_loss = 0.76771187, grad/param norm = 1.8497e-01, time/batch = 0.6704s	
25418/33150 (epoch 38.338), train_loss = 0.73466507, grad/param norm = 1.8346e-01, time/batch = 0.6674s	
25419/33150 (epoch 38.339), train_loss = 0.91579207, grad/param norm = 1.8374e-01, time/batch = 0.6662s	
25420/33150 (epoch 38.341), train_loss = 0.84562831, grad/param norm = 1.9628e-01, time/batch = 0.6698s	
25421/33150 (epoch 38.342), train_loss = 0.79484077, grad/param norm = 1.6734e-01, time/batch = 0.6744s	
25422/33150 (epoch 38.344), train_loss = 0.83828325, grad/param norm = 1.8157e-01, time/batch = 0.6720s	
25423/33150 (epoch 38.345), train_loss = 0.81222214, grad/param norm = 1.7441e-01, time/batch = 0.6712s	
25424/33150 (epoch 38.347), train_loss = 0.69963154, grad/param norm = 1.6842e-01, time/batch = 0.6665s	
25425/33150 (epoch 38.348), train_loss = 0.87478394, grad/param norm = 1.6781e-01, time/batch = 0.6694s	
25426/33150 (epoch 38.350), train_loss = 0.76281417, grad/param norm = 1.8151e-01, time/batch = 0.6737s	
25427/33150 (epoch 38.351), train_loss = 0.92229266, grad/param norm = 1.9741e-01, time/batch = 0.6708s	
25428/33150 (epoch 38.353), train_loss = 0.88693388, grad/param norm = 2.0253e-01, time/batch = 0.6707s	
25429/33150 (epoch 38.354), train_loss = 1.05045510, grad/param norm = 1.8264e-01, time/batch = 0.6726s	
25430/33150 (epoch 38.356), train_loss = 0.93111635, grad/param norm = 1.7850e-01, time/batch = 0.6707s	
25431/33150 (epoch 38.357), train_loss = 0.86455579, grad/param norm = 1.8847e-01, time/batch = 0.6816s	
25432/33150 (epoch 38.359), train_loss = 0.91006487, grad/param norm = 1.5979e-01, time/batch = 0.6732s	
25433/33150 (epoch 38.360), train_loss = 0.89914615, grad/param norm = 2.0138e-01, time/batch = 0.6686s	
25434/33150 (epoch 38.362), train_loss = 0.95208049, grad/param norm = 1.6677e-01, time/batch = 0.6679s	
25435/33150 (epoch 38.363), train_loss = 0.88593705, grad/param norm = 1.7220e-01, time/batch = 0.6706s	
25436/33150 (epoch 38.365), train_loss = 0.83458510, grad/param norm = 1.8924e-01, time/batch = 0.6708s	
25437/33150 (epoch 38.367), train_loss = 0.80382307, grad/param norm = 1.5588e-01, time/batch = 0.6700s	
25438/33150 (epoch 38.368), train_loss = 0.82623643, grad/param norm = 1.8605e-01, time/batch = 0.6709s	
25439/33150 (epoch 38.370), train_loss = 0.86434132, grad/param norm = 2.1259e-01, time/batch = 0.6684s	
25440/33150 (epoch 38.371), train_loss = 0.76270889, grad/param norm = 1.7111e-01, time/batch = 0.6703s	
25441/33150 (epoch 38.373), train_loss = 0.89363947, grad/param norm = 1.8284e-01, time/batch = 0.6777s	
25442/33150 (epoch 38.374), train_loss = 0.86052739, grad/param norm = 1.5584e-01, time/batch = 0.6685s	
25443/33150 (epoch 38.376), train_loss = 0.92284576, grad/param norm = 1.6185e-01, time/batch = 0.6680s	
25444/33150 (epoch 38.377), train_loss = 0.77427259, grad/param norm = 1.7658e-01, time/batch = 0.6669s	
25445/33150 (epoch 38.379), train_loss = 0.88635979, grad/param norm = 1.8174e-01, time/batch = 0.6716s	
25446/33150 (epoch 38.380), train_loss = 0.90753199, grad/param norm = 1.6723e-01, time/batch = 0.6759s	
25447/33150 (epoch 38.382), train_loss = 0.85119839, grad/param norm = 1.7848e-01, time/batch = 0.6666s	
25448/33150 (epoch 38.383), train_loss = 0.76888263, grad/param norm = 1.6213e-01, time/batch = 0.6670s	
25449/33150 (epoch 38.385), train_loss = 0.79486064, grad/param norm = 1.7329e-01, time/batch = 0.6687s	
25450/33150 (epoch 38.386), train_loss = 0.73494951, grad/param norm = 1.4376e-01, time/batch = 0.6719s	
25451/33150 (epoch 38.388), train_loss = 0.77522459, grad/param norm = 1.5891e-01, time/batch = 0.6763s	
25452/33150 (epoch 38.389), train_loss = 0.77578335, grad/param norm = 1.6193e-01, time/batch = 0.6715s	
25453/33150 (epoch 38.391), train_loss = 0.98738241, grad/param norm = 2.0792e-01, time/batch = 0.6743s	
25454/33150 (epoch 38.392), train_loss = 0.79993272, grad/param norm = 1.8550e-01, time/batch = 0.6791s	
25455/33150 (epoch 38.394), train_loss = 0.72676003, grad/param norm = 1.4860e-01, time/batch = 0.6726s	
25456/33150 (epoch 38.395), train_loss = 0.70028873, grad/param norm = 1.6967e-01, time/batch = 0.6701s	
25457/33150 (epoch 38.397), train_loss = 0.59360950, grad/param norm = 1.5840e-01, time/batch = 0.6723s	
25458/33150 (epoch 38.398), train_loss = 0.82760065, grad/param norm = 1.5968e-01, time/batch = 0.6796s	
25459/33150 (epoch 38.400), train_loss = 0.82553393, grad/param norm = 1.4297e-01, time/batch = 0.6930s	
25460/33150 (epoch 38.401), train_loss = 0.70404535, grad/param norm = 1.3680e-01, time/batch = 0.6841s	
25461/33150 (epoch 38.403), train_loss = 0.72179553, grad/param norm = 1.5246e-01, time/batch = 0.6838s	
25462/33150 (epoch 38.404), train_loss = 0.86277138, grad/param norm = 1.7000e-01, time/batch = 0.6843s	
25463/33150 (epoch 38.406), train_loss = 0.80156366, grad/param norm = 1.4381e-01, time/batch = 0.6689s	
25464/33150 (epoch 38.407), train_loss = 0.71316610, grad/param norm = 1.4777e-01, time/batch = 0.6715s	
25465/33150 (epoch 38.409), train_loss = 0.67997461, grad/param norm = 1.5317e-01, time/batch = 0.6713s	
25466/33150 (epoch 38.410), train_loss = 0.85054095, grad/param norm = 1.6573e-01, time/batch = 0.6706s	
25467/33150 (epoch 38.412), train_loss = 0.89897986, grad/param norm = 1.6017e-01, time/batch = 0.6697s	
25468/33150 (epoch 38.413), train_loss = 0.74371296, grad/param norm = 1.5782e-01, time/batch = 0.6701s	
25469/33150 (epoch 38.415), train_loss = 0.86595027, grad/param norm = 1.5538e-01, time/batch = 0.6770s	
25470/33150 (epoch 38.416), train_loss = 0.77283945, grad/param norm = 1.4784e-01, time/batch = 0.6757s	
25471/33150 (epoch 38.418), train_loss = 0.85985710, grad/param norm = 2.0259e-01, time/batch = 0.6744s	
25472/33150 (epoch 38.419), train_loss = 0.81726143, grad/param norm = 1.6250e-01, time/batch = 0.6710s	
25473/33150 (epoch 38.421), train_loss = 0.85300472, grad/param norm = 2.0311e-01, time/batch = 0.6724s	
25474/33150 (epoch 38.422), train_loss = 0.81350318, grad/param norm = 1.6871e-01, time/batch = 0.6688s	
25475/33150 (epoch 38.424), train_loss = 0.77375007, grad/param norm = 1.6785e-01, time/batch = 0.6777s	
25476/33150 (epoch 38.425), train_loss = 0.91261365, grad/param norm = 1.7444e-01, time/batch = 0.6765s	
25477/33150 (epoch 38.427), train_loss = 0.83703785, grad/param norm = 1.6210e-01, time/batch = 0.6688s	
25478/33150 (epoch 38.428), train_loss = 0.80449259, grad/param norm = 1.6039e-01, time/batch = 0.6692s	
25479/33150 (epoch 38.430), train_loss = 0.86626299, grad/param norm = 1.8768e-01, time/batch = 0.6751s	
25480/33150 (epoch 38.431), train_loss = 0.90547340, grad/param norm = 1.9799e-01, time/batch = 0.6873s	
25481/33150 (epoch 38.433), train_loss = 0.82063648, grad/param norm = 1.6747e-01, time/batch = 0.6888s	
25482/33150 (epoch 38.434), train_loss = 0.72282386, grad/param norm = 1.4949e-01, time/batch = 0.6883s	
25483/33150 (epoch 38.436), train_loss = 0.83594996, grad/param norm = 1.5708e-01, time/batch = 0.6727s	
25484/33150 (epoch 38.437), train_loss = 0.83838347, grad/param norm = 1.9265e-01, time/batch = 0.6729s	
25485/33150 (epoch 38.439), train_loss = 0.99071820, grad/param norm = 1.8101e-01, time/batch = 0.6768s	
25486/33150 (epoch 38.440), train_loss = 0.88444250, grad/param norm = 2.3666e-01, time/batch = 0.6852s	
25487/33150 (epoch 38.442), train_loss = 0.73978960, grad/param norm = 1.7446e-01, time/batch = 0.6893s	
25488/33150 (epoch 38.443), train_loss = 0.86976723, grad/param norm = 1.9479e-01, time/batch = 0.6896s	
25489/33150 (epoch 38.445), train_loss = 0.84790415, grad/param norm = 1.9875e-01, time/batch = 0.6776s	
25490/33150 (epoch 38.446), train_loss = 0.87602239, grad/param norm = 2.2024e-01, time/batch = 0.6802s	
25491/33150 (epoch 38.448), train_loss = 0.94738638, grad/param norm = 2.0057e-01, time/batch = 0.6780s	
25492/33150 (epoch 38.449), train_loss = 0.83315574, grad/param norm = 1.4979e-01, time/batch = 0.6760s	
25493/33150 (epoch 38.451), train_loss = 0.84837936, grad/param norm = 1.8577e-01, time/batch = 0.6730s	
25494/33150 (epoch 38.452), train_loss = 1.02117264, grad/param norm = 1.8426e-01, time/batch = 0.6740s	
25495/33150 (epoch 38.454), train_loss = 0.82428695, grad/param norm = 1.6609e-01, time/batch = 0.6778s	
25496/33150 (epoch 38.456), train_loss = 0.78909747, grad/param norm = 1.5932e-01, time/batch = 0.6764s	
25497/33150 (epoch 38.457), train_loss = 0.86516183, grad/param norm = 1.8893e-01, time/batch = 0.6767s	
25498/33150 (epoch 38.459), train_loss = 0.96716223, grad/param norm = 2.6546e-01, time/batch = 0.6765s	
25499/33150 (epoch 38.460), train_loss = 0.90061738, grad/param norm = 1.6340e-01, time/batch = 0.6758s	
25500/33150 (epoch 38.462), train_loss = 0.95811216, grad/param norm = 2.3058e-01, time/batch = 0.6739s	
25501/33150 (epoch 38.463), train_loss = 1.08612651, grad/param norm = 2.4056e-01, time/batch = 0.6834s	
25502/33150 (epoch 38.465), train_loss = 0.91501639, grad/param norm = 1.7382e-01, time/batch = 0.6766s	
25503/33150 (epoch 38.466), train_loss = 0.81271430, grad/param norm = 1.7308e-01, time/batch = 0.6727s	
25504/33150 (epoch 38.468), train_loss = 1.04421727, grad/param norm = 1.8665e-01, time/batch = 0.6760s	
25505/33150 (epoch 38.469), train_loss = 0.79402037, grad/param norm = 2.0569e-01, time/batch = 0.6732s	
25506/33150 (epoch 38.471), train_loss = 0.78802741, grad/param norm = 1.6564e-01, time/batch = 0.6758s	
25507/33150 (epoch 38.472), train_loss = 0.87661520, grad/param norm = 2.0963e-01, time/batch = 0.6728s	
25508/33150 (epoch 38.474), train_loss = 0.93704280, grad/param norm = 2.4500e-01, time/batch = 0.6706s	
25509/33150 (epoch 38.475), train_loss = 1.09561112, grad/param norm = 2.0564e-01, time/batch = 0.6706s	
25510/33150 (epoch 38.477), train_loss = 0.91163089, grad/param norm = 1.7393e-01, time/batch = 0.6730s	
25511/33150 (epoch 38.478), train_loss = 0.88563354, grad/param norm = 1.6562e-01, time/batch = 0.6734s	
25512/33150 (epoch 38.480), train_loss = 0.78757705, grad/param norm = 1.8371e-01, time/batch = 0.6722s	
25513/33150 (epoch 38.481), train_loss = 0.73344283, grad/param norm = 1.6730e-01, time/batch = 0.6744s	
25514/33150 (epoch 38.483), train_loss = 0.80956378, grad/param norm = 1.8123e-01, time/batch = 0.6730s	
25515/33150 (epoch 38.484), train_loss = 0.77473146, grad/param norm = 1.7260e-01, time/batch = 0.6840s	
25516/33150 (epoch 38.486), train_loss = 0.78668787, grad/param norm = 1.7812e-01, time/batch = 0.6821s	
25517/33150 (epoch 38.487), train_loss = 0.91452136, grad/param norm = 1.7684e-01, time/batch = 0.6841s	
25518/33150 (epoch 38.489), train_loss = 0.84908252, grad/param norm = 1.8236e-01, time/batch = 0.6880s	
25519/33150 (epoch 38.490), train_loss = 0.68839343, grad/param norm = 1.5618e-01, time/batch = 0.6874s	
25520/33150 (epoch 38.492), train_loss = 0.80239106, grad/param norm = 1.7259e-01, time/batch = 0.6880s	
25521/33150 (epoch 38.493), train_loss = 0.90537775, grad/param norm = 1.8306e-01, time/batch = 0.6914s	
25522/33150 (epoch 38.495), train_loss = 0.89791011, grad/param norm = 1.6615e-01, time/batch = 0.6890s	
25523/33150 (epoch 38.496), train_loss = 0.83414001, grad/param norm = 1.7389e-01, time/batch = 0.6906s	
25524/33150 (epoch 38.498), train_loss = 0.92417256, grad/param norm = 2.1489e-01, time/batch = 0.6887s	
25525/33150 (epoch 38.499), train_loss = 0.94344245, grad/param norm = 1.6750e-01, time/batch = 0.6809s	
25526/33150 (epoch 38.501), train_loss = 0.88191510, grad/param norm = 1.9314e-01, time/batch = 0.6770s	
25527/33150 (epoch 38.502), train_loss = 0.95181779, grad/param norm = 2.2255e-01, time/batch = 0.6740s	
25528/33150 (epoch 38.504), train_loss = 0.94668055, grad/param norm = 1.8920e-01, time/batch = 0.6807s	
25529/33150 (epoch 38.505), train_loss = 0.96857870, grad/param norm = 1.9492e-01, time/batch = 0.6700s	
25530/33150 (epoch 38.507), train_loss = 0.80147931, grad/param norm = 1.9356e-01, time/batch = 0.6716s	
25531/33150 (epoch 38.508), train_loss = 0.79287837, grad/param norm = 1.7914e-01, time/batch = 0.6954s	
25532/33150 (epoch 38.510), train_loss = 0.92508465, grad/param norm = 1.5612e-01, time/batch = 0.6742s	
25533/33150 (epoch 38.511), train_loss = 0.95996121, grad/param norm = 1.8268e-01, time/batch = 0.6783s	
25534/33150 (epoch 38.513), train_loss = 0.86816879, grad/param norm = 1.9042e-01, time/batch = 0.6801s	
25535/33150 (epoch 38.514), train_loss = 0.75747896, grad/param norm = 1.8702e-01, time/batch = 0.6769s	
25536/33150 (epoch 38.516), train_loss = 0.88127409, grad/param norm = 2.0174e-01, time/batch = 0.6748s	
25537/33150 (epoch 38.517), train_loss = 0.93485903, grad/param norm = 2.0438e-01, time/batch = 0.6685s	
25538/33150 (epoch 38.519), train_loss = 0.78563498, grad/param norm = 1.6191e-01, time/batch = 0.6702s	
25539/33150 (epoch 38.520), train_loss = 0.84640088, grad/param norm = 1.5655e-01, time/batch = 0.6749s	
25540/33150 (epoch 38.522), train_loss = 0.91567545, grad/param norm = 1.9085e-01, time/batch = 0.6722s	
25541/33150 (epoch 38.523), train_loss = 0.75695789, grad/param norm = 1.7760e-01, time/batch = 0.6694s	
25542/33150 (epoch 38.525), train_loss = 0.89354427, grad/param norm = 2.0167e-01, time/batch = 0.6715s	
25543/33150 (epoch 38.526), train_loss = 0.77621566, grad/param norm = 1.6469e-01, time/batch = 0.6700s	
25544/33150 (epoch 38.528), train_loss = 0.86127555, grad/param norm = 1.7568e-01, time/batch = 0.6716s	
25545/33150 (epoch 38.529), train_loss = 0.84171119, grad/param norm = 1.6875e-01, time/batch = 0.6734s	
25546/33150 (epoch 38.531), train_loss = 0.73397210, grad/param norm = 2.1941e-01, time/batch = 0.6712s	
25547/33150 (epoch 38.532), train_loss = 0.87921380, grad/param norm = 1.8926e-01, time/batch = 0.6716s	
25548/33150 (epoch 38.534), train_loss = 0.85373850, grad/param norm = 1.6827e-01, time/batch = 0.6719s	
25549/33150 (epoch 38.535), train_loss = 0.78146622, grad/param norm = 2.0783e-01, time/batch = 0.6714s	
25550/33150 (epoch 38.537), train_loss = 0.88685408, grad/param norm = 2.1708e-01, time/batch = 0.6713s	
25551/33150 (epoch 38.538), train_loss = 0.76271564, grad/param norm = 1.6733e-01, time/batch = 0.6751s	
25552/33150 (epoch 38.540), train_loss = 0.75343358, grad/param norm = 1.7305e-01, time/batch = 0.6866s	
25553/33150 (epoch 38.541), train_loss = 0.94479237, grad/param norm = 1.9008e-01, time/batch = 0.6741s	
25554/33150 (epoch 38.543), train_loss = 0.86560540, grad/param norm = 1.7603e-01, time/batch = 0.6760s	
25555/33150 (epoch 38.544), train_loss = 0.91461167, grad/param norm = 1.7059e-01, time/batch = 0.6807s	
25556/33150 (epoch 38.546), train_loss = 0.81735186, grad/param norm = 1.7637e-01, time/batch = 0.6700s	
25557/33150 (epoch 38.548), train_loss = 0.81725298, grad/param norm = 1.8793e-01, time/batch = 0.6710s	
25558/33150 (epoch 38.549), train_loss = 0.81406483, grad/param norm = 2.0136e-01, time/batch = 0.6715s	
25559/33150 (epoch 38.551), train_loss = 0.77893972, grad/param norm = 1.6235e-01, time/batch = 0.6668s	
25560/33150 (epoch 38.552), train_loss = 0.66438667, grad/param norm = 1.3788e-01, time/batch = 0.6783s	
25561/33150 (epoch 38.554), train_loss = 0.91338889, grad/param norm = 1.8917e-01, time/batch = 0.6759s	
25562/33150 (epoch 38.555), train_loss = 0.95802636, grad/param norm = 2.0662e-01, time/batch = 0.6696s	
25563/33150 (epoch 38.557), train_loss = 0.70673271, grad/param norm = 1.7199e-01, time/batch = 0.6684s	
25564/33150 (epoch 38.558), train_loss = 0.89644847, grad/param norm = 2.5890e-01, time/batch = 0.6672s	
25565/33150 (epoch 38.560), train_loss = 0.76732010, grad/param norm = 1.7173e-01, time/batch = 0.6667s	
25566/33150 (epoch 38.561), train_loss = 0.71664592, grad/param norm = 1.8737e-01, time/batch = 0.6673s	
25567/33150 (epoch 38.563), train_loss = 0.88812583, grad/param norm = 1.8677e-01, time/batch = 0.6679s	
25568/33150 (epoch 38.564), train_loss = 0.95604748, grad/param norm = 1.7256e-01, time/batch = 0.6873s	
25569/33150 (epoch 38.566), train_loss = 0.76515382, grad/param norm = 1.6579e-01, time/batch = 0.6852s	
25570/33150 (epoch 38.567), train_loss = 0.80662355, grad/param norm = 1.7185e-01, time/batch = 0.6783s	
25571/33150 (epoch 38.569), train_loss = 0.85677879, grad/param norm = 2.0301e-01, time/batch = 0.6707s	
25572/33150 (epoch 38.570), train_loss = 0.89177035, grad/param norm = 1.6583e-01, time/batch = 0.6746s	
25573/33150 (epoch 38.572), train_loss = 0.78957087, grad/param norm = 1.7013e-01, time/batch = 0.6721s	
25574/33150 (epoch 38.573), train_loss = 0.72113629, grad/param norm = 1.4236e-01, time/batch = 0.6679s	
25575/33150 (epoch 38.575), train_loss = 0.81060458, grad/param norm = 1.6831e-01, time/batch = 0.6710s	
25576/33150 (epoch 38.576), train_loss = 0.73875943, grad/param norm = 1.5761e-01, time/batch = 0.6684s	
25577/33150 (epoch 38.578), train_loss = 0.78644080, grad/param norm = 1.6160e-01, time/batch = 0.6712s	
25578/33150 (epoch 38.579), train_loss = 0.73137443, grad/param norm = 1.4721e-01, time/batch = 0.6686s	
25579/33150 (epoch 38.581), train_loss = 0.76632564, grad/param norm = 1.8255e-01, time/batch = 0.6832s	
25580/33150 (epoch 38.582), train_loss = 0.96660162, grad/param norm = 1.6575e-01, time/batch = 0.6649s	
25581/33150 (epoch 38.584), train_loss = 0.92033135, grad/param norm = 1.7825e-01, time/batch = 0.6787s	
25582/33150 (epoch 38.585), train_loss = 0.83558124, grad/param norm = 1.6959e-01, time/batch = 0.6854s	
25583/33150 (epoch 38.587), train_loss = 0.83176619, grad/param norm = 1.5083e-01, time/batch = 0.6847s	
25584/33150 (epoch 38.588), train_loss = 0.77327098, grad/param norm = 1.8318e-01, time/batch = 0.6829s	
25585/33150 (epoch 38.590), train_loss = 0.87408609, grad/param norm = 1.6108e-01, time/batch = 0.6866s	
25586/33150 (epoch 38.591), train_loss = 0.85668931, grad/param norm = 1.8398e-01, time/batch = 0.6769s	
25587/33150 (epoch 38.593), train_loss = 0.90494025, grad/param norm = 2.0246e-01, time/batch = 0.6748s	
25588/33150 (epoch 38.594), train_loss = 0.81546642, grad/param norm = 1.8219e-01, time/batch = 0.6716s	
25589/33150 (epoch 38.596), train_loss = 0.81709453, grad/param norm = 1.6475e-01, time/batch = 0.6733s	
25590/33150 (epoch 38.597), train_loss = 0.75523229, grad/param norm = 2.3495e-01, time/batch = 0.6693s	
25591/33150 (epoch 38.599), train_loss = 0.98345691, grad/param norm = 2.1049e-01, time/batch = 0.6753s	
25592/33150 (epoch 38.600), train_loss = 0.84849439, grad/param norm = 2.2731e-01, time/batch = 0.6829s	
25593/33150 (epoch 38.602), train_loss = 0.84281482, grad/param norm = 1.7342e-01, time/batch = 0.6724s	
25594/33150 (epoch 38.603), train_loss = 0.95568049, grad/param norm = 1.8979e-01, time/batch = 0.6717s	
25595/33150 (epoch 38.605), train_loss = 0.75957668, grad/param norm = 1.7387e-01, time/batch = 0.6707s	
25596/33150 (epoch 38.606), train_loss = 0.78763529, grad/param norm = 2.0948e-01, time/batch = 0.6780s	
25597/33150 (epoch 38.608), train_loss = 0.93020300, grad/param norm = 1.7029e-01, time/batch = 0.6797s	
25598/33150 (epoch 38.609), train_loss = 0.84863288, grad/param norm = 2.1328e-01, time/batch = 0.6742s	
25599/33150 (epoch 38.611), train_loss = 0.76617375, grad/param norm = 1.7812e-01, time/batch = 0.6801s	
25600/33150 (epoch 38.612), train_loss = 0.80769309, grad/param norm = 1.7096e-01, time/batch = 0.6753s	
25601/33150 (epoch 38.614), train_loss = 0.77905048, grad/param norm = 1.7008e-01, time/batch = 0.6737s	
25602/33150 (epoch 38.615), train_loss = 0.74991938, grad/param norm = 1.6845e-01, time/batch = 0.6707s	
25603/33150 (epoch 38.617), train_loss = 0.86890589, grad/param norm = 2.2161e-01, time/batch = 0.6701s	
25604/33150 (epoch 38.618), train_loss = 0.88842338, grad/param norm = 1.8832e-01, time/batch = 0.6694s	
25605/33150 (epoch 38.620), train_loss = 0.81626982, grad/param norm = 2.1631e-01, time/batch = 0.6695s	
25606/33150 (epoch 38.621), train_loss = 0.86432970, grad/param norm = 1.7974e-01, time/batch = 0.6719s	
25607/33150 (epoch 38.623), train_loss = 0.89660023, grad/param norm = 1.6916e-01, time/batch = 0.6701s	
25608/33150 (epoch 38.624), train_loss = 0.82175248, grad/param norm = 1.7409e-01, time/batch = 0.6694s	
25609/33150 (epoch 38.626), train_loss = 0.83656024, grad/param norm = 1.7496e-01, time/batch = 0.6685s	
25610/33150 (epoch 38.627), train_loss = 0.81311605, grad/param norm = 1.8367e-01, time/batch = 0.6668s	
25611/33150 (epoch 38.629), train_loss = 0.70442380, grad/param norm = 1.6374e-01, time/batch = 0.6685s	
25612/33150 (epoch 38.630), train_loss = 0.83442632, grad/param norm = 1.8562e-01, time/batch = 0.6713s	
25613/33150 (epoch 38.632), train_loss = 0.72813073, grad/param norm = 1.4403e-01, time/batch = 0.6730s	
25614/33150 (epoch 38.633), train_loss = 0.76570278, grad/param norm = 1.8860e-01, time/batch = 0.6804s	
25615/33150 (epoch 38.635), train_loss = 0.98537343, grad/param norm = 1.9917e-01, time/batch = 0.6716s	
25616/33150 (epoch 38.637), train_loss = 0.69264144, grad/param norm = 1.7492e-01, time/batch = 0.6684s	
25617/33150 (epoch 38.638), train_loss = 0.82471610, grad/param norm = 1.7355e-01, time/batch = 0.6723s	
25618/33150 (epoch 38.640), train_loss = 0.90339558, grad/param norm = 1.9216e-01, time/batch = 0.6690s	
25619/33150 (epoch 38.641), train_loss = 0.70019777, grad/param norm = 1.6877e-01, time/batch = 0.6668s	
25620/33150 (epoch 38.643), train_loss = 0.84713890, grad/param norm = 1.6819e-01, time/batch = 0.6669s	
25621/33150 (epoch 38.644), train_loss = 0.98111421, grad/param norm = 1.5438e-01, time/batch = 0.6681s	
25622/33150 (epoch 38.646), train_loss = 0.83340902, grad/param norm = 1.6404e-01, time/batch = 0.6676s	
25623/33150 (epoch 38.647), train_loss = 1.02025332, grad/param norm = 1.8354e-01, time/batch = 0.6702s	
25624/33150 (epoch 38.649), train_loss = 0.88016495, grad/param norm = 2.2058e-01, time/batch = 0.6699s	
25625/33150 (epoch 38.650), train_loss = 0.75649851, grad/param norm = 1.6222e-01, time/batch = 0.6698s	
25626/33150 (epoch 38.652), train_loss = 0.94335515, grad/param norm = 2.0355e-01, time/batch = 0.6709s	
25627/33150 (epoch 38.653), train_loss = 0.89670407, grad/param norm = 1.6918e-01, time/batch = 0.6676s	
25628/33150 (epoch 38.655), train_loss = 0.88490410, grad/param norm = 2.0777e-01, time/batch = 0.6762s	
25629/33150 (epoch 38.656), train_loss = 0.79926504, grad/param norm = 1.5884e-01, time/batch = 0.6808s	
25630/33150 (epoch 38.658), train_loss = 0.80253032, grad/param norm = 1.6717e-01, time/batch = 0.6658s	
25631/33150 (epoch 38.659), train_loss = 1.06613251, grad/param norm = 3.7289e-01, time/batch = 0.6675s	
25632/33150 (epoch 38.661), train_loss = 0.83670194, grad/param norm = 2.0246e-01, time/batch = 0.6701s	
25633/33150 (epoch 38.662), train_loss = 0.81925276, grad/param norm = 2.0716e-01, time/batch = 0.6695s	
25634/33150 (epoch 38.664), train_loss = 0.93561046, grad/param norm = 1.7196e-01, time/batch = 0.6709s	
25635/33150 (epoch 38.665), train_loss = 0.91892119, grad/param norm = 2.1409e-01, time/batch = 0.6707s	
25636/33150 (epoch 38.667), train_loss = 0.92660115, grad/param norm = 2.0668e-01, time/batch = 0.6673s	
25637/33150 (epoch 38.668), train_loss = 1.00044470, grad/param norm = 2.0472e-01, time/batch = 0.6684s	
25638/33150 (epoch 38.670), train_loss = 0.79586931, grad/param norm = 1.6782e-01, time/batch = 0.6705s	
25639/33150 (epoch 38.671), train_loss = 0.77105721, grad/param norm = 1.9443e-01, time/batch = 0.6701s	
25640/33150 (epoch 38.673), train_loss = 0.96527175, grad/param norm = 1.6632e-01, time/batch = 0.6683s	
25641/33150 (epoch 38.674), train_loss = 0.93340768, grad/param norm = 2.2768e-01, time/batch = 0.6738s	
25642/33150 (epoch 38.676), train_loss = 0.84575845, grad/param norm = 1.6518e-01, time/batch = 0.6734s	
25643/33150 (epoch 38.677), train_loss = 0.97097970, grad/param norm = 1.8647e-01, time/batch = 0.6728s	
25644/33150 (epoch 38.679), train_loss = 0.84056916, grad/param norm = 1.5185e-01, time/batch = 0.6743s	
25645/33150 (epoch 38.680), train_loss = 0.94340730, grad/param norm = 1.8640e-01, time/batch = 0.6709s	
25646/33150 (epoch 38.682), train_loss = 0.84741808, grad/param norm = 1.6227e-01, time/batch = 0.6675s	
25647/33150 (epoch 38.683), train_loss = 0.72114586, grad/param norm = 1.4967e-01, time/batch = 0.6728s	
25648/33150 (epoch 38.685), train_loss = 0.80464130, grad/param norm = 1.9025e-01, time/batch = 0.6802s	
25649/33150 (epoch 38.686), train_loss = 0.71570346, grad/param norm = 1.8057e-01, time/batch = 0.6853s	
25650/33150 (epoch 38.688), train_loss = 0.74023364, grad/param norm = 1.7793e-01, time/batch = 0.6714s	
25651/33150 (epoch 38.689), train_loss = 0.77796401, grad/param norm = 1.7567e-01, time/batch = 0.6703s	
25652/33150 (epoch 38.691), train_loss = 0.67499672, grad/param norm = 1.8714e-01, time/batch = 0.6672s	
25653/33150 (epoch 38.692), train_loss = 0.76143032, grad/param norm = 1.6023e-01, time/batch = 0.6664s	
25654/33150 (epoch 38.694), train_loss = 0.66858058, grad/param norm = 1.5691e-01, time/batch = 0.6679s	
25655/33150 (epoch 38.695), train_loss = 0.78333427, grad/param norm = 1.5488e-01, time/batch = 0.6645s	
25656/33150 (epoch 38.697), train_loss = 0.74005847, grad/param norm = 1.4788e-01, time/batch = 0.6705s	
25657/33150 (epoch 38.698), train_loss = 0.74773216, grad/param norm = 1.8233e-01, time/batch = 0.6846s	
25658/33150 (epoch 38.700), train_loss = 0.65758358, grad/param norm = 1.4928e-01, time/batch = 0.6909s	
25659/33150 (epoch 38.701), train_loss = 0.71720858, grad/param norm = 1.5032e-01, time/batch = 0.6835s	
25660/33150 (epoch 38.703), train_loss = 0.84154912, grad/param norm = 2.4964e-01, time/batch = 0.6706s	
25661/33150 (epoch 38.704), train_loss = 0.71254986, grad/param norm = 1.4943e-01, time/batch = 0.6689s	
25662/33150 (epoch 38.706), train_loss = 0.76402772, grad/param norm = 1.4246e-01, time/batch = 0.6698s	
25663/33150 (epoch 38.707), train_loss = 0.81140401, grad/param norm = 1.7122e-01, time/batch = 0.6692s	
25664/33150 (epoch 38.709), train_loss = 0.85415516, grad/param norm = 1.5935e-01, time/batch = 0.6705s	
25665/33150 (epoch 38.710), train_loss = 0.84208569, grad/param norm = 1.9113e-01, time/batch = 0.6902s	
25666/33150 (epoch 38.712), train_loss = 0.89594524, grad/param norm = 1.5924e-01, time/batch = 0.6786s	
25667/33150 (epoch 38.713), train_loss = 0.86953566, grad/param norm = 1.6329e-01, time/batch = 0.6654s	
25668/33150 (epoch 38.715), train_loss = 0.82400282, grad/param norm = 1.8021e-01, time/batch = 0.6778s	
25669/33150 (epoch 38.716), train_loss = 0.87269867, grad/param norm = 1.7662e-01, time/batch = 0.6727s	
25670/33150 (epoch 38.718), train_loss = 0.84979336, grad/param norm = 1.7461e-01, time/batch = 0.6674s	
25671/33150 (epoch 38.719), train_loss = 0.90278121, grad/param norm = 2.0527e-01, time/batch = 0.6666s	
25672/33150 (epoch 38.721), train_loss = 0.81533721, grad/param norm = 1.8478e-01, time/batch = 0.6699s	
25673/33150 (epoch 38.722), train_loss = 0.87710195, grad/param norm = 1.6910e-01, time/batch = 0.6652s	
25674/33150 (epoch 38.724), train_loss = 0.82533715, grad/param norm = 2.1358e-01, time/batch = 0.6679s	
25675/33150 (epoch 38.725), train_loss = 0.91034415, grad/param norm = 2.2579e-01, time/batch = 0.6667s	
25676/33150 (epoch 38.727), train_loss = 0.88618041, grad/param norm = 1.9755e-01, time/batch = 0.6760s	
25677/33150 (epoch 38.729), train_loss = 0.85223952, grad/param norm = 1.9832e-01, time/batch = 0.6754s	
25678/33150 (epoch 38.730), train_loss = 0.83889511, grad/param norm = 1.6710e-01, time/batch = 0.6811s	
25679/33150 (epoch 38.732), train_loss = 0.87605496, grad/param norm = 1.8587e-01, time/batch = 0.6698s	
25680/33150 (epoch 38.733), train_loss = 0.72267939, grad/param norm = 1.3294e-01, time/batch = 0.6723s	
25681/33150 (epoch 38.735), train_loss = 0.78014487, grad/param norm = 1.8405e-01, time/batch = 0.6902s	
25682/33150 (epoch 38.736), train_loss = 0.81117429, grad/param norm = 1.8705e-01, time/batch = 0.6695s	
25683/33150 (epoch 38.738), train_loss = 0.83463992, grad/param norm = 2.0637e-01, time/batch = 0.6689s	
25684/33150 (epoch 38.739), train_loss = 0.95797924, grad/param norm = 2.1580e-01, time/batch = 0.6713s	
25685/33150 (epoch 38.741), train_loss = 0.88181590, grad/param norm = 2.0399e-01, time/batch = 0.6679s	
25686/33150 (epoch 38.742), train_loss = 0.70549452, grad/param norm = 1.6008e-01, time/batch = 0.6703s	
25687/33150 (epoch 38.744), train_loss = 0.90444039, grad/param norm = 1.7571e-01, time/batch = 0.6714s	
25688/33150 (epoch 38.745), train_loss = 0.77609859, grad/param norm = 1.5265e-01, time/batch = 0.6691s	
25689/33150 (epoch 38.747), train_loss = 0.62691079, grad/param norm = 1.6358e-01, time/batch = 0.6696s	
25690/33150 (epoch 38.748), train_loss = 0.71369023, grad/param norm = 1.6348e-01, time/batch = 0.6690s	
25691/33150 (epoch 38.750), train_loss = 0.86581352, grad/param norm = 1.8376e-01, time/batch = 0.6708s	
25692/33150 (epoch 38.751), train_loss = 0.82199229, grad/param norm = 1.6504e-01, time/batch = 0.6807s	
25693/33150 (epoch 38.753), train_loss = 0.73483400, grad/param norm = 1.9876e-01, time/batch = 0.6826s	
25694/33150 (epoch 38.754), train_loss = 1.02109639, grad/param norm = 2.2746e-01, time/batch = 0.6679s	
25695/33150 (epoch 38.756), train_loss = 0.84032996, grad/param norm = 2.9437e-01, time/batch = 0.6700s	
25696/33150 (epoch 38.757), train_loss = 0.87722794, grad/param norm = 1.7561e-01, time/batch = 0.6688s	
25697/33150 (epoch 38.759), train_loss = 0.96714739, grad/param norm = 2.1211e-01, time/batch = 0.6701s	
25698/33150 (epoch 38.760), train_loss = 0.89670649, grad/param norm = 3.1396e-01, time/batch = 0.6698s	
25699/33150 (epoch 38.762), train_loss = 0.85178210, grad/param norm = 2.1475e-01, time/batch = 0.6717s	
25700/33150 (epoch 38.763), train_loss = 0.89019930, grad/param norm = 1.8982e-01, time/batch = 0.6689s	
25701/33150 (epoch 38.765), train_loss = 0.82799400, grad/param norm = 1.8385e-01, time/batch = 0.6711s	
25702/33150 (epoch 38.766), train_loss = 0.72878707, grad/param norm = 1.8257e-01, time/batch = 0.6727s	
25703/33150 (epoch 38.768), train_loss = 0.77169829, grad/param norm = 1.6998e-01, time/batch = 0.6721s	
25704/33150 (epoch 38.769), train_loss = 0.92260214, grad/param norm = 2.1217e-01, time/batch = 0.6693s	
25705/33150 (epoch 38.771), train_loss = 0.86976179, grad/param norm = 1.8498e-01, time/batch = 0.6700s	
25706/33150 (epoch 38.772), train_loss = 0.89395364, grad/param norm = 2.1638e-01, time/batch = 0.6707s	
25707/33150 (epoch 38.774), train_loss = 0.98467588, grad/param norm = 1.9136e-01, time/batch = 0.6802s	
25708/33150 (epoch 38.775), train_loss = 0.88571314, grad/param norm = 2.1797e-01, time/batch = 0.6746s	
25709/33150 (epoch 38.777), train_loss = 0.90816303, grad/param norm = 1.8566e-01, time/batch = 0.6634s	
25710/33150 (epoch 38.778), train_loss = 0.83615443, grad/param norm = 1.6408e-01, time/batch = 0.6662s	
25711/33150 (epoch 38.780), train_loss = 0.70989929, grad/param norm = 1.5537e-01, time/batch = 0.6680s	
25712/33150 (epoch 38.781), train_loss = 0.83088541, grad/param norm = 1.7284e-01, time/batch = 0.6667s	
25713/33150 (epoch 38.783), train_loss = 0.84808410, grad/param norm = 1.7496e-01, time/batch = 0.6651s	
25714/33150 (epoch 38.784), train_loss = 0.82983727, grad/param norm = 1.9231e-01, time/batch = 0.6677s	
25715/33150 (epoch 38.786), train_loss = 0.83584605, grad/param norm = 1.7203e-01, time/batch = 0.6634s	
25716/33150 (epoch 38.787), train_loss = 0.75875496, grad/param norm = 1.5327e-01, time/batch = 0.6656s	
25717/33150 (epoch 38.789), train_loss = 0.71154840, grad/param norm = 1.4359e-01, time/batch = 0.6736s	
25718/33150 (epoch 38.790), train_loss = 0.71288180, grad/param norm = 1.5091e-01, time/batch = 0.6813s	
25719/33150 (epoch 38.792), train_loss = 0.84112973, grad/param norm = 2.1129e-01, time/batch = 0.6758s	
25720/33150 (epoch 38.793), train_loss = 0.80635300, grad/param norm = 1.8961e-01, time/batch = 0.6698s	
25721/33150 (epoch 38.795), train_loss = 0.78297264, grad/param norm = 1.7644e-01, time/batch = 0.6678s	
25722/33150 (epoch 38.796), train_loss = 0.80701645, grad/param norm = 1.7231e-01, time/batch = 0.6810s	
25723/33150 (epoch 38.798), train_loss = 0.77183085, grad/param norm = 1.4460e-01, time/batch = 0.6757s	
25724/33150 (epoch 38.799), train_loss = 0.70038894, grad/param norm = 1.7504e-01, time/batch = 0.6709s	
25725/33150 (epoch 38.801), train_loss = 0.85706769, grad/param norm = 1.8511e-01, time/batch = 0.6684s	
25726/33150 (epoch 38.802), train_loss = 0.79912936, grad/param norm = 1.7532e-01, time/batch = 0.6673s	
25727/33150 (epoch 38.804), train_loss = 0.80859775, grad/param norm = 1.7089e-01, time/batch = 0.6689s	
25728/33150 (epoch 38.805), train_loss = 0.77479101, grad/param norm = 1.9032e-01, time/batch = 0.6687s	
25729/33150 (epoch 38.807), train_loss = 0.81104175, grad/param norm = 1.6199e-01, time/batch = 0.6743s	
25730/33150 (epoch 38.808), train_loss = 0.90779589, grad/param norm = 1.8685e-01, time/batch = 0.6780s	
25731/33150 (epoch 38.810), train_loss = 0.75720288, grad/param norm = 1.6142e-01, time/batch = 0.6794s	
25732/33150 (epoch 38.811), train_loss = 0.86693168, grad/param norm = 2.2931e-01, time/batch = 0.6710s	
25733/33150 (epoch 38.813), train_loss = 0.79743628, grad/param norm = 1.7164e-01, time/batch = 0.6718s	
25734/33150 (epoch 38.814), train_loss = 0.78663870, grad/param norm = 1.9016e-01, time/batch = 0.6778s	
25735/33150 (epoch 38.816), train_loss = 0.79866530, grad/param norm = 2.0127e-01, time/batch = 0.6878s	
25736/33150 (epoch 38.817), train_loss = 0.87787494, grad/param norm = 1.7692e-01, time/batch = 0.6864s	
25737/33150 (epoch 38.819), train_loss = 0.84658125, grad/param norm = 1.6724e-01, time/batch = 0.6812s	
25738/33150 (epoch 38.821), train_loss = 0.74092583, grad/param norm = 1.4641e-01, time/batch = 0.6845s	
25739/33150 (epoch 38.822), train_loss = 0.79061830, grad/param norm = 1.8796e-01, time/batch = 0.6858s	
25740/33150 (epoch 38.824), train_loss = 0.83612332, grad/param norm = 1.9069e-01, time/batch = 0.6847s	
25741/33150 (epoch 38.825), train_loss = 0.88034393, grad/param norm = 1.8913e-01, time/batch = 0.6708s	
25742/33150 (epoch 38.827), train_loss = 0.89128012, grad/param norm = 1.8097e-01, time/batch = 0.6738s	
25743/33150 (epoch 38.828), train_loss = 0.74169086, grad/param norm = 1.6509e-01, time/batch = 0.6738s	
25744/33150 (epoch 38.830), train_loss = 0.88546382, grad/param norm = 1.9354e-01, time/batch = 0.6666s	
25745/33150 (epoch 38.831), train_loss = 0.77773542, grad/param norm = 1.7270e-01, time/batch = 0.6772s	
25746/33150 (epoch 38.833), train_loss = 0.74066537, grad/param norm = 1.5938e-01, time/batch = 0.6877s	
25747/33150 (epoch 38.834), train_loss = 0.90260170, grad/param norm = 1.6155e-01, time/batch = 0.6882s	
25748/33150 (epoch 38.836), train_loss = 0.94516121, grad/param norm = 1.7811e-01, time/batch = 0.6964s	
25749/33150 (epoch 38.837), train_loss = 0.77341130, grad/param norm = 1.8592e-01, time/batch = 0.6833s	
25750/33150 (epoch 38.839), train_loss = 0.89625457, grad/param norm = 1.8396e-01, time/batch = 0.6852s	
25751/33150 (epoch 38.840), train_loss = 0.88897142, grad/param norm = 1.7660e-01, time/batch = 0.6821s	
25752/33150 (epoch 38.842), train_loss = 0.91942389, grad/param norm = 2.0595e-01, time/batch = 0.6866s	
25753/33150 (epoch 38.843), train_loss = 0.92042004, grad/param norm = 1.9125e-01, time/batch = 0.6700s	
25754/33150 (epoch 38.845), train_loss = 0.78361024, grad/param norm = 1.8271e-01, time/batch = 0.6705s	
25755/33150 (epoch 38.846), train_loss = 0.99241141, grad/param norm = 2.7659e-01, time/batch = 0.6694s	
25756/33150 (epoch 38.848), train_loss = 0.90935937, grad/param norm = 2.0087e-01, time/batch = 0.6745s	
25757/33150 (epoch 38.849), train_loss = 0.93256385, grad/param norm = 1.8269e-01, time/batch = 0.6657s	
25758/33150 (epoch 38.851), train_loss = 0.89312799, grad/param norm = 2.0038e-01, time/batch = 0.6667s	
25759/33150 (epoch 38.852), train_loss = 0.96352280, grad/param norm = 1.7591e-01, time/batch = 0.6686s	
25760/33150 (epoch 38.854), train_loss = 0.88066146, grad/param norm = 1.8771e-01, time/batch = 0.6711s	
25761/33150 (epoch 38.855), train_loss = 0.75375212, grad/param norm = 1.7008e-01, time/batch = 0.6989s	
25762/33150 (epoch 38.857), train_loss = 0.70229870, grad/param norm = 1.8001e-01, time/batch = 0.6911s	
25763/33150 (epoch 38.858), train_loss = 0.80036437, grad/param norm = 1.7386e-01, time/batch = 0.6811s	
25764/33150 (epoch 38.860), train_loss = 0.76108775, grad/param norm = 2.0055e-01, time/batch = 0.6706s	
25765/33150 (epoch 38.861), train_loss = 0.74192457, grad/param norm = 1.4847e-01, time/batch = 0.6751s	
25766/33150 (epoch 38.863), train_loss = 0.81519494, grad/param norm = 1.7650e-01, time/batch = 0.6830s	
25767/33150 (epoch 38.864), train_loss = 0.84740187, grad/param norm = 1.7299e-01, time/batch = 0.6763s	
25768/33150 (epoch 38.866), train_loss = 0.90631937, grad/param norm = 1.7722e-01, time/batch = 0.6704s	
25769/33150 (epoch 38.867), train_loss = 0.83835527, grad/param norm = 1.6425e-01, time/batch = 0.6766s	
25770/33150 (epoch 38.869), train_loss = 0.85063182, grad/param norm = 1.7620e-01, time/batch = 0.6741s	
25771/33150 (epoch 38.870), train_loss = 0.77731003, grad/param norm = 1.7551e-01, time/batch = 0.6875s	
25772/33150 (epoch 38.872), train_loss = 0.88564802, grad/param norm = 1.9939e-01, time/batch = 0.6904s	
25773/33150 (epoch 38.873), train_loss = 0.67660075, grad/param norm = 1.5086e-01, time/batch = 0.6895s	
25774/33150 (epoch 38.875), train_loss = 0.92559976, grad/param norm = 1.8593e-01, time/batch = 0.6887s	
25775/33150 (epoch 38.876), train_loss = 0.68928596, grad/param norm = 1.5551e-01, time/batch = 0.6891s	
25776/33150 (epoch 38.878), train_loss = 0.78301575, grad/param norm = 1.7007e-01, time/batch = 0.6903s	
25777/33150 (epoch 38.879), train_loss = 0.76786691, grad/param norm = 1.5547e-01, time/batch = 0.6902s	
25778/33150 (epoch 38.881), train_loss = 0.76257534, grad/param norm = 1.7427e-01, time/batch = 0.6894s	
25779/33150 (epoch 38.882), train_loss = 0.65514909, grad/param norm = 1.5291e-01, time/batch = 0.6889s	
25780/33150 (epoch 38.884), train_loss = 0.79075141, grad/param norm = 1.5691e-01, time/batch = 0.6881s	
25781/33150 (epoch 38.885), train_loss = 0.63891414, grad/param norm = 1.8305e-01, time/batch = 0.6867s	
25782/33150 (epoch 38.887), train_loss = 0.90979175, grad/param norm = 1.8176e-01, time/batch = 0.6792s	
25783/33150 (epoch 38.888), train_loss = 0.84208901, grad/param norm = 1.8795e-01, time/batch = 0.6724s	
25784/33150 (epoch 38.890), train_loss = 0.75728568, grad/param norm = 2.1047e-01, time/batch = 0.6792s	
25785/33150 (epoch 38.891), train_loss = 0.73695832, grad/param norm = 1.7771e-01, time/batch = 0.6741s	
25786/33150 (epoch 38.893), train_loss = 0.88871604, grad/param norm = 1.9335e-01, time/batch = 0.6707s	
25787/33150 (epoch 38.894), train_loss = 0.84963546, grad/param norm = 1.5010e-01, time/batch = 0.6712s	
25788/33150 (epoch 38.896), train_loss = 0.82342936, grad/param norm = 1.7107e-01, time/batch = 0.6666s	
25789/33150 (epoch 38.897), train_loss = 0.87043632, grad/param norm = 1.7249e-01, time/batch = 0.6679s	
25790/33150 (epoch 38.899), train_loss = 0.68418307, grad/param norm = 2.0414e-01, time/batch = 0.6736s	
25791/33150 (epoch 38.900), train_loss = 0.99079626, grad/param norm = 1.8710e-01, time/batch = 0.6826s	
25792/33150 (epoch 38.902), train_loss = 1.03732429, grad/param norm = 1.7903e-01, time/batch = 0.6839s	
25793/33150 (epoch 38.903), train_loss = 0.84113989, grad/param norm = 1.7953e-01, time/batch = 0.6856s	
25794/33150 (epoch 38.905), train_loss = 0.83068302, grad/param norm = 1.5908e-01, time/batch = 0.6843s	
25795/33150 (epoch 38.906), train_loss = 0.85299334, grad/param norm = 1.9678e-01, time/batch = 0.6852s	
25796/33150 (epoch 38.908), train_loss = 0.89231521, grad/param norm = 1.8130e-01, time/batch = 0.6819s	
25797/33150 (epoch 38.910), train_loss = 0.91793238, grad/param norm = 2.0311e-01, time/batch = 0.6769s	
25798/33150 (epoch 38.911), train_loss = 0.72122139, grad/param norm = 1.5488e-01, time/batch = 0.6761s	
25799/33150 (epoch 38.913), train_loss = 0.78112505, grad/param norm = 1.8115e-01, time/batch = 0.6762s	
25800/33150 (epoch 38.914), train_loss = 0.83267956, grad/param norm = 1.7906e-01, time/batch = 0.6763s	
25801/33150 (epoch 38.916), train_loss = 0.77001778, grad/param norm = 1.6905e-01, time/batch = 0.6821s	
25802/33150 (epoch 38.917), train_loss = 0.86678857, grad/param norm = 1.9250e-01, time/batch = 0.6796s	
25803/33150 (epoch 38.919), train_loss = 0.95788848, grad/param norm = 2.1661e-01, time/batch = 0.6772s	
25804/33150 (epoch 38.920), train_loss = 0.92052821, grad/param norm = 1.8421e-01, time/batch = 0.6751s	
25805/33150 (epoch 38.922), train_loss = 0.97261420, grad/param norm = 2.1945e-01, time/batch = 0.6812s	
25806/33150 (epoch 38.923), train_loss = 0.84193292, grad/param norm = 1.8944e-01, time/batch = 0.6758s	
25807/33150 (epoch 38.925), train_loss = 0.93175018, grad/param norm = 1.7012e-01, time/batch = 0.6771s	
25808/33150 (epoch 38.926), train_loss = 0.81651886, grad/param norm = 1.6115e-01, time/batch = 0.6867s	
25809/33150 (epoch 38.928), train_loss = 0.80036614, grad/param norm = 1.6547e-01, time/batch = 0.6870s	
25810/33150 (epoch 38.929), train_loss = 0.89472968, grad/param norm = 1.7330e-01, time/batch = 0.6856s	
25811/33150 (epoch 38.931), train_loss = 0.94174146, grad/param norm = 2.0403e-01, time/batch = 0.6854s	
25812/33150 (epoch 38.932), train_loss = 0.88425586, grad/param norm = 2.7274e-01, time/batch = 0.6841s	
25813/33150 (epoch 38.934), train_loss = 0.85727252, grad/param norm = 1.7593e-01, time/batch = 0.6755s	
25814/33150 (epoch 38.935), train_loss = 0.93744107, grad/param norm = 1.9088e-01, time/batch = 0.6780s	
25815/33150 (epoch 38.937), train_loss = 0.95740415, grad/param norm = 1.7278e-01, time/batch = 0.6765s	
25816/33150 (epoch 38.938), train_loss = 0.88304870, grad/param norm = 1.7510e-01, time/batch = 0.6806s	
25817/33150 (epoch 38.940), train_loss = 1.07256901, grad/param norm = 2.1207e-01, time/batch = 0.6821s	
25818/33150 (epoch 38.941), train_loss = 0.87664659, grad/param norm = 1.5512e-01, time/batch = 0.6822s	
25819/33150 (epoch 38.943), train_loss = 0.68767831, grad/param norm = 1.5791e-01, time/batch = 0.6740s	
25820/33150 (epoch 38.944), train_loss = 0.90075564, grad/param norm = 1.9897e-01, time/batch = 0.6818s	
25821/33150 (epoch 38.946), train_loss = 0.73631176, grad/param norm = 1.3990e-01, time/batch = 0.6769s	
25822/33150 (epoch 38.947), train_loss = 0.86827854, grad/param norm = 2.0401e-01, time/batch = 0.6801s	
25823/33150 (epoch 38.949), train_loss = 0.93265321, grad/param norm = 1.6903e-01, time/batch = 0.6865s	
25824/33150 (epoch 38.950), train_loss = 0.91398481, grad/param norm = 1.8239e-01, time/batch = 0.6857s	
25825/33150 (epoch 38.952), train_loss = 0.77039999, grad/param norm = 1.5832e-01, time/batch = 0.6730s	
25826/33150 (epoch 38.953), train_loss = 0.84651966, grad/param norm = 1.6749e-01, time/batch = 0.6768s	
25827/33150 (epoch 38.955), train_loss = 0.74043964, grad/param norm = 1.9823e-01, time/batch = 0.6765s	
25828/33150 (epoch 38.956), train_loss = 0.91142349, grad/param norm = 2.0733e-01, time/batch = 0.6737s	
25829/33150 (epoch 38.958), train_loss = 0.76751518, grad/param norm = 1.6567e-01, time/batch = 0.6756s	
25830/33150 (epoch 38.959), train_loss = 0.82844079, grad/param norm = 1.6897e-01, time/batch = 0.6785s	
25831/33150 (epoch 38.961), train_loss = 0.76390401, grad/param norm = 2.0366e-01, time/batch = 0.6802s	
25832/33150 (epoch 38.962), train_loss = 0.71328886, grad/param norm = 1.5402e-01, time/batch = 0.6845s	
25833/33150 (epoch 38.964), train_loss = 0.82127545, grad/param norm = 1.8113e-01, time/batch = 0.6841s	
25834/33150 (epoch 38.965), train_loss = 0.80432746, grad/param norm = 1.7174e-01, time/batch = 0.6894s	
25835/33150 (epoch 38.967), train_loss = 0.82645220, grad/param norm = 1.9749e-01, time/batch = 0.6858s	
25836/33150 (epoch 38.968), train_loss = 0.70421062, grad/param norm = 1.5011e-01, time/batch = 0.6864s	
25837/33150 (epoch 38.970), train_loss = 0.78626616, grad/param norm = 1.6399e-01, time/batch = 0.6994s	
25838/33150 (epoch 38.971), train_loss = 0.82385469, grad/param norm = 1.6341e-01, time/batch = 0.6893s	
25839/33150 (epoch 38.973), train_loss = 0.90788938, grad/param norm = 1.9053e-01, time/batch = 0.6858s	
25840/33150 (epoch 38.974), train_loss = 0.97229024, grad/param norm = 2.1113e-01, time/batch = 0.6809s	
25841/33150 (epoch 38.976), train_loss = 0.92461776, grad/param norm = 1.7941e-01, time/batch = 0.6831s	
25842/33150 (epoch 38.977), train_loss = 0.94720058, grad/param norm = 1.8801e-01, time/batch = 0.6824s	
25843/33150 (epoch 38.979), train_loss = 0.91927481, grad/param norm = 2.0406e-01, time/batch = 0.6792s	
25844/33150 (epoch 38.980), train_loss = 0.98885226, grad/param norm = 2.0528e-01, time/batch = 0.6828s	
25845/33150 (epoch 38.982), train_loss = 0.84079404, grad/param norm = 2.3366e-01, time/batch = 0.6676s	
25846/33150 (epoch 38.983), train_loss = 0.75477657, grad/param norm = 1.7176e-01, time/batch = 0.6789s	
25847/33150 (epoch 38.985), train_loss = 0.95507233, grad/param norm = 1.8048e-01, time/batch = 0.6731s	
25848/33150 (epoch 38.986), train_loss = 0.70925658, grad/param norm = 1.5276e-01, time/batch = 0.6746s	
25849/33150 (epoch 38.988), train_loss = 0.80538253, grad/param norm = 2.2716e-01, time/batch = 0.6798s	
25850/33150 (epoch 38.989), train_loss = 0.81375808, grad/param norm = 1.6278e-01, time/batch = 0.6822s	
25851/33150 (epoch 38.991), train_loss = 0.88790865, grad/param norm = 2.8199e-01, time/batch = 0.6833s	
25852/33150 (epoch 38.992), train_loss = 0.83153653, grad/param norm = 1.6842e-01, time/batch = 0.6827s	
25853/33150 (epoch 38.994), train_loss = 0.85575889, grad/param norm = 1.6907e-01, time/batch = 0.6740s	
25854/33150 (epoch 38.995), train_loss = 0.81656034, grad/param norm = 1.6376e-01, time/batch = 0.6920s	
25855/33150 (epoch 38.997), train_loss = 0.83919364, grad/param norm = 1.7613e-01, time/batch = 0.6850s	
25856/33150 (epoch 38.998), train_loss = 0.71109944, grad/param norm = 1.7499e-01, time/batch = 0.6845s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
25857/33150 (epoch 39.000), train_loss = 0.75352662, grad/param norm = 2.3229e-01, time/batch = 0.6875s	
25858/33150 (epoch 39.002), train_loss = 1.11964530, grad/param norm = 1.9988e-01, time/batch = 0.6852s	
25859/33150 (epoch 39.003), train_loss = 0.75677998, grad/param norm = 1.7133e-01, time/batch = 0.6905s	
25860/33150 (epoch 39.005), train_loss = 0.72263483, grad/param norm = 1.4821e-01, time/batch = 0.6780s	
25861/33150 (epoch 39.006), train_loss = 0.69688942, grad/param norm = 1.6668e-01, time/batch = 0.6811s	
25862/33150 (epoch 39.008), train_loss = 0.89800559, grad/param norm = 1.9052e-01, time/batch = 0.6830s	
25863/33150 (epoch 39.009), train_loss = 0.86290213, grad/param norm = 1.7574e-01, time/batch = 0.6892s	
25864/33150 (epoch 39.011), train_loss = 0.92457903, grad/param norm = 1.8314e-01, time/batch = 0.6874s	
25865/33150 (epoch 39.012), train_loss = 0.82459949, grad/param norm = 2.0942e-01, time/batch = 0.6828s	
25866/33150 (epoch 39.014), train_loss = 0.76153487, grad/param norm = 1.9990e-01, time/batch = 0.6829s	
25867/33150 (epoch 39.015), train_loss = 0.75810659, grad/param norm = 1.9901e-01, time/batch = 0.6848s	
25868/33150 (epoch 39.017), train_loss = 0.75224217, grad/param norm = 1.6371e-01, time/batch = 0.6853s	
25869/33150 (epoch 39.018), train_loss = 0.85039285, grad/param norm = 1.8415e-01, time/batch = 0.6856s	
25870/33150 (epoch 39.020), train_loss = 0.93344203, grad/param norm = 2.0656e-01, time/batch = 0.6832s	
25871/33150 (epoch 39.021), train_loss = 0.75173181, grad/param norm = 1.7459e-01, time/batch = 0.6847s	
25872/33150 (epoch 39.023), train_loss = 1.00843219, grad/param norm = 1.7336e-01, time/batch = 0.6813s	
25873/33150 (epoch 39.024), train_loss = 0.88226379, grad/param norm = 1.9199e-01, time/batch = 0.6881s	
25874/33150 (epoch 39.026), train_loss = 0.65867929, grad/param norm = 1.4834e-01, time/batch = 0.6798s	
25875/33150 (epoch 39.027), train_loss = 0.67726696, grad/param norm = 1.4727e-01, time/batch = 0.6753s	
25876/33150 (epoch 39.029), train_loss = 0.75883275, grad/param norm = 1.7264e-01, time/batch = 0.6749s	
25877/33150 (epoch 39.030), train_loss = 0.80814637, grad/param norm = 1.4982e-01, time/batch = 0.6827s	
25878/33150 (epoch 39.032), train_loss = 0.72585172, grad/param norm = 1.7138e-01, time/batch = 0.6691s	
25879/33150 (epoch 39.033), train_loss = 0.75948940, grad/param norm = 1.5815e-01, time/batch = 0.6725s	
25880/33150 (epoch 39.035), train_loss = 1.00031914, grad/param norm = 2.5732e-01, time/batch = 0.6846s	
25881/33150 (epoch 39.036), train_loss = 0.90691164, grad/param norm = 2.1137e-01, time/batch = 0.6793s	
25882/33150 (epoch 39.038), train_loss = 1.02546786, grad/param norm = 1.9779e-01, time/batch = 0.6894s	
25883/33150 (epoch 39.039), train_loss = 0.89035211, grad/param norm = 1.6632e-01, time/batch = 0.6903s	
25884/33150 (epoch 39.041), train_loss = 0.82961901, grad/param norm = 1.5067e-01, time/batch = 0.6915s	
25885/33150 (epoch 39.042), train_loss = 0.77648549, grad/param norm = 1.9323e-01, time/batch = 0.6915s	
25886/33150 (epoch 39.044), train_loss = 0.82402433, grad/param norm = 1.6634e-01, time/batch = 0.6941s	
25887/33150 (epoch 39.045), train_loss = 0.88910985, grad/param norm = 1.5417e-01, time/batch = 0.6835s	
25888/33150 (epoch 39.047), train_loss = 0.75892743, grad/param norm = 1.5704e-01, time/batch = 0.6867s	
25889/33150 (epoch 39.048), train_loss = 0.92648730, grad/param norm = 2.3077e-01, time/batch = 0.6729s	
25890/33150 (epoch 39.050), train_loss = 0.81966723, grad/param norm = 1.8413e-01, time/batch = 0.6748s	
25891/33150 (epoch 39.051), train_loss = 0.85648266, grad/param norm = 1.6330e-01, time/batch = 0.6718s	
25892/33150 (epoch 39.053), train_loss = 0.86572410, grad/param norm = 1.7207e-01, time/batch = 0.6758s	
25893/33150 (epoch 39.054), train_loss = 0.97155176, grad/param norm = 1.7818e-01, time/batch = 0.6743s	
25894/33150 (epoch 39.056), train_loss = 0.81819838, grad/param norm = 1.6632e-01, time/batch = 0.6752s	
25895/33150 (epoch 39.057), train_loss = 0.87826955, grad/param norm = 1.5786e-01, time/batch = 0.6781s	
25896/33150 (epoch 39.059), train_loss = 0.74947085, grad/param norm = 1.7808e-01, time/batch = 0.6800s	
25897/33150 (epoch 39.060), train_loss = 0.73993928, grad/param norm = 1.5305e-01, time/batch = 0.6759s	
25898/33150 (epoch 39.062), train_loss = 0.84116821, grad/param norm = 1.9603e-01, time/batch = 0.6841s	
25899/33150 (epoch 39.063), train_loss = 0.76201836, grad/param norm = 1.6436e-01, time/batch = 0.6796s	
25900/33150 (epoch 39.065), train_loss = 0.80466637, grad/param norm = 1.8330e-01, time/batch = 0.6872s	
25901/33150 (epoch 39.066), train_loss = 0.82306629, grad/param norm = 1.7615e-01, time/batch = 0.6789s	
25902/33150 (epoch 39.068), train_loss = 0.86417445, grad/param norm = 1.6616e-01, time/batch = 0.6757s	
25903/33150 (epoch 39.069), train_loss = 0.87222988, grad/param norm = 1.9014e-01, time/batch = 0.6805s	
25904/33150 (epoch 39.071), train_loss = 0.84559962, grad/param norm = 1.6804e-01, time/batch = 0.6827s	
25905/33150 (epoch 39.072), train_loss = 0.85589889, grad/param norm = 1.8606e-01, time/batch = 0.6865s	
25906/33150 (epoch 39.074), train_loss = 0.72507823, grad/param norm = 1.8449e-01, time/batch = 0.6856s	
25907/33150 (epoch 39.075), train_loss = 0.72542743, grad/param norm = 1.6230e-01, time/batch = 0.6847s	
25908/33150 (epoch 39.077), train_loss = 0.85541582, grad/param norm = 2.2232e-01, time/batch = 0.6822s	
25909/33150 (epoch 39.078), train_loss = 0.97172852, grad/param norm = 1.9900e-01, time/batch = 0.6802s	
25910/33150 (epoch 39.080), train_loss = 0.94864049, grad/param norm = 1.6022e-01, time/batch = 0.6816s	
25911/33150 (epoch 39.081), train_loss = 0.75533541, grad/param norm = 2.2011e-01, time/batch = 0.6884s	
25912/33150 (epoch 39.083), train_loss = 0.61192268, grad/param norm = 1.8157e-01, time/batch = 0.6848s	
25913/33150 (epoch 39.084), train_loss = 0.69761847, grad/param norm = 1.8393e-01, time/batch = 0.6843s	
25914/33150 (epoch 39.086), train_loss = 0.75888260, grad/param norm = 2.2750e-01, time/batch = 0.6840s	
25915/33150 (epoch 39.087), train_loss = 0.72151969, grad/param norm = 1.7970e-01, time/batch = 0.6856s	
25916/33150 (epoch 39.089), train_loss = 0.76779502, grad/param norm = 1.8656e-01, time/batch = 0.6850s	
25917/33150 (epoch 39.090), train_loss = 0.80250520, grad/param norm = 1.8281e-01, time/batch = 0.6896s	
25918/33150 (epoch 39.092), train_loss = 0.78123529, grad/param norm = 2.1744e-01, time/batch = 0.6888s	
25919/33150 (epoch 39.094), train_loss = 0.86070254, grad/param norm = 2.2072e-01, time/batch = 0.6790s	
25920/33150 (epoch 39.095), train_loss = 0.75155988, grad/param norm = 1.5828e-01, time/batch = 0.6824s	
25921/33150 (epoch 39.097), train_loss = 0.70607163, grad/param norm = 1.5764e-01, time/batch = 0.6891s	
25922/33150 (epoch 39.098), train_loss = 1.05053036, grad/param norm = 1.9350e-01, time/batch = 0.6992s	
25923/33150 (epoch 39.100), train_loss = 1.02211671, grad/param norm = 2.1009e-01, time/batch = 0.6864s	
25924/33150 (epoch 39.101), train_loss = 0.77719907, grad/param norm = 1.7738e-01, time/batch = 0.6765s	
25925/33150 (epoch 39.103), train_loss = 0.83610547, grad/param norm = 1.6954e-01, time/batch = 0.6876s	
25926/33150 (epoch 39.104), train_loss = 0.76999517, grad/param norm = 1.9330e-01, time/batch = 0.6773s	
25927/33150 (epoch 39.106), train_loss = 0.93566612, grad/param norm = 1.9089e-01, time/batch = 0.6774s	
25928/33150 (epoch 39.107), train_loss = 0.99849441, grad/param norm = 2.2790e-01, time/batch = 0.6776s	
25929/33150 (epoch 39.109), train_loss = 0.80875578, grad/param norm = 1.4867e-01, time/batch = 0.6833s	
25930/33150 (epoch 39.110), train_loss = 0.92448376, grad/param norm = 1.9632e-01, time/batch = 0.6791s	
25931/33150 (epoch 39.112), train_loss = 0.73859017, grad/param norm = 1.5204e-01, time/batch = 0.6718s	
25932/33150 (epoch 39.113), train_loss = 0.79956424, grad/param norm = 1.7663e-01, time/batch = 0.6701s	
25933/33150 (epoch 39.115), train_loss = 1.00300742, grad/param norm = 2.1058e-01, time/batch = 0.6778s	
25934/33150 (epoch 39.116), train_loss = 0.87800887, grad/param norm = 1.6947e-01, time/batch = 0.6670s	
25935/33150 (epoch 39.118), train_loss = 0.87463615, grad/param norm = 2.1613e-01, time/batch = 0.6768s	
25936/33150 (epoch 39.119), train_loss = 0.87275073, grad/param norm = 1.9211e-01, time/batch = 0.6745s	
25937/33150 (epoch 39.121), train_loss = 0.81214337, grad/param norm = 1.6869e-01, time/batch = 0.6829s	
25938/33150 (epoch 39.122), train_loss = 0.97206682, grad/param norm = 2.7035e-01, time/batch = 0.6701s	
25939/33150 (epoch 39.124), train_loss = 0.70428455, grad/param norm = 1.5097e-01, time/batch = 0.6696s	
25940/33150 (epoch 39.125), train_loss = 0.96579514, grad/param norm = 1.9402e-01, time/batch = 0.6671s	
25941/33150 (epoch 39.127), train_loss = 0.87018512, grad/param norm = 1.9387e-01, time/batch = 0.6810s	
25942/33150 (epoch 39.128), train_loss = 0.86091728, grad/param norm = 1.7285e-01, time/batch = 0.6700s	
25943/33150 (epoch 39.130), train_loss = 0.83647068, grad/param norm = 1.8276e-01, time/batch = 0.6890s	
25944/33150 (epoch 39.131), train_loss = 1.02615937, grad/param norm = 1.8933e-01, time/batch = 0.6831s	
25945/33150 (epoch 39.133), train_loss = 0.78612960, grad/param norm = 1.6555e-01, time/batch = 0.6710s	
25946/33150 (epoch 39.134), train_loss = 0.94371520, grad/param norm = 1.8279e-01, time/batch = 0.6806s	
25947/33150 (epoch 39.136), train_loss = 0.85949103, grad/param norm = 1.9675e-01, time/batch = 0.6785s	
25948/33150 (epoch 39.137), train_loss = 0.89990702, grad/param norm = 1.6486e-01, time/batch = 0.6740s	
25949/33150 (epoch 39.139), train_loss = 0.90557749, grad/param norm = 1.9704e-01, time/batch = 0.6708s	
25950/33150 (epoch 39.140), train_loss = 0.99724740, grad/param norm = 1.9118e-01, time/batch = 0.6735s	
25951/33150 (epoch 39.142), train_loss = 0.90357131, grad/param norm = 2.1716e-01, time/batch = 0.6779s	
25952/33150 (epoch 39.143), train_loss = 0.84102223, grad/param norm = 2.0180e-01, time/batch = 0.6744s	
25953/33150 (epoch 39.145), train_loss = 0.81027142, grad/param norm = 2.1137e-01, time/batch = 0.6852s	
25954/33150 (epoch 39.146), train_loss = 0.93371669, grad/param norm = 2.1140e-01, time/batch = 0.6761s	
25955/33150 (epoch 39.148), train_loss = 0.99103374, grad/param norm = 1.8202e-01, time/batch = 0.6792s	
25956/33150 (epoch 39.149), train_loss = 0.86167194, grad/param norm = 2.0342e-01, time/batch = 0.6822s	
25957/33150 (epoch 39.151), train_loss = 1.00599209, grad/param norm = 2.2612e-01, time/batch = 0.6804s	
25958/33150 (epoch 39.152), train_loss = 0.79549146, grad/param norm = 1.7280e-01, time/batch = 0.6786s	
25959/33150 (epoch 39.154), train_loss = 0.80058060, grad/param norm = 2.0502e-01, time/batch = 0.6786s	
25960/33150 (epoch 39.155), train_loss = 0.73514837, grad/param norm = 1.7420e-01, time/batch = 0.6686s	
25961/33150 (epoch 39.157), train_loss = 0.83786900, grad/param norm = 1.8834e-01, time/batch = 0.6709s	
25962/33150 (epoch 39.158), train_loss = 0.80605976, grad/param norm = 1.5586e-01, time/batch = 0.6733s	
25963/33150 (epoch 39.160), train_loss = 0.92134955, grad/param norm = 1.8796e-01, time/batch = 0.6786s	
25964/33150 (epoch 39.161), train_loss = 0.80693263, grad/param norm = 2.3133e-01, time/batch = 0.6647s	
25965/33150 (epoch 39.163), train_loss = 0.74477843, grad/param norm = 1.6917e-01, time/batch = 0.6713s	
25966/33150 (epoch 39.164), train_loss = 0.87356827, grad/param norm = 1.8069e-01, time/batch = 0.6674s	
25967/33150 (epoch 39.166), train_loss = 0.81448887, grad/param norm = 1.7369e-01, time/batch = 0.6662s	
25968/33150 (epoch 39.167), train_loss = 0.87062285, grad/param norm = 1.6238e-01, time/batch = 0.6643s	
25969/33150 (epoch 39.169), train_loss = 0.85179374, grad/param norm = 2.1654e-01, time/batch = 0.6694s	
25970/33150 (epoch 39.170), train_loss = 0.76980265, grad/param norm = 2.3924e-01, time/batch = 0.6750s	
25971/33150 (epoch 39.172), train_loss = 0.89376364, grad/param norm = 2.1472e-01, time/batch = 0.6717s	
25972/33150 (epoch 39.173), train_loss = 0.86846002, grad/param norm = 1.9435e-01, time/batch = 0.6669s	
25973/33150 (epoch 39.175), train_loss = 0.81477711, grad/param norm = 1.9145e-01, time/batch = 0.6664s	
25974/33150 (epoch 39.176), train_loss = 0.88572442, grad/param norm = 1.9348e-01, time/batch = 0.6684s	
25975/33150 (epoch 39.178), train_loss = 1.02448863, grad/param norm = 2.0189e-01, time/batch = 0.6722s	
25976/33150 (epoch 39.179), train_loss = 0.92674621, grad/param norm = 1.9608e-01, time/batch = 0.6732s	
25977/33150 (epoch 39.181), train_loss = 0.87477583, grad/param norm = 2.2950e-01, time/batch = 0.6740s	
25978/33150 (epoch 39.183), train_loss = 0.82863145, grad/param norm = 1.9284e-01, time/batch = 0.6852s	
25979/33150 (epoch 39.184), train_loss = 1.07940958, grad/param norm = 2.0026e-01, time/batch = 0.6837s	
25980/33150 (epoch 39.186), train_loss = 1.00211316, grad/param norm = 1.7263e-01, time/batch = 0.6790s	
25981/33150 (epoch 39.187), train_loss = 0.85351186, grad/param norm = 1.9752e-01, time/batch = 0.6868s	
25982/33150 (epoch 39.189), train_loss = 0.67980308, grad/param norm = 1.7423e-01, time/batch = 0.6860s	
25983/33150 (epoch 39.190), train_loss = 0.76846297, grad/param norm = 1.7436e-01, time/batch = 0.6836s	
25984/33150 (epoch 39.192), train_loss = 0.87894809, grad/param norm = 1.9043e-01, time/batch = 0.6831s	
25985/33150 (epoch 39.193), train_loss = 0.90839485, grad/param norm = 1.7503e-01, time/batch = 0.6809s	
25986/33150 (epoch 39.195), train_loss = 1.03571937, grad/param norm = 2.1333e-01, time/batch = 0.6727s	
25987/33150 (epoch 39.196), train_loss = 0.95773107, grad/param norm = 1.7373e-01, time/batch = 0.6720s	
25988/33150 (epoch 39.198), train_loss = 0.74339842, grad/param norm = 1.5334e-01, time/batch = 0.6700s	
25989/33150 (epoch 39.199), train_loss = 0.93735542, grad/param norm = 2.5277e-01, time/batch = 0.6701s	
25990/33150 (epoch 39.201), train_loss = 0.81007146, grad/param norm = 1.7120e-01, time/batch = 0.6678s	
25991/33150 (epoch 39.202), train_loss = 0.67555762, grad/param norm = 1.6485e-01, time/batch = 0.6869s	
25992/33150 (epoch 39.204), train_loss = 0.86232569, grad/param norm = 1.7692e-01, time/batch = 0.6886s	
25993/33150 (epoch 39.205), train_loss = 0.90193128, grad/param norm = 2.3305e-01, time/batch = 0.6760s	
25994/33150 (epoch 39.207), train_loss = 0.88460494, grad/param norm = 1.8405e-01, time/batch = 0.6727s	
25995/33150 (epoch 39.208), train_loss = 0.91773594, grad/param norm = 1.7970e-01, time/batch = 0.6727s	
25996/33150 (epoch 39.210), train_loss = 0.81268441, grad/param norm = 1.8073e-01, time/batch = 0.6768s	
25997/33150 (epoch 39.211), train_loss = 0.83539427, grad/param norm = 1.9577e-01, time/batch = 0.6725s	
25998/33150 (epoch 39.213), train_loss = 0.90224175, grad/param norm = 1.7352e-01, time/batch = 0.6687s	
25999/33150 (epoch 39.214), train_loss = 0.82201386, grad/param norm = 1.7558e-01, time/batch = 0.6666s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch39.22_1.8000.t7	
26000/33150 (epoch 39.216), train_loss = 0.76952292, grad/param norm = 2.2214e-01, time/batch = 0.6645s	
26001/33150 (epoch 39.217), train_loss = 1.43283185, grad/param norm = 2.5323e-01, time/batch = 0.6899s	
26002/33150 (epoch 39.219), train_loss = 0.80062537, grad/param norm = 1.7690e-01, time/batch = 0.6796s	
26003/33150 (epoch 39.220), train_loss = 0.82131340, grad/param norm = 1.5422e-01, time/batch = 0.6666s	
26004/33150 (epoch 39.222), train_loss = 0.93362517, grad/param norm = 1.9096e-01, time/batch = 0.6682s	
26005/33150 (epoch 39.223), train_loss = 0.85588428, grad/param norm = 1.9448e-01, time/batch = 0.6738s	
26006/33150 (epoch 39.225), train_loss = 0.96321679, grad/param norm = 1.7680e-01, time/batch = 0.6688s	
26007/33150 (epoch 39.226), train_loss = 0.81344898, grad/param norm = 1.7026e-01, time/batch = 0.6710s	
26008/33150 (epoch 39.228), train_loss = 0.82186162, grad/param norm = 2.6192e-01, time/batch = 0.6706s	
26009/33150 (epoch 39.229), train_loss = 0.83831843, grad/param norm = 1.7929e-01, time/batch = 0.6789s	
26010/33150 (epoch 39.231), train_loss = 0.95126724, grad/param norm = 1.9108e-01, time/batch = 0.6777s	
26011/33150 (epoch 39.232), train_loss = 0.83219350, grad/param norm = 1.8188e-01, time/batch = 0.6814s	
26012/33150 (epoch 39.234), train_loss = 0.88129506, grad/param norm = 1.8547e-01, time/batch = 0.6748s	
26013/33150 (epoch 39.235), train_loss = 0.90850562, grad/param norm = 1.9455e-01, time/batch = 0.6691s	
26014/33150 (epoch 39.237), train_loss = 0.86776048, grad/param norm = 1.9512e-01, time/batch = 0.6908s	
26015/33150 (epoch 39.238), train_loss = 0.92313102, grad/param norm = 2.1642e-01, time/batch = 0.6979s	
26016/33150 (epoch 39.240), train_loss = 0.89147699, grad/param norm = 1.9738e-01, time/batch = 0.6898s	
26017/33150 (epoch 39.241), train_loss = 0.93563158, grad/param norm = 2.1590e-01, time/batch = 0.6851s	
26018/33150 (epoch 39.243), train_loss = 0.91937838, grad/param norm = 1.8951e-01, time/batch = 0.6779s	
26019/33150 (epoch 39.244), train_loss = 0.87996809, grad/param norm = 1.6819e-01, time/batch = 0.6816s	
26020/33150 (epoch 39.246), train_loss = 0.93532525, grad/param norm = 1.7131e-01, time/batch = 0.6897s	
26021/33150 (epoch 39.247), train_loss = 0.79877255, grad/param norm = 1.7772e-01, time/batch = 0.6799s	
26022/33150 (epoch 39.249), train_loss = 0.98266671, grad/param norm = 1.7636e-01, time/batch = 0.6807s	
26023/33150 (epoch 39.250), train_loss = 0.91164464, grad/param norm = 1.6151e-01, time/batch = 0.6817s	
26024/33150 (epoch 39.252), train_loss = 0.90246958, grad/param norm = 1.5784e-01, time/batch = 0.6893s	
26025/33150 (epoch 39.253), train_loss = 0.83444666, grad/param norm = 2.1954e-01, time/batch = 0.6717s	
26026/33150 (epoch 39.255), train_loss = 0.83639986, grad/param norm = 1.4698e-01, time/batch = 0.6646s	
26027/33150 (epoch 39.256), train_loss = 0.96559570, grad/param norm = 1.8763e-01, time/batch = 0.6664s	
26028/33150 (epoch 39.258), train_loss = 0.80087039, grad/param norm = 1.7900e-01, time/batch = 0.6667s	
26029/33150 (epoch 39.259), train_loss = 0.68734516, grad/param norm = 1.7513e-01, time/batch = 0.6689s	
26030/33150 (epoch 39.261), train_loss = 0.76445688, grad/param norm = 1.5374e-01, time/batch = 0.6699s	
26031/33150 (epoch 39.262), train_loss = 0.96728496, grad/param norm = 1.9450e-01, time/batch = 0.6707s	
26032/33150 (epoch 39.264), train_loss = 0.65896454, grad/param norm = 1.5614e-01, time/batch = 0.6698s	
26033/33150 (epoch 39.265), train_loss = 0.87334304, grad/param norm = 1.8350e-01, time/batch = 0.6736s	
26034/33150 (epoch 39.267), train_loss = 0.96746683, grad/param norm = 2.0746e-01, time/batch = 0.6755s	
26035/33150 (epoch 39.268), train_loss = 0.97006084, grad/param norm = 1.7704e-01, time/batch = 0.6640s	
26036/33150 (epoch 39.270), train_loss = 1.03263542, grad/param norm = 1.8787e-01, time/batch = 0.6719s	
26037/33150 (epoch 39.271), train_loss = 0.92050204, grad/param norm = 2.1825e-01, time/batch = 0.6673s	
26038/33150 (epoch 39.273), train_loss = 0.96217028, grad/param norm = 1.8580e-01, time/batch = 0.6673s	
26039/33150 (epoch 39.275), train_loss = 0.97355097, grad/param norm = 1.7804e-01, time/batch = 0.6680s	
26040/33150 (epoch 39.276), train_loss = 0.86484530, grad/param norm = 1.8716e-01, time/batch = 0.6687s	
26041/33150 (epoch 39.278), train_loss = 0.98271813, grad/param norm = 1.9925e-01, time/batch = 0.6701s	
26042/33150 (epoch 39.279), train_loss = 0.95074753, grad/param norm = 1.6143e-01, time/batch = 0.6726s	
26043/33150 (epoch 39.281), train_loss = 0.87565800, grad/param norm = 1.6587e-01, time/batch = 0.6720s	
26044/33150 (epoch 39.282), train_loss = 0.91012314, grad/param norm = 1.5546e-01, time/batch = 0.6713s	
26045/33150 (epoch 39.284), train_loss = 0.78816299, grad/param norm = 1.6666e-01, time/batch = 0.6718s	
26046/33150 (epoch 39.285), train_loss = 0.88688639, grad/param norm = 1.8669e-01, time/batch = 0.6751s	
26047/33150 (epoch 39.287), train_loss = 0.74930252, grad/param norm = 1.6143e-01, time/batch = 0.6723s	
26048/33150 (epoch 39.288), train_loss = 0.94274582, grad/param norm = 1.9001e-01, time/batch = 0.6824s	
26049/33150 (epoch 39.290), train_loss = 0.73442761, grad/param norm = 1.8389e-01, time/batch = 0.6756s	
26050/33150 (epoch 39.291), train_loss = 0.71027788, grad/param norm = 1.9278e-01, time/batch = 0.6683s	
26051/33150 (epoch 39.293), train_loss = 0.83331977, grad/param norm = 1.8153e-01, time/batch = 0.6734s	
26052/33150 (epoch 39.294), train_loss = 0.67077008, grad/param norm = 1.6398e-01, time/batch = 0.6682s	
26053/33150 (epoch 39.296), train_loss = 0.86498010, grad/param norm = 1.7724e-01, time/batch = 0.6682s	
26054/33150 (epoch 39.297), train_loss = 0.80471937, grad/param norm = 1.9272e-01, time/batch = 0.6678s	
26055/33150 (epoch 39.299), train_loss = 0.80425622, grad/param norm = 2.0821e-01, time/batch = 0.6681s	
26056/33150 (epoch 39.300), train_loss = 0.80506170, grad/param norm = 1.5765e-01, time/batch = 0.6680s	
26057/33150 (epoch 39.302), train_loss = 0.83790035, grad/param norm = 1.7479e-01, time/batch = 0.6717s	
26058/33150 (epoch 39.303), train_loss = 0.81994939, grad/param norm = 1.8012e-01, time/batch = 0.6704s	
26059/33150 (epoch 39.305), train_loss = 0.90192407, grad/param norm = 1.8014e-01, time/batch = 0.6717s	
26060/33150 (epoch 39.306), train_loss = 0.91393846, grad/param norm = 2.1129e-01, time/batch = 0.6825s	
26061/33150 (epoch 39.308), train_loss = 1.06471242, grad/param norm = 1.8833e-01, time/batch = 0.6829s	
26062/33150 (epoch 39.309), train_loss = 0.70120489, grad/param norm = 1.4095e-01, time/batch = 0.6816s	
26063/33150 (epoch 39.311), train_loss = 0.83357529, grad/param norm = 1.9493e-01, time/batch = 0.6816s	
26064/33150 (epoch 39.312), train_loss = 0.70604079, grad/param norm = 1.8913e-01, time/batch = 0.6796s	
26065/33150 (epoch 39.314), train_loss = 0.81682941, grad/param norm = 1.7564e-01, time/batch = 0.6839s	
26066/33150 (epoch 39.315), train_loss = 0.90008885, grad/param norm = 1.7853e-01, time/batch = 0.6757s	
26067/33150 (epoch 39.317), train_loss = 0.68315867, grad/param norm = 1.4305e-01, time/batch = 0.6714s	
26068/33150 (epoch 39.318), train_loss = 0.77694142, grad/param norm = 1.4826e-01, time/batch = 0.6683s	
26069/33150 (epoch 39.320), train_loss = 0.72152131, grad/param norm = 1.7519e-01, time/batch = 0.6718s	
26070/33150 (epoch 39.321), train_loss = 0.80611881, grad/param norm = 1.4565e-01, time/batch = 0.6690s	
26071/33150 (epoch 39.323), train_loss = 0.80921414, grad/param norm = 1.9231e-01, time/batch = 0.6718s	
26072/33150 (epoch 39.324), train_loss = 0.84389149, grad/param norm = 2.3520e-01, time/batch = 0.6793s	
26073/33150 (epoch 39.326), train_loss = 0.83217159, grad/param norm = 1.6683e-01, time/batch = 0.6777s	
26074/33150 (epoch 39.327), train_loss = 0.93112907, grad/param norm = 1.8081e-01, time/batch = 0.6738s	
26075/33150 (epoch 39.329), train_loss = 0.88828628, grad/param norm = 1.7620e-01, time/batch = 0.6757s	
26076/33150 (epoch 39.330), train_loss = 0.80875281, grad/param norm = 1.9034e-01, time/batch = 0.6732s	
26077/33150 (epoch 39.332), train_loss = 0.81960931, grad/param norm = 1.6501e-01, time/batch = 0.6691s	
26078/33150 (epoch 39.333), train_loss = 0.91058407, grad/param norm = 1.6464e-01, time/batch = 0.6743s	
26079/33150 (epoch 39.335), train_loss = 0.77515169, grad/param norm = 1.7201e-01, time/batch = 0.6718s	
26080/33150 (epoch 39.336), train_loss = 0.75642771, grad/param norm = 1.9069e-01, time/batch = 0.6693s	
26081/33150 (epoch 39.338), train_loss = 0.72518209, grad/param norm = 1.7942e-01, time/batch = 0.6728s	
26082/33150 (epoch 39.339), train_loss = 0.91345479, grad/param norm = 1.9397e-01, time/batch = 0.6732s	
26083/33150 (epoch 39.341), train_loss = 0.82900987, grad/param norm = 2.0665e-01, time/batch = 0.6702s	
26084/33150 (epoch 39.342), train_loss = 0.77699674, grad/param norm = 1.6916e-01, time/batch = 0.6759s	
26085/33150 (epoch 39.344), train_loss = 0.82538628, grad/param norm = 1.6387e-01, time/batch = 0.6702s	
26086/33150 (epoch 39.345), train_loss = 0.82278797, grad/param norm = 1.7333e-01, time/batch = 0.6708s	
26087/33150 (epoch 39.347), train_loss = 0.70928994, grad/param norm = 1.8779e-01, time/batch = 0.6775s	
26088/33150 (epoch 39.348), train_loss = 0.86255230, grad/param norm = 1.7732e-01, time/batch = 0.6860s	
26089/33150 (epoch 39.350), train_loss = 0.74151282, grad/param norm = 1.8350e-01, time/batch = 0.6890s	
26090/33150 (epoch 39.351), train_loss = 0.89887749, grad/param norm = 1.7547e-01, time/batch = 0.6843s	
26091/33150 (epoch 39.353), train_loss = 0.86896643, grad/param norm = 1.7222e-01, time/batch = 0.6887s	
26092/33150 (epoch 39.354), train_loss = 1.04303958, grad/param norm = 1.8499e-01, time/batch = 0.6952s	
26093/33150 (epoch 39.356), train_loss = 0.92314695, grad/param norm = 1.7350e-01, time/batch = 0.6747s	
26094/33150 (epoch 39.357), train_loss = 0.86560282, grad/param norm = 2.0019e-01, time/batch = 0.6674s	
26095/33150 (epoch 39.359), train_loss = 0.92401981, grad/param norm = 1.7812e-01, time/batch = 0.6648s	
26096/33150 (epoch 39.360), train_loss = 0.89268979, grad/param norm = 1.9051e-01, time/batch = 0.6885s	
26097/33150 (epoch 39.362), train_loss = 0.95639765, grad/param norm = 1.8754e-01, time/batch = 0.6949s	
26098/33150 (epoch 39.363), train_loss = 0.87896016, grad/param norm = 1.7053e-01, time/batch = 0.6917s	
26099/33150 (epoch 39.365), train_loss = 0.83284375, grad/param norm = 1.6674e-01, time/batch = 0.6762s	
26100/33150 (epoch 39.367), train_loss = 0.80243887, grad/param norm = 1.5711e-01, time/batch = 0.6667s	
26101/33150 (epoch 39.368), train_loss = 0.83508016, grad/param norm = 2.4270e-01, time/batch = 0.6680s	
26102/33150 (epoch 39.370), train_loss = 0.86393857, grad/param norm = 2.1227e-01, time/batch = 0.6676s	
26103/33150 (epoch 39.371), train_loss = 0.76846780, grad/param norm = 1.8237e-01, time/batch = 0.6681s	
26104/33150 (epoch 39.373), train_loss = 0.87647524, grad/param norm = 1.8952e-01, time/batch = 0.6667s	
26105/33150 (epoch 39.374), train_loss = 0.85662684, grad/param norm = 1.6013e-01, time/batch = 0.6673s	
26106/33150 (epoch 39.376), train_loss = 0.92069147, grad/param norm = 1.6107e-01, time/batch = 0.6660s	
26107/33150 (epoch 39.377), train_loss = 0.76380618, grad/param norm = 1.7407e-01, time/batch = 0.6739s	
26108/33150 (epoch 39.379), train_loss = 0.88084835, grad/param norm = 1.9635e-01, time/batch = 0.6713s	
26109/33150 (epoch 39.380), train_loss = 0.90223511, grad/param norm = 1.4986e-01, time/batch = 0.6669s	
26110/33150 (epoch 39.382), train_loss = 0.86297292, grad/param norm = 2.1025e-01, time/batch = 0.6730s	
26111/33150 (epoch 39.383), train_loss = 0.76674035, grad/param norm = 1.6064e-01, time/batch = 0.6668s	
26112/33150 (epoch 39.385), train_loss = 0.79161727, grad/param norm = 1.7042e-01, time/batch = 0.6672s	
26113/33150 (epoch 39.386), train_loss = 0.73848312, grad/param norm = 1.4547e-01, time/batch = 0.6668s	
26114/33150 (epoch 39.388), train_loss = 0.77033421, grad/param norm = 1.8382e-01, time/batch = 0.6734s	
26115/33150 (epoch 39.389), train_loss = 0.77145765, grad/param norm = 1.5109e-01, time/batch = 0.6697s	
26116/33150 (epoch 39.391), train_loss = 0.97929737, grad/param norm = 2.0991e-01, time/batch = 0.6675s	
26117/33150 (epoch 39.392), train_loss = 0.78596923, grad/param norm = 1.7399e-01, time/batch = 0.6681s	
26118/33150 (epoch 39.394), train_loss = 0.72523708, grad/param norm = 1.5367e-01, time/batch = 0.6689s	
26119/33150 (epoch 39.395), train_loss = 0.68424913, grad/param norm = 1.7259e-01, time/batch = 0.6680s	
26120/33150 (epoch 39.397), train_loss = 0.58952239, grad/param norm = 1.5557e-01, time/batch = 0.6773s	
26121/33150 (epoch 39.398), train_loss = 0.83822727, grad/param norm = 1.7086e-01, time/batch = 0.6693s	
26122/33150 (epoch 39.400), train_loss = 0.81878852, grad/param norm = 1.4167e-01, time/batch = 0.6694s	
26123/33150 (epoch 39.401), train_loss = 0.70416516, grad/param norm = 1.4326e-01, time/batch = 0.6692s	
26124/33150 (epoch 39.403), train_loss = 0.70376178, grad/param norm = 1.4694e-01, time/batch = 0.6691s	
26125/33150 (epoch 39.404), train_loss = 0.83382165, grad/param norm = 1.5772e-01, time/batch = 0.6699s	
26126/33150 (epoch 39.406), train_loss = 0.80377587, grad/param norm = 1.4067e-01, time/batch = 0.6710s	
26127/33150 (epoch 39.407), train_loss = 0.71253474, grad/param norm = 1.5638e-01, time/batch = 0.6681s	
26128/33150 (epoch 39.409), train_loss = 0.66275875, grad/param norm = 1.5563e-01, time/batch = 0.6668s	
26129/33150 (epoch 39.410), train_loss = 0.84333120, grad/param norm = 1.9054e-01, time/batch = 0.6670s	
26130/33150 (epoch 39.412), train_loss = 0.89286386, grad/param norm = 1.6173e-01, time/batch = 0.6741s	
26131/33150 (epoch 39.413), train_loss = 0.73371676, grad/param norm = 1.5779e-01, time/batch = 0.6760s	
26132/33150 (epoch 39.415), train_loss = 0.85899087, grad/param norm = 1.6199e-01, time/batch = 0.6738s	
26133/33150 (epoch 39.416), train_loss = 0.76341258, grad/param norm = 1.5057e-01, time/batch = 0.6734s	
26134/33150 (epoch 39.418), train_loss = 0.84647421, grad/param norm = 1.9903e-01, time/batch = 0.6711s	
26135/33150 (epoch 39.419), train_loss = 0.82264676, grad/param norm = 1.6599e-01, time/batch = 0.6751s	
26136/33150 (epoch 39.421), train_loss = 0.83327071, grad/param norm = 1.8522e-01, time/batch = 0.6745s	
26137/33150 (epoch 39.422), train_loss = 0.79865974, grad/param norm = 1.6454e-01, time/batch = 0.6759s	
26138/33150 (epoch 39.424), train_loss = 0.76841296, grad/param norm = 1.8306e-01, time/batch = 0.6751s	
26139/33150 (epoch 39.425), train_loss = 0.90321103, grad/param norm = 1.7525e-01, time/batch = 0.6769s	
26140/33150 (epoch 39.427), train_loss = 0.82438235, grad/param norm = 1.5676e-01, time/batch = 0.6768s	
26141/33150 (epoch 39.428), train_loss = 0.78599770, grad/param norm = 1.7482e-01, time/batch = 0.6734s	
26142/33150 (epoch 39.430), train_loss = 0.84720720, grad/param norm = 1.8075e-01, time/batch = 0.6720s	
26143/33150 (epoch 39.431), train_loss = 0.88895231, grad/param norm = 1.9839e-01, time/batch = 0.6761s	
26144/33150 (epoch 39.433), train_loss = 0.81038276, grad/param norm = 1.6054e-01, time/batch = 0.6751s	
26145/33150 (epoch 39.434), train_loss = 0.71651488, grad/param norm = 1.7402e-01, time/batch = 0.6688s	
26146/33150 (epoch 39.436), train_loss = 0.82645478, grad/param norm = 1.4661e-01, time/batch = 0.6687s	
26147/33150 (epoch 39.437), train_loss = 0.83148616, grad/param norm = 2.0405e-01, time/batch = 0.6915s	
26148/33150 (epoch 39.439), train_loss = 0.97737807, grad/param norm = 1.6705e-01, time/batch = 0.6816s	
26149/33150 (epoch 39.440), train_loss = 0.87517749, grad/param norm = 1.8016e-01, time/batch = 0.6799s	
26150/33150 (epoch 39.442), train_loss = 0.71627209, grad/param norm = 1.7196e-01, time/batch = 0.6739s	
26151/33150 (epoch 39.443), train_loss = 0.84608990, grad/param norm = 1.7936e-01, time/batch = 0.6717s	
26152/33150 (epoch 39.445), train_loss = 0.83905196, grad/param norm = 2.1051e-01, time/batch = 0.6778s	
26153/33150 (epoch 39.446), train_loss = 0.85773251, grad/param norm = 2.0847e-01, time/batch = 0.6692s	
26154/33150 (epoch 39.448), train_loss = 0.92332913, grad/param norm = 1.9441e-01, time/batch = 0.6699s	
26155/33150 (epoch 39.449), train_loss = 0.84252540, grad/param norm = 1.5722e-01, time/batch = 0.6740s	
26156/33150 (epoch 39.451), train_loss = 0.85709930, grad/param norm = 1.9535e-01, time/batch = 0.6693s	
26157/33150 (epoch 39.452), train_loss = 1.01186577, grad/param norm = 1.9992e-01, time/batch = 0.6712s	
26158/33150 (epoch 39.454), train_loss = 0.81286527, grad/param norm = 1.6777e-01, time/batch = 0.6698s	
26159/33150 (epoch 39.456), train_loss = 0.79083804, grad/param norm = 1.6350e-01, time/batch = 0.6713s	
26160/33150 (epoch 39.457), train_loss = 0.84959204, grad/param norm = 1.9774e-01, time/batch = 0.6852s	
26161/33150 (epoch 39.459), train_loss = 0.96857604, grad/param norm = 2.2011e-01, time/batch = 0.6939s	
26162/33150 (epoch 39.460), train_loss = 0.89412679, grad/param norm = 1.6150e-01, time/batch = 0.6798s	
26163/33150 (epoch 39.462), train_loss = 0.93878262, grad/param norm = 1.8184e-01, time/batch = 0.6691s	
26164/33150 (epoch 39.463), train_loss = 1.06431096, grad/param norm = 2.2584e-01, time/batch = 0.6733s	
26165/33150 (epoch 39.465), train_loss = 0.91735270, grad/param norm = 1.7705e-01, time/batch = 0.6703s	
26166/33150 (epoch 39.466), train_loss = 0.80841748, grad/param norm = 1.6704e-01, time/batch = 0.6705s	
26167/33150 (epoch 39.468), train_loss = 1.05706946, grad/param norm = 2.1401e-01, time/batch = 0.6739s	
26168/33150 (epoch 39.469), train_loss = 0.78298288, grad/param norm = 1.7991e-01, time/batch = 0.6752s	
26169/33150 (epoch 39.471), train_loss = 0.78929270, grad/param norm = 1.7571e-01, time/batch = 0.6798s	
26170/33150 (epoch 39.472), train_loss = 0.86348965, grad/param norm = 1.8008e-01, time/batch = 0.6745s	
26171/33150 (epoch 39.474), train_loss = 0.91071492, grad/param norm = 2.2845e-01, time/batch = 0.6711s	
26172/33150 (epoch 39.475), train_loss = 1.08615887, grad/param norm = 1.9239e-01, time/batch = 0.6738s	
26173/33150 (epoch 39.477), train_loss = 0.89857172, grad/param norm = 1.6878e-01, time/batch = 0.6854s	
26174/33150 (epoch 39.478), train_loss = 0.86261351, grad/param norm = 1.7632e-01, time/batch = 0.6849s	
26175/33150 (epoch 39.480), train_loss = 0.77228242, grad/param norm = 1.6620e-01, time/batch = 0.6816s	
26176/33150 (epoch 39.481), train_loss = 0.72266433, grad/param norm = 1.6715e-01, time/batch = 0.6813s	
26177/33150 (epoch 39.483), train_loss = 0.81227525, grad/param norm = 1.7433e-01, time/batch = 0.6897s	
26178/33150 (epoch 39.484), train_loss = 0.75647676, grad/param norm = 1.7591e-01, time/batch = 0.6958s	
26179/33150 (epoch 39.486), train_loss = 0.77833898, grad/param norm = 1.8066e-01, time/batch = 0.6961s	
26180/33150 (epoch 39.487), train_loss = 0.88529366, grad/param norm = 1.7231e-01, time/batch = 0.7040s	
26181/33150 (epoch 39.489), train_loss = 0.84876102, grad/param norm = 1.9048e-01, time/batch = 0.6902s	
26182/33150 (epoch 39.490), train_loss = 0.66674021, grad/param norm = 1.3965e-01, time/batch = 0.6903s	
26183/33150 (epoch 39.492), train_loss = 0.81155900, grad/param norm = 1.8641e-01, time/batch = 0.6907s	
26184/33150 (epoch 39.493), train_loss = 0.89160273, grad/param norm = 1.8950e-01, time/batch = 0.6740s	
26185/33150 (epoch 39.495), train_loss = 0.88966003, grad/param norm = 1.6318e-01, time/batch = 0.6769s	
26186/33150 (epoch 39.496), train_loss = 0.80775222, grad/param norm = 1.6190e-01, time/batch = 0.6727s	
26187/33150 (epoch 39.498), train_loss = 0.91012060, grad/param norm = 2.1616e-01, time/batch = 0.6693s	
26188/33150 (epoch 39.499), train_loss = 0.93205834, grad/param norm = 1.8467e-01, time/batch = 0.6832s	
26189/33150 (epoch 39.501), train_loss = 0.88479319, grad/param norm = 2.4790e-01, time/batch = 0.6684s	
26190/33150 (epoch 39.502), train_loss = 0.94109953, grad/param norm = 2.0827e-01, time/batch = 0.6696s	
26191/33150 (epoch 39.504), train_loss = 0.94563576, grad/param norm = 2.0812e-01, time/batch = 0.6820s	
26192/33150 (epoch 39.505), train_loss = 0.95951232, grad/param norm = 1.9792e-01, time/batch = 0.6722s	
26193/33150 (epoch 39.507), train_loss = 0.78387509, grad/param norm = 1.7324e-01, time/batch = 0.6714s	
26194/33150 (epoch 39.508), train_loss = 0.78621275, grad/param norm = 1.7609e-01, time/batch = 0.6693s	
26195/33150 (epoch 39.510), train_loss = 0.91117437, grad/param norm = 1.5116e-01, time/batch = 0.6659s	
26196/33150 (epoch 39.511), train_loss = 0.93586844, grad/param norm = 1.9093e-01, time/batch = 0.6675s	
26197/33150 (epoch 39.513), train_loss = 0.86415661, grad/param norm = 1.9967e-01, time/batch = 0.6692s	
26198/33150 (epoch 39.514), train_loss = 0.72943868, grad/param norm = 1.6585e-01, time/batch = 0.6696s	
26199/33150 (epoch 39.516), train_loss = 0.87686249, grad/param norm = 2.2586e-01, time/batch = 0.6694s	
26200/33150 (epoch 39.517), train_loss = 0.91492442, grad/param norm = 1.8372e-01, time/batch = 0.6669s	
26201/33150 (epoch 39.519), train_loss = 0.77392384, grad/param norm = 1.6422e-01, time/batch = 0.6664s	
26202/33150 (epoch 39.520), train_loss = 0.84296806, grad/param norm = 1.7590e-01, time/batch = 0.6691s	
26203/33150 (epoch 39.522), train_loss = 0.91333970, grad/param norm = 1.9356e-01, time/batch = 0.6715s	
26204/33150 (epoch 39.523), train_loss = 0.74096409, grad/param norm = 1.6886e-01, time/batch = 0.6702s	
26205/33150 (epoch 39.525), train_loss = 0.88750649, grad/param norm = 1.9551e-01, time/batch = 0.6733s	
26206/33150 (epoch 39.526), train_loss = 0.75614469, grad/param norm = 1.6972e-01, time/batch = 0.6719s	
26207/33150 (epoch 39.528), train_loss = 0.85828509, grad/param norm = 1.7305e-01, time/batch = 0.6674s	
26208/33150 (epoch 39.529), train_loss = 0.83724455, grad/param norm = 1.6852e-01, time/batch = 0.6704s	
26209/33150 (epoch 39.531), train_loss = 0.73197099, grad/param norm = 2.0002e-01, time/batch = 0.6712s	
26210/33150 (epoch 39.532), train_loss = 0.86148251, grad/param norm = 2.0469e-01, time/batch = 0.6685s	
26211/33150 (epoch 39.534), train_loss = 0.83833163, grad/param norm = 1.6376e-01, time/batch = 0.6732s	
26212/33150 (epoch 39.535), train_loss = 0.77111330, grad/param norm = 1.9228e-01, time/batch = 0.6699s	
26213/33150 (epoch 39.537), train_loss = 0.84641943, grad/param norm = 1.9543e-01, time/batch = 0.6687s	
26214/33150 (epoch 39.538), train_loss = 0.76942793, grad/param norm = 1.6499e-01, time/batch = 0.6735s	
26215/33150 (epoch 39.540), train_loss = 0.77221861, grad/param norm = 2.0100e-01, time/batch = 0.6743s	
26216/33150 (epoch 39.541), train_loss = 0.92635890, grad/param norm = 1.8402e-01, time/batch = 0.6680s	
26217/33150 (epoch 39.543), train_loss = 0.85008702, grad/param norm = 1.6703e-01, time/batch = 0.6704s	
26218/33150 (epoch 39.544), train_loss = 0.90036423, grad/param norm = 1.6859e-01, time/batch = 0.6678s	
26219/33150 (epoch 39.546), train_loss = 0.79508949, grad/param norm = 1.8473e-01, time/batch = 0.6704s	
26220/33150 (epoch 39.548), train_loss = 0.82535471, grad/param norm = 2.0280e-01, time/batch = 0.6705s	
26221/33150 (epoch 39.549), train_loss = 0.80986031, grad/param norm = 1.9752e-01, time/batch = 0.6711s	
26222/33150 (epoch 39.551), train_loss = 0.76252113, grad/param norm = 1.6036e-01, time/batch = 0.6681s	
26223/33150 (epoch 39.552), train_loss = 0.66005254, grad/param norm = 1.5907e-01, time/batch = 0.6693s	
26224/33150 (epoch 39.554), train_loss = 0.91650117, grad/param norm = 1.8198e-01, time/batch = 0.6670s	
26225/33150 (epoch 39.555), train_loss = 0.94669554, grad/param norm = 2.1066e-01, time/batch = 0.6657s	
26226/33150 (epoch 39.557), train_loss = 0.71072717, grad/param norm = 1.7702e-01, time/batch = 0.6729s	
26227/33150 (epoch 39.558), train_loss = 0.88547723, grad/param norm = 2.4524e-01, time/batch = 0.6676s	
26228/33150 (epoch 39.560), train_loss = 0.74588120, grad/param norm = 1.5707e-01, time/batch = 0.6681s	
26229/33150 (epoch 39.561), train_loss = 0.70471790, grad/param norm = 1.8480e-01, time/batch = 0.6702s	
26230/33150 (epoch 39.563), train_loss = 0.89197420, grad/param norm = 2.1192e-01, time/batch = 0.6633s	
26231/33150 (epoch 39.564), train_loss = 0.94097791, grad/param norm = 1.6833e-01, time/batch = 0.6688s	
26232/33150 (epoch 39.566), train_loss = 0.76125770, grad/param norm = 1.7015e-01, time/batch = 0.6685s	
26233/33150 (epoch 39.567), train_loss = 0.81143770, grad/param norm = 2.0279e-01, time/batch = 0.6655s	
26234/33150 (epoch 39.569), train_loss = 0.84462545, grad/param norm = 1.7302e-01, time/batch = 0.6781s	
26235/33150 (epoch 39.570), train_loss = 0.87442635, grad/param norm = 1.5459e-01, time/batch = 0.6913s	
26236/33150 (epoch 39.572), train_loss = 0.77999715, grad/param norm = 1.6751e-01, time/batch = 0.6910s	
26237/33150 (epoch 39.573), train_loss = 0.71516884, grad/param norm = 1.3713e-01, time/batch = 0.6900s	
26238/33150 (epoch 39.575), train_loss = 0.80150505, grad/param norm = 1.7794e-01, time/batch = 0.6887s	
26239/33150 (epoch 39.576), train_loss = 0.72907916, grad/param norm = 1.4886e-01, time/batch = 0.6947s	
26240/33150 (epoch 39.578), train_loss = 0.77320807, grad/param norm = 1.7756e-01, time/batch = 0.6972s	
26241/33150 (epoch 39.579), train_loss = 0.72795912, grad/param norm = 1.8567e-01, time/batch = 0.7018s	
26242/33150 (epoch 39.581), train_loss = 0.74514527, grad/param norm = 1.7332e-01, time/batch = 0.7018s	
26243/33150 (epoch 39.582), train_loss = 0.96472706, grad/param norm = 1.6541e-01, time/batch = 0.7016s	
26244/33150 (epoch 39.584), train_loss = 0.91389518, grad/param norm = 1.8201e-01, time/batch = 0.7033s	
26245/33150 (epoch 39.585), train_loss = 0.83215788, grad/param norm = 1.6390e-01, time/batch = 0.7054s	
26246/33150 (epoch 39.587), train_loss = 0.83444795, grad/param norm = 1.7682e-01, time/batch = 0.6894s	
26247/33150 (epoch 39.588), train_loss = 0.77005060, grad/param norm = 1.6809e-01, time/batch = 0.6679s	
26248/33150 (epoch 39.590), train_loss = 0.86696461, grad/param norm = 1.7105e-01, time/batch = 0.6689s	
26249/33150 (epoch 39.591), train_loss = 0.84814353, grad/param norm = 1.8672e-01, time/batch = 0.6686s	
26250/33150 (epoch 39.593), train_loss = 0.89387008, grad/param norm = 1.9232e-01, time/batch = 0.6692s	
26251/33150 (epoch 39.594), train_loss = 0.79978244, grad/param norm = 1.6531e-01, time/batch = 0.6779s	
26252/33150 (epoch 39.596), train_loss = 0.79804563, grad/param norm = 1.8254e-01, time/batch = 0.6863s	
26253/33150 (epoch 39.597), train_loss = 0.73916035, grad/param norm = 2.2748e-01, time/batch = 0.6758s	
26254/33150 (epoch 39.599), train_loss = 0.98220953, grad/param norm = 2.0927e-01, time/batch = 0.6738s	
26255/33150 (epoch 39.600), train_loss = 0.83158843, grad/param norm = 2.1921e-01, time/batch = 0.6719s	
26256/33150 (epoch 39.602), train_loss = 0.83196578, grad/param norm = 1.8371e-01, time/batch = 0.6733s	
26257/33150 (epoch 39.603), train_loss = 0.94866563, grad/param norm = 1.6701e-01, time/batch = 0.6803s	
26258/33150 (epoch 39.605), train_loss = 0.74395529, grad/param norm = 1.6389e-01, time/batch = 0.6778s	
26259/33150 (epoch 39.606), train_loss = 0.79002354, grad/param norm = 2.0411e-01, time/batch = 0.6801s	
26260/33150 (epoch 39.608), train_loss = 0.92692540, grad/param norm = 1.5945e-01, time/batch = 0.6708s	
26261/33150 (epoch 39.609), train_loss = 0.83604672, grad/param norm = 2.1057e-01, time/batch = 0.6707s	
26262/33150 (epoch 39.611), train_loss = 0.75327916, grad/param norm = 1.6987e-01, time/batch = 0.6708s	
26263/33150 (epoch 39.612), train_loss = 0.81273920, grad/param norm = 1.8722e-01, time/batch = 0.6702s	
26264/33150 (epoch 39.614), train_loss = 0.76302205, grad/param norm = 1.6104e-01, time/batch = 0.6729s	
26265/33150 (epoch 39.615), train_loss = 0.74688624, grad/param norm = 1.9342e-01, time/batch = 0.6874s	
26266/33150 (epoch 39.617), train_loss = 0.86531395, grad/param norm = 2.2298e-01, time/batch = 0.6861s	
26267/33150 (epoch 39.618), train_loss = 0.87349326, grad/param norm = 1.8486e-01, time/batch = 0.6844s	
26268/33150 (epoch 39.620), train_loss = 0.82111680, grad/param norm = 2.0069e-01, time/batch = 0.6666s	
26269/33150 (epoch 39.621), train_loss = 0.86045678, grad/param norm = 1.7571e-01, time/batch = 0.6631s	
26270/33150 (epoch 39.623), train_loss = 0.89761796, grad/param norm = 1.8123e-01, time/batch = 0.6807s	
26271/33150 (epoch 39.624), train_loss = 0.80512806, grad/param norm = 1.8335e-01, time/batch = 0.6671s	
26272/33150 (epoch 39.626), train_loss = 0.83784411, grad/param norm = 1.7804e-01, time/batch = 0.6652s	
26273/33150 (epoch 39.627), train_loss = 0.82663278, grad/param norm = 2.2040e-01, time/batch = 0.6640s	
26274/33150 (epoch 39.629), train_loss = 0.71397914, grad/param norm = 1.7215e-01, time/batch = 0.6670s	
26275/33150 (epoch 39.630), train_loss = 0.82491490, grad/param norm = 1.7690e-01, time/batch = 0.6665s	
26276/33150 (epoch 39.632), train_loss = 0.72163107, grad/param norm = 1.3658e-01, time/batch = 0.6941s	
26277/33150 (epoch 39.633), train_loss = 0.76908493, grad/param norm = 1.9834e-01, time/batch = 0.6738s	
26278/33150 (epoch 39.635), train_loss = 0.98066731, grad/param norm = 1.8599e-01, time/batch = 0.6676s	
26279/33150 (epoch 39.637), train_loss = 0.68839363, grad/param norm = 1.7224e-01, time/batch = 0.6676s	
26280/33150 (epoch 39.638), train_loss = 0.81300548, grad/param norm = 1.6144e-01, time/batch = 0.6633s	
26281/33150 (epoch 39.640), train_loss = 0.90481085, grad/param norm = 2.0956e-01, time/batch = 0.6686s	
26282/33150 (epoch 39.641), train_loss = 0.70063545, grad/param norm = 1.8297e-01, time/batch = 0.6703s	
26283/33150 (epoch 39.643), train_loss = 0.84366766, grad/param norm = 1.6905e-01, time/batch = 0.6656s	
26284/33150 (epoch 39.644), train_loss = 0.97254708, grad/param norm = 1.6866e-01, time/batch = 0.6656s	
26285/33150 (epoch 39.646), train_loss = 0.82310186, grad/param norm = 1.5104e-01, time/batch = 0.6667s	
26286/33150 (epoch 39.647), train_loss = 1.00945184, grad/param norm = 1.7822e-01, time/batch = 0.6702s	
26287/33150 (epoch 39.649), train_loss = 0.88286114, grad/param norm = 2.5962e-01, time/batch = 0.6665s	
26288/33150 (epoch 39.650), train_loss = 0.74838404, grad/param norm = 1.5659e-01, time/batch = 0.6739s	
26289/33150 (epoch 39.652), train_loss = 0.92128805, grad/param norm = 1.9452e-01, time/batch = 0.6831s	
26290/33150 (epoch 39.653), train_loss = 0.91080389, grad/param norm = 1.8500e-01, time/batch = 0.6861s	
26291/33150 (epoch 39.655), train_loss = 0.88282639, grad/param norm = 2.2681e-01, time/batch = 0.6746s	
26292/33150 (epoch 39.656), train_loss = 0.79711005, grad/param norm = 1.6675e-01, time/batch = 0.6676s	
26293/33150 (epoch 39.658), train_loss = 0.81932669, grad/param norm = 2.0823e-01, time/batch = 0.6799s	
26294/33150 (epoch 39.659), train_loss = 1.07086711, grad/param norm = 3.4425e-01, time/batch = 0.6828s	
26295/33150 (epoch 39.661), train_loss = 0.82257309, grad/param norm = 1.8381e-01, time/batch = 0.6710s	
26296/33150 (epoch 39.662), train_loss = 0.80319784, grad/param norm = 1.7362e-01, time/batch = 0.6672s	
26297/33150 (epoch 39.664), train_loss = 0.94847064, grad/param norm = 2.0944e-01, time/batch = 0.6686s	
26298/33150 (epoch 39.665), train_loss = 0.92966007, grad/param norm = 2.3294e-01, time/batch = 0.6670s	
26299/33150 (epoch 39.667), train_loss = 0.91828262, grad/param norm = 2.3460e-01, time/batch = 0.6689s	
26300/33150 (epoch 39.668), train_loss = 0.98394838, grad/param norm = 1.9456e-01, time/batch = 0.6681s	
26301/33150 (epoch 39.670), train_loss = 0.79511838, grad/param norm = 1.6176e-01, time/batch = 0.6725s	
26302/33150 (epoch 39.671), train_loss = 0.78293709, grad/param norm = 2.1199e-01, time/batch = 0.6716s	
26303/33150 (epoch 39.673), train_loss = 0.95743098, grad/param norm = 1.6342e-01, time/batch = 0.6701s	
26304/33150 (epoch 39.674), train_loss = 0.90686627, grad/param norm = 2.0443e-01, time/batch = 0.6709s	
26305/33150 (epoch 39.676), train_loss = 0.83683523, grad/param norm = 1.6405e-01, time/batch = 0.6737s	
26306/33150 (epoch 39.677), train_loss = 0.96560599, grad/param norm = 1.9123e-01, time/batch = 0.6718s	
26307/33150 (epoch 39.679), train_loss = 0.82912442, grad/param norm = 1.5274e-01, time/batch = 0.6884s	
26308/33150 (epoch 39.680), train_loss = 0.93326604, grad/param norm = 2.0688e-01, time/batch = 0.6757s	
26309/33150 (epoch 39.682), train_loss = 0.85213059, grad/param norm = 1.8030e-01, time/batch = 0.6784s	
26310/33150 (epoch 39.683), train_loss = 0.71350074, grad/param norm = 1.5214e-01, time/batch = 0.6779s	
26311/33150 (epoch 39.685), train_loss = 0.80039668, grad/param norm = 1.9995e-01, time/batch = 0.6746s	
26312/33150 (epoch 39.686), train_loss = 0.71093770, grad/param norm = 1.5752e-01, time/batch = 0.6836s	
26313/33150 (epoch 39.688), train_loss = 0.72434663, grad/param norm = 1.7911e-01, time/batch = 0.6757s	
26314/33150 (epoch 39.689), train_loss = 0.76620622, grad/param norm = 1.6317e-01, time/batch = 0.6799s	
26315/33150 (epoch 39.691), train_loss = 0.65811852, grad/param norm = 1.4710e-01, time/batch = 0.6730s	
26316/33150 (epoch 39.692), train_loss = 0.74810022, grad/param norm = 1.6416e-01, time/batch = 0.6705s	
26317/33150 (epoch 39.694), train_loss = 0.68181075, grad/param norm = 1.8589e-01, time/batch = 0.6723s	
26318/33150 (epoch 39.695), train_loss = 0.77694718, grad/param norm = 1.6259e-01, time/batch = 0.6761s	
26319/33150 (epoch 39.697), train_loss = 0.72817937, grad/param norm = 1.4988e-01, time/batch = 0.6775s	
26320/33150 (epoch 39.698), train_loss = 0.74347583, grad/param norm = 1.7756e-01, time/batch = 0.6781s	
26321/33150 (epoch 39.700), train_loss = 0.64798181, grad/param norm = 1.4254e-01, time/batch = 0.6704s	
26322/33150 (epoch 39.701), train_loss = 0.71801165, grad/param norm = 1.5366e-01, time/batch = 0.6704s	
26323/33150 (epoch 39.703), train_loss = 0.82518575, grad/param norm = 1.6435e-01, time/batch = 0.6669s	
26324/33150 (epoch 39.704), train_loss = 0.70006287, grad/param norm = 1.4172e-01, time/batch = 0.6740s	
26325/33150 (epoch 39.706), train_loss = 0.77415374, grad/param norm = 1.7018e-01, time/batch = 0.6683s	
26326/33150 (epoch 39.707), train_loss = 0.80708919, grad/param norm = 1.7369e-01, time/batch = 0.6672s	
26327/33150 (epoch 39.709), train_loss = 0.83990378, grad/param norm = 1.6868e-01, time/batch = 0.6660s	
26328/33150 (epoch 39.710), train_loss = 0.84013535, grad/param norm = 1.9968e-01, time/batch = 0.6653s	
26329/33150 (epoch 39.712), train_loss = 0.90141246, grad/param norm = 1.7807e-01, time/batch = 0.6673s	
26330/33150 (epoch 39.713), train_loss = 0.86187989, grad/param norm = 1.5963e-01, time/batch = 0.6697s	
26331/33150 (epoch 39.715), train_loss = 0.80728608, grad/param norm = 1.5940e-01, time/batch = 0.6709s	
26332/33150 (epoch 39.716), train_loss = 0.87341774, grad/param norm = 1.8896e-01, time/batch = 0.6698s	
26333/33150 (epoch 39.718), train_loss = 0.84045109, grad/param norm = 1.6818e-01, time/batch = 0.6698s	
26334/33150 (epoch 39.719), train_loss = 0.90113000, grad/param norm = 2.0064e-01, time/batch = 0.6670s	
26335/33150 (epoch 39.721), train_loss = 0.80509990, grad/param norm = 1.9391e-01, time/batch = 0.6677s	
26336/33150 (epoch 39.722), train_loss = 0.86059539, grad/param norm = 1.6189e-01, time/batch = 0.6721s	
26337/33150 (epoch 39.724), train_loss = 0.80995641, grad/param norm = 1.8624e-01, time/batch = 0.6657s	
26338/33150 (epoch 39.725), train_loss = 0.88454182, grad/param norm = 2.0683e-01, time/batch = 0.6678s	
26339/33150 (epoch 39.727), train_loss = 0.88104322, grad/param norm = 2.0227e-01, time/batch = 0.6688s	
26340/33150 (epoch 39.729), train_loss = 0.85605930, grad/param norm = 2.2899e-01, time/batch = 0.6682s	
26341/33150 (epoch 39.730), train_loss = 0.84024350, grad/param norm = 1.6804e-01, time/batch = 0.6703s	
26342/33150 (epoch 39.732), train_loss = 0.89193513, grad/param norm = 2.4910e-01, time/batch = 0.6704s	
26343/33150 (epoch 39.733), train_loss = 0.72388589, grad/param norm = 1.3093e-01, time/batch = 0.6678s	
26344/33150 (epoch 39.735), train_loss = 0.76886369, grad/param norm = 1.7586e-01, time/batch = 0.6727s	
26345/33150 (epoch 39.736), train_loss = 0.77532918, grad/param norm = 1.6150e-01, time/batch = 0.6692s	
26346/33150 (epoch 39.738), train_loss = 0.84082912, grad/param norm = 2.0757e-01, time/batch = 0.6675s	
26347/33150 (epoch 39.739), train_loss = 0.95115583, grad/param norm = 2.2563e-01, time/batch = 0.6697s	
26348/33150 (epoch 39.741), train_loss = 0.84311061, grad/param norm = 1.8745e-01, time/batch = 0.6772s	
26349/33150 (epoch 39.742), train_loss = 0.70677063, grad/param norm = 1.7921e-01, time/batch = 0.6667s	
26350/33150 (epoch 39.744), train_loss = 0.89028941, grad/param norm = 1.8260e-01, time/batch = 0.6675s	
26351/33150 (epoch 39.745), train_loss = 0.76898372, grad/param norm = 1.5503e-01, time/batch = 0.6749s	
26352/33150 (epoch 39.747), train_loss = 0.62128274, grad/param norm = 1.6254e-01, time/batch = 0.6714s	
26353/33150 (epoch 39.748), train_loss = 0.70686580, grad/param norm = 1.8112e-01, time/batch = 0.6739s	
26354/33150 (epoch 39.750), train_loss = 0.85450829, grad/param norm = 1.8423e-01, time/batch = 0.6830s	
26355/33150 (epoch 39.751), train_loss = 0.80287185, grad/param norm = 1.5690e-01, time/batch = 0.6901s	
26356/33150 (epoch 39.753), train_loss = 0.71939559, grad/param norm = 1.9405e-01, time/batch = 0.6689s	
26357/33150 (epoch 39.754), train_loss = 1.01491267, grad/param norm = 2.2414e-01, time/batch = 0.6671s	
26358/33150 (epoch 39.756), train_loss = 0.82834314, grad/param norm = 2.2587e-01, time/batch = 0.6667s	
26359/33150 (epoch 39.757), train_loss = 0.86607683, grad/param norm = 1.7559e-01, time/batch = 0.6700s	
26360/33150 (epoch 39.759), train_loss = 0.96946199, grad/param norm = 2.4204e-01, time/batch = 0.6880s	
26361/33150 (epoch 39.760), train_loss = 0.88484762, grad/param norm = 1.9315e-01, time/batch = 0.6919s	
26362/33150 (epoch 39.762), train_loss = 0.83529879, grad/param norm = 2.0979e-01, time/batch = 0.6784s	
26363/33150 (epoch 39.763), train_loss = 0.86000277, grad/param norm = 1.7365e-01, time/batch = 0.6761s	
26364/33150 (epoch 39.765), train_loss = 0.83246657, grad/param norm = 1.8331e-01, time/batch = 0.6732s	
26365/33150 (epoch 39.766), train_loss = 0.70972913, grad/param norm = 1.6268e-01, time/batch = 0.6721s	
26366/33150 (epoch 39.768), train_loss = 0.75790779, grad/param norm = 1.6788e-01, time/batch = 0.6723s	
26367/33150 (epoch 39.769), train_loss = 0.90172221, grad/param norm = 1.7124e-01, time/batch = 0.6785s	
26368/33150 (epoch 39.771), train_loss = 0.84880541, grad/param norm = 1.7206e-01, time/batch = 0.6915s	
26369/33150 (epoch 39.772), train_loss = 0.88035509, grad/param norm = 1.9994e-01, time/batch = 0.6814s	
26370/33150 (epoch 39.774), train_loss = 0.97736893, grad/param norm = 1.9006e-01, time/batch = 0.6717s	
26371/33150 (epoch 39.775), train_loss = 0.88907259, grad/param norm = 2.1906e-01, time/batch = 0.6824s	
26372/33150 (epoch 39.777), train_loss = 0.88610201, grad/param norm = 1.9169e-01, time/batch = 0.6851s	
26373/33150 (epoch 39.778), train_loss = 0.81284524, grad/param norm = 1.6610e-01, time/batch = 0.6714s	
26374/33150 (epoch 39.780), train_loss = 0.71853304, grad/param norm = 1.6199e-01, time/batch = 0.6692s	
26375/33150 (epoch 39.781), train_loss = 0.81690312, grad/param norm = 1.6810e-01, time/batch = 0.6705s	
26376/33150 (epoch 39.783), train_loss = 0.82561888, grad/param norm = 1.5732e-01, time/batch = 0.6716s	
26377/33150 (epoch 39.784), train_loss = 0.83265467, grad/param norm = 1.8922e-01, time/batch = 0.6699s	
26378/33150 (epoch 39.786), train_loss = 0.84424294, grad/param norm = 1.7991e-01, time/batch = 0.6715s	
26379/33150 (epoch 39.787), train_loss = 0.75439004, grad/param norm = 1.5126e-01, time/batch = 0.6729s	
26380/33150 (epoch 39.789), train_loss = 0.70536655, grad/param norm = 1.5131e-01, time/batch = 0.6727s	
26381/33150 (epoch 39.790), train_loss = 0.71328796, grad/param norm = 1.6471e-01, time/batch = 0.6774s	
26382/33150 (epoch 39.792), train_loss = 0.82884157, grad/param norm = 1.8682e-01, time/batch = 0.6805s	
26383/33150 (epoch 39.793), train_loss = 0.79959763, grad/param norm = 2.1317e-01, time/batch = 0.6775s	
26384/33150 (epoch 39.795), train_loss = 0.78070406, grad/param norm = 1.9629e-01, time/batch = 0.6731s	
26385/33150 (epoch 39.796), train_loss = 0.79838419, grad/param norm = 1.6255e-01, time/batch = 0.6661s	
26386/33150 (epoch 39.798), train_loss = 0.75722287, grad/param norm = 1.5068e-01, time/batch = 0.6701s	
26387/33150 (epoch 39.799), train_loss = 0.69248330, grad/param norm = 2.0634e-01, time/batch = 0.6694s	
26388/33150 (epoch 39.801), train_loss = 0.84726689, grad/param norm = 1.8379e-01, time/batch = 0.6681s	
26389/33150 (epoch 39.802), train_loss = 0.77981478, grad/param norm = 1.4887e-01, time/batch = 0.6700s	
26390/33150 (epoch 39.804), train_loss = 0.78680831, grad/param norm = 1.7505e-01, time/batch = 0.6943s	
26391/33150 (epoch 39.805), train_loss = 0.77650195, grad/param norm = 1.9394e-01, time/batch = 0.6907s	
26392/33150 (epoch 39.807), train_loss = 0.80949635, grad/param norm = 1.5831e-01, time/batch = 0.6856s	
26393/33150 (epoch 39.808), train_loss = 0.91187093, grad/param norm = 1.9014e-01, time/batch = 0.6821s	
26394/33150 (epoch 39.810), train_loss = 0.75120718, grad/param norm = 1.7680e-01, time/batch = 0.6900s	
26395/33150 (epoch 39.811), train_loss = 0.83913277, grad/param norm = 2.0685e-01, time/batch = 0.6880s	
26396/33150 (epoch 39.813), train_loss = 0.79215363, grad/param norm = 1.6123e-01, time/batch = 0.6768s	
26397/33150 (epoch 39.814), train_loss = 0.77903329, grad/param norm = 2.1552e-01, time/batch = 0.6798s	
26398/33150 (epoch 39.816), train_loss = 0.79975186, grad/param norm = 2.0035e-01, time/batch = 0.6775s	
26399/33150 (epoch 39.817), train_loss = 0.87785901, grad/param norm = 1.7141e-01, time/batch = 0.6831s	
26400/33150 (epoch 39.819), train_loss = 0.83711011, grad/param norm = 1.7869e-01, time/batch = 0.6836s	
26401/33150 (epoch 39.821), train_loss = 0.73818093, grad/param norm = 1.4735e-01, time/batch = 0.6859s	
26402/33150 (epoch 39.822), train_loss = 0.77561227, grad/param norm = 1.6881e-01, time/batch = 0.6765s	
26403/33150 (epoch 39.824), train_loss = 0.82930646, grad/param norm = 1.8573e-01, time/batch = 0.6673s	
26404/33150 (epoch 39.825), train_loss = 0.85651259, grad/param norm = 1.8000e-01, time/batch = 0.6661s	
26405/33150 (epoch 39.827), train_loss = 0.89059441, grad/param norm = 2.2094e-01, time/batch = 0.6657s	
26406/33150 (epoch 39.828), train_loss = 0.74462599, grad/param norm = 1.7129e-01, time/batch = 0.6699s	
26407/33150 (epoch 39.830), train_loss = 0.88524740, grad/param norm = 1.9465e-01, time/batch = 0.6748s	
26408/33150 (epoch 39.831), train_loss = 0.76109543, grad/param norm = 1.6683e-01, time/batch = 0.6664s	
26409/33150 (epoch 39.833), train_loss = 0.74172364, grad/param norm = 1.7306e-01, time/batch = 0.6663s	
26410/33150 (epoch 39.834), train_loss = 0.90107823, grad/param norm = 1.5982e-01, time/batch = 0.6688s	
26411/33150 (epoch 39.836), train_loss = 0.92582644, grad/param norm = 1.6315e-01, time/batch = 0.6674s	
26412/33150 (epoch 39.837), train_loss = 0.76501000, grad/param norm = 1.8511e-01, time/batch = 0.6662s	
26413/33150 (epoch 39.839), train_loss = 0.90385366, grad/param norm = 2.4210e-01, time/batch = 0.6678s	
26414/33150 (epoch 39.840), train_loss = 0.87436612, grad/param norm = 1.7916e-01, time/batch = 0.6701s	
26415/33150 (epoch 39.842), train_loss = 0.90423925, grad/param norm = 2.4218e-01, time/batch = 0.6752s	
26416/33150 (epoch 39.843), train_loss = 0.92655697, grad/param norm = 2.0531e-01, time/batch = 0.6891s	
26417/33150 (epoch 39.845), train_loss = 0.76961774, grad/param norm = 1.6606e-01, time/batch = 0.6715s	
26418/33150 (epoch 39.846), train_loss = 0.99869318, grad/param norm = 2.9606e-01, time/batch = 0.6660s	
26419/33150 (epoch 39.848), train_loss = 0.91280672, grad/param norm = 2.1024e-01, time/batch = 0.6699s	
26420/33150 (epoch 39.849), train_loss = 0.90899710, grad/param norm = 1.6782e-01, time/batch = 0.6664s	
26421/33150 (epoch 39.851), train_loss = 0.87981014, grad/param norm = 1.8812e-01, time/batch = 0.6662s	
26422/33150 (epoch 39.852), train_loss = 0.95244718, grad/param norm = 1.7676e-01, time/batch = 0.6681s	
26423/33150 (epoch 39.854), train_loss = 0.87788155, grad/param norm = 2.0236e-01, time/batch = 0.6664s	
26424/33150 (epoch 39.855), train_loss = 0.76394781, grad/param norm = 2.1157e-01, time/batch = 0.6674s	
26425/33150 (epoch 39.857), train_loss = 0.70134267, grad/param norm = 2.3384e-01, time/batch = 0.6756s	
26426/33150 (epoch 39.858), train_loss = 0.79528889, grad/param norm = 1.6712e-01, time/batch = 0.6705s	
26427/33150 (epoch 39.860), train_loss = 0.75383059, grad/param norm = 1.6213e-01, time/batch = 0.6647s	
26428/33150 (epoch 39.861), train_loss = 0.74271253, grad/param norm = 1.8186e-01, time/batch = 0.6684s	
26429/33150 (epoch 39.863), train_loss = 0.81056697, grad/param norm = 1.6782e-01, time/batch = 0.6699s	
26430/33150 (epoch 39.864), train_loss = 0.85694101, grad/param norm = 1.8348e-01, time/batch = 0.6745s	
26431/33150 (epoch 39.866), train_loss = 0.90334369, grad/param norm = 1.8778e-01, time/batch = 0.6902s	
26432/33150 (epoch 39.867), train_loss = 0.83350825, grad/param norm = 1.7544e-01, time/batch = 0.6687s	
26433/33150 (epoch 39.869), train_loss = 0.83997622, grad/param norm = 2.0030e-01, time/batch = 0.6677s	
26434/33150 (epoch 39.870), train_loss = 0.79962307, grad/param norm = 1.9491e-01, time/batch = 0.6674s	
26435/33150 (epoch 39.872), train_loss = 0.89158307, grad/param norm = 2.0828e-01, time/batch = 0.6827s	
26436/33150 (epoch 39.873), train_loss = 0.67665812, grad/param norm = 1.5658e-01, time/batch = 0.6683s	
26437/33150 (epoch 39.875), train_loss = 0.91849433, grad/param norm = 1.8588e-01, time/batch = 0.6660s	
26438/33150 (epoch 39.876), train_loss = 0.67838716, grad/param norm = 1.5689e-01, time/batch = 0.6646s	
26439/33150 (epoch 39.878), train_loss = 0.76653701, grad/param norm = 1.6170e-01, time/batch = 0.6627s	
26440/33150 (epoch 39.879), train_loss = 0.75798076, grad/param norm = 1.5487e-01, time/batch = 0.6641s	
26441/33150 (epoch 39.881), train_loss = 0.75956897, grad/param norm = 1.7230e-01, time/batch = 0.6650s	
26442/33150 (epoch 39.882), train_loss = 0.64808360, grad/param norm = 1.5816e-01, time/batch = 0.6808s	
26443/33150 (epoch 39.884), train_loss = 0.77741812, grad/param norm = 1.7120e-01, time/batch = 0.6868s	
26444/33150 (epoch 39.885), train_loss = 0.61934591, grad/param norm = 1.6817e-01, time/batch = 0.6878s	
26445/33150 (epoch 39.887), train_loss = 0.90375990, grad/param norm = 1.7989e-01, time/batch = 0.6868s	
26446/33150 (epoch 39.888), train_loss = 0.82724088, grad/param norm = 1.7441e-01, time/batch = 0.6819s	
26447/33150 (epoch 39.890), train_loss = 0.72873010, grad/param norm = 1.7957e-01, time/batch = 0.6675s	
26448/33150 (epoch 39.891), train_loss = 0.73835230, grad/param norm = 1.8910e-01, time/batch = 0.6670s	
26449/33150 (epoch 39.893), train_loss = 0.86579988, grad/param norm = 1.8759e-01, time/batch = 0.6656s	
26450/33150 (epoch 39.894), train_loss = 0.85661920, grad/param norm = 1.6371e-01, time/batch = 0.6675s	
26451/33150 (epoch 39.896), train_loss = 0.80098871, grad/param norm = 1.5539e-01, time/batch = 0.6944s	
26452/33150 (epoch 39.897), train_loss = 0.86192829, grad/param norm = 1.6343e-01, time/batch = 0.6883s	
26453/33150 (epoch 39.899), train_loss = 0.67441900, grad/param norm = 1.8139e-01, time/batch = 0.6705s	
26454/33150 (epoch 39.900), train_loss = 0.97138842, grad/param norm = 1.8823e-01, time/batch = 0.6721s	
26455/33150 (epoch 39.902), train_loss = 1.03946701, grad/param norm = 1.8526e-01, time/batch = 0.6714s	
26456/33150 (epoch 39.903), train_loss = 0.84894959, grad/param norm = 1.7499e-01, time/batch = 0.6661s	
26457/33150 (epoch 39.905), train_loss = 0.82487941, grad/param norm = 1.6543e-01, time/batch = 0.6629s	
26458/33150 (epoch 39.906), train_loss = 0.83909091, grad/param norm = 1.8984e-01, time/batch = 0.6681s	
26459/33150 (epoch 39.908), train_loss = 0.88340555, grad/param norm = 1.7721e-01, time/batch = 0.6725s	
26460/33150 (epoch 39.910), train_loss = 0.90452584, grad/param norm = 1.7467e-01, time/batch = 0.6859s	
26461/33150 (epoch 39.911), train_loss = 0.70753437, grad/param norm = 1.5653e-01, time/batch = 0.6881s	
26462/33150 (epoch 39.913), train_loss = 0.78002142, grad/param norm = 1.8522e-01, time/batch = 0.6894s	
26463/33150 (epoch 39.914), train_loss = 0.82303904, grad/param norm = 1.6329e-01, time/batch = 0.6849s	
26464/33150 (epoch 39.916), train_loss = 0.76538504, grad/param norm = 1.6178e-01, time/batch = 0.6888s	
26465/33150 (epoch 39.917), train_loss = 0.86195478, grad/param norm = 2.2234e-01, time/batch = 0.6891s	
26466/33150 (epoch 39.919), train_loss = 0.95595743, grad/param norm = 2.2845e-01, time/batch = 0.6883s	
26467/33150 (epoch 39.920), train_loss = 0.92076190, grad/param norm = 1.9216e-01, time/batch = 0.6864s	
26468/33150 (epoch 39.922), train_loss = 0.95951526, grad/param norm = 2.2361e-01, time/batch = 0.6867s	
26469/33150 (epoch 39.923), train_loss = 0.84227071, grad/param norm = 1.8090e-01, time/batch = 0.6864s	
26470/33150 (epoch 39.925), train_loss = 0.91964060, grad/param norm = 1.7494e-01, time/batch = 0.6867s	
26471/33150 (epoch 39.926), train_loss = 0.81204326, grad/param norm = 1.6311e-01, time/batch = 0.6711s	
26472/33150 (epoch 39.928), train_loss = 0.80236771, grad/param norm = 1.9838e-01, time/batch = 0.6755s	
26473/33150 (epoch 39.929), train_loss = 0.87553096, grad/param norm = 1.7598e-01, time/batch = 0.6788s	
26474/33150 (epoch 39.931), train_loss = 0.93361650, grad/param norm = 1.9265e-01, time/batch = 0.6669s	
26475/33150 (epoch 39.932), train_loss = 0.85022173, grad/param norm = 2.0755e-01, time/batch = 0.6708s	
26476/33150 (epoch 39.934), train_loss = 0.84852587, grad/param norm = 1.5852e-01, time/batch = 0.6745s	
26477/33150 (epoch 39.935), train_loss = 0.91873965, grad/param norm = 1.8166e-01, time/batch = 0.6761s	
26478/33150 (epoch 39.937), train_loss = 0.94365959, grad/param norm = 1.7170e-01, time/batch = 0.6682s	
26479/33150 (epoch 39.938), train_loss = 0.85000410, grad/param norm = 1.6029e-01, time/batch = 0.6744s	
26480/33150 (epoch 39.940), train_loss = 1.05779373, grad/param norm = 2.3413e-01, time/batch = 0.6838s	
26481/33150 (epoch 39.941), train_loss = 0.87048298, grad/param norm = 1.5660e-01, time/batch = 0.6732s	
26482/33150 (epoch 39.943), train_loss = 0.68363914, grad/param norm = 1.6864e-01, time/batch = 0.6783s	
26483/33150 (epoch 39.944), train_loss = 0.88439041, grad/param norm = 1.9530e-01, time/batch = 0.6722s	
26484/33150 (epoch 39.946), train_loss = 0.73774224, grad/param norm = 1.5004e-01, time/batch = 0.6724s	
26485/33150 (epoch 39.947), train_loss = 0.85585063, grad/param norm = 1.6333e-01, time/batch = 0.6888s	
26486/33150 (epoch 39.949), train_loss = 0.92528588, grad/param norm = 1.7722e-01, time/batch = 0.6776s	
26487/33150 (epoch 39.950), train_loss = 0.91010548, grad/param norm = 1.8049e-01, time/batch = 0.6725s	
26488/33150 (epoch 39.952), train_loss = 0.77472631, grad/param norm = 1.7846e-01, time/batch = 0.6717s	
26489/33150 (epoch 39.953), train_loss = 0.82638060, grad/param norm = 1.5891e-01, time/batch = 0.6729s	
26490/33150 (epoch 39.955), train_loss = 0.71358019, grad/param norm = 1.7942e-01, time/batch = 0.6705s	
26491/33150 (epoch 39.956), train_loss = 0.90196101, grad/param norm = 2.0736e-01, time/batch = 0.6739s	
26492/33150 (epoch 39.958), train_loss = 0.73900535, grad/param norm = 1.5996e-01, time/batch = 0.6779s	
26493/33150 (epoch 39.959), train_loss = 0.81499525, grad/param norm = 1.6540e-01, time/batch = 0.6695s	
26494/33150 (epoch 39.961), train_loss = 0.74783485, grad/param norm = 1.6749e-01, time/batch = 0.6696s	
26495/33150 (epoch 39.962), train_loss = 0.70216245, grad/param norm = 1.5199e-01, time/batch = 0.6784s	
26496/33150 (epoch 39.964), train_loss = 0.80495736, grad/param norm = 1.7336e-01, time/batch = 0.6759s	
26497/33150 (epoch 39.965), train_loss = 0.80083774, grad/param norm = 1.7019e-01, time/batch = 0.6738s	
26498/33150 (epoch 39.967), train_loss = 0.80730907, grad/param norm = 1.8933e-01, time/batch = 0.6743s	
26499/33150 (epoch 39.968), train_loss = 0.69279308, grad/param norm = 1.4339e-01, time/batch = 0.6792s	
26500/33150 (epoch 39.970), train_loss = 0.78693887, grad/param norm = 1.7414e-01, time/batch = 0.6907s	
26501/33150 (epoch 39.971), train_loss = 0.81611544, grad/param norm = 1.6628e-01, time/batch = 0.6816s	
26502/33150 (epoch 39.973), train_loss = 0.88798644, grad/param norm = 1.6964e-01, time/batch = 0.6776s	
26503/33150 (epoch 39.974), train_loss = 0.96005398, grad/param norm = 2.4597e-01, time/batch = 0.6865s	
26504/33150 (epoch 39.976), train_loss = 0.92453589, grad/param norm = 1.8997e-01, time/batch = 0.6819s	
26505/33150 (epoch 39.977), train_loss = 0.94086678, grad/param norm = 1.8523e-01, time/batch = 0.6759s	
26506/33150 (epoch 39.979), train_loss = 0.91922738, grad/param norm = 1.9926e-01, time/batch = 0.6823s	
26507/33150 (epoch 39.980), train_loss = 0.98235851, grad/param norm = 2.0785e-01, time/batch = 0.6706s	
26508/33150 (epoch 39.982), train_loss = 0.83937189, grad/param norm = 2.5243e-01, time/batch = 0.6684s	
26509/33150 (epoch 39.983), train_loss = 0.75502666, grad/param norm = 1.7833e-01, time/batch = 0.6704s	
26510/33150 (epoch 39.985), train_loss = 0.93897636, grad/param norm = 1.8570e-01, time/batch = 0.6696s	
26511/33150 (epoch 39.986), train_loss = 0.69744228, grad/param norm = 1.5030e-01, time/batch = 0.6702s	
26512/33150 (epoch 39.988), train_loss = 0.80359893, grad/param norm = 2.7355e-01, time/batch = 0.6725s	
26513/33150 (epoch 39.989), train_loss = 0.82777538, grad/param norm = 1.9032e-01, time/batch = 0.6707s	
26514/33150 (epoch 39.991), train_loss = 0.88246841, grad/param norm = 2.8311e-01, time/batch = 0.6726s	
26515/33150 (epoch 39.992), train_loss = 0.83460582, grad/param norm = 1.7090e-01, time/batch = 0.6720s	
26516/33150 (epoch 39.994), train_loss = 0.85566145, grad/param norm = 1.7394e-01, time/batch = 0.6876s	
26517/33150 (epoch 39.995), train_loss = 0.80397489, grad/param norm = 1.8294e-01, time/batch = 0.6863s	
26518/33150 (epoch 39.997), train_loss = 0.85012520, grad/param norm = 2.2036e-01, time/batch = 0.6891s	
26519/33150 (epoch 39.998), train_loss = 0.71408698, grad/param norm = 1.6503e-01, time/batch = 0.6808s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
26520/33150 (epoch 40.000), train_loss = 0.74086226, grad/param norm = 2.0717e-01, time/batch = 0.6960s	
26521/33150 (epoch 40.002), train_loss = 1.13076752, grad/param norm = 2.0735e-01, time/batch = 0.6759s	
26522/33150 (epoch 40.003), train_loss = 0.75790889, grad/param norm = 1.7073e-01, time/batch = 0.6688s	
26523/33150 (epoch 40.005), train_loss = 0.71829322, grad/param norm = 1.6688e-01, time/batch = 0.6694s	
26524/33150 (epoch 40.006), train_loss = 0.69811166, grad/param norm = 1.6850e-01, time/batch = 0.6702s	
26525/33150 (epoch 40.008), train_loss = 0.89047073, grad/param norm = 2.1927e-01, time/batch = 0.6741s	
26526/33150 (epoch 40.009), train_loss = 0.85516973, grad/param norm = 1.6569e-01, time/batch = 0.6734s	
26527/33150 (epoch 40.011), train_loss = 0.92817588, grad/param norm = 1.7578e-01, time/batch = 0.6693s	
26528/33150 (epoch 40.012), train_loss = 0.81644238, grad/param norm = 3.1928e-01, time/batch = 0.6701s	
26529/33150 (epoch 40.014), train_loss = 0.75629552, grad/param norm = 2.1225e-01, time/batch = 0.6874s	
26530/33150 (epoch 40.015), train_loss = 0.74639502, grad/param norm = 1.8079e-01, time/batch = 0.6868s	
26531/33150 (epoch 40.017), train_loss = 0.75562614, grad/param norm = 1.7697e-01, time/batch = 0.6888s	
26532/33150 (epoch 40.018), train_loss = 0.83982334, grad/param norm = 1.8664e-01, time/batch = 0.6876s	
26533/33150 (epoch 40.020), train_loss = 0.90374616, grad/param norm = 2.1213e-01, time/batch = 0.7032s	
26534/33150 (epoch 40.021), train_loss = 0.73184107, grad/param norm = 1.6750e-01, time/batch = 0.6867s	
26535/33150 (epoch 40.023), train_loss = 1.02422021, grad/param norm = 1.9255e-01, time/batch = 0.6791s	
26536/33150 (epoch 40.024), train_loss = 0.87385621, grad/param norm = 1.9673e-01, time/batch = 0.6824s	
26537/33150 (epoch 40.026), train_loss = 0.65054266, grad/param norm = 1.5043e-01, time/batch = 0.6689s	
26538/33150 (epoch 40.027), train_loss = 0.67572739, grad/param norm = 1.5760e-01, time/batch = 0.6681s	
26539/33150 (epoch 40.029), train_loss = 0.75209939, grad/param norm = 1.9053e-01, time/batch = 0.6750s	
26540/33150 (epoch 40.030), train_loss = 0.80707315, grad/param norm = 1.4505e-01, time/batch = 0.6782s	
26541/33150 (epoch 40.032), train_loss = 0.74012121, grad/param norm = 1.9074e-01, time/batch = 0.6774s	
26542/33150 (epoch 40.033), train_loss = 0.75100337, grad/param norm = 1.6690e-01, time/batch = 0.6723s	
26543/33150 (epoch 40.035), train_loss = 0.99752070, grad/param norm = 2.0029e-01, time/batch = 0.6735s	
26544/33150 (epoch 40.036), train_loss = 0.90750051, grad/param norm = 2.0572e-01, time/batch = 0.6710s	
26545/33150 (epoch 40.038), train_loss = 1.01002535, grad/param norm = 1.9765e-01, time/batch = 0.6795s	
26546/33150 (epoch 40.039), train_loss = 0.90029650, grad/param norm = 1.8661e-01, time/batch = 0.6773s	
26547/33150 (epoch 40.041), train_loss = 0.82368241, grad/param norm = 1.6813e-01, time/batch = 0.6720s	
26548/33150 (epoch 40.042), train_loss = 0.76459495, grad/param norm = 1.8661e-01, time/batch = 0.6800s	
26549/33150 (epoch 40.044), train_loss = 0.82848380, grad/param norm = 1.8759e-01, time/batch = 0.6713s	
26550/33150 (epoch 40.045), train_loss = 0.88715133, grad/param norm = 1.5716e-01, time/batch = 0.6786s	
26551/33150 (epoch 40.047), train_loss = 0.74932266, grad/param norm = 1.5841e-01, time/batch = 0.6943s	
26552/33150 (epoch 40.048), train_loss = 0.91217374, grad/param norm = 2.1092e-01, time/batch = 0.6758s	
26553/33150 (epoch 40.050), train_loss = 0.80446996, grad/param norm = 1.8323e-01, time/batch = 0.6705s	
26554/33150 (epoch 40.051), train_loss = 0.84980333, grad/param norm = 1.7016e-01, time/batch = 0.6707s	
26555/33150 (epoch 40.053), train_loss = 0.88308288, grad/param norm = 2.4352e-01, time/batch = 0.6731s	
26556/33150 (epoch 40.054), train_loss = 0.97051618, grad/param norm = 1.7200e-01, time/batch = 0.6716s	
26557/33150 (epoch 40.056), train_loss = 0.81573879, grad/param norm = 1.8889e-01, time/batch = 0.6681s	
26558/33150 (epoch 40.057), train_loss = 0.88690389, grad/param norm = 1.5852e-01, time/batch = 0.6693s	
26559/33150 (epoch 40.059), train_loss = 0.75263318, grad/param norm = 1.7984e-01, time/batch = 0.6702s	
26560/33150 (epoch 40.060), train_loss = 0.72764847, grad/param norm = 1.5044e-01, time/batch = 0.6710s	
26561/33150 (epoch 40.062), train_loss = 0.81237489, grad/param norm = 1.8717e-01, time/batch = 0.6726s	
26562/33150 (epoch 40.063), train_loss = 0.76907361, grad/param norm = 2.0747e-01, time/batch = 0.6705s	
26563/33150 (epoch 40.065), train_loss = 0.80642114, grad/param norm = 1.5884e-01, time/batch = 0.6769s	
26564/33150 (epoch 40.066), train_loss = 0.80628777, grad/param norm = 1.7684e-01, time/batch = 0.6687s	
26565/33150 (epoch 40.068), train_loss = 0.86738758, grad/param norm = 1.7819e-01, time/batch = 0.6694s	
26566/33150 (epoch 40.069), train_loss = 0.87260601, grad/param norm = 2.1056e-01, time/batch = 0.6711s	
26567/33150 (epoch 40.071), train_loss = 0.85242529, grad/param norm = 1.7475e-01, time/batch = 0.6666s	
26568/33150 (epoch 40.072), train_loss = 0.85185935, grad/param norm = 1.9691e-01, time/batch = 0.6682s	
26569/33150 (epoch 40.074), train_loss = 0.71386323, grad/param norm = 1.9079e-01, time/batch = 0.6882s	
26570/33150 (epoch 40.075), train_loss = 0.72633581, grad/param norm = 1.6350e-01, time/batch = 0.6793s	
26571/33150 (epoch 40.077), train_loss = 0.85150287, grad/param norm = 2.9805e-01, time/batch = 0.6728s	
26572/33150 (epoch 40.078), train_loss = 0.96724969, grad/param norm = 2.1924e-01, time/batch = 0.6710s	
26573/33150 (epoch 40.080), train_loss = 0.95481622, grad/param norm = 1.8918e-01, time/batch = 0.6688s	
26574/33150 (epoch 40.081), train_loss = 0.73385354, grad/param norm = 1.9319e-01, time/batch = 0.6707s	
26575/33150 (epoch 40.083), train_loss = 0.61202860, grad/param norm = 2.1407e-01, time/batch = 0.6761s	
26576/33150 (epoch 40.084), train_loss = 0.68399794, grad/param norm = 1.8074e-01, time/batch = 0.6772s	
26577/33150 (epoch 40.086), train_loss = 0.76167733, grad/param norm = 1.9852e-01, time/batch = 0.6757s	
26578/33150 (epoch 40.087), train_loss = 0.71344906, grad/param norm = 1.9130e-01, time/batch = 0.6707s	
26579/33150 (epoch 40.089), train_loss = 0.78080185, grad/param norm = 1.9022e-01, time/batch = 0.6767s	
26580/33150 (epoch 40.090), train_loss = 0.80344286, grad/param norm = 1.9158e-01, time/batch = 0.6730s	
26581/33150 (epoch 40.092), train_loss = 0.77948188, grad/param norm = 1.9707e-01, time/batch = 0.6740s	
26582/33150 (epoch 40.094), train_loss = 0.86885249, grad/param norm = 2.4300e-01, time/batch = 0.6727s	
26583/33150 (epoch 40.095), train_loss = 0.75099903, grad/param norm = 1.8154e-01, time/batch = 0.6774s	
26584/33150 (epoch 40.097), train_loss = 0.69433243, grad/param norm = 1.5872e-01, time/batch = 0.6861s	
26585/33150 (epoch 40.098), train_loss = 1.04181589, grad/param norm = 2.0470e-01, time/batch = 0.6715s	
26586/33150 (epoch 40.100), train_loss = 1.01397074, grad/param norm = 2.0172e-01, time/batch = 0.6747s	
26587/33150 (epoch 40.101), train_loss = 0.78112423, grad/param norm = 1.9758e-01, time/batch = 0.6753s	
26588/33150 (epoch 40.103), train_loss = 0.82863148, grad/param norm = 1.6333e-01, time/batch = 0.6686s	
26589/33150 (epoch 40.104), train_loss = 0.78122936, grad/param norm = 2.2271e-01, time/batch = 0.6694s	
26590/33150 (epoch 40.106), train_loss = 0.93024815, grad/param norm = 1.6984e-01, time/batch = 0.6720s	
26591/33150 (epoch 40.107), train_loss = 1.01667843, grad/param norm = 2.2682e-01, time/batch = 0.6928s	
26592/33150 (epoch 40.109), train_loss = 0.81669523, grad/param norm = 1.6206e-01, time/batch = 0.6801s	
26593/33150 (epoch 40.110), train_loss = 0.92165014, grad/param norm = 2.0254e-01, time/batch = 0.6723s	
26594/33150 (epoch 40.112), train_loss = 0.75115307, grad/param norm = 1.7876e-01, time/batch = 0.6756s	
26595/33150 (epoch 40.113), train_loss = 0.78856752, grad/param norm = 1.6897e-01, time/batch = 0.6722s	
26596/33150 (epoch 40.115), train_loss = 0.99608658, grad/param norm = 2.0550e-01, time/batch = 0.6737s	
26597/33150 (epoch 40.116), train_loss = 0.89417874, grad/param norm = 2.0801e-01, time/batch = 0.6722s	
26598/33150 (epoch 40.118), train_loss = 0.86785293, grad/param norm = 2.1512e-01, time/batch = 0.6811s	
26599/33150 (epoch 40.119), train_loss = 0.88035052, grad/param norm = 2.4687e-01, time/batch = 0.6877s	
26600/33150 (epoch 40.121), train_loss = 0.81479862, grad/param norm = 1.7288e-01, time/batch = 0.6735s	
26601/33150 (epoch 40.122), train_loss = 0.97384345, grad/param norm = 2.6660e-01, time/batch = 0.6716s	
26602/33150 (epoch 40.124), train_loss = 0.70073186, grad/param norm = 1.5197e-01, time/batch = 0.6748s	
26603/33150 (epoch 40.125), train_loss = 0.94878109, grad/param norm = 1.8387e-01, time/batch = 0.6720s	
26604/33150 (epoch 40.127), train_loss = 0.85552313, grad/param norm = 1.8053e-01, time/batch = 0.6712s	
26605/33150 (epoch 40.128), train_loss = 0.87990846, grad/param norm = 2.0818e-01, time/batch = 0.6738s	
26606/33150 (epoch 40.130), train_loss = 0.82228458, grad/param norm = 1.7821e-01, time/batch = 0.6737s	
26607/33150 (epoch 40.131), train_loss = 1.01402864, grad/param norm = 1.9146e-01, time/batch = 0.6722s	
26608/33150 (epoch 40.133), train_loss = 0.78552204, grad/param norm = 1.7611e-01, time/batch = 0.6731s	
26609/33150 (epoch 40.134), train_loss = 0.95501034, grad/param norm = 1.8448e-01, time/batch = 0.6729s	
26610/33150 (epoch 40.136), train_loss = 0.84297963, grad/param norm = 1.9349e-01, time/batch = 0.6775s	
26611/33150 (epoch 40.137), train_loss = 0.90011152, grad/param norm = 1.6570e-01, time/batch = 0.6730s	
26612/33150 (epoch 40.139), train_loss = 0.91335807, grad/param norm = 2.4146e-01, time/batch = 0.6719s	
26613/33150 (epoch 40.140), train_loss = 1.00117921, grad/param norm = 2.0458e-01, time/batch = 0.6783s	
26614/33150 (epoch 40.142), train_loss = 0.89095512, grad/param norm = 1.9627e-01, time/batch = 0.6772s	
26615/33150 (epoch 40.143), train_loss = 0.85937504, grad/param norm = 2.4972e-01, time/batch = 0.6727s	
26616/33150 (epoch 40.145), train_loss = 0.78489278, grad/param norm = 1.8246e-01, time/batch = 0.6725s	
26617/33150 (epoch 40.146), train_loss = 0.92449336, grad/param norm = 2.0619e-01, time/batch = 0.6734s	
26618/33150 (epoch 40.148), train_loss = 0.97702648, grad/param norm = 1.7640e-01, time/batch = 0.6756s	
26619/33150 (epoch 40.149), train_loss = 0.86301577, grad/param norm = 1.8408e-01, time/batch = 0.6872s	
26620/33150 (epoch 40.151), train_loss = 1.00060956, grad/param norm = 2.0819e-01, time/batch = 0.6973s	
26621/33150 (epoch 40.152), train_loss = 0.77404124, grad/param norm = 1.5892e-01, time/batch = 0.6971s	
26622/33150 (epoch 40.154), train_loss = 0.77882865, grad/param norm = 1.6317e-01, time/batch = 0.6891s	
26623/33150 (epoch 40.155), train_loss = 0.73418100, grad/param norm = 1.7956e-01, time/batch = 0.6852s	
26624/33150 (epoch 40.157), train_loss = 0.82016904, grad/param norm = 2.0542e-01, time/batch = 0.7895s	
26625/33150 (epoch 40.158), train_loss = 0.81853069, grad/param norm = 1.6530e-01, time/batch = 1.0116s	
26626/33150 (epoch 40.160), train_loss = 0.91122254, grad/param norm = 1.8450e-01, time/batch = 0.9977s	
26627/33150 (epoch 40.161), train_loss = 0.81554672, grad/param norm = 2.1812e-01, time/batch = 0.9867s	
26628/33150 (epoch 40.163), train_loss = 0.72900520, grad/param norm = 1.5709e-01, time/batch = 0.9879s	
26629/33150 (epoch 40.164), train_loss = 0.87465157, grad/param norm = 1.7575e-01, time/batch = 0.8952s	
26630/33150 (epoch 40.166), train_loss = 0.79996902, grad/param norm = 1.6220e-01, time/batch = 0.6818s	
26631/33150 (epoch 40.167), train_loss = 0.86542273, grad/param norm = 1.5780e-01, time/batch = 0.6706s	
26632/33150 (epoch 40.169), train_loss = 0.84559335, grad/param norm = 2.1015e-01, time/batch = 0.6810s	
26633/33150 (epoch 40.170), train_loss = 0.75770180, grad/param norm = 2.1364e-01, time/batch = 0.6703s	
26634/33150 (epoch 40.172), train_loss = 0.89586009, grad/param norm = 2.4690e-01, time/batch = 0.6690s	
26635/33150 (epoch 40.173), train_loss = 0.86029981, grad/param norm = 1.9616e-01, time/batch = 0.6731s	
26636/33150 (epoch 40.175), train_loss = 0.81864540, grad/param norm = 2.0843e-01, time/batch = 0.6663s	
26637/33150 (epoch 40.176), train_loss = 0.87908719, grad/param norm = 1.8142e-01, time/batch = 0.6716s	
26638/33150 (epoch 40.178), train_loss = 1.02931960, grad/param norm = 2.2806e-01, time/batch = 0.6698s	
26639/33150 (epoch 40.179), train_loss = 0.90577665, grad/param norm = 1.9026e-01, time/batch = 0.6641s	
26640/33150 (epoch 40.181), train_loss = 0.85988382, grad/param norm = 2.0699e-01, time/batch = 0.6853s	
26641/33150 (epoch 40.183), train_loss = 0.83040248, grad/param norm = 2.2150e-01, time/batch = 0.6821s	
26642/33150 (epoch 40.184), train_loss = 1.07539611, grad/param norm = 1.8953e-01, time/batch = 0.6668s	
26643/33150 (epoch 40.186), train_loss = 1.00995894, grad/param norm = 1.7780e-01, time/batch = 0.6677s	
26644/33150 (epoch 40.187), train_loss = 0.84178223, grad/param norm = 1.8146e-01, time/batch = 0.6693s	
26645/33150 (epoch 40.189), train_loss = 0.67049871, grad/param norm = 1.7739e-01, time/batch = 0.6719s	
26646/33150 (epoch 40.190), train_loss = 0.75940412, grad/param norm = 1.7410e-01, time/batch = 0.6937s	
26647/33150 (epoch 40.192), train_loss = 0.87784475, grad/param norm = 1.8882e-01, time/batch = 0.6734s	
26648/33150 (epoch 40.193), train_loss = 0.90494719, grad/param norm = 1.7948e-01, time/batch = 0.6701s	
26649/33150 (epoch 40.195), train_loss = 1.01570212, grad/param norm = 2.0182e-01, time/batch = 0.6698s	
26650/33150 (epoch 40.196), train_loss = 0.96365104, grad/param norm = 1.8948e-01, time/batch = 0.6716s	
26651/33150 (epoch 40.198), train_loss = 0.74763251, grad/param norm = 1.5540e-01, time/batch = 0.6713s	
26652/33150 (epoch 40.199), train_loss = 0.91367020, grad/param norm = 2.3877e-01, time/batch = 0.6701s	
26653/33150 (epoch 40.201), train_loss = 0.79974984, grad/param norm = 1.5863e-01, time/batch = 0.6765s	
26654/33150 (epoch 40.202), train_loss = 0.67739353, grad/param norm = 1.6643e-01, time/batch = 0.6786s	
26655/33150 (epoch 40.204), train_loss = 0.86235042, grad/param norm = 1.8117e-01, time/batch = 0.6802s	
26656/33150 (epoch 40.205), train_loss = 0.88056459, grad/param norm = 1.8192e-01, time/batch = 0.6760s	
26657/33150 (epoch 40.207), train_loss = 0.85878225, grad/param norm = 1.7160e-01, time/batch = 0.6757s	
26658/33150 (epoch 40.208), train_loss = 0.92242019, grad/param norm = 2.0150e-01, time/batch = 0.6718s	
26659/33150 (epoch 40.210), train_loss = 0.78802038, grad/param norm = 1.6923e-01, time/batch = 0.6744s	
26660/33150 (epoch 40.211), train_loss = 0.84340944, grad/param norm = 2.0284e-01, time/batch = 0.6742s	
26661/33150 (epoch 40.213), train_loss = 0.90350852, grad/param norm = 1.9531e-01, time/batch = 0.6770s	
26662/33150 (epoch 40.214), train_loss = 0.80391936, grad/param norm = 1.7980e-01, time/batch = 0.6859s	
26663/33150 (epoch 40.216), train_loss = 0.76317726, grad/param norm = 2.0211e-01, time/batch = 0.6736s	
26664/33150 (epoch 40.217), train_loss = 0.85968273, grad/param norm = 1.8260e-01, time/batch = 0.6805s	
26665/33150 (epoch 40.219), train_loss = 0.78369316, grad/param norm = 1.7469e-01, time/batch = 0.6726s	
26666/33150 (epoch 40.220), train_loss = 0.81615544, grad/param norm = 1.5598e-01, time/batch = 0.6705s	
26667/33150 (epoch 40.222), train_loss = 0.91114046, grad/param norm = 1.8599e-01, time/batch = 0.6703s	
26668/33150 (epoch 40.223), train_loss = 0.83412054, grad/param norm = 1.7936e-01, time/batch = 0.6692s	
26669/33150 (epoch 40.225), train_loss = 0.96005834, grad/param norm = 2.0502e-01, time/batch = 0.6735s	
26670/33150 (epoch 40.226), train_loss = 0.81574938, grad/param norm = 1.8515e-01, time/batch = 0.6801s	
26671/33150 (epoch 40.228), train_loss = 0.81775726, grad/param norm = 1.9220e-01, time/batch = 0.6745s	
26672/33150 (epoch 40.229), train_loss = 0.83610971, grad/param norm = 1.8161e-01, time/batch = 0.6740s	
26673/33150 (epoch 40.231), train_loss = 0.94081299, grad/param norm = 2.1006e-01, time/batch = 0.6740s	
26674/33150 (epoch 40.232), train_loss = 0.82083903, grad/param norm = 1.9949e-01, time/batch = 0.6739s	
26675/33150 (epoch 40.234), train_loss = 0.86765209, grad/param norm = 1.8324e-01, time/batch = 0.6727s	
26676/33150 (epoch 40.235), train_loss = 0.92323592, grad/param norm = 2.3536e-01, time/batch = 0.6692s	
26677/33150 (epoch 40.237), train_loss = 0.88134109, grad/param norm = 2.2665e-01, time/batch = 0.6710s	
26678/33150 (epoch 40.238), train_loss = 0.90126901, grad/param norm = 1.8842e-01, time/batch = 0.6697s	
26679/33150 (epoch 40.240), train_loss = 0.85663082, grad/param norm = 1.7800e-01, time/batch = 0.6731s	
26680/33150 (epoch 40.241), train_loss = 0.92229383, grad/param norm = 2.1254e-01, time/batch = 0.6731s	
26681/33150 (epoch 40.243), train_loss = 0.91742261, grad/param norm = 1.9303e-01, time/batch = 0.6725s	
26682/33150 (epoch 40.244), train_loss = 0.85938407, grad/param norm = 1.7611e-01, time/batch = 0.6727s	
26683/33150 (epoch 40.246), train_loss = 0.91770060, grad/param norm = 1.8038e-01, time/batch = 0.6760s	
26684/33150 (epoch 40.247), train_loss = 0.79676083, grad/param norm = 1.6461e-01, time/batch = 0.6671s	
26685/33150 (epoch 40.249), train_loss = 0.97386935, grad/param norm = 1.8339e-01, time/batch = 0.6680s	
26686/33150 (epoch 40.250), train_loss = 0.89912451, grad/param norm = 1.7639e-01, time/batch = 0.6707s	
26687/33150 (epoch 40.252), train_loss = 0.89652728, grad/param norm = 1.6427e-01, time/batch = 0.6695s	
26688/33150 (epoch 40.253), train_loss = 0.82898201, grad/param norm = 2.0379e-01, time/batch = 0.6709s	
26689/33150 (epoch 40.255), train_loss = 0.83718951, grad/param norm = 1.9139e-01, time/batch = 0.6886s	
26690/33150 (epoch 40.256), train_loss = 0.95796731, grad/param norm = 1.8686e-01, time/batch = 0.6750s	
26691/33150 (epoch 40.258), train_loss = 0.79959858, grad/param norm = 1.9011e-01, time/batch = 0.6729s	
26692/33150 (epoch 40.259), train_loss = 0.69225234, grad/param norm = 1.9659e-01, time/batch = 0.6675s	
26693/33150 (epoch 40.261), train_loss = 0.76167494, grad/param norm = 1.6560e-01, time/batch = 0.6697s	
26694/33150 (epoch 40.262), train_loss = 0.95588680, grad/param norm = 1.9058e-01, time/batch = 0.6678s	
26695/33150 (epoch 40.264), train_loss = 0.66076978, grad/param norm = 1.5883e-01, time/batch = 0.6727s	
26696/33150 (epoch 40.265), train_loss = 0.86990496, grad/param norm = 2.0408e-01, time/batch = 0.6670s	
26697/33150 (epoch 40.267), train_loss = 0.94902604, grad/param norm = 2.2354e-01, time/batch = 0.6667s	
26698/33150 (epoch 40.268), train_loss = 0.95753796, grad/param norm = 1.6942e-01, time/batch = 0.6696s	
26699/33150 (epoch 40.270), train_loss = 1.02613443, grad/param norm = 1.7696e-01, time/batch = 0.6669s	
26700/33150 (epoch 40.271), train_loss = 0.89791123, grad/param norm = 2.1997e-01, time/batch = 0.6689s	
26701/33150 (epoch 40.273), train_loss = 0.96788773, grad/param norm = 1.9335e-01, time/batch = 0.6722s	
26702/33150 (epoch 40.275), train_loss = 0.97842230, grad/param norm = 1.9704e-01, time/batch = 0.6717s	
26703/33150 (epoch 40.276), train_loss = 0.85896914, grad/param norm = 1.7377e-01, time/batch = 0.6769s	
26704/33150 (epoch 40.278), train_loss = 0.96765492, grad/param norm = 1.8371e-01, time/batch = 0.6865s	
26705/33150 (epoch 40.279), train_loss = 0.93163676, grad/param norm = 1.5783e-01, time/batch = 0.6880s	
26706/33150 (epoch 40.281), train_loss = 0.85274719, grad/param norm = 1.6677e-01, time/batch = 0.6901s	
26707/33150 (epoch 40.282), train_loss = 0.90885380, grad/param norm = 1.5605e-01, time/batch = 0.6796s	
26708/33150 (epoch 40.284), train_loss = 0.78300054, grad/param norm = 1.7180e-01, time/batch = 0.6705s	
26709/33150 (epoch 40.285), train_loss = 0.90007673, grad/param norm = 2.0140e-01, time/batch = 0.6682s	
26710/33150 (epoch 40.287), train_loss = 0.75798789, grad/param norm = 2.0504e-01, time/batch = 0.6701s	
26711/33150 (epoch 40.288), train_loss = 0.91814229, grad/param norm = 1.7109e-01, time/batch = 0.6686s	
26712/33150 (epoch 40.290), train_loss = 0.73653024, grad/param norm = 1.6181e-01, time/batch = 0.6699s	
26713/33150 (epoch 40.291), train_loss = 0.70645771, grad/param norm = 1.6109e-01, time/batch = 0.6753s	
26714/33150 (epoch 40.293), train_loss = 0.82664195, grad/param norm = 1.7533e-01, time/batch = 0.6764s	
26715/33150 (epoch 40.294), train_loss = 0.65843738, grad/param norm = 1.5178e-01, time/batch = 0.6929s	
26716/33150 (epoch 40.296), train_loss = 0.84107168, grad/param norm = 1.6446e-01, time/batch = 0.7014s	
26717/33150 (epoch 40.297), train_loss = 0.78877720, grad/param norm = 1.7261e-01, time/batch = 0.6749s	
26718/33150 (epoch 40.299), train_loss = 0.77728432, grad/param norm = 1.7901e-01, time/batch = 0.6671s	
26719/33150 (epoch 40.300), train_loss = 0.80120334, grad/param norm = 1.6079e-01, time/batch = 0.6659s	
26720/33150 (epoch 40.302), train_loss = 0.82990735, grad/param norm = 1.8302e-01, time/batch = 0.6898s	
26721/33150 (epoch 40.303), train_loss = 0.81359357, grad/param norm = 1.7470e-01, time/batch = 0.6705s	
26722/33150 (epoch 40.305), train_loss = 0.89545041, grad/param norm = 1.9086e-01, time/batch = 0.6693s	
26723/33150 (epoch 40.306), train_loss = 0.89987364, grad/param norm = 1.8417e-01, time/batch = 0.6751s	
26724/33150 (epoch 40.308), train_loss = 1.04643543, grad/param norm = 1.8878e-01, time/batch = 0.6853s	
26725/33150 (epoch 40.309), train_loss = 0.69461775, grad/param norm = 1.4217e-01, time/batch = 0.6694s	
26726/33150 (epoch 40.311), train_loss = 0.82648338, grad/param norm = 1.9544e-01, time/batch = 0.6815s	
26727/33150 (epoch 40.312), train_loss = 0.68777053, grad/param norm = 1.6518e-01, time/batch = 0.6685s	
26728/33150 (epoch 40.314), train_loss = 0.81728366, grad/param norm = 1.8951e-01, time/batch = 0.6636s	
26729/33150 (epoch 40.315), train_loss = 0.88889697, grad/param norm = 1.6618e-01, time/batch = 0.6647s	
26730/33150 (epoch 40.317), train_loss = 0.67724445, grad/param norm = 1.4006e-01, time/batch = 0.6655s	
26731/33150 (epoch 40.318), train_loss = 0.78103068, grad/param norm = 1.6719e-01, time/batch = 0.6725s	
26732/33150 (epoch 40.320), train_loss = 0.71197059, grad/param norm = 1.8808e-01, time/batch = 0.6640s	
26733/33150 (epoch 40.321), train_loss = 0.81070713, grad/param norm = 1.6099e-01, time/batch = 0.6778s	
26734/33150 (epoch 40.323), train_loss = 0.77820064, grad/param norm = 1.6378e-01, time/batch = 0.6763s	
26735/33150 (epoch 40.324), train_loss = 0.83351722, grad/param norm = 2.1639e-01, time/batch = 0.6686s	
26736/33150 (epoch 40.326), train_loss = 0.82855727, grad/param norm = 1.6814e-01, time/batch = 0.6653s	
26737/33150 (epoch 40.327), train_loss = 0.92203013, grad/param norm = 1.7405e-01, time/batch = 0.6669s	
26738/33150 (epoch 40.329), train_loss = 0.87017005, grad/param norm = 1.6794e-01, time/batch = 0.6643s	
26739/33150 (epoch 40.330), train_loss = 0.79081014, grad/param norm = 1.9233e-01, time/batch = 0.6648s	
26740/33150 (epoch 40.332), train_loss = 0.81426084, grad/param norm = 1.6908e-01, time/batch = 0.6690s	
26741/33150 (epoch 40.333), train_loss = 0.88761043, grad/param norm = 1.6055e-01, time/batch = 0.6685s	
26742/33150 (epoch 40.335), train_loss = 0.76161699, grad/param norm = 1.8299e-01, time/batch = 0.6681s	
26743/33150 (epoch 40.336), train_loss = 0.75972130, grad/param norm = 2.1202e-01, time/batch = 0.6719s	
26744/33150 (epoch 40.338), train_loss = 0.72305713, grad/param norm = 1.8653e-01, time/batch = 0.6681s	
26745/33150 (epoch 40.339), train_loss = 0.90149635, grad/param norm = 2.1187e-01, time/batch = 0.6713s	
26746/33150 (epoch 40.341), train_loss = 0.84757910, grad/param norm = 2.1095e-01, time/batch = 0.6716s	
26747/33150 (epoch 40.342), train_loss = 0.77677257, grad/param norm = 1.7150e-01, time/batch = 0.6712s	
26748/33150 (epoch 40.344), train_loss = 0.81245691, grad/param norm = 1.6576e-01, time/batch = 0.6723s	
26749/33150 (epoch 40.345), train_loss = 0.80726101, grad/param norm = 1.6727e-01, time/batch = 0.6696s	
26750/33150 (epoch 40.347), train_loss = 0.70651965, grad/param norm = 1.8319e-01, time/batch = 0.6706s	
26751/33150 (epoch 40.348), train_loss = 0.84311207, grad/param norm = 1.6337e-01, time/batch = 0.6880s	
26752/33150 (epoch 40.350), train_loss = 0.74439219, grad/param norm = 1.8224e-01, time/batch = 0.6869s	
26753/33150 (epoch 40.351), train_loss = 0.88960588, grad/param norm = 1.8150e-01, time/batch = 0.6887s	
26754/33150 (epoch 40.353), train_loss = 0.87826994, grad/param norm = 1.9537e-01, time/batch = 0.6885s	
26755/33150 (epoch 40.354), train_loss = 1.03676477, grad/param norm = 1.8567e-01, time/batch = 0.6842s	
26756/33150 (epoch 40.356), train_loss = 0.90965403, grad/param norm = 1.7570e-01, time/batch = 0.6877s	
26757/33150 (epoch 40.357), train_loss = 0.86341671, grad/param norm = 2.0880e-01, time/batch = 0.6822s	
26758/33150 (epoch 40.359), train_loss = 0.91342051, grad/param norm = 1.7721e-01, time/batch = 0.6784s	
26759/33150 (epoch 40.360), train_loss = 0.88063213, grad/param norm = 1.9172e-01, time/batch = 0.6871s	
26760/33150 (epoch 40.362), train_loss = 0.94292807, grad/param norm = 1.7222e-01, time/batch = 0.6899s	
26761/33150 (epoch 40.363), train_loss = 0.87281231, grad/param norm = 1.8040e-01, time/batch = 0.6782s	
26762/33150 (epoch 40.365), train_loss = 0.82408093, grad/param norm = 1.6899e-01, time/batch = 0.6752s	
26763/33150 (epoch 40.367), train_loss = 0.79878884, grad/param norm = 1.6141e-01, time/batch = 0.6797s	
26764/33150 (epoch 40.368), train_loss = 0.81763159, grad/param norm = 2.0386e-01, time/batch = 0.6714s	
26765/33150 (epoch 40.370), train_loss = 0.86212493, grad/param norm = 2.2527e-01, time/batch = 0.6701s	
26766/33150 (epoch 40.371), train_loss = 0.76083847, grad/param norm = 1.9260e-01, time/batch = 0.6690s	
26767/33150 (epoch 40.373), train_loss = 0.87522400, grad/param norm = 2.1000e-01, time/batch = 0.6692s	
26768/33150 (epoch 40.374), train_loss = 0.86652168, grad/param norm = 1.6482e-01, time/batch = 0.6695s	
26769/33150 (epoch 40.376), train_loss = 0.91318762, grad/param norm = 1.6308e-01, time/batch = 0.6693s	
26770/33150 (epoch 40.377), train_loss = 0.75400613, grad/param norm = 1.6137e-01, time/batch = 0.6706s	
26771/33150 (epoch 40.379), train_loss = 0.86317752, grad/param norm = 1.7781e-01, time/batch = 0.6699s	
26772/33150 (epoch 40.380), train_loss = 0.89322065, grad/param norm = 1.5430e-01, time/batch = 0.6693s	
26773/33150 (epoch 40.382), train_loss = 0.84294074, grad/param norm = 1.7887e-01, time/batch = 0.6692s	
26774/33150 (epoch 40.383), train_loss = 0.76482076, grad/param norm = 1.7787e-01, time/batch = 0.6716s	
26775/33150 (epoch 40.385), train_loss = 0.79109853, grad/param norm = 1.7306e-01, time/batch = 0.6841s	
26776/33150 (epoch 40.386), train_loss = 0.72969648, grad/param norm = 1.4687e-01, time/batch = 0.6807s	
26777/33150 (epoch 40.388), train_loss = 0.75752635, grad/param norm = 1.6957e-01, time/batch = 0.6873s	
26778/33150 (epoch 40.389), train_loss = 0.76711817, grad/param norm = 1.6874e-01, time/batch = 0.6829s	
26779/33150 (epoch 40.391), train_loss = 0.97540726, grad/param norm = 2.0279e-01, time/batch = 0.6878s	
26780/33150 (epoch 40.392), train_loss = 0.76402090, grad/param norm = 1.6399e-01, time/batch = 0.6886s	
26781/33150 (epoch 40.394), train_loss = 0.72583991, grad/param norm = 1.5018e-01, time/batch = 0.6899s	
26782/33150 (epoch 40.395), train_loss = 0.67634254, grad/param norm = 1.5723e-01, time/batch = 0.6869s	
26783/33150 (epoch 40.397), train_loss = 0.58384204, grad/param norm = 1.6631e-01, time/batch = 0.6750s	
26784/33150 (epoch 40.398), train_loss = 0.82821556, grad/param norm = 1.6956e-01, time/batch = 0.6697s	
26785/33150 (epoch 40.400), train_loss = 0.80750115, grad/param norm = 1.4568e-01, time/batch = 0.6682s	
26786/33150 (epoch 40.401), train_loss = 0.69306281, grad/param norm = 1.3389e-01, time/batch = 0.6707s	
26787/33150 (epoch 40.403), train_loss = 0.70641031, grad/param norm = 1.4734e-01, time/batch = 0.6744s	
26788/33150 (epoch 40.404), train_loss = 0.83169714, grad/param norm = 1.6306e-01, time/batch = 0.6801s	
26789/33150 (epoch 40.406), train_loss = 0.79218455, grad/param norm = 1.4349e-01, time/batch = 0.6737s	
26790/33150 (epoch 40.407), train_loss = 0.70867478, grad/param norm = 1.5416e-01, time/batch = 0.6721s	
26791/33150 (epoch 40.409), train_loss = 0.67278054, grad/param norm = 1.5418e-01, time/batch = 0.6752s	
26792/33150 (epoch 40.410), train_loss = 0.82780838, grad/param norm = 1.7379e-01, time/batch = 0.6720s	
26793/33150 (epoch 40.412), train_loss = 0.88440218, grad/param norm = 1.5857e-01, time/batch = 0.6793s	
26794/33150 (epoch 40.413), train_loss = 0.73441319, grad/param norm = 1.6254e-01, time/batch = 0.6882s	
26795/33150 (epoch 40.415), train_loss = 0.83890655, grad/param norm = 1.5293e-01, time/batch = 0.6898s	
26796/33150 (epoch 40.416), train_loss = 0.74201544, grad/param norm = 1.5059e-01, time/batch = 0.6706s	
26797/33150 (epoch 40.418), train_loss = 0.84849143, grad/param norm = 2.2453e-01, time/batch = 0.6687s	
26798/33150 (epoch 40.419), train_loss = 0.81210885, grad/param norm = 1.7436e-01, time/batch = 0.6695s	
26799/33150 (epoch 40.421), train_loss = 0.82092584, grad/param norm = 2.0889e-01, time/batch = 0.6971s	
26800/33150 (epoch 40.422), train_loss = 0.80315076, grad/param norm = 1.5570e-01, time/batch = 0.6894s	
26801/33150 (epoch 40.424), train_loss = 0.75985325, grad/param norm = 1.8712e-01, time/batch = 0.6825s	
26802/33150 (epoch 40.425), train_loss = 0.88640072, grad/param norm = 1.6373e-01, time/batch = 0.6832s	
26803/33150 (epoch 40.427), train_loss = 0.82929862, grad/param norm = 1.5139e-01, time/batch = 0.6900s	
26804/33150 (epoch 40.428), train_loss = 0.78801929, grad/param norm = 1.9235e-01, time/batch = 0.6708s	
26805/33150 (epoch 40.430), train_loss = 0.84755930, grad/param norm = 1.9138e-01, time/batch = 0.6714s	
26806/33150 (epoch 40.431), train_loss = 0.89172431, grad/param norm = 2.2776e-01, time/batch = 0.6822s	
26807/33150 (epoch 40.433), train_loss = 0.80106566, grad/param norm = 1.6969e-01, time/batch = 0.6836s	
26808/33150 (epoch 40.434), train_loss = 0.71874894, grad/param norm = 1.6252e-01, time/batch = 0.6859s	
26809/33150 (epoch 40.436), train_loss = 0.83983790, grad/param norm = 1.5888e-01, time/batch = 0.6769s	
26810/33150 (epoch 40.437), train_loss = 0.83526933, grad/param norm = 2.2152e-01, time/batch = 0.6722s	
26811/33150 (epoch 40.439), train_loss = 0.97020105, grad/param norm = 1.6979e-01, time/batch = 0.6755s	
26812/33150 (epoch 40.440), train_loss = 0.86027018, grad/param norm = 1.8043e-01, time/batch = 0.6734s	
26813/33150 (epoch 40.442), train_loss = 0.71677780, grad/param norm = 1.8443e-01, time/batch = 0.6756s	
26814/33150 (epoch 40.443), train_loss = 0.83856965, grad/param norm = 1.7753e-01, time/batch = 0.6745s	
26815/33150 (epoch 40.445), train_loss = 0.83161689, grad/param norm = 1.7481e-01, time/batch = 0.6751s	
26816/33150 (epoch 40.446), train_loss = 0.85203142, grad/param norm = 2.0274e-01, time/batch = 0.6724s	
26817/33150 (epoch 40.448), train_loss = 0.92492663, grad/param norm = 1.8072e-01, time/batch = 0.6715s	
26818/33150 (epoch 40.449), train_loss = 0.83750578, grad/param norm = 1.6578e-01, time/batch = 0.6691s	
26819/33150 (epoch 40.451), train_loss = 0.83289382, grad/param norm = 1.9344e-01, time/batch = 0.6679s	
26820/33150 (epoch 40.452), train_loss = 1.00875019, grad/param norm = 1.7493e-01, time/batch = 0.6674s	
26821/33150 (epoch 40.454), train_loss = 0.81228069, grad/param norm = 1.7329e-01, time/batch = 0.6711s	
26822/33150 (epoch 40.456), train_loss = 0.77232536, grad/param norm = 1.5541e-01, time/batch = 0.6694s	
26823/33150 (epoch 40.457), train_loss = 0.84342493, grad/param norm = 1.8630e-01, time/batch = 0.6702s	
26824/33150 (epoch 40.459), train_loss = 0.95636197, grad/param norm = 2.3782e-01, time/batch = 0.6702s	
26825/33150 (epoch 40.460), train_loss = 0.89053246, grad/param norm = 1.5860e-01, time/batch = 0.6658s	
26826/33150 (epoch 40.462), train_loss = 0.93373728, grad/param norm = 2.0783e-01, time/batch = 0.6714s	
26827/33150 (epoch 40.463), train_loss = 1.04083279, grad/param norm = 2.2300e-01, time/batch = 0.6686s	
26828/33150 (epoch 40.465), train_loss = 0.90604513, grad/param norm = 1.9044e-01, time/batch = 0.6667s	
26829/33150 (epoch 40.466), train_loss = 0.79674586, grad/param norm = 1.5900e-01, time/batch = 0.6662s	
26830/33150 (epoch 40.468), train_loss = 1.04899806, grad/param norm = 1.9216e-01, time/batch = 0.6654s	
26831/33150 (epoch 40.469), train_loss = 0.76504172, grad/param norm = 1.7179e-01, time/batch = 0.6690s	
26832/33150 (epoch 40.471), train_loss = 0.77330307, grad/param norm = 1.5868e-01, time/batch = 0.6833s	
26833/33150 (epoch 40.472), train_loss = 0.85766536, grad/param norm = 1.7213e-01, time/batch = 0.6744s	
26834/33150 (epoch 40.474), train_loss = 0.89009999, grad/param norm = 2.2845e-01, time/batch = 0.6674s	
26835/33150 (epoch 40.475), train_loss = 1.08195204, grad/param norm = 2.0156e-01, time/batch = 0.6660s	
26836/33150 (epoch 40.477), train_loss = 0.89217858, grad/param norm = 1.8965e-01, time/batch = 0.6668s	
26837/33150 (epoch 40.478), train_loss = 0.86407418, grad/param norm = 1.6891e-01, time/batch = 0.6671s	
26838/33150 (epoch 40.480), train_loss = 0.76608017, grad/param norm = 1.6979e-01, time/batch = 0.6669s	
26839/33150 (epoch 40.481), train_loss = 0.71349625, grad/param norm = 1.6451e-01, time/batch = 0.6701s	
26840/33150 (epoch 40.483), train_loss = 0.79743866, grad/param norm = 1.6511e-01, time/batch = 0.6666s	
26841/33150 (epoch 40.484), train_loss = 0.75477747, grad/param norm = 1.7993e-01, time/batch = 0.6757s	
26842/33150 (epoch 40.486), train_loss = 0.77444821, grad/param norm = 2.1825e-01, time/batch = 0.6755s	
26843/33150 (epoch 40.487), train_loss = 0.88520168, grad/param norm = 1.8499e-01, time/batch = 0.6791s	
26844/33150 (epoch 40.489), train_loss = 0.83107605, grad/param norm = 1.7834e-01, time/batch = 0.6741s	
26845/33150 (epoch 40.490), train_loss = 0.67320669, grad/param norm = 1.4588e-01, time/batch = 0.6712s	
26846/33150 (epoch 40.492), train_loss = 0.80296176, grad/param norm = 1.9843e-01, time/batch = 0.6709s	
26847/33150 (epoch 40.493), train_loss = 0.89423586, grad/param norm = 1.7934e-01, time/batch = 0.6708s	
26848/33150 (epoch 40.495), train_loss = 0.88103393, grad/param norm = 1.6559e-01, time/batch = 0.6723s	
26849/33150 (epoch 40.496), train_loss = 0.80515162, grad/param norm = 1.7334e-01, time/batch = 0.6704s	
26850/33150 (epoch 40.498), train_loss = 0.90683881, grad/param norm = 2.9244e-01, time/batch = 0.6734s	
26851/33150 (epoch 40.499), train_loss = 0.94015039, grad/param norm = 1.7659e-01, time/batch = 0.6791s	
26852/33150 (epoch 40.501), train_loss = 0.87086592, grad/param norm = 2.0479e-01, time/batch = 0.6713s	
26853/33150 (epoch 40.502), train_loss = 0.96789628, grad/param norm = 2.2668e-01, time/batch = 0.6715s	
26854/33150 (epoch 40.504), train_loss = 0.92435049, grad/param norm = 1.9975e-01, time/batch = 0.6707s	
26855/33150 (epoch 40.505), train_loss = 0.96158717, grad/param norm = 2.0127e-01, time/batch = 0.6676s	
26856/33150 (epoch 40.507), train_loss = 0.78337446, grad/param norm = 1.9734e-01, time/batch = 0.6704s	
26857/33150 (epoch 40.508), train_loss = 0.77942817, grad/param norm = 1.6344e-01, time/batch = 0.6761s	
26858/33150 (epoch 40.510), train_loss = 0.90432950, grad/param norm = 1.5409e-01, time/batch = 0.6808s	
26859/33150 (epoch 40.511), train_loss = 0.94104109, grad/param norm = 1.8269e-01, time/batch = 0.6677s	
26860/33150 (epoch 40.513), train_loss = 0.86449813, grad/param norm = 2.0254e-01, time/batch = 0.6704s	
26861/33150 (epoch 40.514), train_loss = 0.73301561, grad/param norm = 1.8752e-01, time/batch = 0.6727s	
26862/33150 (epoch 40.516), train_loss = 0.86420943, grad/param norm = 2.0838e-01, time/batch = 0.6697s	
26863/33150 (epoch 40.517), train_loss = 0.90823918, grad/param norm = 1.9417e-01, time/batch = 0.6707s	
26864/33150 (epoch 40.519), train_loss = 0.77737011, grad/param norm = 1.6606e-01, time/batch = 0.6717s	
26865/33150 (epoch 40.520), train_loss = 0.84067442, grad/param norm = 1.7129e-01, time/batch = 0.6715s	
26866/33150 (epoch 40.522), train_loss = 0.91278178, grad/param norm = 2.4196e-01, time/batch = 0.6699s	
26867/33150 (epoch 40.523), train_loss = 0.74578882, grad/param norm = 1.8252e-01, time/batch = 0.6711s	
26868/33150 (epoch 40.525), train_loss = 0.87778150, grad/param norm = 2.2682e-01, time/batch = 0.6722s	
26869/33150 (epoch 40.526), train_loss = 0.76592664, grad/param norm = 1.7808e-01, time/batch = 0.6706s	
26870/33150 (epoch 40.528), train_loss = 0.84853938, grad/param norm = 1.7807e-01, time/batch = 0.6691s	
26871/33150 (epoch 40.529), train_loss = 0.82328470, grad/param norm = 1.7469e-01, time/batch = 0.6723s	
26872/33150 (epoch 40.531), train_loss = 0.73530594, grad/param norm = 2.0360e-01, time/batch = 0.6833s	
26873/33150 (epoch 40.532), train_loss = 0.85391324, grad/param norm = 2.1855e-01, time/batch = 0.6801s	
26874/33150 (epoch 40.534), train_loss = 0.83556985, grad/param norm = 1.6189e-01, time/batch = 0.6831s	
26875/33150 (epoch 40.535), train_loss = 0.75922811, grad/param norm = 2.1092e-01, time/batch = 0.6814s	
26876/33150 (epoch 40.537), train_loss = 0.86901262, grad/param norm = 2.1480e-01, time/batch = 0.6682s	
26877/33150 (epoch 40.538), train_loss = 0.76371454, grad/param norm = 1.6784e-01, time/batch = 0.6675s	
26878/33150 (epoch 40.540), train_loss = 0.76601302, grad/param norm = 1.8411e-01, time/batch = 0.6681s	
26879/33150 (epoch 40.541), train_loss = 0.93827993, grad/param norm = 1.9317e-01, time/batch = 0.6662s	
26880/33150 (epoch 40.543), train_loss = 0.85534024, grad/param norm = 1.7644e-01, time/batch = 0.6725s	
26881/33150 (epoch 40.544), train_loss = 0.89296593, grad/param norm = 1.6744e-01, time/batch = 0.6733s	
26882/33150 (epoch 40.546), train_loss = 0.78445481, grad/param norm = 1.7620e-01, time/batch = 0.6864s	
26883/33150 (epoch 40.548), train_loss = 0.81740763, grad/param norm = 2.3044e-01, time/batch = 0.6893s	
26884/33150 (epoch 40.549), train_loss = 0.80346324, grad/param norm = 2.0378e-01, time/batch = 0.6890s	
26885/33150 (epoch 40.551), train_loss = 0.75942546, grad/param norm = 1.5920e-01, time/batch = 0.6693s	
26886/33150 (epoch 40.552), train_loss = 0.66189714, grad/param norm = 1.4280e-01, time/batch = 0.6723s	
26887/33150 (epoch 40.554), train_loss = 0.91100612, grad/param norm = 1.9871e-01, time/batch = 0.6816s	
26888/33150 (epoch 40.555), train_loss = 0.94325273, grad/param norm = 2.2851e-01, time/batch = 0.6789s	
26889/33150 (epoch 40.557), train_loss = 0.70710166, grad/param norm = 1.8139e-01, time/batch = 0.6713s	
26890/33150 (epoch 40.558), train_loss = 0.85591234, grad/param norm = 2.1457e-01, time/batch = 0.6689s	
26891/33150 (epoch 40.560), train_loss = 0.75406433, grad/param norm = 1.7047e-01, time/batch = 0.6683s	
26892/33150 (epoch 40.561), train_loss = 0.70643898, grad/param norm = 1.7937e-01, time/batch = 0.6747s	
26893/33150 (epoch 40.563), train_loss = 0.87361232, grad/param norm = 2.1820e-01, time/batch = 0.6778s	
26894/33150 (epoch 40.564), train_loss = 0.93265623, grad/param norm = 1.7214e-01, time/batch = 0.6692s	
26895/33150 (epoch 40.566), train_loss = 0.75155219, grad/param norm = 1.6200e-01, time/batch = 0.6902s	
26896/33150 (epoch 40.567), train_loss = 0.79769508, grad/param norm = 1.6968e-01, time/batch = 0.6795s	
26897/33150 (epoch 40.569), train_loss = 0.84799571, grad/param norm = 1.9552e-01, time/batch = 0.6670s	
26898/33150 (epoch 40.570), train_loss = 0.88483075, grad/param norm = 1.6697e-01, time/batch = 0.6690s	
26899/33150 (epoch 40.572), train_loss = 0.77229719, grad/param norm = 1.8028e-01, time/batch = 0.6740s	
26900/33150 (epoch 40.573), train_loss = 0.70426953, grad/param norm = 1.3553e-01, time/batch = 0.6720s	
26901/33150 (epoch 40.575), train_loss = 0.79854186, grad/param norm = 1.8895e-01, time/batch = 0.6780s	
26902/33150 (epoch 40.576), train_loss = 0.73150504, grad/param norm = 1.6209e-01, time/batch = 0.6803s	
26903/33150 (epoch 40.578), train_loss = 0.76031311, grad/param norm = 1.6048e-01, time/batch = 0.6787s	
26904/33150 (epoch 40.579), train_loss = 0.72992561, grad/param norm = 1.8015e-01, time/batch = 0.6695s	
26905/33150 (epoch 40.581), train_loss = 0.74291660, grad/param norm = 1.9571e-01, time/batch = 0.6700s	
26906/33150 (epoch 40.582), train_loss = 0.94433187, grad/param norm = 1.6763e-01, time/batch = 0.6688s	
26907/33150 (epoch 40.584), train_loss = 0.91213153, grad/param norm = 1.7525e-01, time/batch = 0.6725s	
26908/33150 (epoch 40.585), train_loss = 0.82834020, grad/param norm = 1.7090e-01, time/batch = 0.6676s	
26909/33150 (epoch 40.587), train_loss = 0.82639650, grad/param norm = 1.7009e-01, time/batch = 0.6679s	
26910/33150 (epoch 40.588), train_loss = 0.76063356, grad/param norm = 1.8381e-01, time/batch = 0.6733s	
26911/33150 (epoch 40.590), train_loss = 0.84990454, grad/param norm = 1.7447e-01, time/batch = 0.6765s	
26912/33150 (epoch 40.591), train_loss = 0.85196464, grad/param norm = 2.0408e-01, time/batch = 0.6984s	
26913/33150 (epoch 40.593), train_loss = 0.88584305, grad/param norm = 1.8663e-01, time/batch = 0.6911s	
26914/33150 (epoch 40.594), train_loss = 0.80153971, grad/param norm = 1.8075e-01, time/batch = 0.6827s	
26915/33150 (epoch 40.596), train_loss = 0.80366914, grad/param norm = 1.9555e-01, time/batch = 0.6732s	
26916/33150 (epoch 40.597), train_loss = 0.73143481, grad/param norm = 2.4993e-01, time/batch = 0.6726s	
26917/33150 (epoch 40.599), train_loss = 0.99465472, grad/param norm = 2.4971e-01, time/batch = 0.6793s	
26918/33150 (epoch 40.600), train_loss = 0.82566573, grad/param norm = 2.7293e-01, time/batch = 0.6677s	
26919/33150 (epoch 40.602), train_loss = 0.82790600, grad/param norm = 1.9043e-01, time/batch = 0.6705s	
26920/33150 (epoch 40.603), train_loss = 0.96247320, grad/param norm = 1.9491e-01, time/batch = 0.6718s	
26921/33150 (epoch 40.605), train_loss = 0.73720197, grad/param norm = 1.6120e-01, time/batch = 0.6782s	
26922/33150 (epoch 40.606), train_loss = 0.78947790, grad/param norm = 2.2864e-01, time/batch = 0.6685s	
26923/33150 (epoch 40.608), train_loss = 0.92911038, grad/param norm = 1.7441e-01, time/batch = 0.6676s	
26924/33150 (epoch 40.609), train_loss = 0.83411365, grad/param norm = 1.9695e-01, time/batch = 0.6688s	
26925/33150 (epoch 40.611), train_loss = 0.74127012, grad/param norm = 1.7919e-01, time/batch = 0.6667s	
26926/33150 (epoch 40.612), train_loss = 0.80689363, grad/param norm = 1.9313e-01, time/batch = 0.6700s	
26927/33150 (epoch 40.614), train_loss = 0.76556561, grad/param norm = 1.6403e-01, time/batch = 0.6714s	
26928/33150 (epoch 40.615), train_loss = 0.72040254, grad/param norm = 1.6293e-01, time/batch = 0.6694s	
26929/33150 (epoch 40.617), train_loss = 0.84960022, grad/param norm = 2.1212e-01, time/batch = 0.6674s	
26930/33150 (epoch 40.618), train_loss = 0.87816706, grad/param norm = 2.0456e-01, time/batch = 0.6651s	
26931/33150 (epoch 40.620), train_loss = 0.79404208, grad/param norm = 1.8571e-01, time/batch = 0.6810s	
26932/33150 (epoch 40.621), train_loss = 0.85766805, grad/param norm = 2.0557e-01, time/batch = 0.6771s	
26933/33150 (epoch 40.623), train_loss = 0.87817631, grad/param norm = 1.7046e-01, time/batch = 0.6703s	
26934/33150 (epoch 40.624), train_loss = 0.82016006, grad/param norm = 1.9871e-01, time/batch = 0.6664s	
26935/33150 (epoch 40.626), train_loss = 0.82092581, grad/param norm = 1.8492e-01, time/batch = 0.6733s	
26936/33150 (epoch 40.627), train_loss = 0.79803534, grad/param norm = 1.8599e-01, time/batch = 0.6734s	
26937/33150 (epoch 40.629), train_loss = 0.69887410, grad/param norm = 1.7886e-01, time/batch = 0.6685s	
26938/33150 (epoch 40.630), train_loss = 0.81659399, grad/param norm = 1.7522e-01, time/batch = 0.6693s	
26939/33150 (epoch 40.632), train_loss = 0.73281932, grad/param norm = 1.4990e-01, time/batch = 0.6705s	
26940/33150 (epoch 40.633), train_loss = 0.75861852, grad/param norm = 1.7929e-01, time/batch = 0.6691s	
26941/33150 (epoch 40.635), train_loss = 0.97275159, grad/param norm = 1.8537e-01, time/batch = 0.6715s	
26942/33150 (epoch 40.637), train_loss = 0.68261187, grad/param norm = 1.7409e-01, time/batch = 0.6704s	
26943/33150 (epoch 40.638), train_loss = 0.81879521, grad/param norm = 1.9987e-01, time/batch = 0.6732s	
26944/33150 (epoch 40.640), train_loss = 0.89788796, grad/param norm = 2.0387e-01, time/batch = 0.6711s	
26945/33150 (epoch 40.641), train_loss = 0.69232282, grad/param norm = 1.6301e-01, time/batch = 0.6715s	
26946/33150 (epoch 40.643), train_loss = 0.84351001, grad/param norm = 1.7950e-01, time/batch = 0.6702s	
26947/33150 (epoch 40.644), train_loss = 0.97469271, grad/param norm = 1.7248e-01, time/batch = 0.6717s	
26948/33150 (epoch 40.646), train_loss = 0.82811776, grad/param norm = 1.6582e-01, time/batch = 0.6694s	
26949/33150 (epoch 40.647), train_loss = 1.00689624, grad/param norm = 1.7840e-01, time/batch = 0.6689s	
26950/33150 (epoch 40.649), train_loss = 0.86948290, grad/param norm = 2.1529e-01, time/batch = 0.6676s	
26951/33150 (epoch 40.650), train_loss = 0.76688427, grad/param norm = 1.8629e-01, time/batch = 0.6676s	
26952/33150 (epoch 40.652), train_loss = 0.92534009, grad/param norm = 2.0006e-01, time/batch = 0.6713s	
26953/33150 (epoch 40.653), train_loss = 0.89014540, grad/param norm = 1.6068e-01, time/batch = 0.6689s	
26954/33150 (epoch 40.655), train_loss = 0.88458002, grad/param norm = 2.0605e-01, time/batch = 0.7946s	
26955/33150 (epoch 40.656), train_loss = 0.78759009, grad/param norm = 1.4767e-01, time/batch = 0.9766s	
26956/33150 (epoch 40.658), train_loss = 0.79750388, grad/param norm = 1.8981e-01, time/batch = 0.9752s	
26957/33150 (epoch 40.659), train_loss = 1.05311862, grad/param norm = 2.9235e-01, time/batch = 0.9878s	
26958/33150 (epoch 40.661), train_loss = 0.82796942, grad/param norm = 1.9216e-01, time/batch = 0.9751s	
26959/33150 (epoch 40.662), train_loss = 0.81755423, grad/param norm = 1.8495e-01, time/batch = 1.2330s	
26960/33150 (epoch 40.664), train_loss = 0.93045709, grad/param norm = 1.8211e-01, time/batch = 1.8292s	
26961/33150 (epoch 40.665), train_loss = 0.92038694, grad/param norm = 2.0892e-01, time/batch = 1.8271s	
26962/33150 (epoch 40.667), train_loss = 0.93465373, grad/param norm = 2.2660e-01, time/batch = 10.8526s	
26963/33150 (epoch 40.668), train_loss = 0.99447530, grad/param norm = 2.3038e-01, time/batch = 18.1248s	
26964/33150 (epoch 40.670), train_loss = 0.77884408, grad/param norm = 1.5947e-01, time/batch = 18.3028s	
26965/33150 (epoch 40.671), train_loss = 0.76597056, grad/param norm = 1.8106e-01, time/batch = 20.1105s	
26966/33150 (epoch 40.673), train_loss = 0.94651667, grad/param norm = 1.6224e-01, time/batch = 28.0861s	
26967/33150 (epoch 40.674), train_loss = 0.90537663, grad/param norm = 2.1247e-01, time/batch = 19.3048s	
26968/33150 (epoch 40.676), train_loss = 0.83889377, grad/param norm = 1.6666e-01, time/batch = 16.6490s	
26969/33150 (epoch 40.677), train_loss = 0.96063603, grad/param norm = 2.3410e-01, time/batch = 17.7206s	
26970/33150 (epoch 40.679), train_loss = 0.83488559, grad/param norm = 1.6795e-01, time/batch = 16.3345s	
26971/33150 (epoch 40.680), train_loss = 0.92869472, grad/param norm = 1.9151e-01, time/batch = 18.3940s	
26972/33150 (epoch 40.682), train_loss = 0.85178127, grad/param norm = 1.6760e-01, time/batch = 17.1312s	
26973/33150 (epoch 40.683), train_loss = 0.70178531, grad/param norm = 1.4367e-01, time/batch = 18.9761s	
26974/33150 (epoch 40.685), train_loss = 0.79344247, grad/param norm = 1.9606e-01, time/batch = 18.3097s	
26975/33150 (epoch 40.686), train_loss = 0.71302426, grad/param norm = 1.9455e-01, time/batch = 16.6552s	
26976/33150 (epoch 40.688), train_loss = 0.73264091, grad/param norm = 1.7778e-01, time/batch = 19.3690s	
26977/33150 (epoch 40.689), train_loss = 0.75699463, grad/param norm = 1.6023e-01, time/batch = 16.3084s	
26978/33150 (epoch 40.691), train_loss = 0.65692283, grad/param norm = 1.6000e-01, time/batch = 17.2135s	
26979/33150 (epoch 40.692), train_loss = 0.74402117, grad/param norm = 2.0354e-01, time/batch = 18.7243s	
26980/33150 (epoch 40.694), train_loss = 0.67170912, grad/param norm = 1.8152e-01, time/batch = 15.9858s	
26981/33150 (epoch 40.695), train_loss = 0.77018083, grad/param norm = 1.6569e-01, time/batch = 17.3061s	
26982/33150 (epoch 40.697), train_loss = 0.72590023, grad/param norm = 1.5715e-01, time/batch = 15.9516s	
26983/33150 (epoch 40.698), train_loss = 0.73252049, grad/param norm = 1.8885e-01, time/batch = 16.0269s	
26984/33150 (epoch 40.700), train_loss = 0.65641926, grad/param norm = 1.6098e-01, time/batch = 18.3087s	
26985/33150 (epoch 40.701), train_loss = 0.71763957, grad/param norm = 1.7445e-01, time/batch = 16.7935s	
26986/33150 (epoch 40.703), train_loss = 0.83927640, grad/param norm = 2.0980e-01, time/batch = 17.9819s	
26987/33150 (epoch 40.704), train_loss = 0.70545885, grad/param norm = 1.4719e-01, time/batch = 17.9069s	
26988/33150 (epoch 40.706), train_loss = 0.75630662, grad/param norm = 1.4331e-01, time/batch = 18.8836s	
26989/33150 (epoch 40.707), train_loss = 0.80213432, grad/param norm = 1.8019e-01, time/batch = 16.6434s	
26990/33150 (epoch 40.709), train_loss = 0.82393287, grad/param norm = 1.6259e-01, time/batch = 19.3081s	
26991/33150 (epoch 40.710), train_loss = 0.83305275, grad/param norm = 2.2229e-01, time/batch = 19.5577s	
26992/33150 (epoch 40.712), train_loss = 0.90302800, grad/param norm = 1.7418e-01, time/batch = 15.7996s	
26993/33150 (epoch 40.713), train_loss = 0.84897109, grad/param norm = 1.6212e-01, time/batch = 20.3654s	
26994/33150 (epoch 40.715), train_loss = 0.79699887, grad/param norm = 1.7404e-01, time/batch = 15.9623s	
26995/33150 (epoch 40.716), train_loss = 0.86211051, grad/param norm = 1.7957e-01, time/batch = 17.3792s	
26996/33150 (epoch 40.718), train_loss = 0.83285747, grad/param norm = 1.9074e-01, time/batch = 19.0448s	
26997/33150 (epoch 40.719), train_loss = 0.89662169, grad/param norm = 1.8633e-01, time/batch = 17.0638s	
26998/33150 (epoch 40.721), train_loss = 0.79455675, grad/param norm = 2.0530e-01, time/batch = 18.7959s	
26999/33150 (epoch 40.722), train_loss = 0.86165366, grad/param norm = 1.6380e-01, time/batch = 16.7896s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch40.72_1.8415.t7	
27000/33150 (epoch 40.724), train_loss = 0.79549493, grad/param norm = 1.8334e-01, time/batch = 17.9552s	
27001/33150 (epoch 40.725), train_loss = 1.44337182, grad/param norm = 2.5712e-01, time/batch = 15.7227s	
27002/33150 (epoch 40.727), train_loss = 0.88127225, grad/param norm = 2.0302e-01, time/batch = 17.9711s	
27003/33150 (epoch 40.729), train_loss = 0.82803259, grad/param norm = 1.8694e-01, time/batch = 16.2392s	
27004/33150 (epoch 40.730), train_loss = 0.82800441, grad/param norm = 1.6554e-01, time/batch = 16.3037s	
27005/33150 (epoch 40.732), train_loss = 0.87328184, grad/param norm = 1.7779e-01, time/batch = 17.9581s	
27006/33150 (epoch 40.733), train_loss = 0.72682080, grad/param norm = 1.5230e-01, time/batch = 18.7241s	
27007/33150 (epoch 40.735), train_loss = 0.75815020, grad/param norm = 1.7706e-01, time/batch = 18.0558s	
27008/33150 (epoch 40.736), train_loss = 0.78735572, grad/param norm = 1.7431e-01, time/batch = 16.2014s	
27009/33150 (epoch 40.738), train_loss = 0.84373497, grad/param norm = 2.2618e-01, time/batch = 17.0485s	
27010/33150 (epoch 40.739), train_loss = 0.93429763, grad/param norm = 2.0982e-01, time/batch = 19.4086s	
27011/33150 (epoch 40.741), train_loss = 0.84817175, grad/param norm = 2.1487e-01, time/batch = 17.3782s	
27012/33150 (epoch 40.742), train_loss = 0.69979638, grad/param norm = 1.6462e-01, time/batch = 17.7998s	
27013/33150 (epoch 40.744), train_loss = 0.87579602, grad/param norm = 1.7785e-01, time/batch = 19.2014s	
27014/33150 (epoch 40.745), train_loss = 0.77270698, grad/param norm = 1.7074e-01, time/batch = 18.8013s	
27015/33150 (epoch 40.747), train_loss = 0.63398866, grad/param norm = 1.6363e-01, time/batch = 16.8120s	
27016/33150 (epoch 40.748), train_loss = 0.69870543, grad/param norm = 1.6345e-01, time/batch = 20.0482s	
27017/33150 (epoch 40.750), train_loss = 0.84574799, grad/param norm = 1.9098e-01, time/batch = 15.6187s	
27018/33150 (epoch 40.751), train_loss = 0.80903835, grad/param norm = 1.6613e-01, time/batch = 16.2953s	
27019/33150 (epoch 40.753), train_loss = 0.72096363, grad/param norm = 1.9529e-01, time/batch = 18.5362s	
27020/33150 (epoch 40.754), train_loss = 1.00427504, grad/param norm = 2.0984e-01, time/batch = 19.4667s	
27021/33150 (epoch 40.756), train_loss = 0.84185359, grad/param norm = 2.9873e-01, time/batch = 17.3682s	
27022/33150 (epoch 40.757), train_loss = 0.85959220, grad/param norm = 1.8039e-01, time/batch = 17.5586s	
27023/33150 (epoch 40.759), train_loss = 0.95895255, grad/param norm = 2.4207e-01, time/batch = 17.6401s	
27024/33150 (epoch 40.760), train_loss = 0.88187459, grad/param norm = 2.0235e-01, time/batch = 18.3761s	
27025/33150 (epoch 40.762), train_loss = 0.82978432, grad/param norm = 2.0823e-01, time/batch = 18.2980s	
27026/33150 (epoch 40.763), train_loss = 0.86641719, grad/param norm = 1.9419e-01, time/batch = 16.1270s	
27027/33150 (epoch 40.765), train_loss = 0.81335598, grad/param norm = 1.9388e-01, time/batch = 20.4424s	
27028/33150 (epoch 40.766), train_loss = 0.70565242, grad/param norm = 1.8477e-01, time/batch = 18.0328s	
27029/33150 (epoch 40.768), train_loss = 0.75044312, grad/param norm = 1.5168e-01, time/batch = 15.6064s	
27030/33150 (epoch 40.769), train_loss = 0.89566548, grad/param norm = 1.7908e-01, time/batch = 15.4626s	
27031/33150 (epoch 40.771), train_loss = 0.85254328, grad/param norm = 1.9094e-01, time/batch = 16.7843s	
27032/33150 (epoch 40.772), train_loss = 0.86812087, grad/param norm = 2.0965e-01, time/batch = 15.6759s	
27033/33150 (epoch 40.774), train_loss = 0.96137069, grad/param norm = 1.7787e-01, time/batch = 15.6655s	
27034/33150 (epoch 40.775), train_loss = 0.89537298, grad/param norm = 3.6839e-01, time/batch = 18.7913s	
27035/33150 (epoch 40.777), train_loss = 0.87849520, grad/param norm = 1.8959e-01, time/batch = 16.7196s	
27036/33150 (epoch 40.778), train_loss = 0.81911921, grad/param norm = 1.6918e-01, time/batch = 16.5521s	
27037/33150 (epoch 40.780), train_loss = 0.69017677, grad/param norm = 1.6683e-01, time/batch = 17.9659s	
27038/33150 (epoch 40.781), train_loss = 0.81833146, grad/param norm = 1.7776e-01, time/batch = 16.2472s	
27039/33150 (epoch 40.783), train_loss = 0.83021131, grad/param norm = 1.6626e-01, time/batch = 18.1388s	
27040/33150 (epoch 40.784), train_loss = 0.82470042, grad/param norm = 1.9147e-01, time/batch = 19.4722s	
27041/33150 (epoch 40.786), train_loss = 0.81160341, grad/param norm = 1.7781e-01, time/batch = 16.5659s	
27042/33150 (epoch 40.787), train_loss = 0.73824073, grad/param norm = 1.5324e-01, time/batch = 16.5469s	
27043/33150 (epoch 40.789), train_loss = 0.69580451, grad/param norm = 1.5524e-01, time/batch = 17.2987s	
27044/33150 (epoch 40.790), train_loss = 0.69376689, grad/param norm = 1.5084e-01, time/batch = 17.0234s	
27045/33150 (epoch 40.792), train_loss = 0.81945175, grad/param norm = 2.0415e-01, time/batch = 17.8835s	
27046/33150 (epoch 40.793), train_loss = 0.79586114, grad/param norm = 2.1293e-01, time/batch = 17.9467s	
27047/33150 (epoch 40.795), train_loss = 0.78872019, grad/param norm = 1.8721e-01, time/batch = 17.2377s	
27048/33150 (epoch 40.796), train_loss = 0.79470377, grad/param norm = 1.5723e-01, time/batch = 18.8005s	
27049/33150 (epoch 40.798), train_loss = 0.76353431, grad/param norm = 1.5414e-01, time/batch = 16.5672s	
27050/33150 (epoch 40.799), train_loss = 0.68738841, grad/param norm = 2.2937e-01, time/batch = 16.7242s	
27051/33150 (epoch 40.801), train_loss = 0.83354809, grad/param norm = 1.6761e-01, time/batch = 19.9477s	
27052/33150 (epoch 40.802), train_loss = 0.78267107, grad/param norm = 1.7347e-01, time/batch = 16.6410s	
27053/33150 (epoch 40.804), train_loss = 0.77295330, grad/param norm = 1.7751e-01, time/batch = 17.3902s	
27054/33150 (epoch 40.805), train_loss = 0.74007661, grad/param norm = 1.8641e-01, time/batch = 18.0485s	
27055/33150 (epoch 40.807), train_loss = 0.81185347, grad/param norm = 1.8238e-01, time/batch = 17.7960s	
27056/33150 (epoch 40.808), train_loss = 0.88313158, grad/param norm = 1.8515e-01, time/batch = 19.3007s	
27057/33150 (epoch 40.810), train_loss = 0.73705436, grad/param norm = 1.7798e-01, time/batch = 18.8011s	
27058/33150 (epoch 40.811), train_loss = 0.84650803, grad/param norm = 2.1796e-01, time/batch = 18.9630s	
27059/33150 (epoch 40.813), train_loss = 0.78880942, grad/param norm = 1.7119e-01, time/batch = 17.6259s	
27060/33150 (epoch 40.814), train_loss = 0.77406924, grad/param norm = 2.0183e-01, time/batch = 16.8941s	
27061/33150 (epoch 40.816), train_loss = 0.78068377, grad/param norm = 1.7970e-01, time/batch = 15.7938s	
27062/33150 (epoch 40.817), train_loss = 0.87300725, grad/param norm = 1.8449e-01, time/batch = 15.7021s	
27063/33150 (epoch 40.819), train_loss = 0.83958696, grad/param norm = 1.7877e-01, time/batch = 15.5383s	
27064/33150 (epoch 40.821), train_loss = 0.73771369, grad/param norm = 1.6447e-01, time/batch = 16.6035s	
27065/33150 (epoch 40.822), train_loss = 0.76929251, grad/param norm = 1.8455e-01, time/batch = 15.4424s	
27066/33150 (epoch 40.824), train_loss = 0.83927281, grad/param norm = 1.9623e-01, time/batch = 15.6893s	
27067/33150 (epoch 40.825), train_loss = 0.86104852, grad/param norm = 1.9958e-01, time/batch = 15.1435s	
27068/33150 (epoch 40.827), train_loss = 0.87647623, grad/param norm = 1.9488e-01, time/batch = 18.0410s	
27069/33150 (epoch 40.828), train_loss = 0.74556393, grad/param norm = 1.7777e-01, time/batch = 18.2024s	
27070/33150 (epoch 40.830), train_loss = 0.87812267, grad/param norm = 2.1026e-01, time/batch = 15.9596s	
27071/33150 (epoch 40.831), train_loss = 0.75777960, grad/param norm = 1.8649e-01, time/batch = 18.4656s	
27072/33150 (epoch 40.833), train_loss = 0.73496141, grad/param norm = 1.6404e-01, time/batch = 17.8845s	
27073/33150 (epoch 40.834), train_loss = 0.89931990, grad/param norm = 1.8788e-01, time/batch = 17.7803s	
27074/33150 (epoch 40.836), train_loss = 0.93347916, grad/param norm = 1.6798e-01, time/batch = 17.9497s	
27075/33150 (epoch 40.837), train_loss = 0.75185817, grad/param norm = 2.0365e-01, time/batch = 17.7841s	
27076/33150 (epoch 40.839), train_loss = 0.90480189, grad/param norm = 2.1061e-01, time/batch = 16.5208s	
27077/33150 (epoch 40.840), train_loss = 0.86099286, grad/param norm = 1.8034e-01, time/batch = 16.9579s	
27078/33150 (epoch 40.842), train_loss = 0.90532619, grad/param norm = 2.2390e-01, time/batch = 18.1114s	
27079/33150 (epoch 40.843), train_loss = 0.92802142, grad/param norm = 1.9539e-01, time/batch = 18.8740s	
27080/33150 (epoch 40.845), train_loss = 0.77506656, grad/param norm = 1.7919e-01, time/batch = 17.2061s	
27081/33150 (epoch 40.846), train_loss = 0.99313966, grad/param norm = 2.6421e-01, time/batch = 18.0493s	
27082/33150 (epoch 40.848), train_loss = 0.89407044, grad/param norm = 1.8849e-01, time/batch = 17.0441s	
27083/33150 (epoch 40.849), train_loss = 0.89066702, grad/param norm = 1.6079e-01, time/batch = 15.9388s	
27084/33150 (epoch 40.851), train_loss = 0.88030468, grad/param norm = 2.0915e-01, time/batch = 17.7992s	
27085/33150 (epoch 40.852), train_loss = 0.95193118, grad/param norm = 1.9651e-01, time/batch = 17.7088s	
27086/33150 (epoch 40.854), train_loss = 0.86390779, grad/param norm = 2.0423e-01, time/batch = 16.1995s	
27087/33150 (epoch 40.855), train_loss = 0.75862177, grad/param norm = 1.8010e-01, time/batch = 15.7298s	
27088/33150 (epoch 40.857), train_loss = 0.69267356, grad/param norm = 1.9690e-01, time/batch = 18.8076s	
27089/33150 (epoch 40.858), train_loss = 0.80168519, grad/param norm = 2.0598e-01, time/batch = 17.1270s	
27090/33150 (epoch 40.860), train_loss = 0.74900396, grad/param norm = 1.7321e-01, time/batch = 17.3756s	
27091/33150 (epoch 40.861), train_loss = 0.72478218, grad/param norm = 1.5507e-01, time/batch = 18.7061s	
27092/33150 (epoch 40.863), train_loss = 0.79306250, grad/param norm = 1.6979e-01, time/batch = 18.7113s	
27093/33150 (epoch 40.864), train_loss = 0.83336678, grad/param norm = 1.7870e-01, time/batch = 17.5409s	
27094/33150 (epoch 40.866), train_loss = 0.89726713, grad/param norm = 1.8151e-01, time/batch = 14.9044s	
27095/33150 (epoch 40.867), train_loss = 0.82091378, grad/param norm = 1.6533e-01, time/batch = 17.2330s	
27096/33150 (epoch 40.869), train_loss = 0.85624613, grad/param norm = 2.1437e-01, time/batch = 14.9434s	
27097/33150 (epoch 40.870), train_loss = 0.77561154, grad/param norm = 1.8306e-01, time/batch = 15.0919s	
27098/33150 (epoch 40.872), train_loss = 0.87470346, grad/param norm = 2.0459e-01, time/batch = 16.1963s	
27099/33150 (epoch 40.873), train_loss = 0.68390042, grad/param norm = 1.5547e-01, time/batch = 16.6981s	
27100/33150 (epoch 40.875), train_loss = 0.91016098, grad/param norm = 1.7122e-01, time/batch = 19.0434s	
27101/33150 (epoch 40.876), train_loss = 0.67389719, grad/param norm = 1.5394e-01, time/batch = 16.4710s	
27102/33150 (epoch 40.878), train_loss = 0.75964242, grad/param norm = 1.4993e-01, time/batch = 18.3924s	
27103/33150 (epoch 40.879), train_loss = 0.74810013, grad/param norm = 1.5389e-01, time/batch = 16.1443s	
27104/33150 (epoch 40.881), train_loss = 0.74973332, grad/param norm = 1.5834e-01, time/batch = 16.1375s	
27105/33150 (epoch 40.882), train_loss = 0.63459815, grad/param norm = 1.4650e-01, time/batch = 17.4642s	
27106/33150 (epoch 40.884), train_loss = 0.75617119, grad/param norm = 1.6444e-01, time/batch = 18.0546s	
27107/33150 (epoch 40.885), train_loss = 0.62360885, grad/param norm = 1.6223e-01, time/batch = 17.6345s	
27108/33150 (epoch 40.887), train_loss = 0.88514660, grad/param norm = 1.7380e-01, time/batch = 17.4639s	
27109/33150 (epoch 40.888), train_loss = 0.82630625, grad/param norm = 1.7012e-01, time/batch = 19.0432s	
27110/33150 (epoch 40.890), train_loss = 0.72539931, grad/param norm = 1.8902e-01, time/batch = 17.7315s	
27111/33150 (epoch 40.891), train_loss = 0.72051258, grad/param norm = 1.8143e-01, time/batch = 15.8620s	
27112/33150 (epoch 40.893), train_loss = 0.86587911, grad/param norm = 1.9921e-01, time/batch = 19.8537s	
27113/33150 (epoch 40.894), train_loss = 0.84703063, grad/param norm = 1.5617e-01, time/batch = 17.8755s	
27114/33150 (epoch 40.896), train_loss = 0.79414384, grad/param norm = 1.4950e-01, time/batch = 17.0532s	
27115/33150 (epoch 40.897), train_loss = 0.86114708, grad/param norm = 1.6293e-01, time/batch = 18.2152s	
27116/33150 (epoch 40.899), train_loss = 0.66137541, grad/param norm = 1.8197e-01, time/batch = 17.5520s	
27117/33150 (epoch 40.900), train_loss = 0.97007919, grad/param norm = 1.9019e-01, time/batch = 18.0608s	
27118/33150 (epoch 40.902), train_loss = 1.01968778, grad/param norm = 1.8933e-01, time/batch = 17.2262s	
27119/33150 (epoch 40.903), train_loss = 0.83253402, grad/param norm = 1.7220e-01, time/batch = 18.5566s	
27120/33150 (epoch 40.905), train_loss = 0.80493788, grad/param norm = 1.5636e-01, time/batch = 16.8642s	
27121/33150 (epoch 40.906), train_loss = 0.82806115, grad/param norm = 1.9347e-01, time/batch = 16.2282s	
27122/33150 (epoch 40.908), train_loss = 0.86721650, grad/param norm = 1.8927e-01, time/batch = 16.8074s	
27123/33150 (epoch 40.910), train_loss = 0.89479246, grad/param norm = 1.9506e-01, time/batch = 17.8914s	
27124/33150 (epoch 40.911), train_loss = 0.71565091, grad/param norm = 1.7292e-01, time/batch = 16.8673s	
27125/33150 (epoch 40.913), train_loss = 0.77333388, grad/param norm = 1.6552e-01, time/batch = 16.5508s	
27126/33150 (epoch 40.914), train_loss = 0.83091836, grad/param norm = 1.8310e-01, time/batch = 18.7163s	
27127/33150 (epoch 40.916), train_loss = 0.75750526, grad/param norm = 1.6947e-01, time/batch = 17.8779s	
27128/33150 (epoch 40.917), train_loss = 0.84877574, grad/param norm = 1.7848e-01, time/batch = 15.8844s	
27129/33150 (epoch 40.919), train_loss = 0.93781148, grad/param norm = 2.4593e-01, time/batch = 17.4013s	
27130/33150 (epoch 40.920), train_loss = 0.90310300, grad/param norm = 1.8074e-01, time/batch = 17.1450s	
27131/33150 (epoch 40.922), train_loss = 0.93059927, grad/param norm = 2.1204e-01, time/batch = 17.6216s	
27132/33150 (epoch 40.923), train_loss = 0.82894072, grad/param norm = 1.8632e-01, time/batch = 16.3554s	
27133/33150 (epoch 40.925), train_loss = 0.90596195, grad/param norm = 1.7930e-01, time/batch = 18.8828s	
27134/33150 (epoch 40.926), train_loss = 0.80438508, grad/param norm = 1.6630e-01, time/batch = 19.6401s	
27135/33150 (epoch 40.928), train_loss = 0.81001051, grad/param norm = 1.8327e-01, time/batch = 18.0289s	
27136/33150 (epoch 40.929), train_loss = 0.86748903, grad/param norm = 1.7461e-01, time/batch = 19.9531s	
27137/33150 (epoch 40.931), train_loss = 0.92473853, grad/param norm = 2.0136e-01, time/batch = 16.3753s	
27138/33150 (epoch 40.932), train_loss = 0.85232866, grad/param norm = 2.2261e-01, time/batch = 18.1235s	
27139/33150 (epoch 40.934), train_loss = 0.83797773, grad/param norm = 1.6630e-01, time/batch = 18.7282s	
27140/33150 (epoch 40.935), train_loss = 0.91226811, grad/param norm = 1.8302e-01, time/batch = 18.6232s	
27141/33150 (epoch 40.937), train_loss = 0.94139396, grad/param norm = 1.6494e-01, time/batch = 17.8586s	
27142/33150 (epoch 40.938), train_loss = 0.85775637, grad/param norm = 1.7204e-01, time/batch = 17.8974s	
27143/33150 (epoch 40.940), train_loss = 1.06037353, grad/param norm = 1.9418e-01, time/batch = 17.7304s	
27144/33150 (epoch 40.941), train_loss = 0.87527266, grad/param norm = 1.5201e-01, time/batch = 18.1229s	
27145/33150 (epoch 40.943), train_loss = 0.68176706, grad/param norm = 1.6261e-01, time/batch = 19.1201s	
27146/33150 (epoch 40.944), train_loss = 0.87326119, grad/param norm = 1.8416e-01, time/batch = 18.5549s	
27147/33150 (epoch 40.946), train_loss = 0.73653082, grad/param norm = 1.5745e-01, time/batch = 17.9659s	
27148/33150 (epoch 40.947), train_loss = 0.85963319, grad/param norm = 1.7880e-01, time/batch = 16.6213s	
27149/33150 (epoch 40.949), train_loss = 0.90808094, grad/param norm = 1.6852e-01, time/batch = 19.7152s	
27150/33150 (epoch 40.950), train_loss = 0.91058886, grad/param norm = 1.9736e-01, time/batch = 20.5471s	
27151/33150 (epoch 40.952), train_loss = 0.77327810, grad/param norm = 1.7532e-01, time/batch = 15.8669s	
27152/33150 (epoch 40.953), train_loss = 0.81442531, grad/param norm = 1.5957e-01, time/batch = 19.8922s	
27153/33150 (epoch 40.955), train_loss = 0.71087596, grad/param norm = 1.7727e-01, time/batch = 18.1360s	
27154/33150 (epoch 40.956), train_loss = 0.89924681, grad/param norm = 2.7745e-01, time/batch = 17.4592s	
27155/33150 (epoch 40.958), train_loss = 0.76270638, grad/param norm = 1.7702e-01, time/batch = 17.5713s	
27156/33150 (epoch 40.959), train_loss = 0.82721148, grad/param norm = 1.6590e-01, time/batch = 19.2302s	
27157/33150 (epoch 40.961), train_loss = 0.74570765, grad/param norm = 1.8029e-01, time/batch = 18.0583s	
27158/33150 (epoch 40.962), train_loss = 0.70170705, grad/param norm = 1.6970e-01, time/batch = 17.2349s	
27159/33150 (epoch 40.964), train_loss = 0.80581830, grad/param norm = 1.7154e-01, time/batch = 18.1503s	
27160/33150 (epoch 40.965), train_loss = 0.80176037, grad/param norm = 1.6392e-01, time/batch = 17.6581s	
27161/33150 (epoch 40.967), train_loss = 0.81281356, grad/param norm = 1.8580e-01, time/batch = 29.1541s	
27162/33150 (epoch 40.968), train_loss = 0.69069933, grad/param norm = 1.5209e-01, time/batch = 21.1087s	
27163/33150 (epoch 40.970), train_loss = 0.77564976, grad/param norm = 1.6935e-01, time/batch = 17.3804s	
27164/33150 (epoch 40.971), train_loss = 0.81834968, grad/param norm = 1.7041e-01, time/batch = 17.4788s	
27165/33150 (epoch 40.973), train_loss = 0.88367717, grad/param norm = 1.8167e-01, time/batch = 16.4028s	
27166/33150 (epoch 40.974), train_loss = 0.95601451, grad/param norm = 2.0344e-01, time/batch = 18.7262s	
27167/33150 (epoch 40.976), train_loss = 0.91177353, grad/param norm = 1.9744e-01, time/batch = 16.1534s	
27168/33150 (epoch 40.977), train_loss = 0.93651765, grad/param norm = 1.9861e-01, time/batch = 18.5654s	
27169/33150 (epoch 40.979), train_loss = 0.90874984, grad/param norm = 2.0036e-01, time/batch = 17.8129s	
27170/33150 (epoch 40.980), train_loss = 0.97697197, grad/param norm = 2.0609e-01, time/batch = 18.0440s	
27171/33150 (epoch 40.982), train_loss = 0.83196590, grad/param norm = 2.0773e-01, time/batch = 18.8785s	
27172/33150 (epoch 40.983), train_loss = 0.74544446, grad/param norm = 1.7239e-01, time/batch = 18.7266s	
27173/33150 (epoch 40.985), train_loss = 0.92919484, grad/param norm = 1.6534e-01, time/batch = 17.8711s	
27174/33150 (epoch 40.986), train_loss = 0.70003973, grad/param norm = 1.5799e-01, time/batch = 17.9810s	
27175/33150 (epoch 40.988), train_loss = 0.78395469, grad/param norm = 2.0807e-01, time/batch = 17.5851s	
27176/33150 (epoch 40.989), train_loss = 0.81036807, grad/param norm = 1.7624e-01, time/batch = 17.3017s	
27177/33150 (epoch 40.991), train_loss = 0.87513192, grad/param norm = 2.3991e-01, time/batch = 16.2235s	
27178/33150 (epoch 40.992), train_loss = 0.81082401, grad/param norm = 1.5995e-01, time/batch = 17.4752s	
27179/33150 (epoch 40.994), train_loss = 0.84467591, grad/param norm = 1.7679e-01, time/batch = 18.8285s	
27180/33150 (epoch 40.995), train_loss = 0.79646363, grad/param norm = 1.7517e-01, time/batch = 16.6401s	
27181/33150 (epoch 40.997), train_loss = 0.82717753, grad/param norm = 1.8403e-01, time/batch = 15.9515s	
27182/33150 (epoch 40.998), train_loss = 0.69156732, grad/param norm = 1.6101e-01, time/batch = 16.8991s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
27183/33150 (epoch 41.000), train_loss = 0.75017837, grad/param norm = 1.9838e-01, time/batch = 18.0789s	
27184/33150 (epoch 41.002), train_loss = 1.12727540, grad/param norm = 2.1196e-01, time/batch = 16.6414s	
27185/33150 (epoch 41.003), train_loss = 0.74985201, grad/param norm = 1.9856e-01, time/batch = 19.2206s	
27186/33150 (epoch 41.005), train_loss = 0.71404964, grad/param norm = 1.5026e-01, time/batch = 19.5622s	
27187/33150 (epoch 41.006), train_loss = 0.68558403, grad/param norm = 1.7309e-01, time/batch = 17.6367s	
27188/33150 (epoch 41.008), train_loss = 0.87472195, grad/param norm = 1.9498e-01, time/batch = 18.2298s	
27189/33150 (epoch 41.009), train_loss = 0.84739552, grad/param norm = 1.6245e-01, time/batch = 17.0715s	
27190/33150 (epoch 41.011), train_loss = 0.90009301, grad/param norm = 1.6732e-01, time/batch = 15.9721s	
27191/33150 (epoch 41.012), train_loss = 0.79244176, grad/param norm = 1.9992e-01, time/batch = 16.6409s	
27192/33150 (epoch 41.014), train_loss = 0.74348109, grad/param norm = 1.9058e-01, time/batch = 18.0712s	
27193/33150 (epoch 41.015), train_loss = 0.74991200, grad/param norm = 1.9160e-01, time/batch = 19.8958s	
27194/33150 (epoch 41.017), train_loss = 0.75081052, grad/param norm = 1.7053e-01, time/batch = 16.1383s	
27195/33150 (epoch 41.018), train_loss = 0.84214964, grad/param norm = 2.2081e-01, time/batch = 18.3776s	
27196/33150 (epoch 41.020), train_loss = 0.92452238, grad/param norm = 2.4913e-01, time/batch = 16.3955s	
27197/33150 (epoch 41.021), train_loss = 0.74745699, grad/param norm = 1.8284e-01, time/batch = 15.2851s	
27198/33150 (epoch 41.023), train_loss = 0.99546658, grad/param norm = 1.7433e-01, time/batch = 16.3801s	
27199/33150 (epoch 41.024), train_loss = 0.87638129, grad/param norm = 1.9779e-01, time/batch = 17.4872s	
27200/33150 (epoch 41.026), train_loss = 0.65745122, grad/param norm = 1.5448e-01, time/batch = 19.4934s	
27201/33150 (epoch 41.027), train_loss = 0.66380003, grad/param norm = 1.4567e-01, time/batch = 16.8941s	
27202/33150 (epoch 41.029), train_loss = 0.76352504, grad/param norm = 1.8031e-01, time/batch = 18.5510s	
27203/33150 (epoch 41.030), train_loss = 0.80112031, grad/param norm = 1.4387e-01, time/batch = 16.4900s	
27204/33150 (epoch 41.032), train_loss = 0.72427393, grad/param norm = 1.8911e-01, time/batch = 16.6582s	
27205/33150 (epoch 41.033), train_loss = 0.73790967, grad/param norm = 1.9616e-01, time/batch = 15.8208s	
27206/33150 (epoch 41.035), train_loss = 0.97581154, grad/param norm = 1.7990e-01, time/batch = 17.0562s	
27207/33150 (epoch 41.036), train_loss = 0.89248056, grad/param norm = 2.0105e-01, time/batch = 18.5422s	
27208/33150 (epoch 41.038), train_loss = 1.00146398, grad/param norm = 1.9513e-01, time/batch = 16.4030s	
27209/33150 (epoch 41.039), train_loss = 0.87392475, grad/param norm = 1.5998e-01, time/batch = 17.4821s	
27210/33150 (epoch 41.041), train_loss = 0.81986925, grad/param norm = 1.7532e-01, time/batch = 18.0005s	
27211/33150 (epoch 41.042), train_loss = 0.75530484, grad/param norm = 1.8079e-01, time/batch = 17.4676s	
27212/33150 (epoch 41.044), train_loss = 0.82705822, grad/param norm = 1.7507e-01, time/batch = 16.9769s	
27213/33150 (epoch 41.045), train_loss = 0.88460744, grad/param norm = 1.5391e-01, time/batch = 15.1026s	
27214/33150 (epoch 41.047), train_loss = 0.76166266, grad/param norm = 2.3209e-01, time/batch = 14.9540s	
27215/33150 (epoch 41.048), train_loss = 0.89464640, grad/param norm = 2.0481e-01, time/batch = 15.2413s	
27216/33150 (epoch 41.050), train_loss = 0.79834933, grad/param norm = 1.9182e-01, time/batch = 15.2797s	
27217/33150 (epoch 41.051), train_loss = 0.84668925, grad/param norm = 1.6383e-01, time/batch = 15.1361s	
27218/33150 (epoch 41.053), train_loss = 0.86360836, grad/param norm = 1.7375e-01, time/batch = 17.1371s	
27219/33150 (epoch 41.054), train_loss = 0.96559982, grad/param norm = 1.7409e-01, time/batch = 16.3780s	
27220/33150 (epoch 41.056), train_loss = 0.81297745, grad/param norm = 1.7419e-01, time/batch = 17.7256s	
27221/33150 (epoch 41.057), train_loss = 0.87674996, grad/param norm = 1.6960e-01, time/batch = 16.5521s	
27222/33150 (epoch 41.059), train_loss = 0.74112614, grad/param norm = 1.8923e-01, time/batch = 16.2271s	
27223/33150 (epoch 41.060), train_loss = 0.74149103, grad/param norm = 1.5423e-01, time/batch = 17.2239s	
27224/33150 (epoch 41.062), train_loss = 0.80502576, grad/param norm = 1.5771e-01, time/batch = 17.0549s	
27225/33150 (epoch 41.063), train_loss = 0.75632944, grad/param norm = 1.9515e-01, time/batch = 15.8471s	
27226/33150 (epoch 41.065), train_loss = 0.80580650, grad/param norm = 1.7729e-01, time/batch = 16.5522s	
27227/33150 (epoch 41.066), train_loss = 0.79743215, grad/param norm = 1.6674e-01, time/batch = 16.3851s	
27228/33150 (epoch 41.068), train_loss = 0.85882937, grad/param norm = 1.6594e-01, time/batch = 16.9625s	
27229/33150 (epoch 41.069), train_loss = 0.86683719, grad/param norm = 1.8777e-01, time/batch = 16.9522s	
27230/33150 (epoch 41.071), train_loss = 0.85261826, grad/param norm = 1.8152e-01, time/batch = 16.4793s	
27231/33150 (epoch 41.072), train_loss = 0.85372124, grad/param norm = 1.8330e-01, time/batch = 17.4048s	
27232/33150 (epoch 41.074), train_loss = 0.70056608, grad/param norm = 1.9075e-01, time/batch = 17.3960s	
27233/33150 (epoch 41.075), train_loss = 0.71511638, grad/param norm = 1.6720e-01, time/batch = 16.3891s	
27234/33150 (epoch 41.077), train_loss = 0.83527244, grad/param norm = 2.2556e-01, time/batch = 15.8752s	
27235/33150 (epoch 41.078), train_loss = 0.95297670, grad/param norm = 1.9171e-01, time/batch = 16.1510s	
27236/33150 (epoch 41.080), train_loss = 0.95221129, grad/param norm = 1.9471e-01, time/batch = 16.8820s	
27237/33150 (epoch 41.081), train_loss = 0.73625219, grad/param norm = 1.9414e-01, time/batch = 15.2780s	
27238/33150 (epoch 41.083), train_loss = 0.60585717, grad/param norm = 2.5900e-01, time/batch = 15.7945s	
27239/33150 (epoch 41.084), train_loss = 0.69506237, grad/param norm = 1.7902e-01, time/batch = 16.3722s	
27240/33150 (epoch 41.086), train_loss = 0.75421502, grad/param norm = 2.1023e-01, time/batch = 16.3138s	
27241/33150 (epoch 41.087), train_loss = 0.72087077, grad/param norm = 2.1347e-01, time/batch = 17.0647s	
27242/33150 (epoch 41.089), train_loss = 0.76746084, grad/param norm = 1.7941e-01, time/batch = 17.6360s	
27243/33150 (epoch 41.090), train_loss = 0.79185334, grad/param norm = 1.8475e-01, time/batch = 15.8145s	
27244/33150 (epoch 41.092), train_loss = 0.76650944, grad/param norm = 2.0503e-01, time/batch = 15.9663s	
27245/33150 (epoch 41.094), train_loss = 0.85789997, grad/param norm = 2.0446e-01, time/batch = 17.7082s	
27246/33150 (epoch 41.095), train_loss = 0.74979799, grad/param norm = 1.8345e-01, time/batch = 17.4643s	
27247/33150 (epoch 41.097), train_loss = 0.69606913, grad/param norm = 1.7494e-01, time/batch = 17.4719s	
27248/33150 (epoch 41.098), train_loss = 1.03085256, grad/param norm = 1.9125e-01, time/batch = 17.8122s	
27249/33150 (epoch 41.100), train_loss = 1.00766376, grad/param norm = 2.1136e-01, time/batch = 18.0641s	
27250/33150 (epoch 41.101), train_loss = 0.76011513, grad/param norm = 1.8553e-01, time/batch = 17.4036s	
27251/33150 (epoch 41.103), train_loss = 0.82008648, grad/param norm = 1.7322e-01, time/batch = 18.3020s	
27252/33150 (epoch 41.104), train_loss = 0.77295907, grad/param norm = 2.0466e-01, time/batch = 17.5554s	
27253/33150 (epoch 41.106), train_loss = 0.93845299, grad/param norm = 2.4461e-01, time/batch = 16.7143s	
27254/33150 (epoch 41.107), train_loss = 0.99508108, grad/param norm = 2.1919e-01, time/batch = 16.2799s	
27255/33150 (epoch 41.109), train_loss = 0.81274664, grad/param norm = 1.5582e-01, time/batch = 19.3069s	
27256/33150 (epoch 41.110), train_loss = 0.90865921, grad/param norm = 2.0168e-01, time/batch = 18.2890s	
27257/33150 (epoch 41.112), train_loss = 0.73406613, grad/param norm = 1.7371e-01, time/batch = 17.7164s	
27258/33150 (epoch 41.113), train_loss = 0.79689833, grad/param norm = 1.7204e-01, time/batch = 16.8799s	
27259/33150 (epoch 41.115), train_loss = 1.00130846, grad/param norm = 2.4882e-01, time/batch = 18.7868s	
27260/33150 (epoch 41.116), train_loss = 0.87023023, grad/param norm = 1.8195e-01, time/batch = 17.9024s	
27261/33150 (epoch 41.118), train_loss = 0.87405702, grad/param norm = 1.8843e-01, time/batch = 16.3935s	
27262/33150 (epoch 41.119), train_loss = 0.88022622, grad/param norm = 2.3509e-01, time/batch = 17.1498s	
27263/33150 (epoch 41.121), train_loss = 0.80569961, grad/param norm = 1.6491e-01, time/batch = 19.3135s	
27264/33150 (epoch 41.122), train_loss = 0.97086583, grad/param norm = 2.2326e-01, time/batch = 15.4495s	
27265/33150 (epoch 41.124), train_loss = 0.68813275, grad/param norm = 1.5247e-01, time/batch = 17.1452s	
27266/33150 (epoch 41.125), train_loss = 0.93896512, grad/param norm = 1.7552e-01, time/batch = 18.1496s	
27267/33150 (epoch 41.127), train_loss = 0.86623066, grad/param norm = 2.1027e-01, time/batch = 16.2162s	
27268/33150 (epoch 41.128), train_loss = 0.87018698, grad/param norm = 1.9840e-01, time/batch = 15.1103s	
27269/33150 (epoch 41.130), train_loss = 0.82791896, grad/param norm = 1.9075e-01, time/batch = 15.7098s	
27270/33150 (epoch 41.131), train_loss = 1.01366785, grad/param norm = 2.0788e-01, time/batch = 16.2063s	
27271/33150 (epoch 41.133), train_loss = 0.77903095, grad/param norm = 1.6180e-01, time/batch = 17.4595s	
27272/33150 (epoch 41.134), train_loss = 0.93814026, grad/param norm = 1.8624e-01, time/batch = 17.1136s	
27273/33150 (epoch 41.136), train_loss = 0.85756435, grad/param norm = 2.3052e-01, time/batch = 17.1834s	
27274/33150 (epoch 41.137), train_loss = 0.88920791, grad/param norm = 1.7361e-01, time/batch = 17.1124s	
27275/33150 (epoch 41.139), train_loss = 0.90605077, grad/param norm = 2.2921e-01, time/batch = 16.2105s	
27276/33150 (epoch 41.140), train_loss = 0.97571876, grad/param norm = 1.9981e-01, time/batch = 17.6201s	
27277/33150 (epoch 41.142), train_loss = 0.91054077, grad/param norm = 2.5736e-01, time/batch = 17.3900s	
27278/33150 (epoch 41.143), train_loss = 0.84957035, grad/param norm = 2.1080e-01, time/batch = 17.0314s	
27279/33150 (epoch 41.145), train_loss = 0.79804352, grad/param norm = 2.1805e-01, time/batch = 16.8035s	
27280/33150 (epoch 41.146), train_loss = 0.93523993, grad/param norm = 2.2808e-01, time/batch = 18.4733s	
27281/33150 (epoch 41.148), train_loss = 0.98290153, grad/param norm = 1.7435e-01, time/batch = 18.5418s	
27282/33150 (epoch 41.149), train_loss = 0.85229920, grad/param norm = 1.8298e-01, time/batch = 15.9614s	
27283/33150 (epoch 41.151), train_loss = 0.99401209, grad/param norm = 1.9164e-01, time/batch = 19.0584s	
27284/33150 (epoch 41.152), train_loss = 0.77184891, grad/param norm = 1.6000e-01, time/batch = 19.4781s	
27285/33150 (epoch 41.154), train_loss = 0.77755558, grad/param norm = 1.9703e-01, time/batch = 16.3796s	
27286/33150 (epoch 41.155), train_loss = 0.73580888, grad/param norm = 1.9082e-01, time/batch = 16.4859s	
27287/33150 (epoch 41.157), train_loss = 0.82716924, grad/param norm = 1.9271e-01, time/batch = 16.8147s	
27288/33150 (epoch 41.158), train_loss = 0.80550405, grad/param norm = 1.5101e-01, time/batch = 19.9444s	
27289/33150 (epoch 41.160), train_loss = 0.89650691, grad/param norm = 1.8363e-01, time/batch = 17.6350s	
27290/33150 (epoch 41.161), train_loss = 0.77907753, grad/param norm = 1.7291e-01, time/batch = 16.8650s	
27291/33150 (epoch 41.163), train_loss = 0.74341793, grad/param norm = 1.8753e-01, time/batch = 19.8854s	
27292/33150 (epoch 41.164), train_loss = 0.87137801, grad/param norm = 1.6816e-01, time/batch = 15.8065s	
27293/33150 (epoch 41.166), train_loss = 0.79010826, grad/param norm = 1.7487e-01, time/batch = 16.8957s	
27294/33150 (epoch 41.167), train_loss = 0.85858116, grad/param norm = 1.6611e-01, time/batch = 18.1337s	
27295/33150 (epoch 41.169), train_loss = 0.82786155, grad/param norm = 2.1416e-01, time/batch = 15.8822s	
27296/33150 (epoch 41.170), train_loss = 0.75009516, grad/param norm = 2.3044e-01, time/batch = 16.3133s	
27297/33150 (epoch 41.172), train_loss = 0.87578524, grad/param norm = 2.1049e-01, time/batch = 17.0781s	
27298/33150 (epoch 41.173), train_loss = 0.86440815, grad/param norm = 2.1341e-01, time/batch = 17.6465s	
27299/33150 (epoch 41.175), train_loss = 0.81214490, grad/param norm = 2.5871e-01, time/batch = 15.4749s	
27300/33150 (epoch 41.176), train_loss = 0.88545805, grad/param norm = 1.9332e-01, time/batch = 16.5746s	
27301/33150 (epoch 41.178), train_loss = 1.01687091, grad/param norm = 2.1439e-01, time/batch = 16.0790s	
27302/33150 (epoch 41.179), train_loss = 0.90196248, grad/param norm = 1.8882e-01, time/batch = 17.6523s	
27303/33150 (epoch 41.181), train_loss = 0.87606533, grad/param norm = 2.1890e-01, time/batch = 15.6334s	
27304/33150 (epoch 41.183), train_loss = 0.82525440, grad/param norm = 2.0597e-01, time/batch = 18.2279s	
27305/33150 (epoch 41.184), train_loss = 1.08159013, grad/param norm = 2.2719e-01, time/batch = 17.9664s	
27306/33150 (epoch 41.186), train_loss = 1.00202332, grad/param norm = 1.8797e-01, time/batch = 17.5624s	
27307/33150 (epoch 41.187), train_loss = 0.83941273, grad/param norm = 1.8853e-01, time/batch = 15.9031s	
27308/33150 (epoch 41.189), train_loss = 0.66962363, grad/param norm = 1.6461e-01, time/batch = 18.2449s	
27309/33150 (epoch 41.190), train_loss = 0.75895088, grad/param norm = 1.7875e-01, time/batch = 17.6460s	
27310/33150 (epoch 41.192), train_loss = 0.87680833, grad/param norm = 2.0544e-01, time/batch = 15.9149s	
27311/33150 (epoch 41.193), train_loss = 0.90279168, grad/param norm = 1.9826e-01, time/batch = 17.9713s	
27312/33150 (epoch 41.195), train_loss = 1.01605650, grad/param norm = 2.0734e-01, time/batch = 18.5759s	
27313/33150 (epoch 41.196), train_loss = 0.94071175, grad/param norm = 1.7653e-01, time/batch = 15.8776s	
27314/33150 (epoch 41.198), train_loss = 0.74402516, grad/param norm = 1.5220e-01, time/batch = 17.4862s	
27315/33150 (epoch 41.199), train_loss = 0.91254305, grad/param norm = 2.1005e-01, time/batch = 17.9825s	
27316/33150 (epoch 41.201), train_loss = 0.80895522, grad/param norm = 1.7559e-01, time/batch = 17.6486s	
27317/33150 (epoch 41.202), train_loss = 0.67819932, grad/param norm = 1.8914e-01, time/batch = 18.1463s	
27318/33150 (epoch 41.204), train_loss = 0.84704975, grad/param norm = 1.8166e-01, time/batch = 17.6485s	
27319/33150 (epoch 41.205), train_loss = 0.86553579, grad/param norm = 1.7935e-01, time/batch = 17.3127s	
27320/33150 (epoch 41.207), train_loss = 0.86450991, grad/param norm = 1.9991e-01, time/batch = 16.0558s	
27321/33150 (epoch 41.208), train_loss = 0.90318359, grad/param norm = 1.8727e-01, time/batch = 16.3255s	
27322/33150 (epoch 41.210), train_loss = 0.77335001, grad/param norm = 1.6094e-01, time/batch = 16.5744s	
27323/33150 (epoch 41.211), train_loss = 0.83001276, grad/param norm = 2.1294e-01, time/batch = 16.4526s	
27324/33150 (epoch 41.213), train_loss = 0.91793056, grad/param norm = 2.1792e-01, time/batch = 17.2984s	
27325/33150 (epoch 41.214), train_loss = 0.80388716, grad/param norm = 1.6984e-01, time/batch = 19.8082s	
27326/33150 (epoch 41.216), train_loss = 0.74388770, grad/param norm = 1.7794e-01, time/batch = 17.8966s	
27327/33150 (epoch 41.217), train_loss = 0.85573244, grad/param norm = 2.0570e-01, time/batch = 18.2937s	
27328/33150 (epoch 41.219), train_loss = 0.77243019, grad/param norm = 1.7929e-01, time/batch = 17.9626s	
27329/33150 (epoch 41.220), train_loss = 0.81253568, grad/param norm = 1.6752e-01, time/batch = 19.0593s	
27330/33150 (epoch 41.222), train_loss = 0.92647716, grad/param norm = 1.9345e-01, time/batch = 16.8082s	
27331/33150 (epoch 41.223), train_loss = 0.83158584, grad/param norm = 1.7503e-01, time/batch = 16.9087s	
27332/33150 (epoch 41.225), train_loss = 0.95039079, grad/param norm = 1.9995e-01, time/batch = 19.0578s	
27333/33150 (epoch 41.226), train_loss = 0.80046438, grad/param norm = 1.7937e-01, time/batch = 17.8743s	
27334/33150 (epoch 41.228), train_loss = 0.81055925, grad/param norm = 1.9635e-01, time/batch = 17.8127s	
27335/33150 (epoch 41.229), train_loss = 0.84371732, grad/param norm = 2.0898e-01, time/batch = 17.7115s	
27336/33150 (epoch 41.231), train_loss = 0.93672345, grad/param norm = 2.2828e-01, time/batch = 16.9916s	
27337/33150 (epoch 41.232), train_loss = 0.80812686, grad/param norm = 1.8380e-01, time/batch = 18.1464s	
27338/33150 (epoch 41.234), train_loss = 0.87289103, grad/param norm = 2.0324e-01, time/batch = 16.7343s	
27339/33150 (epoch 41.235), train_loss = 0.90086345, grad/param norm = 1.8716e-01, time/batch = 18.2859s	
27340/33150 (epoch 41.237), train_loss = 0.84520985, grad/param norm = 1.8535e-01, time/batch = 17.5596s	
27341/33150 (epoch 41.238), train_loss = 0.89210097, grad/param norm = 2.0690e-01, time/batch = 18.1590s	
27342/33150 (epoch 41.240), train_loss = 0.85683600, grad/param norm = 1.8477e-01, time/batch = 18.3089s	
27343/33150 (epoch 41.241), train_loss = 0.92639803, grad/param norm = 2.3158e-01, time/batch = 15.7999s	
27344/33150 (epoch 41.243), train_loss = 0.89930872, grad/param norm = 1.8769e-01, time/batch = 17.1451s	
27345/33150 (epoch 41.244), train_loss = 0.85878173, grad/param norm = 1.6674e-01, time/batch = 18.2296s	
27346/33150 (epoch 41.246), train_loss = 0.91026347, grad/param norm = 2.0280e-01, time/batch = 15.2366s	
27347/33150 (epoch 41.247), train_loss = 0.78698921, grad/param norm = 1.6283e-01, time/batch = 17.0608s	
27348/33150 (epoch 41.249), train_loss = 0.95330738, grad/param norm = 1.7303e-01, time/batch = 17.9882s	
27349/33150 (epoch 41.250), train_loss = 0.88286466, grad/param norm = 1.5728e-01, time/batch = 18.0745s	
27350/33150 (epoch 41.252), train_loss = 0.90287890, grad/param norm = 1.6224e-01, time/batch = 17.6345s	
27351/33150 (epoch 41.253), train_loss = 0.80731375, grad/param norm = 1.7905e-01, time/batch = 18.0674s	
27352/33150 (epoch 41.255), train_loss = 0.82397047, grad/param norm = 1.5061e-01, time/batch = 17.6489s	
27353/33150 (epoch 41.256), train_loss = 0.94139670, grad/param norm = 1.8724e-01, time/batch = 17.7277s	
27354/33150 (epoch 41.258), train_loss = 0.79158820, grad/param norm = 1.8442e-01, time/batch = 17.3063s	
27355/33150 (epoch 41.259), train_loss = 0.67368907, grad/param norm = 1.7142e-01, time/batch = 19.2199s	
27356/33150 (epoch 41.261), train_loss = 0.74527105, grad/param norm = 1.5777e-01, time/batch = 18.0320s	
27357/33150 (epoch 41.262), train_loss = 0.96724512, grad/param norm = 1.9936e-01, time/batch = 17.0467s	
27358/33150 (epoch 41.264), train_loss = 0.65678340, grad/param norm = 1.4593e-01, time/batch = 18.1219s	
27359/33150 (epoch 41.265), train_loss = 0.85857915, grad/param norm = 1.9839e-01, time/batch = 19.4634s	
27360/33150 (epoch 41.267), train_loss = 0.95388207, grad/param norm = 2.3692e-01, time/batch = 16.7283s	
27361/33150 (epoch 41.268), train_loss = 0.97005601, grad/param norm = 1.7962e-01, time/batch = 15.7863s	
27362/33150 (epoch 41.270), train_loss = 1.02541524, grad/param norm = 1.6717e-01, time/batch = 18.3088s	
27363/33150 (epoch 41.271), train_loss = 0.89247636, grad/param norm = 1.8893e-01, time/batch = 19.6252s	
27364/33150 (epoch 41.273), train_loss = 0.95804470, grad/param norm = 1.9450e-01, time/batch = 16.8074s	
27365/33150 (epoch 41.275), train_loss = 0.96187399, grad/param norm = 1.8034e-01, time/batch = 18.9747s	
27366/33150 (epoch 41.276), train_loss = 0.85208427, grad/param norm = 1.8630e-01, time/batch = 18.3188s	
27367/33150 (epoch 41.278), train_loss = 0.95455406, grad/param norm = 1.9475e-01, time/batch = 25.7098s	
27368/33150 (epoch 41.279), train_loss = 0.93634975, grad/param norm = 1.7000e-01, time/batch = 21.8367s	
27369/33150 (epoch 41.281), train_loss = 0.85291885, grad/param norm = 1.8435e-01, time/batch = 16.1179s	
27370/33150 (epoch 41.282), train_loss = 0.89058103, grad/param norm = 1.6036e-01, time/batch = 15.2597s	
27371/33150 (epoch 41.284), train_loss = 0.78701066, grad/param norm = 1.7525e-01, time/batch = 15.6983s	
27372/33150 (epoch 41.285), train_loss = 0.88096421, grad/param norm = 1.9556e-01, time/batch = 15.7854s	
27373/33150 (epoch 41.287), train_loss = 0.74648218, grad/param norm = 1.6135e-01, time/batch = 15.6772s	
27374/33150 (epoch 41.288), train_loss = 0.91290736, grad/param norm = 1.7842e-01, time/batch = 16.3561s	
27375/33150 (epoch 41.290), train_loss = 0.73941900, grad/param norm = 1.9795e-01, time/batch = 15.7008s	
27376/33150 (epoch 41.291), train_loss = 0.69873487, grad/param norm = 1.7437e-01, time/batch = 18.7698s	
27377/33150 (epoch 41.293), train_loss = 0.80886882, grad/param norm = 1.8626e-01, time/batch = 16.9608s	
27378/33150 (epoch 41.294), train_loss = 0.66935913, grad/param norm = 1.5721e-01, time/batch = 17.9574s	
27379/33150 (epoch 41.296), train_loss = 0.84208491, grad/param norm = 1.6788e-01, time/batch = 18.2002s	
27380/33150 (epoch 41.297), train_loss = 0.78140896, grad/param norm = 2.3006e-01, time/batch = 18.5429s	
27381/33150 (epoch 41.299), train_loss = 0.78156870, grad/param norm = 1.8642e-01, time/batch = 17.2048s	
27382/33150 (epoch 41.300), train_loss = 0.79241038, grad/param norm = 1.4538e-01, time/batch = 17.1324s	
27383/33150 (epoch 41.302), train_loss = 0.82884028, grad/param norm = 1.8209e-01, time/batch = 17.3617s	
27384/33150 (epoch 41.303), train_loss = 0.79779327, grad/param norm = 1.6397e-01, time/batch = 15.8477s	
27385/33150 (epoch 41.305), train_loss = 0.88698813, grad/param norm = 1.8632e-01, time/batch = 16.3549s	
27386/33150 (epoch 41.306), train_loss = 0.89909642, grad/param norm = 2.2935e-01, time/batch = 17.7203s	
27387/33150 (epoch 41.308), train_loss = 1.04391039, grad/param norm = 1.9522e-01, time/batch = 16.3106s	
27388/33150 (epoch 41.309), train_loss = 0.68269112, grad/param norm = 1.4297e-01, time/batch = 16.4670s	
27389/33150 (epoch 41.311), train_loss = 0.82467929, grad/param norm = 1.7638e-01, time/batch = 17.2319s	
27390/33150 (epoch 41.312), train_loss = 0.67496759, grad/param norm = 1.5312e-01, time/batch = 18.3867s	
27391/33150 (epoch 41.314), train_loss = 0.81705514, grad/param norm = 1.9043e-01, time/batch = 15.6042s	
27392/33150 (epoch 41.315), train_loss = 0.86952606, grad/param norm = 1.7112e-01, time/batch = 16.5406s	
27393/33150 (epoch 41.317), train_loss = 0.68145135, grad/param norm = 1.5973e-01, time/batch = 15.9649s	
27394/33150 (epoch 41.318), train_loss = 0.76983142, grad/param norm = 1.5967e-01, time/batch = 16.4634s	
27395/33150 (epoch 41.320), train_loss = 0.69849024, grad/param norm = 1.7181e-01, time/batch = 15.5524s	
27396/33150 (epoch 41.321), train_loss = 0.79560911, grad/param norm = 1.5787e-01, time/batch = 17.0474s	
27397/33150 (epoch 41.323), train_loss = 0.77774761, grad/param norm = 1.7664e-01, time/batch = 16.2979s	
27398/33150 (epoch 41.324), train_loss = 0.79587017, grad/param norm = 1.9371e-01, time/batch = 15.7800s	
27399/33150 (epoch 41.326), train_loss = 0.81607121, grad/param norm = 1.6690e-01, time/batch = 16.9745s	
27400/33150 (epoch 41.327), train_loss = 0.92415002, grad/param norm = 1.7936e-01, time/batch = 18.8919s	
27401/33150 (epoch 41.329), train_loss = 0.87837015, grad/param norm = 1.8052e-01, time/batch = 19.9753s	
27402/33150 (epoch 41.330), train_loss = 0.77425137, grad/param norm = 1.6746e-01, time/batch = 16.7911s	
27403/33150 (epoch 41.332), train_loss = 0.80856610, grad/param norm = 1.7740e-01, time/batch = 17.4002s	
27404/33150 (epoch 41.333), train_loss = 0.89000938, grad/param norm = 1.5945e-01, time/batch = 16.5626s	
27405/33150 (epoch 41.335), train_loss = 0.75362461, grad/param norm = 1.6052e-01, time/batch = 17.2984s	
27406/33150 (epoch 41.336), train_loss = 0.75716021, grad/param norm = 1.7095e-01, time/batch = 18.3943s	
27407/33150 (epoch 41.338), train_loss = 0.70829249, grad/param norm = 1.8716e-01, time/batch = 17.7336s	
27408/33150 (epoch 41.339), train_loss = 0.89751137, grad/param norm = 1.9735e-01, time/batch = 18.5523s	
27409/33150 (epoch 41.341), train_loss = 0.82023270, grad/param norm = 2.0510e-01, time/batch = 15.4400s	
27410/33150 (epoch 41.342), train_loss = 0.77406422, grad/param norm = 1.6949e-01, time/batch = 16.8648s	
27411/33150 (epoch 41.344), train_loss = 0.81897228, grad/param norm = 1.9954e-01, time/batch = 18.6372s	
27412/33150 (epoch 41.345), train_loss = 0.80792263, grad/param norm = 1.6762e-01, time/batch = 16.2967s	
27413/33150 (epoch 41.347), train_loss = 0.70358774, grad/param norm = 1.8633e-01, time/batch = 18.5558s	
27414/33150 (epoch 41.348), train_loss = 0.84120988, grad/param norm = 1.6017e-01, time/batch = 18.4694s	
27415/33150 (epoch 41.350), train_loss = 0.74005636, grad/param norm = 2.0335e-01, time/batch = 18.2023s	
27416/33150 (epoch 41.351), train_loss = 0.89388066, grad/param norm = 1.8641e-01, time/batch = 18.0658s	
27417/33150 (epoch 41.353), train_loss = 0.87517640, grad/param norm = 1.9116e-01, time/batch = 16.9960s	
27418/33150 (epoch 41.354), train_loss = 1.03021569, grad/param norm = 1.9840e-01, time/batch = 18.6542s	
27419/33150 (epoch 41.356), train_loss = 0.91267128, grad/param norm = 1.7357e-01, time/batch = 16.5402s	
27420/33150 (epoch 41.357), train_loss = 0.84580467, grad/param norm = 2.0446e-01, time/batch = 19.8005s	
27421/33150 (epoch 41.359), train_loss = 0.91371987, grad/param norm = 1.8052e-01, time/batch = 18.0610s	
27422/33150 (epoch 41.360), train_loss = 0.87355257, grad/param norm = 1.9585e-01, time/batch = 16.9853s	
27423/33150 (epoch 41.362), train_loss = 0.94152815, grad/param norm = 1.8565e-01, time/batch = 18.0417s	
27424/33150 (epoch 41.363), train_loss = 0.86873608, grad/param norm = 1.6662e-01, time/batch = 16.1981s	
27425/33150 (epoch 41.365), train_loss = 0.81935732, grad/param norm = 1.6536e-01, time/batch = 15.7985s	
27426/33150 (epoch 41.367), train_loss = 0.80291517, grad/param norm = 1.6274e-01, time/batch = 15.9610s	
27427/33150 (epoch 41.368), train_loss = 0.81367348, grad/param norm = 2.6018e-01, time/batch = 17.5356s	
27428/33150 (epoch 41.370), train_loss = 0.84344982, grad/param norm = 2.2211e-01, time/batch = 18.4651s	
27429/33150 (epoch 41.371), train_loss = 0.75757942, grad/param norm = 1.7999e-01, time/batch = 17.5416s	
27430/33150 (epoch 41.373), train_loss = 0.86404680, grad/param norm = 1.7697e-01, time/batch = 16.6453s	
27431/33150 (epoch 41.374), train_loss = 0.85821002, grad/param norm = 1.6155e-01, time/batch = 18.7136s	
27432/33150 (epoch 41.376), train_loss = 0.90807113, grad/param norm = 1.6071e-01, time/batch = 16.3905s	
27433/33150 (epoch 41.377), train_loss = 0.76026589, grad/param norm = 1.7995e-01, time/batch = 17.8898s	
27434/33150 (epoch 41.379), train_loss = 0.87197852, grad/param norm = 2.2615e-01, time/batch = 19.7225s	
27435/33150 (epoch 41.380), train_loss = 0.89990894, grad/param norm = 1.6335e-01, time/batch = 19.3012s	
27436/33150 (epoch 41.382), train_loss = 0.82759648, grad/param norm = 1.7446e-01, time/batch = 16.5458s	
27437/33150 (epoch 41.383), train_loss = 0.76062328, grad/param norm = 1.7555e-01, time/batch = 17.6305s	
27438/33150 (epoch 41.385), train_loss = 0.78453318, grad/param norm = 1.8344e-01, time/batch = 18.8975s	
27439/33150 (epoch 41.386), train_loss = 0.72893977, grad/param norm = 1.5069e-01, time/batch = 16.8193s	
27440/33150 (epoch 41.388), train_loss = 0.75049175, grad/param norm = 1.6970e-01, time/batch = 15.5745s	
27441/33150 (epoch 41.389), train_loss = 0.76099491, grad/param norm = 1.6104e-01, time/batch = 17.2964s	
27442/33150 (epoch 41.391), train_loss = 0.95924422, grad/param norm = 1.9747e-01, time/batch = 17.9793s	
27443/33150 (epoch 41.392), train_loss = 0.77530614, grad/param norm = 1.8769e-01, time/batch = 16.3029s	
27444/33150 (epoch 41.394), train_loss = 0.72019082, grad/param norm = 1.5743e-01, time/batch = 18.0549s	
27445/33150 (epoch 41.395), train_loss = 0.66732087, grad/param norm = 1.4718e-01, time/batch = 18.6386s	
27446/33150 (epoch 41.397), train_loss = 0.57949854, grad/param norm = 1.5404e-01, time/batch = 16.8962s	
27447/33150 (epoch 41.398), train_loss = 0.82276851, grad/param norm = 1.6098e-01, time/batch = 18.3935s	
27448/33150 (epoch 41.400), train_loss = 0.80635865, grad/param norm = 1.4859e-01, time/batch = 16.6436s	
27449/33150 (epoch 41.401), train_loss = 0.69207880, grad/param norm = 1.3966e-01, time/batch = 15.7343s	
27450/33150 (epoch 41.403), train_loss = 0.70177595, grad/param norm = 1.6225e-01, time/batch = 16.9879s	
27451/33150 (epoch 41.404), train_loss = 0.81877902, grad/param norm = 1.6616e-01, time/batch = 17.4803s	
27452/33150 (epoch 41.406), train_loss = 0.78523173, grad/param norm = 1.4469e-01, time/batch = 17.4213s	
27453/33150 (epoch 41.407), train_loss = 0.70035523, grad/param norm = 1.6339e-01, time/batch = 16.7198s	
27454/33150 (epoch 41.409), train_loss = 0.65597561, grad/param norm = 1.7232e-01, time/batch = 17.2789s	
27455/33150 (epoch 41.410), train_loss = 0.81148319, grad/param norm = 1.7053e-01, time/batch = 16.6388s	
27456/33150 (epoch 41.412), train_loss = 0.86820477, grad/param norm = 1.6009e-01, time/batch = 16.8960s	
27457/33150 (epoch 41.413), train_loss = 0.71995632, grad/param norm = 1.4935e-01, time/batch = 16.7281s	
27458/33150 (epoch 41.415), train_loss = 0.84998761, grad/param norm = 1.6896e-01, time/batch = 18.4799s	
27459/33150 (epoch 41.416), train_loss = 0.74319845, grad/param norm = 1.4728e-01, time/batch = 18.5484s	
27460/33150 (epoch 41.418), train_loss = 0.84694396, grad/param norm = 1.9258e-01, time/batch = 16.6389s	
27461/33150 (epoch 41.419), train_loss = 0.79644945, grad/param norm = 1.7018e-01, time/batch = 17.5484s	
27462/33150 (epoch 41.421), train_loss = 0.84053087, grad/param norm = 2.3346e-01, time/batch = 19.3055s	
27463/33150 (epoch 41.422), train_loss = 0.79388972, grad/param norm = 1.7816e-01, time/batch = 16.4090s	
27464/33150 (epoch 41.424), train_loss = 0.74477711, grad/param norm = 1.7982e-01, time/batch = 16.9794s	
27465/33150 (epoch 41.425), train_loss = 0.88128450, grad/param norm = 1.7289e-01, time/batch = 18.8992s	
27466/33150 (epoch 41.427), train_loss = 0.81864441, grad/param norm = 1.5360e-01, time/batch = 17.7257s	
27467/33150 (epoch 41.428), train_loss = 0.78182892, grad/param norm = 1.7536e-01, time/batch = 16.6319s	
27468/33150 (epoch 41.430), train_loss = 0.84338341, grad/param norm = 2.1203e-01, time/batch = 18.3196s	
27469/33150 (epoch 41.431), train_loss = 0.87375034, grad/param norm = 2.2404e-01, time/batch = 18.6492s	
27470/33150 (epoch 41.433), train_loss = 0.79502395, grad/param norm = 1.7007e-01, time/batch = 15.8140s	
27471/33150 (epoch 41.434), train_loss = 0.70359746, grad/param norm = 1.7991e-01, time/batch = 17.8724s	
27472/33150 (epoch 41.436), train_loss = 0.81539099, grad/param norm = 1.4579e-01, time/batch = 17.3896s	
27473/33150 (epoch 41.437), train_loss = 0.82218021, grad/param norm = 2.3520e-01, time/batch = 18.1339s	
27474/33150 (epoch 41.439), train_loss = 0.96591187, grad/param norm = 1.6446e-01, time/batch = 18.2205s	
27475/33150 (epoch 41.440), train_loss = 0.86950040, grad/param norm = 2.0940e-01, time/batch = 17.1255s	
27476/33150 (epoch 41.442), train_loss = 0.71796356, grad/param norm = 2.0115e-01, time/batch = 19.0768s	
27477/33150 (epoch 41.443), train_loss = 0.83714071, grad/param norm = 1.8986e-01, time/batch = 17.5493s	
27478/33150 (epoch 41.445), train_loss = 0.83041736, grad/param norm = 2.0103e-01, time/batch = 16.9633s	
27479/33150 (epoch 41.446), train_loss = 0.85959810, grad/param norm = 2.0952e-01, time/batch = 17.2863s	
27480/33150 (epoch 41.448), train_loss = 0.91090144, grad/param norm = 1.9756e-01, time/batch = 17.0531s	
27481/33150 (epoch 41.449), train_loss = 0.81512595, grad/param norm = 1.4209e-01, time/batch = 16.7845s	
27482/33150 (epoch 41.451), train_loss = 0.84275022, grad/param norm = 2.3702e-01, time/batch = 18.9817s	
27483/33150 (epoch 41.452), train_loss = 0.98745314, grad/param norm = 1.8791e-01, time/batch = 16.9719s	
27484/33150 (epoch 41.454), train_loss = 0.78549966, grad/param norm = 1.5016e-01, time/batch = 16.6386s	
27485/33150 (epoch 41.456), train_loss = 0.76509988, grad/param norm = 1.7047e-01, time/batch = 16.2311s	
27486/33150 (epoch 41.457), train_loss = 0.82892603, grad/param norm = 1.9105e-01, time/batch = 18.9653s	
27487/33150 (epoch 41.459), train_loss = 0.95087811, grad/param norm = 2.5570e-01, time/batch = 16.3879s	
27488/33150 (epoch 41.460), train_loss = 0.88050189, grad/param norm = 1.6456e-01, time/batch = 16.9941s	
27489/33150 (epoch 41.462), train_loss = 0.93619947, grad/param norm = 2.2433e-01, time/batch = 16.7362s	
27490/33150 (epoch 41.463), train_loss = 1.06576182, grad/param norm = 2.5858e-01, time/batch = 18.2968s	
27491/33150 (epoch 41.465), train_loss = 0.88859298, grad/param norm = 1.7961e-01, time/batch = 17.6502s	
27492/33150 (epoch 41.466), train_loss = 0.79990657, grad/param norm = 1.9242e-01, time/batch = 17.6129s	
27493/33150 (epoch 41.468), train_loss = 1.02658663, grad/param norm = 2.0460e-01, time/batch = 19.2157s	
27494/33150 (epoch 41.469), train_loss = 0.77349872, grad/param norm = 1.8378e-01, time/batch = 16.7271s	
27495/33150 (epoch 41.471), train_loss = 0.78002928, grad/param norm = 1.7432e-01, time/batch = 17.8875s	
27496/33150 (epoch 41.472), train_loss = 0.85337250, grad/param norm = 1.8634e-01, time/batch = 17.1231s	
27497/33150 (epoch 41.474), train_loss = 0.89309490, grad/param norm = 2.2186e-01, time/batch = 17.3164s	
27498/33150 (epoch 41.475), train_loss = 1.06562773, grad/param norm = 1.9201e-01, time/batch = 18.8808s	
27499/33150 (epoch 41.477), train_loss = 0.87582672, grad/param norm = 1.6896e-01, time/batch = 19.9697s	
27500/33150 (epoch 41.478), train_loss = 0.84773680, grad/param norm = 1.7360e-01, time/batch = 16.8832s	
27501/33150 (epoch 41.480), train_loss = 0.77501852, grad/param norm = 1.8079e-01, time/batch = 18.6360s	
27502/33150 (epoch 41.481), train_loss = 0.71317713, grad/param norm = 1.6788e-01, time/batch = 19.2217s	
27503/33150 (epoch 41.483), train_loss = 0.79013106, grad/param norm = 1.7949e-01, time/batch = 19.2376s	
27504/33150 (epoch 41.484), train_loss = 0.74018278, grad/param norm = 1.7292e-01, time/batch = 17.2001s	
27505/33150 (epoch 41.486), train_loss = 0.77535687, grad/param norm = 1.8128e-01, time/batch = 18.1448s	
27506/33150 (epoch 41.487), train_loss = 0.89416655, grad/param norm = 1.8589e-01, time/batch = 17.8197s	
27507/33150 (epoch 41.489), train_loss = 0.81878964, grad/param norm = 1.7627e-01, time/batch = 17.0603s	
27508/33150 (epoch 41.490), train_loss = 0.65250742, grad/param norm = 1.4297e-01, time/batch = 16.8140s	
27509/33150 (epoch 41.492), train_loss = 0.80186213, grad/param norm = 1.9224e-01, time/batch = 17.5351s	
27510/33150 (epoch 41.493), train_loss = 0.88033397, grad/param norm = 1.8250e-01, time/batch = 18.4531s	
27511/33150 (epoch 41.495), train_loss = 0.88084615, grad/param norm = 1.6580e-01, time/batch = 18.3613s	
27512/33150 (epoch 41.496), train_loss = 0.80245122, grad/param norm = 1.7106e-01, time/batch = 16.1382s	
27513/33150 (epoch 41.498), train_loss = 0.89908388, grad/param norm = 2.1501e-01, time/batch = 19.2245s	
27514/33150 (epoch 41.499), train_loss = 0.94029624, grad/param norm = 1.9395e-01, time/batch = 17.4672s	
27515/33150 (epoch 41.501), train_loss = 0.87312305, grad/param norm = 2.2006e-01, time/batch = 19.2071s	
27516/33150 (epoch 41.502), train_loss = 0.93645759, grad/param norm = 2.1607e-01, time/batch = 17.8002s	
27517/33150 (epoch 41.504), train_loss = 0.90682530, grad/param norm = 1.8470e-01, time/batch = 16.3990s	
27518/33150 (epoch 41.505), train_loss = 0.95507731, grad/param norm = 1.9307e-01, time/batch = 18.4812s	
27519/33150 (epoch 41.507), train_loss = 0.79679344, grad/param norm = 2.0702e-01, time/batch = 18.3221s	
27520/33150 (epoch 41.508), train_loss = 0.78379921, grad/param norm = 2.0410e-01, time/batch = 17.8854s	
27521/33150 (epoch 41.510), train_loss = 0.89790783, grad/param norm = 1.5644e-01, time/batch = 16.9001s	
27522/33150 (epoch 41.511), train_loss = 0.93125388, grad/param norm = 1.8564e-01, time/batch = 15.0450s	
27523/33150 (epoch 41.513), train_loss = 0.85409701, grad/param norm = 2.0033e-01, time/batch = 15.1984s	
27524/33150 (epoch 41.514), train_loss = 0.72235076, grad/param norm = 1.7858e-01, time/batch = 15.4682s	
27525/33150 (epoch 41.516), train_loss = 0.86100793, grad/param norm = 2.3103e-01, time/batch = 15.2701s	
27526/33150 (epoch 41.517), train_loss = 0.89648864, grad/param norm = 1.9224e-01, time/batch = 15.0995s	
27527/33150 (epoch 41.519), train_loss = 0.77517758, grad/param norm = 1.7795e-01, time/batch = 15.4257s	
27528/33150 (epoch 41.520), train_loss = 0.83570705, grad/param norm = 1.7566e-01, time/batch = 15.4629s	
27529/33150 (epoch 41.522), train_loss = 0.90282666, grad/param norm = 1.8523e-01, time/batch = 16.0285s	
27530/33150 (epoch 41.523), train_loss = 0.74082800, grad/param norm = 1.8466e-01, time/batch = 16.4617s	
27531/33150 (epoch 41.525), train_loss = 0.88708444, grad/param norm = 2.0039e-01, time/batch = 16.0630s	
27532/33150 (epoch 41.526), train_loss = 0.75868305, grad/param norm = 1.6356e-01, time/batch = 15.8750s	
27533/33150 (epoch 41.528), train_loss = 0.85133227, grad/param norm = 1.7780e-01, time/batch = 16.5383s	
27534/33150 (epoch 41.529), train_loss = 0.82538433, grad/param norm = 2.0590e-01, time/batch = 17.5544s	
27535/33150 (epoch 41.531), train_loss = 0.72011090, grad/param norm = 1.9955e-01, time/batch = 16.4632s	
27536/33150 (epoch 41.532), train_loss = 0.84734779, grad/param norm = 2.0735e-01, time/batch = 17.6349s	
27537/33150 (epoch 41.534), train_loss = 0.82275904, grad/param norm = 1.6997e-01, time/batch = 17.4695s	
27538/33150 (epoch 41.535), train_loss = 0.76821494, grad/param norm = 2.5381e-01, time/batch = 18.7786s	
27539/33150 (epoch 41.537), train_loss = 0.85258184, grad/param norm = 1.9804e-01, time/batch = 16.3688s	
27540/33150 (epoch 41.538), train_loss = 0.75031365, grad/param norm = 1.7588e-01, time/batch = 18.5460s	
27541/33150 (epoch 41.540), train_loss = 0.74762958, grad/param norm = 2.0254e-01, time/batch = 16.7886s	
27542/33150 (epoch 41.541), train_loss = 0.90753804, grad/param norm = 1.8804e-01, time/batch = 16.7287s	
27543/33150 (epoch 41.543), train_loss = 0.83923702, grad/param norm = 1.7769e-01, time/batch = 16.6361s	
27544/33150 (epoch 41.544), train_loss = 0.90358722, grad/param norm = 1.9824e-01, time/batch = 16.5451s	
27545/33150 (epoch 41.546), train_loss = 0.76936144, grad/param norm = 1.7695e-01, time/batch = 17.7196s	
27546/33150 (epoch 41.548), train_loss = 0.80485810, grad/param norm = 2.0574e-01, time/batch = 17.1828s	
27547/33150 (epoch 41.549), train_loss = 0.79474365, grad/param norm = 1.9463e-01, time/batch = 18.2987s	
27548/33150 (epoch 41.551), train_loss = 0.75825478, grad/param norm = 1.6007e-01, time/batch = 17.6975s	
27549/33150 (epoch 41.552), train_loss = 0.63661579, grad/param norm = 1.3227e-01, time/batch = 16.8857s	
27550/33150 (epoch 41.554), train_loss = 0.89733352, grad/param norm = 1.9273e-01, time/batch = 18.3084s	
27551/33150 (epoch 41.555), train_loss = 0.94467776, grad/param norm = 2.2985e-01, time/batch = 18.1237s	
27552/33150 (epoch 41.557), train_loss = 0.70980308, grad/param norm = 1.9159e-01, time/batch = 16.3795s	
27553/33150 (epoch 41.558), train_loss = 0.86399316, grad/param norm = 2.4399e-01, time/batch = 16.8897s	
27554/33150 (epoch 41.560), train_loss = 0.75135762, grad/param norm = 1.6429e-01, time/batch = 18.3200s	
27555/33150 (epoch 41.561), train_loss = 0.70061964, grad/param norm = 1.9132e-01, time/batch = 19.8039s	
27556/33150 (epoch 41.563), train_loss = 0.87716789, grad/param norm = 2.2868e-01, time/batch = 16.3876s	
27557/33150 (epoch 41.564), train_loss = 0.91426073, grad/param norm = 1.7894e-01, time/batch = 19.3003s	
27558/33150 (epoch 41.566), train_loss = 0.74502714, grad/param norm = 1.8059e-01, time/batch = 15.9595s	
27559/33150 (epoch 41.567), train_loss = 0.80486611, grad/param norm = 1.8691e-01, time/batch = 18.7173s	
27560/33150 (epoch 41.569), train_loss = 0.84307594, grad/param norm = 2.2636e-01, time/batch = 17.4686s	
27561/33150 (epoch 41.570), train_loss = 0.88043473, grad/param norm = 1.6335e-01, time/batch = 17.2721s	
27562/33150 (epoch 41.572), train_loss = 0.76713750, grad/param norm = 2.0937e-01, time/batch = 19.2036s	
27563/33150 (epoch 41.573), train_loss = 0.70795393, grad/param norm = 1.5329e-01, time/batch = 17.8877s	
27564/33150 (epoch 41.575), train_loss = 0.78453801, grad/param norm = 1.7272e-01, time/batch = 19.9682s	
27565/33150 (epoch 41.576), train_loss = 0.72654215, grad/param norm = 1.5578e-01, time/batch = 18.2893s	
27566/33150 (epoch 41.578), train_loss = 0.76678790, grad/param norm = 1.7719e-01, time/batch = 16.5469s	
27567/33150 (epoch 41.579), train_loss = 0.72525499, grad/param norm = 2.0106e-01, time/batch = 18.4802s	
27568/33150 (epoch 41.581), train_loss = 0.73011627, grad/param norm = 1.7603e-01, time/batch = 18.9030s	
27569/33150 (epoch 41.582), train_loss = 0.93148170, grad/param norm = 1.6094e-01, time/batch = 17.2195s	
27570/33150 (epoch 41.584), train_loss = 0.91124734, grad/param norm = 2.0384e-01, time/batch = 17.7274s	
27571/33150 (epoch 41.585), train_loss = 0.82018566, grad/param norm = 1.7110e-01, time/batch = 17.1357s	
27572/33150 (epoch 41.587), train_loss = 0.83159842, grad/param norm = 1.8630e-01, time/batch = 21.6602s	
27573/33150 (epoch 41.588), train_loss = 0.75125110, grad/param norm = 1.6687e-01, time/batch = 29.4956s	
27574/33150 (epoch 41.590), train_loss = 0.84543595, grad/param norm = 1.8580e-01, time/batch = 19.7987s	
27575/33150 (epoch 41.591), train_loss = 0.83178390, grad/param norm = 1.7340e-01, time/batch = 16.6372s	
27576/33150 (epoch 41.593), train_loss = 0.88027445, grad/param norm = 2.0970e-01, time/batch = 17.9831s	
27577/33150 (epoch 41.594), train_loss = 0.79548350, grad/param norm = 1.8043e-01, time/batch = 16.4749s	
27578/33150 (epoch 41.596), train_loss = 0.79213538, grad/param norm = 1.6938e-01, time/batch = 17.6257s	
27579/33150 (epoch 41.597), train_loss = 0.73500700, grad/param norm = 2.5134e-01, time/batch = 16.9627s	
27580/33150 (epoch 41.599), train_loss = 0.98098123, grad/param norm = 2.7599e-01, time/batch = 19.9716s	
27581/33150 (epoch 41.600), train_loss = 0.82579322, grad/param norm = 2.4030e-01, time/batch = 17.7042s	
27582/33150 (epoch 41.602), train_loss = 0.84594294, grad/param norm = 2.2039e-01, time/batch = 17.7933s	
27583/33150 (epoch 41.603), train_loss = 0.93031176, grad/param norm = 1.9679e-01, time/batch = 19.2151s	
27584/33150 (epoch 41.605), train_loss = 0.73325627, grad/param norm = 1.6004e-01, time/batch = 17.8096s	
27585/33150 (epoch 41.606), train_loss = 0.77860311, grad/param norm = 2.0519e-01, time/batch = 16.6330s	
27586/33150 (epoch 41.608), train_loss = 0.92354669, grad/param norm = 2.0126e-01, time/batch = 18.5516s	
27587/33150 (epoch 41.609), train_loss = 0.81435763, grad/param norm = 1.9992e-01, time/batch = 18.1392s	
27588/33150 (epoch 41.611), train_loss = 0.75905587, grad/param norm = 1.8714e-01, time/batch = 16.5593s	
27589/33150 (epoch 41.612), train_loss = 0.79904727, grad/param norm = 1.9823e-01, time/batch = 18.2954s	
27590/33150 (epoch 41.614), train_loss = 0.76360105, grad/param norm = 1.7538e-01, time/batch = 16.7985s	
27591/33150 (epoch 41.615), train_loss = 0.72735137, grad/param norm = 1.8159e-01, time/batch = 19.0391s	
27592/33150 (epoch 41.617), train_loss = 0.85090291, grad/param norm = 1.9566e-01, time/batch = 17.0604s	
27593/33150 (epoch 41.618), train_loss = 0.86296614, grad/param norm = 1.8742e-01, time/batch = 19.8802s	
27594/33150 (epoch 41.620), train_loss = 0.80703101, grad/param norm = 1.9992e-01, time/batch = 18.2314s	
27595/33150 (epoch 41.621), train_loss = 0.85058729, grad/param norm = 1.7834e-01, time/batch = 16.5681s	
27596/33150 (epoch 41.623), train_loss = 0.86592885, grad/param norm = 1.6912e-01, time/batch = 18.0637s	
27597/33150 (epoch 41.624), train_loss = 0.79577515, grad/param norm = 1.7340e-01, time/batch = 18.6370s	
27598/33150 (epoch 41.626), train_loss = 0.83096708, grad/param norm = 1.7797e-01, time/batch = 18.0341s	
27599/33150 (epoch 41.627), train_loss = 0.78799444, grad/param norm = 1.7881e-01, time/batch = 17.0500s	
27600/33150 (epoch 41.629), train_loss = 0.68855237, grad/param norm = 1.6356e-01, time/batch = 16.6374s	
27601/33150 (epoch 41.630), train_loss = 0.80829163, grad/param norm = 1.7884e-01, time/batch = 15.9747s	
27602/33150 (epoch 41.632), train_loss = 0.72133595, grad/param norm = 1.6213e-01, time/batch = 17.1408s	
27603/33150 (epoch 41.633), train_loss = 0.75817842, grad/param norm = 1.8776e-01, time/batch = 17.5710s	
27604/33150 (epoch 41.635), train_loss = 0.96131475, grad/param norm = 1.8718e-01, time/batch = 17.5571s	
27605/33150 (epoch 41.637), train_loss = 0.68640148, grad/param norm = 1.9816e-01, time/batch = 16.3077s	
27606/33150 (epoch 41.638), train_loss = 0.80629864, grad/param norm = 1.6848e-01, time/batch = 17.6524s	
27607/33150 (epoch 41.640), train_loss = 0.88416543, grad/param norm = 2.0451e-01, time/batch = 16.7339s	
27608/33150 (epoch 41.641), train_loss = 0.68451186, grad/param norm = 1.7360e-01, time/batch = 17.8072s	
27609/33150 (epoch 41.643), train_loss = 0.82361493, grad/param norm = 1.7182e-01, time/batch = 15.7300s	
27610/33150 (epoch 41.644), train_loss = 0.96371805, grad/param norm = 1.5835e-01, time/batch = 15.2304s	
27611/33150 (epoch 41.646), train_loss = 0.81952504, grad/param norm = 1.5491e-01, time/batch = 18.4777s	
27612/33150 (epoch 41.647), train_loss = 0.98555685, grad/param norm = 1.9057e-01, time/batch = 17.6540s	
27613/33150 (epoch 41.649), train_loss = 0.85296419, grad/param norm = 2.1401e-01, time/batch = 18.0520s	
27614/33150 (epoch 41.650), train_loss = 0.73139622, grad/param norm = 2.0447e-01, time/batch = 18.4023s	
27615/33150 (epoch 41.652), train_loss = 0.91822956, grad/param norm = 2.0276e-01, time/batch = 17.1265s	
27616/33150 (epoch 41.653), train_loss = 0.88064369, grad/param norm = 1.7198e-01, time/batch = 16.7950s	
27617/33150 (epoch 41.655), train_loss = 0.85724215, grad/param norm = 2.0170e-01, time/batch = 18.4763s	
27618/33150 (epoch 41.656), train_loss = 0.79110417, grad/param norm = 1.7123e-01, time/batch = 19.1346s	
27619/33150 (epoch 41.658), train_loss = 0.77951113, grad/param norm = 1.6992e-01, time/batch = 16.1488s	
27620/33150 (epoch 41.659), train_loss = 1.02496887, grad/param norm = 2.4217e-01, time/batch = 18.4864s	
27621/33150 (epoch 41.661), train_loss = 0.81117368, grad/param norm = 1.9114e-01, time/batch = 18.7265s	
27622/33150 (epoch 41.662), train_loss = 0.80257570, grad/param norm = 1.7447e-01, time/batch = 16.6519s	
27623/33150 (epoch 41.664), train_loss = 0.91944631, grad/param norm = 1.8140e-01, time/batch = 16.2213s	
27624/33150 (epoch 41.665), train_loss = 0.90371191, grad/param norm = 1.9044e-01, time/batch = 17.8973s	
27625/33150 (epoch 41.667), train_loss = 0.89661462, grad/param norm = 2.1118e-01, time/batch = 18.4875s	
27626/33150 (epoch 41.668), train_loss = 0.97202812, grad/param norm = 1.8714e-01, time/batch = 17.1435s	
27627/33150 (epoch 41.670), train_loss = 0.79132773, grad/param norm = 1.6844e-01, time/batch = 16.1333s	
27628/33150 (epoch 41.671), train_loss = 0.75828225, grad/param norm = 1.9113e-01, time/batch = 17.6598s	
27629/33150 (epoch 41.673), train_loss = 0.94021985, grad/param norm = 1.6604e-01, time/batch = 17.5563s	
27630/33150 (epoch 41.674), train_loss = 0.88647450, grad/param norm = 2.0043e-01, time/batch = 19.3031s	
27631/33150 (epoch 41.676), train_loss = 0.82438852, grad/param norm = 1.8013e-01, time/batch = 17.9752s	
27632/33150 (epoch 41.677), train_loss = 0.94731560, grad/param norm = 2.0296e-01, time/batch = 17.8856s	
27633/33150 (epoch 41.679), train_loss = 0.82730519, grad/param norm = 1.6344e-01, time/batch = 17.4658s	
27634/33150 (epoch 41.680), train_loss = 0.92044188, grad/param norm = 1.9747e-01, time/batch = 19.3996s	
27635/33150 (epoch 41.682), train_loss = 0.85287663, grad/param norm = 1.7703e-01, time/batch = 18.8996s	
27636/33150 (epoch 41.683), train_loss = 0.71168711, grad/param norm = 1.7035e-01, time/batch = 16.4614s	
27637/33150 (epoch 41.685), train_loss = 0.78363369, grad/param norm = 1.8445e-01, time/batch = 18.8159s	
27638/33150 (epoch 41.686), train_loss = 0.69412738, grad/param norm = 1.6322e-01, time/batch = 19.5459s	
27639/33150 (epoch 41.688), train_loss = 0.73527050, grad/param norm = 1.7699e-01, time/batch = 17.0448s	
27640/33150 (epoch 41.689), train_loss = 0.75908584, grad/param norm = 1.6727e-01, time/batch = 18.8059s	
27641/33150 (epoch 41.691), train_loss = 0.64263590, grad/param norm = 1.4544e-01, time/batch = 19.6283s	
27642/33150 (epoch 41.692), train_loss = 0.73188440, grad/param norm = 1.7479e-01, time/batch = 18.2988s	
27643/33150 (epoch 41.694), train_loss = 0.66360291, grad/param norm = 1.6523e-01, time/batch = 18.6219s	
27644/33150 (epoch 41.695), train_loss = 0.76959441, grad/param norm = 1.6780e-01, time/batch = 19.0497s	
27645/33150 (epoch 41.697), train_loss = 0.72300844, grad/param norm = 1.6068e-01, time/batch = 16.5456s	
27646/33150 (epoch 41.698), train_loss = 0.73343349, grad/param norm = 1.7498e-01, time/batch = 17.6348s	
27647/33150 (epoch 41.700), train_loss = 0.64070515, grad/param norm = 1.4087e-01, time/batch = 18.1506s	
27648/33150 (epoch 41.701), train_loss = 0.70803320, grad/param norm = 1.5747e-01, time/batch = 19.8836s	
27649/33150 (epoch 41.703), train_loss = 0.81504228, grad/param norm = 1.8142e-01, time/batch = 15.2890s	
27650/33150 (epoch 41.704), train_loss = 0.69878300, grad/param norm = 1.4997e-01, time/batch = 17.3840s	
27651/33150 (epoch 41.706), train_loss = 0.74983882, grad/param norm = 1.5931e-01, time/batch = 16.6105s	
27652/33150 (epoch 41.707), train_loss = 0.78689251, grad/param norm = 1.8070e-01, time/batch = 15.9727s	
27653/33150 (epoch 41.709), train_loss = 0.82156110, grad/param norm = 1.6046e-01, time/batch = 17.9753s	
27654/33150 (epoch 41.710), train_loss = 0.82290831, grad/param norm = 2.0553e-01, time/batch = 18.1448s	
27655/33150 (epoch 41.712), train_loss = 0.88877083, grad/param norm = 1.6301e-01, time/batch = 19.3063s	
27656/33150 (epoch 41.713), train_loss = 0.85018100, grad/param norm = 1.7322e-01, time/batch = 17.0212s	
27657/33150 (epoch 41.715), train_loss = 0.79800065, grad/param norm = 1.7297e-01, time/batch = 17.9938s	
27658/33150 (epoch 41.716), train_loss = 0.86429805, grad/param norm = 1.8470e-01, time/batch = 18.2355s	
27659/33150 (epoch 41.718), train_loss = 0.81964776, grad/param norm = 1.7153e-01, time/batch = 17.6250s	
27660/33150 (epoch 41.719), train_loss = 0.88733951, grad/param norm = 2.0732e-01, time/batch = 18.6374s	
27661/33150 (epoch 41.721), train_loss = 0.78532209, grad/param norm = 1.8842e-01, time/batch = 19.0559s	
27662/33150 (epoch 41.722), train_loss = 0.86388610, grad/param norm = 1.6489e-01, time/batch = 17.4626s	
27663/33150 (epoch 41.724), train_loss = 0.79621684, grad/param norm = 1.8849e-01, time/batch = 18.1278s	
27664/33150 (epoch 41.725), train_loss = 0.88093575, grad/param norm = 2.1293e-01, time/batch = 18.3975s	
27665/33150 (epoch 41.727), train_loss = 0.84817414, grad/param norm = 1.7751e-01, time/batch = 18.5580s	
27666/33150 (epoch 41.729), train_loss = 0.81929886, grad/param norm = 1.7747e-01, time/batch = 15.8969s	
27667/33150 (epoch 41.730), train_loss = 0.83349278, grad/param norm = 1.7743e-01, time/batch = 17.7275s	
27668/33150 (epoch 41.732), train_loss = 0.86650137, grad/param norm = 1.7554e-01, time/batch = 19.2967s	
27669/33150 (epoch 41.733), train_loss = 0.71957122, grad/param norm = 1.3677e-01, time/batch = 17.1401s	
27670/33150 (epoch 41.735), train_loss = 0.75074528, grad/param norm = 1.8136e-01, time/batch = 17.9755s	
27671/33150 (epoch 41.736), train_loss = 0.76986712, grad/param norm = 1.7027e-01, time/batch = 19.5421s	
27672/33150 (epoch 41.738), train_loss = 0.83030558, grad/param norm = 2.1024e-01, time/batch = 17.0480s	
27673/33150 (epoch 41.739), train_loss = 0.91405648, grad/param norm = 1.8139e-01, time/batch = 18.7130s	
27674/33150 (epoch 41.741), train_loss = 0.84084897, grad/param norm = 2.0676e-01, time/batch = 17.3542s	
27675/33150 (epoch 41.742), train_loss = 0.68383769, grad/param norm = 1.6998e-01, time/batch = 15.6981s	
27676/33150 (epoch 41.744), train_loss = 0.87153705, grad/param norm = 1.7853e-01, time/batch = 15.5748s	
27677/33150 (epoch 41.745), train_loss = 0.76712294, grad/param norm = 1.6191e-01, time/batch = 15.0963s	
27678/33150 (epoch 41.747), train_loss = 0.61094478, grad/param norm = 1.6489e-01, time/batch = 15.5737s	
27679/33150 (epoch 41.748), train_loss = 0.68857787, grad/param norm = 1.7851e-01, time/batch = 15.4149s	
27680/33150 (epoch 41.750), train_loss = 0.82897152, grad/param norm = 1.7059e-01, time/batch = 15.5719s	
27681/33150 (epoch 41.751), train_loss = 0.79757326, grad/param norm = 1.6372e-01, time/batch = 17.9618s	
27682/33150 (epoch 41.753), train_loss = 0.70963133, grad/param norm = 1.8403e-01, time/batch = 17.6374s	
27683/33150 (epoch 41.754), train_loss = 0.99690281, grad/param norm = 2.1364e-01, time/batch = 17.7098s	
27684/33150 (epoch 41.756), train_loss = 0.82237124, grad/param norm = 2.8201e-01, time/batch = 16.0228s	
27685/33150 (epoch 41.757), train_loss = 0.84853158, grad/param norm = 1.7931e-01, time/batch = 16.2314s	
27686/33150 (epoch 41.759), train_loss = 0.93820558, grad/param norm = 2.3532e-01, time/batch = 18.3069s	
27687/33150 (epoch 41.760), train_loss = 0.87636637, grad/param norm = 1.9284e-01, time/batch = 16.4677s	
27688/33150 (epoch 41.762), train_loss = 0.82139887, grad/param norm = 2.0387e-01, time/batch = 17.4760s	
27689/33150 (epoch 41.763), train_loss = 0.83865686, grad/param norm = 1.7744e-01, time/batch = 17.1465s	
27690/33150 (epoch 41.765), train_loss = 0.80704965, grad/param norm = 1.7794e-01, time/batch = 16.0219s	
27691/33150 (epoch 41.766), train_loss = 0.70053696, grad/param norm = 1.7008e-01, time/batch = 16.1984s	
27692/33150 (epoch 41.768), train_loss = 0.74493926, grad/param norm = 1.6394e-01, time/batch = 17.1407s	
27693/33150 (epoch 41.769), train_loss = 0.89105409, grad/param norm = 1.7606e-01, time/batch = 18.3804s	
27694/33150 (epoch 41.771), train_loss = 0.83010276, grad/param norm = 1.6631e-01, time/batch = 15.8718s	
27695/33150 (epoch 41.772), train_loss = 0.85421576, grad/param norm = 1.9430e-01, time/batch = 17.5606s	
27696/33150 (epoch 41.774), train_loss = 0.95545763, grad/param norm = 1.8249e-01, time/batch = 17.0379s	
27697/33150 (epoch 41.775), train_loss = 0.85022999, grad/param norm = 2.3186e-01, time/batch = 16.9705s	
27698/33150 (epoch 41.777), train_loss = 0.86280150, grad/param norm = 1.8589e-01, time/batch = 17.2073s	
27699/33150 (epoch 41.778), train_loss = 0.80155415, grad/param norm = 1.7802e-01, time/batch = 18.3868s	
27700/33150 (epoch 41.780), train_loss = 0.69061545, grad/param norm = 1.5192e-01, time/batch = 17.6272s	
27701/33150 (epoch 41.781), train_loss = 0.80778538, grad/param norm = 1.7638e-01, time/batch = 16.8847s	
27702/33150 (epoch 41.783), train_loss = 0.81656532, grad/param norm = 1.7940e-01, time/batch = 15.9435s	
27703/33150 (epoch 41.784), train_loss = 0.82593217, grad/param norm = 1.9700e-01, time/batch = 15.4403s	
27704/33150 (epoch 41.786), train_loss = 0.80079055, grad/param norm = 1.7997e-01, time/batch = 16.0969s	
27705/33150 (epoch 41.787), train_loss = 0.73968844, grad/param norm = 1.6060e-01, time/batch = 17.1492s	
27706/33150 (epoch 41.789), train_loss = 0.68426467, grad/param norm = 1.4375e-01, time/batch = 16.2383s	
27707/33150 (epoch 41.790), train_loss = 0.69296838, grad/param norm = 1.6106e-01, time/batch = 18.8093s	
27708/33150 (epoch 41.792), train_loss = 0.80565775, grad/param norm = 1.9399e-01, time/batch = 15.5448s	
27709/33150 (epoch 41.793), train_loss = 0.78542973, grad/param norm = 1.9677e-01, time/batch = 18.3863s	
27710/33150 (epoch 41.795), train_loss = 0.77348918, grad/param norm = 1.9628e-01, time/batch = 16.9046s	
27711/33150 (epoch 41.796), train_loss = 0.79562492, grad/param norm = 1.6564e-01, time/batch = 17.3854s	
27712/33150 (epoch 41.798), train_loss = 0.73638941, grad/param norm = 1.4801e-01, time/batch = 16.6576s	
27713/33150 (epoch 41.799), train_loss = 0.67616760, grad/param norm = 1.7704e-01, time/batch = 16.6285s	
27714/33150 (epoch 41.801), train_loss = 0.83513139, grad/param norm = 1.9198e-01, time/batch = 17.8180s	
27715/33150 (epoch 41.802), train_loss = 0.78906325, grad/param norm = 2.0010e-01, time/batch = 15.9921s	
27716/33150 (epoch 41.804), train_loss = 0.75893200, grad/param norm = 1.8029e-01, time/batch = 18.2329s	
27717/33150 (epoch 41.805), train_loss = 0.74367615, grad/param norm = 1.7378e-01, time/batch = 15.8968s	
27718/33150 (epoch 41.807), train_loss = 0.80500238, grad/param norm = 1.5603e-01, time/batch = 15.4422s	
27719/33150 (epoch 41.808), train_loss = 0.89518699, grad/param norm = 1.8819e-01, time/batch = 16.7265s	
27720/33150 (epoch 41.810), train_loss = 0.73104047, grad/param norm = 1.8123e-01, time/batch = 16.2784s	
27721/33150 (epoch 41.811), train_loss = 0.80074672, grad/param norm = 1.8634e-01, time/batch = 18.9801s	
27722/33150 (epoch 41.813), train_loss = 0.77321127, grad/param norm = 1.5706e-01, time/batch = 17.2220s	
27723/33150 (epoch 41.814), train_loss = 0.75882711, grad/param norm = 2.0636e-01, time/batch = 18.1383s	
27724/33150 (epoch 41.816), train_loss = 0.77561978, grad/param norm = 1.8762e-01, time/batch = 16.9007s	
27725/33150 (epoch 41.817), train_loss = 0.85360637, grad/param norm = 1.8847e-01, time/batch = 15.9670s	
27726/33150 (epoch 41.819), train_loss = 0.82391355, grad/param norm = 1.7556e-01, time/batch = 17.7185s	
27727/33150 (epoch 41.821), train_loss = 0.73163460, grad/param norm = 1.4780e-01, time/batch = 16.2207s	
27728/33150 (epoch 41.822), train_loss = 0.74452699, grad/param norm = 1.5141e-01, time/batch = 17.7309s	
27729/33150 (epoch 41.824), train_loss = 0.83052456, grad/param norm = 1.9355e-01, time/batch = 16.3141s	
27730/33150 (epoch 41.825), train_loss = 0.84997675, grad/param norm = 1.9353e-01, time/batch = 17.6315s	
27731/33150 (epoch 41.827), train_loss = 0.86101304, grad/param norm = 1.9236e-01, time/batch = 17.8945s	
27732/33150 (epoch 41.828), train_loss = 0.73820710, grad/param norm = 2.0522e-01, time/batch = 16.5692s	
27733/33150 (epoch 41.830), train_loss = 0.87029635, grad/param norm = 1.9188e-01, time/batch = 17.8126s	
27734/33150 (epoch 41.831), train_loss = 0.76535233, grad/param norm = 1.8114e-01, time/batch = 17.3175s	
27735/33150 (epoch 41.833), train_loss = 0.72938953, grad/param norm = 1.6812e-01, time/batch = 18.0632s	
27736/33150 (epoch 41.834), train_loss = 0.89040650, grad/param norm = 1.7767e-01, time/batch = 17.0573s	
27737/33150 (epoch 41.836), train_loss = 0.92235607, grad/param norm = 1.7459e-01, time/batch = 17.1421s	
27738/33150 (epoch 41.837), train_loss = 0.74707198, grad/param norm = 2.4417e-01, time/batch = 17.8136s	
27739/33150 (epoch 41.839), train_loss = 0.88646275, grad/param norm = 1.8562e-01, time/batch = 15.7136s	
27740/33150 (epoch 41.840), train_loss = 0.85764478, grad/param norm = 1.8340e-01, time/batch = 18.3696s	
27741/33150 (epoch 41.842), train_loss = 0.90179813, grad/param norm = 2.6063e-01, time/batch = 17.4015s	
27742/33150 (epoch 41.843), train_loss = 0.90872646, grad/param norm = 1.9594e-01, time/batch = 17.3972s	
27743/33150 (epoch 41.845), train_loss = 0.77886840, grad/param norm = 1.8455e-01, time/batch = 16.3066s	
27744/33150 (epoch 41.846), train_loss = 0.99441172, grad/param norm = 3.1126e-01, time/batch = 18.1599s	
27745/33150 (epoch 41.848), train_loss = 0.89484519, grad/param norm = 2.3141e-01, time/batch = 16.0596s	
27746/33150 (epoch 41.849), train_loss = 0.90170671, grad/param norm = 1.7933e-01, time/batch = 15.9578s	
27747/33150 (epoch 41.851), train_loss = 0.89088834, grad/param norm = 2.4460e-01, time/batch = 17.9786s	
27748/33150 (epoch 41.852), train_loss = 0.94481460, grad/param norm = 1.8346e-01, time/batch = 17.9815s	
27749/33150 (epoch 41.854), train_loss = 0.85591328, grad/param norm = 1.9486e-01, time/batch = 16.6264s	
27750/33150 (epoch 41.855), train_loss = 0.76201345, grad/param norm = 3.0065e-01, time/batch = 16.4038s	
27751/33150 (epoch 41.857), train_loss = 0.68176396, grad/param norm = 1.8719e-01, time/batch = 17.7381s	
27752/33150 (epoch 41.858), train_loss = 0.78330486, grad/param norm = 1.6903e-01, time/batch = 17.3169s	
27753/33150 (epoch 41.860), train_loss = 0.74020243, grad/param norm = 1.5607e-01, time/batch = 15.8323s	
27754/33150 (epoch 41.861), train_loss = 0.71290981, grad/param norm = 1.6288e-01, time/batch = 16.3992s	
27755/33150 (epoch 41.863), train_loss = 0.78528366, grad/param norm = 1.6226e-01, time/batch = 15.7346s	
27756/33150 (epoch 41.864), train_loss = 0.82748959, grad/param norm = 1.7790e-01, time/batch = 14.9012s	
27757/33150 (epoch 41.866), train_loss = 0.89476259, grad/param norm = 2.2634e-01, time/batch = 16.4603s	
27758/33150 (epoch 41.867), train_loss = 0.81841038, grad/param norm = 1.6785e-01, time/batch = 18.3122s	
27759/33150 (epoch 41.869), train_loss = 0.84461423, grad/param norm = 1.9469e-01, time/batch = 19.0666s	
27760/33150 (epoch 41.870), train_loss = 0.76532767, grad/param norm = 2.1767e-01, time/batch = 16.3062s	
27761/33150 (epoch 41.872), train_loss = 0.87800241, grad/param norm = 2.1181e-01, time/batch = 16.0540s	
27762/33150 (epoch 41.873), train_loss = 0.67720956, grad/param norm = 1.4477e-01, time/batch = 17.2968s	
27763/33150 (epoch 41.875), train_loss = 0.90416170, grad/param norm = 1.8337e-01, time/batch = 17.6630s	
27764/33150 (epoch 41.876), train_loss = 0.66717880, grad/param norm = 1.5389e-01, time/batch = 17.3011s	
27765/33150 (epoch 41.878), train_loss = 0.76749505, grad/param norm = 1.7783e-01, time/batch = 16.6577s	
27766/33150 (epoch 41.879), train_loss = 0.74809401, grad/param norm = 1.5834e-01, time/batch = 18.2342s	
27767/33150 (epoch 41.881), train_loss = 0.75137987, grad/param norm = 1.6300e-01, time/batch = 17.3008s	
27768/33150 (epoch 41.882), train_loss = 0.62487357, grad/param norm = 1.4712e-01, time/batch = 17.5655s	
27769/33150 (epoch 41.884), train_loss = 0.75461402, grad/param norm = 1.6362e-01, time/batch = 16.5830s	
27770/33150 (epoch 41.885), train_loss = 0.61647276, grad/param norm = 1.6919e-01, time/batch = 18.6478s	
27771/33150 (epoch 41.887), train_loss = 0.88162705, grad/param norm = 1.7965e-01, time/batch = 17.2264s	
27772/33150 (epoch 41.888), train_loss = 0.81656072, grad/param norm = 1.7829e-01, time/batch = 18.1390s	
27773/33150 (epoch 41.890), train_loss = 0.71506482, grad/param norm = 1.6639e-01, time/batch = 17.0585s	
27774/33150 (epoch 41.891), train_loss = 0.71562627, grad/param norm = 1.5551e-01, time/batch = 16.5553s	
27775/33150 (epoch 41.893), train_loss = 0.85879997, grad/param norm = 1.7522e-01, time/batch = 18.4031s	
27776/33150 (epoch 41.894), train_loss = 0.83504939, grad/param norm = 1.5693e-01, time/batch = 15.9867s	
27777/33150 (epoch 41.896), train_loss = 0.79881141, grad/param norm = 1.7480e-01, time/batch = 18.3805s	
27778/33150 (epoch 41.897), train_loss = 0.84853381, grad/param norm = 1.6203e-01, time/batch = 29.6630s	
27779/33150 (epoch 41.899), train_loss = 0.66102220, grad/param norm = 1.7471e-01, time/batch = 18.3206s	
27780/33150 (epoch 41.900), train_loss = 0.96969895, grad/param norm = 1.9138e-01, time/batch = 16.7381s	
27781/33150 (epoch 41.902), train_loss = 1.00351348, grad/param norm = 1.8141e-01, time/batch = 19.8020s	
27782/33150 (epoch 41.903), train_loss = 0.84351867, grad/param norm = 1.8478e-01, time/batch = 16.5701s	
27783/33150 (epoch 41.905), train_loss = 0.80713342, grad/param norm = 1.6217e-01, time/batch = 17.8869s	
27784/33150 (epoch 41.906), train_loss = 0.82148251, grad/param norm = 1.9525e-01, time/batch = 16.8942s	
27785/33150 (epoch 41.908), train_loss = 0.86368587, grad/param norm = 1.8327e-01, time/batch = 18.7336s	
27786/33150 (epoch 41.910), train_loss = 0.88766143, grad/param norm = 1.8207e-01, time/batch = 18.0407s	
27787/33150 (epoch 41.911), train_loss = 0.70204895, grad/param norm = 1.6567e-01, time/batch = 17.3865s	
27788/33150 (epoch 41.913), train_loss = 0.76436346, grad/param norm = 1.7051e-01, time/batch = 17.0764s	
27789/33150 (epoch 41.914), train_loss = 0.81011369, grad/param norm = 1.6714e-01, time/batch = 17.3906s	
27790/33150 (epoch 41.916), train_loss = 0.74181797, grad/param norm = 1.6769e-01, time/batch = 16.4715s	
27791/33150 (epoch 41.917), train_loss = 0.83368314, grad/param norm = 1.9594e-01, time/batch = 18.4731s	
27792/33150 (epoch 41.919), train_loss = 0.94462469, grad/param norm = 2.3564e-01, time/batch = 15.5582s	
27793/33150 (epoch 41.920), train_loss = 0.91037874, grad/param norm = 2.0168e-01, time/batch = 19.0587s	
27794/33150 (epoch 41.922), train_loss = 0.93010705, grad/param norm = 2.1037e-01, time/batch = 15.1410s	
27795/33150 (epoch 41.923), train_loss = 0.83856093, grad/param norm = 2.0366e-01, time/batch = 16.6352s	
27796/33150 (epoch 41.925), train_loss = 0.93206345, grad/param norm = 2.3443e-01, time/batch = 17.9716s	
27797/33150 (epoch 41.926), train_loss = 0.80897512, grad/param norm = 1.9153e-01, time/batch = 16.7899s	
27798/33150 (epoch 41.928), train_loss = 0.79616364, grad/param norm = 1.8853e-01, time/batch = 17.8078s	
27799/33150 (epoch 41.929), train_loss = 0.87004040, grad/param norm = 1.9527e-01, time/batch = 16.8113s	
27800/33150 (epoch 41.931), train_loss = 0.91405321, grad/param norm = 1.9008e-01, time/batch = 19.5562s	
27801/33150 (epoch 41.932), train_loss = 0.83322014, grad/param norm = 1.9531e-01, time/batch = 17.2149s	
27802/33150 (epoch 41.934), train_loss = 0.83680271, grad/param norm = 1.6617e-01, time/batch = 19.7958s	
27803/33150 (epoch 41.935), train_loss = 0.90856881, grad/param norm = 1.9027e-01, time/batch = 18.7154s	
27804/33150 (epoch 41.937), train_loss = 0.93520122, grad/param norm = 1.7724e-01, time/batch = 15.7220s	
27805/33150 (epoch 41.938), train_loss = 0.84518003, grad/param norm = 1.6733e-01, time/batch = 19.5440s	
27806/33150 (epoch 41.940), train_loss = 1.04677071, grad/param norm = 2.2821e-01, time/batch = 15.4582s	
27807/33150 (epoch 41.941), train_loss = 0.86776442, grad/param norm = 1.6690e-01, time/batch = 16.4657s	
27808/33150 (epoch 41.943), train_loss = 0.67670629, grad/param norm = 1.7021e-01, time/batch = 18.6300s	
27809/33150 (epoch 41.944), train_loss = 0.87843119, grad/param norm = 2.0367e-01, time/batch = 18.8090s	
27810/33150 (epoch 41.946), train_loss = 0.72385619, grad/param norm = 1.4137e-01, time/batch = 19.2160s	
27811/33150 (epoch 41.947), train_loss = 0.84596539, grad/param norm = 1.7854e-01, time/batch = 18.3615s	
27812/33150 (epoch 41.949), train_loss = 0.91080765, grad/param norm = 1.7173e-01, time/batch = 18.8884s	
27813/33150 (epoch 41.950), train_loss = 0.91604472, grad/param norm = 1.9115e-01, time/batch = 17.1469s	
27814/33150 (epoch 41.952), train_loss = 0.74983954, grad/param norm = 1.6224e-01, time/batch = 16.0627s	
27815/33150 (epoch 41.953), train_loss = 0.81868185, grad/param norm = 1.6517e-01, time/batch = 18.0411s	
27816/33150 (epoch 41.955), train_loss = 0.71323176, grad/param norm = 1.9647e-01, time/batch = 18.1471s	
27817/33150 (epoch 41.956), train_loss = 0.89492184, grad/param norm = 2.0837e-01, time/batch = 17.8940s	
27818/33150 (epoch 41.958), train_loss = 0.75808598, grad/param norm = 1.6179e-01, time/batch = 17.7994s	
27819/33150 (epoch 41.959), train_loss = 0.81210779, grad/param norm = 1.7326e-01, time/batch = 19.0557s	
27820/33150 (epoch 41.961), train_loss = 0.73799530, grad/param norm = 1.7500e-01, time/batch = 19.0447s	
27821/33150 (epoch 41.962), train_loss = 0.67992337, grad/param norm = 1.5908e-01, time/batch = 18.4612s	
27822/33150 (epoch 41.964), train_loss = 0.79726147, grad/param norm = 1.6609e-01, time/batch = 18.4014s	
27823/33150 (epoch 41.965), train_loss = 0.79772655, grad/param norm = 1.9006e-01, time/batch = 16.7075s	
27824/33150 (epoch 41.967), train_loss = 0.79879116, grad/param norm = 1.7886e-01, time/batch = 16.7255s	
27825/33150 (epoch 41.968), train_loss = 0.68135839, grad/param norm = 1.4695e-01, time/batch = 18.3170s	
27826/33150 (epoch 41.970), train_loss = 0.77356577, grad/param norm = 1.8500e-01, time/batch = 19.4599s	
27827/33150 (epoch 41.971), train_loss = 0.81854184, grad/param norm = 1.8670e-01, time/batch = 17.3861s	
27828/33150 (epoch 41.973), train_loss = 0.87962933, grad/param norm = 1.8122e-01, time/batch = 16.2763s	
27829/33150 (epoch 41.974), train_loss = 0.93050851, grad/param norm = 1.9457e-01, time/batch = 15.1120s	
27830/33150 (epoch 41.976), train_loss = 0.90730886, grad/param norm = 1.7644e-01, time/batch = 14.8705s	
27831/33150 (epoch 41.977), train_loss = 0.93423518, grad/param norm = 1.9892e-01, time/batch = 15.0193s	
27832/33150 (epoch 41.979), train_loss = 0.89033065, grad/param norm = 2.0258e-01, time/batch = 14.9992s	
27833/33150 (epoch 41.980), train_loss = 0.96084550, grad/param norm = 1.9147e-01, time/batch = 15.0131s	
27834/33150 (epoch 41.982), train_loss = 0.80860268, grad/param norm = 1.8221e-01, time/batch = 14.7745s	
27835/33150 (epoch 41.983), train_loss = 0.75175034, grad/param norm = 1.9377e-01, time/batch = 15.2695s	
27836/33150 (epoch 41.985), train_loss = 0.92165615, grad/param norm = 1.7459e-01, time/batch = 16.3670s	
27837/33150 (epoch 41.986), train_loss = 0.69509194, grad/param norm = 1.6057e-01, time/batch = 15.7168s	
27838/33150 (epoch 41.988), train_loss = 0.76952464, grad/param norm = 1.9615e-01, time/batch = 17.3004s	
27839/33150 (epoch 41.989), train_loss = 0.79705685, grad/param norm = 1.6278e-01, time/batch = 17.4493s	
27840/33150 (epoch 41.991), train_loss = 0.84939865, grad/param norm = 3.0049e-01, time/batch = 18.7830s	
27841/33150 (epoch 41.992), train_loss = 0.81455127, grad/param norm = 1.8625e-01, time/batch = 17.0302s	
27842/33150 (epoch 41.994), train_loss = 0.82272290, grad/param norm = 1.6918e-01, time/batch = 16.1930s	
27843/33150 (epoch 41.995), train_loss = 0.79104013, grad/param norm = 1.7273e-01, time/batch = 17.2983s	
27844/33150 (epoch 41.997), train_loss = 0.81848361, grad/param norm = 1.7233e-01, time/batch = 16.3704s	
27845/33150 (epoch 41.998), train_loss = 0.69410743, grad/param norm = 1.6470e-01, time/batch = 18.1188s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
27846/33150 (epoch 42.000), train_loss = 0.75060652, grad/param norm = 2.1639e-01, time/batch = 15.4560s	
27847/33150 (epoch 42.002), train_loss = 1.10585581, grad/param norm = 2.0120e-01, time/batch = 15.8128s	
27848/33150 (epoch 42.003), train_loss = 0.71646334, grad/param norm = 1.5270e-01, time/batch = 16.8311s	
27849/33150 (epoch 42.005), train_loss = 0.70524040, grad/param norm = 1.5487e-01, time/batch = 16.4707s	
27850/33150 (epoch 42.006), train_loss = 0.69374197, grad/param norm = 1.7318e-01, time/batch = 16.7271s	
27851/33150 (epoch 42.008), train_loss = 0.87784988, grad/param norm = 2.0471e-01, time/batch = 16.1495s	
27852/33150 (epoch 42.009), train_loss = 0.83224817, grad/param norm = 1.7865e-01, time/batch = 16.6311s	
27853/33150 (epoch 42.011), train_loss = 0.90991687, grad/param norm = 1.8349e-01, time/batch = 15.1188s	
27854/33150 (epoch 42.012), train_loss = 0.78666012, grad/param norm = 2.0351e-01, time/batch = 17.1397s	
27855/33150 (epoch 42.014), train_loss = 0.74366598, grad/param norm = 1.8134e-01, time/batch = 16.6463s	
27856/33150 (epoch 42.015), train_loss = 0.74080603, grad/param norm = 1.8336e-01, time/batch = 16.6351s	
27857/33150 (epoch 42.017), train_loss = 0.73055109, grad/param norm = 1.5987e-01, time/batch = 16.1412s	
27858/33150 (epoch 42.018), train_loss = 0.83943392, grad/param norm = 2.0076e-01, time/batch = 16.8926s	
27859/33150 (epoch 42.020), train_loss = 0.89243394, grad/param norm = 2.2625e-01, time/batch = 15.9821s	
27860/33150 (epoch 42.021), train_loss = 0.73794617, grad/param norm = 1.6087e-01, time/batch = 15.5287s	
27861/33150 (epoch 42.023), train_loss = 0.98143989, grad/param norm = 1.7004e-01, time/batch = 17.9778s	
27862/33150 (epoch 42.024), train_loss = 0.86745571, grad/param norm = 2.0659e-01, time/batch = 19.2831s	
27863/33150 (epoch 42.026), train_loss = 0.64140109, grad/param norm = 1.5353e-01, time/batch = 17.6154s	
27864/33150 (epoch 42.027), train_loss = 0.66033285, grad/param norm = 1.5377e-01, time/batch = 16.7625s	
27865/33150 (epoch 42.029), train_loss = 0.74004768, grad/param norm = 1.8507e-01, time/batch = 17.3029s	
27866/33150 (epoch 42.030), train_loss = 0.80283921, grad/param norm = 1.5091e-01, time/batch = 17.7976s	
27867/33150 (epoch 42.032), train_loss = 0.70416179, grad/param norm = 1.6164e-01, time/batch = 16.9844s	
27868/33150 (epoch 42.033), train_loss = 0.73422740, grad/param norm = 1.6704e-01, time/batch = 17.5746s	
27869/33150 (epoch 42.035), train_loss = 0.96690925, grad/param norm = 2.1915e-01, time/batch = 18.3041s	
27870/33150 (epoch 42.036), train_loss = 0.87766330, grad/param norm = 1.8849e-01, time/batch = 16.2950s	
27871/33150 (epoch 42.038), train_loss = 0.98566576, grad/param norm = 1.8302e-01, time/batch = 18.7954s	
27872/33150 (epoch 42.039), train_loss = 0.88232820, grad/param norm = 1.6993e-01, time/batch = 16.5679s	
27873/33150 (epoch 42.041), train_loss = 0.81535819, grad/param norm = 1.8260e-01, time/batch = 18.0584s	
27874/33150 (epoch 42.042), train_loss = 0.74027929, grad/param norm = 1.6946e-01, time/batch = 17.1418s	
27875/33150 (epoch 42.044), train_loss = 0.82081184, grad/param norm = 1.8640e-01, time/batch = 18.8093s	
27876/33150 (epoch 42.045), train_loss = 0.88045717, grad/param norm = 1.5481e-01, time/batch = 17.4795s	
27877/33150 (epoch 42.047), train_loss = 0.74242916, grad/param norm = 1.8108e-01, time/batch = 16.6340s	
27878/33150 (epoch 42.048), train_loss = 0.88638447, grad/param norm = 2.0094e-01, time/batch = 16.2387s	
27879/33150 (epoch 42.050), train_loss = 0.77682818, grad/param norm = 1.7483e-01, time/batch = 18.9799s	
27880/33150 (epoch 42.051), train_loss = 0.84915749, grad/param norm = 1.6458e-01, time/batch = 18.1482s	
27881/33150 (epoch 42.053), train_loss = 0.85773483, grad/param norm = 1.7873e-01, time/batch = 18.4470s	
27882/33150 (epoch 42.054), train_loss = 0.95432847, grad/param norm = 1.7940e-01, time/batch = 17.6993s	
27883/33150 (epoch 42.056), train_loss = 0.80217386, grad/param norm = 1.6737e-01, time/batch = 17.2084s	
27884/33150 (epoch 42.057), train_loss = 0.87677648, grad/param norm = 1.6616e-01, time/batch = 17.5540s	
27885/33150 (epoch 42.059), train_loss = 0.73338415, grad/param norm = 1.8848e-01, time/batch = 17.5521s	
27886/33150 (epoch 42.060), train_loss = 0.71853641, grad/param norm = 1.4403e-01, time/batch = 17.8878s	
27887/33150 (epoch 42.062), train_loss = 0.80089318, grad/param norm = 1.7963e-01, time/batch = 17.0494s	
27888/33150 (epoch 42.063), train_loss = 0.74105714, grad/param norm = 1.8482e-01, time/batch = 17.8720s	
27889/33150 (epoch 42.065), train_loss = 0.80594660, grad/param norm = 1.7424e-01, time/batch = 18.9767s	
27890/33150 (epoch 42.066), train_loss = 0.78365328, grad/param norm = 1.7601e-01, time/batch = 18.6255s	
27891/33150 (epoch 42.068), train_loss = 0.87158762, grad/param norm = 1.9398e-01, time/batch = 18.0463s	
27892/33150 (epoch 42.069), train_loss = 0.86193394, grad/param norm = 2.1188e-01, time/batch = 18.8023s	
27893/33150 (epoch 42.071), train_loss = 0.84966555, grad/param norm = 1.8701e-01, time/batch = 19.1286s	
27894/33150 (epoch 42.072), train_loss = 0.83395305, grad/param norm = 1.7919e-01, time/batch = 16.6105s	
27895/33150 (epoch 42.074), train_loss = 0.69365523, grad/param norm = 1.7165e-01, time/batch = 18.8950s	
27896/33150 (epoch 42.075), train_loss = 0.71288003, grad/param norm = 1.6860e-01, time/batch = 19.5479s	
27897/33150 (epoch 42.077), train_loss = 0.84733895, grad/param norm = 2.0707e-01, time/batch = 17.3910s	
27898/33150 (epoch 42.078), train_loss = 0.94711933, grad/param norm = 2.0229e-01, time/batch = 16.8041s	
27899/33150 (epoch 42.080), train_loss = 0.94784787, grad/param norm = 1.8066e-01, time/batch = 17.8783s	
27900/33150 (epoch 42.081), train_loss = 0.72193966, grad/param norm = 1.8496e-01, time/batch = 17.5395s	
27901/33150 (epoch 42.083), train_loss = 0.60045642, grad/param norm = 2.1201e-01, time/batch = 17.9674s	
27902/33150 (epoch 42.084), train_loss = 0.68700186, grad/param norm = 1.7257e-01, time/batch = 15.4643s	
27903/33150 (epoch 42.086), train_loss = 0.75812181, grad/param norm = 2.0374e-01, time/batch = 18.6394s	
27904/33150 (epoch 42.087), train_loss = 0.70063648, grad/param norm = 1.8426e-01, time/batch = 17.3020s	
27905/33150 (epoch 42.089), train_loss = 0.73748439, grad/param norm = 1.6036e-01, time/batch = 17.8189s	
27906/33150 (epoch 42.090), train_loss = 0.78354271, grad/param norm = 1.7935e-01, time/batch = 18.0663s	
27907/33150 (epoch 42.092), train_loss = 0.75869208, grad/param norm = 1.8860e-01, time/batch = 17.2188s	
27908/33150 (epoch 42.094), train_loss = 0.83774664, grad/param norm = 2.0213e-01, time/batch = 17.3133s	
27909/33150 (epoch 42.095), train_loss = 0.75005977, grad/param norm = 2.1965e-01, time/batch = 16.1489s	
27910/33150 (epoch 42.097), train_loss = 0.67871400, grad/param norm = 1.6211e-01, time/batch = 16.2161s	
27911/33150 (epoch 42.098), train_loss = 1.03915881, grad/param norm = 2.0086e-01, time/batch = 16.7035s	
27912/33150 (epoch 42.100), train_loss = 0.98228481, grad/param norm = 2.1317e-01, time/batch = 18.2120s	
27913/33150 (epoch 42.101), train_loss = 0.75394023, grad/param norm = 2.1231e-01, time/batch = 19.1350s	
27914/33150 (epoch 42.103), train_loss = 0.82454658, grad/param norm = 1.5981e-01, time/batch = 16.7957s	
27915/33150 (epoch 42.104), train_loss = 0.75850334, grad/param norm = 2.2061e-01, time/batch = 18.3053s	
27916/33150 (epoch 42.106), train_loss = 0.92420141, grad/param norm = 1.9857e-01, time/batch = 18.2979s	
27917/33150 (epoch 42.107), train_loss = 0.98669778, grad/param norm = 2.1960e-01, time/batch = 17.7946s	
27918/33150 (epoch 42.109), train_loss = 0.80183826, grad/param norm = 1.5900e-01, time/batch = 17.1397s	
27919/33150 (epoch 42.110), train_loss = 0.90227533, grad/param norm = 2.0320e-01, time/batch = 15.5939s	
27920/33150 (epoch 42.112), train_loss = 0.72813225, grad/param norm = 1.7075e-01, time/batch = 18.1614s	
27921/33150 (epoch 42.113), train_loss = 0.78731123, grad/param norm = 1.9153e-01, time/batch = 16.5561s	
27922/33150 (epoch 42.115), train_loss = 0.99393378, grad/param norm = 2.1782e-01, time/batch = 16.4882s	
27923/33150 (epoch 42.116), train_loss = 0.87172879, grad/param norm = 1.9694e-01, time/batch = 19.8934s	
27924/33150 (epoch 42.118), train_loss = 0.84948595, grad/param norm = 2.0216e-01, time/batch = 18.3108s	
27925/33150 (epoch 42.119), train_loss = 0.87172261, grad/param norm = 1.9922e-01, time/batch = 17.1471s	
27926/33150 (epoch 42.121), train_loss = 0.78867187, grad/param norm = 1.6102e-01, time/batch = 15.3820s	
27927/33150 (epoch 42.122), train_loss = 0.94552908, grad/param norm = 2.5042e-01, time/batch = 15.0552s	
27928/33150 (epoch 42.124), train_loss = 0.68736699, grad/param norm = 1.5439e-01, time/batch = 16.3765s	
27929/33150 (epoch 42.125), train_loss = 0.93123701, grad/param norm = 1.7627e-01, time/batch = 15.4365s	
27930/33150 (epoch 42.127), train_loss = 0.85190192, grad/param norm = 1.8606e-01, time/batch = 15.0470s	
27931/33150 (epoch 42.128), train_loss = 0.85639948, grad/param norm = 1.8260e-01, time/batch = 19.3741s	
27932/33150 (epoch 42.130), train_loss = 0.82824971, grad/param norm = 1.8304e-01, time/batch = 16.2998s	
27933/33150 (epoch 42.131), train_loss = 1.00172936, grad/param norm = 1.8773e-01, time/batch = 18.8156s	
27934/33150 (epoch 42.133), train_loss = 0.77444586, grad/param norm = 1.6241e-01, time/batch = 19.4658s	
27935/33150 (epoch 42.134), train_loss = 0.94125125, grad/param norm = 1.8575e-01, time/batch = 17.0568s	
27936/33150 (epoch 42.136), train_loss = 0.83238195, grad/param norm = 1.9359e-01, time/batch = 18.7185s	
27937/33150 (epoch 42.137), train_loss = 0.88683317, grad/param norm = 1.7211e-01, time/batch = 16.9810s	
27938/33150 (epoch 42.139), train_loss = 0.88540443, grad/param norm = 1.8761e-01, time/batch = 17.3717s	
27939/33150 (epoch 42.140), train_loss = 0.98457363, grad/param norm = 2.0195e-01, time/batch = 18.5423s	
27940/33150 (epoch 42.142), train_loss = 0.87813714, grad/param norm = 2.0325e-01, time/batch = 18.0650s	
27941/33150 (epoch 42.143), train_loss = 0.84298613, grad/param norm = 2.3603e-01, time/batch = 18.4024s	
27942/33150 (epoch 42.145), train_loss = 0.78949006, grad/param norm = 2.3176e-01, time/batch = 17.4595s	
27943/33150 (epoch 42.146), train_loss = 0.92069676, grad/param norm = 2.1990e-01, time/batch = 19.1416s	
27944/33150 (epoch 42.148), train_loss = 0.98346569, grad/param norm = 1.7467e-01, time/batch = 19.0529s	
27945/33150 (epoch 42.149), train_loss = 0.85412291, grad/param norm = 1.8674e-01, time/batch = 16.3075s	
27946/33150 (epoch 42.151), train_loss = 1.00355190, grad/param norm = 2.1723e-01, time/batch = 17.4861s	
27947/33150 (epoch 42.152), train_loss = 0.77057891, grad/param norm = 1.7006e-01, time/batch = 17.8239s	
27948/33150 (epoch 42.154), train_loss = 0.77077277, grad/param norm = 1.7802e-01, time/batch = 15.7234s	
27949/33150 (epoch 42.155), train_loss = 0.71003704, grad/param norm = 1.8128e-01, time/batch = 17.0626s	
27950/33150 (epoch 42.157), train_loss = 0.80785886, grad/param norm = 1.8406e-01, time/batch = 16.0528s	
27951/33150 (epoch 42.158), train_loss = 0.79705785, grad/param norm = 1.5798e-01, time/batch = 17.0582s	
27952/33150 (epoch 42.160), train_loss = 0.89123491, grad/param norm = 1.8958e-01, time/batch = 17.6373s	
27953/33150 (epoch 42.161), train_loss = 0.79868897, grad/param norm = 1.8553e-01, time/batch = 18.7974s	
27954/33150 (epoch 42.163), train_loss = 0.73624948, grad/param norm = 1.6418e-01, time/batch = 16.5887s	
27955/33150 (epoch 42.164), train_loss = 0.84644561, grad/param norm = 1.6415e-01, time/batch = 17.0639s	
27956/33150 (epoch 42.166), train_loss = 0.78299642, grad/param norm = 1.6392e-01, time/batch = 16.8019s	
27957/33150 (epoch 42.167), train_loss = 0.86278408, grad/param norm = 1.7340e-01, time/batch = 19.0633s	
27958/33150 (epoch 42.169), train_loss = 0.82061119, grad/param norm = 2.0055e-01, time/batch = 19.3101s	
27959/33150 (epoch 42.170), train_loss = 0.75422254, grad/param norm = 2.3032e-01, time/batch = 16.9698s	
27960/33150 (epoch 42.172), train_loss = 0.85636664, grad/param norm = 1.8473e-01, time/batch = 18.5743s	
27961/33150 (epoch 42.173), train_loss = 0.82842575, grad/param norm = 1.8511e-01, time/batch = 17.7168s	
27962/33150 (epoch 42.175), train_loss = 0.79030121, grad/param norm = 2.2802e-01, time/batch = 17.2172s	
27963/33150 (epoch 42.176), train_loss = 0.88012858, grad/param norm = 1.9421e-01, time/batch = 17.3878s	
27964/33150 (epoch 42.178), train_loss = 0.99789499, grad/param norm = 2.2211e-01, time/batch = 16.6391s	
27965/33150 (epoch 42.179), train_loss = 0.87889695, grad/param norm = 1.6364e-01, time/batch = 18.5438s	
27966/33150 (epoch 42.181), train_loss = 0.85587135, grad/param norm = 2.2444e-01, time/batch = 18.3889s	
27967/33150 (epoch 42.183), train_loss = 0.81653973, grad/param norm = 2.1329e-01, time/batch = 17.3877s	
27968/33150 (epoch 42.184), train_loss = 1.06218624, grad/param norm = 1.9445e-01, time/batch = 18.6318s	
27969/33150 (epoch 42.186), train_loss = 1.00156811, grad/param norm = 1.8551e-01, time/batch = 17.1459s	
27970/33150 (epoch 42.187), train_loss = 0.83041842, grad/param norm = 1.9229e-01, time/batch = 17.2299s	
27971/33150 (epoch 42.189), train_loss = 0.66040300, grad/param norm = 1.7235e-01, time/batch = 18.0756s	
27972/33150 (epoch 42.190), train_loss = 0.74735184, grad/param norm = 2.0355e-01, time/batch = 16.3134s	
27973/33150 (epoch 42.192), train_loss = 0.85368095, grad/param norm = 1.8170e-01, time/batch = 17.4860s	
27974/33150 (epoch 42.193), train_loss = 0.88913970, grad/param norm = 1.6966e-01, time/batch = 16.9565s	
27975/33150 (epoch 42.195), train_loss = 1.00774347, grad/param norm = 2.2080e-01, time/batch = 18.2265s	
27976/33150 (epoch 42.196), train_loss = 0.94225337, grad/param norm = 1.8547e-01, time/batch = 16.3772s	
27977/33150 (epoch 42.198), train_loss = 0.73314436, grad/param norm = 1.5440e-01, time/batch = 17.8950s	
27978/33150 (epoch 42.199), train_loss = 0.92234072, grad/param norm = 3.6956e-01, time/batch = 18.0555s	
27979/33150 (epoch 42.201), train_loss = 0.80323670, grad/param norm = 1.6422e-01, time/batch = 17.6426s	
27980/33150 (epoch 42.202), train_loss = 0.66193159, grad/param norm = 1.7575e-01, time/batch = 18.3797s	
27981/33150 (epoch 42.204), train_loss = 0.84782062, grad/param norm = 1.8900e-01, time/batch = 19.0539s	
27982/33150 (epoch 42.205), train_loss = 0.86712702, grad/param norm = 2.0287e-01, time/batch = 23.2307s	
27983/33150 (epoch 42.207), train_loss = 0.83925953, grad/param norm = 1.6414e-01, time/batch = 24.9308s	
27984/33150 (epoch 42.208), train_loss = 0.89799488, grad/param norm = 1.8321e-01, time/batch = 17.7929s	
27985/33150 (epoch 42.210), train_loss = 0.78683154, grad/param norm = 1.7244e-01, time/batch = 16.0134s	
27986/33150 (epoch 42.211), train_loss = 0.81169533, grad/param norm = 1.8302e-01, time/batch = 15.8521s	
27987/33150 (epoch 42.213), train_loss = 0.88975812, grad/param norm = 1.7271e-01, time/batch = 15.8407s	
27988/33150 (epoch 42.214), train_loss = 0.78611287, grad/param norm = 1.6722e-01, time/batch = 15.2535s	
27989/33150 (epoch 42.216), train_loss = 0.74218071, grad/param norm = 1.7295e-01, time/batch = 15.5347s	
27990/33150 (epoch 42.217), train_loss = 0.83644425, grad/param norm = 1.7457e-01, time/batch = 15.3533s	
27991/33150 (epoch 42.219), train_loss = 0.77321979, grad/param norm = 1.9139e-01, time/batch = 18.7081s	
27992/33150 (epoch 42.220), train_loss = 0.81125793, grad/param norm = 1.6143e-01, time/batch = 16.2858s	
27993/33150 (epoch 42.222), train_loss = 0.92028867, grad/param norm = 1.9247e-01, time/batch = 16.7122s	
27994/33150 (epoch 42.223), train_loss = 0.82769404, grad/param norm = 1.9774e-01, time/batch = 18.8684s	
27995/33150 (epoch 42.225), train_loss = 0.94295299, grad/param norm = 1.9756e-01, time/batch = 17.9691s	
27996/33150 (epoch 42.226), train_loss = 0.80006662, grad/param norm = 1.7720e-01, time/batch = 16.8648s	
27997/33150 (epoch 42.228), train_loss = 0.79063440, grad/param norm = 1.8910e-01, time/batch = 17.8805s	
27998/33150 (epoch 42.229), train_loss = 0.81052775, grad/param norm = 1.8527e-01, time/batch = 16.1166s	
27999/33150 (epoch 42.231), train_loss = 0.92978235, grad/param norm = 1.9888e-01, time/batch = 17.7863s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch42.23_1.8199.t7	
28000/33150 (epoch 42.232), train_loss = 0.80477188, grad/param norm = 1.6739e-01, time/batch = 15.8373s	
28001/33150 (epoch 42.234), train_loss = 1.35959330, grad/param norm = 2.5033e-01, time/batch = 17.1817s	
28002/33150 (epoch 42.235), train_loss = 0.88586549, grad/param norm = 1.7397e-01, time/batch = 18.0369s	
28003/33150 (epoch 42.237), train_loss = 0.85041250, grad/param norm = 2.2852e-01, time/batch = 16.1802s	
28004/33150 (epoch 42.238), train_loss = 0.87702216, grad/param norm = 1.9291e-01, time/batch = 15.8228s	
28005/33150 (epoch 42.240), train_loss = 0.85911493, grad/param norm = 1.9346e-01, time/batch = 14.9444s	
28006/33150 (epoch 42.241), train_loss = 0.92088883, grad/param norm = 2.5618e-01, time/batch = 16.1524s	
28007/33150 (epoch 42.243), train_loss = 0.88457079, grad/param norm = 1.8145e-01, time/batch = 17.1408s	
28008/33150 (epoch 42.244), train_loss = 0.86649349, grad/param norm = 1.9193e-01, time/batch = 15.9689s	
28009/33150 (epoch 42.246), train_loss = 0.91457782, grad/param norm = 1.9905e-01, time/batch = 15.3608s	
28010/33150 (epoch 42.247), train_loss = 0.78632482, grad/param norm = 1.6061e-01, time/batch = 16.0444s	
28011/33150 (epoch 42.249), train_loss = 0.96072249, grad/param norm = 1.9634e-01, time/batch = 16.1079s	
28012/33150 (epoch 42.250), train_loss = 0.87156957, grad/param norm = 1.6625e-01, time/batch = 17.7171s	
28013/33150 (epoch 42.252), train_loss = 0.89377150, grad/param norm = 1.5322e-01, time/batch = 16.7929s	
28014/33150 (epoch 42.253), train_loss = 0.81329861, grad/param norm = 1.9373e-01, time/batch = 17.8058s	
28015/33150 (epoch 42.255), train_loss = 0.81122897, grad/param norm = 1.5908e-01, time/batch = 17.3793s	
28016/33150 (epoch 42.256), train_loss = 0.92672521, grad/param norm = 1.8893e-01, time/batch = 17.2771s	
28017/33150 (epoch 42.258), train_loss = 0.78127422, grad/param norm = 1.8148e-01, time/batch = 17.7886s	
28018/33150 (epoch 42.259), train_loss = 0.67147068, grad/param norm = 1.6774e-01, time/batch = 19.1268s	
28019/33150 (epoch 42.261), train_loss = 0.74894978, grad/param norm = 1.6460e-01, time/batch = 17.6342s	
28020/33150 (epoch 42.262), train_loss = 0.95252915, grad/param norm = 1.9646e-01, time/batch = 16.7193s	
28021/33150 (epoch 42.264), train_loss = 0.66789336, grad/param norm = 1.6382e-01, time/batch = 20.2146s	
28022/33150 (epoch 42.265), train_loss = 0.85092457, grad/param norm = 1.8151e-01, time/batch = 17.5570s	
28023/33150 (epoch 42.267), train_loss = 0.93196855, grad/param norm = 2.2000e-01, time/batch = 16.8666s	
28024/33150 (epoch 42.268), train_loss = 0.97096733, grad/param norm = 1.7948e-01, time/batch = 17.8780s	
28025/33150 (epoch 42.270), train_loss = 1.00869042, grad/param norm = 1.7139e-01, time/batch = 17.2165s	
28026/33150 (epoch 42.271), train_loss = 0.88477032, grad/param norm = 1.9720e-01, time/batch = 17.2255s	
28027/33150 (epoch 42.273), train_loss = 0.95081763, grad/param norm = 1.9453e-01, time/batch = 15.7285s	
28028/33150 (epoch 42.275), train_loss = 0.96715595, grad/param norm = 1.9087e-01, time/batch = 19.6893s	
28029/33150 (epoch 42.276), train_loss = 0.83829028, grad/param norm = 1.8534e-01, time/batch = 17.6338s	
28030/33150 (epoch 42.278), train_loss = 0.95214310, grad/param norm = 1.8037e-01, time/batch = 17.2278s	
28031/33150 (epoch 42.279), train_loss = 0.93229500, grad/param norm = 1.6465e-01, time/batch = 18.1206s	
28032/33150 (epoch 42.281), train_loss = 0.85357662, grad/param norm = 1.7083e-01, time/batch = 20.6082s	
28033/33150 (epoch 42.282), train_loss = 0.89431355, grad/param norm = 1.5357e-01, time/batch = 16.7854s	
28034/33150 (epoch 42.284), train_loss = 0.77620204, grad/param norm = 1.7967e-01, time/batch = 18.6189s	
28035/33150 (epoch 42.285), train_loss = 0.88035003, grad/param norm = 2.0025e-01, time/batch = 16.8624s	
28036/33150 (epoch 42.287), train_loss = 0.75029716, grad/param norm = 1.9474e-01, time/batch = 17.0821s	
28037/33150 (epoch 42.288), train_loss = 0.92298637, grad/param norm = 1.9361e-01, time/batch = 18.1319s	
28038/33150 (epoch 42.290), train_loss = 0.71635856, grad/param norm = 1.6257e-01, time/batch = 17.5567s	
28039/33150 (epoch 42.291), train_loss = 0.70591388, grad/param norm = 2.0295e-01, time/batch = 17.4558s	
28040/33150 (epoch 42.293), train_loss = 0.79754020, grad/param norm = 1.8331e-01, time/batch = 18.1312s	
28041/33150 (epoch 42.294), train_loss = 0.66065200, grad/param norm = 1.4843e-01, time/batch = 17.7338s	
28042/33150 (epoch 42.296), train_loss = 0.84536525, grad/param norm = 1.6990e-01, time/batch = 16.8720s	
28043/33150 (epoch 42.297), train_loss = 0.78386334, grad/param norm = 1.7579e-01, time/batch = 16.7170s	
28044/33150 (epoch 42.299), train_loss = 0.76641789, grad/param norm = 1.7837e-01, time/batch = 17.2187s	
28045/33150 (epoch 42.300), train_loss = 0.79021053, grad/param norm = 1.6475e-01, time/batch = 16.7872s	
28046/33150 (epoch 42.302), train_loss = 0.81280937, grad/param norm = 1.7828e-01, time/batch = 16.9786s	
28047/33150 (epoch 42.303), train_loss = 0.79782035, grad/param norm = 1.7251e-01, time/batch = 17.9633s	
28048/33150 (epoch 42.305), train_loss = 0.87885780, grad/param norm = 1.8394e-01, time/batch = 17.1482s	
28049/33150 (epoch 42.306), train_loss = 0.89724988, grad/param norm = 2.0465e-01, time/batch = 17.8943s	
28050/33150 (epoch 42.308), train_loss = 1.02108510, grad/param norm = 1.8602e-01, time/batch = 16.8108s	
28051/33150 (epoch 42.309), train_loss = 0.68824542, grad/param norm = 1.6789e-01, time/batch = 18.8171s	
28052/33150 (epoch 42.311), train_loss = 0.81977758, grad/param norm = 1.8493e-01, time/batch = 18.1423s	
28053/33150 (epoch 42.312), train_loss = 0.68346852, grad/param norm = 1.7448e-01, time/batch = 16.5536s	
28054/33150 (epoch 42.314), train_loss = 0.81952821, grad/param norm = 2.7056e-01, time/batch = 18.1430s	
28055/33150 (epoch 42.315), train_loss = 0.86924865, grad/param norm = 1.7650e-01, time/batch = 16.7816s	
28056/33150 (epoch 42.317), train_loss = 0.66888804, grad/param norm = 1.3561e-01, time/batch = 17.4635s	
28057/33150 (epoch 42.318), train_loss = 0.76725862, grad/param norm = 1.6997e-01, time/batch = 16.4606s	
28058/33150 (epoch 42.320), train_loss = 0.70346288, grad/param norm = 2.3628e-01, time/batch = 19.0592s	
28059/33150 (epoch 42.321), train_loss = 0.79523521, grad/param norm = 1.5528e-01, time/batch = 18.7018s	
28060/33150 (epoch 42.323), train_loss = 0.77581211, grad/param norm = 1.7486e-01, time/batch = 17.0432s	
28061/33150 (epoch 42.324), train_loss = 0.81488524, grad/param norm = 2.1373e-01, time/batch = 18.3161s	
28062/33150 (epoch 42.326), train_loss = 0.81760711, grad/param norm = 1.7808e-01, time/batch = 17.6568s	
28063/33150 (epoch 42.327), train_loss = 0.92219729, grad/param norm = 1.8176e-01, time/batch = 16.6290s	
28064/33150 (epoch 42.329), train_loss = 0.88211341, grad/param norm = 1.8739e-01, time/batch = 16.5842s	
28065/33150 (epoch 42.330), train_loss = 0.79620724, grad/param norm = 1.7934e-01, time/batch = 17.8159s	
28066/33150 (epoch 42.332), train_loss = 0.78986245, grad/param norm = 1.7955e-01, time/batch = 18.9727s	
28067/33150 (epoch 42.333), train_loss = 0.87834585, grad/param norm = 1.6265e-01, time/batch = 15.9645s	
28068/33150 (epoch 42.335), train_loss = 0.75481793, grad/param norm = 1.8184e-01, time/batch = 18.8096s	
28069/33150 (epoch 42.336), train_loss = 0.75077530, grad/param norm = 1.9937e-01, time/batch = 18.8944s	
28070/33150 (epoch 42.338), train_loss = 0.70556509, grad/param norm = 1.7314e-01, time/batch = 16.2941s	
28071/33150 (epoch 42.339), train_loss = 0.87633277, grad/param norm = 1.9137e-01, time/batch = 17.9745s	
28072/33150 (epoch 42.341), train_loss = 0.82268333, grad/param norm = 2.2423e-01, time/batch = 18.5693s	
28073/33150 (epoch 42.342), train_loss = 0.76545368, grad/param norm = 1.9114e-01, time/batch = 17.1396s	
28074/33150 (epoch 42.344), train_loss = 0.80463282, grad/param norm = 1.8361e-01, time/batch = 17.0673s	
28075/33150 (epoch 42.345), train_loss = 0.79950154, grad/param norm = 1.8448e-01, time/batch = 19.9635s	
28076/33150 (epoch 42.347), train_loss = 0.69346529, grad/param norm = 1.7808e-01, time/batch = 18.4662s	
28077/33150 (epoch 42.348), train_loss = 0.82148169, grad/param norm = 1.5747e-01, time/batch = 16.4366s	
28078/33150 (epoch 42.350), train_loss = 0.73914780, grad/param norm = 1.9998e-01, time/batch = 19.7859s	
28079/33150 (epoch 42.351), train_loss = 0.88600897, grad/param norm = 2.2456e-01, time/batch = 17.4598s	
28080/33150 (epoch 42.353), train_loss = 0.86157309, grad/param norm = 2.4354e-01, time/batch = 17.3023s	
28081/33150 (epoch 42.354), train_loss = 1.03107972, grad/param norm = 1.8949e-01, time/batch = 15.7258s	
28082/33150 (epoch 42.356), train_loss = 0.91342366, grad/param norm = 1.7748e-01, time/batch = 15.8174s	
28083/33150 (epoch 42.357), train_loss = 0.84220280, grad/param norm = 1.8791e-01, time/batch = 18.6439s	
28084/33150 (epoch 42.359), train_loss = 0.91163676, grad/param norm = 1.7714e-01, time/batch = 15.9881s	
28085/33150 (epoch 42.360), train_loss = 0.86630983, grad/param norm = 1.9599e-01, time/batch = 17.8105s	
28086/33150 (epoch 42.362), train_loss = 0.94606772, grad/param norm = 1.8417e-01, time/batch = 17.3303s	
28087/33150 (epoch 42.363), train_loss = 0.86804534, grad/param norm = 1.8591e-01, time/batch = 15.7291s	
28088/33150 (epoch 42.365), train_loss = 0.82699590, grad/param norm = 1.7075e-01, time/batch = 18.7866s	
28089/33150 (epoch 42.367), train_loss = 0.79091433, grad/param norm = 1.7060e-01, time/batch = 19.3002s	
28090/33150 (epoch 42.368), train_loss = 0.81278447, grad/param norm = 2.8637e-01, time/batch = 18.3928s	
28091/33150 (epoch 42.370), train_loss = 0.85535928, grad/param norm = 2.0657e-01, time/batch = 15.7337s	
28092/33150 (epoch 42.371), train_loss = 0.73535393, grad/param norm = 1.7411e-01, time/batch = 18.3137s	
28093/33150 (epoch 42.373), train_loss = 0.86429881, grad/param norm = 2.1100e-01, time/batch = 17.7393s	
28094/33150 (epoch 42.374), train_loss = 0.84599768, grad/param norm = 1.7028e-01, time/batch = 17.0581s	
28095/33150 (epoch 42.376), train_loss = 0.90541950, grad/param norm = 1.7026e-01, time/batch = 17.2409s	
28096/33150 (epoch 42.377), train_loss = 0.74912759, grad/param norm = 1.8434e-01, time/batch = 18.6617s	
28097/33150 (epoch 42.379), train_loss = 0.84889336, grad/param norm = 1.9036e-01, time/batch = 17.8137s	
28098/33150 (epoch 42.380), train_loss = 0.87776187, grad/param norm = 1.5736e-01, time/batch = 18.0665s	
28099/33150 (epoch 42.382), train_loss = 0.82419832, grad/param norm = 1.6932e-01, time/batch = 17.9832s	
28100/33150 (epoch 42.383), train_loss = 0.74513351, grad/param norm = 1.8291e-01, time/batch = 15.2904s	
28101/33150 (epoch 42.385), train_loss = 0.76914503, grad/param norm = 1.9116e-01, time/batch = 16.3051s	
28102/33150 (epoch 42.386), train_loss = 0.71855259, grad/param norm = 1.4075e-01, time/batch = 17.4943s	
28103/33150 (epoch 42.388), train_loss = 0.75538555, grad/param norm = 1.8179e-01, time/batch = 19.0709s	
28104/33150 (epoch 42.389), train_loss = 0.76065326, grad/param norm = 1.6904e-01, time/batch = 16.4119s	
28105/33150 (epoch 42.391), train_loss = 0.95272984, grad/param norm = 2.0984e-01, time/batch = 17.4900s	
28106/33150 (epoch 42.392), train_loss = 0.75955030, grad/param norm = 1.6521e-01, time/batch = 18.8214s	
28107/33150 (epoch 42.394), train_loss = 0.71179499, grad/param norm = 1.5997e-01, time/batch = 17.5528s	
28108/33150 (epoch 42.395), train_loss = 0.65616415, grad/param norm = 1.6470e-01, time/batch = 17.8828s	
28109/33150 (epoch 42.397), train_loss = 0.58012822, grad/param norm = 1.7197e-01, time/batch = 18.2311s	
28110/33150 (epoch 42.398), train_loss = 0.82186750, grad/param norm = 1.5648e-01, time/batch = 19.8032s	
28111/33150 (epoch 42.400), train_loss = 0.80236965, grad/param norm = 1.5962e-01, time/batch = 16.4448s	
28112/33150 (epoch 42.401), train_loss = 0.68303573, grad/param norm = 1.4249e-01, time/batch = 18.4097s	
28113/33150 (epoch 42.403), train_loss = 0.68946778, grad/param norm = 1.4989e-01, time/batch = 17.2441s	
28114/33150 (epoch 42.404), train_loss = 0.81456763, grad/param norm = 1.7224e-01, time/batch = 18.1451s	
28115/33150 (epoch 42.406), train_loss = 0.77500201, grad/param norm = 1.5072e-01, time/batch = 16.6292s	
28116/33150 (epoch 42.407), train_loss = 0.70096058, grad/param norm = 1.7753e-01, time/batch = 16.6531s	
28117/33150 (epoch 42.409), train_loss = 0.64899667, grad/param norm = 1.6027e-01, time/batch = 18.0593s	
28118/33150 (epoch 42.410), train_loss = 0.82488840, grad/param norm = 1.9088e-01, time/batch = 17.0528s	
28119/33150 (epoch 42.412), train_loss = 0.85537573, grad/param norm = 1.5379e-01, time/batch = 18.7287s	
28120/33150 (epoch 42.413), train_loss = 0.71171582, grad/param norm = 1.5519e-01, time/batch = 18.0727s	
28121/33150 (epoch 42.415), train_loss = 0.82539414, grad/param norm = 1.5321e-01, time/batch = 16.2336s	
28122/33150 (epoch 42.416), train_loss = 0.73883041, grad/param norm = 1.5169e-01, time/batch = 17.7175s	
28123/33150 (epoch 42.418), train_loss = 0.82637500, grad/param norm = 2.1077e-01, time/batch = 17.3236s	
28124/33150 (epoch 42.419), train_loss = 0.79489700, grad/param norm = 1.7065e-01, time/batch = 16.8270s	
28125/33150 (epoch 42.421), train_loss = 0.81350532, grad/param norm = 2.1072e-01, time/batch = 16.9830s	
28126/33150 (epoch 42.422), train_loss = 0.79705500, grad/param norm = 1.6531e-01, time/batch = 18.3094s	
28127/33150 (epoch 42.424), train_loss = 0.73825504, grad/param norm = 1.7929e-01, time/batch = 18.1411s	
28128/33150 (epoch 42.425), train_loss = 0.86796348, grad/param norm = 1.6956e-01, time/batch = 15.3860s	
28129/33150 (epoch 42.427), train_loss = 0.81296847, grad/param norm = 1.5270e-01, time/batch = 16.6510s	
28130/33150 (epoch 42.428), train_loss = 0.77614828, grad/param norm = 1.7177e-01, time/batch = 15.6416s	
28131/33150 (epoch 42.430), train_loss = 0.81820570, grad/param norm = 1.9720e-01, time/batch = 15.5231s	
28132/33150 (epoch 42.431), train_loss = 0.87783241, grad/param norm = 2.3174e-01, time/batch = 15.2419s	
28133/33150 (epoch 42.433), train_loss = 0.77845705, grad/param norm = 1.8002e-01, time/batch = 15.0731s	
28134/33150 (epoch 42.434), train_loss = 0.69472321, grad/param norm = 1.7242e-01, time/batch = 15.0049s	
28135/33150 (epoch 42.436), train_loss = 0.81977132, grad/param norm = 1.5762e-01, time/batch = 14.7820s	
28136/33150 (epoch 42.437), train_loss = 0.82650754, grad/param norm = 2.8533e-01, time/batch = 16.2078s	
28137/33150 (epoch 42.439), train_loss = 0.95662004, grad/param norm = 1.6508e-01, time/batch = 16.1221s	
28138/33150 (epoch 42.440), train_loss = 0.86019601, grad/param norm = 2.0605e-01, time/batch = 17.4619s	
28139/33150 (epoch 42.442), train_loss = 0.70690277, grad/param norm = 1.9024e-01, time/batch = 16.9547s	
28140/33150 (epoch 42.443), train_loss = 0.83793748, grad/param norm = 2.0802e-01, time/batch = 16.7989s	
28141/33150 (epoch 42.445), train_loss = 0.81577127, grad/param norm = 1.7923e-01, time/batch = 16.1069s	
28142/33150 (epoch 42.446), train_loss = 0.84113844, grad/param norm = 2.0768e-01, time/batch = 18.7907s	
28143/33150 (epoch 42.448), train_loss = 0.90516495, grad/param norm = 1.9534e-01, time/batch = 16.6116s	
28144/33150 (epoch 42.449), train_loss = 0.81772578, grad/param norm = 1.5202e-01, time/batch = 16.5334s	
28145/33150 (epoch 42.451), train_loss = 0.84662917, grad/param norm = 2.4053e-01, time/batch = 16.1243s	
28146/33150 (epoch 42.452), train_loss = 0.97984783, grad/param norm = 1.8624e-01, time/batch = 15.7107s	
28147/33150 (epoch 42.454), train_loss = 0.80063324, grad/param norm = 1.6869e-01, time/batch = 15.6104s	
28148/33150 (epoch 42.456), train_loss = 0.75781781, grad/param norm = 1.6326e-01, time/batch = 15.2235s	
28149/33150 (epoch 42.457), train_loss = 0.83160141, grad/param norm = 2.0709e-01, time/batch = 15.8118s	
28150/33150 (epoch 42.459), train_loss = 0.92963240, grad/param norm = 2.4326e-01, time/batch = 15.2211s	
28151/33150 (epoch 42.460), train_loss = 0.89171455, grad/param norm = 1.7593e-01, time/batch = 15.1990s	
28152/33150 (epoch 42.462), train_loss = 0.91502101, grad/param norm = 1.9035e-01, time/batch = 15.4532s	
28153/33150 (epoch 42.463), train_loss = 1.03556279, grad/param norm = 2.4602e-01, time/batch = 16.4826s	
28154/33150 (epoch 42.465), train_loss = 0.88308967, grad/param norm = 1.8611e-01, time/batch = 15.8441s	
28155/33150 (epoch 42.466), train_loss = 0.78823519, grad/param norm = 1.8645e-01, time/batch = 17.7953s	
28156/33150 (epoch 42.468), train_loss = 1.03637285, grad/param norm = 1.9863e-01, time/batch = 16.0433s	
28157/33150 (epoch 42.469), train_loss = 0.76245907, grad/param norm = 1.7909e-01, time/batch = 16.3650s	
28158/33150 (epoch 42.471), train_loss = 0.76875638, grad/param norm = 1.6692e-01, time/batch = 16.0152s	
28159/33150 (epoch 42.472), train_loss = 0.84797787, grad/param norm = 1.8055e-01, time/batch = 15.6714s	
28160/33150 (epoch 42.474), train_loss = 0.87472928, grad/param norm = 2.3835e-01, time/batch = 17.1157s	
28161/33150 (epoch 42.475), train_loss = 1.06419093, grad/param norm = 2.0006e-01, time/batch = 15.1839s	
28162/33150 (epoch 42.477), train_loss = 0.88261590, grad/param norm = 1.7897e-01, time/batch = 16.7445s	
28163/33150 (epoch 42.478), train_loss = 0.84029660, grad/param norm = 1.7747e-01, time/batch = 19.0441s	
28164/33150 (epoch 42.480), train_loss = 0.75854302, grad/param norm = 1.7348e-01, time/batch = 17.1970s	
28165/33150 (epoch 42.481), train_loss = 0.69428377, grad/param norm = 1.6515e-01, time/batch = 16.6845s	
28166/33150 (epoch 42.483), train_loss = 0.78525101, grad/param norm = 1.7624e-01, time/batch = 16.5362s	
28167/33150 (epoch 42.484), train_loss = 0.74413590, grad/param norm = 1.7219e-01, time/batch = 16.3569s	
28168/33150 (epoch 42.486), train_loss = 0.76743113, grad/param norm = 1.7038e-01, time/batch = 17.3874s	
28169/33150 (epoch 42.487), train_loss = 0.87616989, grad/param norm = 1.7729e-01, time/batch = 15.7849s	
28170/33150 (epoch 42.489), train_loss = 0.81908925, grad/param norm = 1.9698e-01, time/batch = 19.0484s	
28171/33150 (epoch 42.490), train_loss = 0.65333284, grad/param norm = 1.4622e-01, time/batch = 15.7974s	
28172/33150 (epoch 42.492), train_loss = 0.80123974, grad/param norm = 1.9409e-01, time/batch = 16.0474s	
28173/33150 (epoch 42.493), train_loss = 0.87214393, grad/param norm = 1.8636e-01, time/batch = 17.2429s	
28174/33150 (epoch 42.495), train_loss = 0.87087455, grad/param norm = 1.7010e-01, time/batch = 18.8845s	
28175/33150 (epoch 42.496), train_loss = 0.77808970, grad/param norm = 1.5494e-01, time/batch = 17.4654s	
28176/33150 (epoch 42.498), train_loss = 0.90035900, grad/param norm = 2.8156e-01, time/batch = 17.3032s	
28177/33150 (epoch 42.499), train_loss = 0.92532856, grad/param norm = 1.8149e-01, time/batch = 17.2317s	
28178/33150 (epoch 42.501), train_loss = 0.84523869, grad/param norm = 2.1374e-01, time/batch = 17.9798s	
28179/33150 (epoch 42.502), train_loss = 0.93055465, grad/param norm = 2.0862e-01, time/batch = 17.5520s	
28180/33150 (epoch 42.504), train_loss = 0.88740879, grad/param norm = 1.8957e-01, time/batch = 18.4805s	
28181/33150 (epoch 42.505), train_loss = 0.94491637, grad/param norm = 1.8857e-01, time/batch = 18.3971s	
28182/33150 (epoch 42.507), train_loss = 0.78265366, grad/param norm = 1.8801e-01, time/batch = 27.8019s	
28183/33150 (epoch 42.508), train_loss = 0.76727046, grad/param norm = 1.8037e-01, time/batch = 20.1895s	
28184/33150 (epoch 42.510), train_loss = 0.89326742, grad/param norm = 1.5324e-01, time/batch = 17.4762s	
28185/33150 (epoch 42.511), train_loss = 0.90955005, grad/param norm = 1.9425e-01, time/batch = 17.9610s	
28186/33150 (epoch 42.513), train_loss = 0.87529390, grad/param norm = 2.3169e-01, time/batch = 17.8222s	
28187/33150 (epoch 42.514), train_loss = 0.72979135, grad/param norm = 1.9572e-01, time/batch = 17.9883s	
28188/33150 (epoch 42.516), train_loss = 0.84823972, grad/param norm = 2.4068e-01, time/batch = 15.3652s	
28189/33150 (epoch 42.517), train_loss = 0.91330889, grad/param norm = 2.0294e-01, time/batch = 16.9737s	
28190/33150 (epoch 42.519), train_loss = 0.75606624, grad/param norm = 1.5799e-01, time/batch = 18.7303s	
28191/33150 (epoch 42.520), train_loss = 0.82358384, grad/param norm = 1.6925e-01, time/batch = 16.5668s	
28192/33150 (epoch 42.522), train_loss = 0.88753197, grad/param norm = 2.1859e-01, time/batch = 17.5607s	
28193/33150 (epoch 42.523), train_loss = 0.74583501, grad/param norm = 1.8999e-01, time/batch = 17.9723s	
28194/33150 (epoch 42.525), train_loss = 0.87070314, grad/param norm = 2.0680e-01, time/batch = 19.3081s	
28195/33150 (epoch 42.526), train_loss = 0.76266833, grad/param norm = 1.6752e-01, time/batch = 17.0240s	
28196/33150 (epoch 42.528), train_loss = 0.84239689, grad/param norm = 1.8265e-01, time/batch = 17.9623s	
28197/33150 (epoch 42.529), train_loss = 0.82625237, grad/param norm = 1.9746e-01, time/batch = 19.4459s	
28198/33150 (epoch 42.531), train_loss = 0.71804583, grad/param norm = 1.9142e-01, time/batch = 16.7140s	
28199/33150 (epoch 42.532), train_loss = 0.84475822, grad/param norm = 2.2290e-01, time/batch = 17.2052s	
28200/33150 (epoch 42.534), train_loss = 0.82877292, grad/param norm = 1.7754e-01, time/batch = 18.3735s	
28201/33150 (epoch 42.535), train_loss = 0.76658448, grad/param norm = 2.7406e-01, time/batch = 18.2098s	
28202/33150 (epoch 42.537), train_loss = 0.85710362, grad/param norm = 2.2153e-01, time/batch = 18.0618s	
28203/33150 (epoch 42.538), train_loss = 0.75155642, grad/param norm = 1.7724e-01, time/batch = 17.4033s	
28204/33150 (epoch 42.540), train_loss = 0.76011216, grad/param norm = 2.0629e-01, time/batch = 17.1359s	
28205/33150 (epoch 42.541), train_loss = 0.90318331, grad/param norm = 1.8622e-01, time/batch = 16.6487s	
28206/33150 (epoch 42.543), train_loss = 0.83734258, grad/param norm = 1.7227e-01, time/batch = 18.8045s	
28207/33150 (epoch 42.544), train_loss = 0.88743326, grad/param norm = 1.7706e-01, time/batch = 18.1459s	
28208/33150 (epoch 42.546), train_loss = 0.77791741, grad/param norm = 1.9278e-01, time/batch = 18.2113s	
28209/33150 (epoch 42.548), train_loss = 0.80156617, grad/param norm = 1.9856e-01, time/batch = 17.4859s	
28210/33150 (epoch 42.549), train_loss = 0.78470463, grad/param norm = 2.2018e-01, time/batch = 16.1212s	
28211/33150 (epoch 42.551), train_loss = 0.75350576, grad/param norm = 1.8384e-01, time/batch = 16.5539s	
28212/33150 (epoch 42.552), train_loss = 0.63845259, grad/param norm = 1.3706e-01, time/batch = 17.2257s	
28213/33150 (epoch 42.554), train_loss = 0.87826083, grad/param norm = 1.8071e-01, time/batch = 17.8119s	
28214/33150 (epoch 42.555), train_loss = 0.92201053, grad/param norm = 2.1372e-01, time/batch = 17.1484s	
28215/33150 (epoch 42.557), train_loss = 0.70732594, grad/param norm = 1.9816e-01, time/batch = 16.3925s	
28216/33150 (epoch 42.558), train_loss = 0.85542711, grad/param norm = 2.5258e-01, time/batch = 16.4158s	
28217/33150 (epoch 42.560), train_loss = 0.73298675, grad/param norm = 1.6951e-01, time/batch = 16.0052s	
28218/33150 (epoch 42.561), train_loss = 0.69263130, grad/param norm = 1.7687e-01, time/batch = 18.7268s	
28219/33150 (epoch 42.563), train_loss = 0.87353681, grad/param norm = 2.3276e-01, time/batch = 18.8023s	
28220/33150 (epoch 42.564), train_loss = 0.90533114, grad/param norm = 1.6233e-01, time/batch = 18.0438s	
28221/33150 (epoch 42.566), train_loss = 0.74435902, grad/param norm = 1.7515e-01, time/batch = 18.5279s	
28222/33150 (epoch 42.567), train_loss = 0.79771649, grad/param norm = 1.8604e-01, time/batch = 16.6419s	
28223/33150 (epoch 42.569), train_loss = 0.83761225, grad/param norm = 1.7288e-01, time/batch = 18.3091s	
28224/33150 (epoch 42.570), train_loss = 0.87062648, grad/param norm = 1.6572e-01, time/batch = 19.3835s	
28225/33150 (epoch 42.572), train_loss = 0.77170271, grad/param norm = 1.8077e-01, time/batch = 16.8787s	
28226/33150 (epoch 42.573), train_loss = 0.70493001, grad/param norm = 1.4970e-01, time/batch = 17.6301s	
28227/33150 (epoch 42.575), train_loss = 0.80013184, grad/param norm = 2.1498e-01, time/batch = 18.8982s	
28228/33150 (epoch 42.576), train_loss = 0.72509608, grad/param norm = 1.6178e-01, time/batch = 17.1340s	
28229/33150 (epoch 42.578), train_loss = 0.77023189, grad/param norm = 1.8061e-01, time/batch = 17.3866s	
28230/33150 (epoch 42.579), train_loss = 0.72822845, grad/param norm = 1.8914e-01, time/batch = 18.1326s	
28231/33150 (epoch 42.581), train_loss = 0.72110283, grad/param norm = 1.8185e-01, time/batch = 18.8658s	
28232/33150 (epoch 42.582), train_loss = 0.92842999, grad/param norm = 1.7514e-01, time/batch = 15.9745s	
28233/33150 (epoch 42.584), train_loss = 0.90404293, grad/param norm = 1.8919e-01, time/batch = 17.6439s	
28234/33150 (epoch 42.585), train_loss = 0.82466511, grad/param norm = 1.7229e-01, time/batch = 15.9676s	
28235/33150 (epoch 42.587), train_loss = 0.81512756, grad/param norm = 1.5825e-01, time/batch = 17.5633s	
28236/33150 (epoch 42.588), train_loss = 0.73483930, grad/param norm = 1.5623e-01, time/batch = 17.9781s	
28237/33150 (epoch 42.590), train_loss = 0.84402831, grad/param norm = 1.7290e-01, time/batch = 17.1383s	
28238/33150 (epoch 42.591), train_loss = 0.84740044, grad/param norm = 1.9643e-01, time/batch = 17.6943s	
28239/33150 (epoch 42.593), train_loss = 0.86772969, grad/param norm = 1.9477e-01, time/batch = 15.8998s	
28240/33150 (epoch 42.594), train_loss = 0.78006858, grad/param norm = 1.7694e-01, time/batch = 17.0799s	
28241/33150 (epoch 42.596), train_loss = 0.77601089, grad/param norm = 1.6207e-01, time/batch = 15.8971s	
28242/33150 (epoch 42.597), train_loss = 0.71622822, grad/param norm = 2.5304e-01, time/batch = 17.3232s	
28243/33150 (epoch 42.599), train_loss = 0.97737755, grad/param norm = 2.5155e-01, time/batch = 16.4751s	
28244/33150 (epoch 42.600), train_loss = 0.83610916, grad/param norm = 3.1819e-01, time/batch = 16.9117s	
28245/33150 (epoch 42.602), train_loss = 0.82624289, grad/param norm = 2.0788e-01, time/batch = 19.2277s	
28246/33150 (epoch 42.603), train_loss = 0.94438399, grad/param norm = 1.9611e-01, time/batch = 15.8020s	
28247/33150 (epoch 42.605), train_loss = 0.73771141, grad/param norm = 1.7817e-01, time/batch = 17.4777s	
28248/33150 (epoch 42.606), train_loss = 0.78442767, grad/param norm = 2.4355e-01, time/batch = 18.3089s	
28249/33150 (epoch 42.608), train_loss = 0.90687115, grad/param norm = 1.6963e-01, time/batch = 16.9003s	
28250/33150 (epoch 42.609), train_loss = 0.80907230, grad/param norm = 1.9651e-01, time/batch = 17.6470s	
28251/33150 (epoch 42.611), train_loss = 0.73487742, grad/param norm = 1.8562e-01, time/batch = 15.8315s	
28252/33150 (epoch 42.612), train_loss = 0.79321448, grad/param norm = 1.8964e-01, time/batch = 17.6336s	
28253/33150 (epoch 42.614), train_loss = 0.75413732, grad/param norm = 1.7000e-01, time/batch = 16.8870s	
28254/33150 (epoch 42.615), train_loss = 0.71948643, grad/param norm = 1.9114e-01, time/batch = 16.9768s	
28255/33150 (epoch 42.617), train_loss = 0.84186894, grad/param norm = 2.1560e-01, time/batch = 18.4742s	
28256/33150 (epoch 42.618), train_loss = 0.86139279, grad/param norm = 1.8520e-01, time/batch = 18.0473s	
28257/33150 (epoch 42.620), train_loss = 0.79434883, grad/param norm = 2.4956e-01, time/batch = 16.8764s	
28258/33150 (epoch 42.621), train_loss = 0.83637829, grad/param norm = 1.8891e-01, time/batch = 19.2285s	
28259/33150 (epoch 42.623), train_loss = 0.86423837, grad/param norm = 1.7326e-01, time/batch = 18.7983s	
28260/33150 (epoch 42.624), train_loss = 0.80608155, grad/param norm = 2.5579e-01, time/batch = 16.4679s	
28261/33150 (epoch 42.626), train_loss = 0.82654983, grad/param norm = 1.9248e-01, time/batch = 17.5449s	
28262/33150 (epoch 42.627), train_loss = 0.80816002, grad/param norm = 2.0997e-01, time/batch = 17.3019s	
28263/33150 (epoch 42.629), train_loss = 0.69278124, grad/param norm = 1.8457e-01, time/batch = 16.7087s	
28264/33150 (epoch 42.630), train_loss = 0.81570355, grad/param norm = 1.8588e-01, time/batch = 18.3858s	
28265/33150 (epoch 42.632), train_loss = 0.72533222, grad/param norm = 1.5540e-01, time/batch = 19.3836s	
28266/33150 (epoch 42.633), train_loss = 0.76964565, grad/param norm = 2.1229e-01, time/batch = 14.5014s	
28267/33150 (epoch 42.635), train_loss = 0.94864565, grad/param norm = 1.7558e-01, time/batch = 14.3386s	
28268/33150 (epoch 42.637), train_loss = 0.67885012, grad/param norm = 1.8989e-01, time/batch = 13.9307s	
28269/33150 (epoch 42.638), train_loss = 0.79605373, grad/param norm = 1.6619e-01, time/batch = 14.0179s	
28270/33150 (epoch 42.640), train_loss = 0.88443546, grad/param norm = 2.0276e-01, time/batch = 13.9416s	
28271/33150 (epoch 42.641), train_loss = 0.67734437, grad/param norm = 1.7638e-01, time/batch = 14.1006s	
28272/33150 (epoch 42.643), train_loss = 0.83179456, grad/param norm = 2.0541e-01, time/batch = 13.7730s	
28273/33150 (epoch 42.644), train_loss = 0.95415335, grad/param norm = 1.7005e-01, time/batch = 14.0889s	
28274/33150 (epoch 42.646), train_loss = 0.82854613, grad/param norm = 1.6228e-01, time/batch = 16.2443s	
28275/33150 (epoch 42.647), train_loss = 0.97939214, grad/param norm = 1.7726e-01, time/batch = 15.6536s	
28276/33150 (epoch 42.649), train_loss = 0.84970964, grad/param norm = 2.4009e-01, time/batch = 18.9614s	
28277/33150 (epoch 42.650), train_loss = 0.73493146, grad/param norm = 1.8019e-01, time/batch = 16.2280s	
28278/33150 (epoch 42.652), train_loss = 0.89826371, grad/param norm = 2.1847e-01, time/batch = 17.2302s	
28279/33150 (epoch 42.653), train_loss = 0.88046715, grad/param norm = 1.8093e-01, time/batch = 16.1131s	
28280/33150 (epoch 42.655), train_loss = 0.85128943, grad/param norm = 2.0061e-01, time/batch = 18.3181s	
28281/33150 (epoch 42.656), train_loss = 0.77876493, grad/param norm = 1.5788e-01, time/batch = 19.3890s	
28282/33150 (epoch 42.658), train_loss = 0.78330288, grad/param norm = 1.9431e-01, time/batch = 18.0365s	
28283/33150 (epoch 42.659), train_loss = 0.99585113, grad/param norm = 2.4260e-01, time/batch = 18.0453s	
28284/33150 (epoch 42.661), train_loss = 0.79934183, grad/param norm = 1.8140e-01, time/batch = 18.0548s	
28285/33150 (epoch 42.662), train_loss = 0.80310301, grad/param norm = 2.0325e-01, time/batch = 16.2962s	
28286/33150 (epoch 42.664), train_loss = 0.91823312, grad/param norm = 1.7920e-01, time/batch = 15.6192s	
28287/33150 (epoch 42.665), train_loss = 0.90377604, grad/param norm = 2.1100e-01, time/batch = 15.6122s	
28288/33150 (epoch 42.667), train_loss = 0.90678566, grad/param norm = 2.2242e-01, time/batch = 15.3419s	
28289/33150 (epoch 42.668), train_loss = 0.95460591, grad/param norm = 1.9357e-01, time/batch = 15.4833s	
28290/33150 (epoch 42.670), train_loss = 0.77817604, grad/param norm = 1.5586e-01, time/batch = 15.1639s	
28291/33150 (epoch 42.671), train_loss = 0.76193972, grad/param norm = 1.8600e-01, time/batch = 15.2438s	
28292/33150 (epoch 42.673), train_loss = 0.93668015, grad/param norm = 1.6278e-01, time/batch = 14.9876s	
28293/33150 (epoch 42.674), train_loss = 0.89278647, grad/param norm = 2.0326e-01, time/batch = 15.3862s	
28294/33150 (epoch 42.676), train_loss = 0.81462724, grad/param norm = 1.7197e-01, time/batch = 14.8945s	
28295/33150 (epoch 42.677), train_loss = 0.93909129, grad/param norm = 1.8107e-01, time/batch = 16.2388s	
28296/33150 (epoch 42.679), train_loss = 0.82087565, grad/param norm = 1.7034e-01, time/batch = 15.7691s	
28297/33150 (epoch 42.680), train_loss = 0.92052855, grad/param norm = 2.0267e-01, time/batch = 16.3612s	
28298/33150 (epoch 42.682), train_loss = 0.84984075, grad/param norm = 1.8327e-01, time/batch = 15.2037s	
28299/33150 (epoch 42.683), train_loss = 0.68530348, grad/param norm = 1.3884e-01, time/batch = 15.4991s	
28300/33150 (epoch 42.685), train_loss = 0.78573870, grad/param norm = 1.8831e-01, time/batch = 16.4377s	
28301/33150 (epoch 42.686), train_loss = 0.69821367, grad/param norm = 1.6740e-01, time/batch = 15.3447s	
28302/33150 (epoch 42.688), train_loss = 0.72357587, grad/param norm = 1.6949e-01, time/batch = 15.4141s	
28303/33150 (epoch 42.689), train_loss = 0.72975229, grad/param norm = 1.4341e-01, time/batch = 15.5816s	
28304/33150 (epoch 42.691), train_loss = 0.64102114, grad/param norm = 1.8032e-01, time/batch = 16.0692s	
28305/33150 (epoch 42.692), train_loss = 0.72948734, grad/param norm = 1.6669e-01, time/batch = 15.1497s	
28306/33150 (epoch 42.694), train_loss = 0.64865169, grad/param norm = 1.6325e-01, time/batch = 16.8332s	
28307/33150 (epoch 42.695), train_loss = 0.74528857, grad/param norm = 1.6165e-01, time/batch = 15.0876s	
28308/33150 (epoch 42.697), train_loss = 0.72142099, grad/param norm = 1.7066e-01, time/batch = 15.0721s	
28309/33150 (epoch 42.698), train_loss = 0.72783612, grad/param norm = 1.8744e-01, time/batch = 15.0508s	
28310/33150 (epoch 42.700), train_loss = 0.63291275, grad/param norm = 1.4216e-01, time/batch = 15.2370s	
28311/33150 (epoch 42.701), train_loss = 0.70555014, grad/param norm = 1.8284e-01, time/batch = 16.5416s	
28312/33150 (epoch 42.703), train_loss = 0.81367600, grad/param norm = 2.0661e-01, time/batch = 15.9616s	
28313/33150 (epoch 42.704), train_loss = 0.69376372, grad/param norm = 1.4892e-01, time/batch = 15.0189s	
28314/33150 (epoch 42.706), train_loss = 0.75211042, grad/param norm = 1.6637e-01, time/batch = 17.7828s	
28315/33150 (epoch 42.707), train_loss = 0.78640325, grad/param norm = 1.7736e-01, time/batch = 17.6287s	
28316/33150 (epoch 42.709), train_loss = 0.80926119, grad/param norm = 1.6522e-01, time/batch = 17.3086s	
28317/33150 (epoch 42.710), train_loss = 0.82334154, grad/param norm = 2.3193e-01, time/batch = 17.1253s	
28318/33150 (epoch 42.712), train_loss = 0.88557582, grad/param norm = 1.8063e-01, time/batch = 16.0937s	
28319/33150 (epoch 42.713), train_loss = 0.82814691, grad/param norm = 1.5289e-01, time/batch = 16.7903s	
28320/33150 (epoch 42.715), train_loss = 0.78135346, grad/param norm = 1.6978e-01, time/batch = 16.7115s	
28321/33150 (epoch 42.716), train_loss = 0.84846157, grad/param norm = 1.7978e-01, time/batch = 15.6009s	
28322/33150 (epoch 42.718), train_loss = 0.81139630, grad/param norm = 1.7799e-01, time/batch = 15.3388s	
28323/33150 (epoch 42.719), train_loss = 0.87162120, grad/param norm = 1.9987e-01, time/batch = 15.6041s	
28324/33150 (epoch 42.721), train_loss = 0.76736713, grad/param norm = 1.7737e-01, time/batch = 15.9652s	
28325/33150 (epoch 42.722), train_loss = 0.85203945, grad/param norm = 1.7071e-01, time/batch = 16.7705s	
28326/33150 (epoch 42.724), train_loss = 0.77722745, grad/param norm = 1.9751e-01, time/batch = 15.6076s	
28327/33150 (epoch 42.725), train_loss = 0.86777780, grad/param norm = 2.3525e-01, time/batch = 15.9263s	
28328/33150 (epoch 42.727), train_loss = 0.85019600, grad/param norm = 1.8872e-01, time/batch = 14.8729s	
28329/33150 (epoch 42.729), train_loss = 0.82168984, grad/param norm = 2.1069e-01, time/batch = 15.8574s	
28330/33150 (epoch 42.730), train_loss = 0.83341026, grad/param norm = 1.8768e-01, time/batch = 15.7708s	
28331/33150 (epoch 42.732), train_loss = 0.85595976, grad/param norm = 1.8254e-01, time/batch = 15.8515s	
28332/33150 (epoch 42.733), train_loss = 0.72092926, grad/param norm = 1.4773e-01, time/batch = 16.9504s	
28333/33150 (epoch 42.735), train_loss = 0.74263744, grad/param norm = 1.7955e-01, time/batch = 16.2830s	
28334/33150 (epoch 42.736), train_loss = 0.75840002, grad/param norm = 1.7552e-01, time/batch = 15.8673s	
28335/33150 (epoch 42.738), train_loss = 0.81612886, grad/param norm = 2.1601e-01, time/batch = 14.9713s	
28336/33150 (epoch 42.739), train_loss = 0.90811070, grad/param norm = 1.9676e-01, time/batch = 16.4266s	
28337/33150 (epoch 42.741), train_loss = 0.83425288, grad/param norm = 2.2773e-01, time/batch = 16.4805s	
28338/33150 (epoch 42.742), train_loss = 0.68246520, grad/param norm = 1.7112e-01, time/batch = 15.6325s	
28339/33150 (epoch 42.744), train_loss = 0.86728197, grad/param norm = 1.7616e-01, time/batch = 15.1215s	
28340/33150 (epoch 42.745), train_loss = 0.75915082, grad/param norm = 1.7330e-01, time/batch = 19.6223s	
28341/33150 (epoch 42.747), train_loss = 0.61680253, grad/param norm = 1.6943e-01, time/batch = 16.3510s	
28342/33150 (epoch 42.748), train_loss = 0.67993108, grad/param norm = 1.6637e-01, time/batch = 17.0272s	
28343/33150 (epoch 42.750), train_loss = 0.83499946, grad/param norm = 1.9129e-01, time/batch = 18.5110s	
28344/33150 (epoch 42.751), train_loss = 0.79402647, grad/param norm = 1.5418e-01, time/batch = 16.4226s	
28345/33150 (epoch 42.753), train_loss = 0.70044110, grad/param norm = 1.9036e-01, time/batch = 15.8536s	
28346/33150 (epoch 42.754), train_loss = 0.98949476, grad/param norm = 2.3458e-01, time/batch = 17.3898s	
28347/33150 (epoch 42.756), train_loss = 0.79960497, grad/param norm = 2.2531e-01, time/batch = 17.7973s	
28348/33150 (epoch 42.757), train_loss = 0.84736738, grad/param norm = 1.7953e-01, time/batch = 15.9481s	
28349/33150 (epoch 42.759), train_loss = 0.93276435, grad/param norm = 2.2621e-01, time/batch = 16.8606s	
28350/33150 (epoch 42.760), train_loss = 0.85885705, grad/param norm = 1.8781e-01, time/batch = 19.4516s	
28351/33150 (epoch 42.762), train_loss = 0.80748025, grad/param norm = 1.7538e-01, time/batch = 15.2375s	
28352/33150 (epoch 42.763), train_loss = 0.85002287, grad/param norm = 2.0179e-01, time/batch = 16.3875s	
28353/33150 (epoch 42.765), train_loss = 0.81192048, grad/param norm = 1.9117e-01, time/batch = 17.2580s	
28354/33150 (epoch 42.766), train_loss = 0.69491566, grad/param norm = 2.0522e-01, time/batch = 16.7055s	
28355/33150 (epoch 42.768), train_loss = 0.73926327, grad/param norm = 1.9099e-01, time/batch = 16.7072s	
28356/33150 (epoch 42.769), train_loss = 0.89300356, grad/param norm = 2.8226e-01, time/batch = 18.5395s	
28357/33150 (epoch 42.771), train_loss = 0.84659564, grad/param norm = 1.9098e-01, time/batch = 17.1983s	
28358/33150 (epoch 42.772), train_loss = 0.85144182, grad/param norm = 2.0508e-01, time/batch = 18.3000s	
28359/33150 (epoch 42.774), train_loss = 0.93958208, grad/param norm = 1.8485e-01, time/batch = 16.1232s	
28360/33150 (epoch 42.775), train_loss = 0.86291847, grad/param norm = 2.4070e-01, time/batch = 15.6267s	
28361/33150 (epoch 42.777), train_loss = 0.87019662, grad/param norm = 2.0023e-01, time/batch = 15.3784s	
28362/33150 (epoch 42.778), train_loss = 0.80145358, grad/param norm = 1.7763e-01, time/batch = 16.4312s	
28363/33150 (epoch 42.780), train_loss = 0.67886674, grad/param norm = 1.5153e-01, time/batch = 16.3015s	
28364/33150 (epoch 42.781), train_loss = 0.78323903, grad/param norm = 1.7661e-01, time/batch = 16.4741s	
28365/33150 (epoch 42.783), train_loss = 0.81314258, grad/param norm = 1.6316e-01, time/batch = 16.9771s	
28366/33150 (epoch 42.784), train_loss = 0.81836183, grad/param norm = 2.1922e-01, time/batch = 15.5454s	
28367/33150 (epoch 42.786), train_loss = 0.79832494, grad/param norm = 1.9429e-01, time/batch = 17.3843s	
28368/33150 (epoch 42.787), train_loss = 0.73041793, grad/param norm = 1.5440e-01, time/batch = 18.0237s	
28369/33150 (epoch 42.789), train_loss = 0.68747377, grad/param norm = 1.4791e-01, time/batch = 16.3894s	
28370/33150 (epoch 42.790), train_loss = 0.68567519, grad/param norm = 1.6519e-01, time/batch = 16.7064s	
28371/33150 (epoch 42.792), train_loss = 0.81445210, grad/param norm = 2.4857e-01, time/batch = 16.1285s	
28372/33150 (epoch 42.793), train_loss = 0.77248023, grad/param norm = 2.0244e-01, time/batch = 17.0332s	
28373/33150 (epoch 42.795), train_loss = 0.77556998, grad/param norm = 1.8094e-01, time/batch = 15.5923s	
28374/33150 (epoch 42.796), train_loss = 0.78513671, grad/param norm = 1.6654e-01, time/batch = 18.5202s	
28375/33150 (epoch 42.798), train_loss = 0.74218944, grad/param norm = 1.4331e-01, time/batch = 17.2766s	
28376/33150 (epoch 42.799), train_loss = 0.66351320, grad/param norm = 1.9427e-01, time/batch = 16.5899s	
28377/33150 (epoch 42.801), train_loss = 0.82516838, grad/param norm = 2.0436e-01, time/batch = 15.3722s	
28378/33150 (epoch 42.802), train_loss = 0.77542733, grad/param norm = 1.6797e-01, time/batch = 16.4752s	
28379/33150 (epoch 42.804), train_loss = 0.76176952, grad/param norm = 1.7572e-01, time/batch = 16.0478s	
28380/33150 (epoch 42.805), train_loss = 0.73129266, grad/param norm = 2.0182e-01, time/batch = 15.7110s	
28381/33150 (epoch 42.807), train_loss = 0.80013933, grad/param norm = 1.6143e-01, time/batch = 15.6138s	
28382/33150 (epoch 42.808), train_loss = 0.88497505, grad/param norm = 1.8628e-01, time/batch = 15.4377s	
28383/33150 (epoch 42.810), train_loss = 0.73107643, grad/param norm = 1.7955e-01, time/batch = 14.9737s	
28384/33150 (epoch 42.811), train_loss = 0.82810901, grad/param norm = 2.0532e-01, time/batch = 15.1781s	
28385/33150 (epoch 42.813), train_loss = 0.77323086, grad/param norm = 1.6454e-01, time/batch = 15.8636s	
28386/33150 (epoch 42.814), train_loss = 0.75546737, grad/param norm = 2.0323e-01, time/batch = 16.3657s	
28387/33150 (epoch 42.816), train_loss = 0.74994268, grad/param norm = 1.8797e-01, time/batch = 17.2067s	
28388/33150 (epoch 42.817), train_loss = 0.84228220, grad/param norm = 1.9251e-01, time/batch = 15.6445s	
28389/33150 (epoch 42.819), train_loss = 0.83250009, grad/param norm = 1.9908e-01, time/batch = 15.6728s	
28390/33150 (epoch 42.821), train_loss = 0.72502064, grad/param norm = 1.4851e-01, time/batch = 16.9752s	
28391/33150 (epoch 42.822), train_loss = 0.76113714, grad/param norm = 1.9088e-01, time/batch = 15.0997s	
28392/33150 (epoch 42.824), train_loss = 0.83062598, grad/param norm = 1.9714e-01, time/batch = 15.5591s	
28393/33150 (epoch 42.825), train_loss = 0.84526052, grad/param norm = 1.8251e-01, time/batch = 15.5518s	
28394/33150 (epoch 42.827), train_loss = 0.85506132, grad/param norm = 2.0220e-01, time/batch = 18.1337s	
28395/33150 (epoch 42.828), train_loss = 0.72172669, grad/param norm = 1.7226e-01, time/batch = 22.2234s	
28396/33150 (epoch 42.830), train_loss = 0.85214412, grad/param norm = 1.9685e-01, time/batch = 22.1141s	
28397/33150 (epoch 42.831), train_loss = 0.75140172, grad/param norm = 1.7978e-01, time/batch = 15.1038s	
28398/33150 (epoch 42.833), train_loss = 0.71864502, grad/param norm = 1.6395e-01, time/batch = 16.4541s	
28399/33150 (epoch 42.834), train_loss = 0.88666701, grad/param norm = 1.6974e-01, time/batch = 16.2895s	
28400/33150 (epoch 42.836), train_loss = 0.90780646, grad/param norm = 1.6582e-01, time/batch = 16.3098s	
28401/33150 (epoch 42.837), train_loss = 0.73739800, grad/param norm = 1.8215e-01, time/batch = 15.4441s	
28402/33150 (epoch 42.839), train_loss = 0.88289498, grad/param norm = 2.0684e-01, time/batch = 15.8846s	
28403/33150 (epoch 42.840), train_loss = 0.84802679, grad/param norm = 1.8071e-01, time/batch = 16.3919s	
28404/33150 (epoch 42.842), train_loss = 0.92339975, grad/param norm = 2.7111e-01, time/batch = 17.0461s	
28405/33150 (epoch 42.843), train_loss = 0.91387138, grad/param norm = 1.9687e-01, time/batch = 16.5378s	
28406/33150 (epoch 42.845), train_loss = 0.76350526, grad/param norm = 1.7271e-01, time/batch = 16.7101s	
28407/33150 (epoch 42.846), train_loss = 0.99024518, grad/param norm = 3.4317e-01, time/batch = 19.0240s	
28408/33150 (epoch 42.848), train_loss = 0.89003830, grad/param norm = 1.9947e-01, time/batch = 17.4536s	
28409/33150 (epoch 42.849), train_loss = 0.89378745, grad/param norm = 1.7290e-01, time/batch = 15.7741s	
28410/33150 (epoch 42.851), train_loss = 0.87794233, grad/param norm = 2.0715e-01, time/batch = 18.1317s	
28411/33150 (epoch 42.852), train_loss = 0.96568083, grad/param norm = 2.0463e-01, time/batch = 17.9349s	
28412/33150 (epoch 42.854), train_loss = 0.85594684, grad/param norm = 2.0243e-01, time/batch = 18.5307s	
28413/33150 (epoch 42.855), train_loss = 0.75099869, grad/param norm = 1.7523e-01, time/batch = 16.7978s	
28414/33150 (epoch 42.857), train_loss = 0.69854592, grad/param norm = 2.1679e-01, time/batch = 15.3578s	
28415/33150 (epoch 42.858), train_loss = 0.76757683, grad/param norm = 1.7884e-01, time/batch = 15.5054s	
28416/33150 (epoch 42.860), train_loss = 0.75181325, grad/param norm = 2.1373e-01, time/batch = 16.9589s	
28417/33150 (epoch 42.861), train_loss = 0.70805328, grad/param norm = 1.6622e-01, time/batch = 15.9588s	
28418/33150 (epoch 42.863), train_loss = 0.78346614, grad/param norm = 1.6597e-01, time/batch = 15.5564s	
28419/33150 (epoch 42.864), train_loss = 0.82949910, grad/param norm = 1.9743e-01, time/batch = 17.0378s	
28420/33150 (epoch 42.866), train_loss = 0.88201755, grad/param norm = 1.7586e-01, time/batch = 15.9344s	
28421/33150 (epoch 42.867), train_loss = 0.82166304, grad/param norm = 1.8064e-01, time/batch = 17.0138s	
28422/33150 (epoch 42.869), train_loss = 0.82502319, grad/param norm = 1.9384e-01, time/batch = 15.1086s	
28423/33150 (epoch 42.870), train_loss = 0.79435266, grad/param norm = 2.2220e-01, time/batch = 16.4761s	
28424/33150 (epoch 42.872), train_loss = 0.88047385, grad/param norm = 2.4772e-01, time/batch = 15.3669s	
28425/33150 (epoch 42.873), train_loss = 0.68548701, grad/param norm = 1.6437e-01, time/batch = 14.6802s	
28426/33150 (epoch 42.875), train_loss = 0.90543852, grad/param norm = 1.8128e-01, time/batch = 15.0221s	
28427/33150 (epoch 42.876), train_loss = 0.67387955, grad/param norm = 1.5989e-01, time/batch = 15.2560s	
28428/33150 (epoch 42.878), train_loss = 0.75806257, grad/param norm = 1.5869e-01, time/batch = 15.1745s	
28429/33150 (epoch 42.879), train_loss = 0.74828692, grad/param norm = 1.6748e-01, time/batch = 17.0528s	
28430/33150 (epoch 42.881), train_loss = 0.73924637, grad/param norm = 1.5816e-01, time/batch = 17.0531s	
28431/33150 (epoch 42.882), train_loss = 0.61724062, grad/param norm = 1.4881e-01, time/batch = 16.1077s	
28432/33150 (epoch 42.884), train_loss = 0.74307603, grad/param norm = 2.0294e-01, time/batch = 15.7041s	
28433/33150 (epoch 42.885), train_loss = 0.61727880, grad/param norm = 1.7802e-01, time/batch = 15.7915s	
28434/33150 (epoch 42.887), train_loss = 0.87271983, grad/param norm = 1.8504e-01, time/batch = 16.0533s	
28435/33150 (epoch 42.888), train_loss = 0.80289252, grad/param norm = 1.8113e-01, time/batch = 16.6459s	
28436/33150 (epoch 42.890), train_loss = 0.70005524, grad/param norm = 1.7013e-01, time/batch = 16.4525s	
28437/33150 (epoch 42.891), train_loss = 0.70570256, grad/param norm = 1.6764e-01, time/batch = 16.0505s	
28438/33150 (epoch 42.893), train_loss = 0.84996930, grad/param norm = 2.0019e-01, time/batch = 17.0442s	
28439/33150 (epoch 42.894), train_loss = 0.84234248, grad/param norm = 1.7004e-01, time/batch = 16.3554s	
28440/33150 (epoch 42.896), train_loss = 0.78269819, grad/param norm = 1.6242e-01, time/batch = 19.6223s	
28441/33150 (epoch 42.897), train_loss = 0.85110036, grad/param norm = 1.8019e-01, time/batch = 16.4678s	
28442/33150 (epoch 42.899), train_loss = 0.64623014, grad/param norm = 1.6859e-01, time/batch = 16.1973s	
28443/33150 (epoch 42.900), train_loss = 0.95991673, grad/param norm = 2.2486e-01, time/batch = 17.5462s	
28444/33150 (epoch 42.902), train_loss = 1.00300802, grad/param norm = 1.8675e-01, time/batch = 18.2147s	
28445/33150 (epoch 42.903), train_loss = 0.82755126, grad/param norm = 1.7051e-01, time/batch = 16.7135s	
28446/33150 (epoch 42.905), train_loss = 0.79280342, grad/param norm = 1.6455e-01, time/batch = 15.4426s	
28447/33150 (epoch 42.906), train_loss = 0.81890597, grad/param norm = 1.9554e-01, time/batch = 18.4447s	
28448/33150 (epoch 42.908), train_loss = 0.85288232, grad/param norm = 1.8396e-01, time/batch = 17.4657s	
28449/33150 (epoch 42.910), train_loss = 0.87488909, grad/param norm = 1.8560e-01, time/batch = 16.1170s	
28450/33150 (epoch 42.911), train_loss = 0.69997457, grad/param norm = 1.6002e-01, time/batch = 16.9383s	
28451/33150 (epoch 42.913), train_loss = 0.77112034, grad/param norm = 1.9922e-01, time/batch = 16.3754s	
28452/33150 (epoch 42.914), train_loss = 0.79898005, grad/param norm = 1.7521e-01, time/batch = 15.4561s	
28453/33150 (epoch 42.916), train_loss = 0.73635175, grad/param norm = 1.7445e-01, time/batch = 15.3645s	
28454/33150 (epoch 42.917), train_loss = 0.82634179, grad/param norm = 1.7574e-01, time/batch = 15.3415s	
28455/33150 (epoch 42.919), train_loss = 0.93486800, grad/param norm = 2.3996e-01, time/batch = 14.8605s	
28456/33150 (epoch 42.920), train_loss = 0.89491707, grad/param norm = 1.9830e-01, time/batch = 15.1065s	
28457/33150 (epoch 42.922), train_loss = 0.91652450, grad/param norm = 2.2518e-01, time/batch = 15.2599s	
28458/33150 (epoch 42.923), train_loss = 0.83566609, grad/param norm = 2.0490e-01, time/batch = 15.0691s	
28459/33150 (epoch 42.925), train_loss = 0.91094011, grad/param norm = 2.2512e-01, time/batch = 16.9448s	
28460/33150 (epoch 42.926), train_loss = 0.80067243, grad/param norm = 1.8499e-01, time/batch = 17.3072s	
28461/33150 (epoch 42.928), train_loss = 0.79443756, grad/param norm = 1.8874e-01, time/batch = 17.3546s	
28462/33150 (epoch 42.929), train_loss = 0.85183174, grad/param norm = 1.7605e-01, time/batch = 16.8617s	
28463/33150 (epoch 42.931), train_loss = 0.90168433, grad/param norm = 2.0923e-01, time/batch = 17.4511s	
28464/33150 (epoch 42.932), train_loss = 0.84104456, grad/param norm = 2.9174e-01, time/batch = 15.3107s	
28465/33150 (epoch 42.934), train_loss = 0.82831579, grad/param norm = 1.7012e-01, time/batch = 16.7099s	
28466/33150 (epoch 42.935), train_loss = 0.89967714, grad/param norm = 2.0236e-01, time/batch = 14.7528s	
28467/33150 (epoch 42.937), train_loss = 0.92419134, grad/param norm = 1.6342e-01, time/batch = 16.2765s	
28468/33150 (epoch 42.938), train_loss = 0.84496596, grad/param norm = 1.7441e-01, time/batch = 15.5520s	
28469/33150 (epoch 42.940), train_loss = 1.05911762, grad/param norm = 2.0697e-01, time/batch = 14.9190s	
28470/33150 (epoch 42.941), train_loss = 0.86631156, grad/param norm = 1.6533e-01, time/batch = 14.9458s	
28471/33150 (epoch 42.943), train_loss = 0.66829864, grad/param norm = 1.6501e-01, time/batch = 14.7556s	
28472/33150 (epoch 42.944), train_loss = 0.86101740, grad/param norm = 1.8526e-01, time/batch = 15.0923s	
28473/33150 (epoch 42.946), train_loss = 0.72020803, grad/param norm = 1.4586e-01, time/batch = 15.1010s	
28474/33150 (epoch 42.947), train_loss = 0.84468569, grad/param norm = 1.5760e-01, time/batch = 14.6535s	
28475/33150 (epoch 42.949), train_loss = 0.90643194, grad/param norm = 1.6587e-01, time/batch = 14.7345s	
28476/33150 (epoch 42.950), train_loss = 0.90515411, grad/param norm = 1.8514e-01, time/batch = 15.2771s	
28477/33150 (epoch 42.952), train_loss = 0.75836236, grad/param norm = 1.7225e-01, time/batch = 14.7081s	
28478/33150 (epoch 42.953), train_loss = 0.80694116, grad/param norm = 1.6438e-01, time/batch = 15.3563s	
28479/33150 (epoch 42.955), train_loss = 0.69329532, grad/param norm = 1.8371e-01, time/batch = 14.9994s	
28480/33150 (epoch 42.956), train_loss = 0.86249162, grad/param norm = 1.7520e-01, time/batch = 15.1011s	
28481/33150 (epoch 42.958), train_loss = 0.74448042, grad/param norm = 1.6754e-01, time/batch = 15.4369s	
28482/33150 (epoch 42.959), train_loss = 0.80916873, grad/param norm = 1.8746e-01, time/batch = 15.0865s	
28483/33150 (epoch 42.961), train_loss = 0.72505241, grad/param norm = 1.7107e-01, time/batch = 15.6218s	
28484/33150 (epoch 42.962), train_loss = 0.68432438, grad/param norm = 1.5696e-01, time/batch = 14.9338s	
28485/33150 (epoch 42.964), train_loss = 0.79149801, grad/param norm = 1.7422e-01, time/batch = 14.8863s	
28486/33150 (epoch 42.965), train_loss = 0.79074292, grad/param norm = 1.7296e-01, time/batch = 16.0251s	
28487/33150 (epoch 42.967), train_loss = 0.79331847, grad/param norm = 1.9113e-01, time/batch = 15.6982s	
28488/33150 (epoch 42.968), train_loss = 0.66983244, grad/param norm = 1.4566e-01, time/batch = 16.7950s	
28489/33150 (epoch 42.970), train_loss = 0.77632200, grad/param norm = 1.9358e-01, time/batch = 16.5548s	
28490/33150 (epoch 42.971), train_loss = 0.80289529, grad/param norm = 1.6748e-01, time/batch = 18.7786s	
28491/33150 (epoch 42.973), train_loss = 0.87743974, grad/param norm = 1.7168e-01, time/batch = 15.6111s	
28492/33150 (epoch 42.974), train_loss = 0.93039920, grad/param norm = 1.9856e-01, time/batch = 19.3541s	
28493/33150 (epoch 42.976), train_loss = 0.89242015, grad/param norm = 1.7862e-01, time/batch = 16.6951s	
28494/33150 (epoch 42.977), train_loss = 0.92830355, grad/param norm = 1.9894e-01, time/batch = 17.3605s	
28495/33150 (epoch 42.979), train_loss = 0.88429555, grad/param norm = 1.9580e-01, time/batch = 17.2220s	
28496/33150 (epoch 42.980), train_loss = 0.95791978, grad/param norm = 2.1296e-01, time/batch = 19.9553s	
28497/33150 (epoch 42.982), train_loss = 0.82924393, grad/param norm = 2.1800e-01, time/batch = 17.2109s	
28498/33150 (epoch 42.983), train_loss = 0.73126241, grad/param norm = 1.7557e-01, time/batch = 16.8654s	
28499/33150 (epoch 42.985), train_loss = 0.91800854, grad/param norm = 1.7127e-01, time/batch = 18.7175s	
28500/33150 (epoch 42.986), train_loss = 0.69755867, grad/param norm = 1.6220e-01, time/batch = 19.5369s	
28501/33150 (epoch 42.988), train_loss = 0.78717541, grad/param norm = 2.4751e-01, time/batch = 17.3715s	
28502/33150 (epoch 42.989), train_loss = 0.80674815, grad/param norm = 1.6854e-01, time/batch = 17.5442s	
28503/33150 (epoch 42.991), train_loss = 0.86072264, grad/param norm = 2.7917e-01, time/batch = 17.6130s	
28504/33150 (epoch 42.992), train_loss = 0.80038592, grad/param norm = 1.7140e-01, time/batch = 15.2935s	
28505/33150 (epoch 42.994), train_loss = 0.83789113, grad/param norm = 1.6738e-01, time/batch = 14.9450s	
28506/33150 (epoch 42.995), train_loss = 0.78487242, grad/param norm = 1.9520e-01, time/batch = 17.3078s	
28507/33150 (epoch 42.997), train_loss = 0.80460666, grad/param norm = 1.8259e-01, time/batch = 17.2928s	
28508/33150 (epoch 42.998), train_loss = 0.67859937, grad/param norm = 1.7226e-01, time/batch = 15.7186s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
28509/33150 (epoch 43.000), train_loss = 0.71992136, grad/param norm = 1.7528e-01, time/batch = 16.8170s	
28510/33150 (epoch 43.002), train_loss = 1.09586693, grad/param norm = 2.0474e-01, time/batch = 15.4453s	
28511/33150 (epoch 43.003), train_loss = 0.73515401, grad/param norm = 1.7441e-01, time/batch = 16.8018s	
28512/33150 (epoch 43.005), train_loss = 0.70504136, grad/param norm = 1.6175e-01, time/batch = 14.9229s	
28513/33150 (epoch 43.006), train_loss = 0.68747176, grad/param norm = 1.6863e-01, time/batch = 18.4538s	
28514/33150 (epoch 43.008), train_loss = 0.87156397, grad/param norm = 1.9755e-01, time/batch = 15.2142s	
28515/33150 (epoch 43.009), train_loss = 0.84138198, grad/param norm = 1.8313e-01, time/batch = 17.2112s	
28516/33150 (epoch 43.011), train_loss = 0.89448918, grad/param norm = 1.7576e-01, time/batch = 17.1487s	
28517/33150 (epoch 43.012), train_loss = 0.80632267, grad/param norm = 2.3463e-01, time/batch = 17.7196s	
28518/33150 (epoch 43.014), train_loss = 0.73202031, grad/param norm = 1.8049e-01, time/batch = 16.2115s	
28519/33150 (epoch 43.015), train_loss = 0.73601568, grad/param norm = 1.9220e-01, time/batch = 15.8657s	
28520/33150 (epoch 43.017), train_loss = 0.72753147, grad/param norm = 1.5831e-01, time/batch = 15.9495s	
28521/33150 (epoch 43.018), train_loss = 0.83230553, grad/param norm = 2.0622e-01, time/batch = 17.2237s	
28522/33150 (epoch 43.020), train_loss = 0.87177032, grad/param norm = 1.8503e-01, time/batch = 16.2137s	
28523/33150 (epoch 43.021), train_loss = 0.73516328, grad/param norm = 1.8200e-01, time/batch = 17.6239s	
28524/33150 (epoch 43.023), train_loss = 0.98639251, grad/param norm = 1.7872e-01, time/batch = 15.7113s	
28525/33150 (epoch 43.024), train_loss = 0.84892274, grad/param norm = 1.9123e-01, time/batch = 17.2111s	
28526/33150 (epoch 43.026), train_loss = 0.64115537, grad/param norm = 1.7094e-01, time/batch = 16.2892s	
28527/33150 (epoch 43.027), train_loss = 0.65910406, grad/param norm = 1.5975e-01, time/batch = 15.7854s	
28528/33150 (epoch 43.029), train_loss = 0.74749283, grad/param norm = 1.6534e-01, time/batch = 17.2262s	
28529/33150 (epoch 43.030), train_loss = 0.79000813, grad/param norm = 1.5224e-01, time/batch = 16.6017s	
28530/33150 (epoch 43.032), train_loss = 0.69875645, grad/param norm = 1.7277e-01, time/batch = 16.7134s	
28531/33150 (epoch 43.033), train_loss = 0.73402986, grad/param norm = 1.7364e-01, time/batch = 18.0401s	
28532/33150 (epoch 43.035), train_loss = 0.96558173, grad/param norm = 1.8399e-01, time/batch = 19.5361s	
28533/33150 (epoch 43.036), train_loss = 0.88435374, grad/param norm = 2.0665e-01, time/batch = 18.0291s	
28534/33150 (epoch 43.038), train_loss = 0.96406073, grad/param norm = 1.7912e-01, time/batch = 15.4648s	
28535/33150 (epoch 43.039), train_loss = 0.86661140, grad/param norm = 1.6887e-01, time/batch = 17.8807s	
28536/33150 (epoch 43.041), train_loss = 0.80853403, grad/param norm = 1.6425e-01, time/batch = 15.7875s	
28537/33150 (epoch 43.042), train_loss = 0.74429115, grad/param norm = 1.9353e-01, time/batch = 15.0126s	
28538/33150 (epoch 43.044), train_loss = 0.81554396, grad/param norm = 2.1050e-01, time/batch = 17.9790s	
28539/33150 (epoch 43.045), train_loss = 0.88246469, grad/param norm = 1.7316e-01, time/batch = 16.3488s	
28540/33150 (epoch 43.047), train_loss = 0.72695112, grad/param norm = 1.5718e-01, time/batch = 16.2939s	
28541/33150 (epoch 43.048), train_loss = 0.87105987, grad/param norm = 2.3410e-01, time/batch = 18.7929s	
28542/33150 (epoch 43.050), train_loss = 0.78402448, grad/param norm = 1.8254e-01, time/batch = 18.7073s	
28543/33150 (epoch 43.051), train_loss = 0.82991781, grad/param norm = 1.6386e-01, time/batch = 15.9517s	
28544/33150 (epoch 43.053), train_loss = 0.84625365, grad/param norm = 1.7232e-01, time/batch = 16.3633s	
28545/33150 (epoch 43.054), train_loss = 0.94072340, grad/param norm = 1.7589e-01, time/batch = 15.9573s	
28546/33150 (epoch 43.056), train_loss = 0.78748499, grad/param norm = 1.6436e-01, time/batch = 17.2890s	
28547/33150 (epoch 43.057), train_loss = 0.85587618, grad/param norm = 1.5471e-01, time/batch = 15.4631s	
28548/33150 (epoch 43.059), train_loss = 0.72211124, grad/param norm = 1.7554e-01, time/batch = 16.9489s	
28549/33150 (epoch 43.060), train_loss = 0.71879176, grad/param norm = 1.5395e-01, time/batch = 18.1245s	
28550/33150 (epoch 43.062), train_loss = 0.80203030, grad/param norm = 2.0050e-01, time/batch = 15.6875s	
28551/33150 (epoch 43.063), train_loss = 0.73069400, grad/param norm = 1.8243e-01, time/batch = 16.1934s	
28552/33150 (epoch 43.065), train_loss = 0.81007291, grad/param norm = 1.7087e-01, time/batch = 17.3002s	
28553/33150 (epoch 43.066), train_loss = 0.78034015, grad/param norm = 1.7503e-01, time/batch = 16.8642s	
28554/33150 (epoch 43.068), train_loss = 0.85526701, grad/param norm = 1.7118e-01, time/batch = 15.7613s	
28555/33150 (epoch 43.069), train_loss = 0.83838675, grad/param norm = 1.8335e-01, time/batch = 15.5445s	
28556/33150 (epoch 43.071), train_loss = 0.83364718, grad/param norm = 1.7999e-01, time/batch = 16.0112s	
28557/33150 (epoch 43.072), train_loss = 0.82564996, grad/param norm = 2.1553e-01, time/batch = 18.1296s	
28558/33150 (epoch 43.074), train_loss = 0.69239164, grad/param norm = 1.9839e-01, time/batch = 15.3275s	
28559/33150 (epoch 43.075), train_loss = 0.71029961, grad/param norm = 1.7327e-01, time/batch = 16.6977s	
28560/33150 (epoch 43.077), train_loss = 0.81708479, grad/param norm = 3.0992e-01, time/batch = 16.6649s	
28561/33150 (epoch 43.078), train_loss = 0.93082092, grad/param norm = 2.0898e-01, time/batch = 16.1801s	
28562/33150 (epoch 43.080), train_loss = 0.94118742, grad/param norm = 1.8950e-01, time/batch = 15.8013s	
28563/33150 (epoch 43.081), train_loss = 0.71844560, grad/param norm = 1.8805e-01, time/batch = 17.2771s	
28564/33150 (epoch 43.083), train_loss = 0.58489213, grad/param norm = 2.3838e-01, time/batch = 15.4995s	
28565/33150 (epoch 43.084), train_loss = 0.67765083, grad/param norm = 1.7856e-01, time/batch = 17.2051s	
28566/33150 (epoch 43.086), train_loss = 0.74240174, grad/param norm = 2.0708e-01, time/batch = 16.0124s	
28567/33150 (epoch 43.087), train_loss = 0.69670504, grad/param norm = 2.1651e-01, time/batch = 15.8560s	
28568/33150 (epoch 43.089), train_loss = 0.73746503, grad/param norm = 1.6655e-01, time/batch = 17.4478s	
28569/33150 (epoch 43.090), train_loss = 0.76809507, grad/param norm = 1.6517e-01, time/batch = 16.9312s	
28570/33150 (epoch 43.092), train_loss = 0.74779784, grad/param norm = 2.0125e-01, time/batch = 15.6991s	
28571/33150 (epoch 43.094), train_loss = 0.82839400, grad/param norm = 1.9508e-01, time/batch = 17.1827s	
28572/33150 (epoch 43.095), train_loss = 0.74745987, grad/param norm = 1.9151e-01, time/batch = 15.5794s	
28573/33150 (epoch 43.097), train_loss = 0.69104972, grad/param norm = 1.8856e-01, time/batch = 15.9590s	
28574/33150 (epoch 43.098), train_loss = 1.02986648, grad/param norm = 1.9930e-01, time/batch = 15.2248s	
28575/33150 (epoch 43.100), train_loss = 0.98910627, grad/param norm = 2.2538e-01, time/batch = 16.2776s	
28576/33150 (epoch 43.101), train_loss = 0.73898101, grad/param norm = 1.8428e-01, time/batch = 15.6047s	
28577/33150 (epoch 43.103), train_loss = 0.81692272, grad/param norm = 1.8550e-01, time/batch = 15.7264s	
28578/33150 (epoch 43.104), train_loss = 0.74598558, grad/param norm = 2.2077e-01, time/batch = 16.7939s	
28579/33150 (epoch 43.106), train_loss = 0.91491604, grad/param norm = 1.9139e-01, time/batch = 16.0194s	
28580/33150 (epoch 43.107), train_loss = 0.98169901, grad/param norm = 2.3883e-01, time/batch = 16.3419s	
28581/33150 (epoch 43.109), train_loss = 0.78736024, grad/param norm = 1.5193e-01, time/batch = 15.5892s	
28582/33150 (epoch 43.110), train_loss = 0.90723933, grad/param norm = 2.2777e-01, time/batch = 15.8898s	
28583/33150 (epoch 43.112), train_loss = 0.72564010, grad/param norm = 1.8532e-01, time/batch = 15.6891s	
28584/33150 (epoch 43.113), train_loss = 0.78742905, grad/param norm = 1.6859e-01, time/batch = 17.2121s	
28585/33150 (epoch 43.115), train_loss = 0.97055158, grad/param norm = 1.9957e-01, time/batch = 17.6336s	
28586/33150 (epoch 43.116), train_loss = 0.86225767, grad/param norm = 1.8365e-01, time/batch = 15.3825s	
28587/33150 (epoch 43.118), train_loss = 0.84138326, grad/param norm = 1.9262e-01, time/batch = 16.0418s	
28588/33150 (epoch 43.119), train_loss = 0.87093689, grad/param norm = 2.1795e-01, time/batch = 14.6939s	
28589/33150 (epoch 43.121), train_loss = 0.80978977, grad/param norm = 1.8250e-01, time/batch = 16.8773s	
28590/33150 (epoch 43.122), train_loss = 0.92185054, grad/param norm = 2.3278e-01, time/batch = 15.2908s	
28591/33150 (epoch 43.124), train_loss = 0.68016170, grad/param norm = 1.5271e-01, time/batch = 15.1973s	
28592/33150 (epoch 43.125), train_loss = 0.92333273, grad/param norm = 1.8068e-01, time/batch = 16.0589s	
28593/33150 (epoch 43.127), train_loss = 0.83876543, grad/param norm = 1.9071e-01, time/batch = 15.4742s	
28594/33150 (epoch 43.128), train_loss = 0.85497873, grad/param norm = 1.8586e-01, time/batch = 16.5487s	
28595/33150 (epoch 43.130), train_loss = 0.80313055, grad/param norm = 1.8832e-01, time/batch = 15.7548s	
28596/33150 (epoch 43.131), train_loss = 0.98442519, grad/param norm = 1.9629e-01, time/batch = 15.5204s	
28597/33150 (epoch 43.133), train_loss = 0.76410635, grad/param norm = 1.5966e-01, time/batch = 18.3715s	
28598/33150 (epoch 43.134), train_loss = 0.92388370, grad/param norm = 1.7941e-01, time/batch = 16.7997s	
28599/33150 (epoch 43.136), train_loss = 0.84644000, grad/param norm = 2.1932e-01, time/batch = 16.6295s	
28600/33150 (epoch 43.137), train_loss = 0.88024289, grad/param norm = 1.7154e-01, time/batch = 18.2080s	
28601/33150 (epoch 43.139), train_loss = 0.89490251, grad/param norm = 2.7990e-01, time/batch = 18.7846s	
28602/33150 (epoch 43.140), train_loss = 0.96712484, grad/param norm = 2.1743e-01, time/batch = 16.5288s	
28603/33150 (epoch 43.142), train_loss = 0.87394442, grad/param norm = 2.0810e-01, time/batch = 16.8629s	
28604/33150 (epoch 43.143), train_loss = 0.82589386, grad/param norm = 2.2254e-01, time/batch = 15.7736s	
28605/33150 (epoch 43.145), train_loss = 0.78030039, grad/param norm = 1.9917e-01, time/batch = 17.0437s	
28606/33150 (epoch 43.146), train_loss = 0.92604673, grad/param norm = 2.2624e-01, time/batch = 16.3033s	
28607/33150 (epoch 43.148), train_loss = 0.96334029, grad/param norm = 1.7637e-01, time/batch = 17.2652s	
28608/33150 (epoch 43.149), train_loss = 0.85478881, grad/param norm = 1.9128e-01, time/batch = 17.0386s	
28609/33150 (epoch 43.151), train_loss = 0.97122382, grad/param norm = 1.9354e-01, time/batch = 17.2707s	
28610/33150 (epoch 43.152), train_loss = 0.75505390, grad/param norm = 1.5639e-01, time/batch = 14.9279s	
28611/33150 (epoch 43.154), train_loss = 0.75947918, grad/param norm = 1.8626e-01, time/batch = 15.8441s	
28612/33150 (epoch 43.155), train_loss = 0.69453897, grad/param norm = 1.6984e-01, time/batch = 18.1859s	
28613/33150 (epoch 43.157), train_loss = 0.79014826, grad/param norm = 1.8073e-01, time/batch = 29.8395s	
28614/33150 (epoch 43.158), train_loss = 0.80307198, grad/param norm = 1.7389e-01, time/batch = 15.2037s	
28615/33150 (epoch 43.160), train_loss = 0.88334283, grad/param norm = 1.9024e-01, time/batch = 14.8626s	
28616/33150 (epoch 43.161), train_loss = 0.78404969, grad/param norm = 1.9746e-01, time/batch = 14.7666s	
28617/33150 (epoch 43.163), train_loss = 0.71435319, grad/param norm = 1.6408e-01, time/batch = 15.1100s	
28618/33150 (epoch 43.164), train_loss = 0.85304508, grad/param norm = 1.8739e-01, time/batch = 15.6685s	
28619/33150 (epoch 43.166), train_loss = 0.78307758, grad/param norm = 1.8698e-01, time/batch = 17.5292s	
28620/33150 (epoch 43.167), train_loss = 0.84005579, grad/param norm = 1.5569e-01, time/batch = 16.3658s	
28621/33150 (epoch 43.169), train_loss = 0.83083907, grad/param norm = 2.3953e-01, time/batch = 17.9626s	
28622/33150 (epoch 43.170), train_loss = 0.72786348, grad/param norm = 2.3200e-01, time/batch = 17.7208s	
28623/33150 (epoch 43.172), train_loss = 0.86384358, grad/param norm = 2.1375e-01, time/batch = 17.8865s	
28624/33150 (epoch 43.173), train_loss = 0.84016603, grad/param norm = 2.1390e-01, time/batch = 18.6095s	
28625/33150 (epoch 43.175), train_loss = 0.77344215, grad/param norm = 1.9983e-01, time/batch = 18.2983s	
28626/33150 (epoch 43.176), train_loss = 0.86818864, grad/param norm = 1.8395e-01, time/batch = 17.1268s	
28627/33150 (epoch 43.178), train_loss = 0.99408917, grad/param norm = 2.1698e-01, time/batch = 18.1198s	
28628/33150 (epoch 43.179), train_loss = 0.88327323, grad/param norm = 1.9304e-01, time/batch = 19.8748s	
28629/33150 (epoch 43.181), train_loss = 0.83974826, grad/param norm = 2.4443e-01, time/batch = 17.6352s	
28630/33150 (epoch 43.183), train_loss = 0.79277936, grad/param norm = 2.0833e-01, time/batch = 17.2855s	
28631/33150 (epoch 43.184), train_loss = 1.05654938, grad/param norm = 1.8614e-01, time/batch = 17.3973s	
28632/33150 (epoch 43.186), train_loss = 0.98838202, grad/param norm = 1.7351e-01, time/batch = 18.0555s	
28633/33150 (epoch 43.187), train_loss = 0.81888374, grad/param norm = 1.8590e-01, time/batch = 17.7981s	
28634/33150 (epoch 43.189), train_loss = 0.65239207, grad/param norm = 1.6177e-01, time/batch = 16.7190s	
28635/33150 (epoch 43.190), train_loss = 0.74549089, grad/param norm = 1.7654e-01, time/batch = 17.1461s	
28636/33150 (epoch 43.192), train_loss = 0.85216641, grad/param norm = 1.8346e-01, time/batch = 17.1421s	
28637/33150 (epoch 43.193), train_loss = 0.88137640, grad/param norm = 1.8132e-01, time/batch = 16.5471s	
28638/33150 (epoch 43.195), train_loss = 1.00984695, grad/param norm = 2.1202e-01, time/batch = 16.0638s	
28639/33150 (epoch 43.196), train_loss = 0.92942757, grad/param norm = 1.7347e-01, time/batch = 18.6351s	
28640/33150 (epoch 43.198), train_loss = 0.73357228, grad/param norm = 1.5795e-01, time/batch = 15.7208s	
28641/33150 (epoch 43.199), train_loss = 0.91890838, grad/param norm = 2.4723e-01, time/batch = 18.1448s	
28642/33150 (epoch 43.201), train_loss = 0.79811653, grad/param norm = 1.7425e-01, time/batch = 16.2844s	
28643/33150 (epoch 43.202), train_loss = 0.66326117, grad/param norm = 1.7285e-01, time/batch = 16.2154s	
28644/33150 (epoch 43.204), train_loss = 0.84410615, grad/param norm = 2.0877e-01, time/batch = 17.4685s	
28645/33150 (epoch 43.205), train_loss = 0.85450980, grad/param norm = 1.8795e-01, time/batch = 18.0487s	
28646/33150 (epoch 43.207), train_loss = 0.84926057, grad/param norm = 1.9477e-01, time/batch = 18.4440s	
28647/33150 (epoch 43.208), train_loss = 0.90731397, grad/param norm = 2.1936e-01, time/batch = 17.3656s	
28648/33150 (epoch 43.210), train_loss = 0.76953393, grad/param norm = 1.6814e-01, time/batch = 17.5296s	
28649/33150 (epoch 43.211), train_loss = 0.82729580, grad/param norm = 2.1052e-01, time/batch = 17.1353s	
28650/33150 (epoch 43.213), train_loss = 0.89414318, grad/param norm = 1.9650e-01, time/batch = 15.8038s	
28651/33150 (epoch 43.214), train_loss = 0.78907287, grad/param norm = 1.7385e-01, time/batch = 16.8130s	
28652/33150 (epoch 43.216), train_loss = 0.73536216, grad/param norm = 2.1867e-01, time/batch = 16.7241s	
28653/33150 (epoch 43.217), train_loss = 0.83881103, grad/param norm = 1.8482e-01, time/batch = 17.8806s	
28654/33150 (epoch 43.219), train_loss = 0.76528444, grad/param norm = 1.8823e-01, time/batch = 15.8884s	
28655/33150 (epoch 43.220), train_loss = 0.79249497, grad/param norm = 1.6186e-01, time/batch = 18.5514s	
28656/33150 (epoch 43.222), train_loss = 0.90306266, grad/param norm = 1.9372e-01, time/batch = 16.9519s	
28657/33150 (epoch 43.223), train_loss = 0.82607772, grad/param norm = 1.8645e-01, time/batch = 17.8749s	
28658/33150 (epoch 43.225), train_loss = 0.91781205, grad/param norm = 1.8259e-01, time/batch = 16.2275s	
28659/33150 (epoch 43.226), train_loss = 0.79159354, grad/param norm = 1.6248e-01, time/batch = 18.2952s	
28660/33150 (epoch 43.228), train_loss = 0.79999997, grad/param norm = 1.9827e-01, time/batch = 17.4691s	
28661/33150 (epoch 43.229), train_loss = 0.80666770, grad/param norm = 1.8034e-01, time/batch = 16.5569s	
28662/33150 (epoch 43.231), train_loss = 0.91147486, grad/param norm = 1.9071e-01, time/batch = 18.2006s	
28663/33150 (epoch 43.232), train_loss = 0.78956931, grad/param norm = 1.7293e-01, time/batch = 19.1274s	
28664/33150 (epoch 43.234), train_loss = 0.87220345, grad/param norm = 1.9574e-01, time/batch = 15.9704s	
28665/33150 (epoch 43.235), train_loss = 0.90000040, grad/param norm = 2.0156e-01, time/batch = 19.4643s	
28666/33150 (epoch 43.237), train_loss = 0.85727604, grad/param norm = 3.0255e-01, time/batch = 16.8912s	
28667/33150 (epoch 43.238), train_loss = 0.88803239, grad/param norm = 2.4046e-01, time/batch = 17.5544s	
28668/33150 (epoch 43.240), train_loss = 0.84471003, grad/param norm = 2.1257e-01, time/batch = 20.2090s	
28669/33150 (epoch 43.241), train_loss = 0.91008433, grad/param norm = 2.2321e-01, time/batch = 18.2084s	
28670/33150 (epoch 43.243), train_loss = 0.87556214, grad/param norm = 1.7363e-01, time/batch = 18.2080s	
28671/33150 (epoch 43.244), train_loss = 0.86846391, grad/param norm = 1.9248e-01, time/batch = 16.8149s	
28672/33150 (epoch 43.246), train_loss = 0.90934849, grad/param norm = 2.0531e-01, time/batch = 17.1323s	
28673/33150 (epoch 43.247), train_loss = 0.78621218, grad/param norm = 1.8886e-01, time/batch = 18.6234s	
28674/33150 (epoch 43.249), train_loss = 0.95587017, grad/param norm = 1.9246e-01, time/batch = 16.6531s	
28675/33150 (epoch 43.250), train_loss = 0.85569115, grad/param norm = 1.7565e-01, time/batch = 17.8913s	
28676/33150 (epoch 43.252), train_loss = 0.89336593, grad/param norm = 1.6206e-01, time/batch = 19.9631s	
28677/33150 (epoch 43.253), train_loss = 0.80448261, grad/param norm = 2.0346e-01, time/batch = 16.6353s	
28678/33150 (epoch 43.255), train_loss = 0.81062457, grad/param norm = 1.5440e-01, time/batch = 18.5483s	
28679/33150 (epoch 43.256), train_loss = 0.93256351, grad/param norm = 2.0529e-01, time/batch = 19.1336s	
28680/33150 (epoch 43.258), train_loss = 0.79040253, grad/param norm = 2.2070e-01, time/batch = 17.1176s	
28681/33150 (epoch 43.259), train_loss = 0.68226992, grad/param norm = 2.0176e-01, time/batch = 17.9580s	
28682/33150 (epoch 43.261), train_loss = 0.73985132, grad/param norm = 1.5116e-01, time/batch = 17.8080s	
28683/33150 (epoch 43.262), train_loss = 0.95143853, grad/param norm = 2.1936e-01, time/batch = 20.1209s	
28684/33150 (epoch 43.264), train_loss = 0.65234570, grad/param norm = 1.5930e-01, time/batch = 16.8796s	
28685/33150 (epoch 43.265), train_loss = 0.82767620, grad/param norm = 1.9047e-01, time/batch = 17.6276s	
28686/33150 (epoch 43.267), train_loss = 0.91940828, grad/param norm = 2.0941e-01, time/batch = 18.2149s	
28687/33150 (epoch 43.268), train_loss = 0.95853863, grad/param norm = 1.7848e-01, time/batch = 17.6266s	
28688/33150 (epoch 43.270), train_loss = 1.00912062, grad/param norm = 1.7318e-01, time/batch = 16.3018s	
28689/33150 (epoch 43.271), train_loss = 0.88003900, grad/param norm = 2.2304e-01, time/batch = 18.5474s	
28690/33150 (epoch 43.273), train_loss = 0.94999368, grad/param norm = 1.9637e-01, time/batch = 16.6218s	
28691/33150 (epoch 43.275), train_loss = 0.95260042, grad/param norm = 2.0960e-01, time/batch = 16.9329s	
28692/33150 (epoch 43.276), train_loss = 0.82277698, grad/param norm = 1.8832e-01, time/batch = 20.0283s	
28693/33150 (epoch 43.278), train_loss = 0.94202728, grad/param norm = 1.7725e-01, time/batch = 16.1235s	
28694/33150 (epoch 43.279), train_loss = 0.92853137, grad/param norm = 1.6900e-01, time/batch = 16.9526s	
28695/33150 (epoch 43.281), train_loss = 0.84692560, grad/param norm = 2.0662e-01, time/batch = 17.3072s	
28696/33150 (epoch 43.282), train_loss = 0.89441205, grad/param norm = 1.6851e-01, time/batch = 17.5623s	
28697/33150 (epoch 43.284), train_loss = 0.77893637, grad/param norm = 1.7857e-01, time/batch = 17.8766s	
28698/33150 (epoch 43.285), train_loss = 0.87008871, grad/param norm = 1.8507e-01, time/batch = 18.5539s	
28699/33150 (epoch 43.287), train_loss = 0.72976032, grad/param norm = 1.6980e-01, time/batch = 17.5508s	
28700/33150 (epoch 43.288), train_loss = 0.90738351, grad/param norm = 1.8840e-01, time/batch = 16.5462s	
28701/33150 (epoch 43.290), train_loss = 0.71904339, grad/param norm = 1.6417e-01, time/batch = 16.7802s	
28702/33150 (epoch 43.291), train_loss = 0.69527967, grad/param norm = 1.8002e-01, time/batch = 16.5707s	
28703/33150 (epoch 43.293), train_loss = 0.80746331, grad/param norm = 2.0733e-01, time/batch = 16.9102s	
28704/33150 (epoch 43.294), train_loss = 0.65795265, grad/param norm = 1.5714e-01, time/batch = 16.6373s	
28705/33150 (epoch 43.296), train_loss = 0.82374099, grad/param norm = 1.6130e-01, time/batch = 17.3965s	
28706/33150 (epoch 43.297), train_loss = 0.76510116, grad/param norm = 1.7625e-01, time/batch = 17.0657s	
28707/33150 (epoch 43.299), train_loss = 0.76491431, grad/param norm = 2.2209e-01, time/batch = 18.1406s	
28708/33150 (epoch 43.300), train_loss = 0.79059263, grad/param norm = 1.5189e-01, time/batch = 16.1994s	
28709/33150 (epoch 43.302), train_loss = 0.81190176, grad/param norm = 1.8498e-01, time/batch = 19.1263s	
28710/33150 (epoch 43.303), train_loss = 0.78916113, grad/param norm = 1.8304e-01, time/batch = 18.3004s	
28711/33150 (epoch 43.305), train_loss = 0.88325071, grad/param norm = 1.8889e-01, time/batch = 17.8777s	
28712/33150 (epoch 43.306), train_loss = 0.88905565, grad/param norm = 1.8716e-01, time/batch = 17.5470s	
28713/33150 (epoch 43.308), train_loss = 1.02050663, grad/param norm = 1.8960e-01, time/batch = 17.3145s	
28714/33150 (epoch 43.309), train_loss = 0.67184697, grad/param norm = 1.3827e-01, time/batch = 18.8669s	
28715/33150 (epoch 43.311), train_loss = 0.82280855, grad/param norm = 2.0587e-01, time/batch = 16.7988s	
28716/33150 (epoch 43.312), train_loss = 0.68051301, grad/param norm = 2.0573e-01, time/batch = 17.1463s	
28717/33150 (epoch 43.314), train_loss = 0.81802465, grad/param norm = 2.3726e-01, time/batch = 17.4797s	
28718/33150 (epoch 43.315), train_loss = 0.87221197, grad/param norm = 1.7975e-01, time/batch = 16.0544s	
28719/33150 (epoch 43.317), train_loss = 0.66534458, grad/param norm = 1.5439e-01, time/batch = 16.2391s	
28720/33150 (epoch 43.318), train_loss = 0.76843253, grad/param norm = 1.6114e-01, time/batch = 15.9090s	
28721/33150 (epoch 43.320), train_loss = 0.69776102, grad/param norm = 1.8310e-01, time/batch = 18.2251s	
28722/33150 (epoch 43.321), train_loss = 0.79222259, grad/param norm = 1.6864e-01, time/batch = 19.0370s	
28723/33150 (epoch 43.323), train_loss = 0.76876944, grad/param norm = 1.7994e-01, time/batch = 16.4227s	
28724/33150 (epoch 43.324), train_loss = 0.80342788, grad/param norm = 2.2871e-01, time/batch = 18.6139s	
28725/33150 (epoch 43.326), train_loss = 0.80689973, grad/param norm = 1.7473e-01, time/batch = 18.0146s	
28726/33150 (epoch 43.327), train_loss = 0.91626351, grad/param norm = 1.8589e-01, time/batch = 18.3892s	
28727/33150 (epoch 43.329), train_loss = 0.86881826, grad/param norm = 1.8110e-01, time/batch = 18.9601s	
28728/33150 (epoch 43.330), train_loss = 0.76737080, grad/param norm = 1.7068e-01, time/batch = 17.2098s	
28729/33150 (epoch 43.332), train_loss = 0.79752527, grad/param norm = 1.8691e-01, time/batch = 17.7956s	
28730/33150 (epoch 43.333), train_loss = 0.86736289, grad/param norm = 1.6317e-01, time/batch = 18.4635s	
28731/33150 (epoch 43.335), train_loss = 0.73954212, grad/param norm = 1.7262e-01, time/batch = 18.5371s	
28732/33150 (epoch 43.336), train_loss = 0.73245533, grad/param norm = 1.8871e-01, time/batch = 18.0585s	
28733/33150 (epoch 43.338), train_loss = 0.70238571, grad/param norm = 2.1377e-01, time/batch = 17.1390s	
28734/33150 (epoch 43.339), train_loss = 0.87200799, grad/param norm = 1.9623e-01, time/batch = 18.7130s	
28735/33150 (epoch 43.341), train_loss = 0.82683979, grad/param norm = 2.5430e-01, time/batch = 15.8765s	
28736/33150 (epoch 43.342), train_loss = 0.76121040, grad/param norm = 1.8831e-01, time/batch = 18.7198s	
28737/33150 (epoch 43.344), train_loss = 0.79603472, grad/param norm = 1.6756e-01, time/batch = 16.7299s	
28738/33150 (epoch 43.345), train_loss = 0.79588800, grad/param norm = 1.9585e-01, time/batch = 17.2819s	
28739/33150 (epoch 43.347), train_loss = 0.69246420, grad/param norm = 1.6983e-01, time/batch = 17.4737s	
28740/33150 (epoch 43.348), train_loss = 0.82563982, grad/param norm = 2.0223e-01, time/batch = 16.7310s	
28741/33150 (epoch 43.350), train_loss = 0.73353602, grad/param norm = 1.7988e-01, time/batch = 18.5542s	
28742/33150 (epoch 43.351), train_loss = 0.87531438, grad/param norm = 1.9118e-01, time/batch = 16.0678s	
28743/33150 (epoch 43.353), train_loss = 0.85304054, grad/param norm = 1.9820e-01, time/batch = 18.7995s	
28744/33150 (epoch 43.354), train_loss = 1.03533906, grad/param norm = 2.0036e-01, time/batch = 16.1272s	
28745/33150 (epoch 43.356), train_loss = 0.90465603, grad/param norm = 1.9499e-01, time/batch = 15.8886s	
28746/33150 (epoch 43.357), train_loss = 0.84749906, grad/param norm = 2.0580e-01, time/batch = 16.5562s	
28747/33150 (epoch 43.359), train_loss = 0.89774084, grad/param norm = 1.8727e-01, time/batch = 18.4572s	
28748/33150 (epoch 43.360), train_loss = 0.86867766, grad/param norm = 2.7172e-01, time/batch = 17.9583s	
28749/33150 (epoch 43.362), train_loss = 0.93430987, grad/param norm = 1.8909e-01, time/batch = 16.7283s	
28750/33150 (epoch 43.363), train_loss = 0.86084448, grad/param norm = 1.8457e-01, time/batch = 17.6399s	
28751/33150 (epoch 43.365), train_loss = 0.81022605, grad/param norm = 1.6667e-01, time/batch = 18.1483s	
28752/33150 (epoch 43.367), train_loss = 0.78700376, grad/param norm = 1.6211e-01, time/batch = 16.4785s	
28753/33150 (epoch 43.368), train_loss = 0.80685513, grad/param norm = 2.7186e-01, time/batch = 17.2208s	
28754/33150 (epoch 43.370), train_loss = 0.86988463, grad/param norm = 2.9533e-01, time/batch = 16.8035s	
28755/33150 (epoch 43.371), train_loss = 0.72554028, grad/param norm = 1.8082e-01, time/batch = 16.2076s	
28756/33150 (epoch 43.373), train_loss = 0.85434922, grad/param norm = 2.2142e-01, time/batch = 15.8969s	
28757/33150 (epoch 43.374), train_loss = 0.83356224, grad/param norm = 1.6473e-01, time/batch = 16.2934s	
28758/33150 (epoch 43.376), train_loss = 0.91741163, grad/param norm = 1.7041e-01, time/batch = 16.8790s	
28759/33150 (epoch 43.377), train_loss = 0.75664140, grad/param norm = 1.8667e-01, time/batch = 16.8136s	
28760/33150 (epoch 43.379), train_loss = 0.84561097, grad/param norm = 2.0157e-01, time/batch = 16.7213s	
28761/33150 (epoch 43.380), train_loss = 0.88568506, grad/param norm = 1.8370e-01, time/batch = 16.8006s	
28762/33150 (epoch 43.382), train_loss = 0.82295176, grad/param norm = 2.0145e-01, time/batch = 17.1468s	
28763/33150 (epoch 43.383), train_loss = 0.73795173, grad/param norm = 1.6592e-01, time/batch = 17.7943s	
28764/33150 (epoch 43.385), train_loss = 0.78126540, grad/param norm = 1.8448e-01, time/batch = 17.3811s	
28765/33150 (epoch 43.386), train_loss = 0.71183553, grad/param norm = 1.3784e-01, time/batch = 18.1345s	
28766/33150 (epoch 43.388), train_loss = 0.75069155, grad/param norm = 2.0997e-01, time/batch = 16.6190s	
28767/33150 (epoch 43.389), train_loss = 0.75069325, grad/param norm = 1.6685e-01, time/batch = 17.0607s	
28768/33150 (epoch 43.391), train_loss = 0.95119514, grad/param norm = 2.1148e-01, time/batch = 20.5429s	
28769/33150 (epoch 43.392), train_loss = 0.75627224, grad/param norm = 1.8614e-01, time/batch = 17.0482s	
28770/33150 (epoch 43.394), train_loss = 0.70455509, grad/param norm = 1.4854e-01, time/batch = 18.1349s	
28771/33150 (epoch 43.395), train_loss = 0.65414319, grad/param norm = 1.5140e-01, time/batch = 19.2042s	
28772/33150 (epoch 43.397), train_loss = 0.57439970, grad/param norm = 1.7887e-01, time/batch = 18.9486s	
28773/33150 (epoch 43.398), train_loss = 0.82373601, grad/param norm = 1.6563e-01, time/batch = 16.1405s	
28774/33150 (epoch 43.400), train_loss = 0.80781327, grad/param norm = 1.6158e-01, time/batch = 16.6466s	
28775/33150 (epoch 43.401), train_loss = 0.68149368, grad/param norm = 1.4026e-01, time/batch = 17.3005s	
28776/33150 (epoch 43.403), train_loss = 0.68884987, grad/param norm = 1.5707e-01, time/batch = 16.6382s	
28777/33150 (epoch 43.404), train_loss = 0.80927437, grad/param norm = 1.7620e-01, time/batch = 16.6344s	
28778/33150 (epoch 43.406), train_loss = 0.77697856, grad/param norm = 1.4357e-01, time/batch = 18.3028s	
28779/33150 (epoch 43.407), train_loss = 0.68085911, grad/param norm = 1.4995e-01, time/batch = 17.0434s	
28780/33150 (epoch 43.409), train_loss = 0.65227266, grad/param norm = 1.6050e-01, time/batch = 16.6326s	
28781/33150 (epoch 43.410), train_loss = 0.81206391, grad/param norm = 1.8746e-01, time/batch = 18.3996s	
28782/33150 (epoch 43.412), train_loss = 0.85507688, grad/param norm = 1.6368e-01, time/batch = 18.8120s	
28783/33150 (epoch 43.413), train_loss = 0.71785616, grad/param norm = 1.7662e-01, time/batch = 16.1443s	
28784/33150 (epoch 43.415), train_loss = 0.83390356, grad/param norm = 1.7248e-01, time/batch = 17.5519s	
28785/33150 (epoch 43.416), train_loss = 0.72856586, grad/param norm = 1.5683e-01, time/batch = 16.3721s	
28786/33150 (epoch 43.418), train_loss = 0.82978899, grad/param norm = 2.0971e-01, time/batch = 18.7782s	
28787/33150 (epoch 43.419), train_loss = 0.80141299, grad/param norm = 1.8841e-01, time/batch = 17.3847s	
28788/33150 (epoch 43.421), train_loss = 0.81152267, grad/param norm = 1.8979e-01, time/batch = 18.3038s	
28789/33150 (epoch 43.422), train_loss = 0.79233420, grad/param norm = 1.6183e-01, time/batch = 19.2065s	
28790/33150 (epoch 43.424), train_loss = 0.73342608, grad/param norm = 2.2522e-01, time/batch = 16.4424s	
28791/33150 (epoch 43.425), train_loss = 0.87690580, grad/param norm = 1.8078e-01, time/batch = 18.0530s	
28792/33150 (epoch 43.427), train_loss = 0.80835382, grad/param norm = 1.5715e-01, time/batch = 16.6381s	
28793/33150 (epoch 43.428), train_loss = 0.76494541, grad/param norm = 1.7587e-01, time/batch = 17.4634s	
28794/33150 (epoch 43.430), train_loss = 0.81487413, grad/param norm = 1.9878e-01, time/batch = 17.2892s	
28795/33150 (epoch 43.431), train_loss = 0.86545207, grad/param norm = 2.1083e-01, time/batch = 17.0698s	
28796/33150 (epoch 43.433), train_loss = 0.77255609, grad/param norm = 1.6442e-01, time/batch = 17.3001s	
28797/33150 (epoch 43.434), train_loss = 0.68743246, grad/param norm = 1.6349e-01, time/batch = 16.7220s	
28798/33150 (epoch 43.436), train_loss = 0.80311999, grad/param norm = 1.4791e-01, time/batch = 19.2192s	
28799/33150 (epoch 43.437), train_loss = 0.80225366, grad/param norm = 1.9769e-01, time/batch = 19.4642s	
28800/33150 (epoch 43.439), train_loss = 0.95133403, grad/param norm = 1.6960e-01, time/batch = 16.7107s	
28801/33150 (epoch 43.440), train_loss = 0.85090078, grad/param norm = 1.9015e-01, time/batch = 19.0440s	
28802/33150 (epoch 43.442), train_loss = 0.69382041, grad/param norm = 1.7628e-01, time/batch = 17.7245s	
28803/33150 (epoch 43.443), train_loss = 0.82346587, grad/param norm = 2.0777e-01, time/batch = 17.8002s	
28804/33150 (epoch 43.445), train_loss = 0.83064764, grad/param norm = 2.1157e-01, time/batch = 18.2161s	
28805/33150 (epoch 43.446), train_loss = 0.84688409, grad/param norm = 2.5026e-01, time/batch = 17.3102s	
28806/33150 (epoch 43.448), train_loss = 0.89984435, grad/param norm = 2.0064e-01, time/batch = 18.1278s	
28807/33150 (epoch 43.449), train_loss = 0.82183412, grad/param norm = 1.5921e-01, time/batch = 16.0345s	
28808/33150 (epoch 43.451), train_loss = 0.81135987, grad/param norm = 1.9029e-01, time/batch = 19.0448s	
28809/33150 (epoch 43.452), train_loss = 0.97039202, grad/param norm = 1.7869e-01, time/batch = 17.9718s	
28810/33150 (epoch 43.454), train_loss = 0.78482807, grad/param norm = 1.6237e-01, time/batch = 16.0222s	
28811/33150 (epoch 43.456), train_loss = 0.76196927, grad/param norm = 1.7843e-01, time/batch = 17.6342s	
28812/33150 (epoch 43.457), train_loss = 0.80913465, grad/param norm = 1.9198e-01, time/batch = 19.7896s	
28813/33150 (epoch 43.459), train_loss = 0.94949423, grad/param norm = 2.7774e-01, time/batch = 17.4661s	
28814/33150 (epoch 43.460), train_loss = 0.86385493, grad/param norm = 1.6466e-01, time/batch = 17.8944s	
28815/33150 (epoch 43.462), train_loss = 0.91793639, grad/param norm = 2.1012e-01, time/batch = 18.8697s	
28816/33150 (epoch 43.463), train_loss = 1.02762030, grad/param norm = 2.7052e-01, time/batch = 19.0342s	
28817/33150 (epoch 43.465), train_loss = 0.86818967, grad/param norm = 1.7699e-01, time/batch = 32.0391s	
28818/33150 (epoch 43.466), train_loss = 0.78214502, grad/param norm = 1.7193e-01, time/batch = 19.9569s	
28819/33150 (epoch 43.468), train_loss = 1.00798719, grad/param norm = 1.9075e-01, time/batch = 16.9479s	
28820/33150 (epoch 43.469), train_loss = 0.75569151, grad/param norm = 1.9119e-01, time/batch = 18.8841s	
28821/33150 (epoch 43.471), train_loss = 0.75502339, grad/param norm = 1.5902e-01, time/batch = 16.3251s	
28822/33150 (epoch 43.472), train_loss = 0.84456102, grad/param norm = 1.8832e-01, time/batch = 18.2188s	
28823/33150 (epoch 43.474), train_loss = 0.85854793, grad/param norm = 2.2348e-01, time/batch = 17.0611s	
28824/33150 (epoch 43.475), train_loss = 1.05781712, grad/param norm = 1.9313e-01, time/batch = 16.0429s	
28825/33150 (epoch 43.477), train_loss = 0.88360734, grad/param norm = 1.9779e-01, time/batch = 18.4649s	
28826/33150 (epoch 43.478), train_loss = 0.83422991, grad/param norm = 1.7110e-01, time/batch = 14.8141s	
28827/33150 (epoch 43.480), train_loss = 0.74577948, grad/param norm = 1.6934e-01, time/batch = 17.5470s	
28828/33150 (epoch 43.481), train_loss = 0.69661806, grad/param norm = 1.8628e-01, time/batch = 15.9601s	
28829/33150 (epoch 43.483), train_loss = 0.78037986, grad/param norm = 1.6541e-01, time/batch = 16.7183s	
28830/33150 (epoch 43.484), train_loss = 0.73361225, grad/param norm = 1.8534e-01, time/batch = 16.8179s	
28831/33150 (epoch 43.486), train_loss = 0.75610539, grad/param norm = 1.9195e-01, time/batch = 17.6209s	
28832/33150 (epoch 43.487), train_loss = 0.87674493, grad/param norm = 1.9423e-01, time/batch = 17.3790s	
28833/33150 (epoch 43.489), train_loss = 0.80291257, grad/param norm = 1.8714e-01, time/batch = 16.1452s	
28834/33150 (epoch 43.490), train_loss = 0.64553349, grad/param norm = 1.4840e-01, time/batch = 16.5527s	
28835/33150 (epoch 43.492), train_loss = 0.78872302, grad/param norm = 1.8529e-01, time/batch = 18.2240s	
28836/33150 (epoch 43.493), train_loss = 0.87639954, grad/param norm = 2.0174e-01, time/batch = 17.7223s	
28837/33150 (epoch 43.495), train_loss = 0.85718946, grad/param norm = 1.6869e-01, time/batch = 15.4074s	
28838/33150 (epoch 43.496), train_loss = 0.77613899, grad/param norm = 1.6210e-01, time/batch = 15.8103s	
28839/33150 (epoch 43.498), train_loss = 0.88960069, grad/param norm = 2.0157e-01, time/batch = 16.7206s	
28840/33150 (epoch 43.499), train_loss = 0.91722788, grad/param norm = 1.8489e-01, time/batch = 16.0643s	
28841/33150 (epoch 43.501), train_loss = 0.83390149, grad/param norm = 2.0161e-01, time/batch = 18.1455s	
28842/33150 (epoch 43.502), train_loss = 0.92946300, grad/param norm = 2.4720e-01, time/batch = 18.2940s	
28843/33150 (epoch 43.504), train_loss = 0.89165257, grad/param norm = 2.0579e-01, time/batch = 17.9585s	
28844/33150 (epoch 43.505), train_loss = 0.94125976, grad/param norm = 1.8783e-01, time/batch = 19.1315s	
28845/33150 (epoch 43.507), train_loss = 0.76450406, grad/param norm = 1.7633e-01, time/batch = 16.8654s	
28846/33150 (epoch 43.508), train_loss = 0.76115868, grad/param norm = 2.0060e-01, time/batch = 17.5509s	
28847/33150 (epoch 43.510), train_loss = 0.88528121, grad/param norm = 1.5410e-01, time/batch = 16.4766s	
28848/33150 (epoch 43.511), train_loss = 0.91574248, grad/param norm = 1.9389e-01, time/batch = 19.8740s	
28849/33150 (epoch 43.513), train_loss = 0.83431829, grad/param norm = 1.9590e-01, time/batch = 19.9457s	
28850/33150 (epoch 43.514), train_loss = 0.71992356, grad/param norm = 1.9095e-01, time/batch = 17.0400s	
28851/33150 (epoch 43.516), train_loss = 0.83366082, grad/param norm = 2.0021e-01, time/batch = 20.0296s	
28852/33150 (epoch 43.517), train_loss = 0.90625832, grad/param norm = 2.0658e-01, time/batch = 16.7258s	
28853/33150 (epoch 43.519), train_loss = 0.76797673, grad/param norm = 1.9990e-01, time/batch = 19.4617s	
28854/33150 (epoch 43.520), train_loss = 0.81647316, grad/param norm = 1.6939e-01, time/batch = 17.6387s	
28855/33150 (epoch 43.522), train_loss = 0.89778752, grad/param norm = 2.1456e-01, time/batch = 18.4686s	
28856/33150 (epoch 43.523), train_loss = 0.72888629, grad/param norm = 1.7356e-01, time/batch = 17.0466s	
28857/33150 (epoch 43.525), train_loss = 0.85579323, grad/param norm = 1.7692e-01, time/batch = 17.0527s	
28858/33150 (epoch 43.526), train_loss = 0.75042041, grad/param norm = 1.6691e-01, time/batch = 16.9700s	
28859/33150 (epoch 43.528), train_loss = 0.84510453, grad/param norm = 1.7982e-01, time/batch = 19.2243s	
28860/33150 (epoch 43.529), train_loss = 0.81648237, grad/param norm = 1.7384e-01, time/batch = 16.3860s	
28861/33150 (epoch 43.531), train_loss = 0.73594672, grad/param norm = 2.1957e-01, time/batch = 18.3775s	
28862/33150 (epoch 43.532), train_loss = 0.83391795, grad/param norm = 2.0628e-01, time/batch = 18.6248s	
28863/33150 (epoch 43.534), train_loss = 0.81857200, grad/param norm = 1.6083e-01, time/batch = 16.4467s	
28864/33150 (epoch 43.535), train_loss = 0.75654397, grad/param norm = 2.3566e-01, time/batch = 16.5679s	
28865/33150 (epoch 43.537), train_loss = 0.82572635, grad/param norm = 2.0289e-01, time/batch = 19.2962s	
28866/33150 (epoch 43.538), train_loss = 0.75522403, grad/param norm = 1.7676e-01, time/batch = 18.1398s	
28867/33150 (epoch 43.540), train_loss = 0.74820113, grad/param norm = 1.9066e-01, time/batch = 16.5362s	
28868/33150 (epoch 43.541), train_loss = 0.90955877, grad/param norm = 2.0053e-01, time/batch = 16.8907s	
28869/33150 (epoch 43.543), train_loss = 0.82418492, grad/param norm = 1.9184e-01, time/batch = 18.2305s	
28870/33150 (epoch 43.544), train_loss = 0.88517989, grad/param norm = 1.8178e-01, time/batch = 17.7259s	
28871/33150 (epoch 43.546), train_loss = 0.75790589, grad/param norm = 1.8132e-01, time/batch = 18.3877s	
28872/33150 (epoch 43.548), train_loss = 0.79758994, grad/param norm = 2.1640e-01, time/batch = 17.4053s	
28873/33150 (epoch 43.549), train_loss = 0.80168799, grad/param norm = 2.0952e-01, time/batch = 16.8074s	
28874/33150 (epoch 43.551), train_loss = 0.73706383, grad/param norm = 1.5789e-01, time/batch = 15.8137s	
28875/33150 (epoch 43.552), train_loss = 0.62918829, grad/param norm = 1.3972e-01, time/batch = 17.9833s	
28876/33150 (epoch 43.554), train_loss = 0.90009465, grad/param norm = 2.0605e-01, time/batch = 18.9756s	
28877/33150 (epoch 43.555), train_loss = 0.91724007, grad/param norm = 2.3226e-01, time/batch = 16.6294s	
28878/33150 (epoch 43.557), train_loss = 0.69608819, grad/param norm = 1.7566e-01, time/batch = 16.7251s	
28879/33150 (epoch 43.558), train_loss = 0.83083905, grad/param norm = 2.0917e-01, time/batch = 19.0704s	
28880/33150 (epoch 43.560), train_loss = 0.73463169, grad/param norm = 1.6958e-01, time/batch = 17.6382s	
28881/33150 (epoch 43.561), train_loss = 0.68865193, grad/param norm = 1.9869e-01, time/batch = 16.2003s	
28882/33150 (epoch 43.563), train_loss = 0.86698369, grad/param norm = 2.1062e-01, time/batch = 17.2940s	
28883/33150 (epoch 43.564), train_loss = 0.89689089, grad/param norm = 1.6271e-01, time/batch = 18.6379s	
28884/33150 (epoch 43.566), train_loss = 0.73527122, grad/param norm = 2.3328e-01, time/batch = 16.3875s	
28885/33150 (epoch 43.567), train_loss = 0.80149417, grad/param norm = 1.9177e-01, time/batch = 16.7303s	
28886/33150 (epoch 43.569), train_loss = 0.81981016, grad/param norm = 1.8064e-01, time/batch = 18.4854s	
28887/33150 (epoch 43.570), train_loss = 0.87537520, grad/param norm = 1.6571e-01, time/batch = 17.3048s	
28888/33150 (epoch 43.572), train_loss = 0.75656332, grad/param norm = 1.7730e-01, time/batch = 17.7336s	
28889/33150 (epoch 43.573), train_loss = 0.69220829, grad/param norm = 1.4747e-01, time/batch = 15.8200s	
28890/33150 (epoch 43.575), train_loss = 0.79617108, grad/param norm = 2.1199e-01, time/batch = 16.2441s	
28891/33150 (epoch 43.576), train_loss = 0.73191054, grad/param norm = 1.7296e-01, time/batch = 15.7992s	
28892/33150 (epoch 43.578), train_loss = 0.76097232, grad/param norm = 1.7510e-01, time/batch = 18.7945s	
28893/33150 (epoch 43.579), train_loss = 0.72276179, grad/param norm = 1.7560e-01, time/batch = 18.1314s	
28894/33150 (epoch 43.581), train_loss = 0.71619736, grad/param norm = 1.8849e-01, time/batch = 16.7879s	
28895/33150 (epoch 43.582), train_loss = 0.91291972, grad/param norm = 1.6754e-01, time/batch = 17.3793s	
28896/33150 (epoch 43.584), train_loss = 0.90582541, grad/param norm = 2.1759e-01, time/batch = 17.8961s	
28897/33150 (epoch 43.585), train_loss = 0.81252047, grad/param norm = 1.6621e-01, time/batch = 16.1412s	
28898/33150 (epoch 43.587), train_loss = 0.80545447, grad/param norm = 1.6334e-01, time/batch = 16.3034s	
28899/33150 (epoch 43.588), train_loss = 0.76624587, grad/param norm = 1.9990e-01, time/batch = 17.3971s	
28900/33150 (epoch 43.590), train_loss = 0.84323013, grad/param norm = 1.7129e-01, time/batch = 16.3103s	
28901/33150 (epoch 43.591), train_loss = 0.82627676, grad/param norm = 1.8193e-01, time/batch = 17.2931s	
28902/33150 (epoch 43.593), train_loss = 0.86411505, grad/param norm = 2.0932e-01, time/batch = 17.6287s	
28903/33150 (epoch 43.594), train_loss = 0.77420101, grad/param norm = 1.8287e-01, time/batch = 17.9680s	
28904/33150 (epoch 43.596), train_loss = 0.77038714, grad/param norm = 1.6332e-01, time/batch = 18.5551s	
28905/33150 (epoch 43.597), train_loss = 0.71540854, grad/param norm = 2.0205e-01, time/batch = 15.8675s	
28906/33150 (epoch 43.599), train_loss = 0.97586808, grad/param norm = 2.4011e-01, time/batch = 17.8688s	
28907/33150 (epoch 43.600), train_loss = 0.79065830, grad/param norm = 2.4758e-01, time/batch = 18.5552s	
28908/33150 (epoch 43.602), train_loss = 0.81707427, grad/param norm = 2.7512e-01, time/batch = 17.1265s	
28909/33150 (epoch 43.603), train_loss = 0.94258724, grad/param norm = 1.9126e-01, time/batch = 18.1324s	
28910/33150 (epoch 43.605), train_loss = 0.73594161, grad/param norm = 1.8097e-01, time/batch = 18.3002s	
28911/33150 (epoch 43.606), train_loss = 0.75397235, grad/param norm = 2.0468e-01, time/batch = 17.8874s	
28912/33150 (epoch 43.608), train_loss = 0.89891689, grad/param norm = 1.7558e-01, time/batch = 17.2806s	
28913/33150 (epoch 43.609), train_loss = 0.82442665, grad/param norm = 2.6256e-01, time/batch = 18.9713s	
28914/33150 (epoch 43.611), train_loss = 0.72285049, grad/param norm = 1.8991e-01, time/batch = 18.8682s	
28915/33150 (epoch 43.612), train_loss = 0.77595282, grad/param norm = 1.8818e-01, time/batch = 17.7163s	
28916/33150 (epoch 43.614), train_loss = 0.74430757, grad/param norm = 1.7531e-01, time/batch = 18.3823s	
28917/33150 (epoch 43.615), train_loss = 0.72927813, grad/param norm = 1.8893e-01, time/batch = 20.4483s	
28918/33150 (epoch 43.617), train_loss = 0.82381231, grad/param norm = 2.1995e-01, time/batch = 15.6444s	
28919/33150 (epoch 43.618), train_loss = 0.83465423, grad/param norm = 1.7545e-01, time/batch = 18.2120s	
28920/33150 (epoch 43.620), train_loss = 0.79108691, grad/param norm = 2.0083e-01, time/batch = 17.4865s	
28921/33150 (epoch 43.621), train_loss = 0.82054819, grad/param norm = 1.7594e-01, time/batch = 17.5531s	
28922/33150 (epoch 43.623), train_loss = 0.85421179, grad/param norm = 1.7919e-01, time/batch = 16.0346s	
28923/33150 (epoch 43.624), train_loss = 0.79762753, grad/param norm = 1.8432e-01, time/batch = 16.6568s	
28924/33150 (epoch 43.626), train_loss = 0.82828075, grad/param norm = 1.9852e-01, time/batch = 16.2960s	
28925/33150 (epoch 43.627), train_loss = 0.78131186, grad/param norm = 1.9626e-01, time/batch = 15.7003s	
28926/33150 (epoch 43.629), train_loss = 0.68267179, grad/param norm = 1.8093e-01, time/batch = 17.6277s	
28927/33150 (epoch 43.630), train_loss = 0.80870994, grad/param norm = 1.8388e-01, time/batch = 18.3880s	
28928/33150 (epoch 43.632), train_loss = 0.71055027, grad/param norm = 1.4027e-01, time/batch = 17.9752s	
28929/33150 (epoch 43.633), train_loss = 0.75177291, grad/param norm = 1.7666e-01, time/batch = 16.2920s	
28930/33150 (epoch 43.635), train_loss = 0.98299655, grad/param norm = 2.0343e-01, time/batch = 17.8671s	
28931/33150 (epoch 43.637), train_loss = 0.66062604, grad/param norm = 1.9978e-01, time/batch = 19.5404s	
28932/33150 (epoch 43.638), train_loss = 0.80076270, grad/param norm = 1.8991e-01, time/batch = 16.2788s	
28933/33150 (epoch 43.640), train_loss = 0.87509207, grad/param norm = 2.0957e-01, time/batch = 19.7087s	
28934/33150 (epoch 43.641), train_loss = 0.70684341, grad/param norm = 2.0895e-01, time/batch = 18.2266s	
28935/33150 (epoch 43.643), train_loss = 0.81708688, grad/param norm = 1.7355e-01, time/batch = 17.1131s	
28936/33150 (epoch 43.644), train_loss = 0.96060674, grad/param norm = 1.7557e-01, time/batch = 17.3057s	
28937/33150 (epoch 43.646), train_loss = 0.82830249, grad/param norm = 1.7091e-01, time/batch = 19.2754s	
28938/33150 (epoch 43.647), train_loss = 0.97686749, grad/param norm = 1.9900e-01, time/batch = 17.1057s	
28939/33150 (epoch 43.649), train_loss = 0.84473476, grad/param norm = 2.3006e-01, time/batch = 18.3017s	
28940/33150 (epoch 43.650), train_loss = 0.71427774, grad/param norm = 1.8265e-01, time/batch = 16.2795s	
28941/33150 (epoch 43.652), train_loss = 0.90274015, grad/param norm = 2.1908e-01, time/batch = 19.3819s	
28942/33150 (epoch 43.653), train_loss = 0.87719295, grad/param norm = 1.7328e-01, time/batch = 16.8796s	
28943/33150 (epoch 43.655), train_loss = 0.85858202, grad/param norm = 2.0035e-01, time/batch = 17.4777s	
28944/33150 (epoch 43.656), train_loss = 0.77454109, grad/param norm = 1.5195e-01, time/batch = 16.4495s	
28945/33150 (epoch 43.658), train_loss = 0.77219039, grad/param norm = 1.8161e-01, time/batch = 16.8146s	
28946/33150 (epoch 43.659), train_loss = 0.98774167, grad/param norm = 2.5193e-01, time/batch = 17.6302s	
28947/33150 (epoch 43.661), train_loss = 0.79563760, grad/param norm = 1.9242e-01, time/batch = 17.8812s	
28948/33150 (epoch 43.662), train_loss = 0.80277956, grad/param norm = 1.8590e-01, time/batch = 15.7963s	
28949/33150 (epoch 43.664), train_loss = 0.92490367, grad/param norm = 1.9384e-01, time/batch = 17.1306s	
28950/33150 (epoch 43.665), train_loss = 0.90150947, grad/param norm = 1.9594e-01, time/batch = 18.6257s	
28951/33150 (epoch 43.667), train_loss = 0.90429526, grad/param norm = 3.6244e-01, time/batch = 19.3696s	
28952/33150 (epoch 43.668), train_loss = 0.97646797, grad/param norm = 1.9459e-01, time/batch = 15.9673s	
28953/33150 (epoch 43.670), train_loss = 0.77299894, grad/param norm = 1.7567e-01, time/batch = 16.7832s	
28954/33150 (epoch 43.671), train_loss = 0.74965880, grad/param norm = 1.8925e-01, time/batch = 18.5612s	
28955/33150 (epoch 43.673), train_loss = 0.92087004, grad/param norm = 1.6223e-01, time/batch = 18.6281s	
28956/33150 (epoch 43.674), train_loss = 0.88738107, grad/param norm = 2.2702e-01, time/batch = 16.3946s	
28957/33150 (epoch 43.676), train_loss = 0.81075054, grad/param norm = 1.6857e-01, time/batch = 18.1207s	
28958/33150 (epoch 43.677), train_loss = 0.93676748, grad/param norm = 2.0722e-01, time/batch = 18.0394s	
28959/33150 (epoch 43.679), train_loss = 0.81316750, grad/param norm = 1.6019e-01, time/batch = 16.8789s	
28960/33150 (epoch 43.680), train_loss = 0.90337941, grad/param norm = 2.3641e-01, time/batch = 18.3756s	
28961/33150 (epoch 43.682), train_loss = 0.83827523, grad/param norm = 1.6497e-01, time/batch = 16.1838s	
28962/33150 (epoch 43.683), train_loss = 0.70107707, grad/param norm = 1.5874e-01, time/batch = 17.0545s	
28963/33150 (epoch 43.685), train_loss = 0.78505478, grad/param norm = 1.9281e-01, time/batch = 18.1197s	
28964/33150 (epoch 43.686), train_loss = 0.68183165, grad/param norm = 1.8940e-01, time/batch = 17.4648s	
28965/33150 (epoch 43.688), train_loss = 0.71980870, grad/param norm = 1.7809e-01, time/batch = 18.5375s	
28966/33150 (epoch 43.689), train_loss = 0.76050167, grad/param norm = 1.8863e-01, time/batch = 17.2155s	
28967/33150 (epoch 43.691), train_loss = 0.62434683, grad/param norm = 1.3149e-01, time/batch = 17.5533s	
28968/33150 (epoch 43.692), train_loss = 0.72177233, grad/param norm = 1.6648e-01, time/batch = 18.3092s	
28969/33150 (epoch 43.694), train_loss = 0.65106386, grad/param norm = 1.6745e-01, time/batch = 16.4721s	
28970/33150 (epoch 43.695), train_loss = 0.73014443, grad/param norm = 1.6370e-01, time/batch = 16.3130s	
28971/33150 (epoch 43.697), train_loss = 0.71185955, grad/param norm = 1.5431e-01, time/batch = 16.6377s	
28972/33150 (epoch 43.698), train_loss = 0.72303685, grad/param norm = 2.1018e-01, time/batch = 19.1246s	
28973/33150 (epoch 43.700), train_loss = 0.63880278, grad/param norm = 1.5922e-01, time/batch = 16.9856s	
28974/33150 (epoch 43.701), train_loss = 0.69284188, grad/param norm = 1.5629e-01, time/batch = 17.5654s	
28975/33150 (epoch 43.703), train_loss = 0.79819120, grad/param norm = 1.8518e-01, time/batch = 17.5486s	
28976/33150 (epoch 43.704), train_loss = 0.69632093, grad/param norm = 1.5064e-01, time/batch = 17.5488s	
28977/33150 (epoch 43.706), train_loss = 0.74515733, grad/param norm = 1.5245e-01, time/batch = 20.2781s	
28978/33150 (epoch 43.707), train_loss = 0.78598031, grad/param norm = 1.7992e-01, time/batch = 16.8818s	
28979/33150 (epoch 43.709), train_loss = 0.80519924, grad/param norm = 1.6875e-01, time/batch = 17.9576s	
28980/33150 (epoch 43.710), train_loss = 0.81863223, grad/param norm = 2.0451e-01, time/batch = 18.0504s	
28981/33150 (epoch 43.712), train_loss = 0.88371328, grad/param norm = 1.7911e-01, time/batch = 16.7725s	
28982/33150 (epoch 43.713), train_loss = 0.83944305, grad/param norm = 1.7284e-01, time/batch = 18.2950s	
28983/33150 (epoch 43.715), train_loss = 0.78760039, grad/param norm = 1.6613e-01, time/batch = 18.3651s	
28984/33150 (epoch 43.716), train_loss = 0.83559726, grad/param norm = 1.6859e-01, time/batch = 18.4677s	
28985/33150 (epoch 43.718), train_loss = 0.80977542, grad/param norm = 1.8553e-01, time/batch = 16.6425s	
28986/33150 (epoch 43.719), train_loss = 0.87206915, grad/param norm = 1.9623e-01, time/batch = 15.0362s	
28987/33150 (epoch 43.721), train_loss = 0.78006032, grad/param norm = 1.9238e-01, time/batch = 18.0512s	
28988/33150 (epoch 43.722), train_loss = 0.86204918, grad/param norm = 1.9635e-01, time/batch = 16.9763s	
28989/33150 (epoch 43.724), train_loss = 0.77855234, grad/param norm = 2.1071e-01, time/batch = 16.6487s	
28990/33150 (epoch 43.725), train_loss = 0.86425304, grad/param norm = 2.1386e-01, time/batch = 16.8985s	
28991/33150 (epoch 43.727), train_loss = 0.85663687, grad/param norm = 2.1285e-01, time/batch = 17.2391s	
28992/33150 (epoch 43.729), train_loss = 0.80323865, grad/param norm = 1.8584e-01, time/batch = 18.5538s	
28993/33150 (epoch 43.730), train_loss = 0.81662364, grad/param norm = 1.6798e-01, time/batch = 16.6089s	
28994/33150 (epoch 43.732), train_loss = 0.86827473, grad/param norm = 1.9050e-01, time/batch = 18.1211s	
28995/33150 (epoch 43.733), train_loss = 0.70634141, grad/param norm = 1.4947e-01, time/batch = 20.0351s	
28996/33150 (epoch 43.735), train_loss = 0.73882469, grad/param norm = 1.8204e-01, time/batch = 16.2142s	
28997/33150 (epoch 43.736), train_loss = 0.75715988, grad/param norm = 1.7812e-01, time/batch = 16.2176s	
28998/33150 (epoch 43.738), train_loss = 0.80410326, grad/param norm = 1.9190e-01, time/batch = 16.7999s	
28999/33150 (epoch 43.739), train_loss = 0.89013683, grad/param norm = 1.8867e-01, time/batch = 15.4791s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch43.74_1.8706.t7	
29000/33150 (epoch 43.741), train_loss = 0.80183066, grad/param norm = 1.9970e-01, time/batch = 17.2044s	
29001/33150 (epoch 43.742), train_loss = 1.20328902, grad/param norm = 2.1681e-01, time/batch = 17.3547s	
29002/33150 (epoch 43.744), train_loss = 0.86488597, grad/param norm = 2.2267e-01, time/batch = 16.8625s	
29003/33150 (epoch 43.745), train_loss = 0.75702948, grad/param norm = 1.6524e-01, time/batch = 17.8086s	
29004/33150 (epoch 43.747), train_loss = 0.61000083, grad/param norm = 1.7736e-01, time/batch = 19.3650s	
29005/33150 (epoch 43.748), train_loss = 0.67432132, grad/param norm = 1.5699e-01, time/batch = 17.3066s	
29006/33150 (epoch 43.750), train_loss = 0.82898334, grad/param norm = 2.0974e-01, time/batch = 17.1246s	
29007/33150 (epoch 43.751), train_loss = 0.78191752, grad/param norm = 1.6839e-01, time/batch = 17.5557s	
29008/33150 (epoch 43.753), train_loss = 0.69950917, grad/param norm = 2.4779e-01, time/batch = 17.1309s	
29009/33150 (epoch 43.754), train_loss = 0.99681567, grad/param norm = 2.5254e-01, time/batch = 17.5442s	
29010/33150 (epoch 43.756), train_loss = 0.78265936, grad/param norm = 2.2100e-01, time/batch = 16.7971s	
29011/33150 (epoch 43.757), train_loss = 0.83395493, grad/param norm = 1.7214e-01, time/batch = 18.4775s	
29012/33150 (epoch 43.759), train_loss = 0.93062753, grad/param norm = 3.0622e-01, time/batch = 22.7307s	
29013/33150 (epoch 43.760), train_loss = 0.85597910, grad/param norm = 1.9240e-01, time/batch = 27.5354s	
29014/33150 (epoch 43.762), train_loss = 0.81324074, grad/param norm = 2.3269e-01, time/batch = 18.2061s	
29015/33150 (epoch 43.763), train_loss = 0.84449864, grad/param norm = 1.7846e-01, time/batch = 16.2225s	
29016/33150 (epoch 43.765), train_loss = 0.80666300, grad/param norm = 2.0782e-01, time/batch = 18.7186s	
29017/33150 (epoch 43.766), train_loss = 0.68746349, grad/param norm = 2.0377e-01, time/batch = 15.7263s	
29018/33150 (epoch 43.768), train_loss = 0.73088732, grad/param norm = 1.6095e-01, time/batch = 16.7173s	
29019/33150 (epoch 43.769), train_loss = 0.87987436, grad/param norm = 1.8755e-01, time/batch = 15.6187s	
29020/33150 (epoch 43.771), train_loss = 0.84746938, grad/param norm = 1.8768e-01, time/batch = 18.8022s	
29021/33150 (epoch 43.772), train_loss = 0.82857054, grad/param norm = 1.8741e-01, time/batch = 17.9744s	
29022/33150 (epoch 43.774), train_loss = 0.93348856, grad/param norm = 1.9882e-01, time/batch = 16.4670s	
29023/33150 (epoch 43.775), train_loss = 0.84759802, grad/param norm = 2.1642e-01, time/batch = 16.7292s	
29024/33150 (epoch 43.777), train_loss = 0.85853868, grad/param norm = 2.0192e-01, time/batch = 18.6315s	
29025/33150 (epoch 43.778), train_loss = 0.79859461, grad/param norm = 1.7365e-01, time/batch = 17.6231s	
29026/33150 (epoch 43.780), train_loss = 0.69180801, grad/param norm = 1.6216e-01, time/batch = 16.7262s	
29027/33150 (epoch 43.781), train_loss = 0.78392135, grad/param norm = 1.7458e-01, time/batch = 18.3831s	
29028/33150 (epoch 43.783), train_loss = 0.81573651, grad/param norm = 1.8011e-01, time/batch = 18.2298s	
29029/33150 (epoch 43.784), train_loss = 0.80633144, grad/param norm = 1.8813e-01, time/batch = 17.4647s	
29030/33150 (epoch 43.786), train_loss = 0.77773385, grad/param norm = 1.8584e-01, time/batch = 17.0590s	
29031/33150 (epoch 43.787), train_loss = 0.72738501, grad/param norm = 1.6558e-01, time/batch = 19.4659s	
29032/33150 (epoch 43.789), train_loss = 0.67698723, grad/param norm = 1.4824e-01, time/batch = 16.6333s	
29033/33150 (epoch 43.790), train_loss = 0.69423738, grad/param norm = 1.6879e-01, time/batch = 17.1357s	
29034/33150 (epoch 43.792), train_loss = 0.80317957, grad/param norm = 2.0525e-01, time/batch = 17.3129s	
29035/33150 (epoch 43.793), train_loss = 0.76317056, grad/param norm = 2.1229e-01, time/batch = 17.4714s	
29036/33150 (epoch 43.795), train_loss = 0.75487275, grad/param norm = 1.8507e-01, time/batch = 16.6998s	
29037/33150 (epoch 43.796), train_loss = 0.78367739, grad/param norm = 1.7825e-01, time/batch = 17.4865s	
29038/33150 (epoch 43.798), train_loss = 0.74210300, grad/param norm = 1.4752e-01, time/batch = 17.3157s	
29039/33150 (epoch 43.799), train_loss = 0.66702078, grad/param norm = 1.9593e-01, time/batch = 16.7324s	
29040/33150 (epoch 43.801), train_loss = 0.81369655, grad/param norm = 2.0205e-01, time/batch = 17.9061s	
29041/33150 (epoch 43.802), train_loss = 0.76401251, grad/param norm = 1.7008e-01, time/batch = 16.8101s	
29042/33150 (epoch 43.804), train_loss = 0.76032688, grad/param norm = 1.7758e-01, time/batch = 15.5992s	
29043/33150 (epoch 43.805), train_loss = 0.72428144, grad/param norm = 1.8131e-01, time/batch = 16.1409s	
29044/33150 (epoch 43.807), train_loss = 0.78688562, grad/param norm = 1.4741e-01, time/batch = 18.4598s	
29045/33150 (epoch 43.808), train_loss = 0.87392936, grad/param norm = 2.0885e-01, time/batch = 19.5477s	
29046/33150 (epoch 43.810), train_loss = 0.70447133, grad/param norm = 1.7734e-01, time/batch = 15.6947s	
29047/33150 (epoch 43.811), train_loss = 0.80984117, grad/param norm = 2.0518e-01, time/batch = 18.2902s	
29048/33150 (epoch 43.813), train_loss = 0.78061580, grad/param norm = 1.8714e-01, time/batch = 17.1364s	
29049/33150 (epoch 43.814), train_loss = 0.74447395, grad/param norm = 2.2473e-01, time/batch = 17.7926s	
29050/33150 (epoch 43.816), train_loss = 0.75889142, grad/param norm = 2.0741e-01, time/batch = 16.8790s	
29051/33150 (epoch 43.817), train_loss = 0.83448079, grad/param norm = 1.7355e-01, time/batch = 16.3253s	
29052/33150 (epoch 43.819), train_loss = 0.82608847, grad/param norm = 1.9301e-01, time/batch = 17.7170s	
29053/33150 (epoch 43.821), train_loss = 0.72700626, grad/param norm = 1.5443e-01, time/batch = 16.4520s	
29054/33150 (epoch 43.822), train_loss = 0.77810089, grad/param norm = 1.8977e-01, time/batch = 17.1327s	
29055/33150 (epoch 43.824), train_loss = 0.82356121, grad/param norm = 1.8243e-01, time/batch = 18.6343s	
29056/33150 (epoch 43.825), train_loss = 0.84161044, grad/param norm = 2.1140e-01, time/batch = 16.1498s	
29057/33150 (epoch 43.827), train_loss = 0.85278185, grad/param norm = 2.3785e-01, time/batch = 17.6224s	
29058/33150 (epoch 43.828), train_loss = 0.71607221, grad/param norm = 1.7270e-01, time/batch = 17.2145s	
29059/33150 (epoch 43.830), train_loss = 0.86389137, grad/param norm = 1.9888e-01, time/batch = 17.1200s	
29060/33150 (epoch 43.831), train_loss = 0.74453286, grad/param norm = 1.7640e-01, time/batch = 18.2791s	
29061/33150 (epoch 43.833), train_loss = 0.70583468, grad/param norm = 1.5834e-01, time/batch = 15.6373s	
29062/33150 (epoch 43.834), train_loss = 0.86790724, grad/param norm = 1.7134e-01, time/batch = 17.7295s	
29063/33150 (epoch 43.836), train_loss = 0.91643528, grad/param norm = 1.8362e-01, time/batch = 16.8103s	
29064/33150 (epoch 43.837), train_loss = 0.72753085, grad/param norm = 1.7114e-01, time/batch = 18.9723s	
29065/33150 (epoch 43.839), train_loss = 0.88322213, grad/param norm = 2.0349e-01, time/batch = 16.0497s	
29066/33150 (epoch 43.840), train_loss = 0.84298389, grad/param norm = 1.7811e-01, time/batch = 17.7167s	
29067/33150 (epoch 43.842), train_loss = 0.89847905, grad/param norm = 2.3081e-01, time/batch = 16.5671s	
29068/33150 (epoch 43.843), train_loss = 0.89416007, grad/param norm = 2.0327e-01, time/batch = 18.1320s	
29069/33150 (epoch 43.845), train_loss = 0.76451063, grad/param norm = 1.7944e-01, time/batch = 16.8007s	
29070/33150 (epoch 43.846), train_loss = 0.96311955, grad/param norm = 2.8112e-01, time/batch = 16.4616s	
29071/33150 (epoch 43.848), train_loss = 0.88792145, grad/param norm = 2.3431e-01, time/batch = 17.8912s	
29072/33150 (epoch 43.849), train_loss = 0.89832038, grad/param norm = 1.9196e-01, time/batch = 15.9802s	
29073/33150 (epoch 43.851), train_loss = 0.87132588, grad/param norm = 2.1004e-01, time/batch = 17.9670s	
29074/33150 (epoch 43.852), train_loss = 0.94839154, grad/param norm = 2.0533e-01, time/batch = 16.9746s	
29075/33150 (epoch 43.854), train_loss = 0.85515043, grad/param norm = 1.9308e-01, time/batch = 16.0577s	
29076/33150 (epoch 43.855), train_loss = 0.75310083, grad/param norm = 2.1246e-01, time/batch = 18.1378s	
29077/33150 (epoch 43.857), train_loss = 0.66997826, grad/param norm = 1.8170e-01, time/batch = 16.4614s	
29078/33150 (epoch 43.858), train_loss = 0.78159492, grad/param norm = 1.9492e-01, time/batch = 18.8748s	
29079/33150 (epoch 43.860), train_loss = 0.73615977, grad/param norm = 1.8845e-01, time/batch = 18.3840s	
29080/33150 (epoch 43.861), train_loss = 0.70503252, grad/param norm = 1.6498e-01, time/batch = 17.7959s	
29081/33150 (epoch 43.863), train_loss = 0.77374112, grad/param norm = 1.6184e-01, time/batch = 17.4764s	
29082/33150 (epoch 43.864), train_loss = 0.81594794, grad/param norm = 2.0241e-01, time/batch = 17.8155s	
29083/33150 (epoch 43.866), train_loss = 0.89177832, grad/param norm = 1.9767e-01, time/batch = 18.6255s	
29084/33150 (epoch 43.867), train_loss = 0.80733969, grad/param norm = 1.7809e-01, time/batch = 17.0564s	
29085/33150 (epoch 43.869), train_loss = 0.82697461, grad/param norm = 1.9677e-01, time/batch = 19.3039s	
29086/33150 (epoch 43.870), train_loss = 0.77937206, grad/param norm = 2.2281e-01, time/batch = 18.3148s	
29087/33150 (epoch 43.872), train_loss = 0.85814601, grad/param norm = 2.2434e-01, time/batch = 17.0505s	
29088/33150 (epoch 43.873), train_loss = 0.67406724, grad/param norm = 1.4751e-01, time/batch = 16.0364s	
29089/33150 (epoch 43.875), train_loss = 0.90492474, grad/param norm = 1.8205e-01, time/batch = 19.6237s	
29090/33150 (epoch 43.876), train_loss = 0.66758558, grad/param norm = 1.6912e-01, time/batch = 18.1926s	
29091/33150 (epoch 43.878), train_loss = 0.74021589, grad/param norm = 1.5823e-01, time/batch = 16.1893s	
29092/33150 (epoch 43.879), train_loss = 0.74095076, grad/param norm = 1.6128e-01, time/batch = 20.5448s	
29093/33150 (epoch 43.881), train_loss = 0.74814869, grad/param norm = 1.8835e-01, time/batch = 17.2940s	
29094/33150 (epoch 43.882), train_loss = 0.61972475, grad/param norm = 1.6257e-01, time/batch = 17.2800s	
29095/33150 (epoch 43.884), train_loss = 0.74708821, grad/param norm = 1.9985e-01, time/batch = 18.8816s	
29096/33150 (epoch 43.885), train_loss = 0.60338173, grad/param norm = 1.5879e-01, time/batch = 17.3731s	
29097/33150 (epoch 43.887), train_loss = 0.87606523, grad/param norm = 2.1120e-01, time/batch = 17.4634s	
29098/33150 (epoch 43.888), train_loss = 0.80515976, grad/param norm = 1.6140e-01, time/batch = 17.6405s	
29099/33150 (epoch 43.890), train_loss = 0.70842623, grad/param norm = 1.7827e-01, time/batch = 19.2083s	
29100/33150 (epoch 43.891), train_loss = 0.71065773, grad/param norm = 1.6807e-01, time/batch = 16.7839s	
29101/33150 (epoch 43.893), train_loss = 0.83073237, grad/param norm = 1.7946e-01, time/batch = 19.1243s	
29102/33150 (epoch 43.894), train_loss = 0.82879700, grad/param norm = 1.7227e-01, time/batch = 18.0363s	
29103/33150 (epoch 43.896), train_loss = 0.78787143, grad/param norm = 1.7935e-01, time/batch = 18.4661s	
29104/33150 (epoch 43.897), train_loss = 0.84171589, grad/param norm = 1.6731e-01, time/batch = 17.8936s	
29105/33150 (epoch 43.899), train_loss = 0.65933648, grad/param norm = 2.0986e-01, time/batch = 17.8130s	
29106/33150 (epoch 43.900), train_loss = 0.95946814, grad/param norm = 2.0667e-01, time/batch = 18.9692s	
29107/33150 (epoch 43.902), train_loss = 1.00624900, grad/param norm = 1.9255e-01, time/batch = 16.8972s	
29108/33150 (epoch 43.903), train_loss = 0.82209622, grad/param norm = 1.8332e-01, time/batch = 16.8889s	
29109/33150 (epoch 43.905), train_loss = 0.79118635, grad/param norm = 1.7215e-01, time/batch = 16.5534s	
29110/33150 (epoch 43.906), train_loss = 0.80921942, grad/param norm = 1.9405e-01, time/batch = 16.3774s	
29111/33150 (epoch 43.908), train_loss = 0.85719614, grad/param norm = 1.8775e-01, time/batch = 17.3012s	
29112/33150 (epoch 43.910), train_loss = 0.88689867, grad/param norm = 1.9489e-01, time/batch = 18.7255s	
29113/33150 (epoch 43.911), train_loss = 0.68657285, grad/param norm = 1.6272e-01, time/batch = 16.8998s	
29114/33150 (epoch 43.913), train_loss = 0.74762081, grad/param norm = 1.6360e-01, time/batch = 15.7125s	
29115/33150 (epoch 43.914), train_loss = 0.81313251, grad/param norm = 2.5192e-01, time/batch = 17.4717s	
29116/33150 (epoch 43.916), train_loss = 0.74315962, grad/param norm = 1.8462e-01, time/batch = 17.5696s	
29117/33150 (epoch 43.917), train_loss = 0.80973058, grad/param norm = 1.6764e-01, time/batch = 17.9743s	
29118/33150 (epoch 43.919), train_loss = 0.92216635, grad/param norm = 2.4785e-01, time/batch = 15.8778s	
29119/33150 (epoch 43.920), train_loss = 0.88692614, grad/param norm = 2.0799e-01, time/batch = 17.1421s	
29120/33150 (epoch 43.922), train_loss = 0.89530915, grad/param norm = 1.9879e-01, time/batch = 17.2138s	
29121/33150 (epoch 43.923), train_loss = 0.81602585, grad/param norm = 1.9130e-01, time/batch = 16.1306s	
29122/33150 (epoch 43.925), train_loss = 0.89493891, grad/param norm = 1.8982e-01, time/batch = 16.2427s	
29123/33150 (epoch 43.926), train_loss = 0.80078800, grad/param norm = 1.8514e-01, time/batch = 19.0494s	
29124/33150 (epoch 43.928), train_loss = 0.78909403, grad/param norm = 1.7642e-01, time/batch = 16.1273s	
29125/33150 (epoch 43.929), train_loss = 0.85351186, grad/param norm = 1.8724e-01, time/batch = 16.3601s	
29126/33150 (epoch 43.931), train_loss = 0.88941553, grad/param norm = 1.9539e-01, time/batch = 16.3929s	
29127/33150 (epoch 43.932), train_loss = 0.84366422, grad/param norm = 2.2715e-01, time/batch = 17.5652s	
29128/33150 (epoch 43.934), train_loss = 0.82735224, grad/param norm = 1.7078e-01, time/batch = 16.8778s	
29129/33150 (epoch 43.935), train_loss = 0.88889526, grad/param norm = 1.8379e-01, time/batch = 15.8853s	
29130/33150 (epoch 43.937), train_loss = 0.91779473, grad/param norm = 1.7857e-01, time/batch = 17.3168s	
29131/33150 (epoch 43.938), train_loss = 0.84709537, grad/param norm = 2.0103e-01, time/batch = 17.1370s	
29132/33150 (epoch 43.940), train_loss = 1.04981650, grad/param norm = 2.2508e-01, time/batch = 15.3754s	
29133/33150 (epoch 43.941), train_loss = 0.85932740, grad/param norm = 1.6397e-01, time/batch = 15.6601s	
29134/33150 (epoch 43.943), train_loss = 0.67710601, grad/param norm = 1.7722e-01, time/batch = 16.6253s	
29135/33150 (epoch 43.944), train_loss = 0.86296654, grad/param norm = 1.9531e-01, time/batch = 16.0608s	
29136/33150 (epoch 43.946), train_loss = 0.72255075, grad/param norm = 1.4851e-01, time/batch = 17.3037s	
29137/33150 (epoch 43.947), train_loss = 0.83839101, grad/param norm = 2.0583e-01, time/batch = 16.7290s	
29138/33150 (epoch 43.949), train_loss = 0.89149907, grad/param norm = 1.7633e-01, time/batch = 17.5470s	
29139/33150 (epoch 43.950), train_loss = 0.88677467, grad/param norm = 1.9239e-01, time/batch = 16.3244s	
29140/33150 (epoch 43.952), train_loss = 0.75627879, grad/param norm = 1.8180e-01, time/batch = 18.3086s	
29141/33150 (epoch 43.953), train_loss = 0.81115162, grad/param norm = 1.6265e-01, time/batch = 16.8225s	
29142/33150 (epoch 43.955), train_loss = 0.68741336, grad/param norm = 1.9251e-01, time/batch = 17.8842s	
29143/33150 (epoch 43.956), train_loss = 0.88602379, grad/param norm = 2.0870e-01, time/batch = 15.9647s	
29144/33150 (epoch 43.958), train_loss = 0.73943659, grad/param norm = 1.6147e-01, time/batch = 18.7948s	
29145/33150 (epoch 43.959), train_loss = 0.79830075, grad/param norm = 1.7318e-01, time/batch = 15.3035s	
29146/33150 (epoch 43.961), train_loss = 0.71973402, grad/param norm = 1.5661e-01, time/batch = 16.8660s	
29147/33150 (epoch 43.962), train_loss = 0.68330581, grad/param norm = 1.5938e-01, time/batch = 16.8747s	
29148/33150 (epoch 43.964), train_loss = 0.78396069, grad/param norm = 1.6951e-01, time/batch = 18.1404s	
29149/33150 (epoch 43.965), train_loss = 0.78297529, grad/param norm = 1.6438e-01, time/batch = 16.6322s	
29150/33150 (epoch 43.967), train_loss = 0.79082943, grad/param norm = 1.7704e-01, time/batch = 18.3773s	
29151/33150 (epoch 43.968), train_loss = 0.67503879, grad/param norm = 1.4960e-01, time/batch = 18.9576s	
29152/33150 (epoch 43.970), train_loss = 0.75031203, grad/param norm = 1.6821e-01, time/batch = 18.3943s	
29153/33150 (epoch 43.971), train_loss = 0.81229355, grad/param norm = 1.6855e-01, time/batch = 17.6459s	
29154/33150 (epoch 43.973), train_loss = 0.86831819, grad/param norm = 1.6997e-01, time/batch = 17.9762s	
29155/33150 (epoch 43.974), train_loss = 0.90850640, grad/param norm = 1.9188e-01, time/batch = 15.9672s	
29156/33150 (epoch 43.976), train_loss = 0.89942020, grad/param norm = 1.8917e-01, time/batch = 16.5292s	
29157/33150 (epoch 43.977), train_loss = 0.92955428, grad/param norm = 2.0134e-01, time/batch = 16.9664s	
29158/33150 (epoch 43.979), train_loss = 0.90017963, grad/param norm = 2.3509e-01, time/batch = 17.2984s	
29159/33150 (epoch 43.980), train_loss = 0.94821189, grad/param norm = 2.1551e-01, time/batch = 17.5517s	
29160/33150 (epoch 43.982), train_loss = 0.81231027, grad/param norm = 1.9706e-01, time/batch = 17.2318s	
29161/33150 (epoch 43.983), train_loss = 0.73858349, grad/param norm = 1.6803e-01, time/batch = 17.3993s	
29162/33150 (epoch 43.985), train_loss = 0.91091416, grad/param norm = 1.8560e-01, time/batch = 17.3748s	
29163/33150 (epoch 43.986), train_loss = 0.69954685, grad/param norm = 1.7232e-01, time/batch = 15.4626s	
29164/33150 (epoch 43.988), train_loss = 0.76904808, grad/param norm = 2.0446e-01, time/batch = 17.0554s	
29165/33150 (epoch 43.989), train_loss = 0.78276972, grad/param norm = 1.7324e-01, time/batch = 17.2205s	
29166/33150 (epoch 43.991), train_loss = 0.82744362, grad/param norm = 2.6488e-01, time/batch = 18.4537s	
29167/33150 (epoch 43.992), train_loss = 0.80103540, grad/param norm = 1.8334e-01, time/batch = 17.3921s	
29168/33150 (epoch 43.994), train_loss = 0.83331321, grad/param norm = 1.8376e-01, time/batch = 17.1526s	
29169/33150 (epoch 43.995), train_loss = 0.78141116, grad/param norm = 2.0283e-01, time/batch = 18.3171s	
29170/33150 (epoch 43.997), train_loss = 0.80186936, grad/param norm = 2.0630e-01, time/batch = 17.4600s	
29171/33150 (epoch 43.998), train_loss = 0.67892707, grad/param norm = 1.6436e-01, time/batch = 17.7009s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
29172/33150 (epoch 44.000), train_loss = 0.72704579, grad/param norm = 2.1015e-01, time/batch = 17.3048s	
29173/33150 (epoch 44.002), train_loss = 1.10110557, grad/param norm = 2.0489e-01, time/batch = 17.5507s	
29174/33150 (epoch 44.003), train_loss = 0.74945148, grad/param norm = 2.1618e-01, time/batch = 17.7174s	
29175/33150 (epoch 44.005), train_loss = 0.69328876, grad/param norm = 1.4940e-01, time/batch = 15.9525s	
29176/33150 (epoch 44.006), train_loss = 0.67973605, grad/param norm = 1.6503e-01, time/batch = 16.5699s	
29177/33150 (epoch 44.008), train_loss = 0.85059130, grad/param norm = 1.9640e-01, time/batch = 16.4746s	
29178/33150 (epoch 44.009), train_loss = 0.82442176, grad/param norm = 1.8902e-01, time/batch = 18.2213s	
29179/33150 (epoch 44.011), train_loss = 0.91018720, grad/param norm = 2.0006e-01, time/batch = 19.7101s	
29180/33150 (epoch 44.012), train_loss = 0.78620954, grad/param norm = 2.3540e-01, time/batch = 15.9694s	
29181/33150 (epoch 44.014), train_loss = 0.74954662, grad/param norm = 2.1774e-01, time/batch = 17.7914s	
29182/33150 (epoch 44.015), train_loss = 0.72147853, grad/param norm = 1.8946e-01, time/batch = 18.7870s	
29183/33150 (epoch 44.017), train_loss = 0.72428125, grad/param norm = 1.6942e-01, time/batch = 17.8719s	
29184/33150 (epoch 44.018), train_loss = 0.80860978, grad/param norm = 2.0696e-01, time/batch = 15.2784s	
29185/33150 (epoch 44.020), train_loss = 0.87306035, grad/param norm = 2.0220e-01, time/batch = 17.6533s	
29186/33150 (epoch 44.021), train_loss = 0.73713658, grad/param norm = 1.9526e-01, time/batch = 17.0630s	
29187/33150 (epoch 44.023), train_loss = 0.98116235, grad/param norm = 1.7784e-01, time/batch = 15.3817s	
29188/33150 (epoch 44.024), train_loss = 0.85836589, grad/param norm = 2.2137e-01, time/batch = 18.6482s	
29189/33150 (epoch 44.026), train_loss = 0.63933841, grad/param norm = 1.6668e-01, time/batch = 17.9632s	
29190/33150 (epoch 44.027), train_loss = 0.66154363, grad/param norm = 1.7562e-01, time/batch = 18.0389s	
29191/33150 (epoch 44.029), train_loss = 0.74295374, grad/param norm = 1.9029e-01, time/batch = 17.9597s	
29192/33150 (epoch 44.030), train_loss = 0.78348209, grad/param norm = 1.4843e-01, time/batch = 16.7366s	
29193/33150 (epoch 44.032), train_loss = 0.71391583, grad/param norm = 2.0985e-01, time/batch = 16.0672s	
29194/33150 (epoch 44.033), train_loss = 0.72128423, grad/param norm = 1.6027e-01, time/batch = 16.0521s	
29195/33150 (epoch 44.035), train_loss = 0.95414932, grad/param norm = 2.0969e-01, time/batch = 17.2327s	
29196/33150 (epoch 44.036), train_loss = 0.88099512, grad/param norm = 2.0912e-01, time/batch = 16.6234s	
29197/33150 (epoch 44.038), train_loss = 0.96303637, grad/param norm = 2.0005e-01, time/batch = 15.5457s	
29198/33150 (epoch 44.039), train_loss = 0.86363687, grad/param norm = 1.8859e-01, time/batch = 16.2884s	
29199/33150 (epoch 44.041), train_loss = 0.79898861, grad/param norm = 1.8134e-01, time/batch = 16.9524s	
29200/33150 (epoch 44.042), train_loss = 0.74095932, grad/param norm = 1.8105e-01, time/batch = 19.9444s	
29201/33150 (epoch 44.044), train_loss = 0.79959343, grad/param norm = 1.7334e-01, time/batch = 16.4642s	
29202/33150 (epoch 44.045), train_loss = 0.86758362, grad/param norm = 1.6500e-01, time/batch = 18.8063s	
29203/33150 (epoch 44.047), train_loss = 0.72701666, grad/param norm = 1.6368e-01, time/batch = 15.7233s	
29204/33150 (epoch 44.048), train_loss = 0.86687694, grad/param norm = 2.3423e-01, time/batch = 15.8101s	
29205/33150 (epoch 44.050), train_loss = 0.78471401, grad/param norm = 1.9834e-01, time/batch = 15.2148s	
29206/33150 (epoch 44.051), train_loss = 0.83245370, grad/param norm = 1.7380e-01, time/batch = 17.0436s	
29207/33150 (epoch 44.053), train_loss = 0.83991698, grad/param norm = 1.8339e-01, time/batch = 18.5551s	
29208/33150 (epoch 44.054), train_loss = 0.93752832, grad/param norm = 1.7702e-01, time/batch = 16.4659s	
29209/33150 (epoch 44.056), train_loss = 0.79625858, grad/param norm = 1.7401e-01, time/batch = 17.8099s	
29210/33150 (epoch 44.057), train_loss = 0.86346042, grad/param norm = 1.7205e-01, time/batch = 18.6494s	
29211/33150 (epoch 44.059), train_loss = 0.72177917, grad/param norm = 1.8086e-01, time/batch = 16.9665s	
29212/33150 (epoch 44.060), train_loss = 0.71201176, grad/param norm = 1.4808e-01, time/batch = 17.1346s	
29213/33150 (epoch 44.062), train_loss = 0.79262101, grad/param norm = 1.7504e-01, time/batch = 18.8776s	
29214/33150 (epoch 44.063), train_loss = 0.73458386, grad/param norm = 1.7537e-01, time/batch = 16.5130s	
29215/33150 (epoch 44.065), train_loss = 0.78857493, grad/param norm = 1.6603e-01, time/batch = 15.2325s	
29216/33150 (epoch 44.066), train_loss = 0.78297456, grad/param norm = 1.7071e-01, time/batch = 15.0217s	
29217/33150 (epoch 44.068), train_loss = 0.85392927, grad/param norm = 1.6537e-01, time/batch = 14.9069s	
29218/33150 (epoch 44.069), train_loss = 0.85556750, grad/param norm = 2.0262e-01, time/batch = 14.6032s	
29219/33150 (epoch 44.071), train_loss = 0.83748581, grad/param norm = 1.8972e-01, time/batch = 24.9233s	
29220/33150 (epoch 44.072), train_loss = 0.83828061, grad/param norm = 2.1098e-01, time/batch = 18.2227s	
29221/33150 (epoch 44.074), train_loss = 0.67408419, grad/param norm = 1.7138e-01, time/batch = 15.1862s	
29222/33150 (epoch 44.075), train_loss = 0.70864928, grad/param norm = 1.8773e-01, time/batch = 15.2630s	
29223/33150 (epoch 44.077), train_loss = 0.82337331, grad/param norm = 2.3407e-01, time/batch = 15.0281s	
29224/33150 (epoch 44.078), train_loss = 0.92871388, grad/param norm = 2.2551e-01, time/batch = 15.4350s	
29225/33150 (epoch 44.080), train_loss = 0.93010550, grad/param norm = 1.7687e-01, time/batch = 16.7914s	
29226/33150 (epoch 44.081), train_loss = 0.72310670, grad/param norm = 2.2075e-01, time/batch = 16.3099s	
29227/33150 (epoch 44.083), train_loss = 0.58064305, grad/param norm = 2.1649e-01, time/batch = 19.2151s	
29228/33150 (epoch 44.084), train_loss = 0.66333616, grad/param norm = 1.6765e-01, time/batch = 16.6824s	
29229/33150 (epoch 44.086), train_loss = 0.75667047, grad/param norm = 1.9736e-01, time/batch = 15.3689s	
29230/33150 (epoch 44.087), train_loss = 0.68398515, grad/param norm = 1.7159e-01, time/batch = 15.5974s	
29231/33150 (epoch 44.089), train_loss = 0.73103940, grad/param norm = 1.7485e-01, time/batch = 15.4508s	
29232/33150 (epoch 44.090), train_loss = 0.76907317, grad/param norm = 1.7804e-01, time/batch = 15.0551s	
29233/33150 (epoch 44.092), train_loss = 0.73904661, grad/param norm = 2.0176e-01, time/batch = 15.1965s	
29234/33150 (epoch 44.094), train_loss = 0.82019342, grad/param norm = 2.2475e-01, time/batch = 17.8920s	
29235/33150 (epoch 44.095), train_loss = 0.75166064, grad/param norm = 1.9616e-01, time/batch = 16.2305s	
29236/33150 (epoch 44.097), train_loss = 0.67052254, grad/param norm = 1.7544e-01, time/batch = 17.4593s	
29237/33150 (epoch 44.098), train_loss = 1.01410827, grad/param norm = 1.9010e-01, time/batch = 15.7034s	
29238/33150 (epoch 44.100), train_loss = 0.97505123, grad/param norm = 2.1921e-01, time/batch = 15.6438s	
29239/33150 (epoch 44.101), train_loss = 0.73416660, grad/param norm = 1.8517e-01, time/batch = 18.1297s	
29240/33150 (epoch 44.103), train_loss = 0.82396756, grad/param norm = 1.7278e-01, time/batch = 17.5540s	
29241/33150 (epoch 44.104), train_loss = 0.75255067, grad/param norm = 2.4137e-01, time/batch = 16.7984s	
29242/33150 (epoch 44.106), train_loss = 0.91796775, grad/param norm = 1.9833e-01, time/batch = 18.2196s	
29243/33150 (epoch 44.107), train_loss = 0.96588105, grad/param norm = 2.1057e-01, time/batch = 18.2197s	
29244/33150 (epoch 44.109), train_loss = 0.78432477, grad/param norm = 1.5859e-01, time/batch = 17.3835s	
29245/33150 (epoch 44.110), train_loss = 0.88474004, grad/param norm = 2.0716e-01, time/batch = 19.4645s	
29246/33150 (epoch 44.112), train_loss = 0.73043678, grad/param norm = 1.8036e-01, time/batch = 18.3125s	
29247/33150 (epoch 44.113), train_loss = 0.76435074, grad/param norm = 1.6310e-01, time/batch = 17.5401s	
29248/33150 (epoch 44.115), train_loss = 0.95826897, grad/param norm = 2.0186e-01, time/batch = 16.9507s	
29249/33150 (epoch 44.116), train_loss = 0.86307592, grad/param norm = 1.7845e-01, time/batch = 18.9699s	
29250/33150 (epoch 44.118), train_loss = 0.84107229, grad/param norm = 1.9876e-01, time/batch = 16.0435s	
29251/33150 (epoch 44.119), train_loss = 0.84700073, grad/param norm = 1.9289e-01, time/batch = 17.4000s	
29252/33150 (epoch 44.121), train_loss = 0.79280345, grad/param norm = 1.7712e-01, time/batch = 17.4571s	
29253/33150 (epoch 44.122), train_loss = 0.94754294, grad/param norm = 2.5767e-01, time/batch = 16.3812s	
29254/33150 (epoch 44.124), train_loss = 0.67655231, grad/param norm = 1.5244e-01, time/batch = 15.7847s	
29255/33150 (epoch 44.125), train_loss = 0.91717798, grad/param norm = 1.8681e-01, time/batch = 17.5604s	
29256/33150 (epoch 44.127), train_loss = 0.84004745, grad/param norm = 1.8137e-01, time/batch = 17.1486s	
29257/33150 (epoch 44.128), train_loss = 0.83904028, grad/param norm = 1.8183e-01, time/batch = 17.5383s	
29258/33150 (epoch 44.130), train_loss = 0.80386924, grad/param norm = 1.6625e-01, time/batch = 18.1377s	
29259/33150 (epoch 44.131), train_loss = 0.98361089, grad/param norm = 1.9653e-01, time/batch = 18.5584s	
29260/33150 (epoch 44.133), train_loss = 0.75498595, grad/param norm = 1.6065e-01, time/batch = 16.6260s	
29261/33150 (epoch 44.134), train_loss = 0.91115548, grad/param norm = 1.7589e-01, time/batch = 15.6910s	
29262/33150 (epoch 44.136), train_loss = 0.82903157, grad/param norm = 2.0908e-01, time/batch = 18.2305s	
29263/33150 (epoch 44.137), train_loss = 0.87484063, grad/param norm = 1.7823e-01, time/batch = 18.1364s	
29264/33150 (epoch 44.139), train_loss = 0.89339664, grad/param norm = 2.1255e-01, time/batch = 17.4687s	
29265/33150 (epoch 44.140), train_loss = 0.96703374, grad/param norm = 2.0662e-01, time/batch = 16.2122s	
29266/33150 (epoch 44.142), train_loss = 0.85469234, grad/param norm = 2.1624e-01, time/batch = 16.5477s	
29267/33150 (epoch 44.143), train_loss = 0.81563768, grad/param norm = 2.1696e-01, time/batch = 19.2907s	
29268/33150 (epoch 44.145), train_loss = 0.77122576, grad/param norm = 2.1196e-01, time/batch = 17.5333s	
29269/33150 (epoch 44.146), train_loss = 0.91794600, grad/param norm = 2.1785e-01, time/batch = 16.7189s	
29270/33150 (epoch 44.148), train_loss = 0.96578958, grad/param norm = 1.8667e-01, time/batch = 18.2951s	
29271/33150 (epoch 44.149), train_loss = 0.84167671, grad/param norm = 2.3489e-01, time/batch = 16.8777s	
29272/33150 (epoch 44.151), train_loss = 0.97300970, grad/param norm = 2.3417e-01, time/batch = 18.6485s	
29273/33150 (epoch 44.152), train_loss = 0.75634817, grad/param norm = 1.7467e-01, time/batch = 19.6934s	
29274/33150 (epoch 44.154), train_loss = 0.75505514, grad/param norm = 2.3497e-01, time/batch = 17.4802s	
29275/33150 (epoch 44.155), train_loss = 0.70229428, grad/param norm = 1.9624e-01, time/batch = 18.7276s	
29276/33150 (epoch 44.157), train_loss = 0.79197203, grad/param norm = 1.9730e-01, time/batch = 16.9917s	
29277/33150 (epoch 44.158), train_loss = 0.80382213, grad/param norm = 1.7015e-01, time/batch = 18.1514s	
29278/33150 (epoch 44.160), train_loss = 0.87838972, grad/param norm = 1.9032e-01, time/batch = 17.7034s	
29279/33150 (epoch 44.161), train_loss = 0.78274873, grad/param norm = 2.1994e-01, time/batch = 16.6349s	
29280/33150 (epoch 44.163), train_loss = 0.71418992, grad/param norm = 1.8043e-01, time/batch = 17.3766s	
29281/33150 (epoch 44.164), train_loss = 0.83387062, grad/param norm = 1.6854e-01, time/batch = 15.9842s	
29282/33150 (epoch 44.166), train_loss = 0.77731516, grad/param norm = 1.7586e-01, time/batch = 15.6256s	
29283/33150 (epoch 44.167), train_loss = 0.83909690, grad/param norm = 1.5819e-01, time/batch = 17.2352s	
29284/33150 (epoch 44.169), train_loss = 0.80729793, grad/param norm = 2.2753e-01, time/batch = 18.1368s	
29285/33150 (epoch 44.170), train_loss = 0.74094947, grad/param norm = 2.9375e-01, time/batch = 16.2828s	
29286/33150 (epoch 44.172), train_loss = 0.85360861, grad/param norm = 1.9164e-01, time/batch = 18.0656s	
29287/33150 (epoch 44.173), train_loss = 0.83167690, grad/param norm = 2.0937e-01, time/batch = 16.7237s	
29288/33150 (epoch 44.175), train_loss = 0.78731494, grad/param norm = 2.0124e-01, time/batch = 16.5441s	
29289/33150 (epoch 44.176), train_loss = 0.87960364, grad/param norm = 2.3697e-01, time/batch = 17.9770s	
29290/33150 (epoch 44.178), train_loss = 0.99459479, grad/param norm = 2.6098e-01, time/batch = 17.3000s	
29291/33150 (epoch 44.179), train_loss = 0.87632861, grad/param norm = 1.7956e-01, time/batch = 18.2120s	
29292/33150 (epoch 44.181), train_loss = 0.84991182, grad/param norm = 2.4742e-01, time/batch = 18.1396s	
29293/33150 (epoch 44.183), train_loss = 0.80487580, grad/param norm = 2.2157e-01, time/batch = 17.8079s	
29294/33150 (epoch 44.184), train_loss = 1.06955651, grad/param norm = 2.1388e-01, time/batch = 18.4728s	
29295/33150 (epoch 44.186), train_loss = 0.99971373, grad/param norm = 1.8305e-01, time/batch = 16.5420s	
29296/33150 (epoch 44.187), train_loss = 0.82495282, grad/param norm = 2.0316e-01, time/batch = 18.3109s	
29297/33150 (epoch 44.189), train_loss = 0.64956345, grad/param norm = 1.7402e-01, time/batch = 18.7152s	
29298/33150 (epoch 44.190), train_loss = 0.74629753, grad/param norm = 2.0846e-01, time/batch = 16.4790s	
29299/33150 (epoch 44.192), train_loss = 0.85241116, grad/param norm = 2.1243e-01, time/batch = 17.3200s	
29300/33150 (epoch 44.193), train_loss = 0.86822151, grad/param norm = 1.6760e-01, time/batch = 16.0508s	
29301/33150 (epoch 44.195), train_loss = 0.99313122, grad/param norm = 2.4412e-01, time/batch = 16.4716s	
29302/33150 (epoch 44.196), train_loss = 0.92901132, grad/param norm = 1.8051e-01, time/batch = 17.0566s	
29303/33150 (epoch 44.198), train_loss = 0.73205333, grad/param norm = 1.7283e-01, time/batch = 17.0507s	
29304/33150 (epoch 44.199), train_loss = 0.89154224, grad/param norm = 2.2588e-01, time/batch = 16.8796s	
29305/33150 (epoch 44.201), train_loss = 0.79038489, grad/param norm = 1.7019e-01, time/batch = 16.3680s	
29306/33150 (epoch 44.202), train_loss = 0.66772444, grad/param norm = 1.9039e-01, time/batch = 17.6381s	
29307/33150 (epoch 44.204), train_loss = 0.83087221, grad/param norm = 1.8488e-01, time/batch = 17.8871s	
29308/33150 (epoch 44.205), train_loss = 0.83974604, grad/param norm = 1.9570e-01, time/batch = 19.7069s	
29309/33150 (epoch 44.207), train_loss = 0.83868216, grad/param norm = 1.7490e-01, time/batch = 16.6318s	
29310/33150 (epoch 44.208), train_loss = 0.89545001, grad/param norm = 1.8649e-01, time/batch = 17.8819s	
29311/33150 (epoch 44.210), train_loss = 0.76284288, grad/param norm = 1.6378e-01, time/batch = 18.2195s	
29312/33150 (epoch 44.211), train_loss = 0.81478817, grad/param norm = 2.0493e-01, time/batch = 16.3919s	
29313/33150 (epoch 44.213), train_loss = 0.88651139, grad/param norm = 1.9463e-01, time/batch = 17.1287s	
29314/33150 (epoch 44.214), train_loss = 0.78594071, grad/param norm = 1.7821e-01, time/batch = 17.5578s	
29315/33150 (epoch 44.216), train_loss = 0.73845540, grad/param norm = 1.7176e-01, time/batch = 17.3867s	
29316/33150 (epoch 44.217), train_loss = 0.83142534, grad/param norm = 1.7678e-01, time/batch = 15.9498s	
29317/33150 (epoch 44.219), train_loss = 0.75672073, grad/param norm = 1.8006e-01, time/batch = 16.0501s	
29318/33150 (epoch 44.220), train_loss = 0.80507466, grad/param norm = 1.6774e-01, time/batch = 18.0505s	
29319/33150 (epoch 44.222), train_loss = 0.89704614, grad/param norm = 2.0157e-01, time/batch = 16.9690s	
29320/33150 (epoch 44.223), train_loss = 0.82165249, grad/param norm = 1.9650e-01, time/batch = 15.9858s	
29321/33150 (epoch 44.225), train_loss = 0.92463603, grad/param norm = 1.9365e-01, time/batch = 18.2120s	
29322/33150 (epoch 44.226), train_loss = 0.78881891, grad/param norm = 1.8152e-01, time/batch = 16.4729s	
29323/33150 (epoch 44.228), train_loss = 0.78649222, grad/param norm = 2.0073e-01, time/batch = 16.9503s	
29324/33150 (epoch 44.229), train_loss = 0.80720957, grad/param norm = 1.7530e-01, time/batch = 16.9737s	
29325/33150 (epoch 44.231), train_loss = 0.90182005, grad/param norm = 1.8571e-01, time/batch = 16.9052s	
29326/33150 (epoch 44.232), train_loss = 0.79163549, grad/param norm = 1.7319e-01, time/batch = 17.2192s	
29327/33150 (epoch 44.234), train_loss = 0.84875422, grad/param norm = 2.0711e-01, time/batch = 17.6357s	
29328/33150 (epoch 44.235), train_loss = 0.88550882, grad/param norm = 1.9076e-01, time/batch = 16.5593s	
29329/33150 (epoch 44.237), train_loss = 0.84756251, grad/param norm = 2.7709e-01, time/batch = 18.4571s	
29330/33150 (epoch 44.238), train_loss = 0.87882824, grad/param norm = 2.3662e-01, time/batch = 15.7848s	
29331/33150 (epoch 44.240), train_loss = 0.84388263, grad/param norm = 2.1189e-01, time/batch = 17.0643s	
29332/33150 (epoch 44.241), train_loss = 0.91793446, grad/param norm = 2.2289e-01, time/batch = 17.8900s	
29333/33150 (epoch 44.243), train_loss = 0.87087396, grad/param norm = 1.8923e-01, time/batch = 17.8083s	
29334/33150 (epoch 44.244), train_loss = 0.83676814, grad/param norm = 1.7177e-01, time/batch = 18.0495s	
29335/33150 (epoch 44.246), train_loss = 0.89545529, grad/param norm = 2.0301e-01, time/batch = 18.9045s	
29336/33150 (epoch 44.247), train_loss = 0.78511534, grad/param norm = 1.8608e-01, time/batch = 17.2181s	
29337/33150 (epoch 44.249), train_loss = 0.96134639, grad/param norm = 1.9607e-01, time/batch = 18.0566s	
29338/33150 (epoch 44.250), train_loss = 0.85089418, grad/param norm = 1.6910e-01, time/batch = 16.8812s	
29339/33150 (epoch 44.252), train_loss = 0.88382395, grad/param norm = 1.6174e-01, time/batch = 16.9789s	
29340/33150 (epoch 44.253), train_loss = 0.80826626, grad/param norm = 2.2866e-01, time/batch = 16.9428s	
29341/33150 (epoch 44.255), train_loss = 0.81658170, grad/param norm = 1.7711e-01, time/batch = 17.2803s	
29342/33150 (epoch 44.256), train_loss = 0.91604659, grad/param norm = 1.9898e-01, time/batch = 18.5483s	
29343/33150 (epoch 44.258), train_loss = 0.79012340, grad/param norm = 2.0478e-01, time/batch = 16.5547s	
29344/33150 (epoch 44.259), train_loss = 0.67736516, grad/param norm = 2.3161e-01, time/batch = 17.3891s	
29345/33150 (epoch 44.261), train_loss = 0.73390766, grad/param norm = 1.6361e-01, time/batch = 18.0422s	
29346/33150 (epoch 44.262), train_loss = 0.95849875, grad/param norm = 2.2777e-01, time/batch = 18.8653s	
29347/33150 (epoch 44.264), train_loss = 0.65183419, grad/param norm = 1.5200e-01, time/batch = 16.5422s	
29348/33150 (epoch 44.265), train_loss = 0.84033020, grad/param norm = 2.1370e-01, time/batch = 19.4616s	
29349/33150 (epoch 44.267), train_loss = 0.92706823, grad/param norm = 2.4001e-01, time/batch = 19.0545s	
29350/33150 (epoch 44.268), train_loss = 0.97614250, grad/param norm = 1.8944e-01, time/batch = 16.5575s	
29351/33150 (epoch 44.270), train_loss = 1.01540132, grad/param norm = 1.7958e-01, time/batch = 19.0274s	
29352/33150 (epoch 44.271), train_loss = 0.87970667, grad/param norm = 1.9798e-01, time/batch = 18.4532s	
29353/33150 (epoch 44.273), train_loss = 0.93765529, grad/param norm = 2.0178e-01, time/batch = 16.7736s	
29354/33150 (epoch 44.275), train_loss = 0.95158577, grad/param norm = 2.0238e-01, time/batch = 19.4480s	
29355/33150 (epoch 44.276), train_loss = 0.83123542, grad/param norm = 2.0022e-01, time/batch = 17.7259s	
29356/33150 (epoch 44.278), train_loss = 0.94214042, grad/param norm = 1.9764e-01, time/batch = 18.3639s	
29357/33150 (epoch 44.279), train_loss = 0.91837643, grad/param norm = 1.8429e-01, time/batch = 15.3785s	
29358/33150 (epoch 44.281), train_loss = 0.82927216, grad/param norm = 1.9577e-01, time/batch = 18.3842s	
29359/33150 (epoch 44.282), train_loss = 0.88388466, grad/param norm = 1.6062e-01, time/batch = 16.4713s	
29360/33150 (epoch 44.284), train_loss = 0.77018639, grad/param norm = 1.6539e-01, time/batch = 16.3248s	
29361/33150 (epoch 44.285), train_loss = 0.87473969, grad/param norm = 2.0385e-01, time/batch = 18.3969s	
29362/33150 (epoch 44.287), train_loss = 0.74254636, grad/param norm = 1.6988e-01, time/batch = 17.0624s	
29363/33150 (epoch 44.288), train_loss = 0.90396475, grad/param norm = 1.8657e-01, time/batch = 17.2286s	
29364/33150 (epoch 44.290), train_loss = 0.70282293, grad/param norm = 1.7998e-01, time/batch = 17.8673s	
29365/33150 (epoch 44.291), train_loss = 0.69002641, grad/param norm = 1.7753e-01, time/batch = 18.4015s	
29366/33150 (epoch 44.293), train_loss = 0.78168623, grad/param norm = 1.6791e-01, time/batch = 17.5573s	
29367/33150 (epoch 44.294), train_loss = 0.67004577, grad/param norm = 1.6433e-01, time/batch = 16.8867s	
29368/33150 (epoch 44.296), train_loss = 0.83233107, grad/param norm = 1.6845e-01, time/batch = 16.7812s	
29369/33150 (epoch 44.297), train_loss = 0.76964123, grad/param norm = 1.7652e-01, time/batch = 17.7320s	
29370/33150 (epoch 44.299), train_loss = 0.76082662, grad/param norm = 2.1814e-01, time/batch = 17.1427s	
29371/33150 (epoch 44.300), train_loss = 0.78582816, grad/param norm = 1.7406e-01, time/batch = 17.1320s	
29372/33150 (epoch 44.302), train_loss = 0.80027525, grad/param norm = 1.8461e-01, time/batch = 16.6413s	
29373/33150 (epoch 44.303), train_loss = 0.79757273, grad/param norm = 1.9019e-01, time/batch = 20.4452s	
29374/33150 (epoch 44.305), train_loss = 0.86760340, grad/param norm = 1.8648e-01, time/batch = 15.7115s	
29375/33150 (epoch 44.306), train_loss = 0.87079958, grad/param norm = 1.8395e-01, time/batch = 18.6374s	
29376/33150 (epoch 44.308), train_loss = 1.00701420, grad/param norm = 1.8265e-01, time/batch = 19.2109s	
29377/33150 (epoch 44.309), train_loss = 0.67642284, grad/param norm = 1.5731e-01, time/batch = 16.2239s	
29378/33150 (epoch 44.311), train_loss = 0.81850492, grad/param norm = 1.8254e-01, time/batch = 16.8964s	
29379/33150 (epoch 44.312), train_loss = 0.67408299, grad/param norm = 1.7273e-01, time/batch = 18.3169s	
29380/33150 (epoch 44.314), train_loss = 0.78950651, grad/param norm = 1.9111e-01, time/batch = 18.2154s	
29381/33150 (epoch 44.315), train_loss = 0.86648503, grad/param norm = 1.8186e-01, time/batch = 16.0445s	
29382/33150 (epoch 44.317), train_loss = 0.64865010, grad/param norm = 1.3911e-01, time/batch = 19.5137s	
29383/33150 (epoch 44.318), train_loss = 0.75370142, grad/param norm = 1.5215e-01, time/batch = 17.8721s	
29384/33150 (epoch 44.320), train_loss = 0.69470230, grad/param norm = 1.8438e-01, time/batch = 17.4641s	
29385/33150 (epoch 44.321), train_loss = 0.78261203, grad/param norm = 1.6697e-01, time/batch = 18.8806s	
29386/33150 (epoch 44.323), train_loss = 0.76724562, grad/param norm = 1.8085e-01, time/batch = 18.3072s	
29387/33150 (epoch 44.324), train_loss = 0.80542624, grad/param norm = 2.3067e-01, time/batch = 17.7146s	
29388/33150 (epoch 44.326), train_loss = 0.80111481, grad/param norm = 1.7590e-01, time/batch = 18.2227s	
29389/33150 (epoch 44.327), train_loss = 0.91158754, grad/param norm = 1.8261e-01, time/batch = 18.8778s	
29390/33150 (epoch 44.329), train_loss = 0.87186270, grad/param norm = 2.0078e-01, time/batch = 16.9717s	
29391/33150 (epoch 44.330), train_loss = 0.76963300, grad/param norm = 1.8719e-01, time/batch = 15.9673s	
29392/33150 (epoch 44.332), train_loss = 0.78301747, grad/param norm = 1.7456e-01, time/batch = 18.9644s	
29393/33150 (epoch 44.333), train_loss = 0.86492000, grad/param norm = 1.6780e-01, time/batch = 17.3105s	
29394/33150 (epoch 44.335), train_loss = 0.74075845, grad/param norm = 1.6737e-01, time/batch = 17.1283s	
29395/33150 (epoch 44.336), train_loss = 0.72644142, grad/param norm = 1.8520e-01, time/batch = 18.4708s	
29396/33150 (epoch 44.338), train_loss = 0.69121810, grad/param norm = 1.8796e-01, time/batch = 18.4795s	
29397/33150 (epoch 44.339), train_loss = 0.86533508, grad/param norm = 1.8512e-01, time/batch = 16.3970s	
29398/33150 (epoch 44.341), train_loss = 0.80135034, grad/param norm = 1.9639e-01, time/batch = 18.7345s	
29399/33150 (epoch 44.342), train_loss = 0.74794572, grad/param norm = 1.7534e-01, time/batch = 17.2263s	
29400/33150 (epoch 44.344), train_loss = 0.78556004, grad/param norm = 1.8672e-01, time/batch = 17.5283s	
29401/33150 (epoch 44.345), train_loss = 0.79230541, grad/param norm = 1.7906e-01, time/batch = 15.7416s	
29402/33150 (epoch 44.347), train_loss = 0.68473410, grad/param norm = 1.9393e-01, time/batch = 19.4669s	
29403/33150 (epoch 44.348), train_loss = 0.80765365, grad/param norm = 1.5941e-01, time/batch = 16.6408s	
29404/33150 (epoch 44.350), train_loss = 0.72765125, grad/param norm = 1.9338e-01, time/batch = 15.5644s	
29405/33150 (epoch 44.351), train_loss = 0.87974630, grad/param norm = 1.8884e-01, time/batch = 17.9062s	
29406/33150 (epoch 44.353), train_loss = 0.84638968, grad/param norm = 1.8774e-01, time/batch = 17.4044s	
29407/33150 (epoch 44.354), train_loss = 1.01906655, grad/param norm = 1.8620e-01, time/batch = 16.4662s	
29408/33150 (epoch 44.356), train_loss = 0.90234494, grad/param norm = 1.8989e-01, time/batch = 16.0531s	
29409/33150 (epoch 44.357), train_loss = 0.82215631, grad/param norm = 1.8016e-01, time/batch = 18.8683s	
29410/33150 (epoch 44.359), train_loss = 0.88451457, grad/param norm = 1.7666e-01, time/batch = 17.1117s	
29411/33150 (epoch 44.360), train_loss = 0.84923405, grad/param norm = 2.0127e-01, time/batch = 17.2144s	
29412/33150 (epoch 44.362), train_loss = 0.92842599, grad/param norm = 1.8570e-01, time/batch = 17.6522s	
29413/33150 (epoch 44.363), train_loss = 0.84794906, grad/param norm = 2.0075e-01, time/batch = 18.8060s	
29414/33150 (epoch 44.365), train_loss = 0.80859919, grad/param norm = 1.7394e-01, time/batch = 17.5490s	
29415/33150 (epoch 44.367), train_loss = 0.78442338, grad/param norm = 1.6076e-01, time/batch = 18.7152s	
29416/33150 (epoch 44.368), train_loss = 0.78697301, grad/param norm = 2.1679e-01, time/batch = 18.7925s	
29417/33150 (epoch 44.370), train_loss = 0.84619894, grad/param norm = 1.9894e-01, time/batch = 18.2933s	
29418/33150 (epoch 44.371), train_loss = 0.71451536, grad/param norm = 1.6524e-01, time/batch = 16.8821s	
29419/33150 (epoch 44.373), train_loss = 0.84748421, grad/param norm = 2.4267e-01, time/batch = 18.8005s	
29420/33150 (epoch 44.374), train_loss = 0.83300999, grad/param norm = 1.6523e-01, time/batch = 17.3995s	
29421/33150 (epoch 44.376), train_loss = 0.87750308, grad/param norm = 1.5265e-01, time/batch = 16.9837s	
29422/33150 (epoch 44.377), train_loss = 0.74354354, grad/param norm = 2.0184e-01, time/batch = 18.5614s	
29423/33150 (epoch 44.379), train_loss = 0.84176136, grad/param norm = 1.9310e-01, time/batch = 17.6341s	
29424/33150 (epoch 44.380), train_loss = 0.87623359, grad/param norm = 1.6951e-01, time/batch = 22.9052s	
29425/33150 (epoch 44.382), train_loss = 0.80885750, grad/param norm = 1.7175e-01, time/batch = 24.6513s	
29426/33150 (epoch 44.383), train_loss = 0.74437796, grad/param norm = 1.6513e-01, time/batch = 17.8968s	
29427/33150 (epoch 44.385), train_loss = 0.76188462, grad/param norm = 1.8827e-01, time/batch = 16.6432s	
29428/33150 (epoch 44.386), train_loss = 0.71464554, grad/param norm = 1.4742e-01, time/batch = 16.4811s	
29429/33150 (epoch 44.388), train_loss = 0.73381993, grad/param norm = 1.6608e-01, time/batch = 15.6029s	
29430/33150 (epoch 44.389), train_loss = 0.75204681, grad/param norm = 1.6151e-01, time/batch = 15.4676s	
29431/33150 (epoch 44.391), train_loss = 0.93417973, grad/param norm = 1.9400e-01, time/batch = 14.7381s	
29432/33150 (epoch 44.392), train_loss = 0.74772145, grad/param norm = 1.6872e-01, time/batch = 16.8210s	
29433/33150 (epoch 44.394), train_loss = 0.70905734, grad/param norm = 1.6889e-01, time/batch = 17.4621s	
29434/33150 (epoch 44.395), train_loss = 0.65114990, grad/param norm = 1.5960e-01, time/batch = 16.2314s	
29435/33150 (epoch 44.397), train_loss = 0.56401231, grad/param norm = 1.5532e-01, time/batch = 17.4015s	
29436/33150 (epoch 44.398), train_loss = 0.81776610, grad/param norm = 1.7569e-01, time/batch = 17.5696s	
29437/33150 (epoch 44.400), train_loss = 0.80321181, grad/param norm = 1.6166e-01, time/batch = 18.5535s	
29438/33150 (epoch 44.401), train_loss = 0.67158007, grad/param norm = 1.4377e-01, time/batch = 15.9750s	
29439/33150 (epoch 44.403), train_loss = 0.69370385, grad/param norm = 1.6021e-01, time/batch = 16.8122s	
29440/33150 (epoch 44.404), train_loss = 0.79259569, grad/param norm = 1.6909e-01, time/batch = 19.3069s	
29441/33150 (epoch 44.406), train_loss = 0.77623370, grad/param norm = 1.6038e-01, time/batch = 16.4742s	
29442/33150 (epoch 44.407), train_loss = 0.68840713, grad/param norm = 1.6160e-01, time/batch = 18.7121s	
29443/33150 (epoch 44.409), train_loss = 0.64814190, grad/param norm = 1.6582e-01, time/batch = 15.7749s	
29444/33150 (epoch 44.410), train_loss = 0.80759086, grad/param norm = 1.7609e-01, time/batch = 18.1413s	
29445/33150 (epoch 44.412), train_loss = 0.84678157, grad/param norm = 1.6548e-01, time/batch = 15.6832s	
29446/33150 (epoch 44.413), train_loss = 0.71102556, grad/param norm = 1.6504e-01, time/batch = 15.6759s	
29447/33150 (epoch 44.415), train_loss = 0.81608775, grad/param norm = 1.7623e-01, time/batch = 18.3953s	
29448/33150 (epoch 44.416), train_loss = 0.71958799, grad/param norm = 1.5492e-01, time/batch = 16.4503s	
29449/33150 (epoch 44.418), train_loss = 0.82692283, grad/param norm = 1.9459e-01, time/batch = 17.1541s	
29450/33150 (epoch 44.419), train_loss = 0.78424160, grad/param norm = 1.8216e-01, time/batch = 17.3896s	
29451/33150 (epoch 44.421), train_loss = 0.79724444, grad/param norm = 1.8365e-01, time/batch = 18.2282s	
29452/33150 (epoch 44.422), train_loss = 0.78266313, grad/param norm = 1.7533e-01, time/batch = 16.3962s	
29453/33150 (epoch 44.424), train_loss = 0.71735510, grad/param norm = 1.7998e-01, time/batch = 17.5659s	
29454/33150 (epoch 44.425), train_loss = 0.86614289, grad/param norm = 1.6091e-01, time/batch = 17.3095s	
29455/33150 (epoch 44.427), train_loss = 0.79744073, grad/param norm = 1.5470e-01, time/batch = 17.0491s	
29456/33150 (epoch 44.428), train_loss = 0.74645847, grad/param norm = 1.7200e-01, time/batch = 18.2980s	
29457/33150 (epoch 44.430), train_loss = 0.80469343, grad/param norm = 1.8343e-01, time/batch = 17.2262s	
29458/33150 (epoch 44.431), train_loss = 0.84994780, grad/param norm = 1.8183e-01, time/batch = 17.5580s	
29459/33150 (epoch 44.433), train_loss = 0.76221079, grad/param norm = 1.6421e-01, time/batch = 16.7377s	
29460/33150 (epoch 44.434), train_loss = 0.67663460, grad/param norm = 1.6799e-01, time/batch = 17.5585s	
29461/33150 (epoch 44.436), train_loss = 0.81656002, grad/param norm = 1.5659e-01, time/batch = 17.0745s	
29462/33150 (epoch 44.437), train_loss = 0.79057144, grad/param norm = 1.9692e-01, time/batch = 17.9561s	
29463/33150 (epoch 44.439), train_loss = 0.94814079, grad/param norm = 1.6786e-01, time/batch = 18.1422s	
29464/33150 (epoch 44.440), train_loss = 0.85351894, grad/param norm = 1.8477e-01, time/batch = 18.3739s	
29465/33150 (epoch 44.442), train_loss = 0.68564051, grad/param norm = 1.8378e-01, time/batch = 17.6282s	
29466/33150 (epoch 44.443), train_loss = 0.82517790, grad/param norm = 2.0213e-01, time/batch = 17.2964s	
29467/33150 (epoch 44.445), train_loss = 0.80850117, grad/param norm = 2.1180e-01, time/batch = 19.2991s	
29468/33150 (epoch 44.446), train_loss = 0.84638043, grad/param norm = 2.5050e-01, time/batch = 16.9778s	
29469/33150 (epoch 44.448), train_loss = 0.89976265, grad/param norm = 1.8851e-01, time/batch = 16.3957s	
29470/33150 (epoch 44.449), train_loss = 0.81275369, grad/param norm = 1.6945e-01, time/batch = 18.8808s	
29471/33150 (epoch 44.451), train_loss = 0.80280369, grad/param norm = 1.9557e-01, time/batch = 19.9758s	
29472/33150 (epoch 44.452), train_loss = 0.98525413, grad/param norm = 1.9002e-01, time/batch = 16.3316s	
29473/33150 (epoch 44.454), train_loss = 0.78330156, grad/param norm = 1.6935e-01, time/batch = 19.4669s	
29474/33150 (epoch 44.456), train_loss = 0.75636219, grad/param norm = 1.7609e-01, time/batch = 18.0696s	
29475/33150 (epoch 44.457), train_loss = 0.80521505, grad/param norm = 1.9654e-01, time/batch = 17.3031s	
29476/33150 (epoch 44.459), train_loss = 0.93091489, grad/param norm = 2.7598e-01, time/batch = 15.5661s	
29477/33150 (epoch 44.460), train_loss = 0.86783822, grad/param norm = 1.7576e-01, time/batch = 17.2007s	
29478/33150 (epoch 44.462), train_loss = 0.91084078, grad/param norm = 2.1835e-01, time/batch = 16.4816s	
29479/33150 (epoch 44.463), train_loss = 1.01938595, grad/param norm = 2.3875e-01, time/batch = 16.0681s	
29480/33150 (epoch 44.465), train_loss = 0.86619249, grad/param norm = 1.7628e-01, time/batch = 16.8226s	
29481/33150 (epoch 44.466), train_loss = 0.76630611, grad/param norm = 1.6828e-01, time/batch = 17.7380s	
29482/33150 (epoch 44.468), train_loss = 1.00834169, grad/param norm = 1.9377e-01, time/batch = 17.8912s	
29483/33150 (epoch 44.469), train_loss = 0.74545722, grad/param norm = 1.7904e-01, time/batch = 15.9086s	
29484/33150 (epoch 44.471), train_loss = 0.74794426, grad/param norm = 1.5351e-01, time/batch = 16.8302s	
29485/33150 (epoch 44.472), train_loss = 0.83298991, grad/param norm = 1.6258e-01, time/batch = 18.4071s	
29486/33150 (epoch 44.474), train_loss = 0.86450374, grad/param norm = 2.4929e-01, time/batch = 17.3786s	
29487/33150 (epoch 44.475), train_loss = 1.04134635, grad/param norm = 1.9901e-01, time/batch = 18.3168s	
29488/33150 (epoch 44.477), train_loss = 0.86791136, grad/param norm = 1.9709e-01, time/batch = 18.0293s	
29489/33150 (epoch 44.478), train_loss = 0.82756131, grad/param norm = 1.7942e-01, time/batch = 16.4766s	
29490/33150 (epoch 44.480), train_loss = 0.75012676, grad/param norm = 1.9505e-01, time/batch = 16.9777s	
29491/33150 (epoch 44.481), train_loss = 0.68573235, grad/param norm = 1.6887e-01, time/batch = 17.8945s	
29492/33150 (epoch 44.483), train_loss = 0.77918434, grad/param norm = 1.7992e-01, time/batch = 19.2946s	
29493/33150 (epoch 44.484), train_loss = 0.72322715, grad/param norm = 1.8545e-01, time/batch = 16.6369s	
29494/33150 (epoch 44.486), train_loss = 0.75040960, grad/param norm = 1.7828e-01, time/batch = 15.1471s	
29495/33150 (epoch 44.487), train_loss = 0.86622636, grad/param norm = 2.1437e-01, time/batch = 15.4907s	
29496/33150 (epoch 44.489), train_loss = 0.78884335, grad/param norm = 1.9390e-01, time/batch = 16.8143s	
29497/33150 (epoch 44.490), train_loss = 0.63774772, grad/param norm = 1.4245e-01, time/batch = 18.0642s	
29498/33150 (epoch 44.492), train_loss = 0.78216022, grad/param norm = 1.8678e-01, time/batch = 17.5614s	
29499/33150 (epoch 44.493), train_loss = 0.85454877, grad/param norm = 1.7424e-01, time/batch = 18.0554s	
29500/33150 (epoch 44.495), train_loss = 0.85295705, grad/param norm = 1.8089e-01, time/batch = 15.7314s	
29501/33150 (epoch 44.496), train_loss = 0.76681457, grad/param norm = 1.5408e-01, time/batch = 18.0575s	
29502/33150 (epoch 44.498), train_loss = 0.90656809, grad/param norm = 2.7608e-01, time/batch = 17.4924s	
29503/33150 (epoch 44.499), train_loss = 0.91966372, grad/param norm = 1.8458e-01, time/batch = 17.2172s	
29504/33150 (epoch 44.501), train_loss = 0.82448549, grad/param norm = 1.9609e-01, time/batch = 18.1308s	
29505/33150 (epoch 44.502), train_loss = 0.92648519, grad/param norm = 2.1771e-01, time/batch = 16.6896s	
29506/33150 (epoch 44.504), train_loss = 0.88302004, grad/param norm = 2.1416e-01, time/batch = 15.2348s	
29507/33150 (epoch 44.505), train_loss = 0.95551673, grad/param norm = 3.2538e-01, time/batch = 16.9747s	
29508/33150 (epoch 44.507), train_loss = 0.78099954, grad/param norm = 2.0729e-01, time/batch = 17.6286s	
29509/33150 (epoch 44.508), train_loss = 0.76122734, grad/param norm = 1.6521e-01, time/batch = 18.5499s	
29510/33150 (epoch 44.510), train_loss = 0.89130391, grad/param norm = 1.5265e-01, time/batch = 16.3846s	
29511/33150 (epoch 44.511), train_loss = 0.90385000, grad/param norm = 1.9427e-01, time/batch = 17.8093s	
29512/33150 (epoch 44.513), train_loss = 0.83761775, grad/param norm = 2.1993e-01, time/batch = 18.3214s	
29513/33150 (epoch 44.514), train_loss = 0.73417465, grad/param norm = 2.7989e-01, time/batch = 17.2941s	
29514/33150 (epoch 44.516), train_loss = 0.84770031, grad/param norm = 2.7430e-01, time/batch = 18.3037s	
29515/33150 (epoch 44.517), train_loss = 0.88339358, grad/param norm = 1.8452e-01, time/batch = 15.9779s	
29516/33150 (epoch 44.519), train_loss = 0.77016634, grad/param norm = 1.8001e-01, time/batch = 17.9021s	
29517/33150 (epoch 44.520), train_loss = 0.81504296, grad/param norm = 1.6805e-01, time/batch = 16.4873s	
29518/33150 (epoch 44.522), train_loss = 0.88031833, grad/param norm = 2.1769e-01, time/batch = 15.8824s	
29519/33150 (epoch 44.523), train_loss = 0.72215670, grad/param norm = 1.7607e-01, time/batch = 17.5591s	
29520/33150 (epoch 44.525), train_loss = 0.85617412, grad/param norm = 2.1719e-01, time/batch = 17.3775s	
29521/33150 (epoch 44.526), train_loss = 0.73827903, grad/param norm = 1.8757e-01, time/batch = 16.8017s	
29522/33150 (epoch 44.528), train_loss = 0.83001384, grad/param norm = 1.7305e-01, time/batch = 16.1861s	
29523/33150 (epoch 44.529), train_loss = 0.80879975, grad/param norm = 1.8427e-01, time/batch = 15.0021s	
29524/33150 (epoch 44.531), train_loss = 0.70936164, grad/param norm = 1.9983e-01, time/batch = 14.8526s	
29525/33150 (epoch 44.532), train_loss = 0.83162926, grad/param norm = 2.1579e-01, time/batch = 14.8728s	
29526/33150 (epoch 44.534), train_loss = 0.81657746, grad/param norm = 1.7658e-01, time/batch = 14.8575s	
29527/33150 (epoch 44.535), train_loss = 0.73589844, grad/param norm = 2.3770e-01, time/batch = 15.0220s	
29528/33150 (epoch 44.537), train_loss = 0.82581257, grad/param norm = 2.2203e-01, time/batch = 15.2698s	
29529/33150 (epoch 44.538), train_loss = 0.73254867, grad/param norm = 1.6514e-01, time/batch = 18.5515s	
29530/33150 (epoch 44.540), train_loss = 0.73741847, grad/param norm = 1.9973e-01, time/batch = 17.2298s	
29531/33150 (epoch 44.541), train_loss = 0.89416149, grad/param norm = 1.9791e-01, time/batch = 16.2978s	
29532/33150 (epoch 44.543), train_loss = 0.83175571, grad/param norm = 1.9338e-01, time/batch = 16.2690s	
29533/33150 (epoch 44.544), train_loss = 0.89107734, grad/param norm = 2.1161e-01, time/batch = 15.3051s	
29534/33150 (epoch 44.546), train_loss = 0.74796174, grad/param norm = 1.8291e-01, time/batch = 15.5428s	
29535/33150 (epoch 44.548), train_loss = 0.78587591, grad/param norm = 1.9897e-01, time/batch = 16.0515s	
29536/33150 (epoch 44.549), train_loss = 0.78258138, grad/param norm = 2.7724e-01, time/batch = 18.2152s	
29537/33150 (epoch 44.551), train_loss = 0.72255167, grad/param norm = 1.5489e-01, time/batch = 18.3766s	
29538/33150 (epoch 44.552), train_loss = 0.62318124, grad/param norm = 1.3872e-01, time/batch = 18.8938s	
29539/33150 (epoch 44.554), train_loss = 0.88055239, grad/param norm = 1.9120e-01, time/batch = 16.5564s	
29540/33150 (epoch 44.555), train_loss = 0.90745772, grad/param norm = 2.0222e-01, time/batch = 17.2318s	
29541/33150 (epoch 44.557), train_loss = 0.68026126, grad/param norm = 1.7197e-01, time/batch = 19.3151s	
29542/33150 (epoch 44.558), train_loss = 0.83460427, grad/param norm = 2.2879e-01, time/batch = 17.2179s	
29543/33150 (epoch 44.560), train_loss = 0.73532769, grad/param norm = 1.6885e-01, time/batch = 16.8032s	
29544/33150 (epoch 44.561), train_loss = 0.68332068, grad/param norm = 1.8549e-01, time/batch = 16.8949s	
29545/33150 (epoch 44.563), train_loss = 0.85456440, grad/param norm = 2.1120e-01, time/batch = 17.4707s	
29546/33150 (epoch 44.564), train_loss = 0.89269847, grad/param norm = 1.6453e-01, time/batch = 16.2271s	
29547/33150 (epoch 44.566), train_loss = 0.74363843, grad/param norm = 1.7806e-01, time/batch = 16.1478s	
29548/33150 (epoch 44.567), train_loss = 0.79721394, grad/param norm = 1.9613e-01, time/batch = 15.9656s	
29549/33150 (epoch 44.569), train_loss = 0.82955654, grad/param norm = 1.9575e-01, time/batch = 16.5376s	
29550/33150 (epoch 44.570), train_loss = 0.86783539, grad/param norm = 1.6445e-01, time/batch = 15.9908s	
29551/33150 (epoch 44.572), train_loss = 0.76664166, grad/param norm = 2.0708e-01, time/batch = 18.0660s	
29552/33150 (epoch 44.573), train_loss = 0.68716312, grad/param norm = 1.3794e-01, time/batch = 18.9643s	
29553/33150 (epoch 44.575), train_loss = 0.78166686, grad/param norm = 1.9329e-01, time/batch = 16.5514s	
29554/33150 (epoch 44.576), train_loss = 0.73363036, grad/param norm = 1.7356e-01, time/batch = 17.7939s	
29555/33150 (epoch 44.578), train_loss = 0.74916920, grad/param norm = 1.7027e-01, time/batch = 18.5593s	
29556/33150 (epoch 44.579), train_loss = 0.70800594, grad/param norm = 1.6801e-01, time/batch = 16.6504s	
29557/33150 (epoch 44.581), train_loss = 0.70554889, grad/param norm = 1.9395e-01, time/batch = 16.8066s	
29558/33150 (epoch 44.582), train_loss = 0.91518541, grad/param norm = 1.7227e-01, time/batch = 18.5619s	
29559/33150 (epoch 44.584), train_loss = 0.88920210, grad/param norm = 1.9311e-01, time/batch = 15.8167s	
29560/33150 (epoch 44.585), train_loss = 0.82970740, grad/param norm = 1.8125e-01, time/batch = 15.5508s	
29561/33150 (epoch 44.587), train_loss = 0.80282092, grad/param norm = 1.6909e-01, time/batch = 17.8022s	
29562/33150 (epoch 44.588), train_loss = 0.75065018, grad/param norm = 1.8598e-01, time/batch = 17.0706s	
29563/33150 (epoch 44.590), train_loss = 0.83723795, grad/param norm = 1.9494e-01, time/batch = 16.7118s	
29564/33150 (epoch 44.591), train_loss = 0.83490701, grad/param norm = 2.2676e-01, time/batch = 17.0528s	
29565/33150 (epoch 44.593), train_loss = 0.85162747, grad/param norm = 1.9751e-01, time/batch = 18.0725s	
29566/33150 (epoch 44.594), train_loss = 0.78030160, grad/param norm = 1.9796e-01, time/batch = 16.7289s	
29567/33150 (epoch 44.596), train_loss = 0.77070855, grad/param norm = 1.7273e-01, time/batch = 16.7171s	
29568/33150 (epoch 44.597), train_loss = 0.70690688, grad/param norm = 2.6660e-01, time/batch = 17.6487s	
29569/33150 (epoch 44.599), train_loss = 0.94658532, grad/param norm = 2.1119e-01, time/batch = 18.7954s	
29570/33150 (epoch 44.600), train_loss = 0.79190368, grad/param norm = 3.2606e-01, time/batch = 15.7841s	
29571/33150 (epoch 44.602), train_loss = 0.82197908, grad/param norm = 2.2517e-01, time/batch = 15.7998s	
29572/33150 (epoch 44.603), train_loss = 0.92857107, grad/param norm = 1.7916e-01, time/batch = 16.1472s	
29573/33150 (epoch 44.605), train_loss = 0.74188391, grad/param norm = 2.0221e-01, time/batch = 17.2971s	
29574/33150 (epoch 44.606), train_loss = 0.76047890, grad/param norm = 2.2072e-01, time/batch = 15.2079s	
29575/33150 (epoch 44.608), train_loss = 0.91106464, grad/param norm = 1.7668e-01, time/batch = 14.9378s	
29576/33150 (epoch 44.609), train_loss = 0.79433339, grad/param norm = 1.8939e-01, time/batch = 16.7750s	
29577/33150 (epoch 44.611), train_loss = 0.72064761, grad/param norm = 1.9714e-01, time/batch = 15.2528s	
29578/33150 (epoch 44.612), train_loss = 0.77568462, grad/param norm = 2.0395e-01, time/batch = 15.0217s	
29579/33150 (epoch 44.614), train_loss = 0.74180689, grad/param norm = 1.6725e-01, time/batch = 15.1813s	
29580/33150 (epoch 44.615), train_loss = 0.72497720, grad/param norm = 1.9419e-01, time/batch = 15.6209s	
29581/33150 (epoch 44.617), train_loss = 0.82692604, grad/param norm = 2.0658e-01, time/batch = 17.2117s	
29582/33150 (epoch 44.618), train_loss = 0.85098009, grad/param norm = 1.9191e-01, time/batch = 17.5626s	
29583/33150 (epoch 44.620), train_loss = 0.78127556, grad/param norm = 2.2427e-01, time/batch = 16.7430s	
29584/33150 (epoch 44.621), train_loss = 0.83134687, grad/param norm = 1.7687e-01, time/batch = 16.8972s	
29585/33150 (epoch 44.623), train_loss = 0.83793674, grad/param norm = 1.5938e-01, time/batch = 15.5531s	
29586/33150 (epoch 44.624), train_loss = 0.78031953, grad/param norm = 1.7439e-01, time/batch = 16.2077s	
29587/33150 (epoch 44.626), train_loss = 0.81934642, grad/param norm = 2.0904e-01, time/batch = 18.2956s	
29588/33150 (epoch 44.627), train_loss = 0.78317039, grad/param norm = 1.9153e-01, time/batch = 18.2163s	
29589/33150 (epoch 44.629), train_loss = 0.67727664, grad/param norm = 1.6917e-01, time/batch = 18.8830s	
29590/33150 (epoch 44.630), train_loss = 0.80374619, grad/param norm = 1.6800e-01, time/batch = 17.9816s	
29591/33150 (epoch 44.632), train_loss = 0.70377434, grad/param norm = 1.5069e-01, time/batch = 18.2234s	
29592/33150 (epoch 44.633), train_loss = 0.74476714, grad/param norm = 1.8858e-01, time/batch = 18.4567s	
29593/33150 (epoch 44.635), train_loss = 0.96003808, grad/param norm = 1.9706e-01, time/batch = 18.9691s	
29594/33150 (epoch 44.637), train_loss = 0.65343923, grad/param norm = 1.7721e-01, time/batch = 19.4864s	
29595/33150 (epoch 44.638), train_loss = 0.79132941, grad/param norm = 1.9483e-01, time/batch = 16.6460s	
29596/33150 (epoch 44.640), train_loss = 0.87252617, grad/param norm = 2.1750e-01, time/batch = 19.0545s	
29597/33150 (epoch 44.641), train_loss = 0.67315060, grad/param norm = 1.6766e-01, time/batch = 16.3954s	
29598/33150 (epoch 44.643), train_loss = 0.80000318, grad/param norm = 1.6808e-01, time/batch = 16.8118s	
29599/33150 (epoch 44.644), train_loss = 0.95063191, grad/param norm = 1.6805e-01, time/batch = 16.9086s	
29600/33150 (epoch 44.646), train_loss = 0.81679469, grad/param norm = 1.5519e-01, time/batch = 18.5555s	
29601/33150 (epoch 44.647), train_loss = 0.97234439, grad/param norm = 1.8814e-01, time/batch = 19.1309s	
29602/33150 (epoch 44.649), train_loss = 0.84014586, grad/param norm = 2.4458e-01, time/batch = 15.7907s	
29603/33150 (epoch 44.650), train_loss = 0.71942344, grad/param norm = 2.0746e-01, time/batch = 17.3916s	
29604/33150 (epoch 44.652), train_loss = 0.89636978, grad/param norm = 2.3350e-01, time/batch = 16.7392s	
29605/33150 (epoch 44.653), train_loss = 0.86745338, grad/param norm = 1.6977e-01, time/batch = 16.6535s	
29606/33150 (epoch 44.655), train_loss = 0.86295748, grad/param norm = 2.1218e-01, time/batch = 17.1511s	
29607/33150 (epoch 44.656), train_loss = 0.76418159, grad/param norm = 1.5829e-01, time/batch = 17.1488s	
29608/33150 (epoch 44.658), train_loss = 0.76319272, grad/param norm = 1.8407e-01, time/batch = 16.8175s	
29609/33150 (epoch 44.659), train_loss = 0.97245517, grad/param norm = 2.7445e-01, time/batch = 16.0797s	
29610/33150 (epoch 44.661), train_loss = 0.80472514, grad/param norm = 1.9770e-01, time/batch = 18.1362s	
29611/33150 (epoch 44.662), train_loss = 0.79617067, grad/param norm = 1.8492e-01, time/batch = 15.4499s	
29612/33150 (epoch 44.664), train_loss = 0.91314035, grad/param norm = 1.9151e-01, time/batch = 15.9626s	
29613/33150 (epoch 44.665), train_loss = 0.90696271, grad/param norm = 2.1281e-01, time/batch = 18.0625s	
29614/33150 (epoch 44.667), train_loss = 0.88892676, grad/param norm = 2.1477e-01, time/batch = 17.5564s	
29615/33150 (epoch 44.668), train_loss = 0.95084469, grad/param norm = 1.9815e-01, time/batch = 18.3176s	
29616/33150 (epoch 44.670), train_loss = 0.77966669, grad/param norm = 1.7008e-01, time/batch = 17.7244s	
29617/33150 (epoch 44.671), train_loss = 0.74223211, grad/param norm = 1.8915e-01, time/batch = 17.3089s	
29618/33150 (epoch 44.673), train_loss = 0.92629656, grad/param norm = 1.7194e-01, time/batch = 19.3086s	
29619/33150 (epoch 44.674), train_loss = 0.88090437, grad/param norm = 2.0060e-01, time/batch = 17.4718s	
29620/33150 (epoch 44.676), train_loss = 0.80725632, grad/param norm = 1.7043e-01, time/batch = 15.5396s	
29621/33150 (epoch 44.677), train_loss = 0.94372431, grad/param norm = 2.2573e-01, time/batch = 17.6646s	
29622/33150 (epoch 44.679), train_loss = 0.81674413, grad/param norm = 1.8661e-01, time/batch = 18.3791s	
29623/33150 (epoch 44.680), train_loss = 0.91731450, grad/param norm = 2.6031e-01, time/batch = 18.3880s	
29624/33150 (epoch 44.682), train_loss = 0.83573260, grad/param norm = 1.8276e-01, time/batch = 16.6551s	
29625/33150 (epoch 44.683), train_loss = 0.69340343, grad/param norm = 1.5840e-01, time/batch = 17.0772s	
29626/33150 (epoch 44.685), train_loss = 0.79222442, grad/param norm = 2.2453e-01, time/batch = 16.2186s	
29627/33150 (epoch 44.686), train_loss = 0.67773850, grad/param norm = 1.6612e-01, time/batch = 17.8912s	
29628/33150 (epoch 44.688), train_loss = 0.72973631, grad/param norm = 2.2509e-01, time/batch = 16.9800s	
29629/33150 (epoch 44.689), train_loss = 0.72745094, grad/param norm = 1.5952e-01, time/batch = 18.2883s	
29630/33150 (epoch 44.691), train_loss = 0.61933827, grad/param norm = 1.4215e-01, time/batch = 19.5500s	
29631/33150 (epoch 44.692), train_loss = 0.71513935, grad/param norm = 1.5528e-01, time/batch = 16.8013s	
29632/33150 (epoch 44.694), train_loss = 0.65609554, grad/param norm = 1.8190e-01, time/batch = 20.9318s	
29633/33150 (epoch 44.695), train_loss = 0.73083046, grad/param norm = 1.6592e-01, time/batch = 26.4044s	
29634/33150 (epoch 44.697), train_loss = 0.70521112, grad/param norm = 1.6109e-01, time/batch = 15.5587s	
29635/33150 (epoch 44.698), train_loss = 0.70820433, grad/param norm = 1.9524e-01, time/batch = 16.7117s	
29636/33150 (epoch 44.700), train_loss = 0.62476840, grad/param norm = 1.5055e-01, time/batch = 16.8816s	
29637/33150 (epoch 44.701), train_loss = 0.69063806, grad/param norm = 1.5611e-01, time/batch = 17.3179s	
29638/33150 (epoch 44.703), train_loss = 0.79794463, grad/param norm = 1.7961e-01, time/batch = 17.2147s	
29639/33150 (epoch 44.704), train_loss = 0.67433722, grad/param norm = 1.5007e-01, time/batch = 15.1695s	
29640/33150 (epoch 44.706), train_loss = 0.74527704, grad/param norm = 1.7208e-01, time/batch = 14.8704s	
29641/33150 (epoch 44.707), train_loss = 0.76919455, grad/param norm = 1.7031e-01, time/batch = 15.3791s	
29642/33150 (epoch 44.709), train_loss = 0.80374838, grad/param norm = 1.6853e-01, time/batch = 15.2096s	
29643/33150 (epoch 44.710), train_loss = 0.79445579, grad/param norm = 2.0705e-01, time/batch = 16.3880s	
29644/33150 (epoch 44.712), train_loss = 0.88157513, grad/param norm = 1.8552e-01, time/batch = 17.8014s	
29645/33150 (epoch 44.713), train_loss = 0.82441679, grad/param norm = 1.6920e-01, time/batch = 16.6551s	
29646/33150 (epoch 44.715), train_loss = 0.76576607, grad/param norm = 1.5420e-01, time/batch = 18.1288s	
29647/33150 (epoch 44.716), train_loss = 0.83174350, grad/param norm = 1.7909e-01, time/batch = 16.8942s	
29648/33150 (epoch 44.718), train_loss = 0.79491899, grad/param norm = 1.7559e-01, time/batch = 18.4804s	
29649/33150 (epoch 44.719), train_loss = 0.88114892, grad/param norm = 2.2861e-01, time/batch = 18.8922s	
29650/33150 (epoch 44.721), train_loss = 0.77159357, grad/param norm = 1.9414e-01, time/batch = 17.3739s	
29651/33150 (epoch 44.722), train_loss = 0.83624143, grad/param norm = 1.6732e-01, time/batch = 18.6206s	
29652/33150 (epoch 44.724), train_loss = 0.75829970, grad/param norm = 1.9959e-01, time/batch = 17.4864s	
29653/33150 (epoch 44.725), train_loss = 0.85107249, grad/param norm = 2.2258e-01, time/batch = 17.1307s	
29654/33150 (epoch 44.727), train_loss = 0.84884992, grad/param norm = 2.2625e-01, time/batch = 16.9401s	
29655/33150 (epoch 44.729), train_loss = 0.80510228, grad/param norm = 1.8947e-01, time/batch = 19.8723s	
29656/33150 (epoch 44.730), train_loss = 0.81191193, grad/param norm = 1.7718e-01, time/batch = 18.2187s	
29657/33150 (epoch 44.732), train_loss = 0.86045889, grad/param norm = 1.9052e-01, time/batch = 17.7905s	
29658/33150 (epoch 44.733), train_loss = 0.71286131, grad/param norm = 1.4565e-01, time/batch = 20.2965s	
29659/33150 (epoch 44.735), train_loss = 0.73842975, grad/param norm = 1.8006e-01, time/batch = 18.1464s	
29660/33150 (epoch 44.736), train_loss = 0.74459173, grad/param norm = 1.7887e-01, time/batch = 16.2437s	
29661/33150 (epoch 44.738), train_loss = 0.80396181, grad/param norm = 2.1694e-01, time/batch = 18.1547s	
29662/33150 (epoch 44.739), train_loss = 0.87840555, grad/param norm = 1.9176e-01, time/batch = 16.8208s	
29663/33150 (epoch 44.741), train_loss = 0.81844008, grad/param norm = 2.4010e-01, time/batch = 15.6487s	
29664/33150 (epoch 44.742), train_loss = 0.68842767, grad/param norm = 1.9465e-01, time/batch = 16.6519s	
29665/33150 (epoch 44.744), train_loss = 0.84697533, grad/param norm = 1.7196e-01, time/batch = 18.0789s	
29666/33150 (epoch 44.745), train_loss = 0.74768107, grad/param norm = 1.7387e-01, time/batch = 17.5467s	
29667/33150 (epoch 44.747), train_loss = 0.58639436, grad/param norm = 1.5920e-01, time/batch = 17.9012s	
29668/33150 (epoch 44.748), train_loss = 0.68310759, grad/param norm = 1.9158e-01, time/batch = 16.5380s	
29669/33150 (epoch 44.750), train_loss = 0.80617559, grad/param norm = 1.9054e-01, time/batch = 15.5528s	
29670/33150 (epoch 44.751), train_loss = 0.77440480, grad/param norm = 1.6496e-01, time/batch = 16.8839s	
29671/33150 (epoch 44.753), train_loss = 0.69379431, grad/param norm = 1.9428e-01, time/batch = 17.9703s	
29672/33150 (epoch 44.754), train_loss = 0.97317258, grad/param norm = 2.2088e-01, time/batch = 16.1603s	
29673/33150 (epoch 44.756), train_loss = 0.80142702, grad/param norm = 2.4265e-01, time/batch = 17.5546s	
29674/33150 (epoch 44.757), train_loss = 0.83355137, grad/param norm = 1.8089e-01, time/batch = 17.7172s	
29675/33150 (epoch 44.759), train_loss = 0.92159706, grad/param norm = 2.5137e-01, time/batch = 18.7219s	
29676/33150 (epoch 44.760), train_loss = 0.85538807, grad/param norm = 1.9900e-01, time/batch = 19.2218s	
29677/33150 (epoch 44.762), train_loss = 0.81747785, grad/param norm = 2.0444e-01, time/batch = 17.3760s	
29678/33150 (epoch 44.763), train_loss = 0.84060681, grad/param norm = 2.0872e-01, time/batch = 19.7976s	
29679/33150 (epoch 44.765), train_loss = 0.78445302, grad/param norm = 1.7960e-01, time/batch = 17.9738s	
29680/33150 (epoch 44.766), train_loss = 0.67247258, grad/param norm = 1.8384e-01, time/batch = 17.3923s	
29681/33150 (epoch 44.768), train_loss = 0.73884810, grad/param norm = 1.9067e-01, time/batch = 16.9921s	
29682/33150 (epoch 44.769), train_loss = 0.88653239, grad/param norm = 1.8449e-01, time/batch = 17.8191s	
29683/33150 (epoch 44.771), train_loss = 0.84216468, grad/param norm = 2.0205e-01, time/batch = 17.0620s	
29684/33150 (epoch 44.772), train_loss = 0.82958392, grad/param norm = 1.9953e-01, time/batch = 15.3900s	
29685/33150 (epoch 44.774), train_loss = 0.93905617, grad/param norm = 1.8465e-01, time/batch = 17.1481s	
29686/33150 (epoch 44.775), train_loss = 0.84671908, grad/param norm = 2.3085e-01, time/batch = 16.0517s	
29687/33150 (epoch 44.777), train_loss = 0.85755340, grad/param norm = 2.0291e-01, time/batch = 15.3084s	
29688/33150 (epoch 44.778), train_loss = 0.78559360, grad/param norm = 1.6362e-01, time/batch = 15.3370s	
29689/33150 (epoch 44.780), train_loss = 0.69889134, grad/param norm = 1.7372e-01, time/batch = 15.3141s	
29690/33150 (epoch 44.781), train_loss = 0.78785021, grad/param norm = 1.7952e-01, time/batch = 15.1576s	
29691/33150 (epoch 44.783), train_loss = 0.79160291, grad/param norm = 1.7100e-01, time/batch = 16.1320s	
29692/33150 (epoch 44.784), train_loss = 0.80164955, grad/param norm = 1.9659e-01, time/batch = 16.1428s	
29693/33150 (epoch 44.786), train_loss = 0.77498783, grad/param norm = 1.7131e-01, time/batch = 19.3834s	
29694/33150 (epoch 44.787), train_loss = 0.72202498, grad/param norm = 1.6236e-01, time/batch = 18.4660s	
29695/33150 (epoch 44.789), train_loss = 0.68709626, grad/param norm = 1.4521e-01, time/batch = 17.4462s	
29696/33150 (epoch 44.790), train_loss = 0.68785515, grad/param norm = 1.7011e-01, time/batch = 18.3918s	
29697/33150 (epoch 44.792), train_loss = 0.78323009, grad/param norm = 1.9359e-01, time/batch = 19.5449s	
29698/33150 (epoch 44.793), train_loss = 0.75738538, grad/param norm = 1.9937e-01, time/batch = 17.6058s	
29699/33150 (epoch 44.795), train_loss = 0.76677536, grad/param norm = 1.8018e-01, time/batch = 18.2935s	
29700/33150 (epoch 44.796), train_loss = 0.77127686, grad/param norm = 1.6307e-01, time/batch = 20.0322s	
29701/33150 (epoch 44.798), train_loss = 0.74057026, grad/param norm = 1.6171e-01, time/batch = 16.6363s	
29702/33150 (epoch 44.799), train_loss = 0.66201915, grad/param norm = 1.8180e-01, time/batch = 18.3686s	
29703/33150 (epoch 44.801), train_loss = 0.79586936, grad/param norm = 2.0318e-01, time/batch = 17.7965s	
29704/33150 (epoch 44.802), train_loss = 0.76468663, grad/param norm = 1.9116e-01, time/batch = 18.2159s	
29705/33150 (epoch 44.804), train_loss = 0.74585319, grad/param norm = 1.7741e-01, time/batch = 18.1358s	
29706/33150 (epoch 44.805), train_loss = 0.71883470, grad/param norm = 1.8914e-01, time/batch = 15.9087s	
29707/33150 (epoch 44.807), train_loss = 0.78206418, grad/param norm = 1.8320e-01, time/batch = 16.2465s	
29708/33150 (epoch 44.808), train_loss = 0.85802784, grad/param norm = 1.9727e-01, time/batch = 17.2215s	
29709/33150 (epoch 44.810), train_loss = 0.70056413, grad/param norm = 1.6027e-01, time/batch = 16.4667s	
29710/33150 (epoch 44.811), train_loss = 0.79611215, grad/param norm = 1.9457e-01, time/batch = 18.7238s	
29711/33150 (epoch 44.813), train_loss = 0.76144785, grad/param norm = 1.8796e-01, time/batch = 15.8971s	
29712/33150 (epoch 44.814), train_loss = 0.73904373, grad/param norm = 2.1357e-01, time/batch = 18.3662s	
29713/33150 (epoch 44.816), train_loss = 0.74476130, grad/param norm = 1.9289e-01, time/batch = 16.7308s	
29714/33150 (epoch 44.817), train_loss = 0.83786916, grad/param norm = 1.8000e-01, time/batch = 17.0523s	
29715/33150 (epoch 44.819), train_loss = 0.80113265, grad/param norm = 1.7590e-01, time/batch = 17.2737s	
29716/33150 (epoch 44.821), train_loss = 0.72040435, grad/param norm = 1.6226e-01, time/batch = 19.0569s	
29717/33150 (epoch 44.822), train_loss = 0.74773425, grad/param norm = 1.8809e-01, time/batch = 19.5406s	
29718/33150 (epoch 44.824), train_loss = 0.81562704, grad/param norm = 1.7809e-01, time/batch = 16.2243s	
29719/33150 (epoch 44.825), train_loss = 0.82660183, grad/param norm = 1.9318e-01, time/batch = 18.8193s	
29720/33150 (epoch 44.827), train_loss = 0.84329352, grad/param norm = 2.1117e-01, time/batch = 15.9110s	
29721/33150 (epoch 44.828), train_loss = 0.72990637, grad/param norm = 2.6151e-01, time/batch = 18.4677s	
29722/33150 (epoch 44.830), train_loss = 0.85142691, grad/param norm = 2.1877e-01, time/batch = 16.9780s	
29723/33150 (epoch 44.831), train_loss = 0.73727550, grad/param norm = 1.9076e-01, time/batch = 18.2940s	
29724/33150 (epoch 44.833), train_loss = 0.70757395, grad/param norm = 1.7288e-01, time/batch = 17.5636s	
29725/33150 (epoch 44.834), train_loss = 0.86952380, grad/param norm = 1.7898e-01, time/batch = 16.7217s	
29726/33150 (epoch 44.836), train_loss = 0.90610889, grad/param norm = 1.8292e-01, time/batch = 17.0411s	
29727/33150 (epoch 44.837), train_loss = 0.72096955, grad/param norm = 1.8346e-01, time/batch = 17.0637s	
29728/33150 (epoch 44.839), train_loss = 0.85601832, grad/param norm = 2.0555e-01, time/batch = 17.2154s	
29729/33150 (epoch 44.840), train_loss = 0.83962888, grad/param norm = 1.8989e-01, time/batch = 16.3251s	
29730/33150 (epoch 44.842), train_loss = 0.88140622, grad/param norm = 2.1875e-01, time/batch = 16.9090s	
29731/33150 (epoch 44.843), train_loss = 0.88224503, grad/param norm = 1.9034e-01, time/batch = 16.6550s	
29732/33150 (epoch 44.845), train_loss = 0.75944823, grad/param norm = 1.7935e-01, time/batch = 15.8809s	
29733/33150 (epoch 44.846), train_loss = 0.95161220, grad/param norm = 2.6239e-01, time/batch = 16.5066s	
29734/33150 (epoch 44.848), train_loss = 0.86907164, grad/param norm = 2.1110e-01, time/batch = 17.0633s	
29735/33150 (epoch 44.849), train_loss = 0.87401805, grad/param norm = 1.7883e-01, time/batch = 16.9752s	
29736/33150 (epoch 44.851), train_loss = 0.86264165, grad/param norm = 1.9036e-01, time/batch = 18.1332s	
29737/33150 (epoch 44.852), train_loss = 0.92462869, grad/param norm = 1.7740e-01, time/batch = 18.3152s	
29738/33150 (epoch 44.854), train_loss = 0.84047425, grad/param norm = 1.8864e-01, time/batch = 16.9774s	
29739/33150 (epoch 44.855), train_loss = 0.73851558, grad/param norm = 1.6145e-01, time/batch = 16.4685s	
29740/33150 (epoch 44.857), train_loss = 0.67167369, grad/param norm = 1.7441e-01, time/batch = 16.7955s	
29741/33150 (epoch 44.858), train_loss = 0.76647689, grad/param norm = 1.7273e-01, time/batch = 15.9093s	
29742/33150 (epoch 44.860), train_loss = 0.73769628, grad/param norm = 1.6513e-01, time/batch = 16.5640s	
29743/33150 (epoch 44.861), train_loss = 0.70077419, grad/param norm = 1.5974e-01, time/batch = 17.0818s	
29744/33150 (epoch 44.863), train_loss = 0.77474051, grad/param norm = 1.8326e-01, time/batch = 16.1550s	
29745/33150 (epoch 44.864), train_loss = 0.80549668, grad/param norm = 1.7622e-01, time/batch = 18.0610s	
29746/33150 (epoch 44.866), train_loss = 0.86922683, grad/param norm = 1.7723e-01, time/batch = 16.5617s	
29747/33150 (epoch 44.867), train_loss = 0.79465484, grad/param norm = 1.7013e-01, time/batch = 17.8187s	
29748/33150 (epoch 44.869), train_loss = 0.82208407, grad/param norm = 2.3620e-01, time/batch = 18.6397s	
29749/33150 (epoch 44.870), train_loss = 0.77903942, grad/param norm = 2.0056e-01, time/batch = 15.4754s	
29750/33150 (epoch 44.872), train_loss = 0.84931838, grad/param norm = 1.9671e-01, time/batch = 17.1421s	
29751/33150 (epoch 44.873), train_loss = 0.67094170, grad/param norm = 1.5910e-01, time/batch = 18.7977s	
29752/33150 (epoch 44.875), train_loss = 0.90564690, grad/param norm = 1.9736e-01, time/batch = 19.7985s	
29753/33150 (epoch 44.876), train_loss = 0.65674758, grad/param norm = 1.7426e-01, time/batch = 16.1236s	
29754/33150 (epoch 44.878), train_loss = 0.72780304, grad/param norm = 1.5103e-01, time/batch = 17.8024s	
29755/33150 (epoch 44.879), train_loss = 0.73763690, grad/param norm = 1.7342e-01, time/batch = 17.3088s	
29756/33150 (epoch 44.881), train_loss = 0.73742377, grad/param norm = 1.7299e-01, time/batch = 17.2241s	
29757/33150 (epoch 44.882), train_loss = 0.60954835, grad/param norm = 1.6406e-01, time/batch = 17.9848s	
29758/33150 (epoch 44.884), train_loss = 0.73441139, grad/param norm = 1.6353e-01, time/batch = 18.5548s	
29759/33150 (epoch 44.885), train_loss = 0.60574594, grad/param norm = 1.6914e-01, time/batch = 17.3881s	
29760/33150 (epoch 44.887), train_loss = 0.86104964, grad/param norm = 1.9554e-01, time/batch = 16.4018s	
29761/33150 (epoch 44.888), train_loss = 0.79088881, grad/param norm = 1.7193e-01, time/batch = 18.0648s	
29762/33150 (epoch 44.890), train_loss = 0.69555005, grad/param norm = 1.8958e-01, time/batch = 19.3094s	
29763/33150 (epoch 44.891), train_loss = 0.70101851, grad/param norm = 1.8816e-01, time/batch = 16.7113s	
29764/33150 (epoch 44.893), train_loss = 0.82325060, grad/param norm = 1.8596e-01, time/batch = 17.1518s	
29765/33150 (epoch 44.894), train_loss = 0.81000072, grad/param norm = 1.6093e-01, time/batch = 18.2305s	
29766/33150 (epoch 44.896), train_loss = 0.77679034, grad/param norm = 1.7353e-01, time/batch = 16.5412s	
29767/33150 (epoch 44.897), train_loss = 0.83942324, grad/param norm = 1.7221e-01, time/batch = 18.5526s	
29768/33150 (epoch 44.899), train_loss = 0.65680822, grad/param norm = 2.2751e-01, time/batch = 19.2976s	
29769/33150 (epoch 44.900), train_loss = 0.95187528, grad/param norm = 2.1293e-01, time/batch = 17.3305s	
29770/33150 (epoch 44.902), train_loss = 0.99417377, grad/param norm = 1.9057e-01, time/batch = 16.2242s	
29771/33150 (epoch 44.903), train_loss = 0.81911668, grad/param norm = 1.8312e-01, time/batch = 18.3014s	
29772/33150 (epoch 44.905), train_loss = 0.78905004, grad/param norm = 1.6756e-01, time/batch = 15.3004s	
29773/33150 (epoch 44.906), train_loss = 0.81019686, grad/param norm = 2.0461e-01, time/batch = 17.4668s	
29774/33150 (epoch 44.908), train_loss = 0.84262682, grad/param norm = 2.0092e-01, time/batch = 15.8111s	
29775/33150 (epoch 44.910), train_loss = 0.88528900, grad/param norm = 2.1793e-01, time/batch = 16.1476s	
29776/33150 (epoch 44.911), train_loss = 0.69254205, grad/param norm = 1.6977e-01, time/batch = 16.8085s	
29777/33150 (epoch 44.913), train_loss = 0.74854008, grad/param norm = 1.8294e-01, time/batch = 15.2930s	
29778/33150 (epoch 44.914), train_loss = 0.79542236, grad/param norm = 1.8519e-01, time/batch = 17.3717s	
29779/33150 (epoch 44.916), train_loss = 0.72966764, grad/param norm = 1.8674e-01, time/batch = 17.3820s	
29780/33150 (epoch 44.917), train_loss = 0.80466731, grad/param norm = 1.9377e-01, time/batch = 15.5513s	
29781/33150 (epoch 44.919), train_loss = 0.92227213, grad/param norm = 3.2504e-01, time/batch = 16.9026s	
29782/33150 (epoch 44.920), train_loss = 0.90880859, grad/param norm = 2.1799e-01, time/batch = 18.7088s	
29783/33150 (epoch 44.922), train_loss = 0.90649166, grad/param norm = 2.2041e-01, time/batch = 18.3883s	
29784/33150 (epoch 44.923), train_loss = 0.83110927, grad/param norm = 2.1089e-01, time/batch = 17.1432s	
29785/33150 (epoch 44.925), train_loss = 0.89408155, grad/param norm = 1.9297e-01, time/batch = 17.1464s	
29786/33150 (epoch 44.926), train_loss = 0.81001773, grad/param norm = 2.0658e-01, time/batch = 17.4751s	
29787/33150 (epoch 44.928), train_loss = 0.79130289, grad/param norm = 1.9662e-01, time/batch = 14.9682s	
29788/33150 (epoch 44.929), train_loss = 0.83965300, grad/param norm = 1.7505e-01, time/batch = 16.5831s	
29789/33150 (epoch 44.931), train_loss = 0.88316584, grad/param norm = 1.9057e-01, time/batch = 17.7354s	
29790/33150 (epoch 44.932), train_loss = 0.81940867, grad/param norm = 2.0779e-01, time/batch = 15.9705s	
29791/33150 (epoch 44.934), train_loss = 0.81760095, grad/param norm = 1.6762e-01, time/batch = 16.4760s	
29792/33150 (epoch 44.935), train_loss = 0.88378292, grad/param norm = 1.9399e-01, time/batch = 16.0586s	
29793/33150 (epoch 44.937), train_loss = 0.91585453, grad/param norm = 1.7777e-01, time/batch = 16.9860s	
29794/33150 (epoch 44.938), train_loss = 0.82601899, grad/param norm = 1.7720e-01, time/batch = 17.0390s	
29795/33150 (epoch 44.940), train_loss = 1.01996094, grad/param norm = 2.0751e-01, time/batch = 16.1219s	
29796/33150 (epoch 44.941), train_loss = 0.86403094, grad/param norm = 1.7920e-01, time/batch = 17.2323s	
29797/33150 (epoch 44.943), train_loss = 0.67261587, grad/param norm = 1.7549e-01, time/batch = 16.3811s	
29798/33150 (epoch 44.944), train_loss = 0.85461852, grad/param norm = 1.9011e-01, time/batch = 17.7090s	
29799/33150 (epoch 44.946), train_loss = 0.70307806, grad/param norm = 1.4979e-01, time/batch = 17.2193s	
29800/33150 (epoch 44.947), train_loss = 0.83440105, grad/param norm = 1.8591e-01, time/batch = 17.7954s	
29801/33150 (epoch 44.949), train_loss = 0.87728245, grad/param norm = 1.7455e-01, time/batch = 18.2811s	
29802/33150 (epoch 44.950), train_loss = 0.88922081, grad/param norm = 1.8961e-01, time/batch = 17.0877s	
29803/33150 (epoch 44.952), train_loss = 0.74417514, grad/param norm = 1.6571e-01, time/batch = 17.6460s	
29804/33150 (epoch 44.953), train_loss = 0.81455540, grad/param norm = 1.6550e-01, time/batch = 16.6198s	
29805/33150 (epoch 44.955), train_loss = 0.68469098, grad/param norm = 2.0103e-01, time/batch = 15.4673s	
29806/33150 (epoch 44.956), train_loss = 0.85701359, grad/param norm = 1.9397e-01, time/batch = 17.4737s	
29807/33150 (epoch 44.958), train_loss = 0.73877983, grad/param norm = 1.7092e-01, time/batch = 15.4160s	
29808/33150 (epoch 44.959), train_loss = 0.79351607, grad/param norm = 1.9941e-01, time/batch = 17.2993s	
29809/33150 (epoch 44.961), train_loss = 0.73607960, grad/param norm = 1.8229e-01, time/batch = 15.4547s	
29810/33150 (epoch 44.962), train_loss = 0.67928717, grad/param norm = 1.7141e-01, time/batch = 15.1193s	
29811/33150 (epoch 44.964), train_loss = 0.78801748, grad/param norm = 1.7965e-01, time/batch = 15.6269s	
29812/33150 (epoch 44.965), train_loss = 0.77509564, grad/param norm = 1.6863e-01, time/batch = 15.1085s	
29813/33150 (epoch 44.967), train_loss = 0.77996944, grad/param norm = 2.0149e-01, time/batch = 14.6273s	
29814/33150 (epoch 44.968), train_loss = 0.67376515, grad/param norm = 1.4711e-01, time/batch = 15.6953s	
29815/33150 (epoch 44.970), train_loss = 0.76510703, grad/param norm = 1.7985e-01, time/batch = 14.9892s	
29816/33150 (epoch 44.971), train_loss = 0.79921664, grad/param norm = 1.8195e-01, time/batch = 15.3414s	
29817/33150 (epoch 44.973), train_loss = 0.87330101, grad/param norm = 1.7954e-01, time/batch = 16.0960s	
29818/33150 (epoch 44.974), train_loss = 0.90023484, grad/param norm = 1.8294e-01, time/batch = 15.1569s	
29819/33150 (epoch 44.976), train_loss = 0.88618669, grad/param norm = 1.8905e-01, time/batch = 15.5842s	
29820/33150 (epoch 44.977), train_loss = 0.91515673, grad/param norm = 1.9440e-01, time/batch = 15.3214s	
29821/33150 (epoch 44.979), train_loss = 0.89075504, grad/param norm = 2.2756e-01, time/batch = 15.4092s	
29822/33150 (epoch 44.980), train_loss = 0.94115378, grad/param norm = 2.1049e-01, time/batch = 15.2412s	
29823/33150 (epoch 44.982), train_loss = 0.80819182, grad/param norm = 1.9910e-01, time/batch = 15.4060s	
29824/33150 (epoch 44.983), train_loss = 0.72577472, grad/param norm = 1.7378e-01, time/batch = 15.5042s	
29825/33150 (epoch 44.985), train_loss = 0.91444803, grad/param norm = 1.7689e-01, time/batch = 15.2686s	
29826/33150 (epoch 44.986), train_loss = 0.68647972, grad/param norm = 1.6315e-01, time/batch = 15.2531s	
29827/33150 (epoch 44.988), train_loss = 0.76289304, grad/param norm = 1.9839e-01, time/batch = 15.1772s	
29828/33150 (epoch 44.989), train_loss = 0.79607910, grad/param norm = 1.7361e-01, time/batch = 16.5403s	
29829/33150 (epoch 44.991), train_loss = 0.82050930, grad/param norm = 2.4074e-01, time/batch = 15.1313s	
29830/33150 (epoch 44.992), train_loss = 0.79550945, grad/param norm = 1.9928e-01, time/batch = 17.5570s	
29831/33150 (epoch 44.994), train_loss = 0.81570629, grad/param norm = 1.6957e-01, time/batch = 17.2294s	
29832/33150 (epoch 44.995), train_loss = 0.79580897, grad/param norm = 2.2952e-01, time/batch = 16.3915s	
29833/33150 (epoch 44.997), train_loss = 0.80303551, grad/param norm = 1.8156e-01, time/batch = 16.9654s	
29834/33150 (epoch 44.998), train_loss = 0.68129953, grad/param norm = 1.6264e-01, time/batch = 17.7348s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
29835/33150 (epoch 45.000), train_loss = 0.72328647, grad/param norm = 2.2782e-01, time/batch = 15.8145s	
29836/33150 (epoch 45.002), train_loss = 1.07900555, grad/param norm = 1.9830e-01, time/batch = 17.4852s	
29837/33150 (epoch 45.003), train_loss = 0.72941015, grad/param norm = 1.7831e-01, time/batch = 16.6374s	
29838/33150 (epoch 45.005), train_loss = 0.70352328, grad/param norm = 1.6787e-01, time/batch = 18.1461s	
29839/33150 (epoch 45.006), train_loss = 0.67789534, grad/param norm = 1.7572e-01, time/batch = 15.7056s	
29840/33150 (epoch 45.008), train_loss = 0.86791064, grad/param norm = 2.0597e-01, time/batch = 16.3951s	
29841/33150 (epoch 45.009), train_loss = 0.82890218, grad/param norm = 1.7254e-01, time/batch = 19.5488s	
29842/33150 (epoch 45.011), train_loss = 0.87886559, grad/param norm = 1.8164e-01, time/batch = 27.7019s	
29843/33150 (epoch 45.012), train_loss = 0.75356193, grad/param norm = 2.0554e-01, time/batch = 20.5151s	
29844/33150 (epoch 45.014), train_loss = 0.73377648, grad/param norm = 1.9276e-01, time/batch = 15.0810s	
29845/33150 (epoch 45.015), train_loss = 0.72875384, grad/param norm = 1.9034e-01, time/batch = 14.8939s	
29846/33150 (epoch 45.017), train_loss = 0.70533750, grad/param norm = 1.7081e-01, time/batch = 15.1632s	
29847/33150 (epoch 45.018), train_loss = 0.80741038, grad/param norm = 1.9729e-01, time/batch = 15.1935s	
29848/33150 (epoch 45.020), train_loss = 0.85671175, grad/param norm = 1.9082e-01, time/batch = 15.5736s	
29849/33150 (epoch 45.021), train_loss = 0.73178486, grad/param norm = 1.6535e-01, time/batch = 15.4047s	
29850/33150 (epoch 45.023), train_loss = 0.96088185, grad/param norm = 1.7608e-01, time/batch = 15.1088s	
29851/33150 (epoch 45.024), train_loss = 0.84847087, grad/param norm = 2.1187e-01, time/batch = 14.9738s	
29852/33150 (epoch 45.026), train_loss = 0.62263263, grad/param norm = 1.7372e-01, time/batch = 15.8324s	
29853/33150 (epoch 45.027), train_loss = 0.64820844, grad/param norm = 1.4986e-01, time/batch = 16.0433s	
29854/33150 (epoch 45.029), train_loss = 0.74082956, grad/param norm = 2.1845e-01, time/batch = 19.2277s	
29855/33150 (epoch 45.030), train_loss = 0.78341466, grad/param norm = 1.4945e-01, time/batch = 18.4722s	
29856/33150 (epoch 45.032), train_loss = 0.69345514, grad/param norm = 1.8740e-01, time/batch = 15.9776s	
29857/33150 (epoch 45.033), train_loss = 0.72651872, grad/param norm = 1.7961e-01, time/batch = 17.8969s	
29858/33150 (epoch 45.035), train_loss = 0.93457483, grad/param norm = 2.0717e-01, time/batch = 17.2184s	
29859/33150 (epoch 45.036), train_loss = 0.87380320, grad/param norm = 1.9854e-01, time/batch = 17.7993s	
29860/33150 (epoch 45.038), train_loss = 0.97318262, grad/param norm = 1.9567e-01, time/batch = 16.7200s	
29861/33150 (epoch 45.039), train_loss = 0.85391740, grad/param norm = 1.6362e-01, time/batch = 17.2448s	
29862/33150 (epoch 45.041), train_loss = 0.78795429, grad/param norm = 1.6880e-01, time/batch = 17.0500s	
29863/33150 (epoch 45.042), train_loss = 0.72907771, grad/param norm = 1.7112e-01, time/batch = 15.9041s	
29864/33150 (epoch 45.044), train_loss = 0.79855464, grad/param norm = 1.8560e-01, time/batch = 17.3843s	
29865/33150 (epoch 45.045), train_loss = 0.86831288, grad/param norm = 1.5793e-01, time/batch = 17.3196s	
29866/33150 (epoch 45.047), train_loss = 0.73068746, grad/param norm = 2.0512e-01, time/batch = 17.1964s	
29867/33150 (epoch 45.048), train_loss = 0.84572499, grad/param norm = 2.1397e-01, time/batch = 16.7069s	
29868/33150 (epoch 45.050), train_loss = 0.75946068, grad/param norm = 1.7408e-01, time/batch = 17.1452s	
29869/33150 (epoch 45.051), train_loss = 0.83213664, grad/param norm = 1.7303e-01, time/batch = 19.2977s	
29870/33150 (epoch 45.053), train_loss = 0.83337721, grad/param norm = 1.6873e-01, time/batch = 15.7422s	
29871/33150 (epoch 45.054), train_loss = 0.93975122, grad/param norm = 1.8611e-01, time/batch = 16.4759s	
29872/33150 (epoch 45.056), train_loss = 0.77910281, grad/param norm = 1.7403e-01, time/batch = 16.9824s	
29873/33150 (epoch 45.057), train_loss = 0.86081096, grad/param norm = 1.7543e-01, time/batch = 15.4042s	
29874/33150 (epoch 45.059), train_loss = 0.72356596, grad/param norm = 1.7580e-01, time/batch = 15.4801s	
29875/33150 (epoch 45.060), train_loss = 0.70347086, grad/param norm = 1.4699e-01, time/batch = 18.3084s	
29876/33150 (epoch 45.062), train_loss = 0.78907032, grad/param norm = 1.8228e-01, time/batch = 15.5712s	
29877/33150 (epoch 45.063), train_loss = 0.73706594, grad/param norm = 1.8479e-01, time/batch = 16.6421s	
29878/33150 (epoch 45.065), train_loss = 0.79923524, grad/param norm = 1.6722e-01, time/batch = 16.3060s	
29879/33150 (epoch 45.066), train_loss = 0.77411504, grad/param norm = 1.8021e-01, time/batch = 17.0551s	
29880/33150 (epoch 45.068), train_loss = 0.84209507, grad/param norm = 1.9294e-01, time/batch = 17.2262s	
29881/33150 (epoch 45.069), train_loss = 0.84326387, grad/param norm = 2.1938e-01, time/batch = 16.4692s	
29882/33150 (epoch 45.071), train_loss = 0.83298299, grad/param norm = 1.9561e-01, time/batch = 17.2971s	
29883/33150 (epoch 45.072), train_loss = 0.82759645, grad/param norm = 2.1408e-01, time/batch = 17.4025s	
29884/33150 (epoch 45.074), train_loss = 0.67586308, grad/param norm = 1.8247e-01, time/batch = 16.2302s	
29885/33150 (epoch 45.075), train_loss = 0.69971169, grad/param norm = 1.7888e-01, time/batch = 15.8786s	
29886/33150 (epoch 45.077), train_loss = 0.83606878, grad/param norm = 2.9642e-01, time/batch = 17.8944s	
29887/33150 (epoch 45.078), train_loss = 0.92415354, grad/param norm = 2.1975e-01, time/batch = 15.3721s	
29888/33150 (epoch 45.080), train_loss = 0.91230371, grad/param norm = 1.7234e-01, time/batch = 16.2175s	
29889/33150 (epoch 45.081), train_loss = 0.72242918, grad/param norm = 1.9776e-01, time/batch = 18.0570s	
29890/33150 (epoch 45.083), train_loss = 0.57743163, grad/param norm = 2.0840e-01, time/batch = 17.1421s	
29891/33150 (epoch 45.084), train_loss = 0.67745130, grad/param norm = 1.8980e-01, time/batch = 17.5495s	
29892/33150 (epoch 45.086), train_loss = 0.74844801, grad/param norm = 2.2441e-01, time/batch = 14.9151s	
29893/33150 (epoch 45.087), train_loss = 0.68110656, grad/param norm = 1.9100e-01, time/batch = 14.8350s	
29894/33150 (epoch 45.089), train_loss = 0.73104254, grad/param norm = 1.8373e-01, time/batch = 14.8410s	
29895/33150 (epoch 45.090), train_loss = 0.75984800, grad/param norm = 1.9122e-01, time/batch = 15.2288s	
29896/33150 (epoch 45.092), train_loss = 0.73539939, grad/param norm = 1.8569e-01, time/batch = 15.0000s	
29897/33150 (epoch 45.094), train_loss = 0.82540302, grad/param norm = 2.0861e-01, time/batch = 14.5924s	
29898/33150 (epoch 45.095), train_loss = 0.73313873, grad/param norm = 1.9354e-01, time/batch = 15.4107s	
29899/33150 (epoch 45.097), train_loss = 0.67650218, grad/param norm = 2.0918e-01, time/batch = 15.2507s	
29900/33150 (epoch 45.098), train_loss = 1.01452064, grad/param norm = 1.9080e-01, time/batch = 15.0912s	
29901/33150 (epoch 45.100), train_loss = 0.96949848, grad/param norm = 2.3545e-01, time/batch = 14.7864s	
29902/33150 (epoch 45.101), train_loss = 0.71988988, grad/param norm = 1.7571e-01, time/batch = 14.7851s	
29903/33150 (epoch 45.103), train_loss = 0.80751155, grad/param norm = 1.8088e-01, time/batch = 15.1859s	
29904/33150 (epoch 45.104), train_loss = 0.72892715, grad/param norm = 1.9738e-01, time/batch = 16.1784s	
29905/33150 (epoch 45.106), train_loss = 0.90421818, grad/param norm = 1.7311e-01, time/batch = 17.8830s	
29906/33150 (epoch 45.107), train_loss = 0.96864335, grad/param norm = 2.1388e-01, time/batch = 17.5629s	
29907/33150 (epoch 45.109), train_loss = 0.78051720, grad/param norm = 1.5326e-01, time/batch = 17.5501s	
29908/33150 (epoch 45.110), train_loss = 0.87938751, grad/param norm = 2.0305e-01, time/batch = 18.7959s	
29909/33150 (epoch 45.112), train_loss = 0.73045943, grad/param norm = 1.6816e-01, time/batch = 18.6266s	
29910/33150 (epoch 45.113), train_loss = 0.76652979, grad/param norm = 1.6995e-01, time/batch = 16.7148s	
29911/33150 (epoch 45.115), train_loss = 0.97160789, grad/param norm = 2.5086e-01, time/batch = 19.8767s	
29912/33150 (epoch 45.116), train_loss = 0.85739922, grad/param norm = 1.7719e-01, time/batch = 16.4676s	
29913/33150 (epoch 45.118), train_loss = 0.83934306, grad/param norm = 2.0888e-01, time/batch = 15.9353s	
29914/33150 (epoch 45.119), train_loss = 0.87250835, grad/param norm = 2.3497e-01, time/batch = 16.0292s	
29915/33150 (epoch 45.121), train_loss = 0.78190168, grad/param norm = 1.8085e-01, time/batch = 16.2983s	
29916/33150 (epoch 45.122), train_loss = 0.92131733, grad/param norm = 2.1997e-01, time/batch = 16.1575s	
29917/33150 (epoch 45.124), train_loss = 0.67836797, grad/param norm = 1.5259e-01, time/batch = 17.2045s	
29918/33150 (epoch 45.125), train_loss = 0.92692324, grad/param norm = 2.0235e-01, time/batch = 16.8920s	
29919/33150 (epoch 45.127), train_loss = 0.83123281, grad/param norm = 1.8558e-01, time/batch = 15.3113s	
29920/33150 (epoch 45.128), train_loss = 0.83966241, grad/param norm = 1.7877e-01, time/batch = 17.2060s	
29921/33150 (epoch 45.130), train_loss = 0.80843357, grad/param norm = 1.9335e-01, time/batch = 16.4662s	
29922/33150 (epoch 45.131), train_loss = 0.97464411, grad/param norm = 2.0928e-01, time/batch = 17.4583s	
29923/33150 (epoch 45.133), train_loss = 0.75184978, grad/param norm = 1.7428e-01, time/batch = 16.7403s	
29924/33150 (epoch 45.134), train_loss = 0.90763413, grad/param norm = 1.7814e-01, time/batch = 16.2061s	
29925/33150 (epoch 45.136), train_loss = 0.81988740, grad/param norm = 2.0416e-01, time/batch = 15.9048s	
29926/33150 (epoch 45.137), train_loss = 0.87072528, grad/param norm = 1.8513e-01, time/batch = 16.7965s	
29927/33150 (epoch 45.139), train_loss = 0.86149656, grad/param norm = 1.7248e-01, time/batch = 15.1265s	
29928/33150 (epoch 45.140), train_loss = 0.95904270, grad/param norm = 1.9476e-01, time/batch = 16.1406s	
29929/33150 (epoch 45.142), train_loss = 0.85766698, grad/param norm = 2.0268e-01, time/batch = 18.8697s	
29930/33150 (epoch 45.143), train_loss = 0.80669626, grad/param norm = 2.1646e-01, time/batch = 17.8919s	
29931/33150 (epoch 45.145), train_loss = 0.76930711, grad/param norm = 2.1884e-01, time/batch = 17.5532s	
29932/33150 (epoch 45.146), train_loss = 0.90953842, grad/param norm = 2.5453e-01, time/batch = 17.0734s	
29933/33150 (epoch 45.148), train_loss = 0.95256187, grad/param norm = 1.6886e-01, time/batch = 16.5488s	
29934/33150 (epoch 45.149), train_loss = 0.82938908, grad/param norm = 2.0004e-01, time/batch = 19.2801s	
29935/33150 (epoch 45.151), train_loss = 0.96785785, grad/param norm = 1.9968e-01, time/batch = 16.3125s	
29936/33150 (epoch 45.152), train_loss = 0.75046884, grad/param norm = 1.8545e-01, time/batch = 16.7038s	
29937/33150 (epoch 45.154), train_loss = 0.75118887, grad/param norm = 2.2079e-01, time/batch = 15.3082s	
29938/33150 (epoch 45.155), train_loss = 0.69612209, grad/param norm = 1.8906e-01, time/batch = 15.6072s	
29939/33150 (epoch 45.157), train_loss = 0.79720504, grad/param norm = 2.1495e-01, time/batch = 15.5550s	
29940/33150 (epoch 45.158), train_loss = 0.78800849, grad/param norm = 1.6637e-01, time/batch = 16.2953s	
29941/33150 (epoch 45.160), train_loss = 0.87197731, grad/param norm = 1.9929e-01, time/batch = 15.0887s	
29942/33150 (epoch 45.161), train_loss = 0.78471390, grad/param norm = 2.6526e-01, time/batch = 15.6410s	
29943/33150 (epoch 45.163), train_loss = 0.70092570, grad/param norm = 1.7205e-01, time/batch = 16.3090s	
29944/33150 (epoch 45.164), train_loss = 0.84498046, grad/param norm = 1.7625e-01, time/batch = 18.2233s	
29945/33150 (epoch 45.166), train_loss = 0.77064514, grad/param norm = 1.8460e-01, time/batch = 16.2261s	
29946/33150 (epoch 45.167), train_loss = 0.82924408, grad/param norm = 1.5837e-01, time/batch = 16.6328s	
29947/33150 (epoch 45.169), train_loss = 0.82126270, grad/param norm = 2.3194e-01, time/batch = 18.4755s	
29948/33150 (epoch 45.170), train_loss = 0.73279328, grad/param norm = 2.5116e-01, time/batch = 17.8947s	
29949/33150 (epoch 45.172), train_loss = 0.84582335, grad/param norm = 1.8784e-01, time/batch = 18.0471s	
29950/33150 (epoch 45.173), train_loss = 0.81528570, grad/param norm = 1.9770e-01, time/batch = 17.1380s	
29951/33150 (epoch 45.175), train_loss = 0.78047922, grad/param norm = 1.7844e-01, time/batch = 18.5540s	
29952/33150 (epoch 45.176), train_loss = 0.87158633, grad/param norm = 1.9819e-01, time/batch = 18.2891s	
29953/33150 (epoch 45.178), train_loss = 0.99603095, grad/param norm = 2.3508e-01, time/batch = 17.8815s	
29954/33150 (epoch 45.179), train_loss = 0.86805302, grad/param norm = 1.8680e-01, time/batch = 18.3066s	
29955/33150 (epoch 45.181), train_loss = 0.82419876, grad/param norm = 2.2556e-01, time/batch = 14.8915s	
29956/33150 (epoch 45.183), train_loss = 0.79745825, grad/param norm = 2.3315e-01, time/batch = 16.1460s	
29957/33150 (epoch 45.184), train_loss = 1.05351082, grad/param norm = 2.0627e-01, time/batch = 17.2154s	
29958/33150 (epoch 45.186), train_loss = 0.98317457, grad/param norm = 1.7616e-01, time/batch = 17.2142s	
29959/33150 (epoch 45.187), train_loss = 0.81328186, grad/param norm = 2.0442e-01, time/batch = 17.4698s	
29960/33150 (epoch 45.189), train_loss = 0.65255484, grad/param norm = 1.7713e-01, time/batch = 16.0566s	
29961/33150 (epoch 45.190), train_loss = 0.73586660, grad/param norm = 1.9296e-01, time/batch = 19.2131s	
29962/33150 (epoch 45.192), train_loss = 0.84251078, grad/param norm = 2.0619e-01, time/batch = 18.0620s	
29963/33150 (epoch 45.193), train_loss = 0.88081723, grad/param norm = 1.8976e-01, time/batch = 17.7195s	
29964/33150 (epoch 45.195), train_loss = 0.99459924, grad/param norm = 2.8400e-01, time/batch = 19.3808s	
29965/33150 (epoch 45.196), train_loss = 0.92001809, grad/param norm = 1.9690e-01, time/batch = 17.4055s	
29966/33150 (epoch 45.198), train_loss = 0.74169261, grad/param norm = 1.6293e-01, time/batch = 17.7103s	
29967/33150 (epoch 45.199), train_loss = 0.89654702, grad/param norm = 2.3545e-01, time/batch = 18.4692s	
29968/33150 (epoch 45.201), train_loss = 0.78937050, grad/param norm = 1.7325e-01, time/batch = 16.8807s	
29969/33150 (epoch 45.202), train_loss = 0.66758900, grad/param norm = 1.9145e-01, time/batch = 18.1586s	
29970/33150 (epoch 45.204), train_loss = 0.82041880, grad/param norm = 1.9420e-01, time/batch = 15.4970s	
29971/33150 (epoch 45.205), train_loss = 0.84179940, grad/param norm = 1.9049e-01, time/batch = 20.2805s	
29972/33150 (epoch 45.207), train_loss = 0.83562267, grad/param norm = 1.8314e-01, time/batch = 19.7871s	
29973/33150 (epoch 45.208), train_loss = 0.90739961, grad/param norm = 2.3359e-01, time/batch = 17.3037s	
29974/33150 (epoch 45.210), train_loss = 0.76162780, grad/param norm = 1.7336e-01, time/batch = 19.8726s	
29975/33150 (epoch 45.211), train_loss = 0.80703205, grad/param norm = 1.9311e-01, time/batch = 16.9658s	
29976/33150 (epoch 45.213), train_loss = 0.85933073, grad/param norm = 1.5927e-01, time/batch = 16.7126s	
29977/33150 (epoch 45.214), train_loss = 0.77689733, grad/param norm = 1.8142e-01, time/batch = 17.5446s	
29978/33150 (epoch 45.216), train_loss = 0.73365155, grad/param norm = 1.7978e-01, time/batch = 17.3814s	
29979/33150 (epoch 45.217), train_loss = 0.83762281, grad/param norm = 1.8558e-01, time/batch = 16.1536s	
29980/33150 (epoch 45.219), train_loss = 0.76304487, grad/param norm = 1.8904e-01, time/batch = 17.0359s	
29981/33150 (epoch 45.220), train_loss = 0.79440560, grad/param norm = 1.6512e-01, time/batch = 17.6552s	
29982/33150 (epoch 45.222), train_loss = 0.89436367, grad/param norm = 2.0006e-01, time/batch = 18.8064s	
29983/33150 (epoch 45.223), train_loss = 0.81035731, grad/param norm = 1.8390e-01, time/batch = 15.5727s	
29984/33150 (epoch 45.225), train_loss = 0.92071953, grad/param norm = 1.9620e-01, time/batch = 16.2320s	
29985/33150 (epoch 45.226), train_loss = 0.77873340, grad/param norm = 1.7044e-01, time/batch = 16.1219s	
29986/33150 (epoch 45.228), train_loss = 0.77383360, grad/param norm = 1.9541e-01, time/batch = 17.7306s	
29987/33150 (epoch 45.229), train_loss = 0.80846822, grad/param norm = 1.9001e-01, time/batch = 16.9780s	
29988/33150 (epoch 45.231), train_loss = 0.90755398, grad/param norm = 2.3738e-01, time/batch = 18.3226s	
29989/33150 (epoch 45.232), train_loss = 0.79449936, grad/param norm = 1.9578e-01, time/batch = 16.4803s	
29990/33150 (epoch 45.234), train_loss = 0.85371368, grad/param norm = 2.1262e-01, time/batch = 15.2099s	
29991/33150 (epoch 45.235), train_loss = 0.86704081, grad/param norm = 2.0145e-01, time/batch = 17.8987s	
29992/33150 (epoch 45.237), train_loss = 0.83666339, grad/param norm = 2.2988e-01, time/batch = 16.0752s	
29993/33150 (epoch 45.238), train_loss = 0.87429013, grad/param norm = 2.5969e-01, time/batch = 18.3766s	
29994/33150 (epoch 45.240), train_loss = 0.83498761, grad/param norm = 1.8944e-01, time/batch = 17.3868s	
29995/33150 (epoch 45.241), train_loss = 0.90454191, grad/param norm = 2.1409e-01, time/batch = 17.0714s	
29996/33150 (epoch 45.243), train_loss = 0.87559468, grad/param norm = 1.8865e-01, time/batch = 17.3361s	
29997/33150 (epoch 45.244), train_loss = 0.85397961, grad/param norm = 1.8748e-01, time/batch = 17.3134s	
29998/33150 (epoch 45.246), train_loss = 0.89502883, grad/param norm = 1.9875e-01, time/batch = 17.4896s	
29999/33150 (epoch 45.247), train_loss = 0.77538029, grad/param norm = 1.8289e-01, time/batch = 16.9960s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch45.25_1.8532.t7	
30000/33150 (epoch 45.249), train_loss = 0.94751208, grad/param norm = 2.2295e-01, time/batch = 18.3078s	
30001/33150 (epoch 45.250), train_loss = 1.47701855, grad/param norm = 2.6780e-01, time/batch = 17.4726s	
30002/33150 (epoch 45.252), train_loss = 0.88382093, grad/param norm = 1.5703e-01, time/batch = 17.5519s	
30003/33150 (epoch 45.253), train_loss = 0.79571778, grad/param norm = 2.0483e-01, time/batch = 17.4590s	
30004/33150 (epoch 45.255), train_loss = 0.79864749, grad/param norm = 1.5632e-01, time/batch = 18.9705s	
30005/33150 (epoch 45.256), train_loss = 0.89360542, grad/param norm = 1.7532e-01, time/batch = 17.7183s	
30006/33150 (epoch 45.258), train_loss = 0.78602634, grad/param norm = 2.0302e-01, time/batch = 17.6283s	
30007/33150 (epoch 45.259), train_loss = 0.67069829, grad/param norm = 2.3426e-01, time/batch = 16.8843s	
30008/33150 (epoch 45.261), train_loss = 0.72248101, grad/param norm = 1.6460e-01, time/batch = 18.5565s	
30009/33150 (epoch 45.262), train_loss = 0.93588028, grad/param norm = 2.2469e-01, time/batch = 18.7840s	
30010/33150 (epoch 45.264), train_loss = 0.64470827, grad/param norm = 1.6068e-01, time/batch = 17.3775s	
30011/33150 (epoch 45.265), train_loss = 0.82695892, grad/param norm = 1.9892e-01, time/batch = 17.8149s	
30012/33150 (epoch 45.267), train_loss = 0.92919307, grad/param norm = 2.3966e-01, time/batch = 16.3132s	
30013/33150 (epoch 45.268), train_loss = 0.95601634, grad/param norm = 1.9357e-01, time/batch = 17.1481s	
30014/33150 (epoch 45.270), train_loss = 1.00453371, grad/param norm = 1.7599e-01, time/batch = 18.9635s	
30015/33150 (epoch 45.271), train_loss = 0.87794767, grad/param norm = 2.0960e-01, time/batch = 18.0788s	
30016/33150 (epoch 45.273), train_loss = 0.92485132, grad/param norm = 1.9652e-01, time/batch = 16.6041s	
30017/33150 (epoch 45.275), train_loss = 0.94185455, grad/param norm = 2.4051e-01, time/batch = 17.2190s	
30018/33150 (epoch 45.276), train_loss = 0.82204358, grad/param norm = 1.8044e-01, time/batch = 19.1447s	
30019/33150 (epoch 45.278), train_loss = 0.93036505, grad/param norm = 1.9604e-01, time/batch = 16.0466s	
30020/33150 (epoch 45.279), train_loss = 0.92037459, grad/param norm = 1.8201e-01, time/batch = 16.3095s	
30021/33150 (epoch 45.281), train_loss = 0.83450826, grad/param norm = 1.6902e-01, time/batch = 17.9748s	
30022/33150 (epoch 45.282), train_loss = 0.88332132, grad/param norm = 1.5195e-01, time/batch = 18.8085s	
30023/33150 (epoch 45.284), train_loss = 0.76283582, grad/param norm = 1.7258e-01, time/batch = 16.2979s	
30024/33150 (epoch 45.285), train_loss = 0.85690974, grad/param norm = 2.0018e-01, time/batch = 17.5476s	
30025/33150 (epoch 45.287), train_loss = 0.74637579, grad/param norm = 1.8738e-01, time/batch = 17.1502s	
30026/33150 (epoch 45.288), train_loss = 0.89342550, grad/param norm = 1.8832e-01, time/batch = 16.5607s	
30027/33150 (epoch 45.290), train_loss = 0.70990935, grad/param norm = 1.7101e-01, time/batch = 17.6295s	
30028/33150 (epoch 45.291), train_loss = 0.68852235, grad/param norm = 1.7598e-01, time/batch = 17.5524s	
30029/33150 (epoch 45.293), train_loss = 0.78371091, grad/param norm = 1.9896e-01, time/batch = 18.7303s	
30030/33150 (epoch 45.294), train_loss = 0.67851909, grad/param norm = 3.6153e-01, time/batch = 16.3876s	
30031/33150 (epoch 45.296), train_loss = 0.81433099, grad/param norm = 1.7507e-01, time/batch = 16.0534s	
30032/33150 (epoch 45.297), train_loss = 0.78636443, grad/param norm = 2.3714e-01, time/batch = 16.7188s	
30033/33150 (epoch 45.299), train_loss = 0.76141477, grad/param norm = 2.0822e-01, time/batch = 17.8650s	
30034/33150 (epoch 45.300), train_loss = 0.78014087, grad/param norm = 1.6143e-01, time/batch = 17.5525s	
30035/33150 (epoch 45.302), train_loss = 0.80665737, grad/param norm = 2.2163e-01, time/batch = 16.0753s	
30036/33150 (epoch 45.303), train_loss = 0.78673410, grad/param norm = 1.8556e-01, time/batch = 17.1566s	
30037/33150 (epoch 45.305), train_loss = 0.88435489, grad/param norm = 2.1696e-01, time/batch = 16.3605s	
30038/33150 (epoch 45.306), train_loss = 0.86620855, grad/param norm = 1.9193e-01, time/batch = 18.3842s	
30039/33150 (epoch 45.308), train_loss = 1.00146559, grad/param norm = 1.8770e-01, time/batch = 18.7066s	
30040/33150 (epoch 45.309), train_loss = 0.67367342, grad/param norm = 1.5622e-01, time/batch = 18.2094s	
30041/33150 (epoch 45.311), train_loss = 0.82917631, grad/param norm = 2.2251e-01, time/batch = 16.6327s	
30042/33150 (epoch 45.312), train_loss = 0.66716699, grad/param norm = 1.7560e-01, time/batch = 18.4747s	
30043/33150 (epoch 45.314), train_loss = 0.79948135, grad/param norm = 2.0552e-01, time/batch = 16.9024s	
30044/33150 (epoch 45.315), train_loss = 0.86019336, grad/param norm = 1.8244e-01, time/batch = 30.4039s	
30045/33150 (epoch 45.317), train_loss = 0.65609388, grad/param norm = 1.4907e-01, time/batch = 18.4351s	
30046/33150 (epoch 45.318), train_loss = 0.75693048, grad/param norm = 1.6789e-01, time/batch = 15.9653s	
30047/33150 (epoch 45.320), train_loss = 0.68993415, grad/param norm = 1.8828e-01, time/batch = 17.4836s	
30048/33150 (epoch 45.321), train_loss = 0.79418549, grad/param norm = 1.8496e-01, time/batch = 17.2177s	
30049/33150 (epoch 45.323), train_loss = 0.75242216, grad/param norm = 1.8991e-01, time/batch = 19.0606s	
30050/33150 (epoch 45.324), train_loss = 0.78351684, grad/param norm = 2.2371e-01, time/batch = 17.2118s	
30051/33150 (epoch 45.326), train_loss = 0.79847564, grad/param norm = 1.8191e-01, time/batch = 17.8120s	
30052/33150 (epoch 45.327), train_loss = 0.91512395, grad/param norm = 1.7841e-01, time/batch = 16.0487s	
30053/33150 (epoch 45.329), train_loss = 0.87371091, grad/param norm = 1.9236e-01, time/batch = 16.5432s	
30054/33150 (epoch 45.330), train_loss = 0.75625576, grad/param norm = 1.8732e-01, time/batch = 16.7413s	
30055/33150 (epoch 45.332), train_loss = 0.78524521, grad/param norm = 2.2439e-01, time/batch = 17.1256s	
30056/33150 (epoch 45.333), train_loss = 0.86492228, grad/param norm = 1.7859e-01, time/batch = 17.5663s	
30057/33150 (epoch 45.335), train_loss = 0.73357260, grad/param norm = 1.9976e-01, time/batch = 17.5532s	
30058/33150 (epoch 45.336), train_loss = 0.73965621, grad/param norm = 1.9842e-01, time/batch = 17.9774s	
30059/33150 (epoch 45.338), train_loss = 0.68618711, grad/param norm = 1.9104e-01, time/batch = 18.3810s	
30060/33150 (epoch 45.339), train_loss = 0.86056541, grad/param norm = 1.9251e-01, time/batch = 16.1234s	
30061/33150 (epoch 45.341), train_loss = 0.79983087, grad/param norm = 2.1722e-01, time/batch = 15.3790s	
30062/33150 (epoch 45.342), train_loss = 0.74858706, grad/param norm = 1.7455e-01, time/batch = 15.7496s	
30063/33150 (epoch 45.344), train_loss = 0.77331244, grad/param norm = 1.6941e-01, time/batch = 15.2330s	
30064/33150 (epoch 45.345), train_loss = 0.78008857, grad/param norm = 2.0077e-01, time/batch = 15.0288s	
30065/33150 (epoch 45.347), train_loss = 0.68097791, grad/param norm = 1.7752e-01, time/batch = 15.1107s	
30066/33150 (epoch 45.348), train_loss = 0.80836962, grad/param norm = 1.7699e-01, time/batch = 15.4680s	
30067/33150 (epoch 45.350), train_loss = 0.71592608, grad/param norm = 1.8526e-01, time/batch = 16.1563s	
30068/33150 (epoch 45.351), train_loss = 0.85993388, grad/param norm = 1.9340e-01, time/batch = 14.9202s	
30069/33150 (epoch 45.353), train_loss = 0.86293685, grad/param norm = 2.0341e-01, time/batch = 15.7303s	
30070/33150 (epoch 45.354), train_loss = 1.01913300, grad/param norm = 1.9394e-01, time/batch = 15.4664s	
30071/33150 (epoch 45.356), train_loss = 0.90631937, grad/param norm = 1.9197e-01, time/batch = 15.6836s	
30072/33150 (epoch 45.357), train_loss = 0.82412660, grad/param norm = 2.0836e-01, time/batch = 17.2707s	
30073/33150 (epoch 45.359), train_loss = 0.88490206, grad/param norm = 1.9138e-01, time/batch = 16.4961s	
30074/33150 (epoch 45.360), train_loss = 0.86003004, grad/param norm = 1.9289e-01, time/batch = 18.8792s	
30075/33150 (epoch 45.362), train_loss = 0.91798671, grad/param norm = 1.7283e-01, time/batch = 16.2112s	
30076/33150 (epoch 45.363), train_loss = 0.82952466, grad/param norm = 1.8705e-01, time/batch = 17.3962s	
30077/33150 (epoch 45.365), train_loss = 0.79830395, grad/param norm = 1.7594e-01, time/batch = 16.5354s	
30078/33150 (epoch 45.367), train_loss = 0.77500851, grad/param norm = 1.6484e-01, time/batch = 18.4513s	
30079/33150 (epoch 45.368), train_loss = 0.77648490, grad/param norm = 3.9689e-01, time/batch = 16.5435s	
30080/33150 (epoch 45.370), train_loss = 0.85322387, grad/param norm = 2.1383e-01, time/batch = 17.1352s	
30081/33150 (epoch 45.371), train_loss = 0.71283045, grad/param norm = 1.8282e-01, time/batch = 16.4700s	
30082/33150 (epoch 45.373), train_loss = 0.85697991, grad/param norm = 1.9468e-01, time/batch = 16.2869s	
30083/33150 (epoch 45.374), train_loss = 0.82887990, grad/param norm = 1.7221e-01, time/batch = 16.2327s	
30084/33150 (epoch 45.376), train_loss = 0.88633385, grad/param norm = 1.6255e-01, time/batch = 16.5532s	
30085/33150 (epoch 45.377), train_loss = 0.72811066, grad/param norm = 1.7045e-01, time/batch = 18.0506s	
30086/33150 (epoch 45.379), train_loss = 0.84008700, grad/param norm = 2.3203e-01, time/batch = 16.2159s	
30087/33150 (epoch 45.380), train_loss = 0.86906074, grad/param norm = 1.7003e-01, time/batch = 16.8216s	
30088/33150 (epoch 45.382), train_loss = 0.82053776, grad/param norm = 1.9919e-01, time/batch = 17.4652s	
30089/33150 (epoch 45.383), train_loss = 0.74554364, grad/param norm = 1.7382e-01, time/batch = 17.4692s	
30090/33150 (epoch 45.385), train_loss = 0.75182580, grad/param norm = 1.7837e-01, time/batch = 18.0239s	
30091/33150 (epoch 45.386), train_loss = 0.71636906, grad/param norm = 1.4971e-01, time/batch = 16.9628s	
30092/33150 (epoch 45.388), train_loss = 0.72710640, grad/param norm = 1.5850e-01, time/batch = 18.3881s	
30093/33150 (epoch 45.389), train_loss = 0.73015560, grad/param norm = 1.6094e-01, time/batch = 17.2946s	
30094/33150 (epoch 45.391), train_loss = 0.93010104, grad/param norm = 2.2859e-01, time/batch = 15.8158s	
30095/33150 (epoch 45.392), train_loss = 0.74393658, grad/param norm = 1.8097e-01, time/batch = 15.4002s	
30096/33150 (epoch 45.394), train_loss = 0.70215955, grad/param norm = 1.6747e-01, time/batch = 15.7038s	
30097/33150 (epoch 45.395), train_loss = 0.64578873, grad/param norm = 1.6141e-01, time/batch = 18.4499s	
30098/33150 (epoch 45.397), train_loss = 0.56322495, grad/param norm = 1.6838e-01, time/batch = 18.1317s	
30099/33150 (epoch 45.398), train_loss = 0.81738294, grad/param norm = 1.7084e-01, time/batch = 17.0502s	
30100/33150 (epoch 45.400), train_loss = 0.78669183, grad/param norm = 1.5352e-01, time/batch = 17.6155s	
30101/33150 (epoch 45.401), train_loss = 0.67669154, grad/param norm = 1.4808e-01, time/batch = 17.9518s	
30102/33150 (epoch 45.403), train_loss = 0.67790332, grad/param norm = 1.4981e-01, time/batch = 17.3852s	
30103/33150 (epoch 45.404), train_loss = 0.79551896, grad/param norm = 1.7732e-01, time/batch = 17.2061s	
30104/33150 (epoch 45.406), train_loss = 0.76649328, grad/param norm = 1.5516e-01, time/batch = 18.1446s	
30105/33150 (epoch 45.407), train_loss = 0.67094467, grad/param norm = 1.6086e-01, time/batch = 19.2914s	
30106/33150 (epoch 45.409), train_loss = 0.64253205, grad/param norm = 1.6644e-01, time/batch = 17.4804s	
30107/33150 (epoch 45.410), train_loss = 0.79830661, grad/param norm = 1.7145e-01, time/batch = 16.4547s	
30108/33150 (epoch 45.412), train_loss = 0.83876179, grad/param norm = 1.5911e-01, time/batch = 16.8796s	
30109/33150 (epoch 45.413), train_loss = 0.69722962, grad/param norm = 1.5245e-01, time/batch = 16.9823s	
30110/33150 (epoch 45.415), train_loss = 0.80782442, grad/param norm = 1.6998e-01, time/batch = 15.6279s	
30111/33150 (epoch 45.416), train_loss = 0.71824394, grad/param norm = 1.6388e-01, time/batch = 17.1547s	
30112/33150 (epoch 45.418), train_loss = 0.81589553, grad/param norm = 2.0120e-01, time/batch = 17.8072s	
30113/33150 (epoch 45.419), train_loss = 0.79169704, grad/param norm = 1.8660e-01, time/batch = 17.7947s	
30114/33150 (epoch 45.421), train_loss = 0.80818760, grad/param norm = 2.3328e-01, time/batch = 17.2335s	
30115/33150 (epoch 45.422), train_loss = 0.77073125, grad/param norm = 1.6933e-01, time/batch = 19.1272s	
30116/33150 (epoch 45.424), train_loss = 0.70861241, grad/param norm = 1.8335e-01, time/batch = 16.6340s	
30117/33150 (epoch 45.425), train_loss = 0.85414110, grad/param norm = 1.6250e-01, time/batch = 15.4649s	
30118/33150 (epoch 45.427), train_loss = 0.80271826, grad/param norm = 1.6408e-01, time/batch = 16.2849s	
30119/33150 (epoch 45.428), train_loss = 0.74792903, grad/param norm = 1.8000e-01, time/batch = 17.7135s	
30120/33150 (epoch 45.430), train_loss = 0.79985758, grad/param norm = 1.7991e-01, time/batch = 17.9541s	
30121/33150 (epoch 45.431), train_loss = 0.85275620, grad/param norm = 2.1366e-01, time/batch = 19.2156s	
30122/33150 (epoch 45.433), train_loss = 0.77163363, grad/param norm = 1.7524e-01, time/batch = 18.6380s	
30123/33150 (epoch 45.434), train_loss = 0.67169136, grad/param norm = 1.6235e-01, time/batch = 18.9360s	
30124/33150 (epoch 45.436), train_loss = 0.79570830, grad/param norm = 1.5303e-01, time/batch = 17.7921s	
30125/33150 (epoch 45.437), train_loss = 0.77756638, grad/param norm = 1.9710e-01, time/batch = 19.1419s	
30126/33150 (epoch 45.439), train_loss = 0.94394163, grad/param norm = 1.6880e-01, time/batch = 17.8619s	
30127/33150 (epoch 45.440), train_loss = 0.84016958, grad/param norm = 1.7632e-01, time/batch = 16.8668s	
30128/33150 (epoch 45.442), train_loss = 0.67566397, grad/param norm = 1.7259e-01, time/batch = 18.2053s	
30129/33150 (epoch 45.443), train_loss = 0.80004022, grad/param norm = 1.8143e-01, time/batch = 19.5378s	
30130/33150 (epoch 45.445), train_loss = 0.81116133, grad/param norm = 2.4314e-01, time/batch = 16.8836s	
30131/33150 (epoch 45.446), train_loss = 0.82939964, grad/param norm = 1.9897e-01, time/batch = 19.4655s	
30132/33150 (epoch 45.448), train_loss = 0.88643700, grad/param norm = 2.0126e-01, time/batch = 17.3794s	
30133/33150 (epoch 45.449), train_loss = 0.80604678, grad/param norm = 1.5313e-01, time/batch = 17.8748s	
30134/33150 (epoch 45.451), train_loss = 0.79068338, grad/param norm = 1.8848e-01, time/batch = 17.0265s	
30135/33150 (epoch 45.452), train_loss = 0.97735986, grad/param norm = 2.0107e-01, time/batch = 19.5402s	
30136/33150 (epoch 45.454), train_loss = 0.76999247, grad/param norm = 1.5636e-01, time/batch = 18.5293s	
30137/33150 (epoch 45.456), train_loss = 0.74177473, grad/param norm = 1.7496e-01, time/batch = 16.9427s	
30138/33150 (epoch 45.457), train_loss = 0.79624754, grad/param norm = 1.9297e-01, time/batch = 18.8782s	
30139/33150 (epoch 45.459), train_loss = 0.95358849, grad/param norm = 3.6573e-01, time/batch = 18.3015s	
30140/33150 (epoch 45.460), train_loss = 0.85692074, grad/param norm = 1.6949e-01, time/batch = 15.2819s	
30141/33150 (epoch 45.462), train_loss = 0.90734740, grad/param norm = 1.9628e-01, time/batch = 16.7049s	
30142/33150 (epoch 45.463), train_loss = 1.01442427, grad/param norm = 2.1817e-01, time/batch = 16.8953s	
30143/33150 (epoch 45.465), train_loss = 0.86465593, grad/param norm = 1.9431e-01, time/batch = 16.6408s	
30144/33150 (epoch 45.466), train_loss = 0.77704051, grad/param norm = 1.9076e-01, time/batch = 17.6329s	
30145/33150 (epoch 45.468), train_loss = 1.00803806, grad/param norm = 2.0921e-01, time/batch = 18.1370s	
30146/33150 (epoch 45.469), train_loss = 0.73274978, grad/param norm = 1.8333e-01, time/batch = 18.2176s	
30147/33150 (epoch 45.471), train_loss = 0.74236439, grad/param norm = 1.6037e-01, time/batch = 16.3904s	
30148/33150 (epoch 45.472), train_loss = 0.83111856, grad/param norm = 1.7798e-01, time/batch = 17.9681s	
30149/33150 (epoch 45.474), train_loss = 0.85822622, grad/param norm = 2.5958e-01, time/batch = 15.8906s	
30150/33150 (epoch 45.475), train_loss = 1.03784162, grad/param norm = 1.8690e-01, time/batch = 15.3700s	
30151/33150 (epoch 45.477), train_loss = 0.85747135, grad/param norm = 1.8551e-01, time/batch = 15.1644s	
30152/33150 (epoch 45.478), train_loss = 0.82269673, grad/param norm = 1.7561e-01, time/batch = 14.6991s	
30153/33150 (epoch 45.480), train_loss = 0.73881432, grad/param norm = 1.8963e-01, time/batch = 15.1862s	
30154/33150 (epoch 45.481), train_loss = 0.67846531, grad/param norm = 1.8945e-01, time/batch = 14.7657s	
30155/33150 (epoch 45.483), train_loss = 0.77261072, grad/param norm = 1.8742e-01, time/batch = 14.9933s	
30156/33150 (epoch 45.484), train_loss = 0.72643442, grad/param norm = 1.7114e-01, time/batch = 15.5471s	
30157/33150 (epoch 45.486), train_loss = 0.73860115, grad/param norm = 1.9204e-01, time/batch = 16.0514s	
30158/33150 (epoch 45.487), train_loss = 0.85393588, grad/param norm = 1.9846e-01, time/batch = 16.3695s	
30159/33150 (epoch 45.489), train_loss = 0.79676606, grad/param norm = 2.1716e-01, time/batch = 17.4418s	
30160/33150 (epoch 45.490), train_loss = 0.63071051, grad/param norm = 1.5182e-01, time/batch = 17.7962s	
30161/33150 (epoch 45.492), train_loss = 0.77097328, grad/param norm = 1.9193e-01, time/batch = 15.4575s	
30162/33150 (epoch 45.493), train_loss = 0.84581505, grad/param norm = 1.7761e-01, time/batch = 17.2129s	
30163/33150 (epoch 45.495), train_loss = 0.83269259, grad/param norm = 1.7729e-01, time/batch = 18.2149s	
30164/33150 (epoch 45.496), train_loss = 0.76624463, grad/param norm = 1.7148e-01, time/batch = 15.6800s	
30165/33150 (epoch 45.498), train_loss = 0.88658073, grad/param norm = 2.8327e-01, time/batch = 15.1994s	
30166/33150 (epoch 45.499), train_loss = 0.90995020, grad/param norm = 1.8645e-01, time/batch = 15.6839s	
30167/33150 (epoch 45.501), train_loss = 0.82300180, grad/param norm = 2.1041e-01, time/batch = 16.0333s	
30168/33150 (epoch 45.502), train_loss = 0.92032937, grad/param norm = 2.1277e-01, time/batch = 16.7723s	
30169/33150 (epoch 45.504), train_loss = 0.87947898, grad/param norm = 2.2062e-01, time/batch = 16.3451s	
30170/33150 (epoch 45.505), train_loss = 0.94180744, grad/param norm = 2.2324e-01, time/batch = 17.8733s	
30171/33150 (epoch 45.507), train_loss = 0.77385482, grad/param norm = 1.9083e-01, time/batch = 16.7924s	
30172/33150 (epoch 45.508), train_loss = 0.75725040, grad/param norm = 1.7694e-01, time/batch = 18.7214s	
30173/33150 (epoch 45.510), train_loss = 0.87622498, grad/param norm = 1.5234e-01, time/batch = 16.7767s	
30174/33150 (epoch 45.511), train_loss = 0.91207608, grad/param norm = 2.0229e-01, time/batch = 17.2195s	
30175/33150 (epoch 45.513), train_loss = 0.83196732, grad/param norm = 2.0301e-01, time/batch = 17.4552s	
30176/33150 (epoch 45.514), train_loss = 0.71137211, grad/param norm = 1.8659e-01, time/batch = 16.6320s	
30177/33150 (epoch 45.516), train_loss = 0.82437654, grad/param norm = 2.0697e-01, time/batch = 18.1287s	
30178/33150 (epoch 45.517), train_loss = 0.88790658, grad/param norm = 2.0906e-01, time/batch = 16.6260s	
30179/33150 (epoch 45.519), train_loss = 0.74880939, grad/param norm = 1.5708e-01, time/batch = 15.9742s	
30180/33150 (epoch 45.520), train_loss = 0.79960116, grad/param norm = 1.6278e-01, time/batch = 15.6335s	
30181/33150 (epoch 45.522), train_loss = 0.87239453, grad/param norm = 2.4931e-01, time/batch = 18.0568s	
30182/33150 (epoch 45.523), train_loss = 0.72779988, grad/param norm = 1.9452e-01, time/batch = 17.9641s	
30183/33150 (epoch 45.525), train_loss = 0.84854916, grad/param norm = 2.2916e-01, time/batch = 15.3501s	
30184/33150 (epoch 45.526), train_loss = 0.74188833, grad/param norm = 1.7107e-01, time/batch = 16.3082s	
30185/33150 (epoch 45.528), train_loss = 0.82359171, grad/param norm = 1.8932e-01, time/batch = 15.9553s	
30186/33150 (epoch 45.529), train_loss = 0.80513527, grad/param norm = 1.8637e-01, time/batch = 17.2273s	
30187/33150 (epoch 45.531), train_loss = 0.72763478, grad/param norm = 2.6436e-01, time/batch = 16.7156s	
30188/33150 (epoch 45.532), train_loss = 0.82409676, grad/param norm = 2.2550e-01, time/batch = 18.4776s	
30189/33150 (epoch 45.534), train_loss = 0.80152338, grad/param norm = 1.7948e-01, time/batch = 15.4765s	
30190/33150 (epoch 45.535), train_loss = 0.74255430, grad/param norm = 2.5900e-01, time/batch = 17.3759s	
30191/33150 (epoch 45.537), train_loss = 0.82104257, grad/param norm = 2.0390e-01, time/batch = 16.5539s	
30192/33150 (epoch 45.538), train_loss = 0.73396925, grad/param norm = 1.8577e-01, time/batch = 17.8837s	
30193/33150 (epoch 45.540), train_loss = 0.72232016, grad/param norm = 1.9946e-01, time/batch = 16.5428s	
30194/33150 (epoch 45.541), train_loss = 0.89893492, grad/param norm = 1.9377e-01, time/batch = 15.6965s	
30195/33150 (epoch 45.543), train_loss = 0.82366482, grad/param norm = 1.8116e-01, time/batch = 16.4597s	
30196/33150 (epoch 45.544), train_loss = 0.86864148, grad/param norm = 1.9317e-01, time/batch = 16.7966s	
30197/33150 (epoch 45.546), train_loss = 0.74688783, grad/param norm = 1.7755e-01, time/batch = 16.8758s	
30198/33150 (epoch 45.548), train_loss = 0.78266058, grad/param norm = 2.0743e-01, time/batch = 16.5338s	
30199/33150 (epoch 45.549), train_loss = 0.80207705, grad/param norm = 2.7636e-01, time/batch = 17.1414s	
30200/33150 (epoch 45.551), train_loss = 0.72722535, grad/param norm = 1.7245e-01, time/batch = 15.2487s	
30201/33150 (epoch 45.552), train_loss = 0.63316188, grad/param norm = 1.5903e-01, time/batch = 15.8064s	
30202/33150 (epoch 45.554), train_loss = 0.87770527, grad/param norm = 2.0757e-01, time/batch = 17.1354s	
30203/33150 (epoch 45.555), train_loss = 0.91061931, grad/param norm = 2.3404e-01, time/batch = 17.5542s	
30204/33150 (epoch 45.557), train_loss = 0.67460219, grad/param norm = 1.8633e-01, time/batch = 17.8011s	
30205/33150 (epoch 45.558), train_loss = 0.82163157, grad/param norm = 2.1339e-01, time/batch = 16.0482s	
30206/33150 (epoch 45.560), train_loss = 0.72489042, grad/param norm = 1.8108e-01, time/batch = 16.2986s	
30207/33150 (epoch 45.561), train_loss = 0.67867692, grad/param norm = 2.0869e-01, time/batch = 17.2167s	
30208/33150 (epoch 45.563), train_loss = 0.86797176, grad/param norm = 2.6533e-01, time/batch = 15.8749s	
30209/33150 (epoch 45.564), train_loss = 0.90102158, grad/param norm = 1.7995e-01, time/batch = 18.1194s	
30210/33150 (epoch 45.566), train_loss = 0.72967009, grad/param norm = 1.8672e-01, time/batch = 18.6386s	
30211/33150 (epoch 45.567), train_loss = 0.79509978, grad/param norm = 2.0454e-01, time/batch = 18.4588s	
30212/33150 (epoch 45.569), train_loss = 0.82332033, grad/param norm = 1.7012e-01, time/batch = 16.7130s	
30213/33150 (epoch 45.570), train_loss = 0.87381249, grad/param norm = 1.6998e-01, time/batch = 17.3891s	
30214/33150 (epoch 45.572), train_loss = 0.75613608, grad/param norm = 2.3752e-01, time/batch = 16.8719s	
30215/33150 (epoch 45.573), train_loss = 0.68739750, grad/param norm = 1.4331e-01, time/batch = 16.2079s	
30216/33150 (epoch 45.575), train_loss = 0.77468019, grad/param norm = 1.9024e-01, time/batch = 16.7207s	
30217/33150 (epoch 45.576), train_loss = 0.71355547, grad/param norm = 1.7691e-01, time/batch = 15.4364s	
30218/33150 (epoch 45.578), train_loss = 0.74631949, grad/param norm = 1.7043e-01, time/batch = 17.9611s	
30219/33150 (epoch 45.579), train_loss = 0.70374022, grad/param norm = 1.5675e-01, time/batch = 17.1873s	
30220/33150 (epoch 45.581), train_loss = 0.70251979, grad/param norm = 1.7584e-01, time/batch = 16.1235s	
30221/33150 (epoch 45.582), train_loss = 0.91543407, grad/param norm = 1.7597e-01, time/batch = 16.6409s	
30222/33150 (epoch 45.584), train_loss = 0.86947677, grad/param norm = 2.0864e-01, time/batch = 17.2035s	
30223/33150 (epoch 45.585), train_loss = 0.80001772, grad/param norm = 1.6038e-01, time/batch = 16.8738s	
30224/33150 (epoch 45.587), train_loss = 0.81249163, grad/param norm = 1.8571e-01, time/batch = 16.6246s	
30225/33150 (epoch 45.588), train_loss = 0.73938027, grad/param norm = 1.6944e-01, time/batch = 16.3708s	
30226/33150 (epoch 45.590), train_loss = 0.83739212, grad/param norm = 2.0315e-01, time/batch = 15.4968s	
30227/33150 (epoch 45.591), train_loss = 0.82773601, grad/param norm = 1.7714e-01, time/batch = 15.8206s	
30228/33150 (epoch 45.593), train_loss = 0.86851107, grad/param norm = 2.1397e-01, time/batch = 17.9650s	
30229/33150 (epoch 45.594), train_loss = 0.75840707, grad/param norm = 1.8671e-01, time/batch = 15.6856s	
30230/33150 (epoch 45.596), train_loss = 0.76488802, grad/param norm = 1.7280e-01, time/batch = 16.4404s	
30231/33150 (epoch 45.597), train_loss = 0.70454018, grad/param norm = 2.3788e-01, time/batch = 16.5126s	
30232/33150 (epoch 45.599), train_loss = 0.94556015, grad/param norm = 2.0632e-01, time/batch = 16.8715s	
30233/33150 (epoch 45.600), train_loss = 0.76796449, grad/param norm = 2.0668e-01, time/batch = 16.2797s	
30234/33150 (epoch 45.602), train_loss = 0.79935819, grad/param norm = 2.0652e-01, time/batch = 17.3841s	
30235/33150 (epoch 45.603), train_loss = 0.93441454, grad/param norm = 2.0504e-01, time/batch = 16.9657s	
30236/33150 (epoch 45.605), train_loss = 0.72959221, grad/param norm = 1.8446e-01, time/batch = 16.3072s	
30237/33150 (epoch 45.606), train_loss = 0.75820402, grad/param norm = 2.2848e-01, time/batch = 15.3445s	
30238/33150 (epoch 45.608), train_loss = 0.89403117, grad/param norm = 1.7575e-01, time/batch = 15.1884s	
30239/33150 (epoch 45.609), train_loss = 0.79648574, grad/param norm = 1.9109e-01, time/batch = 18.4419s	
30240/33150 (epoch 45.611), train_loss = 0.71486904, grad/param norm = 1.9889e-01, time/batch = 16.7072s	
30241/33150 (epoch 45.612), train_loss = 0.78475468, grad/param norm = 2.0364e-01, time/batch = 15.9456s	
30242/33150 (epoch 45.614), train_loss = 0.73389284, grad/param norm = 1.7027e-01, time/batch = 17.1299s	
30243/33150 (epoch 45.615), train_loss = 0.70463413, grad/param norm = 1.8813e-01, time/batch = 16.5466s	
30244/33150 (epoch 45.617), train_loss = 0.81346211, grad/param norm = 2.1518e-01, time/batch = 15.9620s	
30245/33150 (epoch 45.618), train_loss = 0.82738500, grad/param norm = 1.8297e-01, time/batch = 18.3696s	
30246/33150 (epoch 45.620), train_loss = 0.78837900, grad/param norm = 2.3624e-01, time/batch = 17.9393s	
30247/33150 (epoch 45.621), train_loss = 0.82987415, grad/param norm = 1.9986e-01, time/batch = 16.5552s	
30248/33150 (epoch 45.623), train_loss = 0.84494550, grad/param norm = 1.7962e-01, time/batch = 16.3748s	
30249/33150 (epoch 45.624), train_loss = 0.78412114, grad/param norm = 1.9430e-01, time/batch = 16.9281s	
30250/33150 (epoch 45.626), train_loss = 0.82519810, grad/param norm = 2.1439e-01, time/batch = 16.3575s	
30251/33150 (epoch 45.627), train_loss = 0.79024967, grad/param norm = 2.0726e-01, time/batch = 15.2128s	
30252/33150 (epoch 45.629), train_loss = 0.68379667, grad/param norm = 1.9094e-01, time/batch = 16.1223s	
30253/33150 (epoch 45.630), train_loss = 0.78393677, grad/param norm = 1.7796e-01, time/batch = 15.1745s	
30254/33150 (epoch 45.632), train_loss = 0.71324295, grad/param norm = 1.5649e-01, time/batch = 17.2631s	
30255/33150 (epoch 45.633), train_loss = 0.74715713, grad/param norm = 1.9636e-01, time/batch = 28.5564s	
30256/33150 (epoch 45.635), train_loss = 0.95679686, grad/param norm = 1.9161e-01, time/batch = 16.5143s	
30257/33150 (epoch 45.637), train_loss = 0.64851034, grad/param norm = 1.9241e-01, time/batch = 18.1769s	
30258/33150 (epoch 45.638), train_loss = 0.78666749, grad/param norm = 1.6945e-01, time/batch = 15.5321s	
30259/33150 (epoch 45.640), train_loss = 0.85898377, grad/param norm = 1.9437e-01, time/batch = 17.1064s	
30260/33150 (epoch 45.641), train_loss = 0.67953128, grad/param norm = 1.8047e-01, time/batch = 15.6748s	
30261/33150 (epoch 45.643), train_loss = 0.81567227, grad/param norm = 1.7983e-01, time/batch = 16.4447s	
30262/33150 (epoch 45.644), train_loss = 0.94980752, grad/param norm = 1.8154e-01, time/batch = 18.3581s	
30263/33150 (epoch 45.646), train_loss = 0.80715028, grad/param norm = 1.6029e-01, time/batch = 15.6745s	
30264/33150 (epoch 45.647), train_loss = 0.96139973, grad/param norm = 1.9089e-01, time/batch = 15.9631s	
30265/33150 (epoch 45.649), train_loss = 0.83046738, grad/param norm = 2.2999e-01, time/batch = 16.1914s	
30266/33150 (epoch 45.650), train_loss = 0.69894372, grad/param norm = 1.6549e-01, time/batch = 16.2743s	
30267/33150 (epoch 45.652), train_loss = 0.88369095, grad/param norm = 2.1418e-01, time/batch = 15.7819s	
30268/33150 (epoch 45.653), train_loss = 0.85406561, grad/param norm = 1.6215e-01, time/batch = 15.1717s	
30269/33150 (epoch 45.655), train_loss = 0.85889682, grad/param norm = 2.1065e-01, time/batch = 17.4148s	
30270/33150 (epoch 45.656), train_loss = 0.76737070, grad/param norm = 1.6364e-01, time/batch = 18.3765s	
30271/33150 (epoch 45.658), train_loss = 0.76672186, grad/param norm = 2.1136e-01, time/batch = 17.2840s	
30272/33150 (epoch 45.659), train_loss = 0.99394651, grad/param norm = 2.9422e-01, time/batch = 15.5727s	
30273/33150 (epoch 45.661), train_loss = 0.78845790, grad/param norm = 1.8866e-01, time/batch = 16.1264s	
30274/33150 (epoch 45.662), train_loss = 0.78009037, grad/param norm = 1.8484e-01, time/batch = 16.9513s	
30275/33150 (epoch 45.664), train_loss = 0.91294570, grad/param norm = 2.0263e-01, time/batch = 15.3507s	
30276/33150 (epoch 45.665), train_loss = 0.88530879, grad/param norm = 2.3604e-01, time/batch = 15.3512s	
30277/33150 (epoch 45.667), train_loss = 0.87859658, grad/param norm = 2.0737e-01, time/batch = 16.7691s	
30278/33150 (epoch 45.668), train_loss = 0.95930210, grad/param norm = 2.0728e-01, time/batch = 16.1085s	
30279/33150 (epoch 45.670), train_loss = 0.76719535, grad/param norm = 1.5964e-01, time/batch = 17.6155s	
30280/33150 (epoch 45.671), train_loss = 0.73394352, grad/param norm = 2.0305e-01, time/batch = 15.2539s	
30281/33150 (epoch 45.673), train_loss = 0.92343865, grad/param norm = 1.7564e-01, time/batch = 18.1992s	
30282/33150 (epoch 45.674), train_loss = 0.88837007, grad/param norm = 2.3151e-01, time/batch = 16.5293s	
30283/33150 (epoch 45.676), train_loss = 0.80324011, grad/param norm = 1.8969e-01, time/batch = 15.3489s	
30284/33150 (epoch 45.677), train_loss = 0.93822440, grad/param norm = 2.2664e-01, time/batch = 15.0776s	
30285/33150 (epoch 45.679), train_loss = 0.81107436, grad/param norm = 1.7373e-01, time/batch = 16.8522s	
30286/33150 (epoch 45.680), train_loss = 0.90645787, grad/param norm = 2.1617e-01, time/batch = 16.5120s	
30287/33150 (epoch 45.682), train_loss = 0.81884420, grad/param norm = 1.7044e-01, time/batch = 16.0056s	
30288/33150 (epoch 45.683), train_loss = 0.69621317, grad/param norm = 1.5795e-01, time/batch = 29.0881s	
30289/33150 (epoch 45.685), train_loss = 0.76962193, grad/param norm = 2.1161e-01, time/batch = 29.7803s	
30290/33150 (epoch 45.686), train_loss = 0.67158649, grad/param norm = 1.9812e-01, time/batch = 28.6789s	
30291/33150 (epoch 45.688), train_loss = 0.72346283, grad/param norm = 1.8233e-01, time/batch = 33.7642s	
30292/33150 (epoch 45.689), train_loss = 0.73575793, grad/param norm = 1.6358e-01, time/batch = 32.2521s	
30293/33150 (epoch 45.691), train_loss = 0.62292282, grad/param norm = 1.5950e-01, time/batch = 32.5825s	
30294/33150 (epoch 45.692), train_loss = 0.71848107, grad/param norm = 1.8114e-01, time/batch = 34.4559s	
30295/33150 (epoch 45.694), train_loss = 0.63617037, grad/param norm = 1.5407e-01, time/batch = 32.9351s	
30296/33150 (epoch 45.695), train_loss = 0.73201359, grad/param norm = 1.7666e-01, time/batch = 32.8234s	
30297/33150 (epoch 45.697), train_loss = 0.69193146, grad/param norm = 1.5216e-01, time/batch = 32.7810s	
30298/33150 (epoch 45.698), train_loss = 0.72068949, grad/param norm = 2.0120e-01, time/batch = 21.4653s	
30299/33150 (epoch 45.700), train_loss = 0.62946436, grad/param norm = 1.5594e-01, time/batch = 15.5945s	
30300/33150 (epoch 45.701), train_loss = 0.68292862, grad/param norm = 1.6165e-01, time/batch = 15.0616s	
30301/33150 (epoch 45.703), train_loss = 0.78743452, grad/param norm = 2.1857e-01, time/batch = 14.6364s	
30302/33150 (epoch 45.704), train_loss = 0.67707233, grad/param norm = 1.4211e-01, time/batch = 14.7148s	
30303/33150 (epoch 45.706), train_loss = 0.73919076, grad/param norm = 1.6564e-01, time/batch = 14.8007s	
30304/33150 (epoch 45.707), train_loss = 0.76506390, grad/param norm = 1.8560e-01, time/batch = 14.6372s	
30305/33150 (epoch 45.709), train_loss = 0.79281828, grad/param norm = 1.7333e-01, time/batch = 14.8787s	
30306/33150 (epoch 45.710), train_loss = 0.79352336, grad/param norm = 1.9741e-01, time/batch = 14.9654s	
30307/33150 (epoch 45.712), train_loss = 0.86565008, grad/param norm = 1.7235e-01, time/batch = 14.9661s	
30308/33150 (epoch 45.713), train_loss = 0.81947282, grad/param norm = 1.6905e-01, time/batch = 14.9728s	
30309/33150 (epoch 45.715), train_loss = 0.76446659, grad/param norm = 1.6232e-01, time/batch = 14.7320s	
30310/33150 (epoch 45.716), train_loss = 0.82283243, grad/param norm = 1.7278e-01, time/batch = 17.6267s	
30311/33150 (epoch 45.718), train_loss = 0.79149337, grad/param norm = 1.6989e-01, time/batch = 16.2972s	
30312/33150 (epoch 45.719), train_loss = 0.85803271, grad/param norm = 1.9643e-01, time/batch = 15.2952s	
30313/33150 (epoch 45.721), train_loss = 0.76615465, grad/param norm = 1.8714e-01, time/batch = 17.9645s	
30314/33150 (epoch 45.722), train_loss = 0.83677691, grad/param norm = 1.7254e-01, time/batch = 16.4534s	
30315/33150 (epoch 45.724), train_loss = 0.75013850, grad/param norm = 1.8968e-01, time/batch = 16.8782s	
30316/33150 (epoch 45.725), train_loss = 0.86211810, grad/param norm = 2.6232e-01, time/batch = 16.1408s	
30317/33150 (epoch 45.727), train_loss = 0.85997175, grad/param norm = 2.3174e-01, time/batch = 18.5596s	
30318/33150 (epoch 45.729), train_loss = 0.80034081, grad/param norm = 2.0305e-01, time/batch = 16.8635s	
30319/33150 (epoch 45.730), train_loss = 0.79582120, grad/param norm = 1.6264e-01, time/batch = 17.9671s	
30320/33150 (epoch 45.732), train_loss = 0.85279870, grad/param norm = 1.8915e-01, time/batch = 18.9681s	
30321/33150 (epoch 45.733), train_loss = 0.69506046, grad/param norm = 1.4667e-01, time/batch = 16.3701s	
30322/33150 (epoch 45.735), train_loss = 0.73070818, grad/param norm = 1.8616e-01, time/batch = 16.9576s	
30323/33150 (epoch 45.736), train_loss = 0.74362771, grad/param norm = 1.9025e-01, time/batch = 18.0393s	
30324/33150 (epoch 45.738), train_loss = 0.79821545, grad/param norm = 1.9759e-01, time/batch = 17.6949s	
30325/33150 (epoch 45.739), train_loss = 0.87830947, grad/param norm = 2.0090e-01, time/batch = 17.7944s	
30326/33150 (epoch 45.741), train_loss = 0.79861890, grad/param norm = 1.9712e-01, time/batch = 18.5481s	
30327/33150 (epoch 45.742), train_loss = 0.68266614, grad/param norm = 1.9032e-01, time/batch = 16.4465s	
30328/33150 (epoch 45.744), train_loss = 0.84812640, grad/param norm = 1.7028e-01, time/batch = 16.6138s	
30329/33150 (epoch 45.745), train_loss = 0.74597245, grad/param norm = 1.6669e-01, time/batch = 16.9610s	
30330/33150 (epoch 45.747), train_loss = 0.57734895, grad/param norm = 1.6598e-01, time/batch = 18.4554s	
30331/33150 (epoch 45.748), train_loss = 0.68167722, grad/param norm = 1.6782e-01, time/batch = 15.6359s	
30332/33150 (epoch 45.750), train_loss = 0.81029929, grad/param norm = 2.0404e-01, time/batch = 15.8889s	
30333/33150 (epoch 45.751), train_loss = 0.77177327, grad/param norm = 1.6453e-01, time/batch = 19.1370s	
30334/33150 (epoch 45.753), train_loss = 0.69191510, grad/param norm = 1.9387e-01, time/batch = 16.4005s	
30335/33150 (epoch 45.754), train_loss = 0.97206860, grad/param norm = 2.4231e-01, time/batch = 16.7134s	
30336/33150 (epoch 45.756), train_loss = 0.80751347, grad/param norm = 2.4646e-01, time/batch = 16.2318s	
30337/33150 (epoch 45.757), train_loss = 0.83248299, grad/param norm = 1.8272e-01, time/batch = 17.5420s	
30338/33150 (epoch 45.759), train_loss = 0.91894668, grad/param norm = 2.1638e-01, time/batch = 16.0575s	
30339/33150 (epoch 45.760), train_loss = 0.83726661, grad/param norm = 1.8401e-01, time/batch = 17.4661s	
30340/33150 (epoch 45.762), train_loss = 0.80438336, grad/param norm = 2.0956e-01, time/batch = 16.8732s	
30341/33150 (epoch 45.763), train_loss = 0.84246514, grad/param norm = 2.0491e-01, time/batch = 18.0552s	
30342/33150 (epoch 45.765), train_loss = 0.78883592, grad/param norm = 1.8623e-01, time/batch = 16.4684s	
30343/33150 (epoch 45.766), train_loss = 0.66767380, grad/param norm = 1.7402e-01, time/batch = 18.6398s	
30344/33150 (epoch 45.768), train_loss = 0.72806526, grad/param norm = 1.7063e-01, time/batch = 17.9846s	
30345/33150 (epoch 45.769), train_loss = 0.87545133, grad/param norm = 2.5031e-01, time/batch = 17.4724s	
30346/33150 (epoch 45.771), train_loss = 0.82720021, grad/param norm = 2.0983e-01, time/batch = 17.1129s	
30347/33150 (epoch 45.772), train_loss = 0.82928683, grad/param norm = 2.1027e-01, time/batch = 16.7329s	
30348/33150 (epoch 45.774), train_loss = 0.91434406, grad/param norm = 1.8834e-01, time/batch = 17.6491s	
30349/33150 (epoch 45.775), train_loss = 0.83719508, grad/param norm = 2.4502e-01, time/batch = 15.9684s	
30350/33150 (epoch 45.777), train_loss = 0.85657494, grad/param norm = 2.0413e-01, time/batch = 16.4642s	
30351/33150 (epoch 45.778), train_loss = 0.79135434, grad/param norm = 2.0195e-01, time/batch = 17.0453s	
30352/33150 (epoch 45.780), train_loss = 0.69471835, grad/param norm = 1.5807e-01, time/batch = 16.6204s	
30353/33150 (epoch 45.781), train_loss = 0.77740073, grad/param norm = 1.5992e-01, time/batch = 16.8944s	
30354/33150 (epoch 45.783), train_loss = 0.79003705, grad/param norm = 1.6052e-01, time/batch = 17.5611s	
30355/33150 (epoch 45.784), train_loss = 0.80509682, grad/param norm = 1.8741e-01, time/batch = 16.8677s	
30356/33150 (epoch 45.786), train_loss = 0.78179575, grad/param norm = 1.8150e-01, time/batch = 16.2989s	
30357/33150 (epoch 45.787), train_loss = 0.71140712, grad/param norm = 1.4640e-01, time/batch = 17.0624s	
30358/33150 (epoch 45.789), train_loss = 0.67619896, grad/param norm = 1.5115e-01, time/batch = 16.0519s	
30359/33150 (epoch 45.790), train_loss = 0.67407681, grad/param norm = 1.7458e-01, time/batch = 16.6310s	
30360/33150 (epoch 45.792), train_loss = 0.78316912, grad/param norm = 1.9933e-01, time/batch = 17.2099s	
30361/33150 (epoch 45.793), train_loss = 0.75858095, grad/param norm = 2.0309e-01, time/batch = 17.0593s	
30362/33150 (epoch 45.795), train_loss = 0.75660904, grad/param norm = 1.8038e-01, time/batch = 16.1393s	
30363/33150 (epoch 45.796), train_loss = 0.77493556, grad/param norm = 1.6006e-01, time/batch = 15.7774s	
30364/33150 (epoch 45.798), train_loss = 0.73951947, grad/param norm = 1.4554e-01, time/batch = 16.8882s	
30365/33150 (epoch 45.799), train_loss = 0.66560619, grad/param norm = 2.7415e-01, time/batch = 19.0266s	
30366/33150 (epoch 45.801), train_loss = 0.79387385, grad/param norm = 2.0497e-01, time/batch = 17.7678s	
30367/33150 (epoch 45.802), train_loss = 0.75772656, grad/param norm = 1.7749e-01, time/batch = 16.1126s	
30368/33150 (epoch 45.804), train_loss = 0.73457347, grad/param norm = 1.8396e-01, time/batch = 18.1229s	
30369/33150 (epoch 45.805), train_loss = 0.70816097, grad/param norm = 1.7746e-01, time/batch = 18.3083s	
30370/33150 (epoch 45.807), train_loss = 0.78504645, grad/param norm = 1.5696e-01, time/batch = 16.7151s	
30371/33150 (epoch 45.808), train_loss = 0.85522751, grad/param norm = 1.9059e-01, time/batch = 17.5526s	
30372/33150 (epoch 45.810), train_loss = 0.70989573, grad/param norm = 1.6934e-01, time/batch = 17.3125s	
30373/33150 (epoch 45.811), train_loss = 0.78709985, grad/param norm = 1.9190e-01, time/batch = 17.2057s	
30374/33150 (epoch 45.813), train_loss = 0.75290373, grad/param norm = 1.8378e-01, time/batch = 16.4573s	
30375/33150 (epoch 45.814), train_loss = 0.73025942, grad/param norm = 2.3083e-01, time/batch = 17.0379s	
30376/33150 (epoch 45.816), train_loss = 0.74865589, grad/param norm = 2.0326e-01, time/batch = 18.6193s	
30377/33150 (epoch 45.817), train_loss = 0.82341584, grad/param norm = 1.9145e-01, time/batch = 15.9676s	
30378/33150 (epoch 45.819), train_loss = 0.80195788, grad/param norm = 1.9496e-01, time/batch = 19.3789s	
30379/33150 (epoch 45.821), train_loss = 0.72757825, grad/param norm = 1.5377e-01, time/batch = 19.0378s	
30380/33150 (epoch 45.822), train_loss = 0.77112154, grad/param norm = 2.0649e-01, time/batch = 17.4466s	
30381/33150 (epoch 45.824), train_loss = 0.81795593, grad/param norm = 1.8994e-01, time/batch = 17.2929s	
30382/33150 (epoch 45.825), train_loss = 0.82760847, grad/param norm = 2.1391e-01, time/batch = 19.5238s	
30383/33150 (epoch 45.827), train_loss = 0.84046176, grad/param norm = 1.9628e-01, time/batch = 15.9414s	
30384/33150 (epoch 45.828), train_loss = 0.72274265, grad/param norm = 1.9014e-01, time/batch = 15.2027s	
30385/33150 (epoch 45.830), train_loss = 0.84666870, grad/param norm = 2.0683e-01, time/batch = 15.6979s	
30386/33150 (epoch 45.831), train_loss = 0.73106141, grad/param norm = 1.8569e-01, time/batch = 18.9551s	
30387/33150 (epoch 45.833), train_loss = 0.68620862, grad/param norm = 1.6373e-01, time/batch = 16.9609s	
30388/33150 (epoch 45.834), train_loss = 0.85801595, grad/param norm = 1.7455e-01, time/batch = 18.5576s	
30389/33150 (epoch 45.836), train_loss = 0.90658920, grad/param norm = 1.7906e-01, time/batch = 18.2950s	
30390/33150 (epoch 45.837), train_loss = 0.71248324, grad/param norm = 1.7071e-01, time/batch = 18.5403s	
30391/33150 (epoch 45.839), train_loss = 0.85038433, grad/param norm = 1.9263e-01, time/batch = 18.1319s	
30392/33150 (epoch 45.840), train_loss = 0.83377449, grad/param norm = 1.9127e-01, time/batch = 16.1418s	
30393/33150 (epoch 45.842), train_loss = 0.88871995, grad/param norm = 2.4261e-01, time/batch = 19.6835s	
30394/33150 (epoch 45.843), train_loss = 0.87682764, grad/param norm = 2.0994e-01, time/batch = 16.7160s	
30395/33150 (epoch 45.845), train_loss = 0.74065049, grad/param norm = 1.6334e-01, time/batch = 17.2107s	
30396/33150 (epoch 45.846), train_loss = 0.94745260, grad/param norm = 2.7366e-01, time/batch = 17.2209s	
30397/33150 (epoch 45.848), train_loss = 0.85900831, grad/param norm = 1.9540e-01, time/batch = 17.6330s	
30398/33150 (epoch 45.849), train_loss = 0.88312829, grad/param norm = 1.9282e-01, time/batch = 18.0458s	
30399/33150 (epoch 45.851), train_loss = 0.85682056, grad/param norm = 2.0712e-01, time/batch = 15.8586s	
30400/33150 (epoch 45.852), train_loss = 0.93352014, grad/param norm = 1.8986e-01, time/batch = 18.1176s	
30401/33150 (epoch 45.854), train_loss = 0.84745251, grad/param norm = 2.0870e-01, time/batch = 16.5362s	
30402/33150 (epoch 45.855), train_loss = 0.73792426, grad/param norm = 2.4109e-01, time/batch = 15.3732s	
30403/33150 (epoch 45.857), train_loss = 0.66002160, grad/param norm = 1.8944e-01, time/batch = 18.7094s	
30404/33150 (epoch 45.858), train_loss = 0.75359505, grad/param norm = 1.6809e-01, time/batch = 18.3552s	
30405/33150 (epoch 45.860), train_loss = 0.72723262, grad/param norm = 1.9198e-01, time/batch = 16.7967s	
30406/33150 (epoch 45.861), train_loss = 0.68569694, grad/param norm = 1.5524e-01, time/batch = 17.7093s	
30407/33150 (epoch 45.863), train_loss = 0.77142238, grad/param norm = 1.9770e-01, time/batch = 18.2036s	
30408/33150 (epoch 45.864), train_loss = 0.80932282, grad/param norm = 1.8225e-01, time/batch = 16.6395s	
30409/33150 (epoch 45.866), train_loss = 0.86790974, grad/param norm = 1.8571e-01, time/batch = 18.3882s	
30410/33150 (epoch 45.867), train_loss = 0.80020371, grad/param norm = 1.8763e-01, time/batch = 18.1364s	
30411/33150 (epoch 45.869), train_loss = 0.81024801, grad/param norm = 2.0177e-01, time/batch = 16.6267s	
30412/33150 (epoch 45.870), train_loss = 0.78184151, grad/param norm = 2.6156e-01, time/batch = 16.7034s	
30413/33150 (epoch 45.872), train_loss = 0.85953499, grad/param norm = 2.0204e-01, time/batch = 19.2734s	
30414/33150 (epoch 45.873), train_loss = 0.67690264, grad/param norm = 1.7806e-01, time/batch = 16.9428s	
30415/33150 (epoch 45.875), train_loss = 0.89691127, grad/param norm = 1.9305e-01, time/batch = 17.2863s	
30416/33150 (epoch 45.876), train_loss = 0.65876398, grad/param norm = 1.7419e-01, time/batch = 15.2478s	
30417/33150 (epoch 45.878), train_loss = 0.73357309, grad/param norm = 1.6058e-01, time/batch = 15.0039s	
30418/33150 (epoch 45.879), train_loss = 0.73273952, grad/param norm = 1.7001e-01, time/batch = 15.3164s	
30419/33150 (epoch 45.881), train_loss = 0.71737841, grad/param norm = 1.6255e-01, time/batch = 15.0262s	
30420/33150 (epoch 45.882), train_loss = 0.59990775, grad/param norm = 1.5965e-01, time/batch = 15.2641s	
30421/33150 (epoch 45.884), train_loss = 0.72639995, grad/param norm = 1.6960e-01, time/batch = 15.0951s	
30422/33150 (epoch 45.885), train_loss = 0.61641749, grad/param norm = 1.8205e-01, time/batch = 15.4306s	
30423/33150 (epoch 45.887), train_loss = 0.85231296, grad/param norm = 1.9705e-01, time/batch = 17.2147s	
30424/33150 (epoch 45.888), train_loss = 0.80350610, grad/param norm = 1.8231e-01, time/batch = 16.4493s	
30425/33150 (epoch 45.890), train_loss = 0.69581894, grad/param norm = 1.6931e-01, time/batch = 18.2904s	
30426/33150 (epoch 45.891), train_loss = 0.70609201, grad/param norm = 1.9352e-01, time/batch = 16.7243s	
30427/33150 (epoch 45.893), train_loss = 0.80478448, grad/param norm = 1.8074e-01, time/batch = 18.8743s	
30428/33150 (epoch 45.894), train_loss = 0.80571414, grad/param norm = 1.6345e-01, time/batch = 16.7889s	
30429/33150 (epoch 45.896), train_loss = 0.77424128, grad/param norm = 1.8032e-01, time/batch = 16.2962s	
30430/33150 (epoch 45.897), train_loss = 0.82545182, grad/param norm = 1.6491e-01, time/batch = 17.6373s	
30431/33150 (epoch 45.899), train_loss = 0.65202612, grad/param norm = 2.1819e-01, time/batch = 17.4854s	
30432/33150 (epoch 45.900), train_loss = 0.94138868, grad/param norm = 1.9292e-01, time/batch = 15.2306s	
30433/33150 (epoch 45.902), train_loss = 0.98400810, grad/param norm = 1.9302e-01, time/batch = 16.9727s	
30434/33150 (epoch 45.903), train_loss = 0.82233768, grad/param norm = 1.8361e-01, time/batch = 17.3100s	
30435/33150 (epoch 45.905), train_loss = 0.77385797, grad/param norm = 1.5887e-01, time/batch = 17.8067s	
30436/33150 (epoch 45.906), train_loss = 0.80121169, grad/param norm = 2.2630e-01, time/batch = 15.9569s	
30437/33150 (epoch 45.908), train_loss = 0.83346777, grad/param norm = 1.9664e-01, time/batch = 15.9696s	
30438/33150 (epoch 45.910), train_loss = 0.87129458, grad/param norm = 1.8608e-01, time/batch = 16.5646s	
30439/33150 (epoch 45.911), train_loss = 0.69083558, grad/param norm = 1.8245e-01, time/batch = 17.0544s	
30440/33150 (epoch 45.913), train_loss = 0.74477810, grad/param norm = 1.7297e-01, time/batch = 16.6210s	
30441/33150 (epoch 45.914), train_loss = 0.79743549, grad/param norm = 2.1704e-01, time/batch = 17.1457s	
30442/33150 (epoch 45.916), train_loss = 0.73047981, grad/param norm = 1.7776e-01, time/batch = 16.4640s	
30443/33150 (epoch 45.917), train_loss = 0.80247952, grad/param norm = 1.8861e-01, time/batch = 16.2699s	
30444/33150 (epoch 45.919), train_loss = 0.90565197, grad/param norm = 2.0596e-01, time/batch = 16.7256s	
30445/33150 (epoch 45.920), train_loss = 0.87366359, grad/param norm = 2.0086e-01, time/batch = 17.5656s	
30446/33150 (epoch 45.922), train_loss = 0.92556564, grad/param norm = 2.7145e-01, time/batch = 16.6470s	
30447/33150 (epoch 45.923), train_loss = 0.81223993, grad/param norm = 1.9074e-01, time/batch = 16.7144s	
30448/33150 (epoch 45.925), train_loss = 0.86321279, grad/param norm = 1.8616e-01, time/batch = 15.6346s	
30449/33150 (epoch 45.926), train_loss = 0.79643814, grad/param norm = 1.7570e-01, time/batch = 15.8049s	
30450/33150 (epoch 45.928), train_loss = 0.77611878, grad/param norm = 1.7692e-01, time/batch = 16.0295s	
30451/33150 (epoch 45.929), train_loss = 0.83318266, grad/param norm = 1.7614e-01, time/batch = 15.6951s	
30452/33150 (epoch 45.931), train_loss = 0.88123712, grad/param norm = 2.2178e-01, time/batch = 15.5785s	
30453/33150 (epoch 45.932), train_loss = 0.81433145, grad/param norm = 2.5371e-01, time/batch = 15.3343s	
30454/33150 (epoch 45.934), train_loss = 0.81391177, grad/param norm = 1.7111e-01, time/batch = 15.1843s	
30455/33150 (epoch 45.935), train_loss = 0.87125205, grad/param norm = 1.9215e-01, time/batch = 15.5987s	
30456/33150 (epoch 45.937), train_loss = 0.90361591, grad/param norm = 1.6752e-01, time/batch = 15.3354s	
30457/33150 (epoch 45.938), train_loss = 0.83115575, grad/param norm = 1.7045e-01, time/batch = 15.4530s	
30458/33150 (epoch 45.940), train_loss = 1.01731582, grad/param norm = 2.1242e-01, time/batch = 18.7642s	
30459/33150 (epoch 45.941), train_loss = 0.85594090, grad/param norm = 1.6543e-01, time/batch = 29.9408s	
30460/33150 (epoch 45.943), train_loss = 0.65989216, grad/param norm = 1.7749e-01, time/batch = 14.5727s	
30461/33150 (epoch 45.944), train_loss = 0.84540164, grad/param norm = 1.9508e-01, time/batch = 14.9063s	
30462/33150 (epoch 45.946), train_loss = 0.70369403, grad/param norm = 1.4390e-01, time/batch = 14.6712s	
30463/33150 (epoch 45.947), train_loss = 0.82243377, grad/param norm = 1.7237e-01, time/batch = 15.4678s	
30464/33150 (epoch 45.949), train_loss = 0.88186489, grad/param norm = 1.8098e-01, time/batch = 14.9948s	
30465/33150 (epoch 45.950), train_loss = 0.87994349, grad/param norm = 1.9206e-01, time/batch = 15.3083s	
30466/33150 (epoch 45.952), train_loss = 0.74617054, grad/param norm = 1.7573e-01, time/batch = 16.4632s	
30467/33150 (epoch 45.953), train_loss = 0.80587666, grad/param norm = 1.7639e-01, time/batch = 18.0624s	
30468/33150 (epoch 45.955), train_loss = 0.67617270, grad/param norm = 1.7074e-01, time/batch = 16.4725s	
30469/33150 (epoch 45.956), train_loss = 0.85399912, grad/param norm = 1.9861e-01, time/batch = 16.5419s	
30470/33150 (epoch 45.958), train_loss = 0.72466766, grad/param norm = 1.6555e-01, time/batch = 17.1206s	
30471/33150 (epoch 45.959), train_loss = 0.80074246, grad/param norm = 1.9152e-01, time/batch = 15.8342s	
30472/33150 (epoch 45.961), train_loss = 0.72369682, grad/param norm = 1.7606e-01, time/batch = 15.8870s	
30473/33150 (epoch 45.962), train_loss = 0.67741115, grad/param norm = 1.5682e-01, time/batch = 18.0568s	
30474/33150 (epoch 45.964), train_loss = 0.78433939, grad/param norm = 1.8246e-01, time/batch = 16.2217s	
30475/33150 (epoch 45.965), train_loss = 0.78300389, grad/param norm = 1.9389e-01, time/batch = 16.6341s	
30476/33150 (epoch 45.967), train_loss = 0.77130869, grad/param norm = 1.8058e-01, time/batch = 15.1222s	
30477/33150 (epoch 45.968), train_loss = 0.66948171, grad/param norm = 1.7167e-01, time/batch = 15.6216s	
30478/33150 (epoch 45.970), train_loss = 0.75608272, grad/param norm = 2.0090e-01, time/batch = 17.4049s	
30479/33150 (epoch 45.971), train_loss = 0.79275100, grad/param norm = 1.6491e-01, time/batch = 17.2187s	
30480/33150 (epoch 45.973), train_loss = 0.86104361, grad/param norm = 1.9162e-01, time/batch = 16.0615s	
30481/33150 (epoch 45.974), train_loss = 0.89276396, grad/param norm = 2.0800e-01, time/batch = 17.7248s	
30482/33150 (epoch 45.976), train_loss = 0.86278810, grad/param norm = 1.7002e-01, time/batch = 16.4054s	
30483/33150 (epoch 45.977), train_loss = 0.91231455, grad/param norm = 2.0993e-01, time/batch = 15.4808s	
30484/33150 (epoch 45.979), train_loss = 0.87929328, grad/param norm = 2.0245e-01, time/batch = 17.1618s	
30485/33150 (epoch 45.980), train_loss = 0.93738050, grad/param norm = 2.2285e-01, time/batch = 17.3876s	
30486/33150 (epoch 45.982), train_loss = 0.80114691, grad/param norm = 1.8901e-01, time/batch = 15.6383s	
30487/33150 (epoch 45.983), train_loss = 0.71839523, grad/param norm = 1.6173e-01, time/batch = 15.8261s	
30488/33150 (epoch 45.985), train_loss = 0.91494889, grad/param norm = 1.9421e-01, time/batch = 15.4768s	
30489/33150 (epoch 45.986), train_loss = 0.69157143, grad/param norm = 1.7325e-01, time/batch = 17.5575s	
30490/33150 (epoch 45.988), train_loss = 0.76084629, grad/param norm = 2.0690e-01, time/batch = 15.3006s	
30491/33150 (epoch 45.989), train_loss = 0.79431779, grad/param norm = 1.8956e-01, time/batch = 16.6402s	
30492/33150 (epoch 45.991), train_loss = 0.81684761, grad/param norm = 2.8536e-01, time/batch = 18.3947s	
30493/33150 (epoch 45.992), train_loss = 0.78350976, grad/param norm = 1.7794e-01, time/batch = 16.3913s	
30494/33150 (epoch 45.994), train_loss = 0.82324409, grad/param norm = 1.7679e-01, time/batch = 16.1270s	
30495/33150 (epoch 45.995), train_loss = 0.77213737, grad/param norm = 2.1857e-01, time/batch = 17.2615s	
30496/33150 (epoch 45.997), train_loss = 0.79689241, grad/param norm = 1.8608e-01, time/batch = 15.9753s	
30497/33150 (epoch 45.998), train_loss = 0.66233375, grad/param norm = 1.6697e-01, time/batch = 18.3693s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
30498/33150 (epoch 46.000), train_loss = 0.70107879, grad/param norm = 1.9045e-01, time/batch = 17.8755s	
30499/33150 (epoch 46.002), train_loss = 1.07954040, grad/param norm = 1.9852e-01, time/batch = 18.3952s	
30500/33150 (epoch 46.003), train_loss = 0.72079918, grad/param norm = 1.7008e-01, time/batch = 17.9556s	
30501/33150 (epoch 46.005), train_loss = 0.68853244, grad/param norm = 1.5716e-01, time/batch = 18.1832s	
30502/33150 (epoch 46.006), train_loss = 0.66825167, grad/param norm = 1.6444e-01, time/batch = 18.0472s	
30503/33150 (epoch 46.008), train_loss = 0.85238686, grad/param norm = 2.0745e-01, time/batch = 16.9674s	
30504/33150 (epoch 46.009), train_loss = 0.82288362, grad/param norm = 1.8699e-01, time/batch = 17.4681s	
30505/33150 (epoch 46.011), train_loss = 0.87397352, grad/param norm = 1.7935e-01, time/batch = 17.1576s	
30506/33150 (epoch 46.012), train_loss = 0.77155621, grad/param norm = 2.7457e-01, time/batch = 17.6231s	
30507/33150 (epoch 46.014), train_loss = 0.71865523, grad/param norm = 1.8475e-01, time/batch = 17.5446s	
30508/33150 (epoch 46.015), train_loss = 0.72001788, grad/param norm = 1.8612e-01, time/batch = 18.3046s	
30509/33150 (epoch 46.017), train_loss = 0.70857027, grad/param norm = 1.6370e-01, time/batch = 17.9664s	
30510/33150 (epoch 46.018), train_loss = 0.80377935, grad/param norm = 2.3501e-01, time/batch = 16.3961s	
30511/33150 (epoch 46.020), train_loss = 0.86038238, grad/param norm = 2.0108e-01, time/batch = 17.2030s	
30512/33150 (epoch 46.021), train_loss = 0.73869733, grad/param norm = 1.7958e-01, time/batch = 17.2979s	
30513/33150 (epoch 46.023), train_loss = 0.95597200, grad/param norm = 1.8189e-01, time/batch = 16.6972s	
30514/33150 (epoch 46.024), train_loss = 0.85012948, grad/param norm = 2.1683e-01, time/batch = 16.4605s	
30515/33150 (epoch 46.026), train_loss = 0.62156626, grad/param norm = 1.6502e-01, time/batch = 17.4797s	
30516/33150 (epoch 46.027), train_loss = 0.65594210, grad/param norm = 1.8051e-01, time/batch = 18.2949s	
30517/33150 (epoch 46.029), train_loss = 0.72822484, grad/param norm = 1.9664e-01, time/batch = 16.8953s	
30518/33150 (epoch 46.030), train_loss = 0.78343121, grad/param norm = 1.5285e-01, time/batch = 16.6866s	
30519/33150 (epoch 46.032), train_loss = 0.68731928, grad/param norm = 1.8919e-01, time/batch = 18.0208s	
30520/33150 (epoch 46.033), train_loss = 0.72062797, grad/param norm = 1.7688e-01, time/batch = 17.9610s	
30521/33150 (epoch 46.035), train_loss = 0.94871065, grad/param norm = 2.4746e-01, time/batch = 15.5132s	
30522/33150 (epoch 46.036), train_loss = 0.85944944, grad/param norm = 1.9637e-01, time/batch = 15.2537s	
30523/33150 (epoch 46.038), train_loss = 0.95977135, grad/param norm = 1.9338e-01, time/batch = 15.1957s	
30524/33150 (epoch 46.039), train_loss = 0.85349929, grad/param norm = 1.7024e-01, time/batch = 15.1747s	
30525/33150 (epoch 46.041), train_loss = 0.78116261, grad/param norm = 1.7107e-01, time/batch = 15.4330s	
30526/33150 (epoch 46.042), train_loss = 0.72354795, grad/param norm = 1.8191e-01, time/batch = 17.0711s	
30527/33150 (epoch 46.044), train_loss = 0.80496707, grad/param norm = 1.9823e-01, time/batch = 17.6300s	
30528/33150 (epoch 46.045), train_loss = 0.86180587, grad/param norm = 1.5866e-01, time/batch = 17.7074s	
30529/33150 (epoch 46.047), train_loss = 0.72665127, grad/param norm = 1.8713e-01, time/batch = 16.3814s	
30530/33150 (epoch 46.048), train_loss = 0.84604981, grad/param norm = 2.2495e-01, time/batch = 16.7293s	
30531/33150 (epoch 46.050), train_loss = 0.77271620, grad/param norm = 2.2480e-01, time/batch = 18.3902s	
30532/33150 (epoch 46.051), train_loss = 0.82202837, grad/param norm = 1.6758e-01, time/batch = 17.3094s	
30533/33150 (epoch 46.053), train_loss = 0.82989693, grad/param norm = 1.8117e-01, time/batch = 17.3963s	
30534/33150 (epoch 46.054), train_loss = 0.92542060, grad/param norm = 1.7946e-01, time/batch = 16.4044s	
30535/33150 (epoch 46.056), train_loss = 0.78449538, grad/param norm = 1.8382e-01, time/batch = 16.9711s	
30536/33150 (epoch 46.057), train_loss = 0.84274751, grad/param norm = 1.5970e-01, time/batch = 15.7893s	
30537/33150 (epoch 46.059), train_loss = 0.70931334, grad/param norm = 1.8498e-01, time/batch = 16.9886s	
30538/33150 (epoch 46.060), train_loss = 0.70013960, grad/param norm = 1.5275e-01, time/batch = 16.2781s	
30539/33150 (epoch 46.062), train_loss = 0.79043217, grad/param norm = 2.0133e-01, time/batch = 17.0572s	
30540/33150 (epoch 46.063), train_loss = 0.72313080, grad/param norm = 1.8273e-01, time/batch = 16.7332s	
30541/33150 (epoch 46.065), train_loss = 0.78615179, grad/param norm = 1.6145e-01, time/batch = 17.2988s	
30542/33150 (epoch 46.066), train_loss = 0.77767082, grad/param norm = 1.8031e-01, time/batch = 15.7884s	
30543/33150 (epoch 46.068), train_loss = 0.83383075, grad/param norm = 1.6231e-01, time/batch = 15.8063s	
30544/33150 (epoch 46.069), train_loss = 0.82900784, grad/param norm = 2.0609e-01, time/batch = 15.8908s	
30545/33150 (epoch 46.071), train_loss = 0.83080013, grad/param norm = 1.9340e-01, time/batch = 16.9034s	
30546/33150 (epoch 46.072), train_loss = 0.80438010, grad/param norm = 1.8129e-01, time/batch = 18.9321s	
30547/33150 (epoch 46.074), train_loss = 0.67592500, grad/param norm = 2.1324e-01, time/batch = 18.2544s	
30548/33150 (epoch 46.075), train_loss = 0.69978400, grad/param norm = 1.9988e-01, time/batch = 17.5110s	
30549/33150 (epoch 46.077), train_loss = 0.80928244, grad/param norm = 2.5384e-01, time/batch = 18.1953s	
30550/33150 (epoch 46.078), train_loss = 0.91308549, grad/param norm = 2.0635e-01, time/batch = 18.2709s	
30551/33150 (epoch 46.080), train_loss = 0.90521239, grad/param norm = 1.8180e-01, time/batch = 18.6807s	
30552/33150 (epoch 46.081), train_loss = 0.72537222, grad/param norm = 2.0766e-01, time/batch = 19.6008s	
30553/33150 (epoch 46.083), train_loss = 0.57551251, grad/param norm = 1.9840e-01, time/batch = 19.5149s	
30554/33150 (epoch 46.084), train_loss = 0.68212838, grad/param norm = 2.4777e-01, time/batch = 20.4438s	
30555/33150 (epoch 46.086), train_loss = 0.74410362, grad/param norm = 2.3119e-01, time/batch = 21.2068s	
30556/33150 (epoch 46.087), train_loss = 0.67025518, grad/param norm = 1.8253e-01, time/batch = 18.6239s	
30557/33150 (epoch 46.089), train_loss = 0.72774097, grad/param norm = 1.8168e-01, time/batch = 21.9589s	
30558/33150 (epoch 46.090), train_loss = 0.76163326, grad/param norm = 1.8747e-01, time/batch = 23.7587s	
30559/33150 (epoch 46.092), train_loss = 0.73433890, grad/param norm = 2.4024e-01, time/batch = 22.4855s	
30560/33150 (epoch 46.094), train_loss = 0.82710506, grad/param norm = 2.2818e-01, time/batch = 16.2339s	
30561/33150 (epoch 46.095), train_loss = 0.71979491, grad/param norm = 1.8154e-01, time/batch = 18.5501s	
30562/33150 (epoch 46.097), train_loss = 0.65861743, grad/param norm = 1.8055e-01, time/batch = 15.2763s	
30563/33150 (epoch 46.098), train_loss = 1.01680069, grad/param norm = 1.9137e-01, time/batch = 18.1414s	
30564/33150 (epoch 46.100), train_loss = 0.97267408, grad/param norm = 2.3905e-01, time/batch = 16.2213s	
30565/33150 (epoch 46.101), train_loss = 0.71779987, grad/param norm = 1.8337e-01, time/batch = 16.4664s	
30566/33150 (epoch 46.103), train_loss = 0.80757062, grad/param norm = 1.6175e-01, time/batch = 17.8938s	
30567/33150 (epoch 46.104), train_loss = 0.72841214, grad/param norm = 1.9413e-01, time/batch = 16.6468s	
30568/33150 (epoch 46.106), train_loss = 0.91671285, grad/param norm = 2.1118e-01, time/batch = 18.6436s	
30569/33150 (epoch 46.107), train_loss = 0.97353185, grad/param norm = 2.1991e-01, time/batch = 16.3567s	
30570/33150 (epoch 46.109), train_loss = 0.76650708, grad/param norm = 1.6436e-01, time/batch = 19.6123s	
30571/33150 (epoch 46.110), train_loss = 0.87009983, grad/param norm = 1.9558e-01, time/batch = 17.5681s	
30572/33150 (epoch 46.112), train_loss = 0.69755263, grad/param norm = 1.6429e-01, time/batch = 16.8117s	
30573/33150 (epoch 46.113), train_loss = 0.75595146, grad/param norm = 1.9937e-01, time/batch = 17.7944s	
30574/33150 (epoch 46.115), train_loss = 0.96323576, grad/param norm = 1.9496e-01, time/batch = 16.1923s	
30575/33150 (epoch 46.116), train_loss = 0.85455711, grad/param norm = 1.7947e-01, time/batch = 16.7686s	
30576/33150 (epoch 46.118), train_loss = 0.83086838, grad/param norm = 2.0686e-01, time/batch = 17.0334s	
30577/33150 (epoch 46.119), train_loss = 0.85706791, grad/param norm = 2.1447e-01, time/batch = 17.6422s	
30578/33150 (epoch 46.121), train_loss = 0.78672318, grad/param norm = 1.8213e-01, time/batch = 18.4593s	
30579/33150 (epoch 46.122), train_loss = 0.91883696, grad/param norm = 2.3663e-01, time/batch = 16.1165s	
30580/33150 (epoch 46.124), train_loss = 0.66835054, grad/param norm = 1.4089e-01, time/batch = 16.3052s	
30581/33150 (epoch 46.125), train_loss = 0.92416905, grad/param norm = 1.9477e-01, time/batch = 15.8733s	
30582/33150 (epoch 46.127), train_loss = 0.83582151, grad/param norm = 1.8092e-01, time/batch = 16.1495s	
30583/33150 (epoch 46.128), train_loss = 0.84614891, grad/param norm = 1.9934e-01, time/batch = 16.4716s	
30584/33150 (epoch 46.130), train_loss = 0.79302438, grad/param norm = 1.8578e-01, time/batch = 17.6525s	
30585/33150 (epoch 46.131), train_loss = 0.97180730, grad/param norm = 2.5522e-01, time/batch = 15.8872s	
30586/33150 (epoch 46.133), train_loss = 0.74445756, grad/param norm = 1.8353e-01, time/batch = 16.5583s	
30587/33150 (epoch 46.134), train_loss = 0.90721080, grad/param norm = 1.7574e-01, time/batch = 16.2266s	
30588/33150 (epoch 46.136), train_loss = 0.80822009, grad/param norm = 1.7920e-01, time/batch = 16.8096s	
30589/33150 (epoch 46.137), train_loss = 0.84931014, grad/param norm = 1.7087e-01, time/batch = 18.2035s	
30590/33150 (epoch 46.139), train_loss = 0.87022523, grad/param norm = 2.1365e-01, time/batch = 16.8810s	
30591/33150 (epoch 46.140), train_loss = 0.94527470, grad/param norm = 1.9728e-01, time/batch = 16.6392s	
30592/33150 (epoch 46.142), train_loss = 0.85055234, grad/param norm = 2.4836e-01, time/batch = 16.5409s	
30593/33150 (epoch 46.143), train_loss = 0.78877304, grad/param norm = 2.2053e-01, time/batch = 16.1265s	
30594/33150 (epoch 46.145), train_loss = 0.76253938, grad/param norm = 2.9022e-01, time/batch = 15.8817s	
30595/33150 (epoch 46.146), train_loss = 0.89207701, grad/param norm = 2.3261e-01, time/batch = 19.1204s	
30596/33150 (epoch 46.148), train_loss = 0.96917169, grad/param norm = 1.9600e-01, time/batch = 19.2939s	
30597/33150 (epoch 46.149), train_loss = 0.83247238, grad/param norm = 2.0437e-01, time/batch = 15.7890s	
30598/33150 (epoch 46.151), train_loss = 0.96453501, grad/param norm = 2.2552e-01, time/batch = 18.7747s	
30599/33150 (epoch 46.152), train_loss = 0.74446021, grad/param norm = 1.6662e-01, time/batch = 16.8017s	
30600/33150 (epoch 46.154), train_loss = 0.73477160, grad/param norm = 2.0635e-01, time/batch = 18.4629s	
30601/33150 (epoch 46.155), train_loss = 0.68713345, grad/param norm = 1.8492e-01, time/batch = 17.5377s	
30602/33150 (epoch 46.157), train_loss = 0.78843781, grad/param norm = 2.1310e-01, time/batch = 17.9807s	
30603/33150 (epoch 46.158), train_loss = 0.76999759, grad/param norm = 1.5712e-01, time/batch = 17.8880s	
30604/33150 (epoch 46.160), train_loss = 0.87373930, grad/param norm = 1.8767e-01, time/batch = 16.1395s	
30605/33150 (epoch 46.161), train_loss = 0.78477707, grad/param norm = 2.2135e-01, time/batch = 19.3035s	
30606/33150 (epoch 46.163), train_loss = 0.70533824, grad/param norm = 1.7637e-01, time/batch = 17.3945s	
30607/33150 (epoch 46.164), train_loss = 0.82453187, grad/param norm = 1.6547e-01, time/batch = 16.3764s	
30608/33150 (epoch 46.166), train_loss = 0.75624208, grad/param norm = 1.7316e-01, time/batch = 15.8101s	
30609/33150 (epoch 46.167), train_loss = 0.82713635, grad/param norm = 1.5806e-01, time/batch = 19.0275s	
30610/33150 (epoch 46.169), train_loss = 0.81303210, grad/param norm = 2.1136e-01, time/batch = 17.0514s	
30611/33150 (epoch 46.170), train_loss = 0.70992956, grad/param norm = 2.1579e-01, time/batch = 17.1499s	
30612/33150 (epoch 46.172), train_loss = 0.83031806, grad/param norm = 2.0425e-01, time/batch = 16.1515s	
30613/33150 (epoch 46.173), train_loss = 0.82000271, grad/param norm = 2.3405e-01, time/batch = 18.8085s	
30614/33150 (epoch 46.175), train_loss = 0.75911150, grad/param norm = 1.8578e-01, time/batch = 15.4450s	
30615/33150 (epoch 46.176), train_loss = 0.86727313, grad/param norm = 2.1213e-01, time/batch = 15.8588s	
30616/33150 (epoch 46.178), train_loss = 0.97111066, grad/param norm = 2.1617e-01, time/batch = 15.2981s	
30617/33150 (epoch 46.179), train_loss = 0.85616275, grad/param norm = 1.6814e-01, time/batch = 15.1563s	
30618/33150 (epoch 46.181), train_loss = 0.81181249, grad/param norm = 2.0275e-01, time/batch = 15.4313s	
30619/33150 (epoch 46.183), train_loss = 0.79561454, grad/param norm = 2.5030e-01, time/batch = 15.4930s	
30620/33150 (epoch 46.184), train_loss = 1.04035457, grad/param norm = 2.0332e-01, time/batch = 15.3929s	
30621/33150 (epoch 46.186), train_loss = 0.98120340, grad/param norm = 1.9556e-01, time/batch = 17.5397s	
30622/33150 (epoch 46.187), train_loss = 0.81343598, grad/param norm = 1.9889e-01, time/batch = 16.7255s	
30623/33150 (epoch 46.189), train_loss = 0.63972758, grad/param norm = 1.7416e-01, time/batch = 17.8800s	
30624/33150 (epoch 46.190), train_loss = 0.72893776, grad/param norm = 2.0138e-01, time/batch = 17.7949s	
30625/33150 (epoch 46.192), train_loss = 0.82350241, grad/param norm = 1.8886e-01, time/batch = 16.4784s	
30626/33150 (epoch 46.193), train_loss = 0.86960063, grad/param norm = 1.8426e-01, time/batch = 15.9788s	
30627/33150 (epoch 46.195), train_loss = 0.98062220, grad/param norm = 1.9839e-01, time/batch = 19.1453s	
30628/33150 (epoch 46.196), train_loss = 0.92546313, grad/param norm = 2.0215e-01, time/batch = 16.8682s	
30629/33150 (epoch 46.198), train_loss = 0.71906862, grad/param norm = 1.5286e-01, time/batch = 16.4698s	
30630/33150 (epoch 46.199), train_loss = 0.89359384, grad/param norm = 2.4649e-01, time/batch = 17.8880s	
30631/33150 (epoch 46.201), train_loss = 0.78794802, grad/param norm = 1.8182e-01, time/batch = 16.6350s	
30632/33150 (epoch 46.202), train_loss = 0.65677573, grad/param norm = 1.7898e-01, time/batch = 15.7906s	
30633/33150 (epoch 46.204), train_loss = 0.80549119, grad/param norm = 2.0911e-01, time/batch = 15.3733s	
30634/33150 (epoch 46.205), train_loss = 0.82848199, grad/param norm = 2.0208e-01, time/batch = 16.8124s	
30635/33150 (epoch 46.207), train_loss = 0.82641249, grad/param norm = 1.6391e-01, time/batch = 15.4551s	
30636/33150 (epoch 46.208), train_loss = 0.90064272, grad/param norm = 2.0601e-01, time/batch = 17.6173s	
30637/33150 (epoch 46.210), train_loss = 0.74931877, grad/param norm = 1.5740e-01, time/batch = 16.7017s	
30638/33150 (epoch 46.211), train_loss = 0.79524866, grad/param norm = 2.1303e-01, time/batch = 15.8841s	
30639/33150 (epoch 46.213), train_loss = 0.88835484, grad/param norm = 1.9685e-01, time/batch = 17.6966s	
30640/33150 (epoch 46.214), train_loss = 0.77273588, grad/param norm = 1.8704e-01, time/batch = 18.1841s	
30641/33150 (epoch 46.216), train_loss = 0.73311580, grad/param norm = 1.9852e-01, time/batch = 18.0512s	
30642/33150 (epoch 46.217), train_loss = 0.82221816, grad/param norm = 1.7438e-01, time/batch = 17.5640s	
30643/33150 (epoch 46.219), train_loss = 0.75619596, grad/param norm = 1.9885e-01, time/batch = 16.3208s	
30644/33150 (epoch 46.220), train_loss = 0.78560133, grad/param norm = 1.7149e-01, time/batch = 16.7328s	
30645/33150 (epoch 46.222), train_loss = 0.88608974, grad/param norm = 1.9109e-01, time/batch = 17.7232s	
30646/33150 (epoch 46.223), train_loss = 0.80819384, grad/param norm = 1.9919e-01, time/batch = 15.6233s	
30647/33150 (epoch 46.225), train_loss = 0.92654780, grad/param norm = 2.0027e-01, time/batch = 17.1422s	
30648/33150 (epoch 46.226), train_loss = 0.78535712, grad/param norm = 1.8853e-01, time/batch = 16.6432s	
30649/33150 (epoch 46.228), train_loss = 0.76787408, grad/param norm = 2.0096e-01, time/batch = 16.2906s	
30650/33150 (epoch 46.229), train_loss = 0.79916009, grad/param norm = 1.9993e-01, time/batch = 16.5196s	
30651/33150 (epoch 46.231), train_loss = 0.88614368, grad/param norm = 2.3431e-01, time/batch = 15.6416s	
30652/33150 (epoch 46.232), train_loss = 0.79424929, grad/param norm = 2.1002e-01, time/batch = 17.9547s	
30653/33150 (epoch 46.234), train_loss = 0.83906084, grad/param norm = 2.1131e-01, time/batch = 16.7965s	
30654/33150 (epoch 46.235), train_loss = 0.87476096, grad/param norm = 2.8442e-01, time/batch = 17.5489s	
30655/33150 (epoch 46.237), train_loss = 0.83269587, grad/param norm = 2.5030e-01, time/batch = 16.1349s	
30656/33150 (epoch 46.238), train_loss = 0.86593974, grad/param norm = 2.0858e-01, time/batch = 16.6453s	
30657/33150 (epoch 46.240), train_loss = 0.81624138, grad/param norm = 1.9756e-01, time/batch = 16.8919s	
30658/33150 (epoch 46.241), train_loss = 0.89671705, grad/param norm = 2.1894e-01, time/batch = 16.2976s	
30659/33150 (epoch 46.243), train_loss = 0.85515237, grad/param norm = 1.8915e-01, time/batch = 18.5587s	
30660/33150 (epoch 46.244), train_loss = 0.84549932, grad/param norm = 1.8597e-01, time/batch = 15.6510s	
30661/33150 (epoch 46.246), train_loss = 0.88183748, grad/param norm = 1.9627e-01, time/batch = 17.0459s	
30662/33150 (epoch 46.247), train_loss = 0.77412821, grad/param norm = 1.7550e-01, time/batch = 15.9057s	
30663/33150 (epoch 46.249), train_loss = 0.93693084, grad/param norm = 1.9350e-01, time/batch = 15.7314s	
30664/33150 (epoch 46.250), train_loss = 0.86289452, grad/param norm = 1.7498e-01, time/batch = 15.2082s	
30665/33150 (epoch 46.252), train_loss = 0.87153744, grad/param norm = 1.5789e-01, time/batch = 17.9735s	
30666/33150 (epoch 46.253), train_loss = 0.78906110, grad/param norm = 1.9431e-01, time/batch = 17.7102s	
30667/33150 (epoch 46.255), train_loss = 0.79752620, grad/param norm = 1.5901e-01, time/batch = 16.5482s	
30668/33150 (epoch 46.256), train_loss = 0.90887974, grad/param norm = 1.8990e-01, time/batch = 23.5007s	
30669/33150 (epoch 46.258), train_loss = 0.78991929, grad/param norm = 1.9983e-01, time/batch = 26.2882s	
30670/33150 (epoch 46.259), train_loss = 0.66202686, grad/param norm = 2.2004e-01, time/batch = 16.8862s	
30671/33150 (epoch 46.261), train_loss = 0.74220485, grad/param norm = 1.7121e-01, time/batch = 19.3687s	
30672/33150 (epoch 46.262), train_loss = 0.94106161, grad/param norm = 1.9315e-01, time/batch = 16.5594s	
30673/33150 (epoch 46.264), train_loss = 0.63943565, grad/param norm = 1.4854e-01, time/batch = 16.8106s	
30674/33150 (epoch 46.265), train_loss = 0.81930948, grad/param norm = 1.8701e-01, time/batch = 16.9700s	
30675/33150 (epoch 46.267), train_loss = 0.91953709, grad/param norm = 2.1291e-01, time/batch = 16.2994s	
30676/33150 (epoch 46.268), train_loss = 0.95564556, grad/param norm = 1.8995e-01, time/batch = 18.6299s	
30677/33150 (epoch 46.270), train_loss = 0.99806760, grad/param norm = 1.8741e-01, time/batch = 17.4689s	
30678/33150 (epoch 46.271), train_loss = 0.86838502, grad/param norm = 2.2701e-01, time/batch = 16.7954s	
30679/33150 (epoch 46.273), train_loss = 0.91877697, grad/param norm = 1.8823e-01, time/batch = 18.3056s	
30680/33150 (epoch 46.275), train_loss = 0.93152479, grad/param norm = 1.8982e-01, time/batch = 17.0957s	
30681/33150 (epoch 46.276), train_loss = 0.80071857, grad/param norm = 1.8899e-01, time/batch = 18.1352s	
30682/33150 (epoch 46.278), train_loss = 0.93535693, grad/param norm = 1.9081e-01, time/batch = 17.8817s	
30683/33150 (epoch 46.279), train_loss = 0.91804305, grad/param norm = 1.8554e-01, time/batch = 18.3866s	
30684/33150 (epoch 46.281), train_loss = 0.82230826, grad/param norm = 1.7451e-01, time/batch = 16.8530s	
30685/33150 (epoch 46.282), train_loss = 0.87203673, grad/param norm = 1.6510e-01, time/batch = 17.3180s	
30686/33150 (epoch 46.284), train_loss = 0.76162035, grad/param norm = 1.6863e-01, time/batch = 16.7935s	
30687/33150 (epoch 46.285), train_loss = 0.86675355, grad/param norm = 1.9047e-01, time/batch = 17.4663s	
30688/33150 (epoch 46.287), train_loss = 0.74816604, grad/param norm = 1.7967e-01, time/batch = 18.2121s	
30689/33150 (epoch 46.288), train_loss = 0.89383656, grad/param norm = 1.9439e-01, time/batch = 17.0561s	
30690/33150 (epoch 46.290), train_loss = 0.68734928, grad/param norm = 1.4431e-01, time/batch = 18.7136s	
30691/33150 (epoch 46.291), train_loss = 0.69429292, grad/param norm = 1.9481e-01, time/batch = 17.7355s	
30692/33150 (epoch 46.293), train_loss = 0.77581630, grad/param norm = 2.0328e-01, time/batch = 18.8917s	
30693/33150 (epoch 46.294), train_loss = 0.65816536, grad/param norm = 2.0137e-01, time/batch = 18.2330s	
30694/33150 (epoch 46.296), train_loss = 0.81922652, grad/param norm = 1.7252e-01, time/batch = 16.4006s	
30695/33150 (epoch 46.297), train_loss = 0.74931736, grad/param norm = 1.6887e-01, time/batch = 17.0297s	
30696/33150 (epoch 46.299), train_loss = 0.74517145, grad/param norm = 2.0089e-01, time/batch = 17.1527s	
30697/33150 (epoch 46.300), train_loss = 0.77569126, grad/param norm = 1.5108e-01, time/batch = 16.0385s	
30698/33150 (epoch 46.302), train_loss = 0.78315491, grad/param norm = 1.6408e-01, time/batch = 16.7877s	
30699/33150 (epoch 46.303), train_loss = 0.78086702, grad/param norm = 1.8759e-01, time/batch = 18.2238s	
30700/33150 (epoch 46.305), train_loss = 0.86587788, grad/param norm = 1.8192e-01, time/batch = 18.9590s	
30701/33150 (epoch 46.306), train_loss = 0.85619297, grad/param norm = 1.9526e-01, time/batch = 16.1282s	
30702/33150 (epoch 46.308), train_loss = 0.99609599, grad/param norm = 1.8883e-01, time/batch = 18.1308s	
30703/33150 (epoch 46.309), train_loss = 0.66867698, grad/param norm = 1.6542e-01, time/batch = 16.1098s	
30704/33150 (epoch 46.311), train_loss = 0.79949339, grad/param norm = 1.8265e-01, time/batch = 18.0481s	
30705/33150 (epoch 46.312), train_loss = 0.67336169, grad/param norm = 1.6109e-01, time/batch = 19.5272s	
30706/33150 (epoch 46.314), train_loss = 0.78909920, grad/param norm = 2.0366e-01, time/batch = 18.8653s	
30707/33150 (epoch 46.315), train_loss = 0.85654083, grad/param norm = 1.8200e-01, time/batch = 18.2811s	
30708/33150 (epoch 46.317), train_loss = 0.65472842, grad/param norm = 1.4494e-01, time/batch = 16.9644s	
30709/33150 (epoch 46.318), train_loss = 0.76001172, grad/param norm = 1.7445e-01, time/batch = 19.2099s	
30710/33150 (epoch 46.320), train_loss = 0.68665491, grad/param norm = 1.9101e-01, time/batch = 18.7181s	
30711/33150 (epoch 46.321), train_loss = 0.77373373, grad/param norm = 1.6222e-01, time/batch = 16.6307s	
30712/33150 (epoch 46.323), train_loss = 0.75309026, grad/param norm = 1.8109e-01, time/batch = 19.6200s	
30713/33150 (epoch 46.324), train_loss = 0.77638899, grad/param norm = 2.3972e-01, time/batch = 19.0538s	
30714/33150 (epoch 46.326), train_loss = 0.78546173, grad/param norm = 1.6866e-01, time/batch = 16.3771s	
30715/33150 (epoch 46.327), train_loss = 0.90661378, grad/param norm = 1.8538e-01, time/batch = 19.6118s	
30716/33150 (epoch 46.329), train_loss = 0.86837622, grad/param norm = 2.0884e-01, time/batch = 16.5407s	
30717/33150 (epoch 46.330), train_loss = 0.76202543, grad/param norm = 1.8183e-01, time/batch = 17.3021s	
30718/33150 (epoch 46.332), train_loss = 0.77385436, grad/param norm = 1.6961e-01, time/batch = 16.9775s	
30719/33150 (epoch 46.333), train_loss = 0.84573571, grad/param norm = 1.6727e-01, time/batch = 17.9646s	
30720/33150 (epoch 46.335), train_loss = 0.72873231, grad/param norm = 1.9029e-01, time/batch = 16.0354s	
30721/33150 (epoch 46.336), train_loss = 0.73820877, grad/param norm = 1.9834e-01, time/batch = 15.8007s	
30722/33150 (epoch 46.338), train_loss = 0.66569613, grad/param norm = 1.7774e-01, time/batch = 18.7198s	
30723/33150 (epoch 46.339), train_loss = 0.86218878, grad/param norm = 2.0091e-01, time/batch = 17.3878s	
30724/33150 (epoch 46.341), train_loss = 0.80339984, grad/param norm = 2.3398e-01, time/batch = 17.1056s	
30725/33150 (epoch 46.342), train_loss = 0.72765355, grad/param norm = 1.7292e-01, time/batch = 17.8076s	
30726/33150 (epoch 46.344), train_loss = 0.78047308, grad/param norm = 1.7921e-01, time/batch = 18.1358s	
30727/33150 (epoch 46.345), train_loss = 0.78472786, grad/param norm = 2.0333e-01, time/batch = 17.0560s	
30728/33150 (epoch 46.347), train_loss = 0.69183216, grad/param norm = 2.1075e-01, time/batch = 17.5374s	
30729/33150 (epoch 46.348), train_loss = 0.80705133, grad/param norm = 1.6924e-01, time/batch = 18.3125s	
30730/33150 (epoch 46.350), train_loss = 0.71161948, grad/param norm = 1.8942e-01, time/batch = 17.7268s	
30731/33150 (epoch 46.351), train_loss = 0.86793926, grad/param norm = 1.9381e-01, time/batch = 15.8872s	
30732/33150 (epoch 46.353), train_loss = 0.83093173, grad/param norm = 1.9142e-01, time/batch = 18.2983s	
30733/33150 (epoch 46.354), train_loss = 1.00962623, grad/param norm = 1.9801e-01, time/batch = 17.9747s	
30734/33150 (epoch 46.356), train_loss = 0.88726026, grad/param norm = 1.8882e-01, time/batch = 17.1301s	
30735/33150 (epoch 46.357), train_loss = 0.82886126, grad/param norm = 2.1767e-01, time/batch = 17.7118s	
30736/33150 (epoch 46.359), train_loss = 0.88898222, grad/param norm = 1.9661e-01, time/batch = 17.3742s	
30737/33150 (epoch 46.360), train_loss = 0.84543784, grad/param norm = 1.9177e-01, time/batch = 16.1243s	
30738/33150 (epoch 46.362), train_loss = 0.92191689, grad/param norm = 1.9310e-01, time/batch = 17.7219s	
30739/33150 (epoch 46.363), train_loss = 0.82806066, grad/param norm = 1.8036e-01, time/batch = 17.9693s	
30740/33150 (epoch 46.365), train_loss = 0.78209082, grad/param norm = 1.6169e-01, time/batch = 19.2240s	
30741/33150 (epoch 46.367), train_loss = 0.76804231, grad/param norm = 1.6201e-01, time/batch = 19.5291s	
30742/33150 (epoch 46.368), train_loss = 0.78779812, grad/param norm = 2.6465e-01, time/batch = 18.2983s	
30743/33150 (epoch 46.370), train_loss = 0.85004030, grad/param norm = 2.3161e-01, time/batch = 20.2088s	
30744/33150 (epoch 46.371), train_loss = 0.70712626, grad/param norm = 1.7184e-01, time/batch = 18.0483s	
30745/33150 (epoch 46.373), train_loss = 0.84200023, grad/param norm = 2.0917e-01, time/batch = 18.7194s	
30746/33150 (epoch 46.374), train_loss = 0.83199581, grad/param norm = 1.7059e-01, time/batch = 16.9571s	
30747/33150 (epoch 46.376), train_loss = 0.88090911, grad/param norm = 1.6834e-01, time/batch = 17.8757s	
30748/33150 (epoch 46.377), train_loss = 0.73172233, grad/param norm = 1.7904e-01, time/batch = 17.5500s	
30749/33150 (epoch 46.379), train_loss = 0.83369066, grad/param norm = 2.0537e-01, time/batch = 16.0461s	
30750/33150 (epoch 46.380), train_loss = 0.86759160, grad/param norm = 1.6953e-01, time/batch = 19.2992s	
30751/33150 (epoch 46.382), train_loss = 0.79750858, grad/param norm = 1.7240e-01, time/batch = 15.4001s	
30752/33150 (epoch 46.383), train_loss = 0.72396219, grad/param norm = 1.6523e-01, time/batch = 15.1824s	
30753/33150 (epoch 46.385), train_loss = 0.75122510, grad/param norm = 1.8964e-01, time/batch = 15.1233s	
30754/33150 (epoch 46.386), train_loss = 0.70747679, grad/param norm = 1.4365e-01, time/batch = 15.2828s	
30755/33150 (epoch 46.388), train_loss = 0.72780549, grad/param norm = 1.7671e-01, time/batch = 15.3471s	
30756/33150 (epoch 46.389), train_loss = 0.72806013, grad/param norm = 1.7260e-01, time/batch = 15.1950s	
30757/33150 (epoch 46.391), train_loss = 0.91989722, grad/param norm = 2.0074e-01, time/batch = 14.9613s	
30758/33150 (epoch 46.392), train_loss = 0.73390020, grad/param norm = 1.8223e-01, time/batch = 14.7968s	
30759/33150 (epoch 46.394), train_loss = 0.69744191, grad/param norm = 1.6130e-01, time/batch = 15.0415s	
30760/33150 (epoch 46.395), train_loss = 0.65364786, grad/param norm = 1.6883e-01, time/batch = 14.9597s	
30761/33150 (epoch 46.397), train_loss = 0.55499699, grad/param norm = 1.6488e-01, time/batch = 14.8718s	
30762/33150 (epoch 46.398), train_loss = 0.81440530, grad/param norm = 1.9068e-01, time/batch = 15.1282s	
30763/33150 (epoch 46.400), train_loss = 0.79320707, grad/param norm = 1.6077e-01, time/batch = 16.0486s	
30764/33150 (epoch 46.401), train_loss = 0.66867391, grad/param norm = 1.4969e-01, time/batch = 16.7084s	
30765/33150 (epoch 46.403), train_loss = 0.67507504, grad/param norm = 1.5932e-01, time/batch = 18.6182s	
30766/33150 (epoch 46.404), train_loss = 0.78428438, grad/param norm = 1.9181e-01, time/batch = 15.4491s	
30767/33150 (epoch 46.406), train_loss = 0.76055951, grad/param norm = 1.6135e-01, time/batch = 18.2271s	
30768/33150 (epoch 46.407), train_loss = 0.67463930, grad/param norm = 1.6961e-01, time/batch = 19.1994s	
30769/33150 (epoch 46.409), train_loss = 0.62885320, grad/param norm = 1.7403e-01, time/batch = 17.6551s	
30770/33150 (epoch 46.410), train_loss = 0.80662300, grad/param norm = 1.8390e-01, time/batch = 16.6345s	
30771/33150 (epoch 46.412), train_loss = 0.83563277, grad/param norm = 1.6796e-01, time/batch = 15.8831s	
30772/33150 (epoch 46.413), train_loss = 0.69202081, grad/param norm = 1.5626e-01, time/batch = 15.4569s	
30773/33150 (epoch 46.415), train_loss = 0.79682224, grad/param norm = 1.6248e-01, time/batch = 15.4713s	
30774/33150 (epoch 46.416), train_loss = 0.69424669, grad/param norm = 1.4881e-01, time/batch = 15.3658s	
30775/33150 (epoch 46.418), train_loss = 0.81789717, grad/param norm = 2.1300e-01, time/batch = 15.4470s	
30776/33150 (epoch 46.419), train_loss = 0.77693269, grad/param norm = 1.7168e-01, time/batch = 16.0752s	
30777/33150 (epoch 46.421), train_loss = 0.78920509, grad/param norm = 2.0131e-01, time/batch = 17.1314s	
30778/33150 (epoch 46.422), train_loss = 0.76980001, grad/param norm = 1.7145e-01, time/batch = 16.3640s	
30779/33150 (epoch 46.424), train_loss = 0.70063974, grad/param norm = 1.7027e-01, time/batch = 17.2260s	
30780/33150 (epoch 46.425), train_loss = 0.85323819, grad/param norm = 1.7052e-01, time/batch = 18.1219s	
30781/33150 (epoch 46.427), train_loss = 0.79743820, grad/param norm = 1.5832e-01, time/batch = 17.5362s	
30782/33150 (epoch 46.428), train_loss = 0.74147757, grad/param norm = 1.9178e-01, time/batch = 16.0347s	
30783/33150 (epoch 46.430), train_loss = 0.80215309, grad/param norm = 2.3488e-01, time/batch = 16.6362s	
30784/33150 (epoch 46.431), train_loss = 0.85490552, grad/param norm = 2.0395e-01, time/batch = 16.8787s	
30785/33150 (epoch 46.433), train_loss = 0.74445031, grad/param norm = 1.5180e-01, time/batch = 15.9039s	
30786/33150 (epoch 46.434), train_loss = 0.68402988, grad/param norm = 2.1391e-01, time/batch = 17.4803s	
30787/33150 (epoch 46.436), train_loss = 0.78851369, grad/param norm = 1.6555e-01, time/batch = 17.5364s	
30788/33150 (epoch 46.437), train_loss = 0.76921437, grad/param norm = 2.3476e-01, time/batch = 16.7108s	
30789/33150 (epoch 46.439), train_loss = 0.95160508, grad/param norm = 1.7928e-01, time/batch = 15.8804s	
30790/33150 (epoch 46.440), train_loss = 0.84021474, grad/param norm = 1.9574e-01, time/batch = 16.6179s	
30791/33150 (epoch 46.442), train_loss = 0.66978047, grad/param norm = 1.7656e-01, time/batch = 17.3681s	
30792/33150 (epoch 46.443), train_loss = 0.80123953, grad/param norm = 2.1532e-01, time/batch = 17.1228s	
30793/33150 (epoch 46.445), train_loss = 0.81091507, grad/param norm = 2.0989e-01, time/batch = 18.4736s	
30794/33150 (epoch 46.446), train_loss = 0.81859029, grad/param norm = 2.0148e-01, time/batch = 18.5346s	
30795/33150 (epoch 46.448), train_loss = 0.88581528, grad/param norm = 2.0200e-01, time/batch = 18.0387s	
30796/33150 (epoch 46.449), train_loss = 0.79544134, grad/param norm = 1.6466e-01, time/batch = 18.3030s	
30797/33150 (epoch 46.451), train_loss = 0.78504357, grad/param norm = 2.3059e-01, time/batch = 18.5464s	
30798/33150 (epoch 46.452), train_loss = 0.94973752, grad/param norm = 1.8105e-01, time/batch = 17.2154s	
30799/33150 (epoch 46.454), train_loss = 0.76276426, grad/param norm = 1.8019e-01, time/batch = 18.3739s	
30800/33150 (epoch 46.456), train_loss = 0.74183075, grad/param norm = 1.8489e-01, time/batch = 16.2133s	
30801/33150 (epoch 46.457), train_loss = 0.79035649, grad/param norm = 1.8476e-01, time/batch = 16.3764s	
30802/33150 (epoch 46.459), train_loss = 0.89988867, grad/param norm = 2.2255e-01, time/batch = 17.9429s	
30803/33150 (epoch 46.460), train_loss = 0.85226532, grad/param norm = 1.6977e-01, time/batch = 17.5525s	
30804/33150 (epoch 46.462), train_loss = 0.89172664, grad/param norm = 2.1422e-01, time/batch = 19.6226s	
30805/33150 (epoch 46.463), train_loss = 1.01627994, grad/param norm = 2.5506e-01, time/batch = 16.7094s	
30806/33150 (epoch 46.465), train_loss = 0.85591162, grad/param norm = 1.7935e-01, time/batch = 17.9693s	
30807/33150 (epoch 46.466), train_loss = 0.75780899, grad/param norm = 1.6675e-01, time/batch = 18.6403s	
30808/33150 (epoch 46.468), train_loss = 0.98605351, grad/param norm = 1.9378e-01, time/batch = 16.3569s	
30809/33150 (epoch 46.469), train_loss = 0.73081238, grad/param norm = 1.8061e-01, time/batch = 18.2850s	
30810/33150 (epoch 46.471), train_loss = 0.73935808, grad/param norm = 1.5741e-01, time/batch = 18.0334s	
30811/33150 (epoch 46.472), train_loss = 0.83637480, grad/param norm = 1.9833e-01, time/batch = 18.6007s	
30812/33150 (epoch 46.474), train_loss = 0.86213169, grad/param norm = 2.4896e-01, time/batch = 17.2077s	
30813/33150 (epoch 46.475), train_loss = 1.02594969, grad/param norm = 1.8647e-01, time/batch = 18.8869s	
30814/33150 (epoch 46.477), train_loss = 0.86788680, grad/param norm = 1.9906e-01, time/batch = 18.9653s	
30815/33150 (epoch 46.478), train_loss = 0.80852912, grad/param norm = 1.7192e-01, time/batch = 16.8669s	
30816/33150 (epoch 46.480), train_loss = 0.73833942, grad/param norm = 1.6921e-01, time/batch = 18.4537s	
30817/33150 (epoch 46.481), train_loss = 0.67806545, grad/param norm = 1.6950e-01, time/batch = 19.3800s	
30818/33150 (epoch 46.483), train_loss = 0.75515914, grad/param norm = 1.6691e-01, time/batch = 17.4737s	
30819/33150 (epoch 46.484), train_loss = 0.72037429, grad/param norm = 1.8133e-01, time/batch = 15.9692s	
30820/33150 (epoch 46.486), train_loss = 0.75764977, grad/param norm = 2.4190e-01, time/batch = 18.0445s	
30821/33150 (epoch 46.487), train_loss = 0.86806127, grad/param norm = 2.0396e-01, time/batch = 18.8579s	
30822/33150 (epoch 46.489), train_loss = 0.77666100, grad/param norm = 1.9199e-01, time/batch = 17.6081s	
30823/33150 (epoch 46.490), train_loss = 0.64131351, grad/param norm = 1.5241e-01, time/batch = 20.1137s	
30824/33150 (epoch 46.492), train_loss = 0.76024136, grad/param norm = 1.7486e-01, time/batch = 19.7124s	
30825/33150 (epoch 46.493), train_loss = 0.84410592, grad/param norm = 1.9624e-01, time/batch = 16.0952s	
30826/33150 (epoch 46.495), train_loss = 0.83382252, grad/param norm = 1.6834e-01, time/batch = 16.6108s	
30827/33150 (epoch 46.496), train_loss = 0.74911315, grad/param norm = 1.6727e-01, time/batch = 17.6485s	
30828/33150 (epoch 46.498), train_loss = 0.90068941, grad/param norm = 2.3472e-01, time/batch = 15.9686s	
30829/33150 (epoch 46.499), train_loss = 0.90068640, grad/param norm = 1.8086e-01, time/batch = 16.3803s	
30830/33150 (epoch 46.501), train_loss = 0.80955348, grad/param norm = 2.1389e-01, time/batch = 18.4799s	
30831/33150 (epoch 46.502), train_loss = 0.90693603, grad/param norm = 2.2929e-01, time/batch = 18.7961s	
30832/33150 (epoch 46.504), train_loss = 0.87387180, grad/param norm = 2.1662e-01, time/batch = 17.2085s	
30833/33150 (epoch 46.505), train_loss = 0.93355513, grad/param norm = 2.2090e-01, time/batch = 18.7993s	
30834/33150 (epoch 46.507), train_loss = 0.76724100, grad/param norm = 1.8050e-01, time/batch = 18.5560s	
30835/33150 (epoch 46.508), train_loss = 0.75607292, grad/param norm = 1.9954e-01, time/batch = 17.5525s	
30836/33150 (epoch 46.510), train_loss = 0.88579214, grad/param norm = 1.8431e-01, time/batch = 18.5454s	
30837/33150 (epoch 46.511), train_loss = 0.89685755, grad/param norm = 1.9015e-01, time/batch = 16.6233s	
30838/33150 (epoch 46.513), train_loss = 0.81795301, grad/param norm = 2.0132e-01, time/batch = 16.4459s	
30839/33150 (epoch 46.514), train_loss = 0.70903963, grad/param norm = 1.8277e-01, time/batch = 17.3974s	
30840/33150 (epoch 46.516), train_loss = 0.83382687, grad/param norm = 2.4341e-01, time/batch = 17.8014s	
30841/33150 (epoch 46.517), train_loss = 0.87739457, grad/param norm = 1.8916e-01, time/batch = 18.3844s	
30842/33150 (epoch 46.519), train_loss = 0.75359587, grad/param norm = 1.6773e-01, time/batch = 16.1103s	
30843/33150 (epoch 46.520), train_loss = 0.79670656, grad/param norm = 1.6335e-01, time/batch = 16.2103s	
30844/33150 (epoch 46.522), train_loss = 0.85278528, grad/param norm = 2.4841e-01, time/batch = 17.7887s	
30845/33150 (epoch 46.523), train_loss = 0.71457120, grad/param norm = 2.0522e-01, time/batch = 18.0463s	
30846/33150 (epoch 46.525), train_loss = 0.85724849, grad/param norm = 2.0421e-01, time/batch = 16.3019s	
30847/33150 (epoch 46.526), train_loss = 0.72607737, grad/param norm = 1.5283e-01, time/batch = 18.5479s	
30848/33150 (epoch 46.528), train_loss = 0.81618136, grad/param norm = 1.7410e-01, time/batch = 18.1307s	
30849/33150 (epoch 46.529), train_loss = 0.80552525, grad/param norm = 1.9784e-01, time/batch = 15.8190s	
30850/33150 (epoch 46.531), train_loss = 0.70297844, grad/param norm = 1.9676e-01, time/batch = 18.8110s	
30851/33150 (epoch 46.532), train_loss = 0.82966206, grad/param norm = 3.0947e-01, time/batch = 17.3025s	
30852/33150 (epoch 46.534), train_loss = 0.80369252, grad/param norm = 1.7862e-01, time/batch = 16.3734s	
30853/33150 (epoch 46.535), train_loss = 0.74008848, grad/param norm = 2.2836e-01, time/batch = 18.3043s	
30854/33150 (epoch 46.537), train_loss = 0.80086137, grad/param norm = 2.1979e-01, time/batch = 18.4682s	
30855/33150 (epoch 46.538), train_loss = 0.73728130, grad/param norm = 1.7542e-01, time/batch = 17.1232s	
30856/33150 (epoch 46.540), train_loss = 0.71128197, grad/param norm = 1.9223e-01, time/batch = 17.0324s	
30857/33150 (epoch 46.541), train_loss = 0.87965570, grad/param norm = 1.8362e-01, time/batch = 17.4016s	
30858/33150 (epoch 46.543), train_loss = 0.81638547, grad/param norm = 1.9481e-01, time/batch = 17.7981s	
30859/33150 (epoch 46.544), train_loss = 0.85500517, grad/param norm = 1.8931e-01, time/batch = 17.1253s	
30860/33150 (epoch 46.546), train_loss = 0.73755133, grad/param norm = 1.8655e-01, time/batch = 16.5355s	
30861/33150 (epoch 46.548), train_loss = 0.77899494, grad/param norm = 2.2565e-01, time/batch = 19.4550s	
30862/33150 (epoch 46.549), train_loss = 0.78851475, grad/param norm = 2.2298e-01, time/batch = 17.2170s	
30863/33150 (epoch 46.551), train_loss = 0.73821841, grad/param norm = 1.6866e-01, time/batch = 17.2358s	
30864/33150 (epoch 46.552), train_loss = 0.62664057, grad/param norm = 1.3789e-01, time/batch = 17.3630s	
30865/33150 (epoch 46.554), train_loss = 0.86147239, grad/param norm = 1.8562e-01, time/batch = 15.1960s	
30866/33150 (epoch 46.555), train_loss = 0.88164581, grad/param norm = 1.9102e-01, time/batch = 15.4118s	
30867/33150 (epoch 46.557), train_loss = 0.67163142, grad/param norm = 1.7904e-01, time/batch = 15.0245s	
30868/33150 (epoch 46.558), train_loss = 0.82164819, grad/param norm = 2.1173e-01, time/batch = 14.9374s	
30869/33150 (epoch 46.560), train_loss = 0.71704242, grad/param norm = 1.6965e-01, time/batch = 15.1759s	
30870/33150 (epoch 46.561), train_loss = 0.67631357, grad/param norm = 1.8813e-01, time/batch = 15.2666s	
30871/33150 (epoch 46.563), train_loss = 0.84640191, grad/param norm = 2.1690e-01, time/batch = 15.1120s	
30872/33150 (epoch 46.564), train_loss = 0.87381018, grad/param norm = 1.6177e-01, time/batch = 15.0136s	
30873/33150 (epoch 46.566), train_loss = 0.71297324, grad/param norm = 1.7533e-01, time/batch = 15.2595s	
30874/33150 (epoch 46.567), train_loss = 0.79132842, grad/param norm = 2.0460e-01, time/batch = 28.8015s	
30875/33150 (epoch 46.569), train_loss = 0.83217454, grad/param norm = 2.2822e-01, time/batch = 17.4479s	
30876/33150 (epoch 46.570), train_loss = 0.85162098, grad/param norm = 1.7042e-01, time/batch = 15.7083s	
30877/33150 (epoch 46.572), train_loss = 0.75879454, grad/param norm = 1.8268e-01, time/batch = 16.5524s	
30878/33150 (epoch 46.573), train_loss = 0.68700564, grad/param norm = 1.5048e-01, time/batch = 16.4551s	
30879/33150 (epoch 46.575), train_loss = 0.77293544, grad/param norm = 1.9410e-01, time/batch = 17.1525s	
30880/33150 (epoch 46.576), train_loss = 0.70318613, grad/param norm = 1.6652e-01, time/batch = 15.9601s	
30881/33150 (epoch 46.578), train_loss = 0.73292852, grad/param norm = 1.7027e-01, time/batch = 15.5986s	
30882/33150 (epoch 46.579), train_loss = 0.71018395, grad/param norm = 1.9000e-01, time/batch = 15.9381s	
30883/33150 (epoch 46.581), train_loss = 0.69038821, grad/param norm = 2.0058e-01, time/batch = 19.6995s	
30884/33150 (epoch 46.582), train_loss = 0.89159891, grad/param norm = 1.6144e-01, time/batch = 16.9468s	
30885/33150 (epoch 46.584), train_loss = 0.87207074, grad/param norm = 1.7752e-01, time/batch = 19.3683s	
30886/33150 (epoch 46.585), train_loss = 0.79306746, grad/param norm = 1.7464e-01, time/batch = 19.4623s	
30887/33150 (epoch 46.587), train_loss = 0.79481186, grad/param norm = 1.7489e-01, time/batch = 16.7126s	
30888/33150 (epoch 46.588), train_loss = 0.73884422, grad/param norm = 1.7652e-01, time/batch = 18.5324s	
30889/33150 (epoch 46.590), train_loss = 0.83945053, grad/param norm = 1.9387e-01, time/batch = 17.0395s	
30890/33150 (epoch 46.591), train_loss = 0.81315637, grad/param norm = 1.8921e-01, time/batch = 17.9464s	
30891/33150 (epoch 46.593), train_loss = 0.85176180, grad/param norm = 2.2270e-01, time/batch = 17.8784s	
30892/33150 (epoch 46.594), train_loss = 0.76366420, grad/param norm = 1.9189e-01, time/batch = 17.8112s	
30893/33150 (epoch 46.596), train_loss = 0.77004749, grad/param norm = 2.0471e-01, time/batch = 19.6324s	
30894/33150 (epoch 46.597), train_loss = 0.69985990, grad/param norm = 2.3537e-01, time/batch = 17.8788s	
30895/33150 (epoch 46.599), train_loss = 0.93175916, grad/param norm = 1.9898e-01, time/batch = 16.3782s	
30896/33150 (epoch 46.600), train_loss = 0.79961195, grad/param norm = 3.4341e-01, time/batch = 18.3049s	
30897/33150 (epoch 46.602), train_loss = 0.79454816, grad/param norm = 2.1876e-01, time/batch = 16.4724s	
30898/33150 (epoch 46.603), train_loss = 0.93304882, grad/param norm = 2.1570e-01, time/batch = 15.9449s	
30899/33150 (epoch 46.605), train_loss = 0.72484800, grad/param norm = 2.0448e-01, time/batch = 18.2974s	
30900/33150 (epoch 46.606), train_loss = 0.74450462, grad/param norm = 2.3918e-01, time/batch = 17.8766s	
30901/33150 (epoch 46.608), train_loss = 0.88971277, grad/param norm = 1.7927e-01, time/batch = 15.3509s	
30902/33150 (epoch 46.609), train_loss = 0.80425891, grad/param norm = 2.0027e-01, time/batch = 15.1084s	
30903/33150 (epoch 46.611), train_loss = 0.69963847, grad/param norm = 1.7514e-01, time/batch = 15.6281s	
30904/33150 (epoch 46.612), train_loss = 0.75217298, grad/param norm = 1.7341e-01, time/batch = 15.5095s	
30905/33150 (epoch 46.614), train_loss = 0.72984283, grad/param norm = 1.8367e-01, time/batch = 15.1057s	
30906/33150 (epoch 46.615), train_loss = 0.71851764, grad/param norm = 1.9587e-01, time/batch = 17.1102s	
30907/33150 (epoch 46.617), train_loss = 0.80497548, grad/param norm = 2.2738e-01, time/batch = 18.7123s	
30908/33150 (epoch 46.618), train_loss = 0.81790944, grad/param norm = 1.9254e-01, time/batch = 15.8372s	
30909/33150 (epoch 46.620), train_loss = 0.77819982, grad/param norm = 1.7992e-01, time/batch = 16.1423s	
30910/33150 (epoch 46.621), train_loss = 0.81602694, grad/param norm = 1.8413e-01, time/batch = 16.7993s	
30911/33150 (epoch 46.623), train_loss = 0.83590511, grad/param norm = 1.6743e-01, time/batch = 16.4581s	
30912/33150 (epoch 46.624), train_loss = 0.77095098, grad/param norm = 1.7371e-01, time/batch = 17.4684s	
30913/33150 (epoch 46.626), train_loss = 0.81592011, grad/param norm = 1.9236e-01, time/batch = 16.8003s	
30914/33150 (epoch 46.627), train_loss = 0.77391212, grad/param norm = 1.9436e-01, time/batch = 16.8132s	
30915/33150 (epoch 46.629), train_loss = 0.67753236, grad/param norm = 1.7825e-01, time/batch = 15.7904s	
30916/33150 (epoch 46.630), train_loss = 0.77469688, grad/param norm = 1.9388e-01, time/batch = 19.7760s	
30917/33150 (epoch 46.632), train_loss = 0.70603664, grad/param norm = 1.5515e-01, time/batch = 17.4499s	
30918/33150 (epoch 46.633), train_loss = 0.74127812, grad/param norm = 1.9998e-01, time/batch = 16.4270s	
30919/33150 (epoch 46.635), train_loss = 0.94860151, grad/param norm = 2.3364e-01, time/batch = 15.4981s	
30920/33150 (epoch 46.637), train_loss = 0.65965303, grad/param norm = 1.9386e-01, time/batch = 15.4102s	
30921/33150 (epoch 46.638), train_loss = 0.77486547, grad/param norm = 1.9890e-01, time/batch = 15.5940s	
30922/33150 (epoch 46.640), train_loss = 0.84140103, grad/param norm = 1.8901e-01, time/batch = 15.2594s	
30923/33150 (epoch 46.641), train_loss = 0.66159769, grad/param norm = 1.8348e-01, time/batch = 15.2007s	
30924/33150 (epoch 46.643), train_loss = 0.79708015, grad/param norm = 1.7323e-01, time/batch = 15.1108s	
30925/33150 (epoch 46.644), train_loss = 0.93169817, grad/param norm = 1.6652e-01, time/batch = 15.2750s	
30926/33150 (epoch 46.646), train_loss = 0.80775582, grad/param norm = 1.8670e-01, time/batch = 15.9261s	
30927/33150 (epoch 46.647), train_loss = 0.94816684, grad/param norm = 1.8084e-01, time/batch = 16.2389s	
30928/33150 (epoch 46.649), train_loss = 0.83619034, grad/param norm = 2.4674e-01, time/batch = 15.1262s	
30929/33150 (epoch 46.650), train_loss = 0.70338421, grad/param norm = 1.8109e-01, time/batch = 15.4739s	
30930/33150 (epoch 46.652), train_loss = 0.87388263, grad/param norm = 1.9332e-01, time/batch = 15.8892s	
30931/33150 (epoch 46.653), train_loss = 0.84555007, grad/param norm = 1.6995e-01, time/batch = 15.8938s	
30932/33150 (epoch 46.655), train_loss = 0.85905533, grad/param norm = 2.1326e-01, time/batch = 15.8037s	
30933/33150 (epoch 46.656), train_loss = 0.75937089, grad/param norm = 1.5464e-01, time/batch = 18.7111s	
30934/33150 (epoch 46.658), train_loss = 0.77670068, grad/param norm = 1.9163e-01, time/batch = 16.9557s	
30935/33150 (epoch 46.659), train_loss = 0.97092710, grad/param norm = 2.9431e-01, time/batch = 18.4744s	
30936/33150 (epoch 46.661), train_loss = 0.77358449, grad/param norm = 1.9546e-01, time/batch = 18.2897s	
30937/33150 (epoch 46.662), train_loss = 0.78568848, grad/param norm = 2.0181e-01, time/batch = 16.5568s	
30938/33150 (epoch 46.664), train_loss = 0.91513219, grad/param norm = 1.9536e-01, time/batch = 17.3039s	
30939/33150 (epoch 46.665), train_loss = 0.89167644, grad/param norm = 2.3547e-01, time/batch = 16.3159s	
30940/33150 (epoch 46.667), train_loss = 0.87641645, grad/param norm = 2.1834e-01, time/batch = 15.8636s	
30941/33150 (epoch 46.668), train_loss = 0.95032161, grad/param norm = 1.9513e-01, time/batch = 16.1353s	
30942/33150 (epoch 46.670), train_loss = 0.75385212, grad/param norm = 1.7099e-01, time/batch = 18.3961s	
30943/33150 (epoch 46.671), train_loss = 0.72777150, grad/param norm = 1.9745e-01, time/batch = 17.8897s	
30944/33150 (epoch 46.673), train_loss = 0.91020263, grad/param norm = 1.8423e-01, time/batch = 15.7857s	
30945/33150 (epoch 46.674), train_loss = 0.87079438, grad/param norm = 2.2477e-01, time/batch = 16.7279s	
30946/33150 (epoch 46.676), train_loss = 0.79528042, grad/param norm = 1.8588e-01, time/batch = 17.7241s	
30947/33150 (epoch 46.677), train_loss = 0.91835669, grad/param norm = 2.2255e-01, time/batch = 17.4640s	
30948/33150 (epoch 46.679), train_loss = 0.80294033, grad/param norm = 1.7632e-01, time/batch = 17.8047s	
30949/33150 (epoch 46.680), train_loss = 0.89094691, grad/param norm = 1.9799e-01, time/batch = 17.3878s	
30950/33150 (epoch 46.682), train_loss = 0.83421502, grad/param norm = 1.8165e-01, time/batch = 17.2912s	
30951/33150 (epoch 46.683), train_loss = 0.68597867, grad/param norm = 1.5068e-01, time/batch = 16.6315s	
30952/33150 (epoch 46.685), train_loss = 0.77257028, grad/param norm = 2.0588e-01, time/batch = 18.1474s	
30953/33150 (epoch 46.686), train_loss = 0.66360206, grad/param norm = 1.9859e-01, time/batch = 18.0639s	
30954/33150 (epoch 46.688), train_loss = 0.71718539, grad/param norm = 1.9610e-01, time/batch = 16.7420s	
30955/33150 (epoch 46.689), train_loss = 0.72309615, grad/param norm = 1.5914e-01, time/batch = 15.6472s	
30956/33150 (epoch 46.691), train_loss = 0.62718391, grad/param norm = 2.0943e-01, time/batch = 17.3888s	
30957/33150 (epoch 46.692), train_loss = 0.71353988, grad/param norm = 1.9143e-01, time/batch = 16.4771s	
30958/33150 (epoch 46.694), train_loss = 0.64621674, grad/param norm = 1.7811e-01, time/batch = 15.2015s	
30959/33150 (epoch 46.695), train_loss = 0.71812289, grad/param norm = 1.7857e-01, time/batch = 17.7969s	
30960/33150 (epoch 46.697), train_loss = 0.69583612, grad/param norm = 1.5426e-01, time/batch = 15.9607s	
30961/33150 (epoch 46.698), train_loss = 0.70134901, grad/param norm = 2.3204e-01, time/batch = 18.2074s	
30962/33150 (epoch 46.700), train_loss = 0.61134367, grad/param norm = 1.5195e-01, time/batch = 17.3735s	
30963/33150 (epoch 46.701), train_loss = 0.68040139, grad/param norm = 1.5502e-01, time/batch = 18.7990s	
30964/33150 (epoch 46.703), train_loss = 0.77578811, grad/param norm = 1.8063e-01, time/batch = 17.4719s	
30965/33150 (epoch 46.704), train_loss = 0.67708072, grad/param norm = 1.4477e-01, time/batch = 16.7164s	
30966/33150 (epoch 46.706), train_loss = 0.73750344, grad/param norm = 1.7267e-01, time/batch = 17.6344s	
30967/33150 (epoch 46.707), train_loss = 0.76732192, grad/param norm = 1.7201e-01, time/batch = 16.3939s	
30968/33150 (epoch 46.709), train_loss = 0.78729414, grad/param norm = 1.6608e-01, time/batch = 17.5576s	
30969/33150 (epoch 46.710), train_loss = 0.78438618, grad/param norm = 2.0209e-01, time/batch = 16.8019s	
30970/33150 (epoch 46.712), train_loss = 0.87632738, grad/param norm = 1.9347e-01, time/batch = 18.6492s	
30971/33150 (epoch 46.713), train_loss = 0.81035682, grad/param norm = 2.0466e-01, time/batch = 17.4734s	
30972/33150 (epoch 46.715), train_loss = 0.76801545, grad/param norm = 1.7131e-01, time/batch = 17.3643s	
30973/33150 (epoch 46.716), train_loss = 0.81712209, grad/param norm = 2.2356e-01, time/batch = 15.6212s	
30974/33150 (epoch 46.718), train_loss = 0.78878940, grad/param norm = 1.9105e-01, time/batch = 18.1423s	
30975/33150 (epoch 46.719), train_loss = 0.85512832, grad/param norm = 2.0390e-01, time/batch = 17.4625s	
30976/33150 (epoch 46.721), train_loss = 0.75870996, grad/param norm = 1.9574e-01, time/batch = 15.9753s	
30977/33150 (epoch 46.722), train_loss = 0.84312548, grad/param norm = 1.7594e-01, time/batch = 18.3067s	
30978/33150 (epoch 46.724), train_loss = 0.75420961, grad/param norm = 2.0755e-01, time/batch = 18.5480s	
30979/33150 (epoch 46.725), train_loss = 0.83368336, grad/param norm = 1.9902e-01, time/batch = 15.2415s	
30980/33150 (epoch 46.727), train_loss = 0.83413530, grad/param norm = 2.0198e-01, time/batch = 14.9227s	
30981/33150 (epoch 46.729), train_loss = 0.79139037, grad/param norm = 2.0524e-01, time/batch = 15.4124s	
30982/33150 (epoch 46.730), train_loss = 0.80038072, grad/param norm = 1.7278e-01, time/batch = 15.0801s	
30983/33150 (epoch 46.732), train_loss = 0.84528289, grad/param norm = 1.8212e-01, time/batch = 15.1730s	
30984/33150 (epoch 46.733), train_loss = 0.69838455, grad/param norm = 1.4491e-01, time/batch = 15.1616s	
30985/33150 (epoch 46.735), train_loss = 0.72054328, grad/param norm = 1.7650e-01, time/batch = 15.2152s	
30986/33150 (epoch 46.736), train_loss = 0.73706941, grad/param norm = 1.8369e-01, time/batch = 14.7713s	
30987/33150 (epoch 46.738), train_loss = 0.80454907, grad/param norm = 2.6516e-01, time/batch = 14.7973s	
30988/33150 (epoch 46.739), train_loss = 0.87417694, grad/param norm = 1.9580e-01, time/batch = 14.9692s	
30989/33150 (epoch 46.741), train_loss = 0.79251100, grad/param norm = 2.3819e-01, time/batch = 14.5645s	
30990/33150 (epoch 46.742), train_loss = 0.66163590, grad/param norm = 1.8573e-01, time/batch = 14.8088s	
30991/33150 (epoch 46.744), train_loss = 0.85077210, grad/param norm = 1.9821e-01, time/batch = 14.9753s	
30992/33150 (epoch 46.745), train_loss = 0.73871234, grad/param norm = 1.8127e-01, time/batch = 14.8097s	
30993/33150 (epoch 46.747), train_loss = 0.57272559, grad/param norm = 1.5992e-01, time/batch = 14.7334s	
30994/33150 (epoch 46.748), train_loss = 0.65659982, grad/param norm = 1.6527e-01, time/batch = 14.7291s	
30995/33150 (epoch 46.750), train_loss = 0.79351640, grad/param norm = 2.0837e-01, time/batch = 14.7086s	
30996/33150 (epoch 46.751), train_loss = 0.76971287, grad/param norm = 1.8463e-01, time/batch = 15.1230s	
30997/33150 (epoch 46.753), train_loss = 0.69765605, grad/param norm = 2.7484e-01, time/batch = 14.8152s	
30998/33150 (epoch 46.754), train_loss = 0.94374448, grad/param norm = 2.0260e-01, time/batch = 14.7377s	
30999/33150 (epoch 46.756), train_loss = 0.80408651, grad/param norm = 3.3123e-01, time/batch = 14.9481s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasaarmstrong_epoch46.76_1.9051.t7	
31000/33150 (epoch 46.757), train_loss = 0.82472046, grad/param norm = 1.8473e-01, time/batch = 14.4864s	
31001/33150 (epoch 46.759), train_loss = 1.59884243, grad/param norm = 4.4080e-01, time/batch = 17.3143s	
31002/33150 (epoch 46.760), train_loss = 0.85163860, grad/param norm = 2.0215e-01, time/batch = 16.3999s	
31003/33150 (epoch 46.762), train_loss = 0.79993638, grad/param norm = 1.7883e-01, time/batch = 18.5514s	
31004/33150 (epoch 46.763), train_loss = 0.84220492, grad/param norm = 1.9620e-01, time/batch = 16.9658s	
31005/33150 (epoch 46.765), train_loss = 0.79844078, grad/param norm = 1.9039e-01, time/batch = 15.3961s	
31006/33150 (epoch 46.766), train_loss = 0.66119483, grad/param norm = 1.7100e-01, time/batch = 18.4726s	
31007/33150 (epoch 46.768), train_loss = 0.72927763, grad/param norm = 1.6875e-01, time/batch = 18.8997s	
31008/33150 (epoch 46.769), train_loss = 0.86211689, grad/param norm = 1.8818e-01, time/batch = 16.3873s	
31009/33150 (epoch 46.771), train_loss = 0.83793948, grad/param norm = 1.9369e-01, time/batch = 16.8077s	
31010/33150 (epoch 46.772), train_loss = 0.81621087, grad/param norm = 2.0646e-01, time/batch = 16.4827s	
31011/33150 (epoch 46.774), train_loss = 0.91923944, grad/param norm = 1.9670e-01, time/batch = 16.1453s	
31012/33150 (epoch 46.775), train_loss = 0.83838857, grad/param norm = 2.4720e-01, time/batch = 16.6468s	
31013/33150 (epoch 46.777), train_loss = 0.85286977, grad/param norm = 1.9427e-01, time/batch = 18.0534s	
31014/33150 (epoch 46.778), train_loss = 0.79803911, grad/param norm = 2.1671e-01, time/batch = 16.4576s	
31015/33150 (epoch 46.780), train_loss = 0.70059058, grad/param norm = 1.7389e-01, time/batch = 15.7993s	
31016/33150 (epoch 46.781), train_loss = 0.79218797, grad/param norm = 2.0520e-01, time/batch = 15.7338s	
31017/33150 (epoch 46.783), train_loss = 0.79160672, grad/param norm = 1.7619e-01, time/batch = 17.3785s	
31018/33150 (epoch 46.784), train_loss = 0.77403067, grad/param norm = 1.8860e-01, time/batch = 18.0514s	
31019/33150 (epoch 46.786), train_loss = 0.76227835, grad/param norm = 1.9933e-01, time/batch = 17.0484s	
31020/33150 (epoch 46.787), train_loss = 0.71627926, grad/param norm = 1.7772e-01, time/batch = 17.4717s	
31021/33150 (epoch 46.789), train_loss = 0.66684502, grad/param norm = 1.4348e-01, time/batch = 20.4417s	
31022/33150 (epoch 46.790), train_loss = 0.67105229, grad/param norm = 1.7016e-01, time/batch = 17.2094s	
31023/33150 (epoch 46.792), train_loss = 0.77877588, grad/param norm = 2.3765e-01, time/batch = 18.2179s	
31024/33150 (epoch 46.793), train_loss = 0.73120028, grad/param norm = 1.8418e-01, time/batch = 16.8192s	
31025/33150 (epoch 46.795), train_loss = 0.75977615, grad/param norm = 1.9935e-01, time/batch = 19.1971s	
31026/33150 (epoch 46.796), train_loss = 0.76784968, grad/param norm = 1.7335e-01, time/batch = 16.6873s	
31027/33150 (epoch 46.798), train_loss = 0.74008795, grad/param norm = 1.5725e-01, time/batch = 18.8851s	
31028/33150 (epoch 46.799), train_loss = 0.66374252, grad/param norm = 2.0324e-01, time/batch = 18.3070s	
31029/33150 (epoch 46.801), train_loss = 0.77990269, grad/param norm = 1.8621e-01, time/batch = 15.5322s	
31030/33150 (epoch 46.802), train_loss = 0.75543727, grad/param norm = 1.8162e-01, time/batch = 15.5289s	
31031/33150 (epoch 46.804), train_loss = 0.73727699, grad/param norm = 1.8525e-01, time/batch = 15.4535s	
31032/33150 (epoch 46.805), train_loss = 0.70746905, grad/param norm = 2.3828e-01, time/batch = 15.3855s	
31033/33150 (epoch 46.807), train_loss = 0.78638889, grad/param norm = 1.7119e-01, time/batch = 15.7148s	
31034/33150 (epoch 46.808), train_loss = 0.85254341, grad/param norm = 2.2342e-01, time/batch = 17.9707s	
31035/33150 (epoch 46.810), train_loss = 0.70000427, grad/param norm = 1.6906e-01, time/batch = 18.1989s	
31036/33150 (epoch 46.811), train_loss = 0.78608854, grad/param norm = 1.9846e-01, time/batch = 17.7035s	
31037/33150 (epoch 46.813), train_loss = 0.74438795, grad/param norm = 1.7121e-01, time/batch = 18.0421s	
31038/33150 (epoch 46.814), train_loss = 0.73481074, grad/param norm = 2.2085e-01, time/batch = 18.0539s	
31039/33150 (epoch 46.816), train_loss = 0.73920752, grad/param norm = 2.1649e-01, time/batch = 16.8071s	
31040/33150 (epoch 46.817), train_loss = 0.81747026, grad/param norm = 2.0003e-01, time/batch = 16.3094s	
31041/33150 (epoch 46.819), train_loss = 0.78651851, grad/param norm = 1.7922e-01, time/batch = 18.7211s	
31042/33150 (epoch 46.821), train_loss = 0.71535489, grad/param norm = 1.4895e-01, time/batch = 18.2381s	
31043/33150 (epoch 46.822), train_loss = 0.75411207, grad/param norm = 2.1418e-01, time/batch = 16.3829s	
31044/33150 (epoch 46.824), train_loss = 0.81413586, grad/param norm = 1.8729e-01, time/batch = 17.5576s	
31045/33150 (epoch 46.825), train_loss = 0.81914420, grad/param norm = 1.9381e-01, time/batch = 17.4921s	
31046/33150 (epoch 46.827), train_loss = 0.83478249, grad/param norm = 2.7893e-01, time/batch = 16.3577s	
31047/33150 (epoch 46.828), train_loss = 0.72499966, grad/param norm = 1.9909e-01, time/batch = 17.3675s	
31048/33150 (epoch 46.830), train_loss = 0.85171367, grad/param norm = 1.9850e-01, time/batch = 18.2145s	
31049/33150 (epoch 46.831), train_loss = 0.72609126, grad/param norm = 1.7977e-01, time/batch = 18.2244s	
31050/33150 (epoch 46.833), train_loss = 0.69312936, grad/param norm = 1.7557e-01, time/batch = 16.5438s	
31051/33150 (epoch 46.834), train_loss = 0.85104288, grad/param norm = 1.8005e-01, time/batch = 19.1462s	
31052/33150 (epoch 46.836), train_loss = 0.89505725, grad/param norm = 2.0671e-01, time/batch = 17.7291s	
31053/33150 (epoch 46.837), train_loss = 0.71149900, grad/param norm = 2.3673e-01, time/batch = 16.2910s	
31054/33150 (epoch 46.839), train_loss = 0.84291646, grad/param norm = 2.2595e-01, time/batch = 18.3916s	
31055/33150 (epoch 46.840), train_loss = 0.82049539, grad/param norm = 1.8337e-01, time/batch = 17.8969s	
31056/33150 (epoch 46.842), train_loss = 0.89533731, grad/param norm = 2.4309e-01, time/batch = 17.3006s	
31057/33150 (epoch 46.843), train_loss = 0.88857293, grad/param norm = 2.0983e-01, time/batch = 16.5472s	
31058/33150 (epoch 46.845), train_loss = 0.75105864, grad/param norm = 1.9618e-01, time/batch = 19.4727s	
31059/33150 (epoch 46.846), train_loss = 0.93113042, grad/param norm = 2.7120e-01, time/batch = 19.8666s	
31060/33150 (epoch 46.848), train_loss = 0.85804029, grad/param norm = 2.0313e-01, time/batch = 16.9763s	
31061/33150 (epoch 46.849), train_loss = 0.86972307, grad/param norm = 1.9144e-01, time/batch = 19.0404s	
31062/33150 (epoch 46.851), train_loss = 0.85551097, grad/param norm = 2.1045e-01, time/batch = 20.3745s	
31063/33150 (epoch 46.852), train_loss = 0.93105521, grad/param norm = 2.1544e-01, time/batch = 17.4746s	
31064/33150 (epoch 46.854), train_loss = 0.82109419, grad/param norm = 1.9968e-01, time/batch = 17.6384s	
31065/33150 (epoch 46.855), train_loss = 0.74115325, grad/param norm = 1.8111e-01, time/batch = 19.5544s	
31066/33150 (epoch 46.857), train_loss = 0.66487465, grad/param norm = 1.7935e-01, time/batch = 17.5626s	
31067/33150 (epoch 46.858), train_loss = 0.74634468, grad/param norm = 1.7234e-01, time/batch = 16.8025s	
31068/33150 (epoch 46.860), train_loss = 0.72198976, grad/param norm = 1.5509e-01, time/batch = 18.9807s	
31069/33150 (epoch 46.861), train_loss = 0.68298412, grad/param norm = 1.5284e-01, time/batch = 17.4543s	
31070/33150 (epoch 46.863), train_loss = 0.76929398, grad/param norm = 1.9979e-01, time/batch = 17.1754s	
31071/33150 (epoch 46.864), train_loss = 0.80484114, grad/param norm = 2.1641e-01, time/batch = 17.8864s	
31072/33150 (epoch 46.866), train_loss = 0.85752183, grad/param norm = 1.8447e-01, time/batch = 20.0425s	
31073/33150 (epoch 46.867), train_loss = 0.77319578, grad/param norm = 1.6872e-01, time/batch = 16.1374s	
31074/33150 (epoch 46.869), train_loss = 0.81530998, grad/param norm = 2.0378e-01, time/batch = 26.8791s	
31075/33150 (epoch 46.870), train_loss = 0.77304835, grad/param norm = 1.8891e-01, time/batch = 17.5580s	
31076/33150 (epoch 46.872), train_loss = 0.85043212, grad/param norm = 2.2603e-01, time/batch = 29.8065s	
31077/33150 (epoch 46.873), train_loss = 0.66422723, grad/param norm = 1.9818e-01, time/batch = 17.1184s	
31078/33150 (epoch 46.875), train_loss = 0.89410267, grad/param norm = 1.9891e-01, time/batch = 15.4776s	
31079/33150 (epoch 46.876), train_loss = 0.65850362, grad/param norm = 1.9003e-01, time/batch = 15.6865s	
31080/33150 (epoch 46.878), train_loss = 0.72477039, grad/param norm = 1.6920e-01, time/batch = 15.7273s	
31081/33150 (epoch 46.879), train_loss = 0.74778777, grad/param norm = 1.9574e-01, time/batch = 15.6539s	
31082/33150 (epoch 46.881), train_loss = 0.71732491, grad/param norm = 1.7941e-01, time/batch = 15.6410s	
31083/33150 (epoch 46.882), train_loss = 0.59769322, grad/param norm = 1.8234e-01, time/batch = 15.6106s	
31084/33150 (epoch 46.884), train_loss = 0.72248839, grad/param norm = 1.7661e-01, time/batch = 17.8060s	
31085/33150 (epoch 46.885), train_loss = 0.59356906, grad/param norm = 1.6338e-01, time/batch = 17.8133s	
31086/33150 (epoch 46.887), train_loss = 0.85406603, grad/param norm = 1.9715e-01, time/batch = 16.2339s	
31087/33150 (epoch 46.888), train_loss = 0.79588346, grad/param norm = 1.7567e-01, time/batch = 16.1144s	
31088/33150 (epoch 46.890), train_loss = 0.68956842, grad/param norm = 1.9344e-01, time/batch = 18.7874s	
31089/33150 (epoch 46.891), train_loss = 0.69972635, grad/param norm = 1.8658e-01, time/batch = 17.5403s	
31090/33150 (epoch 46.893), train_loss = 0.82171320, grad/param norm = 1.9672e-01, time/batch = 15.8094s	
31091/33150 (epoch 46.894), train_loss = 0.79849687, grad/param norm = 1.6171e-01, time/batch = 18.5585s	
31092/33150 (epoch 46.896), train_loss = 0.76368911, grad/param norm = 1.7822e-01, time/batch = 16.7014s	
31093/33150 (epoch 46.897), train_loss = 0.81995353, grad/param norm = 1.6767e-01, time/batch = 16.3690s	
31094/33150 (epoch 46.899), train_loss = 0.63775801, grad/param norm = 1.9187e-01, time/batch = 16.0510s	
31095/33150 (epoch 46.900), train_loss = 0.93821681, grad/param norm = 1.9939e-01, time/batch = 18.6252s	
31096/33150 (epoch 46.902), train_loss = 0.97256825, grad/param norm = 1.9428e-01, time/batch = 17.8835s	
31097/33150 (epoch 46.903), train_loss = 0.81900226, grad/param norm = 1.8621e-01, time/batch = 16.6484s	
31098/33150 (epoch 46.905), train_loss = 0.76921969, grad/param norm = 1.6553e-01, time/batch = 17.2196s	
31099/33150 (epoch 46.906), train_loss = 0.80252501, grad/param norm = 2.2294e-01, time/batch = 17.6277s	
31100/33150 (epoch 46.908), train_loss = 0.82954418, grad/param norm = 1.9103e-01, time/batch = 15.6489s	
31101/33150 (epoch 46.910), train_loss = 0.86157406, grad/param norm = 1.8449e-01, time/batch = 17.7169s	
31102/33150 (epoch 46.911), train_loss = 0.67563286, grad/param norm = 1.5539e-01, time/batch = 17.5617s	
31103/33150 (epoch 46.913), train_loss = 0.73959623, grad/param norm = 1.8616e-01, time/batch = 16.8773s	
31104/33150 (epoch 46.914), train_loss = 0.78970126, grad/param norm = 1.9397e-01, time/batch = 17.2215s	
31105/33150 (epoch 46.916), train_loss = 0.71836644, grad/param norm = 1.8392e-01, time/batch = 15.7277s	
31106/33150 (epoch 46.917), train_loss = 0.80603289, grad/param norm = 2.0159e-01, time/batch = 17.7978s	
31107/33150 (epoch 46.919), train_loss = 0.90432997, grad/param norm = 2.3441e-01, time/batch = 16.2091s	
31108/33150 (epoch 46.920), train_loss = 0.86311084, grad/param norm = 1.7881e-01, time/batch = 18.2220s	
31109/33150 (epoch 46.922), train_loss = 0.88403316, grad/param norm = 2.0941e-01, time/batch = 18.2221s	
31110/33150 (epoch 46.923), train_loss = 0.80998646, grad/param norm = 1.8334e-01, time/batch = 17.4571s	
31111/33150 (epoch 46.925), train_loss = 0.88661293, grad/param norm = 2.1511e-01, time/batch = 16.3938s	
31112/33150 (epoch 46.926), train_loss = 0.78927054, grad/param norm = 1.7642e-01, time/batch = 19.0509s	
31113/33150 (epoch 46.928), train_loss = 0.76525918, grad/param norm = 1.8576e-01, time/batch = 16.4889s	
31114/33150 (epoch 46.929), train_loss = 0.82275419, grad/param norm = 1.6990e-01, time/batch = 16.1951s	
31115/33150 (epoch 46.931), train_loss = 0.87538868, grad/param norm = 2.0382e-01, time/batch = 18.6415s	
31116/33150 (epoch 46.932), train_loss = 0.80501887, grad/param norm = 2.1677e-01, time/batch = 16.9737s	
31117/33150 (epoch 46.934), train_loss = 0.79272680, grad/param norm = 1.7212e-01, time/batch = 16.5605s	
31118/33150 (epoch 46.935), train_loss = 0.86186523, grad/param norm = 1.8866e-01, time/batch = 15.6192s	
31119/33150 (epoch 46.937), train_loss = 0.90387179, grad/param norm = 1.7663e-01, time/batch = 18.1366s	
31120/33150 (epoch 46.938), train_loss = 0.82404799, grad/param norm = 1.8214e-01, time/batch = 17.9719s	
31121/33150 (epoch 46.940), train_loss = 1.01057078, grad/param norm = 2.0450e-01, time/batch = 17.4686s	
31122/33150 (epoch 46.941), train_loss = 0.84486884, grad/param norm = 1.7400e-01, time/batch = 17.7988s	
31123/33150 (epoch 46.943), train_loss = 0.65808233, grad/param norm = 1.6965e-01, time/batch = 18.0582s	
31124/33150 (epoch 46.944), train_loss = 0.83970364, grad/param norm = 1.9213e-01, time/batch = 17.4701s	
31125/33150 (epoch 46.946), train_loss = 0.70167339, grad/param norm = 1.5400e-01, time/batch = 17.8819s	
31126/33150 (epoch 46.947), train_loss = 0.81253380, grad/param norm = 2.3387e-01, time/batch = 19.0559s	
31127/33150 (epoch 46.949), train_loss = 0.86465946, grad/param norm = 1.6375e-01, time/batch = 17.8055s	
31128/33150 (epoch 46.950), train_loss = 0.88061550, grad/param norm = 2.7158e-01, time/batch = 17.2929s	
31129/33150 (epoch 46.952), train_loss = 0.73283776, grad/param norm = 1.7730e-01, time/batch = 19.1448s	
31130/33150 (epoch 46.953), train_loss = 0.78833764, grad/param norm = 1.6325e-01, time/batch = 18.8020s	
31131/33150 (epoch 46.955), train_loss = 0.66962409, grad/param norm = 2.1604e-01, time/batch = 16.1219s	
31132/33150 (epoch 46.956), train_loss = 0.83658164, grad/param norm = 1.8121e-01, time/batch = 19.2919s	
31133/33150 (epoch 46.958), train_loss = 0.71761730, grad/param norm = 1.6146e-01, time/batch = 17.0637s	
31134/33150 (epoch 46.959), train_loss = 0.79089087, grad/param norm = 1.8228e-01, time/batch = 17.6416s	
31135/33150 (epoch 46.961), train_loss = 0.72213890, grad/param norm = 1.8484e-01, time/batch = 16.5737s	
31136/33150 (epoch 46.962), train_loss = 0.67738592, grad/param norm = 1.6905e-01, time/batch = 17.2906s	
31137/33150 (epoch 46.964), train_loss = 0.78554129, grad/param norm = 2.0318e-01, time/batch = 16.7198s	
31138/33150 (epoch 46.965), train_loss = 0.75465494, grad/param norm = 1.6246e-01, time/batch = 17.4671s	
31139/33150 (epoch 46.967), train_loss = 0.77310676, grad/param norm = 1.8334e-01, time/batch = 18.3050s	
31140/33150 (epoch 46.968), train_loss = 0.66740821, grad/param norm = 1.5691e-01, time/batch = 16.3632s	
31141/33150 (epoch 46.970), train_loss = 0.73915078, grad/param norm = 1.6363e-01, time/batch = 16.6368s	
31142/33150 (epoch 46.971), train_loss = 0.78919340, grad/param norm = 2.1301e-01, time/batch = 18.2370s	
31143/33150 (epoch 46.973), train_loss = 0.87759042, grad/param norm = 1.9200e-01, time/batch = 17.4655s	
31144/33150 (epoch 46.974), train_loss = 0.90259752, grad/param norm = 1.8996e-01, time/batch = 16.2281s	
31145/33150 (epoch 46.976), train_loss = 0.88631124, grad/param norm = 1.9202e-01, time/batch = 15.7290s	
31146/33150 (epoch 46.977), train_loss = 0.90826439, grad/param norm = 1.9792e-01, time/batch = 16.6419s	
31147/33150 (epoch 46.979), train_loss = 0.87019393, grad/param norm = 2.2257e-01, time/batch = 16.2958s	
31148/33150 (epoch 46.980), train_loss = 0.94005330, grad/param norm = 2.2691e-01, time/batch = 16.5623s	
31149/33150 (epoch 46.982), train_loss = 0.80408085, grad/param norm = 2.9264e-01, time/batch = 17.5519s	
31150/33150 (epoch 46.983), train_loss = 0.72927021, grad/param norm = 2.0711e-01, time/batch = 18.2899s	
31151/33150 (epoch 46.985), train_loss = 0.89856190, grad/param norm = 2.0608e-01, time/batch = 17.7065s	
31152/33150 (epoch 46.986), train_loss = 0.68456462, grad/param norm = 1.7144e-01, time/batch = 15.7133s	
31153/33150 (epoch 46.988), train_loss = 0.75883159, grad/param norm = 4.3405e-01, time/batch = 17.9489s	
31154/33150 (epoch 46.989), train_loss = 0.79314374, grad/param norm = 1.8966e-01, time/batch = 18.5520s	
31155/33150 (epoch 46.991), train_loss = 0.84661348, grad/param norm = 3.2908e-01, time/batch = 17.9622s	
31156/33150 (epoch 46.992), train_loss = 0.79761801, grad/param norm = 1.9802e-01, time/batch = 15.7084s	
31157/33150 (epoch 46.994), train_loss = 0.81487505, grad/param norm = 1.6920e-01, time/batch = 19.6159s	
31158/33150 (epoch 46.995), train_loss = 0.77632382, grad/param norm = 2.0439e-01, time/batch = 15.5293s	
31159/33150 (epoch 46.997), train_loss = 0.79231581, grad/param norm = 1.9755e-01, time/batch = 17.6261s	
31160/33150 (epoch 46.998), train_loss = 0.66808647, grad/param norm = 1.8158e-01, time/batch = 16.8742s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
31161/33150 (epoch 47.000), train_loss = 0.70423621, grad/param norm = 1.9382e-01, time/batch = 19.5430s	
31162/33150 (epoch 47.002), train_loss = 1.07509039, grad/param norm = 1.9625e-01, time/batch = 16.8927s	
31163/33150 (epoch 47.003), train_loss = 0.72809083, grad/param norm = 1.8521e-01, time/batch = 16.7980s	
31164/33150 (epoch 47.005), train_loss = 0.68094376, grad/param norm = 1.6026e-01, time/batch = 19.3633s	
31165/33150 (epoch 47.006), train_loss = 0.65693874, grad/param norm = 1.7014e-01, time/batch = 18.3646s	
31166/33150 (epoch 47.008), train_loss = 0.84735069, grad/param norm = 2.1692e-01, time/batch = 17.1408s	
31167/33150 (epoch 47.009), train_loss = 0.82419840, grad/param norm = 2.2594e-01, time/batch = 18.8835s	
31168/33150 (epoch 47.011), train_loss = 0.87873631, grad/param norm = 1.9604e-01, time/batch = 17.5372s	
31169/33150 (epoch 47.012), train_loss = 0.75132611, grad/param norm = 2.6590e-01, time/batch = 20.1349s	
31170/33150 (epoch 47.014), train_loss = 0.72587921, grad/param norm = 2.2534e-01, time/batch = 16.7949s	
31171/33150 (epoch 47.015), train_loss = 0.72081207, grad/param norm = 1.8764e-01, time/batch = 18.7277s	
31172/33150 (epoch 47.017), train_loss = 0.71665081, grad/param norm = 2.1167e-01, time/batch = 17.0229s	
31173/33150 (epoch 47.018), train_loss = 0.79903070, grad/param norm = 1.9757e-01, time/batch = 17.5555s	
31174/33150 (epoch 47.020), train_loss = 0.85299159, grad/param norm = 2.3170e-01, time/batch = 19.1225s	
31175/33150 (epoch 47.021), train_loss = 0.72445901, grad/param norm = 1.7192e-01, time/batch = 16.5623s	
31176/33150 (epoch 47.023), train_loss = 0.94793001, grad/param norm = 1.8069e-01, time/batch = 16.6525s	
31177/33150 (epoch 47.024), train_loss = 0.82094928, grad/param norm = 2.1508e-01, time/batch = 17.3916s	
31178/33150 (epoch 47.026), train_loss = 0.62170444, grad/param norm = 1.5772e-01, time/batch = 17.9718s	
31179/33150 (epoch 47.027), train_loss = 0.64028022, grad/param norm = 1.5134e-01, time/batch = 16.1219s	
31180/33150 (epoch 47.029), train_loss = 0.75189135, grad/param norm = 2.1947e-01, time/batch = 18.1424s	
31181/33150 (epoch 47.030), train_loss = 0.78308854, grad/param norm = 1.4673e-01, time/batch = 17.2209s	
31182/33150 (epoch 47.032), train_loss = 0.67563586, grad/param norm = 1.7835e-01, time/batch = 17.8842s	
31183/33150 (epoch 47.033), train_loss = 0.71854992, grad/param norm = 1.6795e-01, time/batch = 17.1487s	
31184/33150 (epoch 47.035), train_loss = 0.92919973, grad/param norm = 2.1299e-01, time/batch = 17.0585s	
31185/33150 (epoch 47.036), train_loss = 0.86413590, grad/param norm = 1.9315e-01, time/batch = 16.4559s	
31186/33150 (epoch 47.038), train_loss = 0.95077017, grad/param norm = 1.8895e-01, time/batch = 16.4627s	
31187/33150 (epoch 47.039), train_loss = 0.84402211, grad/param norm = 1.7854e-01, time/batch = 17.6421s	
31188/33150 (epoch 47.041), train_loss = 0.76195441, grad/param norm = 1.7424e-01, time/batch = 17.7134s	
31189/33150 (epoch 47.042), train_loss = 0.72062291, grad/param norm = 1.7525e-01, time/batch = 16.0601s	
31190/33150 (epoch 47.044), train_loss = 0.78018287, grad/param norm = 1.9232e-01, time/batch = 18.4766s	
31191/33150 (epoch 47.045), train_loss = 0.85021487, grad/param norm = 1.5053e-01, time/batch = 18.4650s	
31192/33150 (epoch 47.047), train_loss = 0.72762363, grad/param norm = 1.8638e-01, time/batch = 16.1998s	
31193/33150 (epoch 47.048), train_loss = 0.82082382, grad/param norm = 1.8924e-01, time/batch = 18.0500s	
31194/33150 (epoch 47.050), train_loss = 0.76131151, grad/param norm = 1.9210e-01, time/batch = 17.8915s	
31195/33150 (epoch 47.051), train_loss = 0.81516852, grad/param norm = 1.8623e-01, time/batch = 18.3063s	
31196/33150 (epoch 47.053), train_loss = 0.82365217, grad/param norm = 1.7865e-01, time/batch = 16.8021s	
31197/33150 (epoch 47.054), train_loss = 0.92310973, grad/param norm = 1.8739e-01, time/batch = 15.3062s	
31198/33150 (epoch 47.056), train_loss = 0.77292080, grad/param norm = 1.9374e-01, time/batch = 17.8772s	
31199/33150 (epoch 47.057), train_loss = 0.83883204, grad/param norm = 1.5971e-01, time/batch = 16.0325s	
31200/33150 (epoch 47.059), train_loss = 0.70657791, grad/param norm = 1.8666e-01, time/batch = 18.4578s	
31201/33150 (epoch 47.060), train_loss = 0.70572849, grad/param norm = 1.5367e-01, time/batch = 18.2990s	
31202/33150 (epoch 47.062), train_loss = 0.79181651, grad/param norm = 1.7867e-01, time/batch = 18.3661s	
31203/33150 (epoch 47.063), train_loss = 0.72780856, grad/param norm = 1.8489e-01, time/batch = 17.4687s	
31204/33150 (epoch 47.065), train_loss = 0.79235372, grad/param norm = 1.9285e-01, time/batch = 18.4641s	
31205/33150 (epoch 47.066), train_loss = 0.76328758, grad/param norm = 1.8834e-01, time/batch = 17.4491s	
31206/33150 (epoch 47.068), train_loss = 0.83344054, grad/param norm = 1.6907e-01, time/batch = 16.9531s	
31207/33150 (epoch 47.069), train_loss = 0.83541241, grad/param norm = 2.0720e-01, time/batch = 17.0677s	
31208/33150 (epoch 47.071), train_loss = 0.83051615, grad/param norm = 1.9038e-01, time/batch = 19.3706s	
31209/33150 (epoch 47.072), train_loss = 0.79652432, grad/param norm = 1.9048e-01, time/batch = 15.5453s	
31210/33150 (epoch 47.074), train_loss = 0.66730906, grad/param norm = 1.7912e-01, time/batch = 18.1948s	
31211/33150 (epoch 47.075), train_loss = 0.69178961, grad/param norm = 1.8475e-01, time/batch = 17.9628s	
31212/33150 (epoch 47.077), train_loss = 0.79236870, grad/param norm = 2.5749e-01, time/batch = 18.3042s	
31213/33150 (epoch 47.078), train_loss = 0.91221978, grad/param norm = 2.3655e-01, time/batch = 16.0407s	
31214/33150 (epoch 47.080), train_loss = 0.90466027, grad/param norm = 1.6240e-01, time/batch = 17.3900s	
31215/33150 (epoch 47.081), train_loss = 0.70968094, grad/param norm = 2.2088e-01, time/batch = 18.9530s	
31216/33150 (epoch 47.083), train_loss = 0.57792313, grad/param norm = 2.3049e-01, time/batch = 15.5329s	
31217/33150 (epoch 47.084), train_loss = 0.66985443, grad/param norm = 2.0951e-01, time/batch = 17.0559s	
31218/33150 (epoch 47.086), train_loss = 0.73420523, grad/param norm = 2.3161e-01, time/batch = 16.9793s	
31219/33150 (epoch 47.087), train_loss = 0.66974970, grad/param norm = 1.8480e-01, time/batch = 19.1381s	
31220/33150 (epoch 47.089), train_loss = 0.71222364, grad/param norm = 1.7487e-01, time/batch = 18.0530s	
31221/33150 (epoch 47.090), train_loss = 0.75276742, grad/param norm = 2.0240e-01, time/batch = 18.9828s	
31222/33150 (epoch 47.092), train_loss = 0.72084723, grad/param norm = 1.7326e-01, time/batch = 18.3018s	
31223/33150 (epoch 47.094), train_loss = 0.80650660, grad/param norm = 2.1535e-01, time/batch = 17.0466s	
31224/33150 (epoch 47.095), train_loss = 0.72177435, grad/param norm = 1.9599e-01, time/batch = 20.6177s	
31225/33150 (epoch 47.097), train_loss = 0.64600220, grad/param norm = 1.8745e-01, time/batch = 17.7162s	
31226/33150 (epoch 47.098), train_loss = 1.01209584, grad/param norm = 1.9831e-01, time/batch = 16.2078s	
31227/33150 (epoch 47.100), train_loss = 0.95309788, grad/param norm = 2.2265e-01, time/batch = 19.6267s	
31228/33150 (epoch 47.101), train_loss = 0.71885792, grad/param norm = 1.9284e-01, time/batch = 19.5530s	
31229/33150 (epoch 47.103), train_loss = 0.80756147, grad/param norm = 1.7966e-01, time/batch = 16.4483s	
31230/33150 (epoch 47.104), train_loss = 0.73161092, grad/param norm = 2.0505e-01, time/batch = 17.7329s	
31231/33150 (epoch 47.106), train_loss = 0.89965959, grad/param norm = 2.0176e-01, time/batch = 15.5683s	
31232/33150 (epoch 47.107), train_loss = 0.94620064, grad/param norm = 1.9112e-01, time/batch = 15.2711s	
31233/33150 (epoch 47.109), train_loss = 0.77225707, grad/param norm = 1.6408e-01, time/batch = 15.3804s	
31234/33150 (epoch 47.110), train_loss = 0.85945928, grad/param norm = 1.9656e-01, time/batch = 15.3950s	
31235/33150 (epoch 47.112), train_loss = 0.70915225, grad/param norm = 1.7276e-01, time/batch = 14.9688s	
31236/33150 (epoch 47.113), train_loss = 0.74690661, grad/param norm = 1.8335e-01, time/batch = 17.0569s	
31237/33150 (epoch 47.115), train_loss = 0.94330291, grad/param norm = 1.9371e-01, time/batch = 16.2860s	
31238/33150 (epoch 47.116), train_loss = 0.84816482, grad/param norm = 1.9276e-01, time/batch = 16.3913s	
31239/33150 (epoch 47.118), train_loss = 0.82408117, grad/param norm = 1.9156e-01, time/batch = 18.7967s	
31240/33150 (epoch 47.119), train_loss = 0.83515707, grad/param norm = 1.9535e-01, time/batch = 16.2221s	
31241/33150 (epoch 47.121), train_loss = 0.78800996, grad/param norm = 1.7631e-01, time/batch = 17.3913s	
31242/33150 (epoch 47.122), train_loss = 0.91154095, grad/param norm = 2.2795e-01, time/batch = 18.2145s	
31243/33150 (epoch 47.124), train_loss = 0.67303796, grad/param norm = 1.5211e-01, time/batch = 16.6274s	
31244/33150 (epoch 47.125), train_loss = 0.90559135, grad/param norm = 1.7723e-01, time/batch = 15.5083s	
31245/33150 (epoch 47.127), train_loss = 0.84452628, grad/param norm = 1.8628e-01, time/batch = 19.1316s	
31246/33150 (epoch 47.128), train_loss = 0.83783847, grad/param norm = 2.0131e-01, time/batch = 17.4691s	
31247/33150 (epoch 47.130), train_loss = 0.78067261, grad/param norm = 1.7336e-01, time/batch = 15.6994s	
31248/33150 (epoch 47.131), train_loss = 0.94707993, grad/param norm = 1.8764e-01, time/batch = 17.9512s	
31249/33150 (epoch 47.133), train_loss = 0.74105226, grad/param norm = 1.7177e-01, time/batch = 18.8059s	
31250/33150 (epoch 47.134), train_loss = 0.88610064, grad/param norm = 1.7145e-01, time/batch = 16.9024s	
31251/33150 (epoch 47.136), train_loss = 0.80707731, grad/param norm = 1.9838e-01, time/batch = 17.3570s	
31252/33150 (epoch 47.137), train_loss = 0.85665439, grad/param norm = 1.7722e-01, time/batch = 18.2098s	
31253/33150 (epoch 47.139), train_loss = 0.85332512, grad/param norm = 1.8599e-01, time/batch = 15.5156s	
31254/33150 (epoch 47.140), train_loss = 0.92914400, grad/param norm = 1.8287e-01, time/batch = 17.0454s	
31255/33150 (epoch 47.142), train_loss = 0.84962593, grad/param norm = 2.3174e-01, time/batch = 15.8056s	
31256/33150 (epoch 47.143), train_loss = 0.79400101, grad/param norm = 2.1413e-01, time/batch = 19.7086s	
31257/33150 (epoch 47.145), train_loss = 0.76256974, grad/param norm = 2.2010e-01, time/batch = 15.8787s	
31258/33150 (epoch 47.146), train_loss = 0.90658152, grad/param norm = 2.4897e-01, time/batch = 16.5203s	
31259/33150 (epoch 47.148), train_loss = 0.93737722, grad/param norm = 1.6898e-01, time/batch = 18.7171s	
31260/33150 (epoch 47.149), train_loss = 0.81528624, grad/param norm = 1.8737e-01, time/batch = 17.7215s	
31261/33150 (epoch 47.151), train_loss = 0.94477522, grad/param norm = 2.3020e-01, time/batch = 15.6253s	
31262/33150 (epoch 47.152), train_loss = 0.74026323, grad/param norm = 1.8151e-01, time/batch = 18.0625s	
31263/33150 (epoch 47.154), train_loss = 0.72527717, grad/param norm = 1.6104e-01, time/batch = 18.7233s	
31264/33150 (epoch 47.155), train_loss = 0.67480101, grad/param norm = 1.7511e-01, time/batch = 18.2833s	
31265/33150 (epoch 47.157), train_loss = 0.79406303, grad/param norm = 2.2355e-01, time/batch = 16.3819s	
31266/33150 (epoch 47.158), train_loss = 0.78856953, grad/param norm = 1.7375e-01, time/batch = 16.8842s	
31267/33150 (epoch 47.160), train_loss = 0.85786916, grad/param norm = 1.8270e-01, time/batch = 19.8750s	
31268/33150 (epoch 47.161), train_loss = 0.77923618, grad/param norm = 2.4263e-01, time/batch = 15.6267s	
31269/33150 (epoch 47.163), train_loss = 0.68387779, grad/param norm = 1.5429e-01, time/batch = 18.2226s	
31270/33150 (epoch 47.164), train_loss = 0.82703956, grad/param norm = 1.6591e-01, time/batch = 18.6356s	
31271/33150 (epoch 47.166), train_loss = 0.76613654, grad/param norm = 2.1402e-01, time/batch = 16.2036s	
31272/33150 (epoch 47.167), train_loss = 0.82211467, grad/param norm = 1.6440e-01, time/batch = 18.4621s	
31273/33150 (epoch 47.169), train_loss = 0.81102121, grad/param norm = 2.1976e-01, time/batch = 19.2210s	
31274/33150 (epoch 47.170), train_loss = 0.71624610, grad/param norm = 2.4421e-01, time/batch = 16.9352s	
31275/33150 (epoch 47.172), train_loss = 0.83216876, grad/param norm = 2.0479e-01, time/batch = 15.7997s	
31276/33150 (epoch 47.173), train_loss = 0.79649629, grad/param norm = 1.8705e-01, time/batch = 16.1381s	
31277/33150 (epoch 47.175), train_loss = 0.78868430, grad/param norm = 2.7004e-01, time/batch = 17.3880s	
31278/33150 (epoch 47.176), train_loss = 0.86873783, grad/param norm = 2.1217e-01, time/batch = 16.6441s	
31279/33150 (epoch 47.178), train_loss = 0.97957114, grad/param norm = 2.3945e-01, time/batch = 15.9820s	
31280/33150 (epoch 47.179), train_loss = 0.84564767, grad/param norm = 1.7185e-01, time/batch = 17.0755s	
31281/33150 (epoch 47.181), train_loss = 0.81796350, grad/param norm = 2.4083e-01, time/batch = 18.2228s	
31282/33150 (epoch 47.183), train_loss = 0.77383065, grad/param norm = 2.2163e-01, time/batch = 31.4646s	
31283/33150 (epoch 47.184), train_loss = 1.03268947, grad/param norm = 2.1837e-01, time/batch = 17.8882s	
31284/33150 (epoch 47.186), train_loss = 0.96585515, grad/param norm = 1.7055e-01, time/batch = 15.8729s	
31285/33150 (epoch 47.187), train_loss = 0.79792884, grad/param norm = 2.0213e-01, time/batch = 15.3766s	
31286/33150 (epoch 47.189), train_loss = 0.64253612, grad/param norm = 1.8090e-01, time/batch = 15.9459s	
31287/33150 (epoch 47.190), train_loss = 0.74282648, grad/param norm = 2.1038e-01, time/batch = 16.8626s	
31288/33150 (epoch 47.192), train_loss = 0.81351159, grad/param norm = 1.9750e-01, time/batch = 15.3718s	
31289/33150 (epoch 47.193), train_loss = 0.86400616, grad/param norm = 1.8361e-01, time/batch = 15.2980s	
31290/33150 (epoch 47.195), train_loss = 0.97244278, grad/param norm = 2.0585e-01, time/batch = 16.0617s	
31291/33150 (epoch 47.196), train_loss = 0.91684009, grad/param norm = 1.7831e-01, time/batch = 14.9604s	
31292/33150 (epoch 47.198), train_loss = 0.71296447, grad/param norm = 1.5871e-01, time/batch = 15.2867s	
31293/33150 (epoch 47.199), train_loss = 0.87907306, grad/param norm = 2.6141e-01, time/batch = 15.3141s	
31294/33150 (epoch 47.201), train_loss = 0.77870742, grad/param norm = 1.6735e-01, time/batch = 16.6466s	
31295/33150 (epoch 47.202), train_loss = 0.64256829, grad/param norm = 1.7414e-01, time/batch = 18.0521s	
31296/33150 (epoch 47.204), train_loss = 0.80469244, grad/param norm = 1.9111e-01, time/batch = 17.0385s	
31297/33150 (epoch 47.205), train_loss = 0.83734613, grad/param norm = 2.1317e-01, time/batch = 18.6304s	
31298/33150 (epoch 47.207), train_loss = 0.83045332, grad/param norm = 2.0143e-01, time/batch = 16.0441s	
31299/33150 (epoch 47.208), train_loss = 0.88897709, grad/param norm = 1.9587e-01, time/batch = 16.4644s	
31300/33150 (epoch 47.210), train_loss = 0.74735438, grad/param norm = 1.6523e-01, time/batch = 17.3171s	
31301/33150 (epoch 47.211), train_loss = 0.79075999, grad/param norm = 2.1641e-01, time/batch = 17.1423s	
31302/33150 (epoch 47.213), train_loss = 0.87535166, grad/param norm = 1.9336e-01, time/batch = 17.5576s	
31303/33150 (epoch 47.214), train_loss = 0.77422693, grad/param norm = 1.6191e-01, time/batch = 16.8863s	
31304/33150 (epoch 47.216), train_loss = 0.73361908, grad/param norm = 1.8917e-01, time/batch = 17.3794s	
31305/33150 (epoch 47.217), train_loss = 0.82312139, grad/param norm = 1.9072e-01, time/batch = 16.6239s	
31306/33150 (epoch 47.219), train_loss = 0.75544806, grad/param norm = 1.9016e-01, time/batch = 16.5595s	
31307/33150 (epoch 47.220), train_loss = 0.78628431, grad/param norm = 1.6825e-01, time/batch = 16.8938s	
31308/33150 (epoch 47.222), train_loss = 0.88079455, grad/param norm = 1.9218e-01, time/batch = 20.5354s	
31309/33150 (epoch 47.223), train_loss = 0.80497219, grad/param norm = 1.9552e-01, time/batch = 14.9609s	
31310/33150 (epoch 47.225), train_loss = 0.91659562, grad/param norm = 1.9021e-01, time/batch = 15.6396s	
31311/33150 (epoch 47.226), train_loss = 0.76211160, grad/param norm = 1.7897e-01, time/batch = 18.2953s	
31312/33150 (epoch 47.228), train_loss = 0.76512120, grad/param norm = 2.0630e-01, time/batch = 17.7312s	
31313/33150 (epoch 47.229), train_loss = 0.80700832, grad/param norm = 2.0226e-01, time/batch = 16.5398s	
31314/33150 (epoch 47.231), train_loss = 0.89935219, grad/param norm = 2.7091e-01, time/batch = 16.4000s	
31315/33150 (epoch 47.232), train_loss = 0.76898050, grad/param norm = 1.7588e-01, time/batch = 18.9773s	
31316/33150 (epoch 47.234), train_loss = 0.82836863, grad/param norm = 1.8473e-01, time/batch = 18.2065s	
31317/33150 (epoch 47.235), train_loss = 0.87533001, grad/param norm = 1.9128e-01, time/batch = 17.9543s	
31318/33150 (epoch 47.237), train_loss = 0.81470398, grad/param norm = 2.5883e-01, time/batch = 16.1366s	
31319/33150 (epoch 47.238), train_loss = 0.86003922, grad/param norm = 2.1639e-01, time/batch = 16.4806s	
31320/33150 (epoch 47.240), train_loss = 0.80870491, grad/param norm = 1.8712e-01, time/batch = 17.1301s	
31321/33150 (epoch 47.241), train_loss = 0.88445545, grad/param norm = 1.9795e-01, time/batch = 18.8780s	
31322/33150 (epoch 47.243), train_loss = 0.85345575, grad/param norm = 1.8662e-01, time/batch = 16.4711s	
31323/33150 (epoch 47.244), train_loss = 0.82169212, grad/param norm = 1.7229e-01, time/batch = 16.6529s	
31324/33150 (epoch 47.246), train_loss = 0.88523483, grad/param norm = 2.0462e-01, time/batch = 15.2943s	
31325/33150 (epoch 47.247), train_loss = 0.75696920, grad/param norm = 1.6861e-01, time/batch = 18.9588s	
31326/33150 (epoch 47.249), train_loss = 0.93295093, grad/param norm = 1.7452e-01, time/batch = 17.7236s	
31327/33150 (epoch 47.250), train_loss = 0.84601754, grad/param norm = 1.7596e-01, time/batch = 15.8939s	
31328/33150 (epoch 47.252), train_loss = 0.87526108, grad/param norm = 1.6371e-01, time/batch = 16.9637s	
31329/33150 (epoch 47.253), train_loss = 0.79647546, grad/param norm = 2.4952e-01, time/batch = 18.4743s	
31330/33150 (epoch 47.255), train_loss = 0.79741987, grad/param norm = 1.6805e-01, time/batch = 17.0680s	
31331/33150 (epoch 47.256), train_loss = 0.89012259, grad/param norm = 1.9609e-01, time/batch = 16.8014s	
31332/33150 (epoch 47.258), train_loss = 0.77087398, grad/param norm = 1.9946e-01, time/batch = 18.7812s	
31333/33150 (epoch 47.259), train_loss = 0.64758582, grad/param norm = 1.9085e-01, time/batch = 19.1341s	
31334/33150 (epoch 47.261), train_loss = 0.73447981, grad/param norm = 1.6434e-01, time/batch = 17.2040s	
31335/33150 (epoch 47.262), train_loss = 0.92337378, grad/param norm = 1.9894e-01, time/batch = 19.2866s	
31336/33150 (epoch 47.264), train_loss = 0.64356863, grad/param norm = 1.6057e-01, time/batch = 20.2062s	
31337/33150 (epoch 47.265), train_loss = 0.81397029, grad/param norm = 2.0228e-01, time/batch = 17.0415s	
31338/33150 (epoch 47.267), train_loss = 0.91163572, grad/param norm = 2.1132e-01, time/batch = 19.2873s	
31339/33150 (epoch 47.268), train_loss = 0.94158167, grad/param norm = 1.8912e-01, time/batch = 17.2116s	
31340/33150 (epoch 47.270), train_loss = 0.98937418, grad/param norm = 1.7708e-01, time/batch = 17.2976s	
31341/33150 (epoch 47.271), train_loss = 0.85668864, grad/param norm = 2.0198e-01, time/batch = 16.6258s	
31342/33150 (epoch 47.273), train_loss = 0.90799945, grad/param norm = 1.9466e-01, time/batch = 19.1319s	
31343/33150 (epoch 47.275), train_loss = 0.92403352, grad/param norm = 1.9231e-01, time/batch = 18.1433s	
31344/33150 (epoch 47.276), train_loss = 0.80259017, grad/param norm = 1.9127e-01, time/batch = 17.3015s	
31345/33150 (epoch 47.278), train_loss = 0.91714882, grad/param norm = 1.9215e-01, time/batch = 16.6890s	
31346/33150 (epoch 47.279), train_loss = 0.90500575, grad/param norm = 1.8059e-01, time/batch = 20.6168s	
31347/33150 (epoch 47.281), train_loss = 0.81039807, grad/param norm = 1.7909e-01, time/batch = 17.0474s	
31348/33150 (epoch 47.282), train_loss = 0.87390361, grad/param norm = 1.6078e-01, time/batch = 19.1342s	
31349/33150 (epoch 47.284), train_loss = 0.75169032, grad/param norm = 1.6507e-01, time/batch = 20.2045s	
31350/33150 (epoch 47.285), train_loss = 0.87112851, grad/param norm = 2.2101e-01, time/batch = 16.6131s	
31351/33150 (epoch 47.287), train_loss = 0.74795066, grad/param norm = 1.8850e-01, time/batch = 20.1083s	
31352/33150 (epoch 47.288), train_loss = 0.87946020, grad/param norm = 1.8393e-01, time/batch = 17.8712s	
31353/33150 (epoch 47.290), train_loss = 0.69730632, grad/param norm = 1.8078e-01, time/batch = 18.0549s	
31354/33150 (epoch 47.291), train_loss = 0.68200811, grad/param norm = 1.9384e-01, time/batch = 20.1821s	
31355/33150 (epoch 47.293), train_loss = 0.75967305, grad/param norm = 1.8169e-01, time/batch = 17.0345s	
31356/33150 (epoch 47.294), train_loss = 0.65292884, grad/param norm = 1.7014e-01, time/batch = 18.4606s	
31357/33150 (epoch 47.296), train_loss = 0.80540188, grad/param norm = 1.7537e-01, time/batch = 16.6350s	
31358/33150 (epoch 47.297), train_loss = 0.74784896, grad/param norm = 1.8100e-01, time/batch = 19.6438s	
31359/33150 (epoch 47.299), train_loss = 0.73244756, grad/param norm = 1.8391e-01, time/batch = 18.3771s	
31360/33150 (epoch 47.300), train_loss = 0.77533015, grad/param norm = 1.5785e-01, time/batch = 17.6310s	
31361/33150 (epoch 47.302), train_loss = 0.77629650, grad/param norm = 1.7614e-01, time/batch = 17.3800s	
31362/33150 (epoch 47.303), train_loss = 0.77493948, grad/param norm = 2.0314e-01, time/batch = 18.3537s	
31363/33150 (epoch 47.305), train_loss = 0.87918209, grad/param norm = 2.0489e-01, time/batch = 16.4541s	
31364/33150 (epoch 47.306), train_loss = 0.85389396, grad/param norm = 2.2129e-01, time/batch = 18.5335s	
31365/33150 (epoch 47.308), train_loss = 0.99060165, grad/param norm = 1.8183e-01, time/batch = 17.0255s	
31366/33150 (epoch 47.309), train_loss = 0.66070722, grad/param norm = 1.4763e-01, time/batch = 16.6474s	
31367/33150 (epoch 47.311), train_loss = 0.81032942, grad/param norm = 2.0231e-01, time/batch = 15.2015s	
31368/33150 (epoch 47.312), train_loss = 0.66595478, grad/param norm = 1.6606e-01, time/batch = 15.4533s	
31369/33150 (epoch 47.314), train_loss = 0.77518261, grad/param norm = 2.0784e-01, time/batch = 19.3584s	
31370/33150 (epoch 47.315), train_loss = 0.85942397, grad/param norm = 2.0782e-01, time/batch = 17.6200s	
31371/33150 (epoch 47.317), train_loss = 0.64539136, grad/param norm = 1.4753e-01, time/batch = 18.1084s	
31372/33150 (epoch 47.318), train_loss = 0.74832606, grad/param norm = 1.8502e-01, time/batch = 16.7805s	
31373/33150 (epoch 47.320), train_loss = 0.67606025, grad/param norm = 1.8635e-01, time/batch = 17.7988s	
31374/33150 (epoch 47.321), train_loss = 0.76959566, grad/param norm = 1.7681e-01, time/batch = 15.7973s	
31375/33150 (epoch 47.323), train_loss = 0.74958653, grad/param norm = 1.8325e-01, time/batch = 18.7926s	
31376/33150 (epoch 47.324), train_loss = 0.77760170, grad/param norm = 2.5570e-01, time/batch = 17.9725s	
31377/33150 (epoch 47.326), train_loss = 0.78170066, grad/param norm = 1.6845e-01, time/batch = 17.6244s	
31378/33150 (epoch 47.327), train_loss = 0.89751776, grad/param norm = 1.8996e-01, time/batch = 16.1330s	
31379/33150 (epoch 47.329), train_loss = 0.85103765, grad/param norm = 1.8541e-01, time/batch = 19.2977s	
31380/33150 (epoch 47.330), train_loss = 0.74526620, grad/param norm = 1.7141e-01, time/batch = 17.1188s	
31381/33150 (epoch 47.332), train_loss = 0.77049716, grad/param norm = 1.7599e-01, time/batch = 16.3146s	
31382/33150 (epoch 47.333), train_loss = 0.84945177, grad/param norm = 1.6281e-01, time/batch = 18.2941s	
31383/33150 (epoch 47.335), train_loss = 0.71680572, grad/param norm = 1.7494e-01, time/batch = 18.8030s	
31384/33150 (epoch 47.336), train_loss = 0.73499354, grad/param norm = 2.1716e-01, time/batch = 15.5234s	
31385/33150 (epoch 47.338), train_loss = 0.66784802, grad/param norm = 1.9361e-01, time/batch = 16.7708s	
31386/33150 (epoch 47.339), train_loss = 0.85487906, grad/param norm = 2.1788e-01, time/batch = 15.6125s	
31387/33150 (epoch 47.341), train_loss = 0.78414411, grad/param norm = 2.0876e-01, time/batch = 15.2794s	
31388/33150 (epoch 47.342), train_loss = 0.73650263, grad/param norm = 1.7082e-01, time/batch = 15.5156s	
31389/33150 (epoch 47.344), train_loss = 0.77137912, grad/param norm = 1.9533e-01, time/batch = 15.1541s	
31390/33150 (epoch 47.345), train_loss = 0.77184298, grad/param norm = 1.7391e-01, time/batch = 15.9528s	
31391/33150 (epoch 47.347), train_loss = 0.67224610, grad/param norm = 1.7789e-01, time/batch = 16.0449s	
31392/33150 (epoch 47.348), train_loss = 0.79611490, grad/param norm = 1.6750e-01, time/batch = 16.7069s	
31393/33150 (epoch 47.350), train_loss = 0.70007603, grad/param norm = 2.2318e-01, time/batch = 16.6375s	
31394/33150 (epoch 47.351), train_loss = 0.86333780, grad/param norm = 2.1465e-01, time/batch = 16.8784s	
31395/33150 (epoch 47.353), train_loss = 0.83510667, grad/param norm = 1.9263e-01, time/batch = 16.0472s	
31396/33150 (epoch 47.354), train_loss = 0.99562073, grad/param norm = 1.9755e-01, time/batch = 18.2900s	
31397/33150 (epoch 47.356), train_loss = 0.88892711, grad/param norm = 1.8672e-01, time/batch = 17.9676s	
31398/33150 (epoch 47.357), train_loss = 0.80700830, grad/param norm = 2.1614e-01, time/batch = 16.3055s	
31399/33150 (epoch 47.359), train_loss = 0.87826102, grad/param norm = 1.8994e-01, time/batch = 15.8938s	
31400/33150 (epoch 47.360), train_loss = 0.84351912, grad/param norm = 1.9133e-01, time/batch = 16.4405s	
31401/33150 (epoch 47.362), train_loss = 0.90562780, grad/param norm = 1.9192e-01, time/batch = 17.3801s	
31402/33150 (epoch 47.363), train_loss = 0.82530844, grad/param norm = 1.7532e-01, time/batch = 15.5460s	
31403/33150 (epoch 47.365), train_loss = 0.78301932, grad/param norm = 1.8258e-01, time/batch = 16.7116s	
31404/33150 (epoch 47.367), train_loss = 0.76701112, grad/param norm = 1.7312e-01, time/batch = 18.4609s	
31405/33150 (epoch 47.368), train_loss = 0.76501005, grad/param norm = 2.3706e-01, time/batch = 16.6475s	
31406/33150 (epoch 47.370), train_loss = 0.82704021, grad/param norm = 2.0519e-01, time/batch = 15.9621s	
31407/33150 (epoch 47.371), train_loss = 0.71051978, grad/param norm = 1.8039e-01, time/batch = 18.0578s	
31408/33150 (epoch 47.373), train_loss = 0.83258512, grad/param norm = 2.2289e-01, time/batch = 16.2742s	
31409/33150 (epoch 47.374), train_loss = 0.81801411, grad/param norm = 1.6490e-01, time/batch = 16.5376s	
31410/33150 (epoch 47.376), train_loss = 0.87565016, grad/param norm = 1.8154e-01, time/batch = 17.8801s	
31411/33150 (epoch 47.377), train_loss = 0.73012169, grad/param norm = 1.8827e-01, time/batch = 18.1260s	
31412/33150 (epoch 47.379), train_loss = 0.82368562, grad/param norm = 1.9785e-01, time/batch = 16.6382s	
31413/33150 (epoch 47.380), train_loss = 0.87255731, grad/param norm = 1.7995e-01, time/batch = 17.2769s	
31414/33150 (epoch 47.382), train_loss = 0.80016808, grad/param norm = 1.7168e-01, time/batch = 17.6996s	
31415/33150 (epoch 47.383), train_loss = 0.72346741, grad/param norm = 1.7558e-01, time/batch = 16.2099s	
31416/33150 (epoch 47.385), train_loss = 0.74863359, grad/param norm = 1.8283e-01, time/batch = 15.1406s	
31417/33150 (epoch 47.386), train_loss = 0.70292352, grad/param norm = 1.4599e-01, time/batch = 17.9722s	
31418/33150 (epoch 47.388), train_loss = 0.72118418, grad/param norm = 1.7674e-01, time/batch = 18.3919s	
31419/33150 (epoch 47.389), train_loss = 0.71565518, grad/param norm = 1.5330e-01, time/batch = 18.2129s	
31420/33150 (epoch 47.391), train_loss = 0.91880899, grad/param norm = 2.2379e-01, time/batch = 16.9503s	
31421/33150 (epoch 47.392), train_loss = 0.72431471, grad/param norm = 1.6722e-01, time/batch = 18.8921s	
31422/33150 (epoch 47.394), train_loss = 0.69121824, grad/param norm = 1.4385e-01, time/batch = 18.3928s	
31423/33150 (epoch 47.395), train_loss = 0.64041961, grad/param norm = 1.6064e-01, time/batch = 17.0556s	
31424/33150 (epoch 47.397), train_loss = 0.54360622, grad/param norm = 1.5753e-01, time/batch = 18.7757s	
31425/33150 (epoch 47.398), train_loss = 0.80019604, grad/param norm = 1.7725e-01, time/batch = 18.1386s	
31426/33150 (epoch 47.400), train_loss = 0.79414903, grad/param norm = 1.9739e-01, time/batch = 16.9541s	
31427/33150 (epoch 47.401), train_loss = 0.65928294, grad/param norm = 1.4598e-01, time/batch = 17.8953s	
31428/33150 (epoch 47.403), train_loss = 0.67544473, grad/param norm = 1.5337e-01, time/batch = 18.8800s	
31429/33150 (epoch 47.404), train_loss = 0.76902999, grad/param norm = 1.7745e-01, time/batch = 16.9639s	
31430/33150 (epoch 47.406), train_loss = 0.75690097, grad/param norm = 1.5688e-01, time/batch = 18.0357s	
31431/33150 (epoch 47.407), train_loss = 0.66782337, grad/param norm = 1.5318e-01, time/batch = 17.4634s	
31432/33150 (epoch 47.409), train_loss = 0.64052563, grad/param norm = 1.8760e-01, time/batch = 18.8647s	
31433/33150 (epoch 47.410), train_loss = 0.79044699, grad/param norm = 1.7424e-01, time/batch = 18.1922s	
31434/33150 (epoch 47.412), train_loss = 0.81883664, grad/param norm = 1.5612e-01, time/batch = 18.4722s	
31435/33150 (epoch 47.413), train_loss = 0.68216252, grad/param norm = 1.5649e-01, time/batch = 17.2125s	
31436/33150 (epoch 47.415), train_loss = 0.78210354, grad/param norm = 1.5909e-01, time/batch = 16.7087s	
31437/33150 (epoch 47.416), train_loss = 0.70442116, grad/param norm = 1.5801e-01, time/batch = 18.3011s	
31438/33150 (epoch 47.418), train_loss = 0.80499151, grad/param norm = 2.2445e-01, time/batch = 19.5355s	
31439/33150 (epoch 47.419), train_loss = 0.78021312, grad/param norm = 1.8224e-01, time/batch = 17.1136s	
31440/33150 (epoch 47.421), train_loss = 0.78839881, grad/param norm = 2.2870e-01, time/batch = 15.6927s	
31441/33150 (epoch 47.422), train_loss = 0.76879136, grad/param norm = 1.6349e-01, time/batch = 18.7955s	
31442/33150 (epoch 47.424), train_loss = 0.69461342, grad/param norm = 2.0411e-01, time/batch = 18.7156s	
31443/33150 (epoch 47.425), train_loss = 0.85629572, grad/param norm = 1.8372e-01, time/batch = 16.6178s	
31444/33150 (epoch 47.427), train_loss = 0.79905308, grad/param norm = 1.6638e-01, time/batch = 16.6408s	
31445/33150 (epoch 47.428), train_loss = 0.72099992, grad/param norm = 1.6693e-01, time/batch = 18.8928s	
31446/33150 (epoch 47.430), train_loss = 0.78492196, grad/param norm = 1.8715e-01, time/batch = 16.2220s	
31447/33150 (epoch 47.431), train_loss = 0.83848618, grad/param norm = 1.8611e-01, time/batch = 16.8258s	
31448/33150 (epoch 47.433), train_loss = 0.76229661, grad/param norm = 2.1028e-01, time/batch = 18.0505s	
31449/33150 (epoch 47.434), train_loss = 0.67163174, grad/param norm = 1.8088e-01, time/batch = 16.6052s	
31450/33150 (epoch 47.436), train_loss = 0.79399582, grad/param norm = 1.5559e-01, time/batch = 16.3786s	
31451/33150 (epoch 47.437), train_loss = 0.78802334, grad/param norm = 2.1383e-01, time/batch = 17.8141s	
31452/33150 (epoch 47.439), train_loss = 0.94708495, grad/param norm = 1.9545e-01, time/batch = 18.7224s	
31453/33150 (epoch 47.440), train_loss = 0.83936466, grad/param norm = 1.9417e-01, time/batch = 16.2863s	
31454/33150 (epoch 47.442), train_loss = 0.66228075, grad/param norm = 1.7177e-01, time/batch = 16.5209s	
31455/33150 (epoch 47.443), train_loss = 0.78651233, grad/param norm = 1.8700e-01, time/batch = 16.1469s	
31456/33150 (epoch 47.445), train_loss = 0.78742818, grad/param norm = 1.8918e-01, time/batch = 16.9675s	
31457/33150 (epoch 47.446), train_loss = 0.81672987, grad/param norm = 2.3821e-01, time/batch = 17.4749s	
31458/33150 (epoch 47.448), train_loss = 0.86953482, grad/param norm = 1.8080e-01, time/batch = 17.8995s	
31459/33150 (epoch 47.449), train_loss = 0.78224194, grad/param norm = 1.5043e-01, time/batch = 16.9672s	
31460/33150 (epoch 47.451), train_loss = 0.77543206, grad/param norm = 1.8619e-01, time/batch = 16.3080s	
31461/33150 (epoch 47.452), train_loss = 0.94632167, grad/param norm = 1.8414e-01, time/batch = 17.0620s	
31462/33150 (epoch 47.454), train_loss = 0.76850273, grad/param norm = 1.7029e-01, time/batch = 16.9040s	
31463/33150 (epoch 47.456), train_loss = 0.73378820, grad/param norm = 1.7970e-01, time/batch = 15.5634s	
31464/33150 (epoch 47.457), train_loss = 0.78143550, grad/param norm = 1.8636e-01, time/batch = 15.8000s	
31465/33150 (epoch 47.459), train_loss = 0.90494492, grad/param norm = 2.2989e-01, time/batch = 18.4770s	
31466/33150 (epoch 47.460), train_loss = 0.85742662, grad/param norm = 1.7328e-01, time/batch = 16.7150s	
31467/33150 (epoch 47.462), train_loss = 0.90179760, grad/param norm = 2.2736e-01, time/batch = 15.3879s	
31468/33150 (epoch 47.463), train_loss = 0.99331889, grad/param norm = 2.6954e-01, time/batch = 16.8158s	
31469/33150 (epoch 47.465), train_loss = 0.85320593, grad/param norm = 1.9471e-01, time/batch = 18.0595s	
31470/33150 (epoch 47.466), train_loss = 0.75136454, grad/param norm = 1.6895e-01, time/batch = 19.1350s	
31471/33150 (epoch 47.468), train_loss = 0.98514008, grad/param norm = 1.9379e-01, time/batch = 16.2833s	
31472/33150 (epoch 47.469), train_loss = 0.73222393, grad/param norm = 2.0633e-01, time/batch = 17.7276s	
31473/33150 (epoch 47.471), train_loss = 0.73549491, grad/param norm = 1.6216e-01, time/batch = 17.4853s	
31474/33150 (epoch 47.472), train_loss = 0.82838906, grad/param norm = 1.7881e-01, time/batch = 17.8814s	
31475/33150 (epoch 47.474), train_loss = 0.84701401, grad/param norm = 2.5438e-01, time/batch = 18.9675s	
31476/33150 (epoch 47.475), train_loss = 1.01102605, grad/param norm = 1.8511e-01, time/batch = 18.4671s	
31477/33150 (epoch 47.477), train_loss = 0.85268483, grad/param norm = 1.9090e-01, time/batch = 16.8830s	
31478/33150 (epoch 47.478), train_loss = 0.80041014, grad/param norm = 1.6614e-01, time/batch = 18.7020s	
31479/33150 (epoch 47.480), train_loss = 0.74514423, grad/param norm = 1.7854e-01, time/batch = 18.5428s	
31480/33150 (epoch 47.481), train_loss = 0.66492937, grad/param norm = 1.6401e-01, time/batch = 18.7951s	
31481/33150 (epoch 47.483), train_loss = 0.75670598, grad/param norm = 1.8586e-01, time/batch = 15.6108s	
31482/33150 (epoch 47.484), train_loss = 0.70291435, grad/param norm = 1.6918e-01, time/batch = 18.0502s	
31483/33150 (epoch 47.486), train_loss = 0.73447326, grad/param norm = 1.9304e-01, time/batch = 16.8908s	
31484/33150 (epoch 47.487), train_loss = 0.85695447, grad/param norm = 2.0406e-01, time/batch = 16.3758s	
31485/33150 (epoch 47.489), train_loss = 0.78123369, grad/param norm = 2.6767e-01, time/batch = 16.1360s	
31486/33150 (epoch 47.490), train_loss = 0.63156883, grad/param norm = 1.7397e-01, time/batch = 17.6486s	
31487/33150 (epoch 47.492), train_loss = 0.77310445, grad/param norm = 1.9181e-01, time/batch = 19.2976s	
31488/33150 (epoch 47.493), train_loss = 0.83941635, grad/param norm = 1.8441e-01, time/batch = 30.2785s	
31489/33150 (epoch 47.495), train_loss = 0.81795461, grad/param norm = 1.7545e-01, time/batch = 18.5123s	
31490/33150 (epoch 47.496), train_loss = 0.75253041, grad/param norm = 1.7648e-01, time/batch = 17.8781s	
31491/33150 (epoch 47.498), train_loss = 0.89129661, grad/param norm = 2.3465e-01, time/batch = 17.3873s	
31492/33150 (epoch 47.499), train_loss = 0.90496616, grad/param norm = 1.7960e-01, time/batch = 16.7352s	
31493/33150 (epoch 47.501), train_loss = 0.81300509, grad/param norm = 2.0740e-01, time/batch = 17.4001s	
31494/33150 (epoch 47.502), train_loss = 0.90128127, grad/param norm = 2.1655e-01, time/batch = 17.4584s	
31495/33150 (epoch 47.504), train_loss = 0.85574908, grad/param norm = 2.0156e-01, time/batch = 17.4497s	
31496/33150 (epoch 47.505), train_loss = 0.92456680, grad/param norm = 2.0201e-01, time/batch = 18.2052s	
31497/33150 (epoch 47.507), train_loss = 0.75875811, grad/param norm = 2.0787e-01, time/batch = 16.8839s	
31498/33150 (epoch 47.508), train_loss = 0.76097953, grad/param norm = 2.5967e-01, time/batch = 17.0421s	
31499/33150 (epoch 47.510), train_loss = 0.87648730, grad/param norm = 1.6751e-01, time/batch = 17.3108s	
31500/33150 (epoch 47.511), train_loss = 0.87720915, grad/param norm = 1.9701e-01, time/batch = 17.4562s	
31501/33150 (epoch 47.513), train_loss = 0.83438431, grad/param norm = 2.5575e-01, time/batch = 17.3833s	
31502/33150 (epoch 47.514), train_loss = 0.71323328, grad/param norm = 2.0220e-01, time/batch = 19.0459s	
31503/33150 (epoch 47.516), train_loss = 0.81886875, grad/param norm = 2.0928e-01, time/batch = 18.8814s	
31504/33150 (epoch 47.517), train_loss = 0.87609575, grad/param norm = 1.9133e-01, time/batch = 16.7984s	
31505/33150 (epoch 47.519), train_loss = 0.74564306, grad/param norm = 2.0813e-01, time/batch = 17.3920s	
31506/33150 (epoch 47.520), train_loss = 0.80347944, grad/param norm = 1.8101e-01, time/batch = 19.7167s	
31507/33150 (epoch 47.522), train_loss = 0.85697673, grad/param norm = 2.0108e-01, time/batch = 17.8829s	
31508/33150 (epoch 47.523), train_loss = 0.70974755, grad/param norm = 1.8520e-01, time/batch = 17.8675s	
31509/33150 (epoch 47.525), train_loss = 0.84390712, grad/param norm = 2.0206e-01, time/batch = 16.2712s	
31510/33150 (epoch 47.526), train_loss = 0.72450498, grad/param norm = 1.5582e-01, time/batch = 18.7052s	
31511/33150 (epoch 47.528), train_loss = 0.83392531, grad/param norm = 1.9373e-01, time/batch = 16.1431s	
31512/33150 (epoch 47.529), train_loss = 0.79683812, grad/param norm = 1.9314e-01, time/batch = 19.7920s	
31513/33150 (epoch 47.531), train_loss = 0.68938712, grad/param norm = 1.9787e-01, time/batch = 18.7187s	
31514/33150 (epoch 47.532), train_loss = 0.81190792, grad/param norm = 2.0714e-01, time/batch = 16.7940s	
31515/33150 (epoch 47.534), train_loss = 0.78000580, grad/param norm = 1.6614e-01, time/batch = 16.7149s	
31516/33150 (epoch 47.535), train_loss = 0.72673809, grad/param norm = 2.6072e-01, time/batch = 18.8911s	
31517/33150 (epoch 47.537), train_loss = 0.81970317, grad/param norm = 2.3020e-01, time/batch = 16.0205s	
31518/33150 (epoch 47.538), train_loss = 0.71980541, grad/param norm = 1.6999e-01, time/batch = 18.6321s	
31519/33150 (epoch 47.540), train_loss = 0.71692934, grad/param norm = 1.8969e-01, time/batch = 18.4723s	
31520/33150 (epoch 47.541), train_loss = 0.87878011, grad/param norm = 1.8712e-01, time/batch = 17.0370s	
31521/33150 (epoch 47.543), train_loss = 0.82696356, grad/param norm = 2.5199e-01, time/batch = 15.7206s	
31522/33150 (epoch 47.544), train_loss = 0.86243487, grad/param norm = 2.0679e-01, time/batch = 17.3875s	
31523/33150 (epoch 47.546), train_loss = 0.72388211, grad/param norm = 1.6694e-01, time/batch = 15.5503s	
31524/33150 (epoch 47.548), train_loss = 0.77393937, grad/param norm = 2.4142e-01, time/batch = 16.7114s	
31525/33150 (epoch 47.549), train_loss = 0.77312289, grad/param norm = 1.7865e-01, time/batch = 17.5283s	
31526/33150 (epoch 47.551), train_loss = 0.71419765, grad/param norm = 1.5695e-01, time/batch = 17.0328s	
31527/33150 (epoch 47.552), train_loss = 0.62176985, grad/param norm = 1.5512e-01, time/batch = 18.8874s	
31528/33150 (epoch 47.554), train_loss = 0.85945198, grad/param norm = 1.9201e-01, time/batch = 16.9475s	
31529/33150 (epoch 47.555), train_loss = 0.89492392, grad/param norm = 2.4942e-01, time/batch = 18.8032s	
31530/33150 (epoch 47.557), train_loss = 0.66430499, grad/param norm = 1.8291e-01, time/batch = 17.8822s	
31531/33150 (epoch 47.558), train_loss = 0.82241152, grad/param norm = 2.2228e-01, time/batch = 17.2087s	
31532/33150 (epoch 47.560), train_loss = 0.70409798, grad/param norm = 1.6623e-01, time/batch = 19.3085s	
31533/33150 (epoch 47.561), train_loss = 0.66384247, grad/param norm = 1.9938e-01, time/batch = 18.7318s	
31534/33150 (epoch 47.563), train_loss = 0.85984110, grad/param norm = 3.1480e-01, time/batch = 16.8857s	
31535/33150 (epoch 47.564), train_loss = 0.87650129, grad/param norm = 1.6755e-01, time/batch = 17.0436s	
31536/33150 (epoch 47.566), train_loss = 0.71493558, grad/param norm = 1.7715e-01, time/batch = 19.2284s	
31537/33150 (epoch 47.567), train_loss = 0.76462564, grad/param norm = 1.7955e-01, time/batch = 18.9617s	
31538/33150 (epoch 47.569), train_loss = 0.81596999, grad/param norm = 2.2042e-01, time/batch = 16.8627s	
31539/33150 (epoch 47.570), train_loss = 0.84963096, grad/param norm = 1.6827e-01, time/batch = 17.0458s	
31540/33150 (epoch 47.572), train_loss = 0.74885759, grad/param norm = 1.9479e-01, time/batch = 15.7696s	
31541/33150 (epoch 47.573), train_loss = 0.67209622, grad/param norm = 1.5577e-01, time/batch = 15.2789s	
31542/33150 (epoch 47.575), train_loss = 0.77634101, grad/param norm = 1.9999e-01, time/batch = 15.4309s	
31543/33150 (epoch 47.576), train_loss = 0.71372089, grad/param norm = 1.5799e-01, time/batch = 16.5238s	
31544/33150 (epoch 47.578), train_loss = 0.72423662, grad/param norm = 1.6860e-01, time/batch = 15.5263s	
31545/33150 (epoch 47.579), train_loss = 0.70271765, grad/param norm = 1.7200e-01, time/batch = 15.8541s	
31546/33150 (epoch 47.581), train_loss = 0.68768536, grad/param norm = 1.8955e-01, time/batch = 18.2012s	
31547/33150 (epoch 47.582), train_loss = 0.90186791, grad/param norm = 1.8271e-01, time/batch = 17.7171s	
31548/33150 (epoch 47.584), train_loss = 0.86927705, grad/param norm = 2.5874e-01, time/batch = 16.9672s	
31549/33150 (epoch 47.585), train_loss = 0.79485069, grad/param norm = 1.6785e-01, time/batch = 16.4674s	
31550/33150 (epoch 47.587), train_loss = 0.79388607, grad/param norm = 1.7269e-01, time/batch = 17.7225s	
31551/33150 (epoch 47.588), train_loss = 0.74307517, grad/param norm = 1.8226e-01, time/batch = 18.6239s	
31552/33150 (epoch 47.590), train_loss = 0.83642655, grad/param norm = 1.6785e-01, time/batch = 16.0509s	
31553/33150 (epoch 47.591), train_loss = 0.80912385, grad/param norm = 1.8104e-01, time/batch = 18.4650s	
31554/33150 (epoch 47.593), train_loss = 0.83907527, grad/param norm = 1.9173e-01, time/batch = 16.3289s	
31555/33150 (epoch 47.594), train_loss = 0.75972018, grad/param norm = 1.9761e-01, time/batch = 16.2868s	
31556/33150 (epoch 47.596), train_loss = 0.74754146, grad/param norm = 1.7541e-01, time/batch = 16.2820s	
31557/33150 (epoch 47.597), train_loss = 0.69628885, grad/param norm = 2.3133e-01, time/batch = 17.1512s	
31558/33150 (epoch 47.599), train_loss = 0.92253514, grad/param norm = 2.2406e-01, time/batch = 17.2989s	
31559/33150 (epoch 47.600), train_loss = 0.76874381, grad/param norm = 3.0674e-01, time/batch = 16.2970s	
31560/33150 (epoch 47.602), train_loss = 0.79175904, grad/param norm = 2.2056e-01, time/batch = 16.4666s	
31561/33150 (epoch 47.603), train_loss = 0.93420926, grad/param norm = 2.1150e-01, time/batch = 16.2250s	
31562/33150 (epoch 47.605), train_loss = 0.71841667, grad/param norm = 1.8025e-01, time/batch = 18.0464s	
31563/33150 (epoch 47.606), train_loss = 0.74721657, grad/param norm = 2.2026e-01, time/batch = 16.1403s	
31564/33150 (epoch 47.608), train_loss = 0.87393172, grad/param norm = 1.7447e-01, time/batch = 18.4582s	
31565/33150 (epoch 47.609), train_loss = 0.79278434, grad/param norm = 2.1906e-01, time/batch = 16.9426s	
31566/33150 (epoch 47.611), train_loss = 0.70805615, grad/param norm = 2.1477e-01, time/batch = 16.5419s	
31567/33150 (epoch 47.612), train_loss = 0.76218581, grad/param norm = 1.9577e-01, time/batch = 18.1402s	
31568/33150 (epoch 47.614), train_loss = 0.71700772, grad/param norm = 1.9970e-01, time/batch = 18.2992s	
31569/33150 (epoch 47.615), train_loss = 0.70250409, grad/param norm = 1.8472e-01, time/batch = 16.4600s	
31570/33150 (epoch 47.617), train_loss = 0.81267991, grad/param norm = 2.3918e-01, time/batch = 16.0328s	
31571/33150 (epoch 47.618), train_loss = 0.82268056, grad/param norm = 1.9304e-01, time/batch = 20.1226s	
31572/33150 (epoch 47.620), train_loss = 0.77109194, grad/param norm = 1.8452e-01, time/batch = 17.5325s	
31573/33150 (epoch 47.621), train_loss = 0.80752434, grad/param norm = 1.8723e-01, time/batch = 15.3007s	
31574/33150 (epoch 47.623), train_loss = 0.82512182, grad/param norm = 1.7759e-01, time/batch = 17.6432s	
31575/33150 (epoch 47.624), train_loss = 0.77049397, grad/param norm = 1.7934e-01, time/batch = 16.7158s	
31576/33150 (epoch 47.626), train_loss = 0.79972849, grad/param norm = 1.8947e-01, time/batch = 17.0498s	
31577/33150 (epoch 47.627), train_loss = 0.76830320, grad/param norm = 1.7877e-01, time/batch = 16.7880s	
31578/33150 (epoch 47.629), train_loss = 0.66702982, grad/param norm = 1.8099e-01, time/batch = 17.0294s	
31579/33150 (epoch 47.630), train_loss = 0.77813295, grad/param norm = 1.9438e-01, time/batch = 18.3019s	
31580/33150 (epoch 47.632), train_loss = 0.70331167, grad/param norm = 1.5510e-01, time/batch = 15.3914s	
31581/33150 (epoch 47.633), train_loss = 0.73871315, grad/param norm = 1.8284e-01, time/batch = 16.2942s	
31582/33150 (epoch 47.635), train_loss = 0.94746160, grad/param norm = 2.0116e-01, time/batch = 17.3026s	
31583/33150 (epoch 47.637), train_loss = 0.64949649, grad/param norm = 1.8691e-01, time/batch = 16.8765s	
31584/33150 (epoch 47.638), train_loss = 0.78246708, grad/param norm = 2.3049e-01, time/batch = 16.0613s	
31585/33150 (epoch 47.640), train_loss = 0.85275344, grad/param norm = 1.9643e-01, time/batch = 19.5391s	
31586/33150 (epoch 47.641), train_loss = 0.67930918, grad/param norm = 2.2313e-01, time/batch = 20.1175s	
31587/33150 (epoch 47.643), train_loss = 0.80029703, grad/param norm = 1.8852e-01, time/batch = 16.6341s	
31588/33150 (epoch 47.644), train_loss = 0.92889720, grad/param norm = 1.8470e-01, time/batch = 17.2138s	
31589/33150 (epoch 47.646), train_loss = 0.80789724, grad/param norm = 1.6571e-01, time/batch = 19.2922s	
31590/33150 (epoch 47.647), train_loss = 0.94434838, grad/param norm = 2.0329e-01, time/batch = 16.6684s	
31591/33150 (epoch 47.649), train_loss = 0.81995202, grad/param norm = 2.1961e-01, time/batch = 18.6242s	
31592/33150 (epoch 47.650), train_loss = 0.70073174, grad/param norm = 1.7474e-01, time/batch = 17.4665s	
31593/33150 (epoch 47.652), train_loss = 0.86317401, grad/param norm = 1.9644e-01, time/batch = 17.7842s	
31594/33150 (epoch 47.653), train_loss = 0.86145167, grad/param norm = 1.7587e-01, time/batch = 17.9731s	
31595/33150 (epoch 47.655), train_loss = 0.85391699, grad/param norm = 2.2010e-01, time/batch = 16.7326s	
31596/33150 (epoch 47.656), train_loss = 0.75962080, grad/param norm = 1.8400e-01, time/batch = 19.1293s	
31597/33150 (epoch 47.658), train_loss = 0.76640863, grad/param norm = 2.4322e-01, time/batch = 17.3768s	
31598/33150 (epoch 47.659), train_loss = 0.95793001, grad/param norm = 2.7467e-01, time/batch = 18.1183s	
31599/33150 (epoch 47.661), train_loss = 0.78337042, grad/param norm = 2.0398e-01, time/batch = 19.7804s	
31600/33150 (epoch 47.662), train_loss = 0.79019049, grad/param norm = 1.8757e-01, time/batch = 15.9652s	
31601/33150 (epoch 47.664), train_loss = 0.90610326, grad/param norm = 1.9398e-01, time/batch = 18.3117s	
31602/33150 (epoch 47.665), train_loss = 0.88170114, grad/param norm = 2.1583e-01, time/batch = 17.2255s	
31603/33150 (epoch 47.667), train_loss = 0.86253948, grad/param norm = 2.0652e-01, time/batch = 18.5417s	
31604/33150 (epoch 47.668), train_loss = 0.94524582, grad/param norm = 1.9615e-01, time/batch = 18.7179s	
31605/33150 (epoch 47.670), train_loss = 0.74664282, grad/param norm = 1.5815e-01, time/batch = 17.0304s	
31606/33150 (epoch 47.671), train_loss = 0.72228973, grad/param norm = 1.8459e-01, time/batch = 20.1276s	
31607/33150 (epoch 47.673), train_loss = 0.89111043, grad/param norm = 1.7280e-01, time/batch = 17.1273s	
31608/33150 (epoch 47.674), train_loss = 0.85527784, grad/param norm = 2.1760e-01, time/batch = 19.2191s	
31609/33150 (epoch 47.676), train_loss = 0.78723688, grad/param norm = 1.6678e-01, time/batch = 19.1155s	
31610/33150 (epoch 47.677), train_loss = 0.93203837, grad/param norm = 2.1498e-01, time/batch = 16.7229s	
31611/33150 (epoch 47.679), train_loss = 0.79779881, grad/param norm = 1.6105e-01, time/batch = 17.9585s	
31612/33150 (epoch 47.680), train_loss = 0.87872535, grad/param norm = 2.2041e-01, time/batch = 17.4484s	
31613/33150 (epoch 47.682), train_loss = 0.82524968, grad/param norm = 1.9781e-01, time/batch = 17.3735s	
31614/33150 (epoch 47.683), train_loss = 0.68485442, grad/param norm = 1.6827e-01, time/batch = 16.4606s	
31615/33150 (epoch 47.685), train_loss = 0.77033671, grad/param norm = 2.2434e-01, time/batch = 17.8720s	
31616/33150 (epoch 47.686), train_loss = 0.65900824, grad/param norm = 1.7478e-01, time/batch = 18.7923s	
31617/33150 (epoch 47.688), train_loss = 0.72653155, grad/param norm = 1.9056e-01, time/batch = 16.5549s	
31618/33150 (epoch 47.689), train_loss = 0.72910249, grad/param norm = 1.8399e-01, time/batch = 19.2944s	
31619/33150 (epoch 47.691), train_loss = 0.61035366, grad/param norm = 1.5851e-01, time/batch = 18.3765s	
31620/33150 (epoch 47.692), train_loss = 0.70214940, grad/param norm = 1.7677e-01, time/batch = 15.9625s	
31621/33150 (epoch 47.694), train_loss = 0.62851497, grad/param norm = 1.7711e-01, time/batch = 16.8968s	
31622/33150 (epoch 47.695), train_loss = 0.70345610, grad/param norm = 1.6406e-01, time/batch = 19.3707s	
31623/33150 (epoch 47.697), train_loss = 0.69270985, grad/param norm = 1.7301e-01, time/batch = 17.3867s	
31624/33150 (epoch 47.698), train_loss = 0.70622922, grad/param norm = 2.0973e-01, time/batch = 16.5814s	
31625/33150 (epoch 47.700), train_loss = 0.62048353, grad/param norm = 1.6169e-01, time/batch = 17.9606s	
31626/33150 (epoch 47.701), train_loss = 0.67494368, grad/param norm = 1.5028e-01, time/batch = 19.5384s	
31627/33150 (epoch 47.703), train_loss = 0.79456621, grad/param norm = 2.3131e-01, time/batch = 16.6277s	
31628/33150 (epoch 47.704), train_loss = 0.66692055, grad/param norm = 1.4899e-01, time/batch = 18.2846s	
31629/33150 (epoch 47.706), train_loss = 0.73370167, grad/param norm = 1.6337e-01, time/batch = 17.4794s	
31630/33150 (epoch 47.707), train_loss = 0.75822355, grad/param norm = 1.8439e-01, time/batch = 17.1311s	
31631/33150 (epoch 47.709), train_loss = 0.78636908, grad/param norm = 1.6588e-01, time/batch = 17.5372s	
31632/33150 (epoch 47.710), train_loss = 0.76523122, grad/param norm = 1.9141e-01, time/batch = 17.2231s	
31633/33150 (epoch 47.712), train_loss = 0.87325136, grad/param norm = 1.9296e-01, time/batch = 17.6126s	
31634/33150 (epoch 47.713), train_loss = 0.81252974, grad/param norm = 1.6480e-01, time/batch = 16.8838s	
31635/33150 (epoch 47.715), train_loss = 0.76557687, grad/param norm = 1.7308e-01, time/batch = 15.3668s	
31636/33150 (epoch 47.716), train_loss = 0.82926105, grad/param norm = 1.8070e-01, time/batch = 17.8980s	
31637/33150 (epoch 47.718), train_loss = 0.78511495, grad/param norm = 1.8832e-01, time/batch = 16.8598s	
31638/33150 (epoch 47.719), train_loss = 0.85557885, grad/param norm = 2.1820e-01, time/batch = 14.9518s	
31639/33150 (epoch 47.721), train_loss = 0.75183193, grad/param norm = 1.8469e-01, time/batch = 15.1840s	
31640/33150 (epoch 47.722), train_loss = 0.83682500, grad/param norm = 1.7518e-01, time/batch = 15.8812s	
31641/33150 (epoch 47.724), train_loss = 0.73534000, grad/param norm = 1.9172e-01, time/batch = 15.8852s	
31642/33150 (epoch 47.725), train_loss = 0.82651530, grad/param norm = 2.2357e-01, time/batch = 16.9776s	
31643/33150 (epoch 47.727), train_loss = 0.81928485, grad/param norm = 1.8558e-01, time/batch = 19.2129s	
31644/33150 (epoch 47.729), train_loss = 0.78975000, grad/param norm = 1.9664e-01, time/batch = 16.3820s	
31645/33150 (epoch 47.730), train_loss = 0.79429670, grad/param norm = 1.7311e-01, time/batch = 17.0608s	
31646/33150 (epoch 47.732), train_loss = 0.83093820, grad/param norm = 1.9016e-01, time/batch = 18.6245s	
31647/33150 (epoch 47.733), train_loss = 0.70320389, grad/param norm = 1.5665e-01, time/batch = 17.6474s	
31648/33150 (epoch 47.735), train_loss = 0.71635552, grad/param norm = 1.8943e-01, time/batch = 15.9595s	
31649/33150 (epoch 47.736), train_loss = 0.72395766, grad/param norm = 1.7052e-01, time/batch = 17.1878s	
31650/33150 (epoch 47.738), train_loss = 0.78542732, grad/param norm = 2.0512e-01, time/batch = 17.2165s	
31651/33150 (epoch 47.739), train_loss = 0.86130421, grad/param norm = 2.0945e-01, time/batch = 16.7943s	
31652/33150 (epoch 47.741), train_loss = 0.79197710, grad/param norm = 2.1547e-01, time/batch = 17.2164s	
31653/33150 (epoch 47.742), train_loss = 0.66960347, grad/param norm = 1.8562e-01, time/batch = 18.9514s	
31654/33150 (epoch 47.744), train_loss = 0.84193730, grad/param norm = 1.8939e-01, time/batch = 16.3846s	
31655/33150 (epoch 47.745), train_loss = 0.73193394, grad/param norm = 1.7195e-01, time/batch = 15.7053s	
31656/33150 (epoch 47.747), train_loss = 0.56480629, grad/param norm = 1.5736e-01, time/batch = 19.9625s	
31657/33150 (epoch 47.748), train_loss = 0.67249710, grad/param norm = 1.6528e-01, time/batch = 18.6192s	
31658/33150 (epoch 47.750), train_loss = 0.79529123, grad/param norm = 1.9528e-01, time/batch = 16.7168s	
31659/33150 (epoch 47.751), train_loss = 0.75636761, grad/param norm = 1.5935e-01, time/batch = 17.3995s	
31660/33150 (epoch 47.753), train_loss = 0.68718489, grad/param norm = 1.9780e-01, time/batch = 15.6329s	
31661/33150 (epoch 47.754), train_loss = 0.95331273, grad/param norm = 2.4358e-01, time/batch = 17.3751s	
31662/33150 (epoch 47.756), train_loss = 0.76905302, grad/param norm = 2.0424e-01, time/batch = 16.3963s	
31663/33150 (epoch 47.757), train_loss = 0.83093921, grad/param norm = 1.9389e-01, time/batch = 18.3153s	
31664/33150 (epoch 47.759), train_loss = 0.91841189, grad/param norm = 2.2680e-01, time/batch = 17.3091s	
31665/33150 (epoch 47.760), train_loss = 0.82577327, grad/param norm = 2.0420e-01, time/batch = 16.1985s	
31666/33150 (epoch 47.762), train_loss = 0.78626510, grad/param norm = 2.1073e-01, time/batch = 17.7227s	
31667/33150 (epoch 47.763), train_loss = 0.83115983, grad/param norm = 2.0631e-01, time/batch = 19.6173s	
31668/33150 (epoch 47.765), train_loss = 0.77652591, grad/param norm = 2.0084e-01, time/batch = 17.3000s	
31669/33150 (epoch 47.766), train_loss = 0.65371082, grad/param norm = 1.7464e-01, time/batch = 16.4744s	
31670/33150 (epoch 47.768), train_loss = 0.70895018, grad/param norm = 1.6960e-01, time/batch = 19.8034s	
31671/33150 (epoch 47.769), train_loss = 0.86885299, grad/param norm = 2.0632e-01, time/batch = 15.8675s	
31672/33150 (epoch 47.771), train_loss = 0.83614740, grad/param norm = 3.9849e-01, time/batch = 15.5403s	
31673/33150 (epoch 47.772), train_loss = 0.80336002, grad/param norm = 1.8685e-01, time/batch = 17.6419s	
31674/33150 (epoch 47.774), train_loss = 0.90441418, grad/param norm = 1.8813e-01, time/batch = 16.5426s	
31675/33150 (epoch 47.775), train_loss = 0.83379728, grad/param norm = 2.2922e-01, time/batch = 17.0289s	
31676/33150 (epoch 47.777), train_loss = 0.84757471, grad/param norm = 2.0838e-01, time/batch = 15.2634s	
31677/33150 (epoch 47.778), train_loss = 0.77520201, grad/param norm = 1.6825e-01, time/batch = 15.3274s	
31678/33150 (epoch 47.780), train_loss = 0.69422866, grad/param norm = 1.7335e-01, time/batch = 15.1688s	
31679/33150 (epoch 47.781), train_loss = 0.78490451, grad/param norm = 1.8432e-01, time/batch = 15.2645s	
31680/33150 (epoch 47.783), train_loss = 0.77441672, grad/param norm = 1.6240e-01, time/batch = 18.5318s	
31681/33150 (epoch 47.784), train_loss = 0.79335243, grad/param norm = 2.1496e-01, time/batch = 19.1316s	
31682/33150 (epoch 47.786), train_loss = 0.76660115, grad/param norm = 1.7130e-01, time/batch = 17.7933s	
31683/33150 (epoch 47.787), train_loss = 0.69777044, grad/param norm = 1.7402e-01, time/batch = 16.4714s	
31684/33150 (epoch 47.789), train_loss = 0.66414547, grad/param norm = 1.5251e-01, time/batch = 20.1959s	
31685/33150 (epoch 47.790), train_loss = 0.67093790, grad/param norm = 1.6180e-01, time/batch = 19.2859s	
31686/33150 (epoch 47.792), train_loss = 0.78534665, grad/param norm = 2.0786e-01, time/batch = 15.6485s	
31687/33150 (epoch 47.793), train_loss = 0.74077441, grad/param norm = 1.8256e-01, time/batch = 19.6242s	
31688/33150 (epoch 47.795), train_loss = 0.75556485, grad/param norm = 2.0323e-01, time/batch = 17.7047s	
31689/33150 (epoch 47.796), train_loss = 0.76811235, grad/param norm = 1.6972e-01, time/batch = 16.2810s	
31690/33150 (epoch 47.798), train_loss = 0.73817587, grad/param norm = 1.6111e-01, time/batch = 16.3086s	
31691/33150 (epoch 47.799), train_loss = 0.66716680, grad/param norm = 2.1468e-01, time/batch = 18.7237s	
31692/33150 (epoch 47.801), train_loss = 0.77333931, grad/param norm = 2.0041e-01, time/batch = 16.3807s	
