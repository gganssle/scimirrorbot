tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 673, val: 36, test: 0	
vocab size: 130	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 281986	
cloning rnn	
cloning criterion	
1/33650 (epoch 0.001), train_loss = 4.85523956, grad/param norm = 5.4169e-01, time/batch = 0.6710s	
2/33650 (epoch 0.003), train_loss = 4.45107197, grad/param norm = 1.6750e+00, time/batch = 0.6319s	
3/33650 (epoch 0.004), train_loss = 3.64434739, grad/param norm = 1.3964e+00, time/batch = 0.6317s	
4/33650 (epoch 0.006), train_loss = 3.56616220, grad/param norm = 9.9202e-01, time/batch = 0.6262s	
5/33650 (epoch 0.007), train_loss = 3.43718813, grad/param norm = 1.0882e+00, time/batch = 0.6265s	
6/33650 (epoch 0.009), train_loss = 3.50110157, grad/param norm = 8.8175e-01, time/batch = 0.6264s	
7/33650 (epoch 0.010), train_loss = 3.43662172, grad/param norm = 9.5618e-01, time/batch = 0.6278s	
8/33650 (epoch 0.012), train_loss = 3.43408877, grad/param norm = 8.3042e-01, time/batch = 0.6271s	
9/33650 (epoch 0.013), train_loss = 3.49577738, grad/param norm = 6.8857e-01, time/batch = 0.6264s	
10/33650 (epoch 0.015), train_loss = 3.51229528, grad/param norm = 7.2949e-01, time/batch = 0.6280s	
11/33650 (epoch 0.016), train_loss = 3.61952618, grad/param norm = 8.5334e-01, time/batch = 0.6284s	
12/33650 (epoch 0.018), train_loss = 3.61534764, grad/param norm = 6.6689e-01, time/batch = 0.6275s	
13/33650 (epoch 0.019), train_loss = 3.44422773, grad/param norm = 6.9905e-01, time/batch = 0.6658s	
14/33650 (epoch 0.021), train_loss = 3.52950554, grad/param norm = 6.6560e-01, time/batch = 0.6463s	
15/33650 (epoch 0.022), train_loss = 3.47112726, grad/param norm = 7.9528e-01, time/batch = 0.6289s	
16/33650 (epoch 0.024), train_loss = 3.59229948, grad/param norm = 7.2660e-01, time/batch = 0.6271s	
17/33650 (epoch 0.025), train_loss = 3.47684289, grad/param norm = 7.0211e-01, time/batch = 0.6373s	
18/33650 (epoch 0.027), train_loss = 3.57146609, grad/param norm = 5.7725e-01, time/batch = 0.6291s	
19/33650 (epoch 0.028), train_loss = 3.53724603, grad/param norm = 4.2779e-01, time/batch = 0.6278s	
20/33650 (epoch 0.030), train_loss = 3.39199289, grad/param norm = 5.8936e-01, time/batch = 0.6268s	
21/33650 (epoch 0.031), train_loss = 3.51580297, grad/param norm = 6.8555e-01, time/batch = 0.6270s	
22/33650 (epoch 0.033), train_loss = 3.60415586, grad/param norm = 6.4686e-01, time/batch = 0.6267s	
23/33650 (epoch 0.034), train_loss = 3.38639019, grad/param norm = 5.7971e-01, time/batch = 0.6284s	
24/33650 (epoch 0.036), train_loss = 3.44089931, grad/param norm = 7.1516e-01, time/batch = 0.6291s	
25/33650 (epoch 0.037), train_loss = 3.42713507, grad/param norm = 6.8438e-01, time/batch = 0.6261s	
26/33650 (epoch 0.039), train_loss = 3.46754757, grad/param norm = 6.3439e-01, time/batch = 0.6263s	
27/33650 (epoch 0.040), train_loss = 3.51666699, grad/param norm = 8.9140e-01, time/batch = 0.6265s	
28/33650 (epoch 0.042), train_loss = 3.49445909, grad/param norm = 7.5393e-01, time/batch = 0.6291s	
29/33650 (epoch 0.043), train_loss = 3.47863625, grad/param norm = 8.7044e-01, time/batch = 0.6276s	
30/33650 (epoch 0.045), train_loss = 3.49480426, grad/param norm = 5.3914e-01, time/batch = 0.6275s	
31/33650 (epoch 0.046), train_loss = 3.44496879, grad/param norm = 6.4419e-01, time/batch = 0.6312s	
32/33650 (epoch 0.048), train_loss = 3.48569833, grad/param norm = 6.5581e-01, time/batch = 0.6296s	
33/33650 (epoch 0.049), train_loss = 3.44673491, grad/param norm = 6.1756e-01, time/batch = 0.6470s	
34/33650 (epoch 0.051), train_loss = 3.47230657, grad/param norm = 6.6123e-01, time/batch = 0.6658s	
35/33650 (epoch 0.052), train_loss = 3.52646077, grad/param norm = 4.8156e-01, time/batch = 0.6272s	
36/33650 (epoch 0.053), train_loss = 3.49408842, grad/param norm = 4.9278e-01, time/batch = 0.6281s	
37/33650 (epoch 0.055), train_loss = 3.44741560, grad/param norm = 5.9970e-01, time/batch = 0.6282s	
38/33650 (epoch 0.056), train_loss = 3.38388980, grad/param norm = 7.5672e-01, time/batch = 0.6277s	
39/33650 (epoch 0.058), train_loss = 3.36967734, grad/param norm = 7.8939e-01, time/batch = 0.6310s	
40/33650 (epoch 0.059), train_loss = 3.54094518, grad/param norm = 6.9525e-01, time/batch = 0.6317s	
41/33650 (epoch 0.061), train_loss = 3.47350643, grad/param norm = 8.1269e-01, time/batch = 0.6293s	
42/33650 (epoch 0.062), train_loss = 3.61845033, grad/param norm = 8.4977e-01, time/batch = 0.6267s	
43/33650 (epoch 0.064), train_loss = 3.47055196, grad/param norm = 5.5017e-01, time/batch = 0.6300s	
44/33650 (epoch 0.065), train_loss = 3.39384230, grad/param norm = 7.5027e-01, time/batch = 0.6261s	
45/33650 (epoch 0.067), train_loss = 3.42686542, grad/param norm = 6.3091e-01, time/batch = 0.6280s	
46/33650 (epoch 0.068), train_loss = 3.54578249, grad/param norm = 5.9872e-01, time/batch = 0.6266s	
47/33650 (epoch 0.070), train_loss = 3.41386814, grad/param norm = 4.8627e-01, time/batch = 0.6281s	
48/33650 (epoch 0.071), train_loss = 3.49274284, grad/param norm = 5.1129e-01, time/batch = 0.6279s	
49/33650 (epoch 0.073), train_loss = 3.59403688, grad/param norm = 6.7213e-01, time/batch = 0.6276s	
50/33650 (epoch 0.074), train_loss = 3.42965277, grad/param norm = 5.7340e-01, time/batch = 0.6293s	
51/33650 (epoch 0.076), train_loss = 3.58538277, grad/param norm = 7.5949e-01, time/batch = 0.6383s	
52/33650 (epoch 0.077), train_loss = 3.47213716, grad/param norm = 6.7394e-01, time/batch = 0.6281s	
53/33650 (epoch 0.079), train_loss = 3.47089233, grad/param norm = 4.8484e-01, time/batch = 0.6289s	
54/33650 (epoch 0.080), train_loss = 3.41187677, grad/param norm = 5.1355e-01, time/batch = 0.6312s	
55/33650 (epoch 0.082), train_loss = 3.48998173, grad/param norm = 8.3086e-01, time/batch = 0.6278s	
56/33650 (epoch 0.083), train_loss = 3.62830737, grad/param norm = 7.4352e-01, time/batch = 0.6283s	
57/33650 (epoch 0.085), train_loss = 3.54722000, grad/param norm = 5.3085e-01, time/batch = 0.6270s	
58/33650 (epoch 0.086), train_loss = 3.71021122, grad/param norm = 6.1910e-01, time/batch = 0.6264s	
59/33650 (epoch 0.088), train_loss = 3.51894911, grad/param norm = 6.3401e-01, time/batch = 0.6267s	
60/33650 (epoch 0.089), train_loss = 3.36271185, grad/param norm = 5.4065e-01, time/batch = 0.6274s	
61/33650 (epoch 0.091), train_loss = 3.40610160, grad/param norm = 4.7707e-01, time/batch = 0.6310s	
62/33650 (epoch 0.092), train_loss = 3.38159226, grad/param norm = 6.7335e-01, time/batch = 0.6294s	
63/33650 (epoch 0.094), train_loss = 3.47047192, grad/param norm = 5.4390e-01, time/batch = 0.6276s	
64/33650 (epoch 0.095), train_loss = 3.33556564, grad/param norm = 6.1238e-01, time/batch = 0.6284s	
65/33650 (epoch 0.097), train_loss = 3.47888252, grad/param norm = 7.9381e-01, time/batch = 0.6273s	
66/33650 (epoch 0.098), train_loss = 3.45601549, grad/param norm = 6.0717e-01, time/batch = 0.6273s	
67/33650 (epoch 0.100), train_loss = 3.39929052, grad/param norm = 6.2394e-01, time/batch = 0.6282s	
68/33650 (epoch 0.101), train_loss = 3.45016199, grad/param norm = 7.7596e-01, time/batch = 0.6279s	
69/33650 (epoch 0.103), train_loss = 3.47729086, grad/param norm = 7.2977e-01, time/batch = 0.6285s	
70/33650 (epoch 0.104), train_loss = 3.53732000, grad/param norm = 4.5746e-01, time/batch = 0.6296s	
71/33650 (epoch 0.105), train_loss = 3.35732718, grad/param norm = 4.8497e-01, time/batch = 0.6322s	
72/33650 (epoch 0.107), train_loss = 3.49261783, grad/param norm = 6.1030e-01, time/batch = 0.6253s	
73/33650 (epoch 0.108), train_loss = 3.56138269, grad/param norm = 5.5817e-01, time/batch = 0.6259s	
74/33650 (epoch 0.110), train_loss = 3.41933695, grad/param norm = 6.0854e-01, time/batch = 0.6433s	
75/33650 (epoch 0.111), train_loss = 3.42261392, grad/param norm = 6.5113e-01, time/batch = 0.6665s	
76/33650 (epoch 0.113), train_loss = 3.41179026, grad/param norm = 9.1338e-01, time/batch = 0.6358s	
77/33650 (epoch 0.114), train_loss = 3.47957245, grad/param norm = 7.1241e-01, time/batch = 0.6453s	
78/33650 (epoch 0.116), train_loss = 3.51190947, grad/param norm = 5.3822e-01, time/batch = 0.6305s	
79/33650 (epoch 0.117), train_loss = 3.48806073, grad/param norm = 5.7074e-01, time/batch = 0.6422s	
80/33650 (epoch 0.119), train_loss = 3.51637315, grad/param norm = 4.9464e-01, time/batch = 0.6454s	
81/33650 (epoch 0.120), train_loss = 3.40743508, grad/param norm = 4.9572e-01, time/batch = 0.6535s	
82/33650 (epoch 0.122), train_loss = 3.37073082, grad/param norm = 7.6577e-01, time/batch = 0.6332s	
83/33650 (epoch 0.123), train_loss = 3.46777715, grad/param norm = 5.0492e-01, time/batch = 0.6286s	
84/33650 (epoch 0.125), train_loss = 3.46622461, grad/param norm = 4.6572e-01, time/batch = 0.6277s	
85/33650 (epoch 0.126), train_loss = 3.50501428, grad/param norm = 4.0082e-01, time/batch = 0.6311s	
86/33650 (epoch 0.128), train_loss = 3.55760894, grad/param norm = 4.8401e-01, time/batch = 0.6268s	
87/33650 (epoch 0.129), train_loss = 3.56549519, grad/param norm = 5.2943e-01, time/batch = 0.6280s	
88/33650 (epoch 0.131), train_loss = 3.41053115, grad/param norm = 7.3502e-01, time/batch = 0.6250s	
89/33650 (epoch 0.132), train_loss = 3.45655893, grad/param norm = 7.4571e-01, time/batch = 0.6250s	
90/33650 (epoch 0.134), train_loss = 3.50332834, grad/param norm = 7.5392e-01, time/batch = 0.6293s	
91/33650 (epoch 0.135), train_loss = 3.55436620, grad/param norm = 5.6781e-01, time/batch = 0.6350s	
92/33650 (epoch 0.137), train_loss = 3.42085027, grad/param norm = 6.8289e-01, time/batch = 0.6374s	
93/33650 (epoch 0.138), train_loss = 3.68409256, grad/param norm = 7.9419e-01, time/batch = 0.6405s	
94/33650 (epoch 0.140), train_loss = 3.42865193, grad/param norm = 5.7706e-01, time/batch = 0.6400s	
95/33650 (epoch 0.141), train_loss = 3.52182062, grad/param norm = 3.9596e-01, time/batch = 0.6674s	
96/33650 (epoch 0.143), train_loss = 3.56272559, grad/param norm = 5.5488e-01, time/batch = 0.6415s	
97/33650 (epoch 0.144), train_loss = 3.52019203, grad/param norm = 4.8527e-01, time/batch = 0.6273s	
98/33650 (epoch 0.146), train_loss = 3.44471181, grad/param norm = 6.3084e-01, time/batch = 0.6290s	
99/33650 (epoch 0.147), train_loss = 3.50346455, grad/param norm = 6.0600e-01, time/batch = 0.6244s	
100/33650 (epoch 0.149), train_loss = 3.38678564, grad/param norm = 8.5247e-01, time/batch = 0.6259s	
101/33650 (epoch 0.150), train_loss = 3.39240728, grad/param norm = 8.0262e-01, time/batch = 0.6279s	
102/33650 (epoch 0.152), train_loss = 3.44846277, grad/param norm = 6.1968e-01, time/batch = 0.6269s	
103/33650 (epoch 0.153), train_loss = 3.34785594, grad/param norm = 4.7993e-01, time/batch = 0.6273s	
104/33650 (epoch 0.155), train_loss = 3.45291468, grad/param norm = 4.8166e-01, time/batch = 0.6271s	
105/33650 (epoch 0.156), train_loss = 3.41520556, grad/param norm = 6.0188e-01, time/batch = 0.6305s	
106/33650 (epoch 0.158), train_loss = 3.30393996, grad/param norm = 4.0227e-01, time/batch = 0.6329s	
107/33650 (epoch 0.159), train_loss = 3.33519914, grad/param norm = 6.5946e-01, time/batch = 0.6432s	
108/33650 (epoch 0.160), train_loss = 3.49209225, grad/param norm = 1.2751e+00, time/batch = 0.6318s	
109/33650 (epoch 0.162), train_loss = 3.43583016, grad/param norm = 9.6611e-01, time/batch = 0.6275s	
110/33650 (epoch 0.163), train_loss = 3.45097699, grad/param norm = 6.2359e-01, time/batch = 0.6270s	
111/33650 (epoch 0.165), train_loss = 3.40942143, grad/param norm = 4.0792e-01, time/batch = 0.6293s	
112/33650 (epoch 0.166), train_loss = 3.29507425, grad/param norm = 4.5765e-01, time/batch = 0.6270s	
113/33650 (epoch 0.168), train_loss = 3.33787031, grad/param norm = 6.2684e-01, time/batch = 0.6291s	
114/33650 (epoch 0.169), train_loss = 3.42548111, grad/param norm = 1.0125e+00, time/batch = 0.6375s	
115/33650 (epoch 0.171), train_loss = 3.64839928, grad/param norm = 2.8647e+00, time/batch = 0.6548s	
116/33650 (epoch 0.172), train_loss = 3.46640804, grad/param norm = 1.1418e+00, time/batch = 0.6638s	
117/33650 (epoch 0.174), train_loss = 3.35215103, grad/param norm = 4.3094e-01, time/batch = 0.6550s	
118/33650 (epoch 0.175), train_loss = 3.27780155, grad/param norm = 3.6750e-01, time/batch = 0.6611s	
119/33650 (epoch 0.177), train_loss = 3.38743874, grad/param norm = 4.3576e-01, time/batch = 0.6594s	
120/33650 (epoch 0.178), train_loss = 3.32471262, grad/param norm = 4.4368e-01, time/batch = 0.6527s	
121/33650 (epoch 0.180), train_loss = 3.27989277, grad/param norm = 4.3169e-01, time/batch = 0.6466s	
122/33650 (epoch 0.181), train_loss = 3.23552919, grad/param norm = 5.3588e-01, time/batch = 0.6412s	
123/33650 (epoch 0.183), train_loss = 3.39206727, grad/param norm = 6.4249e-01, time/batch = 0.6255s	
124/33650 (epoch 0.184), train_loss = 3.34407316, grad/param norm = 6.2685e-01, time/batch = 0.6275s	
125/33650 (epoch 0.186), train_loss = 3.32112410, grad/param norm = 4.7312e-01, time/batch = 0.6259s	
126/33650 (epoch 0.187), train_loss = 3.56878994, grad/param norm = 6.6008e-01, time/batch = 0.6284s	
127/33650 (epoch 0.189), train_loss = 3.37572034, grad/param norm = 4.6411e-01, time/batch = 0.6290s	
128/33650 (epoch 0.190), train_loss = 3.37736394, grad/param norm = 5.0421e-01, time/batch = 0.6281s	
129/33650 (epoch 0.192), train_loss = 3.27991802, grad/param norm = 7.8108e-01, time/batch = 0.6354s	
130/33650 (epoch 0.193), train_loss = 3.38847273, grad/param norm = 9.8666e-01, time/batch = 0.6257s	
131/33650 (epoch 0.195), train_loss = 3.30218521, grad/param norm = 8.5489e-01, time/batch = 0.6318s	
132/33650 (epoch 0.196), train_loss = 3.28745224, grad/param norm = 7.5395e-01, time/batch = 0.6313s	
133/33650 (epoch 0.198), train_loss = 3.24818003, grad/param norm = 8.3458e-01, time/batch = 0.6276s	
134/33650 (epoch 0.199), train_loss = 3.45125104, grad/param norm = 8.9048e-01, time/batch = 0.6283s	
135/33650 (epoch 0.201), train_loss = 3.28445986, grad/param norm = 8.4273e-01, time/batch = 0.6440s	
136/33650 (epoch 0.202), train_loss = 3.32210335, grad/param norm = 7.5087e-01, time/batch = 0.6672s	
137/33650 (epoch 0.204), train_loss = 3.21161646, grad/param norm = 8.2816e-01, time/batch = 0.6324s	
138/33650 (epoch 0.205), train_loss = 3.28126023, grad/param norm = 8.4645e-01, time/batch = 0.6277s	
139/33650 (epoch 0.207), train_loss = 3.31373211, grad/param norm = 7.2917e-01, time/batch = 0.6259s	
140/33650 (epoch 0.208), train_loss = 3.30961252, grad/param norm = 6.8872e-01, time/batch = 0.6278s	
141/33650 (epoch 0.210), train_loss = 3.19292249, grad/param norm = 5.0924e-01, time/batch = 0.6465s	
142/33650 (epoch 0.211), train_loss = 3.36397243, grad/param norm = 4.9447e-01, time/batch = 0.6399s	
143/33650 (epoch 0.212), train_loss = 3.24670177, grad/param norm = 7.3205e-01, time/batch = 0.6344s	
144/33650 (epoch 0.214), train_loss = 3.14458474, grad/param norm = 7.1523e-01, time/batch = 0.6331s	
145/33650 (epoch 0.215), train_loss = 3.21200754, grad/param norm = 6.4445e-01, time/batch = 0.6265s	
146/33650 (epoch 0.217), train_loss = 3.26707494, grad/param norm = 9.8214e-01, time/batch = 0.6264s	
147/33650 (epoch 0.218), train_loss = 3.22434224, grad/param norm = 9.8487e-01, time/batch = 0.6274s	
148/33650 (epoch 0.220), train_loss = 3.14601039, grad/param norm = 5.7212e-01, time/batch = 0.6276s	
149/33650 (epoch 0.221), train_loss = 3.06702404, grad/param norm = 4.5834e-01, time/batch = 0.6300s	
150/33650 (epoch 0.223), train_loss = 3.13005536, grad/param norm = 3.9576e-01, time/batch = 0.6303s	
151/33650 (epoch 0.224), train_loss = 3.20002398, grad/param norm = 4.6506e-01, time/batch = 0.6337s	
152/33650 (epoch 0.226), train_loss = 3.17608496, grad/param norm = 6.2433e-01, time/batch = 0.6269s	
153/33650 (epoch 0.227), train_loss = 3.23403099, grad/param norm = 8.6266e-01, time/batch = 0.6291s	
154/33650 (epoch 0.229), train_loss = 3.12765083, grad/param norm = 7.6814e-01, time/batch = 0.6301s	
155/33650 (epoch 0.230), train_loss = 3.17652047, grad/param norm = 7.5445e-01, time/batch = 0.6278s	
156/33650 (epoch 0.232), train_loss = 3.14374618, grad/param norm = 8.4749e-01, time/batch = 0.6666s	
157/33650 (epoch 0.233), train_loss = 3.17504580, grad/param norm = 1.0646e+00, time/batch = 0.6368s	
158/33650 (epoch 0.235), train_loss = 3.31425565, grad/param norm = 1.6195e+00, time/batch = 0.6317s	
159/33650 (epoch 0.236), train_loss = 3.13780929, grad/param norm = 9.9280e-01, time/batch = 0.6261s	
160/33650 (epoch 0.238), train_loss = 3.19473154, grad/param norm = 7.4629e-01, time/batch = 0.6274s	
161/33650 (epoch 0.239), train_loss = 3.06972593, grad/param norm = 8.0108e-01, time/batch = 0.6306s	
162/33650 (epoch 0.241), train_loss = 3.04613367, grad/param norm = 7.0045e-01, time/batch = 0.6303s	
163/33650 (epoch 0.242), train_loss = 3.08356680, grad/param norm = 6.6191e-01, time/batch = 0.6294s	
164/33650 (epoch 0.244), train_loss = 3.22117725, grad/param norm = 4.4689e-01, time/batch = 0.6304s	
165/33650 (epoch 0.245), train_loss = 3.09539431, grad/param norm = 5.6413e-01, time/batch = 0.6321s	
166/33650 (epoch 0.247), train_loss = 3.16641281, grad/param norm = 1.1099e+00, time/batch = 0.6313s	
167/33650 (epoch 0.248), train_loss = 3.27051843, grad/param norm = 7.2618e-01, time/batch = 0.6295s	
168/33650 (epoch 0.250), train_loss = 3.04863833, grad/param norm = 3.7022e-01, time/batch = 0.6263s	
169/33650 (epoch 0.251), train_loss = 3.08154003, grad/param norm = 5.4099e-01, time/batch = 0.6327s	
170/33650 (epoch 0.253), train_loss = 3.00408557, grad/param norm = 1.1341e+00, time/batch = 0.6486s	
171/33650 (epoch 0.254), train_loss = 3.13188724, grad/param norm = 1.0432e+00, time/batch = 0.6573s	
172/33650 (epoch 0.256), train_loss = 3.04498442, grad/param norm = 6.6256e-01, time/batch = 0.6495s	
173/33650 (epoch 0.257), train_loss = 3.13773201, grad/param norm = 6.3971e-01, time/batch = 0.6690s	
174/33650 (epoch 0.259), train_loss = 3.01163986, grad/param norm = 7.4190e-01, time/batch = 0.6677s	
175/33650 (epoch 0.260), train_loss = 3.21091004, grad/param norm = 9.0931e-01, time/batch = 0.6608s	
176/33650 (epoch 0.262), train_loss = 3.09085107, grad/param norm = 1.1918e+00, time/batch = 0.6678s	
177/33650 (epoch 0.263), train_loss = 3.19383236, grad/param norm = 1.0343e+00, time/batch = 0.6594s	
178/33650 (epoch 0.264), train_loss = 3.02598284, grad/param norm = 8.3126e-01, time/batch = 0.6412s	
179/33650 (epoch 0.266), train_loss = 2.92284143, grad/param norm = 5.0529e-01, time/batch = 0.6458s	
180/33650 (epoch 0.267), train_loss = 2.94744353, grad/param norm = 4.7706e-01, time/batch = 0.6513s	
181/33650 (epoch 0.269), train_loss = 3.06054907, grad/param norm = 5.1384e-01, time/batch = 0.6456s	
182/33650 (epoch 0.270), train_loss = 3.00071303, grad/param norm = 6.1671e-01, time/batch = 0.6409s	
183/33650 (epoch 0.272), train_loss = 3.00011591, grad/param norm = 5.9453e-01, time/batch = 0.6389s	
184/33650 (epoch 0.273), train_loss = 3.03704463, grad/param norm = 8.4850e-01, time/batch = 0.6394s	
185/33650 (epoch 0.275), train_loss = 3.10214492, grad/param norm = 9.0724e-01, time/batch = 0.6380s	
186/33650 (epoch 0.276), train_loss = 3.01696718, grad/param norm = 7.2649e-01, time/batch = 0.6431s	
187/33650 (epoch 0.278), train_loss = 3.08156320, grad/param norm = 6.2737e-01, time/batch = 0.6484s	
188/33650 (epoch 0.279), train_loss = 2.91791286, grad/param norm = 5.0970e-01, time/batch = 0.6494s	
189/33650 (epoch 0.281), train_loss = 2.94658039, grad/param norm = 4.5091e-01, time/batch = 0.6485s	
190/33650 (epoch 0.282), train_loss = 2.91492955, grad/param norm = 5.5317e-01, time/batch = 0.6499s	
191/33650 (epoch 0.284), train_loss = 3.03792460, grad/param norm = 7.3202e-01, time/batch = 0.6597s	
192/33650 (epoch 0.285), train_loss = 2.98669035, grad/param norm = 1.6633e+00, time/batch = 0.6689s	
193/33650 (epoch 0.287), train_loss = 3.09005959, grad/param norm = 1.5223e+00, time/batch = 0.6505s	
194/33650 (epoch 0.288), train_loss = 3.06074249, grad/param norm = 7.9862e-01, time/batch = 0.6425s	
195/33650 (epoch 0.290), train_loss = 3.08549354, grad/param norm = 7.8451e-01, time/batch = 0.6363s	
196/33650 (epoch 0.291), train_loss = 2.92079649, grad/param norm = 8.6134e-01, time/batch = 0.6356s	
197/33650 (epoch 0.293), train_loss = 2.99044840, grad/param norm = 6.3001e-01, time/batch = 0.6284s	
198/33650 (epoch 0.294), train_loss = 2.93232392, grad/param norm = 6.2902e-01, time/batch = 0.6266s	
199/33650 (epoch 0.296), train_loss = 2.91347758, grad/param norm = 6.4159e-01, time/batch = 0.6421s	
200/33650 (epoch 0.297), train_loss = 3.09270931, grad/param norm = 5.9510e-01, time/batch = 0.6416s	
201/33650 (epoch 0.299), train_loss = 2.92095332, grad/param norm = 6.3388e-01, time/batch = 0.6434s	
202/33650 (epoch 0.300), train_loss = 2.99299158, grad/param norm = 7.1914e-01, time/batch = 0.6371s	
203/33650 (epoch 0.302), train_loss = 2.92822749, grad/param norm = 6.1469e-01, time/batch = 0.6298s	
204/33650 (epoch 0.303), train_loss = 2.94626405, grad/param norm = 4.4400e-01, time/batch = 0.6344s	
205/33650 (epoch 0.305), train_loss = 3.04512303, grad/param norm = 5.9421e-01, time/batch = 0.6279s	
206/33650 (epoch 0.306), train_loss = 2.96674170, grad/param norm = 9.1105e-01, time/batch = 0.6292s	
207/33650 (epoch 0.308), train_loss = 2.98489880, grad/param norm = 1.3855e+00, time/batch = 0.6281s	
208/33650 (epoch 0.309), train_loss = 2.94417823, grad/param norm = 9.0531e-01, time/batch = 0.6284s	
209/33650 (epoch 0.311), train_loss = 3.08016971, grad/param norm = 4.3764e-01, time/batch = 0.6303s	
210/33650 (epoch 0.312), train_loss = 2.93070948, grad/param norm = 4.8860e-01, time/batch = 0.6274s	
211/33650 (epoch 0.314), train_loss = 2.80164632, grad/param norm = 6.2066e-01, time/batch = 0.6308s	
212/33650 (epoch 0.315), train_loss = 3.00261618, grad/param norm = 6.5183e-01, time/batch = 0.6292s	
213/33650 (epoch 0.316), train_loss = 2.95870134, grad/param norm = 5.4832e-01, time/batch = 0.6277s	
214/33650 (epoch 0.318), train_loss = 2.91819899, grad/param norm = 4.0317e-01, time/batch = 0.6292s	
215/33650 (epoch 0.319), train_loss = 2.77723652, grad/param norm = 4.7434e-01, time/batch = 0.6283s	
216/33650 (epoch 0.321), train_loss = 2.86882475, grad/param norm = 4.9196e-01, time/batch = 0.6431s	
217/33650 (epoch 0.322), train_loss = 2.83330649, grad/param norm = 4.6042e-01, time/batch = 0.6675s	
218/33650 (epoch 0.324), train_loss = 2.86292310, grad/param norm = 5.0997e-01, time/batch = 0.6348s	
219/33650 (epoch 0.325), train_loss = 2.89322754, grad/param norm = 9.7889e-01, time/batch = 0.6285s	
220/33650 (epoch 0.327), train_loss = 2.78031965, grad/param norm = 1.3326e+00, time/batch = 0.6300s	
221/33650 (epoch 0.328), train_loss = 2.89172375, grad/param norm = 1.0157e+00, time/batch = 0.6316s	
222/33650 (epoch 0.330), train_loss = 2.76995508, grad/param norm = 7.0778e-01, time/batch = 0.6326s	
223/33650 (epoch 0.331), train_loss = 2.79858814, grad/param norm = 7.1119e-01, time/batch = 0.6310s	
224/33650 (epoch 0.333), train_loss = 2.95871894, grad/param norm = 8.7407e-01, time/batch = 0.6339s	
225/33650 (epoch 0.334), train_loss = 2.84715762, grad/param norm = 9.1481e-01, time/batch = 0.6276s	
226/33650 (epoch 0.336), train_loss = 2.80373917, grad/param norm = 6.2808e-01, time/batch = 0.6321s	
227/33650 (epoch 0.337), train_loss = 2.72165328, grad/param norm = 4.8944e-01, time/batch = 0.6299s	
228/33650 (epoch 0.339), train_loss = 2.90311746, grad/param norm = 3.5495e-01, time/batch = 0.6298s	
229/33650 (epoch 0.340), train_loss = 2.83799281, grad/param norm = 5.7486e-01, time/batch = 0.6294s	
230/33650 (epoch 0.342), train_loss = 2.77949425, grad/param norm = 1.1536e+00, time/batch = 0.6302s	
231/33650 (epoch 0.343), train_loss = 2.90875381, grad/param norm = 1.4143e+00, time/batch = 0.6347s	
232/33650 (epoch 0.345), train_loss = 2.85902051, grad/param norm = 1.2747e+00, time/batch = 0.6263s	
233/33650 (epoch 0.346), train_loss = 2.72738870, grad/param norm = 7.4465e-01, time/batch = 0.6277s	
234/33650 (epoch 0.348), train_loss = 2.76456271, grad/param norm = 7.8993e-01, time/batch = 0.6305s	
235/33650 (epoch 0.349), train_loss = 2.87060282, grad/param norm = 9.1955e-01, time/batch = 0.6289s	
236/33650 (epoch 0.351), train_loss = 2.82578890, grad/param norm = 7.4802e-01, time/batch = 0.6293s	
237/33650 (epoch 0.352), train_loss = 2.67683622, grad/param norm = 6.1993e-01, time/batch = 0.6292s	
238/33650 (epoch 0.354), train_loss = 3.09657831, grad/param norm = 5.8231e-01, time/batch = 0.6309s	
239/33650 (epoch 0.355), train_loss = 2.72889864, grad/param norm = 6.0561e-01, time/batch = 0.6300s	
240/33650 (epoch 0.357), train_loss = 2.80757912, grad/param norm = 8.1166e-01, time/batch = 0.6268s	
241/33650 (epoch 0.358), train_loss = 2.83139240, grad/param norm = 8.8672e-01, time/batch = 0.6365s	
242/33650 (epoch 0.360), train_loss = 2.83632325, grad/param norm = 8.6378e-01, time/batch = 0.6291s	
243/33650 (epoch 0.361), train_loss = 2.68746787, grad/param norm = 8.1992e-01, time/batch = 0.6316s	
244/33650 (epoch 0.363), train_loss = 2.68738252, grad/param norm = 6.6563e-01, time/batch = 0.6297s	
245/33650 (epoch 0.364), train_loss = 2.74808444, grad/param norm = 5.0696e-01, time/batch = 0.6310s	
246/33650 (epoch 0.366), train_loss = 2.63852359, grad/param norm = 4.0891e-01, time/batch = 0.6374s	
247/33650 (epoch 0.367), train_loss = 2.75315287, grad/param norm = 5.2075e-01, time/batch = 0.6338s	
248/33650 (epoch 0.368), train_loss = 2.69527613, grad/param norm = 5.2934e-01, time/batch = 0.6315s	
249/33650 (epoch 0.370), train_loss = 2.89199480, grad/param norm = 5.9484e-01, time/batch = 0.6295s	
250/33650 (epoch 0.371), train_loss = 2.76425794, grad/param norm = 7.9356e-01, time/batch = 0.6271s	
251/33650 (epoch 0.373), train_loss = 2.83479822, grad/param norm = 1.3219e+00, time/batch = 0.6309s	
252/33650 (epoch 0.374), train_loss = 2.81793926, grad/param norm = 1.1371e+00, time/batch = 0.6296s	
253/33650 (epoch 0.376), train_loss = 2.83909557, grad/param norm = 5.5209e-01, time/batch = 0.6291s	
254/33650 (epoch 0.377), train_loss = 2.77810375, grad/param norm = 4.1321e-01, time/batch = 0.6330s	
255/33650 (epoch 0.379), train_loss = 2.72058227, grad/param norm = 4.8396e-01, time/batch = 0.6474s	
256/33650 (epoch 0.380), train_loss = 2.76490038, grad/param norm = 4.6330e-01, time/batch = 0.6288s	
257/33650 (epoch 0.382), train_loss = 2.67349830, grad/param norm = 5.3669e-01, time/batch = 0.6456s	
258/33650 (epoch 0.383), train_loss = 2.78520252, grad/param norm = 5.5026e-01, time/batch = 0.6673s	
259/33650 (epoch 0.385), train_loss = 2.62985520, grad/param norm = 4.2142e-01, time/batch = 0.6304s	
260/33650 (epoch 0.386), train_loss = 2.76988540, grad/param norm = 4.2068e-01, time/batch = 0.6293s	
261/33650 (epoch 0.388), train_loss = 2.60762561, grad/param norm = 5.8762e-01, time/batch = 0.6333s	
262/33650 (epoch 0.389), train_loss = 2.75212639, grad/param norm = 7.8681e-01, time/batch = 0.6270s	
263/33650 (epoch 0.391), train_loss = 2.71715808, grad/param norm = 1.1528e+00, time/batch = 0.6322s	
264/33650 (epoch 0.392), train_loss = 2.76848117, grad/param norm = 6.6805e-01, time/batch = 0.6345s	
265/33650 (epoch 0.394), train_loss = 2.76268558, grad/param norm = 6.1398e-01, time/batch = 0.6537s	
266/33650 (epoch 0.395), train_loss = 2.75408440, grad/param norm = 9.5111e-01, time/batch = 0.6519s	
267/33650 (epoch 0.397), train_loss = 2.93067567, grad/param norm = 1.0237e+00, time/batch = 0.6556s	
268/33650 (epoch 0.398), train_loss = 2.79122294, grad/param norm = 7.4314e-01, time/batch = 0.6478s	
269/33650 (epoch 0.400), train_loss = 2.76858635, grad/param norm = 8.7484e-01, time/batch = 0.6617s	
270/33650 (epoch 0.401), train_loss = 2.82750252, grad/param norm = 7.0133e-01, time/batch = 0.6392s	
271/33650 (epoch 0.403), train_loss = 2.84897841, grad/param norm = 4.5898e-01, time/batch = 0.6462s	
272/33650 (epoch 0.404), train_loss = 2.77061411, grad/param norm = 4.8771e-01, time/batch = 0.6448s	
273/33650 (epoch 0.406), train_loss = 2.80237547, grad/param norm = 5.2918e-01, time/batch = 0.6366s	
274/33650 (epoch 0.407), train_loss = 2.86865366, grad/param norm = 6.2068e-01, time/batch = 0.6413s	
275/33650 (epoch 0.409), train_loss = 2.79598155, grad/param norm = 7.4232e-01, time/batch = 0.6426s	
276/33650 (epoch 0.410), train_loss = 2.61599362, grad/param norm = 7.0776e-01, time/batch = 0.6331s	
277/33650 (epoch 0.412), train_loss = 2.72048605, grad/param norm = 7.0464e-01, time/batch = 0.6381s	
278/33650 (epoch 0.413), train_loss = 2.72707117, grad/param norm = 9.3974e-01, time/batch = 0.6673s	
279/33650 (epoch 0.415), train_loss = 2.78288572, grad/param norm = 1.2836e+00, time/batch = 0.6332s	
280/33650 (epoch 0.416), train_loss = 2.85118653, grad/param norm = 7.0403e-01, time/batch = 0.6272s	
281/33650 (epoch 0.418), train_loss = 2.79573478, grad/param norm = 5.8315e-01, time/batch = 0.6457s	
282/33650 (epoch 0.419), train_loss = 2.74605365, grad/param norm = 5.3058e-01, time/batch = 0.6314s	
283/33650 (epoch 0.421), train_loss = 2.63418628, grad/param norm = 5.2987e-01, time/batch = 0.6281s	
284/33650 (epoch 0.422), train_loss = 2.67327252, grad/param norm = 6.2079e-01, time/batch = 0.6272s	
285/33650 (epoch 0.423), train_loss = 2.57242982, grad/param norm = 6.5956e-01, time/batch = 0.6271s	
286/33650 (epoch 0.425), train_loss = 2.74489766, grad/param norm = 5.9494e-01, time/batch = 0.6284s	
287/33650 (epoch 0.426), train_loss = 2.66087049, grad/param norm = 5.4746e-01, time/batch = 0.6297s	
288/33650 (epoch 0.428), train_loss = 2.65311321, grad/param norm = 4.8060e-01, time/batch = 0.6364s	
289/33650 (epoch 0.429), train_loss = 2.57423670, grad/param norm = 5.0785e-01, time/batch = 0.6343s	
290/33650 (epoch 0.431), train_loss = 2.76528605, grad/param norm = 5.5512e-01, time/batch = 0.6272s	
291/33650 (epoch 0.432), train_loss = 2.82022751, grad/param norm = 3.4957e-01, time/batch = 0.6314s	
292/33650 (epoch 0.434), train_loss = 2.72521675, grad/param norm = 3.7105e-01, time/batch = 0.6271s	
293/33650 (epoch 0.435), train_loss = 2.69640650, grad/param norm = 4.7188e-01, time/batch = 0.6522s	
294/33650 (epoch 0.437), train_loss = 2.64857961, grad/param norm = 4.8853e-01, time/batch = 0.6628s	
295/33650 (epoch 0.438), train_loss = 2.39153696, grad/param norm = 7.1877e-01, time/batch = 0.6321s	
296/33650 (epoch 0.440), train_loss = 2.72426306, grad/param norm = 1.0184e+00, time/batch = 0.6269s	
297/33650 (epoch 0.441), train_loss = 2.86768664, grad/param norm = 8.7973e-01, time/batch = 0.6283s	
298/33650 (epoch 0.443), train_loss = 2.73276650, grad/param norm = 8.6576e-01, time/batch = 0.6271s	
299/33650 (epoch 0.444), train_loss = 2.75419802, grad/param norm = 7.9198e-01, time/batch = 0.6268s	
300/33650 (epoch 0.446), train_loss = 2.76936510, grad/param norm = 7.6329e-01, time/batch = 0.6259s	
301/33650 (epoch 0.447), train_loss = 2.61114067, grad/param norm = 5.1460e-01, time/batch = 0.6295s	
302/33650 (epoch 0.449), train_loss = 2.80413609, grad/param norm = 4.6212e-01, time/batch = 0.6321s	
303/33650 (epoch 0.450), train_loss = 2.85593723, grad/param norm = 5.4177e-01, time/batch = 0.6273s	
304/33650 (epoch 0.452), train_loss = 2.80185547, grad/param norm = 6.5262e-01, time/batch = 0.6282s	
305/33650 (epoch 0.453), train_loss = 2.75338813, grad/param norm = 6.7418e-01, time/batch = 0.6275s	
306/33650 (epoch 0.455), train_loss = 2.79425999, grad/param norm = 5.9426e-01, time/batch = 0.6288s	
307/33650 (epoch 0.456), train_loss = 2.61286368, grad/param norm = 5.6367e-01, time/batch = 0.6286s	
308/33650 (epoch 0.458), train_loss = 2.60227825, grad/param norm = 5.6969e-01, time/batch = 0.6288s	
309/33650 (epoch 0.459), train_loss = 2.54293031, grad/param norm = 6.1822e-01, time/batch = 0.6353s	
310/33650 (epoch 0.461), train_loss = 2.57391325, grad/param norm = 6.5649e-01, time/batch = 0.6403s	
311/33650 (epoch 0.462), train_loss = 2.96169526, grad/param norm = 8.6323e-01, time/batch = 0.6365s	
312/33650 (epoch 0.464), train_loss = 2.71698597, grad/param norm = 7.6445e-01, time/batch = 0.6335s	
313/33650 (epoch 0.465), train_loss = 2.68842560, grad/param norm = 5.4780e-01, time/batch = 0.6346s	
314/33650 (epoch 0.467), train_loss = 2.59365183, grad/param norm = 3.4417e-01, time/batch = 0.6676s	
315/33650 (epoch 0.468), train_loss = 2.56674208, grad/param norm = 4.0659e-01, time/batch = 0.6408s	
316/33650 (epoch 0.470), train_loss = 2.73805675, grad/param norm = 4.6608e-01, time/batch = 0.6286s	
317/33650 (epoch 0.471), train_loss = 2.66609743, grad/param norm = 5.1287e-01, time/batch = 0.6432s	
318/33650 (epoch 0.473), train_loss = 2.49225983, grad/param norm = 5.2560e-01, time/batch = 0.6352s	
319/33650 (epoch 0.474), train_loss = 2.59573757, grad/param norm = 5.0463e-01, time/batch = 0.6288s	
320/33650 (epoch 0.475), train_loss = 2.77279567, grad/param norm = 6.6462e-01, time/batch = 0.6279s	
321/33650 (epoch 0.477), train_loss = 2.88354916, grad/param norm = 9.6655e-01, time/batch = 0.6285s	
322/33650 (epoch 0.478), train_loss = 2.62625177, grad/param norm = 6.6903e-01, time/batch = 0.6303s	
323/33650 (epoch 0.480), train_loss = 2.71368578, grad/param norm = 4.6736e-01, time/batch = 0.6297s	
324/33650 (epoch 0.481), train_loss = 2.61262922, grad/param norm = 5.1050e-01, time/batch = 0.6293s	
325/33650 (epoch 0.483), train_loss = 2.42755467, grad/param norm = 9.5875e-01, time/batch = 0.6293s	
326/33650 (epoch 0.484), train_loss = 2.70953912, grad/param norm = 1.2992e+00, time/batch = 0.6276s	
327/33650 (epoch 0.486), train_loss = 2.79056456, grad/param norm = 9.3903e-01, time/batch = 0.6283s	
328/33650 (epoch 0.487), train_loss = 2.74715935, grad/param norm = 7.9202e-01, time/batch = 0.6292s	
329/33650 (epoch 0.489), train_loss = 2.71069574, grad/param norm = 5.4201e-01, time/batch = 0.6284s	
330/33650 (epoch 0.490), train_loss = 2.56497819, grad/param norm = 4.2123e-01, time/batch = 0.6284s	
331/33650 (epoch 0.492), train_loss = 2.76732512, grad/param norm = 4.4612e-01, time/batch = 0.6328s	
332/33650 (epoch 0.493), train_loss = 2.51897652, grad/param norm = 4.1149e-01, time/batch = 0.6296s	
333/33650 (epoch 0.495), train_loss = 2.50044664, grad/param norm = 3.5590e-01, time/batch = 0.6290s	
334/33650 (epoch 0.496), train_loss = 2.72742153, grad/param norm = 3.9746e-01, time/batch = 0.6567s	
335/33650 (epoch 0.498), train_loss = 2.59869057, grad/param norm = 3.3697e-01, time/batch = 0.6581s	
336/33650 (epoch 0.499), train_loss = 2.64901737, grad/param norm = 4.2062e-01, time/batch = 0.6270s	
337/33650 (epoch 0.501), train_loss = 2.53808527, grad/param norm = 4.6930e-01, time/batch = 0.6276s	
338/33650 (epoch 0.502), train_loss = 2.62267090, grad/param norm = 6.2953e-01, time/batch = 0.6288s	
339/33650 (epoch 0.504), train_loss = 2.65891265, grad/param norm = 5.6965e-01, time/batch = 0.6298s	
340/33650 (epoch 0.505), train_loss = 2.57761496, grad/param norm = 5.3681e-01, time/batch = 0.6315s	
341/33650 (epoch 0.507), train_loss = 2.53731546, grad/param norm = 6.0565e-01, time/batch = 0.6292s	
342/33650 (epoch 0.508), train_loss = 2.61103818, grad/param norm = 7.7159e-01, time/batch = 0.6294s	
343/33650 (epoch 0.510), train_loss = 2.59388509, grad/param norm = 6.9762e-01, time/batch = 0.6278s	
344/33650 (epoch 0.511), train_loss = 2.68482952, grad/param norm = 5.3426e-01, time/batch = 0.6280s	
345/33650 (epoch 0.513), train_loss = 2.58720914, grad/param norm = 5.2844e-01, time/batch = 0.6297s	
346/33650 (epoch 0.514), train_loss = 2.47498705, grad/param norm = 8.1620e-01, time/batch = 0.6284s	
347/33650 (epoch 0.516), train_loss = 2.59279062, grad/param norm = 7.1491e-01, time/batch = 0.6298s	
348/33650 (epoch 0.517), train_loss = 2.37450041, grad/param norm = 4.4551e-01, time/batch = 0.6300s	
349/33650 (epoch 0.519), train_loss = 2.43666759, grad/param norm = 5.3173e-01, time/batch = 0.6310s	
350/33650 (epoch 0.520), train_loss = 2.41828590, grad/param norm = 9.0908e-01, time/batch = 0.6284s	
351/33650 (epoch 0.522), train_loss = 2.62562586, grad/param norm = 9.3703e-01, time/batch = 0.6324s	
352/33650 (epoch 0.523), train_loss = 2.64432933, grad/param norm = 6.7734e-01, time/batch = 0.6302s	
353/33650 (epoch 0.525), train_loss = 2.35669173, grad/param norm = 5.0958e-01, time/batch = 0.6290s	
354/33650 (epoch 0.526), train_loss = 2.64575190, grad/param norm = 5.5754e-01, time/batch = 0.6396s	
355/33650 (epoch 0.527), train_loss = 2.57702067, grad/param norm = 5.6798e-01, time/batch = 0.6673s	
356/33650 (epoch 0.529), train_loss = 2.51853249, grad/param norm = 5.1590e-01, time/batch = 0.6369s	
357/33650 (epoch 0.530), train_loss = 2.44024701, grad/param norm = 5.6241e-01, time/batch = 0.6325s	
358/33650 (epoch 0.532), train_loss = 2.78118226, grad/param norm = 4.3920e-01, time/batch = 0.6338s	
359/33650 (epoch 0.533), train_loss = 2.31792610, grad/param norm = 5.3850e-01, time/batch = 0.6437s	
360/33650 (epoch 0.535), train_loss = 2.67815278, grad/param norm = 5.6110e-01, time/batch = 0.6382s	
361/33650 (epoch 0.536), train_loss = 2.50715087, grad/param norm = 4.4344e-01, time/batch = 0.6648s	
362/33650 (epoch 0.538), train_loss = 2.57218886, grad/param norm = 3.9299e-01, time/batch = 0.6559s	
363/33650 (epoch 0.539), train_loss = 2.43024040, grad/param norm = 5.5097e-01, time/batch = 0.6472s	
364/33650 (epoch 0.541), train_loss = 2.61858341, grad/param norm = 4.2611e-01, time/batch = 0.6287s	
365/33650 (epoch 0.542), train_loss = 2.59232952, grad/param norm = 5.3416e-01, time/batch = 0.6313s	
366/33650 (epoch 0.544), train_loss = 2.72497680, grad/param norm = 5.5118e-01, time/batch = 0.6291s	
367/33650 (epoch 0.545), train_loss = 2.37685141, grad/param norm = 3.0026e-01, time/batch = 0.6313s	
368/33650 (epoch 0.547), train_loss = 2.49831915, grad/param norm = 5.4082e-01, time/batch = 0.6313s	
369/33650 (epoch 0.548), train_loss = 2.68857852, grad/param norm = 6.2959e-01, time/batch = 0.6307s	
370/33650 (epoch 0.550), train_loss = 2.43586378, grad/param norm = 6.2790e-01, time/batch = 0.6402s	
371/33650 (epoch 0.551), train_loss = 2.42883645, grad/param norm = 6.9113e-01, time/batch = 0.6427s	
372/33650 (epoch 0.553), train_loss = 2.31735466, grad/param norm = 7.9381e-01, time/batch = 0.6344s	
373/33650 (epoch 0.554), train_loss = 2.70212611, grad/param norm = 7.4149e-01, time/batch = 0.6405s	
374/33650 (epoch 0.556), train_loss = 2.63455155, grad/param norm = 4.7204e-01, time/batch = 0.6343s	
375/33650 (epoch 0.557), train_loss = 2.57783652, grad/param norm = 3.2032e-01, time/batch = 0.6676s	
376/33650 (epoch 0.559), train_loss = 2.51565969, grad/param norm = 5.9626e-01, time/batch = 0.6450s	
377/33650 (epoch 0.560), train_loss = 2.55952743, grad/param norm = 6.7199e-01, time/batch = 0.6295s	
378/33650 (epoch 0.562), train_loss = 2.56150818, grad/param norm = 6.0998e-01, time/batch = 0.6310s	
379/33650 (epoch 0.563), train_loss = 2.40204611, grad/param norm = 5.3114e-01, time/batch = 0.6249s	
380/33650 (epoch 0.565), train_loss = 2.45620237, grad/param norm = 3.8536e-01, time/batch = 0.6300s	
381/33650 (epoch 0.566), train_loss = 2.45577104, grad/param norm = 4.0686e-01, time/batch = 0.6312s	
382/33650 (epoch 0.568), train_loss = 2.52510527, grad/param norm = 5.0888e-01, time/batch = 0.6304s	
383/33650 (epoch 0.569), train_loss = 2.40255643, grad/param norm = 6.4475e-01, time/batch = 0.6332s	
384/33650 (epoch 0.571), train_loss = 2.55260872, grad/param norm = 5.0177e-01, time/batch = 0.6294s	
385/33650 (epoch 0.572), train_loss = 2.44176102, grad/param norm = 4.9039e-01, time/batch = 0.6329s	
386/33650 (epoch 0.574), train_loss = 2.52168788, grad/param norm = 5.1190e-01, time/batch = 0.6286s	
387/33650 (epoch 0.575), train_loss = 2.47484812, grad/param norm = 3.9911e-01, time/batch = 0.6296s	
388/33650 (epoch 0.577), train_loss = 2.62071547, grad/param norm = 4.8097e-01, time/batch = 0.6273s	
389/33650 (epoch 0.578), train_loss = 2.38862939, grad/param norm = 6.0798e-01, time/batch = 0.6287s	
390/33650 (epoch 0.579), train_loss = 2.44443995, grad/param norm = 6.6183e-01, time/batch = 0.6288s	
391/33650 (epoch 0.581), train_loss = 2.46822027, grad/param norm = 7.0736e-01, time/batch = 0.6310s	
392/33650 (epoch 0.582), train_loss = 2.60758272, grad/param norm = 5.1431e-01, time/batch = 0.6347s	
393/33650 (epoch 0.584), train_loss = 2.40054833, grad/param norm = 4.7643e-01, time/batch = 0.6284s	
394/33650 (epoch 0.585), train_loss = 2.47871838, grad/param norm = 5.1094e-01, time/batch = 0.6264s	
395/33650 (epoch 0.587), train_loss = 2.52934451, grad/param norm = 5.1559e-01, time/batch = 0.6518s	
396/33650 (epoch 0.588), train_loss = 2.51449636, grad/param norm = 4.1847e-01, time/batch = 0.6633s	
397/33650 (epoch 0.590), train_loss = 2.46332158, grad/param norm = 3.5794e-01, time/batch = 0.6270s	
398/33650 (epoch 0.591), train_loss = 2.54369416, grad/param norm = 3.7357e-01, time/batch = 0.6312s	
399/33650 (epoch 0.593), train_loss = 2.43017868, grad/param norm = 4.2223e-01, time/batch = 0.6542s	
400/33650 (epoch 0.594), train_loss = 2.17641278, grad/param norm = 5.3566e-01, time/batch = 0.6273s	
401/33650 (epoch 0.596), train_loss = 2.51190544, grad/param norm = 5.2001e-01, time/batch = 0.6297s	
402/33650 (epoch 0.597), train_loss = 2.17720825, grad/param norm = 4.7154e-01, time/batch = 0.6274s	
403/33650 (epoch 0.599), train_loss = 2.44211828, grad/param norm = 5.7715e-01, time/batch = 0.6294s	
404/33650 (epoch 0.600), train_loss = 2.36450768, grad/param norm = 6.5982e-01, time/batch = 0.6272s	
405/33650 (epoch 0.602), train_loss = 2.62572321, grad/param norm = 7.3589e-01, time/batch = 0.6299s	
406/33650 (epoch 0.603), train_loss = 2.35436311, grad/param norm = 6.5634e-01, time/batch = 0.6347s	
407/33650 (epoch 0.605), train_loss = 2.39663483, grad/param norm = 4.3799e-01, time/batch = 0.6292s	
408/33650 (epoch 0.606), train_loss = 2.47954270, grad/param norm = 3.8508e-01, time/batch = 0.6291s	
409/33650 (epoch 0.608), train_loss = 2.51053967, grad/param norm = 3.8768e-01, time/batch = 0.6295s	
410/33650 (epoch 0.609), train_loss = 2.47042951, grad/param norm = 5.3696e-01, time/batch = 0.6286s	
411/33650 (epoch 0.611), train_loss = 2.40368826, grad/param norm = 6.0543e-01, time/batch = 0.6371s	
412/33650 (epoch 0.612), train_loss = 2.43850890, grad/param norm = 4.8934e-01, time/batch = 0.6302s	
413/33650 (epoch 0.614), train_loss = 2.57792514, grad/param norm = 4.8464e-01, time/batch = 0.6325s	
414/33650 (epoch 0.615), train_loss = 2.32631045, grad/param norm = 5.0030e-01, time/batch = 0.6320s	
415/33650 (epoch 0.617), train_loss = 2.34765435, grad/param norm = 4.2363e-01, time/batch = 0.6362s	
416/33650 (epoch 0.618), train_loss = 2.50857896, grad/param norm = 6.4187e-01, time/batch = 0.6676s	
417/33650 (epoch 0.620), train_loss = 2.47958343, grad/param norm = 7.8815e-01, time/batch = 0.6406s	
418/33650 (epoch 0.621), train_loss = 2.44583890, grad/param norm = 7.0145e-01, time/batch = 0.6280s	
419/33650 (epoch 0.623), train_loss = 2.49990553, grad/param norm = 5.9599e-01, time/batch = 0.6287s	
420/33650 (epoch 0.624), train_loss = 2.30783343, grad/param norm = 5.8323e-01, time/batch = 0.6281s	
421/33650 (epoch 0.626), train_loss = 2.29684887, grad/param norm = 6.5464e-01, time/batch = 0.6337s	
422/33650 (epoch 0.627), train_loss = 2.30999831, grad/param norm = 6.1999e-01, time/batch = 0.6300s	
423/33650 (epoch 0.629), train_loss = 2.39515456, grad/param norm = 5.3298e-01, time/batch = 0.6419s	
424/33650 (epoch 0.630), train_loss = 2.39810633, grad/param norm = 3.6520e-01, time/batch = 0.6304s	
425/33650 (epoch 0.632), train_loss = 2.57338030, grad/param norm = 4.4100e-01, time/batch = 0.6276s	
426/33650 (epoch 0.633), train_loss = 2.50009615, grad/param norm = 4.1518e-01, time/batch = 0.6293s	
427/33650 (epoch 0.634), train_loss = 2.33529527, grad/param norm = 3.8161e-01, time/batch = 0.6279s	
428/33650 (epoch 0.636), train_loss = 2.22128630, grad/param norm = 3.7811e-01, time/batch = 0.6281s	
429/33650 (epoch 0.637), train_loss = 2.55546193, grad/param norm = 5.0247e-01, time/batch = 0.6419s	
430/33650 (epoch 0.639), train_loss = 2.46987871, grad/param norm = 5.0831e-01, time/batch = 0.6415s	
431/33650 (epoch 0.640), train_loss = 2.45889260, grad/param norm = 5.4649e-01, time/batch = 0.6554s	
432/33650 (epoch 0.642), train_loss = 2.63660224, grad/param norm = 4.6268e-01, time/batch = 0.6531s	
433/33650 (epoch 0.643), train_loss = 2.29827402, grad/param norm = 4.6239e-01, time/batch = 0.6284s	
434/33650 (epoch 0.645), train_loss = 2.34539489, grad/param norm = 5.1108e-01, time/batch = 0.6278s	
435/33650 (epoch 0.646), train_loss = 2.27703889, grad/param norm = 5.6277e-01, time/batch = 0.6276s	
436/33650 (epoch 0.648), train_loss = 2.39203000, grad/param norm = 6.8434e-01, time/batch = 0.6282s	
437/33650 (epoch 0.649), train_loss = 2.46624364, grad/param norm = 7.2944e-01, time/batch = 0.6312s	
438/33650 (epoch 0.651), train_loss = 2.55984793, grad/param norm = 4.0510e-01, time/batch = 0.6267s	
439/33650 (epoch 0.652), train_loss = 2.05780653, grad/param norm = 3.2409e-01, time/batch = 0.6281s	
440/33650 (epoch 0.654), train_loss = 2.50319649, grad/param norm = 3.8344e-01, time/batch = 0.6274s	
441/33650 (epoch 0.655), train_loss = 2.23998246, grad/param norm = 3.6073e-01, time/batch = 0.6292s	
442/33650 (epoch 0.657), train_loss = 2.28908753, grad/param norm = 3.8600e-01, time/batch = 0.6281s	
443/33650 (epoch 0.658), train_loss = 2.29465649, grad/param norm = 3.4135e-01, time/batch = 0.6429s	
444/33650 (epoch 0.660), train_loss = 2.23591107, grad/param norm = 3.2044e-01, time/batch = 0.6403s	
445/33650 (epoch 0.661), train_loss = 2.38312887, grad/param norm = 3.4884e-01, time/batch = 0.6359s	
446/33650 (epoch 0.663), train_loss = 2.23505762, grad/param norm = 4.5361e-01, time/batch = 0.6331s	
447/33650 (epoch 0.664), train_loss = 2.20164412, grad/param norm = 5.8563e-01, time/batch = 0.6453s	
448/33650 (epoch 0.666), train_loss = 2.28844774, grad/param norm = 6.2958e-01, time/batch = 0.6409s	
449/33650 (epoch 0.667), train_loss = 2.34776090, grad/param norm = 4.6054e-01, time/batch = 0.6475s	
450/33650 (epoch 0.669), train_loss = 2.24694210, grad/param norm = 4.6251e-01, time/batch = 0.6356s	
451/33650 (epoch 0.670), train_loss = 2.36274877, grad/param norm = 5.1166e-01, time/batch = 0.6522s	
452/33650 (epoch 0.672), train_loss = 2.35094846, grad/param norm = 4.7779e-01, time/batch = 0.6696s	
453/33650 (epoch 0.673), train_loss = 2.24055950, grad/param norm = 5.1425e-01, time/batch = 0.6580s	
454/33650 (epoch 0.675), train_loss = 2.31215483, grad/param norm = 6.1280e-01, time/batch = 0.6429s	
455/33650 (epoch 0.676), train_loss = 2.42185028, grad/param norm = 5.3619e-01, time/batch = 0.6693s	
456/33650 (epoch 0.678), train_loss = 2.27108983, grad/param norm = 3.9699e-01, time/batch = 0.6497s	
457/33650 (epoch 0.679), train_loss = 2.17541209, grad/param norm = 4.2149e-01, time/batch = 0.6382s	
458/33650 (epoch 0.681), train_loss = 2.18483175, grad/param norm = 4.2257e-01, time/batch = 0.6389s	
459/33650 (epoch 0.682), train_loss = 2.36416678, grad/param norm = 3.7393e-01, time/batch = 0.6441s	
460/33650 (epoch 0.684), train_loss = 2.28081782, grad/param norm = 4.2637e-01, time/batch = 0.6435s	
461/33650 (epoch 0.685), train_loss = 2.44637519, grad/param norm = 4.0405e-01, time/batch = 0.6390s	
462/33650 (epoch 0.686), train_loss = 2.26118769, grad/param norm = 4.2725e-01, time/batch = 0.6397s	
463/33650 (epoch 0.688), train_loss = 2.44354812, grad/param norm = 6.2392e-01, time/batch = 0.6428s	
464/33650 (epoch 0.689), train_loss = 2.36014775, grad/param norm = 5.6885e-01, time/batch = 0.6381s	
465/33650 (epoch 0.691), train_loss = 2.27982345, grad/param norm = 4.8753e-01, time/batch = 0.6290s	
466/33650 (epoch 0.692), train_loss = 2.48280363, grad/param norm = 6.0786e-01, time/batch = 0.6275s	
467/33650 (epoch 0.694), train_loss = 2.39757260, grad/param norm = 6.2560e-01, time/batch = 0.6261s	
468/33650 (epoch 0.695), train_loss = 2.12179286, grad/param norm = 4.5583e-01, time/batch = 0.6277s	
469/33650 (epoch 0.697), train_loss = 2.31339018, grad/param norm = 3.7091e-01, time/batch = 0.6366s	
470/33650 (epoch 0.698), train_loss = 2.33586045, grad/param norm = 3.7784e-01, time/batch = 0.6314s	
471/33650 (epoch 0.700), train_loss = 2.36985589, grad/param norm = 4.5588e-01, time/batch = 0.6359s	
472/33650 (epoch 0.701), train_loss = 2.51270716, grad/param norm = 4.6391e-01, time/batch = 0.6322s	
473/33650 (epoch 0.703), train_loss = 2.27157283, grad/param norm = 3.9535e-01, time/batch = 0.6291s	
474/33650 (epoch 0.704), train_loss = 2.19219877, grad/param norm = 5.8417e-01, time/batch = 0.6310s	
475/33650 (epoch 0.706), train_loss = 2.31279251, grad/param norm = 6.9806e-01, time/batch = 0.6351s	
476/33650 (epoch 0.707), train_loss = 2.31907813, grad/param norm = 3.1496e-01, time/batch = 0.6499s	
477/33650 (epoch 0.709), train_loss = 2.35527394, grad/param norm = 4.7111e-01, time/batch = 0.6673s	
478/33650 (epoch 0.710), train_loss = 2.50214787, grad/param norm = 3.5113e-01, time/batch = 0.6370s	
479/33650 (epoch 0.712), train_loss = 2.34738587, grad/param norm = 3.7315e-01, time/batch = 0.6340s	
480/33650 (epoch 0.713), train_loss = 2.41881854, grad/param norm = 4.2491e-01, time/batch = 0.6379s	
481/33650 (epoch 0.715), train_loss = 2.40800875, grad/param norm = 4.0761e-01, time/batch = 0.6343s	
482/33650 (epoch 0.716), train_loss = 2.33948997, grad/param norm = 4.7078e-01, time/batch = 0.6318s	
483/33650 (epoch 0.718), train_loss = 2.46479222, grad/param norm = 4.5506e-01, time/batch = 0.6283s	
484/33650 (epoch 0.719), train_loss = 2.43813273, grad/param norm = 4.3020e-01, time/batch = 0.6296s	
485/33650 (epoch 0.721), train_loss = 2.41905031, grad/param norm = 4.2078e-01, time/batch = 0.6278s	
486/33650 (epoch 0.722), train_loss = 2.52642153, grad/param norm = 3.8375e-01, time/batch = 0.6284s	
487/33650 (epoch 0.724), train_loss = 2.39890860, grad/param norm = 4.5145e-01, time/batch = 0.6284s	
488/33650 (epoch 0.725), train_loss = 2.45438230, grad/param norm = 4.6623e-01, time/batch = 0.6291s	
489/33650 (epoch 0.727), train_loss = 2.23105176, grad/param norm = 5.3493e-01, time/batch = 0.6318s	
490/33650 (epoch 0.728), train_loss = 2.25846570, grad/param norm = 5.0350e-01, time/batch = 0.6296s	
491/33650 (epoch 0.730), train_loss = 2.31453081, grad/param norm = 6.2159e-01, time/batch = 0.6311s	
492/33650 (epoch 0.731), train_loss = 2.53376979, grad/param norm = 6.7791e-01, time/batch = 0.6329s	
493/33650 (epoch 0.733), train_loss = 2.29113862, grad/param norm = 5.7041e-01, time/batch = 0.6316s	
494/33650 (epoch 0.734), train_loss = 2.45804014, grad/param norm = 4.4768e-01, time/batch = 0.6323s	
495/33650 (epoch 0.736), train_loss = 2.42447542, grad/param norm = 4.0758e-01, time/batch = 0.6294s	
496/33650 (epoch 0.737), train_loss = 2.38452552, grad/param norm = 4.7229e-01, time/batch = 0.6265s	
497/33650 (epoch 0.738), train_loss = 2.20633476, grad/param norm = 6.2276e-01, time/batch = 0.6632s	
498/33650 (epoch 0.740), train_loss = 2.44331379, grad/param norm = 5.3274e-01, time/batch = 0.6508s	
499/33650 (epoch 0.741), train_loss = 2.34514946, grad/param norm = 4.0805e-01, time/batch = 0.6310s	
500/33650 (epoch 0.743), train_loss = 2.25394757, grad/param norm = 3.8414e-01, time/batch = 0.6295s	
501/33650 (epoch 0.744), train_loss = 2.14740633, grad/param norm = 3.6517e-01, time/batch = 0.6298s	
502/33650 (epoch 0.746), train_loss = 2.33305905, grad/param norm = 4.0236e-01, time/batch = 0.6379s	
503/33650 (epoch 0.747), train_loss = 2.38182358, grad/param norm = 3.6501e-01, time/batch = 0.6307s	
504/33650 (epoch 0.749), train_loss = 2.00370804, grad/param norm = 3.5962e-01, time/batch = 0.6315s	
505/33650 (epoch 0.750), train_loss = 2.35017079, grad/param norm = 4.1287e-01, time/batch = 0.6291s	
506/33650 (epoch 0.752), train_loss = 2.37878307, grad/param norm = 4.7375e-01, time/batch = 0.6307s	
507/33650 (epoch 0.753), train_loss = 2.50632705, grad/param norm = 4.0994e-01, time/batch = 0.6314s	
508/33650 (epoch 0.755), train_loss = 2.11859602, grad/param norm = 3.3711e-01, time/batch = 0.6288s	
509/33650 (epoch 0.756), train_loss = 2.24381440, grad/param norm = 3.5315e-01, time/batch = 0.6319s	
510/33650 (epoch 0.758), train_loss = 2.50238284, grad/param norm = 3.7829e-01, time/batch = 0.6351s	
511/33650 (epoch 0.759), train_loss = 2.49431362, grad/param norm = 4.7394e-01, time/batch = 0.6318s	
512/33650 (epoch 0.761), train_loss = 2.35366919, grad/param norm = 4.8854e-01, time/batch = 0.6302s	
513/33650 (epoch 0.762), train_loss = 2.36834066, grad/param norm = 3.5798e-01, time/batch = 0.6306s	
514/33650 (epoch 0.764), train_loss = 2.41521056, grad/param norm = 3.7365e-01, time/batch = 0.6401s	
515/33650 (epoch 0.765), train_loss = 2.21035184, grad/param norm = 2.8985e-01, time/batch = 0.6342s	
516/33650 (epoch 0.767), train_loss = 2.19484565, grad/param norm = 2.9364e-01, time/batch = 0.6292s	
517/33650 (epoch 0.768), train_loss = 2.11286304, grad/param norm = 3.5794e-01, time/batch = 0.6502s	
518/33650 (epoch 0.770), train_loss = 2.35637422, grad/param norm = 4.1179e-01, time/batch = 0.6668s	
519/33650 (epoch 0.771), train_loss = 2.34183146, grad/param norm = 3.8228e-01, time/batch = 0.6277s	
520/33650 (epoch 0.773), train_loss = 2.37882868, grad/param norm = 3.5613e-01, time/batch = 0.6271s	
521/33650 (epoch 0.774), train_loss = 2.15700012, grad/param norm = 3.1449e-01, time/batch = 0.6351s	
522/33650 (epoch 0.776), train_loss = 2.38845602, grad/param norm = 3.1702e-01, time/batch = 0.6361s	
523/33650 (epoch 0.777), train_loss = 2.19070605, grad/param norm = 4.1994e-01, time/batch = 0.6313s	
524/33650 (epoch 0.779), train_loss = 2.32813073, grad/param norm = 6.0478e-01, time/batch = 0.6347s	
525/33650 (epoch 0.780), train_loss = 2.16117067, grad/param norm = 6.4287e-01, time/batch = 0.6447s	
526/33650 (epoch 0.782), train_loss = 2.35318948, grad/param norm = 5.8510e-01, time/batch = 0.6478s	
527/33650 (epoch 0.783), train_loss = 2.19766756, grad/param norm = 5.5630e-01, time/batch = 0.6311s	
528/33650 (epoch 0.785), train_loss = 2.52840752, grad/param norm = 6.3330e-01, time/batch = 0.6297s	
529/33650 (epoch 0.786), train_loss = 2.18896865, grad/param norm = 4.8181e-01, time/batch = 0.6287s	
530/33650 (epoch 0.788), train_loss = 2.28420849, grad/param norm = 4.7107e-01, time/batch = 0.6299s	
531/33650 (epoch 0.789), train_loss = 2.32197929, grad/param norm = 3.9527e-01, time/batch = 0.6360s	
532/33650 (epoch 0.790), train_loss = 2.30069928, grad/param norm = 3.9676e-01, time/batch = 0.6287s	
533/33650 (epoch 0.792), train_loss = 2.38791993, grad/param norm = 3.9404e-01, time/batch = 0.6285s	
534/33650 (epoch 0.793), train_loss = 2.25151508, grad/param norm = 3.3679e-01, time/batch = 0.6312s	
535/33650 (epoch 0.795), train_loss = 2.42028485, grad/param norm = 3.9153e-01, time/batch = 0.6292s	
536/33650 (epoch 0.796), train_loss = 2.21917488, grad/param norm = 3.4213e-01, time/batch = 0.6304s	
537/33650 (epoch 0.798), train_loss = 2.24220223, grad/param norm = 3.4686e-01, time/batch = 0.6371s	
538/33650 (epoch 0.799), train_loss = 2.30146258, grad/param norm = 2.9837e-01, time/batch = 0.6672s	
539/33650 (epoch 0.801), train_loss = 2.31423062, grad/param norm = 4.2586e-01, time/batch = 0.6523s	
540/33650 (epoch 0.802), train_loss = 2.48192706, grad/param norm = 5.5751e-01, time/batch = 0.6325s	
541/33650 (epoch 0.804), train_loss = 2.28702097, grad/param norm = 4.6535e-01, time/batch = 0.6375s	
542/33650 (epoch 0.805), train_loss = 2.24612224, grad/param norm = 3.8569e-01, time/batch = 0.6327s	
543/33650 (epoch 0.807), train_loss = 2.57374076, grad/param norm = 3.4255e-01, time/batch = 0.6322s	
544/33650 (epoch 0.808), train_loss = 2.45040225, grad/param norm = 3.4278e-01, time/batch = 0.6330s	
545/33650 (epoch 0.810), train_loss = 2.33629045, grad/param norm = 4.3312e-01, time/batch = 0.6346s	
546/33650 (epoch 0.811), train_loss = 2.38938194, grad/param norm = 4.3840e-01, time/batch = 0.6475s	
547/33650 (epoch 0.813), train_loss = 2.44267920, grad/param norm = 5.2912e-01, time/batch = 0.6426s	
548/33650 (epoch 0.814), train_loss = 2.44075529, grad/param norm = 5.7930e-01, time/batch = 0.6314s	
549/33650 (epoch 0.816), train_loss = 2.28625730, grad/param norm = 4.4700e-01, time/batch = 0.6525s	
550/33650 (epoch 0.817), train_loss = 2.49446329, grad/param norm = 4.5569e-01, time/batch = 0.6308s	
551/33650 (epoch 0.819), train_loss = 2.38161683, grad/param norm = 4.4121e-01, time/batch = 0.6415s	
552/33650 (epoch 0.820), train_loss = 2.37251236, grad/param norm = 3.3946e-01, time/batch = 0.6365s	
553/33650 (epoch 0.822), train_loss = 2.45494706, grad/param norm = 2.7724e-01, time/batch = 0.6549s	
554/33650 (epoch 0.823), train_loss = 2.15153841, grad/param norm = 3.5690e-01, time/batch = 0.6650s	
555/33650 (epoch 0.825), train_loss = 2.30207359, grad/param norm = 4.3850e-01, time/batch = 0.6476s	
556/33650 (epoch 0.826), train_loss = 2.37912091, grad/param norm = 5.3162e-01, time/batch = 0.6344s	
557/33650 (epoch 0.828), train_loss = 2.64390912, grad/param norm = 5.1659e-01, time/batch = 0.6352s	
558/33650 (epoch 0.829), train_loss = 2.20341425, grad/param norm = 4.3001e-01, time/batch = 0.6275s	
559/33650 (epoch 0.831), train_loss = 2.42367621, grad/param norm = 4.6412e-01, time/batch = 0.6310s	
560/33650 (epoch 0.832), train_loss = 2.36891560, grad/param norm = 4.4725e-01, time/batch = 0.6354s	
561/33650 (epoch 0.834), train_loss = 2.29773669, grad/param norm = 4.6866e-01, time/batch = 0.6521s	
562/33650 (epoch 0.835), train_loss = 2.71900393, grad/param norm = 4.4072e-01, time/batch = 0.6474s	
563/33650 (epoch 0.837), train_loss = 2.35692856, grad/param norm = 3.9593e-01, time/batch = 0.6492s	
564/33650 (epoch 0.838), train_loss = 2.30828342, grad/param norm = 2.9762e-01, time/batch = 0.6469s	
565/33650 (epoch 0.840), train_loss = 2.41390247, grad/param norm = 3.2127e-01, time/batch = 0.6366s	
566/33650 (epoch 0.841), train_loss = 2.26263269, grad/param norm = 3.7617e-01, time/batch = 0.6323s	
567/33650 (epoch 0.842), train_loss = 2.16508656, grad/param norm = 4.1589e-01, time/batch = 0.6319s	
568/33650 (epoch 0.844), train_loss = 2.42417569, grad/param norm = 4.3251e-01, time/batch = 0.6353s	
569/33650 (epoch 0.845), train_loss = 2.18279993, grad/param norm = 3.8836e-01, time/batch = 0.6301s	
570/33650 (epoch 0.847), train_loss = 2.08697306, grad/param norm = 3.7230e-01, time/batch = 0.6291s	
571/33650 (epoch 0.848), train_loss = 2.28000711, grad/param norm = 3.2913e-01, time/batch = 0.6297s	
572/33650 (epoch 0.850), train_loss = 2.26018300, grad/param norm = 3.5924e-01, time/batch = 0.6290s	
573/33650 (epoch 0.851), train_loss = 2.15985726, grad/param norm = 3.4024e-01, time/batch = 0.6338s	
574/33650 (epoch 0.853), train_loss = 2.37477721, grad/param norm = 3.9369e-01, time/batch = 0.6307s	
575/33650 (epoch 0.854), train_loss = 2.39655393, grad/param norm = 4.8420e-01, time/batch = 0.6296s	
576/33650 (epoch 0.856), train_loss = 2.14093754, grad/param norm = 6.9814e-01, time/batch = 0.6346s	
577/33650 (epoch 0.857), train_loss = 2.17973777, grad/param norm = 5.6530e-01, time/batch = 0.6317s	
578/33650 (epoch 0.859), train_loss = 2.19219055, grad/param norm = 3.9051e-01, time/batch = 0.6562s	
579/33650 (epoch 0.860), train_loss = 2.03033109, grad/param norm = 3.2820e-01, time/batch = 0.6628s	
580/33650 (epoch 0.862), train_loss = 2.16083097, grad/param norm = 3.3666e-01, time/batch = 0.6271s	
581/33650 (epoch 0.863), train_loss = 2.38677308, grad/param norm = 4.1723e-01, time/batch = 0.6385s	
582/33650 (epoch 0.865), train_loss = 2.13972281, grad/param norm = 5.3274e-01, time/batch = 0.6388s	
583/33650 (epoch 0.866), train_loss = 2.26776535, grad/param norm = 5.7580e-01, time/batch = 0.6285s	
584/33650 (epoch 0.868), train_loss = 2.11346834, grad/param norm = 4.5794e-01, time/batch = 0.6302s	
585/33650 (epoch 0.869), train_loss = 2.36468101, grad/param norm = 3.9234e-01, time/batch = 0.6303s	
586/33650 (epoch 0.871), train_loss = 2.20699840, grad/param norm = 2.9682e-01, time/batch = 0.6299s	
587/33650 (epoch 0.872), train_loss = 2.22432392, grad/param norm = 3.1929e-01, time/batch = 0.6313s	
588/33650 (epoch 0.874), train_loss = 2.28921452, grad/param norm = 4.2419e-01, time/batch = 0.6343s	
589/33650 (epoch 0.875), train_loss = 2.19813493, grad/param norm = 3.6750e-01, time/batch = 0.6424s	
590/33650 (epoch 0.877), train_loss = 2.35926519, grad/param norm = 3.5163e-01, time/batch = 0.6372s	
591/33650 (epoch 0.878), train_loss = 2.02356667, grad/param norm = 3.7187e-01, time/batch = 0.6313s	
592/33650 (epoch 0.880), train_loss = 2.29853646, grad/param norm = 4.6057e-01, time/batch = 0.6294s	
593/33650 (epoch 0.881), train_loss = 2.18705701, grad/param norm = 4.1123e-01, time/batch = 0.6294s	
594/33650 (epoch 0.883), train_loss = 2.24641914, grad/param norm = 3.1924e-01, time/batch = 0.6705s	
595/33650 (epoch 0.884), train_loss = 2.36100061, grad/param norm = 3.4339e-01, time/batch = 0.6468s	
596/33650 (epoch 0.886), train_loss = 2.18870962, grad/param norm = 3.9030e-01, time/batch = 0.6255s	
597/33650 (epoch 0.887), train_loss = 2.22990423, grad/param norm = 4.9287e-01, time/batch = 0.6250s	
598/33650 (epoch 0.889), train_loss = 2.40713201, grad/param norm = 5.5894e-01, time/batch = 0.6252s	
599/33650 (epoch 0.890), train_loss = 2.28077746, grad/param norm = 5.2361e-01, time/batch = 0.6253s	
600/33650 (epoch 0.892), train_loss = 2.21845987, grad/param norm = 3.8654e-01, time/batch = 0.6285s	
601/33650 (epoch 0.893), train_loss = 2.20780895, grad/param norm = 3.0991e-01, time/batch = 0.6326s	
602/33650 (epoch 0.895), train_loss = 2.26663526, grad/param norm = 2.9452e-01, time/batch = 0.6373s	
603/33650 (epoch 0.896), train_loss = 2.26824108, grad/param norm = 3.4137e-01, time/batch = 0.6323s	
604/33650 (epoch 0.897), train_loss = 2.22708722, grad/param norm = 3.4843e-01, time/batch = 0.6346s	
605/33650 (epoch 0.899), train_loss = 2.09960448, grad/param norm = 4.0893e-01, time/batch = 0.6278s	
606/33650 (epoch 0.900), train_loss = 1.89606927, grad/param norm = 3.4458e-01, time/batch = 0.6282s	
607/33650 (epoch 0.902), train_loss = 2.11848909, grad/param norm = 3.5918e-01, time/batch = 0.6285s	
608/33650 (epoch 0.903), train_loss = 2.17513043, grad/param norm = 4.2668e-01, time/batch = 0.6295s	
609/33650 (epoch 0.905), train_loss = 2.39402285, grad/param norm = 4.6320e-01, time/batch = 0.6314s	
610/33650 (epoch 0.906), train_loss = 2.14296722, grad/param norm = 3.5168e-01, time/batch = 0.6316s	
611/33650 (epoch 0.908), train_loss = 1.99838582, grad/param norm = 3.1487e-01, time/batch = 0.6354s	
612/33650 (epoch 0.909), train_loss = 2.14805301, grad/param norm = 2.7545e-01, time/batch = 0.6291s	
613/33650 (epoch 0.911), train_loss = 2.24505055, grad/param norm = 3.3147e-01, time/batch = 0.6288s	
614/33650 (epoch 0.912), train_loss = 2.09328321, grad/param norm = 2.9550e-01, time/batch = 0.6504s	
615/33650 (epoch 0.914), train_loss = 2.07783040, grad/param norm = 3.2840e-01, time/batch = 0.6651s	
616/33650 (epoch 0.915), train_loss = 2.40930389, grad/param norm = 4.0775e-01, time/batch = 0.6401s	
617/33650 (epoch 0.917), train_loss = 2.16150820, grad/param norm = 4.2934e-01, time/batch = 0.6413s	
618/33650 (epoch 0.918), train_loss = 2.01778147, grad/param norm = 4.6488e-01, time/batch = 0.6383s	
619/33650 (epoch 0.920), train_loss = 2.23726632, grad/param norm = 3.5744e-01, time/batch = 0.6377s	
620/33650 (epoch 0.921), train_loss = 2.10822377, grad/param norm = 3.0303e-01, time/batch = 0.6329s	
621/33650 (epoch 0.923), train_loss = 2.04718001, grad/param norm = 3.0639e-01, time/batch = 0.6315s	
622/33650 (epoch 0.924), train_loss = 2.23708667, grad/param norm = 3.1793e-01, time/batch = 0.6336s	
623/33650 (epoch 0.926), train_loss = 2.38492698, grad/param norm = 3.1467e-01, time/batch = 0.6315s	
624/33650 (epoch 0.927), train_loss = 2.23280415, grad/param norm = 3.1563e-01, time/batch = 0.6323s	
625/33650 (epoch 0.929), train_loss = 2.01012777, grad/param norm = 3.5744e-01, time/batch = 0.6353s	
626/33650 (epoch 0.930), train_loss = 2.09791003, grad/param norm = 4.0649e-01, time/batch = 0.6304s	
627/33650 (epoch 0.932), train_loss = 2.15787950, grad/param norm = 4.1389e-01, time/batch = 0.6378s	
628/33650 (epoch 0.933), train_loss = 2.07102800, grad/param norm = 3.6562e-01, time/batch = 0.6423s	
629/33650 (epoch 0.935), train_loss = 2.15798507, grad/param norm = 4.0203e-01, time/batch = 0.6266s	
630/33650 (epoch 0.936), train_loss = 2.09197146, grad/param norm = 4.7675e-01, time/batch = 0.6266s	
631/33650 (epoch 0.938), train_loss = 2.06085646, grad/param norm = 5.0070e-01, time/batch = 0.6342s	
632/33650 (epoch 0.939), train_loss = 2.13115763, grad/param norm = 3.8305e-01, time/batch = 0.6304s	
633/33650 (epoch 0.941), train_loss = 2.20056762, grad/param norm = 3.1595e-01, time/batch = 0.6319s	
634/33650 (epoch 0.942), train_loss = 2.24503613, grad/param norm = 3.2836e-01, time/batch = 0.6297s	
635/33650 (epoch 0.944), train_loss = 2.27308717, grad/param norm = 3.1634e-01, time/batch = 0.6277s	
636/33650 (epoch 0.945), train_loss = 2.21268352, grad/param norm = 3.4649e-01, time/batch = 0.6316s	
637/33650 (epoch 0.947), train_loss = 2.32890081, grad/param norm = 3.2859e-01, time/batch = 0.6275s	
638/33650 (epoch 0.948), train_loss = 2.28697907, grad/param norm = 3.3991e-01, time/batch = 0.6274s	
639/33650 (epoch 0.949), train_loss = 2.00677159, grad/param norm = 4.3898e-01, time/batch = 0.6461s	
640/33650 (epoch 0.951), train_loss = 2.13255769, grad/param norm = 3.7540e-01, time/batch = 0.6685s	
641/33650 (epoch 0.952), train_loss = 2.32268311, grad/param norm = 3.4672e-01, time/batch = 0.6455s	
642/33650 (epoch 0.954), train_loss = 2.14685995, grad/param norm = 3.0218e-01, time/batch = 0.6485s	
643/33650 (epoch 0.955), train_loss = 2.31717048, grad/param norm = 3.6016e-01, time/batch = 0.6370s	
644/33650 (epoch 0.957), train_loss = 2.19134687, grad/param norm = 4.2193e-01, time/batch = 0.6309s	
645/33650 (epoch 0.958), train_loss = 1.86403301, grad/param norm = 5.2290e-01, time/batch = 0.6376s	
646/33650 (epoch 0.960), train_loss = 2.00281054, grad/param norm = 4.5822e-01, time/batch = 0.6427s	
647/33650 (epoch 0.961), train_loss = 2.13457004, grad/param norm = 3.7125e-01, time/batch = 0.6371s	
648/33650 (epoch 0.963), train_loss = 2.23792287, grad/param norm = 4.0307e-01, time/batch = 0.6299s	
649/33650 (epoch 0.964), train_loss = 2.12673048, grad/param norm = 3.4182e-01, time/batch = 0.6388s	
650/33650 (epoch 0.966), train_loss = 2.23723134, grad/param norm = 4.0761e-01, time/batch = 0.6407s	
651/33650 (epoch 0.967), train_loss = 2.21107855, grad/param norm = 4.5728e-01, time/batch = 0.6377s	
652/33650 (epoch 0.969), train_loss = 2.16401718, grad/param norm = 5.7243e-01, time/batch = 0.6376s	
653/33650 (epoch 0.970), train_loss = 2.21874566, grad/param norm = 4.0477e-01, time/batch = 0.6560s	
654/33650 (epoch 0.972), train_loss = 2.41737881, grad/param norm = 3.6159e-01, time/batch = 0.6706s	
655/33650 (epoch 0.973), train_loss = 2.07349536, grad/param norm = 3.5542e-01, time/batch = 0.6712s	
656/33650 (epoch 0.975), train_loss = 2.13534995, grad/param norm = 3.3382e-01, time/batch = 0.6668s	
657/33650 (epoch 0.976), train_loss = 2.04796334, grad/param norm = 3.7368e-01, time/batch = 0.6626s	
658/33650 (epoch 0.978), train_loss = 2.01701259, grad/param norm = 3.5922e-01, time/batch = 0.6577s	
659/33650 (epoch 0.979), train_loss = 2.16161663, grad/param norm = 4.6004e-01, time/batch = 0.6467s	
660/33650 (epoch 0.981), train_loss = 2.16315667, grad/param norm = 3.7714e-01, time/batch = 0.6355s	
661/33650 (epoch 0.982), train_loss = 2.25088915, grad/param norm = 3.6698e-01, time/batch = 0.6288s	
662/33650 (epoch 0.984), train_loss = 1.84465088, grad/param norm = 2.9098e-01, time/batch = 0.6292s	
663/33650 (epoch 0.985), train_loss = 1.95132438, grad/param norm = 2.7551e-01, time/batch = 0.6292s	
664/33650 (epoch 0.987), train_loss = 2.12686343, grad/param norm = 3.0859e-01, time/batch = 0.6407s	
665/33650 (epoch 0.988), train_loss = 2.19069530, grad/param norm = 2.7469e-01, time/batch = 0.6440s	
666/33650 (epoch 0.990), train_loss = 2.38047979, grad/param norm = 3.6814e-01, time/batch = 0.6340s	
667/33650 (epoch 0.991), train_loss = 2.31575464, grad/param norm = 3.5967e-01, time/batch = 0.6353s	
668/33650 (epoch 0.993), train_loss = 2.27158697, grad/param norm = 3.7258e-01, time/batch = 0.6256s	
669/33650 (epoch 0.994), train_loss = 2.08536907, grad/param norm = 3.9114e-01, time/batch = 0.6259s	
670/33650 (epoch 0.996), train_loss = 2.08118208, grad/param norm = 4.5794e-01, time/batch = 0.6469s	
671/33650 (epoch 0.997), train_loss = 2.22636282, grad/param norm = 4.5667e-01, time/batch = 0.6672s	
672/33650 (epoch 0.999), train_loss = 1.98565510, grad/param norm = 4.0722e-01, time/batch = 0.6252s	
673/33650 (epoch 1.000), train_loss = 2.33369990, grad/param norm = 3.8492e-01, time/batch = 0.6255s	
674/33650 (epoch 1.001), train_loss = 2.38496059, grad/param norm = 4.6135e-01, time/batch = 0.6290s	
675/33650 (epoch 1.003), train_loss = 2.33817399, grad/param norm = 3.7435e-01, time/batch = 0.6406s	
676/33650 (epoch 1.004), train_loss = 2.15955591, grad/param norm = 3.1062e-01, time/batch = 0.6407s	
677/33650 (epoch 1.006), train_loss = 2.22881741, grad/param norm = 2.8725e-01, time/batch = 0.6271s	
678/33650 (epoch 1.007), train_loss = 2.00873807, grad/param norm = 3.2270e-01, time/batch = 0.6255s	
679/33650 (epoch 1.009), train_loss = 2.11668865, grad/param norm = 3.4571e-01, time/batch = 0.6233s	
680/33650 (epoch 1.010), train_loss = 2.32010970, grad/param norm = 4.2870e-01, time/batch = 0.6258s	
681/33650 (epoch 1.012), train_loss = 2.17250656, grad/param norm = 4.4969e-01, time/batch = 0.6392s	
682/33650 (epoch 1.013), train_loss = 2.26749600, grad/param norm = 4.2431e-01, time/batch = 0.6465s	
683/33650 (epoch 1.015), train_loss = 2.05335923, grad/param norm = 3.3361e-01, time/batch = 0.6500s	
684/33650 (epoch 1.016), train_loss = 2.26202575, grad/param norm = 3.4838e-01, time/batch = 0.6541s	
685/33650 (epoch 1.018), train_loss = 2.15987436, grad/param norm = 2.9159e-01, time/batch = 0.6371s	
686/33650 (epoch 1.019), train_loss = 2.07521365, grad/param norm = 3.1424e-01, time/batch = 0.6690s	
687/33650 (epoch 1.021), train_loss = 2.29489743, grad/param norm = 3.2431e-01, time/batch = 0.6532s	
688/33650 (epoch 1.022), train_loss = 2.14966015, grad/param norm = 3.6632e-01, time/batch = 0.6298s	
689/33650 (epoch 1.024), train_loss = 2.14961662, grad/param norm = 3.4041e-01, time/batch = 0.6274s	
690/33650 (epoch 1.025), train_loss = 2.14664669, grad/param norm = 3.5394e-01, time/batch = 0.6274s	
691/33650 (epoch 1.027), train_loss = 2.27484593, grad/param norm = 3.6893e-01, time/batch = 0.6291s	
692/33650 (epoch 1.028), train_loss = 2.30025444, grad/param norm = 3.3436e-01, time/batch = 0.6262s	
693/33650 (epoch 1.030), train_loss = 2.07844080, grad/param norm = 3.0863e-01, time/batch = 0.6288s	
694/33650 (epoch 1.031), train_loss = 1.80542461, grad/param norm = 2.9804e-01, time/batch = 0.6279s	
695/33650 (epoch 1.033), train_loss = 2.02275977, grad/param norm = 3.8073e-01, time/batch = 0.6349s	
696/33650 (epoch 1.034), train_loss = 2.15868290, grad/param norm = 3.2018e-01, time/batch = 0.6312s	
697/33650 (epoch 1.036), train_loss = 2.23720018, grad/param norm = 3.9163e-01, time/batch = 0.6275s	
698/33650 (epoch 1.037), train_loss = 2.06502641, grad/param norm = 4.3905e-01, time/batch = 0.6288s	
699/33650 (epoch 1.039), train_loss = 2.21156343, grad/param norm = 3.4206e-01, time/batch = 0.6278s	
700/33650 (epoch 1.040), train_loss = 2.21594143, grad/param norm = 3.3308e-01, time/batch = 0.6285s	
701/33650 (epoch 1.042), train_loss = 2.32068196, grad/param norm = 3.6014e-01, time/batch = 0.6312s	
702/33650 (epoch 1.043), train_loss = 1.96702961, grad/param norm = 3.9007e-01, time/batch = 0.6299s	
703/33650 (epoch 1.045), train_loss = 2.09720851, grad/param norm = 3.2758e-01, time/batch = 0.6306s	
704/33650 (epoch 1.046), train_loss = 2.29871956, grad/param norm = 3.5612e-01, time/batch = 0.6270s	
705/33650 (epoch 1.048), train_loss = 2.12566544, grad/param norm = 3.9873e-01, time/batch = 0.6274s	
706/33650 (epoch 1.049), train_loss = 2.29725369, grad/param norm = 4.4229e-01, time/batch = 0.6271s	
707/33650 (epoch 1.051), train_loss = 2.18374667, grad/param norm = 3.0905e-01, time/batch = 0.6267s	
708/33650 (epoch 1.052), train_loss = 2.22538764, grad/param norm = 2.7838e-01, time/batch = 0.6274s	
709/33650 (epoch 1.053), train_loss = 2.01529858, grad/param norm = 2.5221e-01, time/batch = 0.6281s	
710/33650 (epoch 1.055), train_loss = 1.91878121, grad/param norm = 2.8398e-01, time/batch = 0.6365s	
711/33650 (epoch 1.056), train_loss = 1.84552760, grad/param norm = 3.4815e-01, time/batch = 0.6634s	
712/33650 (epoch 1.058), train_loss = 2.20230229, grad/param norm = 3.0298e-01, time/batch = 0.6582s	
713/33650 (epoch 1.059), train_loss = 2.29485426, grad/param norm = 3.7793e-01, time/batch = 0.6284s	
714/33650 (epoch 1.061), train_loss = 2.12002207, grad/param norm = 3.5771e-01, time/batch = 0.6286s	
715/33650 (epoch 1.062), train_loss = 2.21173766, grad/param norm = 3.6721e-01, time/batch = 0.6292s	
716/33650 (epoch 1.064), train_loss = 2.09188085, grad/param norm = 4.4822e-01, time/batch = 0.6296s	
717/33650 (epoch 1.065), train_loss = 2.09052218, grad/param norm = 4.1286e-01, time/batch = 0.6267s	
718/33650 (epoch 1.067), train_loss = 2.06639062, grad/param norm = 3.4561e-01, time/batch = 0.6273s	
719/33650 (epoch 1.068), train_loss = 2.09640590, grad/param norm = 2.7045e-01, time/batch = 0.6276s	
720/33650 (epoch 1.070), train_loss = 2.06021729, grad/param norm = 2.7529e-01, time/batch = 0.6264s	
721/33650 (epoch 1.071), train_loss = 2.15198520, grad/param norm = 2.6741e-01, time/batch = 0.6286s	
722/33650 (epoch 1.073), train_loss = 2.26058255, grad/param norm = 2.9107e-01, time/batch = 0.6270s	
723/33650 (epoch 1.074), train_loss = 2.18718411, grad/param norm = 3.4381e-01, time/batch = 0.6263s	
724/33650 (epoch 1.076), train_loss = 2.16310242, grad/param norm = 3.1835e-01, time/batch = 0.6261s	
725/33650 (epoch 1.077), train_loss = 2.07192667, grad/param norm = 3.2157e-01, time/batch = 0.6290s	
726/33650 (epoch 1.079), train_loss = 2.05098411, grad/param norm = 3.2932e-01, time/batch = 0.6382s	
727/33650 (epoch 1.080), train_loss = 2.08181991, grad/param norm = 4.0503e-01, time/batch = 0.6528s	
728/33650 (epoch 1.082), train_loss = 2.33368992, grad/param norm = 4.2619e-01, time/batch = 0.6529s	
729/33650 (epoch 1.083), train_loss = 2.31083748, grad/param norm = 3.8473e-01, time/batch = 0.6428s	
730/33650 (epoch 1.085), train_loss = 2.20814059, grad/param norm = 4.1155e-01, time/batch = 0.6397s	
731/33650 (epoch 1.086), train_loss = 2.43029914, grad/param norm = 5.2115e-01, time/batch = 0.6506s	
732/33650 (epoch 1.088), train_loss = 2.13746449, grad/param norm = 4.5324e-01, time/batch = 0.6603s	
733/33650 (epoch 1.089), train_loss = 2.17522900, grad/param norm = 3.2443e-01, time/batch = 0.6360s	
734/33650 (epoch 1.091), train_loss = 1.96993778, grad/param norm = 2.7224e-01, time/batch = 0.6466s	
735/33650 (epoch 1.092), train_loss = 1.97171707, grad/param norm = 2.7893e-01, time/batch = 0.6256s	
736/33650 (epoch 1.094), train_loss = 2.27009281, grad/param norm = 3.3131e-01, time/batch = 0.6381s	
737/33650 (epoch 1.095), train_loss = 2.22107690, grad/param norm = 3.8854e-01, time/batch = 0.6385s	
738/33650 (epoch 1.097), train_loss = 2.06898294, grad/param norm = 4.1582e-01, time/batch = 0.6311s	
739/33650 (epoch 1.098), train_loss = 1.88796479, grad/param norm = 2.6982e-01, time/batch = 0.6328s	
740/33650 (epoch 1.100), train_loss = 2.09360339, grad/param norm = 2.9479e-01, time/batch = 0.6328s	
741/33650 (epoch 1.101), train_loss = 1.93865403, grad/param norm = 3.7446e-01, time/batch = 0.6341s	
742/33650 (epoch 1.103), train_loss = 2.00940593, grad/param norm = 3.5996e-01, time/batch = 0.6305s	
743/33650 (epoch 1.104), train_loss = 2.06778530, grad/param norm = 3.0293e-01, time/batch = 0.6295s	
744/33650 (epoch 1.105), train_loss = 2.10025251, grad/param norm = 2.9594e-01, time/batch = 0.6307s	
745/33650 (epoch 1.107), train_loss = 1.96313849, grad/param norm = 2.9380e-01, time/batch = 0.6326s	
746/33650 (epoch 1.108), train_loss = 2.12881847, grad/param norm = 2.6220e-01, time/batch = 0.6312s	
747/33650 (epoch 1.110), train_loss = 2.23167530, grad/param norm = 4.0605e-01, time/batch = 0.6293s	
748/33650 (epoch 1.111), train_loss = 1.96465536, grad/param norm = 3.7271e-01, time/batch = 0.6398s	
749/33650 (epoch 1.113), train_loss = 2.09833174, grad/param norm = 4.2355e-01, time/batch = 0.6313s	
750/33650 (epoch 1.114), train_loss = 2.16816398, grad/param norm = 3.1906e-01, time/batch = 0.6316s	
751/33650 (epoch 1.116), train_loss = 1.78238908, grad/param norm = 2.9853e-01, time/batch = 0.6475s	
752/33650 (epoch 1.117), train_loss = 2.21922129, grad/param norm = 3.8845e-01, time/batch = 0.6711s	
753/33650 (epoch 1.119), train_loss = 2.06148453, grad/param norm = 3.8510e-01, time/batch = 0.6479s	
754/33650 (epoch 1.120), train_loss = 2.05633274, grad/param norm = 3.4474e-01, time/batch = 0.6297s	
755/33650 (epoch 1.122), train_loss = 2.06619790, grad/param norm = 3.6181e-01, time/batch = 0.6285s	
756/33650 (epoch 1.123), train_loss = 2.02957474, grad/param norm = 2.6466e-01, time/batch = 0.6305s	
757/33650 (epoch 1.125), train_loss = 2.12685680, grad/param norm = 2.6988e-01, time/batch = 0.6273s	
758/33650 (epoch 1.126), train_loss = 2.25929561, grad/param norm = 2.7742e-01, time/batch = 0.6269s	
759/33650 (epoch 1.128), train_loss = 2.14198156, grad/param norm = 2.7726e-01, time/batch = 0.6284s	
760/33650 (epoch 1.129), train_loss = 2.20142823, grad/param norm = 3.0271e-01, time/batch = 0.6262s	
761/33650 (epoch 1.131), train_loss = 2.15104683, grad/param norm = 3.1061e-01, time/batch = 0.6282s	
762/33650 (epoch 1.132), train_loss = 2.05374846, grad/param norm = 2.6863e-01, time/batch = 0.6364s	
763/33650 (epoch 1.134), train_loss = 2.32865035, grad/param norm = 2.9101e-01, time/batch = 0.6336s	
764/33650 (epoch 1.135), train_loss = 2.02251394, grad/param norm = 3.4374e-01, time/batch = 0.6275s	
765/33650 (epoch 1.137), train_loss = 2.04069931, grad/param norm = 3.2840e-01, time/batch = 0.6267s	
766/33650 (epoch 1.138), train_loss = 2.15132804, grad/param norm = 3.1731e-01, time/batch = 0.6278s	
767/33650 (epoch 1.140), train_loss = 1.99708238, grad/param norm = 3.3697e-01, time/batch = 0.6266s	
768/33650 (epoch 1.141), train_loss = 2.28689241, grad/param norm = 2.8408e-01, time/batch = 0.6275s	
769/33650 (epoch 1.143), train_loss = 2.32155147, grad/param norm = 3.7061e-01, time/batch = 0.6274s	
770/33650 (epoch 1.144), train_loss = 2.34722765, grad/param norm = 3.4202e-01, time/batch = 0.6331s	
771/33650 (epoch 1.146), train_loss = 2.10453413, grad/param norm = 3.0243e-01, time/batch = 0.6358s	
772/33650 (epoch 1.147), train_loss = 2.06612037, grad/param norm = 2.7506e-01, time/batch = 0.6542s	
773/33650 (epoch 1.149), train_loss = 1.93687393, grad/param norm = 2.9507e-01, time/batch = 0.6628s	
774/33650 (epoch 1.150), train_loss = 2.01217896, grad/param norm = 2.7261e-01, time/batch = 0.6277s	
775/33650 (epoch 1.152), train_loss = 2.14919272, grad/param norm = 2.9442e-01, time/batch = 0.6283s	
776/33650 (epoch 1.153), train_loss = 2.12985635, grad/param norm = 3.6838e-01, time/batch = 0.6277s	
777/33650 (epoch 1.155), train_loss = 1.97779946, grad/param norm = 3.5902e-01, time/batch = 0.6277s	
778/33650 (epoch 1.156), train_loss = 1.96892463, grad/param norm = 3.2461e-01, time/batch = 0.6330s	
779/33650 (epoch 1.158), train_loss = 2.10133555, grad/param norm = 3.4503e-01, time/batch = 0.6323s	
780/33650 (epoch 1.159), train_loss = 1.86925048, grad/param norm = 3.4499e-01, time/batch = 0.6270s	
781/33650 (epoch 1.160), train_loss = 2.02005311, grad/param norm = 3.3753e-01, time/batch = 0.6298s	
782/33650 (epoch 1.162), train_loss = 1.86310078, grad/param norm = 3.4320e-01, time/batch = 0.6277s	
783/33650 (epoch 1.163), train_loss = 2.14491565, grad/param norm = 3.4579e-01, time/batch = 0.6270s	
784/33650 (epoch 1.165), train_loss = 1.82461822, grad/param norm = 2.7468e-01, time/batch = 0.6337s	
785/33650 (epoch 1.166), train_loss = 1.82440403, grad/param norm = 2.8389e-01, time/batch = 0.6277s	
786/33650 (epoch 1.168), train_loss = 2.20922023, grad/param norm = 3.7366e-01, time/batch = 0.6291s	
787/33650 (epoch 1.169), train_loss = 2.03353274, grad/param norm = 4.4352e-01, time/batch = 0.6285s	
788/33650 (epoch 1.171), train_loss = 2.07127677, grad/param norm = 4.1147e-01, time/batch = 0.6266s	
789/33650 (epoch 1.172), train_loss = 2.00593856, grad/param norm = 4.5235e-01, time/batch = 0.6278s	
790/33650 (epoch 1.174), train_loss = 1.98016633, grad/param norm = 4.3214e-01, time/batch = 0.6269s	
791/33650 (epoch 1.175), train_loss = 1.91206559, grad/param norm = 3.6951e-01, time/batch = 0.6310s	
792/33650 (epoch 1.177), train_loss = 2.14467301, grad/param norm = 2.8374e-01, time/batch = 0.6357s	
793/33650 (epoch 1.178), train_loss = 2.13904992, grad/param norm = 3.2661e-01, time/batch = 0.6675s	
794/33650 (epoch 1.180), train_loss = 2.05456487, grad/param norm = 3.6538e-01, time/batch = 0.6430s	
795/33650 (epoch 1.181), train_loss = 1.93614132, grad/param norm = 2.7152e-01, time/batch = 0.6341s	
796/33650 (epoch 1.183), train_loss = 2.11150306, grad/param norm = 3.0430e-01, time/batch = 0.6333s	
797/33650 (epoch 1.184), train_loss = 2.09532425, grad/param norm = 3.4638e-01, time/batch = 0.6285s	
798/33650 (epoch 1.186), train_loss = 2.17448494, grad/param norm = 3.1549e-01, time/batch = 0.6265s	
799/33650 (epoch 1.187), train_loss = 2.17766841, grad/param norm = 2.9902e-01, time/batch = 0.6272s	
800/33650 (epoch 1.189), train_loss = 2.10721859, grad/param norm = 3.1413e-01, time/batch = 0.6302s	
801/33650 (epoch 1.190), train_loss = 2.23291964, grad/param norm = 3.0990e-01, time/batch = 0.6292s	
802/33650 (epoch 1.192), train_loss = 2.20284106, grad/param norm = 2.4334e-01, time/batch = 0.6273s	
803/33650 (epoch 1.193), train_loss = 2.22246659, grad/param norm = 3.0406e-01, time/batch = 0.6264s	
804/33650 (epoch 1.195), train_loss = 1.88102022, grad/param norm = 2.8460e-01, time/batch = 0.6277s	
805/33650 (epoch 1.196), train_loss = 1.85937346, grad/param norm = 3.1670e-01, time/batch = 0.6318s	
806/33650 (epoch 1.198), train_loss = 2.10218650, grad/param norm = 2.9557e-01, time/batch = 0.6314s	
807/33650 (epoch 1.199), train_loss = 2.20532066, grad/param norm = 3.2505e-01, time/batch = 0.6446s	
808/33650 (epoch 1.201), train_loss = 2.21668302, grad/param norm = 3.5450e-01, time/batch = 0.6600s	
809/33650 (epoch 1.202), train_loss = 2.05755101, grad/param norm = 3.5892e-01, time/batch = 0.6367s	
810/33650 (epoch 1.204), train_loss = 2.11097885, grad/param norm = 3.6182e-01, time/batch = 0.6275s	
811/33650 (epoch 1.205), train_loss = 2.07191395, grad/param norm = 4.1224e-01, time/batch = 0.6294s	
812/33650 (epoch 1.207), train_loss = 2.08454142, grad/param norm = 2.6735e-01, time/batch = 0.6265s	
813/33650 (epoch 1.208), train_loss = 2.06199208, grad/param norm = 2.7818e-01, time/batch = 0.6582s	
814/33650 (epoch 1.210), train_loss = 1.65629174, grad/param norm = 3.0353e-01, time/batch = 0.6576s	
815/33650 (epoch 1.211), train_loss = 2.19535344, grad/param norm = 3.2759e-01, time/batch = 0.6264s	
816/33650 (epoch 1.212), train_loss = 2.07092826, grad/param norm = 3.0180e-01, time/batch = 0.6296s	
817/33650 (epoch 1.214), train_loss = 2.08135615, grad/param norm = 3.4307e-01, time/batch = 0.6302s	
818/33650 (epoch 1.215), train_loss = 1.83331964, grad/param norm = 3.6441e-01, time/batch = 0.6266s	
819/33650 (epoch 1.217), train_loss = 2.03609283, grad/param norm = 3.3115e-01, time/batch = 0.6269s	
820/33650 (epoch 1.218), train_loss = 2.18652124, grad/param norm = 2.7409e-01, time/batch = 0.6262s	
821/33650 (epoch 1.220), train_loss = 2.05267752, grad/param norm = 2.6937e-01, time/batch = 0.6321s	
822/33650 (epoch 1.221), train_loss = 2.13863538, grad/param norm = 2.3480e-01, time/batch = 0.6293s	
823/33650 (epoch 1.223), train_loss = 1.93174318, grad/param norm = 2.9738e-01, time/batch = 0.6303s	
824/33650 (epoch 1.224), train_loss = 2.08641339, grad/param norm = 3.1844e-01, time/batch = 0.6301s	
825/33650 (epoch 1.226), train_loss = 2.25136032, grad/param norm = 3.7001e-01, time/batch = 0.6265s	
826/33650 (epoch 1.227), train_loss = 2.22768284, grad/param norm = 3.2902e-01, time/batch = 0.6275s	
827/33650 (epoch 1.229), train_loss = 2.06516339, grad/param norm = 3.0959e-01, time/batch = 0.6340s	
828/33650 (epoch 1.230), train_loss = 2.20939161, grad/param norm = 3.4724e-01, time/batch = 0.6375s	
829/33650 (epoch 1.232), train_loss = 2.03247644, grad/param norm = 3.4431e-01, time/batch = 0.6477s	
830/33650 (epoch 1.233), train_loss = 2.19199308, grad/param norm = 3.1335e-01, time/batch = 0.6435s	
831/33650 (epoch 1.235), train_loss = 2.12349650, grad/param norm = 3.2814e-01, time/batch = 0.6489s	
832/33650 (epoch 1.236), train_loss = 1.98426593, grad/param norm = 2.9647e-01, time/batch = 0.6353s	
833/33650 (epoch 1.238), train_loss = 2.16513406, grad/param norm = 3.2118e-01, time/batch = 0.6437s	
834/33650 (epoch 1.239), train_loss = 1.96777620, grad/param norm = 3.9063e-01, time/batch = 0.6300s	
835/33650 (epoch 1.241), train_loss = 2.01029783, grad/param norm = 3.5966e-01, time/batch = 0.6277s	
836/33650 (epoch 1.242), train_loss = 1.95228757, grad/param norm = 3.5076e-01, time/batch = 0.6306s	
837/33650 (epoch 1.244), train_loss = 2.12408404, grad/param norm = 3.0636e-01, time/batch = 0.6306s	
838/33650 (epoch 1.245), train_loss = 1.93106623, grad/param norm = 2.7260e-01, time/batch = 0.6562s	
839/33650 (epoch 1.247), train_loss = 2.14271845, grad/param norm = 3.0253e-01, time/batch = 0.6702s	
840/33650 (epoch 1.248), train_loss = 2.14294781, grad/param norm = 3.3730e-01, time/batch = 0.6314s	
841/33650 (epoch 1.250), train_loss = 2.10221546, grad/param norm = 3.2078e-01, time/batch = 0.6321s	
842/33650 (epoch 1.251), train_loss = 2.21988478, grad/param norm = 4.4611e-01, time/batch = 0.6294s	
843/33650 (epoch 1.253), train_loss = 1.94333535, grad/param norm = 5.2342e-01, time/batch = 0.6297s	
844/33650 (epoch 1.254), train_loss = 2.11681531, grad/param norm = 4.6168e-01, time/batch = 0.6284s	
845/33650 (epoch 1.256), train_loss = 2.11848979, grad/param norm = 3.3870e-01, time/batch = 0.6280s	
846/33650 (epoch 1.257), train_loss = 2.40003548, grad/param norm = 3.1298e-01, time/batch = 0.6295s	
847/33650 (epoch 1.259), train_loss = 1.72841137, grad/param norm = 3.0442e-01, time/batch = 0.6274s	
848/33650 (epoch 1.260), train_loss = 2.30501048, grad/param norm = 3.6611e-01, time/batch = 0.6257s	
849/33650 (epoch 1.262), train_loss = 2.05888252, grad/param norm = 2.6957e-01, time/batch = 0.6247s	
850/33650 (epoch 1.263), train_loss = 2.11854971, grad/param norm = 3.2904e-01, time/batch = 0.6261s	
851/33650 (epoch 1.264), train_loss = 2.03159243, grad/param norm = 3.2235e-01, time/batch = 0.6289s	
852/33650 (epoch 1.266), train_loss = 1.98701676, grad/param norm = 3.2487e-01, time/batch = 0.6287s	
853/33650 (epoch 1.267), train_loss = 2.11204829, grad/param norm = 4.2715e-01, time/batch = 0.6264s	
854/33650 (epoch 1.269), train_loss = 2.21226039, grad/param norm = 3.5784e-01, time/batch = 0.6646s	
855/33650 (epoch 1.270), train_loss = 2.06114937, grad/param norm = 2.7724e-01, time/batch = 0.6492s	
856/33650 (epoch 1.272), train_loss = 2.04190224, grad/param norm = 2.8513e-01, time/batch = 0.6268s	
857/33650 (epoch 1.273), train_loss = 2.21232616, grad/param norm = 2.6123e-01, time/batch = 0.6269s	
858/33650 (epoch 1.275), train_loss = 2.18441004, grad/param norm = 2.6233e-01, time/batch = 0.6280s	
859/33650 (epoch 1.276), train_loss = 2.13295163, grad/param norm = 3.2292e-01, time/batch = 0.6278s	
860/33650 (epoch 1.278), train_loss = 2.31833798, grad/param norm = 3.5161e-01, time/batch = 0.6285s	
861/33650 (epoch 1.279), train_loss = 1.92606282, grad/param norm = 3.6019e-01, time/batch = 0.6294s	
862/33650 (epoch 1.281), train_loss = 2.16150984, grad/param norm = 3.1062e-01, time/batch = 0.6259s	
863/33650 (epoch 1.282), train_loss = 2.09574942, grad/param norm = 2.7399e-01, time/batch = 0.6254s	
864/33650 (epoch 1.284), train_loss = 2.16026058, grad/param norm = 3.2737e-01, time/batch = 0.6250s	
865/33650 (epoch 1.285), train_loss = 2.04839628, grad/param norm = 4.1372e-01, time/batch = 0.6251s	
866/33650 (epoch 1.287), train_loss = 2.10472894, grad/param norm = 3.1744e-01, time/batch = 0.6258s	
867/33650 (epoch 1.288), train_loss = 2.08512467, grad/param norm = 3.3956e-01, time/batch = 0.6269s	
868/33650 (epoch 1.290), train_loss = 2.02070166, grad/param norm = 3.2853e-01, time/batch = 0.6320s	
869/33650 (epoch 1.291), train_loss = 1.87160361, grad/param norm = 2.8998e-01, time/batch = 0.6268s	
870/33650 (epoch 1.293), train_loss = 2.12335507, grad/param norm = 2.4913e-01, time/batch = 0.6251s	
871/33650 (epoch 1.294), train_loss = 1.88826043, grad/param norm = 2.9248e-01, time/batch = 0.6277s	
872/33650 (epoch 1.296), train_loss = 1.78593528, grad/param norm = 2.7356e-01, time/batch = 0.6270s	
873/33650 (epoch 1.297), train_loss = 2.16132338, grad/param norm = 3.0971e-01, time/batch = 0.6264s	
874/33650 (epoch 1.299), train_loss = 1.87842951, grad/param norm = 3.8115e-01, time/batch = 0.6265s	
875/33650 (epoch 1.300), train_loss = 2.05975085, grad/param norm = 4.0176e-01, time/batch = 0.6289s	
876/33650 (epoch 1.302), train_loss = 1.90861600, grad/param norm = 3.5336e-01, time/batch = 0.6348s	
877/33650 (epoch 1.303), train_loss = 2.08833003, grad/param norm = 3.5321e-01, time/batch = 0.6307s	
878/33650 (epoch 1.305), train_loss = 2.20058656, grad/param norm = 2.6868e-01, time/batch = 0.6332s	
879/33650 (epoch 1.306), train_loss = 1.98941853, grad/param norm = 2.6429e-01, time/batch = 0.6543s	
880/33650 (epoch 1.308), train_loss = 2.00893329, grad/param norm = 3.0459e-01, time/batch = 0.6608s	
881/33650 (epoch 1.309), train_loss = 1.98665005, grad/param norm = 2.8829e-01, time/batch = 0.6281s	
882/33650 (epoch 1.311), train_loss = 2.18921919, grad/param norm = 3.0448e-01, time/batch = 0.6290s	
883/33650 (epoch 1.312), train_loss = 1.95216165, grad/param norm = 3.3121e-01, time/batch = 0.6371s	
884/33650 (epoch 1.314), train_loss = 1.81632997, grad/param norm = 2.9338e-01, time/batch = 0.6252s	
885/33650 (epoch 1.315), train_loss = 2.12440610, grad/param norm = 3.6052e-01, time/batch = 0.6263s	
886/33650 (epoch 1.316), train_loss = 2.09132785, grad/param norm = 3.2741e-01, time/batch = 0.6272s	
887/33650 (epoch 1.318), train_loss = 2.02286307, grad/param norm = 3.3663e-01, time/batch = 0.6272s	
888/33650 (epoch 1.319), train_loss = 1.95785020, grad/param norm = 3.5668e-01, time/batch = 0.6284s	
889/33650 (epoch 1.321), train_loss = 2.00554524, grad/param norm = 2.7850e-01, time/batch = 0.6297s	
890/33650 (epoch 1.322), train_loss = 2.03644002, grad/param norm = 2.9282e-01, time/batch = 0.6305s	
891/33650 (epoch 1.324), train_loss = 2.03145618, grad/param norm = 2.7266e-01, time/batch = 0.6355s	
892/33650 (epoch 1.325), train_loss = 2.10049936, grad/param norm = 2.9277e-01, time/batch = 0.6406s	
893/33650 (epoch 1.327), train_loss = 1.85182455, grad/param norm = 2.9173e-01, time/batch = 0.6305s	
894/33650 (epoch 1.328), train_loss = 2.03625307, grad/param norm = 2.8596e-01, time/batch = 0.6335s	
895/33650 (epoch 1.330), train_loss = 1.91745575, grad/param norm = 3.0348e-01, time/batch = 0.6340s	
896/33650 (epoch 1.331), train_loss = 1.75320697, grad/param norm = 2.8756e-01, time/batch = 0.6466s	
897/33650 (epoch 1.333), train_loss = 2.12912384, grad/param norm = 2.8085e-01, time/batch = 0.6346s	
898/33650 (epoch 1.334), train_loss = 2.00512938, grad/param norm = 3.4323e-01, time/batch = 0.6423s	
899/33650 (epoch 1.336), train_loss = 2.01760237, grad/param norm = 3.0492e-01, time/batch = 0.6464s	
900/33650 (epoch 1.337), train_loss = 1.66317776, grad/param norm = 2.9400e-01, time/batch = 0.6694s	
901/33650 (epoch 1.339), train_loss = 1.98160328, grad/param norm = 2.6594e-01, time/batch = 0.6464s	
902/33650 (epoch 1.340), train_loss = 2.22007624, grad/param norm = 2.6767e-01, time/batch = 0.6344s	
903/33650 (epoch 1.342), train_loss = 1.70196038, grad/param norm = 2.6139e-01, time/batch = 0.6334s	
904/33650 (epoch 1.343), train_loss = 2.11195732, grad/param norm = 3.0488e-01, time/batch = 0.6267s	
905/33650 (epoch 1.345), train_loss = 1.98492317, grad/param norm = 2.6456e-01, time/batch = 0.6286s	
906/33650 (epoch 1.346), train_loss = 1.61537810, grad/param norm = 2.6026e-01, time/batch = 0.6287s	
907/33650 (epoch 1.348), train_loss = 1.98134458, grad/param norm = 2.8702e-01, time/batch = 0.6298s	
908/33650 (epoch 1.349), train_loss = 1.75577436, grad/param norm = 3.3876e-01, time/batch = 0.6245s	
909/33650 (epoch 1.351), train_loss = 2.09712907, grad/param norm = 2.5444e-01, time/batch = 0.6250s	
910/33650 (epoch 1.352), train_loss = 1.91039246, grad/param norm = 2.4539e-01, time/batch = 0.6259s	
911/33650 (epoch 1.354), train_loss = 2.33941730, grad/param norm = 3.5154e-01, time/batch = 0.6283s	
912/33650 (epoch 1.355), train_loss = 2.05774255, grad/param norm = 4.0094e-01, time/batch = 0.6263s	
913/33650 (epoch 1.357), train_loss = 1.82119018, grad/param norm = 4.4812e-01, time/batch = 0.6325s	
914/33650 (epoch 1.358), train_loss = 2.12202400, grad/param norm = 3.3399e-01, time/batch = 0.6332s	
915/33650 (epoch 1.360), train_loss = 2.06858483, grad/param norm = 2.7254e-01, time/batch = 0.6319s	
916/33650 (epoch 1.361), train_loss = 1.85626563, grad/param norm = 2.4709e-01, time/batch = 0.6287s	
917/33650 (epoch 1.363), train_loss = 1.87624216, grad/param norm = 2.4061e-01, time/batch = 0.6264s	
918/33650 (epoch 1.364), train_loss = 1.93755627, grad/param norm = 2.5876e-01, time/batch = 0.6265s	
919/33650 (epoch 1.366), train_loss = 1.90615648, grad/param norm = 3.0289e-01, time/batch = 0.6279s	
920/33650 (epoch 1.367), train_loss = 2.04600499, grad/param norm = 3.0074e-01, time/batch = 0.6602s	
921/33650 (epoch 1.368), train_loss = 1.79736548, grad/param norm = 2.9126e-01, time/batch = 0.6574s	
922/33650 (epoch 1.370), train_loss = 2.03959966, grad/param norm = 3.1925e-01, time/batch = 0.6438s	
923/33650 (epoch 1.371), train_loss = 1.80524083, grad/param norm = 3.2833e-01, time/batch = 0.6448s	
924/33650 (epoch 1.373), train_loss = 1.88677115, grad/param norm = 3.3323e-01, time/batch = 0.6333s	
925/33650 (epoch 1.374), train_loss = 1.83940583, grad/param norm = 2.9961e-01, time/batch = 0.6612s	
926/33650 (epoch 1.376), train_loss = 1.95889184, grad/param norm = 3.2434e-01, time/batch = 0.6634s	
927/33650 (epoch 1.377), train_loss = 2.08764251, grad/param norm = 3.4923e-01, time/batch = 0.6470s	
928/33650 (epoch 1.379), train_loss = 1.90072795, grad/param norm = 3.5973e-01, time/batch = 0.6416s	
929/33650 (epoch 1.380), train_loss = 1.77314150, grad/param norm = 3.0441e-01, time/batch = 0.6329s	
930/33650 (epoch 1.382), train_loss = 1.65653537, grad/param norm = 2.7160e-01, time/batch = 0.6280s	
931/33650 (epoch 1.383), train_loss = 1.83948057, grad/param norm = 2.3250e-01, time/batch = 0.6294s	
932/33650 (epoch 1.385), train_loss = 1.90649434, grad/param norm = 2.4264e-01, time/batch = 0.6283s	
933/33650 (epoch 1.386), train_loss = 1.90216479, grad/param norm = 2.6561e-01, time/batch = 0.6456s	
934/33650 (epoch 1.388), train_loss = 1.75324896, grad/param norm = 2.7318e-01, time/batch = 0.6436s	
935/33650 (epoch 1.389), train_loss = 1.99456563, grad/param norm = 3.3402e-01, time/batch = 0.6511s	
936/33650 (epoch 1.391), train_loss = 1.73030357, grad/param norm = 2.5802e-01, time/batch = 0.6682s	
937/33650 (epoch 1.392), train_loss = 2.11109941, grad/param norm = 2.5332e-01, time/batch = 0.6328s	
938/33650 (epoch 1.394), train_loss = 1.99671506, grad/param norm = 3.5157e-01, time/batch = 0.6288s	
939/33650 (epoch 1.395), train_loss = 1.98155697, grad/param norm = 3.7114e-01, time/batch = 0.6277s	
940/33650 (epoch 1.397), train_loss = 2.20475264, grad/param norm = 3.4060e-01, time/batch = 0.6257s	
941/33650 (epoch 1.398), train_loss = 2.01268093, grad/param norm = 2.9788e-01, time/batch = 0.6354s	
942/33650 (epoch 1.400), train_loss = 2.06903832, grad/param norm = 3.6975e-01, time/batch = 0.6269s	
943/33650 (epoch 1.401), train_loss = 2.07029291, grad/param norm = 3.2739e-01, time/batch = 0.6266s	
944/33650 (epoch 1.403), train_loss = 2.07410469, grad/param norm = 2.6886e-01, time/batch = 0.6257s	
945/33650 (epoch 1.404), train_loss = 1.94256456, grad/param norm = 2.5577e-01, time/batch = 0.6280s	
946/33650 (epoch 1.406), train_loss = 2.07508596, grad/param norm = 2.5736e-01, time/batch = 0.6300s	
947/33650 (epoch 1.407), train_loss = 1.92540194, grad/param norm = 2.5353e-01, time/batch = 0.6283s	
948/33650 (epoch 1.409), train_loss = 1.98831333, grad/param norm = 3.1372e-01, time/batch = 0.6264s	
949/33650 (epoch 1.410), train_loss = 2.03474164, grad/param norm = 3.9885e-01, time/batch = 0.6276s	
950/33650 (epoch 1.412), train_loss = 1.97074667, grad/param norm = 3.2711e-01, time/batch = 0.6255s	
951/33650 (epoch 1.413), train_loss = 1.95263856, grad/param norm = 3.3586e-01, time/batch = 0.6294s	
952/33650 (epoch 1.415), train_loss = 1.98775457, grad/param norm = 4.5945e-01, time/batch = 0.6273s	
953/33650 (epoch 1.416), train_loss = 2.07633409, grad/param norm = 3.4498e-01, time/batch = 0.6302s	
954/33650 (epoch 1.418), train_loss = 2.07689766, grad/param norm = 2.5694e-01, time/batch = 0.6327s	
955/33650 (epoch 1.419), train_loss = 2.04289998, grad/param norm = 2.6725e-01, time/batch = 0.6296s	
956/33650 (epoch 1.421), train_loss = 1.85747717, grad/param norm = 2.9428e-01, time/batch = 0.6638s	
957/33650 (epoch 1.422), train_loss = 2.05486653, grad/param norm = 3.7508e-01, time/batch = 0.6515s	
958/33650 (epoch 1.423), train_loss = 1.87501438, grad/param norm = 3.0756e-01, time/batch = 0.6288s	
959/33650 (epoch 1.425), train_loss = 2.04643094, grad/param norm = 2.9260e-01, time/batch = 0.6289s	
960/33650 (epoch 1.426), train_loss = 2.08113287, grad/param norm = 2.9402e-01, time/batch = 0.6332s	
961/33650 (epoch 1.428), train_loss = 1.89854288, grad/param norm = 3.1193e-01, time/batch = 0.6284s	
962/33650 (epoch 1.429), train_loss = 2.01928896, grad/param norm = 3.2898e-01, time/batch = 0.6275s	
963/33650 (epoch 1.431), train_loss = 2.16695674, grad/param norm = 3.1388e-01, time/batch = 0.6272s	
964/33650 (epoch 1.432), train_loss = 2.18503641, grad/param norm = 3.1276e-01, time/batch = 0.6269s	
965/33650 (epoch 1.434), train_loss = 2.10058716, grad/param norm = 2.6586e-01, time/batch = 0.6269s	
966/33650 (epoch 1.435), train_loss = 2.08731030, grad/param norm = 2.6158e-01, time/batch = 0.6319s	
967/33650 (epoch 1.437), train_loss = 2.06166071, grad/param norm = 2.5554e-01, time/batch = 0.6331s	
968/33650 (epoch 1.438), train_loss = 1.73618278, grad/param norm = 2.8209e-01, time/batch = 0.6325s	
969/33650 (epoch 1.440), train_loss = 1.98466515, grad/param norm = 3.1632e-01, time/batch = 0.6265s	
970/33650 (epoch 1.441), train_loss = 2.16909271, grad/param norm = 2.8821e-01, time/batch = 0.6278s	
971/33650 (epoch 1.443), train_loss = 2.13612735, grad/param norm = 2.4961e-01, time/batch = 0.6460s	
972/33650 (epoch 1.444), train_loss = 1.96917915, grad/param norm = 2.6928e-01, time/batch = 0.6329s	
973/33650 (epoch 1.446), train_loss = 2.08686709, grad/param norm = 2.7828e-01, time/batch = 0.6278s	
974/33650 (epoch 1.447), train_loss = 2.00214523, grad/param norm = 2.7493e-01, time/batch = 0.6341s	
975/33650 (epoch 1.449), train_loss = 2.23381615, grad/param norm = 3.3558e-01, time/batch = 0.6303s	
976/33650 (epoch 1.450), train_loss = 2.33940421, grad/param norm = 2.9543e-01, time/batch = 0.6492s	
977/33650 (epoch 1.452), train_loss = 2.24619651, grad/param norm = 2.9649e-01, time/batch = 0.6677s	
978/33650 (epoch 1.453), train_loss = 2.20263389, grad/param norm = 2.8891e-01, time/batch = 0.6286s	
979/33650 (epoch 1.455), train_loss = 2.09501685, grad/param norm = 2.7215e-01, time/batch = 0.6283s	
980/33650 (epoch 1.456), train_loss = 1.95838806, grad/param norm = 2.6444e-01, time/batch = 0.6283s	
981/33650 (epoch 1.458), train_loss = 1.97586844, grad/param norm = 2.9952e-01, time/batch = 0.6307s	
982/33650 (epoch 1.459), train_loss = 1.85198565, grad/param norm = 2.6327e-01, time/batch = 0.6308s	
983/33650 (epoch 1.461), train_loss = 1.92457316, grad/param norm = 2.7814e-01, time/batch = 0.6339s	
984/33650 (epoch 1.462), train_loss = 2.25602495, grad/param norm = 3.4209e-01, time/batch = 0.6307s	
985/33650 (epoch 1.464), train_loss = 2.02968003, grad/param norm = 3.6784e-01, time/batch = 0.6316s	
986/33650 (epoch 1.465), train_loss = 2.06038371, grad/param norm = 4.2951e-01, time/batch = 0.6272s	
987/33650 (epoch 1.467), train_loss = 2.09141069, grad/param norm = 3.3344e-01, time/batch = 0.6311s	
988/33650 (epoch 1.468), train_loss = 2.00518527, grad/param norm = 3.0103e-01, time/batch = 0.6425s	
989/33650 (epoch 1.470), train_loss = 2.24170990, grad/param norm = 2.7567e-01, time/batch = 0.6296s	
990/33650 (epoch 1.471), train_loss = 2.05050549, grad/param norm = 2.7109e-01, time/batch = 0.6327s	
991/33650 (epoch 1.473), train_loss = 1.76312312, grad/param norm = 2.4734e-01, time/batch = 0.6310s	
992/33650 (epoch 1.474), train_loss = 2.04984213, grad/param norm = 2.9566e-01, time/batch = 0.6315s	
993/33650 (epoch 1.475), train_loss = 2.20826517, grad/param norm = 3.1573e-01, time/batch = 0.6282s	
994/33650 (epoch 1.477), train_loss = 2.23756408, grad/param norm = 2.8704e-01, time/batch = 0.6323s	
995/33650 (epoch 1.478), train_loss = 2.07921101, grad/param norm = 2.4813e-01, time/batch = 0.6285s	
996/33650 (epoch 1.480), train_loss = 2.13124652, grad/param norm = 3.1013e-01, time/batch = 0.6384s	
997/33650 (epoch 1.481), train_loss = 2.08587712, grad/param norm = 2.9348e-01, time/batch = 0.6695s	
998/33650 (epoch 1.483), train_loss = 1.74902963, grad/param norm = 3.5416e-01, time/batch = 0.6495s	
999/33650 (epoch 1.484), train_loss = 2.04527542, grad/param norm = 3.9061e-01, time/batch = 0.6292s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch1.49_2.0192.t7	
1000/33650 (epoch 1.486), train_loss = 2.13403613, grad/param norm = 3.1883e-01, time/batch = 0.6284s	
1001/33650 (epoch 1.487), train_loss = 2.28475306, grad/param norm = 3.0853e-01, time/batch = 0.6353s	
1002/33650 (epoch 1.489), train_loss = 2.14088936, grad/param norm = 2.8176e-01, time/batch = 0.6411s	
1003/33650 (epoch 1.490), train_loss = 1.89843790, grad/param norm = 2.6158e-01, time/batch = 0.6668s	
1004/33650 (epoch 1.492), train_loss = 2.19958753, grad/param norm = 3.0533e-01, time/batch = 0.6379s	
1005/33650 (epoch 1.493), train_loss = 1.86429869, grad/param norm = 2.8780e-01, time/batch = 0.6310s	
1006/33650 (epoch 1.495), train_loss = 1.91541885, grad/param norm = 2.7875e-01, time/batch = 0.6398s	
1007/33650 (epoch 1.496), train_loss = 2.10344494, grad/param norm = 3.3165e-01, time/batch = 0.6423s	
1008/33650 (epoch 1.498), train_loss = 1.88926441, grad/param norm = 3.4778e-01, time/batch = 0.6422s	
1009/33650 (epoch 1.499), train_loss = 2.04130603, grad/param norm = 3.6968e-01, time/batch = 0.6485s	
1010/33650 (epoch 1.501), train_loss = 1.98060847, grad/param norm = 3.0563e-01, time/batch = 0.6317s	
1011/33650 (epoch 1.502), train_loss = 2.04797130, grad/param norm = 2.5165e-01, time/batch = 0.6418s	
1012/33650 (epoch 1.504), train_loss = 2.17867821, grad/param norm = 2.7343e-01, time/batch = 0.6347s	
1013/33650 (epoch 1.505), train_loss = 2.01974547, grad/param norm = 2.7242e-01, time/batch = 0.6411s	
1014/33650 (epoch 1.507), train_loss = 2.04159194, grad/param norm = 3.1347e-01, time/batch = 0.6406s	
1015/33650 (epoch 1.508), train_loss = 1.96143879, grad/param norm = 2.6563e-01, time/batch = 0.6448s	
1016/33650 (epoch 1.510), train_loss = 2.05742571, grad/param norm = 2.2904e-01, time/batch = 0.6569s	
1017/33650 (epoch 1.511), train_loss = 2.21611163, grad/param norm = 2.8375e-01, time/batch = 0.6456s	
1018/33650 (epoch 1.513), train_loss = 2.09050080, grad/param norm = 3.6967e-01, time/batch = 0.6322s	
1019/33650 (epoch 1.514), train_loss = 2.00047221, grad/param norm = 3.7279e-01, time/batch = 0.6316s	
1020/33650 (epoch 1.516), train_loss = 1.97907737, grad/param norm = 2.9394e-01, time/batch = 0.6340s	
1021/33650 (epoch 1.517), train_loss = 1.83533588, grad/param norm = 2.4745e-01, time/batch = 0.6437s	
1022/33650 (epoch 1.519), train_loss = 1.85845876, grad/param norm = 2.8413e-01, time/batch = 0.6404s	
1023/33650 (epoch 1.520), train_loss = 1.77535391, grad/param norm = 3.2657e-01, time/batch = 0.6382s	
1024/33650 (epoch 1.522), train_loss = 2.03178214, grad/param norm = 3.3044e-01, time/batch = 0.6316s	
1025/33650 (epoch 1.523), train_loss = 2.02135306, grad/param norm = 2.5654e-01, time/batch = 0.6255s	
1026/33650 (epoch 1.525), train_loss = 1.67227325, grad/param norm = 2.4312e-01, time/batch = 0.6268s	
1027/33650 (epoch 1.526), train_loss = 2.12640011, grad/param norm = 3.3333e-01, time/batch = 0.6330s	
1028/33650 (epoch 1.527), train_loss = 1.86274625, grad/param norm = 3.4663e-01, time/batch = 0.6342s	
1029/33650 (epoch 1.529), train_loss = 1.92910577, grad/param norm = 2.8431e-01, time/batch = 0.6272s	
1030/33650 (epoch 1.530), train_loss = 1.85388311, grad/param norm = 3.0157e-01, time/batch = 0.6268s	
1031/33650 (epoch 1.532), train_loss = 2.16431183, grad/param norm = 2.5872e-01, time/batch = 0.6371s	
1032/33650 (epoch 1.533), train_loss = 1.72755303, grad/param norm = 2.4071e-01, time/batch = 0.6271s	
1033/33650 (epoch 1.535), train_loss = 2.10984321, grad/param norm = 2.7041e-01, time/batch = 0.6271s	
1034/33650 (epoch 1.536), train_loss = 1.94643790, grad/param norm = 2.5945e-01, time/batch = 0.6307s	
1035/33650 (epoch 1.538), train_loss = 1.98374557, grad/param norm = 2.8084e-01, time/batch = 0.6249s	
1036/33650 (epoch 1.539), train_loss = 1.77890172, grad/param norm = 3.0826e-01, time/batch = 0.6270s	
1037/33650 (epoch 1.541), train_loss = 2.09535873, grad/param norm = 2.4994e-01, time/batch = 0.6272s	
1038/33650 (epoch 1.542), train_loss = 1.98952878, grad/param norm = 3.1021e-01, time/batch = 0.6441s	
1039/33650 (epoch 1.544), train_loss = 2.29649859, grad/param norm = 3.1676e-01, time/batch = 0.6680s	
1040/33650 (epoch 1.545), train_loss = 1.72800989, grad/param norm = 2.8613e-01, time/batch = 0.6369s	
1041/33650 (epoch 1.547), train_loss = 1.93501925, grad/param norm = 3.1620e-01, time/batch = 0.6507s	
1042/33650 (epoch 1.548), train_loss = 2.12152768, grad/param norm = 2.9364e-01, time/batch = 0.6604s	
1043/33650 (epoch 1.550), train_loss = 1.84660399, grad/param norm = 2.9050e-01, time/batch = 0.6522s	
1044/33650 (epoch 1.551), train_loss = 1.87264823, grad/param norm = 3.0110e-01, time/batch = 0.6474s	
1045/33650 (epoch 1.553), train_loss = 1.73446588, grad/param norm = 3.0730e-01, time/batch = 0.6376s	
1046/33650 (epoch 1.554), train_loss = 2.07109027, grad/param norm = 2.9699e-01, time/batch = 0.6300s	
1047/33650 (epoch 1.556), train_loss = 2.08826194, grad/param norm = 3.3416e-01, time/batch = 0.6345s	
1048/33650 (epoch 1.557), train_loss = 2.04266488, grad/param norm = 2.4785e-01, time/batch = 0.6314s	
1049/33650 (epoch 1.559), train_loss = 2.04414277, grad/param norm = 3.3220e-01, time/batch = 0.6236s	
1050/33650 (epoch 1.560), train_loss = 2.09218989, grad/param norm = 3.1512e-01, time/batch = 0.6256s	
1051/33650 (epoch 1.562), train_loss = 2.04474289, grad/param norm = 2.6785e-01, time/batch = 0.6283s	
1052/33650 (epoch 1.563), train_loss = 1.88637434, grad/param norm = 2.6115e-01, time/batch = 0.6281s	
1053/33650 (epoch 1.565), train_loss = 2.03300935, grad/param norm = 2.7277e-01, time/batch = 0.6295s	
1054/33650 (epoch 1.566), train_loss = 2.00158540, grad/param norm = 2.8515e-01, time/batch = 0.6286s	
1055/33650 (epoch 1.568), train_loss = 2.03001260, grad/param norm = 3.2939e-01, time/batch = 0.6333s	
1056/33650 (epoch 1.569), train_loss = 1.87170115, grad/param norm = 3.8653e-01, time/batch = 0.6308s	
1057/33650 (epoch 1.571), train_loss = 2.04586992, grad/param norm = 2.3843e-01, time/batch = 0.6262s	
1058/33650 (epoch 1.572), train_loss = 1.93607641, grad/param norm = 2.1680e-01, time/batch = 0.6260s	
1059/33650 (epoch 1.574), train_loss = 1.94701012, grad/param norm = 2.6869e-01, time/batch = 0.6669s	
1060/33650 (epoch 1.575), train_loss = 1.90693019, grad/param norm = 2.6494e-01, time/batch = 0.6455s	
1061/33650 (epoch 1.577), train_loss = 2.08170982, grad/param norm = 3.0801e-01, time/batch = 0.6305s	
1062/33650 (epoch 1.578), train_loss = 1.89454991, grad/param norm = 2.5823e-01, time/batch = 0.6317s	
1063/33650 (epoch 1.579), train_loss = 1.90081605, grad/param norm = 2.7054e-01, time/batch = 0.6253s	
1064/33650 (epoch 1.581), train_loss = 1.92836103, grad/param norm = 3.1944e-01, time/batch = 0.6260s	
1065/33650 (epoch 1.582), train_loss = 2.05255855, grad/param norm = 2.6452e-01, time/batch = 0.6267s	
1066/33650 (epoch 1.584), train_loss = 1.87508765, grad/param norm = 3.0411e-01, time/batch = 0.6272s	
1067/33650 (epoch 1.585), train_loss = 1.95148728, grad/param norm = 3.2381e-01, time/batch = 0.6277s	
1068/33650 (epoch 1.587), train_loss = 1.96520371, grad/param norm = 3.2915e-01, time/batch = 0.6284s	
1069/33650 (epoch 1.588), train_loss = 1.97334330, grad/param norm = 3.0814e-01, time/batch = 0.6349s	
1070/33650 (epoch 1.590), train_loss = 2.00997088, grad/param norm = 3.1913e-01, time/batch = 0.6293s	
1071/33650 (epoch 1.591), train_loss = 2.01405104, grad/param norm = 2.6834e-01, time/batch = 0.6325s	
1072/33650 (epoch 1.593), train_loss = 1.82783869, grad/param norm = 2.6260e-01, time/batch = 0.6371s	
1073/33650 (epoch 1.594), train_loss = 1.58322872, grad/param norm = 2.8485e-01, time/batch = 0.6281s	
1074/33650 (epoch 1.596), train_loss = 1.97502195, grad/param norm = 2.5792e-01, time/batch = 0.6275s	
1075/33650 (epoch 1.597), train_loss = 1.57006210, grad/param norm = 2.6303e-01, time/batch = 0.6276s	
1076/33650 (epoch 1.599), train_loss = 1.81545252, grad/param norm = 2.8886e-01, time/batch = 0.6275s	
1077/33650 (epoch 1.600), train_loss = 1.80373545, grad/param norm = 2.5674e-01, time/batch = 0.6332s	
1078/33650 (epoch 1.602), train_loss = 2.09624108, grad/param norm = 2.6204e-01, time/batch = 0.6263s	
1079/33650 (epoch 1.603), train_loss = 1.81304487, grad/param norm = 2.7104e-01, time/batch = 0.6495s	
1080/33650 (epoch 1.605), train_loss = 1.90222308, grad/param norm = 2.6498e-01, time/batch = 0.6652s	
1081/33650 (epoch 1.606), train_loss = 2.12082446, grad/param norm = 2.7142e-01, time/batch = 0.6300s	
1082/33650 (epoch 1.608), train_loss = 2.04391924, grad/param norm = 2.6672e-01, time/batch = 0.6292s	
1083/33650 (epoch 1.609), train_loss = 1.97921334, grad/param norm = 2.4830e-01, time/batch = 0.6293s	
1084/33650 (epoch 1.611), train_loss = 1.84187066, grad/param norm = 2.6946e-01, time/batch = 0.6288s	
1085/33650 (epoch 1.612), train_loss = 1.95176819, grad/param norm = 2.4332e-01, time/batch = 0.6312s	
1086/33650 (epoch 1.614), train_loss = 2.12024739, grad/param norm = 3.1960e-01, time/batch = 0.6289s	
1087/33650 (epoch 1.615), train_loss = 1.91890509, grad/param norm = 2.9994e-01, time/batch = 0.6290s	
1088/33650 (epoch 1.617), train_loss = 1.77626860, grad/param norm = 2.3426e-01, time/batch = 0.6284s	
1089/33650 (epoch 1.618), train_loss = 1.90880713, grad/param norm = 2.9179e-01, time/batch = 0.6312s	
1090/33650 (epoch 1.620), train_loss = 2.06588758, grad/param norm = 3.3924e-01, time/batch = 0.6269s	
1091/33650 (epoch 1.621), train_loss = 1.79311577, grad/param norm = 3.0697e-01, time/batch = 0.6301s	
1092/33650 (epoch 1.623), train_loss = 1.97890365, grad/param norm = 2.8219e-01, time/batch = 0.6290s	
1093/33650 (epoch 1.624), train_loss = 1.74397714, grad/param norm = 2.8813e-01, time/batch = 0.6322s	
1094/33650 (epoch 1.626), train_loss = 1.62395490, grad/param norm = 3.1492e-01, time/batch = 0.6305s	
1095/33650 (epoch 1.627), train_loss = 1.79066737, grad/param norm = 2.7480e-01, time/batch = 0.6306s	
1096/33650 (epoch 1.629), train_loss = 1.84981562, grad/param norm = 2.8045e-01, time/batch = 0.6320s	
1097/33650 (epoch 1.630), train_loss = 1.98132433, grad/param norm = 3.0919e-01, time/batch = 0.6270s	
1098/33650 (epoch 1.632), train_loss = 2.13717417, grad/param norm = 2.8293e-01, time/batch = 0.6263s	
1099/33650 (epoch 1.633), train_loss = 1.95330579, grad/param norm = 2.3786e-01, time/batch = 0.6312s	
1100/33650 (epoch 1.634), train_loss = 1.69959182, grad/param norm = 2.9972e-01, time/batch = 0.6683s	
1101/33650 (epoch 1.636), train_loss = 1.59136079, grad/param norm = 2.5215e-01, time/batch = 0.6582s	
1102/33650 (epoch 1.637), train_loss = 2.04128628, grad/param norm = 2.5758e-01, time/batch = 0.6534s	
1103/33650 (epoch 1.639), train_loss = 1.93673347, grad/param norm = 2.2634e-01, time/batch = 0.6423s	
1104/33650 (epoch 1.640), train_loss = 1.86295622, grad/param norm = 2.5220e-01, time/batch = 0.6289s	
1105/33650 (epoch 1.642), train_loss = 2.22119449, grad/param norm = 3.3587e-01, time/batch = 0.6598s	
1106/33650 (epoch 1.643), train_loss = 1.90081438, grad/param norm = 3.4910e-01, time/batch = 0.6384s	
1107/33650 (epoch 1.645), train_loss = 1.87101070, grad/param norm = 3.0293e-01, time/batch = 0.6265s	
1108/33650 (epoch 1.646), train_loss = 1.74106897, grad/param norm = 2.7351e-01, time/batch = 0.6313s	
1109/33650 (epoch 1.648), train_loss = 1.80622741, grad/param norm = 2.5532e-01, time/batch = 0.6326s	
1110/33650 (epoch 1.649), train_loss = 1.85755995, grad/param norm = 3.0296e-01, time/batch = 0.6321s	
1111/33650 (epoch 1.651), train_loss = 1.99852235, grad/param norm = 2.6188e-01, time/batch = 0.6309s	
1112/33650 (epoch 1.652), train_loss = 1.48260207, grad/param norm = 2.4827e-01, time/batch = 0.6312s	
1113/33650 (epoch 1.654), train_loss = 1.89921973, grad/param norm = 2.3603e-01, time/batch = 0.6301s	
1114/33650 (epoch 1.655), train_loss = 1.67515890, grad/param norm = 2.3661e-01, time/batch = 0.6276s	
1115/33650 (epoch 1.657), train_loss = 1.79266183, grad/param norm = 2.4537e-01, time/batch = 0.6278s	
1116/33650 (epoch 1.658), train_loss = 1.69019556, grad/param norm = 2.4783e-01, time/batch = 0.6343s	
1117/33650 (epoch 1.660), train_loss = 1.63131216, grad/param norm = 2.5511e-01, time/batch = 0.6313s	
1118/33650 (epoch 1.661), train_loss = 1.85796164, grad/param norm = 2.6313e-01, time/batch = 0.6266s	
1119/33650 (epoch 1.663), train_loss = 1.69659263, grad/param norm = 2.8903e-01, time/batch = 0.6256s	
1120/33650 (epoch 1.664), train_loss = 1.69137716, grad/param norm = 2.9322e-01, time/batch = 0.6584s	
1121/33650 (epoch 1.666), train_loss = 1.74123719, grad/param norm = 2.5370e-01, time/batch = 0.6563s	
1122/33650 (epoch 1.667), train_loss = 1.79512081, grad/param norm = 2.5613e-01, time/batch = 0.6268s	
1123/33650 (epoch 1.669), train_loss = 1.68082492, grad/param norm = 2.1165e-01, time/batch = 0.6285s	
1124/33650 (epoch 1.670), train_loss = 1.73949354, grad/param norm = 2.4814e-01, time/batch = 0.6338s	
1125/33650 (epoch 1.672), train_loss = 1.77972569, grad/param norm = 2.3196e-01, time/batch = 0.6256s	
1126/33650 (epoch 1.673), train_loss = 1.65152905, grad/param norm = 2.7549e-01, time/batch = 0.6277s	
1127/33650 (epoch 1.675), train_loss = 1.68736882, grad/param norm = 2.5191e-01, time/batch = 0.6260s	
1128/33650 (epoch 1.676), train_loss = 1.89519305, grad/param norm = 2.5323e-01, time/batch = 0.6295s	
1129/33650 (epoch 1.678), train_loss = 1.70656555, grad/param norm = 2.2624e-01, time/batch = 0.6272s	
1130/33650 (epoch 1.679), train_loss = 1.76721531, grad/param norm = 2.3808e-01, time/batch = 0.6300s	
1131/33650 (epoch 1.681), train_loss = 1.74745771, grad/param norm = 2.7506e-01, time/batch = 0.6323s	
1132/33650 (epoch 1.682), train_loss = 1.88407202, grad/param norm = 2.6372e-01, time/batch = 0.6293s	
1133/33650 (epoch 1.684), train_loss = 1.67883362, grad/param norm = 2.6567e-01, time/batch = 0.6298s	
1134/33650 (epoch 1.685), train_loss = 1.94774692, grad/param norm = 2.7071e-01, time/batch = 0.6277s	
1135/33650 (epoch 1.686), train_loss = 1.75470224, grad/param norm = 2.4245e-01, time/batch = 0.6296s	
1136/33650 (epoch 1.688), train_loss = 1.97178896, grad/param norm = 2.5448e-01, time/batch = 0.6260s	
1137/33650 (epoch 1.689), train_loss = 1.82864777, grad/param norm = 2.5676e-01, time/batch = 0.6263s	
1138/33650 (epoch 1.691), train_loss = 1.88065759, grad/param norm = 2.5890e-01, time/batch = 0.6307s	
1139/33650 (epoch 1.692), train_loss = 1.98918566, grad/param norm = 2.6515e-01, time/batch = 0.6287s	
1140/33650 (epoch 1.694), train_loss = 1.94295321, grad/param norm = 2.8029e-01, time/batch = 0.6387s	
1141/33650 (epoch 1.695), train_loss = 1.57597335, grad/param norm = 2.8080e-01, time/batch = 0.6338s	
1142/33650 (epoch 1.697), train_loss = 1.81308682, grad/param norm = 2.5669e-01, time/batch = 0.6306s	
1143/33650 (epoch 1.698), train_loss = 1.89453660, grad/param norm = 2.3723e-01, time/batch = 0.6272s	
1144/33650 (epoch 1.700), train_loss = 1.89048759, grad/param norm = 2.7132e-01, time/batch = 0.6267s	
1145/33650 (epoch 1.701), train_loss = 2.04391583, grad/param norm = 2.6645e-01, time/batch = 0.6513s	
1146/33650 (epoch 1.703), train_loss = 1.80780893, grad/param norm = 2.8927e-01, time/batch = 0.6634s	
1147/33650 (epoch 1.704), train_loss = 1.72601029, grad/param norm = 3.3929e-01, time/batch = 0.6290s	
1148/33650 (epoch 1.706), train_loss = 1.79734504, grad/param norm = 2.6538e-01, time/batch = 0.6262s	
1149/33650 (epoch 1.707), train_loss = 1.91961080, grad/param norm = 2.3244e-01, time/batch = 0.6271s	
1150/33650 (epoch 1.709), train_loss = 1.85406852, grad/param norm = 3.0683e-01, time/batch = 0.6298s	
1151/33650 (epoch 1.710), train_loss = 2.00198344, grad/param norm = 2.4914e-01, time/batch = 0.6297s	
1152/33650 (epoch 1.712), train_loss = 1.78139457, grad/param norm = 2.5865e-01, time/batch = 0.6276s	
1153/33650 (epoch 1.713), train_loss = 1.90324069, grad/param norm = 2.7900e-01, time/batch = 0.6290s	
1154/33650 (epoch 1.715), train_loss = 1.96619509, grad/param norm = 3.0545e-01, time/batch = 0.6316s	
1155/33650 (epoch 1.716), train_loss = 1.81849690, grad/param norm = 2.8514e-01, time/batch = 0.6353s	
1156/33650 (epoch 1.718), train_loss = 2.01209378, grad/param norm = 2.5663e-01, time/batch = 0.6314s	
1157/33650 (epoch 1.719), train_loss = 2.02406938, grad/param norm = 2.9213e-01, time/batch = 0.6257s	
1158/33650 (epoch 1.721), train_loss = 1.99628827, grad/param norm = 2.6098e-01, time/batch = 0.6280s	
1159/33650 (epoch 1.722), train_loss = 2.09610280, grad/param norm = 2.5656e-01, time/batch = 0.6276s	
1160/33650 (epoch 1.724), train_loss = 1.93459661, grad/param norm = 2.5540e-01, time/batch = 0.6270s	
1161/33650 (epoch 1.725), train_loss = 1.99988575, grad/param norm = 2.3844e-01, time/batch = 0.6304s	
1162/33650 (epoch 1.727), train_loss = 1.80948033, grad/param norm = 3.0202e-01, time/batch = 0.6296s	
1163/33650 (epoch 1.728), train_loss = 1.77652071, grad/param norm = 2.7700e-01, time/batch = 0.6267s	
1164/33650 (epoch 1.730), train_loss = 1.85004802, grad/param norm = 3.1737e-01, time/batch = 0.6274s	
1165/33650 (epoch 1.731), train_loss = 2.08024139, grad/param norm = 3.9690e-01, time/batch = 0.6352s	
1166/33650 (epoch 1.733), train_loss = 1.78972623, grad/param norm = 2.9568e-01, time/batch = 0.6673s	
1167/33650 (epoch 1.734), train_loss = 2.02425358, grad/param norm = 2.9313e-01, time/batch = 0.6438s	
1168/33650 (epoch 1.736), train_loss = 1.90359415, grad/param norm = 2.6840e-01, time/batch = 0.6269s	
1169/33650 (epoch 1.737), train_loss = 1.91089475, grad/param norm = 2.5302e-01, time/batch = 0.6267s	
1170/33650 (epoch 1.738), train_loss = 1.70761490, grad/param norm = 2.7733e-01, time/batch = 0.6288s	
1171/33650 (epoch 1.740), train_loss = 1.86935057, grad/param norm = 2.6418e-01, time/batch = 0.6295s	
1172/33650 (epoch 1.741), train_loss = 1.86184155, grad/param norm = 2.5589e-01, time/batch = 0.6287s	
1173/33650 (epoch 1.743), train_loss = 1.85639610, grad/param norm = 2.5942e-01, time/batch = 0.6282s	
1174/33650 (epoch 1.744), train_loss = 1.73977388, grad/param norm = 2.4286e-01, time/batch = 0.6282s	
1175/33650 (epoch 1.746), train_loss = 1.81259975, grad/param norm = 2.6121e-01, time/batch = 0.6281s	
1176/33650 (epoch 1.747), train_loss = 1.97211062, grad/param norm = 2.5859e-01, time/batch = 0.6285s	
1177/33650 (epoch 1.749), train_loss = 1.51255861, grad/param norm = 2.3605e-01, time/batch = 0.6329s	
1178/33650 (epoch 1.750), train_loss = 1.94001308, grad/param norm = 3.0395e-01, time/batch = 0.6334s	
1179/33650 (epoch 1.752), train_loss = 1.98796309, grad/param norm = 3.1528e-01, time/batch = 0.6306s	
1180/33650 (epoch 1.753), train_loss = 2.09068252, grad/param norm = 2.6954e-01, time/batch = 0.6305s	
1181/33650 (epoch 1.755), train_loss = 1.72246304, grad/param norm = 2.8922e-01, time/batch = 0.6462s	
1182/33650 (epoch 1.756), train_loss = 1.86645451, grad/param norm = 2.6995e-01, time/batch = 0.6679s	
1183/33650 (epoch 1.758), train_loss = 2.09947083, grad/param norm = 2.6162e-01, time/batch = 0.6315s	
1184/33650 (epoch 1.759), train_loss = 2.11539021, grad/param norm = 2.7486e-01, time/batch = 0.6287s	
1185/33650 (epoch 1.761), train_loss = 1.96805198, grad/param norm = 2.5035e-01, time/batch = 0.6274s	
1186/33650 (epoch 1.762), train_loss = 1.89461375, grad/param norm = 2.4081e-01, time/batch = 0.6276s	
1187/33650 (epoch 1.764), train_loss = 2.06359778, grad/param norm = 2.8772e-01, time/batch = 0.6267s	
1188/33650 (epoch 1.765), train_loss = 1.81994128, grad/param norm = 2.2353e-01, time/batch = 0.6270s	
1189/33650 (epoch 1.767), train_loss = 1.77128272, grad/param norm = 2.3494e-01, time/batch = 0.6274s	
1190/33650 (epoch 1.768), train_loss = 1.67376673, grad/param norm = 2.3855e-01, time/batch = 0.6302s	
1191/33650 (epoch 1.770), train_loss = 1.85941167, grad/param norm = 2.4497e-01, time/batch = 0.6319s	
1192/33650 (epoch 1.771), train_loss = 1.90272742, grad/param norm = 2.7779e-01, time/batch = 0.6290s	
1193/33650 (epoch 1.773), train_loss = 2.02577915, grad/param norm = 2.7138e-01, time/batch = 0.6332s	
1194/33650 (epoch 1.774), train_loss = 1.85320686, grad/param norm = 2.4120e-01, time/batch = 0.6341s	
1195/33650 (epoch 1.776), train_loss = 1.99112395, grad/param norm = 2.5884e-01, time/batch = 0.6379s	
1196/33650 (epoch 1.777), train_loss = 1.76323538, grad/param norm = 2.4801e-01, time/batch = 0.6400s	
1197/33650 (epoch 1.779), train_loss = 1.84475422, grad/param norm = 2.5514e-01, time/batch = 0.6467s	
1198/33650 (epoch 1.780), train_loss = 1.66369181, grad/param norm = 2.6366e-01, time/batch = 0.6566s	
1199/33650 (epoch 1.782), train_loss = 1.83938956, grad/param norm = 2.6321e-01, time/batch = 0.6478s	
1200/33650 (epoch 1.783), train_loss = 1.68646095, grad/param norm = 2.2134e-01, time/batch = 0.6515s	
1201/33650 (epoch 1.785), train_loss = 2.11496052, grad/param norm = 2.9896e-01, time/batch = 0.6555s	
1202/33650 (epoch 1.786), train_loss = 1.73401990, grad/param norm = 2.9776e-01, time/batch = 0.6730s	
1203/33650 (epoch 1.788), train_loss = 1.81167290, grad/param norm = 3.1701e-01, time/batch = 0.6423s	
1204/33650 (epoch 1.789), train_loss = 1.86516011, grad/param norm = 2.5015e-01, time/batch = 0.6291s	
1205/33650 (epoch 1.790), train_loss = 1.92168776, grad/param norm = 2.6021e-01, time/batch = 0.6395s	
1206/33650 (epoch 1.792), train_loss = 1.94461985, grad/param norm = 3.0371e-01, time/batch = 0.6322s	
1207/33650 (epoch 1.793), train_loss = 1.89235337, grad/param norm = 3.2656e-01, time/batch = 0.6273s	
1208/33650 (epoch 1.795), train_loss = 2.00901665, grad/param norm = 2.8129e-01, time/batch = 0.6271s	
1209/33650 (epoch 1.796), train_loss = 1.76225660, grad/param norm = 2.2704e-01, time/batch = 0.6270s	
1210/33650 (epoch 1.798), train_loss = 1.76094446, grad/param norm = 2.3476e-01, time/batch = 0.6272s	
1211/33650 (epoch 1.799), train_loss = 1.87216058, grad/param norm = 2.2638e-01, time/batch = 0.6319s	
1212/33650 (epoch 1.801), train_loss = 1.90878169, grad/param norm = 2.2861e-01, time/batch = 0.6332s	
1213/33650 (epoch 1.802), train_loss = 2.01656692, grad/param norm = 2.3439e-01, time/batch = 0.6298s	
1214/33650 (epoch 1.804), train_loss = 1.89702896, grad/param norm = 2.7605e-01, time/batch = 0.6319s	
1215/33650 (epoch 1.805), train_loss = 1.80662991, grad/param norm = 2.7948e-01, time/batch = 0.6263s	
1216/33650 (epoch 1.807), train_loss = 2.21026251, grad/param norm = 2.9875e-01, time/batch = 0.6279s	
1217/33650 (epoch 1.808), train_loss = 2.03021282, grad/param norm = 2.3670e-01, time/batch = 0.6305s	
1218/33650 (epoch 1.810), train_loss = 1.90666829, grad/param norm = 2.5006e-01, time/batch = 0.6302s	
1219/33650 (epoch 1.811), train_loss = 1.94896777, grad/param norm = 2.6199e-01, time/batch = 0.6340s	
1220/33650 (epoch 1.813), train_loss = 2.01005188, grad/param norm = 3.5784e-01, time/batch = 0.6360s	
1221/33650 (epoch 1.814), train_loss = 2.01690344, grad/param norm = 3.4218e-01, time/batch = 0.6333s	
1222/33650 (epoch 1.816), train_loss = 1.83470209, grad/param norm = 2.5239e-01, time/batch = 0.6579s	
1223/33650 (epoch 1.817), train_loss = 2.07661235, grad/param norm = 2.8004e-01, time/batch = 0.6585s	
1224/33650 (epoch 1.819), train_loss = 2.00538949, grad/param norm = 2.7026e-01, time/batch = 0.6315s	
1225/33650 (epoch 1.820), train_loss = 1.98704284, grad/param norm = 2.6533e-01, time/batch = 0.6404s	
1226/33650 (epoch 1.822), train_loss = 2.08362589, grad/param norm = 3.0460e-01, time/batch = 0.6310s	
1227/33650 (epoch 1.823), train_loss = 1.76690401, grad/param norm = 2.7472e-01, time/batch = 0.6316s	
1228/33650 (epoch 1.825), train_loss = 1.85786198, grad/param norm = 2.8282e-01, time/batch = 0.6297s	
1229/33650 (epoch 1.826), train_loss = 1.96145178, grad/param norm = 2.5914e-01, time/batch = 0.6331s	
1230/33650 (epoch 1.828), train_loss = 2.24503859, grad/param norm = 2.6650e-01, time/batch = 0.6271s	
1231/33650 (epoch 1.829), train_loss = 1.79743249, grad/param norm = 2.9381e-01, time/batch = 0.6336s	
1232/33650 (epoch 1.831), train_loss = 2.05845393, grad/param norm = 2.5066e-01, time/batch = 0.6309s	
1233/33650 (epoch 1.832), train_loss = 1.96931988, grad/param norm = 2.5399e-01, time/batch = 0.6340s	
1234/33650 (epoch 1.834), train_loss = 1.95779072, grad/param norm = 2.5227e-01, time/batch = 0.6353s	
1235/33650 (epoch 1.835), train_loss = 2.24549670, grad/param norm = 2.7560e-01, time/batch = 0.6335s	
1236/33650 (epoch 1.837), train_loss = 1.89826430, grad/param norm = 2.4160e-01, time/batch = 0.6362s	
1237/33650 (epoch 1.838), train_loss = 1.88428186, grad/param norm = 2.3252e-01, time/batch = 0.6351s	
1238/33650 (epoch 1.840), train_loss = 2.00811907, grad/param norm = 2.3244e-01, time/batch = 0.6692s	
1239/33650 (epoch 1.841), train_loss = 1.79575001, grad/param norm = 2.3488e-01, time/batch = 0.6493s	
1240/33650 (epoch 1.842), train_loss = 1.75472653, grad/param norm = 2.7936e-01, time/batch = 0.6306s	
1241/33650 (epoch 1.844), train_loss = 2.09200227, grad/param norm = 2.9780e-01, time/batch = 0.6448s	
1242/33650 (epoch 1.845), train_loss = 1.74938860, grad/param norm = 2.4313e-01, time/batch = 0.6321s	
1243/33650 (epoch 1.847), train_loss = 1.68100952, grad/param norm = 2.0851e-01, time/batch = 0.6329s	
1244/33650 (epoch 1.848), train_loss = 1.85630869, grad/param norm = 2.6045e-01, time/batch = 0.6359s	
1245/33650 (epoch 1.850), train_loss = 1.91072416, grad/param norm = 2.5743e-01, time/batch = 0.6337s	
1246/33650 (epoch 1.851), train_loss = 1.73563301, grad/param norm = 2.2102e-01, time/batch = 0.6354s	
1247/33650 (epoch 1.853), train_loss = 1.93535524, grad/param norm = 2.5995e-01, time/batch = 0.6266s	
1248/33650 (epoch 1.854), train_loss = 2.06445326, grad/param norm = 3.4242e-01, time/batch = 0.6268s	
1249/33650 (epoch 1.856), train_loss = 1.62034689, grad/param norm = 3.0697e-01, time/batch = 0.6290s	
1250/33650 (epoch 1.857), train_loss = 1.75591266, grad/param norm = 2.2404e-01, time/batch = 0.6264s	
1251/33650 (epoch 1.859), train_loss = 1.76122102, grad/param norm = 2.2765e-01, time/batch = 0.6280s	
1252/33650 (epoch 1.860), train_loss = 1.60132716, grad/param norm = 2.2743e-01, time/batch = 0.6282s	
1253/33650 (epoch 1.862), train_loss = 1.69268593, grad/param norm = 2.5136e-01, time/batch = 0.6275s	
1254/33650 (epoch 1.863), train_loss = 2.00290443, grad/param norm = 3.3771e-01, time/batch = 0.6265s	
1255/33650 (epoch 1.865), train_loss = 1.74155550, grad/param norm = 2.8750e-01, time/batch = 0.6334s	
1256/33650 (epoch 1.866), train_loss = 1.83176242, grad/param norm = 2.7223e-01, time/batch = 0.6324s	
1257/33650 (epoch 1.868), train_loss = 1.75398669, grad/param norm = 2.5808e-01, time/batch = 0.6285s	
1258/33650 (epoch 1.869), train_loss = 1.96028834, grad/param norm = 2.4055e-01, time/batch = 0.6560s	
1259/33650 (epoch 1.871), train_loss = 1.75483624, grad/param norm = 2.3085e-01, time/batch = 0.6634s	
1260/33650 (epoch 1.872), train_loss = 1.81047409, grad/param norm = 2.7489e-01, time/batch = 0.6311s	
1261/33650 (epoch 1.874), train_loss = 1.91784139, grad/param norm = 2.6594e-01, time/batch = 0.6304s	
1262/33650 (epoch 1.875), train_loss = 1.69469211, grad/param norm = 2.1273e-01, time/batch = 0.6279s	
1263/33650 (epoch 1.877), train_loss = 1.99939803, grad/param norm = 2.9904e-01, time/batch = 0.6351s	
1264/33650 (epoch 1.878), train_loss = 1.57403030, grad/param norm = 2.7309e-01, time/batch = 0.6338s	
1265/33650 (epoch 1.880), train_loss = 1.84668351, grad/param norm = 3.2218e-01, time/batch = 0.6298s	
1266/33650 (epoch 1.881), train_loss = 1.78695988, grad/param norm = 2.6974e-01, time/batch = 0.6337s	
1267/33650 (epoch 1.883), train_loss = 1.87251991, grad/param norm = 2.4608e-01, time/batch = 0.6338s	
1268/33650 (epoch 1.884), train_loss = 1.98654244, grad/param norm = 2.5685e-01, time/batch = 0.6300s	
1269/33650 (epoch 1.886), train_loss = 1.88457626, grad/param norm = 2.6872e-01, time/batch = 0.6285s	
1270/33650 (epoch 1.887), train_loss = 1.75356382, grad/param norm = 2.7585e-01, time/batch = 0.6282s	
1271/33650 (epoch 1.889), train_loss = 2.01458425, grad/param norm = 2.8422e-01, time/batch = 0.6341s	
1272/33650 (epoch 1.890), train_loss = 1.89059223, grad/param norm = 2.5318e-01, time/batch = 0.6351s	
1273/33650 (epoch 1.892), train_loss = 1.85904448, grad/param norm = 2.5586e-01, time/batch = 0.6299s	
1274/33650 (epoch 1.893), train_loss = 1.88464989, grad/param norm = 2.6278e-01, time/batch = 0.6277s	
1275/33650 (epoch 1.895), train_loss = 1.89608166, grad/param norm = 2.5525e-01, time/batch = 0.6274s	
1276/33650 (epoch 1.896), train_loss = 1.80060112, grad/param norm = 2.8197e-01, time/batch = 0.6279s	
1277/33650 (epoch 1.897), train_loss = 1.81122129, grad/param norm = 2.7192e-01, time/batch = 0.6275s	
1278/33650 (epoch 1.899), train_loss = 1.73941400, grad/param norm = 3.1830e-01, time/batch = 0.6377s	
1279/33650 (epoch 1.900), train_loss = 1.52435708, grad/param norm = 2.4456e-01, time/batch = 0.6670s	
1280/33650 (epoch 1.902), train_loss = 1.75926174, grad/param norm = 2.1013e-01, time/batch = 0.6410s	
1281/33650 (epoch 1.903), train_loss = 1.81915231, grad/param norm = 2.6280e-01, time/batch = 0.6288s	
1282/33650 (epoch 1.905), train_loss = 2.11258279, grad/param norm = 2.7845e-01, time/batch = 0.6284s	
1283/33650 (epoch 1.906), train_loss = 1.80861253, grad/param norm = 2.6600e-01, time/batch = 0.6292s	
1284/33650 (epoch 1.908), train_loss = 1.68494154, grad/param norm = 2.2492e-01, time/batch = 0.6281s	
1285/33650 (epoch 1.909), train_loss = 1.74792637, grad/param norm = 2.0600e-01, time/batch = 0.6278s	
1286/33650 (epoch 1.911), train_loss = 1.78467246, grad/param norm = 2.4833e-01, time/batch = 0.6283s	
1287/33650 (epoch 1.912), train_loss = 1.70239264, grad/param norm = 2.2155e-01, time/batch = 0.6339s	
1288/33650 (epoch 1.914), train_loss = 1.78051967, grad/param norm = 2.3853e-01, time/batch = 0.6346s	
1289/33650 (epoch 1.915), train_loss = 1.98566016, grad/param norm = 2.4494e-01, time/batch = 0.6467s	
1290/33650 (epoch 1.917), train_loss = 1.75230132, grad/param norm = 2.7586e-01, time/batch = 0.6318s	
1291/33650 (epoch 1.918), train_loss = 1.56410352, grad/param norm = 2.4902e-01, time/batch = 0.6552s	
1292/33650 (epoch 1.920), train_loss = 1.80398544, grad/param norm = 2.5174e-01, time/batch = 0.6458s	
1293/33650 (epoch 1.921), train_loss = 1.69455899, grad/param norm = 2.5035e-01, time/batch = 0.6332s	
1294/33650 (epoch 1.923), train_loss = 1.67086946, grad/param norm = 2.4639e-01, time/batch = 0.6543s	
1295/33650 (epoch 1.924), train_loss = 1.85341046, grad/param norm = 2.2354e-01, time/batch = 0.6620s	
1296/33650 (epoch 1.926), train_loss = 2.01196408, grad/param norm = 2.5630e-01, time/batch = 0.6337s	
1297/33650 (epoch 1.927), train_loss = 1.83096484, grad/param norm = 2.4429e-01, time/batch = 0.6329s	
1298/33650 (epoch 1.929), train_loss = 1.70202750, grad/param norm = 2.2583e-01, time/batch = 0.6346s	
1299/33650 (epoch 1.930), train_loss = 1.71462462, grad/param norm = 2.5620e-01, time/batch = 0.6309s	
1300/33650 (epoch 1.932), train_loss = 1.76069230, grad/param norm = 2.2926e-01, time/batch = 0.6331s	
1301/33650 (epoch 1.933), train_loss = 1.67698155, grad/param norm = 2.6227e-01, time/batch = 0.6338s	
1302/33650 (epoch 1.935), train_loss = 1.75549174, grad/param norm = 2.5815e-01, time/batch = 0.6318s	
1303/33650 (epoch 1.936), train_loss = 1.68267326, grad/param norm = 2.5013e-01, time/batch = 0.6385s	
1304/33650 (epoch 1.938), train_loss = 1.60549357, grad/param norm = 2.8073e-01, time/batch = 0.6510s	
1305/33650 (epoch 1.939), train_loss = 1.81600375, grad/param norm = 2.8097e-01, time/batch = 0.6363s	
1306/33650 (epoch 1.941), train_loss = 1.85672670, grad/param norm = 2.4268e-01, time/batch = 0.6308s	
1307/33650 (epoch 1.942), train_loss = 1.90127698, grad/param norm = 2.4769e-01, time/batch = 0.6342s	
1308/33650 (epoch 1.944), train_loss = 1.85521113, grad/param norm = 2.5049e-01, time/batch = 0.6294s	
1309/33650 (epoch 1.945), train_loss = 1.83602371, grad/param norm = 2.5750e-01, time/batch = 0.6296s	
1310/33650 (epoch 1.947), train_loss = 2.02509949, grad/param norm = 2.7229e-01, time/batch = 0.6377s	
1311/33650 (epoch 1.948), train_loss = 1.93199098, grad/param norm = 2.4510e-01, time/batch = 0.6396s	
1312/33650 (epoch 1.949), train_loss = 1.68339003, grad/param norm = 2.5224e-01, time/batch = 0.6308s	
1313/33650 (epoch 1.951), train_loss = 1.83914577, grad/param norm = 2.4406e-01, time/batch = 0.6310s	
1314/33650 (epoch 1.952), train_loss = 1.95206639, grad/param norm = 2.8501e-01, time/batch = 0.6426s	
1315/33650 (epoch 1.954), train_loss = 1.88322669, grad/param norm = 2.7869e-01, time/batch = 0.6674s	
1316/33650 (epoch 1.955), train_loss = 2.00544236, grad/param norm = 3.0269e-01, time/batch = 0.6358s	
1317/33650 (epoch 1.957), train_loss = 1.86550349, grad/param norm = 2.7214e-01, time/batch = 0.6300s	
1318/33650 (epoch 1.958), train_loss = 1.43365521, grad/param norm = 2.2842e-01, time/batch = 0.6308s	
1319/33650 (epoch 1.960), train_loss = 1.59358960, grad/param norm = 2.1680e-01, time/batch = 0.6269s	
1320/33650 (epoch 1.961), train_loss = 1.79544883, grad/param norm = 2.3548e-01, time/batch = 0.6281s	
1321/33650 (epoch 1.963), train_loss = 1.80809017, grad/param norm = 2.4972e-01, time/batch = 0.6320s	
1322/33650 (epoch 1.964), train_loss = 1.75975507, grad/param norm = 2.1253e-01, time/batch = 0.6327s	
1323/33650 (epoch 1.966), train_loss = 1.87091751, grad/param norm = 2.8069e-01, time/batch = 0.6291s	
1324/33650 (epoch 1.967), train_loss = 1.85307790, grad/param norm = 2.7185e-01, time/batch = 0.6289s	
1325/33650 (epoch 1.969), train_loss = 1.69584953, grad/param norm = 2.8778e-01, time/batch = 0.6361s	
1326/33650 (epoch 1.970), train_loss = 1.86288429, grad/param norm = 2.5767e-01, time/batch = 0.6256s	
1327/33650 (epoch 1.972), train_loss = 2.13550257, grad/param norm = 2.9054e-01, time/batch = 0.6285s	
1328/33650 (epoch 1.973), train_loss = 1.73473995, grad/param norm = 2.6440e-01, time/batch = 0.6272s	
1329/33650 (epoch 1.975), train_loss = 1.77971947, grad/param norm = 2.5795e-01, time/batch = 0.6276s	
1330/33650 (epoch 1.976), train_loss = 1.71930100, grad/param norm = 2.3526e-01, time/batch = 0.6270s	
1331/33650 (epoch 1.978), train_loss = 1.65083502, grad/param norm = 2.7235e-01, time/batch = 0.6299s	
1332/33650 (epoch 1.979), train_loss = 1.87302778, grad/param norm = 3.1323e-01, time/batch = 0.6290s	
1333/33650 (epoch 1.981), train_loss = 1.75917794, grad/param norm = 2.2933e-01, time/batch = 0.6286s	
1334/33650 (epoch 1.982), train_loss = 1.86634892, grad/param norm = 2.4746e-01, time/batch = 0.6266s	
1335/33650 (epoch 1.984), train_loss = 1.51898061, grad/param norm = 2.2835e-01, time/batch = 0.6278s	
1336/33650 (epoch 1.985), train_loss = 1.61238648, grad/param norm = 2.1212e-01, time/batch = 0.6298s	
1337/33650 (epoch 1.987), train_loss = 1.79602820, grad/param norm = 2.4219e-01, time/batch = 0.6291s	
1338/33650 (epoch 1.988), train_loss = 1.87941511, grad/param norm = 2.1899e-01, time/batch = 0.6434s	
1339/33650 (epoch 1.990), train_loss = 2.05029295, grad/param norm = 2.9888e-01, time/batch = 0.6342s	
1340/33650 (epoch 1.991), train_loss = 1.96698027, grad/param norm = 2.8703e-01, time/batch = 0.6288s	
1341/33650 (epoch 1.993), train_loss = 1.93949316, grad/param norm = 2.5328e-01, time/batch = 0.6293s	
1342/33650 (epoch 1.994), train_loss = 1.75803936, grad/param norm = 2.5957e-01, time/batch = 0.6286s	
1343/33650 (epoch 1.996), train_loss = 1.70006945, grad/param norm = 2.5371e-01, time/batch = 0.6258s	
1344/33650 (epoch 1.997), train_loss = 1.81730886, grad/param norm = 2.3446e-01, time/batch = 0.6307s	
1345/33650 (epoch 1.999), train_loss = 1.60210725, grad/param norm = 2.5370e-01, time/batch = 0.6307s	
1346/33650 (epoch 2.000), train_loss = 1.97777946, grad/param norm = 2.4506e-01, time/batch = 0.6307s	
1347/33650 (epoch 2.001), train_loss = 1.98352350, grad/param norm = 2.6626e-01, time/batch = 0.6252s	
1348/33650 (epoch 2.003), train_loss = 2.02101882, grad/param norm = 2.5174e-01, time/batch = 0.6265s	
1349/33650 (epoch 2.004), train_loss = 1.85469142, grad/param norm = 2.3740e-01, time/batch = 0.6279s	
1350/33650 (epoch 2.006), train_loss = 1.79345420, grad/param norm = 2.4158e-01, time/batch = 0.6273s	
1351/33650 (epoch 2.007), train_loss = 1.72789076, grad/param norm = 2.3611e-01, time/batch = 0.6288s	
1352/33650 (epoch 2.009), train_loss = 1.76179906, grad/param norm = 2.3099e-01, time/batch = 0.6289s	
1353/33650 (epoch 2.010), train_loss = 1.97893685, grad/param norm = 3.0885e-01, time/batch = 0.6302s	
1354/33650 (epoch 2.012), train_loss = 1.79648849, grad/param norm = 2.8053e-01, time/batch = 0.6283s	
1355/33650 (epoch 2.013), train_loss = 1.94535076, grad/param norm = 2.6467e-01, time/batch = 0.6302s	
1356/33650 (epoch 2.015), train_loss = 1.68332194, grad/param norm = 2.5640e-01, time/batch = 0.6285s	
1357/33650 (epoch 2.016), train_loss = 1.86187747, grad/param norm = 2.5563e-01, time/batch = 0.6305s	
1358/33650 (epoch 2.018), train_loss = 1.79354162, grad/param norm = 2.5550e-01, time/batch = 0.6282s	
1359/33650 (epoch 2.019), train_loss = 1.74566156, grad/param norm = 2.9071e-01, time/batch = 0.6286s	
1360/33650 (epoch 2.021), train_loss = 1.95889368, grad/param norm = 2.6809e-01, time/batch = 0.6524s	
1361/33650 (epoch 2.022), train_loss = 1.81336297, grad/param norm = 2.3578e-01, time/batch = 0.6663s	
1362/33650 (epoch 2.024), train_loss = 1.74351341, grad/param norm = 2.3129e-01, time/batch = 0.6295s	
1363/33650 (epoch 2.025), train_loss = 1.74437273, grad/param norm = 2.5444e-01, time/batch = 0.6282s	
1364/33650 (epoch 2.027), train_loss = 1.95945190, grad/param norm = 2.7218e-01, time/batch = 0.6280s	
1365/33650 (epoch 2.028), train_loss = 1.94660045, grad/param norm = 2.3577e-01, time/batch = 0.6323s	
1366/33650 (epoch 2.030), train_loss = 1.69806069, grad/param norm = 2.4299e-01, time/batch = 0.6289s	
1367/33650 (epoch 2.031), train_loss = 1.45380085, grad/param norm = 2.2791e-01, time/batch = 0.6284s	
1368/33650 (epoch 2.033), train_loss = 1.64646122, grad/param norm = 2.0661e-01, time/batch = 0.6319s	
1369/33650 (epoch 2.034), train_loss = 1.76780033, grad/param norm = 2.1887e-01, time/batch = 0.6281s	
1370/33650 (epoch 2.036), train_loss = 1.94050833, grad/param norm = 2.5466e-01, time/batch = 0.6280s	
1371/33650 (epoch 2.037), train_loss = 1.70873967, grad/param norm = 2.5529e-01, time/batch = 0.6368s	
1372/33650 (epoch 2.039), train_loss = 1.92148265, grad/param norm = 2.3048e-01, time/batch = 0.6379s	
1373/33650 (epoch 2.040), train_loss = 1.90245784, grad/param norm = 2.4856e-01, time/batch = 0.6284s	
1374/33650 (epoch 2.042), train_loss = 1.99799065, grad/param norm = 2.6192e-01, time/batch = 0.6285s	
1375/33650 (epoch 2.043), train_loss = 1.64401577, grad/param norm = 3.0305e-01, time/batch = 0.6294s	
1376/33650 (epoch 2.045), train_loss = 1.71801896, grad/param norm = 2.3220e-01, time/batch = 0.6291s	
1377/33650 (epoch 2.046), train_loss = 1.95946983, grad/param norm = 2.2705e-01, time/batch = 0.6271s	
1378/33650 (epoch 2.048), train_loss = 1.82598661, grad/param norm = 2.5963e-01, time/batch = 0.6276s	
1379/33650 (epoch 2.049), train_loss = 1.91891232, grad/param norm = 2.8778e-01, time/batch = 0.6277s	
1380/33650 (epoch 2.051), train_loss = 1.88373496, grad/param norm = 2.2543e-01, time/batch = 0.6306s	
1381/33650 (epoch 2.052), train_loss = 1.94799149, grad/param norm = 2.1622e-01, time/batch = 0.6696s	
1382/33650 (epoch 2.053), train_loss = 1.73164765, grad/param norm = 2.1197e-01, time/batch = 0.6475s	
1383/33650 (epoch 2.055), train_loss = 1.57972601, grad/param norm = 2.5470e-01, time/batch = 0.6528s	
1384/33650 (epoch 2.056), train_loss = 1.54592781, grad/param norm = 2.2326e-01, time/batch = 0.6338s	
1385/33650 (epoch 2.058), train_loss = 1.88997175, grad/param norm = 2.2147e-01, time/batch = 0.6530s	
1386/33650 (epoch 2.059), train_loss = 1.96511093, grad/param norm = 2.6027e-01, time/batch = 0.6609s	
1387/33650 (epoch 2.061), train_loss = 1.80754938, grad/param norm = 2.8666e-01, time/batch = 0.6366s	
1388/33650 (epoch 2.062), train_loss = 1.85099521, grad/param norm = 2.7549e-01, time/batch = 0.6293s	
1389/33650 (epoch 2.064), train_loss = 1.73881977, grad/param norm = 2.1384e-01, time/batch = 0.6480s	
1390/33650 (epoch 2.065), train_loss = 1.76561816, grad/param norm = 2.4367e-01, time/batch = 0.6361s	
1391/33650 (epoch 2.067), train_loss = 1.72258976, grad/param norm = 2.6435e-01, time/batch = 0.6379s	
1392/33650 (epoch 2.068), train_loss = 1.81832129, grad/param norm = 2.3589e-01, time/batch = 0.6398s	
1393/33650 (epoch 2.070), train_loss = 1.70864844, grad/param norm = 2.2598e-01, time/batch = 0.6400s	
1394/33650 (epoch 2.071), train_loss = 1.77783338, grad/param norm = 2.4111e-01, time/batch = 0.6297s	
1395/33650 (epoch 2.073), train_loss = 1.92544755, grad/param norm = 2.9459e-01, time/batch = 0.6359s	
1396/33650 (epoch 2.074), train_loss = 1.88632881, grad/param norm = 2.8983e-01, time/batch = 0.6605s	
1397/33650 (epoch 2.076), train_loss = 1.87870825, grad/param norm = 2.5920e-01, time/batch = 0.6604s	
1398/33650 (epoch 2.077), train_loss = 1.72938885, grad/param norm = 2.5372e-01, time/batch = 0.6345s	
1399/33650 (epoch 2.079), train_loss = 1.75089482, grad/param norm = 2.5108e-01, time/batch = 0.6278s	
1400/33650 (epoch 2.080), train_loss = 1.76964356, grad/param norm = 2.7515e-01, time/batch = 0.6289s	
1401/33650 (epoch 2.082), train_loss = 1.95608533, grad/param norm = 2.7407e-01, time/batch = 0.6288s	
1402/33650 (epoch 2.083), train_loss = 1.91923555, grad/param norm = 2.5302e-01, time/batch = 0.6301s	
1403/33650 (epoch 2.085), train_loss = 1.88170948, grad/param norm = 2.4109e-01, time/batch = 0.6355s	
1404/33650 (epoch 2.086), train_loss = 1.96833435, grad/param norm = 3.1373e-01, time/batch = 0.6331s	
1405/33650 (epoch 2.088), train_loss = 1.83419749, grad/param norm = 2.5845e-01, time/batch = 0.6307s	
1406/33650 (epoch 2.089), train_loss = 1.86878616, grad/param norm = 2.4723e-01, time/batch = 0.6287s	
1407/33650 (epoch 2.091), train_loss = 1.67308066, grad/param norm = 2.4411e-01, time/batch = 0.6345s	
1408/33650 (epoch 2.092), train_loss = 1.70690473, grad/param norm = 2.5742e-01, time/batch = 0.6278s	
1409/33650 (epoch 2.094), train_loss = 1.90007005, grad/param norm = 2.5113e-01, time/batch = 0.6260s	
1410/33650 (epoch 2.095), train_loss = 1.92183501, grad/param norm = 2.6952e-01, time/batch = 0.6264s	
1411/33650 (epoch 2.097), train_loss = 1.75816172, grad/param norm = 2.8388e-01, time/batch = 0.6310s	
1412/33650 (epoch 2.098), train_loss = 1.55339014, grad/param norm = 2.2986e-01, time/batch = 0.6286s	
1413/33650 (epoch 2.100), train_loss = 1.71552910, grad/param norm = 2.3163e-01, time/batch = 0.6299s	
1414/33650 (epoch 2.101), train_loss = 1.66974000, grad/param norm = 2.3770e-01, time/batch = 0.6336s	
1415/33650 (epoch 2.103), train_loss = 1.69016170, grad/param norm = 2.4071e-01, time/batch = 0.6277s	
1416/33650 (epoch 2.104), train_loss = 1.77467049, grad/param norm = 2.3056e-01, time/batch = 0.6261s	
1417/33650 (epoch 2.105), train_loss = 1.80399601, grad/param norm = 2.5936e-01, time/batch = 0.6260s	
1418/33650 (epoch 2.107), train_loss = 1.61121146, grad/param norm = 2.2544e-01, time/batch = 0.6274s	
1419/33650 (epoch 2.108), train_loss = 1.80984425, grad/param norm = 2.5233e-01, time/batch = 0.6269s	
1420/33650 (epoch 2.110), train_loss = 1.96132168, grad/param norm = 3.2156e-01, time/batch = 0.6269s	
1421/33650 (epoch 2.111), train_loss = 1.69008350, grad/param norm = 2.8537e-01, time/batch = 0.6510s	
1422/33650 (epoch 2.113), train_loss = 1.72741802, grad/param norm = 2.7823e-01, time/batch = 0.6677s	
1423/33650 (epoch 2.114), train_loss = 1.88815719, grad/param norm = 2.6401e-01, time/batch = 0.6267s	
1424/33650 (epoch 2.116), train_loss = 1.46209252, grad/param norm = 2.3206e-01, time/batch = 0.6262s	
1425/33650 (epoch 2.117), train_loss = 1.87707228, grad/param norm = 2.4584e-01, time/batch = 0.6255s	
1426/33650 (epoch 2.119), train_loss = 1.70561419, grad/param norm = 2.2298e-01, time/batch = 0.6266s	
1427/33650 (epoch 2.120), train_loss = 1.73175754, grad/param norm = 2.6072e-01, time/batch = 0.6272s	
1428/33650 (epoch 2.122), train_loss = 1.72267685, grad/param norm = 2.5201e-01, time/batch = 0.6349s	
1429/33650 (epoch 2.123), train_loss = 1.68241215, grad/param norm = 2.0357e-01, time/batch = 0.6252s	
1430/33650 (epoch 2.125), train_loss = 1.86808425, grad/param norm = 2.6604e-01, time/batch = 0.6281s	
1431/33650 (epoch 2.126), train_loss = 1.96484998, grad/param norm = 2.4569e-01, time/batch = 0.6290s	
1432/33650 (epoch 2.128), train_loss = 1.86151154, grad/param norm = 2.4091e-01, time/batch = 0.6279s	
1433/33650 (epoch 2.129), train_loss = 1.92836534, grad/param norm = 2.4438e-01, time/batch = 0.6305s	
1434/33650 (epoch 2.131), train_loss = 1.84030796, grad/param norm = 2.3250e-01, time/batch = 0.6285s	
1435/33650 (epoch 2.132), train_loss = 1.77449197, grad/param norm = 2.1821e-01, time/batch = 0.6326s	
1436/33650 (epoch 2.134), train_loss = 2.04037102, grad/param norm = 2.5810e-01, time/batch = 0.6279s	
1437/33650 (epoch 2.135), train_loss = 1.68340948, grad/param norm = 2.4725e-01, time/batch = 0.6282s	
1438/33650 (epoch 2.137), train_loss = 1.71114484, grad/param norm = 2.0769e-01, time/batch = 0.6359s	
1439/33650 (epoch 2.138), train_loss = 1.87354619, grad/param norm = 2.2364e-01, time/batch = 0.6448s	
1440/33650 (epoch 2.140), train_loss = 1.71749317, grad/param norm = 2.2663e-01, time/batch = 0.6293s	
1441/33650 (epoch 2.141), train_loss = 1.96015856, grad/param norm = 2.5051e-01, time/batch = 0.6310s	
1442/33650 (epoch 2.143), train_loss = 2.05805900, grad/param norm = 3.1366e-01, time/batch = 0.6679s	
1443/33650 (epoch 2.144), train_loss = 2.01730708, grad/param norm = 2.3403e-01, time/batch = 0.6483s	
1444/33650 (epoch 2.146), train_loss = 1.84093025, grad/param norm = 2.5409e-01, time/batch = 0.6312s	
1445/33650 (epoch 2.147), train_loss = 1.77242018, grad/param norm = 2.5457e-01, time/batch = 0.6270s	
1446/33650 (epoch 2.149), train_loss = 1.61834537, grad/param norm = 2.3066e-01, time/batch = 0.6265s	
1447/33650 (epoch 2.150), train_loss = 1.65401314, grad/param norm = 2.1633e-01, time/batch = 0.6261s	
1448/33650 (epoch 2.152), train_loss = 1.78024848, grad/param norm = 2.1821e-01, time/batch = 0.6254s	
1449/33650 (epoch 2.153), train_loss = 1.80498861, grad/param norm = 2.6152e-01, time/batch = 0.6268s	
1450/33650 (epoch 2.155), train_loss = 1.67131307, grad/param norm = 2.3347e-01, time/batch = 0.6318s	
1451/33650 (epoch 2.156), train_loss = 1.69536304, grad/param norm = 2.5082e-01, time/batch = 0.6321s	
1452/33650 (epoch 2.158), train_loss = 1.83627413, grad/param norm = 2.6533e-01, time/batch = 0.6313s	
1453/33650 (epoch 2.159), train_loss = 1.51634816, grad/param norm = 2.3008e-01, time/batch = 0.6261s	
1454/33650 (epoch 2.160), train_loss = 1.62170604, grad/param norm = 2.0607e-01, time/batch = 0.6284s	
1455/33650 (epoch 2.162), train_loss = 1.62533113, grad/param norm = 2.6616e-01, time/batch = 0.6270s	
1456/33650 (epoch 2.163), train_loss = 1.86842723, grad/param norm = 2.7888e-01, time/batch = 0.6261s	
1457/33650 (epoch 2.165), train_loss = 1.54826014, grad/param norm = 1.9596e-01, time/batch = 0.6259s	
1458/33650 (epoch 2.166), train_loss = 1.51908139, grad/param norm = 2.1661e-01, time/batch = 0.6280s	
1459/33650 (epoch 2.168), train_loss = 1.89310640, grad/param norm = 2.5259e-01, time/batch = 0.6278s	
1460/33650 (epoch 2.169), train_loss = 1.69006469, grad/param norm = 2.6050e-01, time/batch = 0.6286s	
1461/33650 (epoch 2.171), train_loss = 1.78785892, grad/param norm = 2.1849e-01, time/batch = 0.6310s	
1462/33650 (epoch 2.172), train_loss = 1.66286211, grad/param norm = 2.2779e-01, time/batch = 0.6523s	
1463/33650 (epoch 2.174), train_loss = 1.64665508, grad/param norm = 2.3068e-01, time/batch = 0.6678s	
1464/33650 (epoch 2.175), train_loss = 1.61963020, grad/param norm = 2.5219e-01, time/batch = 0.6268s	
1465/33650 (epoch 2.177), train_loss = 1.84813357, grad/param norm = 2.3591e-01, time/batch = 0.6292s	
1466/33650 (epoch 2.178), train_loss = 1.76024695, grad/param norm = 2.6999e-01, time/batch = 0.6282s	
1467/33650 (epoch 2.180), train_loss = 1.70456797, grad/param norm = 2.9147e-01, time/batch = 0.6269s	
1468/33650 (epoch 2.181), train_loss = 1.56971826, grad/param norm = 2.1359e-01, time/batch = 0.6303s	
1469/33650 (epoch 2.183), train_loss = 1.73215296, grad/param norm = 2.7062e-01, time/batch = 0.6304s	
1470/33650 (epoch 2.184), train_loss = 1.79506779, grad/param norm = 2.8262e-01, time/batch = 0.6298s	
1471/33650 (epoch 2.186), train_loss = 1.82563839, grad/param norm = 2.4910e-01, time/batch = 0.6316s	
1472/33650 (epoch 2.187), train_loss = 1.89479681, grad/param norm = 2.7180e-01, time/batch = 0.6303s	
1473/33650 (epoch 2.189), train_loss = 1.84123631, grad/param norm = 2.6937e-01, time/batch = 0.6306s	
1474/33650 (epoch 2.190), train_loss = 1.89544761, grad/param norm = 2.7339e-01, time/batch = 0.6299s	
1475/33650 (epoch 2.192), train_loss = 1.95888234, grad/param norm = 2.3473e-01, time/batch = 0.6294s	
1476/33650 (epoch 2.193), train_loss = 1.91450483, grad/param norm = 2.5430e-01, time/batch = 0.6355s	
1477/33650 (epoch 2.195), train_loss = 1.59441233, grad/param norm = 2.0804e-01, time/batch = 0.6397s	
1478/33650 (epoch 2.196), train_loss = 1.51597963, grad/param norm = 2.3261e-01, time/batch = 0.6464s	
1479/33650 (epoch 2.198), train_loss = 1.79755470, grad/param norm = 2.4212e-01, time/batch = 0.6393s	
1480/33650 (epoch 2.199), train_loss = 1.92194614, grad/param norm = 2.9562e-01, time/batch = 0.6512s	
1481/33650 (epoch 2.201), train_loss = 1.91776913, grad/param norm = 2.6178e-01, time/batch = 0.6342s	
1482/33650 (epoch 2.202), train_loss = 1.75706649, grad/param norm = 2.3856e-01, time/batch = 0.6531s	
1483/33650 (epoch 2.204), train_loss = 1.83491159, grad/param norm = 2.6700e-01, time/batch = 0.6307s	
1484/33650 (epoch 2.205), train_loss = 1.78401903, grad/param norm = 2.7859e-01, time/batch = 0.6335s	
1485/33650 (epoch 2.207), train_loss = 1.81225735, grad/param norm = 2.2676e-01, time/batch = 0.6315s	
1486/33650 (epoch 2.208), train_loss = 1.78371505, grad/param norm = 2.3162e-01, time/batch = 0.6285s	
1487/33650 (epoch 2.210), train_loss = 1.41524669, grad/param norm = 2.3296e-01, time/batch = 0.6471s	
1488/33650 (epoch 2.211), train_loss = 1.82110745, grad/param norm = 2.3457e-01, time/batch = 0.6676s	
1489/33650 (epoch 2.212), train_loss = 1.77075570, grad/param norm = 2.3774e-01, time/batch = 0.6309s	
1490/33650 (epoch 2.214), train_loss = 1.84177138, grad/param norm = 2.3133e-01, time/batch = 0.6263s	
1491/33650 (epoch 2.215), train_loss = 1.55516849, grad/param norm = 2.2440e-01, time/batch = 0.6303s	
1492/33650 (epoch 2.217), train_loss = 1.73679457, grad/param norm = 2.3292e-01, time/batch = 0.6495s	
1493/33650 (epoch 2.218), train_loss = 1.89173659, grad/param norm = 2.2199e-01, time/batch = 0.6495s	
1494/33650 (epoch 2.220), train_loss = 1.73589246, grad/param norm = 2.2127e-01, time/batch = 0.6440s	
1495/33650 (epoch 2.221), train_loss = 1.90144950, grad/param norm = 2.1855e-01, time/batch = 0.6412s	
1496/33650 (epoch 2.223), train_loss = 1.58069219, grad/param norm = 2.4049e-01, time/batch = 0.6305s	
1497/33650 (epoch 2.224), train_loss = 1.75048824, grad/param norm = 2.1892e-01, time/batch = 0.6354s	
1498/33650 (epoch 2.226), train_loss = 2.09190659, grad/param norm = 2.7827e-01, time/batch = 0.6281s	
1499/33650 (epoch 2.227), train_loss = 1.93869677, grad/param norm = 2.4532e-01, time/batch = 0.6266s	
1500/33650 (epoch 2.229), train_loss = 1.77016381, grad/param norm = 2.3555e-01, time/batch = 0.6331s	
1501/33650 (epoch 2.230), train_loss = 1.97904422, grad/param norm = 2.6651e-01, time/batch = 0.6514s	
1502/33650 (epoch 2.232), train_loss = 1.74815804, grad/param norm = 2.4233e-01, time/batch = 0.6342s	
1503/33650 (epoch 2.233), train_loss = 1.88036736, grad/param norm = 2.6591e-01, time/batch = 0.6658s	
1504/33650 (epoch 2.235), train_loss = 1.78240717, grad/param norm = 2.6535e-01, time/batch = 0.6506s	
1505/33650 (epoch 2.236), train_loss = 1.70570590, grad/param norm = 2.4188e-01, time/batch = 0.6268s	
1506/33650 (epoch 2.238), train_loss = 1.83693050, grad/param norm = 2.2420e-01, time/batch = 0.6272s	
1507/33650 (epoch 2.239), train_loss = 1.66715058, grad/param norm = 2.7134e-01, time/batch = 0.6279s	
1508/33650 (epoch 2.241), train_loss = 1.70040203, grad/param norm = 2.3749e-01, time/batch = 0.6284s	
1509/33650 (epoch 2.242), train_loss = 1.66022398, grad/param norm = 2.6708e-01, time/batch = 0.6396s	
1510/33650 (epoch 2.244), train_loss = 1.76915054, grad/param norm = 2.3879e-01, time/batch = 0.6439s	
1511/33650 (epoch 2.245), train_loss = 1.62037195, grad/param norm = 2.3733e-01, time/batch = 0.6456s	
1512/33650 (epoch 2.247), train_loss = 1.79962291, grad/param norm = 2.1669e-01, time/batch = 0.6349s	
1513/33650 (epoch 2.248), train_loss = 1.81869949, grad/param norm = 2.4571e-01, time/batch = 0.6260s	
1514/33650 (epoch 2.250), train_loss = 1.81751344, grad/param norm = 2.3341e-01, time/batch = 0.6270s	
1515/33650 (epoch 2.251), train_loss = 1.94909492, grad/param norm = 2.6732e-01, time/batch = 0.6269s	
1516/33650 (epoch 2.253), train_loss = 1.60470064, grad/param norm = 2.8535e-01, time/batch = 0.6279s	
1517/33650 (epoch 2.254), train_loss = 1.76291372, grad/param norm = 2.5586e-01, time/batch = 0.6293s	
1518/33650 (epoch 2.256), train_loss = 1.80332201, grad/param norm = 2.3592e-01, time/batch = 0.6311s	
1519/33650 (epoch 2.257), train_loss = 2.08950084, grad/param norm = 2.5724e-01, time/batch = 0.6307s	
1520/33650 (epoch 2.259), train_loss = 1.47410983, grad/param norm = 2.2211e-01, time/batch = 0.6261s	
1521/33650 (epoch 2.260), train_loss = 1.98621957, grad/param norm = 2.9638e-01, time/batch = 0.6325s	
1522/33650 (epoch 2.262), train_loss = 1.78688725, grad/param norm = 2.1865e-01, time/batch = 0.6315s	
1523/33650 (epoch 2.263), train_loss = 1.82026522, grad/param norm = 2.6155e-01, time/batch = 0.6499s	
1524/33650 (epoch 2.264), train_loss = 1.72406586, grad/param norm = 2.3691e-01, time/batch = 0.6664s	
1525/33650 (epoch 2.266), train_loss = 1.70099155, grad/param norm = 2.4683e-01, time/batch = 0.6286s	
1526/33650 (epoch 2.267), train_loss = 1.78287824, grad/param norm = 3.1842e-01, time/batch = 0.6301s	
1527/33650 (epoch 2.269), train_loss = 1.91704104, grad/param norm = 2.8616e-01, time/batch = 0.6268s	
1528/33650 (epoch 2.270), train_loss = 1.72998924, grad/param norm = 2.4002e-01, time/batch = 0.6285s	
1529/33650 (epoch 2.272), train_loss = 1.74106509, grad/param norm = 2.1741e-01, time/batch = 0.6281s	
1530/33650 (epoch 2.273), train_loss = 1.93159442, grad/param norm = 2.3066e-01, time/batch = 0.6296s	
1531/33650 (epoch 2.275), train_loss = 1.91190864, grad/param norm = 2.2549e-01, time/batch = 0.6323s	
1532/33650 (epoch 2.276), train_loss = 1.90149118, grad/param norm = 2.6128e-01, time/batch = 0.6323s	
1533/33650 (epoch 2.278), train_loss = 2.06062618, grad/param norm = 2.6305e-01, time/batch = 0.6336s	
1534/33650 (epoch 2.279), train_loss = 1.66942622, grad/param norm = 2.5420e-01, time/batch = 0.6307s	
1535/33650 (epoch 2.281), train_loss = 1.84677876, grad/param norm = 2.4068e-01, time/batch = 0.6275s	
1536/33650 (epoch 2.282), train_loss = 1.83145858, grad/param norm = 2.1357e-01, time/batch = 0.6272s	
1537/33650 (epoch 2.284), train_loss = 1.88871358, grad/param norm = 2.7003e-01, time/batch = 0.6289s	
1538/33650 (epoch 2.285), train_loss = 1.82640391, grad/param norm = 2.9267e-01, time/batch = 0.6295s	
1539/33650 (epoch 2.287), train_loss = 1.79701853, grad/param norm = 2.5913e-01, time/batch = 0.6284s	
1540/33650 (epoch 2.288), train_loss = 1.79081441, grad/param norm = 2.3659e-01, time/batch = 0.6327s	
1541/33650 (epoch 2.290), train_loss = 1.73566553, grad/param norm = 2.4306e-01, time/batch = 0.6389s	
1542/33650 (epoch 2.291), train_loss = 1.58380129, grad/param norm = 2.0010e-01, time/batch = 0.6387s	
1543/33650 (epoch 2.293), train_loss = 1.83067381, grad/param norm = 2.0681e-01, time/batch = 0.6271s	
1544/33650 (epoch 2.294), train_loss = 1.56917321, grad/param norm = 2.1794e-01, time/batch = 0.6305s	
1545/33650 (epoch 2.296), train_loss = 1.48235463, grad/param norm = 2.2230e-01, time/batch = 0.6285s	
1546/33650 (epoch 2.297), train_loss = 1.83567989, grad/param norm = 2.3331e-01, time/batch = 0.6286s	
1547/33650 (epoch 2.299), train_loss = 1.58538825, grad/param norm = 2.3164e-01, time/batch = 0.6340s	
1548/33650 (epoch 2.300), train_loss = 1.74812874, grad/param norm = 2.4652e-01, time/batch = 0.6415s	
1549/33650 (epoch 2.302), train_loss = 1.63639272, grad/param norm = 2.2728e-01, time/batch = 0.6700s	
1550/33650 (epoch 2.303), train_loss = 1.81242269, grad/param norm = 2.4510e-01, time/batch = 0.6344s	
1551/33650 (epoch 2.305), train_loss = 1.88750261, grad/param norm = 2.3080e-01, time/batch = 0.6327s	
1552/33650 (epoch 2.306), train_loss = 1.68920502, grad/param norm = 2.2903e-01, time/batch = 0.6297s	
1553/33650 (epoch 2.308), train_loss = 1.72399920, grad/param norm = 2.3976e-01, time/batch = 0.6318s	
1554/33650 (epoch 2.309), train_loss = 1.78474785, grad/param norm = 2.3859e-01, time/batch = 0.6306s	
1555/33650 (epoch 2.311), train_loss = 1.87516149, grad/param norm = 2.6752e-01, time/batch = 0.6264s	
1556/33650 (epoch 2.312), train_loss = 1.63980048, grad/param norm = 2.3389e-01, time/batch = 0.6307s	
1557/33650 (epoch 2.314), train_loss = 1.49006927, grad/param norm = 2.2814e-01, time/batch = 0.6282s	
1558/33650 (epoch 2.315), train_loss = 1.78679842, grad/param norm = 2.5486e-01, time/batch = 0.6273s	
1559/33650 (epoch 2.316), train_loss = 1.78851307, grad/param norm = 2.7664e-01, time/batch = 0.6285s	
1560/33650 (epoch 2.318), train_loss = 1.65443419, grad/param norm = 2.4444e-01, time/batch = 0.6291s	
1561/33650 (epoch 2.319), train_loss = 1.65415935, grad/param norm = 2.3366e-01, time/batch = 0.6308s	
1562/33650 (epoch 2.321), train_loss = 1.73305304, grad/param norm = 2.1694e-01, time/batch = 0.6302s	
1563/33650 (epoch 2.322), train_loss = 1.72449826, grad/param norm = 2.2646e-01, time/batch = 0.6268s	
1564/33650 (epoch 2.324), train_loss = 1.80006012, grad/param norm = 2.2382e-01, time/batch = 0.6281s	
1565/33650 (epoch 2.325), train_loss = 1.82781820, grad/param norm = 2.6204e-01, time/batch = 0.6275s	
1566/33650 (epoch 2.327), train_loss = 1.60922281, grad/param norm = 2.4618e-01, time/batch = 0.6307s	
1567/33650 (epoch 2.328), train_loss = 1.78417626, grad/param norm = 2.3686e-01, time/batch = 0.6404s	
1568/33650 (epoch 2.330), train_loss = 1.66565360, grad/param norm = 2.3887e-01, time/batch = 0.6598s	
1569/33650 (epoch 2.331), train_loss = 1.48998784, grad/param norm = 2.0868e-01, time/batch = 0.6701s	
1570/33650 (epoch 2.333), train_loss = 1.81912230, grad/param norm = 2.3674e-01, time/batch = 0.6647s	
1571/33650 (epoch 2.334), train_loss = 1.75348260, grad/param norm = 2.3998e-01, time/batch = 0.6666s	
1572/33650 (epoch 2.336), train_loss = 1.76675168, grad/param norm = 2.3488e-01, time/batch = 0.6393s	
1573/33650 (epoch 2.337), train_loss = 1.40684829, grad/param norm = 2.2192e-01, time/batch = 0.6564s	
1574/33650 (epoch 2.339), train_loss = 1.71360194, grad/param norm = 2.4210e-01, time/batch = 0.6609s	
1575/33650 (epoch 2.340), train_loss = 1.99505654, grad/param norm = 2.2984e-01, time/batch = 0.6518s	
1576/33650 (epoch 2.342), train_loss = 1.44249445, grad/param norm = 2.3520e-01, time/batch = 0.6356s	
1577/33650 (epoch 2.343), train_loss = 1.83051741, grad/param norm = 2.3987e-01, time/batch = 0.6283s	
1578/33650 (epoch 2.345), train_loss = 1.74281391, grad/param norm = 2.1901e-01, time/batch = 0.6269s	
1579/33650 (epoch 2.346), train_loss = 1.35309987, grad/param norm = 2.2499e-01, time/batch = 0.6285s	
1580/33650 (epoch 2.348), train_loss = 1.64815218, grad/param norm = 2.7239e-01, time/batch = 0.6298s	
1581/33650 (epoch 2.349), train_loss = 1.51216904, grad/param norm = 2.6367e-01, time/batch = 0.6357s	
1582/33650 (epoch 2.351), train_loss = 1.86661041, grad/param norm = 2.1033e-01, time/batch = 0.6450s	
1583/33650 (epoch 2.352), train_loss = 1.68337212, grad/param norm = 2.4008e-01, time/batch = 0.6321s	
1584/33650 (epoch 2.354), train_loss = 2.09000649, grad/param norm = 2.4941e-01, time/batch = 0.6532s	
1585/33650 (epoch 2.355), train_loss = 1.82596896, grad/param norm = 2.4660e-01, time/batch = 0.6661s	
1586/33650 (epoch 2.357), train_loss = 1.52439544, grad/param norm = 2.3527e-01, time/batch = 0.6272s	
1587/33650 (epoch 2.358), train_loss = 1.84100163, grad/param norm = 2.4056e-01, time/batch = 0.6283s	
1588/33650 (epoch 2.360), train_loss = 1.83695063, grad/param norm = 2.4448e-01, time/batch = 0.6277s	
1589/33650 (epoch 2.361), train_loss = 1.63703236, grad/param norm = 2.1136e-01, time/batch = 0.6345s	
1590/33650 (epoch 2.363), train_loss = 1.63012714, grad/param norm = 2.1602e-01, time/batch = 0.6419s	
1591/33650 (epoch 2.364), train_loss = 1.65732061, grad/param norm = 2.0725e-01, time/batch = 0.6302s	
1592/33650 (epoch 2.366), train_loss = 1.65668445, grad/param norm = 2.4827e-01, time/batch = 0.6301s	
1593/33650 (epoch 2.367), train_loss = 1.79825467, grad/param norm = 2.3172e-01, time/batch = 0.6254s	
1594/33650 (epoch 2.368), train_loss = 1.53433378, grad/param norm = 2.2420e-01, time/batch = 0.6266s	
1595/33650 (epoch 2.370), train_loss = 1.75723862, grad/param norm = 2.1635e-01, time/batch = 0.6285s	
1596/33650 (epoch 2.371), train_loss = 1.52327826, grad/param norm = 2.1573e-01, time/batch = 0.6260s	
1597/33650 (epoch 2.373), train_loss = 1.63689623, grad/param norm = 2.4787e-01, time/batch = 0.6262s	
1598/33650 (epoch 2.374), train_loss = 1.52869298, grad/param norm = 2.2111e-01, time/batch = 0.6290s	
1599/33650 (epoch 2.376), train_loss = 1.69755385, grad/param norm = 2.1933e-01, time/batch = 0.6306s	
1600/33650 (epoch 2.377), train_loss = 1.80737314, grad/param norm = 2.5780e-01, time/batch = 0.6246s	
1601/33650 (epoch 2.379), train_loss = 1.66734967, grad/param norm = 2.6631e-01, time/batch = 0.6276s	
1602/33650 (epoch 2.380), train_loss = 1.49532767, grad/param norm = 2.1826e-01, time/batch = 0.6267s	
1603/33650 (epoch 2.382), train_loss = 1.39656175, grad/param norm = 1.9918e-01, time/batch = 0.6281s	
1604/33650 (epoch 2.383), train_loss = 1.57503145, grad/param norm = 1.9781e-01, time/batch = 0.6275s	
1605/33650 (epoch 2.385), train_loss = 1.71696613, grad/param norm = 2.0195e-01, time/batch = 0.6306s	
1606/33650 (epoch 2.386), train_loss = 1.56893500, grad/param norm = 2.0760e-01, time/batch = 0.6319s	
1607/33650 (epoch 2.388), train_loss = 1.54598696, grad/param norm = 2.1912e-01, time/batch = 0.6244s	
1608/33650 (epoch 2.389), train_loss = 1.75460209, grad/param norm = 2.7642e-01, time/batch = 0.6262s	
1609/33650 (epoch 2.391), train_loss = 1.48069912, grad/param norm = 2.0491e-01, time/batch = 0.6421s	
1610/33650 (epoch 2.392), train_loss = 1.88537285, grad/param norm = 2.2423e-01, time/batch = 0.6669s	
1611/33650 (epoch 2.394), train_loss = 1.77143200, grad/param norm = 2.7279e-01, time/batch = 0.6386s	
1612/33650 (epoch 2.395), train_loss = 1.72098822, grad/param norm = 2.9889e-01, time/batch = 0.6292s	
1613/33650 (epoch 2.397), train_loss = 1.93506035, grad/param norm = 2.5081e-01, time/batch = 0.6341s	
1614/33650 (epoch 2.398), train_loss = 1.70418959, grad/param norm = 2.1520e-01, time/batch = 0.6480s	
1615/33650 (epoch 2.400), train_loss = 1.84323361, grad/param norm = 2.5334e-01, time/batch = 0.6404s	
1616/33650 (epoch 2.401), train_loss = 1.78662462, grad/param norm = 2.3505e-01, time/batch = 0.6339s	
1617/33650 (epoch 2.403), train_loss = 1.76200199, grad/param norm = 2.4377e-01, time/batch = 0.6296s	
1618/33650 (epoch 2.404), train_loss = 1.68257789, grad/param norm = 2.1640e-01, time/batch = 0.6287s	
1619/33650 (epoch 2.406), train_loss = 1.82739997, grad/param norm = 2.1695e-01, time/batch = 0.6302s	
1620/33650 (epoch 2.407), train_loss = 1.63109780, grad/param norm = 2.1549e-01, time/batch = 0.6264s	
1621/33650 (epoch 2.409), train_loss = 1.74881298, grad/param norm = 2.4287e-01, time/batch = 0.6302s	
1622/33650 (epoch 2.410), train_loss = 1.74963942, grad/param norm = 2.9081e-01, time/batch = 0.6321s	
1623/33650 (epoch 2.412), train_loss = 1.68738515, grad/param norm = 2.5911e-01, time/batch = 0.6286s	
1624/33650 (epoch 2.413), train_loss = 1.63991363, grad/param norm = 2.5290e-01, time/batch = 0.6273s	
1625/33650 (epoch 2.415), train_loss = 1.70403773, grad/param norm = 2.3322e-01, time/batch = 0.6532s	
1626/33650 (epoch 2.416), train_loss = 1.82924636, grad/param norm = 2.3535e-01, time/batch = 0.6442s	
1627/33650 (epoch 2.418), train_loss = 1.79870425, grad/param norm = 2.4158e-01, time/batch = 0.6272s	
1628/33650 (epoch 2.419), train_loss = 1.77198848, grad/param norm = 2.6097e-01, time/batch = 0.6279s	
1629/33650 (epoch 2.421), train_loss = 1.55360288, grad/param norm = 2.5044e-01, time/batch = 0.6327s	
1630/33650 (epoch 2.422), train_loss = 1.78249432, grad/param norm = 2.7714e-01, time/batch = 0.6270s	
1631/33650 (epoch 2.423), train_loss = 1.61329308, grad/param norm = 2.1066e-01, time/batch = 0.6292s	
1632/33650 (epoch 2.425), train_loss = 1.79070590, grad/param norm = 2.2307e-01, time/batch = 0.6267s	
1633/33650 (epoch 2.426), train_loss = 1.82830178, grad/param norm = 2.2610e-01, time/batch = 0.6271s	
1634/33650 (epoch 2.428), train_loss = 1.62953596, grad/param norm = 2.4207e-01, time/batch = 0.6279s	
1635/33650 (epoch 2.429), train_loss = 1.81391987, grad/param norm = 2.3947e-01, time/batch = 0.6292s	
1636/33650 (epoch 2.431), train_loss = 1.96845258, grad/param norm = 2.3773e-01, time/batch = 0.6292s	
1637/33650 (epoch 2.432), train_loss = 1.99401243, grad/param norm = 2.6195e-01, time/batch = 0.6327s	
1638/33650 (epoch 2.434), train_loss = 1.83376883, grad/param norm = 2.4072e-01, time/batch = 0.6317s	
1639/33650 (epoch 2.435), train_loss = 1.79415739, grad/param norm = 2.2254e-01, time/batch = 0.6275s	
1640/33650 (epoch 2.437), train_loss = 1.78320333, grad/param norm = 2.2126e-01, time/batch = 0.6288s	
1641/33650 (epoch 2.438), train_loss = 1.55589043, grad/param norm = 2.5197e-01, time/batch = 0.6275s	
1642/33650 (epoch 2.440), train_loss = 1.72131318, grad/param norm = 2.6030e-01, time/batch = 0.6263s	
1643/33650 (epoch 2.441), train_loss = 1.84752759, grad/param norm = 2.2663e-01, time/batch = 0.6283s	
1644/33650 (epoch 2.443), train_loss = 1.85750989, grad/param norm = 2.3119e-01, time/batch = 0.6295s	
1645/33650 (epoch 2.444), train_loss = 1.67249796, grad/param norm = 2.1946e-01, time/batch = 0.6392s	
1646/33650 (epoch 2.446), train_loss = 1.84495463, grad/param norm = 2.3693e-01, time/batch = 0.6673s	
1647/33650 (epoch 2.447), train_loss = 1.80449994, grad/param norm = 2.4073e-01, time/batch = 0.6422s	
1648/33650 (epoch 2.449), train_loss = 1.98975026, grad/param norm = 2.9187e-01, time/batch = 0.6270s	
1649/33650 (epoch 2.450), train_loss = 2.08181058, grad/param norm = 2.4631e-01, time/batch = 0.6277s	
1650/33650 (epoch 2.452), train_loss = 2.06749564, grad/param norm = 2.5214e-01, time/batch = 0.6276s	
1651/33650 (epoch 2.453), train_loss = 1.99940376, grad/param norm = 2.5343e-01, time/batch = 0.6330s	
1652/33650 (epoch 2.455), train_loss = 1.80121199, grad/param norm = 2.2074e-01, time/batch = 0.6285s	
1653/33650 (epoch 2.456), train_loss = 1.69222921, grad/param norm = 2.2444e-01, time/batch = 0.6275s	
1654/33650 (epoch 2.458), train_loss = 1.77376040, grad/param norm = 2.5522e-01, time/batch = 0.6289s	
1655/33650 (epoch 2.459), train_loss = 1.65244083, grad/param norm = 2.2060e-01, time/batch = 0.6301s	
1656/33650 (epoch 2.461), train_loss = 1.74509910, grad/param norm = 2.2871e-01, time/batch = 0.6276s	
1657/33650 (epoch 2.462), train_loss = 1.96357480, grad/param norm = 2.4469e-01, time/batch = 0.6293s	
1658/33650 (epoch 2.464), train_loss = 1.73081179, grad/param norm = 2.5146e-01, time/batch = 0.6303s	
1659/33650 (epoch 2.465), train_loss = 1.78964781, grad/param norm = 2.5209e-01, time/batch = 0.6294s	
1660/33650 (epoch 2.467), train_loss = 1.83456957, grad/param norm = 2.1620e-01, time/batch = 0.6284s	
1661/33650 (epoch 2.468), train_loss = 1.80693795, grad/param norm = 2.3760e-01, time/batch = 0.6463s	
1662/33650 (epoch 2.470), train_loss = 2.01932656, grad/param norm = 2.4563e-01, time/batch = 0.6676s	
1663/33650 (epoch 2.471), train_loss = 1.80159873, grad/param norm = 2.3743e-01, time/batch = 0.6312s	
1664/33650 (epoch 2.473), train_loss = 1.56873130, grad/param norm = 1.9546e-01, time/batch = 0.6384s	
1665/33650 (epoch 2.474), train_loss = 1.81721857, grad/param norm = 2.4511e-01, time/batch = 0.6428s	
1666/33650 (epoch 2.475), train_loss = 1.95153108, grad/param norm = 2.6748e-01, time/batch = 0.6458s	
1667/33650 (epoch 2.477), train_loss = 1.96409945, grad/param norm = 2.5065e-01, time/batch = 0.6325s	
1668/33650 (epoch 2.478), train_loss = 1.86605880, grad/param norm = 2.3668e-01, time/batch = 0.6498s	
1669/33650 (epoch 2.480), train_loss = 1.91444355, grad/param norm = 2.3000e-01, time/batch = 0.6300s	
1670/33650 (epoch 2.481), train_loss = 1.87326977, grad/param norm = 2.1221e-01, time/batch = 0.6463s	
1671/33650 (epoch 2.483), train_loss = 1.49032286, grad/param norm = 2.3409e-01, time/batch = 0.6340s	
1672/33650 (epoch 2.484), train_loss = 1.79891230, grad/param norm = 2.5714e-01, time/batch = 0.6279s	
1673/33650 (epoch 2.486), train_loss = 1.89789629, grad/param norm = 2.5561e-01, time/batch = 0.6306s	
1674/33650 (epoch 2.487), train_loss = 1.91695577, grad/param norm = 2.9680e-01, time/batch = 0.6342s	
1675/33650 (epoch 2.489), train_loss = 1.94826038, grad/param norm = 2.3881e-01, time/batch = 0.6267s	
1676/33650 (epoch 2.490), train_loss = 1.65244428, grad/param norm = 2.1025e-01, time/batch = 0.6309s	
1677/33650 (epoch 2.492), train_loss = 1.94075451, grad/param norm = 2.2682e-01, time/batch = 0.6258s	
1678/33650 (epoch 2.493), train_loss = 1.55745227, grad/param norm = 2.3187e-01, time/batch = 0.6264s	
1679/33650 (epoch 2.495), train_loss = 1.71329557, grad/param norm = 2.2977e-01, time/batch = 0.6265s	
1680/33650 (epoch 2.496), train_loss = 1.83379873, grad/param norm = 2.5594e-01, time/batch = 0.6266s	
1681/33650 (epoch 2.498), train_loss = 1.57738852, grad/param norm = 2.6675e-01, time/batch = 0.6354s	
1682/33650 (epoch 2.499), train_loss = 1.74397980, grad/param norm = 2.4672e-01, time/batch = 0.6697s	
1683/33650 (epoch 2.501), train_loss = 1.74693641, grad/param norm = 2.3345e-01, time/batch = 0.6451s	
1684/33650 (epoch 2.502), train_loss = 1.82982383, grad/param norm = 2.3334e-01, time/batch = 0.6270s	
1685/33650 (epoch 2.504), train_loss = 1.97440013, grad/param norm = 2.3767e-01, time/batch = 0.6272s	
1686/33650 (epoch 2.505), train_loss = 1.83364049, grad/param norm = 2.4825e-01, time/batch = 0.6263s	
1687/33650 (epoch 2.507), train_loss = 1.86262106, grad/param norm = 2.6102e-01, time/batch = 0.6271s	
1688/33650 (epoch 2.508), train_loss = 1.69748270, grad/param norm = 2.2570e-01, time/batch = 0.6288s	
1689/33650 (epoch 2.510), train_loss = 1.80732900, grad/param norm = 2.0637e-01, time/batch = 0.6355s	
1690/33650 (epoch 2.511), train_loss = 1.98982964, grad/param norm = 2.5258e-01, time/batch = 0.6343s	
1691/33650 (epoch 2.513), train_loss = 1.83005957, grad/param norm = 2.7638e-01, time/batch = 0.6283s	
1692/33650 (epoch 2.514), train_loss = 1.80143529, grad/param norm = 2.5589e-01, time/batch = 0.6281s	
1693/33650 (epoch 2.516), train_loss = 1.76640484, grad/param norm = 2.2603e-01, time/batch = 0.6290s	
1694/33650 (epoch 2.517), train_loss = 1.62317511, grad/param norm = 2.0386e-01, time/batch = 0.6263s	
1695/33650 (epoch 2.519), train_loss = 1.65062679, grad/param norm = 2.0438e-01, time/batch = 0.6270s	
1696/33650 (epoch 2.520), train_loss = 1.51589099, grad/param norm = 2.2888e-01, time/batch = 0.6276s	
1697/33650 (epoch 2.522), train_loss = 1.76293755, grad/param norm = 2.5504e-01, time/batch = 0.6297s	
1698/33650 (epoch 2.523), train_loss = 1.80363859, grad/param norm = 2.3836e-01, time/batch = 0.6296s	
1699/33650 (epoch 2.525), train_loss = 1.41560640, grad/param norm = 2.0928e-01, time/batch = 0.6285s	
1700/33650 (epoch 2.526), train_loss = 1.85336969, grad/param norm = 2.6912e-01, time/batch = 0.6258s	
1701/33650 (epoch 2.527), train_loss = 1.60673863, grad/param norm = 2.5424e-01, time/batch = 0.6288s	
1702/33650 (epoch 2.529), train_loss = 1.66661649, grad/param norm = 2.0862e-01, time/batch = 0.6521s	
1703/33650 (epoch 2.530), train_loss = 1.63592172, grad/param norm = 2.1396e-01, time/batch = 0.6631s	
1704/33650 (epoch 2.532), train_loss = 1.94829267, grad/param norm = 2.5071e-01, time/batch = 0.6292s	
1705/33650 (epoch 2.533), train_loss = 1.56267611, grad/param norm = 2.2250e-01, time/batch = 0.6319s	
1706/33650 (epoch 2.535), train_loss = 1.87477486, grad/param norm = 2.2623e-01, time/batch = 0.6299s	
1707/33650 (epoch 2.536), train_loss = 1.73943432, grad/param norm = 2.4797e-01, time/batch = 0.6275s	
1708/33650 (epoch 2.538), train_loss = 1.75875049, grad/param norm = 2.4968e-01, time/batch = 0.6265s	
1709/33650 (epoch 2.539), train_loss = 1.53861111, grad/param norm = 2.3030e-01, time/batch = 0.6258s	
1710/33650 (epoch 2.541), train_loss = 1.87018488, grad/param norm = 2.2251e-01, time/batch = 0.6262s	
1711/33650 (epoch 2.542), train_loss = 1.78593491, grad/param norm = 2.6110e-01, time/batch = 0.6287s	
1712/33650 (epoch 2.544), train_loss = 2.06527391, grad/param norm = 2.6831e-01, time/batch = 0.6289s	
1713/33650 (epoch 2.545), train_loss = 1.50938720, grad/param norm = 2.1938e-01, time/batch = 0.6286s	
1714/33650 (epoch 2.547), train_loss = 1.75473717, grad/param norm = 2.4306e-01, time/batch = 0.6255s	
1715/33650 (epoch 2.548), train_loss = 1.88448598, grad/param norm = 2.4347e-01, time/batch = 0.6266s	
1716/33650 (epoch 2.550), train_loss = 1.62907653, grad/param norm = 2.5758e-01, time/batch = 0.6284s	
1717/33650 (epoch 2.551), train_loss = 1.64995122, grad/param norm = 2.6051e-01, time/batch = 0.6272s	
1718/33650 (epoch 2.553), train_loss = 1.51027459, grad/param norm = 2.3379e-01, time/batch = 0.6275s	
1719/33650 (epoch 2.554), train_loss = 1.83736834, grad/param norm = 2.2166e-01, time/batch = 0.6280s	
1720/33650 (epoch 2.556), train_loss = 1.86093031, grad/param norm = 2.6437e-01, time/batch = 0.6305s	
1721/33650 (epoch 2.557), train_loss = 1.87887704, grad/param norm = 2.2902e-01, time/batch = 0.6352s	
1722/33650 (epoch 2.559), train_loss = 1.90129873, grad/param norm = 2.8253e-01, time/batch = 0.6311s	
1723/33650 (epoch 2.560), train_loss = 1.90059560, grad/param norm = 2.6214e-01, time/batch = 0.6676s	
1724/33650 (epoch 2.562), train_loss = 1.82176025, grad/param norm = 2.4745e-01, time/batch = 0.6444s	
1725/33650 (epoch 2.563), train_loss = 1.69861039, grad/param norm = 2.4128e-01, time/batch = 0.6273s	
1726/33650 (epoch 2.565), train_loss = 1.79282112, grad/param norm = 2.2006e-01, time/batch = 0.6287s	
1727/33650 (epoch 2.566), train_loss = 1.76980306, grad/param norm = 2.5163e-01, time/batch = 0.6286s	
1728/33650 (epoch 2.568), train_loss = 1.79699937, grad/param norm = 2.7167e-01, time/batch = 0.6492s	
1729/33650 (epoch 2.569), train_loss = 1.65612559, grad/param norm = 2.5060e-01, time/batch = 0.6313s	
1730/33650 (epoch 2.571), train_loss = 1.84577828, grad/param norm = 2.2389e-01, time/batch = 0.6326s	
1731/33650 (epoch 2.572), train_loss = 1.75597049, grad/param norm = 1.9853e-01, time/batch = 0.6322s	
1732/33650 (epoch 2.574), train_loss = 1.73972066, grad/param norm = 2.5657e-01, time/batch = 0.6289s	
1733/33650 (epoch 2.575), train_loss = 1.69450830, grad/param norm = 2.4359e-01, time/batch = 0.6266s	
1734/33650 (epoch 2.577), train_loss = 1.87167374, grad/param norm = 2.3646e-01, time/batch = 0.6279s	
1735/33650 (epoch 2.578), train_loss = 1.70579460, grad/param norm = 2.0018e-01, time/batch = 0.6290s	
1736/33650 (epoch 2.579), train_loss = 1.70301340, grad/param norm = 2.2470e-01, time/batch = 0.6313s	
1737/33650 (epoch 2.581), train_loss = 1.69371010, grad/param norm = 2.3756e-01, time/batch = 0.6304s	
1738/33650 (epoch 2.582), train_loss = 1.82898716, grad/param norm = 2.2033e-01, time/batch = 0.6438s	
1739/33650 (epoch 2.584), train_loss = 1.65366211, grad/param norm = 2.2334e-01, time/batch = 0.6682s	
1740/33650 (epoch 2.585), train_loss = 1.74619847, grad/param norm = 2.3066e-01, time/batch = 0.6325s	
1741/33650 (epoch 2.587), train_loss = 1.68648147, grad/param norm = 2.6323e-01, time/batch = 0.6292s	
1742/33650 (epoch 2.588), train_loss = 1.71680241, grad/param norm = 2.2159e-01, time/batch = 0.6274s	
1743/33650 (epoch 2.590), train_loss = 1.74682896, grad/param norm = 2.2021e-01, time/batch = 0.6583s	
1744/33650 (epoch 2.591), train_loss = 1.79307311, grad/param norm = 2.1769e-01, time/batch = 0.6566s	
1745/33650 (epoch 2.593), train_loss = 1.60148985, grad/param norm = 2.2031e-01, time/batch = 0.6272s	
1746/33650 (epoch 2.594), train_loss = 1.37822932, grad/param norm = 2.4470e-01, time/batch = 0.6285s	
1747/33650 (epoch 2.596), train_loss = 1.71862280, grad/param norm = 2.2409e-01, time/batch = 0.6262s	
1748/33650 (epoch 2.597), train_loss = 1.35949458, grad/param norm = 1.7586e-01, time/batch = 0.6288s	
1749/33650 (epoch 2.599), train_loss = 1.57273482, grad/param norm = 2.2272e-01, time/batch = 0.6281s	
1750/33650 (epoch 2.600), train_loss = 1.58550672, grad/param norm = 2.4649e-01, time/batch = 0.6267s	
1751/33650 (epoch 2.602), train_loss = 1.86592156, grad/param norm = 2.4004e-01, time/batch = 0.6339s	
1752/33650 (epoch 2.603), train_loss = 1.59396783, grad/param norm = 2.2253e-01, time/batch = 0.6316s	
1753/33650 (epoch 2.605), train_loss = 1.69977459, grad/param norm = 2.2540e-01, time/batch = 0.6276s	
1754/33650 (epoch 2.606), train_loss = 1.88892747, grad/param norm = 2.2280e-01, time/batch = 0.6276s	
1755/33650 (epoch 2.608), train_loss = 1.80171011, grad/param norm = 2.3152e-01, time/batch = 0.6272s	
1756/33650 (epoch 2.609), train_loss = 1.76638799, grad/param norm = 2.3689e-01, time/batch = 0.6275s	
1757/33650 (epoch 2.611), train_loss = 1.61479019, grad/param norm = 2.1529e-01, time/batch = 0.6291s	
1758/33650 (epoch 2.612), train_loss = 1.77838095, grad/param norm = 2.3077e-01, time/batch = 0.6393s	
1759/33650 (epoch 2.614), train_loss = 1.91193283, grad/param norm = 2.5444e-01, time/batch = 0.6470s	
1760/33650 (epoch 2.615), train_loss = 1.66900997, grad/param norm = 2.3611e-01, time/batch = 0.6470s	
1761/33650 (epoch 2.617), train_loss = 1.53748732, grad/param norm = 1.9620e-01, time/batch = 0.6587s	
1762/33650 (epoch 2.618), train_loss = 1.63621160, grad/param norm = 2.2425e-01, time/batch = 0.6588s	
1763/33650 (epoch 2.620), train_loss = 1.87856020, grad/param norm = 2.5557e-01, time/batch = 0.6589s	
1764/33650 (epoch 2.621), train_loss = 1.55132606, grad/param norm = 2.3491e-01, time/batch = 0.6432s	
1765/33650 (epoch 2.623), train_loss = 1.73031490, grad/param norm = 2.2870e-01, time/batch = 0.6331s	
1766/33650 (epoch 2.624), train_loss = 1.46356672, grad/param norm = 2.1039e-01, time/batch = 0.6329s	
1767/33650 (epoch 2.626), train_loss = 1.37768248, grad/param norm = 1.9969e-01, time/batch = 0.6331s	
1768/33650 (epoch 2.627), train_loss = 1.59509536, grad/param norm = 2.2949e-01, time/batch = 0.6320s	
1769/33650 (epoch 2.629), train_loss = 1.66335130, grad/param norm = 2.2620e-01, time/batch = 0.6291s	
1770/33650 (epoch 2.630), train_loss = 1.76799582, grad/param norm = 2.2559e-01, time/batch = 0.6284s	
1771/33650 (epoch 2.632), train_loss = 1.90562213, grad/param norm = 2.1966e-01, time/batch = 0.6340s	
1772/33650 (epoch 2.633), train_loss = 1.75017542, grad/param norm = 2.0971e-01, time/batch = 0.6283s	
1773/33650 (epoch 2.634), train_loss = 1.48175497, grad/param norm = 2.4924e-01, time/batch = 0.6311s	
1774/33650 (epoch 2.636), train_loss = 1.36822130, grad/param norm = 2.0693e-01, time/batch = 0.6283s	
1775/33650 (epoch 2.637), train_loss = 1.81774918, grad/param norm = 2.2099e-01, time/batch = 0.6300s	
1776/33650 (epoch 2.639), train_loss = 1.69467800, grad/param norm = 2.0384e-01, time/batch = 0.6281s	
1777/33650 (epoch 2.640), train_loss = 1.65471684, grad/param norm = 2.2269e-01, time/batch = 0.6265s	
1778/33650 (epoch 2.642), train_loss = 1.97475999, grad/param norm = 2.5759e-01, time/batch = 0.6262s	
1779/33650 (epoch 2.643), train_loss = 1.74274368, grad/param norm = 2.5734e-01, time/batch = 0.6561s	
1780/33650 (epoch 2.645), train_loss = 1.66550437, grad/param norm = 2.3970e-01, time/batch = 0.6616s	
1781/33650 (epoch 2.646), train_loss = 1.48834855, grad/param norm = 2.0843e-01, time/batch = 0.6348s	
1782/33650 (epoch 2.648), train_loss = 1.61512517, grad/param norm = 2.0971e-01, time/batch = 0.6525s	
1783/33650 (epoch 2.649), train_loss = 1.67612219, grad/param norm = 2.2229e-01, time/batch = 0.6399s	
1784/33650 (epoch 2.651), train_loss = 1.75552180, grad/param norm = 2.2753e-01, time/batch = 0.6290s	
1785/33650 (epoch 2.652), train_loss = 1.26458946, grad/param norm = 1.8973e-01, time/batch = 0.6272s	
1786/33650 (epoch 2.654), train_loss = 1.65048956, grad/param norm = 1.9740e-01, time/batch = 0.6337s	
1787/33650 (epoch 2.655), train_loss = 1.46159437, grad/param norm = 1.8998e-01, time/batch = 0.6334s	
1788/33650 (epoch 2.657), train_loss = 1.61637560, grad/param norm = 2.3461e-01, time/batch = 0.6305s	
1789/33650 (epoch 2.658), train_loss = 1.47605463, grad/param norm = 2.0144e-01, time/batch = 0.6280s	
1790/33650 (epoch 2.660), train_loss = 1.43638563, grad/param norm = 2.0841e-01, time/batch = 0.6348s	
1791/33650 (epoch 2.661), train_loss = 1.60521886, grad/param norm = 2.0906e-01, time/batch = 0.6416s	
1792/33650 (epoch 2.663), train_loss = 1.46546768, grad/param norm = 2.2210e-01, time/batch = 0.6386s	
1793/33650 (epoch 2.664), train_loss = 1.48023522, grad/param norm = 2.3415e-01, time/batch = 0.6358s	
1794/33650 (epoch 2.666), train_loss = 1.54556648, grad/param norm = 2.1459e-01, time/batch = 0.6467s	
1795/33650 (epoch 2.667), train_loss = 1.54770371, grad/param norm = 2.1216e-01, time/batch = 0.6333s	
1796/33650 (epoch 2.669), train_loss = 1.45986560, grad/param norm = 1.8972e-01, time/batch = 0.6423s	
1797/33650 (epoch 2.670), train_loss = 1.50992627, grad/param norm = 1.9762e-01, time/batch = 0.6422s	
1798/33650 (epoch 2.672), train_loss = 1.54961753, grad/param norm = 1.9342e-01, time/batch = 0.6388s	
1799/33650 (epoch 2.673), train_loss = 1.39981234, grad/param norm = 2.0497e-01, time/batch = 0.6527s	
1800/33650 (epoch 2.675), train_loss = 1.43349677, grad/param norm = 1.8918e-01, time/batch = 0.6689s	
1801/33650 (epoch 2.676), train_loss = 1.67495427, grad/param norm = 2.1445e-01, time/batch = 0.6451s	
1802/33650 (epoch 2.678), train_loss = 1.48918223, grad/param norm = 1.7821e-01, time/batch = 0.6493s	
1803/33650 (epoch 2.679), train_loss = 1.60210833, grad/param norm = 2.1499e-01, time/batch = 0.6264s	
1804/33650 (epoch 2.681), train_loss = 1.52073598, grad/param norm = 2.2212e-01, time/batch = 0.6267s	
1805/33650 (epoch 2.682), train_loss = 1.65108617, grad/param norm = 2.2405e-01, time/batch = 0.6260s	
1806/33650 (epoch 2.684), train_loss = 1.45573341, grad/param norm = 1.8910e-01, time/batch = 0.6264s	
1807/33650 (epoch 2.685), train_loss = 1.73842405, grad/param norm = 2.2232e-01, time/batch = 0.6296s	
1808/33650 (epoch 2.686), train_loss = 1.58378905, grad/param norm = 2.1083e-01, time/batch = 0.6288s	
1809/33650 (epoch 2.688), train_loss = 1.77892452, grad/param norm = 2.1517e-01, time/batch = 0.6310s	
1810/33650 (epoch 2.689), train_loss = 1.59910642, grad/param norm = 2.1712e-01, time/batch = 0.6283s	
1811/33650 (epoch 2.691), train_loss = 1.74668574, grad/param norm = 2.1914e-01, time/batch = 0.6290s	
1812/33650 (epoch 2.692), train_loss = 1.78706153, grad/param norm = 2.1392e-01, time/batch = 0.6274s	
1813/33650 (epoch 2.694), train_loss = 1.71950365, grad/param norm = 2.3382e-01, time/batch = 0.6280s	
1814/33650 (epoch 2.695), train_loss = 1.35637240, grad/param norm = 2.1906e-01, time/batch = 0.6263s	
1815/33650 (epoch 2.697), train_loss = 1.64608321, grad/param norm = 2.3656e-01, time/batch = 0.6289s	
1816/33650 (epoch 2.698), train_loss = 1.73087464, grad/param norm = 2.2013e-01, time/batch = 0.6355s	
1817/33650 (epoch 2.700), train_loss = 1.67105985, grad/param norm = 2.1455e-01, time/batch = 0.6321s	
1818/33650 (epoch 2.701), train_loss = 1.81006376, grad/param norm = 2.2801e-01, time/batch = 0.6271s	
1819/33650 (epoch 2.703), train_loss = 1.62625882, grad/param norm = 2.2978e-01, time/batch = 0.6280s	
1820/33650 (epoch 2.704), train_loss = 1.54223035, grad/param norm = 2.5739e-01, time/batch = 0.6673s	
1821/33650 (epoch 2.706), train_loss = 1.59078317, grad/param norm = 2.2236e-01, time/batch = 0.6472s	
1822/33650 (epoch 2.707), train_loss = 1.74630790, grad/param norm = 2.1347e-01, time/batch = 0.6275s	
1823/33650 (epoch 2.709), train_loss = 1.61085535, grad/param norm = 2.4177e-01, time/batch = 0.6272s	
1824/33650 (epoch 2.710), train_loss = 1.79596992, grad/param norm = 2.2133e-01, time/batch = 0.6323s	
1825/33650 (epoch 2.712), train_loss = 1.56269264, grad/param norm = 2.0325e-01, time/batch = 0.6253s	
1826/33650 (epoch 2.713), train_loss = 1.68122013, grad/param norm = 2.3056e-01, time/batch = 0.6266s	
1827/33650 (epoch 2.715), train_loss = 1.78769794, grad/param norm = 2.4819e-01, time/batch = 0.6272s	
1828/33650 (epoch 2.716), train_loss = 1.57381068, grad/param norm = 2.2858e-01, time/batch = 0.6308s	
1829/33650 (epoch 2.718), train_loss = 1.79113837, grad/param norm = 2.1092e-01, time/batch = 0.6259s	
1830/33650 (epoch 2.719), train_loss = 1.81371918, grad/param norm = 2.4479e-01, time/batch = 0.6265s	
1831/33650 (epoch 2.721), train_loss = 1.82435570, grad/param norm = 2.2187e-01, time/batch = 0.6370s	
1832/33650 (epoch 2.722), train_loss = 1.88040437, grad/param norm = 2.3530e-01, time/batch = 0.6294s	
1833/33650 (epoch 2.724), train_loss = 1.73224879, grad/param norm = 2.2289e-01, time/batch = 0.6264s	
1834/33650 (epoch 2.725), train_loss = 1.82064759, grad/param norm = 2.2046e-01, time/batch = 0.6283s	
1835/33650 (epoch 2.727), train_loss = 1.60376368, grad/param norm = 2.3744e-01, time/batch = 0.6272s	
1836/33650 (epoch 2.728), train_loss = 1.56586295, grad/param norm = 2.0627e-01, time/batch = 0.6257s	
1837/33650 (epoch 2.730), train_loss = 1.64604272, grad/param norm = 2.2263e-01, time/batch = 0.6275s	
1838/33650 (epoch 2.731), train_loss = 1.88589398, grad/param norm = 2.9665e-01, time/batch = 0.6288s	
1839/33650 (epoch 2.733), train_loss = 1.58304470, grad/param norm = 2.1372e-01, time/batch = 0.6278s	
1840/33650 (epoch 2.734), train_loss = 1.84881204, grad/param norm = 2.9208e-01, time/batch = 0.6508s	
1841/33650 (epoch 2.736), train_loss = 1.69673699, grad/param norm = 2.6395e-01, time/batch = 0.6664s	
1842/33650 (epoch 2.737), train_loss = 1.71089811, grad/param norm = 2.1749e-01, time/batch = 0.6263s	
1843/33650 (epoch 2.738), train_loss = 1.49014028, grad/param norm = 2.2765e-01, time/batch = 0.6279s	
1844/33650 (epoch 2.740), train_loss = 1.59423512, grad/param norm = 2.1225e-01, time/batch = 0.6262s	
1845/33650 (epoch 2.741), train_loss = 1.63239055, grad/param norm = 2.0573e-01, time/batch = 0.6275s	
1846/33650 (epoch 2.743), train_loss = 1.67128980, grad/param norm = 2.2985e-01, time/batch = 0.6273s	
1847/33650 (epoch 2.744), train_loss = 1.56425182, grad/param norm = 2.0890e-01, time/batch = 0.6330s	
1848/33650 (epoch 2.746), train_loss = 1.62200111, grad/param norm = 2.1565e-01, time/batch = 0.6301s	
1849/33650 (epoch 2.747), train_loss = 1.76054527, grad/param norm = 2.1033e-01, time/batch = 0.6262s	
1850/33650 (epoch 2.749), train_loss = 1.34364360, grad/param norm = 2.0689e-01, time/batch = 0.6264s	
1851/33650 (epoch 2.750), train_loss = 1.73170160, grad/param norm = 2.5950e-01, time/batch = 0.6314s	
1852/33650 (epoch 2.752), train_loss = 1.78275136, grad/param norm = 2.5907e-01, time/batch = 0.6276s	
1853/33650 (epoch 2.753), train_loss = 1.88192420, grad/param norm = 2.1195e-01, time/batch = 0.6355s	
1854/33650 (epoch 2.755), train_loss = 1.53284889, grad/param norm = 2.4772e-01, time/batch = 0.6434s	
1855/33650 (epoch 2.756), train_loss = 1.69189679, grad/param norm = 2.1628e-01, time/batch = 0.6586s	
1856/33650 (epoch 2.758), train_loss = 1.89151364, grad/param norm = 2.4658e-01, time/batch = 0.6575s	
1857/33650 (epoch 2.759), train_loss = 1.91847353, grad/param norm = 2.3404e-01, time/batch = 0.6479s	
1858/33650 (epoch 2.761), train_loss = 1.79505624, grad/param norm = 2.2371e-01, time/batch = 0.6316s	
1859/33650 (epoch 2.762), train_loss = 1.68237923, grad/param norm = 2.1531e-01, time/batch = 0.6474s	
1860/33650 (epoch 2.764), train_loss = 1.88232312, grad/param norm = 2.6647e-01, time/batch = 0.6375s	
1861/33650 (epoch 2.765), train_loss = 1.68082301, grad/param norm = 2.1248e-01, time/batch = 0.6441s	
1862/33650 (epoch 2.767), train_loss = 1.52830205, grad/param norm = 2.0241e-01, time/batch = 0.6417s	
1863/33650 (epoch 2.768), train_loss = 1.47549308, grad/param norm = 2.0025e-01, time/batch = 0.6302s	
1864/33650 (epoch 2.770), train_loss = 1.65798239, grad/param norm = 2.1189e-01, time/batch = 0.6295s	
1865/33650 (epoch 2.771), train_loss = 1.68728502, grad/param norm = 2.3369e-01, time/batch = 0.6273s	
1866/33650 (epoch 2.773), train_loss = 1.84975777, grad/param norm = 2.5936e-01, time/batch = 0.6342s	
1867/33650 (epoch 2.774), train_loss = 1.70422431, grad/param norm = 2.2023e-01, time/batch = 0.6474s	
1868/33650 (epoch 2.776), train_loss = 1.78881843, grad/param norm = 2.3989e-01, time/batch = 0.6424s	
1869/33650 (epoch 2.777), train_loss = 1.55171251, grad/param norm = 2.3455e-01, time/batch = 0.6340s	
1870/33650 (epoch 2.779), train_loss = 1.64015322, grad/param norm = 2.2454e-01, time/batch = 0.6323s	
1871/33650 (epoch 2.780), train_loss = 1.47661219, grad/param norm = 2.0999e-01, time/batch = 0.6312s	
1872/33650 (epoch 2.782), train_loss = 1.61069415, grad/param norm = 2.1051e-01, time/batch = 0.6322s	
1873/33650 (epoch 2.783), train_loss = 1.46810930, grad/param norm = 2.0230e-01, time/batch = 0.6280s	
1874/33650 (epoch 2.785), train_loss = 1.95277143, grad/param norm = 2.7450e-01, time/batch = 0.6279s	
1875/33650 (epoch 2.786), train_loss = 1.57066953, grad/param norm = 2.4554e-01, time/batch = 0.6296s	
1876/33650 (epoch 2.788), train_loss = 1.63405200, grad/param norm = 2.4962e-01, time/batch = 0.6511s	
1877/33650 (epoch 2.789), train_loss = 1.68098286, grad/param norm = 2.1058e-01, time/batch = 0.6427s	
1878/33650 (epoch 2.790), train_loss = 1.74753118, grad/param norm = 2.2451e-01, time/batch = 0.6320s	
1879/33650 (epoch 2.792), train_loss = 1.79536952, grad/param norm = 2.5753e-01, time/batch = 0.6280s	
1880/33650 (epoch 2.793), train_loss = 1.72562406, grad/param norm = 2.5075e-01, time/batch = 0.6279s	
1881/33650 (epoch 2.795), train_loss = 1.76801550, grad/param norm = 2.0574e-01, time/batch = 0.6310s	
1882/33650 (epoch 2.796), train_loss = 1.55971840, grad/param norm = 1.9691e-01, time/batch = 0.6302s	
1883/33650 (epoch 2.798), train_loss = 1.57761639, grad/param norm = 2.0348e-01, time/batch = 0.6309s	
1884/33650 (epoch 2.799), train_loss = 1.65249310, grad/param norm = 2.0272e-01, time/batch = 0.6325s	
1885/33650 (epoch 2.801), train_loss = 1.72269720, grad/param norm = 2.1252e-01, time/batch = 0.6308s	
1886/33650 (epoch 2.802), train_loss = 1.82396121, grad/param norm = 2.0118e-01, time/batch = 0.6282s	
1887/33650 (epoch 2.804), train_loss = 1.67694140, grad/param norm = 2.2214e-01, time/batch = 0.6288s	
1888/33650 (epoch 2.805), train_loss = 1.60976420, grad/param norm = 2.1000e-01, time/batch = 0.6278s	
1889/33650 (epoch 2.807), train_loss = 2.01663756, grad/param norm = 2.7198e-01, time/batch = 0.6283s	
1890/33650 (epoch 2.808), train_loss = 1.83921191, grad/param norm = 2.2631e-01, time/batch = 0.6298s	
1891/33650 (epoch 2.810), train_loss = 1.70484125, grad/param norm = 2.1491e-01, time/batch = 0.6364s	
1892/33650 (epoch 2.811), train_loss = 1.74418456, grad/param norm = 2.2881e-01, time/batch = 0.6305s	
1893/33650 (epoch 2.813), train_loss = 1.75999585, grad/param norm = 2.8744e-01, time/batch = 0.6299s	
1894/33650 (epoch 2.814), train_loss = 1.81733246, grad/param norm = 2.6918e-01, time/batch = 0.6288s	
1895/33650 (epoch 2.816), train_loss = 1.68177595, grad/param norm = 2.3885e-01, time/batch = 0.6283s	
1896/33650 (epoch 2.817), train_loss = 1.90219450, grad/param norm = 2.4762e-01, time/batch = 0.6308s	
1897/33650 (epoch 2.819), train_loss = 1.82530588, grad/param norm = 2.2650e-01, time/batch = 0.6674s	
1898/33650 (epoch 2.820), train_loss = 1.79966411, grad/param norm = 2.3139e-01, time/batch = 0.6460s	
1899/33650 (epoch 2.822), train_loss = 1.91095847, grad/param norm = 2.3729e-01, time/batch = 0.6302s	
1900/33650 (epoch 2.823), train_loss = 1.55374021, grad/param norm = 2.1681e-01, time/batch = 0.6301s	
1901/33650 (epoch 2.825), train_loss = 1.64024498, grad/param norm = 2.0753e-01, time/batch = 0.6329s	
1902/33650 (epoch 2.826), train_loss = 1.73869864, grad/param norm = 2.2393e-01, time/batch = 0.6310s	
1903/33650 (epoch 2.828), train_loss = 2.01427838, grad/param norm = 2.6272e-01, time/batch = 0.6316s	
1904/33650 (epoch 2.829), train_loss = 1.57899977, grad/param norm = 2.4602e-01, time/batch = 0.6326s	
1905/33650 (epoch 2.831), train_loss = 1.86319259, grad/param norm = 2.1980e-01, time/batch = 0.6373s	
1906/33650 (epoch 2.832), train_loss = 1.76471322, grad/param norm = 2.1795e-01, time/batch = 0.6313s	
1907/33650 (epoch 2.834), train_loss = 1.79459724, grad/param norm = 2.1943e-01, time/batch = 0.6296s	
1908/33650 (epoch 2.835), train_loss = 1.99603327, grad/param norm = 2.4548e-01, time/batch = 0.6266s	
1909/33650 (epoch 2.837), train_loss = 1.70841353, grad/param norm = 2.3048e-01, time/batch = 0.6287s	
1910/33650 (epoch 2.838), train_loss = 1.68708162, grad/param norm = 2.1104e-01, time/batch = 0.6259s	
1911/33650 (epoch 2.840), train_loss = 1.79240360, grad/param norm = 2.0002e-01, time/batch = 0.6327s	
1912/33650 (epoch 2.841), train_loss = 1.57093673, grad/param norm = 1.9672e-01, time/batch = 0.6481s	
1913/33650 (epoch 2.842), train_loss = 1.56456845, grad/param norm = 2.3153e-01, time/batch = 0.6675s	
1914/33650 (epoch 2.844), train_loss = 1.92046957, grad/param norm = 2.5393e-01, time/batch = 0.6297s	
1915/33650 (epoch 2.845), train_loss = 1.52669940, grad/param norm = 2.1154e-01, time/batch = 0.6283s	
1916/33650 (epoch 2.847), train_loss = 1.49897015, grad/param norm = 1.9041e-01, time/batch = 0.6268s	
1917/33650 (epoch 2.848), train_loss = 1.62439613, grad/param norm = 2.3050e-01, time/batch = 0.6270s	
1918/33650 (epoch 2.850), train_loss = 1.73704798, grad/param norm = 2.3311e-01, time/batch = 0.6283s	
1919/33650 (epoch 2.851), train_loss = 1.47071691, grad/param norm = 1.8520e-01, time/batch = 0.6297s	
1920/33650 (epoch 2.853), train_loss = 1.69597614, grad/param norm = 2.0640e-01, time/batch = 0.6273s	
1921/33650 (epoch 2.854), train_loss = 1.85042401, grad/param norm = 2.5598e-01, time/batch = 0.6305s	
1922/33650 (epoch 2.856), train_loss = 1.38446721, grad/param norm = 2.2293e-01, time/batch = 0.6284s	
1923/33650 (epoch 2.857), train_loss = 1.57124654, grad/param norm = 1.8346e-01, time/batch = 0.6279s	
1924/33650 (epoch 2.859), train_loss = 1.55391434, grad/param norm = 2.0717e-01, time/batch = 0.6402s	
1925/33650 (epoch 2.860), train_loss = 1.41037837, grad/param norm = 1.9192e-01, time/batch = 0.6442s	
1926/33650 (epoch 2.862), train_loss = 1.47734507, grad/param norm = 2.0654e-01, time/batch = 0.6318s	
1927/33650 (epoch 2.863), train_loss = 1.78770502, grad/param norm = 2.9049e-01, time/batch = 0.6266s	
1928/33650 (epoch 2.865), train_loss = 1.55161919, grad/param norm = 2.3921e-01, time/batch = 0.6426s	
1929/33650 (epoch 2.866), train_loss = 1.60982770, grad/param norm = 2.3257e-01, time/batch = 0.6336s	
1930/33650 (epoch 2.868), train_loss = 1.54744514, grad/param norm = 2.1710e-01, time/batch = 0.6299s	
1931/33650 (epoch 2.869), train_loss = 1.77343192, grad/param norm = 2.1909e-01, time/batch = 0.6329s	
1932/33650 (epoch 2.871), train_loss = 1.53232065, grad/param norm = 2.2294e-01, time/batch = 0.6330s	
1933/33650 (epoch 2.872), train_loss = 1.62600819, grad/param norm = 2.3863e-01, time/batch = 0.6675s	
1934/33650 (epoch 2.874), train_loss = 1.70987284, grad/param norm = 2.1960e-01, time/batch = 0.6466s	
1935/33650 (epoch 2.875), train_loss = 1.50284300, grad/param norm = 1.8896e-01, time/batch = 0.6281s	
1936/33650 (epoch 2.877), train_loss = 1.77249848, grad/param norm = 2.3621e-01, time/batch = 0.6280s	
1937/33650 (epoch 2.878), train_loss = 1.34656533, grad/param norm = 2.2440e-01, time/batch = 0.6291s	
1938/33650 (epoch 2.880), train_loss = 1.61656601, grad/param norm = 2.3244e-01, time/batch = 0.6283s	
1939/33650 (epoch 2.881), train_loss = 1.59112354, grad/param norm = 2.1322e-01, time/batch = 0.6300s	
1940/33650 (epoch 2.883), train_loss = 1.64679352, grad/param norm = 2.1243e-01, time/batch = 0.6326s	
1941/33650 (epoch 2.884), train_loss = 1.78249247, grad/param norm = 2.2431e-01, time/batch = 0.6317s	
1942/33650 (epoch 2.886), train_loss = 1.72936704, grad/param norm = 2.2857e-01, time/batch = 0.6296s	
1943/33650 (epoch 2.887), train_loss = 1.53245728, grad/param norm = 2.1019e-01, time/batch = 0.6287s	
1944/33650 (epoch 2.889), train_loss = 1.79319871, grad/param norm = 2.3440e-01, time/batch = 0.6283s	
1945/33650 (epoch 2.890), train_loss = 1.70288148, grad/param norm = 2.1764e-01, time/batch = 0.6269s	
1946/33650 (epoch 2.892), train_loss = 1.70884382, grad/param norm = 2.1625e-01, time/batch = 0.6338s	
1947/33650 (epoch 2.893), train_loss = 1.72685195, grad/param norm = 2.2877e-01, time/batch = 0.6383s	
1948/33650 (epoch 2.895), train_loss = 1.72336441, grad/param norm = 2.1941e-01, time/batch = 0.6533s	
1949/33650 (epoch 2.896), train_loss = 1.56786201, grad/param norm = 2.3282e-01, time/batch = 0.6307s	
1950/33650 (epoch 2.897), train_loss = 1.59877655, grad/param norm = 2.1018e-01, time/batch = 0.6491s	
1951/33650 (epoch 2.899), train_loss = 1.54122557, grad/param norm = 2.3711e-01, time/batch = 0.6314s	
1952/33650 (epoch 2.900), train_loss = 1.35188078, grad/param norm = 1.8934e-01, time/batch = 0.6290s	
1953/33650 (epoch 2.902), train_loss = 1.61154403, grad/param norm = 2.0265e-01, time/batch = 0.6555s	
1954/33650 (epoch 2.903), train_loss = 1.62351612, grad/param norm = 2.3534e-01, time/batch = 0.6628s	
1955/33650 (epoch 2.905), train_loss = 1.93223315, grad/param norm = 2.4396e-01, time/batch = 0.6286s	
1956/33650 (epoch 2.906), train_loss = 1.61614678, grad/param norm = 2.2828e-01, time/batch = 0.6313s	
1957/33650 (epoch 2.908), train_loss = 1.52164231, grad/param norm = 1.9050e-01, time/batch = 0.6312s	
1958/33650 (epoch 2.909), train_loss = 1.57541815, grad/param norm = 1.8562e-01, time/batch = 0.6336s	
1959/33650 (epoch 2.911), train_loss = 1.53183273, grad/param norm = 2.2597e-01, time/batch = 0.6303s	
1960/33650 (epoch 2.912), train_loss = 1.51927812, grad/param norm = 1.9922e-01, time/batch = 0.6253s	
1961/33650 (epoch 2.914), train_loss = 1.61337192, grad/param norm = 2.0964e-01, time/batch = 0.6293s	
1962/33650 (epoch 2.915), train_loss = 1.78224066, grad/param norm = 2.2668e-01, time/batch = 0.6324s	
1963/33650 (epoch 2.917), train_loss = 1.59476350, grad/param norm = 2.5286e-01, time/batch = 0.6415s	
1964/33650 (epoch 2.918), train_loss = 1.38992905, grad/param norm = 2.1593e-01, time/batch = 0.6515s	
1965/33650 (epoch 2.920), train_loss = 1.58167479, grad/param norm = 2.0107e-01, time/batch = 0.6389s	
1966/33650 (epoch 2.921), train_loss = 1.49914877, grad/param norm = 1.9886e-01, time/batch = 0.6273s	
1967/33650 (epoch 2.923), train_loss = 1.48735705, grad/param norm = 2.0420e-01, time/batch = 0.6262s	
1968/33650 (epoch 2.924), train_loss = 1.68999790, grad/param norm = 2.0248e-01, time/batch = 0.6249s	
1969/33650 (epoch 2.926), train_loss = 1.79438761, grad/param norm = 2.3545e-01, time/batch = 0.6279s	
1970/33650 (epoch 2.927), train_loss = 1.63130688, grad/param norm = 2.0605e-01, time/batch = 0.6294s	
1971/33650 (epoch 2.929), train_loss = 1.55719773, grad/param norm = 2.0397e-01, time/batch = 0.6334s	
1972/33650 (epoch 2.930), train_loss = 1.55132091, grad/param norm = 2.2049e-01, time/batch = 0.6280s	
1973/33650 (epoch 2.932), train_loss = 1.59506424, grad/param norm = 2.0602e-01, time/batch = 0.6359s	
1974/33650 (epoch 2.933), train_loss = 1.48690327, grad/param norm = 1.9617e-01, time/batch = 0.6708s	
1975/33650 (epoch 2.935), train_loss = 1.54146709, grad/param norm = 2.1266e-01, time/batch = 0.6374s	
1976/33650 (epoch 2.936), train_loss = 1.49309996, grad/param norm = 2.0096e-01, time/batch = 0.6262s	
1977/33650 (epoch 2.938), train_loss = 1.40461771, grad/param norm = 2.0299e-01, time/batch = 0.6264s	
1978/33650 (epoch 2.939), train_loss = 1.65969147, grad/param norm = 2.2365e-01, time/batch = 0.6330s	
1979/33650 (epoch 2.941), train_loss = 1.67949164, grad/param norm = 2.1996e-01, time/batch = 0.6270s	
1980/33650 (epoch 2.942), train_loss = 1.73614454, grad/param norm = 2.1240e-01, time/batch = 0.6275s	
1981/33650 (epoch 2.944), train_loss = 1.66673000, grad/param norm = 2.1013e-01, time/batch = 0.6304s	
1982/33650 (epoch 2.945), train_loss = 1.69232175, grad/param norm = 2.2020e-01, time/batch = 0.6265s	
1983/33650 (epoch 2.947), train_loss = 1.90697842, grad/param norm = 2.3256e-01, time/batch = 0.6273s	
1984/33650 (epoch 2.948), train_loss = 1.75829435, grad/param norm = 2.1804e-01, time/batch = 0.6281s	
1985/33650 (epoch 2.949), train_loss = 1.53156685, grad/param norm = 2.1938e-01, time/batch = 0.6307s	
1986/33650 (epoch 2.951), train_loss = 1.70325957, grad/param norm = 2.2565e-01, time/batch = 0.6270s	
1987/33650 (epoch 2.952), train_loss = 1.78346811, grad/param norm = 2.4815e-01, time/batch = 0.6279s	
1988/33650 (epoch 2.954), train_loss = 1.73628823, grad/param norm = 2.3688e-01, time/batch = 0.6265s	
1989/33650 (epoch 2.955), train_loss = 1.80052854, grad/param norm = 2.5403e-01, time/batch = 0.6293s	
1990/33650 (epoch 2.957), train_loss = 1.73240215, grad/param norm = 2.3198e-01, time/batch = 0.6627s	
1991/33650 (epoch 2.958), train_loss = 1.26239216, grad/param norm = 1.7289e-01, time/batch = 0.6421s	
1992/33650 (epoch 2.960), train_loss = 1.42785738, grad/param norm = 1.7328e-01, time/batch = 0.6304s	
1993/33650 (epoch 2.961), train_loss = 1.61470837, grad/param norm = 2.0668e-01, time/batch = 0.6285s	
1994/33650 (epoch 2.963), train_loss = 1.60929062, grad/param norm = 2.1139e-01, time/batch = 0.6607s	
1995/33650 (epoch 2.964), train_loss = 1.61202540, grad/param norm = 1.9447e-01, time/batch = 0.6547s	
1996/33650 (epoch 2.966), train_loss = 1.65301699, grad/param norm = 2.3207e-01, time/batch = 0.6282s	
1997/33650 (epoch 2.967), train_loss = 1.67172992, grad/param norm = 2.2764e-01, time/batch = 0.6267s	
1998/33650 (epoch 2.969), train_loss = 1.50068079, grad/param norm = 2.0495e-01, time/batch = 0.6366s	
1999/33650 (epoch 2.970), train_loss = 1.68401795, grad/param norm = 2.0602e-01, time/batch = 0.6329s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch2.97_1.7617.t7	
2000/33650 (epoch 2.972), train_loss = 1.95802479, grad/param norm = 2.3255e-01, time/batch = 0.6286s	
2001/33650 (epoch 2.973), train_loss = 1.60198901, grad/param norm = 2.4022e-01, time/batch = 0.6362s	
2002/33650 (epoch 2.975), train_loss = 1.57264178, grad/param norm = 2.2172e-01, time/batch = 0.6292s	
2003/33650 (epoch 2.976), train_loss = 1.54648338, grad/param norm = 2.0540e-01, time/batch = 0.6292s	
2004/33650 (epoch 2.978), train_loss = 1.51448579, grad/param norm = 2.3746e-01, time/batch = 0.6295s	
2005/33650 (epoch 2.979), train_loss = 1.71454429, grad/param norm = 2.5353e-01, time/batch = 0.6439s	
2006/33650 (epoch 2.981), train_loss = 1.55929676, grad/param norm = 1.9437e-01, time/batch = 0.6335s	
2007/33650 (epoch 2.982), train_loss = 1.70296887, grad/param norm = 2.2563e-01, time/batch = 0.6356s	
2008/33650 (epoch 2.984), train_loss = 1.39691706, grad/param norm = 1.9522e-01, time/batch = 0.6415s	
2009/33650 (epoch 2.985), train_loss = 1.48186018, grad/param norm = 1.9486e-01, time/batch = 0.6521s	
2010/33650 (epoch 2.987), train_loss = 1.60095185, grad/param norm = 2.0326e-01, time/batch = 0.6571s	
2011/33650 (epoch 2.988), train_loss = 1.72051008, grad/param norm = 2.0475e-01, time/batch = 0.6405s	
2012/33650 (epoch 2.990), train_loss = 1.88490132, grad/param norm = 2.4570e-01, time/batch = 0.6347s	
2013/33650 (epoch 2.991), train_loss = 1.77374914, grad/param norm = 2.2401e-01, time/batch = 0.6311s	
2014/33650 (epoch 2.993), train_loss = 1.75863214, grad/param norm = 2.1440e-01, time/batch = 0.6306s	
2015/33650 (epoch 2.994), train_loss = 1.59437587, grad/param norm = 2.3139e-01, time/batch = 0.6303s	
2016/33650 (epoch 2.996), train_loss = 1.54691364, grad/param norm = 2.1219e-01, time/batch = 0.6297s	
2017/33650 (epoch 2.997), train_loss = 1.67172753, grad/param norm = 2.1889e-01, time/batch = 0.6298s	
2018/33650 (epoch 2.999), train_loss = 1.44245692, grad/param norm = 2.1142e-01, time/batch = 0.6294s	
2019/33650 (epoch 3.000), train_loss = 1.78584071, grad/param norm = 2.1963e-01, time/batch = 0.6312s	
2020/33650 (epoch 3.001), train_loss = 1.77214716, grad/param norm = 2.2083e-01, time/batch = 0.6304s	
2021/33650 (epoch 3.003), train_loss = 1.87223509, grad/param norm = 2.2512e-01, time/batch = 0.6330s	
2022/33650 (epoch 3.004), train_loss = 1.72160854, grad/param norm = 2.2307e-01, time/batch = 0.6255s	
2023/33650 (epoch 3.006), train_loss = 1.54812820, grad/param norm = 2.0468e-01, time/batch = 0.6275s	
2024/33650 (epoch 3.007), train_loss = 1.57463076, grad/param norm = 2.1637e-01, time/batch = 0.6268s	
2025/33650 (epoch 3.009), train_loss = 1.58856375, grad/param norm = 2.1051e-01, time/batch = 0.6642s	
2026/33650 (epoch 3.010), train_loss = 1.77350745, grad/param norm = 2.4438e-01, time/batch = 0.6493s	
2027/33650 (epoch 3.012), train_loss = 1.61993629, grad/param norm = 2.2798e-01, time/batch = 0.6256s	
2028/33650 (epoch 3.013), train_loss = 1.72736011, grad/param norm = 2.1423e-01, time/batch = 0.6332s	
2029/33650 (epoch 3.015), train_loss = 1.47963995, grad/param norm = 2.1326e-01, time/batch = 0.6240s	
2030/33650 (epoch 3.016), train_loss = 1.62877956, grad/param norm = 2.1658e-01, time/batch = 0.6275s	
2031/33650 (epoch 3.018), train_loss = 1.62886328, grad/param norm = 2.1858e-01, time/batch = 0.6359s	
2032/33650 (epoch 3.019), train_loss = 1.54307379, grad/param norm = 2.2269e-01, time/batch = 0.6496s	
2033/33650 (epoch 3.021), train_loss = 1.77440972, grad/param norm = 2.0626e-01, time/batch = 0.6269s	
2034/33650 (epoch 3.022), train_loss = 1.61280098, grad/param norm = 2.0898e-01, time/batch = 0.6381s	
2035/33650 (epoch 3.024), train_loss = 1.55647371, grad/param norm = 2.2397e-01, time/batch = 0.6426s	
2036/33650 (epoch 3.025), train_loss = 1.56676537, grad/param norm = 2.3722e-01, time/batch = 0.6363s	
2037/33650 (epoch 3.027), train_loss = 1.78204018, grad/param norm = 2.2039e-01, time/batch = 0.6291s	
2038/33650 (epoch 3.028), train_loss = 1.75978166, grad/param norm = 2.1222e-01, time/batch = 0.6270s	
2039/33650 (epoch 3.030), train_loss = 1.53256796, grad/param norm = 2.0085e-01, time/batch = 0.6270s	
2040/33650 (epoch 3.031), train_loss = 1.31204031, grad/param norm = 2.0700e-01, time/batch = 0.6272s	
2041/33650 (epoch 3.033), train_loss = 1.49410894, grad/param norm = 1.8663e-01, time/batch = 0.6299s	
2042/33650 (epoch 3.034), train_loss = 1.59916693, grad/param norm = 2.0092e-01, time/batch = 0.6289s	
2043/33650 (epoch 3.036), train_loss = 1.78538101, grad/param norm = 2.1974e-01, time/batch = 0.6280s	
2044/33650 (epoch 3.037), train_loss = 1.53108413, grad/param norm = 2.2266e-01, time/batch = 0.6301s	
2045/33650 (epoch 3.039), train_loss = 1.76000657, grad/param norm = 2.1418e-01, time/batch = 0.6315s	
2046/33650 (epoch 3.040), train_loss = 1.75866416, grad/param norm = 2.1626e-01, time/batch = 0.6253s	
2047/33650 (epoch 3.042), train_loss = 1.83183756, grad/param norm = 2.2600e-01, time/batch = 0.6261s	
2048/33650 (epoch 3.043), train_loss = 1.45302597, grad/param norm = 2.3928e-01, time/batch = 0.6341s	
2049/33650 (epoch 3.045), train_loss = 1.53093490, grad/param norm = 2.0334e-01, time/batch = 0.6415s	
2050/33650 (epoch 3.046), train_loss = 1.77517911, grad/param norm = 2.0546e-01, time/batch = 0.6280s	
2051/33650 (epoch 3.048), train_loss = 1.69168743, grad/param norm = 2.1402e-01, time/batch = 0.6279s	
2052/33650 (epoch 3.049), train_loss = 1.73432776, grad/param norm = 2.2532e-01, time/batch = 0.6361s	
2053/33650 (epoch 3.051), train_loss = 1.72355550, grad/param norm = 2.0559e-01, time/batch = 0.6282s	
2054/33650 (epoch 3.052), train_loss = 1.81514587, grad/param norm = 2.0827e-01, time/batch = 0.6263s	
2055/33650 (epoch 3.053), train_loss = 1.59879694, grad/param norm = 1.9868e-01, time/batch = 0.6283s	
2056/33650 (epoch 3.055), train_loss = 1.41341885, grad/param norm = 2.1010e-01, time/batch = 0.6285s	
2057/33650 (epoch 3.056), train_loss = 1.39613600, grad/param norm = 1.7830e-01, time/batch = 0.6407s	
2058/33650 (epoch 3.058), train_loss = 1.75045289, grad/param norm = 2.1322e-01, time/batch = 0.6267s	
2059/33650 (epoch 3.059), train_loss = 1.79931396, grad/param norm = 2.2593e-01, time/batch = 0.6289s	
2060/33650 (epoch 3.061), train_loss = 1.66236610, grad/param norm = 2.3410e-01, time/batch = 0.6263s	
2061/33650 (epoch 3.062), train_loss = 1.65564675, grad/param norm = 2.1410e-01, time/batch = 0.6596s	
2062/33650 (epoch 3.064), train_loss = 1.56312650, grad/param norm = 1.9030e-01, time/batch = 0.6579s	
2063/33650 (epoch 3.065), train_loss = 1.59154863, grad/param norm = 2.2805e-01, time/batch = 0.6284s	
2064/33650 (epoch 3.067), train_loss = 1.53217964, grad/param norm = 2.2173e-01, time/batch = 0.6297s	
2065/33650 (epoch 3.068), train_loss = 1.66480772, grad/param norm = 2.1099e-01, time/batch = 0.6265s	
2066/33650 (epoch 3.070), train_loss = 1.55248487, grad/param norm = 2.0632e-01, time/batch = 0.6280s	
2067/33650 (epoch 3.071), train_loss = 1.60933680, grad/param norm = 2.2590e-01, time/batch = 0.6326s	
2068/33650 (epoch 3.073), train_loss = 1.74484470, grad/param norm = 2.5423e-01, time/batch = 0.6487s	
2069/33650 (epoch 3.074), train_loss = 1.72531464, grad/param norm = 2.4811e-01, time/batch = 0.6297s	
2070/33650 (epoch 3.076), train_loss = 1.74763377, grad/param norm = 2.2076e-01, time/batch = 0.6262s	
2071/33650 (epoch 3.077), train_loss = 1.55691420, grad/param norm = 2.1220e-01, time/batch = 0.6296s	
2072/33650 (epoch 3.079), train_loss = 1.58947790, grad/param norm = 2.1142e-01, time/batch = 0.6286s	
2073/33650 (epoch 3.080), train_loss = 1.62314557, grad/param norm = 2.3070e-01, time/batch = 0.6272s	
2074/33650 (epoch 3.082), train_loss = 1.77027808, grad/param norm = 2.3440e-01, time/batch = 0.6351s	
2075/33650 (epoch 3.083), train_loss = 1.74108336, grad/param norm = 2.1461e-01, time/batch = 0.6304s	
2076/33650 (epoch 3.085), train_loss = 1.69762404, grad/param norm = 2.0429e-01, time/batch = 0.6295s	
2077/33650 (epoch 3.086), train_loss = 1.74733099, grad/param norm = 2.4669e-01, time/batch = 0.6322s	
2078/33650 (epoch 3.088), train_loss = 1.67162480, grad/param norm = 2.1328e-01, time/batch = 0.6370s	
2079/33650 (epoch 3.089), train_loss = 1.69302069, grad/param norm = 2.0627e-01, time/batch = 0.6301s	
2080/33650 (epoch 3.091), train_loss = 1.51808272, grad/param norm = 2.2202e-01, time/batch = 0.6383s	
2081/33650 (epoch 3.092), train_loss = 1.54892157, grad/param norm = 2.2514e-01, time/batch = 0.6486s	
2082/33650 (epoch 3.094), train_loss = 1.67988576, grad/param norm = 2.1049e-01, time/batch = 0.6690s	
2083/33650 (epoch 3.095), train_loss = 1.72680553, grad/param norm = 2.3557e-01, time/batch = 0.6389s	
2084/33650 (epoch 3.097), train_loss = 1.60267268, grad/param norm = 2.2837e-01, time/batch = 0.6416s	
2085/33650 (epoch 3.098), train_loss = 1.39417164, grad/param norm = 1.9197e-01, time/batch = 0.6616s	
2086/33650 (epoch 3.100), train_loss = 1.52657900, grad/param norm = 2.2682e-01, time/batch = 0.6345s	
2087/33650 (epoch 3.101), train_loss = 1.51686271, grad/param norm = 2.2194e-01, time/batch = 0.6377s	
2088/33650 (epoch 3.103), train_loss = 1.52193179, grad/param norm = 2.2051e-01, time/batch = 0.6573s	
2089/33650 (epoch 3.104), train_loss = 1.63257579, grad/param norm = 2.0871e-01, time/batch = 0.6623s	
2090/33650 (epoch 3.105), train_loss = 1.61783044, grad/param norm = 2.1559e-01, time/batch = 0.6558s	
2091/33650 (epoch 3.107), train_loss = 1.42006817, grad/param norm = 1.9321e-01, time/batch = 0.6401s	
2092/33650 (epoch 3.108), train_loss = 1.64889983, grad/param norm = 2.4968e-01, time/batch = 0.6306s	
2093/33650 (epoch 3.110), train_loss = 1.79715078, grad/param norm = 2.5601e-01, time/batch = 0.6287s	
2094/33650 (epoch 3.111), train_loss = 1.51365467, grad/param norm = 2.2570e-01, time/batch = 0.6271s	
2095/33650 (epoch 3.113), train_loss = 1.55358989, grad/param norm = 2.1567e-01, time/batch = 0.6315s	
2096/33650 (epoch 3.114), train_loss = 1.71426972, grad/param norm = 2.1709e-01, time/batch = 0.6284s	
2097/33650 (epoch 3.116), train_loss = 1.34161830, grad/param norm = 2.0432e-01, time/batch = 0.6630s	
2098/33650 (epoch 3.117), train_loss = 1.66897517, grad/param norm = 2.0058e-01, time/batch = 0.6530s	
2099/33650 (epoch 3.119), train_loss = 1.50010291, grad/param norm = 1.9487e-01, time/batch = 0.6266s	
2100/33650 (epoch 3.120), train_loss = 1.56801676, grad/param norm = 2.4866e-01, time/batch = 0.6256s	
2101/33650 (epoch 3.122), train_loss = 1.48859710, grad/param norm = 2.1763e-01, time/batch = 0.6383s	
2102/33650 (epoch 3.123), train_loss = 1.52143539, grad/param norm = 1.8036e-01, time/batch = 0.6679s	
2103/33650 (epoch 3.125), train_loss = 1.74108901, grad/param norm = 2.3703e-01, time/batch = 0.6397s	
2104/33650 (epoch 3.126), train_loss = 1.80530219, grad/param norm = 2.0564e-01, time/batch = 0.6354s	
2105/33650 (epoch 3.128), train_loss = 1.71766856, grad/param norm = 2.1332e-01, time/batch = 0.6281s	
2106/33650 (epoch 3.129), train_loss = 1.75395297, grad/param norm = 2.1426e-01, time/batch = 0.6265s	
2107/33650 (epoch 3.131), train_loss = 1.67737244, grad/param norm = 2.1239e-01, time/batch = 0.6270s	
2108/33650 (epoch 3.132), train_loss = 1.62804191, grad/param norm = 1.9870e-01, time/batch = 0.6269s	
2109/33650 (epoch 3.134), train_loss = 1.85968658, grad/param norm = 2.1942e-01, time/batch = 0.6286s	
2110/33650 (epoch 3.135), train_loss = 1.50813524, grad/param norm = 2.1600e-01, time/batch = 0.6292s	
2111/33650 (epoch 3.137), train_loss = 1.56406897, grad/param norm = 1.9022e-01, time/batch = 0.6328s	
2112/33650 (epoch 3.138), train_loss = 1.67734476, grad/param norm = 2.0070e-01, time/batch = 0.6322s	
2113/33650 (epoch 3.140), train_loss = 1.61834067, grad/param norm = 2.1191e-01, time/batch = 0.6281s	
2114/33650 (epoch 3.141), train_loss = 1.78658100, grad/param norm = 2.2236e-01, time/batch = 0.6264s	
2115/33650 (epoch 3.143), train_loss = 1.91144406, grad/param norm = 2.3746e-01, time/batch = 0.6265s	
2116/33650 (epoch 3.144), train_loss = 1.84183395, grad/param norm = 2.2951e-01, time/batch = 0.6271s	
2117/33650 (epoch 3.146), train_loss = 1.66267323, grad/param norm = 2.2412e-01, time/batch = 0.6401s	
2118/33650 (epoch 3.147), train_loss = 1.56825987, grad/param norm = 2.1527e-01, time/batch = 0.6399s	
2119/33650 (epoch 3.149), train_loss = 1.45425821, grad/param norm = 1.9920e-01, time/batch = 0.6458s	
2120/33650 (epoch 3.150), train_loss = 1.46452087, grad/param norm = 1.8118e-01, time/batch = 0.6504s	
2121/33650 (epoch 3.152), train_loss = 1.56646770, grad/param norm = 2.0882e-01, time/batch = 0.6459s	
2122/33650 (epoch 3.153), train_loss = 1.61346540, grad/param norm = 2.0973e-01, time/batch = 0.6754s	
2123/33650 (epoch 3.155), train_loss = 1.49231126, grad/param norm = 1.9068e-01, time/batch = 0.6631s	
2124/33650 (epoch 3.156), train_loss = 1.53168049, grad/param norm = 2.1079e-01, time/batch = 0.6416s	
2125/33650 (epoch 3.158), train_loss = 1.67218272, grad/param norm = 2.3127e-01, time/batch = 0.6496s	
2126/33650 (epoch 3.159), train_loss = 1.34720759, grad/param norm = 2.0429e-01, time/batch = 0.6607s	
2127/33650 (epoch 3.160), train_loss = 1.43784273, grad/param norm = 1.8006e-01, time/batch = 0.6438s	
2128/33650 (epoch 3.162), train_loss = 1.51663866, grad/param norm = 2.3600e-01, time/batch = 0.6650s	
2129/33650 (epoch 3.163), train_loss = 1.71101722, grad/param norm = 2.2635e-01, time/batch = 0.6425s	
2130/33650 (epoch 3.165), train_loss = 1.44249919, grad/param norm = 1.7972e-01, time/batch = 0.6402s	
2131/33650 (epoch 3.166), train_loss = 1.41326686, grad/param norm = 2.0482e-01, time/batch = 0.6419s	
2132/33650 (epoch 3.168), train_loss = 1.73423582, grad/param norm = 2.2482e-01, time/batch = 0.6400s	
2133/33650 (epoch 3.169), train_loss = 1.50328394, grad/param norm = 2.1481e-01, time/batch = 0.6402s	
2134/33650 (epoch 3.171), train_loss = 1.64035307, grad/param norm = 2.0501e-01, time/batch = 0.6433s	
2135/33650 (epoch 3.172), train_loss = 1.51291268, grad/param norm = 1.9068e-01, time/batch = 0.6446s	
2136/33650 (epoch 3.174), train_loss = 1.48202890, grad/param norm = 1.9366e-01, time/batch = 0.6479s	
2137/33650 (epoch 3.175), train_loss = 1.45582484, grad/param norm = 2.0666e-01, time/batch = 0.6381s	
2138/33650 (epoch 3.177), train_loss = 1.64494810, grad/param norm = 1.8640e-01, time/batch = 0.6370s	
2139/33650 (epoch 3.178), train_loss = 1.53787597, grad/param norm = 2.2107e-01, time/batch = 0.6377s	
2140/33650 (epoch 3.180), train_loss = 1.51545472, grad/param norm = 2.3283e-01, time/batch = 0.6442s	
2141/33650 (epoch 3.181), train_loss = 1.36243314, grad/param norm = 1.8725e-01, time/batch = 0.6533s	
2142/33650 (epoch 3.183), train_loss = 1.54151876, grad/param norm = 2.3152e-01, time/batch = 0.6785s	
2143/33650 (epoch 3.184), train_loss = 1.60999385, grad/param norm = 2.3406e-01, time/batch = 0.6442s	
2144/33650 (epoch 3.186), train_loss = 1.64292208, grad/param norm = 2.1475e-01, time/batch = 0.6437s	
2145/33650 (epoch 3.187), train_loss = 1.74224501, grad/param norm = 2.3741e-01, time/batch = 0.6405s	
2146/33650 (epoch 3.189), train_loss = 1.71969265, grad/param norm = 2.2505e-01, time/batch = 0.6474s	
2147/33650 (epoch 3.190), train_loss = 1.71809701, grad/param norm = 2.3798e-01, time/batch = 0.6504s	
2148/33650 (epoch 3.192), train_loss = 1.80255665, grad/param norm = 2.1833e-01, time/batch = 0.6740s	
2149/33650 (epoch 3.193), train_loss = 1.75327850, grad/param norm = 2.3034e-01, time/batch = 0.6729s	
2150/33650 (epoch 3.195), train_loss = 1.43140325, grad/param norm = 1.8710e-01, time/batch = 0.6680s	
2151/33650 (epoch 3.196), train_loss = 1.35845377, grad/param norm = 2.1077e-01, time/batch = 0.6664s	
2152/33650 (epoch 3.198), train_loss = 1.61971755, grad/param norm = 2.2269e-01, time/batch = 0.6511s	
2153/33650 (epoch 3.199), train_loss = 1.71989585, grad/param norm = 2.3491e-01, time/batch = 0.6448s	
2154/33650 (epoch 3.201), train_loss = 1.70466137, grad/param norm = 2.1896e-01, time/batch = 0.6401s	
2155/33650 (epoch 3.202), train_loss = 1.57345770, grad/param norm = 1.9722e-01, time/batch = 0.6385s	
2156/33650 (epoch 3.204), train_loss = 1.69588965, grad/param norm = 2.2796e-01, time/batch = 0.6392s	
2157/33650 (epoch 3.205), train_loss = 1.59983691, grad/param norm = 2.2491e-01, time/batch = 0.6405s	
2158/33650 (epoch 3.207), train_loss = 1.64033013, grad/param norm = 2.0369e-01, time/batch = 0.6489s	
2159/33650 (epoch 3.208), train_loss = 1.60357395, grad/param norm = 2.0579e-01, time/batch = 0.6420s	
2160/33650 (epoch 3.210), train_loss = 1.27227734, grad/param norm = 2.0504e-01, time/batch = 0.6378s	
2161/33650 (epoch 3.211), train_loss = 1.61394369, grad/param norm = 2.1035e-01, time/batch = 0.6419s	
2162/33650 (epoch 3.212), train_loss = 1.62252499, grad/param norm = 2.1327e-01, time/batch = 0.6798s	
2163/33650 (epoch 3.214), train_loss = 1.71819144, grad/param norm = 2.1285e-01, time/batch = 0.6562s	
2164/33650 (epoch 3.215), train_loss = 1.39404806, grad/param norm = 1.9602e-01, time/batch = 0.6415s	
2165/33650 (epoch 3.217), train_loss = 1.59898091, grad/param norm = 2.0393e-01, time/batch = 0.6445s	
2166/33650 (epoch 3.218), train_loss = 1.72125369, grad/param norm = 1.9629e-01, time/batch = 0.6366s	
2167/33650 (epoch 3.220), train_loss = 1.54126259, grad/param norm = 1.9359e-01, time/batch = 0.6386s	
2168/33650 (epoch 3.221), train_loss = 1.73830214, grad/param norm = 2.0518e-01, time/batch = 0.6379s	
2169/33650 (epoch 3.223), train_loss = 1.38247899, grad/param norm = 1.9668e-01, time/batch = 0.6384s	
2170/33650 (epoch 3.224), train_loss = 1.57932020, grad/param norm = 2.0617e-01, time/batch = 0.6377s	
2171/33650 (epoch 3.226), train_loss = 1.98660836, grad/param norm = 2.7091e-01, time/batch = 0.6439s	
2172/33650 (epoch 3.227), train_loss = 1.77481446, grad/param norm = 2.2216e-01, time/batch = 0.6411s	
2173/33650 (epoch 3.229), train_loss = 1.63102144, grad/param norm = 1.9963e-01, time/batch = 0.6395s	
2174/33650 (epoch 3.230), train_loss = 1.82910398, grad/param norm = 2.3197e-01, time/batch = 0.6410s	
2175/33650 (epoch 3.232), train_loss = 1.61239015, grad/param norm = 2.2493e-01, time/batch = 0.6427s	
2176/33650 (epoch 3.233), train_loss = 1.70048168, grad/param norm = 2.4295e-01, time/batch = 0.6383s	
2177/33650 (epoch 3.235), train_loss = 1.60407969, grad/param norm = 2.1613e-01, time/batch = 0.6384s	
2178/33650 (epoch 3.236), train_loss = 1.50129173, grad/param norm = 2.1494e-01, time/batch = 0.6521s	
2179/33650 (epoch 3.238), train_loss = 1.65254092, grad/param norm = 1.9852e-01, time/batch = 0.6500s	
2180/33650 (epoch 3.239), train_loss = 1.48388409, grad/param norm = 2.2359e-01, time/batch = 0.6498s	
2181/33650 (epoch 3.241), train_loss = 1.54133830, grad/param norm = 1.9866e-01, time/batch = 0.6507s	
2182/33650 (epoch 3.242), train_loss = 1.47170750, grad/param norm = 2.0241e-01, time/batch = 0.6502s	
2183/33650 (epoch 3.244), train_loss = 1.61971611, grad/param norm = 2.0107e-01, time/batch = 0.6582s	
2184/33650 (epoch 3.245), train_loss = 1.44751574, grad/param norm = 2.0919e-01, time/batch = 0.6438s	
2185/33650 (epoch 3.247), train_loss = 1.58290008, grad/param norm = 2.0013e-01, time/batch = 0.6563s	
2186/33650 (epoch 3.248), train_loss = 1.61626819, grad/param norm = 2.1402e-01, time/batch = 0.6586s	
2187/33650 (epoch 3.250), train_loss = 1.64134040, grad/param norm = 1.9390e-01, time/batch = 0.6471s	
2188/33650 (epoch 3.251), train_loss = 1.77536020, grad/param norm = 2.3287e-01, time/batch = 0.6551s	
2189/33650 (epoch 3.253), train_loss = 1.43599348, grad/param norm = 2.3258e-01, time/batch = 0.6528s	
2190/33650 (epoch 3.254), train_loss = 1.53813256, grad/param norm = 2.0708e-01, time/batch = 0.6399s	
2191/33650 (epoch 3.256), train_loss = 1.64729297, grad/param norm = 2.2684e-01, time/batch = 0.6438s	
2192/33650 (epoch 3.257), train_loss = 1.90345306, grad/param norm = 2.5394e-01, time/batch = 0.6418s	
2193/33650 (epoch 3.259), train_loss = 1.33379471, grad/param norm = 1.9436e-01, time/batch = 0.6404s	
2194/33650 (epoch 3.260), train_loss = 1.78153073, grad/param norm = 2.3748e-01, time/batch = 0.6397s	
2195/33650 (epoch 3.262), train_loss = 1.64823901, grad/param norm = 2.0973e-01, time/batch = 0.6412s	
2196/33650 (epoch 3.263), train_loss = 1.62417462, grad/param norm = 2.2412e-01, time/batch = 0.6403s	
2197/33650 (epoch 3.264), train_loss = 1.57188537, grad/param norm = 1.9963e-01, time/batch = 0.6404s	
2198/33650 (epoch 3.266), train_loss = 1.54309800, grad/param norm = 2.1253e-01, time/batch = 0.6458s	
2199/33650 (epoch 3.267), train_loss = 1.57555384, grad/param norm = 2.8806e-01, time/batch = 0.6421s	
2200/33650 (epoch 3.269), train_loss = 1.74096690, grad/param norm = 2.4209e-01, time/batch = 0.6470s	
2201/33650 (epoch 3.270), train_loss = 1.54381859, grad/param norm = 2.0242e-01, time/batch = 0.6514s	
2202/33650 (epoch 3.272), train_loss = 1.58493599, grad/param norm = 1.8694e-01, time/batch = 0.6806s	
2203/33650 (epoch 3.273), train_loss = 1.78255869, grad/param norm = 2.1562e-01, time/batch = 0.6690s	
2204/33650 (epoch 3.275), train_loss = 1.74328573, grad/param norm = 2.1236e-01, time/batch = 0.6450s	
2205/33650 (epoch 3.276), train_loss = 1.75253949, grad/param norm = 2.2221e-01, time/batch = 0.6482s	
2206/33650 (epoch 3.278), train_loss = 1.89097869, grad/param norm = 2.3425e-01, time/batch = 0.6421s	
2207/33650 (epoch 3.279), train_loss = 1.51382385, grad/param norm = 2.1306e-01, time/batch = 0.6407s	
2208/33650 (epoch 3.281), train_loss = 1.66024216, grad/param norm = 2.1779e-01, time/batch = 0.6424s	
2209/33650 (epoch 3.282), train_loss = 1.68550171, grad/param norm = 1.9834e-01, time/batch = 0.6412s	
2210/33650 (epoch 3.284), train_loss = 1.73660628, grad/param norm = 2.3081e-01, time/batch = 0.6429s	
2211/33650 (epoch 3.285), train_loss = 1.70730015, grad/param norm = 2.1790e-01, time/batch = 0.6447s	
2212/33650 (epoch 3.287), train_loss = 1.60295199, grad/param norm = 2.2418e-01, time/batch = 0.6410s	
2213/33650 (epoch 3.288), train_loss = 1.62586252, grad/param norm = 2.1858e-01, time/batch = 0.6402s	
2214/33650 (epoch 3.290), train_loss = 1.56711545, grad/param norm = 2.0737e-01, time/batch = 0.6407s	
2215/33650 (epoch 3.291), train_loss = 1.41322054, grad/param norm = 1.7539e-01, time/batch = 0.6408s	
2216/33650 (epoch 3.293), train_loss = 1.66316538, grad/param norm = 2.1089e-01, time/batch = 0.6412s	
2217/33650 (epoch 3.294), train_loss = 1.42120222, grad/param norm = 1.9567e-01, time/batch = 0.6477s	
2218/33650 (epoch 3.296), train_loss = 1.34209141, grad/param norm = 1.8796e-01, time/batch = 0.6626s	
2219/33650 (epoch 3.297), train_loss = 1.65104452, grad/param norm = 2.0411e-01, time/batch = 0.6413s	
2220/33650 (epoch 3.299), train_loss = 1.43078721, grad/param norm = 1.9263e-01, time/batch = 0.6521s	
2221/33650 (epoch 3.300), train_loss = 1.58575096, grad/param norm = 1.9814e-01, time/batch = 0.6603s	
2222/33650 (epoch 3.302), train_loss = 1.52022421, grad/param norm = 1.9873e-01, time/batch = 0.6801s	
2223/33650 (epoch 3.303), train_loss = 1.65582686, grad/param norm = 2.1178e-01, time/batch = 0.6605s	
2224/33650 (epoch 3.305), train_loss = 1.68849417, grad/param norm = 2.1063e-01, time/batch = 0.6415s	
2225/33650 (epoch 3.306), train_loss = 1.51048948, grad/param norm = 2.0773e-01, time/batch = 0.6426s	
2226/33650 (epoch 3.308), train_loss = 1.55368943, grad/param norm = 1.9531e-01, time/batch = 0.6455s	
2227/33650 (epoch 3.309), train_loss = 1.68242177, grad/param norm = 2.1083e-01, time/batch = 0.6473s	
2228/33650 (epoch 3.311), train_loss = 1.69293805, grad/param norm = 2.2021e-01, time/batch = 0.6410s	
2229/33650 (epoch 3.312), train_loss = 1.50653646, grad/param norm = 1.7957e-01, time/batch = 0.6491s	
2230/33650 (epoch 3.314), train_loss = 1.31824674, grad/param norm = 1.8807e-01, time/batch = 0.6463s	
2231/33650 (epoch 3.315), train_loss = 1.60631775, grad/param norm = 2.0735e-01, time/batch = 0.6416s	
2232/33650 (epoch 3.316), train_loss = 1.58973377, grad/param norm = 2.2684e-01, time/batch = 0.6454s	
2233/33650 (epoch 3.318), train_loss = 1.45999608, grad/param norm = 1.8156e-01, time/batch = 0.6387s	
2234/33650 (epoch 3.319), train_loss = 1.49959046, grad/param norm = 1.9245e-01, time/batch = 0.6404s	
2235/33650 (epoch 3.321), train_loss = 1.57620033, grad/param norm = 1.9894e-01, time/batch = 0.6386s	
2236/33650 (epoch 3.322), train_loss = 1.58941404, grad/param norm = 2.1434e-01, time/batch = 0.6381s	
2237/33650 (epoch 3.324), train_loss = 1.68932234, grad/param norm = 2.1162e-01, time/batch = 0.6405s	
2238/33650 (epoch 3.325), train_loss = 1.66119424, grad/param norm = 2.3719e-01, time/batch = 0.6395s	
2239/33650 (epoch 3.327), train_loss = 1.44019888, grad/param norm = 2.0559e-01, time/batch = 0.6476s	
2240/33650 (epoch 3.328), train_loss = 1.62734052, grad/param norm = 2.1231e-01, time/batch = 0.6449s	
2241/33650 (epoch 3.330), train_loss = 1.49951182, grad/param norm = 2.0671e-01, time/batch = 0.6457s	
2242/33650 (epoch 3.331), train_loss = 1.34533309, grad/param norm = 1.7308e-01, time/batch = 0.6793s	
2243/33650 (epoch 3.333), train_loss = 1.61900127, grad/param norm = 2.0944e-01, time/batch = 0.6591s	
2244/33650 (epoch 3.334), train_loss = 1.60345630, grad/param norm = 1.9909e-01, time/batch = 0.6404s	
2245/33650 (epoch 3.336), train_loss = 1.62502835, grad/param norm = 2.1514e-01, time/batch = 0.6404s	
2246/33650 (epoch 3.337), train_loss = 1.29778954, grad/param norm = 1.9281e-01, time/batch = 0.6405s	
2247/33650 (epoch 3.339), train_loss = 1.55843409, grad/param norm = 2.1307e-01, time/batch = 0.6399s	
2248/33650 (epoch 3.340), train_loss = 1.86605924, grad/param norm = 2.2001e-01, time/batch = 0.6390s	
2249/33650 (epoch 3.342), train_loss = 1.29177412, grad/param norm = 1.9711e-01, time/batch = 0.6411s	
2250/33650 (epoch 3.343), train_loss = 1.64913487, grad/param norm = 2.0220e-01, time/batch = 0.6383s	
2251/33650 (epoch 3.345), train_loss = 1.57972778, grad/param norm = 2.0461e-01, time/batch = 0.6574s	
2252/33650 (epoch 3.346), train_loss = 1.20850659, grad/param norm = 2.0340e-01, time/batch = 0.6460s	
2253/33650 (epoch 3.348), train_loss = 1.45594131, grad/param norm = 2.2137e-01, time/batch = 0.6463s	
2254/33650 (epoch 3.349), train_loss = 1.37841899, grad/param norm = 2.3665e-01, time/batch = 0.6427s	
2255/33650 (epoch 3.351), train_loss = 1.69472967, grad/param norm = 1.9013e-01, time/batch = 0.6365s	
2256/33650 (epoch 3.352), train_loss = 1.52381227, grad/param norm = 1.9245e-01, time/batch = 0.6421s	
2257/33650 (epoch 3.354), train_loss = 1.93145571, grad/param norm = 2.2291e-01, time/batch = 0.6401s	
2258/33650 (epoch 3.355), train_loss = 1.68683368, grad/param norm = 2.0944e-01, time/batch = 0.6398s	
2259/33650 (epoch 3.357), train_loss = 1.38030937, grad/param norm = 2.0126e-01, time/batch = 0.6429s	
2260/33650 (epoch 3.358), train_loss = 1.69038651, grad/param norm = 2.0953e-01, time/batch = 0.6407s	
2261/33650 (epoch 3.360), train_loss = 1.68716184, grad/param norm = 2.1438e-01, time/batch = 0.6442s	
2262/33650 (epoch 3.361), train_loss = 1.53678294, grad/param norm = 1.9540e-01, time/batch = 0.6766s	
2263/33650 (epoch 3.363), train_loss = 1.49327660, grad/param norm = 1.9714e-01, time/batch = 0.6622s	
2264/33650 (epoch 3.364), train_loss = 1.51779668, grad/param norm = 1.7776e-01, time/batch = 0.6417s	
2265/33650 (epoch 3.366), train_loss = 1.52938075, grad/param norm = 2.0439e-01, time/batch = 0.6396s	
2266/33650 (epoch 3.367), train_loss = 1.64201542, grad/param norm = 1.9047e-01, time/batch = 0.6408s	
2267/33650 (epoch 3.368), train_loss = 1.40525406, grad/param norm = 2.0970e-01, time/batch = 0.6413s	
2268/33650 (epoch 3.370), train_loss = 1.60046505, grad/param norm = 1.9549e-01, time/batch = 0.6434s	
2269/33650 (epoch 3.371), train_loss = 1.37153686, grad/param norm = 1.8970e-01, time/batch = 0.6390s	
2270/33650 (epoch 3.373), train_loss = 1.47479361, grad/param norm = 2.0888e-01, time/batch = 0.6387s	
2271/33650 (epoch 3.374), train_loss = 1.35359626, grad/param norm = 1.8789e-01, time/batch = 0.6424s	
2272/33650 (epoch 3.376), train_loss = 1.52984503, grad/param norm = 1.8989e-01, time/batch = 0.6448s	
2273/33650 (epoch 3.377), train_loss = 1.65969759, grad/param norm = 2.1760e-01, time/batch = 0.6401s	
2274/33650 (epoch 3.379), train_loss = 1.52805769, grad/param norm = 2.2469e-01, time/batch = 0.6444s	
2275/33650 (epoch 3.380), train_loss = 1.33561663, grad/param norm = 2.0461e-01, time/batch = 0.6409s	
2276/33650 (epoch 3.382), train_loss = 1.27127404, grad/param norm = 1.7626e-01, time/batch = 0.6398s	
2277/33650 (epoch 3.383), train_loss = 1.44952430, grad/param norm = 1.8899e-01, time/batch = 0.6407s	
2278/33650 (epoch 3.385), train_loss = 1.61277154, grad/param norm = 1.7974e-01, time/batch = 0.6416s	
2279/33650 (epoch 3.386), train_loss = 1.40192616, grad/param norm = 1.7687e-01, time/batch = 0.6396s	
2280/33650 (epoch 3.388), train_loss = 1.43195922, grad/param norm = 1.8723e-01, time/batch = 0.6415s	
2281/33650 (epoch 3.389), train_loss = 1.63087727, grad/param norm = 2.3452e-01, time/batch = 0.6444s	
2282/33650 (epoch 3.391), train_loss = 1.32821800, grad/param norm = 1.7314e-01, time/batch = 0.6746s	
2283/33650 (epoch 3.392), train_loss = 1.74463162, grad/param norm = 2.1147e-01, time/batch = 0.6644s	
2284/33650 (epoch 3.394), train_loss = 1.66565892, grad/param norm = 2.3853e-01, time/batch = 0.6396s	
2285/33650 (epoch 3.395), train_loss = 1.55753410, grad/param norm = 2.4002e-01, time/batch = 0.6386s	
2286/33650 (epoch 3.397), train_loss = 1.77601549, grad/param norm = 2.0783e-01, time/batch = 0.6385s	
2287/33650 (epoch 3.398), train_loss = 1.54195042, grad/param norm = 1.8908e-01, time/batch = 0.6386s	
2288/33650 (epoch 3.400), train_loss = 1.69308653, grad/param norm = 2.1730e-01, time/batch = 0.6435s	
2289/33650 (epoch 3.401), train_loss = 1.61440283, grad/param norm = 2.0574e-01, time/batch = 0.6448s	
2290/33650 (epoch 3.403), train_loss = 1.59043989, grad/param norm = 2.0129e-01, time/batch = 0.6429s	
2291/33650 (epoch 3.404), train_loss = 1.53790085, grad/param norm = 1.8626e-01, time/batch = 0.6416s	
2292/33650 (epoch 3.406), train_loss = 1.66654689, grad/param norm = 1.9678e-01, time/batch = 0.6384s	
2293/33650 (epoch 3.407), train_loss = 1.48732426, grad/param norm = 1.8308e-01, time/batch = 0.6393s	
2294/33650 (epoch 3.409), train_loss = 1.59293868, grad/param norm = 1.9992e-01, time/batch = 0.6383s	
2295/33650 (epoch 3.410), train_loss = 1.57566563, grad/param norm = 2.1559e-01, time/batch = 0.6395s	
2296/33650 (epoch 3.412), train_loss = 1.53852401, grad/param norm = 1.8708e-01, time/batch = 0.6406s	
2297/33650 (epoch 3.413), train_loss = 1.45411092, grad/param norm = 1.9959e-01, time/batch = 0.6399s	
2298/33650 (epoch 3.415), train_loss = 1.57694338, grad/param norm = 2.0631e-01, time/batch = 0.6386s	
2299/33650 (epoch 3.416), train_loss = 1.71508120, grad/param norm = 2.1317e-01, time/batch = 0.6397s	
2300/33650 (epoch 3.418), train_loss = 1.63122399, grad/param norm = 2.1989e-01, time/batch = 0.6389s	
2301/33650 (epoch 3.419), train_loss = 1.58241981, grad/param norm = 2.1341e-01, time/batch = 0.6423s	
2302/33650 (epoch 3.421), train_loss = 1.38350517, grad/param norm = 2.0814e-01, time/batch = 0.6695s	
2303/33650 (epoch 3.422), train_loss = 1.62718515, grad/param norm = 2.2734e-01, time/batch = 0.6717s	
2304/33650 (epoch 3.423), train_loss = 1.45010045, grad/param norm = 1.8407e-01, time/batch = 0.6457s	
2305/33650 (epoch 3.425), train_loss = 1.65224351, grad/param norm = 1.9081e-01, time/batch = 0.6427s	
2306/33650 (epoch 3.426), train_loss = 1.69599301, grad/param norm = 2.1198e-01, time/batch = 0.6396s	
2307/33650 (epoch 3.428), train_loss = 1.47266540, grad/param norm = 2.0084e-01, time/batch = 0.6397s	
2308/33650 (epoch 3.429), train_loss = 1.67570391, grad/param norm = 2.1730e-01, time/batch = 0.6406s	
2309/33650 (epoch 3.431), train_loss = 1.84840945, grad/param norm = 2.1324e-01, time/batch = 0.6457s	
2310/33650 (epoch 3.432), train_loss = 1.84669048, grad/param norm = 2.1676e-01, time/batch = 0.6521s	
2311/33650 (epoch 3.434), train_loss = 1.66397184, grad/param norm = 2.2152e-01, time/batch = 0.6665s	
2312/33650 (epoch 3.435), train_loss = 1.60702166, grad/param norm = 1.9803e-01, time/batch = 0.6697s	
2313/33650 (epoch 3.437), train_loss = 1.64672775, grad/param norm = 2.1194e-01, time/batch = 0.6851s	
2314/33650 (epoch 3.438), train_loss = 1.47640343, grad/param norm = 2.4661e-01, time/batch = 0.6742s	
2315/33650 (epoch 3.440), train_loss = 1.58425825, grad/param norm = 2.1705e-01, time/batch = 0.6710s	
2316/33650 (epoch 3.441), train_loss = 1.66078493, grad/param norm = 2.0041e-01, time/batch = 0.6673s	
2317/33650 (epoch 3.443), train_loss = 1.68672456, grad/param norm = 2.0546e-01, time/batch = 0.6732s	
2318/33650 (epoch 3.444), train_loss = 1.52269883, grad/param norm = 1.9875e-01, time/batch = 0.6759s	
2319/33650 (epoch 3.446), train_loss = 1.66847092, grad/param norm = 2.0363e-01, time/batch = 0.6497s	
2320/33650 (epoch 3.447), train_loss = 1.69095097, grad/param norm = 2.1661e-01, time/batch = 0.6475s	
2321/33650 (epoch 3.449), train_loss = 1.84089098, grad/param norm = 2.6616e-01, time/batch = 0.6599s	
2322/33650 (epoch 3.450), train_loss = 1.89155254, grad/param norm = 2.1083e-01, time/batch = 0.6400s	
2323/33650 (epoch 3.452), train_loss = 1.95728277, grad/param norm = 2.4642e-01, time/batch = 0.6424s	
2324/33650 (epoch 3.453), train_loss = 1.84785037, grad/param norm = 2.3810e-01, time/batch = 0.6421s	
2325/33650 (epoch 3.455), train_loss = 1.61726147, grad/param norm = 1.9717e-01, time/batch = 0.6389s	
2326/33650 (epoch 3.456), train_loss = 1.54378287, grad/param norm = 2.0118e-01, time/batch = 0.6408s	
2327/33650 (epoch 3.458), train_loss = 1.64111014, grad/param norm = 2.3470e-01, time/batch = 0.6422s	
2328/33650 (epoch 3.459), train_loss = 1.53888059, grad/param norm = 1.9605e-01, time/batch = 0.6498s	
2329/33650 (epoch 3.461), train_loss = 1.64086196, grad/param norm = 2.0488e-01, time/batch = 0.6518s	
2330/33650 (epoch 3.462), train_loss = 1.78509836, grad/param norm = 2.2487e-01, time/batch = 0.6510s	
2331/33650 (epoch 3.464), train_loss = 1.55794245, grad/param norm = 1.9640e-01, time/batch = 0.6544s	
2332/33650 (epoch 3.465), train_loss = 1.63294459, grad/param norm = 2.0197e-01, time/batch = 0.6549s	
2333/33650 (epoch 3.467), train_loss = 1.66642440, grad/param norm = 1.9399e-01, time/batch = 0.6517s	
2334/33650 (epoch 3.468), train_loss = 1.70176956, grad/param norm = 2.0723e-01, time/batch = 0.6566s	
2335/33650 (epoch 3.470), train_loss = 1.90062537, grad/param norm = 2.2481e-01, time/batch = 0.6488s	
2336/33650 (epoch 3.471), train_loss = 1.61650409, grad/param norm = 2.1009e-01, time/batch = 0.6476s	
2337/33650 (epoch 3.473), train_loss = 1.46311686, grad/param norm = 1.8992e-01, time/batch = 0.6433s	
2338/33650 (epoch 3.474), train_loss = 1.65042799, grad/param norm = 2.0690e-01, time/batch = 0.6505s	
2339/33650 (epoch 3.475), train_loss = 1.76719279, grad/param norm = 2.2140e-01, time/batch = 0.6473s	
2340/33650 (epoch 3.477), train_loss = 1.78144548, grad/param norm = 2.1346e-01, time/batch = 0.6438s	
2341/33650 (epoch 3.478), train_loss = 1.71717674, grad/param norm = 1.9747e-01, time/batch = 0.6492s	
2342/33650 (epoch 3.480), train_loss = 1.79323020, grad/param norm = 2.0738e-01, time/batch = 0.6426s	
2343/33650 (epoch 3.481), train_loss = 1.72291920, grad/param norm = 2.0152e-01, time/batch = 0.6480s	
2344/33650 (epoch 3.483), train_loss = 1.32562547, grad/param norm = 2.0118e-01, time/batch = 0.6639s	
2345/33650 (epoch 3.484), train_loss = 1.64326324, grad/param norm = 2.0410e-01, time/batch = 0.6521s	
2346/33650 (epoch 3.486), train_loss = 1.74817618, grad/param norm = 2.3680e-01, time/batch = 0.6443s	
2347/33650 (epoch 3.487), train_loss = 1.76248032, grad/param norm = 2.5012e-01, time/batch = 0.6480s	
2348/33650 (epoch 3.489), train_loss = 1.83418813, grad/param norm = 2.0725e-01, time/batch = 0.6428s	
2349/33650 (epoch 3.490), train_loss = 1.51623740, grad/param norm = 1.9466e-01, time/batch = 0.6549s	
2350/33650 (epoch 3.492), train_loss = 1.76849815, grad/param norm = 2.1357e-01, time/batch = 0.6641s	
2351/33650 (epoch 3.493), train_loss = 1.36605706, grad/param norm = 1.9390e-01, time/batch = 0.6770s	
2352/33650 (epoch 3.495), train_loss = 1.56239875, grad/param norm = 2.0267e-01, time/batch = 0.6800s	
2353/33650 (epoch 3.496), train_loss = 1.65875456, grad/param norm = 2.1763e-01, time/batch = 0.6806s	
2354/33650 (epoch 3.498), train_loss = 1.39682986, grad/param norm = 2.1733e-01, time/batch = 0.6534s	
2355/33650 (epoch 3.499), train_loss = 1.56670005, grad/param norm = 2.0691e-01, time/batch = 0.6597s	
2356/33650 (epoch 3.501), train_loss = 1.58648434, grad/param norm = 1.9567e-01, time/batch = 0.6534s	
2357/33650 (epoch 3.502), train_loss = 1.67607596, grad/param norm = 2.2456e-01, time/batch = 0.6486s	
2358/33650 (epoch 3.504), train_loss = 1.83941565, grad/param norm = 2.1576e-01, time/batch = 0.6564s	
2359/33650 (epoch 3.505), train_loss = 1.68726325, grad/param norm = 2.2482e-01, time/batch = 0.6487s	
2360/33650 (epoch 3.507), train_loss = 1.73666812, grad/param norm = 2.2910e-01, time/batch = 0.6415s	
2361/33650 (epoch 3.508), train_loss = 1.53167498, grad/param norm = 1.9680e-01, time/batch = 0.6429s	
2362/33650 (epoch 3.510), train_loss = 1.62538597, grad/param norm = 1.9961e-01, time/batch = 0.6405s	
2363/33650 (epoch 3.511), train_loss = 1.85646688, grad/param norm = 2.2185e-01, time/batch = 0.6434s	
2364/33650 (epoch 3.513), train_loss = 1.68268801, grad/param norm = 2.0393e-01, time/batch = 0.6638s	
2365/33650 (epoch 3.514), train_loss = 1.64696247, grad/param norm = 2.0567e-01, time/batch = 0.6417s	
2366/33650 (epoch 3.516), train_loss = 1.63534842, grad/param norm = 2.0683e-01, time/batch = 0.6387s	
2367/33650 (epoch 3.517), train_loss = 1.51951175, grad/param norm = 1.9094e-01, time/batch = 0.6470s	
2368/33650 (epoch 3.519), train_loss = 1.53254361, grad/param norm = 1.7449e-01, time/batch = 0.6792s	
2369/33650 (epoch 3.520), train_loss = 1.35930289, grad/param norm = 1.9368e-01, time/batch = 0.6498s	
2370/33650 (epoch 3.522), train_loss = 1.61448446, grad/param norm = 2.2285e-01, time/batch = 0.6382s	
2371/33650 (epoch 3.523), train_loss = 1.62731600, grad/param norm = 2.2080e-01, time/batch = 0.6471s	
2372/33650 (epoch 3.525), train_loss = 1.27883536, grad/param norm = 1.8107e-01, time/batch = 0.6462s	
2373/33650 (epoch 3.526), train_loss = 1.67873472, grad/param norm = 2.4343e-01, time/batch = 0.6388s	
2374/33650 (epoch 3.527), train_loss = 1.45601274, grad/param norm = 2.1826e-01, time/batch = 0.6413s	
2375/33650 (epoch 3.529), train_loss = 1.53807962, grad/param norm = 1.8598e-01, time/batch = 0.6389s	
2376/33650 (epoch 3.530), train_loss = 1.50490016, grad/param norm = 1.9926e-01, time/batch = 0.6383s	
2377/33650 (epoch 3.532), train_loss = 1.81032122, grad/param norm = 2.2726e-01, time/batch = 0.6396s	
2378/33650 (epoch 3.533), train_loss = 1.46565607, grad/param norm = 2.0101e-01, time/batch = 0.6425s	
2379/33650 (epoch 3.535), train_loss = 1.74389896, grad/param norm = 2.1890e-01, time/batch = 0.6400s	
2380/33650 (epoch 3.536), train_loss = 1.60676427, grad/param norm = 2.1878e-01, time/batch = 0.6404s	
2381/33650 (epoch 3.538), train_loss = 1.62232817, grad/param norm = 2.1478e-01, time/batch = 0.6400s	
2382/33650 (epoch 3.539), train_loss = 1.37834238, grad/param norm = 1.9410e-01, time/batch = 0.6391s	
2383/33650 (epoch 3.541), train_loss = 1.72548202, grad/param norm = 2.0419e-01, time/batch = 0.6429s	
2384/33650 (epoch 3.542), train_loss = 1.66313752, grad/param norm = 2.2806e-01, time/batch = 0.6436s	
2385/33650 (epoch 3.544), train_loss = 1.91405432, grad/param norm = 2.3271e-01, time/batch = 0.6454s	
2386/33650 (epoch 3.545), train_loss = 1.39136173, grad/param norm = 1.9913e-01, time/batch = 0.6455s	
2387/33650 (epoch 3.547), train_loss = 1.63169372, grad/param norm = 2.1185e-01, time/batch = 0.6545s	
2388/33650 (epoch 3.548), train_loss = 1.74266412, grad/param norm = 2.2221e-01, time/batch = 0.6680s	
2389/33650 (epoch 3.550), train_loss = 1.51262412, grad/param norm = 2.2861e-01, time/batch = 0.6410s	
2390/33650 (epoch 3.551), train_loss = 1.53214248, grad/param norm = 2.2843e-01, time/batch = 0.6393s	
2391/33650 (epoch 3.553), train_loss = 1.37444544, grad/param norm = 2.1433e-01, time/batch = 0.6426s	
2392/33650 (epoch 3.554), train_loss = 1.69476224, grad/param norm = 2.0073e-01, time/batch = 0.6419s	
2393/33650 (epoch 3.556), train_loss = 1.72864569, grad/param norm = 2.3829e-01, time/batch = 0.6456s	
2394/33650 (epoch 3.557), train_loss = 1.77059604, grad/param norm = 2.0397e-01, time/batch = 0.6437s	
2395/33650 (epoch 3.559), train_loss = 1.81350264, grad/param norm = 2.6618e-01, time/batch = 0.6402s	
2396/33650 (epoch 3.560), train_loss = 1.78589501, grad/param norm = 2.1808e-01, time/batch = 0.6425s	
2397/33650 (epoch 3.562), train_loss = 1.69096742, grad/param norm = 2.1341e-01, time/batch = 0.6397s	
2398/33650 (epoch 3.563), train_loss = 1.57488583, grad/param norm = 2.2022e-01, time/batch = 0.6443s	
2399/33650 (epoch 3.565), train_loss = 1.63375696, grad/param norm = 1.8995e-01, time/batch = 0.6535s	
2400/33650 (epoch 3.566), train_loss = 1.63351264, grad/param norm = 2.3685e-01, time/batch = 0.6426s	
2401/33650 (epoch 3.568), train_loss = 1.64314438, grad/param norm = 2.1162e-01, time/batch = 0.6495s	
2402/33650 (epoch 3.569), train_loss = 1.53225740, grad/param norm = 2.1134e-01, time/batch = 0.6593s	
2403/33650 (epoch 3.571), train_loss = 1.73433057, grad/param norm = 2.1183e-01, time/batch = 0.6495s	
2404/33650 (epoch 3.572), train_loss = 1.63710887, grad/param norm = 2.0000e-01, time/batch = 0.6395s	
2405/33650 (epoch 3.574), train_loss = 1.62426105, grad/param norm = 2.3505e-01, time/batch = 0.6633s	
2406/33650 (epoch 3.575), train_loss = 1.57378665, grad/param norm = 2.1022e-01, time/batch = 0.6442s	
2407/33650 (epoch 3.577), train_loss = 1.73117464, grad/param norm = 2.0155e-01, time/batch = 0.6439s	
2408/33650 (epoch 3.578), train_loss = 1.58080969, grad/param norm = 1.9271e-01, time/batch = 0.6441s	
2409/33650 (epoch 3.579), train_loss = 1.60996518, grad/param norm = 2.1155e-01, time/batch = 0.6442s	
2410/33650 (epoch 3.581), train_loss = 1.58629034, grad/param norm = 2.0286e-01, time/batch = 0.6426s	
2411/33650 (epoch 3.582), train_loss = 1.69669719, grad/param norm = 2.0051e-01, time/batch = 0.6484s	
2412/33650 (epoch 3.584), train_loss = 1.54822140, grad/param norm = 2.0142e-01, time/batch = 0.6479s	
2413/33650 (epoch 3.585), train_loss = 1.60113490, grad/param norm = 2.0333e-01, time/batch = 0.6457s	
2414/33650 (epoch 3.587), train_loss = 1.52484219, grad/param norm = 2.4041e-01, time/batch = 0.6420s	
2415/33650 (epoch 3.588), train_loss = 1.57512005, grad/param norm = 1.9808e-01, time/batch = 0.6423s	
2416/33650 (epoch 3.590), train_loss = 1.57982952, grad/param norm = 1.8102e-01, time/batch = 0.6470s	
2417/33650 (epoch 3.591), train_loss = 1.63410484, grad/param norm = 1.9892e-01, time/batch = 0.6496s	
2418/33650 (epoch 3.593), train_loss = 1.46520953, grad/param norm = 2.0080e-01, time/batch = 0.6578s	
2419/33650 (epoch 3.594), train_loss = 1.27549524, grad/param norm = 2.2183e-01, time/batch = 0.6564s	
2420/33650 (epoch 3.596), train_loss = 1.55981874, grad/param norm = 2.0292e-01, time/batch = 0.6568s	
2421/33650 (epoch 3.597), train_loss = 1.25312767, grad/param norm = 1.6018e-01, time/batch = 0.6430s	
2422/33650 (epoch 3.599), train_loss = 1.41652425, grad/param norm = 1.9933e-01, time/batch = 0.6463s	
2423/33650 (epoch 3.600), train_loss = 1.44239813, grad/param norm = 2.1208e-01, time/batch = 0.6453s	
2424/33650 (epoch 3.602), train_loss = 1.70458648, grad/param norm = 2.0568e-01, time/batch = 0.6403s	
2425/33650 (epoch 3.603), train_loss = 1.48328001, grad/param norm = 2.0475e-01, time/batch = 0.6399s	
2426/33650 (epoch 3.605), train_loss = 1.55002888, grad/param norm = 2.0272e-01, time/batch = 0.6414s	
2427/33650 (epoch 3.606), train_loss = 1.71496411, grad/param norm = 2.0283e-01, time/batch = 0.6417s	
2428/33650 (epoch 3.608), train_loss = 1.62357025, grad/param norm = 1.9926e-01, time/batch = 0.6401s	
2429/33650 (epoch 3.609), train_loss = 1.62867274, grad/param norm = 2.1827e-01, time/batch = 0.6426s	
2430/33650 (epoch 3.611), train_loss = 1.48075017, grad/param norm = 1.9767e-01, time/batch = 0.6496s	
2431/33650 (epoch 3.612), train_loss = 1.62806595, grad/param norm = 2.0996e-01, time/batch = 0.6475s	
2432/33650 (epoch 3.614), train_loss = 1.76289042, grad/param norm = 2.1876e-01, time/batch = 0.6643s	
2433/33650 (epoch 3.615), train_loss = 1.51335267, grad/param norm = 1.9882e-01, time/batch = 0.6787s	
2434/33650 (epoch 3.617), train_loss = 1.40322295, grad/param norm = 1.7738e-01, time/batch = 0.6434s	
2435/33650 (epoch 3.618), train_loss = 1.49370871, grad/param norm = 1.9857e-01, time/batch = 0.6407s	
2436/33650 (epoch 3.620), train_loss = 1.73059881, grad/param norm = 2.1949e-01, time/batch = 0.6503s	
2437/33650 (epoch 3.621), train_loss = 1.41211413, grad/param norm = 2.0974e-01, time/batch = 0.6486s	
2438/33650 (epoch 3.623), train_loss = 1.56159472, grad/param norm = 1.9667e-01, time/batch = 0.6401s	
2439/33650 (epoch 3.624), train_loss = 1.31850869, grad/param norm = 1.9668e-01, time/batch = 0.6424s	
2440/33650 (epoch 3.626), train_loss = 1.23846748, grad/param norm = 1.7604e-01, time/batch = 0.6410s	
2441/33650 (epoch 3.627), train_loss = 1.49062885, grad/param norm = 2.0730e-01, time/batch = 0.6437s	
2442/33650 (epoch 3.629), train_loss = 1.54386710, grad/param norm = 1.9028e-01, time/batch = 0.6447s	
2443/33650 (epoch 3.630), train_loss = 1.63746526, grad/param norm = 2.0207e-01, time/batch = 0.6404s	
2444/33650 (epoch 3.632), train_loss = 1.75614821, grad/param norm = 2.0230e-01, time/batch = 0.6386s	
2445/33650 (epoch 3.633), train_loss = 1.62025058, grad/param norm = 1.8550e-01, time/batch = 0.6429s	
2446/33650 (epoch 3.634), train_loss = 1.37383084, grad/param norm = 2.0372e-01, time/batch = 0.6416s	
2447/33650 (epoch 3.636), train_loss = 1.24143325, grad/param norm = 1.8427e-01, time/batch = 0.6544s	
2448/33650 (epoch 3.637), train_loss = 1.65493434, grad/param norm = 1.9826e-01, time/batch = 0.6856s	
2449/33650 (epoch 3.639), train_loss = 1.53325594, grad/param norm = 1.8011e-01, time/batch = 0.6755s	
2450/33650 (epoch 3.640), train_loss = 1.54667774, grad/param norm = 2.0783e-01, time/batch = 0.6729s	
2451/33650 (epoch 3.642), train_loss = 1.83477067, grad/param norm = 2.2692e-01, time/batch = 0.6634s	
2452/33650 (epoch 3.643), train_loss = 1.62140629, grad/param norm = 2.2730e-01, time/batch = 0.6496s	
2453/33650 (epoch 3.645), train_loss = 1.53527504, grad/param norm = 1.9765e-01, time/batch = 0.6389s	
2454/33650 (epoch 3.646), train_loss = 1.32068890, grad/param norm = 1.6930e-01, time/batch = 0.6405s	
2455/33650 (epoch 3.648), train_loss = 1.51472816, grad/param norm = 1.9130e-01, time/batch = 0.6409s	
2456/33650 (epoch 3.649), train_loss = 1.58407034, grad/param norm = 2.1476e-01, time/batch = 0.6404s	
2457/33650 (epoch 3.651), train_loss = 1.61448709, grad/param norm = 1.9637e-01, time/batch = 0.6435s	
2458/33650 (epoch 3.652), train_loss = 1.14950920, grad/param norm = 1.7180e-01, time/batch = 0.6411s	
2459/33650 (epoch 3.654), train_loss = 1.50822625, grad/param norm = 1.8943e-01, time/batch = 0.6426s	
2460/33650 (epoch 3.655), train_loss = 1.35154927, grad/param norm = 1.7335e-01, time/batch = 0.6568s	
2461/33650 (epoch 3.657), train_loss = 1.50829980, grad/param norm = 2.0221e-01, time/batch = 0.6514s	
2462/33650 (epoch 3.658), train_loss = 1.35699651, grad/param norm = 1.7435e-01, time/batch = 0.6422s	
2463/33650 (epoch 3.660), train_loss = 1.32939088, grad/param norm = 1.7962e-01, time/batch = 0.6409s	
2464/33650 (epoch 3.661), train_loss = 1.45525833, grad/param norm = 1.7531e-01, time/batch = 0.6419s	
2465/33650 (epoch 3.663), train_loss = 1.34297161, grad/param norm = 1.9548e-01, time/batch = 0.6460s	
2466/33650 (epoch 3.664), train_loss = 1.34896544, grad/param norm = 1.9289e-01, time/batch = 0.6447s	
2467/33650 (epoch 3.666), train_loss = 1.43846168, grad/param norm = 1.9617e-01, time/batch = 0.6562s	
2468/33650 (epoch 3.667), train_loss = 1.39319122, grad/param norm = 1.7818e-01, time/batch = 0.6802s	
2469/33650 (epoch 3.669), train_loss = 1.32818409, grad/param norm = 1.7773e-01, time/batch = 0.6501s	
2470/33650 (epoch 3.670), train_loss = 1.35261423, grad/param norm = 1.7806e-01, time/batch = 0.6388s	
2471/33650 (epoch 3.672), train_loss = 1.41749043, grad/param norm = 1.7040e-01, time/batch = 0.6448s	
2472/33650 (epoch 3.673), train_loss = 1.25759547, grad/param norm = 1.8142e-01, time/batch = 0.6461s	
2473/33650 (epoch 3.675), train_loss = 1.27000435, grad/param norm = 1.6337e-01, time/batch = 0.6541s	
2474/33650 (epoch 3.676), train_loss = 1.54161384, grad/param norm = 1.9018e-01, time/batch = 0.6438s	
2475/33650 (epoch 3.678), train_loss = 1.35898087, grad/param norm = 1.7221e-01, time/batch = 0.6443s	
2476/33650 (epoch 3.679), train_loss = 1.48267214, grad/param norm = 2.0004e-01, time/batch = 0.6399s	
2477/33650 (epoch 3.681), train_loss = 1.37907284, grad/param norm = 1.9323e-01, time/batch = 0.6389s	
2478/33650 (epoch 3.682), train_loss = 1.47882772, grad/param norm = 2.0118e-01, time/batch = 0.6405s	
2479/33650 (epoch 3.684), train_loss = 1.35053551, grad/param norm = 1.7359e-01, time/batch = 0.6417s	
2480/33650 (epoch 3.685), train_loss = 1.61286806, grad/param norm = 1.9987e-01, time/batch = 0.6422s	
2481/33650 (epoch 3.686), train_loss = 1.48000070, grad/param norm = 1.9591e-01, time/batch = 0.6435s	
2482/33650 (epoch 3.688), train_loss = 1.67967471, grad/param norm = 1.9857e-01, time/batch = 0.6407s	
2483/33650 (epoch 3.689), train_loss = 1.43874754, grad/param norm = 1.9553e-01, time/batch = 0.6399s	
2484/33650 (epoch 3.691), train_loss = 1.64788960, grad/param norm = 2.0973e-01, time/batch = 0.6414s	
2485/33650 (epoch 3.692), train_loss = 1.64430421, grad/param norm = 1.8755e-01, time/batch = 0.6414s	
2486/33650 (epoch 3.694), train_loss = 1.58837482, grad/param norm = 2.0931e-01, time/batch = 0.6482s	
2487/33650 (epoch 3.695), train_loss = 1.21578056, grad/param norm = 1.9243e-01, time/batch = 0.6551s	
2488/33650 (epoch 3.697), train_loss = 1.54863895, grad/param norm = 2.0009e-01, time/batch = 0.6791s	
2489/33650 (epoch 3.698), train_loss = 1.63089038, grad/param norm = 2.0019e-01, time/batch = 0.6521s	
2490/33650 (epoch 3.700), train_loss = 1.51731767, grad/param norm = 1.8047e-01, time/batch = 0.6412s	
2491/33650 (epoch 3.701), train_loss = 1.64280659, grad/param norm = 2.0762e-01, time/batch = 0.6646s	
2492/33650 (epoch 3.703), train_loss = 1.50677721, grad/param norm = 1.9709e-01, time/batch = 0.6465s	
2493/33650 (epoch 3.704), train_loss = 1.42632184, grad/param norm = 2.1050e-01, time/batch = 0.6450s	
2494/33650 (epoch 3.706), train_loss = 1.46311367, grad/param norm = 1.8627e-01, time/batch = 0.6597s	
2495/33650 (epoch 3.707), train_loss = 1.62420636, grad/param norm = 1.9721e-01, time/batch = 0.6587s	
2496/33650 (epoch 3.709), train_loss = 1.47605653, grad/param norm = 2.1094e-01, time/batch = 0.6633s	
2497/33650 (epoch 3.710), train_loss = 1.66203674, grad/param norm = 1.9164e-01, time/batch = 0.6514s	
2498/33650 (epoch 3.712), train_loss = 1.43419066, grad/param norm = 1.7749e-01, time/batch = 0.6427s	
2499/33650 (epoch 3.713), train_loss = 1.53802115, grad/param norm = 2.3580e-01, time/batch = 0.6552s	
2500/33650 (epoch 3.715), train_loss = 1.67126049, grad/param norm = 2.1781e-01, time/batch = 0.6559s	
2501/33650 (epoch 3.716), train_loss = 1.41832495, grad/param norm = 1.9561e-01, time/batch = 0.6441s	
2502/33650 (epoch 3.718), train_loss = 1.65753071, grad/param norm = 1.9567e-01, time/batch = 0.6442s	
2503/33650 (epoch 3.719), train_loss = 1.68718686, grad/param norm = 2.1571e-01, time/batch = 0.6410s	
2504/33650 (epoch 3.721), train_loss = 1.73695466, grad/param norm = 1.9952e-01, time/batch = 0.6420s	
2505/33650 (epoch 3.722), train_loss = 1.73830250, grad/param norm = 2.1705e-01, time/batch = 0.6416s	
2506/33650 (epoch 3.724), train_loss = 1.60933800, grad/param norm = 1.9150e-01, time/batch = 0.6397s	
2507/33650 (epoch 3.725), train_loss = 1.69008364, grad/param norm = 2.0759e-01, time/batch = 0.6563s	
2508/33650 (epoch 3.727), train_loss = 1.47243092, grad/param norm = 2.1717e-01, time/batch = 0.6789s	
2509/33650 (epoch 3.728), train_loss = 1.45170368, grad/param norm = 1.8263e-01, time/batch = 0.6436s	
2510/33650 (epoch 3.730), train_loss = 1.53151685, grad/param norm = 1.8919e-01, time/batch = 0.6399s	
2511/33650 (epoch 3.731), train_loss = 1.75855037, grad/param norm = 2.4110e-01, time/batch = 0.6423s	
2512/33650 (epoch 3.733), train_loss = 1.45415449, grad/param norm = 1.8601e-01, time/batch = 0.6399s	
2513/33650 (epoch 3.734), train_loss = 1.72767752, grad/param norm = 2.5626e-01, time/batch = 0.6392s	
2514/33650 (epoch 3.736), train_loss = 1.55728324, grad/param norm = 2.3114e-01, time/batch = 0.6492s	
2515/33650 (epoch 3.737), train_loss = 1.57462040, grad/param norm = 1.9655e-01, time/batch = 0.6475s	
2516/33650 (epoch 3.738), train_loss = 1.37404188, grad/param norm = 1.9176e-01, time/batch = 0.6403s	
2517/33650 (epoch 3.740), train_loss = 1.43995438, grad/param norm = 2.0561e-01, time/batch = 0.6416s	
2518/33650 (epoch 3.741), train_loss = 1.50122090, grad/param norm = 1.8929e-01, time/batch = 0.6452s	
2519/33650 (epoch 3.743), train_loss = 1.54209011, grad/param norm = 1.9703e-01, time/batch = 0.6431s	
2520/33650 (epoch 3.744), train_loss = 1.44440368, grad/param norm = 1.8038e-01, time/batch = 0.6415s	
2521/33650 (epoch 3.746), train_loss = 1.49098273, grad/param norm = 1.9013e-01, time/batch = 0.6449s	
2522/33650 (epoch 3.747), train_loss = 1.63570823, grad/param norm = 1.8997e-01, time/batch = 0.6450s	
2523/33650 (epoch 3.749), train_loss = 1.25648864, grad/param norm = 1.8710e-01, time/batch = 0.6406s	
2524/33650 (epoch 3.750), train_loss = 1.59155823, grad/param norm = 2.2157e-01, time/batch = 0.6416s	
2525/33650 (epoch 3.752), train_loss = 1.66300794, grad/param norm = 2.2497e-01, time/batch = 0.6490s	
2526/33650 (epoch 3.753), train_loss = 1.77042677, grad/param norm = 2.0434e-01, time/batch = 0.6430s	
2527/33650 (epoch 3.755), train_loss = 1.40062885, grad/param norm = 2.1169e-01, time/batch = 0.6421s	
2528/33650 (epoch 3.756), train_loss = 1.57434492, grad/param norm = 1.9742e-01, time/batch = 0.6418s	
2529/33650 (epoch 3.758), train_loss = 1.74519734, grad/param norm = 2.2047e-01, time/batch = 0.6404s	
2530/33650 (epoch 3.759), train_loss = 1.78863642, grad/param norm = 2.0496e-01, time/batch = 0.6412s	
2531/33650 (epoch 3.761), train_loss = 1.65019236, grad/param norm = 2.0027e-01, time/batch = 0.6434s	
2532/33650 (epoch 3.762), train_loss = 1.53919447, grad/param norm = 1.9939e-01, time/batch = 0.6407s	
2533/33650 (epoch 3.764), train_loss = 1.74861344, grad/param norm = 2.4305e-01, time/batch = 0.6420s	
2534/33650 (epoch 3.765), train_loss = 1.58766720, grad/param norm = 2.0022e-01, time/batch = 0.6405s	
2535/33650 (epoch 3.767), train_loss = 1.39346500, grad/param norm = 1.8023e-01, time/batch = 0.6410s	
2536/33650 (epoch 3.768), train_loss = 1.36322830, grad/param norm = 1.7694e-01, time/batch = 0.6465s	
2537/33650 (epoch 3.770), train_loss = 1.51679991, grad/param norm = 1.9933e-01, time/batch = 0.6418s	
2538/33650 (epoch 3.771), train_loss = 1.54156154, grad/param norm = 2.1682e-01, time/batch = 0.6401s	
2539/33650 (epoch 3.773), train_loss = 1.72356091, grad/param norm = 2.2871e-01, time/batch = 0.6453s	
2540/33650 (epoch 3.774), train_loss = 1.59340698, grad/param norm = 2.0171e-01, time/batch = 0.6406s	
2541/33650 (epoch 3.776), train_loss = 1.66449260, grad/param norm = 2.3417e-01, time/batch = 0.6452s	
2542/33650 (epoch 3.777), train_loss = 1.42189867, grad/param norm = 2.0813e-01, time/batch = 0.6395s	
2543/33650 (epoch 3.779), train_loss = 1.51486209, grad/param norm = 1.8750e-01, time/batch = 0.6391s	
2544/33650 (epoch 3.780), train_loss = 1.37136951, grad/param norm = 1.8320e-01, time/batch = 0.6433s	
2545/33650 (epoch 3.782), train_loss = 1.46268136, grad/param norm = 1.9158e-01, time/batch = 0.6431s	
2546/33650 (epoch 3.783), train_loss = 1.33956782, grad/param norm = 1.8216e-01, time/batch = 0.6411s	
2547/33650 (epoch 3.785), train_loss = 1.82582483, grad/param norm = 2.1921e-01, time/batch = 0.6452s	
2548/33650 (epoch 3.786), train_loss = 1.46727047, grad/param norm = 1.9712e-01, time/batch = 0.6792s	
2549/33650 (epoch 3.788), train_loss = 1.51553649, grad/param norm = 2.0994e-01, time/batch = 0.6551s	
2550/33650 (epoch 3.789), train_loss = 1.55675143, grad/param norm = 1.8973e-01, time/batch = 0.6394s	
2551/33650 (epoch 3.790), train_loss = 1.63862824, grad/param norm = 2.1669e-01, time/batch = 0.6425s	
2552/33650 (epoch 3.792), train_loss = 1.69285812, grad/param norm = 2.3588e-01, time/batch = 0.6434s	
2553/33650 (epoch 3.793), train_loss = 1.60884343, grad/param norm = 2.1921e-01, time/batch = 0.6439s	
2554/33650 (epoch 3.795), train_loss = 1.64333204, grad/param norm = 1.8379e-01, time/batch = 0.6395s	
2555/33650 (epoch 3.796), train_loss = 1.44657709, grad/param norm = 1.8711e-01, time/batch = 0.6385s	
2556/33650 (epoch 3.798), train_loss = 1.46720679, grad/param norm = 1.8679e-01, time/batch = 0.6421s	
2557/33650 (epoch 3.799), train_loss = 1.52406470, grad/param norm = 1.8887e-01, time/batch = 0.6399s	
2558/33650 (epoch 3.801), train_loss = 1.60278241, grad/param norm = 2.0241e-01, time/batch = 0.6394s	
2559/33650 (epoch 3.802), train_loss = 1.68489215, grad/param norm = 1.8262e-01, time/batch = 0.6417s	
2560/33650 (epoch 3.804), train_loss = 1.52975512, grad/param norm = 1.9242e-01, time/batch = 0.6450s	
2561/33650 (epoch 3.805), train_loss = 1.50005122, grad/param norm = 2.0090e-01, time/batch = 0.6598s	
2562/33650 (epoch 3.807), train_loss = 1.88661509, grad/param norm = 2.4732e-01, time/batch = 0.6480s	
2563/33650 (epoch 3.808), train_loss = 1.73522915, grad/param norm = 2.0396e-01, time/batch = 0.6440s	
2564/33650 (epoch 3.810), train_loss = 1.58629623, grad/param norm = 1.9664e-01, time/batch = 0.6403s	
2565/33650 (epoch 3.811), train_loss = 1.62517984, grad/param norm = 2.1151e-01, time/batch = 0.6460s	
2566/33650 (epoch 3.813), train_loss = 1.59346712, grad/param norm = 2.4268e-01, time/batch = 0.6478s	
2567/33650 (epoch 3.814), train_loss = 1.67941333, grad/param norm = 2.3644e-01, time/batch = 0.6520s	
2568/33650 (epoch 3.816), train_loss = 1.58904480, grad/param norm = 2.2395e-01, time/batch = 0.6798s	
2569/33650 (epoch 3.817), train_loss = 1.76025921, grad/param norm = 2.3152e-01, time/batch = 0.6532s	
2570/33650 (epoch 3.819), train_loss = 1.71063055, grad/param norm = 2.0174e-01, time/batch = 0.6397s	
2571/33650 (epoch 3.820), train_loss = 1.69571534, grad/param norm = 2.0641e-01, time/batch = 0.6410s	
2572/33650 (epoch 3.822), train_loss = 1.78009277, grad/param norm = 2.0887e-01, time/batch = 0.6430s	
2573/33650 (epoch 3.823), train_loss = 1.44105887, grad/param norm = 2.0379e-01, time/batch = 0.6395s	
2574/33650 (epoch 3.825), train_loss = 1.51287523, grad/param norm = 1.8430e-01, time/batch = 0.6406s	
2575/33650 (epoch 3.826), train_loss = 1.60803980, grad/param norm = 1.9097e-01, time/batch = 0.6424s	
2576/33650 (epoch 3.828), train_loss = 1.88252278, grad/param norm = 2.1742e-01, time/batch = 0.6408s	
2577/33650 (epoch 3.829), train_loss = 1.43124415, grad/param norm = 2.1074e-01, time/batch = 0.6388s	
2578/33650 (epoch 3.831), train_loss = 1.70577460, grad/param norm = 1.9019e-01, time/batch = 0.6394s	
2579/33650 (epoch 3.832), train_loss = 1.62824624, grad/param norm = 2.0271e-01, time/batch = 0.6462s	
2580/33650 (epoch 3.834), train_loss = 1.67132837, grad/param norm = 1.9929e-01, time/batch = 0.6411s	
2581/33650 (epoch 3.835), train_loss = 1.85893523, grad/param norm = 2.0445e-01, time/batch = 0.6461s	
2582/33650 (epoch 3.837), train_loss = 1.59883941, grad/param norm = 2.1631e-01, time/batch = 0.6419s	
2583/33650 (epoch 3.838), train_loss = 1.55608969, grad/param norm = 1.9376e-01, time/batch = 0.6384s	
2584/33650 (epoch 3.840), train_loss = 1.63507149, grad/param norm = 1.8509e-01, time/batch = 0.6397s	
2585/33650 (epoch 3.841), train_loss = 1.43863017, grad/param norm = 1.6777e-01, time/batch = 0.6465s	
2586/33650 (epoch 3.842), train_loss = 1.44764347, grad/param norm = 1.9783e-01, time/batch = 0.6454s	
2587/33650 (epoch 3.844), train_loss = 1.80045786, grad/param norm = 2.1955e-01, time/batch = 0.6629s	
2588/33650 (epoch 3.845), train_loss = 1.39178384, grad/param norm = 1.9415e-01, time/batch = 0.6822s	
2589/33650 (epoch 3.847), train_loss = 1.36793563, grad/param norm = 1.7657e-01, time/batch = 0.6583s	
2590/33650 (epoch 3.848), train_loss = 1.45825369, grad/param norm = 2.0830e-01, time/batch = 0.6589s	
2591/33650 (epoch 3.850), train_loss = 1.62873791, grad/param norm = 2.2260e-01, time/batch = 0.6573s	
2592/33650 (epoch 3.851), train_loss = 1.32096859, grad/param norm = 1.7412e-01, time/batch = 0.6445s	
2593/33650 (epoch 3.853), train_loss = 1.57014855, grad/param norm = 1.9444e-01, time/batch = 0.6393s	
2594/33650 (epoch 3.854), train_loss = 1.72979051, grad/param norm = 2.2345e-01, time/batch = 0.6421s	
2595/33650 (epoch 3.856), train_loss = 1.24496019, grad/param norm = 1.9355e-01, time/batch = 0.6472s	
2596/33650 (epoch 3.857), train_loss = 1.46377482, grad/param norm = 1.6983e-01, time/batch = 0.6429s	
2597/33650 (epoch 3.859), train_loss = 1.41229074, grad/param norm = 1.7890e-01, time/batch = 0.6423s	
2598/33650 (epoch 3.860), train_loss = 1.29336268, grad/param norm = 1.8140e-01, time/batch = 0.6461s	
2599/33650 (epoch 3.862), train_loss = 1.34848534, grad/param norm = 1.8646e-01, time/batch = 0.6389s	
2600/33650 (epoch 3.863), train_loss = 1.64488369, grad/param norm = 2.2281e-01, time/batch = 0.6400s	
2601/33650 (epoch 3.865), train_loss = 1.41504357, grad/param norm = 1.9202e-01, time/batch = 0.6432s	
2602/33650 (epoch 3.866), train_loss = 1.47032434, grad/param norm = 1.9663e-01, time/batch = 0.6442s	
2603/33650 (epoch 3.868), train_loss = 1.41771169, grad/param norm = 1.9702e-01, time/batch = 0.6441s	
2604/33650 (epoch 3.869), train_loss = 1.66366748, grad/param norm = 2.0824e-01, time/batch = 0.6400s	
2605/33650 (epoch 3.871), train_loss = 1.38133062, grad/param norm = 1.9908e-01, time/batch = 0.6398s	
2606/33650 (epoch 3.872), train_loss = 1.52634891, grad/param norm = 2.2394e-01, time/batch = 0.6407s	
2607/33650 (epoch 3.874), train_loss = 1.60355249, grad/param norm = 1.9359e-01, time/batch = 0.6436s	
2608/33650 (epoch 3.875), train_loss = 1.40624612, grad/param norm = 1.8030e-01, time/batch = 0.6791s	
2609/33650 (epoch 3.877), train_loss = 1.64688923, grad/param norm = 2.1201e-01, time/batch = 0.6554s	
2610/33650 (epoch 3.878), train_loss = 1.20127955, grad/param norm = 2.0018e-01, time/batch = 0.6392s	
2611/33650 (epoch 3.880), train_loss = 1.48848856, grad/param norm = 2.0246e-01, time/batch = 0.6434s	
2612/33650 (epoch 3.881), train_loss = 1.44781833, grad/param norm = 1.9339e-01, time/batch = 0.6425s	
2613/33650 (epoch 3.883), train_loss = 1.52874217, grad/param norm = 2.0987e-01, time/batch = 0.6510s	
2614/33650 (epoch 3.884), train_loss = 1.66754038, grad/param norm = 2.0969e-01, time/batch = 0.6418s	
2615/33650 (epoch 3.886), train_loss = 1.62536490, grad/param norm = 2.0173e-01, time/batch = 0.6444s	
2616/33650 (epoch 3.887), train_loss = 1.40575945, grad/param norm = 1.8048e-01, time/batch = 0.6430s	
2617/33650 (epoch 3.889), train_loss = 1.65699856, grad/param norm = 2.1029e-01, time/batch = 0.6383s	
2618/33650 (epoch 3.890), train_loss = 1.59182074, grad/param norm = 1.9133e-01, time/batch = 0.6399s	
2619/33650 (epoch 3.892), train_loss = 1.61071107, grad/param norm = 2.0954e-01, time/batch = 0.6388s	
2620/33650 (epoch 3.893), train_loss = 1.61742683, grad/param norm = 2.0410e-01, time/batch = 0.6385s	
2621/33650 (epoch 3.895), train_loss = 1.62086644, grad/param norm = 2.0582e-01, time/batch = 0.6413s	
2622/33650 (epoch 3.896), train_loss = 1.41515582, grad/param norm = 1.9912e-01, time/batch = 0.6411s	
2623/33650 (epoch 3.897), train_loss = 1.46568499, grad/param norm = 1.7916e-01, time/batch = 0.6394s	
2624/33650 (epoch 3.899), train_loss = 1.43597584, grad/param norm = 2.0641e-01, time/batch = 0.6384s	
2625/33650 (epoch 3.900), train_loss = 1.24721910, grad/param norm = 1.6745e-01, time/batch = 0.6390s	
2626/33650 (epoch 3.902), train_loss = 1.50691614, grad/param norm = 1.8921e-01, time/batch = 0.6402s	
2627/33650 (epoch 3.903), train_loss = 1.50253968, grad/param norm = 2.0903e-01, time/batch = 0.6399s	
2628/33650 (epoch 3.905), train_loss = 1.80062340, grad/param norm = 2.2298e-01, time/batch = 0.6790s	
2629/33650 (epoch 3.906), train_loss = 1.48851133, grad/param norm = 1.9682e-01, time/batch = 0.6585s	
2630/33650 (epoch 3.908), train_loss = 1.43922299, grad/param norm = 1.7792e-01, time/batch = 0.6393s	
2631/33650 (epoch 3.909), train_loss = 1.45051006, grad/param norm = 1.6535e-01, time/batch = 0.6446s	
2632/33650 (epoch 3.911), train_loss = 1.39321760, grad/param norm = 1.9889e-01, time/batch = 0.6458s	
2633/33650 (epoch 3.912), train_loss = 1.38955880, grad/param norm = 1.7664e-01, time/batch = 0.6442s	
2634/33650 (epoch 3.914), train_loss = 1.49856321, grad/param norm = 1.8182e-01, time/batch = 0.6406s	
2635/33650 (epoch 3.915), train_loss = 1.65809340, grad/param norm = 2.2007e-01, time/batch = 0.6463s	
2636/33650 (epoch 3.917), train_loss = 1.50778296, grad/param norm = 2.2923e-01, time/batch = 0.6458s	
2637/33650 (epoch 3.918), train_loss = 1.27826668, grad/param norm = 1.7803e-01, time/batch = 0.6386s	
2638/33650 (epoch 3.920), train_loss = 1.44409607, grad/param norm = 1.7682e-01, time/batch = 0.6444s	
2639/33650 (epoch 3.921), train_loss = 1.37786372, grad/param norm = 1.8565e-01, time/batch = 0.6476s	
2640/33650 (epoch 3.923), train_loss = 1.38364851, grad/param norm = 1.8919e-01, time/batch = 0.6455s	
2641/33650 (epoch 3.924), train_loss = 1.59481370, grad/param norm = 1.9457e-01, time/batch = 0.6440s	
2642/33650 (epoch 3.926), train_loss = 1.62400085, grad/param norm = 2.0986e-01, time/batch = 0.6464s	
2643/33650 (epoch 3.927), train_loss = 1.50134562, grad/param norm = 2.0373e-01, time/batch = 0.6456s	
2644/33650 (epoch 3.929), train_loss = 1.45609023, grad/param norm = 1.8819e-01, time/batch = 0.6417s	
2645/33650 (epoch 3.930), train_loss = 1.45606354, grad/param norm = 1.9603e-01, time/batch = 0.6385s	
2646/33650 (epoch 3.932), train_loss = 1.48963845, grad/param norm = 1.9607e-01, time/batch = 0.6388s	
2647/33650 (epoch 3.933), train_loss = 1.36754992, grad/param norm = 1.7911e-01, time/batch = 0.6459s	
2648/33650 (epoch 3.935), train_loss = 1.40969994, grad/param norm = 1.8630e-01, time/batch = 0.6396s	
2649/33650 (epoch 3.936), train_loss = 1.38890881, grad/param norm = 1.8408e-01, time/batch = 0.6390s	
2650/33650 (epoch 3.938), train_loss = 1.29876580, grad/param norm = 1.7841e-01, time/batch = 0.6406s	
2651/33650 (epoch 3.939), train_loss = 1.54600412, grad/param norm = 1.9345e-01, time/batch = 0.6450s	
2652/33650 (epoch 3.941), train_loss = 1.55215338, grad/param norm = 1.9687e-01, time/batch = 0.6552s	
2653/33650 (epoch 3.942), train_loss = 1.60965290, grad/param norm = 1.9743e-01, time/batch = 0.6793s	
2654/33650 (epoch 3.944), train_loss = 1.54254482, grad/param norm = 1.8275e-01, time/batch = 0.6432s	
2655/33650 (epoch 3.945), train_loss = 1.59114889, grad/param norm = 1.9475e-01, time/batch = 0.6385s	
2656/33650 (epoch 3.947), train_loss = 1.80474819, grad/param norm = 2.1004e-01, time/batch = 0.6400s	
2657/33650 (epoch 3.948), train_loss = 1.65554771, grad/param norm = 1.9797e-01, time/batch = 0.6391s	
2658/33650 (epoch 3.949), train_loss = 1.42351903, grad/param norm = 2.1112e-01, time/batch = 0.6412s	
2659/33650 (epoch 3.951), train_loss = 1.60364149, grad/param norm = 2.0458e-01, time/batch = 0.6550s	
2660/33650 (epoch 3.952), train_loss = 1.66789898, grad/param norm = 2.2035e-01, time/batch = 0.6499s	
2661/33650 (epoch 3.954), train_loss = 1.63877385, grad/param norm = 2.1344e-01, time/batch = 0.6434s	
2662/33650 (epoch 3.955), train_loss = 1.65934970, grad/param norm = 2.2598e-01, time/batch = 0.6597s	
2663/33650 (epoch 3.957), train_loss = 1.61974198, grad/param norm = 2.0986e-01, time/batch = 0.6387s	
2664/33650 (epoch 3.958), train_loss = 1.15941197, grad/param norm = 1.6723e-01, time/batch = 0.6394s	
2665/33650 (epoch 3.960), train_loss = 1.32074473, grad/param norm = 1.5744e-01, time/batch = 0.6394s	
2666/33650 (epoch 3.961), train_loss = 1.46134979, grad/param norm = 1.8961e-01, time/batch = 0.6444s	
2667/33650 (epoch 3.963), train_loss = 1.48158750, grad/param norm = 1.9609e-01, time/batch = 0.6363s	
2668/33650 (epoch 3.964), train_loss = 1.51950514, grad/param norm = 1.8770e-01, time/batch = 0.6764s	
2669/33650 (epoch 3.966), train_loss = 1.52280427, grad/param norm = 2.0518e-01, time/batch = 0.6595s	
2670/33650 (epoch 3.967), train_loss = 1.56520351, grad/param norm = 2.1138e-01, time/batch = 0.6389s	
2671/33650 (epoch 3.969), train_loss = 1.40614523, grad/param norm = 1.8321e-01, time/batch = 0.6402s	
2672/33650 (epoch 3.970), train_loss = 1.57788779, grad/param norm = 1.8937e-01, time/batch = 0.6396s	
2673/33650 (epoch 3.972), train_loss = 1.83059591, grad/param norm = 2.0737e-01, time/batch = 0.6437s	
2674/33650 (epoch 3.973), train_loss = 1.37715139, grad/param norm = 1.7957e-01, time/batch = 0.6377s	
2675/33650 (epoch 3.975), train_loss = 1.44243111, grad/param norm = 1.9760e-01, time/batch = 0.6386s	
2676/33650 (epoch 3.976), train_loss = 1.41058012, grad/param norm = 1.7655e-01, time/batch = 0.6373s	
2677/33650 (epoch 3.978), train_loss = 1.39435309, grad/param norm = 1.9969e-01, time/batch = 0.6371s	
2678/33650 (epoch 3.979), train_loss = 1.58737281, grad/param norm = 2.1221e-01, time/batch = 0.6421s	
2679/33650 (epoch 3.981), train_loss = 1.43559287, grad/param norm = 1.7530e-01, time/batch = 0.6504s	
2680/33650 (epoch 3.982), train_loss = 1.58171786, grad/param norm = 2.1814e-01, time/batch = 0.6522s	
2681/33650 (epoch 3.984), train_loss = 1.32304586, grad/param norm = 1.7500e-01, time/batch = 0.6637s	
2682/33650 (epoch 3.985), train_loss = 1.38533576, grad/param norm = 1.7955e-01, time/batch = 0.6455s	
2683/33650 (epoch 3.987), train_loss = 1.46547333, grad/param norm = 1.7996e-01, time/batch = 0.6434s	
2684/33650 (epoch 3.988), train_loss = 1.61151911, grad/param norm = 1.9427e-01, time/batch = 0.6428s	
2685/33650 (epoch 3.990), train_loss = 1.78052356, grad/param norm = 2.2876e-01, time/batch = 0.6386s	
2686/33650 (epoch 3.991), train_loss = 1.64676981, grad/param norm = 1.9334e-01, time/batch = 0.6386s	
2687/33650 (epoch 3.993), train_loss = 1.62449133, grad/param norm = 1.9875e-01, time/batch = 0.6413s	
2688/33650 (epoch 3.994), train_loss = 1.48744956, grad/param norm = 2.0655e-01, time/batch = 0.6755s	
2689/33650 (epoch 3.996), train_loss = 1.44031546, grad/param norm = 1.8485e-01, time/batch = 0.6656s	
2690/33650 (epoch 3.997), train_loss = 1.57236860, grad/param norm = 2.1479e-01, time/batch = 0.6590s	
2691/33650 (epoch 3.999), train_loss = 1.33337568, grad/param norm = 1.8451e-01, time/batch = 0.6449s	
2692/33650 (epoch 4.000), train_loss = 1.65383352, grad/param norm = 2.0402e-01, time/batch = 0.6383s	
2693/33650 (epoch 4.001), train_loss = 1.66227246, grad/param norm = 2.0556e-01, time/batch = 0.6379s	
2694/33650 (epoch 4.003), train_loss = 1.77811976, grad/param norm = 2.1962e-01, time/batch = 0.6374s	
2695/33650 (epoch 4.004), train_loss = 1.62132138, grad/param norm = 2.1155e-01, time/batch = 0.6385s	
2696/33650 (epoch 4.006), train_loss = 1.41651914, grad/param norm = 1.8331e-01, time/batch = 0.6424s	
2697/33650 (epoch 4.007), train_loss = 1.48745315, grad/param norm = 1.9980e-01, time/batch = 0.6404s	
2698/33650 (epoch 4.009), train_loss = 1.48478062, grad/param norm = 1.9133e-01, time/batch = 0.6427s	
2699/33650 (epoch 4.010), train_loss = 1.63215168, grad/param norm = 2.0375e-01, time/batch = 0.6468s	
2700/33650 (epoch 4.012), train_loss = 1.49248577, grad/param norm = 2.0706e-01, time/batch = 0.6440s	
2701/33650 (epoch 4.013), train_loss = 1.59517597, grad/param norm = 1.9162e-01, time/batch = 0.6492s	
2702/33650 (epoch 4.015), train_loss = 1.37309522, grad/param norm = 1.9493e-01, time/batch = 0.6451s	
2703/33650 (epoch 4.016), train_loss = 1.48562796, grad/param norm = 1.9353e-01, time/batch = 0.6543s	
2704/33650 (epoch 4.018), train_loss = 1.50665777, grad/param norm = 1.9063e-01, time/batch = 0.6474s	
2705/33650 (epoch 4.019), train_loss = 1.39935059, grad/param norm = 1.9018e-01, time/batch = 0.6472s	
2706/33650 (epoch 4.021), train_loss = 1.65117722, grad/param norm = 1.9419e-01, time/batch = 0.6482s	
2707/33650 (epoch 4.022), train_loss = 1.49255320, grad/param norm = 1.9757e-01, time/batch = 0.6467s	
2708/33650 (epoch 4.024), train_loss = 1.41822329, grad/param norm = 1.9699e-01, time/batch = 0.6753s	
2709/33650 (epoch 4.025), train_loss = 1.44402261, grad/param norm = 1.9685e-01, time/batch = 0.6442s	
2710/33650 (epoch 4.027), train_loss = 1.65373703, grad/param norm = 1.9654e-01, time/batch = 0.6418s	
2711/33650 (epoch 4.028), train_loss = 1.62010526, grad/param norm = 2.0135e-01, time/batch = 0.6423s	
2712/33650 (epoch 4.030), train_loss = 1.45937323, grad/param norm = 1.8525e-01, time/batch = 0.6425s	
2713/33650 (epoch 4.031), train_loss = 1.22718799, grad/param norm = 1.9486e-01, time/batch = 0.6390s	
2714/33650 (epoch 4.033), train_loss = 1.40108648, grad/param norm = 1.6917e-01, time/batch = 0.6386s	
2715/33650 (epoch 4.034), train_loss = 1.48819985, grad/param norm = 1.9234e-01, time/batch = 0.6392s	
2716/33650 (epoch 4.036), train_loss = 1.67947207, grad/param norm = 2.0232e-01, time/batch = 0.6374s	
2717/33650 (epoch 4.037), train_loss = 1.41117127, grad/param norm = 2.0672e-01, time/batch = 0.6380s	
2718/33650 (epoch 4.039), train_loss = 1.65981891, grad/param norm = 2.0134e-01, time/batch = 0.6382s	
2719/33650 (epoch 4.040), train_loss = 1.67346906, grad/param norm = 1.9918e-01, time/batch = 0.6451s	
2720/33650 (epoch 4.042), train_loss = 1.71843174, grad/param norm = 2.0590e-01, time/batch = 0.6388s	
2721/33650 (epoch 4.043), train_loss = 1.34236340, grad/param norm = 1.9944e-01, time/batch = 0.6427s	
2722/33650 (epoch 4.045), train_loss = 1.41589122, grad/param norm = 1.8933e-01, time/batch = 0.6392s	
2723/33650 (epoch 4.046), train_loss = 1.64149252, grad/param norm = 1.8684e-01, time/batch = 0.6380s	
2724/33650 (epoch 4.048), train_loss = 1.58945428, grad/param norm = 1.9785e-01, time/batch = 0.6382s	
2725/33650 (epoch 4.049), train_loss = 1.61278834, grad/param norm = 2.1180e-01, time/batch = 0.6392s	
2726/33650 (epoch 4.051), train_loss = 1.60128569, grad/param norm = 1.8991e-01, time/batch = 0.6424s	
2727/33650 (epoch 4.052), train_loss = 1.72048796, grad/param norm = 2.0015e-01, time/batch = 0.6374s	
2728/33650 (epoch 4.053), train_loss = 1.50414369, grad/param norm = 1.8149e-01, time/batch = 0.6378s	
2729/33650 (epoch 4.055), train_loss = 1.31709465, grad/param norm = 1.9323e-01, time/batch = 0.6396s	
2730/33650 (epoch 4.056), train_loss = 1.30174909, grad/param norm = 1.6553e-01, time/batch = 0.6401s	
2731/33650 (epoch 4.058), train_loss = 1.64779910, grad/param norm = 2.0221e-01, time/batch = 0.6407s	
2732/33650 (epoch 4.059), train_loss = 1.66594857, grad/param norm = 2.1289e-01, time/batch = 0.6462s	
2733/33650 (epoch 4.061), train_loss = 1.56596505, grad/param norm = 1.9165e-01, time/batch = 0.6700s	
2734/33650 (epoch 4.062), train_loss = 1.53602996, grad/param norm = 1.8924e-01, time/batch = 0.6461s	
2735/33650 (epoch 4.064), train_loss = 1.44320731, grad/param norm = 1.8533e-01, time/batch = 0.6396s	
2736/33650 (epoch 4.065), train_loss = 1.47630222, grad/param norm = 1.9880e-01, time/batch = 0.6395s	
2737/33650 (epoch 4.067), train_loss = 1.39125926, grad/param norm = 1.8871e-01, time/batch = 0.6477s	
2738/33650 (epoch 4.068), train_loss = 1.54088257, grad/param norm = 1.9239e-01, time/batch = 0.6452s	
2739/33650 (epoch 4.070), train_loss = 1.46114977, grad/param norm = 1.9483e-01, time/batch = 0.6417s	
2740/33650 (epoch 4.071), train_loss = 1.50004396, grad/param norm = 2.0637e-01, time/batch = 0.6413s	
2741/33650 (epoch 4.073), train_loss = 1.61301684, grad/param norm = 2.0479e-01, time/batch = 0.6470s	
2742/33650 (epoch 4.074), train_loss = 1.61570114, grad/param norm = 2.0884e-01, time/batch = 0.6409s	
2743/33650 (epoch 4.076), train_loss = 1.65533277, grad/param norm = 2.0354e-01, time/batch = 0.6414s	
2744/33650 (epoch 4.077), train_loss = 1.43879278, grad/param norm = 1.9185e-01, time/batch = 0.6400s	
2745/33650 (epoch 4.079), train_loss = 1.47888208, grad/param norm = 2.0808e-01, time/batch = 0.6431s	
2746/33650 (epoch 4.080), train_loss = 1.53606217, grad/param norm = 2.1015e-01, time/batch = 0.6461s	
2747/33650 (epoch 4.082), train_loss = 1.64800085, grad/param norm = 2.0867e-01, time/batch = 0.6469s	
2748/33650 (epoch 4.083), train_loss = 1.60201636, grad/param norm = 1.9562e-01, time/batch = 0.6423s	
2749/33650 (epoch 4.085), train_loss = 1.59091793, grad/param norm = 1.9200e-01, time/batch = 0.6398s	
2750/33650 (epoch 4.086), train_loss = 1.61504035, grad/param norm = 2.2740e-01, time/batch = 0.6403s	
2751/33650 (epoch 4.088), train_loss = 1.56843546, grad/param norm = 1.9698e-01, time/batch = 0.6424s	
2752/33650 (epoch 4.089), train_loss = 1.56923027, grad/param norm = 1.9873e-01, time/batch = 0.6433s	
2753/33650 (epoch 4.091), train_loss = 1.41292475, grad/param norm = 2.0290e-01, time/batch = 0.6795s	
2754/33650 (epoch 4.092), train_loss = 1.44246231, grad/param norm = 1.9730e-01, time/batch = 0.6571s	
2755/33650 (epoch 4.094), train_loss = 1.54027109, grad/param norm = 1.7685e-01, time/batch = 0.6425s	
2756/33650 (epoch 4.095), train_loss = 1.60114428, grad/param norm = 2.0893e-01, time/batch = 0.6392s	
2757/33650 (epoch 4.097), train_loss = 1.49202114, grad/param norm = 2.0399e-01, time/batch = 0.6421s	
2758/33650 (epoch 4.098), train_loss = 1.27184160, grad/param norm = 1.6750e-01, time/batch = 0.6394s	
2759/33650 (epoch 4.100), train_loss = 1.39391803, grad/param norm = 1.8337e-01, time/batch = 0.6393s	
2760/33650 (epoch 4.101), train_loss = 1.40667133, grad/param norm = 1.8588e-01, time/batch = 0.6402s	
2761/33650 (epoch 4.103), train_loss = 1.39878444, grad/param norm = 2.0038e-01, time/batch = 0.6449s	
2762/33650 (epoch 4.104), train_loss = 1.54113815, grad/param norm = 1.9535e-01, time/batch = 0.6436s	
2763/33650 (epoch 4.105), train_loss = 1.51227463, grad/param norm = 2.0659e-01, time/batch = 0.6450s	
2764/33650 (epoch 4.107), train_loss = 1.32212937, grad/param norm = 1.8949e-01, time/batch = 0.6420s	
2765/33650 (epoch 4.108), train_loss = 1.54963364, grad/param norm = 2.2352e-01, time/batch = 0.6387s	
2766/33650 (epoch 4.110), train_loss = 1.68065993, grad/param norm = 2.2003e-01, time/batch = 0.6385s	
2767/33650 (epoch 4.111), train_loss = 1.41287488, grad/param norm = 2.1363e-01, time/batch = 0.6383s	
2768/33650 (epoch 4.113), train_loss = 1.44527813, grad/param norm = 1.9768e-01, time/batch = 0.6387s	
2769/33650 (epoch 4.114), train_loss = 1.60833073, grad/param norm = 1.9784e-01, time/batch = 0.6396s	
2770/33650 (epoch 4.116), train_loss = 1.27641178, grad/param norm = 1.8853e-01, time/batch = 0.6469s	
2771/33650 (epoch 4.117), train_loss = 1.53092027, grad/param norm = 1.8073e-01, time/batch = 0.6447s	
2772/33650 (epoch 4.119), train_loss = 1.35859185, grad/param norm = 1.7291e-01, time/batch = 0.6587s	
2773/33650 (epoch 4.120), train_loss = 1.46339561, grad/param norm = 2.3699e-01, time/batch = 0.6847s	
2774/33650 (epoch 4.122), train_loss = 1.34500341, grad/param norm = 1.9398e-01, time/batch = 1.2222s	
2775/33650 (epoch 4.123), train_loss = 1.41823966, grad/param norm = 1.7246e-01, time/batch = 0.7137s	
2776/33650 (epoch 4.125), train_loss = 1.61866876, grad/param norm = 2.1263e-01, time/batch = 0.6387s	
2777/33650 (epoch 4.126), train_loss = 1.70202817, grad/param norm = 1.9667e-01, time/batch = 0.6378s	
2778/33650 (epoch 4.128), train_loss = 1.61860640, grad/param norm = 2.0900e-01, time/batch = 0.6377s	
2779/33650 (epoch 4.129), train_loss = 1.63671982, grad/param norm = 1.9228e-01, time/batch = 0.6405s	
2780/33650 (epoch 4.131), train_loss = 1.57240962, grad/param norm = 1.9666e-01, time/batch = 0.6461s	
2781/33650 (epoch 4.132), train_loss = 1.50944009, grad/param norm = 1.8222e-01, time/batch = 0.6488s	
2782/33650 (epoch 4.134), train_loss = 1.72678527, grad/param norm = 1.9400e-01, time/batch = 0.6459s	
2783/33650 (epoch 4.135), train_loss = 1.39488399, grad/param norm = 1.8896e-01, time/batch = 0.6445s	
2784/33650 (epoch 4.137), train_loss = 1.47280169, grad/param norm = 1.7494e-01, time/batch = 0.6539s	
2785/33650 (epoch 4.138), train_loss = 1.55047561, grad/param norm = 1.9227e-01, time/batch = 0.6569s	
2786/33650 (epoch 4.140), train_loss = 1.53811099, grad/param norm = 2.0553e-01, time/batch = 0.6560s	
2787/33650 (epoch 4.141), train_loss = 1.67688432, grad/param norm = 2.0787e-01, time/batch = 0.6676s	
2788/33650 (epoch 4.143), train_loss = 1.81303192, grad/param norm = 2.1961e-01, time/batch = 0.6730s	
2789/33650 (epoch 4.144), train_loss = 1.73174222, grad/param norm = 2.1218e-01, time/batch = 0.6394s	
2790/33650 (epoch 4.146), train_loss = 1.53699518, grad/param norm = 2.0192e-01, time/batch = 0.6420s	
2791/33650 (epoch 4.147), train_loss = 1.44732920, grad/param norm = 1.9505e-01, time/batch = 0.6461s	
2792/33650 (epoch 4.149), train_loss = 1.33897310, grad/param norm = 1.7782e-01, time/batch = 0.6411s	
2793/33650 (epoch 4.150), train_loss = 1.34575852, grad/param norm = 1.6492e-01, time/batch = 0.6406s	
2794/33650 (epoch 4.152), train_loss = 1.44437785, grad/param norm = 1.9226e-01, time/batch = 0.6437s	
2795/33650 (epoch 4.153), train_loss = 1.49095625, grad/param norm = 1.9335e-01, time/batch = 0.6396s	
2796/33650 (epoch 4.155), train_loss = 1.37116022, grad/param norm = 1.6812e-01, time/batch = 0.6408s	
2797/33650 (epoch 4.156), train_loss = 1.41361533, grad/param norm = 1.7897e-01, time/batch = 0.6404s	
2798/33650 (epoch 4.158), train_loss = 1.54916268, grad/param norm = 2.1186e-01, time/batch = 0.6407s	
2799/33650 (epoch 4.159), train_loss = 1.24400546, grad/param norm = 1.7952e-01, time/batch = 0.6412s	
2800/33650 (epoch 4.160), train_loss = 1.33913149, grad/param norm = 1.6672e-01, time/batch = 0.6387s	
2801/33650 (epoch 4.162), train_loss = 1.44154613, grad/param norm = 2.1605e-01, time/batch = 0.6450s	
2802/33650 (epoch 4.163), train_loss = 1.61674868, grad/param norm = 2.2385e-01, time/batch = 0.6419s	
2803/33650 (epoch 4.165), train_loss = 1.36074670, grad/param norm = 1.7744e-01, time/batch = 0.6411s	
2804/33650 (epoch 4.166), train_loss = 1.35552580, grad/param norm = 1.9241e-01, time/batch = 0.6409s	
2805/33650 (epoch 4.168), train_loss = 1.62831316, grad/param norm = 1.9509e-01, time/batch = 0.6412s	
2806/33650 (epoch 4.169), train_loss = 1.40536692, grad/param norm = 1.8532e-01, time/batch = 0.6414s	
2807/33650 (epoch 4.171), train_loss = 1.53403860, grad/param norm = 1.9681e-01, time/batch = 0.6730s	
2808/33650 (epoch 4.172), train_loss = 1.43044721, grad/param norm = 1.8396e-01, time/batch = 0.6720s	
2809/33650 (epoch 4.174), train_loss = 1.36702706, grad/param norm = 1.7966e-01, time/batch = 0.6410s	
2810/33650 (epoch 4.175), train_loss = 1.34986009, grad/param norm = 1.8850e-01, time/batch = 0.6396s	
2811/33650 (epoch 4.177), train_loss = 1.53048238, grad/param norm = 1.7433e-01, time/batch = 0.6429s	
2812/33650 (epoch 4.178), train_loss = 1.40337012, grad/param norm = 1.9450e-01, time/batch = 0.6428s	
2813/33650 (epoch 4.180), train_loss = 1.39837074, grad/param norm = 1.9463e-01, time/batch = 0.6482s	
2814/33650 (epoch 4.181), train_loss = 1.23305507, grad/param norm = 1.7211e-01, time/batch = 0.6477s	
2815/33650 (epoch 4.183), train_loss = 1.42342735, grad/param norm = 2.0543e-01, time/batch = 0.6432s	
2816/33650 (epoch 4.184), train_loss = 1.47154115, grad/param norm = 2.0221e-01, time/batch = 0.6412s	
2817/33650 (epoch 4.186), train_loss = 1.52607650, grad/param norm = 1.9877e-01, time/batch = 0.6388s	
2818/33650 (epoch 4.187), train_loss = 1.62127855, grad/param norm = 2.0968e-01, time/batch = 0.6399s	
2819/33650 (epoch 4.189), train_loss = 1.65323356, grad/param norm = 2.0421e-01, time/batch = 0.6422s	
2820/33650 (epoch 4.190), train_loss = 1.58424114, grad/param norm = 2.0836e-01, time/batch = 0.6375s	
2821/33650 (epoch 4.192), train_loss = 1.69548416, grad/param norm = 2.0004e-01, time/batch = 0.6413s	
2822/33650 (epoch 4.193), train_loss = 1.63789482, grad/param norm = 2.0578e-01, time/batch = 0.6400s	
2823/33650 (epoch 4.195), train_loss = 1.34311010, grad/param norm = 1.7861e-01, time/batch = 0.6399s	
2824/33650 (epoch 4.196), train_loss = 1.24663175, grad/param norm = 1.8762e-01, time/batch = 0.6430s	
2825/33650 (epoch 4.198), train_loss = 1.48488648, grad/param norm = 2.0569e-01, time/batch = 0.6466s	
2826/33650 (epoch 4.199), train_loss = 1.60760582, grad/param norm = 2.1304e-01, time/batch = 0.6426s	
2827/33650 (epoch 4.201), train_loss = 1.54534539, grad/param norm = 2.0561e-01, time/batch = 0.6433s	
2828/33650 (epoch 4.202), train_loss = 1.46220923, grad/param norm = 1.9205e-01, time/batch = 0.6404s	
2829/33650 (epoch 4.204), train_loss = 1.58074303, grad/param norm = 2.0067e-01, time/batch = 0.6400s	
2830/33650 (epoch 4.205), train_loss = 1.45896593, grad/param norm = 2.0701e-01, time/batch = 0.6411s	
2831/33650 (epoch 4.207), train_loss = 1.52143839, grad/param norm = 1.8961e-01, time/batch = 0.6407s	
2832/33650 (epoch 4.208), train_loss = 1.46945763, grad/param norm = 1.9668e-01, time/batch = 0.6750s	
2833/33650 (epoch 4.210), train_loss = 1.17757538, grad/param norm = 1.7813e-01, time/batch = 0.6671s	
2834/33650 (epoch 4.211), train_loss = 1.45990768, grad/param norm = 1.9007e-01, time/batch = 0.6418s	
2835/33650 (epoch 4.212), train_loss = 1.53452153, grad/param norm = 2.0085e-01, time/batch = 0.6378s	
2836/33650 (epoch 4.214), train_loss = 1.62607586, grad/param norm = 1.9943e-01, time/batch = 0.6387s	
2837/33650 (epoch 4.215), train_loss = 1.27458315, grad/param norm = 1.7419e-01, time/batch = 0.6393s	
2838/33650 (epoch 4.217), train_loss = 1.49262765, grad/param norm = 1.9006e-01, time/batch = 0.6384s	
2839/33650 (epoch 4.218), train_loss = 1.59505970, grad/param norm = 1.8561e-01, time/batch = 0.6441s	
2840/33650 (epoch 4.220), train_loss = 1.42078420, grad/param norm = 1.9350e-01, time/batch = 0.6555s	
2841/33650 (epoch 4.221), train_loss = 1.62652167, grad/param norm = 1.8398e-01, time/batch = 0.6434s	
2842/33650 (epoch 4.223), train_loss = 1.23149190, grad/param norm = 1.7747e-01, time/batch = 0.6435s	
2843/33650 (epoch 4.224), train_loss = 1.46144132, grad/param norm = 1.9450e-01, time/batch = 0.6413s	
2844/33650 (epoch 4.226), train_loss = 1.88827875, grad/param norm = 2.4801e-01, time/batch = 0.6408s	
2845/33650 (epoch 4.227), train_loss = 1.64127215, grad/param norm = 1.9697e-01, time/batch = 0.6397s	
2846/33650 (epoch 4.229), train_loss = 1.56313233, grad/param norm = 1.9682e-01, time/batch = 0.6396s	
2847/33650 (epoch 4.230), train_loss = 1.73932086, grad/param norm = 2.2927e-01, time/batch = 0.6418s	
2848/33650 (epoch 4.232), train_loss = 1.54546042, grad/param norm = 2.0254e-01, time/batch = 0.6409s	
2849/33650 (epoch 4.233), train_loss = 1.56506207, grad/param norm = 2.1828e-01, time/batch = 0.6378s	
2850/33650 (epoch 4.235), train_loss = 1.47208688, grad/param norm = 1.9301e-01, time/batch = 0.6392s	
2851/33650 (epoch 4.236), train_loss = 1.35865535, grad/param norm = 1.9385e-01, time/batch = 0.6426s	
2852/33650 (epoch 4.238), train_loss = 1.50508368, grad/param norm = 1.8482e-01, time/batch = 0.6715s	
2853/33650 (epoch 4.239), train_loss = 1.36473973, grad/param norm = 1.9114e-01, time/batch = 0.6665s	
2854/33650 (epoch 4.241), train_loss = 1.43908417, grad/param norm = 1.8613e-01, time/batch = 0.6397s	
2855/33650 (epoch 4.242), train_loss = 1.32816498, grad/param norm = 1.8180e-01, time/batch = 0.6395s	
2856/33650 (epoch 4.244), train_loss = 1.50725413, grad/param norm = 1.9117e-01, time/batch = 0.6406s	
2857/33650 (epoch 4.245), train_loss = 1.32640780, grad/param norm = 1.8891e-01, time/batch = 0.6391s	
2858/33650 (epoch 4.247), train_loss = 1.44583110, grad/param norm = 1.7952e-01, time/batch = 0.6390s	
2859/33650 (epoch 4.248), train_loss = 1.47474874, grad/param norm = 1.9958e-01, time/batch = 0.6390s	
2860/33650 (epoch 4.250), train_loss = 1.52700197, grad/param norm = 1.7983e-01, time/batch = 0.6401s	
2861/33650 (epoch 4.251), train_loss = 1.66041400, grad/param norm = 1.9801e-01, time/batch = 0.6429s	
2862/33650 (epoch 4.253), train_loss = 1.31603799, grad/param norm = 1.9034e-01, time/batch = 0.6524s	
2863/33650 (epoch 4.254), train_loss = 1.37956412, grad/param norm = 1.8389e-01, time/batch = 0.6621s	
2864/33650 (epoch 4.256), train_loss = 1.53972350, grad/param norm = 1.9657e-01, time/batch = 0.6524s	
2865/33650 (epoch 4.257), train_loss = 1.75848533, grad/param norm = 2.3327e-01, time/batch = 0.6624s	
2866/33650 (epoch 4.259), train_loss = 1.23627939, grad/param norm = 1.8393e-01, time/batch = 0.6732s	
2867/33650 (epoch 4.260), train_loss = 1.65638355, grad/param norm = 2.0987e-01, time/batch = 0.6608s	
2868/33650 (epoch 4.262), train_loss = 1.54671867, grad/param norm = 1.9944e-01, time/batch = 0.6489s	
2869/33650 (epoch 4.263), train_loss = 1.50430672, grad/param norm = 2.0749e-01, time/batch = 0.6440s	
2870/33650 (epoch 4.264), train_loss = 1.48361560, grad/param norm = 1.9253e-01, time/batch = 0.6482s	
2871/33650 (epoch 4.266), train_loss = 1.43543023, grad/param norm = 1.9425e-01, time/batch = 0.6507s	
2872/33650 (epoch 4.267), train_loss = 1.44238912, grad/param norm = 2.3156e-01, time/batch = 0.6782s	
2873/33650 (epoch 4.269), train_loss = 1.60985120, grad/param norm = 2.1208e-01, time/batch = 0.6624s	
2874/33650 (epoch 4.270), train_loss = 1.42108959, grad/param norm = 1.9176e-01, time/batch = 0.6389s	
2875/33650 (epoch 4.272), train_loss = 1.47229395, grad/param norm = 1.7000e-01, time/batch = 0.6406s	
2876/33650 (epoch 4.273), train_loss = 1.69582961, grad/param norm = 2.0629e-01, time/batch = 0.6426s	
2877/33650 (epoch 4.275), train_loss = 1.61603829, grad/param norm = 2.0521e-01, time/batch = 0.6473s	
2878/33650 (epoch 4.276), train_loss = 1.65387164, grad/param norm = 2.0999e-01, time/batch = 0.6538s	
2879/33650 (epoch 4.278), train_loss = 1.78009850, grad/param norm = 2.2373e-01, time/batch = 0.6556s	
2880/33650 (epoch 4.279), train_loss = 1.40526384, grad/param norm = 1.9577e-01, time/batch = 0.6536s	
2881/33650 (epoch 4.281), train_loss = 1.56404137, grad/param norm = 2.1758e-01, time/batch = 0.6499s	
2882/33650 (epoch 4.282), train_loss = 1.57831959, grad/param norm = 1.8037e-01, time/batch = 0.6419s	
2883/33650 (epoch 4.284), train_loss = 1.64495544, grad/param norm = 2.0489e-01, time/batch = 0.6401s	
2884/33650 (epoch 4.285), train_loss = 1.61797081, grad/param norm = 2.0241e-01, time/batch = 0.6415s	
2885/33650 (epoch 4.287), train_loss = 1.48443050, grad/param norm = 2.0287e-01, time/batch = 0.6443s	
2886/33650 (epoch 4.288), train_loss = 1.52572475, grad/param norm = 2.0469e-01, time/batch = 0.6476s	
2887/33650 (epoch 4.290), train_loss = 1.47227922, grad/param norm = 1.8322e-01, time/batch = 0.6678s	
2888/33650 (epoch 4.291), train_loss = 1.31608467, grad/param norm = 1.6159e-01, time/batch = 0.6752s	
2889/33650 (epoch 4.293), train_loss = 1.53334314, grad/param norm = 2.1118e-01, time/batch = 0.6384s	
2890/33650 (epoch 4.294), train_loss = 1.33032524, grad/param norm = 1.7883e-01, time/batch = 0.6397s	
2891/33650 (epoch 4.296), train_loss = 1.26260966, grad/param norm = 1.6384e-01, time/batch = 0.6458s	
2892/33650 (epoch 4.297), train_loss = 1.53172503, grad/param norm = 1.8565e-01, time/batch = 0.6478s	
2893/33650 (epoch 4.299), train_loss = 1.34207817, grad/param norm = 1.7296e-01, time/batch = 0.6439s	
2894/33650 (epoch 4.300), train_loss = 1.46513811, grad/param norm = 1.8696e-01, time/batch = 0.6440s	
2895/33650 (epoch 4.302), train_loss = 1.42313944, grad/param norm = 1.7235e-01, time/batch = 0.6399s	
2896/33650 (epoch 4.303), train_loss = 1.51641077, grad/param norm = 1.8622e-01, time/batch = 0.6396s	
2897/33650 (epoch 4.305), train_loss = 1.54428873, grad/param norm = 1.9125e-01, time/batch = 0.6401s	
2898/33650 (epoch 4.306), train_loss = 1.39916274, grad/param norm = 1.8344e-01, time/batch = 0.6407s	
2899/33650 (epoch 4.308), train_loss = 1.44220882, grad/param norm = 1.8847e-01, time/batch = 0.6409s	
2900/33650 (epoch 4.309), train_loss = 1.61980953, grad/param norm = 1.9318e-01, time/batch = 0.6385s	
2901/33650 (epoch 4.311), train_loss = 1.56657739, grad/param norm = 1.9115e-01, time/batch = 0.6426s	
2902/33650 (epoch 4.312), train_loss = 1.42940769, grad/param norm = 1.7099e-01, time/batch = 0.6417s	
2903/33650 (epoch 4.314), train_loss = 1.22015052, grad/param norm = 1.6282e-01, time/batch = 0.6388s	
2904/33650 (epoch 4.315), train_loss = 1.50883250, grad/param norm = 1.9581e-01, time/batch = 0.6403s	
2905/33650 (epoch 4.316), train_loss = 1.48239235, grad/param norm = 2.0233e-01, time/batch = 0.6432s	
2906/33650 (epoch 4.318), train_loss = 1.35014589, grad/param norm = 1.6431e-01, time/batch = 0.6463s	
2907/33650 (epoch 4.319), train_loss = 1.40152435, grad/param norm = 1.7623e-01, time/batch = 0.6452s	
2908/33650 (epoch 4.321), train_loss = 1.45925225, grad/param norm = 1.8330e-01, time/batch = 0.6413s	
2909/33650 (epoch 4.322), train_loss = 1.50711343, grad/param norm = 2.0908e-01, time/batch = 0.6403s	
2910/33650 (epoch 4.324), train_loss = 1.59037062, grad/param norm = 2.0056e-01, time/batch = 0.6405s	
2911/33650 (epoch 4.325), train_loss = 1.54750987, grad/param norm = 2.0478e-01, time/batch = 0.6436s	
2912/33650 (epoch 4.327), train_loss = 1.32961448, grad/param norm = 1.9186e-01, time/batch = 0.6751s	
2913/33650 (epoch 4.328), train_loss = 1.53763387, grad/param norm = 2.0414e-01, time/batch = 0.6634s	
2914/33650 (epoch 4.330), train_loss = 1.38631206, grad/param norm = 1.7967e-01, time/batch = 0.6419s	
2915/33650 (epoch 4.331), train_loss = 1.25829140, grad/param norm = 1.5716e-01, time/batch = 0.6414s	
2916/33650 (epoch 4.333), train_loss = 1.48127707, grad/param norm = 1.8749e-01, time/batch = 0.6420s	
2917/33650 (epoch 4.334), train_loss = 1.50025081, grad/param norm = 1.8768e-01, time/batch = 0.6412s	
2918/33650 (epoch 4.336), train_loss = 1.53178415, grad/param norm = 1.9170e-01, time/batch = 0.6413s	
2919/33650 (epoch 4.337), train_loss = 1.21045488, grad/param norm = 1.6461e-01, time/batch = 0.6507s	
2920/33650 (epoch 4.339), train_loss = 1.44705842, grad/param norm = 1.8056e-01, time/batch = 0.6422s	
2921/33650 (epoch 4.340), train_loss = 1.75627760, grad/param norm = 2.0065e-01, time/batch = 0.6463s	
2922/33650 (epoch 4.342), train_loss = 1.17574848, grad/param norm = 1.7514e-01, time/batch = 0.6428s	
2923/33650 (epoch 4.343), train_loss = 1.54764107, grad/param norm = 2.0066e-01, time/batch = 0.6421s	
2924/33650 (epoch 4.345), train_loss = 1.46950442, grad/param norm = 1.9618e-01, time/batch = 0.6386s	
2925/33650 (epoch 4.346), train_loss = 1.12005257, grad/param norm = 1.9810e-01, time/batch = 0.6412s	
2926/33650 (epoch 4.348), train_loss = 1.32963479, grad/param norm = 1.8671e-01, time/batch = 0.6390s	
2927/33650 (epoch 4.349), train_loss = 1.27291160, grad/param norm = 2.0900e-01, time/batch = 0.6385s	
2928/33650 (epoch 4.351), train_loss = 1.57120636, grad/param norm = 1.8200e-01, time/batch = 0.6393s	
2929/33650 (epoch 4.352), train_loss = 1.41552346, grad/param norm = 1.7605e-01, time/batch = 0.6400s	
2930/33650 (epoch 4.354), train_loss = 1.82766850, grad/param norm = 2.0778e-01, time/batch = 0.6448s	
2931/33650 (epoch 4.355), train_loss = 1.57314175, grad/param norm = 1.8848e-01, time/batch = 0.6576s	
2932/33650 (epoch 4.357), train_loss = 1.27842009, grad/param norm = 1.7592e-01, time/batch = 0.6781s	
2933/33650 (epoch 4.358), train_loss = 1.59310790, grad/param norm = 1.9504e-01, time/batch = 0.6707s	
2934/33650 (epoch 4.360), train_loss = 1.57615343, grad/param norm = 1.9312e-01, time/batch = 0.6498s	
2935/33650 (epoch 4.361), train_loss = 1.46038953, grad/param norm = 1.8115e-01, time/batch = 0.6475s	
2936/33650 (epoch 4.363), train_loss = 1.39401169, grad/param norm = 1.8494e-01, time/batch = 0.6579s	
2937/33650 (epoch 4.364), train_loss = 1.43785145, grad/param norm = 1.7351e-01, time/batch = 0.6487s	
2938/33650 (epoch 4.366), train_loss = 1.46149555, grad/param norm = 2.0282e-01, time/batch = 0.6481s	
2939/33650 (epoch 4.367), train_loss = 1.54268992, grad/param norm = 1.7828e-01, time/batch = 0.6455s	
2940/33650 (epoch 4.368), train_loss = 1.32633656, grad/param norm = 1.9723e-01, time/batch = 0.6464s	
2941/33650 (epoch 4.370), train_loss = 1.50499659, grad/param norm = 1.8521e-01, time/batch = 0.6526s	
2942/33650 (epoch 4.371), train_loss = 1.25663260, grad/param norm = 1.7457e-01, time/batch = 0.6490s	
2943/33650 (epoch 4.373), train_loss = 1.36376089, grad/param norm = 1.8256e-01, time/batch = 0.6531s	
2944/33650 (epoch 4.374), train_loss = 1.24618128, grad/param norm = 1.6406e-01, time/batch = 0.6472s	
2945/33650 (epoch 4.376), train_loss = 1.42063286, grad/param norm = 1.8060e-01, time/batch = 0.6375s	
2946/33650 (epoch 4.377), train_loss = 1.54245550, grad/param norm = 1.9462e-01, time/batch = 0.6386s	
2947/33650 (epoch 4.379), train_loss = 1.44863102, grad/param norm = 1.9318e-01, time/batch = 0.6389s	
2948/33650 (epoch 4.380), train_loss = 1.22870800, grad/param norm = 1.9202e-01, time/batch = 0.6390s	
2949/33650 (epoch 4.382), train_loss = 1.19417514, grad/param norm = 1.5916e-01, time/batch = 0.6376s	
2950/33650 (epoch 4.383), train_loss = 1.37726364, grad/param norm = 1.7923e-01, time/batch = 0.6371s	
2951/33650 (epoch 4.385), train_loss = 1.55356026, grad/param norm = 1.7491e-01, time/batch = 0.6467s	
2952/33650 (epoch 4.386), train_loss = 1.32450459, grad/param norm = 1.7000e-01, time/batch = 0.6762s	
2953/33650 (epoch 4.388), train_loss = 1.36217569, grad/param norm = 1.7740e-01, time/batch = 0.6644s	
2954/33650 (epoch 4.389), train_loss = 1.53697361, grad/param norm = 2.1894e-01, time/batch = 0.6449s	
2955/33650 (epoch 4.391), train_loss = 1.22481211, grad/param norm = 1.5330e-01, time/batch = 0.6448s	
2956/33650 (epoch 4.392), train_loss = 1.62972235, grad/param norm = 2.0007e-01, time/batch = 0.6593s	
2957/33650 (epoch 4.394), train_loss = 1.59111105, grad/param norm = 2.2291e-01, time/batch = 0.6423s	
2958/33650 (epoch 4.395), train_loss = 1.44234631, grad/param norm = 2.0808e-01, time/batch = 0.6787s	
2959/33650 (epoch 4.397), train_loss = 1.66784409, grad/param norm = 1.9110e-01, time/batch = 0.6434s	
2960/33650 (epoch 4.398), train_loss = 1.44422410, grad/param norm = 1.6329e-01, time/batch = 0.6425s	
2961/33650 (epoch 4.400), train_loss = 1.58142105, grad/param norm = 2.1180e-01, time/batch = 0.6487s	
2962/33650 (epoch 4.401), train_loss = 1.52036343, grad/param norm = 1.9276e-01, time/batch = 0.6414s	
2963/33650 (epoch 4.403), train_loss = 1.49720503, grad/param norm = 1.8601e-01, time/batch = 0.6494s	
2964/33650 (epoch 4.404), train_loss = 1.43516963, grad/param norm = 1.6531e-01, time/batch = 0.6621s	
2965/33650 (epoch 4.406), train_loss = 1.53979949, grad/param norm = 1.7892e-01, time/batch = 0.6410s	
2966/33650 (epoch 4.407), train_loss = 1.40976088, grad/param norm = 1.6959e-01, time/batch = 0.6417s	
2967/33650 (epoch 4.409), train_loss = 1.49516750, grad/param norm = 1.7784e-01, time/batch = 0.6686s	
2968/33650 (epoch 4.410), train_loss = 1.46607282, grad/param norm = 1.9015e-01, time/batch = 0.6735s	
2969/33650 (epoch 4.412), train_loss = 1.43564948, grad/param norm = 1.7099e-01, time/batch = 0.6414s	
2970/33650 (epoch 4.413), train_loss = 1.33754202, grad/param norm = 1.7871e-01, time/batch = 0.6419s	
2971/33650 (epoch 4.415), train_loss = 1.50126229, grad/param norm = 1.9719e-01, time/batch = 0.6516s	
2972/33650 (epoch 4.416), train_loss = 1.64322338, grad/param norm = 2.0585e-01, time/batch = 0.6425s	
2973/33650 (epoch 4.418), train_loss = 1.51707722, grad/param norm = 2.0520e-01, time/batch = 0.6419s	
2974/33650 (epoch 4.419), train_loss = 1.45475871, grad/param norm = 1.9304e-01, time/batch = 0.6401s	
2975/33650 (epoch 4.421), train_loss = 1.29670642, grad/param norm = 1.6999e-01, time/batch = 0.6461s	
2976/33650 (epoch 4.422), train_loss = 1.54256614, grad/param norm = 1.9399e-01, time/batch = 0.6511s	
2977/33650 (epoch 4.423), train_loss = 1.34508693, grad/param norm = 1.7252e-01, time/batch = 0.6548s	
2978/33650 (epoch 4.425), train_loss = 1.53364203, grad/param norm = 1.7737e-01, time/batch = 0.6407s	
2979/33650 (epoch 4.426), train_loss = 1.59742785, grad/param norm = 1.8238e-01, time/batch = 0.6420s	
2980/33650 (epoch 4.428), train_loss = 1.37070885, grad/param norm = 1.7852e-01, time/batch = 0.6420s	
2981/33650 (epoch 4.429), train_loss = 1.55813935, grad/param norm = 1.9275e-01, time/batch = 0.6473s	
2982/33650 (epoch 4.431), train_loss = 1.74936929, grad/param norm = 2.0136e-01, time/batch = 0.6414s	
2983/33650 (epoch 4.432), train_loss = 1.74379705, grad/param norm = 1.9199e-01, time/batch = 0.6398s	
2984/33650 (epoch 4.434), train_loss = 1.55504164, grad/param norm = 1.8874e-01, time/batch = 0.6392s	
2985/33650 (epoch 4.435), train_loss = 1.49882701, grad/param norm = 1.8328e-01, time/batch = 0.6419s	
2986/33650 (epoch 4.437), train_loss = 1.55987798, grad/param norm = 1.9467e-01, time/batch = 0.6390s	
2987/33650 (epoch 4.438), train_loss = 1.38781816, grad/param norm = 2.0786e-01, time/batch = 0.6640s	
2988/33650 (epoch 4.440), train_loss = 1.50048811, grad/param norm = 1.9883e-01, time/batch = 0.6743s	
2989/33650 (epoch 4.441), train_loss = 1.55163624, grad/param norm = 1.9161e-01, time/batch = 0.6486s	
2990/33650 (epoch 4.443), train_loss = 1.57218319, grad/param norm = 1.9821e-01, time/batch = 0.6388s	
2991/33650 (epoch 4.444), train_loss = 1.42188119, grad/param norm = 1.7494e-01, time/batch = 0.6429s	
2992/33650 (epoch 4.446), train_loss = 1.53526191, grad/param norm = 1.8736e-01, time/batch = 0.6406s	
2993/33650 (epoch 4.447), train_loss = 1.59541329, grad/param norm = 2.0706e-01, time/batch = 0.6430s	
2994/33650 (epoch 4.449), train_loss = 1.75159465, grad/param norm = 2.5937e-01, time/batch = 0.6445s	
2995/33650 (epoch 4.450), train_loss = 1.76070440, grad/param norm = 2.0515e-01, time/batch = 0.6482s	
2996/33650 (epoch 4.452), train_loss = 1.84538827, grad/param norm = 2.3075e-01, time/batch = 0.6492s	
2997/33650 (epoch 4.453), train_loss = 1.71765847, grad/param norm = 2.1202e-01, time/batch = 0.6569s	
2998/33650 (epoch 4.455), train_loss = 1.49832404, grad/param norm = 1.8398e-01, time/batch = 0.6548s	
2999/33650 (epoch 4.456), train_loss = 1.44814167, grad/param norm = 1.8624e-01, time/batch = 0.6595s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch4.46_1.6384.t7	
3000/33650 (epoch 4.458), train_loss = 1.52908595, grad/param norm = 2.1002e-01, time/batch = 0.6472s	
3001/33650 (epoch 4.459), train_loss = 1.56101100, grad/param norm = 1.9473e-01, time/batch = 0.6563s	
3002/33650 (epoch 4.461), train_loss = 1.58455340, grad/param norm = 1.9400e-01, time/batch = 0.6448s	
3003/33650 (epoch 4.462), train_loss = 1.65315017, grad/param norm = 1.9480e-01, time/batch = 0.6660s	
3004/33650 (epoch 4.464), train_loss = 1.44588765, grad/param norm = 1.7759e-01, time/batch = 0.6584s	
3005/33650 (epoch 4.465), train_loss = 1.53331214, grad/param norm = 1.8908e-01, time/batch = 0.6723s	
3006/33650 (epoch 4.467), train_loss = 1.55411196, grad/param norm = 1.8133e-01, time/batch = 0.6759s	
3007/33650 (epoch 4.468), train_loss = 1.62737531, grad/param norm = 1.8927e-01, time/batch = 0.6758s	
3008/33650 (epoch 4.470), train_loss = 1.81606220, grad/param norm = 2.1420e-01, time/batch = 0.6679s	
3009/33650 (epoch 4.471), train_loss = 1.49392368, grad/param norm = 1.8658e-01, time/batch = 0.6438s	
3010/33650 (epoch 4.473), train_loss = 1.38394094, grad/param norm = 1.7543e-01, time/batch = 0.6425s	
3011/33650 (epoch 4.474), train_loss = 1.54305538, grad/param norm = 1.9289e-01, time/batch = 0.6405s	
3012/33650 (epoch 4.475), train_loss = 1.61696193, grad/param norm = 1.9520e-01, time/batch = 0.6400s	
3013/33650 (epoch 4.477), train_loss = 1.65577334, grad/param norm = 1.9710e-01, time/batch = 0.6390s	
3014/33650 (epoch 4.478), train_loss = 1.61183858, grad/param norm = 1.8319e-01, time/batch = 0.6391s	
3015/33650 (epoch 4.480), train_loss = 1.68712041, grad/param norm = 1.8989e-01, time/batch = 0.6442s	
3016/33650 (epoch 4.481), train_loss = 1.63007423, grad/param norm = 1.9603e-01, time/batch = 0.6524s	
3017/33650 (epoch 4.483), train_loss = 1.22479585, grad/param norm = 1.7345e-01, time/batch = 0.6631s	
3018/33650 (epoch 4.484), train_loss = 1.52607399, grad/param norm = 1.7687e-01, time/batch = 0.6579s	
3019/33650 (epoch 4.486), train_loss = 1.64907599, grad/param norm = 2.3043e-01, time/batch = 0.6682s	
3020/33650 (epoch 4.487), train_loss = 1.65202574, grad/param norm = 2.3135e-01, time/batch = 0.6510s	
3021/33650 (epoch 4.489), train_loss = 1.74507621, grad/param norm = 1.9394e-01, time/batch = 0.6743s	
3022/33650 (epoch 4.490), train_loss = 1.41052467, grad/param norm = 1.8381e-01, time/batch = 0.6656s	
3023/33650 (epoch 4.492), train_loss = 1.65201062, grad/param norm = 2.0746e-01, time/batch = 0.6613s	
3024/33650 (epoch 4.493), train_loss = 1.24887366, grad/param norm = 1.7366e-01, time/batch = 0.6440s	
3025/33650 (epoch 4.495), train_loss = 1.45968631, grad/param norm = 1.8521e-01, time/batch = 0.6401s	
3026/33650 (epoch 4.496), train_loss = 1.56156305, grad/param norm = 2.1292e-01, time/batch = 0.6355s	
3027/33650 (epoch 4.498), train_loss = 1.30157792, grad/param norm = 1.9981e-01, time/batch = 0.6365s	
3028/33650 (epoch 4.499), train_loss = 1.43882105, grad/param norm = 1.8220e-01, time/batch = 0.6361s	
3029/33650 (epoch 4.501), train_loss = 1.46730492, grad/param norm = 1.7467e-01, time/batch = 0.6376s	
3030/33650 (epoch 4.502), train_loss = 1.57171064, grad/param norm = 2.0925e-01, time/batch = 0.6419s	
3031/33650 (epoch 4.504), train_loss = 1.74111913, grad/param norm = 1.9944e-01, time/batch = 0.6397s	
3032/33650 (epoch 4.505), train_loss = 1.58541486, grad/param norm = 2.2151e-01, time/batch = 0.6506s	
3033/33650 (epoch 4.507), train_loss = 1.64501179, grad/param norm = 2.1951e-01, time/batch = 0.6790s	
3034/33650 (epoch 4.508), train_loss = 1.42898210, grad/param norm = 1.8458e-01, time/batch = 0.6429s	
3035/33650 (epoch 4.510), train_loss = 1.48782976, grad/param norm = 1.9370e-01, time/batch = 0.6381s	
3036/33650 (epoch 4.511), train_loss = 1.77769676, grad/param norm = 2.1525e-01, time/batch = 0.6432s	
3037/33650 (epoch 4.513), train_loss = 1.58445795, grad/param norm = 1.8515e-01, time/batch = 0.6479s	
3038/33650 (epoch 4.514), train_loss = 1.54556435, grad/param norm = 1.9135e-01, time/batch = 0.6600s	
3039/33650 (epoch 4.516), train_loss = 1.53396176, grad/param norm = 1.9555e-01, time/batch = 0.6457s	
3040/33650 (epoch 4.517), train_loss = 1.43205103, grad/param norm = 1.7695e-01, time/batch = 0.6614s	
3041/33650 (epoch 4.519), train_loss = 1.45478332, grad/param norm = 1.6878e-01, time/batch = 0.6441s	
3042/33650 (epoch 4.520), train_loss = 1.26304446, grad/param norm = 1.7218e-01, time/batch = 0.6405s	
3043/33650 (epoch 4.522), train_loss = 1.51173870, grad/param norm = 2.0127e-01, time/batch = 0.6378s	
3044/33650 (epoch 4.523), train_loss = 1.50170522, grad/param norm = 1.8691e-01, time/batch = 0.6383s	
3045/33650 (epoch 4.525), train_loss = 1.18323113, grad/param norm = 1.6905e-01, time/batch = 0.6408s	
3046/33650 (epoch 4.526), train_loss = 1.55440387, grad/param norm = 2.2309e-01, time/batch = 0.6408s	
3047/33650 (epoch 4.527), train_loss = 1.35928750, grad/param norm = 1.8957e-01, time/batch = 0.6397s	
3048/33650 (epoch 4.529), train_loss = 1.45368793, grad/param norm = 1.8125e-01, time/batch = 0.6425s	
3049/33650 (epoch 4.530), train_loss = 1.40741972, grad/param norm = 1.8004e-01, time/batch = 0.6400s	
3050/33650 (epoch 4.532), train_loss = 1.71660739, grad/param norm = 2.1723e-01, time/batch = 0.6387s	
3051/33650 (epoch 4.533), train_loss = 1.39656129, grad/param norm = 1.8569e-01, time/batch = 0.6572s	
3052/33650 (epoch 4.535), train_loss = 1.63970375, grad/param norm = 1.9925e-01, time/batch = 0.6453s	
3053/33650 (epoch 4.536), train_loss = 1.51455179, grad/param norm = 1.9589e-01, time/batch = 0.6413s	
3054/33650 (epoch 4.538), train_loss = 1.53244456, grad/param norm = 1.9828e-01, time/batch = 0.6488s	
3055/33650 (epoch 4.539), train_loss = 1.27377363, grad/param norm = 1.6919e-01, time/batch = 0.6502s	
3056/33650 (epoch 4.541), train_loss = 1.63397705, grad/param norm = 1.9004e-01, time/batch = 0.6393s	
3057/33650 (epoch 4.542), train_loss = 1.57785923, grad/param norm = 2.1029e-01, time/batch = 0.6667s	
3058/33650 (epoch 4.544), train_loss = 1.81430024, grad/param norm = 2.1564e-01, time/batch = 0.6706s	
3059/33650 (epoch 4.545), train_loss = 1.30171933, grad/param norm = 1.7746e-01, time/batch = 0.6410s	
3060/33650 (epoch 4.547), train_loss = 1.52672848, grad/param norm = 1.9384e-01, time/batch = 0.6485s	
3061/33650 (epoch 4.548), train_loss = 1.63225569, grad/param norm = 1.9601e-01, time/batch = 0.6465s	
3062/33650 (epoch 4.550), train_loss = 1.41771294, grad/param norm = 1.8701e-01, time/batch = 0.6431s	
3063/33650 (epoch 4.551), train_loss = 1.43767139, grad/param norm = 1.9785e-01, time/batch = 0.6419s	
3064/33650 (epoch 4.553), train_loss = 1.26365863, grad/param norm = 1.8917e-01, time/batch = 0.6412s	
3065/33650 (epoch 4.554), train_loss = 1.59525489, grad/param norm = 1.9233e-01, time/batch = 0.6431s	
3066/33650 (epoch 4.556), train_loss = 1.65499437, grad/param norm = 2.5341e-01, time/batch = 0.6505s	
3067/33650 (epoch 4.557), train_loss = 1.69809235, grad/param norm = 2.0343e-01, time/batch = 0.6692s	
3068/33650 (epoch 4.559), train_loss = 1.74918504, grad/param norm = 2.5720e-01, time/batch = 0.6520s	
3069/33650 (epoch 4.560), train_loss = 1.70121042, grad/param norm = 1.9863e-01, time/batch = 0.6413s	
3070/33650 (epoch 4.562), train_loss = 1.60692399, grad/param norm = 1.9958e-01, time/batch = 0.6470s	
3071/33650 (epoch 4.563), train_loss = 1.46889635, grad/param norm = 1.9667e-01, time/batch = 0.6441s	
3072/33650 (epoch 4.565), train_loss = 1.53463528, grad/param norm = 1.8209e-01, time/batch = 0.6674s	
3073/33650 (epoch 4.566), train_loss = 1.53102795, grad/param norm = 2.1583e-01, time/batch = 0.6675s	
3074/33650 (epoch 4.568), train_loss = 1.53466191, grad/param norm = 1.8737e-01, time/batch = 0.6599s	
3075/33650 (epoch 4.569), train_loss = 1.44172643, grad/param norm = 1.9361e-01, time/batch = 0.6497s	
3076/33650 (epoch 4.571), train_loss = 1.64360505, grad/param norm = 2.0269e-01, time/batch = 0.6399s	
3077/33650 (epoch 4.572), train_loss = 1.54404573, grad/param norm = 1.8114e-01, time/batch = 0.6723s	
3078/33650 (epoch 4.574), train_loss = 1.51910378, grad/param norm = 2.0392e-01, time/batch = 0.6638s	
3079/33650 (epoch 4.575), train_loss = 1.48231035, grad/param norm = 1.8204e-01, time/batch = 0.6361s	
3080/33650 (epoch 4.577), train_loss = 1.62172273, grad/param norm = 1.8548e-01, time/batch = 0.6363s	
3081/33650 (epoch 4.578), train_loss = 1.49458068, grad/param norm = 1.8164e-01, time/batch = 0.6397s	
3082/33650 (epoch 4.579), train_loss = 1.53465739, grad/param norm = 1.8465e-01, time/batch = 0.6415s	
3083/33650 (epoch 4.581), train_loss = 1.52364345, grad/param norm = 1.8647e-01, time/batch = 0.6393s	
3084/33650 (epoch 4.582), train_loss = 1.60236179, grad/param norm = 1.9113e-01, time/batch = 0.6431s	
3085/33650 (epoch 4.584), train_loss = 1.46656843, grad/param norm = 1.8234e-01, time/batch = 0.6438s	
3086/33650 (epoch 4.585), train_loss = 1.50826113, grad/param norm = 1.8877e-01, time/batch = 0.6414s	
3087/33650 (epoch 4.587), train_loss = 1.40650259, grad/param norm = 2.0932e-01, time/batch = 0.6399s	
3088/33650 (epoch 4.588), train_loss = 1.47864949, grad/param norm = 1.9414e-01, time/batch = 0.6366s	
3089/33650 (epoch 4.590), train_loss = 1.48165898, grad/param norm = 1.6916e-01, time/batch = 0.6390s	
3090/33650 (epoch 4.591), train_loss = 1.50863595, grad/param norm = 1.9201e-01, time/batch = 0.6383s	
3091/33650 (epoch 4.593), train_loss = 1.37007547, grad/param norm = 1.8724e-01, time/batch = 0.6432s	
3092/33650 (epoch 4.594), train_loss = 1.21526957, grad/param norm = 2.0580e-01, time/batch = 0.6396s	
3093/33650 (epoch 4.596), train_loss = 1.45290403, grad/param norm = 1.8887e-01, time/batch = 0.6379s	
3094/33650 (epoch 4.597), train_loss = 1.17991209, grad/param norm = 1.5171e-01, time/batch = 0.6380s	
3095/33650 (epoch 4.599), train_loss = 1.32405666, grad/param norm = 1.7237e-01, time/batch = 0.6382s	
3096/33650 (epoch 4.600), train_loss = 1.34233058, grad/param norm = 1.8429e-01, time/batch = 0.6366s	
3097/33650 (epoch 4.602), train_loss = 1.58912381, grad/param norm = 1.8690e-01, time/batch = 0.6660s	
3098/33650 (epoch 4.603), train_loss = 1.40567017, grad/param norm = 1.7855e-01, time/batch = 0.6731s	
3099/33650 (epoch 4.605), train_loss = 1.46073037, grad/param norm = 2.0086e-01, time/batch = 0.6387s	
3100/33650 (epoch 4.606), train_loss = 1.60838752, grad/param norm = 1.8730e-01, time/batch = 0.6376s	
3101/33650 (epoch 4.608), train_loss = 1.50968086, grad/param norm = 1.8777e-01, time/batch = 0.6389s	
3102/33650 (epoch 4.609), train_loss = 1.53956923, grad/param norm = 2.0165e-01, time/batch = 0.6379s	
3103/33650 (epoch 4.611), train_loss = 1.38701650, grad/param norm = 1.7560e-01, time/batch = 0.6375s	
3104/33650 (epoch 4.612), train_loss = 1.51603209, grad/param norm = 1.9388e-01, time/batch = 0.6382s	
3105/33650 (epoch 4.614), train_loss = 1.63833071, grad/param norm = 1.9865e-01, time/batch = 0.6476s	
3106/33650 (epoch 4.615), train_loss = 1.40296602, grad/param norm = 1.8019e-01, time/batch = 0.6371s	
3107/33650 (epoch 4.617), train_loss = 1.31295474, grad/param norm = 1.6399e-01, time/batch = 0.6372s	
3108/33650 (epoch 4.618), train_loss = 1.40306051, grad/param norm = 1.8714e-01, time/batch = 0.6381s	
3109/33650 (epoch 4.620), train_loss = 1.62231052, grad/param norm = 2.0311e-01, time/batch = 0.6386s	
3110/33650 (epoch 4.621), train_loss = 1.31456385, grad/param norm = 1.8552e-01, time/batch = 0.6353s	
3111/33650 (epoch 4.623), train_loss = 1.45894062, grad/param norm = 1.8291e-01, time/batch = 0.6441s	
3112/33650 (epoch 4.624), train_loss = 1.20211279, grad/param norm = 1.8764e-01, time/batch = 0.6428s	
3113/33650 (epoch 4.626), train_loss = 1.17083710, grad/param norm = 1.7160e-01, time/batch = 0.6406s	
3114/33650 (epoch 4.627), train_loss = 1.41494070, grad/param norm = 1.8572e-01, time/batch = 0.6381s	
3115/33650 (epoch 4.629), train_loss = 1.46723063, grad/param norm = 1.7309e-01, time/batch = 0.6406s	
3116/33650 (epoch 4.630), train_loss = 1.54518189, grad/param norm = 1.8781e-01, time/batch = 0.6389s	
3117/33650 (epoch 4.632), train_loss = 1.64478884, grad/param norm = 1.8255e-01, time/batch = 0.6610s	
3118/33650 (epoch 4.633), train_loss = 1.54527864, grad/param norm = 1.8226e-01, time/batch = 0.6762s	
3119/33650 (epoch 4.634), train_loss = 1.30010850, grad/param norm = 1.8109e-01, time/batch = 0.6436s	
3120/33650 (epoch 4.636), train_loss = 1.16652795, grad/param norm = 1.6154e-01, time/batch = 0.6577s	
3121/33650 (epoch 4.637), train_loss = 1.53647740, grad/param norm = 1.9008e-01, time/batch = 0.6422s	
3122/33650 (epoch 4.639), train_loss = 1.42003816, grad/param norm = 1.6967e-01, time/batch = 0.6448s	
3123/33650 (epoch 4.640), train_loss = 1.47244775, grad/param norm = 1.9731e-01, time/batch = 0.6437s	
3124/33650 (epoch 4.642), train_loss = 1.72053603, grad/param norm = 2.0274e-01, time/batch = 0.6398s	
3125/33650 (epoch 4.643), train_loss = 1.50569299, grad/param norm = 1.9729e-01, time/batch = 0.6394s	
3126/33650 (epoch 4.645), train_loss = 1.44571958, grad/param norm = 1.7571e-01, time/batch = 0.6397s	
3127/33650 (epoch 4.646), train_loss = 1.22685455, grad/param norm = 1.5248e-01, time/batch = 0.6380s	
3128/33650 (epoch 4.648), train_loss = 1.44347420, grad/param norm = 1.7877e-01, time/batch = 0.6366s	
3129/33650 (epoch 4.649), train_loss = 1.51661152, grad/param norm = 2.0103e-01, time/batch = 0.6470s	
3130/33650 (epoch 4.651), train_loss = 1.54008477, grad/param norm = 1.8504e-01, time/batch = 0.6508s	
3131/33650 (epoch 4.652), train_loss = 1.07792333, grad/param norm = 1.5527e-01, time/batch = 0.6543s	
3132/33650 (epoch 4.654), train_loss = 1.40919134, grad/param norm = 1.7993e-01, time/batch = 0.6647s	
3133/33650 (epoch 4.655), train_loss = 1.26917915, grad/param norm = 1.6567e-01, time/batch = 0.6824s	
3134/33650 (epoch 4.657), train_loss = 1.43591044, grad/param norm = 1.8203e-01, time/batch = 0.6722s	
3135/33650 (epoch 4.658), train_loss = 1.27875402, grad/param norm = 1.5950e-01, time/batch = 0.6480s	
3136/33650 (epoch 4.660), train_loss = 1.25340274, grad/param norm = 1.5921e-01, time/batch = 0.6495s	
3137/33650 (epoch 4.661), train_loss = 1.36207100, grad/param norm = 1.5734e-01, time/batch = 0.6676s	
3138/33650 (epoch 4.663), train_loss = 1.25793854, grad/param norm = 1.8408e-01, time/batch = 0.6731s	
3139/33650 (epoch 4.664), train_loss = 1.26030060, grad/param norm = 1.7280e-01, time/batch = 0.6389s	
3140/33650 (epoch 4.666), train_loss = 1.36267794, grad/param norm = 1.9259e-01, time/batch = 0.6439s	
3141/33650 (epoch 4.667), train_loss = 1.28858317, grad/param norm = 1.5734e-01, time/batch = 0.6447s	
3142/33650 (epoch 4.669), train_loss = 1.24949857, grad/param norm = 1.7125e-01, time/batch = 0.6406s	
3143/33650 (epoch 4.670), train_loss = 1.25150820, grad/param norm = 1.6668e-01, time/batch = 0.6414s	
3144/33650 (epoch 4.672), train_loss = 1.32818459, grad/param norm = 1.6490e-01, time/batch = 0.6383s	
3145/33650 (epoch 4.673), train_loss = 1.17767338, grad/param norm = 1.7991e-01, time/batch = 0.6473s	
3146/33650 (epoch 4.675), train_loss = 1.16080001, grad/param norm = 1.4838e-01, time/batch = 0.6475s	
3147/33650 (epoch 4.676), train_loss = 1.43810252, grad/param norm = 1.7052e-01, time/batch = 0.6400s	
3148/33650 (epoch 4.678), train_loss = 1.28490601, grad/param norm = 1.7073e-01, time/batch = 0.6400s	
3149/33650 (epoch 4.679), train_loss = 1.40161658, grad/param norm = 1.9805e-01, time/batch = 0.6399s	
3150/33650 (epoch 4.681), train_loss = 1.29131465, grad/param norm = 1.7736e-01, time/batch = 0.6515s	
3151/33650 (epoch 4.682), train_loss = 1.36308102, grad/param norm = 1.8248e-01, time/batch = 0.6531s	
3152/33650 (epoch 4.684), train_loss = 1.27746550, grad/param norm = 1.6310e-01, time/batch = 0.6443s	
3153/33650 (epoch 4.685), train_loss = 1.51479989, grad/param norm = 1.8352e-01, time/batch = 0.6430s	
3154/33650 (epoch 4.686), train_loss = 1.39664052, grad/param norm = 1.9279e-01, time/batch = 0.6416s	
3155/33650 (epoch 4.688), train_loss = 1.61023915, grad/param norm = 1.9794e-01, time/batch = 0.6397s	
3156/33650 (epoch 4.689), train_loss = 1.33640342, grad/param norm = 1.7960e-01, time/batch = 0.6411s	
3157/33650 (epoch 4.691), train_loss = 1.56480897, grad/param norm = 1.9263e-01, time/batch = 0.6679s	
3158/33650 (epoch 4.692), train_loss = 1.54110490, grad/param norm = 1.7257e-01, time/batch = 0.6711s	
3159/33650 (epoch 4.694), train_loss = 1.49997115, grad/param norm = 1.8909e-01, time/batch = 0.6404s	
3160/33650 (epoch 4.695), train_loss = 1.11507140, grad/param norm = 1.7022e-01, time/batch = 0.6408s	
3161/33650 (epoch 4.697), train_loss = 1.46034732, grad/param norm = 1.7676e-01, time/batch = 0.6425s	
3162/33650 (epoch 4.698), train_loss = 1.55090773, grad/param norm = 1.8926e-01, time/batch = 0.6408s	
3163/33650 (epoch 4.700), train_loss = 1.40635530, grad/param norm = 1.7229e-01, time/batch = 0.6432s	
3164/33650 (epoch 4.701), train_loss = 1.52475197, grad/param norm = 1.8856e-01, time/batch = 0.6419s	
3165/33650 (epoch 4.703), train_loss = 1.43667272, grad/param norm = 1.7291e-01, time/batch = 0.6438s	
3166/33650 (epoch 4.704), train_loss = 1.33392566, grad/param norm = 1.7868e-01, time/batch = 0.6400s	
3167/33650 (epoch 4.706), train_loss = 1.37544063, grad/param norm = 1.5971e-01, time/batch = 0.6507s	
3168/33650 (epoch 4.707), train_loss = 1.54151597, grad/param norm = 1.9000e-01, time/batch = 0.6422s	
3169/33650 (epoch 4.709), train_loss = 1.37490356, grad/param norm = 1.8766e-01, time/batch = 0.6441s	
3170/33650 (epoch 4.710), train_loss = 1.57070054, grad/param norm = 1.7314e-01, time/batch = 0.6394s	
3171/33650 (epoch 4.712), train_loss = 1.35095618, grad/param norm = 1.6531e-01, time/batch = 0.6485s	
3172/33650 (epoch 4.713), train_loss = 1.42935478, grad/param norm = 2.2190e-01, time/batch = 0.6462s	
3173/33650 (epoch 4.715), train_loss = 1.58737923, grad/param norm = 1.9526e-01, time/batch = 0.6417s	
3174/33650 (epoch 4.716), train_loss = 1.31780506, grad/param norm = 1.8254e-01, time/batch = 0.6379s	
3175/33650 (epoch 4.718), train_loss = 1.55224895, grad/param norm = 1.8301e-01, time/batch = 0.6383s	
3176/33650 (epoch 4.719), train_loss = 1.59983398, grad/param norm = 2.0305e-01, time/batch = 0.6391s	
3177/33650 (epoch 4.721), train_loss = 1.67512712, grad/param norm = 1.8961e-01, time/batch = 0.6387s	
3178/33650 (epoch 4.722), train_loss = 1.63903396, grad/param norm = 2.0228e-01, time/batch = 0.6381s	
3179/33650 (epoch 4.724), train_loss = 1.52071155, grad/param norm = 1.7748e-01, time/batch = 0.6433s	
3180/33650 (epoch 4.725), train_loss = 1.60107944, grad/param norm = 1.9031e-01, time/batch = 0.6383s	
3181/33650 (epoch 4.727), train_loss = 1.37049941, grad/param norm = 1.9719e-01, time/batch = 0.6407s	
3182/33650 (epoch 4.728), train_loss = 1.36807500, grad/param norm = 1.7059e-01, time/batch = 0.6377s	
3183/33650 (epoch 4.730), train_loss = 1.46688139, grad/param norm = 1.7774e-01, time/batch = 0.6383s	
3184/33650 (epoch 4.731), train_loss = 1.65078724, grad/param norm = 2.0305e-01, time/batch = 0.6410s	
3185/33650 (epoch 4.733), train_loss = 1.37715230, grad/param norm = 1.8122e-01, time/batch = 0.6437s	
3186/33650 (epoch 4.734), train_loss = 1.63595869, grad/param norm = 2.2941e-01, time/batch = 0.6526s	
3187/33650 (epoch 4.736), train_loss = 1.46149513, grad/param norm = 2.0865e-01, time/batch = 0.6398s	
3188/33650 (epoch 4.737), train_loss = 1.45865390, grad/param norm = 1.8060e-01, time/batch = 0.6379s	
3189/33650 (epoch 4.738), train_loss = 1.29295638, grad/param norm = 1.7599e-01, time/batch = 0.6393s	
3190/33650 (epoch 4.740), train_loss = 1.33275277, grad/param norm = 1.8455e-01, time/batch = 0.6418s	
3191/33650 (epoch 4.741), train_loss = 1.42673233, grad/param norm = 1.8450e-01, time/batch = 0.6454s	
3192/33650 (epoch 4.743), train_loss = 1.43857373, grad/param norm = 1.7106e-01, time/batch = 0.6438s	
3193/33650 (epoch 4.744), train_loss = 1.36700144, grad/param norm = 1.7017e-01, time/batch = 0.6437s	
3194/33650 (epoch 4.746), train_loss = 1.40298377, grad/param norm = 1.7761e-01, time/batch = 0.6390s	
3195/33650 (epoch 4.747), train_loss = 1.53725683, grad/param norm = 1.8071e-01, time/batch = 0.6388s	
3196/33650 (epoch 4.749), train_loss = 1.18531013, grad/param norm = 1.6797e-01, time/batch = 0.6388s	
3197/33650 (epoch 4.750), train_loss = 1.50647563, grad/param norm = 2.0863e-01, time/batch = 0.6564s	
3198/33650 (epoch 4.752), train_loss = 1.56623780, grad/param norm = 2.1736e-01, time/batch = 0.6785s	
3199/33650 (epoch 4.753), train_loss = 1.68696872, grad/param norm = 1.9834e-01, time/batch = 0.6417s	
3200/33650 (epoch 4.755), train_loss = 1.31316625, grad/param norm = 1.8634e-01, time/batch = 0.6419s	
3201/33650 (epoch 4.756), train_loss = 1.49490855, grad/param norm = 1.9129e-01, time/batch = 0.6406s	
3202/33650 (epoch 4.758), train_loss = 1.63432899, grad/param norm = 2.0301e-01, time/batch = 0.6398s	
3203/33650 (epoch 4.759), train_loss = 1.69666885, grad/param norm = 1.8995e-01, time/batch = 0.6392s	
3204/33650 (epoch 4.761), train_loss = 1.54177293, grad/param norm = 1.9136e-01, time/batch = 0.6413s	
3205/33650 (epoch 4.762), train_loss = 1.44896491, grad/param norm = 1.9030e-01, time/batch = 0.6401s	
3206/33650 (epoch 4.764), train_loss = 1.63181356, grad/param norm = 2.2644e-01, time/batch = 0.6413s	
3207/33650 (epoch 4.765), train_loss = 1.51828986, grad/param norm = 1.8955e-01, time/batch = 0.6414s	
3208/33650 (epoch 4.767), train_loss = 1.29971136, grad/param norm = 1.6555e-01, time/batch = 0.6402s	
3209/33650 (epoch 4.768), train_loss = 1.27710646, grad/param norm = 1.6862e-01, time/batch = 0.6413s	
3210/33650 (epoch 4.770), train_loss = 1.42126908, grad/param norm = 1.9081e-01, time/batch = 0.6397s	
3211/33650 (epoch 4.771), train_loss = 1.44078113, grad/param norm = 1.9267e-01, time/batch = 0.6430s	
3212/33650 (epoch 4.773), train_loss = 1.62946998, grad/param norm = 2.1101e-01, time/batch = 0.6401s	
3213/33650 (epoch 4.774), train_loss = 1.50530238, grad/param norm = 1.9058e-01, time/batch = 0.6397s	
3214/33650 (epoch 4.776), train_loss = 1.57247958, grad/param norm = 2.2213e-01, time/batch = 0.6447s	
3215/33650 (epoch 4.777), train_loss = 1.32242026, grad/param norm = 1.8239e-01, time/batch = 0.6396s	
3216/33650 (epoch 4.779), train_loss = 1.43371569, grad/param norm = 1.6414e-01, time/batch = 0.6411s	
3217/33650 (epoch 4.780), train_loss = 1.29931781, grad/param norm = 1.7165e-01, time/batch = 0.6541s	
3218/33650 (epoch 4.782), train_loss = 1.37638139, grad/param norm = 1.7877e-01, time/batch = 0.6787s	
3219/33650 (epoch 4.783), train_loss = 1.25537983, grad/param norm = 1.6979e-01, time/batch = 0.6516s	
3220/33650 (epoch 4.785), train_loss = 1.72593571, grad/param norm = 1.8648e-01, time/batch = 0.6404s	
3221/33650 (epoch 4.786), train_loss = 1.40829878, grad/param norm = 1.7196e-01, time/batch = 0.6485s	
3222/33650 (epoch 4.788), train_loss = 1.43643157, grad/param norm = 1.8395e-01, time/batch = 0.6526s	
3223/33650 (epoch 4.789), train_loss = 1.48083857, grad/param norm = 1.7162e-01, time/batch = 0.6608s	
3224/33650 (epoch 4.790), train_loss = 1.55613064, grad/param norm = 2.0363e-01, time/batch = 0.6579s	
3225/33650 (epoch 4.792), train_loss = 1.60843914, grad/param norm = 2.2339e-01, time/batch = 0.6793s	
3226/33650 (epoch 4.793), train_loss = 1.52626785, grad/param norm = 1.9338e-01, time/batch = 0.6599s	
3227/33650 (epoch 4.795), train_loss = 1.57179434, grad/param norm = 1.7526e-01, time/batch = 0.6432s	
3228/33650 (epoch 4.796), train_loss = 1.36807742, grad/param norm = 1.7336e-01, time/batch = 0.6430s	
3229/33650 (epoch 4.798), train_loss = 1.39283752, grad/param norm = 1.7041e-01, time/batch = 0.6362s	
3230/33650 (epoch 4.799), train_loss = 1.43058737, grad/param norm = 1.7427e-01, time/batch = 0.6452s	
3231/33650 (epoch 4.801), train_loss = 1.51998531, grad/param norm = 1.8712e-01, time/batch = 0.6425s	
3232/33650 (epoch 4.802), train_loss = 1.59041827, grad/param norm = 1.6872e-01, time/batch = 0.6398s	
3233/33650 (epoch 4.804), train_loss = 1.42758712, grad/param norm = 1.7379e-01, time/batch = 0.6393s	
3234/33650 (epoch 4.805), train_loss = 1.41503922, grad/param norm = 1.8716e-01, time/batch = 0.6374s	
3235/33650 (epoch 4.807), train_loss = 1.76851125, grad/param norm = 2.1093e-01, time/batch = 0.6451s	
3236/33650 (epoch 4.808), train_loss = 1.67000515, grad/param norm = 1.8979e-01, time/batch = 0.6443s	
3237/33650 (epoch 4.810), train_loss = 1.49361949, grad/param norm = 1.7652e-01, time/batch = 0.6604s	
3238/33650 (epoch 4.811), train_loss = 1.53083252, grad/param norm = 1.9026e-01, time/batch = 0.6791s	
3239/33650 (epoch 4.813), train_loss = 1.47736877, grad/param norm = 2.1512e-01, time/batch = 0.6406s	
3240/33650 (epoch 4.814), train_loss = 1.58612131, grad/param norm = 2.1451e-01, time/batch = 0.6393s	
3241/33650 (epoch 4.816), train_loss = 1.50757084, grad/param norm = 1.9506e-01, time/batch = 0.6415s	
3242/33650 (epoch 4.817), train_loss = 1.64656258, grad/param norm = 2.1878e-01, time/batch = 0.6422s	
3243/33650 (epoch 4.819), train_loss = 1.62410743, grad/param norm = 1.9015e-01, time/batch = 0.6402s	
3244/33650 (epoch 4.820), train_loss = 1.60859161, grad/param norm = 1.8348e-01, time/batch = 0.6377s	
3245/33650 (epoch 4.822), train_loss = 1.67645968, grad/param norm = 2.0040e-01, time/batch = 0.6380s	
3246/33650 (epoch 4.823), train_loss = 1.35996647, grad/param norm = 1.9282e-01, time/batch = 0.6437s	
3247/33650 (epoch 4.825), train_loss = 1.43556249, grad/param norm = 1.7658e-01, time/batch = 0.6380s	
3248/33650 (epoch 4.826), train_loss = 1.52899210, grad/param norm = 1.8049e-01, time/batch = 0.6398s	
3249/33650 (epoch 4.828), train_loss = 1.79598444, grad/param norm = 2.0106e-01, time/batch = 0.6391s	
3250/33650 (epoch 4.829), train_loss = 1.33511764, grad/param norm = 1.8419e-01, time/batch = 0.6399s	
3251/33650 (epoch 4.831), train_loss = 1.59268409, grad/param norm = 1.7877e-01, time/batch = 0.6517s	
3252/33650 (epoch 4.832), train_loss = 1.54198027, grad/param norm = 1.9479e-01, time/batch = 0.6476s	
3253/33650 (epoch 4.834), train_loss = 1.57790494, grad/param norm = 1.8522e-01, time/batch = 0.6399s	
3254/33650 (epoch 4.835), train_loss = 1.77314388, grad/param norm = 2.0022e-01, time/batch = 0.6473s	
3255/33650 (epoch 4.837), train_loss = 1.51941438, grad/param norm = 2.0399e-01, time/batch = 0.6383s	
3256/33650 (epoch 4.838), train_loss = 1.46943092, grad/param norm = 1.8468e-01, time/batch = 0.6621s	
3257/33650 (epoch 4.840), train_loss = 1.53487306, grad/param norm = 1.7373e-01, time/batch = 0.6648s	
3258/33650 (epoch 4.841), train_loss = 1.35466265, grad/param norm = 1.5874e-01, time/batch = 0.6795s	
3259/33650 (epoch 4.842), train_loss = 1.37919727, grad/param norm = 1.8326e-01, time/batch = 0.6408s	
3260/33650 (epoch 4.844), train_loss = 1.70734862, grad/param norm = 2.0176e-01, time/batch = 0.6363s	
3261/33650 (epoch 4.845), train_loss = 1.30582280, grad/param norm = 1.7710e-01, time/batch = 0.6405s	
3262/33650 (epoch 4.847), train_loss = 1.27541370, grad/param norm = 1.6638e-01, time/batch = 0.6392s	
3263/33650 (epoch 4.848), train_loss = 1.35687622, grad/param norm = 2.0240e-01, time/batch = 0.6391s	
3264/33650 (epoch 4.850), train_loss = 1.54469888, grad/param norm = 2.0843e-01, time/batch = 0.6421s	
3265/33650 (epoch 4.851), train_loss = 1.21916559, grad/param norm = 1.5981e-01, time/batch = 0.6430s	
3266/33650 (epoch 4.853), train_loss = 1.48181962, grad/param norm = 1.7860e-01, time/batch = 0.6435s	
3267/33650 (epoch 4.854), train_loss = 1.64926872, grad/param norm = 2.1835e-01, time/batch = 0.6388s	
3268/33650 (epoch 4.856), train_loss = 1.14111159, grad/param norm = 1.7537e-01, time/batch = 0.6566s	
3269/33650 (epoch 4.857), train_loss = 1.39467180, grad/param norm = 1.6348e-01, time/batch = 0.6477s	
3270/33650 (epoch 4.859), train_loss = 1.31935449, grad/param norm = 1.6338e-01, time/batch = 0.6384s	
3271/33650 (epoch 4.860), train_loss = 1.21919457, grad/param norm = 1.7657e-01, time/batch = 0.6414s	
3272/33650 (epoch 4.862), train_loss = 1.27357364, grad/param norm = 1.6987e-01, time/batch = 0.6415s	
3273/33650 (epoch 4.863), train_loss = 1.54978392, grad/param norm = 1.9159e-01, time/batch = 0.6427s	
3274/33650 (epoch 4.865), train_loss = 1.32929924, grad/param norm = 1.7385e-01, time/batch = 0.6378s	
3275/33650 (epoch 4.866), train_loss = 1.36730050, grad/param norm = 1.8265e-01, time/batch = 0.6376s	
3276/33650 (epoch 4.868), train_loss = 1.31864284, grad/param norm = 1.8323e-01, time/batch = 0.6376s	
3277/33650 (epoch 4.869), train_loss = 1.56942934, grad/param norm = 1.9296e-01, time/batch = 0.6526s	
3278/33650 (epoch 4.871), train_loss = 1.27529491, grad/param norm = 1.8041e-01, time/batch = 0.6790s	
3279/33650 (epoch 4.872), train_loss = 1.43758123, grad/param norm = 2.0769e-01, time/batch = 0.6485s	
3280/33650 (epoch 4.874), train_loss = 1.53779415, grad/param norm = 1.7771e-01, time/batch = 0.6500s	
3281/33650 (epoch 4.875), train_loss = 1.33314493, grad/param norm = 1.7358e-01, time/batch = 0.6667s	
3282/33650 (epoch 4.877), train_loss = 1.56881387, grad/param norm = 1.9248e-01, time/batch = 0.6680s	
3283/33650 (epoch 4.878), train_loss = 1.09007404, grad/param norm = 1.7360e-01, time/batch = 0.6519s	
3284/33650 (epoch 4.880), train_loss = 1.41197911, grad/param norm = 1.9143e-01, time/batch = 0.6429s	
3285/33650 (epoch 4.881), train_loss = 1.34250634, grad/param norm = 1.6874e-01, time/batch = 0.6385s	
3286/33650 (epoch 4.883), train_loss = 1.43900314, grad/param norm = 1.8991e-01, time/batch = 0.6392s	
3287/33650 (epoch 4.884), train_loss = 1.56881634, grad/param norm = 1.9021e-01, time/batch = 0.6430s	
3288/33650 (epoch 4.886), train_loss = 1.55092113, grad/param norm = 1.8859e-01, time/batch = 0.6377s	
3289/33650 (epoch 4.887), train_loss = 1.34030169, grad/param norm = 1.6517e-01, time/batch = 0.6384s	
3290/33650 (epoch 4.889), train_loss = 1.55999206, grad/param norm = 1.8716e-01, time/batch = 0.6375s	
3291/33650 (epoch 4.890), train_loss = 1.51829234, grad/param norm = 1.7114e-01, time/batch = 0.6406s	
3292/33650 (epoch 4.892), train_loss = 1.52806196, grad/param norm = 2.0362e-01, time/batch = 0.6387s	
3293/33650 (epoch 4.893), train_loss = 1.53197430, grad/param norm = 1.8298e-01, time/batch = 0.6791s	
3294/33650 (epoch 4.895), train_loss = 1.55039390, grad/param norm = 1.9990e-01, time/batch = 0.6577s	
3295/33650 (epoch 4.896), train_loss = 1.33048036, grad/param norm = 1.8456e-01, time/batch = 0.6373s	
3296/33650 (epoch 4.897), train_loss = 1.36958997, grad/param norm = 1.7052e-01, time/batch = 0.6381s	
3297/33650 (epoch 4.899), train_loss = 1.36237863, grad/param norm = 1.8498e-01, time/batch = 0.6544s	
3298/33650 (epoch 4.900), train_loss = 1.17266256, grad/param norm = 1.5589e-01, time/batch = 0.6787s	
3299/33650 (epoch 4.902), train_loss = 1.43961959, grad/param norm = 1.7373e-01, time/batch = 0.6414s	
3300/33650 (epoch 4.903), train_loss = 1.42245694, grad/param norm = 2.0945e-01, time/batch = 0.6426s	
3301/33650 (epoch 4.905), train_loss = 1.71424838, grad/param norm = 2.0868e-01, time/batch = 0.6419s	
3302/33650 (epoch 4.906), train_loss = 1.40153159, grad/param norm = 1.7887e-01, time/batch = 0.6403s	
3303/33650 (epoch 4.908), train_loss = 1.37735062, grad/param norm = 1.6998e-01, time/batch = 0.6399s	
3304/33650 (epoch 4.909), train_loss = 1.37920034, grad/param norm = 1.6037e-01, time/batch = 0.6404s	
3305/33650 (epoch 4.911), train_loss = 1.30304082, grad/param norm = 1.7860e-01, time/batch = 0.6411s	
3306/33650 (epoch 4.912), train_loss = 1.30217112, grad/param norm = 1.7003e-01, time/batch = 0.6382s	
3307/33650 (epoch 4.914), train_loss = 1.42135876, grad/param norm = 1.6736e-01, time/batch = 0.6394s	
3308/33650 (epoch 4.915), train_loss = 1.55970141, grad/param norm = 2.0744e-01, time/batch = 0.6413s	
3309/33650 (epoch 4.917), train_loss = 1.43698712, grad/param norm = 1.9195e-01, time/batch = 0.6405s	
3310/33650 (epoch 4.918), train_loss = 1.18443969, grad/param norm = 1.5268e-01, time/batch = 0.6391s	
3311/33650 (epoch 4.920), train_loss = 1.34523194, grad/param norm = 1.6257e-01, time/batch = 0.6418s	
3312/33650 (epoch 4.921), train_loss = 1.29993161, grad/param norm = 1.7616e-01, time/batch = 0.6405s	
3313/33650 (epoch 4.923), train_loss = 1.30663617, grad/param norm = 1.7743e-01, time/batch = 0.6457s	
3314/33650 (epoch 4.924), train_loss = 1.51827305, grad/param norm = 1.8195e-01, time/batch = 0.6441s	
3315/33650 (epoch 4.926), train_loss = 1.51588151, grad/param norm = 2.0321e-01, time/batch = 0.6531s	
3316/33650 (epoch 4.927), train_loss = 1.41017298, grad/param norm = 1.8917e-01, time/batch = 0.6498s	
3317/33650 (epoch 4.929), train_loss = 1.40006848, grad/param norm = 1.7849e-01, time/batch = 0.6700s	
3318/33650 (epoch 4.930), train_loss = 1.38969191, grad/param norm = 1.7638e-01, time/batch = 0.6756s	
3319/33650 (epoch 4.932), train_loss = 1.41445164, grad/param norm = 1.7579e-01, time/batch = 0.6412s	
3320/33650 (epoch 4.933), train_loss = 1.28380773, grad/param norm = 1.6774e-01, time/batch = 0.6441s	
3321/33650 (epoch 4.935), train_loss = 1.32927564, grad/param norm = 1.7302e-01, time/batch = 0.6443s	
3322/33650 (epoch 4.936), train_loss = 1.31782878, grad/param norm = 1.7159e-01, time/batch = 0.6393s	
3323/33650 (epoch 4.938), train_loss = 1.23173918, grad/param norm = 1.6285e-01, time/batch = 0.6409s	
3324/33650 (epoch 4.939), train_loss = 1.45816488, grad/param norm = 1.6844e-01, time/batch = 0.6415s	
3325/33650 (epoch 4.941), train_loss = 1.46304174, grad/param norm = 1.8411e-01, time/batch = 0.6432s	
3326/33650 (epoch 4.942), train_loss = 1.51845297, grad/param norm = 1.8370e-01, time/batch = 0.6400s	
3327/33650 (epoch 4.944), train_loss = 1.44868065, grad/param norm = 1.6907e-01, time/batch = 0.6439s	
3328/33650 (epoch 4.945), train_loss = 1.51183409, grad/param norm = 1.7931e-01, time/batch = 0.6410s	
3329/33650 (epoch 4.947), train_loss = 1.71921714, grad/param norm = 1.9873e-01, time/batch = 0.6401s	
3330/33650 (epoch 4.948), train_loss = 1.57759222, grad/param norm = 1.9449e-01, time/batch = 0.6466s	
3331/33650 (epoch 4.949), train_loss = 1.33745868, grad/param norm = 1.9912e-01, time/batch = 0.6586s	
3332/33650 (epoch 4.951), train_loss = 1.53502497, grad/param norm = 1.8629e-01, time/batch = 0.6560s	
3333/33650 (epoch 4.952), train_loss = 1.57895340, grad/param norm = 2.0043e-01, time/batch = 0.6813s	
3334/33650 (epoch 4.954), train_loss = 1.54812941, grad/param norm = 1.9184e-01, time/batch = 0.6586s	
3335/33650 (epoch 4.955), train_loss = 1.56561721, grad/param norm = 1.9355e-01, time/batch = 0.6438s	
3336/33650 (epoch 4.957), train_loss = 1.51794710, grad/param norm = 1.8938e-01, time/batch = 0.6440s	
3337/33650 (epoch 4.958), train_loss = 1.08906342, grad/param norm = 1.5580e-01, time/batch = 0.6388s	
3338/33650 (epoch 4.960), train_loss = 1.25293621, grad/param norm = 1.5060e-01, time/batch = 0.6413s	
3339/33650 (epoch 4.961), train_loss = 1.36399984, grad/param norm = 1.6894e-01, time/batch = 0.6407s	
3340/33650 (epoch 4.963), train_loss = 1.38494959, grad/param norm = 1.7778e-01, time/batch = 0.6398s	
3341/33650 (epoch 4.964), train_loss = 1.43640105, grad/param norm = 1.8238e-01, time/batch = 0.6437s	
3342/33650 (epoch 4.966), train_loss = 1.43512870, grad/param norm = 1.8548e-01, time/batch = 0.6428s	
3343/33650 (epoch 4.967), train_loss = 1.49290808, grad/param norm = 1.9665e-01, time/batch = 0.6479s	
3344/33650 (epoch 4.969), train_loss = 1.34682618, grad/param norm = 1.6624e-01, time/batch = 0.6460s	
3345/33650 (epoch 4.970), train_loss = 1.48497102, grad/param norm = 1.7831e-01, time/batch = 0.6443s	
3346/33650 (epoch 4.972), train_loss = 1.74135911, grad/param norm = 1.9036e-01, time/batch = 0.6415s	
3347/33650 (epoch 4.973), train_loss = 1.28495127, grad/param norm = 1.6519e-01, time/batch = 0.6400s	
3348/33650 (epoch 4.975), train_loss = 1.34878688, grad/param norm = 1.8108e-01, time/batch = 0.6403s	
3349/33650 (epoch 4.976), train_loss = 1.29299074, grad/param norm = 1.5541e-01, time/batch = 0.6430s	
3350/33650 (epoch 4.978), train_loss = 1.32617665, grad/param norm = 1.7839e-01, time/batch = 0.6429s	
3351/33650 (epoch 4.979), train_loss = 1.48595566, grad/param norm = 1.9498e-01, time/batch = 0.6446s	
3352/33650 (epoch 4.981), train_loss = 1.35503840, grad/param norm = 1.5633e-01, time/batch = 0.6393s	
3353/33650 (epoch 4.982), train_loss = 1.49143261, grad/param norm = 2.0948e-01, time/batch = 0.6772s	
3354/33650 (epoch 4.984), train_loss = 1.26080696, grad/param norm = 1.6624e-01, time/batch = 0.6605s	
3355/33650 (epoch 4.985), train_loss = 1.29373999, grad/param norm = 1.6375e-01, time/batch = 0.6405s	
3356/33650 (epoch 4.987), train_loss = 1.37388230, grad/param norm = 1.7431e-01, time/batch = 0.6418s	
3357/33650 (epoch 4.988), train_loss = 1.51940260, grad/param norm = 1.8084e-01, time/batch = 0.6411s	
3358/33650 (epoch 4.990), train_loss = 1.69458102, grad/param norm = 2.1433e-01, time/batch = 0.6426s	
3359/33650 (epoch 4.991), train_loss = 1.55419720, grad/param norm = 1.8726e-01, time/batch = 0.6416s	
3360/33650 (epoch 4.993), train_loss = 1.51890474, grad/param norm = 1.8813e-01, time/batch = 0.6401s	
3361/33650 (epoch 4.994), train_loss = 1.39772606, grad/param norm = 1.8551e-01, time/batch = 0.6465s	
3362/33650 (epoch 4.996), train_loss = 1.35218808, grad/param norm = 1.7187e-01, time/batch = 0.6447s	
3363/33650 (epoch 4.997), train_loss = 1.48649093, grad/param norm = 2.0201e-01, time/batch = 0.6413s	
3364/33650 (epoch 4.999), train_loss = 1.25091611, grad/param norm = 1.7367e-01, time/batch = 0.6389s	
3365/33650 (epoch 5.000), train_loss = 1.56301119, grad/param norm = 1.8803e-01, time/batch = 0.6407s	
3366/33650 (epoch 5.001), train_loss = 1.58332144, grad/param norm = 2.0011e-01, time/batch = 0.6427s	
3367/33650 (epoch 5.003), train_loss = 1.71061588, grad/param norm = 2.0708e-01, time/batch = 0.6461s	
3368/33650 (epoch 5.004), train_loss = 1.52443745, grad/param norm = 1.9762e-01, time/batch = 0.6465s	
3369/33650 (epoch 5.006), train_loss = 1.34538016, grad/param norm = 1.7399e-01, time/batch = 0.6561s	
3370/33650 (epoch 5.007), train_loss = 1.42781974, grad/param norm = 1.8772e-01, time/batch = 0.6374s	
3371/33650 (epoch 5.009), train_loss = 1.40188813, grad/param norm = 1.7525e-01, time/batch = 0.6425s	
3372/33650 (epoch 5.010), train_loss = 1.52537241, grad/param norm = 1.8964e-01, time/batch = 0.6388s	
3373/33650 (epoch 5.012), train_loss = 1.39352804, grad/param norm = 1.8648e-01, time/batch = 0.6752s	
3374/33650 (epoch 5.013), train_loss = 1.49804680, grad/param norm = 1.8149e-01, time/batch = 0.6629s	
3375/33650 (epoch 5.015), train_loss = 1.30284462, grad/param norm = 1.8148e-01, time/batch = 0.6414s	
3376/33650 (epoch 5.016), train_loss = 1.38783406, grad/param norm = 1.8888e-01, time/batch = 0.6384s	
3377/33650 (epoch 5.018), train_loss = 1.43108646, grad/param norm = 1.9112e-01, time/batch = 0.6453s	
3378/33650 (epoch 5.019), train_loss = 1.31135396, grad/param norm = 1.8030e-01, time/batch = 0.6472s	
3379/33650 (epoch 5.021), train_loss = 1.54959572, grad/param norm = 1.9032e-01, time/batch = 0.6457s	
3380/33650 (epoch 5.022), train_loss = 1.40048771, grad/param norm = 1.9254e-01, time/batch = 0.6397s	
3381/33650 (epoch 5.024), train_loss = 1.31871424, grad/param norm = 1.7562e-01, time/batch = 0.6448s	
3382/33650 (epoch 5.025), train_loss = 1.36603946, grad/param norm = 1.7010e-01, time/batch = 0.6402s	
3383/33650 (epoch 5.027), train_loss = 1.56595273, grad/param norm = 1.8835e-01, time/batch = 0.6413s	
3384/33650 (epoch 5.028), train_loss = 1.53407809, grad/param norm = 1.9608e-01, time/batch = 0.6409s	
3385/33650 (epoch 5.030), train_loss = 1.40002520, grad/param norm = 1.6907e-01, time/batch = 0.6435s	
3386/33650 (epoch 5.031), train_loss = 1.15956344, grad/param norm = 1.6451e-01, time/batch = 0.6444s	
3387/33650 (epoch 5.033), train_loss = 1.33265197, grad/param norm = 1.5454e-01, time/batch = 0.6521s	
3388/33650 (epoch 5.034), train_loss = 1.41263437, grad/param norm = 1.8023e-01, time/batch = 0.6666s	
3389/33650 (epoch 5.036), train_loss = 1.59726703, grad/param norm = 1.9820e-01, time/batch = 0.6799s	
3390/33650 (epoch 5.037), train_loss = 1.32210600, grad/param norm = 2.0800e-01, time/batch = 0.6499s	
3391/33650 (epoch 5.039), train_loss = 1.56589598, grad/param norm = 1.8247e-01, time/batch = 0.6445s	
3392/33650 (epoch 5.040), train_loss = 1.60707207, grad/param norm = 2.0023e-01, time/batch = 0.6457s	
3393/33650 (epoch 5.042), train_loss = 1.64515606, grad/param norm = 1.9488e-01, time/batch = 0.6438s	
3394/33650 (epoch 5.043), train_loss = 1.29122013, grad/param norm = 1.8266e-01, time/batch = 0.6409s	
3395/33650 (epoch 5.045), train_loss = 1.34091887, grad/param norm = 1.7110e-01, time/batch = 0.6408s	
3396/33650 (epoch 5.046), train_loss = 1.53937517, grad/param norm = 1.6715e-01, time/batch = 0.6418s	
3397/33650 (epoch 5.048), train_loss = 1.50563398, grad/param norm = 1.8215e-01, time/batch = 0.6377s	
3398/33650 (epoch 5.049), train_loss = 1.51842727, grad/param norm = 2.0031e-01, time/batch = 0.6382s	
3399/33650 (epoch 5.051), train_loss = 1.51614797, grad/param norm = 1.7899e-01, time/batch = 0.6377s	
3400/33650 (epoch 5.052), train_loss = 1.64084897, grad/param norm = 1.9415e-01, time/batch = 0.6394s	
3401/33650 (epoch 5.053), train_loss = 1.43333424, grad/param norm = 1.7193e-01, time/batch = 0.6406s	
3402/33650 (epoch 5.055), train_loss = 1.25071449, grad/param norm = 1.7900e-01, time/batch = 0.6438s	
3403/33650 (epoch 5.056), train_loss = 1.23549554, grad/param norm = 1.5803e-01, time/batch = 0.6448s	
3404/33650 (epoch 5.058), train_loss = 1.56983744, grad/param norm = 1.9687e-01, time/batch = 0.6441s	
3405/33650 (epoch 5.059), train_loss = 1.55533292, grad/param norm = 1.9516e-01, time/batch = 0.6387s	
3406/33650 (epoch 5.061), train_loss = 1.49253396, grad/param norm = 1.6704e-01, time/batch = 0.6430s	
3407/33650 (epoch 5.062), train_loss = 1.44828620, grad/param norm = 1.7535e-01, time/batch = 0.6524s	
3408/33650 (epoch 5.064), train_loss = 1.36947759, grad/param norm = 1.7451e-01, time/batch = 0.6722s	
3409/33650 (epoch 5.065), train_loss = 1.38688990, grad/param norm = 1.7748e-01, time/batch = 0.6801s	
3410/33650 (epoch 5.067), train_loss = 1.28953264, grad/param norm = 1.7080e-01, time/batch = 0.6634s	
3411/33650 (epoch 5.068), train_loss = 1.46531391, grad/param norm = 1.7911e-01, time/batch = 0.6491s	
3412/33650 (epoch 5.070), train_loss = 1.39232985, grad/param norm = 1.8205e-01, time/batch = 0.6446s	
3413/33650 (epoch 5.071), train_loss = 1.42174064, grad/param norm = 1.8250e-01, time/batch = 0.6417s	
3414/33650 (epoch 5.073), train_loss = 1.52595020, grad/param norm = 1.8356e-01, time/batch = 0.6416s	
3415/33650 (epoch 5.074), train_loss = 1.53744899, grad/param norm = 1.8513e-01, time/batch = 0.6453s	
3416/33650 (epoch 5.076), train_loss = 1.58187030, grad/param norm = 1.8914e-01, time/batch = 0.6421s	
3417/33650 (epoch 5.077), train_loss = 1.35646978, grad/param norm = 1.7328e-01, time/batch = 0.6461s	
3418/33650 (epoch 5.079), train_loss = 1.39704435, grad/param norm = 1.8985e-01, time/batch = 0.6430s	
3419/33650 (epoch 5.080), train_loss = 1.47483647, grad/param norm = 1.8903e-01, time/batch = 0.6441s	
3420/33650 (epoch 5.082), train_loss = 1.56654549, grad/param norm = 1.9597e-01, time/batch = 0.6380s	
3421/33650 (epoch 5.083), train_loss = 1.49744999, grad/param norm = 1.8176e-01, time/batch = 0.6408s	
3422/33650 (epoch 5.085), train_loss = 1.51423654, grad/param norm = 1.8000e-01, time/batch = 0.6402s	
3423/33650 (epoch 5.086), train_loss = 1.52811463, grad/param norm = 2.1516e-01, time/batch = 0.6409s	
3424/33650 (epoch 5.088), train_loss = 1.48638793, grad/param norm = 1.8361e-01, time/batch = 0.6390s	
3425/33650 (epoch 5.089), train_loss = 1.48287148, grad/param norm = 1.9294e-01, time/batch = 0.6401s	
3426/33650 (epoch 5.091), train_loss = 1.34125349, grad/param norm = 1.8643e-01, time/batch = 0.6401s	
3427/33650 (epoch 5.092), train_loss = 1.35458803, grad/param norm = 1.7702e-01, time/batch = 0.6429s	
3428/33650 (epoch 5.094), train_loss = 1.45792415, grad/param norm = 1.6432e-01, time/batch = 0.6590s	
3429/33650 (epoch 5.095), train_loss = 1.51688938, grad/param norm = 1.9191e-01, time/batch = 0.6788s	
3430/33650 (epoch 5.097), train_loss = 1.42050604, grad/param norm = 1.9028e-01, time/batch = 0.6399s	
3431/33650 (epoch 5.098), train_loss = 1.18765671, grad/param norm = 1.6018e-01, time/batch = 0.6412s	
3432/33650 (epoch 5.100), train_loss = 1.30888055, grad/param norm = 1.6342e-01, time/batch = 0.6391s	
3433/33650 (epoch 5.101), train_loss = 1.34037285, grad/param norm = 1.7215e-01, time/batch = 0.6406s	
3434/33650 (epoch 5.103), train_loss = 1.31741915, grad/param norm = 1.7275e-01, time/batch = 0.6408s	
3435/33650 (epoch 5.104), train_loss = 1.47107015, grad/param norm = 1.8119e-01, time/batch = 0.6397s	
3436/33650 (epoch 5.105), train_loss = 1.43055186, grad/param norm = 1.9476e-01, time/batch = 0.6394s	
3437/33650 (epoch 5.107), train_loss = 1.25549866, grad/param norm = 1.7692e-01, time/batch = 0.6390s	
3438/33650 (epoch 5.108), train_loss = 1.47475450, grad/param norm = 2.0191e-01, time/batch = 0.6390s	
3439/33650 (epoch 5.110), train_loss = 1.59798171, grad/param norm = 1.9352e-01, time/batch = 0.6395s	
3440/33650 (epoch 5.111), train_loss = 1.34729498, grad/param norm = 2.0033e-01, time/batch = 0.6410s	
3441/33650 (epoch 5.113), train_loss = 1.35801909, grad/param norm = 1.8602e-01, time/batch = 0.6422s	
3442/33650 (epoch 5.114), train_loss = 1.52831768, grad/param norm = 1.9095e-01, time/batch = 0.6433s	
3443/33650 (epoch 5.116), train_loss = 1.22544193, grad/param norm = 1.7004e-01, time/batch = 0.6433s	
3444/33650 (epoch 5.117), train_loss = 1.42731382, grad/param norm = 1.6391e-01, time/batch = 0.6525s	
3445/33650 (epoch 5.119), train_loss = 1.26965824, grad/param norm = 1.5997e-01, time/batch = 0.6404s	
3446/33650 (epoch 5.120), train_loss = 1.37516667, grad/param norm = 2.1238e-01, time/batch = 0.6400s	
3447/33650 (epoch 5.122), train_loss = 1.26084142, grad/param norm = 1.8372e-01, time/batch = 0.6395s	
3448/33650 (epoch 5.123), train_loss = 1.34979534, grad/param norm = 1.6580e-01, time/batch = 0.6543s	
3449/33650 (epoch 5.125), train_loss = 1.53996856, grad/param norm = 1.9285e-01, time/batch = 0.6790s	
3450/33650 (epoch 5.126), train_loss = 1.63792683, grad/param norm = 1.8424e-01, time/batch = 0.6450s	
3451/33650 (epoch 5.128), train_loss = 1.54571493, grad/param norm = 1.9428e-01, time/batch = 0.6460s	
3452/33650 (epoch 5.129), train_loss = 1.54864179, grad/param norm = 1.7687e-01, time/batch = 0.6407s	
3453/33650 (epoch 5.131), train_loss = 1.49570566, grad/param norm = 1.9042e-01, time/batch = 0.6422s	
3454/33650 (epoch 5.132), train_loss = 1.42379463, grad/param norm = 1.7097e-01, time/batch = 0.6409s	
3455/33650 (epoch 5.134), train_loss = 1.62644947, grad/param norm = 1.7938e-01, time/batch = 0.6400s	
3456/33650 (epoch 5.135), train_loss = 1.30520764, grad/param norm = 1.8043e-01, time/batch = 0.6432s	
3457/33650 (epoch 5.137), train_loss = 1.40060714, grad/param norm = 1.6912e-01, time/batch = 0.6410s	
3458/33650 (epoch 5.138), train_loss = 1.47131950, grad/param norm = 1.8353e-01, time/batch = 0.6516s	
3459/33650 (epoch 5.140), train_loss = 1.48240579, grad/param norm = 1.9731e-01, time/batch = 0.6352s	
3460/33650 (epoch 5.141), train_loss = 1.59871019, grad/param norm = 1.9668e-01, time/batch = 0.6271s	
3461/33650 (epoch 5.143), train_loss = 1.73459156, grad/param norm = 2.0436e-01, time/batch = 0.6309s	
3462/33650 (epoch 5.144), train_loss = 1.63993252, grad/param norm = 1.9113e-01, time/batch = 0.6276s	
3463/33650 (epoch 5.146), train_loss = 1.44581096, grad/param norm = 1.8570e-01, time/batch = 0.6283s	
3464/33650 (epoch 5.147), train_loss = 1.36622830, grad/param norm = 1.7899e-01, time/batch = 0.6347s	
3465/33650 (epoch 5.149), train_loss = 1.26811936, grad/param norm = 1.6887e-01, time/batch = 0.6438s	
3466/33650 (epoch 5.150), train_loss = 1.27917870, grad/param norm = 1.5931e-01, time/batch = 0.6266s	
3467/33650 (epoch 5.152), train_loss = 1.35753960, grad/param norm = 1.7503e-01, time/batch = 0.6366s	
3468/33650 (epoch 5.153), train_loss = 1.39804088, grad/param norm = 1.7390e-01, time/batch = 0.6301s	
3469/33650 (epoch 5.155), train_loss = 1.29381889, grad/param norm = 1.5635e-01, time/batch = 0.6300s	
3470/33650 (epoch 5.156), train_loss = 1.32545984, grad/param norm = 1.6243e-01, time/batch = 0.6473s	
3471/33650 (epoch 5.158), train_loss = 1.45172124, grad/param norm = 1.9312e-01, time/batch = 0.6330s	
3472/33650 (epoch 5.159), train_loss = 1.18348222, grad/param norm = 1.5625e-01, time/batch = 0.6261s	
3473/33650 (epoch 5.160), train_loss = 1.26726427, grad/param norm = 1.5129e-01, time/batch = 0.6469s	
3474/33650 (epoch 5.162), train_loss = 1.38763382, grad/param norm = 2.0104e-01, time/batch = 0.6674s	
3475/33650 (epoch 5.163), train_loss = 1.54764400, grad/param norm = 2.0131e-01, time/batch = 0.6315s	
3476/33650 (epoch 5.165), train_loss = 1.27934249, grad/param norm = 1.6104e-01, time/batch = 0.6269s	
3477/33650 (epoch 5.166), train_loss = 1.29324624, grad/param norm = 1.7636e-01, time/batch = 0.6291s	
3478/33650 (epoch 5.168), train_loss = 1.55708444, grad/param norm = 1.8435e-01, time/batch = 0.6287s	
3479/33650 (epoch 5.169), train_loss = 1.35712526, grad/param norm = 1.7292e-01, time/batch = 0.6297s	
3480/33650 (epoch 5.171), train_loss = 1.45389790, grad/param norm = 1.9139e-01, time/batch = 0.6279s	
3481/33650 (epoch 5.172), train_loss = 1.36051832, grad/param norm = 1.6945e-01, time/batch = 0.6296s	
3482/33650 (epoch 5.174), train_loss = 1.29623644, grad/param norm = 1.7325e-01, time/batch = 0.6274s	
3483/33650 (epoch 5.175), train_loss = 1.28194084, grad/param norm = 1.7415e-01, time/batch = 0.6295s	
3484/33650 (epoch 5.177), train_loss = 1.45028857, grad/param norm = 1.6137e-01, time/batch = 0.6275s	
3485/33650 (epoch 5.178), train_loss = 1.31922182, grad/param norm = 1.7620e-01, time/batch = 0.6295s	
3486/33650 (epoch 5.180), train_loss = 1.32087465, grad/param norm = 1.8132e-01, time/batch = 0.6290s	
3487/33650 (epoch 5.181), train_loss = 1.14507184, grad/param norm = 1.6366e-01, time/batch = 0.6294s	
3488/33650 (epoch 5.183), train_loss = 1.34666710, grad/param norm = 1.8922e-01, time/batch = 0.6261s	
3489/33650 (epoch 5.184), train_loss = 1.39200380, grad/param norm = 1.8912e-01, time/batch = 0.6270s	
3490/33650 (epoch 5.186), train_loss = 1.44310306, grad/param norm = 1.8163e-01, time/batch = 0.6264s	
3491/33650 (epoch 5.187), train_loss = 1.53793732, grad/param norm = 1.8807e-01, time/batch = 0.6288s	
3492/33650 (epoch 5.189), train_loss = 1.59383785, grad/param norm = 1.9723e-01, time/batch = 0.6252s	
3493/33650 (epoch 5.190), train_loss = 1.48286870, grad/param norm = 1.8662e-01, time/batch = 0.6302s	
3494/33650 (epoch 5.192), train_loss = 1.60660661, grad/param norm = 1.8662e-01, time/batch = 0.6654s	
3495/33650 (epoch 5.193), train_loss = 1.54318588, grad/param norm = 1.9046e-01, time/batch = 0.6457s	
3496/33650 (epoch 5.195), train_loss = 1.27090350, grad/param norm = 1.7193e-01, time/batch = 0.6245s	
3497/33650 (epoch 5.196), train_loss = 1.17258954, grad/param norm = 1.7419e-01, time/batch = 0.6255s	
3498/33650 (epoch 5.198), train_loss = 1.38558659, grad/param norm = 1.8784e-01, time/batch = 0.6255s	
3499/33650 (epoch 5.199), train_loss = 1.52474128, grad/param norm = 2.0004e-01, time/batch = 0.6264s	
3500/33650 (epoch 5.201), train_loss = 1.44901821, grad/param norm = 1.9367e-01, time/batch = 0.6385s	
3501/33650 (epoch 5.202), train_loss = 1.38444343, grad/param norm = 1.8444e-01, time/batch = 0.6442s	
3502/33650 (epoch 5.204), train_loss = 1.48085593, grad/param norm = 1.7684e-01, time/batch = 0.6359s	
3503/33650 (epoch 5.205), train_loss = 1.35398327, grad/param norm = 1.9250e-01, time/batch = 0.6443s	
3504/33650 (epoch 5.207), train_loss = 1.43214417, grad/param norm = 1.7379e-01, time/batch = 0.6314s	
3505/33650 (epoch 5.208), train_loss = 1.36981864, grad/param norm = 1.7853e-01, time/batch = 0.6317s	
3506/33650 (epoch 5.210), train_loss = 1.10373301, grad/param norm = 1.6370e-01, time/batch = 0.6292s	
3507/33650 (epoch 5.211), train_loss = 1.34845159, grad/param norm = 1.8454e-01, time/batch = 0.6289s	
3508/33650 (epoch 5.212), train_loss = 1.48399365, grad/param norm = 1.9025e-01, time/batch = 0.6295s	
3509/33650 (epoch 5.214), train_loss = 1.55693178, grad/param norm = 1.8845e-01, time/batch = 0.6309s	
3510/33650 (epoch 5.215), train_loss = 1.18188776, grad/param norm = 1.5948e-01, time/batch = 0.6279s	
3511/33650 (epoch 5.217), train_loss = 1.41447944, grad/param norm = 1.8081e-01, time/batch = 0.6328s	
3512/33650 (epoch 5.218), train_loss = 1.50296165, grad/param norm = 1.7669e-01, time/batch = 0.6578s	
3513/33650 (epoch 5.220), train_loss = 1.32679715, grad/param norm = 1.8939e-01, time/batch = 0.6281s	
3514/33650 (epoch 5.221), train_loss = 1.56634347, grad/param norm = 1.8222e-01, time/batch = 0.6496s	
3515/33650 (epoch 5.223), train_loss = 1.12343675, grad/param norm = 1.6132e-01, time/batch = 0.6723s	
3516/33650 (epoch 5.224), train_loss = 1.38612717, grad/param norm = 1.8608e-01, time/batch = 0.6417s	
3517/33650 (epoch 5.226), train_loss = 1.80470674, grad/param norm = 2.2217e-01, time/batch = 0.6342s	
3518/33650 (epoch 5.227), train_loss = 1.55608482, grad/param norm = 1.8202e-01, time/batch = 0.6461s	
3519/33650 (epoch 5.229), train_loss = 1.50078926, grad/param norm = 1.8903e-01, time/batch = 0.6269s	
3520/33650 (epoch 5.230), train_loss = 1.65962471, grad/param norm = 2.1527e-01, time/batch = 0.6260s	
3521/33650 (epoch 5.232), train_loss = 1.48284947, grad/param norm = 1.9353e-01, time/batch = 0.6290s	
3522/33650 (epoch 5.233), train_loss = 1.47781379, grad/param norm = 2.0433e-01, time/batch = 0.6277s	
3523/33650 (epoch 5.235), train_loss = 1.39063883, grad/param norm = 1.7952e-01, time/batch = 0.6276s	
3524/33650 (epoch 5.236), train_loss = 1.26448853, grad/param norm = 1.7539e-01, time/batch = 0.6343s	
3525/33650 (epoch 5.238), train_loss = 1.39081645, grad/param norm = 1.6288e-01, time/batch = 0.6292s	
3526/33650 (epoch 5.239), train_loss = 1.28384040, grad/param norm = 1.7100e-01, time/batch = 0.6253s	
3527/33650 (epoch 5.241), train_loss = 1.35423089, grad/param norm = 1.7053e-01, time/batch = 0.6263s	
3528/33650 (epoch 5.242), train_loss = 1.22515225, grad/param norm = 1.6566e-01, time/batch = 0.6290s	
3529/33650 (epoch 5.244), train_loss = 1.41415795, grad/param norm = 1.7119e-01, time/batch = 0.6299s	
3530/33650 (epoch 5.245), train_loss = 1.23825253, grad/param norm = 1.6906e-01, time/batch = 0.6298s	
3531/33650 (epoch 5.247), train_loss = 1.36662082, grad/param norm = 1.7083e-01, time/batch = 0.6305s	
3532/33650 (epoch 5.248), train_loss = 1.36894255, grad/param norm = 1.8625e-01, time/batch = 0.6299s	
3533/33650 (epoch 5.250), train_loss = 1.43588486, grad/param norm = 1.6971e-01, time/batch = 0.6289s	
3534/33650 (epoch 5.251), train_loss = 1.57220118, grad/param norm = 1.8035e-01, time/batch = 0.6342s	
3535/33650 (epoch 5.253), train_loss = 1.23807835, grad/param norm = 1.6868e-01, time/batch = 0.6658s	
3536/33650 (epoch 5.254), train_loss = 1.28509645, grad/param norm = 1.7426e-01, time/batch = 0.6377s	
3537/33650 (epoch 5.256), train_loss = 1.46589778, grad/param norm = 1.7971e-01, time/batch = 0.6257s	
3538/33650 (epoch 5.257), train_loss = 1.64713903, grad/param norm = 2.0190e-01, time/batch = 0.6266s	
3539/33650 (epoch 5.259), train_loss = 1.16897974, grad/param norm = 1.6859e-01, time/batch = 0.6324s	
3540/33650 (epoch 5.260), train_loss = 1.58133647, grad/param norm = 2.0049e-01, time/batch = 0.6376s	
3541/33650 (epoch 5.262), train_loss = 1.47951409, grad/param norm = 1.8946e-01, time/batch = 0.6586s	
3542/33650 (epoch 5.263), train_loss = 1.44440828, grad/param norm = 2.1492e-01, time/batch = 0.6608s	
3543/33650 (epoch 5.264), train_loss = 1.42058784, grad/param norm = 2.0158e-01, time/batch = 0.6601s	
3544/33650 (epoch 5.266), train_loss = 1.35630392, grad/param norm = 1.7903e-01, time/batch = 0.6506s	
3545/33650 (epoch 5.267), train_loss = 1.35217033, grad/param norm = 2.0349e-01, time/batch = 0.6467s	
3546/33650 (epoch 5.269), train_loss = 1.50467215, grad/param norm = 1.8272e-01, time/batch = 0.6349s	
3547/33650 (epoch 5.270), train_loss = 1.32926250, grad/param norm = 1.7403e-01, time/batch = 0.6297s	
3548/33650 (epoch 5.272), train_loss = 1.39519227, grad/param norm = 1.6460e-01, time/batch = 0.6275s	
3549/33650 (epoch 5.273), train_loss = 1.62737167, grad/param norm = 2.0738e-01, time/batch = 0.6265s	
3550/33650 (epoch 5.275), train_loss = 1.52996478, grad/param norm = 2.0025e-01, time/batch = 0.6254s	
3551/33650 (epoch 5.276), train_loss = 1.58050668, grad/param norm = 2.0460e-01, time/batch = 0.6290s	
3552/33650 (epoch 5.278), train_loss = 1.70429217, grad/param norm = 2.1306e-01, time/batch = 0.6269s	
3553/33650 (epoch 5.279), train_loss = 1.32790295, grad/param norm = 1.8936e-01, time/batch = 0.6302s	
3554/33650 (epoch 5.281), train_loss = 1.47918748, grad/param norm = 2.0858e-01, time/batch = 0.6284s	
3555/33650 (epoch 5.282), train_loss = 1.50728305, grad/param norm = 1.7178e-01, time/batch = 0.6638s	
3556/33650 (epoch 5.284), train_loss = 1.55717148, grad/param norm = 1.8575e-01, time/batch = 0.6501s	
3557/33650 (epoch 5.285), train_loss = 1.53834487, grad/param norm = 1.8687e-01, time/batch = 0.6277s	
3558/33650 (epoch 5.287), train_loss = 1.39889551, grad/param norm = 1.8866e-01, time/batch = 0.6271s	
3559/33650 (epoch 5.288), train_loss = 1.46048567, grad/param norm = 2.0416e-01, time/batch = 0.6259s	
3560/33650 (epoch 5.290), train_loss = 1.40816454, grad/param norm = 1.7145e-01, time/batch = 0.6254s	
3561/33650 (epoch 5.291), train_loss = 1.25151019, grad/param norm = 1.5096e-01, time/batch = 0.6284s	
3562/33650 (epoch 5.293), train_loss = 1.43490543, grad/param norm = 1.8691e-01, time/batch = 0.6421s	
3563/33650 (epoch 5.294), train_loss = 1.26206424, grad/param norm = 1.7057e-01, time/batch = 0.6322s	
3564/33650 (epoch 5.296), train_loss = 1.21080602, grad/param norm = 1.5926e-01, time/batch = 0.6262s	
3565/33650 (epoch 5.297), train_loss = 1.45056997, grad/param norm = 1.7303e-01, time/batch = 0.6264s	
3566/33650 (epoch 5.299), train_loss = 1.27945507, grad/param norm = 1.6448e-01, time/batch = 0.6322s	
3567/33650 (epoch 5.300), train_loss = 1.37263780, grad/param norm = 1.7069e-01, time/batch = 0.6329s	
3568/33650 (epoch 5.302), train_loss = 1.35971118, grad/param norm = 1.6089e-01, time/batch = 0.6327s	
3569/33650 (epoch 5.303), train_loss = 1.41196410, grad/param norm = 1.7118e-01, time/batch = 0.6281s	
3570/33650 (epoch 5.305), train_loss = 1.44353537, grad/param norm = 1.7306e-01, time/batch = 0.6271s	
3571/33650 (epoch 5.306), train_loss = 1.31923571, grad/param norm = 1.6512e-01, time/batch = 0.6322s	
3572/33650 (epoch 5.308), train_loss = 1.35859833, grad/param norm = 1.7934e-01, time/batch = 0.6310s	
3573/33650 (epoch 5.309), train_loss = 1.56038302, grad/param norm = 1.7849e-01, time/batch = 0.6437s	
3574/33650 (epoch 5.311), train_loss = 1.47231615, grad/param norm = 1.7468e-01, time/batch = 0.6270s	
3575/33650 (epoch 5.312), train_loss = 1.36177998, grad/param norm = 1.6139e-01, time/batch = 0.6473s	
3576/33650 (epoch 5.314), train_loss = 1.15960844, grad/param norm = 1.4755e-01, time/batch = 0.6660s	
3577/33650 (epoch 5.315), train_loss = 1.42394900, grad/param norm = 1.7909e-01, time/batch = 0.6262s	
3578/33650 (epoch 5.316), train_loss = 1.40528655, grad/param norm = 1.9043e-01, time/batch = 0.6274s	
3579/33650 (epoch 5.318), train_loss = 1.26567949, grad/param norm = 1.4934e-01, time/batch = 0.6261s	
3580/33650 (epoch 5.319), train_loss = 1.32046552, grad/param norm = 1.6361e-01, time/batch = 0.6259s	
3581/33650 (epoch 5.321), train_loss = 1.37673148, grad/param norm = 1.7228e-01, time/batch = 0.6276s	
3582/33650 (epoch 5.322), train_loss = 1.44474276, grad/param norm = 1.9949e-01, time/batch = 0.6250s	
3583/33650 (epoch 5.324), train_loss = 1.51357900, grad/param norm = 1.9798e-01, time/batch = 0.6254s	
3584/33650 (epoch 5.325), train_loss = 1.46193209, grad/param norm = 1.7859e-01, time/batch = 0.6301s	
3585/33650 (epoch 5.327), train_loss = 1.24438355, grad/param norm = 1.7374e-01, time/batch = 0.6324s	
3586/33650 (epoch 5.328), train_loss = 1.47844292, grad/param norm = 1.9111e-01, time/batch = 0.6410s	
3587/33650 (epoch 5.330), train_loss = 1.29800293, grad/param norm = 1.6297e-01, time/batch = 0.6618s	
3588/33650 (epoch 5.331), train_loss = 1.19884151, grad/param norm = 1.5494e-01, time/batch = 0.6370s	
3589/33650 (epoch 5.333), train_loss = 1.39270197, grad/param norm = 1.7573e-01, time/batch = 0.6362s	
3590/33650 (epoch 5.334), train_loss = 1.42201622, grad/param norm = 1.8184e-01, time/batch = 0.6397s	
3591/33650 (epoch 5.336), train_loss = 1.45798426, grad/param norm = 1.6967e-01, time/batch = 0.6498s	
3592/33650 (epoch 5.337), train_loss = 1.14252039, grad/param norm = 1.5060e-01, time/batch = 0.6386s	
3593/33650 (epoch 5.339), train_loss = 1.36311677, grad/param norm = 1.6310e-01, time/batch = 0.6387s	
3594/33650 (epoch 5.340), train_loss = 1.68520767, grad/param norm = 1.9303e-01, time/batch = 0.6509s	
3595/33650 (epoch 5.342), train_loss = 1.10599038, grad/param norm = 1.5813e-01, time/batch = 0.6517s	
3596/33650 (epoch 5.343), train_loss = 1.48231369, grad/param norm = 2.0656e-01, time/batch = 0.6592s	
3597/33650 (epoch 5.345), train_loss = 1.38042652, grad/param norm = 1.8594e-01, time/batch = 0.6720s	
3598/33650 (epoch 5.346), train_loss = 1.05675888, grad/param norm = 1.7946e-01, time/batch = 0.6357s	
3599/33650 (epoch 5.348), train_loss = 1.24504717, grad/param norm = 1.7219e-01, time/batch = 0.6307s	
3600/33650 (epoch 5.349), train_loss = 1.18799632, grad/param norm = 1.8193e-01, time/batch = 0.6346s	
3601/33650 (epoch 5.351), train_loss = 1.48262357, grad/param norm = 1.7798e-01, time/batch = 0.6356s	
3602/33650 (epoch 5.352), train_loss = 1.33721762, grad/param norm = 1.6515e-01, time/batch = 0.6331s	
3603/33650 (epoch 5.354), train_loss = 1.73588830, grad/param norm = 2.0444e-01, time/batch = 0.6302s	
3604/33650 (epoch 5.355), train_loss = 1.48980855, grad/param norm = 1.7775e-01, time/batch = 0.6356s	
3605/33650 (epoch 5.357), train_loss = 1.19323395, grad/param norm = 1.5804e-01, time/batch = 0.6397s	
3606/33650 (epoch 5.358), train_loss = 1.51189863, grad/param norm = 1.8435e-01, time/batch = 0.6302s	
3607/33650 (epoch 5.360), train_loss = 1.49721923, grad/param norm = 1.8374e-01, time/batch = 0.6320s	
3608/33650 (epoch 5.361), train_loss = 1.40014451, grad/param norm = 1.7614e-01, time/batch = 0.6307s	
3609/33650 (epoch 5.363), train_loss = 1.31336106, grad/param norm = 1.6857e-01, time/batch = 0.6245s	
3610/33650 (epoch 5.364), train_loss = 1.38150664, grad/param norm = 1.6552e-01, time/batch = 0.6249s	
3611/33650 (epoch 5.366), train_loss = 1.40698822, grad/param norm = 1.9200e-01, time/batch = 0.6308s	
3612/33650 (epoch 5.367), train_loss = 1.47689337, grad/param norm = 1.6637e-01, time/batch = 0.6339s	
3613/33650 (epoch 5.368), train_loss = 1.25758272, grad/param norm = 1.7956e-01, time/batch = 0.6320s	
3614/33650 (epoch 5.370), train_loss = 1.43565419, grad/param norm = 1.7298e-01, time/batch = 0.6311s	
3615/33650 (epoch 5.371), train_loss = 1.17071573, grad/param norm = 1.6502e-01, time/batch = 0.6282s	
3616/33650 (epoch 5.373), train_loss = 1.28900341, grad/param norm = 1.7065e-01, time/batch = 0.6557s	
3617/33650 (epoch 5.374), train_loss = 1.17528582, grad/param norm = 1.4936e-01, time/batch = 0.6475s	
3618/33650 (epoch 5.376), train_loss = 1.34449502, grad/param norm = 1.6977e-01, time/batch = 0.6252s	
3619/33650 (epoch 5.377), train_loss = 1.45855471, grad/param norm = 1.8340e-01, time/batch = 0.6270s	
3620/33650 (epoch 5.379), train_loss = 1.38981387, grad/param norm = 1.6735e-01, time/batch = 0.6261s	
3621/33650 (epoch 5.380), train_loss = 1.16085079, grad/param norm = 1.7991e-01, time/batch = 0.6271s	
3622/33650 (epoch 5.382), train_loss = 1.14082602, grad/param norm = 1.4750e-01, time/batch = 0.6309s	
3623/33650 (epoch 5.383), train_loss = 1.31772420, grad/param norm = 1.6919e-01, time/batch = 0.6250s	
3624/33650 (epoch 5.385), train_loss = 1.50072343, grad/param norm = 1.7542e-01, time/batch = 0.6259s	
3625/33650 (epoch 5.386), train_loss = 1.27217073, grad/param norm = 1.6697e-01, time/batch = 0.6254s	
3626/33650 (epoch 5.388), train_loss = 1.32135316, grad/param norm = 1.6664e-01, time/batch = 0.6270s	
3627/33650 (epoch 5.389), train_loss = 1.44154066, grad/param norm = 1.9695e-01, time/batch = 0.6257s	
3628/33650 (epoch 5.391), train_loss = 1.16362615, grad/param norm = 1.4239e-01, time/batch = 0.6268s	
3629/33650 (epoch 5.392), train_loss = 1.53977863, grad/param norm = 1.9225e-01, time/batch = 0.6280s	
3630/33650 (epoch 5.394), train_loss = 1.52863215, grad/param norm = 2.0949e-01, time/batch = 0.6244s	
3631/33650 (epoch 5.395), train_loss = 1.36441874, grad/param norm = 1.7992e-01, time/batch = 0.6283s	
3632/33650 (epoch 5.397), train_loss = 1.58588400, grad/param norm = 1.8730e-01, time/batch = 0.6260s	
3633/33650 (epoch 5.398), train_loss = 1.37201667, grad/param norm = 1.5015e-01, time/batch = 0.6244s	
3634/33650 (epoch 5.400), train_loss = 1.47025869, grad/param norm = 1.9930e-01, time/batch = 0.6265s	
3635/33650 (epoch 5.401), train_loss = 1.44737284, grad/param norm = 1.7739e-01, time/batch = 0.6266s	
3636/33650 (epoch 5.403), train_loss = 1.43800221, grad/param norm = 1.7295e-01, time/batch = 0.6395s	
3637/33650 (epoch 5.404), train_loss = 1.35747936, grad/param norm = 1.5136e-01, time/batch = 0.6405s	
3638/33650 (epoch 5.406), train_loss = 1.44383381, grad/param norm = 1.6800e-01, time/batch = 0.6265s	
3639/33650 (epoch 5.407), train_loss = 1.35288596, grad/param norm = 1.6474e-01, time/batch = 0.6264s	
3640/33650 (epoch 5.409), train_loss = 1.41941092, grad/param norm = 1.6610e-01, time/batch = 0.6296s	
3641/33650 (epoch 5.410), train_loss = 1.39661571, grad/param norm = 1.8240e-01, time/batch = 0.6281s	
3642/33650 (epoch 5.412), train_loss = 1.36018317, grad/param norm = 1.6129e-01, time/batch = 0.6291s	
3643/33650 (epoch 5.413), train_loss = 1.26925050, grad/param norm = 1.7050e-01, time/batch = 0.6306s	
3644/33650 (epoch 5.415), train_loss = 1.42741877, grad/param norm = 1.7874e-01, time/batch = 0.6297s	
3645/33650 (epoch 5.416), train_loss = 1.58873115, grad/param norm = 2.0946e-01, time/batch = 0.6328s	
3646/33650 (epoch 5.418), train_loss = 1.42580051, grad/param norm = 1.8363e-01, time/batch = 0.6300s	
3647/33650 (epoch 5.419), train_loss = 1.35507181, grad/param norm = 1.7708e-01, time/batch = 0.6283s	
3648/33650 (epoch 5.421), train_loss = 1.24583196, grad/param norm = 1.5970e-01, time/batch = 0.6260s	
3649/33650 (epoch 5.422), train_loss = 1.48552877, grad/param norm = 1.9319e-01, time/batch = 0.6271s	
3650/33650 (epoch 5.423), train_loss = 1.26679573, grad/param norm = 1.6350e-01, time/batch = 0.6288s	
3651/33650 (epoch 5.425), train_loss = 1.44907658, grad/param norm = 1.7410e-01, time/batch = 0.6394s	
3652/33650 (epoch 5.426), train_loss = 1.52464508, grad/param norm = 1.6967e-01, time/batch = 0.6321s	
3653/33650 (epoch 5.428), train_loss = 1.30544036, grad/param norm = 1.7118e-01, time/batch = 0.6347s	
3654/33650 (epoch 5.429), train_loss = 1.48350026, grad/param norm = 1.7592e-01, time/batch = 0.6291s	
3655/33650 (epoch 5.431), train_loss = 1.65577489, grad/param norm = 1.8872e-01, time/batch = 0.6279s	
3656/33650 (epoch 5.432), train_loss = 1.67678766, grad/param norm = 1.8094e-01, time/batch = 0.6278s	
3657/33650 (epoch 5.434), train_loss = 1.48133367, grad/param norm = 1.7731e-01, time/batch = 0.6585s	
3658/33650 (epoch 5.435), train_loss = 1.43662587, grad/param norm = 1.7876e-01, time/batch = 0.6555s	
3659/33650 (epoch 5.437), train_loss = 1.50113964, grad/param norm = 1.9219e-01, time/batch = 0.6295s	
3660/33650 (epoch 5.438), train_loss = 1.33231407, grad/param norm = 1.9273e-01, time/batch = 0.6267s	
3661/33650 (epoch 5.440), train_loss = 1.43551334, grad/param norm = 1.8883e-01, time/batch = 0.6301s	
3662/33650 (epoch 5.441), train_loss = 1.47668515, grad/param norm = 1.7955e-01, time/batch = 0.6301s	
3663/33650 (epoch 5.443), train_loss = 1.49330612, grad/param norm = 1.9032e-01, time/batch = 0.6276s	
3664/33650 (epoch 5.444), train_loss = 1.34254678, grad/param norm = 1.5750e-01, time/batch = 0.6285s	
3665/33650 (epoch 5.446), train_loss = 1.45487001, grad/param norm = 1.8157e-01, time/batch = 0.6273s	
3666/33650 (epoch 5.447), train_loss = 1.51402016, grad/param norm = 1.9900e-01, time/batch = 0.6325s	
3667/33650 (epoch 5.449), train_loss = 1.66968376, grad/param norm = 2.3880e-01, time/batch = 0.6334s	
3668/33650 (epoch 5.450), train_loss = 1.66068005, grad/param norm = 1.9957e-01, time/batch = 0.6267s	
3669/33650 (epoch 5.452), train_loss = 1.75188315, grad/param norm = 2.0535e-01, time/batch = 0.6293s	
3670/33650 (epoch 5.453), train_loss = 1.62830250, grad/param norm = 1.9186e-01, time/batch = 0.6304s	
3671/33650 (epoch 5.455), train_loss = 1.41411248, grad/param norm = 1.7241e-01, time/batch = 0.6278s	
3672/33650 (epoch 5.456), train_loss = 1.37769843, grad/param norm = 1.7476e-01, time/batch = 0.6263s	
3673/33650 (epoch 5.458), train_loss = 1.44742297, grad/param norm = 1.9255e-01, time/batch = 0.6266s	
3674/33650 (epoch 5.459), train_loss = 1.38522832, grad/param norm = 1.8138e-01, time/batch = 0.6326s	
3675/33650 (epoch 5.461), train_loss = 1.53836899, grad/param norm = 1.8509e-01, time/batch = 0.6287s	
3676/33650 (epoch 5.462), train_loss = 1.55851317, grad/param norm = 1.7956e-01, time/batch = 0.6391s	
3677/33650 (epoch 5.464), train_loss = 1.37194627, grad/param norm = 1.7512e-01, time/batch = 0.6391s	
3678/33650 (epoch 5.465), train_loss = 1.46038436, grad/param norm = 1.8119e-01, time/batch = 0.6659s	
3679/33650 (epoch 5.467), train_loss = 1.47916180, grad/param norm = 1.8025e-01, time/batch = 0.6322s	
3680/33650 (epoch 5.468), train_loss = 1.56753554, grad/param norm = 1.7820e-01, time/batch = 0.6264s	
3681/33650 (epoch 5.470), train_loss = 1.73564396, grad/param norm = 2.0208e-01, time/batch = 0.6326s	
3682/33650 (epoch 5.471), train_loss = 1.40849227, grad/param norm = 1.7261e-01, time/batch = 0.6263s	
3683/33650 (epoch 5.473), train_loss = 1.32679266, grad/param norm = 1.6161e-01, time/batch = 0.6265s	
3684/33650 (epoch 5.474), train_loss = 1.46763307, grad/param norm = 1.7728e-01, time/batch = 0.6259s	
3685/33650 (epoch 5.475), train_loss = 1.52448749, grad/param norm = 1.8309e-01, time/batch = 0.6253s	
3686/33650 (epoch 5.477), train_loss = 1.56818507, grad/param norm = 1.8366e-01, time/batch = 0.6273s	
3687/33650 (epoch 5.478), train_loss = 1.54095283, grad/param norm = 1.8170e-01, time/batch = 0.6313s	
3688/33650 (epoch 5.480), train_loss = 1.60648724, grad/param norm = 1.8040e-01, time/batch = 0.6336s	
3689/33650 (epoch 5.481), train_loss = 1.56065357, grad/param norm = 1.9258e-01, time/batch = 0.6398s	
3690/33650 (epoch 5.483), train_loss = 1.16328381, grad/param norm = 1.6320e-01, time/batch = 0.6445s	
3691/33650 (epoch 5.484), train_loss = 1.45140952, grad/param norm = 1.6817e-01, time/batch = 0.6723s	
3692/33650 (epoch 5.486), train_loss = 1.58373494, grad/param norm = 2.2849e-01, time/batch = 0.6533s	
3693/33650 (epoch 5.487), train_loss = 1.57189933, grad/param norm = 2.1921e-01, time/batch = 0.6319s	
3694/33650 (epoch 5.489), train_loss = 1.66070618, grad/param norm = 1.8126e-01, time/batch = 0.6371s	
3695/33650 (epoch 5.490), train_loss = 1.32992567, grad/param norm = 1.7268e-01, time/batch = 0.6316s	
3696/33650 (epoch 5.492), train_loss = 1.55383268, grad/param norm = 1.8946e-01, time/batch = 0.6313s	
3697/33650 (epoch 5.493), train_loss = 1.17424429, grad/param norm = 1.5978e-01, time/batch = 0.6297s	
3698/33650 (epoch 5.495), train_loss = 1.39859274, grad/param norm = 1.7803e-01, time/batch = 0.6657s	
3699/33650 (epoch 5.496), train_loss = 1.48927568, grad/param norm = 2.0098e-01, time/batch = 0.6447s	
3700/33650 (epoch 5.498), train_loss = 1.23624527, grad/param norm = 1.8445e-01, time/batch = 0.6257s	
3701/33650 (epoch 5.499), train_loss = 1.35331924, grad/param norm = 1.6116e-01, time/batch = 0.6288s	
3702/33650 (epoch 5.501), train_loss = 1.37866393, grad/param norm = 1.5440e-01, time/batch = 0.6275s	
3703/33650 (epoch 5.502), train_loss = 1.50183093, grad/param norm = 1.9664e-01, time/batch = 0.6235s	
3704/33650 (epoch 5.504), train_loss = 1.66632716, grad/param norm = 1.9173e-01, time/batch = 0.6259s	
3705/33650 (epoch 5.505), train_loss = 1.50501885, grad/param norm = 2.1200e-01, time/batch = 0.6299s	
3706/33650 (epoch 5.507), train_loss = 1.57196162, grad/param norm = 2.0752e-01, time/batch = 0.6367s	
3707/33650 (epoch 5.508), train_loss = 1.36391523, grad/param norm = 1.8071e-01, time/batch = 0.6273s	
3708/33650 (epoch 5.510), train_loss = 1.40592637, grad/param norm = 1.8332e-01, time/batch = 0.6309s	
3709/33650 (epoch 5.511), train_loss = 1.70741294, grad/param norm = 2.0682e-01, time/batch = 0.6291s	
3710/33650 (epoch 5.513), train_loss = 1.51208097, grad/param norm = 1.7722e-01, time/batch = 0.6264s	
3711/33650 (epoch 5.514), train_loss = 1.47753186, grad/param norm = 1.8397e-01, time/batch = 0.6279s	
3712/33650 (epoch 5.516), train_loss = 1.44884189, grad/param norm = 1.7964e-01, time/batch = 0.6266s	
3713/33650 (epoch 5.517), train_loss = 1.36672056, grad/param norm = 1.6903e-01, time/batch = 0.6259s	
3714/33650 (epoch 5.519), train_loss = 1.39747903, grad/param norm = 1.6461e-01, time/batch = 0.6259s	
3715/33650 (epoch 5.520), train_loss = 1.21234430, grad/param norm = 1.6464e-01, time/batch = 0.6260s	
3716/33650 (epoch 5.522), train_loss = 1.43191142, grad/param norm = 1.8850e-01, time/batch = 0.6294s	
3717/33650 (epoch 5.523), train_loss = 1.42900535, grad/param norm = 1.7640e-01, time/batch = 0.6240s	
3718/33650 (epoch 5.525), train_loss = 1.11261435, grad/param norm = 1.5854e-01, time/batch = 0.6239s	
3719/33650 (epoch 5.526), train_loss = 1.46292827, grad/param norm = 1.9065e-01, time/batch = 0.6252s	
3720/33650 (epoch 5.527), train_loss = 1.28679410, grad/param norm = 1.7115e-01, time/batch = 0.6245s	
3721/33650 (epoch 5.529), train_loss = 1.37988639, grad/param norm = 1.6613e-01, time/batch = 0.6280s	
3722/33650 (epoch 5.530), train_loss = 1.33961797, grad/param norm = 1.6869e-01, time/batch = 0.6266s	
3723/33650 (epoch 5.532), train_loss = 1.64919535, grad/param norm = 2.1150e-01, time/batch = 0.6271s	
3724/33650 (epoch 5.533), train_loss = 1.34767082, grad/param norm = 1.7733e-01, time/batch = 0.6286s	
3725/33650 (epoch 5.535), train_loss = 1.55748258, grad/param norm = 1.8650e-01, time/batch = 0.6289s	
3726/33650 (epoch 5.536), train_loss = 1.45028375, grad/param norm = 1.7813e-01, time/batch = 0.6249s	
3727/33650 (epoch 5.538), train_loss = 1.46509526, grad/param norm = 1.8826e-01, time/batch = 0.6274s	
3728/33650 (epoch 5.539), train_loss = 1.20463114, grad/param norm = 1.5707e-01, time/batch = 0.6259s	
3729/33650 (epoch 5.541), train_loss = 1.56092467, grad/param norm = 1.7537e-01, time/batch = 0.6249s	
3730/33650 (epoch 5.542), train_loss = 1.50209167, grad/param norm = 2.1058e-01, time/batch = 0.6263s	
3731/33650 (epoch 5.544), train_loss = 1.74145144, grad/param norm = 2.0814e-01, time/batch = 0.6345s	
3732/33650 (epoch 5.545), train_loss = 1.23443750, grad/param norm = 1.6445e-01, time/batch = 0.6316s	
3733/33650 (epoch 5.547), train_loss = 1.43832573, grad/param norm = 1.7406e-01, time/batch = 0.6269s	
3734/33650 (epoch 5.548), train_loss = 1.55225687, grad/param norm = 1.8515e-01, time/batch = 0.6533s	
3735/33650 (epoch 5.550), train_loss = 1.35906942, grad/param norm = 1.7409e-01, time/batch = 0.6598s	
3736/33650 (epoch 5.551), train_loss = 1.37578432, grad/param norm = 1.7886e-01, time/batch = 0.6334s	
3737/33650 (epoch 5.553), train_loss = 1.18401016, grad/param norm = 1.7169e-01, time/batch = 0.6260s	
3738/33650 (epoch 5.554), train_loss = 1.53794228, grad/param norm = 1.8811e-01, time/batch = 0.6445s	
3739/33650 (epoch 5.556), train_loss = 1.58900241, grad/param norm = 2.1172e-01, time/batch = 0.6330s	
3740/33650 (epoch 5.557), train_loss = 1.63017777, grad/param norm = 1.9760e-01, time/batch = 0.6262s	
3741/33650 (epoch 5.559), train_loss = 1.70413909, grad/param norm = 2.4832e-01, time/batch = 0.6284s	
3742/33650 (epoch 5.560), train_loss = 1.64999900, grad/param norm = 1.8916e-01, time/batch = 0.6263s	
3743/33650 (epoch 5.562), train_loss = 1.53105626, grad/param norm = 1.8858e-01, time/batch = 0.6268s	
3744/33650 (epoch 5.563), train_loss = 1.38915597, grad/param norm = 1.8802e-01, time/batch = 0.6283s	
3745/33650 (epoch 5.565), train_loss = 1.47303866, grad/param norm = 1.7815e-01, time/batch = 0.6270s	
3746/33650 (epoch 5.566), train_loss = 1.46123439, grad/param norm = 1.9224e-01, time/batch = 0.6301s	
3747/33650 (epoch 5.568), train_loss = 1.45621611, grad/param norm = 1.7472e-01, time/batch = 0.6293s	
3748/33650 (epoch 5.569), train_loss = 1.37278350, grad/param norm = 1.8096e-01, time/batch = 0.6255s	
3749/33650 (epoch 5.571), train_loss = 1.57294107, grad/param norm = 1.9657e-01, time/batch = 0.6283s	
3750/33650 (epoch 5.572), train_loss = 1.47393631, grad/param norm = 1.6512e-01, time/batch = 0.6268s	
3751/33650 (epoch 5.574), train_loss = 1.42804675, grad/param norm = 1.8016e-01, time/batch = 0.6300s	
3752/33650 (epoch 5.575), train_loss = 1.41590164, grad/param norm = 1.7082e-01, time/batch = 0.6301s	
3753/33650 (epoch 5.577), train_loss = 1.53531319, grad/param norm = 1.8075e-01, time/batch = 0.6289s	
3754/33650 (epoch 5.578), train_loss = 1.41957080, grad/param norm = 1.6625e-01, time/batch = 0.6342s	
3755/33650 (epoch 5.579), train_loss = 1.47487867, grad/param norm = 1.6809e-01, time/batch = 0.6660s	
3756/33650 (epoch 5.581), train_loss = 1.47422689, grad/param norm = 1.7800e-01, time/batch = 0.6412s	
3757/33650 (epoch 5.582), train_loss = 1.53394967, grad/param norm = 1.8417e-01, time/batch = 0.6319s	
3758/33650 (epoch 5.584), train_loss = 1.41257680, grad/param norm = 1.7195e-01, time/batch = 0.6407s	
3759/33650 (epoch 5.585), train_loss = 1.44410021, grad/param norm = 1.8182e-01, time/batch = 0.6350s	
3760/33650 (epoch 5.587), train_loss = 1.31924321, grad/param norm = 1.7697e-01, time/batch = 0.6271s	
3761/33650 (epoch 5.588), train_loss = 1.41743218, grad/param norm = 1.9374e-01, time/batch = 0.6325s	
3762/33650 (epoch 5.590), train_loss = 1.40165970, grad/param norm = 1.6682e-01, time/batch = 0.6252s	
3763/33650 (epoch 5.591), train_loss = 1.42579829, grad/param norm = 1.8784e-01, time/batch = 0.6274s	
3764/33650 (epoch 5.593), train_loss = 1.28948932, grad/param norm = 1.7070e-01, time/batch = 0.6265s	
3765/33650 (epoch 5.594), train_loss = 1.16632337, grad/param norm = 1.8346e-01, time/batch = 0.6269s	
3766/33650 (epoch 5.596), train_loss = 1.37160039, grad/param norm = 1.7416e-01, time/batch = 0.6259s	
3767/33650 (epoch 5.597), train_loss = 1.13207528, grad/param norm = 1.3978e-01, time/batch = 0.6284s	
3768/33650 (epoch 5.599), train_loss = 1.27204457, grad/param norm = 1.6244e-01, time/batch = 0.6316s	
3769/33650 (epoch 5.600), train_loss = 1.26522262, grad/param norm = 1.7161e-01, time/batch = 0.6248s	
3770/33650 (epoch 5.602), train_loss = 1.51319037, grad/param norm = 1.7640e-01, time/batch = 0.6449s	
3771/33650 (epoch 5.603), train_loss = 1.34055707, grad/param norm = 1.7255e-01, time/batch = 0.6695s	
3772/33650 (epoch 5.605), train_loss = 1.39522094, grad/param norm = 1.8876e-01, time/batch = 0.6280s	
3773/33650 (epoch 5.606), train_loss = 1.53777802, grad/param norm = 1.7667e-01, time/batch = 0.6283s	
3774/33650 (epoch 5.608), train_loss = 1.41655111, grad/param norm = 1.7292e-01, time/batch = 0.6284s	
3775/33650 (epoch 5.609), train_loss = 1.47389093, grad/param norm = 1.9212e-01, time/batch = 0.6315s	
3776/33650 (epoch 5.611), train_loss = 1.30326147, grad/param norm = 1.5855e-01, time/batch = 0.6276s	
3777/33650 (epoch 5.612), train_loss = 1.42936221, grad/param norm = 1.8332e-01, time/batch = 0.6277s	
3778/33650 (epoch 5.614), train_loss = 1.55763862, grad/param norm = 1.9495e-01, time/batch = 0.6306s	
3779/33650 (epoch 5.615), train_loss = 1.33071154, grad/param norm = 1.6477e-01, time/batch = 0.6349s	
3780/33650 (epoch 5.617), train_loss = 1.24711171, grad/param norm = 1.5227e-01, time/batch = 0.6498s	
3781/33650 (epoch 5.618), train_loss = 1.32869239, grad/param norm = 1.7156e-01, time/batch = 0.6340s	
3782/33650 (epoch 5.620), train_loss = 1.53758426, grad/param norm = 1.8628e-01, time/batch = 0.6453s	
3783/33650 (epoch 5.621), train_loss = 1.24005926, grad/param norm = 1.6195e-01, time/batch = 0.6497s	
3784/33650 (epoch 5.623), train_loss = 1.39063471, grad/param norm = 1.7502e-01, time/batch = 0.6605s	
3785/33650 (epoch 5.624), train_loss = 1.11684325, grad/param norm = 1.8040e-01, time/batch = 0.6590s	
3786/33650 (epoch 5.626), train_loss = 1.11267248, grad/param norm = 1.4932e-01, time/batch = 0.6610s	
3787/33650 (epoch 5.627), train_loss = 1.34842731, grad/param norm = 1.6431e-01, time/batch = 0.6654s	
3788/33650 (epoch 5.629), train_loss = 1.39778478, grad/param norm = 1.6398e-01, time/batch = 0.6567s	
3789/33650 (epoch 5.630), train_loss = 1.48849680, grad/param norm = 1.7865e-01, time/batch = 0.6324s	
3790/33650 (epoch 5.632), train_loss = 1.56342583, grad/param norm = 1.7450e-01, time/batch = 0.6394s	
3791/33650 (epoch 5.633), train_loss = 1.48129641, grad/param norm = 1.7555e-01, time/batch = 0.6651s	
3792/33650 (epoch 5.634), train_loss = 1.24307748, grad/param norm = 1.6272e-01, time/batch = 0.6331s	
3793/33650 (epoch 5.636), train_loss = 1.12627130, grad/param norm = 1.4887e-01, time/batch = 0.6274s	
3794/33650 (epoch 5.637), train_loss = 1.44788369, grad/param norm = 1.7830e-01, time/batch = 0.6293s	
3795/33650 (epoch 5.639), train_loss = 1.33160015, grad/param norm = 1.6259e-01, time/batch = 0.6263s	
3796/33650 (epoch 5.640), train_loss = 1.41880412, grad/param norm = 1.8624e-01, time/batch = 0.6271s	
3797/33650 (epoch 5.642), train_loss = 1.62554052, grad/param norm = 1.9763e-01, time/batch = 0.6264s	
3798/33650 (epoch 5.643), train_loss = 1.43397065, grad/param norm = 1.8901e-01, time/batch = 0.6380s	
3799/33650 (epoch 5.645), train_loss = 1.37526302, grad/param norm = 1.6215e-01, time/batch = 0.6599s	
3800/33650 (epoch 5.646), train_loss = 1.16407163, grad/param norm = 1.4153e-01, time/batch = 0.6400s	
3801/33650 (epoch 5.648), train_loss = 1.38148922, grad/param norm = 1.6957e-01, time/batch = 0.6417s	
3802/33650 (epoch 5.649), train_loss = 1.46215776, grad/param norm = 1.9729e-01, time/batch = 0.6411s	
3803/33650 (epoch 5.651), train_loss = 1.48310095, grad/param norm = 1.7669e-01, time/batch = 0.6330s	
3804/33650 (epoch 5.652), train_loss = 1.02780759, grad/param norm = 1.4401e-01, time/batch = 0.6263s	
3805/33650 (epoch 5.654), train_loss = 1.33248931, grad/param norm = 1.6460e-01, time/batch = 0.6297s	
3806/33650 (epoch 5.655), train_loss = 1.20991675, grad/param norm = 1.6788e-01, time/batch = 0.6565s	
3807/33650 (epoch 5.657), train_loss = 1.39007558, grad/param norm = 1.8238e-01, time/batch = 0.6583s	
3808/33650 (epoch 5.658), train_loss = 1.22805153, grad/param norm = 1.5273e-01, time/batch = 0.6340s	
3809/33650 (epoch 5.660), train_loss = 1.19462520, grad/param norm = 1.6687e-01, time/batch = 0.6353s	
3810/33650 (epoch 5.661), train_loss = 1.29877638, grad/param norm = 1.5118e-01, time/batch = 0.6265s	
3811/33650 (epoch 5.663), train_loss = 1.19823306, grad/param norm = 1.7530e-01, time/batch = 0.6284s	
3812/33650 (epoch 5.664), train_loss = 1.19434328, grad/param norm = 1.5964e-01, time/batch = 0.6271s	
3813/33650 (epoch 5.666), train_loss = 1.30493159, grad/param norm = 1.7802e-01, time/batch = 0.6580s	
3814/33650 (epoch 5.667), train_loss = 1.21861063, grad/param norm = 1.4779e-01, time/batch = 0.6298s	
3815/33650 (epoch 5.669), train_loss = 1.19144411, grad/param norm = 1.5576e-01, time/batch = 0.6417s	
3816/33650 (epoch 5.670), train_loss = 1.18159988, grad/param norm = 1.5860e-01, time/batch = 0.6351s	
3817/33650 (epoch 5.672), train_loss = 1.24491465, grad/param norm = 1.5293e-01, time/batch = 0.6282s	
3818/33650 (epoch 5.673), train_loss = 1.11353533, grad/param norm = 1.6202e-01, time/batch = 0.6266s	
3819/33650 (epoch 5.675), train_loss = 1.08185539, grad/param norm = 1.3150e-01, time/batch = 0.6286s	
3820/33650 (epoch 5.676), train_loss = 1.37022418, grad/param norm = 1.5793e-01, time/batch = 0.6267s	
3821/33650 (epoch 5.678), train_loss = 1.23389904, grad/param norm = 1.6577e-01, time/batch = 0.6316s	
3822/33650 (epoch 5.679), train_loss = 1.33113765, grad/param norm = 1.8506e-01, time/batch = 0.6282s	
3823/33650 (epoch 5.681), train_loss = 1.22703448, grad/param norm = 1.6496e-01, time/batch = 0.6365s	
3824/33650 (epoch 5.682), train_loss = 1.28256545, grad/param norm = 1.6351e-01, time/batch = 0.6295s	
3825/33650 (epoch 5.684), train_loss = 1.21661094, grad/param norm = 1.5475e-01, time/batch = 0.6268s	
3826/33650 (epoch 5.685), train_loss = 1.43917049, grad/param norm = 1.7697e-01, time/batch = 0.6409s	
3827/33650 (epoch 5.686), train_loss = 1.32604259, grad/param norm = 1.7067e-01, time/batch = 0.6657s	
3828/33650 (epoch 5.688), train_loss = 1.54657055, grad/param norm = 1.8253e-01, time/batch = 0.6342s	
3829/33650 (epoch 5.689), train_loss = 1.26354296, grad/param norm = 1.7064e-01, time/batch = 0.6264s	
3830/33650 (epoch 5.691), train_loss = 1.49623826, grad/param norm = 1.8198e-01, time/batch = 0.6285s	
3831/33650 (epoch 5.692), train_loss = 1.48063987, grad/param norm = 1.6904e-01, time/batch = 0.6313s	
3832/33650 (epoch 5.694), train_loss = 1.43424021, grad/param norm = 1.8524e-01, time/batch = 0.6268s	
3833/33650 (epoch 5.695), train_loss = 1.04688227, grad/param norm = 1.5952e-01, time/batch = 0.6285s	
3834/33650 (epoch 5.697), train_loss = 1.38754602, grad/param norm = 1.6713e-01, time/batch = 0.6285s	
3835/33650 (epoch 5.698), train_loss = 1.49256667, grad/param norm = 1.7931e-01, time/batch = 0.6285s	
3836/33650 (epoch 5.700), train_loss = 1.32740371, grad/param norm = 1.6717e-01, time/batch = 0.6280s	
3837/33650 (epoch 5.701), train_loss = 1.43933253, grad/param norm = 1.7798e-01, time/batch = 0.6281s	
3838/33650 (epoch 5.703), train_loss = 1.38923748, grad/param norm = 1.5989e-01, time/batch = 0.6487s	
3839/33650 (epoch 5.704), train_loss = 1.27810089, grad/param norm = 1.6477e-01, time/batch = 0.6361s	
3840/33650 (epoch 5.706), train_loss = 1.31630061, grad/param norm = 1.4857e-01, time/batch = 0.6278s	
3841/33650 (epoch 5.707), train_loss = 1.47213060, grad/param norm = 1.7917e-01, time/batch = 0.6316s	
3842/33650 (epoch 5.709), train_loss = 1.30337119, grad/param norm = 1.6839e-01, time/batch = 0.6283s	
3843/33650 (epoch 5.710), train_loss = 1.51700350, grad/param norm = 1.6799e-01, time/batch = 0.6284s	
3844/33650 (epoch 5.712), train_loss = 1.29268856, grad/param norm = 1.5911e-01, time/batch = 0.6323s	
3845/33650 (epoch 5.713), train_loss = 1.34131290, grad/param norm = 1.9423e-01, time/batch = 0.6375s	
3846/33650 (epoch 5.715), train_loss = 1.51583039, grad/param norm = 1.7744e-01, time/batch = 0.6279s	
3847/33650 (epoch 5.716), train_loss = 1.24161028, grad/param norm = 1.6791e-01, time/batch = 0.6625s	
3848/33650 (epoch 5.718), train_loss = 1.46141754, grad/param norm = 1.6843e-01, time/batch = 0.6509s	
3849/33650 (epoch 5.719), train_loss = 1.53153830, grad/param norm = 1.8612e-01, time/batch = 0.6274s	
3850/33650 (epoch 5.721), train_loss = 1.63055341, grad/param norm = 1.8067e-01, time/batch = 0.6376s	
3851/33650 (epoch 5.722), train_loss = 1.56584350, grad/param norm = 1.9064e-01, time/batch = 0.6489s	
3852/33650 (epoch 5.724), train_loss = 1.44779088, grad/param norm = 1.6728e-01, time/batch = 0.6555s	
3853/33650 (epoch 5.725), train_loss = 1.52826148, grad/param norm = 1.8477e-01, time/batch = 0.6509s	
3854/33650 (epoch 5.727), train_loss = 1.29051571, grad/param norm = 1.8401e-01, time/batch = 0.6505s	
3855/33650 (epoch 5.728), train_loss = 1.30781108, grad/param norm = 1.6128e-01, time/batch = 0.6284s	
3856/33650 (epoch 5.730), train_loss = 1.42106284, grad/param norm = 1.7346e-01, time/batch = 0.6346s	
3857/33650 (epoch 5.731), train_loss = 1.56505482, grad/param norm = 1.8762e-01, time/batch = 0.6541s	
3858/33650 (epoch 5.733), train_loss = 1.32261963, grad/param norm = 1.7368e-01, time/batch = 0.6672s	
3859/33650 (epoch 5.734), train_loss = 1.57314471, grad/param norm = 2.1235e-01, time/batch = 0.6442s	
3860/33650 (epoch 5.736), train_loss = 1.38259067, grad/param norm = 1.8977e-01, time/batch = 0.6327s	
3861/33650 (epoch 5.737), train_loss = 1.39211235, grad/param norm = 1.7839e-01, time/batch = 0.6387s	
3862/33650 (epoch 5.738), train_loss = 1.22410045, grad/param norm = 1.6386e-01, time/batch = 0.6287s	
3863/33650 (epoch 5.740), train_loss = 1.25609090, grad/param norm = 1.6462e-01, time/batch = 0.6266s	
3864/33650 (epoch 5.741), train_loss = 1.35731216, grad/param norm = 1.7595e-01, time/batch = 0.6264s	
3865/33650 (epoch 5.743), train_loss = 1.36984778, grad/param norm = 1.5857e-01, time/batch = 0.6270s	
3866/33650 (epoch 5.744), train_loss = 1.29673909, grad/param norm = 1.5576e-01, time/batch = 0.6255s	
3867/33650 (epoch 5.746), train_loss = 1.32681682, grad/param norm = 1.6350e-01, time/batch = 0.6277s	
3868/33650 (epoch 5.747), train_loss = 1.46798905, grad/param norm = 1.6866e-01, time/batch = 0.6291s	
3869/33650 (epoch 5.749), train_loss = 1.13523622, grad/param norm = 1.5426e-01, time/batch = 0.6276s	
3870/33650 (epoch 5.750), train_loss = 1.45536984, grad/param norm = 2.0354e-01, time/batch = 0.6249s	
3871/33650 (epoch 5.752), train_loss = 1.48695099, grad/param norm = 2.0337e-01, time/batch = 0.6291s	
3872/33650 (epoch 5.753), train_loss = 1.62900613, grad/param norm = 2.0245e-01, time/batch = 0.6292s	
3873/33650 (epoch 5.755), train_loss = 1.25288250, grad/param norm = 1.6755e-01, time/batch = 0.6256s	
3874/33650 (epoch 5.756), train_loss = 1.44308028, grad/param norm = 1.8412e-01, time/batch = 0.6262s	
3875/33650 (epoch 5.758), train_loss = 1.54799074, grad/param norm = 1.9078e-01, time/batch = 0.6263s	
3876/33650 (epoch 5.759), train_loss = 1.62439023, grad/param norm = 1.7787e-01, time/batch = 0.6361s	
3877/33650 (epoch 5.761), train_loss = 1.46154709, grad/param norm = 1.8231e-01, time/batch = 0.6459s	
3878/33650 (epoch 5.762), train_loss = 1.38497679, grad/param norm = 1.7894e-01, time/batch = 0.6590s	
3879/33650 (epoch 5.764), train_loss = 1.54305395, grad/param norm = 2.1546e-01, time/batch = 0.6689s	
3880/33650 (epoch 5.765), train_loss = 1.44939016, grad/param norm = 1.7486e-01, time/batch = 0.6386s	
3881/33650 (epoch 5.767), train_loss = 1.23852015, grad/param norm = 1.6013e-01, time/batch = 0.6345s	
3882/33650 (epoch 5.768), train_loss = 1.21884118, grad/param norm = 1.6118e-01, time/batch = 0.6429s	
3883/33650 (epoch 5.770), train_loss = 1.35302826, grad/param norm = 1.7847e-01, time/batch = 0.6312s	
3884/33650 (epoch 5.771), train_loss = 1.36899107, grad/param norm = 1.7318e-01, time/batch = 0.6280s	
3885/33650 (epoch 5.773), train_loss = 1.56333399, grad/param norm = 1.9632e-01, time/batch = 0.6294s	
3886/33650 (epoch 5.774), train_loss = 1.43997421, grad/param norm = 1.8875e-01, time/batch = 0.6284s	
3887/33650 (epoch 5.776), train_loss = 1.48864186, grad/param norm = 2.0740e-01, time/batch = 0.6274s	
3888/33650 (epoch 5.777), train_loss = 1.25248519, grad/param norm = 1.6689e-01, time/batch = 0.6254s	
3889/33650 (epoch 5.779), train_loss = 1.37930077, grad/param norm = 1.5519e-01, time/batch = 0.6265s	
3890/33650 (epoch 5.780), train_loss = 1.24379817, grad/param norm = 1.6288e-01, time/batch = 0.6254s	
3891/33650 (epoch 5.782), train_loss = 1.31626075, grad/param norm = 1.6449e-01, time/batch = 0.6290s	
3892/33650 (epoch 5.783), train_loss = 1.20120561, grad/param norm = 1.6375e-01, time/batch = 0.6347s	
3893/33650 (epoch 5.785), train_loss = 1.65290142, grad/param norm = 1.7635e-01, time/batch = 0.6355s	
3894/33650 (epoch 5.786), train_loss = 1.36468673, grad/param norm = 1.6079e-01, time/batch = 0.6292s	
3895/33650 (epoch 5.788), train_loss = 1.38598057, grad/param norm = 1.7428e-01, time/batch = 0.6279s	
3896/33650 (epoch 5.789), train_loss = 1.42056719, grad/param norm = 1.5476e-01, time/batch = 0.6322s	
3897/33650 (epoch 5.790), train_loss = 1.50025954, grad/param norm = 1.9588e-01, time/batch = 0.6300s	
3898/33650 (epoch 5.792), train_loss = 1.53084225, grad/param norm = 1.9872e-01, time/batch = 0.6369s	
3899/33650 (epoch 5.793), train_loss = 1.46327422, grad/param norm = 1.7108e-01, time/batch = 0.6658s	
3900/33650 (epoch 5.795), train_loss = 1.51989246, grad/param norm = 1.7265e-01, time/batch = 0.6360s	
3901/33650 (epoch 5.796), train_loss = 1.30109951, grad/param norm = 1.6263e-01, time/batch = 0.6334s	
3902/33650 (epoch 5.798), train_loss = 1.33053245, grad/param norm = 1.5890e-01, time/batch = 0.6302s	
3903/33650 (epoch 5.799), train_loss = 1.36023216, grad/param norm = 1.5949e-01, time/batch = 0.6259s	
3904/33650 (epoch 5.801), train_loss = 1.45633878, grad/param norm = 1.8428e-01, time/batch = 0.6252s	
3905/33650 (epoch 5.802), train_loss = 1.51798558, grad/param norm = 1.5937e-01, time/batch = 0.6265s	
3906/33650 (epoch 5.804), train_loss = 1.35964921, grad/param norm = 1.6103e-01, time/batch = 0.6303s	
3907/33650 (epoch 5.805), train_loss = 1.34120840, grad/param norm = 1.7052e-01, time/batch = 0.6269s	
3908/33650 (epoch 5.807), train_loss = 1.67137285, grad/param norm = 1.9207e-01, time/batch = 0.6264s	
3909/33650 (epoch 5.808), train_loss = 1.63036611, grad/param norm = 1.8470e-01, time/batch = 0.6307s	
3910/33650 (epoch 5.810), train_loss = 1.42993112, grad/param norm = 1.6133e-01, time/batch = 0.6218s	
3911/33650 (epoch 5.811), train_loss = 1.45651399, grad/param norm = 1.7684e-01, time/batch = 0.6295s	
3912/33650 (epoch 5.813), train_loss = 1.40106723, grad/param norm = 1.9812e-01, time/batch = 0.6264s	
3913/33650 (epoch 5.814), train_loss = 1.50274003, grad/param norm = 1.8542e-01, time/batch = 0.6269s	
3914/33650 (epoch 5.816), train_loss = 1.45239980, grad/param norm = 1.8356e-01, time/batch = 0.6261s	
3915/33650 (epoch 5.817), train_loss = 1.55529197, grad/param norm = 2.0581e-01, time/batch = 0.6264s	
3916/33650 (epoch 5.819), train_loss = 1.53780782, grad/param norm = 1.7313e-01, time/batch = 0.6292s	
3917/33650 (epoch 5.820), train_loss = 1.54219640, grad/param norm = 1.7296e-01, time/batch = 0.6324s	
3918/33650 (epoch 5.822), train_loss = 1.59814160, grad/param norm = 1.9458e-01, time/batch = 0.6270s	
3919/33650 (epoch 5.823), train_loss = 1.29719552, grad/param norm = 1.8139e-01, time/batch = 0.6560s	
3920/33650 (epoch 5.825), train_loss = 1.37196140, grad/param norm = 1.6319e-01, time/batch = 0.6567s	
3921/33650 (epoch 5.826), train_loss = 1.46007693, grad/param norm = 1.7058e-01, time/batch = 0.6290s	
3922/33650 (epoch 5.828), train_loss = 1.71687278, grad/param norm = 1.8978e-01, time/batch = 0.6369s	
3923/33650 (epoch 5.829), train_loss = 1.25996507, grad/param norm = 1.7144e-01, time/batch = 0.6319s	
3924/33650 (epoch 5.831), train_loss = 1.51356820, grad/param norm = 1.7154e-01, time/batch = 0.6297s	
3925/33650 (epoch 5.832), train_loss = 1.46670405, grad/param norm = 1.8331e-01, time/batch = 0.6307s	
3926/33650 (epoch 5.834), train_loss = 1.51192694, grad/param norm = 1.7932e-01, time/batch = 0.6297s	
3927/33650 (epoch 5.835), train_loss = 1.70539467, grad/param norm = 1.8428e-01, time/batch = 0.6280s	
3928/33650 (epoch 5.837), train_loss = 1.45351010, grad/param norm = 1.9102e-01, time/batch = 0.6258s	
3929/33650 (epoch 5.838), train_loss = 1.41249213, grad/param norm = 1.8089e-01, time/batch = 0.6308s	
3930/33650 (epoch 5.840), train_loss = 1.46879929, grad/param norm = 1.6359e-01, time/batch = 0.6437s	
3931/33650 (epoch 5.841), train_loss = 1.29794917, grad/param norm = 1.5340e-01, time/batch = 0.6296s	
3932/33650 (epoch 5.842), train_loss = 1.32914110, grad/param norm = 1.7569e-01, time/batch = 0.6265s	
3933/33650 (epoch 5.844), train_loss = 1.63787247, grad/param norm = 1.8984e-01, time/batch = 0.6359s	
3934/33650 (epoch 5.845), train_loss = 1.25241107, grad/param norm = 1.6057e-01, time/batch = 0.6271s	
3935/33650 (epoch 5.847), train_loss = 1.19715329, grad/param norm = 1.5532e-01, time/batch = 0.6254s	
3936/33650 (epoch 5.848), train_loss = 1.27501619, grad/param norm = 1.8286e-01, time/batch = 0.6256s	
3937/33650 (epoch 5.850), train_loss = 1.47470798, grad/param norm = 1.9145e-01, time/batch = 0.6246s	
3938/33650 (epoch 5.851), train_loss = 1.15095757, grad/param norm = 1.4518e-01, time/batch = 0.6275s	
3939/33650 (epoch 5.853), train_loss = 1.41283552, grad/param norm = 1.6089e-01, time/batch = 0.6375s	
3940/33650 (epoch 5.854), train_loss = 1.58837539, grad/param norm = 2.1797e-01, time/batch = 0.6662s	
3941/33650 (epoch 5.856), train_loss = 1.07545766, grad/param norm = 1.6143e-01, time/batch = 0.6344s	
3942/33650 (epoch 5.857), train_loss = 1.34069325, grad/param norm = 1.5553e-01, time/batch = 0.6266s	
3943/33650 (epoch 5.859), train_loss = 1.25114969, grad/param norm = 1.5300e-01, time/batch = 0.6280s	
3944/33650 (epoch 5.860), train_loss = 1.15870376, grad/param norm = 1.6756e-01, time/batch = 0.6258s	
3945/33650 (epoch 5.862), train_loss = 1.22142284, grad/param norm = 1.6477e-01, time/batch = 0.6262s	
3946/33650 (epoch 5.863), train_loss = 1.48236091, grad/param norm = 1.7569e-01, time/batch = 0.6269s	
3947/33650 (epoch 5.865), train_loss = 1.27401227, grad/param norm = 1.6671e-01, time/batch = 0.6302s	
3948/33650 (epoch 5.866), train_loss = 1.29535844, grad/param norm = 1.7759e-01, time/batch = 0.6304s	
3949/33650 (epoch 5.868), train_loss = 1.24453243, grad/param norm = 1.7123e-01, time/batch = 0.6261s	
3950/33650 (epoch 5.869), train_loss = 1.49378339, grad/param norm = 1.7897e-01, time/batch = 0.6254s	
3951/33650 (epoch 5.871), train_loss = 1.20605816, grad/param norm = 1.6039e-01, time/batch = 0.6280s	
3952/33650 (epoch 5.872), train_loss = 1.36094572, grad/param norm = 1.8324e-01, time/batch = 0.6267s	
3953/33650 (epoch 5.874), train_loss = 1.48550143, grad/param norm = 1.7792e-01, time/batch = 0.6279s	
3954/33650 (epoch 5.875), train_loss = 1.28538076, grad/param norm = 1.6866e-01, time/batch = 0.6265s	
3955/33650 (epoch 5.877), train_loss = 1.50078952, grad/param norm = 1.7299e-01, time/batch = 0.6291s	
3956/33650 (epoch 5.878), train_loss = 1.00968384, grad/param norm = 1.5242e-01, time/batch = 0.6519s	
3957/33650 (epoch 5.880), train_loss = 1.36754605, grad/param norm = 1.8237e-01, time/batch = 0.6271s	
3958/33650 (epoch 5.881), train_loss = 1.27869774, grad/param norm = 1.6198e-01, time/batch = 0.6252s	
3959/33650 (epoch 5.883), train_loss = 1.37303257, grad/param norm = 1.7499e-01, time/batch = 0.6257s	
3960/33650 (epoch 5.884), train_loss = 1.48520762, grad/param norm = 1.8198e-01, time/batch = 0.6574s	
3961/33650 (epoch 5.886), train_loss = 1.50315258, grad/param norm = 1.8312e-01, time/batch = 0.6565s	
3962/33650 (epoch 5.887), train_loss = 1.29429070, grad/param norm = 1.6186e-01, time/batch = 0.6298s	
3963/33650 (epoch 5.889), train_loss = 1.48413223, grad/param norm = 1.7284e-01, time/batch = 0.6285s	
3964/33650 (epoch 5.890), train_loss = 1.46979387, grad/param norm = 1.6327e-01, time/batch = 0.6245s	
3965/33650 (epoch 5.892), train_loss = 1.44869397, grad/param norm = 1.8773e-01, time/batch = 0.6248s	
3966/33650 (epoch 5.893), train_loss = 1.46630450, grad/param norm = 1.7744e-01, time/batch = 0.6256s	
3967/33650 (epoch 5.895), train_loss = 1.50246244, grad/param norm = 1.8420e-01, time/batch = 0.6241s	
3968/33650 (epoch 5.896), train_loss = 1.27226604, grad/param norm = 1.6668e-01, time/batch = 0.6259s	
3969/33650 (epoch 5.897), train_loss = 1.29293335, grad/param norm = 1.6024e-01, time/batch = 0.6257s	
3970/33650 (epoch 5.899), train_loss = 1.28480102, grad/param norm = 1.6193e-01, time/batch = 0.6294s	
3971/33650 (epoch 5.900), train_loss = 1.13005008, grad/param norm = 1.5155e-01, time/batch = 0.6400s	
3972/33650 (epoch 5.902), train_loss = 1.37630506, grad/param norm = 1.6227e-01, time/batch = 0.6387s	
3973/33650 (epoch 5.903), train_loss = 1.34767384, grad/param norm = 1.9500e-01, time/batch = 0.6350s	
3974/33650 (epoch 5.905), train_loss = 1.65744216, grad/param norm = 2.0554e-01, time/batch = 0.6587s	
3975/33650 (epoch 5.906), train_loss = 1.33825473, grad/param norm = 1.7070e-01, time/batch = 0.6309s	
3976/33650 (epoch 5.908), train_loss = 1.31138660, grad/param norm = 1.5740e-01, time/batch = 0.6309s	
3977/33650 (epoch 5.909), train_loss = 1.32613682, grad/param norm = 1.5030e-01, time/batch = 0.6279s	
3978/33650 (epoch 5.911), train_loss = 1.22466185, grad/param norm = 1.5950e-01, time/batch = 0.6326s	
3979/33650 (epoch 5.912), train_loss = 1.23829317, grad/param norm = 1.6232e-01, time/batch = 0.6303s	
3980/33650 (epoch 5.914), train_loss = 1.36318592, grad/param norm = 1.5950e-01, time/batch = 0.6412s	
3981/33650 (epoch 5.915), train_loss = 1.47769222, grad/param norm = 1.9498e-01, time/batch = 0.6688s	
3982/33650 (epoch 5.917), train_loss = 1.38302881, grad/param norm = 1.7917e-01, time/batch = 0.6378s	
3983/33650 (epoch 5.918), train_loss = 1.11186253, grad/param norm = 1.4002e-01, time/batch = 0.6280s	
3984/33650 (epoch 5.920), train_loss = 1.28394346, grad/param norm = 1.5411e-01, time/batch = 0.6306s	
3985/33650 (epoch 5.921), train_loss = 1.24304188, grad/param norm = 1.6624e-01, time/batch = 0.6370s	
3986/33650 (epoch 5.923), train_loss = 1.24531804, grad/param norm = 1.6572e-01, time/batch = 0.6285s	
3987/33650 (epoch 5.924), train_loss = 1.44912463, grad/param norm = 1.7712e-01, time/batch = 0.6285s	
3988/33650 (epoch 5.926), train_loss = 1.43884824, grad/param norm = 1.9548e-01, time/batch = 0.6260s	
3989/33650 (epoch 5.927), train_loss = 1.34042049, grad/param norm = 1.7216e-01, time/batch = 0.6253s	
3990/33650 (epoch 5.929), train_loss = 1.35491336, grad/param norm = 1.7134e-01, time/batch = 0.6257s	
3991/33650 (epoch 5.930), train_loss = 1.33813413, grad/param norm = 1.6819e-01, time/batch = 0.6275s	
3992/33650 (epoch 5.932), train_loss = 1.35327019, grad/param norm = 1.6230e-01, time/batch = 0.6320s	
3993/33650 (epoch 5.933), train_loss = 1.22342771, grad/param norm = 1.6129e-01, time/batch = 0.6331s	
3994/33650 (epoch 5.935), train_loss = 1.26683953, grad/param norm = 1.6703e-01, time/batch = 0.6258s	
3995/33650 (epoch 5.936), train_loss = 1.25500725, grad/param norm = 1.5394e-01, time/batch = 0.6271s	
3996/33650 (epoch 5.938), train_loss = 1.17775676, grad/param norm = 1.5622e-01, time/batch = 0.6259s	
3997/33650 (epoch 5.939), train_loss = 1.40255091, grad/param norm = 1.5885e-01, time/batch = 0.6248s	
3998/33650 (epoch 5.941), train_loss = 1.39924044, grad/param norm = 1.8034e-01, time/batch = 0.6252s	
3999/33650 (epoch 5.942), train_loss = 1.45509110, grad/param norm = 1.6996e-01, time/batch = 0.6271s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch5.94_1.5775.t7	
4000/33650 (epoch 5.944), train_loss = 1.38400137, grad/param norm = 1.5992e-01, time/batch = 0.6281s	
4001/33650 (epoch 5.945), train_loss = 1.61280609, grad/param norm = 1.8732e-01, time/batch = 0.6390s	
4002/33650 (epoch 5.947), train_loss = 1.64904706, grad/param norm = 1.9565e-01, time/batch = 0.6327s	
4003/33650 (epoch 5.948), train_loss = 1.50998735, grad/param norm = 1.8223e-01, time/batch = 0.6288s	
4004/33650 (epoch 5.949), train_loss = 1.27221385, grad/param norm = 1.8027e-01, time/batch = 0.6302s	
4005/33650 (epoch 5.951), train_loss = 1.48671935, grad/param norm = 1.7379e-01, time/batch = 0.6356s	
4006/33650 (epoch 5.952), train_loss = 1.51706659, grad/param norm = 1.8133e-01, time/batch = 0.6307s	
4007/33650 (epoch 5.954), train_loss = 1.47251039, grad/param norm = 1.7725e-01, time/batch = 0.6318s	
4008/33650 (epoch 5.955), train_loss = 1.50094592, grad/param norm = 1.8072e-01, time/batch = 0.6348s	
4009/33650 (epoch 5.957), train_loss = 1.45538163, grad/param norm = 1.7709e-01, time/batch = 0.6425s	
4010/33650 (epoch 5.958), train_loss = 1.04021631, grad/param norm = 1.4544e-01, time/batch = 0.6406s	
4011/33650 (epoch 5.960), train_loss = 1.19763545, grad/param norm = 1.4469e-01, time/batch = 0.6667s	
4012/33650 (epoch 5.961), train_loss = 1.28758137, grad/param norm = 1.5636e-01, time/batch = 0.6697s	
4013/33650 (epoch 5.963), train_loss = 1.32196290, grad/param norm = 1.6885e-01, time/batch = 0.6444s	
4014/33650 (epoch 5.964), train_loss = 1.37258252, grad/param norm = 1.7368e-01, time/batch = 0.6413s	
4015/33650 (epoch 5.966), train_loss = 1.36907615, grad/param norm = 1.7805e-01, time/batch = 0.6341s	
4016/33650 (epoch 5.967), train_loss = 1.43412261, grad/param norm = 1.7999e-01, time/batch = 0.6303s	
4017/33650 (epoch 5.969), train_loss = 1.29546808, grad/param norm = 1.5566e-01, time/batch = 0.6307s	
4018/33650 (epoch 5.970), train_loss = 1.41420278, grad/param norm = 1.7174e-01, time/batch = 0.6334s	
4019/33650 (epoch 5.972), train_loss = 1.67379627, grad/param norm = 1.8100e-01, time/batch = 0.6361s	
4020/33650 (epoch 5.973), train_loss = 1.22443559, grad/param norm = 1.5083e-01, time/batch = 0.6475s	
4021/33650 (epoch 5.975), train_loss = 1.27551346, grad/param norm = 1.7034e-01, time/batch = 0.6305s	
4022/33650 (epoch 5.976), train_loss = 1.21707562, grad/param norm = 1.5167e-01, time/batch = 0.6290s	
4023/33650 (epoch 5.978), train_loss = 1.27995658, grad/param norm = 1.7289e-01, time/batch = 0.6282s	
4024/33650 (epoch 5.979), train_loss = 1.40431235, grad/param norm = 1.7894e-01, time/batch = 0.6283s	
4025/33650 (epoch 5.981), train_loss = 1.29521901, grad/param norm = 1.4184e-01, time/batch = 0.6293s	
4026/33650 (epoch 5.982), train_loss = 1.42175508, grad/param norm = 1.9423e-01, time/batch = 0.6297s	
4027/33650 (epoch 5.984), train_loss = 1.20888106, grad/param norm = 1.5843e-01, time/batch = 0.6302s	
4028/33650 (epoch 5.985), train_loss = 1.22598922, grad/param norm = 1.4946e-01, time/batch = 0.6258s	
4029/33650 (epoch 5.987), train_loss = 1.31729732, grad/param norm = 1.7112e-01, time/batch = 0.6271s	
4030/33650 (epoch 5.988), train_loss = 1.44281564, grad/param norm = 1.6871e-01, time/batch = 0.6278s	
4031/33650 (epoch 5.990), train_loss = 1.61677211, grad/param norm = 2.0471e-01, time/batch = 0.6347s	
4032/33650 (epoch 5.991), train_loss = 1.48134321, grad/param norm = 1.7974e-01, time/batch = 0.6665s	
4033/33650 (epoch 5.993), train_loss = 1.44017130, grad/param norm = 1.8044e-01, time/batch = 0.6443s	
4034/33650 (epoch 5.994), train_loss = 1.31583911, grad/param norm = 1.6750e-01, time/batch = 0.6301s	
4035/33650 (epoch 5.996), train_loss = 1.28119544, grad/param norm = 1.6322e-01, time/batch = 0.6279s	
4036/33650 (epoch 5.997), train_loss = 1.41911751, grad/param norm = 1.8836e-01, time/batch = 0.6282s	
4037/33650 (epoch 5.999), train_loss = 1.19683059, grad/param norm = 1.6068e-01, time/batch = 0.6267s	
4038/33650 (epoch 6.000), train_loss = 1.48722827, grad/param norm = 1.7803e-01, time/batch = 0.6281s	
4039/33650 (epoch 6.001), train_loss = 1.52568371, grad/param norm = 1.9047e-01, time/batch = 0.6301s	
4040/33650 (epoch 6.003), train_loss = 1.64405033, grad/param norm = 1.9827e-01, time/batch = 0.6318s	
4041/33650 (epoch 6.004), train_loss = 1.45873589, grad/param norm = 1.8208e-01, time/batch = 0.6432s	
4042/33650 (epoch 6.006), train_loss = 1.29240372, grad/param norm = 1.6267e-01, time/batch = 0.6288s	
4043/33650 (epoch 6.007), train_loss = 1.37239106, grad/param norm = 1.8344e-01, time/batch = 0.6287s	
4044/33650 (epoch 6.009), train_loss = 1.33702205, grad/param norm = 1.6247e-01, time/batch = 0.6288s	
4045/33650 (epoch 6.010), train_loss = 1.44823159, grad/param norm = 1.7482e-01, time/batch = 0.6284s	
4046/33650 (epoch 6.012), train_loss = 1.31257510, grad/param norm = 1.7260e-01, time/batch = 0.6279s	
4047/33650 (epoch 6.013), train_loss = 1.43065817, grad/param norm = 1.7359e-01, time/batch = 0.6311s	
4048/33650 (epoch 6.015), train_loss = 1.24148649, grad/param norm = 1.6662e-01, time/batch = 0.6333s	
4049/33650 (epoch 6.016), train_loss = 1.31422311, grad/param norm = 1.8638e-01, time/batch = 0.6293s	
4050/33650 (epoch 6.018), train_loss = 1.36768512, grad/param norm = 1.7723e-01, time/batch = 0.6277s	
4051/33650 (epoch 6.019), train_loss = 1.25620010, grad/param norm = 1.6941e-01, time/batch = 0.6293s	
4052/33650 (epoch 6.021), train_loss = 1.47627839, grad/param norm = 1.7817e-01, time/batch = 0.6540s	
4053/33650 (epoch 6.022), train_loss = 1.32963090, grad/param norm = 1.7668e-01, time/batch = 0.6607s	
4054/33650 (epoch 6.024), train_loss = 1.24040749, grad/param norm = 1.6790e-01, time/batch = 0.6332s	
4055/33650 (epoch 6.025), train_loss = 1.30650302, grad/param norm = 1.6860e-01, time/batch = 0.6370s	
4056/33650 (epoch 6.027), train_loss = 1.49756316, grad/param norm = 1.8188e-01, time/batch = 0.6482s	
4057/33650 (epoch 6.028), train_loss = 1.46549552, grad/param norm = 1.8245e-01, time/batch = 0.6336s	
4058/33650 (epoch 6.030), train_loss = 1.35185923, grad/param norm = 1.5696e-01, time/batch = 0.6534s	
4059/33650 (epoch 6.031), train_loss = 1.11101955, grad/param norm = 1.4667e-01, time/batch = 0.6571s	
4060/33650 (epoch 6.033), train_loss = 1.27884745, grad/param norm = 1.4701e-01, time/batch = 0.6315s	
4061/33650 (epoch 6.034), train_loss = 1.35972127, grad/param norm = 1.7082e-01, time/batch = 0.6324s	
4062/33650 (epoch 6.036), train_loss = 1.53695743, grad/param norm = 1.9399e-01, time/batch = 0.6317s	
4063/33650 (epoch 6.037), train_loss = 1.24649035, grad/param norm = 1.8726e-01, time/batch = 0.6313s	
4064/33650 (epoch 6.039), train_loss = 1.50407711, grad/param norm = 1.7196e-01, time/batch = 0.6392s	
4065/33650 (epoch 6.040), train_loss = 1.54965596, grad/param norm = 1.9835e-01, time/batch = 0.6338s	
4066/33650 (epoch 6.042), train_loss = 1.58428318, grad/param norm = 1.8667e-01, time/batch = 0.6300s	
4067/33650 (epoch 6.043), train_loss = 1.24521830, grad/param norm = 1.6450e-01, time/batch = 0.6282s	
4068/33650 (epoch 6.045), train_loss = 1.28000896, grad/param norm = 1.6379e-01, time/batch = 0.6277s	
4069/33650 (epoch 6.046), train_loss = 1.46895474, grad/param norm = 1.6051e-01, time/batch = 0.6287s	
4070/33650 (epoch 6.048), train_loss = 1.45032593, grad/param norm = 1.8038e-01, time/batch = 0.6273s	
4071/33650 (epoch 6.049), train_loss = 1.44748772, grad/param norm = 1.8789e-01, time/batch = 0.6355s	
4072/33650 (epoch 6.051), train_loss = 1.45908840, grad/param norm = 1.6846e-01, time/batch = 0.6448s	
4073/33650 (epoch 6.052), train_loss = 1.56639283, grad/param norm = 1.8538e-01, time/batch = 0.6665s	
4074/33650 (epoch 6.053), train_loss = 1.37940695, grad/param norm = 1.6373e-01, time/batch = 0.6324s	
4075/33650 (epoch 6.055), train_loss = 1.19644888, grad/param norm = 1.7518e-01, time/batch = 0.6274s	
4076/33650 (epoch 6.056), train_loss = 1.18578965, grad/param norm = 1.5538e-01, time/batch = 0.6261s	
4077/33650 (epoch 6.058), train_loss = 1.50375996, grad/param norm = 1.8832e-01, time/batch = 0.6287s	
4078/33650 (epoch 6.059), train_loss = 1.46593525, grad/param norm = 1.7462e-01, time/batch = 0.6314s	
4079/33650 (epoch 6.061), train_loss = 1.43254917, grad/param norm = 1.5745e-01, time/batch = 0.6252s	
4080/33650 (epoch 6.062), train_loss = 1.38788707, grad/param norm = 1.6258e-01, time/batch = 0.6267s	
4081/33650 (epoch 6.064), train_loss = 1.30732514, grad/param norm = 1.6385e-01, time/batch = 0.6283s	
4082/33650 (epoch 6.065), train_loss = 1.31399378, grad/param norm = 1.6397e-01, time/batch = 0.6272s	
4083/33650 (epoch 6.067), train_loss = 1.21269915, grad/param norm = 1.6222e-01, time/batch = 0.6294s	
4084/33650 (epoch 6.068), train_loss = 1.40548081, grad/param norm = 1.7348e-01, time/batch = 0.6290s	
4085/33650 (epoch 6.070), train_loss = 1.34063173, grad/param norm = 1.7067e-01, time/batch = 0.6315s	
4086/33650 (epoch 6.071), train_loss = 1.36400656, grad/param norm = 1.6488e-01, time/batch = 0.6265s	
4087/33650 (epoch 6.073), train_loss = 1.45446820, grad/param norm = 1.7419e-01, time/batch = 0.6292s	
4088/33650 (epoch 6.074), train_loss = 1.48204847, grad/param norm = 1.7685e-01, time/batch = 0.6279s	
4089/33650 (epoch 6.076), train_loss = 1.52851284, grad/param norm = 1.8358e-01, time/batch = 0.6272s	
4090/33650 (epoch 6.077), train_loss = 1.30133680, grad/param norm = 1.6148e-01, time/batch = 0.6260s	
4091/33650 (epoch 6.079), train_loss = 1.33052730, grad/param norm = 1.7956e-01, time/batch = 0.6297s	
4092/33650 (epoch 6.080), train_loss = 1.42326593, grad/param norm = 1.8056e-01, time/batch = 0.6287s	
4093/33650 (epoch 6.082), train_loss = 1.51198689, grad/param norm = 1.9173e-01, time/batch = 0.6608s	
4094/33650 (epoch 6.083), train_loss = 1.42162020, grad/param norm = 1.7010e-01, time/batch = 0.6515s	
4095/33650 (epoch 6.085), train_loss = 1.44742895, grad/param norm = 1.6696e-01, time/batch = 0.6270s	
4096/33650 (epoch 6.086), train_loss = 1.47269935, grad/param norm = 2.0154e-01, time/batch = 0.6260s	
4097/33650 (epoch 6.088), train_loss = 1.41579176, grad/param norm = 1.6692e-01, time/batch = 0.6281s	
4098/33650 (epoch 6.089), train_loss = 1.41590945, grad/param norm = 1.8887e-01, time/batch = 0.6275s	
4099/33650 (epoch 6.091), train_loss = 1.28234047, grad/param norm = 1.7100e-01, time/batch = 0.6332s	
4100/33650 (epoch 6.092), train_loss = 1.29562723, grad/param norm = 1.6378e-01, time/batch = 0.6489s	
4101/33650 (epoch 6.094), train_loss = 1.40166057, grad/param norm = 1.5731e-01, time/batch = 0.6335s	
4102/33650 (epoch 6.095), train_loss = 1.44736991, grad/param norm = 1.8520e-01, time/batch = 0.6282s	
4103/33650 (epoch 6.097), train_loss = 1.36379083, grad/param norm = 1.8382e-01, time/batch = 0.6276s	
4104/33650 (epoch 6.098), train_loss = 1.12030526, grad/param norm = 1.5283e-01, time/batch = 0.6276s	
4105/33650 (epoch 6.100), train_loss = 1.24681963, grad/param norm = 1.5826e-01, time/batch = 0.6252s	
4106/33650 (epoch 6.101), train_loss = 1.28836999, grad/param norm = 1.6642e-01, time/batch = 0.6305s	
4107/33650 (epoch 6.103), train_loss = 1.25906972, grad/param norm = 1.5883e-01, time/batch = 0.6306s	
4108/33650 (epoch 6.104), train_loss = 1.41160578, grad/param norm = 1.7110e-01, time/batch = 0.6359s	
4109/33650 (epoch 6.105), train_loss = 1.37779576, grad/param norm = 1.8635e-01, time/batch = 0.6674s	
4110/33650 (epoch 6.107), train_loss = 1.21492363, grad/param norm = 1.6914e-01, time/batch = 0.6427s	
4111/33650 (epoch 6.108), train_loss = 1.42503292, grad/param norm = 1.8220e-01, time/batch = 0.6314s	
4112/33650 (epoch 6.110), train_loss = 1.52932561, grad/param norm = 1.7288e-01, time/batch = 0.6394s	
4113/33650 (epoch 6.111), train_loss = 1.29252446, grad/param norm = 1.8841e-01, time/batch = 0.6420s	
4114/33650 (epoch 6.113), train_loss = 1.29406425, grad/param norm = 1.7059e-01, time/batch = 0.6318s	
4115/33650 (epoch 6.114), train_loss = 1.46641547, grad/param norm = 1.7888e-01, time/batch = 0.6370s	
4116/33650 (epoch 6.116), train_loss = 1.19139381, grad/param norm = 1.6274e-01, time/batch = 0.6296s	
4117/33650 (epoch 6.117), train_loss = 1.35342103, grad/param norm = 1.5642e-01, time/batch = 0.6275s	
4118/33650 (epoch 6.119), train_loss = 1.20515857, grad/param norm = 1.5283e-01, time/batch = 0.6267s	
4119/33650 (epoch 6.120), train_loss = 1.30592953, grad/param norm = 1.9106e-01, time/batch = 0.6274s	
4120/33650 (epoch 6.122), train_loss = 1.19689233, grad/param norm = 1.7411e-01, time/batch = 0.6258s	
4121/33650 (epoch 6.123), train_loss = 1.30315453, grad/param norm = 1.6026e-01, time/batch = 0.6296s	
4122/33650 (epoch 6.125), train_loss = 1.49270768, grad/param norm = 1.8130e-01, time/batch = 0.6290s	
4123/33650 (epoch 6.126), train_loss = 1.58246740, grad/param norm = 1.7333e-01, time/batch = 0.6267s	
4124/33650 (epoch 6.128), train_loss = 1.49272348, grad/param norm = 1.8966e-01, time/batch = 0.6266s	
4125/33650 (epoch 6.129), train_loss = 1.47867509, grad/param norm = 1.6854e-01, time/batch = 0.6256s	
4126/33650 (epoch 6.131), train_loss = 1.43369164, grad/param norm = 1.8018e-01, time/batch = 0.6288s	
4127/33650 (epoch 6.132), train_loss = 1.36403845, grad/param norm = 1.6373e-01, time/batch = 0.6252s	
4128/33650 (epoch 6.134), train_loss = 1.55386100, grad/param norm = 1.7332e-01, time/batch = 0.6258s	
4129/33650 (epoch 6.135), train_loss = 1.24653307, grad/param norm = 1.8416e-01, time/batch = 0.6518s	
4130/33650 (epoch 6.137), train_loss = 1.34149989, grad/param norm = 1.6748e-01, time/batch = 0.6311s	
4131/33650 (epoch 6.138), train_loss = 1.41968569, grad/param norm = 1.7507e-01, time/batch = 0.6301s	
4132/33650 (epoch 6.140), train_loss = 1.44049461, grad/param norm = 1.8784e-01, time/batch = 0.6272s	
4133/33650 (epoch 6.141), train_loss = 1.52526908, grad/param norm = 1.8196e-01, time/batch = 0.6267s	
4134/33650 (epoch 6.143), train_loss = 1.66098828, grad/param norm = 1.9363e-01, time/batch = 0.6264s	
4135/33650 (epoch 6.144), train_loss = 1.56243449, grad/param norm = 1.8305e-01, time/batch = 0.6287s	
4136/33650 (epoch 6.146), train_loss = 1.37167546, grad/param norm = 1.7711e-01, time/batch = 0.6278s	
4137/33650 (epoch 6.147), train_loss = 1.31905390, grad/param norm = 1.7414e-01, time/batch = 0.6273s	
4138/33650 (epoch 6.149), train_loss = 1.22070473, grad/param norm = 1.6910e-01, time/batch = 0.6270s	
4139/33650 (epoch 6.150), train_loss = 1.22766752, grad/param norm = 1.5114e-01, time/batch = 0.6292s	
4140/33650 (epoch 6.152), train_loss = 1.29329972, grad/param norm = 1.5990e-01, time/batch = 0.6260s	
4141/33650 (epoch 6.153), train_loss = 1.33063711, grad/param norm = 1.6021e-01, time/batch = 0.6297s	
4142/33650 (epoch 6.155), train_loss = 1.24076684, grad/param norm = 1.4671e-01, time/batch = 0.6296s	
4143/33650 (epoch 6.156), train_loss = 1.25500552, grad/param norm = 1.5251e-01, time/batch = 0.6298s	
4144/33650 (epoch 6.158), train_loss = 1.38046209, grad/param norm = 1.8018e-01, time/batch = 0.6257s	
4145/33650 (epoch 6.159), train_loss = 1.14803074, grad/param norm = 1.4047e-01, time/batch = 0.6275s	
4146/33650 (epoch 6.160), train_loss = 1.20974149, grad/param norm = 1.4093e-01, time/batch = 0.6268s	
4147/33650 (epoch 6.162), train_loss = 1.34175537, grad/param norm = 1.8067e-01, time/batch = 0.6276s	
4148/33650 (epoch 6.163), train_loss = 1.47978578, grad/param norm = 1.7942e-01, time/batch = 0.6275s	
4149/33650 (epoch 6.165), train_loss = 1.21817425, grad/param norm = 1.5235e-01, time/batch = 0.6333s	
4150/33650 (epoch 6.166), train_loss = 1.23389481, grad/param norm = 1.6128e-01, time/batch = 0.6407s	
4151/33650 (epoch 6.168), train_loss = 1.48153059, grad/param norm = 1.6564e-01, time/batch = 0.6509s	
4152/33650 (epoch 6.169), train_loss = 1.30657006, grad/param norm = 1.6251e-01, time/batch = 0.6373s	
4153/33650 (epoch 6.171), train_loss = 1.38354979, grad/param norm = 1.8362e-01, time/batch = 0.6686s	
4154/33650 (epoch 6.172), train_loss = 1.30417530, grad/param norm = 1.6191e-01, time/batch = 0.6327s	
4155/33650 (epoch 6.174), train_loss = 1.24231684, grad/param norm = 1.6727e-01, time/batch = 0.6328s	
4156/33650 (epoch 6.175), train_loss = 1.24262834, grad/param norm = 1.6925e-01, time/batch = 0.6316s	
4157/33650 (epoch 6.177), train_loss = 1.38616610, grad/param norm = 1.5759e-01, time/batch = 0.6325s	
4158/33650 (epoch 6.178), train_loss = 1.25027826, grad/param norm = 1.5850e-01, time/batch = 0.6339s	
4159/33650 (epoch 6.180), train_loss = 1.25828824, grad/param norm = 1.7114e-01, time/batch = 0.6274s	
4160/33650 (epoch 6.181), train_loss = 1.06764513, grad/param norm = 1.4649e-01, time/batch = 0.6264s	
4161/33650 (epoch 6.183), train_loss = 1.28642079, grad/param norm = 1.7772e-01, time/batch = 0.6498s	
4162/33650 (epoch 6.184), train_loss = 1.32640157, grad/param norm = 1.7975e-01, time/batch = 0.6474s	
4163/33650 (epoch 6.186), train_loss = 1.37585297, grad/param norm = 1.7687e-01, time/batch = 0.6398s	
4164/33650 (epoch 6.187), train_loss = 1.48059799, grad/param norm = 1.7725e-01, time/batch = 0.6308s	
4165/33650 (epoch 6.189), train_loss = 1.54031883, grad/param norm = 1.9264e-01, time/batch = 0.6517s	
4166/33650 (epoch 6.190), train_loss = 1.41320985, grad/param norm = 1.7819e-01, time/batch = 0.6635s	
4167/33650 (epoch 6.192), train_loss = 1.54451184, grad/param norm = 1.7950e-01, time/batch = 0.6300s	
4168/33650 (epoch 6.193), train_loss = 1.47830810, grad/param norm = 1.7330e-01, time/batch = 0.6274s	
4169/33650 (epoch 6.195), train_loss = 1.20909811, grad/param norm = 1.6258e-01, time/batch = 0.6289s	
4170/33650 (epoch 6.196), train_loss = 1.11364651, grad/param norm = 1.6511e-01, time/batch = 0.6294s	
4171/33650 (epoch 6.198), train_loss = 1.31996239, grad/param norm = 1.7508e-01, time/batch = 0.6305s	
4172/33650 (epoch 6.199), train_loss = 1.45723883, grad/param norm = 1.8352e-01, time/batch = 0.6345s	
4173/33650 (epoch 6.201), train_loss = 1.37485666, grad/param norm = 1.7617e-01, time/batch = 0.6273s	
4174/33650 (epoch 6.202), train_loss = 1.32395017, grad/param norm = 1.7548e-01, time/batch = 0.6307s	
4175/33650 (epoch 6.204), train_loss = 1.40045188, grad/param norm = 1.6584e-01, time/batch = 0.6339s	
4176/33650 (epoch 6.205), train_loss = 1.28668284, grad/param norm = 1.8234e-01, time/batch = 0.6313s	
4177/33650 (epoch 6.207), train_loss = 1.35438807, grad/param norm = 1.6481e-01, time/batch = 0.6296s	
4178/33650 (epoch 6.208), train_loss = 1.29785140, grad/param norm = 1.6859e-01, time/batch = 0.6299s	
4179/33650 (epoch 6.210), train_loss = 1.05655248, grad/param norm = 1.6075e-01, time/batch = 0.6334s	
4180/33650 (epoch 6.211), train_loss = 1.26589983, grad/param norm = 1.7797e-01, time/batch = 0.6407s	
4181/33650 (epoch 6.212), train_loss = 1.43700321, grad/param norm = 1.7942e-01, time/batch = 0.6464s	
4182/33650 (epoch 6.214), train_loss = 1.50339341, grad/param norm = 1.7639e-01, time/batch = 0.6295s	
4183/33650 (epoch 6.215), train_loss = 1.10455038, grad/param norm = 1.5022e-01, time/batch = 0.6272s	
4184/33650 (epoch 6.217), train_loss = 1.34684051, grad/param norm = 1.7546e-01, time/batch = 0.6273s	
4185/33650 (epoch 6.218), train_loss = 1.43160285, grad/param norm = 1.6748e-01, time/batch = 0.6273s	
4186/33650 (epoch 6.220), train_loss = 1.26267229, grad/param norm = 1.8091e-01, time/batch = 0.6349s	
4187/33650 (epoch 6.221), train_loss = 1.52090132, grad/param norm = 1.7749e-01, time/batch = 0.6261s	
4188/33650 (epoch 6.223), train_loss = 1.05845983, grad/param norm = 1.4923e-01, time/batch = 0.6261s	
4189/33650 (epoch 6.224), train_loss = 1.33536901, grad/param norm = 1.8254e-01, time/batch = 0.6266s	
4190/33650 (epoch 6.226), train_loss = 1.73566152, grad/param norm = 2.1433e-01, time/batch = 0.6436s	
4191/33650 (epoch 6.227), train_loss = 1.49970343, grad/param norm = 1.7490e-01, time/batch = 0.6684s	
4192/33650 (epoch 6.229), train_loss = 1.46173687, grad/param norm = 1.7761e-01, time/batch = 0.6296s	
4193/33650 (epoch 6.230), train_loss = 1.59942566, grad/param norm = 2.0618e-01, time/batch = 0.6324s	
4194/33650 (epoch 6.232), train_loss = 1.42488846, grad/param norm = 1.8331e-01, time/batch = 0.6434s	
4195/33650 (epoch 6.233), train_loss = 1.41956341, grad/param norm = 1.8951e-01, time/batch = 0.6391s	
4196/33650 (epoch 6.235), train_loss = 1.32299390, grad/param norm = 1.6436e-01, time/batch = 0.6309s	
4197/33650 (epoch 6.236), train_loss = 1.19846200, grad/param norm = 1.6930e-01, time/batch = 0.6404s	
4198/33650 (epoch 6.238), train_loss = 1.31191994, grad/param norm = 1.5401e-01, time/batch = 0.6296s	
4199/33650 (epoch 6.239), train_loss = 1.22726819, grad/param norm = 1.6248e-01, time/batch = 0.6401s	
4200/33650 (epoch 6.241), train_loss = 1.28877389, grad/param norm = 1.5814e-01, time/batch = 0.6445s	
4201/33650 (epoch 6.242), train_loss = 1.15188883, grad/param norm = 1.5099e-01, time/batch = 0.6411s	
4202/33650 (epoch 6.244), train_loss = 1.34068427, grad/param norm = 1.5681e-01, time/batch = 0.6355s	
4203/33650 (epoch 6.245), train_loss = 1.17887306, grad/param norm = 1.5742e-01, time/batch = 0.6365s	
4204/33650 (epoch 6.247), train_loss = 1.31501441, grad/param norm = 1.6966e-01, time/batch = 0.6315s	
4205/33650 (epoch 6.248), train_loss = 1.29142663, grad/param norm = 1.7473e-01, time/batch = 0.6306s	
4206/33650 (epoch 6.250), train_loss = 1.36295943, grad/param norm = 1.6319e-01, time/batch = 0.6329s	
4207/33650 (epoch 6.251), train_loss = 1.50105230, grad/param norm = 1.6780e-01, time/batch = 0.6309s	
4208/33650 (epoch 6.253), train_loss = 1.18526370, grad/param norm = 1.5798e-01, time/batch = 0.6358s	
4209/33650 (epoch 6.254), train_loss = 1.21644470, grad/param norm = 1.5878e-01, time/batch = 0.6296s	
4210/33650 (epoch 6.256), train_loss = 1.40566084, grad/param norm = 1.6686e-01, time/batch = 0.6349s	
4211/33650 (epoch 6.257), train_loss = 1.57516608, grad/param norm = 1.8359e-01, time/batch = 0.6684s	
4212/33650 (epoch 6.259), train_loss = 1.12028678, grad/param norm = 1.5295e-01, time/batch = 0.6448s	
4213/33650 (epoch 6.260), train_loss = 1.52162503, grad/param norm = 1.8680e-01, time/batch = 0.6311s	
4214/33650 (epoch 6.262), train_loss = 1.42072391, grad/param norm = 1.7686e-01, time/batch = 0.6361s	
4215/33650 (epoch 6.263), train_loss = 1.38464788, grad/param norm = 2.0467e-01, time/batch = 0.6280s	
4216/33650 (epoch 6.264), train_loss = 1.35034804, grad/param norm = 1.7099e-01, time/batch = 0.6378s	
4217/33650 (epoch 6.266), train_loss = 1.30850918, grad/param norm = 1.7133e-01, time/batch = 0.6302s	
4218/33650 (epoch 6.267), train_loss = 1.29077131, grad/param norm = 1.8552e-01, time/batch = 0.6280s	
4219/33650 (epoch 6.269), train_loss = 1.42881857, grad/param norm = 1.6987e-01, time/batch = 0.6284s	
4220/33650 (epoch 6.270), train_loss = 1.26145473, grad/param norm = 1.5755e-01, time/batch = 0.6281s	
4221/33650 (epoch 6.272), train_loss = 1.34203844, grad/param norm = 1.5824e-01, time/batch = 0.6299s	
4222/33650 (epoch 6.273), train_loss = 1.55642630, grad/param norm = 1.9510e-01, time/batch = 0.6309s	
4223/33650 (epoch 6.275), train_loss = 1.46947545, grad/param norm = 1.8778e-01, time/batch = 0.6302s	
4224/33650 (epoch 6.276), train_loss = 1.51352501, grad/param norm = 1.8570e-01, time/batch = 0.6295s	
4225/33650 (epoch 6.278), train_loss = 1.64355421, grad/param norm = 2.0333e-01, time/batch = 0.6300s	
4226/33650 (epoch 6.279), train_loss = 1.27636850, grad/param norm = 1.8487e-01, time/batch = 0.6462s	
4227/33650 (epoch 6.281), train_loss = 1.40196851, grad/param norm = 1.9284e-01, time/batch = 0.6660s	
4228/33650 (epoch 6.282), train_loss = 1.45638085, grad/param norm = 1.6551e-01, time/batch = 0.6294s	
4229/33650 (epoch 6.284), train_loss = 1.48464076, grad/param norm = 1.7989e-01, time/batch = 0.6285s	
4230/33650 (epoch 6.285), train_loss = 1.48070601, grad/param norm = 1.7853e-01, time/batch = 0.6281s	
4231/33650 (epoch 6.287), train_loss = 1.33607503, grad/param norm = 1.7489e-01, time/batch = 0.6300s	
4232/33650 (epoch 6.288), train_loss = 1.40959163, grad/param norm = 1.9011e-01, time/batch = 0.6331s	
4233/33650 (epoch 6.290), train_loss = 1.34965332, grad/param norm = 1.5583e-01, time/batch = 0.6313s	
4234/33650 (epoch 6.291), train_loss = 1.21158078, grad/param norm = 1.4529e-01, time/batch = 0.6277s	
4235/33650 (epoch 6.293), train_loss = 1.36432806, grad/param norm = 1.8726e-01, time/batch = 0.6260s	
4236/33650 (epoch 6.294), train_loss = 1.20957017, grad/param norm = 1.5666e-01, time/batch = 0.6281s	
4237/33650 (epoch 6.296), train_loss = 1.17956662, grad/param norm = 1.6851e-01, time/batch = 0.6268s	
4238/33650 (epoch 6.297), train_loss = 1.38492057, grad/param norm = 1.7097e-01, time/batch = 0.6259s	
4239/33650 (epoch 6.299), train_loss = 1.22919168, grad/param norm = 1.6187e-01, time/batch = 0.6263s	
4240/33650 (epoch 6.300), train_loss = 1.30275546, grad/param norm = 1.6247e-01, time/batch = 0.6278s	
4241/33650 (epoch 6.302), train_loss = 1.31161496, grad/param norm = 1.5534e-01, time/batch = 0.6284s	
4242/33650 (epoch 6.303), train_loss = 1.34907351, grad/param norm = 1.6067e-01, time/batch = 0.6315s	
4243/33650 (epoch 6.305), train_loss = 1.38531721, grad/param norm = 1.6279e-01, time/batch = 0.6380s	
4244/33650 (epoch 6.306), train_loss = 1.26232695, grad/param norm = 1.4974e-01, time/batch = 0.6444s	
4245/33650 (epoch 6.308), train_loss = 1.28957426, grad/param norm = 1.6655e-01, time/batch = 0.6436s	
4246/33650 (epoch 6.309), train_loss = 1.51504139, grad/param norm = 1.7057e-01, time/batch = 0.6356s	
4247/33650 (epoch 6.311), train_loss = 1.41006375, grad/param norm = 1.6442e-01, time/batch = 0.6511s	
4248/33650 (epoch 6.312), train_loss = 1.30154321, grad/param norm = 1.5517e-01, time/batch = 0.6310s	
4249/33650 (epoch 6.314), train_loss = 1.11717960, grad/param norm = 1.3838e-01, time/batch = 0.6322s	
4250/33650 (epoch 6.315), train_loss = 1.36405788, grad/param norm = 1.6562e-01, time/batch = 0.6315s	
4251/33650 (epoch 6.316), train_loss = 1.34389082, grad/param norm = 1.7950e-01, time/batch = 0.6427s	
4252/33650 (epoch 6.318), train_loss = 1.20904900, grad/param norm = 1.4098e-01, time/batch = 0.6671s	
4253/33650 (epoch 6.319), train_loss = 1.25246995, grad/param norm = 1.5170e-01, time/batch = 0.6354s	
4254/33650 (epoch 6.321), train_loss = 1.30218937, grad/param norm = 1.5784e-01, time/batch = 0.6303s	
4255/33650 (epoch 6.322), train_loss = 1.39370460, grad/param norm = 1.8778e-01, time/batch = 0.6460s	
4256/33650 (epoch 6.324), train_loss = 1.45150681, grad/param norm = 1.9536e-01, time/batch = 0.6289s	
4257/33650 (epoch 6.325), train_loss = 1.39253174, grad/param norm = 1.6957e-01, time/batch = 0.6288s	
4258/33650 (epoch 6.327), train_loss = 1.18075518, grad/param norm = 1.6670e-01, time/batch = 0.6378s	
4259/33650 (epoch 6.328), train_loss = 1.42891816, grad/param norm = 1.7488e-01, time/batch = 0.6320s	
4260/33650 (epoch 6.330), train_loss = 1.22249481, grad/param norm = 1.4999e-01, time/batch = 0.6255s	
4261/33650 (epoch 6.331), train_loss = 1.14604882, grad/param norm = 1.5371e-01, time/batch = 0.6334s	
4262/33650 (epoch 6.333), train_loss = 1.32545796, grad/param norm = 1.6225e-01, time/batch = 0.6384s	
4263/33650 (epoch 6.334), train_loss = 1.34771625, grad/param norm = 1.6706e-01, time/batch = 0.6381s	
4264/33650 (epoch 6.336), train_loss = 1.41245028, grad/param norm = 1.6002e-01, time/batch = 0.6499s	
4265/33650 (epoch 6.337), train_loss = 1.09445430, grad/param norm = 1.4452e-01, time/batch = 0.6442s	
4266/33650 (epoch 6.339), train_loss = 1.30243419, grad/param norm = 1.5850e-01, time/batch = 0.6458s	
4267/33650 (epoch 6.340), train_loss = 1.63138446, grad/param norm = 1.9267e-01, time/batch = 0.6604s	
4268/33650 (epoch 6.342), train_loss = 1.06435979, grad/param norm = 1.4597e-01, time/batch = 0.6675s	
4269/33650 (epoch 6.343), train_loss = 1.42454283, grad/param norm = 2.0135e-01, time/batch = 0.6572s	
4270/33650 (epoch 6.345), train_loss = 1.30772458, grad/param norm = 1.7041e-01, time/batch = 0.6610s	
4271/33650 (epoch 6.346), train_loss = 0.99854806, grad/param norm = 1.6548e-01, time/batch = 0.6555s	
4272/33650 (epoch 6.348), train_loss = 1.18278644, grad/param norm = 1.5894e-01, time/batch = 0.6431s	
4273/33650 (epoch 6.349), train_loss = 1.13097954, grad/param norm = 1.6929e-01, time/batch = 0.6354s	
4274/33650 (epoch 6.351), train_loss = 1.42202009, grad/param norm = 1.7601e-01, time/batch = 0.6327s	
4275/33650 (epoch 6.352), train_loss = 1.27238499, grad/param norm = 1.5430e-01, time/batch = 0.6296s	
4276/33650 (epoch 6.354), train_loss = 1.65615328, grad/param norm = 1.9723e-01, time/batch = 0.6290s	
4277/33650 (epoch 6.355), train_loss = 1.42748747, grad/param norm = 1.7216e-01, time/batch = 0.6261s	
4278/33650 (epoch 6.357), train_loss = 1.12586352, grad/param norm = 1.4414e-01, time/batch = 0.6268s	
4279/33650 (epoch 6.358), train_loss = 1.45213348, grad/param norm = 1.7873e-01, time/batch = 0.6298s	
4280/33650 (epoch 6.360), train_loss = 1.43759502, grad/param norm = 1.6980e-01, time/batch = 0.6285s	
4281/33650 (epoch 6.361), train_loss = 1.33741906, grad/param norm = 1.6574e-01, time/batch = 0.6287s	
4282/33650 (epoch 6.363), train_loss = 1.24447014, grad/param norm = 1.5342e-01, time/batch = 0.6304s	
4283/33650 (epoch 6.364), train_loss = 1.32257996, grad/param norm = 1.5836e-01, time/batch = 0.6426s	
4284/33650 (epoch 6.366), train_loss = 1.36028174, grad/param norm = 1.7689e-01, time/batch = 0.6327s	
4285/33650 (epoch 6.367), train_loss = 1.43109217, grad/param norm = 1.6520e-01, time/batch = 0.6273s	
4286/33650 (epoch 6.368), train_loss = 1.21215709, grad/param norm = 1.7032e-01, time/batch = 0.6271s	
4287/33650 (epoch 6.370), train_loss = 1.36749405, grad/param norm = 1.6139e-01, time/batch = 0.6509s	
4288/33650 (epoch 6.371), train_loss = 1.11113832, grad/param norm = 1.5958e-01, time/batch = 0.6654s	
4289/33650 (epoch 6.373), train_loss = 1.23838765, grad/param norm = 1.5732e-01, time/batch = 0.6260s	
4290/33650 (epoch 6.374), train_loss = 1.11985623, grad/param norm = 1.4233e-01, time/batch = 0.6254s	
4291/33650 (epoch 6.376), train_loss = 1.28453257, grad/param norm = 1.6581e-01, time/batch = 0.6278s	
4292/33650 (epoch 6.377), train_loss = 1.39433617, grad/param norm = 1.7700e-01, time/batch = 0.6278s	
4293/33650 (epoch 6.379), train_loss = 1.34982267, grad/param norm = 1.5125e-01, time/batch = 0.6321s	
4294/33650 (epoch 6.380), train_loss = 1.10917824, grad/param norm = 1.7855e-01, time/batch = 0.6438s	
4295/33650 (epoch 6.382), train_loss = 1.10721258, grad/param norm = 1.4111e-01, time/batch = 0.6446s	
4296/33650 (epoch 6.383), train_loss = 1.26755350, grad/param norm = 1.6254e-01, time/batch = 0.6316s	
4297/33650 (epoch 6.385), train_loss = 1.45866852, grad/param norm = 1.7359e-01, time/batch = 0.6299s	
4298/33650 (epoch 6.386), train_loss = 1.22982447, grad/param norm = 1.5971e-01, time/batch = 0.6278s	
4299/33650 (epoch 6.388), train_loss = 1.29425566, grad/param norm = 1.5587e-01, time/batch = 0.6258s	
4300/33650 (epoch 6.389), train_loss = 1.36831671, grad/param norm = 1.7672e-01, time/batch = 0.6346s	
4301/33650 (epoch 6.391), train_loss = 1.11638127, grad/param norm = 1.4121e-01, time/batch = 0.6280s	
4302/33650 (epoch 6.392), train_loss = 1.46521113, grad/param norm = 1.8557e-01, time/batch = 0.6260s	
4303/33650 (epoch 6.394), train_loss = 1.47319822, grad/param norm = 2.0205e-01, time/batch = 0.6330s	
4304/33650 (epoch 6.395), train_loss = 1.31280130, grad/param norm = 1.7137e-01, time/batch = 0.6279s	
4305/33650 (epoch 6.397), train_loss = 1.52887221, grad/param norm = 1.8187e-01, time/batch = 0.6285s	
4306/33650 (epoch 6.398), train_loss = 1.30775853, grad/param norm = 1.4113e-01, time/batch = 0.6290s	
4307/33650 (epoch 6.400), train_loss = 1.38776478, grad/param norm = 1.9175e-01, time/batch = 0.6339s	
4308/33650 (epoch 6.401), train_loss = 1.38306859, grad/param norm = 1.6907e-01, time/batch = 0.6660s	
4309/33650 (epoch 6.403), train_loss = 1.40032700, grad/param norm = 1.7212e-01, time/batch = 0.6423s	
4310/33650 (epoch 6.404), train_loss = 1.29743806, grad/param norm = 1.4092e-01, time/batch = 0.6241s	
4311/33650 (epoch 6.406), train_loss = 1.37637573, grad/param norm = 1.6016e-01, time/batch = 0.6304s	
4312/33650 (epoch 6.407), train_loss = 1.32114741, grad/param norm = 1.6422e-01, time/batch = 0.6256s	
4313/33650 (epoch 6.409), train_loss = 1.35452924, grad/param norm = 1.5907e-01, time/batch = 0.6258s	
4314/33650 (epoch 6.410), train_loss = 1.33927350, grad/param norm = 1.7995e-01, time/batch = 0.6285s	
4315/33650 (epoch 6.412), train_loss = 1.30426916, grad/param norm = 1.5090e-01, time/batch = 0.6293s	
4316/33650 (epoch 6.413), train_loss = 1.21372970, grad/param norm = 1.5645e-01, time/batch = 0.6303s	
4317/33650 (epoch 6.415), train_loss = 1.36569960, grad/param norm = 1.6377e-01, time/batch = 0.6348s	
4318/33650 (epoch 6.416), train_loss = 1.53394567, grad/param norm = 1.9621e-01, time/batch = 0.6388s	
4319/33650 (epoch 6.418), train_loss = 1.35696040, grad/param norm = 1.6749e-01, time/batch = 0.6325s	
4320/33650 (epoch 6.419), train_loss = 1.27818063, grad/param norm = 1.6369e-01, time/batch = 0.6330s	
4321/33650 (epoch 6.421), train_loss = 1.20302714, grad/param norm = 1.4924e-01, time/batch = 0.6294s	
4322/33650 (epoch 6.422), train_loss = 1.43984905, grad/param norm = 1.8602e-01, time/batch = 0.6316s	
4323/33650 (epoch 6.423), train_loss = 1.20070220, grad/param norm = 1.5669e-01, time/batch = 0.6308s	
4324/33650 (epoch 6.425), train_loss = 1.38859029, grad/param norm = 1.6332e-01, time/batch = 0.6256s	
4325/33650 (epoch 6.426), train_loss = 1.47389967, grad/param norm = 1.6520e-01, time/batch = 0.6277s	
4326/33650 (epoch 6.428), train_loss = 1.25350882, grad/param norm = 1.6761e-01, time/batch = 0.6286s	
4327/33650 (epoch 6.429), train_loss = 1.43137743, grad/param norm = 1.6849e-01, time/batch = 0.6279s	
4328/33650 (epoch 6.431), train_loss = 1.57753597, grad/param norm = 1.7629e-01, time/batch = 0.6533s	
4329/33650 (epoch 6.432), train_loss = 1.63146265, grad/param norm = 1.7751e-01, time/batch = 0.6614s	
4330/33650 (epoch 6.434), train_loss = 1.41561965, grad/param norm = 1.6610e-01, time/batch = 0.6311s	
4331/33650 (epoch 6.435), train_loss = 1.38995257, grad/param norm = 1.7519e-01, time/batch = 0.6305s	
4332/33650 (epoch 6.437), train_loss = 1.43732999, grad/param norm = 1.8889e-01, time/batch = 0.6338s	
4333/33650 (epoch 6.438), train_loss = 1.28900900, grad/param norm = 1.8576e-01, time/batch = 0.6273s	
4334/33650 (epoch 6.440), train_loss = 1.37530769, grad/param norm = 1.7681e-01, time/batch = 0.6256s	
4335/33650 (epoch 6.441), train_loss = 1.41904978, grad/param norm = 1.6665e-01, time/batch = 0.6292s	
4336/33650 (epoch 6.443), train_loss = 1.43106654, grad/param norm = 1.8372e-01, time/batch = 0.6287s	
4337/33650 (epoch 6.444), train_loss = 1.28748871, grad/param norm = 1.5041e-01, time/batch = 0.6360s	
4338/33650 (epoch 6.446), train_loss = 1.39498298, grad/param norm = 1.7326e-01, time/batch = 0.6596s	
4339/33650 (epoch 6.447), train_loss = 1.46263677, grad/param norm = 1.8837e-01, time/batch = 0.6454s	
4340/33650 (epoch 6.449), train_loss = 1.60484747, grad/param norm = 2.1236e-01, time/batch = 0.6392s	
4341/33650 (epoch 6.450), train_loss = 1.59143873, grad/param norm = 1.8881e-01, time/batch = 0.6444s	
4342/33650 (epoch 6.452), train_loss = 1.68166386, grad/param norm = 1.8834e-01, time/batch = 0.6294s	
4343/33650 (epoch 6.453), train_loss = 1.56537295, grad/param norm = 1.8655e-01, time/batch = 0.6297s	
4344/33650 (epoch 6.455), train_loss = 1.34249205, grad/param norm = 1.5594e-01, time/batch = 0.6458s	
4345/33650 (epoch 6.456), train_loss = 1.31768910, grad/param norm = 1.6434e-01, time/batch = 0.6627s	
4346/33650 (epoch 6.458), train_loss = 1.37858076, grad/param norm = 1.8143e-01, time/batch = 0.6604s	
4347/33650 (epoch 6.459), train_loss = 1.33285019, grad/param norm = 1.7772e-01, time/batch = 0.6517s	
4348/33650 (epoch 6.461), train_loss = 1.49706201, grad/param norm = 1.7495e-01, time/batch = 0.6516s	
4349/33650 (epoch 6.462), train_loss = 1.49092860, grad/param norm = 1.7514e-01, time/batch = 0.6430s	
4350/33650 (epoch 6.464), train_loss = 1.31618115, grad/param norm = 1.7687e-01, time/batch = 0.6336s	
4351/33650 (epoch 6.465), train_loss = 1.40687243, grad/param norm = 1.7959e-01, time/batch = 0.6329s	
4352/33650 (epoch 6.467), train_loss = 1.43214255, grad/param norm = 1.7336e-01, time/batch = 0.6310s	
4353/33650 (epoch 6.468), train_loss = 1.50871555, grad/param norm = 1.7003e-01, time/batch = 0.6347s	
4354/33650 (epoch 6.470), train_loss = 1.66488423, grad/param norm = 1.9189e-01, time/batch = 0.6339s	
4355/33650 (epoch 6.471), train_loss = 1.34326185, grad/param norm = 1.7088e-01, time/batch = 0.6283s	
4356/33650 (epoch 6.473), train_loss = 1.28714227, grad/param norm = 1.5497e-01, time/batch = 0.6321s	
4357/33650 (epoch 6.474), train_loss = 1.40931477, grad/param norm = 1.6563e-01, time/batch = 0.6372s	
4358/33650 (epoch 6.475), train_loss = 1.47182334, grad/param norm = 1.7921e-01, time/batch = 0.6375s	
4359/33650 (epoch 6.477), train_loss = 1.50819700, grad/param norm = 1.7661e-01, time/batch = 0.6270s	
4360/33650 (epoch 6.478), train_loss = 1.48004155, grad/param norm = 1.7507e-01, time/batch = 0.6270s	
4361/33650 (epoch 6.480), train_loss = 1.54122982, grad/param norm = 1.7768e-01, time/batch = 0.6295s	
4362/33650 (epoch 6.481), train_loss = 1.50237956, grad/param norm = 1.8830e-01, time/batch = 0.6271s	
4363/33650 (epoch 6.483), train_loss = 1.11572346, grad/param norm = 1.5865e-01, time/batch = 0.6274s	
4364/33650 (epoch 6.484), train_loss = 1.39502166, grad/param norm = 1.6828e-01, time/batch = 0.6563s	
4365/33650 (epoch 6.486), train_loss = 1.52988466, grad/param norm = 2.2197e-01, time/batch = 0.6566s	
4366/33650 (epoch 6.487), train_loss = 1.50076957, grad/param norm = 1.9801e-01, time/batch = 0.6276s	
4367/33650 (epoch 6.489), train_loss = 1.60050986, grad/param norm = 1.7620e-01, time/batch = 0.6299s	
4368/33650 (epoch 6.490), train_loss = 1.27158838, grad/param norm = 1.6300e-01, time/batch = 0.6279s	
4369/33650 (epoch 6.492), train_loss = 1.47921961, grad/param norm = 1.8550e-01, time/batch = 0.6285s	
4370/33650 (epoch 6.493), train_loss = 1.11592296, grad/param norm = 1.4825e-01, time/batch = 0.6265s	
4371/33650 (epoch 6.495), train_loss = 1.36239560, grad/param norm = 1.7171e-01, time/batch = 0.6350s	
4372/33650 (epoch 6.496), train_loss = 1.43426131, grad/param norm = 1.9120e-01, time/batch = 0.6309s	
4373/33650 (epoch 6.498), train_loss = 1.18101049, grad/param norm = 1.6120e-01, time/batch = 0.6265s	
4374/33650 (epoch 6.499), train_loss = 1.31071379, grad/param norm = 1.5299e-01, time/batch = 0.6319s	
4375/33650 (epoch 6.501), train_loss = 1.30636280, grad/param norm = 1.4056e-01, time/batch = 0.6294s	
4376/33650 (epoch 6.502), train_loss = 1.43622454, grad/param norm = 1.7796e-01, time/batch = 0.6283s	
4377/33650 (epoch 6.504), train_loss = 1.58831459, grad/param norm = 1.8249e-01, time/batch = 0.6280s	
4378/33650 (epoch 6.505), train_loss = 1.42480214, grad/param norm = 1.9536e-01, time/batch = 0.6300s	
4379/33650 (epoch 6.507), train_loss = 1.51420392, grad/param norm = 1.9442e-01, time/batch = 0.6347s	
4380/33650 (epoch 6.508), train_loss = 1.30596181, grad/param norm = 1.7598e-01, time/batch = 0.6338s	
4381/33650 (epoch 6.510), train_loss = 1.35871224, grad/param norm = 1.7359e-01, time/batch = 0.6363s	
4382/33650 (epoch 6.511), train_loss = 1.64931111, grad/param norm = 1.9408e-01, time/batch = 0.6321s	
4383/33650 (epoch 6.513), train_loss = 1.45429076, grad/param norm = 1.6862e-01, time/batch = 0.6281s	
4384/33650 (epoch 6.514), train_loss = 1.44015567, grad/param norm = 1.8029e-01, time/batch = 0.6395s	
4385/33650 (epoch 6.516), train_loss = 1.39793296, grad/param norm = 2.2901e-01, time/batch = 0.6668s	
4386/33650 (epoch 6.517), train_loss = 1.31707310, grad/param norm = 1.5989e-01, time/batch = 0.6528s	
4387/33650 (epoch 6.519), train_loss = 1.35095714, grad/param norm = 1.5689e-01, time/batch = 0.6342s	
4388/33650 (epoch 6.520), train_loss = 1.17278200, grad/param norm = 1.5953e-01, time/batch = 0.6340s	
4389/33650 (epoch 6.522), train_loss = 1.37093776, grad/param norm = 1.7835e-01, time/batch = 0.6302s	
4390/33650 (epoch 6.523), train_loss = 1.37394951, grad/param norm = 1.6504e-01, time/batch = 0.6496s	
4391/33650 (epoch 6.525), train_loss = 1.06598112, grad/param norm = 1.5006e-01, time/batch = 0.6277s	
4392/33650 (epoch 6.526), train_loss = 1.39722059, grad/param norm = 1.6412e-01, time/batch = 0.6247s	
4393/33650 (epoch 6.527), train_loss = 1.23353077, grad/param norm = 1.5833e-01, time/batch = 0.6246s	
4394/33650 (epoch 6.529), train_loss = 1.32888211, grad/param norm = 1.5209e-01, time/batch = 0.6275s	
4395/33650 (epoch 6.530), train_loss = 1.28011245, grad/param norm = 1.5648e-01, time/batch = 0.6295s	
4396/33650 (epoch 6.532), train_loss = 1.58998331, grad/param norm = 2.0251e-01, time/batch = 0.6260s	
4397/33650 (epoch 6.533), train_loss = 1.30822798, grad/param norm = 1.6893e-01, time/batch = 0.6285s	
4398/33650 (epoch 6.535), train_loss = 1.48974282, grad/param norm = 1.7013e-01, time/batch = 0.6322s	
4399/33650 (epoch 6.536), train_loss = 1.40260186, grad/param norm = 1.6743e-01, time/batch = 0.6281s	
4400/33650 (epoch 6.538), train_loss = 1.40950893, grad/param norm = 1.8184e-01, time/batch = 0.6283s	
4401/33650 (epoch 6.539), train_loss = 1.15292004, grad/param norm = 1.5122e-01, time/batch = 0.6336s	
4402/33650 (epoch 6.541), train_loss = 1.51500791, grad/param norm = 1.7373e-01, time/batch = 0.6315s	
4403/33650 (epoch 6.542), train_loss = 1.43283262, grad/param norm = 1.9956e-01, time/batch = 0.6299s	
4404/33650 (epoch 6.544), train_loss = 1.67157108, grad/param norm = 1.9773e-01, time/batch = 0.6296s	
4405/33650 (epoch 6.545), train_loss = 1.18565686, grad/param norm = 1.5584e-01, time/batch = 0.6530s	
4406/33650 (epoch 6.547), train_loss = 1.37432603, grad/param norm = 1.5999e-01, time/batch = 0.6278s	
4407/33650 (epoch 6.548), train_loss = 1.48666941, grad/param norm = 1.7324e-01, time/batch = 0.6297s	
4408/33650 (epoch 6.550), train_loss = 1.31704374, grad/param norm = 1.6523e-01, time/batch = 0.6309s	
4409/33650 (epoch 6.551), train_loss = 1.32726943, grad/param norm = 1.6083e-01, time/batch = 0.6308s	
4410/33650 (epoch 6.553), train_loss = 1.13284587, grad/param norm = 1.6203e-01, time/batch = 0.6265s	
4411/33650 (epoch 6.554), train_loss = 1.49303460, grad/param norm = 1.8438e-01, time/batch = 0.6308s	
4412/33650 (epoch 6.556), train_loss = 1.52574844, grad/param norm = 1.9914e-01, time/batch = 0.6331s	
4413/33650 (epoch 6.557), train_loss = 1.57791355, grad/param norm = 1.9706e-01, time/batch = 0.6302s	
4414/33650 (epoch 6.559), train_loss = 1.64919323, grad/param norm = 2.2434e-01, time/batch = 0.6274s	
4415/33650 (epoch 6.560), train_loss = 1.59552381, grad/param norm = 1.7240e-01, time/batch = 0.6295s	
4416/33650 (epoch 6.562), train_loss = 1.46140306, grad/param norm = 1.7691e-01, time/batch = 0.6301s	
4417/33650 (epoch 6.563), train_loss = 1.34489794, grad/param norm = 1.7978e-01, time/batch = 0.6264s	
4418/33650 (epoch 6.565), train_loss = 1.41745235, grad/param norm = 1.7167e-01, time/batch = 0.6273s	
4419/33650 (epoch 6.566), train_loss = 1.40297428, grad/param norm = 1.7692e-01, time/batch = 0.6261s	
4420/33650 (epoch 6.568), train_loss = 1.38715771, grad/param norm = 1.6270e-01, time/batch = 0.6271s	
4421/33650 (epoch 6.569), train_loss = 1.32123797, grad/param norm = 1.7178e-01, time/batch = 0.6311s	
4422/33650 (epoch 6.571), train_loss = 1.51500463, grad/param norm = 1.8971e-01, time/batch = 0.6287s	
4423/33650 (epoch 6.572), train_loss = 1.41592937, grad/param norm = 1.5497e-01, time/batch = 0.6295s	
4424/33650 (epoch 6.574), train_loss = 1.36736523, grad/param norm = 1.6725e-01, time/batch = 0.6243s	
4425/33650 (epoch 6.575), train_loss = 1.36191945, grad/param norm = 1.6230e-01, time/batch = 0.6260s	
4426/33650 (epoch 6.577), train_loss = 1.47093680, grad/param norm = 1.7579e-01, time/batch = 0.6262s	
4427/33650 (epoch 6.578), train_loss = 1.36914769, grad/param norm = 1.6064e-01, time/batch = 0.6245s	
4428/33650 (epoch 6.579), train_loss = 1.43373676, grad/param norm = 1.6463e-01, time/batch = 0.6269s	
4429/33650 (epoch 6.581), train_loss = 1.43553125, grad/param norm = 1.7138e-01, time/batch = 0.6294s	
4430/33650 (epoch 6.582), train_loss = 1.48327353, grad/param norm = 1.7963e-01, time/batch = 0.6495s	
4431/33650 (epoch 6.584), train_loss = 1.36519936, grad/param norm = 1.6285e-01, time/batch = 0.6390s	
4432/33650 (epoch 6.585), train_loss = 1.39328233, grad/param norm = 1.7728e-01, time/batch = 0.6408s	
4433/33650 (epoch 6.587), train_loss = 1.26532870, grad/param norm = 1.6165e-01, time/batch = 0.6398s	
4434/33650 (epoch 6.588), train_loss = 1.35541789, grad/param norm = 1.8100e-01, time/batch = 0.6461s	
4435/33650 (epoch 6.590), train_loss = 1.34702678, grad/param norm = 1.6302e-01, time/batch = 0.6397s	
4436/33650 (epoch 6.591), train_loss = 1.36188112, grad/param norm = 1.7953e-01, time/batch = 0.6302s	
4437/33650 (epoch 6.593), train_loss = 1.23504915, grad/param norm = 1.6016e-01, time/batch = 0.6336s	
4438/33650 (epoch 6.594), train_loss = 1.12342221, grad/param norm = 1.7073e-01, time/batch = 0.6327s	
4439/33650 (epoch 6.596), train_loss = 1.31190707, grad/param norm = 1.6093e-01, time/batch = 0.6379s	
4440/33650 (epoch 6.597), train_loss = 1.09428207, grad/param norm = 1.3217e-01, time/batch = 0.6297s	
4441/33650 (epoch 6.599), train_loss = 1.24120351, grad/param norm = 1.5982e-01, time/batch = 0.6322s	
4442/33650 (epoch 6.600), train_loss = 1.20007956, grad/param norm = 1.6590e-01, time/batch = 0.6290s	
4443/33650 (epoch 6.602), train_loss = 1.45682436, grad/param norm = 1.6674e-01, time/batch = 0.6335s	
4444/33650 (epoch 6.603), train_loss = 1.28213381, grad/param norm = 1.6230e-01, time/batch = 0.6276s	
4445/33650 (epoch 6.605), train_loss = 1.33946733, grad/param norm = 1.7241e-01, time/batch = 0.6282s	
4446/33650 (epoch 6.606), train_loss = 1.47910961, grad/param norm = 1.7072e-01, time/batch = 0.6287s	
4447/33650 (epoch 6.608), train_loss = 1.34418802, grad/param norm = 1.6230e-01, time/batch = 0.6312s	
4448/33650 (epoch 6.609), train_loss = 1.41757235, grad/param norm = 1.8234e-01, time/batch = 0.6277s	
4449/33650 (epoch 6.611), train_loss = 1.24005858, grad/param norm = 1.5087e-01, time/batch = 0.6287s	
4450/33650 (epoch 6.612), train_loss = 1.35763615, grad/param norm = 1.7412e-01, time/batch = 0.6324s	
4451/33650 (epoch 6.614), train_loss = 1.47014718, grad/param norm = 1.7975e-01, time/batch = 0.6682s	
4452/33650 (epoch 6.615), train_loss = 1.28405219, grad/param norm = 1.5532e-01, time/batch = 0.6370s	
4453/33650 (epoch 6.617), train_loss = 1.19555525, grad/param norm = 1.4378e-01, time/batch = 0.6302s	
4454/33650 (epoch 6.618), train_loss = 1.28177696, grad/param norm = 1.6276e-01, time/batch = 0.6309s	
4455/33650 (epoch 6.620), train_loss = 1.46455464, grad/param norm = 1.7921e-01, time/batch = 0.6302s	
4456/33650 (epoch 6.621), train_loss = 1.19582748, grad/param norm = 1.5035e-01, time/batch = 0.6323s	
4457/33650 (epoch 6.623), train_loss = 1.33875158, grad/param norm = 1.6384e-01, time/batch = 0.6273s	
4458/33650 (epoch 6.624), train_loss = 1.06330058, grad/param norm = 1.6813e-01, time/batch = 0.6278s	
4459/33650 (epoch 6.626), train_loss = 1.06114888, grad/param norm = 1.3651e-01, time/batch = 0.6269s	
4460/33650 (epoch 6.627), train_loss = 1.29823171, grad/param norm = 1.5664e-01, time/batch = 0.6275s	
4461/33650 (epoch 6.629), train_loss = 1.33884932, grad/param norm = 1.5647e-01, time/batch = 0.6355s	
4462/33650 (epoch 6.630), train_loss = 1.44033800, grad/param norm = 1.7183e-01, time/batch = 0.6282s	
4463/33650 (epoch 6.632), train_loss = 1.49737681, grad/param norm = 1.6446e-01, time/batch = 0.6289s	
4464/33650 (epoch 6.633), train_loss = 1.42334477, grad/param norm = 1.6618e-01, time/batch = 0.6303s	
4465/33650 (epoch 6.634), train_loss = 1.18878556, grad/param norm = 1.5324e-01, time/batch = 0.6261s	
4466/33650 (epoch 6.636), train_loss = 1.08800812, grad/param norm = 1.4290e-01, time/batch = 0.6276s	
4467/33650 (epoch 6.637), train_loss = 1.38374409, grad/param norm = 1.6852e-01, time/batch = 0.6265s	
4468/33650 (epoch 6.639), train_loss = 1.26671597, grad/param norm = 1.5850e-01, time/batch = 0.6273s	
4469/33650 (epoch 6.640), train_loss = 1.36828954, grad/param norm = 1.7249e-01, time/batch = 0.6354s	
4470/33650 (epoch 6.642), train_loss = 1.54847548, grad/param norm = 1.9194e-01, time/batch = 0.6310s	
4471/33650 (epoch 6.643), train_loss = 1.36338015, grad/param norm = 1.7145e-01, time/batch = 0.6357s	
4472/33650 (epoch 6.645), train_loss = 1.31639567, grad/param norm = 1.4877e-01, time/batch = 0.6315s	
4473/33650 (epoch 6.646), train_loss = 1.11330848, grad/param norm = 1.3197e-01, time/batch = 0.6290s	
4474/33650 (epoch 6.648), train_loss = 1.33517621, grad/param norm = 1.6151e-01, time/batch = 0.6286s	
4475/33650 (epoch 6.649), train_loss = 1.40969203, grad/param norm = 1.9498e-01, time/batch = 0.6283s	
4476/33650 (epoch 6.651), train_loss = 1.45410862, grad/param norm = 1.7695e-01, time/batch = 0.6659s	
4477/33650 (epoch 6.652), train_loss = 0.98889470, grad/param norm = 1.4665e-01, time/batch = 0.6455s	
4478/33650 (epoch 6.654), train_loss = 1.26645773, grad/param norm = 1.5280e-01, time/batch = 0.6263s	
4479/33650 (epoch 6.655), train_loss = 1.17789096, grad/param norm = 1.6518e-01, time/batch = 0.6265s	
4480/33650 (epoch 6.657), train_loss = 1.34958494, grad/param norm = 1.7904e-01, time/batch = 0.6284s	
4481/33650 (epoch 6.658), train_loss = 1.17478972, grad/param norm = 1.4654e-01, time/batch = 0.6286s	
4482/33650 (epoch 6.660), train_loss = 1.14117681, grad/param norm = 1.5129e-01, time/batch = 0.6295s	
4483/33650 (epoch 6.661), train_loss = 1.24765830, grad/param norm = 1.4104e-01, time/batch = 0.6309s	
4484/33650 (epoch 6.663), train_loss = 1.15574905, grad/param norm = 1.6529e-01, time/batch = 0.6296s	
4485/33650 (epoch 6.664), train_loss = 1.14945998, grad/param norm = 1.5030e-01, time/batch = 0.6251s	
4486/33650 (epoch 6.666), train_loss = 1.26031693, grad/param norm = 1.6199e-01, time/batch = 0.6260s	
4487/33650 (epoch 6.667), train_loss = 1.16976117, grad/param norm = 1.4156e-01, time/batch = 0.6259s	
4488/33650 (epoch 6.669), train_loss = 1.14732386, grad/param norm = 1.4903e-01, time/batch = 0.6281s	
4489/33650 (epoch 6.670), train_loss = 1.12014014, grad/param norm = 1.4936e-01, time/batch = 0.6472s	
4490/33650 (epoch 6.672), train_loss = 1.17692724, grad/param norm = 1.4887e-01, time/batch = 0.6342s	
4491/33650 (epoch 6.673), train_loss = 1.06837103, grad/param norm = 1.5191e-01, time/batch = 0.6300s	
4492/33650 (epoch 6.675), train_loss = 1.02803124, grad/param norm = 1.2289e-01, time/batch = 0.6309s	
4493/33650 (epoch 6.676), train_loss = 1.31289176, grad/param norm = 1.4982e-01, time/batch = 0.6304s	
4494/33650 (epoch 6.678), train_loss = 1.19037434, grad/param norm = 1.5630e-01, time/batch = 0.6306s	
4495/33650 (epoch 6.679), train_loss = 1.27510490, grad/param norm = 1.7342e-01, time/batch = 0.6312s	
4496/33650 (epoch 6.681), train_loss = 1.17800519, grad/param norm = 1.5360e-01, time/batch = 0.6505s	
4497/33650 (epoch 6.682), train_loss = 1.22771846, grad/param norm = 1.5729e-01, time/batch = 0.6644s	
4498/33650 (epoch 6.684), train_loss = 1.17389569, grad/param norm = 1.5136e-01, time/batch = 0.6259s	
4499/33650 (epoch 6.685), train_loss = 1.37629609, grad/param norm = 1.7416e-01, time/batch = 0.6288s	
4500/33650 (epoch 6.686), train_loss = 1.27455404, grad/param norm = 1.5612e-01, time/batch = 0.6360s	
4501/33650 (epoch 6.688), train_loss = 1.50345939, grad/param norm = 1.7675e-01, time/batch = 0.6409s	
4502/33650 (epoch 6.689), train_loss = 1.21130534, grad/param norm = 1.6617e-01, time/batch = 0.6285s	
4503/33650 (epoch 6.691), train_loss = 1.44156903, grad/param norm = 1.7764e-01, time/batch = 0.6278s	
4504/33650 (epoch 6.692), train_loss = 1.42515647, grad/param norm = 1.6466e-01, time/batch = 0.6298s	
4505/33650 (epoch 6.694), train_loss = 1.37674085, grad/param norm = 1.8192e-01, time/batch = 0.6315s	
4506/33650 (epoch 6.695), train_loss = 0.99991750, grad/param norm = 1.5284e-01, time/batch = 0.6318s	
4507/33650 (epoch 6.697), train_loss = 1.33024779, grad/param norm = 1.6064e-01, time/batch = 0.6299s	
4508/33650 (epoch 6.698), train_loss = 1.43921271, grad/param norm = 1.7430e-01, time/batch = 0.6308s	
4509/33650 (epoch 6.700), train_loss = 1.27029530, grad/param norm = 1.5936e-01, time/batch = 0.6246s	
4510/33650 (epoch 6.701), train_loss = 1.37869287, grad/param norm = 1.7222e-01, time/batch = 0.6245s	
4511/33650 (epoch 6.703), train_loss = 1.36161135, grad/param norm = 1.5392e-01, time/batch = 0.6298s	
4512/33650 (epoch 6.704), train_loss = 1.23830948, grad/param norm = 1.5310e-01, time/batch = 0.6273s	
4513/33650 (epoch 6.706), train_loss = 1.27660691, grad/param norm = 1.4605e-01, time/batch = 0.6282s	
4514/33650 (epoch 6.707), train_loss = 1.40831307, grad/param norm = 1.7095e-01, time/batch = 0.6259s	
4515/33650 (epoch 6.709), train_loss = 1.25108924, grad/param norm = 1.5687e-01, time/batch = 0.6255s	
4516/33650 (epoch 6.710), train_loss = 1.46928564, grad/param norm = 1.6024e-01, time/batch = 0.6352s	
4517/33650 (epoch 6.712), train_loss = 1.24953091, grad/param norm = 1.5821e-01, time/batch = 0.6660s	
4518/33650 (epoch 6.713), train_loss = 1.28231142, grad/param norm = 1.9903e-01, time/batch = 0.6457s	
4519/33650 (epoch 6.715), train_loss = 1.46856006, grad/param norm = 1.7569e-01, time/batch = 0.6312s	
4520/33650 (epoch 6.716), train_loss = 1.19910071, grad/param norm = 1.6969e-01, time/batch = 0.6293s	
4521/33650 (epoch 6.718), train_loss = 1.38344217, grad/param norm = 1.6040e-01, time/batch = 0.6287s	
4522/33650 (epoch 6.719), train_loss = 1.47735797, grad/param norm = 1.7360e-01, time/batch = 0.6256s	
4523/33650 (epoch 6.721), train_loss = 1.58342456, grad/param norm = 1.6904e-01, time/batch = 0.6254s	
4524/33650 (epoch 6.722), train_loss = 1.50174326, grad/param norm = 1.8590e-01, time/batch = 0.6268s	
4525/33650 (epoch 6.724), train_loss = 1.39542983, grad/param norm = 1.6232e-01, time/batch = 0.6314s	
4526/33650 (epoch 6.725), train_loss = 1.46814919, grad/param norm = 1.7441e-01, time/batch = 0.6417s	
4527/33650 (epoch 6.727), train_loss = 1.22300694, grad/param norm = 1.7356e-01, time/batch = 0.6382s	
4528/33650 (epoch 6.728), train_loss = 1.25440709, grad/param norm = 1.5741e-01, time/batch = 0.6333s	
4529/33650 (epoch 6.730), train_loss = 1.38197877, grad/param norm = 1.5835e-01, time/batch = 0.6695s	
4530/33650 (epoch 6.731), train_loss = 1.49595897, grad/param norm = 1.7411e-01, time/batch = 0.6613s	
4531/33650 (epoch 6.733), train_loss = 1.29369890, grad/param norm = 1.6730e-01, time/batch = 0.6364s	
4532/33650 (epoch 6.734), train_loss = 1.51927546, grad/param norm = 1.9521e-01, time/batch = 0.6391s	
4533/33650 (epoch 6.736), train_loss = 1.31652125, grad/param norm = 1.7580e-01, time/batch = 0.6311s	
4534/33650 (epoch 6.737), train_loss = 1.35646825, grad/param norm = 1.7715e-01, time/batch = 0.6280s	
4535/33650 (epoch 6.738), train_loss = 1.17903164, grad/param norm = 1.5336e-01, time/batch = 0.6314s	
4536/33650 (epoch 6.740), train_loss = 1.18897888, grad/param norm = 1.5054e-01, time/batch = 0.6274s	
4537/33650 (epoch 6.741), train_loss = 1.29639264, grad/param norm = 1.7023e-01, time/batch = 0.6589s	
4538/33650 (epoch 6.743), train_loss = 1.31914386, grad/param norm = 1.5041e-01, time/batch = 0.6543s	
4539/33650 (epoch 6.744), train_loss = 1.24850273, grad/param norm = 1.4695e-01, time/batch = 0.6275s	
4540/33650 (epoch 6.746), train_loss = 1.27404564, grad/param norm = 1.5750e-01, time/batch = 0.6270s	
4541/33650 (epoch 6.747), train_loss = 1.41831264, grad/param norm = 1.5924e-01, time/batch = 0.6298s	
4542/33650 (epoch 6.749), train_loss = 1.10368295, grad/param norm = 1.4916e-01, time/batch = 0.6622s	
4543/33650 (epoch 6.750), train_loss = 1.41247571, grad/param norm = 1.8716e-01, time/batch = 0.6391s	
4544/33650 (epoch 6.752), train_loss = 1.43244433, grad/param norm = 1.8270e-01, time/batch = 0.6267s	
4545/33650 (epoch 6.753), train_loss = 1.58092465, grad/param norm = 1.8701e-01, time/batch = 0.6258s	
4546/33650 (epoch 6.755), train_loss = 1.20739571, grad/param norm = 1.5496e-01, time/batch = 0.6250s	
4547/33650 (epoch 6.756), train_loss = 1.39825266, grad/param norm = 1.7791e-01, time/batch = 0.6250s	
4548/33650 (epoch 6.758), train_loss = 1.48345986, grad/param norm = 1.7821e-01, time/batch = 0.6274s	
4549/33650 (epoch 6.759), train_loss = 1.56333485, grad/param norm = 1.7450e-01, time/batch = 0.6271s	
4550/33650 (epoch 6.761), train_loss = 1.39546701, grad/param norm = 1.7342e-01, time/batch = 0.6297s	
4551/33650 (epoch 6.762), train_loss = 1.34116085, grad/param norm = 1.6887e-01, time/batch = 0.6299s	
4552/33650 (epoch 6.764), train_loss = 1.46830535, grad/param norm = 1.8653e-01, time/batch = 0.6266s	
4553/33650 (epoch 6.765), train_loss = 1.38682433, grad/param norm = 1.6361e-01, time/batch = 0.6290s	
4554/33650 (epoch 6.767), train_loss = 1.20045858, grad/param norm = 1.5697e-01, time/batch = 0.6362s	
4555/33650 (epoch 6.768), train_loss = 1.17156865, grad/param norm = 1.5263e-01, time/batch = 0.6274s	
4556/33650 (epoch 6.770), train_loss = 1.29896403, grad/param norm = 1.6837e-01, time/batch = 0.6284s	
4557/33650 (epoch 6.771), train_loss = 1.31456291, grad/param norm = 1.5948e-01, time/batch = 0.6413s	
4558/33650 (epoch 6.773), train_loss = 1.50672362, grad/param norm = 1.9029e-01, time/batch = 0.6658s	
4559/33650 (epoch 6.774), train_loss = 1.38057968, grad/param norm = 1.6580e-01, time/batch = 0.6320s	
4560/33650 (epoch 6.776), train_loss = 1.43023883, grad/param norm = 1.9074e-01, time/batch = 0.6271s	
4561/33650 (epoch 6.777), train_loss = 1.19261363, grad/param norm = 1.5584e-01, time/batch = 0.6299s	
4562/33650 (epoch 6.779), train_loss = 1.32707060, grad/param norm = 1.5004e-01, time/batch = 0.6273s	
4563/33650 (epoch 6.780), train_loss = 1.19625068, grad/param norm = 1.5301e-01, time/batch = 0.6288s	
4564/33650 (epoch 6.782), train_loss = 1.27131288, grad/param norm = 1.5846e-01, time/batch = 0.6316s	
4565/33650 (epoch 6.783), train_loss = 1.15479807, grad/param norm = 1.5290e-01, time/batch = 0.6328s	
4566/33650 (epoch 6.785), train_loss = 1.58321744, grad/param norm = 1.7060e-01, time/batch = 0.6289s	
4567/33650 (epoch 6.786), train_loss = 1.32392900, grad/param norm = 1.5118e-01, time/batch = 0.6280s	
4568/33650 (epoch 6.788), train_loss = 1.34794633, grad/param norm = 1.7682e-01, time/batch = 0.6284s	
4569/33650 (epoch 6.789), train_loss = 1.37515943, grad/param norm = 1.4275e-01, time/batch = 0.6295s	
4570/33650 (epoch 6.790), train_loss = 1.45376098, grad/param norm = 1.9077e-01, time/batch = 0.6308s	
4571/33650 (epoch 6.792), train_loss = 1.47818935, grad/param norm = 1.8729e-01, time/batch = 0.6305s	
4572/33650 (epoch 6.793), train_loss = 1.41915313, grad/param norm = 1.6642e-01, time/batch = 0.6301s	
4573/33650 (epoch 6.795), train_loss = 1.46816775, grad/param norm = 1.6375e-01, time/batch = 0.6296s	
4574/33650 (epoch 6.796), train_loss = 1.24711163, grad/param norm = 1.5440e-01, time/batch = 0.6309s	
4575/33650 (epoch 6.798), train_loss = 1.27791969, grad/param norm = 1.5019e-01, time/batch = 0.6282s	
4576/33650 (epoch 6.799), train_loss = 1.30449573, grad/param norm = 1.4498e-01, time/batch = 0.6273s	
4577/33650 (epoch 6.801), train_loss = 1.39766432, grad/param norm = 1.6669e-01, time/batch = 0.6284s	
4578/33650 (epoch 6.802), train_loss = 1.46407923, grad/param norm = 1.5222e-01, time/batch = 0.6613s	
4579/33650 (epoch 6.804), train_loss = 1.31096290, grad/param norm = 1.5255e-01, time/batch = 0.6511s	
4580/33650 (epoch 6.805), train_loss = 1.27476754, grad/param norm = 1.5464e-01, time/batch = 0.6275s	
4581/33650 (epoch 6.807), train_loss = 1.59369087, grad/param norm = 1.8355e-01, time/batch = 0.6294s	
4582/33650 (epoch 6.808), train_loss = 1.56948360, grad/param norm = 1.7743e-01, time/batch = 0.6331s	
4583/33650 (epoch 6.810), train_loss = 1.37551838, grad/param norm = 1.5429e-01, time/batch = 0.6300s	
4584/33650 (epoch 6.811), train_loss = 1.39546361, grad/param norm = 1.6906e-01, time/batch = 0.6282s	
4585/33650 (epoch 6.813), train_loss = 1.34404625, grad/param norm = 1.8714e-01, time/batch = 0.6280s	
4586/33650 (epoch 6.814), train_loss = 1.44427604, grad/param norm = 1.6921e-01, time/batch = 0.6280s	
4587/33650 (epoch 6.816), train_loss = 1.39600377, grad/param norm = 1.7128e-01, time/batch = 0.6305s	
4588/33650 (epoch 6.817), train_loss = 1.48232453, grad/param norm = 1.8583e-01, time/batch = 0.6302s	
4589/33650 (epoch 6.819), train_loss = 1.46967114, grad/param norm = 1.5795e-01, time/batch = 0.6268s	
4590/33650 (epoch 6.820), train_loss = 1.49387613, grad/param norm = 1.7076e-01, time/batch = 0.6276s	
4591/33650 (epoch 6.822), train_loss = 1.54068905, grad/param norm = 1.8863e-01, time/batch = 0.6343s	
4592/33650 (epoch 6.823), train_loss = 1.24686028, grad/param norm = 1.6839e-01, time/batch = 0.6415s	
4593/33650 (epoch 6.825), train_loss = 1.31900887, grad/param norm = 1.5067e-01, time/batch = 0.6276s	
4594/33650 (epoch 6.826), train_loss = 1.40035510, grad/param norm = 1.6116e-01, time/batch = 0.6292s	
4595/33650 (epoch 6.828), train_loss = 1.65907018, grad/param norm = 1.7850e-01, time/batch = 0.6254s	
4596/33650 (epoch 6.829), train_loss = 1.19253914, grad/param norm = 1.5426e-01, time/batch = 0.6318s	
4597/33650 (epoch 6.831), train_loss = 1.45035230, grad/param norm = 1.6420e-01, time/batch = 0.6321s	
4598/33650 (epoch 6.832), train_loss = 1.41061097, grad/param norm = 1.7437e-01, time/batch = 0.6492s	
4599/33650 (epoch 6.834), train_loss = 1.44768597, grad/param norm = 1.6434e-01, time/batch = 0.6677s	
4600/33650 (epoch 6.835), train_loss = 1.64718981, grad/param norm = 1.8029e-01, time/batch = 0.6441s	
4601/33650 (epoch 6.837), train_loss = 1.38411408, grad/param norm = 1.8223e-01, time/batch = 0.6362s	
4602/33650 (epoch 6.838), train_loss = 1.36380287, grad/param norm = 1.8134e-01, time/batch = 0.6384s	
4603/33650 (epoch 6.840), train_loss = 1.42344091, grad/param norm = 1.5917e-01, time/batch = 0.6320s	
4604/33650 (epoch 6.841), train_loss = 1.24664873, grad/param norm = 1.5207e-01, time/batch = 0.6356s	
4605/33650 (epoch 6.842), train_loss = 1.28767435, grad/param norm = 1.6577e-01, time/batch = 0.6468s	
4606/33650 (epoch 6.844), train_loss = 1.57104360, grad/param norm = 1.8557e-01, time/batch = 0.6411s	
4607/33650 (epoch 6.845), train_loss = 1.22394228, grad/param norm = 1.4866e-01, time/batch = 0.6320s	
4608/33650 (epoch 6.847), train_loss = 1.12440396, grad/param norm = 1.4871e-01, time/batch = 0.6284s	
4609/33650 (epoch 6.848), train_loss = 1.21428932, grad/param norm = 1.6872e-01, time/batch = 0.6267s	
4610/33650 (epoch 6.850), train_loss = 1.41549001, grad/param norm = 1.8477e-01, time/batch = 0.6279s	
4611/33650 (epoch 6.851), train_loss = 1.10586939, grad/param norm = 1.4178e-01, time/batch = 0.6279s	
4612/33650 (epoch 6.853), train_loss = 1.35703581, grad/param norm = 1.5387e-01, time/batch = 0.6286s	
4613/33650 (epoch 6.854), train_loss = 1.53350481, grad/param norm = 1.9895e-01, time/batch = 0.6282s	
4614/33650 (epoch 6.856), train_loss = 1.02715353, grad/param norm = 1.5569e-01, time/batch = 0.6602s	
4615/33650 (epoch 6.857), train_loss = 1.29356189, grad/param norm = 1.4849e-01, time/batch = 0.6539s	
4616/33650 (epoch 6.859), train_loss = 1.20251379, grad/param norm = 1.5255e-01, time/batch = 0.6276s	
4617/33650 (epoch 6.860), train_loss = 1.10993356, grad/param norm = 1.5716e-01, time/batch = 0.6314s	
4618/33650 (epoch 6.862), train_loss = 1.17292287, grad/param norm = 1.6022e-01, time/batch = 0.6252s	
4619/33650 (epoch 6.863), train_loss = 1.42101440, grad/param norm = 1.6284e-01, time/batch = 0.6290s	
4620/33650 (epoch 6.865), train_loss = 1.24229471, grad/param norm = 1.6740e-01, time/batch = 0.6399s	
4621/33650 (epoch 6.866), train_loss = 1.23140692, grad/param norm = 1.6660e-01, time/batch = 0.6492s	
4622/33650 (epoch 6.868), train_loss = 1.19647810, grad/param norm = 1.6558e-01, time/batch = 0.6353s	
4623/33650 (epoch 6.869), train_loss = 1.44364044, grad/param norm = 1.7324e-01, time/batch = 0.6577s	
4624/33650 (epoch 6.871), train_loss = 1.16012530, grad/param norm = 1.5823e-01, time/batch = 0.6417s	
4625/33650 (epoch 6.872), train_loss = 1.30403901, grad/param norm = 1.6996e-01, time/batch = 0.6367s	
4626/33650 (epoch 6.874), train_loss = 1.44093607, grad/param norm = 1.7612e-01, time/batch = 0.6275s	
4627/33650 (epoch 6.875), train_loss = 1.24550833, grad/param norm = 1.5966e-01, time/batch = 0.6295s	
4628/33650 (epoch 6.877), train_loss = 1.44235143, grad/param norm = 1.6271e-01, time/batch = 0.6276s	
4629/33650 (epoch 6.878), train_loss = 0.96092145, grad/param norm = 1.5492e-01, time/batch = 0.6267s	
4630/33650 (epoch 6.880), train_loss = 1.32619770, grad/param norm = 1.7263e-01, time/batch = 0.6260s	
4631/33650 (epoch 6.881), train_loss = 1.22860370, grad/param norm = 1.5259e-01, time/batch = 0.6343s	
4632/33650 (epoch 6.883), train_loss = 1.32010619, grad/param norm = 1.6706e-01, time/batch = 0.6438s	
4633/33650 (epoch 6.884), train_loss = 1.41558211, grad/param norm = 1.7216e-01, time/batch = 0.6264s	
4634/33650 (epoch 6.886), train_loss = 1.45086015, grad/param norm = 1.7576e-01, time/batch = 0.6462s	
4635/33650 (epoch 6.887), train_loss = 1.25024585, grad/param norm = 1.5737e-01, time/batch = 0.6657s	
4636/33650 (epoch 6.889), train_loss = 1.42933243, grad/param norm = 1.6826e-01, time/batch = 0.6269s	
4637/33650 (epoch 6.890), train_loss = 1.42297554, grad/param norm = 1.6120e-01, time/batch = 0.6303s	
4638/33650 (epoch 6.892), train_loss = 1.39418608, grad/param norm = 1.7554e-01, time/batch = 0.6295s	
4639/33650 (epoch 6.893), train_loss = 1.41180430, grad/param norm = 1.7439e-01, time/batch = 0.6313s	
4640/33650 (epoch 6.895), train_loss = 1.46988188, grad/param norm = 1.7203e-01, time/batch = 0.6266s	
4641/33650 (epoch 6.896), train_loss = 1.22729372, grad/param norm = 1.6242e-01, time/batch = 0.6257s	
4642/33650 (epoch 6.897), train_loss = 1.23358910, grad/param norm = 1.5681e-01, time/batch = 0.6294s	
4643/33650 (epoch 6.899), train_loss = 1.21934577, grad/param norm = 1.5163e-01, time/batch = 0.6275s	
4644/33650 (epoch 6.900), train_loss = 1.09170070, grad/param norm = 1.4289e-01, time/batch = 0.6263s	
4645/33650 (epoch 6.902), train_loss = 1.32747572, grad/param norm = 1.5762e-01, time/batch = 0.6298s	
4646/33650 (epoch 6.903), train_loss = 1.29029365, grad/param norm = 1.7571e-01, time/batch = 0.6320s	
4647/33650 (epoch 6.905), train_loss = 1.59653504, grad/param norm = 2.0233e-01, time/batch = 0.6362s	
4648/33650 (epoch 6.906), train_loss = 1.29486604, grad/param norm = 1.7076e-01, time/batch = 0.6296s	
4649/33650 (epoch 6.908), train_loss = 1.25763343, grad/param norm = 1.5069e-01, time/batch = 0.6282s	
4650/33650 (epoch 6.909), train_loss = 1.27880428, grad/param norm = 1.4186e-01, time/batch = 0.6401s	
4651/33650 (epoch 6.911), train_loss = 1.16393588, grad/param norm = 1.5001e-01, time/batch = 0.6413s	
4652/33650 (epoch 6.912), train_loss = 1.17568142, grad/param norm = 1.5258e-01, time/batch = 0.6291s	
4653/33650 (epoch 6.914), train_loss = 1.30888989, grad/param norm = 1.5196e-01, time/batch = 0.6282s	
4654/33650 (epoch 6.915), train_loss = 1.41063491, grad/param norm = 1.8273e-01, time/batch = 0.6286s	
4655/33650 (epoch 6.917), train_loss = 1.32762341, grad/param norm = 1.7200e-01, time/batch = 0.6283s	
4656/33650 (epoch 6.918), train_loss = 1.06316675, grad/param norm = 1.3813e-01, time/batch = 0.6290s	
4657/33650 (epoch 6.920), train_loss = 1.22904332, grad/param norm = 1.4257e-01, time/batch = 0.6273s	
4658/33650 (epoch 6.921), train_loss = 1.19689025, grad/param norm = 1.5684e-01, time/batch = 0.6264s	
4659/33650 (epoch 6.923), train_loss = 1.19396579, grad/param norm = 1.5532e-01, time/batch = 0.6260s	
4660/33650 (epoch 6.924), train_loss = 1.39107603, grad/param norm = 1.7816e-01, time/batch = 0.6268s	
4661/33650 (epoch 6.926), train_loss = 1.36290207, grad/param norm = 1.8332e-01, time/batch = 0.6289s	
4662/33650 (epoch 6.927), train_loss = 1.27942941, grad/param norm = 1.7005e-01, time/batch = 0.6279s	
4663/33650 (epoch 6.929), train_loss = 1.30788623, grad/param norm = 1.6353e-01, time/batch = 0.6297s	
4664/33650 (epoch 6.930), train_loss = 1.29073324, grad/param norm = 1.6265e-01, time/batch = 0.6285s	
4665/33650 (epoch 6.932), train_loss = 1.30903350, grad/param norm = 1.5954e-01, time/batch = 0.6267s	
4666/33650 (epoch 6.933), train_loss = 1.17534877, grad/param norm = 1.5174e-01, time/batch = 0.6250s	
4667/33650 (epoch 6.935), train_loss = 1.22444456, grad/param norm = 1.5770e-01, time/batch = 0.6271s	
4668/33650 (epoch 6.936), train_loss = 1.19926749, grad/param norm = 1.4352e-01, time/batch = 0.6283s	
4669/33650 (epoch 6.938), train_loss = 1.13539560, grad/param norm = 1.5140e-01, time/batch = 0.6289s	
4670/33650 (epoch 6.939), train_loss = 1.36191908, grad/param norm = 1.5314e-01, time/batch = 0.6256s	
4671/33650 (epoch 6.941), train_loss = 1.34964462, grad/param norm = 1.7844e-01, time/batch = 0.6295s	
4672/33650 (epoch 6.942), train_loss = 1.40410421, grad/param norm = 1.6611e-01, time/batch = 0.6310s	
4673/33650 (epoch 6.944), train_loss = 1.33780077, grad/param norm = 1.5496e-01, time/batch = 0.6283s	
4674/33650 (epoch 6.945), train_loss = 1.39974630, grad/param norm = 1.6575e-01, time/batch = 0.6394s	
4675/33650 (epoch 6.947), train_loss = 1.58524504, grad/param norm = 1.8358e-01, time/batch = 0.6471s	
4676/33650 (epoch 6.948), train_loss = 1.45467811, grad/param norm = 1.6891e-01, time/batch = 0.6660s	
4677/33650 (epoch 6.949), train_loss = 1.22377955, grad/param norm = 1.7237e-01, time/batch = 0.6262s	
4678/33650 (epoch 6.951), train_loss = 1.45403899, grad/param norm = 1.6393e-01, time/batch = 0.6340s	
4679/33650 (epoch 6.952), train_loss = 1.46481323, grad/param norm = 1.7599e-01, time/batch = 0.6318s	
4680/33650 (epoch 6.954), train_loss = 1.40962243, grad/param norm = 1.6946e-01, time/batch = 0.6268s	
4681/33650 (epoch 6.955), train_loss = 1.44493229, grad/param norm = 1.7219e-01, time/batch = 0.6289s	
4682/33650 (epoch 6.957), train_loss = 1.40162421, grad/param norm = 1.6759e-01, time/batch = 0.6272s	
4683/33650 (epoch 6.958), train_loss = 1.00456012, grad/param norm = 1.3887e-01, time/batch = 0.6292s	
4684/33650 (epoch 6.960), train_loss = 1.14124545, grad/param norm = 1.4175e-01, time/batch = 0.6287s	
4685/33650 (epoch 6.961), train_loss = 1.22937991, grad/param norm = 1.5060e-01, time/batch = 0.6265s	
4686/33650 (epoch 6.963), train_loss = 1.27949758, grad/param norm = 1.6506e-01, time/batch = 0.6264s	
4687/33650 (epoch 6.964), train_loss = 1.32254149, grad/param norm = 1.7010e-01, time/batch = 0.6271s	
4688/33650 (epoch 6.966), train_loss = 1.31375010, grad/param norm = 1.6368e-01, time/batch = 0.6262s	
4689/33650 (epoch 6.967), train_loss = 1.39754364, grad/param norm = 1.7551e-01, time/batch = 0.6297s	
4690/33650 (epoch 6.969), train_loss = 1.25192306, grad/param norm = 1.4603e-01, time/batch = 0.6304s	
4691/33650 (epoch 6.970), train_loss = 1.36547233, grad/param norm = 1.6474e-01, time/batch = 0.6313s	
4692/33650 (epoch 6.972), train_loss = 1.62563970, grad/param norm = 1.7157e-01, time/batch = 0.6263s	
4693/33650 (epoch 6.973), train_loss = 1.18311587, grad/param norm = 1.4202e-01, time/batch = 0.6300s	
4694/33650 (epoch 6.975), train_loss = 1.20309223, grad/param norm = 1.5508e-01, time/batch = 0.6276s	
4695/33650 (epoch 6.976), train_loss = 1.16270269, grad/param norm = 1.4501e-01, time/batch = 0.6250s	
4696/33650 (epoch 6.978), train_loss = 1.23655694, grad/param norm = 1.6806e-01, time/batch = 0.6654s	
4697/33650 (epoch 6.979), train_loss = 1.34693667, grad/param norm = 1.7041e-01, time/batch = 0.6463s	
4698/33650 (epoch 6.981), train_loss = 1.24117017, grad/param norm = 1.3441e-01, time/batch = 0.6294s	
4699/33650 (epoch 6.982), train_loss = 1.36363425, grad/param norm = 1.7792e-01, time/batch = 0.6344s	
4700/33650 (epoch 6.984), train_loss = 1.16885031, grad/param norm = 1.4720e-01, time/batch = 0.6307s	
4701/33650 (epoch 6.985), train_loss = 1.17526290, grad/param norm = 1.4273e-01, time/batch = 0.6329s	
4702/33650 (epoch 6.987), train_loss = 1.27040807, grad/param norm = 1.6356e-01, time/batch = 0.6291s	
4703/33650 (epoch 6.988), train_loss = 1.38321924, grad/param norm = 1.6169e-01, time/batch = 0.6267s	
4704/33650 (epoch 6.990), train_loss = 1.55853624, grad/param norm = 1.9880e-01, time/batch = 0.6269s	
4705/33650 (epoch 6.991), train_loss = 1.41999218, grad/param norm = 1.7353e-01, time/batch = 0.6267s	
4706/33650 (epoch 6.993), train_loss = 1.37929022, grad/param norm = 1.7355e-01, time/batch = 0.6275s	
4707/33650 (epoch 6.994), train_loss = 1.25912162, grad/param norm = 1.5378e-01, time/batch = 0.6266s	
4708/33650 (epoch 6.996), train_loss = 1.22459304, grad/param norm = 1.5497e-01, time/batch = 0.6300s	
4709/33650 (epoch 6.997), train_loss = 1.37105650, grad/param norm = 1.8053e-01, time/batch = 0.6269s	
4710/33650 (epoch 6.999), train_loss = 1.15070542, grad/param norm = 1.5242e-01, time/batch = 0.6283s	
4711/33650 (epoch 7.000), train_loss = 1.42720974, grad/param norm = 1.7449e-01, time/batch = 0.6297s	
4712/33650 (epoch 7.001), train_loss = 1.46819305, grad/param norm = 1.7530e-01, time/batch = 0.6292s	
4713/33650 (epoch 7.003), train_loss = 1.57233342, grad/param norm = 1.8887e-01, time/batch = 0.6286s	
4714/33650 (epoch 7.004), train_loss = 1.40205238, grad/param norm = 1.7376e-01, time/batch = 0.6366s	
4715/33650 (epoch 7.006), train_loss = 1.25371225, grad/param norm = 1.6238e-01, time/batch = 0.6467s	
4716/33650 (epoch 7.007), train_loss = 1.32016835, grad/param norm = 1.7358e-01, time/batch = 0.6538s	
4717/33650 (epoch 7.009), train_loss = 1.28182354, grad/param norm = 1.5087e-01, time/batch = 0.6678s	
4718/33650 (epoch 7.010), train_loss = 1.39213367, grad/param norm = 1.6854e-01, time/batch = 0.6411s	
4719/33650 (epoch 7.012), train_loss = 1.25043160, grad/param norm = 1.6682e-01, time/batch = 0.6274s	
4720/33650 (epoch 7.013), train_loss = 1.38403376, grad/param norm = 1.7322e-01, time/batch = 0.6294s	
4721/33650 (epoch 7.015), train_loss = 1.19861532, grad/param norm = 1.5497e-01, time/batch = 0.6319s	
4722/33650 (epoch 7.016), train_loss = 1.25351757, grad/param norm = 1.8761e-01, time/batch = 0.6309s	
4723/33650 (epoch 7.018), train_loss = 1.31407069, grad/param norm = 1.6206e-01, time/batch = 0.6255s	
4724/33650 (epoch 7.019), train_loss = 1.21102207, grad/param norm = 1.5780e-01, time/batch = 0.6327s	
4725/33650 (epoch 7.021), train_loss = 1.42114689, grad/param norm = 1.6948e-01, time/batch = 0.6295s	
4726/33650 (epoch 7.022), train_loss = 1.27327479, grad/param norm = 1.7045e-01, time/batch = 0.6318s	
4727/33650 (epoch 7.024), train_loss = 1.18076684, grad/param norm = 1.5474e-01, time/batch = 0.6256s	
4728/33650 (epoch 7.025), train_loss = 1.25183315, grad/param norm = 1.5968e-01, time/batch = 0.6270s	
4729/33650 (epoch 7.027), train_loss = 1.42981870, grad/param norm = 1.7766e-01, time/batch = 0.6292s	
4730/33650 (epoch 7.028), train_loss = 1.40063386, grad/param norm = 1.6991e-01, time/batch = 0.6227s	
4731/33650 (epoch 7.030), train_loss = 1.31075968, grad/param norm = 1.5096e-01, time/batch = 0.6487s	
4732/33650 (epoch 7.031), train_loss = 1.08324286, grad/param norm = 1.3849e-01, time/batch = 0.6303s	
4733/33650 (epoch 7.033), train_loss = 1.23057089, grad/param norm = 1.3610e-01, time/batch = 0.6296s	
4734/33650 (epoch 7.034), train_loss = 1.32475607, grad/param norm = 1.6663e-01, time/batch = 0.6354s	
4735/33650 (epoch 7.036), train_loss = 1.47624435, grad/param norm = 1.7794e-01, time/batch = 0.6401s	
4736/33650 (epoch 7.037), train_loss = 1.19217325, grad/param norm = 1.7234e-01, time/batch = 0.6379s	
4737/33650 (epoch 7.039), train_loss = 1.45685949, grad/param norm = 1.7027e-01, time/batch = 0.6256s	
4738/33650 (epoch 7.040), train_loss = 1.49760733, grad/param norm = 1.8543e-01, time/batch = 0.6252s	
4739/33650 (epoch 7.042), train_loss = 1.52661896, grad/param norm = 1.7392e-01, time/batch = 0.6254s	
4740/33650 (epoch 7.043), train_loss = 1.21079723, grad/param norm = 1.5491e-01, time/batch = 0.6252s	
4741/33650 (epoch 7.045), train_loss = 1.22516340, grad/param norm = 1.5880e-01, time/batch = 0.6281s	
4742/33650 (epoch 7.046), train_loss = 1.41721990, grad/param norm = 1.5875e-01, time/batch = 0.6308s	
4743/33650 (epoch 7.048), train_loss = 1.39896148, grad/param norm = 1.6956e-01, time/batch = 0.6291s	
4744/33650 (epoch 7.049), train_loss = 1.38043817, grad/param norm = 1.7593e-01, time/batch = 0.6341s	
4745/33650 (epoch 7.051), train_loss = 1.41653685, grad/param norm = 1.6238e-01, time/batch = 0.6305s	
4746/33650 (epoch 7.052), train_loss = 1.50806112, grad/param norm = 1.7676e-01, time/batch = 0.6332s	
4747/33650 (epoch 7.053), train_loss = 1.33283590, grad/param norm = 1.5788e-01, time/batch = 0.6537s	
4748/33650 (epoch 7.055), train_loss = 1.14981105, grad/param norm = 1.6964e-01, time/batch = 0.6699s	
4749/33650 (epoch 7.056), train_loss = 1.14469075, grad/param norm = 1.5355e-01, time/batch = 0.6663s	
4750/33650 (epoch 7.058), train_loss = 1.44716845, grad/param norm = 1.8599e-01, time/batch = 0.6619s	
4751/33650 (epoch 7.059), train_loss = 1.40105688, grad/param norm = 1.6876e-01, time/batch = 0.6636s	
4752/33650 (epoch 7.061), train_loss = 1.39011305, grad/param norm = 1.5177e-01, time/batch = 0.6558s	
4753/33650 (epoch 7.062), train_loss = 1.34921530, grad/param norm = 1.5442e-01, time/batch = 0.6434s	
4754/33650 (epoch 7.064), train_loss = 1.25237236, grad/param norm = 1.5392e-01, time/batch = 0.6361s	
4755/33650 (epoch 7.065), train_loss = 1.25827558, grad/param norm = 1.5896e-01, time/batch = 0.6274s	
4756/33650 (epoch 7.067), train_loss = 1.16175972, grad/param norm = 1.5543e-01, time/batch = 0.6261s	
4757/33650 (epoch 7.068), train_loss = 1.34397502, grad/param norm = 1.6588e-01, time/batch = 0.6254s	
4758/33650 (epoch 7.070), train_loss = 1.30711815, grad/param norm = 1.6957e-01, time/batch = 0.6280s	
4759/33650 (epoch 7.071), train_loss = 1.31990360, grad/param norm = 1.5606e-01, time/batch = 0.6300s	
4760/33650 (epoch 7.073), train_loss = 1.40056366, grad/param norm = 1.7172e-01, time/batch = 0.6297s	
4761/33650 (epoch 7.074), train_loss = 1.43128456, grad/param norm = 1.7301e-01, time/batch = 0.6274s	
4762/33650 (epoch 7.076), train_loss = 1.47520177, grad/param norm = 1.7799e-01, time/batch = 0.6245s	
4763/33650 (epoch 7.077), train_loss = 1.26065574, grad/param norm = 1.5437e-01, time/batch = 0.6254s	
4764/33650 (epoch 7.079), train_loss = 1.28071315, grad/param norm = 1.7414e-01, time/batch = 0.6251s	
4765/33650 (epoch 7.080), train_loss = 1.39011080, grad/param norm = 1.7757e-01, time/batch = 0.6253s	
4766/33650 (epoch 7.082), train_loss = 1.46276599, grad/param norm = 1.8292e-01, time/batch = 0.6261s	
4767/33650 (epoch 7.083), train_loss = 1.37108777, grad/param norm = 1.6080e-01, time/batch = 0.6261s	
4768/33650 (epoch 7.085), train_loss = 1.39556668, grad/param norm = 1.6102e-01, time/batch = 0.6592s	
4769/33650 (epoch 7.086), train_loss = 1.42078127, grad/param norm = 1.8816e-01, time/batch = 0.6522s	
4770/33650 (epoch 7.088), train_loss = 1.36133758, grad/param norm = 1.5895e-01, time/batch = 0.6239s	
4771/33650 (epoch 7.089), train_loss = 1.36905627, grad/param norm = 1.8013e-01, time/batch = 0.6276s	
4772/33650 (epoch 7.091), train_loss = 1.23480725, grad/param norm = 1.5462e-01, time/batch = 0.6278s	
4773/33650 (epoch 7.092), train_loss = 1.24693385, grad/param norm = 1.5389e-01, time/batch = 0.6253s	
4774/33650 (epoch 7.094), train_loss = 1.36483119, grad/param norm = 1.5402e-01, time/batch = 0.6274s	
4775/33650 (epoch 7.095), train_loss = 1.38394522, grad/param norm = 1.7444e-01, time/batch = 0.6297s	
4776/33650 (epoch 7.097), train_loss = 1.30892851, grad/param norm = 1.6758e-01, time/batch = 0.6288s	
4777/33650 (epoch 7.098), train_loss = 1.06737053, grad/param norm = 1.4761e-01, time/batch = 0.6245s	
4778/33650 (epoch 7.100), train_loss = 1.20401732, grad/param norm = 1.5483e-01, time/batch = 0.6255s	
4779/33650 (epoch 7.101), train_loss = 1.24659247, grad/param norm = 1.6836e-01, time/batch = 0.6242s	
4780/33650 (epoch 7.103), train_loss = 1.20572201, grad/param norm = 1.4837e-01, time/batch = 0.6243s	
4781/33650 (epoch 7.104), train_loss = 1.35157439, grad/param norm = 1.5773e-01, time/batch = 0.6271s	
4782/33650 (epoch 7.105), train_loss = 1.32812006, grad/param norm = 1.8476e-01, time/batch = 0.6258s	
4783/33650 (epoch 7.107), train_loss = 1.19197539, grad/param norm = 1.7076e-01, time/batch = 0.6276s	
4784/33650 (epoch 7.108), train_loss = 1.38152120, grad/param norm = 1.7385e-01, time/batch = 0.6293s	
4785/33650 (epoch 7.110), train_loss = 1.48391305, grad/param norm = 1.6366e-01, time/batch = 0.6273s	
4786/33650 (epoch 7.111), train_loss = 1.24459559, grad/param norm = 1.7568e-01, time/batch = 0.6307s	
4787/33650 (epoch 7.113), train_loss = 1.25328281, grad/param norm = 1.6144e-01, time/batch = 0.6287s	
4788/33650 (epoch 7.114), train_loss = 1.41469864, grad/param norm = 1.7435e-01, time/batch = 0.6383s	
4789/33650 (epoch 7.116), train_loss = 1.16381329, grad/param norm = 1.5887e-01, time/batch = 0.6661s	
4790/33650 (epoch 7.117), train_loss = 1.30590395, grad/param norm = 1.5019e-01, time/batch = 0.6369s	
4791/33650 (epoch 7.119), train_loss = 1.15796356, grad/param norm = 1.4830e-01, time/batch = 0.6329s	
4792/33650 (epoch 7.120), train_loss = 1.24381285, grad/param norm = 1.6714e-01, time/batch = 0.6294s	
4793/33650 (epoch 7.122), train_loss = 1.13652737, grad/param norm = 1.6111e-01, time/batch = 0.6261s	
4794/33650 (epoch 7.123), train_loss = 1.25229056, grad/param norm = 1.5114e-01, time/batch = 0.6272s	
4795/33650 (epoch 7.125), train_loss = 1.44923780, grad/param norm = 1.7265e-01, time/batch = 0.6272s	
4796/33650 (epoch 7.126), train_loss = 1.54228625, grad/param norm = 1.6920e-01, time/batch = 0.6300s	
4797/33650 (epoch 7.128), train_loss = 1.44072556, grad/param norm = 1.7809e-01, time/batch = 0.6279s	
4798/33650 (epoch 7.129), train_loss = 1.42709650, grad/param norm = 1.6326e-01, time/batch = 0.6299s	
4799/33650 (epoch 7.131), train_loss = 1.37573837, grad/param norm = 1.7104e-01, time/batch = 0.6280s	
4800/33650 (epoch 7.132), train_loss = 1.32017450, grad/param norm = 1.5969e-01, time/batch = 0.6250s	
4801/33650 (epoch 7.134), train_loss = 1.49418222, grad/param norm = 1.6979e-01, time/batch = 0.6277s	
4802/33650 (epoch 7.135), train_loss = 1.19691337, grad/param norm = 1.7809e-01, time/batch = 0.6268s	
4803/33650 (epoch 7.137), train_loss = 1.29735836, grad/param norm = 1.6435e-01, time/batch = 0.6271s	
4804/33650 (epoch 7.138), train_loss = 1.36930725, grad/param norm = 1.5228e-01, time/batch = 0.6267s	
4805/33650 (epoch 7.140), train_loss = 1.39285785, grad/param norm = 1.8201e-01, time/batch = 0.6396s	
4806/33650 (epoch 7.141), train_loss = 1.46317769, grad/param norm = 1.6858e-01, time/batch = 0.6328s	
4807/33650 (epoch 7.143), train_loss = 1.61237267, grad/param norm = 1.9276e-01, time/batch = 0.6323s	
4808/33650 (epoch 7.144), train_loss = 1.49130414, grad/param norm = 1.7416e-01, time/batch = 0.6271s	
4809/33650 (epoch 7.146), train_loss = 1.31885040, grad/param norm = 1.7735e-01, time/batch = 0.6643s	
4810/33650 (epoch 7.147), train_loss = 1.27377607, grad/param norm = 1.6621e-01, time/batch = 0.6693s	
4811/33650 (epoch 7.149), train_loss = 1.18071199, grad/param norm = 1.6574e-01, time/batch = 0.6417s	
4812/33650 (epoch 7.150), train_loss = 1.18410341, grad/param norm = 1.4388e-01, time/batch = 0.6510s	
4813/33650 (epoch 7.152), train_loss = 1.24349739, grad/param norm = 1.5003e-01, time/batch = 0.6301s	
4814/33650 (epoch 7.153), train_loss = 1.27897233, grad/param norm = 1.5480e-01, time/batch = 0.6317s	
4815/33650 (epoch 7.155), train_loss = 1.19600901, grad/param norm = 1.3885e-01, time/batch = 0.6285s	
4816/33650 (epoch 7.156), train_loss = 1.19312774, grad/param norm = 1.4238e-01, time/batch = 0.6310s	
4817/33650 (epoch 7.158), train_loss = 1.32261793, grad/param norm = 1.6700e-01, time/batch = 0.6262s	
4818/33650 (epoch 7.159), train_loss = 1.11850162, grad/param norm = 1.3512e-01, time/batch = 0.6269s	
4819/33650 (epoch 7.160), train_loss = 1.16844190, grad/param norm = 1.3552e-01, time/batch = 0.6276s	
4820/33650 (epoch 7.162), train_loss = 1.30652641, grad/param norm = 1.8024e-01, time/batch = 0.6293s	
4821/33650 (epoch 7.163), train_loss = 1.43014931, grad/param norm = 1.7501e-01, time/batch = 0.6332s	
4822/33650 (epoch 7.165), train_loss = 1.16934488, grad/param norm = 1.4379e-01, time/batch = 0.6244s	
4823/33650 (epoch 7.166), train_loss = 1.18592664, grad/param norm = 1.5087e-01, time/batch = 0.6250s	
4824/33650 (epoch 7.168), train_loss = 1.42576564, grad/param norm = 1.5708e-01, time/batch = 0.6259s	
4825/33650 (epoch 7.169), train_loss = 1.27287935, grad/param norm = 1.5399e-01, time/batch = 0.6269s	
4826/33650 (epoch 7.171), train_loss = 1.32931249, grad/param norm = 1.7704e-01, time/batch = 0.6263s	
4827/33650 (epoch 7.172), train_loss = 1.26160492, grad/param norm = 1.5992e-01, time/batch = 0.6296s	
4828/33650 (epoch 7.174), train_loss = 1.19546212, grad/param norm = 1.6114e-01, time/batch = 0.6276s	
4829/33650 (epoch 7.175), train_loss = 1.21075305, grad/param norm = 1.6027e-01, time/batch = 0.6296s	
4830/33650 (epoch 7.177), train_loss = 1.33566262, grad/param norm = 1.5372e-01, time/batch = 0.6280s	
4831/33650 (epoch 7.178), train_loss = 1.19924431, grad/param norm = 1.4826e-01, time/batch = 0.6300s	
4832/33650 (epoch 7.180), train_loss = 1.20599857, grad/param norm = 1.6100e-01, time/batch = 0.6286s	
4833/33650 (epoch 7.181), train_loss = 1.02362940, grad/param norm = 1.4169e-01, time/batch = 0.6353s	
4834/33650 (epoch 7.183), train_loss = 1.23732774, grad/param norm = 1.6821e-01, time/batch = 0.6310s	
4835/33650 (epoch 7.184), train_loss = 1.28304861, grad/param norm = 1.6867e-01, time/batch = 0.6335s	
4836/33650 (epoch 7.186), train_loss = 1.31583866, grad/param norm = 1.7088e-01, time/batch = 0.6298s	
4837/33650 (epoch 7.187), train_loss = 1.44494948, grad/param norm = 1.6708e-01, time/batch = 0.6292s	
4838/33650 (epoch 7.189), train_loss = 1.50928118, grad/param norm = 1.9381e-01, time/batch = 0.6295s	
4839/33650 (epoch 7.190), train_loss = 1.35881454, grad/param norm = 1.7418e-01, time/batch = 0.6271s	
4840/33650 (epoch 7.192), train_loss = 1.49631919, grad/param norm = 1.7553e-01, time/batch = 0.6286s	
4841/33650 (epoch 7.193), train_loss = 1.42907889, grad/param norm = 1.6190e-01, time/batch = 0.6311s	
4842/33650 (epoch 7.195), train_loss = 1.15972133, grad/param norm = 1.4780e-01, time/batch = 0.6282s	
4843/33650 (epoch 7.196), train_loss = 1.07772485, grad/param norm = 1.6216e-01, time/batch = 0.6273s	
4844/33650 (epoch 7.198), train_loss = 1.27121391, grad/param norm = 1.6568e-01, time/batch = 0.6299s	
4845/33650 (epoch 7.199), train_loss = 1.39740325, grad/param norm = 1.7375e-01, time/batch = 0.6280s	
4846/33650 (epoch 7.201), train_loss = 1.31830525, grad/param norm = 1.6622e-01, time/batch = 0.6276s	
4847/33650 (epoch 7.202), train_loss = 1.27449026, grad/param norm = 1.6302e-01, time/batch = 0.6262s	
4848/33650 (epoch 7.204), train_loss = 1.34182549, grad/param norm = 1.6177e-01, time/batch = 0.6258s	
4849/33650 (epoch 7.205), train_loss = 1.23532212, grad/param norm = 1.7352e-01, time/batch = 0.6264s	
4850/33650 (epoch 7.207), train_loss = 1.29117416, grad/param norm = 1.5909e-01, time/batch = 0.6599s	
4851/33650 (epoch 7.208), train_loss = 1.25358913, grad/param norm = 1.6307e-01, time/batch = 0.6656s	
4852/33650 (epoch 7.210), train_loss = 1.01865445, grad/param norm = 1.4481e-01, time/batch = 0.6608s	
4853/33650 (epoch 7.211), train_loss = 1.20217571, grad/param norm = 1.7090e-01, time/batch = 0.6582s	
4854/33650 (epoch 7.212), train_loss = 1.40537128, grad/param norm = 1.7604e-01, time/batch = 0.6459s	
4855/33650 (epoch 7.214), train_loss = 1.45616136, grad/param norm = 1.6991e-01, time/batch = 0.6356s	
4856/33650 (epoch 7.215), train_loss = 1.05505350, grad/param norm = 1.5784e-01, time/batch = 0.6284s	
4857/33650 (epoch 7.217), train_loss = 1.29371545, grad/param norm = 1.6451e-01, time/batch = 0.6249s	
4858/33650 (epoch 7.218), train_loss = 1.37745040, grad/param norm = 1.6067e-01, time/batch = 0.6367s	
4859/33650 (epoch 7.220), train_loss = 1.21479328, grad/param norm = 1.7056e-01, time/batch = 0.6324s	
4860/33650 (epoch 7.221), train_loss = 1.47799656, grad/param norm = 1.7191e-01, time/batch = 0.6292s	
4861/33650 (epoch 7.223), train_loss = 1.02114419, grad/param norm = 1.4570e-01, time/batch = 0.6307s	
4862/33650 (epoch 7.224), train_loss = 1.29429569, grad/param norm = 1.8362e-01, time/batch = 0.6278s	
4863/33650 (epoch 7.226), train_loss = 1.66262739, grad/param norm = 2.1458e-01, time/batch = 0.6253s	
4864/33650 (epoch 7.227), train_loss = 1.45742042, grad/param norm = 1.6477e-01, time/batch = 0.6257s	
4865/33650 (epoch 7.229), train_loss = 1.42475858, grad/param norm = 1.6795e-01, time/batch = 0.6368s	
4866/33650 (epoch 7.230), train_loss = 1.55542599, grad/param norm = 1.9706e-01, time/batch = 0.6674s	
4867/33650 (epoch 7.232), train_loss = 1.36845298, grad/param norm = 1.7384e-01, time/batch = 0.6406s	
4868/33650 (epoch 7.233), train_loss = 1.37661231, grad/param norm = 1.8698e-01, time/batch = 0.6311s	
4869/33650 (epoch 7.235), train_loss = 1.26517857, grad/param norm = 1.5472e-01, time/batch = 0.6252s	
4870/33650 (epoch 7.236), train_loss = 1.14551375, grad/param norm = 1.6255e-01, time/batch = 0.6257s	
4871/33650 (epoch 7.238), train_loss = 1.26090911, grad/param norm = 1.5059e-01, time/batch = 0.6280s	
4872/33650 (epoch 7.239), train_loss = 1.18302196, grad/param norm = 1.5636e-01, time/batch = 0.6351s	
4873/33650 (epoch 7.241), train_loss = 1.23558448, grad/param norm = 1.4905e-01, time/batch = 0.6435s	
4874/33650 (epoch 7.242), train_loss = 1.09592547, grad/param norm = 1.4444e-01, time/batch = 0.6356s	
4875/33650 (epoch 7.244), train_loss = 1.28698439, grad/param norm = 1.5249e-01, time/batch = 0.6473s	
4876/33650 (epoch 7.245), train_loss = 1.12613340, grad/param norm = 1.4803e-01, time/batch = 0.6424s	
4877/33650 (epoch 7.247), train_loss = 1.28569077, grad/param norm = 1.8006e-01, time/batch = 0.6341s	
4878/33650 (epoch 7.248), train_loss = 1.23071089, grad/param norm = 1.6742e-01, time/batch = 0.6368s	
4879/33650 (epoch 7.250), train_loss = 1.29483106, grad/param norm = 1.5279e-01, time/batch = 0.6448s	
4880/33650 (epoch 7.251), train_loss = 1.44843015, grad/param norm = 1.6060e-01, time/batch = 0.6369s	
4881/33650 (epoch 7.253), train_loss = 1.14258862, grad/param norm = 1.4442e-01, time/batch = 0.6464s	
4882/33650 (epoch 7.254), train_loss = 1.16305634, grad/param norm = 1.4434e-01, time/batch = 0.6360s	
4883/33650 (epoch 7.256), train_loss = 1.36235695, grad/param norm = 1.5584e-01, time/batch = 0.6270s	
4884/33650 (epoch 7.257), train_loss = 1.51146922, grad/param norm = 1.6758e-01, time/batch = 0.6260s	
4885/33650 (epoch 7.259), train_loss = 1.08119655, grad/param norm = 1.4636e-01, time/batch = 0.6270s	
4886/33650 (epoch 7.260), train_loss = 1.46527668, grad/param norm = 1.7438e-01, time/batch = 0.6650s	
4887/33650 (epoch 7.262), train_loss = 1.37278482, grad/param norm = 1.7089e-01, time/batch = 0.6476s	
4888/33650 (epoch 7.263), train_loss = 1.32826433, grad/param norm = 1.9453e-01, time/batch = 0.6303s	
4889/33650 (epoch 7.264), train_loss = 1.30316661, grad/param norm = 1.6868e-01, time/batch = 0.6352s	
4890/33650 (epoch 7.266), train_loss = 1.27777435, grad/param norm = 1.6168e-01, time/batch = 0.6294s	
4891/33650 (epoch 7.267), train_loss = 1.24941462, grad/param norm = 1.8417e-01, time/batch = 0.6306s	
4892/33650 (epoch 7.269), train_loss = 1.36776645, grad/param norm = 1.6486e-01, time/batch = 0.6267s	
4893/33650 (epoch 7.270), train_loss = 1.20884137, grad/param norm = 1.4828e-01, time/batch = 0.6253s	
4894/33650 (epoch 7.272), train_loss = 1.29537190, grad/param norm = 1.5435e-01, time/batch = 0.6268s	
4895/33650 (epoch 7.273), train_loss = 1.50271084, grad/param norm = 1.9077e-01, time/batch = 0.6328s	
4896/33650 (epoch 7.275), train_loss = 1.41720885, grad/param norm = 1.7436e-01, time/batch = 0.6239s	
4897/33650 (epoch 7.276), train_loss = 1.46171293, grad/param norm = 1.7188e-01, time/batch = 0.6267s	
4898/33650 (epoch 7.278), train_loss = 1.59852069, grad/param norm = 1.9487e-01, time/batch = 0.6256s	
4899/33650 (epoch 7.279), train_loss = 1.22744376, grad/param norm = 1.7385e-01, time/batch = 0.6260s	
4900/33650 (epoch 7.281), train_loss = 1.34293646, grad/param norm = 1.8003e-01, time/batch = 0.6262s	
4901/33650 (epoch 7.282), train_loss = 1.40812365, grad/param norm = 1.5327e-01, time/batch = 0.6282s	
4902/33650 (epoch 7.284), train_loss = 1.42438879, grad/param norm = 1.7782e-01, time/batch = 0.6376s	
4903/33650 (epoch 7.285), train_loss = 1.43341340, grad/param norm = 1.7692e-01, time/batch = 0.6401s	
4904/33650 (epoch 7.287), train_loss = 1.29522108, grad/param norm = 1.6841e-01, time/batch = 0.6452s	
4905/33650 (epoch 7.288), train_loss = 1.36626381, grad/param norm = 1.8252e-01, time/batch = 0.6510s	
4906/33650 (epoch 7.290), train_loss = 1.30205155, grad/param norm = 1.4673e-01, time/batch = 0.6514s	
4907/33650 (epoch 7.291), train_loss = 1.17878608, grad/param norm = 1.4712e-01, time/batch = 0.6766s	
4908/33650 (epoch 7.293), train_loss = 1.31586676, grad/param norm = 1.7782e-01, time/batch = 0.6638s	
4909/33650 (epoch 7.294), train_loss = 1.16881744, grad/param norm = 1.5001e-01, time/batch = 0.6272s	
4910/33650 (epoch 7.296), train_loss = 1.15180513, grad/param norm = 1.6579e-01, time/batch = 0.6444s	
4911/33650 (epoch 7.297), train_loss = 1.32664647, grad/param norm = 1.6010e-01, time/batch = 0.6309s	
4912/33650 (epoch 7.299), train_loss = 1.18198600, grad/param norm = 1.5649e-01, time/batch = 0.6258s	
4913/33650 (epoch 7.300), train_loss = 1.24321429, grad/param norm = 1.5440e-01, time/batch = 0.6264s	
4914/33650 (epoch 7.302), train_loss = 1.27181634, grad/param norm = 1.4675e-01, time/batch = 0.6276s	
4915/33650 (epoch 7.303), train_loss = 1.29561868, grad/param norm = 1.4622e-01, time/batch = 0.6257s	
4916/33650 (epoch 7.305), train_loss = 1.33753802, grad/param norm = 1.5777e-01, time/batch = 0.6264s	
4917/33650 (epoch 7.306), train_loss = 1.21871530, grad/param norm = 1.4100e-01, time/batch = 0.6344s	
4918/33650 (epoch 7.308), train_loss = 1.23649755, grad/param norm = 1.6492e-01, time/batch = 0.6238s	
4919/33650 (epoch 7.309), train_loss = 1.47370807, grad/param norm = 1.6900e-01, time/batch = 0.6284s	
4920/33650 (epoch 7.311), train_loss = 1.36437973, grad/param norm = 1.6048e-01, time/batch = 0.6266s	
4921/33650 (epoch 7.312), train_loss = 1.25539506, grad/param norm = 1.5559e-01, time/batch = 0.6278s	
4922/33650 (epoch 7.314), train_loss = 1.08318627, grad/param norm = 1.3356e-01, time/batch = 0.6275s	
4923/33650 (epoch 7.315), train_loss = 1.31855615, grad/param norm = 1.6191e-01, time/batch = 0.6272s	
4924/33650 (epoch 7.316), train_loss = 1.28678512, grad/param norm = 1.6597e-01, time/batch = 0.6304s	
4925/33650 (epoch 7.318), train_loss = 1.16169131, grad/param norm = 1.3716e-01, time/batch = 0.6268s	
4926/33650 (epoch 7.319), train_loss = 1.20246308, grad/param norm = 1.4189e-01, time/batch = 0.6321s	
4927/33650 (epoch 7.321), train_loss = 1.24090938, grad/param norm = 1.4771e-01, time/batch = 0.6664s	
4928/33650 (epoch 7.322), train_loss = 1.34790740, grad/param norm = 1.8056e-01, time/batch = 0.6422s	
4929/33650 (epoch 7.324), train_loss = 1.40164806, grad/param norm = 1.8530e-01, time/batch = 0.6282s	
4930/33650 (epoch 7.325), train_loss = 1.35012900, grad/param norm = 1.5931e-01, time/batch = 0.6274s	
4931/33650 (epoch 7.327), train_loss = 1.13363121, grad/param norm = 1.5654e-01, time/batch = 0.6314s	
4932/33650 (epoch 7.328), train_loss = 1.38624349, grad/param norm = 1.6900e-01, time/batch = 0.6257s	
4933/33650 (epoch 7.330), train_loss = 1.17139050, grad/param norm = 1.3959e-01, time/batch = 0.6265s	
4934/33650 (epoch 7.331), train_loss = 1.09776070, grad/param norm = 1.4063e-01, time/batch = 0.6268s	
4935/33650 (epoch 7.333), train_loss = 1.26721722, grad/param norm = 1.4894e-01, time/batch = 0.6262s	
4936/33650 (epoch 7.334), train_loss = 1.28610405, grad/param norm = 1.5800e-01, time/batch = 0.6311s	
4937/33650 (epoch 7.336), train_loss = 1.36734733, grad/param norm = 1.5095e-01, time/batch = 0.6257s	
4938/33650 (epoch 7.337), train_loss = 1.05531915, grad/param norm = 1.3835e-01, time/batch = 0.6279s	
4939/33650 (epoch 7.339), train_loss = 1.25137613, grad/param norm = 1.5099e-01, time/batch = 0.6279s	
4940/33650 (epoch 7.340), train_loss = 1.57416749, grad/param norm = 1.8864e-01, time/batch = 0.6268s	
4941/33650 (epoch 7.342), train_loss = 1.03396395, grad/param norm = 1.3945e-01, time/batch = 0.6303s	
4942/33650 (epoch 7.343), train_loss = 1.37803827, grad/param norm = 1.8862e-01, time/batch = 0.6275s	
4943/33650 (epoch 7.345), train_loss = 1.25453732, grad/param norm = 1.5614e-01, time/batch = 0.6272s	
4944/33650 (epoch 7.346), train_loss = 0.95848403, grad/param norm = 1.5754e-01, time/batch = 0.6264s	
4945/33650 (epoch 7.348), train_loss = 1.13505658, grad/param norm = 1.5105e-01, time/batch = 0.6266s	
4946/33650 (epoch 7.349), train_loss = 1.08530093, grad/param norm = 1.6065e-01, time/batch = 0.6339s	
4947/33650 (epoch 7.351), train_loss = 1.38632359, grad/param norm = 1.8317e-01, time/batch = 0.6284s	
4948/33650 (epoch 7.352), train_loss = 1.23671300, grad/param norm = 1.5162e-01, time/batch = 0.6279s	
4949/33650 (epoch 7.354), train_loss = 1.58725467, grad/param norm = 1.8564e-01, time/batch = 0.6294s	
4950/33650 (epoch 7.355), train_loss = 1.37038925, grad/param norm = 1.6157e-01, time/batch = 0.6297s	
4951/33650 (epoch 7.357), train_loss = 1.07744428, grad/param norm = 1.3478e-01, time/batch = 0.6316s	
4952/33650 (epoch 7.358), train_loss = 1.39906434, grad/param norm = 1.6968e-01, time/batch = 0.6636s	
4953/33650 (epoch 7.360), train_loss = 1.38804091, grad/param norm = 1.6350e-01, time/batch = 0.6508s	
4954/33650 (epoch 7.361), train_loss = 1.28551203, grad/param norm = 1.5063e-01, time/batch = 0.6291s	
4955/33650 (epoch 7.363), train_loss = 1.19124951, grad/param norm = 1.4514e-01, time/batch = 0.6299s	
4956/33650 (epoch 7.364), train_loss = 1.27626959, grad/param norm = 1.5525e-01, time/batch = 0.6289s	
4957/33650 (epoch 7.366), train_loss = 1.31890635, grad/param norm = 1.6702e-01, time/batch = 0.6269s	
4958/33650 (epoch 7.367), train_loss = 1.38472439, grad/param norm = 1.6194e-01, time/batch = 0.6286s	
4959/33650 (epoch 7.368), train_loss = 1.17480688, grad/param norm = 1.6328e-01, time/batch = 0.6467s	
4960/33650 (epoch 7.370), train_loss = 1.30169241, grad/param norm = 1.5475e-01, time/batch = 0.6336s	
4961/33650 (epoch 7.371), train_loss = 1.07091747, grad/param norm = 1.5292e-01, time/batch = 0.6316s	
4962/33650 (epoch 7.373), train_loss = 1.19297150, grad/param norm = 1.5142e-01, time/batch = 0.6275s	
4963/33650 (epoch 7.374), train_loss = 1.07822068, grad/param norm = 1.3862e-01, time/batch = 0.6270s	
4964/33650 (epoch 7.376), train_loss = 1.24120116, grad/param norm = 1.6286e-01, time/batch = 0.6276s	
4965/33650 (epoch 7.377), train_loss = 1.34390986, grad/param norm = 1.7113e-01, time/batch = 0.6399s	
4966/33650 (epoch 7.379), train_loss = 1.32016831, grad/param norm = 1.4346e-01, time/batch = 0.6423s	
4967/33650 (epoch 7.380), train_loss = 1.05634941, grad/param norm = 1.6481e-01, time/batch = 0.6458s	
4968/33650 (epoch 7.382), train_loss = 1.07865081, grad/param norm = 1.3106e-01, time/batch = 0.6699s	
4969/33650 (epoch 7.383), train_loss = 1.22783425, grad/param norm = 1.5736e-01, time/batch = 0.6400s	
4970/33650 (epoch 7.385), train_loss = 1.42010185, grad/param norm = 1.6527e-01, time/batch = 0.6286s	
4971/33650 (epoch 7.386), train_loss = 1.19513702, grad/param norm = 1.5600e-01, time/batch = 0.6288s	
4972/33650 (epoch 7.388), train_loss = 1.27253277, grad/param norm = 1.4744e-01, time/batch = 0.6281s	
4973/33650 (epoch 7.389), train_loss = 1.31101797, grad/param norm = 1.6728e-01, time/batch = 0.6273s	
4974/33650 (epoch 7.391), train_loss = 1.07828403, grad/param norm = 1.4179e-01, time/batch = 0.6299s	
4975/33650 (epoch 7.392), train_loss = 1.39810172, grad/param norm = 1.7450e-01, time/batch = 0.6268s	
4976/33650 (epoch 7.394), train_loss = 1.42638761, grad/param norm = 1.8820e-01, time/batch = 0.6276s	
4977/33650 (epoch 7.395), train_loss = 1.27394907, grad/param norm = 1.6659e-01, time/batch = 0.6312s	
4978/33650 (epoch 7.397), train_loss = 1.48273598, grad/param norm = 1.7961e-01, time/batch = 0.6348s	
4979/33650 (epoch 7.398), train_loss = 1.26368973, grad/param norm = 1.3687e-01, time/batch = 0.6316s	
4980/33650 (epoch 7.400), train_loss = 1.31964716, grad/param norm = 1.8360e-01, time/batch = 0.6266s	
4981/33650 (epoch 7.401), train_loss = 1.31860370, grad/param norm = 1.6826e-01, time/batch = 0.6295s	
4982/33650 (epoch 7.403), train_loss = 1.35972681, grad/param norm = 1.7137e-01, time/batch = 0.6289s	
4983/33650 (epoch 7.404), train_loss = 1.24625118, grad/param norm = 1.3326e-01, time/batch = 0.6276s	
4984/33650 (epoch 7.406), train_loss = 1.32872505, grad/param norm = 1.5746e-01, time/batch = 0.6655s	
4985/33650 (epoch 7.407), train_loss = 1.29045343, grad/param norm = 1.5916e-01, time/batch = 0.6252s	
4986/33650 (epoch 7.409), train_loss = 1.30724506, grad/param norm = 1.5376e-01, time/batch = 0.6373s	
4987/33650 (epoch 7.410), train_loss = 1.28783216, grad/param norm = 1.6908e-01, time/batch = 0.6399s	
4988/33650 (epoch 7.412), train_loss = 1.26195512, grad/param norm = 1.4426e-01, time/batch = 0.6322s	
4989/33650 (epoch 7.413), train_loss = 1.16912334, grad/param norm = 1.4833e-01, time/batch = 0.6434s	
4990/33650 (epoch 7.415), train_loss = 1.32571236, grad/param norm = 1.6073e-01, time/batch = 0.6376s	
4991/33650 (epoch 7.416), train_loss = 1.48610317, grad/param norm = 1.8020e-01, time/batch = 0.6377s	
4992/33650 (epoch 7.418), train_loss = 1.31067818, grad/param norm = 1.6126e-01, time/batch = 0.6370s	
4993/33650 (epoch 7.419), train_loss = 1.22151583, grad/param norm = 1.5343e-01, time/batch = 0.6323s	
4994/33650 (epoch 7.421), train_loss = 1.17277898, grad/param norm = 1.4064e-01, time/batch = 0.6425s	
4995/33650 (epoch 7.422), train_loss = 1.40341689, grad/param norm = 1.7306e-01, time/batch = 0.6449s	
4996/33650 (epoch 7.423), train_loss = 1.14519222, grad/param norm = 1.4713e-01, time/batch = 0.6580s	
4997/33650 (epoch 7.425), train_loss = 1.34003948, grad/param norm = 1.7149e-01, time/batch = 0.6415s	
4998/33650 (epoch 7.426), train_loss = 1.42847766, grad/param norm = 1.6043e-01, time/batch = 0.6523s	
4999/33650 (epoch 7.428), train_loss = 1.21393282, grad/param norm = 1.5593e-01, time/batch = 0.6512s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch7.43_1.5371.t7	
5000/33650 (epoch 7.429), train_loss = 1.38476547, grad/param norm = 1.5773e-01, time/batch = 0.6378s	
5001/33650 (epoch 7.431), train_loss = 1.63509441, grad/param norm = 1.8123e-01, time/batch = 0.6547s	
5002/33650 (epoch 7.432), train_loss = 1.58563094, grad/param norm = 1.7080e-01, time/batch = 0.6296s	
5003/33650 (epoch 7.434), train_loss = 1.35912956, grad/param norm = 1.5671e-01, time/batch = 0.6635s	
5004/33650 (epoch 7.435), train_loss = 1.33802120, grad/param norm = 1.6572e-01, time/batch = 0.6532s	
5005/33650 (epoch 7.437), train_loss = 1.37323763, grad/param norm = 1.7599e-01, time/batch = 0.6349s	
5006/33650 (epoch 7.438), train_loss = 1.24809447, grad/param norm = 1.7251e-01, time/batch = 0.6325s	
5007/33650 (epoch 7.440), train_loss = 1.32588646, grad/param norm = 1.6555e-01, time/batch = 0.6324s	
5008/33650 (epoch 7.441), train_loss = 1.37149506, grad/param norm = 1.6248e-01, time/batch = 0.6375s	
5009/33650 (epoch 7.443), train_loss = 1.37655993, grad/param norm = 1.7717e-01, time/batch = 0.6318s	
5010/33650 (epoch 7.444), train_loss = 1.24305446, grad/param norm = 1.4415e-01, time/batch = 0.6364s	
5011/33650 (epoch 7.446), train_loss = 1.34962079, grad/param norm = 1.7096e-01, time/batch = 0.6288s	
5012/33650 (epoch 7.447), train_loss = 1.41573295, grad/param norm = 1.7925e-01, time/batch = 0.6275s	
5013/33650 (epoch 7.449), train_loss = 1.55249593, grad/param norm = 2.0745e-01, time/batch = 0.6266s	
5014/33650 (epoch 7.450), train_loss = 1.55061303, grad/param norm = 1.8912e-01, time/batch = 0.6273s	
5015/33650 (epoch 7.452), train_loss = 1.62959684, grad/param norm = 1.8326e-01, time/batch = 0.6321s	
5016/33650 (epoch 7.453), train_loss = 1.51121192, grad/param norm = 1.8222e-01, time/batch = 0.6289s	
5017/33650 (epoch 7.455), train_loss = 1.29333090, grad/param norm = 1.4931e-01, time/batch = 0.6269s	
5018/33650 (epoch 7.456), train_loss = 1.27508842, grad/param norm = 1.5410e-01, time/batch = 0.6276s	
5019/33650 (epoch 7.458), train_loss = 1.31348517, grad/param norm = 1.6544e-01, time/batch = 0.6277s	
5020/33650 (epoch 7.459), train_loss = 1.28797753, grad/param norm = 1.6848e-01, time/batch = 0.6261s	
5021/33650 (epoch 7.461), train_loss = 1.46745636, grad/param norm = 1.7159e-01, time/batch = 0.6275s	
5022/33650 (epoch 7.462), train_loss = 1.43340881, grad/param norm = 1.7053e-01, time/batch = 0.6290s	
5023/33650 (epoch 7.464), train_loss = 1.25786128, grad/param norm = 1.7655e-01, time/batch = 0.6417s	
5024/33650 (epoch 7.465), train_loss = 1.36079071, grad/param norm = 1.7659e-01, time/batch = 0.6286s	
5025/33650 (epoch 7.467), train_loss = 1.39328348, grad/param norm = 1.7025e-01, time/batch = 0.6258s	
5026/33650 (epoch 7.468), train_loss = 1.45802799, grad/param norm = 1.6515e-01, time/batch = 0.6263s	
5027/33650 (epoch 7.470), train_loss = 1.61137359, grad/param norm = 1.8525e-01, time/batch = 0.6261s	
5028/33650 (epoch 7.471), train_loss = 1.31059020, grad/param norm = 1.7473e-01, time/batch = 0.6537s	
5029/33650 (epoch 7.473), train_loss = 1.25310792, grad/param norm = 1.4685e-01, time/batch = 0.6596s	
5030/33650 (epoch 7.474), train_loss = 1.36936748, grad/param norm = 1.6143e-01, time/batch = 0.6245s	
5031/33650 (epoch 7.475), train_loss = 1.42374075, grad/param norm = 1.7376e-01, time/batch = 0.6278s	
5032/33650 (epoch 7.477), train_loss = 1.45693577, grad/param norm = 1.6850e-01, time/batch = 0.6303s	
5033/33650 (epoch 7.478), train_loss = 1.42627346, grad/param norm = 1.7071e-01, time/batch = 0.6323s	
5034/33650 (epoch 7.480), train_loss = 1.48857336, grad/param norm = 1.7184e-01, time/batch = 0.6310s	
5035/33650 (epoch 7.481), train_loss = 1.45223994, grad/param norm = 1.8133e-01, time/batch = 0.6332s	
5036/33650 (epoch 7.483), train_loss = 1.07460021, grad/param norm = 1.5313e-01, time/batch = 0.6378s	
5037/33650 (epoch 7.484), train_loss = 1.34778280, grad/param norm = 1.5752e-01, time/batch = 0.6326s	
5038/33650 (epoch 7.486), train_loss = 1.47612743, grad/param norm = 2.0590e-01, time/batch = 0.6270s	
5039/33650 (epoch 7.487), train_loss = 1.44566323, grad/param norm = 1.8674e-01, time/batch = 0.6261s	
5040/33650 (epoch 7.489), train_loss = 1.54788791, grad/param norm = 1.7185e-01, time/batch = 0.6261s	
5041/33650 (epoch 7.490), train_loss = 1.22696538, grad/param norm = 1.5785e-01, time/batch = 0.6314s	
5042/33650 (epoch 7.492), train_loss = 1.42548138, grad/param norm = 1.8871e-01, time/batch = 0.6277s	
5043/33650 (epoch 7.493), train_loss = 1.07409879, grad/param norm = 1.4051e-01, time/batch = 0.6288s	
5044/33650 (epoch 7.495), train_loss = 1.32496205, grad/param norm = 1.6454e-01, time/batch = 0.6652s	
5045/33650 (epoch 7.496), train_loss = 1.38471608, grad/param norm = 1.7928e-01, time/batch = 0.6484s	
5046/33650 (epoch 7.498), train_loss = 1.14097916, grad/param norm = 1.4756e-01, time/batch = 0.6260s	
5047/33650 (epoch 7.499), train_loss = 1.28180999, grad/param norm = 1.4760e-01, time/batch = 0.6268s	
5048/33650 (epoch 7.501), train_loss = 1.25009526, grad/param norm = 1.4227e-01, time/batch = 0.6268s	
5049/33650 (epoch 7.502), train_loss = 1.38010455, grad/param norm = 1.6529e-01, time/batch = 0.6262s	
5050/33650 (epoch 7.504), train_loss = 1.51818683, grad/param norm = 1.7777e-01, time/batch = 0.6272s	
5051/33650 (epoch 7.505), train_loss = 1.37438197, grad/param norm = 1.9815e-01, time/batch = 0.6310s	
5052/33650 (epoch 7.507), train_loss = 1.46740597, grad/param norm = 1.7834e-01, time/batch = 0.6288s	
5053/33650 (epoch 7.508), train_loss = 1.25962379, grad/param norm = 1.6458e-01, time/batch = 0.6276s	
5054/33650 (epoch 7.510), train_loss = 1.31736119, grad/param norm = 1.6432e-01, time/batch = 0.6258s	
5055/33650 (epoch 7.511), train_loss = 1.61151072, grad/param norm = 1.9330e-01, time/batch = 0.6267s	
5056/33650 (epoch 7.513), train_loss = 1.39895111, grad/param norm = 1.5760e-01, time/batch = 0.6439s	
5057/33650 (epoch 7.514), train_loss = 1.40872901, grad/param norm = 1.7248e-01, time/batch = 0.6396s	
5058/33650 (epoch 7.516), train_loss = 1.35422522, grad/param norm = 2.3329e-01, time/batch = 0.6312s	
5059/33650 (epoch 7.517), train_loss = 1.28389462, grad/param norm = 1.5968e-01, time/batch = 0.6284s	
5060/33650 (epoch 7.519), train_loss = 1.31598945, grad/param norm = 1.5523e-01, time/batch = 0.6263s	
5061/33650 (epoch 7.520), train_loss = 1.13569719, grad/param norm = 1.5200e-01, time/batch = 0.6297s	
5062/33650 (epoch 7.522), train_loss = 1.33339548, grad/param norm = 1.7421e-01, time/batch = 0.6271s	
5063/33650 (epoch 7.523), train_loss = 1.32192247, grad/param norm = 1.5625e-01, time/batch = 0.6274s	
5064/33650 (epoch 7.525), train_loss = 1.03239756, grad/param norm = 1.4047e-01, time/batch = 0.6479s	
5065/33650 (epoch 7.526), train_loss = 1.35322798, grad/param norm = 1.5244e-01, time/batch = 0.6661s	
5066/33650 (epoch 7.527), train_loss = 1.18333860, grad/param norm = 1.4576e-01, time/batch = 0.6299s	
5067/33650 (epoch 7.529), train_loss = 1.29239878, grad/param norm = 1.4608e-01, time/batch = 0.6466s	
5068/33650 (epoch 7.530), train_loss = 1.23740102, grad/param norm = 1.5271e-01, time/batch = 0.6365s	
5069/33650 (epoch 7.532), train_loss = 1.54607734, grad/param norm = 1.9445e-01, time/batch = 0.6266s	
5070/33650 (epoch 7.533), train_loss = 1.27957752, grad/param norm = 1.6211e-01, time/batch = 0.6266s	
5071/33650 (epoch 7.535), train_loss = 1.44305767, grad/param norm = 1.6277e-01, time/batch = 0.6275s	
5072/33650 (epoch 7.536), train_loss = 1.36197951, grad/param norm = 1.6502e-01, time/batch = 0.6295s	
5073/33650 (epoch 7.538), train_loss = 1.36462024, grad/param norm = 1.7947e-01, time/batch = 0.6290s	
5074/33650 (epoch 7.539), train_loss = 1.10581426, grad/param norm = 1.4857e-01, time/batch = 0.6282s	
5075/33650 (epoch 7.541), train_loss = 1.46667431, grad/param norm = 1.6742e-01, time/batch = 0.6275s	
5076/33650 (epoch 7.542), train_loss = 1.37067040, grad/param norm = 1.7883e-01, time/batch = 0.6287s	
5077/33650 (epoch 7.544), train_loss = 1.60392305, grad/param norm = 1.8295e-01, time/batch = 0.6274s	
5078/33650 (epoch 7.545), train_loss = 1.15360750, grad/param norm = 1.5428e-01, time/batch = 0.6264s	
5079/33650 (epoch 7.547), train_loss = 1.33147200, grad/param norm = 1.5712e-01, time/batch = 0.6281s	
5080/33650 (epoch 7.548), train_loss = 1.44982764, grad/param norm = 1.6885e-01, time/batch = 0.6326s	
5081/33650 (epoch 7.550), train_loss = 1.27580382, grad/param norm = 1.5755e-01, time/batch = 0.6307s	
5082/33650 (epoch 7.551), train_loss = 1.28966555, grad/param norm = 1.5565e-01, time/batch = 0.6487s	
5083/33650 (epoch 7.553), train_loss = 1.09597619, grad/param norm = 1.5177e-01, time/batch = 0.6430s	
5084/33650 (epoch 7.554), train_loss = 1.45018821, grad/param norm = 1.7699e-01, time/batch = 0.6746s	
5085/33650 (epoch 7.556), train_loss = 1.48108988, grad/param norm = 2.2203e-01, time/batch = 0.6677s	
5086/33650 (epoch 7.557), train_loss = 1.53491028, grad/param norm = 1.9285e-01, time/batch = 0.6459s	
5087/33650 (epoch 7.559), train_loss = 1.60317873, grad/param norm = 2.1168e-01, time/batch = 0.6297s	
5088/33650 (epoch 7.560), train_loss = 1.55619560, grad/param norm = 1.6973e-01, time/batch = 0.6271s	
5089/33650 (epoch 7.562), train_loss = 1.41555675, grad/param norm = 1.6805e-01, time/batch = 0.6270s	
5090/33650 (epoch 7.563), train_loss = 1.30220170, grad/param norm = 1.6761e-01, time/batch = 0.6302s	
5091/33650 (epoch 7.565), train_loss = 1.35376036, grad/param norm = 1.5776e-01, time/batch = 0.6310s	
5092/33650 (epoch 7.566), train_loss = 1.35199307, grad/param norm = 1.6915e-01, time/batch = 0.6337s	
5093/33650 (epoch 7.568), train_loss = 1.33490227, grad/param norm = 1.5865e-01, time/batch = 0.6289s	
5094/33650 (epoch 7.569), train_loss = 1.26871812, grad/param norm = 1.5690e-01, time/batch = 0.6289s	
5095/33650 (epoch 7.571), train_loss = 1.46835804, grad/param norm = 1.7985e-01, time/batch = 0.6429s	
5096/33650 (epoch 7.572), train_loss = 1.37076755, grad/param norm = 1.5054e-01, time/batch = 0.6310s	
5097/33650 (epoch 7.574), train_loss = 1.32233738, grad/param norm = 1.5668e-01, time/batch = 0.6285s	
5098/33650 (epoch 7.575), train_loss = 1.31422563, grad/param norm = 1.5467e-01, time/batch = 0.6288s	
5099/33650 (epoch 7.577), train_loss = 1.41905096, grad/param norm = 1.7014e-01, time/batch = 0.6300s	
5100/33650 (epoch 7.578), train_loss = 1.34169879, grad/param norm = 1.5978e-01, time/batch = 0.6308s	
5101/33650 (epoch 7.579), train_loss = 1.40564869, grad/param norm = 1.6069e-01, time/batch = 0.6344s	
5102/33650 (epoch 7.581), train_loss = 1.39765717, grad/param norm = 1.5836e-01, time/batch = 0.6257s	
5103/33650 (epoch 7.582), train_loss = 1.43141014, grad/param norm = 1.6739e-01, time/batch = 0.6345s	
5104/33650 (epoch 7.584), train_loss = 1.33424079, grad/param norm = 1.5734e-01, time/batch = 0.6403s	
5105/33650 (epoch 7.585), train_loss = 1.35150343, grad/param norm = 1.6769e-01, time/batch = 0.6572s	
5106/33650 (epoch 7.587), train_loss = 1.22877453, grad/param norm = 1.5620e-01, time/batch = 0.6556s	
5107/33650 (epoch 7.588), train_loss = 1.30371838, grad/param norm = 1.6647e-01, time/batch = 0.6272s	
5108/33650 (epoch 7.590), train_loss = 1.29965144, grad/param norm = 1.5723e-01, time/batch = 0.6290s	
5109/33650 (epoch 7.591), train_loss = 1.30941093, grad/param norm = 1.7105e-01, time/batch = 0.6286s	
5110/33650 (epoch 7.593), train_loss = 1.19510030, grad/param norm = 1.4593e-01, time/batch = 0.6265s	
5111/33650 (epoch 7.594), train_loss = 1.08751405, grad/param norm = 1.5900e-01, time/batch = 0.6281s	
5112/33650 (epoch 7.596), train_loss = 1.26367451, grad/param norm = 1.4976e-01, time/batch = 0.6263s	
5113/33650 (epoch 7.597), train_loss = 1.05887683, grad/param norm = 1.2528e-01, time/batch = 0.6263s	
5114/33650 (epoch 7.599), train_loss = 1.21558149, grad/param norm = 1.5754e-01, time/batch = 0.6264s	
5115/33650 (epoch 7.600), train_loss = 1.14927605, grad/param norm = 1.5329e-01, time/batch = 0.6258s	
5116/33650 (epoch 7.602), train_loss = 1.40806927, grad/param norm = 1.5873e-01, time/batch = 0.6325s	
5117/33650 (epoch 7.603), train_loss = 1.23531229, grad/param norm = 1.5533e-01, time/batch = 0.6247s	
5118/33650 (epoch 7.605), train_loss = 1.30639206, grad/param norm = 1.6523e-01, time/batch = 0.6303s	
5119/33650 (epoch 7.606), train_loss = 1.42524851, grad/param norm = 1.6766e-01, time/batch = 0.6380s	
5120/33650 (epoch 7.608), train_loss = 1.28745519, grad/param norm = 1.5534e-01, time/batch = 0.6599s	
5121/33650 (epoch 7.609), train_loss = 1.36562192, grad/param norm = 1.7434e-01, time/batch = 0.6594s	
5122/33650 (epoch 7.611), train_loss = 1.18359172, grad/param norm = 1.4989e-01, time/batch = 0.6619s	
5123/33650 (epoch 7.612), train_loss = 1.30870871, grad/param norm = 1.6629e-01, time/batch = 0.6471s	
5124/33650 (epoch 7.614), train_loss = 1.40055552, grad/param norm = 1.6526e-01, time/batch = 0.6297s	
5125/33650 (epoch 7.615), train_loss = 1.25205686, grad/param norm = 1.4968e-01, time/batch = 0.6457s	
5126/33650 (epoch 7.617), train_loss = 1.14897569, grad/param norm = 1.3704e-01, time/batch = 0.6658s	
5127/33650 (epoch 7.618), train_loss = 1.23935430, grad/param norm = 1.5015e-01, time/batch = 0.6278s	
5128/33650 (epoch 7.620), train_loss = 1.39967803, grad/param norm = 1.7591e-01, time/batch = 0.6257s	
5129/33650 (epoch 7.621), train_loss = 1.15565538, grad/param norm = 1.4509e-01, time/batch = 0.6265s	
5130/33650 (epoch 7.623), train_loss = 1.29287081, grad/param norm = 1.5520e-01, time/batch = 0.6372s	
5131/33650 (epoch 7.624), train_loss = 1.02089330, grad/param norm = 1.5496e-01, time/batch = 0.6349s	
5132/33650 (epoch 7.626), train_loss = 1.02475759, grad/param norm = 1.3317e-01, time/batch = 0.6277s	
5133/33650 (epoch 7.627), train_loss = 1.25775442, grad/param norm = 1.5279e-01, time/batch = 0.6260s	
5134/33650 (epoch 7.629), train_loss = 1.28907837, grad/param norm = 1.4863e-01, time/batch = 0.6276s	
5135/33650 (epoch 7.630), train_loss = 1.39867794, grad/param norm = 1.6905e-01, time/batch = 0.6310s	
5136/33650 (epoch 7.632), train_loss = 1.43738529, grad/param norm = 1.5236e-01, time/batch = 0.6274s	
5137/33650 (epoch 7.633), train_loss = 1.37904020, grad/param norm = 1.6174e-01, time/batch = 0.6313s	
5138/33650 (epoch 7.634), train_loss = 1.13643291, grad/param norm = 1.4896e-01, time/batch = 0.6253s	
5139/33650 (epoch 7.636), train_loss = 1.04707772, grad/param norm = 1.3958e-01, time/batch = 0.6282s	
5140/33650 (epoch 7.637), train_loss = 1.32380494, grad/param norm = 1.5823e-01, time/batch = 0.6273s	
5141/33650 (epoch 7.639), train_loss = 1.21899758, grad/param norm = 1.5425e-01, time/batch = 0.6270s	
5142/33650 (epoch 7.640), train_loss = 1.31347849, grad/param norm = 1.6152e-01, time/batch = 0.6333s	
5143/33650 (epoch 7.642), train_loss = 1.49105191, grad/param norm = 1.8497e-01, time/batch = 0.6309s	
5144/33650 (epoch 7.643), train_loss = 1.30188254, grad/param norm = 1.5617e-01, time/batch = 0.6359s	
5145/33650 (epoch 7.645), train_loss = 1.27652812, grad/param norm = 1.4785e-01, time/batch = 0.6442s	
5146/33650 (epoch 7.646), train_loss = 1.07785519, grad/param norm = 1.3011e-01, time/batch = 0.6284s	
5147/33650 (epoch 7.648), train_loss = 1.29943723, grad/param norm = 1.5289e-01, time/batch = 0.6271s	
5148/33650 (epoch 7.649), train_loss = 1.36120780, grad/param norm = 1.8553e-01, time/batch = 0.6287s	
5149/33650 (epoch 7.651), train_loss = 1.42110963, grad/param norm = 1.7145e-01, time/batch = 0.6275s	
5150/33650 (epoch 7.652), train_loss = 0.95503534, grad/param norm = 1.4217e-01, time/batch = 0.6283s	
5151/33650 (epoch 7.654), train_loss = 1.21805120, grad/param norm = 1.4513e-01, time/batch = 0.6326s	
5152/33650 (epoch 7.655), train_loss = 1.14648621, grad/param norm = 1.5733e-01, time/batch = 0.6270s	
5153/33650 (epoch 7.657), train_loss = 1.30547065, grad/param norm = 1.6871e-01, time/batch = 0.6299s	
5154/33650 (epoch 7.658), train_loss = 1.12678853, grad/param norm = 1.4144e-01, time/batch = 0.6291s	
5155/33650 (epoch 7.660), train_loss = 1.09525742, grad/param norm = 1.4103e-01, time/batch = 0.6279s	
5156/33650 (epoch 7.661), train_loss = 1.20472837, grad/param norm = 1.3560e-01, time/batch = 0.6303s	
5157/33650 (epoch 7.663), train_loss = 1.12543428, grad/param norm = 1.5962e-01, time/batch = 0.6277s	
5158/33650 (epoch 7.664), train_loss = 1.11518933, grad/param norm = 1.4279e-01, time/batch = 0.6283s	
5159/33650 (epoch 7.666), train_loss = 1.22099092, grad/param norm = 1.5272e-01, time/batch = 0.6285s	
5160/33650 (epoch 7.667), train_loss = 1.14179153, grad/param norm = 1.3921e-01, time/batch = 0.6265s	
5161/33650 (epoch 7.669), train_loss = 1.11348465, grad/param norm = 1.4186e-01, time/batch = 0.6291s	
5162/33650 (epoch 7.670), train_loss = 1.07572799, grad/param norm = 1.4839e-01, time/batch = 0.6271s	
5163/33650 (epoch 7.672), train_loss = 1.11938956, grad/param norm = 1.4784e-01, time/batch = 0.6273s	
5164/33650 (epoch 7.673), train_loss = 1.03610122, grad/param norm = 1.4950e-01, time/batch = 0.6286s	
5165/33650 (epoch 7.675), train_loss = 0.99025577, grad/param norm = 1.2326e-01, time/batch = 0.6274s	
5166/33650 (epoch 7.676), train_loss = 1.26803968, grad/param norm = 1.4701e-01, time/batch = 0.6436s	
5167/33650 (epoch 7.678), train_loss = 1.15785821, grad/param norm = 1.5264e-01, time/batch = 0.6667s	
5168/33650 (epoch 7.679), train_loss = 1.22392876, grad/param norm = 1.6408e-01, time/batch = 0.6284s	
5169/33650 (epoch 7.681), train_loss = 1.14086102, grad/param norm = 1.4722e-01, time/batch = 0.6280s	
5170/33650 (epoch 7.682), train_loss = 1.18774187, grad/param norm = 1.5918e-01, time/batch = 0.6267s	
5171/33650 (epoch 7.684), train_loss = 1.14081261, grad/param norm = 1.4524e-01, time/batch = 0.6308s	
5172/33650 (epoch 7.685), train_loss = 1.32789910, grad/param norm = 1.6775e-01, time/batch = 0.6391s	
5173/33650 (epoch 7.686), train_loss = 1.23774968, grad/param norm = 1.4982e-01, time/batch = 0.6324s	
5174/33650 (epoch 7.688), train_loss = 1.45942241, grad/param norm = 1.7273e-01, time/batch = 0.6304s	
5175/33650 (epoch 7.689), train_loss = 1.16894067, grad/param norm = 1.5927e-01, time/batch = 0.6293s	
5176/33650 (epoch 7.691), train_loss = 1.39688568, grad/param norm = 1.7308e-01, time/batch = 0.6379s	
5177/33650 (epoch 7.692), train_loss = 1.37357248, grad/param norm = 1.6008e-01, time/batch = 0.6381s	
5178/33650 (epoch 7.694), train_loss = 1.32508918, grad/param norm = 1.7650e-01, time/batch = 0.6525s	
5179/33650 (epoch 7.695), train_loss = 0.96070741, grad/param norm = 1.4505e-01, time/batch = 0.6327s	
5180/33650 (epoch 7.697), train_loss = 1.28824484, grad/param norm = 1.5606e-01, time/batch = 0.6373s	
5181/33650 (epoch 7.698), train_loss = 1.39992037, grad/param norm = 1.7080e-01, time/batch = 0.6263s	
5182/33650 (epoch 7.700), train_loss = 1.23398939, grad/param norm = 1.5358e-01, time/batch = 0.6274s	
5183/33650 (epoch 7.701), train_loss = 1.32377157, grad/param norm = 1.6563e-01, time/batch = 0.6246s	
5184/33650 (epoch 7.703), train_loss = 1.34084447, grad/param norm = 1.4737e-01, time/batch = 0.6244s	
5185/33650 (epoch 7.704), train_loss = 1.20769785, grad/param norm = 1.4778e-01, time/batch = 0.6274s	
5186/33650 (epoch 7.706), train_loss = 1.23879959, grad/param norm = 1.4277e-01, time/batch = 0.6270s	
5187/33650 (epoch 7.707), train_loss = 1.35582441, grad/param norm = 1.6456e-01, time/batch = 0.6276s	
5188/33650 (epoch 7.709), train_loss = 1.20941312, grad/param norm = 1.4774e-01, time/batch = 0.6273s	
5189/33650 (epoch 7.710), train_loss = 1.44018336, grad/param norm = 1.5456e-01, time/batch = 0.6297s	
5190/33650 (epoch 7.712), train_loss = 1.21147349, grad/param norm = 1.5609e-01, time/batch = 0.6294s	
5191/33650 (epoch 7.713), train_loss = 1.23635471, grad/param norm = 1.6733e-01, time/batch = 0.6518s	
5192/33650 (epoch 7.715), train_loss = 1.41959312, grad/param norm = 1.7424e-01, time/batch = 0.6410s	
5193/33650 (epoch 7.716), train_loss = 1.15078428, grad/param norm = 1.5978e-01, time/batch = 0.6382s	
5194/33650 (epoch 7.718), train_loss = 1.31337218, grad/param norm = 1.5718e-01, time/batch = 0.6384s	
5195/33650 (epoch 7.719), train_loss = 1.43316033, grad/param norm = 1.6914e-01, time/batch = 0.6387s	
5196/33650 (epoch 7.721), train_loss = 1.52855921, grad/param norm = 1.6438e-01, time/batch = 0.6344s	
5197/33650 (epoch 7.722), train_loss = 1.45713226, grad/param norm = 1.8785e-01, time/batch = 0.6272s	
5198/33650 (epoch 7.724), train_loss = 1.35619329, grad/param norm = 1.5908e-01, time/batch = 0.6239s	
5199/33650 (epoch 7.725), train_loss = 1.42117303, grad/param norm = 1.7169e-01, time/batch = 0.6242s	
5200/33650 (epoch 7.727), train_loss = 1.17825291, grad/param norm = 1.6830e-01, time/batch = 0.6256s	
5201/33650 (epoch 7.728), train_loss = 1.21207751, grad/param norm = 1.5553e-01, time/batch = 0.6287s	
5202/33650 (epoch 7.730), train_loss = 1.35073221, grad/param norm = 1.5311e-01, time/batch = 0.6443s	
5203/33650 (epoch 7.731), train_loss = 1.43812495, grad/param norm = 1.6696e-01, time/batch = 0.6663s	
5204/33650 (epoch 7.733), train_loss = 1.26768186, grad/param norm = 1.6010e-01, time/batch = 0.6336s	
5205/33650 (epoch 7.734), train_loss = 1.47170513, grad/param norm = 1.8157e-01, time/batch = 0.6252s	
5206/33650 (epoch 7.736), train_loss = 1.26147141, grad/param norm = 1.6487e-01, time/batch = 0.6248s	
5207/33650 (epoch 7.737), train_loss = 1.31243767, grad/param norm = 1.6492e-01, time/batch = 0.6223s	
5208/33650 (epoch 7.738), train_loss = 1.13996505, grad/param norm = 1.4278e-01, time/batch = 0.6281s	
5209/33650 (epoch 7.740), train_loss = 1.13363732, grad/param norm = 1.4409e-01, time/batch = 0.6263s	
5210/33650 (epoch 7.741), train_loss = 1.23867868, grad/param norm = 1.5948e-01, time/batch = 0.6278s	
5211/33650 (epoch 7.743), train_loss = 1.28109330, grad/param norm = 1.4725e-01, time/batch = 0.6260s	
5212/33650 (epoch 7.744), train_loss = 1.21157096, grad/param norm = 1.4233e-01, time/batch = 0.6249s	
5213/33650 (epoch 7.746), train_loss = 1.23503043, grad/param norm = 1.5474e-01, time/batch = 0.6252s	
5214/33650 (epoch 7.747), train_loss = 1.37578680, grad/param norm = 1.5633e-01, time/batch = 0.6244s	
5215/33650 (epoch 7.749), train_loss = 1.06914356, grad/param norm = 1.3966e-01, time/batch = 0.6260s	
5216/33650 (epoch 7.750), train_loss = 1.36970790, grad/param norm = 1.6934e-01, time/batch = 0.6263s	
5217/33650 (epoch 7.752), train_loss = 1.39586838, grad/param norm = 1.6996e-01, time/batch = 0.6361s	
5218/33650 (epoch 7.753), train_loss = 1.53726853, grad/param norm = 1.7841e-01, time/batch = 0.6284s	
5219/33650 (epoch 7.755), train_loss = 1.17611639, grad/param norm = 1.4928e-01, time/batch = 0.6242s	
5220/33650 (epoch 7.756), train_loss = 1.37848536, grad/param norm = 1.7500e-01, time/batch = 0.6252s	
5221/33650 (epoch 7.758), train_loss = 1.42688609, grad/param norm = 1.7177e-01, time/batch = 0.6287s	
5222/33650 (epoch 7.759), train_loss = 1.52056331, grad/param norm = 1.7524e-01, time/batch = 0.6256s	
5223/33650 (epoch 7.761), train_loss = 1.34698553, grad/param norm = 1.7091e-01, time/batch = 0.6566s	
5224/33650 (epoch 7.762), train_loss = 1.30065424, grad/param norm = 1.5941e-01, time/batch = 0.6571s	
5225/33650 (epoch 7.764), train_loss = 1.40969457, grad/param norm = 1.7872e-01, time/batch = 0.6238s	
5226/33650 (epoch 7.765), train_loss = 1.33914414, grad/param norm = 1.5797e-01, time/batch = 0.6268s	
5227/33650 (epoch 7.767), train_loss = 1.17722601, grad/param norm = 1.5303e-01, time/batch = 0.6253s	
5228/33650 (epoch 7.768), train_loss = 1.13486051, grad/param norm = 1.5014e-01, time/batch = 0.6255s	
5229/33650 (epoch 7.770), train_loss = 1.27076241, grad/param norm = 1.6434e-01, time/batch = 0.6256s	
5230/33650 (epoch 7.771), train_loss = 1.27328255, grad/param norm = 1.5479e-01, time/batch = 0.6257s	
5231/33650 (epoch 7.773), train_loss = 1.45341927, grad/param norm = 1.8302e-01, time/batch = 0.6331s	
5232/33650 (epoch 7.774), train_loss = 1.33033708, grad/param norm = 1.5945e-01, time/batch = 0.6269s	
5233/33650 (epoch 7.776), train_loss = 1.38144849, grad/param norm = 1.7659e-01, time/batch = 0.6250s	
5234/33650 (epoch 7.777), train_loss = 1.14820084, grad/param norm = 1.5455e-01, time/batch = 0.6270s	
5235/33650 (epoch 7.779), train_loss = 1.28274119, grad/param norm = 1.4785e-01, time/batch = 0.6266s	
5236/33650 (epoch 7.780), train_loss = 1.16048301, grad/param norm = 1.4554e-01, time/batch = 0.6261s	
5237/33650 (epoch 7.782), train_loss = 1.23122239, grad/param norm = 1.5436e-01, time/batch = 0.6268s	
5238/33650 (epoch 7.783), train_loss = 1.11290341, grad/param norm = 1.4468e-01, time/batch = 0.6272s	
5239/33650 (epoch 7.785), train_loss = 1.52051734, grad/param norm = 1.5951e-01, time/batch = 0.6299s	
5240/33650 (epoch 7.786), train_loss = 1.28129463, grad/param norm = 1.4417e-01, time/batch = 0.6254s	
5241/33650 (epoch 7.788), train_loss = 1.31522554, grad/param norm = 1.6912e-01, time/batch = 0.6409s	
5242/33650 (epoch 7.789), train_loss = 1.33851381, grad/param norm = 1.4168e-01, time/batch = 0.6305s	
5243/33650 (epoch 7.790), train_loss = 1.40294789, grad/param norm = 1.7773e-01, time/batch = 0.6361s	
5244/33650 (epoch 7.792), train_loss = 1.43399362, grad/param norm = 1.8007e-01, time/batch = 0.6660s	
5245/33650 (epoch 7.793), train_loss = 1.38281125, grad/param norm = 1.7208e-01, time/batch = 0.6362s	
5246/33650 (epoch 7.795), train_loss = 1.43304935, grad/param norm = 1.6003e-01, time/batch = 0.6327s	
5247/33650 (epoch 7.796), train_loss = 1.21817656, grad/param norm = 1.5423e-01, time/batch = 0.6324s	
5248/33650 (epoch 7.798), train_loss = 1.23590158, grad/param norm = 1.4408e-01, time/batch = 0.6284s	
5249/33650 (epoch 7.799), train_loss = 1.26091679, grad/param norm = 1.3754e-01, time/batch = 0.6249s	
5250/33650 (epoch 7.801), train_loss = 1.34708697, grad/param norm = 1.5846e-01, time/batch = 0.6248s	
5251/33650 (epoch 7.802), train_loss = 1.42465481, grad/param norm = 1.4885e-01, time/batch = 0.6345s	
5252/33650 (epoch 7.804), train_loss = 1.26742910, grad/param norm = 1.5009e-01, time/batch = 0.6304s	
5253/33650 (epoch 7.805), train_loss = 1.21820598, grad/param norm = 1.4302e-01, time/batch = 0.6329s	
5254/33650 (epoch 7.807), train_loss = 1.52360527, grad/param norm = 1.7289e-01, time/batch = 0.6310s	
5255/33650 (epoch 7.808), train_loss = 1.51543705, grad/param norm = 1.6955e-01, time/batch = 0.6260s	
5256/33650 (epoch 7.810), train_loss = 1.33094345, grad/param norm = 1.5022e-01, time/batch = 0.6244s	
5257/33650 (epoch 7.811), train_loss = 1.34991434, grad/param norm = 1.6030e-01, time/batch = 0.6253s	
5258/33650 (epoch 7.813), train_loss = 1.29436091, grad/param norm = 1.7546e-01, time/batch = 0.6252s	
5259/33650 (epoch 7.814), train_loss = 1.39974926, grad/param norm = 1.6697e-01, time/batch = 0.6267s	
5260/33650 (epoch 7.816), train_loss = 1.34588296, grad/param norm = 1.6329e-01, time/batch = 0.6250s	
5261/33650 (epoch 7.817), train_loss = 1.42604012, grad/param norm = 1.7592e-01, time/batch = 0.6290s	
5262/33650 (epoch 7.819), train_loss = 1.41553110, grad/param norm = 1.5295e-01, time/batch = 0.6286s	
5263/33650 (epoch 7.820), train_loss = 1.44623458, grad/param norm = 1.6429e-01, time/batch = 0.6275s	
5264/33650 (epoch 7.822), train_loss = 1.48711832, grad/param norm = 1.8304e-01, time/batch = 0.6260s	
5265/33650 (epoch 7.823), train_loss = 1.20811106, grad/param norm = 1.5590e-01, time/batch = 0.6258s	
5266/33650 (epoch 7.825), train_loss = 1.27749162, grad/param norm = 1.4733e-01, time/batch = 0.6254s	
5267/33650 (epoch 7.826), train_loss = 1.35806875, grad/param norm = 1.5353e-01, time/batch = 0.6243s	
5268/33650 (epoch 7.828), train_loss = 1.60511443, grad/param norm = 1.6498e-01, time/batch = 0.6296s	
5269/33650 (epoch 7.829), train_loss = 1.13807364, grad/param norm = 1.4441e-01, time/batch = 0.6647s	
5270/33650 (epoch 7.831), train_loss = 1.40214614, grad/param norm = 1.6134e-01, time/batch = 0.6520s	
5271/33650 (epoch 7.832), train_loss = 1.36536038, grad/param norm = 1.6649e-01, time/batch = 0.6512s	
5272/33650 (epoch 7.834), train_loss = 1.39840548, grad/param norm = 1.5703e-01, time/batch = 0.6317s	
5273/33650 (epoch 7.835), train_loss = 1.59506356, grad/param norm = 1.7426e-01, time/batch = 0.6493s	
5274/33650 (epoch 7.837), train_loss = 1.32796175, grad/param norm = 1.7421e-01, time/batch = 0.6289s	
5275/33650 (epoch 7.838), train_loss = 1.31095880, grad/param norm = 1.8014e-01, time/batch = 0.6255s	
5276/33650 (epoch 7.840), train_loss = 1.39173549, grad/param norm = 1.6421e-01, time/batch = 0.6256s	
5277/33650 (epoch 7.841), train_loss = 1.20207666, grad/param norm = 1.4980e-01, time/batch = 0.6280s	
5278/33650 (epoch 7.842), train_loss = 1.24326932, grad/param norm = 1.5714e-01, time/batch = 0.6305s	
5279/33650 (epoch 7.844), train_loss = 1.50663544, grad/param norm = 1.8310e-01, time/batch = 0.6363s	
5280/33650 (epoch 7.845), train_loss = 1.19576754, grad/param norm = 1.3930e-01, time/batch = 0.6314s	
5281/33650 (epoch 7.847), train_loss = 1.07693015, grad/param norm = 1.6466e-01, time/batch = 0.6548s	
5282/33650 (epoch 7.848), train_loss = 1.16587821, grad/param norm = 1.6052e-01, time/batch = 0.6346s	
5283/33650 (epoch 7.850), train_loss = 1.36723485, grad/param norm = 1.9715e-01, time/batch = 0.6373s	
5284/33650 (epoch 7.851), train_loss = 1.07137198, grad/param norm = 1.4009e-01, time/batch = 0.6571s	
5285/33650 (epoch 7.853), train_loss = 1.30858954, grad/param norm = 1.5134e-01, time/batch = 0.6697s	
5286/33650 (epoch 7.854), train_loss = 1.47799615, grad/param norm = 1.8895e-01, time/batch = 0.6616s	
5287/33650 (epoch 7.856), train_loss = 0.99295341, grad/param norm = 1.5591e-01, time/batch = 0.6545s	
5288/33650 (epoch 7.857), train_loss = 1.25000103, grad/param norm = 1.3838e-01, time/batch = 0.6500s	
5289/33650 (epoch 7.859), train_loss = 1.16259566, grad/param norm = 1.4891e-01, time/batch = 0.6369s	
5290/33650 (epoch 7.860), train_loss = 1.07628481, grad/param norm = 1.5175e-01, time/batch = 0.6283s	
5291/33650 (epoch 7.862), train_loss = 1.13647931, grad/param norm = 1.5481e-01, time/batch = 0.6264s	
5292/33650 (epoch 7.863), train_loss = 1.37164761, grad/param norm = 1.5598e-01, time/batch = 0.6248s	
5293/33650 (epoch 7.865), train_loss = 1.21361204, grad/param norm = 1.6243e-01, time/batch = 0.6267s	
5294/33650 (epoch 7.866), train_loss = 1.17015230, grad/param norm = 1.5524e-01, time/batch = 0.6270s	
5295/33650 (epoch 7.868), train_loss = 1.15390328, grad/param norm = 1.6036e-01, time/batch = 0.6237s	
5296/33650 (epoch 7.869), train_loss = 1.41190473, grad/param norm = 1.6848e-01, time/batch = 0.6263s	
5297/33650 (epoch 7.871), train_loss = 1.12512850, grad/param norm = 1.5011e-01, time/batch = 0.6388s	
5298/33650 (epoch 7.872), train_loss = 1.26427792, grad/param norm = 1.6443e-01, time/batch = 0.6314s	
5299/33650 (epoch 7.874), train_loss = 1.39499656, grad/param norm = 1.6852e-01, time/batch = 0.6261s	
5300/33650 (epoch 7.875), train_loss = 1.20710446, grad/param norm = 1.5237e-01, time/batch = 0.6279s	
5301/33650 (epoch 7.877), train_loss = 1.39893809, grad/param norm = 1.5665e-01, time/batch = 0.6325s	
5302/33650 (epoch 7.878), train_loss = 0.91875480, grad/param norm = 1.3650e-01, time/batch = 0.6270s	
5303/33650 (epoch 7.880), train_loss = 1.28918936, grad/param norm = 1.6254e-01, time/batch = 0.6278s	
5304/33650 (epoch 7.881), train_loss = 1.19206397, grad/param norm = 1.4819e-01, time/batch = 0.6273s	
5305/33650 (epoch 7.883), train_loss = 1.27545135, grad/param norm = 1.5979e-01, time/batch = 0.6660s	
5306/33650 (epoch 7.884), train_loss = 1.37084818, grad/param norm = 1.6701e-01, time/batch = 0.6449s	
5307/33650 (epoch 7.886), train_loss = 1.40310093, grad/param norm = 1.6708e-01, time/batch = 0.6263s	
5308/33650 (epoch 7.887), train_loss = 1.21115782, grad/param norm = 1.4983e-01, time/batch = 0.6345s	
5309/33650 (epoch 7.889), train_loss = 1.38277282, grad/param norm = 1.7138e-01, time/batch = 0.6246s	
5310/33650 (epoch 7.890), train_loss = 1.38265031, grad/param norm = 1.5877e-01, time/batch = 0.6268s	
5311/33650 (epoch 7.892), train_loss = 1.34800526, grad/param norm = 1.7281e-01, time/batch = 0.6289s	
5312/33650 (epoch 7.893), train_loss = 1.37328559, grad/param norm = 1.7308e-01, time/batch = 0.6277s	
5313/33650 (epoch 7.895), train_loss = 1.42977873, grad/param norm = 1.6934e-01, time/batch = 0.6260s	
5314/33650 (epoch 7.896), train_loss = 1.18467138, grad/param norm = 1.5693e-01, time/batch = 0.6261s	
5315/33650 (epoch 7.897), train_loss = 1.18232072, grad/param norm = 1.5283e-01, time/batch = 0.6300s	
5316/33650 (epoch 7.899), train_loss = 1.16922003, grad/param norm = 1.4815e-01, time/batch = 0.6302s	
5317/33650 (epoch 7.900), train_loss = 1.05870462, grad/param norm = 1.4202e-01, time/batch = 0.6273s	
5318/33650 (epoch 7.902), train_loss = 1.29796912, grad/param norm = 1.6885e-01, time/batch = 0.6281s	
5319/33650 (epoch 7.903), train_loss = 1.25961612, grad/param norm = 1.7020e-01, time/batch = 0.6310s	
5320/33650 (epoch 7.905), train_loss = 1.53811966, grad/param norm = 1.9850e-01, time/batch = 0.6265s	
5321/33650 (epoch 7.906), train_loss = 1.24962086, grad/param norm = 1.6548e-01, time/batch = 0.6285s	
5322/33650 (epoch 7.908), train_loss = 1.21670543, grad/param norm = 1.4389e-01, time/batch = 0.6269s	
5323/33650 (epoch 7.909), train_loss = 1.23438932, grad/param norm = 1.4041e-01, time/batch = 0.6272s	
5324/33650 (epoch 7.911), train_loss = 1.11196573, grad/param norm = 1.4531e-01, time/batch = 0.6283s	
5325/33650 (epoch 7.912), train_loss = 1.12256695, grad/param norm = 1.4317e-01, time/batch = 0.6441s	
5326/33650 (epoch 7.914), train_loss = 1.26162824, grad/param norm = 1.4468e-01, time/batch = 0.6283s	
5327/33650 (epoch 7.915), train_loss = 1.35963434, grad/param norm = 1.7200e-01, time/batch = 0.6263s	
5328/33650 (epoch 7.917), train_loss = 1.27059500, grad/param norm = 1.5783e-01, time/batch = 0.6261s	
5329/33650 (epoch 7.918), train_loss = 1.03018380, grad/param norm = 1.3375e-01, time/batch = 0.6264s	
5330/33650 (epoch 7.920), train_loss = 1.18396564, grad/param norm = 1.3413e-01, time/batch = 0.6274s	
5331/33650 (epoch 7.921), train_loss = 1.15500110, grad/param norm = 1.4897e-01, time/batch = 0.6275s	
5332/33650 (epoch 7.923), train_loss = 1.15420619, grad/param norm = 1.5298e-01, time/batch = 0.6280s	
5333/33650 (epoch 7.924), train_loss = 1.33269475, grad/param norm = 1.6756e-01, time/batch = 0.6266s	
5334/33650 (epoch 7.926), train_loss = 1.29542466, grad/param norm = 1.7290e-01, time/batch = 0.6266s	
5335/33650 (epoch 7.927), train_loss = 1.23857437, grad/param norm = 1.6821e-01, time/batch = 0.6260s	
5336/33650 (epoch 7.929), train_loss = 1.27202707, grad/param norm = 1.5381e-01, time/batch = 0.6266s	
5337/33650 (epoch 7.930), train_loss = 1.25160852, grad/param norm = 1.5795e-01, time/batch = 0.6279s	
5338/33650 (epoch 7.932), train_loss = 1.26810042, grad/param norm = 1.5361e-01, time/batch = 0.6273s	
5339/33650 (epoch 7.933), train_loss = 1.13385979, grad/param norm = 1.4775e-01, time/batch = 0.6261s	
5340/33650 (epoch 7.935), train_loss = 1.18214829, grad/param norm = 1.4899e-01, time/batch = 0.6255s	
5341/33650 (epoch 7.936), train_loss = 1.15649250, grad/param norm = 1.3739e-01, time/batch = 0.6347s	
5342/33650 (epoch 7.938), train_loss = 1.09656746, grad/param norm = 1.4133e-01, time/batch = 0.6315s	
5343/33650 (epoch 7.939), train_loss = 1.32373385, grad/param norm = 1.5231e-01, time/batch = 0.6297s	
5344/33650 (epoch 7.941), train_loss = 1.30613634, grad/param norm = 1.7041e-01, time/batch = 0.6283s	
5345/33650 (epoch 7.942), train_loss = 1.36710860, grad/param norm = 1.6583e-01, time/batch = 0.6300s	
5346/33650 (epoch 7.944), train_loss = 1.29239880, grad/param norm = 1.4583e-01, time/batch = 0.6644s	
5347/33650 (epoch 7.945), train_loss = 1.34816476, grad/param norm = 1.6220e-01, time/batch = 0.6470s	
5348/33650 (epoch 7.947), train_loss = 1.52935231, grad/param norm = 1.7565e-01, time/batch = 0.6284s	
5349/33650 (epoch 7.948), train_loss = 1.40705156, grad/param norm = 1.6126e-01, time/batch = 0.6259s	
5350/33650 (epoch 7.949), train_loss = 1.18158665, grad/param norm = 1.6692e-01, time/batch = 0.6309s	
5351/33650 (epoch 7.951), train_loss = 1.41535376, grad/param norm = 1.5966e-01, time/batch = 0.6287s	
5352/33650 (epoch 7.952), train_loss = 1.42010770, grad/param norm = 1.7512e-01, time/batch = 0.6274s	
5353/33650 (epoch 7.954), train_loss = 1.36295414, grad/param norm = 1.6857e-01, time/batch = 0.6296s	
5354/33650 (epoch 7.955), train_loss = 1.38818133, grad/param norm = 1.6655e-01, time/batch = 0.6301s	
5355/33650 (epoch 7.957), train_loss = 1.35602239, grad/param norm = 1.6633e-01, time/batch = 0.6277s	
5356/33650 (epoch 7.958), train_loss = 0.97535340, grad/param norm = 1.3255e-01, time/batch = 0.6272s	
5357/33650 (epoch 7.960), train_loss = 1.09849797, grad/param norm = 1.4236e-01, time/batch = 0.6262s	
5358/33650 (epoch 7.961), train_loss = 1.18503882, grad/param norm = 1.4675e-01, time/batch = 0.6260s	
5359/33650 (epoch 7.963), train_loss = 1.23735846, grad/param norm = 1.6278e-01, time/batch = 0.6255s	
5360/33650 (epoch 7.964), train_loss = 1.28203789, grad/param norm = 1.6951e-01, time/batch = 0.6269s	
5361/33650 (epoch 7.966), train_loss = 1.27856391, grad/param norm = 1.5822e-01, time/batch = 0.6292s	
5362/33650 (epoch 7.967), train_loss = 1.36278886, grad/param norm = 1.6567e-01, time/batch = 0.6293s	
5363/33650 (epoch 7.969), train_loss = 1.21641741, grad/param norm = 1.3961e-01, time/batch = 0.6298s	
5364/33650 (epoch 7.970), train_loss = 1.32761052, grad/param norm = 1.6185e-01, time/batch = 0.6423s	
5365/33650 (epoch 7.972), train_loss = 1.58799751, grad/param norm = 1.6813e-01, time/batch = 0.6505s	
5366/33650 (epoch 7.973), train_loss = 1.14464301, grad/param norm = 1.3934e-01, time/batch = 0.6538s	
5367/33650 (epoch 7.975), train_loss = 1.14387809, grad/param norm = 1.4660e-01, time/batch = 0.6697s	
5368/33650 (epoch 7.976), train_loss = 1.12030889, grad/param norm = 1.3818e-01, time/batch = 0.6442s	
5369/33650 (epoch 7.978), train_loss = 1.19972489, grad/param norm = 1.6185e-01, time/batch = 0.6388s	
5370/33650 (epoch 7.979), train_loss = 1.30197563, grad/param norm = 1.6603e-01, time/batch = 0.6294s	
5371/33650 (epoch 7.981), train_loss = 1.19690687, grad/param norm = 1.3270e-01, time/batch = 0.6344s	
5372/33650 (epoch 7.982), train_loss = 1.31223312, grad/param norm = 1.6186e-01, time/batch = 0.6383s	
5373/33650 (epoch 7.984), train_loss = 1.13530116, grad/param norm = 1.4228e-01, time/batch = 0.6310s	
5374/33650 (epoch 7.985), train_loss = 1.12713670, grad/param norm = 1.3461e-01, time/batch = 0.6317s	
5375/33650 (epoch 7.987), train_loss = 1.23239839, grad/param norm = 1.5686e-01, time/batch = 0.6306s	
5376/33650 (epoch 7.988), train_loss = 1.33285181, grad/param norm = 1.5587e-01, time/batch = 0.6313s	
5377/33650 (epoch 7.990), train_loss = 1.50929295, grad/param norm = 1.9123e-01, time/batch = 0.6319s	
5378/33650 (epoch 7.991), train_loss = 1.35962752, grad/param norm = 1.5685e-01, time/batch = 0.6361s	
5379/33650 (epoch 7.993), train_loss = 1.33074229, grad/param norm = 1.6818e-01, time/batch = 0.6257s	
5380/33650 (epoch 7.994), train_loss = 1.21397081, grad/param norm = 1.4152e-01, time/batch = 0.6383s	
5381/33650 (epoch 7.996), train_loss = 1.17573838, grad/param norm = 1.4678e-01, time/batch = 0.6424s	
5382/33650 (epoch 7.997), train_loss = 1.33183373, grad/param norm = 1.7428e-01, time/batch = 0.6290s	
5383/33650 (epoch 7.999), train_loss = 1.11132750, grad/param norm = 1.4337e-01, time/batch = 0.6398s	
5384/33650 (epoch 8.000), train_loss = 1.36981771, grad/param norm = 1.6417e-01, time/batch = 0.6257s	
5385/33650 (epoch 8.001), train_loss = 1.44307586, grad/param norm = 1.7184e-01, time/batch = 0.6257s	
5386/33650 (epoch 8.003), train_loss = 1.50792995, grad/param norm = 1.7706e-01, time/batch = 0.6332s	
5387/33650 (epoch 8.004), train_loss = 1.35665824, grad/param norm = 1.6837e-01, time/batch = 0.6661s	
5388/33650 (epoch 8.006), train_loss = 1.21850361, grad/param norm = 1.5840e-01, time/batch = 0.6390s	
5389/33650 (epoch 8.007), train_loss = 1.28497562, grad/param norm = 1.6555e-01, time/batch = 0.6285s	
5390/33650 (epoch 8.009), train_loss = 1.23530832, grad/param norm = 1.4097e-01, time/batch = 0.6390s	
5391/33650 (epoch 8.010), train_loss = 1.34625099, grad/param norm = 1.6606e-01, time/batch = 0.6364s	
5392/33650 (epoch 8.012), train_loss = 1.19547868, grad/param norm = 1.6205e-01, time/batch = 0.6281s	
5393/33650 (epoch 8.013), train_loss = 1.33950887, grad/param norm = 1.7517e-01, time/batch = 0.6273s	
5394/33650 (epoch 8.015), train_loss = 1.16182296, grad/param norm = 1.4924e-01, time/batch = 0.6290s	
5395/33650 (epoch 8.016), train_loss = 1.19476024, grad/param norm = 1.7309e-01, time/batch = 0.6256s	
5396/33650 (epoch 8.018), train_loss = 1.27024247, grad/param norm = 1.5380e-01, time/batch = 0.6261s	
5397/33650 (epoch 8.019), train_loss = 1.16656570, grad/param norm = 1.4671e-01, time/batch = 0.6306s	
5398/33650 (epoch 8.021), train_loss = 1.37326795, grad/param norm = 1.5790e-01, time/batch = 0.6240s	
5399/33650 (epoch 8.022), train_loss = 1.22581486, grad/param norm = 1.5765e-01, time/batch = 0.6245s	
5400/33650 (epoch 8.024), train_loss = 1.12903291, grad/param norm = 1.4720e-01, time/batch = 0.6266s	
5401/33650 (epoch 8.025), train_loss = 1.20295009, grad/param norm = 1.5237e-01, time/batch = 0.6281s	
5402/33650 (epoch 8.027), train_loss = 1.37412307, grad/param norm = 1.6827e-01, time/batch = 0.6268s	
5403/33650 (epoch 8.028), train_loss = 1.34761681, grad/param norm = 1.6138e-01, time/batch = 0.6275s	
5404/33650 (epoch 8.030), train_loss = 1.28466527, grad/param norm = 1.5460e-01, time/batch = 0.6307s	
5405/33650 (epoch 8.031), train_loss = 1.06220200, grad/param norm = 1.3267e-01, time/batch = 0.6273s	
5406/33650 (epoch 8.033), train_loss = 1.19517787, grad/param norm = 1.3625e-01, time/batch = 0.6276s	
5407/33650 (epoch 8.034), train_loss = 1.29428503, grad/param norm = 1.6053e-01, time/batch = 0.6278s	
5408/33650 (epoch 8.036), train_loss = 1.42805062, grad/param norm = 1.7277e-01, time/batch = 0.6278s	
5409/33650 (epoch 8.037), train_loss = 1.15306042, grad/param norm = 1.6442e-01, time/batch = 0.6277s	
5410/33650 (epoch 8.039), train_loss = 1.41400647, grad/param norm = 1.6707e-01, time/batch = 0.6293s	
5411/33650 (epoch 8.040), train_loss = 1.45279201, grad/param norm = 1.8032e-01, time/batch = 0.6300s	
5412/33650 (epoch 8.042), train_loss = 1.48051286, grad/param norm = 1.6835e-01, time/batch = 0.6651s	
5413/33650 (epoch 8.043), train_loss = 1.17694758, grad/param norm = 1.5140e-01, time/batch = 0.6548s	
5414/33650 (epoch 8.045), train_loss = 1.18295805, grad/param norm = 1.5958e-01, time/batch = 0.6251s	
5415/33650 (epoch 8.046), train_loss = 1.36796516, grad/param norm = 1.5516e-01, time/batch = 0.6252s	
5416/33650 (epoch 8.048), train_loss = 1.35488863, grad/param norm = 1.5956e-01, time/batch = 0.6329s	
5417/33650 (epoch 8.049), train_loss = 1.32322449, grad/param norm = 1.5903e-01, time/batch = 0.6275s	
5418/33650 (epoch 8.051), train_loss = 1.38196193, grad/param norm = 1.5890e-01, time/batch = 0.6268s	
5419/33650 (epoch 8.052), train_loss = 1.46201032, grad/param norm = 1.6928e-01, time/batch = 0.6305s	
5420/33650 (epoch 8.053), train_loss = 1.28931037, grad/param norm = 1.5292e-01, time/batch = 0.6302s	
5421/33650 (epoch 8.055), train_loss = 1.11136861, grad/param norm = 1.5967e-01, time/batch = 0.6293s	
5422/33650 (epoch 8.056), train_loss = 1.10961636, grad/param norm = 1.4553e-01, time/batch = 0.6278s	
5423/33650 (epoch 8.058), train_loss = 1.40726207, grad/param norm = 1.8359e-01, time/batch = 0.6283s	
5424/33650 (epoch 8.059), train_loss = 1.35690191, grad/param norm = 1.6782e-01, time/batch = 0.6269s	
5425/33650 (epoch 8.061), train_loss = 1.36005748, grad/param norm = 1.5354e-01, time/batch = 0.6287s	
5426/33650 (epoch 8.062), train_loss = 1.31297226, grad/param norm = 1.4645e-01, time/batch = 0.6289s	
5427/33650 (epoch 8.064), train_loss = 1.20925900, grad/param norm = 1.4551e-01, time/batch = 0.6251s	
5428/33650 (epoch 8.065), train_loss = 1.21352462, grad/param norm = 1.5385e-01, time/batch = 0.6304s	
5429/33650 (epoch 8.067), train_loss = 1.13377830, grad/param norm = 1.4791e-01, time/batch = 0.6365s	
5430/33650 (epoch 8.068), train_loss = 1.29814456, grad/param norm = 1.5889e-01, time/batch = 0.6314s	
5431/33650 (epoch 8.070), train_loss = 1.27705030, grad/param norm = 1.6416e-01, time/batch = 0.6302s	
5432/33650 (epoch 8.071), train_loss = 1.28100033, grad/param norm = 1.4851e-01, time/batch = 0.6461s	
5433/33650 (epoch 8.073), train_loss = 1.35259481, grad/param norm = 1.6701e-01, time/batch = 0.6662s	
5434/33650 (epoch 8.074), train_loss = 1.38408765, grad/param norm = 1.6428e-01, time/batch = 0.6264s	
5435/33650 (epoch 8.076), train_loss = 1.42959983, grad/param norm = 1.7561e-01, time/batch = 0.6260s	
5436/33650 (epoch 8.077), train_loss = 1.22659909, grad/param norm = 1.4607e-01, time/batch = 0.6279s	
5437/33650 (epoch 8.079), train_loss = 1.23593514, grad/param norm = 1.6613e-01, time/batch = 0.6282s	
5438/33650 (epoch 8.080), train_loss = 1.35268527, grad/param norm = 1.7058e-01, time/batch = 0.6270s	
5439/33650 (epoch 8.082), train_loss = 1.41055066, grad/param norm = 1.7279e-01, time/batch = 0.6305s	
5440/33650 (epoch 8.083), train_loss = 1.33161090, grad/param norm = 1.5493e-01, time/batch = 0.6323s	
5441/33650 (epoch 8.085), train_loss = 1.35708162, grad/param norm = 1.5112e-01, time/batch = 0.6312s	
5442/33650 (epoch 8.086), train_loss = 1.37928922, grad/param norm = 1.7615e-01, time/batch = 0.6288s	
5443/33650 (epoch 8.088), train_loss = 1.32566599, grad/param norm = 1.5523e-01, time/batch = 0.6267s	
5444/33650 (epoch 8.089), train_loss = 1.32614591, grad/param norm = 1.7173e-01, time/batch = 0.6283s	
5445/33650 (epoch 8.091), train_loss = 1.19628549, grad/param norm = 1.4436e-01, time/batch = 0.6275s	
5446/33650 (epoch 8.092), train_loss = 1.21461066, grad/param norm = 1.5011e-01, time/batch = 0.6275s	
5447/33650 (epoch 8.094), train_loss = 1.33980957, grad/param norm = 1.5302e-01, time/batch = 0.6290s	
5448/33650 (epoch 8.095), train_loss = 1.33971826, grad/param norm = 1.6594e-01, time/batch = 0.6264s	
5449/33650 (epoch 8.097), train_loss = 1.26297814, grad/param norm = 1.6652e-01, time/batch = 0.6280s	
5450/33650 (epoch 8.098), train_loss = 1.02951200, grad/param norm = 1.3713e-01, time/batch = 0.6274s	
5451/33650 (epoch 8.100), train_loss = 1.17134936, grad/param norm = 1.4805e-01, time/batch = 0.6310s	
5452/33650 (epoch 8.101), train_loss = 1.21543596, grad/param norm = 1.6941e-01, time/batch = 0.6282s	
5453/33650 (epoch 8.103), train_loss = 1.16159011, grad/param norm = 1.4074e-01, time/batch = 0.6655s	
5454/33650 (epoch 8.104), train_loss = 1.31096609, grad/param norm = 1.5087e-01, time/batch = 0.6490s	
5455/33650 (epoch 8.105), train_loss = 1.27618984, grad/param norm = 1.7170e-01, time/batch = 0.6250s	
5456/33650 (epoch 8.107), train_loss = 1.17026232, grad/param norm = 1.6916e-01, time/batch = 0.6255s	
5457/33650 (epoch 8.108), train_loss = 1.34141041, grad/param norm = 1.6690e-01, time/batch = 0.6277s	
5458/33650 (epoch 8.110), train_loss = 1.44446803, grad/param norm = 1.5874e-01, time/batch = 0.6341s	
5459/33650 (epoch 8.111), train_loss = 1.20635531, grad/param norm = 1.6324e-01, time/batch = 0.6397s	
5460/33650 (epoch 8.113), train_loss = 1.21618662, grad/param norm = 1.5543e-01, time/batch = 0.6462s	
5461/33650 (epoch 8.114), train_loss = 1.37232420, grad/param norm = 1.6941e-01, time/batch = 0.6446s	
5462/33650 (epoch 8.116), train_loss = 1.13576852, grad/param norm = 1.4911e-01, time/batch = 0.6507s	
5463/33650 (epoch 8.117), train_loss = 1.26692224, grad/param norm = 1.4519e-01, time/batch = 0.6283s	
5464/33650 (epoch 8.119), train_loss = 1.11305833, grad/param norm = 1.4110e-01, time/batch = 0.6273s	
5465/33650 (epoch 8.120), train_loss = 1.18701874, grad/param norm = 1.5685e-01, time/batch = 0.6319s	
5466/33650 (epoch 8.122), train_loss = 1.09448670, grad/param norm = 1.5427e-01, time/batch = 0.6287s	
5467/33650 (epoch 8.123), train_loss = 1.20472147, grad/param norm = 1.4543e-01, time/batch = 0.6255s	
5468/33650 (epoch 8.125), train_loss = 1.40308151, grad/param norm = 1.6549e-01, time/batch = 0.6408s	
5469/33650 (epoch 8.126), train_loss = 1.49481901, grad/param norm = 1.6426e-01, time/batch = 0.6702s	
5470/33650 (epoch 8.128), train_loss = 1.39678038, grad/param norm = 1.7125e-01, time/batch = 0.6455s	
5471/33650 (epoch 8.129), train_loss = 1.39170927, grad/param norm = 1.6034e-01, time/batch = 0.6348s	
5472/33650 (epoch 8.131), train_loss = 1.32467730, grad/param norm = 1.6072e-01, time/batch = 0.6286s	
5473/33650 (epoch 8.132), train_loss = 1.28426540, grad/param norm = 1.5570e-01, time/batch = 0.6265s	
5474/33650 (epoch 8.134), train_loss = 1.43411872, grad/param norm = 1.6123e-01, time/batch = 0.6298s	
5475/33650 (epoch 8.135), train_loss = 1.15848613, grad/param norm = 1.6314e-01, time/batch = 0.6328s	
5476/33650 (epoch 8.137), train_loss = 1.25877590, grad/param norm = 1.5295e-01, time/batch = 0.6329s	
5477/33650 (epoch 8.138), train_loss = 1.33230255, grad/param norm = 1.4629e-01, time/batch = 0.6311s	
5478/33650 (epoch 8.140), train_loss = 1.35361042, grad/param norm = 1.7241e-01, time/batch = 0.6271s	
5479/33650 (epoch 8.141), train_loss = 1.41914462, grad/param norm = 1.6372e-01, time/batch = 0.6257s	
5480/33650 (epoch 8.143), train_loss = 1.57356340, grad/param norm = 1.9173e-01, time/batch = 0.6263s	
5481/33650 (epoch 8.144), train_loss = 1.42636015, grad/param norm = 1.6825e-01, time/batch = 0.6291s	
5482/33650 (epoch 8.146), train_loss = 1.26597187, grad/param norm = 1.6973e-01, time/batch = 0.6321s	
5483/33650 (epoch 8.147), train_loss = 1.22644963, grad/param norm = 1.5289e-01, time/batch = 0.6312s	
5484/33650 (epoch 8.149), train_loss = 1.14824780, grad/param norm = 1.5613e-01, time/batch = 0.6311s	
5485/33650 (epoch 8.150), train_loss = 1.14592966, grad/param norm = 1.3839e-01, time/batch = 0.6273s	
5486/33650 (epoch 8.152), train_loss = 1.20151470, grad/param norm = 1.4764e-01, time/batch = 0.6264s	
5487/33650 (epoch 8.153), train_loss = 1.24207752, grad/param norm = 1.5135e-01, time/batch = 0.6293s	
5488/33650 (epoch 8.155), train_loss = 1.16378729, grad/param norm = 1.3394e-01, time/batch = 0.6279s	
5489/33650 (epoch 8.156), train_loss = 1.14812657, grad/param norm = 1.3459e-01, time/batch = 0.6269s	
5490/33650 (epoch 8.158), train_loss = 1.28264241, grad/param norm = 1.5626e-01, time/batch = 0.6285s	
5491/33650 (epoch 8.159), train_loss = 1.09142423, grad/param norm = 1.3557e-01, time/batch = 0.6326s	
5492/33650 (epoch 8.160), train_loss = 1.13974610, grad/param norm = 1.3064e-01, time/batch = 0.6282s	
5493/33650 (epoch 8.162), train_loss = 1.26561647, grad/param norm = 1.7179e-01, time/batch = 0.6267s	
5494/33650 (epoch 8.163), train_loss = 1.38713147, grad/param norm = 1.6275e-01, time/batch = 0.6258s	
5495/33650 (epoch 8.165), train_loss = 1.13173586, grad/param norm = 1.3963e-01, time/batch = 0.6255s	
5496/33650 (epoch 8.166), train_loss = 1.14539246, grad/param norm = 1.4462e-01, time/batch = 0.6252s	
5497/33650 (epoch 8.168), train_loss = 1.37629706, grad/param norm = 1.5404e-01, time/batch = 0.6259s	
5498/33650 (epoch 8.169), train_loss = 1.24290568, grad/param norm = 1.4807e-01, time/batch = 0.6326s	
5499/33650 (epoch 8.171), train_loss = 1.28281804, grad/param norm = 1.7060e-01, time/batch = 0.6245s	
5500/33650 (epoch 8.172), train_loss = 1.22906905, grad/param norm = 1.6032e-01, time/batch = 0.6249s	
5501/33650 (epoch 8.174), train_loss = 1.15976550, grad/param norm = 1.5370e-01, time/batch = 0.6278s	
5502/33650 (epoch 8.175), train_loss = 1.18449311, grad/param norm = 1.5542e-01, time/batch = 0.6258s	
5503/33650 (epoch 8.177), train_loss = 1.29578266, grad/param norm = 1.5222e-01, time/batch = 0.6261s	
5504/33650 (epoch 8.178), train_loss = 1.16189720, grad/param norm = 1.4294e-01, time/batch = 0.6277s	
5505/33650 (epoch 8.180), train_loss = 1.15308617, grad/param norm = 1.5096e-01, time/batch = 0.6314s	
5506/33650 (epoch 8.181), train_loss = 0.99313237, grad/param norm = 1.3995e-01, time/batch = 0.6253s	
5507/33650 (epoch 8.183), train_loss = 1.18748291, grad/param norm = 1.5499e-01, time/batch = 0.6250s	
5508/33650 (epoch 8.184), train_loss = 1.24254708, grad/param norm = 1.5776e-01, time/batch = 0.6243s	
5509/33650 (epoch 8.186), train_loss = 1.25522768, grad/param norm = 1.6386e-01, time/batch = 0.6343s	
5510/33650 (epoch 8.187), train_loss = 1.41953760, grad/param norm = 1.6474e-01, time/batch = 0.6657s	
5511/33650 (epoch 8.189), train_loss = 1.47556616, grad/param norm = 1.8525e-01, time/batch = 0.6393s	
5512/33650 (epoch 8.190), train_loss = 1.31807416, grad/param norm = 1.8125e-01, time/batch = 0.6292s	
5513/33650 (epoch 8.192), train_loss = 1.45113877, grad/param norm = 1.6983e-01, time/batch = 0.6286s	
5514/33650 (epoch 8.193), train_loss = 1.39125897, grad/param norm = 1.5874e-01, time/batch = 0.6310s	
5515/33650 (epoch 8.195), train_loss = 1.11756120, grad/param norm = 1.3622e-01, time/batch = 0.6333s	
5516/33650 (epoch 8.196), train_loss = 1.04484052, grad/param norm = 1.5389e-01, time/batch = 0.6409s	
5517/33650 (epoch 8.198), train_loss = 1.23026106, grad/param norm = 1.6336e-01, time/batch = 0.6269s	
5518/33650 (epoch 8.199), train_loss = 1.34359601, grad/param norm = 1.6336e-01, time/batch = 0.6267s	
5519/33650 (epoch 8.201), train_loss = 1.27021969, grad/param norm = 1.5919e-01, time/batch = 0.6470s	
5520/33650 (epoch 8.202), train_loss = 1.23078332, grad/param norm = 1.5641e-01, time/batch = 0.6366s	
5521/33650 (epoch 8.204), train_loss = 1.29947292, grad/param norm = 1.5600e-01, time/batch = 0.6322s	
5522/33650 (epoch 8.205), train_loss = 1.20066950, grad/param norm = 1.6152e-01, time/batch = 0.6285s	
5523/33650 (epoch 8.207), train_loss = 1.24789196, grad/param norm = 1.5815e-01, time/batch = 0.6303s	
5524/33650 (epoch 8.208), train_loss = 1.21922725, grad/param norm = 1.5674e-01, time/batch = 0.6262s	
5525/33650 (epoch 8.210), train_loss = 0.98570031, grad/param norm = 1.3212e-01, time/batch = 0.6274s	
5526/33650 (epoch 8.211), train_loss = 1.14964979, grad/param norm = 1.5757e-01, time/batch = 0.6288s	
5527/33650 (epoch 8.212), train_loss = 1.37888310, grad/param norm = 1.7559e-01, time/batch = 0.6302s	
5528/33650 (epoch 8.214), train_loss = 1.41825410, grad/param norm = 1.6486e-01, time/batch = 0.6269s	
5529/33650 (epoch 8.215), train_loss = 1.00939732, grad/param norm = 1.4319e-01, time/batch = 0.6277s	
5530/33650 (epoch 8.217), train_loss = 1.25926281, grad/param norm = 1.6266e-01, time/batch = 0.6419s	
5531/33650 (epoch 8.218), train_loss = 1.33365381, grad/param norm = 1.5388e-01, time/batch = 0.6402s	
5532/33650 (epoch 8.220), train_loss = 1.16565601, grad/param norm = 1.6074e-01, time/batch = 0.6273s	
5533/33650 (epoch 8.221), train_loss = 1.43597025, grad/param norm = 1.6616e-01, time/batch = 0.6268s	
5534/33650 (epoch 8.223), train_loss = 0.97838851, grad/param norm = 1.3718e-01, time/batch = 0.6352s	
5535/33650 (epoch 8.224), train_loss = 1.26550023, grad/param norm = 1.8605e-01, time/batch = 0.6632s	
5536/33650 (epoch 8.226), train_loss = 1.60755060, grad/param norm = 1.9206e-01, time/batch = 0.6422s	
5537/33650 (epoch 8.227), train_loss = 1.41399097, grad/param norm = 1.5935e-01, time/batch = 0.6265s	
5538/33650 (epoch 8.229), train_loss = 1.38242132, grad/param norm = 1.5964e-01, time/batch = 0.6266s	
5539/33650 (epoch 8.230), train_loss = 1.51313657, grad/param norm = 1.8280e-01, time/batch = 0.6273s	
5540/33650 (epoch 8.232), train_loss = 1.31969999, grad/param norm = 1.6273e-01, time/batch = 0.6262s	
5541/33650 (epoch 8.233), train_loss = 1.33510973, grad/param norm = 1.7904e-01, time/batch = 0.6315s	
5542/33650 (epoch 8.235), train_loss = 1.21827312, grad/param norm = 1.5164e-01, time/batch = 0.6252s	
5543/33650 (epoch 8.236), train_loss = 1.09162094, grad/param norm = 1.5475e-01, time/batch = 0.6254s	
5544/33650 (epoch 8.238), train_loss = 1.22086295, grad/param norm = 1.4924e-01, time/batch = 0.6253s	
5545/33650 (epoch 8.239), train_loss = 1.14315210, grad/param norm = 1.5104e-01, time/batch = 0.6257s	
5546/33650 (epoch 8.241), train_loss = 1.19488886, grad/param norm = 1.4333e-01, time/batch = 0.6276s	
5547/33650 (epoch 8.242), train_loss = 1.05252475, grad/param norm = 1.3979e-01, time/batch = 0.6302s	
5548/33650 (epoch 8.244), train_loss = 1.24878665, grad/param norm = 1.5014e-01, time/batch = 0.6298s	
5549/33650 (epoch 8.245), train_loss = 1.09533262, grad/param norm = 1.4647e-01, time/batch = 0.6266s	
5550/33650 (epoch 8.247), train_loss = 1.24471660, grad/param norm = 1.7070e-01, time/batch = 0.6261s	
5551/33650 (epoch 8.248), train_loss = 1.17312258, grad/param norm = 1.5920e-01, time/batch = 0.6274s	
5552/33650 (epoch 8.250), train_loss = 1.23876942, grad/param norm = 1.4627e-01, time/batch = 0.6318s	
5553/33650 (epoch 8.251), train_loss = 1.40930518, grad/param norm = 1.5645e-01, time/batch = 0.6469s	
5554/33650 (epoch 8.253), train_loss = 1.11424088, grad/param norm = 1.4031e-01, time/batch = 0.6491s	
5555/33650 (epoch 8.254), train_loss = 1.12464758, grad/param norm = 1.3952e-01, time/batch = 0.6625s	
5556/33650 (epoch 8.256), train_loss = 1.32938016, grad/param norm = 1.4624e-01, time/batch = 0.6807s	
5557/33650 (epoch 8.257), train_loss = 1.45717610, grad/param norm = 1.5909e-01, time/batch = 0.6504s	
5558/33650 (epoch 8.259), train_loss = 1.04834944, grad/param norm = 1.3940e-01, time/batch = 0.6278s	
5559/33650 (epoch 8.260), train_loss = 1.42408985, grad/param norm = 1.6774e-01, time/batch = 0.6340s	
5560/33650 (epoch 8.262), train_loss = 1.33011125, grad/param norm = 1.6191e-01, time/batch = 0.6277s	
5561/33650 (epoch 8.263), train_loss = 1.28494519, grad/param norm = 1.9534e-01, time/batch = 0.6401s	
5562/33650 (epoch 8.264), train_loss = 1.26172389, grad/param norm = 1.6439e-01, time/batch = 0.6333s	
5563/33650 (epoch 8.266), train_loss = 1.25298699, grad/param norm = 1.5696e-01, time/batch = 0.6425s	
5564/33650 (epoch 8.267), train_loss = 1.21421610, grad/param norm = 1.7498e-01, time/batch = 0.6288s	
5565/33650 (epoch 8.269), train_loss = 1.31502460, grad/param norm = 1.5406e-01, time/batch = 0.6254s	
5566/33650 (epoch 8.270), train_loss = 1.17499630, grad/param norm = 1.4574e-01, time/batch = 0.6246s	
5567/33650 (epoch 8.272), train_loss = 1.25091173, grad/param norm = 1.5272e-01, time/batch = 0.6243s	
5568/33650 (epoch 8.273), train_loss = 1.45128375, grad/param norm = 1.8786e-01, time/batch = 0.6261s	
5569/33650 (epoch 8.275), train_loss = 1.36417230, grad/param norm = 1.6110e-01, time/batch = 0.6327s	
5570/33650 (epoch 8.276), train_loss = 1.42827527, grad/param norm = 1.6948e-01, time/batch = 0.6421s	
5571/33650 (epoch 8.278), train_loss = 1.55732470, grad/param norm = 1.8905e-01, time/batch = 0.6726s	
5572/33650 (epoch 8.279), train_loss = 1.19273352, grad/param norm = 1.6182e-01, time/batch = 0.6551s	
5573/33650 (epoch 8.281), train_loss = 1.30015686, grad/param norm = 1.6794e-01, time/batch = 0.6400s	
5574/33650 (epoch 8.282), train_loss = 1.36919328, grad/param norm = 1.4539e-01, time/batch = 0.6377s	
5575/33650 (epoch 8.284), train_loss = 1.37968110, grad/param norm = 1.7387e-01, time/batch = 0.6361s	
5576/33650 (epoch 8.285), train_loss = 1.38590823, grad/param norm = 1.7093e-01, time/batch = 0.6366s	
5577/33650 (epoch 8.287), train_loss = 1.25962304, grad/param norm = 1.5718e-01, time/batch = 0.6383s	
5578/33650 (epoch 8.288), train_loss = 1.31679812, grad/param norm = 1.7273e-01, time/batch = 0.6375s	
5579/33650 (epoch 8.290), train_loss = 1.26923911, grad/param norm = 1.4532e-01, time/batch = 0.6374s	
5580/33650 (epoch 8.291), train_loss = 1.15394535, grad/param norm = 1.4748e-01, time/batch = 0.6267s	
5581/33650 (epoch 8.293), train_loss = 1.27964594, grad/param norm = 1.7799e-01, time/batch = 0.6270s	
5582/33650 (epoch 8.294), train_loss = 1.13216362, grad/param norm = 1.4394e-01, time/batch = 0.6257s	
5583/33650 (epoch 8.296), train_loss = 1.12361771, grad/param norm = 1.5850e-01, time/batch = 0.6252s	
5584/33650 (epoch 8.297), train_loss = 1.27830244, grad/param norm = 1.5141e-01, time/batch = 0.6262s	
5585/33650 (epoch 8.299), train_loss = 1.14262331, grad/param norm = 1.5013e-01, time/batch = 0.6286s	
5586/33650 (epoch 8.300), train_loss = 1.19150561, grad/param norm = 1.4895e-01, time/batch = 0.6445s	
5587/33650 (epoch 8.302), train_loss = 1.24084455, grad/param norm = 1.4312e-01, time/batch = 0.6660s	
5588/33650 (epoch 8.303), train_loss = 1.25706166, grad/param norm = 1.4304e-01, time/batch = 0.6300s	
5589/33650 (epoch 8.305), train_loss = 1.29776430, grad/param norm = 1.5240e-01, time/batch = 0.6261s	
5590/33650 (epoch 8.306), train_loss = 1.18761842, grad/param norm = 1.3746e-01, time/batch = 0.6248s	
5591/33650 (epoch 8.308), train_loss = 1.18813706, grad/param norm = 1.5986e-01, time/batch = 0.6280s	
5592/33650 (epoch 8.309), train_loss = 1.44160346, grad/param norm = 1.6976e-01, time/batch = 0.6303s	
5593/33650 (epoch 8.311), train_loss = 1.32480011, grad/param norm = 1.5537e-01, time/batch = 0.6300s	
5594/33650 (epoch 8.312), train_loss = 1.22703270, grad/param norm = 1.6091e-01, time/batch = 0.6270s	
5595/33650 (epoch 8.314), train_loss = 1.04947160, grad/param norm = 1.3155e-01, time/batch = 0.6264s	
5596/33650 (epoch 8.315), train_loss = 1.27702345, grad/param norm = 1.5857e-01, time/batch = 0.6265s	
5597/33650 (epoch 8.316), train_loss = 1.24093375, grad/param norm = 1.5727e-01, time/batch = 0.6253s	
5598/33650 (epoch 8.318), train_loss = 1.12045089, grad/param norm = 1.3610e-01, time/batch = 0.6261s	
5599/33650 (epoch 8.319), train_loss = 1.15969883, grad/param norm = 1.3666e-01, time/batch = 0.6250s	
5600/33650 (epoch 8.321), train_loss = 1.19713411, grad/param norm = 1.4566e-01, time/batch = 0.6265s	
5601/33650 (epoch 8.322), train_loss = 1.30946798, grad/param norm = 1.7367e-01, time/batch = 0.6323s	
5602/33650 (epoch 8.324), train_loss = 1.35714378, grad/param norm = 1.8219e-01, time/batch = 0.6299s	
5603/33650 (epoch 8.325), train_loss = 1.31929212, grad/param norm = 1.5674e-01, time/batch = 0.6292s	
5604/33650 (epoch 8.327), train_loss = 1.10163192, grad/param norm = 1.4653e-01, time/batch = 0.6315s	
5605/33650 (epoch 8.328), train_loss = 1.34627065, grad/param norm = 1.6507e-01, time/batch = 0.6283s	
5606/33650 (epoch 8.330), train_loss = 1.13765959, grad/param norm = 1.3291e-01, time/batch = 0.6261s	
5607/33650 (epoch 8.331), train_loss = 1.06245006, grad/param norm = 1.3435e-01, time/batch = 0.6626s	
5608/33650 (epoch 8.333), train_loss = 1.22523425, grad/param norm = 1.4253e-01, time/batch = 0.6504s	
5609/33650 (epoch 8.334), train_loss = 1.24496265, grad/param norm = 1.4903e-01, time/batch = 0.6271s	
5610/33650 (epoch 8.336), train_loss = 1.33028534, grad/param norm = 1.4551e-01, time/batch = 0.6246s	
5611/33650 (epoch 8.337), train_loss = 1.02786489, grad/param norm = 1.3357e-01, time/batch = 0.6329s	
5612/33650 (epoch 8.339), train_loss = 1.20986193, grad/param norm = 1.4279e-01, time/batch = 0.6264s	
5613/33650 (epoch 8.340), train_loss = 1.51916471, grad/param norm = 1.8322e-01, time/batch = 0.6275s	
5614/33650 (epoch 8.342), train_loss = 1.01314829, grad/param norm = 1.3668e-01, time/batch = 0.6278s	
5615/33650 (epoch 8.343), train_loss = 1.33677114, grad/param norm = 1.7979e-01, time/batch = 0.6336s	
5616/33650 (epoch 8.345), train_loss = 1.21708122, grad/param norm = 1.5453e-01, time/batch = 0.6309s	
5617/33650 (epoch 8.346), train_loss = 0.92526892, grad/param norm = 1.4301e-01, time/batch = 0.6272s	
5618/33650 (epoch 8.348), train_loss = 1.09499114, grad/param norm = 1.4679e-01, time/batch = 0.6346s	
5619/33650 (epoch 8.349), train_loss = 1.04560428, grad/param norm = 1.5083e-01, time/batch = 0.6430s	
5620/33650 (epoch 8.351), train_loss = 1.34229442, grad/param norm = 1.7090e-01, time/batch = 0.6261s	
5621/33650 (epoch 8.352), train_loss = 1.20137756, grad/param norm = 1.4212e-01, time/batch = 0.6276s	
5622/33650 (epoch 8.354), train_loss = 1.52520428, grad/param norm = 1.7943e-01, time/batch = 0.6296s	
5623/33650 (epoch 8.355), train_loss = 1.33325839, grad/param norm = 1.5389e-01, time/batch = 0.6279s	
5624/33650 (epoch 8.357), train_loss = 1.04132886, grad/param norm = 1.3452e-01, time/batch = 0.6254s	
5625/33650 (epoch 8.358), train_loss = 1.35583614, grad/param norm = 1.6424e-01, time/batch = 0.6294s	
5626/33650 (epoch 8.360), train_loss = 1.34141130, grad/param norm = 1.6396e-01, time/batch = 0.6381s	
5627/33650 (epoch 8.361), train_loss = 1.25084477, grad/param norm = 1.4220e-01, time/batch = 0.6628s	
5628/33650 (epoch 8.363), train_loss = 1.15378980, grad/param norm = 1.4183e-01, time/batch = 0.6583s	
5629/33650 (epoch 8.364), train_loss = 1.22948276, grad/param norm = 1.4728e-01, time/batch = 0.6323s	
5630/33650 (epoch 8.366), train_loss = 1.27736395, grad/param norm = 1.5811e-01, time/batch = 0.6463s	
5631/33650 (epoch 8.367), train_loss = 1.34149548, grad/param norm = 1.5908e-01, time/batch = 0.6390s	
5632/33650 (epoch 8.368), train_loss = 1.13451109, grad/param norm = 1.5272e-01, time/batch = 0.6293s	
5633/33650 (epoch 8.370), train_loss = 1.25622796, grad/param norm = 1.5108e-01, time/batch = 0.6260s	
5634/33650 (epoch 8.371), train_loss = 1.03542992, grad/param norm = 1.4324e-01, time/batch = 0.6237s	
5635/33650 (epoch 8.373), train_loss = 1.15638527, grad/param norm = 1.4581e-01, time/batch = 0.6237s	
5636/33650 (epoch 8.374), train_loss = 1.03713492, grad/param norm = 1.3275e-01, time/batch = 0.6293s	
5637/33650 (epoch 8.376), train_loss = 1.21466590, grad/param norm = 1.6455e-01, time/batch = 0.6276s	
5638/33650 (epoch 8.377), train_loss = 1.30310900, grad/param norm = 1.6473e-01, time/batch = 0.6271s	
5639/33650 (epoch 8.379), train_loss = 1.29319996, grad/param norm = 1.3998e-01, time/batch = 0.6290s	
5640/33650 (epoch 8.380), train_loss = 1.01161177, grad/param norm = 1.5390e-01, time/batch = 0.6275s	
5641/33650 (epoch 8.382), train_loss = 1.05704657, grad/param norm = 1.2714e-01, time/batch = 0.6281s	
5642/33650 (epoch 8.383), train_loss = 1.19438391, grad/param norm = 1.5113e-01, time/batch = 0.6269s	
5643/33650 (epoch 8.385), train_loss = 1.38105358, grad/param norm = 1.5962e-01, time/batch = 0.6264s	
5644/33650 (epoch 8.386), train_loss = 1.15974083, grad/param norm = 1.4761e-01, time/batch = 0.6277s	
5645/33650 (epoch 8.388), train_loss = 1.25225262, grad/param norm = 1.4320e-01, time/batch = 0.6258s	
5646/33650 (epoch 8.389), train_loss = 1.26025535, grad/param norm = 1.6321e-01, time/batch = 0.6303s	
5647/33650 (epoch 8.391), train_loss = 1.03651861, grad/param norm = 1.4049e-01, time/batch = 0.6331s	
5648/33650 (epoch 8.392), train_loss = 1.33947313, grad/param norm = 1.6492e-01, time/batch = 0.6671s	
5649/33650 (epoch 8.394), train_loss = 1.38083729, grad/param norm = 1.7841e-01, time/batch = 0.6530s	
5650/33650 (epoch 8.395), train_loss = 1.23964554, grad/param norm = 1.5799e-01, time/batch = 0.6536s	
5651/33650 (epoch 8.397), train_loss = 1.44639959, grad/param norm = 1.7354e-01, time/batch = 0.6418s	
5652/33650 (epoch 8.398), train_loss = 1.22907563, grad/param norm = 1.3598e-01, time/batch = 0.6312s	
5653/33650 (epoch 8.400), train_loss = 1.26560737, grad/param norm = 1.7723e-01, time/batch = 0.6322s	
5654/33650 (epoch 8.401), train_loss = 1.26545078, grad/param norm = 1.7272e-01, time/batch = 0.6340s	
5655/33650 (epoch 8.403), train_loss = 1.31817693, grad/param norm = 1.6865e-01, time/batch = 0.6323s	
5656/33650 (epoch 8.404), train_loss = 1.19828928, grad/param norm = 1.2947e-01, time/batch = 0.6305s	
5657/33650 (epoch 8.406), train_loss = 1.28982571, grad/param norm = 1.5288e-01, time/batch = 0.6295s	
5658/33650 (epoch 8.407), train_loss = 1.25776474, grad/param norm = 1.5762e-01, time/batch = 0.6275s	
5659/33650 (epoch 8.409), train_loss = 1.26852597, grad/param norm = 1.5037e-01, time/batch = 0.6264s	
5660/33650 (epoch 8.410), train_loss = 1.24494541, grad/param norm = 1.6214e-01, time/batch = 0.6258s	
5661/33650 (epoch 8.412), train_loss = 1.23277561, grad/param norm = 1.3889e-01, time/batch = 0.6272s	
5662/33650 (epoch 8.413), train_loss = 1.13043242, grad/param norm = 1.4032e-01, time/batch = 0.6272s	
5663/33650 (epoch 8.415), train_loss = 1.29860327, grad/param norm = 1.5774e-01, time/batch = 0.6298s	
5664/33650 (epoch 8.416), train_loss = 1.44116298, grad/param norm = 1.6763e-01, time/batch = 0.6299s	
5665/33650 (epoch 8.418), train_loss = 1.26781015, grad/param norm = 1.5596e-01, time/batch = 0.6288s	
5666/33650 (epoch 8.419), train_loss = 1.17990041, grad/param norm = 1.4652e-01, time/batch = 0.6487s	
5667/33650 (epoch 8.421), train_loss = 1.14974179, grad/param norm = 1.3536e-01, time/batch = 0.6481s	
5668/33650 (epoch 8.422), train_loss = 1.36350571, grad/param norm = 1.5971e-01, time/batch = 0.6725s	
5669/33650 (epoch 8.423), train_loss = 1.10721860, grad/param norm = 1.4528e-01, time/batch = 0.6631s	
5670/33650 (epoch 8.425), train_loss = 1.29498560, grad/param norm = 1.6947e-01, time/batch = 0.6273s	
5671/33650 (epoch 8.426), train_loss = 1.39434476, grad/param norm = 1.6026e-01, time/batch = 0.6333s	
5672/33650 (epoch 8.428), train_loss = 1.17932686, grad/param norm = 1.5238e-01, time/batch = 0.6290s	
5673/33650 (epoch 8.429), train_loss = 1.34547183, grad/param norm = 1.5308e-01, time/batch = 0.6261s	
5674/33650 (epoch 8.431), train_loss = 1.48680521, grad/param norm = 1.7341e-01, time/batch = 0.6259s	
5675/33650 (epoch 8.432), train_loss = 1.54891094, grad/param norm = 1.7189e-01, time/batch = 0.6269s	
5676/33650 (epoch 8.434), train_loss = 1.32000929, grad/param norm = 1.5026e-01, time/batch = 0.6270s	
5677/33650 (epoch 8.435), train_loss = 1.29836607, grad/param norm = 1.6547e-01, time/batch = 0.6256s	
5678/33650 (epoch 8.437), train_loss = 1.32245742, grad/param norm = 1.6268e-01, time/batch = 0.6265s	
5679/33650 (epoch 8.438), train_loss = 1.19945878, grad/param norm = 1.5900e-01, time/batch = 0.6290s	
5680/33650 (epoch 8.440), train_loss = 1.29162427, grad/param norm = 1.6459e-01, time/batch = 0.6267s	
5681/33650 (epoch 8.441), train_loss = 1.32097295, grad/param norm = 1.5987e-01, time/batch = 0.6269s	
5682/33650 (epoch 8.443), train_loss = 1.32462892, grad/param norm = 1.6790e-01, time/batch = 0.6277s	
5683/33650 (epoch 8.444), train_loss = 1.20384999, grad/param norm = 1.3958e-01, time/batch = 0.6268s	
5684/33650 (epoch 8.446), train_loss = 1.31997523, grad/param norm = 1.6798e-01, time/batch = 0.6264s	
5685/33650 (epoch 8.447), train_loss = 1.37882293, grad/param norm = 1.7355e-01, time/batch = 0.6265s	
5686/33650 (epoch 8.449), train_loss = 1.49787013, grad/param norm = 2.0026e-01, time/batch = 0.6258s	
5687/33650 (epoch 8.450), train_loss = 1.50970944, grad/param norm = 1.8993e-01, time/batch = 0.6308s	
5688/33650 (epoch 8.452), train_loss = 1.58283413, grad/param norm = 1.7693e-01, time/batch = 0.6338s	
5689/33650 (epoch 8.453), train_loss = 1.46757024, grad/param norm = 1.8063e-01, time/batch = 0.6659s	
5690/33650 (epoch 8.455), train_loss = 1.25558526, grad/param norm = 1.4625e-01, time/batch = 0.6391s	
5691/33650 (epoch 8.456), train_loss = 1.24238415, grad/param norm = 1.4543e-01, time/batch = 0.6298s	
5692/33650 (epoch 8.458), train_loss = 1.26031400, grad/param norm = 1.5493e-01, time/batch = 0.6277s	
5693/33650 (epoch 8.459), train_loss = 1.24699321, grad/param norm = 1.6166e-01, time/batch = 0.6497s	
5694/33650 (epoch 8.461), train_loss = 1.43910497, grad/param norm = 1.6856e-01, time/batch = 0.6633s	
5695/33650 (epoch 8.462), train_loss = 1.39751916, grad/param norm = 1.6582e-01, time/batch = 0.6272s	
5696/33650 (epoch 8.464), train_loss = 1.20113387, grad/param norm = 1.6489e-01, time/batch = 0.6258s	
5697/33650 (epoch 8.465), train_loss = 1.32461711, grad/param norm = 1.6954e-01, time/batch = 0.6253s	
5698/33650 (epoch 8.467), train_loss = 1.35955788, grad/param norm = 1.7220e-01, time/batch = 0.6269s	
5699/33650 (epoch 8.468), train_loss = 1.40901336, grad/param norm = 1.6350e-01, time/batch = 0.6260s	
5700/33650 (epoch 8.470), train_loss = 1.56765422, grad/param norm = 1.8227e-01, time/batch = 0.6285s	
5701/33650 (epoch 8.471), train_loss = 1.28794155, grad/param norm = 1.6920e-01, time/batch = 0.6333s	
5702/33650 (epoch 8.473), train_loss = 1.23030040, grad/param norm = 1.4509e-01, time/batch = 0.6291s	
5703/33650 (epoch 8.474), train_loss = 1.33599711, grad/param norm = 1.6247e-01, time/batch = 0.6281s	
5704/33650 (epoch 8.475), train_loss = 1.37709892, grad/param norm = 1.6980e-01, time/batch = 0.6263s	
5705/33650 (epoch 8.477), train_loss = 1.41264012, grad/param norm = 1.6056e-01, time/batch = 0.6262s	
5706/33650 (epoch 8.478), train_loss = 1.39098899, grad/param norm = 1.7113e-01, time/batch = 0.6265s	
5707/33650 (epoch 8.480), train_loss = 1.44766195, grad/param norm = 1.6680e-01, time/batch = 0.6269s	
5708/33650 (epoch 8.481), train_loss = 1.40499294, grad/param norm = 1.7315e-01, time/batch = 0.6265s	
5709/33650 (epoch 8.483), train_loss = 1.04028986, grad/param norm = 1.4778e-01, time/batch = 0.6271s	
5710/33650 (epoch 8.484), train_loss = 1.30845974, grad/param norm = 1.5121e-01, time/batch = 0.6267s	
5711/33650 (epoch 8.486), train_loss = 1.43346579, grad/param norm = 2.0227e-01, time/batch = 0.6307s	
5712/33650 (epoch 8.487), train_loss = 1.41114557, grad/param norm = 1.8236e-01, time/batch = 0.6263s	
5713/33650 (epoch 8.489), train_loss = 1.50589302, grad/param norm = 1.6686e-01, time/batch = 0.6263s	
5714/33650 (epoch 8.490), train_loss = 1.18500055, grad/param norm = 1.4852e-01, time/batch = 0.6662s	
5715/33650 (epoch 8.492), train_loss = 1.36630781, grad/param norm = 1.8008e-01, time/batch = 0.6461s	
5716/33650 (epoch 8.493), train_loss = 1.04373998, grad/param norm = 1.3578e-01, time/batch = 0.6260s	
5717/33650 (epoch 8.495), train_loss = 1.28667004, grad/param norm = 1.5458e-01, time/batch = 0.6291s	
5718/33650 (epoch 8.496), train_loss = 1.34791484, grad/param norm = 1.7410e-01, time/batch = 0.6266s	
5719/33650 (epoch 8.498), train_loss = 1.11536832, grad/param norm = 1.4938e-01, time/batch = 0.6249s	
5720/33650 (epoch 8.499), train_loss = 1.25378308, grad/param norm = 1.4226e-01, time/batch = 0.6261s	
5721/33650 (epoch 8.501), train_loss = 1.21339610, grad/param norm = 1.4824e-01, time/batch = 0.6347s	
5722/33650 (epoch 8.502), train_loss = 1.33051851, grad/param norm = 1.5878e-01, time/batch = 0.6377s	
5723/33650 (epoch 8.504), train_loss = 1.45804145, grad/param norm = 1.7792e-01, time/batch = 0.6280s	
5724/33650 (epoch 8.505), train_loss = 1.32468822, grad/param norm = 1.8790e-01, time/batch = 0.6317s	
5725/33650 (epoch 8.507), train_loss = 1.42640578, grad/param norm = 1.6725e-01, time/batch = 0.6263s	
5726/33650 (epoch 8.508), train_loss = 1.21377396, grad/param norm = 1.5051e-01, time/batch = 0.6250s	
5727/33650 (epoch 8.510), train_loss = 1.27234660, grad/param norm = 1.5166e-01, time/batch = 0.6271s	
5728/33650 (epoch 8.511), train_loss = 1.56936247, grad/param norm = 1.9058e-01, time/batch = 0.6257s	
5729/33650 (epoch 8.513), train_loss = 1.34849941, grad/param norm = 1.4832e-01, time/batch = 0.6360s	
5730/33650 (epoch 8.514), train_loss = 1.37933719, grad/param norm = 1.7019e-01, time/batch = 0.6656s	
5731/33650 (epoch 8.516), train_loss = 1.30784471, grad/param norm = 1.6816e-01, time/batch = 0.6385s	
5732/33650 (epoch 8.517), train_loss = 1.25896415, grad/param norm = 1.5896e-01, time/batch = 0.6278s	
5733/33650 (epoch 8.519), train_loss = 1.28727024, grad/param norm = 1.4632e-01, time/batch = 0.6275s	
5734/33650 (epoch 8.520), train_loss = 1.09807336, grad/param norm = 1.4313e-01, time/batch = 0.6384s	
5735/33650 (epoch 8.522), train_loss = 1.29909520, grad/param norm = 1.6385e-01, time/batch = 0.6413s	
5736/33650 (epoch 8.523), train_loss = 1.27787220, grad/param norm = 1.4624e-01, time/batch = 0.6255s	
5737/33650 (epoch 8.525), train_loss = 1.00605533, grad/param norm = 1.3735e-01, time/batch = 0.6256s	
5738/33650 (epoch 8.526), train_loss = 1.33017676, grad/param norm = 1.5007e-01, time/batch = 0.6249s	
5739/33650 (epoch 8.527), train_loss = 1.14837548, grad/param norm = 1.3652e-01, time/batch = 0.6311s	
5740/33650 (epoch 8.529), train_loss = 1.25780761, grad/param norm = 1.4285e-01, time/batch = 0.6263s	
5741/33650 (epoch 8.530), train_loss = 1.19811563, grad/param norm = 1.4667e-01, time/batch = 0.6331s	
5742/33650 (epoch 8.532), train_loss = 1.50788063, grad/param norm = 1.8966e-01, time/batch = 0.6409s	
5743/33650 (epoch 8.533), train_loss = 1.24577522, grad/param norm = 1.5971e-01, time/batch = 0.6437s	
5744/33650 (epoch 8.535), train_loss = 1.40563918, grad/param norm = 1.5750e-01, time/batch = 0.6470s	
5745/33650 (epoch 8.536), train_loss = 1.32309413, grad/param norm = 1.6626e-01, time/batch = 0.6476s	
5746/33650 (epoch 8.538), train_loss = 1.33172666, grad/param norm = 1.7590e-01, time/batch = 0.6416s	
5747/33650 (epoch 8.539), train_loss = 1.07280154, grad/param norm = 1.4365e-01, time/batch = 0.6320s	
5748/33650 (epoch 8.541), train_loss = 1.42667452, grad/param norm = 1.6187e-01, time/batch = 0.6295s	
5749/33650 (epoch 8.542), train_loss = 1.33788486, grad/param norm = 1.8477e-01, time/batch = 0.6272s	
5750/33650 (epoch 8.544), train_loss = 1.54481022, grad/param norm = 1.7446e-01, time/batch = 0.6251s	
5751/33650 (epoch 8.545), train_loss = 1.12398572, grad/param norm = 1.4640e-01, time/batch = 0.6534s	
5752/33650 (epoch 8.547), train_loss = 1.29606716, grad/param norm = 1.4927e-01, time/batch = 0.6386s	
5753/33650 (epoch 8.548), train_loss = 1.42689526, grad/param norm = 1.6072e-01, time/batch = 0.6313s	
5754/33650 (epoch 8.550), train_loss = 1.24636922, grad/param norm = 1.5119e-01, time/batch = 0.6390s	
5755/33650 (epoch 8.551), train_loss = 1.25738767, grad/param norm = 1.5267e-01, time/batch = 0.6660s	
5756/33650 (epoch 8.553), train_loss = 1.07293927, grad/param norm = 1.4662e-01, time/batch = 0.6349s	
5757/33650 (epoch 8.554), train_loss = 1.41186090, grad/param norm = 1.7052e-01, time/batch = 0.6263s	
5758/33650 (epoch 8.556), train_loss = 1.43053979, grad/param norm = 1.8570e-01, time/batch = 0.6415s	
5759/33650 (epoch 8.557), train_loss = 1.49043500, grad/param norm = 1.8626e-01, time/batch = 0.6289s	
5760/33650 (epoch 8.559), train_loss = 1.56923171, grad/param norm = 2.0108e-01, time/batch = 0.6281s	
5761/33650 (epoch 8.560), train_loss = 1.52016565, grad/param norm = 1.6862e-01, time/batch = 0.6355s	
5762/33650 (epoch 8.562), train_loss = 1.37136151, grad/param norm = 1.5377e-01, time/batch = 0.6348s	
5763/33650 (epoch 8.563), train_loss = 1.27125921, grad/param norm = 1.6212e-01, time/batch = 0.6384s	
5764/33650 (epoch 8.565), train_loss = 1.31137526, grad/param norm = 1.5050e-01, time/batch = 0.6291s	
5765/33650 (epoch 8.566), train_loss = 1.31791471, grad/param norm = 1.6645e-01, time/batch = 0.6311s	
5766/33650 (epoch 8.568), train_loss = 1.29570667, grad/param norm = 1.5230e-01, time/batch = 0.6300s	
5767/33650 (epoch 8.569), train_loss = 1.22998738, grad/param norm = 1.4846e-01, time/batch = 0.6286s	
5768/33650 (epoch 8.571), train_loss = 1.43008581, grad/param norm = 1.6746e-01, time/batch = 0.6254s	
5769/33650 (epoch 8.572), train_loss = 1.33335261, grad/param norm = 1.4691e-01, time/batch = 0.6284s	
5770/33650 (epoch 8.574), train_loss = 1.28863399, grad/param norm = 1.5441e-01, time/batch = 0.6503s	
5771/33650 (epoch 8.575), train_loss = 1.27114900, grad/param norm = 1.4851e-01, time/batch = 0.6651s	
5772/33650 (epoch 8.577), train_loss = 1.36310365, grad/param norm = 1.6630e-01, time/batch = 0.6378s	
5773/33650 (epoch 8.578), train_loss = 1.31536932, grad/param norm = 1.5388e-01, time/batch = 0.6336s	
5774/33650 (epoch 8.579), train_loss = 1.37339338, grad/param norm = 1.5883e-01, time/batch = 0.6341s	
5775/33650 (epoch 8.581), train_loss = 1.36710103, grad/param norm = 1.5394e-01, time/batch = 0.6320s	
5776/33650 (epoch 8.582), train_loss = 1.38977630, grad/param norm = 1.5561e-01, time/batch = 0.6314s	
5777/33650 (epoch 8.584), train_loss = 1.30554666, grad/param norm = 1.5527e-01, time/batch = 0.6288s	
5778/33650 (epoch 8.585), train_loss = 1.32056932, grad/param norm = 1.6361e-01, time/batch = 0.6320s	
5779/33650 (epoch 8.587), train_loss = 1.19292109, grad/param norm = 1.5118e-01, time/batch = 0.6268s	
5780/33650 (epoch 8.588), train_loss = 1.26107904, grad/param norm = 1.6155e-01, time/batch = 0.6280s	
5781/33650 (epoch 8.590), train_loss = 1.25926111, grad/param norm = 1.5203e-01, time/batch = 0.6312s	
5782/33650 (epoch 8.591), train_loss = 1.26951371, grad/param norm = 1.7071e-01, time/batch = 0.6281s	
5783/33650 (epoch 8.593), train_loss = 1.17231642, grad/param norm = 1.3884e-01, time/batch = 0.6264s	
5784/33650 (epoch 8.594), train_loss = 1.07080081, grad/param norm = 1.5383e-01, time/batch = 0.6269s	
5785/33650 (epoch 8.596), train_loss = 1.22587764, grad/param norm = 1.4287e-01, time/batch = 0.6267s	
5786/33650 (epoch 8.597), train_loss = 1.02808726, grad/param norm = 1.2000e-01, time/batch = 0.6258s	
5787/33650 (epoch 8.599), train_loss = 1.18922091, grad/param norm = 1.6005e-01, time/batch = 0.6256s	
5788/33650 (epoch 8.600), train_loss = 1.10852572, grad/param norm = 1.4093e-01, time/batch = 0.6250s	
5789/33650 (epoch 8.602), train_loss = 1.37262670, grad/param norm = 1.5678e-01, time/batch = 0.6260s	
5790/33650 (epoch 8.603), train_loss = 1.20377904, grad/param norm = 1.5175e-01, time/batch = 0.6270s	
5791/33650 (epoch 8.605), train_loss = 1.28098056, grad/param norm = 1.6164e-01, time/batch = 0.6276s	
5792/33650 (epoch 8.606), train_loss = 1.38805692, grad/param norm = 1.7255e-01, time/batch = 0.6300s	
5793/33650 (epoch 8.608), train_loss = 1.23663057, grad/param norm = 1.5422e-01, time/batch = 0.6298s	
5794/33650 (epoch 8.609), train_loss = 1.31624623, grad/param norm = 1.6157e-01, time/batch = 0.6268s	
5795/33650 (epoch 8.611), train_loss = 1.13714934, grad/param norm = 1.4546e-01, time/batch = 0.6409s	
5796/33650 (epoch 8.612), train_loss = 1.26774401, grad/param norm = 1.5618e-01, time/batch = 0.6658s	
5797/33650 (epoch 8.614), train_loss = 1.35895910, grad/param norm = 1.7228e-01, time/batch = 0.6350s	
5798/33650 (epoch 8.615), train_loss = 1.22558083, grad/param norm = 1.4253e-01, time/batch = 0.6283s	
5799/33650 (epoch 8.617), train_loss = 1.11270049, grad/param norm = 1.3128e-01, time/batch = 0.6291s	
5800/33650 (epoch 8.618), train_loss = 1.20617213, grad/param norm = 1.4222e-01, time/batch = 0.6378s	
5801/33650 (epoch 8.620), train_loss = 1.35262127, grad/param norm = 1.7471e-01, time/batch = 0.6304s	
5802/33650 (epoch 8.621), train_loss = 1.12101769, grad/param norm = 1.4247e-01, time/batch = 0.6291s	
5803/33650 (epoch 8.623), train_loss = 1.25425135, grad/param norm = 1.4719e-01, time/batch = 0.6287s	
5804/33650 (epoch 8.624), train_loss = 0.98934873, grad/param norm = 1.4192e-01, time/batch = 0.6270s	
5805/33650 (epoch 8.626), train_loss = 0.99209662, grad/param norm = 1.2836e-01, time/batch = 0.6269s	
5806/33650 (epoch 8.627), train_loss = 1.22550029, grad/param norm = 1.5187e-01, time/batch = 0.6279s	
5807/33650 (epoch 8.629), train_loss = 1.24876602, grad/param norm = 1.4444e-01, time/batch = 0.6327s	
5808/33650 (epoch 8.630), train_loss = 1.35968271, grad/param norm = 1.6143e-01, time/batch = 0.6313s	
5809/33650 (epoch 8.632), train_loss = 1.39233205, grad/param norm = 1.4707e-01, time/batch = 0.6274s	
5810/33650 (epoch 8.633), train_loss = 1.34583051, grad/param norm = 1.5370e-01, time/batch = 0.6260s	
5811/33650 (epoch 8.634), train_loss = 1.09079971, grad/param norm = 1.4528e-01, time/batch = 0.6299s	
5812/33650 (epoch 8.636), train_loss = 1.00823827, grad/param norm = 1.3077e-01, time/batch = 0.6288s	
5813/33650 (epoch 8.637), train_loss = 1.27617682, grad/param norm = 1.5561e-01, time/batch = 0.6292s	
5814/33650 (epoch 8.639), train_loss = 1.18365298, grad/param norm = 1.4859e-01, time/batch = 0.6287s	
5815/33650 (epoch 8.640), train_loss = 1.27194415, grad/param norm = 1.5373e-01, time/batch = 0.6310s	
5816/33650 (epoch 8.642), train_loss = 1.43991412, grad/param norm = 1.7799e-01, time/batch = 0.6609s	
5817/33650 (epoch 8.643), train_loss = 1.26246505, grad/param norm = 1.5423e-01, time/batch = 0.6507s	
5818/33650 (epoch 8.645), train_loss = 1.24457121, grad/param norm = 1.4966e-01, time/batch = 0.6266s	
5819/33650 (epoch 8.646), train_loss = 1.04722201, grad/param norm = 1.2876e-01, time/batch = 0.6270s	
5820/33650 (epoch 8.648), train_loss = 1.27254655, grad/param norm = 1.4815e-01, time/batch = 0.6276s	
5821/33650 (epoch 8.649), train_loss = 1.31065908, grad/param norm = 1.7488e-01, time/batch = 0.6292s	
5822/33650 (epoch 8.651), train_loss = 1.38644672, grad/param norm = 1.5919e-01, time/batch = 0.6307s	
5823/33650 (epoch 8.652), train_loss = 0.92846159, grad/param norm = 1.3809e-01, time/batch = 0.6273s	
5824/33650 (epoch 8.654), train_loss = 1.17736666, grad/param norm = 1.4176e-01, time/batch = 0.6292s	
5825/33650 (epoch 8.655), train_loss = 1.10863321, grad/param norm = 1.4441e-01, time/batch = 0.6271s	
5826/33650 (epoch 8.657), train_loss = 1.27123735, grad/param norm = 1.6357e-01, time/batch = 0.6275s	
5827/33650 (epoch 8.658), train_loss = 1.09008657, grad/param norm = 1.3615e-01, time/batch = 0.6276s	
5828/33650 (epoch 8.660), train_loss = 1.05498141, grad/param norm = 1.3251e-01, time/batch = 0.6274s	
5829/33650 (epoch 8.661), train_loss = 1.17120094, grad/param norm = 1.3072e-01, time/batch = 0.6612s	
5830/33650 (epoch 8.663), train_loss = 1.09481723, grad/param norm = 1.5561e-01, time/batch = 0.6355s	
5831/33650 (epoch 8.664), train_loss = 1.08057774, grad/param norm = 1.3736e-01, time/batch = 0.6295s	
5832/33650 (epoch 8.666), train_loss = 1.18850816, grad/param norm = 1.5023e-01, time/batch = 0.6265s	
5833/33650 (epoch 8.667), train_loss = 1.12535907, grad/param norm = 1.4003e-01, time/batch = 0.6276s	
5834/33650 (epoch 8.669), train_loss = 1.09288919, grad/param norm = 1.4313e-01, time/batch = 0.6268s	
5835/33650 (epoch 8.670), train_loss = 1.04242653, grad/param norm = 1.4880e-01, time/batch = 0.6351s	
5836/33650 (epoch 8.672), train_loss = 1.07816317, grad/param norm = 1.4942e-01, time/batch = 0.6454s	
5837/33650 (epoch 8.673), train_loss = 1.01136175, grad/param norm = 1.5014e-01, time/batch = 0.6667s	
5838/33650 (epoch 8.675), train_loss = 0.96488709, grad/param norm = 1.2309e-01, time/batch = 0.6527s	
5839/33650 (epoch 8.676), train_loss = 1.22815892, grad/param norm = 1.4763e-01, time/batch = 0.6405s	
5840/33650 (epoch 8.678), train_loss = 1.12238458, grad/param norm = 1.4142e-01, time/batch = 0.6397s	
5841/33650 (epoch 8.679), train_loss = 1.18057930, grad/param norm = 1.6024e-01, time/batch = 0.6374s	
5842/33650 (epoch 8.681), train_loss = 1.11222372, grad/param norm = 1.4357e-01, time/batch = 0.6289s	
5843/33650 (epoch 8.682), train_loss = 1.14663440, grad/param norm = 1.5829e-01, time/batch = 0.6317s	
5844/33650 (epoch 8.684), train_loss = 1.11889101, grad/param norm = 1.4207e-01, time/batch = 0.6249s	
5845/33650 (epoch 8.685), train_loss = 1.28356139, grad/param norm = 1.5975e-01, time/batch = 0.6262s	
5846/33650 (epoch 8.686), train_loss = 1.20465951, grad/param norm = 1.4368e-01, time/batch = 0.6254s	
5847/33650 (epoch 8.688), train_loss = 1.40984618, grad/param norm = 1.6428e-01, time/batch = 0.6283s	
5848/33650 (epoch 8.689), train_loss = 1.13539703, grad/param norm = 1.4955e-01, time/batch = 0.6269s	
5849/33650 (epoch 8.691), train_loss = 1.36307482, grad/param norm = 1.6584e-01, time/batch = 0.6275s	
5850/33650 (epoch 8.692), train_loss = 1.33060689, grad/param norm = 1.5271e-01, time/batch = 0.6317s	
5851/33650 (epoch 8.694), train_loss = 1.28510272, grad/param norm = 1.6815e-01, time/batch = 0.6275s	
5852/33650 (epoch 8.695), train_loss = 0.92662699, grad/param norm = 1.4107e-01, time/batch = 0.6286s	
5853/33650 (epoch 8.697), train_loss = 1.25075536, grad/param norm = 1.5217e-01, time/batch = 0.6311s	
5854/33650 (epoch 8.698), train_loss = 1.35910893, grad/param norm = 1.6404e-01, time/batch = 0.6284s	
5855/33650 (epoch 8.700), train_loss = 1.20239541, grad/param norm = 1.4781e-01, time/batch = 0.6278s	
5856/33650 (epoch 8.701), train_loss = 1.27570472, grad/param norm = 1.5910e-01, time/batch = 0.6382s	
5857/33650 (epoch 8.703), train_loss = 1.32091066, grad/param norm = 1.4279e-01, time/batch = 0.6664s	
5858/33650 (epoch 8.704), train_loss = 1.18330241, grad/param norm = 1.4470e-01, time/batch = 0.6441s	
5859/33650 (epoch 8.706), train_loss = 1.20070597, grad/param norm = 1.4148e-01, time/batch = 0.6269s	
5860/33650 (epoch 8.707), train_loss = 1.31968252, grad/param norm = 1.5923e-01, time/batch = 0.6259s	
5861/33650 (epoch 8.709), train_loss = 1.17632974, grad/param norm = 1.4301e-01, time/batch = 0.6281s	
5862/33650 (epoch 8.710), train_loss = 1.40669130, grad/param norm = 1.4840e-01, time/batch = 0.6253s	
5863/33650 (epoch 8.712), train_loss = 1.17531519, grad/param norm = 1.5395e-01, time/batch = 0.6271s	
5864/33650 (epoch 8.713), train_loss = 1.20318388, grad/param norm = 1.7737e-01, time/batch = 0.6303s	
5865/33650 (epoch 8.715), train_loss = 1.37472128, grad/param norm = 1.6534e-01, time/batch = 0.6265s	
5866/33650 (epoch 8.716), train_loss = 1.11214819, grad/param norm = 1.4978e-01, time/batch = 0.6289s	
5867/33650 (epoch 8.718), train_loss = 1.25195336, grad/param norm = 1.5540e-01, time/batch = 0.6268s	
5868/33650 (epoch 8.719), train_loss = 1.38324371, grad/param norm = 1.6195e-01, time/batch = 0.6281s	
5869/33650 (epoch 8.721), train_loss = 1.47775084, grad/param norm = 1.5919e-01, time/batch = 0.6273s	
5870/33650 (epoch 8.722), train_loss = 1.41149399, grad/param norm = 1.8796e-01, time/batch = 0.6265s	
5871/33650 (epoch 8.724), train_loss = 1.32773638, grad/param norm = 1.5438e-01, time/batch = 0.6327s	
5872/33650 (epoch 8.725), train_loss = 1.39108958, grad/param norm = 1.7125e-01, time/batch = 0.6291s	
5873/33650 (epoch 8.727), train_loss = 1.14618855, grad/param norm = 1.6367e-01, time/batch = 0.6252s	
5874/33650 (epoch 8.728), train_loss = 1.17399692, grad/param norm = 1.4951e-01, time/batch = 0.6254s	
5875/33650 (epoch 8.730), train_loss = 1.32055854, grad/param norm = 1.4981e-01, time/batch = 0.6255s	
5876/33650 (epoch 8.731), train_loss = 1.39060785, grad/param norm = 1.6605e-01, time/batch = 0.6279s	
5877/33650 (epoch 8.733), train_loss = 1.23882705, grad/param norm = 1.5684e-01, time/batch = 0.6462s	
5878/33650 (epoch 8.734), train_loss = 1.43055771, grad/param norm = 1.7876e-01, time/batch = 0.6653s	
5879/33650 (epoch 8.736), train_loss = 1.20916238, grad/param norm = 1.5267e-01, time/batch = 0.6275s	
5880/33650 (epoch 8.737), train_loss = 1.27233400, grad/param norm = 1.6405e-01, time/batch = 0.6291s	
5881/33650 (epoch 8.738), train_loss = 1.11745093, grad/param norm = 1.3808e-01, time/batch = 0.6352s	
5882/33650 (epoch 8.740), train_loss = 1.08285655, grad/param norm = 1.3239e-01, time/batch = 0.6274s	
5883/33650 (epoch 8.741), train_loss = 1.19209831, grad/param norm = 1.5167e-01, time/batch = 0.6248s	
5884/33650 (epoch 8.743), train_loss = 1.24543077, grad/param norm = 1.4454e-01, time/batch = 0.6270s	
5885/33650 (epoch 8.744), train_loss = 1.18474402, grad/param norm = 1.4049e-01, time/batch = 0.6317s	
5886/33650 (epoch 8.746), train_loss = 1.20358948, grad/param norm = 1.5243e-01, time/batch = 0.6241s	
5887/33650 (epoch 8.747), train_loss = 1.33266524, grad/param norm = 1.4772e-01, time/batch = 0.6243s	
5888/33650 (epoch 8.749), train_loss = 1.04120214, grad/param norm = 1.3513e-01, time/batch = 0.6257s	
5889/33650 (epoch 8.750), train_loss = 1.33817062, grad/param norm = 1.5644e-01, time/batch = 0.6326s	
5890/33650 (epoch 8.752), train_loss = 1.36686404, grad/param norm = 1.5977e-01, time/batch = 0.6337s	
5891/33650 (epoch 8.753), train_loss = 1.48774781, grad/param norm = 1.6951e-01, time/batch = 0.6313s	
5892/33650 (epoch 8.755), train_loss = 1.15152887, grad/param norm = 1.4756e-01, time/batch = 0.6305s	
5893/33650 (epoch 8.756), train_loss = 1.35353619, grad/param norm = 1.7213e-01, time/batch = 0.6248s	
5894/33650 (epoch 8.758), train_loss = 1.38313062, grad/param norm = 1.6461e-01, time/batch = 0.6276s	
5895/33650 (epoch 8.759), train_loss = 1.48472371, grad/param norm = 1.7481e-01, time/batch = 0.6267s	
5896/33650 (epoch 8.761), train_loss = 1.31101793, grad/param norm = 1.6414e-01, time/batch = 0.6272s	
5897/33650 (epoch 8.762), train_loss = 1.26536417, grad/param norm = 1.5530e-01, time/batch = 0.6265s	
5898/33650 (epoch 8.764), train_loss = 1.36086286, grad/param norm = 1.6553e-01, time/batch = 0.6660s	
5899/33650 (epoch 8.765), train_loss = 1.29608595, grad/param norm = 1.5435e-01, time/batch = 0.6467s	
5900/33650 (epoch 8.767), train_loss = 1.16340834, grad/param norm = 1.5099e-01, time/batch = 0.6289s	
5901/33650 (epoch 8.768), train_loss = 1.09838107, grad/param norm = 1.4117e-01, time/batch = 0.6275s	
5902/33650 (epoch 8.770), train_loss = 1.24080192, grad/param norm = 1.5599e-01, time/batch = 0.6279s	
5903/33650 (epoch 8.771), train_loss = 1.24419590, grad/param norm = 1.4820e-01, time/batch = 0.6274s	
5904/33650 (epoch 8.773), train_loss = 1.41912380, grad/param norm = 1.8118e-01, time/batch = 0.6381s	
5905/33650 (epoch 8.774), train_loss = 1.29526471, grad/param norm = 1.4890e-01, time/batch = 0.6371s	
5906/33650 (epoch 8.776), train_loss = 1.34115390, grad/param norm = 1.6166e-01, time/batch = 0.6277s	
5907/33650 (epoch 8.777), train_loss = 1.09521980, grad/param norm = 1.3917e-01, time/batch = 0.6271s	
5908/33650 (epoch 8.779), train_loss = 1.23354524, grad/param norm = 1.4360e-01, time/batch = 0.6270s	
5909/33650 (epoch 8.780), train_loss = 1.12760786, grad/param norm = 1.4109e-01, time/batch = 0.6264s	
5910/33650 (epoch 8.782), train_loss = 1.18966831, grad/param norm = 1.4646e-01, time/batch = 0.6255s	
5911/33650 (epoch 8.783), train_loss = 1.08476459, grad/param norm = 1.3945e-01, time/batch = 0.6292s	
5912/33650 (epoch 8.785), train_loss = 1.46719805, grad/param norm = 1.5179e-01, time/batch = 0.6281s	
5913/33650 (epoch 8.786), train_loss = 1.24404625, grad/param norm = 1.4247e-01, time/batch = 0.6278s	
5914/33650 (epoch 8.788), train_loss = 1.28077645, grad/param norm = 1.6126e-01, time/batch = 0.6280s	
5915/33650 (epoch 8.789), train_loss = 1.30523501, grad/param norm = 1.3691e-01, time/batch = 0.6302s	
5916/33650 (epoch 8.790), train_loss = 1.35512384, grad/param norm = 1.7443e-01, time/batch = 0.6301s	
5917/33650 (epoch 8.792), train_loss = 1.41053784, grad/param norm = 1.9058e-01, time/batch = 0.6258s	
5918/33650 (epoch 8.793), train_loss = 1.34464963, grad/param norm = 1.7411e-01, time/batch = 0.6471s	
5919/33650 (epoch 8.795), train_loss = 1.39634690, grad/param norm = 1.5637e-01, time/batch = 0.6646s	
5920/33650 (epoch 8.796), train_loss = 1.19589847, grad/param norm = 1.5687e-01, time/batch = 0.6269s	
5921/33650 (epoch 8.798), train_loss = 1.20185747, grad/param norm = 1.3853e-01, time/batch = 0.6302s	
5922/33650 (epoch 8.799), train_loss = 1.23088848, grad/param norm = 1.3558e-01, time/batch = 0.6291s	
5923/33650 (epoch 8.801), train_loss = 1.30597266, grad/param norm = 1.5350e-01, time/batch = 0.6362s	
5924/33650 (epoch 8.802), train_loss = 1.38404149, grad/param norm = 1.4869e-01, time/batch = 0.6461s	
5925/33650 (epoch 8.804), train_loss = 1.23567828, grad/param norm = 1.5233e-01, time/batch = 0.6598s	
5926/33650 (epoch 8.805), train_loss = 1.17605213, grad/param norm = 1.3828e-01, time/batch = 0.6599s	
5927/33650 (epoch 8.807), train_loss = 1.47594712, grad/param norm = 1.6826e-01, time/batch = 0.6518s	
5928/33650 (epoch 8.808), train_loss = 1.47269991, grad/param norm = 1.6558e-01, time/batch = 0.6407s	
5929/33650 (epoch 8.810), train_loss = 1.29838462, grad/param norm = 1.4766e-01, time/batch = 0.6359s	
5930/33650 (epoch 8.811), train_loss = 1.31007235, grad/param norm = 1.5362e-01, time/batch = 0.6289s	
5931/33650 (epoch 8.813), train_loss = 1.25527616, grad/param norm = 1.6680e-01, time/batch = 0.6505s	
5932/33650 (epoch 8.814), train_loss = 1.36786921, grad/param norm = 1.6937e-01, time/batch = 0.6259s	
5933/33650 (epoch 8.816), train_loss = 1.30299726, grad/param norm = 1.6059e-01, time/batch = 0.6621s	
5934/33650 (epoch 8.817), train_loss = 1.38108654, grad/param norm = 1.7789e-01, time/batch = 0.6716s	
5935/33650 (epoch 8.819), train_loss = 1.37230333, grad/param norm = 1.4915e-01, time/batch = 0.6445s	
5936/33650 (epoch 8.820), train_loss = 1.40352464, grad/param norm = 1.5949e-01, time/batch = 0.6318s	
5937/33650 (epoch 8.822), train_loss = 1.43435967, grad/param norm = 1.7742e-01, time/batch = 0.6313s	
5938/33650 (epoch 8.823), train_loss = 1.17010519, grad/param norm = 1.4701e-01, time/batch = 0.6479s	
5939/33650 (epoch 8.825), train_loss = 1.23727182, grad/param norm = 1.4511e-01, time/batch = 0.6351s	
5940/33650 (epoch 8.826), train_loss = 1.32864942, grad/param norm = 1.5060e-01, time/batch = 0.6285s	
5941/33650 (epoch 8.828), train_loss = 1.55526073, grad/param norm = 1.6191e-01, time/batch = 0.6296s	
5942/33650 (epoch 8.829), train_loss = 1.09444429, grad/param norm = 1.3945e-01, time/batch = 0.6271s	
5943/33650 (epoch 8.831), train_loss = 1.36317954, grad/param norm = 1.5866e-01, time/batch = 0.6257s	
5944/33650 (epoch 8.832), train_loss = 1.32127857, grad/param norm = 1.5610e-01, time/batch = 0.6278s	
5945/33650 (epoch 8.834), train_loss = 1.35228044, grad/param norm = 1.5353e-01, time/batch = 0.6299s	
5946/33650 (epoch 8.835), train_loss = 1.55951355, grad/param norm = 1.7540e-01, time/batch = 0.6258s	
5947/33650 (epoch 8.837), train_loss = 1.28867581, grad/param norm = 1.6758e-01, time/batch = 0.6266s	
5948/33650 (epoch 8.838), train_loss = 1.26278865, grad/param norm = 1.7100e-01, time/batch = 0.6267s	
5949/33650 (epoch 8.840), train_loss = 1.35887810, grad/param norm = 1.5925e-01, time/batch = 0.6265s	
5950/33650 (epoch 8.841), train_loss = 1.15911849, grad/param norm = 1.3933e-01, time/batch = 0.6260s	
5951/33650 (epoch 8.842), train_loss = 1.20821525, grad/param norm = 1.4812e-01, time/batch = 0.6295s	
5952/33650 (epoch 8.844), train_loss = 1.45961175, grad/param norm = 1.8294e-01, time/batch = 0.6288s	
5953/33650 (epoch 8.845), train_loss = 1.17316570, grad/param norm = 1.3491e-01, time/batch = 0.6285s	
5954/33650 (epoch 8.847), train_loss = 1.03614078, grad/param norm = 1.6856e-01, time/batch = 0.6417s	
5955/33650 (epoch 8.848), train_loss = 1.12193711, grad/param norm = 1.5365e-01, time/batch = 0.6268s	
5956/33650 (epoch 8.850), train_loss = 1.31446668, grad/param norm = 1.8604e-01, time/batch = 0.6257s	
5957/33650 (epoch 8.851), train_loss = 1.03117581, grad/param norm = 1.3428e-01, time/batch = 0.6250s	
5958/33650 (epoch 8.853), train_loss = 1.27192447, grad/param norm = 1.4662e-01, time/batch = 0.6260s	
5959/33650 (epoch 8.854), train_loss = 1.44112513, grad/param norm = 1.8164e-01, time/batch = 0.6373s	
5960/33650 (epoch 8.856), train_loss = 0.95686507, grad/param norm = 1.3862e-01, time/batch = 0.6378s	
5961/33650 (epoch 8.857), train_loss = 1.21738655, grad/param norm = 1.3262e-01, time/batch = 0.6376s	
5962/33650 (epoch 8.859), train_loss = 1.12714988, grad/param norm = 1.4320e-01, time/batch = 0.6305s	
5963/33650 (epoch 8.860), train_loss = 1.05185677, grad/param norm = 1.4492e-01, time/batch = 0.6283s	
5964/33650 (epoch 8.862), train_loss = 1.10827776, grad/param norm = 1.4790e-01, time/batch = 0.6257s	
5965/33650 (epoch 8.863), train_loss = 1.32789489, grad/param norm = 1.4635e-01, time/batch = 0.6257s	
5966/33650 (epoch 8.865), train_loss = 1.18983676, grad/param norm = 1.5291e-01, time/batch = 0.6257s	
5967/33650 (epoch 8.866), train_loss = 1.12278304, grad/param norm = 1.4745e-01, time/batch = 0.6275s	
5968/33650 (epoch 8.868), train_loss = 1.12558686, grad/param norm = 1.5535e-01, time/batch = 0.6343s	
5969/33650 (epoch 8.869), train_loss = 1.38016545, grad/param norm = 1.6394e-01, time/batch = 0.6339s	
5970/33650 (epoch 8.871), train_loss = 1.09769920, grad/param norm = 1.4161e-01, time/batch = 0.6260s	
5971/33650 (epoch 8.872), train_loss = 1.23895700, grad/param norm = 1.6467e-01, time/batch = 0.6282s	
5972/33650 (epoch 8.874), train_loss = 1.36134777, grad/param norm = 1.6630e-01, time/batch = 0.6256s	
5973/33650 (epoch 8.875), train_loss = 1.17403262, grad/param norm = 1.4410e-01, time/batch = 0.6259s	
5974/33650 (epoch 8.877), train_loss = 1.37003198, grad/param norm = 1.5253e-01, time/batch = 0.6263s	
5975/33650 (epoch 8.878), train_loss = 0.88523885, grad/param norm = 1.3083e-01, time/batch = 0.6315s	
5976/33650 (epoch 8.880), train_loss = 1.26418502, grad/param norm = 1.5656e-01, time/batch = 0.6273s	
5977/33650 (epoch 8.881), train_loss = 1.15512420, grad/param norm = 1.4145e-01, time/batch = 0.6288s	
5978/33650 (epoch 8.883), train_loss = 1.23945630, grad/param norm = 1.5278e-01, time/batch = 0.6269s	
5979/33650 (epoch 8.884), train_loss = 1.34023691, grad/param norm = 1.7174e-01, time/batch = 0.6428s	
5980/33650 (epoch 8.886), train_loss = 1.36727300, grad/param norm = 1.6033e-01, time/batch = 0.6281s	
5981/33650 (epoch 8.887), train_loss = 1.17167713, grad/param norm = 1.4754e-01, time/batch = 0.6294s	
5982/33650 (epoch 8.889), train_loss = 1.33605093, grad/param norm = 1.6674e-01, time/batch = 0.6319s	
5983/33650 (epoch 8.890), train_loss = 1.34357792, grad/param norm = 1.5451e-01, time/batch = 0.6450s	
5984/33650 (epoch 8.892), train_loss = 1.30848201, grad/param norm = 1.6397e-01, time/batch = 0.6442s	
5985/33650 (epoch 8.893), train_loss = 1.32693797, grad/param norm = 1.6508e-01, time/batch = 0.6346s	
5986/33650 (epoch 8.895), train_loss = 1.39199591, grad/param norm = 1.6550e-01, time/batch = 0.6281s	
5987/33650 (epoch 8.896), train_loss = 1.14844575, grad/param norm = 1.5134e-01, time/batch = 0.6271s	
5988/33650 (epoch 8.897), train_loss = 1.14287888, grad/param norm = 1.5196e-01, time/batch = 0.6279s	
5989/33650 (epoch 8.899), train_loss = 1.12258829, grad/param norm = 1.4452e-01, time/batch = 0.6284s	
5990/33650 (epoch 8.900), train_loss = 1.03039649, grad/param norm = 1.4036e-01, time/batch = 0.6271s	
5991/33650 (epoch 8.902), train_loss = 1.26399233, grad/param norm = 1.6841e-01, time/batch = 0.6302s	
5992/33650 (epoch 8.903), train_loss = 1.23806978, grad/param norm = 1.6783e-01, time/batch = 0.6275s	
5993/33650 (epoch 8.905), train_loss = 1.49210875, grad/param norm = 1.8703e-01, time/batch = 0.6267s	
5994/33650 (epoch 8.906), train_loss = 1.21261103, grad/param norm = 1.6075e-01, time/batch = 0.6273s	
5995/33650 (epoch 8.908), train_loss = 1.18080567, grad/param norm = 1.3743e-01, time/batch = 0.6280s	
5996/33650 (epoch 8.909), train_loss = 1.20594668, grad/param norm = 1.4367e-01, time/batch = 0.6284s	
5997/33650 (epoch 8.911), train_loss = 1.06872733, grad/param norm = 1.4024e-01, time/batch = 0.6283s	
5998/33650 (epoch 8.912), train_loss = 1.07919751, grad/param norm = 1.3786e-01, time/batch = 0.6281s	
5999/33650 (epoch 8.914), train_loss = 1.23147818, grad/param norm = 1.4291e-01, time/batch = 0.6266s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch8.92_1.5414.t7	
6000/33650 (epoch 8.915), train_loss = 1.31338509, grad/param norm = 1.6753e-01, time/batch = 0.6254s	
6001/33650 (epoch 8.917), train_loss = 1.40830345, grad/param norm = 1.7639e-01, time/batch = 0.6391s	
6002/33650 (epoch 8.918), train_loss = 0.99117561, grad/param norm = 1.2787e-01, time/batch = 0.6272s	
6003/33650 (epoch 8.920), train_loss = 1.14708659, grad/param norm = 1.2884e-01, time/batch = 0.6280s	
6004/33650 (epoch 8.921), train_loss = 1.12746859, grad/param norm = 1.4334e-01, time/batch = 0.6280s	
6005/33650 (epoch 8.923), train_loss = 1.11993252, grad/param norm = 1.4940e-01, time/batch = 0.6332s	
6006/33650 (epoch 8.924), train_loss = 1.29343176, grad/param norm = 1.6997e-01, time/batch = 0.6320s	
6007/33650 (epoch 8.926), train_loss = 1.24298834, grad/param norm = 1.6336e-01, time/batch = 0.6319s	
6008/33650 (epoch 8.927), train_loss = 1.19435286, grad/param norm = 1.6247e-01, time/batch = 0.6442s	
6009/33650 (epoch 8.929), train_loss = 1.24714039, grad/param norm = 1.5118e-01, time/batch = 0.6372s	
6010/33650 (epoch 8.930), train_loss = 1.19774562, grad/param norm = 1.4084e-01, time/batch = 0.6324s	
6011/33650 (epoch 8.932), train_loss = 1.23014732, grad/param norm = 1.4938e-01, time/batch = 0.6286s	
6012/33650 (epoch 8.933), train_loss = 1.10069597, grad/param norm = 1.4445e-01, time/batch = 0.6262s	
6013/33650 (epoch 8.935), train_loss = 1.14244138, grad/param norm = 1.4854e-01, time/batch = 0.6260s	
6014/33650 (epoch 8.936), train_loss = 1.12386921, grad/param norm = 1.3610e-01, time/batch = 0.6355s	
6015/33650 (epoch 8.938), train_loss = 1.06370511, grad/param norm = 1.3870e-01, time/batch = 0.6326s	
6016/33650 (epoch 8.939), train_loss = 1.29024264, grad/param norm = 1.5063e-01, time/batch = 0.6390s	
6017/33650 (epoch 8.941), train_loss = 1.26416758, grad/param norm = 1.6142e-01, time/batch = 0.6576s	
6018/33650 (epoch 8.942), train_loss = 1.32517164, grad/param norm = 1.6301e-01, time/batch = 0.6654s	
6019/33650 (epoch 8.944), train_loss = 1.25584282, grad/param norm = 1.4180e-01, time/batch = 0.6380s	
6020/33650 (epoch 8.945), train_loss = 1.31659703, grad/param norm = 1.6369e-01, time/batch = 0.6266s	
6021/33650 (epoch 8.947), train_loss = 1.48650106, grad/param norm = 1.7403e-01, time/batch = 0.6287s	
6022/33650 (epoch 8.948), train_loss = 1.35715181, grad/param norm = 1.5164e-01, time/batch = 0.6340s	
6023/33650 (epoch 8.949), train_loss = 1.13998059, grad/param norm = 1.5026e-01, time/batch = 0.6414s	
6024/33650 (epoch 8.951), train_loss = 1.38822951, grad/param norm = 1.5853e-01, time/batch = 0.6278s	
6025/33650 (epoch 8.952), train_loss = 1.37654919, grad/param norm = 1.7320e-01, time/batch = 0.6286s	
6026/33650 (epoch 8.954), train_loss = 1.32169475, grad/param norm = 1.6719e-01, time/batch = 0.6269s	
6027/33650 (epoch 8.955), train_loss = 1.34266388, grad/param norm = 1.6249e-01, time/batch = 0.6288s	
6028/33650 (epoch 8.957), train_loss = 1.31907912, grad/param norm = 1.6167e-01, time/batch = 0.6266s	
6029/33650 (epoch 8.958), train_loss = 0.95451371, grad/param norm = 1.2853e-01, time/batch = 0.6274s	
6030/33650 (epoch 8.960), train_loss = 1.06713161, grad/param norm = 1.3777e-01, time/batch = 0.6296s	
6031/33650 (epoch 8.961), train_loss = 1.14698745, grad/param norm = 1.4494e-01, time/batch = 0.6359s	
6032/33650 (epoch 8.963), train_loss = 1.19283872, grad/param norm = 1.5877e-01, time/batch = 0.6337s	
6033/33650 (epoch 8.964), train_loss = 1.25393673, grad/param norm = 1.6814e-01, time/batch = 0.6338s	
6034/33650 (epoch 8.966), train_loss = 1.24216588, grad/param norm = 1.5081e-01, time/batch = 0.6322s	
6035/33650 (epoch 8.967), train_loss = 1.31427536, grad/param norm = 1.5309e-01, time/batch = 0.6355s	
6036/33650 (epoch 8.969), train_loss = 1.18864336, grad/param norm = 1.3831e-01, time/batch = 0.6314s	
6037/33650 (epoch 8.970), train_loss = 1.29369875, grad/param norm = 1.5532e-01, time/batch = 0.6275s	
6038/33650 (epoch 8.972), train_loss = 1.55029731, grad/param norm = 1.6787e-01, time/batch = 0.6258s	
6039/33650 (epoch 8.973), train_loss = 1.10873225, grad/param norm = 1.3193e-01, time/batch = 0.6255s	
6040/33650 (epoch 8.975), train_loss = 1.10788844, grad/param norm = 1.3950e-01, time/batch = 0.6480s	
6041/33650 (epoch 8.976), train_loss = 1.08666787, grad/param norm = 1.3286e-01, time/batch = 0.6706s	
6042/33650 (epoch 8.978), train_loss = 1.16550187, grad/param norm = 1.5847e-01, time/batch = 0.6310s	
6043/33650 (epoch 8.979), train_loss = 1.25706290, grad/param norm = 1.6118e-01, time/batch = 0.6372s	
6044/33650 (epoch 8.981), train_loss = 1.16212826, grad/param norm = 1.3311e-01, time/batch = 0.6393s	
6045/33650 (epoch 8.982), train_loss = 1.27091104, grad/param norm = 1.5412e-01, time/batch = 0.6518s	
6046/33650 (epoch 8.984), train_loss = 1.10107896, grad/param norm = 1.3728e-01, time/batch = 0.6439s	
6047/33650 (epoch 8.985), train_loss = 1.08980332, grad/param norm = 1.3151e-01, time/batch = 0.6304s	
6048/33650 (epoch 8.987), train_loss = 1.19340102, grad/param norm = 1.4732e-01, time/batch = 0.6243s	
6049/33650 (epoch 8.988), train_loss = 1.29335844, grad/param norm = 1.5155e-01, time/batch = 0.6256s	
6050/33650 (epoch 8.990), train_loss = 1.46878776, grad/param norm = 1.8517e-01, time/batch = 0.6280s	
6051/33650 (epoch 8.991), train_loss = 1.30781402, grad/param norm = 1.4784e-01, time/batch = 0.6285s	
6052/33650 (epoch 8.993), train_loss = 1.28627276, grad/param norm = 1.5957e-01, time/batch = 0.6248s	
6053/33650 (epoch 8.994), train_loss = 1.18337288, grad/param norm = 1.3785e-01, time/batch = 0.6262s	
6054/33650 (epoch 8.996), train_loss = 1.14315188, grad/param norm = 1.4380e-01, time/batch = 0.6269s	
6055/33650 (epoch 8.997), train_loss = 1.29638316, grad/param norm = 1.6794e-01, time/batch = 0.6302s	
6056/33650 (epoch 8.999), train_loss = 1.08019897, grad/param norm = 1.4092e-01, time/batch = 0.6594s	
6057/33650 (epoch 9.000), train_loss = 1.31672940, grad/param norm = 1.6121e-01, time/batch = 0.6587s	
6058/33650 (epoch 9.001), train_loss = 1.41924706, grad/param norm = 1.7254e-01, time/batch = 0.6352s	
6059/33650 (epoch 9.003), train_loss = 1.45006445, grad/param norm = 1.7534e-01, time/batch = 0.6365s	
6060/33650 (epoch 9.004), train_loss = 1.32281796, grad/param norm = 1.6334e-01, time/batch = 0.6358s	
6061/33650 (epoch 9.006), train_loss = 1.17834057, grad/param norm = 1.4846e-01, time/batch = 0.6343s	
6062/33650 (epoch 9.007), train_loss = 1.24829644, grad/param norm = 1.5412e-01, time/batch = 0.6336s	
6063/33650 (epoch 9.009), train_loss = 1.18994504, grad/param norm = 1.3426e-01, time/batch = 0.6348s	
6064/33650 (epoch 9.010), train_loss = 1.31128826, grad/param norm = 1.6229e-01, time/batch = 0.6313s	
6065/33650 (epoch 9.012), train_loss = 1.16092375, grad/param norm = 1.6340e-01, time/batch = 0.6376s	
6066/33650 (epoch 9.013), train_loss = 1.29571627, grad/param norm = 1.7208e-01, time/batch = 0.6327s	
6067/33650 (epoch 9.015), train_loss = 1.13065262, grad/param norm = 1.4633e-01, time/batch = 0.6301s	
6068/33650 (epoch 9.016), train_loss = 1.14124420, grad/param norm = 1.5231e-01, time/batch = 0.6329s	
6069/33650 (epoch 9.018), train_loss = 1.23274480, grad/param norm = 1.5357e-01, time/batch = 0.6298s	
6070/33650 (epoch 9.019), train_loss = 1.13165022, grad/param norm = 1.3938e-01, time/batch = 0.6242s	
6071/33650 (epoch 9.021), train_loss = 1.34099814, grad/param norm = 1.5445e-01, time/batch = 0.6274s	
6072/33650 (epoch 9.022), train_loss = 1.17750649, grad/param norm = 1.4468e-01, time/batch = 0.6253s	
6073/33650 (epoch 9.024), train_loss = 1.08665880, grad/param norm = 1.3682e-01, time/batch = 0.6287s	
6074/33650 (epoch 9.025), train_loss = 1.16256291, grad/param norm = 1.4808e-01, time/batch = 0.6308s	
6075/33650 (epoch 9.027), train_loss = 1.33125903, grad/param norm = 1.6196e-01, time/batch = 0.6245s	
6076/33650 (epoch 9.028), train_loss = 1.30323603, grad/param norm = 1.5434e-01, time/batch = 0.6382s	
6077/33650 (epoch 9.030), train_loss = 1.25675944, grad/param norm = 1.4895e-01, time/batch = 0.6610s	
6078/33650 (epoch 9.031), train_loss = 1.04756903, grad/param norm = 1.3140e-01, time/batch = 0.6325s	
6079/33650 (epoch 9.033), train_loss = 1.16768296, grad/param norm = 1.3464e-01, time/batch = 0.6277s	
6080/33650 (epoch 9.034), train_loss = 1.26335434, grad/param norm = 1.5199e-01, time/batch = 0.6333s	
6081/33650 (epoch 9.036), train_loss = 1.38801669, grad/param norm = 1.6727e-01, time/batch = 0.6355s	
6082/33650 (epoch 9.037), train_loss = 1.12413109, grad/param norm = 1.5951e-01, time/batch = 0.6258s	
6083/33650 (epoch 9.039), train_loss = 1.37822250, grad/param norm = 1.6210e-01, time/batch = 0.6262s	
6084/33650 (epoch 9.040), train_loss = 1.42472966, grad/param norm = 1.7946e-01, time/batch = 0.6273s	
6085/33650 (epoch 9.042), train_loss = 1.44402853, grad/param norm = 1.6688e-01, time/batch = 0.6266s	
6086/33650 (epoch 9.043), train_loss = 1.14782420, grad/param norm = 1.4873e-01, time/batch = 0.6275s	
6087/33650 (epoch 9.045), train_loss = 1.13769734, grad/param norm = 1.5125e-01, time/batch = 0.6341s	
6088/33650 (epoch 9.046), train_loss = 1.31438160, grad/param norm = 1.5083e-01, time/batch = 0.6355s	
6089/33650 (epoch 9.048), train_loss = 1.31505361, grad/param norm = 1.4937e-01, time/batch = 0.6336s	
6090/33650 (epoch 9.049), train_loss = 1.27890867, grad/param norm = 1.5411e-01, time/batch = 0.6276s	
6091/33650 (epoch 9.051), train_loss = 1.35945169, grad/param norm = 1.5727e-01, time/batch = 0.6415s	
6092/33650 (epoch 9.052), train_loss = 1.42645942, grad/param norm = 1.6379e-01, time/batch = 0.6363s	
6093/33650 (epoch 9.053), train_loss = 1.25318044, grad/param norm = 1.4532e-01, time/batch = 0.6489s	
6094/33650 (epoch 9.055), train_loss = 1.08305165, grad/param norm = 1.5089e-01, time/batch = 0.6329s	
6095/33650 (epoch 9.056), train_loss = 1.07919999, grad/param norm = 1.3651e-01, time/batch = 0.6379s	
6096/33650 (epoch 9.058), train_loss = 1.37170877, grad/param norm = 1.7955e-01, time/batch = 0.6306s	
6097/33650 (epoch 9.059), train_loss = 1.30542046, grad/param norm = 1.6307e-01, time/batch = 0.6326s	
6098/33650 (epoch 9.061), train_loss = 1.32994779, grad/param norm = 1.5068e-01, time/batch = 0.6363s	
6099/33650 (epoch 9.062), train_loss = 1.27695606, grad/param norm = 1.3908e-01, time/batch = 0.6285s	
6100/33650 (epoch 9.064), train_loss = 1.17531324, grad/param norm = 1.4132e-01, time/batch = 0.6434s	
6101/33650 (epoch 9.065), train_loss = 1.18230937, grad/param norm = 1.4838e-01, time/batch = 0.6322s	
6102/33650 (epoch 9.067), train_loss = 1.11081060, grad/param norm = 1.4460e-01, time/batch = 0.6339s	
6103/33650 (epoch 9.068), train_loss = 1.26313259, grad/param norm = 1.5021e-01, time/batch = 0.6393s	
6104/33650 (epoch 9.070), train_loss = 1.24501499, grad/param norm = 1.5326e-01, time/batch = 0.6351s	
6105/33650 (epoch 9.071), train_loss = 1.25294546, grad/param norm = 1.4579e-01, time/batch = 0.6319s	
6106/33650 (epoch 9.073), train_loss = 1.31052264, grad/param norm = 1.6581e-01, time/batch = 0.6336s	
6107/33650 (epoch 9.074), train_loss = 1.35500113, grad/param norm = 1.6206e-01, time/batch = 0.6328s	
6108/33650 (epoch 9.076), train_loss = 1.39358828, grad/param norm = 1.7679e-01, time/batch = 0.6421s	
6109/33650 (epoch 9.077), train_loss = 1.20154628, grad/param norm = 1.4245e-01, time/batch = 0.6365s	
6110/33650 (epoch 9.079), train_loss = 1.19799206, grad/param norm = 1.5817e-01, time/batch = 0.6488s	
6111/33650 (epoch 9.080), train_loss = 1.31080916, grad/param norm = 1.5950e-01, time/batch = 0.6325s	
6112/33650 (epoch 9.082), train_loss = 1.36568873, grad/param norm = 1.6742e-01, time/batch = 0.6651s	
6113/33650 (epoch 9.083), train_loss = 1.29330374, grad/param norm = 1.5085e-01, time/batch = 0.6672s	
6114/33650 (epoch 9.085), train_loss = 1.32628694, grad/param norm = 1.4434e-01, time/batch = 0.6528s	
6115/33650 (epoch 9.086), train_loss = 1.33982977, grad/param norm = 1.6458e-01, time/batch = 0.6310s	
6116/33650 (epoch 9.088), train_loss = 1.29841822, grad/param norm = 1.5058e-01, time/batch = 0.6328s	
6117/33650 (epoch 9.089), train_loss = 1.28743067, grad/param norm = 1.6977e-01, time/batch = 0.6274s	
6118/33650 (epoch 9.091), train_loss = 1.16569114, grad/param norm = 1.4048e-01, time/batch = 0.6281s	
6119/33650 (epoch 9.092), train_loss = 1.18504854, grad/param norm = 1.4670e-01, time/batch = 0.6289s	
6120/33650 (epoch 9.094), train_loss = 1.30854794, grad/param norm = 1.4560e-01, time/batch = 0.6267s	
6121/33650 (epoch 9.095), train_loss = 1.30169302, grad/param norm = 1.5991e-01, time/batch = 0.6275s	
6122/33650 (epoch 9.097), train_loss = 1.21807826, grad/param norm = 1.5731e-01, time/batch = 0.6283s	
6123/33650 (epoch 9.098), train_loss = 0.99533733, grad/param norm = 1.3012e-01, time/batch = 0.6323s	
6124/33650 (epoch 9.100), train_loss = 1.14174959, grad/param norm = 1.4116e-01, time/batch = 0.6324s	
6125/33650 (epoch 9.101), train_loss = 1.19018727, grad/param norm = 1.6053e-01, time/batch = 0.6292s	
6126/33650 (epoch 9.103), train_loss = 1.12904867, grad/param norm = 1.3284e-01, time/batch = 0.6263s	
6127/33650 (epoch 9.104), train_loss = 1.28936523, grad/param norm = 1.4955e-01, time/batch = 0.6332s	
6128/33650 (epoch 9.105), train_loss = 1.24013788, grad/param norm = 1.6547e-01, time/batch = 0.6575s	
6129/33650 (epoch 9.107), train_loss = 1.14611024, grad/param norm = 1.5685e-01, time/batch = 0.6634s	
6130/33650 (epoch 9.108), train_loss = 1.30564546, grad/param norm = 1.6181e-01, time/batch = 0.6401s	
6131/33650 (epoch 9.110), train_loss = 1.40806481, grad/param norm = 1.5540e-01, time/batch = 0.6313s	
6132/33650 (epoch 9.111), train_loss = 1.17733725, grad/param norm = 1.5683e-01, time/batch = 0.6284s	
6133/33650 (epoch 9.113), train_loss = 1.18384810, grad/param norm = 1.5195e-01, time/batch = 0.6256s	
6134/33650 (epoch 9.114), train_loss = 1.33509107, grad/param norm = 1.6765e-01, time/batch = 0.6251s	
6135/33650 (epoch 9.116), train_loss = 1.10351276, grad/param norm = 1.4463e-01, time/batch = 0.6250s	
6136/33650 (epoch 9.117), train_loss = 1.23319158, grad/param norm = 1.4179e-01, time/batch = 0.6263s	
6137/33650 (epoch 9.119), train_loss = 1.07545862, grad/param norm = 1.3551e-01, time/batch = 0.6295s	
6138/33650 (epoch 9.120), train_loss = 1.13789186, grad/param norm = 1.4912e-01, time/batch = 0.6290s	
6139/33650 (epoch 9.122), train_loss = 1.04809406, grad/param norm = 1.4499e-01, time/batch = 0.6275s	
6140/33650 (epoch 9.123), train_loss = 1.16596536, grad/param norm = 1.4062e-01, time/batch = 0.6265s	
6141/33650 (epoch 9.125), train_loss = 1.35610159, grad/param norm = 1.5679e-01, time/batch = 0.6290s	
6142/33650 (epoch 9.126), train_loss = 1.44747266, grad/param norm = 1.6984e-01, time/batch = 0.6302s	
6143/33650 (epoch 9.128), train_loss = 1.36864770, grad/param norm = 1.6731e-01, time/batch = 0.6255s	
6144/33650 (epoch 9.129), train_loss = 1.35844555, grad/param norm = 1.5642e-01, time/batch = 0.6665s	
6145/33650 (epoch 9.131), train_loss = 1.27974890, grad/param norm = 1.5508e-01, time/batch = 0.6479s	
6146/33650 (epoch 9.132), train_loss = 1.25165335, grad/param norm = 1.4979e-01, time/batch = 0.6287s	
6147/33650 (epoch 9.134), train_loss = 1.38359393, grad/param norm = 1.5496e-01, time/batch = 0.6283s	
6148/33650 (epoch 9.135), train_loss = 1.11074663, grad/param norm = 1.4361e-01, time/batch = 0.6374s	
6149/33650 (epoch 9.137), train_loss = 1.22423689, grad/param norm = 1.4745e-01, time/batch = 0.6656s	
6150/33650 (epoch 9.138), train_loss = 1.30569416, grad/param norm = 1.4436e-01, time/batch = 0.6354s	
6151/33650 (epoch 9.140), train_loss = 1.31434581, grad/param norm = 1.6525e-01, time/batch = 0.6297s	
6152/33650 (epoch 9.141), train_loss = 1.38829962, grad/param norm = 1.5849e-01, time/batch = 0.6294s	
6153/33650 (epoch 9.143), train_loss = 1.53848593, grad/param norm = 1.8974e-01, time/batch = 0.6259s	
6154/33650 (epoch 9.144), train_loss = 1.36948344, grad/param norm = 1.6091e-01, time/batch = 0.6314s	
6155/33650 (epoch 9.146), train_loss = 1.22369365, grad/param norm = 1.6304e-01, time/batch = 0.6294s	
6156/33650 (epoch 9.147), train_loss = 1.18827138, grad/param norm = 1.4650e-01, time/batch = 0.6273s	
6157/33650 (epoch 9.149), train_loss = 1.12012199, grad/param norm = 1.5638e-01, time/batch = 0.6274s	
6158/33650 (epoch 9.150), train_loss = 1.11163842, grad/param norm = 1.3238e-01, time/batch = 0.6281s	
6159/33650 (epoch 9.152), train_loss = 1.16543376, grad/param norm = 1.4438e-01, time/batch = 0.6306s	
6160/33650 (epoch 9.153), train_loss = 1.20569342, grad/param norm = 1.4754e-01, time/batch = 0.6245s	
6161/33650 (epoch 9.155), train_loss = 1.14303986, grad/param norm = 1.3602e-01, time/batch = 0.6293s	
6162/33650 (epoch 9.156), train_loss = 1.11776580, grad/param norm = 1.3041e-01, time/batch = 0.6282s	
6163/33650 (epoch 9.158), train_loss = 1.24557464, grad/param norm = 1.5435e-01, time/batch = 0.6306s	
6164/33650 (epoch 9.159), train_loss = 1.06738248, grad/param norm = 1.3520e-01, time/batch = 0.6286s	
6165/33650 (epoch 9.160), train_loss = 1.11957532, grad/param norm = 1.2752e-01, time/batch = 0.6297s	
6166/33650 (epoch 9.162), train_loss = 1.23276862, grad/param norm = 1.6842e-01, time/batch = 0.6309s	
6167/33650 (epoch 9.163), train_loss = 1.34764797, grad/param norm = 1.6342e-01, time/batch = 0.6338s	
6168/33650 (epoch 9.165), train_loss = 1.10049983, grad/param norm = 1.3738e-01, time/batch = 0.6272s	
6169/33650 (epoch 9.166), train_loss = 1.11268471, grad/param norm = 1.4380e-01, time/batch = 0.6588s	
6170/33650 (epoch 9.168), train_loss = 1.33303230, grad/param norm = 1.5198e-01, time/batch = 0.6579s	
6171/33650 (epoch 9.169), train_loss = 1.21290467, grad/param norm = 1.4496e-01, time/batch = 0.6300s	
6172/33650 (epoch 9.171), train_loss = 1.24108833, grad/param norm = 1.6202e-01, time/batch = 0.6301s	
6173/33650 (epoch 9.172), train_loss = 1.19360440, grad/param norm = 1.5295e-01, time/batch = 0.6305s	
6174/33650 (epoch 9.174), train_loss = 1.12763872, grad/param norm = 1.5195e-01, time/batch = 0.6296s	
6175/33650 (epoch 9.175), train_loss = 1.15351529, grad/param norm = 1.5219e-01, time/batch = 0.6381s	
6176/33650 (epoch 9.177), train_loss = 1.25366258, grad/param norm = 1.5131e-01, time/batch = 0.6435s	
6177/33650 (epoch 9.178), train_loss = 1.14388274, grad/param norm = 1.4622e-01, time/batch = 0.6278s	
6178/33650 (epoch 9.180), train_loss = 1.10670958, grad/param norm = 1.4533e-01, time/batch = 0.6276s	
6179/33650 (epoch 9.181), train_loss = 0.95758916, grad/param norm = 1.4137e-01, time/batch = 0.6308s	
6180/33650 (epoch 9.183), train_loss = 1.15254538, grad/param norm = 1.5111e-01, time/batch = 0.6267s	
6181/33650 (epoch 9.184), train_loss = 1.20110152, grad/param norm = 1.4837e-01, time/batch = 0.6350s	
6182/33650 (epoch 9.186), train_loss = 1.19530772, grad/param norm = 1.5917e-01, time/batch = 0.6303s	
6183/33650 (epoch 9.187), train_loss = 1.39129261, grad/param norm = 1.6250e-01, time/batch = 0.6300s	
6184/33650 (epoch 9.189), train_loss = 1.43194861, grad/param norm = 1.7514e-01, time/batch = 0.6313s	
6185/33650 (epoch 9.190), train_loss = 1.27225285, grad/param norm = 1.7907e-01, time/batch = 0.6409s	
6186/33650 (epoch 9.192), train_loss = 1.42006787, grad/param norm = 1.6599e-01, time/batch = 0.6473s	
6187/33650 (epoch 9.193), train_loss = 1.35640882, grad/param norm = 1.5434e-01, time/batch = 0.6361s	
6188/33650 (epoch 9.195), train_loss = 1.08418008, grad/param norm = 1.3664e-01, time/batch = 0.6324s	
6189/33650 (epoch 9.196), train_loss = 1.01521903, grad/param norm = 1.4556e-01, time/batch = 0.6469s	
6190/33650 (epoch 9.198), train_loss = 1.18564059, grad/param norm = 1.5735e-01, time/batch = 0.6663s	
6191/33650 (epoch 9.199), train_loss = 1.30895643, grad/param norm = 1.6529e-01, time/batch = 0.6327s	
6192/33650 (epoch 9.201), train_loss = 1.22700501, grad/param norm = 1.5393e-01, time/batch = 0.6302s	
6193/33650 (epoch 9.202), train_loss = 1.19201838, grad/param norm = 1.4812e-01, time/batch = 0.6341s	
6194/33650 (epoch 9.204), train_loss = 1.27218123, grad/param norm = 1.5240e-01, time/batch = 0.6316s	
6195/33650 (epoch 9.205), train_loss = 1.16723515, grad/param norm = 1.5072e-01, time/batch = 0.6278s	
6196/33650 (epoch 9.207), train_loss = 1.20458779, grad/param norm = 1.5425e-01, time/batch = 0.6289s	
6197/33650 (epoch 9.208), train_loss = 1.18659234, grad/param norm = 1.4437e-01, time/batch = 0.6273s	
6198/33650 (epoch 9.210), train_loss = 0.95643398, grad/param norm = 1.2666e-01, time/batch = 0.6314s	
6199/33650 (epoch 9.211), train_loss = 1.11029066, grad/param norm = 1.4522e-01, time/batch = 0.6317s	
6200/33650 (epoch 9.212), train_loss = 1.34181841, grad/param norm = 1.6931e-01, time/batch = 0.6310s	
6201/33650 (epoch 9.214), train_loss = 1.38123136, grad/param norm = 1.5958e-01, time/batch = 0.6304s	
6202/33650 (epoch 9.215), train_loss = 0.98211014, grad/param norm = 1.3928e-01, time/batch = 0.6349s	
6203/33650 (epoch 9.217), train_loss = 1.22895593, grad/param norm = 1.6123e-01, time/batch = 0.6358s	
6204/33650 (epoch 9.218), train_loss = 1.30109740, grad/param norm = 1.5050e-01, time/batch = 0.6473s	
6205/33650 (epoch 9.220), train_loss = 1.12033438, grad/param norm = 1.5170e-01, time/batch = 0.6289s	
6206/33650 (epoch 9.221), train_loss = 1.40267685, grad/param norm = 1.6716e-01, time/batch = 0.6510s	
6207/33650 (epoch 9.223), train_loss = 0.94883319, grad/param norm = 1.3561e-01, time/batch = 0.6359s	
6208/33650 (epoch 9.224), train_loss = 1.22104045, grad/param norm = 1.7470e-01, time/batch = 0.6327s	
6209/33650 (epoch 9.226), train_loss = 1.55505031, grad/param norm = 1.7831e-01, time/batch = 0.6356s	
6210/33650 (epoch 9.227), train_loss = 1.37795761, grad/param norm = 1.5604e-01, time/batch = 0.6659s	
6211/33650 (epoch 9.229), train_loss = 1.34622064, grad/param norm = 1.5603e-01, time/batch = 0.6439s	
6212/33650 (epoch 9.230), train_loss = 1.47034013, grad/param norm = 1.7221e-01, time/batch = 0.6324s	
6213/33650 (epoch 9.232), train_loss = 1.28020207, grad/param norm = 1.6727e-01, time/batch = 0.6328s	
6214/33650 (epoch 9.233), train_loss = 1.30166147, grad/param norm = 1.7489e-01, time/batch = 0.6320s	
6215/33650 (epoch 9.235), train_loss = 1.17402328, grad/param norm = 1.4647e-01, time/batch = 0.6314s	
6216/33650 (epoch 9.236), train_loss = 1.05907987, grad/param norm = 1.4877e-01, time/batch = 0.6308s	
6217/33650 (epoch 9.238), train_loss = 1.18739248, grad/param norm = 1.4873e-01, time/batch = 0.6259s	
6218/33650 (epoch 9.239), train_loss = 1.11503012, grad/param norm = 1.4693e-01, time/batch = 0.6330s	
6219/33650 (epoch 9.241), train_loss = 1.15640649, grad/param norm = 1.3777e-01, time/batch = 0.6386s	
6220/33650 (epoch 9.242), train_loss = 1.02034444, grad/param norm = 1.3531e-01, time/batch = 0.6338s	
6221/33650 (epoch 9.244), train_loss = 1.21666302, grad/param norm = 1.4513e-01, time/batch = 0.6325s	
6222/33650 (epoch 9.245), train_loss = 1.05343247, grad/param norm = 1.3910e-01, time/batch = 0.6311s	
6223/33650 (epoch 9.247), train_loss = 1.19319277, grad/param norm = 1.4854e-01, time/batch = 0.6309s	
6224/33650 (epoch 9.248), train_loss = 1.11822847, grad/param norm = 1.5054e-01, time/batch = 0.6305s	
6225/33650 (epoch 9.250), train_loss = 1.19343940, grad/param norm = 1.3898e-01, time/batch = 0.6431s	
6226/33650 (epoch 9.251), train_loss = 1.37389418, grad/param norm = 1.5193e-01, time/batch = 0.6694s	
6227/33650 (epoch 9.253), train_loss = 1.08909922, grad/param norm = 1.3930e-01, time/batch = 0.6290s	
6228/33650 (epoch 9.254), train_loss = 1.09984072, grad/param norm = 1.4235e-01, time/batch = 0.6275s	
6229/33650 (epoch 9.256), train_loss = 1.30394831, grad/param norm = 1.3931e-01, time/batch = 0.6289s	
6230/33650 (epoch 9.257), train_loss = 1.40834194, grad/param norm = 1.5391e-01, time/batch = 0.6272s	
6231/33650 (epoch 9.259), train_loss = 1.02992269, grad/param norm = 1.3982e-01, time/batch = 0.6340s	
6232/33650 (epoch 9.260), train_loss = 1.39173192, grad/param norm = 1.6183e-01, time/batch = 0.6285s	
6233/33650 (epoch 9.262), train_loss = 1.29529110, grad/param norm = 1.5790e-01, time/batch = 0.6308s	
6234/33650 (epoch 9.263), train_loss = 1.24281887, grad/param norm = 1.8378e-01, time/batch = 0.6265s	
6235/33650 (epoch 9.264), train_loss = 1.22766289, grad/param norm = 1.5791e-01, time/batch = 0.6282s	
6236/33650 (epoch 9.266), train_loss = 1.21790273, grad/param norm = 1.5175e-01, time/batch = 0.6277s	
6237/33650 (epoch 9.267), train_loss = 1.16731480, grad/param norm = 1.6315e-01, time/batch = 0.6279s	
6238/33650 (epoch 9.269), train_loss = 1.27351593, grad/param norm = 1.4742e-01, time/batch = 0.6293s	
6239/33650 (epoch 9.270), train_loss = 1.14898732, grad/param norm = 1.4736e-01, time/batch = 0.6297s	
6240/33650 (epoch 9.272), train_loss = 1.21403314, grad/param norm = 1.5091e-01, time/batch = 0.6282s	
6241/33650 (epoch 9.273), train_loss = 1.40344801, grad/param norm = 1.8862e-01, time/batch = 0.6306s	
6242/33650 (epoch 9.275), train_loss = 1.32314253, grad/param norm = 1.5581e-01, time/batch = 0.6280s	
6243/33650 (epoch 9.276), train_loss = 1.39912998, grad/param norm = 1.6528e-01, time/batch = 0.6299s	
6244/33650 (epoch 9.278), train_loss = 1.51182925, grad/param norm = 1.8392e-01, time/batch = 0.6323s	
6245/33650 (epoch 9.279), train_loss = 1.16195523, grad/param norm = 1.5288e-01, time/batch = 0.6301s	
6246/33650 (epoch 9.281), train_loss = 1.26662586, grad/param norm = 1.6203e-01, time/batch = 0.6496s	
6247/33650 (epoch 9.282), train_loss = 1.33481599, grad/param norm = 1.4235e-01, time/batch = 0.6491s	
6248/33650 (epoch 9.284), train_loss = 1.34428201, grad/param norm = 1.7159e-01, time/batch = 0.6323s	
6249/33650 (epoch 9.285), train_loss = 1.34651100, grad/param norm = 1.6738e-01, time/batch = 0.6370s	
6250/33650 (epoch 9.287), train_loss = 1.22327013, grad/param norm = 1.4715e-01, time/batch = 0.6305s	
6251/33650 (epoch 9.288), train_loss = 1.27907505, grad/param norm = 1.6812e-01, time/batch = 0.6331s	
6252/33650 (epoch 9.290), train_loss = 1.23830281, grad/param norm = 1.4227e-01, time/batch = 0.6289s	
6253/33650 (epoch 9.291), train_loss = 1.12282507, grad/param norm = 1.4135e-01, time/batch = 0.6295s	
6254/33650 (epoch 9.293), train_loss = 1.23817586, grad/param norm = 1.6578e-01, time/batch = 0.6288s	
6255/33650 (epoch 9.294), train_loss = 1.10006949, grad/param norm = 1.4139e-01, time/batch = 0.6273s	
6256/33650 (epoch 9.296), train_loss = 1.09567923, grad/param norm = 1.5995e-01, time/batch = 0.6270s	
6257/33650 (epoch 9.297), train_loss = 1.22924697, grad/param norm = 1.4863e-01, time/batch = 0.6274s	
6258/33650 (epoch 9.299), train_loss = 1.09806902, grad/param norm = 1.3429e-01, time/batch = 0.6262s	
6259/33650 (epoch 9.300), train_loss = 1.14911058, grad/param norm = 1.5028e-01, time/batch = 0.6274s	
6260/33650 (epoch 9.302), train_loss = 1.21530319, grad/param norm = 1.3756e-01, time/batch = 0.6281s	
6261/33650 (epoch 9.303), train_loss = 1.22210992, grad/param norm = 1.4336e-01, time/batch = 0.6288s	
6262/33650 (epoch 9.305), train_loss = 1.27095267, grad/param norm = 1.5248e-01, time/batch = 0.6273s	
6263/33650 (epoch 9.306), train_loss = 1.15516661, grad/param norm = 1.3614e-01, time/batch = 0.6329s	
6264/33650 (epoch 9.308), train_loss = 1.14497338, grad/param norm = 1.5050e-01, time/batch = 0.6396s	
6265/33650 (epoch 9.309), train_loss = 1.41336408, grad/param norm = 1.7015e-01, time/batch = 0.6313s	
6266/33650 (epoch 9.311), train_loss = 1.28308073, grad/param norm = 1.5009e-01, time/batch = 0.6511s	
6267/33650 (epoch 9.312), train_loss = 1.19633070, grad/param norm = 1.5155e-01, time/batch = 0.6658s	
6268/33650 (epoch 9.314), train_loss = 1.02546336, grad/param norm = 1.2894e-01, time/batch = 0.6288s	
6269/33650 (epoch 9.315), train_loss = 1.24628092, grad/param norm = 1.6280e-01, time/batch = 0.6291s	
6270/33650 (epoch 9.316), train_loss = 1.20521106, grad/param norm = 1.5462e-01, time/batch = 0.6320s	
6271/33650 (epoch 9.318), train_loss = 1.08245412, grad/param norm = 1.2794e-01, time/batch = 0.6401s	
6272/33650 (epoch 9.319), train_loss = 1.11985134, grad/param norm = 1.3593e-01, time/batch = 0.6309s	
6273/33650 (epoch 9.321), train_loss = 1.16192595, grad/param norm = 1.4445e-01, time/batch = 0.6300s	
6274/33650 (epoch 9.322), train_loss = 1.27372222, grad/param norm = 1.6329e-01, time/batch = 0.6286s	
6275/33650 (epoch 9.324), train_loss = 1.31259315, grad/param norm = 1.7426e-01, time/batch = 0.6308s	
6276/33650 (epoch 9.325), train_loss = 1.28967627, grad/param norm = 1.5330e-01, time/batch = 0.6299s	
6277/33650 (epoch 9.327), train_loss = 1.08146030, grad/param norm = 1.4067e-01, time/batch = 0.6274s	
6278/33650 (epoch 9.328), train_loss = 1.30976658, grad/param norm = 1.6981e-01, time/batch = 0.6299s	
6279/33650 (epoch 9.330), train_loss = 1.10571388, grad/param norm = 1.3023e-01, time/batch = 0.6294s	
6280/33650 (epoch 9.331), train_loss = 1.02917013, grad/param norm = 1.3261e-01, time/batch = 0.6293s	
6281/33650 (epoch 9.333), train_loss = 1.19382835, grad/param norm = 1.4010e-01, time/batch = 0.6409s	
6282/33650 (epoch 9.334), train_loss = 1.20457297, grad/param norm = 1.4369e-01, time/batch = 0.6284s	
6283/33650 (epoch 9.336), train_loss = 1.31121138, grad/param norm = 1.4653e-01, time/batch = 0.6275s	
6284/33650 (epoch 9.337), train_loss = 0.99834537, grad/param norm = 1.3115e-01, time/batch = 0.6252s	
6285/33650 (epoch 9.339), train_loss = 1.18085077, grad/param norm = 1.4095e-01, time/batch = 0.6247s	
6286/33650 (epoch 9.340), train_loss = 1.46992138, grad/param norm = 1.7875e-01, time/batch = 0.6283s	
6287/33650 (epoch 9.342), train_loss = 0.99279259, grad/param norm = 1.2916e-01, time/batch = 0.6659s	
6288/33650 (epoch 9.343), train_loss = 1.30457494, grad/param norm = 1.7521e-01, time/batch = 0.6429s	
6289/33650 (epoch 9.345), train_loss = 1.17708265, grad/param norm = 1.5077e-01, time/batch = 0.6306s	
6290/33650 (epoch 9.346), train_loss = 0.89617744, grad/param norm = 1.3515e-01, time/batch = 0.6300s	
6291/33650 (epoch 9.348), train_loss = 1.06824368, grad/param norm = 1.4245e-01, time/batch = 0.6337s	
6292/33650 (epoch 9.349), train_loss = 1.00307547, grad/param norm = 1.4591e-01, time/batch = 0.6285s	
6293/33650 (epoch 9.351), train_loss = 1.30598439, grad/param norm = 1.6796e-01, time/batch = 0.6286s	
6294/33650 (epoch 9.352), train_loss = 1.15754802, grad/param norm = 1.3717e-01, time/batch = 0.6288s	
6295/33650 (epoch 9.354), train_loss = 1.47420014, grad/param norm = 1.7269e-01, time/batch = 0.6285s	
6296/33650 (epoch 9.355), train_loss = 1.30119790, grad/param norm = 1.4672e-01, time/batch = 0.6276s	
6297/33650 (epoch 9.357), train_loss = 1.01267199, grad/param norm = 1.3663e-01, time/batch = 0.6425s	
6298/33650 (epoch 9.358), train_loss = 1.30396748, grad/param norm = 1.5869e-01, time/batch = 0.6452s	
6299/33650 (epoch 9.360), train_loss = 1.31190107, grad/param norm = 1.6371e-01, time/batch = 0.6343s	
6300/33650 (epoch 9.361), train_loss = 1.22299450, grad/param norm = 1.3592e-01, time/batch = 0.6433s	
6301/33650 (epoch 9.363), train_loss = 1.12526962, grad/param norm = 1.4051e-01, time/batch = 0.6448s	
6302/33650 (epoch 9.364), train_loss = 1.18218682, grad/param norm = 1.4273e-01, time/batch = 0.6301s	
6303/33650 (epoch 9.366), train_loss = 1.24626433, grad/param norm = 1.5382e-01, time/batch = 0.6325s	
6304/33650 (epoch 9.367), train_loss = 1.30346386, grad/param norm = 1.4689e-01, time/batch = 0.6342s	
6305/33650 (epoch 9.368), train_loss = 1.10577825, grad/param norm = 1.4431e-01, time/batch = 0.6319s	
6306/33650 (epoch 9.370), train_loss = 1.21764125, grad/param norm = 1.4901e-01, time/batch = 0.6348s	
6307/33650 (epoch 9.371), train_loss = 0.99873774, grad/param norm = 1.3543e-01, time/batch = 0.6569s	
6308/33650 (epoch 9.373), train_loss = 1.11863961, grad/param norm = 1.3943e-01, time/batch = 0.6573s	
6309/33650 (epoch 9.374), train_loss = 1.00975067, grad/param norm = 1.2906e-01, time/batch = 0.6285s	
6310/33650 (epoch 9.376), train_loss = 1.18638493, grad/param norm = 1.6393e-01, time/batch = 0.6254s	
6311/33650 (epoch 9.377), train_loss = 1.26361006, grad/param norm = 1.6099e-01, time/batch = 0.6276s	
6312/33650 (epoch 9.379), train_loss = 1.26563671, grad/param norm = 1.3871e-01, time/batch = 0.6308s	
6313/33650 (epoch 9.380), train_loss = 0.98216432, grad/param norm = 1.4798e-01, time/batch = 0.6309s	
6314/33650 (epoch 9.382), train_loss = 1.03615628, grad/param norm = 1.2430e-01, time/batch = 0.6282s	
6315/33650 (epoch 9.383), train_loss = 1.16529901, grad/param norm = 1.4441e-01, time/batch = 0.6292s	
6316/33650 (epoch 9.385), train_loss = 1.33848441, grad/param norm = 1.5353e-01, time/batch = 0.6271s	
6317/33650 (epoch 9.386), train_loss = 1.12243513, grad/param norm = 1.4478e-01, time/batch = 0.6279s	
6318/33650 (epoch 9.388), train_loss = 1.23621712, grad/param norm = 1.4205e-01, time/batch = 0.6261s	
6319/33650 (epoch 9.389), train_loss = 1.21695680, grad/param norm = 1.5500e-01, time/batch = 0.6357s	
6320/33650 (epoch 9.391), train_loss = 0.99998777, grad/param norm = 1.3705e-01, time/batch = 0.6348s	
6321/33650 (epoch 9.392), train_loss = 1.29503002, grad/param norm = 1.5503e-01, time/batch = 0.6384s	
6322/33650 (epoch 9.394), train_loss = 1.33707256, grad/param norm = 1.7224e-01, time/batch = 0.6344s	
6323/33650 (epoch 9.395), train_loss = 1.21714470, grad/param norm = 1.5861e-01, time/batch = 0.6332s	
6324/33650 (epoch 9.397), train_loss = 1.41356751, grad/param norm = 1.7065e-01, time/batch = 0.6305s	
6325/33650 (epoch 9.398), train_loss = 1.20489343, grad/param norm = 1.3630e-01, time/batch = 0.6277s	
6326/33650 (epoch 9.400), train_loss = 1.22388206, grad/param norm = 1.7281e-01, time/batch = 0.6301s	
6327/33650 (epoch 9.401), train_loss = 1.22722559, grad/param norm = 1.6666e-01, time/batch = 0.6428s	
6328/33650 (epoch 9.403), train_loss = 1.28325597, grad/param norm = 1.6561e-01, time/batch = 0.6675s	
6329/33650 (epoch 9.404), train_loss = 1.16876509, grad/param norm = 1.2533e-01, time/batch = 0.6577s	
6330/33650 (epoch 9.406), train_loss = 1.25701306, grad/param norm = 1.4653e-01, time/batch = 0.6491s	
6331/33650 (epoch 9.407), train_loss = 1.22042779, grad/param norm = 1.5398e-01, time/batch = 0.6602s	
6332/33650 (epoch 9.409), train_loss = 1.23060776, grad/param norm = 1.4707e-01, time/batch = 0.6479s	
6333/33650 (epoch 9.410), train_loss = 1.21971510, grad/param norm = 1.6352e-01, time/batch = 0.6409s	
6334/33650 (epoch 9.412), train_loss = 1.20780961, grad/param norm = 1.3405e-01, time/batch = 0.6298s	
6335/33650 (epoch 9.413), train_loss = 1.10552943, grad/param norm = 1.3765e-01, time/batch = 0.6259s	
6336/33650 (epoch 9.415), train_loss = 1.27219904, grad/param norm = 1.5151e-01, time/batch = 0.6316s	
6337/33650 (epoch 9.416), train_loss = 1.40012226, grad/param norm = 1.5957e-01, time/batch = 0.6868s	
6338/33650 (epoch 9.418), train_loss = 1.23293575, grad/param norm = 1.5040e-01, time/batch = 0.9222s	
6339/33650 (epoch 9.419), train_loss = 1.15322229, grad/param norm = 1.4606e-01, time/batch = 0.9168s	
6340/33650 (epoch 9.421), train_loss = 1.12426781, grad/param norm = 1.3064e-01, time/batch = 0.9209s	
6341/33650 (epoch 9.422), train_loss = 1.32427673, grad/param norm = 1.4994e-01, time/batch = 0.9594s	
6342/33650 (epoch 9.423), train_loss = 1.07055193, grad/param norm = 1.3901e-01, time/batch = 0.9498s	
6343/33650 (epoch 9.425), train_loss = 1.25857583, grad/param norm = 1.6861e-01, time/batch = 1.6715s	
6344/33650 (epoch 9.426), train_loss = 1.36351509, grad/param norm = 1.5968e-01, time/batch = 1.7116s	
6345/33650 (epoch 9.428), train_loss = 1.14987081, grad/param norm = 1.4944e-01, time/batch = 2.2745s	
6346/33650 (epoch 9.429), train_loss = 1.30161059, grad/param norm = 1.4693e-01, time/batch = 16.7498s	
6347/33650 (epoch 9.431), train_loss = 1.44420309, grad/param norm = 1.7064e-01, time/batch = 15.9932s	
6348/33650 (epoch 9.432), train_loss = 1.52100002, grad/param norm = 1.7228e-01, time/batch = 17.2380s	
6349/33650 (epoch 9.434), train_loss = 1.28977848, grad/param norm = 1.4354e-01, time/batch = 17.3263s	
6350/33650 (epoch 9.435), train_loss = 1.26058050, grad/param norm = 1.5773e-01, time/batch = 17.2462s	
6351/33650 (epoch 9.437), train_loss = 1.28397076, grad/param norm = 1.5648e-01, time/batch = 4.2304s	
6352/33650 (epoch 9.438), train_loss = 1.15726459, grad/param norm = 1.5190e-01, time/batch = 0.6283s	
6353/33650 (epoch 9.440), train_loss = 1.25992610, grad/param norm = 1.6431e-01, time/batch = 0.6426s	
6354/33650 (epoch 9.441), train_loss = 1.28101778, grad/param norm = 1.6016e-01, time/batch = 0.6268s	
6355/33650 (epoch 9.443), train_loss = 1.27552872, grad/param norm = 1.5899e-01, time/batch = 0.6246s	
6356/33650 (epoch 9.444), train_loss = 1.17180137, grad/param norm = 1.3740e-01, time/batch = 0.6247s	
6357/33650 (epoch 9.446), train_loss = 1.28691473, grad/param norm = 1.6066e-01, time/batch = 0.6234s	
6358/33650 (epoch 9.447), train_loss = 1.33951694, grad/param norm = 1.7308e-01, time/batch = 0.6252s	
6359/33650 (epoch 9.449), train_loss = 1.46147447, grad/param norm = 2.0103e-01, time/batch = 0.8708s	
6360/33650 (epoch 9.450), train_loss = 1.47036139, grad/param norm = 1.7853e-01, time/batch = 0.9173s	
6361/33650 (epoch 9.452), train_loss = 1.53424147, grad/param norm = 1.6918e-01, time/batch = 0.9200s	
6362/33650 (epoch 9.453), train_loss = 1.42266758, grad/param norm = 1.6909e-01, time/batch = 0.9181s	
6363/33650 (epoch 9.455), train_loss = 1.22269289, grad/param norm = 1.4967e-01, time/batch = 0.9189s	
6364/33650 (epoch 9.456), train_loss = 1.20805537, grad/param norm = 1.3725e-01, time/batch = 1.2499s	
6365/33650 (epoch 9.458), train_loss = 1.21207215, grad/param norm = 1.5099e-01, time/batch = 1.7569s	
6366/33650 (epoch 9.459), train_loss = 1.22432101, grad/param norm = 1.5832e-01, time/batch = 1.7560s	
6367/33650 (epoch 9.461), train_loss = 1.41533547, grad/param norm = 1.6389e-01, time/batch = 11.4257s	
6368/33650 (epoch 9.462), train_loss = 1.37150913, grad/param norm = 1.6497e-01, time/batch = 15.0630s	
6369/33650 (epoch 9.464), train_loss = 1.15689413, grad/param norm = 1.5281e-01, time/batch = 16.9838s	
6370/33650 (epoch 9.465), train_loss = 1.29096114, grad/param norm = 1.6747e-01, time/batch = 15.6587s	
6371/33650 (epoch 9.467), train_loss = 1.32384247, grad/param norm = 1.6674e-01, time/batch = 18.0691s	
6372/33650 (epoch 9.468), train_loss = 1.37228511, grad/param norm = 1.5440e-01, time/batch = 16.8336s	
6373/33650 (epoch 9.470), train_loss = 1.52160475, grad/param norm = 1.7657e-01, time/batch = 16.3879s	
6374/33650 (epoch 9.471), train_loss = 1.24724249, grad/param norm = 1.5947e-01, time/batch = 17.9082s	
6375/33650 (epoch 9.473), train_loss = 1.20100099, grad/param norm = 1.3994e-01, time/batch = 17.9110s	
6376/33650 (epoch 9.474), train_loss = 1.30630089, grad/param norm = 1.5667e-01, time/batch = 17.9030s	
6377/33650 (epoch 9.475), train_loss = 1.32888007, grad/param norm = 1.6155e-01, time/batch = 16.9928s	
6378/33650 (epoch 9.477), train_loss = 1.36451369, grad/param norm = 1.5498e-01, time/batch = 18.0690s	
6379/33650 (epoch 9.478), train_loss = 1.36585183, grad/param norm = 1.7175e-01, time/batch = 15.0463s	
6380/33650 (epoch 9.480), train_loss = 1.40602322, grad/param norm = 1.6305e-01, time/batch = 16.1600s	
6381/33650 (epoch 9.481), train_loss = 1.37450537, grad/param norm = 1.6473e-01, time/batch = 17.3162s	
6382/33650 (epoch 9.483), train_loss = 1.01310937, grad/param norm = 1.4626e-01, time/batch = 17.3210s	
6383/33650 (epoch 9.484), train_loss = 1.26810633, grad/param norm = 1.4184e-01, time/batch = 16.8964s	
6384/33650 (epoch 9.486), train_loss = 1.38909301, grad/param norm = 1.8806e-01, time/batch = 16.3936s	
6385/33650 (epoch 9.487), train_loss = 1.37105298, grad/param norm = 1.7579e-01, time/batch = 17.0823s	
6386/33650 (epoch 9.489), train_loss = 1.46000856, grad/param norm = 1.6258e-01, time/batch = 17.3237s	
6387/33650 (epoch 9.490), train_loss = 1.14672141, grad/param norm = 1.4153e-01, time/batch = 16.3193s	
6388/33650 (epoch 9.492), train_loss = 1.32581387, grad/param norm = 1.7534e-01, time/batch = 17.0613s	
6389/33650 (epoch 9.493), train_loss = 1.01864778, grad/param norm = 1.3194e-01, time/batch = 17.8229s	
6390/33650 (epoch 9.495), train_loss = 1.24789112, grad/param norm = 1.5254e-01, time/batch = 17.2337s	
6391/33650 (epoch 9.496), train_loss = 1.32506564, grad/param norm = 1.7376e-01, time/batch = 15.6511s	
6392/33650 (epoch 9.498), train_loss = 1.08868825, grad/param norm = 1.4012e-01, time/batch = 16.9478s	
6393/33650 (epoch 9.499), train_loss = 1.22626177, grad/param norm = 1.4045e-01, time/batch = 16.7308s	
6394/33650 (epoch 9.501), train_loss = 1.17985669, grad/param norm = 1.4567e-01, time/batch = 16.9835s	
6395/33650 (epoch 9.502), train_loss = 1.29152555, grad/param norm = 1.5763e-01, time/batch = 17.1611s	
6396/33650 (epoch 9.504), train_loss = 1.40403738, grad/param norm = 1.7517e-01, time/batch = 17.7349s	
6397/33650 (epoch 9.505), train_loss = 1.26945417, grad/param norm = 1.6960e-01, time/batch = 16.9754s	
6398/33650 (epoch 9.507), train_loss = 1.39860786, grad/param norm = 1.5949e-01, time/batch = 16.7368s	
6399/33650 (epoch 9.508), train_loss = 1.17603148, grad/param norm = 1.4441e-01, time/batch = 17.2315s	
6400/33650 (epoch 9.510), train_loss = 1.23664664, grad/param norm = 1.4986e-01, time/batch = 17.7437s	
6401/33650 (epoch 9.511), train_loss = 1.52194745, grad/param norm = 1.8511e-01, time/batch = 15.8227s	
6402/33650 (epoch 9.513), train_loss = 1.31162824, grad/param norm = 1.4612e-01, time/batch = 17.6544s	
6403/33650 (epoch 9.514), train_loss = 1.36030595, grad/param norm = 1.6923e-01, time/batch = 15.8970s	
6404/33650 (epoch 9.516), train_loss = 1.26647830, grad/param norm = 1.5612e-01, time/batch = 16.9039s	
6405/33650 (epoch 9.517), train_loss = 1.23678631, grad/param norm = 1.5842e-01, time/batch = 16.0668s	
6406/33650 (epoch 9.519), train_loss = 1.25296718, grad/param norm = 1.4291e-01, time/batch = 17.4174s	
6407/33650 (epoch 9.520), train_loss = 1.06562032, grad/param norm = 1.3642e-01, time/batch = 15.6490s	
6408/33650 (epoch 9.522), train_loss = 1.27197420, grad/param norm = 1.6051e-01, time/batch = 15.6161s	
6409/33650 (epoch 9.523), train_loss = 1.24306100, grad/param norm = 1.4159e-01, time/batch = 17.4014s	
6410/33650 (epoch 9.525), train_loss = 0.98026709, grad/param norm = 1.3687e-01, time/batch = 16.9836s	
6411/33650 (epoch 9.526), train_loss = 1.30752936, grad/param norm = 1.4812e-01, time/batch = 18.1515s	
6412/33650 (epoch 9.527), train_loss = 1.12164534, grad/param norm = 1.3619e-01, time/batch = 16.5588s	
6413/33650 (epoch 9.529), train_loss = 1.22855312, grad/param norm = 1.4524e-01, time/batch = 18.1537s	
6414/33650 (epoch 9.530), train_loss = 1.17311881, grad/param norm = 1.4592e-01, time/batch = 16.5773s	
6415/33650 (epoch 9.532), train_loss = 1.47273933, grad/param norm = 1.8338e-01, time/batch = 16.4815s	
6416/33650 (epoch 9.533), train_loss = 1.21064845, grad/param norm = 1.5079e-01, time/batch = 17.4024s	
6417/33650 (epoch 9.535), train_loss = 1.36250930, grad/param norm = 1.5602e-01, time/batch = 18.0657s	
6418/33650 (epoch 9.536), train_loss = 1.29112576, grad/param norm = 1.6476e-01, time/batch = 16.9014s	
6419/33650 (epoch 9.538), train_loss = 1.29345951, grad/param norm = 1.7016e-01, time/batch = 16.7227s	
6420/33650 (epoch 9.539), train_loss = 1.04035397, grad/param norm = 1.3581e-01, time/batch = 17.4068s	
6421/33650 (epoch 9.541), train_loss = 1.39947719, grad/param norm = 1.6247e-01, time/batch = 17.4104s	
6422/33650 (epoch 9.542), train_loss = 1.29689283, grad/param norm = 1.7136e-01, time/batch = 16.8964s	
6423/33650 (epoch 9.544), train_loss = 1.49078806, grad/param norm = 1.6713e-01, time/batch = 16.2381s	
6424/33650 (epoch 9.545), train_loss = 1.09375946, grad/param norm = 1.3980e-01, time/batch = 16.8789s	
6425/33650 (epoch 9.547), train_loss = 1.26339141, grad/param norm = 1.4847e-01, time/batch = 17.0703s	
6426/33650 (epoch 9.548), train_loss = 1.40768065, grad/param norm = 1.5705e-01, time/batch = 16.6397s	
6427/33650 (epoch 9.550), train_loss = 1.22053652, grad/param norm = 1.4911e-01, time/batch = 17.4176s	
6428/33650 (epoch 9.551), train_loss = 1.23326607, grad/param norm = 1.5518e-01, time/batch = 17.5694s	
6429/33650 (epoch 9.553), train_loss = 1.06434226, grad/param norm = 1.5069e-01, time/batch = 16.0394s	
6430/33650 (epoch 9.554), train_loss = 1.38285113, grad/param norm = 1.6600e-01, time/batch = 16.9863s	
6431/33650 (epoch 9.556), train_loss = 1.38713284, grad/param norm = 1.8379e-01, time/batch = 17.6470s	
6432/33650 (epoch 9.557), train_loss = 1.43156662, grad/param norm = 1.7256e-01, time/batch = 17.4042s	
6433/33650 (epoch 9.559), train_loss = 1.53234853, grad/param norm = 1.9218e-01, time/batch = 16.9767s	
6434/33650 (epoch 9.560), train_loss = 1.47806274, grad/param norm = 1.6783e-01, time/batch = 17.5630s	
6435/33650 (epoch 9.562), train_loss = 1.33419389, grad/param norm = 1.4562e-01, time/batch = 17.2353s	
6436/33650 (epoch 9.563), train_loss = 1.23897429, grad/param norm = 1.6199e-01, time/batch = 22.6482s	
6437/33650 (epoch 9.565), train_loss = 1.28046293, grad/param norm = 1.5208e-01, time/batch = 24.7442s	
6438/33650 (epoch 9.566), train_loss = 1.27518156, grad/param norm = 1.5750e-01, time/batch = 17.2457s	
6439/33650 (epoch 9.568), train_loss = 1.26353128, grad/param norm = 1.4896e-01, time/batch = 15.6243s	
6440/33650 (epoch 9.569), train_loss = 1.20166944, grad/param norm = 1.4692e-01, time/batch = 17.5712s	
6441/33650 (epoch 9.571), train_loss = 1.39996838, grad/param norm = 1.6349e-01, time/batch = 18.2454s	
6442/33650 (epoch 9.572), train_loss = 1.30081739, grad/param norm = 1.4421e-01, time/batch = 16.5690s	
6443/33650 (epoch 9.574), train_loss = 1.25965833, grad/param norm = 1.5372e-01, time/batch = 17.1615s	
6444/33650 (epoch 9.575), train_loss = 1.23008815, grad/param norm = 1.4449e-01, time/batch = 16.4798s	
6445/33650 (epoch 9.577), train_loss = 1.31059742, grad/param norm = 1.6335e-01, time/batch = 17.0428s	
6446/33650 (epoch 9.578), train_loss = 1.29453380, grad/param norm = 1.4875e-01, time/batch = 15.9063s	
6447/33650 (epoch 9.579), train_loss = 1.33336582, grad/param norm = 1.5248e-01, time/batch = 17.4939s	
6448/33650 (epoch 9.581), train_loss = 1.33849736, grad/param norm = 1.4957e-01, time/batch = 17.5665s	
6449/33650 (epoch 9.582), train_loss = 1.35958611, grad/param norm = 1.4923e-01, time/batch = 16.2203s	
6450/33650 (epoch 9.584), train_loss = 1.27994100, grad/param norm = 1.5191e-01, time/batch = 17.2292s	
6451/33650 (epoch 9.585), train_loss = 1.30291268, grad/param norm = 1.6329e-01, time/batch = 17.7336s	
6452/33650 (epoch 9.587), train_loss = 1.16476140, grad/param norm = 1.5221e-01, time/batch = 17.3163s	
6453/33650 (epoch 9.588), train_loss = 1.23135527, grad/param norm = 1.6000e-01, time/batch = 16.3121s	
6454/33650 (epoch 9.590), train_loss = 1.22480059, grad/param norm = 1.4736e-01, time/batch = 17.4031s	
6455/33650 (epoch 9.591), train_loss = 1.23473390, grad/param norm = 1.6884e-01, time/batch = 17.6596s	
6456/33650 (epoch 9.593), train_loss = 1.15887024, grad/param norm = 1.3758e-01, time/batch = 15.6431s	
6457/33650 (epoch 9.594), train_loss = 1.05170373, grad/param norm = 1.5147e-01, time/batch = 15.9720s	
6458/33650 (epoch 9.596), train_loss = 1.18843578, grad/param norm = 1.3521e-01, time/batch = 17.4734s	
6459/33650 (epoch 9.597), train_loss = 1.00919941, grad/param norm = 1.2034e-01, time/batch = 16.9859s	
6460/33650 (epoch 9.599), train_loss = 1.16299079, grad/param norm = 1.4913e-01, time/batch = 16.3133s	
6461/33650 (epoch 9.600), train_loss = 1.07801272, grad/param norm = 1.3625e-01, time/batch = 16.8143s	
6462/33650 (epoch 9.602), train_loss = 1.33466382, grad/param norm = 1.5429e-01, time/batch = 13.9799s	
6463/33650 (epoch 9.603), train_loss = 1.17448922, grad/param norm = 1.4756e-01, time/batch = 16.3831s	
6464/33650 (epoch 9.605), train_loss = 1.26425935, grad/param norm = 1.5530e-01, time/batch = 15.8721s	
6465/33650 (epoch 9.606), train_loss = 1.34233428, grad/param norm = 1.5931e-01, time/batch = 17.3239s	
6466/33650 (epoch 9.608), train_loss = 1.18943991, grad/param norm = 1.4939e-01, time/batch = 16.8241s	
6467/33650 (epoch 9.609), train_loss = 1.27659918, grad/param norm = 1.5842e-01, time/batch = 16.8070s	
6468/33650 (epoch 9.611), train_loss = 1.10848694, grad/param norm = 1.4320e-01, time/batch = 16.9000s	
6469/33650 (epoch 9.612), train_loss = 1.23244135, grad/param norm = 1.5730e-01, time/batch = 16.4845s	
6470/33650 (epoch 9.614), train_loss = 1.31867841, grad/param norm = 1.6997e-01, time/batch = 17.1373s	
6471/33650 (epoch 9.615), train_loss = 1.19917452, grad/param norm = 1.3580e-01, time/batch = 16.5623s	
6472/33650 (epoch 9.617), train_loss = 1.08413575, grad/param norm = 1.2672e-01, time/batch = 17.3076s	
6473/33650 (epoch 9.618), train_loss = 1.17812088, grad/param norm = 1.3796e-01, time/batch = 16.9671s	
6474/33650 (epoch 9.620), train_loss = 1.30670200, grad/param norm = 1.6948e-01, time/batch = 17.4746s	
6475/33650 (epoch 9.621), train_loss = 1.09110296, grad/param norm = 1.4014e-01, time/batch = 16.8198s	
6476/33650 (epoch 9.623), train_loss = 1.22152322, grad/param norm = 1.4193e-01, time/batch = 16.4089s	
6477/33650 (epoch 9.624), train_loss = 0.96349799, grad/param norm = 1.3770e-01, time/batch = 17.8161s	
6478/33650 (epoch 9.626), train_loss = 0.96150182, grad/param norm = 1.2429e-01, time/batch = 16.7490s	
6479/33650 (epoch 9.627), train_loss = 1.18034327, grad/param norm = 1.4390e-01, time/batch = 17.3986s	
6480/33650 (epoch 9.629), train_loss = 1.21106302, grad/param norm = 1.4155e-01, time/batch = 17.4778s	
6481/33650 (epoch 9.630), train_loss = 1.32297697, grad/param norm = 1.5801e-01, time/batch = 16.6462s	
6482/33650 (epoch 9.632), train_loss = 1.35359894, grad/param norm = 1.4745e-01, time/batch = 16.8017s	
6483/33650 (epoch 9.633), train_loss = 1.31589363, grad/param norm = 1.4730e-01, time/batch = 17.3241s	
6484/33650 (epoch 9.634), train_loss = 1.05389466, grad/param norm = 1.4090e-01, time/batch = 15.6630s	
6485/33650 (epoch 9.636), train_loss = 0.97212038, grad/param norm = 1.2354e-01, time/batch = 16.1497s	
6486/33650 (epoch 9.637), train_loss = 1.23852067, grad/param norm = 1.5501e-01, time/batch = 17.8212s	
6487/33650 (epoch 9.639), train_loss = 1.15301157, grad/param norm = 1.4523e-01, time/batch = 17.4101s	
6488/33650 (epoch 9.640), train_loss = 1.23938063, grad/param norm = 1.4950e-01, time/batch = 16.9739s	
6489/33650 (epoch 9.642), train_loss = 1.38520868, grad/param norm = 1.7323e-01, time/batch = 17.0613s	
6490/33650 (epoch 9.643), train_loss = 1.23235776, grad/param norm = 1.5302e-01, time/batch = 17.6558s	
6491/33650 (epoch 9.645), train_loss = 1.20848046, grad/param norm = 1.4357e-01, time/batch = 16.1393s	
6492/33650 (epoch 9.646), train_loss = 1.01655629, grad/param norm = 1.2790e-01, time/batch = 16.3935s	
6493/33650 (epoch 9.648), train_loss = 1.24695181, grad/param norm = 1.4494e-01, time/batch = 17.5577s	
6494/33650 (epoch 9.649), train_loss = 1.27007827, grad/param norm = 1.7592e-01, time/batch = 16.9882s	
6495/33650 (epoch 9.651), train_loss = 1.35567002, grad/param norm = 1.5360e-01, time/batch = 16.3088s	
6496/33650 (epoch 9.652), train_loss = 0.90092153, grad/param norm = 1.2220e-01, time/batch = 17.1441s	
6497/33650 (epoch 9.654), train_loss = 1.14413814, grad/param norm = 1.4489e-01, time/batch = 16.7255s	
6498/33650 (epoch 9.655), train_loss = 1.08054209, grad/param norm = 1.3273e-01, time/batch = 17.1607s	
6499/33650 (epoch 9.657), train_loss = 1.22821640, grad/param norm = 1.5824e-01, time/batch = 15.7259s	
6500/33650 (epoch 9.658), train_loss = 1.06148939, grad/param norm = 1.3351e-01, time/batch = 18.2386s	
6501/33650 (epoch 9.660), train_loss = 1.02783771, grad/param norm = 1.3145e-01, time/batch = 17.8229s	
6502/33650 (epoch 9.661), train_loss = 1.14121206, grad/param norm = 1.3251e-01, time/batch = 16.8062s	
6503/33650 (epoch 9.663), train_loss = 1.06085255, grad/param norm = 1.5460e-01, time/batch = 17.1409s	
6504/33650 (epoch 9.664), train_loss = 1.05248011, grad/param norm = 1.3197e-01, time/batch = 17.5783s	
6505/33650 (epoch 9.666), train_loss = 1.15015350, grad/param norm = 1.4532e-01, time/batch = 17.7467s	
6506/33650 (epoch 9.667), train_loss = 1.10840771, grad/param norm = 1.4262e-01, time/batch = 15.3095s	
6507/33650 (epoch 9.669), train_loss = 1.07771752, grad/param norm = 1.4418e-01, time/batch = 17.3284s	
6508/33650 (epoch 9.670), train_loss = 1.02328839, grad/param norm = 1.4556e-01, time/batch = 16.4816s	
6509/33650 (epoch 9.672), train_loss = 1.04948730, grad/param norm = 1.4550e-01, time/batch = 17.0506s	
6510/33650 (epoch 9.673), train_loss = 0.98425410, grad/param norm = 1.3982e-01, time/batch = 14.6256s	
6511/33650 (epoch 9.675), train_loss = 0.94936317, grad/param norm = 1.2101e-01, time/batch = 17.8222s	
6512/33650 (epoch 9.676), train_loss = 1.19844483, grad/param norm = 1.4419e-01, time/batch = 16.5619s	
6513/33650 (epoch 9.678), train_loss = 1.08890577, grad/param norm = 1.3989e-01, time/batch = 16.9827s	
6514/33650 (epoch 9.679), train_loss = 1.15257926, grad/param norm = 1.5455e-01, time/batch = 17.2502s	
6515/33650 (epoch 9.681), train_loss = 1.08831209, grad/param norm = 1.3446e-01, time/batch = 16.3050s	
6516/33650 (epoch 9.682), train_loss = 1.11200234, grad/param norm = 1.5164e-01, time/batch = 17.6538s	
6517/33650 (epoch 9.684), train_loss = 1.08864627, grad/param norm = 1.3570e-01, time/batch = 16.7283s	
6518/33650 (epoch 9.685), train_loss = 1.24965545, grad/param norm = 1.5432e-01, time/batch = 17.2526s	
6519/33650 (epoch 9.686), train_loss = 1.18272799, grad/param norm = 1.4145e-01, time/batch = 16.1652s	
6520/33650 (epoch 9.688), train_loss = 1.35930522, grad/param norm = 1.5722e-01, time/batch = 17.1552s	
6521/33650 (epoch 9.689), train_loss = 1.11141315, grad/param norm = 1.4553e-01, time/batch = 16.7328s	
6522/33650 (epoch 9.691), train_loss = 1.32071948, grad/param norm = 1.5492e-01, time/batch = 16.6678s	
6523/33650 (epoch 9.692), train_loss = 1.30483885, grad/param norm = 1.5102e-01, time/batch = 18.1559s	
6524/33650 (epoch 9.694), train_loss = 1.25608075, grad/param norm = 1.6266e-01, time/batch = 16.9783s	
6525/33650 (epoch 9.695), train_loss = 0.89531124, grad/param norm = 1.3776e-01, time/batch = 17.1532s	
6526/33650 (epoch 9.697), train_loss = 1.21494304, grad/param norm = 1.5033e-01, time/batch = 17.4108s	
6527/33650 (epoch 9.698), train_loss = 1.32759748, grad/param norm = 1.5451e-01, time/batch = 16.8039s	
6528/33650 (epoch 9.700), train_loss = 1.16927818, grad/param norm = 1.4124e-01, time/batch = 16.8053s	
6529/33650 (epoch 9.701), train_loss = 1.23320945, grad/param norm = 1.5487e-01, time/batch = 17.0648s	
6530/33650 (epoch 9.703), train_loss = 1.30815146, grad/param norm = 1.4176e-01, time/batch = 16.1927s	
6531/33650 (epoch 9.704), train_loss = 1.16198685, grad/param norm = 1.4108e-01, time/batch = 16.2247s	
6532/33650 (epoch 9.706), train_loss = 1.16775653, grad/param norm = 1.3920e-01, time/batch = 17.9071s	
6533/33650 (epoch 9.707), train_loss = 1.28543885, grad/param norm = 1.5035e-01, time/batch = 16.7438s	
6534/33650 (epoch 9.709), train_loss = 1.14945078, grad/param norm = 1.4221e-01, time/batch = 16.9789s	
6535/33650 (epoch 9.710), train_loss = 1.38427163, grad/param norm = 1.4415e-01, time/batch = 17.0674s	
6536/33650 (epoch 9.712), train_loss = 1.13746054, grad/param norm = 1.4980e-01, time/batch = 17.0763s	
6537/33650 (epoch 9.713), train_loss = 1.16880889, grad/param norm = 1.7716e-01, time/batch = 17.2355s	
6538/33650 (epoch 9.715), train_loss = 1.32626941, grad/param norm = 1.5674e-01, time/batch = 16.3931s	
6539/33650 (epoch 9.716), train_loss = 1.08069800, grad/param norm = 1.4499e-01, time/batch = 14.8876s	
6540/33650 (epoch 9.718), train_loss = 1.19369859, grad/param norm = 1.4918e-01, time/batch = 18.1519s	
6541/33650 (epoch 9.719), train_loss = 1.35496697, grad/param norm = 1.6876e-01, time/batch = 16.7390s	
6542/33650 (epoch 9.721), train_loss = 1.44013421, grad/param norm = 1.5924e-01, time/batch = 16.9016s	
6543/33650 (epoch 9.722), train_loss = 1.37302476, grad/param norm = 1.8602e-01, time/batch = 17.8952s	
6544/33650 (epoch 9.724), train_loss = 1.29247216, grad/param norm = 1.5294e-01, time/batch = 17.3217s	
6545/33650 (epoch 9.725), train_loss = 1.35775363, grad/param norm = 1.6285e-01, time/batch = 16.3136s	
6546/33650 (epoch 9.727), train_loss = 1.12138799, grad/param norm = 1.6198e-01, time/batch = 17.4792s	
6547/33650 (epoch 9.728), train_loss = 1.14265109, grad/param norm = 1.4269e-01, time/batch = 17.4880s	
6548/33650 (epoch 9.730), train_loss = 1.29211909, grad/param norm = 1.4894e-01, time/batch = 17.1233s	
6549/33650 (epoch 9.731), train_loss = 1.34833578, grad/param norm = 1.5939e-01, time/batch = 16.3133s	
6550/33650 (epoch 9.733), train_loss = 1.20761327, grad/param norm = 1.5423e-01, time/batch = 17.7400s	
6551/33650 (epoch 9.734), train_loss = 1.39499325, grad/param norm = 1.7383e-01, time/batch = 17.6578s	
6552/33650 (epoch 9.736), train_loss = 1.17431204, grad/param norm = 1.4717e-01, time/batch = 16.8260s	
6553/33650 (epoch 9.737), train_loss = 1.23729268, grad/param norm = 1.6178e-01, time/batch = 17.5780s	
6554/33650 (epoch 9.738), train_loss = 1.09319683, grad/param norm = 1.3855e-01, time/batch = 17.3829s	
6555/33650 (epoch 9.740), train_loss = 1.04835334, grad/param norm = 1.2927e-01, time/batch = 16.9642s	
6556/33650 (epoch 9.741), train_loss = 1.16308399, grad/param norm = 1.4990e-01, time/batch = 15.9769s	
6557/33650 (epoch 9.743), train_loss = 1.21181298, grad/param norm = 1.4372e-01, time/batch = 17.3219s	
6558/33650 (epoch 9.744), train_loss = 1.16581063, grad/param norm = 1.3974e-01, time/batch = 16.2309s	
6559/33650 (epoch 9.746), train_loss = 1.17731591, grad/param norm = 1.5005e-01, time/batch = 16.2242s	
6560/33650 (epoch 9.747), train_loss = 1.29128981, grad/param norm = 1.4283e-01, time/batch = 17.2373s	
6561/33650 (epoch 9.749), train_loss = 1.02167910, grad/param norm = 1.3693e-01, time/batch = 17.8982s	
6562/33650 (epoch 9.750), train_loss = 1.31754379, grad/param norm = 1.5140e-01, time/batch = 16.8656s	
6563/33650 (epoch 9.752), train_loss = 1.34330196, grad/param norm = 1.5803e-01, time/batch = 17.2051s	
6564/33650 (epoch 9.753), train_loss = 1.44048372, grad/param norm = 1.6397e-01, time/batch = 16.5723s	
6565/33650 (epoch 9.755), train_loss = 1.12436467, grad/param norm = 1.4138e-01, time/batch = 16.4819s	
6566/33650 (epoch 9.756), train_loss = 1.32744443, grad/param norm = 1.6941e-01, time/batch = 16.5592s	
6567/33650 (epoch 9.758), train_loss = 1.33854785, grad/param norm = 1.6038e-01, time/batch = 17.0718s	
6568/33650 (epoch 9.759), train_loss = 1.44152100, grad/param norm = 1.7073e-01, time/batch = 17.3985s	
6569/33650 (epoch 9.761), train_loss = 1.27736955, grad/param norm = 1.5495e-01, time/batch = 16.2305s	
6570/33650 (epoch 9.762), train_loss = 1.23589922, grad/param norm = 1.4941e-01, time/batch = 17.6516s	
6571/33650 (epoch 9.764), train_loss = 1.32193854, grad/param norm = 1.6110e-01, time/batch = 17.9091s	
6572/33650 (epoch 9.765), train_loss = 1.25207599, grad/param norm = 1.5017e-01, time/batch = 16.6522s	
6573/33650 (epoch 9.767), train_loss = 1.14740085, grad/param norm = 1.4650e-01, time/batch = 16.4736s	
6574/33650 (epoch 9.768), train_loss = 1.07023298, grad/param norm = 1.3633e-01, time/batch = 17.2417s	
6575/33650 (epoch 9.770), train_loss = 1.21056308, grad/param norm = 1.5020e-01, time/batch = 18.2961s	
6576/33650 (epoch 9.771), train_loss = 1.22193906, grad/param norm = 1.4688e-01, time/batch = 16.5424s	
6577/33650 (epoch 9.773), train_loss = 1.37470310, grad/param norm = 1.7452e-01, time/batch = 17.6452s	
6578/33650 (epoch 9.774), train_loss = 1.25858126, grad/param norm = 1.5504e-01, time/batch = 18.0643s	
6579/33650 (epoch 9.776), train_loss = 1.31560798, grad/param norm = 1.5868e-01, time/batch = 16.9791s	
6580/33650 (epoch 9.777), train_loss = 1.05780317, grad/param norm = 1.3578e-01, time/batch = 16.4612s	
6581/33650 (epoch 9.779), train_loss = 1.20071386, grad/param norm = 1.4095e-01, time/batch = 18.0523s	
6582/33650 (epoch 9.780), train_loss = 1.10364663, grad/param norm = 1.3680e-01, time/batch = 18.9024s	
6583/33650 (epoch 9.782), train_loss = 1.15756800, grad/param norm = 1.4169e-01, time/batch = 16.3048s	
6584/33650 (epoch 9.783), train_loss = 1.06755335, grad/param norm = 1.3495e-01, time/batch = 18.4758s	
6585/33650 (epoch 9.785), train_loss = 1.42744178, grad/param norm = 1.4545e-01, time/batch = 18.8225s	
6586/33650 (epoch 9.786), train_loss = 1.21552562, grad/param norm = 1.4387e-01, time/batch = 17.4808s	
6587/33650 (epoch 9.788), train_loss = 1.24252719, grad/param norm = 1.5335e-01, time/batch = 17.5574s	
6588/33650 (epoch 9.789), train_loss = 1.28220866, grad/param norm = 1.3428e-01, time/batch = 17.0561s	
6589/33650 (epoch 9.790), train_loss = 1.31149374, grad/param norm = 1.7322e-01, time/batch = 17.5760s	
6590/33650 (epoch 9.792), train_loss = 1.37653605, grad/param norm = 1.8858e-01, time/batch = 15.8051s	
6591/33650 (epoch 9.793), train_loss = 1.30385658, grad/param norm = 1.6967e-01, time/batch = 17.9930s	
6592/33650 (epoch 9.795), train_loss = 1.36288677, grad/param norm = 1.5138e-01, time/batch = 19.2216s	
6593/33650 (epoch 9.796), train_loss = 1.17876786, grad/param norm = 1.5162e-01, time/batch = 16.6422s	
6594/33650 (epoch 9.798), train_loss = 1.17398862, grad/param norm = 1.3771e-01, time/batch = 17.9013s	
6595/33650 (epoch 9.799), train_loss = 1.20459631, grad/param norm = 1.2982e-01, time/batch = 17.0534s	
6596/33650 (epoch 9.801), train_loss = 1.28097311, grad/param norm = 1.5519e-01, time/batch = 17.8172s	
6597/33650 (epoch 9.802), train_loss = 1.34242982, grad/param norm = 1.4556e-01, time/batch = 16.8809s	
6598/33650 (epoch 9.804), train_loss = 1.20722830, grad/param norm = 1.4542e-01, time/batch = 17.7406s	
6599/33650 (epoch 9.805), train_loss = 1.14933151, grad/param norm = 1.3285e-01, time/batch = 18.8993s	
6600/33650 (epoch 9.807), train_loss = 1.43510854, grad/param norm = 1.6326e-01, time/batch = 16.2288s	
6601/33650 (epoch 9.808), train_loss = 1.43930943, grad/param norm = 1.6437e-01, time/batch = 18.0595s	
6602/33650 (epoch 9.810), train_loss = 1.27583006, grad/param norm = 1.4526e-01, time/batch = 18.4841s	
6603/33650 (epoch 9.811), train_loss = 1.27501005, grad/param norm = 1.5530e-01, time/batch = 16.9859s	
6604/33650 (epoch 9.813), train_loss = 1.22123451, grad/param norm = 1.6416e-01, time/batch = 17.3170s	
6605/33650 (epoch 9.814), train_loss = 1.33147842, grad/param norm = 1.6285e-01, time/batch = 18.3218s	
6606/33650 (epoch 9.816), train_loss = 1.26195990, grad/param norm = 1.5403e-01, time/batch = 16.7164s	
6607/33650 (epoch 9.817), train_loss = 1.34491780, grad/param norm = 1.7303e-01, time/batch = 17.1342s	
6608/33650 (epoch 9.819), train_loss = 1.33982045, grad/param norm = 1.4569e-01, time/batch = 18.6576s	
6609/33650 (epoch 9.820), train_loss = 1.36599923, grad/param norm = 1.5771e-01, time/batch = 17.7399s	
6610/33650 (epoch 9.822), train_loss = 1.39141942, grad/param norm = 1.7290e-01, time/batch = 17.0572s	
6611/33650 (epoch 9.823), train_loss = 1.14436278, grad/param norm = 1.4939e-01, time/batch = 16.5657s	
6612/33650 (epoch 9.825), train_loss = 1.21055526, grad/param norm = 1.4040e-01, time/batch = 17.1450s	
6613/33650 (epoch 9.826), train_loss = 1.30231343, grad/param norm = 1.5132e-01, time/batch = 17.5056s	
6614/33650 (epoch 9.828), train_loss = 1.50617614, grad/param norm = 1.5407e-01, time/batch = 16.8079s	
6615/33650 (epoch 9.829), train_loss = 1.06592777, grad/param norm = 1.3630e-01, time/batch = 15.9712s	
6616/33650 (epoch 9.831), train_loss = 1.32327188, grad/param norm = 1.5609e-01, time/batch = 17.7439s	
6617/33650 (epoch 9.832), train_loss = 1.28499338, grad/param norm = 1.4467e-01, time/batch = 17.4673s	
6618/33650 (epoch 9.834), train_loss = 1.31979635, grad/param norm = 1.5328e-01, time/batch = 16.9839s	
6619/33650 (epoch 9.835), train_loss = 1.51202930, grad/param norm = 1.6806e-01, time/batch = 18.3295s	
6620/33650 (epoch 9.837), train_loss = 1.26040033, grad/param norm = 1.6370e-01, time/batch = 15.7450s	
6621/33650 (epoch 9.838), train_loss = 1.23008742, grad/param norm = 1.6689e-01, time/batch = 15.4664s	
6622/33650 (epoch 9.840), train_loss = 1.32648528, grad/param norm = 1.4883e-01, time/batch = 16.9105s	
6623/33650 (epoch 9.841), train_loss = 1.13170882, grad/param norm = 1.3629e-01, time/batch = 18.3118s	
6624/33650 (epoch 9.842), train_loss = 1.18113443, grad/param norm = 1.4328e-01, time/batch = 17.8024s	
6625/33650 (epoch 9.844), train_loss = 1.41306408, grad/param norm = 1.6325e-01, time/batch = 17.6469s	
6626/33650 (epoch 9.845), train_loss = 1.14876455, grad/param norm = 1.3607e-01, time/batch = 17.2288s	
6627/33650 (epoch 9.847), train_loss = 0.99876893, grad/param norm = 1.4838e-01, time/batch = 18.0638s	
6628/33650 (epoch 9.848), train_loss = 1.08213302, grad/param norm = 1.5886e-01, time/batch = 17.2183s	
6629/33650 (epoch 9.850), train_loss = 1.25704770, grad/param norm = 1.7425e-01, time/batch = 18.5559s	
6630/33650 (epoch 9.851), train_loss = 1.00913983, grad/param norm = 1.3002e-01, time/batch = 18.5434s	
6631/33650 (epoch 9.853), train_loss = 1.24248091, grad/param norm = 1.4669e-01, time/batch = 16.9679s	
6632/33650 (epoch 9.854), train_loss = 1.41564429, grad/param norm = 1.8229e-01, time/batch = 17.9026s	
6633/33650 (epoch 9.856), train_loss = 0.92819917, grad/param norm = 1.3364e-01, time/batch = 17.8130s	
6634/33650 (epoch 9.857), train_loss = 1.19055574, grad/param norm = 1.3302e-01, time/batch = 16.8857s	
6635/33650 (epoch 9.859), train_loss = 1.09731118, grad/param norm = 1.3883e-01, time/batch = 17.5536s	
6636/33650 (epoch 9.860), train_loss = 1.02927948, grad/param norm = 1.4201e-01, time/batch = 16.2750s	
6637/33650 (epoch 9.862), train_loss = 1.08394573, grad/param norm = 1.4422e-01, time/batch = 18.7306s	
6638/33650 (epoch 9.863), train_loss = 1.29360356, grad/param norm = 1.4368e-01, time/batch = 17.1386s	
6639/33650 (epoch 9.865), train_loss = 1.17207918, grad/param norm = 1.4778e-01, time/batch = 17.8939s	
6640/33650 (epoch 9.866), train_loss = 1.07895798, grad/param norm = 1.4380e-01, time/batch = 16.3760s	
6641/33650 (epoch 9.868), train_loss = 1.10724126, grad/param norm = 1.5619e-01, time/batch = 17.4795s	
6642/33650 (epoch 9.869), train_loss = 1.35990446, grad/param norm = 1.6506e-01, time/batch = 18.1302s	
6643/33650 (epoch 9.871), train_loss = 1.06527316, grad/param norm = 1.3196e-01, time/batch = 17.1927s	
6644/33650 (epoch 9.872), train_loss = 1.21422955, grad/param norm = 1.6215e-01, time/batch = 18.9760s	
6645/33650 (epoch 9.874), train_loss = 1.33616337, grad/param norm = 1.6621e-01, time/batch = 32.3087s	
6646/33650 (epoch 9.875), train_loss = 1.15374264, grad/param norm = 1.4651e-01, time/batch = 17.4772s	
6647/33650 (epoch 9.877), train_loss = 1.34277144, grad/param norm = 1.4973e-01, time/batch = 17.1340s	
6648/33650 (epoch 9.878), train_loss = 0.86416647, grad/param norm = 1.3070e-01, time/batch = 16.7982s	
6649/33650 (epoch 9.880), train_loss = 1.24303202, grad/param norm = 1.5050e-01, time/batch = 18.4571s	
6650/33650 (epoch 9.881), train_loss = 1.13028873, grad/param norm = 1.3838e-01, time/batch = 17.1429s	
6651/33650 (epoch 9.883), train_loss = 1.21193310, grad/param norm = 1.5240e-01, time/batch = 17.2060s	
6652/33650 (epoch 9.884), train_loss = 1.31555935, grad/param norm = 1.6523e-01, time/batch = 17.8245s	
6653/33650 (epoch 9.886), train_loss = 1.33286002, grad/param norm = 1.5958e-01, time/batch = 18.6420s	
6654/33650 (epoch 9.887), train_loss = 1.13562999, grad/param norm = 1.4443e-01, time/batch = 16.4791s	
6655/33650 (epoch 9.889), train_loss = 1.30288554, grad/param norm = 1.6259e-01, time/batch = 18.0600s	
6656/33650 (epoch 9.890), train_loss = 1.30685634, grad/param norm = 1.4994e-01, time/batch = 17.1381s	
6657/33650 (epoch 9.892), train_loss = 1.26817795, grad/param norm = 1.5962e-01, time/batch = 16.8633s	
6658/33650 (epoch 9.893), train_loss = 1.28655382, grad/param norm = 1.5702e-01, time/batch = 17.3024s	
6659/33650 (epoch 9.895), train_loss = 1.36484360, grad/param norm = 1.6461e-01, time/batch = 18.2973s	
6660/33650 (epoch 9.896), train_loss = 1.12038132, grad/param norm = 1.5110e-01, time/batch = 18.3891s	
6661/33650 (epoch 9.897), train_loss = 1.10613210, grad/param norm = 1.4488e-01, time/batch = 16.9621s	
6662/33650 (epoch 9.899), train_loss = 1.07879275, grad/param norm = 1.3592e-01, time/batch = 17.2106s	
6663/33650 (epoch 9.900), train_loss = 1.00151304, grad/param norm = 1.3272e-01, time/batch = 18.3048s	
6664/33650 (epoch 9.902), train_loss = 1.23380972, grad/param norm = 1.5697e-01, time/batch = 17.5430s	
6665/33650 (epoch 9.903), train_loss = 1.21289922, grad/param norm = 1.6479e-01, time/batch = 16.5413s	
6666/33650 (epoch 9.905), train_loss = 1.45357372, grad/param norm = 1.8156e-01, time/batch = 18.4776s	
6667/33650 (epoch 9.906), train_loss = 1.18238595, grad/param norm = 1.5699e-01, time/batch = 17.6398s	
6668/33650 (epoch 9.908), train_loss = 1.15627506, grad/param norm = 1.3415e-01, time/batch = 17.9704s	
6669/33650 (epoch 9.909), train_loss = 1.17112908, grad/param norm = 1.3770e-01, time/batch = 18.3917s	
6670/33650 (epoch 9.911), train_loss = 1.04020035, grad/param norm = 1.3868e-01, time/batch = 17.6326s	
6671/33650 (epoch 9.912), train_loss = 1.04486543, grad/param norm = 1.3979e-01, time/batch = 17.4766s	
6672/33650 (epoch 9.914), train_loss = 1.20386694, grad/param norm = 1.3990e-01, time/batch = 18.0603s	
6673/33650 (epoch 9.915), train_loss = 1.27528695, grad/param norm = 1.7500e-01, time/batch = 17.6482s	
6674/33650 (epoch 9.917), train_loss = 1.20241362, grad/param norm = 1.6064e-01, time/batch = 16.7329s	
6675/33650 (epoch 9.918), train_loss = 0.96584499, grad/param norm = 1.2434e-01, time/batch = 17.5711s	
6676/33650 (epoch 9.920), train_loss = 1.11948886, grad/param norm = 1.3024e-01, time/batch = 16.4812s	
6677/33650 (epoch 9.921), train_loss = 1.10118908, grad/param norm = 1.4131e-01, time/batch = 18.4758s	
6678/33650 (epoch 9.923), train_loss = 1.08424176, grad/param norm = 1.4522e-01, time/batch = 17.5468s	
6679/33650 (epoch 9.924), train_loss = 1.25620570, grad/param norm = 1.8231e-01, time/batch = 17.8167s	
6680/33650 (epoch 9.926), train_loss = 1.21177341, grad/param norm = 1.6166e-01, time/batch = 17.8991s	
6681/33650 (epoch 9.927), train_loss = 1.15795404, grad/param norm = 1.6399e-01, time/batch = 17.3161s	
6682/33650 (epoch 9.929), train_loss = 1.23152902, grad/param norm = 1.5368e-01, time/batch = 17.7281s	
6683/33650 (epoch 9.930), train_loss = 1.15965722, grad/param norm = 1.3900e-01, time/batch = 17.9676s	
6684/33650 (epoch 9.932), train_loss = 1.20303848, grad/param norm = 1.4906e-01, time/batch = 17.2858s	
6685/33650 (epoch 9.933), train_loss = 1.06258823, grad/param norm = 1.3813e-01, time/batch = 17.3160s	
6686/33650 (epoch 9.935), train_loss = 1.10720233, grad/param norm = 1.4803e-01, time/batch = 17.8951s	
6687/33650 (epoch 9.936), train_loss = 1.08695800, grad/param norm = 1.3102e-01, time/batch = 17.8949s	
6688/33650 (epoch 9.938), train_loss = 1.02741803, grad/param norm = 1.3603e-01, time/batch = 16.9796s	
6689/33650 (epoch 9.939), train_loss = 1.25610288, grad/param norm = 1.5149e-01, time/batch = 17.3867s	
6690/33650 (epoch 9.941), train_loss = 1.23079859, grad/param norm = 1.5753e-01, time/batch = 17.8859s	
6691/33650 (epoch 9.942), train_loss = 1.28266660, grad/param norm = 1.6042e-01, time/batch = 17.0628s	
6692/33650 (epoch 9.944), train_loss = 1.22672017, grad/param norm = 1.3555e-01, time/batch = 17.6422s	
6693/33650 (epoch 9.945), train_loss = 1.28691870, grad/param norm = 1.6156e-01, time/batch = 18.7363s	
6694/33650 (epoch 9.947), train_loss = 1.43923752, grad/param norm = 1.7742e-01, time/batch = 18.2326s	
6695/33650 (epoch 9.948), train_loss = 1.31925096, grad/param norm = 1.4403e-01, time/batch = 16.6939s	
6696/33650 (epoch 9.949), train_loss = 1.11176930, grad/param norm = 1.5050e-01, time/batch = 18.5641s	
6697/33650 (epoch 9.951), train_loss = 1.36042761, grad/param norm = 1.5338e-01, time/batch = 18.5730s	
6698/33650 (epoch 9.952), train_loss = 1.33340356, grad/param norm = 1.6757e-01, time/batch = 16.3980s	
6699/33650 (epoch 9.954), train_loss = 1.28554046, grad/param norm = 1.5795e-01, time/batch = 17.4829s	
6700/33650 (epoch 9.955), train_loss = 1.29555423, grad/param norm = 1.5826e-01, time/batch = 18.1495s	
6701/33650 (epoch 9.957), train_loss = 1.28753485, grad/param norm = 1.5251e-01, time/batch = 15.4629s	
6702/33650 (epoch 9.958), train_loss = 0.92990379, grad/param norm = 1.2220e-01, time/batch = 17.4733s	
6703/33650 (epoch 9.960), train_loss = 1.03856741, grad/param norm = 1.3186e-01, time/batch = 17.7275s	
6704/33650 (epoch 9.961), train_loss = 1.11267474, grad/param norm = 1.4237e-01, time/batch = 18.7218s	
6705/33650 (epoch 9.963), train_loss = 1.16201023, grad/param norm = 1.5948e-01, time/batch = 17.1471s	
6706/33650 (epoch 9.964), train_loss = 1.21892263, grad/param norm = 1.6124e-01, time/batch = 16.9769s	
6707/33650 (epoch 9.966), train_loss = 1.21619534, grad/param norm = 1.4841e-01, time/batch = 15.3761s	
6708/33650 (epoch 9.967), train_loss = 1.27651579, grad/param norm = 1.4195e-01, time/batch = 16.1191s	
6709/33650 (epoch 9.969), train_loss = 1.16754227, grad/param norm = 1.3861e-01, time/batch = 16.8952s	
6710/33650 (epoch 9.970), train_loss = 1.26731157, grad/param norm = 1.5125e-01, time/batch = 14.8753s	
6711/33650 (epoch 9.972), train_loss = 1.52760350, grad/param norm = 1.7394e-01, time/batch = 18.0622s	
6712/33650 (epoch 9.973), train_loss = 1.08372102, grad/param norm = 1.2928e-01, time/batch = 16.8841s	
6713/33650 (epoch 9.975), train_loss = 1.08542509, grad/param norm = 1.3817e-01, time/batch = 18.3913s	
6714/33650 (epoch 9.976), train_loss = 1.05944971, grad/param norm = 1.3048e-01, time/batch = 17.7340s	
6715/33650 (epoch 9.978), train_loss = 1.12809960, grad/param norm = 1.5509e-01, time/batch = 17.9749s	
6716/33650 (epoch 9.979), train_loss = 1.21626506, grad/param norm = 1.5114e-01, time/batch = 16.9808s	
6717/33650 (epoch 9.981), train_loss = 1.12582288, grad/param norm = 1.2909e-01, time/batch = 16.4528s	
6718/33650 (epoch 9.982), train_loss = 1.23571937, grad/param norm = 1.5108e-01, time/batch = 18.0602s	
6719/33650 (epoch 9.984), train_loss = 1.07259411, grad/param norm = 1.3441e-01, time/batch = 17.3869s	
6720/33650 (epoch 9.985), train_loss = 1.05839094, grad/param norm = 1.3271e-01, time/batch = 18.6510s	
6721/33650 (epoch 9.987), train_loss = 1.15875508, grad/param norm = 1.3878e-01, time/batch = 16.7110s	
6722/33650 (epoch 9.988), train_loss = 1.25858809, grad/param norm = 1.4754e-01, time/batch = 17.1432s	
6723/33650 (epoch 9.990), train_loss = 1.43401526, grad/param norm = 1.8033e-01, time/batch = 18.5595s	
6724/33650 (epoch 9.991), train_loss = 1.27200886, grad/param norm = 1.4609e-01, time/batch = 16.2301s	
6725/33650 (epoch 9.993), train_loss = 1.25376084, grad/param norm = 1.5730e-01, time/batch = 17.2178s	
6726/33650 (epoch 9.994), train_loss = 1.15968165, grad/param norm = 1.4402e-01, time/batch = 17.0571s	
6727/33650 (epoch 9.996), train_loss = 1.12748856, grad/param norm = 1.4539e-01, time/batch = 17.1543s	
6728/33650 (epoch 9.997), train_loss = 1.25557198, grad/param norm = 1.5861e-01, time/batch = 18.6524s	
6729/33650 (epoch 9.999), train_loss = 1.04763856, grad/param norm = 1.3949e-01, time/batch = 16.1103s	
decayed learning rate by a factor 0.97 to 0.00194	
6730/33650 (epoch 10.000), train_loss = 1.27304090, grad/param norm = 1.6101e-01, time/batch = 18.1348s	
6731/33650 (epoch 10.001), train_loss = 1.38397036, grad/param norm = 1.6639e-01, time/batch = 17.8174s	
6732/33650 (epoch 10.003), train_loss = 1.40072650, grad/param norm = 1.7304e-01, time/batch = 16.9584s	
6733/33650 (epoch 10.004), train_loss = 1.28778506, grad/param norm = 1.5958e-01, time/batch = 17.2153s	
6734/33650 (epoch 10.006), train_loss = 1.14997067, grad/param norm = 1.4236e-01, time/batch = 16.0567s	
6735/33650 (epoch 10.007), train_loss = 1.22374636, grad/param norm = 1.5167e-01, time/batch = 17.0586s	
6736/33650 (epoch 10.009), train_loss = 1.15332689, grad/param norm = 1.3150e-01, time/batch = 16.3846s	
6737/33650 (epoch 10.010), train_loss = 1.28510049, grad/param norm = 1.5855e-01, time/batch = 14.6272s	
6738/33650 (epoch 10.012), train_loss = 1.14075181, grad/param norm = 1.6101e-01, time/batch = 14.5635s	
6739/33650 (epoch 10.013), train_loss = 1.26232752, grad/param norm = 1.6814e-01, time/batch = 14.8936s	
6740/33650 (epoch 10.015), train_loss = 1.09429404, grad/param norm = 1.3602e-01, time/batch = 14.8687s	
6741/33650 (epoch 10.016), train_loss = 1.09484412, grad/param norm = 1.4772e-01, time/batch = 16.0432s	
6742/33650 (epoch 10.018), train_loss = 1.20326765, grad/param norm = 1.5607e-01, time/batch = 17.0498s	
6743/33650 (epoch 10.019), train_loss = 1.09880902, grad/param norm = 1.3134e-01, time/batch = 17.8987s	
6744/33650 (epoch 10.021), train_loss = 1.31482790, grad/param norm = 1.5113e-01, time/batch = 17.9691s	
6745/33650 (epoch 10.022), train_loss = 1.13928186, grad/param norm = 1.3824e-01, time/batch = 17.8190s	
6746/33650 (epoch 10.024), train_loss = 1.06660945, grad/param norm = 1.3909e-01, time/batch = 18.0736s	
6747/33650 (epoch 10.025), train_loss = 1.13039415, grad/param norm = 1.4170e-01, time/batch = 17.1353s	
6748/33650 (epoch 10.027), train_loss = 1.29029440, grad/param norm = 1.5447e-01, time/batch = 18.0619s	
6749/33650 (epoch 10.028), train_loss = 1.27489216, grad/param norm = 1.5268e-01, time/batch = 18.6531s	
6750/33650 (epoch 10.030), train_loss = 1.22517013, grad/param norm = 1.4808e-01, time/batch = 17.2225s	
6751/33650 (epoch 10.031), train_loss = 1.02669296, grad/param norm = 1.2384e-01, time/batch = 16.1427s	
6752/33650 (epoch 10.033), train_loss = 1.14250999, grad/param norm = 1.3080e-01, time/batch = 16.7280s	
6753/33650 (epoch 10.034), train_loss = 1.23823081, grad/param norm = 1.5466e-01, time/batch = 16.2886s	
6754/33650 (epoch 10.036), train_loss = 1.35000342, grad/param norm = 1.6379e-01, time/batch = 16.0473s	
6755/33650 (epoch 10.037), train_loss = 1.10786895, grad/param norm = 1.5888e-01, time/batch = 17.0594s	
6756/33650 (epoch 10.039), train_loss = 1.34938839, grad/param norm = 1.6175e-01, time/batch = 17.7343s	
6757/33650 (epoch 10.040), train_loss = 1.39591274, grad/param norm = 1.7255e-01, time/batch = 17.8066s	
6758/33650 (epoch 10.042), train_loss = 1.41365427, grad/param norm = 1.6604e-01, time/batch = 18.3084s	
6759/33650 (epoch 10.043), train_loss = 1.12035304, grad/param norm = 1.4213e-01, time/batch = 17.4758s	
6760/33650 (epoch 10.045), train_loss = 1.09848432, grad/param norm = 1.4478e-01, time/batch = 17.5711s	
6761/33650 (epoch 10.046), train_loss = 1.27858434, grad/param norm = 1.5208e-01, time/batch = 16.9725s	
6762/33650 (epoch 10.048), train_loss = 1.27715859, grad/param norm = 1.4365e-01, time/batch = 18.3062s	
6763/33650 (epoch 10.049), train_loss = 1.23462169, grad/param norm = 1.5110e-01, time/batch = 18.3064s	
6764/33650 (epoch 10.051), train_loss = 1.34035227, grad/param norm = 1.5952e-01, time/batch = 16.8020s	
6765/33650 (epoch 10.052), train_loss = 1.39378526, grad/param norm = 1.5752e-01, time/batch = 17.9834s	
6766/33650 (epoch 10.053), train_loss = 1.22473972, grad/param norm = 1.4287e-01, time/batch = 17.5466s	
6767/33650 (epoch 10.055), train_loss = 1.04477880, grad/param norm = 1.3699e-01, time/batch = 18.0500s	
6768/33650 (epoch 10.056), train_loss = 1.05655194, grad/param norm = 1.3845e-01, time/batch = 15.4646s	
6769/33650 (epoch 10.058), train_loss = 1.33791658, grad/param norm = 1.6922e-01, time/batch = 18.4832s	
6770/33650 (epoch 10.059), train_loss = 1.26707065, grad/param norm = 1.5679e-01, time/batch = 17.5672s	
6771/33650 (epoch 10.061), train_loss = 1.29371869, grad/param norm = 1.4450e-01, time/batch = 17.0460s	
6772/33650 (epoch 10.062), train_loss = 1.25217180, grad/param norm = 1.3827e-01, time/batch = 17.1187s	
6773/33650 (epoch 10.064), train_loss = 1.14605733, grad/param norm = 1.3570e-01, time/batch = 17.6376s	
6774/33650 (epoch 10.065), train_loss = 1.15319102, grad/param norm = 1.4706e-01, time/batch = 17.2328s	
6775/33650 (epoch 10.067), train_loss = 1.08420493, grad/param norm = 1.3776e-01, time/batch = 17.2096s	
6776/33650 (epoch 10.068), train_loss = 1.23057216, grad/param norm = 1.4195e-01, time/batch = 17.3154s	
6777/33650 (epoch 10.070), train_loss = 1.20999958, grad/param norm = 1.5031e-01, time/batch = 18.1447s	
6778/33650 (epoch 10.071), train_loss = 1.21852875, grad/param norm = 1.4872e-01, time/batch = 17.0472s	
6779/33650 (epoch 10.073), train_loss = 1.26745408, grad/param norm = 1.6532e-01, time/batch = 18.3021s	
6780/33650 (epoch 10.074), train_loss = 1.31934742, grad/param norm = 1.5605e-01, time/batch = 17.9000s	
6781/33650 (epoch 10.076), train_loss = 1.34922355, grad/param norm = 1.7403e-01, time/batch = 17.3957s	
6782/33650 (epoch 10.077), train_loss = 1.18386567, grad/param norm = 1.4158e-01, time/batch = 18.1375s	
6783/33650 (epoch 10.079), train_loss = 1.16342803, grad/param norm = 1.5324e-01, time/batch = 18.0532s	
6784/33650 (epoch 10.080), train_loss = 1.27029029, grad/param norm = 1.5274e-01, time/batch = 18.2293s	
6785/33650 (epoch 10.082), train_loss = 1.32508127, grad/param norm = 1.6176e-01, time/batch = 16.8063s	
6786/33650 (epoch 10.083), train_loss = 1.25848384, grad/param norm = 1.4871e-01, time/batch = 18.5566s	
6787/33650 (epoch 10.085), train_loss = 1.29281616, grad/param norm = 1.3754e-01, time/batch = 18.8099s	
6788/33650 (epoch 10.086), train_loss = 1.31568671, grad/param norm = 1.6123e-01, time/batch = 15.4741s	
6789/33650 (epoch 10.088), train_loss = 1.27329737, grad/param norm = 1.4759e-01, time/batch = 18.5665s	
6790/33650 (epoch 10.089), train_loss = 1.24379874, grad/param norm = 1.6144e-01, time/batch = 17.4924s	
6791/33650 (epoch 10.091), train_loss = 1.13803775, grad/param norm = 1.3546e-01, time/batch = 16.7142s	
6792/33650 (epoch 10.092), train_loss = 1.16470871, grad/param norm = 1.4807e-01, time/batch = 17.0665s	
6793/33650 (epoch 10.094), train_loss = 1.27319220, grad/param norm = 1.4128e-01, time/batch = 18.7348s	
6794/33650 (epoch 10.095), train_loss = 1.26292115, grad/param norm = 1.5729e-01, time/batch = 17.9799s	
6795/33650 (epoch 10.097), train_loss = 1.18706795, grad/param norm = 1.5242e-01, time/batch = 17.5616s	
6796/33650 (epoch 10.098), train_loss = 0.96400796, grad/param norm = 1.2586e-01, time/batch = 18.7212s	
6797/33650 (epoch 10.100), train_loss = 1.11139335, grad/param norm = 1.3196e-01, time/batch = 17.8898s	
6798/33650 (epoch 10.101), train_loss = 1.16373122, grad/param norm = 1.6467e-01, time/batch = 16.4759s	
6799/33650 (epoch 10.103), train_loss = 1.10370215, grad/param norm = 1.2885e-01, time/batch = 17.8136s	
6800/33650 (epoch 10.104), train_loss = 1.26490963, grad/param norm = 1.4602e-01, time/batch = 18.6441s	
6801/33650 (epoch 10.105), train_loss = 1.20343168, grad/param norm = 1.5953e-01, time/batch = 17.2190s	
6802/33650 (epoch 10.107), train_loss = 1.10881266, grad/param norm = 1.4911e-01, time/batch = 16.6397s	
6803/33650 (epoch 10.108), train_loss = 1.27367799, grad/param norm = 1.6093e-01, time/batch = 18.8173s	
6804/33650 (epoch 10.110), train_loss = 1.37916693, grad/param norm = 1.5476e-01, time/batch = 17.8937s	
6805/33650 (epoch 10.111), train_loss = 1.15398712, grad/param norm = 1.5252e-01, time/batch = 16.2351s	
6806/33650 (epoch 10.113), train_loss = 1.15198630, grad/param norm = 1.4953e-01, time/batch = 17.2032s	
6807/33650 (epoch 10.114), train_loss = 1.29177344, grad/param norm = 1.5699e-01, time/batch = 17.6408s	
6808/33650 (epoch 10.116), train_loss = 1.07571005, grad/param norm = 1.4128e-01, time/batch = 17.5505s	
6809/33650 (epoch 10.117), train_loss = 1.20721820, grad/param norm = 1.3334e-01, time/batch = 17.4666s	
6810/33650 (epoch 10.119), train_loss = 1.04859190, grad/param norm = 1.3336e-01, time/batch = 18.6496s	
6811/33650 (epoch 10.120), train_loss = 1.10795061, grad/param norm = 1.4598e-01, time/batch = 17.9717s	
6812/33650 (epoch 10.122), train_loss = 1.00745065, grad/param norm = 1.3665e-01, time/batch = 17.2098s	
6813/33650 (epoch 10.123), train_loss = 1.13825426, grad/param norm = 1.4001e-01, time/batch = 16.2250s	
6814/33650 (epoch 10.125), train_loss = 1.32505303, grad/param norm = 1.5322e-01, time/batch = 18.5613s	
6815/33650 (epoch 10.126), train_loss = 1.39490471, grad/param norm = 1.7017e-01, time/batch = 16.3070s	
6816/33650 (epoch 10.128), train_loss = 1.33731451, grad/param norm = 1.6087e-01, time/batch = 17.4431s	
6817/33650 (epoch 10.129), train_loss = 1.33091348, grad/param norm = 1.5661e-01, time/batch = 18.4757s	
6818/33650 (epoch 10.131), train_loss = 1.24485597, grad/param norm = 1.4928e-01, time/batch = 17.1504s	
6819/33650 (epoch 10.132), train_loss = 1.21882511, grad/param norm = 1.3965e-01, time/batch = 16.8834s	
6820/33650 (epoch 10.134), train_loss = 1.34681624, grad/param norm = 1.4830e-01, time/batch = 18.7345s	
6821/33650 (epoch 10.135), train_loss = 1.06671291, grad/param norm = 1.3583e-01, time/batch = 18.3017s	
6822/33650 (epoch 10.137), train_loss = 1.19782077, grad/param norm = 1.4307e-01, time/batch = 17.6329s	
6823/33650 (epoch 10.138), train_loss = 1.28357911, grad/param norm = 1.4014e-01, time/batch = 18.4823s	
6824/33650 (epoch 10.140), train_loss = 1.26255736, grad/param norm = 1.5841e-01, time/batch = 16.0658s	
6825/33650 (epoch 10.141), train_loss = 1.35546996, grad/param norm = 1.5397e-01, time/batch = 17.0513s	
6826/33650 (epoch 10.143), train_loss = 1.50154973, grad/param norm = 1.9026e-01, time/batch = 17.9885s	
6827/33650 (epoch 10.144), train_loss = 1.32751292, grad/param norm = 1.6115e-01, time/batch = 17.7420s	
6828/33650 (epoch 10.146), train_loss = 1.18889076, grad/param norm = 1.5258e-01, time/batch = 18.3963s	
6829/33650 (epoch 10.147), train_loss = 1.15144566, grad/param norm = 1.4631e-01, time/batch = 18.0574s	
6830/33650 (epoch 10.149), train_loss = 1.09612694, grad/param norm = 1.5773e-01, time/batch = 18.3231s	
6831/33650 (epoch 10.150), train_loss = 1.08098711, grad/param norm = 1.2996e-01, time/batch = 18.2254s	
6832/33650 (epoch 10.152), train_loss = 1.13349128, grad/param norm = 1.4026e-01, time/batch = 16.5546s	
6833/33650 (epoch 10.153), train_loss = 1.17757355, grad/param norm = 1.4561e-01, time/batch = 16.7804s	
6834/33650 (epoch 10.155), train_loss = 1.12455228, grad/param norm = 1.3666e-01, time/batch = 17.5470s	
6835/33650 (epoch 10.156), train_loss = 1.09257244, grad/param norm = 1.2776e-01, time/batch = 17.9656s	
6836/33650 (epoch 10.158), train_loss = 1.20986844, grad/param norm = 1.5025e-01, time/batch = 17.5613s	
6837/33650 (epoch 10.159), train_loss = 1.03941431, grad/param norm = 1.3305e-01, time/batch = 18.4856s	
6838/33650 (epoch 10.160), train_loss = 1.10186840, grad/param norm = 1.2751e-01, time/batch = 17.6572s	
6839/33650 (epoch 10.162), train_loss = 1.20889861, grad/param norm = 1.6740e-01, time/batch = 17.9696s	
6840/33650 (epoch 10.163), train_loss = 1.29826422, grad/param norm = 1.4998e-01, time/batch = 18.8842s	
6841/33650 (epoch 10.165), train_loss = 1.07386991, grad/param norm = 1.3593e-01, time/batch = 17.8030s	
6842/33650 (epoch 10.166), train_loss = 1.08336175, grad/param norm = 1.4741e-01, time/batch = 17.1322s	
6843/33650 (epoch 10.168), train_loss = 1.28521467, grad/param norm = 1.4549e-01, time/batch = 18.3035s	
6844/33650 (epoch 10.169), train_loss = 1.18504862, grad/param norm = 1.4651e-01, time/batch = 18.3156s	
6845/33650 (epoch 10.171), train_loss = 1.20515100, grad/param norm = 1.5421e-01, time/batch = 17.3891s	
6846/33650 (epoch 10.172), train_loss = 1.15935168, grad/param norm = 1.4909e-01, time/batch = 16.9720s	
6847/33650 (epoch 10.174), train_loss = 1.09317874, grad/param norm = 1.4769e-01, time/batch = 17.0443s	
6848/33650 (epoch 10.175), train_loss = 1.12183953, grad/param norm = 1.4693e-01, time/batch = 18.1522s	
6849/33650 (epoch 10.177), train_loss = 1.21871118, grad/param norm = 1.4906e-01, time/batch = 9.6649s	
6850/33650 (epoch 10.178), train_loss = 1.11332784, grad/param norm = 1.4692e-01, time/batch = 0.6647s	
6851/33650 (epoch 10.180), train_loss = 1.07164100, grad/param norm = 1.4590e-01, time/batch = 0.6449s	
6852/33650 (epoch 10.181), train_loss = 0.93088106, grad/param norm = 1.3525e-01, time/batch = 0.6405s	
6853/33650 (epoch 10.183), train_loss = 1.12949480, grad/param norm = 1.4597e-01, time/batch = 0.6427s	
6854/33650 (epoch 10.184), train_loss = 1.16389844, grad/param norm = 1.4646e-01, time/batch = 0.6416s	
6855/33650 (epoch 10.186), train_loss = 1.15335733, grad/param norm = 1.5749e-01, time/batch = 0.6435s	
6856/33650 (epoch 10.187), train_loss = 1.36613157, grad/param norm = 1.5978e-01, time/batch = 0.8176s	
6857/33650 (epoch 10.189), train_loss = 1.39741364, grad/param norm = 1.6884e-01, time/batch = 0.9508s	
6858/33650 (epoch 10.190), train_loss = 1.23536948, grad/param norm = 1.7794e-01, time/batch = 0.9446s	
6859/33650 (epoch 10.192), train_loss = 1.38767370, grad/param norm = 1.6267e-01, time/batch = 0.9348s	
6860/33650 (epoch 10.193), train_loss = 1.32995172, grad/param norm = 1.5191e-01, time/batch = 0.9464s	
6861/33650 (epoch 10.195), train_loss = 1.05223703, grad/param norm = 1.3270e-01, time/batch = 1.2267s	
6862/33650 (epoch 10.196), train_loss = 0.99215587, grad/param norm = 1.4369e-01, time/batch = 1.8219s	
6863/33650 (epoch 10.198), train_loss = 1.14951551, grad/param norm = 1.5534e-01, time/batch = 1.9171s	
6864/33650 (epoch 10.199), train_loss = 1.28398063, grad/param norm = 1.5915e-01, time/batch = 12.4740s	
6865/33650 (epoch 10.201), train_loss = 1.18529102, grad/param norm = 1.5077e-01, time/batch = 18.3150s	
6866/33650 (epoch 10.202), train_loss = 1.15235874, grad/param norm = 1.4389e-01, time/batch = 16.5615s	
6867/33650 (epoch 10.204), train_loss = 1.24510679, grad/param norm = 1.4355e-01, time/batch = 16.8931s	
6868/33650 (epoch 10.205), train_loss = 1.13693170, grad/param norm = 1.4380e-01, time/batch = 18.0576s	
6869/33650 (epoch 10.207), train_loss = 1.16984888, grad/param norm = 1.5269e-01, time/batch = 16.8722s	
6870/33650 (epoch 10.208), train_loss = 1.15840791, grad/param norm = 1.3892e-01, time/batch = 17.3810s	
6871/33650 (epoch 10.210), train_loss = 0.93105219, grad/param norm = 1.2001e-01, time/batch = 17.9638s	
6872/33650 (epoch 10.211), train_loss = 1.08377383, grad/param norm = 1.3982e-01, time/batch = 18.8100s	
6873/33650 (epoch 10.212), train_loss = 1.30456544, grad/param norm = 1.6462e-01, time/batch = 16.8970s	
6874/33650 (epoch 10.214), train_loss = 1.34969579, grad/param norm = 1.6212e-01, time/batch = 17.0399s	
6875/33650 (epoch 10.215), train_loss = 0.95298882, grad/param norm = 1.4044e-01, time/batch = 18.3160s	
6876/33650 (epoch 10.217), train_loss = 1.19279706, grad/param norm = 1.6024e-01, time/batch = 17.1292s	
6877/33650 (epoch 10.218), train_loss = 1.26853847, grad/param norm = 1.4740e-01, time/batch = 17.5642s	
6878/33650 (epoch 10.220), train_loss = 1.08329485, grad/param norm = 1.4515e-01, time/batch = 17.4051s	
6879/33650 (epoch 10.221), train_loss = 1.36187055, grad/param norm = 1.6364e-01, time/batch = 17.5581s	
6880/33650 (epoch 10.223), train_loss = 0.92165818, grad/param norm = 1.3503e-01, time/batch = 16.7087s	
6881/33650 (epoch 10.224), train_loss = 1.17747372, grad/param norm = 1.6843e-01, time/batch = 18.5600s	
6882/33650 (epoch 10.226), train_loss = 1.51054499, grad/param norm = 1.7591e-01, time/batch = 18.2349s	
6883/33650 (epoch 10.227), train_loss = 1.34908374, grad/param norm = 1.5435e-01, time/batch = 16.4557s	
6884/33650 (epoch 10.229), train_loss = 1.31531412, grad/param norm = 1.5510e-01, time/batch = 17.3973s	
6885/33650 (epoch 10.230), train_loss = 1.43687682, grad/param norm = 1.6859e-01, time/batch = 17.0551s	
6886/33650 (epoch 10.232), train_loss = 1.24725019, grad/param norm = 1.6206e-01, time/batch = 17.4577s	
6887/33650 (epoch 10.233), train_loss = 1.25986578, grad/param norm = 1.7291e-01, time/batch = 16.5532s	
6888/33650 (epoch 10.235), train_loss = 1.13968812, grad/param norm = 1.4039e-01, time/batch = 18.3151s	
6889/33650 (epoch 10.236), train_loss = 1.02455568, grad/param norm = 1.4022e-01, time/batch = 18.0656s	
6890/33650 (epoch 10.238), train_loss = 1.15560970, grad/param norm = 1.4683e-01, time/batch = 17.3076s	
6891/33650 (epoch 10.239), train_loss = 1.08408318, grad/param norm = 1.4432e-01, time/batch = 18.3076s	
6892/33650 (epoch 10.241), train_loss = 1.11530332, grad/param norm = 1.3281e-01, time/batch = 18.2372s	
6893/33650 (epoch 10.242), train_loss = 0.99026678, grad/param norm = 1.3363e-01, time/batch = 17.5609s	
6894/33650 (epoch 10.244), train_loss = 1.17717239, grad/param norm = 1.4151e-01, time/batch = 17.9848s	
6895/33650 (epoch 10.245), train_loss = 1.02642692, grad/param norm = 1.3830e-01, time/batch = 18.0672s	
6896/33650 (epoch 10.247), train_loss = 1.16323787, grad/param norm = 1.3850e-01, time/batch = 18.5581s	
6897/33650 (epoch 10.248), train_loss = 1.07942266, grad/param norm = 1.4385e-01, time/batch = 16.6333s	
6898/33650 (epoch 10.250), train_loss = 1.15949549, grad/param norm = 1.3775e-01, time/batch = 18.4804s	
6899/33650 (epoch 10.251), train_loss = 1.33552712, grad/param norm = 1.4986e-01, time/batch = 16.7253s	
6900/33650 (epoch 10.253), train_loss = 1.06873489, grad/param norm = 1.3669e-01, time/batch = 17.5440s	
6901/33650 (epoch 10.254), train_loss = 1.08030010, grad/param norm = 1.4307e-01, time/batch = 17.4757s	
6902/33650 (epoch 10.256), train_loss = 1.27940534, grad/param norm = 1.3712e-01, time/batch = 16.7081s	
6903/33650 (epoch 10.257), train_loss = 1.37075755, grad/param norm = 1.5582e-01, time/batch = 18.0624s	
6904/33650 (epoch 10.259), train_loss = 1.01043843, grad/param norm = 1.3458e-01, time/batch = 17.5645s	
6905/33650 (epoch 10.260), train_loss = 1.34761310, grad/param norm = 1.5460e-01, time/batch = 17.9837s	
6906/33650 (epoch 10.262), train_loss = 1.25864834, grad/param norm = 1.5923e-01, time/batch = 16.8102s	
6907/33650 (epoch 10.263), train_loss = 1.20714280, grad/param norm = 1.8557e-01, time/batch = 16.8117s	
6908/33650 (epoch 10.264), train_loss = 1.20230574, grad/param norm = 1.5443e-01, time/batch = 18.1560s	
6909/33650 (epoch 10.266), train_loss = 1.19054468, grad/param norm = 1.4567e-01, time/batch = 17.9052s	
6910/33650 (epoch 10.267), train_loss = 1.12917862, grad/param norm = 1.5919e-01, time/batch = 16.8227s	
6911/33650 (epoch 10.269), train_loss = 1.23549689, grad/param norm = 1.4782e-01, time/batch = 17.7253s	
6912/33650 (epoch 10.270), train_loss = 1.12583758, grad/param norm = 1.4329e-01, time/batch = 17.2326s	
6913/33650 (epoch 10.272), train_loss = 1.17596429, grad/param norm = 1.4664e-01, time/batch = 17.9976s	
6914/33650 (epoch 10.273), train_loss = 1.35317226, grad/param norm = 1.7633e-01, time/batch = 16.7265s	
6915/33650 (epoch 10.275), train_loss = 1.29145979, grad/param norm = 1.5518e-01, time/batch = 18.2671s	
6916/33650 (epoch 10.276), train_loss = 1.36483871, grad/param norm = 1.6167e-01, time/batch = 17.6546s	
6917/33650 (epoch 10.278), train_loss = 1.46800145, grad/param norm = 1.8083e-01, time/batch = 16.6331s	
6918/33650 (epoch 10.279), train_loss = 1.13188392, grad/param norm = 1.4848e-01, time/batch = 17.7199s	
6919/33650 (epoch 10.281), train_loss = 1.23398358, grad/param norm = 1.6184e-01, time/batch = 17.4099s	
6920/33650 (epoch 10.282), train_loss = 1.30699807, grad/param norm = 1.4068e-01, time/batch = 17.8961s	
6921/33650 (epoch 10.284), train_loss = 1.30434478, grad/param norm = 1.6045e-01, time/batch = 17.0486s	
6922/33650 (epoch 10.285), train_loss = 1.31482327, grad/param norm = 1.6165e-01, time/batch = 17.8808s	
6923/33650 (epoch 10.287), train_loss = 1.18849341, grad/param norm = 1.4429e-01, time/batch = 17.2336s	
6924/33650 (epoch 10.288), train_loss = 1.24590524, grad/param norm = 1.6252e-01, time/batch = 17.5584s	
6925/33650 (epoch 10.290), train_loss = 1.21743301, grad/param norm = 1.4146e-01, time/batch = 18.1454s	
6926/33650 (epoch 10.291), train_loss = 1.08664359, grad/param norm = 1.3283e-01, time/batch = 17.8109s	
6927/33650 (epoch 10.293), train_loss = 1.19238767, grad/param norm = 1.6033e-01, time/batch = 16.7205s	
6928/33650 (epoch 10.294), train_loss = 1.07307508, grad/param norm = 1.4339e-01, time/batch = 17.4759s	
6929/33650 (epoch 10.296), train_loss = 1.06732111, grad/param norm = 1.4523e-01, time/batch = 18.0617s	
6930/33650 (epoch 10.297), train_loss = 1.18344380, grad/param norm = 1.4909e-01, time/batch = 18.0669s	
6931/33650 (epoch 10.299), train_loss = 1.06244255, grad/param norm = 1.2847e-01, time/batch = 16.6495s	
6932/33650 (epoch 10.300), train_loss = 1.10984373, grad/param norm = 1.4804e-01, time/batch = 18.3975s	
6933/33650 (epoch 10.302), train_loss = 1.19808981, grad/param norm = 1.3531e-01, time/batch = 18.3949s	
6934/33650 (epoch 10.303), train_loss = 1.19348732, grad/param norm = 1.3333e-01, time/batch = 16.3157s	
6935/33650 (epoch 10.305), train_loss = 1.24595167, grad/param norm = 1.5038e-01, time/batch = 17.1483s	
6936/33650 (epoch 10.306), train_loss = 1.12707365, grad/param norm = 1.3786e-01, time/batch = 17.7318s	
6937/33650 (epoch 10.308), train_loss = 1.10879534, grad/param norm = 1.4663e-01, time/batch = 18.0536s	
6938/33650 (epoch 10.309), train_loss = 1.39090962, grad/param norm = 1.6525e-01, time/batch = 16.3535s	
6939/33650 (epoch 10.311), train_loss = 1.24796118, grad/param norm = 1.4508e-01, time/batch = 16.3150s	
6940/33650 (epoch 10.312), train_loss = 1.17341789, grad/param norm = 1.4831e-01, time/batch = 16.9003s	
6941/33650 (epoch 10.314), train_loss = 0.99890714, grad/param norm = 1.2254e-01, time/batch = 16.9753s	
6942/33650 (epoch 10.315), train_loss = 1.20876217, grad/param norm = 1.6260e-01, time/batch = 17.7368s	
6943/33650 (epoch 10.316), train_loss = 1.16333885, grad/param norm = 1.5330e-01, time/batch = 18.3105s	
6944/33650 (epoch 10.318), train_loss = 1.05539373, grad/param norm = 1.2403e-01, time/batch = 17.6406s	
6945/33650 (epoch 10.319), train_loss = 1.08338135, grad/param norm = 1.3575e-01, time/batch = 17.2270s	
6946/33650 (epoch 10.321), train_loss = 1.13167755, grad/param norm = 1.4251e-01, time/batch = 18.2340s	
6947/33650 (epoch 10.322), train_loss = 1.24554109, grad/param norm = 1.5447e-01, time/batch = 16.9764s	
6948/33650 (epoch 10.324), train_loss = 1.27524723, grad/param norm = 1.6862e-01, time/batch = 16.5610s	
6949/33650 (epoch 10.325), train_loss = 1.26408254, grad/param norm = 1.5016e-01, time/batch = 16.5489s	
6950/33650 (epoch 10.327), train_loss = 1.05839017, grad/param norm = 1.3487e-01, time/batch = 17.9855s	
6951/33650 (epoch 10.328), train_loss = 1.27036016, grad/param norm = 1.6365e-01, time/batch = 17.3123s	
6952/33650 (epoch 10.330), train_loss = 1.07375646, grad/param norm = 1.2499e-01, time/batch = 16.7358s	
6953/33650 (epoch 10.331), train_loss = 1.00014098, grad/param norm = 1.3294e-01, time/batch = 18.1470s	
6954/33650 (epoch 10.333), train_loss = 1.16556268, grad/param norm = 1.4638e-01, time/batch = 16.3842s	
6955/33650 (epoch 10.334), train_loss = 1.16946782, grad/param norm = 1.4218e-01, time/batch = 16.9681s	
6956/33650 (epoch 10.336), train_loss = 1.29365297, grad/param norm = 1.4957e-01, time/batch = 18.2357s	
6957/33650 (epoch 10.337), train_loss = 0.96198185, grad/param norm = 1.2592e-01, time/batch = 17.7258s	
6958/33650 (epoch 10.339), train_loss = 1.14579710, grad/param norm = 1.3664e-01, time/batch = 16.9769s	
6959/33650 (epoch 10.340), train_loss = 1.42306322, grad/param norm = 1.7349e-01, time/batch = 18.0590s	
6960/33650 (epoch 10.342), train_loss = 0.97220165, grad/param norm = 1.2547e-01, time/batch = 18.5610s	
6961/33650 (epoch 10.343), train_loss = 1.26320131, grad/param norm = 1.6316e-01, time/batch = 17.9024s	
6962/33650 (epoch 10.345), train_loss = 1.14726695, grad/param norm = 1.4859e-01, time/batch = 17.8782s	
6963/33650 (epoch 10.346), train_loss = 0.87256745, grad/param norm = 1.3310e-01, time/batch = 18.3214s	
6964/33650 (epoch 10.348), train_loss = 1.04464737, grad/param norm = 1.3933e-01, time/batch = 18.0725s	
6965/33650 (epoch 10.349), train_loss = 0.97707491, grad/param norm = 1.3531e-01, time/batch = 15.8953s	
6966/33650 (epoch 10.351), train_loss = 1.26876510, grad/param norm = 1.6330e-01, time/batch = 16.9479s	
6967/33650 (epoch 10.352), train_loss = 1.13357725, grad/param norm = 1.3942e-01, time/batch = 16.0576s	
6968/33650 (epoch 10.354), train_loss = 1.42163301, grad/param norm = 1.6591e-01, time/batch = 17.6516s	
6969/33650 (epoch 10.355), train_loss = 1.26904194, grad/param norm = 1.4150e-01, time/batch = 17.3079s	
6970/33650 (epoch 10.357), train_loss = 0.98927783, grad/param norm = 1.4522e-01, time/batch = 17.8933s	
6971/33650 (epoch 10.358), train_loss = 1.26982433, grad/param norm = 1.6132e-01, time/batch = 18.5561s	
6972/33650 (epoch 10.360), train_loss = 1.28273442, grad/param norm = 1.7214e-01, time/batch = 16.0437s	
6973/33650 (epoch 10.361), train_loss = 1.19937296, grad/param norm = 1.3351e-01, time/batch = 17.9677s	
6974/33650 (epoch 10.363), train_loss = 1.10619764, grad/param norm = 1.4113e-01, time/batch = 18.6461s	
6975/33650 (epoch 10.364), train_loss = 1.14446411, grad/param norm = 1.3578e-01, time/batch = 17.3971s	
6976/33650 (epoch 10.366), train_loss = 1.21372009, grad/param norm = 1.4826e-01, time/batch = 18.2255s	
6977/33650 (epoch 10.367), train_loss = 1.26738862, grad/param norm = 1.3508e-01, time/batch = 18.9805s	
6978/33650 (epoch 10.368), train_loss = 1.07580177, grad/param norm = 1.3907e-01, time/batch = 16.0467s	
6979/33650 (epoch 10.370), train_loss = 1.18282934, grad/param norm = 1.4394e-01, time/batch = 17.0543s	
6980/33650 (epoch 10.371), train_loss = 0.96513609, grad/param norm = 1.3374e-01, time/batch = 18.3935s	
6981/33650 (epoch 10.373), train_loss = 1.09264355, grad/param norm = 1.3803e-01, time/batch = 17.9813s	
6982/33650 (epoch 10.374), train_loss = 0.99236238, grad/param norm = 1.3047e-01, time/batch = 16.6307s	
6983/33650 (epoch 10.376), train_loss = 1.15807470, grad/param norm = 1.6127e-01, time/batch = 17.1482s	
6984/33650 (epoch 10.377), train_loss = 1.22293161, grad/param norm = 1.5437e-01, time/batch = 18.0605s	
6985/33650 (epoch 10.379), train_loss = 1.23865075, grad/param norm = 1.4340e-01, time/batch = 15.8726s	
6986/33650 (epoch 10.380), train_loss = 0.95692546, grad/param norm = 1.6256e-01, time/batch = 17.6293s	
6987/33650 (epoch 10.382), train_loss = 1.01539784, grad/param norm = 1.2016e-01, time/batch = 17.8023s	
6988/33650 (epoch 10.383), train_loss = 1.13602203, grad/param norm = 1.3745e-01, time/batch = 17.2168s	
6989/33650 (epoch 10.385), train_loss = 1.29824445, grad/param norm = 1.4729e-01, time/batch = 16.7059s	
6990/33650 (epoch 10.386), train_loss = 1.07911942, grad/param norm = 1.3761e-01, time/batch = 18.3087s	
6991/33650 (epoch 10.388), train_loss = 1.21280158, grad/param norm = 1.3871e-01, time/batch = 18.5559s	
6992/33650 (epoch 10.389), train_loss = 1.18176928, grad/param norm = 1.4976e-01, time/batch = 17.3015s	
6993/33650 (epoch 10.391), train_loss = 0.97346055, grad/param norm = 1.3323e-01, time/batch = 17.3131s	
6994/33650 (epoch 10.392), train_loss = 1.26140482, grad/param norm = 1.4621e-01, time/batch = 17.7235s	
6995/33650 (epoch 10.394), train_loss = 1.30331508, grad/param norm = 1.6815e-01, time/batch = 17.9852s	
6996/33650 (epoch 10.395), train_loss = 1.19337576, grad/param norm = 1.5296e-01, time/batch = 16.9696s	
6997/33650 (epoch 10.397), train_loss = 1.37157779, grad/param norm = 1.6257e-01, time/batch = 16.7255s	
6998/33650 (epoch 10.398), train_loss = 1.18883020, grad/param norm = 1.3557e-01, time/batch = 17.8882s	
6999/33650 (epoch 10.400), train_loss = 1.18760114, grad/param norm = 1.6767e-01, time/batch = 16.2903s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch10.40_1.5355.t7	
7000/33650 (epoch 10.401), train_loss = 1.19075758, grad/param norm = 1.5958e-01, time/batch = 17.8156s	
7001/33650 (epoch 10.403), train_loss = 1.42593432, grad/param norm = 1.6861e-01, time/batch = 18.1461s	
7002/33650 (epoch 10.404), train_loss = 1.14382805, grad/param norm = 1.2411e-01, time/batch = 17.7415s	
7003/33650 (epoch 10.406), train_loss = 1.22511097, grad/param norm = 1.4274e-01, time/batch = 18.1369s	
7004/33650 (epoch 10.407), train_loss = 1.19534859, grad/param norm = 1.5040e-01, time/batch = 17.4719s	
7005/33650 (epoch 10.409), train_loss = 1.18998554, grad/param norm = 1.4363e-01, time/batch = 17.6326s	
7006/33650 (epoch 10.410), train_loss = 1.20021044, grad/param norm = 1.6321e-01, time/batch = 18.7263s	
7007/33650 (epoch 10.412), train_loss = 1.18415513, grad/param norm = 1.3331e-01, time/batch = 18.7292s	
7008/33650 (epoch 10.413), train_loss = 1.08477468, grad/param norm = 1.3808e-01, time/batch = 16.7969s	
7009/33650 (epoch 10.415), train_loss = 1.24640343, grad/param norm = 1.4656e-01, time/batch = 18.1501s	
7010/33650 (epoch 10.416), train_loss = 1.36008904, grad/param norm = 1.5147e-01, time/batch = 18.8954s	
7011/33650 (epoch 10.418), train_loss = 1.19717506, grad/param norm = 1.5173e-01, time/batch = 16.2099s	
7012/33650 (epoch 10.419), train_loss = 1.12026481, grad/param norm = 1.4249e-01, time/batch = 17.1340s	
7013/33650 (epoch 10.421), train_loss = 1.09986715, grad/param norm = 1.2799e-01, time/batch = 16.7657s	
7014/33650 (epoch 10.422), train_loss = 1.29016987, grad/param norm = 1.4407e-01, time/batch = 18.7290s	
7015/33650 (epoch 10.423), train_loss = 1.04026954, grad/param norm = 1.3131e-01, time/batch = 16.3849s	
7016/33650 (epoch 10.425), train_loss = 1.21460015, grad/param norm = 1.6186e-01, time/batch = 17.8100s	
7017/33650 (epoch 10.426), train_loss = 1.32623368, grad/param norm = 1.5628e-01, time/batch = 18.7293s	
7018/33650 (epoch 10.428), train_loss = 1.12826376, grad/param norm = 1.4596e-01, time/batch = 16.6215s	
7019/33650 (epoch 10.429), train_loss = 1.27456752, grad/param norm = 1.5398e-01, time/batch = 17.3986s	
7020/33650 (epoch 10.431), train_loss = 1.40298793, grad/param norm = 1.6861e-01, time/batch = 16.5077s	
7021/33650 (epoch 10.432), train_loss = 1.48486403, grad/param norm = 1.6743e-01, time/batch = 16.4674s	
7022/33650 (epoch 10.434), train_loss = 1.26595246, grad/param norm = 1.4205e-01, time/batch = 17.3699s	
7023/33650 (epoch 10.435), train_loss = 1.23648613, grad/param norm = 1.5628e-01, time/batch = 17.6318s	
7024/33650 (epoch 10.437), train_loss = 1.24188470, grad/param norm = 1.5490e-01, time/batch = 18.3177s	
7025/33650 (epoch 10.438), train_loss = 1.12282704, grad/param norm = 1.5305e-01, time/batch = 16.9727s	
7026/33650 (epoch 10.440), train_loss = 1.22470061, grad/param norm = 1.5375e-01, time/batch = 18.1461s	
7027/33650 (epoch 10.441), train_loss = 1.25110143, grad/param norm = 1.5846e-01, time/batch = 18.0707s	
7028/33650 (epoch 10.443), train_loss = 1.23490648, grad/param norm = 1.4942e-01, time/batch = 17.4761s	
7029/33650 (epoch 10.444), train_loss = 1.13045985, grad/param norm = 1.3323e-01, time/batch = 16.7914s	
7030/33650 (epoch 10.446), train_loss = 1.24910302, grad/param norm = 1.6011e-01, time/batch = 18.6491s	
7031/33650 (epoch 10.447), train_loss = 1.30721189, grad/param norm = 1.7460e-01, time/batch = 18.3068s	
7032/33650 (epoch 10.449), train_loss = 1.41526004, grad/param norm = 1.8794e-01, time/batch = 16.4538s	
7033/33650 (epoch 10.450), train_loss = 1.43132049, grad/param norm = 1.7164e-01, time/batch = 17.4052s	
7034/33650 (epoch 10.452), train_loss = 1.49501003, grad/param norm = 1.6781e-01, time/batch = 18.4047s	
7035/33650 (epoch 10.453), train_loss = 1.38152266, grad/param norm = 1.6217e-01, time/batch = 16.7349s	
7036/33650 (epoch 10.455), train_loss = 1.18314021, grad/param norm = 1.4426e-01, time/batch = 18.0623s	
7037/33650 (epoch 10.456), train_loss = 1.17785921, grad/param norm = 1.3257e-01, time/batch = 17.9012s	
7038/33650 (epoch 10.458), train_loss = 1.17554582, grad/param norm = 1.5257e-01, time/batch = 16.7306s	
7039/33650 (epoch 10.459), train_loss = 1.20117309, grad/param norm = 1.5911e-01, time/batch = 17.2872s	
7040/33650 (epoch 10.461), train_loss = 1.39143902, grad/param norm = 1.6077e-01, time/batch = 18.4845s	
7041/33650 (epoch 10.462), train_loss = 1.33954275, grad/param norm = 1.6232e-01, time/batch = 18.6461s	
7042/33650 (epoch 10.464), train_loss = 1.12883591, grad/param norm = 1.4863e-01, time/batch = 16.1906s	
7043/33650 (epoch 10.465), train_loss = 1.25144695, grad/param norm = 1.6212e-01, time/batch = 18.2220s	
7044/33650 (epoch 10.467), train_loss = 1.29042262, grad/param norm = 1.6172e-01, time/batch = 18.1479s	
7045/33650 (epoch 10.468), train_loss = 1.34235547, grad/param norm = 1.5286e-01, time/batch = 17.3905s	
7046/33650 (epoch 10.470), train_loss = 1.47764650, grad/param norm = 1.7907e-01, time/batch = 17.3936s	
7047/33650 (epoch 10.471), train_loss = 1.22080732, grad/param norm = 1.5513e-01, time/batch = 18.4776s	
7048/33650 (epoch 10.473), train_loss = 1.16490635, grad/param norm = 1.3842e-01, time/batch = 17.7346s	
7049/33650 (epoch 10.474), train_loss = 1.26782478, grad/param norm = 1.5129e-01, time/batch = 15.5513s	
7050/33650 (epoch 10.475), train_loss = 1.29911526, grad/param norm = 1.5988e-01, time/batch = 16.9828s	
7051/33650 (epoch 10.477), train_loss = 1.31420125, grad/param norm = 1.4640e-01, time/batch = 18.8087s	
7052/33650 (epoch 10.478), train_loss = 1.33839006, grad/param norm = 1.6496e-01, time/batch = 17.5590s	
7053/33650 (epoch 10.480), train_loss = 1.34791967, grad/param norm = 1.6480e-01, time/batch = 17.3931s	
7054/33650 (epoch 10.481), train_loss = 1.35169292, grad/param norm = 1.6026e-01, time/batch = 18.3867s	
7055/33650 (epoch 10.483), train_loss = 0.99288094, grad/param norm = 1.5066e-01, time/batch = 16.3865s	
7056/33650 (epoch 10.484), train_loss = 1.23303479, grad/param norm = 1.4534e-01, time/batch = 17.7896s	
7057/33650 (epoch 10.486), train_loss = 1.35814087, grad/param norm = 1.7565e-01, time/batch = 17.8167s	
7058/33650 (epoch 10.487), train_loss = 1.35418539, grad/param norm = 1.7657e-01, time/batch = 18.0663s	
7059/33650 (epoch 10.489), train_loss = 1.41808376, grad/param norm = 1.5836e-01, time/batch = 28.4940s	
7060/33650 (epoch 10.490), train_loss = 1.11770472, grad/param norm = 1.4417e-01, time/batch = 21.0298s	
7061/33650 (epoch 10.492), train_loss = 1.28827708, grad/param norm = 1.7411e-01, time/batch = 17.4545s	
7062/33650 (epoch 10.493), train_loss = 1.00337664, grad/param norm = 1.2979e-01, time/batch = 16.1953s	
7063/33650 (epoch 10.495), train_loss = 1.21467873, grad/param norm = 1.4634e-01, time/batch = 18.3080s	
7064/33650 (epoch 10.496), train_loss = 1.28603646, grad/param norm = 1.6636e-01, time/batch = 17.9938s	
7065/33650 (epoch 10.498), train_loss = 1.06844234, grad/param norm = 1.3607e-01, time/batch = 16.9597s	
7066/33650 (epoch 10.499), train_loss = 1.19513313, grad/param norm = 1.3787e-01, time/batch = 17.8131s	
7067/33650 (epoch 10.501), train_loss = 1.15134567, grad/param norm = 1.3910e-01, time/batch = 17.2242s	
7068/33650 (epoch 10.502), train_loss = 1.25883154, grad/param norm = 1.5720e-01, time/batch = 17.3099s	
7069/33650 (epoch 10.504), train_loss = 1.35433222, grad/param norm = 1.7222e-01, time/batch = 17.9713s	
7070/33650 (epoch 10.505), train_loss = 1.22570967, grad/param norm = 1.7334e-01, time/batch = 16.6289s	
7071/33650 (epoch 10.507), train_loss = 1.38399386, grad/param norm = 1.6295e-01, time/batch = 18.3145s	
7072/33650 (epoch 10.508), train_loss = 1.14439178, grad/param norm = 1.4044e-01, time/batch = 17.0398s	
7073/33650 (epoch 10.510), train_loss = 1.20270788, grad/param norm = 1.4569e-01, time/batch = 18.2332s	
7074/33650 (epoch 10.511), train_loss = 1.47738833, grad/param norm = 1.7745e-01, time/batch = 17.6530s	
7075/33650 (epoch 10.513), train_loss = 1.28554520, grad/param norm = 1.4739e-01, time/batch = 16.7149s	
7076/33650 (epoch 10.514), train_loss = 1.33884780, grad/param norm = 1.6918e-01, time/batch = 18.3106s	
7077/33650 (epoch 10.516), train_loss = 1.24031901, grad/param norm = 1.7461e-01, time/batch = 18.0631s	
7078/33650 (epoch 10.517), train_loss = 1.22448205, grad/param norm = 1.6566e-01, time/batch = 17.7290s	
7079/33650 (epoch 10.519), train_loss = 1.23627147, grad/param norm = 1.4095e-01, time/batch = 16.3075s	
7080/33650 (epoch 10.520), train_loss = 1.03841650, grad/param norm = 1.3259e-01, time/batch = 18.8107s	
7081/33650 (epoch 10.522), train_loss = 1.24637781, grad/param norm = 1.6308e-01, time/batch = 17.8090s	
7082/33650 (epoch 10.523), train_loss = 1.20500660, grad/param norm = 1.4174e-01, time/batch = 16.5291s	
7083/33650 (epoch 10.525), train_loss = 0.94768252, grad/param norm = 1.2657e-01, time/batch = 16.3030s	
7084/33650 (epoch 10.526), train_loss = 1.28173560, grad/param norm = 1.4226e-01, time/batch = 17.8107s	
7085/33650 (epoch 10.527), train_loss = 1.10209339, grad/param norm = 1.4006e-01, time/batch = 17.9798s	
7086/33650 (epoch 10.529), train_loss = 1.19826099, grad/param norm = 1.4710e-01, time/batch = 17.1501s	
7087/33650 (epoch 10.530), train_loss = 1.15002393, grad/param norm = 1.4769e-01, time/batch = 17.9066s	
7088/33650 (epoch 10.532), train_loss = 1.42817705, grad/param norm = 1.7971e-01, time/batch = 18.2187s	
7089/33650 (epoch 10.533), train_loss = 1.17117531, grad/param norm = 1.4575e-01, time/batch = 16.9760s	
7090/33650 (epoch 10.535), train_loss = 1.32790392, grad/param norm = 1.5798e-01, time/batch = 18.5615s	
7091/33650 (epoch 10.536), train_loss = 1.25606888, grad/param norm = 1.6312e-01, time/batch = 17.9909s	
7092/33650 (epoch 10.538), train_loss = 1.26723048, grad/param norm = 1.6593e-01, time/batch = 15.3996s	
7093/33650 (epoch 10.539), train_loss = 1.01181082, grad/param norm = 1.3330e-01, time/batch = 15.8044s	
7094/33650 (epoch 10.541), train_loss = 1.36486929, grad/param norm = 1.6365e-01, time/batch = 17.8141s	
7095/33650 (epoch 10.542), train_loss = 1.26048467, grad/param norm = 1.6368e-01, time/batch = 18.3991s	
7096/33650 (epoch 10.544), train_loss = 1.44971439, grad/param norm = 1.6162e-01, time/batch = 17.3848s	
7097/33650 (epoch 10.545), train_loss = 1.07090815, grad/param norm = 1.3720e-01, time/batch = 18.2325s	
7098/33650 (epoch 10.547), train_loss = 1.23468549, grad/param norm = 1.4503e-01, time/batch = 16.8038s	
7099/33650 (epoch 10.548), train_loss = 1.37870315, grad/param norm = 1.5173e-01, time/batch = 17.4814s	
7100/33650 (epoch 10.550), train_loss = 1.18729187, grad/param norm = 1.4415e-01, time/batch = 17.8002s	
7101/33650 (epoch 10.551), train_loss = 1.20721806, grad/param norm = 1.5860e-01, time/batch = 18.4013s	
7102/33650 (epoch 10.553), train_loss = 1.04987849, grad/param norm = 1.4749e-01, time/batch = 18.3172s	
7103/33650 (epoch 10.554), train_loss = 1.35072607, grad/param norm = 1.5433e-01, time/batch = 18.4710s	
7104/33650 (epoch 10.556), train_loss = 1.32817554, grad/param norm = 1.7001e-01, time/batch = 17.4030s	
7105/33650 (epoch 10.557), train_loss = 1.38335240, grad/param norm = 1.7006e-01, time/batch = 17.4872s	
7106/33650 (epoch 10.559), train_loss = 1.50651873, grad/param norm = 1.8835e-01, time/batch = 16.8025s	
7107/33650 (epoch 10.560), train_loss = 1.43752815, grad/param norm = 1.6198e-01, time/batch = 17.7352s	
7108/33650 (epoch 10.562), train_loss = 1.29818608, grad/param norm = 1.4327e-01, time/batch = 18.6455s	
7109/33650 (epoch 10.563), train_loss = 1.20924031, grad/param norm = 1.5816e-01, time/batch = 17.4635s	
7110/33650 (epoch 10.565), train_loss = 1.24229899, grad/param norm = 1.5078e-01, time/batch = 17.7839s	
7111/33650 (epoch 10.566), train_loss = 1.24020705, grad/param norm = 1.5138e-01, time/batch = 18.2322s	
7112/33650 (epoch 10.568), train_loss = 1.23500815, grad/param norm = 1.4630e-01, time/batch = 17.6534s	
7113/33650 (epoch 10.569), train_loss = 1.17370109, grad/param norm = 1.4578e-01, time/batch = 16.7992s	
7114/33650 (epoch 10.571), train_loss = 1.36444396, grad/param norm = 1.5848e-01, time/batch = 18.3102s	
7115/33650 (epoch 10.572), train_loss = 1.27136197, grad/param norm = 1.3872e-01, time/batch = 14.0314s	
7116/33650 (epoch 10.574), train_loss = 1.23848648, grad/param norm = 1.6351e-01, time/batch = 17.1221s	
7117/33650 (epoch 10.575), train_loss = 1.19353797, grad/param norm = 1.4121e-01, time/batch = 17.6391s	
7118/33650 (epoch 10.577), train_loss = 1.25688761, grad/param norm = 1.6138e-01, time/batch = 18.1460s	
7119/33650 (epoch 10.578), train_loss = 1.27339174, grad/param norm = 1.4875e-01, time/batch = 17.1170s	
7120/33650 (epoch 10.579), train_loss = 1.29074491, grad/param norm = 1.5181e-01, time/batch = 17.2278s	
7121/33650 (epoch 10.581), train_loss = 1.30566636, grad/param norm = 1.4670e-01, time/batch = 18.2199s	
7122/33650 (epoch 10.582), train_loss = 1.32510280, grad/param norm = 1.4420e-01, time/batch = 18.2254s	
7123/33650 (epoch 10.584), train_loss = 1.25317781, grad/param norm = 1.4665e-01, time/batch = 17.2154s	
7124/33650 (epoch 10.585), train_loss = 1.28190814, grad/param norm = 1.6623e-01, time/batch = 17.7254s	
7125/33650 (epoch 10.587), train_loss = 1.13318783, grad/param norm = 1.5631e-01, time/batch = 18.8081s	
7126/33650 (epoch 10.588), train_loss = 1.20251311, grad/param norm = 1.6768e-01, time/batch = 17.0371s	
7127/33650 (epoch 10.590), train_loss = 1.18738209, grad/param norm = 1.4515e-01, time/batch = 18.3162s	
7128/33650 (epoch 10.591), train_loss = 1.18918504, grad/param norm = 1.6629e-01, time/batch = 17.3750s	
7129/33650 (epoch 10.593), train_loss = 1.13550761, grad/param norm = 1.3623e-01, time/batch = 18.5615s	
7130/33650 (epoch 10.594), train_loss = 1.03313466, grad/param norm = 1.5389e-01, time/batch = 16.3865s	
7131/33650 (epoch 10.596), train_loss = 1.16565331, grad/param norm = 1.3151e-01, time/batch = 17.2190s	
7132/33650 (epoch 10.597), train_loss = 0.99075463, grad/param norm = 1.2169e-01, time/batch = 18.3876s	
7133/33650 (epoch 10.599), train_loss = 1.14394144, grad/param norm = 1.4720e-01, time/batch = 17.4806s	
7134/33650 (epoch 10.600), train_loss = 1.05196245, grad/param norm = 1.3162e-01, time/batch = 18.3917s	
7135/33650 (epoch 10.602), train_loss = 1.29900190, grad/param norm = 1.5059e-01, time/batch = 16.0524s	
7136/33650 (epoch 10.603), train_loss = 1.14414286, grad/param norm = 1.4369e-01, time/batch = 17.5501s	
7137/33650 (epoch 10.605), train_loss = 1.23629929, grad/param norm = 1.5037e-01, time/batch = 17.8938s	
7138/33650 (epoch 10.606), train_loss = 1.30560473, grad/param norm = 1.5461e-01, time/batch = 18.0676s	
7139/33650 (epoch 10.608), train_loss = 1.15207704, grad/param norm = 1.4580e-01, time/batch = 17.1456s	
7140/33650 (epoch 10.609), train_loss = 1.24386635, grad/param norm = 1.5582e-01, time/batch = 17.3837s	
7141/33650 (epoch 10.611), train_loss = 1.08406256, grad/param norm = 1.4126e-01, time/batch = 18.1386s	
7142/33650 (epoch 10.612), train_loss = 1.20559216, grad/param norm = 1.5691e-01, time/batch = 17.6425s	
7143/33650 (epoch 10.614), train_loss = 1.28294248, grad/param norm = 1.6028e-01, time/batch = 16.3658s	
7144/33650 (epoch 10.615), train_loss = 1.16581775, grad/param norm = 1.2859e-01, time/batch = 17.6510s	
7145/33650 (epoch 10.617), train_loss = 1.06426995, grad/param norm = 1.2292e-01, time/batch = 14.8661s	
7146/33650 (epoch 10.618), train_loss = 1.16039108, grad/param norm = 1.3554e-01, time/batch = 14.3873s	
7147/33650 (epoch 10.620), train_loss = 1.27007614, grad/param norm = 1.6681e-01, time/batch = 16.2118s	
7148/33650 (epoch 10.621), train_loss = 1.06727143, grad/param norm = 1.3670e-01, time/batch = 17.4744s	
7149/33650 (epoch 10.623), train_loss = 1.18924594, grad/param norm = 1.3865e-01, time/batch = 18.4772s	
7150/33650 (epoch 10.624), train_loss = 0.93507735, grad/param norm = 1.3238e-01, time/batch = 16.8066s	
7151/33650 (epoch 10.626), train_loss = 0.94072305, grad/param norm = 1.2786e-01, time/batch = 17.8129s	
7152/33650 (epoch 10.627), train_loss = 1.14746665, grad/param norm = 1.4149e-01, time/batch = 18.3136s	
7153/33650 (epoch 10.629), train_loss = 1.18313087, grad/param norm = 1.3927e-01, time/batch = 16.2275s	
7154/33650 (epoch 10.630), train_loss = 1.29090511, grad/param norm = 1.5696e-01, time/batch = 17.2100s	
7155/33650 (epoch 10.632), train_loss = 1.31269688, grad/param norm = 1.4770e-01, time/batch = 17.9764s	
7156/33650 (epoch 10.633), train_loss = 1.29073500, grad/param norm = 1.4227e-01, time/batch = 17.2106s	
7157/33650 (epoch 10.634), train_loss = 1.02119762, grad/param norm = 1.3841e-01, time/batch = 17.9565s	
7158/33650 (epoch 10.636), train_loss = 0.93409623, grad/param norm = 1.1856e-01, time/batch = 18.2192s	
7159/33650 (epoch 10.637), train_loss = 1.20593600, grad/param norm = 1.5436e-01, time/batch = 17.3136s	
7160/33650 (epoch 10.639), train_loss = 1.12563375, grad/param norm = 1.4330e-01, time/batch = 18.6387s	
7161/33650 (epoch 10.640), train_loss = 1.20161429, grad/param norm = 1.4556e-01, time/batch = 17.7211s	
7162/33650 (epoch 10.642), train_loss = 1.33078857, grad/param norm = 1.6489e-01, time/batch = 18.1578s	
7163/33650 (epoch 10.643), train_loss = 1.20156655, grad/param norm = 1.5093e-01, time/batch = 18.1475s	
7164/33650 (epoch 10.645), train_loss = 1.17916855, grad/param norm = 1.3958e-01, time/batch = 17.1444s	
7165/33650 (epoch 10.646), train_loss = 0.99267357, grad/param norm = 1.2639e-01, time/batch = 17.6328s	
7166/33650 (epoch 10.648), train_loss = 1.21113238, grad/param norm = 1.3703e-01, time/batch = 18.3951s	
7167/33650 (epoch 10.649), train_loss = 1.23559029, grad/param norm = 1.7372e-01, time/batch = 18.4700s	
7168/33650 (epoch 10.651), train_loss = 1.32610760, grad/param norm = 1.5300e-01, time/batch = 17.4583s	
7169/33650 (epoch 10.652), train_loss = 0.88065911, grad/param norm = 1.1402e-01, time/batch = 14.6290s	
7170/33650 (epoch 10.654), train_loss = 1.11494472, grad/param norm = 1.4285e-01, time/batch = 15.0136s	
7171/33650 (epoch 10.655), train_loss = 1.05372110, grad/param norm = 1.2793e-01, time/batch = 16.2253s	
7172/33650 (epoch 10.657), train_loss = 1.18446952, grad/param norm = 1.5490e-01, time/batch = 18.3950s	
7173/33650 (epoch 10.658), train_loss = 1.04259495, grad/param norm = 1.3357e-01, time/batch = 17.8134s	
7174/33650 (epoch 10.660), train_loss = 1.00154388, grad/param norm = 1.2671e-01, time/batch = 17.3720s	
7175/33650 (epoch 10.661), train_loss = 1.10929151, grad/param norm = 1.3475e-01, time/batch = 17.9790s	
7176/33650 (epoch 10.663), train_loss = 1.03423453, grad/param norm = 1.5594e-01, time/batch = 17.4907s	
7177/33650 (epoch 10.664), train_loss = 1.02134930, grad/param norm = 1.2307e-01, time/batch = 17.8995s	
7178/33650 (epoch 10.666), train_loss = 1.11837679, grad/param norm = 1.4166e-01, time/batch = 17.4628s	
7179/33650 (epoch 10.667), train_loss = 1.08796569, grad/param norm = 1.3916e-01, time/batch = 18.3214s	
7180/33650 (epoch 10.669), train_loss = 1.06069556, grad/param norm = 1.4153e-01, time/batch = 17.9805s	
7181/33650 (epoch 10.670), train_loss = 0.99241982, grad/param norm = 1.3627e-01, time/batch = 17.1483s	
7182/33650 (epoch 10.672), train_loss = 1.02147367, grad/param norm = 1.4537e-01, time/batch = 16.9773s	
7183/33650 (epoch 10.673), train_loss = 0.96002602, grad/param norm = 1.4100e-01, time/batch = 18.9662s	
7184/33650 (epoch 10.675), train_loss = 0.93486785, grad/param norm = 1.1728e-01, time/batch = 16.1169s	
7185/33650 (epoch 10.676), train_loss = 1.16889583, grad/param norm = 1.4448e-01, time/batch = 17.4668s	
7186/33650 (epoch 10.678), train_loss = 1.06604308, grad/param norm = 1.3670e-01, time/batch = 18.6377s	
7187/33650 (epoch 10.679), train_loss = 1.12940778, grad/param norm = 1.5171e-01, time/batch = 18.4756s	
7188/33650 (epoch 10.681), train_loss = 1.07851707, grad/param norm = 1.3618e-01, time/batch = 17.2261s	
7189/33650 (epoch 10.682), train_loss = 1.08940577, grad/param norm = 1.5120e-01, time/batch = 17.4003s	
7190/33650 (epoch 10.684), train_loss = 1.04788972, grad/param norm = 1.2765e-01, time/batch = 16.8891s	
7191/33650 (epoch 10.685), train_loss = 1.22671804, grad/param norm = 1.4980e-01, time/batch = 17.6316s	
7192/33650 (epoch 10.686), train_loss = 1.16445763, grad/param norm = 1.4259e-01, time/batch = 17.9735s	
7193/33650 (epoch 10.688), train_loss = 1.31074983, grad/param norm = 1.5033e-01, time/batch = 18.3232s	
7194/33650 (epoch 10.689), train_loss = 1.08513639, grad/param norm = 1.4325e-01, time/batch = 18.1362s	
7195/33650 (epoch 10.691), train_loss = 1.28457009, grad/param norm = 1.4712e-01, time/batch = 16.2930s	
7196/33650 (epoch 10.692), train_loss = 1.28046598, grad/param norm = 1.5256e-01, time/batch = 18.5573s	
7197/33650 (epoch 10.694), train_loss = 1.21925985, grad/param norm = 1.5570e-01, time/batch = 17.8179s	
7198/33650 (epoch 10.695), train_loss = 0.86554801, grad/param norm = 1.3232e-01, time/batch = 16.2055s	
7199/33650 (epoch 10.697), train_loss = 1.18129481, grad/param norm = 1.5030e-01, time/batch = 17.7331s	
7200/33650 (epoch 10.698), train_loss = 1.29965955, grad/param norm = 1.5000e-01, time/batch = 16.7110s	
7201/33650 (epoch 10.700), train_loss = 1.14011181, grad/param norm = 1.4220e-01, time/batch = 17.5455s	
7202/33650 (epoch 10.701), train_loss = 1.19083197, grad/param norm = 1.4591e-01, time/batch = 17.2873s	
7203/33650 (epoch 10.703), train_loss = 1.28891754, grad/param norm = 1.4054e-01, time/batch = 18.2114s	
7204/33650 (epoch 10.704), train_loss = 1.13728668, grad/param norm = 1.4063e-01, time/batch = 18.4775s	
7205/33650 (epoch 10.706), train_loss = 1.14155993, grad/param norm = 1.3769e-01, time/batch = 17.1373s	
7206/33650 (epoch 10.707), train_loss = 1.25222164, grad/param norm = 1.4817e-01, time/batch = 17.8092s	
7207/33650 (epoch 10.709), train_loss = 1.11595351, grad/param norm = 1.4088e-01, time/batch = 18.1471s	
7208/33650 (epoch 10.710), train_loss = 1.36621079, grad/param norm = 1.4355e-01, time/batch = 16.4796s	
7209/33650 (epoch 10.712), train_loss = 1.10092526, grad/param norm = 1.4364e-01, time/batch = 17.4853s	
7210/33650 (epoch 10.713), train_loss = 1.12792560, grad/param norm = 1.7427e-01, time/batch = 18.0739s	
7211/33650 (epoch 10.715), train_loss = 1.28548257, grad/param norm = 1.5724e-01, time/batch = 17.7368s	
7212/33650 (epoch 10.716), train_loss = 1.05737974, grad/param norm = 1.4330e-01, time/batch = 17.1345s	
7213/33650 (epoch 10.718), train_loss = 1.15486463, grad/param norm = 1.5046e-01, time/batch = 17.6473s	
7214/33650 (epoch 10.719), train_loss = 1.32929365, grad/param norm = 1.7446e-01, time/batch = 16.9089s	
7215/33650 (epoch 10.721), train_loss = 1.39519532, grad/param norm = 1.5980e-01, time/batch = 15.8853s	
7216/33650 (epoch 10.722), train_loss = 1.33178545, grad/param norm = 1.7548e-01, time/batch = 15.8192s	
7217/33650 (epoch 10.724), train_loss = 1.26211497, grad/param norm = 1.5606e-01, time/batch = 18.3245s	
7218/33650 (epoch 10.725), train_loss = 1.31932360, grad/param norm = 1.5686e-01, time/batch = 17.4831s	
7219/33650 (epoch 10.727), train_loss = 1.08245079, grad/param norm = 1.4933e-01, time/batch = 17.3844s	
7220/33650 (epoch 10.728), train_loss = 1.10406805, grad/param norm = 1.3636e-01, time/batch = 17.4866s	
7221/33650 (epoch 10.730), train_loss = 1.26252640, grad/param norm = 1.4979e-01, time/batch = 17.5699s	
7222/33650 (epoch 10.731), train_loss = 1.31678563, grad/param norm = 1.4944e-01, time/batch = 17.1502s	
7223/33650 (epoch 10.733), train_loss = 1.17939943, grad/param norm = 1.5922e-01, time/batch = 17.3978s	
7224/33650 (epoch 10.734), train_loss = 1.36582643, grad/param norm = 1.7209e-01, time/batch = 16.8588s	
7225/33650 (epoch 10.736), train_loss = 1.15592980, grad/param norm = 1.7548e-01, time/batch = 16.5776s	
7226/33650 (epoch 10.737), train_loss = 1.21242057, grad/param norm = 1.6860e-01, time/batch = 17.8866s	
7227/33650 (epoch 10.738), train_loss = 1.06469532, grad/param norm = 1.3526e-01, time/batch = 16.9110s	
7228/33650 (epoch 10.740), train_loss = 1.02897117, grad/param norm = 1.3197e-01, time/batch = 17.7389s	
7229/33650 (epoch 10.741), train_loss = 1.12911342, grad/param norm = 1.4472e-01, time/batch = 15.9605s	
7230/33650 (epoch 10.743), train_loss = 1.18650090, grad/param norm = 1.4380e-01, time/batch = 17.1466s	
7231/33650 (epoch 10.744), train_loss = 1.13885975, grad/param norm = 1.3748e-01, time/batch = 17.7970s	
7232/33650 (epoch 10.746), train_loss = 1.14730435, grad/param norm = 1.4682e-01, time/batch = 16.7341s	
7233/33650 (epoch 10.747), train_loss = 1.26636361, grad/param norm = 1.4121e-01, time/batch = 14.9644s	
7234/33650 (epoch 10.749), train_loss = 0.99758489, grad/param norm = 1.3658e-01, time/batch = 17.8920s	
7235/33650 (epoch 10.750), train_loss = 1.29511959, grad/param norm = 1.4681e-01, time/batch = 17.6496s	
7236/33650 (epoch 10.752), train_loss = 1.30655487, grad/param norm = 1.5207e-01, time/batch = 17.6349s	
7237/33650 (epoch 10.753), train_loss = 1.40808238, grad/param norm = 1.6126e-01, time/batch = 17.3091s	
7238/33650 (epoch 10.755), train_loss = 1.09418913, grad/param norm = 1.3748e-01, time/batch = 16.7146s	
7239/33650 (epoch 10.756), train_loss = 1.30560785, grad/param norm = 1.6700e-01, time/batch = 17.1471s	
7240/33650 (epoch 10.758), train_loss = 1.29671864, grad/param norm = 1.5726e-01, time/batch = 16.5599s	
7241/33650 (epoch 10.759), train_loss = 1.39282323, grad/param norm = 1.6025e-01, time/batch = 16.9904s	
7242/33650 (epoch 10.761), train_loss = 1.24513185, grad/param norm = 1.4942e-01, time/batch = 17.3194s	
7243/33650 (epoch 10.762), train_loss = 1.20705572, grad/param norm = 1.4274e-01, time/batch = 16.3995s	
7244/33650 (epoch 10.764), train_loss = 1.28664824, grad/param norm = 1.6784e-01, time/batch = 15.3071s	
7245/33650 (epoch 10.765), train_loss = 1.20965982, grad/param norm = 1.4561e-01, time/batch = 16.7498s	
7246/33650 (epoch 10.767), train_loss = 1.12686036, grad/param norm = 1.4080e-01, time/batch = 17.5686s	
7247/33650 (epoch 10.768), train_loss = 1.04295423, grad/param norm = 1.3530e-01, time/batch = 16.0549s	
7248/33650 (epoch 10.770), train_loss = 1.17804327, grad/param norm = 1.4557e-01, time/batch = 16.8170s	
7249/33650 (epoch 10.771), train_loss = 1.19366066, grad/param norm = 1.4535e-01, time/batch = 17.9899s	
7250/33650 (epoch 10.773), train_loss = 1.33872774, grad/param norm = 1.7157e-01, time/batch = 16.9845s	
7251/33650 (epoch 10.774), train_loss = 1.22510477, grad/param norm = 1.6049e-01, time/batch = 16.6262s	
7252/33650 (epoch 10.776), train_loss = 1.28447697, grad/param norm = 1.5176e-01, time/batch = 17.0698s	
7253/33650 (epoch 10.777), train_loss = 1.02685483, grad/param norm = 1.3462e-01, time/batch = 17.8274s	
7254/33650 (epoch 10.779), train_loss = 1.17598557, grad/param norm = 1.4309e-01, time/batch = 16.8133s	
7255/33650 (epoch 10.780), train_loss = 1.07642250, grad/param norm = 1.3124e-01, time/batch = 17.4007s	
7256/33650 (epoch 10.782), train_loss = 1.12851800, grad/param norm = 1.4429e-01, time/batch = 16.5558s	
7257/33650 (epoch 10.783), train_loss = 1.05543149, grad/param norm = 1.3591e-01, time/batch = 16.6406s	
7258/33650 (epoch 10.785), train_loss = 1.39753384, grad/param norm = 1.4332e-01, time/batch = 17.5690s	
7259/33650 (epoch 10.786), train_loss = 1.19272271, grad/param norm = 1.4443e-01, time/batch = 17.0753s	
7260/33650 (epoch 10.788), train_loss = 1.20610668, grad/param norm = 1.4289e-01, time/batch = 16.1410s	
7261/33650 (epoch 10.789), train_loss = 1.25102732, grad/param norm = 1.3255e-01, time/batch = 16.0445s	
7262/33650 (epoch 10.790), train_loss = 1.27049191, grad/param norm = 1.7001e-01, time/batch = 17.0008s	
7263/33650 (epoch 10.792), train_loss = 1.33698440, grad/param norm = 1.7577e-01, time/batch = 18.2372s	
7264/33650 (epoch 10.793), train_loss = 1.27248401, grad/param norm = 1.6307e-01, time/batch = 20.2506s	
7265/33650 (epoch 10.795), train_loss = 1.32961540, grad/param norm = 1.4465e-01, time/batch = 24.7869s	
7266/33650 (epoch 10.796), train_loss = 1.15689672, grad/param norm = 1.5153e-01, time/batch = 17.7345s	
7267/33650 (epoch 10.798), train_loss = 1.15227860, grad/param norm = 1.4166e-01, time/batch = 16.2334s	
7268/33650 (epoch 10.799), train_loss = 1.18080815, grad/param norm = 1.3106e-01, time/batch = 16.6590s	
7269/33650 (epoch 10.801), train_loss = 1.25761725, grad/param norm = 1.6651e-01, time/batch = 17.8997s	
7270/33650 (epoch 10.802), train_loss = 1.30650525, grad/param norm = 1.4061e-01, time/batch = 17.1467s	
7271/33650 (epoch 10.804), train_loss = 1.19027749, grad/param norm = 1.5010e-01, time/batch = 16.8944s	
7272/33650 (epoch 10.805), train_loss = 1.12908639, grad/param norm = 1.3347e-01, time/batch = 16.2266s	
7273/33650 (epoch 10.807), train_loss = 1.40337641, grad/param norm = 1.6098e-01, time/batch = 18.1551s	
7274/33650 (epoch 10.808), train_loss = 1.40989697, grad/param norm = 1.6135e-01, time/batch = 16.6493s	
7275/33650 (epoch 10.810), train_loss = 1.25968490, grad/param norm = 1.4429e-01, time/batch = 17.5654s	
7276/33650 (epoch 10.811), train_loss = 1.24292953, grad/param norm = 1.5102e-01, time/batch = 17.3327s	
7277/33650 (epoch 10.813), train_loss = 1.18568638, grad/param norm = 1.5265e-01, time/batch = 17.2421s	
7278/33650 (epoch 10.814), train_loss = 1.29296791, grad/param norm = 1.5127e-01, time/batch = 16.8087s	
7279/33650 (epoch 10.816), train_loss = 1.23415237, grad/param norm = 1.4916e-01, time/batch = 17.4058s	
7280/33650 (epoch 10.817), train_loss = 1.30698882, grad/param norm = 1.6908e-01, time/batch = 17.9831s	
7281/33650 (epoch 10.819), train_loss = 1.30638601, grad/param norm = 1.4512e-01, time/batch = 15.4636s	
7282/33650 (epoch 10.820), train_loss = 1.33597328, grad/param norm = 1.5642e-01, time/batch = 16.4055s	
7283/33650 (epoch 10.822), train_loss = 1.34444288, grad/param norm = 1.7240e-01, time/batch = 17.3842s	
7284/33650 (epoch 10.823), train_loss = 1.12051498, grad/param norm = 1.5066e-01, time/batch = 16.7359s	
7285/33650 (epoch 10.825), train_loss = 1.18696175, grad/param norm = 1.3886e-01, time/batch = 16.9607s	
7286/33650 (epoch 10.826), train_loss = 1.28056299, grad/param norm = 1.5228e-01, time/batch = 17.5816s	
7287/33650 (epoch 10.828), train_loss = 1.45016890, grad/param norm = 1.4705e-01, time/batch = 17.8994s	
7288/33650 (epoch 10.829), train_loss = 1.04215979, grad/param norm = 1.3381e-01, time/batch = 16.3947s	
7289/33650 (epoch 10.831), train_loss = 1.28007688, grad/param norm = 1.5102e-01, time/batch = 17.3185s	
7290/33650 (epoch 10.832), train_loss = 1.25296987, grad/param norm = 1.3891e-01, time/batch = 15.4851s	
7291/33650 (epoch 10.834), train_loss = 1.29145141, grad/param norm = 1.5460e-01, time/batch = 17.6555s	
7292/33650 (epoch 10.835), train_loss = 1.47061267, grad/param norm = 1.6331e-01, time/batch = 17.5568s	
7293/33650 (epoch 10.837), train_loss = 1.24055065, grad/param norm = 1.6724e-01, time/batch = 17.2377s	
7294/33650 (epoch 10.838), train_loss = 1.20497873, grad/param norm = 1.6145e-01, time/batch = 17.0734s	
7295/33650 (epoch 10.840), train_loss = 1.29912749, grad/param norm = 1.5129e-01, time/batch = 16.3185s	
7296/33650 (epoch 10.841), train_loss = 1.10161573, grad/param norm = 1.3768e-01, time/batch = 16.4143s	
7297/33650 (epoch 10.842), train_loss = 1.15785928, grad/param norm = 1.4142e-01, time/batch = 18.1471s	
7298/33650 (epoch 10.844), train_loss = 1.37131198, grad/param norm = 1.5603e-01, time/batch = 16.9775s	
7299/33650 (epoch 10.845), train_loss = 1.12878020, grad/param norm = 1.3249e-01, time/batch = 15.6265s	
7300/33650 (epoch 10.847), train_loss = 0.96617716, grad/param norm = 1.4153e-01, time/batch = 17.5610s	
7301/33650 (epoch 10.848), train_loss = 1.04277754, grad/param norm = 1.4963e-01, time/batch = 17.6510s	
7302/33650 (epoch 10.850), train_loss = 1.21305321, grad/param norm = 1.6727e-01, time/batch = 16.3218s	
7303/33650 (epoch 10.851), train_loss = 0.98057583, grad/param norm = 1.2757e-01, time/batch = 16.8005s	
7304/33650 (epoch 10.853), train_loss = 1.21365458, grad/param norm = 1.4558e-01, time/batch = 16.5680s	
7305/33650 (epoch 10.854), train_loss = 1.36836421, grad/param norm = 1.7741e-01, time/batch = 17.2465s	
7306/33650 (epoch 10.856), train_loss = 0.90478345, grad/param norm = 1.3212e-01, time/batch = 16.2957s	
7307/33650 (epoch 10.857), train_loss = 1.15832028, grad/param norm = 1.2847e-01, time/batch = 17.9025s	
7308/33650 (epoch 10.859), train_loss = 1.07824731, grad/param norm = 1.3453e-01, time/batch = 17.1577s	
7309/33650 (epoch 10.860), train_loss = 1.00516850, grad/param norm = 1.3883e-01, time/batch = 16.0367s	
7310/33650 (epoch 10.862), train_loss = 1.06423530, grad/param norm = 1.4763e-01, time/batch = 17.4867s	
7311/33650 (epoch 10.863), train_loss = 1.26754751, grad/param norm = 1.4629e-01, time/batch = 17.5682s	
7312/33650 (epoch 10.865), train_loss = 1.15160766, grad/param norm = 1.4672e-01, time/batch = 17.2355s	
7313/33650 (epoch 10.866), train_loss = 1.04891990, grad/param norm = 1.4039e-01, time/batch = 15.9023s	
7314/33650 (epoch 10.868), train_loss = 1.08049923, grad/param norm = 1.5320e-01, time/batch = 17.6555s	
7315/33650 (epoch 10.869), train_loss = 1.33364126, grad/param norm = 1.6241e-01, time/batch = 17.7485s	
7316/33650 (epoch 10.871), train_loss = 1.03594913, grad/param norm = 1.2438e-01, time/batch = 16.7299s	
7317/33650 (epoch 10.872), train_loss = 1.19139880, grad/param norm = 1.5456e-01, time/batch = 16.8234s	
7318/33650 (epoch 10.874), train_loss = 1.29408807, grad/param norm = 1.6053e-01, time/batch = 17.2317s	
7319/33650 (epoch 10.875), train_loss = 1.13358151, grad/param norm = 1.4354e-01, time/batch = 17.5645s	
7320/33650 (epoch 10.877), train_loss = 1.31521188, grad/param norm = 1.4431e-01, time/batch = 16.0561s	
7321/33650 (epoch 10.878), train_loss = 0.84049008, grad/param norm = 1.2556e-01, time/batch = 17.1563s	
7322/33650 (epoch 10.880), train_loss = 1.22554073, grad/param norm = 1.5044e-01, time/batch = 17.6523s	
7323/33650 (epoch 10.881), train_loss = 1.10295504, grad/param norm = 1.3669e-01, time/batch = 16.5694s	
7324/33650 (epoch 10.883), train_loss = 1.18461682, grad/param norm = 1.4772e-01, time/batch = 17.9000s	
7325/33650 (epoch 10.884), train_loss = 1.29802400, grad/param norm = 1.6161e-01, time/batch = 17.1663s	
7326/33650 (epoch 10.886), train_loss = 1.30171845, grad/param norm = 1.5927e-01, time/batch = 16.7161s	
7327/33650 (epoch 10.887), train_loss = 1.09867080, grad/param norm = 1.3551e-01, time/batch = 16.8075s	
7328/33650 (epoch 10.889), train_loss = 1.27331592, grad/param norm = 1.6706e-01, time/batch = 17.8320s	
7329/33650 (epoch 10.890), train_loss = 1.27664294, grad/param norm = 1.4363e-01, time/batch = 17.4796s	
7330/33650 (epoch 10.892), train_loss = 1.23349006, grad/param norm = 1.5671e-01, time/batch = 15.9656s	
7331/33650 (epoch 10.893), train_loss = 1.25024999, grad/param norm = 1.4940e-01, time/batch = 17.7205s	
7332/33650 (epoch 10.895), train_loss = 1.33622830, grad/param norm = 1.6091e-01, time/batch = 15.8894s	
7333/33650 (epoch 10.896), train_loss = 1.08505297, grad/param norm = 1.3621e-01, time/batch = 18.1525s	
7334/33650 (epoch 10.897), train_loss = 1.06132262, grad/param norm = 1.3614e-01, time/batch = 16.5571s	
7335/33650 (epoch 10.899), train_loss = 1.04438720, grad/param norm = 1.3019e-01, time/batch = 17.7332s	
7336/33650 (epoch 10.900), train_loss = 0.97298166, grad/param norm = 1.2671e-01, time/batch = 17.0499s	
7337/33650 (epoch 10.902), train_loss = 1.20806618, grad/param norm = 1.5258e-01, time/batch = 16.5636s	
7338/33650 (epoch 10.903), train_loss = 1.18349233, grad/param norm = 1.6486e-01, time/batch = 16.3096s	
7339/33650 (epoch 10.905), train_loss = 1.40871122, grad/param norm = 1.6283e-01, time/batch = 17.8171s	
7340/33650 (epoch 10.906), train_loss = 1.14945167, grad/param norm = 1.5258e-01, time/batch = 16.6388s	
7341/33650 (epoch 10.908), train_loss = 1.13221503, grad/param norm = 1.3540e-01, time/batch = 17.0561s	
7342/33650 (epoch 10.909), train_loss = 1.13542722, grad/param norm = 1.3214e-01, time/batch = 17.9819s	
7343/33650 (epoch 10.911), train_loss = 1.01279552, grad/param norm = 1.3213e-01, time/batch = 16.5729s	
7344/33650 (epoch 10.912), train_loss = 1.01144392, grad/param norm = 1.3467e-01, time/batch = 14.9653s	
7345/33650 (epoch 10.914), train_loss = 1.17078981, grad/param norm = 1.3608e-01, time/batch = 17.4881s	
7346/33650 (epoch 10.915), train_loss = 1.23476876, grad/param norm = 1.7283e-01, time/batch = 17.9781s	
7347/33650 (epoch 10.917), train_loss = 1.17464674, grad/param norm = 1.4867e-01, time/batch = 17.4179s	
7348/33650 (epoch 10.918), train_loss = 0.94244063, grad/param norm = 1.2246e-01, time/batch = 16.2246s	
7349/33650 (epoch 10.920), train_loss = 1.09182381, grad/param norm = 1.3193e-01, time/batch = 17.0011s	
7350/33650 (epoch 10.921), train_loss = 1.07149177, grad/param norm = 1.3960e-01, time/batch = 17.8288s	
7351/33650 (epoch 10.923), train_loss = 1.04595640, grad/param norm = 1.4219e-01, time/batch = 16.2193s	
7352/33650 (epoch 10.924), train_loss = 1.21007707, grad/param norm = 1.6295e-01, time/batch = 16.1139s	
7353/33650 (epoch 10.926), train_loss = 1.18268891, grad/param norm = 1.5721e-01, time/batch = 17.9778s	
7354/33650 (epoch 10.927), train_loss = 1.12086742, grad/param norm = 1.5399e-01, time/batch = 17.4967s	
7355/33650 (epoch 10.929), train_loss = 1.20590787, grad/param norm = 1.5330e-01, time/batch = 16.1380s	
7356/33650 (epoch 10.930), train_loss = 1.12565544, grad/param norm = 1.4142e-01, time/batch = 16.3758s	
7357/33650 (epoch 10.932), train_loss = 1.17895558, grad/param norm = 1.4557e-01, time/batch = 17.3221s	
7358/33650 (epoch 10.933), train_loss = 1.02528569, grad/param norm = 1.3564e-01, time/batch = 16.8125s	
7359/33650 (epoch 10.935), train_loss = 1.07584920, grad/param norm = 1.4776e-01, time/batch = 17.1428s	
7360/33650 (epoch 10.936), train_loss = 1.06196218, grad/param norm = 1.3086e-01, time/batch = 17.4880s	
7361/33650 (epoch 10.938), train_loss = 0.99380582, grad/param norm = 1.3253e-01, time/batch = 18.1460s	
7362/33650 (epoch 10.939), train_loss = 1.22120528, grad/param norm = 1.4450e-01, time/batch = 17.1454s	
7363/33650 (epoch 10.941), train_loss = 1.19953313, grad/param norm = 1.5471e-01, time/batch = 17.8266s	
7364/33650 (epoch 10.942), train_loss = 1.25051463, grad/param norm = 1.5152e-01, time/batch = 17.0690s	
7365/33650 (epoch 10.944), train_loss = 1.19864401, grad/param norm = 1.3570e-01, time/batch = 16.9015s	
7366/33650 (epoch 10.945), train_loss = 1.25828041, grad/param norm = 1.5975e-01, time/batch = 16.4014s	
7367/33650 (epoch 10.947), train_loss = 1.39644563, grad/param norm = 1.6203e-01, time/batch = 17.3275s	
7368/33650 (epoch 10.948), train_loss = 1.29001137, grad/param norm = 1.4208e-01, time/batch = 15.2285s	
7369/33650 (epoch 10.949), train_loss = 1.06742638, grad/param norm = 1.4435e-01, time/batch = 16.4648s	
7370/33650 (epoch 10.951), train_loss = 1.33759187, grad/param norm = 1.5222e-01, time/batch = 18.3037s	
7371/33650 (epoch 10.952), train_loss = 1.29492932, grad/param norm = 1.6073e-01, time/batch = 17.5721s	
7372/33650 (epoch 10.954), train_loss = 1.25077656, grad/param norm = 1.5351e-01, time/batch = 17.2331s	
7373/33650 (epoch 10.955), train_loss = 1.26040330, grad/param norm = 1.6215e-01, time/batch = 16.8957s	
7374/33650 (epoch 10.957), train_loss = 1.26048363, grad/param norm = 1.5935e-01, time/batch = 18.0650s	
7375/33650 (epoch 10.958), train_loss = 0.90398566, grad/param norm = 1.1905e-01, time/batch = 17.4030s	
7376/33650 (epoch 10.960), train_loss = 1.01865820, grad/param norm = 1.3607e-01, time/batch = 17.0575s	
7377/33650 (epoch 10.961), train_loss = 1.07097849, grad/param norm = 1.3940e-01, time/batch = 16.3861s	
7378/33650 (epoch 10.963), train_loss = 1.13019409, grad/param norm = 1.5248e-01, time/batch = 17.4038s	
7379/33650 (epoch 10.964), train_loss = 1.18371004, grad/param norm = 1.5140e-01, time/batch = 16.0636s	
7380/33650 (epoch 10.966), train_loss = 1.18226319, grad/param norm = 1.4425e-01, time/batch = 17.6505s	
7381/33650 (epoch 10.967), train_loss = 1.24216842, grad/param norm = 1.4167e-01, time/batch = 16.8355s	
7382/33650 (epoch 10.969), train_loss = 1.13701477, grad/param norm = 1.3816e-01, time/batch = 13.4399s	
7383/33650 (epoch 10.970), train_loss = 1.23938966, grad/param norm = 1.5308e-01, time/batch = 14.0758s	
7384/33650 (epoch 10.972), train_loss = 1.50586201, grad/param norm = 1.7132e-01, time/batch = 17.2348s	
7385/33650 (epoch 10.973), train_loss = 1.06080550, grad/param norm = 1.2952e-01, time/batch = 17.3241s	
7386/33650 (epoch 10.975), train_loss = 1.05972181, grad/param norm = 1.3906e-01, time/batch = 16.9860s	
7387/33650 (epoch 10.976), train_loss = 1.03345695, grad/param norm = 1.2752e-01, time/batch = 16.5426s	
7388/33650 (epoch 10.978), train_loss = 1.08566584, grad/param norm = 1.5122e-01, time/batch = 17.4961s	
7389/33650 (epoch 10.979), train_loss = 1.17166963, grad/param norm = 1.4299e-01, time/batch = 16.7458s	
7390/33650 (epoch 10.981), train_loss = 1.09526862, grad/param norm = 1.2347e-01, time/batch = 16.5648s	
7391/33650 (epoch 10.982), train_loss = 1.19878195, grad/param norm = 1.4458e-01, time/batch = 16.7292s	
7392/33650 (epoch 10.984), train_loss = 1.04499703, grad/param norm = 1.3954e-01, time/batch = 17.7470s	
7393/33650 (epoch 10.985), train_loss = 1.03850567, grad/param norm = 1.3413e-01, time/batch = 16.6181s	
7394/33650 (epoch 10.987), train_loss = 1.13190776, grad/param norm = 1.3411e-01, time/batch = 17.4679s	
7395/33650 (epoch 10.988), train_loss = 1.22551907, grad/param norm = 1.4586e-01, time/batch = 18.6531s	
7396/33650 (epoch 10.990), train_loss = 1.40637512, grad/param norm = 1.7739e-01, time/batch = 18.5618s	
7397/33650 (epoch 10.991), train_loss = 1.23894350, grad/param norm = 1.4147e-01, time/batch = 17.5533s	
7398/33650 (epoch 10.993), train_loss = 1.22036578, grad/param norm = 1.5249e-01, time/batch = 18.3900s	
7399/33650 (epoch 10.994), train_loss = 1.12563589, grad/param norm = 1.4406e-01, time/batch = 17.1458s	
7400/33650 (epoch 10.996), train_loss = 1.10263188, grad/param norm = 1.4489e-01, time/batch = 17.5575s	
7401/33650 (epoch 10.997), train_loss = 1.21866148, grad/param norm = 1.5575e-01, time/batch = 17.9818s	
7402/33650 (epoch 10.999), train_loss = 1.02422743, grad/param norm = 1.3733e-01, time/batch = 17.4836s	
decayed learning rate by a factor 0.97 to 0.0018818	
7403/33650 (epoch 11.000), train_loss = 1.24053584, grad/param norm = 1.5481e-01, time/batch = 18.2259s	
7404/33650 (epoch 11.001), train_loss = 1.34630693, grad/param norm = 1.6237e-01, time/batch = 17.0385s	
7405/33650 (epoch 11.003), train_loss = 1.37010380, grad/param norm = 1.7282e-01, time/batch = 17.5590s	
7406/33650 (epoch 11.004), train_loss = 1.24345775, grad/param norm = 1.5735e-01, time/batch = 18.4667s	
7407/33650 (epoch 11.006), train_loss = 1.11969184, grad/param norm = 1.3837e-01, time/batch = 16.9671s	
7408/33650 (epoch 11.007), train_loss = 1.20285484, grad/param norm = 1.5329e-01, time/batch = 17.8043s	
7409/33650 (epoch 11.009), train_loss = 1.12151878, grad/param norm = 1.3817e-01, time/batch = 16.4690s	
7410/33650 (epoch 11.010), train_loss = 1.25210689, grad/param norm = 1.5511e-01, time/batch = 17.7965s	
7411/33650 (epoch 11.012), train_loss = 1.12036025, grad/param norm = 1.5586e-01, time/batch = 18.1414s	
7412/33650 (epoch 11.013), train_loss = 1.22530864, grad/param norm = 1.6661e-01, time/batch = 18.4032s	
7413/33650 (epoch 11.015), train_loss = 1.06236235, grad/param norm = 1.3332e-01, time/batch = 17.8940s	
7414/33650 (epoch 11.016), train_loss = 1.05958323, grad/param norm = 1.4701e-01, time/batch = 17.8799s	
7415/33650 (epoch 11.018), train_loss = 1.16866747, grad/param norm = 1.5439e-01, time/batch = 18.0653s	
7416/33650 (epoch 11.019), train_loss = 1.07944122, grad/param norm = 1.2969e-01, time/batch = 16.3034s	
7417/33650 (epoch 11.021), train_loss = 1.28536279, grad/param norm = 1.4723e-01, time/batch = 16.0702s	
7418/33650 (epoch 11.022), train_loss = 1.10811318, grad/param norm = 1.3464e-01, time/batch = 17.9864s	
7419/33650 (epoch 11.024), train_loss = 1.04434743, grad/param norm = 1.4417e-01, time/batch = 17.9029s	
7420/33650 (epoch 11.025), train_loss = 1.10727606, grad/param norm = 1.3897e-01, time/batch = 17.6433s	
7421/33650 (epoch 11.027), train_loss = 1.25003717, grad/param norm = 1.5040e-01, time/batch = 17.8033s	
7422/33650 (epoch 11.028), train_loss = 1.24901351, grad/param norm = 1.5362e-01, time/batch = 18.9886s	
7423/33650 (epoch 11.030), train_loss = 1.20028524, grad/param norm = 1.5254e-01, time/batch = 17.4574s	
7424/33650 (epoch 11.031), train_loss = 1.01453095, grad/param norm = 1.2158e-01, time/batch = 16.4611s	
7425/33650 (epoch 11.033), train_loss = 1.11816239, grad/param norm = 1.3008e-01, time/batch = 18.1425s	
7426/33650 (epoch 11.034), train_loss = 1.21693219, grad/param norm = 1.5413e-01, time/batch = 18.6407s	
7427/33650 (epoch 11.036), train_loss = 1.31573243, grad/param norm = 1.7586e-01, time/batch = 17.3152s	
7428/33650 (epoch 11.037), train_loss = 1.09121123, grad/param norm = 1.5710e-01, time/batch = 17.4026s	
7429/33650 (epoch 11.039), train_loss = 1.31002447, grad/param norm = 1.6027e-01, time/batch = 18.3987s	
7430/33650 (epoch 11.040), train_loss = 1.36900620, grad/param norm = 1.6853e-01, time/batch = 17.8928s	
7431/33650 (epoch 11.042), train_loss = 1.38308567, grad/param norm = 1.6187e-01, time/batch = 19.8465s	
7432/33650 (epoch 11.043), train_loss = 1.09860859, grad/param norm = 1.4839e-01, time/batch = 24.6750s	
7433/33650 (epoch 11.045), train_loss = 1.07108279, grad/param norm = 1.3704e-01, time/batch = 17.4721s	
7434/33650 (epoch 11.046), train_loss = 1.24902105, grad/param norm = 1.5477e-01, time/batch = 15.9572s	
7435/33650 (epoch 11.048), train_loss = 1.24545584, grad/param norm = 1.4131e-01, time/batch = 16.6272s	
7436/33650 (epoch 11.049), train_loss = 1.20137477, grad/param norm = 1.5704e-01, time/batch = 18.3099s	
7437/33650 (epoch 11.051), train_loss = 1.30817623, grad/param norm = 1.5694e-01, time/batch = 15.7046s	
7438/33650 (epoch 11.052), train_loss = 1.36912948, grad/param norm = 1.6271e-01, time/batch = 18.3073s	
7439/33650 (epoch 11.053), train_loss = 1.19294055, grad/param norm = 1.4253e-01, time/batch = 17.8201s	
7440/33650 (epoch 11.055), train_loss = 1.01469863, grad/param norm = 1.3515e-01, time/batch = 17.3074s	
7441/33650 (epoch 11.056), train_loss = 1.02991327, grad/param norm = 1.3775e-01, time/batch = 17.1355s	
7442/33650 (epoch 11.058), train_loss = 1.30611942, grad/param norm = 1.6619e-01, time/batch = 18.2277s	
7443/33650 (epoch 11.059), train_loss = 1.23339549, grad/param norm = 1.4844e-01, time/batch = 16.2959s	
7444/33650 (epoch 11.061), train_loss = 1.25921411, grad/param norm = 1.4386e-01, time/batch = 17.2736s	
7445/33650 (epoch 11.062), train_loss = 1.22638103, grad/param norm = 1.3485e-01, time/batch = 17.7271s	
7446/33650 (epoch 11.064), train_loss = 1.11495503, grad/param norm = 1.3241e-01, time/batch = 17.9778s	
7447/33650 (epoch 11.065), train_loss = 1.12135291, grad/param norm = 1.4262e-01, time/batch = 17.6376s	
7448/33650 (epoch 11.067), train_loss = 1.05602360, grad/param norm = 1.3633e-01, time/batch = 17.6466s	
7449/33650 (epoch 11.068), train_loss = 1.20790927, grad/param norm = 1.4379e-01, time/batch = 18.6421s	
7450/33650 (epoch 11.070), train_loss = 1.17639110, grad/param norm = 1.4609e-01, time/batch = 17.3141s	
7451/33650 (epoch 11.071), train_loss = 1.18363402, grad/param norm = 1.4628e-01, time/batch = 17.8155s	
7452/33650 (epoch 11.073), train_loss = 1.22163096, grad/param norm = 1.5491e-01, time/batch = 17.9070s	
7453/33650 (epoch 11.074), train_loss = 1.28765967, grad/param norm = 1.4870e-01, time/batch = 17.8139s	
7454/33650 (epoch 11.076), train_loss = 1.30084487, grad/param norm = 1.6998e-01, time/batch = 16.6504s	
7455/33650 (epoch 11.077), train_loss = 1.15558439, grad/param norm = 1.3841e-01, time/batch = 16.9897s	
7456/33650 (epoch 11.079), train_loss = 1.13844497, grad/param norm = 1.4896e-01, time/batch = 18.3846s	
7457/33650 (epoch 11.080), train_loss = 1.24063901, grad/param norm = 1.5041e-01, time/batch = 16.6531s	
7458/33650 (epoch 11.082), train_loss = 1.28929819, grad/param norm = 1.5664e-01, time/batch = 16.2040s	
7459/33650 (epoch 11.083), train_loss = 1.22289508, grad/param norm = 1.3891e-01, time/batch = 18.2270s	
7460/33650 (epoch 11.085), train_loss = 1.26399194, grad/param norm = 1.3421e-01, time/batch = 18.8873s	
7461/33650 (epoch 11.086), train_loss = 1.29297596, grad/param norm = 1.6295e-01, time/batch = 16.7204s	
7462/33650 (epoch 11.088), train_loss = 1.24447360, grad/param norm = 1.4642e-01, time/batch = 18.0553s	
7463/33650 (epoch 11.089), train_loss = 1.21345379, grad/param norm = 1.5677e-01, time/batch = 17.6255s	
7464/33650 (epoch 11.091), train_loss = 1.11018279, grad/param norm = 1.2898e-01, time/batch = 16.4736s	
7465/33650 (epoch 11.092), train_loss = 1.14518105, grad/param norm = 1.4807e-01, time/batch = 17.7201s	
7466/33650 (epoch 11.094), train_loss = 1.23739171, grad/param norm = 1.3603e-01, time/batch = 18.3996s	
7467/33650 (epoch 11.095), train_loss = 1.23103409, grad/param norm = 1.5337e-01, time/batch = 17.4037s	
7468/33650 (epoch 11.097), train_loss = 1.15685452, grad/param norm = 1.4991e-01, time/batch = 17.8031s	
7469/33650 (epoch 11.098), train_loss = 0.94326057, grad/param norm = 1.2692e-01, time/batch = 17.8018s	
7470/33650 (epoch 11.100), train_loss = 1.08510632, grad/param norm = 1.2919e-01, time/batch = 18.2176s	
7471/33650 (epoch 11.101), train_loss = 1.14784417, grad/param norm = 1.6340e-01, time/batch = 30.3983s	
7472/33650 (epoch 11.103), train_loss = 1.08523680, grad/param norm = 1.2945e-01, time/batch = 18.9868s	
7473/33650 (epoch 11.104), train_loss = 1.23942389, grad/param norm = 1.4263e-01, time/batch = 18.2195s	
7474/33650 (epoch 11.105), train_loss = 1.16640028, grad/param norm = 1.5403e-01, time/batch = 16.3751s	
7475/33650 (epoch 11.107), train_loss = 1.07609099, grad/param norm = 1.4025e-01, time/batch = 17.7163s	
7476/33650 (epoch 11.108), train_loss = 1.24966614, grad/param norm = 1.5727e-01, time/batch = 18.6429s	
7477/33650 (epoch 11.110), train_loss = 1.35286631, grad/param norm = 1.5431e-01, time/batch = 16.0548s	
7478/33650 (epoch 11.111), train_loss = 1.12797953, grad/param norm = 1.5040e-01, time/batch = 18.5718s	
7479/33650 (epoch 11.113), train_loss = 1.12578088, grad/param norm = 1.4562e-01, time/batch = 17.8246s	
7480/33650 (epoch 11.114), train_loss = 1.24936523, grad/param norm = 1.4593e-01, time/batch = 17.9741s	
7481/33650 (epoch 11.116), train_loss = 1.04321232, grad/param norm = 1.3252e-01, time/batch = 16.9453s	
7482/33650 (epoch 11.117), train_loss = 1.18330368, grad/param norm = 1.2895e-01, time/batch = 17.7118s	
7483/33650 (epoch 11.119), train_loss = 1.02627215, grad/param norm = 1.3209e-01, time/batch = 17.8015s	
7484/33650 (epoch 11.120), train_loss = 1.07950945, grad/param norm = 1.4181e-01, time/batch = 17.3765s	
7485/33650 (epoch 11.122), train_loss = 0.97552222, grad/param norm = 1.3371e-01, time/batch = 17.9826s	
7486/33650 (epoch 11.123), train_loss = 1.11159563, grad/param norm = 1.3807e-01, time/batch = 17.8161s	
7487/33650 (epoch 11.125), train_loss = 1.29656802, grad/param norm = 1.5613e-01, time/batch = 16.6461s	
7488/33650 (epoch 11.126), train_loss = 1.35933987, grad/param norm = 1.6971e-01, time/batch = 18.3928s	
7489/33650 (epoch 11.128), train_loss = 1.30741860, grad/param norm = 1.6109e-01, time/batch = 17.9019s	
7490/33650 (epoch 11.129), train_loss = 1.30283508, grad/param norm = 1.5416e-01, time/batch = 17.4747s	
7491/33650 (epoch 11.131), train_loss = 1.21268279, grad/param norm = 1.4469e-01, time/batch = 17.2930s	
7492/33650 (epoch 11.132), train_loss = 1.19096715, grad/param norm = 1.3552e-01, time/batch = 17.8140s	
7493/33650 (epoch 11.134), train_loss = 1.31636947, grad/param norm = 1.4818e-01, time/batch = 18.2241s	
7494/33650 (epoch 11.135), train_loss = 1.03227980, grad/param norm = 1.3332e-01, time/batch = 16.3873s	
7495/33650 (epoch 11.137), train_loss = 1.17229643, grad/param norm = 1.5032e-01, time/batch = 17.4035s	
7496/33650 (epoch 11.138), train_loss = 1.25356004, grad/param norm = 1.3645e-01, time/batch = 18.8184s	
7497/33650 (epoch 11.140), train_loss = 1.21064506, grad/param norm = 1.5342e-01, time/batch = 17.1423s	
7498/33650 (epoch 11.141), train_loss = 1.32336384, grad/param norm = 1.5309e-01, time/batch = 17.9798s	
7499/33650 (epoch 11.143), train_loss = 1.45764261, grad/param norm = 1.8626e-01, time/batch = 16.9702s	
7500/33650 (epoch 11.144), train_loss = 1.28953693, grad/param norm = 1.6140e-01, time/batch = 17.5667s	
7501/33650 (epoch 11.146), train_loss = 1.14736604, grad/param norm = 1.4542e-01, time/batch = 16.5395s	
7502/33650 (epoch 11.147), train_loss = 1.11606688, grad/param norm = 1.3978e-01, time/batch = 18.7246s	
7503/33650 (epoch 11.149), train_loss = 1.07015093, grad/param norm = 1.5012e-01, time/batch = 17.8279s	
7504/33650 (epoch 11.150), train_loss = 1.04487922, grad/param norm = 1.2582e-01, time/batch = 13.4841s	
7505/33650 (epoch 11.152), train_loss = 1.11334378, grad/param norm = 1.3687e-01, time/batch = 0.6446s	
7506/33650 (epoch 11.153), train_loss = 1.14001504, grad/param norm = 1.4411e-01, time/batch = 0.6401s	
7507/33650 (epoch 11.155), train_loss = 1.09552744, grad/param norm = 1.3202e-01, time/batch = 0.6413s	
7508/33650 (epoch 11.156), train_loss = 1.06836089, grad/param norm = 1.2692e-01, time/batch = 0.6449s	
7509/33650 (epoch 11.158), train_loss = 1.17927675, grad/param norm = 1.4638e-01, time/batch = 0.6447s	
7510/33650 (epoch 11.159), train_loss = 1.02045668, grad/param norm = 1.2669e-01, time/batch = 0.6403s	
7511/33650 (epoch 11.160), train_loss = 1.07492409, grad/param norm = 1.2206e-01, time/batch = 0.6465s	
7512/33650 (epoch 11.162), train_loss = 1.17501395, grad/param norm = 1.6709e-01, time/batch = 0.7927s	
7513/33650 (epoch 11.163), train_loss = 1.25457061, grad/param norm = 1.5676e-01, time/batch = 0.9437s	
7514/33650 (epoch 11.165), train_loss = 1.05453784, grad/param norm = 1.3129e-01, time/batch = 0.9617s	
7515/33650 (epoch 11.166), train_loss = 1.04945814, grad/param norm = 1.4601e-01, time/batch = 0.9320s	
7516/33650 (epoch 11.168), train_loss = 1.24890034, grad/param norm = 1.5000e-01, time/batch = 0.9412s	
7517/33650 (epoch 11.169), train_loss = 1.16450944, grad/param norm = 1.4374e-01, time/batch = 1.1008s	
7518/33650 (epoch 11.171), train_loss = 1.16574246, grad/param norm = 1.4569e-01, time/batch = 1.8845s	
7519/33650 (epoch 11.172), train_loss = 1.13327163, grad/param norm = 1.4564e-01, time/batch = 1.8356s	
7520/33650 (epoch 11.174), train_loss = 1.05430067, grad/param norm = 1.4163e-01, time/batch = 10.0675s	
7521/33650 (epoch 11.175), train_loss = 1.09935393, grad/param norm = 1.4890e-01, time/batch = 18.1383s	
7522/33650 (epoch 11.177), train_loss = 1.19197610, grad/param norm = 1.4495e-01, time/batch = 17.7279s	
7523/33650 (epoch 11.178), train_loss = 1.08064869, grad/param norm = 1.4798e-01, time/batch = 16.8122s	
7524/33650 (epoch 11.180), train_loss = 1.03772114, grad/param norm = 1.3764e-01, time/batch = 17.8194s	
7525/33650 (epoch 11.181), train_loss = 0.91818385, grad/param norm = 1.4779e-01, time/batch = 16.8050s	
7526/33650 (epoch 11.183), train_loss = 1.11204773, grad/param norm = 1.4781e-01, time/batch = 17.3070s	
7527/33650 (epoch 11.184), train_loss = 1.13131361, grad/param norm = 1.5127e-01, time/batch = 17.5823s	
7528/33650 (epoch 11.186), train_loss = 1.11582626, grad/param norm = 1.5590e-01, time/batch = 18.3057s	
7529/33650 (epoch 11.187), train_loss = 1.33980888, grad/param norm = 1.5239e-01, time/batch = 17.4740s	
7530/33650 (epoch 11.189), train_loss = 1.36582333, grad/param norm = 1.7238e-01, time/batch = 18.0499s	
7531/33650 (epoch 11.190), train_loss = 1.21223554, grad/param norm = 2.0235e-01, time/batch = 18.0722s	
7532/33650 (epoch 11.192), train_loss = 1.35617910, grad/param norm = 1.6128e-01, time/batch = 17.7117s	
7533/33650 (epoch 11.193), train_loss = 1.29503186, grad/param norm = 1.4937e-01, time/batch = 17.6494s	
7534/33650 (epoch 11.195), train_loss = 1.02483681, grad/param norm = 1.2789e-01, time/batch = 17.7241s	
7535/33650 (epoch 11.196), train_loss = 0.97568834, grad/param norm = 1.4540e-01, time/batch = 18.4021s	
7536/33650 (epoch 11.198), train_loss = 1.12354903, grad/param norm = 1.5467e-01, time/batch = 17.4565s	
7537/33650 (epoch 11.199), train_loss = 1.25747191, grad/param norm = 1.5282e-01, time/batch = 18.3967s	
7538/33650 (epoch 11.201), train_loss = 1.14609142, grad/param norm = 1.5031e-01, time/batch = 18.4011s	
7539/33650 (epoch 11.202), train_loss = 1.11682387, grad/param norm = 1.3790e-01, time/batch = 16.2968s	
7540/33650 (epoch 11.204), train_loss = 1.22235075, grad/param norm = 1.4280e-01, time/batch = 17.7194s	
7541/33650 (epoch 11.205), train_loss = 1.11840325, grad/param norm = 1.4190e-01, time/batch = 18.1494s	
7542/33650 (epoch 11.207), train_loss = 1.13698047, grad/param norm = 1.5360e-01, time/batch = 16.7926s	
7543/33650 (epoch 11.208), train_loss = 1.13286768, grad/param norm = 1.3732e-01, time/batch = 17.8017s	
7544/33650 (epoch 11.210), train_loss = 0.90332148, grad/param norm = 1.1760e-01, time/batch = 17.9818s	
7545/33650 (epoch 11.211), train_loss = 1.05973002, grad/param norm = 1.3848e-01, time/batch = 18.2287s	
7546/33650 (epoch 11.212), train_loss = 1.27647706, grad/param norm = 1.6256e-01, time/batch = 16.9803s	
7547/33650 (epoch 11.214), train_loss = 1.32704963, grad/param norm = 1.6520e-01, time/batch = 17.7363s	
7548/33650 (epoch 11.215), train_loss = 0.91984394, grad/param norm = 1.3651e-01, time/batch = 17.6517s	
7549/33650 (epoch 11.217), train_loss = 1.16481032, grad/param norm = 1.6061e-01, time/batch = 16.3823s	
7550/33650 (epoch 11.218), train_loss = 1.23208602, grad/param norm = 1.4537e-01, time/batch = 17.4693s	
7551/33650 (epoch 11.220), train_loss = 1.05309125, grad/param norm = 1.4232e-01, time/batch = 18.5677s	
7552/33650 (epoch 11.221), train_loss = 1.32298734, grad/param norm = 1.6626e-01, time/batch = 18.0632s	
7553/33650 (epoch 11.223), train_loss = 0.89746172, grad/param norm = 1.3387e-01, time/batch = 17.5353s	
7554/33650 (epoch 11.224), train_loss = 1.14278644, grad/param norm = 1.6497e-01, time/batch = 15.9396s	
7555/33650 (epoch 11.226), train_loss = 1.47762331, grad/param norm = 1.7129e-01, time/batch = 17.6324s	
7556/33650 (epoch 11.227), train_loss = 1.32304859, grad/param norm = 1.5401e-01, time/batch = 17.3080s	
7557/33650 (epoch 11.229), train_loss = 1.29492469, grad/param norm = 1.5803e-01, time/batch = 16.7059s	
7558/33650 (epoch 11.230), train_loss = 1.42086723, grad/param norm = 1.6589e-01, time/batch = 18.3965s	
7559/33650 (epoch 11.232), train_loss = 1.21722513, grad/param norm = 1.6326e-01, time/batch = 17.6377s	
7560/33650 (epoch 11.233), train_loss = 1.23077455, grad/param norm = 1.6690e-01, time/batch = 17.7196s	
7561/33650 (epoch 11.235), train_loss = 1.11545352, grad/param norm = 1.3782e-01, time/batch = 17.7259s	
7562/33650 (epoch 11.236), train_loss = 0.99858038, grad/param norm = 1.3713e-01, time/batch = 17.3056s	
7563/33650 (epoch 11.238), train_loss = 1.12726971, grad/param norm = 1.4318e-01, time/batch = 16.7979s	
7564/33650 (epoch 11.239), train_loss = 1.05620460, grad/param norm = 1.3890e-01, time/batch = 18.0542s	
7565/33650 (epoch 11.241), train_loss = 1.08520135, grad/param norm = 1.2847e-01, time/batch = 18.1409s	
7566/33650 (epoch 11.242), train_loss = 0.96844828, grad/param norm = 1.3095e-01, time/batch = 17.3088s	
7567/33650 (epoch 11.244), train_loss = 1.14724962, grad/param norm = 1.5016e-01, time/batch = 18.1535s	
7568/33650 (epoch 11.245), train_loss = 1.00471580, grad/param norm = 1.4099e-01, time/batch = 17.8941s	
7569/33650 (epoch 11.247), train_loss = 1.13234969, grad/param norm = 1.3704e-01, time/batch = 17.5464s	
7570/33650 (epoch 11.248), train_loss = 1.04734628, grad/param norm = 1.4233e-01, time/batch = 17.1276s	
7571/33650 (epoch 11.250), train_loss = 1.13198572, grad/param norm = 1.3530e-01, time/batch = 18.0587s	
7572/33650 (epoch 11.251), train_loss = 1.30191085, grad/param norm = 1.5155e-01, time/batch = 17.3081s	
7573/33650 (epoch 11.253), train_loss = 1.03464873, grad/param norm = 1.3241e-01, time/batch = 17.3028s	
7574/33650 (epoch 11.254), train_loss = 1.05773484, grad/param norm = 1.4220e-01, time/batch = 17.6370s	
7575/33650 (epoch 11.256), train_loss = 1.26132603, grad/param norm = 1.3566e-01, time/batch = 17.9775s	
7576/33650 (epoch 11.257), train_loss = 1.33132636, grad/param norm = 1.5332e-01, time/batch = 17.5592s	
7577/33650 (epoch 11.259), train_loss = 1.00067474, grad/param norm = 1.4035e-01, time/batch = 17.4681s	
7578/33650 (epoch 11.260), train_loss = 1.30917663, grad/param norm = 1.5513e-01, time/batch = 18.0669s	
7579/33650 (epoch 11.262), train_loss = 1.22930791, grad/param norm = 1.5682e-01, time/batch = 16.3679s	
7580/33650 (epoch 11.263), train_loss = 1.17190200, grad/param norm = 1.8962e-01, time/batch = 16.3840s	
7581/33650 (epoch 11.264), train_loss = 1.17734472, grad/param norm = 1.5300e-01, time/batch = 17.6515s	
7582/33650 (epoch 11.266), train_loss = 1.16906262, grad/param norm = 1.4395e-01, time/batch = 18.3206s	
7583/33650 (epoch 11.267), train_loss = 1.09338280, grad/param norm = 1.6890e-01, time/batch = 16.7283s	
7584/33650 (epoch 11.269), train_loss = 1.19921150, grad/param norm = 1.4397e-01, time/batch = 17.4698s	
7585/33650 (epoch 11.270), train_loss = 1.09518960, grad/param norm = 1.3642e-01, time/batch = 18.3043s	
7586/33650 (epoch 11.272), train_loss = 1.13189426, grad/param norm = 1.4106e-01, time/batch = 18.4841s	
7587/33650 (epoch 11.273), train_loss = 1.31586068, grad/param norm = 1.7385e-01, time/batch = 16.7170s	
7588/33650 (epoch 11.275), train_loss = 1.27156641, grad/param norm = 1.6377e-01, time/batch = 18.4773s	
7589/33650 (epoch 11.276), train_loss = 1.33476107, grad/param norm = 1.5891e-01, time/batch = 17.8990s	
7590/33650 (epoch 11.278), train_loss = 1.42277730, grad/param norm = 1.7231e-01, time/batch = 17.0634s	
7591/33650 (epoch 11.279), train_loss = 1.10322673, grad/param norm = 1.4418e-01, time/batch = 17.0682s	
7592/33650 (epoch 11.281), train_loss = 1.19650063, grad/param norm = 1.5579e-01, time/batch = 18.1388s	
7593/33650 (epoch 11.282), train_loss = 1.28188707, grad/param norm = 1.4392e-01, time/batch = 15.6371s	
7594/33650 (epoch 11.284), train_loss = 1.26881875, grad/param norm = 1.5006e-01, time/batch = 17.3112s	
7595/33650 (epoch 11.285), train_loss = 1.28804627, grad/param norm = 1.5949e-01, time/batch = 18.8106s	
7596/33650 (epoch 11.287), train_loss = 1.16281321, grad/param norm = 1.4433e-01, time/batch = 17.9687s	
7597/33650 (epoch 11.288), train_loss = 1.21999969, grad/param norm = 1.6345e-01, time/batch = 16.8982s	
7598/33650 (epoch 11.290), train_loss = 1.18960035, grad/param norm = 1.3858e-01, time/batch = 16.8662s	
7599/33650 (epoch 11.291), train_loss = 1.05608114, grad/param norm = 1.2905e-01, time/batch = 17.0725s	
7600/33650 (epoch 11.293), train_loss = 1.16617280, grad/param norm = 1.5528e-01, time/batch = 15.7245s	
7601/33650 (epoch 11.294), train_loss = 1.05029229, grad/param norm = 1.3931e-01, time/batch = 17.5451s	
7602/33650 (epoch 11.296), train_loss = 1.04620654, grad/param norm = 1.4063e-01, time/batch = 17.9923s	
7603/33650 (epoch 11.297), train_loss = 1.14615760, grad/param norm = 1.4689e-01, time/batch = 18.4098s	
7604/33650 (epoch 11.299), train_loss = 1.03683457, grad/param norm = 1.2211e-01, time/batch = 16.5507s	
7605/33650 (epoch 11.300), train_loss = 1.07755977, grad/param norm = 1.5192e-01, time/batch = 17.7304s	
7606/33650 (epoch 11.302), train_loss = 1.18552601, grad/param norm = 1.3699e-01, time/batch = 18.6547s	
7607/33650 (epoch 11.303), train_loss = 1.16919564, grad/param norm = 1.3444e-01, time/batch = 17.5625s	
7608/33650 (epoch 11.305), train_loss = 1.22038679, grad/param norm = 1.5019e-01, time/batch = 17.0528s	
7609/33650 (epoch 11.306), train_loss = 1.10017580, grad/param norm = 1.3873e-01, time/batch = 17.9772s	
7610/33650 (epoch 11.308), train_loss = 1.07259526, grad/param norm = 1.4801e-01, time/batch = 17.8922s	
7611/33650 (epoch 11.309), train_loss = 1.36578516, grad/param norm = 1.7295e-01, time/batch = 17.8032s	
7612/33650 (epoch 11.311), train_loss = 1.21945752, grad/param norm = 1.4589e-01, time/batch = 18.2278s	
7613/33650 (epoch 11.312), train_loss = 1.14731191, grad/param norm = 1.4953e-01, time/batch = 17.5683s	
7614/33650 (epoch 11.314), train_loss = 0.97974742, grad/param norm = 1.3006e-01, time/batch = 15.9565s	
7615/33650 (epoch 11.315), train_loss = 1.18202099, grad/param norm = 1.6088e-01, time/batch = 17.9830s	
7616/33650 (epoch 11.316), train_loss = 1.12071061, grad/param norm = 1.4935e-01, time/batch = 16.7103s	
7617/33650 (epoch 11.318), train_loss = 1.02977279, grad/param norm = 1.2102e-01, time/batch = 17.2352s	
7618/33650 (epoch 11.319), train_loss = 1.05560712, grad/param norm = 1.3292e-01, time/batch = 17.4704s	
7619/33650 (epoch 11.321), train_loss = 1.10869484, grad/param norm = 1.4000e-01, time/batch = 18.2351s	
7620/33650 (epoch 11.322), train_loss = 1.21736673, grad/param norm = 1.5839e-01, time/batch = 18.0698s	
7621/33650 (epoch 11.324), train_loss = 1.23958316, grad/param norm = 1.7335e-01, time/batch = 16.2103s	
7622/33650 (epoch 11.325), train_loss = 1.23622084, grad/param norm = 1.4988e-01, time/batch = 18.2183s	
7623/33650 (epoch 11.327), train_loss = 1.02770324, grad/param norm = 1.2843e-01, time/batch = 16.9883s	
7624/33650 (epoch 11.328), train_loss = 1.23553222, grad/param norm = 1.5960e-01, time/batch = 17.6348s	
7625/33650 (epoch 11.330), train_loss = 1.04633775, grad/param norm = 1.2248e-01, time/batch = 17.2132s	
7626/33650 (epoch 11.331), train_loss = 0.96635568, grad/param norm = 1.2104e-01, time/batch = 17.9805s	
7627/33650 (epoch 11.333), train_loss = 1.13158844, grad/param norm = 1.4890e-01, time/batch = 17.7111s	
7628/33650 (epoch 11.334), train_loss = 1.13073329, grad/param norm = 1.3363e-01, time/batch = 17.3773s	
7629/33650 (epoch 11.336), train_loss = 1.26661249, grad/param norm = 1.4669e-01, time/batch = 17.9858s	
7630/33650 (epoch 11.337), train_loss = 0.93293316, grad/param norm = 1.2279e-01, time/batch = 17.4883s	
7631/33650 (epoch 11.339), train_loss = 1.11984499, grad/param norm = 1.3966e-01, time/batch = 15.8824s	
7632/33650 (epoch 11.340), train_loss = 1.38383537, grad/param norm = 1.7007e-01, time/batch = 17.4045s	
7633/33650 (epoch 11.342), train_loss = 0.95666030, grad/param norm = 1.2739e-01, time/batch = 17.4021s	
7634/33650 (epoch 11.343), train_loss = 1.23649260, grad/param norm = 1.5881e-01, time/batch = 17.7251s	
7635/33650 (epoch 11.345), train_loss = 1.11993771, grad/param norm = 1.4180e-01, time/batch = 17.8811s	
7636/33650 (epoch 11.346), train_loss = 0.83540320, grad/param norm = 1.2644e-01, time/batch = 17.5668s	
7637/33650 (epoch 11.348), train_loss = 1.02242982, grad/param norm = 1.3474e-01, time/batch = 18.2284s	
7638/33650 (epoch 11.349), train_loss = 0.95928754, grad/param norm = 1.3520e-01, time/batch = 17.1368s	
7639/33650 (epoch 11.351), train_loss = 1.24027179, grad/param norm = 1.5697e-01, time/batch = 18.2280s	
7640/33650 (epoch 11.352), train_loss = 1.11238458, grad/param norm = 1.4033e-01, time/batch = 17.7271s	
7641/33650 (epoch 11.354), train_loss = 1.37950473, grad/param norm = 1.5967e-01, time/batch = 17.4046s	
7642/33650 (epoch 11.355), train_loss = 1.24055031, grad/param norm = 1.3685e-01, time/batch = 15.1318s	
7643/33650 (epoch 11.357), train_loss = 0.96713082, grad/param norm = 1.4196e-01, time/batch = 17.9781s	
7644/33650 (epoch 11.358), train_loss = 1.23817639, grad/param norm = 1.5465e-01, time/batch = 18.3999s	
7645/33650 (epoch 11.360), train_loss = 1.23870923, grad/param norm = 1.5998e-01, time/batch = 16.8083s	
7646/33650 (epoch 11.361), train_loss = 1.18077795, grad/param norm = 1.3552e-01, time/batch = 18.3983s	
7647/33650 (epoch 11.363), train_loss = 1.07873102, grad/param norm = 1.3814e-01, time/batch = 17.7320s	
7648/33650 (epoch 11.364), train_loss = 1.10781419, grad/param norm = 1.3124e-01, time/batch = 17.5572s	
7649/33650 (epoch 11.366), train_loss = 1.18332828, grad/param norm = 1.4663e-01, time/batch = 17.4029s	
7650/33650 (epoch 11.367), train_loss = 1.23803151, grad/param norm = 1.3259e-01, time/batch = 18.5636s	
7651/33650 (epoch 11.368), train_loss = 1.04933892, grad/param norm = 1.3645e-01, time/batch = 17.7758s	
7652/33650 (epoch 11.370), train_loss = 1.15450178, grad/param norm = 1.3922e-01, time/batch = 16.8929s	
7653/33650 (epoch 11.371), train_loss = 0.93165433, grad/param norm = 1.2964e-01, time/batch = 18.3150s	
7654/33650 (epoch 11.373), train_loss = 1.06715212, grad/param norm = 1.3154e-01, time/batch = 16.9795s	
7655/33650 (epoch 11.374), train_loss = 0.96982857, grad/param norm = 1.2477e-01, time/batch = 16.8833s	
7656/33650 (epoch 11.376), train_loss = 1.13628663, grad/param norm = 1.5961e-01, time/batch = 17.7365s	
7657/33650 (epoch 11.377), train_loss = 1.19481662, grad/param norm = 1.5615e-01, time/batch = 18.8972s	
7658/33650 (epoch 11.379), train_loss = 1.21597296, grad/param norm = 1.4271e-01, time/batch = 17.3924s	
7659/33650 (epoch 11.380), train_loss = 0.93052950, grad/param norm = 1.4758e-01, time/batch = 16.6547s	
7660/33650 (epoch 11.382), train_loss = 0.99468036, grad/param norm = 1.1792e-01, time/batch = 17.3252s	
7661/33650 (epoch 11.383), train_loss = 1.11215959, grad/param norm = 1.3699e-01, time/batch = 18.8149s	
7662/33650 (epoch 11.385), train_loss = 1.26896103, grad/param norm = 1.4423e-01, time/batch = 16.7165s	
7663/33650 (epoch 11.386), train_loss = 1.05058325, grad/param norm = 1.3494e-01, time/batch = 17.5716s	
7664/33650 (epoch 11.388), train_loss = 1.18584779, grad/param norm = 1.3515e-01, time/batch = 13.7331s	
7665/33650 (epoch 11.389), train_loss = 1.15053544, grad/param norm = 1.5020e-01, time/batch = 16.7961s	
7666/33650 (epoch 11.391), train_loss = 0.94735690, grad/param norm = 1.2992e-01, time/batch = 17.6271s	
7667/33650 (epoch 11.392), train_loss = 1.22133509, grad/param norm = 1.4069e-01, time/batch = 17.2139s	
7668/33650 (epoch 11.394), train_loss = 1.26302109, grad/param norm = 1.6514e-01, time/batch = 18.7242s	
7669/33650 (epoch 11.395), train_loss = 1.17122057, grad/param norm = 1.4992e-01, time/batch = 16.6449s	
7670/33650 (epoch 11.397), train_loss = 1.33931018, grad/param norm = 1.5394e-01, time/batch = 18.3993s	
7671/33650 (epoch 11.398), train_loss = 1.17463634, grad/param norm = 1.3683e-01, time/batch = 18.5577s	
7672/33650 (epoch 11.400), train_loss = 1.15811769, grad/param norm = 1.6456e-01, time/batch = 18.1292s	
7673/33650 (epoch 11.401), train_loss = 1.16148238, grad/param norm = 1.6377e-01, time/batch = 17.7345s	
7674/33650 (epoch 11.403), train_loss = 1.22467972, grad/param norm = 1.5444e-01, time/batch = 16.7345s	
7675/33650 (epoch 11.404), train_loss = 1.11613242, grad/param norm = 1.2159e-01, time/batch = 16.7169s	
7676/33650 (epoch 11.406), train_loss = 1.20171760, grad/param norm = 1.4346e-01, time/batch = 17.8073s	
7677/33650 (epoch 11.407), train_loss = 1.17432377, grad/param norm = 1.5390e-01, time/batch = 17.8205s	
7678/33650 (epoch 11.409), train_loss = 1.15769658, grad/param norm = 1.4167e-01, time/batch = 18.0028s	
7679/33650 (epoch 11.410), train_loss = 1.17736977, grad/param norm = 1.6049e-01, time/batch = 16.4749s	
7680/33650 (epoch 11.412), train_loss = 1.15623650, grad/param norm = 1.3032e-01, time/batch = 17.5689s	
7681/33650 (epoch 11.413), train_loss = 1.05852498, grad/param norm = 1.3595e-01, time/batch = 17.8191s	
7682/33650 (epoch 11.415), train_loss = 1.22082428, grad/param norm = 1.4220e-01, time/batch = 17.5580s	
7683/33650 (epoch 11.416), train_loss = 1.32555689, grad/param norm = 1.5019e-01, time/batch = 17.6492s	
7684/33650 (epoch 11.418), train_loss = 1.16096206, grad/param norm = 1.5217e-01, time/batch = 17.3259s	
7685/33650 (epoch 11.419), train_loss = 1.10498970, grad/param norm = 1.4901e-01, time/batch = 16.8641s	
7686/33650 (epoch 11.421), train_loss = 1.08036433, grad/param norm = 1.2453e-01, time/batch = 15.9709s	
7687/33650 (epoch 11.422), train_loss = 1.25901839, grad/param norm = 1.4372e-01, time/batch = 17.9818s	
7688/33650 (epoch 11.423), train_loss = 1.00969916, grad/param norm = 1.2673e-01, time/batch = 18.0776s	
7689/33650 (epoch 11.425), train_loss = 1.18104635, grad/param norm = 1.5740e-01, time/batch = 23.4847s	
7690/33650 (epoch 11.426), train_loss = 1.30971017, grad/param norm = 1.6429e-01, time/batch = 24.6518s	
7691/33650 (epoch 11.428), train_loss = 1.09438390, grad/param norm = 1.4029e-01, time/batch = 17.8985s	
7692/33650 (epoch 11.429), train_loss = 1.25140430, grad/param norm = 1.6138e-01, time/batch = 16.3027s	
7693/33650 (epoch 11.431), train_loss = 1.37607520, grad/param norm = 1.6808e-01, time/batch = 17.2297s	
7694/33650 (epoch 11.432), train_loss = 1.44956842, grad/param norm = 1.6783e-01, time/batch = 18.6483s	
7695/33650 (epoch 11.434), train_loss = 1.23945520, grad/param norm = 1.4566e-01, time/batch = 16.2860s	
7696/33650 (epoch 11.435), train_loss = 1.20559797, grad/param norm = 1.5476e-01, time/batch = 18.0528s	
7697/33650 (epoch 11.437), train_loss = 1.20354694, grad/param norm = 1.4873e-01, time/batch = 17.9822s	
7698/33650 (epoch 11.438), train_loss = 1.09500700, grad/param norm = 1.5264e-01, time/batch = 18.4051s	
7699/33650 (epoch 11.440), train_loss = 1.19565940, grad/param norm = 1.5009e-01, time/batch = 17.7201s	
7700/33650 (epoch 11.441), train_loss = 1.22145826, grad/param norm = 1.5828e-01, time/batch = 17.8133s	
7701/33650 (epoch 11.443), train_loss = 1.20561470, grad/param norm = 1.4670e-01, time/batch = 17.3881s	
7702/33650 (epoch 11.444), train_loss = 1.10065263, grad/param norm = 1.3050e-01, time/batch = 15.4431s	
7703/33650 (epoch 11.446), train_loss = 1.21706766, grad/param norm = 1.5721e-01, time/batch = 17.8136s	
7704/33650 (epoch 11.447), train_loss = 1.27623350, grad/param norm = 1.6338e-01, time/batch = 17.9760s	
7705/33650 (epoch 11.449), train_loss = 1.37279056, grad/param norm = 1.7957e-01, time/batch = 17.6301s	
7706/33650 (epoch 11.450), train_loss = 1.40105567, grad/param norm = 1.6986e-01, time/batch = 17.0611s	
7707/33650 (epoch 11.452), train_loss = 1.44776679, grad/param norm = 1.6703e-01, time/batch = 18.3213s	
7708/33650 (epoch 11.453), train_loss = 1.36110725, grad/param norm = 1.6815e-01, time/batch = 18.6452s	
7709/33650 (epoch 11.455), train_loss = 1.14533169, grad/param norm = 1.3996e-01, time/batch = 17.0477s	
7710/33650 (epoch 11.456), train_loss = 1.15141818, grad/param norm = 1.2885e-01, time/batch = 17.1441s	
7711/33650 (epoch 11.458), train_loss = 1.13884160, grad/param norm = 1.4871e-01, time/batch = 18.1519s	
7712/33650 (epoch 11.459), train_loss = 1.18378095, grad/param norm = 1.6279e-01, time/batch = 17.3933s	
7713/33650 (epoch 11.461), train_loss = 1.36488457, grad/param norm = 1.5890e-01, time/batch = 16.9758s	
7714/33650 (epoch 11.462), train_loss = 1.32392059, grad/param norm = 1.6672e-01, time/batch = 18.0367s	
7715/33650 (epoch 11.464), train_loss = 1.10383007, grad/param norm = 1.4321e-01, time/batch = 17.0657s	
7716/33650 (epoch 11.465), train_loss = 1.21697113, grad/param norm = 1.5637e-01, time/batch = 16.9462s	
7717/33650 (epoch 11.467), train_loss = 1.25335287, grad/param norm = 1.5929e-01, time/batch = 17.4828s	
7718/33650 (epoch 11.468), train_loss = 1.31255818, grad/param norm = 1.5564e-01, time/batch = 18.2336s	
7719/33650 (epoch 11.470), train_loss = 1.44239422, grad/param norm = 1.7409e-01, time/batch = 17.0552s	
7720/33650 (epoch 11.471), train_loss = 1.18705092, grad/param norm = 1.6066e-01, time/batch = 17.6454s	
7721/33650 (epoch 11.473), train_loss = 1.13186115, grad/param norm = 1.3939e-01, time/batch = 17.6543s	
7722/33650 (epoch 11.474), train_loss = 1.24381151, grad/param norm = 1.4878e-01, time/batch = 17.8923s	
7723/33650 (epoch 11.475), train_loss = 1.26890930, grad/param norm = 1.5716e-01, time/batch = 17.5591s	
7724/33650 (epoch 11.477), train_loss = 1.28828566, grad/param norm = 1.4794e-01, time/batch = 17.9830s	
7725/33650 (epoch 11.478), train_loss = 1.31393767, grad/param norm = 1.6474e-01, time/batch = 17.2319s	
7726/33650 (epoch 11.480), train_loss = 1.28987523, grad/param norm = 1.5762e-01, time/batch = 17.3983s	
7727/33650 (epoch 11.481), train_loss = 1.33395013, grad/param norm = 1.5608e-01, time/batch = 18.1486s	
7728/33650 (epoch 11.483), train_loss = 0.97555440, grad/param norm = 1.5712e-01, time/batch = 17.8227s	
7729/33650 (epoch 11.484), train_loss = 1.19622109, grad/param norm = 1.4189e-01, time/batch = 17.6562s	
7730/33650 (epoch 11.486), train_loss = 1.32890023, grad/param norm = 1.6872e-01, time/batch = 17.9007s	
7731/33650 (epoch 11.487), train_loss = 1.33295282, grad/param norm = 1.7624e-01, time/batch = 18.1504s	
7732/33650 (epoch 11.489), train_loss = 1.38656466, grad/param norm = 1.5503e-01, time/batch = 17.5534s	
7733/33650 (epoch 11.490), train_loss = 1.09342422, grad/param norm = 1.4721e-01, time/batch = 18.2193s	
7734/33650 (epoch 11.492), train_loss = 1.25510654, grad/param norm = 1.6959e-01, time/batch = 16.8809s	
7735/33650 (epoch 11.493), train_loss = 0.97952471, grad/param norm = 1.2447e-01, time/batch = 16.9643s	
7736/33650 (epoch 11.495), train_loss = 1.19417505, grad/param norm = 1.4695e-01, time/batch = 17.3105s	
7737/33650 (epoch 11.496), train_loss = 1.25478251, grad/param norm = 1.5930e-01, time/batch = 17.9733s	
7738/33650 (epoch 11.498), train_loss = 1.04254588, grad/param norm = 1.2977e-01, time/batch = 17.8931s	
7739/33650 (epoch 11.499), train_loss = 1.16369847, grad/param norm = 1.3448e-01, time/batch = 17.6320s	
7740/33650 (epoch 11.501), train_loss = 1.13359208, grad/param norm = 1.3721e-01, time/batch = 16.1419s	
7741/33650 (epoch 11.502), train_loss = 1.21440462, grad/param norm = 1.5320e-01, time/batch = 17.8819s	
7742/33650 (epoch 11.504), train_loss = 1.32166861, grad/param norm = 1.7080e-01, time/batch = 18.7351s	
7743/33650 (epoch 11.505), train_loss = 1.17804713, grad/param norm = 1.5956e-01, time/batch = 17.1389s	
7744/33650 (epoch 11.507), train_loss = 1.34481293, grad/param norm = 1.5654e-01, time/batch = 17.7106s	
7745/33650 (epoch 11.508), train_loss = 1.11828145, grad/param norm = 1.4120e-01, time/batch = 18.7254s	
7746/33650 (epoch 11.510), train_loss = 1.17361704, grad/param norm = 1.4288e-01, time/batch = 17.0621s	
7747/33650 (epoch 11.511), train_loss = 1.43204888, grad/param norm = 1.6824e-01, time/batch = 18.0389s	
7748/33650 (epoch 11.513), train_loss = 1.26154904, grad/param norm = 1.5292e-01, time/batch = 17.9029s	
7749/33650 (epoch 11.514), train_loss = 1.31642124, grad/param norm = 1.6573e-01, time/batch = 17.0701s	
7750/33650 (epoch 11.516), train_loss = 1.20285412, grad/param norm = 1.6156e-01, time/batch = 17.2171s	
7751/33650 (epoch 11.517), train_loss = 1.19896869, grad/param norm = 1.5652e-01, time/batch = 16.8836s	
7752/33650 (epoch 11.519), train_loss = 1.21599822, grad/param norm = 1.4279e-01, time/batch = 18.3073s	
7753/33650 (epoch 11.520), train_loss = 1.01940903, grad/param norm = 1.3175e-01, time/batch = 17.2133s	
7754/33650 (epoch 11.522), train_loss = 1.20806165, grad/param norm = 1.5756e-01, time/batch = 17.9742s	
7755/33650 (epoch 11.523), train_loss = 1.17047792, grad/param norm = 1.4404e-01, time/batch = 18.4857s	
7756/33650 (epoch 11.525), train_loss = 0.93210949, grad/param norm = 1.2793e-01, time/batch = 17.7192s	
7757/33650 (epoch 11.526), train_loss = 1.25195564, grad/param norm = 1.3942e-01, time/batch = 17.9800s	
7758/33650 (epoch 11.527), train_loss = 1.08675130, grad/param norm = 1.3940e-01, time/batch = 17.8949s	
7759/33650 (epoch 11.529), train_loss = 1.17670324, grad/param norm = 1.4606e-01, time/batch = 18.2316s	
7760/33650 (epoch 11.530), train_loss = 1.12332645, grad/param norm = 1.4568e-01, time/batch = 17.0616s	
7761/33650 (epoch 11.532), train_loss = 1.39414582, grad/param norm = 1.8557e-01, time/batch = 18.0644s	
7762/33650 (epoch 11.533), train_loss = 1.14601358, grad/param norm = 1.4697e-01, time/batch = 16.8057s	
7763/33650 (epoch 11.535), train_loss = 1.29675839, grad/param norm = 1.5653e-01, time/batch = 17.2220s	
7764/33650 (epoch 11.536), train_loss = 1.21571772, grad/param norm = 1.5647e-01, time/batch = 18.3883s	
7765/33650 (epoch 11.538), train_loss = 1.24766074, grad/param norm = 1.6147e-01, time/batch = 16.6522s	
7766/33650 (epoch 11.539), train_loss = 0.98363943, grad/param norm = 1.3742e-01, time/batch = 17.5537s	
7767/33650 (epoch 11.541), train_loss = 1.33746788, grad/param norm = 1.6359e-01, time/batch = 17.6419s	
7768/33650 (epoch 11.542), train_loss = 1.22328341, grad/param norm = 1.7182e-01, time/batch = 17.7305s	
7769/33650 (epoch 11.544), train_loss = 1.41193225, grad/param norm = 1.6422e-01, time/batch = 17.0580s	
7770/33650 (epoch 11.545), train_loss = 1.05184377, grad/param norm = 1.3311e-01, time/batch = 17.4708s	
7771/33650 (epoch 11.547), train_loss = 1.20165481, grad/param norm = 1.4086e-01, time/batch = 18.3989s	
7772/33650 (epoch 11.548), train_loss = 1.35408646, grad/param norm = 1.5175e-01, time/batch = 18.1481s	
7773/33650 (epoch 11.550), train_loss = 1.15863175, grad/param norm = 1.4259e-01, time/batch = 17.2182s	
7774/33650 (epoch 11.551), train_loss = 1.19238746, grad/param norm = 1.5699e-01, time/batch = 17.8800s	
7775/33650 (epoch 11.553), train_loss = 1.02552062, grad/param norm = 1.4189e-01, time/batch = 16.9776s	
7776/33650 (epoch 11.554), train_loss = 1.32141233, grad/param norm = 1.4704e-01, time/batch = 17.4838s	
7777/33650 (epoch 11.556), train_loss = 1.28188892, grad/param norm = 1.7028e-01, time/batch = 16.6209s	
7778/33650 (epoch 11.557), train_loss = 1.34486199, grad/param norm = 1.6423e-01, time/batch = 18.4713s	
7779/33650 (epoch 11.559), train_loss = 1.48075160, grad/param norm = 1.9056e-01, time/batch = 18.3906s	
7780/33650 (epoch 11.560), train_loss = 1.40450292, grad/param norm = 1.5709e-01, time/batch = 16.9828s	
7781/33650 (epoch 11.562), train_loss = 1.27180206, grad/param norm = 1.3990e-01, time/batch = 18.1450s	
7782/33650 (epoch 11.563), train_loss = 1.18317464, grad/param norm = 1.5811e-01, time/batch = 18.4014s	
7783/33650 (epoch 11.565), train_loss = 1.20907058, grad/param norm = 1.4627e-01, time/batch = 16.5473s	
7784/33650 (epoch 11.566), train_loss = 1.20560724, grad/param norm = 1.4937e-01, time/batch = 17.3244s	
7785/33650 (epoch 11.568), train_loss = 1.20170664, grad/param norm = 1.4731e-01, time/batch = 18.3211s	
7786/33650 (epoch 11.569), train_loss = 1.15162150, grad/param norm = 1.5231e-01, time/batch = 16.9879s	
7787/33650 (epoch 11.571), train_loss = 1.33837749, grad/param norm = 1.5691e-01, time/batch = 17.3911s	
7788/33650 (epoch 11.572), train_loss = 1.25169096, grad/param norm = 1.3580e-01, time/batch = 18.3229s	
7789/33650 (epoch 11.574), train_loss = 1.20843156, grad/param norm = 1.5855e-01, time/batch = 17.8132s	
7790/33650 (epoch 11.575), train_loss = 1.16843473, grad/param norm = 1.4132e-01, time/batch = 17.3782s	
7791/33650 (epoch 11.577), train_loss = 1.21748592, grad/param norm = 1.5701e-01, time/batch = 18.2207s	
7792/33650 (epoch 11.578), train_loss = 1.25060513, grad/param norm = 1.5031e-01, time/batch = 17.7332s	
7793/33650 (epoch 11.579), train_loss = 1.25824115, grad/param norm = 1.4472e-01, time/batch = 18.3088s	
7794/33650 (epoch 11.581), train_loss = 1.27942650, grad/param norm = 1.4481e-01, time/batch = 16.6515s	
7795/33650 (epoch 11.582), train_loss = 1.28925180, grad/param norm = 1.3799e-01, time/batch = 17.7254s	
7796/33650 (epoch 11.584), train_loss = 1.23205984, grad/param norm = 1.4778e-01, time/batch = 18.4835s	
7797/33650 (epoch 11.585), train_loss = 1.26434604, grad/param norm = 1.5732e-01, time/batch = 16.6480s	
7798/33650 (epoch 11.587), train_loss = 1.09679240, grad/param norm = 1.5092e-01, time/batch = 18.2291s	
7799/33650 (epoch 11.588), train_loss = 1.16912328, grad/param norm = 1.6160e-01, time/batch = 15.7835s	
7800/33650 (epoch 11.590), train_loss = 1.15642627, grad/param norm = 1.4040e-01, time/batch = 17.6439s	
7801/33650 (epoch 11.591), train_loss = 1.15232127, grad/param norm = 1.6293e-01, time/batch = 18.0667s	
7802/33650 (epoch 11.593), train_loss = 1.10751842, grad/param norm = 1.2870e-01, time/batch = 17.8188s	
7803/33650 (epoch 11.594), train_loss = 1.02502399, grad/param norm = 1.4884e-01, time/batch = 17.8142s	
7804/33650 (epoch 11.596), train_loss = 1.13562578, grad/param norm = 1.2775e-01, time/batch = 16.9712s	
7805/33650 (epoch 11.597), train_loss = 0.97153904, grad/param norm = 1.2145e-01, time/batch = 18.1452s	
7806/33650 (epoch 11.599), train_loss = 1.11580416, grad/param norm = 1.4285e-01, time/batch = 17.7403s	
7807/33650 (epoch 11.600), train_loss = 1.03145648, grad/param norm = 1.2822e-01, time/batch = 17.5509s	
7808/33650 (epoch 11.602), train_loss = 1.27546745, grad/param norm = 1.5287e-01, time/batch = 17.4749s	
7809/33650 (epoch 11.603), train_loss = 1.11791806, grad/param norm = 1.3618e-01, time/batch = 17.0505s	
7810/33650 (epoch 11.605), train_loss = 1.21323797, grad/param norm = 1.4945e-01, time/batch = 18.2411s	
7811/33650 (epoch 11.606), train_loss = 1.27730743, grad/param norm = 1.5518e-01, time/batch = 16.6407s	
7812/33650 (epoch 11.608), train_loss = 1.12888716, grad/param norm = 1.4662e-01, time/batch = 18.1444s	
7813/33650 (epoch 11.609), train_loss = 1.21015980, grad/param norm = 1.5117e-01, time/batch = 17.8177s	
7814/33650 (epoch 11.611), train_loss = 1.06157876, grad/param norm = 1.4262e-01, time/batch = 16.4783s	
7815/33650 (epoch 11.612), train_loss = 1.17406882, grad/param norm = 1.4973e-01, time/batch = 18.4899s	
7816/33650 (epoch 11.614), train_loss = 1.25047679, grad/param norm = 1.5996e-01, time/batch = 17.8926s	
7817/33650 (epoch 11.615), train_loss = 1.13845138, grad/param norm = 1.2754e-01, time/batch = 17.9704s	
7818/33650 (epoch 11.617), train_loss = 1.04538644, grad/param norm = 1.2080e-01, time/batch = 16.4758s	
7819/33650 (epoch 11.618), train_loss = 1.14682297, grad/param norm = 1.3882e-01, time/batch = 17.2996s	
7820/33650 (epoch 11.620), train_loss = 1.23776865, grad/param norm = 1.6015e-01, time/batch = 18.4887s	
7821/33650 (epoch 11.621), train_loss = 1.04999724, grad/param norm = 1.3460e-01, time/batch = 17.2212s	
7822/33650 (epoch 11.623), train_loss = 1.15594535, grad/param norm = 1.3747e-01, time/batch = 17.9673s	
7823/33650 (epoch 11.624), train_loss = 0.90524935, grad/param norm = 1.2532e-01, time/batch = 18.0592s	
7824/33650 (epoch 11.626), train_loss = 0.91694136, grad/param norm = 1.2297e-01, time/batch = 17.1510s	
7825/33650 (epoch 11.627), train_loss = 1.12198651, grad/param norm = 1.4173e-01, time/batch = 16.2125s	
7826/33650 (epoch 11.629), train_loss = 1.14533793, grad/param norm = 1.3382e-01, time/batch = 17.3193s	
7827/33650 (epoch 11.630), train_loss = 1.26383851, grad/param norm = 1.5500e-01, time/batch = 17.1332s	
7828/33650 (epoch 11.632), train_loss = 1.27627032, grad/param norm = 1.4124e-01, time/batch = 17.0578s	
7829/33650 (epoch 11.633), train_loss = 1.27034035, grad/param norm = 1.4042e-01, time/batch = 17.8889s	
7830/33650 (epoch 11.634), train_loss = 0.99476735, grad/param norm = 1.3479e-01, time/batch = 17.3011s	
7831/33650 (epoch 11.636), train_loss = 0.90348919, grad/param norm = 1.1476e-01, time/batch = 17.3881s	
7832/33650 (epoch 11.637), train_loss = 1.17098784, grad/param norm = 1.5298e-01, time/batch = 17.8064s	
7833/33650 (epoch 11.639), train_loss = 1.09921994, grad/param norm = 1.4266e-01, time/batch = 17.4141s	
7834/33650 (epoch 11.640), train_loss = 1.16468652, grad/param norm = 1.3952e-01, time/batch = 17.8976s	
7835/33650 (epoch 11.642), train_loss = 1.28192570, grad/param norm = 1.6267e-01, time/batch = 17.7312s	
7836/33650 (epoch 11.643), train_loss = 1.17883430, grad/param norm = 1.4662e-01, time/batch = 18.0625s	
7837/33650 (epoch 11.645), train_loss = 1.16770403, grad/param norm = 1.4147e-01, time/batch = 18.0679s	
7838/33650 (epoch 11.646), train_loss = 0.96646529, grad/param norm = 1.2423e-01, time/batch = 16.3911s	
7839/33650 (epoch 11.648), train_loss = 1.17617361, grad/param norm = 1.3731e-01, time/batch = 18.2313s	
7840/33650 (epoch 11.649), train_loss = 1.18816463, grad/param norm = 1.7081e-01, time/batch = 17.8132s	
7841/33650 (epoch 11.651), train_loss = 1.30425258, grad/param norm = 1.5584e-01, time/batch = 17.2226s	
7842/33650 (epoch 11.652), train_loss = 0.85939898, grad/param norm = 1.0886e-01, time/batch = 18.3093s	
7843/33650 (epoch 11.654), train_loss = 1.09340087, grad/param norm = 1.4105e-01, time/batch = 18.3895s	
7844/33650 (epoch 11.655), train_loss = 1.03128914, grad/param norm = 1.2670e-01, time/batch = 16.2127s	
7845/33650 (epoch 11.657), train_loss = 1.14716526, grad/param norm = 1.5182e-01, time/batch = 16.7103s	
7846/33650 (epoch 11.658), train_loss = 1.01674628, grad/param norm = 1.3312e-01, time/batch = 18.1503s	
7847/33650 (epoch 11.660), train_loss = 0.97464906, grad/param norm = 1.2249e-01, time/batch = 17.8212s	
7848/33650 (epoch 11.661), train_loss = 1.08279092, grad/param norm = 1.3240e-01, time/batch = 16.9019s	
7849/33650 (epoch 11.663), train_loss = 1.01851094, grad/param norm = 1.5770e-01, time/batch = 17.9882s	
7850/33650 (epoch 11.664), train_loss = 1.00318345, grad/param norm = 1.1918e-01, time/batch = 16.9730s	
7851/33650 (epoch 11.666), train_loss = 1.09395971, grad/param norm = 1.3569e-01, time/batch = 18.0442s	
7852/33650 (epoch 11.667), train_loss = 1.06200377, grad/param norm = 1.3923e-01, time/batch = 17.8909s	
7853/33650 (epoch 11.669), train_loss = 1.04677145, grad/param norm = 1.4025e-01, time/batch = 18.2366s	
7854/33650 (epoch 11.670), train_loss = 0.96750866, grad/param norm = 1.4206e-01, time/batch = 17.7298s	
7855/33650 (epoch 11.672), train_loss = 0.99958080, grad/param norm = 1.4140e-01, time/batch = 17.3892s	
7856/33650 (epoch 11.673), train_loss = 0.93770229, grad/param norm = 1.3968e-01, time/batch = 17.6419s	
7857/33650 (epoch 11.675), train_loss = 0.91414571, grad/param norm = 1.1567e-01, time/batch = 18.8998s	
7858/33650 (epoch 11.676), train_loss = 1.13784299, grad/param norm = 1.4541e-01, time/batch = 16.3808s	
7859/33650 (epoch 11.678), train_loss = 1.03864561, grad/param norm = 1.2958e-01, time/batch = 17.7241s	
7860/33650 (epoch 11.679), train_loss = 1.09679805, grad/param norm = 1.4541e-01, time/batch = 18.1511s	
7861/33650 (epoch 11.681), train_loss = 1.06217106, grad/param norm = 1.3288e-01, time/batch = 16.3710s	
7862/33650 (epoch 11.682), train_loss = 1.07512795, grad/param norm = 1.4557e-01, time/batch = 17.1346s	
7863/33650 (epoch 11.684), train_loss = 1.02098935, grad/param norm = 1.2830e-01, time/batch = 17.9085s	
7864/33650 (epoch 11.685), train_loss = 1.20831913, grad/param norm = 1.4902e-01, time/batch = 18.5619s	
7865/33650 (epoch 11.686), train_loss = 1.14735390, grad/param norm = 1.3978e-01, time/batch = 16.6344s	
7866/33650 (epoch 11.688), train_loss = 1.27230546, grad/param norm = 1.4678e-01, time/batch = 17.4821s	
7867/33650 (epoch 11.689), train_loss = 1.05601026, grad/param norm = 1.4025e-01, time/batch = 18.6483s	
7868/33650 (epoch 11.691), train_loss = 1.25579876, grad/param norm = 1.4316e-01, time/batch = 17.8875s	
7869/33650 (epoch 11.692), train_loss = 1.25334465, grad/param norm = 1.4814e-01, time/batch = 17.7247s	
7870/33650 (epoch 11.694), train_loss = 1.18367787, grad/param norm = 1.5749e-01, time/batch = 18.3227s	
7871/33650 (epoch 11.695), train_loss = 0.83869676, grad/param norm = 1.3038e-01, time/batch = 15.8720s	
7872/33650 (epoch 11.697), train_loss = 1.14062298, grad/param norm = 1.5422e-01, time/batch = 17.5402s	
7873/33650 (epoch 11.698), train_loss = 1.27756756, grad/param norm = 1.5186e-01, time/batch = 18.0486s	
7874/33650 (epoch 11.700), train_loss = 1.11599239, grad/param norm = 1.3847e-01, time/batch = 17.8919s	
7875/33650 (epoch 11.701), train_loss = 1.17100976, grad/param norm = 1.4831e-01, time/batch = 17.4691s	
7876/33650 (epoch 11.703), train_loss = 1.26034118, grad/param norm = 1.4089e-01, time/batch = 17.9726s	
7877/33650 (epoch 11.704), train_loss = 1.11118476, grad/param norm = 1.3910e-01, time/batch = 17.3161s	
7878/33650 (epoch 11.706), train_loss = 1.12157963, grad/param norm = 1.4299e-01, time/batch = 16.7305s	
7879/33650 (epoch 11.707), train_loss = 1.22225463, grad/param norm = 1.4851e-01, time/batch = 17.3803s	
7880/33650 (epoch 11.709), train_loss = 1.09312827, grad/param norm = 1.3742e-01, time/batch = 16.3011s	
7881/33650 (epoch 11.710), train_loss = 1.33711623, grad/param norm = 1.4788e-01, time/batch = 18.3992s	
7882/33650 (epoch 11.712), train_loss = 1.07172324, grad/param norm = 1.4278e-01, time/batch = 16.5468s	
7883/33650 (epoch 11.713), train_loss = 1.08546203, grad/param norm = 1.6642e-01, time/batch = 16.3987s	
7884/33650 (epoch 11.715), train_loss = 1.25152222, grad/param norm = 1.5283e-01, time/batch = 18.4763s	
7885/33650 (epoch 11.716), train_loss = 1.02731264, grad/param norm = 1.3540e-01, time/batch = 17.3115s	
7886/33650 (epoch 11.718), train_loss = 1.11974219, grad/param norm = 1.4998e-01, time/batch = 17.7151s	
7887/33650 (epoch 11.719), train_loss = 1.30688241, grad/param norm = 1.6348e-01, time/batch = 18.2394s	
7888/33650 (epoch 11.721), train_loss = 1.36224610, grad/param norm = 1.6272e-01, time/batch = 16.9748s	
7889/33650 (epoch 11.722), train_loss = 1.29475624, grad/param norm = 1.7446e-01, time/batch = 17.5596s	
7890/33650 (epoch 11.724), train_loss = 1.22819780, grad/param norm = 1.5629e-01, time/batch = 18.2195s	
7891/33650 (epoch 11.725), train_loss = 1.28563832, grad/param norm = 1.6224e-01, time/batch = 18.2405s	
7892/33650 (epoch 11.727), train_loss = 1.04308858, grad/param norm = 1.4151e-01, time/batch = 23.4652s	
7893/33650 (epoch 11.728), train_loss = 1.07189314, grad/param norm = 1.3448e-01, time/batch = 25.1720s	
7894/33650 (epoch 11.730), train_loss = 1.23963807, grad/param norm = 1.4985e-01, time/batch = 18.4119s	
7895/33650 (epoch 11.731), train_loss = 1.29048621, grad/param norm = 1.5173e-01, time/batch = 16.8976s	
7896/33650 (epoch 11.733), train_loss = 1.15406560, grad/param norm = 1.6270e-01, time/batch = 18.2078s	
7897/33650 (epoch 11.734), train_loss = 1.33209852, grad/param norm = 1.7508e-01, time/batch = 17.0733s	
7898/33650 (epoch 11.736), train_loss = 1.13693897, grad/param norm = 1.6839e-01, time/batch = 17.6411s	
7899/33650 (epoch 11.737), train_loss = 1.18507087, grad/param norm = 1.6162e-01, time/batch = 17.8980s	
7900/33650 (epoch 11.738), train_loss = 1.03732651, grad/param norm = 1.3509e-01, time/batch = 17.3939s	
7901/33650 (epoch 11.740), train_loss = 1.00727327, grad/param norm = 1.3319e-01, time/batch = 17.0447s	
7902/33650 (epoch 11.741), train_loss = 1.09242983, grad/param norm = 1.3870e-01, time/batch = 16.2071s	
7903/33650 (epoch 11.743), train_loss = 1.15909311, grad/param norm = 1.4199e-01, time/batch = 18.1434s	
7904/33650 (epoch 11.744), train_loss = 1.12242006, grad/param norm = 1.3818e-01, time/batch = 17.0616s	
7905/33650 (epoch 11.746), train_loss = 1.11269583, grad/param norm = 1.3858e-01, time/batch = 17.0625s	
7906/33650 (epoch 11.747), train_loss = 1.24529576, grad/param norm = 1.4120e-01, time/batch = 18.2947s	
7907/33650 (epoch 11.749), train_loss = 0.96317145, grad/param norm = 1.3515e-01, time/batch = 18.2352s	
7908/33650 (epoch 11.750), train_loss = 1.27038050, grad/param norm = 1.4987e-01, time/batch = 16.8123s	
7909/33650 (epoch 11.752), train_loss = 1.27930040, grad/param norm = 1.5202e-01, time/batch = 17.4774s	
7910/33650 (epoch 11.753), train_loss = 1.39973722, grad/param norm = 1.7566e-01, time/batch = 16.6445s	
7911/33650 (epoch 11.755), train_loss = 1.07131121, grad/param norm = 1.3471e-01, time/batch = 16.3313s	
7912/33650 (epoch 11.756), train_loss = 1.27184849, grad/param norm = 1.6091e-01, time/batch = 17.2129s	
7913/33650 (epoch 11.758), train_loss = 1.26432991, grad/param norm = 1.5217e-01, time/batch = 17.7189s	
7914/33650 (epoch 11.759), train_loss = 1.34802893, grad/param norm = 1.5783e-01, time/batch = 17.8983s	
7915/33650 (epoch 11.761), train_loss = 1.21789804, grad/param norm = 1.4432e-01, time/batch = 17.7214s	
7916/33650 (epoch 11.762), train_loss = 1.18550418, grad/param norm = 1.3996e-01, time/batch = 17.5650s	
7917/33650 (epoch 11.764), train_loss = 1.26063251, grad/param norm = 1.7305e-01, time/batch = 18.4027s	
7918/33650 (epoch 11.765), train_loss = 1.18024286, grad/param norm = 1.4326e-01, time/batch = 17.9851s	
7919/33650 (epoch 11.767), train_loss = 1.10846644, grad/param norm = 1.3521e-01, time/batch = 17.2123s	
7920/33650 (epoch 11.768), train_loss = 1.01077654, grad/param norm = 1.3073e-01, time/batch = 17.9839s	
7921/33650 (epoch 11.770), train_loss = 1.15364569, grad/param norm = 1.4653e-01, time/batch = 17.4920s	
7922/33650 (epoch 11.771), train_loss = 1.16448396, grad/param norm = 1.4546e-01, time/batch = 16.9020s	
7923/33650 (epoch 11.773), train_loss = 1.30553471, grad/param norm = 1.6732e-01, time/batch = 18.5622s	
7924/33650 (epoch 11.774), train_loss = 1.20119904, grad/param norm = 1.6653e-01, time/batch = 16.3872s	
7925/33650 (epoch 11.776), train_loss = 1.24978195, grad/param norm = 1.5568e-01, time/batch = 17.9699s	
7926/33650 (epoch 11.777), train_loss = 1.00908955, grad/param norm = 1.3592e-01, time/batch = 17.6394s	
7927/33650 (epoch 11.779), train_loss = 1.14872726, grad/param norm = 1.4636e-01, time/batch = 18.7294s	
7928/33650 (epoch 11.780), train_loss = 1.05518858, grad/param norm = 1.2701e-01, time/batch = 16.0563s	
7929/33650 (epoch 11.782), train_loss = 1.08687263, grad/param norm = 1.4279e-01, time/batch = 17.0550s	
7930/33650 (epoch 11.783), train_loss = 1.04207760, grad/param norm = 1.3620e-01, time/batch = 16.5606s	
7931/33650 (epoch 11.785), train_loss = 1.36875676, grad/param norm = 1.4525e-01, time/batch = 18.3161s	
7932/33650 (epoch 11.786), train_loss = 1.17908927, grad/param norm = 1.4235e-01, time/batch = 17.7294s	
7933/33650 (epoch 11.788), train_loss = 1.18027809, grad/param norm = 1.3922e-01, time/batch = 17.2322s	
7934/33650 (epoch 11.789), train_loss = 1.22235625, grad/param norm = 1.3532e-01, time/batch = 18.6343s	
7935/33650 (epoch 11.790), train_loss = 1.23142017, grad/param norm = 1.6595e-01, time/batch = 18.3993s	
7936/33650 (epoch 11.792), train_loss = 1.30895499, grad/param norm = 1.6844e-01, time/batch = 17.9728s	
7937/33650 (epoch 11.793), train_loss = 1.23770574, grad/param norm = 1.4825e-01, time/batch = 17.4759s	
7938/33650 (epoch 11.795), train_loss = 1.29245776, grad/param norm = 1.4190e-01, time/batch = 15.0586s	
7939/33650 (epoch 11.796), train_loss = 1.13577750, grad/param norm = 1.4701e-01, time/batch = 16.9798s	
7940/33650 (epoch 11.798), train_loss = 1.12858215, grad/param norm = 1.4241e-01, time/batch = 17.6561s	
7941/33650 (epoch 11.799), train_loss = 1.15356085, grad/param norm = 1.3055e-01, time/batch = 17.5634s	
7942/33650 (epoch 11.801), train_loss = 1.21885161, grad/param norm = 1.4987e-01, time/batch = 17.8189s	
7943/33650 (epoch 11.802), train_loss = 1.27743380, grad/param norm = 1.4486e-01, time/batch = 18.0520s	
7944/33650 (epoch 11.804), train_loss = 1.15549628, grad/param norm = 1.4678e-01, time/batch = 17.2407s	
7945/33650 (epoch 11.805), train_loss = 1.10338752, grad/param norm = 1.3220e-01, time/batch = 18.3208s	
7946/33650 (epoch 11.807), train_loss = 1.37903125, grad/param norm = 1.6260e-01, time/batch = 17.5609s	
7947/33650 (epoch 11.808), train_loss = 1.37779202, grad/param norm = 1.6231e-01, time/batch = 15.9621s	
7948/33650 (epoch 11.810), train_loss = 1.23356960, grad/param norm = 1.4116e-01, time/batch = 17.7332s	
7949/33650 (epoch 11.811), train_loss = 1.20545781, grad/param norm = 1.5241e-01, time/batch = 17.7172s	
7950/33650 (epoch 11.813), train_loss = 1.15201125, grad/param norm = 1.4584e-01, time/batch = 16.8075s	
7951/33650 (epoch 11.814), train_loss = 1.26340381, grad/param norm = 1.4979e-01, time/batch = 18.6521s	
7952/33650 (epoch 11.816), train_loss = 1.20697334, grad/param norm = 1.5040e-01, time/batch = 15.6914s	
7953/33650 (epoch 11.817), train_loss = 1.27391823, grad/param norm = 1.6837e-01, time/batch = 16.7141s	
7954/33650 (epoch 11.819), train_loss = 1.27686293, grad/param norm = 1.4421e-01, time/batch = 18.1526s	
7955/33650 (epoch 11.820), train_loss = 1.31166111, grad/param norm = 1.5344e-01, time/batch = 18.3131s	
7956/33650 (epoch 11.822), train_loss = 1.29569432, grad/param norm = 1.7634e-01, time/batch = 17.0575s	
7957/33650 (epoch 11.823), train_loss = 1.09079413, grad/param norm = 1.5030e-01, time/batch = 17.4771s	
7958/33650 (epoch 11.825), train_loss = 1.16166899, grad/param norm = 1.3751e-01, time/batch = 17.6441s	
7959/33650 (epoch 11.826), train_loss = 1.25658146, grad/param norm = 1.5262e-01, time/batch = 18.1484s	
7960/33650 (epoch 11.828), train_loss = 1.41041105, grad/param norm = 1.5018e-01, time/batch = 16.9696s	
7961/33650 (epoch 11.829), train_loss = 1.02263616, grad/param norm = 1.3637e-01, time/batch = 17.8220s	
7962/33650 (epoch 11.831), train_loss = 1.25120812, grad/param norm = 1.5331e-01, time/batch = 18.3145s	
7963/33650 (epoch 11.832), train_loss = 1.23050255, grad/param norm = 1.3786e-01, time/batch = 17.3868s	
7964/33650 (epoch 11.834), train_loss = 1.25986926, grad/param norm = 1.4733e-01, time/batch = 16.0374s	
7965/33650 (epoch 11.835), train_loss = 1.42501663, grad/param norm = 1.5947e-01, time/batch = 17.8901s	
7966/33650 (epoch 11.837), train_loss = 1.22290855, grad/param norm = 1.6683e-01, time/batch = 17.3085s	
7967/33650 (epoch 11.838), train_loss = 1.17553053, grad/param norm = 1.5576e-01, time/batch = 17.3044s	
7968/33650 (epoch 11.840), train_loss = 1.27577734, grad/param norm = 1.5522e-01, time/batch = 18.2336s	
7969/33650 (epoch 11.841), train_loss = 1.08330979, grad/param norm = 1.2806e-01, time/batch = 17.3912s	
7970/33650 (epoch 11.842), train_loss = 1.13202692, grad/param norm = 1.4265e-01, time/batch = 16.2315s	
7971/33650 (epoch 11.844), train_loss = 1.33569331, grad/param norm = 1.5556e-01, time/batch = 16.6388s	
7972/33650 (epoch 11.845), train_loss = 1.10738158, grad/param norm = 1.3442e-01, time/batch = 17.8997s	
7973/33650 (epoch 11.847), train_loss = 0.94253362, grad/param norm = 1.4497e-01, time/batch = 16.6334s	
7974/33650 (epoch 11.848), train_loss = 1.01639400, grad/param norm = 1.5926e-01, time/batch = 17.6615s	
7975/33650 (epoch 11.850), train_loss = 1.19124356, grad/param norm = 1.8423e-01, time/batch = 18.2202s	
7976/33650 (epoch 11.851), train_loss = 0.96349169, grad/param norm = 1.3231e-01, time/batch = 18.3135s	
7977/33650 (epoch 11.853), train_loss = 1.20249103, grad/param norm = 1.5122e-01, time/batch = 16.1975s	
7978/33650 (epoch 11.854), train_loss = 1.32447818, grad/param norm = 1.6843e-01, time/batch = 18.0634s	
7979/33650 (epoch 11.856), train_loss = 0.89375149, grad/param norm = 1.3408e-01, time/batch = 18.6481s	
7980/33650 (epoch 11.857), train_loss = 1.14277291, grad/param norm = 1.3122e-01, time/batch = 16.7137s	
7981/33650 (epoch 11.859), train_loss = 1.05547468, grad/param norm = 1.3058e-01, time/batch = 16.5679s	
7982/33650 (epoch 11.860), train_loss = 0.97870128, grad/param norm = 1.4034e-01, time/batch = 18.3913s	
7983/33650 (epoch 11.862), train_loss = 1.04202608, grad/param norm = 1.4421e-01, time/batch = 18.1375s	
7984/33650 (epoch 11.863), train_loss = 1.24493141, grad/param norm = 1.5075e-01, time/batch = 17.8837s	
7985/33650 (epoch 11.865), train_loss = 1.13107171, grad/param norm = 1.4012e-01, time/batch = 17.7448s	
7986/33650 (epoch 11.866), train_loss = 1.02675349, grad/param norm = 1.3403e-01, time/batch = 17.4021s	
7987/33650 (epoch 11.868), train_loss = 1.04973926, grad/param norm = 1.4897e-01, time/batch = 16.4528s	
7988/33650 (epoch 11.869), train_loss = 1.29706135, grad/param norm = 1.5302e-01, time/batch = 18.6529s	
7989/33650 (epoch 11.871), train_loss = 1.01091076, grad/param norm = 1.2144e-01, time/batch = 17.8939s	
7990/33650 (epoch 11.872), train_loss = 1.17442818, grad/param norm = 1.5636e-01, time/batch = 17.7245s	
7991/33650 (epoch 11.874), train_loss = 1.25448491, grad/param norm = 1.6641e-01, time/batch = 15.7971s	
7992/33650 (epoch 11.875), train_loss = 1.11247726, grad/param norm = 1.4173e-01, time/batch = 18.3926s	
7993/33650 (epoch 11.877), train_loss = 1.29458705, grad/param norm = 1.4635e-01, time/batch = 17.4940s	
7994/33650 (epoch 11.878), train_loss = 0.82882431, grad/param norm = 1.2638e-01, time/batch = 17.0484s	
7995/33650 (epoch 11.880), train_loss = 1.20863291, grad/param norm = 1.5260e-01, time/batch = 17.7366s	
7996/33650 (epoch 11.881), train_loss = 1.09239777, grad/param norm = 1.4181e-01, time/batch = 18.4738s	
7997/33650 (epoch 11.883), train_loss = 1.16149765, grad/param norm = 1.4695e-01, time/batch = 16.6517s	
7998/33650 (epoch 11.884), train_loss = 1.27539048, grad/param norm = 1.5560e-01, time/batch = 17.8081s	
7999/33650 (epoch 11.886), train_loss = 1.27570092, grad/param norm = 1.4906e-01, time/batch = 17.1323s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch11.89_1.5253.t7	
8000/33650 (epoch 11.887), train_loss = 1.07074576, grad/param norm = 1.3019e-01, time/batch = 17.7419s	
8001/33650 (epoch 11.889), train_loss = 1.52653487, grad/param norm = 1.7666e-01, time/batch = 18.7149s	
8002/33650 (epoch 11.890), train_loss = 1.23054638, grad/param norm = 1.3350e-01, time/batch = 16.0698s	
8003/33650 (epoch 11.892), train_loss = 1.21352958, grad/param norm = 1.5629e-01, time/batch = 16.6436s	
8004/33650 (epoch 11.893), train_loss = 1.22483645, grad/param norm = 1.5037e-01, time/batch = 17.9004s	
8005/33650 (epoch 11.895), train_loss = 1.31265261, grad/param norm = 1.5961e-01, time/batch = 17.8909s	
8006/33650 (epoch 11.896), train_loss = 1.05282416, grad/param norm = 1.2961e-01, time/batch = 17.4700s	
8007/33650 (epoch 11.897), train_loss = 1.02034514, grad/param norm = 1.3540e-01, time/batch = 17.1422s	
8008/33650 (epoch 11.899), train_loss = 1.02481828, grad/param norm = 1.3230e-01, time/batch = 17.9650s	
8009/33650 (epoch 11.900), train_loss = 0.95085331, grad/param norm = 1.2369e-01, time/batch = 18.6380s	
8010/33650 (epoch 11.902), train_loss = 1.18235061, grad/param norm = 1.4626e-01, time/batch = 16.8852s	
8011/33650 (epoch 11.903), train_loss = 1.15619402, grad/param norm = 1.6472e-01, time/batch = 17.2826s	
8012/33650 (epoch 11.905), train_loss = 1.37171131, grad/param norm = 1.7001e-01, time/batch = 18.8986s	
8013/33650 (epoch 11.906), train_loss = 1.12126145, grad/param norm = 1.4993e-01, time/batch = 16.9792s	
8014/33650 (epoch 11.908), train_loss = 1.10904045, grad/param norm = 1.3459e-01, time/batch = 15.9025s	
8015/33650 (epoch 11.909), train_loss = 1.11962353, grad/param norm = 1.4442e-01, time/batch = 16.4573s	
8016/33650 (epoch 11.911), train_loss = 0.97356099, grad/param norm = 1.2599e-01, time/batch = 17.6447s	
8017/33650 (epoch 11.912), train_loss = 0.98210692, grad/param norm = 1.2946e-01, time/batch = 17.8847s	
8018/33650 (epoch 11.914), train_loss = 1.14309181, grad/param norm = 1.3157e-01, time/batch = 18.1498s	
8019/33650 (epoch 11.915), train_loss = 1.18173469, grad/param norm = 1.5878e-01, time/batch = 17.9771s	
8020/33650 (epoch 11.917), train_loss = 1.14570079, grad/param norm = 1.4701e-01, time/batch = 16.3893s	
8021/33650 (epoch 11.918), train_loss = 0.92479776, grad/param norm = 1.2255e-01, time/batch = 18.4724s	
8022/33650 (epoch 11.920), train_loss = 1.06239796, grad/param norm = 1.3106e-01, time/batch = 17.9921s	
8023/33650 (epoch 11.921), train_loss = 1.03992428, grad/param norm = 1.3709e-01, time/batch = 17.1369s	
8024/33650 (epoch 11.923), train_loss = 1.01143575, grad/param norm = 1.3829e-01, time/batch = 16.4612s	
8025/33650 (epoch 11.924), train_loss = 1.17279402, grad/param norm = 1.5749e-01, time/batch = 18.0631s	
8026/33650 (epoch 11.926), train_loss = 1.15153021, grad/param norm = 1.6085e-01, time/batch = 17.1206s	
8027/33650 (epoch 11.927), train_loss = 1.08534717, grad/param norm = 1.4901e-01, time/batch = 17.3007s	
8028/33650 (epoch 11.929), train_loss = 1.18436043, grad/param norm = 1.5517e-01, time/batch = 17.3875s	
8029/33650 (epoch 11.930), train_loss = 1.08843591, grad/param norm = 1.4051e-01, time/batch = 18.6394s	
8030/33650 (epoch 11.932), train_loss = 1.15505947, grad/param norm = 1.4701e-01, time/batch = 16.4004s	
8031/33650 (epoch 11.933), train_loss = 0.99545795, grad/param norm = 1.3484e-01, time/batch = 18.3132s	
8032/33650 (epoch 11.935), train_loss = 1.04840201, grad/param norm = 1.3971e-01, time/batch = 18.6357s	
8033/33650 (epoch 11.936), train_loss = 1.04160556, grad/param norm = 1.3386e-01, time/batch = 17.9777s	
8034/33650 (epoch 11.938), train_loss = 0.96943123, grad/param norm = 1.3702e-01, time/batch = 17.3922s	
8035/33650 (epoch 11.939), train_loss = 1.19042434, grad/param norm = 1.3787e-01, time/batch = 15.4717s	
8036/33650 (epoch 11.941), train_loss = 1.16832150, grad/param norm = 1.5714e-01, time/batch = 18.8056s	
8037/33650 (epoch 11.942), train_loss = 1.22218157, grad/param norm = 1.4938e-01, time/batch = 16.3075s	
8038/33650 (epoch 11.944), train_loss = 1.16741212, grad/param norm = 1.3330e-01, time/batch = 17.9929s	
8039/33650 (epoch 11.945), train_loss = 1.22419143, grad/param norm = 1.5822e-01, time/batch = 17.4765s	
8040/33650 (epoch 11.947), train_loss = 1.37193520, grad/param norm = 1.6975e-01, time/batch = 17.6428s	
8041/33650 (epoch 11.948), train_loss = 1.26668028, grad/param norm = 1.4232e-01, time/batch = 16.3063s	
8042/33650 (epoch 11.949), train_loss = 1.03874980, grad/param norm = 1.4033e-01, time/batch = 18.4794s	
8043/33650 (epoch 11.951), train_loss = 1.30941994, grad/param norm = 1.4989e-01, time/batch = 18.3211s	
8044/33650 (epoch 11.952), train_loss = 1.25164484, grad/param norm = 1.5918e-01, time/batch = 16.8815s	
8045/33650 (epoch 11.954), train_loss = 1.22189561, grad/param norm = 1.5171e-01, time/batch = 18.4079s	
8046/33650 (epoch 11.955), train_loss = 1.22897597, grad/param norm = 1.5638e-01, time/batch = 18.2876s	
8047/33650 (epoch 11.957), train_loss = 1.21712451, grad/param norm = 1.4420e-01, time/batch = 17.1504s	
8048/33650 (epoch 11.958), train_loss = 0.88645635, grad/param norm = 1.1770e-01, time/batch = 15.5642s	
8049/33650 (epoch 11.960), train_loss = 0.99613761, grad/param norm = 1.3279e-01, time/batch = 17.2356s	
8050/33650 (epoch 11.961), train_loss = 1.04126787, grad/param norm = 1.4082e-01, time/batch = 16.3237s	
8051/33650 (epoch 11.963), train_loss = 1.10597156, grad/param norm = 1.4570e-01, time/batch = 17.3059s	
8052/33650 (epoch 11.964), train_loss = 1.15172718, grad/param norm = 1.4861e-01, time/batch = 18.5436s	
8053/33650 (epoch 11.966), train_loss = 1.15599980, grad/param norm = 1.4887e-01, time/batch = 18.8891s	
8054/33650 (epoch 11.967), train_loss = 1.21047278, grad/param norm = 1.4458e-01, time/batch = 16.9610s	
8055/33650 (epoch 11.969), train_loss = 1.10493949, grad/param norm = 1.3350e-01, time/batch = 18.1433s	
8056/33650 (epoch 11.970), train_loss = 1.21163523, grad/param norm = 1.5289e-01, time/batch = 17.1517s	
8057/33650 (epoch 11.972), train_loss = 1.47968617, grad/param norm = 1.6604e-01, time/batch = 17.0595s	
8058/33650 (epoch 11.973), train_loss = 1.04346219, grad/param norm = 1.3091e-01, time/batch = 16.8875s	
8059/33650 (epoch 11.975), train_loss = 1.03741410, grad/param norm = 1.3446e-01, time/batch = 18.6561s	
8060/33650 (epoch 11.976), train_loss = 1.00993156, grad/param norm = 1.2809e-01, time/batch = 18.1515s	
8061/33650 (epoch 11.978), train_loss = 1.06274490, grad/param norm = 1.4987e-01, time/batch = 16.6284s	
8062/33650 (epoch 11.979), train_loss = 1.13223156, grad/param norm = 1.3961e-01, time/batch = 17.2959s	
8063/33650 (epoch 11.981), train_loss = 1.07382594, grad/param norm = 1.2102e-01, time/batch = 17.7190s	
8064/33650 (epoch 11.982), train_loss = 1.16538601, grad/param norm = 1.3614e-01, time/batch = 17.7213s	
8065/33650 (epoch 11.984), train_loss = 1.01172751, grad/param norm = 1.2692e-01, time/batch = 18.1476s	
8066/33650 (epoch 11.985), train_loss = 0.98607644, grad/param norm = 1.2838e-01, time/batch = 17.4823s	
8067/33650 (epoch 11.987), train_loss = 1.10383678, grad/param norm = 1.3244e-01, time/batch = 17.5601s	
8068/33650 (epoch 11.988), train_loss = 1.19674967, grad/param norm = 1.4565e-01, time/batch = 17.8022s	
8069/33650 (epoch 11.990), train_loss = 1.37493844, grad/param norm = 1.7865e-01, time/batch = 18.3276s	
8070/33650 (epoch 11.991), train_loss = 1.20476351, grad/param norm = 1.3314e-01, time/batch = 18.0644s	
8071/33650 (epoch 11.993), train_loss = 1.18915271, grad/param norm = 1.5805e-01, time/batch = 17.0611s	
8072/33650 (epoch 11.994), train_loss = 1.10086781, grad/param norm = 1.4724e-01, time/batch = 18.7302s	
8073/33650 (epoch 11.996), train_loss = 1.07876043, grad/param norm = 1.4085e-01, time/batch = 17.7373s	
8074/33650 (epoch 11.997), train_loss = 1.18681478, grad/param norm = 1.5225e-01, time/batch = 16.7186s	
8075/33650 (epoch 11.999), train_loss = 0.99829617, grad/param norm = 1.3401e-01, time/batch = 15.6477s	
decayed learning rate by a factor 0.97 to 0.001825346	
8076/33650 (epoch 12.000), train_loss = 1.20682154, grad/param norm = 1.5234e-01, time/batch = 17.7096s	
8077/33650 (epoch 12.001), train_loss = 1.31387750, grad/param norm = 1.6153e-01, time/batch = 18.3935s	
8078/33650 (epoch 12.003), train_loss = 1.34082440, grad/param norm = 1.7210e-01, time/batch = 17.0466s	
8079/33650 (epoch 12.004), train_loss = 1.20952544, grad/param norm = 1.5868e-01, time/batch = 18.1520s	
8080/33650 (epoch 12.006), train_loss = 1.09631049, grad/param norm = 1.3584e-01, time/batch = 18.0689s	
8081/33650 (epoch 12.007), train_loss = 1.17937834, grad/param norm = 1.4454e-01, time/batch = 16.9840s	
8082/33650 (epoch 12.009), train_loss = 1.09234486, grad/param norm = 1.3700e-01, time/batch = 16.5366s	
8083/33650 (epoch 12.010), train_loss = 1.21507355, grad/param norm = 1.4994e-01, time/batch = 18.4696s	
8084/33650 (epoch 12.012), train_loss = 1.08756007, grad/param norm = 1.4530e-01, time/batch = 17.8902s	
8085/33650 (epoch 12.013), train_loss = 1.19188953, grad/param norm = 1.6431e-01, time/batch = 17.8888s	
8086/33650 (epoch 12.015), train_loss = 1.03609347, grad/param norm = 1.3412e-01, time/batch = 16.9012s	
8087/33650 (epoch 12.016), train_loss = 1.03421424, grad/param norm = 1.4593e-01, time/batch = 18.2386s	
8088/33650 (epoch 12.018), train_loss = 1.13545911, grad/param norm = 1.4604e-01, time/batch = 23.9462s	
8089/33650 (epoch 12.019), train_loss = 1.05150897, grad/param norm = 1.3080e-01, time/batch = 20.6076s	
8090/33650 (epoch 12.021), train_loss = 1.25446283, grad/param norm = 1.4191e-01, time/batch = 18.2356s	
8091/33650 (epoch 12.022), train_loss = 1.08647127, grad/param norm = 1.4084e-01, time/batch = 19.2053s	
8092/33650 (epoch 12.024), train_loss = 1.01760719, grad/param norm = 1.4451e-01, time/batch = 24.0095s	
8093/33650 (epoch 12.025), train_loss = 1.08872084, grad/param norm = 1.3498e-01, time/batch = 17.6510s	
8094/33650 (epoch 12.027), train_loss = 1.23640666, grad/param norm = 1.4923e-01, time/batch = 17.9601s	
8095/33650 (epoch 12.028), train_loss = 1.22365269, grad/param norm = 1.5163e-01, time/batch = 16.6336s	
8096/33650 (epoch 12.030), train_loss = 1.18070409, grad/param norm = 1.4170e-01, time/batch = 18.3902s	
8097/33650 (epoch 12.031), train_loss = 1.00558268, grad/param norm = 1.2274e-01, time/batch = 17.2240s	
8098/33650 (epoch 12.033), train_loss = 1.09557709, grad/param norm = 1.2945e-01, time/batch = 17.5649s	
8099/33650 (epoch 12.034), train_loss = 1.19281094, grad/param norm = 1.5302e-01, time/batch = 17.8228s	
8100/33650 (epoch 12.036), train_loss = 1.28184512, grad/param norm = 1.5988e-01, time/batch = 17.3074s	
8101/33650 (epoch 12.037), train_loss = 1.06251343, grad/param norm = 1.4485e-01, time/batch = 18.0530s	
8102/33650 (epoch 12.039), train_loss = 1.26504680, grad/param norm = 1.5154e-01, time/batch = 17.9741s	
8103/33650 (epoch 12.040), train_loss = 1.34033211, grad/param norm = 1.6849e-01, time/batch = 15.8121s	
8104/33650 (epoch 12.042), train_loss = 1.34955364, grad/param norm = 1.5780e-01, time/batch = 16.8978s	
8105/33650 (epoch 12.043), train_loss = 1.07294257, grad/param norm = 1.4953e-01, time/batch = 18.9757s	
8106/33650 (epoch 12.045), train_loss = 1.04271797, grad/param norm = 1.2962e-01, time/batch = 16.4626s	
8107/33650 (epoch 12.046), train_loss = 1.22112448, grad/param norm = 1.4988e-01, time/batch = 17.2225s	
8108/33650 (epoch 12.048), train_loss = 1.22551256, grad/param norm = 1.4132e-01, time/batch = 16.7337s	
8109/33650 (epoch 12.049), train_loss = 1.17694495, grad/param norm = 1.4877e-01, time/batch = 18.4808s	
8110/33650 (epoch 12.051), train_loss = 1.27513580, grad/param norm = 1.5326e-01, time/batch = 18.5669s	
8111/33650 (epoch 12.052), train_loss = 1.32977017, grad/param norm = 1.5936e-01, time/batch = 16.6356s	
8112/33650 (epoch 12.053), train_loss = 1.16267729, grad/param norm = 1.3980e-01, time/batch = 18.7310s	
8113/33650 (epoch 12.055), train_loss = 1.00694776, grad/param norm = 1.3810e-01, time/batch = 17.9042s	
8114/33650 (epoch 12.056), train_loss = 1.00766135, grad/param norm = 1.3300e-01, time/batch = 17.0358s	
8115/33650 (epoch 12.058), train_loss = 1.27066685, grad/param norm = 1.7075e-01, time/batch = 17.9803s	
8116/33650 (epoch 12.059), train_loss = 1.20444553, grad/param norm = 1.4784e-01, time/batch = 18.0708s	
8117/33650 (epoch 12.061), train_loss = 1.22857818, grad/param norm = 1.4708e-01, time/batch = 17.1476s	
8118/33650 (epoch 12.062), train_loss = 1.20302371, grad/param norm = 1.3685e-01, time/batch = 15.4742s	
8119/33650 (epoch 12.064), train_loss = 1.08128139, grad/param norm = 1.2814e-01, time/batch = 17.7273s	
8120/33650 (epoch 12.065), train_loss = 1.09833018, grad/param norm = 1.4094e-01, time/batch = 18.4079s	
8121/33650 (epoch 12.067), train_loss = 1.03693131, grad/param norm = 1.3941e-01, time/batch = 16.7143s	
8122/33650 (epoch 12.068), train_loss = 1.18020437, grad/param norm = 1.4982e-01, time/batch = 17.7335s	
8123/33650 (epoch 12.070), train_loss = 1.15116181, grad/param norm = 1.4711e-01, time/batch = 18.2234s	
8124/33650 (epoch 12.071), train_loss = 1.15070723, grad/param norm = 1.4175e-01, time/batch = 17.4716s	
8125/33650 (epoch 12.073), train_loss = 1.19266204, grad/param norm = 1.5097e-01, time/batch = 16.4686s	
8126/33650 (epoch 12.074), train_loss = 1.26302928, grad/param norm = 1.4808e-01, time/batch = 17.9798s	
8127/33650 (epoch 12.076), train_loss = 1.26341556, grad/param norm = 1.5726e-01, time/batch = 18.4809s	
8128/33650 (epoch 12.077), train_loss = 1.13113458, grad/param norm = 1.3462e-01, time/batch = 16.6497s	
8129/33650 (epoch 12.079), train_loss = 1.11769961, grad/param norm = 1.4891e-01, time/batch = 18.1591s	
8130/33650 (epoch 12.080), train_loss = 1.21439106, grad/param norm = 1.4544e-01, time/batch = 17.4848s	
8131/33650 (epoch 12.082), train_loss = 1.24819601, grad/param norm = 1.5317e-01, time/batch = 18.0519s	
8132/33650 (epoch 12.083), train_loss = 1.20103614, grad/param norm = 1.4122e-01, time/batch = 18.1450s	
8133/33650 (epoch 12.085), train_loss = 1.23694436, grad/param norm = 1.3818e-01, time/batch = 17.8269s	
8134/33650 (epoch 12.086), train_loss = 1.26302782, grad/param norm = 1.6123e-01, time/batch = 17.2108s	
8135/33650 (epoch 12.088), train_loss = 1.21396518, grad/param norm = 1.4645e-01, time/batch = 17.7185s	
8136/33650 (epoch 12.089), train_loss = 1.18419182, grad/param norm = 1.5317e-01, time/batch = 17.9016s	
8137/33650 (epoch 12.091), train_loss = 1.09141946, grad/param norm = 1.2941e-01, time/batch = 17.7426s	
8138/33650 (epoch 12.092), train_loss = 1.12961521, grad/param norm = 1.4593e-01, time/batch = 16.8806s	
8139/33650 (epoch 12.094), train_loss = 1.20325865, grad/param norm = 1.3083e-01, time/batch = 18.4799s	
8140/33650 (epoch 12.095), train_loss = 1.20990372, grad/param norm = 1.5412e-01, time/batch = 17.4772s	
8141/33650 (epoch 12.097), train_loss = 1.13070292, grad/param norm = 1.5005e-01, time/batch = 16.8981s	
8142/33650 (epoch 12.098), train_loss = 0.92918075, grad/param norm = 1.2596e-01, time/batch = 16.3083s	
8143/33650 (epoch 12.100), train_loss = 1.05663735, grad/param norm = 1.3173e-01, time/batch = 17.2955s	
8144/33650 (epoch 12.101), train_loss = 1.12698298, grad/param norm = 1.5858e-01, time/batch = 17.1414s	
8145/33650 (epoch 12.103), train_loss = 1.06532143, grad/param norm = 1.3058e-01, time/batch = 16.7299s	
8146/33650 (epoch 12.104), train_loss = 1.21464511, grad/param norm = 1.3991e-01, time/batch = 18.4048s	
8147/33650 (epoch 12.105), train_loss = 1.14121968, grad/param norm = 1.5275e-01, time/batch = 16.8995s	
8148/33650 (epoch 12.107), train_loss = 1.04456762, grad/param norm = 1.3064e-01, time/batch = 16.9619s	
8149/33650 (epoch 12.108), train_loss = 1.22279385, grad/param norm = 1.5343e-01, time/batch = 18.4019s	
8150/33650 (epoch 12.110), train_loss = 1.33185733, grad/param norm = 1.5306e-01, time/batch = 18.4082s	
8151/33650 (epoch 12.111), train_loss = 1.10115542, grad/param norm = 1.4941e-01, time/batch = 17.7121s	
8152/33650 (epoch 12.113), train_loss = 1.10268453, grad/param norm = 1.3686e-01, time/batch = 18.1393s	
8153/33650 (epoch 12.114), train_loss = 1.21839428, grad/param norm = 1.5217e-01, time/batch = 18.3861s	
8154/33650 (epoch 12.116), train_loss = 1.02527973, grad/param norm = 1.3148e-01, time/batch = 17.9836s	
8155/33650 (epoch 12.117), train_loss = 1.16584826, grad/param norm = 1.2739e-01, time/batch = 9.7859s	
8156/33650 (epoch 12.119), train_loss = 1.00342095, grad/param norm = 1.3101e-01, time/batch = 0.6397s	
8157/33650 (epoch 12.120), train_loss = 1.05882674, grad/param norm = 1.4731e-01, time/batch = 0.6391s	
8158/33650 (epoch 12.122), train_loss = 0.94997748, grad/param norm = 1.3321e-01, time/batch = 0.6452s	
8159/33650 (epoch 12.123), train_loss = 1.09531881, grad/param norm = 1.4196e-01, time/batch = 0.6389s	
8160/33650 (epoch 12.125), train_loss = 1.26110725, grad/param norm = 1.5422e-01, time/batch = 0.6402s	
8161/33650 (epoch 12.126), train_loss = 1.32199557, grad/param norm = 1.6546e-01, time/batch = 0.6529s	
8162/33650 (epoch 12.128), train_loss = 1.27428576, grad/param norm = 1.5499e-01, time/batch = 0.6561s	
8163/33650 (epoch 12.129), train_loss = 1.27324862, grad/param norm = 1.5434e-01, time/batch = 0.8674s	
8164/33650 (epoch 12.131), train_loss = 1.18553954, grad/param norm = 1.4463e-01, time/batch = 0.9438s	
8165/33650 (epoch 12.132), train_loss = 1.16729808, grad/param norm = 1.3542e-01, time/batch = 0.9438s	
8166/33650 (epoch 12.134), train_loss = 1.29155078, grad/param norm = 1.4955e-01, time/batch = 0.9421s	
8167/33650 (epoch 12.135), train_loss = 1.01146736, grad/param norm = 1.4348e-01, time/batch = 0.9395s	
8168/33650 (epoch 12.137), train_loss = 1.15102323, grad/param norm = 1.5258e-01, time/batch = 1.3576s	
8169/33650 (epoch 12.138), train_loss = 1.23015510, grad/param norm = 1.3619e-01, time/batch = 1.7720s	
8170/33650 (epoch 12.140), train_loss = 1.17489575, grad/param norm = 1.5377e-01, time/batch = 1.7623s	
8171/33650 (epoch 12.141), train_loss = 1.29547878, grad/param norm = 1.5275e-01, time/batch = 13.6475s	
8172/33650 (epoch 12.143), train_loss = 1.42203946, grad/param norm = 1.9318e-01, time/batch = 17.3277s	
8173/33650 (epoch 12.144), train_loss = 1.25154146, grad/param norm = 1.6458e-01, time/batch = 16.7184s	
8174/33650 (epoch 12.146), train_loss = 1.11323631, grad/param norm = 1.3927e-01, time/batch = 16.6377s	
8175/33650 (epoch 12.147), train_loss = 1.09403813, grad/param norm = 1.4014e-01, time/batch = 17.8145s	
8176/33650 (epoch 12.149), train_loss = 1.05828334, grad/param norm = 1.5316e-01, time/batch = 18.0519s	
8177/33650 (epoch 12.150), train_loss = 1.01339835, grad/param norm = 1.2848e-01, time/batch = 16.3740s	
8178/33650 (epoch 12.152), train_loss = 1.09470719, grad/param norm = 1.3646e-01, time/batch = 18.6406s	
8179/33650 (epoch 12.153), train_loss = 1.11563282, grad/param norm = 1.4484e-01, time/batch = 16.7385s	
8180/33650 (epoch 12.155), train_loss = 1.07441396, grad/param norm = 1.3162e-01, time/batch = 17.0629s	
8181/33650 (epoch 12.156), train_loss = 1.04442650, grad/param norm = 1.2471e-01, time/batch = 16.3043s	
8182/33650 (epoch 12.158), train_loss = 1.15633557, grad/param norm = 1.4642e-01, time/batch = 17.3137s	
8183/33650 (epoch 12.159), train_loss = 1.00739368, grad/param norm = 1.2000e-01, time/batch = 17.7187s	
8184/33650 (epoch 12.160), train_loss = 1.05278547, grad/param norm = 1.2341e-01, time/batch = 17.5605s	
8185/33650 (epoch 12.162), train_loss = 1.15444897, grad/param norm = 1.7021e-01, time/batch = 18.1429s	
8186/33650 (epoch 12.163), train_loss = 1.21867733, grad/param norm = 1.5735e-01, time/batch = 18.1408s	
8187/33650 (epoch 12.165), train_loss = 1.03579922, grad/param norm = 1.3305e-01, time/batch = 17.0519s	
8188/33650 (epoch 12.166), train_loss = 1.02338187, grad/param norm = 1.4185e-01, time/batch = 18.1456s	
8189/33650 (epoch 12.168), train_loss = 1.21289660, grad/param norm = 1.4313e-01, time/batch = 18.6440s	
8190/33650 (epoch 12.169), train_loss = 1.13799681, grad/param norm = 1.4459e-01, time/batch = 16.6506s	
8191/33650 (epoch 12.171), train_loss = 1.12974917, grad/param norm = 1.3988e-01, time/batch = 17.1380s	
8192/33650 (epoch 12.172), train_loss = 1.11538864, grad/param norm = 1.5026e-01, time/batch = 18.4873s	
8193/33650 (epoch 12.174), train_loss = 1.04039373, grad/param norm = 1.4973e-01, time/batch = 17.8962s	
8194/33650 (epoch 12.175), train_loss = 1.08563603, grad/param norm = 1.5433e-01, time/batch = 16.4727s	
8195/33650 (epoch 12.177), train_loss = 1.16341822, grad/param norm = 1.3610e-01, time/batch = 17.9791s	
8196/33650 (epoch 12.178), train_loss = 1.04753554, grad/param norm = 1.4570e-01, time/batch = 17.9814s	
8197/33650 (epoch 12.180), train_loss = 1.00479719, grad/param norm = 1.3229e-01, time/batch = 16.7324s	
8198/33650 (epoch 12.181), train_loss = 0.90137295, grad/param norm = 1.3667e-01, time/batch = 18.3122s	
8199/33650 (epoch 12.183), train_loss = 1.08590197, grad/param norm = 1.4421e-01, time/batch = 18.1527s	
8200/33650 (epoch 12.184), train_loss = 1.10195156, grad/param norm = 1.5425e-01, time/batch = 16.2929s	
8201/33650 (epoch 12.186), train_loss = 1.08211119, grad/param norm = 1.5705e-01, time/batch = 16.4663s	
8202/33650 (epoch 12.187), train_loss = 1.31428207, grad/param norm = 1.4319e-01, time/batch = 18.1492s	
8203/33650 (epoch 12.189), train_loss = 1.33183930, grad/param norm = 1.6778e-01, time/batch = 17.8353s	
8204/33650 (epoch 12.190), train_loss = 1.16708336, grad/param norm = 1.6257e-01, time/batch = 16.5519s	
8205/33650 (epoch 12.192), train_loss = 1.32634296, grad/param norm = 1.5603e-01, time/batch = 17.6444s	
8206/33650 (epoch 12.193), train_loss = 1.27780743, grad/param norm = 1.6034e-01, time/batch = 18.2287s	
8207/33650 (epoch 12.195), train_loss = 1.00340650, grad/param norm = 1.2563e-01, time/batch = 16.9706s	
8208/33650 (epoch 12.196), train_loss = 0.95717259, grad/param norm = 1.4567e-01, time/batch = 16.6245s	
8209/33650 (epoch 12.198), train_loss = 1.10038746, grad/param norm = 1.5097e-01, time/batch = 17.9859s	
8210/33650 (epoch 12.199), train_loss = 1.23599788, grad/param norm = 1.4938e-01, time/batch = 18.2354s	
8211/33650 (epoch 12.201), train_loss = 1.11925491, grad/param norm = 1.5028e-01, time/batch = 17.0624s	
8212/33650 (epoch 12.202), train_loss = 1.09234842, grad/param norm = 1.3236e-01, time/batch = 17.7348s	
8213/33650 (epoch 12.204), train_loss = 1.19936626, grad/param norm = 1.4091e-01, time/batch = 18.7308s	
8214/33650 (epoch 12.205), train_loss = 1.11093474, grad/param norm = 1.4494e-01, time/batch = 17.0574s	
8215/33650 (epoch 12.207), train_loss = 1.10126059, grad/param norm = 1.5864e-01, time/batch = 18.1500s	
8216/33650 (epoch 12.208), train_loss = 1.11612897, grad/param norm = 1.4071e-01, time/batch = 16.2878s	
8217/33650 (epoch 12.210), train_loss = 0.88311186, grad/param norm = 1.1960e-01, time/batch = 17.2200s	
8218/33650 (epoch 12.211), train_loss = 1.03738580, grad/param norm = 1.3256e-01, time/batch = 17.4700s	
8219/33650 (epoch 12.212), train_loss = 1.25097856, grad/param norm = 1.6149e-01, time/batch = 17.9859s	
8220/33650 (epoch 12.214), train_loss = 1.29605557, grad/param norm = 1.5491e-01, time/batch = 17.4858s	
8221/33650 (epoch 12.215), train_loss = 0.90366478, grad/param norm = 1.3888e-01, time/batch = 17.2188s	
8222/33650 (epoch 12.217), train_loss = 1.14393981, grad/param norm = 1.6838e-01, time/batch = 17.9775s	
8223/33650 (epoch 12.218), train_loss = 1.19285188, grad/param norm = 1.4627e-01, time/batch = 17.7384s	
8224/33650 (epoch 12.220), train_loss = 1.02255324, grad/param norm = 1.3735e-01, time/batch = 16.9009s	
8225/33650 (epoch 12.221), train_loss = 1.27805420, grad/param norm = 1.6512e-01, time/batch = 16.9565s	
8226/33650 (epoch 12.223), train_loss = 0.86976236, grad/param norm = 1.3054e-01, time/batch = 18.0641s	
8227/33650 (epoch 12.224), train_loss = 1.10769822, grad/param norm = 1.6195e-01, time/batch = 17.8923s	
8228/33650 (epoch 12.226), train_loss = 1.44305515, grad/param norm = 1.6702e-01, time/batch = 17.2148s	
8229/33650 (epoch 12.227), train_loss = 1.28887888, grad/param norm = 1.5370e-01, time/batch = 18.1432s	
8230/33650 (epoch 12.229), train_loss = 1.28062673, grad/param norm = 1.5614e-01, time/batch = 18.4025s	
8231/33650 (epoch 12.230), train_loss = 1.40391990, grad/param norm = 1.6521e-01, time/batch = 16.9779s	
8232/33650 (epoch 12.232), train_loss = 1.18076978, grad/param norm = 1.5034e-01, time/batch = 17.8951s	
8233/33650 (epoch 12.233), train_loss = 1.19728084, grad/param norm = 1.6252e-01, time/batch = 17.8965s	
8234/33650 (epoch 12.235), train_loss = 1.09077088, grad/param norm = 1.2991e-01, time/batch = 16.0406s	
8235/33650 (epoch 12.236), train_loss = 0.98810719, grad/param norm = 1.3829e-01, time/batch = 17.1463s	
8236/33650 (epoch 12.238), train_loss = 1.09860201, grad/param norm = 1.3607e-01, time/batch = 15.6496s	
8237/33650 (epoch 12.239), train_loss = 1.02861736, grad/param norm = 1.3475e-01, time/batch = 18.8122s	
8238/33650 (epoch 12.241), train_loss = 1.06596750, grad/param norm = 1.2944e-01, time/batch = 16.3806s	
8239/33650 (epoch 12.242), train_loss = 0.94109612, grad/param norm = 1.2689e-01, time/batch = 17.9751s	
8240/33650 (epoch 12.244), train_loss = 1.12413819, grad/param norm = 1.5019e-01, time/batch = 17.5601s	
8241/33650 (epoch 12.245), train_loss = 0.98421663, grad/param norm = 1.4005e-01, time/batch = 17.6385s	
8242/33650 (epoch 12.247), train_loss = 1.11769646, grad/param norm = 1.3687e-01, time/batch = 16.6513s	
8243/33650 (epoch 12.248), train_loss = 1.00826002, grad/param norm = 1.3790e-01, time/batch = 17.4682s	
8244/33650 (epoch 12.250), train_loss = 1.09956090, grad/param norm = 1.3049e-01, time/batch = 18.4017s	
8245/33650 (epoch 12.251), train_loss = 1.27405003, grad/param norm = 1.5186e-01, time/batch = 17.8759s	
8246/33650 (epoch 12.253), train_loss = 1.01458017, grad/param norm = 1.3609e-01, time/batch = 17.2364s	
8247/33650 (epoch 12.254), train_loss = 1.03060516, grad/param norm = 1.3972e-01, time/batch = 17.3910s	
8248/33650 (epoch 12.256), train_loss = 1.25023279, grad/param norm = 1.3696e-01, time/batch = 17.2252s	
8249/33650 (epoch 12.257), train_loss = 1.30232248, grad/param norm = 1.5444e-01, time/batch = 16.5423s	
8250/33650 (epoch 12.259), train_loss = 0.98244678, grad/param norm = 1.4069e-01, time/batch = 16.5574s	
8251/33650 (epoch 12.260), train_loss = 1.27464097, grad/param norm = 1.5353e-01, time/batch = 17.5577s	
8252/33650 (epoch 12.262), train_loss = 1.18785864, grad/param norm = 1.4852e-01, time/batch = 17.4621s	
8253/33650 (epoch 12.263), train_loss = 1.12723587, grad/param norm = 1.7860e-01, time/batch = 17.7285s	
8254/33650 (epoch 12.264), train_loss = 1.16169478, grad/param norm = 1.5188e-01, time/batch = 18.6375s	
8255/33650 (epoch 12.266), train_loss = 1.14584003, grad/param norm = 1.4250e-01, time/batch = 16.7956s	
8256/33650 (epoch 12.267), train_loss = 1.04969757, grad/param norm = 1.5278e-01, time/batch = 18.0603s	
8257/33650 (epoch 12.269), train_loss = 1.16822956, grad/param norm = 1.4481e-01, time/batch = 17.4825s	
8258/33650 (epoch 12.270), train_loss = 1.06518859, grad/param norm = 1.3187e-01, time/batch = 17.0733s	
8259/33650 (epoch 12.272), train_loss = 1.10005718, grad/param norm = 1.4065e-01, time/batch = 15.7881s	
8260/33650 (epoch 12.273), train_loss = 1.27622838, grad/param norm = 1.7239e-01, time/batch = 17.4559s	
8261/33650 (epoch 12.275), train_loss = 1.24746387, grad/param norm = 1.6846e-01, time/batch = 18.8811s	
8262/33650 (epoch 12.276), train_loss = 1.31052473, grad/param norm = 1.6883e-01, time/batch = 17.1404s	
8263/33650 (epoch 12.278), train_loss = 1.38076947, grad/param norm = 1.6435e-01, time/batch = 18.6253s	
8264/33650 (epoch 12.279), train_loss = 1.08403028, grad/param norm = 1.5233e-01, time/batch = 18.0667s	
8265/33650 (epoch 12.281), train_loss = 1.16923696, grad/param norm = 1.5544e-01, time/batch = 17.2237s	
8266/33650 (epoch 12.282), train_loss = 1.26144584, grad/param norm = 1.4490e-01, time/batch = 17.6486s	
8267/33650 (epoch 12.284), train_loss = 1.24683744, grad/param norm = 1.5831e-01, time/batch = 18.8150s	
8268/33650 (epoch 12.285), train_loss = 1.24804773, grad/param norm = 1.5600e-01, time/batch = 17.5701s	
8269/33650 (epoch 12.287), train_loss = 1.13033025, grad/param norm = 1.3844e-01, time/batch = 17.6321s	
8270/33650 (epoch 12.288), train_loss = 1.19605677, grad/param norm = 1.6252e-01, time/batch = 18.4878s	
8271/33650 (epoch 12.290), train_loss = 1.16249156, grad/param norm = 1.3634e-01, time/batch = 18.4076s	
8272/33650 (epoch 12.291), train_loss = 1.03027722, grad/param norm = 1.2766e-01, time/batch = 16.2281s	
8273/33650 (epoch 12.293), train_loss = 1.14049817, grad/param norm = 1.5586e-01, time/batch = 16.5542s	
8274/33650 (epoch 12.294), train_loss = 1.02638298, grad/param norm = 1.3520e-01, time/batch = 14.0713s	
8275/33650 (epoch 12.296), train_loss = 1.02515631, grad/param norm = 1.4005e-01, time/batch = 18.1991s	
8276/33650 (epoch 12.297), train_loss = 1.11121792, grad/param norm = 1.4026e-01, time/batch = 16.2309s	
8277/33650 (epoch 12.299), train_loss = 1.01487126, grad/param norm = 1.2312e-01, time/batch = 17.5565s	
8278/33650 (epoch 12.300), train_loss = 1.04825807, grad/param norm = 1.4590e-01, time/batch = 17.8174s	
8279/33650 (epoch 12.302), train_loss = 1.16739600, grad/param norm = 1.3424e-01, time/batch = 15.8952s	
8280/33650 (epoch 12.303), train_loss = 1.14770845, grad/param norm = 1.3523e-01, time/batch = 17.3215s	
8281/33650 (epoch 12.305), train_loss = 1.19039039, grad/param norm = 1.4782e-01, time/batch = 18.8142s	
8282/33650 (epoch 12.306), train_loss = 1.07496990, grad/param norm = 1.3162e-01, time/batch = 17.8160s	
8283/33650 (epoch 12.308), train_loss = 1.04211636, grad/param norm = 1.4826e-01, time/batch = 15.6466s	
8284/33650 (epoch 12.309), train_loss = 1.33568297, grad/param norm = 1.7440e-01, time/batch = 17.9830s	
8285/33650 (epoch 12.311), train_loss = 1.19565959, grad/param norm = 1.4699e-01, time/batch = 18.2100s	
8286/33650 (epoch 12.312), train_loss = 1.13096484, grad/param norm = 1.4189e-01, time/batch = 16.9747s	
8287/33650 (epoch 12.314), train_loss = 0.95819233, grad/param norm = 1.2046e-01, time/batch = 17.6389s	
8288/33650 (epoch 12.315), train_loss = 1.15431992, grad/param norm = 1.5771e-01, time/batch = 17.8291s	
8289/33650 (epoch 12.316), train_loss = 1.08190618, grad/param norm = 1.4761e-01, time/batch = 17.0666s	
8290/33650 (epoch 12.318), train_loss = 1.01422714, grad/param norm = 1.2437e-01, time/batch = 17.9040s	
8291/33650 (epoch 12.319), train_loss = 1.03060406, grad/param norm = 1.2918e-01, time/batch = 17.6570s	
8292/33650 (epoch 12.321), train_loss = 1.08055939, grad/param norm = 1.4245e-01, time/batch = 17.5747s	
8293/33650 (epoch 12.322), train_loss = 1.20243004, grad/param norm = 1.6073e-01, time/batch = 15.1213s	
8294/33650 (epoch 12.324), train_loss = 1.21389000, grad/param norm = 1.8664e-01, time/batch = 16.8105s	
8295/33650 (epoch 12.325), train_loss = 1.21321769, grad/param norm = 1.5322e-01, time/batch = 17.2247s	
8296/33650 (epoch 12.327), train_loss = 1.00497506, grad/param norm = 1.2657e-01, time/batch = 17.1178s	
8297/33650 (epoch 12.328), train_loss = 1.20512520, grad/param norm = 1.5931e-01, time/batch = 17.4464s	
8298/33650 (epoch 12.330), train_loss = 1.02973104, grad/param norm = 1.2276e-01, time/batch = 17.8285s	
8299/33650 (epoch 12.331), train_loss = 0.94497601, grad/param norm = 1.2045e-01, time/batch = 18.0743s	
8300/33650 (epoch 12.333), train_loss = 1.09887378, grad/param norm = 1.4649e-01, time/batch = 17.0623s	
8301/33650 (epoch 12.334), train_loss = 1.10223260, grad/param norm = 1.3119e-01, time/batch = 18.3182s	
8302/33650 (epoch 12.336), train_loss = 1.25282777, grad/param norm = 1.4914e-01, time/batch = 16.9827s	
8303/33650 (epoch 12.337), train_loss = 0.91512926, grad/param norm = 1.2335e-01, time/batch = 16.6374s	
8304/33650 (epoch 12.339), train_loss = 1.10168826, grad/param norm = 1.3962e-01, time/batch = 18.1525s	
8305/33650 (epoch 12.340), train_loss = 1.34374245, grad/param norm = 1.7063e-01, time/batch = 17.1370s	
8306/33650 (epoch 12.342), train_loss = 0.94026441, grad/param norm = 1.3353e-01, time/batch = 17.3098s	
8307/33650 (epoch 12.343), train_loss = 1.20397314, grad/param norm = 1.5388e-01, time/batch = 31.4094s	
8308/33650 (epoch 12.345), train_loss = 1.10940701, grad/param norm = 1.5513e-01, time/batch = 18.3256s	
8309/33650 (epoch 12.346), train_loss = 0.80303268, grad/param norm = 1.2639e-01, time/batch = 16.7222s	
8310/33650 (epoch 12.348), train_loss = 0.99993224, grad/param norm = 1.3211e-01, time/batch = 17.3012s	
8311/33650 (epoch 12.349), train_loss = 0.94125393, grad/param norm = 1.3504e-01, time/batch = 17.6441s	
8312/33650 (epoch 12.351), train_loss = 1.20862280, grad/param norm = 1.4636e-01, time/batch = 14.7593s	
8313/33650 (epoch 12.352), train_loss = 1.09428927, grad/param norm = 1.3907e-01, time/batch = 15.6128s	
8314/33650 (epoch 12.354), train_loss = 1.35261811, grad/param norm = 1.6865e-01, time/batch = 16.6362s	
8315/33650 (epoch 12.355), train_loss = 1.21596312, grad/param norm = 1.3178e-01, time/batch = 17.2263s	
8316/33650 (epoch 12.357), train_loss = 0.93771205, grad/param norm = 1.3727e-01, time/batch = 16.7244s	
8317/33650 (epoch 12.358), train_loss = 1.21221672, grad/param norm = 1.5113e-01, time/batch = 16.9714s	
8318/33650 (epoch 12.360), train_loss = 1.21722399, grad/param norm = 1.5776e-01, time/batch = 18.1495s	
8319/33650 (epoch 12.361), train_loss = 1.16117093, grad/param norm = 1.3379e-01, time/batch = 17.8053s	
8320/33650 (epoch 12.363), train_loss = 1.05836651, grad/param norm = 1.3721e-01, time/batch = 17.4669s	
8321/33650 (epoch 12.364), train_loss = 1.07404705, grad/param norm = 1.2964e-01, time/batch = 18.0523s	
8322/33650 (epoch 12.366), train_loss = 1.16054997, grad/param norm = 1.5638e-01, time/batch = 18.7270s	
8323/33650 (epoch 12.367), train_loss = 1.21203974, grad/param norm = 1.3954e-01, time/batch = 17.9712s	
8324/33650 (epoch 12.368), train_loss = 1.02503978, grad/param norm = 1.3080e-01, time/batch = 15.9670s	
8325/33650 (epoch 12.370), train_loss = 1.13185965, grad/param norm = 1.3744e-01, time/batch = 17.8114s	
8326/33650 (epoch 12.371), train_loss = 0.90328780, grad/param norm = 1.2537e-01, time/batch = 17.7319s	
8327/33650 (epoch 12.373), train_loss = 1.03692887, grad/param norm = 1.2799e-01, time/batch = 16.8157s	
8328/33650 (epoch 12.374), train_loss = 0.96112384, grad/param norm = 1.2293e-01, time/batch = 18.4679s	
8329/33650 (epoch 12.376), train_loss = 1.12218136, grad/param norm = 1.6186e-01, time/batch = 17.2936s	
8330/33650 (epoch 12.377), train_loss = 1.16099228, grad/param norm = 1.5373e-01, time/batch = 17.3970s	
8331/33650 (epoch 12.379), train_loss = 1.19110656, grad/param norm = 1.3853e-01, time/batch = 17.7149s	
8332/33650 (epoch 12.380), train_loss = 0.89758540, grad/param norm = 1.2762e-01, time/batch = 18.2360s	
8333/33650 (epoch 12.382), train_loss = 0.97617445, grad/param norm = 1.1469e-01, time/batch = 17.3770s	
8334/33650 (epoch 12.383), train_loss = 1.08228745, grad/param norm = 1.3649e-01, time/batch = 18.2998s	
8335/33650 (epoch 12.385), train_loss = 1.25705637, grad/param norm = 1.4328e-01, time/batch = 18.3071s	
8336/33650 (epoch 12.386), train_loss = 1.02509310, grad/param norm = 1.3179e-01, time/batch = 17.8164s	
8337/33650 (epoch 12.388), train_loss = 1.16525246, grad/param norm = 1.3803e-01, time/batch = 17.0574s	
8338/33650 (epoch 12.389), train_loss = 1.12646535, grad/param norm = 1.5472e-01, time/batch = 17.4858s	
8339/33650 (epoch 12.391), train_loss = 0.92354861, grad/param norm = 1.2789e-01, time/batch = 18.5566s	
8340/33650 (epoch 12.392), train_loss = 1.18932769, grad/param norm = 1.4146e-01, time/batch = 17.2283s	
8341/33650 (epoch 12.394), train_loss = 1.22638771, grad/param norm = 1.6274e-01, time/batch = 17.9768s	
8342/33650 (epoch 12.395), train_loss = 1.14765807, grad/param norm = 1.4332e-01, time/batch = 17.5594s	
8343/33650 (epoch 12.397), train_loss = 1.29930474, grad/param norm = 1.5146e-01, time/batch = 16.6184s	
8344/33650 (epoch 12.398), train_loss = 1.15137844, grad/param norm = 1.3625e-01, time/batch = 17.2217s	
8345/33650 (epoch 12.400), train_loss = 1.12988183, grad/param norm = 1.5985e-01, time/batch = 16.3123s	
8346/33650 (epoch 12.401), train_loss = 1.14302971, grad/param norm = 1.7030e-01, time/batch = 18.1509s	
8347/33650 (epoch 12.403), train_loss = 1.19710290, grad/param norm = 1.5345e-01, time/batch = 15.2174s	
8348/33650 (epoch 12.404), train_loss = 1.09691394, grad/param norm = 1.2266e-01, time/batch = 17.3045s	
8349/33650 (epoch 12.406), train_loss = 1.17379639, grad/param norm = 1.4267e-01, time/batch = 18.8108s	
8350/33650 (epoch 12.407), train_loss = 1.15082381, grad/param norm = 1.5688e-01, time/batch = 18.0573s	
8351/33650 (epoch 12.409), train_loss = 1.12227923, grad/param norm = 1.3271e-01, time/batch = 17.6013s	
8352/33650 (epoch 12.410), train_loss = 1.15218630, grad/param norm = 1.5601e-01, time/batch = 18.1466s	
8353/33650 (epoch 12.412), train_loss = 1.12614373, grad/param norm = 1.2654e-01, time/batch = 17.9743s	
8354/33650 (epoch 12.413), train_loss = 1.04311911, grad/param norm = 1.3981e-01, time/batch = 17.5464s	
8355/33650 (epoch 12.415), train_loss = 1.19727343, grad/param norm = 1.3916e-01, time/batch = 18.6381s	
8356/33650 (epoch 12.416), train_loss = 1.29818099, grad/param norm = 1.4697e-01, time/batch = 18.0745s	
8357/33650 (epoch 12.418), train_loss = 1.13252782, grad/param norm = 1.4674e-01, time/batch = 16.5319s	
8358/33650 (epoch 12.419), train_loss = 1.08727628, grad/param norm = 1.5059e-01, time/batch = 17.5627s	
8359/33650 (epoch 12.421), train_loss = 1.06742020, grad/param norm = 1.2908e-01, time/batch = 18.2373s	
8360/33650 (epoch 12.422), train_loss = 1.22909105, grad/param norm = 1.4185e-01, time/batch = 17.0638s	
8361/33650 (epoch 12.423), train_loss = 0.98610197, grad/param norm = 1.2009e-01, time/batch = 17.1405s	
8362/33650 (epoch 12.425), train_loss = 1.14958738, grad/param norm = 1.6342e-01, time/batch = 17.4766s	
8363/33650 (epoch 12.426), train_loss = 1.27541288, grad/param norm = 1.6313e-01, time/batch = 18.3776s	
8364/33650 (epoch 12.428), train_loss = 1.06623668, grad/param norm = 1.3824e-01, time/batch = 17.0629s	
8365/33650 (epoch 12.429), train_loss = 1.22950965, grad/param norm = 1.5814e-01, time/batch = 16.2161s	
8366/33650 (epoch 12.431), train_loss = 1.34440714, grad/param norm = 1.6882e-01, time/batch = 17.3926s	
8367/33650 (epoch 12.432), train_loss = 1.41682132, grad/param norm = 1.7131e-01, time/batch = 17.3867s	
8368/33650 (epoch 12.434), train_loss = 1.20250744, grad/param norm = 1.3953e-01, time/batch = 17.9715s	
8369/33650 (epoch 12.435), train_loss = 1.17531949, grad/param norm = 1.5321e-01, time/batch = 18.1437s	
8370/33650 (epoch 12.437), train_loss = 1.17537952, grad/param norm = 1.4851e-01, time/batch = 16.8092s	
8371/33650 (epoch 12.438), train_loss = 1.06055528, grad/param norm = 1.6303e-01, time/batch = 17.3914s	
8372/33650 (epoch 12.440), train_loss = 1.16051889, grad/param norm = 1.5288e-01, time/batch = 18.2194s	
8373/33650 (epoch 12.441), train_loss = 1.18510785, grad/param norm = 1.5327e-01, time/batch = 18.3903s	
8374/33650 (epoch 12.443), train_loss = 1.18172114, grad/param norm = 1.3977e-01, time/batch = 16.2306s	
8375/33650 (epoch 12.444), train_loss = 1.07074925, grad/param norm = 1.2544e-01, time/batch = 16.9761s	
8376/33650 (epoch 12.446), train_loss = 1.19522098, grad/param norm = 1.6461e-01, time/batch = 17.9834s	
8377/33650 (epoch 12.447), train_loss = 1.24630490, grad/param norm = 1.6154e-01, time/batch = 17.3107s	
8378/33650 (epoch 12.449), train_loss = 1.32538036, grad/param norm = 1.7331e-01, time/batch = 17.5637s	
8379/33650 (epoch 12.450), train_loss = 1.37167384, grad/param norm = 1.7499e-01, time/batch = 17.9809s	
8380/33650 (epoch 12.452), train_loss = 1.40896831, grad/param norm = 1.6157e-01, time/batch = 17.8075s	
8381/33650 (epoch 12.453), train_loss = 1.35367937, grad/param norm = 1.9251e-01, time/batch = 16.7118s	
8382/33650 (epoch 12.455), train_loss = 1.11936120, grad/param norm = 1.4179e-01, time/batch = 17.8106s	
8383/33650 (epoch 12.456), train_loss = 1.12984858, grad/param norm = 1.2962e-01, time/batch = 16.9587s	
8384/33650 (epoch 12.458), train_loss = 1.12033796, grad/param norm = 1.4781e-01, time/batch = 16.8996s	
8385/33650 (epoch 12.459), train_loss = 1.16262883, grad/param norm = 1.5884e-01, time/batch = 15.6563s	
8386/33650 (epoch 12.461), train_loss = 1.33681552, grad/param norm = 1.5989e-01, time/batch = 17.4928s	
8387/33650 (epoch 12.462), train_loss = 1.28791591, grad/param norm = 1.5907e-01, time/batch = 17.6495s	
8388/33650 (epoch 12.464), train_loss = 1.07975902, grad/param norm = 1.4304e-01, time/batch = 16.6403s	
8389/33650 (epoch 12.465), train_loss = 1.19009451, grad/param norm = 1.5735e-01, time/batch = 16.0603s	
8390/33650 (epoch 12.467), train_loss = 1.21516755, grad/param norm = 1.5596e-01, time/batch = 17.5651s	
8391/33650 (epoch 12.468), train_loss = 1.28200994, grad/param norm = 1.5692e-01, time/batch = 17.2236s	
8392/33650 (epoch 12.470), train_loss = 1.41186934, grad/param norm = 1.7508e-01, time/batch = 17.5639s	
8393/33650 (epoch 12.471), train_loss = 1.16822405, grad/param norm = 1.5923e-01, time/batch = 18.5662s	
8394/33650 (epoch 12.473), train_loss = 1.10435005, grad/param norm = 1.3819e-01, time/batch = 18.4925s	
8395/33650 (epoch 12.474), train_loss = 1.21668292, grad/param norm = 1.4219e-01, time/batch = 17.8930s	
8396/33650 (epoch 12.475), train_loss = 1.23797919, grad/param norm = 1.5524e-01, time/batch = 15.8705s	
8397/33650 (epoch 12.477), train_loss = 1.26909155, grad/param norm = 1.4873e-01, time/batch = 17.5612s	
8398/33650 (epoch 12.478), train_loss = 1.29209881, grad/param norm = 1.6299e-01, time/batch = 17.1421s	
8399/33650 (epoch 12.480), train_loss = 1.26797969, grad/param norm = 1.5774e-01, time/batch = 17.7230s	
8400/33650 (epoch 12.481), train_loss = 1.32105472, grad/param norm = 1.5556e-01, time/batch = 14.7100s	
8401/33650 (epoch 12.483), train_loss = 0.95180876, grad/param norm = 1.4798e-01, time/batch = 15.2909s	
8402/33650 (epoch 12.484), train_loss = 1.16617793, grad/param norm = 1.4223e-01, time/batch = 14.9361s	
8403/33650 (epoch 12.486), train_loss = 1.30055030, grad/param norm = 1.6338e-01, time/batch = 14.4979s	
8404/33650 (epoch 12.487), train_loss = 1.31209338, grad/param norm = 1.7713e-01, time/batch = 16.0425s	
8405/33650 (epoch 12.489), train_loss = 1.35351111, grad/param norm = 1.5406e-01, time/batch = 17.8024s	
8406/33650 (epoch 12.490), train_loss = 1.07603902, grad/param norm = 1.4430e-01, time/batch = 17.0592s	
8407/33650 (epoch 12.492), train_loss = 1.20802310, grad/param norm = 1.5999e-01, time/batch = 18.4843s	
8408/33650 (epoch 12.493), train_loss = 0.96535223, grad/param norm = 1.2450e-01, time/batch = 17.8976s	
8409/33650 (epoch 12.495), train_loss = 1.16456275, grad/param norm = 1.4498e-01, time/batch = 16.6459s	
8410/33650 (epoch 12.496), train_loss = 1.22649248, grad/param norm = 1.5034e-01, time/batch = 17.8097s	
8411/33650 (epoch 12.498), train_loss = 1.02763986, grad/param norm = 1.3335e-01, time/batch = 17.6568s	
8412/33650 (epoch 12.499), train_loss = 1.13843537, grad/param norm = 1.3115e-01, time/batch = 17.7305s	
8413/33650 (epoch 12.501), train_loss = 1.11190593, grad/param norm = 1.3444e-01, time/batch = 17.2316s	
8414/33650 (epoch 12.502), train_loss = 1.18099849, grad/param norm = 1.5366e-01, time/batch = 17.8052s	
8415/33650 (epoch 12.504), train_loss = 1.29613496, grad/param norm = 1.6206e-01, time/batch = 14.5310s	
8416/33650 (epoch 12.505), train_loss = 1.13811102, grad/param norm = 1.6041e-01, time/batch = 16.1856s	
8417/33650 (epoch 12.507), train_loss = 1.31277443, grad/param norm = 1.5636e-01, time/batch = 16.9764s	
8418/33650 (epoch 12.508), train_loss = 1.10274028, grad/param norm = 1.4280e-01, time/batch = 18.2235s	
8419/33650 (epoch 12.510), train_loss = 1.14350759, grad/param norm = 1.4057e-01, time/batch = 17.3134s	
8420/33650 (epoch 12.511), train_loss = 1.40257798, grad/param norm = 1.6791e-01, time/batch = 17.9779s	
8421/33650 (epoch 12.513), train_loss = 1.22881069, grad/param norm = 1.5213e-01, time/batch = 18.5676s	
8422/33650 (epoch 12.514), train_loss = 1.28379862, grad/param norm = 1.6422e-01, time/batch = 18.0612s	
8423/33650 (epoch 12.516), train_loss = 1.18113772, grad/param norm = 1.5813e-01, time/batch = 16.2180s	
8424/33650 (epoch 12.517), train_loss = 1.18449879, grad/param norm = 1.6320e-01, time/batch = 16.1438s	
8425/33650 (epoch 12.519), train_loss = 1.20136108, grad/param norm = 1.5140e-01, time/batch = 18.9709s	
8426/33650 (epoch 12.520), train_loss = 1.00527798, grad/param norm = 1.3218e-01, time/batch = 17.4639s	
8427/33650 (epoch 12.522), train_loss = 1.18069058, grad/param norm = 1.5871e-01, time/batch = 17.8181s	
8428/33650 (epoch 12.523), train_loss = 1.14981353, grad/param norm = 1.4357e-01, time/batch = 18.6557s	
8429/33650 (epoch 12.525), train_loss = 0.91485423, grad/param norm = 1.2743e-01, time/batch = 18.0712s	
8430/33650 (epoch 12.526), train_loss = 1.23202307, grad/param norm = 1.3994e-01, time/batch = 17.1480s	
8431/33650 (epoch 12.527), train_loss = 1.06912801, grad/param norm = 1.3918e-01, time/batch = 18.2167s	
8432/33650 (epoch 12.529), train_loss = 1.15247665, grad/param norm = 1.4127e-01, time/batch = 18.9726s	
8433/33650 (epoch 12.530), train_loss = 1.09331609, grad/param norm = 1.3805e-01, time/batch = 17.4639s	
8434/33650 (epoch 12.532), train_loss = 1.35771939, grad/param norm = 1.8157e-01, time/batch = 17.3822s	
8435/33650 (epoch 12.533), train_loss = 1.12421689, grad/param norm = 1.4958e-01, time/batch = 18.4038s	
8436/33650 (epoch 12.535), train_loss = 1.27016464, grad/param norm = 1.6115e-01, time/batch = 16.3065s	
8437/33650 (epoch 12.536), train_loss = 1.18633134, grad/param norm = 1.5427e-01, time/batch = 17.7915s	
8438/33650 (epoch 12.538), train_loss = 1.21878903, grad/param norm = 1.7263e-01, time/batch = 18.6432s	
8439/33650 (epoch 12.539), train_loss = 0.95097237, grad/param norm = 1.3080e-01, time/batch = 18.0655s	
8440/33650 (epoch 12.541), train_loss = 1.31117902, grad/param norm = 1.6186e-01, time/batch = 17.6439s	
8441/33650 (epoch 12.542), train_loss = 1.20764959, grad/param norm = 1.7359e-01, time/batch = 17.6557s	
8442/33650 (epoch 12.544), train_loss = 1.38847045, grad/param norm = 1.7746e-01, time/batch = 19.6285s	
8443/33650 (epoch 12.545), train_loss = 1.02598958, grad/param norm = 1.3274e-01, time/batch = 16.9668s	
8444/33650 (epoch 12.547), train_loss = 1.17858136, grad/param norm = 1.4705e-01, time/batch = 16.9202s	
8445/33650 (epoch 12.548), train_loss = 1.33078150, grad/param norm = 1.5071e-01, time/batch = 16.3773s	
8446/33650 (epoch 12.550), train_loss = 1.14043257, grad/param norm = 1.4769e-01, time/batch = 15.9672s	
8447/33650 (epoch 12.551), train_loss = 1.17645303, grad/param norm = 1.5303e-01, time/batch = 16.4799s	
8448/33650 (epoch 12.553), train_loss = 1.00919513, grad/param norm = 1.4334e-01, time/batch = 17.9747s	
8449/33650 (epoch 12.554), train_loss = 1.28388666, grad/param norm = 1.4372e-01, time/batch = 17.7274s	
8450/33650 (epoch 12.556), train_loss = 1.25060730, grad/param norm = 1.7160e-01, time/batch = 16.8083s	
8451/33650 (epoch 12.557), train_loss = 1.31914859, grad/param norm = 1.7419e-01, time/batch = 17.8864s	
8452/33650 (epoch 12.559), train_loss = 1.46207540, grad/param norm = 1.9294e-01, time/batch = 18.4867s	
8453/33650 (epoch 12.560), train_loss = 1.37744381, grad/param norm = 1.5632e-01, time/batch = 16.8894s	
8454/33650 (epoch 12.562), train_loss = 1.24773982, grad/param norm = 1.3714e-01, time/batch = 16.5480s	
8455/33650 (epoch 12.563), train_loss = 1.15041468, grad/param norm = 1.5169e-01, time/batch = 18.0610s	
8456/33650 (epoch 12.565), train_loss = 1.18184357, grad/param norm = 1.4421e-01, time/batch = 17.3971s	
8457/33650 (epoch 12.566), train_loss = 1.16813849, grad/param norm = 1.4676e-01, time/batch = 17.4709s	
8458/33650 (epoch 12.568), train_loss = 1.17708785, grad/param norm = 1.5190e-01, time/batch = 17.8150s	
8459/33650 (epoch 12.569), train_loss = 1.12970832, grad/param norm = 1.4933e-01, time/batch = 18.8945s	
8460/33650 (epoch 12.571), train_loss = 1.31557617, grad/param norm = 1.5921e-01, time/batch = 15.5434s	
8461/33650 (epoch 12.572), train_loss = 1.23002298, grad/param norm = 1.3580e-01, time/batch = 18.0599s	
8462/33650 (epoch 12.574), train_loss = 1.18282343, grad/param norm = 1.5827e-01, time/batch = 18.0521s	
8463/33650 (epoch 12.575), train_loss = 1.15520182, grad/param norm = 1.4893e-01, time/batch = 17.2175s	
8464/33650 (epoch 12.577), train_loss = 1.17752241, grad/param norm = 1.5297e-01, time/batch = 16.5632s	
8465/33650 (epoch 12.578), train_loss = 1.22622735, grad/param norm = 1.5278e-01, time/batch = 17.8056s	
8466/33650 (epoch 12.579), train_loss = 1.23680262, grad/param norm = 1.4279e-01, time/batch = 18.5610s	
8467/33650 (epoch 12.581), train_loss = 1.26104867, grad/param norm = 1.4669e-01, time/batch = 17.1473s	
8468/33650 (epoch 12.582), train_loss = 1.26273178, grad/param norm = 1.3665e-01, time/batch = 17.6574s	
8469/33650 (epoch 12.584), train_loss = 1.21436296, grad/param norm = 1.4662e-01, time/batch = 18.2337s	
8470/33650 (epoch 12.585), train_loss = 1.24051979, grad/param norm = 1.7394e-01, time/batch = 17.2263s	
8471/33650 (epoch 12.587), train_loss = 1.07716590, grad/param norm = 1.4774e-01, time/batch = 17.9788s	
8472/33650 (epoch 12.588), train_loss = 1.13826039, grad/param norm = 1.5810e-01, time/batch = 17.3043s	
8473/33650 (epoch 12.590), train_loss = 1.12828548, grad/param norm = 1.3635e-01, time/batch = 18.0658s	
8474/33650 (epoch 12.591), train_loss = 1.12373919, grad/param norm = 1.7244e-01, time/batch = 17.0472s	
8475/33650 (epoch 12.593), train_loss = 1.08510157, grad/param norm = 1.3036e-01, time/batch = 15.7393s	
8476/33650 (epoch 12.594), train_loss = 1.00964907, grad/param norm = 1.4644e-01, time/batch = 18.8111s	
8477/33650 (epoch 12.596), train_loss = 1.11156134, grad/param norm = 1.2741e-01, time/batch = 17.5507s	
8478/33650 (epoch 12.597), train_loss = 0.95049671, grad/param norm = 1.1962e-01, time/batch = 17.8900s	
8479/33650 (epoch 12.599), train_loss = 1.10226352, grad/param norm = 1.4565e-01, time/batch = 17.7279s	
8480/33650 (epoch 12.600), train_loss = 1.01167165, grad/param norm = 1.2575e-01, time/batch = 17.7375s	
8481/33650 (epoch 12.602), train_loss = 1.24383031, grad/param norm = 1.5893e-01, time/batch = 16.3895s	
8482/33650 (epoch 12.603), train_loss = 1.08959690, grad/param norm = 1.3772e-01, time/batch = 17.8860s	
8483/33650 (epoch 12.605), train_loss = 1.20481803, grad/param norm = 1.5392e-01, time/batch = 16.8957s	
8484/33650 (epoch 12.606), train_loss = 1.25032344, grad/param norm = 1.5044e-01, time/batch = 16.7253s	
8485/33650 (epoch 12.608), train_loss = 1.09641798, grad/param norm = 1.4514e-01, time/batch = 18.2300s	
8486/33650 (epoch 12.609), train_loss = 1.18009461, grad/param norm = 1.5082e-01, time/batch = 18.0575s	
8487/33650 (epoch 12.611), train_loss = 1.03570545, grad/param norm = 1.3919e-01, time/batch = 17.8963s	
8488/33650 (epoch 12.612), train_loss = 1.14957051, grad/param norm = 1.4815e-01, time/batch = 18.2188s	
8489/33650 (epoch 12.614), train_loss = 1.21517064, grad/param norm = 1.5235e-01, time/batch = 17.9910s	
8490/33650 (epoch 12.615), train_loss = 1.11346718, grad/param norm = 1.2893e-01, time/batch = 17.4822s	
8491/33650 (epoch 12.617), train_loss = 1.03128940, grad/param norm = 1.2454e-01, time/batch = 16.4672s	
8492/33650 (epoch 12.618), train_loss = 1.13073439, grad/param norm = 1.3947e-01, time/batch = 18.6464s	
8493/33650 (epoch 12.620), train_loss = 1.20030322, grad/param norm = 1.6123e-01, time/batch = 15.7235s	
8494/33650 (epoch 12.621), train_loss = 1.02566112, grad/param norm = 1.3239e-01, time/batch = 17.4717s	
8495/33650 (epoch 12.623), train_loss = 1.12962398, grad/param norm = 1.3949e-01, time/batch = 18.0586s	
8496/33650 (epoch 12.624), train_loss = 0.88503740, grad/param norm = 1.2566e-01, time/batch = 18.7191s	
8497/33650 (epoch 12.626), train_loss = 0.89875420, grad/param norm = 1.2623e-01, time/batch = 17.6462s	
8498/33650 (epoch 12.627), train_loss = 1.09094864, grad/param norm = 1.4655e-01, time/batch = 17.1529s	
8499/33650 (epoch 12.629), train_loss = 1.11621640, grad/param norm = 1.3577e-01, time/batch = 17.9590s	
8500/33650 (epoch 12.630), train_loss = 1.24885125, grad/param norm = 1.5877e-01, time/batch = 17.3263s	
8501/33650 (epoch 12.632), train_loss = 1.25297545, grad/param norm = 1.4174e-01, time/batch = 17.1536s	
8502/33650 (epoch 12.633), train_loss = 1.25822125, grad/param norm = 1.3959e-01, time/batch = 17.4879s	
8503/33650 (epoch 12.634), train_loss = 0.97190602, grad/param norm = 1.3371e-01, time/batch = 17.9005s	
8504/33650 (epoch 12.636), train_loss = 0.87971135, grad/param norm = 1.1545e-01, time/batch = 17.0564s	
8505/33650 (epoch 12.637), train_loss = 1.13512692, grad/param norm = 1.5011e-01, time/batch = 16.2867s	
8506/33650 (epoch 12.639), train_loss = 1.07667986, grad/param norm = 1.4354e-01, time/batch = 18.3199s	
8507/33650 (epoch 12.640), train_loss = 1.13316308, grad/param norm = 1.3863e-01, time/batch = 17.4076s	
8508/33650 (epoch 12.642), train_loss = 1.24139970, grad/param norm = 1.5776e-01, time/batch = 17.2167s	
8509/33650 (epoch 12.643), train_loss = 1.14998358, grad/param norm = 1.5214e-01, time/batch = 18.1534s	
8510/33650 (epoch 12.645), train_loss = 1.14463176, grad/param norm = 1.3640e-01, time/batch = 18.7376s	
8511/33650 (epoch 12.646), train_loss = 0.94702169, grad/param norm = 1.2538e-01, time/batch = 26.3572s	
8512/33650 (epoch 12.648), train_loss = 1.14393947, grad/param norm = 1.3640e-01, time/batch = 20.5992s	
8513/33650 (epoch 12.649), train_loss = 1.14556441, grad/param norm = 1.5977e-01, time/batch = 17.6379s	
8514/33650 (epoch 12.651), train_loss = 1.28300160, grad/param norm = 1.5331e-01, time/batch = 15.6005s	
8515/33650 (epoch 12.652), train_loss = 0.84277994, grad/param norm = 1.1116e-01, time/batch = 14.8912s	
8516/33650 (epoch 12.654), train_loss = 1.06694960, grad/param norm = 1.3963e-01, time/batch = 16.7901s	
8517/33650 (epoch 12.655), train_loss = 1.00493734, grad/param norm = 1.2593e-01, time/batch = 17.6370s	
8518/33650 (epoch 12.657), train_loss = 1.11743728, grad/param norm = 1.5748e-01, time/batch = 17.5418s	
8519/33650 (epoch 12.658), train_loss = 0.98978820, grad/param norm = 1.3390e-01, time/batch = 17.4887s	
8520/33650 (epoch 12.660), train_loss = 0.95063321, grad/param norm = 1.2808e-01, time/batch = 15.7441s	
8521/33650 (epoch 12.661), train_loss = 1.06568683, grad/param norm = 1.3774e-01, time/batch = 15.8938s	
8522/33650 (epoch 12.663), train_loss = 0.99383737, grad/param norm = 1.6029e-01, time/batch = 17.4782s	
8523/33650 (epoch 12.664), train_loss = 0.99141990, grad/param norm = 1.1699e-01, time/batch = 17.1541s	
8524/33650 (epoch 12.666), train_loss = 1.06852888, grad/param norm = 1.3975e-01, time/batch = 17.0638s	
8525/33650 (epoch 12.667), train_loss = 1.03164352, grad/param norm = 1.3427e-01, time/batch = 16.9018s	
8526/33650 (epoch 12.669), train_loss = 1.03390995, grad/param norm = 1.4672e-01, time/batch = 17.8137s	
8527/33650 (epoch 12.670), train_loss = 0.93916796, grad/param norm = 1.3887e-01, time/batch = 17.3992s	
8528/33650 (epoch 12.672), train_loss = 0.97387520, grad/param norm = 1.4761e-01, time/batch = 15.7980s	
8529/33650 (epoch 12.673), train_loss = 0.91047702, grad/param norm = 1.3241e-01, time/batch = 17.0450s	
8530/33650 (epoch 12.675), train_loss = 0.89706902, grad/param norm = 1.2157e-01, time/batch = 18.1467s	
8531/33650 (epoch 12.676), train_loss = 1.10829990, grad/param norm = 1.4239e-01, time/batch = 17.8144s	
8532/33650 (epoch 12.678), train_loss = 1.01266072, grad/param norm = 1.2793e-01, time/batch = 16.8727s	
8533/33650 (epoch 12.679), train_loss = 1.07519277, grad/param norm = 1.4354e-01, time/batch = 18.6265s	
8534/33650 (epoch 12.681), train_loss = 1.04735941, grad/param norm = 1.3099e-01, time/batch = 18.8780s	
8535/33650 (epoch 12.682), train_loss = 1.05459053, grad/param norm = 1.4636e-01, time/batch = 17.2059s	
8536/33650 (epoch 12.684), train_loss = 0.98822145, grad/param norm = 1.2466e-01, time/batch = 17.8849s	
8537/33650 (epoch 12.685), train_loss = 1.18544545, grad/param norm = 1.5181e-01, time/batch = 18.8930s	
8538/33650 (epoch 12.686), train_loss = 1.13105747, grad/param norm = 1.3965e-01, time/batch = 16.9878s	
8539/33650 (epoch 12.688), train_loss = 1.24386097, grad/param norm = 1.4755e-01, time/batch = 17.7214s	
8540/33650 (epoch 12.689), train_loss = 1.02964003, grad/param norm = 1.3530e-01, time/batch = 17.8148s	
8541/33650 (epoch 12.691), train_loss = 1.24360541, grad/param norm = 1.4397e-01, time/batch = 16.8051s	
8542/33650 (epoch 12.692), train_loss = 1.23051010, grad/param norm = 1.4796e-01, time/batch = 17.9638s	
8543/33650 (epoch 12.694), train_loss = 1.14969127, grad/param norm = 1.4883e-01, time/batch = 18.9760s	
8544/33650 (epoch 12.695), train_loss = 0.82049945, grad/param norm = 1.3258e-01, time/batch = 17.9123s	
8545/33650 (epoch 12.697), train_loss = 1.10195588, grad/param norm = 1.5336e-01, time/batch = 16.8814s	
8546/33650 (epoch 12.698), train_loss = 1.25281016, grad/param norm = 1.5127e-01, time/batch = 18.2246s	
8547/33650 (epoch 12.700), train_loss = 1.09111220, grad/param norm = 1.3512e-01, time/batch = 17.3015s	
8548/33650 (epoch 12.701), train_loss = 1.14588711, grad/param norm = 1.4909e-01, time/batch = 17.4793s	
8549/33650 (epoch 12.703), train_loss = 1.23802161, grad/param norm = 1.3696e-01, time/batch = 15.8137s	
8550/33650 (epoch 12.704), train_loss = 1.08050876, grad/param norm = 1.3602e-01, time/batch = 18.8955s	
8551/33650 (epoch 12.706), train_loss = 1.09374697, grad/param norm = 1.4242e-01, time/batch = 17.2295s	
8552/33650 (epoch 12.707), train_loss = 1.18861426, grad/param norm = 1.3987e-01, time/batch = 17.6242s	
8553/33650 (epoch 12.709), train_loss = 1.07411543, grad/param norm = 1.3739e-01, time/batch = 17.5590s	
8554/33650 (epoch 12.710), train_loss = 1.30736808, grad/param norm = 1.4395e-01, time/batch = 18.6411s	
8555/33650 (epoch 12.712), train_loss = 1.04191189, grad/param norm = 1.3805e-01, time/batch = 17.3132s	
8556/33650 (epoch 12.713), train_loss = 1.05948338, grad/param norm = 1.8022e-01, time/batch = 17.0575s	
8557/33650 (epoch 12.715), train_loss = 1.22515864, grad/param norm = 1.5352e-01, time/batch = 17.8094s	
8558/33650 (epoch 12.716), train_loss = 1.01220989, grad/param norm = 1.3575e-01, time/batch = 16.1400s	
8559/33650 (epoch 12.718), train_loss = 1.09166212, grad/param norm = 1.4891e-01, time/batch = 17.5712s	
8560/33650 (epoch 12.719), train_loss = 1.28630023, grad/param norm = 1.6706e-01, time/batch = 17.8968s	
8561/33650 (epoch 12.721), train_loss = 1.33572216, grad/param norm = 1.6651e-01, time/batch = 17.6636s	
8562/33650 (epoch 12.722), train_loss = 1.26276965, grad/param norm = 1.6775e-01, time/batch = 16.4701s	
8563/33650 (epoch 12.724), train_loss = 1.19742923, grad/param norm = 1.5453e-01, time/batch = 17.0013s	
8564/33650 (epoch 12.725), train_loss = 1.24739376, grad/param norm = 1.6337e-01, time/batch = 17.3202s	
8565/33650 (epoch 12.727), train_loss = 1.01733197, grad/param norm = 1.3841e-01, time/batch = 16.9863s	
8566/33650 (epoch 12.728), train_loss = 1.04698529, grad/param norm = 1.3729e-01, time/batch = 16.3760s	
8567/33650 (epoch 12.730), train_loss = 1.20869940, grad/param norm = 1.5051e-01, time/batch = 16.5692s	
8568/33650 (epoch 12.731), train_loss = 1.26850215, grad/param norm = 1.6320e-01, time/batch = 15.4031s	
8569/33650 (epoch 12.733), train_loss = 1.12384324, grad/param norm = 1.5488e-01, time/batch = 16.7298s	
8570/33650 (epoch 12.734), train_loss = 1.30319299, grad/param norm = 1.7718e-01, time/batch = 16.4972s	
8571/33650 (epoch 12.736), train_loss = 1.11055402, grad/param norm = 1.5196e-01, time/batch = 16.4459s	
8572/33650 (epoch 12.737), train_loss = 1.15888211, grad/param norm = 1.5155e-01, time/batch = 14.0282s	
8573/33650 (epoch 12.738), train_loss = 1.01261818, grad/param norm = 1.3782e-01, time/batch = 14.8000s	
8574/33650 (epoch 12.740), train_loss = 0.98137606, grad/param norm = 1.3432e-01, time/batch = 16.1552s	
8575/33650 (epoch 12.741), train_loss = 1.06410266, grad/param norm = 1.3988e-01, time/batch = 17.4028s	
8576/33650 (epoch 12.743), train_loss = 1.11808727, grad/param norm = 1.3748e-01, time/batch = 16.4819s	
8577/33650 (epoch 12.744), train_loss = 1.10845754, grad/param norm = 1.3664e-01, time/batch = 16.6381s	
8578/33650 (epoch 12.746), train_loss = 1.09437487, grad/param norm = 1.4338e-01, time/batch = 16.7361s	
8579/33650 (epoch 12.747), train_loss = 1.22499534, grad/param norm = 1.4019e-01, time/batch = 17.3188s	
8580/33650 (epoch 12.749), train_loss = 0.94218388, grad/param norm = 1.3272e-01, time/batch = 15.6491s	
8581/33650 (epoch 12.750), train_loss = 1.24667726, grad/param norm = 1.4685e-01, time/batch = 17.6485s	
8582/33650 (epoch 12.752), train_loss = 1.26232313, grad/param norm = 1.5788e-01, time/batch = 16.4542s	
8583/33650 (epoch 12.753), train_loss = 1.38687281, grad/param norm = 1.7549e-01, time/batch = 17.0639s	
8584/33650 (epoch 12.755), train_loss = 1.04959395, grad/param norm = 1.2818e-01, time/batch = 16.1504s	
8585/33650 (epoch 12.756), train_loss = 1.24637997, grad/param norm = 1.5739e-01, time/batch = 14.8988s	
8586/33650 (epoch 12.758), train_loss = 1.22467612, grad/param norm = 1.4255e-01, time/batch = 17.8984s	
8587/33650 (epoch 12.759), train_loss = 1.31366823, grad/param norm = 1.5853e-01, time/batch = 16.2086s	
8588/33650 (epoch 12.761), train_loss = 1.20352917, grad/param norm = 1.5175e-01, time/batch = 16.9746s	
8589/33650 (epoch 12.762), train_loss = 1.15903557, grad/param norm = 1.4328e-01, time/batch = 17.4734s	
8590/33650 (epoch 12.764), train_loss = 1.21765653, grad/param norm = 1.5785e-01, time/batch = 17.1450s	
8591/33650 (epoch 12.765), train_loss = 1.15414290, grad/param norm = 1.4356e-01, time/batch = 16.8076s	
8592/33650 (epoch 12.767), train_loss = 1.09297245, grad/param norm = 1.3109e-01, time/batch = 16.3990s	
8593/33650 (epoch 12.768), train_loss = 0.99300182, grad/param norm = 1.3399e-01, time/batch = 17.1400s	
8594/33650 (epoch 12.770), train_loss = 1.13716795, grad/param norm = 1.4150e-01, time/batch = 16.3234s	
8595/33650 (epoch 12.771), train_loss = 1.13993889, grad/param norm = 1.4514e-01, time/batch = 17.3940s	
8596/33650 (epoch 12.773), train_loss = 1.28533048, grad/param norm = 1.6742e-01, time/batch = 17.4062s	
8597/33650 (epoch 12.774), train_loss = 1.18616240, grad/param norm = 1.6527e-01, time/batch = 17.0689s	
8598/33650 (epoch 12.776), train_loss = 1.22038841, grad/param norm = 1.5610e-01, time/batch = 15.3791s	
8599/33650 (epoch 12.777), train_loss = 0.98545680, grad/param norm = 1.2695e-01, time/batch = 15.8793s	
8600/33650 (epoch 12.779), train_loss = 1.11094823, grad/param norm = 1.4513e-01, time/batch = 15.9748s	
8601/33650 (epoch 12.780), train_loss = 1.03533900, grad/param norm = 1.2496e-01, time/batch = 16.3512s	
8602/33650 (epoch 12.782), train_loss = 1.04890091, grad/param norm = 1.4066e-01, time/batch = 17.1436s	
8603/33650 (epoch 12.783), train_loss = 1.02655513, grad/param norm = 1.3692e-01, time/batch = 17.2303s	
8604/33650 (epoch 12.785), train_loss = 1.34307069, grad/param norm = 1.4521e-01, time/batch = 16.9066s	
8605/33650 (epoch 12.786), train_loss = 1.16228914, grad/param norm = 1.3900e-01, time/batch = 16.3032s	
8606/33650 (epoch 12.788), train_loss = 1.15697887, grad/param norm = 1.3049e-01, time/batch = 17.1425s	
8607/33650 (epoch 12.789), train_loss = 1.19924268, grad/param norm = 1.4281e-01, time/batch = 17.0710s	
8608/33650 (epoch 12.790), train_loss = 1.19490912, grad/param norm = 1.6748e-01, time/batch = 17.3234s	
8609/33650 (epoch 12.792), train_loss = 1.27648014, grad/param norm = 1.7134e-01, time/batch = 17.2260s	
8610/33650 (epoch 12.793), train_loss = 1.21480063, grad/param norm = 1.6081e-01, time/batch = 17.6645s	
8611/33650 (epoch 12.795), train_loss = 1.26429289, grad/param norm = 1.3822e-01, time/batch = 15.7246s	
8612/33650 (epoch 12.796), train_loss = 1.11493468, grad/param norm = 1.4428e-01, time/batch = 15.8969s	
8613/33650 (epoch 12.798), train_loss = 1.10770973, grad/param norm = 1.4548e-01, time/batch = 17.1590s	
8614/33650 (epoch 12.799), train_loss = 1.13493036, grad/param norm = 1.3131e-01, time/batch = 17.4030s	
8615/33650 (epoch 12.801), train_loss = 1.18755999, grad/param norm = 1.5351e-01, time/batch = 17.9845s	
8616/33650 (epoch 12.802), train_loss = 1.25439876, grad/param norm = 1.4314e-01, time/batch = 15.0863s	
8617/33650 (epoch 12.804), train_loss = 1.13455353, grad/param norm = 1.5237e-01, time/batch = 15.3827s	
8618/33650 (epoch 12.805), train_loss = 1.08159279, grad/param norm = 1.2914e-01, time/batch = 13.8254s	
8619/33650 (epoch 12.807), train_loss = 1.36744058, grad/param norm = 1.6919e-01, time/batch = 13.3169s	
8620/33650 (epoch 12.808), train_loss = 1.35700607, grad/param norm = 1.6625e-01, time/batch = 13.6555s	
8621/33650 (epoch 12.810), train_loss = 1.21051873, grad/param norm = 1.4377e-01, time/batch = 13.8241s	
8622/33650 (epoch 12.811), train_loss = 1.17984619, grad/param norm = 1.5640e-01, time/batch = 13.5816s	
8623/33650 (epoch 12.813), train_loss = 1.11966502, grad/param norm = 1.4573e-01, time/batch = 13.8848s	
8624/33650 (epoch 12.814), train_loss = 1.22529657, grad/param norm = 1.4265e-01, time/batch = 13.5695s	
8625/33650 (epoch 12.816), train_loss = 1.17970927, grad/param norm = 1.4407e-01, time/batch = 13.5663s	
8626/33650 (epoch 12.817), train_loss = 1.23185795, grad/param norm = 1.6175e-01, time/batch = 13.4209s	
8627/33650 (epoch 12.819), train_loss = 1.25412600, grad/param norm = 1.4409e-01, time/batch = 13.4114s	
8628/33650 (epoch 12.820), train_loss = 1.28534001, grad/param norm = 1.4522e-01, time/batch = 13.4071s	
8629/33650 (epoch 12.822), train_loss = 1.24761801, grad/param norm = 1.7458e-01, time/batch = 13.6562s	
8630/33650 (epoch 12.823), train_loss = 1.06799093, grad/param norm = 1.5754e-01, time/batch = 13.4144s	
8631/33650 (epoch 12.825), train_loss = 1.13301279, grad/param norm = 1.3460e-01, time/batch = 13.5624s	
8632/33650 (epoch 12.826), train_loss = 1.23391521, grad/param norm = 1.4678e-01, time/batch = 13.4891s	
8633/33650 (epoch 12.828), train_loss = 1.38283863, grad/param norm = 1.5777e-01, time/batch = 14.1420s	
8634/33650 (epoch 12.829), train_loss = 0.99802018, grad/param norm = 1.3888e-01, time/batch = 13.6544s	
8635/33650 (epoch 12.831), train_loss = 1.23645472, grad/param norm = 1.5792e-01, time/batch = 13.5004s	
8636/33650 (epoch 12.832), train_loss = 1.20070554, grad/param norm = 1.3744e-01, time/batch = 13.4192s	
8637/33650 (epoch 12.834), train_loss = 1.24273751, grad/param norm = 1.4824e-01, time/batch = 13.8944s	
8638/33650 (epoch 12.835), train_loss = 1.40024803, grad/param norm = 1.6930e-01, time/batch = 13.4949s	
8639/33650 (epoch 12.837), train_loss = 1.21934489, grad/param norm = 1.7168e-01, time/batch = 13.3300s	
8640/33650 (epoch 12.838), train_loss = 1.14812357, grad/param norm = 1.5149e-01, time/batch = 13.4194s	
8641/33650 (epoch 12.840), train_loss = 1.24897746, grad/param norm = 1.4639e-01, time/batch = 13.7332s	
8642/33650 (epoch 12.841), train_loss = 1.06331939, grad/param norm = 1.3511e-01, time/batch = 13.6549s	
8643/33650 (epoch 12.842), train_loss = 1.11530356, grad/param norm = 1.4232e-01, time/batch = 13.5817s	
8644/33650 (epoch 12.844), train_loss = 1.30183116, grad/param norm = 1.5021e-01, time/batch = 13.4101s	
8645/33650 (epoch 12.845), train_loss = 1.08686859, grad/param norm = 1.3284e-01, time/batch = 13.7377s	
8646/33650 (epoch 12.847), train_loss = 0.91608252, grad/param norm = 1.2989e-01, time/batch = 13.7414s	
8647/33650 (epoch 12.848), train_loss = 0.99033052, grad/param norm = 1.4436e-01, time/batch = 13.6457s	
8648/33650 (epoch 12.850), train_loss = 1.15615792, grad/param norm = 1.6533e-01, time/batch = 13.3224s	
8649/33650 (epoch 12.851), train_loss = 0.93411227, grad/param norm = 1.2580e-01, time/batch = 13.3300s	
8650/33650 (epoch 12.853), train_loss = 1.18019945, grad/param norm = 1.5585e-01, time/batch = 13.4958s	
8651/33650 (epoch 12.854), train_loss = 1.28642614, grad/param norm = 1.6480e-01, time/batch = 13.7283s	
8652/33650 (epoch 12.856), train_loss = 0.87909121, grad/param norm = 1.2504e-01, time/batch = 13.6425s	
8653/33650 (epoch 12.857), train_loss = 1.12244457, grad/param norm = 1.3138e-01, time/batch = 13.4902s	
8654/33650 (epoch 12.859), train_loss = 1.02910902, grad/param norm = 1.2659e-01, time/batch = 13.3256s	
8655/33650 (epoch 12.860), train_loss = 0.95003458, grad/param norm = 1.3524e-01, time/batch = 13.7304s	
8656/33650 (epoch 12.862), train_loss = 1.02775254, grad/param norm = 1.4092e-01, time/batch = 13.5796s	
8657/33650 (epoch 12.863), train_loss = 1.22469321, grad/param norm = 1.4756e-01, time/batch = 13.3320s	
8658/33650 (epoch 12.865), train_loss = 1.11829736, grad/param norm = 1.4082e-01, time/batch = 13.4887s	
8659/33650 (epoch 12.866), train_loss = 1.01532547, grad/param norm = 1.3455e-01, time/batch = 13.8888s	
8660/33650 (epoch 12.868), train_loss = 1.01903922, grad/param norm = 1.4363e-01, time/batch = 13.6456s	
8661/33650 (epoch 12.869), train_loss = 1.27200880, grad/param norm = 1.5151e-01, time/batch = 13.5861s	
8662/33650 (epoch 12.871), train_loss = 0.98337840, grad/param norm = 1.1653e-01, time/batch = 13.4883s	
8663/33650 (epoch 12.872), train_loss = 1.14335084, grad/param norm = 1.4596e-01, time/batch = 13.4131s	
8664/33650 (epoch 12.874), train_loss = 1.22812885, grad/param norm = 1.6211e-01, time/batch = 13.6439s	
8665/33650 (epoch 12.875), train_loss = 1.10582488, grad/param norm = 1.3805e-01, time/batch = 13.6581s	
8666/33650 (epoch 12.877), train_loss = 1.27220883, grad/param norm = 1.4879e-01, time/batch = 13.4142s	
8667/33650 (epoch 12.878), train_loss = 0.81610789, grad/param norm = 1.2567e-01, time/batch = 13.7298s	
8668/33650 (epoch 12.880), train_loss = 1.18804003, grad/param norm = 1.5262e-01, time/batch = 13.8966s	
8669/33650 (epoch 12.881), train_loss = 1.08872941, grad/param norm = 1.5878e-01, time/batch = 13.4927s	
8670/33650 (epoch 12.883), train_loss = 1.13285447, grad/param norm = 1.4293e-01, time/batch = 13.3220s	
8671/33650 (epoch 12.884), train_loss = 1.25825722, grad/param norm = 1.5725e-01, time/batch = 13.5688s	
8672/33650 (epoch 12.886), train_loss = 1.25273578, grad/param norm = 1.5155e-01, time/batch = 13.5684s	
8673/33650 (epoch 12.887), train_loss = 1.04623435, grad/param norm = 1.2733e-01, time/batch = 13.7404s	
8674/33650 (epoch 12.889), train_loss = 1.22061970, grad/param norm = 1.6359e-01, time/batch = 13.5751s	
8675/33650 (epoch 12.890), train_loss = 1.20059066, grad/param norm = 1.3661e-01, time/batch = 13.6590s	
8676/33650 (epoch 12.892), train_loss = 1.17907346, grad/param norm = 1.6359e-01, time/batch = 13.5804s	
8677/33650 (epoch 12.893), train_loss = 1.19273978, grad/param norm = 1.4468e-01, time/batch = 13.9647s	
8678/33650 (epoch 12.895), train_loss = 1.29087498, grad/param norm = 1.5728e-01, time/batch = 13.4195s	
8679/33650 (epoch 12.896), train_loss = 1.04322155, grad/param norm = 1.3016e-01, time/batch = 13.4871s	
8680/33650 (epoch 12.897), train_loss = 0.98785599, grad/param norm = 1.3108e-01, time/batch = 13.4140s	
8681/33650 (epoch 12.899), train_loss = 1.01254884, grad/param norm = 1.2995e-01, time/batch = 13.8961s	
8682/33650 (epoch 12.900), train_loss = 0.92499856, grad/param norm = 1.2179e-01, time/batch = 13.6587s	
8683/33650 (epoch 12.902), train_loss = 1.16514500, grad/param norm = 1.5467e-01, time/batch = 13.4077s	
8684/33650 (epoch 12.903), train_loss = 1.13454819, grad/param norm = 1.7063e-01, time/batch = 13.5053s	
8685/33650 (epoch 12.905), train_loss = 1.33897911, grad/param norm = 1.7848e-01, time/batch = 13.4095s	
8686/33650 (epoch 12.906), train_loss = 1.10345675, grad/param norm = 1.5107e-01, time/batch = 13.8981s	
8687/33650 (epoch 12.908), train_loss = 1.07553948, grad/param norm = 1.2933e-01, time/batch = 13.6428s	
8688/33650 (epoch 12.909), train_loss = 1.09266251, grad/param norm = 1.3797e-01, time/batch = 13.4174s	
8689/33650 (epoch 12.911), train_loss = 0.94813252, grad/param norm = 1.2560e-01, time/batch = 13.3279s	
8690/33650 (epoch 12.912), train_loss = 0.94792427, grad/param norm = 1.2474e-01, time/batch = 13.8067s	
8691/33650 (epoch 12.914), train_loss = 1.12409185, grad/param norm = 1.3543e-01, time/batch = 13.7379s	
8692/33650 (epoch 12.915), train_loss = 1.14489019, grad/param norm = 1.5735e-01, time/batch = 13.4140s	
8693/33650 (epoch 12.917), train_loss = 1.12922799, grad/param norm = 1.5089e-01, time/batch = 13.8951s	
8694/33650 (epoch 12.918), train_loss = 0.91315218, grad/param norm = 1.2692e-01, time/batch = 13.5732s	
8695/33650 (epoch 12.920), train_loss = 1.03521430, grad/param norm = 1.2892e-01, time/batch = 13.4027s	
8696/33650 (epoch 12.921), train_loss = 1.01769114, grad/param norm = 1.3702e-01, time/batch = 13.4161s	
8697/33650 (epoch 12.923), train_loss = 0.98792305, grad/param norm = 1.3831e-01, time/batch = 13.3205s	
8698/33650 (epoch 12.924), train_loss = 1.13518138, grad/param norm = 1.5035e-01, time/batch = 13.7971s	
8699/33650 (epoch 12.926), train_loss = 1.11988865, grad/param norm = 1.6314e-01, time/batch = 13.8971s	
8700/33650 (epoch 12.927), train_loss = 1.05870817, grad/param norm = 1.4217e-01, time/batch = 13.5695s	
8701/33650 (epoch 12.929), train_loss = 1.15145058, grad/param norm = 1.4832e-01, time/batch = 13.3338s	
8702/33650 (epoch 12.930), train_loss = 1.06032239, grad/param norm = 1.3620e-01, time/batch = 13.3307s	
8703/33650 (epoch 12.932), train_loss = 1.12762034, grad/param norm = 1.4487e-01, time/batch = 13.8160s	
8704/33650 (epoch 12.933), train_loss = 0.96794376, grad/param norm = 1.3181e-01, time/batch = 13.4984s	
8705/33650 (epoch 12.935), train_loss = 1.01577686, grad/param norm = 1.3470e-01, time/batch = 16.4089s	
8706/33650 (epoch 12.936), train_loss = 1.02548866, grad/param norm = 1.4115e-01, time/batch = 17.3242s	
8707/33650 (epoch 12.938), train_loss = 0.94519898, grad/param norm = 1.3416e-01, time/batch = 15.8976s	
8708/33650 (epoch 12.939), train_loss = 1.16597840, grad/param norm = 1.3720e-01, time/batch = 16.7236s	
8709/33650 (epoch 12.941), train_loss = 1.13346836, grad/param norm = 1.5015e-01, time/batch = 18.0696s	
8710/33650 (epoch 12.942), train_loss = 1.19753083, grad/param norm = 1.4777e-01, time/batch = 16.0446s	
8711/33650 (epoch 12.944), train_loss = 1.12957996, grad/param norm = 1.3432e-01, time/batch = 16.5627s	
8712/33650 (epoch 12.945), train_loss = 1.19726687, grad/param norm = 1.5693e-01, time/batch = 17.6532s	
8713/33650 (epoch 12.947), train_loss = 1.34893395, grad/param norm = 1.7595e-01, time/batch = 17.7297s	
8714/33650 (epoch 12.948), train_loss = 1.24502936, grad/param norm = 1.3901e-01, time/batch = 16.8084s	
8715/33650 (epoch 12.949), train_loss = 1.01575059, grad/param norm = 1.3883e-01, time/batch = 17.2277s	
8716/33650 (epoch 12.951), train_loss = 1.27646234, grad/param norm = 1.5456e-01, time/batch = 17.3170s	
8717/33650 (epoch 12.952), train_loss = 1.21974052, grad/param norm = 1.5984e-01, time/batch = 17.0331s	
8718/33650 (epoch 12.954), train_loss = 1.19429694, grad/param norm = 1.4562e-01, time/batch = 16.6287s	
8719/33650 (epoch 12.955), train_loss = 1.20861313, grad/param norm = 1.5325e-01, time/batch = 16.2257s	
8720/33650 (epoch 12.957), train_loss = 1.18955227, grad/param norm = 1.4796e-01, time/batch = 17.4845s	
8721/33650 (epoch 12.958), train_loss = 0.86833682, grad/param norm = 1.1734e-01, time/batch = 16.8072s	
8722/33650 (epoch 12.960), train_loss = 0.96996112, grad/param norm = 1.3329e-01, time/batch = 17.0475s	
8723/33650 (epoch 12.961), train_loss = 1.01487065, grad/param norm = 1.4536e-01, time/batch = 18.2256s	
8724/33650 (epoch 12.963), train_loss = 1.08600261, grad/param norm = 1.5139e-01, time/batch = 14.3477s	
8725/33650 (epoch 12.964), train_loss = 1.13291085, grad/param norm = 1.5231e-01, time/batch = 13.7824s	
8726/33650 (epoch 12.966), train_loss = 1.11634716, grad/param norm = 1.4992e-01, time/batch = 13.6519s	
8727/33650 (epoch 12.967), train_loss = 1.18495905, grad/param norm = 1.4810e-01, time/batch = 13.4024s	
8728/33650 (epoch 12.969), train_loss = 1.07973486, grad/param norm = 1.3398e-01, time/batch = 13.5294s	
8729/33650 (epoch 12.970), train_loss = 1.17612916, grad/param norm = 1.4909e-01, time/batch = 14.4427s	
8730/33650 (epoch 12.972), train_loss = 1.47073077, grad/param norm = 1.6763e-01, time/batch = 13.4918s	
8731/33650 (epoch 12.973), train_loss = 1.02998845, grad/param norm = 1.3831e-01, time/batch = 13.7321s	
8732/33650 (epoch 12.975), train_loss = 1.01625472, grad/param norm = 1.3533e-01, time/batch = 13.4165s	
8733/33650 (epoch 12.976), train_loss = 0.99170041, grad/param norm = 1.2297e-01, time/batch = 13.4862s	
8734/33650 (epoch 12.978), train_loss = 1.04841800, grad/param norm = 1.5228e-01, time/batch = 13.6517s	
8735/33650 (epoch 12.979), train_loss = 1.10497631, grad/param norm = 1.3579e-01, time/batch = 13.4096s	
8736/33650 (epoch 12.981), train_loss = 1.05626836, grad/param norm = 1.2464e-01, time/batch = 13.5843s	
8737/33650 (epoch 12.982), train_loss = 1.13917681, grad/param norm = 1.3495e-01, time/batch = 13.4173s	
8738/33650 (epoch 12.984), train_loss = 0.98903080, grad/param norm = 1.2844e-01, time/batch = 13.8145s	
8739/33650 (epoch 12.985), train_loss = 0.95363941, grad/param norm = 1.2663e-01, time/batch = 13.6625s	
8740/33650 (epoch 12.987), train_loss = 1.08933793, grad/param norm = 1.3407e-01, time/batch = 13.5039s	
8741/33650 (epoch 12.988), train_loss = 1.16808175, grad/param norm = 1.4747e-01, time/batch = 13.5040s	
8742/33650 (epoch 12.990), train_loss = 1.35544279, grad/param norm = 1.7920e-01, time/batch = 17.3566s	
8743/33650 (epoch 12.991), train_loss = 1.17477136, grad/param norm = 1.3061e-01, time/batch = 21.7205s	
8744/33650 (epoch 12.993), train_loss = 1.16053514, grad/param norm = 1.5541e-01, time/batch = 13.4196s	
8745/33650 (epoch 12.994), train_loss = 1.07643308, grad/param norm = 1.4908e-01, time/batch = 13.3311s	
8746/33650 (epoch 12.996), train_loss = 1.04731064, grad/param norm = 1.4023e-01, time/batch = 13.9808s	
8747/33650 (epoch 12.997), train_loss = 1.15618080, grad/param norm = 1.5050e-01, time/batch = 13.5731s	
8748/33650 (epoch 12.999), train_loss = 0.98609936, grad/param norm = 1.3779e-01, time/batch = 13.7370s	
decayed learning rate by a factor 0.97 to 0.00177058562	
8749/33650 (epoch 13.000), train_loss = 1.18988242, grad/param norm = 1.5583e-01, time/batch = 13.9065s	
8750/33650 (epoch 13.001), train_loss = 1.28427907, grad/param norm = 1.5356e-01, time/batch = 14.0338s	
8751/33650 (epoch 13.003), train_loss = 1.31397270, grad/param norm = 1.6797e-01, time/batch = 13.7447s	
8752/33650 (epoch 13.004), train_loss = 1.17749028, grad/param norm = 1.5484e-01, time/batch = 13.4204s	
8753/33650 (epoch 13.006), train_loss = 1.07037991, grad/param norm = 1.3399e-01, time/batch = 13.4955s	
8754/33650 (epoch 13.007), train_loss = 1.16942152, grad/param norm = 1.5325e-01, time/batch = 13.4922s	
8755/33650 (epoch 13.009), train_loss = 1.07846628, grad/param norm = 1.3859e-01, time/batch = 13.7207s	
8756/33650 (epoch 13.010), train_loss = 1.19637139, grad/param norm = 1.5343e-01, time/batch = 13.3288s	
8757/33650 (epoch 13.012), train_loss = 1.07761270, grad/param norm = 1.5097e-01, time/batch = 14.3536s	
8758/33650 (epoch 13.013), train_loss = 1.16540311, grad/param norm = 1.6535e-01, time/batch = 13.8889s	
8759/33650 (epoch 13.015), train_loss = 1.02160676, grad/param norm = 1.3621e-01, time/batch = 14.3572s	
8760/33650 (epoch 13.016), train_loss = 1.01494362, grad/param norm = 1.5238e-01, time/batch = 13.5036s	
8761/33650 (epoch 13.018), train_loss = 1.10788652, grad/param norm = 1.4781e-01, time/batch = 13.8244s	
8762/33650 (epoch 13.019), train_loss = 1.03402160, grad/param norm = 1.3495e-01, time/batch = 13.9838s	
8763/33650 (epoch 13.021), train_loss = 1.22888273, grad/param norm = 1.4356e-01, time/batch = 14.2770s	
8764/33650 (epoch 13.022), train_loss = 1.06856957, grad/param norm = 1.3811e-01, time/batch = 13.6558s	
8765/33650 (epoch 13.024), train_loss = 0.99330251, grad/param norm = 1.4063e-01, time/batch = 13.4824s	
8766/33650 (epoch 13.025), train_loss = 1.06962334, grad/param norm = 1.3298e-01, time/batch = 13.5754s	
8767/33650 (epoch 13.027), train_loss = 1.20534863, grad/param norm = 1.4751e-01, time/batch = 13.6561s	
8768/33650 (epoch 13.028), train_loss = 1.19817583, grad/param norm = 1.4728e-01, time/batch = 13.7361s	
8769/33650 (epoch 13.030), train_loss = 1.15062646, grad/param norm = 1.4200e-01, time/batch = 13.7289s	
8770/33650 (epoch 13.031), train_loss = 0.98881821, grad/param norm = 1.2570e-01, time/batch = 13.5705s	
8771/33650 (epoch 13.033), train_loss = 1.07753299, grad/param norm = 1.2861e-01, time/batch = 13.4165s	
8772/33650 (epoch 13.034), train_loss = 1.16199577, grad/param norm = 1.5122e-01, time/batch = 13.8173s	
8773/33650 (epoch 13.036), train_loss = 1.25733932, grad/param norm = 1.5489e-01, time/batch = 13.6508s	
8774/33650 (epoch 13.037), train_loss = 1.04442994, grad/param norm = 1.4630e-01, time/batch = 13.4850s	
8775/33650 (epoch 13.039), train_loss = 1.22974521, grad/param norm = 1.4734e-01, time/batch = 13.4925s	
8776/33650 (epoch 13.040), train_loss = 1.32113616, grad/param norm = 1.6982e-01, time/batch = 13.7342s	
8777/33650 (epoch 13.042), train_loss = 1.31971784, grad/param norm = 1.5579e-01, time/batch = 13.6582s	
8778/33650 (epoch 13.043), train_loss = 1.05512077, grad/param norm = 1.5312e-01, time/batch = 13.5770s	
8779/33650 (epoch 13.045), train_loss = 1.02209693, grad/param norm = 1.2980e-01, time/batch = 13.4169s	
8780/33650 (epoch 13.046), train_loss = 1.19288400, grad/param norm = 1.4787e-01, time/batch = 13.4932s	
8781/33650 (epoch 13.048), train_loss = 1.21514066, grad/param norm = 1.4549e-01, time/batch = 13.9822s	
8782/33650 (epoch 13.049), train_loss = 1.15006112, grad/param norm = 1.5035e-01, time/batch = 13.4945s	
8783/33650 (epoch 13.051), train_loss = 1.25219377, grad/param norm = 1.4786e-01, time/batch = 13.4112s	
8784/33650 (epoch 13.052), train_loss = 1.29308893, grad/param norm = 1.5396e-01, time/batch = 13.5771s	
8785/33650 (epoch 13.053), train_loss = 1.14352708, grad/param norm = 1.3804e-01, time/batch = 13.8152s	
8786/33650 (epoch 13.055), train_loss = 0.99328498, grad/param norm = 1.3751e-01, time/batch = 13.4950s	
8787/33650 (epoch 13.056), train_loss = 0.98546734, grad/param norm = 1.2572e-01, time/batch = 13.5676s	
8788/33650 (epoch 13.058), train_loss = 1.25568928, grad/param norm = 1.7604e-01, time/batch = 13.7214s	
8789/33650 (epoch 13.059), train_loss = 1.17673898, grad/param norm = 1.4557e-01, time/batch = 13.8082s	
8790/33650 (epoch 13.061), train_loss = 1.20272999, grad/param norm = 1.5197e-01, time/batch = 13.4102s	
8791/33650 (epoch 13.062), train_loss = 1.17442486, grad/param norm = 1.3383e-01, time/batch = 13.5714s	
8792/33650 (epoch 13.064), train_loss = 1.06816176, grad/param norm = 1.3410e-01, time/batch = 13.4968s	
8793/33650 (epoch 13.065), train_loss = 1.07534860, grad/param norm = 1.3694e-01, time/batch = 13.6455s	
8794/33650 (epoch 13.067), train_loss = 1.00880386, grad/param norm = 1.3269e-01, time/batch = 13.9019s	
8795/33650 (epoch 13.068), train_loss = 1.14338160, grad/param norm = 1.4857e-01, time/batch = 13.7305s	
8796/33650 (epoch 13.070), train_loss = 1.13214140, grad/param norm = 1.4510e-01, time/batch = 13.7433s	
8797/33650 (epoch 13.071), train_loss = 1.12197324, grad/param norm = 1.3289e-01, time/batch = 13.8000s	
8798/33650 (epoch 13.073), train_loss = 1.16457589, grad/param norm = 1.4897e-01, time/batch = 13.6565s	
8799/33650 (epoch 13.074), train_loss = 1.24145986, grad/param norm = 1.4923e-01, time/batch = 13.4916s	
8800/33650 (epoch 13.076), train_loss = 1.22718303, grad/param norm = 1.5388e-01, time/batch = 13.8094s	
8801/33650 (epoch 13.077), train_loss = 1.11293410, grad/param norm = 1.3484e-01, time/batch = 13.8175s	
8802/33650 (epoch 13.079), train_loss = 1.10136092, grad/param norm = 1.4695e-01, time/batch = 13.4779s	
8803/33650 (epoch 13.080), train_loss = 1.18509538, grad/param norm = 1.4216e-01, time/batch = 13.5746s	
8804/33650 (epoch 13.082), train_loss = 1.21295648, grad/param norm = 1.5650e-01, time/batch = 13.3363s	
8805/33650 (epoch 13.083), train_loss = 1.18463534, grad/param norm = 1.3997e-01, time/batch = 13.4106s	
8806/33650 (epoch 13.085), train_loss = 1.20910864, grad/param norm = 1.3530e-01, time/batch = 13.7430s	
8807/33650 (epoch 13.086), train_loss = 1.23962156, grad/param norm = 1.5861e-01, time/batch = 13.9692s	
8808/33650 (epoch 13.088), train_loss = 1.18060377, grad/param norm = 1.4550e-01, time/batch = 13.5754s	
8809/33650 (epoch 13.089), train_loss = 1.15308169, grad/param norm = 1.4948e-01, time/batch = 13.4153s	
8810/33650 (epoch 13.091), train_loss = 1.07253323, grad/param norm = 1.3115e-01, time/batch = 13.3360s	
8811/33650 (epoch 13.092), train_loss = 1.11501768, grad/param norm = 1.4243e-01, time/batch = 14.8971s	
8812/33650 (epoch 13.094), train_loss = 1.17156123, grad/param norm = 1.3296e-01, time/batch = 16.5618s	
8813/33650 (epoch 13.095), train_loss = 1.18503667, grad/param norm = 1.6102e-01, time/batch = 16.9805s	
8814/33650 (epoch 13.097), train_loss = 1.10301057, grad/param norm = 1.5156e-01, time/batch = 16.1999s	
8815/33650 (epoch 13.098), train_loss = 0.91748653, grad/param norm = 1.2927e-01, time/batch = 15.0852s	
8816/33650 (epoch 13.100), train_loss = 1.03303159, grad/param norm = 1.2779e-01, time/batch = 14.8205s	
8817/33650 (epoch 13.101), train_loss = 1.11115713, grad/param norm = 1.6917e-01, time/batch = 14.9526s	
8818/33650 (epoch 13.103), train_loss = 1.04981668, grad/param norm = 1.3284e-01, time/batch = 14.1663s	
8819/33650 (epoch 13.104), train_loss = 1.19204898, grad/param norm = 1.4046e-01, time/batch = 14.8760s	
8820/33650 (epoch 13.105), train_loss = 1.12118569, grad/param norm = 1.4936e-01, time/batch = 14.0835s	
8821/33650 (epoch 13.107), train_loss = 1.01597411, grad/param norm = 1.2716e-01, time/batch = 13.9346s	
8822/33650 (epoch 13.108), train_loss = 1.20184099, grad/param norm = 1.5999e-01, time/batch = 14.1082s	
8823/33650 (epoch 13.110), train_loss = 1.31372275, grad/param norm = 1.5836e-01, time/batch = 14.3305s	
8824/33650 (epoch 13.111), train_loss = 1.08032238, grad/param norm = 1.4874e-01, time/batch = 13.9349s	
8825/33650 (epoch 13.113), train_loss = 1.08360288, grad/param norm = 1.3638e-01, time/batch = 14.1006s	
8826/33650 (epoch 13.114), train_loss = 1.19570896, grad/param norm = 1.5307e-01, time/batch = 14.0917s	
8827/33650 (epoch 13.116), train_loss = 1.01283894, grad/param norm = 1.2961e-01, time/batch = 14.3302s	
8828/33650 (epoch 13.117), train_loss = 1.14964592, grad/param norm = 1.3030e-01, time/batch = 14.3497s	
8829/33650 (epoch 13.119), train_loss = 0.98541673, grad/param norm = 1.3201e-01, time/batch = 14.1816s	
8830/33650 (epoch 13.120), train_loss = 1.05305909, grad/param norm = 1.5225e-01, time/batch = 13.9322s	
8831/33650 (epoch 13.122), train_loss = 0.92535151, grad/param norm = 1.3731e-01, time/batch = 14.3970s	
8832/33650 (epoch 13.123), train_loss = 1.06574120, grad/param norm = 1.3896e-01, time/batch = 14.4709s	
8833/33650 (epoch 13.125), train_loss = 1.23811809, grad/param norm = 1.5868e-01, time/batch = 14.1629s	
8834/33650 (epoch 13.126), train_loss = 1.29599430, grad/param norm = 1.6662e-01, time/batch = 14.0994s	
8835/33650 (epoch 13.128), train_loss = 1.24487738, grad/param norm = 1.5734e-01, time/batch = 13.8638s	
8836/33650 (epoch 13.129), train_loss = 1.24645488, grad/param norm = 1.5137e-01, time/batch = 14.4071s	
8837/33650 (epoch 13.131), train_loss = 1.15002608, grad/param norm = 1.3861e-01, time/batch = 14.0076s	
8838/33650 (epoch 13.132), train_loss = 1.14360348, grad/param norm = 1.3713e-01, time/batch = 14.0243s	
8839/33650 (epoch 13.134), train_loss = 1.26845989, grad/param norm = 1.4945e-01, time/batch = 14.5108s	
8840/33650 (epoch 13.135), train_loss = 0.98509361, grad/param norm = 1.4143e-01, time/batch = 14.8722s	
8841/33650 (epoch 13.137), train_loss = 1.12814676, grad/param norm = 1.4591e-01, time/batch = 14.1049s	
8842/33650 (epoch 13.138), train_loss = 1.20900763, grad/param norm = 1.3538e-01, time/batch = 14.2499s	
8843/33650 (epoch 13.140), train_loss = 1.14806145, grad/param norm = 1.6137e-01, time/batch = 14.0170s	
8844/33650 (epoch 13.141), train_loss = 1.27369010, grad/param norm = 1.5175e-01, time/batch = 14.3176s	
8845/33650 (epoch 13.143), train_loss = 1.38145936, grad/param norm = 1.8460e-01, time/batch = 14.1009s	
8846/33650 (epoch 13.144), train_loss = 1.20856595, grad/param norm = 1.5606e-01, time/batch = 13.9960s	
8847/33650 (epoch 13.146), train_loss = 1.09808016, grad/param norm = 1.4382e-01, time/batch = 13.8567s	
8848/33650 (epoch 13.147), train_loss = 1.07234339, grad/param norm = 1.4515e-01, time/batch = 14.4151s	
8849/33650 (epoch 13.149), train_loss = 1.03756916, grad/param norm = 1.5347e-01, time/batch = 14.0920s	
8850/33650 (epoch 13.150), train_loss = 0.98689869, grad/param norm = 1.2233e-01, time/batch = 14.1764s	
8851/33650 (epoch 13.152), train_loss = 1.07465502, grad/param norm = 1.3584e-01, time/batch = 14.1074s	
8852/33650 (epoch 13.153), train_loss = 1.08571262, grad/param norm = 1.4292e-01, time/batch = 14.0889s	
8853/33650 (epoch 13.155), train_loss = 1.05463838, grad/param norm = 1.3070e-01, time/batch = 14.2410s	
8854/33650 (epoch 13.156), train_loss = 1.02759692, grad/param norm = 1.2244e-01, time/batch = 14.3315s	
8855/33650 (epoch 13.158), train_loss = 1.13259190, grad/param norm = 1.4552e-01, time/batch = 14.4750s	
8856/33650 (epoch 13.159), train_loss = 1.00250676, grad/param norm = 1.1669e-01, time/batch = 13.6117s	
8857/33650 (epoch 13.160), train_loss = 1.03939341, grad/param norm = 1.2464e-01, time/batch = 14.8777s	
8858/33650 (epoch 13.162), train_loss = 1.12808289, grad/param norm = 1.6262e-01, time/batch = 14.0825s	
8859/33650 (epoch 13.163), train_loss = 1.18476570, grad/param norm = 1.3876e-01, time/batch = 14.0071s	
8860/33650 (epoch 13.165), train_loss = 1.02157193, grad/param norm = 1.3883e-01, time/batch = 13.8640s	
8861/33650 (epoch 13.166), train_loss = 1.00442169, grad/param norm = 1.3774e-01, time/batch = 14.6470s	
8862/33650 (epoch 13.168), train_loss = 1.19432816, grad/param norm = 1.4461e-01, time/batch = 14.3330s	
8863/33650 (epoch 13.169), train_loss = 1.11482009, grad/param norm = 1.4205e-01, time/batch = 13.9403s	
8864/33650 (epoch 13.171), train_loss = 1.11522452, grad/param norm = 1.4327e-01, time/batch = 14.0993s	
8865/33650 (epoch 13.172), train_loss = 1.09588799, grad/param norm = 1.5088e-01, time/batch = 14.1726s	
8866/33650 (epoch 13.174), train_loss = 1.01245493, grad/param norm = 1.4334e-01, time/batch = 14.0975s	
8867/33650 (epoch 13.175), train_loss = 1.05453096, grad/param norm = 1.5309e-01, time/batch = 13.9346s	
8868/33650 (epoch 13.177), train_loss = 1.14388816, grad/param norm = 1.3986e-01, time/batch = 14.0187s	
8869/33650 (epoch 13.178), train_loss = 1.02191501, grad/param norm = 1.5034e-01, time/batch = 14.4897s	
8870/33650 (epoch 13.180), train_loss = 0.98547533, grad/param norm = 1.2813e-01, time/batch = 4.5418s	
8871/33650 (epoch 13.181), train_loss = 0.89434024, grad/param norm = 1.3819e-01, time/batch = 0.6667s	
8872/33650 (epoch 13.183), train_loss = 1.06608996, grad/param norm = 1.4762e-01, time/batch = 0.6748s	
8873/33650 (epoch 13.184), train_loss = 1.06725937, grad/param norm = 1.4891e-01, time/batch = 0.6817s	
8874/33650 (epoch 13.186), train_loss = 1.06957953, grad/param norm = 1.5745e-01, time/batch = 0.6551s	
8875/33650 (epoch 13.187), train_loss = 1.29174582, grad/param norm = 1.4236e-01, time/batch = 0.6424s	
8876/33650 (epoch 13.189), train_loss = 1.30000843, grad/param norm = 1.7127e-01, time/batch = 0.6601s	
8877/33650 (epoch 13.190), train_loss = 1.14236510, grad/param norm = 1.5676e-01, time/batch = 0.7722s	
8878/33650 (epoch 13.192), train_loss = 1.30336473, grad/param norm = 1.6304e-01, time/batch = 0.9446s	
8879/33650 (epoch 13.193), train_loss = 1.24313126, grad/param norm = 1.5064e-01, time/batch = 0.9582s	
8880/33650 (epoch 13.195), train_loss = 0.99468053, grad/param norm = 1.3404e-01, time/batch = 0.9473s	
8881/33650 (epoch 13.196), train_loss = 0.94796972, grad/param norm = 1.4912e-01, time/batch = 0.9480s	
8882/33650 (epoch 13.198), train_loss = 1.08253370, grad/param norm = 1.5136e-01, time/batch = 1.0627s	
8883/33650 (epoch 13.199), train_loss = 1.22494816, grad/param norm = 1.5458e-01, time/batch = 1.7966s	
8884/33650 (epoch 13.201), train_loss = 1.08134386, grad/param norm = 1.4944e-01, time/batch = 1.7731s	
8885/33650 (epoch 13.202), train_loss = 1.07440654, grad/param norm = 1.3234e-01, time/batch = 6.0288s	
8886/33650 (epoch 13.204), train_loss = 1.17004129, grad/param norm = 1.4211e-01, time/batch = 14.4947s	
8887/33650 (epoch 13.205), train_loss = 1.09875542, grad/param norm = 1.5573e-01, time/batch = 14.5516s	
8888/33650 (epoch 13.207), train_loss = 1.06471770, grad/param norm = 1.4977e-01, time/batch = 15.0266s	
8889/33650 (epoch 13.208), train_loss = 1.09781145, grad/param norm = 1.4280e-01, time/batch = 14.1437s	
8890/33650 (epoch 13.210), train_loss = 0.87199473, grad/param norm = 1.2128e-01, time/batch = 13.7547s	
8891/33650 (epoch 13.211), train_loss = 1.02355202, grad/param norm = 1.3921e-01, time/batch = 13.8416s	
8892/33650 (epoch 13.212), train_loss = 1.22132708, grad/param norm = 1.6415e-01, time/batch = 14.6242s	
8893/33650 (epoch 13.214), train_loss = 1.27393443, grad/param norm = 1.4689e-01, time/batch = 13.8970s	
8894/33650 (epoch 13.215), train_loss = 0.88570543, grad/param norm = 1.2901e-01, time/batch = 13.7482s	
8895/33650 (epoch 13.217), train_loss = 1.12192959, grad/param norm = 1.6036e-01, time/batch = 13.5845s	
8896/33650 (epoch 13.218), train_loss = 1.16168090, grad/param norm = 1.4157e-01, time/batch = 14.0726s	
8897/33650 (epoch 13.220), train_loss = 0.99356606, grad/param norm = 1.3324e-01, time/batch = 13.9133s	
8898/33650 (epoch 13.221), train_loss = 1.24503905, grad/param norm = 1.6613e-01, time/batch = 13.7419s	
8899/33650 (epoch 13.223), train_loss = 0.85541976, grad/param norm = 1.2960e-01, time/batch = 13.5858s	
8900/33650 (epoch 13.224), train_loss = 1.08343936, grad/param norm = 1.6106e-01, time/batch = 13.7445s	
8901/33650 (epoch 13.226), train_loss = 1.42486867, grad/param norm = 1.7886e-01, time/batch = 14.6258s	
8902/33650 (epoch 13.227), train_loss = 1.25955456, grad/param norm = 1.6294e-01, time/batch = 13.6590s	
8903/33650 (epoch 13.229), train_loss = 1.26734988, grad/param norm = 1.6133e-01, time/batch = 14.4018s	
8904/33650 (epoch 13.230), train_loss = 1.37377946, grad/param norm = 1.6019e-01, time/batch = 14.0771s	
8905/33650 (epoch 13.232), train_loss = 1.15373420, grad/param norm = 1.4320e-01, time/batch = 14.3927s	
8906/33650 (epoch 13.233), train_loss = 1.17921513, grad/param norm = 1.7068e-01, time/batch = 14.3903s	
8907/33650 (epoch 13.235), train_loss = 1.08587088, grad/param norm = 1.3984e-01, time/batch = 13.7493s	
8908/33650 (epoch 13.236), train_loss = 0.97321759, grad/param norm = 1.3782e-01, time/batch = 13.8271s	
8909/33650 (epoch 13.238), train_loss = 1.06790912, grad/param norm = 1.3545e-01, time/batch = 14.2333s	
8910/33650 (epoch 13.239), train_loss = 1.01103626, grad/param norm = 1.3434e-01, time/batch = 14.0741s	
8911/33650 (epoch 13.241), train_loss = 1.04508280, grad/param norm = 1.2645e-01, time/batch = 13.9798s	
8912/33650 (epoch 13.242), train_loss = 0.92049571, grad/param norm = 1.2528e-01, time/batch = 13.7471s	
8913/33650 (epoch 13.244), train_loss = 1.09753001, grad/param norm = 1.4404e-01, time/batch = 14.2291s	
8914/33650 (epoch 13.245), train_loss = 0.96188004, grad/param norm = 1.3934e-01, time/batch = 13.8284s	
8915/33650 (epoch 13.247), train_loss = 1.09514472, grad/param norm = 1.3626e-01, time/batch = 14.0770s	
8916/33650 (epoch 13.248), train_loss = 0.98281340, grad/param norm = 1.3341e-01, time/batch = 13.9683s	
8917/33650 (epoch 13.250), train_loss = 1.07988447, grad/param norm = 1.3148e-01, time/batch = 13.9158s	
8918/33650 (epoch 13.251), train_loss = 1.25549563, grad/param norm = 1.5752e-01, time/batch = 14.3994s	
8919/33650 (epoch 13.253), train_loss = 1.00173448, grad/param norm = 1.3292e-01, time/batch = 13.9954s	
8920/33650 (epoch 13.254), train_loss = 1.01743355, grad/param norm = 1.4429e-01, time/batch = 14.0631s	
8921/33650 (epoch 13.256), train_loss = 1.23795477, grad/param norm = 1.3989e-01, time/batch = 13.8921s	
8922/33650 (epoch 13.257), train_loss = 1.25914285, grad/param norm = 1.4958e-01, time/batch = 14.3163s	
8923/33650 (epoch 13.259), train_loss = 0.96740190, grad/param norm = 1.4108e-01, time/batch = 13.9107s	
8924/33650 (epoch 13.260), train_loss = 1.23690330, grad/param norm = 1.5651e-01, time/batch = 13.9901s	
8925/33650 (epoch 13.262), train_loss = 1.16417175, grad/param norm = 1.4901e-01, time/batch = 13.7407s	
8926/33650 (epoch 13.263), train_loss = 1.09617744, grad/param norm = 1.7555e-01, time/batch = 14.4706s	
8927/33650 (epoch 13.264), train_loss = 1.14340006, grad/param norm = 1.4898e-01, time/batch = 14.5488s	
8928/33650 (epoch 13.266), train_loss = 1.11439981, grad/param norm = 1.3904e-01, time/batch = 14.1503s	
8929/33650 (epoch 13.267), train_loss = 1.02380775, grad/param norm = 1.5123e-01, time/batch = 13.6574s	
8930/33650 (epoch 13.269), train_loss = 1.15072261, grad/param norm = 1.4617e-01, time/batch = 14.1517s	
8931/33650 (epoch 13.270), train_loss = 1.04741876, grad/param norm = 1.3263e-01, time/batch = 14.4832s	
8932/33650 (epoch 13.272), train_loss = 1.07761501, grad/param norm = 1.3609e-01, time/batch = 14.7047s	
8933/33650 (epoch 13.273), train_loss = 1.24515399, grad/param norm = 1.6534e-01, time/batch = 14.5551s	
8934/33650 (epoch 13.275), train_loss = 1.21710228, grad/param norm = 1.6257e-01, time/batch = 14.4640s	
8935/33650 (epoch 13.276), train_loss = 1.27936379, grad/param norm = 1.6981e-01, time/batch = 15.0476s	
8936/33650 (epoch 13.278), train_loss = 1.34956288, grad/param norm = 1.6662e-01, time/batch = 14.4727s	
8937/33650 (epoch 13.279), train_loss = 1.05871519, grad/param norm = 1.4107e-01, time/batch = 14.0609s	
8938/33650 (epoch 13.281), train_loss = 1.15242954, grad/param norm = 1.5275e-01, time/batch = 13.7456s	
8939/33650 (epoch 13.282), train_loss = 1.23427593, grad/param norm = 1.3913e-01, time/batch = 13.9855s	
8940/33650 (epoch 13.284), train_loss = 1.21768374, grad/param norm = 1.4861e-01, time/batch = 13.7472s	
8941/33650 (epoch 13.285), train_loss = 1.22760401, grad/param norm = 1.5293e-01, time/batch = 14.5359s	
8942/33650 (epoch 13.287), train_loss = 1.10274080, grad/param norm = 1.3701e-01, time/batch = 13.8198s	
8943/33650 (epoch 13.288), train_loss = 1.16257327, grad/param norm = 1.6303e-01, time/batch = 14.0642s	
8944/33650 (epoch 13.290), train_loss = 1.13839250, grad/param norm = 1.3447e-01, time/batch = 13.9981s	
8945/33650 (epoch 13.291), train_loss = 1.01892673, grad/param norm = 1.2370e-01, time/batch = 13.9037s	
8946/33650 (epoch 13.293), train_loss = 1.12830831, grad/param norm = 1.6611e-01, time/batch = 13.9083s	
8947/33650 (epoch 13.294), train_loss = 1.00728135, grad/param norm = 1.3840e-01, time/batch = 14.3075s	
8948/33650 (epoch 13.296), train_loss = 1.00842193, grad/param norm = 1.3925e-01, time/batch = 13.8344s	
8949/33650 (epoch 13.297), train_loss = 1.09500518, grad/param norm = 1.4196e-01, time/batch = 13.9873s	
8950/33650 (epoch 13.299), train_loss = 0.99472357, grad/param norm = 1.1958e-01, time/batch = 13.7555s	
8951/33650 (epoch 13.300), train_loss = 1.01945535, grad/param norm = 1.4575e-01, time/batch = 14.1494s	
8952/33650 (epoch 13.302), train_loss = 1.14325476, grad/param norm = 1.3309e-01, time/batch = 14.0639s	
8953/33650 (epoch 13.303), train_loss = 1.13451206, grad/param norm = 1.3834e-01, time/batch = 14.0610s	
8954/33650 (epoch 13.305), train_loss = 1.17010885, grad/param norm = 1.4843e-01, time/batch = 13.8237s	
8955/33650 (epoch 13.306), train_loss = 1.05538722, grad/param norm = 1.2763e-01, time/batch = 13.7431s	
8956/33650 (epoch 13.308), train_loss = 1.02479836, grad/param norm = 1.6380e-01, time/batch = 13.9823s	
8957/33650 (epoch 13.309), train_loss = 1.32551057, grad/param norm = 1.8609e-01, time/batch = 14.1395s	
8958/33650 (epoch 13.311), train_loss = 1.17529476, grad/param norm = 1.5115e-01, time/batch = 14.2935s	
8959/33650 (epoch 13.312), train_loss = 1.12622794, grad/param norm = 1.4327e-01, time/batch = 13.9028s	
8960/33650 (epoch 13.314), train_loss = 0.94147801, grad/param norm = 1.1776e-01, time/batch = 14.2267s	
8961/33650 (epoch 13.315), train_loss = 1.12103524, grad/param norm = 1.6199e-01, time/batch = 13.8976s	
8962/33650 (epoch 13.316), train_loss = 1.05367197, grad/param norm = 1.4918e-01, time/batch = 13.9137s	
8963/33650 (epoch 13.318), train_loss = 0.99179298, grad/param norm = 1.2044e-01, time/batch = 13.9046s	
8964/33650 (epoch 13.319), train_loss = 1.00761310, grad/param norm = 1.2401e-01, time/batch = 14.3093s	
8965/33650 (epoch 13.321), train_loss = 1.05270487, grad/param norm = 1.3545e-01, time/batch = 14.0762s	
8966/33650 (epoch 13.322), train_loss = 1.18553390, grad/param norm = 1.6005e-01, time/batch = 13.8230s	
8967/33650 (epoch 13.324), train_loss = 1.18396327, grad/param norm = 1.6603e-01, time/batch = 13.7483s	
8968/33650 (epoch 13.325), train_loss = 1.18727166, grad/param norm = 1.5235e-01, time/batch = 16.7102s	
8969/33650 (epoch 13.327), train_loss = 0.99362029, grad/param norm = 1.3008e-01, time/batch = 14.0726s	
8970/33650 (epoch 13.328), train_loss = 1.17695934, grad/param norm = 1.5633e-01, time/batch = 18.6410s	
8971/33650 (epoch 13.330), train_loss = 1.01556748, grad/param norm = 1.1992e-01, time/batch = 17.8216s	
8972/33650 (epoch 13.331), train_loss = 0.92015870, grad/param norm = 1.1435e-01, time/batch = 17.1357s	
8973/33650 (epoch 13.333), train_loss = 1.07232631, grad/param norm = 1.4208e-01, time/batch = 16.9922s	
8974/33650 (epoch 13.334), train_loss = 1.08037831, grad/param norm = 1.2937e-01, time/batch = 17.8181s	
8975/33650 (epoch 13.336), train_loss = 1.23359293, grad/param norm = 1.4887e-01, time/batch = 17.2987s	
8976/33650 (epoch 13.337), train_loss = 0.89792835, grad/param norm = 1.2200e-01, time/batch = 18.4766s	
8977/33650 (epoch 13.339), train_loss = 1.07872564, grad/param norm = 1.3278e-01, time/batch = 18.8908s	
8978/33650 (epoch 13.340), train_loss = 1.31100376, grad/param norm = 1.7029e-01, time/batch = 18.0621s	
8979/33650 (epoch 13.342), train_loss = 0.92132786, grad/param norm = 1.2915e-01, time/batch = 17.2290s	
8980/33650 (epoch 13.343), train_loss = 1.17718052, grad/param norm = 1.4780e-01, time/batch = 16.6251s	
8981/33650 (epoch 13.345), train_loss = 1.08912680, grad/param norm = 1.4960e-01, time/batch = 16.7764s	
8982/33650 (epoch 13.346), train_loss = 0.78550060, grad/param norm = 1.2232e-01, time/batch = 16.7248s	
8983/33650 (epoch 13.348), train_loss = 0.98272310, grad/param norm = 1.3096e-01, time/batch = 17.9821s	
8984/33650 (epoch 13.349), train_loss = 0.91924945, grad/param norm = 1.3093e-01, time/batch = 17.6434s	
8985/33650 (epoch 13.351), train_loss = 1.18652093, grad/param norm = 1.4045e-01, time/batch = 17.9665s	
8986/33650 (epoch 13.352), train_loss = 1.08215926, grad/param norm = 1.4099e-01, time/batch = 17.6323s	
8987/33650 (epoch 13.354), train_loss = 1.32248095, grad/param norm = 1.6305e-01, time/batch = 15.8574s	
8988/33650 (epoch 13.355), train_loss = 1.20170001, grad/param norm = 1.3546e-01, time/batch = 14.0503s	
8989/33650 (epoch 13.357), train_loss = 0.90893565, grad/param norm = 1.3605e-01, time/batch = 16.4673s	
8990/33650 (epoch 13.358), train_loss = 1.19236617, grad/param norm = 1.5243e-01, time/batch = 16.1377s	
8991/33650 (epoch 13.360), train_loss = 1.18937113, grad/param norm = 1.5459e-01, time/batch = 18.4576s	
8992/33650 (epoch 13.361), train_loss = 1.14992847, grad/param norm = 1.3987e-01, time/batch = 17.8058s	
8993/33650 (epoch 13.363), train_loss = 1.04022986, grad/param norm = 1.3484e-01, time/batch = 17.1399s	
8994/33650 (epoch 13.364), train_loss = 1.05129354, grad/param norm = 1.2869e-01, time/batch = 17.0363s	
8995/33650 (epoch 13.366), train_loss = 1.14006218, grad/param norm = 1.5001e-01, time/batch = 17.6424s	
8996/33650 (epoch 13.367), train_loss = 1.18257347, grad/param norm = 1.3033e-01, time/batch = 17.5435s	
8997/33650 (epoch 13.368), train_loss = 1.00880577, grad/param norm = 1.3134e-01, time/batch = 18.8875s	
8998/33650 (epoch 13.370), train_loss = 1.11114574, grad/param norm = 1.4064e-01, time/batch = 17.4512s	
8999/33650 (epoch 13.371), train_loss = 0.89410151, grad/param norm = 1.3218e-01, time/batch = 17.6126s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch13.37_1.5209.t7	
9000/33650 (epoch 13.373), train_loss = 1.01734006, grad/param norm = 1.2966e-01, time/batch = 17.8035s	
9001/33650 (epoch 13.374), train_loss = 1.20553837, grad/param norm = 1.4288e-01, time/batch = 17.6362s	
9002/33650 (epoch 13.376), train_loss = 1.11219462, grad/param norm = 1.6353e-01, time/batch = 18.6297s	
9003/33650 (epoch 13.377), train_loss = 1.13998850, grad/param norm = 1.5427e-01, time/batch = 17.6343s	
9004/33650 (epoch 13.379), train_loss = 1.16937251, grad/param norm = 1.3907e-01, time/batch = 16.4795s	
9005/33650 (epoch 13.380), train_loss = 0.87981927, grad/param norm = 1.3284e-01, time/batch = 18.8821s	
9006/33650 (epoch 13.382), train_loss = 0.96308817, grad/param norm = 1.1493e-01, time/batch = 19.7933s	
9007/33650 (epoch 13.383), train_loss = 1.07200865, grad/param norm = 1.4116e-01, time/batch = 18.6325s	
9008/33650 (epoch 13.385), train_loss = 1.24419687, grad/param norm = 1.4706e-01, time/batch = 18.6345s	
9009/33650 (epoch 13.386), train_loss = 1.00071739, grad/param norm = 1.2921e-01, time/batch = 16.5446s	
9010/33650 (epoch 13.388), train_loss = 1.13845710, grad/param norm = 1.3765e-01, time/batch = 15.6997s	
9011/33650 (epoch 13.389), train_loss = 1.09976582, grad/param norm = 1.5333e-01, time/batch = 16.1271s	
9012/33650 (epoch 13.391), train_loss = 0.90849168, grad/param norm = 1.2942e-01, time/batch = 17.8768s	
9013/33650 (epoch 13.392), train_loss = 1.17114243, grad/param norm = 1.4514e-01, time/batch = 17.6589s	
9014/33650 (epoch 13.394), train_loss = 1.18953379, grad/param norm = 1.6201e-01, time/batch = 18.0647s	
9015/33650 (epoch 13.395), train_loss = 1.12771489, grad/param norm = 1.3975e-01, time/batch = 17.4095s	
9016/33650 (epoch 13.397), train_loss = 1.27181895, grad/param norm = 1.4822e-01, time/batch = 18.1318s	
9017/33650 (epoch 13.398), train_loss = 1.13346614, grad/param norm = 1.3440e-01, time/batch = 18.4894s	
9018/33650 (epoch 13.400), train_loss = 1.11136832, grad/param norm = 1.6235e-01, time/batch = 17.8832s	
9019/33650 (epoch 13.401), train_loss = 1.11603955, grad/param norm = 1.6038e-01, time/batch = 16.1444s	
9020/33650 (epoch 13.403), train_loss = 1.16408773, grad/param norm = 1.5249e-01, time/batch = 18.1425s	
9021/33650 (epoch 13.404), train_loss = 1.08383035, grad/param norm = 1.2681e-01, time/batch = 17.2222s	
9022/33650 (epoch 13.406), train_loss = 1.14264354, grad/param norm = 1.4144e-01, time/batch = 17.3678s	
9023/33650 (epoch 13.407), train_loss = 1.13662034, grad/param norm = 1.6241e-01, time/batch = 16.4544s	
9024/33650 (epoch 13.409), train_loss = 1.10726423, grad/param norm = 1.3528e-01, time/batch = 17.4771s	
9025/33650 (epoch 13.410), train_loss = 1.10461452, grad/param norm = 1.4821e-01, time/batch = 17.7953s	
9026/33650 (epoch 13.412), train_loss = 1.10505403, grad/param norm = 1.3233e-01, time/batch = 17.4797s	
9027/33650 (epoch 13.413), train_loss = 1.02156039, grad/param norm = 1.3787e-01, time/batch = 18.1620s	
9028/33650 (epoch 13.415), train_loss = 1.17463803, grad/param norm = 1.3741e-01, time/batch = 16.7298s	
9029/33650 (epoch 13.416), train_loss = 1.27951105, grad/param norm = 1.5297e-01, time/batch = 18.0327s	
9030/33650 (epoch 13.418), train_loss = 1.10406646, grad/param norm = 1.4146e-01, time/batch = 18.4029s	
9031/33650 (epoch 13.419), train_loss = 1.06327964, grad/param norm = 1.4933e-01, time/batch = 16.6221s	
9032/33650 (epoch 13.421), train_loss = 1.05803685, grad/param norm = 1.2975e-01, time/batch = 18.4763s	
9033/33650 (epoch 13.422), train_loss = 1.19748806, grad/param norm = 1.3976e-01, time/batch = 17.5538s	
9034/33650 (epoch 13.423), train_loss = 0.97215815, grad/param norm = 1.1830e-01, time/batch = 17.8018s	
9035/33650 (epoch 13.425), train_loss = 1.12695671, grad/param norm = 1.5517e-01, time/batch = 17.7304s	
9036/33650 (epoch 13.426), train_loss = 1.25765075, grad/param norm = 1.6472e-01, time/batch = 16.9645s	
9037/33650 (epoch 13.428), train_loss = 1.04297218, grad/param norm = 1.3527e-01, time/batch = 17.8108s	
9038/33650 (epoch 13.429), train_loss = 1.20952235, grad/param norm = 1.4970e-01, time/batch = 17.7202s	
9039/33650 (epoch 13.431), train_loss = 1.31787870, grad/param norm = 1.6945e-01, time/batch = 17.1357s	
9040/33650 (epoch 13.432), train_loss = 1.37818552, grad/param norm = 1.6633e-01, time/batch = 18.4798s	
9041/33650 (epoch 13.434), train_loss = 1.17161755, grad/param norm = 1.4454e-01, time/batch = 17.3944s	
9042/33650 (epoch 13.435), train_loss = 1.14741225, grad/param norm = 1.6069e-01, time/batch = 17.7301s	
9043/33650 (epoch 13.437), train_loss = 1.15005617, grad/param norm = 1.5446e-01, time/batch = 18.2364s	
9044/33650 (epoch 13.438), train_loss = 1.03655340, grad/param norm = 1.5175e-01, time/batch = 18.7256s	
9045/33650 (epoch 13.440), train_loss = 1.13125896, grad/param norm = 1.5181e-01, time/batch = 17.8029s	
9046/33650 (epoch 13.441), train_loss = 1.16281028, grad/param norm = 1.6255e-01, time/batch = 18.3922s	
9047/33650 (epoch 13.443), train_loss = 1.16038630, grad/param norm = 1.3748e-01, time/batch = 17.2141s	
9048/33650 (epoch 13.444), train_loss = 1.05724296, grad/param norm = 1.2520e-01, time/batch = 17.1375s	
9049/33650 (epoch 13.446), train_loss = 1.17224069, grad/param norm = 1.6766e-01, time/batch = 17.3927s	
9050/33650 (epoch 13.447), train_loss = 1.22766013, grad/param norm = 1.6060e-01, time/batch = 16.7057s	
9051/33650 (epoch 13.449), train_loss = 1.30572267, grad/param norm = 1.9440e-01, time/batch = 18.2297s	
9052/33650 (epoch 13.450), train_loss = 1.33139184, grad/param norm = 1.5768e-01, time/batch = 18.5543s	
9053/33650 (epoch 13.452), train_loss = 1.37133946, grad/param norm = 1.6635e-01, time/batch = 18.2190s	
9054/33650 (epoch 13.453), train_loss = 1.30104072, grad/param norm = 1.6425e-01, time/batch = 18.3913s	
9055/33650 (epoch 13.455), train_loss = 1.10483852, grad/param norm = 1.4648e-01, time/batch = 17.1453s	
9056/33650 (epoch 13.456), train_loss = 1.11377996, grad/param norm = 1.3106e-01, time/batch = 18.0637s	
9057/33650 (epoch 13.458), train_loss = 1.10092399, grad/param norm = 1.5941e-01, time/batch = 18.1548s	
9058/33650 (epoch 13.459), train_loss = 1.14203312, grad/param norm = 1.5483e-01, time/batch = 15.1997s	
9059/33650 (epoch 13.461), train_loss = 1.31524211, grad/param norm = 1.6639e-01, time/batch = 18.6489s	
9060/33650 (epoch 13.462), train_loss = 1.27552329, grad/param norm = 1.5977e-01, time/batch = 18.7374s	
9061/33650 (epoch 13.464), train_loss = 1.06583780, grad/param norm = 1.4443e-01, time/batch = 17.7251s	
9062/33650 (epoch 13.465), train_loss = 1.17039830, grad/param norm = 1.5719e-01, time/batch = 17.0592s	
9063/33650 (epoch 13.467), train_loss = 1.18122552, grad/param norm = 1.4957e-01, time/batch = 18.6402s	
9064/33650 (epoch 13.468), train_loss = 1.24655818, grad/param norm = 1.5275e-01, time/batch = 18.6576s	
9065/33650 (epoch 13.470), train_loss = 1.38420922, grad/param norm = 1.7365e-01, time/batch = 15.4025s	
9066/33650 (epoch 13.471), train_loss = 1.14111122, grad/param norm = 1.5595e-01, time/batch = 14.7376s	
9067/33650 (epoch 13.473), train_loss = 1.07893895, grad/param norm = 1.3626e-01, time/batch = 17.8522s	
9068/33650 (epoch 13.474), train_loss = 1.19543179, grad/param norm = 1.3951e-01, time/batch = 18.2328s	
9069/33650 (epoch 13.475), train_loss = 1.20488898, grad/param norm = 1.4950e-01, time/batch = 18.1423s	
9070/33650 (epoch 13.477), train_loss = 1.24773421, grad/param norm = 1.4680e-01, time/batch = 16.8943s	
9071/33650 (epoch 13.478), train_loss = 1.26912551, grad/param norm = 1.6647e-01, time/batch = 17.2408s	
9072/33650 (epoch 13.480), train_loss = 1.24186215, grad/param norm = 1.5433e-01, time/batch = 16.3860s	
9073/33650 (epoch 13.481), train_loss = 1.29975121, grad/param norm = 1.5479e-01, time/batch = 18.1492s	
9074/33650 (epoch 13.483), train_loss = 0.93431081, grad/param norm = 1.3892e-01, time/batch = 18.3092s	
9075/33650 (epoch 13.484), train_loss = 1.13505725, grad/param norm = 1.4151e-01, time/batch = 17.1503s	
9076/33650 (epoch 13.486), train_loss = 1.27295099, grad/param norm = 1.6735e-01, time/batch = 18.3100s	
9077/33650 (epoch 13.487), train_loss = 1.29788468, grad/param norm = 1.7620e-01, time/batch = 18.4773s	
9078/33650 (epoch 13.489), train_loss = 1.32929316, grad/param norm = 1.5187e-01, time/batch = 17.8116s	
9079/33650 (epoch 13.490), train_loss = 1.05121393, grad/param norm = 1.4446e-01, time/batch = 16.1991s	
9080/33650 (epoch 13.492), train_loss = 1.17064234, grad/param norm = 1.5936e-01, time/batch = 17.8894s	
9081/33650 (epoch 13.493), train_loss = 0.94411761, grad/param norm = 1.2362e-01, time/batch = 18.6520s	
9082/33650 (epoch 13.495), train_loss = 1.15171507, grad/param norm = 1.4529e-01, time/batch = 16.8985s	
9083/33650 (epoch 13.496), train_loss = 1.20092413, grad/param norm = 1.4579e-01, time/batch = 16.2027s	
9084/33650 (epoch 13.498), train_loss = 1.00735625, grad/param norm = 1.3505e-01, time/batch = 17.8950s	
9085/33650 (epoch 13.499), train_loss = 1.11036462, grad/param norm = 1.2701e-01, time/batch = 18.0642s	
9086/33650 (epoch 13.501), train_loss = 1.09121197, grad/param norm = 1.3372e-01, time/batch = 17.8929s	
9087/33650 (epoch 13.502), train_loss = 1.14831911, grad/param norm = 1.5185e-01, time/batch = 17.7261s	
9088/33650 (epoch 13.504), train_loss = 1.25366315, grad/param norm = 1.6055e-01, time/batch = 18.4780s	
9089/33650 (epoch 13.505), train_loss = 1.11585766, grad/param norm = 1.5922e-01, time/batch = 16.8137s	
9090/33650 (epoch 13.507), train_loss = 1.28224941, grad/param norm = 1.5321e-01, time/batch = 18.0689s	
9091/33650 (epoch 13.508), train_loss = 1.07996113, grad/param norm = 1.3966e-01, time/batch = 17.6400s	
9092/33650 (epoch 13.510), train_loss = 1.13219136, grad/param norm = 1.4507e-01, time/batch = 17.7179s	
9093/33650 (epoch 13.511), train_loss = 1.37435955, grad/param norm = 1.7179e-01, time/batch = 17.8031s	
9094/33650 (epoch 13.513), train_loss = 1.20855104, grad/param norm = 1.5179e-01, time/batch = 18.4729s	
9095/33650 (epoch 13.514), train_loss = 1.24903791, grad/param norm = 1.5935e-01, time/batch = 17.3262s	
9096/33650 (epoch 13.516), train_loss = 1.14397139, grad/param norm = 1.4332e-01, time/batch = 17.3777s	
9097/33650 (epoch 13.517), train_loss = 1.15710161, grad/param norm = 1.5278e-01, time/batch = 15.2674s	
9098/33650 (epoch 13.519), train_loss = 1.19006988, grad/param norm = 1.5286e-01, time/batch = 14.5492s	
9099/33650 (epoch 13.520), train_loss = 0.98299830, grad/param norm = 1.2983e-01, time/batch = 16.4724s	
9100/33650 (epoch 13.522), train_loss = 1.14486577, grad/param norm = 1.5593e-01, time/batch = 18.1388s	
9101/33650 (epoch 13.523), train_loss = 1.11667219, grad/param norm = 1.4133e-01, time/batch = 16.0304s	
9102/33650 (epoch 13.525), train_loss = 0.89619919, grad/param norm = 1.2479e-01, time/batch = 18.3984s	
9103/33650 (epoch 13.526), train_loss = 1.20961539, grad/param norm = 1.3757e-01, time/batch = 16.8905s	
9104/33650 (epoch 13.527), train_loss = 1.04801131, grad/param norm = 1.3894e-01, time/batch = 17.8875s	
9105/33650 (epoch 13.529), train_loss = 1.13404596, grad/param norm = 1.4777e-01, time/batch = 18.0611s	
9106/33650 (epoch 13.530), train_loss = 1.06917388, grad/param norm = 1.3724e-01, time/batch = 16.9767s	
9107/33650 (epoch 13.532), train_loss = 1.32180565, grad/param norm = 1.8386e-01, time/batch = 18.6366s	
9108/33650 (epoch 13.533), train_loss = 1.10119912, grad/param norm = 1.4938e-01, time/batch = 18.3106s	
9109/33650 (epoch 13.535), train_loss = 1.24463807, grad/param norm = 1.5910e-01, time/batch = 17.8052s	
9110/33650 (epoch 13.536), train_loss = 1.15709775, grad/param norm = 1.5256e-01, time/batch = 16.4780s	
9111/33650 (epoch 13.538), train_loss = 1.18938100, grad/param norm = 1.5058e-01, time/batch = 17.3940s	
9112/33650 (epoch 13.539), train_loss = 0.93022849, grad/param norm = 1.3016e-01, time/batch = 16.1220s	
9113/33650 (epoch 13.541), train_loss = 1.28438931, grad/param norm = 1.6561e-01, time/batch = 16.3869s	
9114/33650 (epoch 13.542), train_loss = 1.18662493, grad/param norm = 1.5600e-01, time/batch = 17.9812s	
9115/33650 (epoch 13.544), train_loss = 1.36521464, grad/param norm = 1.7611e-01, time/batch = 18.8121s	
9116/33650 (epoch 13.545), train_loss = 1.00922579, grad/param norm = 1.3495e-01, time/batch = 17.6352s	
9117/33650 (epoch 13.547), train_loss = 1.15157240, grad/param norm = 1.4611e-01, time/batch = 18.0737s	
9118/33650 (epoch 13.548), train_loss = 1.31623521, grad/param norm = 1.5130e-01, time/batch = 18.4642s	
9119/33650 (epoch 13.550), train_loss = 1.10642115, grad/param norm = 1.3944e-01, time/batch = 17.7098s	
9120/33650 (epoch 13.551), train_loss = 1.15955489, grad/param norm = 1.5094e-01, time/batch = 17.1224s	
9121/33650 (epoch 13.553), train_loss = 1.00113299, grad/param norm = 1.4928e-01, time/batch = 18.1500s	
9122/33650 (epoch 13.554), train_loss = 1.26881459, grad/param norm = 1.4821e-01, time/batch = 18.8963s	
9123/33650 (epoch 13.556), train_loss = 1.23511698, grad/param norm = 1.7365e-01, time/batch = 16.0488s	
9124/33650 (epoch 13.557), train_loss = 1.28109418, grad/param norm = 1.6756e-01, time/batch = 17.1304s	
9125/33650 (epoch 13.559), train_loss = 1.44539811, grad/param norm = 1.9941e-01, time/batch = 18.0499s	
9126/33650 (epoch 13.560), train_loss = 1.35165870, grad/param norm = 1.5569e-01, time/batch = 17.6364s	
9127/33650 (epoch 13.562), train_loss = 1.23581495, grad/param norm = 1.4070e-01, time/batch = 18.1389s	
9128/33650 (epoch 13.563), train_loss = 1.14543125, grad/param norm = 1.4906e-01, time/batch = 18.1469s	
9129/33650 (epoch 13.565), train_loss = 1.16163594, grad/param norm = 1.4514e-01, time/batch = 18.9835s	
9130/33650 (epoch 13.566), train_loss = 1.14007842, grad/param norm = 1.4965e-01, time/batch = 17.8756s	
9131/33650 (epoch 13.568), train_loss = 1.16627693, grad/param norm = 1.5765e-01, time/batch = 18.5609s	
9132/33650 (epoch 13.569), train_loss = 1.09784184, grad/param norm = 1.4829e-01, time/batch = 17.3865s	
9133/33650 (epoch 13.571), train_loss = 1.29186859, grad/param norm = 1.5834e-01, time/batch = 16.2882s	
9134/33650 (epoch 13.572), train_loss = 1.20805166, grad/param norm = 1.3503e-01, time/batch = 16.2240s	
9135/33650 (epoch 13.574), train_loss = 1.16188140, grad/param norm = 1.5781e-01, time/batch = 18.3138s	
9136/33650 (epoch 13.575), train_loss = 1.13664627, grad/param norm = 1.4962e-01, time/batch = 17.4652s	
9137/33650 (epoch 13.577), train_loss = 1.14678682, grad/param norm = 1.5657e-01, time/batch = 18.2221s	
9138/33650 (epoch 13.578), train_loss = 1.20168299, grad/param norm = 1.4885e-01, time/batch = 16.8999s	
9139/33650 (epoch 13.579), train_loss = 1.21765618, grad/param norm = 1.4298e-01, time/batch = 18.5653s	
9140/33650 (epoch 13.581), train_loss = 1.24313109, grad/param norm = 1.5154e-01, time/batch = 16.0296s	
9141/33650 (epoch 13.582), train_loss = 1.22939604, grad/param norm = 1.3613e-01, time/batch = 18.8954s	
9142/33650 (epoch 13.584), train_loss = 1.20367904, grad/param norm = 1.5605e-01, time/batch = 17.1362s	
9143/33650 (epoch 13.585), train_loss = 1.22722198, grad/param norm = 1.7415e-01, time/batch = 17.8025s	
9144/33650 (epoch 13.587), train_loss = 1.05550167, grad/param norm = 1.5059e-01, time/batch = 17.9824s	
9145/33650 (epoch 13.588), train_loss = 1.11682281, grad/param norm = 1.5720e-01, time/batch = 18.5720s	
9146/33650 (epoch 13.590), train_loss = 1.10931609, grad/param norm = 1.3784e-01, time/batch = 17.6456s	
9147/33650 (epoch 13.591), train_loss = 1.09946412, grad/param norm = 1.5647e-01, time/batch = 17.8781s	
9148/33650 (epoch 13.593), train_loss = 1.05819003, grad/param norm = 1.3404e-01, time/batch = 16.7127s	
9149/33650 (epoch 13.594), train_loss = 0.99255150, grad/param norm = 1.4626e-01, time/batch = 17.2196s	
9150/33650 (epoch 13.596), train_loss = 1.09886575, grad/param norm = 1.3195e-01, time/batch = 17.3057s	
9151/33650 (epoch 13.597), train_loss = 0.92824371, grad/param norm = 1.1668e-01, time/batch = 17.8139s	
9152/33650 (epoch 13.599), train_loss = 1.08651000, grad/param norm = 1.4394e-01, time/batch = 17.7362s	
9153/33650 (epoch 13.600), train_loss = 1.00712810, grad/param norm = 1.3653e-01, time/batch = 16.6470s	
9154/33650 (epoch 13.602), train_loss = 1.20751504, grad/param norm = 1.4864e-01, time/batch = 18.4010s	
9155/33650 (epoch 13.603), train_loss = 1.06375226, grad/param norm = 1.4191e-01, time/batch = 17.6485s	
9156/33650 (epoch 13.605), train_loss = 1.19537534, grad/param norm = 1.5771e-01, time/batch = 17.2432s	
9157/33650 (epoch 13.606), train_loss = 1.23450240, grad/param norm = 1.5380e-01, time/batch = 16.5592s	
9158/33650 (epoch 13.608), train_loss = 1.06900646, grad/param norm = 1.4519e-01, time/batch = 17.6465s	
9159/33650 (epoch 13.609), train_loss = 1.15456861, grad/param norm = 1.5050e-01, time/batch = 17.7203s	
9160/33650 (epoch 13.611), train_loss = 1.01770426, grad/param norm = 1.4662e-01, time/batch = 17.6255s	
9161/33650 (epoch 13.612), train_loss = 1.13498687, grad/param norm = 1.5168e-01, time/batch = 17.3821s	
9162/33650 (epoch 13.614), train_loss = 1.19090929, grad/param norm = 1.4507e-01, time/batch = 18.6340s	
9163/33650 (epoch 13.615), train_loss = 1.09208788, grad/param norm = 1.2653e-01, time/batch = 16.8272s	
9164/33650 (epoch 13.617), train_loss = 1.01630248, grad/param norm = 1.2336e-01, time/batch = 17.2785s	
9165/33650 (epoch 13.618), train_loss = 1.10985431, grad/param norm = 1.3896e-01, time/batch = 18.1446s	
9166/33650 (epoch 13.620), train_loss = 1.17105963, grad/param norm = 1.6109e-01, time/batch = 18.8924s	
9167/33650 (epoch 13.621), train_loss = 1.00198189, grad/param norm = 1.2883e-01, time/batch = 17.3115s	
9168/33650 (epoch 13.623), train_loss = 1.10251615, grad/param norm = 1.4024e-01, time/batch = 17.3869s	
9169/33650 (epoch 13.624), train_loss = 0.86954572, grad/param norm = 1.2832e-01, time/batch = 18.9950s	
9170/33650 (epoch 13.626), train_loss = 0.87751427, grad/param norm = 1.2516e-01, time/batch = 17.8921s	
9171/33650 (epoch 13.627), train_loss = 1.05600525, grad/param norm = 1.4649e-01, time/batch = 17.9752s	
9172/33650 (epoch 13.629), train_loss = 1.09846505, grad/param norm = 1.3938e-01, time/batch = 17.4741s	
9173/33650 (epoch 13.630), train_loss = 1.22050888, grad/param norm = 1.5479e-01, time/batch = 17.9726s	
9174/33650 (epoch 13.632), train_loss = 1.24015511, grad/param norm = 1.5071e-01, time/batch = 17.2233s	
9175/33650 (epoch 13.633), train_loss = 1.23410985, grad/param norm = 1.3795e-01, time/batch = 18.2312s	
9176/33650 (epoch 13.634), train_loss = 0.95050463, grad/param norm = 1.3060e-01, time/batch = 17.6281s	
9177/33650 (epoch 13.636), train_loss = 0.85177634, grad/param norm = 1.1052e-01, time/batch = 16.8763s	
9178/33650 (epoch 13.637), train_loss = 1.10436088, grad/param norm = 1.4952e-01, time/batch = 17.5728s	
9179/33650 (epoch 13.639), train_loss = 1.06498390, grad/param norm = 1.4304e-01, time/batch = 18.8076s	
9180/33650 (epoch 13.640), train_loss = 1.11287212, grad/param norm = 1.4206e-01, time/batch = 17.6423s	
9181/33650 (epoch 13.642), train_loss = 1.20745485, grad/param norm = 1.4978e-01, time/batch = 17.8893s	
9182/33650 (epoch 13.643), train_loss = 1.13229333, grad/param norm = 1.6063e-01, time/batch = 18.5632s	
9183/33650 (epoch 13.645), train_loss = 1.12045455, grad/param norm = 1.3490e-01, time/batch = 18.4815s	
9184/33650 (epoch 13.646), train_loss = 0.93438568, grad/param norm = 1.2061e-01, time/batch = 16.3700s	
9185/33650 (epoch 13.648), train_loss = 1.11993781, grad/param norm = 1.3704e-01, time/batch = 17.3187s	
9186/33650 (epoch 13.649), train_loss = 1.10884312, grad/param norm = 1.5911e-01, time/batch = 18.9831s	
9187/33650 (epoch 13.651), train_loss = 1.25830792, grad/param norm = 1.5578e-01, time/batch = 15.7196s	
9188/33650 (epoch 13.652), train_loss = 0.82271679, grad/param norm = 1.0841e-01, time/batch = 17.8184s	
9189/33650 (epoch 13.654), train_loss = 1.04093751, grad/param norm = 1.3590e-01, time/batch = 14.8629s	
9190/33650 (epoch 13.655), train_loss = 0.98763881, grad/param norm = 1.2728e-01, time/batch = 14.5384s	
9191/33650 (epoch 13.657), train_loss = 1.09693701, grad/param norm = 1.4757e-01, time/batch = 15.3668s	
9192/33650 (epoch 13.658), train_loss = 0.96797464, grad/param norm = 1.3565e-01, time/batch = 14.8987s	
9193/33650 (epoch 13.660), train_loss = 0.92301827, grad/param norm = 1.2833e-01, time/batch = 15.3699s	
9194/33650 (epoch 13.661), train_loss = 1.04140590, grad/param norm = 1.3352e-01, time/batch = 17.6306s	
9195/33650 (epoch 13.663), train_loss = 0.96980264, grad/param norm = 1.5790e-01, time/batch = 17.2188s	
9196/33650 (epoch 13.664), train_loss = 0.98196427, grad/param norm = 1.2153e-01, time/batch = 18.2338s	
9197/33650 (epoch 13.666), train_loss = 1.04476860, grad/param norm = 1.4643e-01, time/batch = 18.4120s	
9198/33650 (epoch 13.667), train_loss = 1.00363259, grad/param norm = 1.3493e-01, time/batch = 27.0095s	
9199/33650 (epoch 13.669), train_loss = 1.02280067, grad/param norm = 1.4978e-01, time/batch = 21.9301s	
9200/33650 (epoch 13.670), train_loss = 0.92394512, grad/param norm = 1.4420e-01, time/batch = 18.3889s	
9201/33650 (epoch 13.672), train_loss = 0.95716912, grad/param norm = 1.4937e-01, time/batch = 15.0071s	
9202/33650 (epoch 13.673), train_loss = 0.89044387, grad/param norm = 1.2950e-01, time/batch = 15.5530s	
9203/33650 (epoch 13.675), train_loss = 0.87292965, grad/param norm = 1.1097e-01, time/batch = 17.7232s	
9204/33650 (epoch 13.676), train_loss = 1.08033203, grad/param norm = 1.4305e-01, time/batch = 15.4545s	
9205/33650 (epoch 13.678), train_loss = 0.99430506, grad/param norm = 1.2546e-01, time/batch = 16.7322s	
9206/33650 (epoch 13.679), train_loss = 1.05549991, grad/param norm = 1.3951e-01, time/batch = 18.4666s	
9207/33650 (epoch 13.681), train_loss = 1.03048366, grad/param norm = 1.2490e-01, time/batch = 18.3761s	
9208/33650 (epoch 13.682), train_loss = 1.02721473, grad/param norm = 1.4670e-01, time/batch = 17.7193s	
9209/33650 (epoch 13.684), train_loss = 0.96330721, grad/param norm = 1.2584e-01, time/batch = 18.4703s	
9210/33650 (epoch 13.685), train_loss = 1.15869601, grad/param norm = 1.4485e-01, time/batch = 17.7155s	
9211/33650 (epoch 13.686), train_loss = 1.10790341, grad/param norm = 1.4138e-01, time/batch = 16.8049s	
9212/33650 (epoch 13.688), train_loss = 1.22274016, grad/param norm = 1.4903e-01, time/batch = 17.8040s	
9213/33650 (epoch 13.689), train_loss = 1.00411245, grad/param norm = 1.3024e-01, time/batch = 18.1410s	
9214/33650 (epoch 13.691), train_loss = 1.23449624, grad/param norm = 1.4847e-01, time/batch = 18.2162s	
9215/33650 (epoch 13.692), train_loss = 1.20473424, grad/param norm = 1.4229e-01, time/batch = 17.7873s	
9216/33650 (epoch 13.694), train_loss = 1.13127098, grad/param norm = 1.4998e-01, time/batch = 17.9814s	
9217/33650 (epoch 13.695), train_loss = 0.80381492, grad/param norm = 1.3352e-01, time/batch = 18.9738s	
9218/33650 (epoch 13.697), train_loss = 1.06552392, grad/param norm = 1.4113e-01, time/batch = 17.4707s	
9219/33650 (epoch 13.698), train_loss = 1.23178002, grad/param norm = 1.4603e-01, time/batch = 16.8763s	
9220/33650 (epoch 13.700), train_loss = 1.07505540, grad/param norm = 1.3913e-01, time/batch = 18.8036s	
9221/33650 (epoch 13.701), train_loss = 1.12925108, grad/param norm = 1.5251e-01, time/batch = 17.2980s	
9222/33650 (epoch 13.703), train_loss = 1.22702959, grad/param norm = 1.3936e-01, time/batch = 16.7089s	
9223/33650 (epoch 13.704), train_loss = 1.04803880, grad/param norm = 1.2997e-01, time/batch = 17.1462s	
9224/33650 (epoch 13.706), train_loss = 1.07057150, grad/param norm = 1.4514e-01, time/batch = 17.4747s	
9225/33650 (epoch 13.707), train_loss = 1.16586611, grad/param norm = 1.4895e-01, time/batch = 17.3097s	
9226/33650 (epoch 13.709), train_loss = 1.06469488, grad/param norm = 1.4074e-01, time/batch = 17.0386s	
9227/33650 (epoch 13.710), train_loss = 1.28792277, grad/param norm = 1.4110e-01, time/batch = 18.1549s	
9228/33650 (epoch 13.712), train_loss = 1.02052227, grad/param norm = 1.3850e-01, time/batch = 15.9769s	
9229/33650 (epoch 13.713), train_loss = 1.02913422, grad/param norm = 2.3654e-01, time/batch = 15.5519s	
9230/33650 (epoch 13.715), train_loss = 1.20758871, grad/param norm = 1.6223e-01, time/batch = 18.8171s	
9231/33650 (epoch 13.716), train_loss = 0.99005166, grad/param norm = 1.3841e-01, time/batch = 18.6346s	
9232/33650 (epoch 13.718), train_loss = 1.07965611, grad/param norm = 1.5235e-01, time/batch = 17.5602s	
9233/33650 (epoch 13.719), train_loss = 1.26586632, grad/param norm = 1.7448e-01, time/batch = 17.8054s	
9234/33650 (epoch 13.721), train_loss = 1.32582288, grad/param norm = 1.7499e-01, time/batch = 15.8907s	
9235/33650 (epoch 13.722), train_loss = 1.21869534, grad/param norm = 1.6883e-01, time/batch = 17.1353s	
9236/33650 (epoch 13.724), train_loss = 1.17855724, grad/param norm = 1.5511e-01, time/batch = 14.2242s	
9237/33650 (epoch 13.725), train_loss = 1.21299518, grad/param norm = 1.6234e-01, time/batch = 18.1380s	
9238/33650 (epoch 13.727), train_loss = 0.99984460, grad/param norm = 1.4328e-01, time/batch = 16.6185s	
9239/33650 (epoch 13.728), train_loss = 1.02416629, grad/param norm = 1.2854e-01, time/batch = 17.4721s	
9240/33650 (epoch 13.730), train_loss = 1.17343662, grad/param norm = 1.4637e-01, time/batch = 16.2283s	
9241/33650 (epoch 13.731), train_loss = 1.23368893, grad/param norm = 1.5423e-01, time/batch = 18.5554s	
9242/33650 (epoch 13.733), train_loss = 1.09965678, grad/param norm = 1.5041e-01, time/batch = 16.3248s	
9243/33650 (epoch 13.734), train_loss = 1.27084739, grad/param norm = 1.6650e-01, time/batch = 18.3156s	
9244/33650 (epoch 13.736), train_loss = 1.10536231, grad/param norm = 1.5814e-01, time/batch = 17.7162s	
9245/33650 (epoch 13.737), train_loss = 1.13678089, grad/param norm = 1.5198e-01, time/batch = 17.4622s	
9246/33650 (epoch 13.738), train_loss = 0.99623215, grad/param norm = 1.4133e-01, time/batch = 18.8886s	
9247/33650 (epoch 13.740), train_loss = 0.95701337, grad/param norm = 1.3055e-01, time/batch = 17.9751s	
9248/33650 (epoch 13.741), train_loss = 1.04865235, grad/param norm = 1.4297e-01, time/batch = 18.9155s	
9249/33650 (epoch 13.743), train_loss = 1.08783921, grad/param norm = 1.3810e-01, time/batch = 17.7110s	
9250/33650 (epoch 13.744), train_loss = 1.09340999, grad/param norm = 1.4039e-01, time/batch = 18.2306s	
9251/33650 (epoch 13.746), train_loss = 1.07852599, grad/param norm = 1.4506e-01, time/batch = 18.2191s	
9252/33650 (epoch 13.747), train_loss = 1.20800752, grad/param norm = 1.4324e-01, time/batch = 17.2284s	
9253/33650 (epoch 13.749), train_loss = 0.92083602, grad/param norm = 1.3164e-01, time/batch = 16.6367s	
9254/33650 (epoch 13.750), train_loss = 1.22431897, grad/param norm = 1.5229e-01, time/batch = 17.9724s	
9255/33650 (epoch 13.752), train_loss = 1.23107747, grad/param norm = 1.4934e-01, time/batch = 18.1337s	
9256/33650 (epoch 13.753), train_loss = 1.36814428, grad/param norm = 1.8816e-01, time/batch = 17.3250s	
9257/33650 (epoch 13.755), train_loss = 1.03229247, grad/param norm = 1.2680e-01, time/batch = 17.9068s	
9258/33650 (epoch 13.756), train_loss = 1.21503767, grad/param norm = 1.6084e-01, time/batch = 16.8783s	
9259/33650 (epoch 13.758), train_loss = 1.19723394, grad/param norm = 1.4764e-01, time/batch = 17.0431s	
9260/33650 (epoch 13.759), train_loss = 1.28243802, grad/param norm = 1.5503e-01, time/batch = 18.3963s	
9261/33650 (epoch 13.761), train_loss = 1.17527813, grad/param norm = 1.5606e-01, time/batch = 17.5556s	
9262/33650 (epoch 13.762), train_loss = 1.13230358, grad/param norm = 1.5147e-01, time/batch = 17.1393s	
9263/33650 (epoch 13.764), train_loss = 1.19053438, grad/param norm = 1.5887e-01, time/batch = 17.7284s	
9264/33650 (epoch 13.765), train_loss = 1.12351066, grad/param norm = 1.4303e-01, time/batch = 18.1463s	
9265/33650 (epoch 13.767), train_loss = 1.08123566, grad/param norm = 1.3718e-01, time/batch = 18.1471s	
9266/33650 (epoch 13.768), train_loss = 0.98293753, grad/param norm = 1.3633e-01, time/batch = 18.4668s	
9267/33650 (epoch 13.770), train_loss = 1.13288434, grad/param norm = 1.4808e-01, time/batch = 18.2389s	
9268/33650 (epoch 13.771), train_loss = 1.11791592, grad/param norm = 1.4247e-01, time/batch = 18.7344s	
9269/33650 (epoch 13.773), train_loss = 1.27174081, grad/param norm = 1.6838e-01, time/batch = 17.4690s	
9270/33650 (epoch 13.774), train_loss = 1.15256171, grad/param norm = 1.5613e-01, time/batch = 17.4031s	
9271/33650 (epoch 13.776), train_loss = 1.19899638, grad/param norm = 1.6073e-01, time/batch = 17.1503s	
9272/33650 (epoch 13.777), train_loss = 0.97411025, grad/param norm = 1.3397e-01, time/batch = 16.8028s	
9273/33650 (epoch 13.779), train_loss = 1.09451001, grad/param norm = 1.4103e-01, time/batch = 16.1363s	
9274/33650 (epoch 13.780), train_loss = 1.01201566, grad/param norm = 1.2482e-01, time/batch = 17.8937s	
9275/33650 (epoch 13.782), train_loss = 1.03303106, grad/param norm = 1.3629e-01, time/batch = 17.9917s	
9276/33650 (epoch 13.783), train_loss = 1.00375858, grad/param norm = 1.3300e-01, time/batch = 18.2126s	
9277/33650 (epoch 13.785), train_loss = 1.31694088, grad/param norm = 1.4330e-01, time/batch = 18.4123s	
9278/33650 (epoch 13.786), train_loss = 1.14367170, grad/param norm = 1.4157e-01, time/batch = 17.5609s	
9279/33650 (epoch 13.788), train_loss = 1.14047542, grad/param norm = 1.2825e-01, time/batch = 16.8974s	
9280/33650 (epoch 13.789), train_loss = 1.17171042, grad/param norm = 1.3810e-01, time/batch = 18.0602s	
9281/33650 (epoch 13.790), train_loss = 1.16937584, grad/param norm = 1.6433e-01, time/batch = 18.7299s	
9282/33650 (epoch 13.792), train_loss = 1.23502424, grad/param norm = 1.6122e-01, time/batch = 17.2356s	
9283/33650 (epoch 13.793), train_loss = 1.20758210, grad/param norm = 2.0551e-01, time/batch = 16.9905s	
9284/33650 (epoch 13.795), train_loss = 1.25369688, grad/param norm = 1.4604e-01, time/batch = 16.8977s	
9285/33650 (epoch 13.796), train_loss = 1.10511596, grad/param norm = 1.4661e-01, time/batch = 17.7377s	
9286/33650 (epoch 13.798), train_loss = 1.08971107, grad/param norm = 1.4270e-01, time/batch = 16.5738s	
9287/33650 (epoch 13.799), train_loss = 1.10996859, grad/param norm = 1.2864e-01, time/batch = 16.7410s	
9288/33650 (epoch 13.801), train_loss = 1.17599111, grad/param norm = 1.6075e-01, time/batch = 16.1321s	
9289/33650 (epoch 13.802), train_loss = 1.23717184, grad/param norm = 1.3949e-01, time/batch = 17.1524s	
9290/33650 (epoch 13.804), train_loss = 1.11347805, grad/param norm = 1.5402e-01, time/batch = 16.9869s	
9291/33650 (epoch 13.805), train_loss = 1.06365555, grad/param norm = 1.2588e-01, time/batch = 16.9769s	
9292/33650 (epoch 13.807), train_loss = 1.35148186, grad/param norm = 1.6841e-01, time/batch = 17.0733s	
9293/33650 (epoch 13.808), train_loss = 1.33590534, grad/param norm = 1.6357e-01, time/batch = 15.9619s	
9294/33650 (epoch 13.810), train_loss = 1.18151834, grad/param norm = 1.4192e-01, time/batch = 17.2322s	
9295/33650 (epoch 13.811), train_loss = 1.14597168, grad/param norm = 1.4665e-01, time/batch = 16.2107s	
9296/33650 (epoch 13.813), train_loss = 1.08925668, grad/param norm = 1.4444e-01, time/batch = 17.4891s	
9297/33650 (epoch 13.814), train_loss = 1.20316982, grad/param norm = 1.4120e-01, time/batch = 17.3123s	
9298/33650 (epoch 13.816), train_loss = 1.15855444, grad/param norm = 1.4384e-01, time/batch = 17.1591s	
9299/33650 (epoch 13.817), train_loss = 1.20461067, grad/param norm = 1.6540e-01, time/batch = 17.4135s	
9300/33650 (epoch 13.819), train_loss = 1.22565186, grad/param norm = 1.4452e-01, time/batch = 16.0531s	
9301/33650 (epoch 13.820), train_loss = 1.26745357, grad/param norm = 1.4723e-01, time/batch = 16.9083s	
9302/33650 (epoch 13.822), train_loss = 1.20609697, grad/param norm = 1.6286e-01, time/batch = 16.1450s	
9303/33650 (epoch 13.823), train_loss = 1.04050958, grad/param norm = 1.5078e-01, time/batch = 17.0527s	
9304/33650 (epoch 13.825), train_loss = 1.10218605, grad/param norm = 1.3380e-01, time/batch = 15.2471s	
9305/33650 (epoch 13.826), train_loss = 1.21116080, grad/param norm = 1.4991e-01, time/batch = 14.7312s	
9306/33650 (epoch 13.828), train_loss = 1.34832801, grad/param norm = 1.5294e-01, time/batch = 16.2391s	
9307/33650 (epoch 13.829), train_loss = 0.96528587, grad/param norm = 1.3302e-01, time/batch = 15.2010s	
9308/33650 (epoch 13.831), train_loss = 1.20192414, grad/param norm = 1.5172e-01, time/batch = 14.4905s	
9309/33650 (epoch 13.832), train_loss = 1.17283460, grad/param norm = 1.3832e-01, time/batch = 13.9944s	
9310/33650 (epoch 13.834), train_loss = 1.21921367, grad/param norm = 1.5387e-01, time/batch = 13.9365s	
9311/33650 (epoch 13.835), train_loss = 1.37836903, grad/param norm = 1.6355e-01, time/batch = 14.0987s	
9312/33650 (epoch 13.837), train_loss = 1.19299206, grad/param norm = 1.6598e-01, time/batch = 14.2584s	
9313/33650 (epoch 13.838), train_loss = 1.12539780, grad/param norm = 1.5165e-01, time/batch = 13.9332s	
9314/33650 (epoch 13.840), train_loss = 1.21681009, grad/param norm = 1.4023e-01, time/batch = 13.9377s	
9315/33650 (epoch 13.841), train_loss = 1.04671394, grad/param norm = 1.3729e-01, time/batch = 14.0199s	
9316/33650 (epoch 13.842), train_loss = 1.09769228, grad/param norm = 1.3822e-01, time/batch = 14.6388s	
9317/33650 (epoch 13.844), train_loss = 1.28358968, grad/param norm = 1.5509e-01, time/batch = 14.0206s	
9318/33650 (epoch 13.845), train_loss = 1.06236009, grad/param norm = 1.3374e-01, time/batch = 13.9351s	
9319/33650 (epoch 13.847), train_loss = 0.88813340, grad/param norm = 1.2713e-01, time/batch = 13.9399s	
9320/33650 (epoch 13.848), train_loss = 0.97259169, grad/param norm = 1.4573e-01, time/batch = 14.6648s	
9321/33650 (epoch 13.850), train_loss = 1.13084746, grad/param norm = 1.6194e-01, time/batch = 14.4062s	
9322/33650 (epoch 13.851), train_loss = 0.90909472, grad/param norm = 1.2205e-01, time/batch = 14.0079s	
9323/33650 (epoch 13.853), train_loss = 1.15253503, grad/param norm = 1.5265e-01, time/batch = 14.0920s	
9324/33650 (epoch 13.854), train_loss = 1.25652722, grad/param norm = 1.6014e-01, time/batch = 14.4164s	
9325/33650 (epoch 13.856), train_loss = 0.86769273, grad/param norm = 1.2791e-01, time/batch = 14.5479s	
9326/33650 (epoch 13.857), train_loss = 1.10103769, grad/param norm = 1.2882e-01, time/batch = 14.1716s	
9327/33650 (epoch 13.859), train_loss = 1.01033963, grad/param norm = 1.2927e-01, time/batch = 14.0156s	
9328/33650 (epoch 13.860), train_loss = 0.93139761, grad/param norm = 1.3220e-01, time/batch = 14.0854s	
9329/33650 (epoch 13.862), train_loss = 1.00634386, grad/param norm = 1.3710e-01, time/batch = 14.6567s	
9330/33650 (epoch 13.863), train_loss = 1.20648870, grad/param norm = 1.4311e-01, time/batch = 14.1522s	
9331/33650 (epoch 13.865), train_loss = 1.10400513, grad/param norm = 1.4109e-01, time/batch = 14.1846s	
9332/33650 (epoch 13.866), train_loss = 0.99696603, grad/param norm = 1.3626e-01, time/batch = 14.0174s	
9333/33650 (epoch 13.868), train_loss = 0.99413796, grad/param norm = 1.4841e-01, time/batch = 14.4216s	
9334/33650 (epoch 13.869), train_loss = 1.24810992, grad/param norm = 1.5713e-01, time/batch = 14.0123s	
9335/33650 (epoch 13.871), train_loss = 0.96321795, grad/param norm = 1.1611e-01, time/batch = 13.8583s	
9336/33650 (epoch 13.872), train_loss = 1.11929397, grad/param norm = 1.4061e-01, time/batch = 14.1046s	
9337/33650 (epoch 13.874), train_loss = 1.20678181, grad/param norm = 1.6993e-01, time/batch = 14.7485s	
9338/33650 (epoch 13.875), train_loss = 1.10010762, grad/param norm = 1.4473e-01, time/batch = 14.0971s	
9339/33650 (epoch 13.877), train_loss = 1.24482664, grad/param norm = 1.4620e-01, time/batch = 13.9383s	
9340/33650 (epoch 13.878), train_loss = 0.80034669, grad/param norm = 1.2490e-01, time/batch = 14.0892s	
9341/33650 (epoch 13.880), train_loss = 1.17570366, grad/param norm = 1.5941e-01, time/batch = 14.8212s	
9342/33650 (epoch 13.881), train_loss = 1.06124255, grad/param norm = 1.5706e-01, time/batch = 14.7177s	
9343/33650 (epoch 13.883), train_loss = 1.12356604, grad/param norm = 1.4672e-01, time/batch = 14.1830s	
9344/33650 (epoch 13.884), train_loss = 1.23209477, grad/param norm = 1.5561e-01, time/batch = 14.1005s	
9345/33650 (epoch 13.886), train_loss = 1.23164493, grad/param norm = 1.5512e-01, time/batch = 14.2581s	
9346/33650 (epoch 13.887), train_loss = 1.02908102, grad/param norm = 1.2666e-01, time/batch = 14.1764s	
9347/33650 (epoch 13.889), train_loss = 1.17793233, grad/param norm = 1.5754e-01, time/batch = 14.6480s	
9348/33650 (epoch 13.890), train_loss = 1.17501114, grad/param norm = 1.3472e-01, time/batch = 14.0968s	
9349/33650 (epoch 13.892), train_loss = 1.14942972, grad/param norm = 1.6067e-01, time/batch = 14.1733s	
9350/33650 (epoch 13.893), train_loss = 1.15616097, grad/param norm = 1.3897e-01, time/batch = 14.3328s	
9351/33650 (epoch 13.895), train_loss = 1.26764180, grad/param norm = 1.5689e-01, time/batch = 14.2628s	
9352/33650 (epoch 13.896), train_loss = 1.02836495, grad/param norm = 1.3507e-01, time/batch = 14.3303s	
9353/33650 (epoch 13.897), train_loss = 0.95042085, grad/param norm = 1.2460e-01, time/batch = 14.1733s	
9354/33650 (epoch 13.899), train_loss = 0.99062768, grad/param norm = 1.2887e-01, time/batch = 14.5172s	
9355/33650 (epoch 13.900), train_loss = 0.90385298, grad/param norm = 1.2546e-01, time/batch = 14.2708s	
9356/33650 (epoch 13.902), train_loss = 1.13701150, grad/param norm = 1.4407e-01, time/batch = 14.0115s	
9357/33650 (epoch 13.903), train_loss = 1.09616745, grad/param norm = 1.6727e-01, time/batch = 14.0957s	
9358/33650 (epoch 13.905), train_loss = 1.30341484, grad/param norm = 1.6973e-01, time/batch = 14.4841s	
9359/33650 (epoch 13.906), train_loss = 1.08193827, grad/param norm = 1.4406e-01, time/batch = 13.9473s	
9360/33650 (epoch 13.908), train_loss = 1.04927438, grad/param norm = 1.2702e-01, time/batch = 14.2639s	
9361/33650 (epoch 13.909), train_loss = 1.06036250, grad/param norm = 1.3921e-01, time/batch = 14.0172s	
9362/33650 (epoch 13.911), train_loss = 0.92914587, grad/param norm = 1.2855e-01, time/batch = 14.5813s	
9363/33650 (epoch 13.912), train_loss = 0.91814183, grad/param norm = 1.2239e-01, time/batch = 14.3977s	
9364/33650 (epoch 13.914), train_loss = 1.10087194, grad/param norm = 1.3405e-01, time/batch = 13.8571s	
9365/33650 (epoch 13.915), train_loss = 1.10640077, grad/param norm = 1.4838e-01, time/batch = 14.4291s	
9366/33650 (epoch 13.917), train_loss = 1.09977826, grad/param norm = 1.4373e-01, time/batch = 14.4143s	
9367/33650 (epoch 13.918), train_loss = 0.89155208, grad/param norm = 1.1999e-01, time/batch = 14.2494s	
9368/33650 (epoch 13.920), train_loss = 1.00658318, grad/param norm = 1.2593e-01, time/batch = 14.1758s	
9369/33650 (epoch 13.921), train_loss = 0.99082709, grad/param norm = 1.3379e-01, time/batch = 14.7478s	
9370/33650 (epoch 13.923), train_loss = 0.95962499, grad/param norm = 1.3699e-01, time/batch = 14.4036s	
9371/33650 (epoch 13.924), train_loss = 1.11445260, grad/param norm = 1.4800e-01, time/batch = 14.2604s	
9372/33650 (epoch 13.926), train_loss = 1.09765391, grad/param norm = 1.6533e-01, time/batch = 14.1779s	
9373/33650 (epoch 13.927), train_loss = 1.03197367, grad/param norm = 1.3831e-01, time/batch = 13.7723s	
9374/33650 (epoch 13.929), train_loss = 1.13065843, grad/param norm = 1.4258e-01, time/batch = 14.2501s	
9375/33650 (epoch 13.930), train_loss = 1.03950933, grad/param norm = 1.3452e-01, time/batch = 14.3449s	
9376/33650 (epoch 13.932), train_loss = 1.10644926, grad/param norm = 1.5336e-01, time/batch = 14.3167s	
9377/33650 (epoch 13.933), train_loss = 0.95450651, grad/param norm = 1.3244e-01, time/batch = 14.1795s	
9378/33650 (epoch 13.935), train_loss = 0.98881466, grad/param norm = 1.3031e-01, time/batch = 14.2563s	
9379/33650 (epoch 13.936), train_loss = 1.00227851, grad/param norm = 1.3547e-01, time/batch = 14.4977s	
9380/33650 (epoch 13.938), train_loss = 0.93008601, grad/param norm = 1.3558e-01, time/batch = 14.8307s	
9381/33650 (epoch 13.939), train_loss = 1.14272692, grad/param norm = 1.3930e-01, time/batch = 14.3430s	
9382/33650 (epoch 13.941), train_loss = 1.10432127, grad/param norm = 1.5144e-01, time/batch = 14.0240s	
9383/33650 (epoch 13.942), train_loss = 1.17920734, grad/param norm = 1.5023e-01, time/batch = 14.6505s	
9384/33650 (epoch 13.944), train_loss = 1.09707330, grad/param norm = 1.2913e-01, time/batch = 13.8531s	
9385/33650 (epoch 13.945), train_loss = 1.17597305, grad/param norm = 1.5192e-01, time/batch = 14.4129s	
9386/33650 (epoch 13.947), train_loss = 1.32469265, grad/param norm = 1.9598e-01, time/batch = 14.3437s	
9387/33650 (epoch 13.948), train_loss = 1.23024808, grad/param norm = 1.4023e-01, time/batch = 14.5731s	
9388/33650 (epoch 13.949), train_loss = 0.99386141, grad/param norm = 1.4219e-01, time/batch = 13.9462s	
9389/33650 (epoch 13.951), train_loss = 1.25176083, grad/param norm = 1.5524e-01, time/batch = 14.3274s	
9390/33650 (epoch 13.952), train_loss = 1.19336356, grad/param norm = 1.5226e-01, time/batch = 13.9491s	
9391/33650 (epoch 13.954), train_loss = 1.17983351, grad/param norm = 1.4901e-01, time/batch = 16.7904s	
9392/33650 (epoch 13.955), train_loss = 1.18576350, grad/param norm = 1.5104e-01, time/batch = 18.6506s	
9393/33650 (epoch 13.957), train_loss = 1.16016391, grad/param norm = 1.5102e-01, time/batch = 18.1245s	
9394/33650 (epoch 13.958), train_loss = 0.85855093, grad/param norm = 1.2116e-01, time/batch = 17.6352s	
9395/33650 (epoch 13.960), train_loss = 0.93928105, grad/param norm = 1.3030e-01, time/batch = 18.0637s	
9396/33650 (epoch 13.961), train_loss = 0.98986189, grad/param norm = 1.4422e-01, time/batch = 17.9857s	
9397/33650 (epoch 13.963), train_loss = 1.06629344, grad/param norm = 1.4881e-01, time/batch = 18.3148s	
9398/33650 (epoch 13.964), train_loss = 1.10802129, grad/param norm = 1.5841e-01, time/batch = 18.0486s	
9399/33650 (epoch 13.966), train_loss = 1.09110826, grad/param norm = 1.4863e-01, time/batch = 17.9737s	
9400/33650 (epoch 13.967), train_loss = 1.16639759, grad/param norm = 1.4466e-01, time/batch = 18.3174s	
9401/33650 (epoch 13.969), train_loss = 1.05923759, grad/param norm = 1.3308e-01, time/batch = 17.2147s	
9402/33650 (epoch 13.970), train_loss = 1.14911220, grad/param norm = 1.4761e-01, time/batch = 17.8951s	
9403/33650 (epoch 13.972), train_loss = 1.44484753, grad/param norm = 1.6296e-01, time/batch = 18.4705s	
9404/33650 (epoch 13.973), train_loss = 1.00865716, grad/param norm = 1.4049e-01, time/batch = 17.1167s	
9405/33650 (epoch 13.975), train_loss = 0.99908993, grad/param norm = 1.3717e-01, time/batch = 16.6490s	
9406/33650 (epoch 13.976), train_loss = 0.97864447, grad/param norm = 1.2468e-01, time/batch = 16.2924s	
9407/33650 (epoch 13.978), train_loss = 1.02749902, grad/param norm = 1.4595e-01, time/batch = 14.7794s	
9408/33650 (epoch 13.979), train_loss = 1.07899597, grad/param norm = 1.3894e-01, time/batch = 16.4800s	
9409/33650 (epoch 13.981), train_loss = 1.03481380, grad/param norm = 1.2441e-01, time/batch = 17.7300s	
9410/33650 (epoch 13.982), train_loss = 1.11674663, grad/param norm = 1.3550e-01, time/batch = 17.5599s	
9411/33650 (epoch 13.984), train_loss = 0.95551231, grad/param norm = 1.2779e-01, time/batch = 16.6600s	
9412/33650 (epoch 13.985), train_loss = 0.93037762, grad/param norm = 1.2396e-01, time/batch = 16.9097s	
9413/33650 (epoch 13.987), train_loss = 1.07384556, grad/param norm = 1.3374e-01, time/batch = 16.5705s	
9414/33650 (epoch 13.988), train_loss = 1.14194520, grad/param norm = 1.4823e-01, time/batch = 17.7270s	
9415/33650 (epoch 13.990), train_loss = 1.33922445, grad/param norm = 1.9095e-01, time/batch = 16.7301s	
9416/33650 (epoch 13.991), train_loss = 1.15396145, grad/param norm = 1.3504e-01, time/batch = 17.8177s	
9417/33650 (epoch 13.993), train_loss = 1.13943523, grad/param norm = 1.6472e-01, time/batch = 17.6531s	
9418/33650 (epoch 13.994), train_loss = 1.05032310, grad/param norm = 1.3493e-01, time/batch = 19.9360s	
9419/33650 (epoch 13.996), train_loss = 1.01957514, grad/param norm = 1.3728e-01, time/batch = 26.8624s	
9420/33650 (epoch 13.997), train_loss = 1.12833674, grad/param norm = 1.4929e-01, time/batch = 17.7446s	
9421/33650 (epoch 13.999), train_loss = 0.97177111, grad/param norm = 1.3549e-01, time/batch = 16.5587s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
9422/33650 (epoch 14.000), train_loss = 1.17138574, grad/param norm = 1.5374e-01, time/batch = 17.3282s	
9423/33650 (epoch 14.001), train_loss = 1.25250249, grad/param norm = 1.5159e-01, time/batch = 16.8088s	
9424/33650 (epoch 14.003), train_loss = 1.29923759, grad/param norm = 1.8711e-01, time/batch = 17.9911s	
9425/33650 (epoch 14.004), train_loss = 1.15282932, grad/param norm = 1.5450e-01, time/batch = 15.1290s	
9426/33650 (epoch 14.006), train_loss = 1.04789313, grad/param norm = 1.3578e-01, time/batch = 17.4046s	
9427/33650 (epoch 14.007), train_loss = 1.16379977, grad/param norm = 1.5939e-01, time/batch = 17.9915s	
9428/33650 (epoch 14.009), train_loss = 1.06898942, grad/param norm = 1.4465e-01, time/batch = 16.4885s	
9429/33650 (epoch 14.010), train_loss = 1.17294943, grad/param norm = 1.5387e-01, time/batch = 17.4797s	
9430/33650 (epoch 14.012), train_loss = 1.04894550, grad/param norm = 1.5006e-01, time/batch = 17.2474s	
9431/33650 (epoch 14.013), train_loss = 1.13892902, grad/param norm = 1.7846e-01, time/batch = 15.2718s	
9432/33650 (epoch 14.015), train_loss = 1.00324907, grad/param norm = 1.3682e-01, time/batch = 15.8337s	
9433/33650 (epoch 14.016), train_loss = 0.99284679, grad/param norm = 1.5495e-01, time/batch = 13.9590s	
9434/33650 (epoch 14.018), train_loss = 1.08482015, grad/param norm = 1.5879e-01, time/batch = 15.8142s	
9435/33650 (epoch 14.019), train_loss = 1.02068338, grad/param norm = 1.3903e-01, time/batch = 16.1622s	
9436/33650 (epoch 14.021), train_loss = 1.20670008, grad/param norm = 1.4244e-01, time/batch = 16.5376s	
9437/33650 (epoch 14.022), train_loss = 1.04872099, grad/param norm = 1.3380e-01, time/batch = 16.6630s	
9438/33650 (epoch 14.024), train_loss = 0.97892820, grad/param norm = 1.4754e-01, time/batch = 17.4914s	
9439/33650 (epoch 14.025), train_loss = 1.04529472, grad/param norm = 1.3408e-01, time/batch = 17.0571s	
9440/33650 (epoch 14.027), train_loss = 1.18435212, grad/param norm = 1.5496e-01, time/batch = 17.3155s	
9441/33650 (epoch 14.028), train_loss = 1.18165429, grad/param norm = 1.4840e-01, time/batch = 17.3053s	
9442/33650 (epoch 14.030), train_loss = 1.13077028, grad/param norm = 1.4486e-01, time/batch = 16.5412s	
9443/33650 (epoch 14.031), train_loss = 0.97424441, grad/param norm = 1.2683e-01, time/batch = 16.1029s	
9444/33650 (epoch 14.033), train_loss = 1.05407854, grad/param norm = 1.2199e-01, time/batch = 17.1481s	
9445/33650 (epoch 14.034), train_loss = 1.13438542, grad/param norm = 1.4702e-01, time/batch = 17.6548s	
9446/33650 (epoch 14.036), train_loss = 1.23402552, grad/param norm = 1.7330e-01, time/batch = 16.6490s	
9447/33650 (epoch 14.037), train_loss = 1.01751395, grad/param norm = 1.4356e-01, time/batch = 16.7165s	
9448/33650 (epoch 14.039), train_loss = 1.19963347, grad/param norm = 1.4507e-01, time/batch = 17.7356s	
9449/33650 (epoch 14.040), train_loss = 1.29080600, grad/param norm = 1.6894e-01, time/batch = 17.2418s	
9450/33650 (epoch 14.042), train_loss = 1.29944939, grad/param norm = 1.5837e-01, time/batch = 16.5324s	
9451/33650 (epoch 14.043), train_loss = 1.03088807, grad/param norm = 1.3912e-01, time/batch = 17.2324s	
9452/33650 (epoch 14.045), train_loss = 0.98991903, grad/param norm = 1.2379e-01, time/batch = 17.7296s	
9453/33650 (epoch 14.046), train_loss = 1.17402357, grad/param norm = 1.4787e-01, time/batch = 17.2223s	
9454/33650 (epoch 14.048), train_loss = 1.18081253, grad/param norm = 1.4162e-01, time/batch = 17.4760s	
9455/33650 (epoch 14.049), train_loss = 1.13062967, grad/param norm = 1.4242e-01, time/batch = 17.8929s	
9456/33650 (epoch 14.051), train_loss = 1.21484599, grad/param norm = 1.4589e-01, time/batch = 17.2375s	
9457/33650 (epoch 14.052), train_loss = 1.25267747, grad/param norm = 1.5587e-01, time/batch = 16.7358s	
9458/33650 (epoch 14.053), train_loss = 1.12329108, grad/param norm = 1.3882e-01, time/batch = 16.4043s	
9459/33650 (epoch 14.055), train_loss = 0.97591590, grad/param norm = 1.3434e-01, time/batch = 17.7323s	
9460/33650 (epoch 14.056), train_loss = 0.96270507, grad/param norm = 1.2431e-01, time/batch = 16.7058s	
9461/33650 (epoch 14.058), train_loss = 1.23189703, grad/param norm = 1.7470e-01, time/batch = 16.3137s	
9462/33650 (epoch 14.059), train_loss = 1.14659781, grad/param norm = 1.5318e-01, time/batch = 16.7165s	
9463/33650 (epoch 14.061), train_loss = 1.17169613, grad/param norm = 1.4796e-01, time/batch = 16.0404s	
9464/33650 (epoch 14.062), train_loss = 1.16414492, grad/param norm = 1.4212e-01, time/batch = 17.2318s	
9465/33650 (epoch 14.064), train_loss = 1.04367041, grad/param norm = 1.3772e-01, time/batch = 16.7418s	
9466/33650 (epoch 14.065), train_loss = 1.05732769, grad/param norm = 1.3888e-01, time/batch = 15.4747s	
9467/33650 (epoch 14.067), train_loss = 0.97852592, grad/param norm = 1.2822e-01, time/batch = 17.0680s	
9468/33650 (epoch 14.068), train_loss = 1.12380185, grad/param norm = 1.4747e-01, time/batch = 16.7350s	
9469/33650 (epoch 14.070), train_loss = 1.11181598, grad/param norm = 1.4358e-01, time/batch = 16.5725s	
9470/33650 (epoch 14.071), train_loss = 1.10724364, grad/param norm = 1.4177e-01, time/batch = 17.6513s	
9471/33650 (epoch 14.073), train_loss = 1.14211406, grad/param norm = 1.5024e-01, time/batch = 17.0547s	
9472/33650 (epoch 14.074), train_loss = 1.23217008, grad/param norm = 1.5211e-01, time/batch = 18.1519s	
9473/33650 (epoch 14.076), train_loss = 1.19264539, grad/param norm = 1.5506e-01, time/batch = 16.9086s	
9474/33650 (epoch 14.077), train_loss = 1.09585732, grad/param norm = 1.3745e-01, time/batch = 17.4792s	
9475/33650 (epoch 14.079), train_loss = 1.09426023, grad/param norm = 1.4895e-01, time/batch = 17.8202s	
9476/33650 (epoch 14.080), train_loss = 1.16020025, grad/param norm = 1.4362e-01, time/batch = 17.4732s	
9477/33650 (epoch 14.082), train_loss = 1.18644489, grad/param norm = 1.5364e-01, time/batch = 15.7845s	
9478/33650 (epoch 14.083), train_loss = 1.16832060, grad/param norm = 1.4474e-01, time/batch = 17.3062s	
9479/33650 (epoch 14.085), train_loss = 1.18857791, grad/param norm = 1.3619e-01, time/batch = 17.4817s	
9480/33650 (epoch 14.086), train_loss = 1.21204778, grad/param norm = 1.5518e-01, time/batch = 17.3212s	
9481/33650 (epoch 14.088), train_loss = 1.16538276, grad/param norm = 1.4497e-01, time/batch = 16.7274s	
9482/33650 (epoch 14.089), train_loss = 1.12777349, grad/param norm = 1.5011e-01, time/batch = 17.0701s	
9483/33650 (epoch 14.091), train_loss = 1.05189447, grad/param norm = 1.3192e-01, time/batch = 17.7286s	
9484/33650 (epoch 14.092), train_loss = 1.09180775, grad/param norm = 1.4047e-01, time/batch = 16.5631s	
9485/33650 (epoch 14.094), train_loss = 1.14810048, grad/param norm = 1.3072e-01, time/batch = 16.8846s	
9486/33650 (epoch 14.095), train_loss = 1.15256142, grad/param norm = 1.5305e-01, time/batch = 16.9960s	
9487/33650 (epoch 14.097), train_loss = 1.06992827, grad/param norm = 1.4808e-01, time/batch = 17.2440s	
9488/33650 (epoch 14.098), train_loss = 0.90411034, grad/param norm = 1.3044e-01, time/batch = 16.3954s	
9489/33650 (epoch 14.100), train_loss = 1.00774137, grad/param norm = 1.2657e-01, time/batch = 16.9811s	
9490/33650 (epoch 14.101), train_loss = 1.08785776, grad/param norm = 1.6809e-01, time/batch = 17.0775s	
9491/33650 (epoch 14.103), train_loss = 1.03839873, grad/param norm = 1.3676e-01, time/batch = 16.3871s	
9492/33650 (epoch 14.104), train_loss = 1.17336049, grad/param norm = 1.4106e-01, time/batch = 15.7035s	
9493/33650 (epoch 14.105), train_loss = 1.09811761, grad/param norm = 1.4694e-01, time/batch = 16.5434s	
9494/33650 (epoch 14.107), train_loss = 0.99525942, grad/param norm = 1.2461e-01, time/batch = 16.6304s	
9495/33650 (epoch 14.108), train_loss = 1.17251525, grad/param norm = 1.5351e-01, time/batch = 16.7293s	
9496/33650 (epoch 14.110), train_loss = 1.29574513, grad/param norm = 1.5335e-01, time/batch = 16.3265s	
9497/33650 (epoch 14.111), train_loss = 1.06011409, grad/param norm = 1.4794e-01, time/batch = 17.8175s	
9498/33650 (epoch 14.113), train_loss = 1.06738722, grad/param norm = 1.3712e-01, time/batch = 16.7476s	
9499/33650 (epoch 14.114), train_loss = 1.17942651, grad/param norm = 1.6050e-01, time/batch = 16.8969s	
9500/33650 (epoch 14.116), train_loss = 0.99297058, grad/param norm = 1.2862e-01, time/batch = 17.7385s	
9501/33650 (epoch 14.117), train_loss = 1.13490019, grad/param norm = 1.3162e-01, time/batch = 16.8960s	
9502/33650 (epoch 14.119), train_loss = 0.96870835, grad/param norm = 1.3089e-01, time/batch = 16.1390s	
9503/33650 (epoch 14.120), train_loss = 1.04320340, grad/param norm = 1.5247e-01, time/batch = 14.4273s	
9504/33650 (epoch 14.122), train_loss = 0.90341382, grad/param norm = 1.3009e-01, time/batch = 17.7418s	
9505/33650 (epoch 14.123), train_loss = 1.05369195, grad/param norm = 1.4172e-01, time/batch = 17.8314s	
9506/33650 (epoch 14.125), train_loss = 1.21539180, grad/param norm = 1.6068e-01, time/batch = 15.9469s	
9507/33650 (epoch 14.126), train_loss = 1.28372422, grad/param norm = 1.7419e-01, time/batch = 17.8982s	
9508/33650 (epoch 14.128), train_loss = 1.22732613, grad/param norm = 1.5668e-01, time/batch = 17.5776s	
9509/33650 (epoch 14.129), train_loss = 1.22104120, grad/param norm = 1.4588e-01, time/batch = 16.9868s	
9510/33650 (epoch 14.131), train_loss = 1.12466644, grad/param norm = 1.3982e-01, time/batch = 17.1418s	
9511/33650 (epoch 14.132), train_loss = 1.12006657, grad/param norm = 1.3931e-01, time/batch = 17.6427s	
9512/33650 (epoch 14.134), train_loss = 1.23522430, grad/param norm = 1.4696e-01, time/batch = 17.3969s	
9513/33650 (epoch 14.135), train_loss = 0.97290926, grad/param norm = 1.4916e-01, time/batch = 15.1405s	
9514/33650 (epoch 14.137), train_loss = 1.11425793, grad/param norm = 1.4812e-01, time/batch = 17.6505s	
9515/33650 (epoch 14.138), train_loss = 1.18969949, grad/param norm = 1.3882e-01, time/batch = 17.0575s	
9516/33650 (epoch 14.140), train_loss = 1.11418175, grad/param norm = 1.6089e-01, time/batch = 16.7329s	
9517/33650 (epoch 14.141), train_loss = 1.25513593, grad/param norm = 1.5567e-01, time/batch = 16.4870s	
9518/33650 (epoch 14.143), train_loss = 1.35142377, grad/param norm = 1.8181e-01, time/batch = 17.9003s	
9519/33650 (epoch 14.144), train_loss = 1.18304025, grad/param norm = 1.4777e-01, time/batch = 15.8037s	
9520/33650 (epoch 14.146), train_loss = 1.08210477, grad/param norm = 1.4640e-01, time/batch = 16.3960s	
9521/33650 (epoch 14.147), train_loss = 1.04763784, grad/param norm = 1.4418e-01, time/batch = 18.1524s	
9522/33650 (epoch 14.149), train_loss = 1.03265961, grad/param norm = 1.5166e-01, time/batch = 17.2363s	
9523/33650 (epoch 14.150), train_loss = 0.97493564, grad/param norm = 1.3651e-01, time/batch = 15.6407s	
9524/33650 (epoch 14.152), train_loss = 1.05467084, grad/param norm = 1.3374e-01, time/batch = 16.9722s	
9525/33650 (epoch 14.153), train_loss = 1.05291611, grad/param norm = 1.3941e-01, time/batch = 17.6544s	
9526/33650 (epoch 14.155), train_loss = 1.03096480, grad/param norm = 1.2822e-01, time/batch = 16.3071s	
9527/33650 (epoch 14.156), train_loss = 1.00719960, grad/param norm = 1.2139e-01, time/batch = 17.0532s	
9528/33650 (epoch 14.158), train_loss = 1.11400488, grad/param norm = 1.5110e-01, time/batch = 17.4002s	
9529/33650 (epoch 14.159), train_loss = 0.98832512, grad/param norm = 1.1505e-01, time/batch = 17.2325s	
9530/33650 (epoch 14.160), train_loss = 1.02364723, grad/param norm = 1.2212e-01, time/batch = 17.2464s	
9531/33650 (epoch 14.162), train_loss = 1.10243902, grad/param norm = 1.6937e-01, time/batch = 17.0602s	
9532/33650 (epoch 14.163), train_loss = 1.15956884, grad/param norm = 1.4713e-01, time/batch = 16.8936s	
9533/33650 (epoch 14.165), train_loss = 1.00755790, grad/param norm = 1.4371e-01, time/batch = 15.8006s	
9534/33650 (epoch 14.166), train_loss = 0.98829813, grad/param norm = 1.3534e-01, time/batch = 16.6488s	
9535/33650 (epoch 14.168), train_loss = 1.17408358, grad/param norm = 1.4340e-01, time/batch = 16.7364s	
9536/33650 (epoch 14.169), train_loss = 1.10167055, grad/param norm = 1.4546e-01, time/batch = 17.7379s	
9537/33650 (epoch 14.171), train_loss = 1.09439550, grad/param norm = 1.4276e-01, time/batch = 17.0720s	
9538/33650 (epoch 14.172), train_loss = 1.07281197, grad/param norm = 1.4959e-01, time/batch = 16.2782s	
9539/33650 (epoch 14.174), train_loss = 1.00423187, grad/param norm = 1.5205e-01, time/batch = 17.6567s	
9540/33650 (epoch 14.175), train_loss = 1.03738868, grad/param norm = 1.6163e-01, time/batch = 16.9021s	
9541/33650 (epoch 14.177), train_loss = 1.11868497, grad/param norm = 1.4067e-01, time/batch = 16.6417s	
9542/33650 (epoch 14.178), train_loss = 1.00784624, grad/param norm = 1.4925e-01, time/batch = 17.5698s	
9543/33650 (epoch 14.180), train_loss = 0.96202082, grad/param norm = 1.2571e-01, time/batch = 17.2359s	
9544/33650 (epoch 14.181), train_loss = 0.88704452, grad/param norm = 1.3651e-01, time/batch = 17.3333s	
9545/33650 (epoch 14.183), train_loss = 1.05343750, grad/param norm = 1.4756e-01, time/batch = 17.8957s	
9546/33650 (epoch 14.184), train_loss = 1.04221081, grad/param norm = 1.5703e-01, time/batch = 16.0654s	
9547/33650 (epoch 14.186), train_loss = 1.05485518, grad/param norm = 1.6634e-01, time/batch = 17.2394s	
9548/33650 (epoch 14.187), train_loss = 1.27054621, grad/param norm = 1.4202e-01, time/batch = 15.6352s	
9549/33650 (epoch 14.189), train_loss = 1.26362076, grad/param norm = 1.7093e-01, time/batch = 16.7106s	
9550/33650 (epoch 14.190), train_loss = 1.12389744, grad/param norm = 1.5418e-01, time/batch = 16.8130s	
9551/33650 (epoch 14.192), train_loss = 1.27340820, grad/param norm = 1.6268e-01, time/batch = 17.5763s	
9552/33650 (epoch 14.193), train_loss = 1.22159713, grad/param norm = 1.4453e-01, time/batch = 17.2119s	
9553/33650 (epoch 14.195), train_loss = 0.98351437, grad/param norm = 1.4014e-01, time/batch = 17.9076s	
9554/33650 (epoch 14.196), train_loss = 0.93449913, grad/param norm = 1.5299e-01, time/batch = 16.9781s	
9555/33650 (epoch 14.198), train_loss = 1.07036751, grad/param norm = 1.5621e-01, time/batch = 16.1283s	
9556/33650 (epoch 14.199), train_loss = 1.20219173, grad/param norm = 1.5166e-01, time/batch = 17.5019s	
9557/33650 (epoch 14.201), train_loss = 1.05368838, grad/param norm = 1.4863e-01, time/batch = 16.9797s	
9558/33650 (epoch 14.202), train_loss = 1.05962756, grad/param norm = 1.4377e-01, time/batch = 16.9975s	
9559/33650 (epoch 14.204), train_loss = 1.14070843, grad/param norm = 1.3858e-01, time/batch = 10.2705s	
9560/33650 (epoch 14.205), train_loss = 1.07425605, grad/param norm = 1.4399e-01, time/batch = 0.6306s	
9561/33650 (epoch 14.207), train_loss = 1.04953401, grad/param norm = 1.5001e-01, time/batch = 0.6287s	
9562/33650 (epoch 14.208), train_loss = 1.07452388, grad/param norm = 1.4506e-01, time/batch = 0.6311s	
9563/33650 (epoch 14.210), train_loss = 0.86624845, grad/param norm = 1.2733e-01, time/batch = 0.6329s	
9564/33650 (epoch 14.211), train_loss = 0.99710417, grad/param norm = 1.3226e-01, time/batch = 0.6297s	
9565/33650 (epoch 14.212), train_loss = 1.19282947, grad/param norm = 1.6450e-01, time/batch = 0.6676s	
9566/33650 (epoch 14.214), train_loss = 1.25389644, grad/param norm = 1.4508e-01, time/batch = 0.6448s	
9567/33650 (epoch 14.215), train_loss = 0.87341375, grad/param norm = 1.2988e-01, time/batch = 0.7960s	
9568/33650 (epoch 14.217), train_loss = 1.10909964, grad/param norm = 1.6893e-01, time/batch = 0.9200s	
9569/33650 (epoch 14.218), train_loss = 1.13926878, grad/param norm = 1.4449e-01, time/batch = 0.9237s	
9570/33650 (epoch 14.220), train_loss = 0.97055370, grad/param norm = 1.3181e-01, time/batch = 0.9311s	
9571/33650 (epoch 14.221), train_loss = 1.23018516, grad/param norm = 1.6494e-01, time/batch = 0.9326s	
9572/33650 (epoch 14.223), train_loss = 0.84793530, grad/param norm = 1.2942e-01, time/batch = 1.0923s	
9573/33650 (epoch 14.224), train_loss = 1.06359775, grad/param norm = 1.6694e-01, time/batch = 1.7306s	
9574/33650 (epoch 14.226), train_loss = 1.39864847, grad/param norm = 1.6251e-01, time/batch = 1.7316s	
9575/33650 (epoch 14.227), train_loss = 1.24078395, grad/param norm = 1.6095e-01, time/batch = 7.1731s	
9576/33650 (epoch 14.229), train_loss = 1.24523840, grad/param norm = 1.6228e-01, time/batch = 15.5614s	
9577/33650 (epoch 14.230), train_loss = 1.33912563, grad/param norm = 1.6549e-01, time/batch = 16.9860s	
9578/33650 (epoch 14.232), train_loss = 1.13556308, grad/param norm = 1.4229e-01, time/batch = 16.4686s	
9579/33650 (epoch 14.233), train_loss = 1.15383939, grad/param norm = 1.5496e-01, time/batch = 16.4701s	
9580/33650 (epoch 14.235), train_loss = 1.06789331, grad/param norm = 1.2950e-01, time/batch = 17.4003s	
9581/33650 (epoch 14.236), train_loss = 0.94951473, grad/param norm = 1.3746e-01, time/batch = 16.2346s	
9582/33650 (epoch 14.238), train_loss = 1.04649650, grad/param norm = 1.3481e-01, time/batch = 17.1664s	
9583/33650 (epoch 14.239), train_loss = 1.00478291, grad/param norm = 1.4454e-01, time/batch = 17.9880s	
9584/33650 (epoch 14.241), train_loss = 1.02614755, grad/param norm = 1.2517e-01, time/batch = 17.0560s	
9585/33650 (epoch 14.242), train_loss = 0.89559701, grad/param norm = 1.2820e-01, time/batch = 17.3995s	
9586/33650 (epoch 14.244), train_loss = 1.07931041, grad/param norm = 1.4272e-01, time/batch = 16.4039s	
9587/33650 (epoch 14.245), train_loss = 0.94634818, grad/param norm = 1.3871e-01, time/batch = 17.2395s	
9588/33650 (epoch 14.247), train_loss = 1.07972749, grad/param norm = 1.3687e-01, time/batch = 16.6577s	
9589/33650 (epoch 14.248), train_loss = 0.95755834, grad/param norm = 1.3257e-01, time/batch = 17.4981s	
9590/33650 (epoch 14.250), train_loss = 1.05140115, grad/param norm = 1.2844e-01, time/batch = 17.3230s	
9591/33650 (epoch 14.251), train_loss = 1.24310018, grad/param norm = 1.5375e-01, time/batch = 17.3857s	
9592/33650 (epoch 14.253), train_loss = 0.98543091, grad/param norm = 1.2772e-01, time/batch = 17.0660s	
9593/33650 (epoch 14.254), train_loss = 0.99518577, grad/param norm = 1.3778e-01, time/batch = 17.6524s	
9594/33650 (epoch 14.256), train_loss = 1.22339578, grad/param norm = 1.4161e-01, time/batch = 18.1455s	
9595/33650 (epoch 14.257), train_loss = 1.23062033, grad/param norm = 1.4756e-01, time/batch = 16.5560s	
9596/33650 (epoch 14.259), train_loss = 0.95960878, grad/param norm = 1.4373e-01, time/batch = 16.3051s	
9597/33650 (epoch 14.260), train_loss = 1.20962230, grad/param norm = 1.5356e-01, time/batch = 16.0570s	
9598/33650 (epoch 14.262), train_loss = 1.13926822, grad/param norm = 1.4692e-01, time/batch = 17.1385s	
9599/33650 (epoch 14.263), train_loss = 1.06064716, grad/param norm = 1.6964e-01, time/batch = 17.6417s	
9600/33650 (epoch 14.264), train_loss = 1.13419827, grad/param norm = 1.5039e-01, time/batch = 17.3859s	
9601/33650 (epoch 14.266), train_loss = 1.09801236, grad/param norm = 1.3570e-01, time/batch = 17.9779s	
9602/33650 (epoch 14.267), train_loss = 1.00487539, grad/param norm = 1.4765e-01, time/batch = 17.0639s	
9603/33650 (epoch 14.269), train_loss = 1.13304944, grad/param norm = 1.5473e-01, time/batch = 17.0626s	
9604/33650 (epoch 14.270), train_loss = 1.02322379, grad/param norm = 1.3023e-01, time/batch = 16.7308s	
9605/33650 (epoch 14.272), train_loss = 1.05638255, grad/param norm = 1.3421e-01, time/batch = 16.3144s	
9606/33650 (epoch 14.273), train_loss = 1.21803038, grad/param norm = 1.6244e-01, time/batch = 17.7220s	
9607/33650 (epoch 14.275), train_loss = 1.18951416, grad/param norm = 1.5983e-01, time/batch = 18.0639s	
9608/33650 (epoch 14.276), train_loss = 1.26477597, grad/param norm = 1.8727e-01, time/batch = 17.5712s	
9609/33650 (epoch 14.278), train_loss = 1.31418022, grad/param norm = 1.7358e-01, time/batch = 16.3897s	
9610/33650 (epoch 14.279), train_loss = 1.03167462, grad/param norm = 1.4296e-01, time/batch = 17.6506s	
9611/33650 (epoch 14.281), train_loss = 1.12952625, grad/param norm = 1.5239e-01, time/batch = 17.3219s	
9612/33650 (epoch 14.282), train_loss = 1.21520577, grad/param norm = 1.3754e-01, time/batch = 17.2312s	
9613/33650 (epoch 14.284), train_loss = 1.19396757, grad/param norm = 1.5490e-01, time/batch = 17.5543s	
9614/33650 (epoch 14.285), train_loss = 1.20957906, grad/param norm = 1.5674e-01, time/batch = 17.3197s	
9615/33650 (epoch 14.287), train_loss = 1.08456176, grad/param norm = 1.3739e-01, time/batch = 17.3184s	
9616/33650 (epoch 14.288), train_loss = 1.14821414, grad/param norm = 1.6461e-01, time/batch = 15.6262s	
9617/33650 (epoch 14.290), train_loss = 1.11344327, grad/param norm = 1.3203e-01, time/batch = 17.0584s	
9618/33650 (epoch 14.291), train_loss = 1.00900630, grad/param norm = 1.2677e-01, time/batch = 17.4055s	
9619/33650 (epoch 14.293), train_loss = 1.10908628, grad/param norm = 1.6276e-01, time/batch = 16.4833s	
9620/33650 (epoch 14.294), train_loss = 0.99531136, grad/param norm = 1.4031e-01, time/batch = 16.8987s	
9621/33650 (epoch 14.296), train_loss = 0.99185478, grad/param norm = 1.4694e-01, time/batch = 17.3991s	
9622/33650 (epoch 14.297), train_loss = 1.07325905, grad/param norm = 1.3765e-01, time/batch = 16.8827s	
9623/33650 (epoch 14.299), train_loss = 0.97641355, grad/param norm = 1.2482e-01, time/batch = 16.4834s	
9624/33650 (epoch 14.300), train_loss = 0.99957424, grad/param norm = 1.5179e-01, time/batch = 17.9934s	
9625/33650 (epoch 14.302), train_loss = 1.12065106, grad/param norm = 1.3567e-01, time/batch = 14.7281s	
9626/33650 (epoch 14.303), train_loss = 1.11108167, grad/param norm = 1.4123e-01, time/batch = 17.0653s	
9627/33650 (epoch 14.305), train_loss = 1.14051425, grad/param norm = 1.4536e-01, time/batch = 17.3195s	
9628/33650 (epoch 14.306), train_loss = 1.04014308, grad/param norm = 1.3454e-01, time/batch = 17.4080s	
9629/33650 (epoch 14.308), train_loss = 0.99161738, grad/param norm = 1.6183e-01, time/batch = 18.2442s	
9630/33650 (epoch 14.309), train_loss = 1.29264328, grad/param norm = 1.8922e-01, time/batch = 16.5608s	
9631/33650 (epoch 14.311), train_loss = 1.15358239, grad/param norm = 1.5174e-01, time/batch = 17.1420s	
9632/33650 (epoch 14.312), train_loss = 1.10824960, grad/param norm = 1.5146e-01, time/batch = 17.7353s	
9633/33650 (epoch 14.314), train_loss = 0.92866373, grad/param norm = 1.1722e-01, time/batch = 15.9549s	
9634/33650 (epoch 14.315), train_loss = 1.09283465, grad/param norm = 1.6361e-01, time/batch = 17.3958s	
9635/33650 (epoch 14.316), train_loss = 1.02551690, grad/param norm = 1.4471e-01, time/batch = 16.7313s	
9636/33650 (epoch 14.318), train_loss = 0.98551804, grad/param norm = 1.2675e-01, time/batch = 18.3149s	
9637/33650 (epoch 14.319), train_loss = 0.98974322, grad/param norm = 1.2485e-01, time/batch = 15.3062s	
9638/33650 (epoch 14.321), train_loss = 1.03956480, grad/param norm = 1.3985e-01, time/batch = 17.3277s	
9639/33650 (epoch 14.322), train_loss = 1.15424108, grad/param norm = 1.5638e-01, time/batch = 17.0758s	
9640/33650 (epoch 14.324), train_loss = 1.15844618, grad/param norm = 2.0528e-01, time/batch = 16.7919s	
9641/33650 (epoch 14.325), train_loss = 1.16495308, grad/param norm = 1.5006e-01, time/batch = 15.7258s	
9642/33650 (epoch 14.327), train_loss = 0.97744569, grad/param norm = 1.2638e-01, time/batch = 17.7343s	
9643/33650 (epoch 14.328), train_loss = 1.16065451, grad/param norm = 1.5552e-01, time/batch = 17.6509s	
9644/33650 (epoch 14.330), train_loss = 1.00118968, grad/param norm = 1.2521e-01, time/batch = 28.4220s	
9645/33650 (epoch 14.331), train_loss = 0.90314168, grad/param norm = 1.1375e-01, time/batch = 19.9770s	
9646/33650 (epoch 14.333), train_loss = 1.05254423, grad/param norm = 1.3887e-01, time/batch = 17.0720s	
9647/33650 (epoch 14.334), train_loss = 1.05686080, grad/param norm = 1.3059e-01, time/batch = 16.8783s	
9648/33650 (epoch 14.336), train_loss = 1.21828067, grad/param norm = 1.5101e-01, time/batch = 17.0694s	
9649/33650 (epoch 14.337), train_loss = 0.87193790, grad/param norm = 1.1702e-01, time/batch = 17.5835s	
9650/33650 (epoch 14.339), train_loss = 1.05724589, grad/param norm = 1.3038e-01, time/batch = 15.1387s	
9651/33650 (epoch 14.340), train_loss = 1.28479843, grad/param norm = 1.6923e-01, time/batch = 16.5748s	
9652/33650 (epoch 14.342), train_loss = 0.90975614, grad/param norm = 1.2897e-01, time/batch = 17.6507s	
9653/33650 (epoch 14.343), train_loss = 1.15805918, grad/param norm = 1.4376e-01, time/batch = 17.5680s	
9654/33650 (epoch 14.345), train_loss = 1.06876902, grad/param norm = 1.4847e-01, time/batch = 16.8124s	
9655/33650 (epoch 14.346), train_loss = 0.76439343, grad/param norm = 1.1885e-01, time/batch = 16.5412s	
9656/33650 (epoch 14.348), train_loss = 0.96060887, grad/param norm = 1.2562e-01, time/batch = 17.6513s	
9657/33650 (epoch 14.349), train_loss = 0.91344845, grad/param norm = 1.4518e-01, time/batch = 16.0528s	
9658/33650 (epoch 14.351), train_loss = 1.16142644, grad/param norm = 1.3769e-01, time/batch = 17.4019s	
9659/33650 (epoch 14.352), train_loss = 1.06838393, grad/param norm = 1.3948e-01, time/batch = 17.6530s	
9660/33650 (epoch 14.354), train_loss = 1.29680409, grad/param norm = 1.6011e-01, time/batch = 17.9850s	
9661/33650 (epoch 14.355), train_loss = 1.18975738, grad/param norm = 1.3611e-01, time/batch = 16.6377s	
9662/33650 (epoch 14.357), train_loss = 0.88206504, grad/param norm = 1.2933e-01, time/batch = 17.8219s	
9663/33650 (epoch 14.358), train_loss = 1.17666727, grad/param norm = 1.5575e-01, time/batch = 17.6520s	
9664/33650 (epoch 14.360), train_loss = 1.17490258, grad/param norm = 1.6485e-01, time/batch = 15.3766s	
9665/33650 (epoch 14.361), train_loss = 1.13282880, grad/param norm = 1.4354e-01, time/batch = 17.1526s	
9666/33650 (epoch 14.363), train_loss = 1.02846507, grad/param norm = 1.3722e-01, time/batch = 16.4838s	
9667/33650 (epoch 14.364), train_loss = 1.03070880, grad/param norm = 1.3366e-01, time/batch = 17.9842s	
9668/33650 (epoch 14.366), train_loss = 1.12622568, grad/param norm = 1.4827e-01, time/batch = 16.2200s	
9669/33650 (epoch 14.367), train_loss = 1.16294957, grad/param norm = 1.4184e-01, time/batch = 16.9824s	
9670/33650 (epoch 14.368), train_loss = 0.98473791, grad/param norm = 1.3178e-01, time/batch = 16.3776s	
9671/33650 (epoch 14.370), train_loss = 1.09320697, grad/param norm = 1.3903e-01, time/batch = 16.5488s	
9672/33650 (epoch 14.371), train_loss = 0.86746190, grad/param norm = 1.2025e-01, time/batch = 16.7384s	
9673/33650 (epoch 14.373), train_loss = 0.98689283, grad/param norm = 1.2519e-01, time/batch = 18.3192s	
9674/33650 (epoch 14.374), train_loss = 0.93733048, grad/param norm = 1.1797e-01, time/batch = 17.4135s	
9675/33650 (epoch 14.376), train_loss = 1.08601942, grad/param norm = 1.6019e-01, time/batch = 16.8910s	
9676/33650 (epoch 14.377), train_loss = 1.12229785, grad/param norm = 1.5245e-01, time/batch = 16.7219s	
9677/33650 (epoch 14.379), train_loss = 1.15343606, grad/param norm = 1.3824e-01, time/batch = 17.8286s	
9678/33650 (epoch 14.380), train_loss = 0.86239966, grad/param norm = 1.3106e-01, time/batch = 15.8927s	
9679/33650 (epoch 14.382), train_loss = 0.95687398, grad/param norm = 1.1575e-01, time/batch = 17.1641s	
9680/33650 (epoch 14.383), train_loss = 1.04920353, grad/param norm = 1.3705e-01, time/batch = 15.4847s	
9681/33650 (epoch 14.385), train_loss = 1.23327989, grad/param norm = 1.4721e-01, time/batch = 17.6389s	
9682/33650 (epoch 14.386), train_loss = 0.98871601, grad/param norm = 1.2594e-01, time/batch = 17.4770s	
9683/33650 (epoch 14.388), train_loss = 1.11231180, grad/param norm = 1.4159e-01, time/batch = 15.0406s	
9684/33650 (epoch 14.389), train_loss = 1.07690245, grad/param norm = 1.5514e-01, time/batch = 16.3233s	
9685/33650 (epoch 14.391), train_loss = 0.88549676, grad/param norm = 1.2752e-01, time/batch = 16.2335s	
9686/33650 (epoch 14.392), train_loss = 1.14260690, grad/param norm = 1.4324e-01, time/batch = 16.5692s	
9687/33650 (epoch 14.394), train_loss = 1.15310904, grad/param norm = 1.5634e-01, time/batch = 17.9022s	
9688/33650 (epoch 14.395), train_loss = 1.10756253, grad/param norm = 1.3882e-01, time/batch = 17.3231s	
9689/33650 (epoch 14.397), train_loss = 1.24178105, grad/param norm = 1.4383e-01, time/batch = 15.9832s	
9690/33650 (epoch 14.398), train_loss = 1.11379120, grad/param norm = 1.4035e-01, time/batch = 17.5664s	
9691/33650 (epoch 14.400), train_loss = 1.09236824, grad/param norm = 1.6318e-01, time/batch = 17.2078s	
9692/33650 (epoch 14.401), train_loss = 1.08913852, grad/param norm = 1.6069e-01, time/batch = 16.3888s	
9693/33650 (epoch 14.403), train_loss = 1.13749374, grad/param norm = 1.5454e-01, time/batch = 17.7312s	
9694/33650 (epoch 14.404), train_loss = 1.06767977, grad/param norm = 1.3045e-01, time/batch = 17.9965s	
9695/33650 (epoch 14.406), train_loss = 1.11918360, grad/param norm = 1.3909e-01, time/batch = 17.0745s	
9696/33650 (epoch 14.407), train_loss = 1.10958405, grad/param norm = 1.5184e-01, time/batch = 15.6436s	
9697/33650 (epoch 14.409), train_loss = 1.09195663, grad/param norm = 1.3707e-01, time/batch = 17.3183s	
9698/33650 (epoch 14.410), train_loss = 1.07856487, grad/param norm = 1.4859e-01, time/batch = 17.8205s	
9699/33650 (epoch 14.412), train_loss = 1.08988933, grad/param norm = 1.2430e-01, time/batch = 15.6390s	
9700/33650 (epoch 14.413), train_loss = 1.00281873, grad/param norm = 1.3345e-01, time/batch = 17.3177s	
9701/33650 (epoch 14.415), train_loss = 1.15369331, grad/param norm = 1.4286e-01, time/batch = 15.4714s	
9702/33650 (epoch 14.416), train_loss = 1.26249527, grad/param norm = 1.6082e-01, time/batch = 16.8926s	
9703/33650 (epoch 14.418), train_loss = 1.07339820, grad/param norm = 1.3977e-01, time/batch = 16.3998s	
9704/33650 (epoch 14.419), train_loss = 1.04133801, grad/param norm = 1.5112e-01, time/batch = 17.5721s	
9705/33650 (epoch 14.421), train_loss = 1.04507142, grad/param norm = 1.2384e-01, time/batch = 16.9883s	
9706/33650 (epoch 14.422), train_loss = 1.17412317, grad/param norm = 1.4043e-01, time/batch = 16.7434s	
9707/33650 (epoch 14.423), train_loss = 0.96043877, grad/param norm = 1.1761e-01, time/batch = 16.5587s	
9708/33650 (epoch 14.425), train_loss = 1.10578040, grad/param norm = 1.4508e-01, time/batch = 17.8159s	
9709/33650 (epoch 14.426), train_loss = 1.24232093, grad/param norm = 1.6953e-01, time/batch = 17.3253s	
9710/33650 (epoch 14.428), train_loss = 1.02441747, grad/param norm = 1.3936e-01, time/batch = 16.3088s	
9711/33650 (epoch 14.429), train_loss = 1.18257099, grad/param norm = 1.5114e-01, time/batch = 17.3152s	
9712/33650 (epoch 14.431), train_loss = 1.29369014, grad/param norm = 1.7057e-01, time/batch = 16.9753s	
9713/33650 (epoch 14.432), train_loss = 1.33153340, grad/param norm = 1.6022e-01, time/batch = 17.4746s	
9714/33650 (epoch 14.434), train_loss = 1.15127134, grad/param norm = 1.4315e-01, time/batch = 17.2232s	
9715/33650 (epoch 14.435), train_loss = 1.11628506, grad/param norm = 1.6060e-01, time/batch = 17.3075s	
9716/33650 (epoch 14.437), train_loss = 1.12002454, grad/param norm = 1.4976e-01, time/batch = 16.8330s	
9717/33650 (epoch 14.438), train_loss = 1.01957134, grad/param norm = 1.6826e-01, time/batch = 16.4032s	
9718/33650 (epoch 14.440), train_loss = 1.11720691, grad/param norm = 1.5162e-01, time/batch = 17.3241s	
9719/33650 (epoch 14.441), train_loss = 1.13093111, grad/param norm = 1.5447e-01, time/batch = 17.5662s	
9720/33650 (epoch 14.443), train_loss = 1.14526207, grad/param norm = 1.3482e-01, time/batch = 16.8199s	
9721/33650 (epoch 14.444), train_loss = 1.03810759, grad/param norm = 1.2341e-01, time/batch = 17.4805s	
9722/33650 (epoch 14.446), train_loss = 1.14907376, grad/param norm = 1.6554e-01, time/batch = 16.9929s	
9723/33650 (epoch 14.447), train_loss = 1.19849473, grad/param norm = 1.5711e-01, time/batch = 16.2109s	
9724/33650 (epoch 14.449), train_loss = 1.25907590, grad/param norm = 1.8107e-01, time/batch = 16.6614s	
9725/33650 (epoch 14.450), train_loss = 1.29848095, grad/param norm = 1.6434e-01, time/batch = 17.0613s	
9726/33650 (epoch 14.452), train_loss = 1.34406095, grad/param norm = 1.6474e-01, time/batch = 15.3947s	
9727/33650 (epoch 14.453), train_loss = 1.29139752, grad/param norm = 1.8251e-01, time/batch = 16.0659s	
9728/33650 (epoch 14.455), train_loss = 1.07971606, grad/param norm = 1.4322e-01, time/batch = 17.2180s	
9729/33650 (epoch 14.456), train_loss = 1.09165617, grad/param norm = 1.3116e-01, time/batch = 17.0743s	
9730/33650 (epoch 14.458), train_loss = 1.08100945, grad/param norm = 1.7296e-01, time/batch = 17.2449s	
9731/33650 (epoch 14.459), train_loss = 1.12460677, grad/param norm = 1.6212e-01, time/batch = 16.8996s	
9732/33650 (epoch 14.461), train_loss = 1.29847535, grad/param norm = 1.6551e-01, time/batch = 17.0712s	
9733/33650 (epoch 14.462), train_loss = 1.24738727, grad/param norm = 1.5675e-01, time/batch = 17.7343s	
9734/33650 (epoch 14.464), train_loss = 1.04251320, grad/param norm = 1.4694e-01, time/batch = 17.4753s	
9735/33650 (epoch 14.465), train_loss = 1.13802211, grad/param norm = 1.5616e-01, time/batch = 15.8138s	
9736/33650 (epoch 14.467), train_loss = 1.15672098, grad/param norm = 1.4907e-01, time/batch = 16.4699s	
9737/33650 (epoch 14.468), train_loss = 1.21893882, grad/param norm = 1.5413e-01, time/batch = 18.0690s	
9738/33650 (epoch 14.470), train_loss = 1.35996813, grad/param norm = 1.7421e-01, time/batch = 15.8792s	
9739/33650 (epoch 14.471), train_loss = 1.11653577, grad/param norm = 1.5281e-01, time/batch = 17.5544s	
9740/33650 (epoch 14.473), train_loss = 1.06134489, grad/param norm = 1.3877e-01, time/batch = 17.6487s	
9741/33650 (epoch 14.474), train_loss = 1.17510493, grad/param norm = 1.3977e-01, time/batch = 17.8102s	
9742/33650 (epoch 14.475), train_loss = 1.18693087, grad/param norm = 1.4731e-01, time/batch = 15.1228s	
9743/33650 (epoch 14.477), train_loss = 1.22855560, grad/param norm = 1.4654e-01, time/batch = 17.7341s	
9744/33650 (epoch 14.478), train_loss = 1.23657571, grad/param norm = 1.6169e-01, time/batch = 17.4065s	
9745/33650 (epoch 14.480), train_loss = 1.20561010, grad/param norm = 1.6225e-01, time/batch = 16.6541s	
9746/33650 (epoch 14.481), train_loss = 1.27853402, grad/param norm = 1.5729e-01, time/batch = 17.3988s	
9747/33650 (epoch 14.483), train_loss = 0.90952892, grad/param norm = 1.3597e-01, time/batch = 17.8964s	
9748/33650 (epoch 14.484), train_loss = 1.10081354, grad/param norm = 1.3834e-01, time/batch = 17.6434s	
9749/33650 (epoch 14.486), train_loss = 1.24703227, grad/param norm = 1.6722e-01, time/batch = 16.9650s	
9750/33650 (epoch 14.487), train_loss = 1.26105954, grad/param norm = 1.7155e-01, time/batch = 17.2230s	
9751/33650 (epoch 14.489), train_loss = 1.29265672, grad/param norm = 1.4923e-01, time/batch = 18.3198s	
9752/33650 (epoch 14.490), train_loss = 1.02447841, grad/param norm = 1.4411e-01, time/batch = 17.3922s	
9753/33650 (epoch 14.492), train_loss = 1.13904598, grad/param norm = 1.5336e-01, time/batch = 17.3215s	
9754/33650 (epoch 14.493), train_loss = 0.92811142, grad/param norm = 1.2892e-01, time/batch = 17.8030s	
9755/33650 (epoch 14.495), train_loss = 1.12717948, grad/param norm = 1.4282e-01, time/batch = 16.4929s	
9756/33650 (epoch 14.496), train_loss = 1.18093997, grad/param norm = 1.4518e-01, time/batch = 17.5614s	
9757/33650 (epoch 14.498), train_loss = 0.98802108, grad/param norm = 1.3143e-01, time/batch = 16.8297s	
9758/33650 (epoch 14.499), train_loss = 1.08270681, grad/param norm = 1.2258e-01, time/batch = 15.1899s	
9759/33650 (epoch 14.501), train_loss = 1.07925505, grad/param norm = 1.3096e-01, time/batch = 15.5160s	
9760/33650 (epoch 14.502), train_loss = 1.12311566, grad/param norm = 1.5392e-01, time/batch = 14.6772s	
9761/33650 (epoch 14.504), train_loss = 1.22882718, grad/param norm = 1.6111e-01, time/batch = 14.9855s	
9762/33650 (epoch 14.505), train_loss = 1.08292446, grad/param norm = 1.6096e-01, time/batch = 15.3269s	
9763/33650 (epoch 14.507), train_loss = 1.24103851, grad/param norm = 1.4847e-01, time/batch = 15.0576s	
9764/33650 (epoch 14.508), train_loss = 1.05902357, grad/param norm = 1.3570e-01, time/batch = 14.0086s	
9765/33650 (epoch 14.510), train_loss = 1.10879116, grad/param norm = 1.4446e-01, time/batch = 14.0938s	
9766/33650 (epoch 14.511), train_loss = 1.35503236, grad/param norm = 1.7335e-01, time/batch = 14.0225s	
9767/33650 (epoch 14.513), train_loss = 1.18530348, grad/param norm = 1.5052e-01, time/batch = 14.5728s	
9768/33650 (epoch 14.514), train_loss = 1.22098628, grad/param norm = 1.5896e-01, time/batch = 14.2397s	
9769/33650 (epoch 14.516), train_loss = 1.12551127, grad/param norm = 1.4196e-01, time/batch = 14.0948s	
9770/33650 (epoch 14.517), train_loss = 1.13625691, grad/param norm = 1.5252e-01, time/batch = 14.0942s	
9771/33650 (epoch 14.519), train_loss = 1.16717479, grad/param norm = 1.5262e-01, time/batch = 14.2569s	
9772/33650 (epoch 14.520), train_loss = 0.97192743, grad/param norm = 1.3399e-01, time/batch = 14.2625s	
9773/33650 (epoch 14.522), train_loss = 1.11873026, grad/param norm = 1.5609e-01, time/batch = 14.5764s	
9774/33650 (epoch 14.523), train_loss = 1.09075920, grad/param norm = 1.4189e-01, time/batch = 13.7633s	
9775/33650 (epoch 14.525), train_loss = 0.88275899, grad/param norm = 1.2413e-01, time/batch = 13.8597s	
9776/33650 (epoch 14.526), train_loss = 1.19613043, grad/param norm = 1.3803e-01, time/batch = 14.5660s	
9777/33650 (epoch 14.527), train_loss = 1.03859963, grad/param norm = 1.3899e-01, time/batch = 14.3231s	
9778/33650 (epoch 14.529), train_loss = 1.10965941, grad/param norm = 1.4493e-01, time/batch = 14.1817s	
9779/33650 (epoch 14.530), train_loss = 1.05895313, grad/param norm = 1.3725e-01, time/batch = 13.9445s	
9780/33650 (epoch 14.532), train_loss = 1.27128365, grad/param norm = 1.7705e-01, time/batch = 14.4857s	
9781/33650 (epoch 14.533), train_loss = 1.08006252, grad/param norm = 1.5428e-01, time/batch = 14.0233s	
9782/33650 (epoch 14.535), train_loss = 1.21109525, grad/param norm = 1.5854e-01, time/batch = 14.3454s	
9783/33650 (epoch 14.536), train_loss = 1.14149762, grad/param norm = 1.5469e-01, time/batch = 14.5718s	
9784/33650 (epoch 14.538), train_loss = 1.17210682, grad/param norm = 1.5748e-01, time/batch = 14.5566s	
9785/33650 (epoch 14.539), train_loss = 0.91011829, grad/param norm = 1.2899e-01, time/batch = 14.5522s	
9786/33650 (epoch 14.541), train_loss = 1.24197217, grad/param norm = 1.5478e-01, time/batch = 14.0193s	
9787/33650 (epoch 14.542), train_loss = 1.16664544, grad/param norm = 1.6088e-01, time/batch = 13.8491s	
9788/33650 (epoch 14.544), train_loss = 1.32452254, grad/param norm = 1.6542e-01, time/batch = 14.4117s	
9789/33650 (epoch 14.545), train_loss = 0.98570899, grad/param norm = 1.2887e-01, time/batch = 14.0998s	
9790/33650 (epoch 14.547), train_loss = 1.13872592, grad/param norm = 1.4828e-01, time/batch = 14.0243s	
9791/33650 (epoch 14.548), train_loss = 1.30548782, grad/param norm = 1.5525e-01, time/batch = 14.3133s	
9792/33650 (epoch 14.550), train_loss = 1.09170273, grad/param norm = 1.4006e-01, time/batch = 14.1780s	
9793/33650 (epoch 14.551), train_loss = 1.13632005, grad/param norm = 1.5352e-01, time/batch = 14.0944s	
9794/33650 (epoch 14.553), train_loss = 0.99544070, grad/param norm = 1.5411e-01, time/batch = 14.2623s	
9795/33650 (epoch 14.554), train_loss = 1.24733710, grad/param norm = 1.5288e-01, time/batch = 14.0936s	
9796/33650 (epoch 14.556), train_loss = 1.20849303, grad/param norm = 1.6524e-01, time/batch = 13.8544s	
9797/33650 (epoch 14.557), train_loss = 1.24588082, grad/param norm = 1.5877e-01, time/batch = 14.4887s	
9798/33650 (epoch 14.559), train_loss = 1.41042189, grad/param norm = 1.8643e-01, time/batch = 13.9401s	
9799/33650 (epoch 14.560), train_loss = 1.32889436, grad/param norm = 1.5304e-01, time/batch = 14.1756s	
9800/33650 (epoch 14.562), train_loss = 1.22057360, grad/param norm = 1.4002e-01, time/batch = 13.7732s	
9801/33650 (epoch 14.563), train_loss = 1.13196692, grad/param norm = 1.4429e-01, time/batch = 14.4992s	
9802/33650 (epoch 14.565), train_loss = 1.12722067, grad/param norm = 1.4102e-01, time/batch = 14.5583s	
9803/33650 (epoch 14.566), train_loss = 1.10813552, grad/param norm = 1.4495e-01, time/batch = 13.9409s	
9804/33650 (epoch 14.568), train_loss = 1.14346780, grad/param norm = 1.6176e-01, time/batch = 14.0929s	
9805/33650 (epoch 14.569), train_loss = 1.07186838, grad/param norm = 1.4394e-01, time/batch = 14.7095s	
9806/33650 (epoch 14.571), train_loss = 1.25352054, grad/param norm = 1.5238e-01, time/batch = 14.1884s	
9807/33650 (epoch 14.572), train_loss = 1.17830353, grad/param norm = 1.4176e-01, time/batch = 14.0195s	
9808/33650 (epoch 14.574), train_loss = 1.13021962, grad/param norm = 1.5269e-01, time/batch = 14.0140s	
9809/33650 (epoch 14.575), train_loss = 1.10906252, grad/param norm = 1.5122e-01, time/batch = 14.2556s	
9810/33650 (epoch 14.577), train_loss = 1.11291266, grad/param norm = 1.4720e-01, time/batch = 14.0108s	
9811/33650 (epoch 14.578), train_loss = 1.17676281, grad/param norm = 1.4824e-01, time/batch = 14.2631s	
9812/33650 (epoch 14.579), train_loss = 1.20330022, grad/param norm = 1.6687e-01, time/batch = 14.1787s	
9813/33650 (epoch 14.581), train_loss = 1.23717676, grad/param norm = 1.5676e-01, time/batch = 14.1677s	
9814/33650 (epoch 14.582), train_loss = 1.20401013, grad/param norm = 1.3595e-01, time/batch = 14.1717s	
9815/33650 (epoch 14.584), train_loss = 1.18859122, grad/param norm = 1.5313e-01, time/batch = 14.8071s	
9816/33650 (epoch 14.585), train_loss = 1.20953545, grad/param norm = 2.1635e-01, time/batch = 13.8554s	
9817/33650 (epoch 14.587), train_loss = 1.02847198, grad/param norm = 1.4024e-01, time/batch = 13.8491s	
9818/33650 (epoch 14.588), train_loss = 1.11653350, grad/param norm = 1.7468e-01, time/batch = 14.4140s	
9819/33650 (epoch 14.590), train_loss = 1.09668713, grad/param norm = 1.4483e-01, time/batch = 14.7030s	
9820/33650 (epoch 14.591), train_loss = 1.07333399, grad/param norm = 1.5654e-01, time/batch = 14.1024s	
9821/33650 (epoch 14.593), train_loss = 1.03258317, grad/param norm = 1.3174e-01, time/batch = 14.0171s	
9822/33650 (epoch 14.594), train_loss = 0.98839827, grad/param norm = 1.5463e-01, time/batch = 14.5009s	
9823/33650 (epoch 14.596), train_loss = 1.09327922, grad/param norm = 1.3644e-01, time/batch = 14.2630s	
9824/33650 (epoch 14.597), train_loss = 0.91195236, grad/param norm = 1.1534e-01, time/batch = 14.1078s	
9825/33650 (epoch 14.599), train_loss = 1.07445270, grad/param norm = 1.4787e-01, time/batch = 14.1776s	
9826/33650 (epoch 14.600), train_loss = 1.00445980, grad/param norm = 1.3596e-01, time/batch = 14.5684s	
9827/33650 (epoch 14.602), train_loss = 1.17169770, grad/param norm = 1.4829e-01, time/batch = 14.5686s	
9828/33650 (epoch 14.603), train_loss = 1.04773062, grad/param norm = 1.4375e-01, time/batch = 13.9378s	
9829/33650 (epoch 14.605), train_loss = 1.17683527, grad/param norm = 1.5015e-01, time/batch = 14.1074s	
9830/33650 (epoch 14.606), train_loss = 1.21659037, grad/param norm = 1.5892e-01, time/batch = 14.4132s	
9831/33650 (epoch 14.608), train_loss = 1.04017412, grad/param norm = 1.4875e-01, time/batch = 14.2559s	
9832/33650 (epoch 14.609), train_loss = 1.12581433, grad/param norm = 1.5093e-01, time/batch = 14.1790s	
9833/33650 (epoch 14.611), train_loss = 0.99020666, grad/param norm = 1.3756e-01, time/batch = 14.6019s	
9834/33650 (epoch 14.612), train_loss = 1.10881261, grad/param norm = 1.4331e-01, time/batch = 14.6707s	
9835/33650 (epoch 14.614), train_loss = 1.17185860, grad/param norm = 1.4567e-01, time/batch = 14.5025s	
9836/33650 (epoch 14.615), train_loss = 1.07081697, grad/param norm = 1.2736e-01, time/batch = 14.6773s	
9837/33650 (epoch 14.617), train_loss = 1.00512398, grad/param norm = 1.2289e-01, time/batch = 14.3438s	
9838/33650 (epoch 14.618), train_loss = 1.08860683, grad/param norm = 1.4232e-01, time/batch = 14.9606s	
9839/33650 (epoch 14.620), train_loss = 1.14942865, grad/param norm = 1.6316e-01, time/batch = 14.7485s	
9840/33650 (epoch 14.621), train_loss = 0.99752867, grad/param norm = 1.3031e-01, time/batch = 14.3431s	
9841/33650 (epoch 14.623), train_loss = 1.07961808, grad/param norm = 1.3892e-01, time/batch = 14.5144s	
9842/33650 (epoch 14.624), train_loss = 0.86335164, grad/param norm = 1.3528e-01, time/batch = 14.7477s	
9843/33650 (epoch 14.626), train_loss = 0.86196478, grad/param norm = 1.2450e-01, time/batch = 14.5079s	
9844/33650 (epoch 14.627), train_loss = 1.02399234, grad/param norm = 1.4720e-01, time/batch = 14.6689s	
9845/33650 (epoch 14.629), train_loss = 1.07567018, grad/param norm = 1.4158e-01, time/batch = 14.4945s	
9846/33650 (epoch 14.630), train_loss = 1.19967967, grad/param norm = 1.5981e-01, time/batch = 14.3469s	
9847/33650 (epoch 14.632), train_loss = 1.20838261, grad/param norm = 1.4819e-01, time/batch = 14.7455s	
9848/33650 (epoch 14.633), train_loss = 1.21546518, grad/param norm = 1.4129e-01, time/batch = 14.2736s	
9849/33650 (epoch 14.634), train_loss = 0.93419965, grad/param norm = 1.2938e-01, time/batch = 14.4373s	
9850/33650 (epoch 14.636), train_loss = 0.83228292, grad/param norm = 1.1095e-01, time/batch = 18.0653s	
9851/33650 (epoch 14.637), train_loss = 1.07864869, grad/param norm = 1.4689e-01, time/batch = 14.5844s	
9852/33650 (epoch 14.639), train_loss = 1.04610087, grad/param norm = 1.3950e-01, time/batch = 17.7398s	
9853/33650 (epoch 14.640), train_loss = 1.09948640, grad/param norm = 1.4277e-01, time/batch = 19.0553s	
9854/33650 (epoch 14.642), train_loss = 1.18831707, grad/param norm = 1.5294e-01, time/batch = 17.2122s	
9855/33650 (epoch 14.643), train_loss = 1.10478654, grad/param norm = 1.5971e-01, time/batch = 16.5411s	
9856/33650 (epoch 14.645), train_loss = 1.10482345, grad/param norm = 1.3558e-01, time/batch = 19.2996s	
9857/33650 (epoch 14.646), train_loss = 0.92534624, grad/param norm = 1.2101e-01, time/batch = 16.9479s	
9858/33650 (epoch 14.648), train_loss = 1.10094340, grad/param norm = 1.3374e-01, time/batch = 17.8884s	
9859/33650 (epoch 14.649), train_loss = 1.08495980, grad/param norm = 1.8015e-01, time/batch = 19.1307s	
9860/33650 (epoch 14.651), train_loss = 1.24028079, grad/param norm = 1.5530e-01, time/batch = 18.6446s	
9861/33650 (epoch 14.652), train_loss = 0.80151164, grad/param norm = 1.1675e-01, time/batch = 17.8819s	
9862/33650 (epoch 14.654), train_loss = 1.01578523, grad/param norm = 1.3568e-01, time/batch = 19.5469s	
9863/33650 (epoch 14.655), train_loss = 0.97165124, grad/param norm = 1.2331e-01, time/batch = 18.8014s	
9864/33650 (epoch 14.657), train_loss = 1.06896098, grad/param norm = 1.4757e-01, time/batch = 18.1190s	
9865/33650 (epoch 14.658), train_loss = 0.94731164, grad/param norm = 1.3629e-01, time/batch = 18.8123s	
9866/33650 (epoch 14.660), train_loss = 0.89927367, grad/param norm = 1.4184e-01, time/batch = 16.9866s	
9867/33650 (epoch 14.661), train_loss = 1.01763836, grad/param norm = 1.3398e-01, time/batch = 23.6974s	
9868/33650 (epoch 14.663), train_loss = 0.95315048, grad/param norm = 1.5257e-01, time/batch = 25.4958s	
9869/33650 (epoch 14.664), train_loss = 0.96914649, grad/param norm = 1.2416e-01, time/batch = 18.4053s	
9870/33650 (epoch 14.666), train_loss = 1.03193831, grad/param norm = 1.3161e-01, time/batch = 16.8809s	
9871/33650 (epoch 14.667), train_loss = 0.96942583, grad/param norm = 1.2988e-01, time/batch = 16.3055s	
9872/33650 (epoch 14.669), train_loss = 0.98970353, grad/param norm = 1.4157e-01, time/batch = 16.8633s	
9873/33650 (epoch 14.670), train_loss = 0.89402282, grad/param norm = 1.3483e-01, time/batch = 16.9276s	
9874/33650 (epoch 14.672), train_loss = 0.92932187, grad/param norm = 1.5040e-01, time/batch = 15.5777s	
9875/33650 (epoch 14.673), train_loss = 0.88082384, grad/param norm = 1.3306e-01, time/batch = 15.4640s	
9876/33650 (epoch 14.675), train_loss = 0.85138000, grad/param norm = 1.0700e-01, time/batch = 15.3815s	
9877/33650 (epoch 14.676), train_loss = 1.06247620, grad/param norm = 1.4393e-01, time/batch = 15.4281s	
9878/33650 (epoch 14.678), train_loss = 0.97512585, grad/param norm = 1.2677e-01, time/batch = 14.6632s	
9879/33650 (epoch 14.679), train_loss = 1.03914364, grad/param norm = 1.4645e-01, time/batch = 14.1680s	
9880/33650 (epoch 14.681), train_loss = 1.01305937, grad/param norm = 1.2254e-01, time/batch = 14.1916s	
9881/33650 (epoch 14.682), train_loss = 0.99181477, grad/param norm = 1.5043e-01, time/batch = 14.7433s	
9882/33650 (epoch 14.684), train_loss = 0.94238192, grad/param norm = 1.2732e-01, time/batch = 14.5909s	
9883/33650 (epoch 14.685), train_loss = 1.13286937, grad/param norm = 1.4104e-01, time/batch = 14.4333s	
9884/33650 (epoch 14.686), train_loss = 1.09353611, grad/param norm = 1.4578e-01, time/batch = 14.2677s	
9885/33650 (epoch 14.688), train_loss = 1.19385615, grad/param norm = 1.4922e-01, time/batch = 14.7447s	
9886/33650 (epoch 14.689), train_loss = 0.98063951, grad/param norm = 1.2524e-01, time/batch = 14.5011s	
9887/33650 (epoch 14.691), train_loss = 1.21275354, grad/param norm = 1.4963e-01, time/batch = 14.1858s	
9888/33650 (epoch 14.692), train_loss = 1.18883833, grad/param norm = 1.4312e-01, time/batch = 14.3518s	
9889/33650 (epoch 14.694), train_loss = 1.11135182, grad/param norm = 1.5284e-01, time/batch = 14.5020s	
9890/33650 (epoch 14.695), train_loss = 0.78813016, grad/param norm = 1.3617e-01, time/batch = 14.4173s	
9891/33650 (epoch 14.697), train_loss = 1.04545692, grad/param norm = 1.5107e-01, time/batch = 14.7555s	
9892/33650 (epoch 14.698), train_loss = 1.22313575, grad/param norm = 1.5227e-01, time/batch = 14.5856s	
9893/33650 (epoch 14.700), train_loss = 1.05612780, grad/param norm = 1.4141e-01, time/batch = 15.0543s	
9894/33650 (epoch 14.701), train_loss = 1.09738240, grad/param norm = 1.4618e-01, time/batch = 14.7435s	
9895/33650 (epoch 14.703), train_loss = 1.20736527, grad/param norm = 1.3908e-01, time/batch = 14.9754s	
9896/33650 (epoch 14.704), train_loss = 1.02460428, grad/param norm = 1.2302e-01, time/batch = 14.5995s	
9897/33650 (epoch 14.706), train_loss = 1.04254017, grad/param norm = 1.4095e-01, time/batch = 14.4333s	
9898/33650 (epoch 14.707), train_loss = 1.14528441, grad/param norm = 1.4332e-01, time/batch = 14.6708s	
9899/33650 (epoch 14.709), train_loss = 1.04617629, grad/param norm = 1.3880e-01, time/batch = 14.4264s	
9900/33650 (epoch 14.710), train_loss = 1.26395655, grad/param norm = 1.4873e-01, time/batch = 14.4332s	
9901/33650 (epoch 14.712), train_loss = 0.99845244, grad/param norm = 1.3787e-01, time/batch = 14.5182s	
9902/33650 (epoch 14.713), train_loss = 0.99815435, grad/param norm = 1.5672e-01, time/batch = 14.6654s	
9903/33650 (epoch 14.715), train_loss = 1.17506370, grad/param norm = 1.5775e-01, time/batch = 14.5901s	
9904/33650 (epoch 14.716), train_loss = 0.96701413, grad/param norm = 1.3537e-01, time/batch = 14.4324s	
9905/33650 (epoch 14.718), train_loss = 1.05568098, grad/param norm = 1.5043e-01, time/batch = 14.1929s	
9906/33650 (epoch 14.719), train_loss = 1.24229590, grad/param norm = 1.6862e-01, time/batch = 14.9012s	
9907/33650 (epoch 14.721), train_loss = 1.30518651, grad/param norm = 1.7289e-01, time/batch = 14.3497s	
9908/33650 (epoch 14.722), train_loss = 1.18447529, grad/param norm = 1.6709e-01, time/batch = 14.7590s	
9909/33650 (epoch 14.724), train_loss = 1.17147684, grad/param norm = 1.6163e-01, time/batch = 14.5611s	
9910/33650 (epoch 14.725), train_loss = 1.17329902, grad/param norm = 1.4866e-01, time/batch = 14.7459s	
9911/33650 (epoch 14.727), train_loss = 0.99344990, grad/param norm = 1.4804e-01, time/batch = 14.3478s	
9912/33650 (epoch 14.728), train_loss = 1.00876707, grad/param norm = 1.2979e-01, time/batch = 14.6638s	
9913/33650 (epoch 14.730), train_loss = 1.15291013, grad/param norm = 1.4933e-01, time/batch = 14.4314s	
9914/33650 (epoch 14.731), train_loss = 1.21560062, grad/param norm = 1.5676e-01, time/batch = 14.8333s	
9915/33650 (epoch 14.733), train_loss = 1.08005863, grad/param norm = 1.5324e-01, time/batch = 14.6643s	
9916/33650 (epoch 14.734), train_loss = 1.22426228, grad/param norm = 1.5874e-01, time/batch = 14.3444s	
9917/33650 (epoch 14.736), train_loss = 1.09798925, grad/param norm = 1.8102e-01, time/batch = 14.2771s	
9918/33650 (epoch 14.737), train_loss = 1.11912790, grad/param norm = 1.7787e-01, time/batch = 14.7528s	
9919/33650 (epoch 14.738), train_loss = 0.96750524, grad/param norm = 1.4203e-01, time/batch = 14.5915s	
9920/33650 (epoch 14.740), train_loss = 0.94079503, grad/param norm = 1.3488e-01, time/batch = 14.5813s	
9921/33650 (epoch 14.741), train_loss = 1.01804608, grad/param norm = 1.4430e-01, time/batch = 14.6779s	
9922/33650 (epoch 14.743), train_loss = 1.06865010, grad/param norm = 1.5261e-01, time/batch = 14.8849s	
9923/33650 (epoch 14.744), train_loss = 1.07861739, grad/param norm = 1.3777e-01, time/batch = 14.5144s	
9924/33650 (epoch 14.746), train_loss = 1.04612088, grad/param norm = 1.3970e-01, time/batch = 14.4337s	
9925/33650 (epoch 14.747), train_loss = 1.18989115, grad/param norm = 1.4354e-01, time/batch = 14.8270s	
9926/33650 (epoch 14.749), train_loss = 0.90441717, grad/param norm = 1.3905e-01, time/batch = 14.7432s	
9927/33650 (epoch 14.750), train_loss = 1.19576962, grad/param norm = 1.4308e-01, time/batch = 14.3490s	
9928/33650 (epoch 14.752), train_loss = 1.20786530, grad/param norm = 1.4615e-01, time/batch = 14.8206s	
9929/33650 (epoch 14.753), train_loss = 1.33427968, grad/param norm = 1.7336e-01, time/batch = 14.3405s	
9930/33650 (epoch 14.755), train_loss = 1.01779366, grad/param norm = 1.2358e-01, time/batch = 14.6611s	
9931/33650 (epoch 14.756), train_loss = 1.18474859, grad/param norm = 1.5351e-01, time/batch = 14.4324s	
9932/33650 (epoch 14.758), train_loss = 1.17717181, grad/param norm = 1.4459e-01, time/batch = 14.5114s	
9933/33650 (epoch 14.759), train_loss = 1.25013818, grad/param norm = 1.5247e-01, time/batch = 14.9721s	
9934/33650 (epoch 14.761), train_loss = 1.13997532, grad/param norm = 1.4777e-01, time/batch = 14.6711s	
9935/33650 (epoch 14.762), train_loss = 1.09496351, grad/param norm = 1.4418e-01, time/batch = 14.6732s	
9936/33650 (epoch 14.764), train_loss = 1.15921503, grad/param norm = 1.5567e-01, time/batch = 14.5097s	
9937/33650 (epoch 14.765), train_loss = 1.10461312, grad/param norm = 1.4553e-01, time/batch = 14.4208s	
9938/33650 (epoch 14.767), train_loss = 1.07245561, grad/param norm = 1.4016e-01, time/batch = 14.3418s	
9939/33650 (epoch 14.768), train_loss = 0.97043603, grad/param norm = 1.2976e-01, time/batch = 14.4940s	
9940/33650 (epoch 14.770), train_loss = 1.11753978, grad/param norm = 1.5094e-01, time/batch = 14.5108s	
9941/33650 (epoch 14.771), train_loss = 1.10288755, grad/param norm = 1.4217e-01, time/batch = 14.3491s	
9942/33650 (epoch 14.773), train_loss = 1.24241885, grad/param norm = 1.6327e-01, time/batch = 14.2549s	
9943/33650 (epoch 14.774), train_loss = 1.13328068, grad/param norm = 1.4721e-01, time/batch = 14.8235s	
9944/33650 (epoch 14.776), train_loss = 1.19103282, grad/param norm = 1.7300e-01, time/batch = 14.1077s	
9945/33650 (epoch 14.777), train_loss = 0.97226837, grad/param norm = 1.3934e-01, time/batch = 14.3456s	
9946/33650 (epoch 14.779), train_loss = 1.07276570, grad/param norm = 1.3894e-01, time/batch = 14.3505s	
9947/33650 (epoch 14.780), train_loss = 0.98818732, grad/param norm = 1.2187e-01, time/batch = 15.2166s	
9948/33650 (epoch 14.782), train_loss = 1.01713626, grad/param norm = 1.3799e-01, time/batch = 14.6497s	
9949/33650 (epoch 14.783), train_loss = 0.98662213, grad/param norm = 1.2985e-01, time/batch = 14.5113s	
9950/33650 (epoch 14.785), train_loss = 1.29510951, grad/param norm = 1.4845e-01, time/batch = 14.3551s	
9951/33650 (epoch 14.786), train_loss = 1.12775772, grad/param norm = 1.3517e-01, time/batch = 14.9118s	
9952/33650 (epoch 14.788), train_loss = 1.13616062, grad/param norm = 1.3367e-01, time/batch = 14.4385s	
9953/33650 (epoch 14.789), train_loss = 1.15106788, grad/param norm = 1.4408e-01, time/batch = 14.5748s	
9954/33650 (epoch 14.790), train_loss = 1.13767160, grad/param norm = 1.6536e-01, time/batch = 14.3461s	
9955/33650 (epoch 14.792), train_loss = 1.21954744, grad/param norm = 1.6954e-01, time/batch = 14.9099s	
9956/33650 (epoch 14.793), train_loss = 1.17208720, grad/param norm = 1.6994e-01, time/batch = 14.1026s	
9957/33650 (epoch 14.795), train_loss = 1.24330912, grad/param norm = 1.5069e-01, time/batch = 14.4357s	
9958/33650 (epoch 14.796), train_loss = 1.09500015, grad/param norm = 1.5311e-01, time/batch = 15.0024s	
9959/33650 (epoch 14.798), train_loss = 1.06322716, grad/param norm = 1.3785e-01, time/batch = 14.7385s	
9960/33650 (epoch 14.799), train_loss = 1.09473712, grad/param norm = 1.4322e-01, time/batch = 14.9759s	
9961/33650 (epoch 14.801), train_loss = 1.15317655, grad/param norm = 1.5734e-01, time/batch = 19.5641s	
9962/33650 (epoch 14.802), train_loss = 1.21965557, grad/param norm = 1.4598e-01, time/batch = 18.3010s	
9963/33650 (epoch 14.804), train_loss = 1.08632880, grad/param norm = 1.4877e-01, time/batch = 18.3034s	
9964/33650 (epoch 14.805), train_loss = 1.05367348, grad/param norm = 1.2654e-01, time/batch = 19.2201s	
9965/33650 (epoch 14.807), train_loss = 1.33527751, grad/param norm = 1.7357e-01, time/batch = 19.0460s	
9966/33650 (epoch 14.808), train_loss = 1.32917358, grad/param norm = 1.6985e-01, time/batch = 14.9067s	
9967/33650 (epoch 14.810), train_loss = 1.15969137, grad/param norm = 1.4594e-01, time/batch = 17.4671s	
9968/33650 (epoch 14.811), train_loss = 1.12265346, grad/param norm = 1.4704e-01, time/batch = 19.7897s	
9969/33650 (epoch 14.813), train_loss = 1.05792308, grad/param norm = 1.4347e-01, time/batch = 17.3938s	
9970/33650 (epoch 14.814), train_loss = 1.18302052, grad/param norm = 1.4642e-01, time/batch = 18.8947s	
9971/33650 (epoch 14.816), train_loss = 1.14143236, grad/param norm = 1.5726e-01, time/batch = 19.7069s	
9972/33650 (epoch 14.817), train_loss = 1.19084754, grad/param norm = 1.7035e-01, time/batch = 17.9715s	
9973/33650 (epoch 14.819), train_loss = 1.19476105, grad/param norm = 1.4345e-01, time/batch = 19.4624s	
9974/33650 (epoch 14.820), train_loss = 1.25514247, grad/param norm = 1.4947e-01, time/batch = 17.5328s	
9975/33650 (epoch 14.822), train_loss = 1.18471413, grad/param norm = 1.6963e-01, time/batch = 18.6263s	
9976/33650 (epoch 14.823), train_loss = 1.03007197, grad/param norm = 1.5176e-01, time/batch = 19.1236s	
9977/33650 (epoch 14.825), train_loss = 1.08690703, grad/param norm = 1.3834e-01, time/batch = 17.0518s	
9978/33650 (epoch 14.826), train_loss = 1.18111204, grad/param norm = 1.4632e-01, time/batch = 16.6515s	
9979/33650 (epoch 14.828), train_loss = 1.32267583, grad/param norm = 1.5867e-01, time/batch = 16.3606s	
9980/33650 (epoch 14.829), train_loss = 0.95374976, grad/param norm = 1.5495e-01, time/batch = 18.0635s	
9981/33650 (epoch 14.831), train_loss = 1.19052741, grad/param norm = 1.6153e-01, time/batch = 18.1391s	
9982/33650 (epoch 14.832), train_loss = 1.15465377, grad/param norm = 1.4353e-01, time/batch = 16.9013s	
9983/33650 (epoch 14.834), train_loss = 1.20107938, grad/param norm = 1.4572e-01, time/batch = 16.8050s	
9984/33650 (epoch 14.835), train_loss = 1.35769332, grad/param norm = 1.6268e-01, time/batch = 18.6454s	
9985/33650 (epoch 14.837), train_loss = 1.17562990, grad/param norm = 1.6226e-01, time/batch = 17.8201s	
9986/33650 (epoch 14.838), train_loss = 1.10265827, grad/param norm = 1.5210e-01, time/batch = 18.2178s	
9987/33650 (epoch 14.840), train_loss = 1.18493537, grad/param norm = 1.3363e-01, time/batch = 17.1168s	
9988/33650 (epoch 14.841), train_loss = 1.02842625, grad/param norm = 1.3400e-01, time/batch = 18.4572s	
9989/33650 (epoch 14.842), train_loss = 1.08692482, grad/param norm = 1.3682e-01, time/batch = 17.7239s	
9990/33650 (epoch 14.844), train_loss = 1.25625296, grad/param norm = 1.5703e-01, time/batch = 18.4769s	
9991/33650 (epoch 14.845), train_loss = 1.04513165, grad/param norm = 1.3467e-01, time/batch = 17.8759s	
9992/33650 (epoch 14.847), train_loss = 0.85667203, grad/param norm = 1.2944e-01, time/batch = 18.2230s	
9993/33650 (epoch 14.848), train_loss = 0.95381884, grad/param norm = 1.5177e-01, time/batch = 18.3938s	
9994/33650 (epoch 14.850), train_loss = 1.10733834, grad/param norm = 1.6418e-01, time/batch = 18.7393s	
9995/33650 (epoch 14.851), train_loss = 0.89109893, grad/param norm = 1.1742e-01, time/batch = 17.5650s	
9996/33650 (epoch 14.853), train_loss = 1.13255645, grad/param norm = 1.5611e-01, time/batch = 17.8058s	
9997/33650 (epoch 14.854), train_loss = 1.23793860, grad/param norm = 1.7955e-01, time/batch = 17.2176s	
9998/33650 (epoch 14.856), train_loss = 0.86194970, grad/param norm = 1.3590e-01, time/batch = 17.7978s	
9999/33650 (epoch 14.857), train_loss = 1.08409729, grad/param norm = 1.2917e-01, time/batch = 17.2234s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch14.86_1.5416.t7	
10000/33650 (epoch 14.859), train_loss = 0.98634407, grad/param norm = 1.2908e-01, time/batch = 19.0563s	
10001/33650 (epoch 14.860), train_loss = 1.34232706, grad/param norm = 1.5929e-01, time/batch = 17.5446s	
10002/33650 (epoch 14.862), train_loss = 0.98498392, grad/param norm = 1.3207e-01, time/batch = 18.1318s	
10003/33650 (epoch 14.863), train_loss = 1.18883965, grad/param norm = 1.4117e-01, time/batch = 18.3113s	
10004/33650 (epoch 14.865), train_loss = 1.08139434, grad/param norm = 1.4108e-01, time/batch = 17.2907s	
10005/33650 (epoch 14.866), train_loss = 0.97654877, grad/param norm = 1.3683e-01, time/batch = 18.4729s	
10006/33650 (epoch 14.868), train_loss = 0.97232368, grad/param norm = 1.5324e-01, time/batch = 17.9786s	
10007/33650 (epoch 14.869), train_loss = 1.22868783, grad/param norm = 1.5638e-01, time/batch = 18.5623s	
10008/33650 (epoch 14.871), train_loss = 0.94189097, grad/param norm = 1.1628e-01, time/batch = 16.9596s	
10009/33650 (epoch 14.872), train_loss = 1.09878639, grad/param norm = 1.4302e-01, time/batch = 18.5614s	
10010/33650 (epoch 14.874), train_loss = 1.18266664, grad/param norm = 1.5900e-01, time/batch = 18.4791s	
10011/33650 (epoch 14.875), train_loss = 1.08442941, grad/param norm = 1.4240e-01, time/batch = 17.5513s	
10012/33650 (epoch 14.877), train_loss = 1.22973003, grad/param norm = 1.4378e-01, time/batch = 18.3140s	
10013/33650 (epoch 14.878), train_loss = 0.78216943, grad/param norm = 1.2001e-01, time/batch = 18.3915s	
10014/33650 (epoch 14.880), train_loss = 1.15043845, grad/param norm = 1.5631e-01, time/batch = 17.1280s	
10015/33650 (epoch 14.881), train_loss = 1.04602624, grad/param norm = 1.5794e-01, time/batch = 17.2283s	
10016/33650 (epoch 14.883), train_loss = 1.09844542, grad/param norm = 1.4080e-01, time/batch = 19.0628s	
10017/33650 (epoch 14.884), train_loss = 1.20744377, grad/param norm = 1.8033e-01, time/batch = 16.5591s	
10018/33650 (epoch 14.886), train_loss = 1.20707717, grad/param norm = 1.6725e-01, time/batch = 17.0688s	
10019/33650 (epoch 14.887), train_loss = 1.01529419, grad/param norm = 1.2908e-01, time/batch = 17.3028s	
10020/33650 (epoch 14.889), train_loss = 1.14188405, grad/param norm = 1.4934e-01, time/batch = 17.6406s	
10021/33650 (epoch 14.890), train_loss = 1.15371775, grad/param norm = 1.3637e-01, time/batch = 17.2259s	
10022/33650 (epoch 14.892), train_loss = 1.12724608, grad/param norm = 1.5924e-01, time/batch = 17.4712s	
10023/33650 (epoch 14.893), train_loss = 1.13448152, grad/param norm = 1.3913e-01, time/batch = 18.7155s	
10024/33650 (epoch 14.895), train_loss = 1.24422751, grad/param norm = 1.6378e-01, time/batch = 17.9771s	
10025/33650 (epoch 14.896), train_loss = 1.01017811, grad/param norm = 1.3040e-01, time/batch = 17.7146s	
10026/33650 (epoch 14.897), train_loss = 0.92710993, grad/param norm = 1.2220e-01, time/batch = 17.5298s	
10027/33650 (epoch 14.899), train_loss = 0.96999722, grad/param norm = 1.2889e-01, time/batch = 18.4034s	
10028/33650 (epoch 14.900), train_loss = 0.88830993, grad/param norm = 1.3134e-01, time/batch = 17.3036s	
10029/33650 (epoch 14.902), train_loss = 1.11844730, grad/param norm = 1.4917e-01, time/batch = 17.8138s	
10030/33650 (epoch 14.903), train_loss = 1.06766868, grad/param norm = 1.6258e-01, time/batch = 18.1492s	
10031/33650 (epoch 14.905), train_loss = 1.26206236, grad/param norm = 1.6967e-01, time/batch = 17.6517s	
10032/33650 (epoch 14.906), train_loss = 1.05189782, grad/param norm = 1.3862e-01, time/batch = 17.4005s	
10033/33650 (epoch 14.908), train_loss = 1.03557056, grad/param norm = 1.2885e-01, time/batch = 18.5549s	
10034/33650 (epoch 14.909), train_loss = 1.03500030, grad/param norm = 1.3043e-01, time/batch = 17.1568s	
10035/33650 (epoch 14.911), train_loss = 0.90847603, grad/param norm = 1.2140e-01, time/batch = 17.2097s	
10036/33650 (epoch 14.912), train_loss = 0.89557125, grad/param norm = 1.2276e-01, time/batch = 17.7389s	
10037/33650 (epoch 14.914), train_loss = 1.08041773, grad/param norm = 1.3336e-01, time/batch = 18.5671s	
10038/33650 (epoch 14.915), train_loss = 1.08153149, grad/param norm = 1.5212e-01, time/batch = 16.3601s	
10039/33650 (epoch 14.917), train_loss = 1.06428666, grad/param norm = 1.4088e-01, time/batch = 18.0602s	
10040/33650 (epoch 14.918), train_loss = 0.88413178, grad/param norm = 1.2129e-01, time/batch = 18.6400s	
10041/33650 (epoch 14.920), train_loss = 0.99597096, grad/param norm = 1.2549e-01, time/batch = 18.0558s	
10042/33650 (epoch 14.921), train_loss = 0.97897238, grad/param norm = 1.3455e-01, time/batch = 18.4680s	
10043/33650 (epoch 14.923), train_loss = 0.94112926, grad/param norm = 1.3247e-01, time/batch = 18.4936s	
10044/33650 (epoch 14.924), train_loss = 1.09925976, grad/param norm = 1.5713e-01, time/batch = 17.9785s	
10045/33650 (epoch 14.926), train_loss = 1.07480218, grad/param norm = 1.6886e-01, time/batch = 17.7172s	
10046/33650 (epoch 14.927), train_loss = 1.00860829, grad/param norm = 1.4061e-01, time/batch = 17.8963s	
10047/33650 (epoch 14.929), train_loss = 1.10940839, grad/param norm = 1.4049e-01, time/batch = 18.3150s	
10048/33650 (epoch 14.930), train_loss = 1.02423299, grad/param norm = 1.3187e-01, time/batch = 16.8805s	
10049/33650 (epoch 14.932), train_loss = 1.07531103, grad/param norm = 1.5030e-01, time/batch = 17.2214s	
10050/33650 (epoch 14.933), train_loss = 0.93523716, grad/param norm = 1.3568e-01, time/batch = 16.4720s	
10051/33650 (epoch 14.935), train_loss = 0.96544790, grad/param norm = 1.3675e-01, time/batch = 17.6397s	
10052/33650 (epoch 14.936), train_loss = 0.97641971, grad/param norm = 1.2075e-01, time/batch = 17.7379s	
10053/33650 (epoch 14.938), train_loss = 0.91924766, grad/param norm = 1.3088e-01, time/batch = 18.4848s	
10054/33650 (epoch 14.939), train_loss = 1.12000927, grad/param norm = 1.3846e-01, time/batch = 17.3203s	
10055/33650 (epoch 14.941), train_loss = 1.09218083, grad/param norm = 1.5188e-01, time/batch = 17.0533s	
10056/33650 (epoch 14.942), train_loss = 1.15712509, grad/param norm = 1.5509e-01, time/batch = 17.5594s	
10057/33650 (epoch 14.944), train_loss = 1.07677679, grad/param norm = 1.3525e-01, time/batch = 18.5570s	
10058/33650 (epoch 14.945), train_loss = 1.15360018, grad/param norm = 1.4727e-01, time/batch = 16.5521s	
10059/33650 (epoch 14.947), train_loss = 1.29382815, grad/param norm = 1.8101e-01, time/batch = 18.5629s	
10060/33650 (epoch 14.948), train_loss = 1.21905773, grad/param norm = 1.4205e-01, time/batch = 18.5636s	
10061/33650 (epoch 14.949), train_loss = 0.97240247, grad/param norm = 1.3742e-01, time/batch = 17.9736s	
10062/33650 (epoch 14.951), train_loss = 1.22813442, grad/param norm = 1.4909e-01, time/batch = 18.5695s	
10063/33650 (epoch 14.952), train_loss = 1.17544299, grad/param norm = 1.4650e-01, time/batch = 17.5631s	
10064/33650 (epoch 14.954), train_loss = 1.15524392, grad/param norm = 1.4635e-01, time/batch = 17.6347s	
10065/33650 (epoch 14.955), train_loss = 1.15458744, grad/param norm = 1.4970e-01, time/batch = 17.0521s	
10066/33650 (epoch 14.957), train_loss = 1.13157903, grad/param norm = 1.3687e-01, time/batch = 18.5517s	
10067/33650 (epoch 14.958), train_loss = 0.84415230, grad/param norm = 1.1900e-01, time/batch = 17.8164s	
10068/33650 (epoch 14.960), train_loss = 0.91899726, grad/param norm = 1.3162e-01, time/batch = 16.8075s	
10069/33650 (epoch 14.961), train_loss = 0.96781349, grad/param norm = 1.4197e-01, time/batch = 17.8906s	
10070/33650 (epoch 14.963), train_loss = 1.05425374, grad/param norm = 1.5556e-01, time/batch = 17.4591s	
10071/33650 (epoch 14.964), train_loss = 1.08727102, grad/param norm = 1.4910e-01, time/batch = 17.5534s	
10072/33650 (epoch 14.966), train_loss = 1.06967923, grad/param norm = 1.4710e-01, time/batch = 18.0665s	
10073/33650 (epoch 14.967), train_loss = 1.14060416, grad/param norm = 1.4977e-01, time/batch = 16.8031s	
10074/33650 (epoch 14.969), train_loss = 1.04421089, grad/param norm = 1.3071e-01, time/batch = 18.0379s	
10075/33650 (epoch 14.970), train_loss = 1.13374249, grad/param norm = 1.4726e-01, time/batch = 29.4184s	
10076/33650 (epoch 14.972), train_loss = 1.41852084, grad/param norm = 1.5616e-01, time/batch = 20.2603s	
10077/33650 (epoch 14.973), train_loss = 0.98575593, grad/param norm = 1.3448e-01, time/batch = 18.1437s	
10078/33650 (epoch 14.975), train_loss = 0.98420230, grad/param norm = 1.3659e-01, time/batch = 14.3202s	
10079/33650 (epoch 14.976), train_loss = 0.96275643, grad/param norm = 1.2605e-01, time/batch = 16.5779s	
10080/33650 (epoch 14.978), train_loss = 1.00790875, grad/param norm = 1.4485e-01, time/batch = 18.5569s	
10081/33650 (epoch 14.979), train_loss = 1.06492208, grad/param norm = 1.4241e-01, time/batch = 17.2205s	
10082/33650 (epoch 14.981), train_loss = 1.01428545, grad/param norm = 1.2140e-01, time/batch = 15.8843s	
10083/33650 (epoch 14.982), train_loss = 1.10998467, grad/param norm = 1.3925e-01, time/batch = 18.0655s	
10084/33650 (epoch 14.984), train_loss = 0.93038933, grad/param norm = 1.3205e-01, time/batch = 16.8960s	
10085/33650 (epoch 14.985), train_loss = 0.91915183, grad/param norm = 1.3601e-01, time/batch = 17.6347s	
10086/33650 (epoch 14.987), train_loss = 1.04888428, grad/param norm = 1.3032e-01, time/batch = 18.7313s	
10087/33650 (epoch 14.988), train_loss = 1.11933857, grad/param norm = 1.4771e-01, time/batch = 18.3117s	
10088/33650 (epoch 14.990), train_loss = 1.30577209, grad/param norm = 1.8412e-01, time/batch = 16.2293s	
10089/33650 (epoch 14.991), train_loss = 1.12006072, grad/param norm = 1.3585e-01, time/batch = 18.2233s	
10090/33650 (epoch 14.993), train_loss = 1.10445248, grad/param norm = 1.4888e-01, time/batch = 18.9028s	
10091/33650 (epoch 14.994), train_loss = 1.02593279, grad/param norm = 1.3883e-01, time/batch = 17.8047s	
10092/33650 (epoch 14.996), train_loss = 0.99296709, grad/param norm = 1.3727e-01, time/batch = 16.2942s	
10093/33650 (epoch 14.997), train_loss = 1.10495384, grad/param norm = 1.4926e-01, time/batch = 17.7217s	
10094/33650 (epoch 14.999), train_loss = 0.95674658, grad/param norm = 1.3188e-01, time/batch = 18.3178s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
10095/33650 (epoch 15.000), train_loss = 1.14990864, grad/param norm = 1.5359e-01, time/batch = 18.0539s	
10096/33650 (epoch 15.001), train_loss = 1.23901268, grad/param norm = 1.5260e-01, time/batch = 17.2208s	
10097/33650 (epoch 15.003), train_loss = 1.27507748, grad/param norm = 1.7767e-01, time/batch = 18.2327s	
10098/33650 (epoch 15.004), train_loss = 1.13293753, grad/param norm = 1.5563e-01, time/batch = 15.8897s	
10099/33650 (epoch 15.006), train_loss = 1.03921217, grad/param norm = 1.4025e-01, time/batch = 16.5315s	
10100/33650 (epoch 15.007), train_loss = 1.14638866, grad/param norm = 1.5211e-01, time/batch = 17.4843s	
10101/33650 (epoch 15.009), train_loss = 1.05528832, grad/param norm = 1.5141e-01, time/batch = 18.1456s	
10102/33650 (epoch 15.010), train_loss = 1.15148329, grad/param norm = 1.5470e-01, time/batch = 16.8851s	
10103/33650 (epoch 15.012), train_loss = 1.03726049, grad/param norm = 1.5976e-01, time/batch = 18.8087s	
10104/33650 (epoch 15.013), train_loss = 1.11865111, grad/param norm = 1.6695e-01, time/batch = 18.3064s	
10105/33650 (epoch 15.015), train_loss = 0.99106495, grad/param norm = 1.3681e-01, time/batch = 17.1427s	
10106/33650 (epoch 15.016), train_loss = 0.96964499, grad/param norm = 1.5208e-01, time/batch = 18.5489s	
10107/33650 (epoch 15.018), train_loss = 1.06378244, grad/param norm = 1.4318e-01, time/batch = 18.8934s	
10108/33650 (epoch 15.019), train_loss = 1.01045222, grad/param norm = 1.4263e-01, time/batch = 16.9740s	
10109/33650 (epoch 15.021), train_loss = 1.17725879, grad/param norm = 1.4266e-01, time/batch = 18.2938s	
10110/33650 (epoch 15.022), train_loss = 1.02918832, grad/param norm = 1.3437e-01, time/batch = 18.5638s	
10111/33650 (epoch 15.024), train_loss = 0.94950452, grad/param norm = 1.4118e-01, time/batch = 18.0597s	
10112/33650 (epoch 15.025), train_loss = 1.03574933, grad/param norm = 1.3368e-01, time/batch = 17.3105s	
10113/33650 (epoch 15.027), train_loss = 1.15907838, grad/param norm = 1.4921e-01, time/batch = 16.9872s	
10114/33650 (epoch 15.028), train_loss = 1.16912540, grad/param norm = 1.5106e-01, time/batch = 19.2244s	
10115/33650 (epoch 15.030), train_loss = 1.11535714, grad/param norm = 1.5736e-01, time/batch = 17.2185s	
10116/33650 (epoch 15.031), train_loss = 0.95878659, grad/param norm = 1.2828e-01, time/batch = 18.5637s	
10117/33650 (epoch 15.033), train_loss = 1.03211258, grad/param norm = 1.1780e-01, time/batch = 16.2059s	
10118/33650 (epoch 15.034), train_loss = 1.10425924, grad/param norm = 1.4488e-01, time/batch = 17.3906s	
10119/33650 (epoch 15.036), train_loss = 1.21252632, grad/param norm = 1.7710e-01, time/batch = 18.0573s	
10120/33650 (epoch 15.037), train_loss = 1.01125532, grad/param norm = 1.5159e-01, time/batch = 17.7269s	
10121/33650 (epoch 15.039), train_loss = 1.18318048, grad/param norm = 1.4445e-01, time/batch = 16.5536s	
10122/33650 (epoch 15.040), train_loss = 1.27510789, grad/param norm = 1.7886e-01, time/batch = 16.8917s	
10123/33650 (epoch 15.042), train_loss = 1.26893646, grad/param norm = 1.5755e-01, time/batch = 18.3888s	
10124/33650 (epoch 15.043), train_loss = 1.02094570, grad/param norm = 1.3731e-01, time/batch = 18.8142s	
10125/33650 (epoch 15.045), train_loss = 0.97461406, grad/param norm = 1.2564e-01, time/batch = 16.7332s	
10126/33650 (epoch 15.046), train_loss = 1.16062991, grad/param norm = 1.5012e-01, time/batch = 18.5578s	
10127/33650 (epoch 15.048), train_loss = 1.17179314, grad/param norm = 1.4499e-01, time/batch = 18.4784s	
10128/33650 (epoch 15.049), train_loss = 1.11901215, grad/param norm = 1.4218e-01, time/batch = 16.3776s	
10129/33650 (epoch 15.051), train_loss = 1.19777824, grad/param norm = 1.4227e-01, time/batch = 17.3159s	
10130/33650 (epoch 15.052), train_loss = 1.23541230, grad/param norm = 1.5671e-01, time/batch = 17.5621s	
10131/33650 (epoch 15.053), train_loss = 1.11414627, grad/param norm = 1.3733e-01, time/batch = 18.9751s	
10132/33650 (epoch 15.055), train_loss = 0.95646190, grad/param norm = 1.3009e-01, time/batch = 17.8772s	
10133/33650 (epoch 15.056), train_loss = 0.94478440, grad/param norm = 1.2321e-01, time/batch = 18.9790s	
10134/33650 (epoch 15.058), train_loss = 1.19664867, grad/param norm = 1.6949e-01, time/batch = 18.8883s	
10135/33650 (epoch 15.059), train_loss = 1.13511933, grad/param norm = 1.5542e-01, time/batch = 16.6580s	
10136/33650 (epoch 15.061), train_loss = 1.15452024, grad/param norm = 1.4906e-01, time/batch = 16.3150s	
10137/33650 (epoch 15.062), train_loss = 1.15215010, grad/param norm = 1.4771e-01, time/batch = 17.2148s	
10138/33650 (epoch 15.064), train_loss = 1.02516511, grad/param norm = 1.3562e-01, time/batch = 17.8978s	
10139/33650 (epoch 15.065), train_loss = 1.04468320, grad/param norm = 1.4791e-01, time/batch = 17.0542s	
10140/33650 (epoch 15.067), train_loss = 0.96392954, grad/param norm = 1.3000e-01, time/batch = 18.6418s	
10141/33650 (epoch 15.068), train_loss = 1.09738252, grad/param norm = 1.4906e-01, time/batch = 18.7329s	
10142/33650 (epoch 15.070), train_loss = 1.09255926, grad/param norm = 1.4618e-01, time/batch = 17.5567s	
10143/33650 (epoch 15.071), train_loss = 1.10431002, grad/param norm = 1.4686e-01, time/batch = 17.7947s	
10144/33650 (epoch 15.073), train_loss = 1.12057962, grad/param norm = 1.4650e-01, time/batch = 18.7179s	
10145/33650 (epoch 15.074), train_loss = 1.20669667, grad/param norm = 1.4725e-01, time/batch = 17.3942s	
10146/33650 (epoch 15.076), train_loss = 1.17117993, grad/param norm = 1.6370e-01, time/batch = 17.6406s	
10147/33650 (epoch 15.077), train_loss = 1.06970312, grad/param norm = 1.4009e-01, time/batch = 17.9647s	
10148/33650 (epoch 15.079), train_loss = 1.07113761, grad/param norm = 1.3999e-01, time/batch = 17.9746s	
10149/33650 (epoch 15.080), train_loss = 1.14169350, grad/param norm = 1.4145e-01, time/batch = 17.4749s	
10150/33650 (epoch 15.082), train_loss = 1.17024913, grad/param norm = 1.5708e-01, time/batch = 18.4881s	
10151/33650 (epoch 15.083), train_loss = 1.14633524, grad/param norm = 1.4943e-01, time/batch = 18.3096s	
10152/33650 (epoch 15.085), train_loss = 1.17278645, grad/param norm = 1.4031e-01, time/batch = 16.6429s	
10153/33650 (epoch 15.086), train_loss = 1.19070460, grad/param norm = 1.5851e-01, time/batch = 17.7535s	
10154/33650 (epoch 15.088), train_loss = 1.15337923, grad/param norm = 1.5068e-01, time/batch = 17.8891s	
10155/33650 (epoch 15.089), train_loss = 1.10434611, grad/param norm = 1.5157e-01, time/batch = 17.5752s	
10156/33650 (epoch 15.091), train_loss = 1.02606035, grad/param norm = 1.3171e-01, time/batch = 17.6528s	
10157/33650 (epoch 15.092), train_loss = 1.06710240, grad/param norm = 1.4353e-01, time/batch = 17.2263s	
10158/33650 (epoch 15.094), train_loss = 1.13247141, grad/param norm = 1.3209e-01, time/batch = 18.0557s	
10159/33650 (epoch 15.095), train_loss = 1.13587899, grad/param norm = 1.5024e-01, time/batch = 21.9124s	
10160/33650 (epoch 15.097), train_loss = 1.04681612, grad/param norm = 1.4728e-01, time/batch = 18.6521s	
10161/33650 (epoch 15.098), train_loss = 0.89124348, grad/param norm = 1.2837e-01, time/batch = 20.3339s	
10162/33650 (epoch 15.100), train_loss = 0.99206832, grad/param norm = 1.2979e-01, time/batch = 20.0131s	
10163/33650 (epoch 15.101), train_loss = 1.07563228, grad/param norm = 1.6899e-01, time/batch = 20.1593s	
10164/33650 (epoch 15.103), train_loss = 1.02036637, grad/param norm = 1.3944e-01, time/batch = 19.5029s	
10165/33650 (epoch 15.104), train_loss = 1.16348657, grad/param norm = 1.4239e-01, time/batch = 20.7526s	
10166/33650 (epoch 15.105), train_loss = 1.08595109, grad/param norm = 1.4835e-01, time/batch = 20.7554s	
10167/33650 (epoch 15.107), train_loss = 0.98008891, grad/param norm = 1.2380e-01, time/batch = 20.6571s	
10168/33650 (epoch 15.108), train_loss = 1.15826278, grad/param norm = 1.5737e-01, time/batch = 21.3153s	
10169/33650 (epoch 15.110), train_loss = 1.27493349, grad/param norm = 1.5294e-01, time/batch = 20.1451s	
10170/33650 (epoch 15.111), train_loss = 1.03594100, grad/param norm = 1.4338e-01, time/batch = 20.4881s	
10171/33650 (epoch 15.113), train_loss = 1.04407503, grad/param norm = 1.3817e-01, time/batch = 20.9224s	
10172/33650 (epoch 15.114), train_loss = 1.15676870, grad/param norm = 1.5229e-01, time/batch = 20.1804s	
10173/33650 (epoch 15.116), train_loss = 0.97116938, grad/param norm = 1.2988e-01, time/batch = 19.6700s	
10174/33650 (epoch 15.117), train_loss = 1.11476537, grad/param norm = 1.2927e-01, time/batch = 19.9190s	
10175/33650 (epoch 15.119), train_loss = 0.95203063, grad/param norm = 1.3311e-01, time/batch = 21.3251s	
10176/33650 (epoch 15.120), train_loss = 1.02190701, grad/param norm = 1.4111e-01, time/batch = 19.8351s	
10177/33650 (epoch 15.122), train_loss = 0.88236001, grad/param norm = 1.3388e-01, time/batch = 19.9905s	
10178/33650 (epoch 15.123), train_loss = 1.03862447, grad/param norm = 1.3577e-01, time/batch = 27.4670s	
10179/33650 (epoch 15.125), train_loss = 1.18523322, grad/param norm = 1.5813e-01, time/batch = 18.9360s	
10180/33650 (epoch 15.126), train_loss = 1.26060992, grad/param norm = 1.6606e-01, time/batch = 16.7373s	
10181/33650 (epoch 15.128), train_loss = 1.20027048, grad/param norm = 1.6018e-01, time/batch = 16.8270s	
10182/33650 (epoch 15.129), train_loss = 1.19265515, grad/param norm = 1.4511e-01, time/batch = 16.3980s	
10183/33650 (epoch 15.131), train_loss = 1.10323314, grad/param norm = 1.4016e-01, time/batch = 16.8133s	
10184/33650 (epoch 15.132), train_loss = 1.10674446, grad/param norm = 1.4765e-01, time/batch = 17.5770s	
10185/33650 (epoch 15.134), train_loss = 1.20156158, grad/param norm = 1.5267e-01, time/batch = 16.4704s	
10186/33650 (epoch 15.135), train_loss = 0.95572701, grad/param norm = 1.5039e-01, time/batch = 16.6238s	
10187/33650 (epoch 15.137), train_loss = 1.09247827, grad/param norm = 1.4725e-01, time/batch = 17.8190s	
10188/33650 (epoch 15.138), train_loss = 1.16450529, grad/param norm = 1.3537e-01, time/batch = 16.4949s	
10189/33650 (epoch 15.140), train_loss = 1.08337374, grad/param norm = 1.5062e-01, time/batch = 16.3155s	
10190/33650 (epoch 15.141), train_loss = 1.23548246, grad/param norm = 1.5761e-01, time/batch = 17.8225s	
10191/33650 (epoch 15.143), train_loss = 1.31637081, grad/param norm = 1.7202e-01, time/batch = 17.3247s	
10192/33650 (epoch 15.144), train_loss = 1.16719951, grad/param norm = 1.5578e-01, time/batch = 18.0789s	
10193/33650 (epoch 15.146), train_loss = 1.05940280, grad/param norm = 1.4614e-01, time/batch = 16.0380s	
10194/33650 (epoch 15.147), train_loss = 1.02703748, grad/param norm = 1.4018e-01, time/batch = 16.8995s	
10195/33650 (epoch 15.149), train_loss = 1.01468141, grad/param norm = 1.5823e-01, time/batch = 17.0739s	
10196/33650 (epoch 15.150), train_loss = 0.95721031, grad/param norm = 1.4300e-01, time/batch = 16.5676s	
10197/33650 (epoch 15.152), train_loss = 1.03521467, grad/param norm = 1.3309e-01, time/batch = 16.4850s	
10198/33650 (epoch 15.153), train_loss = 1.03497448, grad/param norm = 1.4223e-01, time/batch = 16.9847s	
10199/33650 (epoch 15.155), train_loss = 1.00785888, grad/param norm = 1.3118e-01, time/batch = 16.9185s	
10200/33650 (epoch 15.156), train_loss = 0.97496306, grad/param norm = 1.1780e-01, time/batch = 16.5791s	
10201/33650 (epoch 15.158), train_loss = 1.09573541, grad/param norm = 1.5389e-01, time/batch = 17.6488s	
10202/33650 (epoch 15.159), train_loss = 0.98178993, grad/param norm = 1.1758e-01, time/batch = 16.9948s	
10203/33650 (epoch 15.160), train_loss = 1.01479608, grad/param norm = 1.2540e-01, time/batch = 15.9110s	
10204/33650 (epoch 15.162), train_loss = 1.07825042, grad/param norm = 1.7043e-01, time/batch = 17.3972s	
10205/33650 (epoch 15.163), train_loss = 1.13932441, grad/param norm = 1.4558e-01, time/batch = 17.4852s	
10206/33650 (epoch 15.165), train_loss = 0.99585458, grad/param norm = 1.5429e-01, time/batch = 17.8300s	
10207/33650 (epoch 15.166), train_loss = 0.98022035, grad/param norm = 1.4178e-01, time/batch = 16.2070s	
10208/33650 (epoch 15.168), train_loss = 1.16104611, grad/param norm = 1.4843e-01, time/batch = 15.9811s	
10209/33650 (epoch 15.169), train_loss = 1.08236718, grad/param norm = 1.4448e-01, time/batch = 16.7928s	
10210/33650 (epoch 15.171), train_loss = 1.07211120, grad/param norm = 1.3958e-01, time/batch = 17.1400s	
10211/33650 (epoch 15.172), train_loss = 1.04003622, grad/param norm = 1.4319e-01, time/batch = 17.3002s	
10212/33650 (epoch 15.174), train_loss = 0.98490571, grad/param norm = 1.5994e-01, time/batch = 15.6480s	
10213/33650 (epoch 15.175), train_loss = 1.00840247, grad/param norm = 1.5598e-01, time/batch = 17.5715s	
10214/33650 (epoch 15.177), train_loss = 1.09934643, grad/param norm = 1.4323e-01, time/batch = 16.2339s	
10215/33650 (epoch 15.178), train_loss = 0.99032631, grad/param norm = 1.5524e-01, time/batch = 17.0695s	
10216/33650 (epoch 15.180), train_loss = 0.95282518, grad/param norm = 1.3023e-01, time/batch = 17.8322s	
10217/33650 (epoch 15.181), train_loss = 0.87428381, grad/param norm = 1.2986e-01, time/batch = 16.6529s	
10218/33650 (epoch 15.183), train_loss = 1.02628310, grad/param norm = 1.5108e-01, time/batch = 16.9167s	
10219/33650 (epoch 15.184), train_loss = 1.00357090, grad/param norm = 1.4461e-01, time/batch = 17.9161s	
10220/33650 (epoch 15.186), train_loss = 1.03852004, grad/param norm = 1.5740e-01, time/batch = 16.5747s	
10221/33650 (epoch 15.187), train_loss = 1.24749794, grad/param norm = 1.4578e-01, time/batch = 14.2359s	
10222/33650 (epoch 15.189), train_loss = 1.23323217, grad/param norm = 1.6869e-01, time/batch = 16.9869s	
10223/33650 (epoch 15.190), train_loss = 1.09975655, grad/param norm = 1.5194e-01, time/batch = 17.1598s	
10224/33650 (epoch 15.192), train_loss = 1.25661673, grad/param norm = 1.5368e-01, time/batch = 17.3242s	
10225/33650 (epoch 15.193), train_loss = 1.20342736, grad/param norm = 1.4692e-01, time/batch = 16.0350s	
10226/33650 (epoch 15.195), train_loss = 0.96348733, grad/param norm = 1.3444e-01, time/batch = 14.9284s	
10227/33650 (epoch 15.196), train_loss = 0.92142504, grad/param norm = 1.5080e-01, time/batch = 15.1639s	
10228/33650 (epoch 15.198), train_loss = 1.04906304, grad/param norm = 1.6296e-01, time/batch = 14.9776s	
10229/33650 (epoch 15.199), train_loss = 1.17582359, grad/param norm = 1.5813e-01, time/batch = 15.1926s	
10230/33650 (epoch 15.201), train_loss = 1.02849829, grad/param norm = 1.4622e-01, time/batch = 14.7221s	
10231/33650 (epoch 15.202), train_loss = 1.03536595, grad/param norm = 1.4516e-01, time/batch = 16.3181s	
10232/33650 (epoch 15.204), train_loss = 1.11343562, grad/param norm = 1.3809e-01, time/batch = 16.3173s	
10233/33650 (epoch 15.205), train_loss = 1.06208039, grad/param norm = 1.4599e-01, time/batch = 16.9953s	
10234/33650 (epoch 15.207), train_loss = 1.01210556, grad/param norm = 1.5067e-01, time/batch = 17.2384s	
10235/33650 (epoch 15.208), train_loss = 1.05828485, grad/param norm = 1.3961e-01, time/batch = 15.6649s	
10236/33650 (epoch 15.210), train_loss = 0.85590262, grad/param norm = 1.2075e-01, time/batch = 15.9367s	
10237/33650 (epoch 15.211), train_loss = 0.98736148, grad/param norm = 1.4319e-01, time/batch = 16.6454s	
10238/33650 (epoch 15.212), train_loss = 1.15696914, grad/param norm = 1.6318e-01, time/batch = 17.9829s	
10239/33650 (epoch 15.214), train_loss = 1.24210854, grad/param norm = 1.4866e-01, time/batch = 16.6411s	
10240/33650 (epoch 15.215), train_loss = 0.85474494, grad/param norm = 1.2463e-01, time/batch = 17.8264s	
10241/33650 (epoch 15.217), train_loss = 1.07928463, grad/param norm = 1.5048e-01, time/batch = 17.9030s	
10242/33650 (epoch 15.218), train_loss = 1.10383349, grad/param norm = 1.4170e-01, time/batch = 13.8168s	
10243/33650 (epoch 15.220), train_loss = 0.94995119, grad/param norm = 1.3449e-01, time/batch = 14.7498s	
10244/33650 (epoch 15.221), train_loss = 1.22798879, grad/param norm = 1.7378e-01, time/batch = 0.6627s	
10245/33650 (epoch 15.223), train_loss = 0.83753076, grad/param norm = 1.2537e-01, time/batch = 0.6281s	
10246/33650 (epoch 15.224), train_loss = 1.03799367, grad/param norm = 1.5877e-01, time/batch = 0.6309s	
10247/33650 (epoch 15.226), train_loss = 1.37703905, grad/param norm = 1.7078e-01, time/batch = 0.6280s	
10248/33650 (epoch 15.227), train_loss = 1.21564869, grad/param norm = 1.5682e-01, time/batch = 0.6257s	
10249/33650 (epoch 15.229), train_loss = 1.21710468, grad/param norm = 1.5702e-01, time/batch = 0.6356s	
10250/33650 (epoch 15.230), train_loss = 1.31171458, grad/param norm = 1.5305e-01, time/batch = 0.6275s	
10251/33650 (epoch 15.232), train_loss = 1.12652817, grad/param norm = 1.4091e-01, time/batch = 0.7139s	
10252/33650 (epoch 15.233), train_loss = 1.14056820, grad/param norm = 1.6650e-01, time/batch = 0.9252s	
10253/33650 (epoch 15.235), train_loss = 1.04935660, grad/param norm = 1.2844e-01, time/batch = 0.9254s	
10254/33650 (epoch 15.236), train_loss = 0.93422752, grad/param norm = 1.3956e-01, time/batch = 0.9332s	
10255/33650 (epoch 15.238), train_loss = 1.02626437, grad/param norm = 1.3382e-01, time/batch = 0.9190s	
10256/33650 (epoch 15.239), train_loss = 0.98167047, grad/param norm = 1.4843e-01, time/batch = 0.9207s	
10257/33650 (epoch 15.241), train_loss = 1.01548524, grad/param norm = 1.3105e-01, time/batch = 1.6234s	
10258/33650 (epoch 15.242), train_loss = 0.88117826, grad/param norm = 1.2879e-01, time/batch = 1.7562s	
10259/33650 (epoch 15.244), train_loss = 1.05506598, grad/param norm = 1.4084e-01, time/batch = 1.8302s	
10260/33650 (epoch 15.245), train_loss = 0.93196059, grad/param norm = 1.4147e-01, time/batch = 16.9863s	
10261/33650 (epoch 15.247), train_loss = 1.05837870, grad/param norm = 1.3420e-01, time/batch = 17.3166s	
10262/33650 (epoch 15.248), train_loss = 0.94434530, grad/param norm = 1.3378e-01, time/batch = 16.7271s	
10263/33650 (epoch 15.250), train_loss = 1.03339653, grad/param norm = 1.2856e-01, time/batch = 16.4939s	
10264/33650 (epoch 15.251), train_loss = 1.21653257, grad/param norm = 1.5505e-01, time/batch = 16.5487s	
10265/33650 (epoch 15.253), train_loss = 0.97177804, grad/param norm = 1.3458e-01, time/batch = 16.2285s	
10266/33650 (epoch 15.254), train_loss = 0.97737774, grad/param norm = 1.3699e-01, time/batch = 17.3054s	
10267/33650 (epoch 15.256), train_loss = 1.20350467, grad/param norm = 1.3887e-01, time/batch = 17.7321s	
10268/33650 (epoch 15.257), train_loss = 1.20882671, grad/param norm = 1.4126e-01, time/batch = 17.6509s	
10269/33650 (epoch 15.259), train_loss = 0.94044575, grad/param norm = 1.4109e-01, time/batch = 15.5486s	
10270/33650 (epoch 15.260), train_loss = 1.17856232, grad/param norm = 1.4942e-01, time/batch = 16.9115s	
10271/33650 (epoch 15.262), train_loss = 1.11784559, grad/param norm = 1.4201e-01, time/batch = 17.9097s	
10272/33650 (epoch 15.263), train_loss = 1.03798647, grad/param norm = 1.6296e-01, time/batch = 16.3273s	
10273/33650 (epoch 15.264), train_loss = 1.12314810, grad/param norm = 1.4847e-01, time/batch = 17.0764s	
10274/33650 (epoch 15.266), train_loss = 1.08487397, grad/param norm = 1.3837e-01, time/batch = 17.8945s	
10275/33650 (epoch 15.267), train_loss = 0.99288628, grad/param norm = 1.5718e-01, time/batch = 16.8187s	
10276/33650 (epoch 15.269), train_loss = 1.11471853, grad/param norm = 1.4658e-01, time/batch = 16.6304s	
10277/33650 (epoch 15.270), train_loss = 0.99668391, grad/param norm = 1.2985e-01, time/batch = 16.9949s	
10278/33650 (epoch 15.272), train_loss = 1.04185865, grad/param norm = 1.3538e-01, time/batch = 17.5666s	
10279/33650 (epoch 15.273), train_loss = 1.20531935, grad/param norm = 1.6147e-01, time/batch = 16.7384s	
10280/33650 (epoch 15.275), train_loss = 1.16058416, grad/param norm = 1.5669e-01, time/batch = 16.3697s	
10281/33650 (epoch 15.276), train_loss = 1.23149286, grad/param norm = 1.7231e-01, time/batch = 17.3866s	
10282/33650 (epoch 15.278), train_loss = 1.27898597, grad/param norm = 1.5928e-01, time/batch = 17.8320s	
10283/33650 (epoch 15.279), train_loss = 1.01256146, grad/param norm = 1.3922e-01, time/batch = 16.8009s	
10284/33650 (epoch 15.281), train_loss = 1.11576454, grad/param norm = 1.5439e-01, time/batch = 17.3233s	
10285/33650 (epoch 15.282), train_loss = 1.18853199, grad/param norm = 1.3251e-01, time/batch = 15.4824s	
10286/33650 (epoch 15.284), train_loss = 1.16131576, grad/param norm = 1.5111e-01, time/batch = 17.0578s	
10287/33650 (epoch 15.285), train_loss = 1.18946538, grad/param norm = 1.6008e-01, time/batch = 17.6581s	
10288/33650 (epoch 15.287), train_loss = 1.07181755, grad/param norm = 1.5320e-01, time/batch = 17.5672s	
10289/33650 (epoch 15.288), train_loss = 1.13358332, grad/param norm = 1.6639e-01, time/batch = 16.0614s	
10290/33650 (epoch 15.290), train_loss = 1.08751789, grad/param norm = 1.3102e-01, time/batch = 16.4706s	
10291/33650 (epoch 15.291), train_loss = 0.99667393, grad/param norm = 1.2749e-01, time/batch = 17.4856s	
10292/33650 (epoch 15.293), train_loss = 1.08777451, grad/param norm = 1.6947e-01, time/batch = 17.2473s	
10293/33650 (epoch 15.294), train_loss = 0.98352440, grad/param norm = 1.4106e-01, time/batch = 17.7149s	
10294/33650 (epoch 15.296), train_loss = 0.97428357, grad/param norm = 1.3996e-01, time/batch = 28.0866s	
10295/33650 (epoch 15.297), train_loss = 1.04911200, grad/param norm = 1.3369e-01, time/batch = 21.8603s	
10296/33650 (epoch 15.299), train_loss = 0.94834114, grad/param norm = 1.2351e-01, time/batch = 16.0690s	
10297/33650 (epoch 15.300), train_loss = 0.97571814, grad/param norm = 1.4535e-01, time/batch = 17.3190s	
10298/33650 (epoch 15.302), train_loss = 1.10558139, grad/param norm = 1.3358e-01, time/batch = 16.8996s	
10299/33650 (epoch 15.303), train_loss = 1.08512722, grad/param norm = 1.3679e-01, time/batch = 16.3156s	
10300/33650 (epoch 15.305), train_loss = 1.11928114, grad/param norm = 1.4794e-01, time/batch = 16.4923s	
10301/33650 (epoch 15.306), train_loss = 1.00415844, grad/param norm = 1.2405e-01, time/batch = 18.4862s	
10302/33650 (epoch 15.308), train_loss = 0.96465722, grad/param norm = 1.6152e-01, time/batch = 17.9116s	
10303/33650 (epoch 15.309), train_loss = 1.26433694, grad/param norm = 1.7649e-01, time/batch = 16.3137s	
10304/33650 (epoch 15.311), train_loss = 1.13864718, grad/param norm = 1.6033e-01, time/batch = 16.9016s	
10305/33650 (epoch 15.312), train_loss = 1.09795070, grad/param norm = 1.5448e-01, time/batch = 17.2280s	
10306/33650 (epoch 15.314), train_loss = 0.92181918, grad/param norm = 1.1596e-01, time/batch = 16.4023s	
10307/33650 (epoch 15.315), train_loss = 1.06696714, grad/param norm = 1.6291e-01, time/batch = 16.3962s	
10308/33650 (epoch 15.316), train_loss = 1.01677288, grad/param norm = 1.5326e-01, time/batch = 16.9043s	
10309/33650 (epoch 15.318), train_loss = 0.97068172, grad/param norm = 1.2765e-01, time/batch = 17.9886s	
10310/33650 (epoch 15.319), train_loss = 0.97815013, grad/param norm = 1.2652e-01, time/batch = 15.8080s	
10311/33650 (epoch 15.321), train_loss = 1.01499612, grad/param norm = 1.3682e-01, time/batch = 16.9031s	
10312/33650 (epoch 15.322), train_loss = 1.13689248, grad/param norm = 1.5904e-01, time/batch = 17.9778s	
10313/33650 (epoch 15.324), train_loss = 1.14375107, grad/param norm = 1.6511e-01, time/batch = 17.2483s	
10314/33650 (epoch 15.325), train_loss = 1.14583306, grad/param norm = 1.4665e-01, time/batch = 16.7337s	
10315/33650 (epoch 15.327), train_loss = 0.96425460, grad/param norm = 1.2918e-01, time/batch = 15.8577s	
10316/33650 (epoch 15.328), train_loss = 1.15646017, grad/param norm = 1.5654e-01, time/batch = 14.7781s	
10317/33650 (epoch 15.330), train_loss = 0.97817566, grad/param norm = 1.2195e-01, time/batch = 15.5786s	
10318/33650 (epoch 15.331), train_loss = 0.88191642, grad/param norm = 1.1409e-01, time/batch = 17.1344s	
10319/33650 (epoch 15.333), train_loss = 1.04076710, grad/param norm = 1.4459e-01, time/batch = 15.6457s	
10320/33650 (epoch 15.334), train_loss = 1.04201193, grad/param norm = 1.3482e-01, time/batch = 16.7260s	
10321/33650 (epoch 15.336), train_loss = 1.19427532, grad/param norm = 1.4541e-01, time/batch = 15.9698s	
10322/33650 (epoch 15.337), train_loss = 0.86227852, grad/param norm = 1.1976e-01, time/batch = 17.1452s	
10323/33650 (epoch 15.339), train_loss = 1.04117619, grad/param norm = 1.3280e-01, time/batch = 16.7197s	
10324/33650 (epoch 15.340), train_loss = 1.24898672, grad/param norm = 1.6068e-01, time/batch = 16.7199s	
10325/33650 (epoch 15.342), train_loss = 0.90481776, grad/param norm = 1.3418e-01, time/batch = 16.4877s	
10326/33650 (epoch 15.343), train_loss = 1.12592209, grad/param norm = 1.4433e-01, time/batch = 16.8945s	
10327/33650 (epoch 15.345), train_loss = 1.05097614, grad/param norm = 1.5476e-01, time/batch = 16.5578s	
10328/33650 (epoch 15.346), train_loss = 0.76109322, grad/param norm = 1.2460e-01, time/batch = 16.2184s	
10329/33650 (epoch 15.348), train_loss = 0.95118479, grad/param norm = 1.2713e-01, time/batch = 17.1429s	
10330/33650 (epoch 15.349), train_loss = 0.89740540, grad/param norm = 1.2387e-01, time/batch = 16.1440s	
10331/33650 (epoch 15.351), train_loss = 1.14627934, grad/param norm = 1.4488e-01, time/batch = 17.0660s	
10332/33650 (epoch 15.352), train_loss = 1.05148917, grad/param norm = 1.3692e-01, time/batch = 16.0556s	
10333/33650 (epoch 15.354), train_loss = 1.27290068, grad/param norm = 1.6942e-01, time/batch = 17.3119s	
10334/33650 (epoch 15.355), train_loss = 1.17752960, grad/param norm = 1.3747e-01, time/batch = 18.9683s	
10335/33650 (epoch 15.357), train_loss = 0.86479896, grad/param norm = 1.3895e-01, time/batch = 17.8052s	
10336/33650 (epoch 15.358), train_loss = 1.15019793, grad/param norm = 1.5200e-01, time/batch = 18.2213s	
10337/33650 (epoch 15.360), train_loss = 1.15829102, grad/param norm = 1.5511e-01, time/batch = 17.3044s	
10338/33650 (epoch 15.361), train_loss = 1.11042248, grad/param norm = 1.4087e-01, time/batch = 15.6346s	
10339/33650 (epoch 15.363), train_loss = 1.00997274, grad/param norm = 1.4595e-01, time/batch = 16.9799s	
10340/33650 (epoch 15.364), train_loss = 1.02859645, grad/param norm = 1.4188e-01, time/batch = 17.5632s	
10341/33650 (epoch 15.366), train_loss = 1.10866768, grad/param norm = 1.5233e-01, time/batch = 18.4800s	
10342/33650 (epoch 15.367), train_loss = 1.13692720, grad/param norm = 1.3483e-01, time/batch = 16.2239s	
10343/33650 (epoch 15.368), train_loss = 0.97623886, grad/param norm = 1.3391e-01, time/batch = 15.9774s	
10344/33650 (epoch 15.370), train_loss = 1.06823396, grad/param norm = 1.3635e-01, time/batch = 17.3933s	
10345/33650 (epoch 15.371), train_loss = 0.86135363, grad/param norm = 1.2971e-01, time/batch = 16.7868s	
10346/33650 (epoch 15.373), train_loss = 0.96606821, grad/param norm = 1.2303e-01, time/batch = 17.5513s	
10347/33650 (epoch 15.374), train_loss = 0.91495690, grad/param norm = 1.2147e-01, time/batch = 18.4800s	
10348/33650 (epoch 15.376), train_loss = 1.06264091, grad/param norm = 1.5838e-01, time/batch = 17.5612s	
10349/33650 (epoch 15.377), train_loss = 1.10284472, grad/param norm = 1.4876e-01, time/batch = 17.4753s	
10350/33650 (epoch 15.379), train_loss = 1.14304249, grad/param norm = 1.4106e-01, time/batch = 16.9547s	
10351/33650 (epoch 15.380), train_loss = 0.84865633, grad/param norm = 1.5105e-01, time/batch = 18.3946s	
10352/33650 (epoch 15.382), train_loss = 0.95326149, grad/param norm = 1.1622e-01, time/batch = 17.0543s	
10353/33650 (epoch 15.383), train_loss = 1.03527423, grad/param norm = 1.3647e-01, time/batch = 16.5814s	
10354/33650 (epoch 15.385), train_loss = 1.20839317, grad/param norm = 1.4558e-01, time/batch = 17.4837s	
10355/33650 (epoch 15.386), train_loss = 0.97745553, grad/param norm = 1.3080e-01, time/batch = 18.7976s	
10356/33650 (epoch 15.388), train_loss = 1.08818243, grad/param norm = 1.3572e-01, time/batch = 16.9692s	
10357/33650 (epoch 15.389), train_loss = 1.04632096, grad/param norm = 1.4901e-01, time/batch = 16.9494s	
10358/33650 (epoch 15.391), train_loss = 0.86315928, grad/param norm = 1.2277e-01, time/batch = 17.6362s	
10359/33650 (epoch 15.392), train_loss = 1.11161732, grad/param norm = 1.4203e-01, time/batch = 17.0445s	
10360/33650 (epoch 15.394), train_loss = 1.12396683, grad/param norm = 1.5586e-01, time/batch = 16.6464s	
10361/33650 (epoch 15.395), train_loss = 1.08512227, grad/param norm = 1.3806e-01, time/batch = 17.3818s	
10362/33650 (epoch 15.397), train_loss = 1.22235454, grad/param norm = 1.4821e-01, time/batch = 18.4731s	
10363/33650 (epoch 15.398), train_loss = 1.09030313, grad/param norm = 1.3326e-01, time/batch = 17.6403s	
10364/33650 (epoch 15.400), train_loss = 1.07364744, grad/param norm = 1.6035e-01, time/batch = 17.5524s	
10365/33650 (epoch 15.401), train_loss = 1.06086989, grad/param norm = 1.6148e-01, time/batch = 17.8102s	
10366/33650 (epoch 15.403), train_loss = 1.11279383, grad/param norm = 1.5105e-01, time/batch = 16.0322s	
10367/33650 (epoch 15.404), train_loss = 1.05487128, grad/param norm = 1.3929e-01, time/batch = 18.1354s	
10368/33650 (epoch 15.406), train_loss = 1.10592356, grad/param norm = 1.3880e-01, time/batch = 17.2991s	
10369/33650 (epoch 15.407), train_loss = 1.08822179, grad/param norm = 1.4884e-01, time/batch = 17.3906s	
10370/33650 (epoch 15.409), train_loss = 1.08550499, grad/param norm = 1.5149e-01, time/batch = 17.7972s	
10371/33650 (epoch 15.410), train_loss = 1.05033564, grad/param norm = 1.4179e-01, time/batch = 18.8011s	
10372/33650 (epoch 15.412), train_loss = 1.07729910, grad/param norm = 1.2519e-01, time/batch = 17.8935s	
10373/33650 (epoch 15.413), train_loss = 0.98971970, grad/param norm = 1.3341e-01, time/batch = 17.5531s	
10374/33650 (epoch 15.415), train_loss = 1.14469653, grad/param norm = 1.4387e-01, time/batch = 18.4693s	
10375/33650 (epoch 15.416), train_loss = 1.24254535, grad/param norm = 1.5218e-01, time/batch = 18.2921s	
10376/33650 (epoch 15.418), train_loss = 1.05697944, grad/param norm = 1.4070e-01, time/batch = 16.8960s	
10377/33650 (epoch 15.419), train_loss = 1.02747490, grad/param norm = 1.5012e-01, time/batch = 18.0722s	
10378/33650 (epoch 15.421), train_loss = 1.03598623, grad/param norm = 1.1993e-01, time/batch = 16.9168s	
10379/33650 (epoch 15.422), train_loss = 1.14896852, grad/param norm = 1.4011e-01, time/batch = 17.7950s	
10380/33650 (epoch 15.423), train_loss = 0.94404676, grad/param norm = 1.1632e-01, time/batch = 17.0253s	
10381/33650 (epoch 15.425), train_loss = 1.08555059, grad/param norm = 1.4931e-01, time/batch = 18.6259s	
10382/33650 (epoch 15.426), train_loss = 1.22403083, grad/param norm = 1.6429e-01, time/batch = 18.8983s	
10383/33650 (epoch 15.428), train_loss = 1.00009402, grad/param norm = 1.3658e-01, time/batch = 16.9657s	
10384/33650 (epoch 15.429), train_loss = 1.14907088, grad/param norm = 1.4872e-01, time/batch = 17.4775s	
10385/33650 (epoch 15.431), train_loss = 1.25938737, grad/param norm = 1.6713e-01, time/batch = 18.5536s	
10386/33650 (epoch 15.432), train_loss = 1.30827310, grad/param norm = 1.6716e-01, time/batch = 17.8046s	
10387/33650 (epoch 15.434), train_loss = 1.11095035, grad/param norm = 1.3918e-01, time/batch = 17.7306s	
10388/33650 (epoch 15.435), train_loss = 1.08695227, grad/param norm = 1.7924e-01, time/batch = 17.4813s	
10389/33650 (epoch 15.437), train_loss = 1.10060499, grad/param norm = 1.4911e-01, time/batch = 17.6231s	
10390/33650 (epoch 15.438), train_loss = 0.99989514, grad/param norm = 1.7708e-01, time/batch = 17.9902s	
10391/33650 (epoch 15.440), train_loss = 1.09443003, grad/param norm = 1.4873e-01, time/batch = 18.1485s	
10392/33650 (epoch 15.441), train_loss = 1.10523057, grad/param norm = 1.4460e-01, time/batch = 17.9036s	
10393/33650 (epoch 15.443), train_loss = 1.12751177, grad/param norm = 1.3444e-01, time/batch = 17.3030s	
10394/33650 (epoch 15.444), train_loss = 1.03129733, grad/param norm = 1.3009e-01, time/batch = 18.4757s	
10395/33650 (epoch 15.446), train_loss = 1.13433556, grad/param norm = 1.7691e-01, time/batch = 17.7381s	
10396/33650 (epoch 15.447), train_loss = 1.18338410, grad/param norm = 1.6065e-01, time/batch = 17.4751s	
10397/33650 (epoch 15.449), train_loss = 1.25140991, grad/param norm = 1.7912e-01, time/batch = 17.5666s	
10398/33650 (epoch 15.450), train_loss = 1.27083794, grad/param norm = 1.5309e-01, time/batch = 17.9041s	
10399/33650 (epoch 15.452), train_loss = 1.30174277, grad/param norm = 1.6959e-01, time/batch = 18.3977s	
10400/33650 (epoch 15.453), train_loss = 1.26758588, grad/param norm = 1.7153e-01, time/batch = 17.4880s	
10401/33650 (epoch 15.455), train_loss = 1.05694446, grad/param norm = 1.4371e-01, time/batch = 17.9779s	
10402/33650 (epoch 15.456), train_loss = 1.07219156, grad/param norm = 1.3209e-01, time/batch = 17.3871s	
10403/33650 (epoch 15.458), train_loss = 1.05373480, grad/param norm = 1.6343e-01, time/batch = 17.2833s	
10404/33650 (epoch 15.459), train_loss = 1.10036022, grad/param norm = 1.5928e-01, time/batch = 18.4698s	
10405/33650 (epoch 15.461), train_loss = 1.27282051, grad/param norm = 1.6636e-01, time/batch = 17.9015s	
10406/33650 (epoch 15.462), train_loss = 1.22003872, grad/param norm = 1.5882e-01, time/batch = 16.9587s	
10407/33650 (epoch 15.464), train_loss = 1.03384585, grad/param norm = 1.5705e-01, time/batch = 18.8038s	
10408/33650 (epoch 15.465), train_loss = 1.12436010, grad/param norm = 1.6540e-01, time/batch = 18.3146s	
10409/33650 (epoch 15.467), train_loss = 1.13221632, grad/param norm = 1.4879e-01, time/batch = 15.6126s	
10410/33650 (epoch 15.468), train_loss = 1.20067400, grad/param norm = 1.5604e-01, time/batch = 14.6670s	
10411/33650 (epoch 15.470), train_loss = 1.34316649, grad/param norm = 1.7026e-01, time/batch = 18.3794s	
10412/33650 (epoch 15.471), train_loss = 1.10125951, grad/param norm = 1.5928e-01, time/batch = 18.7240s	
10413/33650 (epoch 15.473), train_loss = 1.03819603, grad/param norm = 1.4068e-01, time/batch = 15.7928s	
10414/33650 (epoch 15.474), train_loss = 1.15901639, grad/param norm = 1.3666e-01, time/batch = 16.9823s	
10415/33650 (epoch 15.475), train_loss = 1.16928018, grad/param norm = 1.4870e-01, time/batch = 18.6368s	
10416/33650 (epoch 15.477), train_loss = 1.21371058, grad/param norm = 1.5540e-01, time/batch = 18.3027s	
10417/33650 (epoch 15.478), train_loss = 1.21747973, grad/param norm = 1.6139e-01, time/batch = 18.5476s	
10418/33650 (epoch 15.480), train_loss = 1.19167096, grad/param norm = 1.6000e-01, time/batch = 17.9552s	
10419/33650 (epoch 15.481), train_loss = 1.26187206, grad/param norm = 1.6235e-01, time/batch = 17.4820s	
10420/33650 (epoch 15.483), train_loss = 0.90368714, grad/param norm = 1.4145e-01, time/batch = 16.4709s	
10421/33650 (epoch 15.484), train_loss = 1.08979514, grad/param norm = 1.4531e-01, time/batch = 16.4528s	
10422/33650 (epoch 15.486), train_loss = 1.22563467, grad/param norm = 1.6407e-01, time/batch = 16.6404s	
10423/33650 (epoch 15.487), train_loss = 1.23063365, grad/param norm = 1.6575e-01, time/batch = 17.9719s	
10424/33650 (epoch 15.489), train_loss = 1.26589882, grad/param norm = 1.4851e-01, time/batch = 17.4017s	
10425/33650 (epoch 15.490), train_loss = 1.00295242, grad/param norm = 1.4657e-01, time/batch = 18.5517s	
10426/33650 (epoch 15.492), train_loss = 1.12478412, grad/param norm = 1.5398e-01, time/batch = 17.8992s	
10427/33650 (epoch 15.493), train_loss = 0.92112353, grad/param norm = 1.3150e-01, time/batch = 17.6346s	
10428/33650 (epoch 15.495), train_loss = 1.11487969, grad/param norm = 1.4506e-01, time/batch = 18.3119s	
10429/33650 (epoch 15.496), train_loss = 1.15988729, grad/param norm = 1.5193e-01, time/batch = 18.3048s	
10430/33650 (epoch 15.498), train_loss = 0.97940495, grad/param norm = 1.3250e-01, time/batch = 17.3831s	
10431/33650 (epoch 15.499), train_loss = 1.06113134, grad/param norm = 1.2263e-01, time/batch = 18.2174s	
10432/33650 (epoch 15.501), train_loss = 1.05953874, grad/param norm = 1.3207e-01, time/batch = 18.2982s	
10433/33650 (epoch 15.502), train_loss = 1.10024998, grad/param norm = 1.5430e-01, time/batch = 17.2206s	
10434/33650 (epoch 15.504), train_loss = 1.20834740, grad/param norm = 1.6323e-01, time/batch = 17.7323s	
10435/33650 (epoch 15.505), train_loss = 1.05460769, grad/param norm = 1.6672e-01, time/batch = 16.5468s	
10436/33650 (epoch 15.507), train_loss = 1.21785421, grad/param norm = 1.5059e-01, time/batch = 18.6468s	
10437/33650 (epoch 15.508), train_loss = 1.05030215, grad/param norm = 1.3989e-01, time/batch = 17.4715s	
10438/33650 (epoch 15.510), train_loss = 1.08166319, grad/param norm = 1.4416e-01, time/batch = 16.3753s	
10439/33650 (epoch 15.511), train_loss = 1.33694938, grad/param norm = 1.6590e-01, time/batch = 18.4044s	
10440/33650 (epoch 15.513), train_loss = 1.15910435, grad/param norm = 1.4761e-01, time/batch = 17.3944s	
10441/33650 (epoch 15.514), train_loss = 1.19820443, grad/param norm = 1.5733e-01, time/batch = 17.9750s	
10442/33650 (epoch 15.516), train_loss = 1.10761261, grad/param norm = 1.4717e-01, time/batch = 18.3148s	
10443/33650 (epoch 15.517), train_loss = 1.10382916, grad/param norm = 1.4569e-01, time/batch = 17.8829s	
10444/33650 (epoch 15.519), train_loss = 1.14992756, grad/param norm = 1.5194e-01, time/batch = 16.8888s	
10445/33650 (epoch 15.520), train_loss = 0.95167181, grad/param norm = 1.3299e-01, time/batch = 19.1464s	
10446/33650 (epoch 15.522), train_loss = 1.08942722, grad/param norm = 1.5505e-01, time/batch = 17.8133s	
10447/33650 (epoch 15.523), train_loss = 1.05723535, grad/param norm = 1.3386e-01, time/batch = 16.4698s	
10448/33650 (epoch 15.525), train_loss = 0.87600279, grad/param norm = 1.2843e-01, time/batch = 18.5629s	
10449/33650 (epoch 15.526), train_loss = 1.17967067, grad/param norm = 1.4061e-01, time/batch = 19.2261s	
10450/33650 (epoch 15.527), train_loss = 1.02288138, grad/param norm = 1.3485e-01, time/batch = 17.3156s	
10451/33650 (epoch 15.529), train_loss = 1.08445075, grad/param norm = 1.4224e-01, time/batch = 17.7344s	
10452/33650 (epoch 15.530), train_loss = 1.04017231, grad/param norm = 1.3887e-01, time/batch = 17.2198s	
10453/33650 (epoch 15.532), train_loss = 1.23880475, grad/param norm = 1.7822e-01, time/batch = 18.0636s	
10454/33650 (epoch 15.533), train_loss = 1.06478724, grad/param norm = 1.4496e-01, time/batch = 15.9992s	
10455/33650 (epoch 15.535), train_loss = 1.18657240, grad/param norm = 1.5807e-01, time/batch = 18.6415s	
10456/33650 (epoch 15.536), train_loss = 1.11783164, grad/param norm = 1.5080e-01, time/batch = 18.2384s	
10457/33650 (epoch 15.538), train_loss = 1.14683250, grad/param norm = 1.5640e-01, time/batch = 16.0606s	
10458/33650 (epoch 15.539), train_loss = 0.89847366, grad/param norm = 1.4009e-01, time/batch = 18.8142s	
10459/33650 (epoch 15.541), train_loss = 1.22175570, grad/param norm = 1.6966e-01, time/batch = 17.7204s	
10460/33650 (epoch 15.542), train_loss = 1.13749796, grad/param norm = 1.5994e-01, time/batch = 16.2883s	
10461/33650 (epoch 15.544), train_loss = 1.30842577, grad/param norm = 1.8228e-01, time/batch = 17.7280s	
10462/33650 (epoch 15.545), train_loss = 0.97061925, grad/param norm = 1.3586e-01, time/batch = 18.0481s	
10463/33650 (epoch 15.547), train_loss = 1.10974939, grad/param norm = 1.4563e-01, time/batch = 18.3967s	
10464/33650 (epoch 15.548), train_loss = 1.28539940, grad/param norm = 1.5894e-01, time/batch = 17.1271s	
10465/33650 (epoch 15.550), train_loss = 1.08023127, grad/param norm = 1.4057e-01, time/batch = 17.6341s	
10466/33650 (epoch 15.551), train_loss = 1.12958345, grad/param norm = 1.6474e-01, time/batch = 18.7240s	
10467/33650 (epoch 15.553), train_loss = 0.99234194, grad/param norm = 1.5754e-01, time/batch = 17.7168s	
10468/33650 (epoch 15.554), train_loss = 1.22635276, grad/param norm = 1.5089e-01, time/batch = 17.8930s	
10469/33650 (epoch 15.556), train_loss = 1.18175715, grad/param norm = 1.8150e-01, time/batch = 17.5602s	
10470/33650 (epoch 15.557), train_loss = 1.21359448, grad/param norm = 1.7244e-01, time/batch = 17.3109s	
10471/33650 (epoch 15.559), train_loss = 1.38216085, grad/param norm = 1.8701e-01, time/batch = 17.0681s	
10472/33650 (epoch 15.560), train_loss = 1.31137339, grad/param norm = 1.5912e-01, time/batch = 17.6502s	
10473/33650 (epoch 15.562), train_loss = 1.20365960, grad/param norm = 1.4466e-01, time/batch = 15.7031s	
10474/33650 (epoch 15.563), train_loss = 1.12261976, grad/param norm = 1.5203e-01, time/batch = 16.6992s	
10475/33650 (epoch 15.565), train_loss = 1.11188589, grad/param norm = 1.4489e-01, time/batch = 17.2256s	
10476/33650 (epoch 15.566), train_loss = 1.09497951, grad/param norm = 1.5188e-01, time/batch = 17.7332s	
10477/33650 (epoch 15.568), train_loss = 1.12736618, grad/param norm = 1.6164e-01, time/batch = 17.2190s	
10478/33650 (epoch 15.569), train_loss = 1.04201539, grad/param norm = 1.4466e-01, time/batch = 16.7945s	
10479/33650 (epoch 15.571), train_loss = 1.23689346, grad/param norm = 1.5420e-01, time/batch = 18.8033s	
10480/33650 (epoch 15.572), train_loss = 1.15386665, grad/param norm = 1.3181e-01, time/batch = 18.3859s	
10481/33650 (epoch 15.574), train_loss = 1.10722746, grad/param norm = 1.5752e-01, time/batch = 17.0467s	
10482/33650 (epoch 15.575), train_loss = 1.08528266, grad/param norm = 1.4986e-01, time/batch = 18.3031s	
10483/33650 (epoch 15.577), train_loss = 1.09035135, grad/param norm = 1.6742e-01, time/batch = 18.1351s	
10484/33650 (epoch 15.578), train_loss = 1.16163598, grad/param norm = 1.5112e-01, time/batch = 17.2206s	
10485/33650 (epoch 15.579), train_loss = 1.16806070, grad/param norm = 1.4621e-01, time/batch = 18.1409s	
10486/33650 (epoch 15.581), train_loss = 1.21453952, grad/param norm = 1.5312e-01, time/batch = 17.7143s	
10487/33650 (epoch 15.582), train_loss = 1.17727310, grad/param norm = 1.3499e-01, time/batch = 17.8914s	
10488/33650 (epoch 15.584), train_loss = 1.17773874, grad/param norm = 1.5682e-01, time/batch = 17.8132s	
10489/33650 (epoch 15.585), train_loss = 1.18272347, grad/param norm = 1.6102e-01, time/batch = 18.2275s	
10490/33650 (epoch 15.587), train_loss = 1.00487325, grad/param norm = 1.3087e-01, time/batch = 18.3880s	
10491/33650 (epoch 15.588), train_loss = 1.06927935, grad/param norm = 1.7185e-01, time/batch = 17.3075s	
10492/33650 (epoch 15.590), train_loss = 1.07084961, grad/param norm = 1.4281e-01, time/batch = 17.8106s	
10493/33650 (epoch 15.591), train_loss = 1.04874186, grad/param norm = 1.5102e-01, time/batch = 18.3027s	
10494/33650 (epoch 15.593), train_loss = 1.00618797, grad/param norm = 1.2869e-01, time/batch = 17.0506s	
10495/33650 (epoch 15.594), train_loss = 0.97957812, grad/param norm = 1.6127e-01, time/batch = 18.8944s	
10496/33650 (epoch 15.596), train_loss = 1.08345911, grad/param norm = 1.3853e-01, time/batch = 18.3916s	
10497/33650 (epoch 15.597), train_loss = 0.90279657, grad/param norm = 1.1962e-01, time/batch = 20.5971s	
10498/33650 (epoch 15.599), train_loss = 1.06536173, grad/param norm = 1.4863e-01, time/batch = 29.8668s	
10499/33650 (epoch 15.600), train_loss = 0.99524655, grad/param norm = 1.3958e-01, time/batch = 17.8927s	
10500/33650 (epoch 15.602), train_loss = 1.15895810, grad/param norm = 1.4263e-01, time/batch = 15.9708s	
10501/33650 (epoch 15.603), train_loss = 1.01901510, grad/param norm = 1.3929e-01, time/batch = 18.3865s	
10502/33650 (epoch 15.605), train_loss = 1.15696650, grad/param norm = 1.5142e-01, time/batch = 18.7996s	
10503/33650 (epoch 15.606), train_loss = 1.19751081, grad/param norm = 1.6294e-01, time/batch = 17.2321s	
10504/33650 (epoch 15.608), train_loss = 1.02185651, grad/param norm = 1.5419e-01, time/batch = 19.0448s	
10505/33650 (epoch 15.609), train_loss = 1.11465465, grad/param norm = 1.6159e-01, time/batch = 16.4691s	
10506/33650 (epoch 15.611), train_loss = 0.96571495, grad/param norm = 1.3838e-01, time/batch = 18.7232s	
10507/33650 (epoch 15.612), train_loss = 1.09235702, grad/param norm = 1.4573e-01, time/batch = 16.4505s	
10508/33650 (epoch 15.614), train_loss = 1.15982643, grad/param norm = 1.4795e-01, time/batch = 17.2191s	
10509/33650 (epoch 15.615), train_loss = 1.04967147, grad/param norm = 1.2515e-01, time/batch = 16.6276s	
10510/33650 (epoch 15.617), train_loss = 0.99573088, grad/param norm = 1.2073e-01, time/batch = 16.8911s	
10511/33650 (epoch 15.618), train_loss = 1.05759619, grad/param norm = 1.3570e-01, time/batch = 18.8992s	
10512/33650 (epoch 15.620), train_loss = 1.13452455, grad/param norm = 1.6476e-01, time/batch = 17.9889s	
10513/33650 (epoch 15.621), train_loss = 0.98175823, grad/param norm = 1.3430e-01, time/batch = 17.9766s	
10514/33650 (epoch 15.623), train_loss = 1.06153760, grad/param norm = 1.4197e-01, time/batch = 18.1429s	
10515/33650 (epoch 15.624), train_loss = 0.84688049, grad/param norm = 1.3082e-01, time/batch = 17.8900s	
10516/33650 (epoch 15.626), train_loss = 0.83874436, grad/param norm = 1.2042e-01, time/batch = 17.8785s	
10517/33650 (epoch 15.627), train_loss = 0.99584967, grad/param norm = 1.4170e-01, time/batch = 17.8048s	
10518/33650 (epoch 15.629), train_loss = 1.05314368, grad/param norm = 1.4294e-01, time/batch = 18.4765s	
10519/33650 (epoch 15.630), train_loss = 1.18407746, grad/param norm = 1.7120e-01, time/batch = 17.8790s	
10520/33650 (epoch 15.632), train_loss = 1.19717283, grad/param norm = 1.4632e-01, time/batch = 16.8125s	
10521/33650 (epoch 15.633), train_loss = 1.19447450, grad/param norm = 1.4184e-01, time/batch = 16.8688s	
10522/33650 (epoch 15.634), train_loss = 0.92134858, grad/param norm = 1.2890e-01, time/batch = 18.0613s	
10523/33650 (epoch 15.636), train_loss = 0.81811613, grad/param norm = 1.0839e-01, time/batch = 18.1386s	
10524/33650 (epoch 15.637), train_loss = 1.05311060, grad/param norm = 1.4713e-01, time/batch = 16.7768s	
10525/33650 (epoch 15.639), train_loss = 1.02867450, grad/param norm = 1.3823e-01, time/batch = 18.4789s	
10526/33650 (epoch 15.640), train_loss = 1.08087251, grad/param norm = 1.4570e-01, time/batch = 17.8188s	
10527/33650 (epoch 15.642), train_loss = 1.16155588, grad/param norm = 1.5257e-01, time/batch = 16.9732s	
10528/33650 (epoch 15.643), train_loss = 1.09401177, grad/param norm = 1.4919e-01, time/batch = 18.4798s	
10529/33650 (epoch 15.645), train_loss = 1.09353883, grad/param norm = 1.4050e-01, time/batch = 16.9805s	
10530/33650 (epoch 15.646), train_loss = 0.90928167, grad/param norm = 1.1758e-01, time/batch = 17.0416s	
10531/33650 (epoch 15.648), train_loss = 1.09094069, grad/param norm = 1.3939e-01, time/batch = 18.0504s	
10532/33650 (epoch 15.649), train_loss = 1.04844533, grad/param norm = 1.5060e-01, time/batch = 18.2250s	
10533/33650 (epoch 15.651), train_loss = 1.22068852, grad/param norm = 1.5538e-01, time/batch = 18.1516s	
10534/33650 (epoch 15.652), train_loss = 0.78203417, grad/param norm = 1.0537e-01, time/batch = 17.4680s	
10535/33650 (epoch 15.654), train_loss = 0.99534212, grad/param norm = 1.3798e-01, time/batch = 17.8102s	
10536/33650 (epoch 15.655), train_loss = 0.95154634, grad/param norm = 1.2294e-01, time/batch = 17.4521s	
10537/33650 (epoch 15.657), train_loss = 1.04416333, grad/param norm = 1.4649e-01, time/batch = 17.2262s	
10538/33650 (epoch 15.658), train_loss = 0.92289608, grad/param norm = 1.3644e-01, time/batch = 18.2350s	
10539/33650 (epoch 15.660), train_loss = 0.87758478, grad/param norm = 1.3236e-01, time/batch = 17.3035s	
10540/33650 (epoch 15.661), train_loss = 0.99785749, grad/param norm = 1.3987e-01, time/batch = 18.3027s	
10541/33650 (epoch 15.663), train_loss = 0.93993081, grad/param norm = 1.5113e-01, time/batch = 17.9655s	
10542/33650 (epoch 15.664), train_loss = 0.95712911, grad/param norm = 1.2431e-01, time/batch = 17.3689s	
10543/33650 (epoch 15.666), train_loss = 1.01148815, grad/param norm = 1.3112e-01, time/batch = 18.4703s	
10544/33650 (epoch 15.667), train_loss = 0.95447284, grad/param norm = 1.3417e-01, time/batch = 16.0488s	
10545/33650 (epoch 15.669), train_loss = 0.96993122, grad/param norm = 1.5201e-01, time/batch = 18.4756s	
10546/33650 (epoch 15.670), train_loss = 0.89057083, grad/param norm = 1.4669e-01, time/batch = 18.4783s	
10547/33650 (epoch 15.672), train_loss = 0.90860643, grad/param norm = 1.5014e-01, time/batch = 17.6377s	
10548/33650 (epoch 15.673), train_loss = 0.86494889, grad/param norm = 1.2639e-01, time/batch = 18.0579s	
10549/33650 (epoch 15.675), train_loss = 0.84876397, grad/param norm = 1.1827e-01, time/batch = 16.5553s	
10550/33650 (epoch 15.676), train_loss = 1.05602899, grad/param norm = 1.5046e-01, time/batch = 18.7960s	
10551/33650 (epoch 15.678), train_loss = 0.97010176, grad/param norm = 1.3330e-01, time/batch = 18.4747s	
10552/33650 (epoch 15.679), train_loss = 1.01936373, grad/param norm = 1.5093e-01, time/batch = 16.1303s	
10553/33650 (epoch 15.681), train_loss = 0.99989625, grad/param norm = 1.2993e-01, time/batch = 17.9800s	
10554/33650 (epoch 15.682), train_loss = 0.96834973, grad/param norm = 1.4533e-01, time/batch = 16.9813s	
10555/33650 (epoch 15.684), train_loss = 0.92430201, grad/param norm = 1.2796e-01, time/batch = 17.8848s	
10556/33650 (epoch 15.685), train_loss = 1.12801417, grad/param norm = 1.4913e-01, time/batch = 17.7999s	
10557/33650 (epoch 15.686), train_loss = 1.07322181, grad/param norm = 1.3707e-01, time/batch = 16.3763s	
10558/33650 (epoch 15.688), train_loss = 1.17517281, grad/param norm = 1.4480e-01, time/batch = 17.8026s	
10559/33650 (epoch 15.689), train_loss = 0.96507080, grad/param norm = 1.3113e-01, time/batch = 19.3083s	
10560/33650 (epoch 15.691), train_loss = 1.19175809, grad/param norm = 1.4716e-01, time/batch = 18.3044s	
10561/33650 (epoch 15.692), train_loss = 1.16396326, grad/param norm = 1.3870e-01, time/batch = 18.4530s	
10562/33650 (epoch 15.694), train_loss = 1.09203570, grad/param norm = 1.5439e-01, time/batch = 18.2245s	
10563/33650 (epoch 15.695), train_loss = 0.77502332, grad/param norm = 1.3253e-01, time/batch = 17.3779s	
10564/33650 (epoch 15.697), train_loss = 1.02343322, grad/param norm = 1.6694e-01, time/batch = 16.4614s	
10565/33650 (epoch 15.698), train_loss = 1.20771477, grad/param norm = 1.5512e-01, time/batch = 17.7193s	
10566/33650 (epoch 15.700), train_loss = 1.02558219, grad/param norm = 1.4634e-01, time/batch = 18.0483s	
10567/33650 (epoch 15.701), train_loss = 1.08707162, grad/param norm = 1.4876e-01, time/batch = 18.5417s	
10568/33650 (epoch 15.703), train_loss = 1.19461507, grad/param norm = 1.3829e-01, time/batch = 17.4013s	
10569/33650 (epoch 15.704), train_loss = 1.00669052, grad/param norm = 1.2301e-01, time/batch = 18.3047s	
10570/33650 (epoch 15.706), train_loss = 1.01287167, grad/param norm = 1.3552e-01, time/batch = 18.8026s	
10571/33650 (epoch 15.707), train_loss = 1.12946937, grad/param norm = 1.4371e-01, time/batch = 16.2684s	
10572/33650 (epoch 15.709), train_loss = 1.02159641, grad/param norm = 1.3911e-01, time/batch = 19.2256s	
10573/33650 (epoch 15.710), train_loss = 1.24033236, grad/param norm = 1.4152e-01, time/batch = 17.4023s	
10574/33650 (epoch 15.712), train_loss = 0.97530290, grad/param norm = 1.3508e-01, time/batch = 16.3096s	
10575/33650 (epoch 15.713), train_loss = 0.97291739, grad/param norm = 1.5055e-01, time/batch = 17.0665s	
10576/33650 (epoch 15.715), train_loss = 1.15148932, grad/param norm = 1.5933e-01, time/batch = 18.1393s	
10577/33650 (epoch 15.716), train_loss = 0.95432620, grad/param norm = 1.3633e-01, time/batch = 16.5527s	
10578/33650 (epoch 15.718), train_loss = 1.02341275, grad/param norm = 1.4664e-01, time/batch = 17.9680s	
10579/33650 (epoch 15.719), train_loss = 1.20376567, grad/param norm = 1.6462e-01, time/batch = 18.2362s	
10580/33650 (epoch 15.721), train_loss = 1.28257880, grad/param norm = 1.7243e-01, time/batch = 18.8026s	
10581/33650 (epoch 15.722), train_loss = 1.15340312, grad/param norm = 1.6673e-01, time/batch = 17.8881s	
10582/33650 (epoch 15.724), train_loss = 1.16366894, grad/param norm = 1.6245e-01, time/batch = 17.7294s	
10583/33650 (epoch 15.725), train_loss = 1.15018822, grad/param norm = 1.5027e-01, time/batch = 18.4725s	
10584/33650 (epoch 15.727), train_loss = 0.97430923, grad/param norm = 1.5102e-01, time/batch = 17.4725s	
10585/33650 (epoch 15.728), train_loss = 1.00342802, grad/param norm = 1.3181e-01, time/batch = 17.9780s	
10586/33650 (epoch 15.730), train_loss = 1.12708104, grad/param norm = 1.5488e-01, time/batch = 16.9833s	
10587/33650 (epoch 15.731), train_loss = 1.19440514, grad/param norm = 1.4777e-01, time/batch = 18.1376s	
10588/33650 (epoch 15.733), train_loss = 1.05033234, grad/param norm = 1.5017e-01, time/batch = 17.5549s	
10589/33650 (epoch 15.734), train_loss = 1.20887808, grad/param norm = 1.6758e-01, time/batch = 18.7957s	
10590/33650 (epoch 15.736), train_loss = 1.07836560, grad/param norm = 1.5463e-01, time/batch = 16.8864s	
10591/33650 (epoch 15.737), train_loss = 1.10829907, grad/param norm = 1.7065e-01, time/batch = 16.9626s	
10592/33650 (epoch 15.738), train_loss = 0.96111699, grad/param norm = 1.4627e-01, time/batch = 18.3940s	
10593/33650 (epoch 15.740), train_loss = 0.92528202, grad/param norm = 1.3328e-01, time/batch = 18.5586s	
10594/33650 (epoch 15.741), train_loss = 0.99348995, grad/param norm = 1.4345e-01, time/batch = 17.1382s	
10595/33650 (epoch 15.743), train_loss = 1.04631068, grad/param norm = 1.4777e-01, time/batch = 17.8084s	
10596/33650 (epoch 15.744), train_loss = 1.06149346, grad/param norm = 1.3228e-01, time/batch = 18.9711s	
10597/33650 (epoch 15.746), train_loss = 1.02874666, grad/param norm = 1.3452e-01, time/batch = 16.8901s	
10598/33650 (epoch 15.747), train_loss = 1.17082377, grad/param norm = 1.4556e-01, time/batch = 16.8758s	
10599/33650 (epoch 15.749), train_loss = 0.89250090, grad/param norm = 1.3573e-01, time/batch = 17.8082s	
10600/33650 (epoch 15.750), train_loss = 1.18411467, grad/param norm = 1.6877e-01, time/batch = 18.1438s	
10601/33650 (epoch 15.752), train_loss = 1.18676081, grad/param norm = 1.7041e-01, time/batch = 17.0579s	
10602/33650 (epoch 15.753), train_loss = 1.31581661, grad/param norm = 1.7344e-01, time/batch = 17.8950s	
10603/33650 (epoch 15.755), train_loss = 1.00599397, grad/param norm = 1.2837e-01, time/batch = 17.7241s	
10604/33650 (epoch 15.756), train_loss = 1.16185382, grad/param norm = 1.5941e-01, time/batch = 17.9729s	
10605/33650 (epoch 15.758), train_loss = 1.15339475, grad/param norm = 1.4427e-01, time/batch = 16.5483s	
10606/33650 (epoch 15.759), train_loss = 1.22396610, grad/param norm = 1.5550e-01, time/batch = 18.2330s	
10607/33650 (epoch 15.761), train_loss = 1.12153502, grad/param norm = 1.5342e-01, time/batch = 18.4014s	
10608/33650 (epoch 15.762), train_loss = 1.06888246, grad/param norm = 1.4125e-01, time/batch = 17.2126s	
10609/33650 (epoch 15.764), train_loss = 1.12417529, grad/param norm = 1.4714e-01, time/batch = 18.2348s	
10610/33650 (epoch 15.765), train_loss = 1.08498493, grad/param norm = 1.4533e-01, time/batch = 17.8045s	
10611/33650 (epoch 15.767), train_loss = 1.05733442, grad/param norm = 1.3871e-01, time/batch = 16.8853s	
10612/33650 (epoch 15.768), train_loss = 0.94994920, grad/param norm = 1.3902e-01, time/batch = 17.3089s	
10613/33650 (epoch 15.770), train_loss = 1.09739582, grad/param norm = 1.5304e-01, time/batch = 17.5685s	
10614/33650 (epoch 15.771), train_loss = 1.08117349, grad/param norm = 1.4530e-01, time/batch = 17.4828s	
10615/33650 (epoch 15.773), train_loss = 1.20650183, grad/param norm = 1.5922e-01, time/batch = 17.3896s	
10616/33650 (epoch 15.774), train_loss = 1.11590919, grad/param norm = 1.5622e-01, time/batch = 16.3549s	
10617/33650 (epoch 15.776), train_loss = 1.17167982, grad/param norm = 1.7003e-01, time/batch = 17.7335s	
10618/33650 (epoch 15.777), train_loss = 0.95718826, grad/param norm = 1.4354e-01, time/batch = 14.8486s	
10619/33650 (epoch 15.779), train_loss = 1.04875696, grad/param norm = 1.4438e-01, time/batch = 16.7057s	
10620/33650 (epoch 15.780), train_loss = 0.97690358, grad/param norm = 1.2616e-01, time/batch = 14.1985s	
10621/33650 (epoch 15.782), train_loss = 0.99692730, grad/param norm = 1.3774e-01, time/batch = 13.7906s	
10622/33650 (epoch 15.783), train_loss = 0.96249883, grad/param norm = 1.3122e-01, time/batch = 14.3126s	
10623/33650 (epoch 15.785), train_loss = 1.27636002, grad/param norm = 1.4845e-01, time/batch = 13.9876s	
10624/33650 (epoch 15.786), train_loss = 1.10750593, grad/param norm = 1.2968e-01, time/batch = 13.7505s	
10625/33650 (epoch 15.788), train_loss = 1.11562270, grad/param norm = 1.3818e-01, time/batch = 13.8286s	
10626/33650 (epoch 15.789), train_loss = 1.12970034, grad/param norm = 1.4412e-01, time/batch = 14.0788s	
10627/33650 (epoch 15.790), train_loss = 1.11724038, grad/param norm = 1.6432e-01, time/batch = 13.8178s	
10628/33650 (epoch 15.792), train_loss = 1.19280923, grad/param norm = 1.6035e-01, time/batch = 13.8236s	
10629/33650 (epoch 15.793), train_loss = 1.16166614, grad/param norm = 1.7760e-01, time/batch = 13.8274s	
10630/33650 (epoch 15.795), train_loss = 1.22492862, grad/param norm = 1.4292e-01, time/batch = 13.7458s	
10631/33650 (epoch 15.796), train_loss = 1.06573263, grad/param norm = 1.5119e-01, time/batch = 14.2407s	
10632/33650 (epoch 15.798), train_loss = 1.04279078, grad/param norm = 1.4201e-01, time/batch = 13.9046s	
10633/33650 (epoch 15.799), train_loss = 1.07655829, grad/param norm = 1.5138e-01, time/batch = 13.7350s	
10634/33650 (epoch 15.801), train_loss = 1.13146175, grad/param norm = 1.5760e-01, time/batch = 13.6575s	
10635/33650 (epoch 15.802), train_loss = 1.19168031, grad/param norm = 1.4026e-01, time/batch = 14.2219s	
10636/33650 (epoch 15.804), train_loss = 1.08030141, grad/param norm = 1.5320e-01, time/batch = 13.7361s	
10637/33650 (epoch 15.805), train_loss = 1.04269157, grad/param norm = 1.2932e-01, time/batch = 14.0536s	
10638/33650 (epoch 15.807), train_loss = 1.32081348, grad/param norm = 1.8263e-01, time/batch = 13.6691s	
10639/33650 (epoch 15.808), train_loss = 1.32088952, grad/param norm = 1.6631e-01, time/batch = 14.0680s	
10640/33650 (epoch 15.810), train_loss = 1.15314966, grad/param norm = 1.5553e-01, time/batch = 13.8251s	
10641/33650 (epoch 15.811), train_loss = 1.11269960, grad/param norm = 1.4448e-01, time/batch = 14.2316s	
10642/33650 (epoch 15.813), train_loss = 1.03871241, grad/param norm = 1.4735e-01, time/batch = 13.8275s	
10643/33650 (epoch 15.814), train_loss = 1.16686029, grad/param norm = 1.4596e-01, time/batch = 13.8048s	
10644/33650 (epoch 15.816), train_loss = 1.12829377, grad/param norm = 1.6761e-01, time/batch = 13.9837s	
10645/33650 (epoch 15.817), train_loss = 1.17462177, grad/param norm = 1.7156e-01, time/batch = 13.8196s	
10646/33650 (epoch 15.819), train_loss = 1.16767101, grad/param norm = 1.4243e-01, time/batch = 13.8174s	
10647/33650 (epoch 15.820), train_loss = 1.23251234, grad/param norm = 1.5170e-01, time/batch = 16.3913s	
10648/33650 (epoch 15.822), train_loss = 1.16052569, grad/param norm = 1.6187e-01, time/batch = 17.7063s	
10649/33650 (epoch 15.823), train_loss = 1.02184106, grad/param norm = 1.7144e-01, time/batch = 14.4715s	
10650/33650 (epoch 15.825), train_loss = 1.07437837, grad/param norm = 1.3496e-01, time/batch = 13.9666s	
10651/33650 (epoch 15.826), train_loss = 1.15609997, grad/param norm = 1.4592e-01, time/batch = 13.9845s	
10652/33650 (epoch 15.828), train_loss = 1.29354218, grad/param norm = 1.6024e-01, time/batch = 14.0623s	
10653/33650 (epoch 15.829), train_loss = 0.91784054, grad/param norm = 1.4846e-01, time/batch = 14.5406s	
10654/33650 (epoch 15.831), train_loss = 1.16825597, grad/param norm = 1.5393e-01, time/batch = 13.6559s	
10655/33650 (epoch 15.832), train_loss = 1.14093616, grad/param norm = 1.4240e-01, time/batch = 13.7444s	
10656/33650 (epoch 15.834), train_loss = 1.17515175, grad/param norm = 1.5130e-01, time/batch = 14.2220s	
10657/33650 (epoch 15.835), train_loss = 1.34382224, grad/param norm = 1.8158e-01, time/batch = 14.6248s	
10658/33650 (epoch 15.837), train_loss = 1.17133361, grad/param norm = 1.7573e-01, time/batch = 14.7164s	
10659/33650 (epoch 15.838), train_loss = 1.09580795, grad/param norm = 1.5961e-01, time/batch = 14.2170s	
10660/33650 (epoch 15.840), train_loss = 1.16043470, grad/param norm = 1.3414e-01, time/batch = 14.8614s	
10661/33650 (epoch 15.841), train_loss = 1.01602427, grad/param norm = 1.3328e-01, time/batch = 14.4731s	
10662/33650 (epoch 15.842), train_loss = 1.06799494, grad/param norm = 1.4001e-01, time/batch = 14.2140s	
10663/33650 (epoch 15.844), train_loss = 1.24649184, grad/param norm = 1.5498e-01, time/batch = 13.7473s	
10664/33650 (epoch 15.845), train_loss = 1.02150912, grad/param norm = 1.3559e-01, time/batch = 13.9050s	
10665/33650 (epoch 15.847), train_loss = 0.84339524, grad/param norm = 1.3251e-01, time/batch = 13.9009s	
10666/33650 (epoch 15.848), train_loss = 0.93150529, grad/param norm = 1.4792e-01, time/batch = 13.7245s	
10667/33650 (epoch 15.850), train_loss = 1.07233344, grad/param norm = 1.6253e-01, time/batch = 13.7346s	
10668/33650 (epoch 15.851), train_loss = 0.87606620, grad/param norm = 1.1853e-01, time/batch = 13.9654s	
10669/33650 (epoch 15.853), train_loss = 1.10320987, grad/param norm = 1.5650e-01, time/batch = 13.9749s	
10670/33650 (epoch 15.854), train_loss = 1.20472288, grad/param norm = 1.5657e-01, time/batch = 13.6644s	
10671/33650 (epoch 15.856), train_loss = 0.84005534, grad/param norm = 1.2925e-01, time/batch = 13.8167s	
10672/33650 (epoch 15.857), train_loss = 1.07200371, grad/param norm = 1.3079e-01, time/batch = 14.1353s	
10673/33650 (epoch 15.859), train_loss = 0.97127094, grad/param norm = 1.2778e-01, time/batch = 15.1031s	
10674/33650 (epoch 15.860), train_loss = 0.90203293, grad/param norm = 1.3321e-01, time/batch = 13.7187s	
10675/33650 (epoch 15.862), train_loss = 0.96852283, grad/param norm = 1.3471e-01, time/batch = 14.4745s	
10676/33650 (epoch 15.863), train_loss = 1.17226675, grad/param norm = 1.4695e-01, time/batch = 13.8163s	
10677/33650 (epoch 15.865), train_loss = 1.07193972, grad/param norm = 1.4465e-01, time/batch = 14.8585s	
10678/33650 (epoch 15.866), train_loss = 0.94819691, grad/param norm = 1.3495e-01, time/batch = 13.9089s	
10679/33650 (epoch 15.868), train_loss = 0.94017683, grad/param norm = 1.4773e-01, time/batch = 13.9115s	
10680/33650 (epoch 15.869), train_loss = 1.20082329, grad/param norm = 1.5589e-01, time/batch = 14.3757s	
10681/33650 (epoch 15.871), train_loss = 0.93278060, grad/param norm = 1.1894e-01, time/batch = 14.1447s	
10682/33650 (epoch 15.872), train_loss = 1.07159781, grad/param norm = 1.4325e-01, time/batch = 13.9931s	
10683/33650 (epoch 15.874), train_loss = 1.15968578, grad/param norm = 1.6573e-01, time/batch = 14.1556s	
10684/33650 (epoch 15.875), train_loss = 1.05810234, grad/param norm = 1.3639e-01, time/batch = 14.2006s	
10685/33650 (epoch 15.877), train_loss = 1.21760380, grad/param norm = 1.4405e-01, time/batch = 14.2345s	
10686/33650 (epoch 15.878), train_loss = 0.76875592, grad/param norm = 1.1605e-01, time/batch = 13.9860s	
10687/33650 (epoch 15.880), train_loss = 1.13367646, grad/param norm = 1.6654e-01, time/batch = 13.8287s	
10688/33650 (epoch 15.881), train_loss = 1.02079526, grad/param norm = 1.6216e-01, time/batch = 13.7399s	
10689/33650 (epoch 15.883), train_loss = 1.08848734, grad/param norm = 1.4251e-01, time/batch = 13.9087s	
10690/33650 (epoch 15.884), train_loss = 1.18133313, grad/param norm = 1.6760e-01, time/batch = 13.9014s	
10691/33650 (epoch 15.886), train_loss = 1.18198663, grad/param norm = 1.5575e-01, time/batch = 13.8327s	
10692/33650 (epoch 15.887), train_loss = 0.99280404, grad/param norm = 1.2567e-01, time/batch = 13.8255s	
10693/33650 (epoch 15.889), train_loss = 1.11045749, grad/param norm = 1.4912e-01, time/batch = 13.9054s	
10694/33650 (epoch 15.890), train_loss = 1.13449331, grad/param norm = 1.3587e-01, time/batch = 14.1380s	
10695/33650 (epoch 15.892), train_loss = 1.10021657, grad/param norm = 1.6125e-01, time/batch = 13.8258s	
10696/33650 (epoch 15.893), train_loss = 1.11824823, grad/param norm = 1.3798e-01, time/batch = 14.3118s	
10697/33650 (epoch 15.895), train_loss = 1.21761496, grad/param norm = 1.6082e-01, time/batch = 13.6657s	
10698/33650 (epoch 15.896), train_loss = 0.98812200, grad/param norm = 1.3293e-01, time/batch = 14.2374s	
10699/33650 (epoch 15.897), train_loss = 0.91206897, grad/param norm = 1.2205e-01, time/batch = 13.8993s	
10700/33650 (epoch 15.899), train_loss = 0.95195185, grad/param norm = 1.2918e-01, time/batch = 13.7467s	
10701/33650 (epoch 15.900), train_loss = 0.87019566, grad/param norm = 1.2516e-01, time/batch = 13.8306s	
10702/33650 (epoch 15.902), train_loss = 1.10078293, grad/param norm = 1.5159e-01, time/batch = 14.1622s	
10703/33650 (epoch 15.903), train_loss = 1.04882393, grad/param norm = 1.5977e-01, time/batch = 13.9074s	
10704/33650 (epoch 15.905), train_loss = 1.23919843, grad/param norm = 1.8594e-01, time/batch = 13.8288s	
10705/33650 (epoch 15.906), train_loss = 1.03638847, grad/param norm = 1.3732e-01, time/batch = 14.0482s	
10706/33650 (epoch 15.908), train_loss = 1.01843463, grad/param norm = 1.2408e-01, time/batch = 13.7457s	
10707/33650 (epoch 15.909), train_loss = 1.00945591, grad/param norm = 1.3425e-01, time/batch = 14.2339s	
10708/33650 (epoch 15.911), train_loss = 0.89248687, grad/param norm = 1.2627e-01, time/batch = 17.8148s	
10709/33650 (epoch 15.912), train_loss = 0.88424958, grad/param norm = 1.2670e-01, time/batch = 15.4139s	
10710/33650 (epoch 15.914), train_loss = 1.06902824, grad/param norm = 1.3433e-01, time/batch = 16.2317s	
10711/33650 (epoch 15.915), train_loss = 1.04030343, grad/param norm = 1.4908e-01, time/batch = 16.4446s	
10712/33650 (epoch 15.917), train_loss = 1.05286534, grad/param norm = 1.5054e-01, time/batch = 16.4654s	
10713/33650 (epoch 15.918), train_loss = 0.86616703, grad/param norm = 1.1830e-01, time/batch = 17.7233s	
10714/33650 (epoch 15.920), train_loss = 0.97054055, grad/param norm = 1.2349e-01, time/batch = 17.1370s	
10715/33650 (epoch 15.921), train_loss = 0.95653232, grad/param norm = 1.3101e-01, time/batch = 17.3105s	
10716/33650 (epoch 15.923), train_loss = 0.91798962, grad/param norm = 1.3006e-01, time/batch = 17.9886s	
10717/33650 (epoch 15.924), train_loss = 1.07658667, grad/param norm = 1.4567e-01, time/batch = 19.3520s	
10718/33650 (epoch 15.926), train_loss = 1.04571746, grad/param norm = 1.6640e-01, time/batch = 27.0204s	
10719/33650 (epoch 15.927), train_loss = 0.99916517, grad/param norm = 1.4764e-01, time/batch = 17.4693s	
10720/33650 (epoch 15.929), train_loss = 1.09224700, grad/param norm = 1.4429e-01, time/batch = 16.6271s	
10721/33650 (epoch 15.930), train_loss = 0.99531372, grad/param norm = 1.3289e-01, time/batch = 15.7190s	
10722/33650 (epoch 15.932), train_loss = 1.05920598, grad/param norm = 1.5113e-01, time/batch = 15.8620s	
10723/33650 (epoch 15.933), train_loss = 0.91413493, grad/param norm = 1.3267e-01, time/batch = 18.2366s	
10724/33650 (epoch 15.935), train_loss = 0.94294430, grad/param norm = 1.3677e-01, time/batch = 17.0626s	
10725/33650 (epoch 15.936), train_loss = 0.96554404, grad/param norm = 1.2659e-01, time/batch = 18.4001s	
10726/33650 (epoch 15.938), train_loss = 0.91106645, grad/param norm = 1.4345e-01, time/batch = 16.4784s	
10727/33650 (epoch 15.939), train_loss = 1.10005324, grad/param norm = 1.3962e-01, time/batch = 17.3894s	
10728/33650 (epoch 15.941), train_loss = 1.07242606, grad/param norm = 1.5213e-01, time/batch = 18.6397s	
10729/33650 (epoch 15.942), train_loss = 1.13169504, grad/param norm = 1.5343e-01, time/batch = 17.7323s	
10730/33650 (epoch 15.944), train_loss = 1.04947491, grad/param norm = 1.3330e-01, time/batch = 17.1447s	
10731/33650 (epoch 15.945), train_loss = 1.12404723, grad/param norm = 1.4520e-01, time/batch = 17.0438s	
10732/33650 (epoch 15.947), train_loss = 1.26121354, grad/param norm = 1.8784e-01, time/batch = 17.9034s	
10733/33650 (epoch 15.948), train_loss = 1.20056371, grad/param norm = 1.4253e-01, time/batch = 17.7358s	
10734/33650 (epoch 15.949), train_loss = 0.94585858, grad/param norm = 1.3797e-01, time/batch = 16.5582s	
10735/33650 (epoch 15.951), train_loss = 1.22106640, grad/param norm = 1.5444e-01, time/batch = 16.3842s	
10736/33650 (epoch 15.952), train_loss = 1.14327884, grad/param norm = 1.4495e-01, time/batch = 17.1347s	
10737/33650 (epoch 15.954), train_loss = 1.12909846, grad/param norm = 1.4139e-01, time/batch = 18.0633s	
10738/33650 (epoch 15.955), train_loss = 1.12260242, grad/param norm = 1.4533e-01, time/batch = 16.9922s	
10739/33650 (epoch 15.957), train_loss = 1.10501376, grad/param norm = 1.3643e-01, time/batch = 17.4058s	
10740/33650 (epoch 15.958), train_loss = 0.84619858, grad/param norm = 1.2416e-01, time/batch = 17.8166s	
10741/33650 (epoch 15.960), train_loss = 0.88945608, grad/param norm = 1.2474e-01, time/batch = 17.6383s	
10742/33650 (epoch 15.961), train_loss = 0.94716296, grad/param norm = 1.5384e-01, time/batch = 17.4819s	
10743/33650 (epoch 15.963), train_loss = 1.03138627, grad/param norm = 1.5792e-01, time/batch = 17.8259s	
10744/33650 (epoch 15.964), train_loss = 1.06445386, grad/param norm = 1.4301e-01, time/batch = 17.6438s	
10745/33650 (epoch 15.966), train_loss = 1.04822009, grad/param norm = 1.5569e-01, time/batch = 17.4021s	
10746/33650 (epoch 15.967), train_loss = 1.12394557, grad/param norm = 1.5619e-01, time/batch = 16.8262s	
10747/33650 (epoch 15.969), train_loss = 1.03632656, grad/param norm = 1.3717e-01, time/batch = 18.4846s	
10748/33650 (epoch 15.970), train_loss = 1.11344078, grad/param norm = 1.3837e-01, time/batch = 17.3799s	
10749/33650 (epoch 15.972), train_loss = 1.39871767, grad/param norm = 1.6252e-01, time/batch = 18.4070s	
10750/33650 (epoch 15.973), train_loss = 0.96830095, grad/param norm = 1.3889e-01, time/batch = 18.1495s	
10751/33650 (epoch 15.975), train_loss = 0.96569640, grad/param norm = 1.3010e-01, time/batch = 16.8937s	
10752/33650 (epoch 15.976), train_loss = 0.94743823, grad/param norm = 1.2122e-01, time/batch = 16.2073s	
10753/33650 (epoch 15.978), train_loss = 0.99591691, grad/param norm = 1.4941e-01, time/batch = 17.2233s	
10754/33650 (epoch 15.979), train_loss = 1.05083279, grad/param norm = 1.4519e-01, time/batch = 18.2284s	
10755/33650 (epoch 15.981), train_loss = 0.98994368, grad/param norm = 1.1957e-01, time/batch = 17.3882s	
10756/33650 (epoch 15.982), train_loss = 1.08987007, grad/param norm = 1.4468e-01, time/batch = 17.6438s	
10757/33650 (epoch 15.984), train_loss = 0.89869758, grad/param norm = 1.2941e-01, time/batch = 18.1486s	
10758/33650 (epoch 15.985), train_loss = 0.90985955, grad/param norm = 1.3757e-01, time/batch = 16.4717s	
10759/33650 (epoch 15.987), train_loss = 1.03546802, grad/param norm = 1.3182e-01, time/batch = 18.3952s	
10760/33650 (epoch 15.988), train_loss = 1.09280255, grad/param norm = 1.5115e-01, time/batch = 16.1399s	
10761/33650 (epoch 15.990), train_loss = 1.28909103, grad/param norm = 1.8224e-01, time/batch = 16.1355s	
10762/33650 (epoch 15.991), train_loss = 1.10901869, grad/param norm = 1.4253e-01, time/batch = 16.6070s	
10763/33650 (epoch 15.993), train_loss = 1.09546844, grad/param norm = 1.5716e-01, time/batch = 18.3173s	
10764/33650 (epoch 15.994), train_loss = 1.00832610, grad/param norm = 1.3643e-01, time/batch = 17.9871s	
10765/33650 (epoch 15.996), train_loss = 0.97048136, grad/param norm = 1.4268e-01, time/batch = 16.5549s	
10766/33650 (epoch 15.997), train_loss = 1.09669854, grad/param norm = 1.5211e-01, time/batch = 17.6501s	
10767/33650 (epoch 15.999), train_loss = 0.94707078, grad/param norm = 1.4259e-01, time/batch = 17.8153s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
10768/33650 (epoch 16.000), train_loss = 1.13669698, grad/param norm = 1.6444e-01, time/batch = 16.7363s	
10769/33650 (epoch 16.001), train_loss = 1.22775070, grad/param norm = 1.5130e-01, time/batch = 16.7054s	
10770/33650 (epoch 16.003), train_loss = 1.24474581, grad/param norm = 1.7601e-01, time/batch = 18.3986s	
10771/33650 (epoch 16.004), train_loss = 1.10354873, grad/param norm = 1.5911e-01, time/batch = 18.5527s	
10772/33650 (epoch 16.006), train_loss = 1.02443828, grad/param norm = 1.4359e-01, time/batch = 16.3932s	
10773/33650 (epoch 16.007), train_loss = 1.12321513, grad/param norm = 1.6910e-01, time/batch = 18.0698s	
10774/33650 (epoch 16.009), train_loss = 1.03763296, grad/param norm = 1.4907e-01, time/batch = 18.2341s	
10775/33650 (epoch 16.010), train_loss = 1.13723051, grad/param norm = 1.5857e-01, time/batch = 17.0591s	
10776/33650 (epoch 16.012), train_loss = 1.01102018, grad/param norm = 1.4429e-01, time/batch = 17.8889s	
10777/33650 (epoch 16.013), train_loss = 1.08923747, grad/param norm = 1.6937e-01, time/batch = 18.1445s	
10778/33650 (epoch 16.015), train_loss = 0.97964847, grad/param norm = 1.3943e-01, time/batch = 16.8855s	
10779/33650 (epoch 16.016), train_loss = 0.93881449, grad/param norm = 1.4758e-01, time/batch = 17.8110s	
10780/33650 (epoch 16.018), train_loss = 1.04467296, grad/param norm = 1.4950e-01, time/batch = 18.3149s	
10781/33650 (epoch 16.019), train_loss = 0.99387653, grad/param norm = 1.4168e-01, time/batch = 18.3158s	
10782/33650 (epoch 16.021), train_loss = 1.14066587, grad/param norm = 1.4570e-01, time/batch = 17.0518s	
10783/33650 (epoch 16.022), train_loss = 1.01096715, grad/param norm = 1.3329e-01, time/batch = 17.9009s	
10784/33650 (epoch 16.024), train_loss = 0.92997248, grad/param norm = 1.3878e-01, time/batch = 17.0578s	
10785/33650 (epoch 16.025), train_loss = 1.02993907, grad/param norm = 1.3877e-01, time/batch = 17.4705s	
10786/33650 (epoch 16.027), train_loss = 1.14631167, grad/param norm = 1.6486e-01, time/batch = 17.4799s	
10787/33650 (epoch 16.028), train_loss = 1.15481770, grad/param norm = 1.5745e-01, time/batch = 18.4849s	
10788/33650 (epoch 16.030), train_loss = 1.08164912, grad/param norm = 1.4917e-01, time/batch = 17.8923s	
10789/33650 (epoch 16.031), train_loss = 0.94123864, grad/param norm = 1.2360e-01, time/batch = 17.3946s	
10790/33650 (epoch 16.033), train_loss = 1.02528662, grad/param norm = 1.1848e-01, time/batch = 17.9772s	
10791/33650 (epoch 16.034), train_loss = 1.08013559, grad/param norm = 1.4076e-01, time/batch = 18.0462s	
10792/33650 (epoch 16.036), train_loss = 1.19386446, grad/param norm = 1.5584e-01, time/batch = 16.6345s	
10793/33650 (epoch 16.037), train_loss = 0.99293824, grad/param norm = 1.4414e-01, time/batch = 18.7228s	
10794/33650 (epoch 16.039), train_loss = 1.16237204, grad/param norm = 1.5157e-01, time/batch = 16.9066s	
10795/33650 (epoch 16.040), train_loss = 1.24777692, grad/param norm = 1.8272e-01, time/batch = 18.2314s	
10796/33650 (epoch 16.042), train_loss = 1.25069247, grad/param norm = 1.5559e-01, time/batch = 17.4895s	
10797/33650 (epoch 16.043), train_loss = 1.00120894, grad/param norm = 1.3393e-01, time/batch = 17.6599s	
10798/33650 (epoch 16.045), train_loss = 0.96349757, grad/param norm = 1.3220e-01, time/batch = 17.8955s	
10799/33650 (epoch 16.046), train_loss = 1.14056898, grad/param norm = 1.5070e-01, time/batch = 16.3919s	
10800/33650 (epoch 16.048), train_loss = 1.15148270, grad/param norm = 1.4293e-01, time/batch = 17.8124s	
10801/33650 (epoch 16.049), train_loss = 1.09455642, grad/param norm = 1.5080e-01, time/batch = 18.8084s	
10802/33650 (epoch 16.051), train_loss = 1.18285687, grad/param norm = 1.4711e-01, time/batch = 16.6372s	
10803/33650 (epoch 16.052), train_loss = 1.21090881, grad/param norm = 1.5691e-01, time/batch = 18.1485s	
10804/33650 (epoch 16.053), train_loss = 1.10165624, grad/param norm = 1.3916e-01, time/batch = 18.1496s	
10805/33650 (epoch 16.055), train_loss = 0.94140556, grad/param norm = 1.2996e-01, time/batch = 17.7196s	
10806/33650 (epoch 16.056), train_loss = 0.91952416, grad/param norm = 1.1692e-01, time/batch = 16.3978s	
10807/33650 (epoch 16.058), train_loss = 1.17300611, grad/param norm = 1.6852e-01, time/batch = 16.7267s	
10808/33650 (epoch 16.059), train_loss = 1.11061101, grad/param norm = 1.6018e-01, time/batch = 17.2192s	
10809/33650 (epoch 16.061), train_loss = 1.13741101, grad/param norm = 1.5388e-01, time/batch = 16.8087s	
10810/33650 (epoch 16.062), train_loss = 1.14045475, grad/param norm = 1.4760e-01, time/batch = 17.6383s	
10811/33650 (epoch 16.064), train_loss = 1.00552167, grad/param norm = 1.3560e-01, time/batch = 18.3240s	
10812/33650 (epoch 16.065), train_loss = 1.01623017, grad/param norm = 1.4210e-01, time/batch = 17.0608s	
10813/33650 (epoch 16.067), train_loss = 0.94330304, grad/param norm = 1.3042e-01, time/batch = 16.8889s	
10814/33650 (epoch 16.068), train_loss = 1.08324749, grad/param norm = 1.5034e-01, time/batch = 18.2303s	
10815/33650 (epoch 16.070), train_loss = 1.07740264, grad/param norm = 1.4852e-01, time/batch = 17.9734s	
10816/33650 (epoch 16.071), train_loss = 1.08318422, grad/param norm = 1.4528e-01, time/batch = 17.5506s	
10817/33650 (epoch 16.073), train_loss = 1.10459512, grad/param norm = 1.4662e-01, time/batch = 17.3901s	
10818/33650 (epoch 16.074), train_loss = 1.18432576, grad/param norm = 1.4916e-01, time/batch = 18.3139s	
10819/33650 (epoch 16.076), train_loss = 1.14804290, grad/param norm = 1.5293e-01, time/batch = 16.6430s	
10820/33650 (epoch 16.077), train_loss = 1.05333166, grad/param norm = 1.4275e-01, time/batch = 17.8110s	
10821/33650 (epoch 16.079), train_loss = 1.05786522, grad/param norm = 1.3952e-01, time/batch = 17.4733s	
10822/33650 (epoch 16.080), train_loss = 1.12336360, grad/param norm = 1.4094e-01, time/batch = 17.8136s	
10823/33650 (epoch 16.082), train_loss = 1.14694731, grad/param norm = 1.4833e-01, time/batch = 17.5616s	
10824/33650 (epoch 16.083), train_loss = 1.12628484, grad/param norm = 1.5098e-01, time/batch = 16.8242s	
10825/33650 (epoch 16.085), train_loss = 1.15152547, grad/param norm = 1.4658e-01, time/batch = 18.9016s	
10826/33650 (epoch 16.086), train_loss = 1.16490340, grad/param norm = 1.6028e-01, time/batch = 16.7237s	
10827/33650 (epoch 16.088), train_loss = 1.13732782, grad/param norm = 1.5931e-01, time/batch = 18.3766s	
10828/33650 (epoch 16.089), train_loss = 1.06572617, grad/param norm = 1.4442e-01, time/batch = 17.9881s	
10829/33650 (epoch 16.091), train_loss = 1.01198427, grad/param norm = 1.3139e-01, time/batch = 17.1448s	
10830/33650 (epoch 16.092), train_loss = 1.05081928, grad/param norm = 1.3957e-01, time/batch = 17.6508s	
10831/33650 (epoch 16.094), train_loss = 1.11811770, grad/param norm = 1.3350e-01, time/batch = 18.1498s	
10832/33650 (epoch 16.095), train_loss = 1.10944177, grad/param norm = 1.5390e-01, time/batch = 18.0603s	
10833/33650 (epoch 16.097), train_loss = 1.02287160, grad/param norm = 1.4458e-01, time/batch = 17.7062s	
10834/33650 (epoch 16.098), train_loss = 0.87919745, grad/param norm = 1.3221e-01, time/batch = 17.9619s	
10835/33650 (epoch 16.100), train_loss = 0.97211995, grad/param norm = 1.3512e-01, time/batch = 15.4015s	
10836/33650 (epoch 16.101), train_loss = 1.06684207, grad/param norm = 1.7419e-01, time/batch = 16.4753s	
10837/33650 (epoch 16.103), train_loss = 1.00111251, grad/param norm = 1.3518e-01, time/batch = 14.0202s	
10838/33650 (epoch 16.104), train_loss = 1.14684591, grad/param norm = 1.4081e-01, time/batch = 17.0356s	
10839/33650 (epoch 16.105), train_loss = 1.06965891, grad/param norm = 1.5029e-01, time/batch = 13.6513s	
10840/33650 (epoch 16.107), train_loss = 0.97018382, grad/param norm = 1.2450e-01, time/batch = 14.5080s	
10841/33650 (epoch 16.108), train_loss = 1.13905165, grad/param norm = 1.5335e-01, time/batch = 13.8101s	
10842/33650 (epoch 16.110), train_loss = 1.24078147, grad/param norm = 1.4898e-01, time/batch = 13.9037s	
10843/33650 (epoch 16.111), train_loss = 1.01315765, grad/param norm = 1.4461e-01, time/batch = 13.6626s	
10844/33650 (epoch 16.113), train_loss = 1.03201749, grad/param norm = 1.3971e-01, time/batch = 13.9039s	
10845/33650 (epoch 16.114), train_loss = 1.14060785, grad/param norm = 1.5256e-01, time/batch = 13.9019s	
10846/33650 (epoch 16.116), train_loss = 0.95759947, grad/param norm = 1.2577e-01, time/batch = 13.8231s	
10847/33650 (epoch 16.117), train_loss = 1.08896163, grad/param norm = 1.3037e-01, time/batch = 13.6596s	
10848/33650 (epoch 16.119), train_loss = 0.93839007, grad/param norm = 1.3679e-01, time/batch = 13.6565s	
10849/33650 (epoch 16.120), train_loss = 1.00671509, grad/param norm = 1.4111e-01, time/batch = 13.9829s	
10850/33650 (epoch 16.122), train_loss = 0.86249622, grad/param norm = 1.3702e-01, time/batch = 14.2291s	
10851/33650 (epoch 16.123), train_loss = 1.03545444, grad/param norm = 1.3760e-01, time/batch = 13.8222s	
10852/33650 (epoch 16.125), train_loss = 1.15601478, grad/param norm = 1.5570e-01, time/batch = 13.7404s	
10853/33650 (epoch 16.126), train_loss = 1.23402513, grad/param norm = 1.6211e-01, time/batch = 14.0767s	
10854/33650 (epoch 16.128), train_loss = 1.18352439, grad/param norm = 1.6491e-01, time/batch = 13.8255s	
10855/33650 (epoch 16.129), train_loss = 1.18308294, grad/param norm = 1.5087e-01, time/batch = 13.6638s	
10856/33650 (epoch 16.131), train_loss = 1.08356813, grad/param norm = 1.3726e-01, time/batch = 13.5836s	
10857/33650 (epoch 16.132), train_loss = 1.09015571, grad/param norm = 1.4655e-01, time/batch = 14.0604s	
10858/33650 (epoch 16.134), train_loss = 1.16834303, grad/param norm = 1.4668e-01, time/batch = 13.9879s	
10859/33650 (epoch 16.135), train_loss = 0.93869698, grad/param norm = 1.5055e-01, time/batch = 13.8995s	
10860/33650 (epoch 16.137), train_loss = 1.07698844, grad/param norm = 1.5043e-01, time/batch = 13.6514s	
10861/33650 (epoch 16.138), train_loss = 1.14456986, grad/param norm = 1.4294e-01, time/batch = 13.7251s	
10862/33650 (epoch 16.140), train_loss = 1.05739130, grad/param norm = 1.6482e-01, time/batch = 14.2062s	
10863/33650 (epoch 16.141), train_loss = 1.21595650, grad/param norm = 1.6021e-01, time/batch = 14.1226s	
10864/33650 (epoch 16.143), train_loss = 1.29580357, grad/param norm = 1.8718e-01, time/batch = 13.9839s	
10865/33650 (epoch 16.144), train_loss = 1.14593656, grad/param norm = 1.5273e-01, time/batch = 13.6558s	
10866/33650 (epoch 16.146), train_loss = 1.05346275, grad/param norm = 1.4570e-01, time/batch = 13.8919s	
10867/33650 (epoch 16.147), train_loss = 1.01076034, grad/param norm = 1.4031e-01, time/batch = 13.7358s	
10868/33650 (epoch 16.149), train_loss = 0.98847736, grad/param norm = 1.5955e-01, time/batch = 13.8969s	
10869/33650 (epoch 16.150), train_loss = 0.93528850, grad/param norm = 1.3442e-01, time/batch = 13.6536s	
10870/33650 (epoch 16.152), train_loss = 1.01500315, grad/param norm = 1.2988e-01, time/batch = 13.9820s	
10871/33650 (epoch 16.153), train_loss = 1.00972053, grad/param norm = 1.4139e-01, time/batch = 13.8170s	
10872/33650 (epoch 16.155), train_loss = 0.99249276, grad/param norm = 1.3344e-01, time/batch = 13.6604s	
10873/33650 (epoch 16.156), train_loss = 0.96210866, grad/param norm = 1.1805e-01, time/batch = 13.5773s	
10874/33650 (epoch 16.158), train_loss = 1.09077488, grad/param norm = 1.6165e-01, time/batch = 13.7324s	
10875/33650 (epoch 16.159), train_loss = 0.96071039, grad/param norm = 1.1621e-01, time/batch = 13.9849s	
10876/33650 (epoch 16.160), train_loss = 0.99624449, grad/param norm = 1.2451e-01, time/batch = 13.7428s	
10877/33650 (epoch 16.162), train_loss = 1.04116113, grad/param norm = 1.6093e-01, time/batch = 13.9803s	
10878/33650 (epoch 16.163), train_loss = 1.12790787, grad/param norm = 1.6223e-01, time/batch = 13.7381s	
10879/33650 (epoch 16.165), train_loss = 0.98413508, grad/param norm = 1.5482e-01, time/batch = 14.3114s	
10880/33650 (epoch 16.166), train_loss = 0.96598638, grad/param norm = 1.4540e-01, time/batch = 13.7395s	
10881/33650 (epoch 16.168), train_loss = 1.13770202, grad/param norm = 1.5623e-01, time/batch = 14.1297s	
10882/33650 (epoch 16.169), train_loss = 1.06575873, grad/param norm = 1.4532e-01, time/batch = 13.6436s	
10883/33650 (epoch 16.171), train_loss = 1.05534245, grad/param norm = 1.3765e-01, time/batch = 13.8974s	
10884/33650 (epoch 16.172), train_loss = 1.00964268, grad/param norm = 1.3891e-01, time/batch = 13.9070s	
10885/33650 (epoch 16.174), train_loss = 0.96530261, grad/param norm = 1.3752e-01, time/batch = 13.8943s	
10886/33650 (epoch 16.175), train_loss = 0.98012651, grad/param norm = 1.5708e-01, time/batch = 13.6551s	
10887/33650 (epoch 16.177), train_loss = 1.07684207, grad/param norm = 1.4623e-01, time/batch = 13.8210s	
10888/33650 (epoch 16.178), train_loss = 0.97342951, grad/param norm = 1.5952e-01, time/batch = 14.0555s	
10889/33650 (epoch 16.180), train_loss = 0.94171924, grad/param norm = 1.3298e-01, time/batch = 13.8165s	
10890/33650 (epoch 16.181), train_loss = 0.85296869, grad/param norm = 1.2507e-01, time/batch = 13.8253s	
10891/33650 (epoch 16.183), train_loss = 1.01375433, grad/param norm = 1.4444e-01, time/batch = 13.7424s	
10892/33650 (epoch 16.184), train_loss = 0.98701788, grad/param norm = 1.4729e-01, time/batch = 14.0638s	
10893/33650 (epoch 16.186), train_loss = 1.01252830, grad/param norm = 1.7250e-01, time/batch = 13.9937s	
10894/33650 (epoch 16.187), train_loss = 1.22699352, grad/param norm = 1.4918e-01, time/batch = 13.5826s	
10895/33650 (epoch 16.189), train_loss = 1.21188598, grad/param norm = 1.7351e-01, time/batch = 13.6602s	
10896/33650 (epoch 16.190), train_loss = 1.08040899, grad/param norm = 1.4671e-01, time/batch = 14.2869s	
10897/33650 (epoch 16.192), train_loss = 1.24696774, grad/param norm = 1.5697e-01, time/batch = 13.8229s	
10898/33650 (epoch 16.193), train_loss = 1.18152563, grad/param norm = 1.5170e-01, time/batch = 13.6647s	
10899/33650 (epoch 16.195), train_loss = 0.93941755, grad/param norm = 1.3049e-01, time/batch = 13.9013s	
10900/33650 (epoch 16.196), train_loss = 0.91477087, grad/param norm = 1.5815e-01, time/batch = 14.1464s	
10901/33650 (epoch 16.198), train_loss = 1.02846304, grad/param norm = 1.4933e-01, time/batch = 13.9770s	
10902/33650 (epoch 16.199), train_loss = 1.15181641, grad/param norm = 1.5741e-01, time/batch = 13.7482s	
10903/33650 (epoch 16.201), train_loss = 1.01585529, grad/param norm = 1.5373e-01, time/batch = 13.7339s	
10904/33650 (epoch 16.202), train_loss = 1.03065508, grad/param norm = 1.5188e-01, time/batch = 13.9142s	
10905/33650 (epoch 16.204), train_loss = 1.09379887, grad/param norm = 1.4118e-01, time/batch = 13.9739s	
10906/33650 (epoch 16.205), train_loss = 1.05112952, grad/param norm = 1.5242e-01, time/batch = 13.7456s	
10907/33650 (epoch 16.207), train_loss = 1.00097817, grad/param norm = 1.5945e-01, time/batch = 13.9764s	
10908/33650 (epoch 16.208), train_loss = 1.03497977, grad/param norm = 1.3474e-01, time/batch = 13.5775s	
10909/33650 (epoch 16.210), train_loss = 0.84876684, grad/param norm = 1.2502e-01, time/batch = 14.1355s	
10910/33650 (epoch 16.211), train_loss = 0.98136004, grad/param norm = 1.4728e-01, time/batch = 13.9043s	
10911/33650 (epoch 16.212), train_loss = 1.12812466, grad/param norm = 1.6052e-01, time/batch = 14.0568s	
10912/33650 (epoch 16.214), train_loss = 1.22451404, grad/param norm = 1.4634e-01, time/batch = 13.7281s	
10913/33650 (epoch 16.215), train_loss = 0.83581251, grad/param norm = 1.3117e-01, time/batch = 13.9740s	
10914/33650 (epoch 16.217), train_loss = 1.05659377, grad/param norm = 1.5787e-01, time/batch = 13.8193s	
10915/33650 (epoch 16.218), train_loss = 1.08337118, grad/param norm = 1.4133e-01, time/batch = 13.7315s	
10916/33650 (epoch 16.220), train_loss = 0.91907040, grad/param norm = 1.3123e-01, time/batch = 13.8166s	
10917/33650 (epoch 16.221), train_loss = 1.21400825, grad/param norm = 1.6639e-01, time/batch = 13.9676s	
10918/33650 (epoch 16.223), train_loss = 0.83021272, grad/param norm = 1.2606e-01, time/batch = 14.2275s	
10919/33650 (epoch 16.224), train_loss = 1.03629609, grad/param norm = 1.8399e-01, time/batch = 13.7376s	
10920/33650 (epoch 16.226), train_loss = 1.34951144, grad/param norm = 1.6971e-01, time/batch = 13.6541s	
10921/33650 (epoch 16.227), train_loss = 1.21581156, grad/param norm = 1.6583e-01, time/batch = 13.7357s	
10922/33650 (epoch 16.229), train_loss = 1.19289871, grad/param norm = 1.5730e-01, time/batch = 14.3066s	
10923/33650 (epoch 16.230), train_loss = 1.29224529, grad/param norm = 1.6391e-01, time/batch = 13.9813s	
10924/33650 (epoch 16.232), train_loss = 1.12046691, grad/param norm = 1.6600e-01, time/batch = 17.0504s	
10925/33650 (epoch 16.233), train_loss = 1.11141735, grad/param norm = 1.7774e-01, time/batch = 18.3063s	
10926/33650 (epoch 16.235), train_loss = 1.03695827, grad/param norm = 1.2832e-01, time/batch = 16.7966s	
10927/33650 (epoch 16.236), train_loss = 0.92947122, grad/param norm = 1.4795e-01, time/batch = 17.7202s	
10928/33650 (epoch 16.238), train_loss = 1.01658807, grad/param norm = 1.3588e-01, time/batch = 16.5650s	
10929/33650 (epoch 16.239), train_loss = 0.95730437, grad/param norm = 1.4463e-01, time/batch = 16.8122s	
10930/33650 (epoch 16.241), train_loss = 0.99479094, grad/param norm = 1.2558e-01, time/batch = 17.7993s	
10931/33650 (epoch 16.242), train_loss = 0.86778574, grad/param norm = 1.3013e-01, time/batch = 17.0646s	
10932/33650 (epoch 16.244), train_loss = 1.03602010, grad/param norm = 1.4120e-01, time/batch = 16.6455s	
10933/33650 (epoch 16.245), train_loss = 0.90933676, grad/param norm = 1.3499e-01, time/batch = 17.1338s	
10934/33650 (epoch 16.247), train_loss = 1.03513445, grad/param norm = 1.3340e-01, time/batch = 16.5507s	
10935/33650 (epoch 16.248), train_loss = 0.92516612, grad/param norm = 1.3520e-01, time/batch = 16.9626s	
10936/33650 (epoch 16.250), train_loss = 1.02378386, grad/param norm = 1.3292e-01, time/batch = 16.5614s	
10937/33650 (epoch 16.251), train_loss = 1.19692598, grad/param norm = 1.5219e-01, time/batch = 17.3966s	
10938/33650 (epoch 16.253), train_loss = 0.95016534, grad/param norm = 1.3506e-01, time/batch = 16.6556s	
10939/33650 (epoch 16.254), train_loss = 0.97241430, grad/param norm = 1.3778e-01, time/batch = 17.8065s	
10940/33650 (epoch 16.256), train_loss = 1.18574341, grad/param norm = 1.4154e-01, time/batch = 29.6459s	
10941/33650 (epoch 16.257), train_loss = 1.20328513, grad/param norm = 1.4699e-01, time/batch = 16.0528s	
10942/33650 (epoch 16.259), train_loss = 0.92225178, grad/param norm = 1.4511e-01, time/batch = 14.3875s	
10943/33650 (epoch 16.260), train_loss = 1.16006040, grad/param norm = 1.4882e-01, time/batch = 15.4405s	
10944/33650 (epoch 16.262), train_loss = 1.10002340, grad/param norm = 1.4216e-01, time/batch = 17.6558s	
10945/33650 (epoch 16.263), train_loss = 1.01951944, grad/param norm = 1.6900e-01, time/batch = 17.4825s	
10946/33650 (epoch 16.264), train_loss = 1.11276861, grad/param norm = 1.4970e-01, time/batch = 17.0571s	
10947/33650 (epoch 16.266), train_loss = 1.06706825, grad/param norm = 1.3766e-01, time/batch = 15.7920s	
10948/33650 (epoch 16.267), train_loss = 0.98527076, grad/param norm = 1.4701e-01, time/batch = 13.9375s	
10949/33650 (epoch 16.269), train_loss = 1.10392200, grad/param norm = 1.4155e-01, time/batch = 13.7897s	
10950/33650 (epoch 16.270), train_loss = 0.97838702, grad/param norm = 1.2750e-01, time/batch = 14.1046s	
10951/33650 (epoch 16.272), train_loss = 1.02515125, grad/param norm = 1.3651e-01, time/batch = 13.4873s	
10952/33650 (epoch 16.273), train_loss = 1.18447590, grad/param norm = 1.5763e-01, time/batch = 13.4132s	
10953/33650 (epoch 16.275), train_loss = 1.13545242, grad/param norm = 1.5475e-01, time/batch = 13.4878s	
10954/33650 (epoch 16.276), train_loss = 1.21306971, grad/param norm = 1.7315e-01, time/batch = 13.7273s	
10955/33650 (epoch 16.278), train_loss = 1.27067902, grad/param norm = 1.6661e-01, time/batch = 13.8271s	
10956/33650 (epoch 16.279), train_loss = 0.99830400, grad/param norm = 1.3413e-01, time/batch = 13.3332s	
10957/33650 (epoch 16.281), train_loss = 1.09755434, grad/param norm = 1.4883e-01, time/batch = 13.7226s	
10958/33650 (epoch 16.282), train_loss = 1.16117165, grad/param norm = 1.3264e-01, time/batch = 13.4150s	
10959/33650 (epoch 16.284), train_loss = 1.14417710, grad/param norm = 1.5833e-01, time/batch = 13.8163s	
10960/33650 (epoch 16.285), train_loss = 1.16063118, grad/param norm = 1.6031e-01, time/batch = 13.4063s	
10961/33650 (epoch 16.287), train_loss = 1.04555609, grad/param norm = 1.4666e-01, time/batch = 13.5703s	
10962/33650 (epoch 16.288), train_loss = 1.10926604, grad/param norm = 1.6023e-01, time/batch = 13.4195s	
10963/33650 (epoch 16.290), train_loss = 1.07435708, grad/param norm = 1.2961e-01, time/batch = 13.6448s	
10964/33650 (epoch 16.291), train_loss = 0.98169262, grad/param norm = 1.2865e-01, time/batch = 13.7307s	
10965/33650 (epoch 16.293), train_loss = 1.05895433, grad/param norm = 1.5832e-01, time/batch = 13.8954s	
10966/33650 (epoch 16.294), train_loss = 0.97241763, grad/param norm = 1.3808e-01, time/batch = 13.4857s	
10967/33650 (epoch 16.296), train_loss = 0.96534374, grad/param norm = 1.4219e-01, time/batch = 13.4887s	
10968/33650 (epoch 16.297), train_loss = 1.03571324, grad/param norm = 1.3753e-01, time/batch = 13.7364s	
10969/33650 (epoch 16.299), train_loss = 0.93735637, grad/param norm = 1.3213e-01, time/batch = 13.4939s	
10970/33650 (epoch 16.300), train_loss = 0.96001211, grad/param norm = 1.6400e-01, time/batch = 13.5848s	
10971/33650 (epoch 16.302), train_loss = 1.09265310, grad/param norm = 1.3809e-01, time/batch = 13.7366s	
10972/33650 (epoch 16.303), train_loss = 1.07554720, grad/param norm = 1.3675e-01, time/batch = 13.9852s	
10973/33650 (epoch 16.305), train_loss = 1.10248688, grad/param norm = 1.5702e-01, time/batch = 13.4152s	
10974/33650 (epoch 16.306), train_loss = 0.98580177, grad/param norm = 1.2993e-01, time/batch = 13.4094s	
10975/33650 (epoch 16.308), train_loss = 0.94130985, grad/param norm = 1.7935e-01, time/batch = 13.5744s	
10976/33650 (epoch 16.309), train_loss = 1.24941488, grad/param norm = 1.6962e-01, time/batch = 13.6411s	
10977/33650 (epoch 16.311), train_loss = 1.12138692, grad/param norm = 1.6096e-01, time/batch = 13.8302s	
10978/33650 (epoch 16.312), train_loss = 1.07771534, grad/param norm = 1.6608e-01, time/batch = 13.4948s	
10979/33650 (epoch 16.314), train_loss = 0.90885928, grad/param norm = 1.1611e-01, time/batch = 13.4131s	
10980/33650 (epoch 16.315), train_loss = 1.04074832, grad/param norm = 1.5494e-01, time/batch = 13.8192s	
10981/33650 (epoch 16.316), train_loss = 0.99087620, grad/param norm = 1.4234e-01, time/batch = 14.3815s	
10982/33650 (epoch 16.318), train_loss = 0.93951865, grad/param norm = 1.2264e-01, time/batch = 13.6609s	
10983/33650 (epoch 16.319), train_loss = 0.97205490, grad/param norm = 1.2601e-01, time/batch = 13.8150s	
10984/33650 (epoch 16.321), train_loss = 0.98663682, grad/param norm = 1.3566e-01, time/batch = 13.8194s	
10985/33650 (epoch 16.322), train_loss = 1.10501266, grad/param norm = 1.5524e-01, time/batch = 14.3021s	
10986/33650 (epoch 16.324), train_loss = 1.12551294, grad/param norm = 1.5446e-01, time/batch = 13.7382s	
10987/33650 (epoch 16.325), train_loss = 1.12999005, grad/param norm = 1.4448e-01, time/batch = 13.9839s	
10988/33650 (epoch 16.327), train_loss = 0.95147674, grad/param norm = 1.2680e-01, time/batch = 13.6585s	
10989/33650 (epoch 16.328), train_loss = 1.12927810, grad/param norm = 1.5820e-01, time/batch = 14.0732s	
10990/33650 (epoch 16.330), train_loss = 0.96905341, grad/param norm = 1.2533e-01, time/batch = 14.0708s	
10991/33650 (epoch 16.331), train_loss = 0.87592728, grad/param norm = 1.2418e-01, time/batch = 13.8253s	
10992/33650 (epoch 16.333), train_loss = 1.02096811, grad/param norm = 1.3775e-01, time/batch = 13.7443s	
10993/33650 (epoch 16.334), train_loss = 1.02550771, grad/param norm = 1.4329e-01, time/batch = 14.2277s	
10994/33650 (epoch 16.336), train_loss = 1.16920764, grad/param norm = 1.4001e-01, time/batch = 14.2257s	
10995/33650 (epoch 16.337), train_loss = 0.85865926, grad/param norm = 1.1954e-01, time/batch = 13.7375s	
10996/33650 (epoch 16.339), train_loss = 1.02267536, grad/param norm = 1.2922e-01, time/batch = 13.7340s	
10997/33650 (epoch 16.340), train_loss = 1.21630620, grad/param norm = 1.5616e-01, time/batch = 13.9789s	
10998/33650 (epoch 16.342), train_loss = 0.88817406, grad/param norm = 1.3040e-01, time/batch = 14.2272s	
10999/33650 (epoch 16.343), train_loss = 1.09928408, grad/param norm = 1.4280e-01, time/batch = 13.8332s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch16.34_1.5519.t7	
11000/33650 (epoch 16.345), train_loss = 1.04273809, grad/param norm = 1.5326e-01, time/batch = 13.7416s	
11001/33650 (epoch 16.346), train_loss = 1.00571144, grad/param norm = 1.3495e-01, time/batch = 14.1421s	
11002/33650 (epoch 16.348), train_loss = 0.92191843, grad/param norm = 1.2289e-01, time/batch = 13.8223s	
11003/33650 (epoch 16.349), train_loss = 0.88569248, grad/param norm = 1.2895e-01, time/batch = 14.2093s	
11004/33650 (epoch 16.351), train_loss = 1.13409914, grad/param norm = 1.4517e-01, time/batch = 13.6494s	
11005/33650 (epoch 16.352), train_loss = 1.03468661, grad/param norm = 1.3641e-01, time/batch = 13.8900s	
11006/33650 (epoch 16.354), train_loss = 1.25247975, grad/param norm = 1.6975e-01, time/batch = 14.1566s	
11007/33650 (epoch 16.355), train_loss = 1.15361949, grad/param norm = 1.3692e-01, time/batch = 13.9930s	
11008/33650 (epoch 16.357), train_loss = 0.84500997, grad/param norm = 1.3376e-01, time/batch = 13.7436s	
11009/33650 (epoch 16.358), train_loss = 1.12823011, grad/param norm = 1.5453e-01, time/batch = 14.0707s	
11010/33650 (epoch 16.360), train_loss = 1.14494752, grad/param norm = 1.6196e-01, time/batch = 14.7084s	
11011/33650 (epoch 16.361), train_loss = 1.08163216, grad/param norm = 1.3869e-01, time/batch = 13.8212s	
11012/33650 (epoch 16.363), train_loss = 0.98243284, grad/param norm = 1.3699e-01, time/batch = 13.7355s	
11013/33650 (epoch 16.364), train_loss = 1.00883471, grad/param norm = 1.4038e-01, time/batch = 13.7306s	
11014/33650 (epoch 16.366), train_loss = 1.08463909, grad/param norm = 1.4753e-01, time/batch = 14.1383s	
11015/33650 (epoch 16.367), train_loss = 1.11375560, grad/param norm = 1.3250e-01, time/batch = 13.7355s	
11016/33650 (epoch 16.368), train_loss = 0.96348983, grad/param norm = 1.3575e-01, time/batch = 13.8260s	
11017/33650 (epoch 16.370), train_loss = 1.05330785, grad/param norm = 1.4355e-01, time/batch = 13.8195s	
11018/33650 (epoch 16.371), train_loss = 0.84662755, grad/param norm = 1.3235e-01, time/batch = 13.9893s	
11019/33650 (epoch 16.373), train_loss = 0.95180833, grad/param norm = 1.2792e-01, time/batch = 13.8242s	
11020/33650 (epoch 16.374), train_loss = 0.90398313, grad/param norm = 1.2181e-01, time/batch = 13.7359s	
11021/33650 (epoch 16.376), train_loss = 1.04251735, grad/param norm = 1.5445e-01, time/batch = 14.0597s	
11022/33650 (epoch 16.377), train_loss = 1.09083292, grad/param norm = 1.5579e-01, time/batch = 13.8267s	
11023/33650 (epoch 16.379), train_loss = 1.12264807, grad/param norm = 1.3982e-01, time/batch = 14.3015s	
11024/33650 (epoch 16.380), train_loss = 0.83003219, grad/param norm = 1.3418e-01, time/batch = 13.7318s	
11025/33650 (epoch 16.382), train_loss = 0.94699060, grad/param norm = 1.2020e-01, time/batch = 13.9094s	
11026/33650 (epoch 16.383), train_loss = 1.02053368, grad/param norm = 1.3698e-01, time/batch = 14.1535s	
11027/33650 (epoch 16.385), train_loss = 1.19415952, grad/param norm = 1.4891e-01, time/batch = 14.2163s	
11028/33650 (epoch 16.386), train_loss = 0.95856471, grad/param norm = 1.3303e-01, time/batch = 14.2156s	
11029/33650 (epoch 16.388), train_loss = 1.06867250, grad/param norm = 1.3334e-01, time/batch = 13.8252s	
11030/33650 (epoch 16.389), train_loss = 1.02615241, grad/param norm = 1.5007e-01, time/batch = 13.6536s	
11031/33650 (epoch 16.391), train_loss = 0.84828084, grad/param norm = 1.2374e-01, time/batch = 14.0674s	
11032/33650 (epoch 16.392), train_loss = 1.09631952, grad/param norm = 1.4229e-01, time/batch = 16.6428s	
11033/33650 (epoch 16.394), train_loss = 1.09946893, grad/param norm = 1.5687e-01, time/batch = 16.8873s	
11034/33650 (epoch 16.395), train_loss = 1.06915622, grad/param norm = 1.3556e-01, time/batch = 17.9762s	
11035/33650 (epoch 16.397), train_loss = 1.20614028, grad/param norm = 1.4830e-01, time/batch = 14.3968s	
11036/33650 (epoch 16.398), train_loss = 1.07520416, grad/param norm = 1.3428e-01, time/batch = 16.4842s	
11037/33650 (epoch 16.400), train_loss = 1.04963106, grad/param norm = 1.5627e-01, time/batch = 18.7208s	
11038/33650 (epoch 16.401), train_loss = 1.03415279, grad/param norm = 1.5919e-01, time/batch = 17.4768s	
11039/33650 (epoch 16.403), train_loss = 1.08875754, grad/param norm = 1.4985e-01, time/batch = 17.2952s	
11040/33650 (epoch 16.404), train_loss = 1.03973995, grad/param norm = 1.3711e-01, time/batch = 17.0630s	
11041/33650 (epoch 16.406), train_loss = 1.09137772, grad/param norm = 1.4535e-01, time/batch = 18.7177s	
11042/33650 (epoch 16.407), train_loss = 1.07150132, grad/param norm = 1.4734e-01, time/batch = 17.2154s	
11043/33650 (epoch 16.409), train_loss = 1.06875426, grad/param norm = 1.3766e-01, time/batch = 17.4636s	
11044/33650 (epoch 16.410), train_loss = 1.03876908, grad/param norm = 1.4257e-01, time/batch = 16.1348s	
11045/33650 (epoch 16.412), train_loss = 1.06762596, grad/param norm = 1.2949e-01, time/batch = 16.1214s	
11046/33650 (epoch 16.413), train_loss = 0.98002379, grad/param norm = 1.3810e-01, time/batch = 16.3956s	
11047/33650 (epoch 16.415), train_loss = 1.12637754, grad/param norm = 1.4292e-01, time/batch = 17.8838s	
11048/33650 (epoch 16.416), train_loss = 1.20062103, grad/param norm = 1.4979e-01, time/batch = 17.8951s	
11049/33650 (epoch 16.418), train_loss = 1.03419481, grad/param norm = 1.4134e-01, time/batch = 17.6386s	
11050/33650 (epoch 16.419), train_loss = 1.00303333, grad/param norm = 1.3741e-01, time/batch = 16.0647s	
11051/33650 (epoch 16.421), train_loss = 1.02191116, grad/param norm = 1.1740e-01, time/batch = 16.9051s	
11052/33650 (epoch 16.422), train_loss = 1.13943656, grad/param norm = 1.4496e-01, time/batch = 17.6356s	
11053/33650 (epoch 16.423), train_loss = 0.93911866, grad/param norm = 1.1704e-01, time/batch = 18.1398s	
11054/33650 (epoch 16.425), train_loss = 1.07600697, grad/param norm = 1.6461e-01, time/batch = 18.8964s	
11055/33650 (epoch 16.426), train_loss = 1.22289344, grad/param norm = 1.8486e-01, time/batch = 17.8155s	
11056/33650 (epoch 16.428), train_loss = 0.97419092, grad/param norm = 1.3868e-01, time/batch = 17.8075s	
11057/33650 (epoch 16.429), train_loss = 1.13137438, grad/param norm = 1.5302e-01, time/batch = 17.2342s	
11058/33650 (epoch 16.431), train_loss = 1.23972841, grad/param norm = 1.6720e-01, time/batch = 17.4591s	
11059/33650 (epoch 16.432), train_loss = 1.28753747, grad/param norm = 1.6569e-01, time/batch = 17.4756s	
11060/33650 (epoch 16.434), train_loss = 1.08689133, grad/param norm = 1.3846e-01, time/batch = 18.0652s	
11061/33650 (epoch 16.435), train_loss = 1.07462888, grad/param norm = 1.6060e-01, time/batch = 17.9798s	
11062/33650 (epoch 16.437), train_loss = 1.06571368, grad/param norm = 1.6195e-01, time/batch = 17.8107s	
11063/33650 (epoch 16.438), train_loss = 0.99887545, grad/param norm = 1.5847e-01, time/batch = 18.1319s	
11064/33650 (epoch 16.440), train_loss = 1.08671393, grad/param norm = 1.6269e-01, time/batch = 18.1529s	
11065/33650 (epoch 16.441), train_loss = 1.09064962, grad/param norm = 1.5268e-01, time/batch = 17.8096s	
11066/33650 (epoch 16.443), train_loss = 1.10323758, grad/param norm = 1.3245e-01, time/batch = 15.7194s	
11067/33650 (epoch 16.444), train_loss = 1.01454689, grad/param norm = 1.3325e-01, time/batch = 18.5490s	
11068/33650 (epoch 16.446), train_loss = 1.11403071, grad/param norm = 1.6705e-01, time/batch = 17.7337s	
11069/33650 (epoch 16.447), train_loss = 1.16126471, grad/param norm = 1.6475e-01, time/batch = 14.7643s	
11070/33650 (epoch 16.449), train_loss = 1.22073641, grad/param norm = 1.8597e-01, time/batch = 15.0574s	
11071/33650 (epoch 16.450), train_loss = 1.26680596, grad/param norm = 1.6644e-01, time/batch = 16.5663s	
11072/33650 (epoch 16.452), train_loss = 1.27677738, grad/param norm = 1.7434e-01, time/batch = 15.9973s	
11073/33650 (epoch 16.453), train_loss = 1.23379067, grad/param norm = 1.6501e-01, time/batch = 15.6393s	
11074/33650 (epoch 16.455), train_loss = 1.03912430, grad/param norm = 1.5325e-01, time/batch = 15.9613s	
11075/33650 (epoch 16.456), train_loss = 1.05253450, grad/param norm = 1.2949e-01, time/batch = 16.9667s	
11076/33650 (epoch 16.458), train_loss = 1.04004423, grad/param norm = 1.6639e-01, time/batch = 15.9515s	
11077/33650 (epoch 16.459), train_loss = 1.08487865, grad/param norm = 1.6143e-01, time/batch = 16.8880s	
11078/33650 (epoch 16.461), train_loss = 1.23761675, grad/param norm = 1.5837e-01, time/batch = 17.5682s	
11079/33650 (epoch 16.462), train_loss = 1.20046264, grad/param norm = 1.6566e-01, time/batch = 17.7418s	
11080/33650 (epoch 16.464), train_loss = 1.01710769, grad/param norm = 1.5261e-01, time/batch = 16.9735s	
11081/33650 (epoch 16.465), train_loss = 1.09976174, grad/param norm = 1.6022e-01, time/batch = 16.7999s	
11082/33650 (epoch 16.467), train_loss = 1.11400131, grad/param norm = 1.4580e-01, time/batch = 18.2377s	
11083/33650 (epoch 16.468), train_loss = 1.17886656, grad/param norm = 1.5018e-01, time/batch = 16.8923s	
11084/33650 (epoch 16.470), train_loss = 1.31263776, grad/param norm = 1.7670e-01, time/batch = 17.8917s	
11085/33650 (epoch 16.471), train_loss = 1.06487294, grad/param norm = 1.5995e-01, time/batch = 18.3952s	
11086/33650 (epoch 16.473), train_loss = 1.02602561, grad/param norm = 1.4800e-01, time/batch = 17.3954s	
11087/33650 (epoch 16.474), train_loss = 1.14940759, grad/param norm = 1.4364e-01, time/batch = 16.8984s	
11088/33650 (epoch 16.475), train_loss = 1.13885326, grad/param norm = 1.5013e-01, time/batch = 17.7379s	
11089/33650 (epoch 16.477), train_loss = 1.19153487, grad/param norm = 1.4785e-01, time/batch = 18.6500s	
11090/33650 (epoch 16.478), train_loss = 1.19836495, grad/param norm = 1.5913e-01, time/batch = 16.8979s	
11091/33650 (epoch 16.480), train_loss = 1.17550316, grad/param norm = 1.7263e-01, time/batch = 17.6556s	
11092/33650 (epoch 16.481), train_loss = 1.24495157, grad/param norm = 1.6165e-01, time/batch = 17.6482s	
11093/33650 (epoch 16.483), train_loss = 0.87607070, grad/param norm = 1.3276e-01, time/batch = 17.4725s	
11094/33650 (epoch 16.484), train_loss = 1.07336462, grad/param norm = 1.5416e-01, time/batch = 18.0429s	
11095/33650 (epoch 16.486), train_loss = 1.21223546, grad/param norm = 1.8047e-01, time/batch = 18.7369s	
11096/33650 (epoch 16.487), train_loss = 1.22346494, grad/param norm = 1.7223e-01, time/batch = 18.4789s	
11097/33650 (epoch 16.489), train_loss = 1.23964610, grad/param norm = 1.4861e-01, time/batch = 17.3059s	
11098/33650 (epoch 16.490), train_loss = 0.98285897, grad/param norm = 1.4531e-01, time/batch = 18.6500s	
11099/33650 (epoch 16.492), train_loss = 1.10480178, grad/param norm = 1.4906e-01, time/batch = 17.3803s	
11100/33650 (epoch 16.493), train_loss = 0.89876725, grad/param norm = 1.2879e-01, time/batch = 16.6364s	
11101/33650 (epoch 16.495), train_loss = 1.09738232, grad/param norm = 1.5230e-01, time/batch = 18.8944s	
11102/33650 (epoch 16.496), train_loss = 1.13602293, grad/param norm = 1.5107e-01, time/batch = 18.8200s	
11103/33650 (epoch 16.498), train_loss = 0.97443838, grad/param norm = 1.3893e-01, time/batch = 16.4780s	
11104/33650 (epoch 16.499), train_loss = 1.04508324, grad/param norm = 1.2334e-01, time/batch = 15.7877s	
11105/33650 (epoch 16.501), train_loss = 1.04318284, grad/param norm = 1.3125e-01, time/batch = 18.3989s	
11106/33650 (epoch 16.502), train_loss = 1.08658454, grad/param norm = 1.6841e-01, time/batch = 17.8251s	
11107/33650 (epoch 16.504), train_loss = 1.19253212, grad/param norm = 1.6387e-01, time/batch = 18.1422s	
11108/33650 (epoch 16.505), train_loss = 1.02411618, grad/param norm = 1.4882e-01, time/batch = 18.1317s	
11109/33650 (epoch 16.507), train_loss = 1.19103534, grad/param norm = 1.5074e-01, time/batch = 17.9742s	
11110/33650 (epoch 16.508), train_loss = 1.04206411, grad/param norm = 1.4212e-01, time/batch = 16.9000s	
11111/33650 (epoch 16.510), train_loss = 1.06166273, grad/param norm = 1.4759e-01, time/batch = 17.3158s	
11112/33650 (epoch 16.511), train_loss = 1.30962433, grad/param norm = 1.6573e-01, time/batch = 17.5586s	
11113/33650 (epoch 16.513), train_loss = 1.13758083, grad/param norm = 1.4549e-01, time/batch = 17.1409s	
11114/33650 (epoch 16.514), train_loss = 1.17476008, grad/param norm = 1.5563e-01, time/batch = 17.8659s	
11115/33650 (epoch 16.516), train_loss = 1.10319553, grad/param norm = 1.5790e-01, time/batch = 17.8954s	
11116/33650 (epoch 16.517), train_loss = 1.08092619, grad/param norm = 1.4757e-01, time/batch = 17.6451s	
11117/33650 (epoch 16.519), train_loss = 1.14276581, grad/param norm = 1.5835e-01, time/batch = 16.0436s	
11118/33650 (epoch 16.520), train_loss = 0.92897817, grad/param norm = 1.3078e-01, time/batch = 17.7034s	
11119/33650 (epoch 16.522), train_loss = 1.06197485, grad/param norm = 1.7659e-01, time/batch = 17.3993s	
11120/33650 (epoch 16.523), train_loss = 1.03797721, grad/param norm = 1.3467e-01, time/batch = 18.4815s	
11121/33650 (epoch 16.525), train_loss = 0.85545035, grad/param norm = 1.2457e-01, time/batch = 17.7168s	
11122/33650 (epoch 16.526), train_loss = 1.16386040, grad/param norm = 1.3866e-01, time/batch = 17.3069s	
11123/33650 (epoch 16.527), train_loss = 1.00187363, grad/param norm = 1.3447e-01, time/batch = 18.2360s	
11124/33650 (epoch 16.529), train_loss = 1.06742461, grad/param norm = 1.4121e-01, time/batch = 16.9699s	
11125/33650 (epoch 16.530), train_loss = 1.03158163, grad/param norm = 1.4534e-01, time/batch = 18.1425s	
11126/33650 (epoch 16.532), train_loss = 1.21852272, grad/param norm = 1.9227e-01, time/batch = 16.9036s	
11127/33650 (epoch 16.533), train_loss = 1.05164735, grad/param norm = 1.6805e-01, time/batch = 18.3192s	
11128/33650 (epoch 16.535), train_loss = 1.16193708, grad/param norm = 1.5816e-01, time/batch = 17.5493s	
11129/33650 (epoch 16.536), train_loss = 1.11200396, grad/param norm = 1.5286e-01, time/batch = 17.7439s	
11130/33650 (epoch 16.538), train_loss = 1.13955765, grad/param norm = 1.6381e-01, time/batch = 16.7112s	
11131/33650 (epoch 16.539), train_loss = 0.88332886, grad/param norm = 1.3956e-01, time/batch = 18.0471s	
11132/33650 (epoch 16.541), train_loss = 1.19824604, grad/param norm = 1.6478e-01, time/batch = 18.4010s	
11133/33650 (epoch 16.542), train_loss = 1.13119582, grad/param norm = 2.0165e-01, time/batch = 15.8935s	
11134/33650 (epoch 16.544), train_loss = 1.28621471, grad/param norm = 1.9013e-01, time/batch = 16.8096s	
11135/33650 (epoch 16.545), train_loss = 0.94212987, grad/param norm = 1.3065e-01, time/batch = 18.7149s	
11136/33650 (epoch 16.547), train_loss = 1.09778542, grad/param norm = 1.6063e-01, time/batch = 17.8058s	
11137/33650 (epoch 16.548), train_loss = 1.26667562, grad/param norm = 1.5949e-01, time/batch = 17.6407s	
11138/33650 (epoch 16.550), train_loss = 1.07405181, grad/param norm = 1.4250e-01, time/batch = 17.4709s	
11139/33650 (epoch 16.551), train_loss = 1.11273518, grad/param norm = 1.6643e-01, time/batch = 17.8932s	
11140/33650 (epoch 16.553), train_loss = 0.98244938, grad/param norm = 1.6296e-01, time/batch = 18.3947s	
11141/33650 (epoch 16.554), train_loss = 1.20577972, grad/param norm = 1.5106e-01, time/batch = 17.8849s	
11142/33650 (epoch 16.556), train_loss = 1.14924813, grad/param norm = 1.7183e-01, time/batch = 17.8999s	
11143/33650 (epoch 16.557), train_loss = 1.18378110, grad/param norm = 1.5873e-01, time/batch = 18.2365s	
11144/33650 (epoch 16.559), train_loss = 1.35922974, grad/param norm = 1.7640e-01, time/batch = 16.1349s	
11145/33650 (epoch 16.560), train_loss = 1.28763446, grad/param norm = 1.5471e-01, time/batch = 17.9894s	
11146/33650 (epoch 16.562), train_loss = 1.18778654, grad/param norm = 1.4254e-01, time/batch = 16.4887s	
11147/33650 (epoch 16.563), train_loss = 1.10735109, grad/param norm = 1.4663e-01, time/batch = 17.5603s	
11148/33650 (epoch 16.565), train_loss = 1.09581052, grad/param norm = 1.4485e-01, time/batch = 16.8850s	
11149/33650 (epoch 16.566), train_loss = 1.07007294, grad/param norm = 1.5494e-01, time/batch = 18.2285s	
11150/33650 (epoch 16.568), train_loss = 1.11160899, grad/param norm = 1.6765e-01, time/batch = 18.1481s	
11151/33650 (epoch 16.569), train_loss = 1.01741154, grad/param norm = 1.3857e-01, time/batch = 16.8922s	
11152/33650 (epoch 16.571), train_loss = 1.21426761, grad/param norm = 1.5789e-01, time/batch = 18.1464s	
11153/33650 (epoch 16.572), train_loss = 1.13964797, grad/param norm = 1.3599e-01, time/batch = 17.7398s	
11154/33650 (epoch 16.574), train_loss = 1.09124946, grad/param norm = 1.6572e-01, time/batch = 19.4475s	
11155/33650 (epoch 16.575), train_loss = 1.06975842, grad/param norm = 1.4875e-01, time/batch = 28.9101s	
11156/33650 (epoch 16.577), train_loss = 1.06674531, grad/param norm = 1.4974e-01, time/batch = 17.8702s	
11157/33650 (epoch 16.578), train_loss = 1.14329702, grad/param norm = 1.4446e-01, time/batch = 15.5298s	
11158/33650 (epoch 16.579), train_loss = 1.15021189, grad/param norm = 1.5301e-01, time/batch = 18.0539s	
11159/33650 (epoch 16.581), train_loss = 1.19731885, grad/param norm = 1.5536e-01, time/batch = 16.0665s	
11160/33650 (epoch 16.582), train_loss = 1.15874976, grad/param norm = 1.3729e-01, time/batch = 18.0635s	
11161/33650 (epoch 16.584), train_loss = 1.16220224, grad/param norm = 1.5725e-01, time/batch = 17.3846s	
11162/33650 (epoch 16.585), train_loss = 1.15542599, grad/param norm = 1.5921e-01, time/batch = 18.2344s	
11163/33650 (epoch 16.587), train_loss = 0.99464853, grad/param norm = 1.3450e-01, time/batch = 16.3942s	
11164/33650 (epoch 16.588), train_loss = 1.03109957, grad/param norm = 1.7116e-01, time/batch = 17.1336s	
11165/33650 (epoch 16.590), train_loss = 1.03886871, grad/param norm = 1.3331e-01, time/batch = 17.8146s	
11166/33650 (epoch 16.591), train_loss = 1.02122890, grad/param norm = 1.5178e-01, time/batch = 17.9890s	
11167/33650 (epoch 16.593), train_loss = 0.98656663, grad/param norm = 1.3788e-01, time/batch = 17.4667s	
11168/33650 (epoch 16.594), train_loss = 0.96705476, grad/param norm = 1.5370e-01, time/batch = 17.9795s	
11169/33650 (epoch 16.596), train_loss = 1.07149434, grad/param norm = 1.4205e-01, time/batch = 17.9080s	
11170/33650 (epoch 16.597), train_loss = 0.89729634, grad/param norm = 1.2046e-01, time/batch = 17.9787s	
11171/33650 (epoch 16.599), train_loss = 1.05867636, grad/param norm = 1.5739e-01, time/batch = 17.8868s	
11172/33650 (epoch 16.600), train_loss = 0.97931505, grad/param norm = 1.3964e-01, time/batch = 18.5691s	
11173/33650 (epoch 16.602), train_loss = 1.13809099, grad/param norm = 1.4306e-01, time/batch = 17.2120s	
11174/33650 (epoch 16.603), train_loss = 1.01082690, grad/param norm = 1.3796e-01, time/batch = 16.0687s	
11175/33650 (epoch 16.605), train_loss = 1.15000413, grad/param norm = 1.6145e-01, time/batch = 17.8896s	
11176/33650 (epoch 16.606), train_loss = 1.17540063, grad/param norm = 1.8126e-01, time/batch = 17.2322s	
11177/33650 (epoch 16.608), train_loss = 1.01116724, grad/param norm = 1.5319e-01, time/batch = 17.9886s	
11178/33650 (epoch 16.609), train_loss = 1.09402381, grad/param norm = 1.6059e-01, time/batch = 16.8172s	
11179/33650 (epoch 16.611), train_loss = 0.94236668, grad/param norm = 1.3284e-01, time/batch = 17.6483s	
11180/33650 (epoch 16.612), train_loss = 1.07340182, grad/param norm = 1.4942e-01, time/batch = 17.3216s	
11181/33650 (epoch 16.614), train_loss = 1.15697199, grad/param norm = 1.5601e-01, time/batch = 17.5606s	
11182/33650 (epoch 16.615), train_loss = 1.02958601, grad/param norm = 1.2402e-01, time/batch = 16.8840s	
11183/33650 (epoch 16.617), train_loss = 0.97549175, grad/param norm = 1.2240e-01, time/batch = 18.7295s	
11184/33650 (epoch 16.618), train_loss = 1.04592097, grad/param norm = 1.4344e-01, time/batch = 17.3869s	
11185/33650 (epoch 16.620), train_loss = 1.11434384, grad/param norm = 1.6389e-01, time/batch = 17.7273s	
11186/33650 (epoch 16.621), train_loss = 0.97268968, grad/param norm = 1.3921e-01, time/batch = 18.0669s	
11187/33650 (epoch 16.623), train_loss = 1.04830986, grad/param norm = 1.5021e-01, time/batch = 18.1513s	
11188/33650 (epoch 16.624), train_loss = 0.84147817, grad/param norm = 1.3589e-01, time/batch = 17.3016s	
11189/33650 (epoch 16.626), train_loss = 0.82474400, grad/param norm = 1.2209e-01, time/batch = 17.9874s	
11190/33650 (epoch 16.627), train_loss = 0.97950845, grad/param norm = 1.5511e-01, time/batch = 17.8936s	
11191/33650 (epoch 16.629), train_loss = 1.03654178, grad/param norm = 1.3667e-01, time/batch = 16.6414s	
11192/33650 (epoch 16.630), train_loss = 1.16066412, grad/param norm = 1.7459e-01, time/batch = 18.4754s	
11193/33650 (epoch 16.632), train_loss = 1.17580107, grad/param norm = 1.4239e-01, time/batch = 17.6379s	
11194/33650 (epoch 16.633), train_loss = 1.17035507, grad/param norm = 1.4495e-01, time/batch = 17.2906s	
11195/33650 (epoch 16.634), train_loss = 0.91931039, grad/param norm = 1.3123e-01, time/batch = 16.4596s	
11196/33650 (epoch 16.636), train_loss = 0.80529974, grad/param norm = 1.1090e-01, time/batch = 18.1399s	
11197/33650 (epoch 16.637), train_loss = 1.03174576, grad/param norm = 1.4924e-01, time/batch = 17.9832s	
11198/33650 (epoch 16.639), train_loss = 1.01120697, grad/param norm = 1.3938e-01, time/batch = 17.0538s	
11199/33650 (epoch 16.640), train_loss = 1.06603806, grad/param norm = 1.5093e-01, time/batch = 17.9001s	
11200/33650 (epoch 16.642), train_loss = 1.14655133, grad/param norm = 1.6242e-01, time/batch = 17.4869s	
11201/33650 (epoch 16.643), train_loss = 1.06739089, grad/param norm = 1.5480e-01, time/batch = 17.6292s	
11202/33650 (epoch 16.645), train_loss = 1.06995251, grad/param norm = 1.3646e-01, time/batch = 18.1554s	
11203/33650 (epoch 16.646), train_loss = 0.90211133, grad/param norm = 1.2157e-01, time/batch = 18.4852s	
11204/33650 (epoch 16.648), train_loss = 1.07039862, grad/param norm = 1.3397e-01, time/batch = 17.4844s	
11205/33650 (epoch 16.649), train_loss = 1.02855788, grad/param norm = 1.6430e-01, time/batch = 17.4509s	
11206/33650 (epoch 16.651), train_loss = 1.20223684, grad/param norm = 1.6239e-01, time/batch = 17.9922s	
11207/33650 (epoch 16.652), train_loss = 0.77310697, grad/param norm = 1.1847e-01, time/batch = 18.0555s	
11208/33650 (epoch 16.654), train_loss = 0.97589350, grad/param norm = 1.3480e-01, time/batch = 16.2195s	
11209/33650 (epoch 16.655), train_loss = 0.92666249, grad/param norm = 1.2105e-01, time/batch = 18.8190s	
11210/33650 (epoch 16.657), train_loss = 1.01775899, grad/param norm = 1.4729e-01, time/batch = 17.0667s	
11211/33650 (epoch 16.658), train_loss = 0.90996895, grad/param norm = 1.3504e-01, time/batch = 17.5461s	
11212/33650 (epoch 16.660), train_loss = 0.85946466, grad/param norm = 1.3417e-01, time/batch = 17.8873s	
11213/33650 (epoch 16.661), train_loss = 0.97965193, grad/param norm = 1.2112e-01, time/batch = 18.3958s	
11214/33650 (epoch 16.663), train_loss = 0.92027489, grad/param norm = 1.4979e-01, time/batch = 17.1256s	
11215/33650 (epoch 16.664), train_loss = 0.93984530, grad/param norm = 1.2749e-01, time/batch = 16.1418s	
11216/33650 (epoch 16.666), train_loss = 0.99008527, grad/param norm = 1.3012e-01, time/batch = 16.8903s	
11217/33650 (epoch 16.667), train_loss = 0.93307760, grad/param norm = 1.2912e-01, time/batch = 18.3909s	
11218/33650 (epoch 16.669), train_loss = 0.94823183, grad/param norm = 1.4692e-01, time/batch = 17.3794s	
11219/33650 (epoch 16.670), train_loss = 0.87208814, grad/param norm = 1.4149e-01, time/batch = 16.8980s	
11220/33650 (epoch 16.672), train_loss = 0.89721348, grad/param norm = 1.4994e-01, time/batch = 18.4901s	
11221/33650 (epoch 16.673), train_loss = 0.84286149, grad/param norm = 1.3117e-01, time/batch = 18.4771s	
11222/33650 (epoch 16.675), train_loss = 0.82788797, grad/param norm = 1.1366e-01, time/batch = 17.0563s	
11223/33650 (epoch 16.676), train_loss = 1.03090782, grad/param norm = 1.5526e-01, time/batch = 18.6441s	
11224/33650 (epoch 16.678), train_loss = 0.95125664, grad/param norm = 1.2953e-01, time/batch = 15.9767s	
11225/33650 (epoch 16.679), train_loss = 1.00362651, grad/param norm = 1.5376e-01, time/batch = 16.8143s	
11226/33650 (epoch 16.681), train_loss = 0.98834194, grad/param norm = 1.2974e-01, time/batch = 17.3299s	
11227/33650 (epoch 16.682), train_loss = 0.94103394, grad/param norm = 1.3673e-01, time/batch = 16.0616s	
11228/33650 (epoch 16.684), train_loss = 0.90912224, grad/param norm = 1.2636e-01, time/batch = 18.3023s	
11229/33650 (epoch 16.685), train_loss = 1.11857992, grad/param norm = 1.5202e-01, time/batch = 17.7930s	
11230/33650 (epoch 16.686), train_loss = 1.05430070, grad/param norm = 1.3928e-01, time/batch = 18.0690s	
11231/33650 (epoch 16.688), train_loss = 1.14619747, grad/param norm = 1.4775e-01, time/batch = 17.4085s	
11232/33650 (epoch 16.689), train_loss = 0.93837089, grad/param norm = 1.2697e-01, time/batch = 16.7110s	
11233/33650 (epoch 16.691), train_loss = 1.16248277, grad/param norm = 1.5006e-01, time/batch = 18.0708s	
11234/33650 (epoch 16.692), train_loss = 1.15302859, grad/param norm = 1.4196e-01, time/batch = 17.6485s	
11235/33650 (epoch 16.694), train_loss = 1.07204732, grad/param norm = 1.5432e-01, time/batch = 17.1405s	
11236/33650 (epoch 16.695), train_loss = 0.75622953, grad/param norm = 1.2550e-01, time/batch = 18.2336s	
11237/33650 (epoch 16.697), train_loss = 1.00651293, grad/param norm = 1.5168e-01, time/batch = 17.4786s	
11238/33650 (epoch 16.698), train_loss = 1.19173088, grad/param norm = 1.6641e-01, time/batch = 18.4015s	
11239/33650 (epoch 16.700), train_loss = 1.01234195, grad/param norm = 1.4564e-01, time/batch = 17.5530s	
11240/33650 (epoch 16.701), train_loss = 1.06006770, grad/param norm = 1.4641e-01, time/batch = 18.1410s	
11241/33650 (epoch 16.703), train_loss = 1.18154193, grad/param norm = 1.3353e-01, time/batch = 16.7868s	
11242/33650 (epoch 16.704), train_loss = 0.99601012, grad/param norm = 1.2729e-01, time/batch = 16.8888s	
11243/33650 (epoch 16.706), train_loss = 0.99685577, grad/param norm = 1.3904e-01, time/batch = 18.2305s	
11244/33650 (epoch 16.707), train_loss = 1.11918926, grad/param norm = 1.4502e-01, time/batch = 16.4852s	
11245/33650 (epoch 16.709), train_loss = 1.01044158, grad/param norm = 1.4052e-01, time/batch = 17.0650s	
11246/33650 (epoch 16.710), train_loss = 1.22274541, grad/param norm = 1.4748e-01, time/batch = 16.4579s	
11247/33650 (epoch 16.712), train_loss = 0.96058955, grad/param norm = 1.4370e-01, time/batch = 18.3849s	
11248/33650 (epoch 16.713), train_loss = 0.95205377, grad/param norm = 1.8147e-01, time/batch = 17.9042s	
11249/33650 (epoch 16.715), train_loss = 1.13756244, grad/param norm = 1.6897e-01, time/batch = 16.6584s	
11250/33650 (epoch 16.716), train_loss = 0.94876376, grad/param norm = 1.3764e-01, time/batch = 17.3703s	
11251/33650 (epoch 16.718), train_loss = 1.01024858, grad/param norm = 1.5858e-01, time/batch = 17.8198s	
11252/33650 (epoch 16.719), train_loss = 1.18370484, grad/param norm = 1.6660e-01, time/batch = 17.4029s	
11253/33650 (epoch 16.721), train_loss = 1.25529090, grad/param norm = 1.7137e-01, time/batch = 17.8116s	
11254/33650 (epoch 16.722), train_loss = 1.12574722, grad/param norm = 1.6616e-01, time/batch = 18.7298s	
11255/33650 (epoch 16.724), train_loss = 1.13883927, grad/param norm = 1.5749e-01, time/batch = 18.0579s	
11256/33650 (epoch 16.725), train_loss = 1.13188495, grad/param norm = 1.4440e-01, time/batch = 16.6254s	
11257/33650 (epoch 16.727), train_loss = 0.95911634, grad/param norm = 1.5447e-01, time/batch = 18.1408s	
11258/33650 (epoch 16.728), train_loss = 0.98513520, grad/param norm = 1.3200e-01, time/batch = 18.6420s	
11259/33650 (epoch 16.730), train_loss = 1.08952726, grad/param norm = 1.4644e-01, time/batch = 16.8767s	
11260/33650 (epoch 16.731), train_loss = 1.16530240, grad/param norm = 1.5243e-01, time/batch = 18.1438s	
11261/33650 (epoch 16.733), train_loss = 1.04483811, grad/param norm = 1.5513e-01, time/batch = 17.8972s	
11262/33650 (epoch 16.734), train_loss = 1.17608653, grad/param norm = 1.5990e-01, time/batch = 17.2335s	
11263/33650 (epoch 16.736), train_loss = 1.05679636, grad/param norm = 1.5493e-01, time/batch = 17.3064s	
11264/33650 (epoch 16.737), train_loss = 1.08669310, grad/param norm = 1.6346e-01, time/batch = 16.9670s	
11265/33650 (epoch 16.738), train_loss = 0.93257495, grad/param norm = 1.4025e-01, time/batch = 17.6418s	
11266/33650 (epoch 16.740), train_loss = 0.90976603, grad/param norm = 1.3679e-01, time/batch = 17.0560s	
11267/33650 (epoch 16.741), train_loss = 0.97857817, grad/param norm = 1.4960e-01, time/batch = 18.3935s	
11268/33650 (epoch 16.743), train_loss = 1.02765315, grad/param norm = 1.3960e-01, time/batch = 18.0571s	
11269/33650 (epoch 16.744), train_loss = 1.05490914, grad/param norm = 1.3253e-01, time/batch = 15.8790s	
11270/33650 (epoch 16.746), train_loss = 1.02172506, grad/param norm = 1.3437e-01, time/batch = 18.2253s	
11271/33650 (epoch 16.747), train_loss = 1.14164098, grad/param norm = 1.4533e-01, time/batch = 18.3155s	
11272/33650 (epoch 16.749), train_loss = 0.88155335, grad/param norm = 1.3665e-01, time/batch = 17.9934s	
11273/33650 (epoch 16.750), train_loss = 1.16908840, grad/param norm = 1.5359e-01, time/batch = 17.5562s	
11274/33650 (epoch 16.752), train_loss = 1.16383578, grad/param norm = 1.4321e-01, time/batch = 15.8092s	
11275/33650 (epoch 16.753), train_loss = 1.27641171, grad/param norm = 1.6427e-01, time/batch = 17.8197s	
11276/33650 (epoch 16.755), train_loss = 1.00284232, grad/param norm = 1.3630e-01, time/batch = 17.6414s	
11277/33650 (epoch 16.756), train_loss = 1.13650523, grad/param norm = 1.5814e-01, time/batch = 18.2320s	
11278/33650 (epoch 16.758), train_loss = 1.12730112, grad/param norm = 1.4613e-01, time/batch = 17.5504s	
11279/33650 (epoch 16.759), train_loss = 1.18801572, grad/param norm = 1.4956e-01, time/batch = 17.3761s	
11280/33650 (epoch 16.761), train_loss = 1.09830099, grad/param norm = 1.4811e-01, time/batch = 17.2132s	
11281/33650 (epoch 16.762), train_loss = 1.06071261, grad/param norm = 1.4869e-01, time/batch = 18.4805s	
11282/33650 (epoch 16.764), train_loss = 1.10191899, grad/param norm = 1.4674e-01, time/batch = 17.3737s	
11283/33650 (epoch 16.765), train_loss = 1.05846585, grad/param norm = 1.4934e-01, time/batch = 16.6420s	
11284/33650 (epoch 16.767), train_loss = 1.03134667, grad/param norm = 1.3475e-01, time/batch = 17.8964s	
11285/33650 (epoch 16.768), train_loss = 0.92941200, grad/param norm = 1.3231e-01, time/batch = 15.7210s	
11286/33650 (epoch 16.770), train_loss = 1.09230197, grad/param norm = 1.4480e-01, time/batch = 17.4730s	
11287/33650 (epoch 16.771), train_loss = 1.06582309, grad/param norm = 1.4504e-01, time/batch = 17.6461s	
11288/33650 (epoch 16.773), train_loss = 1.19896421, grad/param norm = 1.6505e-01, time/batch = 17.9864s	
11289/33650 (epoch 16.774), train_loss = 1.10332400, grad/param norm = 1.5916e-01, time/batch = 16.2436s	
11290/33650 (epoch 16.776), train_loss = 1.14564248, grad/param norm = 1.6163e-01, time/batch = 17.4476s	
11291/33650 (epoch 16.777), train_loss = 0.94086023, grad/param norm = 1.5651e-01, time/batch = 18.0679s	
11292/33650 (epoch 16.779), train_loss = 1.03368555, grad/param norm = 1.4420e-01, time/batch = 18.6432s	
11293/33650 (epoch 16.780), train_loss = 0.96118463, grad/param norm = 1.2297e-01, time/batch = 17.5490s	
11294/33650 (epoch 16.782), train_loss = 0.97930628, grad/param norm = 1.4384e-01, time/batch = 17.5510s	
11295/33650 (epoch 16.783), train_loss = 0.94098673, grad/param norm = 1.3078e-01, time/batch = 17.1515s	
11296/33650 (epoch 16.785), train_loss = 1.25899516, grad/param norm = 1.4932e-01, time/batch = 18.1518s	
11297/33650 (epoch 16.786), train_loss = 1.09479944, grad/param norm = 1.3219e-01, time/batch = 17.7372s	
11298/33650 (epoch 16.788), train_loss = 1.10004357, grad/param norm = 1.4116e-01, time/batch = 17.8163s	
11299/33650 (epoch 16.789), train_loss = 1.11727965, grad/param norm = 1.4969e-01, time/batch = 18.8160s	
11300/33650 (epoch 16.790), train_loss = 1.09414447, grad/param norm = 1.7711e-01, time/batch = 16.7007s	
11301/33650 (epoch 16.792), train_loss = 1.18463467, grad/param norm = 1.7515e-01, time/batch = 18.1543s	
11302/33650 (epoch 16.793), train_loss = 1.14622368, grad/param norm = 1.8302e-01, time/batch = 18.3829s	
11303/33650 (epoch 16.795), train_loss = 1.21683431, grad/param norm = 1.4976e-01, time/batch = 16.8816s	
11304/33650 (epoch 16.796), train_loss = 1.04289458, grad/param norm = 1.4961e-01, time/batch = 17.4847s	
11305/33650 (epoch 16.798), train_loss = 1.01786391, grad/param norm = 1.3706e-01, time/batch = 18.6450s	
11306/33650 (epoch 16.799), train_loss = 1.05854471, grad/param norm = 1.4869e-01, time/batch = 17.5565s	
11307/33650 (epoch 16.801), train_loss = 1.11064115, grad/param norm = 1.5307e-01, time/batch = 16.7199s	
11308/33650 (epoch 16.802), train_loss = 1.17087278, grad/param norm = 1.5505e-01, time/batch = 17.9070s	
11309/33650 (epoch 16.804), train_loss = 1.07436057, grad/param norm = 1.7579e-01, time/batch = 19.0662s	
11310/33650 (epoch 16.805), train_loss = 1.02509034, grad/param norm = 1.2429e-01, time/batch = 17.3116s	
11311/33650 (epoch 16.807), train_loss = 1.29167196, grad/param norm = 1.8955e-01, time/batch = 16.9684s	
11312/33650 (epoch 16.808), train_loss = 1.31018538, grad/param norm = 1.7547e-01, time/batch = 16.2253s	
11313/33650 (epoch 16.810), train_loss = 1.13243354, grad/param norm = 1.5232e-01, time/batch = 15.1437s	
11314/33650 (epoch 16.811), train_loss = 1.09516943, grad/param norm = 1.4723e-01, time/batch = 16.8762s	
11315/33650 (epoch 16.813), train_loss = 1.02487929, grad/param norm = 1.4955e-01, time/batch = 18.1423s	
11316/33650 (epoch 16.814), train_loss = 1.15281227, grad/param norm = 1.5508e-01, time/batch = 17.8169s	
11317/33650 (epoch 16.816), train_loss = 1.11125756, grad/param norm = 1.5966e-01, time/batch = 17.2196s	
11318/33650 (epoch 16.817), train_loss = 1.15724504, grad/param norm = 1.6347e-01, time/batch = 18.2201s	
11319/33650 (epoch 16.819), train_loss = 1.14257597, grad/param norm = 1.4530e-01, time/batch = 17.7249s	
11320/33650 (epoch 16.820), train_loss = 1.20969809, grad/param norm = 1.4564e-01, time/batch = 16.8894s	
11321/33650 (epoch 16.822), train_loss = 1.13600346, grad/param norm = 1.6682e-01, time/batch = 17.8924s	
11322/33650 (epoch 16.823), train_loss = 1.00388942, grad/param norm = 1.5237e-01, time/batch = 18.4002s	
11323/33650 (epoch 16.825), train_loss = 1.06077748, grad/param norm = 1.3504e-01, time/batch = 18.4022s	
11324/33650 (epoch 16.826), train_loss = 1.12940389, grad/param norm = 1.3959e-01, time/batch = 17.6372s	
11325/33650 (epoch 16.828), train_loss = 1.26330601, grad/param norm = 1.5223e-01, time/batch = 17.8192s	
11326/33650 (epoch 16.829), train_loss = 0.91555522, grad/param norm = 1.4013e-01, time/batch = 17.9682s	
11327/33650 (epoch 16.831), train_loss = 1.16518986, grad/param norm = 1.6004e-01, time/batch = 15.8035s	
11328/33650 (epoch 16.832), train_loss = 1.12687081, grad/param norm = 1.4520e-01, time/batch = 18.3958s	
11329/33650 (epoch 16.834), train_loss = 1.15805259, grad/param norm = 1.6804e-01, time/batch = 17.2349s	
11330/33650 (epoch 16.835), train_loss = 1.33123445, grad/param norm = 1.7805e-01, time/batch = 17.1479s	
11331/33650 (epoch 16.837), train_loss = 1.15650549, grad/param norm = 1.7847e-01, time/batch = 16.6212s	
11332/33650 (epoch 16.838), train_loss = 1.06508930, grad/param norm = 1.5026e-01, time/batch = 18.0604s	
11333/33650 (epoch 16.840), train_loss = 1.14183942, grad/param norm = 1.5250e-01, time/batch = 18.7281s	
11334/33650 (epoch 16.841), train_loss = 1.00986773, grad/param norm = 1.3521e-01, time/batch = 16.6354s	
11335/33650 (epoch 16.842), train_loss = 1.05298017, grad/param norm = 1.3431e-01, time/batch = 18.5718s	
11336/33650 (epoch 16.844), train_loss = 1.21991881, grad/param norm = 1.5805e-01, time/batch = 16.9696s	
11337/33650 (epoch 16.845), train_loss = 1.00811948, grad/param norm = 1.3965e-01, time/batch = 17.5611s	
11338/33650 (epoch 16.847), train_loss = 0.81831802, grad/param norm = 1.2607e-01, time/batch = 17.4672s	
11339/33650 (epoch 16.848), train_loss = 0.91089755, grad/param norm = 1.3766e-01, time/batch = 17.4813s	
11340/33650 (epoch 16.850), train_loss = 1.04307906, grad/param norm = 1.4930e-01, time/batch = 18.7254s	
11341/33650 (epoch 16.851), train_loss = 0.86033649, grad/param norm = 1.1700e-01, time/batch = 18.7148s	
11342/33650 (epoch 16.853), train_loss = 1.08303222, grad/param norm = 1.6278e-01, time/batch = 17.4065s	
11343/33650 (epoch 16.854), train_loss = 1.17862732, grad/param norm = 1.6419e-01, time/batch = 18.3869s	
11344/33650 (epoch 16.856), train_loss = 0.82627218, grad/param norm = 1.3407e-01, time/batch = 16.9037s	
11345/33650 (epoch 16.857), train_loss = 1.05243983, grad/param norm = 1.2598e-01, time/batch = 16.8888s	
11346/33650 (epoch 16.859), train_loss = 0.95118219, grad/param norm = 1.2805e-01, time/batch = 16.6431s	
11347/33650 (epoch 16.860), train_loss = 0.89642531, grad/param norm = 1.3680e-01, time/batch = 17.3049s	
11348/33650 (epoch 16.862), train_loss = 0.95597208, grad/param norm = 1.3526e-01, time/batch = 17.2996s	
11349/33650 (epoch 16.863), train_loss = 1.16006285, grad/param norm = 1.4431e-01, time/batch = 16.7366s	
11350/33650 (epoch 16.865), train_loss = 1.04320254, grad/param norm = 1.4597e-01, time/batch = 17.9796s	
11351/33650 (epoch 16.866), train_loss = 0.94508777, grad/param norm = 1.3897e-01, time/batch = 17.5722s	
11352/33650 (epoch 16.868), train_loss = 0.92108334, grad/param norm = 1.4212e-01, time/batch = 18.7264s	
11353/33650 (epoch 16.869), train_loss = 1.18845600, grad/param norm = 1.6120e-01, time/batch = 17.3050s	
11354/33650 (epoch 16.871), train_loss = 0.92490753, grad/param norm = 1.2214e-01, time/batch = 17.1497s	
11355/33650 (epoch 16.872), train_loss = 1.05612819, grad/param norm = 1.4485e-01, time/batch = 17.8868s	
11356/33650 (epoch 16.874), train_loss = 1.12613733, grad/param norm = 1.6173e-01, time/batch = 17.8975s	
11357/33650 (epoch 16.875), train_loss = 1.04395094, grad/param norm = 1.3888e-01, time/batch = 17.8983s	
11358/33650 (epoch 16.877), train_loss = 1.20563191, grad/param norm = 1.4626e-01, time/batch = 30.8753s	
11359/33650 (epoch 16.878), train_loss = 0.74908017, grad/param norm = 1.1692e-01, time/batch = 18.3182s	
11360/33650 (epoch 16.880), train_loss = 1.11475644, grad/param norm = 1.5678e-01, time/batch = 16.5625s	
11361/33650 (epoch 16.881), train_loss = 1.00223410, grad/param norm = 1.6737e-01, time/batch = 18.4842s	
11362/33650 (epoch 16.883), train_loss = 1.07931395, grad/param norm = 1.4694e-01, time/batch = 16.9843s	
11363/33650 (epoch 16.884), train_loss = 1.17290161, grad/param norm = 1.6761e-01, time/batch = 18.1367s	
11364/33650 (epoch 16.886), train_loss = 1.14811904, grad/param norm = 1.6538e-01, time/batch = 17.2175s	
11365/33650 (epoch 16.887), train_loss = 0.98309768, grad/param norm = 1.2699e-01, time/batch = 16.7854s	
11366/33650 (epoch 16.889), train_loss = 1.08683461, grad/param norm = 1.5888e-01, time/batch = 17.5637s	
11367/33650 (epoch 16.890), train_loss = 1.11311844, grad/param norm = 1.3407e-01, time/batch = 17.0596s	
11368/33650 (epoch 16.892), train_loss = 1.08410127, grad/param norm = 1.6106e-01, time/batch = 18.8979s	
11369/33650 (epoch 16.893), train_loss = 1.09957554, grad/param norm = 1.4090e-01, time/batch = 17.6325s	
11370/33650 (epoch 16.895), train_loss = 1.18705905, grad/param norm = 1.5330e-01, time/batch = 17.2311s	
11371/33650 (epoch 16.896), train_loss = 0.98032756, grad/param norm = 1.4909e-01, time/batch = 18.2265s	
11372/33650 (epoch 16.897), train_loss = 0.90146140, grad/param norm = 1.3052e-01, time/batch = 17.6492s	
11373/33650 (epoch 16.899), train_loss = 0.93427023, grad/param norm = 1.2549e-01, time/batch = 17.6579s	
11374/33650 (epoch 16.900), train_loss = 0.85683316, grad/param norm = 1.2768e-01, time/batch = 17.5495s	
11375/33650 (epoch 16.902), train_loss = 1.08161703, grad/param norm = 1.5418e-01, time/batch = 16.6243s	
11376/33650 (epoch 16.903), train_loss = 1.02544236, grad/param norm = 1.5692e-01, time/batch = 18.2326s	
11377/33650 (epoch 16.905), train_loss = 1.21786782, grad/param norm = 1.6347e-01, time/batch = 17.0642s	
11378/33650 (epoch 16.906), train_loss = 0.99743736, grad/param norm = 1.3465e-01, time/batch = 17.1575s	
11379/33650 (epoch 16.908), train_loss = 1.00553973, grad/param norm = 1.2994e-01, time/batch = 16.9710s	
11380/33650 (epoch 16.909), train_loss = 1.00152332, grad/param norm = 1.2613e-01, time/batch = 18.3231s	
11381/33650 (epoch 16.911), train_loss = 0.87665732, grad/param norm = 1.2174e-01, time/batch = 18.3882s	
11382/33650 (epoch 16.912), train_loss = 0.87087673, grad/param norm = 1.2922e-01, time/batch = 18.0688s	
11383/33650 (epoch 16.914), train_loss = 1.04168211, grad/param norm = 1.2923e-01, time/batch = 17.7278s	
11384/33650 (epoch 16.915), train_loss = 1.01654422, grad/param norm = 1.5047e-01, time/batch = 17.0422s	
11385/33650 (epoch 16.917), train_loss = 1.02683035, grad/param norm = 1.5256e-01, time/batch = 17.8300s	
11386/33650 (epoch 16.918), train_loss = 0.85452180, grad/param norm = 1.1753e-01, time/batch = 17.8234s	
11387/33650 (epoch 16.920), train_loss = 0.95574737, grad/param norm = 1.2542e-01, time/batch = 17.4066s	
11388/33650 (epoch 16.921), train_loss = 0.95646792, grad/param norm = 1.3445e-01, time/batch = 18.3042s	
11389/33650 (epoch 16.923), train_loss = 0.89933438, grad/param norm = 1.2838e-01, time/batch = 18.1468s	
11390/33650 (epoch 16.924), train_loss = 1.05913589, grad/param norm = 1.4944e-01, time/batch = 18.1470s	
11391/33650 (epoch 16.926), train_loss = 1.00561472, grad/param norm = 1.5567e-01, time/batch = 17.4722s	
11392/33650 (epoch 16.927), train_loss = 0.97328021, grad/param norm = 1.4125e-01, time/batch = 18.5552s	
11393/33650 (epoch 16.929), train_loss = 1.07068842, grad/param norm = 1.3911e-01, time/batch = 17.7365s	
11394/33650 (epoch 16.930), train_loss = 0.98724853, grad/param norm = 1.4158e-01, time/batch = 17.3946s	
11395/33650 (epoch 16.932), train_loss = 1.02682487, grad/param norm = 1.4289e-01, time/batch = 17.4831s	
11396/33650 (epoch 16.933), train_loss = 0.89697007, grad/param norm = 1.2946e-01, time/batch = 16.7083s	
11397/33650 (epoch 16.935), train_loss = 0.92585075, grad/param norm = 1.3214e-01, time/batch = 17.6428s	
11398/33650 (epoch 16.936), train_loss = 0.95936980, grad/param norm = 1.2488e-01, time/batch = 17.7320s	
11399/33650 (epoch 16.938), train_loss = 0.90903551, grad/param norm = 1.4344e-01, time/batch = 18.0706s	
11400/33650 (epoch 16.939), train_loss = 1.08459894, grad/param norm = 1.4552e-01, time/batch = 17.4489s	
11401/33650 (epoch 16.941), train_loss = 1.05990626, grad/param norm = 1.4844e-01, time/batch = 16.7377s	
11402/33650 (epoch 16.942), train_loss = 1.11433518, grad/param norm = 1.5171e-01, time/batch = 19.2287s	
11403/33650 (epoch 16.944), train_loss = 1.02808059, grad/param norm = 1.3923e-01, time/batch = 17.3797s	
11404/33650 (epoch 16.945), train_loss = 1.10376324, grad/param norm = 1.5207e-01, time/batch = 16.9595s	
11405/33650 (epoch 16.947), train_loss = 1.21696052, grad/param norm = 1.7572e-01, time/batch = 18.5671s	
11406/33650 (epoch 16.948), train_loss = 1.19462501, grad/param norm = 1.4734e-01, time/batch = 18.0565s	
11407/33650 (epoch 16.949), train_loss = 0.93110815, grad/param norm = 1.4469e-01, time/batch = 17.5520s	
11408/33650 (epoch 16.951), train_loss = 1.20084568, grad/param norm = 1.5747e-01, time/batch = 17.1454s	
11409/33650 (epoch 16.952), train_loss = 1.12634388, grad/param norm = 1.4783e-01, time/batch = 17.1444s	
11410/33650 (epoch 16.954), train_loss = 1.11477427, grad/param norm = 1.5094e-01, time/batch = 18.2289s	
11411/33650 (epoch 16.955), train_loss = 1.11326545, grad/param norm = 1.4820e-01, time/batch = 17.4751s	
11412/33650 (epoch 16.957), train_loss = 1.08555501, grad/param norm = 1.4526e-01, time/batch = 17.5741s	
11413/33650 (epoch 16.958), train_loss = 0.83168743, grad/param norm = 1.2447e-01, time/batch = 15.2212s	
11414/33650 (epoch 16.960), train_loss = 0.87424499, grad/param norm = 1.2919e-01, time/batch = 17.7247s	
11415/33650 (epoch 16.961), train_loss = 0.92456510, grad/param norm = 1.3651e-01, time/batch = 18.1442s	
11416/33650 (epoch 16.963), train_loss = 1.01466403, grad/param norm = 1.4356e-01, time/batch = 18.0703s	
11417/33650 (epoch 16.964), train_loss = 1.06178142, grad/param norm = 1.4623e-01, time/batch = 14.9745s	
11418/33650 (epoch 16.966), train_loss = 1.03373251, grad/param norm = 1.4545e-01, time/batch = 16.9832s	
11419/33650 (epoch 16.967), train_loss = 1.08790037, grad/param norm = 1.4628e-01, time/batch = 17.8946s	
11420/33650 (epoch 16.969), train_loss = 1.02124725, grad/param norm = 1.3636e-01, time/batch = 18.3154s	
11421/33650 (epoch 16.970), train_loss = 1.09570329, grad/param norm = 1.4203e-01, time/batch = 17.4659s	
11422/33650 (epoch 16.972), train_loss = 1.37591976, grad/param norm = 1.7576e-01, time/batch = 17.7361s	
11423/33650 (epoch 16.973), train_loss = 0.93852430, grad/param norm = 1.2764e-01, time/batch = 15.7334s	
11424/33650 (epoch 16.975), train_loss = 0.94774110, grad/param norm = 1.2700e-01, time/batch = 17.0782s	
11425/33650 (epoch 16.976), train_loss = 0.93909693, grad/param norm = 1.2142e-01, time/batch = 16.8902s	
11426/33650 (epoch 16.978), train_loss = 0.97125609, grad/param norm = 1.4221e-01, time/batch = 16.9083s	
11427/33650 (epoch 16.979), train_loss = 1.03338253, grad/param norm = 1.5688e-01, time/batch = 17.4963s	
11428/33650 (epoch 16.981), train_loss = 0.98014247, grad/param norm = 1.2098e-01, time/batch = 15.4795s	
11429/33650 (epoch 16.982), train_loss = 1.07680419, grad/param norm = 1.4614e-01, time/batch = 16.8298s	
11430/33650 (epoch 16.984), train_loss = 0.88044331, grad/param norm = 1.3322e-01, time/batch = 17.2321s	
11431/33650 (epoch 16.985), train_loss = 0.89338920, grad/param norm = 1.3594e-01, time/batch = 13.8445s	
11432/33650 (epoch 16.987), train_loss = 1.01468594, grad/param norm = 1.3497e-01, time/batch = 17.4811s	
11433/33650 (epoch 16.988), train_loss = 1.07072275, grad/param norm = 1.5143e-01, time/batch = 16.7328s	
11434/33650 (epoch 16.990), train_loss = 1.27198751, grad/param norm = 1.7889e-01, time/batch = 17.2431s	
11435/33650 (epoch 16.991), train_loss = 1.09063913, grad/param norm = 1.4764e-01, time/batch = 16.4849s	
11436/33650 (epoch 16.993), train_loss = 1.06997531, grad/param norm = 1.5821e-01, time/batch = 17.0749s	
11437/33650 (epoch 16.994), train_loss = 0.98799940, grad/param norm = 1.3338e-01, time/batch = 16.4869s	
11438/33650 (epoch 16.996), train_loss = 0.96568892, grad/param norm = 1.4045e-01, time/batch = 17.0758s	
11439/33650 (epoch 16.997), train_loss = 1.07853375, grad/param norm = 1.4911e-01, time/batch = 14.7226s	
11440/33650 (epoch 16.999), train_loss = 0.93325369, grad/param norm = 1.3519e-01, time/batch = 17.9804s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
11441/33650 (epoch 17.000), train_loss = 1.10869291, grad/param norm = 1.5951e-01, time/batch = 17.1487s	
11442/33650 (epoch 17.001), train_loss = 1.22748775, grad/param norm = 1.6025e-01, time/batch = 17.3314s	
11443/33650 (epoch 17.003), train_loss = 1.22269211, grad/param norm = 1.7374e-01, time/batch = 16.9695s	
11444/33650 (epoch 17.004), train_loss = 1.07760318, grad/param norm = 1.5784e-01, time/batch = 16.9919s	
11445/33650 (epoch 17.006), train_loss = 1.00129922, grad/param norm = 1.4152e-01, time/batch = 18.0581s	
11446/33650 (epoch 17.007), train_loss = 1.10818152, grad/param norm = 1.6398e-01, time/batch = 16.2450s	
11447/33650 (epoch 17.009), train_loss = 1.00595619, grad/param norm = 1.4783e-01, time/batch = 16.9816s	
11448/33650 (epoch 17.010), train_loss = 1.11900010, grad/param norm = 1.5904e-01, time/batch = 16.4884s	
11449/33650 (epoch 17.012), train_loss = 0.99637976, grad/param norm = 1.4936e-01, time/batch = 17.5656s	
11450/33650 (epoch 17.013), train_loss = 1.06773849, grad/param norm = 1.7180e-01, time/batch = 15.6347s	
11451/33650 (epoch 17.015), train_loss = 0.97708918, grad/param norm = 1.3729e-01, time/batch = 17.0773s	
11452/33650 (epoch 17.016), train_loss = 0.92687180, grad/param norm = 1.5851e-01, time/batch = 18.0692s	
11453/33650 (epoch 17.018), train_loss = 1.03137848, grad/param norm = 1.4977e-01, time/batch = 16.4931s	
11454/33650 (epoch 17.019), train_loss = 0.97598680, grad/param norm = 1.4582e-01, time/batch = 16.9087s	
11455/33650 (epoch 17.021), train_loss = 1.11313928, grad/param norm = 1.5001e-01, time/batch = 17.2296s	
11456/33650 (epoch 17.022), train_loss = 0.98803022, grad/param norm = 1.3729e-01, time/batch = 16.0443s	
11457/33650 (epoch 17.024), train_loss = 0.91847307, grad/param norm = 1.3071e-01, time/batch = 16.3950s	
11458/33650 (epoch 17.025), train_loss = 1.01171620, grad/param norm = 1.3843e-01, time/batch = 16.8307s	
11459/33650 (epoch 17.027), train_loss = 1.12248470, grad/param norm = 1.5471e-01, time/batch = 17.3313s	
11460/33650 (epoch 17.028), train_loss = 1.13487366, grad/param norm = 1.5478e-01, time/batch = 16.6427s	
11461/33650 (epoch 17.030), train_loss = 1.06211398, grad/param norm = 1.5060e-01, time/batch = 15.4702s	
11462/33650 (epoch 17.031), train_loss = 0.93195098, grad/param norm = 1.3147e-01, time/batch = 17.1625s	
11463/33650 (epoch 17.033), train_loss = 1.00139513, grad/param norm = 1.1624e-01, time/batch = 17.5795s	
11464/33650 (epoch 17.034), train_loss = 1.06474904, grad/param norm = 1.3881e-01, time/batch = 16.4018s	
11465/33650 (epoch 17.036), train_loss = 1.16831734, grad/param norm = 1.6057e-01, time/batch = 17.3217s	
11466/33650 (epoch 17.037), train_loss = 0.99116823, grad/param norm = 1.5158e-01, time/batch = 16.0773s	
11467/33650 (epoch 17.039), train_loss = 1.13592447, grad/param norm = 1.4948e-01, time/batch = 16.8302s	
11468/33650 (epoch 17.040), train_loss = 1.23935030, grad/param norm = 1.8474e-01, time/batch = 16.6589s	
11469/33650 (epoch 17.042), train_loss = 1.22765341, grad/param norm = 1.5544e-01, time/batch = 17.0034s	
11470/33650 (epoch 17.043), train_loss = 0.98858729, grad/param norm = 1.3974e-01, time/batch = 16.8190s	
11471/33650 (epoch 17.045), train_loss = 0.96027305, grad/param norm = 1.3704e-01, time/batch = 15.8959s	
11472/33650 (epoch 17.046), train_loss = 1.12544304, grad/param norm = 1.4627e-01, time/batch = 17.4024s	
11473/33650 (epoch 17.048), train_loss = 1.13392596, grad/param norm = 1.3953e-01, time/batch = 16.9147s	
11474/33650 (epoch 17.049), train_loss = 1.06812265, grad/param norm = 1.4430e-01, time/batch = 16.9935s	
11475/33650 (epoch 17.051), train_loss = 1.16355998, grad/param norm = 1.5707e-01, time/batch = 17.4692s	
11476/33650 (epoch 17.052), train_loss = 1.20048659, grad/param norm = 1.6996e-01, time/batch = 17.2423s	
11477/33650 (epoch 17.053), train_loss = 1.07925865, grad/param norm = 1.3364e-01, time/batch = 17.8268s	
11478/33650 (epoch 17.055), train_loss = 0.91996035, grad/param norm = 1.3954e-01, time/batch = 16.2230s	
11479/33650 (epoch 17.056), train_loss = 0.90553234, grad/param norm = 1.1854e-01, time/batch = 16.4785s	
11480/33650 (epoch 17.058), train_loss = 1.14637998, grad/param norm = 1.6836e-01, time/batch = 17.9048s	
11481/33650 (epoch 17.059), train_loss = 1.08731860, grad/param norm = 1.6173e-01, time/batch = 16.8975s	
11482/33650 (epoch 17.061), train_loss = 1.12319834, grad/param norm = 1.6194e-01, time/batch = 16.7378s	
11483/33650 (epoch 17.062), train_loss = 1.12638667, grad/param norm = 1.5080e-01, time/batch = 17.6580s	
11484/33650 (epoch 17.064), train_loss = 0.99392695, grad/param norm = 1.3196e-01, time/batch = 17.6574s	
11485/33650 (epoch 17.065), train_loss = 1.01242821, grad/param norm = 1.4518e-01, time/batch = 15.9811s	
11486/33650 (epoch 17.067), train_loss = 0.92578562, grad/param norm = 1.2592e-01, time/batch = 16.6342s	
11487/33650 (epoch 17.068), train_loss = 1.05687255, grad/param norm = 1.5093e-01, time/batch = 17.9056s	
11488/33650 (epoch 17.070), train_loss = 1.05912070, grad/param norm = 1.4720e-01, time/batch = 15.8214s	
11489/33650 (epoch 17.071), train_loss = 1.07241624, grad/param norm = 1.4659e-01, time/batch = 15.9042s	
11490/33650 (epoch 17.073), train_loss = 1.09456984, grad/param norm = 1.5799e-01, time/batch = 17.7445s	
11491/33650 (epoch 17.074), train_loss = 1.16449038, grad/param norm = 1.4862e-01, time/batch = 17.7455s	
11492/33650 (epoch 17.076), train_loss = 1.13402115, grad/param norm = 1.5523e-01, time/batch = 16.8126s	
11493/33650 (epoch 17.077), train_loss = 1.02804649, grad/param norm = 1.4012e-01, time/batch = 16.9711s	
11494/33650 (epoch 17.079), train_loss = 1.03681136, grad/param norm = 1.3145e-01, time/batch = 17.2312s	
11495/33650 (epoch 17.080), train_loss = 1.10726455, grad/param norm = 1.4163e-01, time/batch = 17.4031s	
11496/33650 (epoch 17.082), train_loss = 1.11041883, grad/param norm = 1.4576e-01, time/batch = 8.8223s	
11497/33650 (epoch 17.083), train_loss = 1.11416245, grad/param norm = 1.5655e-01, time/batch = 0.6631s	
11498/33650 (epoch 17.085), train_loss = 1.13536559, grad/param norm = 1.4940e-01, time/batch = 0.6533s	
11499/33650 (epoch 17.086), train_loss = 1.14347189, grad/param norm = 1.5658e-01, time/batch = 0.6465s	
11500/33650 (epoch 17.088), train_loss = 1.11344330, grad/param norm = 1.5688e-01, time/batch = 0.6353s	
11501/33650 (epoch 17.089), train_loss = 1.03345746, grad/param norm = 1.3410e-01, time/batch = 0.6275s	
11502/33650 (epoch 17.091), train_loss = 0.99619995, grad/param norm = 1.3437e-01, time/batch = 0.6256s	
11503/33650 (epoch 17.092), train_loss = 1.03849436, grad/param norm = 1.4818e-01, time/batch = 0.6289s	
11504/33650 (epoch 17.094), train_loss = 1.11204925, grad/param norm = 1.4194e-01, time/batch = 0.8299s	
11505/33650 (epoch 17.095), train_loss = 1.10446199, grad/param norm = 1.6750e-01, time/batch = 0.9207s	
11506/33650 (epoch 17.097), train_loss = 1.00400831, grad/param norm = 1.5094e-01, time/batch = 0.9447s	
11507/33650 (epoch 17.098), train_loss = 0.86655448, grad/param norm = 1.3509e-01, time/batch = 0.9413s	
11508/33650 (epoch 17.100), train_loss = 0.95849755, grad/param norm = 1.2662e-01, time/batch = 0.9278s	
11509/33650 (epoch 17.101), train_loss = 1.04085767, grad/param norm = 1.7425e-01, time/batch = 1.1671s	
11510/33650 (epoch 17.103), train_loss = 0.98252619, grad/param norm = 1.3196e-01, time/batch = 1.7296s	
11511/33650 (epoch 17.104), train_loss = 1.13828237, grad/param norm = 1.4650e-01, time/batch = 1.7554s	
11512/33650 (epoch 17.105), train_loss = 1.04371628, grad/param norm = 1.3941e-01, time/batch = 9.7106s	
11513/33650 (epoch 17.107), train_loss = 0.96216016, grad/param norm = 1.2925e-01, time/batch = 17.7380s	
11514/33650 (epoch 17.108), train_loss = 1.13415530, grad/param norm = 1.5154e-01, time/batch = 15.1433s	
11515/33650 (epoch 17.110), train_loss = 1.22321271, grad/param norm = 1.5655e-01, time/batch = 17.3956s	
11516/33650 (epoch 17.111), train_loss = 0.99762562, grad/param norm = 1.5138e-01, time/batch = 16.4916s	
11517/33650 (epoch 17.113), train_loss = 1.01363683, grad/param norm = 1.5457e-01, time/batch = 17.9023s	
11518/33650 (epoch 17.114), train_loss = 1.12320831, grad/param norm = 1.4477e-01, time/batch = 16.6519s	
11519/33650 (epoch 17.116), train_loss = 0.94976369, grad/param norm = 1.2493e-01, time/batch = 17.9936s	
11520/33650 (epoch 17.117), train_loss = 1.06855361, grad/param norm = 1.3036e-01, time/batch = 16.9792s	
11521/33650 (epoch 17.119), train_loss = 0.92479640, grad/param norm = 1.3713e-01, time/batch = 16.9805s	
11522/33650 (epoch 17.120), train_loss = 1.00344640, grad/param norm = 1.6435e-01, time/batch = 16.9172s	
11523/33650 (epoch 17.122), train_loss = 0.84225639, grad/param norm = 1.4249e-01, time/batch = 17.8219s	
11524/33650 (epoch 17.123), train_loss = 1.02093069, grad/param norm = 1.4750e-01, time/batch = 16.9897s	
11525/33650 (epoch 17.125), train_loss = 1.12814676, grad/param norm = 1.5611e-01, time/batch = 17.1506s	
11526/33650 (epoch 17.126), train_loss = 1.21864605, grad/param norm = 1.6474e-01, time/batch = 17.6576s	
11527/33650 (epoch 17.128), train_loss = 1.16566204, grad/param norm = 1.6910e-01, time/batch = 17.2457s	
11528/33650 (epoch 17.129), train_loss = 1.17990283, grad/param norm = 1.5817e-01, time/batch = 15.9763s	
11529/33650 (epoch 17.131), train_loss = 1.08302573, grad/param norm = 1.4786e-01, time/batch = 2.5830s	
11530/33650 (epoch 17.132), train_loss = 1.08007408, grad/param norm = 1.5006e-01, time/batch = 0.6302s	
11531/33650 (epoch 17.134), train_loss = 1.14851997, grad/param norm = 1.5245e-01, time/batch = 0.6293s	
11532/33650 (epoch 17.135), train_loss = 0.91104127, grad/param norm = 1.3142e-01, time/batch = 0.6288s	
11533/33650 (epoch 17.137), train_loss = 1.06122572, grad/param norm = 1.5621e-01, time/batch = 0.6380s	
11534/33650 (epoch 17.138), train_loss = 1.11441918, grad/param norm = 1.3677e-01, time/batch = 0.6684s	
11535/33650 (epoch 17.140), train_loss = 1.04365598, grad/param norm = 1.6152e-01, time/batch = 0.6535s	
11536/33650 (epoch 17.141), train_loss = 1.19744492, grad/param norm = 1.6006e-01, time/batch = 0.6625s	
11537/33650 (epoch 17.143), train_loss = 1.26706144, grad/param norm = 1.6974e-01, time/batch = 0.9181s	
11538/33650 (epoch 17.144), train_loss = 1.14898987, grad/param norm = 1.7811e-01, time/batch = 0.9178s	
11539/33650 (epoch 17.146), train_loss = 1.02670801, grad/param norm = 1.4525e-01, time/batch = 0.9197s	
11540/33650 (epoch 17.147), train_loss = 1.00130047, grad/param norm = 1.4968e-01, time/batch = 0.9199s	
11541/33650 (epoch 17.149), train_loss = 0.97352296, grad/param norm = 1.6582e-01, time/batch = 0.9197s	
11542/33650 (epoch 17.150), train_loss = 0.93126599, grad/param norm = 1.4111e-01, time/batch = 1.5102s	
11543/33650 (epoch 17.152), train_loss = 1.00044583, grad/param norm = 1.3982e-01, time/batch = 1.7406s	
11544/33650 (epoch 17.153), train_loss = 1.00376903, grad/param norm = 1.4093e-01, time/batch = 1.7322s	
11545/33650 (epoch 17.155), train_loss = 0.98051985, grad/param norm = 1.3964e-01, time/batch = 15.4970s	
11546/33650 (epoch 17.156), train_loss = 0.94556130, grad/param norm = 1.2008e-01, time/batch = 17.4952s	
11547/33650 (epoch 17.158), train_loss = 1.06561808, grad/param norm = 1.5144e-01, time/batch = 16.3954s	
11548/33650 (epoch 17.159), train_loss = 0.94902766, grad/param norm = 1.1634e-01, time/batch = 15.9703s	
11549/33650 (epoch 17.160), train_loss = 0.98470355, grad/param norm = 1.2473e-01, time/batch = 17.2392s	
11550/33650 (epoch 17.162), train_loss = 1.02478083, grad/param norm = 1.7020e-01, time/batch = 16.8147s	
11551/33650 (epoch 17.163), train_loss = 1.11869241, grad/param norm = 1.6339e-01, time/batch = 15.1316s	
11552/33650 (epoch 17.165), train_loss = 0.95529878, grad/param norm = 1.4577e-01, time/batch = 17.4143s	
11553/33650 (epoch 17.166), train_loss = 0.95701835, grad/param norm = 1.4634e-01, time/batch = 18.0780s	
11554/33650 (epoch 17.168), train_loss = 1.12365476, grad/param norm = 1.6634e-01, time/batch = 15.8986s	
11555/33650 (epoch 17.169), train_loss = 1.03712851, grad/param norm = 1.4343e-01, time/batch = 17.7267s	
11556/33650 (epoch 17.171), train_loss = 1.03334260, grad/param norm = 1.3998e-01, time/batch = 17.9985s	
11557/33650 (epoch 17.172), train_loss = 0.99816993, grad/param norm = 1.4058e-01, time/batch = 16.8785s	
11558/33650 (epoch 17.174), train_loss = 0.95442422, grad/param norm = 1.3752e-01, time/batch = 16.4073s	
11559/33650 (epoch 17.175), train_loss = 0.94403828, grad/param norm = 1.5004e-01, time/batch = 17.1609s	
11560/33650 (epoch 17.177), train_loss = 1.04844920, grad/param norm = 1.3920e-01, time/batch = 18.1539s	
11561/33650 (epoch 17.178), train_loss = 0.98024217, grad/param norm = 1.6966e-01, time/batch = 16.0686s	
11562/33650 (epoch 17.180), train_loss = 0.92915170, grad/param norm = 1.3526e-01, time/batch = 17.1698s	
11563/33650 (epoch 17.181), train_loss = 0.84629348, grad/param norm = 1.2846e-01, time/batch = 16.3105s	
11564/33650 (epoch 17.183), train_loss = 0.99640995, grad/param norm = 1.5487e-01, time/batch = 17.3182s	
11565/33650 (epoch 17.184), train_loss = 0.97878620, grad/param norm = 1.5789e-01, time/batch = 17.2421s	
11566/33650 (epoch 17.186), train_loss = 1.00570537, grad/param norm = 1.6837e-01, time/batch = 16.4950s	
11567/33650 (epoch 17.187), train_loss = 1.22101370, grad/param norm = 1.5109e-01, time/batch = 17.9745s	
11568/33650 (epoch 17.189), train_loss = 1.17669304, grad/param norm = 1.6842e-01, time/batch = 15.9818s	
11569/33650 (epoch 17.190), train_loss = 1.06617609, grad/param norm = 1.5253e-01, time/batch = 17.5632s	
11570/33650 (epoch 17.192), train_loss = 1.21381347, grad/param norm = 1.4415e-01, time/batch = 17.1568s	
11571/33650 (epoch 17.193), train_loss = 1.16115678, grad/param norm = 1.4582e-01, time/batch = 17.0647s	
11572/33650 (epoch 17.195), train_loss = 0.92378896, grad/param norm = 1.2605e-01, time/batch = 16.0807s	
11573/33650 (epoch 17.196), train_loss = 0.88972981, grad/param norm = 1.5323e-01, time/batch = 17.8113s	
11574/33650 (epoch 17.198), train_loss = 1.00057075, grad/param norm = 1.4506e-01, time/batch = 16.2952s	
11575/33650 (epoch 17.199), train_loss = 1.13003932, grad/param norm = 1.6427e-01, time/batch = 16.8145s	
11576/33650 (epoch 17.201), train_loss = 0.99872770, grad/param norm = 1.5484e-01, time/batch = 17.8979s	
11577/33650 (epoch 17.202), train_loss = 0.99625602, grad/param norm = 1.4937e-01, time/batch = 17.1553s	
11578/33650 (epoch 17.204), train_loss = 1.06656466, grad/param norm = 1.3736e-01, time/batch = 16.9740s	
11579/33650 (epoch 17.205), train_loss = 1.02714536, grad/param norm = 1.5083e-01, time/batch = 17.0770s	
11580/33650 (epoch 17.207), train_loss = 0.98418080, grad/param norm = 1.4983e-01, time/batch = 17.5695s	
11581/33650 (epoch 17.208), train_loss = 1.03448210, grad/param norm = 1.4365e-01, time/batch = 17.3966s	
11582/33650 (epoch 17.210), train_loss = 0.84490412, grad/param norm = 1.2702e-01, time/batch = 16.3151s	
11583/33650 (epoch 17.211), train_loss = 0.96829252, grad/param norm = 1.4772e-01, time/batch = 17.3287s	
11584/33650 (epoch 17.212), train_loss = 1.10594686, grad/param norm = 1.5393e-01, time/batch = 16.6581s	
11585/33650 (epoch 17.214), train_loss = 1.20615953, grad/param norm = 1.4644e-01, time/batch = 17.2300s	
11586/33650 (epoch 17.215), train_loss = 0.81934689, grad/param norm = 1.2963e-01, time/batch = 17.0657s	
11587/33650 (epoch 17.217), train_loss = 1.03725118, grad/param norm = 1.6158e-01, time/batch = 17.9052s	
11588/33650 (epoch 17.218), train_loss = 1.07147545, grad/param norm = 1.4082e-01, time/batch = 17.6459s	
11589/33650 (epoch 17.220), train_loss = 0.90571044, grad/param norm = 1.3666e-01, time/batch = 16.2914s	
11590/33650 (epoch 17.221), train_loss = 1.20288123, grad/param norm = 1.6564e-01, time/batch = 16.4133s	
11591/33650 (epoch 17.223), train_loss = 0.82746776, grad/param norm = 1.2886e-01, time/batch = 17.9061s	
11592/33650 (epoch 17.224), train_loss = 1.01025120, grad/param norm = 1.5782e-01, time/batch = 16.2190s	
11593/33650 (epoch 17.226), train_loss = 1.32915431, grad/param norm = 1.6775e-01, time/batch = 17.0731s	
11594/33650 (epoch 17.227), train_loss = 1.18952840, grad/param norm = 1.7119e-01, time/batch = 15.3073s	
11595/33650 (epoch 17.229), train_loss = 1.18325143, grad/param norm = 1.6079e-01, time/batch = 17.2554s	
11596/33650 (epoch 17.230), train_loss = 1.28536183, grad/param norm = 1.6085e-01, time/batch = 25.2762s	
11597/33650 (epoch 17.232), train_loss = 1.09954498, grad/param norm = 1.4949e-01, time/batch = 21.0294s	
11598/33650 (epoch 17.233), train_loss = 1.09295702, grad/param norm = 1.6741e-01, time/batch = 17.6544s	
11599/33650 (epoch 17.235), train_loss = 1.01572260, grad/param norm = 1.2598e-01, time/batch = 16.3122s	
11600/33650 (epoch 17.236), train_loss = 0.92165351, grad/param norm = 1.5214e-01, time/batch = 16.9823s	
11601/33650 (epoch 17.238), train_loss = 1.00437227, grad/param norm = 1.3457e-01, time/batch = 16.9763s	
11602/33650 (epoch 17.239), train_loss = 0.94327149, grad/param norm = 1.4614e-01, time/batch = 17.3230s	
11603/33650 (epoch 17.241), train_loss = 0.97930048, grad/param norm = 1.2654e-01, time/batch = 16.8969s	
11604/33650 (epoch 17.242), train_loss = 0.85074837, grad/param norm = 1.3332e-01, time/batch = 17.5733s	
11605/33650 (epoch 17.244), train_loss = 1.02313711, grad/param norm = 1.4157e-01, time/batch = 17.0651s	
11606/33650 (epoch 17.245), train_loss = 0.90662812, grad/param norm = 1.3507e-01, time/batch = 16.3174s	
11607/33650 (epoch 17.247), train_loss = 1.01605345, grad/param norm = 1.3372e-01, time/batch = 16.5417s	
11608/33650 (epoch 17.248), train_loss = 0.90200026, grad/param norm = 1.3541e-01, time/batch = 14.8055s	
11609/33650 (epoch 17.250), train_loss = 1.00585834, grad/param norm = 1.3662e-01, time/batch = 16.0557s	
11610/33650 (epoch 17.251), train_loss = 1.17526122, grad/param norm = 1.4749e-01, time/batch = 15.7372s	
11611/33650 (epoch 17.253), train_loss = 0.92748739, grad/param norm = 1.3796e-01, time/batch = 17.6442s	
11612/33650 (epoch 17.254), train_loss = 0.95169104, grad/param norm = 1.4749e-01, time/batch = 17.5653s	
11613/33650 (epoch 17.256), train_loss = 1.16742319, grad/param norm = 1.4179e-01, time/batch = 16.7416s	
11614/33650 (epoch 17.257), train_loss = 1.18107851, grad/param norm = 1.4346e-01, time/batch = 17.9018s	
11615/33650 (epoch 17.259), train_loss = 0.90484457, grad/param norm = 1.3623e-01, time/batch = 18.0515s	
11616/33650 (epoch 17.260), train_loss = 1.13915129, grad/param norm = 1.3980e-01, time/batch = 16.7129s	
11617/33650 (epoch 17.262), train_loss = 1.08199852, grad/param norm = 1.4938e-01, time/batch = 17.6403s	
11618/33650 (epoch 17.263), train_loss = 0.97585548, grad/param norm = 1.5961e-01, time/batch = 17.3137s	
11619/33650 (epoch 17.264), train_loss = 1.09637698, grad/param norm = 1.4613e-01, time/batch = 15.7336s	
11620/33650 (epoch 17.266), train_loss = 1.05078039, grad/param norm = 1.3684e-01, time/batch = 14.0730s	
11621/33650 (epoch 17.267), train_loss = 0.97314920, grad/param norm = 1.4570e-01, time/batch = 17.7260s	
11622/33650 (epoch 17.269), train_loss = 1.08131446, grad/param norm = 1.3815e-01, time/batch = 17.4818s	
11623/33650 (epoch 17.270), train_loss = 0.95227692, grad/param norm = 1.1944e-01, time/batch = 16.8154s	
11624/33650 (epoch 17.272), train_loss = 1.00876526, grad/param norm = 1.3659e-01, time/batch = 17.9694s	
11625/33650 (epoch 17.273), train_loss = 1.16200802, grad/param norm = 1.6261e-01, time/batch = 18.2210s	
11626/33650 (epoch 17.275), train_loss = 1.11110234, grad/param norm = 1.4550e-01, time/batch = 17.0663s	
11627/33650 (epoch 17.276), train_loss = 1.18745148, grad/param norm = 1.7016e-01, time/batch = 16.4835s	
11628/33650 (epoch 17.278), train_loss = 1.24691156, grad/param norm = 1.7280e-01, time/batch = 17.3197s	
11629/33650 (epoch 17.279), train_loss = 0.97617354, grad/param norm = 1.2755e-01, time/batch = 17.9098s	
11630/33650 (epoch 17.281), train_loss = 1.09471218, grad/param norm = 1.6703e-01, time/batch = 17.3054s	
11631/33650 (epoch 17.282), train_loss = 1.14379646, grad/param norm = 1.3563e-01, time/batch = 16.9790s	
11632/33650 (epoch 17.284), train_loss = 1.11893477, grad/param norm = 1.6257e-01, time/batch = 17.6583s	
11633/33650 (epoch 17.285), train_loss = 1.13761755, grad/param norm = 1.5561e-01, time/batch = 16.8997s	
11634/33650 (epoch 17.287), train_loss = 1.02901600, grad/param norm = 1.6296e-01, time/batch = 16.6524s	
11635/33650 (epoch 17.288), train_loss = 1.09857674, grad/param norm = 1.6577e-01, time/batch = 16.9864s	
11636/33650 (epoch 17.290), train_loss = 1.04397352, grad/param norm = 1.2999e-01, time/batch = 16.0740s	
11637/33650 (epoch 17.291), train_loss = 0.96584455, grad/param norm = 1.2602e-01, time/batch = 15.4519s	
11638/33650 (epoch 17.293), train_loss = 1.05335151, grad/param norm = 1.6483e-01, time/batch = 16.8742s	
11639/33650 (epoch 17.294), train_loss = 0.96031511, grad/param norm = 1.4209e-01, time/batch = 16.8710s	
11640/33650 (epoch 17.296), train_loss = 0.95447813, grad/param norm = 1.4739e-01, time/batch = 16.7341s	
11641/33650 (epoch 17.297), train_loss = 1.02755475, grad/param norm = 1.4497e-01, time/batch = 17.6302s	
11642/33650 (epoch 17.299), train_loss = 0.91859315, grad/param norm = 1.3288e-01, time/batch = 16.6457s	
11643/33650 (epoch 17.300), train_loss = 0.93289709, grad/param norm = 1.3791e-01, time/batch = 17.8259s	
11644/33650 (epoch 17.302), train_loss = 1.06251920, grad/param norm = 1.3887e-01, time/batch = 16.5710s	
11645/33650 (epoch 17.303), train_loss = 1.05594190, grad/param norm = 1.2913e-01, time/batch = 16.2281s	
11646/33650 (epoch 17.305), train_loss = 1.08060258, grad/param norm = 1.5243e-01, time/batch = 16.9863s	
11647/33650 (epoch 17.306), train_loss = 0.96647341, grad/param norm = 1.3155e-01, time/batch = 17.5763s	
11648/33650 (epoch 17.308), train_loss = 0.91190574, grad/param norm = 1.4913e-01, time/batch = 16.4872s	
11649/33650 (epoch 17.309), train_loss = 1.23285449, grad/param norm = 1.7244e-01, time/batch = 17.7394s	
11650/33650 (epoch 17.311), train_loss = 1.10004305, grad/param norm = 1.6853e-01, time/batch = 16.2350s	
11651/33650 (epoch 17.312), train_loss = 1.05536098, grad/param norm = 1.4827e-01, time/batch = 17.4927s	
11652/33650 (epoch 17.314), train_loss = 0.90808991, grad/param norm = 1.2226e-01, time/batch = 17.2227s	
11653/33650 (epoch 17.315), train_loss = 1.01861041, grad/param norm = 1.6107e-01, time/batch = 16.9854s	
11654/33650 (epoch 17.316), train_loss = 0.98363124, grad/param norm = 1.6198e-01, time/batch = 17.2453s	
11655/33650 (epoch 17.318), train_loss = 0.93286049, grad/param norm = 1.3080e-01, time/batch = 16.8935s	
11656/33650 (epoch 17.319), train_loss = 0.95632779, grad/param norm = 1.3228e-01, time/batch = 16.7379s	
11657/33650 (epoch 17.321), train_loss = 0.97551295, grad/param norm = 1.3433e-01, time/batch = 16.8856s	
11658/33650 (epoch 17.322), train_loss = 1.07900352, grad/param norm = 1.6011e-01, time/batch = 16.5662s	
11659/33650 (epoch 17.324), train_loss = 1.12150192, grad/param norm = 1.8746e-01, time/batch = 16.3098s	
11660/33650 (epoch 17.325), train_loss = 1.12045726, grad/param norm = 1.5180e-01, time/batch = 17.8937s	
11661/33650 (epoch 17.327), train_loss = 0.93791882, grad/param norm = 1.2533e-01, time/batch = 15.5295s	
11662/33650 (epoch 17.328), train_loss = 1.10831919, grad/param norm = 1.5275e-01, time/batch = 16.3861s	
11663/33650 (epoch 17.330), train_loss = 0.95382459, grad/param norm = 1.2345e-01, time/batch = 16.8206s	
11664/33650 (epoch 17.331), train_loss = 0.86072095, grad/param norm = 1.1798e-01, time/batch = 17.4858s	
11665/33650 (epoch 17.333), train_loss = 1.00813675, grad/param norm = 1.4373e-01, time/batch = 17.4848s	
11666/33650 (epoch 17.334), train_loss = 1.00947513, grad/param norm = 1.4034e-01, time/batch = 16.3043s	
11667/33650 (epoch 17.336), train_loss = 1.15151588, grad/param norm = 1.3831e-01, time/batch = 17.0724s	
11668/33650 (epoch 17.337), train_loss = 0.84551455, grad/param norm = 1.1879e-01, time/batch = 17.8985s	
11669/33650 (epoch 17.339), train_loss = 1.00056544, grad/param norm = 1.3113e-01, time/batch = 17.0636s	
11670/33650 (epoch 17.340), train_loss = 1.19155532, grad/param norm = 1.5988e-01, time/batch = 16.9868s	
11671/33650 (epoch 17.342), train_loss = 0.86700125, grad/param norm = 1.3462e-01, time/batch = 16.5705s	
11672/33650 (epoch 17.343), train_loss = 1.08641386, grad/param norm = 1.4779e-01, time/batch = 17.3322s	
11673/33650 (epoch 17.345), train_loss = 1.01364882, grad/param norm = 1.4806e-01, time/batch = 17.2225s	
11674/33650 (epoch 17.346), train_loss = 0.73216921, grad/param norm = 1.2192e-01, time/batch = 17.2275s	
11675/33650 (epoch 17.348), train_loss = 0.91305136, grad/param norm = 1.2584e-01, time/batch = 16.4926s	
11676/33650 (epoch 17.349), train_loss = 0.87595788, grad/param norm = 1.3074e-01, time/batch = 16.4099s	
11677/33650 (epoch 17.351), train_loss = 1.12778124, grad/param norm = 1.5149e-01, time/batch = 16.4611s	
11678/33650 (epoch 17.352), train_loss = 1.01732525, grad/param norm = 1.3531e-01, time/batch = 16.4856s	
11679/33650 (epoch 17.354), train_loss = 1.21905916, grad/param norm = 1.7107e-01, time/batch = 16.5775s	
11680/33650 (epoch 17.355), train_loss = 1.14328439, grad/param norm = 1.4117e-01, time/batch = 16.0712s	
11681/33650 (epoch 17.357), train_loss = 0.83180996, grad/param norm = 1.3361e-01, time/batch = 17.0630s	
11682/33650 (epoch 17.358), train_loss = 1.10188303, grad/param norm = 1.4304e-01, time/batch = 17.7465s	
11683/33650 (epoch 17.360), train_loss = 1.13031016, grad/param norm = 1.5308e-01, time/batch = 17.1470s	
11684/33650 (epoch 17.361), train_loss = 1.05928614, grad/param norm = 1.3189e-01, time/batch = 15.1160s	
11685/33650 (epoch 17.363), train_loss = 0.97592526, grad/param norm = 1.4376e-01, time/batch = 17.4844s	
11686/33650 (epoch 17.364), train_loss = 0.99297456, grad/param norm = 1.3782e-01, time/batch = 17.6619s	
11687/33650 (epoch 17.366), train_loss = 1.07855899, grad/param norm = 1.4737e-01, time/batch = 16.0701s	
11688/33650 (epoch 17.367), train_loss = 1.09491181, grad/param norm = 1.4242e-01, time/batch = 16.9047s	
11689/33650 (epoch 17.368), train_loss = 0.95123684, grad/param norm = 1.3556e-01, time/batch = 16.7285s	
11690/33650 (epoch 17.370), train_loss = 1.03821651, grad/param norm = 1.4741e-01, time/batch = 17.1526s	
11691/33650 (epoch 17.371), train_loss = 0.84675510, grad/param norm = 1.4781e-01, time/batch = 17.3069s	
11692/33650 (epoch 17.373), train_loss = 0.92820296, grad/param norm = 1.2675e-01, time/batch = 17.8179s	
11693/33650 (epoch 17.374), train_loss = 0.90670363, grad/param norm = 1.2726e-01, time/batch = 17.1719s	
11694/33650 (epoch 17.376), train_loss = 1.02775377, grad/param norm = 1.5578e-01, time/batch = 16.0624s	
11695/33650 (epoch 17.377), train_loss = 1.06077238, grad/param norm = 1.5368e-01, time/batch = 16.9692s	
11696/33650 (epoch 17.379), train_loss = 1.11101248, grad/param norm = 1.4558e-01, time/batch = 17.2403s	
11697/33650 (epoch 17.380), train_loss = 0.81495070, grad/param norm = 1.8069e-01, time/batch = 17.1472s	
11698/33650 (epoch 17.382), train_loss = 0.94342113, grad/param norm = 1.2649e-01, time/batch = 16.9739s	
11699/33650 (epoch 17.383), train_loss = 1.00385459, grad/param norm = 1.3503e-01, time/batch = 16.8149s	
11700/33650 (epoch 17.385), train_loss = 1.17358362, grad/param norm = 1.4921e-01, time/batch = 16.6417s	
11701/33650 (epoch 17.386), train_loss = 0.95389433, grad/param norm = 1.3401e-01, time/batch = 16.5642s	
11702/33650 (epoch 17.388), train_loss = 1.06229864, grad/param norm = 1.3583e-01, time/batch = 16.8108s	
11703/33650 (epoch 17.389), train_loss = 1.01476063, grad/param norm = 1.5092e-01, time/batch = 17.1533s	
11704/33650 (epoch 17.391), train_loss = 0.83074140, grad/param norm = 1.2967e-01, time/batch = 17.6637s	
11705/33650 (epoch 17.392), train_loss = 1.09559754, grad/param norm = 1.5335e-01, time/batch = 16.6378s	
11706/33650 (epoch 17.394), train_loss = 1.08238556, grad/param norm = 1.6082e-01, time/batch = 17.6619s	
11707/33650 (epoch 17.395), train_loss = 1.05723355, grad/param norm = 1.3871e-01, time/batch = 16.5541s	
11708/33650 (epoch 17.397), train_loss = 1.18862026, grad/param norm = 1.4297e-01, time/batch = 16.6503s	
11709/33650 (epoch 17.398), train_loss = 1.06723126, grad/param norm = 1.4077e-01, time/batch = 17.4932s	
11710/33650 (epoch 17.400), train_loss = 1.03650528, grad/param norm = 1.6142e-01, time/batch = 17.6585s	
11711/33650 (epoch 17.401), train_loss = 1.01094714, grad/param norm = 1.5557e-01, time/batch = 17.9144s	
11712/33650 (epoch 17.403), train_loss = 1.06642810, grad/param norm = 1.4259e-01, time/batch = 16.8166s	
11713/33650 (epoch 17.404), train_loss = 1.02507140, grad/param norm = 1.3415e-01, time/batch = 17.5663s	
11714/33650 (epoch 17.406), train_loss = 1.05757053, grad/param norm = 1.5165e-01, time/batch = 17.7234s	
11715/33650 (epoch 17.407), train_loss = 1.05202544, grad/param norm = 1.5566e-01, time/batch = 16.3040s	
11716/33650 (epoch 17.409), train_loss = 1.06231503, grad/param norm = 1.6605e-01, time/batch = 17.0646s	
11717/33650 (epoch 17.410), train_loss = 1.01476875, grad/param norm = 1.3973e-01, time/batch = 17.5783s	
11718/33650 (epoch 17.412), train_loss = 1.04263397, grad/param norm = 1.3138e-01, time/batch = 17.3989s	
11719/33650 (epoch 17.413), train_loss = 0.96761716, grad/param norm = 1.4772e-01, time/batch = 16.7299s	
11720/33650 (epoch 17.415), train_loss = 1.11069166, grad/param norm = 1.4524e-01, time/batch = 17.1571s	
11721/33650 (epoch 17.416), train_loss = 1.18419799, grad/param norm = 1.5944e-01, time/batch = 17.7318s	
11722/33650 (epoch 17.418), train_loss = 1.02018120, grad/param norm = 1.4669e-01, time/batch = 15.9729s	
11723/33650 (epoch 17.419), train_loss = 0.98316226, grad/param norm = 1.3755e-01, time/batch = 16.4803s	
11724/33650 (epoch 17.421), train_loss = 1.01423321, grad/param norm = 1.2384e-01, time/batch = 16.4795s	
11725/33650 (epoch 17.422), train_loss = 1.12746790, grad/param norm = 1.4390e-01, time/batch = 16.4053s	
11726/33650 (epoch 17.423), train_loss = 0.92526306, grad/param norm = 1.1829e-01, time/batch = 16.3885s	
11727/33650 (epoch 17.425), train_loss = 1.06866678, grad/param norm = 1.9469e-01, time/batch = 18.1520s	
11728/33650 (epoch 17.426), train_loss = 1.19786949, grad/param norm = 1.6146e-01, time/batch = 17.8262s	
11729/33650 (epoch 17.428), train_loss = 0.96839782, grad/param norm = 1.3585e-01, time/batch = 16.4708s	
11730/33650 (epoch 17.429), train_loss = 1.11960790, grad/param norm = 1.5554e-01, time/batch = 17.3151s	
11731/33650 (epoch 17.431), train_loss = 1.22809903, grad/param norm = 1.7127e-01, time/batch = 17.3135s	
11732/33650 (epoch 17.432), train_loss = 1.27641667, grad/param norm = 1.7184e-01, time/batch = 17.1504s	
11733/33650 (epoch 17.434), train_loss = 1.07005309, grad/param norm = 1.4662e-01, time/batch = 16.3946s	
11734/33650 (epoch 17.435), train_loss = 1.04145989, grad/param norm = 1.7879e-01, time/batch = 17.3311s	
11735/33650 (epoch 17.437), train_loss = 1.04266758, grad/param norm = 1.5186e-01, time/batch = 17.3201s	
11736/33650 (epoch 17.438), train_loss = 0.98455291, grad/param norm = 1.4777e-01, time/batch = 16.7289s	
11737/33650 (epoch 17.440), train_loss = 1.05676002, grad/param norm = 1.5522e-01, time/batch = 17.0616s	
11738/33650 (epoch 17.441), train_loss = 1.08904524, grad/param norm = 1.7765e-01, time/batch = 17.5775s	
11739/33650 (epoch 17.443), train_loss = 1.07935023, grad/param norm = 1.3400e-01, time/batch = 17.2387s	
11740/33650 (epoch 17.444), train_loss = 1.00427797, grad/param norm = 1.4094e-01, time/batch = 16.9564s	
11741/33650 (epoch 17.446), train_loss = 1.10758861, grad/param norm = 1.6581e-01, time/batch = 16.5455s	
11742/33650 (epoch 17.447), train_loss = 1.14875375, grad/param norm = 1.5580e-01, time/batch = 17.0735s	
11743/33650 (epoch 17.449), train_loss = 1.21292659, grad/param norm = 1.8514e-01, time/batch = 16.4046s	
11744/33650 (epoch 17.450), train_loss = 1.22820127, grad/param norm = 1.5294e-01, time/batch = 17.3205s	
11745/33650 (epoch 17.452), train_loss = 1.25676989, grad/param norm = 1.7176e-01, time/batch = 17.9967s	
11746/33650 (epoch 17.453), train_loss = 1.22703969, grad/param norm = 1.7817e-01, time/batch = 17.0789s	
11747/33650 (epoch 17.455), train_loss = 1.01297150, grad/param norm = 1.4951e-01, time/batch = 16.9875s	
11748/33650 (epoch 17.456), train_loss = 1.04356185, grad/param norm = 1.3528e-01, time/batch = 17.4135s	
11749/33650 (epoch 17.458), train_loss = 1.02044216, grad/param norm = 1.6877e-01, time/batch = 17.9032s	
11750/33650 (epoch 17.459), train_loss = 1.07528650, grad/param norm = 1.6474e-01, time/batch = 15.8136s	
11751/33650 (epoch 17.461), train_loss = 1.22029504, grad/param norm = 1.6379e-01, time/batch = 17.5618s	
11752/33650 (epoch 17.462), train_loss = 1.18323586, grad/param norm = 1.6540e-01, time/batch = 17.4126s	
11753/33650 (epoch 17.464), train_loss = 1.00095418, grad/param norm = 1.7144e-01, time/batch = 17.0638s	
11754/33650 (epoch 17.465), train_loss = 1.08620815, grad/param norm = 1.6868e-01, time/batch = 16.9902s	
11755/33650 (epoch 17.467), train_loss = 1.09846583, grad/param norm = 1.4651e-01, time/batch = 16.8248s	
11756/33650 (epoch 17.468), train_loss = 1.16686591, grad/param norm = 1.6364e-01, time/batch = 17.6753s	
11757/33650 (epoch 17.470), train_loss = 1.29605870, grad/param norm = 1.9318e-01, time/batch = 17.0747s	
11758/33650 (epoch 17.471), train_loss = 1.04746180, grad/param norm = 1.5526e-01, time/batch = 15.9713s	
11759/33650 (epoch 17.473), train_loss = 1.00399804, grad/param norm = 1.3951e-01, time/batch = 16.5489s	
11760/33650 (epoch 17.474), train_loss = 1.14062109, grad/param norm = 1.4287e-01, time/batch = 17.4029s	
11761/33650 (epoch 17.475), train_loss = 1.11967177, grad/param norm = 1.4841e-01, time/batch = 17.3954s	
11762/33650 (epoch 17.477), train_loss = 1.17009689, grad/param norm = 1.4268e-01, time/batch = 17.5694s	
11763/33650 (epoch 17.478), train_loss = 1.17638627, grad/param norm = 1.5668e-01, time/batch = 17.7337s	
11764/33650 (epoch 17.480), train_loss = 1.15676719, grad/param norm = 1.6433e-01, time/batch = 15.6485s	
11765/33650 (epoch 17.481), train_loss = 1.23739222, grad/param norm = 1.6141e-01, time/batch = 17.8260s	
11766/33650 (epoch 17.483), train_loss = 0.85629143, grad/param norm = 1.4073e-01, time/batch = 16.4700s	
11767/33650 (epoch 17.484), train_loss = 1.06198626, grad/param norm = 1.5019e-01, time/batch = 16.7335s	
11768/33650 (epoch 17.486), train_loss = 1.17569308, grad/param norm = 1.5708e-01, time/batch = 17.6416s	
11769/33650 (epoch 17.487), train_loss = 1.21068238, grad/param norm = 1.8332e-01, time/batch = 17.3211s	
11770/33650 (epoch 17.489), train_loss = 1.23396815, grad/param norm = 1.5444e-01, time/batch = 16.5881s	
11771/33650 (epoch 17.490), train_loss = 0.96673064, grad/param norm = 1.4706e-01, time/batch = 16.3940s	
11772/33650 (epoch 17.492), train_loss = 1.09353419, grad/param norm = 1.6619e-01, time/batch = 15.2291s	
11773/33650 (epoch 17.493), train_loss = 0.89882349, grad/param norm = 1.4291e-01, time/batch = 17.4848s	
11774/33650 (epoch 17.495), train_loss = 1.06778730, grad/param norm = 1.3930e-01, time/batch = 17.0011s	
11775/33650 (epoch 17.496), train_loss = 1.11724238, grad/param norm = 1.5236e-01, time/batch = 16.6483s	
11776/33650 (epoch 17.498), train_loss = 0.95016914, grad/param norm = 1.3646e-01, time/batch = 17.2421s	
11777/33650 (epoch 17.499), train_loss = 1.03962022, grad/param norm = 1.2317e-01, time/batch = 17.5643s	
11778/33650 (epoch 17.501), train_loss = 1.03780970, grad/param norm = 1.3561e-01, time/batch = 15.9058s	
11779/33650 (epoch 17.502), train_loss = 1.06209611, grad/param norm = 1.4803e-01, time/batch = 17.3244s	
11780/33650 (epoch 17.504), train_loss = 1.16015523, grad/param norm = 1.6196e-01, time/batch = 16.1441s	
11781/33650 (epoch 17.505), train_loss = 1.00586665, grad/param norm = 1.5639e-01, time/batch = 17.3242s	
11782/33650 (epoch 17.507), train_loss = 1.19134917, grad/param norm = 1.5819e-01, time/batch = 16.2286s	
11783/33650 (epoch 17.508), train_loss = 1.02440200, grad/param norm = 1.4234e-01, time/batch = 17.3945s	
11784/33650 (epoch 17.510), train_loss = 1.04717529, grad/param norm = 1.5519e-01, time/batch = 17.2333s	
11785/33650 (epoch 17.511), train_loss = 1.29986418, grad/param norm = 1.6405e-01, time/batch = 16.5588s	
11786/33650 (epoch 17.513), train_loss = 1.12545884, grad/param norm = 1.5534e-01, time/batch = 17.5814s	
11787/33650 (epoch 17.514), train_loss = 1.14445003, grad/param norm = 1.5219e-01, time/batch = 17.4112s	
11788/33650 (epoch 17.516), train_loss = 1.07902260, grad/param norm = 1.7514e-01, time/batch = 18.0689s	
11789/33650 (epoch 17.517), train_loss = 1.06716441, grad/param norm = 1.4966e-01, time/batch = 16.3767s	
11790/33650 (epoch 17.519), train_loss = 1.12671469, grad/param norm = 1.6094e-01, time/batch = 18.0770s	
11791/33650 (epoch 17.520), train_loss = 0.91776817, grad/param norm = 1.3502e-01, time/batch = 17.6443s	
11792/33650 (epoch 17.522), train_loss = 1.05119562, grad/param norm = 1.5383e-01, time/batch = 16.4750s	
11793/33650 (epoch 17.523), train_loss = 1.00206509, grad/param norm = 1.3592e-01, time/batch = 16.4923s	
11794/33650 (epoch 17.525), train_loss = 0.84601829, grad/param norm = 1.2953e-01, time/batch = 16.3203s	
11795/33650 (epoch 17.526), train_loss = 1.14915863, grad/param norm = 1.4061e-01, time/batch = 17.0700s	
11796/33650 (epoch 17.527), train_loss = 0.98399184, grad/param norm = 1.4167e-01, time/batch = 16.2296s	
11797/33650 (epoch 17.529), train_loss = 1.05914848, grad/param norm = 1.4751e-01, time/batch = 17.5762s	
11798/33650 (epoch 17.530), train_loss = 1.00753379, grad/param norm = 1.4692e-01, time/batch = 17.4809s	
11799/33650 (epoch 17.532), train_loss = 1.20326304, grad/param norm = 1.9992e-01, time/batch = 15.7427s	
11800/33650 (epoch 17.533), train_loss = 1.04024774, grad/param norm = 1.5239e-01, time/batch = 17.4116s	
11801/33650 (epoch 17.535), train_loss = 1.14086654, grad/param norm = 1.4909e-01, time/batch = 17.4114s	
11802/33650 (epoch 17.536), train_loss = 1.09253751, grad/param norm = 1.6379e-01, time/batch = 17.6518s	
11803/33650 (epoch 17.538), train_loss = 1.12590362, grad/param norm = 1.6901e-01, time/batch = 16.2089s	
11804/33650 (epoch 17.539), train_loss = 0.86872660, grad/param norm = 1.4148e-01, time/batch = 18.1506s	
11805/33650 (epoch 17.541), train_loss = 1.17933169, grad/param norm = 1.7276e-01, time/batch = 18.4837s	
11806/33650 (epoch 17.542), train_loss = 1.12973938, grad/param norm = 2.0222e-01, time/batch = 26.6300s	
11807/33650 (epoch 17.544), train_loss = 1.24931154, grad/param norm = 1.9283e-01, time/batch = 21.7670s	
11808/33650 (epoch 17.545), train_loss = 0.92834186, grad/param norm = 1.3435e-01, time/batch = 18.5591s	
11809/33650 (epoch 17.547), train_loss = 1.07272971, grad/param norm = 1.4527e-01, time/batch = 15.7928s	
11810/33650 (epoch 17.548), train_loss = 1.23812463, grad/param norm = 1.5617e-01, time/batch = 17.8980s	
11811/33650 (epoch 17.550), train_loss = 1.06007497, grad/param norm = 1.4748e-01, time/batch = 17.1502s	
11812/33650 (epoch 17.551), train_loss = 1.07869750, grad/param norm = 1.5404e-01, time/batch = 17.4035s	
11813/33650 (epoch 17.553), train_loss = 0.95760051, grad/param norm = 1.6570e-01, time/batch = 17.8263s	
11814/33650 (epoch 17.554), train_loss = 1.19736280, grad/param norm = 1.5613e-01, time/batch = 18.3067s	
11815/33650 (epoch 17.556), train_loss = 1.14161371, grad/param norm = 1.9264e-01, time/batch = 17.8220s	
11816/33650 (epoch 17.557), train_loss = 1.16218779, grad/param norm = 1.6703e-01, time/batch = 17.4914s	
11817/33650 (epoch 17.559), train_loss = 1.33332814, grad/param norm = 1.9477e-01, time/batch = 17.9137s	
11818/33650 (epoch 17.560), train_loss = 1.27051620, grad/param norm = 1.5962e-01, time/batch = 17.9112s	
11819/33650 (epoch 17.562), train_loss = 1.16713820, grad/param norm = 1.4484e-01, time/batch = 15.4886s	
11820/33650 (epoch 17.563), train_loss = 1.10297616, grad/param norm = 1.4841e-01, time/batch = 15.5427s	
11821/33650 (epoch 17.565), train_loss = 1.07148742, grad/param norm = 1.4631e-01, time/batch = 15.1529s	
11822/33650 (epoch 17.566), train_loss = 1.05296421, grad/param norm = 1.5087e-01, time/batch = 15.2343s	
11823/33650 (epoch 17.568), train_loss = 1.09744507, grad/param norm = 1.6913e-01, time/batch = 15.6059s	
11824/33650 (epoch 17.569), train_loss = 1.00917342, grad/param norm = 1.4061e-01, time/batch = 14.4255s	
11825/33650 (epoch 17.571), train_loss = 1.19679263, grad/param norm = 1.6118e-01, time/batch = 14.2515s	
11826/33650 (epoch 17.572), train_loss = 1.12032664, grad/param norm = 1.2996e-01, time/batch = 14.2627s	
11827/33650 (epoch 17.574), train_loss = 1.05696470, grad/param norm = 1.6369e-01, time/batch = 15.0475s	
11828/33650 (epoch 17.575), train_loss = 1.04510806, grad/param norm = 1.4981e-01, time/batch = 14.0141s	
11829/33650 (epoch 17.577), train_loss = 1.04288567, grad/param norm = 1.4541e-01, time/batch = 14.9706s	
11830/33650 (epoch 17.578), train_loss = 1.12498702, grad/param norm = 1.4232e-01, time/batch = 14.0960s	
11831/33650 (epoch 17.579), train_loss = 1.12618403, grad/param norm = 1.4713e-01, time/batch = 14.7552s	
11832/33650 (epoch 17.581), train_loss = 1.19399888, grad/param norm = 1.5750e-01, time/batch = 14.7476s	
11833/33650 (epoch 17.582), train_loss = 1.14277245, grad/param norm = 1.3483e-01, time/batch = 14.1733s	
11834/33650 (epoch 17.584), train_loss = 1.14180985, grad/param norm = 1.5553e-01, time/batch = 14.1792s	
11835/33650 (epoch 17.585), train_loss = 1.13083850, grad/param norm = 1.5450e-01, time/batch = 14.9101s	
11836/33650 (epoch 17.587), train_loss = 0.98286335, grad/param norm = 1.3294e-01, time/batch = 14.3438s	
11837/33650 (epoch 17.588), train_loss = 1.01869895, grad/param norm = 1.8072e-01, time/batch = 14.3479s	
11838/33650 (epoch 17.590), train_loss = 1.02068535, grad/param norm = 1.3855e-01, time/batch = 14.4988s	
11839/33650 (epoch 17.591), train_loss = 1.00835145, grad/param norm = 1.5372e-01, time/batch = 14.9734s	
11840/33650 (epoch 17.593), train_loss = 0.97231674, grad/param norm = 1.3519e-01, time/batch = 14.5853s	
11841/33650 (epoch 17.594), train_loss = 0.95259145, grad/param norm = 1.5517e-01, time/batch = 14.4352s	
11842/33650 (epoch 17.596), train_loss = 1.06015757, grad/param norm = 1.4350e-01, time/batch = 14.2661s	
11843/33650 (epoch 17.597), train_loss = 0.88592370, grad/param norm = 1.2053e-01, time/batch = 14.5847s	
11844/33650 (epoch 17.599), train_loss = 1.03738950, grad/param norm = 1.5411e-01, time/batch = 14.5140s	
11845/33650 (epoch 17.600), train_loss = 0.97213054, grad/param norm = 1.3815e-01, time/batch = 14.4331s	
11846/33650 (epoch 17.602), train_loss = 1.11105761, grad/param norm = 1.4115e-01, time/batch = 14.2690s	
11847/33650 (epoch 17.603), train_loss = 0.99271795, grad/param norm = 1.4082e-01, time/batch = 14.5021s	
11848/33650 (epoch 17.605), train_loss = 1.11611189, grad/param norm = 1.5385e-01, time/batch = 14.6643s	
11849/33650 (epoch 17.606), train_loss = 1.15122833, grad/param norm = 1.6524e-01, time/batch = 14.2680s	
11850/33650 (epoch 17.608), train_loss = 0.99467039, grad/param norm = 1.6362e-01, time/batch = 14.8267s	
11851/33650 (epoch 17.609), train_loss = 1.07152621, grad/param norm = 1.6236e-01, time/batch = 14.4137s	
11852/33650 (epoch 17.611), train_loss = 0.94333760, grad/param norm = 1.3896e-01, time/batch = 14.2654s	
11853/33650 (epoch 17.612), train_loss = 1.05203366, grad/param norm = 1.4975e-01, time/batch = 14.3577s	
11854/33650 (epoch 17.614), train_loss = 1.15276073, grad/param norm = 1.5622e-01, time/batch = 14.3548s	
11855/33650 (epoch 17.615), train_loss = 1.02152863, grad/param norm = 1.2877e-01, time/batch = 14.5078s	
11856/33650 (epoch 17.617), train_loss = 0.96017415, grad/param norm = 1.2386e-01, time/batch = 14.5768s	
11857/33650 (epoch 17.618), train_loss = 1.02205422, grad/param norm = 1.4273e-01, time/batch = 14.3472s	
11858/33650 (epoch 17.620), train_loss = 1.09508084, grad/param norm = 1.7233e-01, time/batch = 14.4270s	
11859/33650 (epoch 17.621), train_loss = 0.95563448, grad/param norm = 1.3964e-01, time/batch = 14.4032s	
11860/33650 (epoch 17.623), train_loss = 1.03826006, grad/param norm = 1.4570e-01, time/batch = 14.6632s	
11861/33650 (epoch 17.624), train_loss = 0.83195620, grad/param norm = 1.3571e-01, time/batch = 14.5892s	
11862/33650 (epoch 17.626), train_loss = 0.82275043, grad/param norm = 1.2046e-01, time/batch = 14.4390s	
11863/33650 (epoch 17.627), train_loss = 0.95865226, grad/param norm = 1.6056e-01, time/batch = 14.2796s	
11864/33650 (epoch 17.629), train_loss = 1.02316514, grad/param norm = 1.5039e-01, time/batch = 14.9122s	
11865/33650 (epoch 17.630), train_loss = 1.13750010, grad/param norm = 1.5713e-01, time/batch = 14.3387s	
11866/33650 (epoch 17.632), train_loss = 1.17419501, grad/param norm = 1.4649e-01, time/batch = 15.2086s	
11867/33650 (epoch 17.633), train_loss = 1.14410515, grad/param norm = 1.4304e-01, time/batch = 14.3482s	
11868/33650 (epoch 17.634), train_loss = 0.90979567, grad/param norm = 1.3525e-01, time/batch = 14.7462s	
11869/33650 (epoch 17.636), train_loss = 0.79881890, grad/param norm = 1.1376e-01, time/batch = 14.2659s	
11870/33650 (epoch 17.637), train_loss = 1.00142707, grad/param norm = 1.4477e-01, time/batch = 14.2619s	
11871/33650 (epoch 17.639), train_loss = 0.98750030, grad/param norm = 1.3500e-01, time/batch = 14.5988s	
11872/33650 (epoch 17.640), train_loss = 1.05037763, grad/param norm = 1.4921e-01, time/batch = 14.8395s	
11873/33650 (epoch 17.642), train_loss = 1.11378390, grad/param norm = 1.5235e-01, time/batch = 14.4986s	
11874/33650 (epoch 17.643), train_loss = 1.06593305, grad/param norm = 1.5838e-01, time/batch = 14.3587s	
11875/33650 (epoch 17.645), train_loss = 1.06321013, grad/param norm = 1.4057e-01, time/batch = 14.5794s	
11876/33650 (epoch 17.646), train_loss = 0.89027092, grad/param norm = 1.2012e-01, time/batch = 14.7458s	
11877/33650 (epoch 17.648), train_loss = 1.05906598, grad/param norm = 1.3721e-01, time/batch = 14.5066s	
11878/33650 (epoch 17.649), train_loss = 1.02002446, grad/param norm = 1.8050e-01, time/batch = 14.1941s	
11879/33650 (epoch 17.651), train_loss = 1.19066601, grad/param norm = 1.6559e-01, time/batch = 14.3414s	
11880/33650 (epoch 17.652), train_loss = 0.75461018, grad/param norm = 1.0945e-01, time/batch = 14.5747s	
11881/33650 (epoch 17.654), train_loss = 0.95108461, grad/param norm = 1.3294e-01, time/batch = 14.4245s	
11882/33650 (epoch 17.655), train_loss = 0.92404693, grad/param norm = 1.2437e-01, time/batch = 14.4230s	
11883/33650 (epoch 17.657), train_loss = 0.99787400, grad/param norm = 1.5068e-01, time/batch = 14.3521s	
11884/33650 (epoch 17.658), train_loss = 0.89137190, grad/param norm = 1.3584e-01, time/batch = 14.6562s	
11885/33650 (epoch 17.660), train_loss = 0.85238750, grad/param norm = 1.4017e-01, time/batch = 15.5786s	
11886/33650 (epoch 17.661), train_loss = 0.96586951, grad/param norm = 1.3784e-01, time/batch = 14.5620s	
11887/33650 (epoch 17.663), train_loss = 0.90301199, grad/param norm = 1.4279e-01, time/batch = 14.6525s	
11888/33650 (epoch 17.664), train_loss = 0.93519643, grad/param norm = 1.2650e-01, time/batch = 14.5689s	
11889/33650 (epoch 17.666), train_loss = 0.97387464, grad/param norm = 1.2652e-01, time/batch = 14.3421s	
11890/33650 (epoch 17.667), train_loss = 0.92021601, grad/param norm = 1.3223e-01, time/batch = 14.1028s	
11891/33650 (epoch 17.669), train_loss = 0.93012136, grad/param norm = 1.6098e-01, time/batch = 14.5057s	
11892/33650 (epoch 17.670), train_loss = 0.85287249, grad/param norm = 1.3736e-01, time/batch = 14.3447s	
11893/33650 (epoch 17.672), train_loss = 0.88896405, grad/param norm = 1.4467e-01, time/batch = 14.5906s	
11894/33650 (epoch 17.673), train_loss = 0.82893467, grad/param norm = 1.2965e-01, time/batch = 14.4305s	
11895/33650 (epoch 17.675), train_loss = 0.83213425, grad/param norm = 1.2770e-01, time/batch = 14.8423s	
11896/33650 (epoch 17.676), train_loss = 1.01905686, grad/param norm = 1.4997e-01, time/batch = 14.3399s	
11897/33650 (epoch 17.678), train_loss = 0.95267342, grad/param norm = 1.4542e-01, time/batch = 14.5783s	
11898/33650 (epoch 17.679), train_loss = 0.97897266, grad/param norm = 1.5176e-01, time/batch = 14.1088s	
11899/33650 (epoch 17.681), train_loss = 0.96739674, grad/param norm = 1.2220e-01, time/batch = 14.5754s	
11900/33650 (epoch 17.682), train_loss = 0.92401533, grad/param norm = 1.4135e-01, time/batch = 14.1779s	
11901/33650 (epoch 17.684), train_loss = 0.90142284, grad/param norm = 1.3397e-01, time/batch = 14.5886s	
11902/33650 (epoch 17.685), train_loss = 1.09496934, grad/param norm = 1.4995e-01, time/batch = 14.4137s	
11903/33650 (epoch 17.686), train_loss = 1.03719824, grad/param norm = 1.3465e-01, time/batch = 14.6491s	
11904/33650 (epoch 17.688), train_loss = 1.12154452, grad/param norm = 1.4377e-01, time/batch = 14.3337s	
11905/33650 (epoch 17.689), train_loss = 0.92765107, grad/param norm = 1.3110e-01, time/batch = 15.1398s	
11906/33650 (epoch 17.691), train_loss = 1.14439118, grad/param norm = 1.5178e-01, time/batch = 14.3443s	
11907/33650 (epoch 17.692), train_loss = 1.14165027, grad/param norm = 1.4445e-01, time/batch = 14.1878s	
11908/33650 (epoch 17.694), train_loss = 1.05600850, grad/param norm = 1.5618e-01, time/batch = 14.3456s	
11909/33650 (epoch 17.695), train_loss = 0.75070159, grad/param norm = 1.2942e-01, time/batch = 14.6501s	
11910/33650 (epoch 17.697), train_loss = 0.98960895, grad/param norm = 1.5015e-01, time/batch = 14.3344s	
11911/33650 (epoch 17.698), train_loss = 1.17963124, grad/param norm = 1.5723e-01, time/batch = 14.3420s	
11912/33650 (epoch 17.700), train_loss = 1.00212488, grad/param norm = 1.4406e-01, time/batch = 14.3439s	
11913/33650 (epoch 17.701), train_loss = 1.04696185, grad/param norm = 1.4530e-01, time/batch = 14.6550s	
11914/33650 (epoch 17.703), train_loss = 1.16754098, grad/param norm = 1.3942e-01, time/batch = 14.3457s	
11915/33650 (epoch 17.704), train_loss = 0.98281734, grad/param norm = 1.2742e-01, time/batch = 14.4309s	
11916/33650 (epoch 17.706), train_loss = 0.97392131, grad/param norm = 1.2955e-01, time/batch = 14.3468s	
11917/33650 (epoch 17.707), train_loss = 1.10725188, grad/param norm = 1.3741e-01, time/batch = 17.6361s	
11918/33650 (epoch 17.709), train_loss = 0.99336740, grad/param norm = 1.4570e-01, time/batch = 17.9455s	
11919/33650 (epoch 17.710), train_loss = 1.20310075, grad/param norm = 1.4770e-01, time/batch = 18.5569s	
11920/33650 (epoch 17.712), train_loss = 0.93974902, grad/param norm = 1.3892e-01, time/batch = 16.7839s	
11921/33650 (epoch 17.713), train_loss = 0.92485074, grad/param norm = 1.8307e-01, time/batch = 18.0468s	
11922/33650 (epoch 17.715), train_loss = 1.12345310, grad/param norm = 1.6969e-01, time/batch = 18.7211s	
11923/33650 (epoch 17.716), train_loss = 0.93486725, grad/param norm = 1.3429e-01, time/batch = 19.4574s	
11924/33650 (epoch 17.718), train_loss = 0.98061629, grad/param norm = 1.6081e-01, time/batch = 15.9021s	
11925/33650 (epoch 17.719), train_loss = 1.15456846, grad/param norm = 1.6308e-01, time/batch = 16.2481s	
11926/33650 (epoch 17.721), train_loss = 1.25209009, grad/param norm = 1.8248e-01, time/batch = 16.0273s	
11927/33650 (epoch 17.722), train_loss = 1.10115400, grad/param norm = 1.7505e-01, time/batch = 15.8496s	
11928/33650 (epoch 17.724), train_loss = 1.13682803, grad/param norm = 1.5985e-01, time/batch = 17.1367s	
11929/33650 (epoch 17.725), train_loss = 1.13049127, grad/param norm = 1.5412e-01, time/batch = 18.0532s	
11930/33650 (epoch 17.727), train_loss = 0.95372480, grad/param norm = 1.6301e-01, time/batch = 18.2252s	
11931/33650 (epoch 17.728), train_loss = 0.97188393, grad/param norm = 1.3650e-01, time/batch = 16.9038s	
11932/33650 (epoch 17.730), train_loss = 1.08064500, grad/param norm = 1.5450e-01, time/batch = 18.4803s	
11933/33650 (epoch 17.731), train_loss = 1.15536614, grad/param norm = 1.6139e-01, time/batch = 18.6394s	
11934/33650 (epoch 17.733), train_loss = 1.02390460, grad/param norm = 1.5504e-01, time/batch = 16.3163s	
11935/33650 (epoch 17.734), train_loss = 1.16766109, grad/param norm = 1.7297e-01, time/batch = 17.8247s	
11936/33650 (epoch 17.736), train_loss = 1.03603186, grad/param norm = 1.4801e-01, time/batch = 15.8906s	
11937/33650 (epoch 17.737), train_loss = 1.07782173, grad/param norm = 1.6516e-01, time/batch = 17.6429s	
11938/33650 (epoch 17.738), train_loss = 0.91511000, grad/param norm = 1.4318e-01, time/batch = 16.8808s	
11939/33650 (epoch 17.740), train_loss = 0.89978397, grad/param norm = 1.4187e-01, time/batch = 18.0547s	
11940/33650 (epoch 17.741), train_loss = 0.94918239, grad/param norm = 1.5228e-01, time/batch = 18.1469s	
11941/33650 (epoch 17.743), train_loss = 1.00952231, grad/param norm = 1.5349e-01, time/batch = 16.4661s	
11942/33650 (epoch 17.744), train_loss = 1.04458648, grad/param norm = 1.3575e-01, time/batch = 18.3114s	
11943/33650 (epoch 17.746), train_loss = 1.01196926, grad/param norm = 1.3502e-01, time/batch = 18.8884s	
11944/33650 (epoch 17.747), train_loss = 1.12885579, grad/param norm = 1.5254e-01, time/batch = 17.5505s	
11945/33650 (epoch 17.749), train_loss = 0.86252566, grad/param norm = 1.3254e-01, time/batch = 17.3616s	
11946/33650 (epoch 17.750), train_loss = 1.14851804, grad/param norm = 1.4291e-01, time/batch = 17.9817s	
11947/33650 (epoch 17.752), train_loss = 1.14679455, grad/param norm = 1.5334e-01, time/batch = 18.8807s	
11948/33650 (epoch 17.753), train_loss = 1.23947035, grad/param norm = 1.6081e-01, time/batch = 17.1299s	
11949/33650 (epoch 17.755), train_loss = 0.99510388, grad/param norm = 1.3873e-01, time/batch = 18.0587s	
11950/33650 (epoch 17.756), train_loss = 1.10115479, grad/param norm = 1.4812e-01, time/batch = 17.6568s	
11951/33650 (epoch 17.758), train_loss = 1.12360932, grad/param norm = 1.5363e-01, time/batch = 17.8815s	
11952/33650 (epoch 17.759), train_loss = 1.16537018, grad/param norm = 1.4508e-01, time/batch = 18.0460s	
11953/33650 (epoch 17.761), train_loss = 1.08500300, grad/param norm = 1.5128e-01, time/batch = 18.6445s	
11954/33650 (epoch 17.762), train_loss = 1.04654132, grad/param norm = 1.4653e-01, time/batch = 17.8875s	
11955/33650 (epoch 17.764), train_loss = 1.09764252, grad/param norm = 1.5704e-01, time/batch = 17.5716s	
11956/33650 (epoch 17.765), train_loss = 1.04835317, grad/param norm = 1.5171e-01, time/batch = 18.4875s	
11957/33650 (epoch 17.767), train_loss = 1.01766308, grad/param norm = 1.3196e-01, time/batch = 18.2381s	
11958/33650 (epoch 17.768), train_loss = 0.91459462, grad/param norm = 1.3495e-01, time/batch = 16.9450s	
11959/33650 (epoch 17.770), train_loss = 1.08609585, grad/param norm = 1.5359e-01, time/batch = 16.3873s	
11960/33650 (epoch 17.771), train_loss = 1.04646847, grad/param norm = 1.4137e-01, time/batch = 18.9779s	
11961/33650 (epoch 17.773), train_loss = 1.18036469, grad/param norm = 1.5868e-01, time/batch = 16.9741s	
11962/33650 (epoch 17.774), train_loss = 1.08892037, grad/param norm = 1.5651e-01, time/batch = 17.8952s	
11963/33650 (epoch 17.776), train_loss = 1.13852048, grad/param norm = 1.6010e-01, time/batch = 17.0672s	
11964/33650 (epoch 17.777), train_loss = 0.92672796, grad/param norm = 1.4330e-01, time/batch = 17.3134s	
11965/33650 (epoch 17.779), train_loss = 1.00426735, grad/param norm = 1.3721e-01, time/batch = 18.7178s	
11966/33650 (epoch 17.780), train_loss = 0.94927189, grad/param norm = 1.2865e-01, time/batch = 17.9054s	
11967/33650 (epoch 17.782), train_loss = 0.96226648, grad/param norm = 1.3714e-01, time/batch = 19.1430s	
11968/33650 (epoch 17.783), train_loss = 0.92822493, grad/param norm = 1.3051e-01, time/batch = 17.4707s	
11969/33650 (epoch 17.785), train_loss = 1.24089819, grad/param norm = 1.4084e-01, time/batch = 17.9911s	
11970/33650 (epoch 17.786), train_loss = 1.08298638, grad/param norm = 1.4215e-01, time/batch = 15.4709s	
11971/33650 (epoch 17.788), train_loss = 1.08033178, grad/param norm = 1.4394e-01, time/batch = 16.2075s	
11972/33650 (epoch 17.789), train_loss = 1.11115565, grad/param norm = 1.4492e-01, time/batch = 18.2433s	
11973/33650 (epoch 17.790), train_loss = 1.07842736, grad/param norm = 1.6370e-01, time/batch = 17.7383s	
11974/33650 (epoch 17.792), train_loss = 1.15768786, grad/param norm = 1.6430e-01, time/batch = 18.7293s	
11975/33650 (epoch 17.793), train_loss = 1.14176143, grad/param norm = 1.9032e-01, time/batch = 17.4642s	
11976/33650 (epoch 17.795), train_loss = 1.18867409, grad/param norm = 1.5744e-01, time/batch = 17.4922s	
11977/33650 (epoch 17.796), train_loss = 1.01991774, grad/param norm = 1.4564e-01, time/batch = 17.5510s	
11978/33650 (epoch 17.798), train_loss = 1.01700135, grad/param norm = 1.4657e-01, time/batch = 16.5407s	
11979/33650 (epoch 17.799), train_loss = 1.05464810, grad/param norm = 1.3579e-01, time/batch = 18.5661s	
11980/33650 (epoch 17.801), train_loss = 1.08203865, grad/param norm = 1.4529e-01, time/batch = 16.4825s	
11981/33650 (epoch 17.802), train_loss = 1.15042685, grad/param norm = 1.4706e-01, time/batch = 17.2434s	
11982/33650 (epoch 17.804), train_loss = 1.04838237, grad/param norm = 1.6060e-01, time/batch = 17.3887s	
11983/33650 (epoch 17.805), train_loss = 1.01688660, grad/param norm = 1.2679e-01, time/batch = 18.4752s	
11984/33650 (epoch 17.807), train_loss = 1.26888807, grad/param norm = 1.7357e-01, time/batch = 18.4806s	
11985/33650 (epoch 17.808), train_loss = 1.31268113, grad/param norm = 1.8007e-01, time/batch = 17.1402s	
11986/33650 (epoch 17.810), train_loss = 1.10773432, grad/param norm = 1.5212e-01, time/batch = 18.0708s	
11987/33650 (epoch 17.811), train_loss = 1.07958360, grad/param norm = 1.5026e-01, time/batch = 17.6395s	
11988/33650 (epoch 17.813), train_loss = 0.98953581, grad/param norm = 1.3766e-01, time/batch = 16.4722s	
11989/33650 (epoch 17.814), train_loss = 1.12672742, grad/param norm = 1.5261e-01, time/batch = 17.9025s	
11990/33650 (epoch 17.816), train_loss = 1.09765828, grad/param norm = 1.4426e-01, time/batch = 18.2301s	
11991/33650 (epoch 17.817), train_loss = 1.14264810, grad/param norm = 1.6795e-01, time/batch = 18.3994s	
11992/33650 (epoch 17.819), train_loss = 1.12121451, grad/param norm = 1.4331e-01, time/batch = 17.7178s	
11993/33650 (epoch 17.820), train_loss = 1.18892747, grad/param norm = 1.5015e-01, time/batch = 17.9053s	
11994/33650 (epoch 17.822), train_loss = 1.10114503, grad/param norm = 1.5844e-01, time/batch = 18.6513s	
11995/33650 (epoch 17.823), train_loss = 0.99028329, grad/param norm = 1.4776e-01, time/batch = 16.4004s	
11996/33650 (epoch 17.825), train_loss = 1.05334096, grad/param norm = 1.4344e-01, time/batch = 18.1596s	
11997/33650 (epoch 17.826), train_loss = 1.11343173, grad/param norm = 1.4032e-01, time/batch = 17.7355s	
11998/33650 (epoch 17.828), train_loss = 1.24164301, grad/param norm = 1.5073e-01, time/batch = 17.4765s	
11999/33650 (epoch 17.829), train_loss = 0.90191675, grad/param norm = 1.4821e-01, time/batch = 16.8854s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch17.83_1.5587.t7	
12000/33650 (epoch 17.831), train_loss = 1.14250882, grad/param norm = 1.5429e-01, time/batch = 18.3872s	
12001/33650 (epoch 17.832), train_loss = 1.40467777, grad/param norm = 1.6993e-01, time/batch = 18.2013s	
12002/33650 (epoch 17.834), train_loss = 1.13641252, grad/param norm = 1.6594e-01, time/batch = 18.1591s	
12003/33650 (epoch 17.835), train_loss = 1.30531150, grad/param norm = 1.7484e-01, time/batch = 17.8913s	
12004/33650 (epoch 17.837), train_loss = 1.10933417, grad/param norm = 1.5511e-01, time/batch = 16.3957s	
12005/33650 (epoch 17.838), train_loss = 1.04817481, grad/param norm = 1.4811e-01, time/batch = 18.4007s	
12006/33650 (epoch 17.840), train_loss = 1.12127382, grad/param norm = 1.3369e-01, time/batch = 17.7210s	
12007/33650 (epoch 17.841), train_loss = 0.98072598, grad/param norm = 1.3825e-01, time/batch = 17.3969s	
12008/33650 (epoch 17.842), train_loss = 1.03812960, grad/param norm = 1.3564e-01, time/batch = 17.8879s	
12009/33650 (epoch 17.844), train_loss = 1.19112782, grad/param norm = 1.5419e-01, time/batch = 18.2356s	
12010/33650 (epoch 17.845), train_loss = 1.00010032, grad/param norm = 1.4342e-01, time/batch = 18.2220s	
12011/33650 (epoch 17.847), train_loss = 0.81092266, grad/param norm = 1.3246e-01, time/batch = 16.9724s	
12012/33650 (epoch 17.848), train_loss = 0.89960162, grad/param norm = 1.4230e-01, time/batch = 18.0660s	
12013/33650 (epoch 17.850), train_loss = 1.04562082, grad/param norm = 1.7542e-01, time/batch = 17.9775s	
12014/33650 (epoch 17.851), train_loss = 0.85484821, grad/param norm = 1.2876e-01, time/batch = 16.6088s	
12015/33650 (epoch 17.853), train_loss = 1.05833260, grad/param norm = 1.5893e-01, time/batch = 18.6384s	
12016/33650 (epoch 17.854), train_loss = 1.17574247, grad/param norm = 1.8471e-01, time/batch = 18.0517s	
12017/33650 (epoch 17.856), train_loss = 0.80870980, grad/param norm = 1.2684e-01, time/batch = 20.9985s	
12018/33650 (epoch 17.857), train_loss = 1.04568809, grad/param norm = 1.2782e-01, time/batch = 27.6230s	
12019/33650 (epoch 17.859), train_loss = 0.94536553, grad/param norm = 1.3350e-01, time/batch = 18.7363s	
12020/33650 (epoch 17.860), train_loss = 0.88136575, grad/param norm = 1.3275e-01, time/batch = 15.4807s	
12021/33650 (epoch 17.862), train_loss = 0.94078604, grad/param norm = 1.3564e-01, time/batch = 18.4757s	
12022/33650 (epoch 17.863), train_loss = 1.14898758, grad/param norm = 1.4427e-01, time/batch = 17.9705s	
12023/33650 (epoch 17.865), train_loss = 1.02339708, grad/param norm = 1.3885e-01, time/batch = 16.6358s	
12024/33650 (epoch 17.866), train_loss = 0.93140324, grad/param norm = 1.3460e-01, time/batch = 17.5746s	
12025/33650 (epoch 17.868), train_loss = 0.89789372, grad/param norm = 1.3906e-01, time/batch = 18.4681s	
12026/33650 (epoch 17.869), train_loss = 1.15163913, grad/param norm = 1.5849e-01, time/batch = 18.3080s	
12027/33650 (epoch 17.871), train_loss = 0.91625399, grad/param norm = 1.2245e-01, time/batch = 16.8113s	
12028/33650 (epoch 17.872), train_loss = 1.03789920, grad/param norm = 1.4643e-01, time/batch = 17.8936s	
12029/33650 (epoch 17.874), train_loss = 1.11217040, grad/param norm = 1.5864e-01, time/batch = 18.1516s	
12030/33650 (epoch 17.875), train_loss = 1.02920275, grad/param norm = 1.3471e-01, time/batch = 16.5478s	
12031/33650 (epoch 17.877), train_loss = 1.19265244, grad/param norm = 1.4581e-01, time/batch = 18.3039s	
12032/33650 (epoch 17.878), train_loss = 0.73663308, grad/param norm = 1.2326e-01, time/batch = 18.6619s	
12033/33650 (epoch 17.880), train_loss = 1.08488883, grad/param norm = 1.5643e-01, time/batch = 17.6382s	
12034/33650 (epoch 17.881), train_loss = 0.98974889, grad/param norm = 1.6564e-01, time/batch = 18.2289s	
12035/33650 (epoch 17.883), train_loss = 1.06473472, grad/param norm = 1.3957e-01, time/batch = 17.9042s	
12036/33650 (epoch 17.884), train_loss = 1.15524981, grad/param norm = 1.7246e-01, time/batch = 18.6453s	
12037/33650 (epoch 17.886), train_loss = 1.11800115, grad/param norm = 1.4312e-01, time/batch = 15.4641s	
12038/33650 (epoch 17.887), train_loss = 0.96178101, grad/param norm = 1.2959e-01, time/batch = 16.9685s	
12039/33650 (epoch 17.889), train_loss = 1.06110363, grad/param norm = 1.5851e-01, time/batch = 16.2349s	
12040/33650 (epoch 17.890), train_loss = 1.09942398, grad/param norm = 1.4612e-01, time/batch = 14.1341s	
12041/33650 (epoch 17.892), train_loss = 1.06030750, grad/param norm = 1.6491e-01, time/batch = 18.3961s	
12042/33650 (epoch 17.893), train_loss = 1.09088228, grad/param norm = 1.4771e-01, time/batch = 17.7216s	
12043/33650 (epoch 17.895), train_loss = 1.16527624, grad/param norm = 1.5140e-01, time/batch = 17.8931s	
12044/33650 (epoch 17.896), train_loss = 0.95950419, grad/param norm = 1.3499e-01, time/batch = 17.1323s	
12045/33650 (epoch 17.897), train_loss = 0.88712038, grad/param norm = 1.3124e-01, time/batch = 18.0680s	
12046/33650 (epoch 17.899), train_loss = 0.91731389, grad/param norm = 1.2544e-01, time/batch = 16.7111s	
12047/33650 (epoch 17.900), train_loss = 0.84716658, grad/param norm = 1.2706e-01, time/batch = 17.5548s	
12048/33650 (epoch 17.902), train_loss = 1.05907373, grad/param norm = 1.4424e-01, time/batch = 17.8097s	
12049/33650 (epoch 17.903), train_loss = 1.01130566, grad/param norm = 1.6181e-01, time/batch = 18.6432s	
12050/33650 (epoch 17.905), train_loss = 1.19432375, grad/param norm = 1.7283e-01, time/batch = 18.0606s	
12051/33650 (epoch 17.906), train_loss = 0.97796497, grad/param norm = 1.3662e-01, time/batch = 17.2957s	
12052/33650 (epoch 17.908), train_loss = 0.99748395, grad/param norm = 1.2851e-01, time/batch = 18.5673s	
12053/33650 (epoch 17.909), train_loss = 0.98132671, grad/param norm = 1.2774e-01, time/batch = 17.7311s	
12054/33650 (epoch 17.911), train_loss = 0.86119808, grad/param norm = 1.3879e-01, time/batch = 16.3926s	
12055/33650 (epoch 17.912), train_loss = 0.85212010, grad/param norm = 1.2462e-01, time/batch = 18.1410s	
12056/33650 (epoch 17.914), train_loss = 1.04390762, grad/param norm = 1.3685e-01, time/batch = 16.2225s	
12057/33650 (epoch 17.915), train_loss = 1.00528144, grad/param norm = 1.4310e-01, time/batch = 17.4010s	
12058/33650 (epoch 17.917), train_loss = 0.99968843, grad/param norm = 1.4223e-01, time/batch = 18.1345s	
12059/33650 (epoch 17.918), train_loss = 0.85151235, grad/param norm = 1.2088e-01, time/batch = 18.8154s	
12060/33650 (epoch 17.920), train_loss = 0.93636260, grad/param norm = 1.2555e-01, time/batch = 16.0753s	
12061/33650 (epoch 17.921), train_loss = 0.93917306, grad/param norm = 1.3132e-01, time/batch = 16.9642s	
12062/33650 (epoch 17.923), train_loss = 0.89143152, grad/param norm = 1.4050e-01, time/batch = 18.4769s	
12063/33650 (epoch 17.924), train_loss = 1.03191676, grad/param norm = 1.4058e-01, time/batch = 17.9761s	
12064/33650 (epoch 17.926), train_loss = 0.98485733, grad/param norm = 1.6032e-01, time/batch = 17.6410s	
12065/33650 (epoch 17.927), train_loss = 0.97269579, grad/param norm = 1.4544e-01, time/batch = 18.2247s	
12066/33650 (epoch 17.929), train_loss = 1.06696367, grad/param norm = 1.4482e-01, time/batch = 18.0518s	
12067/33650 (epoch 17.930), train_loss = 0.96758817, grad/param norm = 1.3863e-01, time/batch = 17.6417s	
12068/33650 (epoch 17.932), train_loss = 1.00868191, grad/param norm = 1.4533e-01, time/batch = 17.3959s	
12069/33650 (epoch 17.933), train_loss = 0.88576214, grad/param norm = 1.3428e-01, time/batch = 18.5626s	
12070/33650 (epoch 17.935), train_loss = 0.90492639, grad/param norm = 1.3656e-01, time/batch = 18.3157s	
12071/33650 (epoch 17.936), train_loss = 0.94173878, grad/param norm = 1.1854e-01, time/batch = 17.3868s	
12072/33650 (epoch 17.938), train_loss = 0.88703792, grad/param norm = 1.3501e-01, time/batch = 17.6317s	
12073/33650 (epoch 17.939), train_loss = 1.07961174, grad/param norm = 1.4674e-01, time/batch = 17.4507s	
12074/33650 (epoch 17.941), train_loss = 1.04366034, grad/param norm = 1.4356e-01, time/batch = 16.7289s	
12075/33650 (epoch 17.942), train_loss = 1.08818940, grad/param norm = 1.5229e-01, time/batch = 16.0630s	
12076/33650 (epoch 17.944), train_loss = 0.99773652, grad/param norm = 1.2989e-01, time/batch = 18.2301s	
12077/33650 (epoch 17.945), train_loss = 1.06325042, grad/param norm = 1.4703e-01, time/batch = 18.2303s	
12078/33650 (epoch 17.947), train_loss = 1.19664473, grad/param norm = 2.1243e-01, time/batch = 18.0443s	
12079/33650 (epoch 17.948), train_loss = 1.17435711, grad/param norm = 1.5277e-01, time/batch = 18.5545s	
12080/33650 (epoch 17.949), train_loss = 0.90807153, grad/param norm = 1.3577e-01, time/batch = 18.0703s	
12081/33650 (epoch 17.951), train_loss = 1.18298134, grad/param norm = 1.5684e-01, time/batch = 16.6212s	
12082/33650 (epoch 17.952), train_loss = 1.12079152, grad/param norm = 1.5594e-01, time/batch = 17.9777s	
12083/33650 (epoch 17.954), train_loss = 1.09964172, grad/param norm = 1.5850e-01, time/batch = 18.3189s	
12084/33650 (epoch 17.955), train_loss = 1.09697238, grad/param norm = 1.4687e-01, time/batch = 16.2003s	
12085/33650 (epoch 17.957), train_loss = 1.07928454, grad/param norm = 1.6121e-01, time/batch = 16.3790s	
12086/33650 (epoch 17.958), train_loss = 0.82371968, grad/param norm = 1.2859e-01, time/batch = 18.4019s	
12087/33650 (epoch 17.960), train_loss = 0.85735553, grad/param norm = 1.2940e-01, time/batch = 17.8983s	
12088/33650 (epoch 17.961), train_loss = 0.91185406, grad/param norm = 1.4263e-01, time/batch = 17.7090s	
12089/33650 (epoch 17.963), train_loss = 1.00503189, grad/param norm = 1.6017e-01, time/batch = 17.9865s	
12090/33650 (epoch 17.964), train_loss = 1.06562737, grad/param norm = 1.4357e-01, time/batch = 17.3912s	
12091/33650 (epoch 17.966), train_loss = 1.03075680, grad/param norm = 1.4554e-01, time/batch = 16.8060s	
12092/33650 (epoch 17.967), train_loss = 1.07086320, grad/param norm = 1.5758e-01, time/batch = 18.3013s	
12093/33650 (epoch 17.969), train_loss = 1.00831532, grad/param norm = 1.3737e-01, time/batch = 17.4003s	
12094/33650 (epoch 17.970), train_loss = 1.08526074, grad/param norm = 1.4223e-01, time/batch = 17.3914s	
12095/33650 (epoch 17.972), train_loss = 1.34632124, grad/param norm = 1.5857e-01, time/batch = 17.1464s	
12096/33650 (epoch 17.973), train_loss = 0.92829259, grad/param norm = 1.3537e-01, time/batch = 18.5632s	
12097/33650 (epoch 17.975), train_loss = 0.93020754, grad/param norm = 1.3069e-01, time/batch = 17.8873s	
12098/33650 (epoch 17.976), train_loss = 0.92926262, grad/param norm = 1.3028e-01, time/batch = 16.0558s	
12099/33650 (epoch 17.978), train_loss = 0.95657704, grad/param norm = 1.4769e-01, time/batch = 17.3980s	
12100/33650 (epoch 17.979), train_loss = 1.01002800, grad/param norm = 1.4262e-01, time/batch = 18.1491s	
12101/33650 (epoch 17.981), train_loss = 0.95727108, grad/param norm = 1.1588e-01, time/batch = 17.2152s	
12102/33650 (epoch 17.982), train_loss = 1.04616392, grad/param norm = 1.4063e-01, time/batch = 15.0436s	
12103/33650 (epoch 17.984), train_loss = 0.85650122, grad/param norm = 1.2860e-01, time/batch = 14.8759s	
12104/33650 (epoch 17.985), train_loss = 0.87951458, grad/param norm = 1.4346e-01, time/batch = 18.7361s	
12105/33650 (epoch 17.987), train_loss = 1.00895506, grad/param norm = 1.3627e-01, time/batch = 17.3071s	
12106/33650 (epoch 17.988), train_loss = 1.03611312, grad/param norm = 1.4496e-01, time/batch = 18.1419s	
12107/33650 (epoch 17.990), train_loss = 1.25050010, grad/param norm = 1.7841e-01, time/batch = 17.0612s	
12108/33650 (epoch 17.991), train_loss = 1.07763363, grad/param norm = 1.4720e-01, time/batch = 17.3971s	
12109/33650 (epoch 17.993), train_loss = 1.04993070, grad/param norm = 1.5950e-01, time/batch = 17.6441s	
12110/33650 (epoch 17.994), train_loss = 0.98026459, grad/param norm = 1.2794e-01, time/batch = 17.5541s	
12111/33650 (epoch 17.996), train_loss = 0.94949037, grad/param norm = 1.5168e-01, time/batch = 16.7934s	
12112/33650 (epoch 17.997), train_loss = 1.05444522, grad/param norm = 1.4199e-01, time/batch = 16.3744s	
12113/33650 (epoch 17.999), train_loss = 0.92366299, grad/param norm = 1.2634e-01, time/batch = 17.7373s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
12114/33650 (epoch 18.000), train_loss = 1.09952850, grad/param norm = 1.6871e-01, time/batch = 17.7632s	
12115/33650 (epoch 18.001), train_loss = 1.21528962, grad/param norm = 1.5601e-01, time/batch = 16.8918s	
12116/33650 (epoch 18.003), train_loss = 1.18790066, grad/param norm = 1.7054e-01, time/batch = 18.2229s	
12117/33650 (epoch 18.004), train_loss = 1.07215426, grad/param norm = 1.5619e-01, time/batch = 18.3191s	
12118/33650 (epoch 18.006), train_loss = 0.98733453, grad/param norm = 1.4312e-01, time/batch = 18.2388s	
12119/33650 (epoch 18.007), train_loss = 1.08560138, grad/param norm = 1.6042e-01, time/batch = 17.6186s	
12120/33650 (epoch 18.009), train_loss = 0.98290233, grad/param norm = 1.3863e-01, time/batch = 16.2210s	
12121/33650 (epoch 18.010), train_loss = 1.11346184, grad/param norm = 1.6206e-01, time/batch = 18.0730s	
12122/33650 (epoch 18.012), train_loss = 0.96832571, grad/param norm = 1.6247e-01, time/batch = 16.3107s	
12123/33650 (epoch 18.013), train_loss = 1.04473704, grad/param norm = 1.6510e-01, time/batch = 17.7241s	
12124/33650 (epoch 18.015), train_loss = 0.96324036, grad/param norm = 1.4205e-01, time/batch = 17.8918s	
12125/33650 (epoch 18.016), train_loss = 0.91024464, grad/param norm = 1.5309e-01, time/batch = 17.4715s	
12126/33650 (epoch 18.018), train_loss = 1.01712194, grad/param norm = 1.4852e-01, time/batch = 18.3039s	
12127/33650 (epoch 18.019), train_loss = 0.96057794, grad/param norm = 1.4509e-01, time/batch = 17.7253s	
12128/33650 (epoch 18.021), train_loss = 1.08952381, grad/param norm = 1.5429e-01, time/batch = 17.3901s	
12129/33650 (epoch 18.022), train_loss = 0.97237518, grad/param norm = 1.3607e-01, time/batch = 16.4708s	
12130/33650 (epoch 18.024), train_loss = 0.90743253, grad/param norm = 1.4813e-01, time/batch = 19.0612s	
12131/33650 (epoch 18.025), train_loss = 1.00292575, grad/param norm = 1.4706e-01, time/batch = 18.3122s	
12132/33650 (epoch 18.027), train_loss = 1.10774590, grad/param norm = 1.5674e-01, time/batch = 15.9694s	
12133/33650 (epoch 18.028), train_loss = 1.11108279, grad/param norm = 1.5886e-01, time/batch = 18.7223s	
12134/33650 (epoch 18.030), train_loss = 1.03235421, grad/param norm = 1.4457e-01, time/batch = 17.6440s	
12135/33650 (epoch 18.031), train_loss = 0.91536551, grad/param norm = 1.3173e-01, time/batch = 18.0518s	
12136/33650 (epoch 18.033), train_loss = 0.98621628, grad/param norm = 1.1703e-01, time/batch = 17.5390s	
12137/33650 (epoch 18.034), train_loss = 1.05051705, grad/param norm = 1.4121e-01, time/batch = 17.7217s	
12138/33650 (epoch 18.036), train_loss = 1.16487672, grad/param norm = 1.5557e-01, time/batch = 18.4589s	
12139/33650 (epoch 18.037), train_loss = 0.97596014, grad/param norm = 1.4439e-01, time/batch = 17.8763s	
12140/33650 (epoch 18.039), train_loss = 1.11902350, grad/param norm = 1.5123e-01, time/batch = 17.5690s	
12141/33650 (epoch 18.040), train_loss = 1.22115025, grad/param norm = 1.8420e-01, time/batch = 17.1490s	
12142/33650 (epoch 18.042), train_loss = 1.21316730, grad/param norm = 1.6221e-01, time/batch = 17.2298s	
12143/33650 (epoch 18.043), train_loss = 0.97583727, grad/param norm = 1.3595e-01, time/batch = 17.6478s	
12144/33650 (epoch 18.045), train_loss = 0.94382450, grad/param norm = 1.3748e-01, time/batch = 18.3017s	
12145/33650 (epoch 18.046), train_loss = 1.10817579, grad/param norm = 1.4760e-01, time/batch = 18.5601s	
12146/33650 (epoch 18.048), train_loss = 1.12442279, grad/param norm = 1.4693e-01, time/batch = 17.7964s	
12147/33650 (epoch 18.049), train_loss = 1.05454513, grad/param norm = 1.5806e-01, time/batch = 17.5807s	
12148/33650 (epoch 18.051), train_loss = 1.15026752, grad/param norm = 1.3987e-01, time/batch = 17.9652s	
12149/33650 (epoch 18.052), train_loss = 1.17971774, grad/param norm = 1.6427e-01, time/batch = 16.6483s	
12150/33650 (epoch 18.053), train_loss = 1.07757786, grad/param norm = 1.4879e-01, time/batch = 18.5722s	
12151/33650 (epoch 18.055), train_loss = 0.90132866, grad/param norm = 1.2913e-01, time/batch = 18.0687s	
12152/33650 (epoch 18.056), train_loss = 0.89239670, grad/param norm = 1.1941e-01, time/batch = 16.1316s	
12153/33650 (epoch 18.058), train_loss = 1.11924674, grad/param norm = 1.6442e-01, time/batch = 18.1454s	
12154/33650 (epoch 18.059), train_loss = 1.07731230, grad/param norm = 1.5767e-01, time/batch = 16.8803s	
12155/33650 (epoch 18.061), train_loss = 1.09752387, grad/param norm = 1.5440e-01, time/batch = 18.8252s	
12156/33650 (epoch 18.062), train_loss = 1.10499067, grad/param norm = 1.4810e-01, time/batch = 17.3759s	
12157/33650 (epoch 18.064), train_loss = 0.97754601, grad/param norm = 1.3567e-01, time/batch = 18.0615s	
12158/33650 (epoch 18.065), train_loss = 0.98420444, grad/param norm = 1.3522e-01, time/batch = 17.6541s	
12159/33650 (epoch 18.067), train_loss = 0.90972459, grad/param norm = 1.2390e-01, time/batch = 17.2315s	
12160/33650 (epoch 18.068), train_loss = 1.03791876, grad/param norm = 1.5402e-01, time/batch = 18.7195s	
12161/33650 (epoch 18.070), train_loss = 1.05417751, grad/param norm = 1.5457e-01, time/batch = 18.8959s	
12162/33650 (epoch 18.071), train_loss = 1.05164503, grad/param norm = 1.4377e-01, time/batch = 16.7919s	
12163/33650 (epoch 18.073), train_loss = 1.08974980, grad/param norm = 1.5434e-01, time/batch = 18.0572s	
12164/33650 (epoch 18.074), train_loss = 1.14241827, grad/param norm = 1.4230e-01, time/batch = 17.9818s	
12165/33650 (epoch 18.076), train_loss = 1.12164805, grad/param norm = 1.6669e-01, time/batch = 17.9005s	
12166/33650 (epoch 18.077), train_loss = 1.01530607, grad/param norm = 1.4184e-01, time/batch = 17.1348s	
12167/33650 (epoch 18.079), train_loss = 1.03115609, grad/param norm = 1.3469e-01, time/batch = 18.1572s	
12168/33650 (epoch 18.080), train_loss = 1.07726411, grad/param norm = 1.3489e-01, time/batch = 18.7204s	
12169/33650 (epoch 18.082), train_loss = 1.08951998, grad/param norm = 1.4772e-01, time/batch = 16.4123s	
12170/33650 (epoch 18.083), train_loss = 1.10546302, grad/param norm = 1.6161e-01, time/batch = 16.1332s	
12171/33650 (epoch 18.085), train_loss = 1.11743445, grad/param norm = 1.4260e-01, time/batch = 18.2236s	
12172/33650 (epoch 18.086), train_loss = 1.11955941, grad/param norm = 1.6571e-01, time/batch = 18.1224s	
12173/33650 (epoch 18.088), train_loss = 1.08859006, grad/param norm = 1.5752e-01, time/batch = 15.9627s	
12174/33650 (epoch 18.089), train_loss = 1.02072254, grad/param norm = 1.4138e-01, time/batch = 17.8130s	
12175/33650 (epoch 18.091), train_loss = 0.97833465, grad/param norm = 1.3019e-01, time/batch = 17.7248s	
12176/33650 (epoch 18.092), train_loss = 1.02037921, grad/param norm = 1.4652e-01, time/batch = 16.9092s	
12177/33650 (epoch 18.094), train_loss = 1.08850142, grad/param norm = 1.4024e-01, time/batch = 17.7277s	
12178/33650 (epoch 18.095), train_loss = 1.08672613, grad/param norm = 1.5698e-01, time/batch = 17.5655s	
12179/33650 (epoch 18.097), train_loss = 0.99800399, grad/param norm = 1.6668e-01, time/batch = 18.2337s	
12180/33650 (epoch 18.098), train_loss = 0.84576249, grad/param norm = 1.3631e-01, time/batch = 16.3842s	
12181/33650 (epoch 18.100), train_loss = 0.94410093, grad/param norm = 1.3095e-01, time/batch = 16.7925s	
12182/33650 (epoch 18.101), train_loss = 1.03374655, grad/param norm = 1.6824e-01, time/batch = 17.9861s	
12183/33650 (epoch 18.103), train_loss = 0.97018276, grad/param norm = 1.4159e-01, time/batch = 16.3649s	
12184/33650 (epoch 18.104), train_loss = 1.12801664, grad/param norm = 1.4829e-01, time/batch = 18.4782s	
12185/33650 (epoch 18.105), train_loss = 1.02505587, grad/param norm = 1.4109e-01, time/batch = 18.0688s	
12186/33650 (epoch 18.107), train_loss = 0.95720459, grad/param norm = 1.3688e-01, time/batch = 17.2235s	
12187/33650 (epoch 18.108), train_loss = 1.12251172, grad/param norm = 1.5032e-01, time/batch = 17.1302s	
12188/33650 (epoch 18.110), train_loss = 1.20444540, grad/param norm = 1.5377e-01, time/batch = 17.7288s	
12189/33650 (epoch 18.111), train_loss = 0.98304571, grad/param norm = 1.6014e-01, time/batch = 18.2320s	
12190/33650 (epoch 18.113), train_loss = 0.98824439, grad/param norm = 1.4395e-01, time/batch = 16.9698s	
12191/33650 (epoch 18.114), train_loss = 1.11729675, grad/param norm = 1.4636e-01, time/batch = 16.5592s	
12192/33650 (epoch 18.116), train_loss = 0.93987808, grad/param norm = 1.3133e-01, time/batch = 17.4768s	
12193/33650 (epoch 18.117), train_loss = 1.04573231, grad/param norm = 1.2866e-01, time/batch = 17.4795s	
12194/33650 (epoch 18.119), train_loss = 0.91714071, grad/param norm = 1.3517e-01, time/batch = 17.7980s	
12195/33650 (epoch 18.120), train_loss = 0.98676203, grad/param norm = 1.3831e-01, time/batch = 18.3998s	
12196/33650 (epoch 18.122), train_loss = 0.82462346, grad/param norm = 1.3756e-01, time/batch = 17.7328s	
12197/33650 (epoch 18.123), train_loss = 1.00197724, grad/param norm = 1.4283e-01, time/batch = 17.1409s	
12198/33650 (epoch 18.125), train_loss = 1.09932684, grad/param norm = 1.4644e-01, time/batch = 18.4727s	
12199/33650 (epoch 18.126), train_loss = 1.18376020, grad/param norm = 1.6991e-01, time/batch = 17.3989s	
12200/33650 (epoch 18.128), train_loss = 1.14939897, grad/param norm = 1.6310e-01, time/batch = 17.3088s	
12201/33650 (epoch 18.129), train_loss = 1.15439259, grad/param norm = 1.5140e-01, time/batch = 30.0829s	
12202/33650 (epoch 18.131), train_loss = 1.06778112, grad/param norm = 1.4667e-01, time/batch = 33.8761s	
12203/33650 (epoch 18.132), train_loss = 1.06511108, grad/param norm = 1.5197e-01, time/batch = 35.4666s	
12204/33650 (epoch 18.134), train_loss = 1.13263635, grad/param norm = 1.4439e-01, time/batch = 37.7404s	
12205/33650 (epoch 18.135), train_loss = 0.88883006, grad/param norm = 1.3423e-01, time/batch = 32.5651s	
12206/33650 (epoch 18.137), train_loss = 1.05701003, grad/param norm = 1.7748e-01, time/batch = 35.6911s	
12207/33650 (epoch 18.138), train_loss = 1.10626596, grad/param norm = 1.5191e-01, time/batch = 36.0255s	
12208/33650 (epoch 18.140), train_loss = 1.01466417, grad/param norm = 1.5906e-01, time/batch = 37.6763s	
12209/33650 (epoch 18.141), train_loss = 1.18361000, grad/param norm = 1.6149e-01, time/batch = 38.3324s	
12210/33650 (epoch 18.143), train_loss = 1.24156013, grad/param norm = 1.8471e-01, time/batch = 37.7443s	
12211/33650 (epoch 18.144), train_loss = 1.11808944, grad/param norm = 1.6463e-01, time/batch = 44.6169s	
12212/33650 (epoch 18.146), train_loss = 1.01902074, grad/param norm = 1.5343e-01, time/batch = 19.7828s	
12213/33650 (epoch 18.147), train_loss = 0.97902484, grad/param norm = 1.3924e-01, time/batch = 18.1227s	
12214/33650 (epoch 18.149), train_loss = 0.96459737, grad/param norm = 1.6882e-01, time/batch = 17.0577s	
12215/33650 (epoch 18.150), train_loss = 0.91427473, grad/param norm = 1.6326e-01, time/batch = 17.3870s	
12216/33650 (epoch 18.152), train_loss = 0.96616850, grad/param norm = 1.3321e-01, time/batch = 17.7244s	
12217/33650 (epoch 18.153), train_loss = 0.99444758, grad/param norm = 1.4324e-01, time/batch = 17.3821s	
12218/33650 (epoch 18.155), train_loss = 0.96449872, grad/param norm = 1.3732e-01, time/batch = 18.0556s	
12219/33650 (epoch 18.156), train_loss = 0.93851111, grad/param norm = 1.2683e-01, time/batch = 17.4039s	
12220/33650 (epoch 18.158), train_loss = 1.06236122, grad/param norm = 1.6296e-01, time/batch = 18.5646s	
12221/33650 (epoch 18.159), train_loss = 0.93714963, grad/param norm = 1.1940e-01, time/batch = 18.1382s	
12222/33650 (epoch 18.160), train_loss = 0.97049850, grad/param norm = 1.2528e-01, time/batch = 16.6305s	
12223/33650 (epoch 18.162), train_loss = 1.00984166, grad/param norm = 1.6666e-01, time/batch = 17.6556s	
12224/33650 (epoch 18.163), train_loss = 1.10190671, grad/param norm = 1.6241e-01, time/batch = 17.4108s	
12225/33650 (epoch 18.165), train_loss = 0.93040177, grad/param norm = 1.4308e-01, time/batch = 15.6434s	
12226/33650 (epoch 18.166), train_loss = 0.95770770, grad/param norm = 1.5023e-01, time/batch = 16.7306s	
12227/33650 (epoch 18.168), train_loss = 1.11934394, grad/param norm = 1.6787e-01, time/batch = 17.9019s	
12228/33650 (epoch 18.169), train_loss = 1.02813472, grad/param norm = 1.4184e-01, time/batch = 17.1536s	
12229/33650 (epoch 18.171), train_loss = 1.02220250, grad/param norm = 1.3662e-01, time/batch = 15.8311s	
12230/33650 (epoch 18.172), train_loss = 0.98347396, grad/param norm = 1.4077e-01, time/batch = 17.3187s	
12231/33650 (epoch 18.174), train_loss = 0.93468756, grad/param norm = 1.3428e-01, time/batch = 17.3998s	
12232/33650 (epoch 18.175), train_loss = 0.93066973, grad/param norm = 1.5702e-01, time/batch = 16.8233s	
12233/33650 (epoch 18.177), train_loss = 1.03212237, grad/param norm = 1.4181e-01, time/batch = 16.4072s	
12234/33650 (epoch 18.178), train_loss = 0.96123965, grad/param norm = 1.6202e-01, time/batch = 17.9786s	
12235/33650 (epoch 18.180), train_loss = 0.92204713, grad/param norm = 1.3503e-01, time/batch = 17.7386s	
12236/33650 (epoch 18.181), train_loss = 0.82369323, grad/param norm = 1.1754e-01, time/batch = 15.8958s	
12237/33650 (epoch 18.183), train_loss = 0.98453705, grad/param norm = 1.6764e-01, time/batch = 17.7365s	
12238/33650 (epoch 18.184), train_loss = 0.97093713, grad/param norm = 1.6349e-01, time/batch = 16.3853s	
12239/33650 (epoch 18.186), train_loss = 0.99618069, grad/param norm = 1.7637e-01, time/batch = 16.7335s	
12240/33650 (epoch 18.187), train_loss = 1.19749896, grad/param norm = 1.5406e-01, time/batch = 15.3278s	
12241/33650 (epoch 18.189), train_loss = 1.15975835, grad/param norm = 1.7706e-01, time/batch = 17.8237s	
12242/33650 (epoch 18.190), train_loss = 1.06321794, grad/param norm = 1.5408e-01, time/batch = 17.9955s	
12243/33650 (epoch 18.192), train_loss = 1.21479274, grad/param norm = 1.5203e-01, time/batch = 16.3054s	
12244/33650 (epoch 18.193), train_loss = 1.14364404, grad/param norm = 1.4607e-01, time/batch = 16.9160s	
12245/33650 (epoch 18.195), train_loss = 0.91815128, grad/param norm = 1.3602e-01, time/batch = 17.4063s	
12246/33650 (epoch 18.196), train_loss = 0.87827683, grad/param norm = 1.4750e-01, time/batch = 17.2279s	
12247/33650 (epoch 18.198), train_loss = 0.98207891, grad/param norm = 1.5103e-01, time/batch = 15.5607s	
12248/33650 (epoch 18.199), train_loss = 1.12364847, grad/param norm = 1.6749e-01, time/batch = 16.7363s	
12249/33650 (epoch 18.201), train_loss = 0.97688428, grad/param norm = 1.5454e-01, time/batch = 15.9740s	
12250/33650 (epoch 18.202), train_loss = 0.99167074, grad/param norm = 1.5427e-01, time/batch = 16.8142s	
12251/33650 (epoch 18.204), train_loss = 1.05025776, grad/param norm = 1.5097e-01, time/batch = 17.2433s	
12252/33650 (epoch 18.205), train_loss = 1.02626455, grad/param norm = 1.6024e-01, time/batch = 17.9105s	
12253/33650 (epoch 18.207), train_loss = 0.97279893, grad/param norm = 1.5833e-01, time/batch = 17.3175s	
12254/33650 (epoch 18.208), train_loss = 1.02430583, grad/param norm = 1.4313e-01, time/batch = 17.4816s	
12255/33650 (epoch 18.210), train_loss = 0.83743399, grad/param norm = 1.2662e-01, time/batch = 17.1568s	
12256/33650 (epoch 18.211), train_loss = 0.96581313, grad/param norm = 1.5715e-01, time/batch = 16.6545s	
12257/33650 (epoch 18.212), train_loss = 1.08130391, grad/param norm = 1.5903e-01, time/batch = 15.5722s	
12258/33650 (epoch 18.214), train_loss = 1.18942736, grad/param norm = 1.4575e-01, time/batch = 17.8112s	
12259/33650 (epoch 18.215), train_loss = 0.79766265, grad/param norm = 1.3886e-01, time/batch = 17.8231s	
12260/33650 (epoch 18.217), train_loss = 1.01323165, grad/param norm = 1.5667e-01, time/batch = 16.9863s	
12261/33650 (epoch 18.218), train_loss = 1.05369893, grad/param norm = 1.4569e-01, time/batch = 16.7295s	
12262/33650 (epoch 18.220), train_loss = 0.89218183, grad/param norm = 1.4112e-01, time/batch = 17.1452s	
12263/33650 (epoch 18.221), train_loss = 1.19632076, grad/param norm = 1.8035e-01, time/batch = 15.6432s	
12264/33650 (epoch 18.223), train_loss = 0.81135810, grad/param norm = 1.2639e-01, time/batch = 14.5992s	
12265/33650 (epoch 18.224), train_loss = 0.99105042, grad/param norm = 1.6669e-01, time/batch = 14.5302s	
12266/33650 (epoch 18.226), train_loss = 1.29533373, grad/param norm = 1.6227e-01, time/batch = 14.4560s	
12267/33650 (epoch 18.227), train_loss = 1.17358079, grad/param norm = 1.7906e-01, time/batch = 14.2374s	
12268/33650 (epoch 18.229), train_loss = 1.15658719, grad/param norm = 1.6144e-01, time/batch = 14.8955s	
12269/33650 (epoch 18.230), train_loss = 1.26222227, grad/param norm = 1.7231e-01, time/batch = 16.6361s	
12270/33650 (epoch 18.232), train_loss = 1.09295124, grad/param norm = 1.5756e-01, time/batch = 17.1555s	
12271/33650 (epoch 18.233), train_loss = 1.06849725, grad/param norm = 1.7228e-01, time/batch = 16.9133s	
12272/33650 (epoch 18.235), train_loss = 1.00716708, grad/param norm = 1.3751e-01, time/batch = 16.2189s	
12273/33650 (epoch 18.236), train_loss = 0.90220722, grad/param norm = 1.3951e-01, time/batch = 15.9750s	
12274/33650 (epoch 18.238), train_loss = 0.99815966, grad/param norm = 1.4117e-01, time/batch = 17.5720s	
12275/33650 (epoch 18.239), train_loss = 0.91997046, grad/param norm = 1.3172e-01, time/batch = 17.0514s	
12276/33650 (epoch 18.241), train_loss = 0.97082304, grad/param norm = 1.3339e-01, time/batch = 17.3120s	
12277/33650 (epoch 18.242), train_loss = 0.84446098, grad/param norm = 1.3707e-01, time/batch = 17.8260s	
12278/33650 (epoch 18.244), train_loss = 1.00289474, grad/param norm = 1.4179e-01, time/batch = 17.9815s	
12279/33650 (epoch 18.245), train_loss = 0.89507445, grad/param norm = 1.3640e-01, time/batch = 16.8080s	
12280/33650 (epoch 18.247), train_loss = 1.00302404, grad/param norm = 1.3371e-01, time/batch = 17.2249s	
12281/33650 (epoch 18.248), train_loss = 0.89144208, grad/param norm = 1.3640e-01, time/batch = 18.8992s	
12282/33650 (epoch 18.250), train_loss = 0.99396648, grad/param norm = 1.3756e-01, time/batch = 17.9706s	
12283/33650 (epoch 18.251), train_loss = 1.15851683, grad/param norm = 1.4753e-01, time/batch = 17.9004s	
12284/33650 (epoch 18.253), train_loss = 0.90876245, grad/param norm = 1.3837e-01, time/batch = 17.1348s	
12285/33650 (epoch 18.254), train_loss = 0.93593531, grad/param norm = 1.4853e-01, time/batch = 17.5636s	
12286/33650 (epoch 18.256), train_loss = 1.14519190, grad/param norm = 1.3708e-01, time/batch = 16.7898s	
12287/33650 (epoch 18.257), train_loss = 1.16756400, grad/param norm = 1.4938e-01, time/batch = 18.1274s	
12288/33650 (epoch 18.259), train_loss = 0.87873455, grad/param norm = 1.2548e-01, time/batch = 17.2421s	
12289/33650 (epoch 18.260), train_loss = 1.11942142, grad/param norm = 1.4531e-01, time/batch = 17.5577s	
12290/33650 (epoch 18.262), train_loss = 1.06088146, grad/param norm = 1.5497e-01, time/batch = 17.2962s	
12291/33650 (epoch 18.263), train_loss = 0.96313096, grad/param norm = 1.6004e-01, time/batch = 17.6534s	
12292/33650 (epoch 18.264), train_loss = 1.07984039, grad/param norm = 1.4968e-01, time/batch = 17.4787s	
12293/33650 (epoch 18.266), train_loss = 1.03936928, grad/param norm = 1.4075e-01, time/batch = 17.4782s	
12294/33650 (epoch 18.267), train_loss = 0.95392473, grad/param norm = 1.4680e-01, time/batch = 16.5481s	
12295/33650 (epoch 18.269), train_loss = 1.05810410, grad/param norm = 1.3787e-01, time/batch = 14.4133s	
12296/33650 (epoch 18.270), train_loss = 0.94459134, grad/param norm = 1.2909e-01, time/batch = 15.0222s	
12297/33650 (epoch 18.272), train_loss = 0.98999767, grad/param norm = 1.3601e-01, time/batch = 15.1858s	
12298/33650 (epoch 18.273), train_loss = 1.14692272, grad/param norm = 1.6453e-01, time/batch = 16.0686s	
12299/33650 (epoch 18.275), train_loss = 1.09211158, grad/param norm = 1.4792e-01, time/batch = 18.3968s	
12300/33650 (epoch 18.276), train_loss = 1.16999729, grad/param norm = 1.7195e-01, time/batch = 17.4738s	
12301/33650 (epoch 18.278), train_loss = 1.22402563, grad/param norm = 1.6873e-01, time/batch = 18.0703s	
12302/33650 (epoch 18.279), train_loss = 0.96962831, grad/param norm = 1.3001e-01, time/batch = 17.9827s	
12303/33650 (epoch 18.281), train_loss = 1.06646357, grad/param norm = 1.4854e-01, time/batch = 16.2066s	
12304/33650 (epoch 18.282), train_loss = 1.12150969, grad/param norm = 1.4009e-01, time/batch = 18.1350s	
12305/33650 (epoch 18.284), train_loss = 1.11741726, grad/param norm = 1.6928e-01, time/batch = 17.4790s	
12306/33650 (epoch 18.285), train_loss = 1.12392146, grad/param norm = 1.6255e-01, time/batch = 17.4784s	
12307/33650 (epoch 18.287), train_loss = 1.00632051, grad/param norm = 1.4782e-01, time/batch = 17.3852s	
12308/33650 (epoch 18.288), train_loss = 1.08362268, grad/param norm = 1.7694e-01, time/batch = 17.8998s	
12309/33650 (epoch 18.290), train_loss = 1.02873010, grad/param norm = 1.3112e-01, time/batch = 17.9755s	
12310/33650 (epoch 18.291), train_loss = 0.95523944, grad/param norm = 1.3226e-01, time/batch = 16.2344s	
12311/33650 (epoch 18.293), train_loss = 1.03119992, grad/param norm = 1.7814e-01, time/batch = 18.6465s	
12312/33650 (epoch 18.294), train_loss = 0.94173146, grad/param norm = 1.3374e-01, time/batch = 17.9844s	
12313/33650 (epoch 18.296), train_loss = 0.94084695, grad/param norm = 1.3521e-01, time/batch = 17.6368s	
12314/33650 (epoch 18.297), train_loss = 1.00509888, grad/param norm = 1.4711e-01, time/batch = 16.6307s	
12315/33650 (epoch 18.299), train_loss = 0.89902680, grad/param norm = 1.2814e-01, time/batch = 18.2201s	
12316/33650 (epoch 18.300), train_loss = 0.92344786, grad/param norm = 1.5096e-01, time/batch = 18.3169s	
12317/33650 (epoch 18.302), train_loss = 1.05832686, grad/param norm = 1.3945e-01, time/batch = 17.5439s	
12318/33650 (epoch 18.303), train_loss = 1.04086417, grad/param norm = 1.3122e-01, time/batch = 14.7517s	
12319/33650 (epoch 18.305), train_loss = 1.05113635, grad/param norm = 1.4523e-01, time/batch = 15.5290s	
12320/33650 (epoch 18.306), train_loss = 0.96003689, grad/param norm = 1.4153e-01, time/batch = 16.6457s	
12321/33650 (epoch 18.308), train_loss = 0.89291556, grad/param norm = 1.4992e-01, time/batch = 17.8070s	
12322/33650 (epoch 18.309), train_loss = 1.20037581, grad/param norm = 1.5358e-01, time/batch = 17.0637s	
12323/33650 (epoch 18.311), train_loss = 1.07606736, grad/param norm = 1.6065e-01, time/batch = 19.1374s	
12324/33650 (epoch 18.312), train_loss = 1.03491704, grad/param norm = 1.5524e-01, time/batch = 17.0572s	
12325/33650 (epoch 18.314), train_loss = 0.89852919, grad/param norm = 1.2214e-01, time/batch = 18.4563s	
12326/33650 (epoch 18.315), train_loss = 0.99794599, grad/param norm = 1.5089e-01, time/batch = 16.8866s	
12327/33650 (epoch 18.316), train_loss = 0.96859775, grad/param norm = 1.4855e-01, time/batch = 17.4556s	
12328/33650 (epoch 18.318), train_loss = 0.90661771, grad/param norm = 1.2756e-01, time/batch = 19.0518s	
12329/33650 (epoch 18.319), train_loss = 0.93442878, grad/param norm = 1.2675e-01, time/batch = 15.9636s	
12330/33650 (epoch 18.321), train_loss = 0.94822676, grad/param norm = 1.3373e-01, time/batch = 18.3969s	
12331/33650 (epoch 18.322), train_loss = 1.04556406, grad/param norm = 1.5684e-01, time/batch = 3.4109s	
12332/33650 (epoch 18.324), train_loss = 1.10689598, grad/param norm = 1.6737e-01, time/batch = 0.6417s	
12333/33650 (epoch 18.325), train_loss = 1.10151028, grad/param norm = 1.4945e-01, time/batch = 0.6484s	
12334/33650 (epoch 18.327), train_loss = 0.92571735, grad/param norm = 1.2648e-01, time/batch = 0.6380s	
12335/33650 (epoch 18.328), train_loss = 1.08658767, grad/param norm = 1.4879e-01, time/batch = 0.6452s	
12336/33650 (epoch 18.330), train_loss = 0.94411388, grad/param norm = 1.2533e-01, time/batch = 0.6382s	
12337/33650 (epoch 18.331), train_loss = 0.84886458, grad/param norm = 1.2169e-01, time/batch = 0.6382s	
12338/33650 (epoch 18.333), train_loss = 1.00483953, grad/param norm = 1.4761e-01, time/batch = 0.6500s	
12339/33650 (epoch 18.334), train_loss = 0.99747903, grad/param norm = 1.3830e-01, time/batch = 0.9393s	
12340/33650 (epoch 18.336), train_loss = 1.13710307, grad/param norm = 1.4084e-01, time/batch = 0.9404s	
12341/33650 (epoch 18.337), train_loss = 0.84699828, grad/param norm = 1.3599e-01, time/batch = 0.9429s	
12342/33650 (epoch 18.339), train_loss = 0.99074193, grad/param norm = 1.2954e-01, time/batch = 0.9308s	
12343/33650 (epoch 18.340), train_loss = 1.16667992, grad/param norm = 1.7118e-01, time/batch = 0.9424s	
12344/33650 (epoch 18.342), train_loss = 0.85921692, grad/param norm = 1.2806e-01, time/batch = 1.6124s	
12345/33650 (epoch 18.343), train_loss = 1.07221287, grad/param norm = 1.5016e-01, time/batch = 1.8677s	
12346/33650 (epoch 18.345), train_loss = 0.99954971, grad/param norm = 1.5366e-01, time/batch = 1.8848s	
12347/33650 (epoch 18.346), train_loss = 0.70231780, grad/param norm = 1.1604e-01, time/batch = 17.9612s	
12348/33650 (epoch 18.348), train_loss = 0.89306148, grad/param norm = 1.2672e-01, time/batch = 17.6601s	
12349/33650 (epoch 18.349), train_loss = 0.86151192, grad/param norm = 1.3127e-01, time/batch = 16.8918s	
12350/33650 (epoch 18.351), train_loss = 1.10956241, grad/param norm = 1.5146e-01, time/batch = 18.4632s	
12351/33650 (epoch 18.352), train_loss = 1.01041912, grad/param norm = 1.3886e-01, time/batch = 17.8995s	
12352/33650 (epoch 18.354), train_loss = 1.20291865, grad/param norm = 1.8549e-01, time/batch = 18.0527s	
12353/33650 (epoch 18.355), train_loss = 1.13337566, grad/param norm = 1.4106e-01, time/batch = 18.5493s	
12354/33650 (epoch 18.357), train_loss = 0.80811822, grad/param norm = 1.3835e-01, time/batch = 16.2123s	
12355/33650 (epoch 18.358), train_loss = 1.07920515, grad/param norm = 1.4058e-01, time/batch = 18.0653s	
12356/33650 (epoch 18.360), train_loss = 1.11097101, grad/param norm = 1.5527e-01, time/batch = 16.0371s	
12357/33650 (epoch 18.361), train_loss = 1.05527834, grad/param norm = 1.3674e-01, time/batch = 18.3878s	
12358/33650 (epoch 18.363), train_loss = 0.96732122, grad/param norm = 1.4266e-01, time/batch = 18.1460s	
12359/33650 (epoch 18.364), train_loss = 0.97088351, grad/param norm = 1.3512e-01, time/batch = 17.0526s	
12360/33650 (epoch 18.366), train_loss = 1.06379222, grad/param norm = 1.5517e-01, time/batch = 19.2951s	
12361/33650 (epoch 18.367), train_loss = 1.07701870, grad/param norm = 1.4234e-01, time/batch = 17.9792s	
12362/33650 (epoch 18.368), train_loss = 0.95111613, grad/param norm = 1.4641e-01, time/batch = 16.8894s	
12363/33650 (epoch 18.370), train_loss = 1.02447759, grad/param norm = 1.5044e-01, time/batch = 16.5698s	
12364/33650 (epoch 18.371), train_loss = 0.82217976, grad/param norm = 1.3460e-01, time/batch = 16.2920s	
12365/33650 (epoch 18.373), train_loss = 0.91500197, grad/param norm = 1.2669e-01, time/batch = 18.5714s	
12366/33650 (epoch 18.374), train_loss = 0.88989156, grad/param norm = 1.2695e-01, time/batch = 16.3933s	
12367/33650 (epoch 18.376), train_loss = 1.00357241, grad/param norm = 1.5293e-01, time/batch = 18.5559s	
12368/33650 (epoch 18.377), train_loss = 1.04848278, grad/param norm = 1.5432e-01, time/batch = 16.7238s	
12369/33650 (epoch 18.379), train_loss = 1.08077176, grad/param norm = 1.4001e-01, time/batch = 16.4057s	
12370/33650 (epoch 18.380), train_loss = 0.79957096, grad/param norm = 1.4048e-01, time/batch = 17.8997s	
12371/33650 (epoch 18.382), train_loss = 0.93095987, grad/param norm = 1.2226e-01, time/batch = 16.5607s	
12372/33650 (epoch 18.383), train_loss = 0.98268996, grad/param norm = 1.3039e-01, time/batch = 18.6417s	
12373/33650 (epoch 18.385), train_loss = 1.15071740, grad/param norm = 1.4745e-01, time/batch = 15.4607s	
12374/33650 (epoch 18.386), train_loss = 0.93793540, grad/param norm = 1.3455e-01, time/batch = 17.5498s	
12375/33650 (epoch 18.388), train_loss = 1.04835531, grad/param norm = 1.3852e-01, time/batch = 17.5481s	
12376/33650 (epoch 18.389), train_loss = 0.99898786, grad/param norm = 1.5789e-01, time/batch = 16.7240s	
12377/33650 (epoch 18.391), train_loss = 0.81321240, grad/param norm = 1.2714e-01, time/batch = 18.3087s	
12378/33650 (epoch 18.392), train_loss = 1.08043518, grad/param norm = 1.5703e-01, time/batch = 18.0687s	
12379/33650 (epoch 18.394), train_loss = 1.05878231, grad/param norm = 1.6449e-01, time/batch = 18.3859s	
12380/33650 (epoch 18.395), train_loss = 1.04811851, grad/param norm = 1.4549e-01, time/batch = 18.1375s	
12381/33650 (epoch 18.397), train_loss = 1.16891078, grad/param norm = 1.5437e-01, time/batch = 17.7322s	
12382/33650 (epoch 18.398), train_loss = 1.06480283, grad/param norm = 1.4552e-01, time/batch = 18.3161s	
12383/33650 (epoch 18.400), train_loss = 1.01996881, grad/param norm = 1.5818e-01, time/batch = 16.6411s	
12384/33650 (epoch 18.401), train_loss = 0.98841265, grad/param norm = 1.5655e-01, time/batch = 18.2295s	
12385/33650 (epoch 18.403), train_loss = 1.05357803, grad/param norm = 1.4903e-01, time/batch = 15.7321s	
12386/33650 (epoch 18.404), train_loss = 1.01557166, grad/param norm = 1.4851e-01, time/batch = 16.9736s	
12387/33650 (epoch 18.406), train_loss = 1.03644334, grad/param norm = 1.5720e-01, time/batch = 16.2364s	
12388/33650 (epoch 18.407), train_loss = 1.01509436, grad/param norm = 1.4322e-01, time/batch = 15.5617s	
12389/33650 (epoch 18.409), train_loss = 1.05263665, grad/param norm = 1.4609e-01, time/batch = 17.4054s	
12390/33650 (epoch 18.410), train_loss = 1.00886904, grad/param norm = 1.4817e-01, time/batch = 15.6188s	
12391/33650 (epoch 18.412), train_loss = 1.02904025, grad/param norm = 1.3131e-01, time/batch = 17.6490s	
12392/33650 (epoch 18.413), train_loss = 0.95605437, grad/param norm = 1.4634e-01, time/batch = 17.5779s	
12393/33650 (epoch 18.415), train_loss = 1.10841649, grad/param norm = 1.5255e-01, time/batch = 16.8036s	
12394/33650 (epoch 18.416), train_loss = 1.16841810, grad/param norm = 1.5283e-01, time/batch = 16.6465s	
12395/33650 (epoch 18.418), train_loss = 0.99391351, grad/param norm = 1.4531e-01, time/batch = 17.4058s	
12396/33650 (epoch 18.419), train_loss = 0.97609471, grad/param norm = 1.4144e-01, time/batch = 17.9941s	
12397/33650 (epoch 18.421), train_loss = 1.00425183, grad/param norm = 1.2808e-01, time/batch = 16.8991s	
12398/33650 (epoch 18.422), train_loss = 1.11176708, grad/param norm = 1.4100e-01, time/batch = 16.9830s	
12399/33650 (epoch 18.423), train_loss = 0.92324618, grad/param norm = 1.2061e-01, time/batch = 14.0892s	
12400/33650 (epoch 18.425), train_loss = 1.04391580, grad/param norm = 1.4740e-01, time/batch = 17.4846s	
12401/33650 (epoch 18.426), train_loss = 1.17487560, grad/param norm = 1.6437e-01, time/batch = 16.2385s	
12402/33650 (epoch 18.428), train_loss = 0.94845424, grad/param norm = 1.3365e-01, time/batch = 17.9968s	
12403/33650 (epoch 18.429), train_loss = 1.10172651, grad/param norm = 1.5640e-01, time/batch = 16.7419s	
12404/33650 (epoch 18.431), train_loss = 1.19298330, grad/param norm = 1.5990e-01, time/batch = 15.9671s	
12405/33650 (epoch 18.432), train_loss = 1.22846370, grad/param norm = 1.5461e-01, time/batch = 17.2264s	
12406/33650 (epoch 18.434), train_loss = 1.04628794, grad/param norm = 1.4660e-01, time/batch = 17.1438s	
12407/33650 (epoch 18.435), train_loss = 1.02516400, grad/param norm = 1.6576e-01, time/batch = 17.8872s	
12408/33650 (epoch 18.437), train_loss = 1.03290593, grad/param norm = 1.5716e-01, time/batch = 16.8082s	
12409/33650 (epoch 18.438), train_loss = 0.97074615, grad/param norm = 1.4918e-01, time/batch = 17.7370s	
12410/33650 (epoch 18.440), train_loss = 1.05017173, grad/param norm = 1.5364e-01, time/batch = 15.9804s	
12411/33650 (epoch 18.441), train_loss = 1.05106200, grad/param norm = 1.5889e-01, time/batch = 16.7125s	
12412/33650 (epoch 18.443), train_loss = 1.07886830, grad/param norm = 1.3562e-01, time/batch = 17.1541s	
12413/33650 (epoch 18.444), train_loss = 0.99077709, grad/param norm = 1.4678e-01, time/batch = 17.6538s	
12414/33650 (epoch 18.446), train_loss = 1.07933996, grad/param norm = 1.6439e-01, time/batch = 17.2379s	
12415/33650 (epoch 18.447), train_loss = 1.13208243, grad/param norm = 1.5789e-01, time/batch = 16.6354s	
12416/33650 (epoch 18.449), train_loss = 1.19555403, grad/param norm = 2.0020e-01, time/batch = 16.7315s	
12417/33650 (epoch 18.450), train_loss = 1.22606738, grad/param norm = 1.5736e-01, time/batch = 17.0702s	
12418/33650 (epoch 18.452), train_loss = 1.22705505, grad/param norm = 1.7264e-01, time/batch = 16.9042s	
12419/33650 (epoch 18.453), train_loss = 1.20769253, grad/param norm = 1.8529e-01, time/batch = 17.1557s	
12420/33650 (epoch 18.455), train_loss = 0.99934154, grad/param norm = 1.4718e-01, time/batch = 16.0471s	
12421/33650 (epoch 18.456), train_loss = 1.03128105, grad/param norm = 1.3687e-01, time/batch = 17.8828s	
12422/33650 (epoch 18.458), train_loss = 1.01934945, grad/param norm = 1.6828e-01, time/batch = 17.2256s	
12423/33650 (epoch 18.459), train_loss = 1.05596254, grad/param norm = 1.7189e-01, time/batch = 17.7261s	
12424/33650 (epoch 18.461), train_loss = 1.20218184, grad/param norm = 1.6704e-01, time/batch = 16.9062s	
12425/33650 (epoch 18.462), train_loss = 1.16643105, grad/param norm = 1.6680e-01, time/batch = 16.3172s	
12426/33650 (epoch 18.464), train_loss = 0.99362631, grad/param norm = 1.5218e-01, time/batch = 17.4842s	
12427/33650 (epoch 18.465), train_loss = 1.06461378, grad/param norm = 1.6210e-01, time/batch = 17.8192s	
12428/33650 (epoch 18.467), train_loss = 1.08817127, grad/param norm = 1.5546e-01, time/batch = 16.5472s	
12429/33650 (epoch 18.468), train_loss = 1.15484269, grad/param norm = 1.5771e-01, time/batch = 16.3033s	
12430/33650 (epoch 18.470), train_loss = 1.27154208, grad/param norm = 1.8608e-01, time/batch = 17.3258s	
12431/33650 (epoch 18.471), train_loss = 1.02557025, grad/param norm = 1.5383e-01, time/batch = 16.6581s	
12432/33650 (epoch 18.473), train_loss = 1.00407901, grad/param norm = 1.6429e-01, time/batch = 23.6475s	
12433/33650 (epoch 18.474), train_loss = 1.13314208, grad/param norm = 1.4515e-01, time/batch = 24.6555s	
12434/33650 (epoch 18.475), train_loss = 1.10363969, grad/param norm = 1.5530e-01, time/batch = 17.3248s	
12435/33650 (epoch 18.477), train_loss = 1.15293095, grad/param norm = 1.4482e-01, time/batch = 15.4689s	
12436/33650 (epoch 18.478), train_loss = 1.16582653, grad/param norm = 1.6417e-01, time/batch = 17.9801s	
12437/33650 (epoch 18.480), train_loss = 1.15685223, grad/param norm = 1.8444e-01, time/batch = 16.8142s	
12438/33650 (epoch 18.481), train_loss = 1.21857524, grad/param norm = 1.6033e-01, time/batch = 14.8957s	
12439/33650 (epoch 18.483), train_loss = 0.84677202, grad/param norm = 1.2792e-01, time/batch = 16.8031s	
12440/33650 (epoch 18.484), train_loss = 1.02909827, grad/param norm = 1.4396e-01, time/batch = 17.3245s	
12441/33650 (epoch 18.486), train_loss = 1.18213360, grad/param norm = 1.6784e-01, time/batch = 17.6509s	
12442/33650 (epoch 18.487), train_loss = 1.19661115, grad/param norm = 1.6350e-01, time/batch = 16.1517s	
12443/33650 (epoch 18.489), train_loss = 1.20795179, grad/param norm = 1.5377e-01, time/batch = 16.3125s	
12444/33650 (epoch 18.490), train_loss = 0.93719041, grad/param norm = 1.4123e-01, time/batch = 17.5727s	
12445/33650 (epoch 18.492), train_loss = 1.07995232, grad/param norm = 1.6126e-01, time/batch = 16.6507s	
12446/33650 (epoch 18.493), train_loss = 0.88471427, grad/param norm = 1.3670e-01, time/batch = 16.4751s	
12447/33650 (epoch 18.495), train_loss = 1.05952794, grad/param norm = 1.5078e-01, time/batch = 17.6526s	
12448/33650 (epoch 18.496), train_loss = 1.10135709, grad/param norm = 1.4976e-01, time/batch = 17.4037s	
12449/33650 (epoch 18.498), train_loss = 0.93690722, grad/param norm = 1.3789e-01, time/batch = 16.8934s	
12450/33650 (epoch 18.499), train_loss = 1.02528459, grad/param norm = 1.2907e-01, time/batch = 16.3208s	
12451/33650 (epoch 18.501), train_loss = 1.02427315, grad/param norm = 1.3527e-01, time/batch = 18.1581s	
12452/33650 (epoch 18.502), train_loss = 1.04762301, grad/param norm = 1.5632e-01, time/batch = 17.0801s	
12453/33650 (epoch 18.504), train_loss = 1.14510704, grad/param norm = 1.6645e-01, time/batch = 15.2079s	
12454/33650 (epoch 18.505), train_loss = 0.98971053, grad/param norm = 1.5758e-01, time/batch = 17.4863s	
12455/33650 (epoch 18.507), train_loss = 1.16713570, grad/param norm = 1.5292e-01, time/batch = 16.3230s	
12456/33650 (epoch 18.508), train_loss = 1.01379182, grad/param norm = 1.4385e-01, time/batch = 16.0568s	
12457/33650 (epoch 18.510), train_loss = 1.02606512, grad/param norm = 1.5044e-01, time/batch = 17.0667s	
12458/33650 (epoch 18.511), train_loss = 1.27293204, grad/param norm = 1.7105e-01, time/batch = 17.0770s	
12459/33650 (epoch 18.513), train_loss = 1.10547807, grad/param norm = 1.4358e-01, time/batch = 17.8288s	
12460/33650 (epoch 18.514), train_loss = 1.12851368, grad/param norm = 1.5412e-01, time/batch = 16.4727s	
12461/33650 (epoch 18.516), train_loss = 1.05913710, grad/param norm = 1.5962e-01, time/batch = 17.5705s	
12462/33650 (epoch 18.517), train_loss = 1.03835086, grad/param norm = 1.5390e-01, time/batch = 17.0711s	
12463/33650 (epoch 18.519), train_loss = 1.11872909, grad/param norm = 1.6772e-01, time/batch = 16.8248s	
12464/33650 (epoch 18.520), train_loss = 0.89361877, grad/param norm = 1.2747e-01, time/batch = 17.2424s	
12465/33650 (epoch 18.522), train_loss = 1.02586206, grad/param norm = 1.5310e-01, time/batch = 15.5493s	
12466/33650 (epoch 18.523), train_loss = 0.98419561, grad/param norm = 1.3284e-01, time/batch = 17.4158s	
12467/33650 (epoch 18.525), train_loss = 0.83507726, grad/param norm = 1.3284e-01, time/batch = 16.3892s	
12468/33650 (epoch 18.526), train_loss = 1.12793063, grad/param norm = 1.4439e-01, time/batch = 17.4083s	
12469/33650 (epoch 18.527), train_loss = 0.97180714, grad/param norm = 1.4247e-01, time/batch = 17.2436s	
12470/33650 (epoch 18.529), train_loss = 1.04295595, grad/param norm = 1.4241e-01, time/batch = 16.8210s	
12471/33650 (epoch 18.530), train_loss = 0.99677966, grad/param norm = 1.5176e-01, time/batch = 16.5723s	
12472/33650 (epoch 18.532), train_loss = 1.16648731, grad/param norm = 1.7996e-01, time/batch = 18.0761s	
12473/33650 (epoch 18.533), train_loss = 1.02778701, grad/param norm = 1.5027e-01, time/batch = 16.6475s	
12474/33650 (epoch 18.535), train_loss = 1.11806115, grad/param norm = 1.4433e-01, time/batch = 15.9850s	
12475/33650 (epoch 18.536), train_loss = 1.07076796, grad/param norm = 1.5958e-01, time/batch = 17.8079s	
12476/33650 (epoch 18.538), train_loss = 1.11903185, grad/param norm = 1.7631e-01, time/batch = 17.5822s	
12477/33650 (epoch 18.539), train_loss = 0.85823516, grad/param norm = 1.4242e-01, time/batch = 16.2434s	
12478/33650 (epoch 18.541), train_loss = 1.17166762, grad/param norm = 1.6337e-01, time/batch = 17.5753s	
12479/33650 (epoch 18.542), train_loss = 1.08540899, grad/param norm = 1.7863e-01, time/batch = 17.6574s	
12480/33650 (epoch 18.544), train_loss = 1.22637679, grad/param norm = 1.8530e-01, time/batch = 16.2993s	
12481/33650 (epoch 18.545), train_loss = 0.91493194, grad/param norm = 1.3446e-01, time/batch = 16.4792s	
12482/33650 (epoch 18.547), train_loss = 1.05907900, grad/param norm = 1.5190e-01, time/batch = 17.8253s	
12483/33650 (epoch 18.548), train_loss = 1.21859943, grad/param norm = 1.5731e-01, time/batch = 17.1601s	
12484/33650 (epoch 18.550), train_loss = 1.04947423, grad/param norm = 1.5338e-01, time/batch = 15.3898s	
12485/33650 (epoch 18.551), train_loss = 1.07571050, grad/param norm = 1.5295e-01, time/batch = 16.9911s	
12486/33650 (epoch 18.553), train_loss = 0.94573785, grad/param norm = 1.6943e-01, time/batch = 16.4067s	
12487/33650 (epoch 18.554), train_loss = 1.20322603, grad/param norm = 1.6275e-01, time/batch = 17.4923s	
12488/33650 (epoch 18.556), train_loss = 1.13094543, grad/param norm = 1.8526e-01, time/batch = 16.0680s	
12489/33650 (epoch 18.557), train_loss = 1.13893684, grad/param norm = 1.5845e-01, time/batch = 17.3121s	
12490/33650 (epoch 18.559), train_loss = 1.32760708, grad/param norm = 1.9516e-01, time/batch = 16.9039s	
12491/33650 (epoch 18.560), train_loss = 1.25727862, grad/param norm = 1.5516e-01, time/batch = 16.9821s	
12492/33650 (epoch 18.562), train_loss = 1.14443505, grad/param norm = 1.3992e-01, time/batch = 16.7383s	
12493/33650 (epoch 18.563), train_loss = 1.07814857, grad/param norm = 1.5254e-01, time/batch = 16.5663s	
12494/33650 (epoch 18.565), train_loss = 1.05947757, grad/param norm = 1.5491e-01, time/batch = 17.8205s	
12495/33650 (epoch 18.566), train_loss = 1.03800603, grad/param norm = 1.6317e-01, time/batch = 15.4761s	
12496/33650 (epoch 18.568), train_loss = 1.08884851, grad/param norm = 1.7530e-01, time/batch = 17.1438s	
12497/33650 (epoch 18.569), train_loss = 0.98551114, grad/param norm = 1.3784e-01, time/batch = 17.1585s	
12498/33650 (epoch 18.571), train_loss = 1.18741876, grad/param norm = 1.7342e-01, time/batch = 16.9896s	
12499/33650 (epoch 18.572), train_loss = 1.11057357, grad/param norm = 1.3657e-01, time/batch = 16.8849s	
12500/33650 (epoch 18.574), train_loss = 1.04008806, grad/param norm = 1.7052e-01, time/batch = 17.5715s	
12501/33650 (epoch 18.575), train_loss = 1.02755897, grad/param norm = 1.4422e-01, time/batch = 17.6517s	
12502/33650 (epoch 18.577), train_loss = 1.04514980, grad/param norm = 1.6310e-01, time/batch = 15.9763s	
12503/33650 (epoch 18.578), train_loss = 1.12109500, grad/param norm = 1.4782e-01, time/batch = 17.8199s	
12504/33650 (epoch 18.579), train_loss = 1.11044106, grad/param norm = 1.4960e-01, time/batch = 17.2416s	
12505/33650 (epoch 18.581), train_loss = 1.17108385, grad/param norm = 1.5148e-01, time/batch = 16.3733s	
12506/33650 (epoch 18.582), train_loss = 1.11641912, grad/param norm = 1.3237e-01, time/batch = 17.3125s	
12507/33650 (epoch 18.584), train_loss = 1.12291121, grad/param norm = 1.5836e-01, time/batch = 16.3123s	
12508/33650 (epoch 18.585), train_loss = 1.11891446, grad/param norm = 1.6374e-01, time/batch = 16.9958s	
12509/33650 (epoch 18.587), train_loss = 0.96083116, grad/param norm = 1.3227e-01, time/batch = 16.6544s	
12510/33650 (epoch 18.588), train_loss = 0.99224363, grad/param norm = 1.6764e-01, time/batch = 17.3197s	
12511/33650 (epoch 18.590), train_loss = 1.00321556, grad/param norm = 1.3541e-01, time/batch = 16.8870s	
12512/33650 (epoch 18.591), train_loss = 0.98448896, grad/param norm = 1.7741e-01, time/batch = 16.7265s	
12513/33650 (epoch 18.593), train_loss = 0.96374002, grad/param norm = 1.3126e-01, time/batch = 16.8162s	
12514/33650 (epoch 18.594), train_loss = 0.93362897, grad/param norm = 1.4762e-01, time/batch = 17.4888s	
12515/33650 (epoch 18.596), train_loss = 1.04919976, grad/param norm = 1.4092e-01, time/batch = 17.2352s	
12516/33650 (epoch 18.597), train_loss = 0.87296822, grad/param norm = 1.2183e-01, time/batch = 16.4881s	
12517/33650 (epoch 18.599), train_loss = 1.02676938, grad/param norm = 1.5166e-01, time/batch = 17.6627s	
12518/33650 (epoch 18.600), train_loss = 0.94837381, grad/param norm = 1.3352e-01, time/batch = 17.1596s	
12519/33650 (epoch 18.602), train_loss = 1.09728845, grad/param norm = 1.5187e-01, time/batch = 17.4827s	
12520/33650 (epoch 18.603), train_loss = 0.99418000, grad/param norm = 1.4474e-01, time/batch = 15.9849s	
12521/33650 (epoch 18.605), train_loss = 1.10908636, grad/param norm = 1.5404e-01, time/batch = 17.8133s	
12522/33650 (epoch 18.606), train_loss = 1.12018669, grad/param norm = 1.7588e-01, time/batch = 17.9046s	
12523/33650 (epoch 18.608), train_loss = 0.98310702, grad/param norm = 1.5591e-01, time/batch = 16.9035s	
12524/33650 (epoch 18.609), train_loss = 1.04681013, grad/param norm = 1.6545e-01, time/batch = 16.4908s	
12525/33650 (epoch 18.611), train_loss = 0.92453657, grad/param norm = 1.3806e-01, time/batch = 16.3974s	
12526/33650 (epoch 18.612), train_loss = 1.03945940, grad/param norm = 1.5497e-01, time/batch = 17.5529s	
12527/33650 (epoch 18.614), train_loss = 1.13172218, grad/param norm = 1.6523e-01, time/batch = 15.8796s	
12528/33650 (epoch 18.615), train_loss = 1.00960386, grad/param norm = 1.2956e-01, time/batch = 16.9755s	
12529/33650 (epoch 18.617), train_loss = 0.94776744, grad/param norm = 1.3118e-01, time/batch = 17.7383s	
12530/33650 (epoch 18.618), train_loss = 1.01123981, grad/param norm = 1.3594e-01, time/batch = 16.4921s	
12531/33650 (epoch 18.620), train_loss = 1.07293423, grad/param norm = 1.6217e-01, time/batch = 17.7180s	
12532/33650 (epoch 18.621), train_loss = 0.93364740, grad/param norm = 1.3762e-01, time/batch = 16.9724s	
12533/33650 (epoch 18.623), train_loss = 1.02098626, grad/param norm = 1.4451e-01, time/batch = 17.2425s	
12534/33650 (epoch 18.624), train_loss = 0.82239693, grad/param norm = 1.3371e-01, time/batch = 16.8918s	
12535/33650 (epoch 18.626), train_loss = 0.81322598, grad/param norm = 1.2280e-01, time/batch = 16.8213s	
12536/33650 (epoch 18.627), train_loss = 0.95127361, grad/param norm = 1.4803e-01, time/batch = 17.5664s	
12537/33650 (epoch 18.629), train_loss = 0.99823214, grad/param norm = 1.4527e-01, time/batch = 16.5628s	
12538/33650 (epoch 18.630), train_loss = 1.12027862, grad/param norm = 1.6671e-01, time/batch = 17.2282s	
12539/33650 (epoch 18.632), train_loss = 1.15855776, grad/param norm = 1.4922e-01, time/batch = 17.1628s	
12540/33650 (epoch 18.633), train_loss = 1.13338831, grad/param norm = 1.4546e-01, time/batch = 17.3217s	
12541/33650 (epoch 18.634), train_loss = 0.90319162, grad/param norm = 1.3583e-01, time/batch = 16.7267s	
12542/33650 (epoch 18.636), train_loss = 0.79160089, grad/param norm = 1.1634e-01, time/batch = 17.6550s	
12543/33650 (epoch 18.637), train_loss = 0.96024680, grad/param norm = 1.3988e-01, time/batch = 15.3824s	
12544/33650 (epoch 18.639), train_loss = 0.97045953, grad/param norm = 1.4277e-01, time/batch = 16.7142s	
12545/33650 (epoch 18.640), train_loss = 1.03317829, grad/param norm = 1.4448e-01, time/batch = 16.8247s	
12546/33650 (epoch 18.642), train_loss = 1.10662301, grad/param norm = 1.5165e-01, time/batch = 17.9853s	
12547/33650 (epoch 18.643), train_loss = 1.03795019, grad/param norm = 1.5183e-01, time/batch = 17.3233s	
12548/33650 (epoch 18.645), train_loss = 1.03765957, grad/param norm = 1.3874e-01, time/batch = 16.8922s	
12549/33650 (epoch 18.646), train_loss = 0.87609280, grad/param norm = 1.2340e-01, time/batch = 17.5023s	
12550/33650 (epoch 18.648), train_loss = 1.04177486, grad/param norm = 1.3693e-01, time/batch = 14.0975s	
12551/33650 (epoch 18.649), train_loss = 1.00068278, grad/param norm = 1.7065e-01, time/batch = 13.5829s	
12552/33650 (epoch 18.651), train_loss = 1.15574003, grad/param norm = 1.6379e-01, time/batch = 16.7192s	
12553/33650 (epoch 18.652), train_loss = 0.73957028, grad/param norm = 1.1618e-01, time/batch = 16.9851s	
12554/33650 (epoch 18.654), train_loss = 0.93568416, grad/param norm = 1.2807e-01, time/batch = 16.9066s	
12555/33650 (epoch 18.655), train_loss = 0.89721488, grad/param norm = 1.2514e-01, time/batch = 15.3650s	
12556/33650 (epoch 18.657), train_loss = 0.97870687, grad/param norm = 1.4704e-01, time/batch = 14.2943s	
12557/33650 (epoch 18.658), train_loss = 0.87385240, grad/param norm = 1.3513e-01, time/batch = 17.8040s	
12558/33650 (epoch 18.660), train_loss = 0.83062183, grad/param norm = 1.3744e-01, time/batch = 17.5641s	
12559/33650 (epoch 18.661), train_loss = 0.94941264, grad/param norm = 1.3540e-01, time/batch = 16.9709s	
12560/33650 (epoch 18.663), train_loss = 0.89857370, grad/param norm = 1.5124e-01, time/batch = 16.4820s	
12561/33650 (epoch 18.664), train_loss = 0.92823416, grad/param norm = 1.2407e-01, time/batch = 16.3163s	
12562/33650 (epoch 18.666), train_loss = 0.94888512, grad/param norm = 1.2782e-01, time/batch = 17.3171s	
12563/33650 (epoch 18.667), train_loss = 0.89364129, grad/param norm = 1.2700e-01, time/batch = 16.9052s	
12564/33650 (epoch 18.669), train_loss = 0.91340600, grad/param norm = 1.3823e-01, time/batch = 17.2247s	
12565/33650 (epoch 18.670), train_loss = 0.82407772, grad/param norm = 1.3690e-01, time/batch = 17.1563s	
12566/33650 (epoch 18.672), train_loss = 0.87981205, grad/param norm = 1.4538e-01, time/batch = 16.1418s	
12567/33650 (epoch 18.673), train_loss = 0.82433477, grad/param norm = 1.3044e-01, time/batch = 16.2175s	
12568/33650 (epoch 18.675), train_loss = 0.82184093, grad/param norm = 1.1201e-01, time/batch = 17.4908s	
12569/33650 (epoch 18.676), train_loss = 0.99887333, grad/param norm = 1.5427e-01, time/batch = 16.8157s	
12570/33650 (epoch 18.678), train_loss = 0.94609086, grad/param norm = 1.6447e-01, time/batch = 15.9037s	
12571/33650 (epoch 18.679), train_loss = 0.95564305, grad/param norm = 1.4923e-01, time/batch = 17.9812s	
12572/33650 (epoch 18.681), train_loss = 0.95888970, grad/param norm = 1.2782e-01, time/batch = 18.0699s	
12573/33650 (epoch 18.682), train_loss = 0.90156474, grad/param norm = 1.4436e-01, time/batch = 16.8830s	
12574/33650 (epoch 18.684), train_loss = 0.87938477, grad/param norm = 1.3504e-01, time/batch = 15.7254s	
12575/33650 (epoch 18.685), train_loss = 1.08108004, grad/param norm = 1.4654e-01, time/batch = 17.4924s	
12576/33650 (epoch 18.686), train_loss = 1.03132711, grad/param norm = 1.4117e-01, time/batch = 15.8951s	
12577/33650 (epoch 18.688), train_loss = 1.10993498, grad/param norm = 1.5441e-01, time/batch = 15.3911s	
12578/33650 (epoch 18.689), train_loss = 0.91122798, grad/param norm = 1.3302e-01, time/batch = 17.4824s	
12579/33650 (epoch 18.691), train_loss = 1.13923120, grad/param norm = 1.7286e-01, time/batch = 16.4758s	
12580/33650 (epoch 18.692), train_loss = 1.12024421, grad/param norm = 1.4701e-01, time/batch = 16.9683s	
12581/33650 (epoch 18.694), train_loss = 1.04344712, grad/param norm = 1.5934e-01, time/batch = 17.9005s	
12582/33650 (epoch 18.695), train_loss = 0.73985503, grad/param norm = 1.2801e-01, time/batch = 17.0475s	
12583/33650 (epoch 18.697), train_loss = 0.96986098, grad/param norm = 1.5005e-01, time/batch = 17.0631s	
12584/33650 (epoch 18.698), train_loss = 1.16318504, grad/param norm = 1.6651e-01, time/batch = 17.1473s	
12585/33650 (epoch 18.700), train_loss = 0.98011913, grad/param norm = 1.4298e-01, time/batch = 17.8287s	
12586/33650 (epoch 18.701), train_loss = 1.03296108, grad/param norm = 1.4878e-01, time/batch = 16.9828s	
12587/33650 (epoch 18.703), train_loss = 1.15105087, grad/param norm = 1.4049e-01, time/batch = 16.1438s	
12588/33650 (epoch 18.704), train_loss = 0.97148129, grad/param norm = 1.3136e-01, time/batch = 15.7985s	
12589/33650 (epoch 18.706), train_loss = 0.95611568, grad/param norm = 1.3593e-01, time/batch = 17.3239s	
12590/33650 (epoch 18.707), train_loss = 1.11084853, grad/param norm = 1.4780e-01, time/batch = 16.9853s	
12591/33650 (epoch 18.709), train_loss = 0.98441170, grad/param norm = 1.4795e-01, time/batch = 16.7328s	
12592/33650 (epoch 18.710), train_loss = 1.18745781, grad/param norm = 1.5410e-01, time/batch = 16.7257s	
12593/33650 (epoch 18.712), train_loss = 0.92307805, grad/param norm = 1.4087e-01, time/batch = 17.9121s	
12594/33650 (epoch 18.713), train_loss = 0.91719384, grad/param norm = 1.6633e-01, time/batch = 16.3911s	
12595/33650 (epoch 18.715), train_loss = 1.09205517, grad/param norm = 1.7234e-01, time/batch = 17.8262s	
12596/33650 (epoch 18.716), train_loss = 0.91288485, grad/param norm = 1.4048e-01, time/batch = 16.9937s	
12597/33650 (epoch 18.718), train_loss = 0.96053339, grad/param norm = 1.5282e-01, time/batch = 16.0781s	
12598/33650 (epoch 18.719), train_loss = 1.13639245, grad/param norm = 1.6149e-01, time/batch = 15.5546s	
12599/33650 (epoch 18.721), train_loss = 1.22468099, grad/param norm = 1.6859e-01, time/batch = 18.0631s	
12600/33650 (epoch 18.722), train_loss = 1.09044730, grad/param norm = 1.7587e-01, time/batch = 17.3785s	
12601/33650 (epoch 18.724), train_loss = 1.12340882, grad/param norm = 1.6461e-01, time/batch = 16.3094s	
12602/33650 (epoch 18.725), train_loss = 1.10558241, grad/param norm = 1.5636e-01, time/batch = 17.0674s	
12603/33650 (epoch 18.727), train_loss = 0.93295334, grad/param norm = 1.5307e-01, time/batch = 16.8280s	
12604/33650 (epoch 18.728), train_loss = 0.96679025, grad/param norm = 1.3856e-01, time/batch = 17.3164s	
12605/33650 (epoch 18.730), train_loss = 1.05726021, grad/param norm = 1.5636e-01, time/batch = 15.4584s	
12606/33650 (epoch 18.731), train_loss = 1.13976689, grad/param norm = 1.5655e-01, time/batch = 17.4979s	
12607/33650 (epoch 18.733), train_loss = 1.01160730, grad/param norm = 1.5550e-01, time/batch = 17.8156s	
12608/33650 (epoch 18.734), train_loss = 1.14005143, grad/param norm = 1.6495e-01, time/batch = 16.9769s	
12609/33650 (epoch 18.736), train_loss = 1.01764902, grad/param norm = 1.5150e-01, time/batch = 14.6476s	
12610/33650 (epoch 18.737), train_loss = 1.05839289, grad/param norm = 1.6186e-01, time/batch = 17.9062s	
12611/33650 (epoch 18.738), train_loss = 0.90145224, grad/param norm = 1.4448e-01, time/batch = 17.8990s	
12612/33650 (epoch 18.740), train_loss = 0.87541568, grad/param norm = 1.3644e-01, time/batch = 16.8112s	
12613/33650 (epoch 18.741), train_loss = 0.92403228, grad/param norm = 1.4856e-01, time/batch = 16.6341s	
12614/33650 (epoch 18.743), train_loss = 0.99818623, grad/param norm = 1.3998e-01, time/batch = 16.9010s	
12615/33650 (epoch 18.744), train_loss = 1.04648647, grad/param norm = 1.3730e-01, time/batch = 16.8227s	
12616/33650 (epoch 18.746), train_loss = 0.99765630, grad/param norm = 1.3514e-01, time/batch = 17.2337s	
12617/33650 (epoch 18.747), train_loss = 1.11521972, grad/param norm = 1.4905e-01, time/batch = 17.8941s	
12618/33650 (epoch 18.749), train_loss = 0.85360512, grad/param norm = 1.4227e-01, time/batch = 17.9860s	
12619/33650 (epoch 18.750), train_loss = 1.13492132, grad/param norm = 1.4259e-01, time/batch = 17.2291s	
12620/33650 (epoch 18.752), train_loss = 1.11873340, grad/param norm = 1.5066e-01, time/batch = 17.9856s	
12621/33650 (epoch 18.753), train_loss = 1.21478755, grad/param norm = 1.6412e-01, time/batch = 15.7858s	
12622/33650 (epoch 18.755), train_loss = 0.97650088, grad/param norm = 1.3304e-01, time/batch = 16.9823s	
12623/33650 (epoch 18.756), train_loss = 1.08494186, grad/param norm = 1.5365e-01, time/batch = 17.7202s	
12624/33650 (epoch 18.758), train_loss = 1.08584410, grad/param norm = 1.4366e-01, time/batch = 17.8167s	
12625/33650 (epoch 18.759), train_loss = 1.13514894, grad/param norm = 1.4797e-01, time/batch = 17.3896s	
12626/33650 (epoch 18.761), train_loss = 1.05761095, grad/param norm = 1.5445e-01, time/batch = 16.3190s	
12627/33650 (epoch 18.762), train_loss = 1.03424998, grad/param norm = 1.5303e-01, time/batch = 16.5583s	
12628/33650 (epoch 18.764), train_loss = 1.08948341, grad/param norm = 1.5753e-01, time/batch = 17.4088s	
12629/33650 (epoch 18.765), train_loss = 1.02385932, grad/param norm = 1.5206e-01, time/batch = 16.7306s	
12630/33650 (epoch 18.767), train_loss = 0.99767286, grad/param norm = 1.3232e-01, time/batch = 15.4765s	
12631/33650 (epoch 18.768), train_loss = 0.89735430, grad/param norm = 1.4574e-01, time/batch = 18.1375s	
12632/33650 (epoch 18.770), train_loss = 1.07255523, grad/param norm = 1.5134e-01, time/batch = 16.6441s	
12633/33650 (epoch 18.771), train_loss = 1.02947622, grad/param norm = 1.4817e-01, time/batch = 16.6489s	
12634/33650 (epoch 18.773), train_loss = 1.15196013, grad/param norm = 1.6952e-01, time/batch = 17.7482s	
12635/33650 (epoch 18.774), train_loss = 1.06419866, grad/param norm = 1.7086e-01, time/batch = 17.9965s	
12636/33650 (epoch 18.776), train_loss = 1.12359687, grad/param norm = 1.6041e-01, time/batch = 15.6359s	
12637/33650 (epoch 18.777), train_loss = 0.90690350, grad/param norm = 1.3772e-01, time/batch = 17.7162s	
12638/33650 (epoch 18.779), train_loss = 0.98703312, grad/param norm = 1.3517e-01, time/batch = 17.2400s	
12639/33650 (epoch 18.780), train_loss = 0.93381947, grad/param norm = 1.3158e-01, time/batch = 16.8320s	
12640/33650 (epoch 18.782), train_loss = 0.94283656, grad/param norm = 1.3178e-01, time/batch = 15.7932s	
12641/33650 (epoch 18.783), train_loss = 0.91391903, grad/param norm = 1.3681e-01, time/batch = 17.3870s	
12642/33650 (epoch 18.785), train_loss = 1.21988648, grad/param norm = 1.4370e-01, time/batch = 17.9869s	
12643/33650 (epoch 18.786), train_loss = 1.07387947, grad/param norm = 1.4004e-01, time/batch = 24.8117s	
12644/33650 (epoch 18.788), train_loss = 1.07265180, grad/param norm = 1.5262e-01, time/batch = 22.6745s	
12645/33650 (epoch 18.789), train_loss = 1.09825188, grad/param norm = 1.4606e-01, time/batch = 18.0644s	
12646/33650 (epoch 18.790), train_loss = 1.06792934, grad/param norm = 1.6687e-01, time/batch = 15.6473s	
12647/33650 (epoch 18.792), train_loss = 1.13754769, grad/param norm = 1.6514e-01, time/batch = 17.7335s	
12648/33650 (epoch 18.793), train_loss = 1.12306037, grad/param norm = 1.7564e-01, time/batch = 16.7349s	
12649/33650 (epoch 18.795), train_loss = 1.17701292, grad/param norm = 1.4874e-01, time/batch = 16.7266s	
12650/33650 (epoch 18.796), train_loss = 0.99297244, grad/param norm = 1.4212e-01, time/batch = 17.7177s	
12651/33650 (epoch 18.798), train_loss = 0.99862214, grad/param norm = 1.4612e-01, time/batch = 17.4936s	
12652/33650 (epoch 18.799), train_loss = 1.04070196, grad/param norm = 1.4572e-01, time/batch = 17.4846s	
12653/33650 (epoch 18.801), train_loss = 1.05823837, grad/param norm = 1.4572e-01, time/batch = 16.0599s	
12654/33650 (epoch 18.802), train_loss = 1.13200687, grad/param norm = 1.4511e-01, time/batch = 17.4963s	
12655/33650 (epoch 18.804), train_loss = 1.04036900, grad/param norm = 1.6642e-01, time/batch = 16.6611s	
12656/33650 (epoch 18.805), train_loss = 1.00017798, grad/param norm = 1.2436e-01, time/batch = 16.4778s	
12657/33650 (epoch 18.807), train_loss = 1.24079113, grad/param norm = 1.7035e-01, time/batch = 17.6474s	
12658/33650 (epoch 18.808), train_loss = 1.28890928, grad/param norm = 1.7053e-01, time/batch = 17.0781s	
12659/33650 (epoch 18.810), train_loss = 1.08954506, grad/param norm = 1.5898e-01, time/batch = 17.7602s	
12660/33650 (epoch 18.811), train_loss = 1.07491420, grad/param norm = 1.6852e-01, time/batch = 16.3854s	
12661/33650 (epoch 18.813), train_loss = 0.98010998, grad/param norm = 1.5130e-01, time/batch = 17.9025s	
12662/33650 (epoch 18.814), train_loss = 1.11707489, grad/param norm = 1.5752e-01, time/batch = 16.5573s	
12663/33650 (epoch 18.816), train_loss = 1.09313295, grad/param norm = 1.6883e-01, time/batch = 16.7233s	
12664/33650 (epoch 18.817), train_loss = 1.13690969, grad/param norm = 1.6194e-01, time/batch = 16.6327s	
12665/33650 (epoch 18.819), train_loss = 1.09429334, grad/param norm = 1.4423e-01, time/batch = 17.5653s	
12666/33650 (epoch 18.820), train_loss = 1.17371324, grad/param norm = 1.5193e-01, time/batch = 17.3314s	
12667/33650 (epoch 18.822), train_loss = 1.10154403, grad/param norm = 1.8180e-01, time/batch = 16.5624s	
12668/33650 (epoch 18.823), train_loss = 0.98627288, grad/param norm = 1.6329e-01, time/batch = 18.0722s	
12669/33650 (epoch 18.825), train_loss = 1.04646873, grad/param norm = 1.4651e-01, time/batch = 17.4162s	
12670/33650 (epoch 18.826), train_loss = 1.10393039, grad/param norm = 1.4539e-01, time/batch = 16.2334s	
12671/33650 (epoch 18.828), train_loss = 1.21846471, grad/param norm = 1.6220e-01, time/batch = 16.9860s	
12672/33650 (epoch 18.829), train_loss = 0.88451126, grad/param norm = 1.4327e-01, time/batch = 17.4744s	
12673/33650 (epoch 18.831), train_loss = 1.12946903, grad/param norm = 1.5584e-01, time/batch = 17.2412s	
12674/33650 (epoch 18.832), train_loss = 1.10730856, grad/param norm = 1.5393e-01, time/batch = 16.1493s	
12675/33650 (epoch 18.834), train_loss = 1.10671123, grad/param norm = 1.5952e-01, time/batch = 17.1702s	
12676/33650 (epoch 18.835), train_loss = 1.30188067, grad/param norm = 1.7707e-01, time/batch = 18.4064s	
12677/33650 (epoch 18.837), train_loss = 1.09796550, grad/param norm = 1.7435e-01, time/batch = 16.4763s	
12678/33650 (epoch 18.838), train_loss = 1.03909372, grad/param norm = 1.5441e-01, time/batch = 15.8828s	
12679/33650 (epoch 18.840), train_loss = 1.11712619, grad/param norm = 1.4692e-01, time/batch = 17.6441s	
12680/33650 (epoch 18.841), train_loss = 0.97531912, grad/param norm = 1.5394e-01, time/batch = 16.7061s	
12681/33650 (epoch 18.842), train_loss = 1.02632497, grad/param norm = 1.4116e-01, time/batch = 17.4656s	
12682/33650 (epoch 18.844), train_loss = 1.18034006, grad/param norm = 1.6191e-01, time/batch = 18.1453s	
12683/33650 (epoch 18.845), train_loss = 0.97994237, grad/param norm = 1.3361e-01, time/batch = 17.7344s	
12684/33650 (epoch 18.847), train_loss = 0.81101839, grad/param norm = 1.5152e-01, time/batch = 16.3128s	
12685/33650 (epoch 18.848), train_loss = 0.90873989, grad/param norm = 1.5168e-01, time/batch = 18.2389s	
12686/33650 (epoch 18.850), train_loss = 1.02910740, grad/param norm = 1.5074e-01, time/batch = 18.7350s	
12687/33650 (epoch 18.851), train_loss = 0.83693403, grad/param norm = 1.2195e-01, time/batch = 17.8929s	
12688/33650 (epoch 18.853), train_loss = 1.03111439, grad/param norm = 1.4670e-01, time/batch = 16.9814s	
12689/33650 (epoch 18.854), train_loss = 1.14834268, grad/param norm = 1.8070e-01, time/batch = 17.5764s	
12690/33650 (epoch 18.856), train_loss = 0.79459843, grad/param norm = 1.2638e-01, time/batch = 17.9046s	
12691/33650 (epoch 18.857), train_loss = 1.03520042, grad/param norm = 1.2767e-01, time/batch = 16.1943s	
12692/33650 (epoch 18.859), train_loss = 0.92598370, grad/param norm = 1.2548e-01, time/batch = 18.4832s	
12693/33650 (epoch 18.860), train_loss = 0.87657544, grad/param norm = 1.3703e-01, time/batch = 18.4032s	
12694/33650 (epoch 18.862), train_loss = 0.92952901, grad/param norm = 1.3372e-01, time/batch = 17.1302s	
12695/33650 (epoch 18.863), train_loss = 1.13938761, grad/param norm = 1.4323e-01, time/batch = 18.1438s	
12696/33650 (epoch 18.865), train_loss = 0.98701790, grad/param norm = 1.3261e-01, time/batch = 18.4041s	
12697/33650 (epoch 18.866), train_loss = 0.92444668, grad/param norm = 1.3478e-01, time/batch = 17.2147s	
12698/33650 (epoch 18.868), train_loss = 0.88192336, grad/param norm = 1.4112e-01, time/batch = 17.8851s	
12699/33650 (epoch 18.869), train_loss = 1.12088813, grad/param norm = 1.5085e-01, time/batch = 15.5561s	
12700/33650 (epoch 18.871), train_loss = 0.90075864, grad/param norm = 1.3337e-01, time/batch = 16.4853s	
12701/33650 (epoch 18.872), train_loss = 1.03286296, grad/param norm = 1.4892e-01, time/batch = 16.8815s	
12702/33650 (epoch 18.874), train_loss = 1.09154858, grad/param norm = 1.6035e-01, time/batch = 17.8900s	
12703/33650 (epoch 18.875), train_loss = 1.00088740, grad/param norm = 1.3890e-01, time/batch = 18.5665s	
12704/33650 (epoch 18.877), train_loss = 1.18276328, grad/param norm = 1.4805e-01, time/batch = 17.8794s	
12705/33650 (epoch 18.878), train_loss = 0.72338888, grad/param norm = 1.1699e-01, time/batch = 18.0543s	
12706/33650 (epoch 18.880), train_loss = 1.07721910, grad/param norm = 1.5955e-01, time/batch = 18.4781s	
12707/33650 (epoch 18.881), train_loss = 0.97675854, grad/param norm = 1.5806e-01, time/batch = 17.6314s	
12708/33650 (epoch 18.883), train_loss = 1.05088941, grad/param norm = 1.4354e-01, time/batch = 16.5412s	
12709/33650 (epoch 18.884), train_loss = 1.13763391, grad/param norm = 1.6024e-01, time/batch = 18.1433s	
12710/33650 (epoch 18.886), train_loss = 1.12578061, grad/param norm = 1.5707e-01, time/batch = 18.9065s	
12711/33650 (epoch 18.887), train_loss = 0.94166763, grad/param norm = 1.2815e-01, time/batch = 16.9561s	
12712/33650 (epoch 18.889), train_loss = 1.03813403, grad/param norm = 1.5679e-01, time/batch = 18.9724s	
12713/33650 (epoch 18.890), train_loss = 1.07622745, grad/param norm = 1.3607e-01, time/batch = 18.8121s	
12714/33650 (epoch 18.892), train_loss = 1.03362497, grad/param norm = 1.6025e-01, time/batch = 17.6452s	
12715/33650 (epoch 18.893), train_loss = 1.07091220, grad/param norm = 1.4109e-01, time/batch = 17.3905s	
12716/33650 (epoch 18.895), train_loss = 1.14635835, grad/param norm = 1.5097e-01, time/batch = 17.2905s	
12717/33650 (epoch 18.896), train_loss = 0.95058152, grad/param norm = 1.6368e-01, time/batch = 18.0663s	
12718/33650 (epoch 18.897), train_loss = 0.85972558, grad/param norm = 1.2540e-01, time/batch = 15.7886s	
12719/33650 (epoch 18.899), train_loss = 0.91310316, grad/param norm = 1.3124e-01, time/batch = 17.5519s	
12720/33650 (epoch 18.900), train_loss = 0.83969290, grad/param norm = 1.3949e-01, time/batch = 17.2388s	
12721/33650 (epoch 18.902), train_loss = 1.04251466, grad/param norm = 1.5068e-01, time/batch = 18.5609s	
12722/33650 (epoch 18.903), train_loss = 1.00469390, grad/param norm = 1.6293e-01, time/batch = 17.7254s	
12723/33650 (epoch 18.905), train_loss = 1.18111633, grad/param norm = 1.7712e-01, time/batch = 17.8970s	
12724/33650 (epoch 18.906), train_loss = 0.96510068, grad/param norm = 1.3806e-01, time/batch = 17.9955s	
12725/33650 (epoch 18.908), train_loss = 0.99135755, grad/param norm = 1.3430e-01, time/batch = 17.7238s	
12726/33650 (epoch 18.909), train_loss = 0.97301781, grad/param norm = 1.3254e-01, time/batch = 18.1513s	
12727/33650 (epoch 18.911), train_loss = 0.84372441, grad/param norm = 1.4036e-01, time/batch = 19.4043s	
12728/33650 (epoch 18.912), train_loss = 0.83933487, grad/param norm = 1.2639e-01, time/batch = 16.0435s	
12729/33650 (epoch 18.914), train_loss = 1.03156766, grad/param norm = 1.4048e-01, time/batch = 18.8134s	
12730/33650 (epoch 18.915), train_loss = 0.98674485, grad/param norm = 1.5098e-01, time/batch = 16.4458s	
12731/33650 (epoch 18.917), train_loss = 0.99056749, grad/param norm = 1.5226e-01, time/batch = 17.8961s	
12732/33650 (epoch 18.918), train_loss = 0.83676682, grad/param norm = 1.1867e-01, time/batch = 18.8047s	
12733/33650 (epoch 18.920), train_loss = 0.91834200, grad/param norm = 1.2581e-01, time/batch = 18.6448s	
12734/33650 (epoch 18.921), train_loss = 0.92722966, grad/param norm = 1.3110e-01, time/batch = 18.3936s	
12735/33650 (epoch 18.923), train_loss = 0.87959491, grad/param norm = 1.3907e-01, time/batch = 17.9635s	
12736/33650 (epoch 18.924), train_loss = 1.01551127, grad/param norm = 1.5437e-01, time/batch = 18.6448s	
12737/33650 (epoch 18.926), train_loss = 0.97561258, grad/param norm = 1.6913e-01, time/batch = 18.8303s	
12738/33650 (epoch 18.927), train_loss = 0.96582127, grad/param norm = 1.5662e-01, time/batch = 16.2320s	
12739/33650 (epoch 18.929), train_loss = 1.04856542, grad/param norm = 1.4399e-01, time/batch = 19.1604s	
12740/33650 (epoch 18.930), train_loss = 0.95437961, grad/param norm = 1.4021e-01, time/batch = 17.7432s	
12741/33650 (epoch 18.932), train_loss = 1.00273306, grad/param norm = 1.4602e-01, time/batch = 17.3970s	
12742/33650 (epoch 18.933), train_loss = 0.87798731, grad/param norm = 1.3542e-01, time/batch = 18.2197s	
12743/33650 (epoch 18.935), train_loss = 0.88229074, grad/param norm = 1.3080e-01, time/batch = 18.7337s	
12744/33650 (epoch 18.936), train_loss = 0.93236906, grad/param norm = 1.2525e-01, time/batch = 17.7251s	
12745/33650 (epoch 18.938), train_loss = 0.87570020, grad/param norm = 1.3834e-01, time/batch = 17.8205s	
12746/33650 (epoch 18.939), train_loss = 1.06451315, grad/param norm = 1.6211e-01, time/batch = 18.3967s	
12747/33650 (epoch 18.941), train_loss = 1.01874756, grad/param norm = 1.4035e-01, time/batch = 15.1520s	
12748/33650 (epoch 18.942), train_loss = 1.07688684, grad/param norm = 1.5282e-01, time/batch = 14.0508s	
12749/33650 (epoch 18.944), train_loss = 0.98618939, grad/param norm = 1.3003e-01, time/batch = 14.1113s	
12750/33650 (epoch 18.945), train_loss = 1.05227813, grad/param norm = 1.4749e-01, time/batch = 13.6414s	
12751/33650 (epoch 18.947), train_loss = 1.17362561, grad/param norm = 1.7955e-01, time/batch = 13.9839s	
12752/33650 (epoch 18.948), train_loss = 1.16527421, grad/param norm = 1.5817e-01, time/batch = 14.0408s	
12753/33650 (epoch 18.949), train_loss = 0.90083723, grad/param norm = 1.4725e-01, time/batch = 13.9669s	
12754/33650 (epoch 18.951), train_loss = 1.16325833, grad/param norm = 1.6224e-01, time/batch = 13.8148s	
12755/33650 (epoch 18.952), train_loss = 1.10234631, grad/param norm = 1.5037e-01, time/batch = 13.7351s	
12756/33650 (epoch 18.954), train_loss = 1.07956496, grad/param norm = 1.5557e-01, time/batch = 13.6596s	
12757/33650 (epoch 18.955), train_loss = 1.07235466, grad/param norm = 1.3824e-01, time/batch = 13.8981s	
12758/33650 (epoch 18.957), train_loss = 1.06566861, grad/param norm = 1.4897e-01, time/batch = 13.6527s	
12759/33650 (epoch 18.958), train_loss = 0.81238018, grad/param norm = 1.3067e-01, time/batch = 13.6601s	
12760/33650 (epoch 18.960), train_loss = 0.84527197, grad/param norm = 1.3456e-01, time/batch = 13.6586s	
12761/33650 (epoch 18.961), train_loss = 0.90387224, grad/param norm = 1.4264e-01, time/batch = 14.2974s	
12762/33650 (epoch 18.963), train_loss = 0.96212607, grad/param norm = 1.4767e-01, time/batch = 13.7369s	
12763/33650 (epoch 18.964), train_loss = 1.05190992, grad/param norm = 1.4601e-01, time/batch = 13.7265s	
12764/33650 (epoch 18.966), train_loss = 1.02423283, grad/param norm = 1.5151e-01, time/batch = 13.7304s	
12765/33650 (epoch 18.967), train_loss = 1.04808785, grad/param norm = 1.4334e-01, time/batch = 14.5361s	
12766/33650 (epoch 18.969), train_loss = 0.99081857, grad/param norm = 1.3263e-01, time/batch = 13.8215s	
12767/33650 (epoch 18.970), train_loss = 1.06890501, grad/param norm = 1.5530e-01, time/batch = 13.7412s	
12768/33650 (epoch 18.972), train_loss = 1.33118519, grad/param norm = 1.9775e-01, time/batch = 13.8196s	
12769/33650 (epoch 18.973), train_loss = 0.91573685, grad/param norm = 1.3078e-01, time/batch = 13.5713s	
12770/33650 (epoch 18.975), train_loss = 0.91121478, grad/param norm = 1.3175e-01, time/batch = 14.2205s	
12771/33650 (epoch 18.976), train_loss = 0.90932434, grad/param norm = 1.2298e-01, time/batch = 13.8184s	
12772/33650 (epoch 18.978), train_loss = 0.94934431, grad/param norm = 1.4554e-01, time/batch = 13.8262s	
12773/33650 (epoch 18.979), train_loss = 0.99665221, grad/param norm = 1.5335e-01, time/batch = 13.8297s	
12774/33650 (epoch 18.981), train_loss = 0.93680623, grad/param norm = 1.1695e-01, time/batch = 14.2329s	
12775/33650 (epoch 18.982), train_loss = 1.03456019, grad/param norm = 1.4243e-01, time/batch = 14.4635s	
12776/33650 (epoch 18.984), train_loss = 0.84252469, grad/param norm = 1.3223e-01, time/batch = 13.6577s	
12777/33650 (epoch 18.985), train_loss = 0.85367729, grad/param norm = 1.3534e-01, time/batch = 13.6538s	
12778/33650 (epoch 18.987), train_loss = 1.00128639, grad/param norm = 1.4499e-01, time/batch = 13.9778s	
12779/33650 (epoch 18.988), train_loss = 1.02090471, grad/param norm = 1.5474e-01, time/batch = 13.9044s	
12780/33650 (epoch 18.990), train_loss = 1.23564860, grad/param norm = 1.7832e-01, time/batch = 13.5768s	
12781/33650 (epoch 18.991), train_loss = 1.06628148, grad/param norm = 1.5327e-01, time/batch = 13.7278s	
12782/33650 (epoch 18.993), train_loss = 1.03032803, grad/param norm = 1.6064e-01, time/batch = 13.8165s	
12783/33650 (epoch 18.994), train_loss = 0.97363880, grad/param norm = 1.3391e-01, time/batch = 13.8274s	
12784/33650 (epoch 18.996), train_loss = 0.93005837, grad/param norm = 1.4221e-01, time/batch = 13.9013s	
12785/33650 (epoch 18.997), train_loss = 1.04685255, grad/param norm = 1.4405e-01, time/batch = 13.6558s	
12786/33650 (epoch 18.999), train_loss = 0.92186407, grad/param norm = 1.3310e-01, time/batch = 13.6549s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
12787/33650 (epoch 19.000), train_loss = 1.08142459, grad/param norm = 1.6558e-01, time/batch = 14.0622s	
12788/33650 (epoch 19.001), train_loss = 1.17417108, grad/param norm = 1.5077e-01, time/batch = 13.7449s	
12789/33650 (epoch 19.003), train_loss = 1.15805096, grad/param norm = 1.7458e-01, time/batch = 13.7375s	
12790/33650 (epoch 19.004), train_loss = 1.04492887, grad/param norm = 1.4989e-01, time/batch = 13.9735s	
12791/33650 (epoch 19.006), train_loss = 0.97225163, grad/param norm = 1.4136e-01, time/batch = 14.2245s	
12792/33650 (epoch 19.007), train_loss = 1.06967349, grad/param norm = 1.8246e-01, time/batch = 13.8291s	
12793/33650 (epoch 19.009), train_loss = 0.96915410, grad/param norm = 1.3466e-01, time/batch = 13.6614s	
12794/33650 (epoch 19.010), train_loss = 1.10417915, grad/param norm = 1.6170e-01, time/batch = 13.9007s	
12795/33650 (epoch 19.012), train_loss = 0.94783107, grad/param norm = 1.3570e-01, time/batch = 13.8159s	
12796/33650 (epoch 19.013), train_loss = 1.02439005, grad/param norm = 1.6302e-01, time/batch = 13.8157s	
12797/33650 (epoch 19.015), train_loss = 0.95496311, grad/param norm = 1.4247e-01, time/batch = 13.5740s	
12798/33650 (epoch 19.016), train_loss = 0.89586480, grad/param norm = 1.5265e-01, time/batch = 13.7432s	
12799/33650 (epoch 19.018), train_loss = 1.00678366, grad/param norm = 1.5288e-01, time/batch = 13.7384s	
12800/33650 (epoch 19.019), train_loss = 0.95406703, grad/param norm = 1.3924e-01, time/batch = 14.2962s	
12801/33650 (epoch 19.021), train_loss = 1.06638924, grad/param norm = 1.6121e-01, time/batch = 13.6649s	
12802/33650 (epoch 19.022), train_loss = 0.96328757, grad/param norm = 1.3417e-01, time/batch = 13.9046s	
12803/33650 (epoch 19.024), train_loss = 0.89559005, grad/param norm = 1.4089e-01, time/batch = 13.7456s	
12804/33650 (epoch 19.025), train_loss = 0.98676706, grad/param norm = 1.4893e-01, time/batch = 14.0657s	
12805/33650 (epoch 19.027), train_loss = 1.07491638, grad/param norm = 1.5116e-01, time/batch = 13.6577s	
12806/33650 (epoch 19.028), train_loss = 1.10961780, grad/param norm = 1.6250e-01, time/batch = 14.0526s	
12807/33650 (epoch 19.030), train_loss = 1.01460856, grad/param norm = 1.4736e-01, time/batch = 13.6596s	
12808/33650 (epoch 19.031), train_loss = 0.91430751, grad/param norm = 1.3549e-01, time/batch = 14.0637s	
12809/33650 (epoch 19.033), train_loss = 0.96740051, grad/param norm = 1.1503e-01, time/batch = 13.9862s	
12810/33650 (epoch 19.034), train_loss = 1.02596107, grad/param norm = 1.4134e-01, time/batch = 13.8810s	
12811/33650 (epoch 19.036), train_loss = 1.14514920, grad/param norm = 1.5601e-01, time/batch = 13.6588s	
12812/33650 (epoch 19.037), train_loss = 0.97487324, grad/param norm = 1.4199e-01, time/batch = 13.6583s	
12813/33650 (epoch 19.039), train_loss = 1.10969667, grad/param norm = 1.6671e-01, time/batch = 13.8119s	
12814/33650 (epoch 19.040), train_loss = 1.20198352, grad/param norm = 1.7343e-01, time/batch = 13.8243s	
12815/33650 (epoch 19.042), train_loss = 1.20668229, grad/param norm = 1.6380e-01, time/batch = 13.8140s	
12816/33650 (epoch 19.043), train_loss = 0.95925889, grad/param norm = 1.3635e-01, time/batch = 13.8122s	
12817/33650 (epoch 19.045), train_loss = 0.92780740, grad/param norm = 1.3890e-01, time/batch = 13.9110s	
12818/33650 (epoch 19.046), train_loss = 1.08507931, grad/param norm = 1.4613e-01, time/batch = 13.8140s	
12819/33650 (epoch 19.048), train_loss = 1.11411256, grad/param norm = 1.4363e-01, time/batch = 13.7420s	
12820/33650 (epoch 19.049), train_loss = 1.02847596, grad/param norm = 1.4571e-01, time/batch = 14.1434s	
12821/33650 (epoch 19.051), train_loss = 1.16108763, grad/param norm = 1.7880e-01, time/batch = 13.9881s	
12822/33650 (epoch 19.052), train_loss = 1.16525561, grad/param norm = 1.8588e-01, time/batch = 14.0683s	
12823/33650 (epoch 19.053), train_loss = 1.06797951, grad/param norm = 1.4234e-01, time/batch = 13.6565s	
12824/33650 (epoch 19.055), train_loss = 0.89858630, grad/param norm = 1.4152e-01, time/batch = 13.7384s	
12825/33650 (epoch 19.056), train_loss = 0.87957680, grad/param norm = 1.2291e-01, time/batch = 13.7303s	
12826/33650 (epoch 19.058), train_loss = 1.10719284, grad/param norm = 1.5728e-01, time/batch = 14.1506s	
12827/33650 (epoch 19.059), train_loss = 1.06362049, grad/param norm = 1.5989e-01, time/batch = 13.6714s	
12828/33650 (epoch 19.061), train_loss = 1.09956818, grad/param norm = 1.6273e-01, time/batch = 13.6546s	
12829/33650 (epoch 19.062), train_loss = 1.08628859, grad/param norm = 1.4547e-01, time/batch = 13.7446s	
12830/33650 (epoch 19.064), train_loss = 0.96827659, grad/param norm = 1.4039e-01, time/batch = 14.3867s	
12831/33650 (epoch 19.065), train_loss = 0.96652947, grad/param norm = 1.3263e-01, time/batch = 14.3151s	
12832/33650 (epoch 19.067), train_loss = 0.89970954, grad/param norm = 1.2873e-01, time/batch = 13.6562s	
12833/33650 (epoch 19.068), train_loss = 1.01182558, grad/param norm = 1.5475e-01, time/batch = 13.7579s	
12834/33650 (epoch 19.070), train_loss = 1.05227770, grad/param norm = 1.5134e-01, time/batch = 16.5676s	
12835/33650 (epoch 19.071), train_loss = 1.03057353, grad/param norm = 1.4645e-01, time/batch = 17.7287s	
12836/33650 (epoch 19.073), train_loss = 1.06662394, grad/param norm = 1.6234e-01, time/batch = 15.9635s	
12837/33650 (epoch 19.074), train_loss = 1.13634228, grad/param norm = 1.4306e-01, time/batch = 17.4738s	
12838/33650 (epoch 19.076), train_loss = 1.10687398, grad/param norm = 1.6026e-01, time/batch = 17.2338s	
12839/33650 (epoch 19.077), train_loss = 1.00567455, grad/param norm = 1.3946e-01, time/batch = 18.5571s	
12840/33650 (epoch 19.079), train_loss = 1.02233042, grad/param norm = 1.3834e-01, time/batch = 18.3151s	
12841/33650 (epoch 19.080), train_loss = 1.06175682, grad/param norm = 1.4373e-01, time/batch = 16.9735s	
12842/33650 (epoch 19.082), train_loss = 1.06479437, grad/param norm = 1.4470e-01, time/batch = 18.6430s	
12843/33650 (epoch 19.083), train_loss = 1.09442148, grad/param norm = 1.5541e-01, time/batch = 17.0510s	
12844/33650 (epoch 19.085), train_loss = 1.10449371, grad/param norm = 1.4107e-01, time/batch = 17.3173s	
12845/33650 (epoch 19.086), train_loss = 1.11121755, grad/param norm = 1.7188e-01, time/batch = 18.2096s	
12846/33650 (epoch 19.088), train_loss = 1.06097475, grad/param norm = 1.4346e-01, time/batch = 19.0614s	
12847/33650 (epoch 19.089), train_loss = 1.00330061, grad/param norm = 1.4795e-01, time/batch = 18.1341s	
12848/33650 (epoch 19.091), train_loss = 0.96296078, grad/param norm = 1.3476e-01, time/batch = 16.1395s	
12849/33650 (epoch 19.092), train_loss = 1.02148565, grad/param norm = 1.5484e-01, time/batch = 18.5559s	
12850/33650 (epoch 19.094), train_loss = 1.07225628, grad/param norm = 1.3376e-01, time/batch = 18.1401s	
12851/33650 (epoch 19.095), train_loss = 1.06765749, grad/param norm = 1.5288e-01, time/batch = 16.0578s	
12852/33650 (epoch 19.097), train_loss = 0.97478874, grad/param norm = 1.5582e-01, time/batch = 15.9518s	
12853/33650 (epoch 19.098), train_loss = 0.83477308, grad/param norm = 1.3885e-01, time/batch = 17.8961s	
12854/33650 (epoch 19.100), train_loss = 0.94370610, grad/param norm = 1.4554e-01, time/batch = 17.3016s	
12855/33650 (epoch 19.101), train_loss = 1.02486741, grad/param norm = 1.6322e-01, time/batch = 16.2331s	
12856/33650 (epoch 19.103), train_loss = 0.98072429, grad/param norm = 1.6821e-01, time/batch = 17.9005s	
12857/33650 (epoch 19.104), train_loss = 1.12699018, grad/param norm = 1.4842e-01, time/batch = 18.4747s	
12858/33650 (epoch 19.105), train_loss = 1.00920130, grad/param norm = 1.4121e-01, time/batch = 17.2310s	
12859/33650 (epoch 19.107), train_loss = 0.94210311, grad/param norm = 1.3392e-01, time/batch = 16.8980s	
12860/33650 (epoch 19.108), train_loss = 1.11498064, grad/param norm = 1.5352e-01, time/batch = 17.0606s	
12861/33650 (epoch 19.110), train_loss = 1.20218181, grad/param norm = 1.6018e-01, time/batch = 17.4550s	
12862/33650 (epoch 19.111), train_loss = 0.97106692, grad/param norm = 1.4764e-01, time/batch = 18.0631s	
12863/33650 (epoch 19.113), train_loss = 0.97739121, grad/param norm = 1.4911e-01, time/batch = 17.4055s	
12864/33650 (epoch 19.114), train_loss = 1.10998027, grad/param norm = 1.4754e-01, time/batch = 15.8062s	
12865/33650 (epoch 19.116), train_loss = 0.92944362, grad/param norm = 1.3201e-01, time/batch = 30.1533s	
12866/33650 (epoch 19.117), train_loss = 1.02679481, grad/param norm = 1.2956e-01, time/batch = 19.5545s	
12867/33650 (epoch 19.119), train_loss = 0.89577878, grad/param norm = 1.2795e-01, time/batch = 17.0582s	
12868/33650 (epoch 19.120), train_loss = 0.97505706, grad/param norm = 1.3439e-01, time/batch = 17.9778s	
12869/33650 (epoch 19.122), train_loss = 0.81639037, grad/param norm = 1.4579e-01, time/batch = 18.2311s	
12870/33650 (epoch 19.123), train_loss = 0.97478423, grad/param norm = 1.3919e-01, time/batch = 17.1548s	
12871/33650 (epoch 19.125), train_loss = 1.07800021, grad/param norm = 1.4640e-01, time/batch = 16.7966s	
12872/33650 (epoch 19.126), train_loss = 1.16347410, grad/param norm = 1.6790e-01, time/batch = 18.2138s	
12873/33650 (epoch 19.128), train_loss = 1.13781739, grad/param norm = 1.7245e-01, time/batch = 18.9713s	
12874/33650 (epoch 19.129), train_loss = 1.15098372, grad/param norm = 1.5371e-01, time/batch = 17.1401s	
12875/33650 (epoch 19.131), train_loss = 1.04316650, grad/param norm = 1.4819e-01, time/batch = 18.0569s	
12876/33650 (epoch 19.132), train_loss = 1.04960177, grad/param norm = 1.4087e-01, time/batch = 17.0446s	
12877/33650 (epoch 19.134), train_loss = 1.12533599, grad/param norm = 1.7271e-01, time/batch = 17.5814s	
12878/33650 (epoch 19.135), train_loss = 0.89111380, grad/param norm = 1.4325e-01, time/batch = 18.2905s	
12879/33650 (epoch 19.137), train_loss = 1.04789469, grad/param norm = 1.7303e-01, time/batch = 17.5695s	
12880/33650 (epoch 19.138), train_loss = 1.07916633, grad/param norm = 1.3944e-01, time/batch = 17.2162s	
12881/33650 (epoch 19.140), train_loss = 1.01569772, grad/param norm = 1.7118e-01, time/batch = 16.9611s	
12882/33650 (epoch 19.141), train_loss = 1.17360818, grad/param norm = 1.6423e-01, time/batch = 17.6532s	
12883/33650 (epoch 19.143), train_loss = 1.22806369, grad/param norm = 1.8074e-01, time/batch = 18.6546s	
12884/33650 (epoch 19.144), train_loss = 1.09400452, grad/param norm = 1.5259e-01, time/batch = 17.5624s	
12885/33650 (epoch 19.146), train_loss = 0.99149301, grad/param norm = 1.4915e-01, time/batch = 17.4868s	
12886/33650 (epoch 19.147), train_loss = 0.95338087, grad/param norm = 1.3727e-01, time/batch = 17.8953s	
12887/33650 (epoch 19.149), train_loss = 0.92964597, grad/param norm = 1.5138e-01, time/batch = 17.9861s	
12888/33650 (epoch 19.150), train_loss = 0.91085979, grad/param norm = 1.8552e-01, time/batch = 17.7191s	
12889/33650 (epoch 19.152), train_loss = 0.95572589, grad/param norm = 1.3343e-01, time/batch = 17.1522s	
12890/33650 (epoch 19.153), train_loss = 0.98152540, grad/param norm = 1.3364e-01, time/batch = 19.0674s	
12891/33650 (epoch 19.155), train_loss = 0.94624943, grad/param norm = 1.3460e-01, time/batch = 17.0600s	
12892/33650 (epoch 19.156), train_loss = 0.92024291, grad/param norm = 1.2621e-01, time/batch = 17.8988s	
12893/33650 (epoch 19.158), train_loss = 1.04657306, grad/param norm = 1.6329e-01, time/batch = 16.7055s	
12894/33650 (epoch 19.159), train_loss = 0.91524968, grad/param norm = 1.1971e-01, time/batch = 17.4604s	
12895/33650 (epoch 19.160), train_loss = 0.95262772, grad/param norm = 1.2931e-01, time/batch = 18.0595s	
12896/33650 (epoch 19.162), train_loss = 0.99278975, grad/param norm = 1.6732e-01, time/batch = 17.5703s	
12897/33650 (epoch 19.163), train_loss = 1.07622574, grad/param norm = 1.6300e-01, time/batch = 18.4862s	
12898/33650 (epoch 19.165), train_loss = 0.90580163, grad/param norm = 1.4530e-01, time/batch = 16.8835s	
12899/33650 (epoch 19.166), train_loss = 0.94840786, grad/param norm = 1.5312e-01, time/batch = 18.3140s	
12900/33650 (epoch 19.168), train_loss = 1.10164321, grad/param norm = 1.7047e-01, time/batch = 17.5679s	
12901/33650 (epoch 19.169), train_loss = 1.01648945, grad/param norm = 1.5133e-01, time/batch = 15.6264s	
12902/33650 (epoch 19.171), train_loss = 1.00720449, grad/param norm = 1.4021e-01, time/batch = 15.7423s	
12903/33650 (epoch 19.172), train_loss = 0.97081364, grad/param norm = 1.3968e-01, time/batch = 17.4689s	
12904/33650 (epoch 19.174), train_loss = 0.93331896, grad/param norm = 1.5467e-01, time/batch = 17.8723s	
12905/33650 (epoch 19.175), train_loss = 0.91039141, grad/param norm = 1.5250e-01, time/batch = 17.3123s	
12906/33650 (epoch 19.177), train_loss = 1.02057581, grad/param norm = 1.4438e-01, time/batch = 17.8148s	
12907/33650 (epoch 19.178), train_loss = 0.95551524, grad/param norm = 1.6090e-01, time/batch = 18.3861s	
12908/33650 (epoch 19.180), train_loss = 0.91533248, grad/param norm = 1.3665e-01, time/batch = 17.6424s	
12909/33650 (epoch 19.181), train_loss = 0.82335278, grad/param norm = 1.3138e-01, time/batch = 18.1461s	
12910/33650 (epoch 19.183), train_loss = 0.96843025, grad/param norm = 1.6003e-01, time/batch = 17.2289s	
12911/33650 (epoch 19.184), train_loss = 0.95396362, grad/param norm = 1.6009e-01, time/batch = 17.3030s	
12912/33650 (epoch 19.186), train_loss = 0.98191001, grad/param norm = 1.6193e-01, time/batch = 18.3026s	
12913/33650 (epoch 19.187), train_loss = 1.18026223, grad/param norm = 1.5221e-01, time/batch = 17.4115s	
12914/33650 (epoch 19.189), train_loss = 1.14359576, grad/param norm = 1.7011e-01, time/batch = 18.3124s	
12915/33650 (epoch 19.190), train_loss = 1.03358335, grad/param norm = 1.5077e-01, time/batch = 17.2311s	
12916/33650 (epoch 19.192), train_loss = 1.19869150, grad/param norm = 1.5333e-01, time/batch = 16.9786s	
12917/33650 (epoch 19.193), train_loss = 1.14142753, grad/param norm = 1.6532e-01, time/batch = 18.7148s	
12918/33650 (epoch 19.195), train_loss = 0.89768912, grad/param norm = 1.3585e-01, time/batch = 17.5578s	
12919/33650 (epoch 19.196), train_loss = 0.86574586, grad/param norm = 1.4767e-01, time/batch = 17.4805s	
12920/33650 (epoch 19.198), train_loss = 0.96032868, grad/param norm = 1.5441e-01, time/batch = 16.1146s	
12921/33650 (epoch 19.199), train_loss = 1.10687998, grad/param norm = 1.6337e-01, time/batch = 18.2321s	
12922/33650 (epoch 19.201), train_loss = 0.97274331, grad/param norm = 1.5808e-01, time/batch = 17.3802s	
12923/33650 (epoch 19.202), train_loss = 0.97373185, grad/param norm = 1.5599e-01, time/batch = 17.6436s	
12924/33650 (epoch 19.204), train_loss = 1.04570675, grad/param norm = 1.4545e-01, time/batch = 18.1394s	
12925/33650 (epoch 19.205), train_loss = 1.00401485, grad/param norm = 1.5089e-01, time/batch = 17.6360s	
12926/33650 (epoch 19.207), train_loss = 0.95098288, grad/param norm = 1.5215e-01, time/batch = 17.4807s	
12927/33650 (epoch 19.208), train_loss = 1.00564234, grad/param norm = 1.4599e-01, time/batch = 18.0583s	
12928/33650 (epoch 19.210), train_loss = 0.82731874, grad/param norm = 1.3384e-01, time/batch = 17.7196s	
12929/33650 (epoch 19.211), train_loss = 0.92672431, grad/param norm = 1.4956e-01, time/batch = 18.2235s	
12930/33650 (epoch 19.212), train_loss = 1.06820199, grad/param norm = 1.6575e-01, time/batch = 18.3997s	
12931/33650 (epoch 19.214), train_loss = 1.16633267, grad/param norm = 1.4977e-01, time/batch = 18.5658s	
12932/33650 (epoch 19.215), train_loss = 0.78288194, grad/param norm = 1.3850e-01, time/batch = 16.3671s	
12933/33650 (epoch 19.217), train_loss = 0.99238111, grad/param norm = 1.6082e-01, time/batch = 17.5436s	
12934/33650 (epoch 19.218), train_loss = 1.03613265, grad/param norm = 1.4465e-01, time/batch = 18.5517s	
12935/33650 (epoch 19.220), train_loss = 0.87500398, grad/param norm = 1.3458e-01, time/batch = 17.0578s	
12936/33650 (epoch 19.221), train_loss = 1.17834366, grad/param norm = 1.6407e-01, time/batch = 17.6536s	
12937/33650 (epoch 19.223), train_loss = 0.80304513, grad/param norm = 1.2965e-01, time/batch = 17.7300s	
12938/33650 (epoch 19.224), train_loss = 0.97380420, grad/param norm = 1.6620e-01, time/batch = 18.1330s	
12939/33650 (epoch 19.226), train_loss = 1.28017174, grad/param norm = 1.6463e-01, time/batch = 17.3812s	
12940/33650 (epoch 19.227), train_loss = 1.15730315, grad/param norm = 1.9832e-01, time/batch = 18.5584s	
12941/33650 (epoch 19.229), train_loss = 1.13690279, grad/param norm = 1.6110e-01, time/batch = 17.5725s	
12942/33650 (epoch 19.230), train_loss = 1.25062899, grad/param norm = 1.7912e-01, time/batch = 17.4874s	
12943/33650 (epoch 19.232), train_loss = 1.08525805, grad/param norm = 1.6153e-01, time/batch = 17.9796s	
12944/33650 (epoch 19.233), train_loss = 1.06453943, grad/param norm = 1.9779e-01, time/batch = 17.4736s	
12945/33650 (epoch 19.235), train_loss = 0.99938397, grad/param norm = 1.3886e-01, time/batch = 15.1184s	
12946/33650 (epoch 19.236), train_loss = 0.89954502, grad/param norm = 1.3955e-01, time/batch = 18.1509s	
12947/33650 (epoch 19.238), train_loss = 0.98841067, grad/param norm = 1.4146e-01, time/batch = 18.1505s	
12948/33650 (epoch 19.239), train_loss = 0.91836539, grad/param norm = 1.4531e-01, time/batch = 18.3906s	
12949/33650 (epoch 19.241), train_loss = 0.96007150, grad/param norm = 1.3365e-01, time/batch = 17.9546s	
12950/33650 (epoch 19.242), train_loss = 0.83803970, grad/param norm = 1.3186e-01, time/batch = 17.2184s	
12951/33650 (epoch 19.244), train_loss = 0.99431474, grad/param norm = 1.4565e-01, time/batch = 18.2296s	
12952/33650 (epoch 19.245), train_loss = 0.88755442, grad/param norm = 1.3457e-01, time/batch = 16.2317s	
12953/33650 (epoch 19.247), train_loss = 0.98667192, grad/param norm = 1.3322e-01, time/batch = 15.8893s	
12954/33650 (epoch 19.248), train_loss = 0.88346574, grad/param norm = 1.3828e-01, time/batch = 17.9005s	
12955/33650 (epoch 19.250), train_loss = 0.98082211, grad/param norm = 1.3750e-01, time/batch = 17.7207s	
12956/33650 (epoch 19.251), train_loss = 1.14203740, grad/param norm = 1.4878e-01, time/batch = 17.5659s	
12957/33650 (epoch 19.253), train_loss = 0.88686640, grad/param norm = 1.2930e-01, time/batch = 18.2210s	
12958/33650 (epoch 19.254), train_loss = 0.91192374, grad/param norm = 1.3805e-01, time/batch = 18.8098s	
12959/33650 (epoch 19.256), train_loss = 1.14502004, grad/param norm = 1.4285e-01, time/batch = 16.5653s	
12960/33650 (epoch 19.257), train_loss = 1.15288003, grad/param norm = 1.5207e-01, time/batch = 18.1239s	
12961/33650 (epoch 19.259), train_loss = 0.87330875, grad/param norm = 1.3438e-01, time/batch = 17.3981s	
12962/33650 (epoch 19.260), train_loss = 1.10526274, grad/param norm = 1.4736e-01, time/batch = 17.3146s	
12963/33650 (epoch 19.262), train_loss = 1.04355145, grad/param norm = 1.5735e-01, time/batch = 16.5388s	
12964/33650 (epoch 19.263), train_loss = 0.94950086, grad/param norm = 1.6373e-01, time/batch = 18.2231s	
12965/33650 (epoch 19.264), train_loss = 1.05836319, grad/param norm = 1.5696e-01, time/batch = 18.3194s	
12966/33650 (epoch 19.266), train_loss = 1.03593645, grad/param norm = 1.4155e-01, time/batch = 17.3817s	
12967/33650 (epoch 19.267), train_loss = 0.93983939, grad/param norm = 1.4339e-01, time/batch = 18.2357s	
12968/33650 (epoch 19.269), train_loss = 1.04753893, grad/param norm = 1.3854e-01, time/batch = 18.8166s	
12969/33650 (epoch 19.270), train_loss = 0.93069829, grad/param norm = 1.2424e-01, time/batch = 17.2213s	
12970/33650 (epoch 19.272), train_loss = 0.97490795, grad/param norm = 1.3692e-01, time/batch = 17.9739s	
12971/33650 (epoch 19.273), train_loss = 1.12433353, grad/param norm = 1.7701e-01, time/batch = 17.6500s	
12972/33650 (epoch 19.275), train_loss = 1.07468972, grad/param norm = 1.4923e-01, time/batch = 17.6482s	
12973/33650 (epoch 19.276), train_loss = 1.13465948, grad/param norm = 1.6087e-01, time/batch = 16.1328s	
12974/33650 (epoch 19.278), train_loss = 1.20970152, grad/param norm = 1.6835e-01, time/batch = 16.8001s	
12975/33650 (epoch 19.279), train_loss = 0.96477228, grad/param norm = 1.3555e-01, time/batch = 18.7257s	
12976/33650 (epoch 19.281), train_loss = 1.05933130, grad/param norm = 1.5837e-01, time/batch = 17.2278s	
12977/33650 (epoch 19.282), train_loss = 1.12126239, grad/param norm = 1.4061e-01, time/batch = 18.2347s	
12978/33650 (epoch 19.284), train_loss = 1.09844586, grad/param norm = 1.6274e-01, time/batch = 17.7422s	
12979/33650 (epoch 19.285), train_loss = 1.09618831, grad/param norm = 1.5518e-01, time/batch = 16.9718s	
12980/33650 (epoch 19.287), train_loss = 0.99756095, grad/param norm = 1.6204e-01, time/batch = 17.5588s	
12981/33650 (epoch 19.288), train_loss = 1.05921053, grad/param norm = 1.7101e-01, time/batch = 18.3925s	
12982/33650 (epoch 19.290), train_loss = 1.02213847, grad/param norm = 1.3594e-01, time/batch = 17.9742s	
12983/33650 (epoch 19.291), train_loss = 0.93810264, grad/param norm = 1.3097e-01, time/batch = 18.0498s	
12984/33650 (epoch 19.293), train_loss = 1.01387752, grad/param norm = 1.6361e-01, time/batch = 17.7219s	
12985/33650 (epoch 19.294), train_loss = 0.91478504, grad/param norm = 1.3506e-01, time/batch = 18.1485s	
12986/33650 (epoch 19.296), train_loss = 0.91988828, grad/param norm = 1.4186e-01, time/batch = 16.8085s	
12987/33650 (epoch 19.297), train_loss = 1.00112263, grad/param norm = 1.4879e-01, time/batch = 18.2236s	
12988/33650 (epoch 19.299), train_loss = 0.87034396, grad/param norm = 1.3362e-01, time/batch = 17.7213s	
12989/33650 (epoch 19.300), train_loss = 0.90463741, grad/param norm = 1.4939e-01, time/batch = 17.7236s	
12990/33650 (epoch 19.302), train_loss = 1.04893259, grad/param norm = 1.3690e-01, time/batch = 17.6578s	
12991/33650 (epoch 19.303), train_loss = 1.03865173, grad/param norm = 1.2943e-01, time/batch = 18.6357s	
12992/33650 (epoch 19.305), train_loss = 1.03383528, grad/param norm = 1.4919e-01, time/batch = 18.2133s	
12993/33650 (epoch 19.306), train_loss = 0.93812879, grad/param norm = 1.3832e-01, time/batch = 17.0620s	
12994/33650 (epoch 19.308), train_loss = 0.87941038, grad/param norm = 1.5101e-01, time/batch = 17.7209s	
12995/33650 (epoch 19.309), train_loss = 1.18557161, grad/param norm = 1.6445e-01, time/batch = 16.0408s	
12996/33650 (epoch 19.311), train_loss = 1.04863968, grad/param norm = 1.6112e-01, time/batch = 16.5554s	
12997/33650 (epoch 19.312), train_loss = 1.01750540, grad/param norm = 1.6355e-01, time/batch = 18.0591s	
12998/33650 (epoch 19.314), train_loss = 0.88335507, grad/param norm = 1.2453e-01, time/batch = 18.8993s	
12999/33650 (epoch 19.315), train_loss = 0.98384261, grad/param norm = 1.5955e-01, time/batch = 17.7202s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch19.32_1.5633.t7	
13000/33650 (epoch 19.316), train_loss = 0.96754736, grad/param norm = 1.5143e-01, time/batch = 17.1496s	
13001/33650 (epoch 19.318), train_loss = 1.23721335, grad/param norm = 1.6297e-01, time/batch = 18.3134s	
13002/33650 (epoch 19.319), train_loss = 0.92485728, grad/param norm = 1.2864e-01, time/batch = 15.9137s	
13003/33650 (epoch 19.321), train_loss = 0.94386537, grad/param norm = 1.3384e-01, time/batch = 18.5600s	
13004/33650 (epoch 19.322), train_loss = 1.02763405, grad/param norm = 1.6782e-01, time/batch = 17.5673s	
13005/33650 (epoch 19.324), train_loss = 1.08049411, grad/param norm = 1.7607e-01, time/batch = 17.4790s	
13006/33650 (epoch 19.325), train_loss = 1.08663301, grad/param norm = 1.5378e-01, time/batch = 18.3939s	
13007/33650 (epoch 19.327), train_loss = 0.91505942, grad/param norm = 1.2889e-01, time/batch = 17.9838s	
13008/33650 (epoch 19.328), train_loss = 1.06185806, grad/param norm = 1.4968e-01, time/batch = 18.0532s	
13009/33650 (epoch 19.330), train_loss = 0.93204657, grad/param norm = 1.2629e-01, time/batch = 0.8295s	
13010/33650 (epoch 19.331), train_loss = 0.83102843, grad/param norm = 1.2805e-01, time/batch = 0.6503s	
13011/33650 (epoch 19.333), train_loss = 0.99762368, grad/param norm = 1.4488e-01, time/batch = 0.6637s	
13012/33650 (epoch 19.334), train_loss = 0.99617814, grad/param norm = 1.4619e-01, time/batch = 0.6837s	
13013/33650 (epoch 19.336), train_loss = 1.12041547, grad/param norm = 1.4557e-01, time/batch = 0.6442s	
13014/33650 (epoch 19.337), train_loss = 0.84093282, grad/param norm = 1.3141e-01, time/batch = 0.6460s	
13015/33650 (epoch 19.339), train_loss = 0.96647852, grad/param norm = 1.2291e-01, time/batch = 0.6461s	
13016/33650 (epoch 19.340), train_loss = 1.14395091, grad/param norm = 1.6840e-01, time/batch = 0.7670s	
13017/33650 (epoch 19.342), train_loss = 0.84706411, grad/param norm = 1.3618e-01, time/batch = 0.9425s	
13018/33650 (epoch 19.343), train_loss = 1.05592641, grad/param norm = 1.4978e-01, time/batch = 0.9410s	
13019/33650 (epoch 19.345), train_loss = 0.98022465, grad/param norm = 1.4702e-01, time/batch = 0.9434s	
13020/33650 (epoch 19.346), train_loss = 0.69444476, grad/param norm = 1.1846e-01, time/batch = 0.9399s	
13021/33650 (epoch 19.348), train_loss = 0.87957797, grad/param norm = 1.2635e-01, time/batch = 1.0724s	
13022/33650 (epoch 19.349), train_loss = 0.84503719, grad/param norm = 1.4981e-01, time/batch = 1.7810s	
13023/33650 (epoch 19.351), train_loss = 1.08349222, grad/param norm = 1.4290e-01, time/batch = 1.7896s	
13024/33650 (epoch 19.352), train_loss = 0.98847099, grad/param norm = 1.4098e-01, time/batch = 8.3365s	
13025/33650 (epoch 19.354), train_loss = 1.20893233, grad/param norm = 2.0008e-01, time/batch = 18.2298s	
13026/33650 (epoch 19.355), train_loss = 1.12730712, grad/param norm = 1.4009e-01, time/batch = 17.3132s	
13027/33650 (epoch 19.357), train_loss = 0.80675993, grad/param norm = 1.4700e-01, time/batch = 17.4823s	
13028/33650 (epoch 19.358), train_loss = 1.06867908, grad/param norm = 1.4652e-01, time/batch = 18.2339s	
13029/33650 (epoch 19.360), train_loss = 1.10385276, grad/param norm = 1.5493e-01, time/batch = 16.4501s	
13030/33650 (epoch 19.361), train_loss = 1.05095507, grad/param norm = 1.3750e-01, time/batch = 17.4708s	
13031/33650 (epoch 19.363), train_loss = 0.95939358, grad/param norm = 1.3901e-01, time/batch = 16.9801s	
13032/33650 (epoch 19.364), train_loss = 0.94309532, grad/param norm = 1.3368e-01, time/batch = 18.3167s	
13033/33650 (epoch 19.366), train_loss = 1.05360459, grad/param norm = 1.5506e-01, time/batch = 16.3822s	
13034/33650 (epoch 19.367), train_loss = 1.05984084, grad/param norm = 1.3910e-01, time/batch = 16.0525s	
13035/33650 (epoch 19.368), train_loss = 0.91814558, grad/param norm = 1.3712e-01, time/batch = 18.6505s	
13036/33650 (epoch 19.370), train_loss = 1.01811061, grad/param norm = 1.5962e-01, time/batch = 18.2323s	
13037/33650 (epoch 19.371), train_loss = 0.80436316, grad/param norm = 1.3511e-01, time/batch = 16.9650s	
13038/33650 (epoch 19.373), train_loss = 0.90261756, grad/param norm = 1.3526e-01, time/batch = 18.2314s	
13039/33650 (epoch 19.374), train_loss = 0.88405358, grad/param norm = 1.2291e-01, time/batch = 18.4898s	
13040/33650 (epoch 19.376), train_loss = 0.99552073, grad/param norm = 1.6289e-01, time/batch = 16.3025s	
13041/33650 (epoch 19.377), train_loss = 1.02749660, grad/param norm = 1.5233e-01, time/batch = 17.6425s	
13042/33650 (epoch 19.379), train_loss = 1.07143477, grad/param norm = 1.5068e-01, time/batch = 18.8942s	
13043/33650 (epoch 19.380), train_loss = 0.79489093, grad/param norm = 1.6861e-01, time/batch = 18.2223s	
13044/33650 (epoch 19.382), train_loss = 0.92684878, grad/param norm = 1.2498e-01, time/batch = 17.1495s	
13045/33650 (epoch 19.383), train_loss = 0.97152721, grad/param norm = 1.3130e-01, time/batch = 15.7350s	
13046/33650 (epoch 19.385), train_loss = 1.11727461, grad/param norm = 1.4622e-01, time/batch = 17.3223s	
13047/33650 (epoch 19.386), train_loss = 0.93584564, grad/param norm = 1.4033e-01, time/batch = 16.9729s	
13048/33650 (epoch 19.388), train_loss = 1.03924044, grad/param norm = 1.3553e-01, time/batch = 18.0612s	
13049/33650 (epoch 19.389), train_loss = 0.98416705, grad/param norm = 1.5019e-01, time/batch = 16.9713s	
13050/33650 (epoch 19.391), train_loss = 0.80815087, grad/param norm = 1.2828e-01, time/batch = 17.9788s	
13051/33650 (epoch 19.392), train_loss = 1.04696795, grad/param norm = 1.5293e-01, time/batch = 18.2352s	
13052/33650 (epoch 19.394), train_loss = 1.03722553, grad/param norm = 1.5558e-01, time/batch = 18.4732s	
13053/33650 (epoch 19.395), train_loss = 1.04067260, grad/param norm = 1.4300e-01, time/batch = 17.8994s	
13054/33650 (epoch 19.397), train_loss = 1.14102587, grad/param norm = 1.4067e-01, time/batch = 15.5420s	
13055/33650 (epoch 19.398), train_loss = 1.05001507, grad/param norm = 1.4592e-01, time/batch = 17.5653s	
13056/33650 (epoch 19.400), train_loss = 1.00742227, grad/param norm = 1.7378e-01, time/batch = 18.5665s	
13057/33650 (epoch 19.401), train_loss = 0.97250052, grad/param norm = 1.6764e-01, time/batch = 16.7329s	
13058/33650 (epoch 19.403), train_loss = 1.04728568, grad/param norm = 1.5477e-01, time/batch = 18.0712s	
13059/33650 (epoch 19.404), train_loss = 0.99630785, grad/param norm = 1.4580e-01, time/batch = 16.7168s	
13060/33650 (epoch 19.406), train_loss = 1.01488845, grad/param norm = 1.4556e-01, time/batch = 18.2182s	
13061/33650 (epoch 19.407), train_loss = 0.99791607, grad/param norm = 1.4683e-01, time/batch = 18.3833s	
13062/33650 (epoch 19.409), train_loss = 1.03044507, grad/param norm = 1.4315e-01, time/batch = 18.7289s	
13063/33650 (epoch 19.410), train_loss = 0.99205894, grad/param norm = 1.4275e-01, time/batch = 16.7400s	
13064/33650 (epoch 19.412), train_loss = 1.00662740, grad/param norm = 1.3317e-01, time/batch = 17.2287s	
13065/33650 (epoch 19.413), train_loss = 0.93399965, grad/param norm = 1.5761e-01, time/batch = 17.3979s	
13066/33650 (epoch 19.415), train_loss = 1.09170056, grad/param norm = 1.5026e-01, time/batch = 18.3873s	
13067/33650 (epoch 19.416), train_loss = 1.14981590, grad/param norm = 1.4940e-01, time/batch = 17.7154s	
13068/33650 (epoch 19.418), train_loss = 0.96564019, grad/param norm = 1.4441e-01, time/batch = 17.4398s	
13069/33650 (epoch 19.419), train_loss = 0.96469378, grad/param norm = 1.4529e-01, time/batch = 18.7107s	
13070/33650 (epoch 19.421), train_loss = 0.99149313, grad/param norm = 1.2962e-01, time/batch = 17.3996s	
13071/33650 (epoch 19.422), train_loss = 1.10054878, grad/param norm = 1.4359e-01, time/batch = 17.0579s	
13072/33650 (epoch 19.423), train_loss = 0.90991554, grad/param norm = 1.1824e-01, time/batch = 18.9722s	
13073/33650 (epoch 19.425), train_loss = 1.02192575, grad/param norm = 1.4868e-01, time/batch = 18.3982s	
13074/33650 (epoch 19.426), train_loss = 1.15365959, grad/param norm = 1.6030e-01, time/batch = 29.1245s	
13075/33650 (epoch 19.428), train_loss = 0.93089730, grad/param norm = 1.2938e-01, time/batch = 19.2141s	
13076/33650 (epoch 19.429), train_loss = 1.08055769, grad/param norm = 1.4435e-01, time/batch = 17.6260s	
13077/33650 (epoch 19.431), train_loss = 1.16544205, grad/param norm = 1.6196e-01, time/batch = 17.0513s	
13078/33650 (epoch 19.432), train_loss = 1.21323961, grad/param norm = 1.7052e-01, time/batch = 18.8119s	
13079/33650 (epoch 19.434), train_loss = 1.02242458, grad/param norm = 1.3889e-01, time/batch = 18.0591s	
13080/33650 (epoch 19.435), train_loss = 1.00178531, grad/param norm = 1.7926e-01, time/batch = 16.9018s	
13081/33650 (epoch 19.437), train_loss = 1.02269998, grad/param norm = 1.4931e-01, time/batch = 17.3242s	
13082/33650 (epoch 19.438), train_loss = 0.96231119, grad/param norm = 1.6265e-01, time/batch = 18.3958s	
13083/33650 (epoch 19.440), train_loss = 1.02030380, grad/param norm = 1.6696e-01, time/batch = 17.6432s	
13084/33650 (epoch 19.441), train_loss = 1.03019048, grad/param norm = 1.6617e-01, time/batch = 18.1466s	
13085/33650 (epoch 19.443), train_loss = 1.06535936, grad/param norm = 1.4054e-01, time/batch = 18.0593s	
13086/33650 (epoch 19.444), train_loss = 0.97528891, grad/param norm = 1.4695e-01, time/batch = 17.1579s	
13087/33650 (epoch 19.446), train_loss = 1.06370648, grad/param norm = 1.6699e-01, time/batch = 17.2224s	
13088/33650 (epoch 19.447), train_loss = 1.11908727, grad/param norm = 1.6293e-01, time/batch = 15.4710s	
13089/33650 (epoch 19.449), train_loss = 1.17125471, grad/param norm = 1.8286e-01, time/batch = 18.1375s	
13090/33650 (epoch 19.450), train_loss = 1.19648154, grad/param norm = 1.6331e-01, time/batch = 17.2214s	
13091/33650 (epoch 19.452), train_loss = 1.20302073, grad/param norm = 1.8939e-01, time/batch = 17.6485s	
13092/33650 (epoch 19.453), train_loss = 1.19479103, grad/param norm = 2.2602e-01, time/batch = 18.4014s	
13093/33650 (epoch 19.455), train_loss = 0.98559415, grad/param norm = 1.4630e-01, time/batch = 17.3916s	
13094/33650 (epoch 19.456), train_loss = 1.01460545, grad/param norm = 1.4388e-01, time/batch = 17.4857s	
13095/33650 (epoch 19.458), train_loss = 1.01217493, grad/param norm = 1.6692e-01, time/batch = 17.0463s	
13096/33650 (epoch 19.459), train_loss = 1.05361019, grad/param norm = 1.8208e-01, time/batch = 16.9768s	
13097/33650 (epoch 19.461), train_loss = 1.19023739, grad/param norm = 1.7793e-01, time/batch = 17.1470s	
13098/33650 (epoch 19.462), train_loss = 1.13428903, grad/param norm = 1.6275e-01, time/batch = 17.6450s	
13099/33650 (epoch 19.464), train_loss = 0.98003128, grad/param norm = 1.6874e-01, time/batch = 17.6232s	
13100/33650 (epoch 19.465), train_loss = 1.04799064, grad/param norm = 1.6072e-01, time/batch = 17.8112s	
13101/33650 (epoch 19.467), train_loss = 1.08179276, grad/param norm = 1.5785e-01, time/batch = 17.2232s	
13102/33650 (epoch 19.468), train_loss = 1.14843530, grad/param norm = 1.5285e-01, time/batch = 17.8698s	
13103/33650 (epoch 19.470), train_loss = 1.25469269, grad/param norm = 1.8529e-01, time/batch = 16.2268s	
13104/33650 (epoch 19.471), train_loss = 1.01376634, grad/param norm = 1.5385e-01, time/batch = 16.3232s	
13105/33650 (epoch 19.473), train_loss = 0.99144260, grad/param norm = 1.4640e-01, time/batch = 18.6522s	
13106/33650 (epoch 19.474), train_loss = 1.10847811, grad/param norm = 1.4342e-01, time/batch = 16.7094s	
13107/33650 (epoch 19.475), train_loss = 1.08055709, grad/param norm = 1.4918e-01, time/batch = 16.4776s	
13108/33650 (epoch 19.477), train_loss = 1.14589872, grad/param norm = 1.4682e-01, time/batch = 18.0663s	
13109/33650 (epoch 19.478), train_loss = 1.13430765, grad/param norm = 1.6153e-01, time/batch = 18.2288s	
13110/33650 (epoch 19.480), train_loss = 1.11658707, grad/param norm = 1.6741e-01, time/batch = 17.1392s	
13111/33650 (epoch 19.481), train_loss = 1.19809733, grad/param norm = 1.6212e-01, time/batch = 17.7893s	
13112/33650 (epoch 19.483), train_loss = 0.84536220, grad/param norm = 1.3975e-01, time/batch = 18.2399s	
13113/33650 (epoch 19.484), train_loss = 1.01829548, grad/param norm = 1.5663e-01, time/batch = 18.1441s	
13114/33650 (epoch 19.486), train_loss = 1.15669654, grad/param norm = 1.6057e-01, time/batch = 17.4661s	
13115/33650 (epoch 19.487), train_loss = 1.17960443, grad/param norm = 1.6711e-01, time/batch = 18.2275s	
13116/33650 (epoch 19.489), train_loss = 1.17654720, grad/param norm = 1.4731e-01, time/batch = 18.3859s	
13117/33650 (epoch 19.490), train_loss = 0.92090618, grad/param norm = 1.3989e-01, time/batch = 16.7841s	
13118/33650 (epoch 19.492), train_loss = 1.06198712, grad/param norm = 1.6360e-01, time/batch = 16.7382s	
13119/33650 (epoch 19.493), train_loss = 0.87248886, grad/param norm = 1.3682e-01, time/batch = 18.6502s	
13120/33650 (epoch 19.495), train_loss = 1.04314522, grad/param norm = 1.5037e-01, time/batch = 18.3973s	
13121/33650 (epoch 19.496), train_loss = 1.08193267, grad/param norm = 1.4678e-01, time/batch = 16.7909s	
13122/33650 (epoch 19.498), train_loss = 0.93300154, grad/param norm = 1.4126e-01, time/batch = 17.9037s	
13123/33650 (epoch 19.499), train_loss = 1.01222295, grad/param norm = 1.2455e-01, time/batch = 15.7217s	
13124/33650 (epoch 19.501), train_loss = 1.01393238, grad/param norm = 1.3776e-01, time/batch = 17.5562s	
13125/33650 (epoch 19.502), train_loss = 1.04020301, grad/param norm = 1.5809e-01, time/batch = 17.9711s	
13126/33650 (epoch 19.504), train_loss = 1.12238814, grad/param norm = 1.6665e-01, time/batch = 17.8151s	
13127/33650 (epoch 19.505), train_loss = 0.98199554, grad/param norm = 1.7592e-01, time/batch = 18.4009s	
13128/33650 (epoch 19.507), train_loss = 1.15000102, grad/param norm = 1.5730e-01, time/batch = 17.3905s	
13129/33650 (epoch 19.508), train_loss = 0.99087033, grad/param norm = 1.4213e-01, time/batch = 17.9718s	
13130/33650 (epoch 19.510), train_loss = 1.01193102, grad/param norm = 1.4991e-01, time/batch = 17.3081s	
13131/33650 (epoch 19.511), train_loss = 1.25348080, grad/param norm = 1.7546e-01, time/batch = 16.3130s	
13132/33650 (epoch 19.513), train_loss = 1.08334274, grad/param norm = 1.4525e-01, time/batch = 18.1524s	
13133/33650 (epoch 19.514), train_loss = 1.10133487, grad/param norm = 1.4728e-01, time/batch = 15.8698s	
13134/33650 (epoch 19.516), train_loss = 1.04057718, grad/param norm = 1.7856e-01, time/batch = 17.8075s	
13135/33650 (epoch 19.517), train_loss = 1.03482847, grad/param norm = 1.4899e-01, time/batch = 17.8900s	
13136/33650 (epoch 19.519), train_loss = 1.10498588, grad/param norm = 1.6028e-01, time/batch = 17.2352s	
13137/33650 (epoch 19.520), train_loss = 0.88028417, grad/param norm = 1.2588e-01, time/batch = 17.4645s	
13138/33650 (epoch 19.522), train_loss = 1.01557458, grad/param norm = 1.5576e-01, time/batch = 16.4663s	
13139/33650 (epoch 19.523), train_loss = 0.97226121, grad/param norm = 1.4567e-01, time/batch = 18.9826s	
13140/33650 (epoch 19.525), train_loss = 0.82007607, grad/param norm = 1.2758e-01, time/batch = 18.3932s	
13141/33650 (epoch 19.526), train_loss = 1.11951813, grad/param norm = 1.4553e-01, time/batch = 17.5546s	
13142/33650 (epoch 19.527), train_loss = 0.96236569, grad/param norm = 1.4278e-01, time/batch = 17.8087s	
13143/33650 (epoch 19.529), train_loss = 1.04213287, grad/param norm = 1.4686e-01, time/batch = 18.5598s	
13144/33650 (epoch 19.530), train_loss = 0.97463934, grad/param norm = 1.4685e-01, time/batch = 17.4807s	
13145/33650 (epoch 19.532), train_loss = 1.15430313, grad/param norm = 1.9433e-01, time/batch = 17.9722s	
13146/33650 (epoch 19.533), train_loss = 1.01176484, grad/param norm = 1.5647e-01, time/batch = 17.5598s	
13147/33650 (epoch 19.535), train_loss = 1.10007808, grad/param norm = 1.4836e-01, time/batch = 17.2142s	
13148/33650 (epoch 19.536), train_loss = 1.05723753, grad/param norm = 1.6243e-01, time/batch = 16.8051s	
13149/33650 (epoch 19.538), train_loss = 1.09811300, grad/param norm = 1.7133e-01, time/batch = 15.3922s	
13150/33650 (epoch 19.539), train_loss = 0.85930846, grad/param norm = 1.5867e-01, time/batch = 17.1492s	
13151/33650 (epoch 19.541), train_loss = 1.16228895, grad/param norm = 1.6387e-01, time/batch = 18.3928s	
13152/33650 (epoch 19.542), train_loss = 1.05993613, grad/param norm = 1.7976e-01, time/batch = 17.2283s	
13153/33650 (epoch 19.544), train_loss = 1.21685045, grad/param norm = 1.8706e-01, time/batch = 18.6510s	
13154/33650 (epoch 19.545), train_loss = 0.90388159, grad/param norm = 1.4683e-01, time/batch = 18.2299s	
13155/33650 (epoch 19.547), train_loss = 1.04809366, grad/param norm = 1.4775e-01, time/batch = 17.1399s	
13156/33650 (epoch 19.548), train_loss = 1.19002002, grad/param norm = 1.5162e-01, time/batch = 17.9915s	
13157/33650 (epoch 19.550), train_loss = 1.03808822, grad/param norm = 1.5414e-01, time/batch = 17.9899s	
13158/33650 (epoch 19.551), train_loss = 1.06026929, grad/param norm = 1.5965e-01, time/batch = 16.5404s	
13159/33650 (epoch 19.553), train_loss = 0.91511235, grad/param norm = 1.5459e-01, time/batch = 16.9748s	
13160/33650 (epoch 19.554), train_loss = 1.17628554, grad/param norm = 1.6482e-01, time/batch = 18.5729s	
13161/33650 (epoch 19.556), train_loss = 1.10875597, grad/param norm = 1.7150e-01, time/batch = 18.0676s	
13162/33650 (epoch 19.557), train_loss = 1.13572383, grad/param norm = 1.8023e-01, time/batch = 17.7165s	
13163/33650 (epoch 19.559), train_loss = 1.29737571, grad/param norm = 1.9386e-01, time/batch = 17.9029s	
13164/33650 (epoch 19.560), train_loss = 1.23757791, grad/param norm = 1.5719e-01, time/batch = 16.6320s	
13165/33650 (epoch 19.562), train_loss = 1.13083549, grad/param norm = 1.4494e-01, time/batch = 17.1419s	
13166/33650 (epoch 19.563), train_loss = 1.06459017, grad/param norm = 1.4738e-01, time/batch = 17.3208s	
13167/33650 (epoch 19.565), train_loss = 1.03816562, grad/param norm = 1.4863e-01, time/batch = 18.3205s	
13168/33650 (epoch 19.566), train_loss = 1.01869128, grad/param norm = 1.5508e-01, time/batch = 17.9852s	
13169/33650 (epoch 19.568), train_loss = 1.08667865, grad/param norm = 1.8916e-01, time/batch = 16.8170s	
13170/33650 (epoch 19.569), train_loss = 0.97226467, grad/param norm = 1.3903e-01, time/batch = 18.0603s	
13171/33650 (epoch 19.571), train_loss = 1.15835960, grad/param norm = 1.6190e-01, time/batch = 18.0634s	
13172/33650 (epoch 19.572), train_loss = 1.10248086, grad/param norm = 1.4052e-01, time/batch = 17.0641s	
13173/33650 (epoch 19.574), train_loss = 1.00846144, grad/param norm = 1.8249e-01, time/batch = 17.9828s	
13174/33650 (epoch 19.575), train_loss = 1.01865346, grad/param norm = 1.5062e-01, time/batch = 16.8113s	
13175/33650 (epoch 19.577), train_loss = 1.00957061, grad/param norm = 1.5371e-01, time/batch = 14.8443s	
13176/33650 (epoch 19.578), train_loss = 1.10630733, grad/param norm = 1.5588e-01, time/batch = 17.5560s	
13177/33650 (epoch 19.579), train_loss = 1.08913277, grad/param norm = 1.5402e-01, time/batch = 17.6497s	
13178/33650 (epoch 19.581), train_loss = 1.16213356, grad/param norm = 1.5529e-01, time/batch = 15.8357s	
13179/33650 (epoch 19.582), train_loss = 1.09692245, grad/param norm = 1.3619e-01, time/batch = 16.4707s	
13180/33650 (epoch 19.584), train_loss = 1.09878635, grad/param norm = 1.6167e-01, time/batch = 17.2999s	
13181/33650 (epoch 19.585), train_loss = 1.09310002, grad/param norm = 1.5564e-01, time/batch = 16.2232s	
13182/33650 (epoch 19.587), train_loss = 0.95256208, grad/param norm = 1.4095e-01, time/batch = 16.8247s	
13183/33650 (epoch 19.588), train_loss = 0.99328240, grad/param norm = 1.8599e-01, time/batch = 15.6361s	
13184/33650 (epoch 19.590), train_loss = 0.98003672, grad/param norm = 1.3148e-01, time/batch = 16.9089s	
13185/33650 (epoch 19.591), train_loss = 0.97429173, grad/param norm = 1.6464e-01, time/batch = 17.3958s	
13186/33650 (epoch 19.593), train_loss = 0.95285759, grad/param norm = 1.4155e-01, time/batch = 16.0712s	
13187/33650 (epoch 19.594), train_loss = 0.92354402, grad/param norm = 1.5051e-01, time/batch = 17.6444s	
13188/33650 (epoch 19.596), train_loss = 1.03388681, grad/param norm = 1.4097e-01, time/batch = 17.8069s	
13189/33650 (epoch 19.597), train_loss = 0.87169851, grad/param norm = 1.2768e-01, time/batch = 17.3091s	
13190/33650 (epoch 19.599), train_loss = 1.00857912, grad/param norm = 1.5332e-01, time/batch = 14.8114s	
13191/33650 (epoch 19.600), train_loss = 0.95399971, grad/param norm = 1.4571e-01, time/batch = 17.3173s	
13192/33650 (epoch 19.602), train_loss = 1.07540615, grad/param norm = 1.4441e-01, time/batch = 17.4027s	
13193/33650 (epoch 19.603), train_loss = 0.98826053, grad/param norm = 1.5406e-01, time/batch = 16.7986s	
13194/33650 (epoch 19.605), train_loss = 1.09139472, grad/param norm = 1.5479e-01, time/batch = 16.3878s	
13195/33650 (epoch 19.606), train_loss = 1.09579009, grad/param norm = 1.7079e-01, time/batch = 16.4097s	
13196/33650 (epoch 19.608), train_loss = 0.96202752, grad/param norm = 1.5453e-01, time/batch = 17.5469s	
13197/33650 (epoch 19.609), train_loss = 1.03004259, grad/param norm = 1.4436e-01, time/batch = 15.3962s	
13198/33650 (epoch 19.611), train_loss = 0.92583874, grad/param norm = 1.4673e-01, time/batch = 16.5741s	
13199/33650 (epoch 19.612), train_loss = 1.02793454, grad/param norm = 1.6161e-01, time/batch = 17.2293s	
13200/33650 (epoch 19.614), train_loss = 1.11688593, grad/param norm = 1.5716e-01, time/batch = 17.4053s	
13201/33650 (epoch 19.615), train_loss = 1.00813507, grad/param norm = 1.3699e-01, time/batch = 16.9707s	
13202/33650 (epoch 19.617), train_loss = 0.93418239, grad/param norm = 1.3250e-01, time/batch = 17.0661s	
13203/33650 (epoch 19.618), train_loss = 1.00248539, grad/param norm = 1.4163e-01, time/batch = 16.3900s	
13204/33650 (epoch 19.620), train_loss = 1.05470480, grad/param norm = 1.6781e-01, time/batch = 16.0598s	
13205/33650 (epoch 19.621), train_loss = 0.91783125, grad/param norm = 1.4172e-01, time/batch = 17.5614s	
13206/33650 (epoch 19.623), train_loss = 1.01720240, grad/param norm = 1.5339e-01, time/batch = 16.6690s	
13207/33650 (epoch 19.624), train_loss = 0.82026396, grad/param norm = 1.4185e-01, time/batch = 16.9887s	
13208/33650 (epoch 19.626), train_loss = 0.80621257, grad/param norm = 1.2403e-01, time/batch = 16.9779s	
13209/33650 (epoch 19.627), train_loss = 0.93743766, grad/param norm = 1.5322e-01, time/batch = 17.6509s	
13210/33650 (epoch 19.629), train_loss = 0.98491467, grad/param norm = 1.4380e-01, time/batch = 15.6456s	
13211/33650 (epoch 19.630), train_loss = 1.10379475, grad/param norm = 1.5853e-01, time/batch = 15.7219s	
13212/33650 (epoch 19.632), train_loss = 1.14665304, grad/param norm = 1.5062e-01, time/batch = 17.5772s	
13213/33650 (epoch 19.633), train_loss = 1.11677797, grad/param norm = 1.4876e-01, time/batch = 15.6146s	
13214/33650 (epoch 19.634), train_loss = 0.88775714, grad/param norm = 1.3302e-01, time/batch = 17.2227s	
13215/33650 (epoch 19.636), train_loss = 0.77556110, grad/param norm = 1.1435e-01, time/batch = 17.4755s	
13216/33650 (epoch 19.637), train_loss = 0.94937624, grad/param norm = 1.4083e-01, time/batch = 17.4910s	
13217/33650 (epoch 19.639), train_loss = 0.94606850, grad/param norm = 1.3860e-01, time/batch = 16.5727s	
13218/33650 (epoch 19.640), train_loss = 1.02770520, grad/param norm = 1.5577e-01, time/batch = 16.4815s	
13219/33650 (epoch 19.642), train_loss = 1.09257152, grad/param norm = 1.7140e-01, time/batch = 17.4844s	
13220/33650 (epoch 19.643), train_loss = 1.03507193, grad/param norm = 1.5475e-01, time/batch = 17.8165s	
13221/33650 (epoch 19.645), train_loss = 1.02086381, grad/param norm = 1.3930e-01, time/batch = 16.7332s	
13222/33650 (epoch 19.646), train_loss = 0.86522679, grad/param norm = 1.2172e-01, time/batch = 17.1495s	
13223/33650 (epoch 19.648), train_loss = 1.03215969, grad/param norm = 1.3918e-01, time/batch = 17.9835s	
13224/33650 (epoch 19.649), train_loss = 0.97286087, grad/param norm = 1.5037e-01, time/batch = 17.4063s	
13225/33650 (epoch 19.651), train_loss = 1.15703676, grad/param norm = 1.7312e-01, time/batch = 16.0767s	
13226/33650 (epoch 19.652), train_loss = 0.73346038, grad/param norm = 1.2141e-01, time/batch = 17.1513s	
13227/33650 (epoch 19.654), train_loss = 0.92842765, grad/param norm = 1.4803e-01, time/batch = 17.8258s	
13228/33650 (epoch 19.655), train_loss = 0.88618860, grad/param norm = 1.2224e-01, time/batch = 16.3136s	
13229/33650 (epoch 19.657), train_loss = 0.96979583, grad/param norm = 1.4493e-01, time/batch = 16.6573s	
13230/33650 (epoch 19.658), train_loss = 0.86181411, grad/param norm = 1.3702e-01, time/batch = 16.7479s	
13231/33650 (epoch 19.660), train_loss = 0.83047842, grad/param norm = 1.5089e-01, time/batch = 16.9784s	
13232/33650 (epoch 19.661), train_loss = 0.93431779, grad/param norm = 1.2847e-01, time/batch = 16.2960s	
13233/33650 (epoch 19.663), train_loss = 0.89377942, grad/param norm = 1.6751e-01, time/batch = 16.6611s	
13234/33650 (epoch 19.664), train_loss = 0.91596396, grad/param norm = 1.2709e-01, time/batch = 17.9001s	
13235/33650 (epoch 19.666), train_loss = 0.94529268, grad/param norm = 1.2698e-01, time/batch = 17.0546s	
13236/33650 (epoch 19.667), train_loss = 0.88333063, grad/param norm = 1.2884e-01, time/batch = 17.3184s	
13237/33650 (epoch 19.669), train_loss = 0.90500050, grad/param norm = 1.4587e-01, time/batch = 17.6567s	
13238/33650 (epoch 19.670), train_loss = 0.81963437, grad/param norm = 1.4756e-01, time/batch = 15.4639s	
13239/33650 (epoch 19.672), train_loss = 0.85647423, grad/param norm = 1.3886e-01, time/batch = 16.9001s	
13240/33650 (epoch 19.673), train_loss = 0.82044897, grad/param norm = 1.4300e-01, time/batch = 17.2365s	
13241/33650 (epoch 19.675), train_loss = 0.79671393, grad/param norm = 1.1504e-01, time/batch = 15.7290s	
13242/33650 (epoch 19.676), train_loss = 0.97825053, grad/param norm = 1.5026e-01, time/batch = 16.7337s	
13243/33650 (epoch 19.678), train_loss = 0.92766126, grad/param norm = 1.4779e-01, time/batch = 17.3012s	
13244/33650 (epoch 19.679), train_loss = 0.93789386, grad/param norm = 1.4675e-01, time/batch = 17.2353s	
13245/33650 (epoch 19.681), train_loss = 0.94458717, grad/param norm = 1.2710e-01, time/batch = 18.1528s	
13246/33650 (epoch 19.682), train_loss = 0.88772616, grad/param norm = 1.4379e-01, time/batch = 16.3962s	
13247/33650 (epoch 19.684), train_loss = 0.87860845, grad/param norm = 1.4293e-01, time/batch = 16.4022s	
13248/33650 (epoch 19.685), train_loss = 1.05298255, grad/param norm = 1.4792e-01, time/batch = 17.6408s	
13249/33650 (epoch 19.686), train_loss = 1.01020644, grad/param norm = 1.4631e-01, time/batch = 16.8208s	
13250/33650 (epoch 19.688), train_loss = 1.09011976, grad/param norm = 1.5426e-01, time/batch = 14.9594s	
13251/33650 (epoch 19.689), train_loss = 0.89724607, grad/param norm = 1.3870e-01, time/batch = 17.5672s	
13252/33650 (epoch 19.691), train_loss = 1.10363017, grad/param norm = 1.6447e-01, time/batch = 16.2315s	
13253/33650 (epoch 19.692), train_loss = 1.10758092, grad/param norm = 1.4303e-01, time/batch = 16.5635s	
13254/33650 (epoch 19.694), train_loss = 1.00997632, grad/param norm = 1.5142e-01, time/batch = 17.5628s	
13255/33650 (epoch 19.695), train_loss = 0.72998921, grad/param norm = 1.3005e-01, time/batch = 17.0646s	
13256/33650 (epoch 19.697), train_loss = 0.95917710, grad/param norm = 1.4526e-01, time/batch = 17.4908s	
13257/33650 (epoch 19.698), train_loss = 1.14489229, grad/param norm = 1.5723e-01, time/batch = 16.6203s	
13258/33650 (epoch 19.700), train_loss = 0.96198259, grad/param norm = 1.3629e-01, time/batch = 18.0689s	
13259/33650 (epoch 19.701), train_loss = 1.00823378, grad/param norm = 1.4254e-01, time/batch = 17.6377s	
13260/33650 (epoch 19.703), train_loss = 1.14992290, grad/param norm = 1.4144e-01, time/batch = 15.5513s	
13261/33650 (epoch 19.704), train_loss = 0.96222878, grad/param norm = 1.3691e-01, time/batch = 17.8154s	
13262/33650 (epoch 19.706), train_loss = 0.94389278, grad/param norm = 1.3634e-01, time/batch = 17.4873s	
13263/33650 (epoch 19.707), train_loss = 1.09549035, grad/param norm = 1.4600e-01, time/batch = 17.3301s	
13264/33650 (epoch 19.709), train_loss = 0.96536893, grad/param norm = 1.4094e-01, time/batch = 16.5570s	
13265/33650 (epoch 19.710), train_loss = 1.17061186, grad/param norm = 1.6854e-01, time/batch = 17.7484s	
13266/33650 (epoch 19.712), train_loss = 0.90593080, grad/param norm = 1.4836e-01, time/batch = 18.3112s	
13267/33650 (epoch 19.713), train_loss = 0.90167920, grad/param norm = 1.8204e-01, time/batch = 16.2371s	
13268/33650 (epoch 19.715), train_loss = 1.07505548, grad/param norm = 1.7175e-01, time/batch = 17.4052s	
13269/33650 (epoch 19.716), train_loss = 0.90126555, grad/param norm = 1.3355e-01, time/batch = 17.5664s	
13270/33650 (epoch 19.718), train_loss = 0.94294505, grad/param norm = 1.5520e-01, time/batch = 16.8739s	
13271/33650 (epoch 19.719), train_loss = 1.10684541, grad/param norm = 1.5489e-01, time/batch = 16.6566s	
13272/33650 (epoch 19.721), train_loss = 1.20898418, grad/param norm = 1.6724e-01, time/batch = 16.7335s	
13273/33650 (epoch 19.722), train_loss = 1.07125219, grad/param norm = 1.6934e-01, time/batch = 16.2364s	
13274/33650 (epoch 19.724), train_loss = 1.10449803, grad/param norm = 1.6431e-01, time/batch = 16.7356s	
13275/33650 (epoch 19.725), train_loss = 1.09979361, grad/param norm = 1.6048e-01, time/batch = 17.1520s	
13276/33650 (epoch 19.727), train_loss = 0.91396192, grad/param norm = 1.4581e-01, time/batch = 17.7158s	
13277/33650 (epoch 19.728), train_loss = 0.95657990, grad/param norm = 1.3861e-01, time/batch = 17.0499s	
13278/33650 (epoch 19.730), train_loss = 1.03916966, grad/param norm = 1.5249e-01, time/batch = 16.7376s	
13279/33650 (epoch 19.731), train_loss = 1.13120365, grad/param norm = 1.5299e-01, time/batch = 16.5762s	
13280/33650 (epoch 19.733), train_loss = 0.99614702, grad/param norm = 1.4911e-01, time/batch = 17.6540s	
13281/33650 (epoch 19.734), train_loss = 1.13313555, grad/param norm = 1.8100e-01, time/batch = 25.3790s	
13282/33650 (epoch 19.736), train_loss = 1.01231503, grad/param norm = 1.6583e-01, time/batch = 22.1178s	
13283/33650 (epoch 19.737), train_loss = 1.05605347, grad/param norm = 1.8245e-01, time/batch = 16.4682s	
13284/33650 (epoch 19.738), train_loss = 0.89315859, grad/param norm = 1.4569e-01, time/batch = 15.8006s	
13285/33650 (epoch 19.740), train_loss = 0.85591991, grad/param norm = 1.4600e-01, time/batch = 17.3172s	
13286/33650 (epoch 19.741), train_loss = 0.91350807, grad/param norm = 1.4426e-01, time/batch = 16.8892s	
13287/33650 (epoch 19.743), train_loss = 0.99160113, grad/param norm = 1.4551e-01, time/batch = 17.2278s	
13288/33650 (epoch 19.744), train_loss = 1.03299656, grad/param norm = 1.3402e-01, time/batch = 15.4738s	
13289/33650 (epoch 19.746), train_loss = 0.97922131, grad/param norm = 1.3641e-01, time/batch = 17.3254s	
13290/33650 (epoch 19.747), train_loss = 1.11229670, grad/param norm = 1.4888e-01, time/batch = 16.9056s	
13291/33650 (epoch 19.749), train_loss = 0.83662949, grad/param norm = 1.3456e-01, time/batch = 16.8195s	
13292/33650 (epoch 19.750), train_loss = 1.11831041, grad/param norm = 1.4422e-01, time/batch = 17.7337s	
13293/33650 (epoch 19.752), train_loss = 1.10830664, grad/param norm = 1.4769e-01, time/batch = 17.8206s	
13294/33650 (epoch 19.753), train_loss = 1.19533456, grad/param norm = 1.5411e-01, time/batch = 16.0589s	
13295/33650 (epoch 19.755), train_loss = 0.97519487, grad/param norm = 1.4866e-01, time/batch = 17.0720s	
13296/33650 (epoch 19.756), train_loss = 1.07648138, grad/param norm = 1.5171e-01, time/batch = 17.3290s	
13297/33650 (epoch 19.758), train_loss = 1.06969048, grad/param norm = 1.4297e-01, time/batch = 17.3267s	
13298/33650 (epoch 19.759), train_loss = 1.14081962, grad/param norm = 1.7229e-01, time/batch = 16.7308s	
13299/33650 (epoch 19.761), train_loss = 1.04558968, grad/param norm = 1.5797e-01, time/batch = 17.3312s	
13300/33650 (epoch 19.762), train_loss = 1.01382950, grad/param norm = 1.4872e-01, time/batch = 16.9856s	
13301/33650 (epoch 19.764), train_loss = 1.07757339, grad/param norm = 1.6661e-01, time/batch = 17.0612s	
13302/33650 (epoch 19.765), train_loss = 1.01514756, grad/param norm = 1.5573e-01, time/batch = 17.3265s	
13303/33650 (epoch 19.767), train_loss = 0.99667198, grad/param norm = 1.3446e-01, time/batch = 16.8977s	
13304/33650 (epoch 19.768), train_loss = 0.87564225, grad/param norm = 1.4345e-01, time/batch = 17.1376s	
13305/33650 (epoch 19.770), train_loss = 1.06370223, grad/param norm = 1.5359e-01, time/batch = 16.7239s	
13306/33650 (epoch 19.771), train_loss = 1.02295443, grad/param norm = 1.4961e-01, time/batch = 17.4893s	
13307/33650 (epoch 19.773), train_loss = 1.14563961, grad/param norm = 1.7116e-01, time/batch = 17.9752s	
13308/33650 (epoch 19.774), train_loss = 1.05209735, grad/param norm = 1.7165e-01, time/batch = 17.0632s	
13309/33650 (epoch 19.776), train_loss = 1.09562386, grad/param norm = 1.6538e-01, time/batch = 15.7209s	
13310/33650 (epoch 19.777), train_loss = 0.90250691, grad/param norm = 1.4050e-01, time/batch = 17.8260s	
13311/33650 (epoch 19.779), train_loss = 0.96794225, grad/param norm = 1.3917e-01, time/batch = 17.8198s	
13312/33650 (epoch 19.780), train_loss = 0.91285640, grad/param norm = 1.3158e-01, time/batch = 16.6423s	
13313/33650 (epoch 19.782), train_loss = 0.93802057, grad/param norm = 1.4222e-01, time/batch = 15.2420s	
13314/33650 (epoch 19.783), train_loss = 0.89865574, grad/param norm = 1.2805e-01, time/batch = 18.0689s	
13315/33650 (epoch 19.785), train_loss = 1.20114011, grad/param norm = 1.4230e-01, time/batch = 16.9075s	
13316/33650 (epoch 19.786), train_loss = 1.05651131, grad/param norm = 1.3799e-01, time/batch = 16.5491s	
13317/33650 (epoch 19.788), train_loss = 1.05355267, grad/param norm = 1.4461e-01, time/batch = 17.1565s	
13318/33650 (epoch 19.789), train_loss = 1.08463088, grad/param norm = 1.5810e-01, time/batch = 18.0790s	
13319/33650 (epoch 19.790), train_loss = 1.04398919, grad/param norm = 1.7173e-01, time/batch = 16.3155s	
13320/33650 (epoch 19.792), train_loss = 1.12409341, grad/param norm = 1.5755e-01, time/batch = 17.8214s	
13321/33650 (epoch 19.793), train_loss = 1.10732079, grad/param norm = 1.9739e-01, time/batch = 16.8178s	
13322/33650 (epoch 19.795), train_loss = 1.14436837, grad/param norm = 1.4684e-01, time/batch = 17.4013s	
13323/33650 (epoch 19.796), train_loss = 0.99947385, grad/param norm = 1.6987e-01, time/batch = 17.4762s	
13324/33650 (epoch 19.798), train_loss = 0.97622484, grad/param norm = 1.4463e-01, time/batch = 17.8290s	
13325/33650 (epoch 19.799), train_loss = 1.01408688, grad/param norm = 1.3167e-01, time/batch = 18.3141s	
13326/33650 (epoch 19.801), train_loss = 1.04658482, grad/param norm = 1.7308e-01, time/batch = 15.0642s	
13327/33650 (epoch 19.802), train_loss = 1.12313588, grad/param norm = 1.6237e-01, time/batch = 16.2184s	
13328/33650 (epoch 19.804), train_loss = 1.02734452, grad/param norm = 1.6696e-01, time/batch = 16.8203s	
13329/33650 (epoch 19.805), train_loss = 0.98749777, grad/param norm = 1.2381e-01, time/batch = 17.5614s	
13330/33650 (epoch 19.807), train_loss = 1.21299487, grad/param norm = 1.6423e-01, time/batch = 17.5743s	
13331/33650 (epoch 19.808), train_loss = 1.27651281, grad/param norm = 1.7472e-01, time/batch = 17.4963s	
13332/33650 (epoch 19.810), train_loss = 1.06750200, grad/param norm = 1.5555e-01, time/batch = 17.2390s	
13333/33650 (epoch 19.811), train_loss = 1.04795168, grad/param norm = 1.7239e-01, time/batch = 16.8083s	
13334/33650 (epoch 19.813), train_loss = 0.97144368, grad/param norm = 1.4165e-01, time/batch = 17.0600s	
13335/33650 (epoch 19.814), train_loss = 1.10409817, grad/param norm = 1.5320e-01, time/batch = 17.5789s	
13336/33650 (epoch 19.816), train_loss = 1.08772572, grad/param norm = 1.4995e-01, time/batch = 16.9071s	
13337/33650 (epoch 19.817), train_loss = 1.11128318, grad/param norm = 1.6275e-01, time/batch = 17.7282s	
13338/33650 (epoch 19.819), train_loss = 1.07499656, grad/param norm = 1.5512e-01, time/batch = 18.0751s	
13339/33650 (epoch 19.820), train_loss = 1.15634453, grad/param norm = 1.5212e-01, time/batch = 16.9067s	
13340/33650 (epoch 19.822), train_loss = 1.06549159, grad/param norm = 1.6348e-01, time/batch = 17.4673s	
13341/33650 (epoch 19.823), train_loss = 0.96918869, grad/param norm = 1.7123e-01, time/batch = 16.5540s	
13342/33650 (epoch 19.825), train_loss = 1.02094778, grad/param norm = 1.4537e-01, time/batch = 16.5685s	
13343/33650 (epoch 19.826), train_loss = 1.09071277, grad/param norm = 1.4500e-01, time/batch = 16.1533s	
13344/33650 (epoch 19.828), train_loss = 1.20937353, grad/param norm = 1.7482e-01, time/batch = 17.3863s	
13345/33650 (epoch 19.829), train_loss = 0.87776260, grad/param norm = 1.4352e-01, time/batch = 16.9684s	
13346/33650 (epoch 19.831), train_loss = 1.10198937, grad/param norm = 1.4738e-01, time/batch = 17.4002s	
13347/33650 (epoch 19.832), train_loss = 1.10370895, grad/param norm = 1.6267e-01, time/batch = 17.1208s	
13348/33650 (epoch 19.834), train_loss = 1.10149360, grad/param norm = 1.5251e-01, time/batch = 17.5672s	
13349/33650 (epoch 19.835), train_loss = 1.27744584, grad/param norm = 1.6877e-01, time/batch = 17.9778s	
13350/33650 (epoch 19.837), train_loss = 1.07477342, grad/param norm = 1.7227e-01, time/batch = 14.8805s	
13351/33650 (epoch 19.838), train_loss = 1.03351119, grad/param norm = 1.5813e-01, time/batch = 17.9843s	
13352/33650 (epoch 19.840), train_loss = 1.10405815, grad/param norm = 1.4246e-01, time/batch = 17.7331s	
13353/33650 (epoch 19.841), train_loss = 0.96235448, grad/param norm = 1.4453e-01, time/batch = 17.8265s	
13354/33650 (epoch 19.842), train_loss = 1.01650937, grad/param norm = 1.4566e-01, time/batch = 16.2178s	
13355/33650 (epoch 19.844), train_loss = 1.16816246, grad/param norm = 1.5114e-01, time/batch = 17.1549s	
13356/33650 (epoch 19.845), train_loss = 0.97834587, grad/param norm = 1.4740e-01, time/batch = 17.2266s	
13357/33650 (epoch 19.847), train_loss = 0.78734706, grad/param norm = 1.2882e-01, time/batch = 16.2261s	
13358/33650 (epoch 19.848), train_loss = 0.88106691, grad/param norm = 1.4161e-01, time/batch = 16.4513s	
13359/33650 (epoch 19.850), train_loss = 0.99720000, grad/param norm = 1.6593e-01, time/batch = 15.8986s	
13360/33650 (epoch 19.851), train_loss = 0.82250194, grad/param norm = 1.1316e-01, time/batch = 17.2424s	
13361/33650 (epoch 19.853), train_loss = 1.01736215, grad/param norm = 1.7176e-01, time/batch = 16.1464s	
13362/33650 (epoch 19.854), train_loss = 1.13529809, grad/param norm = 1.6507e-01, time/batch = 18.0662s	
13363/33650 (epoch 19.856), train_loss = 0.78492222, grad/param norm = 1.3238e-01, time/batch = 17.0746s	
13364/33650 (epoch 19.857), train_loss = 1.02295415, grad/param norm = 1.3128e-01, time/batch = 17.0711s	
13365/33650 (epoch 19.859), train_loss = 0.91269962, grad/param norm = 1.3579e-01, time/batch = 16.9868s	
13366/33650 (epoch 19.860), train_loss = 0.85088449, grad/param norm = 1.3388e-01, time/batch = 18.1569s	
13367/33650 (epoch 19.862), train_loss = 0.91756050, grad/param norm = 1.4495e-01, time/batch = 17.8172s	
13368/33650 (epoch 19.863), train_loss = 1.14847414, grad/param norm = 1.5095e-01, time/batch = 16.1350s	
13369/33650 (epoch 19.865), train_loss = 0.97204318, grad/param norm = 1.3182e-01, time/batch = 17.4939s	
13370/33650 (epoch 19.866), train_loss = 0.90064348, grad/param norm = 1.3267e-01, time/batch = 17.0686s	
13371/33650 (epoch 19.868), train_loss = 0.87871707, grad/param norm = 1.4155e-01, time/batch = 17.5608s	
13372/33650 (epoch 19.869), train_loss = 1.11329924, grad/param norm = 1.5187e-01, time/batch = 16.4772s	
13373/33650 (epoch 19.871), train_loss = 0.88884478, grad/param norm = 1.2629e-01, time/batch = 17.6593s	
13374/33650 (epoch 19.872), train_loss = 1.02749148, grad/param norm = 1.5523e-01, time/batch = 15.1336s	
13375/33650 (epoch 19.874), train_loss = 1.08795499, grad/param norm = 1.6664e-01, time/batch = 16.7257s	
13376/33650 (epoch 19.875), train_loss = 0.98552308, grad/param norm = 1.4023e-01, time/batch = 17.4966s	
13377/33650 (epoch 19.877), train_loss = 1.19925999, grad/param norm = 1.5824e-01, time/batch = 17.6586s	
13378/33650 (epoch 19.878), train_loss = 0.70405636, grad/param norm = 1.4077e-01, time/batch = 16.0611s	
13379/33650 (epoch 19.880), train_loss = 1.04468222, grad/param norm = 1.5445e-01, time/batch = 15.9008s	
13380/33650 (epoch 19.881), train_loss = 0.96520619, grad/param norm = 1.6151e-01, time/batch = 17.3193s	
13381/33650 (epoch 19.883), train_loss = 1.04249319, grad/param norm = 1.4835e-01, time/batch = 17.2522s	
13382/33650 (epoch 19.884), train_loss = 1.11897873, grad/param norm = 1.5044e-01, time/batch = 15.8213s	
13383/33650 (epoch 19.886), train_loss = 1.09551880, grad/param norm = 1.4529e-01, time/batch = 17.3283s	
13384/33650 (epoch 19.887), train_loss = 0.92751032, grad/param norm = 1.2543e-01, time/batch = 17.9870s	
13385/33650 (epoch 19.889), train_loss = 1.02764091, grad/param norm = 1.5902e-01, time/batch = 16.1385s	
13386/33650 (epoch 19.890), train_loss = 1.06290329, grad/param norm = 1.4409e-01, time/batch = 16.9885s	
13387/33650 (epoch 19.892), train_loss = 1.00809692, grad/param norm = 1.6694e-01, time/batch = 17.4931s	
13388/33650 (epoch 19.893), train_loss = 1.05771579, grad/param norm = 1.4885e-01, time/batch = 18.2458s	
13389/33650 (epoch 19.895), train_loss = 1.13814137, grad/param norm = 1.5371e-01, time/batch = 15.9770s	
13390/33650 (epoch 19.896), train_loss = 0.93780475, grad/param norm = 1.4196e-01, time/batch = 17.4817s	
13391/33650 (epoch 19.897), train_loss = 0.85007571, grad/param norm = 1.2924e-01, time/batch = 17.6533s	
13392/33650 (epoch 19.899), train_loss = 0.89623473, grad/param norm = 1.2758e-01, time/batch = 16.9781s	
13393/33650 (epoch 19.900), train_loss = 0.83040797, grad/param norm = 1.2720e-01, time/batch = 16.9836s	
13394/33650 (epoch 19.902), train_loss = 1.02717426, grad/param norm = 1.6309e-01, time/batch = 17.4851s	
13395/33650 (epoch 19.903), train_loss = 0.99241935, grad/param norm = 1.6497e-01, time/batch = 16.1301s	
13396/33650 (epoch 19.905), train_loss = 1.15890895, grad/param norm = 1.8681e-01, time/batch = 16.2330s	
13397/33650 (epoch 19.906), train_loss = 0.94327126, grad/param norm = 1.4015e-01, time/batch = 16.3163s	
13398/33650 (epoch 19.908), train_loss = 0.97679340, grad/param norm = 1.3854e-01, time/batch = 15.5475s	
13399/33650 (epoch 19.909), train_loss = 0.95988180, grad/param norm = 1.3131e-01, time/batch = 17.3973s	
13400/33650 (epoch 19.911), train_loss = 0.83094853, grad/param norm = 1.2479e-01, time/batch = 16.8866s	
13401/33650 (epoch 19.912), train_loss = 0.83160611, grad/param norm = 1.2629e-01, time/batch = 16.7364s	
13402/33650 (epoch 19.914), train_loss = 1.00909121, grad/param norm = 1.3303e-01, time/batch = 17.5709s	
13403/33650 (epoch 19.915), train_loss = 0.97227507, grad/param norm = 1.4901e-01, time/batch = 16.1475s	
13404/33650 (epoch 19.917), train_loss = 0.96821839, grad/param norm = 1.4039e-01, time/batch = 17.5711s	
13405/33650 (epoch 19.918), train_loss = 0.82287549, grad/param norm = 1.1649e-01, time/batch = 17.1527s	
13406/33650 (epoch 19.920), train_loss = 0.90147096, grad/param norm = 1.2608e-01, time/batch = 17.0797s	
13407/33650 (epoch 19.921), train_loss = 0.91310023, grad/param norm = 1.3735e-01, time/batch = 17.1450s	
13408/33650 (epoch 19.923), train_loss = 0.86952250, grad/param norm = 1.3985e-01, time/batch = 16.5608s	
13409/33650 (epoch 19.924), train_loss = 1.00482033, grad/param norm = 1.4519e-01, time/batch = 16.3202s	
13410/33650 (epoch 19.926), train_loss = 0.94370234, grad/param norm = 1.7236e-01, time/batch = 16.9930s	
13411/33650 (epoch 19.927), train_loss = 0.95315955, grad/param norm = 1.4762e-01, time/batch = 17.3105s	
13412/33650 (epoch 19.929), train_loss = 1.04700286, grad/param norm = 1.4230e-01, time/batch = 17.4814s	
13413/33650 (epoch 19.930), train_loss = 0.94519782, grad/param norm = 1.4496e-01, time/batch = 17.1552s	
13414/33650 (epoch 19.932), train_loss = 0.97980383, grad/param norm = 1.4723e-01, time/batch = 16.8998s	
13415/33650 (epoch 19.933), train_loss = 0.86991823, grad/param norm = 1.4018e-01, time/batch = 18.1432s	
13416/33650 (epoch 19.935), train_loss = 0.88123499, grad/param norm = 1.4412e-01, time/batch = 17.4846s	
13417/33650 (epoch 19.936), train_loss = 0.92632242, grad/param norm = 1.3215e-01, time/batch = 16.4032s	
13418/33650 (epoch 19.938), train_loss = 0.85479748, grad/param norm = 1.3513e-01, time/batch = 15.2249s	
13419/33650 (epoch 19.939), train_loss = 1.04963302, grad/param norm = 1.4424e-01, time/batch = 17.6580s	
13420/33650 (epoch 19.941), train_loss = 1.00698244, grad/param norm = 1.3763e-01, time/batch = 17.4740s	
13421/33650 (epoch 19.942), train_loss = 1.05851707, grad/param norm = 1.5178e-01, time/batch = 17.3069s	
13422/33650 (epoch 19.944), train_loss = 0.97627950, grad/param norm = 1.3654e-01, time/batch = 17.7385s	
13423/33650 (epoch 19.945), train_loss = 1.03801885, grad/param norm = 1.5698e-01, time/batch = 15.9567s	
13424/33650 (epoch 19.947), train_loss = 1.14161733, grad/param norm = 1.9267e-01, time/batch = 14.1329s	
13425/33650 (epoch 19.948), train_loss = 1.14454431, grad/param norm = 1.5284e-01, time/batch = 16.6389s	
13426/33650 (epoch 19.949), train_loss = 0.88065957, grad/param norm = 1.3776e-01, time/batch = 18.1470s	
13427/33650 (epoch 19.951), train_loss = 1.13992597, grad/param norm = 1.4997e-01, time/batch = 17.0692s	
13428/33650 (epoch 19.952), train_loss = 1.08579253, grad/param norm = 1.6774e-01, time/batch = 17.2290s	
13429/33650 (epoch 19.954), train_loss = 1.07508497, grad/param norm = 1.5531e-01, time/batch = 17.7406s	
13430/33650 (epoch 19.955), train_loss = 1.05291037, grad/param norm = 1.4149e-01, time/batch = 16.8056s	
13431/33650 (epoch 19.957), train_loss = 1.04563179, grad/param norm = 1.3995e-01, time/batch = 16.2255s	
13432/33650 (epoch 19.958), train_loss = 0.79683569, grad/param norm = 1.2749e-01, time/batch = 16.4905s	
13433/33650 (epoch 19.960), train_loss = 0.82852194, grad/param norm = 1.2494e-01, time/batch = 17.7213s	
13434/33650 (epoch 19.961), train_loss = 0.89244742, grad/param norm = 1.5058e-01, time/batch = 17.4800s	
13435/33650 (epoch 19.963), train_loss = 0.94909578, grad/param norm = 1.4842e-01, time/batch = 16.6476s	
13436/33650 (epoch 19.964), train_loss = 1.04645380, grad/param norm = 1.5041e-01, time/batch = 17.5712s	
13437/33650 (epoch 19.966), train_loss = 1.01009973, grad/param norm = 1.7555e-01, time/batch = 17.3271s	
13438/33650 (epoch 19.967), train_loss = 1.03601062, grad/param norm = 1.4378e-01, time/batch = 16.3925s	
13439/33650 (epoch 19.969), train_loss = 0.98685318, grad/param norm = 1.3305e-01, time/batch = 17.8251s	
13440/33650 (epoch 19.970), train_loss = 1.04218039, grad/param norm = 1.5566e-01, time/batch = 16.5719s	
13441/33650 (epoch 19.972), train_loss = 1.31525363, grad/param norm = 1.8400e-01, time/batch = 18.2268s	
13442/33650 (epoch 19.973), train_loss = 0.89457097, grad/param norm = 1.2189e-01, time/batch = 16.8028s	
13443/33650 (epoch 19.975), train_loss = 0.89217680, grad/param norm = 1.3586e-01, time/batch = 18.9721s	
13444/33650 (epoch 19.976), train_loss = 0.90381501, grad/param norm = 1.2455e-01, time/batch = 17.7240s	
13445/33650 (epoch 19.978), train_loss = 0.93894205, grad/param norm = 1.4599e-01, time/batch = 16.9770s	
13446/33650 (epoch 19.979), train_loss = 0.97973506, grad/param norm = 1.4426e-01, time/batch = 17.9773s	
13447/33650 (epoch 19.981), train_loss = 0.92860695, grad/param norm = 1.1703e-01, time/batch = 18.1461s	
13448/33650 (epoch 19.982), train_loss = 1.02676934, grad/param norm = 1.4893e-01, time/batch = 16.4736s	
13449/33650 (epoch 19.984), train_loss = 0.82680425, grad/param norm = 1.5374e-01, time/batch = 17.6477s	
13450/33650 (epoch 19.985), train_loss = 0.85843413, grad/param norm = 1.4269e-01, time/batch = 18.7229s	
13451/33650 (epoch 19.987), train_loss = 0.97595244, grad/param norm = 1.3574e-01, time/batch = 16.8005s	
13452/33650 (epoch 19.988), train_loss = 1.01362698, grad/param norm = 1.5287e-01, time/batch = 16.7142s	
13453/33650 (epoch 19.990), train_loss = 1.19311923, grad/param norm = 1.7541e-01, time/batch = 16.9754s	
13454/33650 (epoch 19.991), train_loss = 1.05560851, grad/param norm = 1.5292e-01, time/batch = 18.3209s	
13455/33650 (epoch 19.993), train_loss = 1.02697893, grad/param norm = 1.7602e-01, time/batch = 16.5475s	
13456/33650 (epoch 19.994), train_loss = 0.96399640, grad/param norm = 1.4419e-01, time/batch = 17.2369s	
13457/33650 (epoch 19.996), train_loss = 0.91612597, grad/param norm = 1.4444e-01, time/batch = 17.4077s	
13458/33650 (epoch 19.997), train_loss = 1.05231537, grad/param norm = 1.5565e-01, time/batch = 16.2040s	
13459/33650 (epoch 19.999), train_loss = 0.92297781, grad/param norm = 1.3774e-01, time/batch = 17.5560s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
13460/33650 (epoch 20.000), train_loss = 1.08269145, grad/param norm = 1.8072e-01, time/batch = 18.6515s	
13461/33650 (epoch 20.001), train_loss = 1.15939872, grad/param norm = 1.5029e-01, time/batch = 17.3979s	
13462/33650 (epoch 20.003), train_loss = 1.14690341, grad/param norm = 1.7264e-01, time/batch = 17.2337s	
13463/33650 (epoch 20.004), train_loss = 1.03604435, grad/param norm = 1.5463e-01, time/batch = 16.9773s	
13464/33650 (epoch 20.006), train_loss = 0.95479610, grad/param norm = 1.4495e-01, time/batch = 18.5622s	
13465/33650 (epoch 20.007), train_loss = 1.05274910, grad/param norm = 1.6842e-01, time/batch = 17.6580s	
13466/33650 (epoch 20.009), train_loss = 0.94988310, grad/param norm = 1.3944e-01, time/batch = 17.2244s	
13467/33650 (epoch 20.010), train_loss = 1.09283960, grad/param norm = 1.6349e-01, time/batch = 18.2225s	
13468/33650 (epoch 20.012), train_loss = 0.93036589, grad/param norm = 1.5317e-01, time/batch = 16.9523s	
13469/33650 (epoch 20.013), train_loss = 1.00431837, grad/param norm = 1.6464e-01, time/batch = 16.9623s	
13470/33650 (epoch 20.015), train_loss = 0.94877840, grad/param norm = 1.4328e-01, time/batch = 16.4842s	
13471/33650 (epoch 20.016), train_loss = 0.87438247, grad/param norm = 1.4767e-01, time/batch = 18.0533s	
13472/33650 (epoch 20.018), train_loss = 0.98655928, grad/param norm = 1.5556e-01, time/batch = 17.7253s	
13473/33650 (epoch 20.019), train_loss = 0.94065970, grad/param norm = 1.5031e-01, time/batch = 18.4716s	
13474/33650 (epoch 20.021), train_loss = 1.06082915, grad/param norm = 1.5668e-01, time/batch = 17.8147s	
13475/33650 (epoch 20.022), train_loss = 0.94419161, grad/param norm = 1.3501e-01, time/batch = 17.9100s	
13476/33650 (epoch 20.024), train_loss = 0.88948668, grad/param norm = 1.4764e-01, time/batch = 17.6998s	
13477/33650 (epoch 20.025), train_loss = 0.97911106, grad/param norm = 1.5293e-01, time/batch = 17.9090s	
13478/33650 (epoch 20.027), train_loss = 1.05489090, grad/param norm = 1.6662e-01, time/batch = 17.5518s	
13479/33650 (epoch 20.028), train_loss = 1.07570703, grad/param norm = 1.5006e-01, time/batch = 16.7231s	
13480/33650 (epoch 20.030), train_loss = 1.00278203, grad/param norm = 1.4987e-01, time/batch = 18.4017s	
13481/33650 (epoch 20.031), train_loss = 0.89093640, grad/param norm = 1.2960e-01, time/batch = 18.0792s	
13482/33650 (epoch 20.033), train_loss = 0.96616324, grad/param norm = 1.1965e-01, time/batch = 16.7299s	
13483/33650 (epoch 20.034), train_loss = 1.01648934, grad/param norm = 1.4932e-01, time/batch = 18.1313s	
13484/33650 (epoch 20.036), train_loss = 1.13300614, grad/param norm = 1.6586e-01, time/batch = 18.0648s	
13485/33650 (epoch 20.037), train_loss = 0.95129445, grad/param norm = 1.3908e-01, time/batch = 17.3962s	
13486/33650 (epoch 20.039), train_loss = 1.10148156, grad/param norm = 1.5853e-01, time/batch = 16.4610s	
13487/33650 (epoch 20.040), train_loss = 1.19172971, grad/param norm = 1.8632e-01, time/batch = 15.8767s	
13488/33650 (epoch 20.042), train_loss = 1.19858461, grad/param norm = 1.7085e-01, time/batch = 17.9007s	
13489/33650 (epoch 20.043), train_loss = 0.94864083, grad/param norm = 1.3620e-01, time/batch = 20.7755s	
13490/33650 (epoch 20.045), train_loss = 0.91542083, grad/param norm = 1.3483e-01, time/batch = 28.5388s	
13491/33650 (epoch 20.046), train_loss = 1.07884102, grad/param norm = 1.4915e-01, time/batch = 18.2197s	
13492/33650 (epoch 20.048), train_loss = 1.09850390, grad/param norm = 1.4670e-01, time/batch = 16.7985s	
13493/33650 (epoch 20.049), train_loss = 1.00627712, grad/param norm = 1.4919e-01, time/batch = 17.9904s	
13494/33650 (epoch 20.051), train_loss = 1.13934582, grad/param norm = 1.4258e-01, time/batch = 18.6524s	
13495/33650 (epoch 20.052), train_loss = 1.14246049, grad/param norm = 1.6872e-01, time/batch = 16.8848s	
13496/33650 (epoch 20.053), train_loss = 1.05428413, grad/param norm = 1.5029e-01, time/batch = 16.2111s	
13497/33650 (epoch 20.055), train_loss = 0.87487766, grad/param norm = 1.3122e-01, time/batch = 18.3094s	
13498/33650 (epoch 20.056), train_loss = 0.86800365, grad/param norm = 1.2944e-01, time/batch = 18.3144s	
13499/33650 (epoch 20.058), train_loss = 1.08615611, grad/param norm = 1.5627e-01, time/batch = 16.1234s	
13500/33650 (epoch 20.059), train_loss = 1.05808163, grad/param norm = 1.7042e-01, time/batch = 17.7225s	
13501/33650 (epoch 20.061), train_loss = 1.08626746, grad/param norm = 1.6747e-01, time/batch = 17.4049s	
13502/33650 (epoch 20.062), train_loss = 1.07100826, grad/param norm = 1.4161e-01, time/batch = 16.6449s	
13503/33650 (epoch 20.064), train_loss = 0.95106865, grad/param norm = 1.2889e-01, time/batch = 17.7384s	
13504/33650 (epoch 20.065), train_loss = 0.95204635, grad/param norm = 1.4203e-01, time/batch = 18.8187s	
13505/33650 (epoch 20.067), train_loss = 0.87624008, grad/param norm = 1.2348e-01, time/batch = 17.8946s	
13506/33650 (epoch 20.068), train_loss = 1.00704581, grad/param norm = 1.5962e-01, time/batch = 17.3914s	
13507/33650 (epoch 20.070), train_loss = 1.05181308, grad/param norm = 1.5966e-01, time/batch = 17.4037s	
13508/33650 (epoch 20.071), train_loss = 1.01421238, grad/param norm = 1.4815e-01, time/batch = 18.9810s	
13509/33650 (epoch 20.073), train_loss = 1.04921249, grad/param norm = 1.5195e-01, time/batch = 15.6874s	
13510/33650 (epoch 20.074), train_loss = 1.13770432, grad/param norm = 1.4575e-01, time/batch = 17.4789s	
13511/33650 (epoch 20.076), train_loss = 1.10598566, grad/param norm = 1.8297e-01, time/batch = 18.4829s	
13512/33650 (epoch 20.077), train_loss = 1.00458473, grad/param norm = 1.4804e-01, time/batch = 17.2970s	
13513/33650 (epoch 20.079), train_loss = 1.01221035, grad/param norm = 1.3922e-01, time/batch = 17.7230s	
13514/33650 (epoch 20.080), train_loss = 1.03382513, grad/param norm = 1.4565e-01, time/batch = 16.9711s	
13515/33650 (epoch 20.082), train_loss = 1.04681532, grad/param norm = 1.3793e-01, time/batch = 18.3794s	
13516/33650 (epoch 20.083), train_loss = 1.07259901, grad/param norm = 1.6101e-01, time/batch = 17.7141s	
13517/33650 (epoch 20.085), train_loss = 1.10177284, grad/param norm = 1.4343e-01, time/batch = 17.6463s	
13518/33650 (epoch 20.086), train_loss = 1.09494451, grad/param norm = 1.7065e-01, time/batch = 16.4650s	
13519/33650 (epoch 20.088), train_loss = 1.04442269, grad/param norm = 1.5032e-01, time/batch = 17.2328s	
13520/33650 (epoch 20.089), train_loss = 0.98937946, grad/param norm = 1.4586e-01, time/batch = 17.7335s	
13521/33650 (epoch 20.091), train_loss = 0.94811011, grad/param norm = 1.3423e-01, time/batch = 16.3806s	
13522/33650 (epoch 20.092), train_loss = 1.00367620, grad/param norm = 1.5440e-01, time/batch = 17.6532s	
13523/33650 (epoch 20.094), train_loss = 1.05798504, grad/param norm = 1.3521e-01, time/batch = 18.6270s	
13524/33650 (epoch 20.095), train_loss = 1.05260822, grad/param norm = 1.5691e-01, time/batch = 17.9019s	
13525/33650 (epoch 20.097), train_loss = 0.96228182, grad/param norm = 1.5853e-01, time/batch = 18.0702s	
13526/33650 (epoch 20.098), train_loss = 0.82591091, grad/param norm = 1.4218e-01, time/batch = 17.2277s	
13527/33650 (epoch 20.100), train_loss = 0.92521623, grad/param norm = 1.3369e-01, time/batch = 18.3018s	
13528/33650 (epoch 20.101), train_loss = 1.00090642, grad/param norm = 1.5503e-01, time/batch = 18.0702s	
13529/33650 (epoch 20.103), train_loss = 0.96721863, grad/param norm = 1.5239e-01, time/batch = 16.4668s	
13530/33650 (epoch 20.104), train_loss = 1.11625853, grad/param norm = 1.4743e-01, time/batch = 18.1325s	
13531/33650 (epoch 20.105), train_loss = 0.99444823, grad/param norm = 1.4393e-01, time/batch = 18.3103s	
13532/33650 (epoch 20.107), train_loss = 0.93467652, grad/param norm = 1.3822e-01, time/batch = 17.9874s	
13533/33650 (epoch 20.108), train_loss = 1.10830232, grad/param norm = 1.5213e-01, time/batch = 16.6250s	
13534/33650 (epoch 20.110), train_loss = 1.17787590, grad/param norm = 1.5870e-01, time/batch = 18.4068s	
13535/33650 (epoch 20.111), train_loss = 0.97067290, grad/param norm = 1.5665e-01, time/batch = 17.9905s	
13536/33650 (epoch 20.113), train_loss = 0.97272572, grad/param norm = 1.4571e-01, time/batch = 16.7259s	
13537/33650 (epoch 20.114), train_loss = 1.08896012, grad/param norm = 1.5009e-01, time/batch = 18.2306s	
13538/33650 (epoch 20.116), train_loss = 0.91930644, grad/param norm = 1.2910e-01, time/batch = 18.0641s	
13539/33650 (epoch 20.117), train_loss = 1.01145403, grad/param norm = 1.3519e-01, time/batch = 16.7225s	
13540/33650 (epoch 20.119), train_loss = 0.88431601, grad/param norm = 1.2744e-01, time/batch = 17.5606s	
13541/33650 (epoch 20.120), train_loss = 0.95991210, grad/param norm = 1.3076e-01, time/batch = 18.6524s	
13542/33650 (epoch 20.122), train_loss = 0.79946572, grad/param norm = 1.4387e-01, time/batch = 18.4710s	
13543/33650 (epoch 20.123), train_loss = 0.96984226, grad/param norm = 1.4074e-01, time/batch = 16.4693s	
13544/33650 (epoch 20.125), train_loss = 1.06213791, grad/param norm = 1.5020e-01, time/batch = 14.8677s	
13545/33650 (epoch 20.126), train_loss = 1.13912164, grad/param norm = 1.9309e-01, time/batch = 18.1128s	
13546/33650 (epoch 20.128), train_loss = 1.10515253, grad/param norm = 1.5991e-01, time/batch = 17.8809s	
13547/33650 (epoch 20.129), train_loss = 1.12787271, grad/param norm = 1.5304e-01, time/batch = 17.3976s	
13548/33650 (epoch 20.131), train_loss = 1.03120202, grad/param norm = 1.4856e-01, time/batch = 14.3285s	
13549/33650 (epoch 20.132), train_loss = 1.03335780, grad/param norm = 1.4650e-01, time/batch = 17.3150s	
13550/33650 (epoch 20.134), train_loss = 1.09702763, grad/param norm = 1.5816e-01, time/batch = 15.9741s	
13551/33650 (epoch 20.135), train_loss = 0.89095223, grad/param norm = 1.5864e-01, time/batch = 17.7327s	
13552/33650 (epoch 20.137), train_loss = 1.02557473, grad/param norm = 1.4780e-01, time/batch = 16.7338s	
13553/33650 (epoch 20.138), train_loss = 1.06768691, grad/param norm = 1.3885e-01, time/batch = 16.1425s	
13554/33650 (epoch 20.140), train_loss = 0.98918251, grad/param norm = 1.6645e-01, time/batch = 18.3895s	
13555/33650 (epoch 20.141), train_loss = 1.16115107, grad/param norm = 1.6654e-01, time/batch = 17.5604s	
13556/33650 (epoch 20.143), train_loss = 1.21021734, grad/param norm = 1.8384e-01, time/batch = 18.7313s	
13557/33650 (epoch 20.144), train_loss = 1.08264774, grad/param norm = 1.6382e-01, time/batch = 17.2123s	
13558/33650 (epoch 20.146), train_loss = 0.98483664, grad/param norm = 1.6077e-01, time/batch = 16.1974s	
13559/33650 (epoch 20.147), train_loss = 0.94705525, grad/param norm = 1.4553e-01, time/batch = 17.7362s	
13560/33650 (epoch 20.149), train_loss = 0.90709684, grad/param norm = 1.5283e-01, time/batch = 17.2970s	
13561/33650 (epoch 20.150), train_loss = 0.88377945, grad/param norm = 1.4189e-01, time/batch = 18.8760s	
13562/33650 (epoch 20.152), train_loss = 0.95089368, grad/param norm = 1.4649e-01, time/batch = 18.3934s	
13563/33650 (epoch 20.153), train_loss = 0.96083715, grad/param norm = 1.3458e-01, time/batch = 17.1343s	
13564/33650 (epoch 20.155), train_loss = 0.94430242, grad/param norm = 1.3513e-01, time/batch = 24.2298s	
13565/33650 (epoch 20.156), train_loss = 0.90719937, grad/param norm = 1.3136e-01, time/batch = 19.2101s	
13566/33650 (epoch 20.158), train_loss = 1.03164148, grad/param norm = 1.6579e-01, time/batch = 17.7251s	
13567/33650 (epoch 20.159), train_loss = 0.90958768, grad/param norm = 1.2104e-01, time/batch = 16.2151s	
13568/33650 (epoch 20.160), train_loss = 0.93625896, grad/param norm = 1.3202e-01, time/batch = 18.3987s	
13569/33650 (epoch 20.162), train_loss = 0.97125312, grad/param norm = 1.6041e-01, time/batch = 17.8179s	
13570/33650 (epoch 20.163), train_loss = 1.05793338, grad/param norm = 1.7509e-01, time/batch = 16.8067s	
13571/33650 (epoch 20.165), train_loss = 0.89296939, grad/param norm = 1.4020e-01, time/batch = 17.7877s	
13572/33650 (epoch 20.166), train_loss = 0.92551386, grad/param norm = 1.4829e-01, time/batch = 18.2287s	
13573/33650 (epoch 20.168), train_loss = 1.08104654, grad/param norm = 1.6893e-01, time/batch = 16.7881s	
13574/33650 (epoch 20.169), train_loss = 1.00698227, grad/param norm = 1.5020e-01, time/batch = 17.8980s	
13575/33650 (epoch 20.171), train_loss = 0.99324044, grad/param norm = 1.4191e-01, time/batch = 18.5615s	
13576/33650 (epoch 20.172), train_loss = 0.95206203, grad/param norm = 1.4798e-01, time/batch = 17.0390s	
13577/33650 (epoch 20.174), train_loss = 0.90656018, grad/param norm = 1.3559e-01, time/batch = 17.2244s	
13578/33650 (epoch 20.175), train_loss = 0.89419100, grad/param norm = 1.5598e-01, time/batch = 17.8833s	
13579/33650 (epoch 20.177), train_loss = 1.00683166, grad/param norm = 1.4034e-01, time/batch = 17.8118s	
13580/33650 (epoch 20.178), train_loss = 0.94900391, grad/param norm = 1.8705e-01, time/batch = 17.2300s	
13581/33650 (epoch 20.180), train_loss = 0.90309760, grad/param norm = 1.3771e-01, time/batch = 17.4944s	
13582/33650 (epoch 20.181), train_loss = 0.81369028, grad/param norm = 1.3142e-01, time/batch = 18.5555s	
13583/33650 (epoch 20.183), train_loss = 0.94304132, grad/param norm = 1.4882e-01, time/batch = 16.4603s	
13584/33650 (epoch 20.184), train_loss = 0.94198871, grad/param norm = 1.6001e-01, time/batch = 16.9905s	
13585/33650 (epoch 20.186), train_loss = 0.99312626, grad/param norm = 2.0389e-01, time/batch = 17.2463s	
13586/33650 (epoch 20.187), train_loss = 1.17217879, grad/param norm = 1.7005e-01, time/batch = 18.7204s	
13587/33650 (epoch 20.189), train_loss = 1.12063295, grad/param norm = 1.7570e-01, time/batch = 16.3883s	
13588/33650 (epoch 20.190), train_loss = 1.02722927, grad/param norm = 1.5811e-01, time/batch = 17.9890s	
13589/33650 (epoch 20.192), train_loss = 1.18955508, grad/param norm = 1.6379e-01, time/batch = 18.0691s	
13590/33650 (epoch 20.193), train_loss = 1.11644643, grad/param norm = 1.5181e-01, time/batch = 17.8038s	
13591/33650 (epoch 20.195), train_loss = 0.88912595, grad/param norm = 1.3943e-01, time/batch = 18.0600s	
13592/33650 (epoch 20.196), train_loss = 0.86032987, grad/param norm = 1.5347e-01, time/batch = 17.1566s	
13593/33650 (epoch 20.198), train_loss = 0.94745408, grad/param norm = 1.5515e-01, time/batch = 18.1550s	
13594/33650 (epoch 20.199), train_loss = 1.08201818, grad/param norm = 1.5840e-01, time/batch = 17.3981s	
13595/33650 (epoch 20.201), train_loss = 0.94973317, grad/param norm = 1.5272e-01, time/batch = 18.8862s	
13596/33650 (epoch 20.202), train_loss = 0.97067205, grad/param norm = 1.5317e-01, time/batch = 15.6263s	
13597/33650 (epoch 20.204), train_loss = 1.03848014, grad/param norm = 1.5409e-01, time/batch = 17.3200s	
13598/33650 (epoch 20.205), train_loss = 0.99386449, grad/param norm = 1.4801e-01, time/batch = 17.9772s	
13599/33650 (epoch 20.207), train_loss = 0.93220605, grad/param norm = 1.5026e-01, time/batch = 18.1196s	
13600/33650 (epoch 20.208), train_loss = 1.00181627, grad/param norm = 1.4646e-01, time/batch = 17.5487s	
13601/33650 (epoch 20.210), train_loss = 0.82021646, grad/param norm = 1.4635e-01, time/batch = 16.8852s	
13602/33650 (epoch 20.211), train_loss = 0.93572353, grad/param norm = 1.7047e-01, time/batch = 17.4940s	
13603/33650 (epoch 20.212), train_loss = 1.05093553, grad/param norm = 1.6873e-01, time/batch = 17.8220s	
13604/33650 (epoch 20.214), train_loss = 1.15802516, grad/param norm = 1.5123e-01, time/batch = 17.4692s	
13605/33650 (epoch 20.215), train_loss = 0.77456811, grad/param norm = 1.3816e-01, time/batch = 18.2297s	
13606/33650 (epoch 20.217), train_loss = 0.96397616, grad/param norm = 1.5268e-01, time/batch = 17.6426s	
13607/33650 (epoch 20.218), train_loss = 1.01664623, grad/param norm = 1.4333e-01, time/batch = 17.2240s	
13608/33650 (epoch 20.220), train_loss = 0.87050710, grad/param norm = 1.3867e-01, time/batch = 16.6359s	
13609/33650 (epoch 20.221), train_loss = 1.16269015, grad/param norm = 1.6425e-01, time/batch = 18.2355s	
13610/33650 (epoch 20.223), train_loss = 0.80002579, grad/param norm = 1.3806e-01, time/batch = 18.1542s	
13611/33650 (epoch 20.224), train_loss = 0.95281635, grad/param norm = 1.5033e-01, time/batch = 16.7163s	
13612/33650 (epoch 20.226), train_loss = 1.26772989, grad/param norm = 1.7888e-01, time/batch = 18.8963s	
13613/33650 (epoch 20.227), train_loss = 1.13724089, grad/param norm = 1.7779e-01, time/batch = 17.6467s	
13614/33650 (epoch 20.229), train_loss = 1.12132612, grad/param norm = 1.6711e-01, time/batch = 16.2181s	
13615/33650 (epoch 20.230), train_loss = 1.24374349, grad/param norm = 1.7003e-01, time/batch = 17.9740s	
13616/33650 (epoch 20.232), train_loss = 1.07437567, grad/param norm = 1.7248e-01, time/batch = 18.4046s	
13617/33650 (epoch 20.233), train_loss = 1.05397301, grad/param norm = 1.8737e-01, time/batch = 18.1443s	
13618/33650 (epoch 20.235), train_loss = 0.99368510, grad/param norm = 1.4900e-01, time/batch = 17.2429s	
13619/33650 (epoch 20.236), train_loss = 0.88543823, grad/param norm = 1.4071e-01, time/batch = 18.4800s	
13620/33650 (epoch 20.238), train_loss = 0.97373670, grad/param norm = 1.3995e-01, time/batch = 17.9795s	
13621/33650 (epoch 20.239), train_loss = 0.90356901, grad/param norm = 1.4882e-01, time/batch = 17.2312s	
13622/33650 (epoch 20.241), train_loss = 0.95318346, grad/param norm = 1.3701e-01, time/batch = 17.6542s	
13623/33650 (epoch 20.242), train_loss = 0.81116447, grad/param norm = 1.2804e-01, time/batch = 17.4825s	
13624/33650 (epoch 20.244), train_loss = 0.97797510, grad/param norm = 1.4034e-01, time/batch = 17.5493s	
13625/33650 (epoch 20.245), train_loss = 0.86976092, grad/param norm = 1.3265e-01, time/batch = 17.7309s	
13626/33650 (epoch 20.247), train_loss = 0.97374619, grad/param norm = 1.2752e-01, time/batch = 18.5590s	
13627/33650 (epoch 20.248), train_loss = 0.86663565, grad/param norm = 1.3331e-01, time/batch = 15.7940s	
13628/33650 (epoch 20.250), train_loss = 0.97607227, grad/param norm = 1.4105e-01, time/batch = 17.3198s	
13629/33650 (epoch 20.251), train_loss = 1.11807635, grad/param norm = 1.5673e-01, time/batch = 18.0626s	
13630/33650 (epoch 20.253), train_loss = 0.86682163, grad/param norm = 1.3767e-01, time/batch = 17.6503s	
13631/33650 (epoch 20.254), train_loss = 0.90134263, grad/param norm = 1.4181e-01, time/batch = 17.3078s	
13632/33650 (epoch 20.256), train_loss = 1.12540632, grad/param norm = 1.4691e-01, time/batch = 18.1420s	
13633/33650 (epoch 20.257), train_loss = 1.13202840, grad/param norm = 1.5343e-01, time/batch = 18.3871s	
13634/33650 (epoch 20.259), train_loss = 0.86387031, grad/param norm = 1.4165e-01, time/batch = 18.0550s	
13635/33650 (epoch 20.260), train_loss = 1.08054716, grad/param norm = 1.5263e-01, time/batch = 17.9723s	
13636/33650 (epoch 20.262), train_loss = 1.02769900, grad/param norm = 1.5905e-01, time/batch = 17.1390s	
13637/33650 (epoch 20.263), train_loss = 0.94143205, grad/param norm = 1.7068e-01, time/batch = 16.6442s	
13638/33650 (epoch 20.264), train_loss = 1.04318622, grad/param norm = 1.4838e-01, time/batch = 18.2101s	
13639/33650 (epoch 20.266), train_loss = 1.01368892, grad/param norm = 1.3940e-01, time/batch = 17.9734s	
13640/33650 (epoch 20.267), train_loss = 0.92908127, grad/param norm = 1.4664e-01, time/batch = 18.2346s	
13641/33650 (epoch 20.269), train_loss = 1.02857511, grad/param norm = 1.3829e-01, time/batch = 17.0575s	
13642/33650 (epoch 20.270), train_loss = 0.91744824, grad/param norm = 1.3572e-01, time/batch = 18.3110s	
13643/33650 (epoch 20.272), train_loss = 0.96052700, grad/param norm = 1.3414e-01, time/batch = 17.7232s	
13644/33650 (epoch 20.273), train_loss = 1.11093221, grad/param norm = 1.7271e-01, time/batch = 17.6446s	
13645/33650 (epoch 20.275), train_loss = 1.05869597, grad/param norm = 1.4928e-01, time/batch = 18.3859s	
13646/33650 (epoch 20.276), train_loss = 1.11332830, grad/param norm = 1.5985e-01, time/batch = 18.6528s	
13647/33650 (epoch 20.278), train_loss = 1.19951843, grad/param norm = 1.8817e-01, time/batch = 17.3946s	
13648/33650 (epoch 20.279), train_loss = 0.96394024, grad/param norm = 1.3778e-01, time/batch = 16.7087s	
13649/33650 (epoch 20.281), train_loss = 1.04262014, grad/param norm = 1.5164e-01, time/batch = 18.4802s	
13650/33650 (epoch 20.282), train_loss = 1.09788996, grad/param norm = 1.3277e-01, time/batch = 17.9079s	
13651/33650 (epoch 20.284), train_loss = 1.08520288, grad/param norm = 1.6535e-01, time/batch = 15.8903s	
13652/33650 (epoch 20.285), train_loss = 1.07695382, grad/param norm = 1.5730e-01, time/batch = 17.3789s	
13653/33650 (epoch 20.287), train_loss = 0.98332760, grad/param norm = 1.4810e-01, time/batch = 17.5531s	
13654/33650 (epoch 20.288), train_loss = 1.04447671, grad/param norm = 1.7349e-01, time/batch = 17.8747s	
13655/33650 (epoch 20.290), train_loss = 1.00604094, grad/param norm = 1.3446e-01, time/batch = 17.3068s	
13656/33650 (epoch 20.291), train_loss = 0.92113273, grad/param norm = 1.2678e-01, time/batch = 18.7371s	
13657/33650 (epoch 20.293), train_loss = 0.99019859, grad/param norm = 1.6683e-01, time/batch = 18.1488s	
13658/33650 (epoch 20.294), train_loss = 0.90731141, grad/param norm = 1.3684e-01, time/batch = 16.8085s	
13659/33650 (epoch 20.296), train_loss = 0.89986618, grad/param norm = 1.3955e-01, time/batch = 18.4037s	
13660/33650 (epoch 20.297), train_loss = 0.98378352, grad/param norm = 1.4710e-01, time/batch = 18.6435s	
13661/33650 (epoch 20.299), train_loss = 0.84646894, grad/param norm = 1.2805e-01, time/batch = 16.0511s	
13662/33650 (epoch 20.300), train_loss = 0.89338359, grad/param norm = 1.4466e-01, time/batch = 17.2291s	
13663/33650 (epoch 20.302), train_loss = 1.03093902, grad/param norm = 1.4144e-01, time/batch = 18.1464s	
13664/33650 (epoch 20.303), train_loss = 1.02883920, grad/param norm = 1.3459e-01, time/batch = 17.3137s	
13665/33650 (epoch 20.305), train_loss = 1.02378606, grad/param norm = 1.4750e-01, time/batch = 16.3811s	
13666/33650 (epoch 20.306), train_loss = 0.92514053, grad/param norm = 1.3507e-01, time/batch = 18.2177s	
13667/33650 (epoch 20.308), train_loss = 0.86223382, grad/param norm = 1.4368e-01, time/batch = 17.8026s	
13668/33650 (epoch 20.309), train_loss = 1.16891063, grad/param norm = 1.5396e-01, time/batch = 17.4712s	
13669/33650 (epoch 20.311), train_loss = 1.02950077, grad/param norm = 1.6450e-01, time/batch = 16.2953s	
13670/33650 (epoch 20.312), train_loss = 1.00472448, grad/param norm = 1.6215e-01, time/batch = 17.8029s	
13671/33650 (epoch 20.314), train_loss = 0.87250593, grad/param norm = 1.2186e-01, time/batch = 17.8991s	
13672/33650 (epoch 20.315), train_loss = 0.98051081, grad/param norm = 1.8839e-01, time/batch = 17.2233s	
13673/33650 (epoch 20.316), train_loss = 0.95663289, grad/param norm = 1.5373e-01, time/batch = 18.6486s	
13674/33650 (epoch 20.318), train_loss = 0.88794845, grad/param norm = 1.3100e-01, time/batch = 18.1555s	
13675/33650 (epoch 20.319), train_loss = 0.91703227, grad/param norm = 1.3339e-01, time/batch = 9.0755s	
13676/33650 (epoch 20.321), train_loss = 0.92539058, grad/param norm = 1.3737e-01, time/batch = 0.6528s	
13677/33650 (epoch 20.322), train_loss = 1.01614487, grad/param norm = 1.5325e-01, time/batch = 0.6414s	
13678/33650 (epoch 20.324), train_loss = 1.06660353, grad/param norm = 1.6405e-01, time/batch = 0.6404s	
13679/33650 (epoch 20.325), train_loss = 1.05791554, grad/param norm = 1.5320e-01, time/batch = 0.6382s	
13680/33650 (epoch 20.327), train_loss = 0.91453295, grad/param norm = 1.2907e-01, time/batch = 0.6448s	
13681/33650 (epoch 20.328), train_loss = 1.04736068, grad/param norm = 1.5228e-01, time/batch = 0.6411s	
13682/33650 (epoch 20.330), train_loss = 0.90923950, grad/param norm = 1.2319e-01, time/batch = 0.6398s	
13683/33650 (epoch 20.331), train_loss = 0.81935790, grad/param norm = 1.2326e-01, time/batch = 0.8769s	
13684/33650 (epoch 20.333), train_loss = 0.97376128, grad/param norm = 1.3687e-01, time/batch = 0.9305s	
13685/33650 (epoch 20.334), train_loss = 0.97898651, grad/param norm = 1.4405e-01, time/batch = 0.9404s	
13686/33650 (epoch 20.336), train_loss = 1.10538965, grad/param norm = 1.4575e-01, time/batch = 0.9444s	
13687/33650 (epoch 20.337), train_loss = 0.83664481, grad/param norm = 1.3089e-01, time/batch = 0.9380s	
13688/33650 (epoch 20.339), train_loss = 0.94628716, grad/param norm = 1.2821e-01, time/batch = 1.3116s	
13689/33650 (epoch 20.340), train_loss = 1.12168764, grad/param norm = 1.7302e-01, time/batch = 1.8429s	
13690/33650 (epoch 20.342), train_loss = 0.83232494, grad/param norm = 1.3615e-01, time/batch = 1.7743s	
13691/33650 (epoch 20.343), train_loss = 1.03481721, grad/param norm = 1.5578e-01, time/batch = 14.1016s	
13692/33650 (epoch 20.345), train_loss = 0.96063581, grad/param norm = 1.4308e-01, time/batch = 18.0663s	
13693/33650 (epoch 20.346), train_loss = 0.67866983, grad/param norm = 1.1784e-01, time/batch = 16.4514s	
13694/33650 (epoch 20.348), train_loss = 0.86449475, grad/param norm = 1.3196e-01, time/batch = 17.8211s	
13695/33650 (epoch 20.349), train_loss = 0.83574307, grad/param norm = 1.4062e-01, time/batch = 17.2428s	
13696/33650 (epoch 20.351), train_loss = 1.06217441, grad/param norm = 1.4102e-01, time/batch = 16.5576s	
13697/33650 (epoch 20.352), train_loss = 0.98148483, grad/param norm = 1.4245e-01, time/batch = 17.2285s	
13698/33650 (epoch 20.354), train_loss = 1.17444412, grad/param norm = 1.8530e-01, time/batch = 18.8120s	
13699/33650 (epoch 20.355), train_loss = 1.10640053, grad/param norm = 1.4217e-01, time/batch = 16.0496s	
13700/33650 (epoch 20.357), train_loss = 0.79492767, grad/param norm = 1.3963e-01, time/batch = 16.8708s	
13701/33650 (epoch 20.358), train_loss = 1.06553735, grad/param norm = 1.5439e-01, time/batch = 16.8967s	
13702/33650 (epoch 20.360), train_loss = 1.08760638, grad/param norm = 1.6526e-01, time/batch = 18.3964s	
13703/33650 (epoch 20.361), train_loss = 1.02870487, grad/param norm = 1.3842e-01, time/batch = 16.6467s	
13704/33650 (epoch 20.363), train_loss = 0.95780683, grad/param norm = 1.4447e-01, time/batch = 17.9800s	
13705/33650 (epoch 20.364), train_loss = 0.93969790, grad/param norm = 1.3340e-01, time/batch = 17.8194s	
13706/33650 (epoch 20.366), train_loss = 1.04530766, grad/param norm = 1.7595e-01, time/batch = 17.4890s	
13707/33650 (epoch 20.367), train_loss = 1.03867795, grad/param norm = 1.4517e-01, time/batch = 30.1509s	
13708/33650 (epoch 20.368), train_loss = 0.90402071, grad/param norm = 1.3670e-01, time/batch = 18.6392s	
13709/33650 (epoch 20.370), train_loss = 1.00248186, grad/param norm = 1.4908e-01, time/batch = 17.5651s	
13710/33650 (epoch 20.371), train_loss = 0.79531237, grad/param norm = 1.3295e-01, time/batch = 16.7361s	
13711/33650 (epoch 20.373), train_loss = 0.88870834, grad/param norm = 1.3570e-01, time/batch = 17.9079s	
13712/33650 (epoch 20.374), train_loss = 0.86509831, grad/param norm = 1.2734e-01, time/batch = 17.3082s	
13713/33650 (epoch 20.376), train_loss = 0.97298404, grad/param norm = 1.5243e-01, time/batch = 17.2257s	
13714/33650 (epoch 20.377), train_loss = 1.02284946, grad/param norm = 1.5346e-01, time/batch = 17.7296s	
13715/33650 (epoch 20.379), train_loss = 1.04464718, grad/param norm = 1.4514e-01, time/batch = 16.8730s	
13716/33650 (epoch 20.380), train_loss = 0.78522874, grad/param norm = 1.4032e-01, time/batch = 17.6447s	
13717/33650 (epoch 20.382), train_loss = 0.91787806, grad/param norm = 1.2443e-01, time/batch = 17.1484s	
13718/33650 (epoch 20.383), train_loss = 0.96652301, grad/param norm = 1.3078e-01, time/batch = 17.3133s	
13719/33650 (epoch 20.385), train_loss = 1.10838451, grad/param norm = 1.4874e-01, time/batch = 16.7125s	
13720/33650 (epoch 20.386), train_loss = 0.92247241, grad/param norm = 1.3779e-01, time/batch = 16.7301s	
13721/33650 (epoch 20.388), train_loss = 1.02385247, grad/param norm = 1.3987e-01, time/batch = 18.7366s	
13722/33650 (epoch 20.389), train_loss = 0.95951903, grad/param norm = 1.6460e-01, time/batch = 17.6593s	
13723/33650 (epoch 20.391), train_loss = 0.78622178, grad/param norm = 1.2547e-01, time/batch = 17.5546s	
13724/33650 (epoch 20.392), train_loss = 1.03557949, grad/param norm = 1.6959e-01, time/batch = 17.9063s	
13725/33650 (epoch 20.394), train_loss = 1.01681102, grad/param norm = 1.5771e-01, time/batch = 17.9048s	
13726/33650 (epoch 20.395), train_loss = 1.03097122, grad/param norm = 1.4369e-01, time/batch = 17.2331s	
13727/33650 (epoch 20.397), train_loss = 1.12426494, grad/param norm = 1.4526e-01, time/batch = 17.3836s	
13728/33650 (epoch 20.398), train_loss = 1.04516531, grad/param norm = 1.5761e-01, time/batch = 18.1565s	
13729/33650 (epoch 20.400), train_loss = 0.98034177, grad/param norm = 1.6620e-01, time/batch = 18.1452s	
13730/33650 (epoch 20.401), train_loss = 0.93940432, grad/param norm = 1.5147e-01, time/batch = 15.3853s	
13731/33650 (epoch 20.403), train_loss = 1.02380397, grad/param norm = 1.5055e-01, time/batch = 18.0526s	
13732/33650 (epoch 20.404), train_loss = 0.98483685, grad/param norm = 1.4142e-01, time/batch = 18.1430s	
13733/33650 (epoch 20.406), train_loss = 0.99999515, grad/param norm = 1.5088e-01, time/batch = 17.0529s	
13734/33650 (epoch 20.407), train_loss = 0.98607387, grad/param norm = 1.5015e-01, time/batch = 16.7917s	
13735/33650 (epoch 20.409), train_loss = 1.03021756, grad/param norm = 1.5110e-01, time/batch = 17.8246s	
13736/33650 (epoch 20.410), train_loss = 0.97296300, grad/param norm = 1.4055e-01, time/batch = 17.9012s	
13737/33650 (epoch 20.412), train_loss = 0.99324689, grad/param norm = 1.3001e-01, time/batch = 17.1559s	
13738/33650 (epoch 20.413), train_loss = 0.93336284, grad/param norm = 1.4721e-01, time/batch = 17.3955s	
13739/33650 (epoch 20.415), train_loss = 1.06360148, grad/param norm = 1.5301e-01, time/batch = 18.8983s	
13740/33650 (epoch 20.416), train_loss = 1.12375565, grad/param norm = 1.4875e-01, time/batch = 15.3773s	
13741/33650 (epoch 20.418), train_loss = 0.94111322, grad/param norm = 1.3940e-01, time/batch = 18.3899s	
13742/33650 (epoch 20.419), train_loss = 0.94889230, grad/param norm = 1.4592e-01, time/batch = 17.6580s	
13743/33650 (epoch 20.421), train_loss = 0.96488740, grad/param norm = 1.2947e-01, time/batch = 18.6411s	
13744/33650 (epoch 20.422), train_loss = 1.08530976, grad/param norm = 1.3994e-01, time/batch = 16.9705s	
13745/33650 (epoch 20.423), train_loss = 0.90436837, grad/param norm = 1.2069e-01, time/batch = 18.0763s	
13746/33650 (epoch 20.425), train_loss = 0.99754208, grad/param norm = 1.3973e-01, time/batch = 17.4877s	
13747/33650 (epoch 20.426), train_loss = 1.14779457, grad/param norm = 1.6818e-01, time/batch = 16.9879s	
13748/33650 (epoch 20.428), train_loss = 0.91650849, grad/param norm = 1.3363e-01, time/batch = 18.4762s	
13749/33650 (epoch 20.429), train_loss = 1.07659744, grad/param norm = 1.5671e-01, time/batch = 18.3944s	
13750/33650 (epoch 20.431), train_loss = 1.14396169, grad/param norm = 1.6227e-01, time/batch = 17.3946s	
13751/33650 (epoch 20.432), train_loss = 1.18442137, grad/param norm = 1.5773e-01, time/batch = 17.8943s	
13752/33650 (epoch 20.434), train_loss = 1.00946516, grad/param norm = 1.4378e-01, time/batch = 17.6561s	
13753/33650 (epoch 20.435), train_loss = 0.98072587, grad/param norm = 1.6956e-01, time/batch = 16.5425s	
13754/33650 (epoch 20.437), train_loss = 1.00594326, grad/param norm = 1.5442e-01, time/batch = 16.4776s	
13755/33650 (epoch 20.438), train_loss = 0.93684208, grad/param norm = 1.8901e-01, time/batch = 17.8166s	
13756/33650 (epoch 20.440), train_loss = 0.99335630, grad/param norm = 1.6528e-01, time/batch = 18.4016s	
13757/33650 (epoch 20.441), train_loss = 1.02099459, grad/param norm = 1.7236e-01, time/batch = 17.1471s	
13758/33650 (epoch 20.443), train_loss = 1.06384851, grad/param norm = 1.4260e-01, time/batch = 17.5722s	
13759/33650 (epoch 20.444), train_loss = 0.96489703, grad/param norm = 1.4439e-01, time/batch = 16.8024s	
13760/33650 (epoch 20.446), train_loss = 1.03615112, grad/param norm = 1.6429e-01, time/batch = 18.7349s	
13761/33650 (epoch 20.447), train_loss = 1.11217235, grad/param norm = 1.6764e-01, time/batch = 17.3189s	
13762/33650 (epoch 20.449), train_loss = 1.16470082, grad/param norm = 1.9627e-01, time/batch = 18.5671s	
13763/33650 (epoch 20.450), train_loss = 1.18457461, grad/param norm = 1.6231e-01, time/batch = 17.4064s	
13764/33650 (epoch 20.452), train_loss = 1.16914845, grad/param norm = 1.6225e-01, time/batch = 16.8949s	
13765/33650 (epoch 20.453), train_loss = 1.17589067, grad/param norm = 1.9475e-01, time/batch = 18.0576s	
13766/33650 (epoch 20.455), train_loss = 0.98078263, grad/param norm = 1.5280e-01, time/batch = 17.4636s	
13767/33650 (epoch 20.456), train_loss = 1.00491078, grad/param norm = 1.5635e-01, time/batch = 17.3810s	
13768/33650 (epoch 20.458), train_loss = 0.98035281, grad/param norm = 1.4996e-01, time/batch = 16.6522s	
13769/33650 (epoch 20.459), train_loss = 1.03914980, grad/param norm = 1.8544e-01, time/batch = 17.7217s	
13770/33650 (epoch 20.461), train_loss = 1.15476805, grad/param norm = 1.6396e-01, time/batch = 18.5563s	
13771/33650 (epoch 20.462), train_loss = 1.13178794, grad/param norm = 1.6514e-01, time/batch = 16.9633s	
13772/33650 (epoch 20.464), train_loss = 0.97393282, grad/param norm = 1.6146e-01, time/batch = 18.3951s	
13773/33650 (epoch 20.465), train_loss = 1.03446207, grad/param norm = 1.5998e-01, time/batch = 17.9806s	
13774/33650 (epoch 20.467), train_loss = 1.05803675, grad/param norm = 1.5090e-01, time/batch = 16.2309s	
13775/33650 (epoch 20.468), train_loss = 1.12784281, grad/param norm = 1.4840e-01, time/batch = 17.8942s	
13776/33650 (epoch 20.470), train_loss = 1.21740087, grad/param norm = 1.7245e-01, time/batch = 15.8976s	
13777/33650 (epoch 20.471), train_loss = 1.01270036, grad/param norm = 1.5993e-01, time/batch = 18.4868s	
13778/33650 (epoch 20.473), train_loss = 0.98218036, grad/param norm = 1.5402e-01, time/batch = 17.5526s	
13779/33650 (epoch 20.474), train_loss = 1.09605258, grad/param norm = 1.4769e-01, time/batch = 17.6213s	
13780/33650 (epoch 20.475), train_loss = 1.07397529, grad/param norm = 1.6287e-01, time/batch = 17.8101s	
13781/33650 (epoch 20.477), train_loss = 1.12629575, grad/param norm = 1.5356e-01, time/batch = 16.9855s	
13782/33650 (epoch 20.478), train_loss = 1.11718162, grad/param norm = 1.6580e-01, time/batch = 17.9029s	
13783/33650 (epoch 20.480), train_loss = 1.11054404, grad/param norm = 1.7354e-01, time/batch = 16.8954s	
13784/33650 (epoch 20.481), train_loss = 1.17785910, grad/param norm = 1.6126e-01, time/batch = 17.6413s	
13785/33650 (epoch 20.483), train_loss = 0.82351559, grad/param norm = 1.3100e-01, time/batch = 17.5572s	
13786/33650 (epoch 20.484), train_loss = 1.01093135, grad/param norm = 1.4724e-01, time/batch = 18.2324s	
13787/33650 (epoch 20.486), train_loss = 1.15279281, grad/param norm = 1.7971e-01, time/batch = 18.3169s	
13788/33650 (epoch 20.487), train_loss = 1.18061081, grad/param norm = 1.6997e-01, time/batch = 17.8901s	
13789/33650 (epoch 20.489), train_loss = 1.15809721, grad/param norm = 1.5438e-01, time/batch = 17.4098s	
13790/33650 (epoch 20.490), train_loss = 0.91292650, grad/param norm = 1.4836e-01, time/batch = 15.7322s	
13791/33650 (epoch 20.492), train_loss = 1.07289479, grad/param norm = 1.8144e-01, time/batch = 16.7100s	
13792/33650 (epoch 20.493), train_loss = 0.86755151, grad/param norm = 1.3459e-01, time/batch = 17.8085s	
13793/33650 (epoch 20.495), train_loss = 1.02978461, grad/param norm = 1.4991e-01, time/batch = 17.9989s	
13794/33650 (epoch 20.496), train_loss = 1.07140006, grad/param norm = 1.5591e-01, time/batch = 18.3113s	
13795/33650 (epoch 20.498), train_loss = 0.91888340, grad/param norm = 1.3554e-01, time/batch = 17.2349s	
13796/33650 (epoch 20.499), train_loss = 1.00511348, grad/param norm = 1.3069e-01, time/batch = 18.6410s	
13797/33650 (epoch 20.501), train_loss = 0.98969324, grad/param norm = 1.3396e-01, time/batch = 17.8131s	
13798/33650 (epoch 20.502), train_loss = 1.02192810, grad/param norm = 1.4814e-01, time/batch = 17.0649s	
13799/33650 (epoch 20.504), train_loss = 1.11615125, grad/param norm = 1.7001e-01, time/batch = 18.4019s	
13800/33650 (epoch 20.505), train_loss = 0.97501793, grad/param norm = 1.6725e-01, time/batch = 17.6468s	
13801/33650 (epoch 20.507), train_loss = 1.14051152, grad/param norm = 1.6041e-01, time/batch = 17.1468s	
13802/33650 (epoch 20.508), train_loss = 0.97996476, grad/param norm = 1.4740e-01, time/batch = 17.3141s	
13803/33650 (epoch 20.510), train_loss = 1.00341980, grad/param norm = 1.4726e-01, time/batch = 16.0589s	
13804/33650 (epoch 20.511), train_loss = 1.22748200, grad/param norm = 1.6678e-01, time/batch = 17.7277s	
13805/33650 (epoch 20.513), train_loss = 1.08215243, grad/param norm = 1.5448e-01, time/batch = 16.6452s	
13806/33650 (epoch 20.514), train_loss = 1.07965321, grad/param norm = 1.5830e-01, time/batch = 18.3086s	
13807/33650 (epoch 20.516), train_loss = 1.02584730, grad/param norm = 1.5677e-01, time/batch = 17.6596s	
13808/33650 (epoch 20.517), train_loss = 1.02658070, grad/param norm = 1.6123e-01, time/batch = 16.9933s	
13809/33650 (epoch 20.519), train_loss = 1.09538397, grad/param norm = 1.6806e-01, time/batch = 17.8069s	
13810/33650 (epoch 20.520), train_loss = 0.87141747, grad/param norm = 1.2276e-01, time/batch = 17.9054s	
13811/33650 (epoch 20.522), train_loss = 1.01041285, grad/param norm = 1.6235e-01, time/batch = 17.9809s	
13812/33650 (epoch 20.523), train_loss = 0.95638058, grad/param norm = 1.4580e-01, time/batch = 17.2280s	
13813/33650 (epoch 20.525), train_loss = 0.80763708, grad/param norm = 1.2645e-01, time/batch = 17.2898s	
13814/33650 (epoch 20.526), train_loss = 1.10916564, grad/param norm = 1.5209e-01, time/batch = 17.4813s	
13815/33650 (epoch 20.527), train_loss = 0.96475530, grad/param norm = 1.4787e-01, time/batch = 17.0646s	
13816/33650 (epoch 20.529), train_loss = 1.01698374, grad/param norm = 1.4340e-01, time/batch = 18.2345s	
13817/33650 (epoch 20.530), train_loss = 0.96016054, grad/param norm = 1.4576e-01, time/batch = 16.5573s	
13818/33650 (epoch 20.532), train_loss = 1.12640805, grad/param norm = 1.8885e-01, time/batch = 17.8101s	
13819/33650 (epoch 20.533), train_loss = 1.00199143, grad/param norm = 1.5183e-01, time/batch = 17.1526s	
13820/33650 (epoch 20.535), train_loss = 1.09670904, grad/param norm = 1.4579e-01, time/batch = 16.4722s	
13821/33650 (epoch 20.536), train_loss = 1.02653609, grad/param norm = 1.5798e-01, time/batch = 18.1312s	
13822/33650 (epoch 20.538), train_loss = 1.09129646, grad/param norm = 1.7585e-01, time/batch = 17.2237s	
13823/33650 (epoch 20.539), train_loss = 0.83976179, grad/param norm = 1.4388e-01, time/batch = 16.7461s	
13824/33650 (epoch 20.541), train_loss = 1.14221762, grad/param norm = 1.6793e-01, time/batch = 17.5638s	
13825/33650 (epoch 20.542), train_loss = 1.05109268, grad/param norm = 1.8470e-01, time/batch = 16.8169s	
13826/33650 (epoch 20.544), train_loss = 1.18821136, grad/param norm = 1.8268e-01, time/batch = 17.4850s	
13827/33650 (epoch 20.545), train_loss = 0.88265528, grad/param norm = 1.3767e-01, time/batch = 17.6426s	
13828/33650 (epoch 20.547), train_loss = 1.04303658, grad/param norm = 1.4947e-01, time/batch = 17.6598s	
13829/33650 (epoch 20.548), train_loss = 1.16786852, grad/param norm = 1.5058e-01, time/batch = 15.9648s	
13830/33650 (epoch 20.550), train_loss = 1.02365552, grad/param norm = 1.4177e-01, time/batch = 15.6273s	
13831/33650 (epoch 20.551), train_loss = 1.04650302, grad/param norm = 1.6499e-01, time/batch = 17.8293s	
13832/33650 (epoch 20.553), train_loss = 0.89798873, grad/param norm = 1.5484e-01, time/batch = 16.4007s	
13833/33650 (epoch 20.554), train_loss = 1.16344892, grad/param norm = 1.6459e-01, time/batch = 17.4836s	
13834/33650 (epoch 20.556), train_loss = 1.10082876, grad/param norm = 2.0206e-01, time/batch = 16.9900s	
13835/33650 (epoch 20.557), train_loss = 1.11467600, grad/param norm = 1.7479e-01, time/batch = 18.1582s	
13836/33650 (epoch 20.559), train_loss = 1.28926749, grad/param norm = 1.9444e-01, time/batch = 16.7076s	
13837/33650 (epoch 20.560), train_loss = 1.22024904, grad/param norm = 1.6466e-01, time/batch = 17.4874s	
13838/33650 (epoch 20.562), train_loss = 1.12058523, grad/param norm = 1.4611e-01, time/batch = 17.9837s	
13839/33650 (epoch 20.563), train_loss = 1.05261010, grad/param norm = 1.5802e-01, time/batch = 17.8137s	
13840/33650 (epoch 20.565), train_loss = 1.02453922, grad/param norm = 1.4990e-01, time/batch = 17.2407s	
13841/33650 (epoch 20.566), train_loss = 1.02089264, grad/param norm = 1.5861e-01, time/batch = 16.9808s	
13842/33650 (epoch 20.568), train_loss = 1.08233028, grad/param norm = 1.8893e-01, time/batch = 18.4691s	
13843/33650 (epoch 20.569), train_loss = 0.95628237, grad/param norm = 1.3688e-01, time/batch = 16.8593s	
13844/33650 (epoch 20.571), train_loss = 1.13704817, grad/param norm = 1.5755e-01, time/batch = 17.3995s	
13845/33650 (epoch 20.572), train_loss = 1.09546413, grad/param norm = 1.4888e-01, time/batch = 18.4032s	
13846/33650 (epoch 20.574), train_loss = 0.98073775, grad/param norm = 1.7727e-01, time/batch = 16.8836s	
13847/33650 (epoch 20.575), train_loss = 1.00605039, grad/param norm = 1.6320e-01, time/batch = 16.5410s	
13848/33650 (epoch 20.577), train_loss = 1.00418785, grad/param norm = 1.5387e-01, time/batch = 17.9701s	
13849/33650 (epoch 20.578), train_loss = 1.10040962, grad/param norm = 1.5330e-01, time/batch = 16.8924s	
13850/33650 (epoch 20.579), train_loss = 1.07941882, grad/param norm = 1.5421e-01, time/batch = 17.4732s	
13851/33650 (epoch 20.581), train_loss = 1.15934018, grad/param norm = 1.6188e-01, time/batch = 18.7246s	
13852/33650 (epoch 20.582), train_loss = 1.08909811, grad/param norm = 1.3419e-01, time/batch = 17.1595s	
13853/33650 (epoch 20.584), train_loss = 1.07824395, grad/param norm = 1.5438e-01, time/batch = 15.3124s	
13854/33650 (epoch 20.585), train_loss = 1.07784123, grad/param norm = 1.7022e-01, time/batch = 16.1251s	
13855/33650 (epoch 20.587), train_loss = 0.94414062, grad/param norm = 1.3995e-01, time/batch = 17.8776s	
13856/33650 (epoch 20.588), train_loss = 0.98375392, grad/param norm = 1.8479e-01, time/batch = 17.6525s	
13857/33650 (epoch 20.590), train_loss = 0.96644131, grad/param norm = 1.3683e-01, time/batch = 17.7235s	
13858/33650 (epoch 20.591), train_loss = 0.95151858, grad/param norm = 1.5036e-01, time/batch = 18.1363s	
13859/33650 (epoch 20.593), train_loss = 0.93527990, grad/param norm = 1.4280e-01, time/batch = 18.9809s	
13860/33650 (epoch 20.594), train_loss = 0.91368883, grad/param norm = 1.5849e-01, time/batch = 17.5663s	
13861/33650 (epoch 20.596), train_loss = 1.00539263, grad/param norm = 1.4092e-01, time/batch = 17.6486s	
13862/33650 (epoch 20.597), train_loss = 0.86852651, grad/param norm = 1.3383e-01, time/batch = 19.2377s	
13863/33650 (epoch 20.599), train_loss = 1.00511932, grad/param norm = 1.6051e-01, time/batch = 17.3058s	
13864/33650 (epoch 20.600), train_loss = 0.92765070, grad/param norm = 1.4305e-01, time/batch = 16.8909s	
13865/33650 (epoch 20.602), train_loss = 1.07109313, grad/param norm = 1.4822e-01, time/batch = 17.9549s	
13866/33650 (epoch 20.603), train_loss = 0.98102107, grad/param norm = 1.6051e-01, time/batch = 16.9776s	
13867/33650 (epoch 20.605), train_loss = 1.06891574, grad/param norm = 1.5283e-01, time/batch = 18.2278s	
13868/33650 (epoch 20.606), train_loss = 1.08019643, grad/param norm = 1.8284e-01, time/batch = 17.9771s	
13869/33650 (epoch 20.608), train_loss = 0.95286395, grad/param norm = 1.7137e-01, time/batch = 17.2067s	
13870/33650 (epoch 20.609), train_loss = 1.02153495, grad/param norm = 1.7040e-01, time/batch = 16.8833s	
13871/33650 (epoch 20.611), train_loss = 0.91446786, grad/param norm = 1.5704e-01, time/batch = 17.2306s	
13872/33650 (epoch 20.612), train_loss = 1.00825763, grad/param norm = 1.6096e-01, time/batch = 18.6506s	
13873/33650 (epoch 20.614), train_loss = 1.10403708, grad/param norm = 1.6640e-01, time/batch = 17.4759s	
13874/33650 (epoch 20.615), train_loss = 1.00473146, grad/param norm = 1.4457e-01, time/batch = 18.1393s	
13875/33650 (epoch 20.617), train_loss = 0.92224910, grad/param norm = 1.2749e-01, time/batch = 19.1510s	
13876/33650 (epoch 20.618), train_loss = 1.00539814, grad/param norm = 1.4509e-01, time/batch = 17.0708s	
13877/33650 (epoch 20.620), train_loss = 1.02800080, grad/param norm = 1.6395e-01, time/batch = 17.5497s	
13878/33650 (epoch 20.621), train_loss = 0.92153197, grad/param norm = 1.4443e-01, time/batch = 18.7141s	
13879/33650 (epoch 20.623), train_loss = 0.99476075, grad/param norm = 1.4357e-01, time/batch = 17.9915s	
13880/33650 (epoch 20.624), train_loss = 0.80199818, grad/param norm = 1.3414e-01, time/batch = 17.5736s	
13881/33650 (epoch 20.626), train_loss = 0.80719037, grad/param norm = 1.2595e-01, time/batch = 17.7076s	
13882/33650 (epoch 20.627), train_loss = 0.91815593, grad/param norm = 1.3733e-01, time/batch = 18.8035s	
13883/33650 (epoch 20.629), train_loss = 0.96462550, grad/param norm = 1.4729e-01, time/batch = 17.4603s	
13884/33650 (epoch 20.630), train_loss = 1.10196377, grad/param norm = 1.6235e-01, time/batch = 18.4739s	
13885/33650 (epoch 20.632), train_loss = 1.14789653, grad/param norm = 1.6723e-01, time/batch = 17.3718s	
13886/33650 (epoch 20.633), train_loss = 1.09259894, grad/param norm = 1.5521e-01, time/batch = 17.6420s	
13887/33650 (epoch 20.634), train_loss = 0.88830921, grad/param norm = 1.3764e-01, time/batch = 16.1298s	
13888/33650 (epoch 20.636), train_loss = 0.77180930, grad/param norm = 1.2278e-01, time/batch = 18.1268s	
13889/33650 (epoch 20.637), train_loss = 0.93502004, grad/param norm = 1.4162e-01, time/batch = 17.4736s	
13890/33650 (epoch 20.639), train_loss = 0.93553780, grad/param norm = 1.3948e-01, time/batch = 16.5601s	
13891/33650 (epoch 20.640), train_loss = 1.01173688, grad/param norm = 1.4001e-01, time/batch = 18.8859s	
13892/33650 (epoch 20.642), train_loss = 1.07369305, grad/param norm = 1.5303e-01, time/batch = 17.8897s	
13893/33650 (epoch 20.643), train_loss = 1.01536439, grad/param norm = 1.5484e-01, time/batch = 18.0535s	
13894/33650 (epoch 20.645), train_loss = 1.01311270, grad/param norm = 1.4378e-01, time/batch = 17.9741s	
13895/33650 (epoch 20.646), train_loss = 0.85622134, grad/param norm = 1.2337e-01, time/batch = 18.8988s	
13896/33650 (epoch 20.648), train_loss = 1.02482382, grad/param norm = 1.4832e-01, time/batch = 18.8069s	
13897/33650 (epoch 20.649), train_loss = 0.96524694, grad/param norm = 1.4990e-01, time/batch = 18.1364s	
13898/33650 (epoch 20.651), train_loss = 1.13223545, grad/param norm = 1.6320e-01, time/batch = 17.8054s	
13899/33650 (epoch 20.652), train_loss = 0.72779517, grad/param norm = 1.2986e-01, time/batch = 17.8100s	
13900/33650 (epoch 20.654), train_loss = 0.91278305, grad/param norm = 1.3646e-01, time/batch = 17.8117s	
13901/33650 (epoch 20.655), train_loss = 0.86917698, grad/param norm = 1.2700e-01, time/batch = 17.3868s	
13902/33650 (epoch 20.657), train_loss = 0.95523549, grad/param norm = 1.5370e-01, time/batch = 19.0646s	
13903/33650 (epoch 20.658), train_loss = 0.84446483, grad/param norm = 1.3647e-01, time/batch = 16.6489s	
13904/33650 (epoch 20.660), train_loss = 0.82223651, grad/param norm = 1.4072e-01, time/batch = 17.9528s	
13905/33650 (epoch 20.661), train_loss = 0.91295481, grad/param norm = 1.2793e-01, time/batch = 17.3839s	
13906/33650 (epoch 20.663), train_loss = 0.86441226, grad/param norm = 1.5001e-01, time/batch = 18.2220s	
13907/33650 (epoch 20.664), train_loss = 0.91239317, grad/param norm = 1.3598e-01, time/batch = 17.9638s	
13908/33650 (epoch 20.666), train_loss = 0.93739415, grad/param norm = 1.2034e-01, time/batch = 15.4737s	
13909/33650 (epoch 20.667), train_loss = 0.85803406, grad/param norm = 1.2407e-01, time/batch = 18.6383s	
13910/33650 (epoch 20.669), train_loss = 0.88988356, grad/param norm = 1.4698e-01, time/batch = 25.0537s	
13911/33650 (epoch 20.670), train_loss = 0.80865902, grad/param norm = 1.4485e-01, time/batch = 22.6742s	
13912/33650 (epoch 20.672), train_loss = 0.86077767, grad/param norm = 1.6524e-01, time/batch = 17.8191s	
13913/33650 (epoch 20.673), train_loss = 0.80429673, grad/param norm = 1.3367e-01, time/batch = 17.2177s	
13914/33650 (epoch 20.675), train_loss = 0.79901802, grad/param norm = 1.1892e-01, time/batch = 17.8177s	
13915/33650 (epoch 20.676), train_loss = 0.96367221, grad/param norm = 1.4392e-01, time/batch = 18.1451s	
13916/33650 (epoch 20.678), train_loss = 0.91927537, grad/param norm = 1.5605e-01, time/batch = 16.6270s	
13917/33650 (epoch 20.679), train_loss = 0.92228407, grad/param norm = 1.5650e-01, time/batch = 18.6398s	
13918/33650 (epoch 20.681), train_loss = 0.94124115, grad/param norm = 1.3674e-01, time/batch = 18.3179s	
13919/33650 (epoch 20.682), train_loss = 0.88485107, grad/param norm = 1.4871e-01, time/batch = 17.3981s	
13920/33650 (epoch 20.684), train_loss = 0.85595045, grad/param norm = 1.4144e-01, time/batch = 18.2200s	
13921/33650 (epoch 20.685), train_loss = 1.02818988, grad/param norm = 1.4655e-01, time/batch = 17.5676s	
13922/33650 (epoch 20.686), train_loss = 0.98702694, grad/param norm = 1.3940e-01, time/batch = 18.7975s	
13923/33650 (epoch 20.688), train_loss = 1.05512802, grad/param norm = 1.4707e-01, time/batch = 17.5324s	
13924/33650 (epoch 20.689), train_loss = 0.89018259, grad/param norm = 1.4041e-01, time/batch = 19.1443s	
13925/33650 (epoch 20.691), train_loss = 1.08817318, grad/param norm = 1.6053e-01, time/batch = 18.8043s	
13926/33650 (epoch 20.692), train_loss = 1.10480821, grad/param norm = 1.5389e-01, time/batch = 16.3786s	
13927/33650 (epoch 20.694), train_loss = 1.00518892, grad/param norm = 1.6214e-01, time/batch = 18.0650s	
13928/33650 (epoch 20.695), train_loss = 0.72878001, grad/param norm = 1.4094e-01, time/batch = 18.8124s	
13929/33650 (epoch 20.697), train_loss = 0.94265917, grad/param norm = 1.3988e-01, time/batch = 17.5707s	
13930/33650 (epoch 20.698), train_loss = 1.12924211, grad/param norm = 1.5804e-01, time/batch = 17.3905s	
13931/33650 (epoch 20.700), train_loss = 0.95065281, grad/param norm = 1.4256e-01, time/batch = 17.6360s	
13932/33650 (epoch 20.701), train_loss = 1.00134119, grad/param norm = 1.5980e-01, time/batch = 15.6396s	
13933/33650 (epoch 20.703), train_loss = 1.13535005, grad/param norm = 1.4260e-01, time/batch = 17.5554s	
13934/33650 (epoch 20.704), train_loss = 0.93952706, grad/param norm = 1.3171e-01, time/batch = 18.0619s	
13935/33650 (epoch 20.706), train_loss = 0.93912861, grad/param norm = 1.4530e-01, time/batch = 17.8874s	
13936/33650 (epoch 20.707), train_loss = 1.07292893, grad/param norm = 1.3927e-01, time/batch = 17.0626s	
13937/33650 (epoch 20.709), train_loss = 0.95206333, grad/param norm = 1.4155e-01, time/batch = 18.4866s	
13938/33650 (epoch 20.710), train_loss = 1.15177106, grad/param norm = 1.5131e-01, time/batch = 18.0628s	
13939/33650 (epoch 20.712), train_loss = 0.88663747, grad/param norm = 1.4215e-01, time/batch = 17.3055s	
13940/33650 (epoch 20.713), train_loss = 0.89368080, grad/param norm = 1.7880e-01, time/batch = 17.4081s	
13941/33650 (epoch 20.715), train_loss = 1.05093213, grad/param norm = 1.6653e-01, time/batch = 16.4052s	
13942/33650 (epoch 20.716), train_loss = 0.89173242, grad/param norm = 1.4478e-01, time/batch = 18.4887s	
13943/33650 (epoch 20.718), train_loss = 0.92348995, grad/param norm = 1.4572e-01, time/batch = 15.8971s	
13944/33650 (epoch 20.719), train_loss = 1.11258516, grad/param norm = 1.6969e-01, time/batch = 17.9726s	
13945/33650 (epoch 20.721), train_loss = 1.19963800, grad/param norm = 1.7830e-01, time/batch = 17.7550s	
13946/33650 (epoch 20.722), train_loss = 1.05849609, grad/param norm = 1.6847e-01, time/batch = 17.3133s	
13947/33650 (epoch 20.724), train_loss = 1.09067393, grad/param norm = 1.6377e-01, time/batch = 16.7402s	
13948/33650 (epoch 20.725), train_loss = 1.08143910, grad/param norm = 1.6757e-01, time/batch = 16.8977s	
13949/33650 (epoch 20.727), train_loss = 0.90544320, grad/param norm = 1.6252e-01, time/batch = 16.7372s	
13950/33650 (epoch 20.728), train_loss = 0.94094440, grad/param norm = 1.4497e-01, time/batch = 17.0582s	
13951/33650 (epoch 20.730), train_loss = 1.03270416, grad/param norm = 1.5561e-01, time/batch = 18.1511s	
13952/33650 (epoch 20.731), train_loss = 1.12064252, grad/param norm = 1.6315e-01, time/batch = 16.9868s	
13953/33650 (epoch 20.733), train_loss = 0.98312253, grad/param norm = 1.4731e-01, time/batch = 15.3646s	
13954/33650 (epoch 20.734), train_loss = 1.11407937, grad/param norm = 1.8190e-01, time/batch = 17.5660s	
13955/33650 (epoch 20.736), train_loss = 0.99613341, grad/param norm = 1.5225e-01, time/batch = 17.2498s	
13956/33650 (epoch 20.737), train_loss = 1.03660899, grad/param norm = 1.6955e-01, time/batch = 17.0638s	
13957/33650 (epoch 20.738), train_loss = 0.87795403, grad/param norm = 1.3923e-01, time/batch = 16.4720s	
13958/33650 (epoch 20.740), train_loss = 0.84267970, grad/param norm = 1.4112e-01, time/batch = 17.6440s	
13959/33650 (epoch 20.741), train_loss = 0.89469287, grad/param norm = 1.4192e-01, time/batch = 17.9936s	
13960/33650 (epoch 20.743), train_loss = 0.97832026, grad/param norm = 1.4420e-01, time/batch = 17.0618s	
13961/33650 (epoch 20.744), train_loss = 1.03143453, grad/param norm = 1.3888e-01, time/batch = 16.6165s	
13962/33650 (epoch 20.746), train_loss = 0.95996876, grad/param norm = 1.3938e-01, time/batch = 17.6521s	
13963/33650 (epoch 20.747), train_loss = 1.09759691, grad/param norm = 1.5075e-01, time/batch = 17.7390s	
13964/33650 (epoch 20.749), train_loss = 0.83115853, grad/param norm = 1.3810e-01, time/batch = 15.8195s	
13965/33650 (epoch 20.750), train_loss = 1.11071237, grad/param norm = 1.5929e-01, time/batch = 17.9092s	
13966/33650 (epoch 20.752), train_loss = 1.09303698, grad/param norm = 1.4405e-01, time/batch = 16.1447s	
13967/33650 (epoch 20.753), train_loss = 1.17281738, grad/param norm = 1.6424e-01, time/batch = 16.5341s	
13968/33650 (epoch 20.755), train_loss = 0.95416271, grad/param norm = 1.2950e-01, time/batch = 16.0705s	
13969/33650 (epoch 20.756), train_loss = 1.06237364, grad/param norm = 1.5380e-01, time/batch = 18.0753s	
13970/33650 (epoch 20.758), train_loss = 1.05580279, grad/param norm = 1.3640e-01, time/batch = 18.1493s	
13971/33650 (epoch 20.759), train_loss = 1.11481276, grad/param norm = 1.6705e-01, time/batch = 16.5593s	
13972/33650 (epoch 20.761), train_loss = 1.02910316, grad/param norm = 1.5710e-01, time/batch = 17.3981s	
13973/33650 (epoch 20.762), train_loss = 1.00451181, grad/param norm = 1.5136e-01, time/batch = 17.1410s	
13974/33650 (epoch 20.764), train_loss = 1.04883017, grad/param norm = 1.5709e-01, time/batch = 16.6347s	
13975/33650 (epoch 20.765), train_loss = 0.99106476, grad/param norm = 1.5327e-01, time/batch = 17.8212s	
13976/33650 (epoch 20.767), train_loss = 0.97816979, grad/param norm = 1.3686e-01, time/batch = 15.3885s	
13977/33650 (epoch 20.768), train_loss = 0.86416800, grad/param norm = 1.5326e-01, time/batch = 18.2371s	
13978/33650 (epoch 20.770), train_loss = 1.03163517, grad/param norm = 1.4816e-01, time/batch = 16.3143s	
13979/33650 (epoch 20.771), train_loss = 1.02419851, grad/param norm = 1.5500e-01, time/batch = 17.3984s	
13980/33650 (epoch 20.773), train_loss = 1.13829085, grad/param norm = 1.6731e-01, time/batch = 17.7447s	
13981/33650 (epoch 20.774), train_loss = 1.03361123, grad/param norm = 1.5402e-01, time/batch = 16.7090s	
13982/33650 (epoch 20.776), train_loss = 1.07952111, grad/param norm = 1.5494e-01, time/batch = 17.1475s	
13983/33650 (epoch 20.777), train_loss = 0.89748492, grad/param norm = 1.4021e-01, time/batch = 17.4012s	
13984/33650 (epoch 20.779), train_loss = 0.95801512, grad/param norm = 1.3895e-01, time/batch = 16.9827s	
13985/33650 (epoch 20.780), train_loss = 0.88287120, grad/param norm = 1.2404e-01, time/batch = 16.1441s	
13986/33650 (epoch 20.782), train_loss = 0.92447537, grad/param norm = 1.4423e-01, time/batch = 17.9762s	
13987/33650 (epoch 20.783), train_loss = 0.89047960, grad/param norm = 1.3188e-01, time/batch = 16.2396s	
13988/33650 (epoch 20.785), train_loss = 1.18920491, grad/param norm = 1.4457e-01, time/batch = 17.1451s	
13989/33650 (epoch 20.786), train_loss = 1.05677111, grad/param norm = 1.3916e-01, time/batch = 17.7287s	
13990/33650 (epoch 20.788), train_loss = 1.04342147, grad/param norm = 1.4466e-01, time/batch = 17.2172s	
13991/33650 (epoch 20.789), train_loss = 1.08812504, grad/param norm = 1.8512e-01, time/batch = 17.0574s	
13992/33650 (epoch 20.790), train_loss = 1.01764641, grad/param norm = 1.5603e-01, time/batch = 15.2917s	
13993/33650 (epoch 20.792), train_loss = 1.11678348, grad/param norm = 1.6512e-01, time/batch = 17.2367s	
13994/33650 (epoch 20.793), train_loss = 1.07975118, grad/param norm = 1.8014e-01, time/batch = 17.9851s	
13995/33650 (epoch 20.795), train_loss = 1.13047707, grad/param norm = 1.5616e-01, time/batch = 16.4722s	
13996/33650 (epoch 20.796), train_loss = 0.97297289, grad/param norm = 1.4966e-01, time/batch = 16.9756s	
13997/33650 (epoch 20.798), train_loss = 0.95782229, grad/param norm = 1.4632e-01, time/batch = 18.0639s	
13998/33650 (epoch 20.799), train_loss = 1.01133468, grad/param norm = 1.3495e-01, time/batch = 16.3163s	
13999/33650 (epoch 20.801), train_loss = 1.03120573, grad/param norm = 1.7986e-01, time/batch = 15.7383s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch20.80_1.5879.t7	
14000/33650 (epoch 20.802), train_loss = 1.10238729, grad/param norm = 1.5026e-01, time/batch = 16.9021s	
14001/33650 (epoch 20.804), train_loss = 1.39794852, grad/param norm = 1.9451e-01, time/batch = 17.3159s	
14002/33650 (epoch 20.805), train_loss = 0.97837199, grad/param norm = 1.2235e-01, time/batch = 16.6479s	
14003/33650 (epoch 20.807), train_loss = 1.20748277, grad/param norm = 1.8945e-01, time/batch = 17.8318s	
14004/33650 (epoch 20.808), train_loss = 1.26109483, grad/param norm = 1.8112e-01, time/batch = 17.9070s	
14005/33650 (epoch 20.810), train_loss = 1.04761725, grad/param norm = 1.5624e-01, time/batch = 16.2961s	
14006/33650 (epoch 20.811), train_loss = 1.03336869, grad/param norm = 1.4539e-01, time/batch = 16.7985s	
14007/33650 (epoch 20.813), train_loss = 0.94949067, grad/param norm = 1.3798e-01, time/batch = 18.0626s	
14008/33650 (epoch 20.814), train_loss = 1.09289583, grad/param norm = 1.5993e-01, time/batch = 17.5565s	
14009/33650 (epoch 20.816), train_loss = 1.07826438, grad/param norm = 1.5684e-01, time/batch = 17.4798s	
14010/33650 (epoch 20.817), train_loss = 1.08533660, grad/param norm = 1.6390e-01, time/batch = 16.9065s	
14011/33650 (epoch 20.819), train_loss = 1.05302326, grad/param norm = 1.5649e-01, time/batch = 17.4068s	
14012/33650 (epoch 20.820), train_loss = 1.14127068, grad/param norm = 1.5647e-01, time/batch = 16.8026s	
14013/33650 (epoch 20.822), train_loss = 1.05382322, grad/param norm = 1.7752e-01, time/batch = 17.6549s	
14014/33650 (epoch 20.823), train_loss = 0.96750346, grad/param norm = 1.6605e-01, time/batch = 16.3029s	
14015/33650 (epoch 20.825), train_loss = 1.01392071, grad/param norm = 1.5260e-01, time/batch = 16.9804s	
14016/33650 (epoch 20.826), train_loss = 1.08469522, grad/param norm = 1.4692e-01, time/batch = 16.3203s	
14017/33650 (epoch 20.828), train_loss = 1.18476623, grad/param norm = 1.5920e-01, time/batch = 17.4009s	
14018/33650 (epoch 20.829), train_loss = 0.85182722, grad/param norm = 1.2346e-01, time/batch = 17.0615s	
14019/33650 (epoch 20.831), train_loss = 1.07890816, grad/param norm = 1.4924e-01, time/batch = 16.7192s	
14020/33650 (epoch 20.832), train_loss = 1.09194068, grad/param norm = 1.7184e-01, time/batch = 15.7470s	
14021/33650 (epoch 20.834), train_loss = 1.07426931, grad/param norm = 1.7319e-01, time/batch = 17.3195s	
14022/33650 (epoch 20.835), train_loss = 1.25658833, grad/param norm = 1.6653e-01, time/batch = 14.8754s	
14023/33650 (epoch 20.837), train_loss = 1.05096509, grad/param norm = 1.6680e-01, time/batch = 16.7204s	
14024/33650 (epoch 20.838), train_loss = 1.02749488, grad/param norm = 1.6178e-01, time/batch = 17.9707s	
14025/33650 (epoch 20.840), train_loss = 1.09092201, grad/param norm = 1.4670e-01, time/batch = 16.9108s	
14026/33650 (epoch 20.841), train_loss = 0.96751026, grad/param norm = 1.8353e-01, time/batch = 16.5697s	
14027/33650 (epoch 20.842), train_loss = 1.00279844, grad/param norm = 1.4581e-01, time/batch = 17.4828s	
14028/33650 (epoch 20.844), train_loss = 1.17245821, grad/param norm = 1.5959e-01, time/batch = 17.9854s	
14029/33650 (epoch 20.845), train_loss = 0.97645782, grad/param norm = 1.5035e-01, time/batch = 16.9841s	
14030/33650 (epoch 20.847), train_loss = 0.78459111, grad/param norm = 1.2955e-01, time/batch = 16.0489s	
14031/33650 (epoch 20.848), train_loss = 0.87443913, grad/param norm = 1.4548e-01, time/batch = 17.0643s	
14032/33650 (epoch 20.850), train_loss = 0.97535618, grad/param norm = 1.5159e-01, time/batch = 17.2358s	
14033/33650 (epoch 20.851), train_loss = 0.82052812, grad/param norm = 1.1691e-01, time/batch = 16.5797s	
14034/33650 (epoch 20.853), train_loss = 0.99540652, grad/param norm = 1.5631e-01, time/batch = 16.4695s	
14035/33650 (epoch 20.854), train_loss = 1.11354822, grad/param norm = 1.7966e-01, time/batch = 17.7465s	
14036/33650 (epoch 20.856), train_loss = 0.77419301, grad/param norm = 1.3467e-01, time/batch = 17.1429s	
14037/33650 (epoch 20.857), train_loss = 1.02048108, grad/param norm = 1.3892e-01, time/batch = 16.9813s	
14038/33650 (epoch 20.859), train_loss = 0.89091117, grad/param norm = 1.2395e-01, time/batch = 15.1499s	
14039/33650 (epoch 20.860), train_loss = 0.83975397, grad/param norm = 1.3423e-01, time/batch = 17.9007s	
14040/33650 (epoch 20.862), train_loss = 0.90318060, grad/param norm = 1.4411e-01, time/batch = 16.5609s	
14041/33650 (epoch 20.863), train_loss = 1.13336809, grad/param norm = 1.4830e-01, time/batch = 17.4092s	
14042/33650 (epoch 20.865), train_loss = 0.95826410, grad/param norm = 1.2997e-01, time/batch = 17.3915s	
14043/33650 (epoch 20.866), train_loss = 0.90722846, grad/param norm = 1.4579e-01, time/batch = 17.1459s	
14044/33650 (epoch 20.868), train_loss = 0.88209108, grad/param norm = 1.5243e-01, time/batch = 16.0787s	
14045/33650 (epoch 20.869), train_loss = 1.09424406, grad/param norm = 1.5532e-01, time/batch = 17.2317s	
14046/33650 (epoch 20.871), train_loss = 0.86292142, grad/param norm = 1.2124e-01, time/batch = 17.3870s	
14047/33650 (epoch 20.872), train_loss = 1.00651459, grad/param norm = 1.5755e-01, time/batch = 16.2259s	
14048/33650 (epoch 20.874), train_loss = 1.06853004, grad/param norm = 1.6272e-01, time/batch = 16.4885s	
14049/33650 (epoch 20.875), train_loss = 0.97747217, grad/param norm = 1.4351e-01, time/batch = 15.5663s	
14050/33650 (epoch 20.877), train_loss = 1.16491611, grad/param norm = 1.5226e-01, time/batch = 17.2447s	
14051/33650 (epoch 20.878), train_loss = 0.70039581, grad/param norm = 1.2855e-01, time/batch = 17.8834s	
14052/33650 (epoch 20.880), train_loss = 1.04334682, grad/param norm = 1.7442e-01, time/batch = 17.4844s	
14053/33650 (epoch 20.881), train_loss = 0.94736721, grad/param norm = 1.6068e-01, time/batch = 17.7368s	
14054/33650 (epoch 20.883), train_loss = 1.03269249, grad/param norm = 1.4928e-01, time/batch = 16.4047s	
14055/33650 (epoch 20.884), train_loss = 1.11334357, grad/param norm = 1.8240e-01, time/batch = 17.3199s	
14056/33650 (epoch 20.886), train_loss = 1.07462981, grad/param norm = 1.5476e-01, time/batch = 17.5664s	
14057/33650 (epoch 20.887), train_loss = 0.91519120, grad/param norm = 1.3558e-01, time/batch = 17.3946s	
14058/33650 (epoch 20.889), train_loss = 1.00020425, grad/param norm = 1.5832e-01, time/batch = 16.7209s	
14059/33650 (epoch 20.890), train_loss = 1.04487270, grad/param norm = 1.4117e-01, time/batch = 14.9767s	
14060/33650 (epoch 20.892), train_loss = 1.00328435, grad/param norm = 1.6814e-01, time/batch = 15.8090s	
14061/33650 (epoch 20.893), train_loss = 1.04236640, grad/param norm = 1.4975e-01, time/batch = 16.2361s	
14062/33650 (epoch 20.895), train_loss = 1.12424712, grad/param norm = 1.5604e-01, time/batch = 17.1383s	
14063/33650 (epoch 20.896), train_loss = 0.92543755, grad/param norm = 1.4622e-01, time/batch = 17.5660s	
14064/33650 (epoch 20.897), train_loss = 0.84216393, grad/param norm = 1.3338e-01, time/batch = 16.1368s	
14065/33650 (epoch 20.899), train_loss = 0.88847495, grad/param norm = 1.2729e-01, time/batch = 17.2265s	
14066/33650 (epoch 20.900), train_loss = 0.81705114, grad/param norm = 1.2724e-01, time/batch = 16.6578s	
14067/33650 (epoch 20.902), train_loss = 1.02818898, grad/param norm = 2.0131e-01, time/batch = 17.9916s	
14068/33650 (epoch 20.903), train_loss = 0.95828166, grad/param norm = 1.6292e-01, time/batch = 16.9839s	
14069/33650 (epoch 20.905), train_loss = 1.11974503, grad/param norm = 1.6072e-01, time/batch = 17.5644s	
14070/33650 (epoch 20.906), train_loss = 0.92667734, grad/param norm = 1.4363e-01, time/batch = 16.9036s	
14071/33650 (epoch 20.908), train_loss = 0.96629610, grad/param norm = 1.3734e-01, time/batch = 16.7239s	
14072/33650 (epoch 20.909), train_loss = 0.94223459, grad/param norm = 1.3833e-01, time/batch = 16.9702s	
14073/33650 (epoch 20.911), train_loss = 0.82402718, grad/param norm = 1.2759e-01, time/batch = 17.5710s	
14074/33650 (epoch 20.912), train_loss = 0.81727699, grad/param norm = 1.3020e-01, time/batch = 18.2293s	
14075/33650 (epoch 20.914), train_loss = 0.99467285, grad/param norm = 1.3303e-01, time/batch = 16.7184s	
14076/33650 (epoch 20.915), train_loss = 0.95409060, grad/param norm = 1.5122e-01, time/batch = 17.8260s	
14077/33650 (epoch 20.917), train_loss = 0.96080356, grad/param norm = 1.4589e-01, time/batch = 17.9836s	
14078/33650 (epoch 20.918), train_loss = 0.82015398, grad/param norm = 1.1899e-01, time/batch = 16.2973s	
14079/33650 (epoch 20.920), train_loss = 0.88782786, grad/param norm = 1.3043e-01, time/batch = 16.8125s	
14080/33650 (epoch 20.921), train_loss = 0.89848987, grad/param norm = 1.3854e-01, time/batch = 16.1379s	
14081/33650 (epoch 20.923), train_loss = 0.86017222, grad/param norm = 1.4036e-01, time/batch = 17.7205s	
14082/33650 (epoch 20.924), train_loss = 0.98240395, grad/param norm = 1.4896e-01, time/batch = 16.9005s	
14083/33650 (epoch 20.926), train_loss = 0.92211079, grad/param norm = 1.5261e-01, time/batch = 16.9082s	
14084/33650 (epoch 20.927), train_loss = 0.94367120, grad/param norm = 1.4746e-01, time/batch = 16.7390s	
14085/33650 (epoch 20.929), train_loss = 1.03264872, grad/param norm = 1.4410e-01, time/batch = 17.9864s	
14086/33650 (epoch 20.930), train_loss = 0.92059256, grad/param norm = 1.3964e-01, time/batch = 16.8111s	
14087/33650 (epoch 20.932), train_loss = 0.95301017, grad/param norm = 1.4412e-01, time/batch = 17.6661s	
14088/33650 (epoch 20.933), train_loss = 0.85668473, grad/param norm = 1.4201e-01, time/batch = 17.7268s	
14089/33650 (epoch 20.935), train_loss = 0.86248848, grad/param norm = 1.3516e-01, time/batch = 15.9780s	
14090/33650 (epoch 20.936), train_loss = 0.91190955, grad/param norm = 1.3367e-01, time/batch = 18.1533s	
14091/33650 (epoch 20.938), train_loss = 0.84184480, grad/param norm = 1.3705e-01, time/batch = 17.1672s	
14092/33650 (epoch 20.939), train_loss = 1.04852320, grad/param norm = 1.4749e-01, time/batch = 16.5774s	
14093/33650 (epoch 20.941), train_loss = 0.98374432, grad/param norm = 1.3445e-01, time/batch = 17.5541s	
14094/33650 (epoch 20.942), train_loss = 1.05918697, grad/param norm = 1.5688e-01, time/batch = 17.9037s	
14095/33650 (epoch 20.944), train_loss = 0.96005974, grad/param norm = 1.3443e-01, time/batch = 18.1569s	
14096/33650 (epoch 20.945), train_loss = 1.02518922, grad/param norm = 1.5692e-01, time/batch = 17.3005s	
14097/33650 (epoch 20.947), train_loss = 1.11599559, grad/param norm = 1.8924e-01, time/batch = 17.7416s	
14098/33650 (epoch 20.948), train_loss = 1.12457786, grad/param norm = 1.5556e-01, time/batch = 17.4951s	
14099/33650 (epoch 20.949), train_loss = 0.86170557, grad/param norm = 1.3235e-01, time/batch = 16.1622s	
14100/33650 (epoch 20.951), train_loss = 1.12060232, grad/param norm = 1.6044e-01, time/batch = 16.0565s	
14101/33650 (epoch 20.952), train_loss = 1.06284553, grad/param norm = 1.5693e-01, time/batch = 16.4568s	
14102/33650 (epoch 20.954), train_loss = 1.06392377, grad/param norm = 1.4163e-01, time/batch = 16.6415s	
14103/33650 (epoch 20.955), train_loss = 1.04071344, grad/param norm = 1.4360e-01, time/batch = 16.4036s	
14104/33650 (epoch 20.957), train_loss = 1.05228629, grad/param norm = 1.6291e-01, time/batch = 18.2412s	
14105/33650 (epoch 20.958), train_loss = 0.78365617, grad/param norm = 1.2873e-01, time/batch = 16.8239s	
14106/33650 (epoch 20.960), train_loss = 0.81666898, grad/param norm = 1.2828e-01, time/batch = 17.2388s	
14107/33650 (epoch 20.961), train_loss = 0.88285045, grad/param norm = 1.4551e-01, time/batch = 17.6553s	
14108/33650 (epoch 20.963), train_loss = 0.92946425, grad/param norm = 1.5798e-01, time/batch = 17.1592s	
14109/33650 (epoch 20.964), train_loss = 1.05016645, grad/param norm = 1.6137e-01, time/batch = 17.6624s	
14110/33650 (epoch 20.966), train_loss = 0.99805283, grad/param norm = 1.3307e-01, time/batch = 27.5066s	
14111/33650 (epoch 20.967), train_loss = 1.01656802, grad/param norm = 1.5126e-01, time/batch = 17.5702s	
14112/33650 (epoch 20.969), train_loss = 0.97508493, grad/param norm = 1.3619e-01, time/batch = 18.0000s	
14113/33650 (epoch 20.970), train_loss = 1.02604730, grad/param norm = 1.6964e-01, time/batch = 16.4070s	
14114/33650 (epoch 20.972), train_loss = 1.28641060, grad/param norm = 1.6009e-01, time/batch = 16.9042s	
14115/33650 (epoch 20.973), train_loss = 0.89230690, grad/param norm = 1.3149e-01, time/batch = 16.3174s	
14116/33650 (epoch 20.975), train_loss = 0.87861345, grad/param norm = 1.3288e-01, time/batch = 15.7243s	
14117/33650 (epoch 20.976), train_loss = 0.88570971, grad/param norm = 1.1768e-01, time/batch = 15.6434s	
14118/33650 (epoch 20.978), train_loss = 0.92176752, grad/param norm = 1.4495e-01, time/batch = 18.0657s	
14119/33650 (epoch 20.979), train_loss = 0.96631467, grad/param norm = 1.5198e-01, time/batch = 17.7248s	
14120/33650 (epoch 20.981), train_loss = 0.91084209, grad/param norm = 1.1528e-01, time/batch = 16.8143s	
14121/33650 (epoch 20.982), train_loss = 1.01423613, grad/param norm = 1.4222e-01, time/batch = 17.7196s	
14122/33650 (epoch 20.984), train_loss = 0.82088498, grad/param norm = 1.3298e-01, time/batch = 17.2347s	
14123/33650 (epoch 20.985), train_loss = 0.85953901, grad/param norm = 1.6688e-01, time/batch = 17.0518s	
14124/33650 (epoch 20.987), train_loss = 0.96328995, grad/param norm = 1.3679e-01, time/batch = 17.3160s	
14125/33650 (epoch 20.988), train_loss = 0.98772915, grad/param norm = 1.6642e-01, time/batch = 17.4011s	
14126/33650 (epoch 20.990), train_loss = 1.17396870, grad/param norm = 1.6595e-01, time/batch = 18.1606s	
14127/33650 (epoch 20.991), train_loss = 1.02987894, grad/param norm = 1.5810e-01, time/batch = 16.9713s	
14128/33650 (epoch 20.993), train_loss = 1.00887668, grad/param norm = 1.6304e-01, time/batch = 17.3979s	
14129/33650 (epoch 20.994), train_loss = 0.95498535, grad/param norm = 1.4162e-01, time/batch = 17.7966s	
14130/33650 (epoch 20.996), train_loss = 0.90895844, grad/param norm = 1.4597e-01, time/batch = 16.3849s	
14131/33650 (epoch 20.997), train_loss = 1.04375852, grad/param norm = 1.5232e-01, time/batch = 17.9775s	
14132/33650 (epoch 20.999), train_loss = 0.91602247, grad/param norm = 1.4014e-01, time/batch = 17.1636s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
14133/33650 (epoch 21.000), train_loss = 1.06302968, grad/param norm = 1.7853e-01, time/batch = 14.8903s	
14134/33650 (epoch 21.001), train_loss = 1.15077839, grad/param norm = 1.5592e-01, time/batch = 14.2901s	
14135/33650 (epoch 21.003), train_loss = 1.13605578, grad/param norm = 1.8817e-01, time/batch = 15.8806s	
14136/33650 (epoch 21.004), train_loss = 1.01625023, grad/param norm = 1.5357e-01, time/batch = 14.1103s	
14137/33650 (epoch 21.006), train_loss = 0.94597968, grad/param norm = 1.4130e-01, time/batch = 14.2343s	
14138/33650 (epoch 21.007), train_loss = 1.03978117, grad/param norm = 1.5644e-01, time/batch = 16.3941s	
14139/33650 (epoch 21.009), train_loss = 0.93791604, grad/param norm = 1.4170e-01, time/batch = 17.1385s	
14140/33650 (epoch 21.010), train_loss = 1.08015464, grad/param norm = 1.6602e-01, time/batch = 17.3172s	
14141/33650 (epoch 21.012), train_loss = 0.90535505, grad/param norm = 1.3084e-01, time/batch = 16.9794s	
14142/33650 (epoch 21.013), train_loss = 0.98527193, grad/param norm = 1.6306e-01, time/batch = 16.9928s	
14143/33650 (epoch 21.015), train_loss = 0.94249501, grad/param norm = 1.4770e-01, time/batch = 17.4029s	
14144/33650 (epoch 21.016), train_loss = 0.88445684, grad/param norm = 1.5075e-01, time/batch = 18.0787s	
14145/33650 (epoch 21.018), train_loss = 0.97199520, grad/param norm = 1.6621e-01, time/batch = 16.2898s	
14146/33650 (epoch 21.019), train_loss = 0.92568398, grad/param norm = 1.4767e-01, time/batch = 15.6328s	
14147/33650 (epoch 21.021), train_loss = 1.02120830, grad/param norm = 1.4759e-01, time/batch = 17.3265s	
14148/33650 (epoch 21.022), train_loss = 0.92570586, grad/param norm = 1.3001e-01, time/batch = 17.4807s	
14149/33650 (epoch 21.024), train_loss = 0.88589380, grad/param norm = 1.5289e-01, time/batch = 17.4851s	
14150/33650 (epoch 21.025), train_loss = 0.97002099, grad/param norm = 1.6260e-01, time/batch = 17.7485s	
14151/33650 (epoch 21.027), train_loss = 1.03290875, grad/param norm = 1.5287e-01, time/batch = 17.3268s	
14152/33650 (epoch 21.028), train_loss = 1.06725515, grad/param norm = 1.5036e-01, time/batch = 16.9008s	
14153/33650 (epoch 21.030), train_loss = 0.98540706, grad/param norm = 1.5551e-01, time/batch = 17.1562s	
14154/33650 (epoch 21.031), train_loss = 0.87783029, grad/param norm = 1.3662e-01, time/batch = 17.1625s	
14155/33650 (epoch 21.033), train_loss = 0.96046201, grad/param norm = 1.2707e-01, time/batch = 16.6370s	
14156/33650 (epoch 21.034), train_loss = 0.99640165, grad/param norm = 1.4574e-01, time/batch = 16.4918s	
14157/33650 (epoch 21.036), train_loss = 1.10967657, grad/param norm = 1.6648e-01, time/batch = 17.9050s	
14158/33650 (epoch 21.037), train_loss = 0.94368035, grad/param norm = 1.4389e-01, time/batch = 15.9704s	
14159/33650 (epoch 21.039), train_loss = 1.06978147, grad/param norm = 1.6337e-01, time/batch = 14.2828s	
14160/33650 (epoch 21.040), train_loss = 1.16881927, grad/param norm = 1.8351e-01, time/batch = 16.9064s	
14161/33650 (epoch 21.042), train_loss = 1.17481716, grad/param norm = 1.6476e-01, time/batch = 17.1575s	
14162/33650 (epoch 21.043), train_loss = 0.93701919, grad/param norm = 1.4520e-01, time/batch = 16.5461s	
14163/33650 (epoch 21.045), train_loss = 0.90771475, grad/param norm = 1.3893e-01, time/batch = 17.3111s	
14164/33650 (epoch 21.046), train_loss = 1.05590974, grad/param norm = 1.5367e-01, time/batch = 16.9849s	
14165/33650 (epoch 21.048), train_loss = 1.08193084, grad/param norm = 1.4235e-01, time/batch = 17.8993s	
14166/33650 (epoch 21.049), train_loss = 0.99832254, grad/param norm = 1.6748e-01, time/batch = 15.9853s	
14167/33650 (epoch 21.051), train_loss = 1.12513181, grad/param norm = 1.6739e-01, time/batch = 17.8251s	
14168/33650 (epoch 21.052), train_loss = 1.10653205, grad/param norm = 1.7232e-01, time/batch = 16.5576s	
14169/33650 (epoch 21.053), train_loss = 1.02830150, grad/param norm = 1.3668e-01, time/batch = 16.3087s	
14170/33650 (epoch 21.055), train_loss = 0.87530981, grad/param norm = 1.3685e-01, time/batch = 16.9880s	
14171/33650 (epoch 21.056), train_loss = 0.85685134, grad/param norm = 1.2090e-01, time/batch = 16.0601s	
14172/33650 (epoch 21.058), train_loss = 1.07554002, grad/param norm = 1.5697e-01, time/batch = 16.8940s	
14173/33650 (epoch 21.059), train_loss = 1.04231587, grad/param norm = 1.5462e-01, time/batch = 16.5603s	
14174/33650 (epoch 21.061), train_loss = 1.06821477, grad/param norm = 1.6029e-01, time/batch = 15.4820s	
14175/33650 (epoch 21.062), train_loss = 1.05132865, grad/param norm = 1.4032e-01, time/batch = 16.0615s	
14176/33650 (epoch 21.064), train_loss = 0.95616874, grad/param norm = 1.4929e-01, time/batch = 16.2216s	
14177/33650 (epoch 21.065), train_loss = 0.94592420, grad/param norm = 1.4156e-01, time/batch = 15.6390s	
14178/33650 (epoch 21.067), train_loss = 0.86723061, grad/param norm = 1.3116e-01, time/batch = 17.7417s	
14179/33650 (epoch 21.068), train_loss = 0.99250810, grad/param norm = 1.5730e-01, time/batch = 17.5783s	
14180/33650 (epoch 21.070), train_loss = 1.03039578, grad/param norm = 1.5572e-01, time/batch = 16.4786s	
14181/33650 (epoch 21.071), train_loss = 0.99101881, grad/param norm = 1.4210e-01, time/batch = 16.8205s	
14182/33650 (epoch 21.073), train_loss = 1.02706218, grad/param norm = 1.5031e-01, time/batch = 18.2355s	
14183/33650 (epoch 21.074), train_loss = 1.11791162, grad/param norm = 1.4580e-01, time/batch = 17.9085s	
14184/33650 (epoch 21.076), train_loss = 1.07216201, grad/param norm = 1.6133e-01, time/batch = 16.5569s	
14185/33650 (epoch 21.077), train_loss = 0.98718730, grad/param norm = 1.4512e-01, time/batch = 15.7007s	
14186/33650 (epoch 21.079), train_loss = 1.00069199, grad/param norm = 1.4179e-01, time/batch = 17.6442s	
14187/33650 (epoch 21.080), train_loss = 1.02717740, grad/param norm = 1.5430e-01, time/batch = 16.1452s	
14188/33650 (epoch 21.082), train_loss = 1.01129426, grad/param norm = 1.3708e-01, time/batch = 16.2440s	
14189/33650 (epoch 21.083), train_loss = 1.05387733, grad/param norm = 1.5306e-01, time/batch = 18.0663s	
14190/33650 (epoch 21.085), train_loss = 1.08382224, grad/param norm = 1.4578e-01, time/batch = 16.9892s	
14191/33650 (epoch 21.086), train_loss = 1.08173627, grad/param norm = 1.7112e-01, time/batch = 15.8013s	
14192/33650 (epoch 21.088), train_loss = 1.02404483, grad/param norm = 1.5468e-01, time/batch = 17.6504s	
14193/33650 (epoch 21.089), train_loss = 0.97032686, grad/param norm = 1.5548e-01, time/batch = 17.2179s	
14194/33650 (epoch 21.091), train_loss = 0.93364913, grad/param norm = 1.3248e-01, time/batch = 16.8923s	
14195/33650 (epoch 21.092), train_loss = 0.98974774, grad/param norm = 1.5189e-01, time/batch = 16.9865s	
14196/33650 (epoch 21.094), train_loss = 1.05942235, grad/param norm = 1.3722e-01, time/batch = 17.3988s	
14197/33650 (epoch 21.095), train_loss = 1.04552426, grad/param norm = 1.6690e-01, time/batch = 18.0699s	
14198/33650 (epoch 21.097), train_loss = 0.93523218, grad/param norm = 1.5046e-01, time/batch = 16.1401s	
14199/33650 (epoch 21.098), train_loss = 0.81347982, grad/param norm = 1.4145e-01, time/batch = 17.7356s	
14200/33650 (epoch 21.100), train_loss = 0.92004504, grad/param norm = 1.2858e-01, time/batch = 18.4015s	
14201/33650 (epoch 21.101), train_loss = 1.00076696, grad/param norm = 1.7893e-01, time/batch = 17.4118s	
14202/33650 (epoch 21.103), train_loss = 0.95593932, grad/param norm = 1.5936e-01, time/batch = 16.7407s	
14203/33650 (epoch 21.104), train_loss = 1.09349831, grad/param norm = 1.4974e-01, time/batch = 17.1563s	
14204/33650 (epoch 21.105), train_loss = 0.98615713, grad/param norm = 1.4440e-01, time/batch = 15.7095s	
14205/33650 (epoch 21.107), train_loss = 0.92546212, grad/param norm = 1.3805e-01, time/batch = 17.2201s	
14206/33650 (epoch 21.108), train_loss = 1.08481762, grad/param norm = 1.4819e-01, time/batch = 16.6954s	
14207/33650 (epoch 21.110), train_loss = 1.16550374, grad/param norm = 1.5692e-01, time/batch = 17.4985s	
14208/33650 (epoch 21.111), train_loss = 0.94593588, grad/param norm = 1.5045e-01, time/batch = 16.8972s	
14209/33650 (epoch 21.113), train_loss = 0.96255945, grad/param norm = 1.5269e-01, time/batch = 17.2324s	
14210/33650 (epoch 21.114), train_loss = 1.07383446, grad/param norm = 1.5448e-01, time/batch = 15.2298s	
14211/33650 (epoch 21.116), train_loss = 0.91022262, grad/param norm = 1.3806e-01, time/batch = 17.3991s	
14212/33650 (epoch 21.117), train_loss = 0.99283535, grad/param norm = 1.3125e-01, time/batch = 17.0595s	
14213/33650 (epoch 21.119), train_loss = 0.87485676, grad/param norm = 1.2832e-01, time/batch = 17.1544s	
14214/33650 (epoch 21.120), train_loss = 0.95217533, grad/param norm = 1.3448e-01, time/batch = 17.4859s	
14215/33650 (epoch 21.122), train_loss = 0.79687663, grad/param norm = 1.5454e-01, time/batch = 17.0688s	
14216/33650 (epoch 21.123), train_loss = 0.95056746, grad/param norm = 1.5046e-01, time/batch = 17.9035s	
14217/33650 (epoch 21.125), train_loss = 1.05307024, grad/param norm = 1.6221e-01, time/batch = 17.4827s	
14218/33650 (epoch 21.126), train_loss = 1.11511970, grad/param norm = 1.6775e-01, time/batch = 16.5045s	
14219/33650 (epoch 21.128), train_loss = 1.08746073, grad/param norm = 1.6206e-01, time/batch = 16.5614s	
14220/33650 (epoch 21.129), train_loss = 1.11053176, grad/param norm = 1.5136e-01, time/batch = 18.0859s	
14221/33650 (epoch 21.131), train_loss = 1.01564448, grad/param norm = 1.4858e-01, time/batch = 17.6624s	
14222/33650 (epoch 21.132), train_loss = 1.01124215, grad/param norm = 1.4586e-01, time/batch = 16.3066s	
14223/33650 (epoch 21.134), train_loss = 1.08144119, grad/param norm = 1.4907e-01, time/batch = 16.6331s	
14224/33650 (epoch 21.135), train_loss = 0.88197775, grad/param norm = 1.4961e-01, time/batch = 17.1560s	
14225/33650 (epoch 21.137), train_loss = 1.01686159, grad/param norm = 1.5142e-01, time/batch = 17.2353s	
14226/33650 (epoch 21.138), train_loss = 1.04891598, grad/param norm = 1.4829e-01, time/batch = 16.2207s	
14227/33650 (epoch 21.140), train_loss = 0.96433144, grad/param norm = 1.5361e-01, time/batch = 17.8166s	
14228/33650 (epoch 21.141), train_loss = 1.14328379, grad/param norm = 1.5665e-01, time/batch = 17.2379s	
14229/33650 (epoch 21.143), train_loss = 1.18696829, grad/param norm = 1.9116e-01, time/batch = 16.1523s	
14230/33650 (epoch 21.144), train_loss = 1.06434384, grad/param norm = 1.6816e-01, time/batch = 15.9747s	
14231/33650 (epoch 21.146), train_loss = 0.96240396, grad/param norm = 1.4509e-01, time/batch = 18.1258s	
14232/33650 (epoch 21.147), train_loss = 0.94252379, grad/param norm = 1.4854e-01, time/batch = 17.8983s	
14233/33650 (epoch 21.149), train_loss = 0.89538927, grad/param norm = 1.5401e-01, time/batch = 15.8774s	
14234/33650 (epoch 21.150), train_loss = 0.88578520, grad/param norm = 1.7388e-01, time/batch = 17.9015s	
14235/33650 (epoch 21.152), train_loss = 0.93255047, grad/param norm = 1.3557e-01, time/batch = 16.9012s	
14236/33650 (epoch 21.153), train_loss = 0.95723472, grad/param norm = 1.4136e-01, time/batch = 16.8250s	
14237/33650 (epoch 21.155), train_loss = 0.93473149, grad/param norm = 1.3605e-01, time/batch = 16.1582s	
14238/33650 (epoch 21.156), train_loss = 0.88836159, grad/param norm = 1.2874e-01, time/batch = 17.4048s	
14239/33650 (epoch 21.158), train_loss = 1.02256474, grad/param norm = 1.6242e-01, time/batch = 17.0749s	
14240/33650 (epoch 21.159), train_loss = 0.89712691, grad/param norm = 1.2307e-01, time/batch = 16.9004s	
14241/33650 (epoch 21.160), train_loss = 0.93024137, grad/param norm = 1.4376e-01, time/batch = 17.9047s	
14242/33650 (epoch 21.162), train_loss = 0.95823478, grad/param norm = 1.5726e-01, time/batch = 17.0651s	
14243/33650 (epoch 21.163), train_loss = 1.04737115, grad/param norm = 1.9462e-01, time/batch = 17.5705s	
14244/33650 (epoch 21.165), train_loss = 0.88646152, grad/param norm = 1.4558e-01, time/batch = 17.4009s	
14245/33650 (epoch 21.166), train_loss = 0.91461113, grad/param norm = 1.5941e-01, time/batch = 16.8284s	
14246/33650 (epoch 21.168), train_loss = 1.08052796, grad/param norm = 1.7855e-01, time/batch = 15.1327s	
14247/33650 (epoch 21.169), train_loss = 1.00542371, grad/param norm = 1.4788e-01, time/batch = 16.4726s	
14248/33650 (epoch 21.171), train_loss = 0.98177554, grad/param norm = 1.4338e-01, time/batch = 17.8189s	
14249/33650 (epoch 21.172), train_loss = 0.94717820, grad/param norm = 1.5156e-01, time/batch = 17.4150s	
14250/33650 (epoch 21.174), train_loss = 0.90276360, grad/param norm = 1.3628e-01, time/batch = 16.8958s	
14251/33650 (epoch 21.175), train_loss = 0.87844838, grad/param norm = 1.4907e-01, time/batch = 17.4052s	
14252/33650 (epoch 21.177), train_loss = 0.99196849, grad/param norm = 1.4300e-01, time/batch = 17.3255s	
14253/33650 (epoch 21.178), train_loss = 0.92804997, grad/param norm = 1.7836e-01, time/batch = 16.9040s	
14254/33650 (epoch 21.180), train_loss = 0.87934157, grad/param norm = 1.3463e-01, time/batch = 16.8816s	
14255/33650 (epoch 21.181), train_loss = 0.80754394, grad/param norm = 1.3421e-01, time/batch = 17.5760s	
14256/33650 (epoch 21.183), train_loss = 0.92046695, grad/param norm = 1.5367e-01, time/batch = 17.4028s	
14257/33650 (epoch 21.184), train_loss = 0.91800291, grad/param norm = 1.5870e-01, time/batch = 15.6248s	
14258/33650 (epoch 21.186), train_loss = 0.97202757, grad/param norm = 1.7119e-01, time/batch = 17.4913s	
14259/33650 (epoch 21.187), train_loss = 1.16154143, grad/param norm = 1.7202e-01, time/batch = 17.1532s	
14260/33650 (epoch 21.189), train_loss = 1.08420528, grad/param norm = 1.6959e-01, time/batch = 17.3138s	
14261/33650 (epoch 21.190), train_loss = 1.00532913, grad/param norm = 1.6811e-01, time/batch = 16.5489s	
14262/33650 (epoch 21.192), train_loss = 1.17575402, grad/param norm = 1.4725e-01, time/batch = 16.9582s	
14263/33650 (epoch 21.193), train_loss = 1.11927003, grad/param norm = 1.5804e-01, time/batch = 17.6512s	
14264/33650 (epoch 21.195), train_loss = 0.87188812, grad/param norm = 1.3215e-01, time/batch = 16.3975s	
14265/33650 (epoch 21.196), train_loss = 0.84548874, grad/param norm = 1.4921e-01, time/batch = 16.8955s	
14266/33650 (epoch 21.198), train_loss = 0.92924514, grad/param norm = 1.5575e-01, time/batch = 16.2325s	
14267/33650 (epoch 21.199), train_loss = 1.06246666, grad/param norm = 1.6210e-01, time/batch = 17.8919s	
14268/33650 (epoch 21.201), train_loss = 0.93291113, grad/param norm = 1.5083e-01, time/batch = 16.3097s	
14269/33650 (epoch 21.202), train_loss = 0.95749074, grad/param norm = 1.5280e-01, time/batch = 16.8235s	
14270/33650 (epoch 21.204), train_loss = 1.04089352, grad/param norm = 1.6093e-01, time/batch = 18.6422s	
14271/33650 (epoch 21.205), train_loss = 0.98879528, grad/param norm = 1.5248e-01, time/batch = 17.0491s	
14272/33650 (epoch 21.207), train_loss = 0.92312159, grad/param norm = 1.5170e-01, time/batch = 17.8915s	
14273/33650 (epoch 21.208), train_loss = 0.98671398, grad/param norm = 1.4403e-01, time/batch = 17.4553s	
14274/33650 (epoch 21.210), train_loss = 0.81401414, grad/param norm = 1.6573e-01, time/batch = 17.3895s	
14275/33650 (epoch 21.211), train_loss = 0.90755324, grad/param norm = 1.4817e-01, time/batch = 17.3834s	
14276/33650 (epoch 21.212), train_loss = 1.04378642, grad/param norm = 1.7193e-01, time/batch = 17.2136s	
14277/33650 (epoch 21.214), train_loss = 1.14438542, grad/param norm = 1.5318e-01, time/batch = 18.1522s	
14278/33650 (epoch 21.215), train_loss = 0.76467329, grad/param norm = 1.3186e-01, time/batch = 17.8047s	
14279/33650 (epoch 21.217), train_loss = 0.95465772, grad/param norm = 1.6937e-01, time/batch = 15.5506s	
14280/33650 (epoch 21.218), train_loss = 0.99758593, grad/param norm = 1.4785e-01, time/batch = 16.8242s	
14281/33650 (epoch 21.220), train_loss = 0.86853347, grad/param norm = 1.4680e-01, time/batch = 17.4875s	
14282/33650 (epoch 21.221), train_loss = 1.14928533, grad/param norm = 1.6779e-01, time/batch = 17.5424s	
14283/33650 (epoch 21.223), train_loss = 0.78309465, grad/param norm = 1.3300e-01, time/batch = 18.2329s	
14284/33650 (epoch 21.224), train_loss = 0.95302769, grad/param norm = 1.8654e-01, time/batch = 18.8194s	
14285/33650 (epoch 21.226), train_loss = 1.25745192, grad/param norm = 1.6775e-01, time/batch = 16.8900s	
14286/33650 (epoch 21.227), train_loss = 1.11360748, grad/param norm = 1.7328e-01, time/batch = 18.6481s	
14287/33650 (epoch 21.229), train_loss = 1.10303063, grad/param norm = 1.5515e-01, time/batch = 18.2148s	
14288/33650 (epoch 21.230), train_loss = 1.22462954, grad/param norm = 1.6914e-01, time/batch = 17.2195s	
14289/33650 (epoch 21.232), train_loss = 1.06051051, grad/param norm = 1.7721e-01, time/batch = 17.8971s	
14290/33650 (epoch 21.233), train_loss = 1.05527836, grad/param norm = 2.0191e-01, time/batch = 17.7347s	
14291/33650 (epoch 21.235), train_loss = 0.97721722, grad/param norm = 1.4064e-01, time/batch = 17.5552s	
14292/33650 (epoch 21.236), train_loss = 0.88977533, grad/param norm = 1.4764e-01, time/batch = 16.8781s	
14293/33650 (epoch 21.238), train_loss = 0.96632858, grad/param norm = 1.4676e-01, time/batch = 17.3804s	
14294/33650 (epoch 21.239), train_loss = 0.90394491, grad/param norm = 1.4135e-01, time/batch = 18.0618s	
14295/33650 (epoch 21.241), train_loss = 0.94568164, grad/param norm = 1.3997e-01, time/batch = 17.3900s	
14296/33650 (epoch 21.242), train_loss = 0.81561847, grad/param norm = 1.4779e-01, time/batch = 17.9907s	
14297/33650 (epoch 21.244), train_loss = 0.96865207, grad/param norm = 1.5430e-01, time/batch = 18.6522s	
14298/33650 (epoch 21.245), train_loss = 0.86952260, grad/param norm = 1.3492e-01, time/batch = 17.6468s	
14299/33650 (epoch 21.247), train_loss = 0.95867699, grad/param norm = 1.3900e-01, time/batch = 18.0659s	
14300/33650 (epoch 21.248), train_loss = 0.86475581, grad/param norm = 1.6065e-01, time/batch = 18.3148s	
14301/33650 (epoch 21.250), train_loss = 0.96562666, grad/param norm = 1.4526e-01, time/batch = 18.7356s	
14302/33650 (epoch 21.251), train_loss = 1.10492673, grad/param norm = 1.4603e-01, time/batch = 17.9628s	
14303/33650 (epoch 21.253), train_loss = 0.84765090, grad/param norm = 1.3083e-01, time/batch = 17.1287s	
14304/33650 (epoch 21.254), train_loss = 0.89012320, grad/param norm = 1.5198e-01, time/batch = 17.9664s	
14305/33650 (epoch 21.256), train_loss = 1.11950144, grad/param norm = 1.4420e-01, time/batch = 16.7221s	
14306/33650 (epoch 21.257), train_loss = 1.11149731, grad/param norm = 1.4799e-01, time/batch = 17.7311s	
14307/33650 (epoch 21.259), train_loss = 0.84551995, grad/param norm = 1.3409e-01, time/batch = 18.5652s	
14308/33650 (epoch 21.260), train_loss = 1.06296912, grad/param norm = 1.5335e-01, time/batch = 15.5484s	
14309/33650 (epoch 21.262), train_loss = 1.01179465, grad/param norm = 1.5827e-01, time/batch = 17.8940s	
14310/33650 (epoch 21.263), train_loss = 0.93858842, grad/param norm = 1.7259e-01, time/batch = 17.1083s	
14311/33650 (epoch 21.264), train_loss = 1.04330625, grad/param norm = 1.6600e-01, time/batch = 17.9889s	
14312/33650 (epoch 21.266), train_loss = 1.01572216, grad/param norm = 1.4369e-01, time/batch = 16.7232s	
14313/33650 (epoch 21.267), train_loss = 0.91833713, grad/param norm = 1.4738e-01, time/batch = 17.9699s	
14314/33650 (epoch 21.269), train_loss = 1.01646977, grad/param norm = 1.4498e-01, time/batch = 18.5528s	
14315/33650 (epoch 21.270), train_loss = 0.90796084, grad/param norm = 1.3033e-01, time/batch = 18.0592s	
14316/33650 (epoch 21.272), train_loss = 0.95240948, grad/param norm = 1.4449e-01, time/batch = 18.1368s	
14317/33650 (epoch 21.273), train_loss = 1.08845448, grad/param norm = 1.6902e-01, time/batch = 18.8890s	
14318/33650 (epoch 21.275), train_loss = 1.04415466, grad/param norm = 1.5834e-01, time/batch = 18.9537s	
14319/33650 (epoch 21.276), train_loss = 1.10240393, grad/param norm = 1.7637e-01, time/batch = 29.3223s	
14320/33650 (epoch 21.278), train_loss = 1.16281587, grad/param norm = 1.6307e-01, time/batch = 16.7299s	
14321/33650 (epoch 21.279), train_loss = 0.95133500, grad/param norm = 1.3520e-01, time/batch = 16.3794s	
14322/33650 (epoch 21.281), train_loss = 1.02814312, grad/param norm = 1.7966e-01, time/batch = 17.4737s	
14323/33650 (epoch 21.282), train_loss = 1.08835954, grad/param norm = 1.3764e-01, time/batch = 17.8855s	
14324/33650 (epoch 21.284), train_loss = 1.06245639, grad/param norm = 1.6304e-01, time/batch = 18.0580s	
14325/33650 (epoch 21.285), train_loss = 1.05630071, grad/param norm = 1.5959e-01, time/batch = 16.5312s	
14326/33650 (epoch 21.287), train_loss = 0.97588042, grad/param norm = 1.5024e-01, time/batch = 18.1355s	
14327/33650 (epoch 21.288), train_loss = 1.02484884, grad/param norm = 1.8554e-01, time/batch = 18.5583s	
14328/33650 (epoch 21.290), train_loss = 0.99495795, grad/param norm = 1.3923e-01, time/batch = 17.5545s	
14329/33650 (epoch 21.291), train_loss = 0.90160996, grad/param norm = 1.2298e-01, time/batch = 18.3092s	
14330/33650 (epoch 21.293), train_loss = 0.97642543, grad/param norm = 1.6469e-01, time/batch = 18.2299s	
14331/33650 (epoch 21.294), train_loss = 0.90085749, grad/param norm = 1.3538e-01, time/batch = 16.9763s	
14332/33650 (epoch 21.296), train_loss = 0.88480887, grad/param norm = 1.4280e-01, time/batch = 17.7179s	
14333/33650 (epoch 21.297), train_loss = 0.98631423, grad/param norm = 1.6107e-01, time/batch = 18.7225s	
14334/33650 (epoch 21.299), train_loss = 0.83942864, grad/param norm = 1.2953e-01, time/batch = 18.1476s	
14335/33650 (epoch 21.300), train_loss = 0.88168134, grad/param norm = 1.4817e-01, time/batch = 7.7026s	
14336/33650 (epoch 21.302), train_loss = 1.01200967, grad/param norm = 1.3622e-01, time/batch = 0.6390s	
14337/33650 (epoch 21.303), train_loss = 1.01378878, grad/param norm = 1.4672e-01, time/batch = 0.6447s	
14338/33650 (epoch 21.305), train_loss = 0.99825475, grad/param norm = 1.4898e-01, time/batch = 0.6522s	
14339/33650 (epoch 21.306), train_loss = 0.91314720, grad/param norm = 1.3970e-01, time/batch = 0.6469s	
14340/33650 (epoch 21.308), train_loss = 0.85724125, grad/param norm = 1.5113e-01, time/batch = 0.6452s	
14341/33650 (epoch 21.309), train_loss = 1.14230033, grad/param norm = 1.5623e-01, time/batch = 0.6516s	
14342/33650 (epoch 21.311), train_loss = 1.00685268, grad/param norm = 1.5924e-01, time/batch = 0.6441s	
14343/33650 (epoch 21.312), train_loss = 0.98650115, grad/param norm = 1.5981e-01, time/batch = 0.9101s	
14344/33650 (epoch 21.314), train_loss = 0.86441442, grad/param norm = 1.2755e-01, time/batch = 0.9430s	
14345/33650 (epoch 21.315), train_loss = 0.95517171, grad/param norm = 1.8074e-01, time/batch = 0.9641s	
14346/33650 (epoch 21.316), train_loss = 0.94652660, grad/param norm = 1.6933e-01, time/batch = 0.9678s	
14347/33650 (epoch 21.318), train_loss = 0.88878635, grad/param norm = 1.3241e-01, time/batch = 0.9408s	
14348/33650 (epoch 21.319), train_loss = 0.90416532, grad/param norm = 1.3001e-01, time/batch = 1.4874s	
14349/33650 (epoch 21.321), train_loss = 0.91719654, grad/param norm = 1.3735e-01, time/batch = 1.8252s	
14350/33650 (epoch 21.322), train_loss = 1.00925775, grad/param norm = 1.5646e-01, time/batch = 1.7696s	
14351/33650 (epoch 21.324), train_loss = 1.04815285, grad/param norm = 1.7579e-01, time/batch = 15.3315s	
14352/33650 (epoch 21.325), train_loss = 1.04429887, grad/param norm = 1.5358e-01, time/batch = 18.9731s	
14353/33650 (epoch 21.327), train_loss = 0.89176523, grad/param norm = 1.2820e-01, time/batch = 16.9696s	
14354/33650 (epoch 21.328), train_loss = 1.02392621, grad/param norm = 1.5277e-01, time/batch = 17.9767s	
14355/33650 (epoch 21.330), train_loss = 0.89995545, grad/param norm = 1.2449e-01, time/batch = 16.8781s	
14356/33650 (epoch 21.331), train_loss = 0.80874533, grad/param norm = 1.1598e-01, time/batch = 16.4627s	
14357/33650 (epoch 21.333), train_loss = 0.95499176, grad/param norm = 1.4143e-01, time/batch = 16.8955s	
14358/33650 (epoch 21.334), train_loss = 0.96718077, grad/param norm = 1.4567e-01, time/batch = 17.5661s	
14359/33650 (epoch 21.336), train_loss = 1.07913274, grad/param norm = 1.4087e-01, time/batch = 18.8950s	
14360/33650 (epoch 21.337), train_loss = 0.82610226, grad/param norm = 1.3064e-01, time/batch = 17.5531s	
14361/33650 (epoch 21.339), train_loss = 0.94222032, grad/param norm = 1.3541e-01, time/batch = 17.6526s	
14362/33650 (epoch 21.340), train_loss = 1.09237594, grad/param norm = 1.6267e-01, time/batch = 17.6355s	
14363/33650 (epoch 21.342), train_loss = 0.82361158, grad/param norm = 1.4229e-01, time/batch = 17.2318s	
14364/33650 (epoch 21.343), train_loss = 1.02540242, grad/param norm = 1.5132e-01, time/batch = 17.3231s	
14365/33650 (epoch 21.345), train_loss = 0.94897339, grad/param norm = 1.4880e-01, time/batch = 16.7279s	
14366/33650 (epoch 21.346), train_loss = 0.67608108, grad/param norm = 1.2773e-01, time/batch = 18.2312s	
14367/33650 (epoch 21.348), train_loss = 0.85028773, grad/param norm = 1.2853e-01, time/batch = 17.2257s	
14368/33650 (epoch 21.349), train_loss = 0.80837181, grad/param norm = 1.3125e-01, time/batch = 16.6381s	
14369/33650 (epoch 21.351), train_loss = 1.05162617, grad/param norm = 1.4075e-01, time/batch = 17.1345s	
14370/33650 (epoch 21.352), train_loss = 0.96109914, grad/param norm = 1.4445e-01, time/batch = 17.1406s	
14371/33650 (epoch 21.354), train_loss = 1.15411753, grad/param norm = 1.9076e-01, time/batch = 18.4712s	
14372/33650 (epoch 21.355), train_loss = 1.12533953, grad/param norm = 1.5827e-01, time/batch = 17.2048s	
14373/33650 (epoch 21.357), train_loss = 0.78975635, grad/param norm = 1.3397e-01, time/batch = 17.2289s	
14374/33650 (epoch 21.358), train_loss = 1.05352635, grad/param norm = 1.5610e-01, time/batch = 17.1441s	
14375/33650 (epoch 21.360), train_loss = 1.07980101, grad/param norm = 1.9593e-01, time/batch = 17.6531s	
14376/33650 (epoch 21.361), train_loss = 1.02240077, grad/param norm = 1.5173e-01, time/batch = 19.0668s	
14377/33650 (epoch 21.363), train_loss = 0.95261680, grad/param norm = 1.4367e-01, time/batch = 17.5566s	
14378/33650 (epoch 21.364), train_loss = 0.92375270, grad/param norm = 1.3358e-01, time/batch = 18.9062s	
14379/33650 (epoch 21.366), train_loss = 1.01538412, grad/param norm = 1.5403e-01, time/batch = 17.6556s	
14380/33650 (epoch 21.367), train_loss = 1.02190115, grad/param norm = 1.4316e-01, time/batch = 17.3081s	
14381/33650 (epoch 21.368), train_loss = 0.89155457, grad/param norm = 1.3767e-01, time/batch = 18.5666s	
14382/33650 (epoch 21.370), train_loss = 0.99145126, grad/param norm = 1.5380e-01, time/batch = 18.2399s	
14383/33650 (epoch 21.371), train_loss = 0.77944774, grad/param norm = 1.3502e-01, time/batch = 17.9663s	
14384/33650 (epoch 21.373), train_loss = 0.87734564, grad/param norm = 1.3590e-01, time/batch = 16.9892s	
14385/33650 (epoch 21.374), train_loss = 0.86249782, grad/param norm = 1.2829e-01, time/batch = 18.2065s	
14386/33650 (epoch 21.376), train_loss = 0.97182023, grad/param norm = 1.6629e-01, time/batch = 16.8595s	
14387/33650 (epoch 21.377), train_loss = 1.00955244, grad/param norm = 1.5420e-01, time/batch = 16.9771s	
14388/33650 (epoch 21.379), train_loss = 1.02718126, grad/param norm = 1.4357e-01, time/batch = 16.8133s	
14389/33650 (epoch 21.380), train_loss = 0.78434975, grad/param norm = 1.5484e-01, time/batch = 18.0719s	
14390/33650 (epoch 21.382), train_loss = 0.91892715, grad/param norm = 1.2534e-01, time/batch = 16.7205s	
14391/33650 (epoch 21.383), train_loss = 0.95539673, grad/param norm = 1.4016e-01, time/batch = 18.2271s	
14392/33650 (epoch 21.385), train_loss = 1.07959143, grad/param norm = 1.4759e-01, time/batch = 18.6491s	
14393/33650 (epoch 21.386), train_loss = 0.91414133, grad/param norm = 1.4961e-01, time/batch = 17.2468s	
14394/33650 (epoch 21.388), train_loss = 1.01025913, grad/param norm = 1.3688e-01, time/batch = 15.4633s	
14395/33650 (epoch 21.389), train_loss = 0.94093896, grad/param norm = 1.5372e-01, time/batch = 18.3191s	
14396/33650 (epoch 21.391), train_loss = 0.77336235, grad/param norm = 1.3058e-01, time/batch = 17.9885s	
14397/33650 (epoch 21.392), train_loss = 1.01653208, grad/param norm = 1.5548e-01, time/batch = 16.7204s	
14398/33650 (epoch 21.394), train_loss = 1.00521350, grad/param norm = 1.6329e-01, time/batch = 17.4843s	
14399/33650 (epoch 21.395), train_loss = 1.02919249, grad/param norm = 1.4626e-01, time/batch = 17.5777s	
14400/33650 (epoch 21.397), train_loss = 1.11322547, grad/param norm = 1.5772e-01, time/batch = 18.3962s	
14401/33650 (epoch 21.398), train_loss = 1.03557212, grad/param norm = 1.5015e-01, time/batch = 18.5500s	
14402/33650 (epoch 21.400), train_loss = 0.98227264, grad/param norm = 1.7293e-01, time/batch = 17.6460s	
14403/33650 (epoch 21.401), train_loss = 0.93033182, grad/param norm = 1.5867e-01, time/batch = 18.5705s	
14404/33650 (epoch 21.403), train_loss = 1.01171783, grad/param norm = 1.6717e-01, time/batch = 17.4649s	
14405/33650 (epoch 21.404), train_loss = 0.95735043, grad/param norm = 1.3086e-01, time/batch = 17.5623s	
14406/33650 (epoch 21.406), train_loss = 0.98684955, grad/param norm = 1.4412e-01, time/batch = 16.9775s	
14407/33650 (epoch 21.407), train_loss = 0.96621527, grad/param norm = 1.4729e-01, time/batch = 16.7418s	
14408/33650 (epoch 21.409), train_loss = 1.01397772, grad/param norm = 1.5656e-01, time/batch = 17.4820s	
14409/33650 (epoch 21.410), train_loss = 0.96106303, grad/param norm = 1.3791e-01, time/batch = 17.4741s	
14410/33650 (epoch 21.412), train_loss = 0.96713819, grad/param norm = 1.2794e-01, time/batch = 16.7198s	
14411/33650 (epoch 21.413), train_loss = 0.92170955, grad/param norm = 1.4083e-01, time/batch = 17.8085s	
14412/33650 (epoch 21.415), train_loss = 1.04885388, grad/param norm = 1.5189e-01, time/batch = 18.3887s	
14413/33650 (epoch 21.416), train_loss = 1.10173882, grad/param norm = 1.4623e-01, time/batch = 16.4622s	
14414/33650 (epoch 21.418), train_loss = 0.91900111, grad/param norm = 1.4123e-01, time/batch = 17.3896s	
14415/33650 (epoch 21.419), train_loss = 0.92783086, grad/param norm = 1.4336e-01, time/batch = 18.1488s	
14416/33650 (epoch 21.421), train_loss = 0.94832543, grad/param norm = 1.3190e-01, time/batch = 17.3205s	
14417/33650 (epoch 21.422), train_loss = 1.07205426, grad/param norm = 1.4674e-01, time/batch = 17.8187s	
14418/33650 (epoch 21.423), train_loss = 0.89111553, grad/param norm = 1.2154e-01, time/batch = 17.5581s	
14419/33650 (epoch 21.425), train_loss = 0.99729691, grad/param norm = 1.6062e-01, time/batch = 18.4910s	
14420/33650 (epoch 21.426), train_loss = 1.12242652, grad/param norm = 1.6175e-01, time/batch = 17.4872s	
14421/33650 (epoch 21.428), train_loss = 0.90104605, grad/param norm = 1.2932e-01, time/batch = 16.4832s	
14422/33650 (epoch 21.429), train_loss = 1.05698459, grad/param norm = 1.5659e-01, time/batch = 18.4742s	
14423/33650 (epoch 21.431), train_loss = 1.12263805, grad/param norm = 1.6644e-01, time/batch = 18.3133s	
14424/33650 (epoch 21.432), train_loss = 1.15124639, grad/param norm = 1.5980e-01, time/batch = 16.1489s	
14425/33650 (epoch 21.434), train_loss = 1.00359483, grad/param norm = 1.4384e-01, time/batch = 17.1267s	
14426/33650 (epoch 21.435), train_loss = 0.97674623, grad/param norm = 1.8333e-01, time/batch = 18.3905s	
14427/33650 (epoch 21.437), train_loss = 0.99398946, grad/param norm = 1.4802e-01, time/batch = 18.0626s	
14428/33650 (epoch 21.438), train_loss = 0.93528421, grad/param norm = 1.5909e-01, time/batch = 17.3892s	
14429/33650 (epoch 21.440), train_loss = 0.97857934, grad/param norm = 1.6417e-01, time/batch = 18.1345s	
14430/33650 (epoch 21.441), train_loss = 0.99355785, grad/param norm = 1.6401e-01, time/batch = 16.2984s	
14431/33650 (epoch 21.443), train_loss = 1.04176233, grad/param norm = 1.4209e-01, time/batch = 16.9712s	
14432/33650 (epoch 21.444), train_loss = 0.96527984, grad/param norm = 1.5737e-01, time/batch = 18.6339s	
14433/33650 (epoch 21.446), train_loss = 1.01934739, grad/param norm = 1.7140e-01, time/batch = 17.9910s	
14434/33650 (epoch 21.447), train_loss = 1.08783102, grad/param norm = 1.5187e-01, time/batch = 17.4742s	
14435/33650 (epoch 21.449), train_loss = 1.14989025, grad/param norm = 1.9332e-01, time/batch = 17.0754s	
14436/33650 (epoch 21.450), train_loss = 1.16879734, grad/param norm = 1.6936e-01, time/batch = 18.3220s	
14437/33650 (epoch 21.452), train_loss = 1.16875603, grad/param norm = 1.9737e-01, time/batch = 17.8979s	
14438/33650 (epoch 21.453), train_loss = 1.14377392, grad/param norm = 1.6867e-01, time/batch = 17.5509s	
14439/33650 (epoch 21.455), train_loss = 0.96431034, grad/param norm = 1.4919e-01, time/batch = 18.7231s	
14440/33650 (epoch 21.456), train_loss = 0.98759544, grad/param norm = 1.5227e-01, time/batch = 17.8194s	
14441/33650 (epoch 21.458), train_loss = 0.97985876, grad/param norm = 1.7094e-01, time/batch = 15.9691s	
14442/33650 (epoch 21.459), train_loss = 1.00862781, grad/param norm = 1.6175e-01, time/batch = 17.6321s	
14443/33650 (epoch 21.461), train_loss = 1.12778107, grad/param norm = 1.7047e-01, time/batch = 18.2230s	
14444/33650 (epoch 21.462), train_loss = 1.11675097, grad/param norm = 1.7700e-01, time/batch = 17.8115s	
14445/33650 (epoch 21.464), train_loss = 0.95772883, grad/param norm = 1.6788e-01, time/batch = 17.6413s	
14446/33650 (epoch 21.465), train_loss = 1.01076726, grad/param norm = 1.5730e-01, time/batch = 16.8716s	
14447/33650 (epoch 21.467), train_loss = 1.04227839, grad/param norm = 1.4991e-01, time/batch = 16.4790s	
14448/33650 (epoch 21.468), train_loss = 1.12379519, grad/param norm = 1.5372e-01, time/batch = 16.9657s	
14449/33650 (epoch 21.470), train_loss = 1.20693677, grad/param norm = 1.9064e-01, time/batch = 17.5584s	
14450/33650 (epoch 21.471), train_loss = 0.99778601, grad/param norm = 1.5168e-01, time/batch = 17.8284s	
14451/33650 (epoch 21.473), train_loss = 0.97214669, grad/param norm = 1.5530e-01, time/batch = 17.3820s	
14452/33650 (epoch 21.474), train_loss = 1.09314902, grad/param norm = 1.5159e-01, time/batch = 17.4753s	
14453/33650 (epoch 21.475), train_loss = 1.05540786, grad/param norm = 1.5348e-01, time/batch = 18.1444s	
14454/33650 (epoch 21.477), train_loss = 1.11843119, grad/param norm = 1.5731e-01, time/batch = 17.1465s	
14455/33650 (epoch 21.478), train_loss = 1.09692770, grad/param norm = 1.6512e-01, time/batch = 17.6406s	
14456/33650 (epoch 21.480), train_loss = 1.09694077, grad/param norm = 1.7102e-01, time/batch = 18.6434s	
14457/33650 (epoch 21.481), train_loss = 1.15611784, grad/param norm = 1.6205e-01, time/batch = 17.2332s	
14458/33650 (epoch 21.483), train_loss = 0.82420584, grad/param norm = 1.3358e-01, time/batch = 16.2868s	
14459/33650 (epoch 21.484), train_loss = 0.99665766, grad/param norm = 1.5761e-01, time/batch = 17.4796s	
14460/33650 (epoch 21.486), train_loss = 1.14234810, grad/param norm = 1.7699e-01, time/batch = 19.1255s	
14461/33650 (epoch 21.487), train_loss = 1.14431821, grad/param norm = 1.6551e-01, time/batch = 17.2416s	
14462/33650 (epoch 21.489), train_loss = 1.15165363, grad/param norm = 1.6058e-01, time/batch = 17.1528s	
14463/33650 (epoch 21.490), train_loss = 0.90514083, grad/param norm = 1.5741e-01, time/batch = 17.8079s	
14464/33650 (epoch 21.492), train_loss = 1.04855722, grad/param norm = 1.6855e-01, time/batch = 18.1490s	
14465/33650 (epoch 21.493), train_loss = 0.84461895, grad/param norm = 1.3256e-01, time/batch = 16.7191s	
14466/33650 (epoch 21.495), train_loss = 1.01142145, grad/param norm = 1.4766e-01, time/batch = 17.9676s	
14467/33650 (epoch 21.496), train_loss = 1.05551191, grad/param norm = 1.6175e-01, time/batch = 18.5649s	
14468/33650 (epoch 21.498), train_loss = 0.90798418, grad/param norm = 1.3911e-01, time/batch = 15.7878s	
14469/33650 (epoch 21.499), train_loss = 0.99283562, grad/param norm = 1.3770e-01, time/batch = 16.8091s	
14470/33650 (epoch 21.501), train_loss = 0.96519788, grad/param norm = 1.3707e-01, time/batch = 17.2008s	
14471/33650 (epoch 21.502), train_loss = 1.00184476, grad/param norm = 1.4864e-01, time/batch = 19.0563s	
14472/33650 (epoch 21.504), train_loss = 1.09657676, grad/param norm = 1.6714e-01, time/batch = 17.8124s	
14473/33650 (epoch 21.505), train_loss = 0.95597017, grad/param norm = 1.5949e-01, time/batch = 18.5585s	
14474/33650 (epoch 21.507), train_loss = 1.12703378, grad/param norm = 1.6248e-01, time/batch = 18.9011s	
14475/33650 (epoch 21.508), train_loss = 0.96941230, grad/param norm = 1.4703e-01, time/batch = 16.7863s	
14476/33650 (epoch 21.510), train_loss = 0.99047740, grad/param norm = 1.4123e-01, time/batch = 17.9874s	
14477/33650 (epoch 21.511), train_loss = 1.22410157, grad/param norm = 1.9241e-01, time/batch = 18.6332s	
14478/33650 (epoch 21.513), train_loss = 1.06169508, grad/param norm = 1.5462e-01, time/batch = 17.2250s	
14479/33650 (epoch 21.514), train_loss = 1.07742772, grad/param norm = 1.5998e-01, time/batch = 17.8927s	
14480/33650 (epoch 21.516), train_loss = 1.01408718, grad/param norm = 1.7083e-01, time/batch = 16.1370s	
14481/33650 (epoch 21.517), train_loss = 1.00408918, grad/param norm = 1.5292e-01, time/batch = 17.3256s	
14482/33650 (epoch 21.519), train_loss = 1.07725009, grad/param norm = 1.7231e-01, time/batch = 16.0681s	
14483/33650 (epoch 21.520), train_loss = 0.86781769, grad/param norm = 1.2907e-01, time/batch = 17.4080s	
14484/33650 (epoch 21.522), train_loss = 0.98956150, grad/param norm = 1.5049e-01, time/batch = 16.9040s	
14485/33650 (epoch 21.523), train_loss = 0.95972558, grad/param norm = 1.5812e-01, time/batch = 17.1483s	
14486/33650 (epoch 21.525), train_loss = 0.80388225, grad/param norm = 1.3038e-01, time/batch = 17.1545s	
14487/33650 (epoch 21.526), train_loss = 1.09035100, grad/param norm = 1.4480e-01, time/batch = 17.2849s	
14488/33650 (epoch 21.527), train_loss = 0.94536037, grad/param norm = 1.4483e-01, time/batch = 18.0712s	
14489/33650 (epoch 21.529), train_loss = 1.00806599, grad/param norm = 1.4990e-01, time/batch = 15.8102s	
14490/33650 (epoch 21.530), train_loss = 0.94646514, grad/param norm = 1.4815e-01, time/batch = 17.4077s	
14491/33650 (epoch 21.532), train_loss = 1.09713765, grad/param norm = 1.8796e-01, time/batch = 18.0600s	
14492/33650 (epoch 21.533), train_loss = 0.98552025, grad/param norm = 1.5380e-01, time/batch = 14.7096s	
14493/33650 (epoch 21.535), train_loss = 1.09624331, grad/param norm = 1.5547e-01, time/batch = 17.3273s	
14494/33650 (epoch 21.536), train_loss = 1.00731305, grad/param norm = 1.5368e-01, time/batch = 16.3353s	
14495/33650 (epoch 21.538), train_loss = 1.07389001, grad/param norm = 1.9295e-01, time/batch = 17.0772s	
14496/33650 (epoch 21.539), train_loss = 0.84086889, grad/param norm = 1.5059e-01, time/batch = 16.8257s	
14497/33650 (epoch 21.541), train_loss = 1.12594929, grad/param norm = 1.7313e-01, time/batch = 16.8219s	
14498/33650 (epoch 21.542), train_loss = 1.03024437, grad/param norm = 1.8193e-01, time/batch = 17.1650s	
14499/33650 (epoch 21.544), train_loss = 1.18091490, grad/param norm = 1.9714e-01, time/batch = 16.4912s	
14500/33650 (epoch 21.545), train_loss = 0.85826208, grad/param norm = 1.3890e-01, time/batch = 16.8890s	
14501/33650 (epoch 21.547), train_loss = 1.01322584, grad/param norm = 1.3673e-01, time/batch = 16.7279s	
14502/33650 (epoch 21.548), train_loss = 1.16484642, grad/param norm = 1.5845e-01, time/batch = 18.2365s	
14503/33650 (epoch 21.550), train_loss = 1.02476944, grad/param norm = 1.5805e-01, time/batch = 16.3227s	
14504/33650 (epoch 21.551), train_loss = 1.02076595, grad/param norm = 1.6286e-01, time/batch = 17.4874s	
14505/33650 (epoch 21.553), train_loss = 0.88496318, grad/param norm = 1.4709e-01, time/batch = 16.1437s	
14506/33650 (epoch 21.554), train_loss = 1.15926127, grad/param norm = 1.6110e-01, time/batch = 17.1588s	
14507/33650 (epoch 21.556), train_loss = 1.09581941, grad/param norm = 2.2615e-01, time/batch = 16.7337s	
14508/33650 (epoch 21.557), train_loss = 1.09542602, grad/param norm = 1.8984e-01, time/batch = 16.9859s	
14509/33650 (epoch 21.559), train_loss = 1.27369196, grad/param norm = 1.8962e-01, time/batch = 17.9855s	
14510/33650 (epoch 21.560), train_loss = 1.21218684, grad/param norm = 1.6707e-01, time/batch = 15.8009s	
14511/33650 (epoch 21.562), train_loss = 1.11193417, grad/param norm = 1.4729e-01, time/batch = 16.8940s	
14512/33650 (epoch 21.563), train_loss = 1.03996821, grad/param norm = 1.5076e-01, time/batch = 17.4769s	
14513/33650 (epoch 21.565), train_loss = 1.01022305, grad/param norm = 1.4304e-01, time/batch = 17.0714s	
14514/33650 (epoch 21.566), train_loss = 0.98708814, grad/param norm = 1.5647e-01, time/batch = 16.7296s	
14515/33650 (epoch 21.568), train_loss = 1.04574880, grad/param norm = 1.7289e-01, time/batch = 16.7416s	
14516/33650 (epoch 21.569), train_loss = 0.94294603, grad/param norm = 1.3712e-01, time/batch = 15.6537s	
14517/33650 (epoch 21.571), train_loss = 1.12971627, grad/param norm = 1.6763e-01, time/batch = 15.8219s	
14518/33650 (epoch 21.572), train_loss = 1.09270757, grad/param norm = 1.5837e-01, time/batch = 16.8988s	
14519/33650 (epoch 21.574), train_loss = 0.98019053, grad/param norm = 1.9768e-01, time/batch = 17.5752s	
14520/33650 (epoch 21.575), train_loss = 1.00433396, grad/param norm = 1.6668e-01, time/batch = 17.6607s	
14521/33650 (epoch 21.577), train_loss = 0.99146501, grad/param norm = 1.6024e-01, time/batch = 17.2988s	
14522/33650 (epoch 21.578), train_loss = 1.08636828, grad/param norm = 1.5868e-01, time/batch = 16.9906s	
14523/33650 (epoch 21.579), train_loss = 1.06253609, grad/param norm = 1.5925e-01, time/batch = 17.9067s	
14524/33650 (epoch 21.581), train_loss = 1.14806915, grad/param norm = 1.6718e-01, time/batch = 16.4887s	
14525/33650 (epoch 21.582), train_loss = 1.06799109, grad/param norm = 1.3208e-01, time/batch = 15.9021s	
14526/33650 (epoch 21.584), train_loss = 1.04930320, grad/param norm = 1.5118e-01, time/batch = 16.6499s	
14527/33650 (epoch 21.585), train_loss = 1.07671045, grad/param norm = 1.7598e-01, time/batch = 17.1374s	
14528/33650 (epoch 21.587), train_loss = 0.93221400, grad/param norm = 1.4137e-01, time/batch = 16.1395s	
14529/33650 (epoch 21.588), train_loss = 0.97457249, grad/param norm = 2.0015e-01, time/batch = 17.8948s	
14530/33650 (epoch 21.590), train_loss = 0.95000038, grad/param norm = 1.3579e-01, time/batch = 17.4935s	
14531/33650 (epoch 21.591), train_loss = 0.94769950, grad/param norm = 1.6554e-01, time/batch = 15.8192s	
14532/33650 (epoch 21.593), train_loss = 0.92280105, grad/param norm = 1.4159e-01, time/batch = 17.4919s	
14533/33650 (epoch 21.594), train_loss = 0.90657374, grad/param norm = 1.5283e-01, time/batch = 16.7408s	
14534/33650 (epoch 21.596), train_loss = 0.99567922, grad/param norm = 1.4631e-01, time/batch = 17.5727s	
14535/33650 (epoch 21.597), train_loss = 0.86259771, grad/param norm = 1.3015e-01, time/batch = 16.2335s	
14536/33650 (epoch 21.599), train_loss = 0.98386790, grad/param norm = 1.5570e-01, time/batch = 16.9885s	
14537/33650 (epoch 21.600), train_loss = 0.92076449, grad/param norm = 1.4291e-01, time/batch = 18.2360s	
14538/33650 (epoch 21.602), train_loss = 1.05722724, grad/param norm = 1.5064e-01, time/batch = 21.3380s	
14539/33650 (epoch 21.603), train_loss = 0.96833545, grad/param norm = 1.7471e-01, time/batch = 26.1631s	
14540/33650 (epoch 21.605), train_loss = 1.05846259, grad/param norm = 1.5369e-01, time/batch = 18.0821s	
14541/33650 (epoch 21.606), train_loss = 1.05930181, grad/param norm = 1.9164e-01, time/batch = 15.9051s	
14542/33650 (epoch 21.608), train_loss = 0.92691161, grad/param norm = 1.7125e-01, time/batch = 17.3992s	
14543/33650 (epoch 21.609), train_loss = 1.00407637, grad/param norm = 1.5914e-01, time/batch = 17.7279s	
14544/33650 (epoch 21.611), train_loss = 0.90448725, grad/param norm = 1.5753e-01, time/batch = 16.9033s	
14545/33650 (epoch 21.612), train_loss = 1.01457674, grad/param norm = 1.7358e-01, time/batch = 17.4832s	
14546/33650 (epoch 21.614), train_loss = 1.10684582, grad/param norm = 1.5475e-01, time/batch = 17.1451s	
14547/33650 (epoch 21.615), train_loss = 0.98486021, grad/param norm = 1.3926e-01, time/batch = 16.6376s	
14548/33650 (epoch 21.617), train_loss = 0.91597142, grad/param norm = 1.3648e-01, time/batch = 15.8818s	
14549/33650 (epoch 21.618), train_loss = 0.98438869, grad/param norm = 1.4033e-01, time/batch = 16.5747s	
14550/33650 (epoch 21.620), train_loss = 1.00281339, grad/param norm = 1.5824e-01, time/batch = 16.8240s	
14551/33650 (epoch 21.621), train_loss = 0.91387793, grad/param norm = 1.4131e-01, time/batch = 17.3210s	
14552/33650 (epoch 21.623), train_loss = 0.98427623, grad/param norm = 1.6868e-01, time/batch = 16.1435s	
14553/33650 (epoch 21.624), train_loss = 0.80761900, grad/param norm = 1.5489e-01, time/batch = 17.1340s	
14554/33650 (epoch 21.626), train_loss = 0.79755100, grad/param norm = 1.2947e-01, time/batch = 17.9017s	
14555/33650 (epoch 21.627), train_loss = 0.91000397, grad/param norm = 1.5139e-01, time/batch = 16.4700s	
14556/33650 (epoch 21.629), train_loss = 0.96209795, grad/param norm = 1.4452e-01, time/batch = 17.2423s	
14557/33650 (epoch 21.630), train_loss = 1.08721924, grad/param norm = 1.6704e-01, time/batch = 16.8994s	
14558/33650 (epoch 21.632), train_loss = 1.13487443, grad/param norm = 1.6581e-01, time/batch = 17.6273s	
14559/33650 (epoch 21.633), train_loss = 1.07320600, grad/param norm = 1.4874e-01, time/batch = 17.2324s	
14560/33650 (epoch 21.634), train_loss = 0.88299693, grad/param norm = 1.4626e-01, time/batch = 17.4806s	
14561/33650 (epoch 21.636), train_loss = 0.76510300, grad/param norm = 1.1896e-01, time/batch = 15.9790s	
14562/33650 (epoch 21.637), train_loss = 0.93491372, grad/param norm = 1.5260e-01, time/batch = 15.6619s	
14563/33650 (epoch 21.639), train_loss = 0.92847667, grad/param norm = 1.4222e-01, time/batch = 16.9167s	
14564/33650 (epoch 21.640), train_loss = 1.01257318, grad/param norm = 1.6107e-01, time/batch = 17.6527s	
14565/33650 (epoch 21.642), train_loss = 1.07497963, grad/param norm = 1.6892e-01, time/batch = 17.9870s	
14566/33650 (epoch 21.643), train_loss = 1.00328800, grad/param norm = 1.5585e-01, time/batch = 16.5660s	
14567/33650 (epoch 21.645), train_loss = 1.01172713, grad/param norm = 1.4706e-01, time/batch = 17.3138s	
14568/33650 (epoch 21.646), train_loss = 0.84366780, grad/param norm = 1.2133e-01, time/batch = 17.0612s	
14569/33650 (epoch 21.648), train_loss = 1.01845720, grad/param norm = 1.4894e-01, time/batch = 15.9011s	
14570/33650 (epoch 21.649), train_loss = 0.95015843, grad/param norm = 1.6296e-01, time/batch = 17.8172s	
14571/33650 (epoch 21.651), train_loss = 1.11978464, grad/param norm = 1.7035e-01, time/batch = 17.7287s	
14572/33650 (epoch 21.652), train_loss = 0.72721677, grad/param norm = 1.3393e-01, time/batch = 17.8968s	
14573/33650 (epoch 21.654), train_loss = 0.90572595, grad/param norm = 1.4057e-01, time/batch = 16.3033s	
14574/33650 (epoch 21.655), train_loss = 0.85101184, grad/param norm = 1.2823e-01, time/batch = 17.2414s	
14575/33650 (epoch 21.657), train_loss = 0.94820016, grad/param norm = 1.5546e-01, time/batch = 17.8230s	
14576/33650 (epoch 21.658), train_loss = 0.82130217, grad/param norm = 1.4009e-01, time/batch = 15.8168s	
14577/33650 (epoch 21.660), train_loss = 0.80249327, grad/param norm = 1.3201e-01, time/batch = 17.5640s	
14578/33650 (epoch 21.661), train_loss = 0.90392819, grad/param norm = 1.3383e-01, time/batch = 17.6555s	
14579/33650 (epoch 21.663), train_loss = 0.85525148, grad/param norm = 1.5723e-01, time/batch = 16.7991s	
14580/33650 (epoch 21.664), train_loss = 0.90695223, grad/param norm = 1.3722e-01, time/batch = 17.1206s	
14581/33650 (epoch 21.666), train_loss = 0.93723579, grad/param norm = 1.2469e-01, time/batch = 17.6487s	
14582/33650 (epoch 21.667), train_loss = 0.84900072, grad/param norm = 1.2573e-01, time/batch = 17.3268s	
14583/33650 (epoch 21.669), train_loss = 0.87538595, grad/param norm = 1.4023e-01, time/batch = 14.9019s	
14584/33650 (epoch 21.670), train_loss = 0.79093440, grad/param norm = 1.4424e-01, time/batch = 16.3110s	
14585/33650 (epoch 21.672), train_loss = 0.83628965, grad/param norm = 1.3401e-01, time/batch = 15.9638s	
14586/33650 (epoch 21.673), train_loss = 0.79313213, grad/param norm = 1.4181e-01, time/batch = 16.8092s	
14587/33650 (epoch 21.675), train_loss = 0.78638578, grad/param norm = 1.2601e-01, time/batch = 16.2208s	
14588/33650 (epoch 21.676), train_loss = 0.96367338, grad/param norm = 1.5652e-01, time/batch = 17.7259s	
14589/33650 (epoch 21.678), train_loss = 0.89305471, grad/param norm = 1.3981e-01, time/batch = 17.4033s	
14590/33650 (epoch 21.679), train_loss = 0.92541956, grad/param norm = 1.5686e-01, time/batch = 16.3970s	
14591/33650 (epoch 21.681), train_loss = 0.93179829, grad/param norm = 1.3329e-01, time/batch = 17.2345s	
14592/33650 (epoch 21.682), train_loss = 0.86416917, grad/param norm = 1.4813e-01, time/batch = 17.2325s	
14593/33650 (epoch 21.684), train_loss = 0.83688054, grad/param norm = 1.3234e-01, time/batch = 17.9799s	
14594/33650 (epoch 21.685), train_loss = 1.01327978, grad/param norm = 1.4422e-01, time/batch = 16.6294s	
14595/33650 (epoch 21.686), train_loss = 0.96230002, grad/param norm = 1.3941e-01, time/batch = 17.1467s	
14596/33650 (epoch 21.688), train_loss = 1.04086479, grad/param norm = 1.5101e-01, time/batch = 17.1573s	
14597/33650 (epoch 21.689), train_loss = 0.87991782, grad/param norm = 1.4250e-01, time/batch = 16.4805s	
14598/33650 (epoch 21.691), train_loss = 1.06525528, grad/param norm = 1.7168e-01, time/batch = 17.0655s	
14599/33650 (epoch 21.692), train_loss = 1.08544319, grad/param norm = 1.5076e-01, time/batch = 16.9984s	
14600/33650 (epoch 21.694), train_loss = 0.98843258, grad/param norm = 1.6390e-01, time/batch = 17.9781s	
14601/33650 (epoch 21.695), train_loss = 0.70741783, grad/param norm = 1.3155e-01, time/batch = 16.8034s	
14602/33650 (epoch 21.697), train_loss = 0.94079888, grad/param norm = 1.6300e-01, time/batch = 17.8966s	
14603/33650 (epoch 21.698), train_loss = 1.11748983, grad/param norm = 1.5907e-01, time/batch = 15.5453s	
14604/33650 (epoch 21.700), train_loss = 0.95270403, grad/param norm = 1.4602e-01, time/batch = 16.9732s	
14605/33650 (epoch 21.701), train_loss = 0.98354468, grad/param norm = 1.5820e-01, time/batch = 17.3921s	
14606/33650 (epoch 21.703), train_loss = 1.13053039, grad/param norm = 1.4679e-01, time/batch = 16.9798s	
14607/33650 (epoch 21.704), train_loss = 0.93150689, grad/param norm = 1.3191e-01, time/batch = 17.8112s	
14608/33650 (epoch 21.706), train_loss = 0.92553244, grad/param norm = 1.4299e-01, time/batch = 16.6431s	
14609/33650 (epoch 21.707), train_loss = 1.06004280, grad/param norm = 1.4081e-01, time/batch = 16.5593s	
14610/33650 (epoch 21.709), train_loss = 0.93415272, grad/param norm = 1.4465e-01, time/batch = 17.0729s	
14611/33650 (epoch 21.710), train_loss = 1.13646207, grad/param norm = 1.5894e-01, time/batch = 17.4892s	
14612/33650 (epoch 21.712), train_loss = 0.87324605, grad/param norm = 1.3973e-01, time/batch = 17.0579s	
14613/33650 (epoch 21.713), train_loss = 0.87050244, grad/param norm = 1.5371e-01, time/batch = 17.7328s	
14614/33650 (epoch 21.715), train_loss = 1.02678688, grad/param norm = 1.5721e-01, time/batch = 16.9872s	
14615/33650 (epoch 21.716), train_loss = 0.89057112, grad/param norm = 1.4018e-01, time/batch = 17.5622s	
14616/33650 (epoch 21.718), train_loss = 0.91350769, grad/param norm = 1.7026e-01, time/batch = 17.4038s	
14617/33650 (epoch 21.719), train_loss = 1.07205987, grad/param norm = 1.6595e-01, time/batch = 16.5706s	
14618/33650 (epoch 21.721), train_loss = 1.18052989, grad/param norm = 1.7593e-01, time/batch = 16.0607s	
14619/33650 (epoch 21.722), train_loss = 1.05477885, grad/param norm = 1.8696e-01, time/batch = 17.5549s	
14620/33650 (epoch 21.724), train_loss = 1.08460341, grad/param norm = 1.6660e-01, time/batch = 16.7297s	
14621/33650 (epoch 21.725), train_loss = 1.06498408, grad/param norm = 1.5315e-01, time/batch = 17.4733s	
14622/33650 (epoch 21.727), train_loss = 0.89747558, grad/param norm = 1.6296e-01, time/batch = 16.3031s	
14623/33650 (epoch 21.728), train_loss = 0.92847946, grad/param norm = 1.4023e-01, time/batch = 17.9868s	
14624/33650 (epoch 21.730), train_loss = 1.00376323, grad/param norm = 1.5135e-01, time/batch = 17.3222s	
14625/33650 (epoch 21.731), train_loss = 1.10317775, grad/param norm = 1.6408e-01, time/batch = 16.2341s	
14626/33650 (epoch 21.733), train_loss = 0.97416970, grad/param norm = 1.5843e-01, time/batch = 18.0739s	
14627/33650 (epoch 21.734), train_loss = 1.09471991, grad/param norm = 1.9089e-01, time/batch = 17.4942s	
14628/33650 (epoch 21.736), train_loss = 0.99645511, grad/param norm = 1.9182e-01, time/batch = 16.9738s	
14629/33650 (epoch 21.737), train_loss = 1.02357489, grad/param norm = 1.6852e-01, time/batch = 16.8156s	
14630/33650 (epoch 21.738), train_loss = 0.87132363, grad/param norm = 1.3546e-01, time/batch = 16.7315s	
14631/33650 (epoch 21.740), train_loss = 0.82049461, grad/param norm = 1.3812e-01, time/batch = 18.3088s	
14632/33650 (epoch 21.741), train_loss = 0.89335760, grad/param norm = 1.5467e-01, time/batch = 16.0713s	
14633/33650 (epoch 21.743), train_loss = 0.97018183, grad/param norm = 1.5337e-01, time/batch = 16.9106s	
14634/33650 (epoch 21.744), train_loss = 1.01714763, grad/param norm = 1.3827e-01, time/batch = 17.8189s	
14635/33650 (epoch 21.746), train_loss = 0.95243670, grad/param norm = 1.4346e-01, time/batch = 17.7431s	
14636/33650 (epoch 21.747), train_loss = 1.08111929, grad/param norm = 1.4930e-01, time/batch = 17.4909s	
14637/33650 (epoch 21.749), train_loss = 0.82898896, grad/param norm = 1.4200e-01, time/batch = 17.3172s	
14638/33650 (epoch 21.750), train_loss = 1.10150889, grad/param norm = 1.4945e-01, time/batch = 16.4809s	
14639/33650 (epoch 21.752), train_loss = 1.09084853, grad/param norm = 1.6346e-01, time/batch = 15.7969s	
14640/33650 (epoch 21.753), train_loss = 1.16568250, grad/param norm = 1.8555e-01, time/batch = 17.4063s	
14641/33650 (epoch 21.755), train_loss = 0.94057592, grad/param norm = 1.3128e-01, time/batch = 17.3105s	
14642/33650 (epoch 21.756), train_loss = 1.05062413, grad/param norm = 1.5334e-01, time/batch = 17.1523s	
14643/33650 (epoch 21.758), train_loss = 1.03933059, grad/param norm = 1.4426e-01, time/batch = 16.4704s	
14644/33650 (epoch 21.759), train_loss = 1.09897360, grad/param norm = 1.6725e-01, time/batch = 17.8952s	
14645/33650 (epoch 21.761), train_loss = 1.00316041, grad/param norm = 1.4415e-01, time/batch = 17.1622s	
14646/33650 (epoch 21.762), train_loss = 0.97845358, grad/param norm = 1.4128e-01, time/batch = 16.3993s	
14647/33650 (epoch 21.764), train_loss = 1.04832542, grad/param norm = 1.6515e-01, time/batch = 17.9771s	
14648/33650 (epoch 21.765), train_loss = 0.97578679, grad/param norm = 1.5617e-01, time/batch = 16.4713s	
14649/33650 (epoch 21.767), train_loss = 0.97372434, grad/param norm = 1.4192e-01, time/batch = 16.7334s	
14650/33650 (epoch 21.768), train_loss = 0.84417146, grad/param norm = 1.4128e-01, time/batch = 17.1478s	
14651/33650 (epoch 21.770), train_loss = 1.02259942, grad/param norm = 1.5965e-01, time/batch = 17.8239s	
14652/33650 (epoch 21.771), train_loss = 1.00700255, grad/param norm = 1.5193e-01, time/batch = 17.3971s	
14653/33650 (epoch 21.773), train_loss = 1.10676529, grad/param norm = 1.6670e-01, time/batch = 15.8868s	
14654/33650 (epoch 21.774), train_loss = 1.02177934, grad/param norm = 1.8491e-01, time/batch = 17.9102s	
14655/33650 (epoch 21.776), train_loss = 1.08251768, grad/param norm = 1.5896e-01, time/batch = 18.0732s	
14656/33650 (epoch 21.777), train_loss = 0.89778994, grad/param norm = 1.5444e-01, time/batch = 17.0404s	
14657/33650 (epoch 21.779), train_loss = 0.93626718, grad/param norm = 1.3790e-01, time/batch = 16.3942s	
14658/33650 (epoch 21.780), train_loss = 0.87558990, grad/param norm = 1.3848e-01, time/batch = 16.6475s	
14659/33650 (epoch 21.782), train_loss = 0.92857269, grad/param norm = 1.5185e-01, time/batch = 17.4839s	
14660/33650 (epoch 21.783), train_loss = 0.88036578, grad/param norm = 1.2374e-01, time/batch = 16.4779s	
14661/33650 (epoch 21.785), train_loss = 1.17455930, grad/param norm = 1.5045e-01, time/batch = 17.9114s	
14662/33650 (epoch 21.786), train_loss = 1.04553456, grad/param norm = 1.3892e-01, time/batch = 15.4706s	
14663/33650 (epoch 21.788), train_loss = 1.03098555, grad/param norm = 1.5294e-01, time/batch = 14.7886s	
14664/33650 (epoch 21.789), train_loss = 1.06959653, grad/param norm = 1.6469e-01, time/batch = 16.9675s	
14665/33650 (epoch 21.790), train_loss = 1.00985690, grad/param norm = 1.6439e-01, time/batch = 17.4870s	
14666/33650 (epoch 21.792), train_loss = 1.11283363, grad/param norm = 1.7666e-01, time/batch = 17.8087s	
14667/33650 (epoch 21.793), train_loss = 1.06081186, grad/param norm = 1.7764e-01, time/batch = 16.1460s	
14668/33650 (epoch 21.795), train_loss = 1.09371863, grad/param norm = 1.4076e-01, time/batch = 16.4950s	
14669/33650 (epoch 21.796), train_loss = 0.97239782, grad/param norm = 1.6003e-01, time/batch = 17.7308s	
14670/33650 (epoch 21.798), train_loss = 0.95941905, grad/param norm = 1.5467e-01, time/batch = 17.4093s	
14671/33650 (epoch 21.799), train_loss = 0.99192801, grad/param norm = 1.3788e-01, time/batch = 14.2677s	
14672/33650 (epoch 21.801), train_loss = 1.03262380, grad/param norm = 1.8685e-01, time/batch = 15.8601s	
14673/33650 (epoch 21.802), train_loss = 1.10900281, grad/param norm = 1.6985e-01, time/batch = 17.3232s	
14674/33650 (epoch 21.804), train_loss = 0.99740904, grad/param norm = 1.6445e-01, time/batch = 16.3128s	
14675/33650 (epoch 21.805), train_loss = 0.97706028, grad/param norm = 1.2738e-01, time/batch = 16.7110s	
14676/33650 (epoch 21.807), train_loss = 1.18686099, grad/param norm = 1.7897e-01, time/batch = 17.5735s	
14677/33650 (epoch 21.808), train_loss = 1.22596653, grad/param norm = 1.6653e-01, time/batch = 18.3273s	
14678/33650 (epoch 21.810), train_loss = 1.03937871, grad/param norm = 1.5739e-01, time/batch = 16.5492s	
14679/33650 (epoch 21.811), train_loss = 1.01275746, grad/param norm = 1.5202e-01, time/batch = 16.8253s	
14680/33650 (epoch 21.813), train_loss = 0.93111581, grad/param norm = 1.3789e-01, time/batch = 18.2260s	
14681/33650 (epoch 21.814), train_loss = 1.07721110, grad/param norm = 1.6476e-01, time/batch = 16.8089s	
14682/33650 (epoch 21.816), train_loss = 1.07354206, grad/param norm = 1.7385e-01, time/batch = 17.5016s	
14683/33650 (epoch 21.817), train_loss = 1.08433461, grad/param norm = 1.6731e-01, time/batch = 17.1618s	
14684/33650 (epoch 21.819), train_loss = 1.04406196, grad/param norm = 1.5279e-01, time/batch = 16.4736s	
14685/33650 (epoch 21.820), train_loss = 1.12923577, grad/param norm = 1.5402e-01, time/batch = 16.4773s	
14686/33650 (epoch 21.822), train_loss = 1.04473330, grad/param norm = 1.8221e-01, time/batch = 17.3314s	
14687/33650 (epoch 21.823), train_loss = 0.94229120, grad/param norm = 1.8420e-01, time/batch = 17.1562s	
14688/33650 (epoch 21.825), train_loss = 0.99561942, grad/param norm = 1.4861e-01, time/batch = 17.2407s	
14689/33650 (epoch 21.826), train_loss = 1.07142649, grad/param norm = 1.4897e-01, time/batch = 17.1407s	
14690/33650 (epoch 21.828), train_loss = 1.16699386, grad/param norm = 1.7765e-01, time/batch = 17.7286s	
14691/33650 (epoch 21.829), train_loss = 0.84418254, grad/param norm = 1.4333e-01, time/batch = 17.0497s	
14692/33650 (epoch 21.831), train_loss = 1.06837836, grad/param norm = 1.5561e-01, time/batch = 15.7276s	
14693/33650 (epoch 21.832), train_loss = 1.07713126, grad/param norm = 1.6392e-01, time/batch = 18.1435s	
14694/33650 (epoch 21.834), train_loss = 1.07024692, grad/param norm = 1.5512e-01, time/batch = 18.4840s	
14695/33650 (epoch 21.835), train_loss = 1.24640701, grad/param norm = 1.7332e-01, time/batch = 16.6300s	
14696/33650 (epoch 21.837), train_loss = 1.04052394, grad/param norm = 1.6856e-01, time/batch = 18.5709s	
14697/33650 (epoch 21.838), train_loss = 1.02702650, grad/param norm = 1.4906e-01, time/batch = 18.6491s	
14698/33650 (epoch 21.840), train_loss = 1.08756401, grad/param norm = 1.4852e-01, time/batch = 17.6420s	
14699/33650 (epoch 21.841), train_loss = 0.95131187, grad/param norm = 1.5816e-01, time/batch = 18.1255s	
14700/33650 (epoch 21.842), train_loss = 0.98745226, grad/param norm = 1.5671e-01, time/batch = 18.8103s	
14701/33650 (epoch 21.844), train_loss = 1.16908110, grad/param norm = 1.5723e-01, time/batch = 18.6478s	
14702/33650 (epoch 21.845), train_loss = 0.95413641, grad/param norm = 1.4491e-01, time/batch = 17.3791s	
14703/33650 (epoch 21.847), train_loss = 0.76281449, grad/param norm = 1.2364e-01, time/batch = 18.4100s	
14704/33650 (epoch 21.848), train_loss = 0.86101210, grad/param norm = 1.4962e-01, time/batch = 18.4925s	
14705/33650 (epoch 21.850), train_loss = 0.97187773, grad/param norm = 1.7330e-01, time/batch = 16.3014s	
14706/33650 (epoch 21.851), train_loss = 0.81137709, grad/param norm = 1.1536e-01, time/batch = 16.5576s	
14707/33650 (epoch 21.853), train_loss = 0.97815181, grad/param norm = 1.5030e-01, time/batch = 17.8965s	
14708/33650 (epoch 21.854), train_loss = 1.09888449, grad/param norm = 1.6759e-01, time/batch = 17.8044s	
14709/33650 (epoch 21.856), train_loss = 0.76821898, grad/param norm = 1.3784e-01, time/batch = 18.2106s	
14710/33650 (epoch 21.857), train_loss = 0.99872406, grad/param norm = 1.3577e-01, time/batch = 16.6426s	
14711/33650 (epoch 21.859), train_loss = 0.89136837, grad/param norm = 1.2848e-01, time/batch = 18.9811s	
14712/33650 (epoch 21.860), train_loss = 0.83264785, grad/param norm = 1.3252e-01, time/batch = 17.0477s	
14713/33650 (epoch 21.862), train_loss = 0.90150178, grad/param norm = 1.5166e-01, time/batch = 17.5346s	
14714/33650 (epoch 21.863), train_loss = 1.11897813, grad/param norm = 1.5064e-01, time/batch = 18.0667s	
14715/33650 (epoch 21.865), train_loss = 0.94927378, grad/param norm = 1.3488e-01, time/batch = 17.0632s	
14716/33650 (epoch 21.866), train_loss = 0.89151886, grad/param norm = 1.3799e-01, time/batch = 18.8151s	
14717/33650 (epoch 21.868), train_loss = 0.86236137, grad/param norm = 1.4746e-01, time/batch = 17.9013s	
14718/33650 (epoch 21.869), train_loss = 1.08735442, grad/param norm = 1.5658e-01, time/batch = 17.7269s	
14719/33650 (epoch 21.871), train_loss = 0.87074179, grad/param norm = 1.3447e-01, time/batch = 17.5589s	
14720/33650 (epoch 21.872), train_loss = 1.00696093, grad/param norm = 1.5841e-01, time/batch = 18.2272s	
14721/33650 (epoch 21.874), train_loss = 1.06651258, grad/param norm = 1.7345e-01, time/batch = 19.3952s	
14722/33650 (epoch 21.875), train_loss = 0.96048272, grad/param norm = 1.4221e-01, time/batch = 17.5592s	
14723/33650 (epoch 21.877), train_loss = 1.15361434, grad/param norm = 1.5586e-01, time/batch = 18.2203s	
14724/33650 (epoch 21.878), train_loss = 0.70251934, grad/param norm = 1.4246e-01, time/batch = 18.4615s	
14725/33650 (epoch 21.880), train_loss = 1.03017957, grad/param norm = 1.6461e-01, time/batch = 16.4849s	
14726/33650 (epoch 21.881), train_loss = 0.94384982, grad/param norm = 1.5278e-01, time/batch = 18.4736s	
14727/33650 (epoch 21.883), train_loss = 1.00699642, grad/param norm = 1.4291e-01, time/batch = 18.4772s	
14728/33650 (epoch 21.884), train_loss = 1.09408292, grad/param norm = 1.6059e-01, time/batch = 16.3029s	
14729/33650 (epoch 21.886), train_loss = 1.07019826, grad/param norm = 1.8727e-01, time/batch = 18.0362s	
14730/33650 (epoch 21.887), train_loss = 0.89826442, grad/param norm = 1.3071e-01, time/batch = 17.6489s	
14731/33650 (epoch 21.889), train_loss = 0.99347713, grad/param norm = 1.6221e-01, time/batch = 17.0506s	
14732/33650 (epoch 21.890), train_loss = 1.03722924, grad/param norm = 1.4727e-01, time/batch = 17.1451s	
14733/33650 (epoch 21.892), train_loss = 0.98708158, grad/param norm = 1.8311e-01, time/batch = 18.2247s	
14734/33650 (epoch 21.893), train_loss = 1.01786743, grad/param norm = 1.4307e-01, time/batch = 18.8205s	
14735/33650 (epoch 21.895), train_loss = 1.11198054, grad/param norm = 1.5553e-01, time/batch = 16.8972s	
14736/33650 (epoch 21.896), train_loss = 0.92950590, grad/param norm = 1.4763e-01, time/batch = 17.9829s	
14737/33650 (epoch 21.897), train_loss = 0.84317309, grad/param norm = 1.4429e-01, time/batch = 19.0606s	
14738/33650 (epoch 21.899), train_loss = 0.87523351, grad/param norm = 1.3221e-01, time/batch = 18.7323s	
14739/33650 (epoch 21.900), train_loss = 0.81090995, grad/param norm = 1.3239e-01, time/batch = 15.9013s	
14740/33650 (epoch 21.902), train_loss = 0.99497470, grad/param norm = 1.5622e-01, time/batch = 18.5625s	
14741/33650 (epoch 21.903), train_loss = 0.94642091, grad/param norm = 1.4990e-01, time/batch = 16.2700s	
14742/33650 (epoch 21.905), train_loss = 1.12375747, grad/param norm = 1.7021e-01, time/batch = 17.0642s	
14743/33650 (epoch 21.906), train_loss = 0.91133476, grad/param norm = 1.4114e-01, time/batch = 18.1550s	
14744/33650 (epoch 21.908), train_loss = 0.95468911, grad/param norm = 1.4288e-01, time/batch = 18.7330s	
14745/33650 (epoch 21.909), train_loss = 0.92972644, grad/param norm = 1.3901e-01, time/batch = 20.2857s	
14746/33650 (epoch 21.911), train_loss = 0.80500668, grad/param norm = 1.1681e-01, time/batch = 28.8738s	
14747/33650 (epoch 21.912), train_loss = 0.80369757, grad/param norm = 1.3084e-01, time/batch = 18.3163s	
14748/33650 (epoch 21.914), train_loss = 0.97778671, grad/param norm = 1.2961e-01, time/batch = 16.3948s	
14749/33650 (epoch 21.915), train_loss = 0.94698142, grad/param norm = 1.5754e-01, time/batch = 17.6630s	
14750/33650 (epoch 21.917), train_loss = 0.94322456, grad/param norm = 1.4902e-01, time/batch = 18.8973s	
14751/33650 (epoch 21.918), train_loss = 0.80848742, grad/param norm = 1.1729e-01, time/batch = 16.4556s	
14752/33650 (epoch 21.920), train_loss = 0.87432229, grad/param norm = 1.2767e-01, time/batch = 18.0668s	
14753/33650 (epoch 21.921), train_loss = 0.87956689, grad/param norm = 1.3454e-01, time/batch = 17.9860s	
14754/33650 (epoch 21.923), train_loss = 0.82860799, grad/param norm = 1.3665e-01, time/batch = 18.2358s	
14755/33650 (epoch 21.924), train_loss = 0.97679835, grad/param norm = 1.4386e-01, time/batch = 16.7308s	
14756/33650 (epoch 21.926), train_loss = 0.90413768, grad/param norm = 1.5798e-01, time/batch = 17.9837s	
14757/33650 (epoch 21.927), train_loss = 0.94139488, grad/param norm = 1.3942e-01, time/batch = 16.7214s	
14758/33650 (epoch 21.929), train_loss = 1.02829053, grad/param norm = 1.4727e-01, time/batch = 17.3828s	
14759/33650 (epoch 21.930), train_loss = 0.92639358, grad/param norm = 1.4376e-01, time/batch = 18.3133s	
14760/33650 (epoch 21.932), train_loss = 0.93261469, grad/param norm = 1.4387e-01, time/batch = 16.5662s	
14761/33650 (epoch 21.933), train_loss = 0.85226966, grad/param norm = 1.5138e-01, time/batch = 17.8845s	
14762/33650 (epoch 21.935), train_loss = 0.85048758, grad/param norm = 1.4755e-01, time/batch = 16.4478s	
14763/33650 (epoch 21.936), train_loss = 0.90331484, grad/param norm = 1.3978e-01, time/batch = 18.4041s	
14764/33650 (epoch 21.938), train_loss = 0.83471308, grad/param norm = 1.5255e-01, time/batch = 17.5670s	
14765/33650 (epoch 21.939), train_loss = 1.02521801, grad/param norm = 1.3835e-01, time/batch = 17.1380s	
14766/33650 (epoch 21.941), train_loss = 0.96446585, grad/param norm = 1.3603e-01, time/batch = 17.3077s	
14767/33650 (epoch 21.942), train_loss = 1.04958590, grad/param norm = 1.7671e-01, time/batch = 17.0499s	
14768/33650 (epoch 21.944), train_loss = 0.93566520, grad/param norm = 1.3338e-01, time/batch = 16.8102s	
14769/33650 (epoch 21.945), train_loss = 1.00235137, grad/param norm = 1.5208e-01, time/batch = 18.4739s	
14770/33650 (epoch 21.947), train_loss = 1.08929611, grad/param norm = 1.9653e-01, time/batch = 18.3070s	
14771/33650 (epoch 21.948), train_loss = 1.11479084, grad/param norm = 1.5216e-01, time/batch = 17.9911s	
14772/33650 (epoch 21.949), train_loss = 0.84688750, grad/param norm = 1.4306e-01, time/batch = 17.1454s	
14773/33650 (epoch 21.951), train_loss = 1.10204488, grad/param norm = 1.5293e-01, time/batch = 17.3264s	
14774/33650 (epoch 21.952), train_loss = 1.03580149, grad/param norm = 1.6505e-01, time/batch = 17.0465s	
14775/33650 (epoch 21.954), train_loss = 1.03909938, grad/param norm = 1.4476e-01, time/batch = 16.7265s	
14776/33650 (epoch 21.955), train_loss = 1.01636233, grad/param norm = 1.4462e-01, time/batch = 17.6507s	
14777/33650 (epoch 21.957), train_loss = 1.04349887, grad/param norm = 1.7457e-01, time/batch = 18.8136s	
14778/33650 (epoch 21.958), train_loss = 0.77282013, grad/param norm = 1.3027e-01, time/batch = 15.7182s	
14779/33650 (epoch 21.960), train_loss = 0.80018564, grad/param norm = 1.2678e-01, time/batch = 17.0404s	
14780/33650 (epoch 21.961), train_loss = 0.86115102, grad/param norm = 1.4345e-01, time/batch = 17.4651s	
14781/33650 (epoch 21.963), train_loss = 0.90967136, grad/param norm = 1.4576e-01, time/batch = 16.1362s	
14782/33650 (epoch 21.964), train_loss = 1.02834762, grad/param norm = 1.5456e-01, time/batch = 17.7072s	
14783/33650 (epoch 21.966), train_loss = 0.98314379, grad/param norm = 1.4870e-01, time/batch = 17.5679s	
14784/33650 (epoch 21.967), train_loss = 1.01163818, grad/param norm = 1.5050e-01, time/batch = 18.7194s	
14785/33650 (epoch 21.969), train_loss = 0.96787770, grad/param norm = 1.3326e-01, time/batch = 16.6461s	
14786/33650 (epoch 21.970), train_loss = 1.00237829, grad/param norm = 1.5770e-01, time/batch = 17.7191s	
14787/33650 (epoch 21.972), train_loss = 1.27629771, grad/param norm = 1.8917e-01, time/batch = 17.4028s	
14788/33650 (epoch 21.973), train_loss = 0.87271533, grad/param norm = 1.3155e-01, time/batch = 18.8070s	
14789/33650 (epoch 21.975), train_loss = 0.87306869, grad/param norm = 1.3811e-01, time/batch = 16.8047s	
14790/33650 (epoch 21.976), train_loss = 0.88102613, grad/param norm = 1.2453e-01, time/batch = 18.3212s	
14791/33650 (epoch 21.978), train_loss = 0.90901692, grad/param norm = 1.4477e-01, time/batch = 18.4788s	
14792/33650 (epoch 21.979), train_loss = 0.95090768, grad/param norm = 1.5261e-01, time/batch = 17.3972s	
14793/33650 (epoch 21.981), train_loss = 0.91064104, grad/param norm = 1.2405e-01, time/batch = 17.9811s	
14794/33650 (epoch 21.982), train_loss = 1.00076925, grad/param norm = 1.4735e-01, time/batch = 17.8926s	
14795/33650 (epoch 21.984), train_loss = 0.80574446, grad/param norm = 1.2916e-01, time/batch = 18.3213s	
14796/33650 (epoch 21.985), train_loss = 0.82669667, grad/param norm = 1.3865e-01, time/batch = 18.2301s	
14797/33650 (epoch 21.987), train_loss = 0.95428799, grad/param norm = 1.3773e-01, time/batch = 18.2252s	
14798/33650 (epoch 21.988), train_loss = 0.97530399, grad/param norm = 1.6672e-01, time/batch = 17.9712s	
14799/33650 (epoch 21.990), train_loss = 1.14323349, grad/param norm = 1.6197e-01, time/batch = 16.0469s	
14800/33650 (epoch 21.991), train_loss = 1.00756186, grad/param norm = 1.4391e-01, time/batch = 17.4004s	
14801/33650 (epoch 21.993), train_loss = 0.99284786, grad/param norm = 1.8305e-01, time/batch = 17.8161s	
14802/33650 (epoch 21.994), train_loss = 0.94038362, grad/param norm = 1.3479e-01, time/batch = 17.1406s	
14803/33650 (epoch 21.996), train_loss = 0.89327515, grad/param norm = 1.4404e-01, time/batch = 17.9720s	
14804/33650 (epoch 21.997), train_loss = 1.02983189, grad/param norm = 1.4932e-01, time/batch = 16.3822s	
14805/33650 (epoch 21.999), train_loss = 0.89775958, grad/param norm = 1.4065e-01, time/batch = 17.3835s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
14806/33650 (epoch 22.000), train_loss = 1.05590766, grad/param norm = 1.7233e-01, time/batch = 17.4668s	
14807/33650 (epoch 22.001), train_loss = 1.13589744, grad/param norm = 1.5865e-01, time/batch = 18.1553s	
14808/33650 (epoch 22.003), train_loss = 1.12977137, grad/param norm = 2.0190e-01, time/batch = 17.5630s	
14809/33650 (epoch 22.004), train_loss = 1.00366522, grad/param norm = 1.5720e-01, time/batch = 17.3842s	
14810/33650 (epoch 22.006), train_loss = 0.93039491, grad/param norm = 1.3903e-01, time/batch = 18.3085s	
14811/33650 (epoch 22.007), train_loss = 1.03385648, grad/param norm = 1.6590e-01, time/batch = 17.8845s	
14812/33650 (epoch 22.009), train_loss = 0.92808119, grad/param norm = 1.4579e-01, time/batch = 17.3990s	
14813/33650 (epoch 22.010), train_loss = 1.06344686, grad/param norm = 1.6502e-01, time/batch = 18.8025s	
14814/33650 (epoch 22.012), train_loss = 0.90512038, grad/param norm = 1.3935e-01, time/batch = 18.6211s	
14815/33650 (epoch 22.013), train_loss = 0.97897330, grad/param norm = 1.6840e-01, time/batch = 17.9908s	
14816/33650 (epoch 22.015), train_loss = 0.93507979, grad/param norm = 1.4270e-01, time/batch = 16.8840s	
14817/33650 (epoch 22.016), train_loss = 0.86935925, grad/param norm = 1.5977e-01, time/batch = 18.0638s	
14818/33650 (epoch 22.018), train_loss = 0.95847517, grad/param norm = 1.6983e-01, time/batch = 19.1353s	
14819/33650 (epoch 22.019), train_loss = 0.91368868, grad/param norm = 1.5111e-01, time/batch = 16.2891s	
14820/33650 (epoch 22.021), train_loss = 1.01042680, grad/param norm = 1.5283e-01, time/batch = 18.3178s	
14821/33650 (epoch 22.022), train_loss = 0.91459825, grad/param norm = 1.3399e-01, time/batch = 17.5456s	
14822/33650 (epoch 22.024), train_loss = 0.88318590, grad/param norm = 1.4250e-01, time/batch = 16.8215s	
14823/33650 (epoch 22.025), train_loss = 0.95768553, grad/param norm = 1.6802e-01, time/batch = 17.8039s	
14824/33650 (epoch 22.027), train_loss = 1.02246159, grad/param norm = 1.7097e-01, time/batch = 17.3154s	
14825/33650 (epoch 22.028), train_loss = 1.05251650, grad/param norm = 1.5074e-01, time/batch = 15.8972s	
14826/33650 (epoch 22.030), train_loss = 0.97354013, grad/param norm = 1.4597e-01, time/batch = 16.3691s	
14827/33650 (epoch 22.031), train_loss = 0.87172110, grad/param norm = 1.3995e-01, time/batch = 18.2244s	
14828/33650 (epoch 22.033), train_loss = 0.94095721, grad/param norm = 1.2397e-01, time/batch = 17.9777s	
14829/33650 (epoch 22.034), train_loss = 0.99986738, grad/param norm = 1.5170e-01, time/batch = 17.4687s	
14830/33650 (epoch 22.036), train_loss = 1.09017061, grad/param norm = 1.6400e-01, time/batch = 17.4731s	
14831/33650 (epoch 22.037), train_loss = 0.93530259, grad/param norm = 1.4143e-01, time/batch = 17.5651s	
14832/33650 (epoch 22.039), train_loss = 1.05161078, grad/param norm = 1.5329e-01, time/batch = 17.3951s	
14833/33650 (epoch 22.040), train_loss = 1.15130813, grad/param norm = 1.7942e-01, time/batch = 16.8946s	
14834/33650 (epoch 22.042), train_loss = 1.16030844, grad/param norm = 1.7811e-01, time/batch = 18.0627s	
14835/33650 (epoch 22.043), train_loss = 0.91248037, grad/param norm = 1.3844e-01, time/batch = 17.0576s	
14836/33650 (epoch 22.045), train_loss = 0.90245616, grad/param norm = 1.4429e-01, time/batch = 16.9713s	
14837/33650 (epoch 22.046), train_loss = 1.03082502, grad/param norm = 1.4831e-01, time/batch = 18.8831s	
14838/33650 (epoch 22.048), train_loss = 1.07933432, grad/param norm = 1.5321e-01, time/batch = 15.4644s	
14839/33650 (epoch 22.049), train_loss = 0.96219677, grad/param norm = 1.4856e-01, time/batch = 14.3816s	
14840/33650 (epoch 22.051), train_loss = 1.11187108, grad/param norm = 1.5621e-01, time/batch = 15.4649s	
14841/33650 (epoch 22.052), train_loss = 1.09446148, grad/param norm = 1.6544e-01, time/batch = 14.7661s	
14842/33650 (epoch 22.053), train_loss = 1.02960922, grad/param norm = 1.3920e-01, time/batch = 14.8906s	
14843/33650 (epoch 22.055), train_loss = 0.85780828, grad/param norm = 1.3160e-01, time/batch = 16.5517s	
14844/33650 (epoch 22.056), train_loss = 0.85158672, grad/param norm = 1.2305e-01, time/batch = 17.6408s	
14845/33650 (epoch 22.058), train_loss = 1.05810925, grad/param norm = 1.6160e-01, time/batch = 18.4009s	
14846/33650 (epoch 22.059), train_loss = 1.02652851, grad/param norm = 1.6376e-01, time/batch = 18.7992s	
14847/33650 (epoch 22.061), train_loss = 1.05080661, grad/param norm = 1.6176e-01, time/batch = 15.8144s	
14848/33650 (epoch 22.062), train_loss = 1.03506956, grad/param norm = 1.4127e-01, time/batch = 18.5648s	
14849/33650 (epoch 22.064), train_loss = 0.93371702, grad/param norm = 1.3088e-01, time/batch = 17.4765s	
14850/33650 (epoch 22.065), train_loss = 0.91395807, grad/param norm = 1.3351e-01, time/batch = 16.6188s	
14851/33650 (epoch 22.067), train_loss = 0.85241577, grad/param norm = 1.2795e-01, time/batch = 17.4787s	
14852/33650 (epoch 22.068), train_loss = 0.97699878, grad/param norm = 1.6163e-01, time/batch = 18.6322s	
14853/33650 (epoch 22.070), train_loss = 1.02026728, grad/param norm = 1.6056e-01, time/batch = 18.5755s	
14854/33650 (epoch 22.071), train_loss = 0.97635226, grad/param norm = 1.4920e-01, time/batch = 16.6351s	
14855/33650 (epoch 22.073), train_loss = 1.01477218, grad/param norm = 1.5993e-01, time/batch = 17.9828s	
14856/33650 (epoch 22.074), train_loss = 1.10652765, grad/param norm = 1.4801e-01, time/batch = 18.8160s	
14857/33650 (epoch 22.076), train_loss = 1.06813795, grad/param norm = 1.6412e-01, time/batch = 17.7179s	
14858/33650 (epoch 22.077), train_loss = 0.96175365, grad/param norm = 1.4033e-01, time/batch = 16.8868s	
14859/33650 (epoch 22.079), train_loss = 1.00118468, grad/param norm = 1.3933e-01, time/batch = 18.0643s	
14860/33650 (epoch 22.080), train_loss = 1.01110437, grad/param norm = 1.4210e-01, time/batch = 17.5740s	
14861/33650 (epoch 22.082), train_loss = 0.98928252, grad/param norm = 1.3850e-01, time/batch = 17.5425s	
14862/33650 (epoch 22.083), train_loss = 1.04822766, grad/param norm = 1.5887e-01, time/batch = 17.8896s	
14863/33650 (epoch 22.085), train_loss = 1.07381391, grad/param norm = 1.4847e-01, time/batch = 17.6505s	
14864/33650 (epoch 22.086), train_loss = 1.05829914, grad/param norm = 1.7249e-01, time/batch = 17.4631s	
14865/33650 (epoch 22.088), train_loss = 1.01863025, grad/param norm = 1.6019e-01, time/batch = 18.0711s	
14866/33650 (epoch 22.089), train_loss = 0.95086669, grad/param norm = 1.6674e-01, time/batch = 17.9670s	
14867/33650 (epoch 22.091), train_loss = 0.92515564, grad/param norm = 1.3588e-01, time/batch = 17.6425s	
14868/33650 (epoch 22.092), train_loss = 0.97308501, grad/param norm = 1.5412e-01, time/batch = 18.8921s	
14869/33650 (epoch 22.094), train_loss = 1.05730388, grad/param norm = 1.4165e-01, time/batch = 17.4803s	
14870/33650 (epoch 22.095), train_loss = 1.04017214, grad/param norm = 1.7739e-01, time/batch = 17.4839s	
14871/33650 (epoch 22.097), train_loss = 0.92323751, grad/param norm = 1.5735e-01, time/batch = 17.5924s	
14872/33650 (epoch 22.098), train_loss = 0.80298677, grad/param norm = 1.3966e-01, time/batch = 17.2200s	
14873/33650 (epoch 22.100), train_loss = 0.91921293, grad/param norm = 1.4854e-01, time/batch = 18.3902s	
14874/33650 (epoch 22.101), train_loss = 0.98700892, grad/param norm = 1.5261e-01, time/batch = 16.9785s	
14875/33650 (epoch 22.103), train_loss = 0.94830787, grad/param norm = 1.6247e-01, time/batch = 18.5662s	
14876/33650 (epoch 22.104), train_loss = 1.09418716, grad/param norm = 1.5464e-01, time/batch = 16.8271s	
14877/33650 (epoch 22.105), train_loss = 0.98166912, grad/param norm = 1.5132e-01, time/batch = 16.4999s	
14878/33650 (epoch 22.107), train_loss = 0.91601712, grad/param norm = 1.4077e-01, time/batch = 17.0614s	
14879/33650 (epoch 22.108), train_loss = 1.06528964, grad/param norm = 1.5215e-01, time/batch = 17.7398s	
14880/33650 (epoch 22.110), train_loss = 1.15688956, grad/param norm = 1.6580e-01, time/batch = 17.5716s	
14881/33650 (epoch 22.111), train_loss = 0.93505775, grad/param norm = 1.4820e-01, time/batch = 15.5688s	
14882/33650 (epoch 22.113), train_loss = 0.95489639, grad/param norm = 1.5275e-01, time/batch = 16.2307s	
14883/33650 (epoch 22.114), train_loss = 1.07237606, grad/param norm = 1.5763e-01, time/batch = 17.9016s	
14884/33650 (epoch 22.116), train_loss = 0.90068517, grad/param norm = 1.3951e-01, time/batch = 17.7321s	
14885/33650 (epoch 22.117), train_loss = 0.97833507, grad/param norm = 1.3141e-01, time/batch = 17.1410s	
14886/33650 (epoch 22.119), train_loss = 0.87309155, grad/param norm = 1.3201e-01, time/batch = 16.9932s	
14887/33650 (epoch 22.120), train_loss = 0.94261843, grad/param norm = 1.4192e-01, time/batch = 17.8171s	
14888/33650 (epoch 22.122), train_loss = 0.76891176, grad/param norm = 1.4176e-01, time/batch = 15.7328s	
14889/33650 (epoch 22.123), train_loss = 0.93463624, grad/param norm = 1.3369e-01, time/batch = 17.9014s	
14890/33650 (epoch 22.125), train_loss = 1.02463569, grad/param norm = 1.5762e-01, time/batch = 17.2432s	
14891/33650 (epoch 22.126), train_loss = 1.09854142, grad/param norm = 1.6306e-01, time/batch = 17.6572s	
14892/33650 (epoch 22.128), train_loss = 1.07802518, grad/param norm = 1.6334e-01, time/batch = 16.4736s	
14893/33650 (epoch 22.129), train_loss = 1.09231794, grad/param norm = 1.5564e-01, time/batch = 17.3126s	
14894/33650 (epoch 22.131), train_loss = 0.99214795, grad/param norm = 1.5212e-01, time/batch = 15.2227s	
14895/33650 (epoch 22.132), train_loss = 0.99968356, grad/param norm = 1.5941e-01, time/batch = 16.2434s	
14896/33650 (epoch 22.134), train_loss = 1.07319349, grad/param norm = 1.5654e-01, time/batch = 16.3199s	
14897/33650 (epoch 22.135), train_loss = 0.87429537, grad/param norm = 1.4703e-01, time/batch = 17.4893s	
14898/33650 (epoch 22.137), train_loss = 1.00623502, grad/param norm = 1.5562e-01, time/batch = 17.5605s	
14899/33650 (epoch 22.138), train_loss = 1.04143838, grad/param norm = 1.4307e-01, time/batch = 16.7988s	
14900/33650 (epoch 22.140), train_loss = 0.96385744, grad/param norm = 1.7801e-01, time/batch = 17.2420s	
14901/33650 (epoch 22.141), train_loss = 1.12234067, grad/param norm = 1.5661e-01, time/batch = 16.7180s	
14902/33650 (epoch 22.143), train_loss = 1.14684868, grad/param norm = 1.7833e-01, time/batch = 15.2180s	
14903/33650 (epoch 22.144), train_loss = 1.05665095, grad/param norm = 1.7350e-01, time/batch = 17.6555s	
14904/33650 (epoch 22.146), train_loss = 0.96113222, grad/param norm = 1.5100e-01, time/batch = 16.9127s	
14905/33650 (epoch 22.147), train_loss = 0.91781882, grad/param norm = 1.4625e-01, time/batch = 16.8153s	
14906/33650 (epoch 22.149), train_loss = 0.88875566, grad/param norm = 1.5382e-01, time/batch = 16.1333s	
14907/33650 (epoch 22.150), train_loss = 0.86704839, grad/param norm = 1.4505e-01, time/batch = 17.4832s	
14908/33650 (epoch 22.152), train_loss = 0.91970022, grad/param norm = 1.4246e-01, time/batch = 17.1430s	
14909/33650 (epoch 22.153), train_loss = 0.93738001, grad/param norm = 1.3447e-01, time/batch = 16.0558s	
14910/33650 (epoch 22.155), train_loss = 0.91784393, grad/param norm = 1.3178e-01, time/batch = 14.7260s	
14911/33650 (epoch 22.156), train_loss = 0.88350180, grad/param norm = 1.3321e-01, time/batch = 17.8149s	
14912/33650 (epoch 22.158), train_loss = 1.02186076, grad/param norm = 1.7341e-01, time/batch = 17.0627s	
14913/33650 (epoch 22.159), train_loss = 0.89093162, grad/param norm = 1.2582e-01, time/batch = 15.9748s	
14914/33650 (epoch 22.160), train_loss = 0.91803757, grad/param norm = 1.3231e-01, time/batch = 18.4806s	
14915/33650 (epoch 22.162), train_loss = 0.95307158, grad/param norm = 1.6205e-01, time/batch = 17.3098s	
14916/33650 (epoch 22.163), train_loss = 1.04254697, grad/param norm = 1.7597e-01, time/batch = 16.8029s	
14917/33650 (epoch 22.165), train_loss = 0.87895972, grad/param norm = 1.5146e-01, time/batch = 17.2319s	
14918/33650 (epoch 22.166), train_loss = 0.88235591, grad/param norm = 1.4445e-01, time/batch = 17.7363s	
14919/33650 (epoch 22.168), train_loss = 1.06339658, grad/param norm = 1.5488e-01, time/batch = 16.6608s	
14920/33650 (epoch 22.169), train_loss = 1.00224221, grad/param norm = 1.5470e-01, time/batch = 16.7372s	
14921/33650 (epoch 22.171), train_loss = 0.96575840, grad/param norm = 1.4236e-01, time/batch = 16.6665s	
14922/33650 (epoch 22.172), train_loss = 0.92860651, grad/param norm = 1.5086e-01, time/batch = 17.8975s	
14923/33650 (epoch 22.174), train_loss = 0.90657876, grad/param norm = 1.6121e-01, time/batch = 17.1339s	
14924/33650 (epoch 22.175), train_loss = 0.87166663, grad/param norm = 1.6010e-01, time/batch = 17.3175s	
14925/33650 (epoch 22.177), train_loss = 0.97961374, grad/param norm = 1.4781e-01, time/batch = 16.4642s	
14926/33650 (epoch 22.178), train_loss = 0.91701173, grad/param norm = 1.6712e-01, time/batch = 17.3982s	
14927/33650 (epoch 22.180), train_loss = 0.86744207, grad/param norm = 1.3860e-01, time/batch = 16.9045s	
14928/33650 (epoch 22.181), train_loss = 0.79254958, grad/param norm = 1.3049e-01, time/batch = 16.4959s	
14929/33650 (epoch 22.183), train_loss = 0.91701731, grad/param norm = 1.7643e-01, time/batch = 15.8240s	
14930/33650 (epoch 22.184), train_loss = 0.91203122, grad/param norm = 1.5355e-01, time/batch = 17.3035s	
14931/33650 (epoch 22.186), train_loss = 0.95391001, grad/param norm = 1.9130e-01, time/batch = 17.3096s	
14932/33650 (epoch 22.187), train_loss = 1.12251602, grad/param norm = 1.6290e-01, time/batch = 18.2380s	
14933/33650 (epoch 22.189), train_loss = 1.06549006, grad/param norm = 1.6969e-01, time/batch = 18.1474s	
14934/33650 (epoch 22.190), train_loss = 0.99317423, grad/param norm = 1.6410e-01, time/batch = 16.7229s	
14935/33650 (epoch 22.192), train_loss = 1.15646954, grad/param norm = 1.4955e-01, time/batch = 15.8806s	
14936/33650 (epoch 22.193), train_loss = 1.09702683, grad/param norm = 1.4777e-01, time/batch = 17.9862s	
14937/33650 (epoch 22.195), train_loss = 0.86433925, grad/param norm = 1.3762e-01, time/batch = 16.3875s	
14938/33650 (epoch 22.196), train_loss = 0.83861688, grad/param norm = 1.4733e-01, time/batch = 16.4844s	
14939/33650 (epoch 22.198), train_loss = 0.92573150, grad/param norm = 1.5740e-01, time/batch = 17.5698s	
14940/33650 (epoch 22.199), train_loss = 1.06269601, grad/param norm = 1.7511e-01, time/batch = 17.6486s	
14941/33650 (epoch 22.201), train_loss = 0.93280429, grad/param norm = 1.5058e-01, time/batch = 16.7189s	
14942/33650 (epoch 22.202), train_loss = 0.94081642, grad/param norm = 1.5210e-01, time/batch = 17.4840s	
14943/33650 (epoch 22.204), train_loss = 1.03149305, grad/param norm = 1.5582e-01, time/batch = 17.5835s	
14944/33650 (epoch 22.205), train_loss = 0.96282503, grad/param norm = 1.5024e-01, time/batch = 16.5772s	
14945/33650 (epoch 22.207), train_loss = 0.91784366, grad/param norm = 1.4911e-01, time/batch = 17.2442s	
14946/33650 (epoch 22.208), train_loss = 0.98204246, grad/param norm = 1.5429e-01, time/batch = 17.4915s	
14947/33650 (epoch 22.210), train_loss = 0.79568061, grad/param norm = 1.5842e-01, time/batch = 17.6503s	
14948/33650 (epoch 22.211), train_loss = 0.90829442, grad/param norm = 1.6217e-01, time/batch = 17.6364s	
14949/33650 (epoch 22.212), train_loss = 1.03931456, grad/param norm = 1.8833e-01, time/batch = 18.0744s	
14950/33650 (epoch 22.214), train_loss = 1.13983668, grad/param norm = 1.6229e-01, time/batch = 17.5640s	
14951/33650 (epoch 22.215), train_loss = 0.76072622, grad/param norm = 1.3311e-01, time/batch = 25.4725s	
14952/33650 (epoch 22.217), train_loss = 0.95678331, grad/param norm = 1.7454e-01, time/batch = 21.9591s	
14953/33650 (epoch 22.218), train_loss = 0.98696333, grad/param norm = 1.4444e-01, time/batch = 16.7489s	
14954/33650 (epoch 22.220), train_loss = 0.86338452, grad/param norm = 1.4279e-01, time/batch = 16.4055s	
14955/33650 (epoch 22.221), train_loss = 1.14789691, grad/param norm = 1.6957e-01, time/batch = 17.3303s	
14956/33650 (epoch 22.223), train_loss = 0.78750130, grad/param norm = 1.4365e-01, time/batch = 17.6545s	
14957/33650 (epoch 22.224), train_loss = 0.92838155, grad/param norm = 1.6273e-01, time/batch = 16.7300s	
14958/33650 (epoch 22.226), train_loss = 1.24722395, grad/param norm = 1.7438e-01, time/batch = 14.7661s	
14959/33650 (epoch 22.227), train_loss = 1.09888606, grad/param norm = 1.7881e-01, time/batch = 16.6209s	
14960/33650 (epoch 22.229), train_loss = 1.08667671, grad/param norm = 1.5652e-01, time/batch = 18.8664s	
14961/33650 (epoch 22.230), train_loss = 1.22422993, grad/param norm = 1.7217e-01, time/batch = 16.7053s	
14962/33650 (epoch 22.232), train_loss = 1.06239909, grad/param norm = 1.7442e-01, time/batch = 17.1179s	
14963/33650 (epoch 22.233), train_loss = 1.02418299, grad/param norm = 1.7800e-01, time/batch = 15.4051s	
14964/33650 (epoch 22.235), train_loss = 0.97585464, grad/param norm = 1.5003e-01, time/batch = 15.4867s	
14965/33650 (epoch 22.236), train_loss = 0.87188168, grad/param norm = 1.3617e-01, time/batch = 15.8051s	
14966/33650 (epoch 22.238), train_loss = 0.94861518, grad/param norm = 1.4211e-01, time/batch = 15.6372s	
14967/33650 (epoch 22.239), train_loss = 0.90027115, grad/param norm = 1.4844e-01, time/batch = 15.7017s	
14968/33650 (epoch 22.241), train_loss = 0.93814023, grad/param norm = 1.4389e-01, time/batch = 15.7278s	
14969/33650 (epoch 22.242), train_loss = 0.79927807, grad/param norm = 1.5176e-01, time/batch = 15.5639s	
14970/33650 (epoch 22.244), train_loss = 0.95257559, grad/param norm = 1.5232e-01, time/batch = 15.4826s	
14971/33650 (epoch 22.245), train_loss = 0.84901204, grad/param norm = 1.2802e-01, time/batch = 15.5709s	
14972/33650 (epoch 22.247), train_loss = 0.95813228, grad/param norm = 1.3854e-01, time/batch = 15.6484s	
14973/33650 (epoch 22.248), train_loss = 0.85108247, grad/param norm = 1.3483e-01, time/batch = 15.4834s	
14974/33650 (epoch 22.250), train_loss = 0.95338085, grad/param norm = 1.5632e-01, time/batch = 15.4026s	
14975/33650 (epoch 22.251), train_loss = 1.09508877, grad/param norm = 1.4465e-01, time/batch = 15.4890s	
14976/33650 (epoch 22.253), train_loss = 0.83809609, grad/param norm = 1.3243e-01, time/batch = 15.6412s	
14977/33650 (epoch 22.254), train_loss = 0.87756984, grad/param norm = 1.6429e-01, time/batch = 15.7244s	
14978/33650 (epoch 22.256), train_loss = 1.10153293, grad/param norm = 1.4426e-01, time/batch = 15.5602s	
14979/33650 (epoch 22.257), train_loss = 1.10457795, grad/param norm = 1.5937e-01, time/batch = 15.4856s	
14980/33650 (epoch 22.259), train_loss = 0.82322069, grad/param norm = 1.2707e-01, time/batch = 15.7993s	
14981/33650 (epoch 22.260), train_loss = 1.04709549, grad/param norm = 1.5586e-01, time/batch = 15.7320s	
14982/33650 (epoch 22.262), train_loss = 0.99242862, grad/param norm = 1.6008e-01, time/batch = 15.7261s	
14983/33650 (epoch 22.263), train_loss = 0.92159287, grad/param norm = 1.7139e-01, time/batch = 15.4132s	
14984/33650 (epoch 22.264), train_loss = 1.02078569, grad/param norm = 1.5047e-01, time/batch = 15.7320s	
14985/33650 (epoch 22.266), train_loss = 0.99748384, grad/param norm = 1.3876e-01, time/batch = 15.6464s	
14986/33650 (epoch 22.267), train_loss = 0.90199663, grad/param norm = 1.4354e-01, time/batch = 15.4933s	
14987/33650 (epoch 22.269), train_loss = 1.00067713, grad/param norm = 1.4970e-01, time/batch = 15.6481s	
14988/33650 (epoch 22.270), train_loss = 0.89490961, grad/param norm = 1.4913e-01, time/batch = 15.6478s	
14989/33650 (epoch 22.272), train_loss = 0.93463828, grad/param norm = 1.3808e-01, time/batch = 15.6504s	
14990/33650 (epoch 22.273), train_loss = 1.07702211, grad/param norm = 1.7775e-01, time/batch = 15.8066s	
14991/33650 (epoch 22.275), train_loss = 1.04084666, grad/param norm = 1.6251e-01, time/batch = 15.7305s	
14992/33650 (epoch 22.276), train_loss = 1.08338466, grad/param norm = 1.6753e-01, time/batch = 15.5741s	
14993/33650 (epoch 22.278), train_loss = 1.15319537, grad/param norm = 1.9020e-01, time/batch = 15.4964s	
14994/33650 (epoch 22.279), train_loss = 0.94085235, grad/param norm = 1.3271e-01, time/batch = 15.6500s	
14995/33650 (epoch 22.281), train_loss = 1.01358498, grad/param norm = 1.4584e-01, time/batch = 15.8080s	
14996/33650 (epoch 22.282), train_loss = 1.08289210, grad/param norm = 1.4010e-01, time/batch = 15.7237s	
14997/33650 (epoch 22.284), train_loss = 1.05573932, grad/param norm = 1.7192e-01, time/batch = 15.5696s	
14998/33650 (epoch 22.285), train_loss = 1.03881156, grad/param norm = 1.6111e-01, time/batch = 15.5732s	
14999/33650 (epoch 22.287), train_loss = 0.95175770, grad/param norm = 1.5677e-01, time/batch = 15.7287s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch22.29_1.6014.t7	
15000/33650 (epoch 22.288), train_loss = 1.02789466, grad/param norm = 1.7889e-01, time/batch = 15.4947s	
15001/33650 (epoch 22.290), train_loss = 1.33357523, grad/param norm = 1.7678e-01, time/batch = 0.6918s	
15002/33650 (epoch 22.291), train_loss = 0.89868934, grad/param norm = 1.4347e-01, time/batch = 0.6895s	
15003/33650 (epoch 22.293), train_loss = 0.95314928, grad/param norm = 1.5929e-01, time/batch = 0.6848s	
15004/33650 (epoch 22.294), train_loss = 0.89224529, grad/param norm = 1.3944e-01, time/batch = 0.6830s	
15005/33650 (epoch 22.296), train_loss = 0.88256422, grad/param norm = 1.5031e-01, time/batch = 0.8796s	
15006/33650 (epoch 22.297), train_loss = 0.95777341, grad/param norm = 1.5265e-01, time/batch = 0.9953s	
15007/33650 (epoch 22.299), train_loss = 0.83589880, grad/param norm = 1.4034e-01, time/batch = 0.9875s	
15008/33650 (epoch 22.300), train_loss = 0.87330000, grad/param norm = 1.5112e-01, time/batch = 1.0045s	
15009/33650 (epoch 22.302), train_loss = 1.00178521, grad/param norm = 1.3807e-01, time/batch = 1.0018s	
15010/33650 (epoch 22.303), train_loss = 1.00881709, grad/param norm = 1.4484e-01, time/batch = 1.5580s	
15011/33650 (epoch 22.305), train_loss = 0.99669693, grad/param norm = 1.5815e-01, time/batch = 1.8772s	
15012/33650 (epoch 22.306), train_loss = 0.90776988, grad/param norm = 1.4936e-01, time/batch = 2.0171s	
15013/33650 (epoch 22.308), train_loss = 0.83851889, grad/param norm = 1.4797e-01, time/batch = 15.6476s	
15014/33650 (epoch 22.309), train_loss = 1.13328810, grad/param norm = 1.5631e-01, time/batch = 15.8076s	
15015/33650 (epoch 22.311), train_loss = 0.99471705, grad/param norm = 1.6112e-01, time/batch = 15.7292s	
15016/33650 (epoch 22.312), train_loss = 0.97125838, grad/param norm = 1.5961e-01, time/batch = 15.5734s	
15017/33650 (epoch 22.314), train_loss = 0.85322236, grad/param norm = 1.2642e-01, time/batch = 15.5698s	
15018/33650 (epoch 22.315), train_loss = 0.96864712, grad/param norm = 1.9002e-01, time/batch = 15.5774s	
15019/33650 (epoch 22.316), train_loss = 0.92225931, grad/param norm = 1.7027e-01, time/batch = 15.9764s	
15020/33650 (epoch 22.318), train_loss = 0.88605806, grad/param norm = 1.3866e-01, time/batch = 15.7333s	
15021/33650 (epoch 22.319), train_loss = 0.90242077, grad/param norm = 1.3199e-01, time/batch = 15.5729s	
15022/33650 (epoch 22.321), train_loss = 0.90434570, grad/param norm = 1.3783e-01, time/batch = 15.8009s	
15023/33650 (epoch 22.322), train_loss = 0.99995799, grad/param norm = 1.6850e-01, time/batch = 15.5592s	
15024/33650 (epoch 22.324), train_loss = 1.04119065, grad/param norm = 1.8735e-01, time/batch = 15.4872s	
15025/33650 (epoch 22.325), train_loss = 1.03323306, grad/param norm = 1.6055e-01, time/batch = 15.5610s	
15026/33650 (epoch 22.327), train_loss = 0.88274826, grad/param norm = 1.2141e-01, time/batch = 15.4833s	
15027/33650 (epoch 22.328), train_loss = 1.02009202, grad/param norm = 1.4970e-01, time/batch = 15.5634s	
15028/33650 (epoch 22.330), train_loss = 0.90130010, grad/param norm = 1.5195e-01, time/batch = 15.4067s	
15029/33650 (epoch 22.331), train_loss = 0.80556630, grad/param norm = 1.2769e-01, time/batch = 15.4820s	
15030/33650 (epoch 22.333), train_loss = 0.94519536, grad/param norm = 1.5572e-01, time/batch = 15.6261s	
15031/33650 (epoch 22.334), train_loss = 0.95430343, grad/param norm = 1.5260e-01, time/batch = 15.6490s	
15032/33650 (epoch 22.336), train_loss = 1.07225586, grad/param norm = 1.4602e-01, time/batch = 15.9642s	
15033/33650 (epoch 22.337), train_loss = 0.81590129, grad/param norm = 1.3513e-01, time/batch = 15.5705s	
15034/33650 (epoch 22.339), train_loss = 0.93229242, grad/param norm = 1.4105e-01, time/batch = 15.6495s	
15035/33650 (epoch 22.340), train_loss = 1.06935675, grad/param norm = 1.6060e-01, time/batch = 15.5611s	
15036/33650 (epoch 22.342), train_loss = 0.82041034, grad/param norm = 1.4103e-01, time/batch = 15.4793s	
15037/33650 (epoch 22.343), train_loss = 1.01934528, grad/param norm = 1.5623e-01, time/batch = 15.5652s	
15038/33650 (epoch 22.345), train_loss = 0.94067418, grad/param norm = 1.5436e-01, time/batch = 15.6485s	
15039/33650 (epoch 22.346), train_loss = 0.66868670, grad/param norm = 1.2448e-01, time/batch = 15.4929s	
15040/33650 (epoch 22.348), train_loss = 0.84454953, grad/param norm = 1.3925e-01, time/batch = 15.7274s	
15041/33650 (epoch 22.349), train_loss = 0.80848589, grad/param norm = 1.3122e-01, time/batch = 15.8919s	
15042/33650 (epoch 22.351), train_loss = 1.03737909, grad/param norm = 1.4505e-01, time/batch = 15.7284s	
15043/33650 (epoch 22.352), train_loss = 0.94596953, grad/param norm = 1.4404e-01, time/batch = 15.4792s	
15044/33650 (epoch 22.354), train_loss = 1.12629827, grad/param norm = 1.8975e-01, time/batch = 15.3222s	
15045/33650 (epoch 22.355), train_loss = 1.09183745, grad/param norm = 1.4334e-01, time/batch = 15.3275s	
15046/33650 (epoch 22.357), train_loss = 0.77640784, grad/param norm = 1.2878e-01, time/batch = 15.4746s	
15047/33650 (epoch 22.358), train_loss = 1.02823560, grad/param norm = 1.5542e-01, time/batch = 15.4911s	
15048/33650 (epoch 22.360), train_loss = 1.05328123, grad/param norm = 1.7251e-01, time/batch = 15.4826s	
15049/33650 (epoch 22.361), train_loss = 1.00642120, grad/param norm = 1.4643e-01, time/batch = 15.8853s	
15050/33650 (epoch 22.363), train_loss = 0.95045749, grad/param norm = 1.4617e-01, time/batch = 15.4892s	
15051/33650 (epoch 22.364), train_loss = 0.91653636, grad/param norm = 1.2276e-01, time/batch = 15.5631s	
15052/33650 (epoch 22.366), train_loss = 1.02493141, grad/param norm = 1.9442e-01, time/batch = 15.4896s	
15053/33650 (epoch 22.367), train_loss = 1.00261087, grad/param norm = 1.6323e-01, time/batch = 15.7198s	
15054/33650 (epoch 22.368), train_loss = 0.87656913, grad/param norm = 1.2992e-01, time/batch = 15.4848s	
15055/33650 (epoch 22.370), train_loss = 0.97433527, grad/param norm = 1.4508e-01, time/batch = 15.5736s	
15056/33650 (epoch 22.371), train_loss = 0.77170640, grad/param norm = 1.3906e-01, time/batch = 15.4868s	
15057/33650 (epoch 22.373), train_loss = 0.86933398, grad/param norm = 1.3507e-01, time/batch = 15.5560s	
15058/33650 (epoch 22.374), train_loss = 0.84592013, grad/param norm = 1.2780e-01, time/batch = 15.4032s	
15059/33650 (epoch 22.376), train_loss = 0.96470114, grad/param norm = 1.6914e-01, time/batch = 15.4053s	
15060/33650 (epoch 22.377), train_loss = 0.99802802, grad/param norm = 1.5928e-01, time/batch = 15.3201s	
15061/33650 (epoch 22.379), train_loss = 1.01835338, grad/param norm = 1.5903e-01, time/batch = 15.5638s	
15062/33650 (epoch 22.380), train_loss = 0.77419139, grad/param norm = 1.5657e-01, time/batch = 15.5576s	
15063/33650 (epoch 22.382), train_loss = 0.91569068, grad/param norm = 1.2628e-01, time/batch = 15.6422s	
15064/33650 (epoch 22.383), train_loss = 0.94939596, grad/param norm = 1.4373e-01, time/batch = 15.3315s	
15065/33650 (epoch 22.385), train_loss = 1.05415483, grad/param norm = 1.4747e-01, time/batch = 15.8003s	
15066/33650 (epoch 22.386), train_loss = 0.90472890, grad/param norm = 1.4919e-01, time/batch = 15.4014s	
15067/33650 (epoch 22.388), train_loss = 0.99735458, grad/param norm = 1.3088e-01, time/batch = 15.4892s	
15068/33650 (epoch 22.389), train_loss = 0.93219817, grad/param norm = 1.6512e-01, time/batch = 15.3957s	
15069/33650 (epoch 22.391), train_loss = 0.76709603, grad/param norm = 1.2864e-01, time/batch = 15.5647s	
15070/33650 (epoch 22.392), train_loss = 1.00047373, grad/param norm = 1.6692e-01, time/batch = 15.3187s	
15071/33650 (epoch 22.394), train_loss = 0.98508716, grad/param norm = 1.6514e-01, time/batch = 15.7345s	
15072/33650 (epoch 22.395), train_loss = 1.02170245, grad/param norm = 1.4445e-01, time/batch = 15.6472s	
15073/33650 (epoch 22.397), train_loss = 1.09345809, grad/param norm = 1.4739e-01, time/batch = 15.6477s	
15074/33650 (epoch 22.398), train_loss = 1.03129127, grad/param norm = 1.5352e-01, time/batch = 15.5717s	
15075/33650 (epoch 22.400), train_loss = 0.96383064, grad/param norm = 1.9475e-01, time/batch = 15.4845s	
15076/33650 (epoch 22.401), train_loss = 0.91242244, grad/param norm = 1.6374e-01, time/batch = 15.5590s	
15077/33650 (epoch 22.403), train_loss = 1.01325317, grad/param norm = 1.5599e-01, time/batch = 15.6377s	
15078/33650 (epoch 22.404), train_loss = 0.94546286, grad/param norm = 1.3722e-01, time/batch = 15.5689s	
15079/33650 (epoch 22.406), train_loss = 0.98313234, grad/param norm = 1.7049e-01, time/batch = 15.4812s	
15080/33650 (epoch 22.407), train_loss = 0.94481461, grad/param norm = 1.4678e-01, time/batch = 15.5635s	
15081/33650 (epoch 22.409), train_loss = 1.01528560, grad/param norm = 1.5920e-01, time/batch = 15.5655s	
15082/33650 (epoch 22.410), train_loss = 0.94587954, grad/param norm = 1.4368e-01, time/batch = 15.5572s	
15083/33650 (epoch 22.412), train_loss = 0.94969247, grad/param norm = 1.2839e-01, time/batch = 15.4013s	
15084/33650 (epoch 22.413), train_loss = 0.92018726, grad/param norm = 1.5446e-01, time/batch = 15.5612s	
15085/33650 (epoch 22.415), train_loss = 1.03296676, grad/param norm = 1.4814e-01, time/batch = 15.5612s	
15086/33650 (epoch 22.416), train_loss = 1.08625715, grad/param norm = 1.5062e-01, time/batch = 15.4796s	
15087/33650 (epoch 22.418), train_loss = 0.90090949, grad/param norm = 1.4212e-01, time/batch = 15.3243s	
15088/33650 (epoch 22.419), train_loss = 0.91497326, grad/param norm = 1.4545e-01, time/batch = 15.7967s	
15089/33650 (epoch 22.421), train_loss = 0.94262201, grad/param norm = 1.3114e-01, time/batch = 15.3206s	
15090/33650 (epoch 22.422), train_loss = 1.06952797, grad/param norm = 1.4510e-01, time/batch = 15.6497s	
15091/33650 (epoch 22.423), train_loss = 0.88016547, grad/param norm = 1.2760e-01, time/batch = 15.4108s	
15092/33650 (epoch 22.425), train_loss = 0.97442260, grad/param norm = 1.5243e-01, time/batch = 15.5625s	
15093/33650 (epoch 22.426), train_loss = 1.10787383, grad/param norm = 1.6193e-01, time/batch = 15.4823s	
15094/33650 (epoch 22.428), train_loss = 0.88931477, grad/param norm = 1.3455e-01, time/batch = 15.6459s	
15095/33650 (epoch 22.429), train_loss = 1.02462793, grad/param norm = 1.5218e-01, time/batch = 15.3951s	
15096/33650 (epoch 22.431), train_loss = 1.11313929, grad/param norm = 1.6204e-01, time/batch = 15.4777s	
15097/33650 (epoch 22.432), train_loss = 1.13576611, grad/param norm = 1.7178e-01, time/batch = 15.4003s	
15098/33650 (epoch 22.434), train_loss = 0.98169562, grad/param norm = 1.4369e-01, time/batch = 15.4014s	
15099/33650 (epoch 22.435), train_loss = 0.96558666, grad/param norm = 1.9174e-01, time/batch = 15.6322s	
15100/33650 (epoch 22.437), train_loss = 0.98308087, grad/param norm = 1.5318e-01, time/batch = 15.4881s	
15101/33650 (epoch 22.438), train_loss = 0.93539488, grad/param norm = 1.6470e-01, time/batch = 15.5703s	
15102/33650 (epoch 22.440), train_loss = 0.96281405, grad/param norm = 1.5609e-01, time/batch = 15.4884s	
15103/33650 (epoch 22.441), train_loss = 0.98068290, grad/param norm = 1.6178e-01, time/batch = 15.5642s	
15104/33650 (epoch 22.443), train_loss = 1.03382272, grad/param norm = 1.4147e-01, time/batch = 15.4813s	
15105/33650 (epoch 22.444), train_loss = 0.95160798, grad/param norm = 1.5203e-01, time/batch = 15.4095s	
15106/33650 (epoch 22.446), train_loss = 1.02936747, grad/param norm = 2.0458e-01, time/batch = 15.3227s	
15107/33650 (epoch 22.447), train_loss = 1.08387799, grad/param norm = 1.6084e-01, time/batch = 15.4787s	
15108/33650 (epoch 22.449), train_loss = 1.12376782, grad/param norm = 2.0411e-01, time/batch = 15.3222s	
15109/33650 (epoch 22.450), train_loss = 1.14941403, grad/param norm = 1.7595e-01, time/batch = 15.4075s	
15110/33650 (epoch 22.452), train_loss = 1.14397155, grad/param norm = 1.8112e-01, time/batch = 15.3203s	
15111/33650 (epoch 22.453), train_loss = 1.11581970, grad/param norm = 1.7267e-01, time/batch = 15.7171s	
15112/33650 (epoch 22.455), train_loss = 0.94677601, grad/param norm = 1.3854e-01, time/batch = 15.5618s	
15113/33650 (epoch 22.456), train_loss = 0.97290979, grad/param norm = 1.4994e-01, time/batch = 15.3217s	
15114/33650 (epoch 22.458), train_loss = 0.96264236, grad/param norm = 1.5745e-01, time/batch = 15.3276s	
15115/33650 (epoch 22.459), train_loss = 0.98966773, grad/param norm = 1.7046e-01, time/batch = 15.7137s	
15116/33650 (epoch 22.461), train_loss = 1.11313754, grad/param norm = 1.8228e-01, time/batch = 15.3268s	
15117/33650 (epoch 22.462), train_loss = 1.09245085, grad/param norm = 1.7235e-01, time/batch = 15.4020s	
15118/33650 (epoch 22.464), train_loss = 0.95536609, grad/param norm = 1.6776e-01, time/batch = 15.4087s	
15119/33650 (epoch 22.465), train_loss = 0.99789716, grad/param norm = 1.5641e-01, time/batch = 15.3960s	
15120/33650 (epoch 22.467), train_loss = 1.02697584, grad/param norm = 1.5290e-01, time/batch = 15.3221s	
15121/33650 (epoch 22.468), train_loss = 1.10623896, grad/param norm = 1.4702e-01, time/batch = 15.5712s	
15122/33650 (epoch 22.470), train_loss = 1.19951203, grad/param norm = 1.7698e-01, time/batch = 15.5551s	
15123/33650 (epoch 22.471), train_loss = 0.98913972, grad/param norm = 1.5742e-01, time/batch = 15.4847s	
15124/33650 (epoch 22.473), train_loss = 0.95587002, grad/param norm = 1.4592e-01, time/batch = 15.5573s	
15125/33650 (epoch 22.474), train_loss = 1.07511441, grad/param norm = 1.5371e-01, time/batch = 15.4847s	
15126/33650 (epoch 22.475), train_loss = 1.05415305, grad/param norm = 1.7586e-01, time/batch = 15.7261s	
15127/33650 (epoch 22.477), train_loss = 1.11017336, grad/param norm = 1.6174e-01, time/batch = 15.4887s	
15128/33650 (epoch 22.478), train_loss = 1.09472649, grad/param norm = 1.7605e-01, time/batch = 15.4866s	
15129/33650 (epoch 22.480), train_loss = 1.07261764, grad/param norm = 1.7561e-01, time/batch = 15.4869s	
15130/33650 (epoch 22.481), train_loss = 1.13364924, grad/param norm = 1.6940e-01, time/batch = 15.4817s	
15131/33650 (epoch 22.483), train_loss = 0.82908095, grad/param norm = 1.3992e-01, time/batch = 15.6527s	
15132/33650 (epoch 22.484), train_loss = 0.97198991, grad/param norm = 1.4691e-01, time/batch = 15.2427s	
15133/33650 (epoch 22.486), train_loss = 1.12145507, grad/param norm = 1.7208e-01, time/batch = 15.4038s	
15134/33650 (epoch 22.487), train_loss = 1.12689577, grad/param norm = 1.5676e-01, time/batch = 15.6383s	
15135/33650 (epoch 22.489), train_loss = 1.14141918, grad/param norm = 1.5632e-01, time/batch = 15.4862s	
15136/33650 (epoch 22.490), train_loss = 0.88561925, grad/param norm = 1.5036e-01, time/batch = 15.6470s	
15137/33650 (epoch 22.492), train_loss = 1.05581249, grad/param norm = 1.7825e-01, time/batch = 15.4025s	
15138/33650 (epoch 22.493), train_loss = 0.83279087, grad/param norm = 1.3418e-01, time/batch = 15.7212s	
15139/33650 (epoch 22.495), train_loss = 0.99885338, grad/param norm = 1.4653e-01, time/batch = 15.1579s	
15140/33650 (epoch 22.496), train_loss = 1.04476798, grad/param norm = 1.5335e-01, time/batch = 15.2303s	
15141/33650 (epoch 22.498), train_loss = 0.89946096, grad/param norm = 1.3630e-01, time/batch = 15.2427s	
15142/33650 (epoch 22.499), train_loss = 0.98507299, grad/param norm = 1.3460e-01, time/batch = 15.2287s	
15143/33650 (epoch 22.501), train_loss = 0.95360731, grad/param norm = 1.2509e-01, time/batch = 15.1585s	
15144/33650 (epoch 22.502), train_loss = 0.99531561, grad/param norm = 1.5854e-01, time/batch = 14.9992s	
15145/33650 (epoch 22.504), train_loss = 1.08984113, grad/param norm = 1.6953e-01, time/batch = 15.0046s	
15146/33650 (epoch 22.505), train_loss = 0.94687012, grad/param norm = 1.7537e-01, time/batch = 15.2227s	
15147/33650 (epoch 22.507), train_loss = 1.11245267, grad/param norm = 1.6255e-01, time/batch = 14.9999s	
15148/33650 (epoch 22.508), train_loss = 0.95675037, grad/param norm = 1.3839e-01, time/batch = 15.0824s	
15149/33650 (epoch 22.510), train_loss = 0.99122824, grad/param norm = 1.4580e-01, time/batch = 15.0026s	
15150/33650 (epoch 22.511), train_loss = 1.20989235, grad/param norm = 1.8278e-01, time/batch = 15.2118s	
15151/33650 (epoch 22.513), train_loss = 1.05332908, grad/param norm = 1.5828e-01, time/batch = 15.1535s	
15152/33650 (epoch 22.514), train_loss = 1.06028556, grad/param norm = 1.5838e-01, time/batch = 15.0777s	
15153/33650 (epoch 22.516), train_loss = 1.01328567, grad/param norm = 1.8706e-01, time/batch = 15.0740s	
15154/33650 (epoch 22.517), train_loss = 0.99804956, grad/param norm = 1.5044e-01, time/batch = 15.3944s	
15155/33650 (epoch 22.519), train_loss = 1.06549146, grad/param norm = 1.7475e-01, time/batch = 15.0749s	
15156/33650 (epoch 22.520), train_loss = 0.86878246, grad/param norm = 1.3114e-01, time/batch = 15.2969s	
15157/33650 (epoch 22.522), train_loss = 0.98270482, grad/param norm = 1.6238e-01, time/batch = 15.0725s	
15158/33650 (epoch 22.523), train_loss = 0.94374132, grad/param norm = 1.5096e-01, time/batch = 15.2358s	
15159/33650 (epoch 22.525), train_loss = 0.78922484, grad/param norm = 1.2109e-01, time/batch = 15.2404s	
15160/33650 (epoch 22.526), train_loss = 1.08368128, grad/param norm = 1.4352e-01, time/batch = 15.0573s	
15161/33650 (epoch 22.527), train_loss = 0.94185032, grad/param norm = 1.4705e-01, time/batch = 15.2427s	
15162/33650 (epoch 22.529), train_loss = 0.99325626, grad/param norm = 1.4909e-01, time/batch = 15.2375s	
15163/33650 (epoch 22.530), train_loss = 0.93072140, grad/param norm = 1.5546e-01, time/batch = 15.1635s	
15164/33650 (epoch 22.532), train_loss = 1.08579167, grad/param norm = 1.9270e-01, time/batch = 15.3968s	
15165/33650 (epoch 22.533), train_loss = 0.97029972, grad/param norm = 1.4208e-01, time/batch = 15.3983s	
15166/33650 (epoch 22.535), train_loss = 1.08546415, grad/param norm = 1.5655e-01, time/batch = 14.9892s	
15167/33650 (epoch 22.536), train_loss = 1.00985771, grad/param norm = 1.5901e-01, time/batch = 15.1585s	
15168/33650 (epoch 22.538), train_loss = 1.06052536, grad/param norm = 1.8348e-01, time/batch = 15.3907s	
15169/33650 (epoch 22.539), train_loss = 0.82221581, grad/param norm = 1.4983e-01, time/batch = 15.1565s	
15170/33650 (epoch 22.541), train_loss = 1.10846525, grad/param norm = 1.6910e-01, time/batch = 15.1415s	
15171/33650 (epoch 22.542), train_loss = 1.01768394, grad/param norm = 1.8198e-01, time/batch = 15.2436s	
15172/33650 (epoch 22.544), train_loss = 1.19032101, grad/param norm = 2.6082e-01, time/batch = 15.1606s	
15173/33650 (epoch 22.545), train_loss = 0.86782947, grad/param norm = 1.5056e-01, time/batch = 15.2393s	
15174/33650 (epoch 22.547), train_loss = 1.02707990, grad/param norm = 1.5720e-01, time/batch = 15.1426s	
15175/33650 (epoch 22.548), train_loss = 1.14737184, grad/param norm = 1.6443e-01, time/batch = 15.1555s	
15176/33650 (epoch 22.550), train_loss = 1.00989208, grad/param norm = 1.6911e-01, time/batch = 15.1475s	
15177/33650 (epoch 22.551), train_loss = 1.03471421, grad/param norm = 1.8544e-01, time/batch = 15.2350s	
15178/33650 (epoch 22.553), train_loss = 0.89715510, grad/param norm = 1.7467e-01, time/batch = 15.0781s	
15179/33650 (epoch 22.554), train_loss = 1.14835241, grad/param norm = 1.7182e-01, time/batch = 15.1559s	
15180/33650 (epoch 22.556), train_loss = 1.08033021, grad/param norm = 1.6490e-01, time/batch = 15.2943s	
15181/33650 (epoch 22.557), train_loss = 1.08110565, grad/param norm = 1.7991e-01, time/batch = 15.3933s	
15182/33650 (epoch 22.559), train_loss = 1.25663902, grad/param norm = 1.7779e-01, time/batch = 15.1597s	
15183/33650 (epoch 22.560), train_loss = 1.18968975, grad/param norm = 1.6239e-01, time/batch = 15.2349s	
15184/33650 (epoch 22.562), train_loss = 1.11227127, grad/param norm = 1.4951e-01, time/batch = 15.3215s	
15185/33650 (epoch 22.563), train_loss = 1.03613934, grad/param norm = 1.5133e-01, time/batch = 24.3215s	
15186/33650 (epoch 22.565), train_loss = 0.99393643, grad/param norm = 1.4532e-01, time/batch = 19.2442s	
15187/33650 (epoch 22.566), train_loss = 0.99004265, grad/param norm = 1.5028e-01, time/batch = 15.1656s	
15188/33650 (epoch 22.568), train_loss = 1.03816327, grad/param norm = 1.8097e-01, time/batch = 15.3119s	
15189/33650 (epoch 22.569), train_loss = 0.93422402, grad/param norm = 1.4328e-01, time/batch = 15.0833s	
15190/33650 (epoch 22.571), train_loss = 1.10949951, grad/param norm = 1.6475e-01, time/batch = 15.2358s	
15191/33650 (epoch 22.572), train_loss = 1.07351149, grad/param norm = 1.4258e-01, time/batch = 15.3257s	
15192/33650 (epoch 22.574), train_loss = 0.95705873, grad/param norm = 1.9042e-01, time/batch = 15.3952s	
15193/33650 (epoch 22.575), train_loss = 0.99624314, grad/param norm = 1.5279e-01, time/batch = 15.2444s	
15194/33650 (epoch 22.577), train_loss = 0.97121151, grad/param norm = 1.5129e-01, time/batch = 15.2282s	
15195/33650 (epoch 22.578), train_loss = 1.07760888, grad/param norm = 1.5655e-01, time/batch = 15.2408s	
15196/33650 (epoch 22.579), train_loss = 1.06220739, grad/param norm = 1.6343e-01, time/batch = 15.4009s	
15197/33650 (epoch 22.581), train_loss = 1.13376202, grad/param norm = 1.5509e-01, time/batch = 15.1627s	
15198/33650 (epoch 22.582), train_loss = 1.05339386, grad/param norm = 1.3018e-01, time/batch = 15.3981s	
15199/33650 (epoch 22.584), train_loss = 1.03226792, grad/param norm = 1.5282e-01, time/batch = 15.1571s	
15200/33650 (epoch 22.585), train_loss = 1.05869855, grad/param norm = 1.6709e-01, time/batch = 15.3785s	
15201/33650 (epoch 22.587), train_loss = 0.92831746, grad/param norm = 1.4706e-01, time/batch = 15.3193s	
15202/33650 (epoch 22.588), train_loss = 0.96021511, grad/param norm = 1.9654e-01, time/batch = 15.3196s	
15203/33650 (epoch 22.590), train_loss = 0.95294686, grad/param norm = 1.4104e-01, time/batch = 15.2383s	
15204/33650 (epoch 22.591), train_loss = 0.92883873, grad/param norm = 1.6584e-01, time/batch = 15.5441s	
15205/33650 (epoch 22.593), train_loss = 0.90320958, grad/param norm = 1.4181e-01, time/batch = 15.1659s	
15206/33650 (epoch 22.594), train_loss = 0.88788672, grad/param norm = 1.5001e-01, time/batch = 15.3153s	
15207/33650 (epoch 22.596), train_loss = 0.97399459, grad/param norm = 1.4195e-01, time/batch = 15.1587s	
15208/33650 (epoch 22.597), train_loss = 0.84529282, grad/param norm = 1.3622e-01, time/batch = 15.1534s	
15209/33650 (epoch 22.599), train_loss = 0.97656713, grad/param norm = 1.5794e-01, time/batch = 15.3235s	
15210/33650 (epoch 22.600), train_loss = 0.90520667, grad/param norm = 1.4293e-01, time/batch = 15.1588s	
15211/33650 (epoch 22.602), train_loss = 1.05407804, grad/param norm = 1.5585e-01, time/batch = 15.3986s	
15212/33650 (epoch 22.603), train_loss = 0.95208196, grad/param norm = 1.5412e-01, time/batch = 15.4003s	
15213/33650 (epoch 22.605), train_loss = 1.05354152, grad/param norm = 1.5444e-01, time/batch = 15.2377s	
15214/33650 (epoch 22.606), train_loss = 1.04463045, grad/param norm = 1.7109e-01, time/batch = 15.3166s	
15215/33650 (epoch 22.608), train_loss = 0.91799418, grad/param norm = 1.7338e-01, time/batch = 15.3088s	
15216/33650 (epoch 22.609), train_loss = 0.98812882, grad/param norm = 1.4217e-01, time/batch = 15.4085s	
15217/33650 (epoch 22.611), train_loss = 0.89397045, grad/param norm = 1.5087e-01, time/batch = 17.1882s	
15218/33650 (epoch 22.612), train_loss = 1.00047458, grad/param norm = 1.7122e-01, time/batch = 17.0510s	
15219/33650 (epoch 22.614), train_loss = 1.08241626, grad/param norm = 1.6345e-01, time/batch = 16.5555s	
15220/33650 (epoch 22.615), train_loss = 0.97597370, grad/param norm = 1.3917e-01, time/batch = 17.7113s	
15221/33650 (epoch 22.617), train_loss = 0.90076745, grad/param norm = 1.2935e-01, time/batch = 18.1298s	
15222/33650 (epoch 22.618), train_loss = 0.96788961, grad/param norm = 1.3313e-01, time/batch = 16.4524s	
15223/33650 (epoch 22.620), train_loss = 0.98615096, grad/param norm = 1.5879e-01, time/batch = 15.0964s	
15224/33650 (epoch 22.621), train_loss = 0.91118350, grad/param norm = 1.5070e-01, time/batch = 15.1667s	
15225/33650 (epoch 22.623), train_loss = 0.96760040, grad/param norm = 1.5614e-01, time/batch = 17.4291s	
15226/33650 (epoch 22.624), train_loss = 0.78685421, grad/param norm = 1.4057e-01, time/batch = 16.4606s	
15227/33650 (epoch 22.626), train_loss = 0.78641132, grad/param norm = 1.2832e-01, time/batch = 17.3682s	
15228/33650 (epoch 22.627), train_loss = 0.88884647, grad/param norm = 1.3999e-01, time/batch = 17.8727s	
15229/33650 (epoch 22.629), train_loss = 0.94260854, grad/param norm = 1.4663e-01, time/batch = 17.4706s	
15230/33650 (epoch 22.630), train_loss = 1.07914230, grad/param norm = 1.7082e-01, time/batch = 17.3629s	
15231/33650 (epoch 22.632), train_loss = 1.11503897, grad/param norm = 1.6263e-01, time/batch = 18.0623s	
15232/33650 (epoch 22.633), train_loss = 1.05785438, grad/param norm = 1.5318e-01, time/batch = 18.0434s	
15233/33650 (epoch 22.634), train_loss = 0.87719979, grad/param norm = 1.4296e-01, time/batch = 15.8842s	
15234/33650 (epoch 22.636), train_loss = 0.76080051, grad/param norm = 1.2041e-01, time/batch = 15.7915s	
15235/33650 (epoch 22.637), train_loss = 0.91065139, grad/param norm = 1.3913e-01, time/batch = 17.8103s	
15236/33650 (epoch 22.639), train_loss = 0.92571991, grad/param norm = 1.4734e-01, time/batch = 17.7083s	
15237/33650 (epoch 22.640), train_loss = 0.99743025, grad/param norm = 1.4615e-01, time/batch = 18.0510s	
15238/33650 (epoch 22.642), train_loss = 1.04478894, grad/param norm = 1.6539e-01, time/batch = 18.0405s	
15239/33650 (epoch 22.643), train_loss = 0.98887886, grad/param norm = 1.4670e-01, time/batch = 18.3822s	
15240/33650 (epoch 22.645), train_loss = 0.99403900, grad/param norm = 1.4803e-01, time/batch = 15.9595s	
15241/33650 (epoch 22.646), train_loss = 0.84060020, grad/param norm = 1.2209e-01, time/batch = 18.6298s	
15242/33650 (epoch 22.648), train_loss = 1.00761693, grad/param norm = 1.4379e-01, time/batch = 17.8076s	
15243/33650 (epoch 22.649), train_loss = 0.94006848, grad/param norm = 1.8078e-01, time/batch = 16.7147s	
15244/33650 (epoch 22.651), train_loss = 1.09947112, grad/param norm = 1.7694e-01, time/batch = 17.2224s	
15245/33650 (epoch 22.652), train_loss = 0.70682994, grad/param norm = 1.1167e-01, time/batch = 18.1270s	
15246/33650 (epoch 22.654), train_loss = 0.89900703, grad/param norm = 1.4706e-01, time/batch = 17.9645s	
15247/33650 (epoch 22.655), train_loss = 0.84273843, grad/param norm = 1.3780e-01, time/batch = 17.4532s	
15248/33650 (epoch 22.657), train_loss = 0.93506929, grad/param norm = 1.6098e-01, time/batch = 17.4856s	
15249/33650 (epoch 22.658), train_loss = 0.80864179, grad/param norm = 1.3917e-01, time/batch = 16.2096s	
15250/33650 (epoch 22.660), train_loss = 0.79237859, grad/param norm = 1.3260e-01, time/batch = 16.7705s	
15251/33650 (epoch 22.661), train_loss = 0.89949028, grad/param norm = 1.4896e-01, time/batch = 18.3839s	
15252/33650 (epoch 22.663), train_loss = 0.84854819, grad/param norm = 1.5095e-01, time/batch = 16.0331s	
15253/33650 (epoch 22.664), train_loss = 0.90932351, grad/param norm = 1.4133e-01, time/batch = 16.4628s	
15254/33650 (epoch 22.666), train_loss = 0.92726202, grad/param norm = 1.2424e-01, time/batch = 17.4512s	
15255/33650 (epoch 22.667), train_loss = 0.83814091, grad/param norm = 1.2399e-01, time/batch = 17.8871s	
15256/33650 (epoch 22.669), train_loss = 0.85146558, grad/param norm = 1.4357e-01, time/batch = 18.6318s	
15257/33650 (epoch 22.670), train_loss = 0.77722364, grad/param norm = 1.4064e-01, time/batch = 15.6287s	
15258/33650 (epoch 22.672), train_loss = 0.82597910, grad/param norm = 1.4940e-01, time/batch = 17.0556s	
15259/33650 (epoch 22.673), train_loss = 0.78884376, grad/param norm = 1.4048e-01, time/batch = 16.9653s	
15260/33650 (epoch 22.675), train_loss = 0.77244150, grad/param norm = 1.2973e-01, time/batch = 17.0640s	
15261/33650 (epoch 22.676), train_loss = 0.95040535, grad/param norm = 1.4453e-01, time/batch = 17.5568s	
15262/33650 (epoch 22.678), train_loss = 0.89503054, grad/param norm = 1.4821e-01, time/batch = 18.6417s	
15263/33650 (epoch 22.679), train_loss = 0.90462665, grad/param norm = 1.4795e-01, time/batch = 16.9767s	
15264/33650 (epoch 22.681), train_loss = 0.91292247, grad/param norm = 1.2543e-01, time/batch = 15.7991s	
15265/33650 (epoch 22.682), train_loss = 0.86787771, grad/param norm = 1.5794e-01, time/batch = 17.1233s	
15266/33650 (epoch 22.684), train_loss = 0.82882650, grad/param norm = 1.3745e-01, time/batch = 16.4691s	
15267/33650 (epoch 22.685), train_loss = 1.00179315, grad/param norm = 1.5433e-01, time/batch = 16.8066s	
15268/33650 (epoch 22.686), train_loss = 0.95859178, grad/param norm = 1.4396e-01, time/batch = 15.5406s	
15269/33650 (epoch 22.688), train_loss = 1.02448823, grad/param norm = 1.5176e-01, time/batch = 18.1258s	
15270/33650 (epoch 22.689), train_loss = 0.86943586, grad/param norm = 1.4551e-01, time/batch = 16.2094s	
15271/33650 (epoch 22.691), train_loss = 1.06974059, grad/param norm = 1.7252e-01, time/batch = 16.0497s	
15272/33650 (epoch 22.692), train_loss = 1.07565073, grad/param norm = 1.5439e-01, time/batch = 16.0578s	
15273/33650 (epoch 22.694), train_loss = 0.97276349, grad/param norm = 1.5791e-01, time/batch = 17.6353s	
15274/33650 (epoch 22.695), train_loss = 0.69743857, grad/param norm = 1.3908e-01, time/batch = 17.5616s	
15275/33650 (epoch 22.697), train_loss = 0.92488969, grad/param norm = 1.4652e-01, time/batch = 20.8911s	
15276/33650 (epoch 22.698), train_loss = 1.09860422, grad/param norm = 1.5932e-01, time/batch = 20.6219s	
15277/33650 (epoch 22.700), train_loss = 0.94680231, grad/param norm = 1.4599e-01, time/batch = 17.9927s	
15278/33650 (epoch 22.701), train_loss = 0.95702975, grad/param norm = 1.5062e-01, time/batch = 20.9529s	
15279/33650 (epoch 22.703), train_loss = 1.12990119, grad/param norm = 1.4822e-01, time/batch = 21.7075s	
15280/33650 (epoch 22.704), train_loss = 0.92421496, grad/param norm = 1.3738e-01, time/batch = 21.6197s	
15281/33650 (epoch 22.706), train_loss = 0.89677012, grad/param norm = 1.3251e-01, time/batch = 22.1212s	
15282/33650 (epoch 22.707), train_loss = 1.04259904, grad/param norm = 1.3916e-01, time/batch = 22.1982s	
15283/33650 (epoch 22.709), train_loss = 0.93247162, grad/param norm = 1.4458e-01, time/batch = 20.0456s	
15284/33650 (epoch 22.710), train_loss = 1.11474571, grad/param norm = 1.5591e-01, time/batch = 21.8588s	
15285/33650 (epoch 22.712), train_loss = 0.87215805, grad/param norm = 1.5078e-01, time/batch = 19.3918s	
15286/33650 (epoch 22.713), train_loss = 0.85889833, grad/param norm = 1.6190e-01, time/batch = 19.1241s	
15287/33650 (epoch 22.715), train_loss = 1.02617721, grad/param norm = 1.7778e-01, time/batch = 19.7160s	
15288/33650 (epoch 22.716), train_loss = 0.89057022, grad/param norm = 1.4150e-01, time/batch = 21.0591s	
15289/33650 (epoch 22.718), train_loss = 0.89155507, grad/param norm = 1.5915e-01, time/batch = 19.3103s	
15290/33650 (epoch 22.719), train_loss = 1.06981497, grad/param norm = 1.6328e-01, time/batch = 21.1204s	
15291/33650 (epoch 22.721), train_loss = 1.15718812, grad/param norm = 1.7539e-01, time/batch = 23.1224s	
15292/33650 (epoch 22.722), train_loss = 1.04130404, grad/param norm = 1.7979e-01, time/batch = 20.7920s	
15293/33650 (epoch 22.724), train_loss = 1.06441136, grad/param norm = 1.5474e-01, time/batch = 25.0968s	
15294/33650 (epoch 22.725), train_loss = 1.04556406, grad/param norm = 1.6385e-01, time/batch = 26.9217s	
15295/33650 (epoch 22.727), train_loss = 0.88947580, grad/param norm = 1.6280e-01, time/batch = 16.8927s	
15296/33650 (epoch 22.728), train_loss = 0.92248186, grad/param norm = 1.4021e-01, time/batch = 15.9608s	
15297/33650 (epoch 22.730), train_loss = 0.99456169, grad/param norm = 1.6311e-01, time/batch = 17.5472s	
15298/33650 (epoch 22.731), train_loss = 1.08956036, grad/param norm = 1.5669e-01, time/batch = 16.8888s	
15299/33650 (epoch 22.733), train_loss = 0.95344346, grad/param norm = 1.4987e-01, time/batch = 18.0666s	
15300/33650 (epoch 22.734), train_loss = 1.09337958, grad/param norm = 1.9870e-01, time/batch = 17.1396s	
15301/33650 (epoch 22.736), train_loss = 0.95206639, grad/param norm = 1.5353e-01, time/batch = 17.1244s	
15302/33650 (epoch 22.737), train_loss = 1.02195564, grad/param norm = 1.7150e-01, time/batch = 18.3024s	
15303/33650 (epoch 22.738), train_loss = 0.85650828, grad/param norm = 1.3261e-01, time/batch = 17.8184s	
15304/33650 (epoch 22.740), train_loss = 0.82844051, grad/param norm = 1.4118e-01, time/batch = 17.6353s	
15305/33650 (epoch 22.741), train_loss = 0.89004830, grad/param norm = 1.4668e-01, time/batch = 17.1286s	
15306/33650 (epoch 22.743), train_loss = 0.96748723, grad/param norm = 1.5668e-01, time/batch = 18.0555s	
15307/33650 (epoch 22.744), train_loss = 1.01511823, grad/param norm = 1.3587e-01, time/batch = 18.6475s	
15308/33650 (epoch 22.746), train_loss = 0.93300030, grad/param norm = 1.4331e-01, time/batch = 16.7967s	
15309/33650 (epoch 22.747), train_loss = 1.07177152, grad/param norm = 1.5364e-01, time/batch = 18.2231s	
15310/33650 (epoch 22.749), train_loss = 0.81545378, grad/param norm = 1.4035e-01, time/batch = 17.8188s	
15311/33650 (epoch 22.750), train_loss = 1.10524008, grad/param norm = 1.8595e-01, time/batch = 18.0544s	
15312/33650 (epoch 22.752), train_loss = 1.07196397, grad/param norm = 1.5339e-01, time/batch = 18.1419s	
15313/33650 (epoch 22.753), train_loss = 1.15780310, grad/param norm = 1.6447e-01, time/batch = 18.2310s	
15314/33650 (epoch 22.755), train_loss = 0.91794824, grad/param norm = 1.3008e-01, time/batch = 17.8918s	
15315/33650 (epoch 22.756), train_loss = 1.03381663, grad/param norm = 1.5531e-01, time/batch = 17.8106s	
15316/33650 (epoch 22.758), train_loss = 1.02226315, grad/param norm = 1.3682e-01, time/batch = 15.6523s	
15317/33650 (epoch 22.759), train_loss = 1.09158477, grad/param norm = 1.8233e-01, time/batch = 17.1468s	
15318/33650 (epoch 22.761), train_loss = 0.99693875, grad/param norm = 1.5915e-01, time/batch = 16.6393s	
15319/33650 (epoch 22.762), train_loss = 0.96799474, grad/param norm = 1.4704e-01, time/batch = 18.3098s	
15320/33650 (epoch 22.764), train_loss = 1.02620556, grad/param norm = 1.7039e-01, time/batch = 18.3147s	
15321/33650 (epoch 22.765), train_loss = 0.96102846, grad/param norm = 1.5880e-01, time/batch = 17.7311s	
15322/33650 (epoch 22.767), train_loss = 0.95164541, grad/param norm = 1.3471e-01, time/batch = 17.6434s	
15323/33650 (epoch 22.768), train_loss = 0.84969622, grad/param norm = 1.4916e-01, time/batch = 17.9962s	
15324/33650 (epoch 22.770), train_loss = 1.00029277, grad/param norm = 1.5887e-01, time/batch = 16.8779s	
15325/33650 (epoch 22.771), train_loss = 1.00038207, grad/param norm = 1.5589e-01, time/batch = 17.4731s	
15326/33650 (epoch 22.773), train_loss = 1.09839958, grad/param norm = 1.7652e-01, time/batch = 18.3034s	
15327/33650 (epoch 22.774), train_loss = 1.00182051, grad/param norm = 1.7337e-01, time/batch = 18.2281s	
15328/33650 (epoch 22.776), train_loss = 1.05920985, grad/param norm = 1.5883e-01, time/batch = 17.3025s	
15329/33650 (epoch 22.777), train_loss = 0.87745910, grad/param norm = 1.3815e-01, time/batch = 18.0617s	
15330/33650 (epoch 22.779), train_loss = 0.92316966, grad/param norm = 1.4050e-01, time/batch = 18.5603s	
15331/33650 (epoch 22.780), train_loss = 0.85031604, grad/param norm = 1.2242e-01, time/batch = 18.1414s	
15332/33650 (epoch 22.782), train_loss = 0.91513808, grad/param norm = 1.5622e-01, time/batch = 15.9789s	
15333/33650 (epoch 22.783), train_loss = 0.87695751, grad/param norm = 1.3560e-01, time/batch = 17.8955s	
15334/33650 (epoch 22.785), train_loss = 1.14706415, grad/param norm = 1.4447e-01, time/batch = 17.9782s	
15335/33650 (epoch 22.786), train_loss = 1.03526151, grad/param norm = 1.4537e-01, time/batch = 15.9772s	
15336/33650 (epoch 22.788), train_loss = 1.02187684, grad/param norm = 1.4634e-01, time/batch = 17.8959s	
15337/33650 (epoch 22.789), train_loss = 1.06196743, grad/param norm = 1.6378e-01, time/batch = 16.8924s	
15338/33650 (epoch 22.790), train_loss = 0.97526637, grad/param norm = 1.6319e-01, time/batch = 16.9790s	
15339/33650 (epoch 22.792), train_loss = 1.09382287, grad/param norm = 1.8833e-01, time/batch = 17.5554s	
15340/33650 (epoch 22.793), train_loss = 1.05032726, grad/param norm = 1.7160e-01, time/batch = 18.2160s	
15341/33650 (epoch 22.795), train_loss = 1.10301236, grad/param norm = 1.5166e-01, time/batch = 18.5583s	
15342/33650 (epoch 22.796), train_loss = 0.95591163, grad/param norm = 1.6096e-01, time/batch = 17.7917s	
15343/33650 (epoch 22.798), train_loss = 0.92700360, grad/param norm = 1.5192e-01, time/batch = 17.1381s	
15344/33650 (epoch 22.799), train_loss = 0.97869757, grad/param norm = 1.4106e-01, time/batch = 18.2339s	
15345/33650 (epoch 22.801), train_loss = 1.00851007, grad/param norm = 1.9562e-01, time/batch = 16.6431s	
15346/33650 (epoch 22.802), train_loss = 1.08937470, grad/param norm = 1.6755e-01, time/batch = 17.3117s	
15347/33650 (epoch 22.804), train_loss = 0.97928934, grad/param norm = 1.6299e-01, time/batch = 18.9810s	
15348/33650 (epoch 22.805), train_loss = 0.96724358, grad/param norm = 1.2636e-01, time/batch = 17.9515s	
15349/33650 (epoch 22.807), train_loss = 1.17331204, grad/param norm = 1.8244e-01, time/batch = 17.7284s	
15350/33650 (epoch 22.808), train_loss = 1.22147413, grad/param norm = 1.8861e-01, time/batch = 17.7360s	
15351/33650 (epoch 22.810), train_loss = 1.02333534, grad/param norm = 1.6095e-01, time/batch = 17.8103s	
15352/33650 (epoch 22.811), train_loss = 1.00101415, grad/param norm = 1.5506e-01, time/batch = 17.0489s	
15353/33650 (epoch 22.813), train_loss = 0.92558373, grad/param norm = 1.3213e-01, time/batch = 18.5725s	
15354/33650 (epoch 22.814), train_loss = 1.07275212, grad/param norm = 1.6036e-01, time/batch = 16.9721s	
15355/33650 (epoch 22.816), train_loss = 1.04965543, grad/param norm = 1.6252e-01, time/batch = 17.0382s	
15356/33650 (epoch 22.817), train_loss = 1.06656392, grad/param norm = 1.6133e-01, time/batch = 16.1398s	
15357/33650 (epoch 22.819), train_loss = 1.02201133, grad/param norm = 1.5091e-01, time/batch = 18.2246s	
15358/33650 (epoch 22.820), train_loss = 1.11428165, grad/param norm = 1.5738e-01, time/batch = 18.3962s	
15359/33650 (epoch 22.822), train_loss = 1.02892535, grad/param norm = 1.9053e-01, time/batch = 17.8114s	
15360/33650 (epoch 22.823), train_loss = 0.94003679, grad/param norm = 1.8030e-01, time/batch = 18.2274s	
15361/33650 (epoch 22.825), train_loss = 0.99413388, grad/param norm = 1.5866e-01, time/batch = 18.3234s	
15362/33650 (epoch 22.826), train_loss = 1.05797029, grad/param norm = 1.5073e-01, time/batch = 16.8859s	
15363/33650 (epoch 22.828), train_loss = 1.15748318, grad/param norm = 1.8703e-01, time/batch = 15.6370s	
15364/33650 (epoch 22.829), train_loss = 0.82985615, grad/param norm = 1.3547e-01, time/batch = 18.3848s	
15365/33650 (epoch 22.831), train_loss = 1.03672511, grad/param norm = 1.6056e-01, time/batch = 17.9776s	
15366/33650 (epoch 22.832), train_loss = 1.06654776, grad/param norm = 1.6599e-01, time/batch = 18.0634s	
15367/33650 (epoch 22.834), train_loss = 1.07155385, grad/param norm = 1.5938e-01, time/batch = 17.1279s	
15368/33650 (epoch 22.835), train_loss = 1.22749406, grad/param norm = 1.7343e-01, time/batch = 17.3187s	
15369/33650 (epoch 22.837), train_loss = 1.02339946, grad/param norm = 1.6208e-01, time/batch = 17.1117s	
15370/33650 (epoch 22.838), train_loss = 1.01734124, grad/param norm = 1.6878e-01, time/batch = 18.2290s	
15371/33650 (epoch 22.840), train_loss = 1.07203406, grad/param norm = 1.5276e-01, time/batch = 18.7349s	
15372/33650 (epoch 22.841), train_loss = 0.93331159, grad/param norm = 1.4288e-01, time/batch = 16.6418s	
15373/33650 (epoch 22.842), train_loss = 0.97604251, grad/param norm = 1.5080e-01, time/batch = 17.5752s	
15374/33650 (epoch 22.844), train_loss = 1.16674968, grad/param norm = 1.6755e-01, time/batch = 18.8974s	
15375/33650 (epoch 22.845), train_loss = 0.94459988, grad/param norm = 1.5459e-01, time/batch = 17.7207s	
15376/33650 (epoch 22.847), train_loss = 0.75559533, grad/param norm = 1.3079e-01, time/batch = 17.8171s	
15377/33650 (epoch 22.848), train_loss = 0.85898778, grad/param norm = 1.6428e-01, time/batch = 16.3923s	
15378/33650 (epoch 22.850), train_loss = 0.96466928, grad/param norm = 1.6406e-01, time/batch = 15.0207s	
15379/33650 (epoch 22.851), train_loss = 0.81357433, grad/param norm = 1.2891e-01, time/batch = 16.7937s	
15380/33650 (epoch 22.853), train_loss = 0.96528527, grad/param norm = 1.6219e-01, time/batch = 17.3959s	
15381/33650 (epoch 22.854), train_loss = 1.09712219, grad/param norm = 1.8622e-01, time/batch = 19.1311s	
15382/33650 (epoch 22.856), train_loss = 0.75263525, grad/param norm = 1.2806e-01, time/batch = 18.0588s	
15383/33650 (epoch 22.857), train_loss = 0.99351852, grad/param norm = 1.3796e-01, time/batch = 17.8892s	
15384/33650 (epoch 22.859), train_loss = 0.86862260, grad/param norm = 1.3036e-01, time/batch = 18.1583s	
15385/33650 (epoch 22.860), train_loss = 0.82560065, grad/param norm = 1.3779e-01, time/batch = 17.4018s	
15386/33650 (epoch 22.862), train_loss = 0.89202701, grad/param norm = 1.6000e-01, time/batch = 16.4582s	
15387/33650 (epoch 22.863), train_loss = 1.12196861, grad/param norm = 1.6617e-01, time/batch = 17.7305s	
15388/33650 (epoch 22.865), train_loss = 0.93817741, grad/param norm = 1.3996e-01, time/batch = 18.4072s	
15389/33650 (epoch 22.866), train_loss = 0.88325734, grad/param norm = 1.3710e-01, time/batch = 20.1856s	
15390/33650 (epoch 22.868), train_loss = 0.85205812, grad/param norm = 1.4633e-01, time/batch = 28.7835s	
15391/33650 (epoch 22.869), train_loss = 1.05720132, grad/param norm = 1.5668e-01, time/batch = 20.6955s	
15392/33650 (epoch 22.871), train_loss = 0.86179955, grad/param norm = 1.4388e-01, time/batch = 17.5554s	
15393/33650 (epoch 22.872), train_loss = 0.98661599, grad/param norm = 1.4514e-01, time/batch = 17.6598s	
15394/33650 (epoch 22.874), train_loss = 1.03494040, grad/param norm = 1.6274e-01, time/batch = 17.1219s	
15395/33650 (epoch 22.875), train_loss = 0.93505046, grad/param norm = 1.4187e-01, time/batch = 16.9716s	
15396/33650 (epoch 22.877), train_loss = 1.13485053, grad/param norm = 1.5016e-01, time/batch = 17.7303s	
15397/33650 (epoch 22.878), train_loss = 0.68555982, grad/param norm = 1.3263e-01, time/batch = 16.9432s	
15398/33650 (epoch 22.880), train_loss = 1.02411533, grad/param norm = 1.7607e-01, time/batch = 16.9893s	
15399/33650 (epoch 22.881), train_loss = 0.92709570, grad/param norm = 1.4932e-01, time/batch = 17.8169s	
15400/33650 (epoch 22.883), train_loss = 0.99602537, grad/param norm = 1.4437e-01, time/batch = 17.2196s	
15401/33650 (epoch 22.884), train_loss = 1.08999450, grad/param norm = 1.6201e-01, time/batch = 17.8165s	
15402/33650 (epoch 22.886), train_loss = 1.04984722, grad/param norm = 1.5154e-01, time/batch = 17.5460s	
15403/33650 (epoch 22.887), train_loss = 0.86121255, grad/param norm = 1.2692e-01, time/batch = 18.2334s	
15404/33650 (epoch 22.889), train_loss = 0.97540243, grad/param norm = 1.6341e-01, time/batch = 19.0680s	
15405/33650 (epoch 22.890), train_loss = 1.02624445, grad/param norm = 1.4067e-01, time/batch = 17.4668s	
15406/33650 (epoch 22.892), train_loss = 0.96253249, grad/param norm = 1.6968e-01, time/batch = 17.3267s	
15407/33650 (epoch 22.893), train_loss = 1.00806122, grad/param norm = 1.4307e-01, time/batch = 18.3081s	
15408/33650 (epoch 22.895), train_loss = 1.09632204, grad/param norm = 1.5826e-01, time/batch = 17.8065s	
15409/33650 (epoch 22.896), train_loss = 0.92439287, grad/param norm = 1.8317e-01, time/batch = 16.3824s	
15410/33650 (epoch 22.897), train_loss = 0.81834021, grad/param norm = 1.3886e-01, time/batch = 18.0705s	
15411/33650 (epoch 22.899), train_loss = 0.85838712, grad/param norm = 1.2909e-01, time/batch = 18.6413s	
15412/33650 (epoch 22.900), train_loss = 0.81114387, grad/param norm = 1.3032e-01, time/batch = 17.1228s	
15413/33650 (epoch 22.902), train_loss = 0.98717316, grad/param norm = 1.6683e-01, time/batch = 18.2257s	
15414/33650 (epoch 22.903), train_loss = 0.93134635, grad/param norm = 1.4091e-01, time/batch = 18.0698s	
15415/33650 (epoch 22.905), train_loss = 1.12230818, grad/param norm = 1.8678e-01, time/batch = 16.5417s	
15416/33650 (epoch 22.906), train_loss = 0.90436347, grad/param norm = 1.4563e-01, time/batch = 17.6307s	
15417/33650 (epoch 22.908), train_loss = 0.94848053, grad/param norm = 1.4201e-01, time/batch = 18.2867s	
15418/33650 (epoch 22.909), train_loss = 0.90692310, grad/param norm = 1.2651e-01, time/batch = 17.9639s	
15419/33650 (epoch 22.911), train_loss = 0.79573978, grad/param norm = 1.1929e-01, time/batch = 17.8962s	
15420/33650 (epoch 22.912), train_loss = 0.78901963, grad/param norm = 1.3076e-01, time/batch = 18.1484s	
15421/33650 (epoch 22.914), train_loss = 0.96759104, grad/param norm = 1.3107e-01, time/batch = 18.8122s	
15422/33650 (epoch 22.915), train_loss = 0.92389023, grad/param norm = 1.7953e-01, time/batch = 17.5549s	
15423/33650 (epoch 22.917), train_loss = 0.92786905, grad/param norm = 1.5322e-01, time/batch = 18.3183s	
15424/33650 (epoch 22.918), train_loss = 0.80199955, grad/param norm = 1.2161e-01, time/batch = 18.7240s	
15425/33650 (epoch 22.920), train_loss = 0.86327313, grad/param norm = 1.2736e-01, time/batch = 17.9773s	
15426/33650 (epoch 22.921), train_loss = 0.86798676, grad/param norm = 1.4145e-01, time/batch = 18.4771s	
15427/33650 (epoch 22.923), train_loss = 0.81436097, grad/param norm = 1.4256e-01, time/batch = 17.3985s	
15428/33650 (epoch 22.924), train_loss = 0.97835445, grad/param norm = 1.7589e-01, time/batch = 17.4797s	
15429/33650 (epoch 22.926), train_loss = 0.90572262, grad/param norm = 1.9710e-01, time/batch = 18.2347s	
15430/33650 (epoch 22.927), train_loss = 0.92339589, grad/param norm = 1.4350e-01, time/batch = 17.3153s	
15431/33650 (epoch 22.929), train_loss = 1.01155847, grad/param norm = 1.4960e-01, time/batch = 17.6222s	
15432/33650 (epoch 22.930), train_loss = 0.92009831, grad/param norm = 1.5154e-01, time/batch = 17.4583s	
15433/33650 (epoch 22.932), train_loss = 0.92747942, grad/param norm = 1.4407e-01, time/batch = 18.6477s	
15434/33650 (epoch 22.933), train_loss = 0.82844963, grad/param norm = 1.4183e-01, time/batch = 17.8910s	
15435/33650 (epoch 22.935), train_loss = 0.84499187, grad/param norm = 1.5967e-01, time/batch = 15.9700s	
15436/33650 (epoch 22.936), train_loss = 0.88489801, grad/param norm = 1.3852e-01, time/batch = 18.7184s	
15437/33650 (epoch 22.938), train_loss = 0.83936889, grad/param norm = 1.5324e-01, time/batch = 18.0599s	
15438/33650 (epoch 22.939), train_loss = 1.02081990, grad/param norm = 1.5203e-01, time/batch = 17.1553s	
15439/33650 (epoch 22.941), train_loss = 0.96283377, grad/param norm = 1.4019e-01, time/batch = 18.1377s	
15440/33650 (epoch 22.942), train_loss = 1.04950081, grad/param norm = 1.6841e-01, time/batch = 18.2397s	
15441/33650 (epoch 22.944), train_loss = 0.92238729, grad/param norm = 1.3310e-01, time/batch = 17.6599s	
15442/33650 (epoch 22.945), train_loss = 0.97993510, grad/param norm = 1.4179e-01, time/batch = 17.4742s	
15443/33650 (epoch 22.947), train_loss = 1.11307719, grad/param norm = 2.0579e-01, time/batch = 19.0570s	
15444/33650 (epoch 22.948), train_loss = 1.09431770, grad/param norm = 1.4915e-01, time/batch = 16.7146s	
15445/33650 (epoch 22.949), train_loss = 0.83508559, grad/param norm = 1.3446e-01, time/batch = 17.1354s	
15446/33650 (epoch 22.951), train_loss = 1.10124574, grad/param norm = 1.6327e-01, time/batch = 17.8113s	
15447/33650 (epoch 22.952), train_loss = 1.02869501, grad/param norm = 1.6434e-01, time/batch = 18.8981s	
15448/33650 (epoch 22.954), train_loss = 1.01849585, grad/param norm = 1.3837e-01, time/batch = 18.2289s	
15449/33650 (epoch 22.955), train_loss = 1.00456973, grad/param norm = 1.4602e-01, time/batch = 17.6878s	
15450/33650 (epoch 22.957), train_loss = 1.03289540, grad/param norm = 1.7093e-01, time/batch = 18.6463s	
15451/33650 (epoch 22.958), train_loss = 0.77653904, grad/param norm = 1.3935e-01, time/batch = 17.4016s	
15452/33650 (epoch 22.960), train_loss = 0.78651029, grad/param norm = 1.3320e-01, time/batch = 16.8046s	
15453/33650 (epoch 22.961), train_loss = 0.84356988, grad/param norm = 1.4310e-01, time/batch = 17.4033s	
15454/33650 (epoch 22.963), train_loss = 0.89908430, grad/param norm = 1.5698e-01, time/batch = 14.7331s	
15455/33650 (epoch 22.964), train_loss = 1.03970341, grad/param norm = 1.9177e-01, time/batch = 17.5479s	
15456/33650 (epoch 22.966), train_loss = 0.98396729, grad/param norm = 1.6492e-01, time/batch = 17.6356s	
15457/33650 (epoch 22.967), train_loss = 0.98581967, grad/param norm = 1.4449e-01, time/batch = 16.2173s	
15458/33650 (epoch 22.969), train_loss = 0.95419963, grad/param norm = 1.3584e-01, time/batch = 18.1318s	
15459/33650 (epoch 22.970), train_loss = 0.99317167, grad/param norm = 1.4809e-01, time/batch = 17.2299s	
15460/33650 (epoch 22.972), train_loss = 1.25676848, grad/param norm = 1.6522e-01, time/batch = 17.3123s	
15461/33650 (epoch 22.973), train_loss = 0.86403663, grad/param norm = 1.3160e-01, time/batch = 18.6446s	
15462/33650 (epoch 22.975), train_loss = 0.86496669, grad/param norm = 1.4057e-01, time/batch = 16.6238s	
15463/33650 (epoch 22.976), train_loss = 0.86910922, grad/param norm = 1.3074e-01, time/batch = 17.3063s	
15464/33650 (epoch 22.978), train_loss = 0.89778684, grad/param norm = 1.4796e-01, time/batch = 18.1410s	
15465/33650 (epoch 22.979), train_loss = 0.93344938, grad/param norm = 1.4939e-01, time/batch = 17.7351s	
15466/33650 (epoch 22.981), train_loss = 0.89861308, grad/param norm = 1.2325e-01, time/batch = 17.6393s	
15467/33650 (epoch 22.982), train_loss = 0.99009432, grad/param norm = 1.4199e-01, time/batch = 18.4779s	
15468/33650 (epoch 22.984), train_loss = 0.79734503, grad/param norm = 1.3329e-01, time/batch = 17.5584s	
15469/33650 (epoch 22.985), train_loss = 0.81302027, grad/param norm = 1.3991e-01, time/batch = 16.4730s	
15470/33650 (epoch 22.987), train_loss = 0.94599462, grad/param norm = 1.4080e-01, time/batch = 18.8142s	
15471/33650 (epoch 22.988), train_loss = 0.96072719, grad/param norm = 1.6130e-01, time/batch = 17.8222s	
15472/33650 (epoch 22.990), train_loss = 1.12876647, grad/param norm = 1.7806e-01, time/batch = 16.7051s	
15473/33650 (epoch 22.991), train_loss = 0.99410928, grad/param norm = 1.4911e-01, time/batch = 17.8724s	
15474/33650 (epoch 22.993), train_loss = 0.99055305, grad/param norm = 1.6962e-01, time/batch = 17.4617s	
15475/33650 (epoch 22.994), train_loss = 0.94605553, grad/param norm = 1.5651e-01, time/batch = 17.8054s	
15476/33650 (epoch 22.996), train_loss = 0.87007142, grad/param norm = 1.3801e-01, time/batch = 16.7119s	
15477/33650 (epoch 22.997), train_loss = 1.03009336, grad/param norm = 1.5586e-01, time/batch = 18.8886s	
15478/33650 (epoch 22.999), train_loss = 0.88415583, grad/param norm = 1.4440e-01, time/batch = 17.6561s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
15479/33650 (epoch 23.000), train_loss = 1.04455802, grad/param norm = 1.7461e-01, time/batch = 16.3890s	
15480/33650 (epoch 23.001), train_loss = 1.12320720, grad/param norm = 1.6241e-01, time/batch = 18.3217s	
15481/33650 (epoch 23.003), train_loss = 1.09777836, grad/param norm = 1.7812e-01, time/batch = 18.5538s	
15482/33650 (epoch 23.004), train_loss = 0.97938730, grad/param norm = 1.5961e-01, time/batch = 17.8896s	
15483/33650 (epoch 23.006), train_loss = 0.91157252, grad/param norm = 1.4332e-01, time/batch = 18.3844s	
15484/33650 (epoch 23.007), train_loss = 1.01956112, grad/param norm = 1.5075e-01, time/batch = 16.8778s	
15485/33650 (epoch 23.009), train_loss = 0.91330414, grad/param norm = 1.4224e-01, time/batch = 15.8043s	
15486/33650 (epoch 23.010), train_loss = 1.04565026, grad/param norm = 1.6248e-01, time/batch = 17.1356s	
15487/33650 (epoch 23.012), train_loss = 0.89174180, grad/param norm = 1.5066e-01, time/batch = 18.6470s	
15488/33650 (epoch 23.013), train_loss = 0.95058847, grad/param norm = 1.6629e-01, time/batch = 18.1504s	
15489/33650 (epoch 23.015), train_loss = 0.94708760, grad/param norm = 1.5979e-01, time/batch = 17.3949s	
15490/33650 (epoch 23.016), train_loss = 0.84651493, grad/param norm = 1.4548e-01, time/batch = 17.7351s	
15491/33650 (epoch 23.018), train_loss = 0.94780358, grad/param norm = 1.8697e-01, time/batch = 18.2188s	
15492/33650 (epoch 23.019), train_loss = 0.90932296, grad/param norm = 1.4828e-01, time/batch = 18.4848s	
15493/33650 (epoch 23.021), train_loss = 1.00361779, grad/param norm = 1.5705e-01, time/batch = 17.9674s	
15494/33650 (epoch 23.022), train_loss = 0.89478841, grad/param norm = 1.3522e-01, time/batch = 17.5507s	
15495/33650 (epoch 23.024), train_loss = 0.86903959, grad/param norm = 1.4761e-01, time/batch = 18.3897s	
15496/33650 (epoch 23.025), train_loss = 0.96502553, grad/param norm = 1.7328e-01, time/batch = 16.5547s	
15497/33650 (epoch 23.027), train_loss = 0.98834027, grad/param norm = 1.5911e-01, time/batch = 18.0671s	
15498/33650 (epoch 23.028), train_loss = 1.03400519, grad/param norm = 1.4730e-01, time/batch = 18.3129s	
15499/33650 (epoch 23.030), train_loss = 0.96975165, grad/param norm = 1.5198e-01, time/batch = 17.1310s	
15500/33650 (epoch 23.031), train_loss = 0.86937903, grad/param norm = 1.3510e-01, time/batch = 18.2320s	
15501/33650 (epoch 23.033), train_loss = 0.93603188, grad/param norm = 1.2854e-01, time/batch = 17.9812s	
15502/33650 (epoch 23.034), train_loss = 0.97880016, grad/param norm = 1.5141e-01, time/batch = 17.8180s	
15503/33650 (epoch 23.036), train_loss = 1.07779431, grad/param norm = 1.6881e-01, time/batch = 17.5506s	
15504/33650 (epoch 23.037), train_loss = 0.92412473, grad/param norm = 1.4661e-01, time/batch = 18.7326s	
15505/33650 (epoch 23.039), train_loss = 1.03612285, grad/param norm = 1.5455e-01, time/batch = 16.5451s	
15506/33650 (epoch 23.040), train_loss = 1.13709727, grad/param norm = 1.7618e-01, time/batch = 16.6377s	
15507/33650 (epoch 23.042), train_loss = 1.14512235, grad/param norm = 1.6563e-01, time/batch = 17.4824s	
15508/33650 (epoch 23.043), train_loss = 0.90393296, grad/param norm = 1.4315e-01, time/batch = 16.3832s	
15509/33650 (epoch 23.045), train_loss = 0.89969092, grad/param norm = 1.4014e-01, time/batch = 17.8219s	
15510/33650 (epoch 23.046), train_loss = 1.00902827, grad/param norm = 1.4265e-01, time/batch = 17.6390s	
15511/33650 (epoch 23.048), train_loss = 1.04824892, grad/param norm = 1.5814e-01, time/batch = 18.9850s	
15512/33650 (epoch 23.049), train_loss = 0.94915169, grad/param norm = 1.5001e-01, time/batch = 17.7459s	
15513/33650 (epoch 23.051), train_loss = 1.12119160, grad/param norm = 1.6417e-01, time/batch = 17.3045s	
15514/33650 (epoch 23.052), train_loss = 1.09406917, grad/param norm = 1.8809e-01, time/batch = 17.7341s	
15515/33650 (epoch 23.053), train_loss = 1.01312552, grad/param norm = 1.3637e-01, time/batch = 18.3134s	
15516/33650 (epoch 23.055), train_loss = 0.86904086, grad/param norm = 1.4460e-01, time/batch = 17.3003s	
15517/33650 (epoch 23.056), train_loss = 0.84512811, grad/param norm = 1.2557e-01, time/batch = 18.2225s	
15518/33650 (epoch 23.058), train_loss = 1.06231313, grad/param norm = 1.8453e-01, time/batch = 16.8738s	
15519/33650 (epoch 23.059), train_loss = 1.00541562, grad/param norm = 1.5466e-01, time/batch = 18.2286s	
15520/33650 (epoch 23.061), train_loss = 1.04861051, grad/param norm = 1.6305e-01, time/batch = 17.3005s	
15521/33650 (epoch 23.062), train_loss = 1.00893557, grad/param norm = 1.4697e-01, time/batch = 18.5618s	
15522/33650 (epoch 23.064), train_loss = 0.93294799, grad/param norm = 1.3478e-01, time/batch = 17.8922s	
15523/33650 (epoch 23.065), train_loss = 0.91591230, grad/param norm = 1.3587e-01, time/batch = 15.6509s	
15524/33650 (epoch 23.067), train_loss = 0.84849029, grad/param norm = 1.3111e-01, time/batch = 17.2049s	
15525/33650 (epoch 23.068), train_loss = 0.97229627, grad/param norm = 1.8120e-01, time/batch = 16.7977s	
15526/33650 (epoch 23.070), train_loss = 1.02111863, grad/param norm = 1.6540e-01, time/batch = 18.6384s	
15527/33650 (epoch 23.071), train_loss = 0.94888003, grad/param norm = 1.4425e-01, time/batch = 17.7239s	
15528/33650 (epoch 23.073), train_loss = 1.00286319, grad/param norm = 1.5854e-01, time/batch = 17.2173s	
15529/33650 (epoch 23.074), train_loss = 1.08084959, grad/param norm = 1.3872e-01, time/batch = 18.3124s	
15530/33650 (epoch 23.076), train_loss = 1.04669593, grad/param norm = 1.7670e-01, time/batch = 16.6424s	
15531/33650 (epoch 23.077), train_loss = 0.96129945, grad/param norm = 1.4355e-01, time/batch = 18.0591s	
15532/33650 (epoch 23.079), train_loss = 0.99342231, grad/param norm = 1.4469e-01, time/batch = 18.6474s	
15533/33650 (epoch 23.080), train_loss = 0.99837787, grad/param norm = 1.5998e-01, time/batch = 17.0630s	
15534/33650 (epoch 23.082), train_loss = 0.98243822, grad/param norm = 1.4178e-01, time/batch = 18.0618s	
15535/33650 (epoch 23.083), train_loss = 1.03582054, grad/param norm = 1.5287e-01, time/batch = 16.2266s	
15536/33650 (epoch 23.085), train_loss = 1.05605080, grad/param norm = 1.5492e-01, time/batch = 17.8159s	
15537/33650 (epoch 23.086), train_loss = 1.04666507, grad/param norm = 1.6799e-01, time/batch = 17.3012s	
15538/33650 (epoch 23.088), train_loss = 0.99396846, grad/param norm = 1.5326e-01, time/batch = 17.4100s	
15539/33650 (epoch 23.089), train_loss = 0.93633685, grad/param norm = 1.5391e-01, time/batch = 18.4814s	
15540/33650 (epoch 23.091), train_loss = 0.91883963, grad/param norm = 1.3308e-01, time/batch = 17.4696s	
15541/33650 (epoch 23.092), train_loss = 0.95827695, grad/param norm = 1.4814e-01, time/batch = 18.0422s	
15542/33650 (epoch 23.094), train_loss = 1.03655878, grad/param norm = 1.4187e-01, time/batch = 18.2385s	
15543/33650 (epoch 23.095), train_loss = 1.02073757, grad/param norm = 1.6922e-01, time/batch = 17.1405s	
15544/33650 (epoch 23.097), train_loss = 0.90870345, grad/param norm = 1.5758e-01, time/batch = 23.1364s	
15545/33650 (epoch 23.098), train_loss = 0.78986100, grad/param norm = 1.4393e-01, time/batch = 36.4217s	
15546/33650 (epoch 23.100), train_loss = 0.90618092, grad/param norm = 1.4221e-01, time/batch = 30.9709s	
15547/33650 (epoch 23.101), train_loss = 0.97794063, grad/param norm = 2.0954e-01, time/batch = 37.8972s	
15548/33650 (epoch 23.103), train_loss = 0.94144821, grad/param norm = 1.5542e-01, time/batch = 37.0724s	
15549/33650 (epoch 23.104), train_loss = 1.07903127, grad/param norm = 1.4448e-01, time/batch = 36.0725s	
15550/33650 (epoch 23.105), train_loss = 0.95996940, grad/param norm = 1.4741e-01, time/batch = 36.5868s	
15551/33650 (epoch 23.107), train_loss = 0.90973600, grad/param norm = 1.4656e-01, time/batch = 38.6631s	
15552/33650 (epoch 23.108), train_loss = 1.04802206, grad/param norm = 1.4626e-01, time/batch = 37.5073s	
15553/33650 (epoch 23.110), train_loss = 1.14410103, grad/param norm = 1.7074e-01, time/batch = 38.9033s	
15554/33650 (epoch 23.111), train_loss = 0.92320640, grad/param norm = 1.4687e-01, time/batch = 36.0905s	
15555/33650 (epoch 23.113), train_loss = 0.94603165, grad/param norm = 1.4996e-01, time/batch = 22.0183s	
15556/33650 (epoch 23.114), train_loss = 1.05065016, grad/param norm = 1.5558e-01, time/batch = 17.2154s	
15557/33650 (epoch 23.116), train_loss = 0.88489453, grad/param norm = 1.4109e-01, time/batch = 16.7262s	
15558/33650 (epoch 23.117), train_loss = 0.96191246, grad/param norm = 1.3195e-01, time/batch = 16.8001s	
15559/33650 (epoch 23.119), train_loss = 0.85612634, grad/param norm = 1.3452e-01, time/batch = 17.6483s	
15560/33650 (epoch 23.120), train_loss = 0.92961178, grad/param norm = 1.3915e-01, time/batch = 17.1550s	
15561/33650 (epoch 23.122), train_loss = 0.76022859, grad/param norm = 1.4592e-01, time/batch = 18.4753s	
15562/33650 (epoch 23.123), train_loss = 0.91922089, grad/param norm = 1.3221e-01, time/batch = 18.4817s	
15563/33650 (epoch 23.125), train_loss = 1.01206124, grad/param norm = 1.5511e-01, time/batch = 18.4595s	
15564/33650 (epoch 23.126), train_loss = 1.07977425, grad/param norm = 1.6252e-01, time/batch = 17.9891s	
15565/33650 (epoch 23.128), train_loss = 1.05272255, grad/param norm = 1.6786e-01, time/batch = 18.3173s	
15566/33650 (epoch 23.129), train_loss = 1.07657120, grad/param norm = 1.5041e-01, time/batch = 16.7036s	
15567/33650 (epoch 23.131), train_loss = 0.99154397, grad/param norm = 1.5004e-01, time/batch = 17.8249s	
15568/33650 (epoch 23.132), train_loss = 0.98160228, grad/param norm = 1.5390e-01, time/batch = 17.5755s	
15569/33650 (epoch 23.134), train_loss = 1.04318065, grad/param norm = 1.6648e-01, time/batch = 17.4766s	
15570/33650 (epoch 23.135), train_loss = 0.87143703, grad/param norm = 1.6538e-01, time/batch = 15.9671s	
15571/33650 (epoch 23.137), train_loss = 0.99122839, grad/param norm = 1.6473e-01, time/batch = 17.2401s	
15572/33650 (epoch 23.138), train_loss = 1.02510598, grad/param norm = 1.5446e-01, time/batch = 17.8986s	
15573/33650 (epoch 23.140), train_loss = 0.96016345, grad/param norm = 1.6964e-01, time/batch = 16.8719s	
15574/33650 (epoch 23.141), train_loss = 1.10659631, grad/param norm = 1.6589e-01, time/batch = 17.4844s	
15575/33650 (epoch 23.143), train_loss = 1.14178150, grad/param norm = 1.9492e-01, time/batch = 18.3830s	
15576/33650 (epoch 23.144), train_loss = 1.03917795, grad/param norm = 1.7695e-01, time/batch = 17.2312s	
15577/33650 (epoch 23.146), train_loss = 0.95199361, grad/param norm = 1.4639e-01, time/batch = 18.6574s	
15578/33650 (epoch 23.147), train_loss = 0.92489313, grad/param norm = 1.5203e-01, time/batch = 18.2274s	
15579/33650 (epoch 23.149), train_loss = 0.87394291, grad/param norm = 1.5214e-01, time/batch = 17.4826s	
15580/33650 (epoch 23.150), train_loss = 0.85431015, grad/param norm = 1.5043e-01, time/batch = 25.6838s	
15581/33650 (epoch 23.152), train_loss = 0.91049531, grad/param norm = 1.4796e-01, time/batch = 24.9300s	
15582/33650 (epoch 23.153), train_loss = 0.93722995, grad/param norm = 1.4488e-01, time/batch = 15.8012s	
15583/33650 (epoch 23.155), train_loss = 0.90283934, grad/param norm = 1.3423e-01, time/batch = 18.5536s	
15584/33650 (epoch 23.156), train_loss = 0.87096625, grad/param norm = 1.3536e-01, time/batch = 18.2386s	
15585/33650 (epoch 23.158), train_loss = 1.00883319, grad/param norm = 1.6863e-01, time/batch = 17.4739s	
15586/33650 (epoch 23.159), train_loss = 0.88915878, grad/param norm = 1.3180e-01, time/batch = 17.3965s	
15587/33650 (epoch 23.160), train_loss = 0.90500328, grad/param norm = 1.3108e-01, time/batch = 18.3918s	
15588/33650 (epoch 23.162), train_loss = 0.94590615, grad/param norm = 1.5337e-01, time/batch = 18.8108s	
15589/33650 (epoch 23.163), train_loss = 1.03115007, grad/param norm = 1.7400e-01, time/batch = 15.8573s	
15590/33650 (epoch 23.165), train_loss = 0.86603559, grad/param norm = 1.5079e-01, time/batch = 17.8191s	
15591/33650 (epoch 23.166), train_loss = 0.87335694, grad/param norm = 1.5450e-01, time/batch = 18.3919s	
15592/33650 (epoch 23.168), train_loss = 1.04418914, grad/param norm = 1.6243e-01, time/batch = 17.3881s	
15593/33650 (epoch 23.169), train_loss = 0.98400450, grad/param norm = 1.5985e-01, time/batch = 17.7427s	
15594/33650 (epoch 23.171), train_loss = 0.95472957, grad/param norm = 1.4392e-01, time/batch = 17.6384s	
15595/33650 (epoch 23.172), train_loss = 0.92100888, grad/param norm = 1.4588e-01, time/batch = 17.7264s	
15596/33650 (epoch 23.174), train_loss = 0.88565409, grad/param norm = 1.3303e-01, time/batch = 16.7083s	
15597/33650 (epoch 23.175), train_loss = 0.84966048, grad/param norm = 1.4096e-01, time/batch = 17.4091s	
15598/33650 (epoch 23.177), train_loss = 0.96374045, grad/param norm = 1.5205e-01, time/batch = 16.5797s	
15599/33650 (epoch 23.178), train_loss = 0.90757881, grad/param norm = 1.6860e-01, time/batch = 17.3166s	
15600/33650 (epoch 23.180), train_loss = 0.84973922, grad/param norm = 1.3631e-01, time/batch = 18.8098s	
15601/33650 (epoch 23.181), train_loss = 0.78208673, grad/param norm = 1.3860e-01, time/batch = 18.2182s	
15602/33650 (epoch 23.183), train_loss = 0.90327706, grad/param norm = 1.8286e-01, time/batch = 17.1351s	
15603/33650 (epoch 23.184), train_loss = 0.90890595, grad/param norm = 1.7815e-01, time/batch = 18.2156s	
15604/33650 (epoch 23.186), train_loss = 0.94444958, grad/param norm = 1.6666e-01, time/batch = 17.5656s	
15605/33650 (epoch 23.187), train_loss = 1.11322765, grad/param norm = 1.6516e-01, time/batch = 18.4021s	
15606/33650 (epoch 23.189), train_loss = 1.04570432, grad/param norm = 1.7632e-01, time/batch = 17.2228s	
15607/33650 (epoch 23.190), train_loss = 0.96788410, grad/param norm = 1.5452e-01, time/batch = 17.0439s	
15608/33650 (epoch 23.192), train_loss = 1.14809403, grad/param norm = 1.5038e-01, time/batch = 16.6471s	
15609/33650 (epoch 23.193), train_loss = 1.08250673, grad/param norm = 1.4478e-01, time/batch = 16.7295s	
15610/33650 (epoch 23.195), train_loss = 0.83826181, grad/param norm = 1.3189e-01, time/batch = 18.8940s	
15611/33650 (epoch 23.196), train_loss = 0.83399995, grad/param norm = 1.5941e-01, time/batch = 17.3971s	
15612/33650 (epoch 23.198), train_loss = 0.90472162, grad/param norm = 1.5457e-01, time/batch = 17.1374s	
15613/33650 (epoch 23.199), train_loss = 1.04444153, grad/param norm = 1.8162e-01, time/batch = 18.4733s	
15614/33650 (epoch 23.201), train_loss = 0.91945698, grad/param norm = 1.5246e-01, time/batch = 17.9037s	
15615/33650 (epoch 23.202), train_loss = 0.92491279, grad/param norm = 1.5018e-01, time/batch = 18.4709s	
15616/33650 (epoch 23.204), train_loss = 1.02166697, grad/param norm = 1.5969e-01, time/batch = 17.5606s	
15617/33650 (epoch 23.205), train_loss = 0.94830700, grad/param norm = 1.4740e-01, time/batch = 17.3769s	
15618/33650 (epoch 23.207), train_loss = 0.91692381, grad/param norm = 1.5646e-01, time/batch = 18.5660s	
15619/33650 (epoch 23.208), train_loss = 0.97141576, grad/param norm = 1.5338e-01, time/batch = 16.4687s	
15620/33650 (epoch 23.210), train_loss = 0.78762490, grad/param norm = 1.4182e-01, time/batch = 16.1367s	
15621/33650 (epoch 23.211), train_loss = 0.89339290, grad/param norm = 1.5291e-01, time/batch = 18.5443s	
15622/33650 (epoch 23.212), train_loss = 1.01533836, grad/param norm = 1.6596e-01, time/batch = 18.0644s	
15623/33650 (epoch 23.214), train_loss = 1.12454810, grad/param norm = 1.5557e-01, time/batch = 17.7305s	
15624/33650 (epoch 23.215), train_loss = 0.75153387, grad/param norm = 1.5722e-01, time/batch = 17.6420s	
15625/33650 (epoch 23.217), train_loss = 0.95047782, grad/param norm = 1.9674e-01, time/batch = 18.2284s	
15626/33650 (epoch 23.218), train_loss = 0.95801397, grad/param norm = 1.4645e-01, time/batch = 16.7190s	
15627/33650 (epoch 23.220), train_loss = 0.85384948, grad/param norm = 1.4958e-01, time/batch = 18.0634s	
15628/33650 (epoch 23.221), train_loss = 1.13748148, grad/param norm = 1.7871e-01, time/batch = 18.1554s	
15629/33650 (epoch 23.223), train_loss = 0.76180738, grad/param norm = 1.3679e-01, time/batch = 17.2097s	
15630/33650 (epoch 23.224), train_loss = 0.91625078, grad/param norm = 1.6829e-01, time/batch = 16.6310s	
15631/33650 (epoch 23.226), train_loss = 1.23218756, grad/param norm = 1.7848e-01, time/batch = 18.1431s	
15632/33650 (epoch 23.227), train_loss = 1.09999043, grad/param norm = 1.9167e-01, time/batch = 18.5671s	
15633/33650 (epoch 23.229), train_loss = 1.07878457, grad/param norm = 1.5802e-01, time/batch = 16.5640s	
15634/33650 (epoch 23.230), train_loss = 1.21124301, grad/param norm = 1.8662e-01, time/batch = 18.8143s	
15635/33650 (epoch 23.232), train_loss = 1.05031552, grad/param norm = 1.8539e-01, time/batch = 17.3129s	
15636/33650 (epoch 23.233), train_loss = 1.03205809, grad/param norm = 2.2769e-01, time/batch = 16.7267s	
15637/33650 (epoch 23.235), train_loss = 0.97157094, grad/param norm = 1.5652e-01, time/batch = 17.9767s	
15638/33650 (epoch 23.236), train_loss = 0.86028920, grad/param norm = 1.4711e-01, time/batch = 17.8212s	
15639/33650 (epoch 23.238), train_loss = 0.94321942, grad/param norm = 1.4365e-01, time/batch = 17.3015s	
15640/33650 (epoch 23.239), train_loss = 0.89531784, grad/param norm = 1.5964e-01, time/batch = 17.2372s	
15641/33650 (epoch 23.241), train_loss = 0.91738872, grad/param norm = 1.3649e-01, time/batch = 18.2097s	
15642/33650 (epoch 23.242), train_loss = 0.78014320, grad/param norm = 1.3858e-01, time/batch = 15.8792s	
15643/33650 (epoch 23.244), train_loss = 0.94414948, grad/param norm = 1.5215e-01, time/batch = 17.2212s	
15644/33650 (epoch 23.245), train_loss = 0.84968546, grad/param norm = 1.4011e-01, time/batch = 18.2248s	
15645/33650 (epoch 23.247), train_loss = 0.93662416, grad/param norm = 1.3274e-01, time/batch = 17.2335s	
15646/33650 (epoch 23.248), train_loss = 0.82621151, grad/param norm = 1.3063e-01, time/batch = 16.7150s	
15647/33650 (epoch 23.250), train_loss = 0.94128538, grad/param norm = 1.5164e-01, time/batch = 17.0761s	
15648/33650 (epoch 23.251), train_loss = 1.08074082, grad/param norm = 1.4180e-01, time/batch = 19.0654s	
15649/33650 (epoch 23.253), train_loss = 0.83563493, grad/param norm = 1.4380e-01, time/batch = 17.7330s	
15650/33650 (epoch 23.254), train_loss = 0.87668049, grad/param norm = 1.6004e-01, time/batch = 17.1320s	
15651/33650 (epoch 23.256), train_loss = 1.10033410, grad/param norm = 1.4995e-01, time/batch = 18.4748s	
15652/33650 (epoch 23.257), train_loss = 1.09502514, grad/param norm = 1.5475e-01, time/batch = 18.6465s	
15653/33650 (epoch 23.259), train_loss = 0.82566452, grad/param norm = 1.5122e-01, time/batch = 16.3257s	
15654/33650 (epoch 23.260), train_loss = 1.03256433, grad/param norm = 1.7652e-01, time/batch = 18.8894s	
15655/33650 (epoch 23.262), train_loss = 0.97980105, grad/param norm = 1.7036e-01, time/batch = 15.9540s	
15656/33650 (epoch 23.263), train_loss = 0.89858133, grad/param norm = 1.8071e-01, time/batch = 17.8221s	
15657/33650 (epoch 23.264), train_loss = 1.00815714, grad/param norm = 1.5503e-01, time/batch = 18.2175s	
15658/33650 (epoch 23.266), train_loss = 0.98423179, grad/param norm = 1.3797e-01, time/batch = 18.8172s	
15659/33650 (epoch 23.267), train_loss = 0.91071355, grad/param norm = 1.6120e-01, time/batch = 18.2334s	
15660/33650 (epoch 23.269), train_loss = 0.98105758, grad/param norm = 1.4612e-01, time/batch = 16.8868s	
15661/33650 (epoch 23.270), train_loss = 0.87712428, grad/param norm = 1.3880e-01, time/batch = 18.8920s	
15662/33650 (epoch 23.272), train_loss = 0.92451708, grad/param norm = 1.3685e-01, time/batch = 18.2223s	
15663/33650 (epoch 23.273), train_loss = 1.07483088, grad/param norm = 1.7575e-01, time/batch = 17.3056s	
15664/33650 (epoch 23.275), train_loss = 1.02600235, grad/param norm = 1.7231e-01, time/batch = 17.2310s	
15665/33650 (epoch 23.276), train_loss = 1.07479198, grad/param norm = 1.8932e-01, time/batch = 18.8178s	
15666/33650 (epoch 23.278), train_loss = 1.13391783, grad/param norm = 1.9028e-01, time/batch = 17.5651s	
15667/33650 (epoch 23.279), train_loss = 0.94979249, grad/param norm = 1.5897e-01, time/batch = 18.3084s	
15668/33650 (epoch 23.281), train_loss = 0.99348389, grad/param norm = 1.4684e-01, time/batch = 17.4892s	
15669/33650 (epoch 23.282), train_loss = 1.07119496, grad/param norm = 1.4294e-01, time/batch = 16.9647s	
15670/33650 (epoch 23.284), train_loss = 1.04923952, grad/param norm = 1.7685e-01, time/batch = 16.9665s	
15671/33650 (epoch 23.285), train_loss = 1.03656427, grad/param norm = 1.6015e-01, time/batch = 16.4787s	
15672/33650 (epoch 23.287), train_loss = 0.94715379, grad/param norm = 1.5930e-01, time/batch = 16.0477s	
15673/33650 (epoch 23.288), train_loss = 0.99498502, grad/param norm = 1.8305e-01, time/batch = 17.4070s	
15674/33650 (epoch 23.290), train_loss = 0.97970057, grad/param norm = 1.3999e-01, time/batch = 16.8024s	
15675/33650 (epoch 23.291), train_loss = 0.87817598, grad/param norm = 1.4759e-01, time/batch = 19.0577s	
15676/33650 (epoch 23.293), train_loss = 0.94013068, grad/param norm = 1.6771e-01, time/batch = 16.9945s	
15677/33650 (epoch 23.294), train_loss = 0.87675856, grad/param norm = 1.4414e-01, time/batch = 17.4004s	
15678/33650 (epoch 23.296), train_loss = 0.86764423, grad/param norm = 1.4842e-01, time/batch = 17.9745s	
15679/33650 (epoch 23.297), train_loss = 0.95046929, grad/param norm = 1.5048e-01, time/batch = 18.4897s	
15680/33650 (epoch 23.299), train_loss = 0.83124689, grad/param norm = 1.4613e-01, time/batch = 17.7985s	
15681/33650 (epoch 23.300), train_loss = 0.85948376, grad/param norm = 1.4017e-01, time/batch = 18.5589s	
15682/33650 (epoch 23.302), train_loss = 0.99527040, grad/param norm = 1.4091e-01, time/batch = 17.9824s	
15683/33650 (epoch 23.303), train_loss = 1.00456523, grad/param norm = 1.5299e-01, time/batch = 16.0464s	
15684/33650 (epoch 23.305), train_loss = 0.97645692, grad/param norm = 1.5456e-01, time/batch = 17.9833s	
15685/33650 (epoch 23.306), train_loss = 0.88498895, grad/param norm = 1.3708e-01, time/batch = 18.8071s	
15686/33650 (epoch 23.308), train_loss = 0.84116587, grad/param norm = 1.6113e-01, time/batch = 17.6615s	
15687/33650 (epoch 23.309), train_loss = 1.11184798, grad/param norm = 1.6495e-01, time/batch = 16.5572s	
15688/33650 (epoch 23.311), train_loss = 0.98924812, grad/param norm = 1.8250e-01, time/batch = 18.3901s	
15689/33650 (epoch 23.312), train_loss = 0.96358957, grad/param norm = 1.5172e-01, time/batch = 17.2898s	
15690/33650 (epoch 23.314), train_loss = 0.84708409, grad/param norm = 1.3077e-01, time/batch = 16.3916s	
15691/33650 (epoch 23.315), train_loss = 0.93913923, grad/param norm = 1.8386e-01, time/batch = 17.8936s	
15692/33650 (epoch 23.316), train_loss = 0.91423629, grad/param norm = 1.7901e-01, time/batch = 18.8930s	
15693/33650 (epoch 23.318), train_loss = 0.86659977, grad/param norm = 1.4041e-01, time/batch = 17.3238s	
15694/33650 (epoch 23.319), train_loss = 0.89161341, grad/param norm = 1.3297e-01, time/batch = 17.5495s	
15695/33650 (epoch 23.321), train_loss = 0.90036335, grad/param norm = 1.3665e-01, time/batch = 18.7327s	
15696/33650 (epoch 23.322), train_loss = 0.99867836, grad/param norm = 1.7495e-01, time/batch = 17.8977s	
15697/33650 (epoch 23.324), train_loss = 1.02150257, grad/param norm = 1.6631e-01, time/batch = 17.2144s	
15698/33650 (epoch 23.325), train_loss = 1.00958600, grad/param norm = 1.5164e-01, time/batch = 18.3045s	
15699/33650 (epoch 23.327), train_loss = 0.87578751, grad/param norm = 1.2775e-01, time/batch = 16.1459s	
15700/33650 (epoch 23.328), train_loss = 1.01074879, grad/param norm = 1.6150e-01, time/batch = 15.4686s	
15701/33650 (epoch 23.330), train_loss = 0.89251951, grad/param norm = 1.2856e-01, time/batch = 18.1427s	
15702/33650 (epoch 23.331), train_loss = 0.79115731, grad/param norm = 1.1919e-01, time/batch = 16.6142s	
15703/33650 (epoch 23.333), train_loss = 0.92934388, grad/param norm = 1.4220e-01, time/batch = 18.0594s	
15704/33650 (epoch 23.334), train_loss = 0.94928050, grad/param norm = 1.5326e-01, time/batch = 17.1322s	
15705/33650 (epoch 23.336), train_loss = 1.06056427, grad/param norm = 1.5330e-01, time/batch = 18.3912s	
15706/33650 (epoch 23.337), train_loss = 0.79846173, grad/param norm = 1.3055e-01, time/batch = 18.8010s	
15707/33650 (epoch 23.339), train_loss = 0.90885700, grad/param norm = 1.4195e-01, time/batch = 17.3929s	
15708/33650 (epoch 23.340), train_loss = 1.06849294, grad/param norm = 1.7346e-01, time/batch = 17.8934s	
15709/33650 (epoch 23.342), train_loss = 0.80695153, grad/param norm = 1.4967e-01, time/batch = 18.1511s	
15710/33650 (epoch 23.343), train_loss = 1.00845679, grad/param norm = 1.6051e-01, time/batch = 17.0751s	
15711/33650 (epoch 23.345), train_loss = 0.94207146, grad/param norm = 1.7229e-01, time/batch = 18.3924s	
15712/33650 (epoch 23.346), train_loss = 0.64603927, grad/param norm = 1.2200e-01, time/batch = 18.9851s	
15713/33650 (epoch 23.348), train_loss = 0.83297493, grad/param norm = 1.3361e-01, time/batch = 17.7376s	
15714/33650 (epoch 23.349), train_loss = 0.79223652, grad/param norm = 1.4266e-01, time/batch = 17.2195s	
15715/33650 (epoch 23.351), train_loss = 1.03335626, grad/param norm = 1.4825e-01, time/batch = 17.9787s	
15716/33650 (epoch 23.352), train_loss = 0.93114733, grad/param norm = 1.4763e-01, time/batch = 17.7925s	
15717/33650 (epoch 23.354), train_loss = 1.10520198, grad/param norm = 1.8335e-01, time/batch = 16.9816s	
15718/33650 (epoch 23.355), train_loss = 1.09048187, grad/param norm = 1.5002e-01, time/batch = 17.8079s	
15719/33650 (epoch 23.357), train_loss = 0.77097822, grad/param norm = 1.4388e-01, time/batch = 18.6481s	
15720/33650 (epoch 23.358), train_loss = 1.02007543, grad/param norm = 1.4699e-01, time/batch = 17.1921s	
15721/33650 (epoch 23.360), train_loss = 1.03575781, grad/param norm = 1.7479e-01, time/batch = 17.6222s	
15722/33650 (epoch 23.361), train_loss = 0.98145929, grad/param norm = 1.4730e-01, time/batch = 18.8083s	
15723/33650 (epoch 23.363), train_loss = 0.94924563, grad/param norm = 1.4490e-01, time/batch = 17.5740s	
15724/33650 (epoch 23.364), train_loss = 0.91555622, grad/param norm = 1.3866e-01, time/batch = 17.2288s	
15725/33650 (epoch 23.366), train_loss = 1.00356661, grad/param norm = 1.5733e-01, time/batch = 18.0658s	
15726/33650 (epoch 23.367), train_loss = 0.99486933, grad/param norm = 1.4218e-01, time/batch = 18.5570s	
15727/33650 (epoch 23.368), train_loss = 0.87038761, grad/param norm = 1.3604e-01, time/batch = 17.1388s	
15728/33650 (epoch 23.370), train_loss = 0.95248008, grad/param norm = 1.4161e-01, time/batch = 17.8922s	
15729/33650 (epoch 23.371), train_loss = 0.75708887, grad/param norm = 1.3396e-01, time/batch = 18.6528s	
15730/33650 (epoch 23.373), train_loss = 0.85831209, grad/param norm = 1.3102e-01, time/batch = 17.8982s	
15731/33650 (epoch 23.374), train_loss = 0.83752350, grad/param norm = 1.2686e-01, time/batch = 16.9443s	
15732/33650 (epoch 23.376), train_loss = 0.93508243, grad/param norm = 1.6739e-01, time/batch = 18.0644s	
15733/33650 (epoch 23.377), train_loss = 0.99005935, grad/param norm = 1.5996e-01, time/batch = 18.5565s	
15734/33650 (epoch 23.379), train_loss = 0.99285349, grad/param norm = 1.4056e-01, time/batch = 17.0599s	
15735/33650 (epoch 23.380), train_loss = 0.77452503, grad/param norm = 1.7150e-01, time/batch = 17.8261s	
15736/33650 (epoch 23.382), train_loss = 0.90742835, grad/param norm = 1.2388e-01, time/batch = 18.7441s	
15737/33650 (epoch 23.383), train_loss = 0.94082862, grad/param norm = 1.4199e-01, time/batch = 16.9830s	
15738/33650 (epoch 23.385), train_loss = 1.03803615, grad/param norm = 1.5343e-01, time/batch = 18.0537s	
15739/33650 (epoch 23.386), train_loss = 0.88526363, grad/param norm = 1.4359e-01, time/batch = 18.0746s	
15740/33650 (epoch 23.388), train_loss = 0.99117591, grad/param norm = 1.4051e-01, time/batch = 17.5447s	
15741/33650 (epoch 23.389), train_loss = 0.92099270, grad/param norm = 1.5363e-01, time/batch = 18.1399s	
15742/33650 (epoch 23.391), train_loss = 0.76057328, grad/param norm = 1.2823e-01, time/batch = 17.8200s	
15743/33650 (epoch 23.392), train_loss = 0.97051972, grad/param norm = 1.5849e-01, time/batch = 17.9942s	
15744/33650 (epoch 23.394), train_loss = 0.97241507, grad/param norm = 1.5964e-01, time/batch = 15.9570s	
15745/33650 (epoch 23.395), train_loss = 1.00344630, grad/param norm = 1.4392e-01, time/batch = 18.4639s	
15746/33650 (epoch 23.397), train_loss = 1.08090423, grad/param norm = 1.5414e-01, time/batch = 18.0682s	
15747/33650 (epoch 23.398), train_loss = 1.01236698, grad/param norm = 1.5384e-01, time/batch = 17.3885s	
15748/33650 (epoch 23.400), train_loss = 0.95897406, grad/param norm = 1.7260e-01, time/batch = 18.6511s	
15749/33650 (epoch 23.401), train_loss = 0.92637572, grad/param norm = 1.7810e-01, time/batch = 18.2293s	
15750/33650 (epoch 23.403), train_loss = 1.00225329, grad/param norm = 1.5341e-01, time/batch = 16.6591s	
15751/33650 (epoch 23.404), train_loss = 0.94462055, grad/param norm = 1.4158e-01, time/batch = 17.0562s	
15752/33650 (epoch 23.406), train_loss = 0.96012645, grad/param norm = 1.5207e-01, time/batch = 18.3175s	
15753/33650 (epoch 23.407), train_loss = 0.93255551, grad/param norm = 1.4824e-01, time/batch = 18.4023s	
15754/33650 (epoch 23.409), train_loss = 0.99293254, grad/param norm = 1.8482e-01, time/batch = 16.7309s	
15755/33650 (epoch 23.410), train_loss = 0.94150334, grad/param norm = 1.4974e-01, time/batch = 18.1460s	
15756/33650 (epoch 23.412), train_loss = 0.94367708, grad/param norm = 1.3539e-01, time/batch = 17.3938s	
15757/33650 (epoch 23.413), train_loss = 0.90398540, grad/param norm = 1.4472e-01, time/batch = 17.4069s	
15758/33650 (epoch 23.415), train_loss = 1.01524224, grad/param norm = 1.5419e-01, time/batch = 17.4774s	
15759/33650 (epoch 23.416), train_loss = 1.08592780, grad/param norm = 1.5670e-01, time/batch = 18.3212s	
15760/33650 (epoch 23.418), train_loss = 0.89074850, grad/param norm = 1.3190e-01, time/batch = 18.4808s	
15761/33650 (epoch 23.419), train_loss = 0.91072407, grad/param norm = 1.5051e-01, time/batch = 17.2239s	
15762/33650 (epoch 23.421), train_loss = 0.92969258, grad/param norm = 1.3462e-01, time/batch = 18.2300s	
15763/33650 (epoch 23.422), train_loss = 1.05352187, grad/param norm = 1.4442e-01, time/batch = 17.8329s	
15764/33650 (epoch 23.423), train_loss = 0.86525531, grad/param norm = 1.2385e-01, time/batch = 17.5489s	
15765/33650 (epoch 23.425), train_loss = 0.95926732, grad/param norm = 1.7034e-01, time/batch = 17.8203s	
15766/33650 (epoch 23.426), train_loss = 1.07907450, grad/param norm = 1.5560e-01, time/batch = 17.8875s	
15767/33650 (epoch 23.428), train_loss = 0.88555256, grad/param norm = 1.3809e-01, time/batch = 17.7345s	
15768/33650 (epoch 23.429), train_loss = 1.02850298, grad/param norm = 1.7718e-01, time/batch = 16.5612s	
15769/33650 (epoch 23.431), train_loss = 1.10868244, grad/param norm = 1.8281e-01, time/batch = 17.7949s	
15770/33650 (epoch 23.432), train_loss = 1.11822829, grad/param norm = 1.7695e-01, time/batch = 18.2400s	
15771/33650 (epoch 23.434), train_loss = 0.98638808, grad/param norm = 1.5060e-01, time/batch = 16.2329s	
15772/33650 (epoch 23.435), train_loss = 0.96520207, grad/param norm = 1.6353e-01, time/batch = 17.8217s	
15773/33650 (epoch 23.437), train_loss = 0.98519387, grad/param norm = 1.6077e-01, time/batch = 18.7310s	
15774/33650 (epoch 23.438), train_loss = 0.91344300, grad/param norm = 1.7386e-01, time/batch = 17.0684s	
15775/33650 (epoch 23.440), train_loss = 0.94353127, grad/param norm = 1.6450e-01, time/batch = 18.0560s	
15776/33650 (epoch 23.441), train_loss = 0.95993672, grad/param norm = 1.5732e-01, time/batch = 18.5717s	
15777/33650 (epoch 23.443), train_loss = 1.00787271, grad/param norm = 1.4047e-01, time/batch = 17.4122s	
15778/33650 (epoch 23.444), train_loss = 0.93108031, grad/param norm = 1.4873e-01, time/batch = 17.8087s	
15779/33650 (epoch 23.446), train_loss = 0.99738524, grad/param norm = 1.6657e-01, time/batch = 17.3163s	
15780/33650 (epoch 23.447), train_loss = 1.07156033, grad/param norm = 1.6566e-01, time/batch = 18.7318s	
15781/33650 (epoch 23.449), train_loss = 1.11492445, grad/param norm = 2.2491e-01, time/batch = 26.9414s	
15782/33650 (epoch 23.450), train_loss = 1.14351444, grad/param norm = 1.9181e-01, time/batch = 20.0978s	
15783/33650 (epoch 23.452), train_loss = 1.14236395, grad/param norm = 2.0559e-01, time/batch = 17.9905s	
15784/33650 (epoch 23.453), train_loss = 1.11287341, grad/param norm = 1.8212e-01, time/batch = 15.8631s	
15785/33650 (epoch 23.455), train_loss = 0.94170772, grad/param norm = 1.4467e-01, time/batch = 18.1593s	
15786/33650 (epoch 23.456), train_loss = 0.96385702, grad/param norm = 1.5377e-01, time/batch = 18.3983s	
15787/33650 (epoch 23.458), train_loss = 0.94745576, grad/param norm = 1.7299e-01, time/batch = 16.4702s	
15788/33650 (epoch 23.459), train_loss = 0.98781176, grad/param norm = 1.6582e-01, time/batch = 17.7327s	
15789/33650 (epoch 23.461), train_loss = 1.10246205, grad/param norm = 1.7585e-01, time/batch = 18.8892s	
15790/33650 (epoch 23.462), train_loss = 1.08362516, grad/param norm = 1.7203e-01, time/batch = 17.4000s	
15791/33650 (epoch 23.464), train_loss = 0.94364030, grad/param norm = 1.8225e-01, time/batch = 16.1427s	
15792/33650 (epoch 23.465), train_loss = 0.98756727, grad/param norm = 1.7637e-01, time/batch = 18.8090s	
15793/33650 (epoch 23.467), train_loss = 1.01489179, grad/param norm = 1.5561e-01, time/batch = 17.3127s	
15794/33650 (epoch 23.468), train_loss = 1.09750649, grad/param norm = 1.5202e-01, time/batch = 16.4724s	
15795/33650 (epoch 23.470), train_loss = 1.17717712, grad/param norm = 1.8324e-01, time/batch = 17.3174s	
15796/33650 (epoch 23.471), train_loss = 0.99038000, grad/param norm = 1.5232e-01, time/batch = 17.9094s	
15797/33650 (epoch 23.473), train_loss = 0.94248383, grad/param norm = 1.4361e-01, time/batch = 17.3824s	
15798/33650 (epoch 23.474), train_loss = 1.08728043, grad/param norm = 1.6839e-01, time/batch = 18.0630s	
15799/33650 (epoch 23.475), train_loss = 1.04236401, grad/param norm = 1.6302e-01, time/batch = 17.8233s	
15800/33650 (epoch 23.477), train_loss = 1.08780239, grad/param norm = 1.6154e-01, time/batch = 18.2323s	
15801/33650 (epoch 23.478), train_loss = 1.08088754, grad/param norm = 1.8198e-01, time/batch = 16.6896s	
15802/33650 (epoch 23.480), train_loss = 1.07663738, grad/param norm = 1.7889e-01, time/batch = 17.2199s	
15803/33650 (epoch 23.481), train_loss = 1.13214045, grad/param norm = 1.7005e-01, time/batch = 18.6541s	
15804/33650 (epoch 23.483), train_loss = 0.81632348, grad/param norm = 1.3972e-01, time/batch = 15.0397s	
15805/33650 (epoch 23.484), train_loss = 0.97806741, grad/param norm = 1.6126e-01, time/batch = 18.0612s	
15806/33650 (epoch 23.486), train_loss = 1.13145892, grad/param norm = 1.8780e-01, time/batch = 18.5541s	
15807/33650 (epoch 23.487), train_loss = 1.12294257, grad/param norm = 1.6023e-01, time/batch = 18.2280s	
15808/33650 (epoch 23.489), train_loss = 1.14079450, grad/param norm = 1.6306e-01, time/batch = 17.4715s	
15809/33650 (epoch 23.490), train_loss = 0.87718872, grad/param norm = 1.5079e-01, time/batch = 17.9940s	
15810/33650 (epoch 23.492), train_loss = 1.02938329, grad/param norm = 1.5811e-01, time/batch = 17.4854s	
15811/33650 (epoch 23.493), train_loss = 0.82254236, grad/param norm = 1.3489e-01, time/batch = 17.3097s	
15812/33650 (epoch 23.495), train_loss = 0.98987565, grad/param norm = 1.5774e-01, time/batch = 17.6493s	
15813/33650 (epoch 23.496), train_loss = 1.04001713, grad/param norm = 1.6067e-01, time/batch = 18.8949s	
15814/33650 (epoch 23.498), train_loss = 0.88469725, grad/param norm = 1.3541e-01, time/batch = 17.0686s	
15815/33650 (epoch 23.499), train_loss = 0.97858512, grad/param norm = 1.3360e-01, time/batch = 17.5398s	
15816/33650 (epoch 23.501), train_loss = 0.94416810, grad/param norm = 1.2588e-01, time/batch = 17.6600s	
15817/33650 (epoch 23.502), train_loss = 0.98618650, grad/param norm = 1.5550e-01, time/batch = 18.3146s	
15818/33650 (epoch 23.504), train_loss = 1.07285322, grad/param norm = 1.6600e-01, time/batch = 17.0619s	
15819/33650 (epoch 23.505), train_loss = 0.94815819, grad/param norm = 1.8847e-01, time/batch = 18.4842s	
15820/33650 (epoch 23.507), train_loss = 1.08390091, grad/param norm = 1.5268e-01, time/batch = 17.3843s	
15821/33650 (epoch 23.508), train_loss = 0.95294569, grad/param norm = 1.4679e-01, time/batch = 17.1414s	
15822/33650 (epoch 23.510), train_loss = 0.98308068, grad/param norm = 1.4698e-01, time/batch = 17.9797s	
15823/33650 (epoch 23.511), train_loss = 1.18960830, grad/param norm = 1.8160e-01, time/batch = 16.4771s	
15824/33650 (epoch 23.513), train_loss = 1.04590816, grad/param norm = 1.5197e-01, time/batch = 18.6486s	
15825/33650 (epoch 23.514), train_loss = 1.06219068, grad/param norm = 1.6353e-01, time/batch = 16.8823s	
15826/33650 (epoch 23.516), train_loss = 1.00169307, grad/param norm = 1.8526e-01, time/batch = 18.3153s	
15827/33650 (epoch 23.517), train_loss = 0.99371643, grad/param norm = 1.7542e-01, time/batch = 17.1413s	
15828/33650 (epoch 23.519), train_loss = 1.03676694, grad/param norm = 1.5408e-01, time/batch = 17.3887s	
15829/33650 (epoch 23.520), train_loss = 0.84863780, grad/param norm = 1.3026e-01, time/batch = 18.1500s	
15830/33650 (epoch 23.522), train_loss = 0.96739972, grad/param norm = 1.5639e-01, time/batch = 17.9030s	
15831/33650 (epoch 23.523), train_loss = 0.93279133, grad/param norm = 1.5179e-01, time/batch = 17.0379s	
15832/33650 (epoch 23.525), train_loss = 0.78253773, grad/param norm = 1.2586e-01, time/batch = 18.9653s	
15833/33650 (epoch 23.526), train_loss = 1.07142861, grad/param norm = 1.4851e-01, time/batch = 17.9021s	
15834/33650 (epoch 23.527), train_loss = 0.92862829, grad/param norm = 1.4555e-01, time/batch = 17.6454s	
15835/33650 (epoch 23.529), train_loss = 0.97823332, grad/param norm = 1.5390e-01, time/batch = 17.0621s	
15836/33650 (epoch 23.530), train_loss = 0.91863144, grad/param norm = 1.4906e-01, time/batch = 17.0575s	
15837/33650 (epoch 23.532), train_loss = 1.05710940, grad/param norm = 1.7309e-01, time/batch = 16.8919s	
15838/33650 (epoch 23.533), train_loss = 0.97193352, grad/param norm = 1.5896e-01, time/batch = 16.5597s	
15839/33650 (epoch 23.535), train_loss = 1.08498493, grad/param norm = 1.5951e-01, time/batch = 18.6457s	
15840/33650 (epoch 23.536), train_loss = 0.98769595, grad/param norm = 1.6854e-01, time/batch = 18.0732s	
15841/33650 (epoch 23.538), train_loss = 1.03412457, grad/param norm = 1.8294e-01, time/batch = 16.2303s	
15842/33650 (epoch 23.539), train_loss = 0.81533719, grad/param norm = 1.5208e-01, time/batch = 17.5563s	
15843/33650 (epoch 23.541), train_loss = 1.09531552, grad/param norm = 1.7569e-01, time/batch = 17.3212s	
15844/33650 (epoch 23.542), train_loss = 1.00409427, grad/param norm = 1.9600e-01, time/batch = 17.3194s	
15845/33650 (epoch 23.544), train_loss = 1.15527983, grad/param norm = 1.9300e-01, time/batch = 16.3856s	
15846/33650 (epoch 23.545), train_loss = 0.84467114, grad/param norm = 1.3970e-01, time/batch = 18.2201s	
15847/33650 (epoch 23.547), train_loss = 1.01450131, grad/param norm = 1.5611e-01, time/batch = 17.8949s	
15848/33650 (epoch 23.548), train_loss = 1.15652917, grad/param norm = 1.6170e-01, time/batch = 17.0458s	
15849/33650 (epoch 23.550), train_loss = 0.99823073, grad/param norm = 1.4774e-01, time/batch = 17.3800s	
15850/33650 (epoch 23.551), train_loss = 0.99231626, grad/param norm = 1.6356e-01, time/batch = 18.2251s	
15851/33650 (epoch 23.553), train_loss = 0.86137452, grad/param norm = 1.5252e-01, time/batch = 18.8083s	
15852/33650 (epoch 23.554), train_loss = 1.13595112, grad/param norm = 1.6920e-01, time/batch = 17.2180s	
15853/33650 (epoch 23.556), train_loss = 1.06297526, grad/param norm = 1.8675e-01, time/batch = 17.3657s	
15854/33650 (epoch 23.557), train_loss = 1.07766899, grad/param norm = 1.9574e-01, time/batch = 17.9789s	
15855/33650 (epoch 23.559), train_loss = 1.25390186, grad/param norm = 1.9177e-01, time/batch = 17.1288s	
15856/33650 (epoch 23.560), train_loss = 1.18516099, grad/param norm = 1.7910e-01, time/batch = 18.7243s	
15857/33650 (epoch 23.562), train_loss = 1.12023871, grad/param norm = 1.6218e-01, time/batch = 16.7314s	
15858/33650 (epoch 23.563), train_loss = 1.02820460, grad/param norm = 1.5983e-01, time/batch = 18.1395s	
15859/33650 (epoch 23.565), train_loss = 0.97618738, grad/param norm = 1.4481e-01, time/batch = 18.5587s	
15860/33650 (epoch 23.566), train_loss = 0.96850363, grad/param norm = 1.4661e-01, time/batch = 18.4009s	
15861/33650 (epoch 23.568), train_loss = 1.02120112, grad/param norm = 1.8889e-01, time/batch = 18.1408s	
15862/33650 (epoch 23.569), train_loss = 0.92362601, grad/param norm = 1.4544e-01, time/batch = 17.0499s	
15863/33650 (epoch 23.571), train_loss = 1.10138564, grad/param norm = 1.6536e-01, time/batch = 18.8887s	
15864/33650 (epoch 23.572), train_loss = 1.04808467, grad/param norm = 1.3880e-01, time/batch = 18.4068s	
15865/33650 (epoch 23.574), train_loss = 0.93070836, grad/param norm = 1.7634e-01, time/batch = 17.3836s	
15866/33650 (epoch 23.575), train_loss = 0.99958281, grad/param norm = 1.5840e-01, time/batch = 18.4801s	
15867/33650 (epoch 23.577), train_loss = 0.96547973, grad/param norm = 1.5890e-01, time/batch = 18.3164s	
15868/33650 (epoch 23.578), train_loss = 1.06357129, grad/param norm = 1.4988e-01, time/batch = 16.7335s	
15869/33650 (epoch 23.579), train_loss = 1.03171140, grad/param norm = 1.6104e-01, time/batch = 17.9008s	
15870/33650 (epoch 23.581), train_loss = 1.11393462, grad/param norm = 1.5133e-01, time/batch = 17.4862s	
15871/33650 (epoch 23.582), train_loss = 1.04144860, grad/param norm = 1.3664e-01, time/batch = 16.1349s	
15872/33650 (epoch 23.584), train_loss = 1.00971578, grad/param norm = 1.5203e-01, time/batch = 15.5227s	
15873/33650 (epoch 23.585), train_loss = 1.03985341, grad/param norm = 1.8489e-01, time/batch = 18.6367s	
15874/33650 (epoch 23.587), train_loss = 0.91454582, grad/param norm = 1.5272e-01, time/batch = 17.8035s	
15875/33650 (epoch 23.588), train_loss = 0.95429929, grad/param norm = 1.9266e-01, time/batch = 16.1474s	
15876/33650 (epoch 23.590), train_loss = 0.94023659, grad/param norm = 1.3988e-01, time/batch = 16.8782s	
15877/33650 (epoch 23.591), train_loss = 0.91663414, grad/param norm = 1.6679e-01, time/batch = 18.5679s	
15878/33650 (epoch 23.593), train_loss = 0.89180863, grad/param norm = 1.4382e-01, time/batch = 16.9800s	
15879/33650 (epoch 23.594), train_loss = 0.89039808, grad/param norm = 1.6144e-01, time/batch = 17.3801s	
15880/33650 (epoch 23.596), train_loss = 0.97853278, grad/param norm = 1.5554e-01, time/batch = 19.0638s	
15881/33650 (epoch 23.597), train_loss = 0.83336522, grad/param norm = 1.2979e-01, time/batch = 18.5691s	
15882/33650 (epoch 23.599), train_loss = 0.96639923, grad/param norm = 1.5939e-01, time/batch = 17.0527s	
15883/33650 (epoch 23.600), train_loss = 0.89600453, grad/param norm = 1.3962e-01, time/batch = 18.4109s	
15884/33650 (epoch 23.602), train_loss = 1.02066747, grad/param norm = 1.4873e-01, time/batch = 17.9803s	
15885/33650 (epoch 23.603), train_loss = 0.92614200, grad/param norm = 1.5187e-01, time/batch = 17.0351s	
15886/33650 (epoch 23.605), train_loss = 1.03614266, grad/param norm = 1.5645e-01, time/batch = 16.4792s	
15887/33650 (epoch 23.606), train_loss = 1.01768436, grad/param norm = 1.5610e-01, time/batch = 18.6499s	
15888/33650 (epoch 23.608), train_loss = 0.90149042, grad/param norm = 1.6956e-01, time/batch = 17.5522s	
15889/33650 (epoch 23.609), train_loss = 0.97766522, grad/param norm = 1.5522e-01, time/batch = 17.2212s	
15890/33650 (epoch 23.611), train_loss = 0.88149457, grad/param norm = 1.4855e-01, time/batch = 17.2475s	
15891/33650 (epoch 23.612), train_loss = 0.98840454, grad/param norm = 1.7939e-01, time/batch = 17.6503s	
15892/33650 (epoch 23.614), train_loss = 1.07119572, grad/param norm = 1.6646e-01, time/batch = 17.7982s	
15893/33650 (epoch 23.615), train_loss = 0.97388542, grad/param norm = 1.3575e-01, time/batch = 17.5697s	
15894/33650 (epoch 23.617), train_loss = 0.88853093, grad/param norm = 1.3608e-01, time/batch = 18.3979s	
15895/33650 (epoch 23.618), train_loss = 0.95940331, grad/param norm = 1.3485e-01, time/batch = 17.5638s	
15896/33650 (epoch 23.620), train_loss = 0.99188145, grad/param norm = 1.6666e-01, time/batch = 17.6371s	
15897/33650 (epoch 23.621), train_loss = 0.88971120, grad/param norm = 1.4159e-01, time/batch = 18.3153s	
15898/33650 (epoch 23.623), train_loss = 0.96230997, grad/param norm = 1.7339e-01, time/batch = 18.2349s	
15899/33650 (epoch 23.624), train_loss = 0.77316760, grad/param norm = 1.3663e-01, time/batch = 17.1442s	
15900/33650 (epoch 23.626), train_loss = 0.79199128, grad/param norm = 1.3174e-01, time/batch = 18.1441s	
15901/33650 (epoch 23.627), train_loss = 0.88545481, grad/param norm = 1.4745e-01, time/batch = 18.1559s	
15902/33650 (epoch 23.629), train_loss = 0.93638989, grad/param norm = 1.4531e-01, time/batch = 16.4795s	
15903/33650 (epoch 23.630), train_loss = 1.05165582, grad/param norm = 1.6581e-01, time/batch = 18.2230s	
15904/33650 (epoch 23.632), train_loss = 1.09583507, grad/param norm = 1.5831e-01, time/batch = 17.8936s	
15905/33650 (epoch 23.633), train_loss = 1.04297820, grad/param norm = 1.5635e-01, time/batch = 17.6430s	
15906/33650 (epoch 23.634), train_loss = 0.87014339, grad/param norm = 1.3706e-01, time/batch = 16.7172s	
15907/33650 (epoch 23.636), train_loss = 0.74471889, grad/param norm = 1.1535e-01, time/batch = 16.2085s	
15908/33650 (epoch 23.637), train_loss = 0.90113670, grad/param norm = 1.4240e-01, time/batch = 18.1417s	
15909/33650 (epoch 23.639), train_loss = 0.90182326, grad/param norm = 1.4524e-01, time/batch = 16.5500s	
15910/33650 (epoch 23.640), train_loss = 0.98200718, grad/param norm = 1.5089e-01, time/batch = 16.7843s	
15911/33650 (epoch 23.642), train_loss = 1.04365956, grad/param norm = 1.7175e-01, time/batch = 17.9667s	
15912/33650 (epoch 23.643), train_loss = 0.98062702, grad/param norm = 1.5238e-01, time/batch = 16.7387s	
15913/33650 (epoch 23.645), train_loss = 0.98212212, grad/param norm = 1.4978e-01, time/batch = 17.8170s	
15914/33650 (epoch 23.646), train_loss = 0.84032300, grad/param norm = 1.2486e-01, time/batch = 18.9814s	
15915/33650 (epoch 23.648), train_loss = 1.01842156, grad/param norm = 1.5122e-01, time/batch = 18.4013s	
15916/33650 (epoch 23.649), train_loss = 0.91305194, grad/param norm = 1.4791e-01, time/batch = 16.6312s	
15917/33650 (epoch 23.651), train_loss = 1.07296618, grad/param norm = 1.6075e-01, time/batch = 18.1531s	
15918/33650 (epoch 23.652), train_loss = 0.70551622, grad/param norm = 1.3000e-01, time/batch = 18.3144s	
15919/33650 (epoch 23.654), train_loss = 0.87975598, grad/param norm = 1.4868e-01, time/batch = 17.3916s	
15920/33650 (epoch 23.655), train_loss = 0.84161901, grad/param norm = 1.4949e-01, time/batch = 17.6546s	
15921/33650 (epoch 23.657), train_loss = 0.91893291, grad/param norm = 1.5489e-01, time/batch = 18.6502s	
15922/33650 (epoch 23.658), train_loss = 0.79277928, grad/param norm = 1.3903e-01, time/batch = 17.9009s	
15923/33650 (epoch 23.660), train_loss = 0.79291074, grad/param norm = 1.4077e-01, time/batch = 17.1433s	
15924/33650 (epoch 23.661), train_loss = 0.87755933, grad/param norm = 1.4118e-01, time/batch = 16.7155s	
15925/33650 (epoch 23.663), train_loss = 0.82527451, grad/param norm = 1.5331e-01, time/batch = 14.0110s	
15926/33650 (epoch 23.664), train_loss = 0.89382456, grad/param norm = 1.4629e-01, time/batch = 17.2140s	
15927/33650 (epoch 23.666), train_loss = 0.91747836, grad/param norm = 1.3740e-01, time/batch = 18.3132s	
15928/33650 (epoch 23.667), train_loss = 0.82825599, grad/param norm = 1.3272e-01, time/batch = 18.4771s	
15929/33650 (epoch 23.669), train_loss = 0.84471582, grad/param norm = 1.4788e-01, time/batch = 15.7269s	
15930/33650 (epoch 23.670), train_loss = 0.76716439, grad/param norm = 1.3658e-01, time/batch = 17.8934s	
15931/33650 (epoch 23.672), train_loss = 0.80856124, grad/param norm = 1.6314e-01, time/batch = 18.3189s	
15932/33650 (epoch 23.673), train_loss = 0.77805540, grad/param norm = 1.4406e-01, time/batch = 17.9874s	
15933/33650 (epoch 23.675), train_loss = 0.76240128, grad/param norm = 1.1743e-01, time/batch = 16.1248s	
15934/33650 (epoch 23.676), train_loss = 0.92598142, grad/param norm = 1.5856e-01, time/batch = 16.6514s	
15935/33650 (epoch 23.678), train_loss = 0.87782881, grad/param norm = 1.4048e-01, time/batch = 18.4734s	
15936/33650 (epoch 23.679), train_loss = 0.89207008, grad/param norm = 1.5768e-01, time/batch = 17.6533s	
15937/33650 (epoch 23.681), train_loss = 0.90520650, grad/param norm = 1.3534e-01, time/batch = 16.5501s	
15938/33650 (epoch 23.682), train_loss = 0.84868663, grad/param norm = 1.5498e-01, time/batch = 18.8106s	
15939/33650 (epoch 23.684), train_loss = 0.81231389, grad/param norm = 1.3656e-01, time/batch = 16.6433s	
15940/33650 (epoch 23.685), train_loss = 0.99285358, grad/param norm = 1.6464e-01, time/batch = 16.8673s	
15941/33650 (epoch 23.686), train_loss = 0.93031227, grad/param norm = 1.3887e-01, time/batch = 18.5707s	
15942/33650 (epoch 23.688), train_loss = 1.01457212, grad/param norm = 1.5216e-01, time/batch = 18.3976s	
15943/33650 (epoch 23.689), train_loss = 0.86803227, grad/param norm = 1.4806e-01, time/batch = 15.3071s	
15944/33650 (epoch 23.691), train_loss = 1.06172590, grad/param norm = 1.8318e-01, time/batch = 17.0573s	
15945/33650 (epoch 23.692), train_loss = 1.06162860, grad/param norm = 1.5659e-01, time/batch = 17.8987s	
15946/33650 (epoch 23.694), train_loss = 0.96230055, grad/param norm = 1.5873e-01, time/batch = 16.8168s	
15947/33650 (epoch 23.695), train_loss = 0.69756479, grad/param norm = 1.4221e-01, time/batch = 17.4667s	
15948/33650 (epoch 23.697), train_loss = 0.90864207, grad/param norm = 1.4913e-01, time/batch = 17.9050s	
15949/33650 (epoch 23.698), train_loss = 1.08585397, grad/param norm = 1.6165e-01, time/batch = 19.2274s	
15950/33650 (epoch 23.700), train_loss = 0.93368116, grad/param norm = 1.4931e-01, time/batch = 16.8862s	
15951/33650 (epoch 23.701), train_loss = 0.95607872, grad/param norm = 1.5768e-01, time/batch = 17.9840s	
15952/33650 (epoch 23.703), train_loss = 1.13088757, grad/param norm = 1.4877e-01, time/batch = 18.7306s	
15953/33650 (epoch 23.704), train_loss = 0.91889640, grad/param norm = 1.3368e-01, time/batch = 17.4778s	
15954/33650 (epoch 23.706), train_loss = 0.88712483, grad/param norm = 1.3889e-01, time/batch = 17.3986s	
15955/33650 (epoch 23.707), train_loss = 1.03049031, grad/param norm = 1.4188e-01, time/batch = 17.8248s	
15956/33650 (epoch 23.709), train_loss = 0.91906489, grad/param norm = 1.4123e-01, time/batch = 17.1387s	
15957/33650 (epoch 23.710), train_loss = 1.10941061, grad/param norm = 1.5937e-01, time/batch = 16.3898s	
15958/33650 (epoch 23.712), train_loss = 0.85338976, grad/param norm = 1.4452e-01, time/batch = 18.7304s	
15959/33650 (epoch 23.713), train_loss = 0.84296859, grad/param norm = 1.8643e-01, time/batch = 17.7991s	
15960/33650 (epoch 23.715), train_loss = 1.00526504, grad/param norm = 1.7421e-01, time/batch = 16.9021s	
15961/33650 (epoch 23.716), train_loss = 0.87739483, grad/param norm = 1.4516e-01, time/batch = 18.3065s	
15962/33650 (epoch 23.718), train_loss = 0.88656206, grad/param norm = 1.5874e-01, time/batch = 18.2380s	
15963/33650 (epoch 23.719), train_loss = 1.06522508, grad/param norm = 1.7681e-01, time/batch = 16.0571s	
15964/33650 (epoch 23.721), train_loss = 1.15267524, grad/param norm = 1.8145e-01, time/batch = 17.9678s	
15965/33650 (epoch 23.722), train_loss = 1.00205976, grad/param norm = 1.8414e-01, time/batch = 17.4003s	
15966/33650 (epoch 23.724), train_loss = 1.06312556, grad/param norm = 1.6319e-01, time/batch = 18.4840s	
15967/33650 (epoch 23.725), train_loss = 1.02462675, grad/param norm = 1.5480e-01, time/batch = 17.1423s	
15968/33650 (epoch 23.727), train_loss = 0.88024046, grad/param norm = 1.7011e-01, time/batch = 17.8933s	
15969/33650 (epoch 23.728), train_loss = 0.90855888, grad/param norm = 1.4738e-01, time/batch = 17.9575s	
15970/33650 (epoch 23.730), train_loss = 0.98662131, grad/param norm = 1.5154e-01, time/batch = 17.3108s	
15971/33650 (epoch 23.731), train_loss = 1.08744878, grad/param norm = 1.6761e-01, time/batch = 17.9771s	
15972/33650 (epoch 23.733), train_loss = 0.94134153, grad/param norm = 1.5831e-01, time/batch = 18.3067s	
15973/33650 (epoch 23.734), train_loss = 1.07532735, grad/param norm = 1.7648e-01, time/batch = 18.3149s	
15974/33650 (epoch 23.736), train_loss = 0.94202745, grad/param norm = 1.7808e-01, time/batch = 16.8015s	
15975/33650 (epoch 23.737), train_loss = 0.99404340, grad/param norm = 1.6384e-01, time/batch = 18.2251s	
15976/33650 (epoch 23.738), train_loss = 0.86238477, grad/param norm = 1.5257e-01, time/batch = 16.4669s	
15977/33650 (epoch 23.740), train_loss = 0.80469178, grad/param norm = 1.3368e-01, time/batch = 17.4701s	
15978/33650 (epoch 23.741), train_loss = 0.88981767, grad/param norm = 1.6024e-01, time/batch = 17.9655s	
15979/33650 (epoch 23.743), train_loss = 0.95041044, grad/param norm = 1.5121e-01, time/batch = 19.0582s	
15980/33650 (epoch 23.744), train_loss = 1.00977387, grad/param norm = 1.4095e-01, time/batch = 16.7321s	
15981/33650 (epoch 23.746), train_loss = 0.91337894, grad/param norm = 1.4302e-01, time/batch = 18.3876s	
15982/33650 (epoch 23.747), train_loss = 1.05178408, grad/param norm = 1.5515e-01, time/batch = 18.2281s	
15983/33650 (epoch 23.749), train_loss = 0.80607648, grad/param norm = 1.4832e-01, time/batch = 15.7178s	
15984/33650 (epoch 23.750), train_loss = 1.08392160, grad/param norm = 1.4945e-01, time/batch = 11.6783s	
15985/33650 (epoch 23.752), train_loss = 1.05641297, grad/param norm = 1.5158e-01, time/batch = 0.6595s	
15986/33650 (epoch 23.753), train_loss = 1.14124496, grad/param norm = 1.7100e-01, time/batch = 0.6374s	
15987/33650 (epoch 23.755), train_loss = 0.91634092, grad/param norm = 1.3444e-01, time/batch = 0.6401s	
15988/33650 (epoch 23.756), train_loss = 1.03161192, grad/param norm = 1.6626e-01, time/batch = 0.6398s	
15989/33650 (epoch 23.758), train_loss = 1.03117826, grad/param norm = 1.4470e-01, time/batch = 0.6416s	
15990/33650 (epoch 23.759), train_loss = 1.07137545, grad/param norm = 1.6785e-01, time/batch = 0.6431s	
15991/33650 (epoch 23.761), train_loss = 0.97624999, grad/param norm = 1.4715e-01, time/batch = 0.7612s	
15992/33650 (epoch 23.762), train_loss = 0.95356373, grad/param norm = 1.5527e-01, time/batch = 0.9400s	
15993/33650 (epoch 23.764), train_loss = 1.01891426, grad/param norm = 1.5707e-01, time/batch = 0.9884s	
15994/33650 (epoch 23.765), train_loss = 0.94732335, grad/param norm = 1.6171e-01, time/batch = 0.9452s	
15995/33650 (epoch 23.767), train_loss = 0.94040804, grad/param norm = 1.4840e-01, time/batch = 0.9299s	
15996/33650 (epoch 23.768), train_loss = 0.83776078, grad/param norm = 1.4504e-01, time/batch = 1.0508s	
15997/33650 (epoch 23.770), train_loss = 0.99981133, grad/param norm = 1.5561e-01, time/batch = 1.7554s	
15998/33650 (epoch 23.771), train_loss = 0.98527151, grad/param norm = 1.6112e-01, time/batch = 1.7727s	
15999/33650 (epoch 23.773), train_loss = 1.07612667, grad/param norm = 1.6991e-01, time/batch = 7.3546s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch23.77_1.6209.t7	
16000/33650 (epoch 23.774), train_loss = 0.98733420, grad/param norm = 1.5084e-01, time/batch = 18.3021s	
16001/33650 (epoch 23.776), train_loss = 1.30471206, grad/param norm = 1.9064e-01, time/batch = 18.3164s	
16002/33650 (epoch 23.777), train_loss = 0.87864086, grad/param norm = 1.4404e-01, time/batch = 18.1596s	
16003/33650 (epoch 23.779), train_loss = 0.92131517, grad/param norm = 1.4552e-01, time/batch = 16.5442s	
16004/33650 (epoch 23.780), train_loss = 0.84508243, grad/param norm = 1.2616e-01, time/batch = 17.4788s	
16005/33650 (epoch 23.782), train_loss = 0.89710178, grad/param norm = 1.5707e-01, time/batch = 18.3231s	
16006/33650 (epoch 23.783), train_loss = 0.87957278, grad/param norm = 1.3131e-01, time/batch = 18.4851s	
16007/33650 (epoch 23.785), train_loss = 1.14222857, grad/param norm = 1.5154e-01, time/batch = 16.8014s	
16008/33650 (epoch 23.786), train_loss = 1.03749472, grad/param norm = 1.4188e-01, time/batch = 17.2325s	
16009/33650 (epoch 23.788), train_loss = 1.00771588, grad/param norm = 1.5499e-01, time/batch = 18.1530s	
16010/33650 (epoch 23.789), train_loss = 1.04964604, grad/param norm = 1.5108e-01, time/batch = 17.8045s	
16011/33650 (epoch 23.790), train_loss = 0.96610506, grad/param norm = 1.7073e-01, time/batch = 16.4869s	
16012/33650 (epoch 23.792), train_loss = 1.07874692, grad/param norm = 1.6790e-01, time/batch = 17.9876s	
16013/33650 (epoch 23.793), train_loss = 1.05251501, grad/param norm = 2.0129e-01, time/batch = 18.8128s	
16014/33650 (epoch 23.795), train_loss = 1.07062901, grad/param norm = 1.4891e-01, time/batch = 16.1506s	
16015/33650 (epoch 23.796), train_loss = 0.94541427, grad/param norm = 1.4837e-01, time/batch = 18.3946s	
16016/33650 (epoch 23.798), train_loss = 0.93451084, grad/param norm = 1.5885e-01, time/batch = 18.0506s	
16017/33650 (epoch 23.799), train_loss = 0.96288315, grad/param norm = 1.4176e-01, time/batch = 16.6311s	
16018/33650 (epoch 23.801), train_loss = 0.97594635, grad/param norm = 1.8264e-01, time/batch = 18.0659s	
16019/33650 (epoch 23.802), train_loss = 1.07623030, grad/param norm = 1.6553e-01, time/batch = 17.7341s	
16020/33650 (epoch 23.804), train_loss = 0.97823274, grad/param norm = 1.6697e-01, time/batch = 15.7071s	
16021/33650 (epoch 23.805), train_loss = 0.95699472, grad/param norm = 1.2743e-01, time/batch = 18.0530s	
16022/33650 (epoch 23.807), train_loss = 1.16976972, grad/param norm = 1.9461e-01, time/batch = 18.1476s	
16023/33650 (epoch 23.808), train_loss = 1.20662654, grad/param norm = 1.7168e-01, time/batch = 18.8125s	
16024/33650 (epoch 23.810), train_loss = 0.99530096, grad/param norm = 1.5678e-01, time/batch = 17.4751s	
16025/33650 (epoch 23.811), train_loss = 0.99348063, grad/param norm = 1.5853e-01, time/batch = 16.9596s	
16026/33650 (epoch 23.813), train_loss = 0.91591462, grad/param norm = 1.6013e-01, time/batch = 18.4758s	
16027/33650 (epoch 23.814), train_loss = 1.06023406, grad/param norm = 1.6563e-01, time/batch = 16.9730s	
16028/33650 (epoch 23.816), train_loss = 1.05149034, grad/param norm = 1.6748e-01, time/batch = 18.4725s	
16029/33650 (epoch 23.817), train_loss = 1.05559888, grad/param norm = 1.6629e-01, time/batch = 16.1311s	
16030/33650 (epoch 23.819), train_loss = 1.01239886, grad/param norm = 1.5396e-01, time/batch = 18.6356s	
16031/33650 (epoch 23.820), train_loss = 1.09331320, grad/param norm = 1.6080e-01, time/batch = 16.9643s	
16032/33650 (epoch 23.822), train_loss = 1.01247839, grad/param norm = 1.8432e-01, time/batch = 18.4826s	
16033/33650 (epoch 23.823), train_loss = 0.91069452, grad/param norm = 1.5124e-01, time/batch = 18.4806s	
16034/33650 (epoch 23.825), train_loss = 0.97192901, grad/param norm = 1.4223e-01, time/batch = 16.4792s	
16035/33650 (epoch 23.826), train_loss = 1.05103344, grad/param norm = 1.5463e-01, time/batch = 18.6501s	
16036/33650 (epoch 23.828), train_loss = 1.13740995, grad/param norm = 1.6806e-01, time/batch = 17.8236s	
16037/33650 (epoch 23.829), train_loss = 0.83124689, grad/param norm = 1.4331e-01, time/batch = 18.2209s	
16038/33650 (epoch 23.831), train_loss = 1.01433885, grad/param norm = 1.5290e-01, time/batch = 17.1439s	
16039/33650 (epoch 23.832), train_loss = 1.04351166, grad/param norm = 1.5940e-01, time/batch = 18.0678s	
16040/33650 (epoch 23.834), train_loss = 1.04850044, grad/param norm = 1.8045e-01, time/batch = 18.7253s	
16041/33650 (epoch 23.835), train_loss = 1.20899763, grad/param norm = 1.7409e-01, time/batch = 17.3763s	
16042/33650 (epoch 23.837), train_loss = 1.00253198, grad/param norm = 1.7711e-01, time/batch = 16.8057s	
16043/33650 (epoch 23.838), train_loss = 0.99934388, grad/param norm = 1.5873e-01, time/batch = 18.1511s	
16044/33650 (epoch 23.840), train_loss = 1.06994822, grad/param norm = 1.5079e-01, time/batch = 16.7255s	
16045/33650 (epoch 23.841), train_loss = 0.90985067, grad/param norm = 1.3914e-01, time/batch = 18.3937s	
16046/33650 (epoch 23.842), train_loss = 0.97121224, grad/param norm = 1.4932e-01, time/batch = 16.5543s	
16047/33650 (epoch 23.844), train_loss = 1.16268197, grad/param norm = 1.8829e-01, time/batch = 18.4771s	
16048/33650 (epoch 23.845), train_loss = 0.91128742, grad/param norm = 1.3927e-01, time/batch = 17.7316s	
16049/33650 (epoch 23.847), train_loss = 0.74862998, grad/param norm = 1.3496e-01, time/batch = 18.0618s	
16050/33650 (epoch 23.848), train_loss = 0.84316383, grad/param norm = 1.5029e-01, time/batch = 18.0608s	
16051/33650 (epoch 23.850), train_loss = 0.95021008, grad/param norm = 1.6902e-01, time/batch = 17.7135s	
16052/33650 (epoch 23.851), train_loss = 0.80033873, grad/param norm = 1.1926e-01, time/batch = 18.3957s	
16053/33650 (epoch 23.853), train_loss = 0.96842018, grad/param norm = 1.7181e-01, time/batch = 17.0511s	
16054/33650 (epoch 23.854), train_loss = 1.07499622, grad/param norm = 1.7353e-01, time/batch = 17.7166s	
16055/33650 (epoch 23.856), train_loss = 0.75606269, grad/param norm = 1.4057e-01, time/batch = 17.9882s	
16056/33650 (epoch 23.857), train_loss = 0.98443870, grad/param norm = 1.3650e-01, time/batch = 17.7375s	
16057/33650 (epoch 23.859), train_loss = 0.87054983, grad/param norm = 1.3640e-01, time/batch = 17.4680s	
16058/33650 (epoch 23.860), train_loss = 0.82536226, grad/param norm = 1.4577e-01, time/batch = 17.1563s	
16059/33650 (epoch 23.862), train_loss = 0.88934541, grad/param norm = 1.4975e-01, time/batch = 18.3025s	
16060/33650 (epoch 23.863), train_loss = 1.11013254, grad/param norm = 1.6810e-01, time/batch = 15.3757s	
16061/33650 (epoch 23.865), train_loss = 0.93764954, grad/param norm = 1.3628e-01, time/batch = 16.8084s	
16062/33650 (epoch 23.866), train_loss = 0.88123237, grad/param norm = 1.4498e-01, time/batch = 17.4066s	
16063/33650 (epoch 23.868), train_loss = 0.85707143, grad/param norm = 1.7018e-01, time/batch = 18.3093s	
16064/33650 (epoch 23.869), train_loss = 1.04826629, grad/param norm = 1.5660e-01, time/batch = 16.0451s	
16065/33650 (epoch 23.871), train_loss = 0.84465969, grad/param norm = 1.4151e-01, time/batch = 16.0413s	
16066/33650 (epoch 23.872), train_loss = 0.98711046, grad/param norm = 1.5617e-01, time/batch = 18.8096s	
16067/33650 (epoch 23.874), train_loss = 1.02508511, grad/param norm = 1.7783e-01, time/batch = 16.8981s	
16068/33650 (epoch 23.875), train_loss = 0.94330217, grad/param norm = 1.5586e-01, time/batch = 16.8088s	
16069/33650 (epoch 23.877), train_loss = 1.12572183, grad/param norm = 1.5679e-01, time/batch = 18.2329s	
16070/33650 (epoch 23.878), train_loss = 0.67307914, grad/param norm = 1.2407e-01, time/batch = 17.2169s	
16071/33650 (epoch 23.880), train_loss = 0.99614738, grad/param norm = 1.6427e-01, time/batch = 17.0558s	
16072/33650 (epoch 23.881), train_loss = 0.91105471, grad/param norm = 1.4996e-01, time/batch = 18.0629s	
16073/33650 (epoch 23.883), train_loss = 0.98445231, grad/param norm = 1.4487e-01, time/batch = 17.2176s	
16074/33650 (epoch 23.884), train_loss = 1.07395088, grad/param norm = 1.6656e-01, time/batch = 17.7402s	
16075/33650 (epoch 23.886), train_loss = 1.03219089, grad/param norm = 1.4641e-01, time/batch = 16.7160s	
16076/33650 (epoch 23.887), train_loss = 0.84299607, grad/param norm = 1.3271e-01, time/batch = 17.8099s	
16077/33650 (epoch 23.889), train_loss = 0.94605266, grad/param norm = 1.5392e-01, time/batch = 18.0641s	
16078/33650 (epoch 23.890), train_loss = 1.02109218, grad/param norm = 1.4927e-01, time/batch = 17.7290s	
16079/33650 (epoch 23.892), train_loss = 0.95947015, grad/param norm = 1.7702e-01, time/batch = 17.2191s	
16080/33650 (epoch 23.893), train_loss = 0.99460183, grad/param norm = 1.4409e-01, time/batch = 18.0704s	
16081/33650 (epoch 23.895), train_loss = 1.08842291, grad/param norm = 1.5646e-01, time/batch = 17.4808s	
16082/33650 (epoch 23.896), train_loss = 0.89957292, grad/param norm = 1.4951e-01, time/batch = 17.0563s	
16083/33650 (epoch 23.897), train_loss = 0.80252820, grad/param norm = 1.3294e-01, time/batch = 18.1540s	
16084/33650 (epoch 23.899), train_loss = 0.85369019, grad/param norm = 1.3315e-01, time/batch = 18.1436s	
16085/33650 (epoch 23.900), train_loss = 0.79272355, grad/param norm = 1.2996e-01, time/batch = 17.5610s	
16086/33650 (epoch 23.902), train_loss = 0.96948901, grad/param norm = 1.4936e-01, time/batch = 17.0518s	
16087/33650 (epoch 23.903), train_loss = 0.91812080, grad/param norm = 1.5478e-01, time/batch = 16.4694s	
16088/33650 (epoch 23.905), train_loss = 1.08858106, grad/param norm = 1.8634e-01, time/batch = 16.5669s	
16089/33650 (epoch 23.906), train_loss = 0.89975183, grad/param norm = 1.5058e-01, time/batch = 17.8101s	
16090/33650 (epoch 23.908), train_loss = 0.92768479, grad/param norm = 1.3813e-01, time/batch = 18.8184s	
16091/33650 (epoch 23.909), train_loss = 0.89651616, grad/param norm = 1.4354e-01, time/batch = 18.5594s	
16092/33650 (epoch 23.911), train_loss = 0.79487367, grad/param norm = 1.3044e-01, time/batch = 17.8666s	
16093/33650 (epoch 23.912), train_loss = 0.78103570, grad/param norm = 1.5313e-01, time/batch = 16.4668s	
16094/33650 (epoch 23.914), train_loss = 0.95514569, grad/param norm = 1.2847e-01, time/batch = 17.8224s	
16095/33650 (epoch 23.915), train_loss = 0.91461829, grad/param norm = 1.4720e-01, time/batch = 16.2047s	
16096/33650 (epoch 23.917), train_loss = 0.92075870, grad/param norm = 1.7248e-01, time/batch = 17.6442s	
16097/33650 (epoch 23.918), train_loss = 0.80368191, grad/param norm = 1.1601e-01, time/batch = 18.4780s	
16098/33650 (epoch 23.920), train_loss = 0.85321630, grad/param norm = 1.3724e-01, time/batch = 17.2251s	
16099/33650 (epoch 23.921), train_loss = 0.85689565, grad/param norm = 1.4790e-01, time/batch = 17.1397s	
16100/33650 (epoch 23.923), train_loss = 0.79047513, grad/param norm = 1.4350e-01, time/batch = 16.6351s	
16101/33650 (epoch 23.924), train_loss = 0.95462392, grad/param norm = 1.8561e-01, time/batch = 18.2229s	
16102/33650 (epoch 23.926), train_loss = 0.87955297, grad/param norm = 1.7446e-01, time/batch = 16.7974s	
16103/33650 (epoch 23.927), train_loss = 0.90909269, grad/param norm = 1.3615e-01, time/batch = 18.2303s	
16104/33650 (epoch 23.929), train_loss = 0.99398703, grad/param norm = 1.4853e-01, time/batch = 18.5563s	
16105/33650 (epoch 23.930), train_loss = 0.91144141, grad/param norm = 1.4782e-01, time/batch = 17.1262s	
16106/33650 (epoch 23.932), train_loss = 0.91536520, grad/param norm = 1.5032e-01, time/batch = 17.8918s	
16107/33650 (epoch 23.933), train_loss = 0.82894354, grad/param norm = 1.5261e-01, time/batch = 18.7236s	
16108/33650 (epoch 23.935), train_loss = 0.82817916, grad/param norm = 1.4097e-01, time/batch = 17.8112s	
16109/33650 (epoch 23.936), train_loss = 0.87988774, grad/param norm = 1.4768e-01, time/batch = 17.3865s	
16110/33650 (epoch 23.938), train_loss = 0.80745528, grad/param norm = 1.3469e-01, time/batch = 18.6506s	
16111/33650 (epoch 23.939), train_loss = 1.01061454, grad/param norm = 1.4693e-01, time/batch = 17.8943s	
16112/33650 (epoch 23.941), train_loss = 0.93248337, grad/param norm = 1.3977e-01, time/batch = 17.2261s	
16113/33650 (epoch 23.942), train_loss = 1.04579546, grad/param norm = 1.7269e-01, time/batch = 16.9082s	
16114/33650 (epoch 23.944), train_loss = 0.90779036, grad/param norm = 1.3128e-01, time/batch = 17.7532s	
16115/33650 (epoch 23.945), train_loss = 0.97279169, grad/param norm = 1.5652e-01, time/batch = 17.8875s	
16116/33650 (epoch 23.947), train_loss = 1.09321112, grad/param norm = 2.0764e-01, time/batch = 16.6213s	
16117/33650 (epoch 23.948), train_loss = 1.08893076, grad/param norm = 1.5634e-01, time/batch = 18.5553s	
16118/33650 (epoch 23.949), train_loss = 0.82740579, grad/param norm = 1.3880e-01, time/batch = 17.7064s	
16119/33650 (epoch 23.951), train_loss = 1.08161369, grad/param norm = 1.6602e-01, time/batch = 17.2192s	
16120/33650 (epoch 23.952), train_loss = 0.99646131, grad/param norm = 1.5567e-01, time/batch = 17.7310s	
16121/33650 (epoch 23.954), train_loss = 1.02310397, grad/param norm = 1.5700e-01, time/batch = 16.3162s	
16122/33650 (epoch 23.955), train_loss = 0.98103525, grad/param norm = 1.4414e-01, time/batch = 16.4529s	
16123/33650 (epoch 23.957), train_loss = 1.02476311, grad/param norm = 1.7703e-01, time/batch = 18.1541s	
16124/33650 (epoch 23.958), train_loss = 0.76077559, grad/param norm = 1.3667e-01, time/batch = 18.1487s	
16125/33650 (epoch 23.960), train_loss = 0.76440714, grad/param norm = 1.2666e-01, time/batch = 18.1491s	
16126/33650 (epoch 23.961), train_loss = 0.83700863, grad/param norm = 1.7216e-01, time/batch = 17.5474s	
16127/33650 (epoch 23.963), train_loss = 0.88167994, grad/param norm = 1.5956e-01, time/batch = 17.4808s	
16128/33650 (epoch 23.964), train_loss = 1.02428495, grad/param norm = 1.5790e-01, time/batch = 18.2345s	
16129/33650 (epoch 23.966), train_loss = 0.95410449, grad/param norm = 1.5015e-01, time/batch = 17.1433s	
16130/33650 (epoch 23.967), train_loss = 0.98000999, grad/param norm = 1.4368e-01, time/batch = 17.8988s	
16131/33650 (epoch 23.969), train_loss = 0.94097424, grad/param norm = 1.3749e-01, time/batch = 18.5621s	
16132/33650 (epoch 23.970), train_loss = 0.97810840, grad/param norm = 1.5330e-01, time/batch = 17.8893s	
16133/33650 (epoch 23.972), train_loss = 1.23617902, grad/param norm = 1.7813e-01, time/batch = 18.7113s	
16134/33650 (epoch 23.973), train_loss = 0.84905439, grad/param norm = 1.3225e-01, time/batch = 16.2953s	
16135/33650 (epoch 23.975), train_loss = 0.86052443, grad/param norm = 1.4570e-01, time/batch = 17.8193s	
16136/33650 (epoch 23.976), train_loss = 0.85469820, grad/param norm = 1.2713e-01, time/batch = 16.5618s	
16137/33650 (epoch 23.978), train_loss = 0.88923870, grad/param norm = 1.5499e-01, time/batch = 17.0732s	
16138/33650 (epoch 23.979), train_loss = 0.91880190, grad/param norm = 1.4426e-01, time/batch = 17.7382s	
16139/33650 (epoch 23.981), train_loss = 0.88735616, grad/param norm = 1.2500e-01, time/batch = 16.7396s	
16140/33650 (epoch 23.982), train_loss = 0.97861756, grad/param norm = 1.5252e-01, time/batch = 17.9104s	
16141/33650 (epoch 23.984), train_loss = 0.79227086, grad/param norm = 1.3714e-01, time/batch = 17.2454s	
16142/33650 (epoch 23.985), train_loss = 0.81953206, grad/param norm = 1.5540e-01, time/batch = 16.8042s	
16143/33650 (epoch 23.987), train_loss = 0.93360328, grad/param norm = 1.4190e-01, time/batch = 16.9614s	
16144/33650 (epoch 23.988), train_loss = 0.94477874, grad/param norm = 1.6780e-01, time/batch = 17.4067s	
16145/33650 (epoch 23.990), train_loss = 1.12055527, grad/param norm = 1.7542e-01, time/batch = 17.6593s	
16146/33650 (epoch 23.991), train_loss = 0.97458509, grad/param norm = 1.4567e-01, time/batch = 16.4924s	
16147/33650 (epoch 23.993), train_loss = 0.96017145, grad/param norm = 1.5896e-01, time/batch = 17.7258s	
16148/33650 (epoch 23.994), train_loss = 0.92567835, grad/param norm = 1.4080e-01, time/batch = 17.6581s	
16149/33650 (epoch 23.996), train_loss = 0.86761727, grad/param norm = 1.7220e-01, time/batch = 17.4865s	
16150/33650 (epoch 23.997), train_loss = 1.01317379, grad/param norm = 1.5479e-01, time/batch = 16.5514s	
16151/33650 (epoch 23.999), train_loss = 0.86635886, grad/param norm = 1.6528e-01, time/batch = 17.9865s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
16152/33650 (epoch 24.000), train_loss = 1.02992988, grad/param norm = 1.8046e-01, time/batch = 18.2238s	
16153/33650 (epoch 24.001), train_loss = 1.10684366, grad/param norm = 1.6683e-01, time/batch = 15.2992s	
16154/33650 (epoch 24.003), train_loss = 1.08297185, grad/param norm = 1.8793e-01, time/batch = 16.1270s	
16155/33650 (epoch 24.004), train_loss = 0.98739442, grad/param norm = 1.6969e-01, time/batch = 17.6522s	
16156/33650 (epoch 24.006), train_loss = 0.90147043, grad/param norm = 1.4033e-01, time/batch = 16.3931s	
16157/33650 (epoch 24.007), train_loss = 1.02531849, grad/param norm = 1.7600e-01, time/batch = 17.0474s	
16158/33650 (epoch 24.009), train_loss = 0.90653491, grad/param norm = 1.6322e-01, time/batch = 15.8023s	
16159/33650 (epoch 24.010), train_loss = 1.04995272, grad/param norm = 1.7103e-01, time/batch = 17.6559s	
16160/33650 (epoch 24.012), train_loss = 0.89468520, grad/param norm = 1.5170e-01, time/batch = 16.2330s	
16161/33650 (epoch 24.013), train_loss = 0.94210961, grad/param norm = 1.7099e-01, time/batch = 18.4899s	
16162/33650 (epoch 24.015), train_loss = 0.93310328, grad/param norm = 1.5573e-01, time/batch = 17.5805s	
16163/33650 (epoch 24.016), train_loss = 0.85173921, grad/param norm = 1.5178e-01, time/batch = 17.4038s	
16164/33650 (epoch 24.018), train_loss = 0.92153092, grad/param norm = 1.5944e-01, time/batch = 17.1575s	
16165/33650 (epoch 24.019), train_loss = 0.89622352, grad/param norm = 1.5186e-01, time/batch = 17.0698s	
16166/33650 (epoch 24.021), train_loss = 0.97517986, grad/param norm = 1.5146e-01, time/batch = 17.8205s	
16167/33650 (epoch 24.022), train_loss = 0.89213414, grad/param norm = 1.4499e-01, time/batch = 15.6340s	
16168/33650 (epoch 24.024), train_loss = 0.85937497, grad/param norm = 1.5554e-01, time/batch = 17.3147s	
16169/33650 (epoch 24.025), train_loss = 0.95207545, grad/param norm = 1.6654e-01, time/batch = 17.8179s	
16170/33650 (epoch 24.027), train_loss = 0.98349729, grad/param norm = 1.6699e-01, time/batch = 17.4638s	
16171/33650 (epoch 24.028), train_loss = 1.01644845, grad/param norm = 1.4635e-01, time/batch = 17.4019s	
16172/33650 (epoch 24.030), train_loss = 0.95242211, grad/param norm = 1.6176e-01, time/batch = 17.5798s	
16173/33650 (epoch 24.031), train_loss = 0.86540560, grad/param norm = 1.4435e-01, time/batch = 16.3901s	
16174/33650 (epoch 24.033), train_loss = 0.93137036, grad/param norm = 1.2442e-01, time/batch = 16.2407s	
16175/33650 (epoch 24.034), train_loss = 0.97303040, grad/param norm = 1.5105e-01, time/batch = 17.6592s	
16176/33650 (epoch 24.036), train_loss = 1.04967739, grad/param norm = 1.5855e-01, time/batch = 17.8334s	
16177/33650 (epoch 24.037), train_loss = 0.90546601, grad/param norm = 1.4168e-01, time/batch = 14.8891s	
16178/33650 (epoch 24.039), train_loss = 1.03358013, grad/param norm = 1.6189e-01, time/batch = 17.1361s	
16179/33650 (epoch 24.040), train_loss = 1.13251269, grad/param norm = 1.9199e-01, time/batch = 16.4894s	
16180/33650 (epoch 24.042), train_loss = 1.13784880, grad/param norm = 1.9279e-01, time/batch = 17.4901s	
16181/33650 (epoch 24.043), train_loss = 0.88774727, grad/param norm = 1.4576e-01, time/batch = 16.6591s	
16182/33650 (epoch 24.045), train_loss = 0.89202469, grad/param norm = 1.4398e-01, time/batch = 18.5702s	
16183/33650 (epoch 24.046), train_loss = 1.00044274, grad/param norm = 1.4852e-01, time/batch = 17.6540s	
16184/33650 (epoch 24.048), train_loss = 1.04603032, grad/param norm = 1.5351e-01, time/batch = 16.8832s	
16185/33650 (epoch 24.049), train_loss = 0.94471479, grad/param norm = 1.5411e-01, time/batch = 17.2912s	
16186/33650 (epoch 24.051), train_loss = 1.08557832, grad/param norm = 1.6287e-01, time/batch = 17.8199s	
16187/33650 (epoch 24.052), train_loss = 1.09054326, grad/param norm = 1.7145e-01, time/batch = 17.6580s	
16188/33650 (epoch 24.053), train_loss = 1.00908615, grad/param norm = 1.4476e-01, time/batch = 15.9709s	
16189/33650 (epoch 24.055), train_loss = 0.85655185, grad/param norm = 1.4236e-01, time/batch = 17.2242s	
16190/33650 (epoch 24.056), train_loss = 0.83636137, grad/param norm = 1.2413e-01, time/batch = 18.1438s	
16191/33650 (epoch 24.058), train_loss = 1.03600611, grad/param norm = 1.7791e-01, time/batch = 15.8960s	
16192/33650 (epoch 24.059), train_loss = 1.00563144, grad/param norm = 1.6710e-01, time/batch = 14.2433s	
16193/33650 (epoch 24.061), train_loss = 1.03454134, grad/param norm = 1.6365e-01, time/batch = 17.0683s	
16194/33650 (epoch 24.062), train_loss = 0.99585692, grad/param norm = 1.3842e-01, time/batch = 18.0692s	
16195/33650 (epoch 24.064), train_loss = 0.92896238, grad/param norm = 1.4389e-01, time/batch = 25.8750s	
16196/33650 (epoch 24.065), train_loss = 0.91611619, grad/param norm = 1.6040e-01, time/batch = 22.0152s	
16197/33650 (epoch 24.067), train_loss = 0.84235409, grad/param norm = 1.2583e-01, time/batch = 17.7345s	
16198/33650 (epoch 24.068), train_loss = 0.95190268, grad/param norm = 1.5991e-01, time/batch = 15.1740s	
16199/33650 (epoch 24.070), train_loss = 0.99723654, grad/param norm = 1.6724e-01, time/batch = 17.2394s	
16200/33650 (epoch 24.071), train_loss = 0.93566203, grad/param norm = 1.5646e-01, time/batch = 18.0503s	
16201/33650 (epoch 24.073), train_loss = 0.99894954, grad/param norm = 1.6739e-01, time/batch = 16.8963s	
16202/33650 (epoch 24.074), train_loss = 1.07559909, grad/param norm = 1.4743e-01, time/batch = 17.5658s	
16203/33650 (epoch 24.076), train_loss = 1.01499474, grad/param norm = 1.5342e-01, time/batch = 17.3216s	
16204/33650 (epoch 24.077), train_loss = 0.95810577, grad/param norm = 1.5685e-01, time/batch = 17.6430s	
16205/33650 (epoch 24.079), train_loss = 0.98164421, grad/param norm = 1.4098e-01, time/batch = 15.7844s	
16206/33650 (epoch 24.080), train_loss = 0.99127027, grad/param norm = 1.5143e-01, time/batch = 19.3085s	
16207/33650 (epoch 24.082), train_loss = 0.96361649, grad/param norm = 1.4161e-01, time/batch = 18.0544s	
16208/33650 (epoch 24.083), train_loss = 1.01168403, grad/param norm = 1.6486e-01, time/batch = 16.8844s	
16209/33650 (epoch 24.085), train_loss = 1.05178580, grad/param norm = 1.5488e-01, time/batch = 18.6430s	
16210/33650 (epoch 24.086), train_loss = 1.03596478, grad/param norm = 1.7567e-01, time/batch = 18.5569s	
16211/33650 (epoch 24.088), train_loss = 0.98071521, grad/param norm = 1.6690e-01, time/batch = 18.0528s	
16212/33650 (epoch 24.089), train_loss = 0.93543266, grad/param norm = 1.7062e-01, time/batch = 18.2279s	
16213/33650 (epoch 24.091), train_loss = 0.91607318, grad/param norm = 1.6737e-01, time/batch = 18.3830s	
16214/33650 (epoch 24.092), train_loss = 0.94919338, grad/param norm = 1.4989e-01, time/batch = 18.3376s	
16215/33650 (epoch 24.094), train_loss = 1.02539727, grad/param norm = 1.4169e-01, time/batch = 17.0452s	
16216/33650 (epoch 24.095), train_loss = 1.02029433, grad/param norm = 1.7608e-01, time/batch = 17.1425s	
16217/33650 (epoch 24.097), train_loss = 0.90905617, grad/param norm = 1.7546e-01, time/batch = 18.5674s	
16218/33650 (epoch 24.098), train_loss = 0.78552854, grad/param norm = 1.4886e-01, time/batch = 16.1386s	
16219/33650 (epoch 24.100), train_loss = 0.89965407, grad/param norm = 1.5135e-01, time/batch = 19.0519s	
16220/33650 (epoch 24.101), train_loss = 0.96008286, grad/param norm = 1.6068e-01, time/batch = 18.3933s	
16221/33650 (epoch 24.103), train_loss = 0.94458597, grad/param norm = 1.6275e-01, time/batch = 14.9745s	
16222/33650 (epoch 24.104), train_loss = 1.08081073, grad/param norm = 1.5439e-01, time/batch = 17.9927s	
16223/33650 (epoch 24.105), train_loss = 0.96408183, grad/param norm = 1.5048e-01, time/batch = 16.6357s	
16224/33650 (epoch 24.107), train_loss = 0.91102455, grad/param norm = 1.5382e-01, time/batch = 18.3717s	
16225/33650 (epoch 24.108), train_loss = 1.03298267, grad/param norm = 1.6323e-01, time/batch = 16.6262s	
16226/33650 (epoch 24.110), train_loss = 1.12843239, grad/param norm = 1.5958e-01, time/batch = 19.1338s	
16227/33650 (epoch 24.111), train_loss = 0.92206701, grad/param norm = 1.4871e-01, time/batch = 18.3128s	
16228/33650 (epoch 24.113), train_loss = 0.93323105, grad/param norm = 1.6953e-01, time/batch = 17.1495s	
16229/33650 (epoch 24.114), train_loss = 1.04340143, grad/param norm = 1.5331e-01, time/batch = 18.2247s	
16230/33650 (epoch 24.116), train_loss = 0.87207235, grad/param norm = 1.3662e-01, time/batch = 18.3126s	
16231/33650 (epoch 24.117), train_loss = 0.95380917, grad/param norm = 1.3190e-01, time/batch = 17.9034s	
16232/33650 (epoch 24.119), train_loss = 0.85650622, grad/param norm = 1.3552e-01, time/batch = 17.8149s	
16233/33650 (epoch 24.120), train_loss = 0.91886867, grad/param norm = 1.4844e-01, time/batch = 16.8933s	
16234/33650 (epoch 24.122), train_loss = 0.74842710, grad/param norm = 1.4784e-01, time/batch = 18.7117s	
16235/33650 (epoch 24.123), train_loss = 0.90633887, grad/param norm = 1.3544e-01, time/batch = 17.0442s	
16236/33650 (epoch 24.125), train_loss = 0.98017436, grad/param norm = 1.5197e-01, time/batch = 18.5509s	
16237/33650 (epoch 24.126), train_loss = 1.06452218, grad/param norm = 1.7863e-01, time/batch = 18.9778s	
16238/33650 (epoch 24.128), train_loss = 1.03356413, grad/param norm = 1.6677e-01, time/batch = 17.3932s	
16239/33650 (epoch 24.129), train_loss = 1.06920551, grad/param norm = 1.6173e-01, time/batch = 18.5557s	
16240/33650 (epoch 24.131), train_loss = 0.97386430, grad/param norm = 1.5709e-01, time/batch = 18.5608s	
16241/33650 (epoch 24.132), train_loss = 0.96636739, grad/param norm = 1.5391e-01, time/batch = 16.8669s	
16242/33650 (epoch 24.134), train_loss = 1.02780300, grad/param norm = 1.5210e-01, time/batch = 18.6539s	
16243/33650 (epoch 24.135), train_loss = 0.85431507, grad/param norm = 1.4613e-01, time/batch = 18.0553s	
16244/33650 (epoch 24.137), train_loss = 0.97596916, grad/param norm = 1.6123e-01, time/batch = 16.3010s	
16245/33650 (epoch 24.138), train_loss = 1.01726083, grad/param norm = 1.4842e-01, time/batch = 17.3084s	
16246/33650 (epoch 24.140), train_loss = 0.94205354, grad/param norm = 1.8574e-01, time/batch = 18.6448s	
16247/33650 (epoch 24.141), train_loss = 1.10335988, grad/param norm = 1.6424e-01, time/batch = 17.8132s	
16248/33650 (epoch 24.143), train_loss = 1.11374878, grad/param norm = 1.7901e-01, time/batch = 17.3877s	
16249/33650 (epoch 24.144), train_loss = 1.01148440, grad/param norm = 1.6772e-01, time/batch = 18.6487s	
16250/33650 (epoch 24.146), train_loss = 0.94189800, grad/param norm = 1.4784e-01, time/batch = 18.3128s	
16251/33650 (epoch 24.147), train_loss = 0.89994795, grad/param norm = 1.5320e-01, time/batch = 17.2942s	
16252/33650 (epoch 24.149), train_loss = 0.85969060, grad/param norm = 1.5145e-01, time/batch = 17.4722s	
16253/33650 (epoch 24.150), train_loss = 0.84204330, grad/param norm = 1.4103e-01, time/batch = 16.8051s	
16254/33650 (epoch 24.152), train_loss = 0.89413074, grad/param norm = 1.3299e-01, time/batch = 17.9760s	
16255/33650 (epoch 24.153), train_loss = 0.93757013, grad/param norm = 1.4681e-01, time/batch = 16.9711s	
16256/33650 (epoch 24.155), train_loss = 0.89183621, grad/param norm = 1.4048e-01, time/batch = 19.5634s	
16257/33650 (epoch 24.156), train_loss = 0.87267690, grad/param norm = 1.3524e-01, time/batch = 17.3923s	
16258/33650 (epoch 24.158), train_loss = 0.98695884, grad/param norm = 1.4735e-01, time/batch = 17.1365s	
16259/33650 (epoch 24.159), train_loss = 0.88410780, grad/param norm = 1.3022e-01, time/batch = 17.6462s	
16260/33650 (epoch 24.160), train_loss = 0.90199112, grad/param norm = 1.3981e-01, time/batch = 17.0605s	
16261/33650 (epoch 24.162), train_loss = 0.93310094, grad/param norm = 1.5230e-01, time/batch = 18.3972s	
16262/33650 (epoch 24.163), train_loss = 1.00113524, grad/param norm = 1.5882e-01, time/batch = 17.1997s	
16263/33650 (epoch 24.165), train_loss = 0.85380758, grad/param norm = 1.4458e-01, time/batch = 18.8967s	
16264/33650 (epoch 24.166), train_loss = 0.86394674, grad/param norm = 1.6038e-01, time/batch = 17.8245s	
16265/33650 (epoch 24.168), train_loss = 1.02560653, grad/param norm = 1.5235e-01, time/batch = 17.2125s	
16266/33650 (epoch 24.169), train_loss = 0.96755142, grad/param norm = 1.5395e-01, time/batch = 18.3163s	
16267/33650 (epoch 24.171), train_loss = 0.93909136, grad/param norm = 1.3475e-01, time/batch = 17.7321s	
16268/33650 (epoch 24.172), train_loss = 0.90298936, grad/param norm = 1.5698e-01, time/batch = 17.8167s	
16269/33650 (epoch 24.174), train_loss = 0.87384887, grad/param norm = 1.5374e-01, time/batch = 16.1375s	
16270/33650 (epoch 24.175), train_loss = 0.85575542, grad/param norm = 1.6781e-01, time/batch = 18.6498s	
16271/33650 (epoch 24.177), train_loss = 0.95113130, grad/param norm = 1.4881e-01, time/batch = 18.0565s	
16272/33650 (epoch 24.178), train_loss = 0.89446850, grad/param norm = 1.6955e-01, time/batch = 17.3113s	
16273/33650 (epoch 24.180), train_loss = 0.86322997, grad/param norm = 1.4199e-01, time/batch = 18.7264s	
16274/33650 (epoch 24.181), train_loss = 0.76250078, grad/param norm = 1.3570e-01, time/batch = 17.9811s	
16275/33650 (epoch 24.183), train_loss = 0.88719632, grad/param norm = 1.6241e-01, time/batch = 17.1519s	
16276/33650 (epoch 24.184), train_loss = 0.88043321, grad/param norm = 1.8013e-01, time/batch = 19.0530s	
16277/33650 (epoch 24.186), train_loss = 0.92773013, grad/param norm = 1.7158e-01, time/batch = 17.2482s	
16278/33650 (epoch 24.187), train_loss = 1.08545956, grad/param norm = 1.8111e-01, time/batch = 17.5588s	
16279/33650 (epoch 24.189), train_loss = 1.03953128, grad/param norm = 1.7860e-01, time/batch = 17.4057s	
16280/33650 (epoch 24.190), train_loss = 0.96116492, grad/param norm = 1.6304e-01, time/batch = 18.8887s	
16281/33650 (epoch 24.192), train_loss = 1.13727069, grad/param norm = 1.4490e-01, time/batch = 18.8913s	
16282/33650 (epoch 24.193), train_loss = 1.08377389, grad/param norm = 1.5657e-01, time/batch = 17.7225s	
16283/33650 (epoch 24.195), train_loss = 0.82825247, grad/param norm = 1.4283e-01, time/batch = 17.9857s	
16284/33650 (epoch 24.196), train_loss = 0.81501657, grad/param norm = 1.4809e-01, time/batch = 16.2981s	
16285/33650 (epoch 24.198), train_loss = 0.89796760, grad/param norm = 1.5021e-01, time/batch = 16.8037s	
16286/33650 (epoch 24.199), train_loss = 1.03744650, grad/param norm = 1.6525e-01, time/batch = 17.5579s	
16287/33650 (epoch 24.201), train_loss = 0.90441608, grad/param norm = 1.5207e-01, time/batch = 16.0463s	
16288/33650 (epoch 24.202), train_loss = 0.92660262, grad/param norm = 1.7031e-01, time/batch = 18.6495s	
16289/33650 (epoch 24.204), train_loss = 1.00268024, grad/param norm = 1.5201e-01, time/batch = 17.8941s	
16290/33650 (epoch 24.205), train_loss = 0.92651311, grad/param norm = 1.5534e-01, time/batch = 18.6471s	
16291/33650 (epoch 24.207), train_loss = 0.89935729, grad/param norm = 1.8307e-01, time/batch = 18.3080s	
16292/33650 (epoch 24.208), train_loss = 0.96362822, grad/param norm = 1.4841e-01, time/batch = 17.2922s	
16293/33650 (epoch 24.210), train_loss = 0.79352133, grad/param norm = 1.5174e-01, time/batch = 17.9777s	
16294/33650 (epoch 24.211), train_loss = 0.89161737, grad/param norm = 1.7292e-01, time/batch = 18.2252s	
16295/33650 (epoch 24.212), train_loss = 1.00477168, grad/param norm = 1.7215e-01, time/batch = 16.6227s	
16296/33650 (epoch 24.214), train_loss = 1.12056562, grad/param norm = 1.6135e-01, time/batch = 18.0568s	
16297/33650 (epoch 24.215), train_loss = 0.73872438, grad/param norm = 1.4404e-01, time/batch = 18.4015s	
16298/33650 (epoch 24.217), train_loss = 0.92781682, grad/param norm = 1.6896e-01, time/batch = 17.5741s	
16299/33650 (epoch 24.218), train_loss = 0.95474663, grad/param norm = 1.4718e-01, time/batch = 16.7316s	
16300/33650 (epoch 24.220), train_loss = 0.84054912, grad/param norm = 1.4750e-01, time/batch = 18.8080s	
16301/33650 (epoch 24.221), train_loss = 1.11366053, grad/param norm = 1.7531e-01, time/batch = 18.3206s	
16302/33650 (epoch 24.223), train_loss = 0.76529162, grad/param norm = 1.4401e-01, time/batch = 16.7268s	
16303/33650 (epoch 24.224), train_loss = 0.90920766, grad/param norm = 1.7353e-01, time/batch = 19.1433s	
16304/33650 (epoch 24.226), train_loss = 1.22352734, grad/param norm = 1.7087e-01, time/batch = 18.2217s	
16305/33650 (epoch 24.227), train_loss = 1.07185396, grad/param norm = 1.9331e-01, time/batch = 16.6385s	
16306/33650 (epoch 24.229), train_loss = 1.07152941, grad/param norm = 1.7767e-01, time/batch = 17.9734s	
16307/33650 (epoch 24.230), train_loss = 1.21560260, grad/param norm = 1.8641e-01, time/batch = 19.0658s	
16308/33650 (epoch 24.232), train_loss = 1.04835208, grad/param norm = 2.8626e-01, time/batch = 16.8863s	
16309/33650 (epoch 24.233), train_loss = 1.01240923, grad/param norm = 1.9180e-01, time/batch = 16.7960s	
16310/33650 (epoch 24.235), train_loss = 0.96195812, grad/param norm = 1.5894e-01, time/batch = 18.2304s	
16311/33650 (epoch 24.236), train_loss = 0.84791201, grad/param norm = 1.3974e-01, time/batch = 18.7358s	
16312/33650 (epoch 24.238), train_loss = 0.91549694, grad/param norm = 1.3829e-01, time/batch = 17.8020s	
16313/33650 (epoch 24.239), train_loss = 0.88018533, grad/param norm = 1.5001e-01, time/batch = 18.4809s	
16314/33650 (epoch 24.241), train_loss = 0.91999422, grad/param norm = 1.4991e-01, time/batch = 17.7322s	
16315/33650 (epoch 24.242), train_loss = 0.76557066, grad/param norm = 1.3160e-01, time/batch = 17.5502s	
16316/33650 (epoch 24.244), train_loss = 0.94360620, grad/param norm = 1.5331e-01, time/batch = 18.3945s	
16317/33650 (epoch 24.245), train_loss = 0.84222907, grad/param norm = 1.4661e-01, time/batch = 17.9972s	
16318/33650 (epoch 24.247), train_loss = 0.92759264, grad/param norm = 1.4388e-01, time/batch = 16.0439s	
16319/33650 (epoch 24.248), train_loss = 0.83022170, grad/param norm = 1.5245e-01, time/batch = 16.5433s	
16320/33650 (epoch 24.250), train_loss = 0.94015046, grad/param norm = 1.5569e-01, time/batch = 19.0534s	
16321/33650 (epoch 24.251), train_loss = 1.06144697, grad/param norm = 1.4618e-01, time/batch = 18.5618s	
16322/33650 (epoch 24.253), train_loss = 0.82309804, grad/param norm = 1.3587e-01, time/batch = 15.9569s	
16323/33650 (epoch 24.254), train_loss = 0.87818255, grad/param norm = 1.6047e-01, time/batch = 18.8058s	
16324/33650 (epoch 24.256), train_loss = 1.08403172, grad/param norm = 1.4325e-01, time/batch = 18.4862s	
16325/33650 (epoch 24.257), train_loss = 1.06970308, grad/param norm = 1.5646e-01, time/batch = 16.8926s	
16326/33650 (epoch 24.259), train_loss = 0.82000574, grad/param norm = 1.3627e-01, time/batch = 17.9792s	
16327/33650 (epoch 24.260), train_loss = 1.00643559, grad/param norm = 1.4540e-01, time/batch = 18.0727s	
16328/33650 (epoch 24.262), train_loss = 0.97743728, grad/param norm = 1.8469e-01, time/batch = 18.6460s	
16329/33650 (epoch 24.263), train_loss = 0.91386362, grad/param norm = 1.8839e-01, time/batch = 17.3753s	
16330/33650 (epoch 24.264), train_loss = 0.98436866, grad/param norm = 1.4794e-01, time/batch = 19.2409s	
16331/33650 (epoch 24.266), train_loss = 0.98599383, grad/param norm = 1.4507e-01, time/batch = 18.6349s	
16332/33650 (epoch 24.267), train_loss = 0.89417594, grad/param norm = 1.7056e-01, time/batch = 16.2158s	
16333/33650 (epoch 24.269), train_loss = 0.96785771, grad/param norm = 1.5187e-01, time/batch = 18.3077s	
16334/33650 (epoch 24.270), train_loss = 0.86457476, grad/param norm = 1.3249e-01, time/batch = 18.4014s	
16335/33650 (epoch 24.272), train_loss = 0.91000316, grad/param norm = 1.3642e-01, time/batch = 17.0626s	
16336/33650 (epoch 24.273), train_loss = 1.06898148, grad/param norm = 2.0640e-01, time/batch = 17.2184s	
16337/33650 (epoch 24.275), train_loss = 1.00428455, grad/param norm = 1.5314e-01, time/batch = 18.9804s	
16338/33650 (epoch 24.276), train_loss = 1.04516349, grad/param norm = 1.7715e-01, time/batch = 18.4886s	
16339/33650 (epoch 24.278), train_loss = 1.11395770, grad/param norm = 1.7111e-01, time/batch = 16.3662s	
16340/33650 (epoch 24.279), train_loss = 0.91478711, grad/param norm = 1.4855e-01, time/batch = 18.7975s	
16341/33650 (epoch 24.281), train_loss = 0.98515976, grad/param norm = 1.6124e-01, time/batch = 18.3919s	
16342/33650 (epoch 24.282), train_loss = 1.06402552, grad/param norm = 1.4444e-01, time/batch = 17.8002s	
16343/33650 (epoch 24.284), train_loss = 1.02761855, grad/param norm = 1.7105e-01, time/batch = 18.2236s	
16344/33650 (epoch 24.285), train_loss = 1.00798768, grad/param norm = 1.5364e-01, time/batch = 18.8821s	
16345/33650 (epoch 24.287), train_loss = 0.91829083, grad/param norm = 1.6763e-01, time/batch = 17.8047s	
16346/33650 (epoch 24.288), train_loss = 0.99907796, grad/param norm = 1.7714e-01, time/batch = 18.2251s	
16347/33650 (epoch 24.290), train_loss = 0.96078428, grad/param norm = 1.4064e-01, time/batch = 18.9004s	
16348/33650 (epoch 24.291), train_loss = 0.85616452, grad/param norm = 1.3251e-01, time/batch = 17.6539s	
16349/33650 (epoch 24.293), train_loss = 0.93843072, grad/param norm = 1.6801e-01, time/batch = 18.1537s	
16350/33650 (epoch 24.294), train_loss = 0.85904981, grad/param norm = 1.3140e-01, time/batch = 17.7075s	
16351/33650 (epoch 24.296), train_loss = 0.86667312, grad/param norm = 1.6248e-01, time/batch = 18.1536s	
16352/33650 (epoch 24.297), train_loss = 0.92356625, grad/param norm = 1.5783e-01, time/batch = 15.7016s	
16353/33650 (epoch 24.299), train_loss = 0.82670818, grad/param norm = 1.4275e-01, time/batch = 18.9803s	
16354/33650 (epoch 24.300), train_loss = 0.83336038, grad/param norm = 1.3711e-01, time/batch = 18.6474s	
16355/33650 (epoch 24.302), train_loss = 0.96574889, grad/param norm = 1.2990e-01, time/batch = 17.8176s	
16356/33650 (epoch 24.303), train_loss = 0.97527750, grad/param norm = 1.4095e-01, time/batch = 18.0576s	
16357/33650 (epoch 24.305), train_loss = 0.95830487, grad/param norm = 1.4590e-01, time/batch = 18.4884s	
16358/33650 (epoch 24.306), train_loss = 0.87808281, grad/param norm = 1.4452e-01, time/batch = 17.4748s	
16359/33650 (epoch 24.308), train_loss = 0.81911819, grad/param norm = 1.5105e-01, time/batch = 18.7025s	
16360/33650 (epoch 24.309), train_loss = 1.10466615, grad/param norm = 1.6788e-01, time/batch = 18.3221s	
16361/33650 (epoch 24.311), train_loss = 0.96598292, grad/param norm = 1.7779e-01, time/batch = 16.6483s	
16362/33650 (epoch 24.312), train_loss = 0.95986910, grad/param norm = 1.6157e-01, time/batch = 16.9712s	
16363/33650 (epoch 24.314), train_loss = 0.84174711, grad/param norm = 1.2737e-01, time/batch = 17.9769s	
16364/33650 (epoch 24.315), train_loss = 0.91829649, grad/param norm = 1.6732e-01, time/batch = 18.8941s	
16365/33650 (epoch 24.316), train_loss = 0.89656146, grad/param norm = 1.6767e-01, time/batch = 17.8095s	
16366/33650 (epoch 24.318), train_loss = 0.84327965, grad/param norm = 1.3929e-01, time/batch = 18.4000s	
16367/33650 (epoch 24.319), train_loss = 0.87827900, grad/param norm = 1.3767e-01, time/batch = 17.0604s	
16368/33650 (epoch 24.321), train_loss = 0.89727146, grad/param norm = 1.4251e-01, time/batch = 17.9702s	
16369/33650 (epoch 24.322), train_loss = 0.97524060, grad/param norm = 1.7023e-01, time/batch = 17.3822s	
16370/33650 (epoch 24.324), train_loss = 1.00551813, grad/param norm = 2.0131e-01, time/batch = 18.8999s	
16371/33650 (epoch 24.325), train_loss = 1.00854063, grad/param norm = 1.5229e-01, time/batch = 17.2935s	
16372/33650 (epoch 24.327), train_loss = 0.86769271, grad/param norm = 1.2990e-01, time/batch = 16.7288s	
16373/33650 (epoch 24.328), train_loss = 1.00421003, grad/param norm = 1.6263e-01, time/batch = 18.5717s	
16374/33650 (epoch 24.330), train_loss = 0.88202367, grad/param norm = 1.3072e-01, time/batch = 17.6494s	
16375/33650 (epoch 24.331), train_loss = 0.80222504, grad/param norm = 1.3460e-01, time/batch = 17.3159s	
16376/33650 (epoch 24.333), train_loss = 0.92458647, grad/param norm = 1.5812e-01, time/batch = 17.7355s	
16377/33650 (epoch 24.334), train_loss = 0.92832300, grad/param norm = 1.5298e-01, time/batch = 19.1476s	
16378/33650 (epoch 24.336), train_loss = 1.04334209, grad/param norm = 1.5001e-01, time/batch = 15.9847s	
16379/33650 (epoch 24.337), train_loss = 0.79285406, grad/param norm = 1.4154e-01, time/batch = 17.7972s	
16380/33650 (epoch 24.339), train_loss = 0.88895925, grad/param norm = 1.4588e-01, time/batch = 16.9761s	
16381/33650 (epoch 24.340), train_loss = 1.06151240, grad/param norm = 1.6398e-01, time/batch = 18.1459s	
16382/33650 (epoch 24.342), train_loss = 0.79034459, grad/param norm = 1.4607e-01, time/batch = 17.7292s	
16383/33650 (epoch 24.343), train_loss = 0.99428309, grad/param norm = 1.5373e-01, time/batch = 18.1527s	
16384/33650 (epoch 24.345), train_loss = 0.92352712, grad/param norm = 1.7376e-01, time/batch = 18.4786s	
16385/33650 (epoch 24.346), train_loss = 0.65674316, grad/param norm = 1.2977e-01, time/batch = 17.8082s	
16386/33650 (epoch 24.348), train_loss = 0.82649135, grad/param norm = 1.3673e-01, time/batch = 18.2953s	
16387/33650 (epoch 24.349), train_loss = 0.77738441, grad/param norm = 1.5354e-01, time/batch = 17.8153s	
16388/33650 (epoch 24.351), train_loss = 1.03041291, grad/param norm = 1.4967e-01, time/batch = 18.5625s	
16389/33650 (epoch 24.352), train_loss = 0.91438077, grad/param norm = 1.4451e-01, time/batch = 18.0472s	
16390/33650 (epoch 24.354), train_loss = 1.10043836, grad/param norm = 2.0596e-01, time/batch = 17.7321s	
16391/33650 (epoch 24.355), train_loss = 1.08490340, grad/param norm = 1.5410e-01, time/batch = 18.0420s	
16392/33650 (epoch 24.357), train_loss = 0.76568482, grad/param norm = 1.3762e-01, time/batch = 16.3941s	
16393/33650 (epoch 24.358), train_loss = 1.00917297, grad/param norm = 1.6081e-01, time/batch = 18.2294s	
16394/33650 (epoch 24.360), train_loss = 1.02745890, grad/param norm = 1.7966e-01, time/batch = 18.8161s	
16395/33650 (epoch 24.361), train_loss = 0.98385893, grad/param norm = 1.5319e-01, time/batch = 26.7005s	
16396/33650 (epoch 24.363), train_loss = 0.94588930, grad/param norm = 1.4556e-01, time/batch = 36.5154s	
16397/33650 (epoch 24.364), train_loss = 0.90829532, grad/param norm = 1.3483e-01, time/batch = 17.1103s	
16398/33650 (epoch 24.366), train_loss = 1.00100590, grad/param norm = 1.6071e-01, time/batch = 17.6518s	
16399/33650 (epoch 24.367), train_loss = 0.98053559, grad/param norm = 1.4402e-01, time/batch = 18.7242s	
16400/33650 (epoch 24.368), train_loss = 0.85348863, grad/param norm = 1.3315e-01, time/batch = 17.7288s	
16401/33650 (epoch 24.370), train_loss = 0.94448167, grad/param norm = 1.4707e-01, time/batch = 17.5225s	
16402/33650 (epoch 24.371), train_loss = 0.74333017, grad/param norm = 1.4569e-01, time/batch = 19.1474s	
16403/33650 (epoch 24.373), train_loss = 0.84321985, grad/param norm = 1.3764e-01, time/batch = 18.8903s	
16404/33650 (epoch 24.374), train_loss = 0.83837901, grad/param norm = 1.3355e-01, time/batch = 18.2890s	
16405/33650 (epoch 24.376), train_loss = 0.94654137, grad/param norm = 1.7513e-01, time/batch = 18.0768s	
16406/33650 (epoch 24.377), train_loss = 0.97947012, grad/param norm = 1.8163e-01, time/batch = 17.9798s	
16407/33650 (epoch 24.379), train_loss = 0.97556691, grad/param norm = 1.4946e-01, time/batch = 16.4286s	
16408/33650 (epoch 24.380), train_loss = 0.76118500, grad/param norm = 1.5287e-01, time/batch = 18.3927s	
16409/33650 (epoch 24.382), train_loss = 0.90489434, grad/param norm = 1.2818e-01, time/batch = 18.5646s	
16410/33650 (epoch 24.383), train_loss = 0.92940868, grad/param norm = 1.4714e-01, time/batch = 17.0543s	
16411/33650 (epoch 24.385), train_loss = 1.00857621, grad/param norm = 1.4525e-01, time/batch = 18.4792s	
16412/33650 (epoch 24.386), train_loss = 0.87923934, grad/param norm = 1.4336e-01, time/batch = 18.5680s	
16413/33650 (epoch 24.388), train_loss = 0.98899627, grad/param norm = 1.3974e-01, time/batch = 18.4691s	
16414/33650 (epoch 24.389), train_loss = 0.90667771, grad/param norm = 1.6399e-01, time/batch = 17.8871s	
16415/33650 (epoch 24.391), train_loss = 0.74386786, grad/param norm = 1.2383e-01, time/batch = 17.9739s	
16416/33650 (epoch 24.392), train_loss = 0.96101955, grad/param norm = 1.6930e-01, time/batch = 17.8707s	
16417/33650 (epoch 24.394), train_loss = 0.95092568, grad/param norm = 1.6313e-01, time/batch = 15.1364s	
16418/33650 (epoch 24.395), train_loss = 0.99355115, grad/param norm = 1.5198e-01, time/batch = 18.6178s	
16419/33650 (epoch 24.397), train_loss = 1.08108974, grad/param norm = 1.5871e-01, time/batch = 18.7205s	
16420/33650 (epoch 24.398), train_loss = 0.99488741, grad/param norm = 1.4601e-01, time/batch = 17.6346s	
16421/33650 (epoch 24.400), train_loss = 0.95077639, grad/param norm = 1.6717e-01, time/batch = 18.3859s	
16422/33650 (epoch 24.401), train_loss = 0.87367080, grad/param norm = 1.5078e-01, time/batch = 18.3938s	
16423/33650 (epoch 24.403), train_loss = 0.98778307, grad/param norm = 1.5285e-01, time/batch = 18.2208s	
16424/33650 (epoch 24.404), train_loss = 0.93777442, grad/param norm = 1.4567e-01, time/batch = 17.5471s	
16425/33650 (epoch 24.406), train_loss = 0.93649211, grad/param norm = 1.4820e-01, time/batch = 18.5572s	
16426/33650 (epoch 24.407), train_loss = 0.92297429, grad/param norm = 1.5315e-01, time/batch = 18.7965s	
16427/33650 (epoch 24.409), train_loss = 0.98733367, grad/param norm = 1.6712e-01, time/batch = 17.1370s	
16428/33650 (epoch 24.410), train_loss = 0.92615910, grad/param norm = 1.5638e-01, time/batch = 18.6359s	
16429/33650 (epoch 24.412), train_loss = 0.93837646, grad/param norm = 1.4275e-01, time/batch = 17.9613s	
16430/33650 (epoch 24.413), train_loss = 0.89608949, grad/param norm = 1.5695e-01, time/batch = 18.2988s	
16431/33650 (epoch 24.415), train_loss = 1.00307533, grad/param norm = 1.5580e-01, time/batch = 18.2179s	
16432/33650 (epoch 24.416), train_loss = 1.07725508, grad/param norm = 1.6114e-01, time/batch = 18.4787s	
16433/33650 (epoch 24.418), train_loss = 0.87467111, grad/param norm = 1.4938e-01, time/batch = 17.9729s	
16434/33650 (epoch 24.419), train_loss = 0.90402299, grad/param norm = 1.5503e-01, time/batch = 16.8732s	
16435/33650 (epoch 24.421), train_loss = 0.92020433, grad/param norm = 1.3294e-01, time/batch = 18.9695s	
16436/33650 (epoch 24.422), train_loss = 1.05508299, grad/param norm = 1.5533e-01, time/batch = 17.6438s	
16437/33650 (epoch 24.423), train_loss = 0.85440099, grad/param norm = 1.2780e-01, time/batch = 16.9524s	
16438/33650 (epoch 24.425), train_loss = 0.95185732, grad/param norm = 1.8905e-01, time/batch = 17.2887s	
16439/33650 (epoch 24.426), train_loss = 1.07820446, grad/param norm = 1.6504e-01, time/batch = 18.6330s	
16440/33650 (epoch 24.428), train_loss = 0.88585005, grad/param norm = 1.4595e-01, time/batch = 17.0561s	
16441/33650 (epoch 24.429), train_loss = 1.00170248, grad/param norm = 1.6835e-01, time/batch = 19.3917s	
16442/33650 (epoch 24.431), train_loss = 1.09125715, grad/param norm = 1.7203e-01, time/batch = 18.6469s	
16443/33650 (epoch 24.432), train_loss = 1.12484993, grad/param norm = 1.8376e-01, time/batch = 17.7072s	
16444/33650 (epoch 24.434), train_loss = 0.96457213, grad/param norm = 1.4499e-01, time/batch = 17.8896s	
16445/33650 (epoch 24.435), train_loss = 0.95392475, grad/param norm = 1.6453e-01, time/batch = 16.6463s	
16446/33650 (epoch 24.437), train_loss = 0.95948531, grad/param norm = 1.5393e-01, time/batch = 18.9720s	
16447/33650 (epoch 24.438), train_loss = 0.91506473, grad/param norm = 1.5544e-01, time/batch = 16.4682s	
16448/33650 (epoch 24.440), train_loss = 0.93973357, grad/param norm = 1.6661e-01, time/batch = 17.7188s	
16449/33650 (epoch 24.441), train_loss = 0.96038906, grad/param norm = 1.6671e-01, time/batch = 18.3203s	
16450/33650 (epoch 24.443), train_loss = 1.01341264, grad/param norm = 1.5253e-01, time/batch = 17.5600s	
16451/33650 (epoch 24.444), train_loss = 0.95187442, grad/param norm = 1.7345e-01, time/batch = 18.0448s	
16452/33650 (epoch 24.446), train_loss = 0.99444811, grad/param norm = 1.9695e-01, time/batch = 18.2432s	
16453/33650 (epoch 24.447), train_loss = 1.06330524, grad/param norm = 1.6990e-01, time/batch = 17.6449s	
16454/33650 (epoch 24.449), train_loss = 1.09619582, grad/param norm = 2.0976e-01, time/batch = 17.3986s	
16455/33650 (epoch 24.450), train_loss = 1.11944203, grad/param norm = 1.6850e-01, time/batch = 18.5682s	
16456/33650 (epoch 24.452), train_loss = 1.12745718, grad/param norm = 1.9717e-01, time/batch = 18.8202s	
16457/33650 (epoch 24.453), train_loss = 1.10328266, grad/param norm = 1.8908e-01, time/batch = 17.5139s	
16458/33650 (epoch 24.455), train_loss = 0.93281263, grad/param norm = 1.4167e-01, time/batch = 14.8659s	
16459/33650 (epoch 24.456), train_loss = 0.93679912, grad/param norm = 1.4509e-01, time/batch = 14.6244s	
16460/33650 (epoch 24.458), train_loss = 0.94264407, grad/param norm = 1.6747e-01, time/batch = 15.7113s	
16461/33650 (epoch 24.459), train_loss = 0.99624710, grad/param norm = 1.7548e-01, time/batch = 15.5919s	
16462/33650 (epoch 24.461), train_loss = 1.07966138, grad/param norm = 1.6481e-01, time/batch = 15.3747s	
16463/33650 (epoch 24.462), train_loss = 1.07052340, grad/param norm = 1.7153e-01, time/batch = 17.5581s	
16464/33650 (epoch 24.464), train_loss = 0.92325063, grad/param norm = 1.7967e-01, time/batch = 18.2175s	
16465/33650 (epoch 24.465), train_loss = 0.96888768, grad/param norm = 1.5607e-01, time/batch = 18.3049s	
16466/33650 (epoch 24.467), train_loss = 0.99868404, grad/param norm = 1.4810e-01, time/batch = 18.4010s	
16467/33650 (epoch 24.468), train_loss = 1.10016525, grad/param norm = 1.6274e-01, time/batch = 17.6527s	
16468/33650 (epoch 24.470), train_loss = 1.18279536, grad/param norm = 1.8403e-01, time/batch = 16.7164s	
16469/33650 (epoch 24.471), train_loss = 0.97172854, grad/param norm = 1.5391e-01, time/batch = 16.8743s	
16470/33650 (epoch 24.473), train_loss = 0.95037470, grad/param norm = 1.5020e-01, time/batch = 16.4823s	
16471/33650 (epoch 24.474), train_loss = 1.07550985, grad/param norm = 1.6688e-01, time/batch = 17.0679s	
16472/33650 (epoch 24.475), train_loss = 1.02859806, grad/param norm = 1.6212e-01, time/batch = 18.9761s	
16473/33650 (epoch 24.477), train_loss = 1.08214790, grad/param norm = 1.6579e-01, time/batch = 17.8985s	
16474/33650 (epoch 24.478), train_loss = 1.05810439, grad/param norm = 1.7770e-01, time/batch = 17.8881s	
16475/33650 (epoch 24.480), train_loss = 1.04931750, grad/param norm = 1.7519e-01, time/batch = 17.9813s	
16476/33650 (epoch 24.481), train_loss = 1.10785453, grad/param norm = 1.6491e-01, time/batch = 18.9709s	
16477/33650 (epoch 24.483), train_loss = 0.81857803, grad/param norm = 1.6556e-01, time/batch = 18.9708s	
16478/33650 (epoch 24.484), train_loss = 0.96090323, grad/param norm = 1.5846e-01, time/batch = 17.0453s	
16479/33650 (epoch 24.486), train_loss = 1.11939748, grad/param norm = 1.7652e-01, time/batch = 18.2342s	
16480/33650 (epoch 24.487), train_loss = 1.09217953, grad/param norm = 1.6438e-01, time/batch = 18.4675s	
16481/33650 (epoch 24.489), train_loss = 1.11135449, grad/param norm = 1.5653e-01, time/batch = 16.1293s	
16482/33650 (epoch 24.490), train_loss = 0.87647211, grad/param norm = 1.5666e-01, time/batch = 19.2931s	
16483/33650 (epoch 24.492), train_loss = 1.02644874, grad/param norm = 1.7924e-01, time/batch = 18.9705s	
16484/33650 (epoch 24.493), train_loss = 0.81760456, grad/param norm = 1.3249e-01, time/batch = 17.3077s	
16485/33650 (epoch 24.495), train_loss = 0.98794056, grad/param norm = 1.8683e-01, time/batch = 17.7232s	
16486/33650 (epoch 24.496), train_loss = 1.02347776, grad/param norm = 1.5849e-01, time/batch = 18.0524s	
16487/33650 (epoch 24.498), train_loss = 0.88136699, grad/param norm = 1.4818e-01, time/batch = 18.7300s	
16488/33650 (epoch 24.499), train_loss = 0.97778037, grad/param norm = 1.3345e-01, time/batch = 17.8119s	
16489/33650 (epoch 24.501), train_loss = 0.93484440, grad/param norm = 1.2861e-01, time/batch = 19.1437s	
16490/33650 (epoch 24.502), train_loss = 0.98378345, grad/param norm = 1.5887e-01, time/batch = 18.3995s	
16491/33650 (epoch 24.504), train_loss = 1.05123680, grad/param norm = 1.7129e-01, time/batch = 17.2040s	
16492/33650 (epoch 24.505), train_loss = 0.91891305, grad/param norm = 1.6198e-01, time/batch = 18.3143s	
16493/33650 (epoch 24.507), train_loss = 1.06843903, grad/param norm = 1.4967e-01, time/batch = 18.6370s	
16494/33650 (epoch 24.508), train_loss = 0.94046419, grad/param norm = 1.4248e-01, time/batch = 17.2959s	
16495/33650 (epoch 24.510), train_loss = 0.97273224, grad/param norm = 1.4251e-01, time/batch = 17.8208s	
16496/33650 (epoch 24.511), train_loss = 1.16608303, grad/param norm = 1.8462e-01, time/batch = 16.5456s	
16497/33650 (epoch 24.513), train_loss = 1.01767695, grad/param norm = 1.5512e-01, time/batch = 18.7245s	
16498/33650 (epoch 24.514), train_loss = 1.05965457, grad/param norm = 1.9333e-01, time/batch = 17.2038s	
16499/33650 (epoch 24.516), train_loss = 0.98679264, grad/param norm = 1.7060e-01, time/batch = 18.6524s	
16500/33650 (epoch 24.517), train_loss = 0.97844121, grad/param norm = 1.6559e-01, time/batch = 18.2314s	
16501/33650 (epoch 24.519), train_loss = 1.02487937, grad/param norm = 1.6689e-01, time/batch = 16.2867s	
16502/33650 (epoch 24.520), train_loss = 0.84087926, grad/param norm = 1.3216e-01, time/batch = 17.8980s	
16503/33650 (epoch 24.522), train_loss = 0.95357339, grad/param norm = 1.5875e-01, time/batch = 16.9795s	
16504/33650 (epoch 24.523), train_loss = 0.91716612, grad/param norm = 1.4947e-01, time/batch = 16.8026s	
16505/33650 (epoch 24.525), train_loss = 0.76909599, grad/param norm = 1.2682e-01, time/batch = 17.7205s	
16506/33650 (epoch 24.526), train_loss = 1.05493792, grad/param norm = 1.4815e-01, time/batch = 18.3147s	
16507/33650 (epoch 24.527), train_loss = 0.91752631, grad/param norm = 1.4487e-01, time/batch = 17.6348s	
16508/33650 (epoch 24.529), train_loss = 0.95858412, grad/param norm = 1.3915e-01, time/batch = 16.9523s	
16509/33650 (epoch 24.530), train_loss = 0.91422982, grad/param norm = 1.5856e-01, time/batch = 18.3124s	
16510/33650 (epoch 24.532), train_loss = 1.05416437, grad/param norm = 1.9479e-01, time/batch = 18.0589s	
16511/33650 (epoch 24.533), train_loss = 0.96198863, grad/param norm = 1.5423e-01, time/batch = 16.7033s	
16512/33650 (epoch 24.535), train_loss = 1.06116036, grad/param norm = 1.6141e-01, time/batch = 18.7257s	
16513/33650 (epoch 24.536), train_loss = 0.98682660, grad/param norm = 1.6733e-01, time/batch = 18.6448s	
16514/33650 (epoch 24.538), train_loss = 1.03626247, grad/param norm = 1.9166e-01, time/batch = 17.7226s	
16515/33650 (epoch 24.539), train_loss = 0.79407015, grad/param norm = 1.4499e-01, time/batch = 18.6497s	
16516/33650 (epoch 24.541), train_loss = 1.07739970, grad/param norm = 1.7999e-01, time/batch = 17.3194s	
16517/33650 (epoch 24.542), train_loss = 0.98312539, grad/param norm = 2.0801e-01, time/batch = 17.6210s	
16518/33650 (epoch 24.544), train_loss = 1.13309455, grad/param norm = 1.9176e-01, time/batch = 16.1198s	
16519/33650 (epoch 24.545), train_loss = 0.84279825, grad/param norm = 1.4763e-01, time/batch = 18.6332s	
16520/33650 (epoch 24.547), train_loss = 1.01545334, grad/param norm = 1.6471e-01, time/batch = 18.6420s	
16521/33650 (epoch 24.548), train_loss = 1.14264649, grad/param norm = 1.6692e-01, time/batch = 17.5522s	
16522/33650 (epoch 24.550), train_loss = 1.00308570, grad/param norm = 1.7302e-01, time/batch = 18.7931s	
16523/33650 (epoch 24.551), train_loss = 0.99747756, grad/param norm = 1.6653e-01, time/batch = 18.7262s	
16524/33650 (epoch 24.553), train_loss = 0.85792983, grad/param norm = 1.6550e-01, time/batch = 17.3843s	
16525/33650 (epoch 24.554), train_loss = 1.13201829, grad/param norm = 1.7242e-01, time/batch = 17.7304s	
16526/33650 (epoch 24.556), train_loss = 1.05509063, grad/param norm = 1.8176e-01, time/batch = 18.3123s	
16527/33650 (epoch 24.557), train_loss = 1.05985600, grad/param norm = 1.8541e-01, time/batch = 18.0665s	
16528/33650 (epoch 24.559), train_loss = 1.23143149, grad/param norm = 2.1509e-01, time/batch = 10.6823s	
16529/33650 (epoch 24.560), train_loss = 1.17509389, grad/param norm = 1.7417e-01, time/batch = 0.6482s	
16530/33650 (epoch 24.562), train_loss = 1.09676678, grad/param norm = 1.4581e-01, time/batch = 0.6442s	
16531/33650 (epoch 24.563), train_loss = 1.01771464, grad/param norm = 1.7196e-01, time/batch = 0.6482s	
16532/33650 (epoch 24.565), train_loss = 0.97795792, grad/param norm = 1.5689e-01, time/batch = 0.6528s	
16533/33650 (epoch 24.566), train_loss = 0.95389727, grad/param norm = 1.5625e-01, time/batch = 0.6450s	
16534/33650 (epoch 24.568), train_loss = 1.01925055, grad/param norm = 2.0301e-01, time/batch = 0.6442s	
16535/33650 (epoch 24.569), train_loss = 0.91403798, grad/param norm = 1.3782e-01, time/batch = 0.6460s	
16536/33650 (epoch 24.571), train_loss = 1.09316935, grad/param norm = 1.7033e-01, time/batch = 0.8921s	
16537/33650 (epoch 24.572), train_loss = 1.05290267, grad/param norm = 1.5781e-01, time/batch = 0.9838s	
16538/33650 (epoch 24.574), train_loss = 0.92078279, grad/param norm = 1.8798e-01, time/batch = 0.9479s	
16539/33650 (epoch 24.575), train_loss = 0.98246182, grad/param norm = 1.5966e-01, time/batch = 0.9508s	
16540/33650 (epoch 24.577), train_loss = 0.95039966, grad/param norm = 1.5881e-01, time/batch = 0.9815s	
16541/33650 (epoch 24.578), train_loss = 1.06823171, grad/param norm = 1.6972e-01, time/batch = 1.4838s	
16542/33650 (epoch 24.579), train_loss = 1.02439261, grad/param norm = 1.6028e-01, time/batch = 1.9019s	
16543/33650 (epoch 24.581), train_loss = 1.11301211, grad/param norm = 1.5791e-01, time/batch = 1.8465s	
16544/33650 (epoch 24.582), train_loss = 1.02546620, grad/param norm = 1.3731e-01, time/batch = 17.9260s	
16545/33650 (epoch 24.584), train_loss = 1.01894781, grad/param norm = 1.5085e-01, time/batch = 18.4906s	
16546/33650 (epoch 24.585), train_loss = 1.04358100, grad/param norm = 1.8084e-01, time/batch = 17.5546s	
16547/33650 (epoch 24.587), train_loss = 0.90714610, grad/param norm = 1.6444e-01, time/batch = 18.8071s	
16548/33650 (epoch 24.588), train_loss = 0.93310500, grad/param norm = 1.8726e-01, time/batch = 18.3085s	
16549/33650 (epoch 24.590), train_loss = 0.92122470, grad/param norm = 1.4089e-01, time/batch = 17.1417s	
16550/33650 (epoch 24.591), train_loss = 0.89143943, grad/param norm = 1.6026e-01, time/batch = 16.4633s	
16551/33650 (epoch 24.593), train_loss = 0.88204784, grad/param norm = 1.4135e-01, time/batch = 16.9532s	
16552/33650 (epoch 24.594), train_loss = 0.88258480, grad/param norm = 1.5672e-01, time/batch = 18.0591s	
16553/33650 (epoch 24.596), train_loss = 0.95020440, grad/param norm = 1.4355e-01, time/batch = 17.9052s	
16554/33650 (epoch 24.597), train_loss = 0.83109899, grad/param norm = 1.3235e-01, time/batch = 17.2918s	
16555/33650 (epoch 24.599), train_loss = 0.95663241, grad/param norm = 1.5683e-01, time/batch = 17.5668s	
16556/33650 (epoch 24.600), train_loss = 0.88741402, grad/param norm = 1.4972e-01, time/batch = 18.2265s	
16557/33650 (epoch 24.602), train_loss = 1.01810368, grad/param norm = 1.5411e-01, time/batch = 19.1432s	
16558/33650 (epoch 24.603), train_loss = 0.91504469, grad/param norm = 1.5224e-01, time/batch = 17.6478s	
16559/33650 (epoch 24.605), train_loss = 1.02367187, grad/param norm = 1.6168e-01, time/batch = 15.8704s	
16560/33650 (epoch 24.606), train_loss = 1.00357246, grad/param norm = 1.7923e-01, time/batch = 18.3079s	
16561/33650 (epoch 24.608), train_loss = 0.88623156, grad/param norm = 1.6884e-01, time/batch = 18.8222s	
16562/33650 (epoch 24.609), train_loss = 0.96337737, grad/param norm = 1.5359e-01, time/batch = 16.8784s	
16563/33650 (epoch 24.611), train_loss = 0.86819336, grad/param norm = 1.5153e-01, time/batch = 18.4015s	
16564/33650 (epoch 24.612), train_loss = 0.97938898, grad/param norm = 1.9259e-01, time/batch = 19.0630s	
16565/33650 (epoch 24.614), train_loss = 1.06969679, grad/param norm = 1.7123e-01, time/batch = 18.3999s	
16566/33650 (epoch 24.615), train_loss = 0.96521391, grad/param norm = 1.3464e-01, time/batch = 17.1285s	
16567/33650 (epoch 24.617), train_loss = 0.87301624, grad/param norm = 1.3748e-01, time/batch = 19.3919s	
16568/33650 (epoch 24.618), train_loss = 0.94488334, grad/param norm = 1.4265e-01, time/batch = 18.2351s	
16569/33650 (epoch 24.620), train_loss = 0.95129957, grad/param norm = 1.5645e-01, time/batch = 17.0562s	
16570/33650 (epoch 24.621), train_loss = 0.91349730, grad/param norm = 1.5076e-01, time/batch = 16.6228s	
16571/33650 (epoch 24.623), train_loss = 0.94482355, grad/param norm = 1.5021e-01, time/batch = 19.1290s	
16572/33650 (epoch 24.624), train_loss = 0.77338277, grad/param norm = 1.5197e-01, time/batch = 17.7135s	
16573/33650 (epoch 24.626), train_loss = 0.79384404, grad/param norm = 1.4301e-01, time/batch = 17.5601s	
16574/33650 (epoch 24.627), train_loss = 0.86585088, grad/param norm = 1.3883e-01, time/batch = 19.5617s	
16575/33650 (epoch 24.629), train_loss = 0.90604431, grad/param norm = 1.3916e-01, time/batch = 16.9761s	
16576/33650 (epoch 24.630), train_loss = 1.05369289, grad/param norm = 1.6639e-01, time/batch = 15.8802s	
16577/33650 (epoch 24.632), train_loss = 1.07613230, grad/param norm = 1.5915e-01, time/batch = 18.4751s	
16578/33650 (epoch 24.633), train_loss = 1.01609804, grad/param norm = 1.4672e-01, time/batch = 19.1374s	
16579/33650 (epoch 24.634), train_loss = 0.84667524, grad/param norm = 1.3925e-01, time/batch = 16.4496s	
16580/33650 (epoch 24.636), train_loss = 0.74392103, grad/param norm = 1.1385e-01, time/batch = 18.1470s	
16581/33650 (epoch 24.637), train_loss = 0.88458646, grad/param norm = 1.3934e-01, time/batch = 18.3130s	
16582/33650 (epoch 24.639), train_loss = 0.89019369, grad/param norm = 1.4004e-01, time/batch = 16.8940s	
16583/33650 (epoch 24.640), train_loss = 0.97357946, grad/param norm = 1.4799e-01, time/batch = 17.3080s	
16584/33650 (epoch 24.642), train_loss = 1.02988205, grad/param norm = 1.6782e-01, time/batch = 18.0699s	
16585/33650 (epoch 24.643), train_loss = 0.97082061, grad/param norm = 1.5255e-01, time/batch = 16.0654s	
16586/33650 (epoch 24.645), train_loss = 0.98480233, grad/param norm = 1.5639e-01, time/batch = 16.6428s	
16587/33650 (epoch 24.646), train_loss = 0.83174615, grad/param norm = 1.3250e-01, time/batch = 19.1432s	
16588/33650 (epoch 24.648), train_loss = 0.99717779, grad/param norm = 1.6099e-01, time/batch = 17.4883s	
16589/33650 (epoch 24.649), train_loss = 0.91335467, grad/param norm = 2.3258e-01, time/batch = 17.3874s	
16590/33650 (epoch 24.651), train_loss = 1.05492510, grad/param norm = 1.7448e-01, time/batch = 16.1508s	
16591/33650 (epoch 24.652), train_loss = 0.71194178, grad/param norm = 1.2454e-01, time/batch = 17.2398s	
16592/33650 (epoch 24.654), train_loss = 0.87800148, grad/param norm = 1.4652e-01, time/batch = 17.1422s	
16593/33650 (epoch 24.655), train_loss = 0.83405105, grad/param norm = 1.3324e-01, time/batch = 16.3104s	
16594/33650 (epoch 24.657), train_loss = 0.93080753, grad/param norm = 1.9354e-01, time/batch = 18.9866s	
16595/33650 (epoch 24.658), train_loss = 0.77954513, grad/param norm = 1.4775e-01, time/batch = 18.3218s	
16596/33650 (epoch 24.660), train_loss = 0.78733766, grad/param norm = 1.4601e-01, time/batch = 17.5583s	
16597/33650 (epoch 24.661), train_loss = 0.86520078, grad/param norm = 1.4673e-01, time/batch = 18.5694s	
16598/33650 (epoch 24.663), train_loss = 0.81889143, grad/param norm = 1.5287e-01, time/batch = 18.1475s	
16599/33650 (epoch 24.664), train_loss = 0.89926796, grad/param norm = 1.6195e-01, time/batch = 15.5445s	
16600/33650 (epoch 24.666), train_loss = 0.91408290, grad/param norm = 1.2950e-01, time/batch = 16.9649s	
16601/33650 (epoch 24.667), train_loss = 0.81743659, grad/param norm = 1.2950e-01, time/batch = 18.4090s	
16602/33650 (epoch 24.669), train_loss = 0.83263237, grad/param norm = 1.4468e-01, time/batch = 18.6501s	
16603/33650 (epoch 24.670), train_loss = 0.77082836, grad/param norm = 1.3595e-01, time/batch = 16.2321s	
16604/33650 (epoch 24.672), train_loss = 0.81386750, grad/param norm = 1.4630e-01, time/batch = 18.9803s	
16605/33650 (epoch 24.673), train_loss = 0.77337023, grad/param norm = 1.4394e-01, time/batch = 18.8923s	
16606/33650 (epoch 24.675), train_loss = 0.74775356, grad/param norm = 1.4192e-01, time/batch = 17.4756s	
16607/33650 (epoch 24.676), train_loss = 0.92494510, grad/param norm = 1.4259e-01, time/batch = 17.9868s	
16608/33650 (epoch 24.678), train_loss = 0.88845712, grad/param norm = 1.4331e-01, time/batch = 19.2373s	
16609/33650 (epoch 24.679), train_loss = 0.88804868, grad/param norm = 1.7272e-01, time/batch = 18.2221s	
16610/33650 (epoch 24.681), train_loss = 0.90081635, grad/param norm = 1.3275e-01, time/batch = 31.5878s	
16611/33650 (epoch 24.682), train_loss = 0.82777373, grad/param norm = 1.5227e-01, time/batch = 18.7167s	
16612/33650 (epoch 24.684), train_loss = 0.79536829, grad/param norm = 1.3589e-01, time/batch = 17.3026s	
16613/33650 (epoch 24.685), train_loss = 0.98002144, grad/param norm = 1.6287e-01, time/batch = 17.5506s	
16614/33650 (epoch 24.686), train_loss = 0.91559272, grad/param norm = 1.3351e-01, time/batch = 18.5748s	
16615/33650 (epoch 24.688), train_loss = 1.00434302, grad/param norm = 1.5957e-01, time/batch = 17.7233s	
16616/33650 (epoch 24.689), train_loss = 0.85346901, grad/param norm = 1.5120e-01, time/batch = 16.3064s	
16617/33650 (epoch 24.691), train_loss = 1.03776859, grad/param norm = 1.6172e-01, time/batch = 17.9703s	
16618/33650 (epoch 24.692), train_loss = 1.03846871, grad/param norm = 1.5255e-01, time/batch = 18.4881s	
16619/33650 (epoch 24.694), train_loss = 0.96694603, grad/param norm = 1.7895e-01, time/batch = 17.1455s	
16620/33650 (epoch 24.695), train_loss = 0.68194472, grad/param norm = 1.3923e-01, time/batch = 17.7348s	
16621/33650 (epoch 24.697), train_loss = 0.89463703, grad/param norm = 1.4954e-01, time/batch = 16.3146s	
16622/33650 (epoch 24.698), train_loss = 1.05721665, grad/param norm = 1.7026e-01, time/batch = 16.5588s	
16623/33650 (epoch 24.700), train_loss = 0.90896082, grad/param norm = 1.4086e-01, time/batch = 18.7276s	
16624/33650 (epoch 24.701), train_loss = 0.94130463, grad/param norm = 1.4700e-01, time/batch = 18.4057s	
16625/33650 (epoch 24.703), train_loss = 1.11635952, grad/param norm = 1.5209e-01, time/batch = 18.5481s	
16626/33650 (epoch 24.704), train_loss = 0.90208459, grad/param norm = 1.3571e-01, time/batch = 18.2217s	
16627/33650 (epoch 24.706), train_loss = 0.88047890, grad/param norm = 1.3833e-01, time/batch = 17.9042s	
16628/33650 (epoch 24.707), train_loss = 1.01374218, grad/param norm = 1.4155e-01, time/batch = 17.1332s	
16629/33650 (epoch 24.709), train_loss = 0.91286527, grad/param norm = 1.4752e-01, time/batch = 16.7249s	
16630/33650 (epoch 24.710), train_loss = 1.09807877, grad/param norm = 1.6523e-01, time/batch = 18.6443s	
16631/33650 (epoch 24.712), train_loss = 0.83921366, grad/param norm = 1.4826e-01, time/batch = 18.3974s	
16632/33650 (epoch 24.713), train_loss = 0.83305688, grad/param norm = 1.6392e-01, time/batch = 16.4762s	
16633/33650 (epoch 24.715), train_loss = 0.99748187, grad/param norm = 1.6469e-01, time/batch = 17.7965s	
16634/33650 (epoch 24.716), train_loss = 0.88231235, grad/param norm = 1.5525e-01, time/batch = 18.5551s	
16635/33650 (epoch 24.718), train_loss = 0.88003665, grad/param norm = 1.6250e-01, time/batch = 18.2209s	
16636/33650 (epoch 24.719), train_loss = 1.03810419, grad/param norm = 1.7211e-01, time/batch = 18.0649s	
16637/33650 (epoch 24.721), train_loss = 1.13197989, grad/param norm = 1.7700e-01, time/batch = 18.2086s	
16638/33650 (epoch 24.722), train_loss = 1.00825812, grad/param norm = 1.7893e-01, time/batch = 15.8866s	
16639/33650 (epoch 24.724), train_loss = 1.05737924, grad/param norm = 1.6024e-01, time/batch = 16.0764s	
16640/33650 (epoch 24.725), train_loss = 1.01301487, grad/param norm = 1.5789e-01, time/batch = 17.6463s	
16641/33650 (epoch 24.727), train_loss = 0.88113807, grad/param norm = 1.6955e-01, time/batch = 17.3045s	
16642/33650 (epoch 24.728), train_loss = 0.89997125, grad/param norm = 1.4499e-01, time/batch = 18.0424s	
16643/33650 (epoch 24.730), train_loss = 0.98910947, grad/param norm = 1.5638e-01, time/batch = 17.7173s	
16644/33650 (epoch 24.731), train_loss = 1.06909139, grad/param norm = 1.6521e-01, time/batch = 18.4730s	
16645/33650 (epoch 24.733), train_loss = 0.93473995, grad/param norm = 1.5294e-01, time/batch = 18.9736s	
16646/33650 (epoch 24.734), train_loss = 1.07376361, grad/param norm = 1.8752e-01, time/batch = 17.4740s	
16647/33650 (epoch 24.736), train_loss = 0.93146286, grad/param norm = 1.6273e-01, time/batch = 18.7905s	
16648/33650 (epoch 24.737), train_loss = 0.99136799, grad/param norm = 1.6530e-01, time/batch = 17.4608s	
16649/33650 (epoch 24.738), train_loss = 0.84716589, grad/param norm = 1.3630e-01, time/batch = 17.1346s	
16650/33650 (epoch 24.740), train_loss = 0.78731719, grad/param norm = 1.3695e-01, time/batch = 18.2191s	
16651/33650 (epoch 24.741), train_loss = 0.87099396, grad/param norm = 1.5677e-01, time/batch = 18.7239s	
16652/33650 (epoch 24.743), train_loss = 0.94368351, grad/param norm = 1.5844e-01, time/batch = 18.1411s	
16653/33650 (epoch 24.744), train_loss = 1.00373422, grad/param norm = 1.3438e-01, time/batch = 16.7221s	
16654/33650 (epoch 24.746), train_loss = 0.90206930, grad/param norm = 1.3985e-01, time/batch = 18.6454s	
16655/33650 (epoch 24.747), train_loss = 1.03602583, grad/param norm = 1.5479e-01, time/batch = 17.9891s	
16656/33650 (epoch 24.749), train_loss = 0.79488486, grad/param norm = 1.4851e-01, time/batch = 17.3073s	
16657/33650 (epoch 24.750), train_loss = 1.09109486, grad/param norm = 1.6459e-01, time/batch = 18.4011s	
16658/33650 (epoch 24.752), train_loss = 1.02247433, grad/param norm = 1.4847e-01, time/batch = 18.5696s	
16659/33650 (epoch 24.753), train_loss = 1.12716859, grad/param norm = 1.7120e-01, time/batch = 16.7979s	
16660/33650 (epoch 24.755), train_loss = 0.89571380, grad/param norm = 1.3693e-01, time/batch = 17.6284s	
16661/33650 (epoch 24.756), train_loss = 1.01263170, grad/param norm = 1.6225e-01, time/batch = 18.3979s	
16662/33650 (epoch 24.758), train_loss = 1.01271599, grad/param norm = 1.5398e-01, time/batch = 18.0511s	
16663/33650 (epoch 24.759), train_loss = 1.06011184, grad/param norm = 1.7251e-01, time/batch = 17.8985s	
16664/33650 (epoch 24.761), train_loss = 0.97744071, grad/param norm = 1.5552e-01, time/batch = 19.0694s	
16665/33650 (epoch 24.762), train_loss = 0.94872698, grad/param norm = 1.5640e-01, time/batch = 18.7260s	
16666/33650 (epoch 24.764), train_loss = 1.00815542, grad/param norm = 1.7339e-01, time/batch = 17.3833s	
16667/33650 (epoch 24.765), train_loss = 0.93871414, grad/param norm = 1.5960e-01, time/batch = 17.5654s	
16668/33650 (epoch 24.767), train_loss = 0.93309958, grad/param norm = 1.4313e-01, time/batch = 17.9715s	
16669/33650 (epoch 24.768), train_loss = 0.82447933, grad/param norm = 1.4140e-01, time/batch = 17.3078s	
16670/33650 (epoch 24.770), train_loss = 0.97784221, grad/param norm = 1.6001e-01, time/batch = 18.7199s	
16671/33650 (epoch 24.771), train_loss = 0.97933615, grad/param norm = 1.5182e-01, time/batch = 16.9611s	
16672/33650 (epoch 24.773), train_loss = 1.06035381, grad/param norm = 1.7791e-01, time/batch = 16.7125s	
16673/33650 (epoch 24.774), train_loss = 0.98621131, grad/param norm = 1.6925e-01, time/batch = 18.4709s	
16674/33650 (epoch 24.776), train_loss = 1.04239284, grad/param norm = 1.6718e-01, time/batch = 19.1460s	
16675/33650 (epoch 24.777), train_loss = 0.86996529, grad/param norm = 1.4724e-01, time/batch = 17.9944s	
16676/33650 (epoch 24.779), train_loss = 0.90082971, grad/param norm = 1.3699e-01, time/batch = 18.1249s	
16677/33650 (epoch 24.780), train_loss = 0.83795550, grad/param norm = 1.3463e-01, time/batch = 18.6505s	
16678/33650 (epoch 24.782), train_loss = 0.88505335, grad/param norm = 1.5330e-01, time/batch = 18.3090s	
16679/33650 (epoch 24.783), train_loss = 0.86344385, grad/param norm = 1.3714e-01, time/batch = 16.7288s	
16680/33650 (epoch 24.785), train_loss = 1.12606823, grad/param norm = 1.5047e-01, time/batch = 18.4874s	
16681/33650 (epoch 24.786), train_loss = 1.01631351, grad/param norm = 1.4758e-01, time/batch = 16.6084s	
16682/33650 (epoch 24.788), train_loss = 0.99232686, grad/param norm = 1.4677e-01, time/batch = 17.1447s	
16683/33650 (epoch 24.789), train_loss = 1.03996242, grad/param norm = 1.8847e-01, time/batch = 17.3943s	
16684/33650 (epoch 24.790), train_loss = 0.95535093, grad/param norm = 1.5967e-01, time/batch = 19.2322s	
16685/33650 (epoch 24.792), train_loss = 1.05795801, grad/param norm = 1.9680e-01, time/batch = 18.3918s	
16686/33650 (epoch 24.793), train_loss = 1.02345972, grad/param norm = 2.2463e-01, time/batch = 17.0524s	
16687/33650 (epoch 24.795), train_loss = 1.07860897, grad/param norm = 1.6383e-01, time/batch = 18.7343s	
16688/33650 (epoch 24.796), train_loss = 0.92577485, grad/param norm = 1.5857e-01, time/batch = 17.7258s	
16689/33650 (epoch 24.798), train_loss = 0.91863370, grad/param norm = 1.5685e-01, time/batch = 18.2305s	
16690/33650 (epoch 24.799), train_loss = 0.94831553, grad/param norm = 1.4766e-01, time/batch = 18.2999s	
16691/33650 (epoch 24.801), train_loss = 0.97985118, grad/param norm = 1.9502e-01, time/batch = 19.3097s	
16692/33650 (epoch 24.802), train_loss = 1.06074367, grad/param norm = 1.5691e-01, time/batch = 17.2221s	
16693/33650 (epoch 24.804), train_loss = 0.97304968, grad/param norm = 1.6926e-01, time/batch = 18.8924s	
16694/33650 (epoch 24.805), train_loss = 0.95025604, grad/param norm = 1.3839e-01, time/batch = 17.4528s	
16695/33650 (epoch 24.807), train_loss = 1.15966444, grad/param norm = 1.8420e-01, time/batch = 17.8044s	
16696/33650 (epoch 24.808), train_loss = 1.20871325, grad/param norm = 1.9938e-01, time/batch = 17.4525s	
16697/33650 (epoch 24.810), train_loss = 1.00343026, grad/param norm = 1.6727e-01, time/batch = 17.3215s	
16698/33650 (epoch 24.811), train_loss = 0.97633088, grad/param norm = 1.5566e-01, time/batch = 18.8941s	
16699/33650 (epoch 24.813), train_loss = 0.89892359, grad/param norm = 1.4466e-01, time/batch = 16.2167s	
16700/33650 (epoch 24.814), train_loss = 1.06403400, grad/param norm = 1.7394e-01, time/batch = 18.3108s	
16701/33650 (epoch 24.816), train_loss = 1.03830701, grad/param norm = 1.8855e-01, time/batch = 18.7244s	
16702/33650 (epoch 24.817), train_loss = 1.05008766, grad/param norm = 1.8407e-01, time/batch = 17.9742s	
16703/33650 (epoch 24.819), train_loss = 0.99985008, grad/param norm = 1.7251e-01, time/batch = 19.1360s	
16704/33650 (epoch 24.820), train_loss = 1.08828403, grad/param norm = 1.6122e-01, time/batch = 18.5688s	
16705/33650 (epoch 24.822), train_loss = 1.00069148, grad/param norm = 1.9807e-01, time/batch = 17.0569s	
16706/33650 (epoch 24.823), train_loss = 0.90946359, grad/param norm = 1.9394e-01, time/batch = 18.2198s	
16707/33650 (epoch 24.825), train_loss = 0.95519059, grad/param norm = 1.3847e-01, time/batch = 18.1516s	
16708/33650 (epoch 24.826), train_loss = 1.01755282, grad/param norm = 1.5198e-01, time/batch = 18.4811s	
16709/33650 (epoch 24.828), train_loss = 1.13328467, grad/param norm = 1.7935e-01, time/batch = 17.7093s	
16710/33650 (epoch 24.829), train_loss = 0.80046786, grad/param norm = 1.2731e-01, time/batch = 18.1400s	
16711/33650 (epoch 24.831), train_loss = 0.99252111, grad/param norm = 1.5114e-01, time/batch = 18.3700s	
16712/33650 (epoch 24.832), train_loss = 1.04704642, grad/param norm = 1.6021e-01, time/batch = 17.5548s	
16713/33650 (epoch 24.834), train_loss = 1.03546815, grad/param norm = 1.5468e-01, time/batch = 18.9795s	
16714/33650 (epoch 24.835), train_loss = 1.18969698, grad/param norm = 1.8584e-01, time/batch = 16.2126s	
16715/33650 (epoch 24.837), train_loss = 1.00477771, grad/param norm = 1.8307e-01, time/batch = 17.9754s	
16716/33650 (epoch 24.838), train_loss = 0.98822246, grad/param norm = 1.6822e-01, time/batch = 17.4736s	
16717/33650 (epoch 24.840), train_loss = 1.04714313, grad/param norm = 1.5299e-01, time/batch = 17.9720s	
16718/33650 (epoch 24.841), train_loss = 0.92274747, grad/param norm = 1.4989e-01, time/batch = 18.9735s	
16719/33650 (epoch 24.842), train_loss = 0.95417275, grad/param norm = 1.4164e-01, time/batch = 17.2239s	
16720/33650 (epoch 24.844), train_loss = 1.15564680, grad/param norm = 1.7666e-01, time/batch = 18.0763s	
16721/33650 (epoch 24.845), train_loss = 0.90551666, grad/param norm = 1.4272e-01, time/batch = 16.6339s	
16722/33650 (epoch 24.847), train_loss = 0.74580817, grad/param norm = 1.6297e-01, time/batch = 16.2222s	
16723/33650 (epoch 24.848), train_loss = 0.84720230, grad/param norm = 1.5646e-01, time/batch = 17.6442s	
16724/33650 (epoch 24.850), train_loss = 0.93863416, grad/param norm = 1.8473e-01, time/batch = 17.3252s	
16725/33650 (epoch 24.851), train_loss = 0.80235472, grad/param norm = 1.3005e-01, time/batch = 18.2293s	
16726/33650 (epoch 24.853), train_loss = 0.95133121, grad/param norm = 1.5341e-01, time/batch = 17.3993s	
16727/33650 (epoch 24.854), train_loss = 1.06806487, grad/param norm = 1.6292e-01, time/batch = 17.4055s	
16728/33650 (epoch 24.856), train_loss = 0.74628063, grad/param norm = 1.3876e-01, time/batch = 17.6519s	
16729/33650 (epoch 24.857), train_loss = 0.97248946, grad/param norm = 1.4813e-01, time/batch = 16.4907s	
16730/33650 (epoch 24.859), train_loss = 0.85486895, grad/param norm = 1.3409e-01, time/batch = 17.6542s	
16731/33650 (epoch 24.860), train_loss = 0.82249610, grad/param norm = 1.4243e-01, time/batch = 16.3224s	
16732/33650 (epoch 24.862), train_loss = 0.87738586, grad/param norm = 1.5645e-01, time/batch = 17.7271s	
16733/33650 (epoch 24.863), train_loss = 1.10448973, grad/param norm = 1.6335e-01, time/batch = 16.0466s	
16734/33650 (epoch 24.865), train_loss = 0.91880424, grad/param norm = 1.3776e-01, time/batch = 17.3050s	
16735/33650 (epoch 24.866), train_loss = 0.87476972, grad/param norm = 1.4472e-01, time/batch = 17.9017s	
16736/33650 (epoch 24.868), train_loss = 0.83980879, grad/param norm = 1.5953e-01, time/batch = 16.6463s	
16737/33650 (epoch 24.869), train_loss = 1.03516822, grad/param norm = 1.6367e-01, time/batch = 18.3142s	
16738/33650 (epoch 24.871), train_loss = 0.83966764, grad/param norm = 1.4261e-01, time/batch = 15.3870s	
16739/33650 (epoch 24.872), train_loss = 0.98461472, grad/param norm = 1.5009e-01, time/batch = 16.1746s	
16740/33650 (epoch 24.874), train_loss = 1.02338423, grad/param norm = 1.8601e-01, time/batch = 16.8788s	
16741/33650 (epoch 24.875), train_loss = 0.91693452, grad/param norm = 1.3603e-01, time/batch = 17.4133s	
16742/33650 (epoch 24.877), train_loss = 1.12266435, grad/param norm = 1.5602e-01, time/batch = 17.5680s	
16743/33650 (epoch 24.878), train_loss = 0.68424685, grad/param norm = 1.2957e-01, time/batch = 15.9431s	
16744/33650 (epoch 24.880), train_loss = 0.97891495, grad/param norm = 1.7494e-01, time/batch = 0.6336s	
16745/33650 (epoch 24.881), train_loss = 0.90732175, grad/param norm = 1.5310e-01, time/batch = 0.6275s	
16746/33650 (epoch 24.883), train_loss = 0.96057294, grad/param norm = 1.4045e-01, time/batch = 0.6268s	
16747/33650 (epoch 24.884), train_loss = 1.06115273, grad/param norm = 1.5883e-01, time/batch = 0.6276s	
16748/33650 (epoch 24.886), train_loss = 1.01853689, grad/param norm = 1.4711e-01, time/batch = 0.6429s	
16749/33650 (epoch 24.887), train_loss = 0.82195299, grad/param norm = 1.2583e-01, time/batch = 0.6314s	
16750/33650 (epoch 24.889), train_loss = 0.93089840, grad/param norm = 1.5379e-01, time/batch = 0.6292s	
16751/33650 (epoch 24.890), train_loss = 1.00228492, grad/param norm = 1.4240e-01, time/batch = 0.6713s	
16752/33650 (epoch 24.892), train_loss = 0.93435055, grad/param norm = 1.6985e-01, time/batch = 0.9190s	
16753/33650 (epoch 24.893), train_loss = 0.98156187, grad/param norm = 1.4149e-01, time/batch = 0.9195s	
16754/33650 (epoch 24.895), train_loss = 1.07516501, grad/param norm = 1.5616e-01, time/batch = 0.9190s	
16755/33650 (epoch 24.896), train_loss = 0.89122861, grad/param norm = 1.3756e-01, time/batch = 0.9199s	
16756/33650 (epoch 24.897), train_loss = 0.80149230, grad/param norm = 1.3757e-01, time/batch = 0.9099s	
16757/33650 (epoch 24.899), train_loss = 0.84731536, grad/param norm = 1.3278e-01, time/batch = 1.5571s	
16758/33650 (epoch 24.900), train_loss = 0.80498553, grad/param norm = 1.4958e-01, time/batch = 1.8931s	
16759/33650 (epoch 24.902), train_loss = 0.95430786, grad/param norm = 1.8280e-01, time/batch = 1.7288s	
16760/33650 (epoch 24.903), train_loss = 0.90175454, grad/param norm = 1.4926e-01, time/batch = 17.1538s	
16761/33650 (epoch 24.905), train_loss = 1.07010195, grad/param norm = 1.7459e-01, time/batch = 16.2196s	
16762/33650 (epoch 24.906), train_loss = 0.89750822, grad/param norm = 1.5490e-01, time/batch = 16.5492s	
16763/33650 (epoch 24.908), train_loss = 0.92452827, grad/param norm = 1.3965e-01, time/batch = 17.5632s	
16764/33650 (epoch 24.909), train_loss = 0.88588757, grad/param norm = 1.3381e-01, time/batch = 17.7368s	
16765/33650 (epoch 24.911), train_loss = 0.79136208, grad/param norm = 1.3552e-01, time/batch = 16.4774s	
16766/33650 (epoch 24.912), train_loss = 0.77210520, grad/param norm = 1.4491e-01, time/batch = 17.0697s	
16767/33650 (epoch 24.914), train_loss = 0.95443687, grad/param norm = 1.3706e-01, time/batch = 17.9873s	
16768/33650 (epoch 24.915), train_loss = 0.91017279, grad/param norm = 1.6734e-01, time/batch = 17.9128s	
16769/33650 (epoch 24.917), train_loss = 0.90838009, grad/param norm = 1.6297e-01, time/batch = 17.1097s	
16770/33650 (epoch 24.918), train_loss = 0.80884963, grad/param norm = 1.2820e-01, time/batch = 18.3202s	
16771/33650 (epoch 24.920), train_loss = 0.84028817, grad/param norm = 1.2302e-01, time/batch = 16.6148s	
16772/33650 (epoch 24.921), train_loss = 0.84077749, grad/param norm = 1.4728e-01, time/batch = 17.5409s	
16773/33650 (epoch 24.923), train_loss = 0.78061590, grad/param norm = 1.4448e-01, time/batch = 18.3945s	
16774/33650 (epoch 24.924), train_loss = 0.94867280, grad/param norm = 1.6133e-01, time/batch = 18.7274s	
16775/33650 (epoch 24.926), train_loss = 0.87572611, grad/param norm = 1.7102e-01, time/batch = 17.8943s	
16776/33650 (epoch 24.927), train_loss = 0.91803967, grad/param norm = 1.6432e-01, time/batch = 18.1412s	
16777/33650 (epoch 24.929), train_loss = 0.99178539, grad/param norm = 1.5023e-01, time/batch = 17.5521s	
16778/33650 (epoch 24.930), train_loss = 0.90317686, grad/param norm = 1.4723e-01, time/batch = 18.8150s	
16779/33650 (epoch 24.932), train_loss = 0.88960980, grad/param norm = 1.4994e-01, time/batch = 17.8088s	
16780/33650 (epoch 24.933), train_loss = 0.80021005, grad/param norm = 1.3727e-01, time/batch = 18.6400s	
16781/33650 (epoch 24.935), train_loss = 0.82461401, grad/param norm = 1.5628e-01, time/batch = 18.7346s	
16782/33650 (epoch 24.936), train_loss = 0.86001078, grad/param norm = 1.2930e-01, time/batch = 16.2174s	
16783/33650 (epoch 24.938), train_loss = 0.80885794, grad/param norm = 1.6094e-01, time/batch = 19.2302s	
16784/33650 (epoch 24.939), train_loss = 1.00074215, grad/param norm = 1.5382e-01, time/batch = 18.3243s	
16785/33650 (epoch 24.941), train_loss = 0.92088297, grad/param norm = 1.4218e-01, time/batch = 17.8070s	
16786/33650 (epoch 24.942), train_loss = 1.02151487, grad/param norm = 1.6209e-01, time/batch = 18.8874s	
16787/33650 (epoch 24.944), train_loss = 0.89978759, grad/param norm = 1.3862e-01, time/batch = 18.3135s	
16788/33650 (epoch 24.945), train_loss = 0.95750444, grad/param norm = 1.4368e-01, time/batch = 18.0520s	
16789/33650 (epoch 24.947), train_loss = 1.05958451, grad/param norm = 1.8142e-01, time/batch = 14.9714s	
16790/33650 (epoch 24.948), train_loss = 1.05985443, grad/param norm = 1.5093e-01, time/batch = 19.1425s	
16791/33650 (epoch 24.949), train_loss = 0.80641824, grad/param norm = 1.3864e-01, time/batch = 17.8274s	
16792/33650 (epoch 24.951), train_loss = 1.06706401, grad/param norm = 1.4840e-01, time/batch = 17.1435s	
16793/33650 (epoch 24.952), train_loss = 0.99374363, grad/param norm = 1.5889e-01, time/batch = 19.0605s	
16794/33650 (epoch 24.954), train_loss = 1.00661770, grad/param norm = 1.6345e-01, time/batch = 17.1404s	
16795/33650 (epoch 24.955), train_loss = 0.97601162, grad/param norm = 1.5205e-01, time/batch = 17.6463s	
16796/33650 (epoch 24.957), train_loss = 1.00034705, grad/param norm = 1.5451e-01, time/batch = 17.4741s	
16797/33650 (epoch 24.958), train_loss = 0.74868390, grad/param norm = 1.3287e-01, time/batch = 18.5716s	
16798/33650 (epoch 24.960), train_loss = 0.75345662, grad/param norm = 1.2875e-01, time/batch = 16.5546s	
16799/33650 (epoch 24.961), train_loss = 0.82224394, grad/param norm = 1.4994e-01, time/batch = 16.9491s	
16800/33650 (epoch 24.963), train_loss = 0.87172943, grad/param norm = 1.6452e-01, time/batch = 18.8219s	
16801/33650 (epoch 24.964), train_loss = 1.00474426, grad/param norm = 1.4625e-01, time/batch = 15.8565s	
16802/33650 (epoch 24.966), train_loss = 0.95516711, grad/param norm = 1.4725e-01, time/batch = 15.5505s	
16803/33650 (epoch 24.967), train_loss = 0.97172868, grad/param norm = 1.5392e-01, time/batch = 15.6368s	
16804/33650 (epoch 24.969), train_loss = 0.92789224, grad/param norm = 1.3303e-01, time/batch = 18.4624s	
16805/33650 (epoch 24.970), train_loss = 0.96132026, grad/param norm = 1.7104e-01, time/batch = 17.7366s	
16806/33650 (epoch 24.972), train_loss = 1.22755355, grad/param norm = 1.8536e-01, time/batch = 17.2278s	
16807/33650 (epoch 24.973), train_loss = 0.84203036, grad/param norm = 1.3822e-01, time/batch = 18.8911s	
16808/33650 (epoch 24.975), train_loss = 0.84035944, grad/param norm = 1.3618e-01, time/batch = 18.8212s	
16809/33650 (epoch 24.976), train_loss = 0.84412047, grad/param norm = 1.2417e-01, time/batch = 17.1372s	
16810/33650 (epoch 24.978), train_loss = 0.86729327, grad/param norm = 1.5029e-01, time/batch = 18.6434s	
16811/33650 (epoch 24.979), train_loss = 0.91919306, grad/param norm = 1.5817e-01, time/batch = 19.2754s	
16812/33650 (epoch 24.981), train_loss = 0.87614515, grad/param norm = 1.1821e-01, time/batch = 17.3070s	
16813/33650 (epoch 24.982), train_loss = 0.96641348, grad/param norm = 1.5452e-01, time/batch = 17.5359s	
16814/33650 (epoch 24.984), train_loss = 0.78722745, grad/param norm = 1.3853e-01, time/batch = 18.2248s	
16815/33650 (epoch 24.985), train_loss = 0.80268973, grad/param norm = 1.4767e-01, time/batch = 18.6393s	
16816/33650 (epoch 24.987), train_loss = 0.92322566, grad/param norm = 1.4085e-01, time/batch = 16.8934s	
16817/33650 (epoch 24.988), train_loss = 0.93223271, grad/param norm = 1.7615e-01, time/batch = 18.5815s	
16818/33650 (epoch 24.990), train_loss = 1.09043085, grad/param norm = 1.6724e-01, time/batch = 17.2872s	
16819/33650 (epoch 24.991), train_loss = 0.95770932, grad/param norm = 1.4552e-01, time/batch = 17.3909s	
16820/33650 (epoch 24.993), train_loss = 0.96162367, grad/param norm = 1.6780e-01, time/batch = 18.8943s	
16821/33650 (epoch 24.994), train_loss = 0.90793886, grad/param norm = 1.3711e-01, time/batch = 18.2233s	
16822/33650 (epoch 24.996), train_loss = 0.85971493, grad/param norm = 1.6615e-01, time/batch = 16.4594s	
16823/33650 (epoch 24.997), train_loss = 1.00783846, grad/param norm = 1.5693e-01, time/batch = 18.1504s	
16824/33650 (epoch 24.999), train_loss = 0.85801398, grad/param norm = 1.4896e-01, time/batch = 17.5708s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
16825/33650 (epoch 25.000), train_loss = 1.00458367, grad/param norm = 1.7137e-01, time/batch = 17.7312s	
16826/33650 (epoch 25.001), train_loss = 1.08428388, grad/param norm = 1.6631e-01, time/batch = 31.8874s	
16827/33650 (epoch 25.003), train_loss = 1.08690636, grad/param norm = 2.2105e-01, time/batch = 18.4005s	
16828/33650 (epoch 25.004), train_loss = 0.98210285, grad/param norm = 1.7418e-01, time/batch = 16.1517s	
16829/33650 (epoch 25.006), train_loss = 0.90153416, grad/param norm = 1.5536e-01, time/batch = 18.6417s	
16830/33650 (epoch 25.007), train_loss = 0.99976742, grad/param norm = 1.5535e-01, time/batch = 18.2309s	
16831/33650 (epoch 25.009), train_loss = 0.88076180, grad/param norm = 1.4658e-01, time/batch = 18.1208s	
16832/33650 (epoch 25.010), train_loss = 1.04229995, grad/param norm = 1.7200e-01, time/batch = 17.8819s	
16833/33650 (epoch 25.012), train_loss = 0.87091540, grad/param norm = 1.4163e-01, time/batch = 18.8886s	
16834/33650 (epoch 25.013), train_loss = 0.93720992, grad/param norm = 1.9100e-01, time/batch = 18.4732s	
16835/33650 (epoch 25.015), train_loss = 0.93338237, grad/param norm = 1.6119e-01, time/batch = 17.2158s	
16836/33650 (epoch 25.016), train_loss = 0.84065427, grad/param norm = 1.5087e-01, time/batch = 18.6459s	
16837/33650 (epoch 25.018), train_loss = 0.91639798, grad/param norm = 1.8510e-01, time/batch = 17.9870s	
16838/33650 (epoch 25.019), train_loss = 0.89691740, grad/param norm = 1.5711e-01, time/batch = 16.9740s	
16839/33650 (epoch 25.021), train_loss = 0.97420110, grad/param norm = 1.5243e-01, time/batch = 18.6404s	
16840/33650 (epoch 25.022), train_loss = 0.87944849, grad/param norm = 1.4063e-01, time/batch = 19.0667s	
16841/33650 (epoch 25.024), train_loss = 0.84900636, grad/param norm = 1.6503e-01, time/batch = 17.7880s	
16842/33650 (epoch 25.025), train_loss = 0.94709292, grad/param norm = 1.7190e-01, time/batch = 16.8789s	
16843/33650 (epoch 25.027), train_loss = 0.96870089, grad/param norm = 1.5963e-01, time/batch = 18.4828s	
16844/33650 (epoch 25.028), train_loss = 0.99912926, grad/param norm = 1.6493e-01, time/batch = 18.8143s	
16845/33650 (epoch 25.030), train_loss = 0.94766176, grad/param norm = 1.7326e-01, time/batch = 16.6229s	
16846/33650 (epoch 25.031), train_loss = 0.84993261, grad/param norm = 1.3672e-01, time/batch = 18.9810s	
16847/33650 (epoch 25.033), train_loss = 0.92035101, grad/param norm = 1.3466e-01, time/batch = 17.6561s	
16848/33650 (epoch 25.034), train_loss = 0.95676519, grad/param norm = 1.4946e-01, time/batch = 16.9674s	
16849/33650 (epoch 25.036), train_loss = 1.03745700, grad/param norm = 1.6145e-01, time/batch = 17.2129s	
16850/33650 (epoch 25.037), train_loss = 0.90182612, grad/param norm = 1.5024e-01, time/batch = 18.8830s	
16851/33650 (epoch 25.039), train_loss = 1.01649474, grad/param norm = 1.5626e-01, time/batch = 17.1431s	
16852/33650 (epoch 25.040), train_loss = 1.11484258, grad/param norm = 1.8820e-01, time/batch = 17.9710s	
16853/33650 (epoch 25.042), train_loss = 1.14032657, grad/param norm = 1.7701e-01, time/batch = 18.7293s	
16854/33650 (epoch 25.043), train_loss = 0.88806574, grad/param norm = 1.6129e-01, time/batch = 18.0715s	
16855/33650 (epoch 25.045), train_loss = 0.89140830, grad/param norm = 1.4777e-01, time/batch = 16.9781s	
16856/33650 (epoch 25.046), train_loss = 0.98563642, grad/param norm = 1.5019e-01, time/batch = 18.8074s	
16857/33650 (epoch 25.048), train_loss = 1.04002415, grad/param norm = 1.6147e-01, time/batch = 18.6538s	
16858/33650 (epoch 25.049), train_loss = 0.93024389, grad/param norm = 1.5567e-01, time/batch = 17.4616s	
16859/33650 (epoch 25.051), train_loss = 1.08661575, grad/param norm = 1.5432e-01, time/batch = 18.8902s	
16860/33650 (epoch 25.052), train_loss = 1.07765699, grad/param norm = 1.7527e-01, time/batch = 18.3954s	
16861/33650 (epoch 25.053), train_loss = 0.99194247, grad/param norm = 1.4492e-01, time/batch = 17.7246s	
16862/33650 (epoch 25.055), train_loss = 0.84568270, grad/param norm = 1.3999e-01, time/batch = 18.1417s	
16863/33650 (epoch 25.056), train_loss = 0.83448922, grad/param norm = 1.2305e-01, time/batch = 17.1280s	
16864/33650 (epoch 25.058), train_loss = 1.02095976, grad/param norm = 1.7678e-01, time/batch = 18.8027s	
16865/33650 (epoch 25.059), train_loss = 0.98638490, grad/param norm = 1.6367e-01, time/batch = 15.7050s	
16866/33650 (epoch 25.061), train_loss = 1.02591660, grad/param norm = 1.5523e-01, time/batch = 18.3154s	
16867/33650 (epoch 25.062), train_loss = 0.98389621, grad/param norm = 1.4827e-01, time/batch = 17.0461s	
16868/33650 (epoch 25.064), train_loss = 0.91740212, grad/param norm = 1.4049e-01, time/batch = 17.3951s	
16869/33650 (epoch 25.065), train_loss = 0.89468663, grad/param norm = 1.5472e-01, time/batch = 18.8914s	
16870/33650 (epoch 25.067), train_loss = 0.82222155, grad/param norm = 1.2439e-01, time/batch = 18.6479s	
16871/33650 (epoch 25.068), train_loss = 0.94588545, grad/param norm = 1.7451e-01, time/batch = 18.1204s	
16872/33650 (epoch 25.070), train_loss = 0.98960788, grad/param norm = 1.5681e-01, time/batch = 18.2227s	
16873/33650 (epoch 25.071), train_loss = 0.92201560, grad/param norm = 1.8672e-01, time/batch = 15.7367s	
16874/33650 (epoch 25.073), train_loss = 0.99309998, grad/param norm = 1.7571e-01, time/batch = 18.2297s	
16875/33650 (epoch 25.074), train_loss = 1.05543310, grad/param norm = 1.4465e-01, time/batch = 15.5401s	
16876/33650 (epoch 25.076), train_loss = 1.01093118, grad/param norm = 1.6441e-01, time/batch = 16.3902s	
16877/33650 (epoch 25.077), train_loss = 0.95743991, grad/param norm = 1.4682e-01, time/batch = 17.2111s	
16878/33650 (epoch 25.079), train_loss = 0.98084163, grad/param norm = 1.4364e-01, time/batch = 17.8002s	
16879/33650 (epoch 25.080), train_loss = 0.99424447, grad/param norm = 1.5544e-01, time/batch = 17.5528s	
16880/33650 (epoch 25.082), train_loss = 0.94280370, grad/param norm = 1.4724e-01, time/batch = 19.3013s	
16881/33650 (epoch 25.083), train_loss = 1.00237129, grad/param norm = 1.6069e-01, time/batch = 18.1380s	
16882/33650 (epoch 25.085), train_loss = 1.05100571, grad/param norm = 1.6836e-01, time/batch = 17.8835s	
16883/33650 (epoch 25.086), train_loss = 1.01569327, grad/param norm = 1.9195e-01, time/batch = 19.0555s	
16884/33650 (epoch 25.088), train_loss = 0.97742199, grad/param norm = 1.6355e-01, time/batch = 18.8999s	
16885/33650 (epoch 25.089), train_loss = 0.91547273, grad/param norm = 1.5461e-01, time/batch = 16.9668s	
16886/33650 (epoch 25.091), train_loss = 0.90839792, grad/param norm = 1.3196e-01, time/batch = 18.6398s	
16887/33650 (epoch 25.092), train_loss = 0.93259527, grad/param norm = 1.4452e-01, time/batch = 18.6324s	
16888/33650 (epoch 25.094), train_loss = 1.01186605, grad/param norm = 1.3928e-01, time/batch = 17.1366s	
16889/33650 (epoch 25.095), train_loss = 1.00947665, grad/param norm = 1.8198e-01, time/batch = 17.6498s	
16890/33650 (epoch 25.097), train_loss = 0.88025004, grad/param norm = 1.5345e-01, time/batch = 17.5655s	
16891/33650 (epoch 25.098), train_loss = 0.77726387, grad/param norm = 1.4437e-01, time/batch = 17.9690s	
16892/33650 (epoch 25.100), train_loss = 0.88628271, grad/param norm = 1.4388e-01, time/batch = 17.3936s	
16893/33650 (epoch 25.101), train_loss = 0.95036142, grad/param norm = 1.5975e-01, time/batch = 17.8953s	
16894/33650 (epoch 25.103), train_loss = 0.92608505, grad/param norm = 1.5992e-01, time/batch = 16.7234s	
16895/33650 (epoch 25.104), train_loss = 1.06603712, grad/param norm = 1.5468e-01, time/batch = 16.6226s	
16896/33650 (epoch 25.105), train_loss = 0.94713347, grad/param norm = 1.5875e-01, time/batch = 18.1471s	
16897/33650 (epoch 25.107), train_loss = 0.90688154, grad/param norm = 1.5377e-01, time/batch = 18.2296s	
16898/33650 (epoch 25.108), train_loss = 1.01414579, grad/param norm = 1.5121e-01, time/batch = 15.5546s	
16899/33650 (epoch 25.110), train_loss = 1.10103859, grad/param norm = 1.5160e-01, time/batch = 15.8991s	
16900/33650 (epoch 25.111), train_loss = 0.91632398, grad/param norm = 1.5838e-01, time/batch = 18.2407s	
16901/33650 (epoch 25.113), train_loss = 0.92108311, grad/param norm = 1.5627e-01, time/batch = 16.9012s	
16902/33650 (epoch 25.114), train_loss = 1.00756200, grad/param norm = 1.4834e-01, time/batch = 17.9798s	
16903/33650 (epoch 25.116), train_loss = 0.85991143, grad/param norm = 1.2565e-01, time/batch = 17.7267s	
16904/33650 (epoch 25.117), train_loss = 0.94055331, grad/param norm = 1.3196e-01, time/batch = 18.2341s	
16905/33650 (epoch 25.119), train_loss = 0.85160365, grad/param norm = 1.4413e-01, time/batch = 17.8080s	
16906/33650 (epoch 25.120), train_loss = 0.90265104, grad/param norm = 1.3616e-01, time/batch = 18.4751s	
16907/33650 (epoch 25.122), train_loss = 0.74641253, grad/param norm = 1.5084e-01, time/batch = 18.9684s	
16908/33650 (epoch 25.123), train_loss = 0.89264380, grad/param norm = 1.3719e-01, time/batch = 16.1457s	
16909/33650 (epoch 25.125), train_loss = 0.99576330, grad/param norm = 1.6172e-01, time/batch = 17.2464s	
16910/33650 (epoch 25.126), train_loss = 1.05004854, grad/param norm = 1.9159e-01, time/batch = 17.7397s	
16911/33650 (epoch 25.128), train_loss = 1.01871776, grad/param norm = 1.7505e-01, time/batch = 18.3019s	
16912/33650 (epoch 25.129), train_loss = 1.04875532, grad/param norm = 1.6078e-01, time/batch = 16.9780s	
16913/33650 (epoch 25.131), train_loss = 0.96119355, grad/param norm = 1.4635e-01, time/batch = 18.5673s	
16914/33650 (epoch 25.132), train_loss = 0.95221040, grad/param norm = 1.5269e-01, time/batch = 18.2333s	
16915/33650 (epoch 25.134), train_loss = 1.02883111, grad/param norm = 1.6771e-01, time/batch = 16.1963s	
16916/33650 (epoch 25.135), train_loss = 0.84679279, grad/param norm = 1.5264e-01, time/batch = 17.4631s	
16917/33650 (epoch 25.137), train_loss = 0.98446994, grad/param norm = 1.8282e-01, time/batch = 17.9855s	
16918/33650 (epoch 25.138), train_loss = 1.02194226, grad/param norm = 1.6310e-01, time/batch = 17.8279s	
16919/33650 (epoch 25.140), train_loss = 0.93946826, grad/param norm = 1.7358e-01, time/batch = 17.6360s	
16920/33650 (epoch 25.141), train_loss = 1.08101030, grad/param norm = 1.5919e-01, time/batch = 17.1284s	
16921/33650 (epoch 25.143), train_loss = 1.10730951, grad/param norm = 1.9142e-01, time/batch = 18.3939s	
16922/33650 (epoch 25.144), train_loss = 0.99820311, grad/param norm = 1.7233e-01, time/batch = 16.5437s	
16923/33650 (epoch 25.146), train_loss = 0.93405110, grad/param norm = 1.4819e-01, time/batch = 17.7244s	
16924/33650 (epoch 25.147), train_loss = 0.89400150, grad/param norm = 1.5217e-01, time/batch = 18.0627s	
16925/33650 (epoch 25.149), train_loss = 0.85585199, grad/param norm = 1.6126e-01, time/batch = 17.4042s	
16926/33650 (epoch 25.150), train_loss = 0.83075973, grad/param norm = 1.4038e-01, time/batch = 17.4706s	
16927/33650 (epoch 25.152), train_loss = 0.88492284, grad/param norm = 1.3954e-01, time/batch = 18.6517s	
16928/33650 (epoch 25.153), train_loss = 0.92239558, grad/param norm = 1.4574e-01, time/batch = 18.8223s	
16929/33650 (epoch 25.155), train_loss = 0.88442689, grad/param norm = 1.3502e-01, time/batch = 17.5270s	
16930/33650 (epoch 25.156), train_loss = 0.86553408, grad/param norm = 1.4385e-01, time/batch = 17.8962s	
16931/33650 (epoch 25.158), train_loss = 0.97806757, grad/param norm = 1.6697e-01, time/batch = 19.2963s	
16932/33650 (epoch 25.159), train_loss = 0.86804679, grad/param norm = 1.2956e-01, time/batch = 17.9721s	
16933/33650 (epoch 25.160), train_loss = 0.88455337, grad/param norm = 1.3099e-01, time/batch = 18.2183s	
16934/33650 (epoch 25.162), train_loss = 0.92505637, grad/param norm = 1.7265e-01, time/batch = 18.9669s	
16935/33650 (epoch 25.163), train_loss = 0.98844923, grad/param norm = 1.6111e-01, time/batch = 16.2083s	
16936/33650 (epoch 25.165), train_loss = 0.84327358, grad/param norm = 1.4851e-01, time/batch = 17.5567s	
16937/33650 (epoch 25.166), train_loss = 0.85163072, grad/param norm = 1.5065e-01, time/batch = 18.5622s	
16938/33650 (epoch 25.168), train_loss = 1.02076952, grad/param norm = 1.6080e-01, time/batch = 18.0676s	
16939/33650 (epoch 25.169), train_loss = 0.95883222, grad/param norm = 1.5145e-01, time/batch = 16.9689s	
16940/33650 (epoch 25.171), train_loss = 0.92747596, grad/param norm = 1.3739e-01, time/batch = 18.5493s	
16941/33650 (epoch 25.172), train_loss = 0.89730921, grad/param norm = 1.5866e-01, time/batch = 18.8886s	
16942/33650 (epoch 25.174), train_loss = 0.86141200, grad/param norm = 1.7127e-01, time/batch = 17.8030s	
16943/33650 (epoch 25.175), train_loss = 0.83876189, grad/param norm = 1.6081e-01, time/batch = 18.6401s	
16944/33650 (epoch 25.177), train_loss = 0.94232753, grad/param norm = 1.4992e-01, time/batch = 17.2325s	
16945/33650 (epoch 25.178), train_loss = 0.88457867, grad/param norm = 1.8025e-01, time/batch = 18.0618s	
16946/33650 (epoch 25.180), train_loss = 0.84797653, grad/param norm = 1.4774e-01, time/batch = 17.3069s	
16947/33650 (epoch 25.181), train_loss = 0.76280279, grad/param norm = 1.3477e-01, time/batch = 18.9736s	
16948/33650 (epoch 25.183), train_loss = 0.88095009, grad/param norm = 1.4993e-01, time/batch = 17.9864s	
16949/33650 (epoch 25.184), train_loss = 0.87677178, grad/param norm = 1.6415e-01, time/batch = 17.3789s	
16950/33650 (epoch 25.186), train_loss = 0.92336636, grad/param norm = 1.6652e-01, time/batch = 16.0216s	
16951/33650 (epoch 25.187), train_loss = 1.07540244, grad/param norm = 1.6903e-01, time/batch = 18.8607s	
16952/33650 (epoch 25.189), train_loss = 1.04620746, grad/param norm = 1.8929e-01, time/batch = 17.4694s	
16953/33650 (epoch 25.190), train_loss = 0.96102628, grad/param norm = 1.6191e-01, time/batch = 18.9765s	
16954/33650 (epoch 25.192), train_loss = 1.12243781, grad/param norm = 1.5462e-01, time/batch = 16.9655s	
16955/33650 (epoch 25.193), train_loss = 1.07354806, grad/param norm = 1.5839e-01, time/batch = 18.8699s	
16956/33650 (epoch 25.195), train_loss = 0.83438654, grad/param norm = 1.5976e-01, time/batch = 18.0527s	
16957/33650 (epoch 25.196), train_loss = 0.81470133, grad/param norm = 1.6164e-01, time/batch = 18.4761s	
16958/33650 (epoch 25.198), train_loss = 0.89246270, grad/param norm = 1.5792e-01, time/batch = 19.0565s	
16959/33650 (epoch 25.199), train_loss = 1.01917558, grad/param norm = 1.7308e-01, time/batch = 17.3836s	
16960/33650 (epoch 25.201), train_loss = 0.92016903, grad/param norm = 1.7135e-01, time/batch = 17.6561s	
16961/33650 (epoch 25.202), train_loss = 0.90785273, grad/param norm = 1.5243e-01, time/batch = 17.0558s	
16962/33650 (epoch 25.204), train_loss = 0.99612454, grad/param norm = 1.6288e-01, time/batch = 17.6442s	
16963/33650 (epoch 25.205), train_loss = 0.92142459, grad/param norm = 1.9723e-01, time/batch = 17.7123s	
16964/33650 (epoch 25.207), train_loss = 0.88865075, grad/param norm = 1.7599e-01, time/batch = 18.2137s	
16965/33650 (epoch 25.208), train_loss = 0.96180352, grad/param norm = 1.5224e-01, time/batch = 18.3964s	
16966/33650 (epoch 25.210), train_loss = 0.77455967, grad/param norm = 1.4995e-01, time/batch = 18.2212s	
16967/33650 (epoch 25.211), train_loss = 0.89990772, grad/param norm = 2.0373e-01, time/batch = 18.7194s	
16968/33650 (epoch 25.212), train_loss = 1.00599998, grad/param norm = 1.7235e-01, time/batch = 18.9678s	
16969/33650 (epoch 25.214), train_loss = 1.10158575, grad/param norm = 1.5567e-01, time/batch = 17.3124s	
16970/33650 (epoch 25.215), train_loss = 0.72094278, grad/param norm = 1.4373e-01, time/batch = 17.2882s	
16971/33650 (epoch 25.217), train_loss = 0.91559108, grad/param norm = 1.9143e-01, time/batch = 17.0692s	
16972/33650 (epoch 25.218), train_loss = 0.93668324, grad/param norm = 1.4442e-01, time/batch = 17.1480s	
16973/33650 (epoch 25.220), train_loss = 0.81608456, grad/param norm = 1.4298e-01, time/batch = 18.5687s	
16974/33650 (epoch 25.221), train_loss = 1.10025933, grad/param norm = 1.7277e-01, time/batch = 18.8118s	
16975/33650 (epoch 25.223), train_loss = 0.75448945, grad/param norm = 1.4014e-01, time/batch = 17.1405s	
16976/33650 (epoch 25.224), train_loss = 0.89057690, grad/param norm = 1.8604e-01, time/batch = 16.7203s	
16977/33650 (epoch 25.226), train_loss = 1.22073728, grad/param norm = 1.8103e-01, time/batch = 18.7318s	
16978/33650 (epoch 25.227), train_loss = 1.05308538, grad/param norm = 1.9109e-01, time/batch = 18.3125s	
16979/33650 (epoch 25.229), train_loss = 1.04759885, grad/param norm = 1.5707e-01, time/batch = 17.7191s	
16980/33650 (epoch 25.230), train_loss = 1.17920978, grad/param norm = 1.7396e-01, time/batch = 18.5600s	
16981/33650 (epoch 25.232), train_loss = 1.04081118, grad/param norm = 2.2256e-01, time/batch = 15.3811s	
16982/33650 (epoch 25.233), train_loss = 1.02078184, grad/param norm = 2.2738e-01, time/batch = 17.8859s	
16983/33650 (epoch 25.235), train_loss = 0.94548643, grad/param norm = 1.4724e-01, time/batch = 19.1364s	
16984/33650 (epoch 25.236), train_loss = 0.84717815, grad/param norm = 1.3580e-01, time/batch = 18.5623s	
16985/33650 (epoch 25.238), train_loss = 0.91248068, grad/param norm = 1.4501e-01, time/batch = 17.8999s	
16986/33650 (epoch 25.239), train_loss = 0.87374519, grad/param norm = 1.5627e-01, time/batch = 18.3178s	
16987/33650 (epoch 25.241), train_loss = 0.90920676, grad/param norm = 1.3964e-01, time/batch = 16.6300s	
16988/33650 (epoch 25.242), train_loss = 0.76256790, grad/param norm = 1.5930e-01, time/batch = 18.2304s	
16989/33650 (epoch 25.244), train_loss = 0.91811486, grad/param norm = 1.4554e-01, time/batch = 16.9759s	
16990/33650 (epoch 25.245), train_loss = 0.81356830, grad/param norm = 1.3731e-01, time/batch = 18.3884s	
16991/33650 (epoch 25.247), train_loss = 0.92315525, grad/param norm = 1.3267e-01, time/batch = 18.9819s	
16992/33650 (epoch 25.248), train_loss = 0.82331370, grad/param norm = 1.4771e-01, time/batch = 16.1460s	
16993/33650 (epoch 25.250), train_loss = 0.92660453, grad/param norm = 1.5187e-01, time/batch = 18.5660s	
16994/33650 (epoch 25.251), train_loss = 1.06015793, grad/param norm = 1.5660e-01, time/batch = 17.9019s	
16995/33650 (epoch 25.253), train_loss = 0.81607846, grad/param norm = 1.4524e-01, time/batch = 17.8878s	
16996/33650 (epoch 25.254), train_loss = 0.86452190, grad/param norm = 1.6302e-01, time/batch = 17.2228s	
16997/33650 (epoch 25.256), train_loss = 1.07754953, grad/param norm = 1.5095e-01, time/batch = 19.3845s	
16998/33650 (epoch 25.257), train_loss = 1.07145464, grad/param norm = 1.6689e-01, time/batch = 17.7929s	
16999/33650 (epoch 25.259), train_loss = 0.81066454, grad/param norm = 1.4626e-01, time/batch = 17.1070s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch25.26_1.6253.t7	
17000/33650 (epoch 25.260), train_loss = 1.00024287, grad/param norm = 1.5568e-01, time/batch = 18.3138s	
17001/33650 (epoch 25.262), train_loss = 1.37944333, grad/param norm = 2.0688e-01, time/batch = 17.6328s	
17002/33650 (epoch 25.263), train_loss = 0.89278064, grad/param norm = 1.8323e-01, time/batch = 16.7062s	
17003/33650 (epoch 25.264), train_loss = 0.98650840, grad/param norm = 1.6930e-01, time/batch = 17.8078s	
17004/33650 (epoch 25.266), train_loss = 0.95901500, grad/param norm = 1.4236e-01, time/batch = 17.8925s	
17005/33650 (epoch 25.267), train_loss = 0.88290439, grad/param norm = 1.5852e-01, time/batch = 16.7902s	
17006/33650 (epoch 25.269), train_loss = 0.95809762, grad/param norm = 1.7215e-01, time/batch = 19.2244s	
17007/33650 (epoch 25.270), train_loss = 0.85552656, grad/param norm = 1.4217e-01, time/batch = 18.5577s	
17008/33650 (epoch 25.272), train_loss = 0.91021932, grad/param norm = 1.4471e-01, time/batch = 16.6963s	
17009/33650 (epoch 25.273), train_loss = 1.04758733, grad/param norm = 1.7589e-01, time/batch = 19.0497s	
17010/33650 (epoch 25.275), train_loss = 1.00608447, grad/param norm = 1.6811e-01, time/batch = 18.3014s	
17011/33650 (epoch 25.276), train_loss = 1.02557539, grad/param norm = 1.8029e-01, time/batch = 16.9563s	
17012/33650 (epoch 25.278), train_loss = 1.09701712, grad/param norm = 1.7296e-01, time/batch = 18.8120s	
17013/33650 (epoch 25.279), train_loss = 0.91476267, grad/param norm = 1.4921e-01, time/batch = 18.2347s	
17014/33650 (epoch 25.281), train_loss = 0.95307175, grad/param norm = 1.5219e-01, time/batch = 17.3120s	
17015/33650 (epoch 25.282), train_loss = 1.05982558, grad/param norm = 1.4581e-01, time/batch = 18.2177s	
17016/33650 (epoch 25.284), train_loss = 1.01804227, grad/param norm = 1.6772e-01, time/batch = 18.7225s	
17017/33650 (epoch 25.285), train_loss = 0.99683445, grad/param norm = 1.6717e-01, time/batch = 18.2177s	
17018/33650 (epoch 25.287), train_loss = 0.90154064, grad/param norm = 1.5798e-01, time/batch = 32.1496s	
17019/33650 (epoch 25.288), train_loss = 0.96548632, grad/param norm = 1.6786e-01, time/batch = 18.8113s	
17020/33650 (epoch 25.290), train_loss = 0.95771123, grad/param norm = 1.3642e-01, time/batch = 16.8087s	
17021/33650 (epoch 25.291), train_loss = 0.84310590, grad/param norm = 1.2963e-01, time/batch = 18.3046s	
17022/33650 (epoch 25.293), train_loss = 0.92156864, grad/param norm = 1.7470e-01, time/batch = 19.0502s	
17023/33650 (epoch 25.294), train_loss = 0.85845545, grad/param norm = 1.4501e-01, time/batch = 18.0632s	
17024/33650 (epoch 25.296), train_loss = 0.85074147, grad/param norm = 1.4680e-01, time/batch = 16.1088s	
17025/33650 (epoch 25.297), train_loss = 0.91968103, grad/param norm = 1.4848e-01, time/batch = 18.2181s	
17026/33650 (epoch 25.299), train_loss = 0.81345582, grad/param norm = 1.5477e-01, time/batch = 17.5450s	
17027/33650 (epoch 25.300), train_loss = 0.84047443, grad/param norm = 1.5769e-01, time/batch = 17.5576s	
17028/33650 (epoch 25.302), train_loss = 0.95996104, grad/param norm = 1.2711e-01, time/batch = 17.8198s	
17029/33650 (epoch 25.303), train_loss = 0.96912064, grad/param norm = 1.4460e-01, time/batch = 18.6516s	
17030/33650 (epoch 25.305), train_loss = 0.95568115, grad/param norm = 1.5339e-01, time/batch = 17.0492s	
17031/33650 (epoch 25.306), train_loss = 0.87670216, grad/param norm = 1.3731e-01, time/batch = 18.9701s	
17032/33650 (epoch 25.308), train_loss = 0.82336223, grad/param norm = 1.5338e-01, time/batch = 18.3254s	
17033/33650 (epoch 25.309), train_loss = 1.09753736, grad/param norm = 1.7079e-01, time/batch = 17.7238s	
17034/33650 (epoch 25.311), train_loss = 0.96348032, grad/param norm = 2.1410e-01, time/batch = 18.3030s	
17035/33650 (epoch 25.312), train_loss = 0.96119117, grad/param norm = 1.5374e-01, time/batch = 18.1593s	
17036/33650 (epoch 25.314), train_loss = 0.84406948, grad/param norm = 1.3554e-01, time/batch = 17.1424s	
17037/33650 (epoch 25.315), train_loss = 0.92291124, grad/param norm = 2.0315e-01, time/batch = 17.5505s	
17038/33650 (epoch 25.316), train_loss = 0.89182625, grad/param norm = 1.7034e-01, time/batch = 18.6542s	
17039/33650 (epoch 25.318), train_loss = 0.84344912, grad/param norm = 1.4026e-01, time/batch = 18.4016s	
17040/33650 (epoch 25.319), train_loss = 0.86647615, grad/param norm = 1.3550e-01, time/batch = 16.5713s	
17041/33650 (epoch 25.321), train_loss = 0.88531710, grad/param norm = 1.4483e-01, time/batch = 15.7167s	
17042/33650 (epoch 25.322), train_loss = 0.95056040, grad/param norm = 1.8531e-01, time/batch = 18.6282s	
17043/33650 (epoch 25.324), train_loss = 0.99067626, grad/param norm = 1.6928e-01, time/batch = 17.8033s	
17044/33650 (epoch 25.325), train_loss = 0.98427876, grad/param norm = 1.6500e-01, time/batch = 18.4690s	
17045/33650 (epoch 25.327), train_loss = 0.86199950, grad/param norm = 1.3625e-01, time/batch = 17.2108s	
17046/33650 (epoch 25.328), train_loss = 0.97942208, grad/param norm = 1.5694e-01, time/batch = 17.8827s	
17047/33650 (epoch 25.330), train_loss = 0.87600775, grad/param norm = 1.3208e-01, time/batch = 16.8963s	
17048/33650 (epoch 25.331), train_loss = 0.78356631, grad/param norm = 1.2720e-01, time/batch = 18.8079s	
17049/33650 (epoch 25.333), train_loss = 0.90740235, grad/param norm = 1.5710e-01, time/batch = 18.9759s	
17050/33650 (epoch 25.334), train_loss = 0.91752419, grad/param norm = 1.5529e-01, time/batch = 17.3028s	
17051/33650 (epoch 25.336), train_loss = 1.03092391, grad/param norm = 1.5330e-01, time/batch = 17.3821s	
17052/33650 (epoch 25.337), train_loss = 0.78780236, grad/param norm = 1.3061e-01, time/batch = 18.7160s	
17053/33650 (epoch 25.339), train_loss = 0.88867899, grad/param norm = 1.4723e-01, time/batch = 16.6318s	
17054/33650 (epoch 25.340), train_loss = 1.04634574, grad/param norm = 1.6028e-01, time/batch = 16.6398s	
17055/33650 (epoch 25.342), train_loss = 0.77634821, grad/param norm = 1.4616e-01, time/batch = 18.3917s	
17056/33650 (epoch 25.343), train_loss = 0.99006312, grad/param norm = 1.6039e-01, time/batch = 17.5520s	
17057/33650 (epoch 25.345), train_loss = 0.92968565, grad/param norm = 1.7948e-01, time/batch = 17.1306s	
17058/33650 (epoch 25.346), train_loss = 0.65504834, grad/param norm = 1.3360e-01, time/batch = 18.0673s	
17059/33650 (epoch 25.348), train_loss = 0.82302255, grad/param norm = 1.4903e-01, time/batch = 18.3151s	
17060/33650 (epoch 25.349), train_loss = 0.77178147, grad/param norm = 1.4135e-01, time/batch = 17.6358s	
17061/33650 (epoch 25.351), train_loss = 1.01900540, grad/param norm = 1.6456e-01, time/batch = 18.8920s	
17062/33650 (epoch 25.352), train_loss = 0.89941683, grad/param norm = 1.4705e-01, time/batch = 17.9934s	
17063/33650 (epoch 25.354), train_loss = 1.08236099, grad/param norm = 2.1308e-01, time/batch = 17.1448s	
17064/33650 (epoch 25.355), train_loss = 1.07323532, grad/param norm = 1.5781e-01, time/batch = 17.9679s	
17065/33650 (epoch 25.357), train_loss = 0.75097379, grad/param norm = 1.4770e-01, time/batch = 18.9775s	
17066/33650 (epoch 25.358), train_loss = 1.01228899, grad/param norm = 1.6231e-01, time/batch = 17.9823s	
17067/33650 (epoch 25.360), train_loss = 1.01074369, grad/param norm = 1.9303e-01, time/batch = 15.4587s	
17068/33650 (epoch 25.361), train_loss = 0.96085040, grad/param norm = 1.5042e-01, time/batch = 17.7299s	
17069/33650 (epoch 25.363), train_loss = 0.91516306, grad/param norm = 1.3844e-01, time/batch = 18.8158s	
17070/33650 (epoch 25.364), train_loss = 0.91309299, grad/param norm = 1.4508e-01, time/batch = 17.3853s	
17071/33650 (epoch 25.366), train_loss = 1.00214226, grad/param norm = 1.6687e-01, time/batch = 18.2170s	
17072/33650 (epoch 25.367), train_loss = 0.97140850, grad/param norm = 1.4717e-01, time/batch = 16.0690s	
17073/33650 (epoch 25.368), train_loss = 0.85265374, grad/param norm = 1.3330e-01, time/batch = 16.8686s	
17074/33650 (epoch 25.370), train_loss = 0.91630143, grad/param norm = 1.4806e-01, time/batch = 17.0385s	
17075/33650 (epoch 25.371), train_loss = 0.71802811, grad/param norm = 1.2254e-01, time/batch = 18.8963s	
17076/33650 (epoch 25.373), train_loss = 0.82516003, grad/param norm = 1.3803e-01, time/batch = 16.8679s	
17077/33650 (epoch 25.374), train_loss = 0.82507799, grad/param norm = 1.3096e-01, time/batch = 15.7097s	
17078/33650 (epoch 25.376), train_loss = 0.92662905, grad/param norm = 1.8014e-01, time/batch = 17.8204s	
17079/33650 (epoch 25.377), train_loss = 0.94896377, grad/param norm = 1.6202e-01, time/batch = 19.0573s	
17080/33650 (epoch 25.379), train_loss = 0.97389590, grad/param norm = 1.4958e-01, time/batch = 16.9856s	
17081/33650 (epoch 25.380), train_loss = 0.75691752, grad/param norm = 1.5063e-01, time/batch = 17.0527s	
17082/33650 (epoch 25.382), train_loss = 0.89894875, grad/param norm = 1.3293e-01, time/batch = 19.1361s	
17083/33650 (epoch 25.383), train_loss = 0.91190685, grad/param norm = 1.4575e-01, time/batch = 18.5588s	
17084/33650 (epoch 25.385), train_loss = 0.99306073, grad/param norm = 1.5016e-01, time/batch = 16.3844s	
17085/33650 (epoch 25.386), train_loss = 0.85503835, grad/param norm = 1.3693e-01, time/batch = 17.6328s	
17086/33650 (epoch 25.388), train_loss = 0.98032842, grad/param norm = 1.4297e-01, time/batch = 16.7914s	
17087/33650 (epoch 25.389), train_loss = 0.88530330, grad/param norm = 1.5428e-01, time/batch = 17.2260s	
17088/33650 (epoch 25.391), train_loss = 0.73795811, grad/param norm = 1.2721e-01, time/batch = 17.6526s	
17089/33650 (epoch 25.392), train_loss = 0.94478223, grad/param norm = 1.5872e-01, time/batch = 18.8086s	
17090/33650 (epoch 25.394), train_loss = 0.95005020, grad/param norm = 1.6926e-01, time/batch = 18.3091s	
17091/33650 (epoch 25.395), train_loss = 0.97789301, grad/param norm = 1.4976e-01, time/batch = 17.3773s	
17092/33650 (epoch 25.397), train_loss = 1.05650260, grad/param norm = 1.7235e-01, time/batch = 17.4808s	
17093/33650 (epoch 25.398), train_loss = 0.98053351, grad/param norm = 1.4805e-01, time/batch = 17.4778s	
17094/33650 (epoch 25.400), train_loss = 0.94051591, grad/param norm = 1.8514e-01, time/batch = 16.7962s	
17095/33650 (epoch 25.401), train_loss = 0.87659996, grad/param norm = 1.6298e-01, time/batch = 17.2339s	
17096/33650 (epoch 25.403), train_loss = 0.99219892, grad/param norm = 1.5585e-01, time/batch = 19.2343s	
17097/33650 (epoch 25.404), train_loss = 0.93739569, grad/param norm = 1.5101e-01, time/batch = 17.9706s	
17098/33650 (epoch 25.406), train_loss = 0.93286516, grad/param norm = 1.5843e-01, time/batch = 18.3854s	
17099/33650 (epoch 25.407), train_loss = 0.90512173, grad/param norm = 1.5004e-01, time/batch = 18.8923s	
17100/33650 (epoch 25.409), train_loss = 0.96285006, grad/param norm = 1.5745e-01, time/batch = 17.2178s	
17101/33650 (epoch 25.410), train_loss = 0.90096370, grad/param norm = 1.3787e-01, time/batch = 17.9546s	
17102/33650 (epoch 25.412), train_loss = 0.91794849, grad/param norm = 1.3530e-01, time/batch = 18.4835s	
17103/33650 (epoch 25.413), train_loss = 0.89492527, grad/param norm = 1.6673e-01, time/batch = 18.3971s	
17104/33650 (epoch 25.415), train_loss = 1.01175636, grad/param norm = 1.7282e-01, time/batch = 15.2228s	
17105/33650 (epoch 25.416), train_loss = 1.07523506, grad/param norm = 1.6602e-01, time/batch = 17.8819s	
17106/33650 (epoch 25.418), train_loss = 0.84641743, grad/param norm = 1.3149e-01, time/batch = 18.2279s	
17107/33650 (epoch 25.419), train_loss = 0.87993955, grad/param norm = 1.6389e-01, time/batch = 17.9824s	
17108/33650 (epoch 25.421), train_loss = 0.90425505, grad/param norm = 1.3559e-01, time/batch = 16.9421s	
17109/33650 (epoch 25.422), train_loss = 1.04357146, grad/param norm = 1.4923e-01, time/batch = 18.3944s	
17110/33650 (epoch 25.423), train_loss = 0.84820635, grad/param norm = 1.2053e-01, time/batch = 16.1382s	
17111/33650 (epoch 25.425), train_loss = 0.93429609, grad/param norm = 1.6664e-01, time/batch = 16.7192s	
17112/33650 (epoch 25.426), train_loss = 1.06870251, grad/param norm = 1.8194e-01, time/batch = 18.8949s	
17113/33650 (epoch 25.428), train_loss = 0.87548911, grad/param norm = 1.5053e-01, time/batch = 18.8158s	
17114/33650 (epoch 25.429), train_loss = 0.98976388, grad/param norm = 1.7312e-01, time/batch = 17.3797s	
17115/33650 (epoch 25.431), train_loss = 1.08367462, grad/param norm = 1.8469e-01, time/batch = 17.9709s	
17116/33650 (epoch 25.432), train_loss = 1.09926472, grad/param norm = 1.8451e-01, time/batch = 18.6492s	
17117/33650 (epoch 25.434), train_loss = 0.97457371, grad/param norm = 1.5083e-01, time/batch = 18.2292s	
17118/33650 (epoch 25.435), train_loss = 0.94840588, grad/param norm = 1.7393e-01, time/batch = 18.8594s	
17119/33650 (epoch 25.437), train_loss = 0.96221766, grad/param norm = 1.6746e-01, time/batch = 18.8082s	
17120/33650 (epoch 25.438), train_loss = 0.91473557, grad/param norm = 1.9848e-01, time/batch = 18.4734s	
17121/33650 (epoch 25.440), train_loss = 0.93716321, grad/param norm = 1.8490e-01, time/batch = 17.9669s	
17122/33650 (epoch 25.441), train_loss = 0.95913709, grad/param norm = 1.6811e-01, time/batch = 18.3134s	
17123/33650 (epoch 25.443), train_loss = 1.00448233, grad/param norm = 1.4975e-01, time/batch = 17.7226s	
17124/33650 (epoch 25.444), train_loss = 0.92886647, grad/param norm = 1.5173e-01, time/batch = 16.9427s	
17125/33650 (epoch 25.446), train_loss = 0.96548301, grad/param norm = 1.6500e-01, time/batch = 18.6306s	
17126/33650 (epoch 25.447), train_loss = 1.05481281, grad/param norm = 1.6377e-01, time/batch = 19.0413s	
17127/33650 (epoch 25.449), train_loss = 1.09160136, grad/param norm = 2.0090e-01, time/batch = 18.1349s	
17128/33650 (epoch 25.450), train_loss = 1.10789763, grad/param norm = 1.6401e-01, time/batch = 17.2232s	
17129/33650 (epoch 25.452), train_loss = 1.10494913, grad/param norm = 1.7938e-01, time/batch = 17.9874s	
17130/33650 (epoch 25.453), train_loss = 1.08414003, grad/param norm = 1.7515e-01, time/batch = 17.8966s	
17131/33650 (epoch 25.455), train_loss = 0.91810205, grad/param norm = 1.5202e-01, time/batch = 18.1988s	
17132/33650 (epoch 25.456), train_loss = 0.94236895, grad/param norm = 1.6919e-01, time/batch = 18.3995s	
17133/33650 (epoch 25.458), train_loss = 0.92007501, grad/param norm = 1.6997e-01, time/batch = 18.9595s	
17134/33650 (epoch 25.459), train_loss = 0.97804562, grad/param norm = 1.8262e-01, time/batch = 17.2858s	
17135/33650 (epoch 25.461), train_loss = 1.06350197, grad/param norm = 1.7806e-01, time/batch = 17.8941s	
17136/33650 (epoch 25.462), train_loss = 1.05316911, grad/param norm = 1.7318e-01, time/batch = 18.8945s	
17137/33650 (epoch 25.464), train_loss = 0.94588307, grad/param norm = 1.9244e-01, time/batch = 18.2205s	
17138/33650 (epoch 25.465), train_loss = 0.97666597, grad/param norm = 1.8399e-01, time/batch = 16.7181s	
17139/33650 (epoch 25.467), train_loss = 0.98837700, grad/param norm = 1.4910e-01, time/batch = 17.7068s	
17140/33650 (epoch 25.468), train_loss = 1.09525810, grad/param norm = 1.4978e-01, time/batch = 18.5574s	
17141/33650 (epoch 25.470), train_loss = 1.15604079, grad/param norm = 1.7856e-01, time/batch = 18.3643s	
17142/33650 (epoch 25.471), train_loss = 0.96271010, grad/param norm = 1.5111e-01, time/batch = 17.6431s	
17143/33650 (epoch 25.473), train_loss = 0.93611319, grad/param norm = 1.4712e-01, time/batch = 18.5655s	
17144/33650 (epoch 25.474), train_loss = 1.05098227, grad/param norm = 1.6183e-01, time/batch = 16.8832s	
17145/33650 (epoch 25.475), train_loss = 1.01600663, grad/param norm = 1.6188e-01, time/batch = 16.5656s	
17146/33650 (epoch 25.477), train_loss = 1.06523803, grad/param norm = 1.6019e-01, time/batch = 17.7179s	
17147/33650 (epoch 25.478), train_loss = 1.03799517, grad/param norm = 1.7318e-01, time/batch = 17.9601s	
17148/33650 (epoch 25.480), train_loss = 1.04809059, grad/param norm = 1.7715e-01, time/batch = 18.4787s	
17149/33650 (epoch 25.481), train_loss = 1.09404932, grad/param norm = 1.6167e-01, time/batch = 17.5674s	
17150/33650 (epoch 25.483), train_loss = 0.80790134, grad/param norm = 1.5063e-01, time/batch = 18.8025s	
17151/33650 (epoch 25.484), train_loss = 0.94249408, grad/param norm = 1.6530e-01, time/batch = 18.3060s	
17152/33650 (epoch 25.486), train_loss = 1.11833131, grad/param norm = 1.9874e-01, time/batch = 18.3136s	
17153/33650 (epoch 25.487), train_loss = 1.10023060, grad/param norm = 1.6064e-01, time/batch = 17.9614s	
17154/33650 (epoch 25.489), train_loss = 1.12479850, grad/param norm = 1.6055e-01, time/batch = 17.0465s	
17155/33650 (epoch 25.490), train_loss = 0.86803526, grad/param norm = 1.6437e-01, time/batch = 17.9495s	
17156/33650 (epoch 25.492), train_loss = 1.00527260, grad/param norm = 1.5967e-01, time/batch = 18.5661s	
17157/33650 (epoch 25.493), train_loss = 0.80089435, grad/param norm = 1.2816e-01, time/batch = 16.8972s	
17158/33650 (epoch 25.495), train_loss = 0.96815318, grad/param norm = 1.4823e-01, time/batch = 18.3843s	
17159/33650 (epoch 25.496), train_loss = 1.00836394, grad/param norm = 1.6789e-01, time/batch = 18.7302s	
17160/33650 (epoch 25.498), train_loss = 0.87690945, grad/param norm = 1.3811e-01, time/batch = 17.7192s	
17161/33650 (epoch 25.499), train_loss = 0.95921287, grad/param norm = 1.3326e-01, time/batch = 17.9649s	
17162/33650 (epoch 25.501), train_loss = 0.93209897, grad/param norm = 1.3451e-01, time/batch = 18.9722s	
17163/33650 (epoch 25.502), train_loss = 0.97938959, grad/param norm = 1.7048e-01, time/batch = 18.3842s	
17164/33650 (epoch 25.504), train_loss = 1.05105771, grad/param norm = 1.8231e-01, time/batch = 17.4662s	
17165/33650 (epoch 25.505), train_loss = 0.91987885, grad/param norm = 1.7300e-01, time/batch = 16.1354s	
17166/33650 (epoch 25.507), train_loss = 1.06477704, grad/param norm = 1.5218e-01, time/batch = 17.6435s	
17167/33650 (epoch 25.508), train_loss = 0.93995935, grad/param norm = 1.5213e-01, time/batch = 17.0542s	
17168/33650 (epoch 25.510), train_loss = 0.95449383, grad/param norm = 1.4027e-01, time/batch = 17.9840s	
17169/33650 (epoch 25.511), train_loss = 1.15406675, grad/param norm = 1.9198e-01, time/batch = 18.8912s	
17170/33650 (epoch 25.513), train_loss = 1.00585149, grad/param norm = 1.5878e-01, time/batch = 18.6398s	
17171/33650 (epoch 25.514), train_loss = 1.05767273, grad/param norm = 1.7601e-01, time/batch = 17.8970s	
17172/33650 (epoch 25.516), train_loss = 0.97484676, grad/param norm = 1.5978e-01, time/batch = 18.5563s	
17173/33650 (epoch 25.517), train_loss = 0.97669843, grad/param norm = 1.5944e-01, time/batch = 17.1432s	
17174/33650 (epoch 25.519), train_loss = 1.01737384, grad/param norm = 1.5562e-01, time/batch = 16.8817s	
17175/33650 (epoch 25.520), train_loss = 0.82891918, grad/param norm = 1.2973e-01, time/batch = 17.4607s	
17176/33650 (epoch 25.522), train_loss = 0.94841621, grad/param norm = 1.5815e-01, time/batch = 18.2114s	
17177/33650 (epoch 25.523), train_loss = 0.91998158, grad/param norm = 1.6699e-01, time/batch = 17.9807s	
17178/33650 (epoch 25.525), train_loss = 0.76130382, grad/param norm = 1.2729e-01, time/batch = 17.8111s	
17179/33650 (epoch 25.526), train_loss = 1.05422125, grad/param norm = 1.5190e-01, time/batch = 18.2396s	
17180/33650 (epoch 25.527), train_loss = 0.90310351, grad/param norm = 1.4511e-01, time/batch = 17.8972s	
17181/33650 (epoch 25.529), train_loss = 0.95853436, grad/param norm = 1.5758e-01, time/batch = 17.4711s	
17182/33650 (epoch 25.530), train_loss = 0.90224128, grad/param norm = 1.5116e-01, time/batch = 18.8257s	
17183/33650 (epoch 25.532), train_loss = 1.04135468, grad/param norm = 1.8485e-01, time/batch = 18.3926s	
17184/33650 (epoch 25.533), train_loss = 0.94327914, grad/param norm = 1.5810e-01, time/batch = 17.8880s	
17185/33650 (epoch 25.535), train_loss = 1.08121501, grad/param norm = 1.7710e-01, time/batch = 18.2387s	
17186/33650 (epoch 25.536), train_loss = 0.95953761, grad/param norm = 1.6459e-01, time/batch = 17.3058s	
17187/33650 (epoch 25.538), train_loss = 1.00905970, grad/param norm = 1.7152e-01, time/batch = 18.6225s	
17188/33650 (epoch 25.539), train_loss = 0.78606957, grad/param norm = 1.4575e-01, time/batch = 18.2302s	
17189/33650 (epoch 25.541), train_loss = 1.04747196, grad/param norm = 1.5803e-01, time/batch = 16.0465s	
17190/33650 (epoch 25.542), train_loss = 0.98190346, grad/param norm = 2.1808e-01, time/batch = 17.7288s	
17191/33650 (epoch 25.544), train_loss = 1.12186603, grad/param norm = 2.3819e-01, time/batch = 16.5509s	
17192/33650 (epoch 25.545), train_loss = 0.84993434, grad/param norm = 1.4967e-01, time/batch = 18.6473s	
17193/33650 (epoch 25.547), train_loss = 1.00557654, grad/param norm = 1.5518e-01, time/batch = 17.3851s	
17194/33650 (epoch 25.548), train_loss = 1.13337036, grad/param norm = 1.7737e-01, time/batch = 17.5566s	
17195/33650 (epoch 25.550), train_loss = 0.99604657, grad/param norm = 1.7252e-01, time/batch = 18.4603s	
17196/33650 (epoch 25.551), train_loss = 0.98500821, grad/param norm = 1.8090e-01, time/batch = 17.9801s	
17197/33650 (epoch 25.553), train_loss = 0.84125130, grad/param norm = 1.5656e-01, time/batch = 17.8103s	
17198/33650 (epoch 25.554), train_loss = 1.12285539, grad/param norm = 1.7096e-01, time/batch = 18.2245s	
17199/33650 (epoch 25.556), train_loss = 1.03689336, grad/param norm = 2.0134e-01, time/batch = 19.3048s	
17200/33650 (epoch 25.557), train_loss = 1.08003311, grad/param norm = 2.2428e-01, time/batch = 18.5438s	
17201/33650 (epoch 25.559), train_loss = 1.22957986, grad/param norm = 1.8978e-01, time/batch = 16.8709s	
17202/33650 (epoch 25.560), train_loss = 1.16942134, grad/param norm = 1.8536e-01, time/batch = 19.4795s	
17203/33650 (epoch 25.562), train_loss = 1.10808026, grad/param norm = 1.5655e-01, time/batch = 18.7219s	
17204/33650 (epoch 25.563), train_loss = 1.00901511, grad/param norm = 1.6616e-01, time/batch = 17.8016s	
17205/33650 (epoch 25.565), train_loss = 0.96824523, grad/param norm = 1.5387e-01, time/batch = 19.1364s	
17206/33650 (epoch 25.566), train_loss = 0.95671442, grad/param norm = 1.5082e-01, time/batch = 15.0348s	
17207/33650 (epoch 25.568), train_loss = 1.00113222, grad/param norm = 1.8899e-01, time/batch = 17.8011s	
17208/33650 (epoch 25.569), train_loss = 0.89163771, grad/param norm = 1.3813e-01, time/batch = 17.2379s	
17209/33650 (epoch 25.571), train_loss = 1.07777223, grad/param norm = 1.6622e-01, time/batch = 18.6580s	
17210/33650 (epoch 25.572), train_loss = 1.02835531, grad/param norm = 1.4028e-01, time/batch = 17.8952s	
17211/33650 (epoch 25.574), train_loss = 0.90372620, grad/param norm = 1.7506e-01, time/batch = 17.8851s	
17212/33650 (epoch 25.575), train_loss = 0.96507016, grad/param norm = 1.6206e-01, time/batch = 18.0606s	
17213/33650 (epoch 25.577), train_loss = 0.93372044, grad/param norm = 1.6023e-01, time/batch = 18.7246s	
17214/33650 (epoch 25.578), train_loss = 1.05292734, grad/param norm = 1.6276e-01, time/batch = 17.2249s	
17215/33650 (epoch 25.579), train_loss = 1.01833300, grad/param norm = 1.6249e-01, time/batch = 19.2159s	
17216/33650 (epoch 25.581), train_loss = 1.10474331, grad/param norm = 1.6112e-01, time/batch = 17.8130s	
17217/33650 (epoch 25.582), train_loss = 1.00737468, grad/param norm = 1.4372e-01, time/batch = 25.1367s	
17218/33650 (epoch 25.584), train_loss = 0.99632385, grad/param norm = 1.5400e-01, time/batch = 24.0815s	
17219/33650 (epoch 25.585), train_loss = 1.02370622, grad/param norm = 1.6262e-01, time/batch = 18.5650s	
17220/33650 (epoch 25.587), train_loss = 0.89382938, grad/param norm = 1.6656e-01, time/batch = 17.0390s	
17221/33650 (epoch 25.588), train_loss = 0.92790859, grad/param norm = 1.8704e-01, time/batch = 17.3873s	
17222/33650 (epoch 25.590), train_loss = 0.91087325, grad/param norm = 1.3850e-01, time/batch = 18.7295s	
17223/33650 (epoch 25.591), train_loss = 0.88702876, grad/param norm = 1.6498e-01, time/batch = 17.5608s	
17224/33650 (epoch 25.593), train_loss = 0.87975694, grad/param norm = 1.4790e-01, time/batch = 19.2241s	
17225/33650 (epoch 25.594), train_loss = 0.86166910, grad/param norm = 1.6543e-01, time/batch = 16.7110s	
17226/33650 (epoch 25.596), train_loss = 0.95160398, grad/param norm = 1.4727e-01, time/batch = 17.5544s	
17227/33650 (epoch 25.597), train_loss = 0.81656957, grad/param norm = 1.3697e-01, time/batch = 18.4728s	
17228/33650 (epoch 25.599), train_loss = 0.94984547, grad/param norm = 1.5817e-01, time/batch = 18.6491s	
17229/33650 (epoch 25.600), train_loss = 0.87991691, grad/param norm = 1.4319e-01, time/batch = 18.0635s	
17230/33650 (epoch 25.602), train_loss = 0.99436632, grad/param norm = 1.4969e-01, time/batch = 16.9658s	
17231/33650 (epoch 25.603), train_loss = 0.89751600, grad/param norm = 1.5324e-01, time/batch = 19.5602s	
17232/33650 (epoch 25.605), train_loss = 1.02150740, grad/param norm = 1.6018e-01, time/batch = 18.0639s	
17233/33650 (epoch 25.606), train_loss = 0.98393145, grad/param norm = 1.7475e-01, time/batch = 16.6355s	
17234/33650 (epoch 25.608), train_loss = 0.87054310, grad/param norm = 1.6777e-01, time/batch = 18.6457s	
17235/33650 (epoch 25.609), train_loss = 0.94693501, grad/param norm = 1.4417e-01, time/batch = 18.2318s	
17236/33650 (epoch 25.611), train_loss = 0.85226681, grad/param norm = 1.4864e-01, time/batch = 17.4802s	
17237/33650 (epoch 25.612), train_loss = 0.96151358, grad/param norm = 1.8368e-01, time/batch = 17.9854s	
17238/33650 (epoch 25.614), train_loss = 1.05871675, grad/param norm = 1.6301e-01, time/batch = 18.6484s	
17239/33650 (epoch 25.615), train_loss = 0.95574048, grad/param norm = 1.3433e-01, time/batch = 18.5566s	
17240/33650 (epoch 25.617), train_loss = 0.86411365, grad/param norm = 1.2625e-01, time/batch = 17.3054s	
17241/33650 (epoch 25.618), train_loss = 0.92895062, grad/param norm = 1.5123e-01, time/batch = 19.1463s	
17242/33650 (epoch 25.620), train_loss = 0.94041705, grad/param norm = 1.6397e-01, time/batch = 17.2805s	
17243/33650 (epoch 25.621), train_loss = 0.87686685, grad/param norm = 1.5272e-01, time/batch = 15.8816s	
17244/33650 (epoch 25.623), train_loss = 0.92742145, grad/param norm = 1.4923e-01, time/batch = 18.3867s	
17245/33650 (epoch 25.624), train_loss = 0.76462999, grad/param norm = 1.5479e-01, time/batch = 17.8128s	
17246/33650 (epoch 25.626), train_loss = 0.78141224, grad/param norm = 1.3870e-01, time/batch = 18.2207s	
17247/33650 (epoch 25.627), train_loss = 0.87234667, grad/param norm = 1.4643e-01, time/batch = 17.7265s	
17248/33650 (epoch 25.629), train_loss = 0.91162780, grad/param norm = 1.7761e-01, time/batch = 18.2193s	
17249/33650 (epoch 25.630), train_loss = 1.04323775, grad/param norm = 1.6967e-01, time/batch = 18.5594s	
17250/33650 (epoch 25.632), train_loss = 1.07037199, grad/param norm = 1.5679e-01, time/batch = 18.2159s	
17251/33650 (epoch 25.633), train_loss = 1.01637500, grad/param norm = 1.5454e-01, time/batch = 17.6208s	
17252/33650 (epoch 25.634), train_loss = 0.84093126, grad/param norm = 1.3809e-01, time/batch = 18.7290s	
17253/33650 (epoch 25.636), train_loss = 0.73551634, grad/param norm = 1.1668e-01, time/batch = 17.3041s	
17254/33650 (epoch 25.637), train_loss = 0.88129807, grad/param norm = 1.4406e-01, time/batch = 15.9761s	
17255/33650 (epoch 25.639), train_loss = 0.88382230, grad/param norm = 1.5032e-01, time/batch = 17.7932s	
17256/33650 (epoch 25.640), train_loss = 0.95804734, grad/param norm = 1.5078e-01, time/batch = 17.8911s	
17257/33650 (epoch 25.642), train_loss = 1.01607100, grad/param norm = 1.6510e-01, time/batch = 16.9835s	
17258/33650 (epoch 25.643), train_loss = 0.96301426, grad/param norm = 1.6320e-01, time/batch = 18.0701s	
17259/33650 (epoch 25.645), train_loss = 0.96539059, grad/param norm = 1.4841e-01, time/batch = 18.6452s	
17260/33650 (epoch 25.646), train_loss = 0.82674480, grad/param norm = 1.2038e-01, time/batch = 17.5526s	
17261/33650 (epoch 25.648), train_loss = 0.98629794, grad/param norm = 1.5852e-01, time/batch = 19.3894s	
17262/33650 (epoch 25.649), train_loss = 0.89711149, grad/param norm = 1.5595e-01, time/batch = 18.1559s	
17263/33650 (epoch 25.651), train_loss = 1.04188720, grad/param norm = 1.6773e-01, time/batch = 17.1439s	
17264/33650 (epoch 25.652), train_loss = 0.70279677, grad/param norm = 1.3995e-01, time/batch = 18.4818s	
17265/33650 (epoch 25.654), train_loss = 0.86572856, grad/param norm = 1.5228e-01, time/batch = 18.4697s	
17266/33650 (epoch 25.655), train_loss = 0.83322333, grad/param norm = 1.4565e-01, time/batch = 17.1276s	
17267/33650 (epoch 25.657), train_loss = 0.91245635, grad/param norm = 1.5429e-01, time/batch = 18.3022s	
17268/33650 (epoch 25.658), train_loss = 0.77484615, grad/param norm = 1.4695e-01, time/batch = 17.4817s	
17269/33650 (epoch 25.660), train_loss = 0.77694118, grad/param norm = 1.4230e-01, time/batch = 18.0532s	
17270/33650 (epoch 25.661), train_loss = 0.84921121, grad/param norm = 1.3956e-01, time/batch = 17.1214s	
17271/33650 (epoch 25.663), train_loss = 0.81310594, grad/param norm = 1.4955e-01, time/batch = 17.6334s	
17272/33650 (epoch 25.664), train_loss = 0.88685631, grad/param norm = 1.5457e-01, time/batch = 18.7271s	
17273/33650 (epoch 25.666), train_loss = 0.90314083, grad/param norm = 1.3754e-01, time/batch = 16.5531s	
17274/33650 (epoch 25.667), train_loss = 0.81622844, grad/param norm = 1.2650e-01, time/batch = 17.8948s	
17275/33650 (epoch 25.669), train_loss = 0.82312863, grad/param norm = 1.5770e-01, time/batch = 19.3139s	
17276/33650 (epoch 25.670), train_loss = 0.76664977, grad/param norm = 1.3872e-01, time/batch = 17.3797s	
17277/33650 (epoch 25.672), train_loss = 0.79437223, grad/param norm = 1.4579e-01, time/batch = 17.8072s	
17278/33650 (epoch 25.673), train_loss = 0.77143536, grad/param norm = 1.4645e-01, time/batch = 18.6440s	
17279/33650 (epoch 25.675), train_loss = 0.72792453, grad/param norm = 1.1389e-01, time/batch = 17.1485s	
17280/33650 (epoch 25.676), train_loss = 0.91574357, grad/param norm = 1.5084e-01, time/batch = 16.4723s	
17281/33650 (epoch 25.678), train_loss = 0.88330668, grad/param norm = 1.4281e-01, time/batch = 18.2291s	
17282/33650 (epoch 25.679), train_loss = 0.88693741, grad/param norm = 1.7438e-01, time/batch = 19.3058s	
17283/33650 (epoch 25.681), train_loss = 0.89493720, grad/param norm = 1.2900e-01, time/batch = 16.7122s	
17284/33650 (epoch 25.682), train_loss = 0.82437601, grad/param norm = 1.6183e-01, time/batch = 17.8882s	
17285/33650 (epoch 25.684), train_loss = 0.80351999, grad/param norm = 1.4024e-01, time/batch = 18.2250s	
17286/33650 (epoch 25.685), train_loss = 0.95980614, grad/param norm = 1.5740e-01, time/batch = 17.5562s	
17287/33650 (epoch 25.686), train_loss = 0.90756981, grad/param norm = 1.4251e-01, time/batch = 18.0581s	
17288/33650 (epoch 25.688), train_loss = 0.99031817, grad/param norm = 1.5755e-01, time/batch = 16.4279s	
17289/33650 (epoch 25.689), train_loss = 0.84740727, grad/param norm = 1.5169e-01, time/batch = 18.5682s	
17290/33650 (epoch 25.691), train_loss = 1.03054690, grad/param norm = 2.1300e-01, time/batch = 16.7860s	
17291/33650 (epoch 25.692), train_loss = 1.03132312, grad/param norm = 1.5183e-01, time/batch = 18.2254s	
17292/33650 (epoch 25.694), train_loss = 0.95548283, grad/param norm = 1.6095e-01, time/batch = 16.6437s	
17293/33650 (epoch 25.695), train_loss = 0.66333293, grad/param norm = 1.3328e-01, time/batch = 17.3905s	
17294/33650 (epoch 25.697), train_loss = 0.88882461, grad/param norm = 1.5617e-01, time/batch = 18.3949s	
17295/33650 (epoch 25.698), train_loss = 1.05298104, grad/param norm = 1.6692e-01, time/batch = 18.7959s	
17296/33650 (epoch 25.700), train_loss = 0.90878956, grad/param norm = 1.4003e-01, time/batch = 17.6396s	
17297/33650 (epoch 25.701), train_loss = 0.92065760, grad/param norm = 1.4809e-01, time/batch = 17.5615s	
17298/33650 (epoch 25.703), train_loss = 1.11781916, grad/param norm = 1.5597e-01, time/batch = 16.0660s	
17299/33650 (epoch 25.704), train_loss = 0.89820896, grad/param norm = 1.3601e-01, time/batch = 14.6256s	
17300/33650 (epoch 25.706), train_loss = 0.86868004, grad/param norm = 1.2821e-01, time/batch = 14.8698s	
17301/33650 (epoch 25.707), train_loss = 1.00729197, grad/param norm = 1.4323e-01, time/batch = 17.8767s	
17302/33650 (epoch 25.709), train_loss = 0.90344482, grad/param norm = 1.5422e-01, time/batch = 17.8181s	
17303/33650 (epoch 25.710), train_loss = 1.09101830, grad/param norm = 1.6044e-01, time/batch = 16.6379s	
17304/33650 (epoch 25.712), train_loss = 0.82464437, grad/param norm = 1.3739e-01, time/batch = 16.3680s	
17305/33650 (epoch 25.713), train_loss = 0.81335667, grad/param norm = 1.6107e-01, time/batch = 16.7342s	
17306/33650 (epoch 25.715), train_loss = 0.97495419, grad/param norm = 1.6958e-01, time/batch = 17.7396s	
17307/33650 (epoch 25.716), train_loss = 0.86953765, grad/param norm = 1.4579e-01, time/batch = 16.3923s	
17308/33650 (epoch 25.718), train_loss = 0.87303312, grad/param norm = 1.5346e-01, time/batch = 17.4645s	
17309/33650 (epoch 25.719), train_loss = 1.02669743, grad/param norm = 1.7742e-01, time/batch = 18.5758s	
17310/33650 (epoch 25.721), train_loss = 1.12527038, grad/param norm = 1.9347e-01, time/batch = 17.6597s	
17311/33650 (epoch 25.722), train_loss = 0.98427712, grad/param norm = 2.1598e-01, time/batch = 18.3920s	
17312/33650 (epoch 25.724), train_loss = 1.04999629, grad/param norm = 1.5841e-01, time/batch = 18.2166s	
17313/33650 (epoch 25.725), train_loss = 1.00097674, grad/param norm = 1.5740e-01, time/batch = 15.5653s	
17314/33650 (epoch 25.727), train_loss = 0.86575942, grad/param norm = 2.0443e-01, time/batch = 14.8689s	
17315/33650 (epoch 25.728), train_loss = 0.90125452, grad/param norm = 1.5568e-01, time/batch = 14.8745s	
17316/33650 (epoch 25.730), train_loss = 0.96791947, grad/param norm = 1.5556e-01, time/batch = 18.3168s	
17317/33650 (epoch 25.731), train_loss = 1.05682823, grad/param norm = 1.6039e-01, time/batch = 19.2288s	
17318/33650 (epoch 25.733), train_loss = 0.91518010, grad/param norm = 1.6355e-01, time/batch = 18.1312s	
17319/33650 (epoch 25.734), train_loss = 1.06102752, grad/param norm = 1.7733e-01, time/batch = 17.6424s	
17320/33650 (epoch 25.736), train_loss = 0.92975478, grad/param norm = 1.8038e-01, time/batch = 19.0570s	
17321/33650 (epoch 25.737), train_loss = 0.97069154, grad/param norm = 1.6499e-01, time/batch = 17.4654s	
17322/33650 (epoch 25.738), train_loss = 0.85640217, grad/param norm = 1.4443e-01, time/batch = 17.5454s	
17323/33650 (epoch 25.740), train_loss = 0.78228839, grad/param norm = 1.3238e-01, time/batch = 17.5531s	
17324/33650 (epoch 25.741), train_loss = 0.86746746, grad/param norm = 1.6134e-01, time/batch = 17.5473s	
17325/33650 (epoch 25.743), train_loss = 0.93121598, grad/param norm = 1.5751e-01, time/batch = 17.3083s	
17326/33650 (epoch 25.744), train_loss = 0.99890846, grad/param norm = 1.4128e-01, time/batch = 17.9695s	
17327/33650 (epoch 25.746), train_loss = 0.89731859, grad/param norm = 1.4068e-01, time/batch = 18.2100s	
17328/33650 (epoch 25.747), train_loss = 1.03699114, grad/param norm = 1.5118e-01, time/batch = 17.3808s	
17329/33650 (epoch 25.749), train_loss = 0.78209585, grad/param norm = 1.3924e-01, time/batch = 17.8101s	
17330/33650 (epoch 25.750), train_loss = 1.08260095, grad/param norm = 1.6881e-01, time/batch = 17.7944s	
17331/33650 (epoch 25.752), train_loss = 1.01978290, grad/param norm = 1.4769e-01, time/batch = 17.0507s	
17332/33650 (epoch 25.753), train_loss = 1.11263804, grad/param norm = 1.6448e-01, time/batch = 17.8151s	
17333/33650 (epoch 25.755), train_loss = 0.88786657, grad/param norm = 1.3789e-01, time/batch = 17.4054s	
17334/33650 (epoch 25.756), train_loss = 1.01540803, grad/param norm = 1.6901e-01, time/batch = 17.7239s	
17335/33650 (epoch 25.758), train_loss = 1.00904813, grad/param norm = 1.4566e-01, time/batch = 15.6306s	
17336/33650 (epoch 25.759), train_loss = 1.05934199, grad/param norm = 1.9066e-01, time/batch = 18.7132s	
17337/33650 (epoch 25.761), train_loss = 0.95499823, grad/param norm = 1.5246e-01, time/batch = 18.8209s	
17338/33650 (epoch 25.762), train_loss = 0.94959683, grad/param norm = 1.6315e-01, time/batch = 16.8885s	
17339/33650 (epoch 25.764), train_loss = 0.98505627, grad/param norm = 1.6699e-01, time/batch = 18.5693s	
17340/33650 (epoch 25.765), train_loss = 0.90495902, grad/param norm = 1.5379e-01, time/batch = 18.4021s	
17341/33650 (epoch 25.767), train_loss = 0.92248269, grad/param norm = 1.4383e-01, time/batch = 17.4752s	
17342/33650 (epoch 25.768), train_loss = 0.82755309, grad/param norm = 1.6230e-01, time/batch = 17.7783s	
17343/33650 (epoch 25.770), train_loss = 0.98113728, grad/param norm = 1.6010e-01, time/batch = 18.0643s	
17344/33650 (epoch 25.771), train_loss = 0.96978513, grad/param norm = 1.5781e-01, time/batch = 17.1350s	
17345/33650 (epoch 25.773), train_loss = 1.04781333, grad/param norm = 1.7851e-01, time/batch = 17.5646s	
17346/33650 (epoch 25.774), train_loss = 0.96385544, grad/param norm = 1.5985e-01, time/batch = 18.9841s	
17347/33650 (epoch 25.776), train_loss = 1.03073299, grad/param norm = 1.6311e-01, time/batch = 17.9803s	
17348/33650 (epoch 25.777), train_loss = 0.85799370, grad/param norm = 1.3413e-01, time/batch = 16.5536s	
17349/33650 (epoch 25.779), train_loss = 0.90056946, grad/param norm = 1.4482e-01, time/batch = 19.0664s	
17350/33650 (epoch 25.780), train_loss = 0.82851348, grad/param norm = 1.3750e-01, time/batch = 18.1460s	
17351/33650 (epoch 25.782), train_loss = 0.85722277, grad/param norm = 1.5081e-01, time/batch = 17.0553s	
17352/33650 (epoch 25.783), train_loss = 0.85110094, grad/param norm = 1.2452e-01, time/batch = 17.9035s	
17353/33650 (epoch 25.785), train_loss = 1.10753702, grad/param norm = 1.4969e-01, time/batch = 18.4868s	
17354/33650 (epoch 25.786), train_loss = 1.00016998, grad/param norm = 1.4676e-01, time/batch = 17.8068s	
17355/33650 (epoch 25.788), train_loss = 0.97633498, grad/param norm = 1.5558e-01, time/batch = 18.0620s	
17356/33650 (epoch 25.789), train_loss = 1.03135862, grad/param norm = 1.5677e-01, time/batch = 16.4496s	
17357/33650 (epoch 25.790), train_loss = 0.95719962, grad/param norm = 1.8151e-01, time/batch = 18.4763s	
17358/33650 (epoch 25.792), train_loss = 1.04605007, grad/param norm = 1.7709e-01, time/batch = 16.9007s	
17359/33650 (epoch 25.793), train_loss = 1.02789265, grad/param norm = 1.9238e-01, time/batch = 18.5564s	
17360/33650 (epoch 25.795), train_loss = 1.05902586, grad/param norm = 1.6564e-01, time/batch = 18.3155s	
17361/33650 (epoch 25.796), train_loss = 0.92454377, grad/param norm = 1.5356e-01, time/batch = 17.4718s	
17362/33650 (epoch 25.798), train_loss = 0.89701086, grad/param norm = 1.5308e-01, time/batch = 19.0548s	
17363/33650 (epoch 25.799), train_loss = 0.92252946, grad/param norm = 1.3867e-01, time/batch = 17.9915s	
17364/33650 (epoch 25.801), train_loss = 0.95057559, grad/param norm = 1.7281e-01, time/batch = 17.3063s	
17365/33650 (epoch 25.802), train_loss = 1.04612493, grad/param norm = 1.6041e-01, time/batch = 17.8958s	
17366/33650 (epoch 25.804), train_loss = 0.96494898, grad/param norm = 1.8052e-01, time/batch = 18.6409s	
17367/33650 (epoch 25.805), train_loss = 0.93999579, grad/param norm = 1.4799e-01, time/batch = 19.1429s	
17368/33650 (epoch 25.807), train_loss = 1.15439474, grad/param norm = 1.9762e-01, time/batch = 17.4635s	
17369/33650 (epoch 25.808), train_loss = 1.18843948, grad/param norm = 1.8095e-01, time/batch = 18.4889s	
17370/33650 (epoch 25.810), train_loss = 0.97918933, grad/param norm = 1.7067e-01, time/batch = 18.2278s	
17371/33650 (epoch 25.811), train_loss = 0.97247557, grad/param norm = 1.6082e-01, time/batch = 17.4696s	
17372/33650 (epoch 25.813), train_loss = 0.88055327, grad/param norm = 1.4370e-01, time/batch = 18.6402s	
17373/33650 (epoch 25.814), train_loss = 1.03952620, grad/param norm = 1.5906e-01, time/batch = 18.5336s	
17374/33650 (epoch 25.816), train_loss = 1.01320065, grad/param norm = 1.6227e-01, time/batch = 17.7259s	
17375/33650 (epoch 25.817), train_loss = 1.05554318, grad/param norm = 1.7981e-01, time/batch = 16.5693s	
17376/33650 (epoch 25.819), train_loss = 0.97399785, grad/param norm = 1.4828e-01, time/batch = 19.1446s	
17377/33650 (epoch 25.820), train_loss = 1.06902557, grad/param norm = 1.6386e-01, time/batch = 18.1486s	
17378/33650 (epoch 25.822), train_loss = 1.00486912, grad/param norm = 2.0552e-01, time/batch = 17.0592s	
17379/33650 (epoch 25.823), train_loss = 0.90403530, grad/param norm = 1.7471e-01, time/batch = 17.8952s	
17380/33650 (epoch 25.825), train_loss = 0.93943176, grad/param norm = 1.5111e-01, time/batch = 17.4775s	
17381/33650 (epoch 25.826), train_loss = 1.01764358, grad/param norm = 1.4758e-01, time/batch = 16.6183s	
17382/33650 (epoch 25.828), train_loss = 1.12643850, grad/param norm = 1.9057e-01, time/batch = 18.7213s	
17383/33650 (epoch 25.829), train_loss = 0.79402706, grad/param norm = 1.3005e-01, time/batch = 19.1460s	
17384/33650 (epoch 25.831), train_loss = 0.96754028, grad/param norm = 1.4916e-01, time/batch = 17.3811s	
17385/33650 (epoch 25.832), train_loss = 1.03636041, grad/param norm = 1.6757e-01, time/batch = 18.2235s	
17386/33650 (epoch 25.834), train_loss = 1.03221247, grad/param norm = 1.5546e-01, time/batch = 18.3953s	
17387/33650 (epoch 25.835), train_loss = 1.17541278, grad/param norm = 1.7605e-01, time/batch = 18.2381s	
17388/33650 (epoch 25.837), train_loss = 0.99729758, grad/param norm = 2.0209e-01, time/batch = 17.0756s	
17389/33650 (epoch 25.838), train_loss = 0.97335523, grad/param norm = 1.6993e-01, time/batch = 16.4748s	
17390/33650 (epoch 25.840), train_loss = 1.03932735, grad/param norm = 1.7121e-01, time/batch = 18.3852s	
17391/33650 (epoch 25.841), train_loss = 0.92208976, grad/param norm = 1.5939e-01, time/batch = 16.9812s	
17392/33650 (epoch 25.842), train_loss = 0.94931486, grad/param norm = 1.5840e-01, time/batch = 18.2170s	
17393/33650 (epoch 25.844), train_loss = 1.13626800, grad/param norm = 1.5972e-01, time/batch = 18.2272s	
17394/33650 (epoch 25.845), train_loss = 0.91996444, grad/param norm = 1.5034e-01, time/batch = 16.5455s	
17395/33650 (epoch 25.847), train_loss = 0.73612849, grad/param norm = 1.3424e-01, time/batch = 18.4678s	
17396/33650 (epoch 25.848), train_loss = 0.84708313, grad/param norm = 1.7369e-01, time/batch = 17.2266s	
17397/33650 (epoch 25.850), train_loss = 0.92576903, grad/param norm = 1.6518e-01, time/batch = 17.9788s	
17398/33650 (epoch 25.851), train_loss = 0.78650832, grad/param norm = 1.2209e-01, time/batch = 17.0560s	
17399/33650 (epoch 25.853), train_loss = 0.95229919, grad/param norm = 1.8102e-01, time/batch = 18.9742s	
17400/33650 (epoch 25.854), train_loss = 1.05102929, grad/param norm = 1.6387e-01, time/batch = 18.9860s	
17401/33650 (epoch 25.856), train_loss = 0.74029398, grad/param norm = 1.4661e-01, time/batch = 15.8824s	
17402/33650 (epoch 25.857), train_loss = 0.96252311, grad/param norm = 1.4226e-01, time/batch = 17.3739s	
17403/33650 (epoch 25.859), train_loss = 0.84922182, grad/param norm = 1.3871e-01, time/batch = 17.9831s	
17404/33650 (epoch 25.860), train_loss = 0.81323088, grad/param norm = 1.4118e-01, time/batch = 17.8187s	
17405/33650 (epoch 25.862), train_loss = 0.86974231, grad/param norm = 1.5412e-01, time/batch = 17.4795s	
17406/33650 (epoch 25.863), train_loss = 1.08564812, grad/param norm = 1.5812e-01, time/batch = 18.6511s	
17407/33650 (epoch 25.865), train_loss = 0.90505166, grad/param norm = 1.3277e-01, time/batch = 17.4640s	
17408/33650 (epoch 25.866), train_loss = 0.85598812, grad/param norm = 1.4347e-01, time/batch = 17.7144s	
17409/33650 (epoch 25.868), train_loss = 0.82075385, grad/param norm = 1.5851e-01, time/batch = 18.1476s	
17410/33650 (epoch 25.869), train_loss = 1.01828270, grad/param norm = 1.5552e-01, time/batch = 17.9492s	
17411/33650 (epoch 25.871), train_loss = 0.83148535, grad/param norm = 1.4434e-01, time/batch = 17.3821s	
17412/33650 (epoch 25.872), train_loss = 0.97394200, grad/param norm = 1.5206e-01, time/batch = 18.3959s	
17413/33650 (epoch 25.874), train_loss = 1.00169605, grad/param norm = 1.5776e-01, time/batch = 18.7326s	
17414/33650 (epoch 25.875), train_loss = 0.93695335, grad/param norm = 1.5499e-01, time/batch = 17.6525s	
17415/33650 (epoch 25.877), train_loss = 1.10988247, grad/param norm = 1.5524e-01, time/batch = 16.7113s	
17416/33650 (epoch 25.878), train_loss = 0.67889238, grad/param norm = 1.2157e-01, time/batch = 18.8200s	
17417/33650 (epoch 25.880), train_loss = 0.97734728, grad/param norm = 1.6941e-01, time/batch = 18.3121s	
17418/33650 (epoch 25.881), train_loss = 0.89372990, grad/param norm = 1.6507e-01, time/batch = 31.8957s	
17419/33650 (epoch 25.883), train_loss = 0.95359902, grad/param norm = 1.4420e-01, time/batch = 18.0576s	
17420/33650 (epoch 25.884), train_loss = 1.07129123, grad/param norm = 1.9790e-01, time/batch = 17.8018s	
17421/33650 (epoch 25.886), train_loss = 1.02190376, grad/param norm = 1.8422e-01, time/batch = 17.8104s	
17422/33650 (epoch 25.887), train_loss = 0.81632625, grad/param norm = 1.3800e-01, time/batch = 17.1417s	
17423/33650 (epoch 25.889), train_loss = 0.93008089, grad/param norm = 1.5129e-01, time/batch = 18.2996s	
17424/33650 (epoch 25.890), train_loss = 0.99486686, grad/param norm = 1.4447e-01, time/batch = 16.5318s	
17425/33650 (epoch 25.892), train_loss = 0.91465590, grad/param norm = 1.7802e-01, time/batch = 18.2214s	
17426/33650 (epoch 25.893), train_loss = 0.98105349, grad/param norm = 1.5162e-01, time/batch = 18.7243s	
17427/33650 (epoch 25.895), train_loss = 1.06244012, grad/param norm = 1.5095e-01, time/batch = 17.5572s	
17428/33650 (epoch 25.896), train_loss = 0.88882893, grad/param norm = 2.1027e-01, time/batch = 18.2383s	
17429/33650 (epoch 25.897), train_loss = 0.79069068, grad/param norm = 1.4410e-01, time/batch = 18.1491s	
17430/33650 (epoch 25.899), train_loss = 0.83956230, grad/param norm = 1.3831e-01, time/batch = 17.7287s	
17431/33650 (epoch 25.900), train_loss = 0.79371646, grad/param norm = 1.5219e-01, time/batch = 18.1445s	
17432/33650 (epoch 25.902), train_loss = 0.95258470, grad/param norm = 1.6306e-01, time/batch = 17.5535s	
17433/33650 (epoch 25.903), train_loss = 0.89588710, grad/param norm = 1.4349e-01, time/batch = 19.0676s	
17434/33650 (epoch 25.905), train_loss = 1.07556163, grad/param norm = 2.1722e-01, time/batch = 17.8006s	
17435/33650 (epoch 25.906), train_loss = 0.86612454, grad/param norm = 1.4221e-01, time/batch = 17.9843s	
17436/33650 (epoch 25.908), train_loss = 0.90350339, grad/param norm = 1.3886e-01, time/batch = 17.9773s	
17437/33650 (epoch 25.909), train_loss = 0.88170990, grad/param norm = 1.4076e-01, time/batch = 17.7050s	
17438/33650 (epoch 25.911), train_loss = 0.78063169, grad/param norm = 1.3829e-01, time/batch = 17.2115s	
17439/33650 (epoch 25.912), train_loss = 0.75066843, grad/param norm = 1.6998e-01, time/batch = 17.0502s	
17440/33650 (epoch 25.914), train_loss = 0.95284723, grad/param norm = 1.3462e-01, time/batch = 18.0643s	
17441/33650 (epoch 25.915), train_loss = 0.90381775, grad/param norm = 1.6647e-01, time/batch = 17.7166s	
17442/33650 (epoch 25.917), train_loss = 0.90959517, grad/param norm = 1.8011e-01, time/batch = 19.0602s	
17443/33650 (epoch 25.918), train_loss = 0.80291936, grad/param norm = 1.2994e-01, time/batch = 18.3008s	
17444/33650 (epoch 25.920), train_loss = 0.83348450, grad/param norm = 1.3687e-01, time/batch = 18.1297s	
17445/33650 (epoch 25.921), train_loss = 0.84183019, grad/param norm = 1.5409e-01, time/batch = 18.6322s	
17446/33650 (epoch 25.923), train_loss = 0.78131607, grad/param norm = 1.5714e-01, time/batch = 18.3938s	
17447/33650 (epoch 25.924), train_loss = 0.94472387, grad/param norm = 1.7481e-01, time/batch = 17.7142s	
17448/33650 (epoch 25.926), train_loss = 0.87178467, grad/param norm = 1.6980e-01, time/batch = 17.7999s	
17449/33650 (epoch 25.927), train_loss = 0.89847503, grad/param norm = 1.4107e-01, time/batch = 18.9708s	
17450/33650 (epoch 25.929), train_loss = 0.99133572, grad/param norm = 1.5046e-01, time/batch = 17.5432s	
17451/33650 (epoch 25.930), train_loss = 0.90174949, grad/param norm = 1.6947e-01, time/batch = 17.9763s	
17452/33650 (epoch 25.932), train_loss = 0.88367923, grad/param norm = 1.4163e-01, time/batch = 18.7323s	
17453/33650 (epoch 25.933), train_loss = 0.79792661, grad/param norm = 1.4559e-01, time/batch = 15.5490s	
17454/33650 (epoch 25.935), train_loss = 0.81632566, grad/param norm = 1.4869e-01, time/batch = 18.4679s	
17455/33650 (epoch 25.936), train_loss = 0.86750258, grad/param norm = 1.5924e-01, time/batch = 16.4614s	
17456/33650 (epoch 25.938), train_loss = 0.80293516, grad/param norm = 1.5460e-01, time/batch = 18.2307s	
17457/33650 (epoch 25.939), train_loss = 0.99049987, grad/param norm = 1.4698e-01, time/batch = 17.4731s	
17458/33650 (epoch 25.941), train_loss = 0.92645187, grad/param norm = 1.5030e-01, time/batch = 18.1317s	
17459/33650 (epoch 25.942), train_loss = 1.02148161, grad/param norm = 1.6322e-01, time/batch = 18.7346s	
17460/33650 (epoch 25.944), train_loss = 0.89173571, grad/param norm = 1.4930e-01, time/batch = 17.6439s	
17461/33650 (epoch 25.945), train_loss = 0.94783001, grad/param norm = 1.4723e-01, time/batch = 18.3074s	
17462/33650 (epoch 25.947), train_loss = 1.07283100, grad/param norm = 2.1931e-01, time/batch = 19.1538s	
17463/33650 (epoch 25.948), train_loss = 1.04882633, grad/param norm = 1.5768e-01, time/batch = 17.8898s	
17464/33650 (epoch 25.949), train_loss = 0.80846565, grad/param norm = 1.5119e-01, time/batch = 17.9524s	
17465/33650 (epoch 25.951), train_loss = 1.05678268, grad/param norm = 1.6816e-01, time/batch = 18.5741s	
17466/33650 (epoch 25.952), train_loss = 0.97909534, grad/param norm = 1.6926e-01, time/batch = 19.1436s	
17467/33650 (epoch 25.954), train_loss = 0.98624656, grad/param norm = 1.4739e-01, time/batch = 16.9647s	
17468/33650 (epoch 25.955), train_loss = 0.97122600, grad/param norm = 1.6019e-01, time/batch = 18.2298s	
17469/33650 (epoch 25.957), train_loss = 0.98873495, grad/param norm = 1.8441e-01, time/batch = 18.0643s	
17470/33650 (epoch 25.958), train_loss = 0.73375413, grad/param norm = 1.3681e-01, time/batch = 17.0424s	
17471/33650 (epoch 25.960), train_loss = 0.75244599, grad/param norm = 1.2787e-01, time/batch = 16.9510s	
17472/33650 (epoch 25.961), train_loss = 0.81260632, grad/param norm = 1.5047e-01, time/batch = 18.5601s	
17473/33650 (epoch 25.963), train_loss = 0.85110164, grad/param norm = 1.7171e-01, time/batch = 18.2254s	
17474/33650 (epoch 25.964), train_loss = 0.99626982, grad/param norm = 1.5689e-01, time/batch = 17.8691s	
17475/33650 (epoch 25.966), train_loss = 0.94206660, grad/param norm = 2.0881e-01, time/batch = 18.5572s	
17476/33650 (epoch 25.967), train_loss = 0.96009103, grad/param norm = 1.5624e-01, time/batch = 17.4669s	
17477/33650 (epoch 25.969), train_loss = 0.91339753, grad/param norm = 1.4159e-01, time/batch = 17.3913s	
17478/33650 (epoch 25.970), train_loss = 0.94707830, grad/param norm = 1.6195e-01, time/batch = 18.2192s	
17479/33650 (epoch 25.972), train_loss = 1.22093094, grad/param norm = 1.8443e-01, time/batch = 17.7175s	
17480/33650 (epoch 25.973), train_loss = 0.84217040, grad/param norm = 1.3015e-01, time/batch = 14.3000s	
17481/33650 (epoch 25.975), train_loss = 0.82270398, grad/param norm = 1.2829e-01, time/batch = 16.9658s	
17482/33650 (epoch 25.976), train_loss = 0.83609836, grad/param norm = 1.2738e-01, time/batch = 18.7280s	
17483/33650 (epoch 25.978), train_loss = 0.86382536, grad/param norm = 1.4994e-01, time/batch = 18.8180s	
17484/33650 (epoch 25.979), train_loss = 0.90179589, grad/param norm = 1.4910e-01, time/batch = 17.3734s	
17485/33650 (epoch 25.981), train_loss = 0.87345877, grad/param norm = 1.2795e-01, time/batch = 19.0554s	
17486/33650 (epoch 25.982), train_loss = 0.93889324, grad/param norm = 1.4576e-01, time/batch = 18.8901s	
17487/33650 (epoch 25.984), train_loss = 0.77229832, grad/param norm = 1.3629e-01, time/batch = 16.5533s	
17488/33650 (epoch 25.985), train_loss = 0.80583664, grad/param norm = 1.5353e-01, time/batch = 18.3125s	
17489/33650 (epoch 25.987), train_loss = 0.92797751, grad/param norm = 1.4614e-01, time/batch = 16.4620s	
17490/33650 (epoch 25.988), train_loss = 0.91931162, grad/param norm = 1.6034e-01, time/batch = 17.8829s	
17491/33650 (epoch 25.990), train_loss = 1.07337853, grad/param norm = 1.7193e-01, time/batch = 17.1220s	
17492/33650 (epoch 25.991), train_loss = 0.95203524, grad/param norm = 1.5163e-01, time/batch = 18.8986s	
17493/33650 (epoch 25.993), train_loss = 0.94214203, grad/param norm = 1.7248e-01, time/batch = 17.6441s	
17494/33650 (epoch 25.994), train_loss = 0.90267073, grad/param norm = 1.4699e-01, time/batch = 16.5519s	
17495/33650 (epoch 25.996), train_loss = 0.85784597, grad/param norm = 1.5269e-01, time/batch = 18.9037s	
17496/33650 (epoch 25.997), train_loss = 0.98753467, grad/param norm = 1.5892e-01, time/batch = 18.1364s	
17497/33650 (epoch 25.999), train_loss = 0.83572022, grad/param norm = 1.3863e-01, time/batch = 17.0571s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
17498/33650 (epoch 26.000), train_loss = 0.99815932, grad/param norm = 1.7054e-01, time/batch = 18.7264s	
17499/33650 (epoch 26.001), train_loss = 1.07448444, grad/param norm = 1.6135e-01, time/batch = 18.8871s	
17500/33650 (epoch 26.003), train_loss = 1.05842893, grad/param norm = 1.7705e-01, time/batch = 18.2295s	
17501/33650 (epoch 26.004), train_loss = 0.95334473, grad/param norm = 1.5598e-01, time/batch = 17.5595s	
17502/33650 (epoch 26.006), train_loss = 0.88967408, grad/param norm = 1.4230e-01, time/batch = 16.8779s	
17503/33650 (epoch 26.007), train_loss = 0.99325377, grad/param norm = 1.5651e-01, time/batch = 19.2228s	
17504/33650 (epoch 26.009), train_loss = 0.88095736, grad/param norm = 1.5311e-01, time/batch = 18.0563s	
17505/33650 (epoch 26.010), train_loss = 1.02943942, grad/param norm = 1.7718e-01, time/batch = 17.5613s	
17506/33650 (epoch 26.012), train_loss = 0.87165102, grad/param norm = 1.5066e-01, time/batch = 19.4730s	
17507/33650 (epoch 26.013), train_loss = 0.90681478, grad/param norm = 1.5709e-01, time/batch = 16.9769s	
17508/33650 (epoch 26.015), train_loss = 0.91806808, grad/param norm = 1.6030e-01, time/batch = 18.9486s	
17509/33650 (epoch 26.016), train_loss = 0.82291632, grad/param norm = 1.4775e-01, time/batch = 17.3965s	
17510/33650 (epoch 26.018), train_loss = 0.90066631, grad/param norm = 1.7003e-01, time/batch = 17.4675s	
17511/33650 (epoch 26.019), train_loss = 0.87481607, grad/param norm = 1.5786e-01, time/batch = 18.3151s	
17512/33650 (epoch 26.021), train_loss = 0.95606117, grad/param norm = 1.4933e-01, time/batch = 17.3257s	
17513/33650 (epoch 26.022), train_loss = 0.87292417, grad/param norm = 1.4453e-01, time/batch = 17.4661s	
17514/33650 (epoch 26.024), train_loss = 0.84794778, grad/param norm = 1.5184e-01, time/batch = 16.9837s	
17515/33650 (epoch 26.025), train_loss = 0.93236787, grad/param norm = 1.6737e-01, time/batch = 18.3080s	
17516/33650 (epoch 26.027), train_loss = 0.95953048, grad/param norm = 1.7571e-01, time/batch = 18.0608s	
17517/33650 (epoch 26.028), train_loss = 0.99052030, grad/param norm = 1.5247e-01, time/batch = 16.7952s	
17518/33650 (epoch 26.030), train_loss = 0.92375887, grad/param norm = 1.7000e-01, time/batch = 19.3844s	
17519/33650 (epoch 26.031), train_loss = 0.85372196, grad/param norm = 1.3808e-01, time/batch = 17.9718s	
17520/33650 (epoch 26.033), train_loss = 0.91992103, grad/param norm = 1.3639e-01, time/batch = 17.7914s	
17521/33650 (epoch 26.034), train_loss = 0.95135054, grad/param norm = 1.6153e-01, time/batch = 18.6385s	
17522/33650 (epoch 26.036), train_loss = 1.05049999, grad/param norm = 1.8316e-01, time/batch = 18.1489s	
17523/33650 (epoch 26.037), train_loss = 0.88837793, grad/param norm = 1.4779e-01, time/batch = 18.4030s	
17524/33650 (epoch 26.039), train_loss = 1.00341536, grad/param norm = 1.4707e-01, time/batch = 16.6313s	
17525/33650 (epoch 26.040), train_loss = 1.11022202, grad/param norm = 1.9175e-01, time/batch = 18.1302s	
17526/33650 (epoch 26.042), train_loss = 1.12370588, grad/param norm = 1.7599e-01, time/batch = 19.2241s	
17527/33650 (epoch 26.043), train_loss = 0.87062958, grad/param norm = 1.3864e-01, time/batch = 16.7969s	
17528/33650 (epoch 26.045), train_loss = 0.88178817, grad/param norm = 1.4098e-01, time/batch = 18.4745s	
17529/33650 (epoch 26.046), train_loss = 0.96758559, grad/param norm = 1.4680e-01, time/batch = 17.1991s	
17530/33650 (epoch 26.048), train_loss = 1.01984316, grad/param norm = 1.6712e-01, time/batch = 13.9577s	
17531/33650 (epoch 26.049), train_loss = 0.92390293, grad/param norm = 1.5726e-01, time/batch = 16.3878s	
17532/33650 (epoch 26.051), train_loss = 1.07287888, grad/param norm = 1.5324e-01, time/batch = 18.3046s	
17533/33650 (epoch 26.052), train_loss = 1.06520336, grad/param norm = 1.8174e-01, time/batch = 18.5480s	
17534/33650 (epoch 26.053), train_loss = 0.99214921, grad/param norm = 1.5205e-01, time/batch = 16.9000s	
17535/33650 (epoch 26.055), train_loss = 0.84070853, grad/param norm = 1.5306e-01, time/batch = 19.3026s	
17536/33650 (epoch 26.056), train_loss = 0.81224903, grad/param norm = 1.1957e-01, time/batch = 17.8871s	
17537/33650 (epoch 26.058), train_loss = 1.00932280, grad/param norm = 1.8304e-01, time/batch = 18.2905s	
17538/33650 (epoch 26.059), train_loss = 0.98812597, grad/param norm = 1.6315e-01, time/batch = 18.1270s	
17539/33650 (epoch 26.061), train_loss = 1.02165009, grad/param norm = 1.7144e-01, time/batch = 18.7138s	
17540/33650 (epoch 26.062), train_loss = 0.97012225, grad/param norm = 1.4423e-01, time/batch = 18.5503s	
17541/33650 (epoch 26.064), train_loss = 0.90017878, grad/param norm = 1.3815e-01, time/batch = 17.3189s	
17542/33650 (epoch 26.065), train_loss = 0.90072998, grad/param norm = 1.5437e-01, time/batch = 18.3876s	
17543/33650 (epoch 26.067), train_loss = 0.82384408, grad/param norm = 1.2557e-01, time/batch = 18.1389s	
17544/33650 (epoch 26.068), train_loss = 0.92875005, grad/param norm = 1.6957e-01, time/batch = 16.5505s	
17545/33650 (epoch 26.070), train_loss = 0.98846437, grad/param norm = 1.6212e-01, time/batch = 18.6475s	
17546/33650 (epoch 26.071), train_loss = 0.89150732, grad/param norm = 1.3830e-01, time/batch = 17.9743s	
17547/33650 (epoch 26.073), train_loss = 0.99413874, grad/param norm = 1.7800e-01, time/batch = 17.2302s	
17548/33650 (epoch 26.074), train_loss = 1.06242944, grad/param norm = 1.5282e-01, time/batch = 17.8888s	
17549/33650 (epoch 26.076), train_loss = 1.00497008, grad/param norm = 1.6804e-01, time/batch = 18.2264s	
17550/33650 (epoch 26.077), train_loss = 0.93954906, grad/param norm = 1.4990e-01, time/batch = 15.6282s	
17551/33650 (epoch 26.079), train_loss = 0.97695567, grad/param norm = 1.4781e-01, time/batch = 18.2910s	
17552/33650 (epoch 26.080), train_loss = 0.97889270, grad/param norm = 1.4926e-01, time/batch = 18.9686s	
17553/33650 (epoch 26.082), train_loss = 0.93820477, grad/param norm = 1.4526e-01, time/batch = 17.2345s	
17554/33650 (epoch 26.083), train_loss = 0.98307398, grad/param norm = 1.6693e-01, time/batch = 17.3771s	
17555/33650 (epoch 26.085), train_loss = 1.01991573, grad/param norm = 1.4675e-01, time/batch = 18.3933s	
17556/33650 (epoch 26.086), train_loss = 1.00806234, grad/param norm = 1.7024e-01, time/batch = 17.7302s	
17557/33650 (epoch 26.088), train_loss = 0.95882172, grad/param norm = 1.5709e-01, time/batch = 17.5649s	
17558/33650 (epoch 26.089), train_loss = 0.89817094, grad/param norm = 1.5990e-01, time/batch = 16.3660s	
17559/33650 (epoch 26.091), train_loss = 0.89319220, grad/param norm = 1.3770e-01, time/batch = 18.6470s	
17560/33650 (epoch 26.092), train_loss = 0.91839999, grad/param norm = 1.5069e-01, time/batch = 18.3148s	
17561/33650 (epoch 26.094), train_loss = 1.00495794, grad/param norm = 1.4370e-01, time/batch = 17.7231s	
17562/33650 (epoch 26.095), train_loss = 1.00295674, grad/param norm = 1.8187e-01, time/batch = 17.7076s	
17563/33650 (epoch 26.097), train_loss = 0.87990131, grad/param norm = 1.6302e-01, time/batch = 18.6443s	
17564/33650 (epoch 26.098), train_loss = 0.76099900, grad/param norm = 1.3348e-01, time/batch = 17.7235s	
17565/33650 (epoch 26.100), train_loss = 0.87255953, grad/param norm = 1.4649e-01, time/batch = 19.0507s	
17566/33650 (epoch 26.101), train_loss = 0.94294431, grad/param norm = 1.5750e-01, time/batch = 18.9874s	
17567/33650 (epoch 26.103), train_loss = 0.91362764, grad/param norm = 1.6080e-01, time/batch = 18.0505s	
17568/33650 (epoch 26.104), train_loss = 1.05238867, grad/param norm = 1.4907e-01, time/batch = 16.8881s	
17569/33650 (epoch 26.105), train_loss = 0.94319894, grad/param norm = 1.5068e-01, time/batch = 18.9010s	
17570/33650 (epoch 26.107), train_loss = 0.88713371, grad/param norm = 1.5387e-01, time/batch = 18.4755s	
17571/33650 (epoch 26.108), train_loss = 0.99117024, grad/param norm = 1.6216e-01, time/batch = 17.5533s	
17572/33650 (epoch 26.110), train_loss = 1.10053028, grad/param norm = 1.5578e-01, time/batch = 17.3726s	
17573/33650 (epoch 26.111), train_loss = 0.90486039, grad/param norm = 1.4901e-01, time/batch = 18.6602s	
17574/33650 (epoch 26.113), train_loss = 0.91822616, grad/param norm = 1.6003e-01, time/batch = 16.8955s	
17575/33650 (epoch 26.114), train_loss = 0.99657215, grad/param norm = 1.5484e-01, time/batch = 18.0691s	
17576/33650 (epoch 26.116), train_loss = 0.85185354, grad/param norm = 1.3636e-01, time/batch = 17.9815s	
17577/33650 (epoch 26.117), train_loss = 0.93282438, grad/param norm = 1.3686e-01, time/batch = 17.0494s	
17578/33650 (epoch 26.119), train_loss = 0.83949599, grad/param norm = 1.3984e-01, time/batch = 18.5657s	
17579/33650 (epoch 26.120), train_loss = 0.90314742, grad/param norm = 1.5911e-01, time/batch = 18.5572s	
17580/33650 (epoch 26.122), train_loss = 0.73571685, grad/param norm = 1.7011e-01, time/batch = 18.1409s	
17581/33650 (epoch 26.123), train_loss = 0.88968389, grad/param norm = 1.3511e-01, time/batch = 18.0726s	
17582/33650 (epoch 26.125), train_loss = 0.98102935, grad/param norm = 1.5315e-01, time/batch = 18.7199s	
17583/33650 (epoch 26.126), train_loss = 1.05005582, grad/param norm = 2.0778e-01, time/batch = 19.2227s	
17584/33650 (epoch 26.128), train_loss = 0.98606807, grad/param norm = 1.6996e-01, time/batch = 17.7114s	
17585/33650 (epoch 26.129), train_loss = 1.03403244, grad/param norm = 1.6865e-01, time/batch = 17.4654s	
17586/33650 (epoch 26.131), train_loss = 0.95113093, grad/param norm = 1.4608e-01, time/batch = 17.4077s	
17587/33650 (epoch 26.132), train_loss = 0.94077206, grad/param norm = 1.5147e-01, time/batch = 17.9733s	
17588/33650 (epoch 26.134), train_loss = 1.01807132, grad/param norm = 1.5707e-01, time/batch = 17.7167s	
17589/33650 (epoch 26.135), train_loss = 0.82766097, grad/param norm = 1.4233e-01, time/batch = 17.3885s	
17590/33650 (epoch 26.137), train_loss = 0.98476573, grad/param norm = 2.1273e-01, time/batch = 18.5559s	
17591/33650 (epoch 26.138), train_loss = 0.99396097, grad/param norm = 1.5357e-01, time/batch = 17.6396s	
17592/33650 (epoch 26.140), train_loss = 0.94120783, grad/param norm = 1.8991e-01, time/batch = 19.3782s	
17593/33650 (epoch 26.141), train_loss = 1.07078658, grad/param norm = 1.6286e-01, time/batch = 18.0555s	
17594/33650 (epoch 26.143), train_loss = 1.10685105, grad/param norm = 2.0028e-01, time/batch = 16.4618s	
17595/33650 (epoch 26.144), train_loss = 0.98561654, grad/param norm = 1.6577e-01, time/batch = 18.7220s	
17596/33650 (epoch 26.146), train_loss = 0.91764520, grad/param norm = 1.5017e-01, time/batch = 18.4794s	
17597/33650 (epoch 26.147), train_loss = 0.88372155, grad/param norm = 1.4587e-01, time/batch = 16.8787s	
17598/33650 (epoch 26.149), train_loss = 0.82873752, grad/param norm = 1.4974e-01, time/batch = 17.4529s	
17599/33650 (epoch 26.150), train_loss = 0.81296796, grad/param norm = 1.4383e-01, time/batch = 17.6335s	
17600/33650 (epoch 26.152), train_loss = 0.88691438, grad/param norm = 1.5417e-01, time/batch = 18.0524s	
17601/33650 (epoch 26.153), train_loss = 0.91913795, grad/param norm = 1.5254e-01, time/batch = 18.3803s	
17602/33650 (epoch 26.155), train_loss = 0.87104420, grad/param norm = 1.3465e-01, time/batch = 18.8887s	
17603/33650 (epoch 26.156), train_loss = 0.84891428, grad/param norm = 1.3043e-01, time/batch = 18.2272s	
17604/33650 (epoch 26.158), train_loss = 0.96961906, grad/param norm = 1.4015e-01, time/batch = 17.2000s	
17605/33650 (epoch 26.159), train_loss = 0.85924762, grad/param norm = 1.3156e-01, time/batch = 17.5589s	
17606/33650 (epoch 26.160), train_loss = 0.88051037, grad/param norm = 1.3744e-01, time/batch = 18.2331s	
17607/33650 (epoch 26.162), train_loss = 0.89922122, grad/param norm = 1.5461e-01, time/batch = 17.7969s	
17608/33650 (epoch 26.163), train_loss = 0.97616245, grad/param norm = 1.7238e-01, time/batch = 17.6326s	
17609/33650 (epoch 26.165), train_loss = 0.83278588, grad/param norm = 1.5365e-01, time/batch = 18.7300s	
17610/33650 (epoch 26.166), train_loss = 0.83996735, grad/param norm = 1.5649e-01, time/batch = 17.5665s	
17611/33650 (epoch 26.168), train_loss = 1.02454534, grad/param norm = 1.6189e-01, time/batch = 17.4014s	
17612/33650 (epoch 26.169), train_loss = 0.95981866, grad/param norm = 1.5247e-01, time/batch = 18.8277s	
17613/33650 (epoch 26.171), train_loss = 0.92005280, grad/param norm = 1.4261e-01, time/batch = 19.0569s	
17614/33650 (epoch 26.172), train_loss = 0.87837031, grad/param norm = 1.4297e-01, time/batch = 17.2865s	
17615/33650 (epoch 26.174), train_loss = 0.85363217, grad/param norm = 1.4236e-01, time/batch = 14.7162s	
17616/33650 (epoch 26.175), train_loss = 0.82231924, grad/param norm = 1.4949e-01, time/batch = 14.5349s	
17617/33650 (epoch 26.177), train_loss = 0.92110932, grad/param norm = 1.6539e-01, time/batch = 17.3458s	
17618/33650 (epoch 26.178), train_loss = 0.87835231, grad/param norm = 1.8336e-01, time/batch = 26.6137s	
17619/33650 (epoch 26.180), train_loss = 0.82745515, grad/param norm = 1.3432e-01, time/batch = 18.1451s	
17620/33650 (epoch 26.181), train_loss = 0.74746088, grad/param norm = 1.3349e-01, time/batch = 17.3114s	
17621/33650 (epoch 26.183), train_loss = 0.87302935, grad/param norm = 1.8769e-01, time/batch = 18.5627s	
17622/33650 (epoch 26.184), train_loss = 0.86344753, grad/param norm = 1.7720e-01, time/batch = 18.6399s	
17623/33650 (epoch 26.186), train_loss = 0.92486001, grad/param norm = 1.7132e-01, time/batch = 18.2229s	
17624/33650 (epoch 26.187), train_loss = 1.07724433, grad/param norm = 1.6964e-01, time/batch = 17.6372s	
17625/33650 (epoch 26.189), train_loss = 1.02487417, grad/param norm = 1.8552e-01, time/batch = 18.5629s	
17626/33650 (epoch 26.190), train_loss = 0.95783279, grad/param norm = 1.6750e-01, time/batch = 16.2217s	
17627/33650 (epoch 26.192), train_loss = 1.10447199, grad/param norm = 1.6433e-01, time/batch = 16.4765s	
17628/33650 (epoch 26.193), train_loss = 1.06778556, grad/param norm = 1.5633e-01, time/batch = 17.9763s	
17629/33650 (epoch 26.195), train_loss = 0.81393395, grad/param norm = 1.3882e-01, time/batch = 18.4871s	
17630/33650 (epoch 26.196), train_loss = 0.78788175, grad/param norm = 1.4363e-01, time/batch = 17.3822s	
17631/33650 (epoch 26.198), train_loss = 0.88321296, grad/param norm = 1.5393e-01, time/batch = 18.2296s	
17632/33650 (epoch 26.199), train_loss = 1.00607160, grad/param norm = 1.8654e-01, time/batch = 19.0598s	
17633/33650 (epoch 26.201), train_loss = 0.90679054, grad/param norm = 1.6484e-01, time/batch = 17.1377s	
17634/33650 (epoch 26.202), train_loss = 0.89471281, grad/param norm = 1.5052e-01, time/batch = 18.0263s	
17635/33650 (epoch 26.204), train_loss = 0.97122389, grad/param norm = 1.5150e-01, time/batch = 18.8205s	
17636/33650 (epoch 26.205), train_loss = 0.89503696, grad/param norm = 1.5642e-01, time/batch = 19.0629s	
17637/33650 (epoch 26.207), train_loss = 0.87291429, grad/param norm = 1.7131e-01, time/batch = 17.2244s	
17638/33650 (epoch 26.208), train_loss = 0.94947111, grad/param norm = 1.5411e-01, time/batch = 17.7916s	
17639/33650 (epoch 26.210), train_loss = 0.76791023, grad/param norm = 1.5794e-01, time/batch = 18.8941s	
17640/33650 (epoch 26.211), train_loss = 0.87066575, grad/param norm = 1.6763e-01, time/batch = 17.0667s	
17641/33650 (epoch 26.212), train_loss = 0.99149238, grad/param norm = 1.9491e-01, time/batch = 17.5442s	
17642/33650 (epoch 26.214), train_loss = 1.09654652, grad/param norm = 1.6329e-01, time/batch = 18.7272s	
17643/33650 (epoch 26.215), train_loss = 0.72020514, grad/param norm = 1.7256e-01, time/batch = 17.8084s	
17644/33650 (epoch 26.217), train_loss = 0.91610611, grad/param norm = 1.9680e-01, time/batch = 16.8151s	
17645/33650 (epoch 26.218), train_loss = 0.93295833, grad/param norm = 1.4768e-01, time/batch = 19.2284s	
17646/33650 (epoch 26.220), train_loss = 0.81425373, grad/param norm = 1.4916e-01, time/batch = 17.8923s	
17647/33650 (epoch 26.221), train_loss = 1.09868466, grad/param norm = 1.7627e-01, time/batch = 16.9827s	
17648/33650 (epoch 26.223), train_loss = 0.74727327, grad/param norm = 1.3875e-01, time/batch = 17.8976s	
17649/33650 (epoch 26.224), train_loss = 0.86420543, grad/param norm = 1.6628e-01, time/batch = 18.7352s	
17650/33650 (epoch 26.226), train_loss = 1.19830817, grad/param norm = 1.7688e-01, time/batch = 17.4034s	
17651/33650 (epoch 26.227), train_loss = 1.05401849, grad/param norm = 1.7475e-01, time/batch = 17.9769s	
17652/33650 (epoch 26.229), train_loss = 1.04268999, grad/param norm = 1.6335e-01, time/batch = 19.0629s	
17653/33650 (epoch 26.230), train_loss = 1.19807471, grad/param norm = 2.0564e-01, time/batch = 17.5601s	
17654/33650 (epoch 26.232), train_loss = 1.03371742, grad/param norm = 2.4594e-01, time/batch = 18.3096s	
17655/33650 (epoch 26.233), train_loss = 0.98706648, grad/param norm = 2.0584e-01, time/batch = 16.4712s	
17656/33650 (epoch 26.235), train_loss = 0.93316970, grad/param norm = 1.5357e-01, time/batch = 19.4796s	
17657/33650 (epoch 26.236), train_loss = 0.84691177, grad/param norm = 1.4267e-01, time/batch = 17.3708s	
17658/33650 (epoch 26.238), train_loss = 0.89693365, grad/param norm = 1.3713e-01, time/batch = 18.0673s	
17659/33650 (epoch 26.239), train_loss = 0.86221559, grad/param norm = 1.6001e-01, time/batch = 18.4836s	
17660/33650 (epoch 26.241), train_loss = 0.89596852, grad/param norm = 1.4432e-01, time/batch = 17.1376s	
17661/33650 (epoch 26.242), train_loss = 0.75583156, grad/param norm = 1.5099e-01, time/batch = 17.7097s	
17662/33650 (epoch 26.244), train_loss = 0.91791855, grad/param norm = 1.5939e-01, time/batch = 17.5602s	
17663/33650 (epoch 26.245), train_loss = 0.80586503, grad/param norm = 1.3724e-01, time/batch = 15.9618s	
17664/33650 (epoch 26.247), train_loss = 0.92063817, grad/param norm = 1.4537e-01, time/batch = 17.8959s	
17665/33650 (epoch 26.248), train_loss = 0.82164340, grad/param norm = 1.4306e-01, time/batch = 18.3115s	
17666/33650 (epoch 26.250), train_loss = 0.91016595, grad/param norm = 1.4514e-01, time/batch = 18.4777s	
17667/33650 (epoch 26.251), train_loss = 1.04131145, grad/param norm = 1.4816e-01, time/batch = 16.8854s	
17668/33650 (epoch 26.253), train_loss = 0.80395234, grad/param norm = 1.5084e-01, time/batch = 18.0597s	
17669/33650 (epoch 26.254), train_loss = 0.86580678, grad/param norm = 1.5853e-01, time/batch = 19.1493s	
17670/33650 (epoch 26.256), train_loss = 1.05505395, grad/param norm = 1.4139e-01, time/batch = 16.7310s	
17671/33650 (epoch 26.257), train_loss = 1.04196325, grad/param norm = 1.6321e-01, time/batch = 17.1310s	
17672/33650 (epoch 26.259), train_loss = 0.80239208, grad/param norm = 1.5735e-01, time/batch = 18.1356s	
17673/33650 (epoch 26.260), train_loss = 0.99532526, grad/param norm = 1.5229e-01, time/batch = 18.5630s	
17674/33650 (epoch 26.262), train_loss = 0.94454526, grad/param norm = 1.9108e-01, time/batch = 16.8737s	
17675/33650 (epoch 26.263), train_loss = 0.88201090, grad/param norm = 1.7545e-01, time/batch = 18.9791s	
17676/33650 (epoch 26.264), train_loss = 0.97321720, grad/param norm = 1.6278e-01, time/batch = 18.6436s	
17677/33650 (epoch 26.266), train_loss = 0.96593255, grad/param norm = 1.5057e-01, time/batch = 17.2064s	
17678/33650 (epoch 26.267), train_loss = 0.88734196, grad/param norm = 1.6924e-01, time/batch = 18.9695s	
17679/33650 (epoch 26.269), train_loss = 0.94314005, grad/param norm = 1.6291e-01, time/batch = 18.1517s	
17680/33650 (epoch 26.270), train_loss = 0.84435282, grad/param norm = 1.4777e-01, time/batch = 17.5572s	
17681/33650 (epoch 26.272), train_loss = 0.90786368, grad/param norm = 1.5021e-01, time/batch = 18.0708s	
17682/33650 (epoch 26.273), train_loss = 1.03032335, grad/param norm = 1.6929e-01, time/batch = 17.7363s	
17683/33650 (epoch 26.275), train_loss = 0.99121837, grad/param norm = 1.6668e-01, time/batch = 18.3941s	
17684/33650 (epoch 26.276), train_loss = 1.02045767, grad/param norm = 2.0355e-01, time/batch = 17.5541s	
17685/33650 (epoch 26.278), train_loss = 1.08941437, grad/param norm = 1.7468e-01, time/batch = 18.9760s	
17686/33650 (epoch 26.279), train_loss = 0.90195888, grad/param norm = 1.4728e-01, time/batch = 18.6428s	
17687/33650 (epoch 26.281), train_loss = 0.95238377, grad/param norm = 1.5290e-01, time/batch = 17.3059s	
17688/33650 (epoch 26.282), train_loss = 1.03827905, grad/param norm = 1.4057e-01, time/batch = 18.8039s	
17689/33650 (epoch 26.284), train_loss = 1.01013422, grad/param norm = 1.7870e-01, time/batch = 19.0542s	
17690/33650 (epoch 26.285), train_loss = 0.98510413, grad/param norm = 1.6610e-01, time/batch = 17.3934s	
17691/33650 (epoch 26.287), train_loss = 0.89033037, grad/param norm = 1.7681e-01, time/batch = 16.4506s	
17692/33650 (epoch 26.288), train_loss = 0.96640595, grad/param norm = 1.9865e-01, time/batch = 17.8299s	
17693/33650 (epoch 26.290), train_loss = 0.93030654, grad/param norm = 1.4022e-01, time/batch = 17.2263s	
17694/33650 (epoch 26.291), train_loss = 0.84413999, grad/param norm = 1.3913e-01, time/batch = 16.7347s	
17695/33650 (epoch 26.293), train_loss = 0.92605959, grad/param norm = 1.8418e-01, time/batch = 17.8138s	
17696/33650 (epoch 26.294), train_loss = 0.84986533, grad/param norm = 1.3751e-01, time/batch = 16.7796s	
17697/33650 (epoch 26.296), train_loss = 0.84932140, grad/param norm = 1.5119e-01, time/batch = 16.8039s	
17698/33650 (epoch 26.297), train_loss = 0.89284604, grad/param norm = 1.5150e-01, time/batch = 18.4716s	
17699/33650 (epoch 26.299), train_loss = 0.80316041, grad/param norm = 1.5529e-01, time/batch = 18.3974s	
17700/33650 (epoch 26.300), train_loss = 0.81886593, grad/param norm = 1.5158e-01, time/batch = 16.6504s	
17701/33650 (epoch 26.302), train_loss = 0.95468768, grad/param norm = 1.4602e-01, time/batch = 18.4585s	
17702/33650 (epoch 26.303), train_loss = 0.95150016, grad/param norm = 1.4534e-01, time/batch = 18.5517s	
17703/33650 (epoch 26.305), train_loss = 0.92879907, grad/param norm = 1.6019e-01, time/batch = 18.9779s	
17704/33650 (epoch 26.306), train_loss = 0.86046622, grad/param norm = 1.4198e-01, time/batch = 17.2239s	
17705/33650 (epoch 26.308), train_loss = 0.81417583, grad/param norm = 1.5702e-01, time/batch = 19.2275s	
17706/33650 (epoch 26.309), train_loss = 1.09435116, grad/param norm = 1.8484e-01, time/batch = 18.3952s	
17707/33650 (epoch 26.311), train_loss = 0.94739093, grad/param norm = 2.1855e-01, time/batch = 16.3795s	
17708/33650 (epoch 26.312), train_loss = 0.94466150, grad/param norm = 1.5618e-01, time/batch = 18.3905s	
17709/33650 (epoch 26.314), train_loss = 0.82916032, grad/param norm = 1.3960e-01, time/batch = 18.2159s	
17710/33650 (epoch 26.315), train_loss = 0.90735861, grad/param norm = 1.7815e-01, time/batch = 17.7215s	
17711/33650 (epoch 26.316), train_loss = 0.88346488, grad/param norm = 1.6994e-01, time/batch = 19.1454s	
17712/33650 (epoch 26.318), train_loss = 0.81364236, grad/param norm = 1.3371e-01, time/batch = 18.5603s	
17713/33650 (epoch 26.319), train_loss = 0.85620440, grad/param norm = 1.4687e-01, time/batch = 18.4713s	
17714/33650 (epoch 26.321), train_loss = 0.87524818, grad/param norm = 1.4045e-01, time/batch = 17.5553s	
17715/33650 (epoch 26.322), train_loss = 0.95334210, grad/param norm = 2.1595e-01, time/batch = 18.3877s	
17716/33650 (epoch 26.324), train_loss = 1.00012167, grad/param norm = 2.2485e-01, time/batch = 16.4693s	
17717/33650 (epoch 26.325), train_loss = 0.98178882, grad/param norm = 1.6374e-01, time/batch = 17.3880s	
17718/33650 (epoch 26.327), train_loss = 0.85293659, grad/param norm = 1.3443e-01, time/batch = 18.3096s	
17719/33650 (epoch 26.328), train_loss = 0.98145552, grad/param norm = 1.7574e-01, time/batch = 19.1450s	
17720/33650 (epoch 26.330), train_loss = 0.87242378, grad/param norm = 1.4070e-01, time/batch = 16.7049s	
17721/33650 (epoch 26.331), train_loss = 0.78297543, grad/param norm = 1.2397e-01, time/batch = 19.4774s	
17722/33650 (epoch 26.333), train_loss = 0.90128384, grad/param norm = 1.5563e-01, time/batch = 19.2312s	
17723/33650 (epoch 26.334), train_loss = 0.90238616, grad/param norm = 1.4955e-01, time/batch = 17.6264s	
17724/33650 (epoch 26.336), train_loss = 1.01833329, grad/param norm = 1.5469e-01, time/batch = 17.2983s	
17725/33650 (epoch 26.337), train_loss = 0.76870839, grad/param norm = 1.2969e-01, time/batch = 18.6522s	
17726/33650 (epoch 26.339), train_loss = 0.87341428, grad/param norm = 1.4609e-01, time/batch = 18.9762s	
17727/33650 (epoch 26.340), train_loss = 1.04667667, grad/param norm = 1.8233e-01, time/batch = 18.2942s	
17728/33650 (epoch 26.342), train_loss = 0.76399042, grad/param norm = 1.4154e-01, time/batch = 16.3855s	
17729/33650 (epoch 26.343), train_loss = 0.96767367, grad/param norm = 1.5212e-01, time/batch = 18.4773s	
17730/33650 (epoch 26.345), train_loss = 0.92027332, grad/param norm = 1.9453e-01, time/batch = 16.2138s	
17731/33650 (epoch 26.346), train_loss = 0.65070232, grad/param norm = 1.4294e-01, time/batch = 18.8114s	
17732/33650 (epoch 26.348), train_loss = 0.80643583, grad/param norm = 1.4083e-01, time/batch = 17.7330s	
17733/33650 (epoch 26.349), train_loss = 0.76858456, grad/param norm = 1.5567e-01, time/batch = 17.8018s	
17734/33650 (epoch 26.351), train_loss = 0.98664858, grad/param norm = 1.5124e-01, time/batch = 18.4662s	
17735/33650 (epoch 26.352), train_loss = 0.89283822, grad/param norm = 1.5640e-01, time/batch = 18.6388s	
17736/33650 (epoch 26.354), train_loss = 1.05831193, grad/param norm = 2.2068e-01, time/batch = 18.5619s	
17737/33650 (epoch 26.355), train_loss = 1.06193138, grad/param norm = 1.5343e-01, time/batch = 18.1345s	
17738/33650 (epoch 26.357), train_loss = 0.74640432, grad/param norm = 1.4473e-01, time/batch = 18.6350s	
17739/33650 (epoch 26.358), train_loss = 0.98957690, grad/param norm = 1.6381e-01, time/batch = 17.9722s	
17740/33650 (epoch 26.360), train_loss = 0.99638920, grad/param norm = 1.8127e-01, time/batch = 16.8029s	
17741/33650 (epoch 26.361), train_loss = 0.96161281, grad/param norm = 1.5501e-01, time/batch = 18.3852s	
17742/33650 (epoch 26.363), train_loss = 0.92908180, grad/param norm = 1.6177e-01, time/batch = 18.8095s	
17743/33650 (epoch 26.364), train_loss = 0.90302935, grad/param norm = 1.4077e-01, time/batch = 16.8038s	
17744/33650 (epoch 26.366), train_loss = 0.98403146, grad/param norm = 1.6329e-01, time/batch = 17.3751s	
17745/33650 (epoch 26.367), train_loss = 0.95059686, grad/param norm = 1.3726e-01, time/batch = 18.4835s	
17746/33650 (epoch 26.368), train_loss = 0.84719103, grad/param norm = 1.3432e-01, time/batch = 17.9807s	
17747/33650 (epoch 26.370), train_loss = 0.91576411, grad/param norm = 1.5611e-01, time/batch = 17.3829s	
17748/33650 (epoch 26.371), train_loss = 0.71873667, grad/param norm = 1.3242e-01, time/batch = 18.6443s	
17749/33650 (epoch 26.373), train_loss = 0.81920827, grad/param norm = 1.3514e-01, time/batch = 17.3948s	
17750/33650 (epoch 26.374), train_loss = 0.82240648, grad/param norm = 1.2849e-01, time/batch = 16.3954s	
17751/33650 (epoch 26.376), train_loss = 0.90297567, grad/param norm = 1.7078e-01, time/batch = 13.9953s	
17752/33650 (epoch 26.377), train_loss = 0.94260717, grad/param norm = 1.6911e-01, time/batch = 14.6371s	
17753/33650 (epoch 26.379), train_loss = 0.95335688, grad/param norm = 1.4745e-01, time/batch = 13.9844s	
17754/33650 (epoch 26.380), train_loss = 0.75203378, grad/param norm = 1.5319e-01, time/batch = 16.5201s	
17755/33650 (epoch 26.382), train_loss = 0.88748784, grad/param norm = 1.2895e-01, time/batch = 19.0584s	
17756/33650 (epoch 26.383), train_loss = 0.90764078, grad/param norm = 1.5296e-01, time/batch = 19.1540s	
17757/33650 (epoch 26.385), train_loss = 0.96866561, grad/param norm = 1.4793e-01, time/batch = 18.3064s	
17758/33650 (epoch 26.386), train_loss = 0.85014214, grad/param norm = 1.3925e-01, time/batch = 17.5538s	
17759/33650 (epoch 26.388), train_loss = 0.97628256, grad/param norm = 1.4233e-01, time/batch = 18.8219s	
17760/33650 (epoch 26.389), train_loss = 0.88673386, grad/param norm = 1.5920e-01, time/batch = 17.0448s	
17761/33650 (epoch 26.391), train_loss = 0.73970396, grad/param norm = 1.3405e-01, time/batch = 17.2919s	
17762/33650 (epoch 26.392), train_loss = 0.94101574, grad/param norm = 1.5455e-01, time/batch = 18.4858s	
17763/33650 (epoch 26.394), train_loss = 0.92901830, grad/param norm = 1.5851e-01, time/batch = 18.4721s	
17764/33650 (epoch 26.395), train_loss = 0.97376680, grad/param norm = 1.6029e-01, time/batch = 17.2267s	
17765/33650 (epoch 26.397), train_loss = 1.05047618, grad/param norm = 1.6479e-01, time/batch = 18.1472s	
17766/33650 (epoch 26.398), train_loss = 0.96620130, grad/param norm = 1.4681e-01, time/batch = 18.9777s	
17767/33650 (epoch 26.400), train_loss = 0.93334535, grad/param norm = 1.8926e-01, time/batch = 15.6221s	
17768/33650 (epoch 26.401), train_loss = 0.88159653, grad/param norm = 1.7884e-01, time/batch = 17.3179s	
17769/33650 (epoch 26.403), train_loss = 0.96198088, grad/param norm = 1.6163e-01, time/batch = 18.2318s	
17770/33650 (epoch 26.404), train_loss = 0.92434204, grad/param norm = 1.4977e-01, time/batch = 18.3853s	
17771/33650 (epoch 26.406), train_loss = 0.92497907, grad/param norm = 1.5803e-01, time/batch = 18.2994s	
17772/33650 (epoch 26.407), train_loss = 0.91552607, grad/param norm = 1.6586e-01, time/batch = 18.3218s	
17773/33650 (epoch 26.409), train_loss = 0.97393173, grad/param norm = 2.8934e-01, time/batch = 18.6510s	
17774/33650 (epoch 26.410), train_loss = 0.90343763, grad/param norm = 1.5234e-01, time/batch = 17.4568s	
17775/33650 (epoch 26.412), train_loss = 0.91802458, grad/param norm = 1.4380e-01, time/batch = 18.4668s	
17776/33650 (epoch 26.413), train_loss = 0.88818477, grad/param norm = 1.6282e-01, time/batch = 17.2027s	
17777/33650 (epoch 26.415), train_loss = 0.99812431, grad/param norm = 1.6681e-01, time/batch = 17.9773s	
17778/33650 (epoch 26.416), train_loss = 1.05713367, grad/param norm = 1.6800e-01, time/batch = 18.0538s	
17779/33650 (epoch 26.418), train_loss = 0.85120879, grad/param norm = 1.5055e-01, time/batch = 19.3069s	
17780/33650 (epoch 26.419), train_loss = 0.87854077, grad/param norm = 1.6095e-01, time/batch = 18.0424s	
17781/33650 (epoch 26.421), train_loss = 0.88970516, grad/param norm = 1.3731e-01, time/batch = 17.7204s	
17782/33650 (epoch 26.422), train_loss = 1.04347798, grad/param norm = 1.5866e-01, time/batch = 18.4797s	
17783/33650 (epoch 26.423), train_loss = 0.83883174, grad/param norm = 1.3347e-01, time/batch = 19.0601s	
17784/33650 (epoch 26.425), train_loss = 0.92331913, grad/param norm = 1.6684e-01, time/batch = 17.4566s	
17785/33650 (epoch 26.426), train_loss = 1.03788332, grad/param norm = 1.7403e-01, time/batch = 18.1295s	
17786/33650 (epoch 26.428), train_loss = 0.88370735, grad/param norm = 1.5832e-01, time/batch = 18.6493s	
17787/33650 (epoch 26.429), train_loss = 0.98530912, grad/param norm = 1.7215e-01, time/batch = 16.8123s	
17788/33650 (epoch 26.431), train_loss = 1.08882466, grad/param norm = 1.9455e-01, time/batch = 18.6480s	
17789/33650 (epoch 26.432), train_loss = 1.09662412, grad/param norm = 1.8977e-01, time/batch = 17.2879s	
17790/33650 (epoch 26.434), train_loss = 0.96037927, grad/param norm = 1.6026e-01, time/batch = 18.2130s	
17791/33650 (epoch 26.435), train_loss = 0.93926644, grad/param norm = 1.5818e-01, time/batch = 16.0432s	
17792/33650 (epoch 26.437), train_loss = 0.95315783, grad/param norm = 1.6220e-01, time/batch = 18.8878s	
17793/33650 (epoch 26.438), train_loss = 0.89817781, grad/param norm = 2.3437e-01, time/batch = 18.7235s	
17794/33650 (epoch 26.440), train_loss = 0.93740926, grad/param norm = 1.6903e-01, time/batch = 17.3054s	
17795/33650 (epoch 26.441), train_loss = 0.94065359, grad/param norm = 1.6625e-01, time/batch = 17.6337s	
17796/33650 (epoch 26.443), train_loss = 0.97853368, grad/param norm = 1.4315e-01, time/batch = 18.2332s	
17797/33650 (epoch 26.444), train_loss = 0.90836199, grad/param norm = 1.5377e-01, time/batch = 17.6354s	
17798/33650 (epoch 26.446), train_loss = 0.98299658, grad/param norm = 1.8553e-01, time/batch = 17.8105s	
17799/33650 (epoch 26.447), train_loss = 1.05365159, grad/param norm = 1.6725e-01, time/batch = 17.9667s	
17800/33650 (epoch 26.449), train_loss = 1.08245028, grad/param norm = 1.9715e-01, time/batch = 18.1251s	
17801/33650 (epoch 26.450), train_loss = 1.10904597, grad/param norm = 1.6855e-01, time/batch = 27.3010s	
17802/33650 (epoch 26.452), train_loss = 1.08818297, grad/param norm = 1.8869e-01, time/batch = 18.5618s	
17803/33650 (epoch 26.453), train_loss = 1.08525946, grad/param norm = 1.8720e-01, time/batch = 18.2280s	
17804/33650 (epoch 26.455), train_loss = 0.91215252, grad/param norm = 1.4767e-01, time/batch = 18.7261s	
17805/33650 (epoch 26.456), train_loss = 0.92878991, grad/param norm = 1.5494e-01, time/batch = 17.9638s	
17806/33650 (epoch 26.458), train_loss = 0.90547222, grad/param norm = 1.8065e-01, time/batch = 17.4831s	
17807/33650 (epoch 26.459), train_loss = 0.96833419, grad/param norm = 1.8498e-01, time/batch = 16.5353s	
17808/33650 (epoch 26.461), train_loss = 1.05860292, grad/param norm = 1.7401e-01, time/batch = 18.2197s	
17809/33650 (epoch 26.462), train_loss = 1.04197454, grad/param norm = 1.7856e-01, time/batch = 18.2223s	
17810/33650 (epoch 26.464), train_loss = 0.91399021, grad/param norm = 1.7418e-01, time/batch = 17.5600s	
17811/33650 (epoch 26.465), train_loss = 0.98068510, grad/param norm = 2.1356e-01, time/batch = 17.8821s	
17812/33650 (epoch 26.467), train_loss = 0.97735198, grad/param norm = 1.5218e-01, time/batch = 17.8132s	
17813/33650 (epoch 26.468), train_loss = 1.07492416, grad/param norm = 1.5645e-01, time/batch = 17.3983s	
17814/33650 (epoch 26.470), train_loss = 1.14520888, grad/param norm = 1.8576e-01, time/batch = 18.1396s	
17815/33650 (epoch 26.471), train_loss = 0.94709761, grad/param norm = 1.5855e-01, time/batch = 18.4728s	
17816/33650 (epoch 26.473), train_loss = 0.92126142, grad/param norm = 1.5748e-01, time/batch = 17.8174s	
17817/33650 (epoch 26.474), train_loss = 1.04846608, grad/param norm = 1.6812e-01, time/batch = 32.9724s	
17818/33650 (epoch 26.475), train_loss = 1.01933370, grad/param norm = 1.7995e-01, time/batch = 18.0556s	
17819/33650 (epoch 26.477), train_loss = 1.05571362, grad/param norm = 1.6549e-01, time/batch = 15.6879s	
17820/33650 (epoch 26.478), train_loss = 1.03115401, grad/param norm = 1.7146e-01, time/batch = 18.0595s	
17821/33650 (epoch 26.480), train_loss = 1.02080914, grad/param norm = 2.4777e-01, time/batch = 18.5625s	
17822/33650 (epoch 26.481), train_loss = 1.08097365, grad/param norm = 1.6973e-01, time/batch = 18.2315s	
17823/33650 (epoch 26.483), train_loss = 0.79539518, grad/param norm = 1.5485e-01, time/batch = 17.8863s	
17824/33650 (epoch 26.484), train_loss = 0.93639316, grad/param norm = 1.6999e-01, time/batch = 18.8943s	
17825/33650 (epoch 26.486), train_loss = 1.10579763, grad/param norm = 1.8648e-01, time/batch = 18.3889s	
17826/33650 (epoch 26.487), train_loss = 1.05388660, grad/param norm = 1.5608e-01, time/batch = 16.3611s	
17827/33650 (epoch 26.489), train_loss = 1.10666199, grad/param norm = 1.6385e-01, time/batch = 18.5605s	
17828/33650 (epoch 26.490), train_loss = 0.86383637, grad/param norm = 1.5512e-01, time/batch = 17.3951s	
17829/33650 (epoch 26.492), train_loss = 0.99415703, grad/param norm = 1.7729e-01, time/batch = 17.5503s	
17830/33650 (epoch 26.493), train_loss = 0.79916747, grad/param norm = 1.3394e-01, time/batch = 18.5567s	
17831/33650 (epoch 26.495), train_loss = 0.96864546, grad/param norm = 1.7536e-01, time/batch = 17.8911s	
17832/33650 (epoch 26.496), train_loss = 0.99968654, grad/param norm = 1.7432e-01, time/batch = 17.2210s	
17833/33650 (epoch 26.498), train_loss = 0.86935381, grad/param norm = 1.4108e-01, time/batch = 18.3068s	
17834/33650 (epoch 26.499), train_loss = 0.95568588, grad/param norm = 1.3742e-01, time/batch = 18.6488s	
17835/33650 (epoch 26.501), train_loss = 0.93109863, grad/param norm = 1.3565e-01, time/batch = 18.2331s	
17836/33650 (epoch 26.502), train_loss = 0.97819922, grad/param norm = 1.7543e-01, time/batch = 17.8850s	
17837/33650 (epoch 26.504), train_loss = 1.04304305, grad/param norm = 1.7537e-01, time/batch = 18.3988s	
17838/33650 (epoch 26.505), train_loss = 0.91143507, grad/param norm = 1.5837e-01, time/batch = 16.8616s	
17839/33650 (epoch 26.507), train_loss = 1.04962716, grad/param norm = 1.5715e-01, time/batch = 17.5442s	
17840/33650 (epoch 26.508), train_loss = 0.93625623, grad/param norm = 1.5584e-01, time/batch = 17.3907s	
17841/33650 (epoch 26.510), train_loss = 0.94575546, grad/param norm = 1.4347e-01, time/batch = 18.7996s	
17842/33650 (epoch 26.511), train_loss = 1.13517967, grad/param norm = 1.8856e-01, time/batch = 18.3025s	
17843/33650 (epoch 26.513), train_loss = 1.00872591, grad/param norm = 1.5785e-01, time/batch = 17.1508s	
17844/33650 (epoch 26.514), train_loss = 1.03639879, grad/param norm = 1.6750e-01, time/batch = 17.1336s	
17845/33650 (epoch 26.516), train_loss = 0.96129555, grad/param norm = 1.7964e-01, time/batch = 18.0596s	
17846/33650 (epoch 26.517), train_loss = 0.97068536, grad/param norm = 1.7041e-01, time/batch = 17.2252s	
17847/33650 (epoch 26.519), train_loss = 1.01568695, grad/param norm = 1.6898e-01, time/batch = 18.2350s	
17848/33650 (epoch 26.520), train_loss = 0.81734001, grad/param norm = 1.2496e-01, time/batch = 17.8895s	
17849/33650 (epoch 26.522), train_loss = 0.93969945, grad/param norm = 1.5939e-01, time/batch = 16.9749s	
17850/33650 (epoch 26.523), train_loss = 0.90000410, grad/param norm = 1.5609e-01, time/batch = 18.1278s	
17851/33650 (epoch 26.525), train_loss = 0.76158906, grad/param norm = 1.3471e-01, time/batch = 18.4732s	
17852/33650 (epoch 26.526), train_loss = 1.03827039, grad/param norm = 1.5292e-01, time/batch = 17.8166s	
17853/33650 (epoch 26.527), train_loss = 0.90048467, grad/param norm = 1.5667e-01, time/batch = 17.7136s	
17854/33650 (epoch 26.529), train_loss = 0.94969639, grad/param norm = 1.5467e-01, time/batch = 18.2277s	
17855/33650 (epoch 26.530), train_loss = 0.89671682, grad/param norm = 1.5789e-01, time/batch = 18.2328s	
17856/33650 (epoch 26.532), train_loss = 1.02559324, grad/param norm = 1.7236e-01, time/batch = 16.5319s	
17857/33650 (epoch 26.533), train_loss = 0.93564532, grad/param norm = 1.4807e-01, time/batch = 17.9652s	
17858/33650 (epoch 26.535), train_loss = 1.05646145, grad/param norm = 1.5587e-01, time/batch = 18.8871s	
17859/33650 (epoch 26.536), train_loss = 0.96938729, grad/param norm = 1.9650e-01, time/batch = 17.2978s	
17860/33650 (epoch 26.538), train_loss = 0.99729586, grad/param norm = 1.7231e-01, time/batch = 18.2267s	
17861/33650 (epoch 26.539), train_loss = 0.77315007, grad/param norm = 1.5364e-01, time/batch = 19.1410s	
17862/33650 (epoch 26.541), train_loss = 1.05077179, grad/param norm = 1.8796e-01, time/batch = 17.6348s	
17863/33650 (epoch 26.542), train_loss = 0.95918973, grad/param norm = 2.0216e-01, time/batch = 17.2144s	
17864/33650 (epoch 26.544), train_loss = 1.11137111, grad/param norm = 2.0773e-01, time/batch = 17.9709s	
17865/33650 (epoch 26.545), train_loss = 0.81843797, grad/param norm = 1.3505e-01, time/batch = 18.9775s	
17866/33650 (epoch 26.547), train_loss = 0.99532580, grad/param norm = 1.7076e-01, time/batch = 17.3753s	
17867/33650 (epoch 26.548), train_loss = 1.13193315, grad/param norm = 1.7508e-01, time/batch = 18.5691s	
17868/33650 (epoch 26.550), train_loss = 0.97733973, grad/param norm = 1.8009e-01, time/batch = 17.3141s	
17869/33650 (epoch 26.551), train_loss = 0.96516652, grad/param norm = 1.8500e-01, time/batch = 17.0394s	
17870/33650 (epoch 26.553), train_loss = 0.82684640, grad/param norm = 1.5719e-01, time/batch = 17.9790s	
17871/33650 (epoch 26.554), train_loss = 1.09529858, grad/param norm = 1.7992e-01, time/batch = 18.7267s	
17872/33650 (epoch 26.556), train_loss = 1.04784672, grad/param norm = 2.6761e-01, time/batch = 18.2251s	
17873/33650 (epoch 26.557), train_loss = 1.04551659, grad/param norm = 1.8848e-01, time/batch = 16.7961s	
17874/33650 (epoch 26.559), train_loss = 1.22843033, grad/param norm = 2.1850e-01, time/batch = 18.7233s	
17875/33650 (epoch 26.560), train_loss = 1.17435582, grad/param norm = 1.9050e-01, time/batch = 18.6317s	
17876/33650 (epoch 26.562), train_loss = 1.09563740, grad/param norm = 1.5322e-01, time/batch = 17.7322s	
17877/33650 (epoch 26.563), train_loss = 0.99852708, grad/param norm = 1.6504e-01, time/batch = 17.4027s	
17878/33650 (epoch 26.565), train_loss = 0.96324041, grad/param norm = 1.5116e-01, time/batch = 16.0546s	
17879/33650 (epoch 26.566), train_loss = 0.94070844, grad/param norm = 1.7701e-01, time/batch = 17.0509s	
17880/33650 (epoch 26.568), train_loss = 0.99019493, grad/param norm = 1.9336e-01, time/batch = 18.4856s	
17881/33650 (epoch 26.569), train_loss = 0.89530939, grad/param norm = 1.4251e-01, time/batch = 18.9868s	
17882/33650 (epoch 26.571), train_loss = 1.05461760, grad/param norm = 1.6696e-01, time/batch = 18.2958s	
17883/33650 (epoch 26.572), train_loss = 1.02901194, grad/param norm = 1.4692e-01, time/batch = 17.8069s	
17884/33650 (epoch 26.574), train_loss = 0.88670684, grad/param norm = 1.7334e-01, time/batch = 18.6525s	
17885/33650 (epoch 26.575), train_loss = 0.96198409, grad/param norm = 1.6449e-01, time/batch = 18.6501s	
17886/33650 (epoch 26.577), train_loss = 0.91196592, grad/param norm = 1.6432e-01, time/batch = 17.3753s	
17887/33650 (epoch 26.578), train_loss = 1.05800724, grad/param norm = 1.8526e-01, time/batch = 18.8079s	
17888/33650 (epoch 26.579), train_loss = 1.02301680, grad/param norm = 1.7629e-01, time/batch = 18.5722s	
17889/33650 (epoch 26.581), train_loss = 1.09540239, grad/param norm = 1.7115e-01, time/batch = 17.7302s	
17890/33650 (epoch 26.582), train_loss = 0.99888731, grad/param norm = 1.4614e-01, time/batch = 18.2969s	
17891/33650 (epoch 26.584), train_loss = 0.98903943, grad/param norm = 1.4915e-01, time/batch = 18.1497s	
17892/33650 (epoch 26.585), train_loss = 1.00869260, grad/param norm = 1.7438e-01, time/batch = 15.9495s	
17893/33650 (epoch 26.587), train_loss = 0.89743255, grad/param norm = 1.7304e-01, time/batch = 18.5591s	
17894/33650 (epoch 26.588), train_loss = 0.93195025, grad/param norm = 1.9242e-01, time/batch = 17.7205s	
17895/33650 (epoch 26.590), train_loss = 0.90888989, grad/param norm = 1.3681e-01, time/batch = 17.5295s	
17896/33650 (epoch 26.591), train_loss = 0.87755105, grad/param norm = 1.8468e-01, time/batch = 16.8784s	
17897/33650 (epoch 26.593), train_loss = 0.88139590, grad/param norm = 1.4881e-01, time/batch = 18.7338s	
17898/33650 (epoch 26.594), train_loss = 0.85184135, grad/param norm = 1.6150e-01, time/batch = 18.4875s	
17899/33650 (epoch 26.596), train_loss = 0.94418934, grad/param norm = 1.5699e-01, time/batch = 16.5587s	
17900/33650 (epoch 26.597), train_loss = 0.81127571, grad/param norm = 1.3964e-01, time/batch = 17.3032s	
17901/33650 (epoch 26.599), train_loss = 0.92972852, grad/param norm = 1.4715e-01, time/batch = 17.9823s	
17902/33650 (epoch 26.600), train_loss = 0.87214172, grad/param norm = 1.4050e-01, time/batch = 18.1514s	
17903/33650 (epoch 26.602), train_loss = 0.97143991, grad/param norm = 1.5730e-01, time/batch = 17.2220s	
17904/33650 (epoch 26.603), train_loss = 0.88790843, grad/param norm = 1.5560e-01, time/batch = 19.4799s	
17905/33650 (epoch 26.605), train_loss = 1.02295295, grad/param norm = 1.5855e-01, time/batch = 19.1500s	
17906/33650 (epoch 26.606), train_loss = 0.96855616, grad/param norm = 1.6731e-01, time/batch = 16.9663s	
17907/33650 (epoch 26.608), train_loss = 0.84666126, grad/param norm = 1.6626e-01, time/batch = 18.9835s	
17908/33650 (epoch 26.609), train_loss = 0.94103511, grad/param norm = 1.5737e-01, time/batch = 18.9003s	
17909/33650 (epoch 26.611), train_loss = 0.85226373, grad/param norm = 1.4879e-01, time/batch = 15.3902s	
17910/33650 (epoch 26.612), train_loss = 0.97114651, grad/param norm = 1.8504e-01, time/batch = 14.1460s	
17911/33650 (epoch 26.614), train_loss = 1.03543121, grad/param norm = 1.5333e-01, time/batch = 14.2191s	
17912/33650 (epoch 26.615), train_loss = 0.94742946, grad/param norm = 1.3698e-01, time/batch = 16.9498s	
17913/33650 (epoch 26.617), train_loss = 0.85312813, grad/param norm = 1.3055e-01, time/batch = 17.8071s	
17914/33650 (epoch 26.618), train_loss = 0.91289003, grad/param norm = 1.4666e-01, time/batch = 17.2411s	
17915/33650 (epoch 26.620), train_loss = 0.92516132, grad/param norm = 1.6754e-01, time/batch = 17.7281s	
17916/33650 (epoch 26.621), train_loss = 0.86492709, grad/param norm = 1.4739e-01, time/batch = 16.4672s	
17917/33650 (epoch 26.623), train_loss = 0.91921071, grad/param norm = 1.5422e-01, time/batch = 17.1461s	
17918/33650 (epoch 26.624), train_loss = 0.74445288, grad/param norm = 1.3956e-01, time/batch = 17.0565s	
17919/33650 (epoch 26.626), train_loss = 0.78001760, grad/param norm = 1.5283e-01, time/batch = 18.6574s	
17920/33650 (epoch 26.627), train_loss = 0.87067959, grad/param norm = 1.5266e-01, time/batch = 17.3821s	
17921/33650 (epoch 26.629), train_loss = 0.89197462, grad/param norm = 1.4891e-01, time/batch = 18.9734s	
17922/33650 (epoch 26.630), train_loss = 1.04595169, grad/param norm = 1.7614e-01, time/batch = 18.6389s	
17923/33650 (epoch 26.632), train_loss = 1.05434403, grad/param norm = 1.6687e-01, time/batch = 17.2212s	
17924/33650 (epoch 26.633), train_loss = 1.00917560, grad/param norm = 1.5766e-01, time/batch = 17.3937s	
17925/33650 (epoch 26.634), train_loss = 0.83857469, grad/param norm = 1.4121e-01, time/batch = 18.0723s	
17926/33650 (epoch 26.636), train_loss = 0.73523836, grad/param norm = 1.2309e-01, time/batch = 17.7168s	
17927/33650 (epoch 26.637), train_loss = 0.86806151, grad/param norm = 1.4586e-01, time/batch = 17.0662s	
17928/33650 (epoch 26.639), train_loss = 0.87444737, grad/param norm = 1.5223e-01, time/batch = 18.3190s	
17929/33650 (epoch 26.640), train_loss = 0.94305731, grad/param norm = 1.4742e-01, time/batch = 16.8727s	
17930/33650 (epoch 26.642), train_loss = 0.99627444, grad/param norm = 1.5868e-01, time/batch = 16.7219s	
17931/33650 (epoch 26.643), train_loss = 0.96320447, grad/param norm = 1.6726e-01, time/batch = 18.7315s	
17932/33650 (epoch 26.645), train_loss = 0.95458475, grad/param norm = 1.5205e-01, time/batch = 16.8078s	
17933/33650 (epoch 26.646), train_loss = 0.82209423, grad/param norm = 1.2846e-01, time/batch = 16.3886s	
17934/33650 (epoch 26.648), train_loss = 0.98015151, grad/param norm = 1.6587e-01, time/batch = 17.2237s	
17935/33650 (epoch 26.649), train_loss = 0.88285438, grad/param norm = 1.6794e-01, time/batch = 18.4752s	
17936/33650 (epoch 26.651), train_loss = 1.01980246, grad/param norm = 1.7051e-01, time/batch = 18.8111s	
17937/33650 (epoch 26.652), train_loss = 0.69688898, grad/param norm = 1.3071e-01, time/batch = 16.5481s	
17938/33650 (epoch 26.654), train_loss = 0.84178330, grad/param norm = 1.5101e-01, time/batch = 19.0497s	
17939/33650 (epoch 26.655), train_loss = 0.83713936, grad/param norm = 1.4317e-01, time/batch = 18.5541s	
17940/33650 (epoch 26.657), train_loss = 0.90048234, grad/param norm = 1.5485e-01, time/batch = 16.5279s	
17941/33650 (epoch 26.658), train_loss = 0.76161328, grad/param norm = 1.5851e-01, time/batch = 18.0321s	
17942/33650 (epoch 26.660), train_loss = 0.75787723, grad/param norm = 1.3803e-01, time/batch = 17.7305s	
17943/33650 (epoch 26.661), train_loss = 0.83610016, grad/param norm = 1.4780e-01, time/batch = 17.7887s	
17944/33650 (epoch 26.663), train_loss = 0.79655355, grad/param norm = 1.5910e-01, time/batch = 18.2308s	
17945/33650 (epoch 26.664), train_loss = 0.87840645, grad/param norm = 1.4502e-01, time/batch = 17.3032s	
17946/33650 (epoch 26.666), train_loss = 0.88712903, grad/param norm = 1.2494e-01, time/batch = 18.0501s	
17947/33650 (epoch 26.667), train_loss = 0.80295692, grad/param norm = 1.3674e-01, time/batch = 17.1318s	
17948/33650 (epoch 26.669), train_loss = 0.81920742, grad/param norm = 1.5348e-01, time/batch = 16.9720s	
17949/33650 (epoch 26.670), train_loss = 0.75137783, grad/param norm = 1.4513e-01, time/batch = 18.4003s	
17950/33650 (epoch 26.672), train_loss = 0.78145333, grad/param norm = 1.6435e-01, time/batch = 17.2149s	
17951/33650 (epoch 26.673), train_loss = 0.75299982, grad/param norm = 1.4751e-01, time/batch = 17.4831s	
17952/33650 (epoch 26.675), train_loss = 0.73151780, grad/param norm = 1.2783e-01, time/batch = 18.3067s	
17953/33650 (epoch 26.676), train_loss = 0.90246472, grad/param norm = 1.5179e-01, time/batch = 16.2914s	
17954/33650 (epoch 26.678), train_loss = 0.86930976, grad/param norm = 1.4803e-01, time/batch = 17.0362s	
17955/33650 (epoch 26.679), train_loss = 0.85617023, grad/param norm = 1.5369e-01, time/batch = 18.8811s	
17956/33650 (epoch 26.681), train_loss = 0.88608947, grad/param norm = 1.3642e-01, time/batch = 17.8943s	
17957/33650 (epoch 26.682), train_loss = 0.80817591, grad/param norm = 1.4354e-01, time/batch = 16.8079s	
17958/33650 (epoch 26.684), train_loss = 0.77932455, grad/param norm = 1.3427e-01, time/batch = 17.1328s	
17959/33650 (epoch 26.685), train_loss = 0.94076386, grad/param norm = 1.6446e-01, time/batch = 18.4829s	
17960/33650 (epoch 26.686), train_loss = 0.89366648, grad/param norm = 1.3250e-01, time/batch = 17.8031s	
17961/33650 (epoch 26.688), train_loss = 0.97750837, grad/param norm = 1.5401e-01, time/batch = 18.8148s	
17962/33650 (epoch 26.689), train_loss = 0.82238155, grad/param norm = 1.3998e-01, time/batch = 18.3954s	
17963/33650 (epoch 26.691), train_loss = 1.01909670, grad/param norm = 2.0046e-01, time/batch = 17.3232s	
17964/33650 (epoch 26.692), train_loss = 1.02573502, grad/param norm = 1.7125e-01, time/batch = 17.5500s	
17965/33650 (epoch 26.694), train_loss = 0.94474573, grad/param norm = 1.5741e-01, time/batch = 16.2185s	
17966/33650 (epoch 26.695), train_loss = 0.67741076, grad/param norm = 1.7093e-01, time/batch = 18.3224s	
17967/33650 (epoch 26.697), train_loss = 0.86777237, grad/param norm = 1.5844e-01, time/batch = 16.4337s	
17968/33650 (epoch 26.698), train_loss = 1.02984975, grad/param norm = 1.6481e-01, time/batch = 0.6416s	
17969/33650 (epoch 26.700), train_loss = 0.90133019, grad/param norm = 1.4823e-01, time/batch = 0.6438s	
17970/33650 (epoch 26.701), train_loss = 0.91108809, grad/param norm = 1.4768e-01, time/batch = 0.6456s	
17971/33650 (epoch 26.703), train_loss = 1.09676674, grad/param norm = 1.5419e-01, time/batch = 0.6412s	
17972/33650 (epoch 26.704), train_loss = 0.89203340, grad/param norm = 1.3708e-01, time/batch = 0.6400s	
17973/33650 (epoch 26.706), train_loss = 0.86934949, grad/param norm = 1.3746e-01, time/batch = 0.6391s	
17974/33650 (epoch 26.707), train_loss = 0.98494432, grad/param norm = 1.3730e-01, time/batch = 0.6402s	
17975/33650 (epoch 26.709), train_loss = 0.88254607, grad/param norm = 1.5138e-01, time/batch = 0.7501s	
17976/33650 (epoch 26.710), train_loss = 1.06884858, grad/param norm = 1.5237e-01, time/batch = 0.9415s	
17977/33650 (epoch 26.712), train_loss = 0.82452014, grad/param norm = 1.5049e-01, time/batch = 0.9407s	
17978/33650 (epoch 26.713), train_loss = 0.81197978, grad/param norm = 1.7249e-01, time/batch = 0.9396s	
17979/33650 (epoch 26.715), train_loss = 0.96671237, grad/param norm = 1.7179e-01, time/batch = 0.9317s	
17980/33650 (epoch 26.716), train_loss = 0.86536325, grad/param norm = 1.6485e-01, time/batch = 0.9648s	
17981/33650 (epoch 26.718), train_loss = 0.86683992, grad/param norm = 1.5794e-01, time/batch = 1.7686s	
17982/33650 (epoch 26.719), train_loss = 1.00838192, grad/param norm = 1.6546e-01, time/batch = 1.7765s	
17983/33650 (epoch 26.721), train_loss = 1.10189512, grad/param norm = 1.8105e-01, time/batch = 5.8567s	
17984/33650 (epoch 26.722), train_loss = 0.97387194, grad/param norm = 1.8652e-01, time/batch = 18.8125s	
17985/33650 (epoch 26.724), train_loss = 1.04130735, grad/param norm = 1.6540e-01, time/batch = 17.3035s	
17986/33650 (epoch 26.725), train_loss = 1.01322797, grad/param norm = 2.0926e-01, time/batch = 17.8111s	
17987/33650 (epoch 26.727), train_loss = 0.86507741, grad/param norm = 1.7334e-01, time/batch = 18.2827s	
17988/33650 (epoch 26.728), train_loss = 0.87492646, grad/param norm = 1.4307e-01, time/batch = 18.2385s	
17989/33650 (epoch 26.730), train_loss = 0.96162925, grad/param norm = 1.6021e-01, time/batch = 16.4722s	
17990/33650 (epoch 26.731), train_loss = 1.05777093, grad/param norm = 1.7040e-01, time/batch = 18.3929s	
17991/33650 (epoch 26.733), train_loss = 0.90318856, grad/param norm = 1.8340e-01, time/batch = 18.8031s	
17992/33650 (epoch 26.734), train_loss = 1.06264101, grad/param norm = 1.8654e-01, time/batch = 16.3861s	
17993/33650 (epoch 26.736), train_loss = 0.91014273, grad/param norm = 1.6067e-01, time/batch = 17.6425s	
17994/33650 (epoch 26.737), train_loss = 0.98696763, grad/param norm = 2.0114e-01, time/batch = 18.4630s	
17995/33650 (epoch 26.738), train_loss = 0.84008987, grad/param norm = 1.5263e-01, time/batch = 17.5444s	
17996/33650 (epoch 26.740), train_loss = 0.78270891, grad/param norm = 1.4039e-01, time/batch = 16.9810s	
17997/33650 (epoch 26.741), train_loss = 0.86062618, grad/param norm = 1.8233e-01, time/batch = 18.3992s	
17998/33650 (epoch 26.743), train_loss = 0.91500912, grad/param norm = 1.6370e-01, time/batch = 18.0702s	
17999/33650 (epoch 26.744), train_loss = 0.98791279, grad/param norm = 1.4261e-01, time/batch = 17.1253s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch26.75_1.6614.t7	
18000/33650 (epoch 26.746), train_loss = 0.88670596, grad/param norm = 1.4312e-01, time/batch = 16.1421s	
18001/33650 (epoch 26.747), train_loss = 1.38700416, grad/param norm = 1.8716e-01, time/batch = 16.0354s	
18002/33650 (epoch 26.749), train_loss = 0.77030824, grad/param norm = 1.5339e-01, time/batch = 18.5611s	
18003/33650 (epoch 26.750), train_loss = 1.07269051, grad/param norm = 1.5824e-01, time/batch = 17.4673s	
18004/33650 (epoch 26.752), train_loss = 1.01618274, grad/param norm = 1.5788e-01, time/batch = 17.9689s	
18005/33650 (epoch 26.753), train_loss = 1.11143734, grad/param norm = 1.8170e-01, time/batch = 17.9760s	
18006/33650 (epoch 26.755), train_loss = 0.87428430, grad/param norm = 1.3678e-01, time/batch = 17.9095s	
18007/33650 (epoch 26.756), train_loss = 1.00911362, grad/param norm = 1.7636e-01, time/batch = 17.2263s	
18008/33650 (epoch 26.758), train_loss = 1.00889852, grad/param norm = 1.4614e-01, time/batch = 16.8826s	
18009/33650 (epoch 26.759), train_loss = 1.03249574, grad/param norm = 1.8470e-01, time/batch = 19.0507s	
18010/33650 (epoch 26.761), train_loss = 0.95281553, grad/param norm = 1.5475e-01, time/batch = 18.9000s	
18011/33650 (epoch 26.762), train_loss = 0.93202753, grad/param norm = 1.5782e-01, time/batch = 17.3962s	
18012/33650 (epoch 26.764), train_loss = 0.97678448, grad/param norm = 1.6587e-01, time/batch = 15.7326s	
18013/33650 (epoch 26.765), train_loss = 0.88818975, grad/param norm = 1.4953e-01, time/batch = 18.8178s	
18014/33650 (epoch 26.767), train_loss = 0.91031189, grad/param norm = 1.4043e-01, time/batch = 17.9747s	
18015/33650 (epoch 26.768), train_loss = 0.81463073, grad/param norm = 1.6311e-01, time/batch = 16.8714s	
18016/33650 (epoch 26.770), train_loss = 0.97335811, grad/param norm = 1.6264e-01, time/batch = 17.7465s	
18017/33650 (epoch 26.771), train_loss = 0.95293029, grad/param norm = 1.6001e-01, time/batch = 19.1559s	
18018/33650 (epoch 26.773), train_loss = 1.03769397, grad/param norm = 1.9264e-01, time/batch = 16.6471s	
18019/33650 (epoch 26.774), train_loss = 0.95786189, grad/param norm = 1.5581e-01, time/batch = 18.5527s	
18020/33650 (epoch 26.776), train_loss = 1.00051492, grad/param norm = 1.6972e-01, time/batch = 16.8602s	
18021/33650 (epoch 26.777), train_loss = 0.86310495, grad/param norm = 1.4500e-01, time/batch = 17.2269s	
18022/33650 (epoch 26.779), train_loss = 0.88749880, grad/param norm = 1.3865e-01, time/batch = 17.8084s	
18023/33650 (epoch 26.780), train_loss = 0.82744725, grad/param norm = 1.3091e-01, time/batch = 18.3083s	
18024/33650 (epoch 26.782), train_loss = 0.85464816, grad/param norm = 1.5149e-01, time/batch = 18.3938s	
18025/33650 (epoch 26.783), train_loss = 0.84107504, grad/param norm = 1.2733e-01, time/batch = 31.8981s	
18026/33650 (epoch 26.785), train_loss = 1.09395134, grad/param norm = 1.4716e-01, time/batch = 16.3025s	
18027/33650 (epoch 26.786), train_loss = 0.98154456, grad/param norm = 1.4843e-01, time/batch = 16.8884s	
18028/33650 (epoch 26.788), train_loss = 0.98714708, grad/param norm = 1.5975e-01, time/batch = 18.0606s	
18029/33650 (epoch 26.789), train_loss = 1.02487698, grad/param norm = 1.6579e-01, time/batch = 16.1992s	
18030/33650 (epoch 26.790), train_loss = 0.94633519, grad/param norm = 1.6543e-01, time/batch = 18.9784s	
18031/33650 (epoch 26.792), train_loss = 1.04417799, grad/param norm = 1.8210e-01, time/batch = 16.9618s	
18032/33650 (epoch 26.793), train_loss = 1.01444122, grad/param norm = 1.9344e-01, time/batch = 17.8975s	
18033/33650 (epoch 26.795), train_loss = 1.04149957, grad/param norm = 1.6457e-01, time/batch = 18.4868s	
18034/33650 (epoch 26.796), train_loss = 0.89951365, grad/param norm = 1.5494e-01, time/batch = 17.3060s	
18035/33650 (epoch 26.798), train_loss = 0.89239421, grad/param norm = 1.5498e-01, time/batch = 18.1464s	
18036/33650 (epoch 26.799), train_loss = 0.93060370, grad/param norm = 1.4382e-01, time/batch = 16.8095s	
18037/33650 (epoch 26.801), train_loss = 0.93698778, grad/param norm = 1.6101e-01, time/batch = 17.5451s	
18038/33650 (epoch 26.802), train_loss = 1.04277092, grad/param norm = 1.7014e-01, time/batch = 18.4736s	
18039/33650 (epoch 26.804), train_loss = 0.93906104, grad/param norm = 1.6658e-01, time/batch = 18.0691s	
18040/33650 (epoch 26.805), train_loss = 0.92182892, grad/param norm = 1.3749e-01, time/batch = 18.3269s	
18041/33650 (epoch 26.807), train_loss = 1.13920192, grad/param norm = 1.9050e-01, time/batch = 17.2997s	
18042/33650 (epoch 26.808), train_loss = 1.18252064, grad/param norm = 1.8166e-01, time/batch = 16.8830s	
18043/33650 (epoch 26.810), train_loss = 0.95850852, grad/param norm = 1.6664e-01, time/batch = 18.2317s	
18044/33650 (epoch 26.811), train_loss = 0.96405728, grad/param norm = 1.5942e-01, time/batch = 18.1387s	
18045/33650 (epoch 26.813), train_loss = 0.85596944, grad/param norm = 1.4441e-01, time/batch = 18.3849s	
18046/33650 (epoch 26.814), train_loss = 1.02796059, grad/param norm = 1.5732e-01, time/batch = 17.8146s	
18047/33650 (epoch 26.816), train_loss = 1.00614503, grad/param norm = 1.6234e-01, time/batch = 17.4790s	
18048/33650 (epoch 26.817), train_loss = 1.02704843, grad/param norm = 1.5923e-01, time/batch = 17.1400s	
18049/33650 (epoch 26.819), train_loss = 0.96311764, grad/param norm = 1.5738e-01, time/batch = 17.9898s	
18050/33650 (epoch 26.820), train_loss = 1.06588009, grad/param norm = 1.6933e-01, time/batch = 18.1437s	
18051/33650 (epoch 26.822), train_loss = 0.98480086, grad/param norm = 2.0163e-01, time/batch = 17.2995s	
18052/33650 (epoch 26.823), train_loss = 0.87806693, grad/param norm = 1.4563e-01, time/batch = 18.9006s	
18053/33650 (epoch 26.825), train_loss = 0.93670977, grad/param norm = 1.5667e-01, time/batch = 16.9706s	
18054/33650 (epoch 26.826), train_loss = 1.01223978, grad/param norm = 1.5424e-01, time/batch = 17.4848s	
18055/33650 (epoch 26.828), train_loss = 1.10122837, grad/param norm = 1.6695e-01, time/batch = 17.3138s	
18056/33650 (epoch 26.829), train_loss = 0.79270436, grad/param norm = 1.4152e-01, time/batch = 18.4021s	
18057/33650 (epoch 26.831), train_loss = 0.95584775, grad/param norm = 1.5034e-01, time/batch = 18.3032s	
18058/33650 (epoch 26.832), train_loss = 1.02474715, grad/param norm = 1.5998e-01, time/batch = 17.3821s	
18059/33650 (epoch 26.834), train_loss = 1.03031203, grad/param norm = 1.5931e-01, time/batch = 18.8093s	
18060/33650 (epoch 26.835), train_loss = 1.17678241, grad/param norm = 2.3174e-01, time/batch = 16.5488s	
18061/33650 (epoch 26.837), train_loss = 1.00571931, grad/param norm = 2.8067e-01, time/batch = 17.2316s	
18062/33650 (epoch 26.838), train_loss = 0.97634100, grad/param norm = 1.7999e-01, time/batch = 18.5630s	
18063/33650 (epoch 26.840), train_loss = 1.03102278, grad/param norm = 1.6558e-01, time/batch = 17.9027s	
18064/33650 (epoch 26.841), train_loss = 0.90516922, grad/param norm = 1.5486e-01, time/batch = 18.2271s	
18065/33650 (epoch 26.842), train_loss = 0.92742877, grad/param norm = 1.4351e-01, time/batch = 15.9589s	
18066/33650 (epoch 26.844), train_loss = 1.13620701, grad/param norm = 2.0329e-01, time/batch = 18.8161s	
18067/33650 (epoch 26.845), train_loss = 0.88648899, grad/param norm = 1.5272e-01, time/batch = 18.2272s	
18068/33650 (epoch 26.847), train_loss = 0.73480096, grad/param norm = 1.6012e-01, time/batch = 17.4643s	
18069/33650 (epoch 26.848), train_loss = 0.82941633, grad/param norm = 1.5831e-01, time/batch = 18.3283s	
18070/33650 (epoch 26.850), train_loss = 0.92330841, grad/param norm = 1.9047e-01, time/batch = 16.0601s	
18071/33650 (epoch 26.851), train_loss = 0.78292111, grad/param norm = 1.2410e-01, time/batch = 17.4789s	
18072/33650 (epoch 26.853), train_loss = 0.92880359, grad/param norm = 1.6528e-01, time/batch = 17.4004s	
18073/33650 (epoch 26.854), train_loss = 1.03646542, grad/param norm = 1.4927e-01, time/batch = 18.2397s	
18074/33650 (epoch 26.856), train_loss = 0.74665508, grad/param norm = 1.4675e-01, time/batch = 17.5527s	
18075/33650 (epoch 26.857), train_loss = 0.95993471, grad/param norm = 1.4573e-01, time/batch = 18.1385s	
18076/33650 (epoch 26.859), train_loss = 0.83318315, grad/param norm = 1.2685e-01, time/batch = 18.5651s	
18077/33650 (epoch 26.860), train_loss = 0.80250424, grad/param norm = 1.4086e-01, time/batch = 17.8973s	
18078/33650 (epoch 26.862), train_loss = 0.84766228, grad/param norm = 1.4777e-01, time/batch = 15.6160s	
18079/33650 (epoch 26.863), train_loss = 1.07582248, grad/param norm = 1.6096e-01, time/batch = 18.8831s	
18080/33650 (epoch 26.865), train_loss = 0.90100829, grad/param norm = 1.3662e-01, time/batch = 17.0531s	
18081/33650 (epoch 26.866), train_loss = 0.84728371, grad/param norm = 1.4602e-01, time/batch = 17.2210s	
18082/33650 (epoch 26.868), train_loss = 0.81749137, grad/param norm = 1.6024e-01, time/batch = 17.1303s	
18083/33650 (epoch 26.869), train_loss = 1.00720878, grad/param norm = 1.6137e-01, time/batch = 18.5278s	
18084/33650 (epoch 26.871), train_loss = 0.81985385, grad/param norm = 1.4295e-01, time/batch = 17.3910s	
18085/33650 (epoch 26.872), train_loss = 0.97440575, grad/param norm = 1.6513e-01, time/batch = 17.3262s	
18086/33650 (epoch 26.874), train_loss = 1.00221696, grad/param norm = 1.8476e-01, time/batch = 18.4138s	
18087/33650 (epoch 26.875), train_loss = 0.91502661, grad/param norm = 1.6335e-01, time/batch = 17.8164s	
18088/33650 (epoch 26.877), train_loss = 1.08473234, grad/param norm = 1.8451e-01, time/batch = 16.8956s	
18089/33650 (epoch 26.878), train_loss = 0.69020249, grad/param norm = 1.3947e-01, time/batch = 17.7203s	
18090/33650 (epoch 26.880), train_loss = 0.96177223, grad/param norm = 1.5748e-01, time/batch = 18.1448s	
18091/33650 (epoch 26.881), train_loss = 0.87789881, grad/param norm = 1.5994e-01, time/batch = 16.8175s	
18092/33650 (epoch 26.883), train_loss = 0.93790054, grad/param norm = 1.3598e-01, time/batch = 17.7239s	
18093/33650 (epoch 26.884), train_loss = 1.04773469, grad/param norm = 1.6254e-01, time/batch = 14.0861s	
18094/33650 (epoch 26.886), train_loss = 0.99972602, grad/param norm = 1.5430e-01, time/batch = 13.6034s	
18095/33650 (epoch 26.887), train_loss = 0.80622892, grad/param norm = 1.4013e-01, time/batch = 14.5338s	
18096/33650 (epoch 26.889), train_loss = 0.91449693, grad/param norm = 1.5640e-01, time/batch = 16.9504s	
18097/33650 (epoch 26.890), train_loss = 0.97359346, grad/param norm = 1.3862e-01, time/batch = 18.8029s	
18098/33650 (epoch 26.892), train_loss = 0.89908095, grad/param norm = 1.6983e-01, time/batch = 18.1394s	
18099/33650 (epoch 26.893), train_loss = 0.96450007, grad/param norm = 1.4571e-01, time/batch = 17.0462s	
18100/33650 (epoch 26.895), train_loss = 1.06616551, grad/param norm = 1.6899e-01, time/batch = 18.8210s	
18101/33650 (epoch 26.896), train_loss = 0.86638658, grad/param norm = 1.4976e-01, time/batch = 17.0679s	
18102/33650 (epoch 26.897), train_loss = 0.79212178, grad/param norm = 1.3772e-01, time/batch = 16.5428s	
18103/33650 (epoch 26.899), train_loss = 0.83412393, grad/param norm = 1.3546e-01, time/batch = 18.0591s	
18104/33650 (epoch 26.900), train_loss = 0.79900595, grad/param norm = 1.4900e-01, time/batch = 15.7906s	
18105/33650 (epoch 26.902), train_loss = 0.92220896, grad/param norm = 1.6305e-01, time/batch = 17.7248s	
18106/33650 (epoch 26.903), train_loss = 0.88053028, grad/param norm = 1.5244e-01, time/batch = 17.6392s	
18107/33650 (epoch 26.905), train_loss = 1.03873962, grad/param norm = 1.7870e-01, time/batch = 17.8513s	
18108/33650 (epoch 26.906), train_loss = 0.85793771, grad/param norm = 1.4680e-01, time/batch = 18.6409s	
18109/33650 (epoch 26.908), train_loss = 0.89858147, grad/param norm = 1.4306e-01, time/batch = 16.8069s	
18110/33650 (epoch 26.909), train_loss = 0.87010922, grad/param norm = 1.3789e-01, time/batch = 18.2417s	
18111/33650 (epoch 26.911), train_loss = 0.77832025, grad/param norm = 1.4055e-01, time/batch = 18.7413s	
18112/33650 (epoch 26.912), train_loss = 0.74313889, grad/param norm = 1.4062e-01, time/batch = 17.6387s	
18113/33650 (epoch 26.914), train_loss = 0.93325045, grad/param norm = 1.3588e-01, time/batch = 18.1409s	
18114/33650 (epoch 26.915), train_loss = 0.89893884, grad/param norm = 1.7662e-01, time/batch = 17.6213s	
18115/33650 (epoch 26.917), train_loss = 0.88675976, grad/param norm = 1.5735e-01, time/batch = 15.9789s	
18116/33650 (epoch 26.918), train_loss = 0.80444932, grad/param norm = 1.3508e-01, time/batch = 16.6407s	
18117/33650 (epoch 26.920), train_loss = 0.82064958, grad/param norm = 1.4059e-01, time/batch = 18.8179s	
18118/33650 (epoch 26.921), train_loss = 0.81234322, grad/param norm = 1.3637e-01, time/batch = 18.5661s	
18119/33650 (epoch 26.923), train_loss = 0.75718802, grad/param norm = 1.4399e-01, time/batch = 17.1341s	
18120/33650 (epoch 26.924), train_loss = 0.92584636, grad/param norm = 1.5218e-01, time/batch = 18.1432s	
18121/33650 (epoch 26.926), train_loss = 0.85728708, grad/param norm = 1.6830e-01, time/batch = 18.4868s	
18122/33650 (epoch 26.927), train_loss = 0.90821520, grad/param norm = 1.5891e-01, time/batch = 16.7073s	
18123/33650 (epoch 26.929), train_loss = 0.97218026, grad/param norm = 1.5803e-01, time/batch = 17.3872s	
18124/33650 (epoch 26.930), train_loss = 0.88110122, grad/param norm = 1.5190e-01, time/batch = 18.2290s	
18125/33650 (epoch 26.932), train_loss = 0.87496882, grad/param norm = 1.4846e-01, time/batch = 18.0633s	
18126/33650 (epoch 26.933), train_loss = 0.78376749, grad/param norm = 1.4423e-01, time/batch = 17.5401s	
18127/33650 (epoch 26.935), train_loss = 0.80071349, grad/param norm = 1.6041e-01, time/batch = 18.2313s	
18128/33650 (epoch 26.936), train_loss = 0.84627485, grad/param norm = 1.3005e-01, time/batch = 17.0674s	
18129/33650 (epoch 26.938), train_loss = 0.78351841, grad/param norm = 1.5440e-01, time/batch = 17.2199s	
18130/33650 (epoch 26.939), train_loss = 0.97893456, grad/param norm = 1.5892e-01, time/batch = 17.8294s	
18131/33650 (epoch 26.941), train_loss = 0.90284888, grad/param norm = 1.4195e-01, time/batch = 17.9100s	
18132/33650 (epoch 26.942), train_loss = 0.98321040, grad/param norm = 1.5275e-01, time/batch = 17.0355s	
18133/33650 (epoch 26.944), train_loss = 0.86017204, grad/param norm = 1.2792e-01, time/batch = 17.5529s	
18134/33650 (epoch 26.945), train_loss = 0.93614459, grad/param norm = 1.4767e-01, time/batch = 17.9781s	
18135/33650 (epoch 26.947), train_loss = 1.05888349, grad/param norm = 2.1149e-01, time/batch = 18.4019s	
18136/33650 (epoch 26.948), train_loss = 1.02720850, grad/param norm = 1.5448e-01, time/batch = 17.0513s	
18137/33650 (epoch 26.949), train_loss = 0.78130178, grad/param norm = 1.3470e-01, time/batch = 18.7326s	
18138/33650 (epoch 26.951), train_loss = 1.05244344, grad/param norm = 1.6472e-01, time/batch = 18.3239s	
18139/33650 (epoch 26.952), train_loss = 0.95548890, grad/param norm = 1.5278e-01, time/batch = 16.4689s	
18140/33650 (epoch 26.954), train_loss = 0.97802001, grad/param norm = 1.4820e-01, time/batch = 18.4763s	
18141/33650 (epoch 26.955), train_loss = 0.95478157, grad/param norm = 1.5473e-01, time/batch = 16.1373s	
18142/33650 (epoch 26.957), train_loss = 0.98184248, grad/param norm = 1.6160e-01, time/batch = 18.0486s	
18143/33650 (epoch 26.958), train_loss = 0.73904042, grad/param norm = 1.4176e-01, time/batch = 17.5495s	
18144/33650 (epoch 26.960), train_loss = 0.75071370, grad/param norm = 1.3746e-01, time/batch = 17.5594s	
18145/33650 (epoch 26.961), train_loss = 0.80167298, grad/param norm = 1.4058e-01, time/batch = 17.3098s	
18146/33650 (epoch 26.963), train_loss = 0.84348062, grad/param norm = 1.5459e-01, time/batch = 16.1444s	
18147/33650 (epoch 26.964), train_loss = 0.99566993, grad/param norm = 1.5230e-01, time/batch = 17.6459s	
18148/33650 (epoch 26.966), train_loss = 0.92409358, grad/param norm = 1.4449e-01, time/batch = 17.5624s	
18149/33650 (epoch 26.967), train_loss = 0.94543695, grad/param norm = 1.5893e-01, time/batch = 16.9815s	
18150/33650 (epoch 26.969), train_loss = 0.92236560, grad/param norm = 1.5161e-01, time/batch = 15.8102s	
18151/33650 (epoch 26.970), train_loss = 0.94311198, grad/param norm = 1.5616e-01, time/batch = 18.0674s	
18152/33650 (epoch 26.972), train_loss = 1.19023799, grad/param norm = 1.6647e-01, time/batch = 17.5626s	
18153/33650 (epoch 26.973), train_loss = 0.81698233, grad/param norm = 1.3820e-01, time/batch = 16.2340s	
18154/33650 (epoch 26.975), train_loss = 0.82149700, grad/param norm = 1.3428e-01, time/batch = 17.8952s	
18155/33650 (epoch 26.976), train_loss = 0.82431073, grad/param norm = 1.2496e-01, time/batch = 16.9925s	
18156/33650 (epoch 26.978), train_loss = 0.84439990, grad/param norm = 1.4052e-01, time/batch = 15.6229s	
18157/33650 (epoch 26.979), train_loss = 0.89112296, grad/param norm = 1.4867e-01, time/batch = 15.8891s	
18158/33650 (epoch 26.981), train_loss = 0.86078430, grad/param norm = 1.3110e-01, time/batch = 16.5452s	
18159/33650 (epoch 26.982), train_loss = 0.93753486, grad/param norm = 1.5967e-01, time/batch = 17.4847s	
18160/33650 (epoch 26.984), train_loss = 0.76463171, grad/param norm = 1.3965e-01, time/batch = 17.0627s	
18161/33650 (epoch 26.985), train_loss = 0.79131970, grad/param norm = 1.4749e-01, time/batch = 17.2404s	
18162/33650 (epoch 26.987), train_loss = 0.90616491, grad/param norm = 1.4376e-01, time/batch = 17.7419s	
18163/33650 (epoch 26.988), train_loss = 0.89176355, grad/param norm = 1.5828e-01, time/batch = 14.5703s	
18164/33650 (epoch 26.990), train_loss = 1.06391855, grad/param norm = 1.7547e-01, time/batch = 16.9846s	
18165/33650 (epoch 26.991), train_loss = 0.94029031, grad/param norm = 1.5308e-01, time/batch = 17.3228s	
18166/33650 (epoch 26.993), train_loss = 0.92532962, grad/param norm = 1.7629e-01, time/batch = 18.1558s	
18167/33650 (epoch 26.994), train_loss = 0.89698566, grad/param norm = 1.3801e-01, time/batch = 15.7208s	
18168/33650 (epoch 26.996), train_loss = 0.85647711, grad/param norm = 2.6107e-01, time/batch = 17.1474s	
18169/33650 (epoch 26.997), train_loss = 0.98420337, grad/param norm = 1.6021e-01, time/batch = 17.9071s	
18170/33650 (epoch 26.999), train_loss = 0.83027592, grad/param norm = 1.6513e-01, time/batch = 17.8222s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
18171/33650 (epoch 27.000), train_loss = 0.98761662, grad/param norm = 1.7524e-01, time/batch = 16.9193s	
18172/33650 (epoch 27.001), train_loss = 1.05535250, grad/param norm = 1.8811e-01, time/batch = 17.6454s	
18173/33650 (epoch 27.003), train_loss = 1.05008402, grad/param norm = 1.9703e-01, time/batch = 18.1556s	
18174/33650 (epoch 27.004), train_loss = 0.94088013, grad/param norm = 1.5832e-01, time/batch = 16.8975s	
18175/33650 (epoch 27.006), train_loss = 0.88423830, grad/param norm = 1.4738e-01, time/batch = 17.7227s	
18176/33650 (epoch 27.007), train_loss = 0.97477058, grad/param norm = 1.5736e-01, time/batch = 17.7450s	
18177/33650 (epoch 27.009), train_loss = 0.87242915, grad/param norm = 1.7266e-01, time/batch = 17.3055s	
18178/33650 (epoch 27.010), train_loss = 0.99870717, grad/param norm = 1.6609e-01, time/batch = 17.1432s	
18179/33650 (epoch 27.012), train_loss = 0.85760110, grad/param norm = 1.4043e-01, time/batch = 15.3822s	
18180/33650 (epoch 27.013), train_loss = 0.90212282, grad/param norm = 1.6997e-01, time/batch = 17.0688s	
18181/33650 (epoch 27.015), train_loss = 0.90275794, grad/param norm = 1.5581e-01, time/batch = 16.1657s	
18182/33650 (epoch 27.016), train_loss = 0.82758696, grad/param norm = 1.5663e-01, time/batch = 16.0469s	
18183/33650 (epoch 27.018), train_loss = 0.90231720, grad/param norm = 1.9899e-01, time/batch = 17.0797s	
18184/33650 (epoch 27.019), train_loss = 0.86325431, grad/param norm = 1.5874e-01, time/batch = 17.6628s	
18185/33650 (epoch 27.021), train_loss = 0.97000266, grad/param norm = 1.5366e-01, time/batch = 16.8183s	
18186/33650 (epoch 27.022), train_loss = 0.86623807, grad/param norm = 1.3835e-01, time/batch = 17.6537s	
18187/33650 (epoch 27.024), train_loss = 0.84103027, grad/param norm = 1.5401e-01, time/batch = 18.3141s	
18188/33650 (epoch 27.025), train_loss = 0.92217848, grad/param norm = 1.6431e-01, time/batch = 16.4113s	
18189/33650 (epoch 27.027), train_loss = 0.94769247, grad/param norm = 1.6431e-01, time/batch = 17.4934s	
18190/33650 (epoch 27.028), train_loss = 0.96219278, grad/param norm = 1.4175e-01, time/batch = 17.7349s	
18191/33650 (epoch 27.030), train_loss = 0.90984676, grad/param norm = 1.6956e-01, time/batch = 16.8119s	
18192/33650 (epoch 27.031), train_loss = 0.83801075, grad/param norm = 1.3181e-01, time/batch = 17.2357s	
18193/33650 (epoch 27.033), train_loss = 0.91195638, grad/param norm = 1.3148e-01, time/batch = 17.4086s	
18194/33650 (epoch 27.034), train_loss = 0.95255846, grad/param norm = 1.6214e-01, time/batch = 17.1567s	
18195/33650 (epoch 27.036), train_loss = 1.03367781, grad/param norm = 1.7679e-01, time/batch = 15.9739s	
18196/33650 (epoch 27.037), train_loss = 0.87621470, grad/param norm = 1.4663e-01, time/batch = 17.8194s	
18197/33650 (epoch 27.039), train_loss = 0.99206218, grad/param norm = 1.6122e-01, time/batch = 15.2388s	
18198/33650 (epoch 27.040), train_loss = 1.09595672, grad/param norm = 2.0183e-01, time/batch = 17.3198s	
18199/33650 (epoch 27.042), train_loss = 1.11208981, grad/param norm = 1.8317e-01, time/batch = 17.7204s	
18200/33650 (epoch 27.043), train_loss = 0.85757856, grad/param norm = 1.4319e-01, time/batch = 17.2335s	
18201/33650 (epoch 27.045), train_loss = 0.86331481, grad/param norm = 1.3930e-01, time/batch = 18.2388s	
18202/33650 (epoch 27.046), train_loss = 0.97296471, grad/param norm = 1.8538e-01, time/batch = 15.6102s	
18203/33650 (epoch 27.048), train_loss = 1.00514516, grad/param norm = 1.6508e-01, time/batch = 17.1533s	
18204/33650 (epoch 27.049), train_loss = 0.90279600, grad/param norm = 1.5286e-01, time/batch = 17.8084s	
18205/33650 (epoch 27.051), train_loss = 1.07609820, grad/param norm = 1.9495e-01, time/batch = 17.6464s	
18206/33650 (epoch 27.052), train_loss = 1.06821245, grad/param norm = 1.7871e-01, time/batch = 15.6369s	
18207/33650 (epoch 27.053), train_loss = 0.99195526, grad/param norm = 1.5588e-01, time/batch = 17.6581s	
18208/33650 (epoch 27.055), train_loss = 0.83425669, grad/param norm = 1.5005e-01, time/batch = 16.5740s	
18209/33650 (epoch 27.056), train_loss = 0.81295243, grad/param norm = 1.2958e-01, time/batch = 16.3830s	
18210/33650 (epoch 27.058), train_loss = 0.99136558, grad/param norm = 1.8476e-01, time/batch = 16.9142s	
18211/33650 (epoch 27.059), train_loss = 0.98332561, grad/param norm = 1.6606e-01, time/batch = 17.4979s	
18212/33650 (epoch 27.061), train_loss = 1.02269618, grad/param norm = 1.6950e-01, time/batch = 17.0614s	
18213/33650 (epoch 27.062), train_loss = 0.96603507, grad/param norm = 1.4438e-01, time/batch = 17.0696s	
18214/33650 (epoch 27.064), train_loss = 0.88562158, grad/param norm = 1.4117e-01, time/batch = 16.8140s	
18215/33650 (epoch 27.065), train_loss = 0.90222678, grad/param norm = 1.5008e-01, time/batch = 17.6498s	
18216/33650 (epoch 27.067), train_loss = 0.81318852, grad/param norm = 1.2288e-01, time/batch = 16.9045s	
18217/33650 (epoch 27.068), train_loss = 0.91605557, grad/param norm = 1.9178e-01, time/batch = 16.6262s	
18218/33650 (epoch 27.070), train_loss = 0.97293528, grad/param norm = 1.6205e-01, time/batch = 17.9773s	
18219/33650 (epoch 27.071), train_loss = 0.87289952, grad/param norm = 1.5162e-01, time/batch = 16.8089s	
18220/33650 (epoch 27.073), train_loss = 0.96685231, grad/param norm = 1.4715e-01, time/batch = 16.3245s	
18221/33650 (epoch 27.074), train_loss = 1.05069691, grad/param norm = 1.5029e-01, time/batch = 15.7937s	
18222/33650 (epoch 27.076), train_loss = 1.00854829, grad/param norm = 1.9468e-01, time/batch = 17.9792s	
18223/33650 (epoch 27.077), train_loss = 0.93815038, grad/param norm = 1.4846e-01, time/batch = 16.7321s	
18224/33650 (epoch 27.079), train_loss = 0.95720002, grad/param norm = 1.4766e-01, time/batch = 17.6426s	
18225/33650 (epoch 27.080), train_loss = 0.97799655, grad/param norm = 1.7065e-01, time/batch = 17.9713s	
18226/33650 (epoch 27.082), train_loss = 0.93709177, grad/param norm = 1.6698e-01, time/batch = 17.0569s	
18227/33650 (epoch 27.083), train_loss = 0.96649971, grad/param norm = 1.4875e-01, time/batch = 17.3109s	
18228/33650 (epoch 27.085), train_loss = 1.02984135, grad/param norm = 1.5839e-01, time/batch = 17.2388s	
18229/33650 (epoch 27.086), train_loss = 0.99104015, grad/param norm = 1.9063e-01, time/batch = 17.7354s	
18230/33650 (epoch 27.088), train_loss = 0.94220660, grad/param norm = 1.5667e-01, time/batch = 29.8407s	
18231/33650 (epoch 27.089), train_loss = 0.89543371, grad/param norm = 1.5946e-01, time/batch = 16.6576s	
18232/33650 (epoch 27.091), train_loss = 0.89931335, grad/param norm = 1.3651e-01, time/batch = 17.8167s	
18233/33650 (epoch 27.092), train_loss = 0.92328441, grad/param norm = 1.7124e-01, time/batch = 16.7091s	
18234/33650 (epoch 27.094), train_loss = 0.99140866, grad/param norm = 1.3701e-01, time/batch = 16.5420s	
18235/33650 (epoch 27.095), train_loss = 0.98033285, grad/param norm = 1.7253e-01, time/batch = 17.0711s	
18236/33650 (epoch 27.097), train_loss = 0.87647719, grad/param norm = 1.5758e-01, time/batch = 17.1461s	
18237/33650 (epoch 27.098), train_loss = 0.75243788, grad/param norm = 1.3194e-01, time/batch = 16.0557s	
18238/33650 (epoch 27.100), train_loss = 0.85854531, grad/param norm = 1.5056e-01, time/batch = 18.2386s	
18239/33650 (epoch 27.101), train_loss = 0.92170459, grad/param norm = 1.6329e-01, time/batch = 17.5644s	
18240/33650 (epoch 27.103), train_loss = 0.92072503, grad/param norm = 1.6535e-01, time/batch = 16.8995s	
18241/33650 (epoch 27.104), train_loss = 1.04814251, grad/param norm = 1.5977e-01, time/batch = 17.8245s	
18242/33650 (epoch 27.105), train_loss = 0.93162427, grad/param norm = 1.5361e-01, time/batch = 16.9939s	
18243/33650 (epoch 27.107), train_loss = 0.88682870, grad/param norm = 1.4787e-01, time/batch = 16.3846s	
18244/33650 (epoch 27.108), train_loss = 1.00497813, grad/param norm = 1.8876e-01, time/batch = 17.4054s	
18245/33650 (epoch 27.110), train_loss = 1.08349199, grad/param norm = 1.6292e-01, time/batch = 18.3215s	
18246/33650 (epoch 27.111), train_loss = 0.90371260, grad/param norm = 1.5416e-01, time/batch = 17.6420s	
18247/33650 (epoch 27.113), train_loss = 0.89762257, grad/param norm = 1.8013e-01, time/batch = 16.8901s	
18248/33650 (epoch 27.114), train_loss = 0.98581482, grad/param norm = 1.4584e-01, time/batch = 16.4735s	
18249/33650 (epoch 27.116), train_loss = 0.83880223, grad/param norm = 1.2993e-01, time/batch = 18.2349s	
18250/33650 (epoch 27.117), train_loss = 0.91759793, grad/param norm = 1.3783e-01, time/batch = 16.3061s	
18251/33650 (epoch 27.119), train_loss = 0.84046095, grad/param norm = 1.5815e-01, time/batch = 18.1404s	
18252/33650 (epoch 27.120), train_loss = 0.87715430, grad/param norm = 1.4547e-01, time/batch = 16.8811s	
18253/33650 (epoch 27.122), train_loss = 0.73551564, grad/param norm = 1.6041e-01, time/batch = 16.8206s	
18254/33650 (epoch 27.123), train_loss = 0.88585659, grad/param norm = 1.4662e-01, time/batch = 16.3946s	
18255/33650 (epoch 27.125), train_loss = 0.97131188, grad/param norm = 1.5785e-01, time/batch = 18.0747s	
18256/33650 (epoch 27.126), train_loss = 1.02781165, grad/param norm = 1.8285e-01, time/batch = 17.2463s	
18257/33650 (epoch 27.128), train_loss = 0.99187554, grad/param norm = 1.6606e-01, time/batch = 16.3881s	
18258/33650 (epoch 27.129), train_loss = 1.01672295, grad/param norm = 1.5781e-01, time/batch = 17.3193s	
18259/33650 (epoch 27.131), train_loss = 0.94008347, grad/param norm = 1.6231e-01, time/batch = 17.4123s	
18260/33650 (epoch 27.132), train_loss = 0.92494123, grad/param norm = 1.4637e-01, time/batch = 16.5594s	
18261/33650 (epoch 27.134), train_loss = 1.02349062, grad/param norm = 1.6716e-01, time/batch = 17.6558s	
18262/33650 (epoch 27.135), train_loss = 0.83037159, grad/param norm = 1.4593e-01, time/batch = 17.6453s	
18263/33650 (epoch 27.137), train_loss = 0.97426692, grad/param norm = 2.2072e-01, time/batch = 16.0650s	
18264/33650 (epoch 27.138), train_loss = 0.99269270, grad/param norm = 1.5408e-01, time/batch = 16.5559s	
18265/33650 (epoch 27.140), train_loss = 0.93648848, grad/param norm = 1.8897e-01, time/batch = 17.1450s	
18266/33650 (epoch 27.141), train_loss = 1.07401289, grad/param norm = 1.6060e-01, time/batch = 17.6565s	
18267/33650 (epoch 27.143), train_loss = 1.08679660, grad/param norm = 1.9558e-01, time/batch = 16.7431s	
18268/33650 (epoch 27.144), train_loss = 0.98577081, grad/param norm = 1.8031e-01, time/batch = 17.8898s	
18269/33650 (epoch 27.146), train_loss = 0.90701417, grad/param norm = 1.5688e-01, time/batch = 17.9898s	
18270/33650 (epoch 27.147), train_loss = 0.87747139, grad/param norm = 1.5307e-01, time/batch = 17.2101s	
18271/33650 (epoch 27.149), train_loss = 0.83823661, grad/param norm = 1.5075e-01, time/batch = 16.4825s	
18272/33650 (epoch 27.150), train_loss = 0.81262272, grad/param norm = 1.4005e-01, time/batch = 17.6700s	
18273/33650 (epoch 27.152), train_loss = 0.86445879, grad/param norm = 1.4800e-01, time/batch = 17.1678s	
18274/33650 (epoch 27.153), train_loss = 0.89693479, grad/param norm = 1.5648e-01, time/batch = 15.6379s	
18275/33650 (epoch 27.155), train_loss = 0.85428294, grad/param norm = 1.3792e-01, time/batch = 17.7246s	
18276/33650 (epoch 27.156), train_loss = 0.84976187, grad/param norm = 1.4751e-01, time/batch = 16.6475s	
18277/33650 (epoch 27.158), train_loss = 0.95925358, grad/param norm = 1.4998e-01, time/batch = 16.6373s	
18278/33650 (epoch 27.159), train_loss = 0.84732903, grad/param norm = 1.3335e-01, time/batch = 17.2292s	
18279/33650 (epoch 27.160), train_loss = 0.87295661, grad/param norm = 1.3756e-01, time/batch = 17.3140s	
18280/33650 (epoch 27.162), train_loss = 0.89343944, grad/param norm = 1.5856e-01, time/batch = 18.0794s	
18281/33650 (epoch 27.163), train_loss = 0.95504008, grad/param norm = 1.6254e-01, time/batch = 16.9889s	
18282/33650 (epoch 27.165), train_loss = 0.80974719, grad/param norm = 1.4354e-01, time/batch = 17.1586s	
18283/33650 (epoch 27.166), train_loss = 0.82241810, grad/param norm = 1.4643e-01, time/batch = 17.9030s	
18284/33650 (epoch 27.168), train_loss = 1.02416227, grad/param norm = 1.7006e-01, time/batch = 16.8787s	
18285/33650 (epoch 27.169), train_loss = 0.93585025, grad/param norm = 1.5858e-01, time/batch = 15.8925s	
18286/33650 (epoch 27.171), train_loss = 0.92132420, grad/param norm = 1.5190e-01, time/batch = 16.3905s	
18287/33650 (epoch 27.172), train_loss = 0.87148844, grad/param norm = 1.5581e-01, time/batch = 17.7476s	
18288/33650 (epoch 27.174), train_loss = 0.83522053, grad/param norm = 1.5807e-01, time/batch = 16.2935s	
18289/33650 (epoch 27.175), train_loss = 0.81757947, grad/param norm = 1.8047e-01, time/batch = 16.0668s	
18290/33650 (epoch 27.177), train_loss = 0.91223187, grad/param norm = 1.4655e-01, time/batch = 17.5724s	
18291/33650 (epoch 27.178), train_loss = 0.87269939, grad/param norm = 1.7325e-01, time/batch = 17.3234s	
18292/33650 (epoch 27.180), train_loss = 0.82992924, grad/param norm = 1.5322e-01, time/batch = 16.3820s	
18293/33650 (epoch 27.181), train_loss = 0.74397685, grad/param norm = 1.3226e-01, time/batch = 16.3195s	
18294/33650 (epoch 27.183), train_loss = 0.85918411, grad/param norm = 1.6644e-01, time/batch = 17.9147s	
18295/33650 (epoch 27.184), train_loss = 0.84558417, grad/param norm = 1.7410e-01, time/batch = 17.0586s	
18296/33650 (epoch 27.186), train_loss = 0.91083901, grad/param norm = 1.9434e-01, time/batch = 16.8942s	
18297/33650 (epoch 27.187), train_loss = 1.05079355, grad/param norm = 1.7798e-01, time/batch = 17.1560s	
18298/33650 (epoch 27.189), train_loss = 1.02212107, grad/param norm = 1.8360e-01, time/batch = 17.7381s	
18299/33650 (epoch 27.190), train_loss = 0.93637412, grad/param norm = 1.5928e-01, time/batch = 15.8881s	
18300/33650 (epoch 27.192), train_loss = 1.09014384, grad/param norm = 1.5628e-01, time/batch = 17.9762s	
18301/33650 (epoch 27.193), train_loss = 1.05777785, grad/param norm = 1.5623e-01, time/batch = 18.3314s	
18302/33650 (epoch 27.195), train_loss = 0.79500758, grad/param norm = 1.4789e-01, time/batch = 16.2170s	
18303/33650 (epoch 27.196), train_loss = 0.77746053, grad/param norm = 1.4966e-01, time/batch = 17.8957s	
18304/33650 (epoch 27.198), train_loss = 0.87565363, grad/param norm = 1.5291e-01, time/batch = 17.3226s	
18305/33650 (epoch 27.199), train_loss = 0.99471923, grad/param norm = 1.7229e-01, time/batch = 17.7360s	
18306/33650 (epoch 27.201), train_loss = 0.88775649, grad/param norm = 1.6401e-01, time/batch = 16.9830s	
18307/33650 (epoch 27.202), train_loss = 0.91099751, grad/param norm = 1.6751e-01, time/batch = 17.3138s	
18308/33650 (epoch 27.204), train_loss = 0.96321730, grad/param norm = 1.6075e-01, time/batch = 15.9206s	
18309/33650 (epoch 27.205), train_loss = 0.87362028, grad/param norm = 1.5930e-01, time/batch = 16.9828s	
18310/33650 (epoch 27.207), train_loss = 0.85528418, grad/param norm = 1.6543e-01, time/batch = 17.6503s	
18311/33650 (epoch 27.208), train_loss = 0.93425166, grad/param norm = 1.5830e-01, time/batch = 17.1480s	
18312/33650 (epoch 27.210), train_loss = 0.74970442, grad/param norm = 1.5951e-01, time/batch = 16.1339s	
18313/33650 (epoch 27.211), train_loss = 0.86549608, grad/param norm = 1.6393e-01, time/batch = 16.0645s	
18314/33650 (epoch 27.212), train_loss = 0.97420667, grad/param norm = 1.7783e-01, time/batch = 16.1593s	
18315/33650 (epoch 27.214), train_loss = 1.07719441, grad/param norm = 1.5874e-01, time/batch = 17.8221s	
18316/33650 (epoch 27.215), train_loss = 0.70343955, grad/param norm = 1.5007e-01, time/batch = 15.9775s	
18317/33650 (epoch 27.217), train_loss = 0.88742858, grad/param norm = 1.6900e-01, time/batch = 16.9861s	
18318/33650 (epoch 27.218), train_loss = 0.91638243, grad/param norm = 1.5338e-01, time/batch = 17.8150s	
18319/33650 (epoch 27.220), train_loss = 0.80304065, grad/param norm = 1.5216e-01, time/batch = 17.9153s	
18320/33650 (epoch 27.221), train_loss = 1.07974705, grad/param norm = 1.7521e-01, time/batch = 16.9825s	
18321/33650 (epoch 27.223), train_loss = 0.74023711, grad/param norm = 1.4906e-01, time/batch = 18.0708s	
18322/33650 (epoch 27.224), train_loss = 0.85782066, grad/param norm = 1.6823e-01, time/batch = 17.4000s	
18323/33650 (epoch 27.226), train_loss = 1.18588623, grad/param norm = 1.7725e-01, time/batch = 16.4533s	
18324/33650 (epoch 27.227), train_loss = 1.03481355, grad/param norm = 1.7643e-01, time/batch = 16.7358s	
18325/33650 (epoch 27.229), train_loss = 1.01881464, grad/param norm = 1.5402e-01, time/batch = 17.9892s	
18326/33650 (epoch 27.230), train_loss = 1.15477473, grad/param norm = 2.0620e-01, time/batch = 17.6499s	
18327/33650 (epoch 27.232), train_loss = 1.03105084, grad/param norm = 2.0159e-01, time/batch = 15.7938s	
18328/33650 (epoch 27.233), train_loss = 0.99987018, grad/param norm = 1.9615e-01, time/batch = 18.1561s	
18329/33650 (epoch 27.235), train_loss = 0.91459613, grad/param norm = 1.4294e-01, time/batch = 16.5663s	
18330/33650 (epoch 27.236), train_loss = 0.84141913, grad/param norm = 1.4258e-01, time/batch = 17.6422s	
18331/33650 (epoch 27.238), train_loss = 0.88666963, grad/param norm = 1.3835e-01, time/batch = 16.9896s	
18332/33650 (epoch 27.239), train_loss = 0.84857936, grad/param norm = 1.5189e-01, time/batch = 17.5557s	
18333/33650 (epoch 27.241), train_loss = 0.88632740, grad/param norm = 1.3564e-01, time/batch = 17.6572s	
18334/33650 (epoch 27.242), train_loss = 0.73783996, grad/param norm = 1.3985e-01, time/batch = 16.9774s	
18335/33650 (epoch 27.244), train_loss = 0.91386573, grad/param norm = 1.5278e-01, time/batch = 17.4059s	
18336/33650 (epoch 27.245), train_loss = 0.80146792, grad/param norm = 1.2708e-01, time/batch = 17.9847s	
18337/33650 (epoch 27.247), train_loss = 0.89177428, grad/param norm = 1.3736e-01, time/batch = 16.2086s	
18338/33650 (epoch 27.248), train_loss = 0.81253980, grad/param norm = 1.4271e-01, time/batch = 17.1492s	
18339/33650 (epoch 27.250), train_loss = 0.90759352, grad/param norm = 1.4862e-01, time/batch = 17.2167s	
18340/33650 (epoch 27.251), train_loss = 1.03502854, grad/param norm = 1.6290e-01, time/batch = 17.4056s	
18341/33650 (epoch 27.253), train_loss = 0.78742748, grad/param norm = 1.4034e-01, time/batch = 16.8902s	
18342/33650 (epoch 27.254), train_loss = 0.84494334, grad/param norm = 1.4386e-01, time/batch = 17.3142s	
18343/33650 (epoch 27.256), train_loss = 1.04161542, grad/param norm = 1.3860e-01, time/batch = 18.4001s	
18344/33650 (epoch 27.257), train_loss = 1.03541464, grad/param norm = 1.6486e-01, time/batch = 16.8062s	
18345/33650 (epoch 27.259), train_loss = 0.80570014, grad/param norm = 1.6233e-01, time/batch = 17.5683s	
18346/33650 (epoch 27.260), train_loss = 0.97053204, grad/param norm = 1.5411e-01, time/batch = 17.9844s	
18347/33650 (epoch 27.262), train_loss = 0.94564162, grad/param norm = 1.8057e-01, time/batch = 16.4527s	
18348/33650 (epoch 27.263), train_loss = 0.86962044, grad/param norm = 2.0194e-01, time/batch = 17.2340s	
18349/33650 (epoch 27.264), train_loss = 0.96917260, grad/param norm = 1.7503e-01, time/batch = 17.5668s	
18350/33650 (epoch 27.266), train_loss = 0.95233246, grad/param norm = 1.8738e-01, time/batch = 17.4941s	
18351/33650 (epoch 27.267), train_loss = 0.86307517, grad/param norm = 1.5990e-01, time/batch = 17.2250s	
18352/33650 (epoch 27.269), train_loss = 0.92904587, grad/param norm = 1.5567e-01, time/batch = 17.3952s	
18353/33650 (epoch 27.270), train_loss = 0.83742860, grad/param norm = 1.4765e-01, time/batch = 17.9838s	
18354/33650 (epoch 27.272), train_loss = 0.88715326, grad/param norm = 1.4475e-01, time/batch = 17.2213s	
18355/33650 (epoch 27.273), train_loss = 1.01457723, grad/param norm = 1.8501e-01, time/batch = 16.1335s	
18356/33650 (epoch 27.275), train_loss = 0.97999208, grad/param norm = 1.7338e-01, time/batch = 16.6589s	
18357/33650 (epoch 27.276), train_loss = 0.99427481, grad/param norm = 1.6588e-01, time/batch = 18.2370s	
18358/33650 (epoch 27.278), train_loss = 1.08793579, grad/param norm = 1.7309e-01, time/batch = 16.1441s	
18359/33650 (epoch 27.279), train_loss = 0.89136491, grad/param norm = 1.5534e-01, time/batch = 16.4075s	
18360/33650 (epoch 27.281), train_loss = 0.93806704, grad/param norm = 1.7669e-01, time/batch = 18.2386s	
18361/33650 (epoch 27.282), train_loss = 1.04026160, grad/param norm = 1.5390e-01, time/batch = 17.4716s	
18362/33650 (epoch 27.284), train_loss = 0.99869155, grad/param norm = 1.8076e-01, time/batch = 17.0473s	
18363/33650 (epoch 27.285), train_loss = 0.96800986, grad/param norm = 1.6092e-01, time/batch = 17.2277s	
18364/33650 (epoch 27.287), train_loss = 0.89908347, grad/param norm = 1.8347e-01, time/batch = 16.9614s	
18365/33650 (epoch 27.288), train_loss = 0.95285110, grad/param norm = 1.9784e-01, time/batch = 15.6445s	
18366/33650 (epoch 27.290), train_loss = 0.93458117, grad/param norm = 1.5014e-01, time/batch = 17.1573s	
18367/33650 (epoch 27.291), train_loss = 0.82128766, grad/param norm = 1.4296e-01, time/batch = 17.8090s	
18368/33650 (epoch 27.293), train_loss = 0.91246110, grad/param norm = 1.8926e-01, time/batch = 17.2269s	
18369/33650 (epoch 27.294), train_loss = 0.84174487, grad/param norm = 1.3998e-01, time/batch = 17.4029s	
18370/33650 (epoch 27.296), train_loss = 0.82949568, grad/param norm = 1.5472e-01, time/batch = 17.4057s	
18371/33650 (epoch 27.297), train_loss = 0.89102451, grad/param norm = 1.4897e-01, time/batch = 17.8911s	
18372/33650 (epoch 27.299), train_loss = 0.80897831, grad/param norm = 1.5838e-01, time/batch = 16.2951s	
18373/33650 (epoch 27.300), train_loss = 0.82569454, grad/param norm = 1.5782e-01, time/batch = 17.5751s	
18374/33650 (epoch 27.302), train_loss = 0.94148615, grad/param norm = 1.3936e-01, time/batch = 17.0513s	
18375/33650 (epoch 27.303), train_loss = 0.93982118, grad/param norm = 1.4600e-01, time/batch = 16.9008s	
18376/33650 (epoch 27.305), train_loss = 0.92448132, grad/param norm = 1.5091e-01, time/batch = 17.3262s	
18377/33650 (epoch 27.306), train_loss = 0.85266100, grad/param norm = 1.6120e-01, time/batch = 17.1417s	
18378/33650 (epoch 27.308), train_loss = 0.80148027, grad/param norm = 1.4763e-01, time/batch = 18.4016s	
18379/33650 (epoch 27.309), train_loss = 1.06449245, grad/param norm = 1.7777e-01, time/batch = 17.4694s	
18380/33650 (epoch 27.311), train_loss = 0.92835207, grad/param norm = 1.8507e-01, time/batch = 17.2361s	
18381/33650 (epoch 27.312), train_loss = 0.95441087, grad/param norm = 1.7241e-01, time/batch = 17.2292s	
18382/33650 (epoch 27.314), train_loss = 0.82593557, grad/param norm = 1.3746e-01, time/batch = 16.8953s	
18383/33650 (epoch 27.315), train_loss = 0.91038335, grad/param norm = 2.2891e-01, time/batch = 15.4731s	
18384/33650 (epoch 27.316), train_loss = 0.87690647, grad/param norm = 1.7607e-01, time/batch = 16.8226s	
18385/33650 (epoch 27.318), train_loss = 0.82283800, grad/param norm = 1.3535e-01, time/batch = 18.0754s	
18386/33650 (epoch 27.319), train_loss = 0.84707788, grad/param norm = 1.4302e-01, time/batch = 17.1367s	
18387/33650 (epoch 27.321), train_loss = 0.87384217, grad/param norm = 1.4243e-01, time/batch = 17.5707s	
18388/33650 (epoch 27.322), train_loss = 0.94485048, grad/param norm = 1.9735e-01, time/batch = 16.3671s	
18389/33650 (epoch 27.324), train_loss = 0.96503297, grad/param norm = 2.0004e-01, time/batch = 17.2293s	
18390/33650 (epoch 27.325), train_loss = 0.97391543, grad/param norm = 1.6544e-01, time/batch = 17.8126s	
18391/33650 (epoch 27.327), train_loss = 0.85068330, grad/param norm = 1.4148e-01, time/batch = 17.0640s	
18392/33650 (epoch 27.328), train_loss = 0.94011913, grad/param norm = 1.5816e-01, time/batch = 17.2368s	
18393/33650 (epoch 27.330), train_loss = 0.86005727, grad/param norm = 1.3845e-01, time/batch = 17.3948s	
18394/33650 (epoch 27.331), train_loss = 0.77925962, grad/param norm = 1.2790e-01, time/batch = 17.8173s	
18395/33650 (epoch 27.333), train_loss = 0.89420166, grad/param norm = 1.5224e-01, time/batch = 18.4018s	
18396/33650 (epoch 27.334), train_loss = 0.90037470, grad/param norm = 1.4551e-01, time/batch = 16.7285s	
18397/33650 (epoch 27.336), train_loss = 1.01076554, grad/param norm = 1.6114e-01, time/batch = 17.8156s	
18398/33650 (epoch 27.337), train_loss = 0.77357888, grad/param norm = 1.5818e-01, time/batch = 17.8972s	
18399/33650 (epoch 27.339), train_loss = 0.88295659, grad/param norm = 1.4264e-01, time/batch = 16.8060s	
18400/33650 (epoch 27.340), train_loss = 1.02931251, grad/param norm = 1.6669e-01, time/batch = 17.9069s	
18401/33650 (epoch 27.342), train_loss = 0.75517848, grad/param norm = 1.4449e-01, time/batch = 17.4899s	
18402/33650 (epoch 27.343), train_loss = 0.96344893, grad/param norm = 1.5334e-01, time/batch = 15.0614s	
18403/33650 (epoch 27.345), train_loss = 0.91726478, grad/param norm = 1.9108e-01, time/batch = 15.8209s	
18404/33650 (epoch 27.346), train_loss = 0.64470593, grad/param norm = 1.3669e-01, time/batch = 17.5627s	
18405/33650 (epoch 27.348), train_loss = 0.80484733, grad/param norm = 1.4272e-01, time/batch = 17.6565s	
18406/33650 (epoch 27.349), train_loss = 0.74689246, grad/param norm = 1.4524e-01, time/batch = 17.2160s	
18407/33650 (epoch 27.351), train_loss = 0.98554252, grad/param norm = 1.5738e-01, time/batch = 17.4813s	
18408/33650 (epoch 27.352), train_loss = 0.88158552, grad/param norm = 1.5659e-01, time/batch = 17.6644s	
18409/33650 (epoch 27.354), train_loss = 1.03624497, grad/param norm = 1.9917e-01, time/batch = 18.1544s	
18410/33650 (epoch 27.355), train_loss = 1.06095178, grad/param norm = 1.6252e-01, time/batch = 16.4150s	
18411/33650 (epoch 27.357), train_loss = 0.74226651, grad/param norm = 1.4109e-01, time/batch = 16.7225s	
18412/33650 (epoch 27.358), train_loss = 0.97806548, grad/param norm = 1.6155e-01, time/batch = 17.9936s	
18413/33650 (epoch 27.360), train_loss = 0.97672662, grad/param norm = 1.7630e-01, time/batch = 16.9630s	
18414/33650 (epoch 27.361), train_loss = 0.94202169, grad/param norm = 1.5224e-01, time/batch = 17.8159s	
18415/33650 (epoch 27.363), train_loss = 0.91316459, grad/param norm = 1.4623e-01, time/batch = 16.5900s	
18416/33650 (epoch 27.364), train_loss = 0.89210586, grad/param norm = 1.3897e-01, time/batch = 17.6527s	
18417/33650 (epoch 27.366), train_loss = 0.97981481, grad/param norm = 1.7448e-01, time/batch = 16.0620s	
18418/33650 (epoch 27.367), train_loss = 0.94096859, grad/param norm = 1.4287e-01, time/batch = 17.9845s	
18419/33650 (epoch 27.368), train_loss = 0.84138650, grad/param norm = 1.3234e-01, time/batch = 17.3229s	
18420/33650 (epoch 27.370), train_loss = 0.89935695, grad/param norm = 1.4405e-01, time/batch = 17.0554s	
18421/33650 (epoch 27.371), train_loss = 0.70014484, grad/param norm = 1.3130e-01, time/batch = 17.8088s	
18422/33650 (epoch 27.373), train_loss = 0.81546838, grad/param norm = 1.3911e-01, time/batch = 17.6578s	
18423/33650 (epoch 27.374), train_loss = 0.81765837, grad/param norm = 1.3598e-01, time/batch = 15.7344s	
18424/33650 (epoch 27.376), train_loss = 0.90418579, grad/param norm = 1.7001e-01, time/batch = 16.3970s	
18425/33650 (epoch 27.377), train_loss = 0.91623572, grad/param norm = 1.6037e-01, time/batch = 17.4826s	
18426/33650 (epoch 27.379), train_loss = 0.94706410, grad/param norm = 1.5305e-01, time/batch = 17.0694s	
18427/33650 (epoch 27.380), train_loss = 0.74967134, grad/param norm = 1.5413e-01, time/batch = 16.8231s	
18428/33650 (epoch 27.382), train_loss = 0.88212509, grad/param norm = 1.2705e-01, time/batch = 16.4697s	
18429/33650 (epoch 27.383), train_loss = 0.90314948, grad/param norm = 1.5312e-01, time/batch = 17.4638s	
18430/33650 (epoch 27.385), train_loss = 0.95937085, grad/param norm = 1.5970e-01, time/batch = 17.9024s	
18431/33650 (epoch 27.386), train_loss = 0.85202707, grad/param norm = 1.4439e-01, time/batch = 17.2100s	
18432/33650 (epoch 27.388), train_loss = 0.96897359, grad/param norm = 1.4550e-01, time/batch = 17.3053s	
18433/33650 (epoch 27.389), train_loss = 0.88053051, grad/param norm = 1.7041e-01, time/batch = 16.4917s	
18434/33650 (epoch 27.391), train_loss = 0.73235256, grad/param norm = 1.3689e-01, time/batch = 16.9842s	
18435/33650 (epoch 27.392), train_loss = 0.92736615, grad/param norm = 1.6019e-01, time/batch = 17.1455s	
18436/33650 (epoch 27.394), train_loss = 0.92770516, grad/param norm = 1.7980e-01, time/batch = 17.3933s	
18437/33650 (epoch 27.395), train_loss = 0.96444355, grad/param norm = 1.5155e-01, time/batch = 17.9853s	
18438/33650 (epoch 27.397), train_loss = 1.04208085, grad/param norm = 1.5729e-01, time/batch = 31.2320s	
18439/33650 (epoch 27.398), train_loss = 0.94668312, grad/param norm = 1.4810e-01, time/batch = 18.3174s	
18440/33650 (epoch 27.400), train_loss = 0.91560847, grad/param norm = 1.6969e-01, time/batch = 16.4908s	
18441/33650 (epoch 27.401), train_loss = 0.86361791, grad/param norm = 1.8691e-01, time/batch = 16.1404s	
18442/33650 (epoch 27.403), train_loss = 0.94995823, grad/param norm = 1.7028e-01, time/batch = 16.3797s	
18443/33650 (epoch 27.404), train_loss = 0.90527163, grad/param norm = 1.5345e-01, time/batch = 17.9034s	
18444/33650 (epoch 27.406), train_loss = 0.89124417, grad/param norm = 1.5774e-01, time/batch = 16.5551s	
18445/33650 (epoch 27.407), train_loss = 0.89596504, grad/param norm = 1.5497e-01, time/batch = 17.2285s	
18446/33650 (epoch 27.409), train_loss = 0.96095281, grad/param norm = 1.7775e-01, time/batch = 17.4841s	
18447/33650 (epoch 27.410), train_loss = 0.88728993, grad/param norm = 1.4191e-01, time/batch = 17.1388s	
18448/33650 (epoch 27.412), train_loss = 0.90316834, grad/param norm = 1.3958e-01, time/batch = 17.7328s	
18449/33650 (epoch 27.413), train_loss = 0.86146156, grad/param norm = 1.6424e-01, time/batch = 17.4857s	
18450/33650 (epoch 27.415), train_loss = 0.99095534, grad/param norm = 1.6972e-01, time/batch = 17.8245s	
18451/33650 (epoch 27.416), train_loss = 1.06210520, grad/param norm = 1.6408e-01, time/batch = 17.5657s	
18452/33650 (epoch 27.418), train_loss = 0.84578156, grad/param norm = 1.4881e-01, time/batch = 16.8172s	
18453/33650 (epoch 27.419), train_loss = 0.86438349, grad/param norm = 1.5830e-01, time/batch = 16.1421s	
18454/33650 (epoch 27.421), train_loss = 0.89002136, grad/param norm = 1.4154e-01, time/batch = 17.3067s	
18455/33650 (epoch 27.422), train_loss = 1.03639248, grad/param norm = 1.5537e-01, time/batch = 17.6421s	
18456/33650 (epoch 27.423), train_loss = 0.82786452, grad/param norm = 1.2779e-01, time/batch = 17.3177s	
18457/33650 (epoch 27.425), train_loss = 0.90367228, grad/param norm = 1.7832e-01, time/batch = 18.2412s	
18458/33650 (epoch 27.426), train_loss = 1.04493453, grad/param norm = 1.8179e-01, time/batch = 17.3162s	
18459/33650 (epoch 27.428), train_loss = 0.87813503, grad/param norm = 1.5511e-01, time/batch = 15.8179s	
18460/33650 (epoch 27.429), train_loss = 0.98508581, grad/param norm = 2.0009e-01, time/batch = 17.2596s	
18461/33650 (epoch 27.431), train_loss = 1.07135622, grad/param norm = 1.8316e-01, time/batch = 17.1352s	
18462/33650 (epoch 27.432), train_loss = 1.09129273, grad/param norm = 2.0520e-01, time/batch = 16.8671s	
18463/33650 (epoch 27.434), train_loss = 0.95408883, grad/param norm = 1.6365e-01, time/batch = 17.8989s	
18464/33650 (epoch 27.435), train_loss = 0.95343557, grad/param norm = 1.8824e-01, time/batch = 17.6473s	
18465/33650 (epoch 27.437), train_loss = 0.92622221, grad/param norm = 1.5900e-01, time/batch = 17.3132s	
18466/33650 (epoch 27.438), train_loss = 0.89878029, grad/param norm = 1.6997e-01, time/batch = 16.7403s	
18467/33650 (epoch 27.440), train_loss = 0.91574912, grad/param norm = 1.8229e-01, time/batch = 16.9052s	
18468/33650 (epoch 27.441), train_loss = 0.92948226, grad/param norm = 1.6759e-01, time/batch = 16.8058s	
18469/33650 (epoch 27.443), train_loss = 0.97458316, grad/param norm = 1.4917e-01, time/batch = 16.3227s	
18470/33650 (epoch 27.444), train_loss = 0.90913336, grad/param norm = 1.6808e-01, time/batch = 17.4019s	
18471/33650 (epoch 27.446), train_loss = 0.94837308, grad/param norm = 1.7118e-01, time/batch = 17.0656s	
18472/33650 (epoch 27.447), train_loss = 1.05284443, grad/param norm = 1.9121e-01, time/batch = 16.1175s	
18473/33650 (epoch 27.449), train_loss = 1.05234275, grad/param norm = 1.7335e-01, time/batch = 16.9784s	
18474/33650 (epoch 27.450), train_loss = 1.09308038, grad/param norm = 1.7811e-01, time/batch = 18.2353s	
18475/33650 (epoch 27.452), train_loss = 1.07427102, grad/param norm = 1.9551e-01, time/batch = 15.7354s	
18476/33650 (epoch 27.453), train_loss = 1.07402145, grad/param norm = 1.6590e-01, time/batch = 18.2336s	
18477/33650 (epoch 27.455), train_loss = 0.90193115, grad/param norm = 1.4461e-01, time/batch = 17.5726s	
18478/33650 (epoch 27.456), train_loss = 0.90533300, grad/param norm = 1.5918e-01, time/batch = 17.7397s	
18479/33650 (epoch 27.458), train_loss = 0.90510451, grad/param norm = 1.7698e-01, time/batch = 15.6330s	
18480/33650 (epoch 27.459), train_loss = 0.96400034, grad/param norm = 1.7300e-01, time/batch = 17.6378s	
18481/33650 (epoch 27.461), train_loss = 1.03265607, grad/param norm = 1.6647e-01, time/batch = 18.2315s	
18482/33650 (epoch 27.462), train_loss = 1.03621810, grad/param norm = 1.7743e-01, time/batch = 16.9739s	
18483/33650 (epoch 27.464), train_loss = 0.90158648, grad/param norm = 1.7169e-01, time/batch = 17.2382s	
18484/33650 (epoch 27.465), train_loss = 0.95317669, grad/param norm = 1.7984e-01, time/batch = 17.9836s	
18485/33650 (epoch 27.467), train_loss = 0.97273720, grad/param norm = 1.5590e-01, time/batch = 17.3082s	
18486/33650 (epoch 27.468), train_loss = 1.07473440, grad/param norm = 1.4543e-01, time/batch = 16.9864s	
18487/33650 (epoch 27.470), train_loss = 1.13977369, grad/param norm = 1.7587e-01, time/batch = 17.9125s	
18488/33650 (epoch 27.471), train_loss = 0.94376625, grad/param norm = 1.4684e-01, time/batch = 17.4987s	
18489/33650 (epoch 27.473), train_loss = 0.90580122, grad/param norm = 1.5498e-01, time/batch = 16.3145s	
18490/33650 (epoch 27.474), train_loss = 1.04476751, grad/param norm = 1.7018e-01, time/batch = 17.5741s	
18491/33650 (epoch 27.475), train_loss = 0.99366811, grad/param norm = 1.6333e-01, time/batch = 17.6540s	
18492/33650 (epoch 27.477), train_loss = 1.04761620, grad/param norm = 1.7020e-01, time/batch = 16.9925s	
18493/33650 (epoch 27.478), train_loss = 1.01366982, grad/param norm = 1.7517e-01, time/batch = 16.1208s	
18494/33650 (epoch 27.480), train_loss = 1.01315667, grad/param norm = 1.6934e-01, time/batch = 16.9133s	
18495/33650 (epoch 27.481), train_loss = 1.06851410, grad/param norm = 1.7246e-01, time/batch = 17.9962s	
18496/33650 (epoch 27.483), train_loss = 0.79672045, grad/param norm = 1.5351e-01, time/batch = 16.5454s	
18497/33650 (epoch 27.484), train_loss = 0.91998041, grad/param norm = 1.5441e-01, time/batch = 16.6391s	
18498/33650 (epoch 27.486), train_loss = 1.08880300, grad/param norm = 1.7228e-01, time/batch = 17.6542s	
18499/33650 (epoch 27.487), train_loss = 1.06238146, grad/param norm = 1.7352e-01, time/batch = 16.8151s	
18500/33650 (epoch 27.489), train_loss = 1.09505875, grad/param norm = 1.6297e-01, time/batch = 17.3952s	
18501/33650 (epoch 27.490), train_loss = 0.86563260, grad/param norm = 1.6386e-01, time/batch = 18.1468s	
18502/33650 (epoch 27.492), train_loss = 0.98547017, grad/param norm = 1.6937e-01, time/batch = 17.7384s	
18503/33650 (epoch 27.493), train_loss = 0.78475647, grad/param norm = 1.3208e-01, time/batch = 16.7888s	
18504/33650 (epoch 27.495), train_loss = 0.95748079, grad/param norm = 1.4924e-01, time/batch = 17.4024s	
18505/33650 (epoch 27.496), train_loss = 0.99551091, grad/param norm = 1.7306e-01, time/batch = 17.6493s	
18506/33650 (epoch 27.498), train_loss = 0.86606084, grad/param norm = 1.4979e-01, time/batch = 16.8103s	
18507/33650 (epoch 27.499), train_loss = 0.95165006, grad/param norm = 1.3874e-01, time/batch = 17.3991s	
18508/33650 (epoch 27.501), train_loss = 0.92324508, grad/param norm = 1.2956e-01, time/batch = 16.5598s	
18509/33650 (epoch 27.502), train_loss = 0.96743233, grad/param norm = 1.7396e-01, time/batch = 17.0742s	
18510/33650 (epoch 27.504), train_loss = 1.03703583, grad/param norm = 1.9413e-01, time/batch = 15.6276s	
18511/33650 (epoch 27.505), train_loss = 0.92201635, grad/param norm = 2.0735e-01, time/batch = 17.7275s	
18512/33650 (epoch 27.507), train_loss = 1.03937780, grad/param norm = 1.5412e-01, time/batch = 17.9102s	
18513/33650 (epoch 27.508), train_loss = 0.92983631, grad/param norm = 1.5280e-01, time/batch = 16.3278s	
18514/33650 (epoch 27.510), train_loss = 0.94669223, grad/param norm = 1.5711e-01, time/batch = 16.8991s	
18515/33650 (epoch 27.511), train_loss = 1.12702546, grad/param norm = 2.0179e-01, time/batch = 17.3220s	
18516/33650 (epoch 27.513), train_loss = 0.98822408, grad/param norm = 1.5829e-01, time/batch = 17.4830s	
18517/33650 (epoch 27.514), train_loss = 1.02879445, grad/param norm = 1.7645e-01, time/batch = 15.7045s	
18518/33650 (epoch 27.516), train_loss = 0.95443605, grad/param norm = 1.9339e-01, time/batch = 17.8294s	
18519/33650 (epoch 27.517), train_loss = 0.95150320, grad/param norm = 1.6834e-01, time/batch = 16.9872s	
18520/33650 (epoch 27.519), train_loss = 0.99509240, grad/param norm = 1.4975e-01, time/batch = 16.4832s	
18521/33650 (epoch 27.520), train_loss = 0.80396111, grad/param norm = 1.2301e-01, time/batch = 16.1545s	
18522/33650 (epoch 27.522), train_loss = 0.94839312, grad/param norm = 1.6607e-01, time/batch = 17.6594s	
18523/33650 (epoch 27.523), train_loss = 0.88644288, grad/param norm = 1.6236e-01, time/batch = 17.9884s	
18524/33650 (epoch 27.525), train_loss = 0.74853724, grad/param norm = 1.2959e-01, time/batch = 16.0509s	
18525/33650 (epoch 27.526), train_loss = 1.04292406, grad/param norm = 1.5488e-01, time/batch = 16.9778s	
18526/33650 (epoch 27.527), train_loss = 0.88958054, grad/param norm = 1.4293e-01, time/batch = 17.3199s	
18527/33650 (epoch 27.529), train_loss = 0.92490752, grad/param norm = 1.6191e-01, time/batch = 17.8123s	
18528/33650 (epoch 27.530), train_loss = 0.89970879, grad/param norm = 1.6582e-01, time/batch = 17.1572s	
18529/33650 (epoch 27.532), train_loss = 1.01682789, grad/param norm = 1.7060e-01, time/batch = 16.8873s	
18530/33650 (epoch 27.533), train_loss = 0.92742683, grad/param norm = 1.4713e-01, time/batch = 17.5664s	
18531/33650 (epoch 27.535), train_loss = 1.05333370, grad/param norm = 1.5519e-01, time/batch = 16.2975s	
18532/33650 (epoch 27.536), train_loss = 0.97740656, grad/param norm = 1.8562e-01, time/batch = 17.4766s	
18533/33650 (epoch 27.538), train_loss = 0.98665428, grad/param norm = 1.7584e-01, time/batch = 17.7437s	
18534/33650 (epoch 27.539), train_loss = 0.75734155, grad/param norm = 1.4711e-01, time/batch = 17.0681s	
18535/33650 (epoch 27.541), train_loss = 1.02806127, grad/param norm = 1.8174e-01, time/batch = 17.3948s	
18536/33650 (epoch 27.542), train_loss = 0.94939457, grad/param norm = 2.0443e-01, time/batch = 17.7243s	
18537/33650 (epoch 27.544), train_loss = 1.10602356, grad/param norm = 1.9638e-01, time/batch = 17.5835s	
18538/33650 (epoch 27.545), train_loss = 0.83572972, grad/param norm = 1.5971e-01, time/batch = 16.9829s	
18539/33650 (epoch 27.547), train_loss = 0.98918077, grad/param norm = 1.6000e-01, time/batch = 17.6608s	
18540/33650 (epoch 27.548), train_loss = 1.11291215, grad/param norm = 1.7199e-01, time/batch = 15.8817s	
18541/33650 (epoch 27.550), train_loss = 0.97421501, grad/param norm = 1.6446e-01, time/batch = 17.0645s	
18542/33650 (epoch 27.551), train_loss = 0.95187748, grad/param norm = 1.5939e-01, time/batch = 16.5715s	
18543/33650 (epoch 27.553), train_loss = 0.81011994, grad/param norm = 1.6323e-01, time/batch = 17.9866s	
18544/33650 (epoch 27.554), train_loss = 1.10107619, grad/param norm = 1.8103e-01, time/batch = 16.6424s	
18545/33650 (epoch 27.556), train_loss = 1.03429554, grad/param norm = 2.0665e-01, time/batch = 16.0487s	
18546/33650 (epoch 27.557), train_loss = 1.03516406, grad/param norm = 1.8420e-01, time/batch = 17.9751s	
18547/33650 (epoch 27.559), train_loss = 1.19960967, grad/param norm = 1.9740e-01, time/batch = 17.2382s	
18548/33650 (epoch 27.560), train_loss = 1.14331876, grad/param norm = 1.8234e-01, time/batch = 17.0469s	
18549/33650 (epoch 27.562), train_loss = 1.08461799, grad/param norm = 1.5788e-01, time/batch = 16.7366s	
18550/33650 (epoch 27.563), train_loss = 0.99965692, grad/param norm = 1.6690e-01, time/batch = 17.9823s	
18551/33650 (epoch 27.565), train_loss = 0.95842249, grad/param norm = 1.6077e-01, time/batch = 17.8081s	
18552/33650 (epoch 27.566), train_loss = 0.92897059, grad/param norm = 1.6829e-01, time/batch = 16.9036s	
18553/33650 (epoch 27.568), train_loss = 0.96700410, grad/param norm = 1.8859e-01, time/batch = 17.8179s	
18554/33650 (epoch 27.569), train_loss = 0.88576889, grad/param norm = 1.4384e-01, time/batch = 16.9923s	
18555/33650 (epoch 27.571), train_loss = 1.05326204, grad/param norm = 1.7047e-01, time/batch = 16.4788s	
18556/33650 (epoch 27.572), train_loss = 1.01344964, grad/param norm = 1.5363e-01, time/batch = 17.0724s	
18557/33650 (epoch 27.574), train_loss = 0.88716148, grad/param norm = 1.7772e-01, time/batch = 16.8273s	
18558/33650 (epoch 27.575), train_loss = 0.94173256, grad/param norm = 1.5254e-01, time/batch = 16.8961s	
18559/33650 (epoch 27.577), train_loss = 0.89822905, grad/param norm = 1.6701e-01, time/batch = 16.5586s	
18560/33650 (epoch 27.578), train_loss = 1.05011513, grad/param norm = 1.6855e-01, time/batch = 16.6356s	
18561/33650 (epoch 27.579), train_loss = 1.01176514, grad/param norm = 1.6700e-01, time/batch = 17.2414s	
18562/33650 (epoch 27.581), train_loss = 1.08288160, grad/param norm = 1.5831e-01, time/batch = 16.8150s	
18563/33650 (epoch 27.582), train_loss = 0.98169646, grad/param norm = 1.3317e-01, time/batch = 16.1477s	
18564/33650 (epoch 27.584), train_loss = 0.96816198, grad/param norm = 1.4987e-01, time/batch = 17.7178s	
18565/33650 (epoch 27.585), train_loss = 1.00233933, grad/param norm = 1.7995e-01, time/batch = 17.8932s	
18566/33650 (epoch 27.587), train_loss = 0.87389421, grad/param norm = 1.5185e-01, time/batch = 17.3951s	
18567/33650 (epoch 27.588), train_loss = 0.92764131, grad/param norm = 2.1322e-01, time/batch = 16.9823s	
18568/33650 (epoch 27.590), train_loss = 0.90338485, grad/param norm = 1.5358e-01, time/batch = 17.4062s	
18569/33650 (epoch 27.591), train_loss = 0.86188396, grad/param norm = 1.5546e-01, time/batch = 16.7207s	
18570/33650 (epoch 27.593), train_loss = 0.86567681, grad/param norm = 1.5714e-01, time/batch = 17.6288s	
18571/33650 (epoch 27.594), train_loss = 0.84781486, grad/param norm = 1.5094e-01, time/batch = 18.1417s	
18572/33650 (epoch 27.596), train_loss = 0.93275269, grad/param norm = 1.5108e-01, time/batch = 16.9720s	
18573/33650 (epoch 27.597), train_loss = 0.80314313, grad/param norm = 1.3910e-01, time/batch = 16.5548s	
18574/33650 (epoch 27.599), train_loss = 0.92309052, grad/param norm = 1.5699e-01, time/batch = 15.9755s	
18575/33650 (epoch 27.600), train_loss = 0.86192331, grad/param norm = 1.4726e-01, time/batch = 18.1378s	
18576/33650 (epoch 27.602), train_loss = 0.96631294, grad/param norm = 1.6376e-01, time/batch = 15.8817s	
18577/33650 (epoch 27.603), train_loss = 0.87254833, grad/param norm = 1.4941e-01, time/batch = 17.7275s	
18578/33650 (epoch 27.605), train_loss = 1.00764145, grad/param norm = 1.5707e-01, time/batch = 16.9069s	
18579/33650 (epoch 27.606), train_loss = 0.95755119, grad/param norm = 1.7358e-01, time/batch = 17.8164s	
18580/33650 (epoch 27.608), train_loss = 0.83987576, grad/param norm = 1.5859e-01, time/batch = 16.8165s	
18581/33650 (epoch 27.609), train_loss = 0.93128628, grad/param norm = 1.5237e-01, time/batch = 18.3140s	
18582/33650 (epoch 27.611), train_loss = 0.84158716, grad/param norm = 1.5641e-01, time/batch = 17.0735s	
18583/33650 (epoch 27.612), train_loss = 0.94394840, grad/param norm = 1.9146e-01, time/batch = 17.2274s	
18584/33650 (epoch 27.614), train_loss = 1.03173945, grad/param norm = 1.6101e-01, time/batch = 16.9797s	
18585/33650 (epoch 27.615), train_loss = 0.94481377, grad/param norm = 1.4056e-01, time/batch = 17.9093s	
18586/33650 (epoch 27.617), train_loss = 0.84441649, grad/param norm = 1.3141e-01, time/batch = 17.0716s	
18587/33650 (epoch 27.618), train_loss = 0.90391559, grad/param norm = 1.4434e-01, time/batch = 16.7370s	
18588/33650 (epoch 27.620), train_loss = 0.90243753, grad/param norm = 1.6199e-01, time/batch = 16.7315s	
18589/33650 (epoch 27.621), train_loss = 0.88622456, grad/param norm = 1.6370e-01, time/batch = 17.1430s	
18590/33650 (epoch 27.623), train_loss = 0.92560105, grad/param norm = 1.7782e-01, time/batch = 16.6574s	
18591/33650 (epoch 27.624), train_loss = 0.73188609, grad/param norm = 1.4694e-01, time/batch = 17.3968s	
18592/33650 (epoch 27.626), train_loss = 0.77136617, grad/param norm = 1.5414e-01, time/batch = 17.8258s	
18593/33650 (epoch 27.627), train_loss = 0.86641067, grad/param norm = 1.5445e-01, time/batch = 16.8939s	
18594/33650 (epoch 27.629), train_loss = 0.87440201, grad/param norm = 1.4554e-01, time/batch = 15.7461s	
18595/33650 (epoch 27.630), train_loss = 1.03323158, grad/param norm = 1.8047e-01, time/batch = 17.9002s	
18596/33650 (epoch 27.632), train_loss = 1.04491514, grad/param norm = 1.6226e-01, time/batch = 16.4759s	
18597/33650 (epoch 27.633), train_loss = 1.00896997, grad/param norm = 1.6820e-01, time/batch = 15.0545s	
18598/33650 (epoch 27.634), train_loss = 0.82083179, grad/param norm = 1.4527e-01, time/batch = 17.3124s	
18599/33650 (epoch 27.636), train_loss = 0.72740796, grad/param norm = 1.2139e-01, time/batch = 18.1581s	
18600/33650 (epoch 27.637), train_loss = 0.84984562, grad/param norm = 1.4474e-01, time/batch = 17.1570s	
18601/33650 (epoch 27.639), train_loss = 0.86006131, grad/param norm = 1.4797e-01, time/batch = 16.5653s	
18602/33650 (epoch 27.640), train_loss = 0.93264876, grad/param norm = 1.5257e-01, time/batch = 17.8973s	
18603/33650 (epoch 27.642), train_loss = 0.99307883, grad/param norm = 1.7060e-01, time/batch = 17.4120s	
18604/33650 (epoch 27.643), train_loss = 0.94831099, grad/param norm = 1.7782e-01, time/batch = 16.4864s	
18605/33650 (epoch 27.645), train_loss = 0.94527917, grad/param norm = 1.5236e-01, time/batch = 17.5706s	
18606/33650 (epoch 27.646), train_loss = 0.81281816, grad/param norm = 1.2951e-01, time/batch = 16.8087s	
18607/33650 (epoch 27.648), train_loss = 0.96426454, grad/param norm = 1.5787e-01, time/batch = 17.1463s	
18608/33650 (epoch 27.649), train_loss = 0.87094268, grad/param norm = 1.9773e-01, time/batch = 17.5472s	
18609/33650 (epoch 27.651), train_loss = 0.99157598, grad/param norm = 1.5948e-01, time/batch = 15.9889s	
18610/33650 (epoch 27.652), train_loss = 0.68908587, grad/param norm = 1.3261e-01, time/batch = 17.0817s	
18611/33650 (epoch 27.654), train_loss = 0.83775729, grad/param norm = 1.5547e-01, time/batch = 15.2139s	
18612/33650 (epoch 27.655), train_loss = 0.81500924, grad/param norm = 1.3768e-01, time/batch = 17.3943s	
18613/33650 (epoch 27.657), train_loss = 0.89083160, grad/param norm = 1.5988e-01, time/batch = 16.5647s	
18614/33650 (epoch 27.658), train_loss = 0.75610093, grad/param norm = 1.5372e-01, time/batch = 17.2371s	
18615/33650 (epoch 27.660), train_loss = 0.75043091, grad/param norm = 1.4420e-01, time/batch = 16.7202s	
18616/33650 (epoch 27.661), train_loss = 0.81736263, grad/param norm = 1.4355e-01, time/batch = 17.9154s	
18617/33650 (epoch 27.663), train_loss = 0.79162876, grad/param norm = 1.4976e-01, time/batch = 17.6645s	
18618/33650 (epoch 27.664), train_loss = 0.87600002, grad/param norm = 1.5197e-01, time/batch = 16.8159s	
18619/33650 (epoch 27.666), train_loss = 0.87331847, grad/param norm = 1.2662e-01, time/batch = 17.3160s	
18620/33650 (epoch 27.667), train_loss = 0.78859805, grad/param norm = 1.3929e-01, time/batch = 16.7942s	
18621/33650 (epoch 27.669), train_loss = 0.81755930, grad/param norm = 1.6220e-01, time/batch = 16.8989s	
18622/33650 (epoch 27.670), train_loss = 0.74611682, grad/param norm = 1.3959e-01, time/batch = 17.7212s	
18623/33650 (epoch 27.672), train_loss = 0.77074713, grad/param norm = 1.4880e-01, time/batch = 17.6538s	
18624/33650 (epoch 27.673), train_loss = 0.74866974, grad/param norm = 1.4801e-01, time/batch = 17.0790s	
18625/33650 (epoch 27.675), train_loss = 0.71394481, grad/param norm = 1.2443e-01, time/batch = 16.4821s	
18626/33650 (epoch 27.676), train_loss = 0.88185274, grad/param norm = 1.5615e-01, time/batch = 16.4054s	
18627/33650 (epoch 27.678), train_loss = 0.86711720, grad/param norm = 1.4989e-01, time/batch = 18.0731s	
18628/33650 (epoch 27.679), train_loss = 0.84966862, grad/param norm = 1.6613e-01, time/batch = 16.4869s	
18629/33650 (epoch 27.681), train_loss = 0.88338948, grad/param norm = 1.4361e-01, time/batch = 4.2124s	
18630/33650 (epoch 27.682), train_loss = 0.79704676, grad/param norm = 1.5290e-01, time/batch = 0.6489s	
18631/33650 (epoch 27.684), train_loss = 0.77855445, grad/param norm = 1.3776e-01, time/batch = 0.6667s	
18632/33650 (epoch 27.685), train_loss = 0.92694047, grad/param norm = 1.5888e-01, time/batch = 0.6718s	
18633/33650 (epoch 27.686), train_loss = 0.89568311, grad/param norm = 1.4999e-01, time/batch = 0.6654s	
18634/33650 (epoch 27.688), train_loss = 0.96930166, grad/param norm = 1.5389e-01, time/batch = 0.6731s	
18635/33650 (epoch 27.689), train_loss = 0.83378985, grad/param norm = 1.4757e-01, time/batch = 0.6480s	
18636/33650 (epoch 27.691), train_loss = 0.99317407, grad/param norm = 1.7067e-01, time/batch = 0.6812s	
18637/33650 (epoch 27.692), train_loss = 0.99983380, grad/param norm = 1.5231e-01, time/batch = 0.9180s	
18638/33650 (epoch 27.694), train_loss = 0.93038027, grad/param norm = 1.5802e-01, time/batch = 0.9283s	
18639/33650 (epoch 27.695), train_loss = 0.65563992, grad/param norm = 1.3961e-01, time/batch = 0.9190s	
18640/33650 (epoch 27.697), train_loss = 0.86332339, grad/param norm = 1.8179e-01, time/batch = 0.9190s	
18641/33650 (epoch 27.698), train_loss = 1.03041857, grad/param norm = 1.8222e-01, time/batch = 0.9219s	
18642/33650 (epoch 27.700), train_loss = 0.88118585, grad/param norm = 1.4679e-01, time/batch = 1.5802s	
18643/33650 (epoch 27.701), train_loss = 0.89934090, grad/param norm = 1.5183e-01, time/batch = 1.7475s	
18644/33650 (epoch 27.703), train_loss = 1.09468577, grad/param norm = 1.6019e-01, time/batch = 1.7454s	
18645/33650 (epoch 27.704), train_loss = 0.88392696, grad/param norm = 1.4547e-01, time/batch = 15.5000s	
18646/33650 (epoch 27.706), train_loss = 0.85647579, grad/param norm = 1.3842e-01, time/batch = 17.8195s	
18647/33650 (epoch 27.707), train_loss = 0.99312299, grad/param norm = 1.4270e-01, time/batch = 16.2283s	
18648/33650 (epoch 27.709), train_loss = 0.86679640, grad/param norm = 1.4789e-01, time/batch = 17.0734s	
18649/33650 (epoch 27.710), train_loss = 1.06749289, grad/param norm = 1.7313e-01, time/batch = 17.9140s	
18650/33650 (epoch 27.712), train_loss = 0.80553935, grad/param norm = 1.4401e-01, time/batch = 15.7979s	
18651/33650 (epoch 27.713), train_loss = 0.79977488, grad/param norm = 2.0613e-01, time/batch = 17.2339s	
18652/33650 (epoch 27.715), train_loss = 0.94994085, grad/param norm = 1.8394e-01, time/batch = 16.6374s	
18653/33650 (epoch 27.716), train_loss = 0.86516941, grad/param norm = 1.5470e-01, time/batch = 18.0594s	
18654/33650 (epoch 27.718), train_loss = 0.85326371, grad/param norm = 1.5899e-01, time/batch = 16.7322s	
18655/33650 (epoch 27.719), train_loss = 0.99818794, grad/param norm = 1.7106e-01, time/batch = 16.9829s	
18656/33650 (epoch 27.721), train_loss = 1.09819087, grad/param norm = 1.9783e-01, time/batch = 17.8232s	
18657/33650 (epoch 27.722), train_loss = 0.96585700, grad/param norm = 2.4682e-01, time/batch = 16.9819s	
18658/33650 (epoch 27.724), train_loss = 1.03025869, grad/param norm = 1.6476e-01, time/batch = 17.4845s	
18659/33650 (epoch 27.725), train_loss = 0.97150293, grad/param norm = 1.5944e-01, time/batch = 16.3346s	
18660/33650 (epoch 27.727), train_loss = 0.84784310, grad/param norm = 1.7258e-01, time/batch = 18.1554s	
18661/33650 (epoch 27.728), train_loss = 0.87658505, grad/param norm = 1.5582e-01, time/batch = 28.7641s	
18662/33650 (epoch 27.730), train_loss = 0.94052077, grad/param norm = 1.5379e-01, time/batch = 17.8721s	
18663/33650 (epoch 27.731), train_loss = 1.04694654, grad/param norm = 1.6526e-01, time/batch = 17.7412s	
18664/33650 (epoch 27.733), train_loss = 0.88297490, grad/param norm = 1.6010e-01, time/batch = 16.6295s	
18665/33650 (epoch 27.734), train_loss = 1.04966021, grad/param norm = 1.8128e-01, time/batch = 17.9884s	
18666/33650 (epoch 27.736), train_loss = 0.89933313, grad/param norm = 1.8808e-01, time/batch = 17.2497s	
18667/33650 (epoch 27.737), train_loss = 0.96038136, grad/param norm = 1.6672e-01, time/batch = 16.9034s	
18668/33650 (epoch 27.738), train_loss = 0.84246698, grad/param norm = 1.4610e-01, time/batch = 15.7852s	
18669/33650 (epoch 27.740), train_loss = 0.76231253, grad/param norm = 1.3150e-01, time/batch = 17.7360s	
18670/33650 (epoch 27.741), train_loss = 0.85849727, grad/param norm = 1.6666e-01, time/batch = 17.5775s	
18671/33650 (epoch 27.743), train_loss = 0.90315560, grad/param norm = 1.5021e-01, time/batch = 17.1430s	
18672/33650 (epoch 27.744), train_loss = 0.98310443, grad/param norm = 1.4865e-01, time/batch = 17.2243s	
18673/33650 (epoch 27.746), train_loss = 0.87364759, grad/param norm = 1.3823e-01, time/batch = 17.2467s	
18674/33650 (epoch 27.747), train_loss = 1.01717616, grad/param norm = 1.5770e-01, time/batch = 16.1576s	
18675/33650 (epoch 27.749), train_loss = 0.77439765, grad/param norm = 1.5249e-01, time/batch = 15.0554s	
18676/33650 (epoch 27.750), train_loss = 1.06171828, grad/param norm = 1.7634e-01, time/batch = 17.5823s	
18677/33650 (epoch 27.752), train_loss = 0.99151444, grad/param norm = 1.5178e-01, time/batch = 17.4986s	
18678/33650 (epoch 27.753), train_loss = 1.09689286, grad/param norm = 1.8388e-01, time/batch = 16.3898s	
18679/33650 (epoch 27.755), train_loss = 0.87375748, grad/param norm = 1.4318e-01, time/batch = 16.8870s	
18680/33650 (epoch 27.756), train_loss = 0.99047492, grad/param norm = 1.7243e-01, time/batch = 17.7479s	
18681/33650 (epoch 27.758), train_loss = 0.99567126, grad/param norm = 1.5150e-01, time/batch = 16.4963s	
18682/33650 (epoch 27.759), train_loss = 1.02773714, grad/param norm = 2.0149e-01, time/batch = 17.4038s	
18683/33650 (epoch 27.761), train_loss = 0.92802131, grad/param norm = 1.5360e-01, time/batch = 16.9008s	
18684/33650 (epoch 27.762), train_loss = 0.92287409, grad/param norm = 1.7726e-01, time/batch = 17.8181s	
18685/33650 (epoch 27.764), train_loss = 0.97543772, grad/param norm = 1.7552e-01, time/batch = 16.5524s	
18686/33650 (epoch 27.765), train_loss = 0.86794946, grad/param norm = 1.6106e-01, time/batch = 16.8931s	
18687/33650 (epoch 27.767), train_loss = 0.90057739, grad/param norm = 1.4289e-01, time/batch = 15.5498s	
18688/33650 (epoch 27.768), train_loss = 0.80568009, grad/param norm = 1.4359e-01, time/batch = 16.6540s	
18689/33650 (epoch 27.770), train_loss = 0.94612463, grad/param norm = 1.5353e-01, time/batch = 17.8980s	
18690/33650 (epoch 27.771), train_loss = 0.94013227, grad/param norm = 1.4518e-01, time/batch = 17.4857s	
18691/33650 (epoch 27.773), train_loss = 1.01709171, grad/param norm = 1.8813e-01, time/batch = 17.7334s	
18692/33650 (epoch 27.774), train_loss = 0.94575060, grad/param norm = 1.8093e-01, time/batch = 16.8938s	
18693/33650 (epoch 27.776), train_loss = 0.99191814, grad/param norm = 1.6767e-01, time/batch = 17.0678s	
18694/33650 (epoch 27.777), train_loss = 0.84996587, grad/param norm = 1.4613e-01, time/batch = 18.1492s	
18695/33650 (epoch 27.779), train_loss = 0.88495069, grad/param norm = 1.4824e-01, time/batch = 16.3033s	
18696/33650 (epoch 27.780), train_loss = 0.82556560, grad/param norm = 1.5283e-01, time/batch = 17.3222s	
18697/33650 (epoch 27.782), train_loss = 0.84331774, grad/param norm = 1.5132e-01, time/batch = 16.8117s	
18698/33650 (epoch 27.783), train_loss = 0.83359565, grad/param norm = 1.3564e-01, time/batch = 17.4861s	
18699/33650 (epoch 27.785), train_loss = 1.09112583, grad/param norm = 1.5166e-01, time/batch = 16.8936s	
18700/33650 (epoch 27.786), train_loss = 0.98395137, grad/param norm = 1.5219e-01, time/batch = 18.0783s	
18701/33650 (epoch 27.788), train_loss = 0.96742064, grad/param norm = 1.4745e-01, time/batch = 16.2980s	
18702/33650 (epoch 27.789), train_loss = 1.01243768, grad/param norm = 1.5803e-01, time/batch = 16.9875s	
18703/33650 (epoch 27.790), train_loss = 0.92838263, grad/param norm = 1.6891e-01, time/batch = 16.8221s	
18704/33650 (epoch 27.792), train_loss = 1.02356549, grad/param norm = 1.9164e-01, time/batch = 17.1551s	
18705/33650 (epoch 27.793), train_loss = 1.00592701, grad/param norm = 1.9253e-01, time/batch = 17.4978s	
18706/33650 (epoch 27.795), train_loss = 1.03001724, grad/param norm = 1.6038e-01, time/batch = 16.2183s	
18707/33650 (epoch 27.796), train_loss = 0.92070679, grad/param norm = 2.1244e-01, time/batch = 17.4758s	
18708/33650 (epoch 27.798), train_loss = 0.87897593, grad/param norm = 1.5257e-01, time/batch = 15.3177s	
18709/33650 (epoch 27.799), train_loss = 0.93399703, grad/param norm = 1.7091e-01, time/batch = 16.2455s	
18710/33650 (epoch 27.801), train_loss = 0.95364700, grad/param norm = 2.1283e-01, time/batch = 16.9861s	
18711/33650 (epoch 27.802), train_loss = 1.03518414, grad/param norm = 1.9014e-01, time/batch = 17.1508s	
18712/33650 (epoch 27.804), train_loss = 0.94291057, grad/param norm = 1.7813e-01, time/batch = 17.4863s	
18713/33650 (epoch 27.805), train_loss = 0.91175448, grad/param norm = 1.3890e-01, time/batch = 16.1403s	
18714/33650 (epoch 27.807), train_loss = 1.12736708, grad/param norm = 1.8988e-01, time/batch = 17.6496s	
18715/33650 (epoch 27.808), train_loss = 1.17449534, grad/param norm = 1.8381e-01, time/batch = 17.8180s	
18716/33650 (epoch 27.810), train_loss = 0.96806894, grad/param norm = 1.7329e-01, time/batch = 16.6492s	
18717/33650 (epoch 27.811), train_loss = 0.96392976, grad/param norm = 1.9259e-01, time/batch = 17.7381s	
18718/33650 (epoch 27.813), train_loss = 0.84922717, grad/param norm = 1.4218e-01, time/batch = 18.2399s	
18719/33650 (epoch 27.814), train_loss = 1.03360644, grad/param norm = 1.7511e-01, time/batch = 16.3352s	
18720/33650 (epoch 27.816), train_loss = 1.00986755, grad/param norm = 1.9759e-01, time/batch = 16.6335s	
18721/33650 (epoch 27.817), train_loss = 1.01121351, grad/param norm = 1.6344e-01, time/batch = 16.7360s	
18722/33650 (epoch 27.819), train_loss = 0.95441275, grad/param norm = 1.6253e-01, time/batch = 16.9739s	
18723/33650 (epoch 27.820), train_loss = 1.04196236, grad/param norm = 1.7080e-01, time/batch = 17.3000s	
18724/33650 (epoch 27.822), train_loss = 0.96890784, grad/param norm = 2.0278e-01, time/batch = 16.9705s	
18725/33650 (epoch 27.823), train_loss = 0.88285588, grad/param norm = 1.8532e-01, time/batch = 17.9784s	
18726/33650 (epoch 27.825), train_loss = 0.92448232, grad/param norm = 1.5004e-01, time/batch = 17.2363s	
18727/33650 (epoch 27.826), train_loss = 0.99328597, grad/param norm = 1.4991e-01, time/batch = 16.7926s	
18728/33650 (epoch 27.828), train_loss = 1.08787490, grad/param norm = 1.7124e-01, time/batch = 16.4800s	
18729/33650 (epoch 27.829), train_loss = 0.79158232, grad/param norm = 1.4889e-01, time/batch = 17.9715s	
18730/33650 (epoch 27.831), train_loss = 0.95262569, grad/param norm = 1.6553e-01, time/batch = 15.8182s	
18731/33650 (epoch 27.832), train_loss = 1.02978795, grad/param norm = 1.7103e-01, time/batch = 16.1993s	
18732/33650 (epoch 27.834), train_loss = 1.01648682, grad/param norm = 1.7459e-01, time/batch = 18.3902s	
18733/33650 (epoch 27.835), train_loss = 1.14341013, grad/param norm = 2.0664e-01, time/batch = 15.9718s	
18734/33650 (epoch 27.837), train_loss = 0.99082660, grad/param norm = 1.9085e-01, time/batch = 16.7231s	
18735/33650 (epoch 27.838), train_loss = 0.96345547, grad/param norm = 1.9478e-01, time/batch = 16.0535s	
18736/33650 (epoch 27.840), train_loss = 1.02366255, grad/param norm = 1.6491e-01, time/batch = 17.5776s	
18737/33650 (epoch 27.841), train_loss = 0.90866387, grad/param norm = 1.6590e-01, time/batch = 17.0610s	
18738/33650 (epoch 27.842), train_loss = 0.91686337, grad/param norm = 1.6055e-01, time/batch = 17.2163s	
18739/33650 (epoch 27.844), train_loss = 1.11710784, grad/param norm = 1.8161e-01, time/batch = 17.6558s	
18740/33650 (epoch 27.845), train_loss = 0.88783272, grad/param norm = 1.5276e-01, time/batch = 16.8209s	
18741/33650 (epoch 27.847), train_loss = 0.72496488, grad/param norm = 1.3651e-01, time/batch = 16.7188s	
18742/33650 (epoch 27.848), train_loss = 0.81040010, grad/param norm = 1.6025e-01, time/batch = 17.4143s	
18743/33650 (epoch 27.850), train_loss = 0.89468291, grad/param norm = 1.6084e-01, time/batch = 17.2337s	
18744/33650 (epoch 27.851), train_loss = 0.78222451, grad/param norm = 1.2842e-01, time/batch = 17.1539s	
18745/33650 (epoch 27.853), train_loss = 0.90683338, grad/param norm = 1.5311e-01, time/batch = 17.3970s	
18746/33650 (epoch 27.854), train_loss = 1.01328160, grad/param norm = 1.4903e-01, time/batch = 16.7378s	
18747/33650 (epoch 27.856), train_loss = 0.73775062, grad/param norm = 1.4695e-01, time/batch = 17.9827s	
18748/33650 (epoch 27.857), train_loss = 0.95112114, grad/param norm = 1.5178e-01, time/batch = 16.5233s	
18749/33650 (epoch 27.859), train_loss = 0.83002926, grad/param norm = 1.2938e-01, time/batch = 17.5709s	
18750/33650 (epoch 27.860), train_loss = 0.79371570, grad/param norm = 1.3872e-01, time/batch = 16.9883s	
18751/33650 (epoch 27.862), train_loss = 0.84964998, grad/param norm = 1.5444e-01, time/batch = 16.0366s	
18752/33650 (epoch 27.863), train_loss = 1.07630613, grad/param norm = 1.6080e-01, time/batch = 16.6593s	
18753/33650 (epoch 27.865), train_loss = 0.89445322, grad/param norm = 1.5326e-01, time/batch = 17.9055s	
18754/33650 (epoch 27.866), train_loss = 0.84127205, grad/param norm = 1.4800e-01, time/batch = 17.2394s	
18755/33650 (epoch 27.868), train_loss = 0.80840782, grad/param norm = 1.6994e-01, time/batch = 16.8085s	
18756/33650 (epoch 27.869), train_loss = 0.98346857, grad/param norm = 1.6546e-01, time/batch = 17.7186s	
18757/33650 (epoch 27.871), train_loss = 0.81953292, grad/param norm = 1.4435e-01, time/batch = 17.9023s	
18758/33650 (epoch 27.872), train_loss = 0.94688341, grad/param norm = 1.4616e-01, time/batch = 16.8137s	
18759/33650 (epoch 27.874), train_loss = 0.98360664, grad/param norm = 1.6487e-01, time/batch = 16.9062s	
18760/33650 (epoch 27.875), train_loss = 0.88559317, grad/param norm = 1.4534e-01, time/batch = 17.9861s	
18761/33650 (epoch 27.877), train_loss = 1.08795311, grad/param norm = 1.6926e-01, time/batch = 17.1625s	
18762/33650 (epoch 27.878), train_loss = 0.66382711, grad/param norm = 1.2736e-01, time/batch = 17.0663s	
18763/33650 (epoch 27.880), train_loss = 0.94233461, grad/param norm = 1.5347e-01, time/batch = 17.7283s	
18764/33650 (epoch 27.881), train_loss = 0.86915272, grad/param norm = 1.5461e-01, time/batch = 17.3997s	
18765/33650 (epoch 27.883), train_loss = 0.94690216, grad/param norm = 1.4812e-01, time/batch = 16.0614s	
18766/33650 (epoch 27.884), train_loss = 1.03497635, grad/param norm = 1.6524e-01, time/batch = 17.4947s	
18767/33650 (epoch 27.886), train_loss = 0.98287734, grad/param norm = 1.6227e-01, time/batch = 17.3938s	
18768/33650 (epoch 27.887), train_loss = 0.79113669, grad/param norm = 1.3655e-01, time/batch = 17.4747s	
18769/33650 (epoch 27.889), train_loss = 0.89044891, grad/param norm = 1.4298e-01, time/batch = 16.4813s	
18770/33650 (epoch 27.890), train_loss = 0.96905545, grad/param norm = 1.5061e-01, time/batch = 15.8368s	
18771/33650 (epoch 27.892), train_loss = 0.90200961, grad/param norm = 1.9807e-01, time/batch = 16.3043s	
18772/33650 (epoch 27.893), train_loss = 0.95406575, grad/param norm = 1.6478e-01, time/batch = 17.4107s	
18773/33650 (epoch 27.895), train_loss = 1.05202954, grad/param norm = 1.6454e-01, time/batch = 16.7245s	
18774/33650 (epoch 27.896), train_loss = 0.84850547, grad/param norm = 1.4526e-01, time/batch = 17.9004s	
18775/33650 (epoch 27.897), train_loss = 0.79034607, grad/param norm = 1.6787e-01, time/batch = 17.8254s	
18776/33650 (epoch 27.899), train_loss = 0.83677063, grad/param norm = 1.4330e-01, time/batch = 16.8003s	
18777/33650 (epoch 27.900), train_loss = 0.77516089, grad/param norm = 1.4392e-01, time/batch = 17.0709s	
18778/33650 (epoch 27.902), train_loss = 0.91588705, grad/param norm = 1.6863e-01, time/batch = 17.5712s	
18779/33650 (epoch 27.903), train_loss = 0.88221711, grad/param norm = 1.5221e-01, time/batch = 16.8932s	
18780/33650 (epoch 27.905), train_loss = 1.04271458, grad/param norm = 1.8856e-01, time/batch = 17.3127s	
18781/33650 (epoch 27.906), train_loss = 0.85263111, grad/param norm = 1.4852e-01, time/batch = 17.0628s	
18782/33650 (epoch 27.908), train_loss = 0.88236578, grad/param norm = 1.4919e-01, time/batch = 16.9071s	
18783/33650 (epoch 27.909), train_loss = 0.86077469, grad/param norm = 1.4627e-01, time/batch = 17.2238s	
18784/33650 (epoch 27.911), train_loss = 0.76848688, grad/param norm = 1.3226e-01, time/batch = 17.8277s	
18785/33650 (epoch 27.912), train_loss = 0.73943509, grad/param norm = 1.6126e-01, time/batch = 17.3162s	
18786/33650 (epoch 27.914), train_loss = 0.93026989, grad/param norm = 1.3306e-01, time/batch = 16.9665s	
18787/33650 (epoch 27.915), train_loss = 0.88225126, grad/param norm = 1.5628e-01, time/batch = 16.0544s	
18788/33650 (epoch 27.917), train_loss = 0.87437574, grad/param norm = 1.6445e-01, time/batch = 18.0644s	
18789/33650 (epoch 27.918), train_loss = 0.79381176, grad/param norm = 1.3786e-01, time/batch = 16.1682s	
18790/33650 (epoch 27.920), train_loss = 0.81586749, grad/param norm = 1.3328e-01, time/batch = 17.7171s	
18791/33650 (epoch 27.921), train_loss = 0.80594111, grad/param norm = 1.3789e-01, time/batch = 16.8971s	
18792/33650 (epoch 27.923), train_loss = 0.74736374, grad/param norm = 1.4283e-01, time/batch = 17.4882s	
18793/33650 (epoch 27.924), train_loss = 0.91613358, grad/param norm = 1.6536e-01, time/batch = 16.0578s	
18794/33650 (epoch 27.926), train_loss = 0.85112022, grad/param norm = 1.6655e-01, time/batch = 16.6288s	
18795/33650 (epoch 27.927), train_loss = 0.89055573, grad/param norm = 1.6382e-01, time/batch = 18.3934s	
18796/33650 (epoch 27.929), train_loss = 0.96164620, grad/param norm = 1.4700e-01, time/batch = 16.7054s	
18797/33650 (epoch 27.930), train_loss = 0.87556841, grad/param norm = 1.6948e-01, time/batch = 17.8697s	
18798/33650 (epoch 27.932), train_loss = 0.86055301, grad/param norm = 1.4533e-01, time/batch = 17.8885s	
18799/33650 (epoch 27.933), train_loss = 0.78785216, grad/param norm = 1.5594e-01, time/batch = 18.6383s	
18800/33650 (epoch 27.935), train_loss = 0.78236679, grad/param norm = 1.5235e-01, time/batch = 17.1264s	
18801/33650 (epoch 27.936), train_loss = 0.84239702, grad/param norm = 1.5095e-01, time/batch = 18.0479s	
18802/33650 (epoch 27.938), train_loss = 0.78284167, grad/param norm = 1.5342e-01, time/batch = 19.1405s	
18803/33650 (epoch 27.939), train_loss = 0.97547656, grad/param norm = 1.5464e-01, time/batch = 17.7243s	
18804/33650 (epoch 27.941), train_loss = 0.90304899, grad/param norm = 1.5008e-01, time/batch = 16.6932s	
18805/33650 (epoch 27.942), train_loss = 0.95846783, grad/param norm = 1.5195e-01, time/batch = 17.7916s	
18806/33650 (epoch 27.944), train_loss = 0.85614664, grad/param norm = 1.3699e-01, time/batch = 17.5507s	
18807/33650 (epoch 27.945), train_loss = 0.92283082, grad/param norm = 1.4542e-01, time/batch = 17.3884s	
18808/33650 (epoch 27.947), train_loss = 1.03102779, grad/param norm = 2.1810e-01, time/batch = 18.3003s	
18809/33650 (epoch 27.948), train_loss = 1.00283434, grad/param norm = 1.4711e-01, time/batch = 18.6371s	
18810/33650 (epoch 27.949), train_loss = 0.76638494, grad/param norm = 1.3088e-01, time/batch = 16.8842s	
18811/33650 (epoch 27.951), train_loss = 1.02587204, grad/param norm = 1.7008e-01, time/batch = 18.0625s	
18812/33650 (epoch 27.952), train_loss = 0.94878764, grad/param norm = 1.5725e-01, time/batch = 17.1188s	
18813/33650 (epoch 27.954), train_loss = 0.95442542, grad/param norm = 1.3990e-01, time/batch = 17.6427s	
18814/33650 (epoch 27.955), train_loss = 0.93341466, grad/param norm = 1.5396e-01, time/batch = 16.8968s	
18815/33650 (epoch 27.957), train_loss = 0.96261513, grad/param norm = 1.8389e-01, time/batch = 17.5765s	
18816/33650 (epoch 27.958), train_loss = 0.71776086, grad/param norm = 1.3557e-01, time/batch = 14.2165s	
18817/33650 (epoch 27.960), train_loss = 0.75401012, grad/param norm = 1.6803e-01, time/batch = 14.2723s	
18818/33650 (epoch 27.961), train_loss = 0.80221074, grad/param norm = 1.4171e-01, time/batch = 13.8956s	
18819/33650 (epoch 27.963), train_loss = 0.83153480, grad/param norm = 1.5873e-01, time/batch = 15.9907s	
18820/33650 (epoch 27.964), train_loss = 0.97278211, grad/param norm = 1.5058e-01, time/batch = 18.4808s	
18821/33650 (epoch 27.966), train_loss = 0.92696360, grad/param norm = 1.6991e-01, time/batch = 17.7971s	
18822/33650 (epoch 27.967), train_loss = 0.92879692, grad/param norm = 1.5675e-01, time/batch = 18.4898s	
18823/33650 (epoch 27.969), train_loss = 0.89828383, grad/param norm = 1.4141e-01, time/batch = 17.6427s	
18824/33650 (epoch 27.970), train_loss = 0.91633889, grad/param norm = 1.5859e-01, time/batch = 17.3131s	
18825/33650 (epoch 27.972), train_loss = 1.19061931, grad/param norm = 1.7430e-01, time/batch = 17.3169s	
18826/33650 (epoch 27.973), train_loss = 0.81159299, grad/param norm = 1.3098e-01, time/batch = 18.5593s	
18827/33650 (epoch 27.975), train_loss = 0.80696643, grad/param norm = 1.5274e-01, time/batch = 17.1897s	
18828/33650 (epoch 27.976), train_loss = 0.82441049, grad/param norm = 1.3374e-01, time/batch = 17.7325s	
18829/33650 (epoch 27.978), train_loss = 0.83383894, grad/param norm = 1.4539e-01, time/batch = 16.3046s	
18830/33650 (epoch 27.979), train_loss = 0.88074368, grad/param norm = 1.6143e-01, time/batch = 17.4755s	
18831/33650 (epoch 27.981), train_loss = 0.85809613, grad/param norm = 1.4043e-01, time/batch = 17.0485s	
18832/33650 (epoch 27.982), train_loss = 0.90960943, grad/param norm = 1.4802e-01, time/batch = 17.9836s	
18833/33650 (epoch 27.984), train_loss = 0.75729997, grad/param norm = 1.3997e-01, time/batch = 19.4627s	
18834/33650 (epoch 27.985), train_loss = 0.79930514, grad/param norm = 1.5402e-01, time/batch = 16.8940s	
18835/33650 (epoch 27.987), train_loss = 0.90393188, grad/param norm = 1.4607e-01, time/batch = 17.6551s	
18836/33650 (epoch 27.988), train_loss = 0.87390182, grad/param norm = 1.5481e-01, time/batch = 18.6474s	
18837/33650 (epoch 27.990), train_loss = 1.05376999, grad/param norm = 1.8163e-01, time/batch = 17.8889s	
18838/33650 (epoch 27.991), train_loss = 0.91833480, grad/param norm = 1.4809e-01, time/batch = 16.9740s	
18839/33650 (epoch 27.993), train_loss = 0.91504978, grad/param norm = 1.5757e-01, time/batch = 17.9738s	
18840/33650 (epoch 27.994), train_loss = 0.89135250, grad/param norm = 1.4494e-01, time/batch = 18.5568s	
18841/33650 (epoch 27.996), train_loss = 0.85825360, grad/param norm = 1.8643e-01, time/batch = 17.2965s	
18842/33650 (epoch 27.997), train_loss = 0.97571656, grad/param norm = 1.7620e-01, time/batch = 17.7192s	
18843/33650 (epoch 27.999), train_loss = 0.82346291, grad/param norm = 1.6325e-01, time/batch = 18.3149s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
18844/33650 (epoch 28.000), train_loss = 0.98077219, grad/param norm = 2.1768e-01, time/batch = 17.7059s	
18845/33650 (epoch 28.001), train_loss = 1.03765513, grad/param norm = 1.7196e-01, time/batch = 17.0380s	
18846/33650 (epoch 28.003), train_loss = 1.04627534, grad/param norm = 2.0212e-01, time/batch = 17.3683s	
18847/33650 (epoch 28.004), train_loss = 0.92649397, grad/param norm = 1.5338e-01, time/batch = 17.2954s	
18848/33650 (epoch 28.006), train_loss = 0.86676369, grad/param norm = 1.5047e-01, time/batch = 16.4478s	
18849/33650 (epoch 28.007), train_loss = 0.96873459, grad/param norm = 1.7163e-01, time/batch = 17.1631s	
18850/33650 (epoch 28.009), train_loss = 0.86043572, grad/param norm = 1.5694e-01, time/batch = 17.4006s	
18851/33650 (epoch 28.010), train_loss = 1.00799992, grad/param norm = 1.7273e-01, time/batch = 17.9701s	
18852/33650 (epoch 28.012), train_loss = 0.84718419, grad/param norm = 1.4386e-01, time/batch = 18.0612s	
18853/33650 (epoch 28.013), train_loss = 0.90718470, grad/param norm = 1.7310e-01, time/batch = 17.8208s	
18854/33650 (epoch 28.015), train_loss = 0.88997603, grad/param norm = 1.6028e-01, time/batch = 17.8241s	
18855/33650 (epoch 28.016), train_loss = 0.82434247, grad/param norm = 1.7183e-01, time/batch = 16.7002s	
18856/33650 (epoch 28.018), train_loss = 0.89800483, grad/param norm = 1.7807e-01, time/batch = 17.8872s	
18857/33650 (epoch 28.019), train_loss = 0.85955468, grad/param norm = 1.5996e-01, time/batch = 16.6331s	
18858/33650 (epoch 28.021), train_loss = 0.95213905, grad/param norm = 1.5772e-01, time/batch = 17.1364s	
18859/33650 (epoch 28.022), train_loss = 0.86017574, grad/param norm = 1.4126e-01, time/batch = 17.4054s	
18860/33650 (epoch 28.024), train_loss = 0.82203886, grad/param norm = 1.5496e-01, time/batch = 17.9743s	
18861/33650 (epoch 28.025), train_loss = 0.90663497, grad/param norm = 1.5821e-01, time/batch = 17.7217s	
18862/33650 (epoch 28.027), train_loss = 0.93939854, grad/param norm = 1.5720e-01, time/batch = 16.1177s	
18863/33650 (epoch 28.028), train_loss = 0.96608336, grad/param norm = 1.4914e-01, time/batch = 18.2329s	
18864/33650 (epoch 28.030), train_loss = 0.91073911, grad/param norm = 1.7534e-01, time/batch = 18.2328s	
18865/33650 (epoch 28.031), train_loss = 0.81821408, grad/param norm = 1.3432e-01, time/batch = 17.8750s	
18866/33650 (epoch 28.033), train_loss = 0.88746538, grad/param norm = 1.3080e-01, time/batch = 18.2256s	
18867/33650 (epoch 28.034), train_loss = 0.93324185, grad/param norm = 1.6351e-01, time/batch = 18.0593s	
18868/33650 (epoch 28.036), train_loss = 1.01824888, grad/param norm = 1.7103e-01, time/batch = 23.5741s	
18869/33650 (epoch 28.037), train_loss = 0.86322565, grad/param norm = 1.4738e-01, time/batch = 24.3977s	
18870/33650 (epoch 28.039), train_loss = 0.99362217, grad/param norm = 1.4635e-01, time/batch = 17.9587s	
18871/33650 (epoch 28.040), train_loss = 1.09063741, grad/param norm = 2.0457e-01, time/batch = 16.4515s	
18872/33650 (epoch 28.042), train_loss = 1.10750031, grad/param norm = 1.8104e-01, time/batch = 18.8083s	
18873/33650 (epoch 28.043), train_loss = 0.86289251, grad/param norm = 1.6063e-01, time/batch = 18.1343s	
18874/33650 (epoch 28.045), train_loss = 0.86902293, grad/param norm = 1.5762e-01, time/batch = 17.0604s	
18875/33650 (epoch 28.046), train_loss = 0.95690673, grad/param norm = 1.5383e-01, time/batch = 17.3131s	
18876/33650 (epoch 28.048), train_loss = 1.00142096, grad/param norm = 1.6210e-01, time/batch = 18.3156s	
18877/33650 (epoch 28.049), train_loss = 0.89745338, grad/param norm = 1.7425e-01, time/batch = 18.0657s	
18878/33650 (epoch 28.051), train_loss = 1.06321443, grad/param norm = 1.6054e-01, time/batch = 17.7223s	
18879/33650 (epoch 28.052), train_loss = 1.04351981, grad/param norm = 1.7082e-01, time/batch = 16.2329s	
18880/33650 (epoch 28.053), train_loss = 0.98964730, grad/param norm = 1.5826e-01, time/batch = 17.9827s	
18881/33650 (epoch 28.055), train_loss = 0.82430539, grad/param norm = 1.4674e-01, time/batch = 17.0559s	
18882/33650 (epoch 28.056), train_loss = 0.79876772, grad/param norm = 1.2307e-01, time/batch = 18.8096s	
18883/33650 (epoch 28.058), train_loss = 0.99261772, grad/param norm = 1.8647e-01, time/batch = 18.2344s	
18884/33650 (epoch 28.059), train_loss = 0.98149587, grad/param norm = 1.7538e-01, time/batch = 17.1295s	
18885/33650 (epoch 28.061), train_loss = 1.00489507, grad/param norm = 1.5313e-01, time/batch = 18.4858s	
18886/33650 (epoch 28.062), train_loss = 0.95953283, grad/param norm = 1.5510e-01, time/batch = 18.7177s	
18887/33650 (epoch 28.064), train_loss = 0.88288072, grad/param norm = 1.5301e-01, time/batch = 18.1349s	
18888/33650 (epoch 28.065), train_loss = 0.88502484, grad/param norm = 1.5686e-01, time/batch = 17.4737s	
18889/33650 (epoch 28.067), train_loss = 0.80373613, grad/param norm = 1.2725e-01, time/batch = 17.3097s	
18890/33650 (epoch 28.068), train_loss = 0.90101583, grad/param norm = 1.5093e-01, time/batch = 16.6149s	
18891/33650 (epoch 28.070), train_loss = 0.96472767, grad/param norm = 1.6114e-01, time/batch = 17.3894s	
18892/33650 (epoch 28.071), train_loss = 0.86825391, grad/param norm = 1.4978e-01, time/batch = 17.5505s	
18893/33650 (epoch 28.073), train_loss = 0.96863831, grad/param norm = 1.6173e-01, time/batch = 18.3218s	
18894/33650 (epoch 28.074), train_loss = 1.04290819, grad/param norm = 1.4733e-01, time/batch = 15.7211s	
18895/33650 (epoch 28.076), train_loss = 0.98506836, grad/param norm = 1.6168e-01, time/batch = 18.2872s	
18896/33650 (epoch 28.077), train_loss = 0.91963198, grad/param norm = 1.5383e-01, time/batch = 18.6466s	
18897/33650 (epoch 28.079), train_loss = 0.96383475, grad/param norm = 1.5269e-01, time/batch = 17.8998s	
18898/33650 (epoch 28.080), train_loss = 0.96691653, grad/param norm = 1.4749e-01, time/batch = 17.0575s	
18899/33650 (epoch 28.082), train_loss = 0.91810541, grad/param norm = 1.5512e-01, time/batch = 17.9081s	
18900/33650 (epoch 28.083), train_loss = 0.94684781, grad/param norm = 1.5904e-01, time/batch = 16.7300s	
18901/33650 (epoch 28.085), train_loss = 1.01333092, grad/param norm = 1.5023e-01, time/batch = 17.2218s	
18902/33650 (epoch 28.086), train_loss = 0.98977699, grad/param norm = 1.8076e-01, time/batch = 17.9689s	
18903/33650 (epoch 28.088), train_loss = 0.92350865, grad/param norm = 1.5656e-01, time/batch = 18.0611s	
18904/33650 (epoch 28.089), train_loss = 0.87641997, grad/param norm = 1.5610e-01, time/batch = 17.8224s	
18905/33650 (epoch 28.091), train_loss = 0.90001616, grad/param norm = 1.5204e-01, time/batch = 17.9747s	
18906/33650 (epoch 28.092), train_loss = 0.91131960, grad/param norm = 1.5952e-01, time/batch = 18.0759s	
18907/33650 (epoch 28.094), train_loss = 0.98020335, grad/param norm = 1.4204e-01, time/batch = 18.8985s	
18908/33650 (epoch 28.095), train_loss = 0.98817520, grad/param norm = 1.8519e-01, time/batch = 15.2849s	
18909/33650 (epoch 28.097), train_loss = 0.86922305, grad/param norm = 1.6329e-01, time/batch = 17.4836s	
18910/33650 (epoch 28.098), train_loss = 0.75492958, grad/param norm = 1.6443e-01, time/batch = 18.4814s	
18911/33650 (epoch 28.100), train_loss = 0.84625923, grad/param norm = 1.4830e-01, time/batch = 17.5585s	
18912/33650 (epoch 28.101), train_loss = 0.91406341, grad/param norm = 1.6297e-01, time/batch = 18.4736s	
18913/33650 (epoch 28.103), train_loss = 0.92294530, grad/param norm = 1.6650e-01, time/batch = 18.5542s	
18914/33650 (epoch 28.104), train_loss = 1.03548515, grad/param norm = 1.7046e-01, time/batch = 17.9771s	
18915/33650 (epoch 28.105), train_loss = 0.94234125, grad/param norm = 1.6007e-01, time/batch = 17.4807s	
18916/33650 (epoch 28.107), train_loss = 0.88555736, grad/param norm = 1.5200e-01, time/batch = 18.2360s	
18917/33650 (epoch 28.108), train_loss = 0.96846033, grad/param norm = 1.6456e-01, time/batch = 18.0691s	
18918/33650 (epoch 28.110), train_loss = 1.07491784, grad/param norm = 1.6236e-01, time/batch = 16.6435s	
18919/33650 (epoch 28.111), train_loss = 0.89528000, grad/param norm = 1.5500e-01, time/batch = 16.2275s	
18920/33650 (epoch 28.113), train_loss = 0.88182758, grad/param norm = 1.5745e-01, time/batch = 18.8118s	
18921/33650 (epoch 28.114), train_loss = 0.97752497, grad/param norm = 1.5658e-01, time/batch = 17.2885s	
18922/33650 (epoch 28.116), train_loss = 0.83425926, grad/param norm = 1.4078e-01, time/batch = 17.1522s	
18923/33650 (epoch 28.117), train_loss = 0.91071312, grad/param norm = 1.3802e-01, time/batch = 18.2317s	
18924/33650 (epoch 28.119), train_loss = 0.83319440, grad/param norm = 1.4658e-01, time/batch = 19.0528s	
18925/33650 (epoch 28.120), train_loss = 0.86682803, grad/param norm = 1.4986e-01, time/batch = 17.9747s	
18926/33650 (epoch 28.122), train_loss = 0.71378269, grad/param norm = 1.5361e-01, time/batch = 18.2164s	
18927/33650 (epoch 28.123), train_loss = 0.86565229, grad/param norm = 1.3923e-01, time/batch = 17.6383s	
18928/33650 (epoch 28.125), train_loss = 0.94870648, grad/param norm = 1.5639e-01, time/batch = 16.8840s	
18929/33650 (epoch 28.126), train_loss = 1.01666939, grad/param norm = 1.9773e-01, time/batch = 18.0688s	
18930/33650 (epoch 28.128), train_loss = 0.97736239, grad/param norm = 1.8170e-01, time/batch = 18.7220s	
18931/33650 (epoch 28.129), train_loss = 1.01433515, grad/param norm = 1.7407e-01, time/batch = 16.9486s	
18932/33650 (epoch 28.131), train_loss = 0.95176837, grad/param norm = 1.7722e-01, time/batch = 17.7170s	
18933/33650 (epoch 28.132), train_loss = 0.92347135, grad/param norm = 1.6219e-01, time/batch = 17.6283s	
18934/33650 (epoch 28.134), train_loss = 1.00712055, grad/param norm = 1.7339e-01, time/batch = 18.3202s	
18935/33650 (epoch 28.135), train_loss = 0.81383514, grad/param norm = 1.4518e-01, time/batch = 16.7956s	
18936/33650 (epoch 28.137), train_loss = 0.95988381, grad/param norm = 1.6699e-01, time/batch = 18.7347s	
18937/33650 (epoch 28.138), train_loss = 0.99028875, grad/param norm = 1.5006e-01, time/batch = 18.3886s	
18938/33650 (epoch 28.140), train_loss = 0.92754712, grad/param norm = 1.8262e-01, time/batch = 17.3914s	
18939/33650 (epoch 28.141), train_loss = 1.05586535, grad/param norm = 1.7527e-01, time/batch = 18.0503s	
18940/33650 (epoch 28.143), train_loss = 1.07657150, grad/param norm = 1.8716e-01, time/batch = 16.5585s	
18941/33650 (epoch 28.144), train_loss = 0.97033024, grad/param norm = 1.7175e-01, time/batch = 17.3030s	
18942/33650 (epoch 28.146), train_loss = 0.89989833, grad/param norm = 1.5136e-01, time/batch = 17.0572s	
18943/33650 (epoch 28.147), train_loss = 0.86779552, grad/param norm = 1.5747e-01, time/batch = 16.6233s	
18944/33650 (epoch 28.149), train_loss = 0.83116437, grad/param norm = 1.6004e-01, time/batch = 16.9809s	
18945/33650 (epoch 28.150), train_loss = 0.80750305, grad/param norm = 1.5899e-01, time/batch = 17.1268s	
18946/33650 (epoch 28.152), train_loss = 0.86723007, grad/param norm = 1.4628e-01, time/batch = 18.2195s	
18947/33650 (epoch 28.153), train_loss = 0.89175326, grad/param norm = 1.5769e-01, time/batch = 16.8045s	
18948/33650 (epoch 28.155), train_loss = 0.84354680, grad/param norm = 1.3379e-01, time/batch = 17.6538s	
18949/33650 (epoch 28.156), train_loss = 0.83146597, grad/param norm = 1.3558e-01, time/batch = 17.0725s	
18950/33650 (epoch 28.158), train_loss = 0.95438549, grad/param norm = 1.6499e-01, time/batch = 18.4933s	
18951/33650 (epoch 28.159), train_loss = 0.84612864, grad/param norm = 1.3700e-01, time/batch = 16.9858s	
18952/33650 (epoch 28.160), train_loss = 0.86031538, grad/param norm = 1.3433e-01, time/batch = 16.1341s	
18953/33650 (epoch 28.162), train_loss = 0.88369723, grad/param norm = 1.5382e-01, time/batch = 18.6230s	
18954/33650 (epoch 28.163), train_loss = 0.95003497, grad/param norm = 1.7591e-01, time/batch = 18.5633s	
18955/33650 (epoch 28.165), train_loss = 0.81609539, grad/param norm = 1.6038e-01, time/batch = 16.8895s	
18956/33650 (epoch 28.166), train_loss = 0.80405066, grad/param norm = 1.5427e-01, time/batch = 17.4043s	
18957/33650 (epoch 28.168), train_loss = 1.01867858, grad/param norm = 1.7964e-01, time/batch = 17.2953s	
18958/33650 (epoch 28.169), train_loss = 0.92967041, grad/param norm = 1.5672e-01, time/batch = 18.2428s	
18959/33650 (epoch 28.171), train_loss = 0.89740673, grad/param norm = 1.4350e-01, time/batch = 17.9617s	
18960/33650 (epoch 28.172), train_loss = 0.86052866, grad/param norm = 1.4532e-01, time/batch = 18.5523s	
18961/33650 (epoch 28.174), train_loss = 0.82702019, grad/param norm = 1.3860e-01, time/batch = 18.9050s	
18962/33650 (epoch 28.175), train_loss = 0.80489285, grad/param norm = 1.8962e-01, time/batch = 16.8876s	
18963/33650 (epoch 28.177), train_loss = 0.91202174, grad/param norm = 1.7037e-01, time/batch = 17.8954s	
18964/33650 (epoch 28.178), train_loss = 0.84470674, grad/param norm = 1.5362e-01, time/batch = 16.8205s	
18965/33650 (epoch 28.180), train_loss = 0.82042937, grad/param norm = 1.4718e-01, time/batch = 17.5575s	
18966/33650 (epoch 28.181), train_loss = 0.74124720, grad/param norm = 1.3845e-01, time/batch = 18.4654s	
18967/33650 (epoch 28.183), train_loss = 0.83678577, grad/param norm = 1.5846e-01, time/batch = 17.3292s	
18968/33650 (epoch 28.184), train_loss = 0.83777326, grad/param norm = 1.6802e-01, time/batch = 18.3922s	
18969/33650 (epoch 28.186), train_loss = 0.89062441, grad/param norm = 1.7456e-01, time/batch = 17.0506s	
18970/33650 (epoch 28.187), train_loss = 1.03142249, grad/param norm = 1.6594e-01, time/batch = 17.7320s	
18971/33650 (epoch 28.189), train_loss = 1.00477528, grad/param norm = 1.9046e-01, time/batch = 18.3586s	
18972/33650 (epoch 28.190), train_loss = 0.93817285, grad/param norm = 1.8412e-01, time/batch = 18.0576s	
18973/33650 (epoch 28.192), train_loss = 1.07489566, grad/param norm = 1.5452e-01, time/batch = 18.3756s	
18974/33650 (epoch 28.193), train_loss = 1.04138483, grad/param norm = 1.7002e-01, time/batch = 17.7440s	
18975/33650 (epoch 28.195), train_loss = 0.78628612, grad/param norm = 1.3788e-01, time/batch = 15.8016s	
18976/33650 (epoch 28.196), train_loss = 0.77361296, grad/param norm = 1.7406e-01, time/batch = 17.3127s	
18977/33650 (epoch 28.198), train_loss = 0.87602269, grad/param norm = 1.5451e-01, time/batch = 18.1549s	
18978/33650 (epoch 28.199), train_loss = 0.98270865, grad/param norm = 1.7033e-01, time/batch = 18.1560s	
18979/33650 (epoch 28.201), train_loss = 0.87118137, grad/param norm = 1.6244e-01, time/batch = 17.7239s	
18980/33650 (epoch 28.202), train_loss = 0.89287177, grad/param norm = 1.6178e-01, time/batch = 17.2194s	
18981/33650 (epoch 28.204), train_loss = 0.94279898, grad/param norm = 1.6044e-01, time/batch = 17.4040s	
18982/33650 (epoch 28.205), train_loss = 0.87644307, grad/param norm = 1.6736e-01, time/batch = 16.8058s	
18983/33650 (epoch 28.207), train_loss = 0.84460160, grad/param norm = 1.5927e-01, time/batch = 17.4693s	
18984/33650 (epoch 28.208), train_loss = 0.92498366, grad/param norm = 1.5258e-01, time/batch = 18.3278s	
18985/33650 (epoch 28.210), train_loss = 0.74876466, grad/param norm = 1.8278e-01, time/batch = 17.5645s	
18986/33650 (epoch 28.211), train_loss = 0.85187942, grad/param norm = 1.8613e-01, time/batch = 17.7096s	
18987/33650 (epoch 28.212), train_loss = 0.95281699, grad/param norm = 1.7862e-01, time/batch = 16.7268s	
18988/33650 (epoch 28.214), train_loss = 1.07344356, grad/param norm = 1.6671e-01, time/batch = 17.9159s	
18989/33650 (epoch 28.215), train_loss = 0.69228640, grad/param norm = 1.6969e-01, time/batch = 16.7990s	
18990/33650 (epoch 28.217), train_loss = 0.88490007, grad/param norm = 1.7668e-01, time/batch = 17.4059s	
18991/33650 (epoch 28.218), train_loss = 0.89873882, grad/param norm = 1.4814e-01, time/batch = 18.5673s	
18992/33650 (epoch 28.220), train_loss = 0.80268103, grad/param norm = 1.6059e-01, time/batch = 17.9020s	
18993/33650 (epoch 28.221), train_loss = 1.07171463, grad/param norm = 1.8350e-01, time/batch = 16.6267s	
18994/33650 (epoch 28.223), train_loss = 0.73103587, grad/param norm = 1.4249e-01, time/batch = 18.8872s	
18995/33650 (epoch 28.224), train_loss = 0.84898220, grad/param norm = 1.8811e-01, time/batch = 18.2368s	
18996/33650 (epoch 28.226), train_loss = 1.18154719, grad/param norm = 1.6926e-01, time/batch = 16.2017s	
18997/33650 (epoch 28.227), train_loss = 1.02283908, grad/param norm = 1.9755e-01, time/batch = 17.7153s	
18998/33650 (epoch 28.229), train_loss = 1.02576452, grad/param norm = 1.7985e-01, time/batch = 18.2320s	
18999/33650 (epoch 28.230), train_loss = 1.14468478, grad/param norm = 1.8999e-01, time/batch = 17.5582s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch28.23_1.6647.t7	
19000/33650 (epoch 28.232), train_loss = 0.98580459, grad/param norm = 1.8457e-01, time/batch = 17.4875s	
19001/33650 (epoch 28.233), train_loss = 1.26550075, grad/param norm = 1.9511e-01, time/batch = 17.3101s	
19002/33650 (epoch 28.235), train_loss = 0.91259007, grad/param norm = 1.5618e-01, time/batch = 17.5556s	
19003/33650 (epoch 28.236), train_loss = 0.84478799, grad/param norm = 1.4455e-01, time/batch = 17.3903s	
19004/33650 (epoch 28.238), train_loss = 0.87146092, grad/param norm = 1.4030e-01, time/batch = 16.3022s	
19005/33650 (epoch 28.239), train_loss = 0.84878608, grad/param norm = 1.5413e-01, time/batch = 17.8090s	
19006/33650 (epoch 28.241), train_loss = 0.88824471, grad/param norm = 1.4903e-01, time/batch = 18.4801s	
19007/33650 (epoch 28.242), train_loss = 0.72780821, grad/param norm = 1.4007e-01, time/batch = 17.9932s	
19008/33650 (epoch 28.244), train_loss = 0.89011672, grad/param norm = 1.5516e-01, time/batch = 17.2254s	
19009/33650 (epoch 28.245), train_loss = 0.78473398, grad/param norm = 1.3632e-01, time/batch = 18.5528s	
19010/33650 (epoch 28.247), train_loss = 0.88930112, grad/param norm = 1.4684e-01, time/batch = 17.7302s	
19011/33650 (epoch 28.248), train_loss = 0.80740204, grad/param norm = 1.4349e-01, time/batch = 17.2195s	
19012/33650 (epoch 28.250), train_loss = 0.88895533, grad/param norm = 1.4632e-01, time/batch = 17.3008s	
19013/33650 (epoch 28.251), train_loss = 1.01422066, grad/param norm = 1.5353e-01, time/batch = 18.8026s	
19014/33650 (epoch 28.253), train_loss = 0.79123997, grad/param norm = 1.5648e-01, time/batch = 18.2319s	
19015/33650 (epoch 28.254), train_loss = 0.84534137, grad/param norm = 1.5079e-01, time/batch = 16.1942s	
19016/33650 (epoch 28.256), train_loss = 1.03759835, grad/param norm = 1.4738e-01, time/batch = 17.6532s	
19017/33650 (epoch 28.257), train_loss = 1.00488611, grad/param norm = 1.5448e-01, time/batch = 17.9820s	
19018/33650 (epoch 28.259), train_loss = 0.79433350, grad/param norm = 1.6008e-01, time/batch = 17.7210s	
19019/33650 (epoch 28.260), train_loss = 0.96438058, grad/param norm = 1.5975e-01, time/batch = 16.3085s	
19020/33650 (epoch 28.262), train_loss = 0.92891326, grad/param norm = 1.8265e-01, time/batch = 16.9352s	
19021/33650 (epoch 28.263), train_loss = 0.87326851, grad/param norm = 1.8077e-01, time/batch = 18.5681s	
19022/33650 (epoch 28.264), train_loss = 0.95275277, grad/param norm = 1.6471e-01, time/batch = 17.3949s	
19023/33650 (epoch 28.266), train_loss = 0.94676520, grad/param norm = 1.8045e-01, time/batch = 17.6513s	
19024/33650 (epoch 28.267), train_loss = 0.85654336, grad/param norm = 1.6090e-01, time/batch = 18.1504s	
19025/33650 (epoch 28.269), train_loss = 0.93211019, grad/param norm = 1.6026e-01, time/batch = 16.8074s	
19026/33650 (epoch 28.270), train_loss = 0.81233627, grad/param norm = 1.4496e-01, time/batch = 17.4033s	
19027/33650 (epoch 28.272), train_loss = 0.88121377, grad/param norm = 1.5701e-01, time/batch = 17.2327s	
19028/33650 (epoch 28.273), train_loss = 0.99001928, grad/param norm = 1.6960e-01, time/batch = 17.8931s	
19029/33650 (epoch 28.275), train_loss = 0.94240478, grad/param norm = 1.4589e-01, time/batch = 16.9929s	
19030/33650 (epoch 28.276), train_loss = 1.00154098, grad/param norm = 1.8745e-01, time/batch = 15.8900s	
19031/33650 (epoch 28.278), train_loss = 1.06449415, grad/param norm = 1.7392e-01, time/batch = 18.6579s	
19032/33650 (epoch 28.279), train_loss = 0.87354213, grad/param norm = 1.6071e-01, time/batch = 16.6404s	
19033/33650 (epoch 28.281), train_loss = 0.93102580, grad/param norm = 1.4556e-01, time/batch = 17.9043s	
19034/33650 (epoch 28.282), train_loss = 1.03292259, grad/param norm = 1.4883e-01, time/batch = 18.3227s	
19035/33650 (epoch 28.284), train_loss = 0.98285989, grad/param norm = 1.8845e-01, time/batch = 17.1036s	
19036/33650 (epoch 28.285), train_loss = 0.95455436, grad/param norm = 1.6760e-01, time/batch = 16.8946s	
19037/33650 (epoch 28.287), train_loss = 0.87717706, grad/param norm = 1.5673e-01, time/batch = 18.3877s	
19038/33650 (epoch 28.288), train_loss = 0.93896299, grad/param norm = 1.8474e-01, time/batch = 18.7247s	
19039/33650 (epoch 28.290), train_loss = 0.92618969, grad/param norm = 1.4971e-01, time/batch = 17.8880s	
19040/33650 (epoch 28.291), train_loss = 0.82889051, grad/param norm = 1.3992e-01, time/batch = 18.3315s	
19041/33650 (epoch 28.293), train_loss = 0.92754373, grad/param norm = 1.9620e-01, time/batch = 17.8865s	
19042/33650 (epoch 28.294), train_loss = 0.83260007, grad/param norm = 1.3770e-01, time/batch = 17.7151s	
19043/33650 (epoch 28.296), train_loss = 0.82209675, grad/param norm = 1.4885e-01, time/batch = 17.4888s	
19044/33650 (epoch 28.297), train_loss = 0.87647669, grad/param norm = 1.5334e-01, time/batch = 18.0727s	
19045/33650 (epoch 28.299), train_loss = 0.77956057, grad/param norm = 1.5979e-01, time/batch = 16.3912s	
19046/33650 (epoch 28.300), train_loss = 0.81152709, grad/param norm = 1.5768e-01, time/batch = 17.8956s	
19047/33650 (epoch 28.302), train_loss = 0.92446002, grad/param norm = 1.3802e-01, time/batch = 18.4796s	
19048/33650 (epoch 28.303), train_loss = 0.92623535, grad/param norm = 1.4197e-01, time/batch = 15.8840s	
19049/33650 (epoch 28.305), train_loss = 0.91227340, grad/param norm = 1.5942e-01, time/batch = 16.4876s	
19050/33650 (epoch 28.306), train_loss = 0.83156466, grad/param norm = 1.3838e-01, time/batch = 16.9587s	
19051/33650 (epoch 28.308), train_loss = 0.80990876, grad/param norm = 1.7537e-01, time/batch = 17.6403s	
19052/33650 (epoch 28.309), train_loss = 1.06818267, grad/param norm = 1.9170e-01, time/batch = 16.3225s	
19053/33650 (epoch 28.311), train_loss = 0.90951599, grad/param norm = 1.8504e-01, time/batch = 16.9042s	
19054/33650 (epoch 28.312), train_loss = 0.94013604, grad/param norm = 1.6278e-01, time/batch = 18.6594s	
19055/33650 (epoch 28.314), train_loss = 0.83055890, grad/param norm = 1.6276e-01, time/batch = 18.9023s	
19056/33650 (epoch 28.315), train_loss = 0.88331718, grad/param norm = 1.7403e-01, time/batch = 16.7147s	
19057/33650 (epoch 28.316), train_loss = 0.87240198, grad/param norm = 1.9587e-01, time/batch = 18.6314s	
19058/33650 (epoch 28.318), train_loss = 0.79608239, grad/param norm = 1.3689e-01, time/batch = 18.1406s	
19059/33650 (epoch 28.319), train_loss = 0.82787207, grad/param norm = 1.4493e-01, time/batch = 16.2119s	
19060/33650 (epoch 28.321), train_loss = 0.85472710, grad/param norm = 1.3844e-01, time/batch = 17.6536s	
19061/33650 (epoch 28.322), train_loss = 0.93078610, grad/param norm = 2.3306e-01, time/batch = 17.7344s	
19062/33650 (epoch 28.324), train_loss = 0.99421706, grad/param norm = 2.7063e-01, time/batch = 18.2084s	
19063/33650 (epoch 28.325), train_loss = 0.95823495, grad/param norm = 1.6922e-01, time/batch = 30.5665s	
19064/33650 (epoch 28.327), train_loss = 0.83977112, grad/param norm = 1.4169e-01, time/batch = 17.4820s	
19065/33650 (epoch 28.328), train_loss = 0.93854569, grad/param norm = 1.6857e-01, time/batch = 17.1332s	
19066/33650 (epoch 28.330), train_loss = 0.85007431, grad/param norm = 1.4300e-01, time/batch = 17.2272s	
19067/33650 (epoch 28.331), train_loss = 0.77554289, grad/param norm = 1.3127e-01, time/batch = 18.8789s	
19068/33650 (epoch 28.333), train_loss = 0.89144281, grad/param norm = 1.7289e-01, time/batch = 17.5619s	
19069/33650 (epoch 28.334), train_loss = 0.88289597, grad/param norm = 1.5623e-01, time/batch = 17.8040s	
19070/33650 (epoch 28.336), train_loss = 0.98918366, grad/param norm = 1.6474e-01, time/batch = 16.5286s	
19071/33650 (epoch 28.337), train_loss = 0.75151295, grad/param norm = 1.2873e-01, time/batch = 18.4061s	
19072/33650 (epoch 28.339), train_loss = 0.85194997, grad/param norm = 1.5188e-01, time/batch = 17.7163s	
19073/33650 (epoch 28.340), train_loss = 1.01943103, grad/param norm = 1.7138e-01, time/batch = 16.8153s	
19074/33650 (epoch 28.342), train_loss = 0.75639882, grad/param norm = 1.4651e-01, time/batch = 16.6340s	
19075/33650 (epoch 28.343), train_loss = 0.94617221, grad/param norm = 1.5578e-01, time/batch = 17.2886s	
19076/33650 (epoch 28.345), train_loss = 0.91641165, grad/param norm = 2.0373e-01, time/batch = 18.0619s	
19077/33650 (epoch 28.346), train_loss = 0.62811815, grad/param norm = 1.2871e-01, time/batch = 18.5554s	
19078/33650 (epoch 28.348), train_loss = 0.78232801, grad/param norm = 1.3931e-01, time/batch = 18.3167s	
19079/33650 (epoch 28.349), train_loss = 0.74188874, grad/param norm = 1.4577e-01, time/batch = 17.2830s	
19080/33650 (epoch 28.351), train_loss = 0.95414980, grad/param norm = 1.6453e-01, time/batch = 18.3989s	
19081/33650 (epoch 28.352), train_loss = 0.87324058, grad/param norm = 1.5977e-01, time/batch = 18.3120s	
19082/33650 (epoch 28.354), train_loss = 1.00925445, grad/param norm = 2.0959e-01, time/batch = 17.2315s	
19083/33650 (epoch 28.355), train_loss = 1.05667228, grad/param norm = 1.6141e-01, time/batch = 17.2129s	
19084/33650 (epoch 28.357), train_loss = 0.73344774, grad/param norm = 1.4237e-01, time/batch = 17.9834s	
19085/33650 (epoch 28.358), train_loss = 0.95682982, grad/param norm = 1.6591e-01, time/batch = 17.3907s	
19086/33650 (epoch 28.360), train_loss = 0.96655021, grad/param norm = 1.8196e-01, time/batch = 17.3895s	
19087/33650 (epoch 28.361), train_loss = 0.92939210, grad/param norm = 1.5372e-01, time/batch = 17.7181s	
19088/33650 (epoch 28.363), train_loss = 0.91305314, grad/param norm = 1.4526e-01, time/batch = 17.4747s	
19089/33650 (epoch 28.364), train_loss = 0.89318703, grad/param norm = 1.4442e-01, time/batch = 17.7141s	
19090/33650 (epoch 28.366), train_loss = 0.96256091, grad/param norm = 1.6257e-01, time/batch = 17.7202s	
19091/33650 (epoch 28.367), train_loss = 0.93626583, grad/param norm = 1.5758e-01, time/batch = 18.0667s	
19092/33650 (epoch 28.368), train_loss = 0.83240575, grad/param norm = 1.3408e-01, time/batch = 16.4834s	
19093/33650 (epoch 28.370), train_loss = 0.89092732, grad/param norm = 1.5045e-01, time/batch = 18.1538s	
19094/33650 (epoch 28.371), train_loss = 0.70251159, grad/param norm = 1.4483e-01, time/batch = 18.2309s	
19095/33650 (epoch 28.373), train_loss = 0.81437933, grad/param norm = 1.5185e-01, time/batch = 16.7914s	
19096/33650 (epoch 28.374), train_loss = 0.81899488, grad/param norm = 1.3017e-01, time/batch = 17.3777s	
19097/33650 (epoch 28.376), train_loss = 0.88869261, grad/param norm = 1.7470e-01, time/batch = 16.8786s	
19098/33650 (epoch 28.377), train_loss = 0.91618530, grad/param norm = 1.6567e-01, time/batch = 18.1417s	
19099/33650 (epoch 28.379), train_loss = 0.93330337, grad/param norm = 1.5281e-01, time/batch = 17.2272s	
19100/33650 (epoch 28.380), train_loss = 0.74564128, grad/param norm = 1.6275e-01, time/batch = 18.4814s	
19101/33650 (epoch 28.382), train_loss = 0.87586503, grad/param norm = 1.3156e-01, time/batch = 18.7247s	
19102/33650 (epoch 28.383), train_loss = 0.88684297, grad/param norm = 1.5487e-01, time/batch = 16.9789s	
19103/33650 (epoch 28.385), train_loss = 0.94028031, grad/param norm = 1.4860e-01, time/batch = 17.5578s	
19104/33650 (epoch 28.386), train_loss = 0.82519110, grad/param norm = 1.4516e-01, time/batch = 18.3994s	
19105/33650 (epoch 28.388), train_loss = 0.96478775, grad/param norm = 1.4862e-01, time/batch = 17.1331s	
19106/33650 (epoch 28.389), train_loss = 0.85887553, grad/param norm = 1.5978e-01, time/batch = 17.9686s	
19107/33650 (epoch 28.391), train_loss = 0.72687776, grad/param norm = 1.3636e-01, time/batch = 17.9875s	
19108/33650 (epoch 28.392), train_loss = 0.91933901, grad/param norm = 1.5519e-01, time/batch = 17.6370s	
19109/33650 (epoch 28.394), train_loss = 0.91239327, grad/param norm = 1.7371e-01, time/batch = 15.6305s	
19110/33650 (epoch 28.395), train_loss = 0.94453791, grad/param norm = 1.5744e-01, time/batch = 17.8103s	
19111/33650 (epoch 28.397), train_loss = 1.04427456, grad/param norm = 1.9270e-01, time/batch = 18.0679s	
19112/33650 (epoch 28.398), train_loss = 0.96150565, grad/param norm = 1.4582e-01, time/batch = 17.5601s	
19113/33650 (epoch 28.400), train_loss = 0.91493910, grad/param norm = 1.6858e-01, time/batch = 17.8865s	
19114/33650 (epoch 28.401), train_loss = 0.85357641, grad/param norm = 1.6898e-01, time/batch = 17.9896s	
19115/33650 (epoch 28.403), train_loss = 0.94040504, grad/param norm = 1.6645e-01, time/batch = 17.5390s	
19116/33650 (epoch 28.404), train_loss = 0.88919098, grad/param norm = 1.5823e-01, time/batch = 16.8116s	
19117/33650 (epoch 28.406), train_loss = 0.88434698, grad/param norm = 1.5006e-01, time/batch = 18.2345s	
19118/33650 (epoch 28.407), train_loss = 0.90682435, grad/param norm = 1.7028e-01, time/batch = 16.0641s	
19119/33650 (epoch 28.409), train_loss = 0.94072205, grad/param norm = 1.7515e-01, time/batch = 17.6481s	
19120/33650 (epoch 28.410), train_loss = 0.87682510, grad/param norm = 1.4681e-01, time/batch = 17.0652s	
19121/33650 (epoch 28.412), train_loss = 0.89116703, grad/param norm = 1.3699e-01, time/batch = 17.0491s	
19122/33650 (epoch 28.413), train_loss = 0.85339035, grad/param norm = 1.6995e-01, time/batch = 17.9100s	
19123/33650 (epoch 28.415), train_loss = 0.97752530, grad/param norm = 1.6827e-01, time/batch = 17.0532s	
19124/33650 (epoch 28.416), train_loss = 1.03771744, grad/param norm = 1.6953e-01, time/batch = 18.0586s	
19125/33650 (epoch 28.418), train_loss = 0.82334147, grad/param norm = 1.4533e-01, time/batch = 16.8127s	
19126/33650 (epoch 28.419), train_loss = 0.84878642, grad/param norm = 1.5467e-01, time/batch = 17.2090s	
19127/33650 (epoch 28.421), train_loss = 0.87617787, grad/param norm = 1.3747e-01, time/batch = 18.3909s	
19128/33650 (epoch 28.422), train_loss = 1.02790390, grad/param norm = 1.6439e-01, time/batch = 17.7333s	
19129/33650 (epoch 28.423), train_loss = 0.81013515, grad/param norm = 1.1565e-01, time/batch = 18.2311s	
19130/33650 (epoch 28.425), train_loss = 0.91602501, grad/param norm = 1.9039e-01, time/batch = 16.5363s	
19131/33650 (epoch 28.426), train_loss = 1.00492782, grad/param norm = 1.8556e-01, time/batch = 18.6409s	
19132/33650 (epoch 28.428), train_loss = 0.85072873, grad/param norm = 1.4593e-01, time/batch = 17.4501s	
19133/33650 (epoch 28.429), train_loss = 0.96570750, grad/param norm = 1.8010e-01, time/batch = 14.0976s	
19134/33650 (epoch 28.431), train_loss = 1.05232583, grad/param norm = 1.7986e-01, time/batch = 13.8950s	
19135/33650 (epoch 28.432), train_loss = 1.07290788, grad/param norm = 1.9570e-01, time/batch = 14.1635s	
19136/33650 (epoch 28.434), train_loss = 0.94025285, grad/param norm = 1.6053e-01, time/batch = 13.6664s	
19137/33650 (epoch 28.435), train_loss = 0.92414968, grad/param norm = 1.6902e-01, time/batch = 13.9670s	
19138/33650 (epoch 28.437), train_loss = 0.92552566, grad/param norm = 1.5830e-01, time/batch = 14.0708s	
19139/33650 (epoch 28.438), train_loss = 0.87916853, grad/param norm = 1.6711e-01, time/batch = 18.3939s	
19140/33650 (epoch 28.440), train_loss = 0.91884150, grad/param norm = 1.7331e-01, time/batch = 16.7398s	
19141/33650 (epoch 28.441), train_loss = 0.90827014, grad/param norm = 1.6279e-01, time/batch = 16.5534s	
19142/33650 (epoch 28.443), train_loss = 0.97075192, grad/param norm = 1.5190e-01, time/batch = 18.1459s	
19143/33650 (epoch 28.444), train_loss = 0.89356569, grad/param norm = 1.5353e-01, time/batch = 18.2285s	
19144/33650 (epoch 28.446), train_loss = 0.94014369, grad/param norm = 1.6116e-01, time/batch = 17.3122s	
19145/33650 (epoch 28.447), train_loss = 1.03980666, grad/param norm = 1.6976e-01, time/batch = 18.1496s	
19146/33650 (epoch 28.449), train_loss = 1.05637706, grad/param norm = 1.9133e-01, time/batch = 18.0554s	
19147/33650 (epoch 28.450), train_loss = 1.07836716, grad/param norm = 1.7032e-01, time/batch = 18.4838s	
19148/33650 (epoch 28.452), train_loss = 1.03784711, grad/param norm = 1.7541e-01, time/batch = 17.4684s	
19149/33650 (epoch 28.453), train_loss = 1.07272434, grad/param norm = 1.9341e-01, time/batch = 17.0702s	
19150/33650 (epoch 28.455), train_loss = 0.89422055, grad/param norm = 1.5338e-01, time/batch = 17.9009s	
19151/33650 (epoch 28.456), train_loss = 0.91600160, grad/param norm = 1.5893e-01, time/batch = 17.0610s	
19152/33650 (epoch 28.458), train_loss = 0.89776303, grad/param norm = 1.7362e-01, time/batch = 18.1457s	
19153/33650 (epoch 28.459), train_loss = 0.95027442, grad/param norm = 1.6202e-01, time/batch = 17.8080s	
19154/33650 (epoch 28.461), train_loss = 1.01757430, grad/param norm = 1.7133e-01, time/batch = 18.0538s	
19155/33650 (epoch 28.462), train_loss = 1.00998631, grad/param norm = 1.8300e-01, time/batch = 17.3088s	
19156/33650 (epoch 28.464), train_loss = 0.89171998, grad/param norm = 1.8327e-01, time/batch = 18.8172s	
19157/33650 (epoch 28.465), train_loss = 0.95966243, grad/param norm = 1.8809e-01, time/batch = 18.6471s	
19158/33650 (epoch 28.467), train_loss = 0.96095811, grad/param norm = 1.5129e-01, time/batch = 15.5912s	
19159/33650 (epoch 28.468), train_loss = 1.06812640, grad/param norm = 1.5582e-01, time/batch = 18.9664s	
19160/33650 (epoch 28.470), train_loss = 1.12451390, grad/param norm = 1.8210e-01, time/batch = 17.2257s	
19161/33650 (epoch 28.471), train_loss = 0.92515663, grad/param norm = 1.5061e-01, time/batch = 16.9699s	
19162/33650 (epoch 28.473), train_loss = 0.88580140, grad/param norm = 1.5738e-01, time/batch = 18.7144s	
19163/33650 (epoch 28.474), train_loss = 1.01454563, grad/param norm = 1.5870e-01, time/batch = 17.0749s	
19164/33650 (epoch 28.475), train_loss = 0.99375967, grad/param norm = 1.7090e-01, time/batch = 17.5533s	
19165/33650 (epoch 28.477), train_loss = 1.02085452, grad/param norm = 1.6280e-01, time/batch = 16.8759s	
19166/33650 (epoch 28.478), train_loss = 0.99919302, grad/param norm = 1.8017e-01, time/batch = 18.3974s	
19167/33650 (epoch 28.480), train_loss = 1.00628401, grad/param norm = 1.8779e-01, time/batch = 18.6465s	
19168/33650 (epoch 28.481), train_loss = 1.04346287, grad/param norm = 1.6564e-01, time/batch = 17.2065s	
19169/33650 (epoch 28.483), train_loss = 0.79161852, grad/param norm = 1.5994e-01, time/batch = 18.7327s	
19170/33650 (epoch 28.484), train_loss = 0.90679553, grad/param norm = 1.6208e-01, time/batch = 17.9795s	
19171/33650 (epoch 28.486), train_loss = 1.07811210, grad/param norm = 2.0442e-01, time/batch = 18.0510s	
19172/33650 (epoch 28.487), train_loss = 1.03719873, grad/param norm = 1.7067e-01, time/batch = 16.8090s	
19173/33650 (epoch 28.489), train_loss = 1.07472202, grad/param norm = 1.5952e-01, time/batch = 15.8920s	
19174/33650 (epoch 28.490), train_loss = 0.85354247, grad/param norm = 1.6623e-01, time/batch = 18.6486s	
19175/33650 (epoch 28.492), train_loss = 0.97105051, grad/param norm = 1.6231e-01, time/batch = 17.1406s	
19176/33650 (epoch 28.493), train_loss = 0.77824239, grad/param norm = 1.3058e-01, time/batch = 17.5332s	
19177/33650 (epoch 28.495), train_loss = 0.94758030, grad/param norm = 1.8129e-01, time/batch = 18.2354s	
19178/33650 (epoch 28.496), train_loss = 0.97669038, grad/param norm = 1.6764e-01, time/batch = 16.7117s	
19179/33650 (epoch 28.498), train_loss = 0.85632986, grad/param norm = 1.4372e-01, time/batch = 17.0645s	
19180/33650 (epoch 28.499), train_loss = 0.93494273, grad/param norm = 1.3561e-01, time/batch = 17.9015s	
19181/33650 (epoch 28.501), train_loss = 0.92579813, grad/param norm = 1.3906e-01, time/batch = 17.8080s	
19182/33650 (epoch 28.502), train_loss = 0.96855517, grad/param norm = 1.7762e-01, time/batch = 17.8071s	
19183/33650 (epoch 28.504), train_loss = 1.01480822, grad/param norm = 1.8023e-01, time/batch = 17.5742s	
19184/33650 (epoch 28.505), train_loss = 0.90984500, grad/param norm = 1.8985e-01, time/batch = 18.6419s	
19185/33650 (epoch 28.507), train_loss = 1.02815437, grad/param norm = 1.5780e-01, time/batch = 17.3976s	
19186/33650 (epoch 28.508), train_loss = 0.92258899, grad/param norm = 1.5710e-01, time/batch = 18.1561s	
19187/33650 (epoch 28.510), train_loss = 0.93624610, grad/param norm = 1.4655e-01, time/batch = 18.5601s	
19188/33650 (epoch 28.511), train_loss = 1.09895151, grad/param norm = 1.7946e-01, time/batch = 16.3942s	
19189/33650 (epoch 28.513), train_loss = 0.97346307, grad/param norm = 1.6535e-01, time/batch = 17.5673s	
19190/33650 (epoch 28.514), train_loss = 1.03134486, grad/param norm = 2.0253e-01, time/batch = 18.0577s	
19191/33650 (epoch 28.516), train_loss = 0.94682234, grad/param norm = 1.7985e-01, time/batch = 16.7144s	
19192/33650 (epoch 28.517), train_loss = 0.95519379, grad/param norm = 1.8060e-01, time/batch = 17.8930s	
19193/33650 (epoch 28.519), train_loss = 1.00390148, grad/param norm = 1.7692e-01, time/batch = 16.6073s	
19194/33650 (epoch 28.520), train_loss = 0.81113625, grad/param norm = 1.2771e-01, time/batch = 16.9778s	
19195/33650 (epoch 28.522), train_loss = 0.93024528, grad/param norm = 1.5926e-01, time/batch = 17.0632s	
19196/33650 (epoch 28.523), train_loss = 0.86722184, grad/param norm = 1.4881e-01, time/batch = 17.1541s	
19197/33650 (epoch 28.525), train_loss = 0.74442079, grad/param norm = 1.2925e-01, time/batch = 17.9020s	
19198/33650 (epoch 28.526), train_loss = 1.04789149, grad/param norm = 1.5961e-01, time/batch = 16.9766s	
19199/33650 (epoch 28.527), train_loss = 0.88002963, grad/param norm = 1.6633e-01, time/batch = 15.5542s	
19200/33650 (epoch 28.529), train_loss = 0.92467595, grad/param norm = 1.5478e-01, time/batch = 17.6256s	
19201/33650 (epoch 28.530), train_loss = 0.87853069, grad/param norm = 1.5421e-01, time/batch = 18.2276s	
19202/33650 (epoch 28.532), train_loss = 1.01861947, grad/param norm = 1.7808e-01, time/batch = 16.9804s	
19203/33650 (epoch 28.533), train_loss = 0.93130513, grad/param norm = 1.5078e-01, time/batch = 17.5787s	
19204/33650 (epoch 28.535), train_loss = 1.05195262, grad/param norm = 1.6611e-01, time/batch = 16.6431s	
19205/33650 (epoch 28.536), train_loss = 0.96786909, grad/param norm = 2.4441e-01, time/batch = 17.7258s	
19206/33650 (epoch 28.538), train_loss = 0.97620541, grad/param norm = 1.7631e-01, time/batch = 17.4879s	
19207/33650 (epoch 28.539), train_loss = 0.75713049, grad/param norm = 1.4291e-01, time/batch = 17.5423s	
19208/33650 (epoch 28.541), train_loss = 1.01980635, grad/param norm = 1.7513e-01, time/batch = 18.4886s	
19209/33650 (epoch 28.542), train_loss = 0.95050107, grad/param norm = 2.0756e-01, time/batch = 16.8060s	
19210/33650 (epoch 28.544), train_loss = 1.09199232, grad/param norm = 2.6106e-01, time/batch = 18.6463s	
19211/33650 (epoch 28.545), train_loss = 0.83591070, grad/param norm = 1.5738e-01, time/batch = 16.8996s	
19212/33650 (epoch 28.547), train_loss = 0.97176519, grad/param norm = 1.6968e-01, time/batch = 17.4818s	
19213/33650 (epoch 28.548), train_loss = 1.11872673, grad/param norm = 1.8349e-01, time/batch = 17.0745s	
19214/33650 (epoch 28.550), train_loss = 0.95937672, grad/param norm = 1.6705e-01, time/batch = 18.4733s	
19215/33650 (epoch 28.551), train_loss = 0.95025904, grad/param norm = 1.8160e-01, time/batch = 17.8899s	
19216/33650 (epoch 28.553), train_loss = 0.82396339, grad/param norm = 1.8607e-01, time/batch = 15.8889s	
19217/33650 (epoch 28.554), train_loss = 1.09483790, grad/param norm = 1.9176e-01, time/batch = 15.0003s	
19218/33650 (epoch 28.556), train_loss = 1.02316651, grad/param norm = 2.3382e-01, time/batch = 15.8569s	
19219/33650 (epoch 28.557), train_loss = 1.03312659, grad/param norm = 1.9193e-01, time/batch = 14.7738s	
19220/33650 (epoch 28.559), train_loss = 1.19571732, grad/param norm = 1.8427e-01, time/batch = 14.6294s	
19221/33650 (epoch 28.560), train_loss = 1.12254723, grad/param norm = 1.8706e-01, time/batch = 16.1500s	
19222/33650 (epoch 28.562), train_loss = 1.08614730, grad/param norm = 1.6327e-01, time/batch = 18.5607s	
19223/33650 (epoch 28.563), train_loss = 0.99368199, grad/param norm = 1.7699e-01, time/batch = 17.8929s	
19224/33650 (epoch 28.565), train_loss = 0.95894141, grad/param norm = 1.6421e-01, time/batch = 17.1353s	
19225/33650 (epoch 28.566), train_loss = 0.91783332, grad/param norm = 1.6823e-01, time/batch = 18.0643s	
19226/33650 (epoch 28.568), train_loss = 0.95654335, grad/param norm = 1.7390e-01, time/batch = 18.0675s	
19227/33650 (epoch 28.569), train_loss = 0.87998707, grad/param norm = 1.7981e-01, time/batch = 17.4838s	
19228/33650 (epoch 28.571), train_loss = 1.04140901, grad/param norm = 1.6453e-01, time/batch = 18.3925s	
19229/33650 (epoch 28.572), train_loss = 0.99737764, grad/param norm = 1.6068e-01, time/batch = 18.1412s	
19230/33650 (epoch 28.574), train_loss = 0.86396628, grad/param norm = 1.6393e-01, time/batch = 16.9676s	
19231/33650 (epoch 28.575), train_loss = 0.94599596, grad/param norm = 1.7009e-01, time/batch = 18.8944s	
19232/33650 (epoch 28.577), train_loss = 0.89207441, grad/param norm = 1.7695e-01, time/batch = 17.3982s	
19233/33650 (epoch 28.578), train_loss = 1.03657575, grad/param norm = 1.8135e-01, time/batch = 16.7179s	
19234/33650 (epoch 28.579), train_loss = 0.99988571, grad/param norm = 1.6436e-01, time/batch = 18.3181s	
19235/33650 (epoch 28.581), train_loss = 1.08687413, grad/param norm = 1.7724e-01, time/batch = 15.1875s	
19236/33650 (epoch 28.582), train_loss = 0.97744417, grad/param norm = 1.4515e-01, time/batch = 17.9702s	
19237/33650 (epoch 28.584), train_loss = 0.95248544, grad/param norm = 1.4756e-01, time/batch = 17.4658s	
19238/33650 (epoch 28.585), train_loss = 0.97597375, grad/param norm = 1.5787e-01, time/batch = 18.3209s	
19239/33650 (epoch 28.587), train_loss = 0.87715361, grad/param norm = 1.5440e-01, time/batch = 17.8282s	
19240/33650 (epoch 28.588), train_loss = 0.88531235, grad/param norm = 1.9522e-01, time/batch = 17.5543s	
19241/33650 (epoch 28.590), train_loss = 0.89130125, grad/param norm = 1.4524e-01, time/batch = 17.7381s	
19242/33650 (epoch 28.591), train_loss = 0.84387214, grad/param norm = 1.4812e-01, time/batch = 18.8997s	
19243/33650 (epoch 28.593), train_loss = 0.84522962, grad/param norm = 1.4616e-01, time/batch = 16.3664s	
19244/33650 (epoch 28.594), train_loss = 0.83438533, grad/param norm = 1.5558e-01, time/batch = 16.3956s	
19245/33650 (epoch 28.596), train_loss = 0.92019060, grad/param norm = 1.5644e-01, time/batch = 17.6548s	
19246/33650 (epoch 28.597), train_loss = 0.79106974, grad/param norm = 1.2936e-01, time/batch = 17.9103s	
19247/33650 (epoch 28.599), train_loss = 0.91385728, grad/param norm = 1.5334e-01, time/batch = 17.8965s	
19248/33650 (epoch 28.600), train_loss = 0.86002913, grad/param norm = 1.5220e-01, time/batch = 17.8246s	
19249/33650 (epoch 28.602), train_loss = 0.94790600, grad/param norm = 1.5535e-01, time/batch = 18.5642s	
19250/33650 (epoch 28.603), train_loss = 0.87656637, grad/param norm = 1.5989e-01, time/batch = 16.9690s	
19251/33650 (epoch 28.605), train_loss = 0.99913442, grad/param norm = 1.5867e-01, time/batch = 18.3952s	
19252/33650 (epoch 28.606), train_loss = 0.94267615, grad/param norm = 1.8675e-01, time/batch = 18.8084s	
19253/33650 (epoch 28.608), train_loss = 0.83199714, grad/param norm = 1.6356e-01, time/batch = 16.3673s	
19254/33650 (epoch 28.609), train_loss = 0.92898448, grad/param norm = 1.5157e-01, time/batch = 17.6391s	
19255/33650 (epoch 28.611), train_loss = 0.83409819, grad/param norm = 1.5545e-01, time/batch = 18.4780s	
19256/33650 (epoch 28.612), train_loss = 0.94973896, grad/param norm = 1.9541e-01, time/batch = 16.2231s	
19257/33650 (epoch 28.614), train_loss = 1.02694838, grad/param norm = 1.6819e-01, time/batch = 16.8891s	
19258/33650 (epoch 28.615), train_loss = 0.93443443, grad/param norm = 1.4294e-01, time/batch = 17.0624s	
19259/33650 (epoch 28.617), train_loss = 0.84187186, grad/param norm = 1.3154e-01, time/batch = 17.3032s	
19260/33650 (epoch 28.618), train_loss = 0.89572370, grad/param norm = 1.5376e-01, time/batch = 17.6460s	
19261/33650 (epoch 28.620), train_loss = 0.88185806, grad/param norm = 1.6121e-01, time/batch = 18.3910s	
19262/33650 (epoch 28.621), train_loss = 0.83807574, grad/param norm = 1.4850e-01, time/batch = 17.8147s	
19263/33650 (epoch 28.623), train_loss = 0.89581517, grad/param norm = 1.5677e-01, time/batch = 17.0643s	
19264/33650 (epoch 28.624), train_loss = 0.72869468, grad/param norm = 1.5953e-01, time/batch = 17.4666s	
19265/33650 (epoch 28.626), train_loss = 0.76384721, grad/param norm = 1.5423e-01, time/batch = 18.1417s	
19266/33650 (epoch 28.627), train_loss = 0.86246374, grad/param norm = 1.6358e-01, time/batch = 18.6402s	
19267/33650 (epoch 28.629), train_loss = 0.87045100, grad/param norm = 1.7839e-01, time/batch = 28.6667s	
19268/33650 (epoch 28.630), train_loss = 1.03635626, grad/param norm = 1.8225e-01, time/batch = 18.8325s	
19269/33650 (epoch 28.632), train_loss = 1.03335892, grad/param norm = 1.6464e-01, time/batch = 18.2283s	
19270/33650 (epoch 28.633), train_loss = 1.01100419, grad/param norm = 1.6023e-01, time/batch = 17.1198s	
19271/33650 (epoch 28.634), train_loss = 0.82233824, grad/param norm = 1.4701e-01, time/batch = 18.3154s	
19272/33650 (epoch 28.636), train_loss = 0.73044244, grad/param norm = 1.3172e-01, time/batch = 18.1479s	
19273/33650 (epoch 28.637), train_loss = 0.84150475, grad/param norm = 1.4722e-01, time/batch = 16.9674s	
19274/33650 (epoch 28.639), train_loss = 0.84241081, grad/param norm = 1.4269e-01, time/batch = 17.9740s	
19275/33650 (epoch 28.640), train_loss = 0.93549233, grad/param norm = 1.6415e-01, time/batch = 18.8050s	
19276/33650 (epoch 28.642), train_loss = 0.98002344, grad/param norm = 1.5877e-01, time/batch = 15.8759s	
19277/33650 (epoch 28.643), train_loss = 0.92845586, grad/param norm = 1.6004e-01, time/batch = 15.9650s	
19278/33650 (epoch 28.645), train_loss = 0.96183121, grad/param norm = 1.7627e-01, time/batch = 18.4859s	
19279/33650 (epoch 28.646), train_loss = 0.81453842, grad/param norm = 1.3213e-01, time/batch = 18.5635s	
19280/33650 (epoch 28.648), train_loss = 0.96057572, grad/param norm = 1.5551e-01, time/batch = 17.7175s	
19281/33650 (epoch 28.649), train_loss = 0.84649312, grad/param norm = 1.4805e-01, time/batch = 18.6487s	
19282/33650 (epoch 28.651), train_loss = 0.99085774, grad/param norm = 1.9300e-01, time/batch = 19.0674s	
19283/33650 (epoch 28.652), train_loss = 0.68037833, grad/param norm = 1.2695e-01, time/batch = 13.2370s	
19284/33650 (epoch 28.654), train_loss = 0.82200822, grad/param norm = 1.5573e-01, time/batch = 0.6438s	
19285/33650 (epoch 28.655), train_loss = 0.83352196, grad/param norm = 1.6027e-01, time/batch = 0.6419s	
19286/33650 (epoch 28.657), train_loss = 0.89270194, grad/param norm = 1.7646e-01, time/batch = 0.6390s	
19287/33650 (epoch 28.658), train_loss = 0.75527791, grad/param norm = 1.6175e-01, time/batch = 0.6424s	
19288/33650 (epoch 28.660), train_loss = 0.74312487, grad/param norm = 1.4854e-01, time/batch = 0.6414s	
19289/33650 (epoch 28.661), train_loss = 0.81904141, grad/param norm = 1.4520e-01, time/batch = 0.6398s	
19290/33650 (epoch 28.663), train_loss = 0.79332344, grad/param norm = 1.5964e-01, time/batch = 0.6432s	
19291/33650 (epoch 28.664), train_loss = 0.86399052, grad/param norm = 1.5218e-01, time/batch = 0.8177s	
19292/33650 (epoch 28.666), train_loss = 0.87457938, grad/param norm = 1.2912e-01, time/batch = 0.9446s	
19293/33650 (epoch 28.667), train_loss = 0.78484057, grad/param norm = 1.3346e-01, time/batch = 0.9548s	
19294/33650 (epoch 28.669), train_loss = 0.79845308, grad/param norm = 1.5193e-01, time/batch = 0.9842s	
19295/33650 (epoch 28.670), train_loss = 0.74946452, grad/param norm = 1.5313e-01, time/batch = 0.9402s	
19296/33650 (epoch 28.672), train_loss = 0.75800424, grad/param norm = 1.3745e-01, time/batch = 1.2048s	
19297/33650 (epoch 28.673), train_loss = 0.74351257, grad/param norm = 1.4147e-01, time/batch = 1.7768s	
19298/33650 (epoch 28.675), train_loss = 0.71443416, grad/param norm = 1.1979e-01, time/batch = 1.9497s	
19299/33650 (epoch 28.676), train_loss = 0.87437534, grad/param norm = 1.5655e-01, time/batch = 11.4372s	
19300/33650 (epoch 28.678), train_loss = 0.85520730, grad/param norm = 1.5594e-01, time/batch = 18.5608s	
19301/33650 (epoch 28.679), train_loss = 0.83987840, grad/param norm = 1.6355e-01, time/batch = 16.8116s	
19302/33650 (epoch 28.681), train_loss = 0.87237270, grad/param norm = 1.4756e-01, time/batch = 18.0669s	
19303/33650 (epoch 28.682), train_loss = 0.79217260, grad/param norm = 1.5558e-01, time/batch = 17.8923s	
19304/33650 (epoch 28.684), train_loss = 0.77959702, grad/param norm = 1.4554e-01, time/batch = 17.7225s	
19305/33650 (epoch 28.685), train_loss = 0.92171383, grad/param norm = 1.6680e-01, time/batch = 18.2307s	
19306/33650 (epoch 28.686), train_loss = 0.88226641, grad/param norm = 1.4902e-01, time/batch = 18.2178s	
19307/33650 (epoch 28.688), train_loss = 0.96962105, grad/param norm = 1.5613e-01, time/batch = 18.8941s	
19308/33650 (epoch 28.689), train_loss = 0.81171283, grad/param norm = 1.4440e-01, time/batch = 17.4669s	
19309/33650 (epoch 28.691), train_loss = 0.97782430, grad/param norm = 1.6917e-01, time/batch = 15.8056s	
19310/33650 (epoch 28.692), train_loss = 1.00407497, grad/param norm = 1.6078e-01, time/batch = 17.3900s	
19311/33650 (epoch 28.694), train_loss = 0.93102988, grad/param norm = 1.6492e-01, time/batch = 16.7022s	
19312/33650 (epoch 28.695), train_loss = 0.64655261, grad/param norm = 1.3897e-01, time/batch = 18.7299s	
19313/33650 (epoch 28.697), train_loss = 0.85367032, grad/param norm = 1.4762e-01, time/batch = 16.7395s	
19314/33650 (epoch 28.698), train_loss = 1.00849739, grad/param norm = 1.6134e-01, time/batch = 19.2310s	
19315/33650 (epoch 28.700), train_loss = 0.87909714, grad/param norm = 1.4652e-01, time/batch = 16.9620s	
19316/33650 (epoch 28.701), train_loss = 0.88875744, grad/param norm = 1.5406e-01, time/batch = 17.3755s	
19317/33650 (epoch 28.703), train_loss = 1.08783511, grad/param norm = 1.6422e-01, time/batch = 17.8964s	
19318/33650 (epoch 28.704), train_loss = 0.88326312, grad/param norm = 1.4906e-01, time/batch = 17.1378s	
19319/33650 (epoch 28.706), train_loss = 0.84542568, grad/param norm = 1.3101e-01, time/batch = 18.0542s	
19320/33650 (epoch 28.707), train_loss = 0.98088211, grad/param norm = 1.4597e-01, time/batch = 16.8896s	
19321/33650 (epoch 28.709), train_loss = 0.86057691, grad/param norm = 1.5795e-01, time/batch = 17.7263s	
19322/33650 (epoch 28.710), train_loss = 1.06948973, grad/param norm = 1.7913e-01, time/batch = 18.0577s	
19323/33650 (epoch 28.712), train_loss = 0.80095285, grad/param norm = 1.5821e-01, time/batch = 17.8088s	
19324/33650 (epoch 28.713), train_loss = 0.79390117, grad/param norm = 1.7223e-01, time/batch = 18.2402s	
19325/33650 (epoch 28.715), train_loss = 0.96660695, grad/param norm = 1.7767e-01, time/batch = 16.9757s	
19326/33650 (epoch 28.716), train_loss = 0.85885913, grad/param norm = 1.5519e-01, time/batch = 15.7915s	
19327/33650 (epoch 28.718), train_loss = 0.85422599, grad/param norm = 1.5225e-01, time/batch = 18.1485s	
19328/33650 (epoch 28.719), train_loss = 0.99113623, grad/param norm = 1.9212e-01, time/batch = 17.5482s	
19329/33650 (epoch 28.721), train_loss = 1.07611627, grad/param norm = 1.8715e-01, time/batch = 17.7289s	
19330/33650 (epoch 28.722), train_loss = 0.96101143, grad/param norm = 2.2850e-01, time/batch = 16.3827s	
19331/33650 (epoch 28.724), train_loss = 1.00835150, grad/param norm = 1.6096e-01, time/batch = 18.2384s	
19332/33650 (epoch 28.725), train_loss = 0.98655767, grad/param norm = 2.0729e-01, time/batch = 17.7152s	
19333/33650 (epoch 28.727), train_loss = 0.85249890, grad/param norm = 1.7413e-01, time/batch = 17.6478s	
19334/33650 (epoch 28.728), train_loss = 0.87466750, grad/param norm = 1.5076e-01, time/batch = 18.5598s	
19335/33650 (epoch 28.730), train_loss = 0.93092158, grad/param norm = 1.7432e-01, time/batch = 17.2232s	
19336/33650 (epoch 28.731), train_loss = 1.04704243, grad/param norm = 1.7083e-01, time/batch = 18.6413s	
19337/33650 (epoch 28.733), train_loss = 0.87669122, grad/param norm = 1.6976e-01, time/batch = 18.3261s	
19338/33650 (epoch 28.734), train_loss = 1.02809506, grad/param norm = 1.7239e-01, time/batch = 18.4757s	
19339/33650 (epoch 28.736), train_loss = 0.89610411, grad/param norm = 1.9235e-01, time/batch = 17.3940s	
19340/33650 (epoch 28.737), train_loss = 0.93428978, grad/param norm = 1.5171e-01, time/batch = 17.8917s	
19341/33650 (epoch 28.738), train_loss = 0.84449043, grad/param norm = 1.7086e-01, time/batch = 18.5593s	
19342/33650 (epoch 28.740), train_loss = 0.77034541, grad/param norm = 1.4228e-01, time/batch = 17.3183s	
19343/33650 (epoch 28.741), train_loss = 0.85006120, grad/param norm = 1.9046e-01, time/batch = 18.8879s	
19344/33650 (epoch 28.743), train_loss = 0.89356936, grad/param norm = 1.6096e-01, time/batch = 16.8127s	
19345/33650 (epoch 28.744), train_loss = 0.97546208, grad/param norm = 1.4578e-01, time/batch = 16.7163s	
19346/33650 (epoch 28.746), train_loss = 0.86202702, grad/param norm = 1.4825e-01, time/batch = 17.7302s	
19347/33650 (epoch 28.747), train_loss = 1.01497620, grad/param norm = 1.6425e-01, time/batch = 17.5691s	
19348/33650 (epoch 28.749), train_loss = 0.75994411, grad/param norm = 1.5841e-01, time/batch = 15.7234s	
19349/33650 (epoch 28.750), train_loss = 1.05654090, grad/param norm = 1.9849e-01, time/batch = 17.0606s	
19350/33650 (epoch 28.752), train_loss = 0.98273006, grad/param norm = 1.5417e-01, time/batch = 18.4792s	
19351/33650 (epoch 28.753), train_loss = 1.09789400, grad/param norm = 1.8773e-01, time/batch = 19.0593s	
19352/33650 (epoch 28.755), train_loss = 0.86258229, grad/param norm = 1.4201e-01, time/batch = 17.4729s	
19353/33650 (epoch 28.756), train_loss = 0.98949809, grad/param norm = 1.6878e-01, time/batch = 18.0546s	
19354/33650 (epoch 28.758), train_loss = 0.99430905, grad/param norm = 1.5677e-01, time/batch = 17.4042s	
19355/33650 (epoch 28.759), train_loss = 1.00022426, grad/param norm = 1.8018e-01, time/batch = 17.6470s	
19356/33650 (epoch 28.761), train_loss = 0.92560784, grad/param norm = 1.5013e-01, time/batch = 17.3994s	
19357/33650 (epoch 28.762), train_loss = 0.89924543, grad/param norm = 1.5974e-01, time/batch = 16.1165s	
19358/33650 (epoch 28.764), train_loss = 0.96749028, grad/param norm = 1.9402e-01, time/batch = 17.1366s	
19359/33650 (epoch 28.765), train_loss = 0.86903764, grad/param norm = 1.6316e-01, time/batch = 17.1326s	
19360/33650 (epoch 28.767), train_loss = 0.89610885, grad/param norm = 1.4451e-01, time/batch = 18.0683s	
19361/33650 (epoch 28.768), train_loss = 0.80030297, grad/param norm = 1.5277e-01, time/batch = 17.0563s	
19362/33650 (epoch 28.770), train_loss = 0.93488991, grad/param norm = 1.6513e-01, time/batch = 17.4749s	
19363/33650 (epoch 28.771), train_loss = 0.93685455, grad/param norm = 1.4911e-01, time/batch = 18.6427s	
19364/33650 (epoch 28.773), train_loss = 1.02527981, grad/param norm = 1.9418e-01, time/batch = 16.9082s	
19365/33650 (epoch 28.774), train_loss = 0.95206784, grad/param norm = 1.5406e-01, time/batch = 17.0720s	
19366/33650 (epoch 28.776), train_loss = 0.97779024, grad/param norm = 1.8519e-01, time/batch = 17.2990s	
19367/33650 (epoch 28.777), train_loss = 0.84491392, grad/param norm = 1.4721e-01, time/batch = 16.0445s	
19368/33650 (epoch 28.779), train_loss = 0.87541097, grad/param norm = 1.4341e-01, time/batch = 18.3208s	
19369/33650 (epoch 28.780), train_loss = 0.80671626, grad/param norm = 1.3559e-01, time/batch = 16.9021s	
19370/33650 (epoch 28.782), train_loss = 0.83575813, grad/param norm = 1.5859e-01, time/batch = 16.8833s	
19371/33650 (epoch 28.783), train_loss = 0.83216123, grad/param norm = 1.2923e-01, time/batch = 18.2258s	
19372/33650 (epoch 28.785), train_loss = 1.07623230, grad/param norm = 1.6297e-01, time/batch = 18.1461s	
19373/33650 (epoch 28.786), train_loss = 0.97231785, grad/param norm = 1.5017e-01, time/batch = 17.8938s	
19374/33650 (epoch 28.788), train_loss = 0.96544034, grad/param norm = 1.5686e-01, time/batch = 18.0536s	
19375/33650 (epoch 28.789), train_loss = 1.00742745, grad/param norm = 1.7427e-01, time/batch = 18.4052s	
19376/33650 (epoch 28.790), train_loss = 0.92569787, grad/param norm = 1.6058e-01, time/batch = 17.5535s	
19377/33650 (epoch 28.792), train_loss = 1.00244647, grad/param norm = 1.6298e-01, time/batch = 18.8909s	
19378/33650 (epoch 28.793), train_loss = 0.99771140, grad/param norm = 1.8619e-01, time/batch = 17.7416s	
19379/33650 (epoch 28.795), train_loss = 1.02177411, grad/param norm = 1.5341e-01, time/batch = 16.8260s	
19380/33650 (epoch 28.796), train_loss = 0.88545910, grad/param norm = 1.5778e-01, time/batch = 17.4852s	
19381/33650 (epoch 28.798), train_loss = 0.87491143, grad/param norm = 1.5030e-01, time/batch = 18.1608s	
19382/33650 (epoch 28.799), train_loss = 0.91886417, grad/param norm = 1.9243e-01, time/batch = 17.4630s	
19383/33650 (epoch 28.801), train_loss = 0.94492021, grad/param norm = 2.0969e-01, time/batch = 18.3827s	
19384/33650 (epoch 28.802), train_loss = 0.99912046, grad/param norm = 1.7059e-01, time/batch = 16.5394s	
19385/33650 (epoch 28.804), train_loss = 0.93004163, grad/param norm = 1.7588e-01, time/batch = 16.9799s	
19386/33650 (epoch 28.805), train_loss = 0.90789513, grad/param norm = 1.4543e-01, time/batch = 17.5555s	
19387/33650 (epoch 28.807), train_loss = 1.13005581, grad/param norm = 2.2103e-01, time/batch = 17.8225s	
19388/33650 (epoch 28.808), train_loss = 1.18292017, grad/param norm = 1.8781e-01, time/batch = 18.2289s	
19389/33650 (epoch 28.810), train_loss = 0.95542196, grad/param norm = 1.6913e-01, time/batch = 16.4695s	
19390/33650 (epoch 28.811), train_loss = 0.94524714, grad/param norm = 1.5136e-01, time/batch = 17.7156s	
19391/33650 (epoch 28.813), train_loss = 0.83073308, grad/param norm = 1.4778e-01, time/batch = 18.2301s	
19392/33650 (epoch 28.814), train_loss = 1.01496989, grad/param norm = 1.7261e-01, time/batch = 18.2294s	
19393/33650 (epoch 28.816), train_loss = 0.98582924, grad/param norm = 1.7011e-01, time/batch = 17.6377s	
19394/33650 (epoch 28.817), train_loss = 1.01615179, grad/param norm = 1.8743e-01, time/batch = 18.7214s	
19395/33650 (epoch 28.819), train_loss = 0.93860881, grad/param norm = 1.6307e-01, time/batch = 17.6291s	
19396/33650 (epoch 28.820), train_loss = 1.04069423, grad/param norm = 1.6519e-01, time/batch = 16.3815s	
19397/33650 (epoch 28.822), train_loss = 0.96665969, grad/param norm = 2.1462e-01, time/batch = 17.9747s	
19398/33650 (epoch 28.823), train_loss = 0.85977804, grad/param norm = 1.5870e-01, time/batch = 17.8975s	
19399/33650 (epoch 28.825), train_loss = 0.93655776, grad/param norm = 1.7102e-01, time/batch = 17.3932s	
19400/33650 (epoch 28.826), train_loss = 0.97638644, grad/param norm = 1.4576e-01, time/batch = 16.5417s	
19401/33650 (epoch 28.828), train_loss = 1.09521731, grad/param norm = 1.9147e-01, time/batch = 18.0635s	
19402/33650 (epoch 28.829), train_loss = 0.77972479, grad/param norm = 1.4711e-01, time/batch = 17.7372s	
19403/33650 (epoch 28.831), train_loss = 0.94913291, grad/param norm = 1.7312e-01, time/batch = 17.3901s	
19404/33650 (epoch 28.832), train_loss = 1.02239974, grad/param norm = 1.7732e-01, time/batch = 18.6382s	
19405/33650 (epoch 28.834), train_loss = 1.00213034, grad/param norm = 1.5859e-01, time/batch = 15.3286s	
19406/33650 (epoch 28.835), train_loss = 1.16242178, grad/param norm = 2.1964e-01, time/batch = 13.8256s	
19407/33650 (epoch 28.837), train_loss = 0.95996352, grad/param norm = 1.8410e-01, time/batch = 13.9078s	
19408/33650 (epoch 28.838), train_loss = 0.94409516, grad/param norm = 1.9194e-01, time/batch = 16.0473s	
19409/33650 (epoch 28.840), train_loss = 1.01530053, grad/param norm = 1.5672e-01, time/batch = 18.6436s	
19410/33650 (epoch 28.841), train_loss = 0.89752272, grad/param norm = 1.6153e-01, time/batch = 16.5535s	
19411/33650 (epoch 28.842), train_loss = 0.91970892, grad/param norm = 1.5451e-01, time/batch = 18.5565s	
19412/33650 (epoch 28.844), train_loss = 1.10518679, grad/param norm = 1.9331e-01, time/batch = 17.7317s	
19413/33650 (epoch 28.845), train_loss = 0.88458516, grad/param norm = 1.5595e-01, time/batch = 17.6450s	
19414/33650 (epoch 28.847), train_loss = 0.72107762, grad/param norm = 1.3546e-01, time/batch = 17.2091s	
19415/33650 (epoch 28.848), train_loss = 0.81286444, grad/param norm = 1.6875e-01, time/batch = 16.2929s	
19416/33650 (epoch 28.850), train_loss = 0.87976302, grad/param norm = 1.8192e-01, time/batch = 17.5658s	
19417/33650 (epoch 28.851), train_loss = 0.77328871, grad/param norm = 1.2761e-01, time/batch = 17.5480s	
19418/33650 (epoch 28.853), train_loss = 0.90290806, grad/param norm = 1.8816e-01, time/batch = 16.5550s	
19419/33650 (epoch 28.854), train_loss = 1.01352076, grad/param norm = 1.6965e-01, time/batch = 18.5621s	
19420/33650 (epoch 28.856), train_loss = 0.73038950, grad/param norm = 1.4462e-01, time/batch = 17.4707s	
19421/33650 (epoch 28.857), train_loss = 0.94423170, grad/param norm = 1.4519e-01, time/batch = 18.5574s	
19422/33650 (epoch 28.859), train_loss = 0.80636457, grad/param norm = 1.2620e-01, time/batch = 18.5641s	
19423/33650 (epoch 28.860), train_loss = 0.79066651, grad/param norm = 1.5623e-01, time/batch = 17.1914s	
19424/33650 (epoch 28.862), train_loss = 0.83221423, grad/param norm = 1.5301e-01, time/batch = 17.7901s	
19425/33650 (epoch 28.863), train_loss = 1.04821236, grad/param norm = 1.5475e-01, time/batch = 16.3075s	
19426/33650 (epoch 28.865), train_loss = 0.88746828, grad/param norm = 1.5734e-01, time/batch = 15.5553s	
19427/33650 (epoch 28.866), train_loss = 0.83934512, grad/param norm = 1.4916e-01, time/batch = 18.0611s	
19428/33650 (epoch 28.868), train_loss = 0.80125574, grad/param norm = 1.7692e-01, time/batch = 17.5690s	
19429/33650 (epoch 28.869), train_loss = 0.96931572, grad/param norm = 1.5873e-01, time/batch = 17.8203s	
19430/33650 (epoch 28.871), train_loss = 0.81894190, grad/param norm = 1.5919e-01, time/batch = 18.0576s	
19431/33650 (epoch 28.872), train_loss = 0.95695532, grad/param norm = 1.8685e-01, time/batch = 18.5480s	
19432/33650 (epoch 28.874), train_loss = 0.97654242, grad/param norm = 1.7950e-01, time/batch = 18.4653s	
19433/33650 (epoch 28.875), train_loss = 0.89801619, grad/param norm = 1.6525e-01, time/batch = 18.3270s	
19434/33650 (epoch 28.877), train_loss = 1.08596891, grad/param norm = 1.6935e-01, time/batch = 17.2084s	
19435/33650 (epoch 28.878), train_loss = 0.65228473, grad/param norm = 1.2022e-01, time/batch = 18.2294s	
19436/33650 (epoch 28.880), train_loss = 0.93671052, grad/param norm = 1.7402e-01, time/batch = 18.7416s	
19437/33650 (epoch 28.881), train_loss = 0.86961191, grad/param norm = 1.6740e-01, time/batch = 16.6300s	
19438/33650 (epoch 28.883), train_loss = 0.95287485, grad/param norm = 1.6957e-01, time/batch = 17.6988s	
19439/33650 (epoch 28.884), train_loss = 1.03111304, grad/param norm = 1.6236e-01, time/batch = 15.7980s	
19440/33650 (epoch 28.886), train_loss = 0.96432078, grad/param norm = 1.4586e-01, time/batch = 18.7364s	
19441/33650 (epoch 28.887), train_loss = 0.77970062, grad/param norm = 1.3756e-01, time/batch = 17.6388s	
19442/33650 (epoch 28.889), train_loss = 0.87911919, grad/param norm = 1.5760e-01, time/batch = 17.5580s	
19443/33650 (epoch 28.890), train_loss = 0.95742835, grad/param norm = 1.4844e-01, time/batch = 18.4866s	
19444/33650 (epoch 28.892), train_loss = 0.87273551, grad/param norm = 1.7506e-01, time/batch = 16.8987s	
19445/33650 (epoch 28.893), train_loss = 0.94578616, grad/param norm = 1.6385e-01, time/batch = 18.8916s	
19446/33650 (epoch 28.895), train_loss = 1.04619170, grad/param norm = 1.5943e-01, time/batch = 16.9445s	
19447/33650 (epoch 28.896), train_loss = 0.84144636, grad/param norm = 1.5121e-01, time/batch = 17.5422s	
19448/33650 (epoch 28.897), train_loss = 0.77435931, grad/param norm = 1.4877e-01, time/batch = 18.8079s	
19449/33650 (epoch 28.899), train_loss = 0.83395420, grad/param norm = 1.4143e-01, time/batch = 17.7290s	
19450/33650 (epoch 28.900), train_loss = 0.77151870, grad/param norm = 1.4280e-01, time/batch = 18.2281s	
19451/33650 (epoch 28.902), train_loss = 0.90693608, grad/param norm = 1.6423e-01, time/batch = 17.6994s	
19452/33650 (epoch 28.903), train_loss = 0.86853428, grad/param norm = 1.5669e-01, time/batch = 18.1373s	
19453/33650 (epoch 28.905), train_loss = 1.01331739, grad/param norm = 1.7627e-01, time/batch = 18.9747s	
19454/33650 (epoch 28.906), train_loss = 0.84343004, grad/param norm = 1.5760e-01, time/batch = 15.2209s	
19455/33650 (epoch 28.908), train_loss = 0.87205019, grad/param norm = 1.4632e-01, time/batch = 18.4806s	
19456/33650 (epoch 28.909), train_loss = 0.85608107, grad/param norm = 1.5155e-01, time/batch = 17.8966s	
19457/33650 (epoch 28.911), train_loss = 0.76748075, grad/param norm = 1.4707e-01, time/batch = 18.1441s	
19458/33650 (epoch 28.912), train_loss = 0.72783511, grad/param norm = 2.1377e-01, time/batch = 17.9029s	
19459/33650 (epoch 28.914), train_loss = 0.93394697, grad/param norm = 1.4061e-01, time/batch = 18.4711s	
19460/33650 (epoch 28.915), train_loss = 0.88007713, grad/param norm = 1.6056e-01, time/batch = 17.1268s	
19461/33650 (epoch 28.917), train_loss = 0.86313042, grad/param norm = 1.5447e-01, time/batch = 17.4609s	
19462/33650 (epoch 28.918), train_loss = 0.79445992, grad/param norm = 1.4496e-01, time/batch = 16.5401s	
19463/33650 (epoch 28.920), train_loss = 0.81497689, grad/param norm = 1.6288e-01, time/batch = 18.8157s	
19464/33650 (epoch 28.921), train_loss = 0.81439892, grad/param norm = 1.4917e-01, time/batch = 15.4813s	
19465/33650 (epoch 28.923), train_loss = 0.73219108, grad/param norm = 1.4540e-01, time/batch = 16.8851s	
19466/33650 (epoch 28.924), train_loss = 0.90787190, grad/param norm = 1.5567e-01, time/batch = 18.3110s	
19467/33650 (epoch 28.926), train_loss = 0.84812650, grad/param norm = 1.8589e-01, time/batch = 18.6544s	
19468/33650 (epoch 28.927), train_loss = 0.88210402, grad/param norm = 1.5764e-01, time/batch = 16.3578s	
19469/33650 (epoch 28.929), train_loss = 0.96964738, grad/param norm = 1.7350e-01, time/batch = 17.3977s	
19470/33650 (epoch 28.930), train_loss = 0.87109063, grad/param norm = 1.5558e-01, time/batch = 17.9830s	
19471/33650 (epoch 28.932), train_loss = 0.86233606, grad/param norm = 1.4153e-01, time/batch = 17.2298s	
19472/33650 (epoch 28.933), train_loss = 0.78164264, grad/param norm = 1.5961e-01, time/batch = 17.9843s	
19473/33650 (epoch 28.935), train_loss = 0.78177333, grad/param norm = 1.5545e-01, time/batch = 18.7202s	
19474/33650 (epoch 28.936), train_loss = 0.83448450, grad/param norm = 1.4502e-01, time/batch = 18.1441s	
19475/33650 (epoch 28.938), train_loss = 0.77882610, grad/param norm = 1.6431e-01, time/batch = 17.5304s	
19476/33650 (epoch 28.939), train_loss = 0.97016915, grad/param norm = 1.5019e-01, time/batch = 17.8032s	
19477/33650 (epoch 28.941), train_loss = 0.89387587, grad/param norm = 1.5671e-01, time/batch = 18.4138s	
19478/33650 (epoch 28.942), train_loss = 0.96187233, grad/param norm = 1.6510e-01, time/batch = 17.8842s	
19479/33650 (epoch 28.944), train_loss = 0.85537629, grad/param norm = 1.5601e-01, time/batch = 18.2079s	
19480/33650 (epoch 28.945), train_loss = 0.90686770, grad/param norm = 1.5206e-01, time/batch = 18.0608s	
19481/33650 (epoch 28.947), train_loss = 1.03021519, grad/param norm = 1.9119e-01, time/batch = 16.6340s	
19482/33650 (epoch 28.948), train_loss = 1.01528519, grad/param norm = 1.6687e-01, time/batch = 18.6420s	
19483/33650 (epoch 28.949), train_loss = 0.76576379, grad/param norm = 1.3465e-01, time/batch = 17.7223s	
19484/33650 (epoch 28.951), train_loss = 1.01978190, grad/param norm = 1.5530e-01, time/batch = 20.5974s	
19485/33650 (epoch 28.952), train_loss = 0.94123657, grad/param norm = 1.6714e-01, time/batch = 28.2781s	
19486/33650 (epoch 28.954), train_loss = 0.95538646, grad/param norm = 1.5013e-01, time/batch = 18.6427s	
19487/33650 (epoch 28.955), train_loss = 0.93303389, grad/param norm = 1.5618e-01, time/batch = 17.3867s	
19488/33650 (epoch 28.957), train_loss = 0.95163730, grad/param norm = 1.7528e-01, time/batch = 18.1415s	
19489/33650 (epoch 28.958), train_loss = 0.71742730, grad/param norm = 1.3961e-01, time/batch = 17.0367s	
19490/33650 (epoch 28.960), train_loss = 0.73721842, grad/param norm = 1.4358e-01, time/batch = 17.7232s	
19491/33650 (epoch 28.961), train_loss = 0.78360545, grad/param norm = 1.4041e-01, time/batch = 17.9829s	
19492/33650 (epoch 28.963), train_loss = 0.82930605, grad/param norm = 1.6420e-01, time/batch = 18.1256s	
19493/33650 (epoch 28.964), train_loss = 0.96859500, grad/param norm = 1.5999e-01, time/batch = 18.1537s	
19494/33650 (epoch 28.966), train_loss = 0.91610949, grad/param norm = 1.6595e-01, time/batch = 17.4782s	
19495/33650 (epoch 28.967), train_loss = 0.92192071, grad/param norm = 1.5374e-01, time/batch = 18.1452s	
19496/33650 (epoch 28.969), train_loss = 0.89145235, grad/param norm = 1.4403e-01, time/batch = 16.3695s	
19497/33650 (epoch 28.970), train_loss = 0.90573628, grad/param norm = 1.6410e-01, time/batch = 16.3729s	
19498/33650 (epoch 28.972), train_loss = 1.17297631, grad/param norm = 1.6626e-01, time/batch = 18.6357s	
19499/33650 (epoch 28.973), train_loss = 0.81026036, grad/param norm = 1.3316e-01, time/batch = 18.2356s	
19500/33650 (epoch 28.975), train_loss = 0.80169820, grad/param norm = 1.4320e-01, time/batch = 18.0559s	
19501/33650 (epoch 28.976), train_loss = 0.81587425, grad/param norm = 1.3001e-01, time/batch = 17.2997s	
19502/33650 (epoch 28.978), train_loss = 0.82929969, grad/param norm = 1.4466e-01, time/batch = 17.9812s	
19503/33650 (epoch 28.979), train_loss = 0.86181422, grad/param norm = 1.5020e-01, time/batch = 18.6359s	
19504/33650 (epoch 28.981), train_loss = 0.84322805, grad/param norm = 1.2802e-01, time/batch = 17.2208s	
19505/33650 (epoch 28.982), train_loss = 0.90825739, grad/param norm = 1.5170e-01, time/batch = 18.9046s	
19506/33650 (epoch 28.984), train_loss = 0.74078051, grad/param norm = 1.4561e-01, time/batch = 18.4779s	
19507/33650 (epoch 28.985), train_loss = 0.78869541, grad/param norm = 1.5339e-01, time/batch = 16.4005s	
19508/33650 (epoch 28.987), train_loss = 0.89184635, grad/param norm = 1.4409e-01, time/batch = 17.8930s	
19509/33650 (epoch 28.988), train_loss = 0.85560181, grad/param norm = 1.5990e-01, time/batch = 18.3833s	
19510/33650 (epoch 28.990), train_loss = 1.04570314, grad/param norm = 1.8177e-01, time/batch = 17.0300s	
19511/33650 (epoch 28.991), train_loss = 0.91373545, grad/param norm = 1.6833e-01, time/batch = 14.6750s	
19512/33650 (epoch 28.993), train_loss = 0.90480051, grad/param norm = 1.6266e-01, time/batch = 15.6185s	
19513/33650 (epoch 28.994), train_loss = 0.88010730, grad/param norm = 1.4134e-01, time/batch = 17.8869s	
19514/33650 (epoch 28.996), train_loss = 0.85631388, grad/param norm = 1.7646e-01, time/batch = 16.3127s	
19515/33650 (epoch 28.997), train_loss = 0.96216565, grad/param norm = 1.6954e-01, time/batch = 18.2304s	
19516/33650 (epoch 28.999), train_loss = 0.80913162, grad/param norm = 1.5530e-01, time/batch = 17.4855s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
19517/33650 (epoch 29.000), train_loss = 0.95764870, grad/param norm = 1.8171e-01, time/batch = 17.8841s	
19518/33650 (epoch 29.001), train_loss = 1.02512552, grad/param norm = 1.6171e-01, time/batch = 17.4643s	
19519/33650 (epoch 29.003), train_loss = 1.03038404, grad/param norm = 2.0367e-01, time/batch = 17.7302s	
19520/33650 (epoch 29.004), train_loss = 0.94379598, grad/param norm = 1.6283e-01, time/batch = 18.9024s	
19521/33650 (epoch 29.006), train_loss = 0.87502925, grad/param norm = 1.5435e-01, time/batch = 16.4675s	
19522/33650 (epoch 29.007), train_loss = 0.96220289, grad/param norm = 1.8035e-01, time/batch = 15.9633s	
19523/33650 (epoch 29.009), train_loss = 0.84541316, grad/param norm = 1.4986e-01, time/batch = 18.3148s	
19524/33650 (epoch 29.010), train_loss = 0.99412744, grad/param norm = 1.7665e-01, time/batch = 17.6412s	
19525/33650 (epoch 29.012), train_loss = 0.84305233, grad/param norm = 1.4760e-01, time/batch = 18.2133s	
19526/33650 (epoch 29.013), train_loss = 0.89269590, grad/param norm = 1.7844e-01, time/batch = 16.7156s	
19527/33650 (epoch 29.015), train_loss = 0.87090517, grad/param norm = 1.5117e-01, time/batch = 18.3140s	
19528/33650 (epoch 29.016), train_loss = 0.80567658, grad/param norm = 1.6658e-01, time/batch = 16.9478s	
19529/33650 (epoch 29.018), train_loss = 0.88238410, grad/param norm = 1.8117e-01, time/batch = 17.8872s	
19530/33650 (epoch 29.019), train_loss = 0.85156165, grad/param norm = 1.6281e-01, time/batch = 16.9829s	
19531/33650 (epoch 29.021), train_loss = 0.94372307, grad/param norm = 1.5546e-01, time/batch = 17.5591s	
19532/33650 (epoch 29.022), train_loss = 0.85949196, grad/param norm = 1.5808e-01, time/batch = 17.4798s	
19533/33650 (epoch 29.024), train_loss = 0.81946175, grad/param norm = 1.5729e-01, time/batch = 18.5589s	
19534/33650 (epoch 29.025), train_loss = 0.89891319, grad/param norm = 1.5418e-01, time/batch = 17.8118s	
19535/33650 (epoch 29.027), train_loss = 0.91422423, grad/param norm = 1.5514e-01, time/batch = 17.4010s	
19536/33650 (epoch 29.028), train_loss = 0.95999503, grad/param norm = 1.6106e-01, time/batch = 18.4014s	
19537/33650 (epoch 29.030), train_loss = 0.89895776, grad/param norm = 1.8271e-01, time/batch = 18.2366s	
19538/33650 (epoch 29.031), train_loss = 0.81122000, grad/param norm = 1.3390e-01, time/batch = 17.1463s	
19539/33650 (epoch 29.033), train_loss = 0.88921297, grad/param norm = 1.3619e-01, time/batch = 17.8167s	
19540/33650 (epoch 29.034), train_loss = 0.92921815, grad/param norm = 1.7107e-01, time/batch = 18.3761s	
19541/33650 (epoch 29.036), train_loss = 1.00950565, grad/param norm = 1.7442e-01, time/batch = 18.0554s	
19542/33650 (epoch 29.037), train_loss = 0.84995070, grad/param norm = 1.4342e-01, time/batch = 17.7195s	
19543/33650 (epoch 29.039), train_loss = 0.97437098, grad/param norm = 1.5391e-01, time/batch = 18.3170s	
19544/33650 (epoch 29.040), train_loss = 1.07735959, grad/param norm = 2.1507e-01, time/batch = 17.2319s	
19545/33650 (epoch 29.042), train_loss = 1.09126197, grad/param norm = 1.8982e-01, time/batch = 17.3015s	
19546/33650 (epoch 29.043), train_loss = 0.86050296, grad/param norm = 1.4663e-01, time/batch = 17.9686s	
19547/33650 (epoch 29.045), train_loss = 0.85468914, grad/param norm = 1.5387e-01, time/batch = 16.7064s	
19548/33650 (epoch 29.046), train_loss = 0.96223361, grad/param norm = 1.7375e-01, time/batch = 16.9703s	
19549/33650 (epoch 29.048), train_loss = 0.97341666, grad/param norm = 1.5291e-01, time/batch = 17.7295s	
19550/33650 (epoch 29.049), train_loss = 0.88841705, grad/param norm = 1.5893e-01, time/batch = 17.1517s	
19551/33650 (epoch 29.051), train_loss = 1.04856350, grad/param norm = 1.5619e-01, time/batch = 16.9464s	
19552/33650 (epoch 29.052), train_loss = 1.03444849, grad/param norm = 1.6967e-01, time/batch = 17.6524s	
19553/33650 (epoch 29.053), train_loss = 0.97286969, grad/param norm = 1.5016e-01, time/batch = 18.8960s	
19554/33650 (epoch 29.055), train_loss = 0.81439930, grad/param norm = 1.4137e-01, time/batch = 17.6563s	
19555/33650 (epoch 29.056), train_loss = 0.79703288, grad/param norm = 1.2370e-01, time/batch = 18.3766s	
19556/33650 (epoch 29.058), train_loss = 0.97107245, grad/param norm = 1.7905e-01, time/batch = 18.6431s	
19557/33650 (epoch 29.059), train_loss = 0.95819462, grad/param norm = 1.5851e-01, time/batch = 18.3159s	
19558/33650 (epoch 29.061), train_loss = 0.98778964, grad/param norm = 1.5094e-01, time/batch = 15.7111s	
19559/33650 (epoch 29.062), train_loss = 0.94874732, grad/param norm = 1.5038e-01, time/batch = 16.7305s	
19560/33650 (epoch 29.064), train_loss = 0.89498819, grad/param norm = 1.6435e-01, time/batch = 17.3875s	
19561/33650 (epoch 29.065), train_loss = 0.86944226, grad/param norm = 1.5457e-01, time/batch = 17.8887s	
19562/33650 (epoch 29.067), train_loss = 0.80849344, grad/param norm = 1.3130e-01, time/batch = 17.1519s	
19563/33650 (epoch 29.068), train_loss = 0.90629523, grad/param norm = 1.5539e-01, time/batch = 18.2346s	
19564/33650 (epoch 29.070), train_loss = 0.97118601, grad/param norm = 1.5279e-01, time/batch = 17.0350s	
19565/33650 (epoch 29.071), train_loss = 0.85669880, grad/param norm = 1.4309e-01, time/batch = 17.2271s	
19566/33650 (epoch 29.073), train_loss = 0.96334938, grad/param norm = 1.7417e-01, time/batch = 18.1540s	
19567/33650 (epoch 29.074), train_loss = 1.02748003, grad/param norm = 1.5625e-01, time/batch = 18.6431s	
19568/33650 (epoch 29.076), train_loss = 0.98183166, grad/param norm = 1.6446e-01, time/batch = 17.2262s	
19569/33650 (epoch 29.077), train_loss = 0.89510970, grad/param norm = 1.5070e-01, time/batch = 17.6525s	
19570/33650 (epoch 29.079), train_loss = 0.95832862, grad/param norm = 1.4872e-01, time/batch = 17.8167s	
19571/33650 (epoch 29.080), train_loss = 0.94362023, grad/param norm = 1.4411e-01, time/batch = 17.9829s	
19572/33650 (epoch 29.082), train_loss = 0.92688375, grad/param norm = 1.5550e-01, time/batch = 18.3886s	
19573/33650 (epoch 29.083), train_loss = 0.93715873, grad/param norm = 1.6574e-01, time/batch = 17.4794s	
19574/33650 (epoch 29.085), train_loss = 1.00609191, grad/param norm = 1.5100e-01, time/batch = 17.9907s	
19575/33650 (epoch 29.086), train_loss = 0.97018172, grad/param norm = 1.7995e-01, time/batch = 15.5363s	
19576/33650 (epoch 29.088), train_loss = 0.90657458, grad/param norm = 1.5950e-01, time/batch = 17.8896s	
19577/33650 (epoch 29.089), train_loss = 0.86296034, grad/param norm = 1.5749e-01, time/batch = 18.7277s	
19578/33650 (epoch 29.091), train_loss = 0.88365124, grad/param norm = 1.3875e-01, time/batch = 17.3919s	
19579/33650 (epoch 29.092), train_loss = 0.91025617, grad/param norm = 1.7563e-01, time/batch = 17.6489s	
19580/33650 (epoch 29.094), train_loss = 0.98474024, grad/param norm = 1.4135e-01, time/batch = 18.6473s	
19581/33650 (epoch 29.095), train_loss = 0.95548216, grad/param norm = 1.7059e-01, time/batch = 17.0357s	
19582/33650 (epoch 29.097), train_loss = 0.85770703, grad/param norm = 1.7642e-01, time/batch = 17.7273s	
19583/33650 (epoch 29.098), train_loss = 0.73233611, grad/param norm = 1.3933e-01, time/batch = 17.7287s	
19584/33650 (epoch 29.100), train_loss = 0.82329385, grad/param norm = 1.4348e-01, time/batch = 17.6580s	
19585/33650 (epoch 29.101), train_loss = 0.90469493, grad/param norm = 1.6706e-01, time/batch = 16.1305s	
19586/33650 (epoch 29.103), train_loss = 0.91955446, grad/param norm = 1.9711e-01, time/batch = 17.0571s	
19587/33650 (epoch 29.104), train_loss = 1.02517973, grad/param norm = 1.6050e-01, time/batch = 17.3068s	
19588/33650 (epoch 29.105), train_loss = 0.93276190, grad/param norm = 1.7269e-01, time/batch = 17.6466s	
19589/33650 (epoch 29.107), train_loss = 0.87494765, grad/param norm = 1.5590e-01, time/batch = 18.1475s	
19590/33650 (epoch 29.108), train_loss = 0.96638435, grad/param norm = 1.7195e-01, time/batch = 18.3989s	
19591/33650 (epoch 29.110), train_loss = 1.05840733, grad/param norm = 1.6129e-01, time/batch = 18.4020s	
19592/33650 (epoch 29.111), train_loss = 0.88587446, grad/param norm = 1.6640e-01, time/batch = 17.0462s	
19593/33650 (epoch 29.113), train_loss = 0.86745511, grad/param norm = 1.6001e-01, time/batch = 17.8063s	
19594/33650 (epoch 29.114), train_loss = 0.97177045, grad/param norm = 1.5289e-01, time/batch = 18.8147s	
19595/33650 (epoch 29.116), train_loss = 0.84017820, grad/param norm = 1.3947e-01, time/batch = 16.9800s	
19596/33650 (epoch 29.117), train_loss = 0.89094361, grad/param norm = 1.3844e-01, time/batch = 18.8102s	
19597/33650 (epoch 29.119), train_loss = 0.82354248, grad/param norm = 1.4426e-01, time/batch = 18.5579s	
19598/33650 (epoch 29.120), train_loss = 0.85864930, grad/param norm = 1.5429e-01, time/batch = 17.5388s	
19599/33650 (epoch 29.122), train_loss = 0.71863551, grad/param norm = 1.6938e-01, time/batch = 17.4831s	
19600/33650 (epoch 29.123), train_loss = 0.86587253, grad/param norm = 1.5326e-01, time/batch = 17.9881s	
19601/33650 (epoch 29.125), train_loss = 0.94202963, grad/param norm = 1.6009e-01, time/batch = 18.0562s	
19602/33650 (epoch 29.126), train_loss = 1.00278502, grad/param norm = 2.1454e-01, time/batch = 17.3858s	
19603/33650 (epoch 29.128), train_loss = 0.97217881, grad/param norm = 1.7813e-01, time/batch = 17.8882s	
19604/33650 (epoch 29.129), train_loss = 0.99562288, grad/param norm = 1.6657e-01, time/batch = 18.7255s	
19605/33650 (epoch 29.131), train_loss = 0.93224695, grad/param norm = 1.7231e-01, time/batch = 16.9776s	
19606/33650 (epoch 29.132), train_loss = 0.90865814, grad/param norm = 1.4813e-01, time/batch = 18.0643s	
19607/33650 (epoch 29.134), train_loss = 0.98596447, grad/param norm = 1.8587e-01, time/batch = 18.5676s	
19608/33650 (epoch 29.135), train_loss = 0.81073547, grad/param norm = 1.5553e-01, time/batch = 18.1408s	
19609/33650 (epoch 29.137), train_loss = 0.95366654, grad/param norm = 1.6302e-01, time/batch = 17.1376s	
19610/33650 (epoch 29.138), train_loss = 0.98086933, grad/param norm = 1.5479e-01, time/batch = 16.5303s	
19611/33650 (epoch 29.140), train_loss = 0.92217898, grad/param norm = 1.9362e-01, time/batch = 19.1422s	
19612/33650 (epoch 29.141), train_loss = 1.05628565, grad/param norm = 1.6588e-01, time/batch = 17.3968s	
19613/33650 (epoch 29.143), train_loss = 1.05774617, grad/param norm = 2.1952e-01, time/batch = 17.4789s	
19614/33650 (epoch 29.144), train_loss = 0.95510522, grad/param norm = 1.8066e-01, time/batch = 13.8121s	
19615/33650 (epoch 29.146), train_loss = 0.91784477, grad/param norm = 1.7346e-01, time/batch = 13.9110s	
19616/33650 (epoch 29.147), train_loss = 0.86069757, grad/param norm = 1.5659e-01, time/batch = 14.2345s	
19617/33650 (epoch 29.149), train_loss = 0.82471774, grad/param norm = 1.6576e-01, time/batch = 18.1390s	
19618/33650 (epoch 29.150), train_loss = 0.79675486, grad/param norm = 1.5820e-01, time/batch = 17.8974s	
19619/33650 (epoch 29.152), train_loss = 0.85978396, grad/param norm = 1.5173e-01, time/batch = 17.4691s	
19620/33650 (epoch 29.153), train_loss = 0.87708701, grad/param norm = 1.5412e-01, time/batch = 16.5466s	
19621/33650 (epoch 29.155), train_loss = 0.83029676, grad/param norm = 1.3457e-01, time/batch = 17.8910s	
19622/33650 (epoch 29.156), train_loss = 0.82743075, grad/param norm = 1.3172e-01, time/batch = 17.3803s	
19623/33650 (epoch 29.158), train_loss = 0.93148008, grad/param norm = 1.6226e-01, time/batch = 17.5455s	
19624/33650 (epoch 29.159), train_loss = 0.82650312, grad/param norm = 1.3139e-01, time/batch = 18.7315s	
19625/33650 (epoch 29.160), train_loss = 0.84626553, grad/param norm = 1.3258e-01, time/batch = 17.9866s	
19626/33650 (epoch 29.162), train_loss = 0.87315442, grad/param norm = 1.8500e-01, time/batch = 17.2954s	
19627/33650 (epoch 29.163), train_loss = 0.94441635, grad/param norm = 1.8840e-01, time/batch = 18.1433s	
19628/33650 (epoch 29.165), train_loss = 0.80779410, grad/param norm = 1.4928e-01, time/batch = 18.9690s	
19629/33650 (epoch 29.166), train_loss = 0.79992224, grad/param norm = 1.8476e-01, time/batch = 16.8170s	
19630/33650 (epoch 29.168), train_loss = 1.00968411, grad/param norm = 1.7534e-01, time/batch = 18.1489s	
19631/33650 (epoch 29.169), train_loss = 0.92911014, grad/param norm = 1.6173e-01, time/batch = 18.2291s	
19632/33650 (epoch 29.171), train_loss = 0.89658617, grad/param norm = 1.4202e-01, time/batch = 18.3993s	
19633/33650 (epoch 29.172), train_loss = 0.86687543, grad/param norm = 1.6185e-01, time/batch = 16.3718s	
19634/33650 (epoch 29.174), train_loss = 0.82254275, grad/param norm = 1.5873e-01, time/batch = 18.3040s	
19635/33650 (epoch 29.175), train_loss = 0.80405790, grad/param norm = 1.6859e-01, time/batch = 18.8957s	
19636/33650 (epoch 29.177), train_loss = 0.91075484, grad/param norm = 1.7270e-01, time/batch = 16.4758s	
19637/33650 (epoch 29.178), train_loss = 0.86140798, grad/param norm = 1.6999e-01, time/batch = 17.9715s	
19638/33650 (epoch 29.180), train_loss = 0.80725645, grad/param norm = 1.5178e-01, time/batch = 18.4010s	
19639/33650 (epoch 29.181), train_loss = 0.72717785, grad/param norm = 1.3208e-01, time/batch = 18.2270s	
19640/33650 (epoch 29.183), train_loss = 0.83578233, grad/param norm = 1.6366e-01, time/batch = 18.1435s	
19641/33650 (epoch 29.184), train_loss = 0.83109620, grad/param norm = 1.8274e-01, time/batch = 17.8233s	
19642/33650 (epoch 29.186), train_loss = 0.86814947, grad/param norm = 1.6240e-01, time/batch = 16.5303s	
19643/33650 (epoch 29.187), train_loss = 1.01493378, grad/param norm = 1.6653e-01, time/batch = 17.7259s	
19644/33650 (epoch 29.189), train_loss = 1.00607728, grad/param norm = 2.0770e-01, time/batch = 17.1434s	
19645/33650 (epoch 29.190), train_loss = 0.92676713, grad/param norm = 1.8569e-01, time/batch = 17.4769s	
19646/33650 (epoch 29.192), train_loss = 1.07475035, grad/param norm = 1.6350e-01, time/batch = 17.3168s	
19647/33650 (epoch 29.193), train_loss = 1.03323846, grad/param norm = 1.8617e-01, time/batch = 18.3956s	
19648/33650 (epoch 29.195), train_loss = 0.78797027, grad/param norm = 1.4488e-01, time/batch = 18.3082s	
19649/33650 (epoch 29.196), train_loss = 0.75470755, grad/param norm = 1.6268e-01, time/batch = 16.8131s	
19650/33650 (epoch 29.198), train_loss = 0.86988966, grad/param norm = 1.4902e-01, time/batch = 17.8091s	
19651/33650 (epoch 29.199), train_loss = 0.97121714, grad/param norm = 1.6891e-01, time/batch = 18.0680s	
19652/33650 (epoch 29.201), train_loss = 0.85968652, grad/param norm = 1.6962e-01, time/batch = 17.4797s	
19653/33650 (epoch 29.202), train_loss = 0.88338978, grad/param norm = 1.6092e-01, time/batch = 16.9629s	
19654/33650 (epoch 29.204), train_loss = 0.92948856, grad/param norm = 1.6329e-01, time/batch = 18.1447s	
19655/33650 (epoch 29.205), train_loss = 0.88810440, grad/param norm = 1.9342e-01, time/batch = 17.1640s	
19656/33650 (epoch 29.207), train_loss = 0.81913076, grad/param norm = 1.6380e-01, time/batch = 16.8826s	
19657/33650 (epoch 29.208), train_loss = 0.92196800, grad/param norm = 1.5547e-01, time/batch = 18.2220s	
19658/33650 (epoch 29.210), train_loss = 0.73851902, grad/param norm = 1.4854e-01, time/batch = 17.3918s	
19659/33650 (epoch 29.211), train_loss = 0.84249723, grad/param norm = 1.7965e-01, time/batch = 18.8998s	
19660/33650 (epoch 29.212), train_loss = 0.94374694, grad/param norm = 1.7616e-01, time/batch = 18.1277s	
19661/33650 (epoch 29.214), train_loss = 1.05633326, grad/param norm = 1.6338e-01, time/batch = 18.1472s	
19662/33650 (epoch 29.215), train_loss = 0.69297283, grad/param norm = 1.5393e-01, time/batch = 18.4112s	
19663/33650 (epoch 29.217), train_loss = 0.88677101, grad/param norm = 2.0893e-01, time/batch = 16.9730s	
19664/33650 (epoch 29.218), train_loss = 0.88977931, grad/param norm = 1.4845e-01, time/batch = 17.3176s	
19665/33650 (epoch 29.220), train_loss = 0.78893344, grad/param norm = 1.6601e-01, time/batch = 17.4738s	
19666/33650 (epoch 29.221), train_loss = 1.06438521, grad/param norm = 1.9011e-01, time/batch = 17.1512s	
19667/33650 (epoch 29.223), train_loss = 0.73094120, grad/param norm = 1.5601e-01, time/batch = 15.7964s	
19668/33650 (epoch 29.224), train_loss = 0.84258359, grad/param norm = 1.8661e-01, time/batch = 18.7235s	
19669/33650 (epoch 29.226), train_loss = 1.15627126, grad/param norm = 1.5976e-01, time/batch = 18.8160s	
19670/33650 (epoch 29.227), train_loss = 1.01853673, grad/param norm = 1.8159e-01, time/batch = 16.1237s	
19671/33650 (epoch 29.229), train_loss = 1.00431499, grad/param norm = 1.6809e-01, time/batch = 18.3146s	
19672/33650 (epoch 29.230), train_loss = 1.11787605, grad/param norm = 1.8843e-01, time/batch = 17.3056s	
19673/33650 (epoch 29.232), train_loss = 0.98873904, grad/param norm = 1.9136e-01, time/batch = 17.3829s	
19674/33650 (epoch 29.233), train_loss = 0.97552187, grad/param norm = 2.1584e-01, time/batch = 17.5615s	
19675/33650 (epoch 29.235), train_loss = 0.90352495, grad/param norm = 1.5967e-01, time/batch = 17.9090s	
19676/33650 (epoch 29.236), train_loss = 0.83284139, grad/param norm = 1.4641e-01, time/batch = 17.9781s	
19677/33650 (epoch 29.238), train_loss = 0.85985682, grad/param norm = 1.4552e-01, time/batch = 16.9797s	
19678/33650 (epoch 29.239), train_loss = 0.82100590, grad/param norm = 1.6363e-01, time/batch = 16.8772s	
19679/33650 (epoch 29.241), train_loss = 0.87564458, grad/param norm = 1.4022e-01, time/batch = 18.3997s	
19680/33650 (epoch 29.242), train_loss = 0.72675826, grad/param norm = 1.6071e-01, time/batch = 17.2320s	
19681/33650 (epoch 29.244), train_loss = 0.87335844, grad/param norm = 1.4703e-01, time/batch = 18.0565s	
19682/33650 (epoch 29.245), train_loss = 0.77618444, grad/param norm = 1.3822e-01, time/batch = 18.1355s	
19683/33650 (epoch 29.247), train_loss = 0.86263828, grad/param norm = 1.4358e-01, time/batch = 16.7294s	
19684/33650 (epoch 29.248), train_loss = 0.80194575, grad/param norm = 1.4909e-01, time/batch = 18.4936s	
19685/33650 (epoch 29.250), train_loss = 0.87997031, grad/param norm = 1.4534e-01, time/batch = 18.3074s	
19686/33650 (epoch 29.251), train_loss = 1.01084063, grad/param norm = 1.4987e-01, time/batch = 17.7994s	
19687/33650 (epoch 29.253), train_loss = 0.79059456, grad/param norm = 1.5798e-01, time/batch = 31.2244s	
19688/33650 (epoch 29.254), train_loss = 0.84265444, grad/param norm = 1.5173e-01, time/batch = 18.4049s	
19689/33650 (epoch 29.256), train_loss = 1.02306107, grad/param norm = 1.5019e-01, time/batch = 16.2130s	
19690/33650 (epoch 29.257), train_loss = 0.99339029, grad/param norm = 1.6176e-01, time/batch = 17.3080s	
19691/33650 (epoch 29.259), train_loss = 0.78968372, grad/param norm = 1.6470e-01, time/batch = 17.9670s	
19692/33650 (epoch 29.260), train_loss = 0.94938127, grad/param norm = 1.6010e-01, time/batch = 18.4714s	
19693/33650 (epoch 29.262), train_loss = 0.91217413, grad/param norm = 1.7807e-01, time/batch = 17.4694s	
19694/33650 (epoch 29.263), train_loss = 0.86277732, grad/param norm = 2.0320e-01, time/batch = 17.8151s	
19695/33650 (epoch 29.264), train_loss = 0.93707543, grad/param norm = 1.7263e-01, time/batch = 18.3140s	
19696/33650 (epoch 29.266), train_loss = 0.93796430, grad/param norm = 1.5414e-01, time/batch = 17.4815s	
19697/33650 (epoch 29.267), train_loss = 0.85585385, grad/param norm = 1.5931e-01, time/batch = 18.3995s	
19698/33650 (epoch 29.269), train_loss = 0.90741351, grad/param norm = 1.7446e-01, time/batch = 17.2916s	
19699/33650 (epoch 29.270), train_loss = 0.80274421, grad/param norm = 1.3403e-01, time/batch = 16.1373s	
19700/33650 (epoch 29.272), train_loss = 0.87682826, grad/param norm = 1.4970e-01, time/batch = 18.1369s	
19701/33650 (epoch 29.273), train_loss = 1.01040740, grad/param norm = 1.8923e-01, time/batch = 18.5681s	
19702/33650 (epoch 29.275), train_loss = 0.95570746, grad/param norm = 1.6996e-01, time/batch = 18.5557s	
19703/33650 (epoch 29.276), train_loss = 0.99184431, grad/param norm = 1.8041e-01, time/batch = 17.6290s	
19704/33650 (epoch 29.278), train_loss = 1.06815920, grad/param norm = 2.1151e-01, time/batch = 18.0596s	
19705/33650 (epoch 29.279), train_loss = 0.86779445, grad/param norm = 1.4825e-01, time/batch = 18.4847s	
19706/33650 (epoch 29.281), train_loss = 0.92394863, grad/param norm = 1.7143e-01, time/batch = 17.0529s	
19707/33650 (epoch 29.282), train_loss = 1.01462994, grad/param norm = 1.5376e-01, time/batch = 17.9713s	
19708/33650 (epoch 29.284), train_loss = 0.97288920, grad/param norm = 1.6376e-01, time/batch = 18.2352s	
19709/33650 (epoch 29.285), train_loss = 0.95241846, grad/param norm = 1.6267e-01, time/batch = 17.3062s	
19710/33650 (epoch 29.287), train_loss = 0.86178568, grad/param norm = 1.6601e-01, time/batch = 17.1455s	
19711/33650 (epoch 29.288), train_loss = 0.90820200, grad/param norm = 1.6445e-01, time/batch = 15.7207s	
19712/33650 (epoch 29.290), train_loss = 0.90944988, grad/param norm = 1.4955e-01, time/batch = 18.7305s	
19713/33650 (epoch 29.291), train_loss = 0.81217976, grad/param norm = 1.3746e-01, time/batch = 15.5410s	
19714/33650 (epoch 29.293), train_loss = 0.90242877, grad/param norm = 1.8286e-01, time/batch = 19.0497s	
19715/33650 (epoch 29.294), train_loss = 0.81802875, grad/param norm = 1.5043e-01, time/batch = 18.0800s	
19716/33650 (epoch 29.296), train_loss = 0.81826827, grad/param norm = 1.4703e-01, time/batch = 17.8122s	
19717/33650 (epoch 29.297), train_loss = 0.87430141, grad/param norm = 1.4749e-01, time/batch = 17.5618s	
19718/33650 (epoch 29.299), train_loss = 0.78166550, grad/param norm = 1.8601e-01, time/batch = 18.3173s	
19719/33650 (epoch 29.300), train_loss = 0.80949614, grad/param norm = 1.8548e-01, time/batch = 18.3906s	
19720/33650 (epoch 29.302), train_loss = 0.91379967, grad/param norm = 1.4118e-01, time/batch = 17.1351s	
19721/33650 (epoch 29.303), train_loss = 0.92812883, grad/param norm = 1.5937e-01, time/batch = 18.4778s	
19722/33650 (epoch 29.305), train_loss = 0.89741571, grad/param norm = 1.5885e-01, time/batch = 17.3935s	
19723/33650 (epoch 29.306), train_loss = 0.82612942, grad/param norm = 1.3711e-01, time/batch = 16.8104s	
19724/33650 (epoch 29.308), train_loss = 0.79891946, grad/param norm = 1.7201e-01, time/batch = 16.3014s	
19725/33650 (epoch 29.309), train_loss = 1.03633681, grad/param norm = 1.7750e-01, time/batch = 18.3928s	
19726/33650 (epoch 29.311), train_loss = 0.89365957, grad/param norm = 1.8615e-01, time/batch = 17.5551s	
19727/33650 (epoch 29.312), train_loss = 0.94557821, grad/param norm = 1.8794e-01, time/batch = 18.0616s	
19728/33650 (epoch 29.314), train_loss = 0.81232304, grad/param norm = 1.4243e-01, time/batch = 18.2148s	
19729/33650 (epoch 29.315), train_loss = 0.86851916, grad/param norm = 1.7960e-01, time/batch = 17.1365s	
19730/33650 (epoch 29.316), train_loss = 0.85672170, grad/param norm = 1.7663e-01, time/batch = 17.3874s	
19731/33650 (epoch 29.318), train_loss = 0.79934136, grad/param norm = 1.4083e-01, time/batch = 17.7188s	
19732/33650 (epoch 29.319), train_loss = 0.83614992, grad/param norm = 1.4843e-01, time/batch = 16.7419s	
19733/33650 (epoch 29.321), train_loss = 0.86016310, grad/param norm = 1.3768e-01, time/batch = 17.1430s	
19734/33650 (epoch 29.322), train_loss = 0.93347806, grad/param norm = 1.8930e-01, time/batch = 18.4714s	
19735/33650 (epoch 29.324), train_loss = 0.95284747, grad/param norm = 1.9104e-01, time/batch = 18.6420s	
19736/33650 (epoch 29.325), train_loss = 0.93405568, grad/param norm = 1.6297e-01, time/batch = 17.9682s	
19737/33650 (epoch 29.327), train_loss = 0.83467822, grad/param norm = 1.3430e-01, time/batch = 17.2346s	
19738/33650 (epoch 29.328), train_loss = 0.91572267, grad/param norm = 1.7943e-01, time/batch = 19.0631s	
19739/33650 (epoch 29.330), train_loss = 0.83947226, grad/param norm = 1.4039e-01, time/batch = 18.1536s	
19740/33650 (epoch 29.331), train_loss = 0.77627594, grad/param norm = 1.3680e-01, time/batch = 15.5392s	
19741/33650 (epoch 29.333), train_loss = 0.87447377, grad/param norm = 1.5654e-01, time/batch = 18.0662s	
19742/33650 (epoch 29.334), train_loss = 0.90421108, grad/param norm = 1.8733e-01, time/batch = 17.2912s	
19743/33650 (epoch 29.336), train_loss = 0.97735759, grad/param norm = 1.5560e-01, time/batch = 17.4709s	
19744/33650 (epoch 29.337), train_loss = 0.75041932, grad/param norm = 1.3679e-01, time/batch = 17.2905s	
19745/33650 (epoch 29.339), train_loss = 0.85295018, grad/param norm = 1.4200e-01, time/batch = 18.7167s	
19746/33650 (epoch 29.340), train_loss = 1.00859808, grad/param norm = 1.7043e-01, time/batch = 17.9808s	
19747/33650 (epoch 29.342), train_loss = 0.74358375, grad/param norm = 1.5482e-01, time/batch = 17.5488s	
19748/33650 (epoch 29.343), train_loss = 0.93968700, grad/param norm = 1.5349e-01, time/batch = 17.3213s	
19749/33650 (epoch 29.345), train_loss = 0.90034019, grad/param norm = 1.9730e-01, time/batch = 17.9917s	
19750/33650 (epoch 29.346), train_loss = 0.62272412, grad/param norm = 1.3705e-01, time/batch = 17.5396s	
19751/33650 (epoch 29.348), train_loss = 0.77752390, grad/param norm = 1.4982e-01, time/batch = 18.0706s	
19752/33650 (epoch 29.349), train_loss = 0.74882726, grad/param norm = 1.5705e-01, time/batch = 18.4768s	
19753/33650 (epoch 29.351), train_loss = 0.94606258, grad/param norm = 1.6118e-01, time/batch = 17.0408s	
19754/33650 (epoch 29.352), train_loss = 0.86479145, grad/param norm = 1.5512e-01, time/batch = 17.8130s	
19755/33650 (epoch 29.354), train_loss = 1.02304486, grad/param norm = 2.4380e-01, time/batch = 17.6970s	
19756/33650 (epoch 29.355), train_loss = 1.03239355, grad/param norm = 1.5768e-01, time/batch = 18.8842s	
19757/33650 (epoch 29.357), train_loss = 0.72333781, grad/param norm = 1.4388e-01, time/batch = 17.5563s	
19758/33650 (epoch 29.358), train_loss = 0.93582875, grad/param norm = 1.6345e-01, time/batch = 18.1429s	
19759/33650 (epoch 29.360), train_loss = 0.96428557, grad/param norm = 2.1725e-01, time/batch = 17.8150s	
19760/33650 (epoch 29.361), train_loss = 0.93058698, grad/param norm = 1.5549e-01, time/batch = 17.9672s	
19761/33650 (epoch 29.363), train_loss = 0.90979211, grad/param norm = 1.5583e-01, time/batch = 16.5291s	
19762/33650 (epoch 29.364), train_loss = 0.88917427, grad/param norm = 1.6320e-01, time/batch = 17.5679s	
19763/33650 (epoch 29.366), train_loss = 0.95300368, grad/param norm = 1.7893e-01, time/batch = 17.8796s	
19764/33650 (epoch 29.367), train_loss = 0.91880932, grad/param norm = 1.4725e-01, time/batch = 17.5490s	
19765/33650 (epoch 29.368), train_loss = 0.83039076, grad/param norm = 1.3295e-01, time/batch = 17.8946s	
19766/33650 (epoch 29.370), train_loss = 0.87862341, grad/param norm = 1.4792e-01, time/batch = 18.2294s	
19767/33650 (epoch 29.371), train_loss = 0.68245322, grad/param norm = 1.3170e-01, time/batch = 17.1486s	
19768/33650 (epoch 29.373), train_loss = 0.78011967, grad/param norm = 1.3467e-01, time/batch = 18.3160s	
19769/33650 (epoch 29.374), train_loss = 0.80217198, grad/param norm = 1.3311e-01, time/batch = 17.5764s	
19770/33650 (epoch 29.376), train_loss = 0.86839897, grad/param norm = 1.8282e-01, time/batch = 17.7970s	
19771/33650 (epoch 29.377), train_loss = 0.91013810, grad/param norm = 1.7681e-01, time/batch = 18.4700s	
19772/33650 (epoch 29.379), train_loss = 0.93005428, grad/param norm = 1.4845e-01, time/batch = 17.8900s	
19773/33650 (epoch 29.380), train_loss = 0.73996642, grad/param norm = 1.6228e-01, time/batch = 16.9741s	
19774/33650 (epoch 29.382), train_loss = 0.87647075, grad/param norm = 1.3349e-01, time/batch = 17.1389s	
19775/33650 (epoch 29.383), train_loss = 0.86797876, grad/param norm = 1.5691e-01, time/batch = 18.2257s	
19776/33650 (epoch 29.385), train_loss = 0.93515826, grad/param norm = 1.5603e-01, time/batch = 16.4661s	
19777/33650 (epoch 29.386), train_loss = 0.81892776, grad/param norm = 1.3979e-01, time/batch = 16.7995s	
19778/33650 (epoch 29.388), train_loss = 0.96930870, grad/param norm = 1.5457e-01, time/batch = 17.6453s	
19779/33650 (epoch 29.389), train_loss = 0.83683099, grad/param norm = 1.5684e-01, time/batch = 18.1528s	
19780/33650 (epoch 29.391), train_loss = 0.71389768, grad/param norm = 1.3637e-01, time/batch = 17.5743s	
19781/33650 (epoch 29.392), train_loss = 0.90921276, grad/param norm = 1.6500e-01, time/batch = 17.9829s	
19782/33650 (epoch 29.394), train_loss = 0.89941773, grad/param norm = 1.6817e-01, time/batch = 18.3948s	
19783/33650 (epoch 29.395), train_loss = 0.92270140, grad/param norm = 1.5066e-01, time/batch = 17.6530s	
19784/33650 (epoch 29.397), train_loss = 1.03081430, grad/param norm = 1.5753e-01, time/batch = 17.3074s	
19785/33650 (epoch 29.398), train_loss = 0.96165966, grad/param norm = 1.5504e-01, time/batch = 17.7387s	
19786/33650 (epoch 29.400), train_loss = 0.88965412, grad/param norm = 1.7345e-01, time/batch = 17.8986s	
19787/33650 (epoch 29.401), train_loss = 0.84292042, grad/param norm = 1.8579e-01, time/batch = 16.8966s	
19788/33650 (epoch 29.403), train_loss = 0.92397122, grad/param norm = 1.5708e-01, time/batch = 17.8151s	
19789/33650 (epoch 29.404), train_loss = 0.88234447, grad/param norm = 1.4415e-01, time/batch = 16.7934s	
19790/33650 (epoch 29.406), train_loss = 0.87300648, grad/param norm = 1.6539e-01, time/batch = 17.8136s	
19791/33650 (epoch 29.407), train_loss = 0.89182732, grad/param norm = 1.6837e-01, time/batch = 18.7367s	
19792/33650 (epoch 29.409), train_loss = 0.93334779, grad/param norm = 1.6418e-01, time/batch = 17.4738s	
19793/33650 (epoch 29.410), train_loss = 0.87396313, grad/param norm = 1.5495e-01, time/batch = 18.6401s	
19794/33650 (epoch 29.412), train_loss = 0.89217193, grad/param norm = 1.4067e-01, time/batch = 18.1312s	
19795/33650 (epoch 29.413), train_loss = 0.83052018, grad/param norm = 1.5689e-01, time/batch = 16.3875s	
19796/33650 (epoch 29.415), train_loss = 0.97127727, grad/param norm = 1.6916e-01, time/batch = 17.4856s	
19797/33650 (epoch 29.416), train_loss = 1.04807982, grad/param norm = 1.7757e-01, time/batch = 16.7372s	
19798/33650 (epoch 29.418), train_loss = 0.81105510, grad/param norm = 1.6170e-01, time/batch = 18.5687s	
19799/33650 (epoch 29.419), train_loss = 0.85071978, grad/param norm = 1.6393e-01, time/batch = 18.7413s	
19800/33650 (epoch 29.421), train_loss = 0.86380189, grad/param norm = 1.3821e-01, time/batch = 17.8083s	
19801/33650 (epoch 29.422), train_loss = 1.00700059, grad/param norm = 1.5422e-01, time/batch = 18.2283s	
19802/33650 (epoch 29.423), train_loss = 0.80942590, grad/param norm = 1.2254e-01, time/batch = 17.8111s	
19803/33650 (epoch 29.425), train_loss = 0.89418782, grad/param norm = 1.7938e-01, time/batch = 18.9014s	
19804/33650 (epoch 29.426), train_loss = 1.00297083, grad/param norm = 1.8750e-01, time/batch = 16.4593s	
19805/33650 (epoch 29.428), train_loss = 0.85701826, grad/param norm = 1.4870e-01, time/batch = 17.3862s	
19806/33650 (epoch 29.429), train_loss = 0.94766544, grad/param norm = 1.7781e-01, time/batch = 18.7201s	
19807/33650 (epoch 29.431), train_loss = 1.04795700, grad/param norm = 1.8277e-01, time/batch = 16.7396s	
19808/33650 (epoch 29.432), train_loss = 1.06829748, grad/param norm = 1.8386e-01, time/batch = 17.1364s	
19809/33650 (epoch 29.434), train_loss = 0.92496169, grad/param norm = 1.5312e-01, time/batch = 17.9794s	
19810/33650 (epoch 29.435), train_loss = 0.92612999, grad/param norm = 1.9179e-01, time/batch = 17.8951s	
19811/33650 (epoch 29.437), train_loss = 0.91113272, grad/param norm = 1.6063e-01, time/batch = 18.2186s	
19812/33650 (epoch 29.438), train_loss = 0.86834800, grad/param norm = 1.7333e-01, time/batch = 17.4800s	
19813/33650 (epoch 29.440), train_loss = 0.91687834, grad/param norm = 1.7143e-01, time/batch = 18.3942s	
19814/33650 (epoch 29.441), train_loss = 0.89417165, grad/param norm = 1.6273e-01, time/batch = 16.4659s	
19815/33650 (epoch 29.443), train_loss = 0.95879697, grad/param norm = 1.4768e-01, time/batch = 17.2329s	
19816/33650 (epoch 29.444), train_loss = 0.88936260, grad/param norm = 1.5748e-01, time/batch = 17.1355s	
19817/33650 (epoch 29.446), train_loss = 0.94442140, grad/param norm = 1.6890e-01, time/batch = 17.6440s	
19818/33650 (epoch 29.447), train_loss = 1.02699798, grad/param norm = 1.7227e-01, time/batch = 18.0618s	
19819/33650 (epoch 29.449), train_loss = 1.03593799, grad/param norm = 1.8911e-01, time/batch = 16.0517s	
19820/33650 (epoch 29.450), train_loss = 1.06235017, grad/param norm = 1.6552e-01, time/batch = 17.9772s	
19821/33650 (epoch 29.452), train_loss = 1.02480499, grad/param norm = 1.8135e-01, time/batch = 16.1377s	
19822/33650 (epoch 29.453), train_loss = 1.04590458, grad/param norm = 1.8198e-01, time/batch = 16.8135s	
19823/33650 (epoch 29.455), train_loss = 0.88642585, grad/param norm = 1.6279e-01, time/batch = 18.7235s	
19824/33650 (epoch 29.456), train_loss = 0.89743542, grad/param norm = 1.6358e-01, time/batch = 16.7140s	
19825/33650 (epoch 29.458), train_loss = 0.90699677, grad/param norm = 1.6934e-01, time/batch = 17.6512s	
19826/33650 (epoch 29.459), train_loss = 0.96327171, grad/param norm = 2.2217e-01, time/batch = 17.9736s	
19827/33650 (epoch 29.461), train_loss = 1.02160106, grad/param norm = 1.9654e-01, time/batch = 18.3950s	
19828/33650 (epoch 29.462), train_loss = 0.99515757, grad/param norm = 1.7831e-01, time/batch = 17.8046s	
19829/33650 (epoch 29.464), train_loss = 0.88993927, grad/param norm = 1.8910e-01, time/batch = 17.6334s	
19830/33650 (epoch 29.465), train_loss = 0.94802488, grad/param norm = 1.9202e-01, time/batch = 16.7229s	
19831/33650 (epoch 29.467), train_loss = 0.95898519, grad/param norm = 1.6835e-01, time/batch = 17.6403s	
19832/33650 (epoch 29.468), train_loss = 1.05545615, grad/param norm = 1.5321e-01, time/batch = 17.5729s	
19833/33650 (epoch 29.470), train_loss = 1.12008655, grad/param norm = 2.0114e-01, time/batch = 17.9850s	
19834/33650 (epoch 29.471), train_loss = 0.91379170, grad/param norm = 1.5971e-01, time/batch = 17.3185s	
19835/33650 (epoch 29.473), train_loss = 0.87638325, grad/param norm = 1.5891e-01, time/batch = 17.4737s	
19836/33650 (epoch 29.474), train_loss = 1.01244607, grad/param norm = 1.7834e-01, time/batch = 17.3996s	
19837/33650 (epoch 29.475), train_loss = 0.99654326, grad/param norm = 1.7799e-01, time/batch = 19.1468s	
19838/33650 (epoch 29.477), train_loss = 1.02087109, grad/param norm = 1.7507e-01, time/batch = 17.3059s	
19839/33650 (epoch 29.478), train_loss = 0.99654293, grad/param norm = 1.7103e-01, time/batch = 18.3987s	
19840/33650 (epoch 29.480), train_loss = 0.98477877, grad/param norm = 1.7413e-01, time/batch = 18.3967s	
19841/33650 (epoch 29.481), train_loss = 1.03128559, grad/param norm = 1.7469e-01, time/batch = 15.9646s	
19842/33650 (epoch 29.483), train_loss = 0.76843947, grad/param norm = 1.4182e-01, time/batch = 18.3911s	
19843/33650 (epoch 29.484), train_loss = 0.89978978, grad/param norm = 1.5693e-01, time/batch = 17.2921s	
19844/33650 (epoch 29.486), train_loss = 1.06632374, grad/param norm = 1.8598e-01, time/batch = 18.2355s	
19845/33650 (epoch 29.487), train_loss = 1.02679403, grad/param norm = 1.6746e-01, time/batch = 17.3009s	
19846/33650 (epoch 29.489), train_loss = 1.07999222, grad/param norm = 1.6943e-01, time/batch = 17.4808s	
19847/33650 (epoch 29.490), train_loss = 0.85582841, grad/param norm = 1.7022e-01, time/batch = 18.4897s	
19848/33650 (epoch 29.492), train_loss = 0.96278384, grad/param norm = 1.7598e-01, time/batch = 16.3853s	
19849/33650 (epoch 29.493), train_loss = 0.77344519, grad/param norm = 1.4106e-01, time/batch = 18.9788s	
19850/33650 (epoch 29.495), train_loss = 0.94096676, grad/param norm = 1.6253e-01, time/batch = 18.4864s	
19851/33650 (epoch 29.496), train_loss = 0.96987671, grad/param norm = 1.6812e-01, time/batch = 16.7929s	
19852/33650 (epoch 29.498), train_loss = 0.84814763, grad/param norm = 1.4314e-01, time/batch = 19.3959s	
19853/33650 (epoch 29.499), train_loss = 0.93531209, grad/param norm = 1.4138e-01, time/batch = 18.3045s	
19854/33650 (epoch 29.501), train_loss = 0.91508457, grad/param norm = 1.3593e-01, time/batch = 17.3054s	
19855/33650 (epoch 29.502), train_loss = 0.96781383, grad/param norm = 1.8260e-01, time/batch = 17.5412s	
19856/33650 (epoch 29.504), train_loss = 1.00002998, grad/param norm = 1.7339e-01, time/batch = 15.8896s	
19857/33650 (epoch 29.505), train_loss = 0.90415623, grad/param norm = 1.9617e-01, time/batch = 18.3218s	
19858/33650 (epoch 29.507), train_loss = 1.02544548, grad/param norm = 1.6973e-01, time/batch = 17.4713s	
19859/33650 (epoch 29.508), train_loss = 0.90856632, grad/param norm = 1.9696e-01, time/batch = 18.8812s	
19860/33650 (epoch 29.510), train_loss = 0.93268340, grad/param norm = 1.5901e-01, time/batch = 15.1574s	
19861/33650 (epoch 29.511), train_loss = 1.08655504, grad/param norm = 1.9476e-01, time/batch = 17.9796s	
19862/33650 (epoch 29.513), train_loss = 0.97889045, grad/param norm = 1.5714e-01, time/batch = 17.1389s	
19863/33650 (epoch 29.514), train_loss = 1.02140700, grad/param norm = 1.7825e-01, time/batch = 17.7241s	
19864/33650 (epoch 29.516), train_loss = 0.92902170, grad/param norm = 1.7134e-01, time/batch = 17.6341s	
19865/33650 (epoch 29.517), train_loss = 0.94937780, grad/param norm = 1.8707e-01, time/batch = 16.5620s	
19866/33650 (epoch 29.519), train_loss = 0.97967880, grad/param norm = 1.6321e-01, time/batch = 17.3279s	
19867/33650 (epoch 29.520), train_loss = 0.79726402, grad/param norm = 1.2945e-01, time/batch = 18.4777s	
19868/33650 (epoch 29.522), train_loss = 0.91799165, grad/param norm = 1.5759e-01, time/batch = 18.0590s	
19869/33650 (epoch 29.523), train_loss = 0.85602713, grad/param norm = 1.5095e-01, time/batch = 18.6455s	
19870/33650 (epoch 29.525), train_loss = 0.73442574, grad/param norm = 1.2845e-01, time/batch = 18.5556s	
19871/33650 (epoch 29.526), train_loss = 1.03711883, grad/param norm = 1.6283e-01, time/batch = 18.3031s	
19872/33650 (epoch 29.527), train_loss = 0.86165177, grad/param norm = 1.5224e-01, time/batch = 17.4161s	
19873/33650 (epoch 29.529), train_loss = 0.93103882, grad/param norm = 1.7975e-01, time/batch = 18.0642s	
19874/33650 (epoch 29.530), train_loss = 0.86671148, grad/param norm = 1.6263e-01, time/batch = 16.8059s	
19875/33650 (epoch 29.532), train_loss = 1.00564908, grad/param norm = 1.8962e-01, time/batch = 17.0621s	
19876/33650 (epoch 29.533), train_loss = 0.92251721, grad/param norm = 1.4833e-01, time/batch = 18.0739s	
19877/33650 (epoch 29.535), train_loss = 1.04590407, grad/param norm = 1.6442e-01, time/batch = 16.2308s	
19878/33650 (epoch 29.536), train_loss = 0.95445412, grad/param norm = 1.9715e-01, time/batch = 17.9861s	
19879/33650 (epoch 29.538), train_loss = 0.96158572, grad/param norm = 1.7730e-01, time/batch = 18.3117s	
19880/33650 (epoch 29.539), train_loss = 0.74791986, grad/param norm = 1.6140e-01, time/batch = 17.4785s	
19881/33650 (epoch 29.541), train_loss = 1.01072158, grad/param norm = 1.8549e-01, time/batch = 16.6989s	
19882/33650 (epoch 29.542), train_loss = 0.92250937, grad/param norm = 1.9182e-01, time/batch = 17.5589s	
19883/33650 (epoch 29.544), train_loss = 1.10092423, grad/param norm = 2.3721e-01, time/batch = 18.5537s	
19884/33650 (epoch 29.545), train_loss = 0.82525445, grad/param norm = 1.5799e-01, time/batch = 17.4761s	
19885/33650 (epoch 29.547), train_loss = 0.97312436, grad/param norm = 1.6202e-01, time/batch = 17.3743s	
19886/33650 (epoch 29.548), train_loss = 1.10227637, grad/param norm = 1.8095e-01, time/batch = 17.8988s	
19887/33650 (epoch 29.550), train_loss = 0.93886093, grad/param norm = 1.5930e-01, time/batch = 18.4002s	
19888/33650 (epoch 29.551), train_loss = 0.94868072, grad/param norm = 1.6792e-01, time/batch = 18.4539s	
19889/33650 (epoch 29.553), train_loss = 0.79895732, grad/param norm = 1.5606e-01, time/batch = 28.7633s	
19890/33650 (epoch 29.554), train_loss = 1.09079188, grad/param norm = 1.8761e-01, time/batch = 18.0739s	
19891/33650 (epoch 29.556), train_loss = 1.01502826, grad/param norm = 2.4201e-01, time/batch = 16.9014s	
19892/33650 (epoch 29.557), train_loss = 1.03127909, grad/param norm = 2.2682e-01, time/batch = 18.3024s	
19893/33650 (epoch 29.559), train_loss = 1.18822156, grad/param norm = 2.1461e-01, time/batch = 18.1561s	
19894/33650 (epoch 29.560), train_loss = 1.11590150, grad/param norm = 1.9121e-01, time/batch = 16.5542s	
19895/33650 (epoch 29.562), train_loss = 1.07168055, grad/param norm = 1.6174e-01, time/batch = 15.7981s	
19896/33650 (epoch 29.563), train_loss = 0.98318149, grad/param norm = 1.7854e-01, time/batch = 17.4702s	
19897/33650 (epoch 29.565), train_loss = 0.94830114, grad/param norm = 1.6978e-01, time/batch = 18.2229s	
19898/33650 (epoch 29.566), train_loss = 0.90702804, grad/param norm = 1.5428e-01, time/batch = 17.4679s	
19899/33650 (epoch 29.568), train_loss = 0.95737332, grad/param norm = 2.1414e-01, time/batch = 18.6378s	
19900/33650 (epoch 29.569), train_loss = 0.86032334, grad/param norm = 1.4298e-01, time/batch = 18.4817s	
19901/33650 (epoch 29.571), train_loss = 1.04523471, grad/param norm = 1.7728e-01, time/batch = 17.0596s	
19902/33650 (epoch 29.572), train_loss = 0.99797692, grad/param norm = 1.6219e-01, time/batch = 17.5665s	
19903/33650 (epoch 29.574), train_loss = 0.87193965, grad/param norm = 1.9336e-01, time/batch = 18.5615s	
19904/33650 (epoch 29.575), train_loss = 0.92983316, grad/param norm = 1.5523e-01, time/batch = 17.9814s	
19905/33650 (epoch 29.577), train_loss = 0.88110921, grad/param norm = 1.7254e-01, time/batch = 16.6319s	
19906/33650 (epoch 29.578), train_loss = 1.03743160, grad/param norm = 1.7777e-01, time/batch = 16.7220s	
19907/33650 (epoch 29.579), train_loss = 0.99362792, grad/param norm = 1.7382e-01, time/batch = 18.1380s	
19908/33650 (epoch 29.581), train_loss = 1.07243743, grad/param norm = 1.6598e-01, time/batch = 17.8997s	
19909/33650 (epoch 29.582), train_loss = 0.96731434, grad/param norm = 1.4653e-01, time/batch = 17.6454s	
19910/33650 (epoch 29.584), train_loss = 0.95000993, grad/param norm = 1.5172e-01, time/batch = 17.1409s	
19911/33650 (epoch 29.585), train_loss = 0.97753781, grad/param norm = 2.1576e-01, time/batch = 17.9558s	
19912/33650 (epoch 29.587), train_loss = 0.87454936, grad/param norm = 1.7919e-01, time/batch = 17.8217s	
19913/33650 (epoch 29.588), train_loss = 0.90966200, grad/param norm = 2.2007e-01, time/batch = 16.9912s	
19914/33650 (epoch 29.590), train_loss = 0.88726064, grad/param norm = 1.4255e-01, time/batch = 17.9796s	
19915/33650 (epoch 29.591), train_loss = 0.85292254, grad/param norm = 1.7966e-01, time/batch = 15.5420s	
19916/33650 (epoch 29.593), train_loss = 0.83569581, grad/param norm = 1.5127e-01, time/batch = 18.3889s	
19917/33650 (epoch 29.594), train_loss = 0.83496308, grad/param norm = 1.6117e-01, time/batch = 18.0704s	
19918/33650 (epoch 29.596), train_loss = 0.92556426, grad/param norm = 1.5688e-01, time/batch = 17.2131s	
19919/33650 (epoch 29.597), train_loss = 0.78591390, grad/param norm = 1.4294e-01, time/batch = 17.2394s	
19920/33650 (epoch 29.599), train_loss = 0.91772603, grad/param norm = 1.6145e-01, time/batch = 19.0577s	
19921/33650 (epoch 29.600), train_loss = 0.83758271, grad/param norm = 1.4856e-01, time/batch = 17.8957s	
19922/33650 (epoch 29.602), train_loss = 0.94263299, grad/param norm = 1.7113e-01, time/batch = 17.2006s	
19923/33650 (epoch 29.603), train_loss = 0.86035005, grad/param norm = 1.4634e-01, time/batch = 17.7285s	
19924/33650 (epoch 29.605), train_loss = 0.99011306, grad/param norm = 1.6263e-01, time/batch = 19.0669s	
19925/33650 (epoch 29.606), train_loss = 0.93290753, grad/param norm = 2.0214e-01, time/batch = 16.7087s	
19926/33650 (epoch 29.608), train_loss = 0.82022794, grad/param norm = 1.6024e-01, time/batch = 17.2898s	
19927/33650 (epoch 29.609), train_loss = 0.91845558, grad/param norm = 1.4382e-01, time/batch = 18.1485s	
19928/33650 (epoch 29.611), train_loss = 0.81912080, grad/param norm = 1.5855e-01, time/batch = 17.7209s	
19929/33650 (epoch 29.612), train_loss = 0.92650212, grad/param norm = 1.9209e-01, time/batch = 18.1580s	
19930/33650 (epoch 29.614), train_loss = 1.00636409, grad/param norm = 1.6841e-01, time/batch = 17.5510s	
19931/33650 (epoch 29.615), train_loss = 0.92856394, grad/param norm = 1.4086e-01, time/batch = 18.8991s	
19932/33650 (epoch 29.617), train_loss = 0.83094512, grad/param norm = 1.3412e-01, time/batch = 16.8132s	
19933/33650 (epoch 29.618), train_loss = 0.89411416, grad/param norm = 1.5823e-01, time/batch = 19.0573s	
19934/33650 (epoch 29.620), train_loss = 0.87823269, grad/param norm = 1.6627e-01, time/batch = 17.7376s	
19935/33650 (epoch 29.621), train_loss = 0.82920215, grad/param norm = 1.5147e-01, time/batch = 16.2954s	
19936/33650 (epoch 29.623), train_loss = 0.89454791, grad/param norm = 1.7476e-01, time/batch = 17.7251s	
19937/33650 (epoch 29.624), train_loss = 0.72204162, grad/param norm = 1.6929e-01, time/batch = 18.8046s	
19938/33650 (epoch 29.626), train_loss = 0.75704573, grad/param norm = 1.4650e-01, time/batch = 18.0576s	
19939/33650 (epoch 29.627), train_loss = 0.85229536, grad/param norm = 1.6048e-01, time/batch = 3.6488s	
19940/33650 (epoch 29.629), train_loss = 0.86067170, grad/param norm = 1.6720e-01, time/batch = 0.6439s	
19941/33650 (epoch 29.630), train_loss = 1.01732113, grad/param norm = 1.7522e-01, time/batch = 0.6445s	
19942/33650 (epoch 29.632), train_loss = 1.01345206, grad/param norm = 1.5751e-01, time/batch = 0.6390s	
19943/33650 (epoch 29.633), train_loss = 0.99241332, grad/param norm = 1.6047e-01, time/batch = 0.6382s	
19944/33650 (epoch 29.634), train_loss = 0.79718219, grad/param norm = 1.4232e-01, time/batch = 0.6416s	
19945/33650 (epoch 29.636), train_loss = 0.72374921, grad/param norm = 1.2847e-01, time/batch = 0.6477s	
19946/33650 (epoch 29.637), train_loss = 0.82539828, grad/param norm = 1.3704e-01, time/batch = 0.7195s	
19947/33650 (epoch 29.639), train_loss = 0.83629831, grad/param norm = 1.5233e-01, time/batch = 0.9480s	
19948/33650 (epoch 29.640), train_loss = 0.91402081, grad/param norm = 1.5389e-01, time/batch = 0.9394s	
19949/33650 (epoch 29.642), train_loss = 0.97297715, grad/param norm = 1.6240e-01, time/batch = 0.9393s	
19950/33650 (epoch 29.643), train_loss = 0.93352327, grad/param norm = 1.5743e-01, time/batch = 0.9331s	
19951/33650 (epoch 29.645), train_loss = 0.94151635, grad/param norm = 1.7272e-01, time/batch = 0.9551s	
19952/33650 (epoch 29.646), train_loss = 0.80371168, grad/param norm = 1.2788e-01, time/batch = 1.6924s	
19953/33650 (epoch 29.648), train_loss = 0.96130138, grad/param norm = 1.6223e-01, time/batch = 1.7815s	
19954/33650 (epoch 29.649), train_loss = 0.83310670, grad/param norm = 1.6782e-01, time/batch = 2.7809s	
19955/33650 (epoch 29.651), train_loss = 0.96918416, grad/param norm = 1.6418e-01, time/batch = 17.8951s	
19956/33650 (epoch 29.652), train_loss = 0.67884801, grad/param norm = 1.3210e-01, time/batch = 18.5667s	
19957/33650 (epoch 29.654), train_loss = 0.81284596, grad/param norm = 1.5354e-01, time/batch = 16.3839s	
19958/33650 (epoch 29.655), train_loss = 0.79921080, grad/param norm = 1.4052e-01, time/batch = 18.4933s	
19959/33650 (epoch 29.657), train_loss = 0.86912015, grad/param norm = 1.4925e-01, time/batch = 17.8984s	
19960/33650 (epoch 29.658), train_loss = 0.73640373, grad/param norm = 1.5335e-01, time/batch = 17.9747s	
19961/33650 (epoch 29.660), train_loss = 0.74063710, grad/param norm = 1.3704e-01, time/batch = 17.2240s	
19962/33650 (epoch 29.661), train_loss = 0.79954654, grad/param norm = 1.4705e-01, time/batch = 18.2170s	
19963/33650 (epoch 29.663), train_loss = 0.77104447, grad/param norm = 1.4914e-01, time/batch = 13.8149s	
19964/33650 (epoch 29.664), train_loss = 0.85347743, grad/param norm = 1.4542e-01, time/batch = 14.1465s	
19965/33650 (epoch 29.666), train_loss = 0.86888180, grad/param norm = 1.2979e-01, time/batch = 13.8557s	
19966/33650 (epoch 29.667), train_loss = 0.77031054, grad/param norm = 1.3928e-01, time/batch = 17.3827s	
19967/33650 (epoch 29.669), train_loss = 0.80149218, grad/param norm = 1.6545e-01, time/batch = 17.5314s	
19968/33650 (epoch 29.670), train_loss = 0.72716358, grad/param norm = 1.4289e-01, time/batch = 18.3156s	
19969/33650 (epoch 29.672), train_loss = 0.75663244, grad/param norm = 1.4581e-01, time/batch = 18.3893s	
19970/33650 (epoch 29.673), train_loss = 0.74033889, grad/param norm = 1.5518e-01, time/batch = 18.1471s	
19971/33650 (epoch 29.675), train_loss = 0.70720623, grad/param norm = 2.1249e-01, time/batch = 17.2067s	
19972/33650 (epoch 29.676), train_loss = 0.85859019, grad/param norm = 1.5386e-01, time/batch = 18.1382s	
19973/33650 (epoch 29.678), train_loss = 0.85476687, grad/param norm = 1.6069e-01, time/batch = 18.0532s	
19974/33650 (epoch 29.679), train_loss = 0.82620891, grad/param norm = 1.6510e-01, time/batch = 17.7984s	
19975/33650 (epoch 29.681), train_loss = 0.86905549, grad/param norm = 1.6785e-01, time/batch = 16.8587s	
19976/33650 (epoch 29.682), train_loss = 0.80318176, grad/param norm = 1.4493e-01, time/batch = 18.2160s	
19977/33650 (epoch 29.684), train_loss = 0.76824159, grad/param norm = 1.5473e-01, time/batch = 17.4033s	
19978/33650 (epoch 29.685), train_loss = 0.91002000, grad/param norm = 1.7165e-01, time/batch = 17.5545s	
19979/33650 (epoch 29.686), train_loss = 0.87767703, grad/param norm = 1.4279e-01, time/batch = 17.5598s	
19980/33650 (epoch 29.688), train_loss = 0.95667190, grad/param norm = 1.5390e-01, time/batch = 17.2350s	
19981/33650 (epoch 29.689), train_loss = 0.82450349, grad/param norm = 1.5865e-01, time/batch = 17.0521s	
19982/33650 (epoch 29.691), train_loss = 0.96069253, grad/param norm = 1.7015e-01, time/batch = 18.6460s	
19983/33650 (epoch 29.692), train_loss = 0.99782499, grad/param norm = 1.7035e-01, time/batch = 18.0606s	
19984/33650 (epoch 29.694), train_loss = 0.90875050, grad/param norm = 1.5465e-01, time/batch = 17.2198s	
19985/33650 (epoch 29.695), train_loss = 0.61962065, grad/param norm = 1.3379e-01, time/batch = 18.0579s	
19986/33650 (epoch 29.697), train_loss = 0.83592011, grad/param norm = 1.4868e-01, time/batch = 19.3115s	
19987/33650 (epoch 29.698), train_loss = 1.00430125, grad/param norm = 1.8056e-01, time/batch = 18.0418s	
19988/33650 (epoch 29.700), train_loss = 0.86705675, grad/param norm = 1.4877e-01, time/batch = 17.5495s	
19989/33650 (epoch 29.701), train_loss = 0.88403102, grad/param norm = 1.5280e-01, time/batch = 18.5602s	
19990/33650 (epoch 29.703), train_loss = 1.07296844, grad/param norm = 1.5884e-01, time/batch = 18.0631s	
19991/33650 (epoch 29.704), train_loss = 0.87198645, grad/param norm = 1.4512e-01, time/batch = 17.4577s	
19992/33650 (epoch 29.706), train_loss = 0.85287579, grad/param norm = 1.4870e-01, time/batch = 18.2315s	
19993/33650 (epoch 29.707), train_loss = 0.97957135, grad/param norm = 1.4846e-01, time/batch = 18.0819s	
19994/33650 (epoch 29.709), train_loss = 0.84969677, grad/param norm = 1.4963e-01, time/batch = 17.1460s	
19995/33650 (epoch 29.710), train_loss = 1.04518163, grad/param norm = 1.5338e-01, time/batch = 17.4022s	
19996/33650 (epoch 29.712), train_loss = 0.78373981, grad/param norm = 1.5365e-01, time/batch = 17.8104s	
19997/33650 (epoch 29.713), train_loss = 0.78226104, grad/param norm = 1.6040e-01, time/batch = 17.8831s	
19998/33650 (epoch 29.715), train_loss = 0.93069566, grad/param norm = 1.6454e-01, time/batch = 18.3886s	
19999/33650 (epoch 29.716), train_loss = 0.85482597, grad/param norm = 1.4441e-01, time/batch = 17.4805s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch29.72_1.7060.t7	
20000/33650 (epoch 29.718), train_loss = 0.84667544, grad/param norm = 1.7493e-01, time/batch = 16.1375s	
20001/33650 (epoch 29.719), train_loss = 1.36482212, grad/param norm = 2.3719e-01, time/batch = 18.3035s	
20002/33650 (epoch 29.721), train_loss = 1.07655711, grad/param norm = 1.8939e-01, time/batch = 18.3960s	
20003/33650 (epoch 29.722), train_loss = 0.96215312, grad/param norm = 2.2452e-01, time/batch = 17.8819s	
20004/33650 (epoch 29.724), train_loss = 1.00897967, grad/param norm = 1.6884e-01, time/batch = 17.1382s	
20005/33650 (epoch 29.725), train_loss = 0.96132911, grad/param norm = 1.7038e-01, time/batch = 18.6470s	
20006/33650 (epoch 29.727), train_loss = 0.83710181, grad/param norm = 1.7359e-01, time/batch = 17.1404s	
20007/33650 (epoch 29.728), train_loss = 0.86016394, grad/param norm = 1.6213e-01, time/batch = 17.4007s	
20008/33650 (epoch 29.730), train_loss = 0.93260104, grad/param norm = 1.7398e-01, time/batch = 18.8206s	
20009/33650 (epoch 29.731), train_loss = 1.04985440, grad/param norm = 1.8100e-01, time/batch = 18.4770s	
20010/33650 (epoch 29.733), train_loss = 0.86223526, grad/param norm = 1.6169e-01, time/batch = 17.8734s	
20011/33650 (epoch 29.734), train_loss = 1.02389061, grad/param norm = 1.8097e-01, time/batch = 18.6446s	
20012/33650 (epoch 29.736), train_loss = 0.87981490, grad/param norm = 1.8635e-01, time/batch = 18.8835s	
20013/33650 (epoch 29.737), train_loss = 0.95069399, grad/param norm = 1.8669e-01, time/batch = 16.6296s	
20014/33650 (epoch 29.738), train_loss = 0.84069055, grad/param norm = 1.7755e-01, time/batch = 18.4754s	
20015/33650 (epoch 29.740), train_loss = 0.76012312, grad/param norm = 1.4987e-01, time/batch = 18.4777s	
20016/33650 (epoch 29.741), train_loss = 0.83044036, grad/param norm = 1.6915e-01, time/batch = 16.2098s	
20017/33650 (epoch 29.743), train_loss = 0.87022848, grad/param norm = 1.5422e-01, time/batch = 17.8168s	
20018/33650 (epoch 29.744), train_loss = 0.97409160, grad/param norm = 1.4706e-01, time/batch = 19.0621s	
20019/33650 (epoch 29.746), train_loss = 0.85795059, grad/param norm = 1.5776e-01, time/batch = 18.6430s	
20020/33650 (epoch 29.747), train_loss = 1.00603973, grad/param norm = 1.5863e-01, time/batch = 17.1491s	
20021/33650 (epoch 29.749), train_loss = 0.74213118, grad/param norm = 1.5824e-01, time/batch = 16.2044s	
20022/33650 (epoch 29.750), train_loss = 1.04991714, grad/param norm = 1.7228e-01, time/batch = 17.3861s	
20023/33650 (epoch 29.752), train_loss = 0.98593270, grad/param norm = 1.6044e-01, time/batch = 17.6376s	
20024/33650 (epoch 29.753), train_loss = 1.07762808, grad/param norm = 1.7620e-01, time/batch = 17.3958s	
20025/33650 (epoch 29.755), train_loss = 0.86028885, grad/param norm = 1.4674e-01, time/batch = 18.5708s	
20026/33650 (epoch 29.756), train_loss = 0.97780991, grad/param norm = 1.8131e-01, time/batch = 17.0532s	
20027/33650 (epoch 29.758), train_loss = 0.98498048, grad/param norm = 1.5425e-01, time/batch = 16.9888s	
20028/33650 (epoch 29.759), train_loss = 0.98998358, grad/param norm = 1.7112e-01, time/batch = 18.0557s	
20029/33650 (epoch 29.761), train_loss = 0.91964004, grad/param norm = 1.6354e-01, time/batch = 17.9804s	
20030/33650 (epoch 29.762), train_loss = 0.87856536, grad/param norm = 1.4792e-01, time/batch = 16.1201s	
20031/33650 (epoch 29.764), train_loss = 0.95886101, grad/param norm = 1.8285e-01, time/batch = 17.3997s	
20032/33650 (epoch 29.765), train_loss = 0.85375959, grad/param norm = 1.5894e-01, time/batch = 18.3185s	
20033/33650 (epoch 29.767), train_loss = 0.87994146, grad/param norm = 1.5494e-01, time/batch = 17.2320s	
20034/33650 (epoch 29.768), train_loss = 0.81978991, grad/param norm = 1.7537e-01, time/batch = 18.3889s	
20035/33650 (epoch 29.770), train_loss = 0.92713779, grad/param norm = 1.7569e-01, time/batch = 18.0589s	
20036/33650 (epoch 29.771), train_loss = 0.95230916, grad/param norm = 1.8245e-01, time/batch = 18.3048s	
20037/33650 (epoch 29.773), train_loss = 1.00070829, grad/param norm = 1.8293e-01, time/batch = 17.6302s	
20038/33650 (epoch 29.774), train_loss = 0.93713073, grad/param norm = 1.7455e-01, time/batch = 17.7348s	
20039/33650 (epoch 29.776), train_loss = 0.97941216, grad/param norm = 1.7613e-01, time/batch = 18.4847s	
20040/33650 (epoch 29.777), train_loss = 0.84584443, grad/param norm = 1.5716e-01, time/batch = 16.9757s	
20041/33650 (epoch 29.779), train_loss = 0.87183159, grad/param norm = 1.4360e-01, time/batch = 16.7339s	
20042/33650 (epoch 29.780), train_loss = 0.80576512, grad/param norm = 1.5280e-01, time/batch = 17.3049s	
20043/33650 (epoch 29.782), train_loss = 0.82174916, grad/param norm = 1.6273e-01, time/batch = 17.6247s	
20044/33650 (epoch 29.783), train_loss = 0.81563662, grad/param norm = 1.2530e-01, time/batch = 17.8890s	
20045/33650 (epoch 29.785), train_loss = 1.05740619, grad/param norm = 1.4623e-01, time/batch = 18.8145s	
20046/33650 (epoch 29.786), train_loss = 0.95662120, grad/param norm = 1.5837e-01, time/batch = 18.7309s	
20047/33650 (epoch 29.788), train_loss = 0.95321407, grad/param norm = 1.6702e-01, time/batch = 18.0531s	
20048/33650 (epoch 29.789), train_loss = 0.99450707, grad/param norm = 1.6730e-01, time/batch = 18.7288s	
20049/33650 (epoch 29.790), train_loss = 0.91674481, grad/param norm = 1.6223e-01, time/batch = 18.0607s	
20050/33650 (epoch 29.792), train_loss = 0.99805761, grad/param norm = 1.8645e-01, time/batch = 16.8069s	
20051/33650 (epoch 29.793), train_loss = 0.99390806, grad/param norm = 1.9403e-01, time/batch = 18.9717s	
20052/33650 (epoch 29.795), train_loss = 1.01697287, grad/param norm = 1.6945e-01, time/batch = 18.0563s	
20053/33650 (epoch 29.796), train_loss = 0.87005543, grad/param norm = 1.6028e-01, time/batch = 17.4729s	
20054/33650 (epoch 29.798), train_loss = 0.86654449, grad/param norm = 1.5278e-01, time/batch = 17.8146s	
20055/33650 (epoch 29.799), train_loss = 0.89977023, grad/param norm = 1.5707e-01, time/batch = 17.8833s	
20056/33650 (epoch 29.801), train_loss = 0.93172297, grad/param norm = 1.8259e-01, time/batch = 17.1369s	
20057/33650 (epoch 29.802), train_loss = 1.00464023, grad/param norm = 1.6757e-01, time/batch = 16.9555s	
20058/33650 (epoch 29.804), train_loss = 0.91346489, grad/param norm = 1.5547e-01, time/batch = 18.5568s	
20059/33650 (epoch 29.805), train_loss = 0.89809257, grad/param norm = 1.4511e-01, time/batch = 17.3003s	
20060/33650 (epoch 29.807), train_loss = 1.11557631, grad/param norm = 1.9896e-01, time/batch = 15.6948s	
20061/33650 (epoch 29.808), train_loss = 1.17345909, grad/param norm = 2.0991e-01, time/batch = 18.4779s	
20062/33650 (epoch 29.810), train_loss = 0.94735753, grad/param norm = 1.7694e-01, time/batch = 18.5733s	
20063/33650 (epoch 29.811), train_loss = 0.94047313, grad/param norm = 1.7000e-01, time/batch = 17.4784s	
20064/33650 (epoch 29.813), train_loss = 0.82511531, grad/param norm = 1.4976e-01, time/batch = 18.0543s	
20065/33650 (epoch 29.814), train_loss = 1.00006720, grad/param norm = 1.5987e-01, time/batch = 17.9030s	
20066/33650 (epoch 29.816), train_loss = 0.98037320, grad/param norm = 1.7791e-01, time/batch = 16.9735s	
20067/33650 (epoch 29.817), train_loss = 0.98552600, grad/param norm = 1.7045e-01, time/batch = 17.1310s	
20068/33650 (epoch 29.819), train_loss = 0.92288560, grad/param norm = 1.5892e-01, time/batch = 17.9723s	
20069/33650 (epoch 29.820), train_loss = 1.03388897, grad/param norm = 1.6350e-01, time/batch = 17.5581s	
20070/33650 (epoch 29.822), train_loss = 0.95586627, grad/param norm = 1.9889e-01, time/batch = 13.8851s	
20071/33650 (epoch 29.823), train_loss = 0.86019157, grad/param norm = 1.7354e-01, time/batch = 13.8854s	
20072/33650 (epoch 29.825), train_loss = 0.91236458, grad/param norm = 1.5908e-01, time/batch = 14.3134s	
20073/33650 (epoch 29.826), train_loss = 0.97359401, grad/param norm = 1.4608e-01, time/batch = 18.2291s	
20074/33650 (epoch 29.828), train_loss = 1.07753874, grad/param norm = 1.9205e-01, time/batch = 17.8901s	
20075/33650 (epoch 29.829), train_loss = 0.77055145, grad/param norm = 1.4428e-01, time/batch = 18.7219s	
20076/33650 (epoch 29.831), train_loss = 0.94320586, grad/param norm = 1.9065e-01, time/batch = 17.3934s	
20077/33650 (epoch 29.832), train_loss = 0.99926151, grad/param norm = 1.8210e-01, time/batch = 17.7288s	
20078/33650 (epoch 29.834), train_loss = 0.99663173, grad/param norm = 1.7190e-01, time/batch = 17.7224s	
20079/33650 (epoch 29.835), train_loss = 1.13733300, grad/param norm = 1.9698e-01, time/batch = 17.0434s	
20080/33650 (epoch 29.837), train_loss = 0.95539702, grad/param norm = 1.7601e-01, time/batch = 18.6410s	
20081/33650 (epoch 29.838), train_loss = 0.93010041, grad/param norm = 1.6752e-01, time/batch = 17.2982s	
20082/33650 (epoch 29.840), train_loss = 1.00727866, grad/param norm = 1.6841e-01, time/batch = 19.1464s	
20083/33650 (epoch 29.841), train_loss = 0.89192003, grad/param norm = 1.6240e-01, time/batch = 16.6265s	
20084/33650 (epoch 29.842), train_loss = 0.89912418, grad/param norm = 1.5204e-01, time/batch = 17.1392s	
20085/33650 (epoch 29.844), train_loss = 1.06526861, grad/param norm = 1.6820e-01, time/batch = 17.8135s	
20086/33650 (epoch 29.845), train_loss = 0.88654992, grad/param norm = 1.6597e-01, time/batch = 18.3187s	
20087/33650 (epoch 29.847), train_loss = 0.71109720, grad/param norm = 1.3782e-01, time/batch = 18.3939s	
20088/33650 (epoch 29.848), train_loss = 0.81760147, grad/param norm = 1.7313e-01, time/batch = 16.6342s	
20089/33650 (epoch 29.850), train_loss = 0.86125768, grad/param norm = 1.8148e-01, time/batch = 16.0372s	
20090/33650 (epoch 29.851), train_loss = 0.78414546, grad/param norm = 1.4483e-01, time/batch = 18.6423s	
20091/33650 (epoch 29.853), train_loss = 0.87734918, grad/param norm = 1.6318e-01, time/batch = 17.3894s	
20092/33650 (epoch 29.854), train_loss = 1.01385608, grad/param norm = 1.7326e-01, time/batch = 18.5498s	
20093/33650 (epoch 29.856), train_loss = 0.72545008, grad/param norm = 1.4561e-01, time/batch = 18.3022s	
20094/33650 (epoch 29.857), train_loss = 0.93533844, grad/param norm = 1.6457e-01, time/batch = 17.7356s	
20095/33650 (epoch 29.859), train_loss = 0.81063613, grad/param norm = 1.2844e-01, time/batch = 18.1401s	
20096/33650 (epoch 29.860), train_loss = 0.79072894, grad/param norm = 1.5032e-01, time/batch = 18.0529s	
20097/33650 (epoch 29.862), train_loss = 0.82802964, grad/param norm = 1.6486e-01, time/batch = 18.3138s	
20098/33650 (epoch 29.863), train_loss = 1.04483705, grad/param norm = 1.6204e-01, time/batch = 31.4768s	
20099/33650 (epoch 29.865), train_loss = 0.88223001, grad/param norm = 1.4164e-01, time/batch = 16.8846s	
20100/33650 (epoch 29.866), train_loss = 0.83270466, grad/param norm = 1.5995e-01, time/batch = 17.4714s	
20101/33650 (epoch 29.868), train_loss = 0.79388437, grad/param norm = 1.7005e-01, time/batch = 17.1498s	
20102/33650 (epoch 29.869), train_loss = 0.96820504, grad/param norm = 1.7146e-01, time/batch = 17.9890s	
20103/33650 (epoch 29.871), train_loss = 0.81414037, grad/param norm = 1.5575e-01, time/batch = 18.3878s	
20104/33650 (epoch 29.872), train_loss = 0.93629896, grad/param norm = 1.5523e-01, time/batch = 17.7984s	
20105/33650 (epoch 29.874), train_loss = 0.96953816, grad/param norm = 1.6406e-01, time/batch = 17.0598s	
20106/33650 (epoch 29.875), train_loss = 0.87047131, grad/param norm = 1.4790e-01, time/batch = 16.9525s	
20107/33650 (epoch 29.877), train_loss = 1.07196048, grad/param norm = 1.7081e-01, time/batch = 17.6347s	
20108/33650 (epoch 29.878), train_loss = 0.65407127, grad/param norm = 1.2941e-01, time/batch = 17.7360s	
20109/33650 (epoch 29.880), train_loss = 0.94399717, grad/param norm = 2.0425e-01, time/batch = 17.8053s	
20110/33650 (epoch 29.881), train_loss = 0.85347925, grad/param norm = 1.6582e-01, time/batch = 17.5315s	
20111/33650 (epoch 29.883), train_loss = 0.93110485, grad/param norm = 1.4458e-01, time/batch = 17.8908s	
20112/33650 (epoch 29.884), train_loss = 1.01464978, grad/param norm = 1.7426e-01, time/batch = 17.8151s	
20113/33650 (epoch 29.886), train_loss = 0.96972326, grad/param norm = 1.5948e-01, time/batch = 18.1455s	
20114/33650 (epoch 29.887), train_loss = 0.77454211, grad/param norm = 1.3544e-01, time/batch = 17.3008s	
20115/33650 (epoch 29.889), train_loss = 0.87109950, grad/param norm = 1.5044e-01, time/batch = 18.6365s	
20116/33650 (epoch 29.890), train_loss = 0.94920082, grad/param norm = 1.4623e-01, time/batch = 17.4871s	
20117/33650 (epoch 29.892), train_loss = 0.87435748, grad/param norm = 2.0565e-01, time/batch = 16.6176s	
20118/33650 (epoch 29.893), train_loss = 0.93295697, grad/param norm = 1.6282e-01, time/batch = 18.4734s	
20119/33650 (epoch 29.895), train_loss = 1.04103008, grad/param norm = 1.6353e-01, time/batch = 17.4752s	
20120/33650 (epoch 29.896), train_loss = 0.83419518, grad/param norm = 1.3458e-01, time/batch = 17.8864s	
20121/33650 (epoch 29.897), train_loss = 0.76833296, grad/param norm = 1.4084e-01, time/batch = 16.1234s	
20122/33650 (epoch 29.899), train_loss = 0.81716755, grad/param norm = 1.3566e-01, time/batch = 17.8953s	
20123/33650 (epoch 29.900), train_loss = 0.75675189, grad/param norm = 1.3060e-01, time/batch = 18.1563s	
20124/33650 (epoch 29.902), train_loss = 0.90389307, grad/param norm = 1.7594e-01, time/batch = 16.7173s	
20125/33650 (epoch 29.903), train_loss = 0.86177274, grad/param norm = 1.6758e-01, time/batch = 18.4757s	
20126/33650 (epoch 29.905), train_loss = 1.01720741, grad/param norm = 1.9048e-01, time/batch = 18.0622s	
20127/33650 (epoch 29.906), train_loss = 0.83348703, grad/param norm = 1.6355e-01, time/batch = 16.8074s	
20128/33650 (epoch 29.908), train_loss = 0.87738993, grad/param norm = 1.5663e-01, time/batch = 18.3025s	
20129/33650 (epoch 29.909), train_loss = 0.84026883, grad/param norm = 1.4256e-01, time/batch = 18.6362s	
20130/33650 (epoch 29.911), train_loss = 0.75495907, grad/param norm = 1.3326e-01, time/batch = 18.0630s	
20131/33650 (epoch 29.912), train_loss = 0.71810017, grad/param norm = 1.5152e-01, time/batch = 16.8868s	
20132/33650 (epoch 29.914), train_loss = 0.90938733, grad/param norm = 1.3684e-01, time/batch = 19.0643s	
20133/33650 (epoch 29.915), train_loss = 0.86932208, grad/param norm = 1.5809e-01, time/batch = 18.2346s	
20134/33650 (epoch 29.917), train_loss = 0.85210644, grad/param norm = 1.5946e-01, time/batch = 17.3958s	
20135/33650 (epoch 29.918), train_loss = 0.79763148, grad/param norm = 1.5018e-01, time/batch = 17.8054s	
20136/33650 (epoch 29.920), train_loss = 0.80936682, grad/param norm = 1.3819e-01, time/batch = 17.7399s	
20137/33650 (epoch 29.921), train_loss = 0.78820078, grad/param norm = 1.4425e-01, time/batch = 17.5478s	
20138/33650 (epoch 29.923), train_loss = 0.72391952, grad/param norm = 1.3521e-01, time/batch = 17.3016s	
20139/33650 (epoch 29.924), train_loss = 0.90856806, grad/param norm = 1.4952e-01, time/batch = 17.7330s	
20140/33650 (epoch 29.926), train_loss = 0.83387260, grad/param norm = 1.7444e-01, time/batch = 18.6479s	
20141/33650 (epoch 29.927), train_loss = 0.88203250, grad/param norm = 1.6593e-01, time/batch = 17.7947s	
20142/33650 (epoch 29.929), train_loss = 0.93893324, grad/param norm = 1.4745e-01, time/batch = 18.3850s	
20143/33650 (epoch 29.930), train_loss = 0.86447835, grad/param norm = 1.7249e-01, time/batch = 18.7262s	
20144/33650 (epoch 29.932), train_loss = 0.85529654, grad/param norm = 1.4527e-01, time/batch = 17.1398s	
20145/33650 (epoch 29.933), train_loss = 0.76646377, grad/param norm = 1.5308e-01, time/batch = 16.3803s	
20146/33650 (epoch 29.935), train_loss = 0.76771698, grad/param norm = 1.7284e-01, time/batch = 18.3962s	
20147/33650 (epoch 29.936), train_loss = 0.82527221, grad/param norm = 1.3607e-01, time/batch = 17.3103s	
20148/33650 (epoch 29.938), train_loss = 0.76771715, grad/param norm = 1.5334e-01, time/batch = 17.6540s	
20149/33650 (epoch 29.939), train_loss = 0.95489150, grad/param norm = 1.5013e-01, time/batch = 18.2340s	
20150/33650 (epoch 29.941), train_loss = 0.87549765, grad/param norm = 1.3670e-01, time/batch = 18.5685s	
20151/33650 (epoch 29.942), train_loss = 0.94754829, grad/param norm = 1.5896e-01, time/batch = 18.5506s	
20152/33650 (epoch 29.944), train_loss = 0.84066356, grad/param norm = 1.4911e-01, time/batch = 17.9857s	
20153/33650 (epoch 29.945), train_loss = 0.89942418, grad/param norm = 1.6277e-01, time/batch = 17.9008s	
20154/33650 (epoch 29.947), train_loss = 1.02896807, grad/param norm = 2.1494e-01, time/batch = 17.2030s	
20155/33650 (epoch 29.948), train_loss = 0.99117996, grad/param norm = 1.5503e-01, time/batch = 17.0660s	
20156/33650 (epoch 29.949), train_loss = 0.75482190, grad/param norm = 1.2799e-01, time/batch = 16.5120s	
20157/33650 (epoch 29.951), train_loss = 1.00313666, grad/param norm = 1.4996e-01, time/batch = 14.9707s	
20158/33650 (epoch 29.952), train_loss = 0.92948195, grad/param norm = 1.7750e-01, time/batch = 15.0438s	
20159/33650 (epoch 29.954), train_loss = 0.93251277, grad/param norm = 1.6161e-01, time/batch = 14.2193s	
20160/33650 (epoch 29.955), train_loss = 0.91510175, grad/param norm = 1.5351e-01, time/batch = 14.3890s	
20161/33650 (epoch 29.957), train_loss = 0.93349247, grad/param norm = 1.6363e-01, time/batch = 17.0538s	
20162/33650 (epoch 29.958), train_loss = 0.70235433, grad/param norm = 1.3266e-01, time/batch = 17.9657s	
20163/33650 (epoch 29.960), train_loss = 0.72477694, grad/param norm = 1.3566e-01, time/batch = 18.2205s	
20164/33650 (epoch 29.961), train_loss = 0.78041587, grad/param norm = 1.4206e-01, time/batch = 17.5453s	
20165/33650 (epoch 29.963), train_loss = 0.81393545, grad/param norm = 1.5958e-01, time/batch = 16.3786s	
20166/33650 (epoch 29.964), train_loss = 0.97071045, grad/param norm = 1.5485e-01, time/batch = 18.4046s	
20167/33650 (epoch 29.966), train_loss = 0.90457621, grad/param norm = 1.5607e-01, time/batch = 18.2283s	
20168/33650 (epoch 29.967), train_loss = 0.91516582, grad/param norm = 1.7217e-01, time/batch = 16.8062s	
20169/33650 (epoch 29.969), train_loss = 0.87354595, grad/param norm = 1.3737e-01, time/batch = 16.9667s	
20170/33650 (epoch 29.970), train_loss = 0.89070386, grad/param norm = 1.5252e-01, time/batch = 18.6569s	
20171/33650 (epoch 29.972), train_loss = 1.17224657, grad/param norm = 1.8728e-01, time/batch = 18.6403s	
20172/33650 (epoch 29.973), train_loss = 0.79821247, grad/param norm = 1.2964e-01, time/batch = 16.5124s	
20173/33650 (epoch 29.975), train_loss = 0.78279678, grad/param norm = 1.3694e-01, time/batch = 16.8875s	
20174/33650 (epoch 29.976), train_loss = 0.80658588, grad/param norm = 1.3492e-01, time/batch = 17.4825s	
20175/33650 (epoch 29.978), train_loss = 0.81856189, grad/param norm = 1.4075e-01, time/batch = 16.9733s	
20176/33650 (epoch 29.979), train_loss = 0.86542364, grad/param norm = 1.6000e-01, time/batch = 17.4761s	
20177/33650 (epoch 29.981), train_loss = 0.83749290, grad/param norm = 1.3385e-01, time/batch = 17.9860s	
20178/33650 (epoch 29.982), train_loss = 0.89563950, grad/param norm = 1.5556e-01, time/batch = 17.4037s	
20179/33650 (epoch 29.984), train_loss = 0.74237931, grad/param norm = 1.4807e-01, time/batch = 17.5548s	
20180/33650 (epoch 29.985), train_loss = 0.79202750, grad/param norm = 1.6732e-01, time/batch = 17.8179s	
20181/33650 (epoch 29.987), train_loss = 0.88852607, grad/param norm = 1.5487e-01, time/batch = 18.4786s	
20182/33650 (epoch 29.988), train_loss = 0.84556211, grad/param norm = 1.7170e-01, time/batch = 20.4297s	
20183/33650 (epoch 29.990), train_loss = 1.03054818, grad/param norm = 1.8119e-01, time/batch = 20.0625s	
20184/33650 (epoch 29.991), train_loss = 0.89507747, grad/param norm = 1.4831e-01, time/batch = 20.7324s	
20185/33650 (epoch 29.993), train_loss = 0.89374695, grad/param norm = 1.6318e-01, time/batch = 19.4563s	
20186/33650 (epoch 29.994), train_loss = 0.88800176, grad/param norm = 1.5661e-01, time/batch = 22.0603s	
20187/33650 (epoch 29.996), train_loss = 0.83734774, grad/param norm = 1.5846e-01, time/batch = 22.1454s	
20188/33650 (epoch 29.997), train_loss = 0.94711329, grad/param norm = 1.7029e-01, time/batch = 19.4427s	
20189/33650 (epoch 29.999), train_loss = 0.80135614, grad/param norm = 1.4932e-01, time/batch = 20.1366s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
20190/33650 (epoch 30.000), train_loss = 0.96127798, grad/param norm = 1.7839e-01, time/batch = 20.8203s	
20191/33650 (epoch 30.001), train_loss = 1.00734804, grad/param norm = 1.6384e-01, time/batch = 21.9479s	
20192/33650 (epoch 30.003), train_loss = 1.01113064, grad/param norm = 1.9084e-01, time/batch = 23.7987s	
20193/33650 (epoch 30.004), train_loss = 0.92136140, grad/param norm = 1.6809e-01, time/batch = 20.9847s	
20194/33650 (epoch 30.006), train_loss = 0.86496665, grad/param norm = 1.4600e-01, time/batch = 22.1586s	
20195/33650 (epoch 30.007), train_loss = 0.93671565, grad/param norm = 1.5518e-01, time/batch = 22.0753s	
20196/33650 (epoch 30.009), train_loss = 0.83950527, grad/param norm = 1.5368e-01, time/batch = 19.8235s	
20197/33650 (epoch 30.010), train_loss = 0.98284736, grad/param norm = 1.7660e-01, time/batch = 22.5811s	
20198/33650 (epoch 30.012), train_loss = 0.83334172, grad/param norm = 1.3389e-01, time/batch = 22.6524s	
20199/33650 (epoch 30.013), train_loss = 0.89080542, grad/param norm = 1.8486e-01, time/batch = 21.1523s	
20200/33650 (epoch 30.015), train_loss = 0.87747054, grad/param norm = 1.6479e-01, time/batch = 22.7070s	
20201/33650 (epoch 30.016), train_loss = 0.79137806, grad/param norm = 1.5447e-01, time/batch = 23.3231s	
20202/33650 (epoch 30.018), train_loss = 0.86900253, grad/param norm = 1.8433e-01, time/batch = 17.6885s	
20203/33650 (epoch 30.019), train_loss = 0.84752714, grad/param norm = 1.7370e-01, time/batch = 18.6493s	
20204/33650 (epoch 30.021), train_loss = 0.93276731, grad/param norm = 1.5725e-01, time/batch = 17.4763s	
20205/33650 (epoch 30.022), train_loss = 0.85719721, grad/param norm = 1.5665e-01, time/batch = 16.7937s	
20206/33650 (epoch 30.024), train_loss = 0.81103155, grad/param norm = 1.8265e-01, time/batch = 18.5675s	
20207/33650 (epoch 30.025), train_loss = 0.89014147, grad/param norm = 1.6119e-01, time/batch = 15.9201s	
20208/33650 (epoch 30.027), train_loss = 0.92395336, grad/param norm = 2.0466e-01, time/batch = 15.5356s	
20209/33650 (epoch 30.028), train_loss = 0.94026418, grad/param norm = 1.5003e-01, time/batch = 16.8097s	
20210/33650 (epoch 30.030), train_loss = 0.88653397, grad/param norm = 2.0307e-01, time/batch = 16.1755s	
20211/33650 (epoch 30.031), train_loss = 0.80429139, grad/param norm = 1.3196e-01, time/batch = 14.3348s	
20212/33650 (epoch 30.033), train_loss = 0.89536504, grad/param norm = 1.3736e-01, time/batch = 14.6606s	
20213/33650 (epoch 30.034), train_loss = 0.90288516, grad/param norm = 1.5849e-01, time/batch = 14.9176s	
20214/33650 (epoch 30.036), train_loss = 1.01284654, grad/param norm = 1.7766e-01, time/batch = 17.7958s	
20215/33650 (epoch 30.037), train_loss = 0.83506812, grad/param norm = 1.3970e-01, time/batch = 17.3819s	
20216/33650 (epoch 30.039), train_loss = 0.96612821, grad/param norm = 1.5148e-01, time/batch = 17.3998s	
20217/33650 (epoch 30.040), train_loss = 1.05349652, grad/param norm = 1.8809e-01, time/batch = 17.1626s	
20218/33650 (epoch 30.042), train_loss = 1.07528618, grad/param norm = 1.7358e-01, time/batch = 15.9733s	
20219/33650 (epoch 30.043), train_loss = 0.85578421, grad/param norm = 1.4658e-01, time/batch = 17.1322s	
20220/33650 (epoch 30.045), train_loss = 0.85343050, grad/param norm = 1.5715e-01, time/batch = 15.8914s	
20221/33650 (epoch 30.046), train_loss = 0.93316199, grad/param norm = 1.5484e-01, time/batch = 14.1586s	
20222/33650 (epoch 30.048), train_loss = 0.96197412, grad/param norm = 1.5899e-01, time/batch = 18.4079s	
20223/33650 (epoch 30.049), train_loss = 0.86321780, grad/param norm = 1.6126e-01, time/batch = 17.6315s	
20224/33650 (epoch 30.051), train_loss = 1.03801654, grad/param norm = 2.0644e-01, time/batch = 17.7266s	
20225/33650 (epoch 30.052), train_loss = 1.04454141, grad/param norm = 2.0016e-01, time/batch = 16.3093s	
20226/33650 (epoch 30.053), train_loss = 0.95682422, grad/param norm = 1.4972e-01, time/batch = 16.9808s	
20227/33650 (epoch 30.055), train_loss = 0.81618718, grad/param norm = 1.5301e-01, time/batch = 17.3159s	
20228/33650 (epoch 30.056), train_loss = 0.78128849, grad/param norm = 1.2360e-01, time/batch = 18.0634s	
20229/33650 (epoch 30.058), train_loss = 0.96328710, grad/param norm = 1.8342e-01, time/batch = 16.8225s	
20230/33650 (epoch 30.059), train_loss = 0.95858586, grad/param norm = 1.6611e-01, time/batch = 17.9842s	
20231/33650 (epoch 30.061), train_loss = 0.99491855, grad/param norm = 1.6461e-01, time/batch = 17.4629s	
20232/33650 (epoch 30.062), train_loss = 0.95074090, grad/param norm = 1.5592e-01, time/batch = 19.1729s	
20233/33650 (epoch 30.064), train_loss = 0.87927892, grad/param norm = 1.5801e-01, time/batch = 16.6361s	
20234/33650 (epoch 30.065), train_loss = 0.87242083, grad/param norm = 1.6602e-01, time/batch = 17.1492s	
20235/33650 (epoch 30.067), train_loss = 0.78833174, grad/param norm = 1.3106e-01, time/batch = 18.9081s	
20236/33650 (epoch 30.068), train_loss = 0.89404238, grad/param norm = 1.5823e-01, time/batch = 16.5587s	
20237/33650 (epoch 30.070), train_loss = 0.96136287, grad/param norm = 1.5730e-01, time/batch = 17.9756s	
20238/33650 (epoch 30.071), train_loss = 0.87112021, grad/param norm = 2.1756e-01, time/batch = 17.1344s	
20239/33650 (epoch 30.073), train_loss = 0.95112852, grad/param norm = 1.7182e-01, time/batch = 17.6333s	
20240/33650 (epoch 30.074), train_loss = 1.00868542, grad/param norm = 1.5652e-01, time/batch = 17.2139s	
20241/33650 (epoch 30.076), train_loss = 0.98755787, grad/param norm = 1.7949e-01, time/batch = 18.9832s	
20242/33650 (epoch 30.077), train_loss = 0.89331555, grad/param norm = 1.5616e-01, time/batch = 16.0076s	
20243/33650 (epoch 30.079), train_loss = 0.94992914, grad/param norm = 1.4623e-01, time/batch = 15.7373s	
20244/33650 (epoch 30.080), train_loss = 0.94782110, grad/param norm = 1.6168e-01, time/batch = 15.2343s	
20245/33650 (epoch 30.082), train_loss = 0.89191385, grad/param norm = 1.4023e-01, time/batch = 15.1447s	
20246/33650 (epoch 30.083), train_loss = 0.93391739, grad/param norm = 1.6482e-01, time/batch = 15.6667s	
20247/33650 (epoch 30.085), train_loss = 0.99016330, grad/param norm = 1.5225e-01, time/batch = 15.3022s	
20248/33650 (epoch 30.086), train_loss = 0.96450660, grad/param norm = 1.6015e-01, time/batch = 14.3391s	
20249/33650 (epoch 30.088), train_loss = 0.91213635, grad/param norm = 1.6309e-01, time/batch = 14.4242s	
20250/33650 (epoch 30.089), train_loss = 0.85788496, grad/param norm = 1.5269e-01, time/batch = 14.2710s	
20251/33650 (epoch 30.091), train_loss = 0.87578753, grad/param norm = 1.3825e-01, time/batch = 14.8947s	
20252/33650 (epoch 30.092), train_loss = 0.89482914, grad/param norm = 1.7312e-01, time/batch = 14.5659s	
20253/33650 (epoch 30.094), train_loss = 0.96917696, grad/param norm = 1.4590e-01, time/batch = 14.5628s	
20254/33650 (epoch 30.095), train_loss = 0.95211002, grad/param norm = 2.0931e-01, time/batch = 14.3397s	
20255/33650 (epoch 30.097), train_loss = 0.85703608, grad/param norm = 1.7309e-01, time/batch = 14.5792s	
20256/33650 (epoch 30.098), train_loss = 0.73598047, grad/param norm = 1.5356e-01, time/batch = 14.5794s	
20257/33650 (epoch 30.100), train_loss = 0.83320736, grad/param norm = 1.5483e-01, time/batch = 14.5696s	
20258/33650 (epoch 30.101), train_loss = 0.89401029, grad/param norm = 1.7008e-01, time/batch = 14.4157s	
20259/33650 (epoch 30.103), train_loss = 0.90378997, grad/param norm = 1.6310e-01, time/batch = 14.5897s	
20260/33650 (epoch 30.104), train_loss = 1.01464303, grad/param norm = 1.5867e-01, time/batch = 14.5708s	
20261/33650 (epoch 30.105), train_loss = 0.91583151, grad/param norm = 1.6095e-01, time/batch = 14.5136s	
20262/33650 (epoch 30.107), train_loss = 0.86037528, grad/param norm = 1.5696e-01, time/batch = 14.8844s	
20263/33650 (epoch 30.108), train_loss = 0.95061574, grad/param norm = 1.8477e-01, time/batch = 14.5721s	
20264/33650 (epoch 30.110), train_loss = 1.04158756, grad/param norm = 1.5362e-01, time/batch = 14.6710s	
20265/33650 (epoch 30.111), train_loss = 0.88831944, grad/param norm = 1.6864e-01, time/batch = 14.3360s	
20266/33650 (epoch 30.113), train_loss = 0.85115708, grad/param norm = 1.6681e-01, time/batch = 14.3500s	
20267/33650 (epoch 30.114), train_loss = 0.96542770, grad/param norm = 1.5382e-01, time/batch = 14.4969s	
20268/33650 (epoch 30.116), train_loss = 0.82191144, grad/param norm = 1.2635e-01, time/batch = 14.6538s	
20269/33650 (epoch 30.117), train_loss = 0.88742823, grad/param norm = 1.3850e-01, time/batch = 14.3403s	
20270/33650 (epoch 30.119), train_loss = 0.81350769, grad/param norm = 1.3894e-01, time/batch = 14.1772s	
20271/33650 (epoch 30.120), train_loss = 0.84554553, grad/param norm = 1.5106e-01, time/batch = 14.5918s	
20272/33650 (epoch 30.122), train_loss = 0.69829849, grad/param norm = 1.6003e-01, time/batch = 14.5755s	
20273/33650 (epoch 30.123), train_loss = 0.84920839, grad/param norm = 1.3927e-01, time/batch = 14.4946s	
20274/33650 (epoch 30.125), train_loss = 0.95589918, grad/param norm = 1.7432e-01, time/batch = 14.1837s	
20275/33650 (epoch 30.126), train_loss = 0.99881116, grad/param norm = 2.2750e-01, time/batch = 15.0959s	
20276/33650 (epoch 30.128), train_loss = 0.95796028, grad/param norm = 1.8045e-01, time/batch = 15.1726s	
20277/33650 (epoch 30.129), train_loss = 0.98239896, grad/param norm = 1.6380e-01, time/batch = 14.6355s	
20278/33650 (epoch 30.131), train_loss = 0.92865653, grad/param norm = 1.7337e-01, time/batch = 14.3338s	
20279/33650 (epoch 30.132), train_loss = 0.91238763, grad/param norm = 1.5026e-01, time/batch = 14.4264s	
20280/33650 (epoch 30.134), train_loss = 0.98297443, grad/param norm = 1.6468e-01, time/batch = 14.9824s	
20281/33650 (epoch 30.135), train_loss = 0.81165175, grad/param norm = 1.7083e-01, time/batch = 14.3281s	
20282/33650 (epoch 30.137), train_loss = 0.94663074, grad/param norm = 1.7348e-01, time/batch = 14.4156s	
20283/33650 (epoch 30.138), train_loss = 0.96819097, grad/param norm = 1.5273e-01, time/batch = 14.3497s	
20284/33650 (epoch 30.140), train_loss = 0.91149948, grad/param norm = 1.7755e-01, time/batch = 14.9767s	
20285/33650 (epoch 30.141), train_loss = 1.04836391, grad/param norm = 1.7300e-01, time/batch = 14.3539s	
20286/33650 (epoch 30.143), train_loss = 1.05777359, grad/param norm = 2.1244e-01, time/batch = 14.3474s	
20287/33650 (epoch 30.144), train_loss = 0.95884266, grad/param norm = 1.7584e-01, time/batch = 14.1838s	
20288/33650 (epoch 30.146), train_loss = 0.89406319, grad/param norm = 1.6060e-01, time/batch = 14.9878s	
20289/33650 (epoch 30.147), train_loss = 0.84322453, grad/param norm = 1.5518e-01, time/batch = 14.1864s	
20290/33650 (epoch 30.149), train_loss = 0.80717588, grad/param norm = 1.5925e-01, time/batch = 14.5074s	
20291/33650 (epoch 30.150), train_loss = 0.77925468, grad/param norm = 1.4814e-01, time/batch = 14.2770s	
20292/33650 (epoch 30.152), train_loss = 0.85897871, grad/param norm = 1.6010e-01, time/batch = 14.9722s	
20293/33650 (epoch 30.153), train_loss = 0.87830693, grad/param norm = 1.6508e-01, time/batch = 14.5143s	
20294/33650 (epoch 30.155), train_loss = 0.82327481, grad/param norm = 1.3468e-01, time/batch = 14.5846s	
20295/33650 (epoch 30.156), train_loss = 0.81775076, grad/param norm = 1.4240e-01, time/batch = 14.5878s	
20296/33650 (epoch 30.158), train_loss = 0.92800625, grad/param norm = 1.7505e-01, time/batch = 14.8912s	
20297/33650 (epoch 30.159), train_loss = 0.82619402, grad/param norm = 1.3493e-01, time/batch = 14.4021s	
20298/33650 (epoch 30.160), train_loss = 0.82954176, grad/param norm = 1.3513e-01, time/batch = 14.3257s	
20299/33650 (epoch 30.162), train_loss = 0.85638151, grad/param norm = 1.6307e-01, time/batch = 14.0111s	
20300/33650 (epoch 30.163), train_loss = 0.93035675, grad/param norm = 1.7607e-01, time/batch = 14.4993s	
20301/33650 (epoch 30.165), train_loss = 0.79712481, grad/param norm = 1.4963e-01, time/batch = 14.4384s	
20302/33650 (epoch 30.166), train_loss = 0.80242806, grad/param norm = 1.5329e-01, time/batch = 14.4308s	
20303/33650 (epoch 30.168), train_loss = 0.99991447, grad/param norm = 1.6829e-01, time/batch = 14.4284s	
20304/33650 (epoch 30.169), train_loss = 0.90086036, grad/param norm = 1.6219e-01, time/batch = 14.5898s	
20305/33650 (epoch 30.171), train_loss = 0.88489423, grad/param norm = 1.3951e-01, time/batch = 14.5893s	
20306/33650 (epoch 30.172), train_loss = 0.83969569, grad/param norm = 1.5490e-01, time/batch = 14.3426s	
20307/33650 (epoch 30.174), train_loss = 0.80979560, grad/param norm = 1.9286e-01, time/batch = 15.2825s	
20308/33650 (epoch 30.175), train_loss = 0.78595211, grad/param norm = 1.9996e-01, time/batch = 15.2205s	
20309/33650 (epoch 30.177), train_loss = 0.88174164, grad/param norm = 1.6988e-01, time/batch = 21.3887s	
20310/33650 (epoch 30.178), train_loss = 0.84373878, grad/param norm = 1.7310e-01, time/batch = 22.0740s	
20311/33650 (epoch 30.180), train_loss = 0.80372550, grad/param norm = 1.6159e-01, time/batch = 14.3499s	
20312/33650 (epoch 30.181), train_loss = 0.71754318, grad/param norm = 1.2923e-01, time/batch = 14.7339s	
20313/33650 (epoch 30.183), train_loss = 0.82925127, grad/param norm = 1.8559e-01, time/batch = 14.5763s	
20314/33650 (epoch 30.184), train_loss = 0.81157012, grad/param norm = 1.8057e-01, time/batch = 14.2674s	
20315/33650 (epoch 30.186), train_loss = 0.87165330, grad/param norm = 1.8004e-01, time/batch = 14.1100s	
20316/33650 (epoch 30.187), train_loss = 1.00970223, grad/param norm = 1.7838e-01, time/batch = 14.5835s	
20317/33650 (epoch 30.189), train_loss = 0.98085068, grad/param norm = 1.9498e-01, time/batch = 14.3395s	
20318/33650 (epoch 30.190), train_loss = 0.91503954, grad/param norm = 1.7468e-01, time/batch = 14.4120s	
20319/33650 (epoch 30.192), train_loss = 1.05615994, grad/param norm = 1.6369e-01, time/batch = 14.4132s	
20320/33650 (epoch 30.193), train_loss = 1.02388676, grad/param norm = 1.5691e-01, time/batch = 14.7341s	
20321/33650 (epoch 30.195), train_loss = 0.76192191, grad/param norm = 1.3324e-01, time/batch = 14.2625s	
20322/33650 (epoch 30.196), train_loss = 0.75129673, grad/param norm = 1.7272e-01, time/batch = 14.4402s	
20323/33650 (epoch 30.198), train_loss = 0.87087872, grad/param norm = 1.5608e-01, time/batch = 14.2584s	
20324/33650 (epoch 30.199), train_loss = 0.96651400, grad/param norm = 1.6522e-01, time/batch = 14.8301s	
20325/33650 (epoch 30.201), train_loss = 0.84858876, grad/param norm = 1.7296e-01, time/batch = 14.7317s	
20326/33650 (epoch 30.202), train_loss = 0.87845264, grad/param norm = 1.5521e-01, time/batch = 14.2593s	
20327/33650 (epoch 30.204), train_loss = 0.92600629, grad/param norm = 1.6839e-01, time/batch = 14.1807s	
20328/33650 (epoch 30.205), train_loss = 0.86397929, grad/param norm = 1.5496e-01, time/batch = 14.8319s	
20329/33650 (epoch 30.207), train_loss = 0.82532613, grad/param norm = 1.7876e-01, time/batch = 14.7279s	
20330/33650 (epoch 30.208), train_loss = 0.92238606, grad/param norm = 1.5537e-01, time/batch = 15.0868s	
20331/33650 (epoch 30.210), train_loss = 0.72882011, grad/param norm = 1.5425e-01, time/batch = 14.5638s	
20332/33650 (epoch 30.211), train_loss = 0.83538357, grad/param norm = 1.9409e-01, time/batch = 14.6547s	
20333/33650 (epoch 30.212), train_loss = 0.92463041, grad/param norm = 2.0939e-01, time/batch = 14.7459s	
20334/33650 (epoch 30.214), train_loss = 1.06363855, grad/param norm = 1.6913e-01, time/batch = 14.3401s	
20335/33650 (epoch 30.215), train_loss = 0.68314736, grad/param norm = 1.4720e-01, time/batch = 14.0214s	
20336/33650 (epoch 30.217), train_loss = 0.87192750, grad/param norm = 1.8704e-01, time/batch = 14.5821s	
20337/33650 (epoch 30.218), train_loss = 0.87304236, grad/param norm = 1.5029e-01, time/batch = 14.3412s	
20338/33650 (epoch 30.220), train_loss = 0.78793878, grad/param norm = 1.6636e-01, time/batch = 16.2875s	
20339/33650 (epoch 30.221), train_loss = 1.05369446, grad/param norm = 1.9374e-01, time/batch = 19.4820s	
20340/33650 (epoch 30.223), train_loss = 0.73466494, grad/param norm = 1.8930e-01, time/batch = 17.2122s	
20341/33650 (epoch 30.224), train_loss = 0.82987615, grad/param norm = 1.7846e-01, time/batch = 16.3783s	
20342/33650 (epoch 30.226), train_loss = 1.16298321, grad/param norm = 1.8287e-01, time/batch = 18.7224s	
20343/33650 (epoch 30.227), train_loss = 0.99337480, grad/param norm = 1.8629e-01, time/batch = 17.3832s	
20344/33650 (epoch 30.229), train_loss = 0.99591859, grad/param norm = 1.8053e-01, time/batch = 17.8066s	
20345/33650 (epoch 30.230), train_loss = 1.12578578, grad/param norm = 2.1318e-01, time/batch = 17.1389s	
20346/33650 (epoch 30.232), train_loss = 0.98194867, grad/param norm = 2.1132e-01, time/batch = 14.6549s	
20347/33650 (epoch 30.233), train_loss = 0.94005168, grad/param norm = 1.7932e-01, time/batch = 16.6277s	
20348/33650 (epoch 30.235), train_loss = 0.87748999, grad/param norm = 1.4637e-01, time/batch = 19.3732s	
20349/33650 (epoch 30.236), train_loss = 0.82599248, grad/param norm = 1.4398e-01, time/batch = 17.0625s	
20350/33650 (epoch 30.238), train_loss = 0.85389655, grad/param norm = 1.4116e-01, time/batch = 15.9516s	
20351/33650 (epoch 30.239), train_loss = 0.82061889, grad/param norm = 1.7409e-01, time/batch = 16.7649s	
20352/33650 (epoch 30.241), train_loss = 0.86364493, grad/param norm = 1.4973e-01, time/batch = 16.2076s	
20353/33650 (epoch 30.242), train_loss = 0.71473758, grad/param norm = 1.4079e-01, time/batch = 16.1133s	
20354/33650 (epoch 30.244), train_loss = 0.87155128, grad/param norm = 1.5782e-01, time/batch = 16.2232s	
20355/33650 (epoch 30.245), train_loss = 0.76610057, grad/param norm = 1.3443e-01, time/batch = 16.2337s	
20356/33650 (epoch 30.247), train_loss = 0.87222115, grad/param norm = 1.4991e-01, time/batch = 18.8871s	
20357/33650 (epoch 30.248), train_loss = 0.78771524, grad/param norm = 1.4063e-01, time/batch = 16.5600s	
20358/33650 (epoch 30.250), train_loss = 0.87284114, grad/param norm = 1.4965e-01, time/batch = 17.8949s	
20359/33650 (epoch 30.251), train_loss = 0.99073037, grad/param norm = 1.5078e-01, time/batch = 15.8077s	
20360/33650 (epoch 30.253), train_loss = 0.77194531, grad/param norm = 1.4890e-01, time/batch = 17.5563s	
20361/33650 (epoch 30.254), train_loss = 0.83605552, grad/param norm = 1.6887e-01, time/batch = 17.2254s	
20362/33650 (epoch 30.256), train_loss = 1.01645637, grad/param norm = 1.4637e-01, time/batch = 18.7270s	
20363/33650 (epoch 30.257), train_loss = 0.99522498, grad/param norm = 1.6161e-01, time/batch = 18.2254s	
20364/33650 (epoch 30.259), train_loss = 0.79603222, grad/param norm = 1.5513e-01, time/batch = 17.5599s	
20365/33650 (epoch 30.260), train_loss = 0.92674244, grad/param norm = 1.5102e-01, time/batch = 17.3906s	
20366/33650 (epoch 30.262), train_loss = 0.91328558, grad/param norm = 1.9691e-01, time/batch = 17.8792s	
20367/33650 (epoch 30.263), train_loss = 0.85665326, grad/param norm = 2.1711e-01, time/batch = 18.3826s	
20368/33650 (epoch 30.264), train_loss = 0.94226215, grad/param norm = 1.8010e-01, time/batch = 17.2217s	
20369/33650 (epoch 30.266), train_loss = 0.91650379, grad/param norm = 1.4734e-01, time/batch = 18.0624s	
20370/33650 (epoch 30.267), train_loss = 0.84237974, grad/param norm = 1.6057e-01, time/batch = 18.4774s	
20371/33650 (epoch 30.269), train_loss = 0.90169711, grad/param norm = 1.5505e-01, time/batch = 17.2961s	
20372/33650 (epoch 30.270), train_loss = 0.80869861, grad/param norm = 1.4780e-01, time/batch = 17.8730s	
20373/33650 (epoch 30.272), train_loss = 0.84869475, grad/param norm = 1.5513e-01, time/batch = 15.9694s	
20374/33650 (epoch 30.273), train_loss = 0.98710590, grad/param norm = 1.9919e-01, time/batch = 17.2902s	
20375/33650 (epoch 30.275), train_loss = 0.93490717, grad/param norm = 1.6569e-01, time/batch = 17.1531s	
20376/33650 (epoch 30.276), train_loss = 0.97825038, grad/param norm = 2.0118e-01, time/batch = 18.3960s	
20377/33650 (epoch 30.278), train_loss = 1.07560837, grad/param norm = 2.0248e-01, time/batch = 17.3941s	
20378/33650 (epoch 30.279), train_loss = 0.87753819, grad/param norm = 1.7236e-01, time/batch = 17.2141s	
20379/33650 (epoch 30.281), train_loss = 0.91275139, grad/param norm = 1.8609e-01, time/batch = 17.5679s	
20380/33650 (epoch 30.282), train_loss = 1.00646094, grad/param norm = 1.3216e-01, time/batch = 18.1453s	
20381/33650 (epoch 30.284), train_loss = 0.96325547, grad/param norm = 1.6598e-01, time/batch = 17.2916s	
20382/33650 (epoch 30.285), train_loss = 0.93179118, grad/param norm = 1.7156e-01, time/batch = 17.0673s	
20383/33650 (epoch 30.287), train_loss = 0.85724176, grad/param norm = 1.5897e-01, time/batch = 17.8858s	
20384/33650 (epoch 30.288), train_loss = 0.90136938, grad/param norm = 1.7552e-01, time/batch = 17.6329s	
20385/33650 (epoch 30.290), train_loss = 0.89778809, grad/param norm = 1.5260e-01, time/batch = 17.3902s	
20386/33650 (epoch 30.291), train_loss = 0.81336146, grad/param norm = 1.4935e-01, time/batch = 17.5656s	
20387/33650 (epoch 30.293), train_loss = 0.89217477, grad/param norm = 1.8612e-01, time/batch = 18.5586s	
20388/33650 (epoch 30.294), train_loss = 0.81143870, grad/param norm = 1.3627e-01, time/batch = 17.3858s	
20389/33650 (epoch 30.296), train_loss = 0.79915789, grad/param norm = 1.4882e-01, time/batch = 17.1386s	
20390/33650 (epoch 30.297), train_loss = 0.85919934, grad/param norm = 1.5121e-01, time/batch = 16.8238s	
20391/33650 (epoch 30.299), train_loss = 0.77824408, grad/param norm = 1.6474e-01, time/batch = 17.3001s	
20392/33650 (epoch 30.300), train_loss = 0.80558448, grad/param norm = 1.5542e-01, time/batch = 17.7987s	
20393/33650 (epoch 30.302), train_loss = 0.90552393, grad/param norm = 1.5648e-01, time/batch = 17.8835s	
20394/33650 (epoch 30.303), train_loss = 0.92155383, grad/param norm = 1.5157e-01, time/batch = 17.6552s	
20395/33650 (epoch 30.305), train_loss = 0.87813470, grad/param norm = 1.4907e-01, time/batch = 16.7947s	
20396/33650 (epoch 30.306), train_loss = 0.81601837, grad/param norm = 1.3101e-01, time/batch = 16.1399s	
20397/33650 (epoch 30.308), train_loss = 0.78627795, grad/param norm = 1.5858e-01, time/batch = 18.9615s	
20398/33650 (epoch 30.309), train_loss = 1.03148003, grad/param norm = 1.8706e-01, time/batch = 16.6448s	
20399/33650 (epoch 30.311), train_loss = 0.88504834, grad/param norm = 1.7309e-01, time/batch = 18.3982s	
20400/33650 (epoch 30.312), train_loss = 0.92666521, grad/param norm = 1.7455e-01, time/batch = 17.8891s	
20401/33650 (epoch 30.314), train_loss = 0.81288136, grad/param norm = 1.4609e-01, time/batch = 17.8027s	
20402/33650 (epoch 30.315), train_loss = 0.87941873, grad/param norm = 2.0087e-01, time/batch = 17.6249s	
20403/33650 (epoch 30.316), train_loss = 0.84285826, grad/param norm = 1.7766e-01, time/batch = 17.7283s	
20404/33650 (epoch 30.318), train_loss = 0.79003553, grad/param norm = 1.4695e-01, time/batch = 18.9777s	
20405/33650 (epoch 30.319), train_loss = 0.82335947, grad/param norm = 1.4025e-01, time/batch = 15.7293s	
20406/33650 (epoch 30.321), train_loss = 0.84430830, grad/param norm = 1.3586e-01, time/batch = 17.8927s	
20407/33650 (epoch 30.322), train_loss = 0.90587754, grad/param norm = 1.9189e-01, time/batch = 18.8837s	
20408/33650 (epoch 30.324), train_loss = 0.94535064, grad/param norm = 1.9799e-01, time/batch = 16.3584s	
20409/33650 (epoch 30.325), train_loss = 0.93497487, grad/param norm = 1.8171e-01, time/batch = 17.9722s	
20410/33650 (epoch 30.327), train_loss = 0.82776976, grad/param norm = 1.4717e-01, time/batch = 16.7108s	
20411/33650 (epoch 30.328), train_loss = 0.91656894, grad/param norm = 1.6864e-01, time/batch = 17.7274s	
20412/33650 (epoch 30.330), train_loss = 0.83243797, grad/param norm = 1.4898e-01, time/batch = 15.7926s	
20413/33650 (epoch 30.331), train_loss = 0.76948300, grad/param norm = 1.3323e-01, time/batch = 17.8330s	
20414/33650 (epoch 30.333), train_loss = 0.87294269, grad/param norm = 1.7367e-01, time/batch = 18.1453s	
20415/33650 (epoch 30.334), train_loss = 0.87746694, grad/param norm = 1.5014e-01, time/batch = 16.7259s	
20416/33650 (epoch 30.336), train_loss = 0.96610820, grad/param norm = 1.5434e-01, time/batch = 18.5532s	
20417/33650 (epoch 30.337), train_loss = 0.74540814, grad/param norm = 1.3091e-01, time/batch = 18.3890s	
20418/33650 (epoch 30.339), train_loss = 0.83643831, grad/param norm = 1.4588e-01, time/batch = 18.1370s	
20419/33650 (epoch 30.340), train_loss = 0.98520077, grad/param norm = 1.8048e-01, time/batch = 18.4721s	
20420/33650 (epoch 30.342), train_loss = 0.73084768, grad/param norm = 1.5040e-01, time/batch = 16.1441s	
20421/33650 (epoch 30.343), train_loss = 0.93097069, grad/param norm = 1.6915e-01, time/batch = 19.2265s	
20422/33650 (epoch 30.345), train_loss = 0.89401453, grad/param norm = 1.6706e-01, time/batch = 17.1464s	
20423/33650 (epoch 30.346), train_loss = 0.61578971, grad/param norm = 1.3477e-01, time/batch = 17.6463s	
20424/33650 (epoch 30.348), train_loss = 0.77280064, grad/param norm = 1.5553e-01, time/batch = 17.4007s	
20425/33650 (epoch 30.349), train_loss = 0.73095277, grad/param norm = 1.5483e-01, time/batch = 14.6134s	
20426/33650 (epoch 30.351), train_loss = 0.92898359, grad/param norm = 1.6306e-01, time/batch = 14.7708s	
20427/33650 (epoch 30.352), train_loss = 0.85558680, grad/param norm = 1.5979e-01, time/batch = 14.9359s	
20428/33650 (epoch 30.354), train_loss = 0.99411957, grad/param norm = 1.8568e-01, time/batch = 14.5022s	
20429/33650 (epoch 30.355), train_loss = 1.01518549, grad/param norm = 1.5578e-01, time/batch = 15.3590s	
20430/33650 (epoch 30.357), train_loss = 0.72283996, grad/param norm = 1.3495e-01, time/batch = 17.8852s	
20431/33650 (epoch 30.358), train_loss = 0.92188941, grad/param norm = 1.6837e-01, time/batch = 18.3031s	
20432/33650 (epoch 30.360), train_loss = 0.94636435, grad/param norm = 1.8073e-01, time/batch = 17.9676s	
20433/33650 (epoch 30.361), train_loss = 0.90121285, grad/param norm = 1.5699e-01, time/batch = 16.9669s	
20434/33650 (epoch 30.363), train_loss = 0.88656894, grad/param norm = 1.4272e-01, time/batch = 17.7251s	
20435/33650 (epoch 30.364), train_loss = 0.88606558, grad/param norm = 1.4833e-01, time/batch = 19.1357s	
20436/33650 (epoch 30.366), train_loss = 0.94607555, grad/param norm = 1.7264e-01, time/batch = 16.6158s	
20437/33650 (epoch 30.367), train_loss = 0.91878019, grad/param norm = 1.5352e-01, time/batch = 18.8011s	
20438/33650 (epoch 30.368), train_loss = 0.83025705, grad/param norm = 1.3954e-01, time/batch = 18.7277s	
20439/33650 (epoch 30.370), train_loss = 0.88394686, grad/param norm = 1.6358e-01, time/batch = 17.8119s	
20440/33650 (epoch 30.371), train_loss = 0.68908027, grad/param norm = 1.3596e-01, time/batch = 17.6360s	
20441/33650 (epoch 30.373), train_loss = 0.78970519, grad/param norm = 1.5036e-01, time/batch = 16.9609s	
20442/33650 (epoch 30.374), train_loss = 0.80441974, grad/param norm = 1.3540e-01, time/batch = 17.8042s	
20443/33650 (epoch 30.376), train_loss = 0.87092190, grad/param norm = 1.8570e-01, time/batch = 16.9328s	
20444/33650 (epoch 30.377), train_loss = 0.89922563, grad/param norm = 1.5959e-01, time/batch = 18.6372s	
20445/33650 (epoch 30.379), train_loss = 0.90829500, grad/param norm = 1.6246e-01, time/batch = 16.4579s	
20446/33650 (epoch 30.380), train_loss = 0.73253893, grad/param norm = 1.8496e-01, time/batch = 17.1313s	
20447/33650 (epoch 30.382), train_loss = 0.88154796, grad/param norm = 1.3712e-01, time/batch = 17.5499s	
20448/33650 (epoch 30.383), train_loss = 0.87056325, grad/param norm = 1.6252e-01, time/batch = 17.9815s	
20449/33650 (epoch 30.385), train_loss = 0.92317050, grad/param norm = 1.4995e-01, time/batch = 17.9724s	
20450/33650 (epoch 30.386), train_loss = 0.82383480, grad/param norm = 1.5743e-01, time/batch = 17.5334s	
20451/33650 (epoch 30.388), train_loss = 0.95716589, grad/param norm = 1.6063e-01, time/batch = 17.8262s	
20452/33650 (epoch 30.389), train_loss = 0.83436283, grad/param norm = 1.5285e-01, time/batch = 18.3004s	
20453/33650 (epoch 30.391), train_loss = 0.70360229, grad/param norm = 1.3489e-01, time/batch = 16.5375s	
20454/33650 (epoch 30.392), train_loss = 0.90169685, grad/param norm = 1.5482e-01, time/batch = 17.5633s	
20455/33650 (epoch 30.394), train_loss = 0.88923672, grad/param norm = 1.7494e-01, time/batch = 17.5493s	
20456/33650 (epoch 30.395), train_loss = 0.90735080, grad/param norm = 1.4239e-01, time/batch = 18.0605s	
20457/33650 (epoch 30.397), train_loss = 1.02251819, grad/param norm = 1.5536e-01, time/batch = 16.1135s	
20458/33650 (epoch 30.398), train_loss = 0.94400044, grad/param norm = 1.5108e-01, time/batch = 16.1988s	
20459/33650 (epoch 30.400), train_loss = 0.89221868, grad/param norm = 1.9086e-01, time/batch = 18.3910s	
20460/33650 (epoch 30.401), train_loss = 0.81736914, grad/param norm = 1.5594e-01, time/batch = 16.2286s	
20461/33650 (epoch 30.403), train_loss = 0.92701953, grad/param norm = 1.6834e-01, time/batch = 18.1396s	
20462/33650 (epoch 30.404), train_loss = 0.86246107, grad/param norm = 1.4772e-01, time/batch = 18.2984s	
20463/33650 (epoch 30.406), train_loss = 0.84973317, grad/param norm = 1.4278e-01, time/batch = 17.8832s	
20464/33650 (epoch 30.407), train_loss = 0.88721055, grad/param norm = 1.8420e-01, time/batch = 17.3120s	
20465/33650 (epoch 30.409), train_loss = 0.91748683, grad/param norm = 1.5666e-01, time/batch = 17.2361s	
20466/33650 (epoch 30.410), train_loss = 0.86097899, grad/param norm = 1.5356e-01, time/batch = 18.6301s	
20467/33650 (epoch 30.412), train_loss = 0.87315003, grad/param norm = 1.3607e-01, time/batch = 17.7060s	
20468/33650 (epoch 30.413), train_loss = 0.81404011, grad/param norm = 1.8726e-01, time/batch = 17.9787s	
20469/33650 (epoch 30.415), train_loss = 0.95022795, grad/param norm = 1.7676e-01, time/batch = 18.2220s	
20470/33650 (epoch 30.416), train_loss = 1.03767547, grad/param norm = 1.7648e-01, time/batch = 15.4651s	
20471/33650 (epoch 30.418), train_loss = 0.81365548, grad/param norm = 1.5769e-01, time/batch = 17.9524s	
20472/33650 (epoch 30.419), train_loss = 0.84162958, grad/param norm = 1.6203e-01, time/batch = 18.1458s	
20473/33650 (epoch 30.421), train_loss = 0.85385138, grad/param norm = 1.4200e-01, time/batch = 17.8937s	
20474/33650 (epoch 30.422), train_loss = 1.00036651, grad/param norm = 1.6160e-01, time/batch = 17.1477s	
20475/33650 (epoch 30.423), train_loss = 0.79786200, grad/param norm = 1.1946e-01, time/batch = 16.7794s	
20476/33650 (epoch 30.425), train_loss = 0.90789428, grad/param norm = 1.8156e-01, time/batch = 18.5506s	
20477/33650 (epoch 30.426), train_loss = 0.99292974, grad/param norm = 1.8700e-01, time/batch = 17.0459s	
20478/33650 (epoch 30.428), train_loss = 0.84521969, grad/param norm = 1.5282e-01, time/batch = 18.6416s	
20479/33650 (epoch 30.429), train_loss = 0.93481032, grad/param norm = 1.6863e-01, time/batch = 16.8725s	
20480/33650 (epoch 30.431), train_loss = 1.05466800, grad/param norm = 1.9840e-01, time/batch = 17.3834s	
20481/33650 (epoch 30.432), train_loss = 1.05469933, grad/param norm = 1.9453e-01, time/batch = 18.4737s	
20482/33650 (epoch 30.434), train_loss = 0.90848219, grad/param norm = 1.5016e-01, time/batch = 18.3927s	
20483/33650 (epoch 30.435), train_loss = 0.89529813, grad/param norm = 1.6669e-01, time/batch = 17.3915s	
20484/33650 (epoch 30.437), train_loss = 0.90559413, grad/param norm = 1.6134e-01, time/batch = 16.8801s	
20485/33650 (epoch 30.438), train_loss = 0.86049191, grad/param norm = 1.5695e-01, time/batch = 18.5704s	
20486/33650 (epoch 30.440), train_loss = 0.88957714, grad/param norm = 1.7205e-01, time/batch = 17.1307s	
20487/33650 (epoch 30.441), train_loss = 0.87403187, grad/param norm = 1.6196e-01, time/batch = 16.4586s	
20488/33650 (epoch 30.443), train_loss = 0.95547381, grad/param norm = 1.5967e-01, time/batch = 17.4632s	
20489/33650 (epoch 30.444), train_loss = 0.87055219, grad/param norm = 1.6261e-01, time/batch = 18.3171s	
20490/33650 (epoch 30.446), train_loss = 0.94348849, grad/param norm = 1.8643e-01, time/batch = 17.8911s	
20491/33650 (epoch 30.447), train_loss = 1.00291340, grad/param norm = 1.6898e-01, time/batch = 17.8106s	
20492/33650 (epoch 30.449), train_loss = 1.01925823, grad/param norm = 1.7374e-01, time/batch = 17.6421s	
20493/33650 (epoch 30.450), train_loss = 1.05222953, grad/param norm = 1.6542e-01, time/batch = 18.9703s	
20494/33650 (epoch 30.452), train_loss = 1.02071721, grad/param norm = 2.0742e-01, time/batch = 16.7740s	
20495/33650 (epoch 30.453), train_loss = 1.05746179, grad/param norm = 2.0577e-01, time/batch = 17.5628s	
20496/33650 (epoch 30.455), train_loss = 0.87790141, grad/param norm = 1.5395e-01, time/batch = 17.6426s	
20497/33650 (epoch 30.456), train_loss = 0.90443621, grad/param norm = 1.7194e-01, time/batch = 17.4706s	
20498/33650 (epoch 30.458), train_loss = 0.86810870, grad/param norm = 1.5567e-01, time/batch = 18.3873s	
20499/33650 (epoch 30.459), train_loss = 0.92808641, grad/param norm = 1.7337e-01, time/batch = 17.6532s	
20500/33650 (epoch 30.461), train_loss = 1.00156561, grad/param norm = 1.8487e-01, time/batch = 17.9732s	
20501/33650 (epoch 30.462), train_loss = 0.99170213, grad/param norm = 1.7409e-01, time/batch = 17.7257s	
20502/33650 (epoch 30.464), train_loss = 0.87252593, grad/param norm = 1.7917e-01, time/batch = 17.4632s	
20503/33650 (epoch 30.465), train_loss = 0.92660449, grad/param norm = 1.5979e-01, time/batch = 18.2259s	
20504/33650 (epoch 30.467), train_loss = 0.93772524, grad/param norm = 1.5566e-01, time/batch = 16.0604s	
20505/33650 (epoch 30.468), train_loss = 1.04742785, grad/param norm = 1.5997e-01, time/batch = 18.2262s	
20506/33650 (epoch 30.470), train_loss = 1.08834903, grad/param norm = 1.7481e-01, time/batch = 17.4681s	
20507/33650 (epoch 30.471), train_loss = 0.88729379, grad/param norm = 1.5040e-01, time/batch = 15.9645s	
20508/33650 (epoch 30.473), train_loss = 0.86457706, grad/param norm = 1.4685e-01, time/batch = 17.9796s	
20509/33650 (epoch 30.474), train_loss = 1.00640826, grad/param norm = 1.7213e-01, time/batch = 17.5459s	
20510/33650 (epoch 30.475), train_loss = 0.96668235, grad/param norm = 1.6731e-01, time/batch = 16.3066s	
20511/33650 (epoch 30.477), train_loss = 1.00561220, grad/param norm = 1.7072e-01, time/batch = 16.3039s	
20512/33650 (epoch 30.478), train_loss = 1.01481386, grad/param norm = 1.9659e-01, time/batch = 18.5646s	
20513/33650 (epoch 30.480), train_loss = 0.99855519, grad/param norm = 2.0160e-01, time/batch = 18.5500s	
20514/33650 (epoch 30.481), train_loss = 1.03325383, grad/param norm = 1.7189e-01, time/batch = 16.6273s	
20515/33650 (epoch 30.483), train_loss = 0.77111191, grad/param norm = 1.4541e-01, time/batch = 18.3906s	
20516/33650 (epoch 30.484), train_loss = 0.87733306, grad/param norm = 1.6637e-01, time/batch = 17.8161s	
20517/33650 (epoch 30.486), train_loss = 1.04873985, grad/param norm = 1.8576e-01, time/batch = 17.5629s	
20518/33650 (epoch 30.487), train_loss = 1.02216346, grad/param norm = 1.7381e-01, time/batch = 31.6218s	
20519/33650 (epoch 30.489), train_loss = 1.07244062, grad/param norm = 1.7472e-01, time/batch = 18.1394s	
20520/33650 (epoch 30.490), train_loss = 0.83237987, grad/param norm = 1.5511e-01, time/batch = 16.7222s	
20521/33650 (epoch 30.492), train_loss = 0.97435218, grad/param norm = 1.7301e-01, time/batch = 17.7808s	
20522/33650 (epoch 30.493), train_loss = 0.76648398, grad/param norm = 1.3677e-01, time/batch = 17.9679s	
20523/33650 (epoch 30.495), train_loss = 0.94469629, grad/param norm = 1.7397e-01, time/batch = 18.1403s	
20524/33650 (epoch 30.496), train_loss = 0.96378987, grad/param norm = 1.7291e-01, time/batch = 17.6298s	
20525/33650 (epoch 30.498), train_loss = 0.84083400, grad/param norm = 1.4856e-01, time/batch = 16.9628s	
20526/33650 (epoch 30.499), train_loss = 0.90904548, grad/param norm = 1.4247e-01, time/batch = 18.4807s	
20527/33650 (epoch 30.501), train_loss = 0.91193034, grad/param norm = 1.4641e-01, time/batch = 16.5521s	
20528/33650 (epoch 30.502), train_loss = 0.94938470, grad/param norm = 1.7939e-01, time/batch = 17.2968s	
20529/33650 (epoch 30.504), train_loss = 0.99961297, grad/param norm = 1.7869e-01, time/batch = 18.0682s	
20530/33650 (epoch 30.505), train_loss = 0.88884893, grad/param norm = 1.8097e-01, time/batch = 17.1270s	
20531/33650 (epoch 30.507), train_loss = 1.02148007, grad/param norm = 1.6663e-01, time/batch = 16.6455s	
20532/33650 (epoch 30.508), train_loss = 0.90010682, grad/param norm = 1.5990e-01, time/batch = 17.5713s	
20533/33650 (epoch 30.510), train_loss = 0.92079842, grad/param norm = 1.6753e-01, time/batch = 18.0705s	
20534/33650 (epoch 30.511), train_loss = 1.07190364, grad/param norm = 1.9704e-01, time/batch = 16.1930s	
20535/33650 (epoch 30.513), train_loss = 0.96382054, grad/param norm = 1.6436e-01, time/batch = 18.8807s	
20536/33650 (epoch 30.514), train_loss = 1.00314190, grad/param norm = 1.7911e-01, time/batch = 18.3091s	
20537/33650 (epoch 30.516), train_loss = 0.92237270, grad/param norm = 1.8862e-01, time/batch = 17.2303s	
20538/33650 (epoch 30.517), train_loss = 0.94302961, grad/param norm = 1.8594e-01, time/batch = 18.5591s	
20539/33650 (epoch 30.519), train_loss = 0.98158090, grad/param norm = 1.7966e-01, time/batch = 18.0571s	
20540/33650 (epoch 30.520), train_loss = 0.79614223, grad/param norm = 1.3403e-01, time/batch = 18.3067s	
20541/33650 (epoch 30.522), train_loss = 0.92345977, grad/param norm = 1.6757e-01, time/batch = 17.7331s	
20542/33650 (epoch 30.523), train_loss = 0.84658831, grad/param norm = 1.5094e-01, time/batch = 16.8907s	
20543/33650 (epoch 30.525), train_loss = 0.72992097, grad/param norm = 1.3085e-01, time/batch = 17.1215s	
20544/33650 (epoch 30.526), train_loss = 1.02533402, grad/param norm = 1.5398e-01, time/batch = 16.4754s	
20545/33650 (epoch 30.527), train_loss = 0.85013216, grad/param norm = 1.6223e-01, time/batch = 18.3126s	
20546/33650 (epoch 30.529), train_loss = 0.92880668, grad/param norm = 1.7289e-01, time/batch = 17.8957s	
20547/33650 (epoch 30.530), train_loss = 0.85410705, grad/param norm = 1.5716e-01, time/batch = 17.4002s	
20548/33650 (epoch 30.532), train_loss = 1.00203226, grad/param norm = 1.8942e-01, time/batch = 17.6437s	
20549/33650 (epoch 30.533), train_loss = 0.91880384, grad/param norm = 1.5727e-01, time/batch = 18.8169s	
20550/33650 (epoch 30.535), train_loss = 1.03732911, grad/param norm = 1.6610e-01, time/batch = 17.3951s	
20551/33650 (epoch 30.536), train_loss = 0.94245180, grad/param norm = 2.2321e-01, time/batch = 18.1290s	
20552/33650 (epoch 30.538), train_loss = 0.95499821, grad/param norm = 1.7465e-01, time/batch = 18.4842s	
20553/33650 (epoch 30.539), train_loss = 0.73009202, grad/param norm = 1.4655e-01, time/batch = 18.0623s	
20554/33650 (epoch 30.541), train_loss = 1.00359649, grad/param norm = 1.9301e-01, time/batch = 16.9665s	
20555/33650 (epoch 30.542), train_loss = 0.93055170, grad/param norm = 2.3458e-01, time/batch = 18.3963s	
20556/33650 (epoch 30.544), train_loss = 1.06458237, grad/param norm = 2.3352e-01, time/batch = 17.5330s	
20557/33650 (epoch 30.545), train_loss = 0.83000493, grad/param norm = 1.6183e-01, time/batch = 17.4756s	
20558/33650 (epoch 30.547), train_loss = 0.94827651, grad/param norm = 1.6585e-01, time/batch = 17.7259s	
20559/33650 (epoch 30.548), train_loss = 1.07719089, grad/param norm = 1.6886e-01, time/batch = 16.8115s	
20560/33650 (epoch 30.550), train_loss = 0.94233389, grad/param norm = 1.6891e-01, time/batch = 16.9776s	
20561/33650 (epoch 30.551), train_loss = 0.94199865, grad/param norm = 1.7680e-01, time/batch = 17.5451s	
20562/33650 (epoch 30.553), train_loss = 0.79030651, grad/param norm = 1.4499e-01, time/batch = 18.4827s	
20563/33650 (epoch 30.554), train_loss = 1.07907538, grad/param norm = 1.8130e-01, time/batch = 17.9707s	
20564/33650 (epoch 30.556), train_loss = 1.01085083, grad/param norm = 2.7344e-01, time/batch = 16.9761s	
20565/33650 (epoch 30.557), train_loss = 1.00730520, grad/param norm = 2.1240e-01, time/batch = 17.9857s	
20566/33650 (epoch 30.559), train_loss = 1.17331707, grad/param norm = 1.8362e-01, time/batch = 17.6388s	
20567/33650 (epoch 30.560), train_loss = 1.10856495, grad/param norm = 2.0685e-01, time/batch = 18.1999s	
20568/33650 (epoch 30.562), train_loss = 1.06569195, grad/param norm = 1.6356e-01, time/batch = 17.6262s	
20569/33650 (epoch 30.563), train_loss = 0.96969790, grad/param norm = 1.7031e-01, time/batch = 17.8156s	
20570/33650 (epoch 30.565), train_loss = 0.94961635, grad/param norm = 1.6354e-01, time/batch = 18.8107s	
20571/33650 (epoch 30.566), train_loss = 0.92272370, grad/param norm = 1.9790e-01, time/batch = 18.0481s	
20572/33650 (epoch 30.568), train_loss = 0.93699821, grad/param norm = 1.7975e-01, time/batch = 19.2117s	
20573/33650 (epoch 30.569), train_loss = 0.84297673, grad/param norm = 1.3904e-01, time/batch = 17.9766s	
20574/33650 (epoch 30.571), train_loss = 1.03473171, grad/param norm = 1.7573e-01, time/batch = 17.0503s	
20575/33650 (epoch 30.572), train_loss = 0.98180390, grad/param norm = 1.5618e-01, time/batch = 18.5511s	
20576/33650 (epoch 30.574), train_loss = 0.86151447, grad/param norm = 1.8600e-01, time/batch = 17.3753s	
20577/33650 (epoch 30.575), train_loss = 0.92237709, grad/param norm = 1.6548e-01, time/batch = 17.9661s	
20578/33650 (epoch 30.577), train_loss = 0.87028113, grad/param norm = 1.8835e-01, time/batch = 15.0287s	
20579/33650 (epoch 30.578), train_loss = 1.03804519, grad/param norm = 1.9794e-01, time/batch = 18.6500s	
20580/33650 (epoch 30.579), train_loss = 0.98399420, grad/param norm = 1.6616e-01, time/batch = 17.3337s	
20581/33650 (epoch 30.581), train_loss = 1.06476039, grad/param norm = 1.8378e-01, time/batch = 16.8725s	
20582/33650 (epoch 30.582), train_loss = 0.95781081, grad/param norm = 1.4045e-01, time/batch = 18.3888s	
20583/33650 (epoch 30.584), train_loss = 0.94387365, grad/param norm = 1.5588e-01, time/batch = 18.8887s	
20584/33650 (epoch 30.585), train_loss = 0.98617095, grad/param norm = 1.9846e-01, time/batch = 16.2119s	
20585/33650 (epoch 30.587), train_loss = 0.86806951, grad/param norm = 1.7950e-01, time/batch = 17.4745s	
20586/33650 (epoch 30.588), train_loss = 0.87223979, grad/param norm = 1.9633e-01, time/batch = 18.8085s	
20587/33650 (epoch 30.590), train_loss = 0.88321832, grad/param norm = 1.4457e-01, time/batch = 17.8154s	
20588/33650 (epoch 30.591), train_loss = 0.82989185, grad/param norm = 1.6650e-01, time/batch = 17.3835s	
20589/33650 (epoch 30.593), train_loss = 0.83493326, grad/param norm = 1.4933e-01, time/batch = 18.3934s	
20590/33650 (epoch 30.594), train_loss = 0.81829319, grad/param norm = 1.5722e-01, time/batch = 18.7225s	
20591/33650 (epoch 30.596), train_loss = 0.90974512, grad/param norm = 1.5260e-01, time/batch = 16.9692s	
20592/33650 (epoch 30.597), train_loss = 0.78013526, grad/param norm = 1.3552e-01, time/batch = 17.4759s	
20593/33650 (epoch 30.599), train_loss = 0.90232848, grad/param norm = 1.5399e-01, time/batch = 17.4802s	
20594/33650 (epoch 30.600), train_loss = 0.84635345, grad/param norm = 1.5525e-01, time/batch = 17.4749s	
20595/33650 (epoch 30.602), train_loss = 0.92413227, grad/param norm = 1.5414e-01, time/batch = 16.9682s	
20596/33650 (epoch 30.603), train_loss = 0.85298699, grad/param norm = 1.5747e-01, time/batch = 18.1434s	
20597/33650 (epoch 30.605), train_loss = 0.98754669, grad/param norm = 1.6181e-01, time/batch = 17.0626s	
20598/33650 (epoch 30.606), train_loss = 0.93301561, grad/param norm = 1.9256e-01, time/batch = 17.2190s	
20599/33650 (epoch 30.608), train_loss = 0.83308002, grad/param norm = 1.8757e-01, time/batch = 18.3905s	
20600/33650 (epoch 30.609), train_loss = 0.90724194, grad/param norm = 1.5312e-01, time/batch = 17.9913s	
20601/33650 (epoch 30.611), train_loss = 0.80388000, grad/param norm = 1.5281e-01, time/batch = 14.8259s	
20602/33650 (epoch 30.612), train_loss = 0.90781847, grad/param norm = 1.8354e-01, time/batch = 0.6413s	
20603/33650 (epoch 30.614), train_loss = 1.01031597, grad/param norm = 1.7366e-01, time/batch = 0.6444s	
20604/33650 (epoch 30.615), train_loss = 0.93083523, grad/param norm = 1.4089e-01, time/batch = 0.6547s	
20605/33650 (epoch 30.617), train_loss = 0.83616605, grad/param norm = 1.4177e-01, time/batch = 0.6445s	
20606/33650 (epoch 30.618), train_loss = 0.88619699, grad/param norm = 1.5514e-01, time/batch = 0.6437s	
20607/33650 (epoch 30.620), train_loss = 0.87124820, grad/param norm = 1.6886e-01, time/batch = 0.6449s	
20608/33650 (epoch 30.621), train_loss = 0.84056596, grad/param norm = 1.5344e-01, time/batch = 0.6557s	
20609/33650 (epoch 30.623), train_loss = 0.88374233, grad/param norm = 1.5059e-01, time/batch = 0.7965s	
20610/33650 (epoch 30.624), train_loss = 0.71638408, grad/param norm = 1.6834e-01, time/batch = 0.9908s	
20611/33650 (epoch 30.626), train_loss = 0.74758480, grad/param norm = 1.5555e-01, time/batch = 0.9458s	
20612/33650 (epoch 30.627), train_loss = 0.84975558, grad/param norm = 1.6175e-01, time/batch = 0.9437s	
20613/33650 (epoch 30.629), train_loss = 0.85318239, grad/param norm = 1.6808e-01, time/batch = 0.9443s	
20614/33650 (epoch 30.630), train_loss = 1.02089307, grad/param norm = 1.7766e-01, time/batch = 1.1848s	
20615/33650 (epoch 30.632), train_loss = 1.00842835, grad/param norm = 1.6981e-01, time/batch = 1.7820s	
20616/33650 (epoch 30.633), train_loss = 0.98955023, grad/param norm = 1.6221e-01, time/batch = 1.8348s	
20617/33650 (epoch 30.634), train_loss = 0.78277802, grad/param norm = 1.3192e-01, time/batch = 9.1920s	
20618/33650 (epoch 30.636), train_loss = 0.71439012, grad/param norm = 1.2358e-01, time/batch = 19.1222s	
20619/33650 (epoch 30.637), train_loss = 0.81172804, grad/param norm = 1.4773e-01, time/batch = 16.8736s	
20620/33650 (epoch 30.639), train_loss = 0.82208147, grad/param norm = 1.4093e-01, time/batch = 17.5563s	
20621/33650 (epoch 30.640), train_loss = 0.91930682, grad/param norm = 1.7179e-01, time/batch = 18.8962s	
20622/33650 (epoch 30.642), train_loss = 0.96993544, grad/param norm = 1.6637e-01, time/batch = 16.6413s	
20623/33650 (epoch 30.643), train_loss = 0.92194461, grad/param norm = 1.6877e-01, time/batch = 17.8738s	
20624/33650 (epoch 30.645), train_loss = 0.92998910, grad/param norm = 1.6469e-01, time/batch = 16.8857s	
20625/33650 (epoch 30.646), train_loss = 0.79216596, grad/param norm = 1.2433e-01, time/batch = 18.0644s	
20626/33650 (epoch 30.648), train_loss = 0.95868343, grad/param norm = 1.7365e-01, time/batch = 16.9759s	
20627/33650 (epoch 30.649), train_loss = 0.82489875, grad/param norm = 1.6762e-01, time/batch = 17.3930s	
20628/33650 (epoch 30.651), train_loss = 0.96938186, grad/param norm = 1.6151e-01, time/batch = 17.9879s	
20629/33650 (epoch 30.652), train_loss = 0.67051190, grad/param norm = 1.3900e-01, time/batch = 16.4484s	
20630/33650 (epoch 30.654), train_loss = 0.80763334, grad/param norm = 1.6629e-01, time/batch = 18.6523s	
20631/33650 (epoch 30.655), train_loss = 0.79770688, grad/param norm = 1.4617e-01, time/batch = 18.8103s	
20632/33650 (epoch 30.657), train_loss = 0.86135737, grad/param norm = 1.6548e-01, time/batch = 17.4655s	
20633/33650 (epoch 30.658), train_loss = 0.73201021, grad/param norm = 1.6128e-01, time/batch = 17.5438s	
20634/33650 (epoch 30.660), train_loss = 0.73931971, grad/param norm = 1.5059e-01, time/batch = 17.6424s	
20635/33650 (epoch 30.661), train_loss = 0.79973860, grad/param norm = 1.5648e-01, time/batch = 17.9694s	
20636/33650 (epoch 30.663), train_loss = 0.76588458, grad/param norm = 1.6177e-01, time/batch = 16.5595s	
20637/33650 (epoch 30.664), train_loss = 0.84274878, grad/param norm = 1.4800e-01, time/batch = 17.3971s	
20638/33650 (epoch 30.666), train_loss = 0.85322841, grad/param norm = 1.2897e-01, time/batch = 18.7235s	
20639/33650 (epoch 30.667), train_loss = 0.76186252, grad/param norm = 1.3814e-01, time/batch = 17.5554s	
20640/33650 (epoch 30.669), train_loss = 0.78266892, grad/param norm = 1.4775e-01, time/batch = 18.3915s	
20641/33650 (epoch 30.670), train_loss = 0.72019803, grad/param norm = 1.5051e-01, time/batch = 17.7227s	
20642/33650 (epoch 30.672), train_loss = 0.74510557, grad/param norm = 1.4399e-01, time/batch = 17.1355s	
20643/33650 (epoch 30.673), train_loss = 0.73021075, grad/param norm = 1.4169e-01, time/batch = 16.7946s	
20644/33650 (epoch 30.675), train_loss = 0.69245671, grad/param norm = 1.2278e-01, time/batch = 17.8960s	
20645/33650 (epoch 30.676), train_loss = 0.84587503, grad/param norm = 1.6321e-01, time/batch = 17.7216s	
20646/33650 (epoch 30.678), train_loss = 0.82611612, grad/param norm = 1.6419e-01, time/batch = 17.7081s	
20647/33650 (epoch 30.679), train_loss = 0.81133314, grad/param norm = 1.5665e-01, time/batch = 17.4663s	
20648/33650 (epoch 30.681), train_loss = 0.84436542, grad/param norm = 1.3941e-01, time/batch = 18.3123s	
20649/33650 (epoch 30.682), train_loss = 0.79467087, grad/param norm = 1.8243e-01, time/batch = 18.3922s	
20650/33650 (epoch 30.684), train_loss = 0.74499325, grad/param norm = 1.4486e-01, time/batch = 17.4561s	
20651/33650 (epoch 30.685), train_loss = 0.90772435, grad/param norm = 1.6503e-01, time/batch = 18.3209s	
20652/33650 (epoch 30.686), train_loss = 0.86465303, grad/param norm = 1.8113e-01, time/batch = 18.4014s	
20653/33650 (epoch 30.688), train_loss = 0.96909164, grad/param norm = 1.6597e-01, time/batch = 16.3859s	
20654/33650 (epoch 30.689), train_loss = 0.81751319, grad/param norm = 1.5590e-01, time/batch = 18.3037s	
20655/33650 (epoch 30.691), train_loss = 0.95363401, grad/param norm = 1.6841e-01, time/batch = 18.6481s	
20656/33650 (epoch 30.692), train_loss = 0.98158291, grad/param norm = 1.8175e-01, time/batch = 17.3124s	
20657/33650 (epoch 30.694), train_loss = 0.92768326, grad/param norm = 1.6643e-01, time/batch = 15.9636s	
20658/33650 (epoch 30.695), train_loss = 0.62795358, grad/param norm = 1.4700e-01, time/batch = 17.7252s	
20659/33650 (epoch 30.697), train_loss = 0.84374402, grad/param norm = 1.5958e-01, time/batch = 16.7935s	
20660/33650 (epoch 30.698), train_loss = 0.98666306, grad/param norm = 1.8562e-01, time/batch = 17.0564s	
20661/33650 (epoch 30.700), train_loss = 0.86197126, grad/param norm = 1.6479e-01, time/batch = 18.2381s	
20662/33650 (epoch 30.701), train_loss = 0.86608118, grad/param norm = 1.4644e-01, time/batch = 17.5693s	
20663/33650 (epoch 30.703), train_loss = 1.05342903, grad/param norm = 1.6263e-01, time/batch = 16.9523s	
20664/33650 (epoch 30.704), train_loss = 0.86700893, grad/param norm = 1.5120e-01, time/batch = 17.4885s	
20665/33650 (epoch 30.706), train_loss = 0.83735498, grad/param norm = 1.4677e-01, time/batch = 18.3126s	
20666/33650 (epoch 30.707), train_loss = 0.96745866, grad/param norm = 1.4820e-01, time/batch = 17.8099s	
20667/33650 (epoch 30.709), train_loss = 0.84319628, grad/param norm = 1.5760e-01, time/batch = 17.9581s	
20668/33650 (epoch 30.710), train_loss = 1.04391140, grad/param norm = 1.6777e-01, time/batch = 18.5650s	
20669/33650 (epoch 30.712), train_loss = 0.76956122, grad/param norm = 1.5647e-01, time/batch = 18.6455s	
20670/33650 (epoch 30.713), train_loss = 0.78486925, grad/param norm = 1.8694e-01, time/batch = 15.4623s	
20671/33650 (epoch 30.715), train_loss = 0.93089044, grad/param norm = 1.8682e-01, time/batch = 18.8885s	
20672/33650 (epoch 30.716), train_loss = 0.84553062, grad/param norm = 1.4435e-01, time/batch = 17.5515s	
20673/33650 (epoch 30.718), train_loss = 0.83939546, grad/param norm = 1.6667e-01, time/batch = 16.2984s	
20674/33650 (epoch 30.719), train_loss = 0.97891080, grad/param norm = 1.7804e-01, time/batch = 18.7332s	
20675/33650 (epoch 30.721), train_loss = 1.06743767, grad/param norm = 1.9194e-01, time/batch = 16.8936s	
20676/33650 (epoch 30.722), train_loss = 0.93949730, grad/param norm = 1.9548e-01, time/batch = 18.2446s	
20677/33650 (epoch 30.724), train_loss = 1.00234023, grad/param norm = 1.7321e-01, time/batch = 17.6400s	
20678/33650 (epoch 30.725), train_loss = 0.94415774, grad/param norm = 1.5779e-01, time/batch = 18.3987s	
20679/33650 (epoch 30.727), train_loss = 0.84864661, grad/param norm = 1.7871e-01, time/batch = 17.9046s	
20680/33650 (epoch 30.728), train_loss = 0.85674929, grad/param norm = 1.6428e-01, time/batch = 16.3221s	
20681/33650 (epoch 30.730), train_loss = 0.92000578, grad/param norm = 1.6413e-01, time/batch = 18.3974s	
20682/33650 (epoch 30.731), train_loss = 1.02453520, grad/param norm = 1.7317e-01, time/batch = 18.2402s	
20683/33650 (epoch 30.733), train_loss = 0.85155017, grad/param norm = 1.5638e-01, time/batch = 16.7111s	
20684/33650 (epoch 30.734), train_loss = 1.01587824, grad/param norm = 1.9252e-01, time/batch = 17.5488s	
20685/33650 (epoch 30.736), train_loss = 0.87563317, grad/param norm = 2.2572e-01, time/batch = 18.8865s	
20686/33650 (epoch 30.737), train_loss = 0.91580234, grad/param norm = 1.6259e-01, time/batch = 18.8207s	
20687/33650 (epoch 30.738), train_loss = 0.81570492, grad/param norm = 1.5882e-01, time/batch = 17.2249s	
20688/33650 (epoch 30.740), train_loss = 0.75089108, grad/param norm = 1.4215e-01, time/batch = 18.0658s	
20689/33650 (epoch 30.741), train_loss = 0.81964927, grad/param norm = 1.5201e-01, time/batch = 19.0542s	
20690/33650 (epoch 30.743), train_loss = 0.85796394, grad/param norm = 1.4952e-01, time/batch = 16.1207s	
20691/33650 (epoch 30.744), train_loss = 0.97085007, grad/param norm = 1.5118e-01, time/batch = 17.9837s	
20692/33650 (epoch 30.746), train_loss = 0.86223786, grad/param norm = 1.6387e-01, time/batch = 17.8964s	
20693/33650 (epoch 30.747), train_loss = 0.99023500, grad/param norm = 1.6181e-01, time/batch = 17.6418s	
20694/33650 (epoch 30.749), train_loss = 0.72887406, grad/param norm = 1.5042e-01, time/batch = 16.7901s	
20695/33650 (epoch 30.750), train_loss = 1.03225223, grad/param norm = 1.7556e-01, time/batch = 17.9024s	
20696/33650 (epoch 30.752), train_loss = 0.96484497, grad/param norm = 1.5998e-01, time/batch = 18.3154s	
20697/33650 (epoch 30.753), train_loss = 1.07834669, grad/param norm = 1.8156e-01, time/batch = 16.0282s	
20698/33650 (epoch 30.755), train_loss = 0.85882186, grad/param norm = 1.6592e-01, time/batch = 18.2277s	
20699/33650 (epoch 30.756), train_loss = 0.96659927, grad/param norm = 1.8704e-01, time/batch = 17.9858s	
20700/33650 (epoch 30.758), train_loss = 0.98483049, grad/param norm = 1.5605e-01, time/batch = 16.4698s	
20701/33650 (epoch 30.759), train_loss = 0.99776674, grad/param norm = 1.9817e-01, time/batch = 18.6400s	
20702/33650 (epoch 30.761), train_loss = 0.91347207, grad/param norm = 1.5517e-01, time/batch = 18.0684s	
20703/33650 (epoch 30.762), train_loss = 0.87029964, grad/param norm = 1.5986e-01, time/batch = 18.2157s	
20704/33650 (epoch 30.764), train_loss = 0.94259128, grad/param norm = 1.9589e-01, time/batch = 17.3932s	
20705/33650 (epoch 30.765), train_loss = 0.84318874, grad/param norm = 1.6060e-01, time/batch = 17.9032s	
20706/33650 (epoch 30.767), train_loss = 0.87838647, grad/param norm = 1.4977e-01, time/batch = 18.1365s	
20707/33650 (epoch 30.768), train_loss = 0.79803379, grad/param norm = 1.6669e-01, time/batch = 17.6351s	
20708/33650 (epoch 30.770), train_loss = 0.91820614, grad/param norm = 1.7480e-01, time/batch = 17.6416s	
20709/33650 (epoch 30.771), train_loss = 0.92132850, grad/param norm = 1.5353e-01, time/batch = 16.3783s	
20710/33650 (epoch 30.773), train_loss = 0.98202769, grad/param norm = 1.7556e-01, time/batch = 17.2791s	
20711/33650 (epoch 30.774), train_loss = 0.93214071, grad/param norm = 1.7302e-01, time/batch = 18.1354s	
20712/33650 (epoch 30.776), train_loss = 0.96168731, grad/param norm = 1.6658e-01, time/batch = 17.9635s	
20713/33650 (epoch 30.777), train_loss = 0.83359701, grad/param norm = 1.4058e-01, time/batch = 18.0715s	
20714/33650 (epoch 30.779), train_loss = 0.85836095, grad/param norm = 1.4414e-01, time/batch = 17.7117s	
20715/33650 (epoch 30.780), train_loss = 0.79521659, grad/param norm = 1.5028e-01, time/batch = 17.5626s	
20716/33650 (epoch 30.782), train_loss = 0.80771073, grad/param norm = 1.5871e-01, time/batch = 18.3101s	
20717/33650 (epoch 30.783), train_loss = 0.81991363, grad/param norm = 1.3215e-01, time/batch = 17.0460s	
20718/33650 (epoch 30.785), train_loss = 1.05503356, grad/param norm = 1.5021e-01, time/batch = 18.4827s	
20719/33650 (epoch 30.786), train_loss = 0.94742295, grad/param norm = 1.5174e-01, time/batch = 17.9056s	
20720/33650 (epoch 30.788), train_loss = 0.94721007, grad/param norm = 1.5774e-01, time/batch = 16.9839s	
20721/33650 (epoch 30.789), train_loss = 0.98788555, grad/param norm = 1.6268e-01, time/batch = 17.4784s	
20722/33650 (epoch 30.790), train_loss = 0.90283112, grad/param norm = 1.8185e-01, time/batch = 18.9014s	
20723/33650 (epoch 30.792), train_loss = 0.99876898, grad/param norm = 1.7945e-01, time/batch = 18.4711s	
20724/33650 (epoch 30.793), train_loss = 0.97547463, grad/param norm = 1.9438e-01, time/batch = 17.3018s	
20725/33650 (epoch 30.795), train_loss = 0.99324848, grad/param norm = 1.7560e-01, time/batch = 17.9777s	
20726/33650 (epoch 30.796), train_loss = 0.85678070, grad/param norm = 1.4670e-01, time/batch = 17.7355s	
20727/33650 (epoch 30.798), train_loss = 0.84890097, grad/param norm = 1.5273e-01, time/batch = 16.1269s	
20728/33650 (epoch 30.799), train_loss = 0.88970205, grad/param norm = 1.4815e-01, time/batch = 17.5678s	
20729/33650 (epoch 30.801), train_loss = 0.90234125, grad/param norm = 1.7658e-01, time/batch = 18.4845s	
20730/33650 (epoch 30.802), train_loss = 1.00757789, grad/param norm = 1.8878e-01, time/batch = 17.1267s	
20731/33650 (epoch 30.804), train_loss = 0.90635620, grad/param norm = 1.7259e-01, time/batch = 18.3119s	
20732/33650 (epoch 30.805), train_loss = 0.88522993, grad/param norm = 1.4762e-01, time/batch = 18.1580s	
20733/33650 (epoch 30.807), train_loss = 1.09764256, grad/param norm = 1.9816e-01, time/batch = 18.1451s	
20734/33650 (epoch 30.808), train_loss = 1.15687605, grad/param norm = 1.9166e-01, time/batch = 31.4075s	
20735/33650 (epoch 30.810), train_loss = 0.94275696, grad/param norm = 1.7209e-01, time/batch = 16.8047s	
20736/33650 (epoch 30.811), train_loss = 0.92797822, grad/param norm = 1.6511e-01, time/batch = 16.6982s	
20737/33650 (epoch 30.813), train_loss = 0.81566142, grad/param norm = 1.4387e-01, time/batch = 17.4694s	
20738/33650 (epoch 30.814), train_loss = 1.00686852, grad/param norm = 1.9177e-01, time/batch = 18.4619s	
20739/33650 (epoch 30.816), train_loss = 0.96259748, grad/param norm = 1.8547e-01, time/batch = 18.5557s	
20740/33650 (epoch 30.817), train_loss = 0.97465375, grad/param norm = 1.7700e-01, time/batch = 17.8800s	
20741/33650 (epoch 30.819), train_loss = 0.92254335, grad/param norm = 1.8598e-01, time/batch = 18.0527s	
20742/33650 (epoch 30.820), train_loss = 1.01535213, grad/param norm = 1.6546e-01, time/batch = 17.0467s	
20743/33650 (epoch 30.822), train_loss = 0.93305870, grad/param norm = 2.0566e-01, time/batch = 17.3874s	
20744/33650 (epoch 30.823), train_loss = 0.85115786, grad/param norm = 1.5928e-01, time/batch = 15.4793s	
20745/33650 (epoch 30.825), train_loss = 0.90982158, grad/param norm = 1.8033e-01, time/batch = 18.7349s	
20746/33650 (epoch 30.826), train_loss = 0.97248646, grad/param norm = 1.5370e-01, time/batch = 17.6357s	
20747/33650 (epoch 30.828), train_loss = 1.05869825, grad/param norm = 1.6788e-01, time/batch = 16.6275s	
20748/33650 (epoch 30.829), train_loss = 0.78246244, grad/param norm = 1.6483e-01, time/batch = 18.6529s	
20749/33650 (epoch 30.831), train_loss = 0.93145925, grad/param norm = 1.7293e-01, time/batch = 18.7295s	
20750/33650 (epoch 30.832), train_loss = 0.97313070, grad/param norm = 1.6915e-01, time/batch = 17.0496s	
20751/33650 (epoch 30.834), train_loss = 0.98368739, grad/param norm = 1.6549e-01, time/batch = 13.7406s	
20752/33650 (epoch 30.835), train_loss = 1.12278564, grad/param norm = 1.9028e-01, time/batch = 13.6797s	
20753/33650 (epoch 30.837), train_loss = 0.93156038, grad/param norm = 2.3716e-01, time/batch = 14.1609s	
20754/33650 (epoch 30.838), train_loss = 0.92961985, grad/param norm = 1.9438e-01, time/batch = 16.6463s	
20755/33650 (epoch 30.840), train_loss = 0.99681953, grad/param norm = 1.7523e-01, time/batch = 16.8668s	
20756/33650 (epoch 30.841), train_loss = 0.87384021, grad/param norm = 1.6450e-01, time/batch = 18.9803s	
20757/33650 (epoch 30.842), train_loss = 0.90293194, grad/param norm = 1.5166e-01, time/batch = 17.7279s	
20758/33650 (epoch 30.844), train_loss = 1.06154710, grad/param norm = 1.9558e-01, time/batch = 16.4672s	
20759/33650 (epoch 30.845), train_loss = 0.88278977, grad/param norm = 1.6373e-01, time/batch = 17.4792s	
20760/33650 (epoch 30.847), train_loss = 0.70376812, grad/param norm = 1.4441e-01, time/batch = 18.9846s	
20761/33650 (epoch 30.848), train_loss = 0.79173242, grad/param norm = 1.6688e-01, time/batch = 17.2227s	
20762/33650 (epoch 30.850), train_loss = 0.87026892, grad/param norm = 1.8496e-01, time/batch = 17.4842s	
20763/33650 (epoch 30.851), train_loss = 0.76833164, grad/param norm = 1.3872e-01, time/batch = 18.4805s	
20764/33650 (epoch 30.853), train_loss = 0.87072721, grad/param norm = 1.7250e-01, time/batch = 16.9008s	
20765/33650 (epoch 30.854), train_loss = 0.99127136, grad/param norm = 1.5908e-01, time/batch = 18.6411s	
20766/33650 (epoch 30.856), train_loss = 0.70618355, grad/param norm = 1.4054e-01, time/batch = 16.4705s	
20767/33650 (epoch 30.857), train_loss = 0.93893940, grad/param norm = 1.5678e-01, time/batch = 17.8197s	
20768/33650 (epoch 30.859), train_loss = 0.81060759, grad/param norm = 1.4391e-01, time/batch = 18.0477s	
20769/33650 (epoch 30.860), train_loss = 0.77567404, grad/param norm = 1.6146e-01, time/batch = 16.3872s	
20770/33650 (epoch 30.862), train_loss = 0.81216979, grad/param norm = 1.5539e-01, time/batch = 18.5675s	
20771/33650 (epoch 30.863), train_loss = 1.03029116, grad/param norm = 1.6470e-01, time/batch = 17.1380s	
20772/33650 (epoch 30.865), train_loss = 0.87753498, grad/param norm = 1.4720e-01, time/batch = 19.0542s	
20773/33650 (epoch 30.866), train_loss = 0.82819187, grad/param norm = 1.7121e-01, time/batch = 18.3084s	
20774/33650 (epoch 30.868), train_loss = 0.77432494, grad/param norm = 1.6341e-01, time/batch = 16.7211s	
20775/33650 (epoch 30.869), train_loss = 0.95908267, grad/param norm = 1.7552e-01, time/batch = 18.0548s	
20776/33650 (epoch 30.871), train_loss = 0.79852175, grad/param norm = 1.4972e-01, time/batch = 17.3097s	
20777/33650 (epoch 30.872), train_loss = 0.92680552, grad/param norm = 1.4999e-01, time/batch = 17.5585s	
20778/33650 (epoch 30.874), train_loss = 0.96447716, grad/param norm = 1.7887e-01, time/batch = 17.2095s	
20779/33650 (epoch 30.875), train_loss = 0.86267754, grad/param norm = 1.4708e-01, time/batch = 18.7408s	
20780/33650 (epoch 30.877), train_loss = 1.05389263, grad/param norm = 1.6493e-01, time/batch = 18.0574s	
20781/33650 (epoch 30.878), train_loss = 0.64031568, grad/param norm = 1.3374e-01, time/batch = 17.3835s	
20782/33650 (epoch 30.880), train_loss = 0.92043871, grad/param norm = 1.6802e-01, time/batch = 18.1455s	
20783/33650 (epoch 30.881), train_loss = 0.84988972, grad/param norm = 1.6174e-01, time/batch = 18.3204s	
20784/33650 (epoch 30.883), train_loss = 0.92001793, grad/param norm = 1.6099e-01, time/batch = 17.5482s	
20785/33650 (epoch 30.884), train_loss = 1.03770207, grad/param norm = 2.1513e-01, time/batch = 17.8201s	
20786/33650 (epoch 30.886), train_loss = 0.95276619, grad/param norm = 1.6045e-01, time/batch = 18.5740s	
20787/33650 (epoch 30.887), train_loss = 0.77599217, grad/param norm = 1.3972e-01, time/batch = 17.4878s	
20788/33650 (epoch 30.889), train_loss = 0.85710351, grad/param norm = 1.6391e-01, time/batch = 16.0475s	
20789/33650 (epoch 30.890), train_loss = 0.93565339, grad/param norm = 1.5706e-01, time/batch = 18.7250s	
20790/33650 (epoch 30.892), train_loss = 0.85254794, grad/param norm = 2.0508e-01, time/batch = 18.8061s	
20791/33650 (epoch 30.893), train_loss = 0.92155071, grad/param norm = 1.6608e-01, time/batch = 16.3822s	
20792/33650 (epoch 30.895), train_loss = 1.02920378, grad/param norm = 1.7395e-01, time/batch = 18.3661s	
20793/33650 (epoch 30.896), train_loss = 0.83663276, grad/param norm = 1.5024e-01, time/batch = 18.8902s	
20794/33650 (epoch 30.897), train_loss = 0.75692379, grad/param norm = 1.4661e-01, time/batch = 17.4117s	
20795/33650 (epoch 30.899), train_loss = 0.80967876, grad/param norm = 1.3770e-01, time/batch = 18.4733s	
20796/33650 (epoch 30.900), train_loss = 0.76242291, grad/param norm = 1.4093e-01, time/batch = 18.1274s	
20797/33650 (epoch 30.902), train_loss = 0.87744316, grad/param norm = 1.6094e-01, time/batch = 17.8061s	
20798/33650 (epoch 30.903), train_loss = 0.85600312, grad/param norm = 1.7871e-01, time/batch = 17.2949s	
20799/33650 (epoch 30.905), train_loss = 1.00472744, grad/param norm = 1.9183e-01, time/batch = 16.1355s	
20800/33650 (epoch 30.906), train_loss = 0.83080634, grad/param norm = 1.5833e-01, time/batch = 18.8210s	
20801/33650 (epoch 30.908), train_loss = 0.85741134, grad/param norm = 1.4793e-01, time/batch = 16.8889s	
20802/33650 (epoch 30.909), train_loss = 0.83465586, grad/param norm = 1.3598e-01, time/batch = 18.4792s	
20803/33650 (epoch 30.911), train_loss = 0.75021593, grad/param norm = 1.3918e-01, time/batch = 18.5672s	
20804/33650 (epoch 30.912), train_loss = 0.70872630, grad/param norm = 1.5555e-01, time/batch = 18.4669s	
20805/33650 (epoch 30.914), train_loss = 0.91161735, grad/param norm = 1.3615e-01, time/batch = 17.8985s	
20806/33650 (epoch 30.915), train_loss = 0.86608549, grad/param norm = 1.7531e-01, time/batch = 17.9075s	
20807/33650 (epoch 30.917), train_loss = 0.84818492, grad/param norm = 1.6120e-01, time/batch = 18.6371s	
20808/33650 (epoch 30.918), train_loss = 0.77880884, grad/param norm = 1.4022e-01, time/batch = 17.6382s	
20809/33650 (epoch 30.920), train_loss = 0.79784111, grad/param norm = 1.5252e-01, time/batch = 17.6507s	
20810/33650 (epoch 30.921), train_loss = 0.78909222, grad/param norm = 1.5044e-01, time/batch = 16.9720s	
20811/33650 (epoch 30.923), train_loss = 0.73161285, grad/param norm = 1.5581e-01, time/batch = 17.2298s	
20812/33650 (epoch 30.924), train_loss = 0.90033537, grad/param norm = 1.5745e-01, time/batch = 18.8886s	
20813/33650 (epoch 30.926), train_loss = 0.81090076, grad/param norm = 1.7691e-01, time/batch = 16.6258s	
20814/33650 (epoch 30.927), train_loss = 0.85789678, grad/param norm = 1.5515e-01, time/batch = 16.8817s	
20815/33650 (epoch 30.929), train_loss = 0.93922815, grad/param norm = 1.5562e-01, time/batch = 17.4627s	
20816/33650 (epoch 30.930), train_loss = 0.85806606, grad/param norm = 1.8152e-01, time/batch = 18.6467s	
20817/33650 (epoch 30.932), train_loss = 0.84949795, grad/param norm = 1.4926e-01, time/batch = 18.0597s	
20818/33650 (epoch 30.933), train_loss = 0.75071705, grad/param norm = 1.5904e-01, time/batch = 16.0422s	
20819/33650 (epoch 30.935), train_loss = 0.76137138, grad/param norm = 1.7424e-01, time/batch = 18.4001s	
20820/33650 (epoch 30.936), train_loss = 0.82480255, grad/param norm = 1.4875e-01, time/batch = 15.8857s	
20821/33650 (epoch 30.938), train_loss = 0.76289287, grad/param norm = 1.4543e-01, time/batch = 17.8051s	
20822/33650 (epoch 30.939), train_loss = 0.94577938, grad/param norm = 1.4376e-01, time/batch = 18.2133s	
20823/33650 (epoch 30.941), train_loss = 0.88928440, grad/param norm = 1.6554e-01, time/batch = 16.4724s	
20824/33650 (epoch 30.942), train_loss = 0.94740495, grad/param norm = 1.6129e-01, time/batch = 17.9705s	
20825/33650 (epoch 30.944), train_loss = 0.81779143, grad/param norm = 1.3412e-01, time/batch = 16.7962s	
20826/33650 (epoch 30.945), train_loss = 0.88712391, grad/param norm = 1.5477e-01, time/batch = 17.3866s	
20827/33650 (epoch 30.947), train_loss = 1.02980166, grad/param norm = 2.1147e-01, time/batch = 17.2892s	
20828/33650 (epoch 30.948), train_loss = 0.98528038, grad/param norm = 1.5449e-01, time/batch = 17.8117s	
20829/33650 (epoch 30.949), train_loss = 0.75545333, grad/param norm = 1.5307e-01, time/batch = 17.3853s	
20830/33650 (epoch 30.951), train_loss = 1.00878046, grad/param norm = 1.6930e-01, time/batch = 18.3995s	
20831/33650 (epoch 30.952), train_loss = 0.91126312, grad/param norm = 1.5672e-01, time/batch = 18.1349s	
20832/33650 (epoch 30.954), train_loss = 0.93389201, grad/param norm = 1.7309e-01, time/batch = 17.6388s	
20833/33650 (epoch 30.955), train_loss = 0.90631217, grad/param norm = 1.5819e-01, time/batch = 18.7146s	
20834/33650 (epoch 30.957), train_loss = 0.92662953, grad/param norm = 1.6328e-01, time/batch = 18.2329s	
20835/33650 (epoch 30.958), train_loss = 0.70616866, grad/param norm = 1.3240e-01, time/batch = 15.8867s	
20836/33650 (epoch 30.960), train_loss = 0.72320912, grad/param norm = 1.3857e-01, time/batch = 18.7259s	
20837/33650 (epoch 30.961), train_loss = 0.76810672, grad/param norm = 1.5353e-01, time/batch = 18.1462s	
20838/33650 (epoch 30.963), train_loss = 0.79830652, grad/param norm = 1.6059e-01, time/batch = 17.2852s	
20839/33650 (epoch 30.964), train_loss = 0.95481755, grad/param norm = 1.5171e-01, time/batch = 17.1223s	
20840/33650 (epoch 30.966), train_loss = 0.89901949, grad/param norm = 1.7886e-01, time/batch = 18.6428s	
20841/33650 (epoch 30.967), train_loss = 0.91862312, grad/param norm = 1.6801e-01, time/batch = 18.2137s	
20842/33650 (epoch 30.969), train_loss = 0.87726933, grad/param norm = 1.7474e-01, time/batch = 17.2251s	
20843/33650 (epoch 30.970), train_loss = 0.89751262, grad/param norm = 2.2415e-01, time/batch = 17.1434s	
20844/33650 (epoch 30.972), train_loss = 1.16103019, grad/param norm = 1.8838e-01, time/batch = 18.8903s	
20845/33650 (epoch 30.973), train_loss = 0.78777901, grad/param norm = 1.3342e-01, time/batch = 16.3876s	
20846/33650 (epoch 30.975), train_loss = 0.77920125, grad/param norm = 1.3807e-01, time/batch = 18.0628s	
20847/33650 (epoch 30.976), train_loss = 0.79999975, grad/param norm = 1.3243e-01, time/batch = 17.8226s	
20848/33650 (epoch 30.978), train_loss = 0.80339528, grad/param norm = 1.4358e-01, time/batch = 17.6393s	
20849/33650 (epoch 30.979), train_loss = 0.85019900, grad/param norm = 1.6461e-01, time/batch = 16.2151s	
20850/33650 (epoch 30.981), train_loss = 0.82821705, grad/param norm = 1.3754e-01, time/batch = 17.2432s	
20851/33650 (epoch 30.982), train_loss = 0.88532535, grad/param norm = 1.6518e-01, time/batch = 17.7298s	
20852/33650 (epoch 30.984), train_loss = 0.73909020, grad/param norm = 1.4426e-01, time/batch = 17.2118s	
20853/33650 (epoch 30.985), train_loss = 0.77842761, grad/param norm = 1.4348e-01, time/batch = 18.4795s	
20854/33650 (epoch 30.987), train_loss = 0.87715331, grad/param norm = 1.4648e-01, time/batch = 17.6446s	
20855/33650 (epoch 30.988), train_loss = 0.82364898, grad/param norm = 1.4595e-01, time/batch = 16.8846s	
20856/33650 (epoch 30.990), train_loss = 1.02069450, grad/param norm = 1.8753e-01, time/batch = 16.8121s	
20857/33650 (epoch 30.991), train_loss = 0.88501209, grad/param norm = 1.5202e-01, time/batch = 18.8747s	
20858/33650 (epoch 30.993), train_loss = 0.89398542, grad/param norm = 1.5662e-01, time/batch = 17.8949s	
20859/33650 (epoch 30.994), train_loss = 0.88307660, grad/param norm = 1.4512e-01, time/batch = 18.1381s	
20860/33650 (epoch 30.996), train_loss = 0.83989550, grad/param norm = 1.5497e-01, time/batch = 17.4675s	
20861/33650 (epoch 30.997), train_loss = 0.93676257, grad/param norm = 1.7948e-01, time/batch = 18.3983s	
20862/33650 (epoch 30.999), train_loss = 0.79570271, grad/param norm = 1.4996e-01, time/batch = 17.8767s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
20863/33650 (epoch 31.000), train_loss = 0.95195624, grad/param norm = 1.8012e-01, time/batch = 17.4816s	
20864/33650 (epoch 31.001), train_loss = 0.99293518, grad/param norm = 1.5035e-01, time/batch = 18.3171s	
20865/33650 (epoch 31.003), train_loss = 1.00684696, grad/param norm = 1.9650e-01, time/batch = 17.5613s	
20866/33650 (epoch 31.004), train_loss = 0.93057135, grad/param norm = 1.6790e-01, time/batch = 18.0582s	
20867/33650 (epoch 31.006), train_loss = 0.85320270, grad/param norm = 1.6557e-01, time/batch = 18.8087s	
20868/33650 (epoch 31.007), train_loss = 0.92395528, grad/param norm = 1.7367e-01, time/batch = 17.2253s	
20869/33650 (epoch 31.009), train_loss = 0.82610024, grad/param norm = 1.5260e-01, time/batch = 15.9612s	
20870/33650 (epoch 31.010), train_loss = 0.97679673, grad/param norm = 1.7261e-01, time/batch = 18.2162s	
20871/33650 (epoch 31.012), train_loss = 0.83169710, grad/param norm = 1.5346e-01, time/batch = 17.9825s	
20872/33650 (epoch 31.013), train_loss = 0.86646194, grad/param norm = 1.8435e-01, time/batch = 16.9815s	
20873/33650 (epoch 31.015), train_loss = 0.84206533, grad/param norm = 1.5594e-01, time/batch = 18.4703s	
20874/33650 (epoch 31.016), train_loss = 0.80215990, grad/param norm = 1.7768e-01, time/batch = 17.7293s	
20875/33650 (epoch 31.018), train_loss = 0.86306214, grad/param norm = 1.8266e-01, time/batch = 18.3914s	
20876/33650 (epoch 31.019), train_loss = 0.83723584, grad/param norm = 1.7834e-01, time/batch = 17.2311s	
20877/33650 (epoch 31.021), train_loss = 0.92688872, grad/param norm = 1.5845e-01, time/batch = 17.2797s	
20878/33650 (epoch 31.022), train_loss = 0.84848239, grad/param norm = 1.5351e-01, time/batch = 18.4761s	
20879/33650 (epoch 31.024), train_loss = 0.80096970, grad/param norm = 1.6978e-01, time/batch = 17.7936s	
20880/33650 (epoch 31.025), train_loss = 0.88504675, grad/param norm = 1.5854e-01, time/batch = 18.1556s	
20881/33650 (epoch 31.027), train_loss = 0.90332076, grad/param norm = 1.6623e-01, time/batch = 16.8896s	
20882/33650 (epoch 31.028), train_loss = 0.95110582, grad/param norm = 1.6576e-01, time/batch = 17.2208s	
20883/33650 (epoch 31.030), train_loss = 0.87223825, grad/param norm = 1.7874e-01, time/batch = 17.6314s	
20884/33650 (epoch 31.031), train_loss = 0.78405210, grad/param norm = 1.4080e-01, time/batch = 15.3914s	
20885/33650 (epoch 31.033), train_loss = 0.89401730, grad/param norm = 1.5439e-01, time/batch = 18.2142s	
20886/33650 (epoch 31.034), train_loss = 0.91500895, grad/param norm = 1.9109e-01, time/batch = 18.5428s	
20887/33650 (epoch 31.036), train_loss = 0.99388925, grad/param norm = 1.7324e-01, time/batch = 17.3106s	
20888/33650 (epoch 31.037), train_loss = 0.83425178, grad/param norm = 1.4614e-01, time/batch = 18.0327s	
20889/33650 (epoch 31.039), train_loss = 0.96916058, grad/param norm = 1.6319e-01, time/batch = 17.0474s	
20890/33650 (epoch 31.040), train_loss = 1.04837794, grad/param norm = 2.0390e-01, time/batch = 18.1392s	
20891/33650 (epoch 31.042), train_loss = 1.04538778, grad/param norm = 1.6499e-01, time/batch = 18.1349s	
20892/33650 (epoch 31.043), train_loss = 0.83553733, grad/param norm = 1.3595e-01, time/batch = 16.3163s	
20893/33650 (epoch 31.045), train_loss = 0.85136542, grad/param norm = 1.6249e-01, time/batch = 18.5644s	
20894/33650 (epoch 31.046), train_loss = 0.94678021, grad/param norm = 1.7788e-01, time/batch = 17.8790s	
20895/33650 (epoch 31.048), train_loss = 0.94909828, grad/param norm = 1.5577e-01, time/batch = 17.8950s	
20896/33650 (epoch 31.049), train_loss = 0.85263918, grad/param norm = 1.7298e-01, time/batch = 17.6391s	
20897/33650 (epoch 31.051), train_loss = 1.02124450, grad/param norm = 1.6214e-01, time/batch = 18.3934s	
20898/33650 (epoch 31.052), train_loss = 1.03207880, grad/param norm = 1.8639e-01, time/batch = 17.8147s	
20899/33650 (epoch 31.053), train_loss = 0.96510572, grad/param norm = 1.6377e-01, time/batch = 16.7975s	
20900/33650 (epoch 31.055), train_loss = 0.81119196, grad/param norm = 1.4974e-01, time/batch = 18.8083s	
20901/33650 (epoch 31.056), train_loss = 0.78065380, grad/param norm = 1.2863e-01, time/batch = 18.3936s	
20902/33650 (epoch 31.058), train_loss = 0.96729930, grad/param norm = 2.0209e-01, time/batch = 16.7119s	
20903/33650 (epoch 31.059), train_loss = 0.95578485, grad/param norm = 1.6447e-01, time/batch = 17.7209s	
20904/33650 (epoch 31.061), train_loss = 0.97755768, grad/param norm = 1.5770e-01, time/batch = 16.8862s	
20905/33650 (epoch 31.062), train_loss = 0.92793444, grad/param norm = 1.3976e-01, time/batch = 18.5757s	
20906/33650 (epoch 31.064), train_loss = 0.86720749, grad/param norm = 1.5382e-01, time/batch = 16.6352s	
20907/33650 (epoch 31.065), train_loss = 0.85807821, grad/param norm = 1.8005e-01, time/batch = 17.7289s	
20908/33650 (epoch 31.067), train_loss = 0.78254184, grad/param norm = 1.2831e-01, time/batch = 18.8109s	
20909/33650 (epoch 31.068), train_loss = 0.89868186, grad/param norm = 1.7631e-01, time/batch = 17.7190s	
20910/33650 (epoch 31.070), train_loss = 0.96497565, grad/param norm = 1.7286e-01, time/batch = 17.4819s	
20911/33650 (epoch 31.071), train_loss = 0.85328058, grad/param norm = 1.6777e-01, time/batch = 18.8823s	
20912/33650 (epoch 31.073), train_loss = 0.93873686, grad/param norm = 1.8480e-01, time/batch = 17.4749s	
20913/33650 (epoch 31.074), train_loss = 1.00856754, grad/param norm = 1.5662e-01, time/batch = 16.0904s	
20914/33650 (epoch 31.076), train_loss = 0.98058511, grad/param norm = 1.9854e-01, time/batch = 18.0641s	
20915/33650 (epoch 31.077), train_loss = 0.87382941, grad/param norm = 1.5024e-01, time/batch = 18.6467s	
20916/33650 (epoch 31.079), train_loss = 0.92954318, grad/param norm = 1.4728e-01, time/batch = 17.2248s	
20917/33650 (epoch 31.080), train_loss = 0.94079438, grad/param norm = 1.6150e-01, time/batch = 17.7399s	
20918/33650 (epoch 31.082), train_loss = 0.88772173, grad/param norm = 1.4296e-01, time/batch = 18.7316s	
20919/33650 (epoch 31.083), train_loss = 0.92490713, grad/param norm = 1.7046e-01, time/batch = 17.3914s	
20920/33650 (epoch 31.085), train_loss = 0.99031070, grad/param norm = 1.6197e-01, time/batch = 18.3865s	
20921/33650 (epoch 31.086), train_loss = 0.94223068, grad/param norm = 1.6723e-01, time/batch = 14.0725s	
20922/33650 (epoch 31.088), train_loss = 0.88464803, grad/param norm = 1.5330e-01, time/batch = 13.8307s	
20923/33650 (epoch 31.089), train_loss = 0.84695147, grad/param norm = 1.6829e-01, time/batch = 14.2289s	
20924/33650 (epoch 31.091), train_loss = 0.86975768, grad/param norm = 1.4785e-01, time/batch = 18.3738s	
20925/33650 (epoch 31.092), train_loss = 0.89642490, grad/param norm = 1.9994e-01, time/batch = 18.3184s	
20926/33650 (epoch 31.094), train_loss = 0.96921437, grad/param norm = 1.5312e-01, time/batch = 18.5615s	
20927/33650 (epoch 31.095), train_loss = 0.94323520, grad/param norm = 1.7703e-01, time/batch = 16.9713s	
20928/33650 (epoch 31.097), train_loss = 0.83298348, grad/param norm = 1.6564e-01, time/batch = 17.9031s	
20929/33650 (epoch 31.098), train_loss = 0.73276233, grad/param norm = 1.5777e-01, time/batch = 18.7204s	
20930/33650 (epoch 31.100), train_loss = 0.80854949, grad/param norm = 1.5232e-01, time/batch = 17.8845s	
20931/33650 (epoch 31.101), train_loss = 0.89491769, grad/param norm = 1.7920e-01, time/batch = 18.4004s	
20932/33650 (epoch 31.103), train_loss = 0.88648741, grad/param norm = 1.6611e-01, time/batch = 15.8951s	
20933/33650 (epoch 31.104), train_loss = 1.01192154, grad/param norm = 1.6374e-01, time/batch = 17.5360s	
20934/33650 (epoch 31.105), train_loss = 0.91159467, grad/param norm = 1.7113e-01, time/batch = 17.4748s	
20935/33650 (epoch 31.107), train_loss = 0.84806206, grad/param norm = 1.5989e-01, time/batch = 17.8118s	
20936/33650 (epoch 31.108), train_loss = 0.93861684, grad/param norm = 1.5734e-01, time/batch = 18.7919s	
20937/33650 (epoch 31.110), train_loss = 1.03121584, grad/param norm = 1.6756e-01, time/batch = 31.7664s	
20938/33650 (epoch 31.111), train_loss = 0.87884605, grad/param norm = 1.6792e-01, time/batch = 18.8900s	
20939/33650 (epoch 31.113), train_loss = 0.82333756, grad/param norm = 1.5196e-01, time/batch = 16.6323s	
20940/33650 (epoch 31.114), train_loss = 0.95785856, grad/param norm = 1.5462e-01, time/batch = 18.8172s	
20941/33650 (epoch 31.116), train_loss = 0.81403481, grad/param norm = 1.2744e-01, time/batch = 17.6538s	
20942/33650 (epoch 31.117), train_loss = 0.87441964, grad/param norm = 1.4219e-01, time/batch = 17.1479s	
20943/33650 (epoch 31.119), train_loss = 0.80972435, grad/param norm = 1.3901e-01, time/batch = 18.9772s	
20944/33650 (epoch 31.120), train_loss = 0.83237272, grad/param norm = 1.4199e-01, time/batch = 17.6525s	
20945/33650 (epoch 31.122), train_loss = 0.68350798, grad/param norm = 1.4591e-01, time/batch = 17.6408s	
20946/33650 (epoch 31.123), train_loss = 0.84045962, grad/param norm = 1.4868e-01, time/batch = 17.2155s	
20947/33650 (epoch 31.125), train_loss = 0.92660424, grad/param norm = 1.5237e-01, time/batch = 15.7193s	
20948/33650 (epoch 31.126), train_loss = 0.98254156, grad/param norm = 1.8833e-01, time/batch = 16.1481s	
20949/33650 (epoch 31.128), train_loss = 0.94866511, grad/param norm = 1.6909e-01, time/batch = 16.4701s	
20950/33650 (epoch 31.129), train_loss = 0.96626286, grad/param norm = 1.6720e-01, time/batch = 17.1567s	
20951/33650 (epoch 31.131), train_loss = 0.91557237, grad/param norm = 1.7290e-01, time/batch = 17.8919s	
20952/33650 (epoch 31.132), train_loss = 0.89498309, grad/param norm = 1.4568e-01, time/batch = 17.5620s	
20953/33650 (epoch 31.134), train_loss = 0.98123477, grad/param norm = 1.7408e-01, time/batch = 16.9741s	
20954/33650 (epoch 31.135), train_loss = 0.79621748, grad/param norm = 1.5578e-01, time/batch = 17.4849s	
20955/33650 (epoch 31.137), train_loss = 0.94099177, grad/param norm = 1.8939e-01, time/batch = 17.7297s	
20956/33650 (epoch 31.138), train_loss = 0.96639571, grad/param norm = 1.5434e-01, time/batch = 16.7222s	
20957/33650 (epoch 31.140), train_loss = 0.89912108, grad/param norm = 1.7342e-01, time/batch = 18.0626s	
20958/33650 (epoch 31.141), train_loss = 1.03432779, grad/param norm = 1.6886e-01, time/batch = 17.5503s	
20959/33650 (epoch 31.143), train_loss = 1.04684503, grad/param norm = 2.0710e-01, time/batch = 15.7437s	
20960/33650 (epoch 31.144), train_loss = 0.93333020, grad/param norm = 1.6384e-01, time/batch = 16.0599s	
20961/33650 (epoch 31.146), train_loss = 0.87615830, grad/param norm = 1.5621e-01, time/batch = 17.0694s	
20962/33650 (epoch 31.147), train_loss = 0.83062643, grad/param norm = 1.5613e-01, time/batch = 18.3223s	
20963/33650 (epoch 31.149), train_loss = 0.80067668, grad/param norm = 1.6682e-01, time/batch = 16.3137s	
20964/33650 (epoch 31.150), train_loss = 0.77509933, grad/param norm = 1.5430e-01, time/batch = 17.6417s	
20965/33650 (epoch 31.152), train_loss = 0.84567777, grad/param norm = 1.5133e-01, time/batch = 15.5468s	
20966/33650 (epoch 31.153), train_loss = 0.87305901, grad/param norm = 1.6682e-01, time/batch = 17.7359s	
20967/33650 (epoch 31.155), train_loss = 0.81923569, grad/param norm = 1.4104e-01, time/batch = 16.8891s	
20968/33650 (epoch 31.156), train_loss = 0.80893667, grad/param norm = 1.3646e-01, time/batch = 17.9903s	
20969/33650 (epoch 31.158), train_loss = 0.92364742, grad/param norm = 1.6306e-01, time/batch = 17.8157s	
20970/33650 (epoch 31.159), train_loss = 0.82771337, grad/param norm = 1.4323e-01, time/batch = 16.0591s	
20971/33650 (epoch 31.160), train_loss = 0.82169827, grad/param norm = 1.3523e-01, time/batch = 17.8243s	
20972/33650 (epoch 31.162), train_loss = 0.84382462, grad/param norm = 1.5948e-01, time/batch = 17.3160s	
20973/33650 (epoch 31.163), train_loss = 0.92319962, grad/param norm = 1.7147e-01, time/batch = 17.0587s	
20974/33650 (epoch 31.165), train_loss = 0.78818861, grad/param norm = 1.5569e-01, time/batch = 17.4819s	
20975/33650 (epoch 31.166), train_loss = 0.78436580, grad/param norm = 1.4354e-01, time/batch = 17.6568s	
20976/33650 (epoch 31.168), train_loss = 1.01105682, grad/param norm = 1.7980e-01, time/batch = 16.7279s	
20977/33650 (epoch 31.169), train_loss = 0.88477383, grad/param norm = 1.5961e-01, time/batch = 16.3833s	
20978/33650 (epoch 31.171), train_loss = 0.88098976, grad/param norm = 1.4871e-01, time/batch = 16.7326s	
20979/33650 (epoch 31.172), train_loss = 0.84549439, grad/param norm = 1.5755e-01, time/batch = 16.0812s	
20980/33650 (epoch 31.174), train_loss = 0.79832099, grad/param norm = 1.7202e-01, time/batch = 17.0764s	
20981/33650 (epoch 31.175), train_loss = 0.77690568, grad/param norm = 1.7248e-01, time/batch = 17.5591s	
20982/33650 (epoch 31.177), train_loss = 0.87736230, grad/param norm = 1.6608e-01, time/batch = 16.9740s	
20983/33650 (epoch 31.178), train_loss = 0.84031636, grad/param norm = 1.7899e-01, time/batch = 17.2096s	
20984/33650 (epoch 31.180), train_loss = 0.79671760, grad/param norm = 1.5248e-01, time/batch = 16.2162s	
20985/33650 (epoch 31.181), train_loss = 0.71170191, grad/param norm = 1.3303e-01, time/batch = 17.1543s	
20986/33650 (epoch 31.183), train_loss = 0.82017387, grad/param norm = 1.9578e-01, time/batch = 17.9047s	
20987/33650 (epoch 31.184), train_loss = 0.81697811, grad/param norm = 1.8749e-01, time/batch = 17.4864s	
20988/33650 (epoch 31.186), train_loss = 0.87930059, grad/param norm = 1.9278e-01, time/batch = 17.5550s	
20989/33650 (epoch 31.187), train_loss = 1.02084952, grad/param norm = 1.9308e-01, time/batch = 15.7947s	
20990/33650 (epoch 31.189), train_loss = 0.99551110, grad/param norm = 1.9691e-01, time/batch = 16.6392s	
20991/33650 (epoch 31.190), train_loss = 0.91387617, grad/param norm = 1.9144e-01, time/batch = 16.3934s	
20992/33650 (epoch 31.192), train_loss = 1.04774563, grad/param norm = 1.5645e-01, time/batch = 17.1564s	
20993/33650 (epoch 31.193), train_loss = 1.02232313, grad/param norm = 1.7329e-01, time/batch = 17.4748s	
20994/33650 (epoch 31.195), train_loss = 0.77980410, grad/param norm = 1.6414e-01, time/batch = 17.6563s	
20995/33650 (epoch 31.196), train_loss = 0.72797338, grad/param norm = 1.5821e-01, time/batch = 16.8147s	
20996/33650 (epoch 31.198), train_loss = 0.86089807, grad/param norm = 1.5967e-01, time/batch = 16.3181s	
20997/33650 (epoch 31.199), train_loss = 0.95098767, grad/param norm = 1.7530e-01, time/batch = 16.0755s	
20998/33650 (epoch 31.201), train_loss = 0.83164157, grad/param norm = 1.6686e-01, time/batch = 16.9743s	
20999/33650 (epoch 31.202), train_loss = 0.86432738, grad/param norm = 1.4451e-01, time/batch = 17.0542s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch31.20_1.7042.t7	
21000/33650 (epoch 31.204), train_loss = 0.92343847, grad/param norm = 1.6231e-01, time/batch = 17.4730s	
21001/33650 (epoch 31.205), train_loss = 1.19021732, grad/param norm = 1.7799e-01, time/batch = 17.3126s	
21002/33650 (epoch 31.207), train_loss = 0.80100798, grad/param norm = 1.6370e-01, time/batch = 16.4613s	
21003/33650 (epoch 31.208), train_loss = 0.90355833, grad/param norm = 1.5727e-01, time/batch = 17.2180s	
21004/33650 (epoch 31.210), train_loss = 0.72197065, grad/param norm = 1.7756e-01, time/batch = 15.7254s	
21005/33650 (epoch 31.211), train_loss = 0.82662913, grad/param norm = 1.8551e-01, time/batch = 18.0738s	
21006/33650 (epoch 31.212), train_loss = 0.91947435, grad/param norm = 1.8434e-01, time/batch = 16.7204s	
21007/33650 (epoch 31.214), train_loss = 1.04730004, grad/param norm = 1.7305e-01, time/batch = 17.0636s	
21008/33650 (epoch 31.215), train_loss = 0.69205884, grad/param norm = 1.6525e-01, time/batch = 16.9685s	
21009/33650 (epoch 31.217), train_loss = 0.85660641, grad/param norm = 1.7610e-01, time/batch = 18.3959s	
21010/33650 (epoch 31.218), train_loss = 0.86757772, grad/param norm = 1.4800e-01, time/batch = 16.3032s	
21011/33650 (epoch 31.220), train_loss = 0.76843040, grad/param norm = 1.6497e-01, time/batch = 15.8823s	
21012/33650 (epoch 31.221), train_loss = 1.02527645, grad/param norm = 1.7237e-01, time/batch = 17.0691s	
21013/33650 (epoch 31.223), train_loss = 0.72741218, grad/param norm = 1.6540e-01, time/batch = 17.9052s	
21014/33650 (epoch 31.224), train_loss = 0.83353173, grad/param norm = 1.9314e-01, time/batch = 17.2221s	
21015/33650 (epoch 31.226), train_loss = 1.12650801, grad/param norm = 1.6081e-01, time/batch = 15.8903s	
21016/33650 (epoch 31.227), train_loss = 0.98208900, grad/param norm = 1.7880e-01, time/batch = 18.0731s	
21017/33650 (epoch 31.229), train_loss = 0.99949915, grad/param norm = 1.9284e-01, time/batch = 17.6581s	
21018/33650 (epoch 31.230), train_loss = 1.11684302, grad/param norm = 2.0894e-01, time/batch = 17.0634s	
21019/33650 (epoch 31.232), train_loss = 0.96542466, grad/param norm = 2.2193e-01, time/batch = 16.6389s	
21020/33650 (epoch 31.233), train_loss = 0.95309812, grad/param norm = 3.7996e-01, time/batch = 18.2350s	
21021/33650 (epoch 31.235), train_loss = 0.90091576, grad/param norm = 1.7545e-01, time/batch = 17.4763s	
21022/33650 (epoch 31.236), train_loss = 0.82708361, grad/param norm = 1.3984e-01, time/batch = 16.8057s	
21023/33650 (epoch 31.238), train_loss = 0.85075067, grad/param norm = 1.5294e-01, time/batch = 16.4848s	
21024/33650 (epoch 31.239), train_loss = 0.81886193, grad/param norm = 1.9190e-01, time/batch = 17.6622s	
21025/33650 (epoch 31.241), train_loss = 0.86256741, grad/param norm = 1.3901e-01, time/batch = 16.1453s	
21026/33650 (epoch 31.242), train_loss = 0.72399043, grad/param norm = 1.5403e-01, time/batch = 17.4008s	
21027/33650 (epoch 31.244), train_loss = 0.85587991, grad/param norm = 1.5977e-01, time/batch = 16.4635s	
21028/33650 (epoch 31.245), train_loss = 0.76115781, grad/param norm = 1.4296e-01, time/batch = 17.0571s	
21029/33650 (epoch 31.247), train_loss = 0.83352393, grad/param norm = 1.4028e-01, time/batch = 16.9806s	
21030/33650 (epoch 31.248), train_loss = 0.78050630, grad/param norm = 1.5602e-01, time/batch = 17.4212s	
21031/33650 (epoch 31.250), train_loss = 0.86665359, grad/param norm = 1.5861e-01, time/batch = 16.5699s	
21032/33650 (epoch 31.251), train_loss = 0.99263542, grad/param norm = 1.5682e-01, time/batch = 15.8759s	
21033/33650 (epoch 31.253), train_loss = 0.78214919, grad/param norm = 1.5953e-01, time/batch = 17.9828s	
21034/33650 (epoch 31.254), train_loss = 0.83858432, grad/param norm = 1.7146e-01, time/batch = 17.3214s	
21035/33650 (epoch 31.256), train_loss = 1.00946335, grad/param norm = 1.5174e-01, time/batch = 17.7292s	
21036/33650 (epoch 31.257), train_loss = 0.99063310, grad/param norm = 1.7544e-01, time/batch = 16.3861s	
21037/33650 (epoch 31.259), train_loss = 0.79686228, grad/param norm = 1.6286e-01, time/batch = 17.9057s	
21038/33650 (epoch 31.260), train_loss = 0.93401749, grad/param norm = 1.8256e-01, time/batch = 17.0679s	
21039/33650 (epoch 31.262), train_loss = 0.90420518, grad/param norm = 1.7577e-01, time/batch = 17.1450s	
21040/33650 (epoch 31.263), train_loss = 0.84204248, grad/param norm = 1.9033e-01, time/batch = 17.4073s	
21041/33650 (epoch 31.264), train_loss = 0.93001746, grad/param norm = 1.8653e-01, time/batch = 17.6479s	
21042/33650 (epoch 31.266), train_loss = 0.90919187, grad/param norm = 1.5116e-01, time/batch = 16.7307s	
21043/33650 (epoch 31.267), train_loss = 0.83536610, grad/param norm = 1.6092e-01, time/batch = 16.5595s	
21044/33650 (epoch 31.269), train_loss = 0.89159642, grad/param norm = 1.5155e-01, time/batch = 17.9069s	
21045/33650 (epoch 31.270), train_loss = 0.80409436, grad/param norm = 1.5894e-01, time/batch = 16.9053s	
21046/33650 (epoch 31.272), train_loss = 0.83777750, grad/param norm = 1.4878e-01, time/batch = 16.3022s	
21047/33650 (epoch 31.273), train_loss = 0.96486092, grad/param norm = 1.7230e-01, time/batch = 17.0615s	
21048/33650 (epoch 31.275), train_loss = 0.90998415, grad/param norm = 1.4197e-01, time/batch = 17.7296s	
21049/33650 (epoch 31.276), train_loss = 0.96599844, grad/param norm = 1.7989e-01, time/batch = 16.9003s	
21050/33650 (epoch 31.278), train_loss = 1.06984177, grad/param norm = 2.2542e-01, time/batch = 16.8939s	
21051/33650 (epoch 31.279), train_loss = 0.85992958, grad/param norm = 1.4393e-01, time/batch = 15.0266s	
21052/33650 (epoch 31.281), train_loss = 0.90807670, grad/param norm = 1.9154e-01, time/batch = 17.4872s	
21053/33650 (epoch 31.282), train_loss = 1.00509439, grad/param norm = 1.6388e-01, time/batch = 16.6386s	
21054/33650 (epoch 31.284), train_loss = 0.97274685, grad/param norm = 1.8612e-01, time/batch = 17.3976s	
21055/33650 (epoch 31.285), train_loss = 0.93583370, grad/param norm = 1.7751e-01, time/batch = 18.2295s	
21056/33650 (epoch 31.287), train_loss = 0.84754459, grad/param norm = 1.7032e-01, time/batch = 16.3812s	
21057/33650 (epoch 31.288), train_loss = 0.88329857, grad/param norm = 1.7796e-01, time/batch = 15.7154s	
21058/33650 (epoch 31.290), train_loss = 0.89041498, grad/param norm = 1.5803e-01, time/batch = 16.8159s	
21059/33650 (epoch 31.291), train_loss = 0.81417624, grad/param norm = 1.4493e-01, time/batch = 17.0753s	
21060/33650 (epoch 31.293), train_loss = 0.89092485, grad/param norm = 1.8372e-01, time/batch = 16.5626s	
21061/33650 (epoch 31.294), train_loss = 0.79573714, grad/param norm = 1.2941e-01, time/batch = 17.0686s	
21062/33650 (epoch 31.296), train_loss = 0.78760477, grad/param norm = 1.5555e-01, time/batch = 18.2405s	
21063/33650 (epoch 31.297), train_loss = 0.84878166, grad/param norm = 1.5851e-01, time/batch = 16.7333s	
21064/33650 (epoch 31.299), train_loss = 0.76144673, grad/param norm = 1.6304e-01, time/batch = 16.9009s	
21065/33650 (epoch 31.300), train_loss = 0.78948159, grad/param norm = 1.5427e-01, time/batch = 17.3257s	
21066/33650 (epoch 31.302), train_loss = 0.90314650, grad/param norm = 1.6446e-01, time/batch = 18.1576s	
21067/33650 (epoch 31.303), train_loss = 0.92003263, grad/param norm = 1.4606e-01, time/batch = 16.1443s	
21068/33650 (epoch 31.305), train_loss = 0.87974690, grad/param norm = 1.5589e-01, time/batch = 16.8883s	
21069/33650 (epoch 31.306), train_loss = 0.80569271, grad/param norm = 1.3042e-01, time/batch = 17.4904s	
21070/33650 (epoch 31.308), train_loss = 0.79261748, grad/param norm = 1.8398e-01, time/batch = 17.6558s	
21071/33650 (epoch 31.309), train_loss = 1.03014446, grad/param norm = 1.9563e-01, time/batch = 17.9787s	
21072/33650 (epoch 31.311), train_loss = 0.88250983, grad/param norm = 2.0488e-01, time/batch = 15.4901s	
21073/33650 (epoch 31.312), train_loss = 0.92018427, grad/param norm = 1.8040e-01, time/batch = 17.3228s	
21074/33650 (epoch 31.314), train_loss = 0.81265383, grad/param norm = 1.7260e-01, time/batch = 15.8670s	
21075/33650 (epoch 31.315), train_loss = 0.86944590, grad/param norm = 1.9108e-01, time/batch = 17.6560s	
21076/33650 (epoch 31.316), train_loss = 0.83680631, grad/param norm = 1.7439e-01, time/batch = 16.7255s	
21077/33650 (epoch 31.318), train_loss = 0.78553468, grad/param norm = 1.4291e-01, time/batch = 17.2398s	
21078/33650 (epoch 31.319), train_loss = 0.80873057, grad/param norm = 1.4354e-01, time/batch = 16.7309s	
21079/33650 (epoch 31.321), train_loss = 0.83383696, grad/param norm = 1.3799e-01, time/batch = 17.4101s	
21080/33650 (epoch 31.322), train_loss = 0.90917479, grad/param norm = 2.0020e-01, time/batch = 16.3085s	
21081/33650 (epoch 31.324), train_loss = 0.93899698, grad/param norm = 2.0469e-01, time/batch = 16.8107s	
21082/33650 (epoch 31.325), train_loss = 0.91143970, grad/param norm = 1.5577e-01, time/batch = 17.4087s	
21083/33650 (epoch 31.327), train_loss = 0.82114160, grad/param norm = 1.4732e-01, time/batch = 17.9040s	
21084/33650 (epoch 31.328), train_loss = 0.90275499, grad/param norm = 1.6900e-01, time/batch = 17.6507s	
21085/33650 (epoch 31.330), train_loss = 0.82022817, grad/param norm = 1.4781e-01, time/batch = 16.3953s	
21086/33650 (epoch 31.331), train_loss = 0.75738897, grad/param norm = 1.3295e-01, time/batch = 17.4851s	
21087/33650 (epoch 31.333), train_loss = 0.85160745, grad/param norm = 1.6182e-01, time/batch = 17.6529s	
21088/33650 (epoch 31.334), train_loss = 0.86718404, grad/param norm = 1.5832e-01, time/batch = 16.8155s	
21089/33650 (epoch 31.336), train_loss = 0.97090278, grad/param norm = 1.6219e-01, time/batch = 17.3969s	
21090/33650 (epoch 31.337), train_loss = 0.73327291, grad/param norm = 1.3485e-01, time/batch = 16.6207s	
21091/33650 (epoch 31.339), train_loss = 0.84220097, grad/param norm = 1.5328e-01, time/batch = 17.2185s	
21092/33650 (epoch 31.340), train_loss = 0.97467106, grad/param norm = 1.6638e-01, time/batch = 17.0619s	
21093/33650 (epoch 31.342), train_loss = 0.71756287, grad/param norm = 1.4536e-01, time/batch = 16.4872s	
21094/33650 (epoch 31.343), train_loss = 0.92470073, grad/param norm = 1.5944e-01, time/batch = 18.1629s	
21095/33650 (epoch 31.345), train_loss = 0.89492397, grad/param norm = 1.9050e-01, time/batch = 15.9810s	
21096/33650 (epoch 31.346), train_loss = 0.61760262, grad/param norm = 1.3867e-01, time/batch = 17.0759s	
21097/33650 (epoch 31.348), train_loss = 0.75066181, grad/param norm = 1.4131e-01, time/batch = 16.2228s	
21098/33650 (epoch 31.349), train_loss = 0.72265772, grad/param norm = 1.5642e-01, time/batch = 16.7463s	
21099/33650 (epoch 31.351), train_loss = 0.93713538, grad/param norm = 1.7428e-01, time/batch = 17.1352s	
21100/33650 (epoch 31.352), train_loss = 0.85230962, grad/param norm = 1.5832e-01, time/batch = 16.6719s	
21101/33650 (epoch 31.354), train_loss = 0.97987261, grad/param norm = 1.9539e-01, time/batch = 17.4881s	
21102/33650 (epoch 31.355), train_loss = 1.01590698, grad/param norm = 1.5657e-01, time/batch = 15.6940s	
21103/33650 (epoch 31.357), train_loss = 0.71666170, grad/param norm = 1.3898e-01, time/batch = 13.5789s	
21104/33650 (epoch 31.358), train_loss = 0.89628439, grad/param norm = 1.5676e-01, time/batch = 13.8285s	
21105/33650 (epoch 31.360), train_loss = 0.93021434, grad/param norm = 1.9012e-01, time/batch = 14.8134s	
21106/33650 (epoch 31.361), train_loss = 0.89888426, grad/param norm = 1.6461e-01, time/batch = 16.4059s	
21107/33650 (epoch 31.363), train_loss = 0.88652786, grad/param norm = 1.4880e-01, time/batch = 17.0772s	
21108/33650 (epoch 31.364), train_loss = 0.86936411, grad/param norm = 1.5328e-01, time/batch = 17.4122s	
21109/33650 (epoch 31.366), train_loss = 0.91834830, grad/param norm = 1.7523e-01, time/batch = 18.2356s	
21110/33650 (epoch 31.367), train_loss = 0.90458317, grad/param norm = 1.5012e-01, time/batch = 17.3981s	
21111/33650 (epoch 31.368), train_loss = 0.82320985, grad/param norm = 1.3609e-01, time/batch = 16.5749s	
21112/33650 (epoch 31.370), train_loss = 0.86164653, grad/param norm = 1.5227e-01, time/batch = 16.2339s	
21113/33650 (epoch 31.371), train_loss = 0.67494194, grad/param norm = 1.3449e-01, time/batch = 16.8769s	
21114/33650 (epoch 31.373), train_loss = 0.76454506, grad/param norm = 1.5488e-01, time/batch = 17.1499s	
21115/33650 (epoch 31.374), train_loss = 0.79566096, grad/param norm = 1.4125e-01, time/batch = 17.7551s	
21116/33650 (epoch 31.376), train_loss = 0.86693088, grad/param norm = 1.9890e-01, time/batch = 14.9729s	
21117/33650 (epoch 31.377), train_loss = 0.89095186, grad/param norm = 1.6328e-01, time/batch = 16.5633s	
21118/33650 (epoch 31.379), train_loss = 0.91017404, grad/param norm = 1.6722e-01, time/batch = 17.6539s	
21119/33650 (epoch 31.380), train_loss = 0.71957803, grad/param norm = 1.4883e-01, time/batch = 17.4036s	
21120/33650 (epoch 31.382), train_loss = 0.86465480, grad/param norm = 1.3862e-01, time/batch = 16.4036s	
21121/33650 (epoch 31.383), train_loss = 0.85614379, grad/param norm = 1.5760e-01, time/batch = 17.4806s	
21122/33650 (epoch 31.385), train_loss = 0.91568665, grad/param norm = 1.5800e-01, time/batch = 17.4928s	
21123/33650 (epoch 31.386), train_loss = 0.80034702, grad/param norm = 1.4398e-01, time/batch = 17.6571s	
21124/33650 (epoch 31.388), train_loss = 0.94292199, grad/param norm = 1.5417e-01, time/batch = 16.5710s	
21125/33650 (epoch 31.389), train_loss = 0.81404759, grad/param norm = 1.6526e-01, time/batch = 17.6504s	
21126/33650 (epoch 31.391), train_loss = 0.70332308, grad/param norm = 1.3580e-01, time/batch = 17.3972s	
21127/33650 (epoch 31.392), train_loss = 0.87944515, grad/param norm = 1.5127e-01, time/batch = 16.6483s	
21128/33650 (epoch 31.394), train_loss = 0.87689441, grad/param norm = 1.6353e-01, time/batch = 17.5674s	
21129/33650 (epoch 31.395), train_loss = 0.91170160, grad/param norm = 1.5997e-01, time/batch = 16.9826s	
21130/33650 (epoch 31.397), train_loss = 1.02984592, grad/param norm = 1.6472e-01, time/batch = 17.9116s	
21131/33650 (epoch 31.398), train_loss = 0.94951431, grad/param norm = 1.6437e-01, time/batch = 15.5497s	
21132/33650 (epoch 31.400), train_loss = 0.87038726, grad/param norm = 1.6974e-01, time/batch = 17.6476s	
21133/33650 (epoch 31.401), train_loss = 0.81902821, grad/param norm = 1.6835e-01, time/batch = 17.0681s	
21134/33650 (epoch 31.403), train_loss = 0.92112151, grad/param norm = 1.6637e-01, time/batch = 17.1465s	
21135/33650 (epoch 31.404), train_loss = 0.87326941, grad/param norm = 1.6339e-01, time/batch = 17.5714s	
21136/33650 (epoch 31.406), train_loss = 0.85520576, grad/param norm = 1.5151e-01, time/batch = 17.2312s	
21137/33650 (epoch 31.407), train_loss = 0.88401451, grad/param norm = 1.6875e-01, time/batch = 17.6571s	
21138/33650 (epoch 31.409), train_loss = 0.90680333, grad/param norm = 1.5675e-01, time/batch = 30.8289s	
21139/33650 (epoch 31.410), train_loss = 0.84526874, grad/param norm = 1.4165e-01, time/batch = 17.6439s	
21140/33650 (epoch 31.412), train_loss = 0.87273491, grad/param norm = 1.6582e-01, time/batch = 16.4110s	
21141/33650 (epoch 31.413), train_loss = 0.81566019, grad/param norm = 1.6610e-01, time/batch = 16.8666s	
21142/33650 (epoch 31.415), train_loss = 0.96043683, grad/param norm = 1.7612e-01, time/batch = 17.6665s	
21143/33650 (epoch 31.416), train_loss = 1.03331295, grad/param norm = 1.7671e-01, time/batch = 17.7312s	
21144/33650 (epoch 31.418), train_loss = 0.79954234, grad/param norm = 1.4661e-01, time/batch = 16.4696s	
21145/33650 (epoch 31.419), train_loss = 0.83135871, grad/param norm = 1.7374e-01, time/batch = 17.1705s	
21146/33650 (epoch 31.421), train_loss = 0.84042895, grad/param norm = 1.3762e-01, time/batch = 17.2411s	
21147/33650 (epoch 31.422), train_loss = 0.98875173, grad/param norm = 1.5495e-01, time/batch = 16.9826s	
21148/33650 (epoch 31.423), train_loss = 0.79051063, grad/param norm = 1.2236e-01, time/batch = 17.4770s	
21149/33650 (epoch 31.425), train_loss = 0.88404346, grad/param norm = 1.7243e-01, time/batch = 16.8071s	
21150/33650 (epoch 31.426), train_loss = 0.95664864, grad/param norm = 1.8343e-01, time/batch = 17.2395s	
21151/33650 (epoch 31.428), train_loss = 0.83529285, grad/param norm = 1.4704e-01, time/batch = 16.9659s	
21152/33650 (epoch 31.429), train_loss = 0.92960950, grad/param norm = 1.8481e-01, time/batch = 17.2398s	
21153/33650 (epoch 31.431), train_loss = 1.03176903, grad/param norm = 1.9528e-01, time/batch = 16.2530s	
21154/33650 (epoch 31.432), train_loss = 1.04489417, grad/param norm = 1.9199e-01, time/batch = 16.7277s	
21155/33650 (epoch 31.434), train_loss = 0.91675782, grad/param norm = 1.8034e-01, time/batch = 17.4848s	
21156/33650 (epoch 31.435), train_loss = 0.91615966, grad/param norm = 2.0380e-01, time/batch = 17.0454s	
21157/33650 (epoch 31.437), train_loss = 0.89892430, grad/param norm = 1.7261e-01, time/batch = 16.9810s	
21158/33650 (epoch 31.438), train_loss = 0.87341041, grad/param norm = 1.6538e-01, time/batch = 17.1409s	
21159/33650 (epoch 31.440), train_loss = 0.88372164, grad/param norm = 1.7191e-01, time/batch = 17.9830s	
21160/33650 (epoch 31.441), train_loss = 0.86973055, grad/param norm = 1.6546e-01, time/batch = 17.9022s	
21161/33650 (epoch 31.443), train_loss = 0.94358114, grad/param norm = 1.5116e-01, time/batch = 16.4873s	
21162/33650 (epoch 31.444), train_loss = 0.86201732, grad/param norm = 1.5641e-01, time/batch = 17.4857s	
21163/33650 (epoch 31.446), train_loss = 0.92915132, grad/param norm = 1.9676e-01, time/batch = 16.5652s	
21164/33650 (epoch 31.447), train_loss = 1.00368187, grad/param norm = 1.8149e-01, time/batch = 17.0584s	
21165/33650 (epoch 31.449), train_loss = 1.00456550, grad/param norm = 1.9463e-01, time/batch = 16.3159s	
21166/33650 (epoch 31.450), train_loss = 1.03348892, grad/param norm = 1.6746e-01, time/batch = 16.8101s	
21167/33650 (epoch 31.452), train_loss = 1.00818032, grad/param norm = 1.8683e-01, time/batch = 16.4865s	
21168/33650 (epoch 31.453), train_loss = 1.02296242, grad/param norm = 1.7489e-01, time/batch = 17.4063s	
21169/33650 (epoch 31.455), train_loss = 0.87621931, grad/param norm = 1.5967e-01, time/batch = 17.3238s	
21170/33650 (epoch 31.456), train_loss = 0.86807182, grad/param norm = 1.5402e-01, time/batch = 18.1588s	
21171/33650 (epoch 31.458), train_loss = 0.87965683, grad/param norm = 1.7375e-01, time/batch = 17.8206s	
21172/33650 (epoch 31.459), train_loss = 0.92656260, grad/param norm = 1.8213e-01, time/batch = 15.3940s	
21173/33650 (epoch 31.461), train_loss = 0.97630138, grad/param norm = 1.9149e-01, time/batch = 17.9047s	
21174/33650 (epoch 31.462), train_loss = 0.98709019, grad/param norm = 1.8773e-01, time/batch = 17.4834s	
21175/33650 (epoch 31.464), train_loss = 0.86676724, grad/param norm = 1.8080e-01, time/batch = 15.9780s	
21176/33650 (epoch 31.465), train_loss = 0.93567042, grad/param norm = 2.0677e-01, time/batch = 16.4870s	
21177/33650 (epoch 31.467), train_loss = 0.92840319, grad/param norm = 1.5806e-01, time/batch = 18.0746s	
21178/33650 (epoch 31.468), train_loss = 1.03553783, grad/param norm = 1.5781e-01, time/batch = 17.3944s	
21179/33650 (epoch 31.470), train_loss = 1.11173682, grad/param norm = 2.1135e-01, time/batch = 16.8037s	
21180/33650 (epoch 31.471), train_loss = 0.89942106, grad/param norm = 1.8263e-01, time/batch = 16.4859s	
21181/33650 (epoch 31.473), train_loss = 0.86430588, grad/param norm = 1.5619e-01, time/batch = 17.1509s	
21182/33650 (epoch 31.474), train_loss = 1.00622767, grad/param norm = 1.8736e-01, time/batch = 16.8170s	
21183/33650 (epoch 31.475), train_loss = 0.98666484, grad/param norm = 1.9801e-01, time/batch = 15.4754s	
21184/33650 (epoch 31.477), train_loss = 0.98968036, grad/param norm = 1.6965e-01, time/batch = 17.6519s	
21185/33650 (epoch 31.478), train_loss = 0.99641867, grad/param norm = 1.8390e-01, time/batch = 17.2403s	
21186/33650 (epoch 31.480), train_loss = 0.99306656, grad/param norm = 2.2722e-01, time/batch = 16.3163s	
21187/33650 (epoch 31.481), train_loss = 1.01779350, grad/param norm = 1.7846e-01, time/batch = 18.1626s	
21188/33650 (epoch 31.483), train_loss = 0.78026376, grad/param norm = 1.6984e-01, time/batch = 16.6518s	
21189/33650 (epoch 31.484), train_loss = 0.87493408, grad/param norm = 1.6375e-01, time/batch = 16.9791s	
21190/33650 (epoch 31.486), train_loss = 1.05477020, grad/param norm = 1.8259e-01, time/batch = 17.2271s	
21191/33650 (epoch 31.487), train_loss = 1.01385102, grad/param norm = 1.8320e-01, time/batch = 18.2390s	
21192/33650 (epoch 31.489), train_loss = 1.07128138, grad/param norm = 1.8609e-01, time/batch = 17.3301s	
21193/33650 (epoch 31.490), train_loss = 0.83624727, grad/param norm = 1.6759e-01, time/batch = 16.4565s	
21194/33650 (epoch 31.492), train_loss = 0.93951778, grad/param norm = 1.7248e-01, time/batch = 16.4037s	
21195/33650 (epoch 31.493), train_loss = 0.76110693, grad/param norm = 1.3769e-01, time/batch = 15.3162s	
21196/33650 (epoch 31.495), train_loss = 0.92191751, grad/param norm = 1.5144e-01, time/batch = 17.2167s	
21197/33650 (epoch 31.496), train_loss = 0.95588857, grad/param norm = 1.6787e-01, time/batch = 17.2417s	
21198/33650 (epoch 31.498), train_loss = 0.83577679, grad/param norm = 1.4957e-01, time/batch = 17.4042s	
21199/33650 (epoch 31.499), train_loss = 0.91198377, grad/param norm = 1.3881e-01, time/batch = 17.0556s	
21200/33650 (epoch 31.501), train_loss = 0.89300901, grad/param norm = 1.3863e-01, time/batch = 16.8039s	
21201/33650 (epoch 31.502), train_loss = 0.93235694, grad/param norm = 1.8346e-01, time/batch = 17.9879s	
21202/33650 (epoch 31.504), train_loss = 0.98983533, grad/param norm = 1.9472e-01, time/batch = 17.7318s	
21203/33650 (epoch 31.505), train_loss = 0.87642701, grad/param norm = 1.7315e-01, time/batch = 16.3265s	
21204/33650 (epoch 31.507), train_loss = 1.00960620, grad/param norm = 1.6404e-01, time/batch = 18.0664s	
21205/33650 (epoch 31.508), train_loss = 0.88822506, grad/param norm = 1.5807e-01, time/batch = 17.8222s	
21206/33650 (epoch 31.510), train_loss = 0.92607488, grad/param norm = 1.6469e-01, time/batch = 17.5725s	
21207/33650 (epoch 31.511), train_loss = 1.06101972, grad/param norm = 2.0923e-01, time/batch = 16.3042s	
21208/33650 (epoch 31.513), train_loss = 0.95158682, grad/param norm = 1.5765e-01, time/batch = 17.2253s	
21209/33650 (epoch 31.514), train_loss = 0.99727881, grad/param norm = 1.7319e-01, time/batch = 17.6633s	
21210/33650 (epoch 31.516), train_loss = 0.91674839, grad/param norm = 1.6880e-01, time/batch = 15.8964s	
21211/33650 (epoch 31.517), train_loss = 0.92983632, grad/param norm = 1.7877e-01, time/batch = 16.9025s	
21212/33650 (epoch 31.519), train_loss = 0.96083912, grad/param norm = 1.5530e-01, time/batch = 17.7386s	
21213/33650 (epoch 31.520), train_loss = 0.78272198, grad/param norm = 1.3438e-01, time/batch = 17.6476s	
21214/33650 (epoch 31.522), train_loss = 0.90225412, grad/param norm = 1.7665e-01, time/batch = 15.2254s	
21215/33650 (epoch 31.523), train_loss = 0.83447381, grad/param norm = 1.6441e-01, time/batch = 16.7321s	
21216/33650 (epoch 31.525), train_loss = 0.71299650, grad/param norm = 1.2725e-01, time/batch = 16.5743s	
21217/33650 (epoch 31.526), train_loss = 1.00716783, grad/param norm = 1.5382e-01, time/batch = 17.3986s	
21218/33650 (epoch 31.527), train_loss = 0.85636430, grad/param norm = 1.6254e-01, time/batch = 16.6395s	
21219/33650 (epoch 31.529), train_loss = 0.91104180, grad/param norm = 1.7993e-01, time/batch = 17.7343s	
21220/33650 (epoch 31.530), train_loss = 0.84499619, grad/param norm = 1.6079e-01, time/batch = 17.3282s	
21221/33650 (epoch 31.532), train_loss = 0.98714496, grad/param norm = 2.0809e-01, time/batch = 16.7194s	
21222/33650 (epoch 31.533), train_loss = 0.91600781, grad/param norm = 1.4969e-01, time/batch = 17.4836s	
21223/33650 (epoch 31.535), train_loss = 1.02832900, grad/param norm = 1.7453e-01, time/batch = 17.9002s	
21224/33650 (epoch 31.536), train_loss = 0.92032702, grad/param norm = 1.7989e-01, time/batch = 16.7250s	
21225/33650 (epoch 31.538), train_loss = 0.93224720, grad/param norm = 1.7099e-01, time/batch = 17.9954s	
21226/33650 (epoch 31.539), train_loss = 0.72463381, grad/param norm = 1.4788e-01, time/batch = 16.7399s	
21227/33650 (epoch 31.541), train_loss = 1.00262086, grad/param norm = 1.7659e-01, time/batch = 17.3224s	
21228/33650 (epoch 31.542), train_loss = 0.91360613, grad/param norm = 2.4852e-01, time/batch = 17.1422s	
21229/33650 (epoch 31.544), train_loss = 1.09516485, grad/param norm = 2.8147e-01, time/batch = 17.3223s	
21230/33650 (epoch 31.545), train_loss = 0.83757009, grad/param norm = 1.6913e-01, time/batch = 17.5785s	
21231/33650 (epoch 31.547), train_loss = 0.95564280, grad/param norm = 1.6744e-01, time/batch = 16.4871s	
21232/33650 (epoch 31.548), train_loss = 1.07119373, grad/param norm = 1.7139e-01, time/batch = 17.1548s	
21233/33650 (epoch 31.550), train_loss = 0.95845439, grad/param norm = 2.3188e-01, time/batch = 16.2930s	
21234/33650 (epoch 31.551), train_loss = 0.92892858, grad/param norm = 1.7631e-01, time/batch = 15.4886s	
21235/33650 (epoch 31.553), train_loss = 0.80820620, grad/param norm = 1.7795e-01, time/batch = 16.8055s	
21236/33650 (epoch 31.554), train_loss = 1.07376024, grad/param norm = 1.9526e-01, time/batch = 17.5680s	
21237/33650 (epoch 31.556), train_loss = 1.01477080, grad/param norm = 2.5870e-01, time/batch = 17.1465s	
21238/33650 (epoch 31.557), train_loss = 0.97759433, grad/param norm = 1.8216e-01, time/batch = 15.9052s	
21239/33650 (epoch 31.559), train_loss = 1.17685761, grad/param norm = 2.0643e-01, time/batch = 17.4093s	
21240/33650 (epoch 31.560), train_loss = 1.07853122, grad/param norm = 1.9385e-01, time/batch = 17.3321s	
21241/33650 (epoch 31.562), train_loss = 1.04707872, grad/param norm = 1.6331e-01, time/batch = 17.9839s	
21242/33650 (epoch 31.563), train_loss = 0.94446795, grad/param norm = 1.6795e-01, time/batch = 16.3806s	
21243/33650 (epoch 31.565), train_loss = 0.95380079, grad/param norm = 1.8661e-01, time/batch = 17.5730s	
21244/33650 (epoch 31.566), train_loss = 0.90498836, grad/param norm = 1.8358e-01, time/batch = 18.0713s	
21245/33650 (epoch 31.568), train_loss = 0.94483051, grad/param norm = 2.3922e-01, time/batch = 16.1508s	
21246/33650 (epoch 31.569), train_loss = 0.85324929, grad/param norm = 1.5147e-01, time/batch = 17.8183s	
21247/33650 (epoch 31.571), train_loss = 1.02485151, grad/param norm = 1.7698e-01, time/batch = 17.4798s	
21248/33650 (epoch 31.572), train_loss = 0.98740525, grad/param norm = 1.6341e-01, time/batch = 15.9883s	
21249/33650 (epoch 31.574), train_loss = 0.84445877, grad/param norm = 1.6873e-01, time/batch = 13.8196s	
21250/33650 (epoch 31.575), train_loss = 0.91488930, grad/param norm = 1.6122e-01, time/batch = 13.4076s	
21251/33650 (epoch 31.577), train_loss = 0.85486851, grad/param norm = 1.8093e-01, time/batch = 15.1356s	
21252/33650 (epoch 31.578), train_loss = 1.02463265, grad/param norm = 1.8941e-01, time/batch = 16.7988s	
21253/33650 (epoch 31.579), train_loss = 0.97958396, grad/param norm = 1.8777e-01, time/batch = 16.8880s	
21254/33650 (epoch 31.581), train_loss = 1.06712764, grad/param norm = 1.9070e-01, time/batch = 16.9754s	
21255/33650 (epoch 31.582), train_loss = 0.95577095, grad/param norm = 1.5024e-01, time/batch = 16.9831s	
21256/33650 (epoch 31.584), train_loss = 0.93233228, grad/param norm = 1.6300e-01, time/batch = 16.5597s	
21257/33650 (epoch 31.585), train_loss = 0.96185631, grad/param norm = 1.9265e-01, time/batch = 17.0847s	
21258/33650 (epoch 31.587), train_loss = 0.85933170, grad/param norm = 1.5950e-01, time/batch = 17.4887s	
21259/33650 (epoch 31.588), train_loss = 0.86572935, grad/param norm = 1.9273e-01, time/batch = 17.8272s	
21260/33650 (epoch 31.590), train_loss = 0.88079795, grad/param norm = 1.4540e-01, time/batch = 16.7062s	
21261/33650 (epoch 31.591), train_loss = 0.80834856, grad/param norm = 1.5433e-01, time/batch = 17.9104s	
21262/33650 (epoch 31.593), train_loss = 0.81350982, grad/param norm = 1.5394e-01, time/batch = 17.7386s	
21263/33650 (epoch 31.594), train_loss = 0.80447389, grad/param norm = 1.5293e-01, time/batch = 16.8234s	
21264/33650 (epoch 31.596), train_loss = 0.89601657, grad/param norm = 1.5603e-01, time/batch = 17.6519s	
21265/33650 (epoch 31.597), train_loss = 0.78742497, grad/param norm = 1.4221e-01, time/batch = 16.9913s	
21266/33650 (epoch 31.599), train_loss = 0.89134208, grad/param norm = 1.5308e-01, time/batch = 17.8265s	
21267/33650 (epoch 31.600), train_loss = 0.83046284, grad/param norm = 1.4974e-01, time/batch = 17.1447s	
21268/33650 (epoch 31.602), train_loss = 0.90879758, grad/param norm = 1.5962e-01, time/batch = 16.9797s	
21269/33650 (epoch 31.603), train_loss = 0.85673465, grad/param norm = 1.5977e-01, time/batch = 16.9803s	
21270/33650 (epoch 31.605), train_loss = 0.96667144, grad/param norm = 1.6126e-01, time/batch = 16.0503s	
21271/33650 (epoch 31.606), train_loss = 0.91039085, grad/param norm = 1.5716e-01, time/batch = 17.7334s	
21272/33650 (epoch 31.608), train_loss = 0.80881833, grad/param norm = 1.7035e-01, time/batch = 17.2409s	
21273/33650 (epoch 31.609), train_loss = 0.91314946, grad/param norm = 1.5697e-01, time/batch = 16.6516s	
21274/33650 (epoch 31.611), train_loss = 0.80854025, grad/param norm = 1.6899e-01, time/batch = 16.5544s	
21275/33650 (epoch 31.612), train_loss = 0.89306766, grad/param norm = 1.9400e-01, time/batch = 17.6555s	
21276/33650 (epoch 31.614), train_loss = 0.99614132, grad/param norm = 1.5879e-01, time/batch = 18.0881s	
21277/33650 (epoch 31.615), train_loss = 0.92425663, grad/param norm = 1.3917e-01, time/batch = 16.2292s	
21278/33650 (epoch 31.617), train_loss = 0.82884638, grad/param norm = 1.6148e-01, time/batch = 16.7300s	
21279/33650 (epoch 31.618), train_loss = 0.87396716, grad/param norm = 1.6603e-01, time/batch = 16.8923s	
21280/33650 (epoch 31.620), train_loss = 0.86277161, grad/param norm = 1.9027e-01, time/batch = 17.8911s	
21281/33650 (epoch 31.621), train_loss = 0.81088944, grad/param norm = 1.5904e-01, time/batch = 16.8092s	
21282/33650 (epoch 31.623), train_loss = 0.88084714, grad/param norm = 1.5894e-01, time/batch = 17.6644s	
21283/33650 (epoch 31.624), train_loss = 0.71005697, grad/param norm = 1.6604e-01, time/batch = 17.6552s	
21284/33650 (epoch 31.626), train_loss = 0.74600067, grad/param norm = 1.7578e-01, time/batch = 16.0726s	
21285/33650 (epoch 31.627), train_loss = 0.83438523, grad/param norm = 1.5759e-01, time/batch = 17.4093s	
21286/33650 (epoch 31.629), train_loss = 0.84371928, grad/param norm = 1.6856e-01, time/batch = 16.3217s	
21287/33650 (epoch 31.630), train_loss = 1.00449443, grad/param norm = 1.8306e-01, time/batch = 17.2230s	
21288/33650 (epoch 31.632), train_loss = 0.98195175, grad/param norm = 1.6530e-01, time/batch = 16.2346s	
21289/33650 (epoch 31.633), train_loss = 0.97518633, grad/param norm = 1.6016e-01, time/batch = 18.2384s	
21290/33650 (epoch 31.634), train_loss = 0.79952918, grad/param norm = 1.4893e-01, time/batch = 17.3132s	
21291/33650 (epoch 31.636), train_loss = 0.70874412, grad/param norm = 1.2196e-01, time/batch = 16.4717s	
21292/33650 (epoch 31.637), train_loss = 0.80856944, grad/param norm = 1.4957e-01, time/batch = 17.2392s	
21293/33650 (epoch 31.639), train_loss = 0.81776236, grad/param norm = 1.4888e-01, time/batch = 17.4933s	
21294/33650 (epoch 31.640), train_loss = 0.91452406, grad/param norm = 1.7019e-01, time/batch = 16.5647s	
21295/33650 (epoch 31.642), train_loss = 0.96105120, grad/param norm = 1.6730e-01, time/batch = 17.2226s	
21296/33650 (epoch 31.643), train_loss = 0.90892768, grad/param norm = 1.7802e-01, time/batch = 16.7989s	
21297/33650 (epoch 31.645), train_loss = 0.92257480, grad/param norm = 1.5834e-01, time/batch = 17.3205s	
21298/33650 (epoch 31.646), train_loss = 0.78805112, grad/param norm = 1.2662e-01, time/batch = 16.4776s	
21299/33650 (epoch 31.648), train_loss = 0.95297989, grad/param norm = 1.6453e-01, time/batch = 17.4914s	
21300/33650 (epoch 31.649), train_loss = 0.80648422, grad/param norm = 1.8684e-01, time/batch = 17.3246s	
21301/33650 (epoch 31.651), train_loss = 0.94810271, grad/param norm = 1.6078e-01, time/batch = 17.5677s	
21302/33650 (epoch 31.652), train_loss = 0.66595621, grad/param norm = 1.3121e-01, time/batch = 17.1449s	
21303/33650 (epoch 31.654), train_loss = 0.79544976, grad/param norm = 1.8200e-01, time/batch = 16.3165s	
21304/33650 (epoch 31.655), train_loss = 0.77950147, grad/param norm = 1.4886e-01, time/batch = 17.9859s	
21305/33650 (epoch 31.657), train_loss = 0.84040357, grad/param norm = 1.6374e-01, time/batch = 15.5521s	
21306/33650 (epoch 31.658), train_loss = 0.73302967, grad/param norm = 1.6580e-01, time/batch = 16.6630s	
21307/33650 (epoch 31.660), train_loss = 0.72092816, grad/param norm = 1.3749e-01, time/batch = 17.4022s	
21308/33650 (epoch 31.661), train_loss = 0.79116325, grad/param norm = 1.4685e-01, time/batch = 17.2377s	
21309/33650 (epoch 31.663), train_loss = 0.76353459, grad/param norm = 1.5064e-01, time/batch = 16.9736s	
21310/33650 (epoch 31.664), train_loss = 0.84437711, grad/param norm = 1.5327e-01, time/batch = 18.0824s	
21311/33650 (epoch 31.666), train_loss = 0.85360306, grad/param norm = 1.2877e-01, time/batch = 17.3293s	
21312/33650 (epoch 31.667), train_loss = 0.74807596, grad/param norm = 1.3666e-01, time/batch = 16.3142s	
21313/33650 (epoch 31.669), train_loss = 0.77652826, grad/param norm = 1.5464e-01, time/batch = 17.2430s	
21314/33650 (epoch 31.670), train_loss = 0.70645803, grad/param norm = 1.3389e-01, time/batch = 16.9717s	
21315/33650 (epoch 31.672), train_loss = 0.73624559, grad/param norm = 1.5426e-01, time/batch = 16.6519s	
21316/33650 (epoch 31.673), train_loss = 0.73340395, grad/param norm = 1.4592e-01, time/batch = 16.9806s	
21317/33650 (epoch 31.675), train_loss = 0.68120791, grad/param norm = 1.3817e-01, time/batch = 17.1593s	
21318/33650 (epoch 31.676), train_loss = 0.81893046, grad/param norm = 1.5374e-01, time/batch = 17.2487s	
21319/33650 (epoch 31.678), train_loss = 0.81036139, grad/param norm = 1.6467e-01, time/batch = 16.8043s	
21320/33650 (epoch 31.679), train_loss = 0.80412452, grad/param norm = 1.5577e-01, time/batch = 17.0767s	
21321/33650 (epoch 31.681), train_loss = 0.83263543, grad/param norm = 1.3426e-01, time/batch = 17.4067s	
21322/33650 (epoch 31.682), train_loss = 0.76638733, grad/param norm = 1.4108e-01, time/batch = 17.3865s	
21323/33650 (epoch 31.684), train_loss = 0.74660162, grad/param norm = 1.5607e-01, time/batch = 15.7305s	
21324/33650 (epoch 31.685), train_loss = 0.89618914, grad/param norm = 1.6858e-01, time/batch = 16.3994s	
21325/33650 (epoch 31.686), train_loss = 0.87774655, grad/param norm = 1.5672e-01, time/batch = 16.8932s	
21326/33650 (epoch 31.688), train_loss = 0.94104696, grad/param norm = 1.6324e-01, time/batch = 17.0442s	
21327/33650 (epoch 31.689), train_loss = 0.80840604, grad/param norm = 1.5767e-01, time/batch = 17.4870s	
21328/33650 (epoch 31.691), train_loss = 0.95010826, grad/param norm = 1.7941e-01, time/batch = 17.4902s	
21329/33650 (epoch 31.692), train_loss = 0.95586461, grad/param norm = 1.5538e-01, time/batch = 16.9101s	
21330/33650 (epoch 31.694), train_loss = 0.90635047, grad/param norm = 1.6756e-01, time/batch = 16.8143s	
21331/33650 (epoch 31.695), train_loss = 0.60787795, grad/param norm = 1.3368e-01, time/batch = 16.9680s	
21332/33650 (epoch 31.697), train_loss = 0.84799066, grad/param norm = 1.7600e-01, time/batch = 17.9151s	
21333/33650 (epoch 31.698), train_loss = 0.98530514, grad/param norm = 1.8278e-01, time/batch = 17.0692s	
21334/33650 (epoch 31.700), train_loss = 0.84642706, grad/param norm = 1.5488e-01, time/batch = 17.5763s	
21335/33650 (epoch 31.701), train_loss = 0.87654376, grad/param norm = 1.6974e-01, time/batch = 16.7439s	
21336/33650 (epoch 31.703), train_loss = 1.04298589, grad/param norm = 1.6093e-01, time/batch = 17.5736s	
21337/33650 (epoch 31.704), train_loss = 0.85321767, grad/param norm = 1.4546e-01, time/batch = 15.3899s	
21338/33650 (epoch 31.706), train_loss = 0.83170316, grad/param norm = 1.6551e-01, time/batch = 16.4860s	
21339/33650 (epoch 31.707), train_loss = 0.95269048, grad/param norm = 1.5439e-01, time/batch = 16.5555s	
21340/33650 (epoch 31.709), train_loss = 0.84143851, grad/param norm = 1.6615e-01, time/batch = 16.3898s	
21341/33650 (epoch 31.710), train_loss = 1.04989270, grad/param norm = 2.1554e-01, time/batch = 17.9893s	
21342/33650 (epoch 31.712), train_loss = 0.75534900, grad/param norm = 1.4815e-01, time/batch = 16.8257s	
21343/33650 (epoch 31.713), train_loss = 0.78374124, grad/param norm = 1.9595e-01, time/batch = 16.8234s	
21344/33650 (epoch 31.715), train_loss = 0.91909988, grad/param norm = 1.8422e-01, time/batch = 17.5674s	
21345/33650 (epoch 31.716), train_loss = 0.83510723, grad/param norm = 1.5231e-01, time/batch = 17.4893s	
21346/33650 (epoch 31.718), train_loss = 0.81477495, grad/param norm = 1.5251e-01, time/batch = 16.8229s	
21347/33650 (epoch 31.719), train_loss = 0.98843159, grad/param norm = 1.8511e-01, time/batch = 25.4281s	
21348/33650 (epoch 31.721), train_loss = 1.04187078, grad/param norm = 1.8402e-01, time/batch = 31.8917s	
21349/33650 (epoch 31.722), train_loss = 0.92300194, grad/param norm = 1.9194e-01, time/batch = 17.3037s	
21350/33650 (epoch 31.724), train_loss = 0.99346176, grad/param norm = 1.7957e-01, time/batch = 18.0593s	
21351/33650 (epoch 31.725), train_loss = 0.92298291, grad/param norm = 1.6769e-01, time/batch = 18.9003s	
21352/33650 (epoch 31.727), train_loss = 0.82485011, grad/param norm = 1.7467e-01, time/batch = 17.5747s	
21353/33650 (epoch 31.728), train_loss = 0.83522029, grad/param norm = 1.5701e-01, time/batch = 17.7160s	
21354/33650 (epoch 31.730), train_loss = 0.90550740, grad/param norm = 1.5912e-01, time/batch = 17.7071s	
21355/33650 (epoch 31.731), train_loss = 1.01978302, grad/param norm = 1.7318e-01, time/batch = 18.6490s	
21356/33650 (epoch 31.733), train_loss = 0.83484582, grad/param norm = 1.5257e-01, time/batch = 16.2083s	
21357/33650 (epoch 31.734), train_loss = 1.02512252, grad/param norm = 1.9183e-01, time/batch = 18.1466s	
21358/33650 (epoch 31.736), train_loss = 0.87384012, grad/param norm = 2.0867e-01, time/batch = 18.6309s	
21359/33650 (epoch 31.737), train_loss = 0.91553485, grad/param norm = 1.8079e-01, time/batch = 16.7061s	
21360/33650 (epoch 31.738), train_loss = 0.80849770, grad/param norm = 1.7283e-01, time/batch = 17.7196s	
21361/33650 (epoch 31.740), train_loss = 0.73483136, grad/param norm = 1.4745e-01, time/batch = 18.9030s	
21362/33650 (epoch 31.741), train_loss = 0.81324669, grad/param norm = 1.6010e-01, time/batch = 18.3130s	
21363/33650 (epoch 31.743), train_loss = 0.86218040, grad/param norm = 1.5326e-01, time/batch = 17.3902s	
21364/33650 (epoch 31.744), train_loss = 0.95089215, grad/param norm = 1.4318e-01, time/batch = 16.3827s	
21365/33650 (epoch 31.746), train_loss = 0.84179633, grad/param norm = 1.5783e-01, time/batch = 18.7270s	
21366/33650 (epoch 31.747), train_loss = 0.98976689, grad/param norm = 1.6215e-01, time/batch = 16.8846s	
21367/33650 (epoch 31.749), train_loss = 0.72962411, grad/param norm = 1.6627e-01, time/batch = 17.8888s	
21368/33650 (epoch 31.750), train_loss = 1.02272655, grad/param norm = 1.5794e-01, time/batch = 18.3181s	
21369/33650 (epoch 31.752), train_loss = 0.95935412, grad/param norm = 1.5945e-01, time/batch = 16.7024s	
21370/33650 (epoch 31.753), train_loss = 1.06457558, grad/param norm = 1.8162e-01, time/batch = 18.4733s	
21371/33650 (epoch 31.755), train_loss = 0.85494494, grad/param norm = 1.4794e-01, time/batch = 17.6427s	
21372/33650 (epoch 31.756), train_loss = 0.96504932, grad/param norm = 1.8378e-01, time/batch = 18.0585s	
21373/33650 (epoch 31.758), train_loss = 0.96243555, grad/param norm = 1.5404e-01, time/batch = 17.2157s	
21374/33650 (epoch 31.759), train_loss = 0.97784324, grad/param norm = 1.7825e-01, time/batch = 17.8030s	
21375/33650 (epoch 31.761), train_loss = 0.88929004, grad/param norm = 1.5769e-01, time/batch = 17.5678s	
21376/33650 (epoch 31.762), train_loss = 0.85395317, grad/param norm = 1.4831e-01, time/batch = 17.0627s	
21377/33650 (epoch 31.764), train_loss = 0.93174255, grad/param norm = 1.7749e-01, time/batch = 16.4620s	
21378/33650 (epoch 31.765), train_loss = 0.84178195, grad/param norm = 1.7224e-01, time/batch = 17.9844s	
21379/33650 (epoch 31.767), train_loss = 0.86458974, grad/param norm = 1.4635e-01, time/batch = 18.0690s	
21380/33650 (epoch 31.768), train_loss = 0.78642906, grad/param norm = 1.6014e-01, time/batch = 16.9650s	
21381/33650 (epoch 31.770), train_loss = 0.90221928, grad/param norm = 1.7048e-01, time/batch = 18.3282s	
21382/33650 (epoch 31.771), train_loss = 0.92925580, grad/param norm = 1.6039e-01, time/batch = 18.4912s	
21383/33650 (epoch 31.773), train_loss = 0.98266518, grad/param norm = 2.0124e-01, time/batch = 16.6448s	
21384/33650 (epoch 31.774), train_loss = 0.92527092, grad/param norm = 1.9168e-01, time/batch = 18.6384s	
21385/33650 (epoch 31.776), train_loss = 0.97028262, grad/param norm = 2.1075e-01, time/batch = 18.4006s	
21386/33650 (epoch 31.777), train_loss = 0.83018149, grad/param norm = 1.5684e-01, time/batch = 16.7251s	
21387/33650 (epoch 31.779), train_loss = 0.86531851, grad/param norm = 1.5093e-01, time/batch = 18.2259s	
21388/33650 (epoch 31.780), train_loss = 0.80154167, grad/param norm = 2.0298e-01, time/batch = 16.8815s	
21389/33650 (epoch 31.782), train_loss = 0.80360376, grad/param norm = 1.6226e-01, time/batch = 16.8928s	
21390/33650 (epoch 31.783), train_loss = 0.81475011, grad/param norm = 1.4685e-01, time/batch = 17.3097s	
21391/33650 (epoch 31.785), train_loss = 1.05744231, grad/param norm = 1.5922e-01, time/batch = 18.2190s	
21392/33650 (epoch 31.786), train_loss = 0.94351684, grad/param norm = 1.6346e-01, time/batch = 16.9691s	
21393/33650 (epoch 31.788), train_loss = 0.93793775, grad/param norm = 1.5484e-01, time/batch = 16.7449s	
21394/33650 (epoch 31.789), train_loss = 0.98178825, grad/param norm = 1.7998e-01, time/batch = 17.7310s	
21395/33650 (epoch 31.790), train_loss = 0.89416394, grad/param norm = 1.7698e-01, time/batch = 19.2296s	
21396/33650 (epoch 31.792), train_loss = 0.97602824, grad/param norm = 1.6921e-01, time/batch = 17.4752s	
21397/33650 (epoch 31.793), train_loss = 0.95660119, grad/param norm = 1.8389e-01, time/batch = 17.4819s	
21398/33650 (epoch 31.795), train_loss = 0.97174794, grad/param norm = 1.6400e-01, time/batch = 16.7058s	
21399/33650 (epoch 31.796), train_loss = 0.85060525, grad/param norm = 1.5493e-01, time/batch = 18.6532s	
21400/33650 (epoch 31.798), train_loss = 0.84925507, grad/param norm = 1.6305e-01, time/batch = 16.8066s	
21401/33650 (epoch 31.799), train_loss = 0.88830597, grad/param norm = 1.6377e-01, time/batch = 16.8800s	
21402/33650 (epoch 31.801), train_loss = 0.89870633, grad/param norm = 2.0726e-01, time/batch = 18.3088s	
21403/33650 (epoch 31.802), train_loss = 0.99455920, grad/param norm = 1.8242e-01, time/batch = 16.0394s	
21404/33650 (epoch 31.804), train_loss = 0.91379622, grad/param norm = 1.7350e-01, time/batch = 17.5712s	
21405/33650 (epoch 31.805), train_loss = 0.88367701, grad/param norm = 1.4555e-01, time/batch = 16.5573s	
21406/33650 (epoch 31.807), train_loss = 1.07974190, grad/param norm = 1.9837e-01, time/batch = 18.8098s	
21407/33650 (epoch 31.808), train_loss = 1.15055016, grad/param norm = 2.1607e-01, time/batch = 16.9787s	
21408/33650 (epoch 31.810), train_loss = 0.93037007, grad/param norm = 1.7092e-01, time/batch = 18.3223s	
21409/33650 (epoch 31.811), train_loss = 0.93330914, grad/param norm = 1.8886e-01, time/batch = 18.4742s	
21410/33650 (epoch 31.813), train_loss = 0.81668255, grad/param norm = 1.6192e-01, time/batch = 17.2242s	
21411/33650 (epoch 31.814), train_loss = 0.99327588, grad/param norm = 1.7623e-01, time/batch = 17.5674s	
21412/33650 (epoch 31.816), train_loss = 0.95333003, grad/param norm = 1.9228e-01, time/batch = 16.6576s	
21413/33650 (epoch 31.817), train_loss = 0.97988979, grad/param norm = 1.7579e-01, time/batch = 17.5631s	
21414/33650 (epoch 31.819), train_loss = 0.91872362, grad/param norm = 1.6319e-01, time/batch = 17.3890s	
21415/33650 (epoch 31.820), train_loss = 0.99914643, grad/param norm = 1.8516e-01, time/batch = 18.3957s	
21416/33650 (epoch 31.822), train_loss = 0.93299512, grad/param norm = 2.0510e-01, time/batch = 16.5499s	
21417/33650 (epoch 31.823), train_loss = 0.85771885, grad/param norm = 1.9765e-01, time/batch = 16.5679s	
21418/33650 (epoch 31.825), train_loss = 0.89702420, grad/param norm = 1.5439e-01, time/batch = 17.8956s	
21419/33650 (epoch 31.826), train_loss = 0.96834657, grad/param norm = 1.7012e-01, time/batch = 18.4871s	
21420/33650 (epoch 31.828), train_loss = 1.04178092, grad/param norm = 1.6940e-01, time/batch = 17.4745s	
21421/33650 (epoch 31.829), train_loss = 0.76255592, grad/param norm = 1.5714e-01, time/batch = 18.8947s	
21422/33650 (epoch 31.831), train_loss = 0.92726346, grad/param norm = 1.9547e-01, time/batch = 17.8097s	
21423/33650 (epoch 31.832), train_loss = 0.98244073, grad/param norm = 1.8662e-01, time/batch = 17.6521s	
21424/33650 (epoch 31.834), train_loss = 0.96462867, grad/param norm = 1.6133e-01, time/batch = 17.0454s	
21425/33650 (epoch 31.835), train_loss = 1.11404052, grad/param norm = 2.1070e-01, time/batch = 18.5746s	
21426/33650 (epoch 31.837), train_loss = 0.93640087, grad/param norm = 1.7566e-01, time/batch = 16.0561s	
21427/33650 (epoch 31.838), train_loss = 0.90927595, grad/param norm = 1.6834e-01, time/batch = 17.1553s	
21428/33650 (epoch 31.840), train_loss = 0.98365298, grad/param norm = 1.7082e-01, time/batch = 18.0691s	
21429/33650 (epoch 31.841), train_loss = 0.86589735, grad/param norm = 1.6981e-01, time/batch = 18.4097s	
21430/33650 (epoch 31.842), train_loss = 0.88701722, grad/param norm = 1.5283e-01, time/batch = 17.4800s	
21431/33650 (epoch 31.844), train_loss = 1.04633861, grad/param norm = 1.9193e-01, time/batch = 18.2220s	
21432/33650 (epoch 31.845), train_loss = 0.88347801, grad/param norm = 1.7424e-01, time/batch = 18.3827s	
21433/33650 (epoch 31.847), train_loss = 0.70855209, grad/param norm = 1.8690e-01, time/batch = 17.8202s	
21434/33650 (epoch 31.848), train_loss = 0.79219480, grad/param norm = 1.8155e-01, time/batch = 16.3731s	
21435/33650 (epoch 31.850), train_loss = 0.85665754, grad/param norm = 2.2569e-01, time/batch = 18.9738s	
21436/33650 (epoch 31.851), train_loss = 0.75789539, grad/param norm = 1.4535e-01, time/batch = 18.7195s	
21437/33650 (epoch 31.853), train_loss = 0.85519455, grad/param norm = 1.6219e-01, time/batch = 16.2878s	
21438/33650 (epoch 31.854), train_loss = 0.99156859, grad/param norm = 1.8264e-01, time/batch = 17.8052s	
21439/33650 (epoch 31.856), train_loss = 0.71773980, grad/param norm = 1.5330e-01, time/batch = 17.8992s	
21440/33650 (epoch 31.857), train_loss = 0.92143295, grad/param norm = 1.5386e-01, time/batch = 17.6382s	
21441/33650 (epoch 31.859), train_loss = 0.78816367, grad/param norm = 1.2558e-01, time/batch = 18.0566s	
21442/33650 (epoch 31.860), train_loss = 0.77358408, grad/param norm = 1.6386e-01, time/batch = 17.4887s	
21443/33650 (epoch 31.862), train_loss = 0.82034345, grad/param norm = 1.5654e-01, time/batch = 18.2309s	
21444/33650 (epoch 31.863), train_loss = 1.01470281, grad/param norm = 1.5607e-01, time/batch = 17.3914s	
21445/33650 (epoch 31.865), train_loss = 0.87327776, grad/param norm = 1.5363e-01, time/batch = 18.4824s	
21446/33650 (epoch 31.866), train_loss = 0.80978345, grad/param norm = 1.6240e-01, time/batch = 15.8917s	
21447/33650 (epoch 31.868), train_loss = 0.77246364, grad/param norm = 1.7771e-01, time/batch = 17.2161s	
21448/33650 (epoch 31.869), train_loss = 0.94028952, grad/param norm = 1.6717e-01, time/batch = 13.9901s	
21449/33650 (epoch 31.871), train_loss = 0.79122394, grad/param norm = 1.4760e-01, time/batch = 14.0608s	
21450/33650 (epoch 31.872), train_loss = 0.91813325, grad/param norm = 1.4927e-01, time/batch = 13.7598s	
21451/33650 (epoch 31.874), train_loss = 0.95368450, grad/param norm = 1.8502e-01, time/batch = 17.2183s	
21452/33650 (epoch 31.875), train_loss = 0.85935345, grad/param norm = 1.5566e-01, time/batch = 18.3946s	
21453/33650 (epoch 31.877), train_loss = 1.05409797, grad/param norm = 1.7817e-01, time/batch = 18.5598s	
21454/33650 (epoch 31.878), train_loss = 0.63819527, grad/param norm = 1.2221e-01, time/batch = 18.3099s	
21455/33650 (epoch 31.880), train_loss = 0.91424699, grad/param norm = 1.6856e-01, time/batch = 17.5694s	
21456/33650 (epoch 31.881), train_loss = 0.83119183, grad/param norm = 1.5307e-01, time/batch = 17.1468s	
21457/33650 (epoch 31.883), train_loss = 0.91058966, grad/param norm = 1.6864e-01, time/batch = 18.6524s	
21458/33650 (epoch 31.884), train_loss = 1.00562637, grad/param norm = 1.6735e-01, time/batch = 16.1268s	
21459/33650 (epoch 31.886), train_loss = 0.93899948, grad/param norm = 1.5765e-01, time/batch = 17.8847s	
21460/33650 (epoch 31.887), train_loss = 0.76446350, grad/param norm = 1.4201e-01, time/batch = 18.3154s	
21461/33650 (epoch 31.889), train_loss = 0.85593736, grad/param norm = 1.5801e-01, time/batch = 17.3826s	
21462/33650 (epoch 31.890), train_loss = 0.92857930, grad/param norm = 1.5112e-01, time/batch = 18.3966s	
21463/33650 (epoch 31.892), train_loss = 0.84112394, grad/param norm = 1.7135e-01, time/batch = 18.7304s	
21464/33650 (epoch 31.893), train_loss = 0.92783980, grad/param norm = 2.0171e-01, time/batch = 18.6422s	
21465/33650 (epoch 31.895), train_loss = 1.01074848, grad/param norm = 1.5723e-01, time/batch = 16.9686s	
21466/33650 (epoch 31.896), train_loss = 0.82463648, grad/param norm = 1.7145e-01, time/batch = 18.5454s	
21467/33650 (epoch 31.897), train_loss = 0.75246523, grad/param norm = 1.5874e-01, time/batch = 18.7274s	
21468/33650 (epoch 31.899), train_loss = 0.80102778, grad/param norm = 1.3508e-01, time/batch = 15.9679s	
21469/33650 (epoch 31.900), train_loss = 0.75144700, grad/param norm = 1.3561e-01, time/batch = 18.1581s	
21470/33650 (epoch 31.902), train_loss = 0.86411363, grad/param norm = 1.8397e-01, time/batch = 18.6551s	
21471/33650 (epoch 31.903), train_loss = 0.85078645, grad/param norm = 1.7831e-01, time/batch = 17.8132s	
21472/33650 (epoch 31.905), train_loss = 1.03122911, grad/param norm = 2.6468e-01, time/batch = 16.5434s	
21473/33650 (epoch 31.906), train_loss = 0.82648924, grad/param norm = 1.7448e-01, time/batch = 16.7307s	
21474/33650 (epoch 31.908), train_loss = 0.85811653, grad/param norm = 1.8534e-01, time/batch = 13.5231s	
21475/33650 (epoch 31.909), train_loss = 0.83199518, grad/param norm = 1.5563e-01, time/batch = 14.0718s	
21476/33650 (epoch 31.911), train_loss = 0.75404973, grad/param norm = 1.5692e-01, time/batch = 14.3630s	
21477/33650 (epoch 31.912), train_loss = 0.70602315, grad/param norm = 1.5403e-01, time/batch = 18.2866s	
21478/33650 (epoch 31.914), train_loss = 0.90128164, grad/param norm = 1.4210e-01, time/batch = 18.1467s	
21479/33650 (epoch 31.915), train_loss = 0.85996966, grad/param norm = 1.9482e-01, time/batch = 17.2299s	
21480/33650 (epoch 31.917), train_loss = 0.84094728, grad/param norm = 1.7090e-01, time/batch = 18.2327s	
21481/33650 (epoch 31.918), train_loss = 0.78076130, grad/param norm = 1.5714e-01, time/batch = 19.3176s	
21482/33650 (epoch 31.920), train_loss = 0.78703265, grad/param norm = 1.4615e-01, time/batch = 16.3887s	
21483/33650 (epoch 31.921), train_loss = 0.79149645, grad/param norm = 1.5340e-01, time/batch = 18.2192s	
21484/33650 (epoch 31.923), train_loss = 0.70518816, grad/param norm = 1.4944e-01, time/batch = 17.5510s	
21485/33650 (epoch 31.924), train_loss = 0.90014060, grad/param norm = 1.6837e-01, time/batch = 17.9792s	
21486/33650 (epoch 31.926), train_loss = 0.83586604, grad/param norm = 2.3419e-01, time/batch = 17.4011s	
21487/33650 (epoch 31.927), train_loss = 0.84472508, grad/param norm = 1.6880e-01, time/batch = 18.3211s	
21488/33650 (epoch 31.929), train_loss = 0.93409015, grad/param norm = 1.5181e-01, time/batch = 18.4863s	
21489/33650 (epoch 31.930), train_loss = 0.85248102, grad/param norm = 1.6311e-01, time/batch = 16.7914s	
21490/33650 (epoch 31.932), train_loss = 0.85181371, grad/param norm = 1.4513e-01, time/batch = 18.3152s	
21491/33650 (epoch 31.933), train_loss = 0.74291904, grad/param norm = 1.4725e-01, time/batch = 18.6403s	
21492/33650 (epoch 31.935), train_loss = 0.74800493, grad/param norm = 1.7005e-01, time/batch = 16.3922s	
21493/33650 (epoch 31.936), train_loss = 0.80553103, grad/param norm = 1.4863e-01, time/batch = 18.5580s	
21494/33650 (epoch 31.938), train_loss = 0.75835853, grad/param norm = 1.5902e-01, time/batch = 17.8117s	
21495/33650 (epoch 31.939), train_loss = 0.94704874, grad/param norm = 1.4716e-01, time/batch = 17.0526s	
21496/33650 (epoch 31.941), train_loss = 0.87669433, grad/param norm = 1.6136e-01, time/batch = 17.3068s	
21497/33650 (epoch 31.942), train_loss = 0.93840737, grad/param norm = 1.6622e-01, time/batch = 18.4011s	
21498/33650 (epoch 31.944), train_loss = 0.81751876, grad/param norm = 1.4460e-01, time/batch = 18.2278s	
21499/33650 (epoch 31.945), train_loss = 0.86841742, grad/param norm = 1.4055e-01, time/batch = 12.3255s	
21500/33650 (epoch 31.947), train_loss = 1.01228949, grad/param norm = 2.3907e-01, time/batch = 0.6375s	
21501/33650 (epoch 31.948), train_loss = 0.98432661, grad/param norm = 1.5985e-01, time/batch = 0.6439s	
21502/33650 (epoch 31.949), train_loss = 0.75001496, grad/param norm = 1.4893e-01, time/batch = 0.6443s	
21503/33650 (epoch 31.951), train_loss = 1.00999034, grad/param norm = 1.6522e-01, time/batch = 0.6439s	
21504/33650 (epoch 31.952), train_loss = 0.90276485, grad/param norm = 1.5276e-01, time/batch = 0.6401s	
21505/33650 (epoch 31.954), train_loss = 0.91712779, grad/param norm = 1.5490e-01, time/batch = 0.6397s	
21506/33650 (epoch 31.955), train_loss = 0.87881361, grad/param norm = 1.5270e-01, time/batch = 0.6400s	
21507/33650 (epoch 31.957), train_loss = 0.91156978, grad/param norm = 1.6268e-01, time/batch = 0.6424s	
21508/33650 (epoch 31.958), train_loss = 0.69102751, grad/param norm = 1.3386e-01, time/batch = 0.6402s	
21509/33650 (epoch 31.960), train_loss = 0.71715468, grad/param norm = 1.5125e-01, time/batch = 0.6389s	
21510/33650 (epoch 31.961), train_loss = 0.76049307, grad/param norm = 1.6241e-01, time/batch = 0.6373s	
21511/33650 (epoch 31.963), train_loss = 0.79731081, grad/param norm = 1.6425e-01, time/batch = 0.6410s	
21512/33650 (epoch 31.964), train_loss = 0.95164429, grad/param norm = 1.5405e-01, time/batch = 0.6459s	
21513/33650 (epoch 31.966), train_loss = 0.87908739, grad/param norm = 2.0227e-01, time/batch = 0.6399s	
21514/33650 (epoch 31.967), train_loss = 0.89930534, grad/param norm = 1.6118e-01, time/batch = 0.6398s	
21515/33650 (epoch 31.969), train_loss = 0.86198894, grad/param norm = 1.5861e-01, time/batch = 0.6392s	
21516/33650 (epoch 31.970), train_loss = 0.88372524, grad/param norm = 1.6546e-01, time/batch = 0.6397s	
21517/33650 (epoch 31.972), train_loss = 1.15223954, grad/param norm = 1.8602e-01, time/batch = 0.6697s	
21518/33650 (epoch 31.973), train_loss = 0.77924994, grad/param norm = 1.2977e-01, time/batch = 0.6669s	
21519/33650 (epoch 31.975), train_loss = 0.77547436, grad/param norm = 1.6770e-01, time/batch = 0.6385s	
21520/33650 (epoch 31.976), train_loss = 0.79155246, grad/param norm = 1.4318e-01, time/batch = 0.6430s	
21521/33650 (epoch 31.978), train_loss = 0.79240740, grad/param norm = 1.4567e-01, time/batch = 0.6442s	
21522/33650 (epoch 31.979), train_loss = 0.84743123, grad/param norm = 1.6437e-01, time/batch = 0.6727s	
21523/33650 (epoch 31.981), train_loss = 0.83063858, grad/param norm = 1.4521e-01, time/batch = 0.9414s	
21524/33650 (epoch 31.982), train_loss = 0.87724416, grad/param norm = 1.5699e-01, time/batch = 0.9398s	
21525/33650 (epoch 31.984), train_loss = 0.71765385, grad/param norm = 1.4230e-01, time/batch = 0.9394s	
21526/33650 (epoch 31.985), train_loss = 0.78144761, grad/param norm = 1.8192e-01, time/batch = 0.9330s	
21527/33650 (epoch 31.987), train_loss = 0.88470107, grad/param norm = 1.5116e-01, time/batch = 0.9343s	
21528/33650 (epoch 31.988), train_loss = 0.81027282, grad/param norm = 1.4956e-01, time/batch = 1.6109s	
21529/33650 (epoch 31.990), train_loss = 1.00519130, grad/param norm = 1.7318e-01, time/batch = 1.8933s	
21530/33650 (epoch 31.991), train_loss = 0.88091879, grad/param norm = 1.6709e-01, time/batch = 2.9115s	
21531/33650 (epoch 31.993), train_loss = 0.88592445, grad/param norm = 1.6409e-01, time/batch = 18.0687s	
21532/33650 (epoch 31.994), train_loss = 0.87337388, grad/param norm = 1.5486e-01, time/batch = 16.3734s	
21533/33650 (epoch 31.996), train_loss = 0.82710753, grad/param norm = 1.5343e-01, time/batch = 18.3982s	
21534/33650 (epoch 31.997), train_loss = 0.92612282, grad/param norm = 1.6989e-01, time/batch = 17.8885s	
21535/33650 (epoch 31.999), train_loss = 0.80404220, grad/param norm = 1.7131e-01, time/batch = 16.6215s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
21536/33650 (epoch 32.000), train_loss = 0.94067332, grad/param norm = 1.7957e-01, time/batch = 17.3168s	
21537/33650 (epoch 32.001), train_loss = 1.00041358, grad/param norm = 1.6505e-01, time/batch = 17.2261s	
21538/33650 (epoch 32.003), train_loss = 0.99935511, grad/param norm = 2.0109e-01, time/batch = 18.1499s	
21539/33650 (epoch 32.004), train_loss = 0.90953010, grad/param norm = 1.6901e-01, time/batch = 16.9010s	
21540/33650 (epoch 32.006), train_loss = 0.85461346, grad/param norm = 1.5622e-01, time/batch = 18.0610s	
21541/33650 (epoch 32.007), train_loss = 0.91617167, grad/param norm = 1.8321e-01, time/batch = 17.4850s	
21542/33650 (epoch 32.009), train_loss = 0.81546964, grad/param norm = 1.7810e-01, time/batch = 16.8586s	
21543/33650 (epoch 32.010), train_loss = 0.98355026, grad/param norm = 1.8473e-01, time/batch = 17.2300s	
21544/33650 (epoch 32.012), train_loss = 0.82278724, grad/param norm = 1.5723e-01, time/batch = 17.4806s	
21545/33650 (epoch 32.013), train_loss = 0.86650322, grad/param norm = 1.8619e-01, time/batch = 18.9790s	
21546/33650 (epoch 32.015), train_loss = 0.84859950, grad/param norm = 1.7398e-01, time/batch = 16.3901s	
21547/33650 (epoch 32.016), train_loss = 0.78630145, grad/param norm = 1.6318e-01, time/batch = 18.9012s	
21548/33650 (epoch 32.018), train_loss = 0.85301558, grad/param norm = 1.8079e-01, time/batch = 18.3066s	
21549/33650 (epoch 32.019), train_loss = 0.82465592, grad/param norm = 1.7128e-01, time/batch = 16.7128s	
21550/33650 (epoch 32.021), train_loss = 0.92128853, grad/param norm = 1.4877e-01, time/batch = 15.9751s	
21551/33650 (epoch 32.022), train_loss = 0.84577340, grad/param norm = 1.5771e-01, time/batch = 18.1554s	
21552/33650 (epoch 32.024), train_loss = 0.77764669, grad/param norm = 1.5307e-01, time/batch = 17.8915s	
21553/33650 (epoch 32.025), train_loss = 0.88988396, grad/param norm = 1.6905e-01, time/batch = 18.3888s	
21554/33650 (epoch 32.027), train_loss = 0.90535699, grad/param norm = 1.7880e-01, time/batch = 17.2429s	
21555/33650 (epoch 32.028), train_loss = 0.93696695, grad/param norm = 1.5896e-01, time/batch = 18.6504s	
21556/33650 (epoch 32.030), train_loss = 0.86896467, grad/param norm = 1.8539e-01, time/batch = 17.7236s	
21557/33650 (epoch 32.031), train_loss = 0.78430082, grad/param norm = 1.4249e-01, time/batch = 17.0544s	
21558/33650 (epoch 32.033), train_loss = 0.88584923, grad/param norm = 1.4820e-01, time/batch = 17.8131s	
21559/33650 (epoch 32.034), train_loss = 0.91408911, grad/param norm = 1.5933e-01, time/batch = 16.8080s	
21560/33650 (epoch 32.036), train_loss = 0.99336382, grad/param norm = 1.8110e-01, time/batch = 18.2272s	
21561/33650 (epoch 32.037), train_loss = 0.82418417, grad/param norm = 1.4353e-01, time/batch = 18.0764s	
21562/33650 (epoch 32.039), train_loss = 0.95991892, grad/param norm = 1.6042e-01, time/batch = 18.4667s	
21563/33650 (epoch 32.040), train_loss = 1.04192180, grad/param norm = 2.0499e-01, time/batch = 17.4617s	
21564/33650 (epoch 32.042), train_loss = 1.05487849, grad/param norm = 1.9045e-01, time/batch = 18.2431s	
21565/33650 (epoch 32.043), train_loss = 0.84990480, grad/param norm = 1.7229e-01, time/batch = 19.0745s	
21566/33650 (epoch 32.045), train_loss = 0.82773192, grad/param norm = 1.5655e-01, time/batch = 17.1387s	
21567/33650 (epoch 32.046), train_loss = 0.94016673, grad/param norm = 2.0925e-01, time/batch = 16.4830s	
21568/33650 (epoch 32.048), train_loss = 0.95165888, grad/param norm = 1.7467e-01, time/batch = 16.7849s	
21569/33650 (epoch 32.049), train_loss = 0.84334907, grad/param norm = 1.6598e-01, time/batch = 17.8961s	
21570/33650 (epoch 32.051), train_loss = 1.02934058, grad/param norm = 1.8134e-01, time/batch = 17.2213s	
21571/33650 (epoch 32.052), train_loss = 1.00407060, grad/param norm = 1.7352e-01, time/batch = 17.6439s	
21572/33650 (epoch 32.053), train_loss = 0.95164312, grad/param norm = 1.8231e-01, time/batch = 18.0732s	
21573/33650 (epoch 32.055), train_loss = 0.80599717, grad/param norm = 1.4153e-01, time/batch = 17.0385s	
21574/33650 (epoch 32.056), train_loss = 0.77356657, grad/param norm = 1.3175e-01, time/batch = 18.6507s	
21575/33650 (epoch 32.058), train_loss = 0.94288476, grad/param norm = 1.8899e-01, time/batch = 17.6487s	
21576/33650 (epoch 32.059), train_loss = 0.95445783, grad/param norm = 1.6119e-01, time/batch = 16.8971s	
21577/33650 (epoch 32.061), train_loss = 0.97312322, grad/param norm = 1.7206e-01, time/batch = 17.4905s	
21578/33650 (epoch 32.062), train_loss = 0.93885804, grad/param norm = 1.4858e-01, time/batch = 18.1583s	
21579/33650 (epoch 32.064), train_loss = 0.86042527, grad/param norm = 1.5856e-01, time/batch = 18.0448s	
21580/33650 (epoch 32.065), train_loss = 0.84885638, grad/param norm = 1.6904e-01, time/batch = 31.3076s	
21581/33650 (epoch 32.067), train_loss = 0.79545652, grad/param norm = 1.3707e-01, time/batch = 18.0668s	
21582/33650 (epoch 32.068), train_loss = 0.89039507, grad/param norm = 1.8590e-01, time/batch = 16.7258s	
21583/33650 (epoch 32.070), train_loss = 0.93480780, grad/param norm = 1.6576e-01, time/batch = 17.5749s	
21584/33650 (epoch 32.071), train_loss = 0.84594157, grad/param norm = 1.5784e-01, time/batch = 15.8940s	
21585/33650 (epoch 32.073), train_loss = 0.92430519, grad/param norm = 1.7620e-01, time/batch = 17.6401s	
21586/33650 (epoch 32.074), train_loss = 0.98810195, grad/param norm = 1.5889e-01, time/batch = 18.1271s	
21587/33650 (epoch 32.076), train_loss = 0.97453946, grad/param norm = 1.8500e-01, time/batch = 16.4653s	
21588/33650 (epoch 32.077), train_loss = 0.86972174, grad/param norm = 1.5065e-01, time/batch = 18.4845s	
21589/33650 (epoch 32.079), train_loss = 0.92617425, grad/param norm = 1.5921e-01, time/batch = 16.1328s	
21590/33650 (epoch 32.080), train_loss = 0.93177265, grad/param norm = 1.5749e-01, time/batch = 18.2375s	
21591/33650 (epoch 32.082), train_loss = 0.87981745, grad/param norm = 1.5977e-01, time/batch = 18.2178s	
21592/33650 (epoch 32.083), train_loss = 0.90965154, grad/param norm = 1.7485e-01, time/batch = 16.6394s	
21593/33650 (epoch 32.085), train_loss = 0.97968330, grad/param norm = 1.5331e-01, time/batch = 18.0663s	
21594/33650 (epoch 32.086), train_loss = 0.93429391, grad/param norm = 1.7209e-01, time/batch = 17.3127s	
21595/33650 (epoch 32.088), train_loss = 0.88216499, grad/param norm = 1.6219e-01, time/batch = 18.7348s	
21596/33650 (epoch 32.089), train_loss = 0.82880109, grad/param norm = 1.7428e-01, time/batch = 17.7076s	
21597/33650 (epoch 32.091), train_loss = 0.86392193, grad/param norm = 1.5367e-01, time/batch = 18.8100s	
21598/33650 (epoch 32.092), train_loss = 0.87324628, grad/param norm = 1.5880e-01, time/batch = 18.1537s	
21599/33650 (epoch 32.094), train_loss = 0.96002559, grad/param norm = 1.5517e-01, time/batch = 16.9586s	
21600/33650 (epoch 32.095), train_loss = 0.94253901, grad/param norm = 1.9113e-01, time/batch = 16.2918s	
21601/33650 (epoch 32.097), train_loss = 0.82132636, grad/param norm = 1.7147e-01, time/batch = 18.1403s	
21602/33650 (epoch 32.098), train_loss = 0.71827355, grad/param norm = 1.4218e-01, time/batch = 17.6344s	
21603/33650 (epoch 32.100), train_loss = 0.79704795, grad/param norm = 1.4719e-01, time/batch = 18.2181s	
21604/33650 (epoch 32.101), train_loss = 0.89177358, grad/param norm = 1.7758e-01, time/batch = 17.6362s	
21605/33650 (epoch 32.103), train_loss = 0.87911611, grad/param norm = 1.6061e-01, time/batch = 17.8833s	
21606/33650 (epoch 32.104), train_loss = 1.01301263, grad/param norm = 1.6487e-01, time/batch = 17.5457s	
21607/33650 (epoch 32.105), train_loss = 0.90917415, grad/param norm = 1.6011e-01, time/batch = 18.1459s	
21608/33650 (epoch 32.107), train_loss = 0.84281045, grad/param norm = 1.5586e-01, time/batch = 18.2281s	
21609/33650 (epoch 32.108), train_loss = 0.92893406, grad/param norm = 1.6290e-01, time/batch = 15.8527s	
21610/33650 (epoch 32.110), train_loss = 1.02475560, grad/param norm = 1.6220e-01, time/batch = 18.2229s	
21611/33650 (epoch 32.111), train_loss = 0.86753034, grad/param norm = 1.6841e-01, time/batch = 18.4864s	
21612/33650 (epoch 32.113), train_loss = 0.82915895, grad/param norm = 1.5872e-01, time/batch = 17.4677s	
21613/33650 (epoch 32.114), train_loss = 0.95414736, grad/param norm = 1.6188e-01, time/batch = 16.9561s	
21614/33650 (epoch 32.116), train_loss = 0.81794016, grad/param norm = 1.3409e-01, time/batch = 19.0607s	
21615/33650 (epoch 32.117), train_loss = 0.86500806, grad/param norm = 1.4575e-01, time/batch = 18.7215s	
21616/33650 (epoch 32.119), train_loss = 0.79830951, grad/param norm = 1.3923e-01, time/batch = 16.5482s	
21617/33650 (epoch 32.120), train_loss = 0.83446603, grad/param norm = 1.8363e-01, time/batch = 18.1513s	
21618/33650 (epoch 32.122), train_loss = 0.67478799, grad/param norm = 1.6185e-01, time/batch = 16.8803s	
21619/33650 (epoch 32.123), train_loss = 0.83693466, grad/param norm = 1.5211e-01, time/batch = 17.4788s	
21620/33650 (epoch 32.125), train_loss = 0.94717820, grad/param norm = 1.6404e-01, time/batch = 17.5630s	
21621/33650 (epoch 32.126), train_loss = 0.98501292, grad/param norm = 1.9931e-01, time/batch = 17.8890s	
21622/33650 (epoch 32.128), train_loss = 0.94191938, grad/param norm = 1.7570e-01, time/batch = 17.8917s	
21623/33650 (epoch 32.129), train_loss = 0.95378875, grad/param norm = 1.7299e-01, time/batch = 16.0352s	
21624/33650 (epoch 32.131), train_loss = 0.90510323, grad/param norm = 1.7171e-01, time/batch = 18.1532s	
21625/33650 (epoch 32.132), train_loss = 0.89212177, grad/param norm = 1.5248e-01, time/batch = 17.8877s	
21626/33650 (epoch 32.134), train_loss = 0.95593551, grad/param norm = 1.8711e-01, time/batch = 17.4744s	
21627/33650 (epoch 32.135), train_loss = 0.77400662, grad/param norm = 1.5104e-01, time/batch = 18.1422s	
21628/33650 (epoch 32.137), train_loss = 0.93518744, grad/param norm = 2.0744e-01, time/batch = 18.3196s	
21629/33650 (epoch 32.138), train_loss = 0.94898400, grad/param norm = 1.5570e-01, time/batch = 17.4631s	
21630/33650 (epoch 32.140), train_loss = 0.89996763, grad/param norm = 1.9223e-01, time/batch = 17.9834s	
21631/33650 (epoch 32.141), train_loss = 1.02381867, grad/param norm = 1.7626e-01, time/batch = 18.4837s	
21632/33650 (epoch 32.143), train_loss = 1.04707801, grad/param norm = 2.1727e-01, time/batch = 17.9049s	
21633/33650 (epoch 32.144), train_loss = 0.94563272, grad/param norm = 1.7929e-01, time/batch = 16.6302s	
21634/33650 (epoch 32.146), train_loss = 0.87532884, grad/param norm = 1.5238e-01, time/batch = 17.7192s	
21635/33650 (epoch 32.147), train_loss = 0.82016922, grad/param norm = 1.5487e-01, time/batch = 18.0742s	
21636/33650 (epoch 32.149), train_loss = 0.78813406, grad/param norm = 1.5838e-01, time/batch = 17.1491s	
21637/33650 (epoch 32.150), train_loss = 0.76272434, grad/param norm = 1.3982e-01, time/batch = 15.7328s	
21638/33650 (epoch 32.152), train_loss = 0.84043546, grad/param norm = 1.5392e-01, time/batch = 17.2174s	
21639/33650 (epoch 32.153), train_loss = 0.86442095, grad/param norm = 1.6235e-01, time/batch = 18.6494s	
21640/33650 (epoch 32.155), train_loss = 0.80546856, grad/param norm = 1.4607e-01, time/batch = 17.0627s	
21641/33650 (epoch 32.156), train_loss = 0.80071088, grad/param norm = 1.3524e-01, time/batch = 18.3114s	
21642/33650 (epoch 32.158), train_loss = 0.92641437, grad/param norm = 1.9120e-01, time/batch = 16.9671s	
21643/33650 (epoch 32.159), train_loss = 0.82072712, grad/param norm = 1.3798e-01, time/batch = 16.8163s	
21644/33650 (epoch 32.160), train_loss = 0.81229489, grad/param norm = 1.4010e-01, time/batch = 18.3151s	
21645/33650 (epoch 32.162), train_loss = 0.84540662, grad/param norm = 1.6787e-01, time/batch = 18.0657s	
21646/33650 (epoch 32.163), train_loss = 0.91378181, grad/param norm = 1.7721e-01, time/batch = 16.5542s	
21647/33650 (epoch 32.165), train_loss = 0.78780644, grad/param norm = 1.7272e-01, time/batch = 17.5636s	
21648/33650 (epoch 32.166), train_loss = 0.78526230, grad/param norm = 1.6235e-01, time/batch = 18.1454s	
21649/33650 (epoch 32.168), train_loss = 0.98722472, grad/param norm = 1.8962e-01, time/batch = 18.3058s	
21650/33650 (epoch 32.169), train_loss = 0.88079486, grad/param norm = 2.0249e-01, time/batch = 17.0537s	
21651/33650 (epoch 32.171), train_loss = 0.85488435, grad/param norm = 1.3457e-01, time/batch = 18.5698s	
21652/33650 (epoch 32.172), train_loss = 0.84011802, grad/param norm = 1.6211e-01, time/batch = 18.8922s	
21653/33650 (epoch 32.174), train_loss = 0.82532937, grad/param norm = 1.8076e-01, time/batch = 16.2083s	
21654/33650 (epoch 32.175), train_loss = 0.77542820, grad/param norm = 1.8767e-01, time/batch = 18.6480s	
21655/33650 (epoch 32.177), train_loss = 0.87399134, grad/param norm = 1.6791e-01, time/batch = 16.9830s	
21656/33650 (epoch 32.178), train_loss = 0.83829067, grad/param norm = 1.7641e-01, time/batch = 17.5610s	
21657/33650 (epoch 32.180), train_loss = 0.78288665, grad/param norm = 1.5033e-01, time/batch = 17.3831s	
21658/33650 (epoch 32.181), train_loss = 0.71235839, grad/param norm = 1.4434e-01, time/batch = 17.8133s	
21659/33650 (epoch 32.183), train_loss = 0.80889498, grad/param norm = 1.8970e-01, time/batch = 17.7419s	
21660/33650 (epoch 32.184), train_loss = 0.79884104, grad/param norm = 1.7537e-01, time/batch = 16.5535s	
21661/33650 (epoch 32.186), train_loss = 0.84296742, grad/param norm = 1.8246e-01, time/batch = 18.5554s	
21662/33650 (epoch 32.187), train_loss = 0.99210162, grad/param norm = 1.7659e-01, time/batch = 19.1446s	
21663/33650 (epoch 32.189), train_loss = 0.98135333, grad/param norm = 1.9919e-01, time/batch = 15.3751s	
21664/33650 (epoch 32.190), train_loss = 0.91005295, grad/param norm = 2.0719e-01, time/batch = 18.2282s	
21665/33650 (epoch 32.192), train_loss = 1.03812714, grad/param norm = 1.5639e-01, time/batch = 16.7832s	
21666/33650 (epoch 32.193), train_loss = 1.00819339, grad/param norm = 1.8234e-01, time/batch = 18.7300s	
21667/33650 (epoch 32.195), train_loss = 0.76559013, grad/param norm = 1.5558e-01, time/batch = 17.7170s	
21668/33650 (epoch 32.196), train_loss = 0.74148314, grad/param norm = 1.8387e-01, time/batch = 16.6380s	
21669/33650 (epoch 32.198), train_loss = 0.85005069, grad/param norm = 1.5435e-01, time/batch = 18.3067s	
21670/33650 (epoch 32.199), train_loss = 0.93854072, grad/param norm = 1.7639e-01, time/batch = 16.2234s	
21671/33650 (epoch 32.201), train_loss = 0.83906316, grad/param norm = 1.9395e-01, time/batch = 18.7226s	
21672/33650 (epoch 32.202), train_loss = 0.86775783, grad/param norm = 1.6241e-01, time/batch = 18.1386s	
21673/33650 (epoch 32.204), train_loss = 0.91869264, grad/param norm = 1.6655e-01, time/batch = 17.5611s	
21674/33650 (epoch 32.205), train_loss = 0.86402811, grad/param norm = 1.7410e-01, time/batch = 17.4635s	
21675/33650 (epoch 32.207), train_loss = 0.80935341, grad/param norm = 1.8986e-01, time/batch = 18.6469s	
21676/33650 (epoch 32.208), train_loss = 0.90313763, grad/param norm = 1.5855e-01, time/batch = 17.9674s	
21677/33650 (epoch 32.210), train_loss = 0.72917170, grad/param norm = 1.6018e-01, time/batch = 17.2183s	
21678/33650 (epoch 32.211), train_loss = 0.82136231, grad/param norm = 1.6890e-01, time/batch = 17.8175s	
21679/33650 (epoch 32.212), train_loss = 0.90837697, grad/param norm = 1.8242e-01, time/batch = 18.7366s	
21680/33650 (epoch 32.214), train_loss = 1.04112096, grad/param norm = 1.7435e-01, time/batch = 16.8879s	
21681/33650 (epoch 32.215), train_loss = 0.68278324, grad/param norm = 1.5551e-01, time/batch = 18.4037s	
21682/33650 (epoch 32.217), train_loss = 0.84997158, grad/param norm = 1.9107e-01, time/batch = 18.3169s	
21683/33650 (epoch 32.218), train_loss = 0.85146454, grad/param norm = 1.4808e-01, time/batch = 16.7921s	
21684/33650 (epoch 32.220), train_loss = 0.76053272, grad/param norm = 1.5951e-01, time/batch = 17.5702s	
21685/33650 (epoch 32.221), train_loss = 1.01709034, grad/param norm = 1.9318e-01, time/batch = 18.2334s	
21686/33650 (epoch 32.223), train_loss = 0.71748960, grad/param norm = 1.5910e-01, time/batch = 18.8213s	
21687/33650 (epoch 32.224), train_loss = 0.82621075, grad/param norm = 2.0944e-01, time/batch = 16.3926s	
21688/33650 (epoch 32.226), train_loss = 1.11568263, grad/param norm = 1.7067e-01, time/batch = 16.2226s	
21689/33650 (epoch 32.227), train_loss = 0.98007345, grad/param norm = 2.0316e-01, time/batch = 17.1580s	
21690/33650 (epoch 32.229), train_loss = 0.97856007, grad/param norm = 1.6090e-01, time/batch = 17.8164s	
21691/33650 (epoch 32.230), train_loss = 1.10243575, grad/param norm = 2.1356e-01, time/batch = 16.7935s	
21692/33650 (epoch 32.232), train_loss = 0.95456747, grad/param norm = 2.2448e-01, time/batch = 18.6575s	
21693/33650 (epoch 32.233), train_loss = 0.94457833, grad/param norm = 2.4297e-01, time/batch = 17.7342s	
21694/33650 (epoch 32.235), train_loss = 0.88975503, grad/param norm = 1.9982e-01, time/batch = 17.7958s	
21695/33650 (epoch 32.236), train_loss = 0.82008598, grad/param norm = 1.4378e-01, time/batch = 17.8981s	
21696/33650 (epoch 32.238), train_loss = 0.84062469, grad/param norm = 1.5015e-01, time/batch = 18.1546s	
21697/33650 (epoch 32.239), train_loss = 0.80293010, grad/param norm = 1.6923e-01, time/batch = 16.6277s	
21698/33650 (epoch 32.241), train_loss = 0.85733758, grad/param norm = 1.4625e-01, time/batch = 17.8155s	
21699/33650 (epoch 32.242), train_loss = 0.71398344, grad/param norm = 1.6138e-01, time/batch = 18.6497s	
21700/33650 (epoch 32.244), train_loss = 0.84690466, grad/param norm = 1.4845e-01, time/batch = 17.9844s	
21701/33650 (epoch 32.245), train_loss = 0.75131786, grad/param norm = 1.3929e-01, time/batch = 18.6506s	
21702/33650 (epoch 32.247), train_loss = 0.84099031, grad/param norm = 1.5818e-01, time/batch = 17.1199s	
21703/33650 (epoch 32.248), train_loss = 0.77223096, grad/param norm = 1.5905e-01, time/batch = 17.1421s	
21704/33650 (epoch 32.250), train_loss = 0.86576568, grad/param norm = 1.4878e-01, time/batch = 17.7102s	
21705/33650 (epoch 32.251), train_loss = 0.97205254, grad/param norm = 1.5182e-01, time/batch = 17.8102s	
21706/33650 (epoch 32.253), train_loss = 0.76541566, grad/param norm = 1.4920e-01, time/batch = 18.8811s	
21707/33650 (epoch 32.254), train_loss = 0.83647156, grad/param norm = 1.6471e-01, time/batch = 16.2974s	
21708/33650 (epoch 32.256), train_loss = 0.98807120, grad/param norm = 1.4905e-01, time/batch = 18.8829s	
21709/33650 (epoch 32.257), train_loss = 0.95725475, grad/param norm = 1.6779e-01, time/batch = 17.8291s	
21710/33650 (epoch 32.259), train_loss = 0.78248472, grad/param norm = 1.4469e-01, time/batch = 17.2324s	
21711/33650 (epoch 32.260), train_loss = 0.90047901, grad/param norm = 1.5622e-01, time/batch = 17.8966s	
21712/33650 (epoch 32.262), train_loss = 0.88173315, grad/param norm = 1.7264e-01, time/batch = 18.4858s	
21713/33650 (epoch 32.263), train_loss = 0.84060102, grad/param norm = 2.2633e-01, time/batch = 19.1398s	
21714/33650 (epoch 32.264), train_loss = 0.94720356, grad/param norm = 1.8277e-01, time/batch = 16.3631s	
21715/33650 (epoch 32.266), train_loss = 0.91303438, grad/param norm = 1.8454e-01, time/batch = 18.0547s	
21716/33650 (epoch 32.267), train_loss = 0.83251818, grad/param norm = 1.5814e-01, time/batch = 18.0728s	
21717/33650 (epoch 32.269), train_loss = 0.88288229, grad/param norm = 1.6008e-01, time/batch = 17.3160s	
21718/33650 (epoch 32.270), train_loss = 0.80060747, grad/param norm = 1.7149e-01, time/batch = 18.5617s	
21719/33650 (epoch 32.272), train_loss = 0.82258990, grad/param norm = 1.4136e-01, time/batch = 17.5667s	
21720/33650 (epoch 32.273), train_loss = 0.96263410, grad/param norm = 1.8123e-01, time/batch = 17.6523s	
21721/33650 (epoch 32.275), train_loss = 0.92244952, grad/param norm = 1.6919e-01, time/batch = 17.6387s	
21722/33650 (epoch 32.276), train_loss = 0.96396546, grad/param norm = 1.8558e-01, time/batch = 15.5551s	
21723/33650 (epoch 32.278), train_loss = 1.05470665, grad/param norm = 1.9625e-01, time/batch = 18.9019s	
21724/33650 (epoch 32.279), train_loss = 0.84449923, grad/param norm = 1.4050e-01, time/batch = 17.2184s	
21725/33650 (epoch 32.281), train_loss = 0.88626061, grad/param norm = 1.5586e-01, time/batch = 17.9826s	
21726/33650 (epoch 32.282), train_loss = 0.99055079, grad/param norm = 1.3982e-01, time/batch = 17.9038s	
21727/33650 (epoch 32.284), train_loss = 0.96589752, grad/param norm = 1.7306e-01, time/batch = 17.4077s	
21728/33650 (epoch 32.285), train_loss = 0.92374560, grad/param norm = 1.8336e-01, time/batch = 17.6521s	
21729/33650 (epoch 32.287), train_loss = 0.84234559, grad/param norm = 1.6195e-01, time/batch = 18.9069s	
21730/33650 (epoch 32.288), train_loss = 0.86973558, grad/param norm = 1.7572e-01, time/batch = 17.8871s	
21731/33650 (epoch 32.290), train_loss = 0.87673464, grad/param norm = 1.5477e-01, time/batch = 17.4770s	
21732/33650 (epoch 32.291), train_loss = 0.80493877, grad/param norm = 1.4103e-01, time/batch = 18.0705s	
21733/33650 (epoch 32.293), train_loss = 0.88669337, grad/param norm = 2.0861e-01, time/batch = 18.1480s	
21734/33650 (epoch 32.294), train_loss = 0.80842716, grad/param norm = 1.4652e-01, time/batch = 16.2937s	
21735/33650 (epoch 32.296), train_loss = 0.78578090, grad/param norm = 1.5946e-01, time/batch = 16.2855s	
21736/33650 (epoch 32.297), train_loss = 0.84703255, grad/param norm = 1.5983e-01, time/batch = 18.7330s	
21737/33650 (epoch 32.299), train_loss = 0.74510719, grad/param norm = 1.5796e-01, time/batch = 18.3930s	
21738/33650 (epoch 32.300), train_loss = 0.78667155, grad/param norm = 1.7323e-01, time/batch = 16.4711s	
21739/33650 (epoch 32.302), train_loss = 0.89088988, grad/param norm = 1.5756e-01, time/batch = 17.4728s	
21740/33650 (epoch 32.303), train_loss = 0.90166995, grad/param norm = 1.4413e-01, time/batch = 18.3105s	
21741/33650 (epoch 32.305), train_loss = 0.85877702, grad/param norm = 1.5141e-01, time/batch = 17.1352s	
21742/33650 (epoch 32.306), train_loss = 0.79412765, grad/param norm = 1.3385e-01, time/batch = 17.8902s	
21743/33650 (epoch 32.308), train_loss = 0.76078531, grad/param norm = 1.5716e-01, time/batch = 17.7995s	
21744/33650 (epoch 32.309), train_loss = 0.99715340, grad/param norm = 1.8257e-01, time/batch = 16.8795s	
21745/33650 (epoch 32.311), train_loss = 0.87681344, grad/param norm = 2.2631e-01, time/batch = 18.0498s	
21746/33650 (epoch 32.312), train_loss = 0.92506065, grad/param norm = 1.8957e-01, time/batch = 18.6403s	
21747/33650 (epoch 32.314), train_loss = 0.80189399, grad/param norm = 1.4846e-01, time/batch = 17.9643s	
21748/33650 (epoch 32.315), train_loss = 0.86202593, grad/param norm = 1.8981e-01, time/batch = 16.5591s	
21749/33650 (epoch 32.316), train_loss = 0.81655296, grad/param norm = 1.8268e-01, time/batch = 17.6187s	
21750/33650 (epoch 32.318), train_loss = 0.76389207, grad/param norm = 1.4547e-01, time/batch = 17.0633s	
21751/33650 (epoch 32.319), train_loss = 0.80593365, grad/param norm = 1.6353e-01, time/batch = 16.9002s	
21752/33650 (epoch 32.321), train_loss = 0.83074508, grad/param norm = 1.4555e-01, time/batch = 18.6311s	
21753/33650 (epoch 32.322), train_loss = 0.89235200, grad/param norm = 1.8537e-01, time/batch = 18.2312s	
21754/33650 (epoch 32.324), train_loss = 0.92106761, grad/param norm = 1.8047e-01, time/batch = 18.0531s	
21755/33650 (epoch 32.325), train_loss = 0.91409022, grad/param norm = 1.7539e-01, time/batch = 16.7906s	
21756/33650 (epoch 32.327), train_loss = 0.81480487, grad/param norm = 1.4111e-01, time/batch = 18.0630s	
21757/33650 (epoch 32.328), train_loss = 0.87715260, grad/param norm = 1.6818e-01, time/batch = 18.3152s	
21758/33650 (epoch 32.330), train_loss = 0.81357832, grad/param norm = 1.4760e-01, time/batch = 17.7980s	
21759/33650 (epoch 32.331), train_loss = 0.76067766, grad/param norm = 1.3821e-01, time/batch = 17.2351s	
21760/33650 (epoch 32.333), train_loss = 0.84281628, grad/param norm = 1.7293e-01, time/batch = 18.2229s	
21761/33650 (epoch 32.334), train_loss = 0.86646454, grad/param norm = 1.6351e-01, time/batch = 15.9479s	
21762/33650 (epoch 32.336), train_loss = 0.96402928, grad/param norm = 1.6019e-01, time/batch = 18.5684s	
21763/33650 (epoch 32.337), train_loss = 0.73638221, grad/param norm = 1.3853e-01, time/batch = 17.7272s	
21764/33650 (epoch 32.339), train_loss = 0.82975126, grad/param norm = 1.5390e-01, time/batch = 17.5576s	
21765/33650 (epoch 32.340), train_loss = 0.96173419, grad/param norm = 1.6180e-01, time/batch = 17.2348s	
21766/33650 (epoch 32.342), train_loss = 0.70822671, grad/param norm = 1.4521e-01, time/batch = 19.3926s	
21767/33650 (epoch 32.343), train_loss = 0.91644808, grad/param norm = 1.6827e-01, time/batch = 18.6363s	
21768/33650 (epoch 32.345), train_loss = 0.87359097, grad/param norm = 1.7167e-01, time/batch = 16.9670s	
21769/33650 (epoch 32.346), train_loss = 0.60284931, grad/param norm = 1.4463e-01, time/batch = 18.5732s	
21770/33650 (epoch 32.348), train_loss = 0.74751021, grad/param norm = 1.5500e-01, time/batch = 18.5587s	
21771/33650 (epoch 32.349), train_loss = 0.70161928, grad/param norm = 1.5044e-01, time/batch = 17.8965s	
21772/33650 (epoch 32.351), train_loss = 0.90851712, grad/param norm = 1.7391e-01, time/batch = 17.3010s	
21773/33650 (epoch 32.352), train_loss = 0.84247790, grad/param norm = 1.5778e-01, time/batch = 17.7838s	
21774/33650 (epoch 32.354), train_loss = 0.98457524, grad/param norm = 2.1053e-01, time/batch = 17.3910s	
21775/33650 (epoch 32.355), train_loss = 1.01077431, grad/param norm = 1.6603e-01, time/batch = 17.3110s	
21776/33650 (epoch 32.357), train_loss = 0.72657214, grad/param norm = 1.5176e-01, time/batch = 17.0476s	
21777/33650 (epoch 32.358), train_loss = 0.88655929, grad/param norm = 1.6274e-01, time/batch = 18.0753s	
21778/33650 (epoch 32.360), train_loss = 0.91371841, grad/param norm = 1.7710e-01, time/batch = 18.2989s	
21779/33650 (epoch 32.361), train_loss = 0.88264892, grad/param norm = 1.6447e-01, time/batch = 17.5622s	
21780/33650 (epoch 32.363), train_loss = 0.87668065, grad/param norm = 1.4957e-01, time/batch = 18.9774s	
21781/33650 (epoch 32.364), train_loss = 0.85988723, grad/param norm = 1.4960e-01, time/batch = 28.3341s	
21782/33650 (epoch 32.366), train_loss = 0.91575152, grad/param norm = 1.8777e-01, time/batch = 19.3661s	
21783/33650 (epoch 32.367), train_loss = 0.90622757, grad/param norm = 1.6629e-01, time/batch = 18.5594s	
21784/33650 (epoch 32.368), train_loss = 0.81346869, grad/param norm = 1.3310e-01, time/batch = 17.7216s	
21785/33650 (epoch 32.370), train_loss = 0.84784608, grad/param norm = 1.4772e-01, time/batch = 17.5605s	
21786/33650 (epoch 32.371), train_loss = 0.66872835, grad/param norm = 1.3092e-01, time/batch = 17.7404s	
21787/33650 (epoch 32.373), train_loss = 0.76504038, grad/param norm = 1.5436e-01, time/batch = 17.3860s	
21788/33650 (epoch 32.374), train_loss = 0.78762428, grad/param norm = 1.4170e-01, time/batch = 17.8966s	
21789/33650 (epoch 32.376), train_loss = 0.84705643, grad/param norm = 1.7839e-01, time/batch = 17.4980s	
21790/33650 (epoch 32.377), train_loss = 0.89744385, grad/param norm = 1.8628e-01, time/batch = 15.8036s	
21791/33650 (epoch 32.379), train_loss = 0.89527651, grad/param norm = 1.5434e-01, time/batch = 17.7250s	
21792/33650 (epoch 32.380), train_loss = 0.73288640, grad/param norm = 1.7203e-01, time/batch = 18.1440s	
21793/33650 (epoch 32.382), train_loss = 0.87426137, grad/param norm = 1.3400e-01, time/batch = 17.4101s	
21794/33650 (epoch 32.383), train_loss = 0.84012838, grad/param norm = 1.5614e-01, time/batch = 16.7273s	
21795/33650 (epoch 32.385), train_loss = 0.89625193, grad/param norm = 1.5770e-01, time/batch = 18.4837s	
21796/33650 (epoch 32.386), train_loss = 0.79958588, grad/param norm = 1.5698e-01, time/batch = 18.0586s	
21797/33650 (epoch 32.388), train_loss = 0.94016194, grad/param norm = 1.6460e-01, time/batch = 16.9735s	
21798/33650 (epoch 32.389), train_loss = 0.80706485, grad/param norm = 1.4695e-01, time/batch = 17.7339s	
21799/33650 (epoch 32.391), train_loss = 0.68350741, grad/param norm = 1.3513e-01, time/batch = 18.9800s	
21800/33650 (epoch 32.392), train_loss = 0.88640241, grad/param norm = 1.5649e-01, time/batch = 16.6385s	
21801/33650 (epoch 32.394), train_loss = 0.87227834, grad/param norm = 1.7489e-01, time/batch = 15.7980s	
21802/33650 (epoch 32.395), train_loss = 0.89559696, grad/param norm = 1.5638e-01, time/batch = 17.9036s	
21803/33650 (epoch 32.397), train_loss = 1.02689560, grad/param norm = 1.9124e-01, time/batch = 19.0668s	
21804/33650 (epoch 32.398), train_loss = 0.93572529, grad/param norm = 1.6014e-01, time/batch = 17.0567s	
21805/33650 (epoch 32.400), train_loss = 0.86309247, grad/param norm = 1.7805e-01, time/batch = 18.8985s	
21806/33650 (epoch 32.401), train_loss = 0.80339402, grad/param norm = 1.8381e-01, time/batch = 16.7284s	
21807/33650 (epoch 32.403), train_loss = 0.89904352, grad/param norm = 1.6222e-01, time/batch = 17.3033s	
21808/33650 (epoch 32.404), train_loss = 0.85772300, grad/param norm = 1.6548e-01, time/batch = 17.9721s	
21809/33650 (epoch 32.406), train_loss = 0.83875624, grad/param norm = 1.6295e-01, time/batch = 17.7280s	
21810/33650 (epoch 32.407), train_loss = 0.86520211, grad/param norm = 1.7461e-01, time/batch = 18.1479s	
21811/33650 (epoch 32.409), train_loss = 0.89669694, grad/param norm = 1.6264e-01, time/batch = 17.1911s	
21812/33650 (epoch 32.410), train_loss = 0.85182026, grad/param norm = 1.5523e-01, time/batch = 18.2338s	
21813/33650 (epoch 32.412), train_loss = 0.86748513, grad/param norm = 1.5500e-01, time/batch = 18.8986s	
21814/33650 (epoch 32.413), train_loss = 0.79916936, grad/param norm = 1.5541e-01, time/batch = 16.6371s	
21815/33650 (epoch 32.415), train_loss = 0.94880902, grad/param norm = 1.7096e-01, time/batch = 18.2182s	
21816/33650 (epoch 32.416), train_loss = 1.00097922, grad/param norm = 1.5394e-01, time/batch = 18.3039s	
21817/33650 (epoch 32.418), train_loss = 0.78531852, grad/param norm = 1.5375e-01, time/batch = 17.9704s	
21818/33650 (epoch 32.419), train_loss = 0.82162796, grad/param norm = 1.6116e-01, time/batch = 16.9057s	
21819/33650 (epoch 32.421), train_loss = 0.83791327, grad/param norm = 1.3949e-01, time/batch = 17.5553s	
21820/33650 (epoch 32.422), train_loss = 0.98315004, grad/param norm = 1.6087e-01, time/batch = 18.3142s	
21821/33650 (epoch 32.423), train_loss = 0.78592792, grad/param norm = 1.3025e-01, time/batch = 16.8933s	
21822/33650 (epoch 32.425), train_loss = 0.88584682, grad/param norm = 1.7279e-01, time/batch = 18.7311s	
21823/33650 (epoch 32.426), train_loss = 0.94314138, grad/param norm = 1.7605e-01, time/batch = 17.8122s	
21824/33650 (epoch 32.428), train_loss = 0.82106713, grad/param norm = 1.4428e-01, time/batch = 16.5551s	
21825/33650 (epoch 32.429), train_loss = 0.92384442, grad/param norm = 1.6453e-01, time/batch = 17.0380s	
21826/33650 (epoch 32.431), train_loss = 1.02038023, grad/param norm = 1.9606e-01, time/batch = 18.4836s	
21827/33650 (epoch 32.432), train_loss = 1.00853916, grad/param norm = 1.8409e-01, time/batch = 17.4604s	
21828/33650 (epoch 32.434), train_loss = 0.89134259, grad/param norm = 1.6474e-01, time/batch = 18.2264s	
21829/33650 (epoch 32.435), train_loss = 0.89250312, grad/param norm = 1.8354e-01, time/batch = 18.4079s	
21830/33650 (epoch 32.437), train_loss = 0.88948462, grad/param norm = 1.6807e-01, time/batch = 18.3017s	
21831/33650 (epoch 32.438), train_loss = 0.84440160, grad/param norm = 1.6079e-01, time/batch = 17.0502s	
21832/33650 (epoch 32.440), train_loss = 0.88193524, grad/param norm = 1.9236e-01, time/batch = 18.3188s	
21833/33650 (epoch 32.441), train_loss = 0.88164814, grad/param norm = 2.1324e-01, time/batch = 18.1489s	
21834/33650 (epoch 32.443), train_loss = 0.93983522, grad/param norm = 1.5816e-01, time/batch = 17.6412s	
21835/33650 (epoch 32.444), train_loss = 0.85680505, grad/param norm = 1.6041e-01, time/batch = 17.0562s	
21836/33650 (epoch 32.446), train_loss = 0.92320172, grad/param norm = 1.8561e-01, time/batch = 17.7331s	
21837/33650 (epoch 32.447), train_loss = 1.00111027, grad/param norm = 1.8770e-01, time/batch = 18.8978s	
21838/33650 (epoch 32.449), train_loss = 0.98202626, grad/param norm = 1.8343e-01, time/batch = 18.2222s	
21839/33650 (epoch 32.450), train_loss = 1.03077722, grad/param norm = 1.8044e-01, time/batch = 16.5430s	
21840/33650 (epoch 32.452), train_loss = 0.99562240, grad/param norm = 2.1744e-01, time/batch = 15.5362s	
21841/33650 (epoch 32.453), train_loss = 1.03813458, grad/param norm = 1.8598e-01, time/batch = 16.4713s	
21842/33650 (epoch 32.455), train_loss = 0.87491869, grad/param norm = 1.5344e-01, time/batch = 17.9850s	
21843/33650 (epoch 32.456), train_loss = 0.89556082, grad/param norm = 1.6944e-01, time/batch = 17.9798s	
21844/33650 (epoch 32.458), train_loss = 0.86295338, grad/param norm = 1.6128e-01, time/batch = 17.4939s	
21845/33650 (epoch 32.459), train_loss = 0.90960409, grad/param norm = 1.6310e-01, time/batch = 17.4691s	
21846/33650 (epoch 32.461), train_loss = 0.96666727, grad/param norm = 1.7943e-01, time/batch = 17.4912s	
21847/33650 (epoch 32.462), train_loss = 0.97127844, grad/param norm = 1.7909e-01, time/batch = 18.7260s	
21848/33650 (epoch 32.464), train_loss = 0.84029033, grad/param norm = 1.7402e-01, time/batch = 16.6414s	
21849/33650 (epoch 32.465), train_loss = 0.92544145, grad/param norm = 1.9383e-01, time/batch = 15.9576s	
21850/33650 (epoch 32.467), train_loss = 0.90295690, grad/param norm = 1.4950e-01, time/batch = 17.9836s	
21851/33650 (epoch 32.468), train_loss = 1.03540784, grad/param norm = 1.5778e-01, time/batch = 18.3059s	
21852/33650 (epoch 32.470), train_loss = 1.08255247, grad/param norm = 1.9475e-01, time/batch = 18.1446s	
21853/33650 (epoch 32.471), train_loss = 0.87903776, grad/param norm = 1.6031e-01, time/batch = 18.3068s	
21854/33650 (epoch 32.473), train_loss = 0.84975781, grad/param norm = 1.4943e-01, time/batch = 18.8086s	
21855/33650 (epoch 32.474), train_loss = 0.99579756, grad/param norm = 1.7165e-01, time/batch = 15.3915s	
21856/33650 (epoch 32.475), train_loss = 0.96370578, grad/param norm = 1.7922e-01, time/batch = 15.0665s	
21857/33650 (epoch 32.477), train_loss = 0.98362309, grad/param norm = 1.6972e-01, time/batch = 15.2332s	
21858/33650 (epoch 32.478), train_loss = 0.99783431, grad/param norm = 1.8623e-01, time/batch = 17.7782s	
21859/33650 (epoch 32.480), train_loss = 0.97975606, grad/param norm = 1.9090e-01, time/batch = 17.7242s	
21860/33650 (epoch 32.481), train_loss = 1.00501813, grad/param norm = 1.7102e-01, time/batch = 18.4074s	
21861/33650 (epoch 32.483), train_loss = 0.75889518, grad/param norm = 1.4896e-01, time/batch = 17.1436s	
21862/33650 (epoch 32.484), train_loss = 0.85673103, grad/param norm = 1.6342e-01, time/batch = 16.7051s	
21863/33650 (epoch 32.486), train_loss = 1.03389098, grad/param norm = 2.1193e-01, time/batch = 18.0778s	
21864/33650 (epoch 32.487), train_loss = 1.01107100, grad/param norm = 1.7656e-01, time/batch = 18.0710s	
21865/33650 (epoch 32.489), train_loss = 1.05618674, grad/param norm = 1.7836e-01, time/batch = 16.9329s	
21866/33650 (epoch 32.490), train_loss = 0.82489871, grad/param norm = 1.5701e-01, time/batch = 18.0287s	
21867/33650 (epoch 32.492), train_loss = 0.95559829, grad/param norm = 2.1161e-01, time/batch = 18.6464s	
21868/33650 (epoch 32.493), train_loss = 0.76081387, grad/param norm = 1.5828e-01, time/batch = 15.8167s	
21869/33650 (epoch 32.495), train_loss = 0.94414644, grad/param norm = 1.7464e-01, time/batch = 17.9579s	
21870/33650 (epoch 32.496), train_loss = 0.95275723, grad/param norm = 1.7796e-01, time/batch = 18.4731s	
21871/33650 (epoch 32.498), train_loss = 0.83681940, grad/param norm = 1.5334e-01, time/batch = 17.9779s	
21872/33650 (epoch 32.499), train_loss = 0.88442343, grad/param norm = 1.3888e-01, time/batch = 17.1424s	
21873/33650 (epoch 32.501), train_loss = 0.88631352, grad/param norm = 1.3583e-01, time/batch = 18.3875s	
21874/33650 (epoch 32.502), train_loss = 0.95339268, grad/param norm = 3.6970e-01, time/batch = 17.3128s	
21875/33650 (epoch 32.504), train_loss = 0.97963165, grad/param norm = 1.8676e-01, time/batch = 16.8771s	
21876/33650 (epoch 32.505), train_loss = 0.89070042, grad/param norm = 2.0274e-01, time/batch = 18.3840s	
21877/33650 (epoch 32.507), train_loss = 1.02217971, grad/param norm = 1.8387e-01, time/batch = 16.1150s	
21878/33650 (epoch 32.508), train_loss = 0.88929457, grad/param norm = 1.6071e-01, time/batch = 17.2211s	
21879/33650 (epoch 32.510), train_loss = 0.90840711, grad/param norm = 1.6599e-01, time/batch = 17.3865s	
21880/33650 (epoch 32.511), train_loss = 1.05442843, grad/param norm = 2.1477e-01, time/batch = 17.8820s	
21881/33650 (epoch 32.513), train_loss = 0.95017685, grad/param norm = 1.5549e-01, time/batch = 18.8911s	
21882/33650 (epoch 32.514), train_loss = 1.00779667, grad/param norm = 2.0184e-01, time/batch = 17.0470s	
21883/33650 (epoch 32.516), train_loss = 0.90498898, grad/param norm = 1.7966e-01, time/batch = 16.8001s	
21884/33650 (epoch 32.517), train_loss = 0.91545157, grad/param norm = 1.7230e-01, time/batch = 18.4754s	
21885/33650 (epoch 32.519), train_loss = 0.96569514, grad/param norm = 1.7946e-01, time/batch = 17.8060s	
21886/33650 (epoch 32.520), train_loss = 0.78037749, grad/param norm = 1.4090e-01, time/batch = 16.0626s	
21887/33650 (epoch 32.522), train_loss = 0.89024544, grad/param norm = 1.6881e-01, time/batch = 15.4873s	
21888/33650 (epoch 32.523), train_loss = 0.83623562, grad/param norm = 1.6375e-01, time/batch = 15.1482s	
21889/33650 (epoch 32.525), train_loss = 0.70933507, grad/param norm = 1.2068e-01, time/batch = 17.2201s	
21890/33650 (epoch 32.526), train_loss = 1.00316961, grad/param norm = 1.5722e-01, time/batch = 17.2994s	
21891/33650 (epoch 32.527), train_loss = 0.84191620, grad/param norm = 1.5631e-01, time/batch = 17.4030s	
21892/33650 (epoch 32.529), train_loss = 0.90050766, grad/param norm = 1.7671e-01, time/batch = 18.3117s	
21893/33650 (epoch 32.530), train_loss = 0.84144091, grad/param norm = 1.6135e-01, time/batch = 16.4760s	
21894/33650 (epoch 32.532), train_loss = 0.97861923, grad/param norm = 1.9244e-01, time/batch = 18.6582s	
21895/33650 (epoch 32.533), train_loss = 0.90154825, grad/param norm = 1.5062e-01, time/batch = 18.3156s	
21896/33650 (epoch 32.535), train_loss = 1.02599094, grad/param norm = 1.8618e-01, time/batch = 17.2299s	
21897/33650 (epoch 32.536), train_loss = 0.92789383, grad/param norm = 2.1296e-01, time/batch = 18.8093s	
21898/33650 (epoch 32.538), train_loss = 0.93039585, grad/param norm = 1.8805e-01, time/batch = 17.2359s	
21899/33650 (epoch 32.539), train_loss = 0.70829821, grad/param norm = 1.5094e-01, time/batch = 17.2165s	
21900/33650 (epoch 32.541), train_loss = 0.98148694, grad/param norm = 1.8935e-01, time/batch = 17.5600s	
21901/33650 (epoch 32.542), train_loss = 0.90244530, grad/param norm = 2.2025e-01, time/batch = 18.4774s	
21902/33650 (epoch 32.544), train_loss = 1.06439996, grad/param norm = 2.5269e-01, time/batch = 17.9662s	
21903/33650 (epoch 32.545), train_loss = 0.80530626, grad/param norm = 1.5983e-01, time/batch = 17.8879s	
21904/33650 (epoch 32.547), train_loss = 0.95188244, grad/param norm = 1.6134e-01, time/batch = 18.5726s	
21905/33650 (epoch 32.548), train_loss = 1.06703291, grad/param norm = 1.7328e-01, time/batch = 16.9100s	
21906/33650 (epoch 32.550), train_loss = 0.92323964, grad/param norm = 1.7228e-01, time/batch = 16.5511s	
21907/33650 (epoch 32.551), train_loss = 0.93608078, grad/param norm = 1.8525e-01, time/batch = 18.3973s	
21908/33650 (epoch 32.553), train_loss = 0.79314902, grad/param norm = 1.6863e-01, time/batch = 17.9840s	
21909/33650 (epoch 32.554), train_loss = 1.07042251, grad/param norm = 1.9410e-01, time/batch = 17.5624s	
21910/33650 (epoch 32.556), train_loss = 1.01826575, grad/param norm = 2.9258e-01, time/batch = 16.5292s	
21911/33650 (epoch 32.557), train_loss = 0.99862258, grad/param norm = 2.3731e-01, time/batch = 18.3947s	
21912/33650 (epoch 32.559), train_loss = 1.15667271, grad/param norm = 2.0254e-01, time/batch = 16.9680s	
21913/33650 (epoch 32.560), train_loss = 1.06879290, grad/param norm = 1.9076e-01, time/batch = 16.4818s	
21914/33650 (epoch 32.562), train_loss = 1.04027051, grad/param norm = 1.7076e-01, time/batch = 17.9014s	
21915/33650 (epoch 32.563), train_loss = 0.94737083, grad/param norm = 1.7169e-01, time/batch = 18.5529s	
21916/33650 (epoch 32.565), train_loss = 0.93552463, grad/param norm = 1.6546e-01, time/batch = 16.8916s	
21917/33650 (epoch 32.566), train_loss = 0.90005865, grad/param norm = 2.2512e-01, time/batch = 17.4873s	
21918/33650 (epoch 32.568), train_loss = 0.92258352, grad/param norm = 1.9268e-01, time/batch = 17.8087s	
21919/33650 (epoch 32.569), train_loss = 0.84058696, grad/param norm = 1.5674e-01, time/batch = 18.5581s	
21920/33650 (epoch 32.571), train_loss = 1.01379996, grad/param norm = 1.7217e-01, time/batch = 17.3770s	
21921/33650 (epoch 32.572), train_loss = 0.97013280, grad/param norm = 1.6379e-01, time/batch = 19.1444s	
21922/33650 (epoch 32.574), train_loss = 0.83892102, grad/param norm = 1.8953e-01, time/batch = 18.5635s	
21923/33650 (epoch 32.575), train_loss = 0.91229002, grad/param norm = 1.6105e-01, time/batch = 17.3984s	
21924/33650 (epoch 32.577), train_loss = 0.83563096, grad/param norm = 1.7104e-01, time/batch = 17.2233s	
21925/33650 (epoch 32.578), train_loss = 1.02371168, grad/param norm = 1.8179e-01, time/batch = 17.8091s	
21926/33650 (epoch 32.579), train_loss = 0.97235643, grad/param norm = 1.8147e-01, time/batch = 17.6395s	
21927/33650 (epoch 32.581), train_loss = 1.06693922, grad/param norm = 1.7755e-01, time/batch = 18.2319s	
21928/33650 (epoch 32.582), train_loss = 0.94068890, grad/param norm = 1.5453e-01, time/batch = 16.2375s	
21929/33650 (epoch 32.584), train_loss = 0.93129090, grad/param norm = 1.5230e-01, time/batch = 17.9496s	
21930/33650 (epoch 32.585), train_loss = 0.95069958, grad/param norm = 1.7121e-01, time/batch = 17.4802s	
21931/33650 (epoch 32.587), train_loss = 0.84438898, grad/param norm = 1.6203e-01, time/batch = 17.0466s	
21932/33650 (epoch 32.588), train_loss = 0.86676307, grad/param norm = 2.3236e-01, time/batch = 18.6446s	
21933/33650 (epoch 32.590), train_loss = 0.87357862, grad/param norm = 1.4934e-01, time/batch = 17.4786s	
21934/33650 (epoch 32.591), train_loss = 0.79977703, grad/param norm = 1.6245e-01, time/batch = 17.7190s	
21935/33650 (epoch 32.593), train_loss = 0.80252179, grad/param norm = 1.6598e-01, time/batch = 17.8215s	
21936/33650 (epoch 32.594), train_loss = 0.79730231, grad/param norm = 1.5460e-01, time/batch = 17.6429s	
21937/33650 (epoch 32.596), train_loss = 0.90049063, grad/param norm = 1.6663e-01, time/batch = 17.3979s	
21938/33650 (epoch 32.597), train_loss = 0.79008633, grad/param norm = 1.4312e-01, time/batch = 18.8047s	
21939/33650 (epoch 32.599), train_loss = 0.88059515, grad/param norm = 1.5670e-01, time/batch = 17.8209s	
21940/33650 (epoch 32.600), train_loss = 0.84645867, grad/param norm = 1.7395e-01, time/batch = 16.8947s	
21941/33650 (epoch 32.602), train_loss = 0.91111523, grad/param norm = 1.6358e-01, time/batch = 18.7022s	
21942/33650 (epoch 32.603), train_loss = 0.85273494, grad/param norm = 1.7361e-01, time/batch = 17.0585s	
21943/33650 (epoch 32.605), train_loss = 0.95871962, grad/param norm = 1.7216e-01, time/batch = 17.1489s	
21944/33650 (epoch 32.606), train_loss = 0.89813888, grad/param norm = 1.8980e-01, time/batch = 17.8155s	
21945/33650 (epoch 32.608), train_loss = 0.79989113, grad/param norm = 1.7522e-01, time/batch = 17.8145s	
21946/33650 (epoch 32.609), train_loss = 0.90387565, grad/param norm = 1.6054e-01, time/batch = 17.7304s	
21947/33650 (epoch 32.611), train_loss = 0.80066765, grad/param norm = 1.6661e-01, time/batch = 17.4698s	
21948/33650 (epoch 32.612), train_loss = 0.89505619, grad/param norm = 1.9820e-01, time/batch = 17.4927s	
21949/33650 (epoch 32.614), train_loss = 1.00400555, grad/param norm = 1.7465e-01, time/batch = 19.0539s	
21950/33650 (epoch 32.615), train_loss = 0.92236291, grad/param norm = 1.5346e-01, time/batch = 16.4726s	
21951/33650 (epoch 32.617), train_loss = 0.82723987, grad/param norm = 1.3968e-01, time/batch = 17.9758s	
21952/33650 (epoch 32.618), train_loss = 0.85710604, grad/param norm = 1.6599e-01, time/batch = 18.1162s	
21953/33650 (epoch 32.620), train_loss = 0.83696963, grad/param norm = 1.6259e-01, time/batch = 16.6375s	
21954/33650 (epoch 32.621), train_loss = 0.81476037, grad/param norm = 1.5224e-01, time/batch = 17.8714s	
21955/33650 (epoch 32.623), train_loss = 0.86713532, grad/param norm = 1.5283e-01, time/batch = 15.6591s	
21956/33650 (epoch 32.624), train_loss = 0.70752514, grad/param norm = 1.5862e-01, time/batch = 13.8451s	
21957/33650 (epoch 32.626), train_loss = 0.73513196, grad/param norm = 1.4743e-01, time/batch = 13.9791s	
21958/33650 (epoch 32.627), train_loss = 0.83013715, grad/param norm = 1.4507e-01, time/batch = 16.5443s	
21959/33650 (epoch 32.629), train_loss = 0.84595647, grad/param norm = 1.7272e-01, time/batch = 17.0597s	
21960/33650 (epoch 32.630), train_loss = 0.99375700, grad/param norm = 1.7255e-01, time/batch = 18.6374s	
21961/33650 (epoch 32.632), train_loss = 0.97437996, grad/param norm = 1.6997e-01, time/batch = 16.2023s	
21962/33650 (epoch 32.633), train_loss = 0.97792158, grad/param norm = 1.7252e-01, time/batch = 18.3887s	
21963/33650 (epoch 32.634), train_loss = 0.78266905, grad/param norm = 1.5254e-01, time/batch = 18.2298s	
21964/33650 (epoch 32.636), train_loss = 0.69738311, grad/param norm = 1.2017e-01, time/batch = 17.2281s	
21965/33650 (epoch 32.637), train_loss = 0.80714084, grad/param norm = 1.5563e-01, time/batch = 17.3180s	
21966/33650 (epoch 32.639), train_loss = 0.82501449, grad/param norm = 1.6908e-01, time/batch = 18.3181s	
21967/33650 (epoch 32.640), train_loss = 0.91868485, grad/param norm = 1.8297e-01, time/batch = 17.6324s	
21968/33650 (epoch 32.642), train_loss = 0.96543979, grad/param norm = 1.6786e-01, time/batch = 17.5628s	
21969/33650 (epoch 32.643), train_loss = 0.89972413, grad/param norm = 1.6802e-01, time/batch = 17.9923s	
21970/33650 (epoch 32.645), train_loss = 0.91842718, grad/param norm = 1.8186e-01, time/batch = 18.7341s	
21971/33650 (epoch 32.646), train_loss = 0.78650560, grad/param norm = 1.3751e-01, time/batch = 17.8973s	
21972/33650 (epoch 32.648), train_loss = 0.94595673, grad/param norm = 1.7748e-01, time/batch = 18.5563s	
21973/33650 (epoch 32.649), train_loss = 0.80254882, grad/param norm = 1.6519e-01, time/batch = 16.8011s	
21974/33650 (epoch 32.651), train_loss = 0.95937581, grad/param norm = 1.7034e-01, time/batch = 17.3782s	
21975/33650 (epoch 32.652), train_loss = 0.66436580, grad/param norm = 1.4395e-01, time/batch = 17.3002s	
21976/33650 (epoch 32.654), train_loss = 0.79555701, grad/param norm = 1.5335e-01, time/batch = 16.7893s	
21977/33650 (epoch 32.655), train_loss = 0.78038419, grad/param norm = 1.5159e-01, time/batch = 18.2953s	
21978/33650 (epoch 32.657), train_loss = 0.84322713, grad/param norm = 1.6868e-01, time/batch = 17.8068s	
21979/33650 (epoch 32.658), train_loss = 0.71538243, grad/param norm = 1.5798e-01, time/batch = 16.5518s	
21980/33650 (epoch 32.660), train_loss = 0.71654017, grad/param norm = 1.4532e-01, time/batch = 17.4790s	
21981/33650 (epoch 32.661), train_loss = 0.79329731, grad/param norm = 1.4578e-01, time/batch = 16.8082s	
21982/33650 (epoch 32.663), train_loss = 0.76095547, grad/param norm = 1.8147e-01, time/batch = 18.8902s	
21983/33650 (epoch 32.664), train_loss = 0.84430656, grad/param norm = 1.6520e-01, time/batch = 18.7339s	
21984/33650 (epoch 32.666), train_loss = 0.84940513, grad/param norm = 1.3870e-01, time/batch = 19.5699s	
21985/33650 (epoch 32.667), train_loss = 0.74062687, grad/param norm = 1.4431e-01, time/batch = 27.4593s	
21986/33650 (epoch 32.669), train_loss = 0.77013082, grad/param norm = 1.5287e-01, time/batch = 17.7431s	
21987/33650 (epoch 32.670), train_loss = 0.69004253, grad/param norm = 1.5359e-01, time/batch = 15.3756s	
21988/33650 (epoch 32.672), train_loss = 0.72630326, grad/param norm = 1.4445e-01, time/batch = 17.5633s	
21989/33650 (epoch 32.673), train_loss = 0.72297893, grad/param norm = 1.5038e-01, time/batch = 17.5777s	
21990/33650 (epoch 32.675), train_loss = 0.67741747, grad/param norm = 1.3163e-01, time/batch = 17.6486s	
21991/33650 (epoch 32.676), train_loss = 0.82856092, grad/param norm = 1.7956e-01, time/batch = 16.8188s	
21992/33650 (epoch 32.678), train_loss = 0.81693213, grad/param norm = 1.7548e-01, time/batch = 16.3111s	
21993/33650 (epoch 32.679), train_loss = 0.81091901, grad/param norm = 2.2156e-01, time/batch = 18.1373s	
21994/33650 (epoch 32.681), train_loss = 0.82475672, grad/param norm = 1.5089e-01, time/batch = 16.8963s	
21995/33650 (epoch 32.682), train_loss = 0.78691203, grad/param norm = 1.7072e-01, time/batch = 17.5696s	
21996/33650 (epoch 32.684), train_loss = 0.74124289, grad/param norm = 1.4036e-01, time/batch = 17.4071s	
21997/33650 (epoch 32.685), train_loss = 0.88648471, grad/param norm = 1.6282e-01, time/batch = 17.1382s	
21998/33650 (epoch 32.686), train_loss = 0.84997476, grad/param norm = 1.6952e-01, time/batch = 15.4703s	
21999/33650 (epoch 32.688), train_loss = 0.94536351, grad/param norm = 1.5757e-01, time/batch = 16.8181s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch32.69_1.7268.t7	
22000/33650 (epoch 32.689), train_loss = 0.79825397, grad/param norm = 1.5304e-01, time/batch = 18.3271s	
22001/33650 (epoch 32.691), train_loss = 1.33429457, grad/param norm = 2.4879e-01, time/batch = 16.7064s	
22002/33650 (epoch 32.692), train_loss = 0.96499433, grad/param norm = 1.8153e-01, time/batch = 16.7282s	
22003/33650 (epoch 32.694), train_loss = 0.91008090, grad/param norm = 1.7916e-01, time/batch = 16.8983s	
22004/33650 (epoch 32.695), train_loss = 0.60317040, grad/param norm = 1.5245e-01, time/batch = 16.8988s	
22005/33650 (epoch 32.697), train_loss = 0.84554036, grad/param norm = 1.6150e-01, time/batch = 16.5668s	
22006/33650 (epoch 32.698), train_loss = 0.96226065, grad/param norm = 1.9507e-01, time/batch = 16.1598s	
22007/33650 (epoch 32.700), train_loss = 0.84007512, grad/param norm = 1.5509e-01, time/batch = 15.8119s	
22008/33650 (epoch 32.701), train_loss = 0.86886572, grad/param norm = 1.6592e-01, time/batch = 18.3174s	
22009/33650 (epoch 32.703), train_loss = 1.03271779, grad/param norm = 1.5431e-01, time/batch = 17.8973s	
22010/33650 (epoch 32.704), train_loss = 0.84671219, grad/param norm = 1.4731e-01, time/batch = 16.8101s	
22011/33650 (epoch 32.706), train_loss = 0.82740963, grad/param norm = 1.7019e-01, time/batch = 17.1414s	
22012/33650 (epoch 32.707), train_loss = 0.94426723, grad/param norm = 1.4785e-01, time/batch = 18.0724s	
22013/33650 (epoch 32.709), train_loss = 0.82606480, grad/param norm = 1.5451e-01, time/batch = 15.2285s	
22014/33650 (epoch 32.710), train_loss = 1.03548951, grad/param norm = 1.8666e-01, time/batch = 16.9032s	
22015/33650 (epoch 32.712), train_loss = 0.76157871, grad/param norm = 1.7476e-01, time/batch = 17.5743s	
22016/33650 (epoch 32.713), train_loss = 0.76806442, grad/param norm = 1.9099e-01, time/batch = 15.8868s	
22017/33650 (epoch 32.715), train_loss = 0.91604582, grad/param norm = 1.9129e-01, time/batch = 16.8997s	
22018/33650 (epoch 32.716), train_loss = 0.82670645, grad/param norm = 1.6594e-01, time/batch = 17.5729s	
22019/33650 (epoch 32.718), train_loss = 0.81017555, grad/param norm = 1.6329e-01, time/batch = 17.1565s	
22020/33650 (epoch 32.719), train_loss = 0.97388462, grad/param norm = 2.1145e-01, time/batch = 17.4099s	
22021/33650 (epoch 32.721), train_loss = 1.04620784, grad/param norm = 1.9622e-01, time/batch = 16.1375s	
22022/33650 (epoch 32.722), train_loss = 0.92620130, grad/param norm = 2.1921e-01, time/batch = 18.1485s	
22023/33650 (epoch 32.724), train_loss = 0.96815121, grad/param norm = 1.7217e-01, time/batch = 16.4917s	
22024/33650 (epoch 32.725), train_loss = 0.93024580, grad/param norm = 1.7776e-01, time/batch = 16.8138s	
22025/33650 (epoch 32.727), train_loss = 0.83657900, grad/param norm = 1.8718e-01, time/batch = 17.1474s	
22026/33650 (epoch 32.728), train_loss = 0.81756945, grad/param norm = 1.5075e-01, time/batch = 17.3354s	
22027/33650 (epoch 32.730), train_loss = 0.89753796, grad/param norm = 1.6478e-01, time/batch = 17.8267s	
22028/33650 (epoch 32.731), train_loss = 1.01820916, grad/param norm = 1.7053e-01, time/batch = 15.8943s	
22029/33650 (epoch 32.733), train_loss = 0.82549534, grad/param norm = 1.7080e-01, time/batch = 17.4909s	
22030/33650 (epoch 32.734), train_loss = 1.01023737, grad/param norm = 1.8920e-01, time/batch = 16.8195s	
22031/33650 (epoch 32.736), train_loss = 0.87211599, grad/param norm = 2.4468e-01, time/batch = 17.3181s	
22032/33650 (epoch 32.737), train_loss = 0.91400836, grad/param norm = 1.7121e-01, time/batch = 17.2234s	
22033/33650 (epoch 32.738), train_loss = 0.80619715, grad/param norm = 1.5996e-01, time/batch = 17.7462s	
22034/33650 (epoch 32.740), train_loss = 0.73498251, grad/param norm = 1.4940e-01, time/batch = 16.6384s	
22035/33650 (epoch 32.741), train_loss = 0.81045479, grad/param norm = 1.6889e-01, time/batch = 16.9533s	
22036/33650 (epoch 32.743), train_loss = 0.85462395, grad/param norm = 1.5266e-01, time/batch = 17.3221s	
22037/33650 (epoch 32.744), train_loss = 0.95839483, grad/param norm = 1.5011e-01, time/batch = 16.1629s	
22038/33650 (epoch 32.746), train_loss = 0.83390621, grad/param norm = 1.6916e-01, time/batch = 16.9022s	
22039/33650 (epoch 32.747), train_loss = 0.98552757, grad/param norm = 1.6671e-01, time/batch = 17.4914s	
22040/33650 (epoch 32.749), train_loss = 0.71697677, grad/param norm = 1.6781e-01, time/batch = 17.7363s	
22041/33650 (epoch 32.750), train_loss = 1.03005111, grad/param norm = 1.6928e-01, time/batch = 17.7444s	
22042/33650 (epoch 32.752), train_loss = 0.94603079, grad/param norm = 1.7653e-01, time/batch = 16.3938s	
22043/33650 (epoch 32.753), train_loss = 1.05925776, grad/param norm = 1.9069e-01, time/batch = 17.0663s	
22044/33650 (epoch 32.755), train_loss = 0.84232817, grad/param norm = 1.4988e-01, time/batch = 17.5026s	
22045/33650 (epoch 32.756), train_loss = 0.95231111, grad/param norm = 1.8864e-01, time/batch = 17.2174s	
22046/33650 (epoch 32.758), train_loss = 0.97043865, grad/param norm = 1.6333e-01, time/batch = 15.8977s	
22047/33650 (epoch 32.759), train_loss = 0.97385820, grad/param norm = 2.0993e-01, time/batch = 16.5585s	
22048/33650 (epoch 32.761), train_loss = 0.87824272, grad/param norm = 1.6023e-01, time/batch = 17.4007s	
22049/33650 (epoch 32.762), train_loss = 0.85198528, grad/param norm = 1.5774e-01, time/batch = 15.7466s	
22050/33650 (epoch 32.764), train_loss = 0.92590922, grad/param norm = 1.8455e-01, time/batch = 18.1500s	
22051/33650 (epoch 32.765), train_loss = 0.82377205, grad/param norm = 1.5597e-01, time/batch = 17.1599s	
22052/33650 (epoch 32.767), train_loss = 0.85379174, grad/param norm = 1.5694e-01, time/batch = 16.9835s	
22053/33650 (epoch 32.768), train_loss = 0.78787252, grad/param norm = 1.5697e-01, time/batch = 17.3199s	
22054/33650 (epoch 32.770), train_loss = 0.89427852, grad/param norm = 1.8078e-01, time/batch = 16.8069s	
22055/33650 (epoch 32.771), train_loss = 0.91436246, grad/param norm = 1.6083e-01, time/batch = 16.8288s	
22056/33650 (epoch 32.773), train_loss = 0.98381486, grad/param norm = 2.0733e-01, time/batch = 16.1360s	
22057/33650 (epoch 32.774), train_loss = 0.91941335, grad/param norm = 1.7693e-01, time/batch = 17.2342s	
22058/33650 (epoch 32.776), train_loss = 0.97611389, grad/param norm = 2.0432e-01, time/batch = 17.4126s	
22059/33650 (epoch 32.777), train_loss = 0.82130827, grad/param norm = 1.5170e-01, time/batch = 17.0654s	
22060/33650 (epoch 32.779), train_loss = 0.84986663, grad/param norm = 1.4930e-01, time/batch = 16.9861s	
22061/33650 (epoch 32.780), train_loss = 0.77779345, grad/param norm = 1.4922e-01, time/batch = 17.7353s	
22062/33650 (epoch 32.782), train_loss = 0.80413390, grad/param norm = 1.5297e-01, time/batch = 17.4922s	
22063/33650 (epoch 32.783), train_loss = 0.80659051, grad/param norm = 1.3094e-01, time/batch = 15.7201s	
22064/33650 (epoch 32.785), train_loss = 1.03016327, grad/param norm = 1.6388e-01, time/batch = 16.9818s	
22065/33650 (epoch 32.786), train_loss = 0.93690207, grad/param norm = 1.6151e-01, time/batch = 17.2203s	
22066/33650 (epoch 32.788), train_loss = 0.92484508, grad/param norm = 1.5479e-01, time/batch = 17.4756s	
22067/33650 (epoch 32.789), train_loss = 0.97312500, grad/param norm = 1.6585e-01, time/batch = 16.7232s	
22068/33650 (epoch 32.790), train_loss = 0.88575201, grad/param norm = 1.6109e-01, time/batch = 17.5805s	
22069/33650 (epoch 32.792), train_loss = 0.99110498, grad/param norm = 1.8850e-01, time/batch = 17.9104s	
22070/33650 (epoch 32.793), train_loss = 0.95660056, grad/param norm = 2.1783e-01, time/batch = 17.2273s	
22071/33650 (epoch 32.795), train_loss = 0.95734602, grad/param norm = 1.6789e-01, time/batch = 17.8312s	
22072/33650 (epoch 32.796), train_loss = 0.84837874, grad/param norm = 1.8062e-01, time/batch = 16.3963s	
22073/33650 (epoch 32.798), train_loss = 0.84747486, grad/param norm = 1.6620e-01, time/batch = 15.5588s	
22074/33650 (epoch 32.799), train_loss = 0.87303758, grad/param norm = 1.5796e-01, time/batch = 17.3241s	
22075/33650 (epoch 32.801), train_loss = 0.87996888, grad/param norm = 1.7857e-01, time/batch = 16.8981s	
22076/33650 (epoch 32.802), train_loss = 0.97932113, grad/param norm = 1.6792e-01, time/batch = 16.4893s	
22077/33650 (epoch 32.804), train_loss = 0.90494135, grad/param norm = 1.7660e-01, time/batch = 16.2036s	
22078/33650 (epoch 32.805), train_loss = 0.86381897, grad/param norm = 1.4767e-01, time/batch = 17.2320s	
22079/33650 (epoch 32.807), train_loss = 1.05258160, grad/param norm = 1.9335e-01, time/batch = 16.9117s	
22080/33650 (epoch 32.808), train_loss = 1.13132567, grad/param norm = 1.8292e-01, time/batch = 16.9002s	
22081/33650 (epoch 32.810), train_loss = 0.92764918, grad/param norm = 1.6830e-01, time/batch = 16.6425s	
22082/33650 (epoch 32.811), train_loss = 0.92193002, grad/param norm = 1.8902e-01, time/batch = 18.1512s	
22083/33650 (epoch 32.813), train_loss = 0.81164088, grad/param norm = 1.5149e-01, time/batch = 17.2446s	
22084/33650 (epoch 32.814), train_loss = 0.99464230, grad/param norm = 1.8765e-01, time/batch = 16.7094s	
22085/33650 (epoch 32.816), train_loss = 0.95404720, grad/param norm = 2.0637e-01, time/batch = 17.7186s	
22086/33650 (epoch 32.817), train_loss = 0.99382724, grad/param norm = 1.7780e-01, time/batch = 17.9047s	
22087/33650 (epoch 32.819), train_loss = 0.89547682, grad/param norm = 1.6871e-01, time/batch = 16.6512s	
22088/33650 (epoch 32.820), train_loss = 0.98607537, grad/param norm = 1.7185e-01, time/batch = 16.1341s	
22089/33650 (epoch 32.822), train_loss = 0.94463894, grad/param norm = 2.0154e-01, time/batch = 17.4710s	
22090/33650 (epoch 32.823), train_loss = 0.82842819, grad/param norm = 1.5697e-01, time/batch = 17.7262s	
22091/33650 (epoch 32.825), train_loss = 0.89376252, grad/param norm = 1.7522e-01, time/batch = 16.3974s	
22092/33650 (epoch 32.826), train_loss = 0.95013962, grad/param norm = 1.5471e-01, time/batch = 17.5690s	
22093/33650 (epoch 32.828), train_loss = 1.06052979, grad/param norm = 1.9127e-01, time/batch = 17.0796s	
22094/33650 (epoch 32.829), train_loss = 0.76671308, grad/param norm = 1.6487e-01, time/batch = 15.5471s	
22095/33650 (epoch 32.831), train_loss = 0.90950829, grad/param norm = 1.7487e-01, time/batch = 17.8079s	
22096/33650 (epoch 32.832), train_loss = 0.96309372, grad/param norm = 1.6719e-01, time/batch = 17.7388s	
22097/33650 (epoch 32.834), train_loss = 0.97356753, grad/param norm = 2.0702e-01, time/batch = 17.3195s	
22098/33650 (epoch 32.835), train_loss = 1.12367151, grad/param norm = 2.2550e-01, time/batch = 16.1346s	
22099/33650 (epoch 32.837), train_loss = 0.94635995, grad/param norm = 1.8272e-01, time/batch = 18.0657s	
22100/33650 (epoch 32.838), train_loss = 0.91151615, grad/param norm = 1.7776e-01, time/batch = 17.3265s	
22101/33650 (epoch 32.840), train_loss = 0.97442402, grad/param norm = 1.7240e-01, time/batch = 17.5815s	
22102/33650 (epoch 32.841), train_loss = 0.87303789, grad/param norm = 1.7250e-01, time/batch = 16.2473s	
22103/33650 (epoch 32.842), train_loss = 0.88464185, grad/param norm = 1.5019e-01, time/batch = 17.8985s	
22104/33650 (epoch 32.844), train_loss = 1.03028762, grad/param norm = 1.8668e-01, time/batch = 16.2969s	
22105/33650 (epoch 32.845), train_loss = 0.88867763, grad/param norm = 1.7513e-01, time/batch = 16.8146s	
22106/33650 (epoch 32.847), train_loss = 0.68330536, grad/param norm = 1.5106e-01, time/batch = 16.7272s	
22107/33650 (epoch 32.848), train_loss = 0.78641643, grad/param norm = 1.8324e-01, time/batch = 17.4811s	
22108/33650 (epoch 32.850), train_loss = 0.85852336, grad/param norm = 1.9605e-01, time/batch = 16.4087s	
22109/33650 (epoch 32.851), train_loss = 0.75601183, grad/param norm = 1.4095e-01, time/batch = 17.2244s	
22110/33650 (epoch 32.853), train_loss = 0.84800168, grad/param norm = 1.6480e-01, time/batch = 18.3172s	
22111/33650 (epoch 32.854), train_loss = 0.97559819, grad/param norm = 1.6392e-01, time/batch = 17.0693s	
22112/33650 (epoch 32.856), train_loss = 0.70257701, grad/param norm = 1.4605e-01, time/batch = 16.5529s	
22113/33650 (epoch 32.857), train_loss = 0.92110779, grad/param norm = 1.5869e-01, time/batch = 16.0604s	
22114/33650 (epoch 32.859), train_loss = 0.79446601, grad/param norm = 1.4314e-01, time/batch = 16.3987s	
22115/33650 (epoch 32.860), train_loss = 0.76092918, grad/param norm = 1.4893e-01, time/batch = 16.4007s	
22116/33650 (epoch 32.862), train_loss = 0.81753984, grad/param norm = 1.6243e-01, time/batch = 15.8642s	
22117/33650 (epoch 32.863), train_loss = 1.01047121, grad/param norm = 1.6209e-01, time/batch = 16.8998s	
22118/33650 (epoch 32.865), train_loss = 0.87361624, grad/param norm = 1.4298e-01, time/batch = 17.7334s	
22119/33650 (epoch 32.866), train_loss = 0.81669915, grad/param norm = 1.6999e-01, time/batch = 16.9742s	
22120/33650 (epoch 32.868), train_loss = 0.77042702, grad/param norm = 1.8789e-01, time/batch = 16.7419s	
22121/33650 (epoch 32.869), train_loss = 0.94269454, grad/param norm = 1.7669e-01, time/batch = 17.8125s	
22122/33650 (epoch 32.871), train_loss = 0.80016033, grad/param norm = 1.8300e-01, time/batch = 16.8193s	
22123/33650 (epoch 32.872), train_loss = 0.90532676, grad/param norm = 1.5930e-01, time/batch = 16.6504s	
22124/33650 (epoch 32.874), train_loss = 0.96094675, grad/param norm = 1.9850e-01, time/batch = 17.2388s	
22125/33650 (epoch 32.875), train_loss = 0.84908459, grad/param norm = 1.5775e-01, time/batch = 17.4772s	
22126/33650 (epoch 32.877), train_loss = 1.05288406, grad/param norm = 1.8269e-01, time/batch = 16.1159s	
22127/33650 (epoch 32.878), train_loss = 0.63015125, grad/param norm = 1.2182e-01, time/batch = 17.7329s	
22128/33650 (epoch 32.880), train_loss = 0.91715265, grad/param norm = 1.7753e-01, time/batch = 17.5633s	
22129/33650 (epoch 32.881), train_loss = 0.83905843, grad/param norm = 1.8054e-01, time/batch = 16.6431s	
22130/33650 (epoch 32.883), train_loss = 0.90483452, grad/param norm = 1.7116e-01, time/batch = 16.8151s	
22131/33650 (epoch 32.884), train_loss = 1.00305570, grad/param norm = 1.7642e-01, time/batch = 15.3986s	
22132/33650 (epoch 32.886), train_loss = 0.94202220, grad/param norm = 1.6984e-01, time/batch = 14.3043s	
22133/33650 (epoch 32.887), train_loss = 0.76527048, grad/param norm = 1.4102e-01, time/batch = 15.2066s	
22134/33650 (epoch 32.889), train_loss = 0.85281710, grad/param norm = 1.7750e-01, time/batch = 14.6978s	
22135/33650 (epoch 32.890), train_loss = 0.91024938, grad/param norm = 1.5108e-01, time/batch = 14.0195s	
22136/33650 (epoch 32.892), train_loss = 0.83301466, grad/param norm = 1.7806e-01, time/batch = 15.8162s	
22137/33650 (epoch 32.893), train_loss = 0.90396756, grad/param norm = 1.6195e-01, time/batch = 15.4545s	
22138/33650 (epoch 32.895), train_loss = 0.99567203, grad/param norm = 1.6112e-01, time/batch = 16.8328s	
22139/33650 (epoch 32.896), train_loss = 0.80317338, grad/param norm = 1.3860e-01, time/batch = 17.5798s	
22140/33650 (epoch 32.897), train_loss = 0.73801027, grad/param norm = 1.4923e-01, time/batch = 18.0743s	
22141/33650 (epoch 32.899), train_loss = 0.79319987, grad/param norm = 1.4381e-01, time/batch = 16.8994s	
22142/33650 (epoch 32.900), train_loss = 0.75438507, grad/param norm = 1.4381e-01, time/batch = 17.8274s	
22143/33650 (epoch 32.902), train_loss = 0.84872784, grad/param norm = 1.6968e-01, time/batch = 16.1269s	
22144/33650 (epoch 32.903), train_loss = 0.82831821, grad/param norm = 1.7134e-01, time/batch = 17.0575s	
22145/33650 (epoch 32.905), train_loss = 0.99328298, grad/param norm = 1.9196e-01, time/batch = 17.0720s	
22146/33650 (epoch 32.906), train_loss = 0.81598383, grad/param norm = 1.7068e-01, time/batch = 17.9937s	
22147/33650 (epoch 32.908), train_loss = 0.84749486, grad/param norm = 1.5257e-01, time/batch = 17.7237s	
22148/33650 (epoch 32.909), train_loss = 0.82306106, grad/param norm = 1.3909e-01, time/batch = 16.2229s	
22149/33650 (epoch 32.911), train_loss = 0.73273718, grad/param norm = 1.3547e-01, time/batch = 17.2421s	
22150/33650 (epoch 32.912), train_loss = 0.69614160, grad/param norm = 1.5174e-01, time/batch = 17.5723s	
22151/33650 (epoch 32.914), train_loss = 0.88876570, grad/param norm = 1.4352e-01, time/batch = 16.2308s	
22152/33650 (epoch 32.915), train_loss = 0.83598743, grad/param norm = 1.5828e-01, time/batch = 17.0669s	
22153/33650 (epoch 32.917), train_loss = 0.81681207, grad/param norm = 1.4928e-01, time/batch = 17.2468s	
22154/33650 (epoch 32.918), train_loss = 0.77094888, grad/param norm = 1.4110e-01, time/batch = 16.3839s	
22155/33650 (epoch 32.920), train_loss = 0.78481384, grad/param norm = 1.5333e-01, time/batch = 15.9759s	
22156/33650 (epoch 32.921), train_loss = 0.78963242, grad/param norm = 1.5467e-01, time/batch = 15.9596s	
22157/33650 (epoch 32.923), train_loss = 0.69356361, grad/param norm = 1.4357e-01, time/batch = 17.1606s	
22158/33650 (epoch 32.924), train_loss = 0.90517877, grad/param norm = 1.7459e-01, time/batch = 17.2426s	
22159/33650 (epoch 32.926), train_loss = 0.81921535, grad/param norm = 1.8104e-01, time/batch = 17.4891s	
22160/33650 (epoch 32.927), train_loss = 0.85652388, grad/param norm = 1.6509e-01, time/batch = 16.1333s	
22161/33650 (epoch 32.929), train_loss = 0.93300728, grad/param norm = 1.6531e-01, time/batch = 17.9040s	
22162/33650 (epoch 32.930), train_loss = 0.84158713, grad/param norm = 1.7444e-01, time/batch = 17.0590s	
22163/33650 (epoch 32.932), train_loss = 0.83882674, grad/param norm = 1.4918e-01, time/batch = 17.9915s	
22164/33650 (epoch 32.933), train_loss = 0.72591263, grad/param norm = 1.4750e-01, time/batch = 17.2338s	
22165/33650 (epoch 32.935), train_loss = 0.73127929, grad/param norm = 1.9228e-01, time/batch = 16.4876s	
22166/33650 (epoch 32.936), train_loss = 0.79046869, grad/param norm = 1.4676e-01, time/batch = 17.8155s	
22167/33650 (epoch 32.938), train_loss = 0.74877308, grad/param norm = 1.4345e-01, time/batch = 17.2401s	
22168/33650 (epoch 32.939), train_loss = 0.94157861, grad/param norm = 1.5713e-01, time/batch = 17.6579s	
22169/33650 (epoch 32.941), train_loss = 0.85680601, grad/param norm = 1.5107e-01, time/batch = 16.8088s	
22170/33650 (epoch 32.942), train_loss = 0.93295983, grad/param norm = 1.8481e-01, time/batch = 16.3891s	
22171/33650 (epoch 32.944), train_loss = 0.80823797, grad/param norm = 1.4970e-01, time/batch = 18.0637s	
22172/33650 (epoch 32.945), train_loss = 0.86785958, grad/param norm = 1.5007e-01, time/batch = 16.3950s	
22173/33650 (epoch 32.947), train_loss = 0.98989652, grad/param norm = 2.2371e-01, time/batch = 16.9887s	
22174/33650 (epoch 32.948), train_loss = 0.98022838, grad/param norm = 1.6210e-01, time/batch = 17.5702s	
22175/33650 (epoch 32.949), train_loss = 0.74809230, grad/param norm = 1.4353e-01, time/batch = 18.3965s	
22176/33650 (epoch 32.951), train_loss = 0.98916530, grad/param norm = 1.5398e-01, time/batch = 16.1326s	
22177/33650 (epoch 32.952), train_loss = 0.89818895, grad/param norm = 1.6999e-01, time/batch = 18.1486s	
22178/33650 (epoch 32.954), train_loss = 0.91013760, grad/param norm = 1.7103e-01, time/batch = 17.5609s	
22179/33650 (epoch 32.955), train_loss = 0.88237198, grad/param norm = 1.5830e-01, time/batch = 15.8085s	
22180/33650 (epoch 32.957), train_loss = 0.92727689, grad/param norm = 1.7998e-01, time/batch = 17.2313s	
22181/33650 (epoch 32.958), train_loss = 0.68869636, grad/param norm = 1.3306e-01, time/batch = 17.6528s	
22182/33650 (epoch 32.960), train_loss = 0.69935476, grad/param norm = 1.4278e-01, time/batch = 15.9859s	
22183/33650 (epoch 32.961), train_loss = 0.76394650, grad/param norm = 1.6300e-01, time/batch = 16.2196s	
22184/33650 (epoch 32.963), train_loss = 0.77048665, grad/param norm = 1.5921e-01, time/batch = 17.7334s	
22185/33650 (epoch 32.964), train_loss = 0.94504673, grad/param norm = 1.6203e-01, time/batch = 17.7416s	
22186/33650 (epoch 32.966), train_loss = 0.87745560, grad/param norm = 1.9653e-01, time/batch = 22.3262s	
22187/33650 (epoch 32.967), train_loss = 0.90346970, grad/param norm = 1.6987e-01, time/batch = 25.5040s	
22188/33650 (epoch 32.969), train_loss = 0.86088822, grad/param norm = 1.4700e-01, time/batch = 15.9698s	
22189/33650 (epoch 32.970), train_loss = 0.86725460, grad/param norm = 1.5632e-01, time/batch = 15.5635s	
22190/33650 (epoch 32.972), train_loss = 1.14104614, grad/param norm = 2.0590e-01, time/batch = 17.3157s	
22191/33650 (epoch 32.973), train_loss = 0.78361372, grad/param norm = 1.3036e-01, time/batch = 17.8175s	
22192/33650 (epoch 32.975), train_loss = 0.75952790, grad/param norm = 1.4675e-01, time/batch = 17.6625s	
22193/33650 (epoch 32.976), train_loss = 0.79143724, grad/param norm = 1.3740e-01, time/batch = 16.5685s	
22194/33650 (epoch 32.978), train_loss = 0.78453550, grad/param norm = 1.4583e-01, time/batch = 17.2352s	
22195/33650 (epoch 32.979), train_loss = 0.85458266, grad/param norm = 1.9291e-01, time/batch = 18.0647s	
22196/33650 (epoch 32.981), train_loss = 0.82151012, grad/param norm = 1.3376e-01, time/batch = 16.3978s	
22197/33650 (epoch 32.982), train_loss = 0.86593798, grad/param norm = 1.6263e-01, time/batch = 15.9736s	
22198/33650 (epoch 32.984), train_loss = 0.70773631, grad/param norm = 1.5398e-01, time/batch = 17.4080s	
22199/33650 (epoch 32.985), train_loss = 0.76864396, grad/param norm = 1.5121e-01, time/batch = 17.2242s	
22200/33650 (epoch 32.987), train_loss = 0.85989409, grad/param norm = 1.5345e-01, time/batch = 17.3169s	
22201/33650 (epoch 32.988), train_loss = 0.81795747, grad/param norm = 1.6576e-01, time/batch = 15.8164s	
22202/33650 (epoch 32.990), train_loss = 1.00403876, grad/param norm = 1.7482e-01, time/batch = 17.2363s	
22203/33650 (epoch 32.991), train_loss = 0.87696788, grad/param norm = 1.6229e-01, time/batch = 16.5661s	
22204/33650 (epoch 32.993), train_loss = 0.86613605, grad/param norm = 1.5119e-01, time/batch = 18.0624s	
22205/33650 (epoch 32.994), train_loss = 0.87334832, grad/param norm = 1.5299e-01, time/batch = 16.0451s	
22206/33650 (epoch 32.996), train_loss = 0.82936493, grad/param norm = 1.8130e-01, time/batch = 17.2169s	
22207/33650 (epoch 32.997), train_loss = 0.92817585, grad/param norm = 1.7824e-01, time/batch = 16.7354s	
22208/33650 (epoch 32.999), train_loss = 0.77930220, grad/param norm = 1.5419e-01, time/batch = 18.0069s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
22209/33650 (epoch 33.000), train_loss = 0.95501354, grad/param norm = 2.0358e-01, time/batch = 17.0030s	
22210/33650 (epoch 33.001), train_loss = 0.98696119, grad/param norm = 1.6173e-01, time/batch = 15.9786s	
22211/33650 (epoch 33.003), train_loss = 0.99370534, grad/param norm = 1.9322e-01, time/batch = 17.1488s	
22212/33650 (epoch 33.004), train_loss = 0.89408237, grad/param norm = 1.8022e-01, time/batch = 17.0740s	
22213/33650 (epoch 33.006), train_loss = 0.83865299, grad/param norm = 1.5399e-01, time/batch = 16.9749s	
22214/33650 (epoch 33.007), train_loss = 0.90342672, grad/param norm = 1.9295e-01, time/batch = 17.1244s	
22215/33650 (epoch 33.009), train_loss = 0.79455796, grad/param norm = 1.5050e-01, time/batch = 18.3135s	
22216/33650 (epoch 33.010), train_loss = 0.97176952, grad/param norm = 1.7056e-01, time/batch = 17.0766s	
22217/33650 (epoch 33.012), train_loss = 0.82347133, grad/param norm = 1.6411e-01, time/batch = 16.3061s	
22218/33650 (epoch 33.013), train_loss = 0.88168427, grad/param norm = 2.3333e-01, time/batch = 16.6515s	
22219/33650 (epoch 33.015), train_loss = 0.84899701, grad/param norm = 1.7297e-01, time/batch = 18.0676s	
22220/33650 (epoch 33.016), train_loss = 0.81315127, grad/param norm = 1.9188e-01, time/batch = 16.9728s	
22221/33650 (epoch 33.018), train_loss = 0.85118426, grad/param norm = 1.8739e-01, time/batch = 16.0515s	
22222/33650 (epoch 33.019), train_loss = 0.82760382, grad/param norm = 1.7036e-01, time/batch = 16.9005s	
22223/33650 (epoch 33.021), train_loss = 0.91859948, grad/param norm = 1.6418e-01, time/batch = 16.9862s	
22224/33650 (epoch 33.022), train_loss = 0.83272918, grad/param norm = 1.5805e-01, time/batch = 15.7988s	
22225/33650 (epoch 33.024), train_loss = 0.76546748, grad/param norm = 1.5371e-01, time/batch = 16.8940s	
22226/33650 (epoch 33.025), train_loss = 0.87854445, grad/param norm = 1.5742e-01, time/batch = 17.1594s	
22227/33650 (epoch 33.027), train_loss = 0.89125022, grad/param norm = 1.8589e-01, time/batch = 16.2107s	
22228/33650 (epoch 33.028), train_loss = 0.92956914, grad/param norm = 1.6910e-01, time/batch = 16.8933s	
22229/33650 (epoch 33.030), train_loss = 0.86195920, grad/param norm = 1.8365e-01, time/batch = 18.1456s	
22230/33650 (epoch 33.031), train_loss = 0.78055929, grad/param norm = 1.3700e-01, time/batch = 16.8964s	
22231/33650 (epoch 33.033), train_loss = 0.88252274, grad/param norm = 1.4623e-01, time/batch = 16.5603s	
22232/33650 (epoch 33.034), train_loss = 0.89323896, grad/param norm = 1.5736e-01, time/batch = 17.4717s	
22233/33650 (epoch 33.036), train_loss = 0.97142223, grad/param norm = 1.6833e-01, time/batch = 17.3075s	
22234/33650 (epoch 33.037), train_loss = 0.80877899, grad/param norm = 1.4760e-01, time/batch = 15.5551s	
22235/33650 (epoch 33.039), train_loss = 0.94442897, grad/param norm = 1.6210e-01, time/batch = 16.6287s	
22236/33650 (epoch 33.040), train_loss = 1.02867405, grad/param norm = 2.0858e-01, time/batch = 17.0684s	
22237/33650 (epoch 33.042), train_loss = 1.05105979, grad/param norm = 2.0058e-01, time/batch = 17.2984s	
22238/33650 (epoch 33.043), train_loss = 0.83298835, grad/param norm = 1.6514e-01, time/batch = 16.3874s	
22239/33650 (epoch 33.045), train_loss = 0.81689306, grad/param norm = 1.6992e-01, time/batch = 17.0749s	
22240/33650 (epoch 33.046), train_loss = 0.92218151, grad/param norm = 1.6510e-01, time/batch = 17.6399s	
22241/33650 (epoch 33.048), train_loss = 0.94275923, grad/param norm = 1.6770e-01, time/batch = 17.4767s	
22242/33650 (epoch 33.049), train_loss = 0.83466754, grad/param norm = 1.6602e-01, time/batch = 16.9827s	
22243/33650 (epoch 33.051), train_loss = 1.01400303, grad/param norm = 1.7839e-01, time/batch = 16.8830s	
22244/33650 (epoch 33.052), train_loss = 0.99064935, grad/param norm = 1.7833e-01, time/batch = 16.9075s	
22245/33650 (epoch 33.053), train_loss = 0.95888914, grad/param norm = 1.7844e-01, time/batch = 17.3989s	
22246/33650 (epoch 33.055), train_loss = 0.81024514, grad/param norm = 1.5955e-01, time/batch = 17.2201s	
22247/33650 (epoch 33.056), train_loss = 0.76380664, grad/param norm = 1.2964e-01, time/batch = 17.1499s	
22248/33650 (epoch 33.058), train_loss = 0.92874935, grad/param norm = 1.7302e-01, time/batch = 17.6610s	
22249/33650 (epoch 33.059), train_loss = 0.94035247, grad/param norm = 1.7235e-01, time/batch = 16.9774s	
22250/33650 (epoch 33.061), train_loss = 0.97649127, grad/param norm = 1.8384e-01, time/batch = 17.2335s	
22251/33650 (epoch 33.062), train_loss = 0.91401610, grad/param norm = 1.6074e-01, time/batch = 17.5739s	
22252/33650 (epoch 33.064), train_loss = 0.86902424, grad/param norm = 1.8510e-01, time/batch = 16.3168s	
22253/33650 (epoch 33.065), train_loss = 0.83376287, grad/param norm = 1.5734e-01, time/batch = 18.0715s	
22254/33650 (epoch 33.067), train_loss = 0.78736115, grad/param norm = 1.3798e-01, time/batch = 17.3942s	
22255/33650 (epoch 33.068), train_loss = 0.87690666, grad/param norm = 1.5247e-01, time/batch = 17.4026s	
22256/33650 (epoch 33.070), train_loss = 0.92906400, grad/param norm = 1.7046e-01, time/batch = 16.3128s	
22257/33650 (epoch 33.071), train_loss = 0.82585967, grad/param norm = 1.6043e-01, time/batch = 14.9576s	
22258/33650 (epoch 33.073), train_loss = 0.91264445, grad/param norm = 1.7116e-01, time/batch = 17.2445s	
22259/33650 (epoch 33.074), train_loss = 0.99330558, grad/param norm = 1.6425e-01, time/batch = 17.4784s	
22260/33650 (epoch 33.076), train_loss = 0.95576316, grad/param norm = 1.9139e-01, time/batch = 16.9041s	
22261/33650 (epoch 33.077), train_loss = 0.86165186, grad/param norm = 1.5150e-01, time/batch = 17.3159s	
22262/33650 (epoch 33.079), train_loss = 0.92747828, grad/param norm = 1.5155e-01, time/batch = 17.8974s	
22263/33650 (epoch 33.080), train_loss = 0.92616667, grad/param norm = 1.6141e-01, time/batch = 17.5578s	
22264/33650 (epoch 33.082), train_loss = 0.88389944, grad/param norm = 1.6290e-01, time/batch = 17.9012s	
22265/33650 (epoch 33.083), train_loss = 0.90063968, grad/param norm = 1.7551e-01, time/batch = 16.4841s	
22266/33650 (epoch 33.085), train_loss = 0.96580181, grad/param norm = 1.5972e-01, time/batch = 15.7251s	
22267/33650 (epoch 33.086), train_loss = 0.92410482, grad/param norm = 1.6533e-01, time/batch = 17.4732s	
22268/33650 (epoch 33.088), train_loss = 0.87666764, grad/param norm = 1.6232e-01, time/batch = 17.8227s	
22269/33650 (epoch 33.089), train_loss = 0.82594071, grad/param norm = 1.6837e-01, time/batch = 17.0643s	
22270/33650 (epoch 33.091), train_loss = 0.86810089, grad/param norm = 1.6445e-01, time/batch = 16.8152s	
22271/33650 (epoch 33.092), train_loss = 0.87504724, grad/param norm = 1.8165e-01, time/batch = 17.1609s	
22272/33650 (epoch 33.094), train_loss = 0.95173700, grad/param norm = 1.5053e-01, time/batch = 17.8140s	
22273/33650 (epoch 33.095), train_loss = 0.92641274, grad/param norm = 1.7935e-01, time/batch = 16.5581s	
22274/33650 (epoch 33.097), train_loss = 0.81726166, grad/param norm = 1.6596e-01, time/batch = 16.4916s	
22275/33650 (epoch 33.098), train_loss = 0.71250018, grad/param norm = 1.4950e-01, time/batch = 14.0631s	
22276/33650 (epoch 33.100), train_loss = 0.78985721, grad/param norm = 1.5053e-01, time/batch = 13.9756s	
22277/33650 (epoch 33.101), train_loss = 0.88671063, grad/param norm = 1.8748e-01, time/batch = 14.5387s	
22278/33650 (epoch 33.103), train_loss = 0.85856857, grad/param norm = 1.7589e-01, time/batch = 17.1356s	
22279/33650 (epoch 33.104), train_loss = 0.99745986, grad/param norm = 1.5016e-01, time/batch = 18.1599s	
22280/33650 (epoch 33.105), train_loss = 0.91282445, grad/param norm = 1.8214e-01, time/batch = 17.1491s	
22281/33650 (epoch 33.107), train_loss = 0.83600842, grad/param norm = 1.6832e-01, time/batch = 15.8615s	
22282/33650 (epoch 33.108), train_loss = 0.91954700, grad/param norm = 1.7805e-01, time/batch = 18.0588s	
22283/33650 (epoch 33.110), train_loss = 1.01357210, grad/param norm = 1.7235e-01, time/batch = 17.7329s	
22284/33650 (epoch 33.111), train_loss = 0.87057549, grad/param norm = 1.7223e-01, time/batch = 15.9758s	
22285/33650 (epoch 33.113), train_loss = 0.82322097, grad/param norm = 1.5908e-01, time/batch = 17.6487s	
22286/33650 (epoch 33.114), train_loss = 0.93828624, grad/param norm = 1.4756e-01, time/batch = 17.9032s	
22287/33650 (epoch 33.116), train_loss = 0.80544001, grad/param norm = 1.2971e-01, time/batch = 15.4010s	
22288/33650 (epoch 33.117), train_loss = 0.85504255, grad/param norm = 1.4423e-01, time/batch = 16.7407s	
22289/33650 (epoch 33.119), train_loss = 0.79415538, grad/param norm = 1.3465e-01, time/batch = 17.4843s	
22290/33650 (epoch 33.120), train_loss = 0.81707714, grad/param norm = 1.7298e-01, time/batch = 17.4891s	
22291/33650 (epoch 33.122), train_loss = 0.66891526, grad/param norm = 1.4271e-01, time/batch = 15.3063s	
22292/33650 (epoch 33.123), train_loss = 0.82808506, grad/param norm = 1.4535e-01, time/batch = 17.0723s	
22293/33650 (epoch 33.125), train_loss = 0.91338004, grad/param norm = 1.5613e-01, time/batch = 18.1461s	
22294/33650 (epoch 33.126), train_loss = 0.95037538, grad/param norm = 1.8077e-01, time/batch = 17.0725s	
22295/33650 (epoch 33.128), train_loss = 0.92822192, grad/param norm = 1.7410e-01, time/batch = 16.7268s	
22296/33650 (epoch 33.129), train_loss = 0.94977818, grad/param norm = 1.6634e-01, time/batch = 17.0446s	
22297/33650 (epoch 33.131), train_loss = 0.88670344, grad/param norm = 1.5992e-01, time/batch = 17.5613s	
22298/33650 (epoch 33.132), train_loss = 0.89261798, grad/param norm = 1.6044e-01, time/batch = 16.2293s	
22299/33650 (epoch 33.134), train_loss = 0.94342251, grad/param norm = 1.7845e-01, time/batch = 16.9033s	
22300/33650 (epoch 33.135), train_loss = 0.76514873, grad/param norm = 1.4395e-01, time/batch = 16.6511s	
22301/33650 (epoch 33.137), train_loss = 0.92743464, grad/param norm = 2.1313e-01, time/batch = 13.6493s	
22302/33650 (epoch 33.138), train_loss = 0.94867628, grad/param norm = 1.6664e-01, time/batch = 13.7462s	
22303/33650 (epoch 33.140), train_loss = 0.89609936, grad/param norm = 1.9411e-01, time/batch = 23.0274s	
22304/33650 (epoch 33.141), train_loss = 1.00608550, grad/param norm = 1.7167e-01, time/batch = 37.0881s	
22305/33650 (epoch 33.143), train_loss = 1.04364705, grad/param norm = 1.9188e-01, time/batch = 30.6711s	
22306/33650 (epoch 33.144), train_loss = 0.91911830, grad/param norm = 1.8158e-01, time/batch = 34.6649s	
22307/33650 (epoch 33.146), train_loss = 0.86448564, grad/param norm = 1.5316e-01, time/batch = 38.6613s	
22308/33650 (epoch 33.147), train_loss = 0.80947429, grad/param norm = 1.5844e-01, time/batch = 35.8591s	
22309/33650 (epoch 33.149), train_loss = 0.77630822, grad/param norm = 1.5657e-01, time/batch = 36.4698s	
22310/33650 (epoch 33.150), train_loss = 0.75530069, grad/param norm = 1.3699e-01, time/batch = 37.2816s	
22311/33650 (epoch 33.152), train_loss = 0.84268627, grad/param norm = 1.7889e-01, time/batch = 38.6026s	
22312/33650 (epoch 33.153), train_loss = 0.83424793, grad/param norm = 1.6067e-01, time/batch = 36.7946s	
22313/33650 (epoch 33.155), train_loss = 0.80510140, grad/param norm = 1.4532e-01, time/batch = 36.9467s	
22314/33650 (epoch 33.156), train_loss = 0.79589850, grad/param norm = 1.3014e-01, time/batch = 35.1122s	
22315/33650 (epoch 33.158), train_loss = 0.92433013, grad/param norm = 1.7311e-01, time/batch = 35.1098s	
22316/33650 (epoch 33.159), train_loss = 0.81821464, grad/param norm = 1.4097e-01, time/batch = 34.6352s	
22317/33650 (epoch 33.160), train_loss = 0.80866208, grad/param norm = 1.4700e-01, time/batch = 36.9659s	
22318/33650 (epoch 33.162), train_loss = 0.83386208, grad/param norm = 1.7039e-01, time/batch = 36.8414s	
22319/33650 (epoch 33.163), train_loss = 0.90970419, grad/param norm = 1.6118e-01, time/batch = 35.6949s	
22320/33650 (epoch 33.165), train_loss = 0.77272440, grad/param norm = 1.5526e-01, time/batch = 36.4585s	
22321/33650 (epoch 33.166), train_loss = 0.77732558, grad/param norm = 1.5835e-01, time/batch = 34.7932s	
22322/33650 (epoch 33.168), train_loss = 0.96979200, grad/param norm = 1.7386e-01, time/batch = 36.4423s	
22323/33650 (epoch 33.169), train_loss = 0.86830412, grad/param norm = 1.5733e-01, time/batch = 35.9635s	
22324/33650 (epoch 33.171), train_loss = 0.85703831, grad/param norm = 1.4389e-01, time/batch = 34.2818s	
22325/33650 (epoch 33.172), train_loss = 0.82145834, grad/param norm = 1.4293e-01, time/batch = 35.8084s	
22326/33650 (epoch 33.174), train_loss = 0.79062746, grad/param norm = 1.6460e-01, time/batch = 37.2045s	
22327/33650 (epoch 33.175), train_loss = 0.74745349, grad/param norm = 1.6752e-01, time/batch = 28.5242s	
22328/33650 (epoch 33.177), train_loss = 0.84867182, grad/param norm = 1.5682e-01, time/batch = 28.0066s	
22329/33650 (epoch 33.178), train_loss = 0.82663979, grad/param norm = 1.8820e-01, time/batch = 28.8253s	
22330/33650 (epoch 33.180), train_loss = 0.77493906, grad/param norm = 1.3888e-01, time/batch = 31.0382s	
22331/33650 (epoch 33.181), train_loss = 0.69661594, grad/param norm = 1.4297e-01, time/batch = 26.4430s	
22332/33650 (epoch 33.183), train_loss = 0.80175319, grad/param norm = 1.6985e-01, time/batch = 29.1500s	
22333/33650 (epoch 33.184), train_loss = 0.80628418, grad/param norm = 2.0024e-01, time/batch = 34.3951s	
22334/33650 (epoch 33.186), train_loss = 0.82665077, grad/param norm = 1.7109e-01, time/batch = 30.2319s	
22335/33650 (epoch 33.187), train_loss = 0.97695021, grad/param norm = 1.7555e-01, time/batch = 35.8716s	
22336/33650 (epoch 33.189), train_loss = 0.95695721, grad/param norm = 1.8376e-01, time/batch = 31.8432s	
22337/33650 (epoch 33.190), train_loss = 0.88326144, grad/param norm = 1.8679e-01, time/batch = 32.9596s	
22338/33650 (epoch 33.192), train_loss = 1.03161265, grad/param norm = 1.5642e-01, time/batch = 36.8313s	
22339/33650 (epoch 33.193), train_loss = 0.99866192, grad/param norm = 1.5619e-01, time/batch = 27.0222s	
22340/33650 (epoch 33.195), train_loss = 0.77022086, grad/param norm = 1.5725e-01, time/batch = 32.9693s	
22341/33650 (epoch 33.196), train_loss = 0.71819921, grad/param norm = 1.5990e-01, time/batch = 34.5262s	
22342/33650 (epoch 33.198), train_loss = 0.85234207, grad/param norm = 1.6429e-01, time/batch = 38.9498s	
22343/33650 (epoch 33.199), train_loss = 0.93222520, grad/param norm = 1.8025e-01, time/batch = 37.6657s	
22344/33650 (epoch 33.201), train_loss = 0.82977328, grad/param norm = 1.8039e-01, time/batch = 36.8721s	
22345/33650 (epoch 33.202), train_loss = 0.85103558, grad/param norm = 1.5795e-01, time/batch = 26.0614s	
22346/33650 (epoch 33.204), train_loss = 0.89852050, grad/param norm = 1.5047e-01, time/batch = 17.5401s	
22347/33650 (epoch 33.205), train_loss = 0.85626253, grad/param norm = 1.6304e-01, time/batch = 16.8979s	
22348/33650 (epoch 33.207), train_loss = 0.79988155, grad/param norm = 1.8491e-01, time/batch = 16.9952s	
22349/33650 (epoch 33.208), train_loss = 0.88734635, grad/param norm = 1.5962e-01, time/batch = 17.5701s	
22350/33650 (epoch 33.210), train_loss = 0.72217327, grad/param norm = 1.6048e-01, time/batch = 15.1374s	
22351/33650 (epoch 33.211), train_loss = 0.81449592, grad/param norm = 1.8118e-01, time/batch = 16.4578s	
22352/33650 (epoch 33.212), train_loss = 0.89291826, grad/param norm = 1.6364e-01, time/batch = 17.6426s	
22353/33650 (epoch 33.214), train_loss = 1.04068925, grad/param norm = 1.8511e-01, time/batch = 17.7292s	
22354/33650 (epoch 33.215), train_loss = 0.68272022, grad/param norm = 1.6178e-01, time/batch = 21.4025s	
22355/33650 (epoch 33.217), train_loss = 0.84096740, grad/param norm = 1.8660e-01, time/batch = 27.3324s	
22356/33650 (epoch 33.218), train_loss = 0.85735884, grad/param norm = 1.6463e-01, time/batch = 17.3226s	
22357/33650 (epoch 33.220), train_loss = 0.74011530, grad/param norm = 1.5785e-01, time/batch = 17.2157s	
22358/33650 (epoch 33.221), train_loss = 1.01539218, grad/param norm = 1.9396e-01, time/batch = 17.9044s	
22359/33650 (epoch 33.223), train_loss = 0.70255573, grad/param norm = 1.5726e-01, time/batch = 17.9834s	
22360/33650 (epoch 33.224), train_loss = 0.82137395, grad/param norm = 1.7817e-01, time/batch = 15.7853s	
22361/33650 (epoch 33.226), train_loss = 1.11450902, grad/param norm = 1.6906e-01, time/batch = 17.6514s	
22362/33650 (epoch 33.227), train_loss = 0.96618649, grad/param norm = 2.0737e-01, time/batch = 13.7797s	
22363/33650 (epoch 33.229), train_loss = 0.97658105, grad/param norm = 1.9873e-01, time/batch = 13.4153s	
22364/33650 (epoch 33.230), train_loss = 1.08466074, grad/param norm = 1.9528e-01, time/batch = 13.8482s	
22365/33650 (epoch 33.232), train_loss = 0.95242822, grad/param norm = 2.6271e-01, time/batch = 17.4093s	
22366/33650 (epoch 33.233), train_loss = 0.93710244, grad/param norm = 2.3963e-01, time/batch = 17.4054s	
22367/33650 (epoch 33.235), train_loss = 0.85997634, grad/param norm = 1.5579e-01, time/batch = 17.3940s	
22368/33650 (epoch 33.236), train_loss = 0.81620966, grad/param norm = 1.5432e-01, time/batch = 17.2216s	
22369/33650 (epoch 33.238), train_loss = 0.83791595, grad/param norm = 1.5593e-01, time/batch = 17.7352s	
22370/33650 (epoch 33.239), train_loss = 0.78663819, grad/param norm = 1.6239e-01, time/batch = 18.1552s	
22371/33650 (epoch 33.241), train_loss = 0.84582171, grad/param norm = 1.4869e-01, time/batch = 16.3913s	
22372/33650 (epoch 33.242), train_loss = 0.70579907, grad/param norm = 1.8531e-01, time/batch = 17.4958s	
22373/33650 (epoch 33.244), train_loss = 0.84435662, grad/param norm = 1.6090e-01, time/batch = 17.4030s	
22374/33650 (epoch 33.245), train_loss = 0.74998706, grad/param norm = 1.3895e-01, time/batch = 17.0626s	
22375/33650 (epoch 33.247), train_loss = 0.83319378, grad/param norm = 1.6084e-01, time/batch = 16.5717s	
22376/33650 (epoch 33.248), train_loss = 0.77542267, grad/param norm = 1.7041e-01, time/batch = 18.1599s	
22377/33650 (epoch 33.250), train_loss = 0.85971625, grad/param norm = 1.5234e-01, time/batch = 18.2457s	
22378/33650 (epoch 33.251), train_loss = 0.97131703, grad/param norm = 1.6135e-01, time/batch = 16.5598s	
22379/33650 (epoch 33.253), train_loss = 0.76183391, grad/param norm = 1.5822e-01, time/batch = 17.4124s	
22380/33650 (epoch 33.254), train_loss = 0.84262028, grad/param norm = 1.6916e-01, time/batch = 16.9796s	
22381/33650 (epoch 33.256), train_loss = 0.98000882, grad/param norm = 1.4706e-01, time/batch = 16.3824s	
22382/33650 (epoch 33.257), train_loss = 0.95896509, grad/param norm = 1.6690e-01, time/batch = 16.2922s	
22383/33650 (epoch 33.259), train_loss = 0.78356200, grad/param norm = 1.4982e-01, time/batch = 17.8135s	
22384/33650 (epoch 33.260), train_loss = 0.90941670, grad/param norm = 1.6038e-01, time/batch = 17.3163s	
22385/33650 (epoch 33.262), train_loss = 0.88874727, grad/param norm = 1.9128e-01, time/batch = 16.8130s	
22386/33650 (epoch 33.263), train_loss = 0.86057599, grad/param norm = 2.3174e-01, time/batch = 16.1503s	
22387/33650 (epoch 33.264), train_loss = 0.92432503, grad/param norm = 1.8373e-01, time/batch = 16.8240s	
22388/33650 (epoch 33.266), train_loss = 0.91266504, grad/param norm = 1.6418e-01, time/batch = 16.8138s	
22389/33650 (epoch 33.267), train_loss = 0.82367023, grad/param norm = 1.5806e-01, time/batch = 16.4908s	
22390/33650 (epoch 33.269), train_loss = 0.87575738, grad/param norm = 1.5800e-01, time/batch = 17.1574s	
22391/33650 (epoch 33.270), train_loss = 0.78338590, grad/param norm = 1.5813e-01, time/batch = 17.4008s	
22392/33650 (epoch 33.272), train_loss = 0.81549289, grad/param norm = 1.5007e-01, time/batch = 16.8108s	
22393/33650 (epoch 33.273), train_loss = 0.95199902, grad/param norm = 2.0756e-01, time/batch = 18.2406s	
22394/33650 (epoch 33.275), train_loss = 0.90918402, grad/param norm = 1.6866e-01, time/batch = 16.8291s	
22395/33650 (epoch 33.276), train_loss = 0.93604005, grad/param norm = 1.8088e-01, time/batch = 16.8045s	
22396/33650 (epoch 33.278), train_loss = 1.03454515, grad/param norm = 1.7676e-01, time/batch = 17.3128s	
22397/33650 (epoch 33.279), train_loss = 0.85549443, grad/param norm = 1.9764e-01, time/batch = 17.3978s	
22398/33650 (epoch 33.281), train_loss = 0.90197755, grad/param norm = 2.0029e-01, time/batch = 16.7438s	
22399/33650 (epoch 33.282), train_loss = 0.97531765, grad/param norm = 1.3585e-01, time/batch = 15.4632s	
22400/33650 (epoch 33.284), train_loss = 0.93177940, grad/param norm = 1.7502e-01, time/batch = 16.9868s	
22401/33650 (epoch 33.285), train_loss = 0.90433469, grad/param norm = 1.6882e-01, time/batch = 17.6415s	
22402/33650 (epoch 33.287), train_loss = 0.83856718, grad/param norm = 2.0366e-01, time/batch = 16.8126s	
22403/33650 (epoch 33.288), train_loss = 0.84937789, grad/param norm = 1.6614e-01, time/batch = 16.8040s	
22404/33650 (epoch 33.290), train_loss = 0.86167349, grad/param norm = 1.5050e-01, time/batch = 18.0659s	
22405/33650 (epoch 33.291), train_loss = 0.79515122, grad/param norm = 1.5738e-01, time/batch = 17.6643s	
22406/33650 (epoch 33.293), train_loss = 0.87146681, grad/param norm = 1.7375e-01, time/batch = 16.0551s	
22407/33650 (epoch 33.294), train_loss = 0.78857718, grad/param norm = 1.3662e-01, time/batch = 17.8210s	
22408/33650 (epoch 33.296), train_loss = 0.77379483, grad/param norm = 1.8178e-01, time/batch = 14.7436s	
22409/33650 (epoch 33.297), train_loss = 0.83703477, grad/param norm = 1.6777e-01, time/batch = 16.7886s	
22410/33650 (epoch 33.299), train_loss = 0.74026103, grad/param norm = 1.5754e-01, time/batch = 16.3919s	
22411/33650 (epoch 33.300), train_loss = 0.78614634, grad/param norm = 1.5579e-01, time/batch = 17.3902s	
22412/33650 (epoch 33.302), train_loss = 0.89075398, grad/param norm = 1.5231e-01, time/batch = 18.0431s	
22413/33650 (epoch 33.303), train_loss = 0.90073243, grad/param norm = 1.6076e-01, time/batch = 15.6311s	
22414/33650 (epoch 33.305), train_loss = 0.85667390, grad/param norm = 1.4636e-01, time/batch = 17.2423s	
22415/33650 (epoch 33.306), train_loss = 0.78363412, grad/param norm = 1.4196e-01, time/batch = 16.0749s	
22416/33650 (epoch 33.308), train_loss = 0.77480282, grad/param norm = 1.7658e-01, time/batch = 17.5689s	
22417/33650 (epoch 33.309), train_loss = 0.99242224, grad/param norm = 1.8505e-01, time/batch = 17.1536s	
22418/33650 (epoch 33.311), train_loss = 0.87357288, grad/param norm = 1.9179e-01, time/batch = 17.1477s	
22419/33650 (epoch 33.312), train_loss = 0.90815032, grad/param norm = 1.7612e-01, time/batch = 17.3242s	
22420/33650 (epoch 33.314), train_loss = 0.79544556, grad/param norm = 1.5367e-01, time/batch = 16.4729s	
22421/33650 (epoch 33.315), train_loss = 0.85200951, grad/param norm = 1.9674e-01, time/batch = 17.6419s	
22422/33650 (epoch 33.316), train_loss = 0.83750651, grad/param norm = 2.0057e-01, time/batch = 17.4145s	
22423/33650 (epoch 33.318), train_loss = 0.76614222, grad/param norm = 1.4794e-01, time/batch = 17.0621s	
22424/33650 (epoch 33.319), train_loss = 0.79447759, grad/param norm = 1.4996e-01, time/batch = 17.2278s	
22425/33650 (epoch 33.321), train_loss = 0.82019251, grad/param norm = 1.7538e-01, time/batch = 16.5744s	
22426/33650 (epoch 33.322), train_loss = 0.88455390, grad/param norm = 2.0033e-01, time/batch = 17.6472s	
22427/33650 (epoch 33.324), train_loss = 0.91800089, grad/param norm = 1.9054e-01, time/batch = 15.8948s	
22428/33650 (epoch 33.325), train_loss = 0.89673691, grad/param norm = 1.7110e-01, time/batch = 17.4073s	
22429/33650 (epoch 33.327), train_loss = 0.80631361, grad/param norm = 1.4205e-01, time/batch = 15.3834s	
22430/33650 (epoch 33.328), train_loss = 0.86846635, grad/param norm = 1.5853e-01, time/batch = 17.3284s	
22431/33650 (epoch 33.330), train_loss = 0.79187586, grad/param norm = 1.3725e-01, time/batch = 17.8927s	
22432/33650 (epoch 33.331), train_loss = 0.74574353, grad/param norm = 1.3626e-01, time/batch = 17.5666s	
22433/33650 (epoch 33.333), train_loss = 0.82887363, grad/param norm = 1.6747e-01, time/batch = 15.9601s	
22434/33650 (epoch 33.334), train_loss = 0.86481439, grad/param norm = 1.5750e-01, time/batch = 16.6326s	
22435/33650 (epoch 33.336), train_loss = 0.94971992, grad/param norm = 1.5455e-01, time/batch = 16.8949s	
22436/33650 (epoch 33.337), train_loss = 0.72964267, grad/param norm = 1.4268e-01, time/batch = 17.6480s	
22437/33650 (epoch 33.339), train_loss = 0.82278216, grad/param norm = 1.7731e-01, time/batch = 16.6489s	
22438/33650 (epoch 33.340), train_loss = 0.96591680, grad/param norm = 1.9668e-01, time/batch = 16.7218s	
22439/33650 (epoch 33.342), train_loss = 0.69815773, grad/param norm = 1.5095e-01, time/batch = 17.4023s	
22440/33650 (epoch 33.343), train_loss = 0.90462635, grad/param norm = 1.6351e-01, time/batch = 17.9869s	
22441/33650 (epoch 33.345), train_loss = 0.88216471, grad/param norm = 1.7826e-01, time/batch = 16.3013s	
22442/33650 (epoch 33.346), train_loss = 0.59651820, grad/param norm = 1.3261e-01, time/batch = 17.1452s	
22443/33650 (epoch 33.348), train_loss = 0.72681766, grad/param norm = 1.3928e-01, time/batch = 16.3089s	
22444/33650 (epoch 33.349), train_loss = 0.70698230, grad/param norm = 1.6468e-01, time/batch = 17.0594s	
22445/33650 (epoch 33.351), train_loss = 0.89535925, grad/param norm = 1.6618e-01, time/batch = 17.2087s	
22446/33650 (epoch 33.352), train_loss = 0.83637017, grad/param norm = 1.6835e-01, time/batch = 18.2347s	
22447/33650 (epoch 33.354), train_loss = 0.98835491, grad/param norm = 2.0343e-01, time/batch = 17.4984s	
22448/33650 (epoch 33.355), train_loss = 0.99732132, grad/param norm = 1.5603e-01, time/batch = 16.3149s	
22449/33650 (epoch 33.357), train_loss = 0.71291838, grad/param norm = 1.7483e-01, time/batch = 17.3076s	
22450/33650 (epoch 33.358), train_loss = 0.88415471, grad/param norm = 1.6243e-01, time/batch = 16.2984s	
22451/33650 (epoch 33.360), train_loss = 0.91449944, grad/param norm = 1.9698e-01, time/batch = 16.2226s	
22452/33650 (epoch 33.361), train_loss = 0.88293925, grad/param norm = 1.7128e-01, time/batch = 17.1374s	
22453/33650 (epoch 33.363), train_loss = 0.87467377, grad/param norm = 1.6037e-01, time/batch = 17.8147s	
22454/33650 (epoch 33.364), train_loss = 0.86048511, grad/param norm = 1.6544e-01, time/batch = 17.7422s	
22455/33650 (epoch 33.366), train_loss = 0.90217458, grad/param norm = 2.0558e-01, time/batch = 16.8081s	
22456/33650 (epoch 33.367), train_loss = 0.89031640, grad/param norm = 1.5555e-01, time/batch = 16.7246s	
22457/33650 (epoch 33.368), train_loss = 0.81245865, grad/param norm = 1.5631e-01, time/batch = 17.9020s	
22458/33650 (epoch 33.370), train_loss = 0.83643105, grad/param norm = 1.5119e-01, time/batch = 16.9075s	
22459/33650 (epoch 33.371), train_loss = 0.66606284, grad/param norm = 1.3966e-01, time/batch = 16.3845s	
22460/33650 (epoch 33.373), train_loss = 0.75011454, grad/param norm = 1.5382e-01, time/batch = 16.8157s	
22461/33650 (epoch 33.374), train_loss = 0.78205471, grad/param norm = 1.4068e-01, time/batch = 16.6460s	
22462/33650 (epoch 33.376), train_loss = 0.85556955, grad/param norm = 1.9969e-01, time/batch = 16.3024s	
22463/33650 (epoch 33.377), train_loss = 0.87561228, grad/param norm = 1.5905e-01, time/batch = 17.2347s	
22464/33650 (epoch 33.379), train_loss = 0.87935906, grad/param norm = 1.5637e-01, time/batch = 16.8266s	
22465/33650 (epoch 33.380), train_loss = 0.71104335, grad/param norm = 1.7350e-01, time/batch = 14.7254s	
22466/33650 (epoch 33.382), train_loss = 0.87529805, grad/param norm = 1.3875e-01, time/batch = 14.8866s	
22467/33650 (epoch 33.383), train_loss = 0.84771425, grad/param norm = 1.6193e-01, time/batch = 16.6289s	
22468/33650 (epoch 33.385), train_loss = 0.89742809, grad/param norm = 1.5713e-01, time/batch = 16.8103s	
22469/33650 (epoch 33.386), train_loss = 0.79658742, grad/param norm = 1.5993e-01, time/batch = 17.5726s	
22470/33650 (epoch 33.388), train_loss = 0.92330050, grad/param norm = 1.5353e-01, time/batch = 16.9793s	
22471/33650 (epoch 33.389), train_loss = 0.78983879, grad/param norm = 1.5499e-01, time/batch = 17.8171s	
22472/33650 (epoch 33.391), train_loss = 0.68774181, grad/param norm = 1.3623e-01, time/batch = 13.8099s	
22473/33650 (epoch 33.392), train_loss = 0.86555903, grad/param norm = 1.5165e-01, time/batch = 13.7513s	
22474/33650 (epoch 33.394), train_loss = 0.86242898, grad/param norm = 1.6299e-01, time/batch = 14.8867s	
22475/33650 (epoch 33.395), train_loss = 0.88208006, grad/param norm = 1.5152e-01, time/batch = 16.8138s	
22476/33650 (epoch 33.397), train_loss = 1.02443850, grad/param norm = 1.8333e-01, time/batch = 17.7237s	
22477/33650 (epoch 33.398), train_loss = 0.92731904, grad/param norm = 1.5000e-01, time/batch = 16.3856s	
22478/33650 (epoch 33.400), train_loss = 0.85832263, grad/param norm = 2.4041e-01, time/batch = 17.3282s	
22479/33650 (epoch 33.401), train_loss = 0.78879875, grad/param norm = 1.6157e-01, time/batch = 18.1554s	
22480/33650 (epoch 33.403), train_loss = 0.90034301, grad/param norm = 1.7983e-01, time/batch = 16.4019s	
22481/33650 (epoch 33.404), train_loss = 0.85362395, grad/param norm = 1.6171e-01, time/batch = 16.8874s	
22482/33650 (epoch 33.406), train_loss = 0.83359111, grad/param norm = 1.4750e-01, time/batch = 17.8809s	
22483/33650 (epoch 33.407), train_loss = 0.87341161, grad/param norm = 1.9062e-01, time/batch = 18.4019s	
22484/33650 (epoch 33.409), train_loss = 0.88755538, grad/param norm = 1.6230e-01, time/batch = 16.2284s	
22485/33650 (epoch 33.410), train_loss = 0.84910194, grad/param norm = 1.5924e-01, time/batch = 17.3313s	
22486/33650 (epoch 33.412), train_loss = 0.85978401, grad/param norm = 1.4856e-01, time/batch = 17.1467s	
22487/33650 (epoch 33.413), train_loss = 0.80031900, grad/param norm = 1.5287e-01, time/batch = 15.8902s	
22488/33650 (epoch 33.415), train_loss = 0.93709564, grad/param norm = 1.7302e-01, time/batch = 16.8127s	
22489/33650 (epoch 33.416), train_loss = 1.01441056, grad/param norm = 1.6813e-01, time/batch = 17.4065s	
22490/33650 (epoch 33.418), train_loss = 0.77008088, grad/param norm = 1.5613e-01, time/batch = 18.1536s	
22491/33650 (epoch 33.419), train_loss = 0.80957899, grad/param norm = 1.5363e-01, time/batch = 15.6209s	
22492/33650 (epoch 33.421), train_loss = 0.83280889, grad/param norm = 1.4406e-01, time/batch = 18.2290s	
22493/33650 (epoch 33.422), train_loss = 0.99133628, grad/param norm = 1.7828e-01, time/batch = 15.6374s	
22494/33650 (epoch 33.423), train_loss = 0.77620289, grad/param norm = 1.2426e-01, time/batch = 16.8906s	
22495/33650 (epoch 33.425), train_loss = 0.89506231, grad/param norm = 2.9031e-01, time/batch = 16.1287s	
22496/33650 (epoch 33.426), train_loss = 0.92499818, grad/param norm = 1.8414e-01, time/batch = 16.9013s	
22497/33650 (epoch 33.428), train_loss = 0.82298307, grad/param norm = 1.5092e-01, time/batch = 17.9856s	
22498/33650 (epoch 33.429), train_loss = 0.90568713, grad/param norm = 1.9375e-01, time/batch = 16.5642s	
22499/33650 (epoch 33.431), train_loss = 1.00707036, grad/param norm = 2.1532e-01, time/batch = 17.1609s	
22500/33650 (epoch 33.432), train_loss = 1.00612020, grad/param norm = 2.0215e-01, time/batch = 17.9035s	
22501/33650 (epoch 33.434), train_loss = 0.90207847, grad/param norm = 1.6586e-01, time/batch = 17.8185s	
22502/33650 (epoch 33.435), train_loss = 0.88958561, grad/param norm = 1.8907e-01, time/batch = 16.5546s	
22503/33650 (epoch 33.437), train_loss = 0.87289025, grad/param norm = 1.7346e-01, time/batch = 16.9084s	
22504/33650 (epoch 33.438), train_loss = 0.85036332, grad/param norm = 1.5634e-01, time/batch = 17.7325s	
22505/33650 (epoch 33.440), train_loss = 0.87272907, grad/param norm = 1.8816e-01, time/batch = 16.6469s	
22506/33650 (epoch 33.441), train_loss = 0.84307912, grad/param norm = 1.6181e-01, time/batch = 17.8260s	
22507/33650 (epoch 33.443), train_loss = 0.94960774, grad/param norm = 1.7683e-01, time/batch = 16.7506s	
22508/33650 (epoch 33.444), train_loss = 0.84683319, grad/param norm = 1.8444e-01, time/batch = 16.3048s	
22509/33650 (epoch 33.446), train_loss = 0.90702999, grad/param norm = 1.8500e-01, time/batch = 16.3111s	
22510/33650 (epoch 33.447), train_loss = 0.97718416, grad/param norm = 1.7607e-01, time/batch = 17.0792s	
22511/33650 (epoch 33.449), train_loss = 0.98121913, grad/param norm = 2.0039e-01, time/batch = 17.5751s	
22512/33650 (epoch 33.450), train_loss = 1.02903704, grad/param norm = 1.8255e-01, time/batch = 15.2378s	
22513/33650 (epoch 33.452), train_loss = 1.00223561, grad/param norm = 2.1053e-01, time/batch = 17.9782s	
22514/33650 (epoch 33.453), train_loss = 1.00974248, grad/param norm = 1.9236e-01, time/batch = 17.9884s	
22515/33650 (epoch 33.455), train_loss = 0.86273792, grad/param norm = 1.5936e-01, time/batch = 16.8949s	
22516/33650 (epoch 33.456), train_loss = 0.86422222, grad/param norm = 1.7588e-01, time/batch = 17.4850s	
22517/33650 (epoch 33.458), train_loss = 0.85259763, grad/param norm = 1.6394e-01, time/batch = 16.8857s	
22518/33650 (epoch 33.459), train_loss = 0.91197257, grad/param norm = 1.9130e-01, time/batch = 16.0610s	
22519/33650 (epoch 33.461), train_loss = 0.95382550, grad/param norm = 1.9327e-01, time/batch = 16.5622s	
22520/33650 (epoch 33.462), train_loss = 0.97580815, grad/param norm = 1.9118e-01, time/batch = 17.7375s	
22521/33650 (epoch 33.464), train_loss = 0.84231644, grad/param norm = 2.0559e-01, time/batch = 17.3962s	
22522/33650 (epoch 33.465), train_loss = 0.90265920, grad/param norm = 2.0278e-01, time/batch = 16.9070s	
22523/33650 (epoch 33.467), train_loss = 0.90337183, grad/param norm = 1.7002e-01, time/batch = 17.4954s	
22524/33650 (epoch 33.468), train_loss = 1.02868929, grad/param norm = 1.5657e-01, time/batch = 17.9794s	
22525/33650 (epoch 33.470), train_loss = 1.08133377, grad/param norm = 1.9349e-01, time/batch = 17.8268s	
22526/33650 (epoch 33.471), train_loss = 0.87770188, grad/param norm = 2.1860e-01, time/batch = 16.4693s	
22527/33650 (epoch 33.473), train_loss = 0.85770778, grad/param norm = 1.8434e-01, time/batch = 17.9027s	
22528/33650 (epoch 33.474), train_loss = 1.00923409, grad/param norm = 1.8177e-01, time/batch = 17.5773s	
22529/33650 (epoch 33.475), train_loss = 0.96195225, grad/param norm = 2.0365e-01, time/batch = 16.2286s	
22530/33650 (epoch 33.477), train_loss = 0.98260009, grad/param norm = 1.9767e-01, time/batch = 16.3203s	
22531/33650 (epoch 33.478), train_loss = 0.96865468, grad/param norm = 1.7996e-01, time/batch = 17.8198s	
22532/33650 (epoch 33.480), train_loss = 0.96855577, grad/param norm = 1.9466e-01, time/batch = 18.2342s	
22533/33650 (epoch 33.481), train_loss = 0.98605885, grad/param norm = 1.5664e-01, time/batch = 15.4540s	
22534/33650 (epoch 33.483), train_loss = 0.76127820, grad/param norm = 1.7274e-01, time/batch = 17.3251s	
22535/33650 (epoch 33.484), train_loss = 0.85039340, grad/param norm = 1.6380e-01, time/batch = 17.1605s	
22536/33650 (epoch 33.486), train_loss = 1.02333653, grad/param norm = 1.9780e-01, time/batch = 16.9047s	
22537/33650 (epoch 33.487), train_loss = 0.98975960, grad/param norm = 1.6454e-01, time/batch = 16.4666s	
22538/33650 (epoch 33.489), train_loss = 1.04802925, grad/param norm = 1.7120e-01, time/batch = 16.4713s	
22539/33650 (epoch 33.490), train_loss = 0.83345826, grad/param norm = 1.7078e-01, time/batch = 17.4080s	
22540/33650 (epoch 33.492), train_loss = 0.94932817, grad/param norm = 2.0921e-01, time/batch = 16.2222s	
22541/33650 (epoch 33.493), train_loss = 0.75125647, grad/param norm = 1.5674e-01, time/batch = 17.3932s	
22542/33650 (epoch 33.495), train_loss = 0.92333268, grad/param norm = 1.6562e-01, time/batch = 16.3845s	
22543/33650 (epoch 33.496), train_loss = 0.95089840, grad/param norm = 1.8316e-01, time/batch = 17.5499s	
22544/33650 (epoch 33.498), train_loss = 0.83872735, grad/param norm = 1.7279e-01, time/batch = 19.0487s	
22545/33650 (epoch 33.499), train_loss = 0.88967250, grad/param norm = 1.4532e-01, time/batch = 16.8856s	
22546/33650 (epoch 33.501), train_loss = 0.87817433, grad/param norm = 1.4761e-01, time/batch = 18.9658s	
22547/33650 (epoch 33.502), train_loss = 0.94911953, grad/param norm = 2.0536e-01, time/batch = 17.7984s	
22548/33650 (epoch 33.504), train_loss = 0.97171512, grad/param norm = 2.1878e-01, time/batch = 18.9791s	
22549/33650 (epoch 33.505), train_loss = 0.88932649, grad/param norm = 1.9655e-01, time/batch = 18.4883s	
22550/33650 (epoch 33.507), train_loss = 0.99403969, grad/param norm = 1.6235e-01, time/batch = 16.9748s	
22551/33650 (epoch 33.508), train_loss = 0.88202004, grad/param norm = 1.6310e-01, time/batch = 18.9710s	
22552/33650 (epoch 33.510), train_loss = 0.89739060, grad/param norm = 1.5602e-01, time/batch = 18.6539s	
22553/33650 (epoch 33.511), train_loss = 1.04046360, grad/param norm = 2.5448e-01, time/batch = 17.1313s	
22554/33650 (epoch 33.513), train_loss = 0.94866429, grad/param norm = 1.6678e-01, time/batch = 18.6310s	
22555/33650 (epoch 33.514), train_loss = 0.99933277, grad/param norm = 1.8588e-01, time/batch = 17.1423s	
22556/33650 (epoch 33.516), train_loss = 0.90704249, grad/param norm = 1.8873e-01, time/batch = 17.9815s	
22557/33650 (epoch 33.517), train_loss = 0.90001003, grad/param norm = 1.8370e-01, time/batch = 17.1236s	
22558/33650 (epoch 33.519), train_loss = 0.94021299, grad/param norm = 1.5597e-01, time/batch = 19.1456s	
22559/33650 (epoch 33.520), train_loss = 0.78311270, grad/param norm = 1.4024e-01, time/batch = 18.4000s	
22560/33650 (epoch 33.522), train_loss = 0.87696806, grad/param norm = 1.6892e-01, time/batch = 18.1362s	
22561/33650 (epoch 33.523), train_loss = 0.83606040, grad/param norm = 1.6764e-01, time/batch = 17.8937s	
22562/33650 (epoch 33.525), train_loss = 0.71101606, grad/param norm = 1.2387e-01, time/batch = 19.0613s	
22563/33650 (epoch 33.526), train_loss = 0.98866279, grad/param norm = 1.5318e-01, time/batch = 25.7903s	
22564/33650 (epoch 33.527), train_loss = 0.83669809, grad/param norm = 1.6656e-01, time/batch = 22.9816s	
22565/33650 (epoch 33.529), train_loss = 0.89377959, grad/param norm = 1.7046e-01, time/batch = 19.3017s	
22566/33650 (epoch 33.530), train_loss = 0.83171159, grad/param norm = 1.6648e-01, time/batch = 17.1408s	
22567/33650 (epoch 33.532), train_loss = 0.96391847, grad/param norm = 1.9798e-01, time/batch = 17.6231s	
22568/33650 (epoch 33.533), train_loss = 0.89131376, grad/param norm = 1.5627e-01, time/batch = 17.9780s	
22569/33650 (epoch 33.535), train_loss = 1.03055402, grad/param norm = 1.8025e-01, time/batch = 16.7205s	
22570/33650 (epoch 33.536), train_loss = 0.91656556, grad/param norm = 1.7453e-01, time/batch = 18.8745s	
22571/33650 (epoch 33.538), train_loss = 0.92295822, grad/param norm = 1.8250e-01, time/batch = 17.9801s	
22572/33650 (epoch 33.539), train_loss = 0.70709514, grad/param norm = 1.4644e-01, time/batch = 18.3160s	
22573/33650 (epoch 33.541), train_loss = 0.98034766, grad/param norm = 1.7115e-01, time/batch = 18.2199s	
22574/33650 (epoch 33.542), train_loss = 0.87981274, grad/param norm = 2.4487e-01, time/batch = 18.0515s	
22575/33650 (epoch 33.544), train_loss = 1.05285699, grad/param norm = 2.1991e-01, time/batch = 17.7379s	
22576/33650 (epoch 33.545), train_loss = 0.80855997, grad/param norm = 1.6531e-01, time/batch = 18.1295s	
22577/33650 (epoch 33.547), train_loss = 0.94218777, grad/param norm = 1.6552e-01, time/batch = 17.6555s	
22578/33650 (epoch 33.548), train_loss = 1.05548421, grad/param norm = 1.7000e-01, time/batch = 18.3993s	
22579/33650 (epoch 33.550), train_loss = 0.91410907, grad/param norm = 1.6708e-01, time/batch = 18.0430s	
22580/33650 (epoch 33.551), train_loss = 0.93351245, grad/param norm = 1.8747e-01, time/batch = 17.9730s	
22581/33650 (epoch 33.553), train_loss = 0.78302998, grad/param norm = 1.8538e-01, time/batch = 17.3828s	
22582/33650 (epoch 33.554), train_loss = 1.04522429, grad/param norm = 1.7903e-01, time/batch = 17.3872s	
22583/33650 (epoch 33.556), train_loss = 1.02264087, grad/param norm = 4.1988e-01, time/batch = 17.9737s	
22584/33650 (epoch 33.557), train_loss = 0.96388772, grad/param norm = 1.8363e-01, time/batch = 18.9834s	
22585/33650 (epoch 33.559), train_loss = 1.15091743, grad/param norm = 2.1738e-01, time/batch = 18.0507s	
22586/33650 (epoch 33.560), train_loss = 1.06245801, grad/param norm = 1.9618e-01, time/batch = 17.8968s	
22587/33650 (epoch 33.562), train_loss = 1.02525471, grad/param norm = 1.7300e-01, time/batch = 17.4662s	
22588/33650 (epoch 33.563), train_loss = 0.93465108, grad/param norm = 1.7245e-01, time/batch = 18.1471s	
22589/33650 (epoch 33.565), train_loss = 0.93891778, grad/param norm = 1.7664e-01, time/batch = 15.7947s	
22590/33650 (epoch 33.566), train_loss = 0.89445900, grad/param norm = 1.7887e-01, time/batch = 18.4568s	
22591/33650 (epoch 33.568), train_loss = 0.92018917, grad/param norm = 2.0161e-01, time/batch = 18.5599s	
22592/33650 (epoch 33.569), train_loss = 0.83877094, grad/param norm = 1.6221e-01, time/batch = 17.3043s	
22593/33650 (epoch 33.571), train_loss = 1.00163780, grad/param norm = 1.8859e-01, time/batch = 18.8931s	
22594/33650 (epoch 33.572), train_loss = 0.95367499, grad/param norm = 1.4876e-01, time/batch = 19.2265s	
22595/33650 (epoch 33.574), train_loss = 0.84450814, grad/param norm = 2.1371e-01, time/batch = 17.9644s	
22596/33650 (epoch 33.575), train_loss = 0.91588903, grad/param norm = 1.7346e-01, time/batch = 6.9851s	
22597/33650 (epoch 33.577), train_loss = 0.83116197, grad/param norm = 1.9069e-01, time/batch = 0.6486s	
22598/33650 (epoch 33.578), train_loss = 1.01952207, grad/param norm = 1.9678e-01, time/batch = 0.6448s	
22599/33650 (epoch 33.579), train_loss = 0.96854962, grad/param norm = 1.8302e-01, time/batch = 0.6426s	
22600/33650 (epoch 33.581), train_loss = 1.05628168, grad/param norm = 1.8064e-01, time/batch = 0.6441s	
22601/33650 (epoch 33.582), train_loss = 0.93881041, grad/param norm = 1.5641e-01, time/batch = 0.6457s	
22602/33650 (epoch 33.584), train_loss = 0.91770105, grad/param norm = 1.5947e-01, time/batch = 0.6444s	
22603/33650 (epoch 33.585), train_loss = 0.93945781, grad/param norm = 1.6907e-01, time/batch = 0.6436s	
22604/33650 (epoch 33.587), train_loss = 0.85205965, grad/param norm = 1.6232e-01, time/batch = 0.9307s	
22605/33650 (epoch 33.588), train_loss = 0.85602494, grad/param norm = 2.1142e-01, time/batch = 0.9564s	
22606/33650 (epoch 33.590), train_loss = 0.87043544, grad/param norm = 1.4994e-01, time/batch = 0.9443s	
22607/33650 (epoch 33.591), train_loss = 0.79321135, grad/param norm = 1.5898e-01, time/batch = 0.9444s	
22608/33650 (epoch 33.593), train_loss = 0.80481244, grad/param norm = 1.6712e-01, time/batch = 0.9442s	
22609/33650 (epoch 33.594), train_loss = 0.80774028, grad/param norm = 1.5582e-01, time/batch = 1.4982s	
22610/33650 (epoch 33.596), train_loss = 0.88231420, grad/param norm = 1.5711e-01, time/batch = 1.7712s	
22611/33650 (epoch 33.597), train_loss = 0.77842474, grad/param norm = 1.4651e-01, time/batch = 1.7765s	
22612/33650 (epoch 33.599), train_loss = 0.88581735, grad/param norm = 1.5506e-01, time/batch = 16.4029s	
22613/33650 (epoch 33.600), train_loss = 0.82638705, grad/param norm = 1.4522e-01, time/batch = 17.7265s	
22614/33650 (epoch 33.602), train_loss = 0.91501603, grad/param norm = 1.8031e-01, time/batch = 16.5385s	
22615/33650 (epoch 33.603), train_loss = 0.84623220, grad/param norm = 1.6917e-01, time/batch = 18.1299s	
22616/33650 (epoch 33.605), train_loss = 0.94610008, grad/param norm = 1.5823e-01, time/batch = 18.2146s	
22617/33650 (epoch 33.606), train_loss = 0.90836673, grad/param norm = 1.9562e-01, time/batch = 17.6322s	
22618/33650 (epoch 33.608), train_loss = 0.80944882, grad/param norm = 1.9715e-01, time/batch = 18.5361s	
22619/33650 (epoch 33.609), train_loss = 0.88798332, grad/param norm = 1.6283e-01, time/batch = 17.8131s	
22620/33650 (epoch 33.611), train_loss = 0.80208721, grad/param norm = 1.8354e-01, time/batch = 15.4659s	
22621/33650 (epoch 33.612), train_loss = 0.88620720, grad/param norm = 1.9030e-01, time/batch = 15.0223s	
22622/33650 (epoch 33.614), train_loss = 0.99026665, grad/param norm = 1.8211e-01, time/batch = 14.9545s	
22623/33650 (epoch 33.615), train_loss = 0.91452172, grad/param norm = 1.4239e-01, time/batch = 18.3862s	
22624/33650 (epoch 33.617), train_loss = 0.82166421, grad/param norm = 1.4193e-01, time/batch = 17.8043s	
22625/33650 (epoch 33.618), train_loss = 0.85788014, grad/param norm = 1.6683e-01, time/batch = 16.3799s	
22626/33650 (epoch 33.620), train_loss = 0.83418415, grad/param norm = 1.6454e-01, time/batch = 18.8775s	
22627/33650 (epoch 33.621), train_loss = 0.78414143, grad/param norm = 1.5729e-01, time/batch = 18.2147s	
22628/33650 (epoch 33.623), train_loss = 0.85428832, grad/param norm = 1.5516e-01, time/batch = 17.7914s	
22629/33650 (epoch 33.624), train_loss = 0.69818106, grad/param norm = 1.6009e-01, time/batch = 19.1442s	
22630/33650 (epoch 33.626), train_loss = 0.72718621, grad/param norm = 1.5420e-01, time/batch = 18.8915s	
22631/33650 (epoch 33.627), train_loss = 0.81563738, grad/param norm = 1.5545e-01, time/batch = 16.9829s	
22632/33650 (epoch 33.629), train_loss = 0.83984151, grad/param norm = 1.7233e-01, time/batch = 19.1226s	
22633/33650 (epoch 33.630), train_loss = 0.98262217, grad/param norm = 1.6809e-01, time/batch = 18.8872s	
22634/33650 (epoch 33.632), train_loss = 0.96326765, grad/param norm = 1.6486e-01, time/batch = 15.4416s	
22635/33650 (epoch 33.633), train_loss = 0.95564249, grad/param norm = 1.5924e-01, time/batch = 14.7137s	
22636/33650 (epoch 33.634), train_loss = 0.79236667, grad/param norm = 1.6148e-01, time/batch = 14.7954s	
22637/33650 (epoch 33.636), train_loss = 0.69569051, grad/param norm = 1.2256e-01, time/batch = 18.6255s	
22638/33650 (epoch 33.637), train_loss = 0.79983209, grad/param norm = 1.4746e-01, time/batch = 16.1256s	
22639/33650 (epoch 33.639), train_loss = 0.80760190, grad/param norm = 1.5407e-01, time/batch = 17.8882s	
22640/33650 (epoch 33.640), train_loss = 0.89703885, grad/param norm = 1.7599e-01, time/batch = 18.1274s	
22641/33650 (epoch 33.642), train_loss = 0.95534504, grad/param norm = 1.6662e-01, time/batch = 17.7173s	
22642/33650 (epoch 33.643), train_loss = 0.89111002, grad/param norm = 1.6900e-01, time/batch = 16.9005s	
22643/33650 (epoch 33.645), train_loss = 0.89501834, grad/param norm = 1.5876e-01, time/batch = 18.5747s	
22644/33650 (epoch 33.646), train_loss = 0.79009326, grad/param norm = 1.3997e-01, time/batch = 18.0608s	
22645/33650 (epoch 33.648), train_loss = 0.92702203, grad/param norm = 1.6203e-01, time/batch = 17.2955s	
22646/33650 (epoch 33.649), train_loss = 0.79194818, grad/param norm = 2.2826e-01, time/batch = 18.4883s	
22647/33650 (epoch 33.651), train_loss = 0.94736723, grad/param norm = 1.7723e-01, time/batch = 18.0673s	
22648/33650 (epoch 33.652), train_loss = 0.66626228, grad/param norm = 1.4487e-01, time/batch = 15.3070s	
22649/33650 (epoch 33.654), train_loss = 0.79167520, grad/param norm = 1.6765e-01, time/batch = 14.6352s	
22650/33650 (epoch 33.655), train_loss = 0.78113275, grad/param norm = 1.5712e-01, time/batch = 15.4459s	
22651/33650 (epoch 33.657), train_loss = 0.82336917, grad/param norm = 1.6413e-01, time/batch = 18.8157s	
22652/33650 (epoch 33.658), train_loss = 0.71961121, grad/param norm = 1.6280e-01, time/batch = 17.2076s	
22653/33650 (epoch 33.660), train_loss = 0.70856225, grad/param norm = 1.3293e-01, time/batch = 18.3099s	
22654/33650 (epoch 33.661), train_loss = 0.78347907, grad/param norm = 1.5416e-01, time/batch = 16.8959s	
22655/33650 (epoch 33.663), train_loss = 0.73799925, grad/param norm = 1.5867e-01, time/batch = 17.5575s	
22656/33650 (epoch 33.664), train_loss = 0.83550339, grad/param norm = 1.5229e-01, time/batch = 16.9666s	
22657/33650 (epoch 33.666), train_loss = 0.84462163, grad/param norm = 1.5702e-01, time/batch = 16.3817s	
22658/33650 (epoch 33.667), train_loss = 0.72659585, grad/param norm = 1.4304e-01, time/batch = 17.7196s	
22659/33650 (epoch 33.669), train_loss = 0.75925737, grad/param norm = 1.4486e-01, time/batch = 17.8765s	
22660/33650 (epoch 33.670), train_loss = 0.69539834, grad/param norm = 1.6088e-01, time/batch = 18.5587s	
22661/33650 (epoch 33.672), train_loss = 0.72757081, grad/param norm = 1.5747e-01, time/batch = 19.1479s	
22662/33650 (epoch 33.673), train_loss = 0.71455908, grad/param norm = 1.5331e-01, time/batch = 17.5412s	
22663/33650 (epoch 33.675), train_loss = 0.65902435, grad/param norm = 1.3149e-01, time/batch = 18.2383s	
22664/33650 (epoch 33.676), train_loss = 0.82504547, grad/param norm = 1.6769e-01, time/batch = 18.4805s	
22665/33650 (epoch 33.678), train_loss = 0.80436925, grad/param norm = 1.7802e-01, time/batch = 16.8806s	
22666/33650 (epoch 33.679), train_loss = 0.81027225, grad/param norm = 1.9874e-01, time/batch = 18.0602s	
22667/33650 (epoch 33.681), train_loss = 0.81803766, grad/param norm = 1.4002e-01, time/batch = 18.2958s	
22668/33650 (epoch 33.682), train_loss = 0.78527704, grad/param norm = 1.7456e-01, time/batch = 14.7042s	
22669/33650 (epoch 33.684), train_loss = 0.73278869, grad/param norm = 1.4818e-01, time/batch = 15.0992s	
22670/33650 (epoch 33.685), train_loss = 0.88683202, grad/param norm = 1.7410e-01, time/batch = 14.7815s	
22671/33650 (epoch 33.686), train_loss = 0.85860771, grad/param norm = 1.6216e-01, time/batch = 15.8151s	
22672/33650 (epoch 33.688), train_loss = 0.91119627, grad/param norm = 1.5909e-01, time/batch = 17.3034s	
22673/33650 (epoch 33.689), train_loss = 0.80598052, grad/param norm = 1.6020e-01, time/batch = 18.1385s	
22674/33650 (epoch 33.691), train_loss = 0.95030313, grad/param norm = 1.8578e-01, time/batch = 18.3777s	
22675/33650 (epoch 33.692), train_loss = 0.94879837, grad/param norm = 1.7354e-01, time/batch = 18.4660s	
22676/33650 (epoch 33.694), train_loss = 0.90165575, grad/param norm = 1.7158e-01, time/batch = 16.8893s	
22677/33650 (epoch 33.695), train_loss = 0.59433115, grad/param norm = 1.4167e-01, time/batch = 17.7325s	
22678/33650 (epoch 33.697), train_loss = 0.83356740, grad/param norm = 1.8909e-01, time/batch = 17.8873s	
22679/33650 (epoch 33.698), train_loss = 0.95992484, grad/param norm = 1.8153e-01, time/batch = 17.6235s	
22680/33650 (epoch 33.700), train_loss = 0.83372048, grad/param norm = 1.6508e-01, time/batch = 17.8837s	
22681/33650 (epoch 33.701), train_loss = 0.86126383, grad/param norm = 1.6053e-01, time/batch = 18.0449s	
22682/33650 (epoch 33.703), train_loss = 1.05336889, grad/param norm = 1.7375e-01, time/batch = 17.4602s	
22683/33650 (epoch 33.704), train_loss = 0.83397796, grad/param norm = 1.4263e-01, time/batch = 14.6370s	
22684/33650 (epoch 33.706), train_loss = 0.81200020, grad/param norm = 1.3944e-01, time/batch = 14.6255s	
22685/33650 (epoch 33.707), train_loss = 0.94818751, grad/param norm = 1.6455e-01, time/batch = 15.7107s	
22686/33650 (epoch 33.709), train_loss = 0.80405318, grad/param norm = 1.5422e-01, time/batch = 17.4428s	
22687/33650 (epoch 33.710), train_loss = 1.01791925, grad/param norm = 1.7788e-01, time/batch = 18.7052s	
22688/33650 (epoch 33.712), train_loss = 0.73133061, grad/param norm = 1.5822e-01, time/batch = 15.2800s	
22689/33650 (epoch 33.713), train_loss = 0.76213196, grad/param norm = 1.7479e-01, time/batch = 14.7942s	
22690/33650 (epoch 33.715), train_loss = 0.90034582, grad/param norm = 1.8170e-01, time/batch = 15.7643s	
22691/33650 (epoch 33.716), train_loss = 0.83346007, grad/param norm = 1.5543e-01, time/batch = 14.7773s	
22692/33650 (epoch 33.718), train_loss = 0.81085340, grad/param norm = 1.6222e-01, time/batch = 15.3647s	
22693/33650 (epoch 33.719), train_loss = 0.95762712, grad/param norm = 1.8278e-01, time/batch = 16.9810s	
22694/33650 (epoch 33.721), train_loss = 1.03262695, grad/param norm = 1.7629e-01, time/batch = 17.2782s	
22695/33650 (epoch 33.722), train_loss = 0.92403947, grad/param norm = 2.1314e-01, time/batch = 18.2106s	
22696/33650 (epoch 33.724), train_loss = 0.95611352, grad/param norm = 1.6934e-01, time/batch = 18.9778s	
22697/33650 (epoch 33.725), train_loss = 0.90502265, grad/param norm = 1.7606e-01, time/batch = 16.9836s	
22698/33650 (epoch 33.727), train_loss = 0.82211353, grad/param norm = 1.7600e-01, time/batch = 17.4793s	
22699/33650 (epoch 33.728), train_loss = 0.82101153, grad/param norm = 1.5794e-01, time/batch = 16.8968s	
22700/33650 (epoch 33.730), train_loss = 0.87823972, grad/param norm = 1.5774e-01, time/batch = 16.5452s	
22701/33650 (epoch 33.731), train_loss = 1.01894910, grad/param norm = 1.8563e-01, time/batch = 16.9042s	
22702/33650 (epoch 33.733), train_loss = 0.82512587, grad/param norm = 1.7539e-01, time/batch = 17.5810s	
22703/33650 (epoch 33.734), train_loss = 0.99402402, grad/param norm = 1.8834e-01, time/batch = 17.0848s	
22704/33650 (epoch 33.736), train_loss = 0.85989220, grad/param norm = 2.0644e-01, time/batch = 16.0450s	
22705/33650 (epoch 33.737), train_loss = 0.89923568, grad/param norm = 1.8642e-01, time/batch = 14.2054s	
22706/33650 (epoch 33.738), train_loss = 0.79060501, grad/param norm = 1.7346e-01, time/batch = 14.2826s	
22707/33650 (epoch 33.740), train_loss = 0.72810831, grad/param norm = 1.4432e-01, time/batch = 16.7306s	
22708/33650 (epoch 33.741), train_loss = 0.78870865, grad/param norm = 1.6484e-01, time/batch = 16.9821s	
22709/33650 (epoch 33.743), train_loss = 0.85844273, grad/param norm = 1.6398e-01, time/batch = 16.9878s	
22710/33650 (epoch 33.744), train_loss = 0.94442112, grad/param norm = 1.5046e-01, time/batch = 17.1593s	
22711/33650 (epoch 33.746), train_loss = 0.83128695, grad/param norm = 1.5946e-01, time/batch = 17.3149s	
22712/33650 (epoch 33.747), train_loss = 0.98428992, grad/param norm = 1.7931e-01, time/batch = 17.7369s	
22713/33650 (epoch 33.749), train_loss = 0.71058928, grad/param norm = 1.8273e-01, time/batch = 16.9881s	
22714/33650 (epoch 33.750), train_loss = 1.02248757, grad/param norm = 1.9975e-01, time/batch = 17.5761s	
22715/33650 (epoch 33.752), train_loss = 0.95400551, grad/param norm = 1.6576e-01, time/batch = 15.9026s	
22716/33650 (epoch 33.753), train_loss = 1.04589986, grad/param norm = 1.8142e-01, time/batch = 16.9831s	
22717/33650 (epoch 33.755), train_loss = 0.85383790, grad/param norm = 1.5168e-01, time/batch = 16.3977s	
22718/33650 (epoch 33.756), train_loss = 0.93270728, grad/param norm = 1.7010e-01, time/batch = 17.1524s	
22719/33650 (epoch 33.758), train_loss = 0.95869661, grad/param norm = 1.6406e-01, time/batch = 16.5644s	
22720/33650 (epoch 33.759), train_loss = 0.96577941, grad/param norm = 2.0583e-01, time/batch = 15.5482s	
22721/33650 (epoch 33.761), train_loss = 0.87092906, grad/param norm = 1.5013e-01, time/batch = 14.0628s	
22722/33650 (epoch 33.762), train_loss = 0.86178480, grad/param norm = 1.6830e-01, time/batch = 14.2913s	
22723/33650 (epoch 33.764), train_loss = 0.92229155, grad/param norm = 1.9746e-01, time/batch = 17.3113s	
22724/33650 (epoch 33.765), train_loss = 0.81535908, grad/param norm = 1.6766e-01, time/batch = 17.1558s	
22725/33650 (epoch 33.767), train_loss = 0.86397512, grad/param norm = 1.6906e-01, time/batch = 17.0571s	
22726/33650 (epoch 33.768), train_loss = 0.79168827, grad/param norm = 1.6240e-01, time/batch = 16.5750s	
22727/33650 (epoch 33.770), train_loss = 0.87668725, grad/param norm = 1.7795e-01, time/batch = 18.0707s	
22728/33650 (epoch 33.771), train_loss = 0.91029573, grad/param norm = 1.5763e-01, time/batch = 16.6613s	
22729/33650 (epoch 33.773), train_loss = 0.96724270, grad/param norm = 2.3857e-01, time/batch = 17.0571s	
22730/33650 (epoch 33.774), train_loss = 0.89877744, grad/param norm = 1.5989e-01, time/batch = 17.1524s	
22731/33650 (epoch 33.776), train_loss = 0.94432713, grad/param norm = 1.8247e-01, time/batch = 16.7311s	
22732/33650 (epoch 33.777), train_loss = 0.79696393, grad/param norm = 1.4451e-01, time/batch = 18.0800s	
22733/33650 (epoch 33.779), train_loss = 0.85851963, grad/param norm = 1.5662e-01, time/batch = 15.6441s	
22734/33650 (epoch 33.780), train_loss = 0.77658822, grad/param norm = 1.5007e-01, time/batch = 17.8233s	
22735/33650 (epoch 33.782), train_loss = 0.79584305, grad/param norm = 1.7121e-01, time/batch = 17.4056s	
22736/33650 (epoch 33.783), train_loss = 0.79120363, grad/param norm = 1.3107e-01, time/batch = 16.8073s	
22737/33650 (epoch 33.785), train_loss = 1.02630887, grad/param norm = 1.6168e-01, time/batch = 16.2925s	
22738/33650 (epoch 33.786), train_loss = 0.91387082, grad/param norm = 1.4939e-01, time/batch = 17.5755s	
22739/33650 (epoch 33.788), train_loss = 0.92928126, grad/param norm = 1.7633e-01, time/batch = 17.9112s	
22740/33650 (epoch 33.789), train_loss = 0.97123454, grad/param norm = 2.0079e-01, time/batch = 16.4794s	
22741/33650 (epoch 33.790), train_loss = 0.88118290, grad/param norm = 1.7739e-01, time/batch = 16.9876s	
22742/33650 (epoch 33.792), train_loss = 0.99384748, grad/param norm = 2.2043e-01, time/batch = 16.9874s	
22743/33650 (epoch 33.793), train_loss = 0.95193177, grad/param norm = 2.2033e-01, time/batch = 16.6383s	
22744/33650 (epoch 33.795), train_loss = 0.94519660, grad/param norm = 1.6465e-01, time/batch = 16.7144s	
22745/33650 (epoch 33.796), train_loss = 0.85253516, grad/param norm = 1.5924e-01, time/batch = 16.8184s	
22746/33650 (epoch 33.798), train_loss = 0.82737836, grad/param norm = 1.5970e-01, time/batch = 17.8290s	
22747/33650 (epoch 33.799), train_loss = 0.87131046, grad/param norm = 1.6284e-01, time/batch = 16.8166s	
22748/33650 (epoch 33.801), train_loss = 0.89319267, grad/param norm = 2.0748e-01, time/batch = 17.3228s	
22749/33650 (epoch 33.802), train_loss = 0.97566819, grad/param norm = 1.7997e-01, time/batch = 17.6548s	
22750/33650 (epoch 33.804), train_loss = 0.88821796, grad/param norm = 1.7396e-01, time/batch = 17.1525s	
22751/33650 (epoch 33.805), train_loss = 0.86598937, grad/param norm = 1.5800e-01, time/batch = 17.4043s	
22752/33650 (epoch 33.807), train_loss = 1.06337501, grad/param norm = 2.3303e-01, time/batch = 17.7188s	
22753/33650 (epoch 33.808), train_loss = 1.11346967, grad/param norm = 1.9425e-01, time/batch = 14.7133s	
22754/33650 (epoch 33.810), train_loss = 0.91894903, grad/param norm = 1.7253e-01, time/batch = 15.6551s	
22755/33650 (epoch 33.811), train_loss = 0.90508729, grad/param norm = 1.6708e-01, time/batch = 18.1522s	
22756/33650 (epoch 33.813), train_loss = 0.80197960, grad/param norm = 1.5202e-01, time/batch = 16.9964s	
22757/33650 (epoch 33.814), train_loss = 0.96616358, grad/param norm = 1.7064e-01, time/batch = 16.8985s	
22758/33650 (epoch 33.816), train_loss = 0.94644519, grad/param norm = 1.9946e-01, time/batch = 24.4735s	
22759/33650 (epoch 33.817), train_loss = 0.98521383, grad/param norm = 2.1902e-01, time/batch = 17.0468s	
22760/33650 (epoch 33.819), train_loss = 0.88991447, grad/param norm = 1.7196e-01, time/batch = 17.1583s	
22761/33650 (epoch 33.820), train_loss = 0.98750195, grad/param norm = 1.8407e-01, time/batch = 17.3950s	
22762/33650 (epoch 33.822), train_loss = 0.90758677, grad/param norm = 1.9708e-01, time/batch = 18.0623s	
22763/33650 (epoch 33.823), train_loss = 0.83776967, grad/param norm = 1.6021e-01, time/batch = 17.3111s	
22764/33650 (epoch 33.825), train_loss = 0.88575108, grad/param norm = 1.5464e-01, time/batch = 16.7272s	
22765/33650 (epoch 33.826), train_loss = 0.96466508, grad/param norm = 1.8180e-01, time/batch = 17.6512s	
22766/33650 (epoch 33.828), train_loss = 1.06954392, grad/param norm = 2.1257e-01, time/batch = 17.4832s	
22767/33650 (epoch 33.829), train_loss = 0.76276217, grad/param norm = 1.6199e-01, time/batch = 17.2180s	
22768/33650 (epoch 33.831), train_loss = 0.90937885, grad/param norm = 1.8143e-01, time/batch = 17.3829s	
22769/33650 (epoch 33.832), train_loss = 0.96392193, grad/param norm = 1.8147e-01, time/batch = 17.4052s	
22770/33650 (epoch 33.834), train_loss = 0.96037151, grad/param norm = 2.1362e-01, time/batch = 17.4133s	
22771/33650 (epoch 33.835), train_loss = 1.11751254, grad/param norm = 2.2397e-01, time/batch = 16.2267s	
22772/33650 (epoch 33.837), train_loss = 0.92994044, grad/param norm = 1.7140e-01, time/batch = 16.3906s	
22773/33650 (epoch 33.838), train_loss = 0.89610792, grad/param norm = 1.6761e-01, time/batch = 17.5762s	
22774/33650 (epoch 33.840), train_loss = 0.96798557, grad/param norm = 1.7324e-01, time/batch = 17.4912s	
22775/33650 (epoch 33.841), train_loss = 0.84944939, grad/param norm = 1.6737e-01, time/batch = 16.9884s	
22776/33650 (epoch 33.842), train_loss = 0.87944677, grad/param norm = 1.6839e-01, time/batch = 16.0578s	
22777/33650 (epoch 33.844), train_loss = 1.01815186, grad/param norm = 1.9112e-01, time/batch = 18.2296s	
22778/33650 (epoch 33.845), train_loss = 0.87605421, grad/param norm = 1.6576e-01, time/batch = 16.4745s	
22779/33650 (epoch 33.847), train_loss = 0.66946999, grad/param norm = 1.3634e-01, time/batch = 17.8110s	
22780/33650 (epoch 33.848), train_loss = 0.78491281, grad/param norm = 2.1687e-01, time/batch = 17.0689s	
22781/33650 (epoch 33.850), train_loss = 0.84547248, grad/param norm = 2.0397e-01, time/batch = 17.5633s	
22782/33650 (epoch 33.851), train_loss = 0.75355688, grad/param norm = 1.4453e-01, time/batch = 17.9803s	
22783/33650 (epoch 33.853), train_loss = 0.84200398, grad/param norm = 2.0221e-01, time/batch = 16.3251s	
22784/33650 (epoch 33.854), train_loss = 0.96459002, grad/param norm = 1.7171e-01, time/batch = 17.9029s	
22785/33650 (epoch 33.856), train_loss = 0.69750346, grad/param norm = 1.5009e-01, time/batch = 30.3302s	
22786/33650 (epoch 33.857), train_loss = 0.90560918, grad/param norm = 1.4780e-01, time/batch = 16.2782s	
22787/33650 (epoch 33.859), train_loss = 0.78669121, grad/param norm = 1.3304e-01, time/batch = 17.6476s	
22788/33650 (epoch 33.860), train_loss = 0.75988753, grad/param norm = 1.6381e-01, time/batch = 17.1353s	
22789/33650 (epoch 33.862), train_loss = 0.80834544, grad/param norm = 1.5774e-01, time/batch = 18.3254s	
22790/33650 (epoch 33.863), train_loss = 0.99032781, grad/param norm = 1.5541e-01, time/batch = 17.1465s	
22791/33650 (epoch 33.865), train_loss = 0.86187886, grad/param norm = 1.5411e-01, time/batch = 17.3129s	
22792/33650 (epoch 33.866), train_loss = 0.81162860, grad/param norm = 1.7189e-01, time/batch = 17.9879s	
22793/33650 (epoch 33.868), train_loss = 0.76019421, grad/param norm = 1.8560e-01, time/batch = 17.1464s	
22794/33650 (epoch 33.869), train_loss = 0.93985211, grad/param norm = 2.0069e-01, time/batch = 16.8081s	
22795/33650 (epoch 33.871), train_loss = 0.78012624, grad/param norm = 1.5471e-01, time/batch = 16.8760s	
22796/33650 (epoch 33.872), train_loss = 0.90534051, grad/param norm = 1.5702e-01, time/batch = 17.6523s	
22797/33650 (epoch 33.874), train_loss = 0.93512861, grad/param norm = 2.2719e-01, time/batch = 16.8213s	
22798/33650 (epoch 33.875), train_loss = 0.83790990, grad/param norm = 1.5263e-01, time/batch = 15.9006s	
22799/33650 (epoch 33.877), train_loss = 1.02840231, grad/param norm = 1.6796e-01, time/batch = 17.8908s	
22800/33650 (epoch 33.878), train_loss = 0.63791011, grad/param norm = 1.3059e-01, time/batch = 17.9883s	
22801/33650 (epoch 33.880), train_loss = 0.91423153, grad/param norm = 1.8066e-01, time/batch = 16.5640s	
22802/33650 (epoch 33.881), train_loss = 0.83769637, grad/param norm = 1.7434e-01, time/batch = 16.9822s	
22803/33650 (epoch 33.883), train_loss = 0.89971937, grad/param norm = 1.6416e-01, time/batch = 17.9078s	
22804/33650 (epoch 33.884), train_loss = 0.99518273, grad/param norm = 1.7988e-01, time/batch = 18.2338s	
22805/33650 (epoch 33.886), train_loss = 0.92636359, grad/param norm = 1.6696e-01, time/batch = 16.3116s	
22806/33650 (epoch 33.887), train_loss = 0.75109486, grad/param norm = 1.4507e-01, time/batch = 17.3323s	
22807/33650 (epoch 33.889), train_loss = 0.84868101, grad/param norm = 2.3049e-01, time/batch = 16.6274s	
22808/33650 (epoch 33.890), train_loss = 0.90806497, grad/param norm = 1.4894e-01, time/batch = 17.0758s	
22809/33650 (epoch 33.892), train_loss = 0.82893549, grad/param norm = 2.5825e-01, time/batch = 16.4803s	
22810/33650 (epoch 33.893), train_loss = 0.89972391, grad/param norm = 1.7100e-01, time/batch = 16.9560s	
22811/33650 (epoch 33.895), train_loss = 0.99391202, grad/param norm = 1.5553e-01, time/batch = 17.4834s	
22812/33650 (epoch 33.896), train_loss = 0.80205248, grad/param norm = 1.5121e-01, time/batch = 16.2042s	
22813/33650 (epoch 33.897), train_loss = 0.73140663, grad/param norm = 1.6125e-01, time/batch = 17.1470s	
22814/33650 (epoch 33.899), train_loss = 0.78800713, grad/param norm = 1.4186e-01, time/batch = 17.5741s	
22815/33650 (epoch 33.900), train_loss = 0.74901246, grad/param norm = 1.4122e-01, time/batch = 15.9909s	
22816/33650 (epoch 33.902), train_loss = 0.84452720, grad/param norm = 1.7272e-01, time/batch = 17.6437s	
22817/33650 (epoch 33.903), train_loss = 0.83086422, grad/param norm = 1.6021e-01, time/batch = 17.8149s	
22818/33650 (epoch 33.905), train_loss = 0.99398619, grad/param norm = 1.9265e-01, time/batch = 17.2246s	
22819/33650 (epoch 33.906), train_loss = 0.81206897, grad/param norm = 1.6030e-01, time/batch = 16.3127s	
22820/33650 (epoch 33.908), train_loss = 0.84102241, grad/param norm = 1.5255e-01, time/batch = 16.6562s	
22821/33650 (epoch 33.909), train_loss = 0.81516750, grad/param norm = 1.3961e-01, time/batch = 17.0655s	
22822/33650 (epoch 33.911), train_loss = 0.73769546, grad/param norm = 1.4408e-01, time/batch = 16.3971s	
22823/33650 (epoch 33.912), train_loss = 0.67427181, grad/param norm = 1.6488e-01, time/batch = 16.8976s	
22824/33650 (epoch 33.914), train_loss = 0.87241542, grad/param norm = 1.4268e-01, time/batch = 16.9754s	
22825/33650 (epoch 33.915), train_loss = 0.83896365, grad/param norm = 1.9504e-01, time/batch = 17.5752s	
22826/33650 (epoch 33.917), train_loss = 0.82777442, grad/param norm = 1.7134e-01, time/batch = 16.1487s	
22827/33650 (epoch 33.918), train_loss = 0.78035053, grad/param norm = 1.5567e-01, time/batch = 17.9710s	
22828/33650 (epoch 33.920), train_loss = 0.77836252, grad/param norm = 1.4207e-01, time/batch = 16.8118s	
22829/33650 (epoch 33.921), train_loss = 0.76836914, grad/param norm = 1.5526e-01, time/batch = 16.7296s	
22830/33650 (epoch 33.923), train_loss = 0.69421125, grad/param norm = 1.5193e-01, time/batch = 16.8861s	
22831/33650 (epoch 33.924), train_loss = 0.88174150, grad/param norm = 1.7967e-01, time/batch = 17.7434s	
22832/33650 (epoch 33.926), train_loss = 0.81166122, grad/param norm = 1.9153e-01, time/batch = 16.9140s	
22833/33650 (epoch 33.927), train_loss = 0.85655514, grad/param norm = 1.6878e-01, time/batch = 16.1565s	
22834/33650 (epoch 33.929), train_loss = 0.92799584, grad/param norm = 1.5627e-01, time/batch = 17.3291s	
22835/33650 (epoch 33.930), train_loss = 0.84176293, grad/param norm = 1.7548e-01, time/batch = 17.0834s	
22836/33650 (epoch 33.932), train_loss = 0.85638551, grad/param norm = 1.6140e-01, time/batch = 16.8844s	
22837/33650 (epoch 33.933), train_loss = 0.72217678, grad/param norm = 1.6352e-01, time/batch = 17.1502s	
22838/33650 (epoch 33.935), train_loss = 0.72489634, grad/param norm = 1.6761e-01, time/batch = 17.9160s	
22839/33650 (epoch 33.936), train_loss = 0.77808892, grad/param norm = 1.3924e-01, time/batch = 16.8098s	
22840/33650 (epoch 33.938), train_loss = 0.75048993, grad/param norm = 1.7089e-01, time/batch = 16.4058s	
22841/33650 (epoch 33.939), train_loss = 0.91657256, grad/param norm = 1.4085e-01, time/batch = 17.4803s	
22842/33650 (epoch 33.941), train_loss = 0.84099802, grad/param norm = 1.4469e-01, time/batch = 17.8190s	
22843/33650 (epoch 33.942), train_loss = 0.92738891, grad/param norm = 1.8101e-01, time/batch = 16.7066s	
22844/33650 (epoch 33.944), train_loss = 0.80238818, grad/param norm = 1.5365e-01, time/batch = 17.4721s	
22845/33650 (epoch 33.945), train_loss = 0.85532700, grad/param norm = 1.5323e-01, time/batch = 17.3987s	
22846/33650 (epoch 33.947), train_loss = 0.97259756, grad/param norm = 2.5392e-01, time/batch = 16.8043s	
22847/33650 (epoch 33.948), train_loss = 0.97045971, grad/param norm = 1.6072e-01, time/batch = 15.9714s	
22848/33650 (epoch 33.949), train_loss = 0.74586759, grad/param norm = 1.6279e-01, time/batch = 17.4825s	
22849/33650 (epoch 33.951), train_loss = 1.00107668, grad/param norm = 1.7778e-01, time/batch = 17.6570s	
22850/33650 (epoch 33.952), train_loss = 0.89379730, grad/param norm = 1.6084e-01, time/batch = 17.0703s	
22851/33650 (epoch 33.954), train_loss = 0.89013727, grad/param norm = 1.7368e-01, time/batch = 17.3208s	
22852/33650 (epoch 33.955), train_loss = 0.87341755, grad/param norm = 1.6192e-01, time/batch = 17.5762s	
22853/33650 (epoch 33.957), train_loss = 0.89972077, grad/param norm = 1.8047e-01, time/batch = 17.9897s	
22854/33650 (epoch 33.958), train_loss = 0.66996428, grad/param norm = 1.3126e-01, time/batch = 16.0480s	
22855/33650 (epoch 33.960), train_loss = 0.69730794, grad/param norm = 1.4377e-01, time/batch = 15.1379s	
22856/33650 (epoch 33.961), train_loss = 0.73272022, grad/param norm = 1.3815e-01, time/batch = 13.2612s	
22857/33650 (epoch 33.963), train_loss = 0.76542319, grad/param norm = 1.6559e-01, time/batch = 13.3610s	
22858/33650 (epoch 33.964), train_loss = 0.93722165, grad/param norm = 1.5708e-01, time/batch = 14.3213s	
22859/33650 (epoch 33.966), train_loss = 0.87268316, grad/param norm = 1.9390e-01, time/batch = 16.9747s	
22860/33650 (epoch 33.967), train_loss = 0.89608417, grad/param norm = 1.7122e-01, time/batch = 18.1523s	
22861/33650 (epoch 33.969), train_loss = 0.84554345, grad/param norm = 1.6464e-01, time/batch = 16.5699s	
22862/33650 (epoch 33.970), train_loss = 0.85220047, grad/param norm = 1.8075e-01, time/batch = 17.3963s	
22863/33650 (epoch 33.972), train_loss = 1.12195269, grad/param norm = 2.0289e-01, time/batch = 16.7224s	
22864/33650 (epoch 33.973), train_loss = 0.76840540, grad/param norm = 1.3418e-01, time/batch = 16.3215s	
22865/33650 (epoch 33.975), train_loss = 0.74362303, grad/param norm = 1.3526e-01, time/batch = 16.4922s	
22866/33650 (epoch 33.976), train_loss = 0.77247791, grad/param norm = 1.4948e-01, time/batch = 17.4660s	
22867/33650 (epoch 33.978), train_loss = 0.77982956, grad/param norm = 1.4805e-01, time/batch = 16.8407s	
22868/33650 (epoch 33.979), train_loss = 0.83402598, grad/param norm = 1.5966e-01, time/batch = 17.1408s	
22869/33650 (epoch 33.981), train_loss = 0.82017230, grad/param norm = 1.5400e-01, time/batch = 16.4840s	
22870/33650 (epoch 33.982), train_loss = 0.85006928, grad/param norm = 1.5429e-01, time/batch = 16.8290s	
22871/33650 (epoch 33.984), train_loss = 0.70270485, grad/param norm = 1.4602e-01, time/batch = 17.5714s	
22872/33650 (epoch 33.985), train_loss = 0.76102441, grad/param norm = 1.6729e-01, time/batch = 16.7257s	
22873/33650 (epoch 33.987), train_loss = 0.86179434, grad/param norm = 1.4872e-01, time/batch = 17.8163s	
22874/33650 (epoch 33.988), train_loss = 0.80017177, grad/param norm = 1.6889e-01, time/batch = 17.4944s	
22875/33650 (epoch 33.990), train_loss = 0.98380348, grad/param norm = 1.8249e-01, time/batch = 16.7324s	
22876/33650 (epoch 33.991), train_loss = 0.87294472, grad/param norm = 1.8282e-01, time/batch = 17.4009s	
22877/33650 (epoch 33.993), train_loss = 0.86449219, grad/param norm = 1.5708e-01, time/batch = 15.5212s	
22878/33650 (epoch 33.994), train_loss = 0.88690117, grad/param norm = 1.5706e-01, time/batch = 17.0829s	
22879/33650 (epoch 33.996), train_loss = 0.83110938, grad/param norm = 1.8516e-01, time/batch = 16.1477s	
22880/33650 (epoch 33.997), train_loss = 0.91753668, grad/param norm = 1.8578e-01, time/batch = 17.2411s	
22881/33650 (epoch 33.999), train_loss = 0.77755693, grad/param norm = 1.5051e-01, time/batch = 17.1409s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
22882/33650 (epoch 34.000), train_loss = 0.92635091, grad/param norm = 1.8938e-01, time/batch = 17.8283s	
22883/33650 (epoch 34.001), train_loss = 0.97642325, grad/param norm = 1.5115e-01, time/batch = 17.1548s	
22884/33650 (epoch 34.003), train_loss = 0.96802654, grad/param norm = 2.0390e-01, time/batch = 17.4915s	
22885/33650 (epoch 34.004), train_loss = 0.87762119, grad/param norm = 1.6661e-01, time/batch = 17.4675s	
22886/33650 (epoch 34.006), train_loss = 0.82541628, grad/param norm = 1.6083e-01, time/batch = 16.9792s	
22887/33650 (epoch 34.007), train_loss = 0.87395875, grad/param norm = 1.8814e-01, time/batch = 17.4851s	
22888/33650 (epoch 34.009), train_loss = 0.78653050, grad/param norm = 1.5611e-01, time/batch = 14.8956s	
22889/33650 (epoch 34.010), train_loss = 0.94643291, grad/param norm = 1.6956e-01, time/batch = 13.6727s	
22890/33650 (epoch 34.012), train_loss = 0.81452486, grad/param norm = 1.6593e-01, time/batch = 14.3413s	
22891/33650 (epoch 34.013), train_loss = 0.84794286, grad/param norm = 1.9679e-01, time/batch = 15.3111s	
22892/33650 (epoch 34.015), train_loss = 0.84461610, grad/param norm = 1.8574e-01, time/batch = 17.3935s	
22893/33650 (epoch 34.016), train_loss = 0.78537300, grad/param norm = 1.9057e-01, time/batch = 17.6296s	
22894/33650 (epoch 34.018), train_loss = 0.83923348, grad/param norm = 2.1058e-01, time/batch = 17.9839s	
22895/33650 (epoch 34.019), train_loss = 0.80836512, grad/param norm = 1.8140e-01, time/batch = 17.5672s	
22896/33650 (epoch 34.021), train_loss = 0.91366878, grad/param norm = 1.6029e-01, time/batch = 17.9068s	
22897/33650 (epoch 34.022), train_loss = 0.81324470, grad/param norm = 1.4948e-01, time/batch = 16.7270s	
22898/33650 (epoch 34.024), train_loss = 0.76756957, grad/param norm = 1.7563e-01, time/batch = 16.0703s	
22899/33650 (epoch 34.025), train_loss = 0.88442887, grad/param norm = 1.6622e-01, time/batch = 16.9836s	
22900/33650 (epoch 34.027), train_loss = 0.87804242, grad/param norm = 1.8659e-01, time/batch = 17.4798s	
22901/33650 (epoch 34.028), train_loss = 0.93169892, grad/param norm = 1.7333e-01, time/batch = 16.9012s	
22902/33650 (epoch 34.030), train_loss = 0.84614286, grad/param norm = 2.0163e-01, time/batch = 15.2198s	
22903/33650 (epoch 34.031), train_loss = 0.76527570, grad/param norm = 1.3284e-01, time/batch = 17.4060s	
22904/33650 (epoch 34.033), train_loss = 0.88027963, grad/param norm = 1.5865e-01, time/batch = 16.0547s	
22905/33650 (epoch 34.034), train_loss = 0.89053461, grad/param norm = 1.6855e-01, time/batch = 18.0700s	
22906/33650 (epoch 34.036), train_loss = 0.97618004, grad/param norm = 1.8959e-01, time/batch = 16.9966s	
22907/33650 (epoch 34.037), train_loss = 0.80055370, grad/param norm = 1.4114e-01, time/batch = 17.6526s	
22908/33650 (epoch 34.039), train_loss = 0.94920412, grad/param norm = 1.6272e-01, time/batch = 17.7247s	
22909/33650 (epoch 34.040), train_loss = 1.00433199, grad/param norm = 1.9022e-01, time/batch = 17.4773s	
22910/33650 (epoch 34.042), train_loss = 1.02335173, grad/param norm = 1.7081e-01, time/batch = 16.5575s	
22911/33650 (epoch 34.043), train_loss = 0.83465359, grad/param norm = 1.5740e-01, time/batch = 16.0593s	
22912/33650 (epoch 34.045), train_loss = 0.78961826, grad/param norm = 1.5440e-01, time/batch = 18.1416s	
22913/33650 (epoch 34.046), train_loss = 0.92033107, grad/param norm = 1.7085e-01, time/batch = 15.2222s	
22914/33650 (epoch 34.048), train_loss = 0.94310931, grad/param norm = 1.7580e-01, time/batch = 17.2396s	
22915/33650 (epoch 34.049), train_loss = 0.81779807, grad/param norm = 1.6263e-01, time/batch = 16.5579s	
22916/33650 (epoch 34.051), train_loss = 1.00799950, grad/param norm = 2.0718e-01, time/batch = 17.4960s	
22917/33650 (epoch 34.052), train_loss = 0.99560031, grad/param norm = 1.7964e-01, time/batch = 17.4002s	
22918/33650 (epoch 34.053), train_loss = 0.93387899, grad/param norm = 1.6312e-01, time/batch = 16.8974s	
22919/33650 (epoch 34.055), train_loss = 0.80106973, grad/param norm = 1.5245e-01, time/batch = 17.8048s	
22920/33650 (epoch 34.056), train_loss = 0.76165232, grad/param norm = 1.3323e-01, time/batch = 16.8232s	
22921/33650 (epoch 34.058), train_loss = 0.94412688, grad/param norm = 1.8285e-01, time/batch = 16.0538s	
22922/33650 (epoch 34.059), train_loss = 0.95042126, grad/param norm = 1.8878e-01, time/batch = 16.8947s	
22923/33650 (epoch 34.061), train_loss = 0.95154901, grad/param norm = 1.7221e-01, time/batch = 18.3990s	
22924/33650 (epoch 34.062), train_loss = 0.91520480, grad/param norm = 1.6898e-01, time/batch = 17.5682s	
22925/33650 (epoch 34.064), train_loss = 0.83723784, grad/param norm = 1.5755e-01, time/batch = 16.0523s	
22926/33650 (epoch 34.065), train_loss = 0.83788548, grad/param norm = 1.6658e-01, time/batch = 16.8134s	
22927/33650 (epoch 34.067), train_loss = 0.78533205, grad/param norm = 1.3814e-01, time/batch = 17.8175s	
22928/33650 (epoch 34.068), train_loss = 0.86993995, grad/param norm = 1.5179e-01, time/batch = 17.3964s	
22929/33650 (epoch 34.070), train_loss = 0.92777516, grad/param norm = 1.6008e-01, time/batch = 17.1328s	
22930/33650 (epoch 34.071), train_loss = 0.82492591, grad/param norm = 1.5742e-01, time/batch = 17.3943s	
22931/33650 (epoch 34.073), train_loss = 0.88954566, grad/param norm = 1.7551e-01, time/batch = 17.4074s	
22932/33650 (epoch 34.074), train_loss = 0.96480006, grad/param norm = 1.6099e-01, time/batch = 16.9789s	
22933/33650 (epoch 34.076), train_loss = 0.92915306, grad/param norm = 1.9021e-01, time/batch = 17.0803s	
22934/33650 (epoch 34.077), train_loss = 0.84673514, grad/param norm = 1.5325e-01, time/batch = 16.9869s	
22935/33650 (epoch 34.079), train_loss = 0.91029156, grad/param norm = 1.6009e-01, time/batch = 16.0588s	
22936/33650 (epoch 34.080), train_loss = 0.91152662, grad/param norm = 1.8707e-01, time/batch = 16.6452s	
22937/33650 (epoch 34.082), train_loss = 0.87431011, grad/param norm = 1.6006e-01, time/batch = 17.8201s	
22938/33650 (epoch 34.083), train_loss = 0.89659008, grad/param norm = 1.7924e-01, time/batch = 16.8974s	
22939/33650 (epoch 34.085), train_loss = 0.95503468, grad/param norm = 1.5992e-01, time/batch = 14.6994s	
22940/33650 (epoch 34.086), train_loss = 0.90406469, grad/param norm = 1.6564e-01, time/batch = 17.7209s	
22941/33650 (epoch 34.088), train_loss = 0.86486046, grad/param norm = 1.6108e-01, time/batch = 17.8164s	
22942/33650 (epoch 34.089), train_loss = 0.80844648, grad/param norm = 1.7235e-01, time/batch = 16.8856s	
22943/33650 (epoch 34.091), train_loss = 0.86066394, grad/param norm = 1.5427e-01, time/batch = 16.7175s	
22944/33650 (epoch 34.092), train_loss = 0.86516756, grad/param norm = 1.9318e-01, time/batch = 18.0601s	
22945/33650 (epoch 34.094), train_loss = 0.95482763, grad/param norm = 1.7903e-01, time/batch = 17.4053s	
22946/33650 (epoch 34.095), train_loss = 0.92831613, grad/param norm = 2.0106e-01, time/batch = 16.8124s	
22947/33650 (epoch 34.097), train_loss = 0.81918848, grad/param norm = 1.8249e-01, time/batch = 17.4086s	
22948/33650 (epoch 34.098), train_loss = 0.71152862, grad/param norm = 1.5959e-01, time/batch = 17.2475s	
22949/33650 (epoch 34.100), train_loss = 0.78601752, grad/param norm = 1.4951e-01, time/batch = 16.3069s	
22950/33650 (epoch 34.101), train_loss = 0.88128109, grad/param norm = 1.8114e-01, time/batch = 17.2142s	
22951/33650 (epoch 34.103), train_loss = 0.86337715, grad/param norm = 1.7178e-01, time/batch = 17.5731s	
22952/33650 (epoch 34.104), train_loss = 0.99697551, grad/param norm = 1.5873e-01, time/batch = 16.6226s	
22953/33650 (epoch 34.105), train_loss = 0.90850842, grad/param norm = 1.8373e-01, time/batch = 17.4016s	
22954/33650 (epoch 34.107), train_loss = 0.83111241, grad/param norm = 1.5537e-01, time/batch = 17.8160s	
22955/33650 (epoch 34.108), train_loss = 0.90819438, grad/param norm = 1.6145e-01, time/batch = 17.7266s	
22956/33650 (epoch 34.110), train_loss = 1.01184960, grad/param norm = 1.7859e-01, time/batch = 16.3972s	
22957/33650 (epoch 34.111), train_loss = 0.85728056, grad/param norm = 1.6915e-01, time/batch = 17.3198s	
22958/33650 (epoch 34.113), train_loss = 0.83670795, grad/param norm = 1.6829e-01, time/batch = 17.9143s	
22959/33650 (epoch 34.114), train_loss = 0.93488789, grad/param norm = 1.5639e-01, time/batch = 17.1579s	
22960/33650 (epoch 34.116), train_loss = 0.81514332, grad/param norm = 1.4568e-01, time/batch = 15.6399s	
22961/33650 (epoch 34.117), train_loss = 0.85400565, grad/param norm = 1.5786e-01, time/batch = 17.1502s	
22962/33650 (epoch 34.119), train_loss = 0.78135760, grad/param norm = 1.2798e-01, time/batch = 18.2338s	
22963/33650 (epoch 34.120), train_loss = 0.79916972, grad/param norm = 1.5350e-01, time/batch = 15.2151s	
22964/33650 (epoch 34.122), train_loss = 0.66490921, grad/param norm = 1.4831e-01, time/batch = 17.2210s	
22965/33650 (epoch 34.123), train_loss = 0.81293717, grad/param norm = 1.4748e-01, time/batch = 18.2391s	
22966/33650 (epoch 34.125), train_loss = 0.92109181, grad/param norm = 1.6642e-01, time/batch = 17.8941s	
22967/33650 (epoch 34.126), train_loss = 0.94647564, grad/param norm = 1.9571e-01, time/batch = 16.3794s	
22968/33650 (epoch 34.128), train_loss = 0.91158078, grad/param norm = 1.6410e-01, time/batch = 17.9769s	
22969/33650 (epoch 34.129), train_loss = 0.92631940, grad/param norm = 1.6179e-01, time/batch = 16.8050s	
22970/33650 (epoch 34.131), train_loss = 0.87453604, grad/param norm = 1.6165e-01, time/batch = 16.6528s	
22971/33650 (epoch 34.132), train_loss = 0.88409087, grad/param norm = 1.7392e-01, time/batch = 16.4837s	
22972/33650 (epoch 34.134), train_loss = 0.94499044, grad/param norm = 1.8781e-01, time/batch = 18.3885s	
22973/33650 (epoch 34.135), train_loss = 0.74863186, grad/param norm = 1.3297e-01, time/batch = 17.3828s	
22974/33650 (epoch 34.137), train_loss = 0.91217872, grad/param norm = 1.9700e-01, time/batch = 16.0576s	
22975/33650 (epoch 34.138), train_loss = 0.93164351, grad/param norm = 1.6292e-01, time/batch = 16.8166s	
22976/33650 (epoch 34.140), train_loss = 0.89858596, grad/param norm = 1.9342e-01, time/batch = 17.9848s	
22977/33650 (epoch 34.141), train_loss = 1.00103218, grad/param norm = 1.7688e-01, time/batch = 17.1451s	
22978/33650 (epoch 34.143), train_loss = 1.02197554, grad/param norm = 1.9105e-01, time/batch = 16.9025s	
22979/33650 (epoch 34.144), train_loss = 0.90921079, grad/param norm = 1.7968e-01, time/batch = 16.9218s	
22980/33650 (epoch 34.146), train_loss = 0.87089007, grad/param norm = 1.6415e-01, time/batch = 17.8320s	
22981/33650 (epoch 34.147), train_loss = 0.79424411, grad/param norm = 1.6507e-01, time/batch = 16.9709s	
22982/33650 (epoch 34.149), train_loss = 0.77929651, grad/param norm = 1.6204e-01, time/batch = 17.9871s	
22983/33650 (epoch 34.150), train_loss = 0.75576082, grad/param norm = 1.4934e-01, time/batch = 15.9673s	
22984/33650 (epoch 34.152), train_loss = 0.82192550, grad/param norm = 1.5530e-01, time/batch = 15.1966s	
22985/33650 (epoch 34.153), train_loss = 0.85207537, grad/param norm = 1.8083e-01, time/batch = 16.5798s	
22986/33650 (epoch 34.155), train_loss = 0.80008833, grad/param norm = 1.4832e-01, time/batch = 17.9798s	
22987/33650 (epoch 34.156), train_loss = 0.78501892, grad/param norm = 1.3203e-01, time/batch = 17.2428s	
22988/33650 (epoch 34.158), train_loss = 0.89617044, grad/param norm = 1.5668e-01, time/batch = 16.3995s	
22989/33650 (epoch 34.159), train_loss = 0.81077030, grad/param norm = 1.5477e-01, time/batch = 16.7329s	
22990/33650 (epoch 34.160), train_loss = 0.79739325, grad/param norm = 1.5005e-01, time/batch = 17.8135s	
22991/33650 (epoch 34.162), train_loss = 0.81723173, grad/param norm = 1.5565e-01, time/batch = 16.8834s	
22992/33650 (epoch 34.163), train_loss = 0.90126799, grad/param norm = 1.6948e-01, time/batch = 17.2340s	
22993/33650 (epoch 34.165), train_loss = 0.76893663, grad/param norm = 1.6346e-01, time/batch = 17.9946s	
22994/33650 (epoch 34.166), train_loss = 0.76095088, grad/param norm = 1.8281e-01, time/batch = 15.5539s	
22995/33650 (epoch 34.168), train_loss = 0.97609756, grad/param norm = 1.9522e-01, time/batch = 29.1704s	
22996/33650 (epoch 34.169), train_loss = 0.85671200, grad/param norm = 2.0218e-01, time/batch = 18.0595s	
22997/33650 (epoch 34.171), train_loss = 0.86009361, grad/param norm = 1.4841e-01, time/batch = 17.2937s	
22998/33650 (epoch 34.172), train_loss = 0.81628311, grad/param norm = 1.5676e-01, time/batch = 16.0610s	
22999/33650 (epoch 34.174), train_loss = 0.78266158, grad/param norm = 1.5752e-01, time/batch = 17.5679s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch34.18_1.7352.t7	
23000/33650 (epoch 34.175), train_loss = 0.74253577, grad/param norm = 1.6992e-01, time/batch = 17.7512s	
23001/33650 (epoch 34.177), train_loss = 1.27561308, grad/param norm = 2.1579e-01, time/batch = 16.2410s	
23002/33650 (epoch 34.178), train_loss = 0.83196505, grad/param norm = 2.0348e-01, time/batch = 18.1515s	
23003/33650 (epoch 34.180), train_loss = 0.77011997, grad/param norm = 1.4496e-01, time/batch = 16.9823s	
23004/33650 (epoch 34.181), train_loss = 0.69501931, grad/param norm = 1.4844e-01, time/batch = 16.6467s	
23005/33650 (epoch 34.183), train_loss = 0.79154380, grad/param norm = 1.6299e-01, time/batch = 17.9096s	
23006/33650 (epoch 34.184), train_loss = 0.77024461, grad/param norm = 1.6245e-01, time/batch = 17.7323s	
23007/33650 (epoch 34.186), train_loss = 0.83130966, grad/param norm = 1.9852e-01, time/batch = 16.5629s	
23008/33650 (epoch 34.187), train_loss = 0.96668437, grad/param norm = 1.7961e-01, time/batch = 17.9886s	
23009/33650 (epoch 34.189), train_loss = 0.95405004, grad/param norm = 2.0044e-01, time/batch = 17.8208s	
23010/33650 (epoch 34.190), train_loss = 0.88009061, grad/param norm = 1.7739e-01, time/batch = 17.6408s	
23011/33650 (epoch 34.192), train_loss = 1.01972139, grad/param norm = 1.6926e-01, time/batch = 16.4826s	
23012/33650 (epoch 34.193), train_loss = 0.98674062, grad/param norm = 1.6852e-01, time/batch = 16.3941s	
23013/33650 (epoch 34.195), train_loss = 0.75850642, grad/param norm = 1.5042e-01, time/batch = 17.8987s	
23014/33650 (epoch 34.196), train_loss = 0.70701928, grad/param norm = 1.4994e-01, time/batch = 16.0626s	
23015/33650 (epoch 34.198), train_loss = 0.85745043, grad/param norm = 1.6131e-01, time/batch = 17.7248s	
23016/33650 (epoch 34.199), train_loss = 0.93195499, grad/param norm = 1.8224e-01, time/batch = 17.2302s	
23017/33650 (epoch 34.201), train_loss = 0.79938432, grad/param norm = 1.7661e-01, time/batch = 16.5589s	
23018/33650 (epoch 34.202), train_loss = 0.85545318, grad/param norm = 1.6206e-01, time/batch = 16.8810s	
23019/33650 (epoch 34.204), train_loss = 0.89097923, grad/param norm = 1.5508e-01, time/batch = 18.1616s	
23020/33650 (epoch 34.205), train_loss = 0.84615759, grad/param norm = 1.7864e-01, time/batch = 17.4077s	
23021/33650 (epoch 34.207), train_loss = 0.79584856, grad/param norm = 1.9891e-01, time/batch = 16.8915s	
23022/33650 (epoch 34.208), train_loss = 0.87754358, grad/param norm = 1.5704e-01, time/batch = 16.9063s	
23023/33650 (epoch 34.210), train_loss = 0.71583117, grad/param norm = 1.7361e-01, time/batch = 18.3251s	
23024/33650 (epoch 34.211), train_loss = 0.80490891, grad/param norm = 1.8217e-01, time/batch = 16.2830s	
23025/33650 (epoch 34.212), train_loss = 0.89490836, grad/param norm = 2.1375e-01, time/batch = 16.2402s	
23026/33650 (epoch 34.214), train_loss = 1.04089952, grad/param norm = 1.8894e-01, time/batch = 17.5786s	
23027/33650 (epoch 34.215), train_loss = 0.68286207, grad/param norm = 1.6716e-01, time/batch = 17.4176s	
23028/33650 (epoch 34.217), train_loss = 0.83211289, grad/param norm = 2.3306e-01, time/batch = 16.8839s	
23029/33650 (epoch 34.218), train_loss = 0.83731444, grad/param norm = 1.5207e-01, time/batch = 17.1566s	
23030/33650 (epoch 34.220), train_loss = 0.73638057, grad/param norm = 1.5989e-01, time/batch = 16.8194s	
23031/33650 (epoch 34.221), train_loss = 1.00749163, grad/param norm = 1.9310e-01, time/batch = 16.5630s	
23032/33650 (epoch 34.223), train_loss = 0.69898260, grad/param norm = 1.7101e-01, time/batch = 16.8997s	
23033/33650 (epoch 34.224), train_loss = 0.82518693, grad/param norm = 2.5460e-01, time/batch = 17.6557s	
23034/33650 (epoch 34.226), train_loss = 1.09920592, grad/param norm = 1.6907e-01, time/batch = 16.9883s	
23035/33650 (epoch 34.227), train_loss = 0.94078229, grad/param norm = 1.7487e-01, time/batch = 15.7973s	
23036/33650 (epoch 34.229), train_loss = 0.96495135, grad/param norm = 1.7608e-01, time/batch = 16.5645s	
23037/33650 (epoch 34.230), train_loss = 1.09473618, grad/param norm = 2.2213e-01, time/batch = 17.2426s	
23038/33650 (epoch 34.232), train_loss = 0.92355967, grad/param norm = 1.9593e-01, time/batch = 15.9736s	
23039/33650 (epoch 34.233), train_loss = 0.91501424, grad/param norm = 2.0538e-01, time/batch = 17.3919s	
23040/33650 (epoch 34.235), train_loss = 0.85768336, grad/param norm = 1.7587e-01, time/batch = 17.6478s	
23041/33650 (epoch 34.236), train_loss = 0.79486438, grad/param norm = 1.4795e-01, time/batch = 17.4078s	
23042/33650 (epoch 34.238), train_loss = 0.82488947, grad/param norm = 1.5055e-01, time/batch = 17.3069s	
23043/33650 (epoch 34.239), train_loss = 0.78641293, grad/param norm = 1.7237e-01, time/batch = 17.2533s	
23044/33650 (epoch 34.241), train_loss = 0.84156834, grad/param norm = 1.4966e-01, time/batch = 16.4677s	
23045/33650 (epoch 34.242), train_loss = 0.69341734, grad/param norm = 1.5632e-01, time/batch = 17.3736s	
23046/33650 (epoch 34.244), train_loss = 0.84133975, grad/param norm = 1.6736e-01, time/batch = 17.2361s	
23047/33650 (epoch 34.245), train_loss = 0.73943050, grad/param norm = 1.4413e-01, time/batch = 16.9141s	
23048/33650 (epoch 34.247), train_loss = 0.81034143, grad/param norm = 1.5141e-01, time/batch = 17.7309s	
23049/33650 (epoch 34.248), train_loss = 0.74809065, grad/param norm = 1.5966e-01, time/batch = 15.2348s	
23050/33650 (epoch 34.250), train_loss = 0.85897513, grad/param norm = 1.6841e-01, time/batch = 17.8154s	
23051/33650 (epoch 34.251), train_loss = 0.94674925, grad/param norm = 1.6233e-01, time/batch = 17.7418s	
23052/33650 (epoch 34.253), train_loss = 0.75793035, grad/param norm = 1.6125e-01, time/batch = 15.8137s	
23053/33650 (epoch 34.254), train_loss = 0.83419211, grad/param norm = 1.6884e-01, time/batch = 17.3144s	
23054/33650 (epoch 34.256), train_loss = 0.97761488, grad/param norm = 1.6604e-01, time/batch = 17.0669s	
23055/33650 (epoch 34.257), train_loss = 0.94281606, grad/param norm = 1.7871e-01, time/batch = 17.6568s	
23056/33650 (epoch 34.259), train_loss = 0.77802241, grad/param norm = 1.5920e-01, time/batch = 16.4511s	
23057/33650 (epoch 34.260), train_loss = 0.88468232, grad/param norm = 1.6474e-01, time/batch = 16.8251s	
23058/33650 (epoch 34.262), train_loss = 0.86508697, grad/param norm = 1.9702e-01, time/batch = 17.3725s	
23059/33650 (epoch 34.263), train_loss = 0.83041568, grad/param norm = 2.1359e-01, time/batch = 16.9733s	
23060/33650 (epoch 34.264), train_loss = 0.93012456, grad/param norm = 1.9343e-01, time/batch = 17.7298s	
23061/33650 (epoch 34.266), train_loss = 0.89914975, grad/param norm = 1.5910e-01, time/batch = 18.0664s	
23062/33650 (epoch 34.267), train_loss = 0.82131197, grad/param norm = 1.7802e-01, time/batch = 16.9068s	
23063/33650 (epoch 34.269), train_loss = 0.86085305, grad/param norm = 1.5853e-01, time/batch = 16.8814s	
23064/33650 (epoch 34.270), train_loss = 0.76821043, grad/param norm = 1.5595e-01, time/batch = 17.8223s	
23065/33650 (epoch 34.272), train_loss = 0.81259187, grad/param norm = 1.4765e-01, time/batch = 15.9023s	
23066/33650 (epoch 34.273), train_loss = 0.94131351, grad/param norm = 2.0465e-01, time/batch = 15.3094s	
23067/33650 (epoch 34.275), train_loss = 0.90805030, grad/param norm = 1.6995e-01, time/batch = 17.1492s	
23068/33650 (epoch 34.276), train_loss = 0.93281956, grad/param norm = 2.0233e-01, time/batch = 17.4002s	
23069/33650 (epoch 34.278), train_loss = 1.04106173, grad/param norm = 2.0083e-01, time/batch = 17.5775s	
23070/33650 (epoch 34.279), train_loss = 0.84279200, grad/param norm = 1.5088e-01, time/batch = 16.6367s	
23071/33650 (epoch 34.281), train_loss = 0.87324580, grad/param norm = 1.5937e-01, time/batch = 17.4771s	
23072/33650 (epoch 34.282), train_loss = 0.97409603, grad/param norm = 1.3991e-01, time/batch = 17.5747s	
23073/33650 (epoch 34.284), train_loss = 0.92533334, grad/param norm = 1.7680e-01, time/batch = 17.0648s	
23074/33650 (epoch 34.285), train_loss = 0.90945225, grad/param norm = 1.8245e-01, time/batch = 16.6515s	
23075/33650 (epoch 34.287), train_loss = 0.83715459, grad/param norm = 1.7222e-01, time/batch = 18.0672s	
23076/33650 (epoch 34.288), train_loss = 0.84804266, grad/param norm = 2.0856e-01, time/batch = 18.3267s	
23077/33650 (epoch 34.290), train_loss = 0.85349653, grad/param norm = 1.5497e-01, time/batch = 16.4580s	
23078/33650 (epoch 34.291), train_loss = 0.80197219, grad/param norm = 1.9400e-01, time/batch = 17.3158s	
23079/33650 (epoch 34.293), train_loss = 0.87008421, grad/param norm = 1.7885e-01, time/batch = 17.8180s	
23080/33650 (epoch 34.294), train_loss = 0.79831436, grad/param norm = 1.3190e-01, time/batch = 16.8118s	
23081/33650 (epoch 34.296), train_loss = 0.76396002, grad/param norm = 1.6765e-01, time/batch = 17.7306s	
23082/33650 (epoch 34.297), train_loss = 0.82717223, grad/param norm = 1.6524e-01, time/batch = 16.6565s	
23083/33650 (epoch 34.299), train_loss = 0.72936957, grad/param norm = 1.6429e-01, time/batch = 17.2279s	
23084/33650 (epoch 34.300), train_loss = 0.76921299, grad/param norm = 1.6082e-01, time/batch = 16.7276s	
23085/33650 (epoch 34.302), train_loss = 0.86855546, grad/param norm = 1.4677e-01, time/batch = 16.6633s	
23086/33650 (epoch 34.303), train_loss = 0.87727512, grad/param norm = 1.4288e-01, time/batch = 16.8210s	
23087/33650 (epoch 34.305), train_loss = 0.84175961, grad/param norm = 1.5351e-01, time/batch = 15.7995s	
23088/33650 (epoch 34.306), train_loss = 0.78154708, grad/param norm = 1.3502e-01, time/batch = 17.4013s	
23089/33650 (epoch 34.308), train_loss = 0.74098242, grad/param norm = 1.6327e-01, time/batch = 17.4875s	
23090/33650 (epoch 34.309), train_loss = 0.98588596, grad/param norm = 2.1199e-01, time/batch = 16.7300s	
23091/33650 (epoch 34.311), train_loss = 0.85422524, grad/param norm = 1.7090e-01, time/batch = 16.0353s	
23092/33650 (epoch 34.312), train_loss = 0.90408560, grad/param norm = 1.7424e-01, time/batch = 15.3092s	
23093/33650 (epoch 34.314), train_loss = 0.79638834, grad/param norm = 1.5862e-01, time/batch = 17.5013s	
23094/33650 (epoch 34.315), train_loss = 0.83988871, grad/param norm = 2.0993e-01, time/batch = 16.9934s	
23095/33650 (epoch 34.316), train_loss = 0.80717120, grad/param norm = 1.7616e-01, time/batch = 17.3182s	
23096/33650 (epoch 34.318), train_loss = 0.76214131, grad/param norm = 1.5581e-01, time/batch = 17.5675s	
23097/33650 (epoch 34.319), train_loss = 0.78055617, grad/param norm = 1.4211e-01, time/batch = 17.9034s	
23098/33650 (epoch 34.321), train_loss = 0.82529084, grad/param norm = 1.4825e-01, time/batch = 17.2914s	
23099/33650 (epoch 34.322), train_loss = 0.88444485, grad/param norm = 1.9804e-01, time/batch = 16.7296s	
23100/33650 (epoch 34.324), train_loss = 0.89602049, grad/param norm = 1.9182e-01, time/batch = 16.8134s	
23101/33650 (epoch 34.325), train_loss = 0.88669195, grad/param norm = 1.5723e-01, time/batch = 16.8069s	
23102/33650 (epoch 34.327), train_loss = 0.80002070, grad/param norm = 1.4051e-01, time/batch = 17.9763s	
23103/33650 (epoch 34.328), train_loss = 0.86648873, grad/param norm = 1.6866e-01, time/batch = 17.4832s	
23104/33650 (epoch 34.330), train_loss = 0.80502698, grad/param norm = 1.5095e-01, time/batch = 16.1391s	
23105/33650 (epoch 34.331), train_loss = 0.74848218, grad/param norm = 1.3917e-01, time/batch = 17.0402s	
23106/33650 (epoch 34.333), train_loss = 0.82258805, grad/param norm = 1.7226e-01, time/batch = 16.9962s	
23107/33650 (epoch 34.334), train_loss = 0.84402506, grad/param norm = 1.5825e-01, time/batch = 17.7986s	
23108/33650 (epoch 34.336), train_loss = 0.94068885, grad/param norm = 1.5779e-01, time/batch = 16.5594s	
23109/33650 (epoch 34.337), train_loss = 0.72651031, grad/param norm = 1.3546e-01, time/batch = 17.8122s	
23110/33650 (epoch 34.339), train_loss = 0.81313808, grad/param norm = 1.5106e-01, time/batch = 17.3853s	
23111/33650 (epoch 34.340), train_loss = 0.94148574, grad/param norm = 2.0169e-01, time/batch = 17.9027s	
23112/33650 (epoch 34.342), train_loss = 0.70800839, grad/param norm = 1.5427e-01, time/batch = 16.8064s	
23113/33650 (epoch 34.343), train_loss = 0.89283070, grad/param norm = 1.6175e-01, time/batch = 17.6417s	
23114/33650 (epoch 34.345), train_loss = 0.88591581, grad/param norm = 2.0192e-01, time/batch = 17.0612s	
23115/33650 (epoch 34.346), train_loss = 0.60061081, grad/param norm = 1.4000e-01, time/batch = 17.0668s	
23116/33650 (epoch 34.348), train_loss = 0.73885040, grad/param norm = 1.5676e-01, time/batch = 17.8945s	
23117/33650 (epoch 34.349), train_loss = 0.69017836, grad/param norm = 1.4519e-01, time/batch = 16.7323s	
23118/33650 (epoch 34.351), train_loss = 0.86834395, grad/param norm = 1.5480e-01, time/batch = 17.7336s	
23119/33650 (epoch 34.352), train_loss = 0.81899277, grad/param norm = 1.7888e-01, time/batch = 17.2958s	
23120/33650 (epoch 34.354), train_loss = 0.95798874, grad/param norm = 1.9595e-01, time/batch = 17.5574s	
23121/33650 (epoch 34.355), train_loss = 0.97376836, grad/param norm = 1.5319e-01, time/batch = 17.1563s	
23122/33650 (epoch 34.357), train_loss = 0.70524560, grad/param norm = 1.4199e-01, time/batch = 17.0642s	
23123/33650 (epoch 34.358), train_loss = 0.85795867, grad/param norm = 1.7837e-01, time/batch = 17.3147s	
23124/33650 (epoch 34.360), train_loss = 0.90082431, grad/param norm = 1.8260e-01, time/batch = 17.4806s	
23125/33650 (epoch 34.361), train_loss = 0.86928946, grad/param norm = 1.6602e-01, time/batch = 16.8912s	
23126/33650 (epoch 34.363), train_loss = 0.86236359, grad/param norm = 1.4425e-01, time/batch = 17.7222s	
23127/33650 (epoch 34.364), train_loss = 0.84748267, grad/param norm = 1.5178e-01, time/batch = 15.5591s	
23128/33650 (epoch 34.366), train_loss = 0.90747413, grad/param norm = 2.0724e-01, time/batch = 17.9781s	
23129/33650 (epoch 34.367), train_loss = 0.89363068, grad/param norm = 1.5962e-01, time/batch = 15.9782s	
23130/33650 (epoch 34.368), train_loss = 0.81361117, grad/param norm = 1.3955e-01, time/batch = 17.5643s	
23131/33650 (epoch 34.370), train_loss = 0.83921565, grad/param norm = 1.5879e-01, time/batch = 16.2197s	
23132/33650 (epoch 34.371), train_loss = 0.66757692, grad/param norm = 1.4978e-01, time/batch = 17.6529s	
23133/33650 (epoch 34.373), train_loss = 0.74899354, grad/param norm = 1.5533e-01, time/batch = 17.3167s	
23134/33650 (epoch 34.374), train_loss = 0.77214687, grad/param norm = 1.4034e-01, time/batch = 17.5748s	
23135/33650 (epoch 34.376), train_loss = 0.82750495, grad/param norm = 1.9636e-01, time/batch = 17.9086s	
23136/33650 (epoch 34.377), train_loss = 0.86885455, grad/param norm = 1.5691e-01, time/batch = 16.7376s	
23137/33650 (epoch 34.379), train_loss = 0.88290865, grad/param norm = 1.7080e-01, time/batch = 18.3222s	
23138/33650 (epoch 34.380), train_loss = 0.73080495, grad/param norm = 2.1159e-01, time/batch = 17.0649s	
23139/33650 (epoch 34.382), train_loss = 0.85838753, grad/param norm = 1.3669e-01, time/batch = 17.0602s	
23140/33650 (epoch 34.383), train_loss = 0.83624198, grad/param norm = 1.7590e-01, time/batch = 18.0690s	
23141/33650 (epoch 34.385), train_loss = 0.87977109, grad/param norm = 1.7122e-01, time/batch = 17.8272s	
23142/33650 (epoch 34.386), train_loss = 0.78140460, grad/param norm = 1.6022e-01, time/batch = 17.4068s	
23143/33650 (epoch 34.388), train_loss = 0.92455742, grad/param norm = 1.6631e-01, time/batch = 16.7934s	
23144/33650 (epoch 34.389), train_loss = 0.77267854, grad/param norm = 1.5262e-01, time/batch = 18.1563s	
23145/33650 (epoch 34.391), train_loss = 0.65767492, grad/param norm = 1.3232e-01, time/batch = 18.4807s	
23146/33650 (epoch 34.392), train_loss = 0.86401935, grad/param norm = 1.6712e-01, time/batch = 15.9862s	
23147/33650 (epoch 34.394), train_loss = 0.85432515, grad/param norm = 1.6377e-01, time/batch = 16.7898s	
23148/33650 (epoch 34.395), train_loss = 0.87402757, grad/param norm = 1.5320e-01, time/batch = 17.4006s	
23149/33650 (epoch 34.397), train_loss = 1.00423265, grad/param norm = 1.8309e-01, time/batch = 18.1430s	
23150/33650 (epoch 34.398), train_loss = 0.91461851, grad/param norm = 1.6045e-01, time/batch = 15.7187s	
23151/33650 (epoch 34.400), train_loss = 0.83143625, grad/param norm = 1.7101e-01, time/batch = 15.6390s	
23152/33650 (epoch 34.401), train_loss = 0.79147473, grad/param norm = 1.8115e-01, time/batch = 16.8254s	
23153/33650 (epoch 34.403), train_loss = 0.90309385, grad/param norm = 1.8793e-01, time/batch = 16.9071s	
23154/33650 (epoch 34.404), train_loss = 0.85030118, grad/param norm = 2.1596e-01, time/batch = 14.6644s	
23155/33650 (epoch 34.406), train_loss = 0.82606108, grad/param norm = 1.6966e-01, time/batch = 13.2603s	
23156/33650 (epoch 34.407), train_loss = 0.85277308, grad/param norm = 1.7553e-01, time/batch = 13.2574s	
23157/33650 (epoch 34.409), train_loss = 0.88289334, grad/param norm = 1.9632e-01, time/batch = 15.1285s	
23158/33650 (epoch 34.410), train_loss = 0.82837278, grad/param norm = 1.5842e-01, time/batch = 17.1439s	
23159/33650 (epoch 34.412), train_loss = 0.86480859, grad/param norm = 1.6127e-01, time/batch = 17.0691s	
23160/33650 (epoch 34.413), train_loss = 0.80512316, grad/param norm = 1.8132e-01, time/batch = 18.2450s	
23161/33650 (epoch 34.415), train_loss = 0.92307515, grad/param norm = 1.6586e-01, time/batch = 16.4638s	
23162/33650 (epoch 34.416), train_loss = 1.00596863, grad/param norm = 1.8804e-01, time/batch = 17.5739s	
23163/33650 (epoch 34.418), train_loss = 0.76855263, grad/param norm = 1.5034e-01, time/batch = 17.1538s	
23164/33650 (epoch 34.419), train_loss = 0.78910005, grad/param norm = 1.6728e-01, time/batch = 16.3061s	
23165/33650 (epoch 34.421), train_loss = 0.80396241, grad/param norm = 1.4043e-01, time/batch = 16.7261s	
23166/33650 (epoch 34.422), train_loss = 0.97427768, grad/param norm = 1.6828e-01, time/batch = 16.7293s	
23167/33650 (epoch 34.423), train_loss = 0.76357390, grad/param norm = 1.2738e-01, time/batch = 17.9771s	
23168/33650 (epoch 34.425), train_loss = 0.87862832, grad/param norm = 1.7226e-01, time/batch = 16.5647s	
23169/33650 (epoch 34.426), train_loss = 0.91761797, grad/param norm = 1.8074e-01, time/batch = 17.3929s	
23170/33650 (epoch 34.428), train_loss = 0.82318304, grad/param norm = 1.6423e-01, time/batch = 16.8095s	
23171/33650 (epoch 34.429), train_loss = 0.91327961, grad/param norm = 1.9614e-01, time/batch = 17.1415s	
23172/33650 (epoch 34.431), train_loss = 1.01272191, grad/param norm = 2.1172e-01, time/batch = 16.9703s	
23173/33650 (epoch 34.432), train_loss = 1.01329429, grad/param norm = 2.0176e-01, time/batch = 18.0600s	
23174/33650 (epoch 34.434), train_loss = 0.88670399, grad/param norm = 1.7116e-01, time/batch = 16.7067s	
23175/33650 (epoch 34.435), train_loss = 0.86839611, grad/param norm = 1.8618e-01, time/batch = 15.8844s	
23176/33650 (epoch 34.437), train_loss = 0.85150970, grad/param norm = 1.7187e-01, time/batch = 17.0669s	
23177/33650 (epoch 34.438), train_loss = 0.83964155, grad/param norm = 1.9211e-01, time/batch = 16.7226s	
23178/33650 (epoch 34.440), train_loss = 0.85579707, grad/param norm = 1.7826e-01, time/batch = 16.9834s	
23179/33650 (epoch 34.441), train_loss = 0.84774538, grad/param norm = 1.7427e-01, time/batch = 16.6411s	
23180/33650 (epoch 34.443), train_loss = 0.93338197, grad/param norm = 1.5820e-01, time/batch = 17.8191s	
23181/33650 (epoch 34.444), train_loss = 0.84557406, grad/param norm = 1.6931e-01, time/batch = 18.3151s	
23182/33650 (epoch 34.446), train_loss = 0.90017664, grad/param norm = 2.0194e-01, time/batch = 16.4812s	
23183/33650 (epoch 34.447), train_loss = 0.97442933, grad/param norm = 1.9150e-01, time/batch = 18.2439s	
23184/33650 (epoch 34.449), train_loss = 0.97134840, grad/param norm = 1.9452e-01, time/batch = 17.4033s	
23185/33650 (epoch 34.450), train_loss = 1.01567151, grad/param norm = 2.1336e-01, time/batch = 15.8901s	
23186/33650 (epoch 34.452), train_loss = 0.97829876, grad/param norm = 1.8638e-01, time/batch = 16.3173s	
23187/33650 (epoch 34.453), train_loss = 1.02094320, grad/param norm = 1.9213e-01, time/batch = 17.2289s	
23188/33650 (epoch 34.455), train_loss = 0.85151261, grad/param norm = 1.5405e-01, time/batch = 17.8968s	
23189/33650 (epoch 34.456), train_loss = 0.87431524, grad/param norm = 1.7613e-01, time/batch = 15.9931s	
23190/33650 (epoch 34.458), train_loss = 0.85102432, grad/param norm = 1.8631e-01, time/batch = 17.2450s	
23191/33650 (epoch 34.459), train_loss = 0.89714837, grad/param norm = 1.9850e-01, time/batch = 17.4860s	
23192/33650 (epoch 34.461), train_loss = 0.93030750, grad/param norm = 1.8275e-01, time/batch = 17.4069s	
23193/33650 (epoch 34.462), train_loss = 0.95906067, grad/param norm = 1.8492e-01, time/batch = 16.8762s	
23194/33650 (epoch 34.464), train_loss = 0.82849119, grad/param norm = 2.0142e-01, time/batch = 17.7449s	
23195/33650 (epoch 34.465), train_loss = 0.90860185, grad/param norm = 2.3002e-01, time/batch = 17.9822s	
23196/33650 (epoch 34.467), train_loss = 0.88273016, grad/param norm = 1.5976e-01, time/batch = 29.7478s	
23197/33650 (epoch 34.468), train_loss = 1.02576135, grad/param norm = 1.7307e-01, time/batch = 17.0649s	
23198/33650 (epoch 34.470), train_loss = 1.07870991, grad/param norm = 1.8737e-01, time/batch = 17.4878s	
23199/33650 (epoch 34.471), train_loss = 0.87175149, grad/param norm = 1.7627e-01, time/batch = 16.1371s	
23200/33650 (epoch 34.473), train_loss = 0.84590981, grad/param norm = 1.6083e-01, time/batch = 16.9545s	
23201/33650 (epoch 34.474), train_loss = 0.97950308, grad/param norm = 1.8289e-01, time/batch = 18.1467s	
23202/33650 (epoch 34.475), train_loss = 0.94378997, grad/param norm = 1.7395e-01, time/batch = 16.8933s	
23203/33650 (epoch 34.477), train_loss = 0.98170639, grad/param norm = 1.9178e-01, time/batch = 16.5786s	
23204/33650 (epoch 34.478), train_loss = 0.97057894, grad/param norm = 1.8138e-01, time/batch = 16.2880s	
23205/33650 (epoch 34.480), train_loss = 0.95416834, grad/param norm = 2.1567e-01, time/batch = 17.1596s	
23206/33650 (epoch 34.481), train_loss = 0.99250381, grad/param norm = 1.6939e-01, time/batch = 16.3997s	
23207/33650 (epoch 34.483), train_loss = 0.74685660, grad/param norm = 1.5232e-01, time/batch = 17.9937s	
23208/33650 (epoch 34.484), train_loss = 0.85289440, grad/param norm = 1.9114e-01, time/batch = 17.2462s	
23209/33650 (epoch 34.486), train_loss = 1.02340698, grad/param norm = 2.1152e-01, time/batch = 17.1529s	
23210/33650 (epoch 34.487), train_loss = 0.98618456, grad/param norm = 1.8572e-01, time/batch = 17.2361s	
23211/33650 (epoch 34.489), train_loss = 1.03563559, grad/param norm = 1.8571e-01, time/batch = 18.1527s	
23212/33650 (epoch 34.490), train_loss = 0.81773976, grad/param norm = 1.6805e-01, time/batch = 17.1499s	
23213/33650 (epoch 34.492), train_loss = 0.92936040, grad/param norm = 1.8896e-01, time/batch = 16.7237s	
23214/33650 (epoch 34.493), train_loss = 0.74362302, grad/param norm = 1.3747e-01, time/batch = 18.1563s	
23215/33650 (epoch 34.495), train_loss = 0.92009084, grad/param norm = 1.9228e-01, time/batch = 16.8262s	
23216/33650 (epoch 34.496), train_loss = 0.93239968, grad/param norm = 1.7189e-01, time/batch = 16.7267s	
23217/33650 (epoch 34.498), train_loss = 0.81395534, grad/param norm = 1.6820e-01, time/batch = 16.5725s	
23218/33650 (epoch 34.499), train_loss = 0.88190361, grad/param norm = 1.4459e-01, time/batch = 16.4612s	
23219/33650 (epoch 34.501), train_loss = 0.87867411, grad/param norm = 1.8939e-01, time/batch = 17.1539s	
23220/33650 (epoch 34.502), train_loss = 0.91846373, grad/param norm = 1.7268e-01, time/batch = 17.1500s	
23221/33650 (epoch 34.504), train_loss = 0.96601636, grad/param norm = 1.9062e-01, time/batch = 17.8311s	
23222/33650 (epoch 34.505), train_loss = 0.85528555, grad/param norm = 1.7012e-01, time/batch = 17.9707s	
23223/33650 (epoch 34.507), train_loss = 0.99472548, grad/param norm = 1.8020e-01, time/batch = 16.5505s	
23224/33650 (epoch 34.508), train_loss = 0.88365323, grad/param norm = 1.6854e-01, time/batch = 17.9742s	
23225/33650 (epoch 34.510), train_loss = 0.90895625, grad/param norm = 1.7564e-01, time/batch = 16.4818s	
23226/33650 (epoch 34.511), train_loss = 1.02194024, grad/param norm = 2.0054e-01, time/batch = 16.6354s	
23227/33650 (epoch 34.513), train_loss = 0.93211459, grad/param norm = 1.6233e-01, time/batch = 17.1546s	
23228/33650 (epoch 34.514), train_loss = 0.99265084, grad/param norm = 1.9908e-01, time/batch = 16.7503s	
23229/33650 (epoch 34.516), train_loss = 0.90080182, grad/param norm = 1.8301e-01, time/batch = 16.2173s	
23230/33650 (epoch 34.517), train_loss = 0.90164410, grad/param norm = 2.2310e-01, time/batch = 16.6404s	
23231/33650 (epoch 34.519), train_loss = 0.93713519, grad/param norm = 1.8020e-01, time/batch = 17.2360s	
23232/33650 (epoch 34.520), train_loss = 0.76822540, grad/param norm = 1.3821e-01, time/batch = 17.7282s	
23233/33650 (epoch 34.522), train_loss = 0.87729833, grad/param norm = 1.7176e-01, time/batch = 17.0700s	
23234/33650 (epoch 34.523), train_loss = 0.81519482, grad/param norm = 1.6504e-01, time/batch = 15.7187s	
23235/33650 (epoch 34.525), train_loss = 0.70795440, grad/param norm = 1.2560e-01, time/batch = 16.3060s	
23236/33650 (epoch 34.526), train_loss = 0.99554091, grad/param norm = 1.5124e-01, time/batch = 17.7305s	
23237/33650 (epoch 34.527), train_loss = 0.82732486, grad/param norm = 1.6217e-01, time/batch = 17.3035s	
23238/33650 (epoch 34.529), train_loss = 0.89845316, grad/param norm = 1.9624e-01, time/batch = 17.6547s	
23239/33650 (epoch 34.530), train_loss = 0.83454504, grad/param norm = 1.6522e-01, time/batch = 17.1430s	
23240/33650 (epoch 34.532), train_loss = 0.95272957, grad/param norm = 2.0879e-01, time/batch = 16.7335s	
23241/33650 (epoch 34.533), train_loss = 0.89944914, grad/param norm = 1.7518e-01, time/batch = 16.9037s	
23242/33650 (epoch 34.535), train_loss = 0.99913365, grad/param norm = 1.7373e-01, time/batch = 17.2376s	
23243/33650 (epoch 34.536), train_loss = 0.90454317, grad/param norm = 1.9187e-01, time/batch = 16.3207s	
23244/33650 (epoch 34.538), train_loss = 0.90812306, grad/param norm = 1.8491e-01, time/batch = 16.5623s	
23245/33650 (epoch 34.539), train_loss = 0.71527953, grad/param norm = 1.6084e-01, time/batch = 16.9866s	
23246/33650 (epoch 34.541), train_loss = 0.98428699, grad/param norm = 2.1109e-01, time/batch = 16.6515s	
23247/33650 (epoch 34.542), train_loss = 0.86857429, grad/param norm = 1.8658e-01, time/batch = 16.9129s	
23248/33650 (epoch 34.544), train_loss = 1.06028663, grad/param norm = 2.5333e-01, time/batch = 15.3728s	
23249/33650 (epoch 34.545), train_loss = 0.78675429, grad/param norm = 1.6487e-01, time/batch = 17.2107s	
23250/33650 (epoch 34.547), train_loss = 0.94163152, grad/param norm = 1.7337e-01, time/batch = 17.7385s	
23251/33650 (epoch 34.548), train_loss = 1.04940588, grad/param norm = 1.8626e-01, time/batch = 16.4807s	
23252/33650 (epoch 34.550), train_loss = 0.90538472, grad/param norm = 1.9438e-01, time/batch = 16.7230s	
23253/33650 (epoch 34.551), train_loss = 0.91250061, grad/param norm = 1.7218e-01, time/batch = 17.6438s	
23254/33650 (epoch 34.553), train_loss = 0.79454132, grad/param norm = 1.8212e-01, time/batch = 17.2401s	
23255/33650 (epoch 34.554), train_loss = 1.06170038, grad/param norm = 1.9781e-01, time/batch = 17.3912s	
23256/33650 (epoch 34.556), train_loss = 1.01225438, grad/param norm = 2.9788e-01, time/batch = 16.5557s	
23257/33650 (epoch 34.557), train_loss = 0.96921569, grad/param norm = 2.0617e-01, time/batch = 17.4792s	
23258/33650 (epoch 34.559), train_loss = 1.12316919, grad/param norm = 1.9532e-01, time/batch = 16.1521s	
23259/33650 (epoch 34.560), train_loss = 1.04576738, grad/param norm = 2.0723e-01, time/batch = 15.3182s	
23260/33650 (epoch 34.562), train_loss = 1.01774969, grad/param norm = 1.7122e-01, time/batch = 17.5744s	
23261/33650 (epoch 34.563), train_loss = 0.92813397, grad/param norm = 1.7651e-01, time/batch = 17.5698s	
23262/33650 (epoch 34.565), train_loss = 0.92400329, grad/param norm = 1.6240e-01, time/batch = 17.5493s	
23263/33650 (epoch 34.566), train_loss = 0.88127744, grad/param norm = 1.9246e-01, time/batch = 17.2335s	
23264/33650 (epoch 34.568), train_loss = 0.89958043, grad/param norm = 2.1701e-01, time/batch = 18.1589s	
23265/33650 (epoch 34.569), train_loss = 0.82041421, grad/param norm = 1.5583e-01, time/batch = 15.4841s	
23266/33650 (epoch 34.571), train_loss = 1.00085588, grad/param norm = 1.7571e-01, time/batch = 2.9656s	
23267/33650 (epoch 34.572), train_loss = 0.96103567, grad/param norm = 1.7069e-01, time/batch = 0.6325s	
23268/33650 (epoch 34.574), train_loss = 0.82363309, grad/param norm = 1.6572e-01, time/batch = 0.6294s	
23269/33650 (epoch 34.575), train_loss = 0.91419023, grad/param norm = 1.9391e-01, time/batch = 0.6291s	
23270/33650 (epoch 34.577), train_loss = 0.80319729, grad/param norm = 1.6750e-01, time/batch = 0.6279s	
23271/33650 (epoch 34.578), train_loss = 1.00599811, grad/param norm = 1.8048e-01, time/batch = 0.6329s	
23272/33650 (epoch 34.579), train_loss = 0.95838175, grad/param norm = 1.6282e-01, time/batch = 0.6338s	
23273/33650 (epoch 34.581), train_loss = 1.04123442, grad/param norm = 1.7251e-01, time/batch = 0.6303s	
23274/33650 (epoch 34.582), train_loss = 0.94293011, grad/param norm = 1.5717e-01, time/batch = 0.9292s	
23275/33650 (epoch 34.584), train_loss = 0.90349556, grad/param norm = 1.5710e-01, time/batch = 0.9244s	
23276/33650 (epoch 34.585), train_loss = 0.93121654, grad/param norm = 1.7983e-01, time/batch = 0.9203s	
23277/33650 (epoch 34.587), train_loss = 0.84128278, grad/param norm = 1.7786e-01, time/batch = 0.9190s	
23278/33650 (epoch 34.588), train_loss = 0.85464551, grad/param norm = 2.3542e-01, time/batch = 0.9294s	
23279/33650 (epoch 34.590), train_loss = 0.86145291, grad/param norm = 1.5435e-01, time/batch = 1.3884s	
23280/33650 (epoch 34.591), train_loss = 0.79173669, grad/param norm = 1.6108e-01, time/batch = 1.7010s	
23281/33650 (epoch 34.593), train_loss = 0.78426798, grad/param norm = 1.5919e-01, time/batch = 1.7312s	
23282/33650 (epoch 34.594), train_loss = 0.79030184, grad/param norm = 1.5334e-01, time/batch = 13.4378s	
23283/33650 (epoch 34.596), train_loss = 0.87037263, grad/param norm = 1.5678e-01, time/batch = 16.3086s	
23284/33650 (epoch 34.597), train_loss = 0.77849645, grad/param norm = 1.5988e-01, time/batch = 13.7958s	
23285/33650 (epoch 34.599), train_loss = 0.87499238, grad/param norm = 1.6164e-01, time/batch = 13.5083s	
23286/33650 (epoch 34.600), train_loss = 0.82010534, grad/param norm = 1.5194e-01, time/batch = 13.5474s	
23287/33650 (epoch 34.602), train_loss = 0.89162847, grad/param norm = 1.6944e-01, time/batch = 15.3625s	
23288/33650 (epoch 34.603), train_loss = 0.82612095, grad/param norm = 1.5721e-01, time/batch = 16.2301s	
23289/33650 (epoch 34.605), train_loss = 0.93269661, grad/param norm = 1.6591e-01, time/batch = 17.1516s	
23290/33650 (epoch 34.606), train_loss = 0.87492539, grad/param norm = 1.6448e-01, time/batch = 17.0516s	
23291/33650 (epoch 34.608), train_loss = 0.78602461, grad/param norm = 1.6360e-01, time/batch = 17.0816s	
23292/33650 (epoch 34.609), train_loss = 0.88271106, grad/param norm = 1.7108e-01, time/batch = 16.8258s	
23293/33650 (epoch 34.611), train_loss = 0.78998209, grad/param norm = 1.7013e-01, time/batch = 16.4811s	
23294/33650 (epoch 34.612), train_loss = 0.87201382, grad/param norm = 1.9337e-01, time/batch = 17.7372s	
23295/33650 (epoch 34.614), train_loss = 0.98416090, grad/param norm = 1.9136e-01, time/batch = 16.4024s	
23296/33650 (epoch 34.615), train_loss = 0.91153358, grad/param norm = 1.4418e-01, time/batch = 17.4834s	
23297/33650 (epoch 34.617), train_loss = 0.81447294, grad/param norm = 1.3692e-01, time/batch = 16.6513s	
23298/33650 (epoch 34.618), train_loss = 0.86466800, grad/param norm = 1.6744e-01, time/batch = 18.3211s	
23299/33650 (epoch 34.620), train_loss = 0.83695206, grad/param norm = 1.6699e-01, time/batch = 15.7008s	
23300/33650 (epoch 34.621), train_loss = 0.78162834, grad/param norm = 1.5538e-01, time/batch = 17.1408s	
23301/33650 (epoch 34.623), train_loss = 0.86580279, grad/param norm = 1.6511e-01, time/batch = 17.7381s	
23302/33650 (epoch 34.624), train_loss = 0.69190728, grad/param norm = 1.5544e-01, time/batch = 16.8906s	
23303/33650 (epoch 34.626), train_loss = 0.71962245, grad/param norm = 1.5871e-01, time/batch = 17.2415s	
23304/33650 (epoch 34.627), train_loss = 0.81423575, grad/param norm = 1.7101e-01, time/batch = 17.9946s	
23305/33650 (epoch 34.629), train_loss = 0.82575620, grad/param norm = 1.8380e-01, time/batch = 17.4156s	
23306/33650 (epoch 34.630), train_loss = 0.97388336, grad/param norm = 1.6936e-01, time/batch = 17.1417s	
23307/33650 (epoch 34.632), train_loss = 0.96072455, grad/param norm = 1.7192e-01, time/batch = 18.0560s	
23308/33650 (epoch 34.633), train_loss = 0.96632207, grad/param norm = 1.5759e-01, time/batch = 15.3978s	
23309/33650 (epoch 34.634), train_loss = 0.79079247, grad/param norm = 1.7073e-01, time/batch = 16.4701s	
23310/33650 (epoch 34.636), train_loss = 0.69265475, grad/param norm = 1.2910e-01, time/batch = 18.0680s	
23311/33650 (epoch 34.637), train_loss = 0.78183329, grad/param norm = 1.4871e-01, time/batch = 17.6576s	
23312/33650 (epoch 34.639), train_loss = 0.80198188, grad/param norm = 1.7024e-01, time/batch = 14.3969s	
23313/33650 (epoch 34.640), train_loss = 0.88617690, grad/param norm = 1.7510e-01, time/batch = 16.8138s	
23314/33650 (epoch 34.642), train_loss = 0.94518626, grad/param norm = 1.7168e-01, time/batch = 17.7436s	
23315/33650 (epoch 34.643), train_loss = 0.88577984, grad/param norm = 1.8528e-01, time/batch = 17.4908s	
23316/33650 (epoch 34.645), train_loss = 0.88905013, grad/param norm = 1.7220e-01, time/batch = 16.7402s	
23317/33650 (epoch 34.646), train_loss = 0.77453466, grad/param norm = 1.3818e-01, time/batch = 17.1540s	
23318/33650 (epoch 34.648), train_loss = 0.92368100, grad/param norm = 1.7502e-01, time/batch = 16.5639s	
23319/33650 (epoch 34.649), train_loss = 0.78994092, grad/param norm = 2.3134e-01, time/batch = 17.9147s	
23320/33650 (epoch 34.651), train_loss = 0.94523730, grad/param norm = 1.7718e-01, time/batch = 16.2350s	
23321/33650 (epoch 34.652), train_loss = 0.65412709, grad/param norm = 1.2475e-01, time/batch = 17.6444s	
23322/33650 (epoch 34.654), train_loss = 0.78453960, grad/param norm = 1.6459e-01, time/batch = 17.5808s	
23323/33650 (epoch 34.655), train_loss = 0.76959341, grad/param norm = 1.4715e-01, time/batch = 17.2305s	
23324/33650 (epoch 34.657), train_loss = 0.81658127, grad/param norm = 1.6473e-01, time/batch = 17.3183s	
23325/33650 (epoch 34.658), train_loss = 0.71616134, grad/param norm = 1.5544e-01, time/batch = 16.1486s	
23326/33650 (epoch 34.660), train_loss = 0.70292994, grad/param norm = 1.5949e-01, time/batch = 17.9005s	
23327/33650 (epoch 34.661), train_loss = 0.77470960, grad/param norm = 1.3971e-01, time/batch = 16.5535s	
23328/33650 (epoch 34.663), train_loss = 0.74134337, grad/param norm = 1.6148e-01, time/batch = 18.0663s	
23329/33650 (epoch 34.664), train_loss = 0.82477228, grad/param norm = 1.4658e-01, time/batch = 16.3907s	
23330/33650 (epoch 34.666), train_loss = 0.84325155, grad/param norm = 1.3540e-01, time/batch = 15.4629s	
23331/33650 (epoch 34.667), train_loss = 0.73243227, grad/param norm = 1.4903e-01, time/batch = 17.9962s	
23332/33650 (epoch 34.669), train_loss = 0.75960127, grad/param norm = 1.4593e-01, time/batch = 16.8111s	
23333/33650 (epoch 34.670), train_loss = 0.68779167, grad/param norm = 1.5610e-01, time/batch = 18.0616s	
23334/33650 (epoch 34.672), train_loss = 0.71842622, grad/param norm = 1.4811e-01, time/batch = 17.5478s	
23335/33650 (epoch 34.673), train_loss = 0.71277604, grad/param norm = 1.4716e-01, time/batch = 17.1659s	
23336/33650 (epoch 34.675), train_loss = 0.65468144, grad/param norm = 1.2042e-01, time/batch = 17.9762s	
23337/33650 (epoch 34.676), train_loss = 0.80612722, grad/param norm = 1.8019e-01, time/batch = 16.5605s	
23338/33650 (epoch 34.678), train_loss = 0.79451218, grad/param norm = 1.6818e-01, time/batch = 17.4831s	
23339/33650 (epoch 34.679), train_loss = 0.78338391, grad/param norm = 1.5732e-01, time/batch = 17.7402s	
23340/33650 (epoch 34.681), train_loss = 0.81149078, grad/param norm = 1.5388e-01, time/batch = 16.5842s	
23341/33650 (epoch 34.682), train_loss = 0.76983388, grad/param norm = 1.6712e-01, time/batch = 17.2219s	
23342/33650 (epoch 34.684), train_loss = 0.72126167, grad/param norm = 1.3520e-01, time/batch = 18.2431s	
23343/33650 (epoch 34.685), train_loss = 0.86988791, grad/param norm = 1.7832e-01, time/batch = 16.9844s	
23344/33650 (epoch 34.686), train_loss = 0.85787485, grad/param norm = 1.6820e-01, time/batch = 16.8067s	
23345/33650 (epoch 34.688), train_loss = 0.92390851, grad/param norm = 1.6732e-01, time/batch = 16.0381s	
23346/33650 (epoch 34.689), train_loss = 0.80084942, grad/param norm = 1.6313e-01, time/batch = 17.3227s	
23347/33650 (epoch 34.691), train_loss = 0.93992325, grad/param norm = 1.8101e-01, time/batch = 15.8832s	
23348/33650 (epoch 34.692), train_loss = 0.94608416, grad/param norm = 1.6601e-01, time/batch = 16.2317s	
23349/33650 (epoch 34.694), train_loss = 0.90061209, grad/param norm = 1.6690e-01, time/batch = 17.8973s	
23350/33650 (epoch 34.695), train_loss = 0.58309072, grad/param norm = 1.3491e-01, time/batch = 17.5696s	
23351/33650 (epoch 34.697), train_loss = 0.81293217, grad/param norm = 1.5364e-01, time/batch = 16.2191s	
23352/33650 (epoch 34.698), train_loss = 0.94267741, grad/param norm = 1.7920e-01, time/batch = 17.5698s	
23353/33650 (epoch 34.700), train_loss = 0.83231682, grad/param norm = 1.7659e-01, time/batch = 16.6538s	
23354/33650 (epoch 34.701), train_loss = 0.83856299, grad/param norm = 1.6874e-01, time/batch = 17.6484s	
23355/33650 (epoch 34.703), train_loss = 1.03701805, grad/param norm = 1.6175e-01, time/batch = 16.5724s	
23356/33650 (epoch 34.704), train_loss = 0.83913118, grad/param norm = 1.5713e-01, time/batch = 17.5803s	
23357/33650 (epoch 34.706), train_loss = 0.80484907, grad/param norm = 1.5004e-01, time/batch = 17.8213s	
23358/33650 (epoch 34.707), train_loss = 0.92166899, grad/param norm = 1.5556e-01, time/batch = 16.7200s	
23359/33650 (epoch 34.709), train_loss = 0.81666215, grad/param norm = 1.6673e-01, time/batch = 17.4120s	
23360/33650 (epoch 34.710), train_loss = 1.00077173, grad/param norm = 1.7387e-01, time/batch = 17.2322s	
23361/33650 (epoch 34.712), train_loss = 0.73654486, grad/param norm = 1.7806e-01, time/batch = 16.6284s	
23362/33650 (epoch 34.713), train_loss = 0.77579179, grad/param norm = 2.0630e-01, time/batch = 16.6335s	
23363/33650 (epoch 34.715), train_loss = 0.87973905, grad/param norm = 1.7520e-01, time/batch = 17.1376s	
23364/33650 (epoch 34.716), train_loss = 0.80953152, grad/param norm = 1.5840e-01, time/batch = 16.8373s	
23365/33650 (epoch 34.718), train_loss = 0.79472079, grad/param norm = 1.4608e-01, time/batch = 16.6597s	
23366/33650 (epoch 34.719), train_loss = 0.97886373, grad/param norm = 2.1773e-01, time/batch = 17.2357s	
23367/33650 (epoch 34.721), train_loss = 1.02496796, grad/param norm = 2.0381e-01, time/batch = 17.3884s	
23368/33650 (epoch 34.722), train_loss = 0.91721065, grad/param norm = 1.7947e-01, time/batch = 17.7310s	
23369/33650 (epoch 34.724), train_loss = 0.93790598, grad/param norm = 1.6588e-01, time/batch = 16.6197s	
23370/33650 (epoch 34.725), train_loss = 0.90360594, grad/param norm = 1.7273e-01, time/batch = 16.3932s	
23371/33650 (epoch 34.727), train_loss = 0.81513693, grad/param norm = 1.7498e-01, time/batch = 17.9866s	
23372/33650 (epoch 34.728), train_loss = 0.80509507, grad/param norm = 1.6094e-01, time/batch = 16.7348s	
23373/33650 (epoch 34.730), train_loss = 0.86331042, grad/param norm = 1.4015e-01, time/batch = 18.5524s	
23374/33650 (epoch 34.731), train_loss = 1.01439399, grad/param norm = 1.8456e-01, time/batch = 17.4053s	
23375/33650 (epoch 34.733), train_loss = 0.82606191, grad/param norm = 1.6564e-01, time/batch = 16.8246s	
23376/33650 (epoch 34.734), train_loss = 0.97929201, grad/param norm = 1.9086e-01, time/batch = 17.2409s	
23377/33650 (epoch 34.736), train_loss = 0.84880996, grad/param norm = 2.1230e-01, time/batch = 17.6703s	
23378/33650 (epoch 34.737), train_loss = 0.90865272, grad/param norm = 3.7578e-01, time/batch = 18.2288s	
23379/33650 (epoch 34.738), train_loss = 0.78968763, grad/param norm = 1.6324e-01, time/batch = 16.2263s	
23380/33650 (epoch 34.740), train_loss = 0.73387486, grad/param norm = 1.6779e-01, time/batch = 17.8253s	
23381/33650 (epoch 34.741), train_loss = 0.79254884, grad/param norm = 1.6370e-01, time/batch = 16.7049s	
23382/33650 (epoch 34.743), train_loss = 0.84822275, grad/param norm = 1.7542e-01, time/batch = 16.4846s	
23383/33650 (epoch 34.744), train_loss = 0.93955305, grad/param norm = 1.5343e-01, time/batch = 17.1630s	
23384/33650 (epoch 34.746), train_loss = 0.81580031, grad/param norm = 1.6278e-01, time/batch = 17.6613s	
23385/33650 (epoch 34.747), train_loss = 0.96262482, grad/param norm = 1.6258e-01, time/batch = 17.9887s	
23386/33650 (epoch 34.749), train_loss = 0.70065902, grad/param norm = 1.7137e-01, time/batch = 16.3871s	
23387/33650 (epoch 34.750), train_loss = 0.99372965, grad/param norm = 1.8985e-01, time/batch = 17.0809s	
23388/33650 (epoch 34.752), train_loss = 0.94747815, grad/param norm = 1.8011e-01, time/batch = 15.3835s	
23389/33650 (epoch 34.753), train_loss = 1.03241492, grad/param norm = 1.9611e-01, time/batch = 16.8208s	
23390/33650 (epoch 34.755), train_loss = 0.84723786, grad/param norm = 1.5312e-01, time/batch = 16.8213s	
23391/33650 (epoch 34.756), train_loss = 0.91495957, grad/param norm = 1.7246e-01, time/batch = 17.0594s	
23392/33650 (epoch 34.758), train_loss = 0.95104709, grad/param norm = 1.6579e-01, time/batch = 18.0755s	
23393/33650 (epoch 34.759), train_loss = 0.97636712, grad/param norm = 1.8919e-01, time/batch = 16.7188s	
23394/33650 (epoch 34.761), train_loss = 0.88018927, grad/param norm = 1.6728e-01, time/batch = 17.8176s	
23395/33650 (epoch 34.762), train_loss = 0.86056067, grad/param norm = 1.9329e-01, time/batch = 16.2378s	
23396/33650 (epoch 34.764), train_loss = 0.91200381, grad/param norm = 1.9553e-01, time/batch = 17.2401s	
23397/33650 (epoch 34.765), train_loss = 0.81546148, grad/param norm = 1.6403e-01, time/batch = 15.5570s	
23398/33650 (epoch 34.767), train_loss = 0.84607770, grad/param norm = 1.5722e-01, time/batch = 17.7345s	
23399/33650 (epoch 34.768), train_loss = 0.79302996, grad/param norm = 1.7486e-01, time/batch = 16.1449s	
23400/33650 (epoch 34.770), train_loss = 0.86234081, grad/param norm = 1.7479e-01, time/batch = 15.8933s	
23401/33650 (epoch 34.771), train_loss = 0.89856096, grad/param norm = 1.7408e-01, time/batch = 17.2329s	
23402/33650 (epoch 34.773), train_loss = 0.96337532, grad/param norm = 2.0788e-01, time/batch = 18.0662s	
23403/33650 (epoch 34.774), train_loss = 0.89770579, grad/param norm = 2.9142e-01, time/batch = 17.4742s	
23404/33650 (epoch 34.776), train_loss = 0.96380536, grad/param norm = 2.0307e-01, time/batch = 16.4742s	
23405/33650 (epoch 34.777), train_loss = 0.78121304, grad/param norm = 1.3898e-01, time/batch = 17.2386s	
23406/33650 (epoch 34.779), train_loss = 0.84121758, grad/param norm = 1.5403e-01, time/batch = 16.3977s	
23407/33650 (epoch 34.780), train_loss = 0.77803323, grad/param norm = 1.4814e-01, time/batch = 16.9061s	
23408/33650 (epoch 34.782), train_loss = 0.78184323, grad/param norm = 1.4406e-01, time/batch = 17.8960s	
23409/33650 (epoch 34.783), train_loss = 0.79631581, grad/param norm = 1.3188e-01, time/batch = 17.5764s	
23410/33650 (epoch 34.785), train_loss = 1.01686769, grad/param norm = 1.6550e-01, time/batch = 17.1465s	
23411/33650 (epoch 34.786), train_loss = 0.89662738, grad/param norm = 1.5686e-01, time/batch = 17.3961s	
23412/33650 (epoch 34.788), train_loss = 0.93274801, grad/param norm = 1.7999e-01, time/batch = 17.4913s	
23413/33650 (epoch 34.789), train_loss = 0.95544089, grad/param norm = 1.8345e-01, time/batch = 17.4758s	
23414/33650 (epoch 34.790), train_loss = 0.87610751, grad/param norm = 1.8885e-01, time/batch = 16.5600s	
23415/33650 (epoch 34.792), train_loss = 0.98147656, grad/param norm = 1.9241e-01, time/batch = 16.9632s	
23416/33650 (epoch 34.793), train_loss = 0.93969362, grad/param norm = 1.8732e-01, time/batch = 17.4894s	
23417/33650 (epoch 34.795), train_loss = 0.93953133, grad/param norm = 1.5601e-01, time/batch = 17.1387s	
23418/33650 (epoch 34.796), train_loss = 0.83979321, grad/param norm = 1.6108e-01, time/batch = 16.4067s	
23419/33650 (epoch 34.798), train_loss = 0.84064305, grad/param norm = 1.7552e-01, time/batch = 17.6586s	
23420/33650 (epoch 34.799), train_loss = 0.87290158, grad/param norm = 1.9907e-01, time/batch = 17.7420s	
23421/33650 (epoch 34.801), train_loss = 0.86528181, grad/param norm = 1.8326e-01, time/batch = 28.4941s	
23422/33650 (epoch 34.802), train_loss = 0.96454621, grad/param norm = 1.9681e-01, time/batch = 18.2245s	
23423/33650 (epoch 34.804), train_loss = 0.87845867, grad/param norm = 1.6942e-01, time/batch = 17.2387s	
23424/33650 (epoch 34.805), train_loss = 0.86096527, grad/param norm = 1.5154e-01, time/batch = 16.6310s	
23425/33650 (epoch 34.807), train_loss = 1.02783008, grad/param norm = 1.9813e-01, time/batch = 18.3196s	
23426/33650 (epoch 34.808), train_loss = 1.11606745, grad/param norm = 2.3333e-01, time/batch = 17.6483s	
23427/33650 (epoch 34.810), train_loss = 0.91373054, grad/param norm = 1.7893e-01, time/batch = 16.5578s	
23428/33650 (epoch 34.811), train_loss = 0.89923406, grad/param norm = 1.7392e-01, time/batch = 17.1534s	
23429/33650 (epoch 34.813), train_loss = 0.79371170, grad/param norm = 1.6855e-01, time/batch = 16.8990s	
23430/33650 (epoch 34.814), train_loss = 0.95936856, grad/param norm = 1.8908e-01, time/batch = 16.0496s	
23431/33650 (epoch 34.816), train_loss = 0.93865178, grad/param norm = 2.1891e-01, time/batch = 16.9028s	
23432/33650 (epoch 34.817), train_loss = 0.94878890, grad/param norm = 1.8011e-01, time/batch = 17.9902s	
23433/33650 (epoch 34.819), train_loss = 0.88448675, grad/param norm = 1.7913e-01, time/batch = 17.7329s	
23434/33650 (epoch 34.820), train_loss = 0.96482041, grad/param norm = 1.8684e-01, time/batch = 16.2269s	
23435/33650 (epoch 34.822), train_loss = 0.91462952, grad/param norm = 2.1309e-01, time/batch = 17.6490s	
23436/33650 (epoch 34.823), train_loss = 0.82764501, grad/param norm = 1.6836e-01, time/batch = 17.6553s	
23437/33650 (epoch 34.825), train_loss = 0.88314003, grad/param norm = 1.6896e-01, time/batch = 17.5682s	
23438/33650 (epoch 34.826), train_loss = 0.94550741, grad/param norm = 1.6497e-01, time/batch = 16.6529s	
23439/33650 (epoch 34.828), train_loss = 1.05109895, grad/param norm = 2.0047e-01, time/batch = 17.5748s	
23440/33650 (epoch 34.829), train_loss = 0.75433752, grad/param norm = 2.0498e-01, time/batch = 17.4014s	
23441/33650 (epoch 34.831), train_loss = 0.91466197, grad/param norm = 2.0459e-01, time/batch = 16.5605s	
23442/33650 (epoch 34.832), train_loss = 0.95410785, grad/param norm = 1.8321e-01, time/batch = 17.9003s	
23443/33650 (epoch 34.834), train_loss = 0.94946357, grad/param norm = 1.9053e-01, time/batch = 16.3866s	
23444/33650 (epoch 34.835), train_loss = 1.10381313, grad/param norm = 2.2388e-01, time/batch = 17.4028s	
23445/33650 (epoch 34.837), train_loss = 0.92911790, grad/param norm = 1.8931e-01, time/batch = 17.3099s	
23446/33650 (epoch 34.838), train_loss = 0.89247126, grad/param norm = 1.8446e-01, time/batch = 17.8933s	
23447/33650 (epoch 34.840), train_loss = 0.95672752, grad/param norm = 1.7092e-01, time/batch = 16.7195s	
23448/33650 (epoch 34.841), train_loss = 0.84912344, grad/param norm = 1.6610e-01, time/batch = 16.2267s	
23449/33650 (epoch 34.842), train_loss = 0.86507559, grad/param norm = 1.6712e-01, time/batch = 17.2162s	
23450/33650 (epoch 34.844), train_loss = 1.01036073, grad/param norm = 2.0702e-01, time/batch = 17.6526s	
23451/33650 (epoch 34.845), train_loss = 0.87970563, grad/param norm = 1.7193e-01, time/batch = 17.2263s	
23452/33650 (epoch 34.847), train_loss = 0.66615280, grad/param norm = 1.4293e-01, time/batch = 16.8094s	
23453/33650 (epoch 34.848), train_loss = 0.75849781, grad/param norm = 1.5793e-01, time/batch = 17.1583s	
23454/33650 (epoch 34.850), train_loss = 0.84361480, grad/param norm = 1.8933e-01, time/batch = 17.4216s	
23455/33650 (epoch 34.851), train_loss = 0.74786996, grad/param norm = 1.3998e-01, time/batch = 16.0588s	
23456/33650 (epoch 34.853), train_loss = 0.82929994, grad/param norm = 1.6393e-01, time/batch = 16.0431s	
23457/33650 (epoch 34.854), train_loss = 0.95794234, grad/param norm = 1.6493e-01, time/batch = 16.5782s	
23458/33650 (epoch 34.856), train_loss = 0.70151660, grad/param norm = 1.6487e-01, time/batch = 17.3998s	
23459/33650 (epoch 34.857), train_loss = 0.89832963, grad/param norm = 1.4967e-01, time/batch = 15.8967s	
23460/33650 (epoch 34.859), train_loss = 0.78031516, grad/param norm = 1.3195e-01, time/batch = 18.2480s	
23461/33650 (epoch 34.860), train_loss = 0.75546987, grad/param norm = 1.5349e-01, time/batch = 16.8279s	
23462/33650 (epoch 34.862), train_loss = 0.78695101, grad/param norm = 1.5643e-01, time/batch = 16.7218s	
23463/33650 (epoch 34.863), train_loss = 0.99104689, grad/param norm = 1.6268e-01, time/batch = 17.9071s	
23464/33650 (epoch 34.865), train_loss = 0.86312452, grad/param norm = 1.7782e-01, time/batch = 16.5628s	
23465/33650 (epoch 34.866), train_loss = 0.79488055, grad/param norm = 1.7389e-01, time/batch = 17.2275s	
23466/33650 (epoch 34.868), train_loss = 0.75088513, grad/param norm = 1.8043e-01, time/batch = 17.4882s	
23467/33650 (epoch 34.869), train_loss = 0.91971088, grad/param norm = 1.7080e-01, time/batch = 17.9072s	
23468/33650 (epoch 34.871), train_loss = 0.77457540, grad/param norm = 1.5729e-01, time/batch = 15.2125s	
23469/33650 (epoch 34.872), train_loss = 0.88610925, grad/param norm = 1.5289e-01, time/batch = 16.3219s	
23470/33650 (epoch 34.874), train_loss = 0.92707837, grad/param norm = 1.9965e-01, time/batch = 16.9810s	
23471/33650 (epoch 34.875), train_loss = 0.81523673, grad/param norm = 1.5019e-01, time/batch = 18.2361s	
23472/33650 (epoch 34.877), train_loss = 1.02729223, grad/param norm = 1.8752e-01, time/batch = 17.3064s	
23473/33650 (epoch 34.878), train_loss = 0.63185750, grad/param norm = 1.2759e-01, time/batch = 16.3227s	
23474/33650 (epoch 34.880), train_loss = 0.90811175, grad/param norm = 1.9212e-01, time/batch = 16.1514s	
23475/33650 (epoch 34.881), train_loss = 0.83049220, grad/param norm = 1.8043e-01, time/batch = 17.4784s	
23476/33650 (epoch 34.883), train_loss = 0.89192419, grad/param norm = 1.7468e-01, time/batch = 16.6448s	
23477/33650 (epoch 34.884), train_loss = 0.98192928, grad/param norm = 1.8761e-01, time/batch = 17.0759s	
23478/33650 (epoch 34.886), train_loss = 0.92184063, grad/param norm = 1.6737e-01, time/batch = 17.9072s	
23479/33650 (epoch 34.887), train_loss = 0.75436812, grad/param norm = 1.4763e-01, time/batch = 17.3245s	
23480/33650 (epoch 34.889), train_loss = 0.82961901, grad/param norm = 1.6569e-01, time/batch = 16.8913s	
23481/33650 (epoch 34.890), train_loss = 0.90083531, grad/param norm = 1.5300e-01, time/batch = 16.8724s	
23482/33650 (epoch 34.892), train_loss = 0.81209587, grad/param norm = 2.0746e-01, time/batch = 16.8073s	
23483/33650 (epoch 34.893), train_loss = 0.88649223, grad/param norm = 1.8019e-01, time/batch = 16.6481s	
23484/33650 (epoch 34.895), train_loss = 0.97507062, grad/param norm = 1.5925e-01, time/batch = 16.1314s	
23485/33650 (epoch 34.896), train_loss = 0.79846618, grad/param norm = 1.4792e-01, time/batch = 17.9160s	
23486/33650 (epoch 34.897), train_loss = 0.72890915, grad/param norm = 1.5994e-01, time/batch = 16.8238s	
23487/33650 (epoch 34.899), train_loss = 0.79160095, grad/param norm = 1.5137e-01, time/batch = 14.9503s	
23488/33650 (epoch 34.900), train_loss = 0.74603054, grad/param norm = 1.4759e-01, time/batch = 17.4061s	
23489/33650 (epoch 34.902), train_loss = 0.83947930, grad/param norm = 1.8781e-01, time/batch = 17.6605s	
23490/33650 (epoch 34.903), train_loss = 0.81116173, grad/param norm = 1.6772e-01, time/batch = 16.0550s	
23491/33650 (epoch 34.905), train_loss = 0.97619413, grad/param norm = 1.9639e-01, time/batch = 17.6477s	
23492/33650 (epoch 34.906), train_loss = 0.79994315, grad/param norm = 1.8601e-01, time/batch = 17.1513s	
23493/33650 (epoch 34.908), train_loss = 0.83166775, grad/param norm = 1.7279e-01, time/batch = 17.6574s	
23494/33650 (epoch 34.909), train_loss = 0.80955298, grad/param norm = 1.4184e-01, time/batch = 16.5626s	
23495/33650 (epoch 34.911), train_loss = 0.73210604, grad/param norm = 1.3621e-01, time/batch = 17.1566s	
23496/33650 (epoch 34.912), train_loss = 0.66701617, grad/param norm = 1.5605e-01, time/batch = 17.2427s	
23497/33650 (epoch 34.914), train_loss = 0.87238925, grad/param norm = 1.5465e-01, time/batch = 16.6373s	
23498/33650 (epoch 34.915), train_loss = 0.81978805, grad/param norm = 1.6851e-01, time/batch = 16.4066s	
23499/33650 (epoch 34.917), train_loss = 0.81706227, grad/param norm = 1.7361e-01, time/batch = 16.6403s	
23500/33650 (epoch 34.918), train_loss = 0.76337489, grad/param norm = 1.4170e-01, time/batch = 16.1494s	
23501/33650 (epoch 34.920), train_loss = 0.77531195, grad/param norm = 1.4542e-01, time/batch = 17.4823s	
23502/33650 (epoch 34.921), train_loss = 0.76471946, grad/param norm = 1.5185e-01, time/batch = 16.9872s	
23503/33650 (epoch 34.923), train_loss = 0.68787849, grad/param norm = 1.5471e-01, time/batch = 16.9616s	
23504/33650 (epoch 34.924), train_loss = 0.86458801, grad/param norm = 1.5881e-01, time/batch = 16.9761s	
23505/33650 (epoch 34.926), train_loss = 0.80505624, grad/param norm = 2.0662e-01, time/batch = 15.3274s	
23506/33650 (epoch 34.927), train_loss = 0.83188272, grad/param norm = 1.5147e-01, time/batch = 17.8187s	
23507/33650 (epoch 34.929), train_loss = 0.91133943, grad/param norm = 1.6522e-01, time/batch = 17.9097s	
23508/33650 (epoch 34.930), train_loss = 0.82558966, grad/param norm = 1.7432e-01, time/batch = 16.0609s	
23509/33650 (epoch 34.932), train_loss = 0.86475671, grad/param norm = 1.5918e-01, time/batch = 17.2346s	
23510/33650 (epoch 34.933), train_loss = 0.71157987, grad/param norm = 1.7111e-01, time/batch = 17.2310s	
23511/33650 (epoch 34.935), train_loss = 0.71675751, grad/param norm = 1.7224e-01, time/batch = 16.8964s	
23512/33650 (epoch 34.936), train_loss = 0.76403772, grad/param norm = 1.4508e-01, time/batch = 15.9651s	
23513/33650 (epoch 34.938), train_loss = 0.72962423, grad/param norm = 1.4648e-01, time/batch = 17.9072s	
23514/33650 (epoch 34.939), train_loss = 0.91301766, grad/param norm = 1.5664e-01, time/batch = 18.1498s	
23515/33650 (epoch 34.941), train_loss = 0.83834920, grad/param norm = 1.7161e-01, time/batch = 16.9838s	
23516/33650 (epoch 34.942), train_loss = 0.91382394, grad/param norm = 1.7438e-01, time/batch = 17.5652s	
23517/33650 (epoch 34.944), train_loss = 0.80704696, grad/param norm = 1.5764e-01, time/batch = 17.5764s	
23518/33650 (epoch 34.945), train_loss = 0.85427086, grad/param norm = 1.5907e-01, time/batch = 16.9827s	
23519/33650 (epoch 34.947), train_loss = 0.98190145, grad/param norm = 2.6174e-01, time/batch = 17.3117s	
23520/33650 (epoch 34.948), train_loss = 0.95273455, grad/param norm = 1.6016e-01, time/batch = 17.0540s	
23521/33650 (epoch 34.949), train_loss = 0.73384010, grad/param norm = 1.5078e-01, time/batch = 16.7217s	
23522/33650 (epoch 34.951), train_loss = 0.97859143, grad/param norm = 1.6954e-01, time/batch = 16.4659s	
23523/33650 (epoch 34.952), train_loss = 0.87943736, grad/param norm = 1.5779e-01, time/batch = 16.6580s	
23524/33650 (epoch 34.954), train_loss = 0.88283387, grad/param norm = 1.6621e-01, time/batch = 17.5809s	
23525/33650 (epoch 34.955), train_loss = 0.86245460, grad/param norm = 1.6193e-01, time/batch = 16.3821s	
23526/33650 (epoch 34.957), train_loss = 0.89730097, grad/param norm = 1.7162e-01, time/batch = 17.7387s	
23527/33650 (epoch 34.958), train_loss = 0.67845993, grad/param norm = 1.3997e-01, time/batch = 15.6662s	
23528/33650 (epoch 34.960), train_loss = 0.68447212, grad/param norm = 1.4715e-01, time/batch = 18.4150s	
23529/33650 (epoch 34.961), train_loss = 0.74086856, grad/param norm = 1.8956e-01, time/batch = 16.0438s	
23530/33650 (epoch 34.963), train_loss = 0.75209857, grad/param norm = 1.4832e-01, time/batch = 17.3997s	
23531/33650 (epoch 34.964), train_loss = 0.93074051, grad/param norm = 1.7263e-01, time/batch = 17.4109s	
23532/33650 (epoch 34.966), train_loss = 0.85999739, grad/param norm = 1.9079e-01, time/batch = 17.4829s	
23533/33650 (epoch 34.967), train_loss = 0.87635886, grad/param norm = 1.6598e-01, time/batch = 16.9145s	
23534/33650 (epoch 34.969), train_loss = 0.83916190, grad/param norm = 1.5444e-01, time/batch = 17.3112s	
23535/33650 (epoch 34.970), train_loss = 0.85446734, grad/param norm = 1.6825e-01, time/batch = 16.9031s	
23536/33650 (epoch 34.972), train_loss = 1.11983790, grad/param norm = 1.8731e-01, time/batch = 16.9829s	
23537/33650 (epoch 34.973), train_loss = 0.76751858, grad/param norm = 1.3642e-01, time/batch = 17.7363s	
23538/33650 (epoch 34.975), train_loss = 0.73915317, grad/param norm = 1.4030e-01, time/batch = 17.0534s	
23539/33650 (epoch 34.976), train_loss = 0.77339412, grad/param norm = 1.5152e-01, time/batch = 16.0499s	
23540/33650 (epoch 34.978), train_loss = 0.76936295, grad/param norm = 1.4965e-01, time/batch = 17.3101s	
23541/33650 (epoch 34.979), train_loss = 0.84276133, grad/param norm = 1.8878e-01, time/batch = 17.8231s	
23542/33650 (epoch 34.981), train_loss = 0.81089713, grad/param norm = 1.4620e-01, time/batch = 17.4814s	
23543/33650 (epoch 34.982), train_loss = 0.83918174, grad/param norm = 1.4825e-01, time/batch = 16.7979s	
23544/33650 (epoch 34.984), train_loss = 0.68538934, grad/param norm = 1.2841e-01, time/batch = 16.5692s	
23545/33650 (epoch 34.985), train_loss = 0.74648342, grad/param norm = 1.4726e-01, time/batch = 17.1359s	
23546/33650 (epoch 34.987), train_loss = 0.85455238, grad/param norm = 1.6372e-01, time/batch = 16.2869s	
23547/33650 (epoch 34.988), train_loss = 0.77492063, grad/param norm = 1.4900e-01, time/batch = 17.4714s	
23548/33650 (epoch 34.990), train_loss = 0.97666937, grad/param norm = 1.8358e-01, time/batch = 17.6471s	
23549/33650 (epoch 34.991), train_loss = 0.84615459, grad/param norm = 1.7055e-01, time/batch = 17.2366s	
23550/33650 (epoch 34.993), train_loss = 0.85008239, grad/param norm = 1.6233e-01, time/batch = 17.0626s	
23551/33650 (epoch 34.994), train_loss = 0.86502842, grad/param norm = 1.5314e-01, time/batch = 16.8096s	
23552/33650 (epoch 34.996), train_loss = 0.83286399, grad/param norm = 1.7103e-01, time/batch = 17.6376s	
23553/33650 (epoch 34.997), train_loss = 0.90161459, grad/param norm = 1.7813e-01, time/batch = 17.0630s	
23554/33650 (epoch 34.999), train_loss = 0.76936458, grad/param norm = 1.6573e-01, time/batch = 16.8917s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
23555/33650 (epoch 35.000), train_loss = 0.93022434, grad/param norm = 2.0474e-01, time/batch = 17.6470s	
23556/33650 (epoch 35.001), train_loss = 0.96469264, grad/param norm = 1.7385e-01, time/batch = 17.0674s	
23557/33650 (epoch 35.003), train_loss = 0.98924599, grad/param norm = 2.0664e-01, time/batch = 15.3819s	
23558/33650 (epoch 35.004), train_loss = 0.87227391, grad/param norm = 1.6841e-01, time/batch = 17.7291s	
23559/33650 (epoch 35.006), train_loss = 0.81883322, grad/param norm = 1.6837e-01, time/batch = 17.4021s	
23560/33650 (epoch 35.007), train_loss = 0.88262009, grad/param norm = 1.7616e-01, time/batch = 15.8142s	
23561/33650 (epoch 35.009), train_loss = 0.77174995, grad/param norm = 1.5899e-01, time/batch = 17.6387s	
23562/33650 (epoch 35.010), train_loss = 0.94762096, grad/param norm = 1.7935e-01, time/batch = 16.5653s	
23563/33650 (epoch 35.012), train_loss = 0.82458253, grad/param norm = 1.7965e-01, time/batch = 18.3216s	
23564/33650 (epoch 35.013), train_loss = 0.84737597, grad/param norm = 1.8704e-01, time/batch = 15.6139s	
23565/33650 (epoch 35.015), train_loss = 0.83978852, grad/param norm = 1.7694e-01, time/batch = 16.7426s	
23566/33650 (epoch 35.016), train_loss = 0.77740719, grad/param norm = 1.8005e-01, time/batch = 17.7387s	
23567/33650 (epoch 35.018), train_loss = 0.83289679, grad/param norm = 1.7929e-01, time/batch = 14.8922s	
23568/33650 (epoch 35.019), train_loss = 0.80583901, grad/param norm = 1.8522e-01, time/batch = 16.8221s	
23569/33650 (epoch 35.021), train_loss = 0.89335645, grad/param norm = 1.5226e-01, time/batch = 17.6539s	
23570/33650 (epoch 35.022), train_loss = 0.81358622, grad/param norm = 1.4948e-01, time/batch = 18.3930s	
23571/33650 (epoch 35.024), train_loss = 0.75587572, grad/param norm = 1.5019e-01, time/batch = 16.2017s	
23572/33650 (epoch 35.025), train_loss = 0.86629975, grad/param norm = 1.6587e-01, time/batch = 18.1442s	
23573/33650 (epoch 35.027), train_loss = 0.87596442, grad/param norm = 1.8208e-01, time/batch = 17.0647s	
23574/33650 (epoch 35.028), train_loss = 0.92331555, grad/param norm = 1.6922e-01, time/batch = 17.0624s	
23575/33650 (epoch 35.030), train_loss = 0.82818860, grad/param norm = 1.6477e-01, time/batch = 18.2218s	
23576/33650 (epoch 35.031), train_loss = 0.77032774, grad/param norm = 1.3415e-01, time/batch = 17.7412s	
23577/33650 (epoch 35.033), train_loss = 0.86030515, grad/param norm = 1.5430e-01, time/batch = 17.9736s	
23578/33650 (epoch 35.034), train_loss = 0.90070786, grad/param norm = 2.1677e-01, time/batch = 17.3876s	
23579/33650 (epoch 35.036), train_loss = 0.95675989, grad/param norm = 1.7390e-01, time/batch = 16.9052s	
23580/33650 (epoch 35.037), train_loss = 0.80297935, grad/param norm = 1.5397e-01, time/batch = 15.9680s	
23581/33650 (epoch 35.039), train_loss = 0.93257348, grad/param norm = 1.7610e-01, time/batch = 17.4699s	
23582/33650 (epoch 35.040), train_loss = 1.00795333, grad/param norm = 1.9337e-01, time/batch = 15.4721s	
23583/33650 (epoch 35.042), train_loss = 1.01813187, grad/param norm = 1.8404e-01, time/batch = 18.1504s	
23584/33650 (epoch 35.043), train_loss = 0.81851166, grad/param norm = 1.5842e-01, time/batch = 17.8186s	
23585/33650 (epoch 35.045), train_loss = 0.79585370, grad/param norm = 1.5288e-01, time/batch = 17.8138s	
23586/33650 (epoch 35.046), train_loss = 0.90978533, grad/param norm = 1.7308e-01, time/batch = 17.9100s	
23587/33650 (epoch 35.048), train_loss = 0.94341335, grad/param norm = 1.8395e-01, time/batch = 16.9839s	
23588/33650 (epoch 35.049), train_loss = 0.79800037, grad/param norm = 1.6534e-01, time/batch = 16.2332s	
23589/33650 (epoch 35.051), train_loss = 1.00693270, grad/param norm = 1.8120e-01, time/batch = 16.9854s	
23590/33650 (epoch 35.052), train_loss = 0.97993604, grad/param norm = 2.1399e-01, time/batch = 17.8151s	
23591/33650 (epoch 35.053), train_loss = 0.93526166, grad/param norm = 1.9025e-01, time/batch = 14.2328s	
23592/33650 (epoch 35.055), train_loss = 0.81380192, grad/param norm = 1.7209e-01, time/batch = 14.0100s	
23593/33650 (epoch 35.056), train_loss = 0.75900564, grad/param norm = 1.4676e-01, time/batch = 13.3502s	
23594/33650 (epoch 35.058), train_loss = 0.92601800, grad/param norm = 1.7747e-01, time/batch = 15.9643s	
23595/33650 (epoch 35.059), train_loss = 0.92684433, grad/param norm = 1.6697e-01, time/batch = 17.3281s	
23596/33650 (epoch 35.061), train_loss = 0.94900490, grad/param norm = 1.6665e-01, time/batch = 17.0495s	
23597/33650 (epoch 35.062), train_loss = 0.90390283, grad/param norm = 1.4675e-01, time/batch = 15.2847s	
23598/33650 (epoch 35.064), train_loss = 0.85883081, grad/param norm = 1.5974e-01, time/batch = 17.2421s	
23599/33650 (epoch 35.065), train_loss = 0.81495416, grad/param norm = 1.4725e-01, time/batch = 17.4923s	
23600/33650 (epoch 35.067), train_loss = 0.78704286, grad/param norm = 1.4451e-01, time/batch = 17.8143s	
23601/33650 (epoch 35.068), train_loss = 0.89141472, grad/param norm = 1.7438e-01, time/batch = 17.2409s	
23602/33650 (epoch 35.070), train_loss = 0.91652501, grad/param norm = 1.5997e-01, time/batch = 17.3238s	
23603/33650 (epoch 35.071), train_loss = 0.80531636, grad/param norm = 1.6134e-01, time/batch = 17.3036s	
23604/33650 (epoch 35.073), train_loss = 0.89234182, grad/param norm = 1.7081e-01, time/batch = 17.8145s	
23605/33650 (epoch 35.074), train_loss = 0.97891506, grad/param norm = 1.5973e-01, time/batch = 17.1528s	
23606/33650 (epoch 35.076), train_loss = 0.92946423, grad/param norm = 1.7947e-01, time/batch = 16.6420s	
23607/33650 (epoch 35.077), train_loss = 0.84422324, grad/param norm = 1.5208e-01, time/batch = 17.6565s	
23608/33650 (epoch 35.079), train_loss = 0.89488124, grad/param norm = 1.5789e-01, time/batch = 16.5624s	
23609/33650 (epoch 35.080), train_loss = 0.91025836, grad/param norm = 1.7543e-01, time/batch = 16.2278s	
23610/33650 (epoch 35.082), train_loss = 0.86801478, grad/param norm = 1.4991e-01, time/batch = 17.1328s	
23611/33650 (epoch 35.083), train_loss = 0.88878546, grad/param norm = 1.7253e-01, time/batch = 17.4857s	
23612/33650 (epoch 35.085), train_loss = 0.94349168, grad/param norm = 1.5536e-01, time/batch = 18.1581s	
23613/33650 (epoch 35.086), train_loss = 0.90649913, grad/param norm = 1.9698e-01, time/batch = 16.7197s	
23614/33650 (epoch 35.088), train_loss = 0.86065809, grad/param norm = 1.5585e-01, time/batch = 15.6398s	
23615/33650 (epoch 35.089), train_loss = 0.81298893, grad/param norm = 1.6718e-01, time/batch = 17.7256s	
23616/33650 (epoch 35.091), train_loss = 0.84318090, grad/param norm = 1.5735e-01, time/batch = 16.8111s	
23617/33650 (epoch 35.092), train_loss = 0.85927354, grad/param norm = 1.6966e-01, time/batch = 17.0584s	
23618/33650 (epoch 35.094), train_loss = 0.93293806, grad/param norm = 1.4965e-01, time/batch = 17.6528s	
23619/33650 (epoch 35.095), train_loss = 0.91007165, grad/param norm = 1.7480e-01, time/batch = 17.8203s	
23620/33650 (epoch 35.097), train_loss = 0.80721683, grad/param norm = 1.8690e-01, time/batch = 16.3794s	
23621/33650 (epoch 35.098), train_loss = 0.69037255, grad/param norm = 1.3365e-01, time/batch = 18.3957s	
23622/33650 (epoch 35.100), train_loss = 0.78447175, grad/param norm = 1.5232e-01, time/batch = 16.5650s	
23623/33650 (epoch 35.101), train_loss = 0.87142665, grad/param norm = 1.8154e-01, time/batch = 16.7117s	
23624/33650 (epoch 35.103), train_loss = 0.84241533, grad/param norm = 1.6970e-01, time/batch = 17.1405s	
23625/33650 (epoch 35.104), train_loss = 0.98204952, grad/param norm = 1.6190e-01, time/batch = 17.4067s	
23626/33650 (epoch 35.105), train_loss = 0.90407168, grad/param norm = 1.7788e-01, time/batch = 17.8238s	
23627/33650 (epoch 35.107), train_loss = 0.81329540, grad/param norm = 1.5405e-01, time/batch = 16.4019s	
23628/33650 (epoch 35.108), train_loss = 0.90339549, grad/param norm = 1.9277e-01, time/batch = 17.5632s	
23629/33650 (epoch 35.110), train_loss = 0.99598907, grad/param norm = 1.7406e-01, time/batch = 17.3206s	
23630/33650 (epoch 35.111), train_loss = 0.85977248, grad/param norm = 1.8671e-01, time/batch = 19.1306s	
23631/33650 (epoch 35.113), train_loss = 0.81308868, grad/param norm = 1.7165e-01, time/batch = 27.9422s	
23632/33650 (epoch 35.114), train_loss = 0.93911944, grad/param norm = 1.6630e-01, time/batch = 17.1497s	
23633/33650 (epoch 35.116), train_loss = 0.79695438, grad/param norm = 1.3905e-01, time/batch = 16.8968s	
23634/33650 (epoch 35.117), train_loss = 0.85489715, grad/param norm = 1.4913e-01, time/batch = 17.7236s	
23635/33650 (epoch 35.119), train_loss = 0.77966763, grad/param norm = 1.3466e-01, time/batch = 15.1442s	
23636/33650 (epoch 35.120), train_loss = 0.80002586, grad/param norm = 1.6358e-01, time/batch = 17.7224s	
23637/33650 (epoch 35.122), train_loss = 0.66172547, grad/param norm = 1.3580e-01, time/batch = 16.3229s	
23638/33650 (epoch 35.123), train_loss = 0.81125257, grad/param norm = 1.4853e-01, time/batch = 17.5670s	
23639/33650 (epoch 35.125), train_loss = 0.89306065, grad/param norm = 1.5796e-01, time/batch = 17.6498s	
23640/33650 (epoch 35.126), train_loss = 0.93127714, grad/param norm = 2.1449e-01, time/batch = 16.3072s	
23641/33650 (epoch 35.128), train_loss = 0.91920463, grad/param norm = 1.8580e-01, time/batch = 18.3171s	
23642/33650 (epoch 35.129), train_loss = 0.93728200, grad/param norm = 1.8290e-01, time/batch = 17.3984s	
23643/33650 (epoch 35.131), train_loss = 0.88727243, grad/param norm = 2.3891e-01, time/batch = 17.1526s	
23644/33650 (epoch 35.132), train_loss = 0.88336085, grad/param norm = 1.5686e-01, time/batch = 17.2142s	
23645/33650 (epoch 35.134), train_loss = 0.93888826, grad/param norm = 1.7497e-01, time/batch = 17.8256s	
23646/33650 (epoch 35.135), train_loss = 0.76757076, grad/param norm = 1.6192e-01, time/batch = 17.8286s	
23647/33650 (epoch 35.137), train_loss = 0.89352956, grad/param norm = 2.0216e-01, time/batch = 16.6434s	
23648/33650 (epoch 35.138), train_loss = 0.91940182, grad/param norm = 1.6069e-01, time/batch = 17.7424s	
23649/33650 (epoch 35.140), train_loss = 0.87484354, grad/param norm = 1.8612e-01, time/batch = 16.8242s	
23650/33650 (epoch 35.141), train_loss = 0.99432189, grad/param norm = 1.8223e-01, time/batch = 15.5469s	
23651/33650 (epoch 35.143), train_loss = 1.01502100, grad/param norm = 2.0738e-01, time/batch = 17.0596s	
23652/33650 (epoch 35.144), train_loss = 0.90968311, grad/param norm = 1.7912e-01, time/batch = 18.1460s	
23653/33650 (epoch 35.146), train_loss = 0.86114546, grad/param norm = 1.7687e-01, time/batch = 17.1623s	
23654/33650 (epoch 35.147), train_loss = 0.79346208, grad/param norm = 1.7012e-01, time/batch = 17.3962s	
23655/33650 (epoch 35.149), train_loss = 0.77642678, grad/param norm = 1.6014e-01, time/batch = 17.1445s	
23656/33650 (epoch 35.150), train_loss = 0.74715652, grad/param norm = 1.4860e-01, time/batch = 16.4712s	
23657/33650 (epoch 35.152), train_loss = 0.82051786, grad/param norm = 1.6872e-01, time/batch = 16.8929s	
23658/33650 (epoch 35.153), train_loss = 0.85233354, grad/param norm = 1.8793e-01, time/batch = 16.6490s	
23659/33650 (epoch 35.155), train_loss = 0.78398566, grad/param norm = 1.4159e-01, time/batch = 16.5467s	
23660/33650 (epoch 35.156), train_loss = 0.77857692, grad/param norm = 1.3984e-01, time/batch = 16.9892s	
23661/33650 (epoch 35.158), train_loss = 0.89661493, grad/param norm = 1.6043e-01, time/batch = 16.3152s	
23662/33650 (epoch 35.159), train_loss = 0.79955740, grad/param norm = 1.4801e-01, time/batch = 17.8150s	
23663/33650 (epoch 35.160), train_loss = 0.79143744, grad/param norm = 1.3990e-01, time/batch = 17.3254s	
23664/33650 (epoch 35.162), train_loss = 0.81915035, grad/param norm = 1.7572e-01, time/batch = 17.6417s	
23665/33650 (epoch 35.163), train_loss = 0.88841292, grad/param norm = 1.6561e-01, time/batch = 17.4700s	
23666/33650 (epoch 35.165), train_loss = 0.76845701, grad/param norm = 1.5985e-01, time/batch = 17.1563s	
23667/33650 (epoch 35.166), train_loss = 0.75240629, grad/param norm = 1.4738e-01, time/batch = 17.4782s	
23668/33650 (epoch 35.168), train_loss = 0.96177678, grad/param norm = 1.8290e-01, time/batch = 14.9815s	
23669/33650 (epoch 35.169), train_loss = 0.85103409, grad/param norm = 1.8182e-01, time/batch = 16.2306s	
23670/33650 (epoch 35.171), train_loss = 0.83150355, grad/param norm = 1.4700e-01, time/batch = 18.2391s	
23671/33650 (epoch 35.172), train_loss = 0.80429422, grad/param norm = 1.4927e-01, time/batch = 17.4046s	
23672/33650 (epoch 35.174), train_loss = 0.78430240, grad/param norm = 1.5154e-01, time/batch = 16.7310s	
23673/33650 (epoch 35.175), train_loss = 0.73571622, grad/param norm = 2.0122e-01, time/batch = 18.1593s	
23674/33650 (epoch 35.177), train_loss = 0.86900338, grad/param norm = 2.1430e-01, time/batch = 17.8880s	
23675/33650 (epoch 35.178), train_loss = 0.82522289, grad/param norm = 1.9475e-01, time/batch = 16.8241s	
23676/33650 (epoch 35.180), train_loss = 0.77587995, grad/param norm = 1.6248e-01, time/batch = 17.0779s	
23677/33650 (epoch 35.181), train_loss = 0.68854590, grad/param norm = 1.4248e-01, time/batch = 17.8146s	
23678/33650 (epoch 35.183), train_loss = 0.77140661, grad/param norm = 1.5775e-01, time/batch = 16.6605s	
23679/33650 (epoch 35.184), train_loss = 0.78036093, grad/param norm = 1.9021e-01, time/batch = 17.3223s	
23680/33650 (epoch 35.186), train_loss = 0.81274130, grad/param norm = 1.8440e-01, time/batch = 17.5714s	
23681/33650 (epoch 35.187), train_loss = 0.94506196, grad/param norm = 1.8670e-01, time/batch = 15.9724s	
23682/33650 (epoch 35.189), train_loss = 0.94214973, grad/param norm = 1.7964e-01, time/batch = 15.9762s	
23683/33650 (epoch 35.190), train_loss = 0.86732383, grad/param norm = 1.7556e-01, time/batch = 15.8846s	
23684/33650 (epoch 35.192), train_loss = 1.01773906, grad/param norm = 1.5718e-01, time/batch = 16.7469s	
23685/33650 (epoch 35.193), train_loss = 0.98687008, grad/param norm = 1.6745e-01, time/batch = 17.4842s	
23686/33650 (epoch 35.195), train_loss = 0.74819863, grad/param norm = 1.5234e-01, time/batch = 17.0578s	
23687/33650 (epoch 35.196), train_loss = 0.71652308, grad/param norm = 1.8577e-01, time/batch = 18.1424s	
23688/33650 (epoch 35.198), train_loss = 0.84352547, grad/param norm = 1.5541e-01, time/batch = 16.8309s	
23689/33650 (epoch 35.199), train_loss = 0.91544773, grad/param norm = 1.7881e-01, time/batch = 17.2300s	
23690/33650 (epoch 35.201), train_loss = 0.80110049, grad/param norm = 1.8046e-01, time/batch = 18.1463s	
23691/33650 (epoch 35.202), train_loss = 0.84045415, grad/param norm = 1.6821e-01, time/batch = 16.9843s	
23692/33650 (epoch 35.204), train_loss = 0.88621917, grad/param norm = 1.5971e-01, time/batch = 17.2826s	
23693/33650 (epoch 35.205), train_loss = 0.85528487, grad/param norm = 1.7323e-01, time/batch = 17.1415s	
23694/33650 (epoch 35.207), train_loss = 0.79655188, grad/param norm = 1.9271e-01, time/batch = 18.3188s	
23695/33650 (epoch 35.208), train_loss = 0.87513584, grad/param norm = 1.6194e-01, time/batch = 17.7238s	
23696/33650 (epoch 35.210), train_loss = 0.70719297, grad/param norm = 1.5202e-01, time/batch = 17.4755s	
23697/33650 (epoch 35.211), train_loss = 0.79238291, grad/param norm = 1.8930e-01, time/batch = 18.2290s	
23698/33650 (epoch 35.212), train_loss = 0.88150568, grad/param norm = 1.8710e-01, time/batch = 18.7306s	
23699/33650 (epoch 35.214), train_loss = 1.02273368, grad/param norm = 1.8876e-01, time/batch = 16.5625s	
23700/33650 (epoch 35.215), train_loss = 0.68110598, grad/param norm = 1.5468e-01, time/batch = 18.6336s	
23701/33650 (epoch 35.217), train_loss = 0.82768306, grad/param norm = 1.9974e-01, time/batch = 15.9519s	
23702/33650 (epoch 35.218), train_loss = 0.84069805, grad/param norm = 1.7577e-01, time/batch = 17.6400s	
23703/33650 (epoch 35.220), train_loss = 0.73938394, grad/param norm = 1.7848e-01, time/batch = 17.8058s	
23704/33650 (epoch 35.221), train_loss = 1.00342612, grad/param norm = 2.0689e-01, time/batch = 17.8985s	
23705/33650 (epoch 35.223), train_loss = 0.70000190, grad/param norm = 1.6118e-01, time/batch = 18.8120s	
23706/33650 (epoch 35.224), train_loss = 0.80820792, grad/param norm = 1.8657e-01, time/batch = 16.5477s	
23707/33650 (epoch 35.226), train_loss = 1.10705407, grad/param norm = 1.8026e-01, time/batch = 18.2328s	
23708/33650 (epoch 35.227), train_loss = 0.93236141, grad/param norm = 1.8943e-01, time/batch = 16.4096s	
23709/33650 (epoch 35.229), train_loss = 0.96310974, grad/param norm = 1.9856e-01, time/batch = 16.7111s	
23710/33650 (epoch 35.230), train_loss = 1.07549712, grad/param norm = 2.1686e-01, time/batch = 16.2940s	
23711/33650 (epoch 35.232), train_loss = 0.91872485, grad/param norm = 2.0740e-01, time/batch = 19.0572s	
23712/33650 (epoch 35.233), train_loss = 0.89627261, grad/param norm = 2.4424e-01, time/batch = 17.7392s	
23713/33650 (epoch 35.235), train_loss = 0.84664848, grad/param norm = 1.6455e-01, time/batch = 17.6432s	
23714/33650 (epoch 35.236), train_loss = 0.79094521, grad/param norm = 1.5183e-01, time/batch = 17.5645s	
23715/33650 (epoch 35.238), train_loss = 0.81877055, grad/param norm = 1.4996e-01, time/batch = 19.0618s	
23716/33650 (epoch 35.239), train_loss = 0.77977212, grad/param norm = 1.6812e-01, time/batch = 16.0560s	
23717/33650 (epoch 35.241), train_loss = 0.83136340, grad/param norm = 1.4318e-01, time/batch = 18.3093s	
23718/33650 (epoch 35.242), train_loss = 0.68351172, grad/param norm = 1.6187e-01, time/batch = 18.8109s	
23719/33650 (epoch 35.244), train_loss = 0.82852617, grad/param norm = 1.5511e-01, time/batch = 18.1411s	
23720/33650 (epoch 35.245), train_loss = 0.73427248, grad/param norm = 1.5943e-01, time/batch = 17.8698s	
23721/33650 (epoch 35.247), train_loss = 0.81013561, grad/param norm = 1.4648e-01, time/batch = 18.1513s	
23722/33650 (epoch 35.248), train_loss = 0.75024881, grad/param norm = 1.6817e-01, time/batch = 18.9723s	
23723/33650 (epoch 35.250), train_loss = 0.83296357, grad/param norm = 1.4593e-01, time/batch = 16.2860s	
23724/33650 (epoch 35.251), train_loss = 0.94778866, grad/param norm = 1.8201e-01, time/batch = 17.2161s	
23725/33650 (epoch 35.253), train_loss = 0.73640219, grad/param norm = 1.5268e-01, time/batch = 17.4914s	
23726/33650 (epoch 35.254), train_loss = 0.83144960, grad/param norm = 1.7802e-01, time/batch = 18.2201s	
23727/33650 (epoch 35.256), train_loss = 0.96320036, grad/param norm = 1.5535e-01, time/batch = 17.7324s	
23728/33650 (epoch 35.257), train_loss = 0.92564458, grad/param norm = 1.7997e-01, time/batch = 18.3905s	
23729/33650 (epoch 35.259), train_loss = 0.77568396, grad/param norm = 1.6711e-01, time/batch = 13.8132s	
23730/33650 (epoch 35.260), train_loss = 0.88758255, grad/param norm = 1.6612e-01, time/batch = 13.9988s	
23731/33650 (epoch 35.262), train_loss = 0.86765611, grad/param norm = 2.0859e-01, time/batch = 14.4061s	
23732/33650 (epoch 35.263), train_loss = 0.85553103, grad/param norm = 2.2877e-01, time/batch = 18.3119s	
23733/33650 (epoch 35.264), train_loss = 0.91705556, grad/param norm = 1.8463e-01, time/batch = 17.7968s	
23734/33650 (epoch 35.266), train_loss = 0.90660321, grad/param norm = 1.8380e-01, time/batch = 18.2296s	
23735/33650 (epoch 35.267), train_loss = 0.80678177, grad/param norm = 1.5444e-01, time/batch = 17.9767s	
23736/33650 (epoch 35.269), train_loss = 0.85766235, grad/param norm = 1.8660e-01, time/batch = 17.2280s	
23737/33650 (epoch 35.270), train_loss = 0.76488403, grad/param norm = 1.5486e-01, time/batch = 17.7172s	
23738/33650 (epoch 35.272), train_loss = 0.80838285, grad/param norm = 1.5404e-01, time/batch = 18.3128s	
23739/33650 (epoch 35.273), train_loss = 0.92725537, grad/param norm = 1.8301e-01, time/batch = 16.9581s	
23740/33650 (epoch 35.275), train_loss = 0.90189263, grad/param norm = 1.6710e-01, time/batch = 17.4717s	
23741/33650 (epoch 35.276), train_loss = 0.91559612, grad/param norm = 1.8870e-01, time/batch = 17.3873s	
23742/33650 (epoch 35.278), train_loss = 1.03602804, grad/param norm = 1.8708e-01, time/batch = 17.0528s	
23743/33650 (epoch 35.279), train_loss = 0.83049030, grad/param norm = 1.4455e-01, time/batch = 17.5534s	
23744/33650 (epoch 35.281), train_loss = 0.86702270, grad/param norm = 1.6943e-01, time/batch = 17.1414s	
23745/33650 (epoch 35.282), train_loss = 0.95876529, grad/param norm = 1.4150e-01, time/batch = 18.2266s	
23746/33650 (epoch 35.284), train_loss = 0.91920494, grad/param norm = 1.7824e-01, time/batch = 18.7323s	
23747/33650 (epoch 35.285), train_loss = 0.88592533, grad/param norm = 1.6124e-01, time/batch = 16.5488s	
23748/33650 (epoch 35.287), train_loss = 0.82336253, grad/param norm = 1.6292e-01, time/batch = 18.0574s	
23749/33650 (epoch 35.288), train_loss = 0.82778102, grad/param norm = 1.9844e-01, time/batch = 17.6456s	
23750/33650 (epoch 35.290), train_loss = 0.83733962, grad/param norm = 1.6420e-01, time/batch = 17.7271s	
23751/33650 (epoch 35.291), train_loss = 0.78580247, grad/param norm = 1.5295e-01, time/batch = 18.4723s	
23752/33650 (epoch 35.293), train_loss = 0.85427641, grad/param norm = 1.7072e-01, time/batch = 17.7152s	
23753/33650 (epoch 35.294), train_loss = 0.79570344, grad/param norm = 1.4522e-01, time/batch = 18.5553s	
23754/33650 (epoch 35.296), train_loss = 0.75043949, grad/param norm = 1.6209e-01, time/batch = 17.3931s	
23755/33650 (epoch 35.297), train_loss = 0.82221424, grad/param norm = 1.6776e-01, time/batch = 18.2319s	
23756/33650 (epoch 35.299), train_loss = 0.71535570, grad/param norm = 1.4918e-01, time/batch = 18.5610s	
23757/33650 (epoch 35.300), train_loss = 0.77382376, grad/param norm = 1.5717e-01, time/batch = 17.3900s	
23758/33650 (epoch 35.302), train_loss = 0.86179450, grad/param norm = 1.5475e-01, time/batch = 16.9771s	
23759/33650 (epoch 35.303), train_loss = 0.87382930, grad/param norm = 1.5637e-01, time/batch = 17.2235s	
23760/33650 (epoch 35.305), train_loss = 0.83138046, grad/param norm = 1.5326e-01, time/batch = 18.0571s	
23761/33650 (epoch 35.306), train_loss = 0.77266542, grad/param norm = 1.4555e-01, time/batch = 18.1376s	
23762/33650 (epoch 35.308), train_loss = 0.72936634, grad/param norm = 1.8376e-01, time/batch = 17.9659s	
23763/33650 (epoch 35.309), train_loss = 0.96716685, grad/param norm = 1.9751e-01, time/batch = 17.9812s	
23764/33650 (epoch 35.311), train_loss = 0.85795627, grad/param norm = 2.2543e-01, time/batch = 18.3519s	
23765/33650 (epoch 35.312), train_loss = 0.88949183, grad/param norm = 1.7283e-01, time/batch = 18.4013s	
23766/33650 (epoch 35.314), train_loss = 0.79265774, grad/param norm = 1.8190e-01, time/batch = 17.6587s	
23767/33650 (epoch 35.315), train_loss = 0.82340820, grad/param norm = 1.7456e-01, time/batch = 16.8925s	
23768/33650 (epoch 35.316), train_loss = 0.80291112, grad/param norm = 1.9959e-01, time/batch = 18.3034s	
23769/33650 (epoch 35.318), train_loss = 0.74290567, grad/param norm = 1.6039e-01, time/batch = 17.9926s	
23770/33650 (epoch 35.319), train_loss = 0.78976847, grad/param norm = 1.6040e-01, time/batch = 17.8879s	
23771/33650 (epoch 35.321), train_loss = 0.80898145, grad/param norm = 1.4226e-01, time/batch = 18.3934s	
23772/33650 (epoch 35.322), train_loss = 0.86763144, grad/param norm = 1.9027e-01, time/batch = 18.3981s	
23773/33650 (epoch 35.324), train_loss = 0.88110499, grad/param norm = 1.8687e-01, time/batch = 17.5757s	
23774/33650 (epoch 35.325), train_loss = 0.88382877, grad/param norm = 1.6925e-01, time/batch = 17.7226s	
23775/33650 (epoch 35.327), train_loss = 0.78843842, grad/param norm = 1.4825e-01, time/batch = 17.1548s	
23776/33650 (epoch 35.328), train_loss = 0.86225369, grad/param norm = 1.6919e-01, time/batch = 18.0520s	
23777/33650 (epoch 35.330), train_loss = 0.79509596, grad/param norm = 1.4665e-01, time/batch = 16.2779s	
23778/33650 (epoch 35.331), train_loss = 0.73421502, grad/param norm = 1.3542e-01, time/batch = 17.2973s	
23779/33650 (epoch 35.333), train_loss = 0.80766988, grad/param norm = 1.5842e-01, time/batch = 17.8138s	
23780/33650 (epoch 35.334), train_loss = 0.82415785, grad/param norm = 1.6422e-01, time/batch = 17.6358s	
23781/33650 (epoch 35.336), train_loss = 0.93527079, grad/param norm = 1.5882e-01, time/batch = 17.4002s	
23782/33650 (epoch 35.337), train_loss = 0.71579302, grad/param norm = 1.3141e-01, time/batch = 17.8009s	
23783/33650 (epoch 35.339), train_loss = 0.81716574, grad/param norm = 1.6931e-01, time/batch = 19.1506s	
23784/33650 (epoch 35.340), train_loss = 0.92285276, grad/param norm = 1.7076e-01, time/batch = 16.4708s	
23785/33650 (epoch 35.342), train_loss = 0.68309161, grad/param norm = 1.4849e-01, time/batch = 18.4037s	
23786/33650 (epoch 35.343), train_loss = 0.88213280, grad/param norm = 1.7118e-01, time/batch = 17.2991s	
23787/33650 (epoch 35.345), train_loss = 0.87928304, grad/param norm = 1.7305e-01, time/batch = 16.3664s	
23788/33650 (epoch 35.346), train_loss = 0.58850831, grad/param norm = 1.4194e-01, time/batch = 17.3950s	
23789/33650 (epoch 35.348), train_loss = 0.72997500, grad/param norm = 1.4888e-01, time/batch = 18.3955s	
23790/33650 (epoch 35.349), train_loss = 0.69497544, grad/param norm = 1.6516e-01, time/batch = 18.9735s	
23791/33650 (epoch 35.351), train_loss = 0.87026173, grad/param norm = 1.5975e-01, time/batch = 17.9726s	
23792/33650 (epoch 35.352), train_loss = 0.81087540, grad/param norm = 1.6534e-01, time/batch = 18.2241s	
23793/33650 (epoch 35.354), train_loss = 0.95027932, grad/param norm = 1.9106e-01, time/batch = 18.7290s	
23794/33650 (epoch 35.355), train_loss = 0.97808447, grad/param norm = 1.6116e-01, time/batch = 17.3086s	
23795/33650 (epoch 35.357), train_loss = 0.69781618, grad/param norm = 1.4467e-01, time/batch = 17.9796s	
23796/33650 (epoch 35.358), train_loss = 0.84289295, grad/param norm = 1.5366e-01, time/batch = 16.1951s	
23797/33650 (epoch 35.360), train_loss = 0.89824602, grad/param norm = 1.9496e-01, time/batch = 17.3859s	
23798/33650 (epoch 35.361), train_loss = 0.85265394, grad/param norm = 1.5628e-01, time/batch = 17.3163s	
23799/33650 (epoch 35.363), train_loss = 0.86678160, grad/param norm = 1.5862e-01, time/batch = 18.4907s	
23800/33650 (epoch 35.364), train_loss = 0.83730674, grad/param norm = 1.6457e-01, time/batch = 18.4807s	
23801/33650 (epoch 35.366), train_loss = 0.87760967, grad/param norm = 1.6585e-01, time/batch = 17.5308s	
23802/33650 (epoch 35.367), train_loss = 0.86092681, grad/param norm = 1.7274e-01, time/batch = 18.4838s	
23803/33650 (epoch 35.368), train_loss = 0.80531700, grad/param norm = 1.4310e-01, time/batch = 17.6587s	
23804/33650 (epoch 35.370), train_loss = 0.81712421, grad/param norm = 1.6678e-01, time/batch = 17.3077s	
23805/33650 (epoch 35.371), train_loss = 0.66294819, grad/param norm = 1.4651e-01, time/batch = 18.2325s	
23806/33650 (epoch 35.373), train_loss = 0.73220827, grad/param norm = 1.5981e-01, time/batch = 18.1459s	
23807/33650 (epoch 35.374), train_loss = 0.78314303, grad/param norm = 1.4832e-01, time/batch = 15.3027s	
23808/33650 (epoch 35.376), train_loss = 0.82394316, grad/param norm = 1.9345e-01, time/batch = 17.0615s	
23809/33650 (epoch 35.377), train_loss = 0.86019713, grad/param norm = 1.7767e-01, time/batch = 18.7267s	
23810/33650 (epoch 35.379), train_loss = 0.87392348, grad/param norm = 1.7330e-01, time/batch = 18.6406s	
23811/33650 (epoch 35.380), train_loss = 0.70959670, grad/param norm = 1.8951e-01, time/batch = 16.8025s	
23812/33650 (epoch 35.382), train_loss = 0.85858530, grad/param norm = 1.3159e-01, time/batch = 18.4722s	
23813/33650 (epoch 35.383), train_loss = 0.81424986, grad/param norm = 1.5596e-01, time/batch = 18.4705s	
23814/33650 (epoch 35.385), train_loss = 0.88143871, grad/param norm = 1.7410e-01, time/batch = 16.4750s	
23815/33650 (epoch 35.386), train_loss = 0.77855602, grad/param norm = 1.5767e-01, time/batch = 17.9773s	
23816/33650 (epoch 35.388), train_loss = 0.91705690, grad/param norm = 1.5828e-01, time/batch = 18.3896s	
23817/33650 (epoch 35.389), train_loss = 0.79538056, grad/param norm = 1.9896e-01, time/batch = 18.3123s	
23818/33650 (epoch 35.391), train_loss = 0.66095393, grad/param norm = 1.3638e-01, time/batch = 17.3236s	
23819/33650 (epoch 35.392), train_loss = 0.85720371, grad/param norm = 1.6434e-01, time/batch = 18.6528s	
23820/33650 (epoch 35.394), train_loss = 0.84935615, grad/param norm = 1.6338e-01, time/batch = 17.6209s	
23821/33650 (epoch 35.395), train_loss = 0.88283355, grad/param norm = 1.7659e-01, time/batch = 17.4593s	
23822/33650 (epoch 35.397), train_loss = 1.00813387, grad/param norm = 2.0584e-01, time/batch = 18.6558s	
23823/33650 (epoch 35.398), train_loss = 0.91688898, grad/param norm = 1.5540e-01, time/batch = 16.7963s	
23824/33650 (epoch 35.400), train_loss = 0.83963743, grad/param norm = 1.9365e-01, time/batch = 16.6342s	
23825/33650 (epoch 35.401), train_loss = 0.78626414, grad/param norm = 2.1376e-01, time/batch = 17.4517s	
23826/33650 (epoch 35.403), train_loss = 0.89131422, grad/param norm = 1.7862e-01, time/batch = 17.7351s	
23827/33650 (epoch 35.404), train_loss = 0.82597800, grad/param norm = 1.6060e-01, time/batch = 18.5553s	
23828/33650 (epoch 35.406), train_loss = 0.81964033, grad/param norm = 1.6943e-01, time/batch = 17.3106s	
23829/33650 (epoch 35.407), train_loss = 0.85412127, grad/param norm = 1.9729e-01, time/batch = 17.9850s	
23830/33650 (epoch 35.409), train_loss = 0.87866267, grad/param norm = 1.9139e-01, time/batch = 18.3165s	
23831/33650 (epoch 35.410), train_loss = 0.82914810, grad/param norm = 1.5846e-01, time/batch = 17.3046s	
23832/33650 (epoch 35.412), train_loss = 0.85472028, grad/param norm = 1.5240e-01, time/batch = 18.4751s	
23833/33650 (epoch 35.413), train_loss = 0.80894921, grad/param norm = 2.0039e-01, time/batch = 18.2268s	
23834/33650 (epoch 35.415), train_loss = 0.91068036, grad/param norm = 1.7686e-01, time/batch = 24.1530s	
23835/33650 (epoch 35.416), train_loss = 0.99097198, grad/param norm = 1.5811e-01, time/batch = 25.5000s	
23836/33650 (epoch 35.418), train_loss = 0.76893698, grad/param norm = 1.6424e-01, time/batch = 16.9792s	
23837/33650 (epoch 35.419), train_loss = 0.80291221, grad/param norm = 1.9019e-01, time/batch = 16.6407s	
23838/33650 (epoch 35.421), train_loss = 0.81343800, grad/param norm = 1.4992e-01, time/batch = 17.6356s	
23839/33650 (epoch 35.422), train_loss = 0.96196145, grad/param norm = 1.6994e-01, time/batch = 17.7324s	
23840/33650 (epoch 35.423), train_loss = 0.76703941, grad/param norm = 1.5496e-01, time/batch = 16.7246s	
23841/33650 (epoch 35.425), train_loss = 0.87130777, grad/param norm = 1.7542e-01, time/batch = 18.2220s	
23842/33650 (epoch 35.426), train_loss = 0.89895080, grad/param norm = 1.8453e-01, time/batch = 16.3975s	
23843/33650 (epoch 35.428), train_loss = 0.81951398, grad/param norm = 1.6242e-01, time/batch = 17.8113s	
23844/33650 (epoch 35.429), train_loss = 0.89211861, grad/param norm = 1.7504e-01, time/batch = 17.3129s	
23845/33650 (epoch 35.431), train_loss = 0.98653534, grad/param norm = 1.9961e-01, time/batch = 18.5719s	
23846/33650 (epoch 35.432), train_loss = 0.97911200, grad/param norm = 1.9803e-01, time/batch = 17.3192s	
23847/33650 (epoch 35.434), train_loss = 0.88166471, grad/param norm = 1.8110e-01, time/batch = 16.9735s	
23848/33650 (epoch 35.435), train_loss = 0.85518428, grad/param norm = 1.8683e-01, time/batch = 17.6529s	
23849/33650 (epoch 35.437), train_loss = 0.85425381, grad/param norm = 1.8914e-01, time/batch = 18.4831s	
23850/33650 (epoch 35.438), train_loss = 0.84314382, grad/param norm = 1.6240e-01, time/batch = 17.3981s	
23851/33650 (epoch 35.440), train_loss = 0.84456000, grad/param norm = 1.7875e-01, time/batch = 18.4452s	
23852/33650 (epoch 35.441), train_loss = 0.83374313, grad/param norm = 1.9644e-01, time/batch = 18.7382s	
23853/33650 (epoch 35.443), train_loss = 0.91963135, grad/param norm = 1.4786e-01, time/batch = 17.8278s	
23854/33650 (epoch 35.444), train_loss = 0.83931575, grad/param norm = 1.8120e-01, time/batch = 16.5712s	
23855/33650 (epoch 35.446), train_loss = 0.88742536, grad/param norm = 1.9848e-01, time/batch = 17.9024s	
23856/33650 (epoch 35.447), train_loss = 0.96638662, grad/param norm = 1.7882e-01, time/batch = 17.6438s	
23857/33650 (epoch 35.449), train_loss = 0.94739268, grad/param norm = 2.0485e-01, time/batch = 16.4692s	
23858/33650 (epoch 35.450), train_loss = 1.01865404, grad/param norm = 1.9277e-01, time/batch = 17.2336s	
23859/33650 (epoch 35.452), train_loss = 0.97588886, grad/param norm = 1.9693e-01, time/batch = 17.5723s	
23860/33650 (epoch 35.453), train_loss = 1.01342509, grad/param norm = 1.8716e-01, time/batch = 17.2505s	
23861/33650 (epoch 35.455), train_loss = 0.84625373, grad/param norm = 1.5390e-01, time/batch = 16.7227s	
23862/33650 (epoch 35.456), train_loss = 0.84383214, grad/param norm = 1.5119e-01, time/batch = 17.2290s	
23863/33650 (epoch 35.458), train_loss = 0.84013632, grad/param norm = 1.8353e-01, time/batch = 17.2371s	
23864/33650 (epoch 35.459), train_loss = 0.88840411, grad/param norm = 1.8413e-01, time/batch = 16.0474s	
23865/33650 (epoch 35.461), train_loss = 0.90305192, grad/param norm = 1.9761e-01, time/batch = 16.6491s	
23866/33650 (epoch 35.462), train_loss = 0.94833483, grad/param norm = 1.7663e-01, time/batch = 17.3994s	
23867/33650 (epoch 35.464), train_loss = 0.81335107, grad/param norm = 1.6737e-01, time/batch = 17.0781s	
23868/33650 (epoch 35.465), train_loss = 0.89352338, grad/param norm = 2.2569e-01, time/batch = 15.8853s	
23869/33650 (epoch 35.467), train_loss = 0.87496268, grad/param norm = 1.5906e-01, time/batch = 17.9001s	
23870/33650 (epoch 35.468), train_loss = 1.01162450, grad/param norm = 1.7494e-01, time/batch = 16.9925s	
23871/33650 (epoch 35.470), train_loss = 1.06807586, grad/param norm = 1.9467e-01, time/batch = 16.3155s	
23872/33650 (epoch 35.471), train_loss = 0.86194214, grad/param norm = 1.7668e-01, time/batch = 17.9918s	
23873/33650 (epoch 35.473), train_loss = 0.85309785, grad/param norm = 1.6166e-01, time/batch = 17.9830s	
23874/33650 (epoch 35.474), train_loss = 0.98458588, grad/param norm = 1.8295e-01, time/batch = 17.8229s	
23875/33650 (epoch 35.475), train_loss = 0.94882739, grad/param norm = 1.9081e-01, time/batch = 16.5444s	
23876/33650 (epoch 35.477), train_loss = 0.96935387, grad/param norm = 1.8606e-01, time/batch = 17.1377s	
23877/33650 (epoch 35.478), train_loss = 0.96679481, grad/param norm = 1.8483e-01, time/batch = 16.4747s	
23878/33650 (epoch 35.480), train_loss = 0.94804183, grad/param norm = 1.9053e-01, time/batch = 17.3997s	
23879/33650 (epoch 35.481), train_loss = 0.98357343, grad/param norm = 1.6861e-01, time/batch = 17.2286s	
23880/33650 (epoch 35.483), train_loss = 0.74493354, grad/param norm = 1.5511e-01, time/batch = 18.1639s	
23881/33650 (epoch 35.484), train_loss = 0.83009941, grad/param norm = 1.7378e-01, time/batch = 16.8208s	
23882/33650 (epoch 35.486), train_loss = 1.00016533, grad/param norm = 1.9810e-01, time/batch = 16.6442s	
23883/33650 (epoch 35.487), train_loss = 0.97797020, grad/param norm = 1.7860e-01, time/batch = 15.8913s	
23884/33650 (epoch 35.489), train_loss = 1.02299325, grad/param norm = 1.9078e-01, time/batch = 17.9033s	
23885/33650 (epoch 35.490), train_loss = 0.81326985, grad/param norm = 1.6908e-01, time/batch = 15.8996s	
23886/33650 (epoch 35.492), train_loss = 0.92291497, grad/param norm = 1.9861e-01, time/batch = 17.8907s	
23887/33650 (epoch 35.493), train_loss = 0.74737732, grad/param norm = 1.5202e-01, time/batch = 17.8954s	
23888/33650 (epoch 35.495), train_loss = 0.90686370, grad/param norm = 1.5648e-01, time/batch = 16.5729s	
23889/33650 (epoch 35.496), train_loss = 0.94330189, grad/param norm = 1.9216e-01, time/batch = 16.8008s	
23890/33650 (epoch 35.498), train_loss = 0.79625572, grad/param norm = 1.5608e-01, time/batch = 17.0421s	
23891/33650 (epoch 35.499), train_loss = 0.85776523, grad/param norm = 1.3995e-01, time/batch = 17.8982s	
23892/33650 (epoch 35.501), train_loss = 0.86934548, grad/param norm = 1.5571e-01, time/batch = 16.5634s	
23893/33650 (epoch 35.502), train_loss = 0.90508326, grad/param norm = 1.6765e-01, time/batch = 17.3062s	
23894/33650 (epoch 35.504), train_loss = 0.94415543, grad/param norm = 1.8161e-01, time/batch = 17.5616s	
23895/33650 (epoch 35.505), train_loss = 0.86621325, grad/param norm = 2.0115e-01, time/batch = 17.4756s	
23896/33650 (epoch 35.507), train_loss = 0.98389365, grad/param norm = 1.6839e-01, time/batch = 16.6335s	
23897/33650 (epoch 35.508), train_loss = 0.86419401, grad/param norm = 1.5391e-01, time/batch = 17.1576s	
23898/33650 (epoch 35.510), train_loss = 0.89116104, grad/param norm = 1.6560e-01, time/batch = 17.9172s	
23899/33650 (epoch 35.511), train_loss = 1.03719450, grad/param norm = 2.1842e-01, time/batch = 16.5634s	
23900/33650 (epoch 35.513), train_loss = 0.93641263, grad/param norm = 1.6354e-01, time/batch = 17.4041s	
23901/33650 (epoch 35.514), train_loss = 0.97767448, grad/param norm = 2.2023e-01, time/batch = 18.6461s	
23902/33650 (epoch 35.516), train_loss = 0.89268160, grad/param norm = 2.0300e-01, time/batch = 16.7380s	
23903/33650 (epoch 35.517), train_loss = 0.87846139, grad/param norm = 1.6292e-01, time/batch = 17.0614s	
23904/33650 (epoch 35.519), train_loss = 0.93001724, grad/param norm = 1.8945e-01, time/batch = 17.5653s	
23905/33650 (epoch 35.520), train_loss = 0.78383239, grad/param norm = 1.6404e-01, time/batch = 15.9643s	
23906/33650 (epoch 35.522), train_loss = 0.87674243, grad/param norm = 1.8535e-01, time/batch = 15.9729s	
23907/33650 (epoch 35.523), train_loss = 0.82834710, grad/param norm = 1.8101e-01, time/batch = 16.2215s	
23908/33650 (epoch 35.525), train_loss = 0.69404444, grad/param norm = 1.1875e-01, time/batch = 17.8163s	
23909/33650 (epoch 35.526), train_loss = 0.98891538, grad/param norm = 1.6452e-01, time/batch = 17.2355s	
23910/33650 (epoch 35.527), train_loss = 0.81180622, grad/param norm = 1.6319e-01, time/batch = 16.8978s	
23911/33650 (epoch 35.529), train_loss = 0.89619196, grad/param norm = 1.7361e-01, time/batch = 17.9894s	
23912/33650 (epoch 35.530), train_loss = 0.82496826, grad/param norm = 1.8179e-01, time/batch = 15.9935s	
23913/33650 (epoch 35.532), train_loss = 0.92747495, grad/param norm = 1.9867e-01, time/batch = 16.9860s	
23914/33650 (epoch 35.533), train_loss = 0.88709227, grad/param norm = 1.5997e-01, time/batch = 17.4826s	
23915/33650 (epoch 35.535), train_loss = 1.00386818, grad/param norm = 1.8851e-01, time/batch = 17.4819s	
23916/33650 (epoch 35.536), train_loss = 0.90629202, grad/param norm = 2.0487e-01, time/batch = 16.9911s	
23917/33650 (epoch 35.538), train_loss = 0.91033279, grad/param norm = 2.0246e-01, time/batch = 17.3102s	
23918/33650 (epoch 35.539), train_loss = 0.70263043, grad/param norm = 1.5257e-01, time/batch = 17.4852s	
23919/33650 (epoch 35.541), train_loss = 0.97494055, grad/param norm = 2.2360e-01, time/batch = 17.8995s	
23920/33650 (epoch 35.542), train_loss = 0.88145048, grad/param norm = 2.6246e-01, time/batch = 16.5626s	
23921/33650 (epoch 35.544), train_loss = 1.05726702, grad/param norm = 2.5617e-01, time/batch = 17.4894s	
23922/33650 (epoch 35.545), train_loss = 0.77995771, grad/param norm = 1.5459e-01, time/batch = 18.0807s	
23923/33650 (epoch 35.547), train_loss = 0.93100930, grad/param norm = 1.6900e-01, time/batch = 15.8887s	
23924/33650 (epoch 35.548), train_loss = 1.05296000, grad/param norm = 1.7667e-01, time/batch = 17.2251s	
23925/33650 (epoch 35.550), train_loss = 0.88925444, grad/param norm = 1.6062e-01, time/batch = 17.4078s	
23926/33650 (epoch 35.551), train_loss = 0.90640997, grad/param norm = 2.0070e-01, time/batch = 17.5635s	
23927/33650 (epoch 35.553), train_loss = 0.78899099, grad/param norm = 1.8299e-01, time/batch = 15.8047s	
23928/33650 (epoch 35.554), train_loss = 1.03864996, grad/param norm = 1.9219e-01, time/batch = 16.9834s	
23929/33650 (epoch 35.556), train_loss = 1.01875744, grad/param norm = 2.7149e-01, time/batch = 17.4884s	
23930/33650 (epoch 35.557), train_loss = 0.94823340, grad/param norm = 2.1808e-01, time/batch = 16.8166s	
23931/33650 (epoch 35.559), train_loss = 1.11495972, grad/param norm = 1.9839e-01, time/batch = 17.1426s	
23932/33650 (epoch 35.560), train_loss = 1.02688242, grad/param norm = 1.9956e-01, time/batch = 16.1387s	
23933/33650 (epoch 35.562), train_loss = 0.99839375, grad/param norm = 1.6430e-01, time/batch = 16.9777s	
23934/33650 (epoch 35.563), train_loss = 0.90460608, grad/param norm = 1.5521e-01, time/batch = 16.8229s	
23935/33650 (epoch 35.565), train_loss = 0.92214178, grad/param norm = 1.5950e-01, time/batch = 17.6631s	
23936/33650 (epoch 35.566), train_loss = 0.87708367, grad/param norm = 1.9391e-01, time/batch = 17.8195s	
23937/33650 (epoch 35.568), train_loss = 0.91922191, grad/param norm = 2.4474e-01, time/batch = 16.9704s	
23938/33650 (epoch 35.569), train_loss = 0.80704608, grad/param norm = 1.4708e-01, time/batch = 7.8813s	
23939/33650 (epoch 35.571), train_loss = 0.99041422, grad/param norm = 1.7664e-01, time/batch = 0.6295s	
23940/33650 (epoch 35.572), train_loss = 0.95727425, grad/param norm = 1.7137e-01, time/batch = 0.6281s	
23941/33650 (epoch 35.574), train_loss = 0.80930258, grad/param norm = 1.7700e-01, time/batch = 0.6268s	
23942/33650 (epoch 35.575), train_loss = 0.89543886, grad/param norm = 1.6348e-01, time/batch = 0.6259s	
23943/33650 (epoch 35.577), train_loss = 0.80565546, grad/param norm = 1.7998e-01, time/batch = 0.6280s	
23944/33650 (epoch 35.578), train_loss = 0.99622949, grad/param norm = 2.1675e-01, time/batch = 0.6264s	
23945/33650 (epoch 35.579), train_loss = 0.96409551, grad/param norm = 1.8802e-01, time/batch = 0.6271s	
23946/33650 (epoch 35.581), train_loss = 1.03274272, grad/param norm = 2.0390e-01, time/batch = 0.8639s	
23947/33650 (epoch 35.582), train_loss = 0.92661411, grad/param norm = 1.6980e-01, time/batch = 0.9377s	
23948/33650 (epoch 35.584), train_loss = 0.90599474, grad/param norm = 1.6287e-01, time/batch = 0.9162s	
23949/33650 (epoch 35.585), train_loss = 0.93840916, grad/param norm = 2.4408e-01, time/batch = 0.9223s	
23950/33650 (epoch 35.587), train_loss = 0.83553400, grad/param norm = 1.7823e-01, time/batch = 0.9329s	
23951/33650 (epoch 35.588), train_loss = 0.85069022, grad/param norm = 2.1775e-01, time/batch = 1.2154s	
23952/33650 (epoch 35.590), train_loss = 0.85042523, grad/param norm = 1.4829e-01, time/batch = 1.7130s	
23953/33650 (epoch 35.591), train_loss = 0.77632206, grad/param norm = 1.5994e-01, time/batch = 1.7290s	
23954/33650 (epoch 35.593), train_loss = 0.77673683, grad/param norm = 1.6015e-01, time/batch = 9.0164s	
23955/33650 (epoch 35.594), train_loss = 0.78181878, grad/param norm = 1.6228e-01, time/batch = 17.0782s	
23956/33650 (epoch 35.596), train_loss = 0.86406811, grad/param norm = 1.5526e-01, time/batch = 16.3140s	
23957/33650 (epoch 35.597), train_loss = 0.75825748, grad/param norm = 1.4629e-01, time/batch = 17.0711s	
23958/33650 (epoch 35.599), train_loss = 0.86609563, grad/param norm = 1.6109e-01, time/batch = 16.0637s	
23959/33650 (epoch 35.600), train_loss = 0.82517347, grad/param norm = 1.5391e-01, time/batch = 17.8183s	
23960/33650 (epoch 35.602), train_loss = 0.89613664, grad/param norm = 1.7431e-01, time/batch = 16.9729s	
23961/33650 (epoch 35.603), train_loss = 0.80574967, grad/param norm = 1.4523e-01, time/batch = 17.0692s	
23962/33650 (epoch 35.605), train_loss = 0.92558198, grad/param norm = 1.5700e-01, time/batch = 17.4813s	
23963/33650 (epoch 35.606), train_loss = 0.87525713, grad/param norm = 1.7772e-01, time/batch = 16.3197s	
23964/33650 (epoch 35.608), train_loss = 0.76963115, grad/param norm = 1.7477e-01, time/batch = 15.9784s	
23965/33650 (epoch 35.609), train_loss = 0.86820011, grad/param norm = 1.5721e-01, time/batch = 16.8231s	
23966/33650 (epoch 35.611), train_loss = 0.76088821, grad/param norm = 1.4778e-01, time/batch = 17.2476s	
23967/33650 (epoch 35.612), train_loss = 0.86556584, grad/param norm = 1.8675e-01, time/batch = 16.2323s	
23968/33650 (epoch 35.614), train_loss = 0.97321739, grad/param norm = 1.9362e-01, time/batch = 17.6614s	
23969/33650 (epoch 35.615), train_loss = 0.91196515, grad/param norm = 1.4447e-01, time/batch = 13.5015s	
23970/33650 (epoch 35.617), train_loss = 0.81048214, grad/param norm = 1.3626e-01, time/batch = 13.2688s	
23971/33650 (epoch 35.618), train_loss = 0.86104681, grad/param norm = 1.7336e-01, time/batch = 14.0605s	
23972/33650 (epoch 35.620), train_loss = 0.82344550, grad/param norm = 1.7279e-01, time/batch = 16.4707s	
23973/33650 (epoch 35.621), train_loss = 0.82814026, grad/param norm = 1.7469e-01, time/batch = 16.6374s	
23974/33650 (epoch 35.623), train_loss = 0.85473116, grad/param norm = 1.6631e-01, time/batch = 17.3032s	
23975/33650 (epoch 35.624), train_loss = 0.68130035, grad/param norm = 1.4618e-01, time/batch = 17.5663s	
23976/33650 (epoch 35.626), train_loss = 0.70910631, grad/param norm = 1.5572e-01, time/batch = 17.4023s	
23977/33650 (epoch 35.627), train_loss = 0.79527374, grad/param norm = 1.5255e-01, time/batch = 16.7466s	
23978/33650 (epoch 35.629), train_loss = 0.81712777, grad/param norm = 1.6670e-01, time/batch = 15.6311s	
23979/33650 (epoch 35.630), train_loss = 0.97222264, grad/param norm = 1.7315e-01, time/batch = 17.9850s	
23980/33650 (epoch 35.632), train_loss = 0.94805620, grad/param norm = 1.7169e-01, time/batch = 16.3230s	
23981/33650 (epoch 35.633), train_loss = 0.94555763, grad/param norm = 1.5456e-01, time/batch = 17.6407s	
23982/33650 (epoch 35.634), train_loss = 0.76984380, grad/param norm = 1.5245e-01, time/batch = 17.3899s	
23983/33650 (epoch 35.636), train_loss = 0.67515709, grad/param norm = 1.2031e-01, time/batch = 17.8108s	
23984/33650 (epoch 35.637), train_loss = 0.77916596, grad/param norm = 1.5181e-01, time/batch = 17.1581s	
23985/33650 (epoch 35.639), train_loss = 0.79125203, grad/param norm = 1.3695e-01, time/batch = 15.8186s	
23986/33650 (epoch 35.640), train_loss = 0.88063856, grad/param norm = 1.7043e-01, time/batch = 17.9148s	
23987/33650 (epoch 35.642), train_loss = 0.95092788, grad/param norm = 1.7987e-01, time/batch = 17.7403s	
23988/33650 (epoch 35.643), train_loss = 0.87740184, grad/param norm = 1.7188e-01, time/batch = 16.9071s	
23989/33650 (epoch 35.645), train_loss = 0.88394942, grad/param norm = 1.6808e-01, time/batch = 16.2230s	
23990/33650 (epoch 35.646), train_loss = 0.77612541, grad/param norm = 1.4148e-01, time/batch = 17.6639s	
23991/33650 (epoch 35.648), train_loss = 0.89407335, grad/param norm = 1.5750e-01, time/batch = 17.7378s	
23992/33650 (epoch 35.649), train_loss = 0.77640107, grad/param norm = 1.9113e-01, time/batch = 15.1364s	
23993/33650 (epoch 35.651), train_loss = 0.92590609, grad/param norm = 1.6924e-01, time/batch = 17.8101s	
23994/33650 (epoch 35.652), train_loss = 0.64300210, grad/param norm = 1.2886e-01, time/batch = 17.1557s	
23995/33650 (epoch 35.654), train_loss = 0.76573569, grad/param norm = 1.5292e-01, time/batch = 17.6464s	
23996/33650 (epoch 35.655), train_loss = 0.75989791, grad/param norm = 1.4642e-01, time/batch = 15.7204s	
23997/33650 (epoch 35.657), train_loss = 0.79653977, grad/param norm = 1.7733e-01, time/batch = 17.5685s	
23998/33650 (epoch 35.658), train_loss = 0.70071348, grad/param norm = 1.6917e-01, time/batch = 16.8218s	
23999/33650 (epoch 35.660), train_loss = 0.70598460, grad/param norm = 1.5184e-01, time/batch = 16.2291s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch35.66_1.7689.t7	
24000/33650 (epoch 35.661), train_loss = 0.78234788, grad/param norm = 1.4734e-01, time/batch = 17.4949s	
24001/33650 (epoch 35.663), train_loss = 1.26440707, grad/param norm = 2.2814e-01, time/batch = 15.9674s	
24002/33650 (epoch 35.664), train_loss = 0.82786740, grad/param norm = 1.4841e-01, time/batch = 17.6510s	
24003/33650 (epoch 35.666), train_loss = 0.82455046, grad/param norm = 1.3252e-01, time/batch = 17.9005s	
24004/33650 (epoch 35.667), train_loss = 0.72041380, grad/param norm = 1.4848e-01, time/batch = 17.7358s	
24005/33650 (epoch 35.669), train_loss = 0.75117106, grad/param norm = 1.5851e-01, time/batch = 16.7220s	
24006/33650 (epoch 35.670), train_loss = 0.68571531, grad/param norm = 1.5721e-01, time/batch = 18.0721s	
24007/33650 (epoch 35.672), train_loss = 0.73397608, grad/param norm = 1.9391e-01, time/batch = 16.8138s	
24008/33650 (epoch 35.673), train_loss = 0.70232142, grad/param norm = 1.4941e-01, time/batch = 17.6420s	
24009/33650 (epoch 35.675), train_loss = 0.66784283, grad/param norm = 1.4602e-01, time/batch = 16.9737s	
24010/33650 (epoch 35.676), train_loss = 0.79919699, grad/param norm = 1.6403e-01, time/batch = 17.2207s	
24011/33650 (epoch 35.678), train_loss = 0.78132666, grad/param norm = 1.6946e-01, time/batch = 17.3187s	
24012/33650 (epoch 35.679), train_loss = 0.77148962, grad/param norm = 1.7479e-01, time/batch = 16.7854s	
24013/33650 (epoch 35.681), train_loss = 0.79125049, grad/param norm = 1.5500e-01, time/batch = 17.6564s	
24014/33650 (epoch 35.682), train_loss = 0.78077282, grad/param norm = 1.7546e-01, time/batch = 17.0749s	
24015/33650 (epoch 35.684), train_loss = 0.71600810, grad/param norm = 1.5253e-01, time/batch = 16.5586s	
24016/33650 (epoch 35.685), train_loss = 0.86457080, grad/param norm = 1.8642e-01, time/batch = 17.3199s	
24017/33650 (epoch 35.686), train_loss = 0.84486115, grad/param norm = 1.7164e-01, time/batch = 17.2336s	
24018/33650 (epoch 35.688), train_loss = 0.89734938, grad/param norm = 1.5663e-01, time/batch = 17.4888s	
24019/33650 (epoch 35.689), train_loss = 0.79252814, grad/param norm = 1.7251e-01, time/batch = 16.4005s	
24020/33650 (epoch 35.691), train_loss = 0.92775601, grad/param norm = 1.7565e-01, time/batch = 17.2480s	
24021/33650 (epoch 35.692), train_loss = 0.93210454, grad/param norm = 1.8518e-01, time/batch = 17.5584s	
24022/33650 (epoch 35.694), train_loss = 0.88960075, grad/param norm = 1.8516e-01, time/batch = 17.0618s	
24023/33650 (epoch 35.695), train_loss = 0.57753792, grad/param norm = 1.3823e-01, time/batch = 17.2423s	
24024/33650 (epoch 35.697), train_loss = 0.80790204, grad/param norm = 1.6167e-01, time/batch = 16.0497s	
24025/33650 (epoch 35.698), train_loss = 0.92533065, grad/param norm = 1.8511e-01, time/batch = 16.8910s	
24026/33650 (epoch 35.700), train_loss = 0.82965747, grad/param norm = 1.7265e-01, time/batch = 17.0538s	
24027/33650 (epoch 35.701), train_loss = 0.84373013, grad/param norm = 1.9051e-01, time/batch = 17.5637s	
24028/33650 (epoch 35.703), train_loss = 1.04053191, grad/param norm = 1.7305e-01, time/batch = 17.2408s	
24029/33650 (epoch 35.704), train_loss = 0.82929368, grad/param norm = 1.5490e-01, time/batch = 15.8137s	
24030/33650 (epoch 35.706), train_loss = 0.81214414, grad/param norm = 1.6871e-01, time/batch = 13.4271s	
24031/33650 (epoch 35.707), train_loss = 0.92224159, grad/param norm = 1.6494e-01, time/batch = 13.4251s	
24032/33650 (epoch 35.709), train_loss = 0.79904496, grad/param norm = 1.5964e-01, time/batch = 13.7501s	
24033/33650 (epoch 35.710), train_loss = 0.99448600, grad/param norm = 1.9164e-01, time/batch = 16.5632s	
24034/33650 (epoch 35.712), train_loss = 0.74459975, grad/param norm = 1.7883e-01, time/batch = 14.8825s	
24035/33650 (epoch 35.713), train_loss = 0.76012477, grad/param norm = 1.8955e-01, time/batch = 17.3938s	
24036/33650 (epoch 35.715), train_loss = 0.88281207, grad/param norm = 1.8481e-01, time/batch = 17.4820s	
24037/33650 (epoch 35.716), train_loss = 0.81198150, grad/param norm = 1.6528e-01, time/batch = 16.4820s	
24038/33650 (epoch 35.718), train_loss = 0.79688543, grad/param norm = 1.6438e-01, time/batch = 17.2408s	
24039/33650 (epoch 35.719), train_loss = 0.95018824, grad/param norm = 1.9658e-01, time/batch = 17.3105s	
24040/33650 (epoch 35.721), train_loss = 1.01849839, grad/param norm = 2.1540e-01, time/batch = 15.8797s	
24041/33650 (epoch 35.722), train_loss = 0.90616372, grad/param norm = 2.1136e-01, time/batch = 17.4850s	
24042/33650 (epoch 35.724), train_loss = 0.92806363, grad/param norm = 1.6437e-01, time/batch = 17.8999s	
24043/33650 (epoch 35.725), train_loss = 0.89169866, grad/param norm = 1.7801e-01, time/batch = 17.3010s	
24044/33650 (epoch 35.727), train_loss = 0.79693248, grad/param norm = 1.6913e-01, time/batch = 16.5737s	
24045/33650 (epoch 35.728), train_loss = 0.80512084, grad/param norm = 1.6802e-01, time/batch = 17.9035s	
24046/33650 (epoch 35.730), train_loss = 0.87710550, grad/param norm = 1.6339e-01, time/batch = 17.6644s	
24047/33650 (epoch 35.731), train_loss = 1.02141386, grad/param norm = 1.9235e-01, time/batch = 16.0592s	
24048/33650 (epoch 35.733), train_loss = 0.82802180, grad/param norm = 1.9265e-01, time/batch = 17.9030s	
24049/33650 (epoch 35.734), train_loss = 0.97423042, grad/param norm = 2.1785e-01, time/batch = 16.9854s	
24050/33650 (epoch 35.736), train_loss = 0.84542608, grad/param norm = 2.0004e-01, time/batch = 17.9157s	
24051/33650 (epoch 35.737), train_loss = 0.89321035, grad/param norm = 1.8156e-01, time/batch = 25.8028s	
24052/33650 (epoch 35.738), train_loss = 0.78187963, grad/param norm = 1.8766e-01, time/batch = 17.0585s	
24053/33650 (epoch 35.740), train_loss = 0.72640161, grad/param norm = 1.5665e-01, time/batch = 17.1550s	
24054/33650 (epoch 35.741), train_loss = 0.77307000, grad/param norm = 1.5488e-01, time/batch = 14.9785s	
24055/33650 (epoch 35.743), train_loss = 0.82704138, grad/param norm = 1.5487e-01, time/batch = 17.9868s	
24056/33650 (epoch 35.744), train_loss = 0.93015755, grad/param norm = 1.4892e-01, time/batch = 17.6546s	
24057/33650 (epoch 35.746), train_loss = 0.80519672, grad/param norm = 1.5070e-01, time/batch = 16.0589s	
24058/33650 (epoch 35.747), train_loss = 0.97007935, grad/param norm = 1.7456e-01, time/batch = 17.4821s	
24059/33650 (epoch 35.749), train_loss = 0.68935130, grad/param norm = 1.7262e-01, time/batch = 17.5717s	
24060/33650 (epoch 35.750), train_loss = 0.98923260, grad/param norm = 2.2920e-01, time/batch = 16.2012s	
24061/33650 (epoch 35.752), train_loss = 0.93247409, grad/param norm = 1.6987e-01, time/batch = 16.6435s	
24062/33650 (epoch 35.753), train_loss = 1.03115937, grad/param norm = 1.9584e-01, time/batch = 17.9011s	
24063/33650 (epoch 35.755), train_loss = 0.83622146, grad/param norm = 1.5902e-01, time/batch = 17.3162s	
24064/33650 (epoch 35.756), train_loss = 0.91676552, grad/param norm = 1.7970e-01, time/batch = 16.0349s	
24065/33650 (epoch 35.758), train_loss = 0.95054633, grad/param norm = 1.7347e-01, time/batch = 17.2417s	
24066/33650 (epoch 35.759), train_loss = 0.97544677, grad/param norm = 2.4017e-01, time/batch = 17.8221s	
24067/33650 (epoch 35.761), train_loss = 0.87757290, grad/param norm = 1.7083e-01, time/batch = 17.6516s	
24068/33650 (epoch 35.762), train_loss = 0.86130026, grad/param norm = 1.6926e-01, time/batch = 17.1366s	
24069/33650 (epoch 35.764), train_loss = 0.88960734, grad/param norm = 1.8091e-01, time/batch = 16.2420s	
24070/33650 (epoch 35.765), train_loss = 0.80383537, grad/param norm = 1.6699e-01, time/batch = 18.2324s	
24071/33650 (epoch 35.767), train_loss = 0.84213377, grad/param norm = 1.6232e-01, time/batch = 17.0649s	
24072/33650 (epoch 35.768), train_loss = 0.77551248, grad/param norm = 1.5736e-01, time/batch = 18.0606s	
24073/33650 (epoch 35.770), train_loss = 0.85883631, grad/param norm = 1.8971e-01, time/batch = 16.8889s	
24074/33650 (epoch 35.771), train_loss = 0.90692101, grad/param norm = 1.7964e-01, time/batch = 15.8083s	
24075/33650 (epoch 35.773), train_loss = 0.95939968, grad/param norm = 2.0554e-01, time/batch = 17.4904s	
24076/33650 (epoch 35.774), train_loss = 0.86621905, grad/param norm = 1.5769e-01, time/batch = 17.4016s	
24077/33650 (epoch 35.776), train_loss = 0.92984495, grad/param norm = 1.8932e-01, time/batch = 17.1532s	
24078/33650 (epoch 35.777), train_loss = 0.77153086, grad/param norm = 1.4009e-01, time/batch = 16.9019s	
24079/33650 (epoch 35.779), train_loss = 0.82926074, grad/param norm = 1.4291e-01, time/batch = 15.8841s	
24080/33650 (epoch 35.780), train_loss = 0.77690082, grad/param norm = 1.6074e-01, time/batch = 16.7326s	
24081/33650 (epoch 35.782), train_loss = 0.79149810, grad/param norm = 1.6367e-01, time/batch = 15.9568s	
24082/33650 (epoch 35.783), train_loss = 0.79318664, grad/param norm = 1.3803e-01, time/batch = 17.0655s	
24083/33650 (epoch 35.785), train_loss = 1.00519058, grad/param norm = 1.5877e-01, time/batch = 17.0650s	
24084/33650 (epoch 35.786), train_loss = 0.89083863, grad/param norm = 1.5632e-01, time/batch = 18.0757s	
24085/33650 (epoch 35.788), train_loss = 0.91606448, grad/param norm = 1.6930e-01, time/batch = 16.8192s	
24086/33650 (epoch 35.789), train_loss = 0.94909099, grad/param norm = 1.6746e-01, time/batch = 16.9852s	
24087/33650 (epoch 35.790), train_loss = 0.85681071, grad/param norm = 1.6379e-01, time/batch = 17.6576s	
24088/33650 (epoch 35.792), train_loss = 0.96871968, grad/param norm = 1.9720e-01, time/batch = 17.3113s	
24089/33650 (epoch 35.793), train_loss = 0.92343517, grad/param norm = 1.8880e-01, time/batch = 16.6577s	
24090/33650 (epoch 35.795), train_loss = 0.94034602, grad/param norm = 1.6769e-01, time/batch = 17.1565s	
24091/33650 (epoch 35.796), train_loss = 0.83187169, grad/param norm = 1.7774e-01, time/batch = 17.7960s	
24092/33650 (epoch 35.798), train_loss = 0.82516853, grad/param norm = 1.6696e-01, time/batch = 16.7322s	
24093/33650 (epoch 35.799), train_loss = 0.86471057, grad/param norm = 1.7698e-01, time/batch = 16.7405s	
24094/33650 (epoch 35.801), train_loss = 0.85614160, grad/param norm = 1.9329e-01, time/batch = 17.8076s	
24095/33650 (epoch 35.802), train_loss = 0.95982250, grad/param norm = 1.7704e-01, time/batch = 17.3303s	
24096/33650 (epoch 35.804), train_loss = 0.87266220, grad/param norm = 1.7480e-01, time/batch = 16.3005s	
24097/33650 (epoch 35.805), train_loss = 0.85508791, grad/param norm = 1.5752e-01, time/batch = 16.7226s	
24098/33650 (epoch 35.807), train_loss = 1.01630832, grad/param norm = 2.0230e-01, time/batch = 17.9833s	
24099/33650 (epoch 35.808), train_loss = 1.10814518, grad/param norm = 2.1984e-01, time/batch = 16.5762s	
24100/33650 (epoch 35.810), train_loss = 0.91966607, grad/param norm = 1.7976e-01, time/batch = 17.1585s	
24101/33650 (epoch 35.811), train_loss = 0.88377797, grad/param norm = 1.7710e-01, time/batch = 18.2360s	
24102/33650 (epoch 35.813), train_loss = 0.79275363, grad/param norm = 1.6264e-01, time/batch = 17.9087s	
24103/33650 (epoch 35.814), train_loss = 0.94540396, grad/param norm = 1.8812e-01, time/batch = 16.7225s	
24104/33650 (epoch 35.816), train_loss = 0.93016443, grad/param norm = 1.8659e-01, time/batch = 16.9021s	
24105/33650 (epoch 35.817), train_loss = 0.95441576, grad/param norm = 1.8582e-01, time/batch = 16.6180s	
24106/33650 (epoch 35.819), train_loss = 0.88266164, grad/param norm = 1.7994e-01, time/batch = 15.8182s	
24107/33650 (epoch 35.820), train_loss = 0.97966665, grad/param norm = 1.9376e-01, time/batch = 16.6574s	
24108/33650 (epoch 35.822), train_loss = 0.88895452, grad/param norm = 1.9447e-01, time/batch = 17.4037s	
24109/33650 (epoch 35.823), train_loss = 0.82498620, grad/param norm = 1.9098e-01, time/batch = 17.5577s	
24110/33650 (epoch 35.825), train_loss = 0.87288885, grad/param norm = 1.4769e-01, time/batch = 16.9024s	
24111/33650 (epoch 35.826), train_loss = 0.92432888, grad/param norm = 1.6224e-01, time/batch = 17.4054s	
24112/33650 (epoch 35.828), train_loss = 1.06028804, grad/param norm = 2.3113e-01, time/batch = 17.1386s	
24113/33650 (epoch 35.829), train_loss = 0.75764701, grad/param norm = 1.6126e-01, time/batch = 15.7273s	
24114/33650 (epoch 35.831), train_loss = 0.89904731, grad/param norm = 1.9308e-01, time/batch = 17.9015s	
24115/33650 (epoch 35.832), train_loss = 0.93650690, grad/param norm = 1.8633e-01, time/batch = 16.7151s	
24116/33650 (epoch 35.834), train_loss = 0.93185578, grad/param norm = 1.8998e-01, time/batch = 17.0639s	
24117/33650 (epoch 35.835), train_loss = 1.09688935, grad/param norm = 2.6620e-01, time/batch = 17.2210s	
24118/33650 (epoch 35.837), train_loss = 0.91152469, grad/param norm = 2.3298e-01, time/batch = 17.8148s	
24119/33650 (epoch 35.838), train_loss = 0.88232606, grad/param norm = 1.9194e-01, time/batch = 16.6563s	
24120/33650 (epoch 35.840), train_loss = 0.95556138, grad/param norm = 1.7613e-01, time/batch = 16.6448s	
24121/33650 (epoch 35.841), train_loss = 0.84296601, grad/param norm = 1.6401e-01, time/batch = 17.6482s	
24122/33650 (epoch 35.842), train_loss = 0.86386432, grad/param norm = 1.6633e-01, time/batch = 18.2261s	
24123/33650 (epoch 35.844), train_loss = 1.00512257, grad/param norm = 1.9789e-01, time/batch = 17.1477s	
24124/33650 (epoch 35.845), train_loss = 0.86651941, grad/param norm = 1.6246e-01, time/batch = 16.8930s	
24125/33650 (epoch 35.847), train_loss = 0.66733747, grad/param norm = 1.5142e-01, time/batch = 17.7430s	
24126/33650 (epoch 35.848), train_loss = 0.75888224, grad/param norm = 1.8704e-01, time/batch = 15.9046s	
24127/33650 (epoch 35.850), train_loss = 0.83951260, grad/param norm = 1.8101e-01, time/batch = 16.2166s	
24128/33650 (epoch 35.851), train_loss = 0.74178238, grad/param norm = 1.5361e-01, time/batch = 17.3082s	
24129/33650 (epoch 35.853), train_loss = 0.81957536, grad/param norm = 1.9976e-01, time/batch = 17.2189s	
24130/33650 (epoch 35.854), train_loss = 0.95761910, grad/param norm = 1.7940e-01, time/batch = 16.5887s	
24131/33650 (epoch 35.856), train_loss = 0.68237711, grad/param norm = 1.5479e-01, time/batch = 16.4721s	
24132/33650 (epoch 35.857), train_loss = 0.89294223, grad/param norm = 1.6411e-01, time/batch = 17.5509s	
24133/33650 (epoch 35.859), train_loss = 0.77547924, grad/param norm = 1.5183e-01, time/batch = 17.3961s	
24134/33650 (epoch 35.860), train_loss = 0.74437827, grad/param norm = 1.5525e-01, time/batch = 16.8138s	
24135/33650 (epoch 35.862), train_loss = 0.78868879, grad/param norm = 1.5240e-01, time/batch = 17.3188s	
24136/33650 (epoch 35.863), train_loss = 0.97662458, grad/param norm = 1.5747e-01, time/batch = 17.4918s	
24137/33650 (epoch 35.865), train_loss = 0.86876271, grad/param norm = 1.6721e-01, time/batch = 15.9933s	
24138/33650 (epoch 35.866), train_loss = 0.79341809, grad/param norm = 1.6863e-01, time/batch = 16.3810s	
24139/33650 (epoch 35.868), train_loss = 0.74441637, grad/param norm = 1.9422e-01, time/batch = 17.5758s	
24140/33650 (epoch 35.869), train_loss = 0.92098201, grad/param norm = 1.7592e-01, time/batch = 17.2411s	
24141/33650 (epoch 35.871), train_loss = 0.75403393, grad/param norm = 1.4773e-01, time/batch = 16.8927s	
24142/33650 (epoch 35.872), train_loss = 0.89185222, grad/param norm = 2.0328e-01, time/batch = 17.2332s	
24143/33650 (epoch 35.874), train_loss = 0.91975434, grad/param norm = 1.8088e-01, time/batch = 17.8997s	
24144/33650 (epoch 35.875), train_loss = 0.80898863, grad/param norm = 1.4891e-01, time/batch = 18.0731s	
24145/33650 (epoch 35.877), train_loss = 0.99982707, grad/param norm = 1.7592e-01, time/batch = 17.3921s	
24146/33650 (epoch 35.878), train_loss = 0.63762357, grad/param norm = 1.3378e-01, time/batch = 17.1533s	
24147/33650 (epoch 35.880), train_loss = 0.88239076, grad/param norm = 1.7747e-01, time/batch = 16.7482s	
24148/33650 (epoch 35.881), train_loss = 0.82523400, grad/param norm = 1.6344e-01, time/batch = 16.0762s	
24149/33650 (epoch 35.883), train_loss = 0.89262977, grad/param norm = 1.9037e-01, time/batch = 17.5791s	
24150/33650 (epoch 35.884), train_loss = 0.97371241, grad/param norm = 2.0977e-01, time/batch = 17.8108s	
24151/33650 (epoch 35.886), train_loss = 0.90789022, grad/param norm = 1.6914e-01, time/batch = 15.8922s	
24152/33650 (epoch 35.887), train_loss = 0.74108576, grad/param norm = 1.5678e-01, time/batch = 16.7342s	
24153/33650 (epoch 35.889), train_loss = 0.82703658, grad/param norm = 2.0978e-01, time/batch = 17.1550s	
24154/33650 (epoch 35.890), train_loss = 0.90031066, grad/param norm = 1.6533e-01, time/batch = 17.4879s	
24155/33650 (epoch 35.892), train_loss = 0.79195826, grad/param norm = 1.8465e-01, time/batch = 16.3955s	
24156/33650 (epoch 35.893), train_loss = 0.88762217, grad/param norm = 1.7397e-01, time/batch = 17.3994s	
24157/33650 (epoch 35.895), train_loss = 0.96423528, grad/param norm = 1.6314e-01, time/batch = 17.1649s	
24158/33650 (epoch 35.896), train_loss = 0.79395424, grad/param norm = 1.7201e-01, time/batch = 17.9737s	
24159/33650 (epoch 35.897), train_loss = 0.71765566, grad/param norm = 1.4549e-01, time/batch = 16.1477s	
24160/33650 (epoch 35.899), train_loss = 0.77969739, grad/param norm = 1.5237e-01, time/batch = 17.8171s	
24161/33650 (epoch 35.900), train_loss = 0.74001222, grad/param norm = 1.4941e-01, time/batch = 17.3114s	
24162/33650 (epoch 35.902), train_loss = 0.81803565, grad/param norm = 1.6288e-01, time/batch = 15.5185s	
24163/33650 (epoch 35.903), train_loss = 0.81355312, grad/param norm = 1.7619e-01, time/batch = 17.1627s	
24164/33650 (epoch 35.905), train_loss = 0.95662561, grad/param norm = 1.9384e-01, time/batch = 16.8179s	
24165/33650 (epoch 35.906), train_loss = 0.78927222, grad/param norm = 1.7069e-01, time/batch = 17.8912s	
24166/33650 (epoch 35.908), train_loss = 0.82359846, grad/param norm = 1.6027e-01, time/batch = 16.6440s	
24167/33650 (epoch 35.909), train_loss = 0.80683319, grad/param norm = 1.3868e-01, time/batch = 17.8119s	
24168/33650 (epoch 35.911), train_loss = 0.72620816, grad/param norm = 1.4130e-01, time/batch = 17.2382s	
24169/33650 (epoch 35.912), train_loss = 0.66908493, grad/param norm = 1.4044e-01, time/batch = 16.1566s	
24170/33650 (epoch 35.914), train_loss = 0.86360377, grad/param norm = 1.5346e-01, time/batch = 17.5718s	
24171/33650 (epoch 35.915), train_loss = 0.82034118, grad/param norm = 1.7806e-01, time/batch = 17.0710s	
24172/33650 (epoch 35.917), train_loss = 0.80632901, grad/param norm = 1.5931e-01, time/batch = 17.4007s	
24173/33650 (epoch 35.918), train_loss = 0.76516387, grad/param norm = 1.5197e-01, time/batch = 17.1426s	
24174/33650 (epoch 35.920), train_loss = 0.75824007, grad/param norm = 1.5522e-01, time/batch = 16.7202s	
24175/33650 (epoch 35.921), train_loss = 0.75705012, grad/param norm = 1.5270e-01, time/batch = 15.8047s	
24176/33650 (epoch 35.923), train_loss = 0.67770002, grad/param norm = 1.3938e-01, time/batch = 16.8959s	
24177/33650 (epoch 35.924), train_loss = 0.86147468, grad/param norm = 1.6096e-01, time/batch = 17.0624s	
24178/33650 (epoch 35.926), train_loss = 0.79399341, grad/param norm = 1.9227e-01, time/batch = 17.6489s	
24179/33650 (epoch 35.927), train_loss = 0.82528808, grad/param norm = 1.7465e-01, time/batch = 18.1511s	
24180/33650 (epoch 35.929), train_loss = 0.90685942, grad/param norm = 1.6116e-01, time/batch = 16.9847s	
24181/33650 (epoch 35.930), train_loss = 0.80614910, grad/param norm = 1.7187e-01, time/batch = 17.5570s	
24182/33650 (epoch 35.932), train_loss = 0.84169790, grad/param norm = 1.7333e-01, time/batch = 17.1468s	
24183/33650 (epoch 35.933), train_loss = 0.70960682, grad/param norm = 1.5690e-01, time/batch = 16.7322s	
24184/33650 (epoch 35.935), train_loss = 0.71545052, grad/param norm = 1.6072e-01, time/batch = 17.3922s	
24185/33650 (epoch 35.936), train_loss = 0.75453497, grad/param norm = 1.4287e-01, time/batch = 17.4784s	
24186/33650 (epoch 35.938), train_loss = 0.72211362, grad/param norm = 1.4497e-01, time/batch = 15.1444s	
24187/33650 (epoch 35.939), train_loss = 0.90654594, grad/param norm = 1.4670e-01, time/batch = 16.8885s	
24188/33650 (epoch 35.941), train_loss = 0.82506687, grad/param norm = 1.4999e-01, time/batch = 17.3194s	
24189/33650 (epoch 35.942), train_loss = 0.90736038, grad/param norm = 1.7631e-01, time/batch = 17.3941s	
24190/33650 (epoch 35.944), train_loss = 0.78078326, grad/param norm = 1.4259e-01, time/batch = 16.6489s	
24191/33650 (epoch 35.945), train_loss = 0.84658947, grad/param norm = 1.7365e-01, time/batch = 17.4067s	
24192/33650 (epoch 35.947), train_loss = 0.94253588, grad/param norm = 2.3781e-01, time/batch = 17.0692s	
24193/33650 (epoch 35.948), train_loss = 0.95156265, grad/param norm = 1.9401e-01, time/batch = 16.3053s	
24194/33650 (epoch 35.949), train_loss = 0.72455153, grad/param norm = 1.6065e-01, time/batch = 17.0619s	
24195/33650 (epoch 35.951), train_loss = 0.98006832, grad/param norm = 1.6717e-01, time/batch = 17.5711s	
24196/33650 (epoch 35.952), train_loss = 0.87621390, grad/param norm = 1.6629e-01, time/batch = 17.2296s	
24197/33650 (epoch 35.954), train_loss = 0.86771239, grad/param norm = 1.6359e-01, time/batch = 16.2346s	
24198/33650 (epoch 35.955), train_loss = 0.84732584, grad/param norm = 1.5495e-01, time/batch = 16.2202s	
24199/33650 (epoch 35.957), train_loss = 0.88237798, grad/param norm = 1.7500e-01, time/batch = 17.9004s	
24200/33650 (epoch 35.958), train_loss = 0.67346216, grad/param norm = 1.4890e-01, time/batch = 17.1510s	
24201/33650 (epoch 35.960), train_loss = 0.68798694, grad/param norm = 1.4824e-01, time/batch = 15.6174s	
24202/33650 (epoch 35.961), train_loss = 0.75176665, grad/param norm = 1.6486e-01, time/batch = 17.5566s	
24203/33650 (epoch 35.963), train_loss = 0.75508218, grad/param norm = 1.6896e-01, time/batch = 17.1341s	
24204/33650 (epoch 35.964), train_loss = 0.90968611, grad/param norm = 1.5902e-01, time/batch = 16.2163s	
24205/33650 (epoch 35.966), train_loss = 0.85445550, grad/param norm = 1.6968e-01, time/batch = 17.0648s	
24206/33650 (epoch 35.967), train_loss = 0.87948131, grad/param norm = 1.7252e-01, time/batch = 17.2464s	
24207/33650 (epoch 35.969), train_loss = 0.81831485, grad/param norm = 1.4693e-01, time/batch = 18.2409s	
24208/33650 (epoch 35.970), train_loss = 0.84734083, grad/param norm = 1.7111e-01, time/batch = 17.1313s	
24209/33650 (epoch 35.972), train_loss = 1.10930369, grad/param norm = 1.9876e-01, time/batch = 17.8982s	
24210/33650 (epoch 35.973), train_loss = 0.77418482, grad/param norm = 1.4749e-01, time/batch = 17.7410s	
24211/33650 (epoch 35.975), train_loss = 0.73380100, grad/param norm = 1.4440e-01, time/batch = 16.3912s	
24212/33650 (epoch 35.976), train_loss = 0.76414274, grad/param norm = 1.3543e-01, time/batch = 15.8779s	
24213/33650 (epoch 35.978), train_loss = 0.76799133, grad/param norm = 1.5973e-01, time/batch = 17.9931s	
24214/33650 (epoch 35.979), train_loss = 0.83390702, grad/param norm = 1.8103e-01, time/batch = 17.2457s	
24215/33650 (epoch 35.981), train_loss = 0.81080921, grad/param norm = 1.5184e-01, time/batch = 17.1284s	
24216/33650 (epoch 35.982), train_loss = 0.83419257, grad/param norm = 1.6427e-01, time/batch = 18.0763s	
24217/33650 (epoch 35.984), train_loss = 0.69031478, grad/param norm = 1.5228e-01, time/batch = 17.2337s	
24218/33650 (epoch 35.985), train_loss = 0.74897301, grad/param norm = 1.6043e-01, time/batch = 17.1363s	
24219/33650 (epoch 35.987), train_loss = 0.84431185, grad/param norm = 1.5604e-01, time/batch = 16.4885s	
24220/33650 (epoch 35.988), train_loss = 0.77343964, grad/param norm = 1.5399e-01, time/batch = 18.1444s	
24221/33650 (epoch 35.990), train_loss = 0.98395511, grad/param norm = 1.9510e-01, time/batch = 16.9771s	
24222/33650 (epoch 35.991), train_loss = 0.86329381, grad/param norm = 1.7518e-01, time/batch = 17.0610s	
24223/33650 (epoch 35.993), train_loss = 0.84587289, grad/param norm = 1.7542e-01, time/batch = 17.3200s	
24224/33650 (epoch 35.994), train_loss = 0.85307696, grad/param norm = 1.4275e-01, time/batch = 16.9806s	
24225/33650 (epoch 35.996), train_loss = 0.82110197, grad/param norm = 1.7603e-01, time/batch = 16.3066s	
24226/33650 (epoch 35.997), train_loss = 0.90119565, grad/param norm = 1.8078e-01, time/batch = 17.6539s	
24227/33650 (epoch 35.999), train_loss = 0.75373617, grad/param norm = 1.5416e-01, time/batch = 17.3269s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
24228/33650 (epoch 36.000), train_loss = 0.91791516, grad/param norm = 2.0107e-01, time/batch = 17.1415s	
24229/33650 (epoch 36.001), train_loss = 0.96328832, grad/param norm = 1.6772e-01, time/batch = 17.1422s	
24230/33650 (epoch 36.003), train_loss = 0.95889026, grad/param norm = 1.8884e-01, time/batch = 15.3088s	
24231/33650 (epoch 36.004), train_loss = 0.86893869, grad/param norm = 1.6845e-01, time/batch = 14.5384s	
24232/33650 (epoch 36.006), train_loss = 0.81298899, grad/param norm = 1.5278e-01, time/batch = 14.5533s	
24233/33650 (epoch 36.007), train_loss = 0.85515290, grad/param norm = 1.6356e-01, time/batch = 14.8768s	
24234/33650 (epoch 36.009), train_loss = 0.77454254, grad/param norm = 1.6734e-01, time/batch = 14.2765s	
24235/33650 (epoch 36.010), train_loss = 0.93923664, grad/param norm = 1.7162e-01, time/batch = 14.6300s	
24236/33650 (epoch 36.012), train_loss = 0.80939106, grad/param norm = 1.6381e-01, time/batch = 17.1321s	
24237/33650 (epoch 36.013), train_loss = 0.85703106, grad/param norm = 2.0903e-01, time/batch = 15.9676s	
24238/33650 (epoch 36.015), train_loss = 0.82452052, grad/param norm = 1.6318e-01, time/batch = 17.8899s	
24239/33650 (epoch 36.016), train_loss = 0.77290055, grad/param norm = 1.8802e-01, time/batch = 15.9649s	
24240/33650 (epoch 36.018), train_loss = 0.83713450, grad/param norm = 2.0933e-01, time/batch = 17.3228s	
24241/33650 (epoch 36.019), train_loss = 0.79617438, grad/param norm = 1.7864e-01, time/batch = 17.1501s	
24242/33650 (epoch 36.021), train_loss = 0.89581899, grad/param norm = 1.7293e-01, time/batch = 18.1556s	
24243/33650 (epoch 36.022), train_loss = 0.80721842, grad/param norm = 1.5069e-01, time/batch = 16.2282s	
24244/33650 (epoch 36.024), train_loss = 0.75716390, grad/param norm = 1.7189e-01, time/batch = 17.1547s	
24245/33650 (epoch 36.025), train_loss = 0.85995235, grad/param norm = 1.7236e-01, time/batch = 17.0701s	
24246/33650 (epoch 36.027), train_loss = 0.85528846, grad/param norm = 1.6915e-01, time/batch = 15.5697s	
24247/33650 (epoch 36.028), train_loss = 0.89503061, grad/param norm = 1.5849e-01, time/batch = 16.8075s	
24248/33650 (epoch 36.030), train_loss = 0.84627574, grad/param norm = 1.7418e-01, time/batch = 16.8988s	
24249/33650 (epoch 36.031), train_loss = 0.77224792, grad/param norm = 1.4117e-01, time/batch = 17.8887s	
24250/33650 (epoch 36.033), train_loss = 0.86099286, grad/param norm = 1.5913e-01, time/batch = 16.9812s	
24251/33650 (epoch 36.034), train_loss = 0.88885773, grad/param norm = 1.7399e-01, time/batch = 15.6991s	
24252/33650 (epoch 36.036), train_loss = 0.95034846, grad/param norm = 1.8898e-01, time/batch = 17.6538s	
24253/33650 (epoch 36.037), train_loss = 0.78574851, grad/param norm = 1.3871e-01, time/batch = 17.2362s	
24254/33650 (epoch 36.039), train_loss = 0.92629839, grad/param norm = 1.5432e-01, time/batch = 16.1418s	
24255/33650 (epoch 36.040), train_loss = 0.99652951, grad/param norm = 1.9237e-01, time/batch = 17.2323s	
24256/33650 (epoch 36.042), train_loss = 0.99984222, grad/param norm = 1.8030e-01, time/batch = 17.8922s	
24257/33650 (epoch 36.043), train_loss = 0.81202869, grad/param norm = 1.5352e-01, time/batch = 16.7962s	
24258/33650 (epoch 36.045), train_loss = 0.78540551, grad/param norm = 1.5837e-01, time/batch = 16.5548s	
24259/33650 (epoch 36.046), train_loss = 0.90271247, grad/param norm = 1.6478e-01, time/batch = 17.2312s	
24260/33650 (epoch 36.048), train_loss = 0.92918855, grad/param norm = 1.7366e-01, time/batch = 17.9069s	
24261/33650 (epoch 36.049), train_loss = 0.80459329, grad/param norm = 1.6245e-01, time/batch = 26.5942s	
24262/33650 (epoch 36.051), train_loss = 0.98623727, grad/param norm = 1.7122e-01, time/batch = 20.8437s	
24263/33650 (epoch 36.052), train_loss = 0.95179120, grad/param norm = 1.7502e-01, time/batch = 17.8052s	
24264/33650 (epoch 36.053), train_loss = 0.91752536, grad/param norm = 1.7137e-01, time/batch = 16.8077s	
24265/33650 (epoch 36.055), train_loss = 0.79584345, grad/param norm = 1.6049e-01, time/batch = 16.4001s	
24266/33650 (epoch 36.056), train_loss = 0.74542832, grad/param norm = 1.3880e-01, time/batch = 17.9165s	
24267/33650 (epoch 36.058), train_loss = 0.91570621, grad/param norm = 1.9475e-01, time/batch = 16.9843s	
24268/33650 (epoch 36.059), train_loss = 0.92980237, grad/param norm = 1.8538e-01, time/batch = 17.3991s	
24269/33650 (epoch 36.061), train_loss = 0.94339564, grad/param norm = 1.7594e-01, time/batch = 15.7938s	
24270/33650 (epoch 36.062), train_loss = 0.89542095, grad/param norm = 1.4048e-01, time/batch = 17.2375s	
24271/33650 (epoch 36.064), train_loss = 0.83999235, grad/param norm = 1.6419e-01, time/batch = 17.0567s	
24272/33650 (epoch 36.065), train_loss = 0.82330905, grad/param norm = 1.8763e-01, time/batch = 17.8289s	
24273/33650 (epoch 36.067), train_loss = 0.77907426, grad/param norm = 1.4896e-01, time/batch = 17.5698s	
24274/33650 (epoch 36.068), train_loss = 0.86802404, grad/param norm = 1.5692e-01, time/batch = 15.7036s	
24275/33650 (epoch 36.070), train_loss = 0.91736712, grad/param norm = 1.6737e-01, time/batch = 17.8234s	
24276/33650 (epoch 36.071), train_loss = 0.79967594, grad/param norm = 1.5470e-01, time/batch = 16.9151s	
24277/33650 (epoch 36.073), train_loss = 0.87711096, grad/param norm = 1.7510e-01, time/batch = 17.8995s	
24278/33650 (epoch 36.074), train_loss = 0.96145786, grad/param norm = 1.6693e-01, time/batch = 16.8143s	
24279/33650 (epoch 36.076), train_loss = 0.92910302, grad/param norm = 1.9692e-01, time/batch = 17.4104s	
24280/33650 (epoch 36.077), train_loss = 0.82833033, grad/param norm = 1.4982e-01, time/batch = 15.6432s	
24281/33650 (epoch 36.079), train_loss = 0.89225515, grad/param norm = 1.6583e-01, time/batch = 16.5683s	
24282/33650 (epoch 36.080), train_loss = 0.89798837, grad/param norm = 1.8000e-01, time/batch = 16.9009s	
24283/33650 (epoch 36.082), train_loss = 0.86729305, grad/param norm = 1.5960e-01, time/batch = 17.4862s	
24284/33650 (epoch 36.083), train_loss = 0.87854292, grad/param norm = 1.7057e-01, time/batch = 17.9812s	
24285/33650 (epoch 36.085), train_loss = 0.94253037, grad/param norm = 1.6179e-01, time/batch = 16.9783s	
24286/33650 (epoch 36.086), train_loss = 0.88236015, grad/param norm = 1.6136e-01, time/batch = 17.4129s	
24287/33650 (epoch 36.088), train_loss = 0.83490714, grad/param norm = 1.5413e-01, time/batch = 16.7423s	
24288/33650 (epoch 36.089), train_loss = 0.79119380, grad/param norm = 1.6984e-01, time/batch = 15.9721s	
24289/33650 (epoch 36.091), train_loss = 0.83347158, grad/param norm = 1.5346e-01, time/batch = 16.6925s	
24290/33650 (epoch 36.092), train_loss = 0.84410848, grad/param norm = 1.7325e-01, time/batch = 16.5515s	
24291/33650 (epoch 36.094), train_loss = 0.93184012, grad/param norm = 1.6813e-01, time/batch = 16.9051s	
24292/33650 (epoch 36.095), train_loss = 0.89891543, grad/param norm = 1.7830e-01, time/batch = 16.7310s	
24293/33650 (epoch 36.097), train_loss = 0.80576453, grad/param norm = 1.7814e-01, time/batch = 17.2505s	
24294/33650 (epoch 36.098), train_loss = 0.70025639, grad/param norm = 1.8409e-01, time/batch = 17.6617s	
24295/33650 (epoch 36.100), train_loss = 0.76992747, grad/param norm = 1.5913e-01, time/batch = 16.8069s	
24296/33650 (epoch 36.101), train_loss = 0.85534075, grad/param norm = 1.7628e-01, time/batch = 16.5785s	
24297/33650 (epoch 36.103), train_loss = 0.82914114, grad/param norm = 1.7202e-01, time/batch = 18.0641s	
24298/33650 (epoch 36.104), train_loss = 0.99415242, grad/param norm = 1.7296e-01, time/batch = 16.4383s	
24299/33650 (epoch 36.105), train_loss = 0.88844373, grad/param norm = 1.7852e-01, time/batch = 15.8849s	
24300/33650 (epoch 36.107), train_loss = 0.81631084, grad/param norm = 1.6048e-01, time/batch = 17.2433s	
24301/33650 (epoch 36.108), train_loss = 0.89110047, grad/param norm = 1.6418e-01, time/batch = 18.4091s	
24302/33650 (epoch 36.110), train_loss = 0.98766529, grad/param norm = 1.6051e-01, time/batch = 17.1552s	
24303/33650 (epoch 36.111), train_loss = 0.83832197, grad/param norm = 1.6686e-01, time/batch = 17.0792s	
24304/33650 (epoch 36.113), train_loss = 0.81634796, grad/param norm = 1.8873e-01, time/batch = 17.2280s	
24305/33650 (epoch 36.114), train_loss = 0.92825689, grad/param norm = 1.5349e-01, time/batch = 17.4777s	
24306/33650 (epoch 36.116), train_loss = 0.79131569, grad/param norm = 1.2682e-01, time/batch = 17.4835s	
24307/33650 (epoch 36.117), train_loss = 0.85746838, grad/param norm = 1.5687e-01, time/batch = 17.5644s	
24308/33650 (epoch 36.119), train_loss = 0.76222702, grad/param norm = 1.3394e-01, time/batch = 17.5772s	
24309/33650 (epoch 36.120), train_loss = 0.78387867, grad/param norm = 1.5148e-01, time/batch = 16.1506s	
24310/33650 (epoch 36.122), train_loss = 0.65777268, grad/param norm = 1.3758e-01, time/batch = 17.6455s	
24311/33650 (epoch 36.123), train_loss = 0.78768502, grad/param norm = 1.4340e-01, time/batch = 17.3130s	
24312/33650 (epoch 36.125), train_loss = 0.90799700, grad/param norm = 1.6551e-01, time/batch = 17.4855s	
24313/33650 (epoch 36.126), train_loss = 0.92047325, grad/param norm = 1.8592e-01, time/batch = 15.5399s	
24314/33650 (epoch 36.128), train_loss = 0.90192924, grad/param norm = 1.7874e-01, time/batch = 18.1499s	
24315/33650 (epoch 36.129), train_loss = 0.90664537, grad/param norm = 1.6688e-01, time/batch = 17.4973s	
24316/33650 (epoch 36.131), train_loss = 0.87277153, grad/param norm = 1.9525e-01, time/batch = 15.8601s	
24317/33650 (epoch 36.132), train_loss = 0.86573490, grad/param norm = 1.4765e-01, time/batch = 17.1506s	
24318/33650 (epoch 36.134), train_loss = 0.93116581, grad/param norm = 2.1814e-01, time/batch = 17.6518s	
24319/33650 (epoch 36.135), train_loss = 0.73717325, grad/param norm = 1.4491e-01, time/batch = 17.0784s	
24320/33650 (epoch 36.137), train_loss = 0.89000146, grad/param norm = 2.6123e-01, time/batch = 16.8970s	
24321/33650 (epoch 36.138), train_loss = 0.91869193, grad/param norm = 1.7577e-01, time/batch = 17.2349s	
24322/33650 (epoch 36.140), train_loss = 0.88059724, grad/param norm = 1.9153e-01, time/batch = 17.0540s	
24323/33650 (epoch 36.141), train_loss = 0.97632730, grad/param norm = 1.7585e-01, time/batch = 16.1537s	
24324/33650 (epoch 36.143), train_loss = 1.01288021, grad/param norm = 2.3340e-01, time/batch = 16.9712s	
24325/33650 (epoch 36.144), train_loss = 0.91047701, grad/param norm = 1.9050e-01, time/batch = 17.9521s	
24326/33650 (epoch 36.146), train_loss = 0.86096971, grad/param norm = 1.6662e-01, time/batch = 17.3186s	
24327/33650 (epoch 36.147), train_loss = 0.77077211, grad/param norm = 1.5069e-01, time/batch = 17.3917s	
24328/33650 (epoch 36.149), train_loss = 0.78194720, grad/param norm = 1.8273e-01, time/batch = 17.1548s	
24329/33650 (epoch 36.150), train_loss = 0.75094809, grad/param norm = 1.5913e-01, time/batch = 17.6541s	
24330/33650 (epoch 36.152), train_loss = 0.80401476, grad/param norm = 1.6599e-01, time/batch = 16.3090s	
24331/33650 (epoch 36.153), train_loss = 0.82822539, grad/param norm = 1.6934e-01, time/batch = 16.7481s	
24332/33650 (epoch 36.155), train_loss = 0.79751476, grad/param norm = 1.5244e-01, time/batch = 16.6434s	
24333/33650 (epoch 36.156), train_loss = 0.76573592, grad/param norm = 1.3993e-01, time/batch = 16.9698s	
24334/33650 (epoch 36.158), train_loss = 0.90315403, grad/param norm = 1.7578e-01, time/batch = 15.7916s	
24335/33650 (epoch 36.159), train_loss = 0.79245887, grad/param norm = 1.4898e-01, time/batch = 17.3988s	
24336/33650 (epoch 36.160), train_loss = 0.79633868, grad/param norm = 1.5456e-01, time/batch = 18.1595s	
24337/33650 (epoch 36.162), train_loss = 0.82026810, grad/param norm = 1.8169e-01, time/batch = 16.8173s	
24338/33650 (epoch 36.163), train_loss = 0.88216339, grad/param norm = 2.0826e-01, time/batch = 16.9967s	
24339/33650 (epoch 36.165), train_loss = 0.75488361, grad/param norm = 1.6545e-01, time/batch = 17.2340s	
24340/33650 (epoch 36.166), train_loss = 0.74858213, grad/param norm = 1.8174e-01, time/batch = 17.5637s	
24341/33650 (epoch 36.168), train_loss = 0.94870102, grad/param norm = 1.7654e-01, time/batch = 16.6473s	
24342/33650 (epoch 36.169), train_loss = 0.84872578, grad/param norm = 1.9431e-01, time/batch = 16.1349s	
24343/33650 (epoch 36.171), train_loss = 0.84394699, grad/param norm = 1.5433e-01, time/batch = 17.3161s	
24344/33650 (epoch 36.172), train_loss = 0.79649467, grad/param norm = 1.4568e-01, time/batch = 16.4826s	
24345/33650 (epoch 36.174), train_loss = 0.77698203, grad/param norm = 1.8628e-01, time/batch = 15.9775s	
24346/33650 (epoch 36.175), train_loss = 0.71802075, grad/param norm = 1.7465e-01, time/batch = 13.6335s	
24347/33650 (epoch 36.177), train_loss = 0.86760936, grad/param norm = 2.0394e-01, time/batch = 13.7087s	
24348/33650 (epoch 36.178), train_loss = 0.80072464, grad/param norm = 1.7425e-01, time/batch = 14.6328s	
24349/33650 (epoch 36.180), train_loss = 0.76880077, grad/param norm = 1.5383e-01, time/batch = 17.2283s	
24350/33650 (epoch 36.181), train_loss = 0.68778934, grad/param norm = 1.4485e-01, time/batch = 17.9083s	
24351/33650 (epoch 36.183), train_loss = 0.78022339, grad/param norm = 1.7444e-01, time/batch = 17.5044s	
24352/33650 (epoch 36.184), train_loss = 0.76977570, grad/param norm = 1.6677e-01, time/batch = 16.3981s	
24353/33650 (epoch 36.186), train_loss = 0.81613295, grad/param norm = 1.7662e-01, time/batch = 17.7411s	
24354/33650 (epoch 36.187), train_loss = 0.93326018, grad/param norm = 1.7885e-01, time/batch = 17.5616s	
24355/33650 (epoch 36.189), train_loss = 0.93596742, grad/param norm = 1.9749e-01, time/batch = 16.7396s	
24356/33650 (epoch 36.190), train_loss = 0.87595945, grad/param norm = 2.0921e-01, time/batch = 17.0538s	
24357/33650 (epoch 36.192), train_loss = 1.02408772, grad/param norm = 1.7887e-01, time/batch = 18.0654s	
24358/33650 (epoch 36.193), train_loss = 0.98937707, grad/param norm = 1.6268e-01, time/batch = 16.7859s	
24359/33650 (epoch 36.195), train_loss = 0.75193986, grad/param norm = 1.7248e-01, time/batch = 17.3751s	
24360/33650 (epoch 36.196), train_loss = 0.70751491, grad/param norm = 1.6714e-01, time/batch = 17.3934s	
24361/33650 (epoch 36.198), train_loss = 0.84305363, grad/param norm = 1.6567e-01, time/batch = 16.8973s	
24362/33650 (epoch 36.199), train_loss = 0.92508071, grad/param norm = 1.9555e-01, time/batch = 15.7381s	
24363/33650 (epoch 36.201), train_loss = 0.80178394, grad/param norm = 1.7986e-01, time/batch = 17.2391s	
24364/33650 (epoch 36.202), train_loss = 0.83364702, grad/param norm = 1.5312e-01, time/batch = 17.4046s	
24365/33650 (epoch 36.204), train_loss = 0.87857564, grad/param norm = 1.4846e-01, time/batch = 17.7485s	
24366/33650 (epoch 36.205), train_loss = 0.83000779, grad/param norm = 1.7902e-01, time/batch = 16.8049s	
24367/33650 (epoch 36.207), train_loss = 0.79981137, grad/param norm = 2.2194e-01, time/batch = 17.4848s	
24368/33650 (epoch 36.208), train_loss = 0.88970460, grad/param norm = 1.7331e-01, time/batch = 17.4962s	
24369/33650 (epoch 36.210), train_loss = 0.70877845, grad/param norm = 1.6461e-01, time/batch = 17.4739s	
24370/33650 (epoch 36.211), train_loss = 0.78395814, grad/param norm = 1.9133e-01, time/batch = 15.5713s	
24371/33650 (epoch 36.212), train_loss = 0.87337863, grad/param norm = 2.0480e-01, time/batch = 17.0619s	
24372/33650 (epoch 36.214), train_loss = 1.02075996, grad/param norm = 1.7728e-01, time/batch = 17.6424s	
24373/33650 (epoch 36.215), train_loss = 0.68371759, grad/param norm = 1.8995e-01, time/batch = 16.5841s	
24374/33650 (epoch 36.217), train_loss = 0.81774437, grad/param norm = 1.9350e-01, time/batch = 17.9832s	
24375/33650 (epoch 36.218), train_loss = 0.81816571, grad/param norm = 1.5086e-01, time/batch = 15.8610s	
24376/33650 (epoch 36.220), train_loss = 0.73132950, grad/param norm = 2.0075e-01, time/batch = 16.9004s	
24377/33650 (epoch 36.221), train_loss = 0.99084329, grad/param norm = 1.9208e-01, time/batch = 16.6512s	
24378/33650 (epoch 36.223), train_loss = 0.69178266, grad/param norm = 1.6289e-01, time/batch = 16.7131s	
24379/33650 (epoch 36.224), train_loss = 0.81440855, grad/param norm = 2.2000e-01, time/batch = 17.3886s	
24380/33650 (epoch 36.226), train_loss = 1.09138502, grad/param norm = 1.8851e-01, time/batch = 16.5544s	
24381/33650 (epoch 36.227), train_loss = 0.91762857, grad/param norm = 1.7385e-01, time/batch = 17.6531s	
24382/33650 (epoch 36.229), train_loss = 0.95734784, grad/param norm = 1.8538e-01, time/batch = 17.2406s	
24383/33650 (epoch 36.230), train_loss = 1.07368055, grad/param norm = 2.2013e-01, time/batch = 16.6422s	
24384/33650 (epoch 36.232), train_loss = 0.91239839, grad/param norm = 1.8644e-01, time/batch = 16.4809s	
24385/33650 (epoch 36.233), train_loss = 0.88165614, grad/param norm = 1.8474e-01, time/batch = 16.2045s	
24386/33650 (epoch 36.235), train_loss = 0.84058870, grad/param norm = 1.8025e-01, time/batch = 16.7856s	
24387/33650 (epoch 36.236), train_loss = 0.79065497, grad/param norm = 1.4991e-01, time/batch = 16.3896s	
24388/33650 (epoch 36.238), train_loss = 0.81076765, grad/param norm = 1.6129e-01, time/batch = 17.4012s	
24389/33650 (epoch 36.239), train_loss = 0.76790961, grad/param norm = 1.6577e-01, time/batch = 17.5715s	
24390/33650 (epoch 36.241), train_loss = 0.83250941, grad/param norm = 1.5947e-01, time/batch = 17.7345s	
24391/33650 (epoch 36.242), train_loss = 0.67521445, grad/param norm = 1.6228e-01, time/batch = 17.1383s	
24392/33650 (epoch 36.244), train_loss = 0.82631945, grad/param norm = 1.6105e-01, time/batch = 17.4120s	
24393/33650 (epoch 36.245), train_loss = 0.72524897, grad/param norm = 1.3880e-01, time/batch = 17.2261s	
24394/33650 (epoch 36.247), train_loss = 0.80889139, grad/param norm = 1.5727e-01, time/batch = 16.7277s	
24395/33650 (epoch 36.248), train_loss = 0.74475958, grad/param norm = 1.6672e-01, time/batch = 16.9748s	
24396/33650 (epoch 36.250), train_loss = 0.83331366, grad/param norm = 1.5449e-01, time/batch = 16.4826s	
24397/33650 (epoch 36.251), train_loss = 0.92504276, grad/param norm = 1.6520e-01, time/batch = 17.2253s	
24398/33650 (epoch 36.253), train_loss = 0.73567359, grad/param norm = 1.5164e-01, time/batch = 17.3189s	
24399/33650 (epoch 36.254), train_loss = 0.82284570, grad/param norm = 1.8636e-01, time/batch = 18.1523s	
24400/33650 (epoch 36.256), train_loss = 0.94613885, grad/param norm = 1.5757e-01, time/batch = 15.8999s	
24401/33650 (epoch 36.257), train_loss = 0.90759281, grad/param norm = 1.6345e-01, time/batch = 17.5494s	
24402/33650 (epoch 36.259), train_loss = 0.78643299, grad/param norm = 1.8801e-01, time/batch = 17.6509s	
24403/33650 (epoch 36.260), train_loss = 0.87960479, grad/param norm = 1.8339e-01, time/batch = 18.0655s	
24404/33650 (epoch 36.262), train_loss = 0.86081173, grad/param norm = 1.8389e-01, time/batch = 17.8082s	
24405/33650 (epoch 36.263), train_loss = 0.85696886, grad/param norm = 2.2813e-01, time/batch = 17.9820s	
24406/33650 (epoch 36.264), train_loss = 0.92145782, grad/param norm = 1.9843e-01, time/batch = 17.9785s	
24407/33650 (epoch 36.266), train_loss = 0.88330910, grad/param norm = 1.5338e-01, time/batch = 17.9791s	
24408/33650 (epoch 36.267), train_loss = 0.81105793, grad/param norm = 1.5809e-01, time/batch = 17.2349s	
24409/33650 (epoch 36.269), train_loss = 0.84132804, grad/param norm = 1.6315e-01, time/batch = 18.8175s	
24410/33650 (epoch 36.270), train_loss = 0.76203996, grad/param norm = 1.6636e-01, time/batch = 15.9303s	
24411/33650 (epoch 36.272), train_loss = 0.79084904, grad/param norm = 1.5046e-01, time/batch = 18.1383s	
24412/33650 (epoch 36.273), train_loss = 0.91983495, grad/param norm = 2.1023e-01, time/batch = 17.1211s	
24413/33650 (epoch 36.275), train_loss = 0.89468231, grad/param norm = 1.7828e-01, time/batch = 18.6218s	
24414/33650 (epoch 36.276), train_loss = 0.90165217, grad/param norm = 1.7862e-01, time/batch = 17.1482s	
24415/33650 (epoch 36.278), train_loss = 1.02585629, grad/param norm = 2.3532e-01, time/batch = 18.7317s	
24416/33650 (epoch 36.279), train_loss = 0.83049459, grad/param norm = 1.6141e-01, time/batch = 18.9851s	
24417/33650 (epoch 36.281), train_loss = 0.87507548, grad/param norm = 1.7435e-01, time/batch = 16.3866s	
24418/33650 (epoch 36.282), train_loss = 0.95400982, grad/param norm = 1.4573e-01, time/batch = 18.3972s	
24419/33650 (epoch 36.284), train_loss = 0.91139745, grad/param norm = 1.7705e-01, time/batch = 18.3973s	
24420/33650 (epoch 36.285), train_loss = 0.87962031, grad/param norm = 1.7038e-01, time/batch = 18.1442s	
24421/33650 (epoch 36.287), train_loss = 0.81654334, grad/param norm = 1.7020e-01, time/batch = 18.3820s	
24422/33650 (epoch 36.288), train_loss = 0.81262482, grad/param norm = 1.8423e-01, time/batch = 18.7341s	
24423/33650 (epoch 36.290), train_loss = 0.83047651, grad/param norm = 1.6604e-01, time/batch = 18.2235s	
24424/33650 (epoch 36.291), train_loss = 0.78573674, grad/param norm = 1.5708e-01, time/batch = 17.3029s	
24425/33650 (epoch 36.293), train_loss = 0.85517713, grad/param norm = 1.8569e-01, time/batch = 18.8105s	
24426/33650 (epoch 36.294), train_loss = 0.79638449, grad/param norm = 1.4768e-01, time/batch = 16.6343s	
24427/33650 (epoch 36.296), train_loss = 0.74362653, grad/param norm = 1.6176e-01, time/batch = 17.7927s	
24428/33650 (epoch 36.297), train_loss = 0.80849779, grad/param norm = 1.6833e-01, time/batch = 18.2222s	
24429/33650 (epoch 36.299), train_loss = 0.71868313, grad/param norm = 1.6736e-01, time/batch = 19.0611s	
24430/33650 (epoch 36.300), train_loss = 0.74998161, grad/param norm = 1.5500e-01, time/batch = 16.6205s	
24431/33650 (epoch 36.302), train_loss = 0.85961018, grad/param norm = 1.6430e-01, time/batch = 18.0398s	
24432/33650 (epoch 36.303), train_loss = 0.86236270, grad/param norm = 1.4705e-01, time/batch = 17.9848s	
24433/33650 (epoch 36.305), train_loss = 0.82859282, grad/param norm = 1.6863e-01, time/batch = 16.7393s	
24434/33650 (epoch 36.306), train_loss = 0.77316600, grad/param norm = 1.6039e-01, time/batch = 16.7143s	
24435/33650 (epoch 36.308), train_loss = 0.71593901, grad/param norm = 1.8735e-01, time/batch = 16.5605s	
24436/33650 (epoch 36.309), train_loss = 0.96119200, grad/param norm = 1.8830e-01, time/batch = 17.7281s	
24437/33650 (epoch 36.311), train_loss = 0.84296505, grad/param norm = 1.8427e-01, time/batch = 16.4887s	
24438/33650 (epoch 36.312), train_loss = 0.87839901, grad/param norm = 1.7347e-01, time/batch = 17.1388s	
24439/33650 (epoch 36.314), train_loss = 0.78227124, grad/param norm = 1.5091e-01, time/batch = 17.3129s	
24440/33650 (epoch 36.315), train_loss = 0.80683277, grad/param norm = 2.0174e-01, time/batch = 17.4865s	
24441/33650 (epoch 36.316), train_loss = 0.79981246, grad/param norm = 1.8371e-01, time/batch = 16.1210s	
24442/33650 (epoch 36.318), train_loss = 0.74092197, grad/param norm = 1.5042e-01, time/batch = 17.6236s	
24443/33650 (epoch 36.319), train_loss = 0.77601746, grad/param norm = 1.5231e-01, time/batch = 17.1532s	
24444/33650 (epoch 36.321), train_loss = 0.81286487, grad/param norm = 1.4464e-01, time/batch = 17.3148s	
24445/33650 (epoch 36.322), train_loss = 0.85194604, grad/param norm = 1.7498e-01, time/batch = 16.3754s	
24446/33650 (epoch 36.324), train_loss = 0.87497618, grad/param norm = 1.9636e-01, time/batch = 17.2986s	
24447/33650 (epoch 36.325), train_loss = 0.87767398, grad/param norm = 1.6448e-01, time/batch = 17.9790s	
24448/33650 (epoch 36.327), train_loss = 0.78451325, grad/param norm = 1.4475e-01, time/batch = 16.4764s	
24449/33650 (epoch 36.328), train_loss = 0.85172292, grad/param norm = 1.6891e-01, time/batch = 16.0589s	
24450/33650 (epoch 36.330), train_loss = 0.77665840, grad/param norm = 1.4046e-01, time/batch = 17.3973s	
24451/33650 (epoch 36.331), train_loss = 0.72474666, grad/param norm = 1.5634e-01, time/batch = 17.4758s	
24452/33650 (epoch 36.333), train_loss = 0.79837587, grad/param norm = 1.6160e-01, time/batch = 17.5309s	
24453/33650 (epoch 36.334), train_loss = 0.81894350, grad/param norm = 1.5359e-01, time/batch = 17.7972s	
24454/33650 (epoch 36.336), train_loss = 0.92660830, grad/param norm = 1.6410e-01, time/batch = 17.4843s	
24455/33650 (epoch 36.337), train_loss = 0.72377810, grad/param norm = 1.4705e-01, time/batch = 16.7300s	
24456/33650 (epoch 36.339), train_loss = 0.80877412, grad/param norm = 1.7488e-01, time/batch = 17.7252s	
24457/33650 (epoch 36.340), train_loss = 0.90783179, grad/param norm = 1.8104e-01, time/batch = 18.3879s	
24458/33650 (epoch 36.342), train_loss = 0.69546620, grad/param norm = 2.0114e-01, time/batch = 17.6489s	
24459/33650 (epoch 36.343), train_loss = 0.87650795, grad/param norm = 1.7413e-01, time/batch = 17.6286s	
24460/33650 (epoch 36.345), train_loss = 0.86774519, grad/param norm = 1.8459e-01, time/batch = 18.3128s	
24461/33650 (epoch 36.346), train_loss = 0.59987610, grad/param norm = 1.6495e-01, time/batch = 17.8979s	
24462/33650 (epoch 36.348), train_loss = 0.70837230, grad/param norm = 1.4773e-01, time/batch = 16.7280s	
24463/33650 (epoch 36.349), train_loss = 0.67973183, grad/param norm = 1.4987e-01, time/batch = 18.0673s	
24464/33650 (epoch 36.351), train_loss = 0.86548248, grad/param norm = 1.8569e-01, time/batch = 15.8055s	
24465/33650 (epoch 36.352), train_loss = 0.79965626, grad/param norm = 1.6784e-01, time/batch = 17.3849s	
24466/33650 (epoch 36.354), train_loss = 0.96100332, grad/param norm = 1.9606e-01, time/batch = 17.8955s	
24467/33650 (epoch 36.355), train_loss = 0.96862940, grad/param norm = 1.6905e-01, time/batch = 18.2968s	
24468/33650 (epoch 36.357), train_loss = 0.69701167, grad/param norm = 1.5244e-01, time/batch = 17.6375s	
24469/33650 (epoch 36.358), train_loss = 0.83464858, grad/param norm = 1.7086e-01, time/batch = 31.9788s	
24470/33650 (epoch 36.360), train_loss = 0.89018265, grad/param norm = 1.8657e-01, time/batch = 18.3896s	
24471/33650 (epoch 36.361), train_loss = 0.85170464, grad/param norm = 1.6604e-01, time/batch = 16.4529s	
24472/33650 (epoch 36.363), train_loss = 0.86234495, grad/param norm = 1.6535e-01, time/batch = 18.3068s	
24473/33650 (epoch 36.364), train_loss = 0.82831194, grad/param norm = 1.6541e-01, time/batch = 17.6366s	
24474/33650 (epoch 36.366), train_loss = 0.88440911, grad/param norm = 1.8496e-01, time/batch = 17.2243s	
24475/33650 (epoch 36.367), train_loss = 0.86478254, grad/param norm = 1.5972e-01, time/batch = 16.2110s	
24476/33650 (epoch 36.368), train_loss = 0.80459452, grad/param norm = 1.4685e-01, time/batch = 18.2142s	
24477/33650 (epoch 36.370), train_loss = 0.81249977, grad/param norm = 1.7310e-01, time/batch = 17.4775s	
24478/33650 (epoch 36.371), train_loss = 0.64212416, grad/param norm = 1.4330e-01, time/batch = 17.2239s	
24479/33650 (epoch 36.373), train_loss = 0.73923117, grad/param norm = 1.6020e-01, time/batch = 18.3142s	
24480/33650 (epoch 36.374), train_loss = 0.78124517, grad/param norm = 1.4803e-01, time/batch = 17.1089s	
24481/33650 (epoch 36.376), train_loss = 0.82930800, grad/param norm = 2.1458e-01, time/batch = 17.5510s	
24482/33650 (epoch 36.377), train_loss = 0.85015392, grad/param norm = 1.5864e-01, time/batch = 17.1497s	
24483/33650 (epoch 36.379), train_loss = 0.87029684, grad/param norm = 1.7850e-01, time/batch = 18.4000s	
24484/33650 (epoch 36.380), train_loss = 0.71244242, grad/param norm = 2.3239e-01, time/batch = 18.6357s	
24485/33650 (epoch 36.382), train_loss = 0.86433231, grad/param norm = 1.6053e-01, time/batch = 16.9690s	
24486/33650 (epoch 36.383), train_loss = 0.81788260, grad/param norm = 1.6722e-01, time/batch = 18.2397s	
24487/33650 (epoch 36.385), train_loss = 0.85975643, grad/param norm = 1.5713e-01, time/batch = 18.3054s	
24488/33650 (epoch 36.386), train_loss = 0.76526729, grad/param norm = 1.5491e-01, time/batch = 17.0456s	
24489/33650 (epoch 36.388), train_loss = 0.91994264, grad/param norm = 1.6474e-01, time/batch = 16.3104s	
24490/33650 (epoch 36.389), train_loss = 0.75264707, grad/param norm = 1.4577e-01, time/batch = 18.3114s	
24491/33650 (epoch 36.391), train_loss = 0.65731577, grad/param norm = 1.4530e-01, time/batch = 17.9834s	
24492/33650 (epoch 36.392), train_loss = 0.84158705, grad/param norm = 1.5843e-01, time/batch = 16.1914s	
24493/33650 (epoch 36.394), train_loss = 0.85807221, grad/param norm = 1.7137e-01, time/batch = 17.7266s	
24494/33650 (epoch 36.395), train_loss = 0.86209911, grad/param norm = 1.5200e-01, time/batch = 17.9718s	
24495/33650 (epoch 36.397), train_loss = 1.00162433, grad/param norm = 2.0981e-01, time/batch = 17.3786s	
24496/33650 (epoch 36.398), train_loss = 0.91467777, grad/param norm = 1.6343e-01, time/batch = 15.7385s	
24497/33650 (epoch 36.400), train_loss = 0.83580442, grad/param norm = 2.2827e-01, time/batch = 17.8079s	
24498/33650 (epoch 36.401), train_loss = 0.75783053, grad/param norm = 1.5689e-01, time/batch = 17.7218s	
24499/33650 (epoch 36.403), train_loss = 0.86627048, grad/param norm = 2.0286e-01, time/batch = 17.9730s	
24500/33650 (epoch 36.404), train_loss = 0.83032661, grad/param norm = 1.5446e-01, time/batch = 17.4878s	
24501/33650 (epoch 36.406), train_loss = 0.80533164, grad/param norm = 1.6797e-01, time/batch = 18.5638s	
24502/33650 (epoch 36.407), train_loss = 0.84692487, grad/param norm = 1.8519e-01, time/batch = 16.9735s	
24503/33650 (epoch 36.409), train_loss = 0.86591393, grad/param norm = 2.1103e-01, time/batch = 18.4735s	
24504/33650 (epoch 36.410), train_loss = 0.82586612, grad/param norm = 1.6378e-01, time/batch = 15.2816s	
24505/33650 (epoch 36.412), train_loss = 0.86525586, grad/param norm = 1.8532e-01, time/batch = 17.6337s	
24506/33650 (epoch 36.413), train_loss = 0.81404191, grad/param norm = 2.1463e-01, time/batch = 17.4750s	
24507/33650 (epoch 36.415), train_loss = 0.90571942, grad/param norm = 1.8366e-01, time/batch = 16.6650s	
24508/33650 (epoch 36.416), train_loss = 0.99504927, grad/param norm = 1.7519e-01, time/batch = 18.3125s	
24509/33650 (epoch 36.418), train_loss = 0.77089764, grad/param norm = 1.8616e-01, time/batch = 17.4756s	
24510/33650 (epoch 36.419), train_loss = 0.79055126, grad/param norm = 1.5542e-01, time/batch = 18.5637s	
24511/33650 (epoch 36.421), train_loss = 0.81221271, grad/param norm = 1.4104e-01, time/batch = 17.7320s	
24512/33650 (epoch 36.422), train_loss = 0.96604377, grad/param norm = 1.7651e-01, time/batch = 16.2237s	
24513/33650 (epoch 36.423), train_loss = 0.75424942, grad/param norm = 1.3326e-01, time/batch = 18.4580s	
24514/33650 (epoch 36.425), train_loss = 0.86708653, grad/param norm = 1.7451e-01, time/batch = 18.2274s	
24515/33650 (epoch 36.426), train_loss = 0.90251818, grad/param norm = 2.0986e-01, time/batch = 17.1237s	
24516/33650 (epoch 36.428), train_loss = 0.80821250, grad/param norm = 1.5801e-01, time/batch = 17.1064s	
24517/33650 (epoch 36.429), train_loss = 0.87932549, grad/param norm = 1.6456e-01, time/batch = 18.7323s	
24518/33650 (epoch 36.431), train_loss = 0.98095785, grad/param norm = 2.0732e-01, time/batch = 19.0702s	
24519/33650 (epoch 36.432), train_loss = 0.97461918, grad/param norm = 1.9650e-01, time/batch = 17.3837s	
24520/33650 (epoch 36.434), train_loss = 0.87640234, grad/param norm = 1.7233e-01, time/batch = 18.4002s	
24521/33650 (epoch 36.435), train_loss = 0.87099893, grad/param norm = 2.0984e-01, time/batch = 16.1957s	
24522/33650 (epoch 36.437), train_loss = 0.85441973, grad/param norm = 1.8714e-01, time/batch = 17.6376s	
24523/33650 (epoch 36.438), train_loss = 0.83544761, grad/param norm = 1.6612e-01, time/batch = 17.2170s	
24524/33650 (epoch 36.440), train_loss = 0.83355235, grad/param norm = 1.9859e-01, time/batch = 17.5634s	
24525/33650 (epoch 36.441), train_loss = 0.82526869, grad/param norm = 1.9005e-01, time/batch = 17.7953s	
24526/33650 (epoch 36.443), train_loss = 0.92693277, grad/param norm = 1.7458e-01, time/batch = 18.1345s	
24527/33650 (epoch 36.444), train_loss = 0.82904202, grad/param norm = 1.6194e-01, time/batch = 15.6625s	
24528/33650 (epoch 36.446), train_loss = 0.89754115, grad/param norm = 2.1933e-01, time/batch = 13.7456s	
24529/33650 (epoch 36.447), train_loss = 0.95050551, grad/param norm = 1.7742e-01, time/batch = 14.3489s	
24530/33650 (epoch 36.449), train_loss = 0.95819689, grad/param norm = 2.1483e-01, time/batch = 15.4638s	
24531/33650 (epoch 36.450), train_loss = 1.00373847, grad/param norm = 1.8460e-01, time/batch = 17.8942s	
24532/33650 (epoch 36.452), train_loss = 0.98958168, grad/param norm = 2.0152e-01, time/batch = 17.7331s	
24533/33650 (epoch 36.453), train_loss = 0.99264998, grad/param norm = 1.8642e-01, time/batch = 17.9475s	
24534/33650 (epoch 36.455), train_loss = 0.83760808, grad/param norm = 1.5874e-01, time/batch = 17.8924s	
24535/33650 (epoch 36.456), train_loss = 0.85362302, grad/param norm = 1.6600e-01, time/batch = 17.6442s	
24536/33650 (epoch 36.458), train_loss = 0.83732557, grad/param norm = 1.8474e-01, time/batch = 16.6389s	
24537/33650 (epoch 36.459), train_loss = 0.88087945, grad/param norm = 2.0723e-01, time/batch = 17.7660s	
24538/33650 (epoch 36.461), train_loss = 0.89237452, grad/param norm = 1.9659e-01, time/batch = 17.1397s	
24539/33650 (epoch 36.462), train_loss = 0.94490571, grad/param norm = 1.8334e-01, time/batch = 17.1363s	
24540/33650 (epoch 36.464), train_loss = 0.83213055, grad/param norm = 1.8905e-01, time/batch = 17.5409s	
24541/33650 (epoch 36.465), train_loss = 0.90120326, grad/param norm = 3.2763e-01, time/batch = 18.4816s	
24542/33650 (epoch 36.467), train_loss = 0.87439419, grad/param norm = 1.6861e-01, time/batch = 18.7383s	
24543/33650 (epoch 36.468), train_loss = 1.01227760, grad/param norm = 1.7861e-01, time/batch = 17.1406s	
24544/33650 (epoch 36.470), train_loss = 1.06165826, grad/param norm = 2.0636e-01, time/batch = 18.2267s	
24545/33650 (epoch 36.471), train_loss = 0.85817486, grad/param norm = 1.8258e-01, time/batch = 15.9534s	
24546/33650 (epoch 36.473), train_loss = 0.82409046, grad/param norm = 1.4925e-01, time/batch = 18.1313s	
24547/33650 (epoch 36.474), train_loss = 0.97810209, grad/param norm = 1.7811e-01, time/batch = 17.4758s	
24548/33650 (epoch 36.475), train_loss = 0.93528385, grad/param norm = 1.8568e-01, time/batch = 18.4733s	
24549/33650 (epoch 36.477), train_loss = 0.96368724, grad/param norm = 1.9578e-01, time/batch = 16.2937s	
24550/33650 (epoch 36.478), train_loss = 0.95002733, grad/param norm = 1.7766e-01, time/batch = 16.8079s	
24551/33650 (epoch 36.480), train_loss = 0.93748729, grad/param norm = 2.2758e-01, time/batch = 18.4736s	
24552/33650 (epoch 36.481), train_loss = 0.97716912, grad/param norm = 1.8285e-01, time/batch = 17.8958s	
24553/33650 (epoch 36.483), train_loss = 0.72552035, grad/param norm = 1.4849e-01, time/batch = 16.9684s	
24554/33650 (epoch 36.484), train_loss = 0.83587126, grad/param norm = 1.6289e-01, time/batch = 17.7276s	
24555/33650 (epoch 36.486), train_loss = 1.02622687, grad/param norm = 2.2224e-01, time/batch = 18.3125s	
24556/33650 (epoch 36.487), train_loss = 0.96229587, grad/param norm = 1.6607e-01, time/batch = 18.3117s	
24557/33650 (epoch 36.489), train_loss = 1.00554099, grad/param norm = 1.8600e-01, time/batch = 18.3786s	
24558/33650 (epoch 36.490), train_loss = 0.81779356, grad/param norm = 1.8259e-01, time/batch = 17.7277s	
24559/33650 (epoch 36.492), train_loss = 0.91696276, grad/param norm = 2.0100e-01, time/batch = 19.1286s	
24560/33650 (epoch 36.493), train_loss = 0.74415338, grad/param norm = 1.4100e-01, time/batch = 16.4712s	
24561/33650 (epoch 36.495), train_loss = 0.89223960, grad/param norm = 1.5924e-01, time/batch = 18.4830s	
24562/33650 (epoch 36.496), train_loss = 0.91730004, grad/param norm = 1.7574e-01, time/batch = 17.1535s	
24563/33650 (epoch 36.498), train_loss = 0.81172747, grad/param norm = 1.8263e-01, time/batch = 17.8161s	
24564/33650 (epoch 36.499), train_loss = 0.85930051, grad/param norm = 1.4153e-01, time/batch = 17.3309s	
24565/33650 (epoch 36.501), train_loss = 0.86599623, grad/param norm = 1.4374e-01, time/batch = 17.9778s	
24566/33650 (epoch 36.502), train_loss = 0.90431366, grad/param norm = 1.9638e-01, time/batch = 16.5355s	
24567/33650 (epoch 36.504), train_loss = 0.96682530, grad/param norm = 2.1015e-01, time/batch = 16.8773s	
24568/33650 (epoch 36.505), train_loss = 0.86086875, grad/param norm = 2.2338e-01, time/batch = 17.6477s	
24569/33650 (epoch 36.507), train_loss = 0.96650094, grad/param norm = 1.8122e-01, time/batch = 18.8144s	
24570/33650 (epoch 36.508), train_loss = 0.86549269, grad/param norm = 1.6740e-01, time/batch = 16.8007s	
24571/33650 (epoch 36.510), train_loss = 0.88533802, grad/param norm = 1.7174e-01, time/batch = 18.4922s	
24572/33650 (epoch 36.511), train_loss = 1.02335433, grad/param norm = 2.2083e-01, time/batch = 18.0581s	
24573/33650 (epoch 36.513), train_loss = 0.91455561, grad/param norm = 1.5475e-01, time/batch = 17.2234s	
24574/33650 (epoch 36.514), train_loss = 0.98353098, grad/param norm = 1.9829e-01, time/batch = 18.5610s	
24575/33650 (epoch 36.516), train_loss = 0.89927724, grad/param norm = 1.9897e-01, time/batch = 18.0639s	
24576/33650 (epoch 36.517), train_loss = 0.87500787, grad/param norm = 1.6923e-01, time/batch = 17.8077s	
24577/33650 (epoch 36.519), train_loss = 0.93944290, grad/param norm = 1.9397e-01, time/batch = 17.2252s	
24578/33650 (epoch 36.520), train_loss = 0.76308675, grad/param norm = 1.4431e-01, time/batch = 17.5299s	
24579/33650 (epoch 36.522), train_loss = 0.85425377, grad/param norm = 1.7576e-01, time/batch = 17.1272s	
24580/33650 (epoch 36.523), train_loss = 0.81433096, grad/param norm = 1.7750e-01, time/batch = 16.9862s	
24581/33650 (epoch 36.525), train_loss = 0.69445044, grad/param norm = 1.2976e-01, time/batch = 17.8812s	
24582/33650 (epoch 36.526), train_loss = 0.98074759, grad/param norm = 1.6349e-01, time/batch = 17.3024s	
24583/33650 (epoch 36.527), train_loss = 0.81246818, grad/param norm = 1.6080e-01, time/batch = 17.4116s	
24584/33650 (epoch 36.529), train_loss = 0.89255392, grad/param norm = 1.7282e-01, time/batch = 18.4570s	
24585/33650 (epoch 36.530), train_loss = 0.82031177, grad/param norm = 1.6556e-01, time/batch = 17.6564s	
24586/33650 (epoch 36.532), train_loss = 0.91475959, grad/param norm = 1.7474e-01, time/batch = 18.8165s	
24587/33650 (epoch 36.533), train_loss = 0.88210560, grad/param norm = 1.5617e-01, time/batch = 16.7161s	
24588/33650 (epoch 36.535), train_loss = 0.98126171, grad/param norm = 1.7657e-01, time/batch = 18.6498s	
24589/33650 (epoch 36.536), train_loss = 0.88852082, grad/param norm = 2.0521e-01, time/batch = 18.1573s	
24590/33650 (epoch 36.538), train_loss = 0.90035710, grad/param norm = 2.0269e-01, time/batch = 16.8084s	
24591/33650 (epoch 36.539), train_loss = 0.71567687, grad/param norm = 1.8083e-01, time/batch = 17.8982s	
24592/33650 (epoch 36.541), train_loss = 0.98868312, grad/param norm = 2.1303e-01, time/batch = 18.1495s	
24593/33650 (epoch 36.542), train_loss = 0.85039864, grad/param norm = 2.2939e-01, time/batch = 18.1488s	
24594/33650 (epoch 36.544), train_loss = 1.01344393, grad/param norm = 2.0040e-01, time/batch = 16.1786s	
24595/33650 (epoch 36.545), train_loss = 0.77222727, grad/param norm = 1.5976e-01, time/batch = 18.5498s	
24596/33650 (epoch 36.547), train_loss = 0.93873303, grad/param norm = 1.8115e-01, time/batch = 17.7324s	
24597/33650 (epoch 36.548), train_loss = 1.04582061, grad/param norm = 1.8355e-01, time/batch = 17.3101s	
24598/33650 (epoch 36.550), train_loss = 0.89341980, grad/param norm = 1.8079e-01, time/batch = 18.1210s	
24599/33650 (epoch 36.551), train_loss = 0.90199956, grad/param norm = 1.8076e-01, time/batch = 18.1288s	
24600/33650 (epoch 36.553), train_loss = 0.76472724, grad/param norm = 1.6775e-01, time/batch = 17.6197s	
24601/33650 (epoch 36.554), train_loss = 1.02791635, grad/param norm = 1.8674e-01, time/batch = 17.8034s	
24602/33650 (epoch 36.556), train_loss = 0.97608270, grad/param norm = 2.3629e-01, time/batch = 18.3175s	
24603/33650 (epoch 36.557), train_loss = 0.94174165, grad/param norm = 2.0843e-01, time/batch = 18.3995s	
24604/33650 (epoch 36.559), train_loss = 1.11194018, grad/param norm = 2.0944e-01, time/batch = 5.0609s	
24605/33650 (epoch 36.560), train_loss = 1.00559962, grad/param norm = 1.8767e-01, time/batch = 0.6449s	
24606/33650 (epoch 36.562), train_loss = 0.99307704, grad/param norm = 1.8095e-01, time/batch = 0.6483s	
24607/33650 (epoch 36.563), train_loss = 0.91273892, grad/param norm = 1.8877e-01, time/batch = 0.6430s	
24608/33650 (epoch 36.565), train_loss = 0.91687282, grad/param norm = 1.6865e-01, time/batch = 0.6409s	
24609/33650 (epoch 36.566), train_loss = 0.85463903, grad/param norm = 1.8356e-01, time/batch = 0.6406s	
24610/33650 (epoch 36.568), train_loss = 0.90194634, grad/param norm = 2.2228e-01, time/batch = 0.6394s	
24611/33650 (epoch 36.569), train_loss = 0.80379148, grad/param norm = 1.5462e-01, time/batch = 0.6517s	
24612/33650 (epoch 36.571), train_loss = 0.97494911, grad/param norm = 1.7711e-01, time/batch = 0.9419s	
24613/33650 (epoch 36.572), train_loss = 0.94192665, grad/param norm = 1.5997e-01, time/batch = 0.9426s	
24614/33650 (epoch 36.574), train_loss = 0.81413265, grad/param norm = 1.7810e-01, time/batch = 0.9442s	
24615/33650 (epoch 36.575), train_loss = 0.89472440, grad/param norm = 1.7509e-01, time/batch = 0.9385s	
24616/33650 (epoch 36.577), train_loss = 0.79259774, grad/param norm = 1.6412e-01, time/batch = 0.9427s	
24617/33650 (epoch 36.578), train_loss = 0.99254647, grad/param norm = 1.8421e-01, time/batch = 1.5454s	
24618/33650 (epoch 36.579), train_loss = 0.93566500, grad/param norm = 1.7050e-01, time/batch = 1.9310s	
24619/33650 (epoch 36.581), train_loss = 1.02305658, grad/param norm = 1.7625e-01, time/batch = 1.8439s	
24620/33650 (epoch 36.582), train_loss = 0.90803575, grad/param norm = 1.5163e-01, time/batch = 17.7243s	
24621/33650 (epoch 36.584), train_loss = 0.90658067, grad/param norm = 1.6510e-01, time/batch = 16.9501s	
24622/33650 (epoch 36.585), train_loss = 0.94827319, grad/param norm = 3.7394e-01, time/batch = 16.8874s	
24623/33650 (epoch 36.587), train_loss = 0.82358643, grad/param norm = 1.7609e-01, time/batch = 18.6420s	
24624/33650 (epoch 36.588), train_loss = 0.85216376, grad/param norm = 2.3170e-01, time/batch = 18.4851s	
24625/33650 (epoch 36.590), train_loss = 0.86064308, grad/param norm = 1.6345e-01, time/batch = 18.3952s	
24626/33650 (epoch 36.591), train_loss = 0.77244550, grad/param norm = 1.7079e-01, time/batch = 17.4797s	
24627/33650 (epoch 36.593), train_loss = 0.80488215, grad/param norm = 1.7418e-01, time/batch = 16.9671s	
24628/33650 (epoch 36.594), train_loss = 0.79019078, grad/param norm = 1.6382e-01, time/batch = 17.7278s	
24629/33650 (epoch 36.596), train_loss = 0.85932853, grad/param norm = 1.5837e-01, time/batch = 18.0429s	
24630/33650 (epoch 36.597), train_loss = 0.76944673, grad/param norm = 1.6227e-01, time/batch = 18.2374s	
24631/33650 (epoch 36.599), train_loss = 0.86303098, grad/param norm = 1.5950e-01, time/batch = 16.1234s	
24632/33650 (epoch 36.600), train_loss = 0.80946183, grad/param norm = 1.6280e-01, time/batch = 16.7399s	
24633/33650 (epoch 36.602), train_loss = 0.87241960, grad/param norm = 1.6196e-01, time/batch = 18.4812s	
24634/33650 (epoch 36.603), train_loss = 0.80934298, grad/param norm = 1.6652e-01, time/batch = 18.0654s	
24635/33650 (epoch 36.605), train_loss = 0.93271802, grad/param norm = 1.6358e-01, time/batch = 17.6278s	
24636/33650 (epoch 36.606), train_loss = 0.87252575, grad/param norm = 1.6688e-01, time/batch = 17.9752s	
24637/33650 (epoch 36.608), train_loss = 0.77312744, grad/param norm = 1.8406e-01, time/batch = 18.7283s	
24638/33650 (epoch 36.609), train_loss = 0.86797850, grad/param norm = 1.8224e-01, time/batch = 18.1457s	
24639/33650 (epoch 36.611), train_loss = 0.76934724, grad/param norm = 1.6470e-01, time/batch = 16.6819s	
24640/33650 (epoch 36.612), train_loss = 0.85890235, grad/param norm = 1.9268e-01, time/batch = 18.4080s	
24641/33650 (epoch 36.614), train_loss = 0.97104466, grad/param norm = 1.7467e-01, time/batch = 17.1450s	
24642/33650 (epoch 36.615), train_loss = 0.91948237, grad/param norm = 1.5209e-01, time/batch = 15.4512s	
24643/33650 (epoch 36.617), train_loss = 0.79147193, grad/param norm = 1.4428e-01, time/batch = 16.1125s	
24644/33650 (epoch 36.618), train_loss = 0.86140061, grad/param norm = 1.7197e-01, time/batch = 18.8191s	
24645/33650 (epoch 36.620), train_loss = 0.82598362, grad/param norm = 1.7279e-01, time/batch = 15.7011s	
24646/33650 (epoch 36.621), train_loss = 0.75588025, grad/param norm = 1.4311e-01, time/batch = 17.1362s	
24647/33650 (epoch 36.623), train_loss = 0.84515729, grad/param norm = 1.7998e-01, time/batch = 18.2310s	
24648/33650 (epoch 36.624), train_loss = 0.66931933, grad/param norm = 1.4191e-01, time/batch = 18.1407s	
24649/33650 (epoch 36.626), train_loss = 0.71208932, grad/param norm = 1.6367e-01, time/batch = 17.3061s	
24650/33650 (epoch 36.627), train_loss = 0.80355391, grad/param norm = 1.5627e-01, time/batch = 17.6254s	
24651/33650 (epoch 36.629), train_loss = 0.80967186, grad/param norm = 1.7318e-01, time/batch = 18.4825s	
24652/33650 (epoch 36.630), train_loss = 0.97050179, grad/param norm = 1.7537e-01, time/batch = 17.9765s	
24653/33650 (epoch 36.632), train_loss = 0.94560317, grad/param norm = 1.7361e-01, time/batch = 16.7852s	
24654/33650 (epoch 36.633), train_loss = 0.93957776, grad/param norm = 1.5689e-01, time/batch = 18.7998s	
24655/33650 (epoch 36.634), train_loss = 0.76781754, grad/param norm = 1.6571e-01, time/batch = 15.6440s	
24656/33650 (epoch 36.636), train_loss = 0.66766341, grad/param norm = 1.2060e-01, time/batch = 18.2144s	
24657/33650 (epoch 36.637), train_loss = 0.77604689, grad/param norm = 1.5737e-01, time/batch = 17.6602s	
24658/33650 (epoch 36.639), train_loss = 0.78056301, grad/param norm = 1.5244e-01, time/batch = 18.1531s	
24659/33650 (epoch 36.640), train_loss = 0.86140689, grad/param norm = 1.6831e-01, time/batch = 18.0582s	
24660/33650 (epoch 36.642), train_loss = 0.94057058, grad/param norm = 1.7149e-01, time/batch = 17.8113s	
24661/33650 (epoch 36.643), train_loss = 0.87786784, grad/param norm = 1.8168e-01, time/batch = 18.8100s	
24662/33650 (epoch 36.645), train_loss = 0.87744278, grad/param norm = 1.7525e-01, time/batch = 17.7998s	
24663/33650 (epoch 36.646), train_loss = 0.76040467, grad/param norm = 1.3600e-01, time/batch = 17.9768s	
24664/33650 (epoch 36.648), train_loss = 0.89649011, grad/param norm = 1.6626e-01, time/batch = 17.5619s	
24665/33650 (epoch 36.649), train_loss = 0.76893136, grad/param norm = 1.5782e-01, time/batch = 16.7834s	
24666/33650 (epoch 36.651), train_loss = 0.93797671, grad/param norm = 1.9964e-01, time/batch = 17.4795s	
24667/33650 (epoch 36.652), train_loss = 0.64995514, grad/param norm = 1.4489e-01, time/batch = 17.9803s	
24668/33650 (epoch 36.654), train_loss = 0.75860950, grad/param norm = 1.4903e-01, time/batch = 16.3186s	
24669/33650 (epoch 36.655), train_loss = 0.75786217, grad/param norm = 1.5565e-01, time/batch = 17.3843s	
24670/33650 (epoch 36.657), train_loss = 0.79959160, grad/param norm = 2.2149e-01, time/batch = 18.1325s	
24671/33650 (epoch 36.658), train_loss = 0.69515565, grad/param norm = 1.6054e-01, time/batch = 19.0644s	
24672/33650 (epoch 36.660), train_loss = 0.69420368, grad/param norm = 1.5334e-01, time/batch = 17.1371s	
24673/33650 (epoch 36.661), train_loss = 0.77553369, grad/param norm = 1.5681e-01, time/batch = 16.8673s	
24674/33650 (epoch 36.663), train_loss = 0.73568660, grad/param norm = 1.7621e-01, time/batch = 18.4708s	
24675/33650 (epoch 36.664), train_loss = 0.81585136, grad/param norm = 1.5125e-01, time/batch = 18.3995s	
24676/33650 (epoch 36.666), train_loss = 0.82966196, grad/param norm = 1.4802e-01, time/batch = 17.5471s	
24677/33650 (epoch 36.667), train_loss = 0.71266936, grad/param norm = 1.5637e-01, time/batch = 16.2176s	
24678/33650 (epoch 36.669), train_loss = 0.74550906, grad/param norm = 1.5647e-01, time/batch = 18.0803s	
24679/33650 (epoch 36.670), train_loss = 0.67660950, grad/param norm = 1.5712e-01, time/batch = 17.0419s	
24680/33650 (epoch 36.672), train_loss = 0.71207292, grad/param norm = 1.4258e-01, time/batch = 17.8130s	
24681/33650 (epoch 36.673), train_loss = 0.70182184, grad/param norm = 1.5463e-01, time/batch = 18.8072s	
24682/33650 (epoch 36.675), train_loss = 0.65229884, grad/param norm = 1.3927e-01, time/batch = 18.2264s	
24683/33650 (epoch 36.676), train_loss = 0.77622199, grad/param norm = 1.6140e-01, time/batch = 17.6409s	
24684/33650 (epoch 36.678), train_loss = 0.78169136, grad/param norm = 1.7430e-01, time/batch = 15.8066s	
24685/33650 (epoch 36.679), train_loss = 0.75889407, grad/param norm = 1.5478e-01, time/batch = 18.0724s	
24686/33650 (epoch 36.681), train_loss = 0.78631530, grad/param norm = 1.4603e-01, time/batch = 25.1109s	
24687/33650 (epoch 36.682), train_loss = 0.76175569, grad/param norm = 1.6800e-01, time/batch = 24.4269s	
24688/33650 (epoch 36.684), train_loss = 0.71090506, grad/param norm = 1.4097e-01, time/batch = 18.1518s	
24689/33650 (epoch 36.685), train_loss = 0.85802254, grad/param norm = 1.8160e-01, time/batch = 16.6297s	
24690/33650 (epoch 36.686), train_loss = 0.83043740, grad/param norm = 1.6718e-01, time/batch = 18.1352s	
24691/33650 (epoch 36.688), train_loss = 0.88959656, grad/param norm = 1.5810e-01, time/batch = 18.6510s	
24692/33650 (epoch 36.689), train_loss = 0.77357961, grad/param norm = 1.7197e-01, time/batch = 17.4520s	
24693/33650 (epoch 36.691), train_loss = 0.91922575, grad/param norm = 1.8288e-01, time/batch = 18.3538s	
24694/33650 (epoch 36.692), train_loss = 0.92330003, grad/param norm = 1.6979e-01, time/batch = 18.3944s	
24695/33650 (epoch 36.694), train_loss = 0.88906583, grad/param norm = 1.7517e-01, time/batch = 17.8725s	
24696/33650 (epoch 36.695), train_loss = 0.56203116, grad/param norm = 1.4078e-01, time/batch = 18.5618s	
24697/33650 (epoch 36.697), train_loss = 0.79676313, grad/param norm = 1.5508e-01, time/batch = 18.1406s	
24698/33650 (epoch 36.698), train_loss = 0.91625456, grad/param norm = 1.9427e-01, time/batch = 18.0431s	
24699/33650 (epoch 36.700), train_loss = 0.81187790, grad/param norm = 1.6497e-01, time/batch = 17.2878s	
24700/33650 (epoch 36.701), train_loss = 0.83893436, grad/param norm = 1.7899e-01, time/batch = 18.8953s	
24701/33650 (epoch 36.703), train_loss = 1.03079558, grad/param norm = 1.7556e-01, time/batch = 19.1388s	
24702/33650 (epoch 36.704), train_loss = 0.82782022, grad/param norm = 1.6898e-01, time/batch = 16.8866s	
24703/33650 (epoch 36.706), train_loss = 0.78744944, grad/param norm = 1.4253e-01, time/batch = 18.7226s	
24704/33650 (epoch 36.707), train_loss = 0.90566234, grad/param norm = 1.5954e-01, time/batch = 18.8961s	
24705/33650 (epoch 36.709), train_loss = 0.77852861, grad/param norm = 1.4936e-01, time/batch = 17.3939s	
24706/33650 (epoch 36.710), train_loss = 0.99175889, grad/param norm = 2.0248e-01, time/batch = 17.1396s	
24707/33650 (epoch 36.712), train_loss = 0.72358922, grad/param norm = 1.7812e-01, time/batch = 18.8678s	
24708/33650 (epoch 36.713), train_loss = 0.75237970, grad/param norm = 1.8030e-01, time/batch = 18.3166s	
24709/33650 (epoch 36.715), train_loss = 0.87458773, grad/param norm = 1.9099e-01, time/batch = 18.3061s	
24710/33650 (epoch 36.716), train_loss = 0.80850304, grad/param norm = 1.6392e-01, time/batch = 18.5619s	
24711/33650 (epoch 36.718), train_loss = 0.78037383, grad/param norm = 1.4072e-01, time/batch = 17.7293s	
24712/33650 (epoch 36.719), train_loss = 0.94130564, grad/param norm = 2.0843e-01, time/batch = 16.9776s	
24713/33650 (epoch 36.721), train_loss = 0.99630264, grad/param norm = 1.8073e-01, time/batch = 18.2073s	
24714/33650 (epoch 36.722), train_loss = 0.90587963, grad/param norm = 2.1880e-01, time/batch = 18.6370s	
24715/33650 (epoch 36.724), train_loss = 0.91415299, grad/param norm = 1.6790e-01, time/batch = 16.7179s	
24716/33650 (epoch 36.725), train_loss = 0.87756014, grad/param norm = 1.6994e-01, time/batch = 18.3089s	
24717/33650 (epoch 36.727), train_loss = 0.79327410, grad/param norm = 1.6740e-01, time/batch = 18.4847s	
24718/33650 (epoch 36.728), train_loss = 0.80317741, grad/param norm = 1.5980e-01, time/batch = 18.3877s	
24719/33650 (epoch 36.730), train_loss = 0.85635679, grad/param norm = 1.5847e-01, time/batch = 18.0627s	
24720/33650 (epoch 36.731), train_loss = 1.01085052, grad/param norm = 2.0246e-01, time/batch = 16.8085s	
24721/33650 (epoch 36.733), train_loss = 0.81439051, grad/param norm = 1.6887e-01, time/batch = 18.1422s	
24722/33650 (epoch 36.734), train_loss = 0.97391736, grad/param norm = 2.7120e-01, time/batch = 15.8567s	
24723/33650 (epoch 36.736), train_loss = 0.82717307, grad/param norm = 1.8422e-01, time/batch = 18.8030s	
24724/33650 (epoch 36.737), train_loss = 0.89991812, grad/param norm = 3.0262e-01, time/batch = 19.0737s	
24725/33650 (epoch 36.738), train_loss = 0.76950250, grad/param norm = 1.5250e-01, time/batch = 17.4712s	
24726/33650 (epoch 36.740), train_loss = 0.73594239, grad/param norm = 1.6550e-01, time/batch = 17.9916s	
24727/33650 (epoch 36.741), train_loss = 0.77600755, grad/param norm = 1.7658e-01, time/batch = 18.8068s	
24728/33650 (epoch 36.743), train_loss = 0.83662466, grad/param norm = 1.6251e-01, time/batch = 17.9627s	
24729/33650 (epoch 36.744), train_loss = 0.91222196, grad/param norm = 1.4149e-01, time/batch = 18.3033s	
24730/33650 (epoch 36.746), train_loss = 0.79610277, grad/param norm = 1.6149e-01, time/batch = 18.3978s	
24731/33650 (epoch 36.747), train_loss = 0.96675058, grad/param norm = 1.7851e-01, time/batch = 17.5418s	
24732/33650 (epoch 36.749), train_loss = 0.68372096, grad/param norm = 1.8056e-01, time/batch = 18.4600s	
24733/33650 (epoch 36.750), train_loss = 0.98173526, grad/param norm = 1.9174e-01, time/batch = 17.9825s	
24734/33650 (epoch 36.752), train_loss = 0.92685410, grad/param norm = 1.8739e-01, time/batch = 18.4088s	
24735/33650 (epoch 36.753), train_loss = 1.00863260, grad/param norm = 1.8642e-01, time/batch = 17.2165s	
24736/33650 (epoch 36.755), train_loss = 0.84483236, grad/param norm = 1.5132e-01, time/batch = 18.2151s	
24737/33650 (epoch 36.756), train_loss = 0.90741425, grad/param norm = 1.8039e-01, time/batch = 19.3024s	
24738/33650 (epoch 36.758), train_loss = 0.93344088, grad/param norm = 1.6232e-01, time/batch = 17.8199s	
24739/33650 (epoch 36.759), train_loss = 0.95394832, grad/param norm = 1.9692e-01, time/batch = 16.1385s	
24740/33650 (epoch 36.761), train_loss = 0.87271298, grad/param norm = 1.5990e-01, time/batch = 17.9817s	
24741/33650 (epoch 36.762), train_loss = 0.84008161, grad/param norm = 1.5447e-01, time/batch = 18.6560s	
24742/33650 (epoch 36.764), train_loss = 0.89297083, grad/param norm = 1.9130e-01, time/batch = 18.0526s	
24743/33650 (epoch 36.765), train_loss = 0.80313629, grad/param norm = 1.6838e-01, time/batch = 18.1297s	
24744/33650 (epoch 36.767), train_loss = 0.83013210, grad/param norm = 1.6579e-01, time/batch = 15.4104s	
24745/33650 (epoch 36.768), train_loss = 0.78676253, grad/param norm = 1.7753e-01, time/batch = 17.5605s	
24746/33650 (epoch 36.770), train_loss = 0.84549612, grad/param norm = 2.0008e-01, time/batch = 17.1181s	
24747/33650 (epoch 36.771), train_loss = 0.89220463, grad/param norm = 1.6022e-01, time/batch = 18.2259s	
24748/33650 (epoch 36.773), train_loss = 0.94229288, grad/param norm = 1.9511e-01, time/batch = 17.7145s	
24749/33650 (epoch 36.774), train_loss = 0.86863322, grad/param norm = 2.2661e-01, time/batch = 17.8684s	
24750/33650 (epoch 36.776), train_loss = 0.93675348, grad/param norm = 2.0580e-01, time/batch = 18.4715s	
24751/33650 (epoch 36.777), train_loss = 0.76992229, grad/param norm = 1.4511e-01, time/batch = 19.2172s	
24752/33650 (epoch 36.779), train_loss = 0.83200160, grad/param norm = 1.5478e-01, time/batch = 17.4622s	
24753/33650 (epoch 36.780), train_loss = 0.76803337, grad/param norm = 1.4901e-01, time/batch = 18.7184s	
24754/33650 (epoch 36.782), train_loss = 0.77569158, grad/param norm = 1.7646e-01, time/batch = 18.0583s	
24755/33650 (epoch 36.783), train_loss = 0.78933123, grad/param norm = 1.3784e-01, time/batch = 17.4665s	
24756/33650 (epoch 36.785), train_loss = 1.00408746, grad/param norm = 1.8586e-01, time/batch = 18.3854s	
24757/33650 (epoch 36.786), train_loss = 0.88074550, grad/param norm = 1.6559e-01, time/batch = 17.3680s	
24758/33650 (epoch 36.788), train_loss = 0.91293581, grad/param norm = 1.6070e-01, time/batch = 18.1435s	
24759/33650 (epoch 36.789), train_loss = 0.92410881, grad/param norm = 1.6135e-01, time/batch = 17.8025s	
24760/33650 (epoch 36.790), train_loss = 0.86496021, grad/param norm = 1.8582e-01, time/batch = 19.0571s	
24761/33650 (epoch 36.792), train_loss = 0.99485657, grad/param norm = 2.1404e-01, time/batch = 18.2199s	
24762/33650 (epoch 36.793), train_loss = 0.91372343, grad/param norm = 1.8544e-01, time/batch = 17.2099s	
24763/33650 (epoch 36.795), train_loss = 0.92151269, grad/param norm = 1.6579e-01, time/batch = 18.1470s	
24764/33650 (epoch 36.796), train_loss = 0.82685786, grad/param norm = 1.7538e-01, time/batch = 18.6343s	
24765/33650 (epoch 36.798), train_loss = 0.82689798, grad/param norm = 1.7018e-01, time/batch = 16.6420s	
24766/33650 (epoch 36.799), train_loss = 0.86633560, grad/param norm = 1.8714e-01, time/batch = 17.6352s	
24767/33650 (epoch 36.801), train_loss = 0.85085058, grad/param norm = 2.0019e-01, time/batch = 18.8041s	
24768/33650 (epoch 36.802), train_loss = 0.94195815, grad/param norm = 1.9333e-01, time/batch = 17.6294s	
24769/33650 (epoch 36.804), train_loss = 0.87001817, grad/param norm = 1.8094e-01, time/batch = 16.8699s	
24770/33650 (epoch 36.805), train_loss = 0.85215565, grad/param norm = 1.6015e-01, time/batch = 17.3039s	
24771/33650 (epoch 36.807), train_loss = 1.01416073, grad/param norm = 2.0307e-01, time/batch = 19.2243s	
24772/33650 (epoch 36.808), train_loss = 1.09240391, grad/param norm = 2.0752e-01, time/batch = 17.7965s	
24773/33650 (epoch 36.810), train_loss = 0.90521042, grad/param norm = 1.7280e-01, time/batch = 18.8110s	
24774/33650 (epoch 36.811), train_loss = 0.89345464, grad/param norm = 1.8756e-01, time/batch = 19.0547s	
24775/33650 (epoch 36.813), train_loss = 0.78504867, grad/param norm = 1.6421e-01, time/batch = 17.3954s	
24776/33650 (epoch 36.814), train_loss = 0.93780662, grad/param norm = 1.8513e-01, time/batch = 17.1206s	
24777/33650 (epoch 36.816), train_loss = 0.91994359, grad/param norm = 1.8908e-01, time/batch = 17.9005s	
24778/33650 (epoch 36.817), train_loss = 0.93274076, grad/param norm = 1.8689e-01, time/batch = 17.7944s	
24779/33650 (epoch 36.819), train_loss = 0.86543970, grad/param norm = 1.8247e-01, time/batch = 18.3845s	
24780/33650 (epoch 36.820), train_loss = 0.95030449, grad/param norm = 1.6007e-01, time/batch = 18.2319s	
24781/33650 (epoch 36.822), train_loss = 0.89161830, grad/param norm = 2.5414e-01, time/batch = 18.3007s	
24782/33650 (epoch 36.823), train_loss = 0.81498493, grad/param norm = 1.9063e-01, time/batch = 17.1364s	
24783/33650 (epoch 36.825), train_loss = 0.86467476, grad/param norm = 1.6070e-01, time/batch = 18.6400s	
24784/33650 (epoch 36.826), train_loss = 0.92514095, grad/param norm = 1.9203e-01, time/batch = 18.4662s	
24785/33650 (epoch 36.828), train_loss = 1.03485322, grad/param norm = 2.2057e-01, time/batch = 17.6395s	
24786/33650 (epoch 36.829), train_loss = 0.74019658, grad/param norm = 1.9246e-01, time/batch = 18.0787s	
24787/33650 (epoch 36.831), train_loss = 0.89426689, grad/param norm = 1.9218e-01, time/batch = 18.4760s	
24788/33650 (epoch 36.832), train_loss = 0.92279937, grad/param norm = 1.7261e-01, time/batch = 16.6501s	
24789/33650 (epoch 36.834), train_loss = 0.92244676, grad/param norm = 1.7550e-01, time/batch = 17.2121s	
24790/33650 (epoch 36.835), train_loss = 1.06220015, grad/param norm = 2.0012e-01, time/batch = 16.5544s	
24791/33650 (epoch 36.837), train_loss = 0.90878731, grad/param norm = 1.8930e-01, time/batch = 18.6421s	
24792/33650 (epoch 36.838), train_loss = 0.87369184, grad/param norm = 1.7619e-01, time/batch = 17.7845s	
24793/33650 (epoch 36.840), train_loss = 0.94893228, grad/param norm = 2.0450e-01, time/batch = 19.4799s	
24794/33650 (epoch 36.841), train_loss = 0.82298673, grad/param norm = 1.6585e-01, time/batch = 17.3757s	
24795/33650 (epoch 36.842), train_loss = 0.84900937, grad/param norm = 1.5678e-01, time/batch = 17.3017s	
24796/33650 (epoch 36.844), train_loss = 0.98832974, grad/param norm = 1.8317e-01, time/batch = 19.1415s	
24797/33650 (epoch 36.845), train_loss = 0.86968877, grad/param norm = 1.7371e-01, time/batch = 17.4775s	
24798/33650 (epoch 36.847), train_loss = 0.65082511, grad/param norm = 1.4028e-01, time/batch = 17.3974s	
24799/33650 (epoch 36.848), train_loss = 0.74972100, grad/param norm = 1.7104e-01, time/batch = 17.5594s	
24800/33650 (epoch 36.850), train_loss = 0.82675985, grad/param norm = 1.8019e-01, time/batch = 18.0676s	
24801/33650 (epoch 36.851), train_loss = 0.73524329, grad/param norm = 1.5669e-01, time/batch = 18.5650s	
24802/33650 (epoch 36.853), train_loss = 0.82097367, grad/param norm = 1.7638e-01, time/batch = 17.6052s	
24803/33650 (epoch 36.854), train_loss = 0.94404989, grad/param norm = 1.7990e-01, time/batch = 18.4000s	
24804/33650 (epoch 36.856), train_loss = 0.67802360, grad/param norm = 1.4870e-01, time/batch = 18.7992s	
24805/33650 (epoch 36.857), train_loss = 0.89284078, grad/param norm = 1.5684e-01, time/batch = 17.0678s	
24806/33650 (epoch 36.859), train_loss = 0.76971563, grad/param norm = 1.4955e-01, time/batch = 17.2988s	
24807/33650 (epoch 36.860), train_loss = 0.74484139, grad/param norm = 1.8427e-01, time/batch = 18.2209s	
24808/33650 (epoch 36.862), train_loss = 0.78225803, grad/param norm = 1.6452e-01, time/batch = 17.8118s	
24809/33650 (epoch 36.863), train_loss = 0.97209447, grad/param norm = 1.5367e-01, time/batch = 18.6455s	
24810/33650 (epoch 36.865), train_loss = 0.86248340, grad/param norm = 1.7244e-01, time/batch = 18.2268s	
24811/33650 (epoch 36.866), train_loss = 0.79843374, grad/param norm = 1.8106e-01, time/batch = 17.8847s	
24812/33650 (epoch 36.868), train_loss = 0.73650643, grad/param norm = 1.9521e-01, time/batch = 16.9440s	
24813/33650 (epoch 36.869), train_loss = 0.90368586, grad/param norm = 1.8641e-01, time/batch = 18.0668s	
24814/33650 (epoch 36.871), train_loss = 0.74828580, grad/param norm = 1.6228e-01, time/batch = 18.1402s	
24815/33650 (epoch 36.872), train_loss = 0.87368383, grad/param norm = 1.6465e-01, time/batch = 17.2346s	
24816/33650 (epoch 36.874), train_loss = 0.92315558, grad/param norm = 1.9821e-01, time/batch = 19.4666s	
24817/33650 (epoch 36.875), train_loss = 0.80314937, grad/param norm = 1.5173e-01, time/batch = 18.2309s	
24818/33650 (epoch 36.877), train_loss = 1.01231388, grad/param norm = 1.7870e-01, time/batch = 18.0543s	
24819/33650 (epoch 36.878), train_loss = 0.63351126, grad/param norm = 1.2895e-01, time/batch = 17.2114s	
24820/33650 (epoch 36.880), train_loss = 0.89322092, grad/param norm = 2.1929e-01, time/batch = 15.2123s	
24821/33650 (epoch 36.881), train_loss = 0.83585972, grad/param norm = 1.8856e-01, time/batch = 17.8842s	
24822/33650 (epoch 36.883), train_loss = 0.87645673, grad/param norm = 1.6583e-01, time/batch = 17.1378s	
24823/33650 (epoch 36.884), train_loss = 0.95903541, grad/param norm = 2.0139e-01, time/batch = 14.2486s	
24824/33650 (epoch 36.886), train_loss = 0.89856202, grad/param norm = 1.7370e-01, time/batch = 13.8135s	
24825/33650 (epoch 36.887), train_loss = 0.73443021, grad/param norm = 1.5857e-01, time/batch = 13.7317s	
24826/33650 (epoch 36.889), train_loss = 0.82943960, grad/param norm = 1.8361e-01, time/batch = 17.2816s	
24827/33650 (epoch 36.890), train_loss = 0.87981586, grad/param norm = 1.5509e-01, time/batch = 19.1468s	
24828/33650 (epoch 36.892), train_loss = 0.80947998, grad/param norm = 2.1447e-01, time/batch = 17.6462s	
24829/33650 (epoch 36.893), train_loss = 0.88087526, grad/param norm = 1.8614e-01, time/batch = 17.3072s	
24830/33650 (epoch 36.895), train_loss = 0.95789458, grad/param norm = 1.6403e-01, time/batch = 18.2272s	
24831/33650 (epoch 36.896), train_loss = 0.77986581, grad/param norm = 1.4709e-01, time/batch = 18.8098s	
24832/33650 (epoch 36.897), train_loss = 0.71451262, grad/param norm = 1.5889e-01, time/batch = 18.3056s	
24833/33650 (epoch 36.899), train_loss = 0.76717608, grad/param norm = 1.4218e-01, time/batch = 17.3265s	
24834/33650 (epoch 36.900), train_loss = 0.73839126, grad/param norm = 1.5712e-01, time/batch = 18.8826s	
24835/33650 (epoch 36.902), train_loss = 0.81603664, grad/param norm = 1.7291e-01, time/batch = 19.2216s	
24836/33650 (epoch 36.903), train_loss = 0.81847577, grad/param norm = 1.8412e-01, time/batch = 16.6095s	
24837/33650 (epoch 36.905), train_loss = 0.97109382, grad/param norm = 2.1148e-01, time/batch = 18.8789s	
24838/33650 (epoch 36.906), train_loss = 0.78940856, grad/param norm = 1.6809e-01, time/batch = 16.2301s	
24839/33650 (epoch 36.908), train_loss = 0.82249048, grad/param norm = 1.6038e-01, time/batch = 17.3983s	
24840/33650 (epoch 36.909), train_loss = 0.80811679, grad/param norm = 1.5446e-01, time/batch = 18.6352s	
24841/33650 (epoch 36.911), train_loss = 0.72068040, grad/param norm = 1.3559e-01, time/batch = 18.3065s	
24842/33650 (epoch 36.912), train_loss = 0.65212167, grad/param norm = 1.4867e-01, time/batch = 18.3003s	
24843/33650 (epoch 36.914), train_loss = 0.85761301, grad/param norm = 1.5555e-01, time/batch = 18.2240s	
24844/33650 (epoch 36.915), train_loss = 0.80502391, grad/param norm = 1.8380e-01, time/batch = 19.3000s	
24845/33650 (epoch 36.917), train_loss = 0.79175200, grad/param norm = 1.5887e-01, time/batch = 16.8764s	
24846/33650 (epoch 36.918), train_loss = 0.75730329, grad/param norm = 1.5409e-01, time/batch = 17.6356s	
24847/33650 (epoch 36.920), train_loss = 0.75529345, grad/param norm = 1.3883e-01, time/batch = 17.9869s	
24848/33650 (epoch 36.921), train_loss = 0.76770290, grad/param norm = 1.7201e-01, time/batch = 18.1505s	
24849/33650 (epoch 36.923), train_loss = 0.66433331, grad/param norm = 1.4023e-01, time/batch = 17.3049s	
24850/33650 (epoch 36.924), train_loss = 0.84917134, grad/param norm = 1.6296e-01, time/batch = 18.1337s	
24851/33650 (epoch 36.926), train_loss = 0.78416101, grad/param norm = 2.1829e-01, time/batch = 17.6312s	
24852/33650 (epoch 36.927), train_loss = 0.81532490, grad/param norm = 1.7267e-01, time/batch = 17.6404s	
24853/33650 (epoch 36.929), train_loss = 0.91156667, grad/param norm = 1.7966e-01, time/batch = 18.7107s	
24854/33650 (epoch 36.930), train_loss = 0.79534253, grad/param norm = 1.6134e-01, time/batch = 18.7356s	
24855/33650 (epoch 36.932), train_loss = 0.83492455, grad/param norm = 1.6095e-01, time/batch = 17.7382s	
24856/33650 (epoch 36.933), train_loss = 0.69858414, grad/param norm = 1.8625e-01, time/batch = 17.9734s	
24857/33650 (epoch 36.935), train_loss = 0.69602949, grad/param norm = 1.4682e-01, time/batch = 18.7265s	
24858/33650 (epoch 36.936), train_loss = 0.75092190, grad/param norm = 1.4597e-01, time/batch = 18.6351s	
24859/33650 (epoch 36.938), train_loss = 0.71433747, grad/param norm = 1.4737e-01, time/batch = 15.8839s	
24860/33650 (epoch 36.939), train_loss = 0.89798352, grad/param norm = 1.6200e-01, time/batch = 18.8855s	
24861/33650 (epoch 36.941), train_loss = 0.81612169, grad/param norm = 1.5992e-01, time/batch = 16.9466s	
24862/33650 (epoch 36.942), train_loss = 0.90186112, grad/param norm = 2.0195e-01, time/batch = 18.0510s	
24863/33650 (epoch 36.944), train_loss = 0.78942822, grad/param norm = 1.7002e-01, time/batch = 17.9806s	
24864/33650 (epoch 36.945), train_loss = 0.83575148, grad/param norm = 1.7330e-01, time/batch = 17.7164s	
24865/33650 (epoch 36.947), train_loss = 0.94732943, grad/param norm = 2.3745e-01, time/batch = 18.1413s	
24866/33650 (epoch 36.948), train_loss = 0.95024718, grad/param norm = 1.7381e-01, time/batch = 17.2236s	
24867/33650 (epoch 36.949), train_loss = 0.71734345, grad/param norm = 1.6629e-01, time/batch = 18.5606s	
24868/33650 (epoch 36.951), train_loss = 0.97283688, grad/param norm = 1.9464e-01, time/batch = 19.0600s	
24869/33650 (epoch 36.952), train_loss = 0.87079961, grad/param norm = 1.7062e-01, time/batch = 17.2241s	
24870/33650 (epoch 36.954), train_loss = 0.86197059, grad/param norm = 1.6869e-01, time/batch = 18.8835s	
24871/33650 (epoch 36.955), train_loss = 0.84261810, grad/param norm = 1.6449e-01, time/batch = 18.8928s	
24872/33650 (epoch 36.957), train_loss = 0.88940990, grad/param norm = 1.8955e-01, time/batch = 17.0457s	
24873/33650 (epoch 36.958), train_loss = 0.65422557, grad/param norm = 1.2960e-01, time/batch = 17.7998s	
24874/33650 (epoch 36.960), train_loss = 0.67808426, grad/param norm = 1.4374e-01, time/batch = 18.8974s	
24875/33650 (epoch 36.961), train_loss = 0.73190694, grad/param norm = 1.5373e-01, time/batch = 18.3118s	
24876/33650 (epoch 36.963), train_loss = 0.74748617, grad/param norm = 1.7471e-01, time/batch = 17.1265s	
24877/33650 (epoch 36.964), train_loss = 0.90321352, grad/param norm = 1.5496e-01, time/batch = 18.5598s	
24878/33650 (epoch 36.966), train_loss = 0.84050122, grad/param norm = 1.8356e-01, time/batch = 17.8944s	
24879/33650 (epoch 36.967), train_loss = 0.86752347, grad/param norm = 1.6420e-01, time/batch = 17.7201s	
24880/33650 (epoch 36.969), train_loss = 0.81869347, grad/param norm = 1.5851e-01, time/batch = 18.2262s	
24881/33650 (epoch 36.970), train_loss = 0.83175189, grad/param norm = 1.6574e-01, time/batch = 17.7230s	
24882/33650 (epoch 36.972), train_loss = 1.10646583, grad/param norm = 2.1256e-01, time/batch = 16.5426s	
24883/33650 (epoch 36.973), train_loss = 0.76108078, grad/param norm = 1.3711e-01, time/batch = 18.8072s	
24884/33650 (epoch 36.975), train_loss = 0.72518858, grad/param norm = 1.3997e-01, time/batch = 18.3147s	
24885/33650 (epoch 36.976), train_loss = 0.76754907, grad/param norm = 1.6716e-01, time/batch = 19.5325s	
24886/33650 (epoch 36.978), train_loss = 0.75998926, grad/param norm = 1.5339e-01, time/batch = 30.2687s	
24887/33650 (epoch 36.979), train_loss = 0.81897568, grad/param norm = 1.9422e-01, time/batch = 17.5475s	
24888/33650 (epoch 36.981), train_loss = 0.79744482, grad/param norm = 1.4524e-01, time/batch = 17.7933s	
24889/33650 (epoch 36.982), train_loss = 0.82686546, grad/param norm = 1.5463e-01, time/batch = 18.2980s	
24890/33650 (epoch 36.984), train_loss = 0.68564810, grad/param norm = 1.3979e-01, time/batch = 17.1349s	
24891/33650 (epoch 36.985), train_loss = 0.73620241, grad/param norm = 1.5033e-01, time/batch = 18.3749s	
24892/33650 (epoch 36.987), train_loss = 0.84066871, grad/param norm = 1.5923e-01, time/batch = 17.2205s	
24893/33650 (epoch 36.988), train_loss = 0.77579048, grad/param norm = 1.7791e-01, time/batch = 18.0613s	
24894/33650 (epoch 36.990), train_loss = 0.95531045, grad/param norm = 1.7328e-01, time/batch = 17.2971s	
24895/33650 (epoch 36.991), train_loss = 0.84454415, grad/param norm = 1.6150e-01, time/batch = 16.7951s	
24896/33650 (epoch 36.993), train_loss = 0.83144220, grad/param norm = 1.6716e-01, time/batch = 18.5660s	
24897/33650 (epoch 36.994), train_loss = 0.85096462, grad/param norm = 1.7724e-01, time/batch = 17.5726s	
24898/33650 (epoch 36.996), train_loss = 0.81394197, grad/param norm = 1.6898e-01, time/batch = 16.3827s	
24899/33650 (epoch 36.997), train_loss = 0.89027432, grad/param norm = 1.9193e-01, time/batch = 18.3981s	
24900/33650 (epoch 36.999), train_loss = 0.76064977, grad/param norm = 1.4784e-01, time/batch = 18.7252s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
24901/33650 (epoch 37.000), train_loss = 0.94198891, grad/param norm = 2.5692e-01, time/batch = 17.8787s	
24902/33650 (epoch 37.001), train_loss = 0.95782026, grad/param norm = 1.6659e-01, time/batch = 18.3141s	
24903/33650 (epoch 37.003), train_loss = 0.94614061, grad/param norm = 1.9467e-01, time/batch = 18.3115s	
24904/33650 (epoch 37.004), train_loss = 0.86328385, grad/param norm = 1.6994e-01, time/batch = 16.3916s	
24905/33650 (epoch 37.006), train_loss = 0.82151596, grad/param norm = 1.7360e-01, time/batch = 17.0641s	
24906/33650 (epoch 37.007), train_loss = 0.86877916, grad/param norm = 2.0284e-01, time/batch = 18.6505s	
24907/33650 (epoch 37.009), train_loss = 0.74029964, grad/param norm = 1.4797e-01, time/batch = 18.8145s	
24908/33650 (epoch 37.010), train_loss = 0.92524836, grad/param norm = 1.7772e-01, time/batch = 17.0627s	
24909/33650 (epoch 37.012), train_loss = 0.79349072, grad/param norm = 1.5198e-01, time/batch = 18.5648s	
24910/33650 (epoch 37.013), train_loss = 0.83856237, grad/param norm = 2.0740e-01, time/batch = 18.4681s	
24911/33650 (epoch 37.015), train_loss = 0.82735660, grad/param norm = 1.9556e-01, time/batch = 17.4429s	
24912/33650 (epoch 37.016), train_loss = 0.75719482, grad/param norm = 1.8102e-01, time/batch = 18.8086s	
24913/33650 (epoch 37.018), train_loss = 0.82598107, grad/param norm = 2.1921e-01, time/batch = 17.8923s	
24914/33650 (epoch 37.019), train_loss = 0.79620586, grad/param norm = 1.9498e-01, time/batch = 18.1455s	
24915/33650 (epoch 37.021), train_loss = 0.89011169, grad/param norm = 1.7453e-01, time/batch = 17.3835s	
24916/33650 (epoch 37.022), train_loss = 0.81409964, grad/param norm = 1.6332e-01, time/batch = 17.8139s	
24917/33650 (epoch 37.024), train_loss = 0.75318554, grad/param norm = 1.8494e-01, time/batch = 18.9033s	
24918/33650 (epoch 37.025), train_loss = 0.84591436, grad/param norm = 1.6904e-01, time/batch = 17.3808s	
24919/33650 (epoch 37.027), train_loss = 0.84791907, grad/param norm = 1.8362e-01, time/batch = 17.8785s	
24920/33650 (epoch 37.028), train_loss = 0.90305320, grad/param norm = 1.7477e-01, time/batch = 18.8002s	
24921/33650 (epoch 37.030), train_loss = 0.85258847, grad/param norm = 2.5002e-01, time/batch = 17.7194s	
24922/33650 (epoch 37.031), train_loss = 0.76430877, grad/param norm = 1.3265e-01, time/batch = 17.8222s	
24923/33650 (epoch 37.033), train_loss = 0.85482029, grad/param norm = 1.5697e-01, time/batch = 17.4037s	
24924/33650 (epoch 37.034), train_loss = 0.87526567, grad/param norm = 1.6463e-01, time/batch = 18.1547s	
24925/33650 (epoch 37.036), train_loss = 0.93772097, grad/param norm = 1.7881e-01, time/batch = 16.8937s	
24926/33650 (epoch 37.037), train_loss = 0.79020774, grad/param norm = 1.5286e-01, time/batch = 18.0743s	
24927/33650 (epoch 37.039), train_loss = 0.91876615, grad/param norm = 1.6578e-01, time/batch = 17.0707s	
24928/33650 (epoch 37.040), train_loss = 1.00766089, grad/param norm = 2.4150e-01, time/batch = 15.3795s	
24929/33650 (epoch 37.042), train_loss = 0.98944424, grad/param norm = 1.9215e-01, time/batch = 17.4723s	
24930/33650 (epoch 37.043), train_loss = 0.80707312, grad/param norm = 1.6103e-01, time/batch = 14.1725s	
24931/33650 (epoch 37.045), train_loss = 0.78133228, grad/param norm = 1.6883e-01, time/batch = 13.7293s	
24932/33650 (epoch 37.046), train_loss = 0.91852773, grad/param norm = 2.1525e-01, time/batch = 13.9142s	
24933/33650 (epoch 37.048), train_loss = 0.93012392, grad/param norm = 1.7412e-01, time/batch = 18.0642s	
24934/33650 (epoch 37.049), train_loss = 0.78839020, grad/param norm = 1.6196e-01, time/batch = 18.1518s	
24935/33650 (epoch 37.051), train_loss = 0.98649903, grad/param norm = 1.8701e-01, time/batch = 17.5724s	
24936/33650 (epoch 37.052), train_loss = 0.95144850, grad/param norm = 1.8763e-01, time/batch = 17.1456s	
24937/33650 (epoch 37.053), train_loss = 0.90344757, grad/param norm = 1.8058e-01, time/batch = 17.5731s	
24938/33650 (epoch 37.055), train_loss = 0.78740799, grad/param norm = 1.6593e-01, time/batch = 18.4834s	
24939/33650 (epoch 37.056), train_loss = 0.74895081, grad/param norm = 1.3693e-01, time/batch = 15.8803s	
24940/33650 (epoch 37.058), train_loss = 0.91282701, grad/param norm = 1.7430e-01, time/batch = 17.9920s	
24941/33650 (epoch 37.059), train_loss = 0.94015397, grad/param norm = 1.7766e-01, time/batch = 17.5697s	
24942/33650 (epoch 37.061), train_loss = 0.92691614, grad/param norm = 1.8423e-01, time/batch = 17.3133s	
24943/33650 (epoch 37.062), train_loss = 0.90469566, grad/param norm = 1.6281e-01, time/batch = 15.8976s	
24944/33650 (epoch 37.064), train_loss = 0.83890043, grad/param norm = 1.6872e-01, time/batch = 16.1308s	
24945/33650 (epoch 37.065), train_loss = 0.81857928, grad/param norm = 1.7248e-01, time/batch = 16.6510s	
24946/33650 (epoch 37.067), train_loss = 0.76436099, grad/param norm = 1.4339e-01, time/batch = 16.2319s	
24947/33650 (epoch 37.068), train_loss = 0.85770910, grad/param norm = 1.5934e-01, time/batch = 16.6500s	
24948/33650 (epoch 37.070), train_loss = 0.90828892, grad/param norm = 1.6420e-01, time/batch = 18.1411s	
24949/33650 (epoch 37.071), train_loss = 0.79795286, grad/param norm = 1.7356e-01, time/batch = 17.4043s	
24950/33650 (epoch 37.073), train_loss = 0.87747751, grad/param norm = 1.8412e-01, time/batch = 16.9632s	
24951/33650 (epoch 37.074), train_loss = 0.96391695, grad/param norm = 1.6304e-01, time/batch = 18.1411s	
24952/33650 (epoch 37.076), train_loss = 0.91234751, grad/param norm = 1.8697e-01, time/batch = 17.8137s	
24953/33650 (epoch 37.077), train_loss = 0.82805903, grad/param norm = 1.6902e-01, time/batch = 17.0496s	
24954/33650 (epoch 37.079), train_loss = 0.88255525, grad/param norm = 1.5701e-01, time/batch = 17.0680s	
24955/33650 (epoch 37.080), train_loss = 0.89304943, grad/param norm = 1.7240e-01, time/batch = 17.7309s	
24956/33650 (epoch 37.082), train_loss = 0.86257811, grad/param norm = 1.6359e-01, time/batch = 16.9775s	
24957/33650 (epoch 37.083), train_loss = 0.88356812, grad/param norm = 1.8638e-01, time/batch = 15.6385s	
24958/33650 (epoch 37.085), train_loss = 0.93399197, grad/param norm = 1.6407e-01, time/batch = 17.0674s	
24959/33650 (epoch 37.086), train_loss = 0.88042360, grad/param norm = 1.6485e-01, time/batch = 18.4035s	
24960/33650 (epoch 37.088), train_loss = 0.83185904, grad/param norm = 1.5526e-01, time/batch = 16.5596s	
24961/33650 (epoch 37.089), train_loss = 0.78968311, grad/param norm = 1.9156e-01, time/batch = 17.8944s	
24962/33650 (epoch 37.091), train_loss = 0.83219193, grad/param norm = 1.5860e-01, time/batch = 15.9742s	
24963/33650 (epoch 37.092), train_loss = 0.84767284, grad/param norm = 1.9271e-01, time/batch = 16.9786s	
24964/33650 (epoch 37.094), train_loss = 0.91099234, grad/param norm = 1.5187e-01, time/batch = 16.3011s	
24965/33650 (epoch 37.095), train_loss = 0.89801404, grad/param norm = 2.2306e-01, time/batch = 17.5765s	
24966/33650 (epoch 37.097), train_loss = 0.80734699, grad/param norm = 2.3008e-01, time/batch = 17.3174s	
24967/33650 (epoch 37.098), train_loss = 0.67586113, grad/param norm = 1.4543e-01, time/batch = 16.2242s	
24968/33650 (epoch 37.100), train_loss = 0.76943502, grad/param norm = 1.4607e-01, time/batch = 17.7392s	
24969/33650 (epoch 37.101), train_loss = 0.86609212, grad/param norm = 1.7973e-01, time/batch = 17.9824s	
24970/33650 (epoch 37.103), train_loss = 0.82551111, grad/param norm = 1.7665e-01, time/batch = 17.7341s	
24971/33650 (epoch 37.104), train_loss = 0.97702283, grad/param norm = 1.6282e-01, time/batch = 17.3889s	
24972/33650 (epoch 37.105), train_loss = 0.89293095, grad/param norm = 2.7542e-01, time/batch = 17.8244s	
24973/33650 (epoch 37.107), train_loss = 0.79992295, grad/param norm = 1.5711e-01, time/batch = 17.6667s	
24974/33650 (epoch 37.108), train_loss = 0.89412831, grad/param norm = 2.0326e-01, time/batch = 16.8238s	
24975/33650 (epoch 37.110), train_loss = 0.98007348, grad/param norm = 1.7306e-01, time/batch = 17.3229s	
24976/33650 (epoch 37.111), train_loss = 0.82587251, grad/param norm = 1.8101e-01, time/batch = 17.8265s	
24977/33650 (epoch 37.113), train_loss = 0.82219442, grad/param norm = 1.7894e-01, time/batch = 15.0523s	
24978/33650 (epoch 37.114), train_loss = 0.92378508, grad/param norm = 1.8268e-01, time/batch = 17.5624s	
24979/33650 (epoch 37.116), train_loss = 0.78442819, grad/param norm = 1.4031e-01, time/batch = 17.7273s	
24980/33650 (epoch 37.117), train_loss = 0.84651861, grad/param norm = 1.5779e-01, time/batch = 17.3220s	
24981/33650 (epoch 37.119), train_loss = 0.76345345, grad/param norm = 1.3244e-01, time/batch = 16.2320s	
24982/33650 (epoch 37.120), train_loss = 0.77477270, grad/param norm = 1.4997e-01, time/batch = 18.2345s	
24983/33650 (epoch 37.122), train_loss = 0.65737508, grad/param norm = 1.6211e-01, time/batch = 16.5419s	
24984/33650 (epoch 37.123), train_loss = 0.78786336, grad/param norm = 1.6823e-01, time/batch = 16.5612s	
24985/33650 (epoch 37.125), train_loss = 0.88610669, grad/param norm = 1.6295e-01, time/batch = 17.2304s	
24986/33650 (epoch 37.126), train_loss = 0.91320116, grad/param norm = 1.9338e-01, time/batch = 18.0768s	
24987/33650 (epoch 37.128), train_loss = 0.89015178, grad/param norm = 2.1643e-01, time/batch = 18.1563s	
24988/33650 (epoch 37.129), train_loss = 0.90443901, grad/param norm = 1.7207e-01, time/batch = 16.7241s	
24989/33650 (epoch 37.131), train_loss = 0.85794214, grad/param norm = 1.6688e-01, time/batch = 17.2369s	
24990/33650 (epoch 37.132), train_loss = 0.85367894, grad/param norm = 1.5598e-01, time/batch = 18.0629s	
24991/33650 (epoch 37.134), train_loss = 0.91967378, grad/param norm = 1.9756e-01, time/batch = 15.9728s	
24992/33650 (epoch 37.135), train_loss = 0.74225167, grad/param norm = 1.5301e-01, time/batch = 17.7861s	
24993/33650 (epoch 37.137), train_loss = 0.89967914, grad/param norm = 2.0274e-01, time/batch = 17.9055s	
24994/33650 (epoch 37.138), train_loss = 0.90501797, grad/param norm = 1.6079e-01, time/batch = 17.5005s	
24995/33650 (epoch 37.140), train_loss = 0.87460821, grad/param norm = 1.8953e-01, time/batch = 16.3757s	
24996/33650 (epoch 37.141), train_loss = 0.96831290, grad/param norm = 1.7385e-01, time/batch = 17.8128s	
24997/33650 (epoch 37.143), train_loss = 1.01500314, grad/param norm = 2.1393e-01, time/batch = 16.4758s	
24998/33650 (epoch 37.144), train_loss = 0.90586411, grad/param norm = 1.8769e-01, time/batch = 16.4882s	
24999/33650 (epoch 37.146), train_loss = 0.84253273, grad/param norm = 1.5639e-01, time/batch = 18.1458s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch37.15_1.7604.t7	
25000/33650 (epoch 37.147), train_loss = 0.77376288, grad/param norm = 1.5572e-01, time/batch = 16.2988s	
25001/33650 (epoch 37.149), train_loss = 1.19724259, grad/param norm = 2.0292e-01, time/batch = 16.9810s	
25002/33650 (epoch 37.150), train_loss = 0.73326153, grad/param norm = 1.5537e-01, time/batch = 17.0600s	
25003/33650 (epoch 37.152), train_loss = 0.79181662, grad/param norm = 1.6883e-01, time/batch = 18.2341s	
25004/33650 (epoch 37.153), train_loss = 0.82399727, grad/param norm = 1.6716e-01, time/batch = 16.3008s	
25005/33650 (epoch 37.155), train_loss = 0.79548320, grad/param norm = 1.6365e-01, time/batch = 18.4073s	
25006/33650 (epoch 37.156), train_loss = 0.75070624, grad/param norm = 1.3065e-01, time/batch = 17.5569s	
25007/33650 (epoch 37.158), train_loss = 0.89986785, grad/param norm = 1.7509e-01, time/batch = 16.8049s	
25008/33650 (epoch 37.159), train_loss = 0.79614313, grad/param norm = 1.4836e-01, time/batch = 16.5685s	
25009/33650 (epoch 37.160), train_loss = 0.78906024, grad/param norm = 1.4546e-01, time/batch = 17.5602s	
25010/33650 (epoch 37.162), train_loss = 0.81259811, grad/param norm = 1.8118e-01, time/batch = 17.4815s	
25011/33650 (epoch 37.163), train_loss = 0.87952434, grad/param norm = 1.6444e-01, time/batch = 16.0480s	
25012/33650 (epoch 37.165), train_loss = 0.75973671, grad/param norm = 1.7243e-01, time/batch = 17.5763s	
25013/33650 (epoch 37.166), train_loss = 0.74723174, grad/param norm = 1.7448e-01, time/batch = 17.8873s	
25014/33650 (epoch 37.168), train_loss = 0.95226275, grad/param norm = 2.2824e-01, time/batch = 16.4731s	
25015/33650 (epoch 37.169), train_loss = 0.82986731, grad/param norm = 1.8608e-01, time/batch = 17.4751s	
25016/33650 (epoch 37.171), train_loss = 0.82627974, grad/param norm = 1.5048e-01, time/batch = 15.8097s	
25017/33650 (epoch 37.172), train_loss = 0.80028137, grad/param norm = 1.7081e-01, time/batch = 17.7303s	
25018/33650 (epoch 37.174), train_loss = 0.78458632, grad/param norm = 1.8515e-01, time/batch = 16.9774s	
25019/33650 (epoch 37.175), train_loss = 0.72276195, grad/param norm = 1.7361e-01, time/batch = 17.4881s	
25020/33650 (epoch 37.177), train_loss = 0.83863589, grad/param norm = 1.6234e-01, time/batch = 17.1472s	
25021/33650 (epoch 37.178), train_loss = 0.80158711, grad/param norm = 1.7612e-01, time/batch = 16.1991s	
25022/33650 (epoch 37.180), train_loss = 0.75357300, grad/param norm = 1.4640e-01, time/batch = 16.7323s	
25023/33650 (epoch 37.181), train_loss = 0.67514655, grad/param norm = 1.3356e-01, time/batch = 17.1469s	
25024/33650 (epoch 37.183), train_loss = 0.75593065, grad/param norm = 1.5013e-01, time/batch = 17.3115s	
25025/33650 (epoch 37.184), train_loss = 0.77185934, grad/param norm = 1.7991e-01, time/batch = 16.5607s	
25026/33650 (epoch 37.186), train_loss = 0.79779696, grad/param norm = 1.8754e-01, time/batch = 16.7405s	
25027/33650 (epoch 37.187), train_loss = 0.92862913, grad/param norm = 2.0317e-01, time/batch = 17.5769s	
25028/33650 (epoch 37.189), train_loss = 0.93168390, grad/param norm = 1.9550e-01, time/batch = 16.9892s	
25029/33650 (epoch 37.190), train_loss = 0.85746666, grad/param norm = 1.8752e-01, time/batch = 17.5731s	
25030/33650 (epoch 37.192), train_loss = 1.01007559, grad/param norm = 1.7121e-01, time/batch = 17.4776s	
25031/33650 (epoch 37.193), train_loss = 0.97053234, grad/param norm = 1.6456e-01, time/batch = 18.3121s	
25032/33650 (epoch 37.195), train_loss = 0.75299800, grad/param norm = 1.8264e-01, time/batch = 16.3892s	
25033/33650 (epoch 37.196), train_loss = 0.69859028, grad/param norm = 1.7366e-01, time/batch = 17.8759s	
25034/33650 (epoch 37.198), train_loss = 0.84062437, grad/param norm = 1.6051e-01, time/batch = 15.4672s	
25035/33650 (epoch 37.199), train_loss = 0.92330634, grad/param norm = 1.9639e-01, time/batch = 17.3220s	
25036/33650 (epoch 37.201), train_loss = 0.78050281, grad/param norm = 1.7685e-01, time/batch = 16.9772s	
25037/33650 (epoch 37.202), train_loss = 0.81726531, grad/param norm = 1.5440e-01, time/batch = 17.7505s	
25038/33650 (epoch 37.204), train_loss = 0.86800016, grad/param norm = 1.5535e-01, time/batch = 17.1250s	
25039/33650 (epoch 37.205), train_loss = 0.83493033, grad/param norm = 1.7746e-01, time/batch = 16.7295s	
25040/33650 (epoch 37.207), train_loss = 0.79029259, grad/param norm = 1.8572e-01, time/batch = 16.7289s	
25041/33650 (epoch 37.208), train_loss = 0.87213874, grad/param norm = 1.6336e-01, time/batch = 17.4920s	
25042/33650 (epoch 37.210), train_loss = 0.69352807, grad/param norm = 1.4446e-01, time/batch = 16.2315s	
25043/33650 (epoch 37.211), train_loss = 0.77174863, grad/param norm = 1.9230e-01, time/batch = 17.2380s	
25044/33650 (epoch 37.212), train_loss = 0.86996148, grad/param norm = 1.8983e-01, time/batch = 17.6522s	
25045/33650 (epoch 37.214), train_loss = 1.01330452, grad/param norm = 1.8716e-01, time/batch = 17.3194s	
25046/33650 (epoch 37.215), train_loss = 0.68373338, grad/param norm = 1.6045e-01, time/batch = 16.5535s	
25047/33650 (epoch 37.217), train_loss = 0.82679804, grad/param norm = 2.0467e-01, time/batch = 17.5650s	
25048/33650 (epoch 37.218), train_loss = 0.81444667, grad/param norm = 1.7318e-01, time/batch = 17.9038s	
25049/33650 (epoch 37.220), train_loss = 0.72086872, grad/param norm = 1.7664e-01, time/batch = 16.3169s	
25050/33650 (epoch 37.221), train_loss = 0.99863431, grad/param norm = 1.9426e-01, time/batch = 16.9842s	
25051/33650 (epoch 37.223), train_loss = 0.68938703, grad/param norm = 1.5421e-01, time/batch = 18.4765s	
25052/33650 (epoch 37.224), train_loss = 0.79620454, grad/param norm = 1.7110e-01, time/batch = 17.4909s	
25053/33650 (epoch 37.226), train_loss = 1.07816838, grad/param norm = 1.6964e-01, time/batch = 16.4773s	
25054/33650 (epoch 37.227), train_loss = 0.91630742, grad/param norm = 2.3190e-01, time/batch = 18.0771s	
25055/33650 (epoch 37.229), train_loss = 0.93917721, grad/param norm = 1.7227e-01, time/batch = 16.8957s	
25056/33650 (epoch 37.230), train_loss = 1.06312983, grad/param norm = 1.9615e-01, time/batch = 17.0544s	
25057/33650 (epoch 37.232), train_loss = 0.89339870, grad/param norm = 1.9956e-01, time/batch = 15.7907s	
25058/33650 (epoch 37.233), train_loss = 0.87762293, grad/param norm = 2.1286e-01, time/batch = 17.4909s	
25059/33650 (epoch 37.235), train_loss = 0.83474592, grad/param norm = 1.5499e-01, time/batch = 17.2335s	
25060/33650 (epoch 37.236), train_loss = 0.78419493, grad/param norm = 1.5017e-01, time/batch = 17.2303s	
25061/33650 (epoch 37.238), train_loss = 0.79879512, grad/param norm = 1.5809e-01, time/batch = 17.3199s	
25062/33650 (epoch 37.239), train_loss = 0.76891824, grad/param norm = 1.9820e-01, time/batch = 17.5672s	
25063/33650 (epoch 37.241), train_loss = 0.82845332, grad/param norm = 1.5248e-01, time/batch = 17.3894s	
25064/33650 (epoch 37.242), train_loss = 0.67842643, grad/param norm = 1.8115e-01, time/batch = 17.9791s	
25065/33650 (epoch 37.244), train_loss = 0.82525078, grad/param norm = 1.7887e-01, time/batch = 17.9807s	
25066/33650 (epoch 37.245), train_loss = 0.72526116, grad/param norm = 1.4414e-01, time/batch = 16.8951s	
25067/33650 (epoch 37.247), train_loss = 0.80054569, grad/param norm = 1.4986e-01, time/batch = 16.3207s	
25068/33650 (epoch 37.248), train_loss = 0.73749503, grad/param norm = 1.8835e-01, time/batch = 17.6544s	
25069/33650 (epoch 37.250), train_loss = 0.82308839, grad/param norm = 1.4952e-01, time/batch = 17.8957s	
25070/33650 (epoch 37.251), train_loss = 0.92046829, grad/param norm = 1.6356e-01, time/batch = 17.0710s	
25071/33650 (epoch 37.253), train_loss = 0.73244655, grad/param norm = 1.6653e-01, time/batch = 17.7315s	
25072/33650 (epoch 37.254), train_loss = 0.81457672, grad/param norm = 1.7519e-01, time/batch = 17.4984s	
25073/33650 (epoch 37.256), train_loss = 0.94528066, grad/param norm = 1.6826e-01, time/batch = 17.1588s	
25074/33650 (epoch 37.257), train_loss = 0.90364075, grad/param norm = 1.8014e-01, time/batch = 17.2268s	
25075/33650 (epoch 37.259), train_loss = 0.77250288, grad/param norm = 1.8077e-01, time/batch = 17.2044s	
25076/33650 (epoch 37.260), train_loss = 0.87810674, grad/param norm = 1.8153e-01, time/batch = 16.8185s	
25077/33650 (epoch 37.262), train_loss = 0.84578670, grad/param norm = 1.8521e-01, time/batch = 17.0668s	
25078/33650 (epoch 37.263), train_loss = 0.82605562, grad/param norm = 2.0496e-01, time/batch = 16.0610s	
25079/33650 (epoch 37.264), train_loss = 0.89049632, grad/param norm = 1.7793e-01, time/batch = 17.5551s	
25080/33650 (epoch 37.266), train_loss = 0.89676948, grad/param norm = 1.9195e-01, time/batch = 15.8186s	
25081/33650 (epoch 37.267), train_loss = 0.79105440, grad/param norm = 1.5078e-01, time/batch = 17.4763s	
25082/33650 (epoch 37.269), train_loss = 0.83103766, grad/param norm = 1.8285e-01, time/batch = 17.8197s	
25083/33650 (epoch 37.270), train_loss = 0.73329514, grad/param norm = 1.5349e-01, time/batch = 17.2362s	
25084/33650 (epoch 37.272), train_loss = 0.78495392, grad/param norm = 1.5676e-01, time/batch = 28.0717s	
25085/33650 (epoch 37.273), train_loss = 0.91302392, grad/param norm = 1.8205e-01, time/batch = 18.9685s	
25086/33650 (epoch 37.275), train_loss = 0.88960064, grad/param norm = 1.7386e-01, time/batch = 16.8853s	
25087/33650 (epoch 37.276), train_loss = 0.91086472, grad/param norm = 1.8618e-01, time/batch = 16.8900s	
25088/33650 (epoch 37.278), train_loss = 1.01599121, grad/param norm = 2.0714e-01, time/batch = 18.4089s	
25089/33650 (epoch 37.279), train_loss = 0.82577453, grad/param norm = 1.5457e-01, time/batch = 16.1266s	
25090/33650 (epoch 37.281), train_loss = 0.85719650, grad/param norm = 1.8177e-01, time/batch = 16.4680s	
25091/33650 (epoch 37.282), train_loss = 0.93719976, grad/param norm = 1.4069e-01, time/batch = 15.9928s	
25092/33650 (epoch 37.284), train_loss = 0.88541082, grad/param norm = 1.8273e-01, time/batch = 17.7404s	
25093/33650 (epoch 37.285), train_loss = 0.87000499, grad/param norm = 1.7893e-01, time/batch = 17.1472s	
25094/33650 (epoch 37.287), train_loss = 0.81014882, grad/param norm = 1.5901e-01, time/batch = 16.4742s	
25095/33650 (epoch 37.288), train_loss = 0.81003109, grad/param norm = 2.4747e-01, time/batch = 16.3239s	
25096/33650 (epoch 37.290), train_loss = 0.83720857, grad/param norm = 1.6219e-01, time/batch = 16.6501s	
25097/33650 (epoch 37.291), train_loss = 0.79103609, grad/param norm = 1.6352e-01, time/batch = 16.8133s	
25098/33650 (epoch 37.293), train_loss = 0.84669926, grad/param norm = 1.9335e-01, time/batch = 17.1602s	
25099/33650 (epoch 37.294), train_loss = 0.78394774, grad/param norm = 1.4350e-01, time/batch = 17.4847s	
25100/33650 (epoch 37.296), train_loss = 0.74275919, grad/param norm = 1.7130e-01, time/batch = 17.5726s	
25101/33650 (epoch 37.297), train_loss = 0.81359028, grad/param norm = 1.6457e-01, time/batch = 16.8040s	
25102/33650 (epoch 37.299), train_loss = 0.70500669, grad/param norm = 1.4877e-01, time/batch = 17.7398s	
25103/33650 (epoch 37.300), train_loss = 0.75232627, grad/param norm = 1.7911e-01, time/batch = 18.0691s	
25104/33650 (epoch 37.302), train_loss = 0.84155421, grad/param norm = 1.7034e-01, time/batch = 16.5737s	
25105/33650 (epoch 37.303), train_loss = 0.86421942, grad/param norm = 1.5661e-01, time/batch = 17.7363s	
25106/33650 (epoch 37.305), train_loss = 0.80268886, grad/param norm = 1.5629e-01, time/batch = 17.4863s	
25107/33650 (epoch 37.306), train_loss = 0.77174977, grad/param norm = 1.7794e-01, time/batch = 16.2230s	
25108/33650 (epoch 37.308), train_loss = 0.72594896, grad/param norm = 1.9055e-01, time/batch = 17.1476s	
25109/33650 (epoch 37.309), train_loss = 0.94258222, grad/param norm = 1.9392e-01, time/batch = 18.1516s	
25110/33650 (epoch 37.311), train_loss = 0.85330192, grad/param norm = 2.2029e-01, time/batch = 17.0007s	
25111/33650 (epoch 37.312), train_loss = 0.86473455, grad/param norm = 1.6964e-01, time/batch = 16.4825s	
25112/33650 (epoch 37.314), train_loss = 0.78261778, grad/param norm = 1.6182e-01, time/batch = 16.8935s	
25113/33650 (epoch 37.315), train_loss = 0.81332007, grad/param norm = 2.1929e-01, time/batch = 17.8002s	
25114/33650 (epoch 37.316), train_loss = 0.78492725, grad/param norm = 1.7372e-01, time/batch = 17.3139s	
25115/33650 (epoch 37.318), train_loss = 0.74417961, grad/param norm = 1.5974e-01, time/batch = 16.8249s	
25116/33650 (epoch 37.319), train_loss = 0.77195614, grad/param norm = 1.4455e-01, time/batch = 17.4096s	
25117/33650 (epoch 37.321), train_loss = 0.81230616, grad/param norm = 1.5298e-01, time/batch = 17.6604s	
25118/33650 (epoch 37.322), train_loss = 0.84841034, grad/param norm = 1.8639e-01, time/batch = 17.1415s	
25119/33650 (epoch 37.324), train_loss = 0.87073245, grad/param norm = 2.1660e-01, time/batch = 17.8220s	
25120/33650 (epoch 37.325), train_loss = 0.87707228, grad/param norm = 1.6851e-01, time/batch = 17.7319s	
25121/33650 (epoch 37.327), train_loss = 0.77145257, grad/param norm = 1.4089e-01, time/batch = 15.6367s	
25122/33650 (epoch 37.328), train_loss = 0.84345014, grad/param norm = 1.7822e-01, time/batch = 15.4917s	
25123/33650 (epoch 37.330), train_loss = 0.77549232, grad/param norm = 1.4595e-01, time/batch = 17.4866s	
25124/33650 (epoch 37.331), train_loss = 0.73237054, grad/param norm = 1.4976e-01, time/batch = 17.9933s	
25125/33650 (epoch 37.333), train_loss = 0.80289730, grad/param norm = 1.6472e-01, time/batch = 16.0445s	
25126/33650 (epoch 37.334), train_loss = 0.81802534, grad/param norm = 1.5849e-01, time/batch = 17.1496s	
25127/33650 (epoch 37.336), train_loss = 0.92001279, grad/param norm = 1.6166e-01, time/batch = 17.8226s	
25128/33650 (epoch 37.337), train_loss = 0.70979568, grad/param norm = 1.3908e-01, time/batch = 16.5547s	
25129/33650 (epoch 37.339), train_loss = 0.79325299, grad/param norm = 1.6729e-01, time/batch = 17.4900s	
25130/33650 (epoch 37.340), train_loss = 0.89489775, grad/param norm = 1.8410e-01, time/batch = 17.4835s	
25131/33650 (epoch 37.342), train_loss = 0.68313886, grad/param norm = 1.6218e-01, time/batch = 17.0727s	
25132/33650 (epoch 37.343), train_loss = 0.86625649, grad/param norm = 1.7425e-01, time/batch = 16.9786s	
25133/33650 (epoch 37.345), train_loss = 0.87136236, grad/param norm = 1.8256e-01, time/batch = 17.8156s	
25134/33650 (epoch 37.346), train_loss = 0.58680090, grad/param norm = 1.4967e-01, time/batch = 18.0824s	
25135/33650 (epoch 37.348), train_loss = 0.71410871, grad/param norm = 1.4728e-01, time/batch = 16.5636s	
25136/33650 (epoch 37.349), train_loss = 0.68404848, grad/param norm = 1.6055e-01, time/batch = 16.4078s	
25137/33650 (epoch 37.351), train_loss = 0.86428984, grad/param norm = 1.8823e-01, time/batch = 17.2446s	
25138/33650 (epoch 37.352), train_loss = 0.79395443, grad/param norm = 1.9170e-01, time/batch = 17.9110s	
25139/33650 (epoch 37.354), train_loss = 0.94902460, grad/param norm = 2.1290e-01, time/batch = 15.9744s	
25140/33650 (epoch 37.355), train_loss = 0.95936172, grad/param norm = 1.6187e-01, time/batch = 17.4025s	
25141/33650 (epoch 37.357), train_loss = 0.69810174, grad/param norm = 1.6138e-01, time/batch = 18.4014s	
25142/33650 (epoch 37.358), train_loss = 0.83586593, grad/param norm = 1.5668e-01, time/batch = 16.9858s	
25143/33650 (epoch 37.360), train_loss = 0.86256021, grad/param norm = 1.7937e-01, time/batch = 17.4221s	
25144/33650 (epoch 37.361), train_loss = 0.83476919, grad/param norm = 1.6173e-01, time/batch = 17.1438s	
25145/33650 (epoch 37.363), train_loss = 0.84845138, grad/param norm = 1.5350e-01, time/batch = 16.0635s	
25146/33650 (epoch 37.364), train_loss = 0.82216308, grad/param norm = 1.6438e-01, time/batch = 15.8837s	
25147/33650 (epoch 37.366), train_loss = 0.88150719, grad/param norm = 1.8238e-01, time/batch = 15.8531s	
25148/33650 (epoch 37.367), train_loss = 0.85714224, grad/param norm = 1.7172e-01, time/batch = 16.8107s	
25149/33650 (epoch 37.368), train_loss = 0.80304840, grad/param norm = 1.3979e-01, time/batch = 16.4746s	
25150/33650 (epoch 37.370), train_loss = 0.80602433, grad/param norm = 1.6539e-01, time/batch = 17.3906s	
25151/33650 (epoch 37.371), train_loss = 0.63883700, grad/param norm = 1.4891e-01, time/batch = 17.7245s	
25152/33650 (epoch 37.373), train_loss = 0.72495751, grad/param norm = 1.5761e-01, time/batch = 18.1460s	
25153/33650 (epoch 37.374), train_loss = 0.77241936, grad/param norm = 1.4328e-01, time/batch = 16.8874s	
25154/33650 (epoch 37.376), train_loss = 0.81866835, grad/param norm = 2.1992e-01, time/batch = 17.1366s	
25155/33650 (epoch 37.377), train_loss = 0.85412663, grad/param norm = 1.8105e-01, time/batch = 18.4005s	
25156/33650 (epoch 37.379), train_loss = 0.86230973, grad/param norm = 1.8099e-01, time/batch = 15.9481s	
25157/33650 (epoch 37.380), train_loss = 0.70105103, grad/param norm = 1.6151e-01, time/batch = 16.1986s	
25158/33650 (epoch 37.382), train_loss = 0.85670682, grad/param norm = 1.5409e-01, time/batch = 17.8997s	
25159/33650 (epoch 37.383), train_loss = 0.79933630, grad/param norm = 1.6304e-01, time/batch = 17.4135s	
25160/33650 (epoch 37.385), train_loss = 0.86085270, grad/param norm = 1.7525e-01, time/batch = 15.8083s	
25161/33650 (epoch 37.386), train_loss = 0.77007090, grad/param norm = 1.6797e-01, time/batch = 18.2387s	
25162/33650 (epoch 37.388), train_loss = 0.91298414, grad/param norm = 1.7862e-01, time/batch = 16.4175s	
25163/33650 (epoch 37.389), train_loss = 0.75669179, grad/param norm = 1.6165e-01, time/batch = 15.5482s	
25164/33650 (epoch 37.391), train_loss = 0.65683702, grad/param norm = 1.4872e-01, time/batch = 17.3064s	
25165/33650 (epoch 37.392), train_loss = 0.82277082, grad/param norm = 1.5696e-01, time/batch = 17.3948s	
25166/33650 (epoch 37.394), train_loss = 0.85090015, grad/param norm = 1.7771e-01, time/batch = 17.2431s	
25167/33650 (epoch 37.395), train_loss = 0.85090764, grad/param norm = 1.5514e-01, time/batch = 15.9622s	
25168/33650 (epoch 37.397), train_loss = 0.97585990, grad/param norm = 1.7586e-01, time/batch = 16.9978s	
25169/33650 (epoch 37.398), train_loss = 0.91255162, grad/param norm = 1.7196e-01, time/batch = 18.3180s	
25170/33650 (epoch 37.400), train_loss = 0.81966083, grad/param norm = 2.0254e-01, time/batch = 18.7601s	
25171/33650 (epoch 37.401), train_loss = 0.75525548, grad/param norm = 1.7286e-01, time/batch = 20.6837s	
25172/33650 (epoch 37.403), train_loss = 0.86220395, grad/param norm = 1.8308e-01, time/batch = 20.7417s	
25173/33650 (epoch 37.404), train_loss = 0.82009842, grad/param norm = 1.6110e-01, time/batch = 18.9821s	
25174/33650 (epoch 37.406), train_loss = 0.79982948, grad/param norm = 1.6785e-01, time/batch = 20.5766s	
25175/33650 (epoch 37.407), train_loss = 0.85040203, grad/param norm = 1.8574e-01, time/batch = 21.4071s	
25176/33650 (epoch 37.409), train_loss = 0.85007597, grad/param norm = 1.8546e-01, time/batch = 20.4821s	
25177/33650 (epoch 37.410), train_loss = 0.82038889, grad/param norm = 1.6988e-01, time/batch = 19.9655s	
25178/33650 (epoch 37.412), train_loss = 0.83890337, grad/param norm = 1.6380e-01, time/batch = 21.6520s	
25179/33650 (epoch 37.413), train_loss = 0.77935388, grad/param norm = 1.6742e-01, time/batch = 19.9052s	
25180/33650 (epoch 37.415), train_loss = 0.90568983, grad/param norm = 1.8066e-01, time/batch = 21.6521s	
25181/33650 (epoch 37.416), train_loss = 0.97805894, grad/param norm = 1.6793e-01, time/batch = 20.2279s	
25182/33650 (epoch 37.418), train_loss = 0.76027487, grad/param norm = 1.5835e-01, time/batch = 19.8177s	
25183/33650 (epoch 37.419), train_loss = 0.79556741, grad/param norm = 1.7389e-01, time/batch = 21.4928s	
25184/33650 (epoch 37.421), train_loss = 0.80329908, grad/param norm = 1.4592e-01, time/batch = 21.2531s	
25185/33650 (epoch 37.422), train_loss = 0.95411171, grad/param norm = 1.6789e-01, time/batch = 18.6697s	
25186/33650 (epoch 37.423), train_loss = 0.74846397, grad/param norm = 1.3712e-01, time/batch = 20.4236s	
25187/33650 (epoch 37.425), train_loss = 0.85865823, grad/param norm = 1.9554e-01, time/batch = 21.2579s	
25188/33650 (epoch 37.426), train_loss = 0.87720147, grad/param norm = 1.7974e-01, time/batch = 19.1649s	
25189/33650 (epoch 37.428), train_loss = 0.82007250, grad/param norm = 1.7995e-01, time/batch = 18.3340s	
25190/33650 (epoch 37.429), train_loss = 0.87589689, grad/param norm = 1.8240e-01, time/batch = 29.0857s	
25191/33650 (epoch 37.431), train_loss = 0.98703815, grad/param norm = 2.1047e-01, time/batch = 18.8091s	
25192/33650 (epoch 37.432), train_loss = 0.95856114, grad/param norm = 2.0300e-01, time/batch = 16.7389s	
25193/33650 (epoch 37.434), train_loss = 0.86392583, grad/param norm = 1.6736e-01, time/batch = 16.4898s	
25194/33650 (epoch 37.435), train_loss = 0.82676755, grad/param norm = 2.0881e-01, time/batch = 15.3822s	
25195/33650 (epoch 37.437), train_loss = 0.84940148, grad/param norm = 1.7702e-01, time/batch = 17.9082s	
25196/33650 (epoch 37.438), train_loss = 0.82411054, grad/param norm = 1.8871e-01, time/batch = 16.6300s	
25197/33650 (epoch 37.440), train_loss = 0.84522372, grad/param norm = 1.8633e-01, time/batch = 17.0545s	
25198/33650 (epoch 37.441), train_loss = 0.82380838, grad/param norm = 1.8364e-01, time/batch = 17.4053s	
25199/33650 (epoch 37.443), train_loss = 0.93844719, grad/param norm = 1.8447e-01, time/batch = 16.9860s	
25200/33650 (epoch 37.444), train_loss = 0.81454847, grad/param norm = 1.7305e-01, time/batch = 18.4119s	
25201/33650 (epoch 37.446), train_loss = 0.86996401, grad/param norm = 1.8510e-01, time/batch = 16.4812s	
25202/33650 (epoch 37.447), train_loss = 0.94967791, grad/param norm = 1.7022e-01, time/batch = 18.4050s	
25203/33650 (epoch 37.449), train_loss = 0.94645776, grad/param norm = 2.3692e-01, time/batch = 17.5694s	
25204/33650 (epoch 37.450), train_loss = 1.00360838, grad/param norm = 1.7125e-01, time/batch = 16.8152s	
25205/33650 (epoch 37.452), train_loss = 0.97345024, grad/param norm = 2.1889e-01, time/batch = 17.2408s	
25206/33650 (epoch 37.453), train_loss = 0.98975850, grad/param norm = 1.8722e-01, time/batch = 16.1235s	
25207/33650 (epoch 37.455), train_loss = 0.84302853, grad/param norm = 1.7578e-01, time/batch = 18.3019s	
25208/33650 (epoch 37.456), train_loss = 0.85233056, grad/param norm = 1.8135e-01, time/batch = 16.4756s	
25209/33650 (epoch 37.458), train_loss = 0.83093004, grad/param norm = 1.8955e-01, time/batch = 17.1456s	
25210/33650 (epoch 37.459), train_loss = 0.86302065, grad/param norm = 2.0882e-01, time/batch = 17.6383s	
25211/33650 (epoch 37.461), train_loss = 0.89966354, grad/param norm = 1.8833e-01, time/batch = 16.3133s	
25212/33650 (epoch 37.462), train_loss = 0.94381482, grad/param norm = 1.8245e-01, time/batch = 16.8253s	
25213/33650 (epoch 37.464), train_loss = 0.80561402, grad/param norm = 1.8213e-01, time/batch = 17.3993s	
25214/33650 (epoch 37.465), train_loss = 0.90022186, grad/param norm = 2.6063e-01, time/batch = 15.0535s	
25215/33650 (epoch 37.467), train_loss = 0.85969115, grad/param norm = 1.6869e-01, time/batch = 16.7176s	
25216/33650 (epoch 37.468), train_loss = 1.00455709, grad/param norm = 1.8394e-01, time/batch = 17.3190s	
25217/33650 (epoch 37.470), train_loss = 1.07314296, grad/param norm = 2.2299e-01, time/batch = 17.7204s	
25218/33650 (epoch 37.471), train_loss = 0.84437662, grad/param norm = 1.7128e-01, time/batch = 16.3915s	
25219/33650 (epoch 37.473), train_loss = 0.84085086, grad/param norm = 2.3976e-01, time/batch = 17.6536s	
25220/33650 (epoch 37.474), train_loss = 0.97595275, grad/param norm = 1.8847e-01, time/batch = 16.5537s	
25221/33650 (epoch 37.475), train_loss = 0.92152574, grad/param norm = 1.7969e-01, time/batch = 18.1455s	
25222/33650 (epoch 37.477), train_loss = 0.95523879, grad/param norm = 1.8948e-01, time/batch = 16.3195s	
25223/33650 (epoch 37.478), train_loss = 0.95234777, grad/param norm = 1.8506e-01, time/batch = 18.3908s	
25224/33650 (epoch 37.480), train_loss = 0.93985234, grad/param norm = 2.1554e-01, time/batch = 16.9046s	
25225/33650 (epoch 37.481), train_loss = 0.97950979, grad/param norm = 1.8510e-01, time/batch = 17.1322s	
25226/33650 (epoch 37.483), train_loss = 0.73634644, grad/param norm = 1.8050e-01, time/batch = 17.0715s	
25227/33650 (epoch 37.484), train_loss = 0.83071507, grad/param norm = 1.7073e-01, time/batch = 17.8145s	
25228/33650 (epoch 37.486), train_loss = 0.98054960, grad/param norm = 2.1871e-01, time/batch = 16.3751s	
25229/33650 (epoch 37.487), train_loss = 0.97056627, grad/param norm = 2.2395e-01, time/batch = 17.1431s	
25230/33650 (epoch 37.489), train_loss = 1.02036199, grad/param norm = 1.9160e-01, time/batch = 15.8203s	
25231/33650 (epoch 37.490), train_loss = 0.81474732, grad/param norm = 1.8519e-01, time/batch = 17.2146s	
25232/33650 (epoch 37.492), train_loss = 0.91791333, grad/param norm = 2.1708e-01, time/batch = 17.4068s	
25233/33650 (epoch 37.493), train_loss = 0.75054125, grad/param norm = 1.4660e-01, time/batch = 17.2399s	
25234/33650 (epoch 37.495), train_loss = 0.89560370, grad/param norm = 1.5672e-01, time/batch = 17.7434s	
25235/33650 (epoch 37.496), train_loss = 0.90807377, grad/param norm = 1.7558e-01, time/batch = 18.3262s	
25236/33650 (epoch 37.498), train_loss = 0.79190230, grad/param norm = 1.5146e-01, time/batch = 16.8920s	
25237/33650 (epoch 37.499), train_loss = 0.84943391, grad/param norm = 1.4197e-01, time/batch = 17.9031s	
25238/33650 (epoch 37.501), train_loss = 0.86419850, grad/param norm = 1.7922e-01, time/batch = 17.9014s	
25239/33650 (epoch 37.502), train_loss = 0.88947843, grad/param norm = 1.7441e-01, time/batch = 16.3201s	
25240/33650 (epoch 37.504), train_loss = 0.95404261, grad/param norm = 2.0365e-01, time/batch = 17.3286s	
25241/33650 (epoch 37.505), train_loss = 0.86009177, grad/param norm = 1.7416e-01, time/batch = 17.5700s	
25242/33650 (epoch 37.507), train_loss = 0.94794194, grad/param norm = 1.6875e-01, time/batch = 17.8953s	
25243/33650 (epoch 37.508), train_loss = 0.84088360, grad/param norm = 1.5630e-01, time/batch = 17.2259s	
25244/33650 (epoch 37.510), train_loss = 0.88920865, grad/param norm = 1.7780e-01, time/batch = 16.2133s	
25245/33650 (epoch 37.511), train_loss = 1.01224595, grad/param norm = 2.2621e-01, time/batch = 17.2889s	
25246/33650 (epoch 37.513), train_loss = 0.93382022, grad/param norm = 1.7697e-01, time/batch = 16.0712s	
25247/33650 (epoch 37.514), train_loss = 0.97020199, grad/param norm = 2.0621e-01, time/batch = 17.4622s	
25248/33650 (epoch 37.516), train_loss = 0.89451929, grad/param norm = 2.4756e-01, time/batch = 17.9048s	
25249/33650 (epoch 37.517), train_loss = 0.87091222, grad/param norm = 1.9537e-01, time/batch = 17.3172s	
25250/33650 (epoch 37.519), train_loss = 0.92579866, grad/param norm = 1.7476e-01, time/batch = 16.1327s	
25251/33650 (epoch 37.520), train_loss = 0.76922196, grad/param norm = 1.6820e-01, time/batch = 17.5705s	
25252/33650 (epoch 37.522), train_loss = 0.85196963, grad/param norm = 1.7101e-01, time/batch = 18.1515s	
25253/33650 (epoch 37.523), train_loss = 0.80894085, grad/param norm = 1.9360e-01, time/batch = 12.2491s	
25254/33650 (epoch 37.525), train_loss = 0.68568269, grad/param norm = 1.2889e-01, time/batch = 0.6332s	
25255/33650 (epoch 37.526), train_loss = 0.97596687, grad/param norm = 1.6733e-01, time/batch = 0.6302s	
25256/33650 (epoch 37.527), train_loss = 0.80293678, grad/param norm = 1.6340e-01, time/batch = 0.6297s	
25257/33650 (epoch 37.529), train_loss = 0.89268239, grad/param norm = 1.8466e-01, time/batch = 0.6279s	
25258/33650 (epoch 37.530), train_loss = 0.79913708, grad/param norm = 1.6550e-01, time/batch = 0.6312s	
25259/33650 (epoch 37.532), train_loss = 0.92112500, grad/param norm = 2.2132e-01, time/batch = 0.6318s	
25260/33650 (epoch 37.533), train_loss = 0.87791483, grad/param norm = 1.8435e-01, time/batch = 0.6301s	
25261/33650 (epoch 37.535), train_loss = 0.98084606, grad/param norm = 1.8213e-01, time/batch = 0.7512s	
25262/33650 (epoch 37.536), train_loss = 0.88170552, grad/param norm = 1.9584e-01, time/batch = 0.9216s	
25263/33650 (epoch 37.538), train_loss = 0.87508302, grad/param norm = 1.8201e-01, time/batch = 0.9205s	
25264/33650 (epoch 37.539), train_loss = 0.69800346, grad/param norm = 1.7567e-01, time/batch = 0.9560s	
25265/33650 (epoch 37.541), train_loss = 0.96496633, grad/param norm = 1.7248e-01, time/batch = 0.9416s	
25266/33650 (epoch 37.542), train_loss = 0.85608358, grad/param norm = 2.1277e-01, time/batch = 0.9586s	
25267/33650 (epoch 37.544), train_loss = 1.04655723, grad/param norm = 2.2305e-01, time/batch = 1.7234s	
25268/33650 (epoch 37.545), train_loss = 0.77282891, grad/param norm = 1.7586e-01, time/batch = 1.7321s	
25269/33650 (epoch 37.547), train_loss = 0.91728840, grad/param norm = 1.5673e-01, time/batch = 4.1843s	
25270/33650 (epoch 37.548), train_loss = 1.02702080, grad/param norm = 1.6760e-01, time/batch = 16.7439s	
25271/33650 (epoch 37.550), train_loss = 0.88900093, grad/param norm = 1.9464e-01, time/batch = 18.0711s	
25272/33650 (epoch 37.551), train_loss = 0.89500158, grad/param norm = 1.7852e-01, time/batch = 16.9668s	
25273/33650 (epoch 37.553), train_loss = 0.75335368, grad/param norm = 1.6302e-01, time/batch = 18.1515s	
25274/33650 (epoch 37.554), train_loss = 1.02771491, grad/param norm = 2.0528e-01, time/batch = 17.1483s	
25275/33650 (epoch 37.556), train_loss = 0.99462739, grad/param norm = 2.5162e-01, time/batch = 16.6597s	
25276/33650 (epoch 37.557), train_loss = 0.93844215, grad/param norm = 2.1651e-01, time/batch = 15.4557s	
25277/33650 (epoch 37.559), train_loss = 1.09288302, grad/param norm = 2.0127e-01, time/batch = 17.2377s	
25278/33650 (epoch 37.560), train_loss = 1.00831457, grad/param norm = 1.9758e-01, time/batch = 17.0755s	
25279/33650 (epoch 37.562), train_loss = 0.99231534, grad/param norm = 1.7520e-01, time/batch = 16.8046s	
25280/33650 (epoch 37.563), train_loss = 0.91000984, grad/param norm = 1.9931e-01, time/batch = 18.2353s	
25281/33650 (epoch 37.565), train_loss = 0.90722771, grad/param norm = 1.5908e-01, time/batch = 15.2231s	
25282/33650 (epoch 37.566), train_loss = 0.86366556, grad/param norm = 2.1115e-01, time/batch = 17.0631s	
25283/33650 (epoch 37.568), train_loss = 0.89510578, grad/param norm = 2.3657e-01, time/batch = 17.7371s	
25284/33650 (epoch 37.569), train_loss = 0.80628097, grad/param norm = 1.7093e-01, time/batch = 18.1516s	
25285/33650 (epoch 37.571), train_loss = 0.97713776, grad/param norm = 1.7570e-01, time/batch = 17.3353s	
25286/33650 (epoch 37.572), train_loss = 0.92977544, grad/param norm = 1.6329e-01, time/batch = 16.9705s	
25287/33650 (epoch 37.574), train_loss = 0.79515851, grad/param norm = 1.6921e-01, time/batch = 18.1551s	
25288/33650 (epoch 37.575), train_loss = 0.89288162, grad/param norm = 1.8235e-01, time/batch = 16.4899s	
25289/33650 (epoch 37.577), train_loss = 0.79009125, grad/param norm = 1.9054e-01, time/batch = 13.8946s	
25290/33650 (epoch 37.578), train_loss = 0.97504329, grad/param norm = 1.9215e-01, time/batch = 13.5129s	
25291/33650 (epoch 37.579), train_loss = 0.92109326, grad/param norm = 1.6498e-01, time/batch = 13.9117s	
25292/33650 (epoch 37.581), train_loss = 1.02048712, grad/param norm = 1.8807e-01, time/batch = 16.8974s	
25293/33650 (epoch 37.582), train_loss = 0.91008232, grad/param norm = 1.7482e-01, time/batch = 15.7709s	
25294/33650 (epoch 37.584), train_loss = 0.88012652, grad/param norm = 1.5721e-01, time/batch = 16.8871s	
25295/33650 (epoch 37.585), train_loss = 0.93900215, grad/param norm = 2.5177e-01, time/batch = 17.7429s	
25296/33650 (epoch 37.587), train_loss = 0.82160412, grad/param norm = 1.8130e-01, time/batch = 17.3202s	
25297/33650 (epoch 37.588), train_loss = 0.83629193, grad/param norm = 2.3120e-01, time/batch = 16.3899s	
25298/33650 (epoch 37.590), train_loss = 0.84126388, grad/param norm = 1.4512e-01, time/batch = 17.9831s	
25299/33650 (epoch 37.591), train_loss = 0.76612120, grad/param norm = 1.7496e-01, time/batch = 17.6549s	
25300/33650 (epoch 37.593), train_loss = 0.77306106, grad/param norm = 1.6376e-01, time/batch = 17.0649s	
25301/33650 (epoch 37.594), train_loss = 0.77699463, grad/param norm = 1.7071e-01, time/batch = 17.2174s	
25302/33650 (epoch 37.596), train_loss = 0.86140750, grad/param norm = 1.5531e-01, time/batch = 18.0605s	
25303/33650 (epoch 37.597), train_loss = 0.75649421, grad/param norm = 1.5656e-01, time/batch = 17.7295s	
25304/33650 (epoch 37.599), train_loss = 0.86400253, grad/param norm = 1.7221e-01, time/batch = 25.9538s	
25305/33650 (epoch 37.600), train_loss = 0.82061947, grad/param norm = 1.6750e-01, time/batch = 23.8695s	
25306/33650 (epoch 37.602), train_loss = 0.88711446, grad/param norm = 1.9077e-01, time/batch = 16.3885s	
25307/33650 (epoch 37.603), train_loss = 0.80498217, grad/param norm = 1.6289e-01, time/batch = 16.3978s	
25308/33650 (epoch 37.605), train_loss = 0.92853504, grad/param norm = 1.6332e-01, time/batch = 17.3041s	
25309/33650 (epoch 37.606), train_loss = 0.85932290, grad/param norm = 1.9126e-01, time/batch = 18.1519s	
25310/33650 (epoch 37.608), train_loss = 0.75735476, grad/param norm = 1.7190e-01, time/batch = 16.6472s	
25311/33650 (epoch 37.609), train_loss = 0.85701645, grad/param norm = 1.5879e-01, time/batch = 17.5522s	
25312/33650 (epoch 37.611), train_loss = 0.74897050, grad/param norm = 1.4842e-01, time/batch = 16.7369s	
25313/33650 (epoch 37.612), train_loss = 0.85391958, grad/param norm = 1.9971e-01, time/batch = 17.0668s	
25314/33650 (epoch 37.614), train_loss = 0.95472530, grad/param norm = 1.7292e-01, time/batch = 17.3253s	
25315/33650 (epoch 37.615), train_loss = 0.89785622, grad/param norm = 1.4910e-01, time/batch = 17.4056s	
25316/33650 (epoch 37.617), train_loss = 0.78412391, grad/param norm = 1.4987e-01, time/batch = 17.6593s	
25317/33650 (epoch 37.618), train_loss = 0.83450880, grad/param norm = 1.6669e-01, time/batch = 15.2065s	
25318/33650 (epoch 37.620), train_loss = 0.80410531, grad/param norm = 1.7676e-01, time/batch = 17.7403s	
25319/33650 (epoch 37.621), train_loss = 0.78840600, grad/param norm = 1.5959e-01, time/batch = 17.3100s	
25320/33650 (epoch 37.623), train_loss = 0.83242882, grad/param norm = 1.6011e-01, time/batch = 16.2273s	
25321/33650 (epoch 37.624), train_loss = 0.66572551, grad/param norm = 1.6539e-01, time/batch = 18.4927s	
25322/33650 (epoch 37.626), train_loss = 0.72354751, grad/param norm = 1.7304e-01, time/batch = 17.5710s	
25323/33650 (epoch 37.627), train_loss = 0.79512715, grad/param norm = 1.5450e-01, time/batch = 16.7197s	
25324/33650 (epoch 37.629), train_loss = 0.81591594, grad/param norm = 1.9558e-01, time/batch = 17.5516s	
25325/33650 (epoch 37.630), train_loss = 0.96344341, grad/param norm = 1.8045e-01, time/batch = 17.0749s	
25326/33650 (epoch 37.632), train_loss = 0.94545185, grad/param norm = 1.7946e-01, time/batch = 17.9757s	
25327/33650 (epoch 37.633), train_loss = 0.94274881, grad/param norm = 1.6874e-01, time/batch = 17.0708s	
25328/33650 (epoch 37.634), train_loss = 0.76753824, grad/param norm = 1.5892e-01, time/batch = 17.9715s	
25329/33650 (epoch 37.636), train_loss = 0.66560613, grad/param norm = 1.2440e-01, time/batch = 18.1247s	
25330/33650 (epoch 37.637), train_loss = 0.76849701, grad/param norm = 1.7094e-01, time/batch = 16.8076s	
25331/33650 (epoch 37.639), train_loss = 0.76754868, grad/param norm = 1.5321e-01, time/batch = 18.0606s	
25332/33650 (epoch 37.640), train_loss = 0.86757444, grad/param norm = 1.9366e-01, time/batch = 18.5551s	
25333/33650 (epoch 37.642), train_loss = 0.94168788, grad/param norm = 1.8529e-01, time/batch = 18.6418s	
25334/33650 (epoch 37.643), train_loss = 0.86261898, grad/param norm = 1.6665e-01, time/batch = 18.0466s	
25335/33650 (epoch 37.645), train_loss = 0.86221699, grad/param norm = 1.7655e-01, time/batch = 18.2361s	
25336/33650 (epoch 37.646), train_loss = 0.76110455, grad/param norm = 1.3606e-01, time/batch = 16.3880s	
25337/33650 (epoch 37.648), train_loss = 0.88724032, grad/param norm = 1.6017e-01, time/batch = 17.6438s	
25338/33650 (epoch 37.649), train_loss = 0.75994796, grad/param norm = 1.7015e-01, time/batch = 17.9030s	
25339/33650 (epoch 37.651), train_loss = 0.92604912, grad/param norm = 1.8218e-01, time/batch = 18.6415s	
25340/33650 (epoch 37.652), train_loss = 0.64175378, grad/param norm = 1.2895e-01, time/batch = 17.6369s	
25341/33650 (epoch 37.654), train_loss = 0.77296326, grad/param norm = 1.6811e-01, time/batch = 18.0531s	
25342/33650 (epoch 37.655), train_loss = 0.74551064, grad/param norm = 1.4645e-01, time/batch = 18.3794s	
25343/33650 (epoch 37.657), train_loss = 0.77512713, grad/param norm = 1.8555e-01, time/batch = 18.1467s	
25344/33650 (epoch 37.658), train_loss = 0.69524007, grad/param norm = 1.7402e-01, time/batch = 17.9639s	
25345/33650 (epoch 37.660), train_loss = 0.68816206, grad/param norm = 1.4818e-01, time/batch = 15.6254s	
25346/33650 (epoch 37.661), train_loss = 0.75821627, grad/param norm = 1.4904e-01, time/batch = 17.3851s	
25347/33650 (epoch 37.663), train_loss = 0.72866940, grad/param norm = 1.7358e-01, time/batch = 17.3784s	
25348/33650 (epoch 37.664), train_loss = 0.81379910, grad/param norm = 1.5545e-01, time/batch = 18.1346s	
25349/33650 (epoch 37.666), train_loss = 0.84363422, grad/param norm = 1.6306e-01, time/batch = 18.3998s	
25350/33650 (epoch 37.667), train_loss = 0.70581065, grad/param norm = 1.5646e-01, time/batch = 17.6122s	
25351/33650 (epoch 37.669), train_loss = 0.73965149, grad/param norm = 1.4550e-01, time/batch = 17.6368s	
25352/33650 (epoch 37.670), train_loss = 0.66627163, grad/param norm = 1.4569e-01, time/batch = 19.0623s	
25353/33650 (epoch 37.672), train_loss = 0.70693752, grad/param norm = 1.5826e-01, time/batch = 18.2183s	
25354/33650 (epoch 37.673), train_loss = 0.70153078, grad/param norm = 1.5938e-01, time/batch = 17.5410s	
25355/33650 (epoch 37.675), train_loss = 0.65091725, grad/param norm = 1.3153e-01, time/batch = 17.1299s	
25356/33650 (epoch 37.676), train_loss = 0.76870282, grad/param norm = 1.5928e-01, time/batch = 17.9740s	
25357/33650 (epoch 37.678), train_loss = 0.76143577, grad/param norm = 1.5398e-01, time/batch = 16.7265s	
25358/33650 (epoch 37.679), train_loss = 0.77331806, grad/param norm = 1.9624e-01, time/batch = 18.2935s	
25359/33650 (epoch 37.681), train_loss = 0.77000919, grad/param norm = 1.4123e-01, time/batch = 19.2245s	
25360/33650 (epoch 37.682), train_loss = 0.75592575, grad/param norm = 1.6064e-01, time/batch = 17.7197s	
25361/33650 (epoch 37.684), train_loss = 0.71127622, grad/param norm = 1.5483e-01, time/batch = 18.4751s	
25362/33650 (epoch 37.685), train_loss = 0.85521648, grad/param norm = 1.8511e-01, time/batch = 19.1373s	
25363/33650 (epoch 37.686), train_loss = 0.83183523, grad/param norm = 1.8392e-01, time/batch = 17.3065s	
25364/33650 (epoch 37.688), train_loss = 0.88318335, grad/param norm = 1.6452e-01, time/batch = 17.2938s	
25365/33650 (epoch 37.689), train_loss = 0.76634189, grad/param norm = 1.5742e-01, time/batch = 18.5592s	
25366/33650 (epoch 37.691), train_loss = 0.90778435, grad/param norm = 1.7567e-01, time/batch = 18.2874s	
25367/33650 (epoch 37.692), train_loss = 0.90135180, grad/param norm = 1.7157e-01, time/batch = 17.0647s	
25368/33650 (epoch 37.694), train_loss = 0.88584334, grad/param norm = 1.8273e-01, time/batch = 18.9614s	
25369/33650 (epoch 37.695), train_loss = 0.56173060, grad/param norm = 1.3708e-01, time/batch = 17.7238s	
25370/33650 (epoch 37.697), train_loss = 0.78810990, grad/param norm = 1.5431e-01, time/batch = 17.0551s	
25371/33650 (epoch 37.698), train_loss = 0.90888660, grad/param norm = 1.9114e-01, time/batch = 17.6422s	
25372/33650 (epoch 37.700), train_loss = 0.80553631, grad/param norm = 1.7508e-01, time/batch = 16.3059s	
25373/33650 (epoch 37.701), train_loss = 0.83717242, grad/param norm = 1.7343e-01, time/batch = 17.2888s	
25374/33650 (epoch 37.703), train_loss = 1.00793994, grad/param norm = 1.6892e-01, time/batch = 17.3097s	
25375/33650 (epoch 37.704), train_loss = 0.81799588, grad/param norm = 1.5893e-01, time/batch = 18.6392s	
25376/33650 (epoch 37.706), train_loss = 0.78223397, grad/param norm = 1.4338e-01, time/batch = 18.2950s	
25377/33650 (epoch 37.707), train_loss = 0.90980041, grad/param norm = 1.7131e-01, time/batch = 18.6289s	
25378/33650 (epoch 37.709), train_loss = 0.77043313, grad/param norm = 1.5337e-01, time/batch = 15.9629s	
25379/33650 (epoch 37.710), train_loss = 0.98985402, grad/param norm = 2.0310e-01, time/batch = 19.0557s	
25380/33650 (epoch 37.712), train_loss = 0.71622441, grad/param norm = 1.7297e-01, time/batch = 17.1360s	
25381/33650 (epoch 37.713), train_loss = 0.75167094, grad/param norm = 2.1146e-01, time/batch = 18.3812s	
25382/33650 (epoch 37.715), train_loss = 0.87590737, grad/param norm = 1.9165e-01, time/batch = 17.8076s	
25383/33650 (epoch 37.716), train_loss = 0.79889147, grad/param norm = 1.6647e-01, time/batch = 18.3846s	
25384/33650 (epoch 37.718), train_loss = 0.76818943, grad/param norm = 1.5328e-01, time/batch = 17.8891s	
25385/33650 (epoch 37.719), train_loss = 0.93146912, grad/param norm = 2.1439e-01, time/batch = 19.0515s	
25386/33650 (epoch 37.721), train_loss = 0.99751843, grad/param norm = 1.9536e-01, time/batch = 17.6441s	
25387/33650 (epoch 37.722), train_loss = 0.90862709, grad/param norm = 2.2558e-01, time/batch = 16.8890s	
25388/33650 (epoch 37.724), train_loss = 0.90923415, grad/param norm = 1.8109e-01, time/batch = 18.3923s	
25389/33650 (epoch 37.725), train_loss = 0.87416463, grad/param norm = 1.7691e-01, time/batch = 17.5470s	
25390/33650 (epoch 37.727), train_loss = 0.80315241, grad/param norm = 1.7978e-01, time/batch = 16.2026s	
25391/33650 (epoch 37.728), train_loss = 0.80302133, grad/param norm = 1.5346e-01, time/batch = 18.3011s	
25392/33650 (epoch 37.730), train_loss = 0.85389066, grad/param norm = 1.5669e-01, time/batch = 18.3193s	
25393/33650 (epoch 37.731), train_loss = 1.00029757, grad/param norm = 2.0301e-01, time/batch = 18.9837s	
25394/33650 (epoch 37.733), train_loss = 0.79848241, grad/param norm = 1.7779e-01, time/batch = 17.0469s	
25395/33650 (epoch 37.734), train_loss = 0.96338666, grad/param norm = 1.9060e-01, time/batch = 19.0494s	
25396/33650 (epoch 37.736), train_loss = 0.84916685, grad/param norm = 2.4875e-01, time/batch = 18.4817s	
25397/33650 (epoch 37.737), train_loss = 0.86403892, grad/param norm = 1.7264e-01, time/batch = 16.4667s	
25398/33650 (epoch 37.738), train_loss = 0.77163059, grad/param norm = 1.6870e-01, time/batch = 19.2282s	
25399/33650 (epoch 37.740), train_loss = 0.72097220, grad/param norm = 1.6079e-01, time/batch = 19.0547s	
25400/33650 (epoch 37.741), train_loss = 0.76563837, grad/param norm = 1.7127e-01, time/batch = 16.9688s	
25401/33650 (epoch 37.743), train_loss = 0.81257828, grad/param norm = 1.6214e-01, time/batch = 18.0663s	
25402/33650 (epoch 37.744), train_loss = 0.92469385, grad/param norm = 1.4798e-01, time/batch = 18.7227s	
25403/33650 (epoch 37.746), train_loss = 0.79019686, grad/param norm = 1.6639e-01, time/batch = 18.7223s	
25404/33650 (epoch 37.747), train_loss = 0.94645183, grad/param norm = 1.7179e-01, time/batch = 17.2977s	
25405/33650 (epoch 37.749), train_loss = 0.67788597, grad/param norm = 1.6694e-01, time/batch = 17.8812s	
25406/33650 (epoch 37.750), train_loss = 0.96646087, grad/param norm = 1.7642e-01, time/batch = 18.1478s	
25407/33650 (epoch 37.752), train_loss = 0.91753968, grad/param norm = 1.8034e-01, time/batch = 17.6530s	
25408/33650 (epoch 37.753), train_loss = 1.00952604, grad/param norm = 1.9964e-01, time/batch = 18.7290s	
25409/33650 (epoch 37.755), train_loss = 0.83521295, grad/param norm = 1.6050e-01, time/batch = 19.2344s	
25410/33650 (epoch 37.756), train_loss = 0.90321005, grad/param norm = 1.8509e-01, time/batch = 17.4721s	
25411/33650 (epoch 37.758), train_loss = 0.94038661, grad/param norm = 1.8230e-01, time/batch = 16.9598s	
25412/33650 (epoch 37.759), train_loss = 0.95713711, grad/param norm = 2.1369e-01, time/batch = 17.9841s	
25413/33650 (epoch 37.761), train_loss = 0.86156439, grad/param norm = 1.7609e-01, time/batch = 17.0625s	
25414/33650 (epoch 37.762), train_loss = 0.85094133, grad/param norm = 1.6714e-01, time/batch = 18.3836s	
25415/33650 (epoch 37.764), train_loss = 0.87493677, grad/param norm = 1.8879e-01, time/batch = 17.8993s	
25416/33650 (epoch 37.765), train_loss = 0.79126193, grad/param norm = 1.8104e-01, time/batch = 19.1402s	
25417/33650 (epoch 37.767), train_loss = 0.83135176, grad/param norm = 1.7034e-01, time/batch = 16.7881s	
25418/33650 (epoch 37.768), train_loss = 0.77528992, grad/param norm = 1.6280e-01, time/batch = 18.2192s	
25419/33650 (epoch 37.770), train_loss = 0.84990186, grad/param norm = 1.9319e-01, time/batch = 18.5666s	
25420/33650 (epoch 37.771), train_loss = 0.86432858, grad/param norm = 1.5953e-01, time/batch = 17.0468s	
25421/33650 (epoch 37.773), train_loss = 0.94022195, grad/param norm = 2.2460e-01, time/batch = 18.6508s	
25422/33650 (epoch 37.774), train_loss = 0.85998321, grad/param norm = 1.9234e-01, time/batch = 17.6560s	
25423/33650 (epoch 37.776), train_loss = 0.92927935, grad/param norm = 2.0645e-01, time/batch = 17.5577s	
25424/33650 (epoch 37.777), train_loss = 0.76353768, grad/param norm = 1.4404e-01, time/batch = 17.0388s	
25425/33650 (epoch 37.779), train_loss = 0.82346871, grad/param norm = 1.5308e-01, time/batch = 18.7241s	
25426/33650 (epoch 37.780), train_loss = 0.76503669, grad/param norm = 1.3999e-01, time/batch = 18.0611s	
25427/33650 (epoch 37.782), train_loss = 0.76642167, grad/param norm = 1.6886e-01, time/batch = 16.8000s	
25428/33650 (epoch 37.783), train_loss = 0.77365502, grad/param norm = 1.3654e-01, time/batch = 18.7291s	
25429/33650 (epoch 37.785), train_loss = 0.98384682, grad/param norm = 1.5888e-01, time/batch = 18.0619s	
25430/33650 (epoch 37.786), train_loss = 0.87099558, grad/param norm = 1.5796e-01, time/batch = 17.4584s	
25431/33650 (epoch 37.788), train_loss = 0.90631583, grad/param norm = 1.7127e-01, time/batch = 18.2929s	
25432/33650 (epoch 37.789), train_loss = 0.92259352, grad/param norm = 1.7006e-01, time/batch = 18.9643s	
25433/33650 (epoch 37.790), train_loss = 0.84181360, grad/param norm = 1.7219e-01, time/batch = 17.5722s	
25434/33650 (epoch 37.792), train_loss = 0.95202094, grad/param norm = 1.8069e-01, time/batch = 17.7873s	
25435/33650 (epoch 37.793), train_loss = 0.90790220, grad/param norm = 2.0396e-01, time/batch = 19.2308s	
25436/33650 (epoch 37.795), train_loss = 0.92170168, grad/param norm = 1.7591e-01, time/batch = 18.4789s	
25437/33650 (epoch 37.796), train_loss = 0.81723122, grad/param norm = 1.5833e-01, time/batch = 17.3870s	
25438/33650 (epoch 37.798), train_loss = 0.80668233, grad/param norm = 1.6905e-01, time/batch = 18.2105s	
25439/33650 (epoch 37.799), train_loss = 0.83807726, grad/param norm = 1.6103e-01, time/batch = 18.8078s	
25440/33650 (epoch 37.801), train_loss = 0.85025578, grad/param norm = 1.9896e-01, time/batch = 17.3928s	
25441/33650 (epoch 37.802), train_loss = 0.95002323, grad/param norm = 1.8582e-01, time/batch = 18.6520s	
25442/33650 (epoch 37.804), train_loss = 0.83758949, grad/param norm = 1.6303e-01, time/batch = 18.0544s	
25443/33650 (epoch 37.805), train_loss = 0.84245390, grad/param norm = 1.5689e-01, time/batch = 18.1996s	
25444/33650 (epoch 37.807), train_loss = 0.98233865, grad/param norm = 2.1670e-01, time/batch = 17.8823s	
25445/33650 (epoch 37.808), train_loss = 1.08363277, grad/param norm = 2.2714e-01, time/batch = 18.2288s	
25446/33650 (epoch 37.810), train_loss = 0.89209206, grad/param norm = 1.7879e-01, time/batch = 18.0422s	
25447/33650 (epoch 37.811), train_loss = 0.86617689, grad/param norm = 1.6818e-01, time/batch = 14.0569s	
25448/33650 (epoch 37.813), train_loss = 0.77101589, grad/param norm = 1.5682e-01, time/batch = 15.6359s	
25449/33650 (epoch 37.814), train_loss = 0.93034417, grad/param norm = 1.8562e-01, time/batch = 18.8217s	
25450/33650 (epoch 37.816), train_loss = 0.92632149, grad/param norm = 2.3108e-01, time/batch = 17.5568s	
25451/33650 (epoch 37.817), train_loss = 0.93899080, grad/param norm = 1.8017e-01, time/batch = 17.2369s	
25452/33650 (epoch 37.819), train_loss = 0.86113793, grad/param norm = 1.8763e-01, time/batch = 18.3089s	
25453/33650 (epoch 37.820), train_loss = 0.93551680, grad/param norm = 1.6867e-01, time/batch = 19.1488s	
25454/33650 (epoch 37.822), train_loss = 0.88992546, grad/param norm = 2.0658e-01, time/batch = 18.4592s	
25455/33650 (epoch 37.823), train_loss = 0.80864653, grad/param norm = 1.7966e-01, time/batch = 16.8192s	
25456/33650 (epoch 37.825), train_loss = 0.84712612, grad/param norm = 1.5923e-01, time/batch = 19.1401s	
25457/33650 (epoch 37.826), train_loss = 0.91195802, grad/param norm = 1.5787e-01, time/batch = 17.2158s	
25458/33650 (epoch 37.828), train_loss = 1.02460994, grad/param norm = 2.7962e-01, time/batch = 18.3834s	
25459/33650 (epoch 37.829), train_loss = 0.74527798, grad/param norm = 1.8521e-01, time/batch = 18.3176s	
25460/33650 (epoch 37.831), train_loss = 0.91733424, grad/param norm = 2.6456e-01, time/batch = 18.3858s	
25461/33650 (epoch 37.832), train_loss = 0.93100031, grad/param norm = 1.8868e-01, time/batch = 18.6491s	
25462/33650 (epoch 37.834), train_loss = 0.92073723, grad/param norm = 1.7901e-01, time/batch = 17.5746s	
25463/33650 (epoch 37.835), train_loss = 1.05763914, grad/param norm = 2.0754e-01, time/batch = 16.2181s	
25464/33650 (epoch 37.837), train_loss = 0.90917874, grad/param norm = 1.9050e-01, time/batch = 18.1295s	
25465/33650 (epoch 37.838), train_loss = 0.86389682, grad/param norm = 1.8021e-01, time/batch = 17.2153s	
25466/33650 (epoch 37.840), train_loss = 0.95088409, grad/param norm = 1.8415e-01, time/batch = 17.7307s	
25467/33650 (epoch 37.841), train_loss = 0.81931594, grad/param norm = 1.7128e-01, time/batch = 16.7929s	
25468/33650 (epoch 37.842), train_loss = 0.85101240, grad/param norm = 1.7208e-01, time/batch = 18.8993s	
25469/33650 (epoch 37.844), train_loss = 0.97518257, grad/param norm = 1.7331e-01, time/batch = 18.3824s	
25470/33650 (epoch 37.845), train_loss = 0.85541102, grad/param norm = 2.1586e-01, time/batch = 17.6505s	
25471/33650 (epoch 37.847), train_loss = 0.64623804, grad/param norm = 1.4201e-01, time/batch = 18.8755s	
25472/33650 (epoch 37.848), train_loss = 0.76273662, grad/param norm = 2.0395e-01, time/batch = 18.1255s	
25473/33650 (epoch 37.850), train_loss = 0.83276961, grad/param norm = 2.4098e-01, time/batch = 14.3164s	
25474/33650 (epoch 37.851), train_loss = 0.72663870, grad/param norm = 1.5359e-01, time/batch = 14.4219s	
25475/33650 (epoch 37.853), train_loss = 0.81738101, grad/param norm = 1.9310e-01, time/batch = 14.8508s	
25476/33650 (epoch 37.854), train_loss = 0.94504156, grad/param norm = 1.9360e-01, time/batch = 19.0670s	
25477/33650 (epoch 37.856), train_loss = 0.68091554, grad/param norm = 1.5257e-01, time/batch = 18.2969s	
25478/33650 (epoch 37.857), train_loss = 0.88646092, grad/param norm = 1.5515e-01, time/batch = 17.1331s	
25479/33650 (epoch 37.859), train_loss = 0.76834698, grad/param norm = 1.4966e-01, time/batch = 19.2278s	
25480/33650 (epoch 37.860), train_loss = 0.73706854, grad/param norm = 1.7347e-01, time/batch = 17.8953s	
25481/33650 (epoch 37.862), train_loss = 0.78296873, grad/param norm = 1.6818e-01, time/batch = 17.7259s	
25482/33650 (epoch 37.863), train_loss = 0.95915205, grad/param norm = 1.5980e-01, time/batch = 18.8960s	
25483/33650 (epoch 37.865), train_loss = 0.84997491, grad/param norm = 1.6434e-01, time/batch = 17.8096s	
25484/33650 (epoch 37.866), train_loss = 0.78946517, grad/param norm = 1.7800e-01, time/batch = 17.6398s	
25485/33650 (epoch 37.868), train_loss = 0.71361729, grad/param norm = 1.6255e-01, time/batch = 19.2254s	
25486/33650 (epoch 37.869), train_loss = 0.89767323, grad/param norm = 1.8153e-01, time/batch = 16.0621s	
25487/33650 (epoch 37.871), train_loss = 0.74178743, grad/param norm = 1.5827e-01, time/batch = 17.7215s	
25488/33650 (epoch 37.872), train_loss = 0.86844355, grad/param norm = 1.7744e-01, time/batch = 17.4778s	
25489/33650 (epoch 37.874), train_loss = 0.91941481, grad/param norm = 1.7555e-01, time/batch = 18.3978s	
25490/33650 (epoch 37.875), train_loss = 0.80619548, grad/param norm = 1.6314e-01, time/batch = 19.3115s	
25491/33650 (epoch 37.877), train_loss = 0.99011577, grad/param norm = 1.7797e-01, time/batch = 17.7223s	
25492/33650 (epoch 37.878), train_loss = 0.63171531, grad/param norm = 1.4041e-01, time/batch = 16.7199s	
25493/33650 (epoch 37.880), train_loss = 0.88021967, grad/param norm = 1.8399e-01, time/batch = 18.4788s	
25494/33650 (epoch 37.881), train_loss = 0.81685644, grad/param norm = 1.8628e-01, time/batch = 17.5612s	
25495/33650 (epoch 37.883), train_loss = 0.88435588, grad/param norm = 1.8461e-01, time/batch = 17.7103s	
25496/33650 (epoch 37.884), train_loss = 0.95392019, grad/param norm = 2.2687e-01, time/batch = 18.5618s	
25497/33650 (epoch 37.886), train_loss = 0.90306318, grad/param norm = 1.7350e-01, time/batch = 16.9815s	
25498/33650 (epoch 37.887), train_loss = 0.75017547, grad/param norm = 1.6262e-01, time/batch = 18.1332s	
25499/33650 (epoch 37.889), train_loss = 0.81406507, grad/param norm = 1.7505e-01, time/batch = 16.9837s	
25500/33650 (epoch 37.890), train_loss = 0.88193732, grad/param norm = 1.5698e-01, time/batch = 18.2196s	
25501/33650 (epoch 37.892), train_loss = 0.77995316, grad/param norm = 1.8346e-01, time/batch = 17.1332s	
25502/33650 (epoch 37.893), train_loss = 0.88050677, grad/param norm = 1.7980e-01, time/batch = 18.4782s	
25503/33650 (epoch 37.895), train_loss = 0.94536370, grad/param norm = 1.7576e-01, time/batch = 18.2371s	
25504/33650 (epoch 37.896), train_loss = 0.78085410, grad/param norm = 1.5484e-01, time/batch = 22.3587s	
25505/33650 (epoch 37.897), train_loss = 0.69880180, grad/param norm = 1.5156e-01, time/batch = 19.2939s	
25506/33650 (epoch 37.899), train_loss = 0.76310834, grad/param norm = 1.5196e-01, time/batch = 13.7592s	
25507/33650 (epoch 37.900), train_loss = 0.73474966, grad/param norm = 1.7010e-01, time/batch = 17.0460s	
25508/33650 (epoch 37.902), train_loss = 0.80558553, grad/param norm = 1.7052e-01, time/batch = 17.3958s	
25509/33650 (epoch 37.903), train_loss = 0.80038102, grad/param norm = 1.7093e-01, time/batch = 17.0611s	
25510/33650 (epoch 37.905), train_loss = 0.95099053, grad/param norm = 1.8061e-01, time/batch = 18.9786s	
25511/33650 (epoch 37.906), train_loss = 0.78634065, grad/param norm = 1.7517e-01, time/batch = 17.9707s	
25512/33650 (epoch 37.908), train_loss = 0.81812526, grad/param norm = 1.6221e-01, time/batch = 17.7032s	
25513/33650 (epoch 37.909), train_loss = 0.78041039, grad/param norm = 1.5173e-01, time/batch = 18.4883s	
25514/33650 (epoch 37.911), train_loss = 0.70971715, grad/param norm = 1.3519e-01, time/batch = 16.7190s	
25515/33650 (epoch 37.912), train_loss = 0.64152930, grad/param norm = 1.4707e-01, time/batch = 18.6502s	
25516/33650 (epoch 37.914), train_loss = 0.85340021, grad/param norm = 1.5429e-01, time/batch = 16.7912s	
25517/33650 (epoch 37.915), train_loss = 0.80035504, grad/param norm = 1.8310e-01, time/batch = 17.8964s	
25518/33650 (epoch 37.917), train_loss = 0.79563165, grad/param norm = 1.6474e-01, time/batch = 17.2261s	
25519/33650 (epoch 37.918), train_loss = 0.74037652, grad/param norm = 1.4978e-01, time/batch = 18.4813s	
25520/33650 (epoch 37.920), train_loss = 0.74858918, grad/param norm = 1.5598e-01, time/batch = 18.7251s	
25521/33650 (epoch 37.921), train_loss = 0.73499030, grad/param norm = 1.5225e-01, time/batch = 16.8840s	
25522/33650 (epoch 37.923), train_loss = 0.65466721, grad/param norm = 1.3576e-01, time/batch = 18.6218s	
25523/33650 (epoch 37.924), train_loss = 0.84193536, grad/param norm = 1.6427e-01, time/batch = 18.4714s	
25524/33650 (epoch 37.926), train_loss = 0.77392781, grad/param norm = 1.7268e-01, time/batch = 17.8030s	
25525/33650 (epoch 37.927), train_loss = 0.80790730, grad/param norm = 1.5707e-01, time/batch = 17.4792s	
25526/33650 (epoch 37.929), train_loss = 0.90238604, grad/param norm = 1.8638e-01, time/batch = 18.1455s	
25527/33650 (epoch 37.930), train_loss = 0.80625680, grad/param norm = 1.8133e-01, time/batch = 17.6409s	
25528/33650 (epoch 37.932), train_loss = 0.82805083, grad/param norm = 1.7328e-01, time/batch = 18.3854s	
25529/33650 (epoch 37.933), train_loss = 0.68114603, grad/param norm = 1.5853e-01, time/batch = 17.2378s	
25530/33650 (epoch 37.935), train_loss = 0.70201698, grad/param norm = 1.7709e-01, time/batch = 17.9730s	
25531/33650 (epoch 37.936), train_loss = 0.75644167, grad/param norm = 1.4145e-01, time/batch = 17.8001s	
25532/33650 (epoch 37.938), train_loss = 0.70659422, grad/param norm = 1.4362e-01, time/batch = 17.8914s	
25533/33650 (epoch 37.939), train_loss = 0.88863738, grad/param norm = 1.4875e-01, time/batch = 17.5609s	
25534/33650 (epoch 37.941), train_loss = 0.81184692, grad/param norm = 1.8895e-01, time/batch = 16.3862s	
25535/33650 (epoch 37.942), train_loss = 0.88733396, grad/param norm = 1.8096e-01, time/batch = 18.4649s	
25536/33650 (epoch 37.944), train_loss = 0.77375161, grad/param norm = 1.4295e-01, time/batch = 17.5564s	
25537/33650 (epoch 37.945), train_loss = 0.82770311, grad/param norm = 1.7438e-01, time/batch = 18.2181s	
25538/33650 (epoch 37.947), train_loss = 0.94325453, grad/param norm = 2.8518e-01, time/batch = 17.5557s	
25539/33650 (epoch 37.948), train_loss = 0.92190438, grad/param norm = 1.6092e-01, time/batch = 17.4534s	
25540/33650 (epoch 37.949), train_loss = 0.71940323, grad/param norm = 1.6050e-01, time/batch = 17.1387s	
25541/33650 (epoch 37.951), train_loss = 0.96358397, grad/param norm = 1.7576e-01, time/batch = 17.1332s	
25542/33650 (epoch 37.952), train_loss = 0.85711609, grad/param norm = 1.6400e-01, time/batch = 18.2957s	
25543/33650 (epoch 37.954), train_loss = 0.85371390, grad/param norm = 1.6694e-01, time/batch = 15.7272s	
25544/33650 (epoch 37.955), train_loss = 0.84540524, grad/param norm = 1.7854e-01, time/batch = 17.7207s	
25545/33650 (epoch 37.957), train_loss = 0.87878070, grad/param norm = 1.9429e-01, time/batch = 17.5615s	
25546/33650 (epoch 37.958), train_loss = 0.65037897, grad/param norm = 1.3496e-01, time/batch = 16.8901s	
25547/33650 (epoch 37.960), train_loss = 0.68823667, grad/param norm = 1.5846e-01, time/batch = 17.8871s	
25548/33650 (epoch 37.961), train_loss = 0.73495350, grad/param norm = 1.6396e-01, time/batch = 17.5514s	
25549/33650 (epoch 37.963), train_loss = 0.74672245, grad/param norm = 1.6728e-01, time/batch = 18.2375s	
25550/33650 (epoch 37.964), train_loss = 0.91241095, grad/param norm = 1.7353e-01, time/batch = 17.5495s	
25551/33650 (epoch 37.966), train_loss = 0.85480528, grad/param norm = 1.9469e-01, time/batch = 16.8925s	
25552/33650 (epoch 37.967), train_loss = 0.84657997, grad/param norm = 1.6091e-01, time/batch = 17.4719s	
25553/33650 (epoch 37.969), train_loss = 0.81372443, grad/param norm = 1.6548e-01, time/batch = 18.6527s	
25554/33650 (epoch 37.970), train_loss = 0.84038441, grad/param norm = 1.8525e-01, time/batch = 18.2192s	
25555/33650 (epoch 37.972), train_loss = 1.09932365, grad/param norm = 1.9303e-01, time/batch = 17.1775s	
25556/33650 (epoch 37.973), train_loss = 0.75816163, grad/param norm = 1.4621e-01, time/batch = 18.4812s	
25557/33650 (epoch 37.975), train_loss = 0.71741449, grad/param norm = 1.3624e-01, time/batch = 17.7989s	
25558/33650 (epoch 37.976), train_loss = 0.74979851, grad/param norm = 1.4060e-01, time/batch = 16.9778s	
25559/33650 (epoch 37.978), train_loss = 0.76001738, grad/param norm = 1.6792e-01, time/batch = 18.5536s	
25560/33650 (epoch 37.979), train_loss = 0.82113797, grad/param norm = 1.7949e-01, time/batch = 15.7169s	
25561/33650 (epoch 37.981), train_loss = 0.79501710, grad/param norm = 1.5163e-01, time/batch = 18.1374s	
25562/33650 (epoch 37.982), train_loss = 0.81067143, grad/param norm = 1.6729e-01, time/batch = 17.3926s	
25563/33650 (epoch 37.984), train_loss = 0.67368080, grad/param norm = 1.4153e-01, time/batch = 18.0497s	
25564/33650 (epoch 37.985), train_loss = 0.72791255, grad/param norm = 1.5017e-01, time/batch = 17.7220s	
25565/33650 (epoch 37.987), train_loss = 0.84015163, grad/param norm = 1.5775e-01, time/batch = 17.2088s	
25566/33650 (epoch 37.988), train_loss = 0.76914660, grad/param norm = 1.7755e-01, time/batch = 15.4605s	
25567/33650 (epoch 37.990), train_loss = 0.96741394, grad/param norm = 2.0286e-01, time/batch = 13.6782s	
25568/33650 (epoch 37.991), train_loss = 0.82443490, grad/param norm = 1.5602e-01, time/batch = 13.6631s	
25569/33650 (epoch 37.993), train_loss = 0.83180189, grad/param norm = 1.7187e-01, time/batch = 15.6804s	
25570/33650 (epoch 37.994), train_loss = 0.84173731, grad/param norm = 1.6142e-01, time/batch = 19.3005s	
25571/33650 (epoch 37.996), train_loss = 0.81256893, grad/param norm = 1.7235e-01, time/batch = 18.3981s	
25572/33650 (epoch 37.997), train_loss = 0.89791298, grad/param norm = 1.8466e-01, time/batch = 17.8833s	
25573/33650 (epoch 37.999), train_loss = 0.75250823, grad/param norm = 1.5564e-01, time/batch = 17.2220s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
25574/33650 (epoch 38.000), train_loss = 0.91860431, grad/param norm = 1.9100e-01, time/batch = 18.7225s	
25575/33650 (epoch 38.001), train_loss = 0.94065011, grad/param norm = 1.6488e-01, time/batch = 16.5414s	
25576/33650 (epoch 38.003), train_loss = 0.94338337, grad/param norm = 2.1158e-01, time/batch = 17.6273s	
25577/33650 (epoch 38.004), train_loss = 0.84638422, grad/param norm = 1.7252e-01, time/batch = 18.5696s	
25578/33650 (epoch 38.006), train_loss = 0.80550180, grad/param norm = 1.6594e-01, time/batch = 17.3169s	
25579/33650 (epoch 38.007), train_loss = 0.86253690, grad/param norm = 2.2113e-01, time/batch = 16.1221s	
25580/33650 (epoch 38.009), train_loss = 0.75698663, grad/param norm = 1.7634e-01, time/batch = 18.4727s	
25581/33650 (epoch 38.010), train_loss = 0.92013492, grad/param norm = 1.8721e-01, time/batch = 17.3187s	
25582/33650 (epoch 38.012), train_loss = 0.80407399, grad/param norm = 1.7035e-01, time/batch = 17.3809s	
25583/33650 (epoch 38.013), train_loss = 0.83922084, grad/param norm = 2.1746e-01, time/batch = 17.3980s	
25584/33650 (epoch 38.015), train_loss = 0.81614451, grad/param norm = 1.8260e-01, time/batch = 18.2366s	
25585/33650 (epoch 38.016), train_loss = 0.76596775, grad/param norm = 2.0189e-01, time/batch = 17.0722s	
25586/33650 (epoch 38.018), train_loss = 0.80030495, grad/param norm = 1.9459e-01, time/batch = 17.8051s	
25587/33650 (epoch 38.019), train_loss = 0.78605931, grad/param norm = 2.0880e-01, time/batch = 18.6311s	
25588/33650 (epoch 38.021), train_loss = 0.87745244, grad/param norm = 1.6485e-01, time/batch = 18.7283s	
25589/33650 (epoch 38.022), train_loss = 0.81057085, grad/param norm = 1.6352e-01, time/batch = 16.1226s	
25590/33650 (epoch 38.024), train_loss = 0.74483329, grad/param norm = 1.6876e-01, time/batch = 18.3061s	
25591/33650 (epoch 38.025), train_loss = 0.83872576, grad/param norm = 1.7331e-01, time/batch = 18.3127s	
25592/33650 (epoch 38.027), train_loss = 0.84582356, grad/param norm = 1.7867e-01, time/batch = 16.7034s	
25593/33650 (epoch 38.028), train_loss = 0.88990450, grad/param norm = 1.7511e-01, time/batch = 17.8933s	
25594/33650 (epoch 38.030), train_loss = 0.82209510, grad/param norm = 1.8508e-01, time/batch = 18.8894s	
25595/33650 (epoch 38.031), train_loss = 0.76539025, grad/param norm = 1.5028e-01, time/batch = 17.2968s	
25596/33650 (epoch 38.033), train_loss = 0.85809344, grad/param norm = 1.5896e-01, time/batch = 17.0607s	
25597/33650 (epoch 38.034), train_loss = 0.86680546, grad/param norm = 1.7822e-01, time/batch = 17.8143s	
25598/33650 (epoch 38.036), train_loss = 0.92065020, grad/param norm = 1.7631e-01, time/batch = 18.7293s	
25599/33650 (epoch 38.037), train_loss = 0.78427579, grad/param norm = 1.4666e-01, time/batch = 16.9680s	
25600/33650 (epoch 38.039), train_loss = 0.91490370, grad/param norm = 1.7272e-01, time/batch = 17.4119s	
25601/33650 (epoch 38.040), train_loss = 1.01370530, grad/param norm = 2.0752e-01, time/batch = 16.4817s	
25602/33650 (epoch 38.042), train_loss = 0.99559622, grad/param norm = 2.0248e-01, time/batch = 16.9754s	
25603/33650 (epoch 38.043), train_loss = 0.80794077, grad/param norm = 1.6132e-01, time/batch = 18.7203s	
25604/33650 (epoch 38.045), train_loss = 0.77560867, grad/param norm = 1.6141e-01, time/batch = 18.1487s	
25605/33650 (epoch 38.046), train_loss = 0.89689184, grad/param norm = 2.0210e-01, time/batch = 17.9703s	
25606/33650 (epoch 38.048), train_loss = 0.91243381, grad/param norm = 1.7371e-01, time/batch = 15.6282s	
25607/33650 (epoch 38.049), train_loss = 0.78112556, grad/param norm = 1.6758e-01, time/batch = 18.1441s	
25608/33650 (epoch 38.051), train_loss = 0.96794182, grad/param norm = 2.1373e-01, time/batch = 18.5650s	
25609/33650 (epoch 38.052), train_loss = 0.94307424, grad/param norm = 1.8138e-01, time/batch = 17.3798s	
25610/33650 (epoch 38.053), train_loss = 0.90668827, grad/param norm = 1.7448e-01, time/batch = 16.1255s	
25611/33650 (epoch 38.055), train_loss = 0.80199665, grad/param norm = 1.7189e-01, time/batch = 17.5558s	
25612/33650 (epoch 38.056), train_loss = 0.73256242, grad/param norm = 1.5062e-01, time/batch = 17.9739s	
25613/33650 (epoch 38.058), train_loss = 0.91797733, grad/param norm = 1.8893e-01, time/batch = 17.6415s	
25614/33650 (epoch 38.059), train_loss = 0.92691419, grad/param norm = 1.8038e-01, time/batch = 15.4974s	
25615/33650 (epoch 38.061), train_loss = 0.91915724, grad/param norm = 1.8278e-01, time/batch = 15.3070s	
25616/33650 (epoch 38.062), train_loss = 0.89001536, grad/param norm = 1.5960e-01, time/batch = 16.2227s	
25617/33650 (epoch 38.064), train_loss = 0.82721018, grad/param norm = 1.8816e-01, time/batch = 18.3177s	
25618/33650 (epoch 38.065), train_loss = 0.80662247, grad/param norm = 1.6738e-01, time/batch = 18.7324s	
25619/33650 (epoch 38.067), train_loss = 0.76856166, grad/param norm = 1.4718e-01, time/batch = 17.7983s	
25620/33650 (epoch 38.068), train_loss = 0.84840709, grad/param norm = 1.6975e-01, time/batch = 16.6418s	
25621/33650 (epoch 38.070), train_loss = 0.89516735, grad/param norm = 1.7637e-01, time/batch = 16.2120s	
25622/33650 (epoch 38.071), train_loss = 0.78648055, grad/param norm = 1.7453e-01, time/batch = 18.1473s	
25623/33650 (epoch 38.073), train_loss = 0.87707366, grad/param norm = 2.0267e-01, time/batch = 17.4632s	
25624/33650 (epoch 38.074), train_loss = 0.95707937, grad/param norm = 1.6745e-01, time/batch = 17.2998s	
25625/33650 (epoch 38.076), train_loss = 0.91609479, grad/param norm = 2.0595e-01, time/batch = 18.1506s	
25626/33650 (epoch 38.077), train_loss = 0.81044203, grad/param norm = 1.5013e-01, time/batch = 17.9762s	
25627/33650 (epoch 38.079), train_loss = 0.87204638, grad/param norm = 1.7212e-01, time/batch = 17.7148s	
25628/33650 (epoch 38.080), train_loss = 0.87181015, grad/param norm = 1.7118e-01, time/batch = 16.8763s	
25629/33650 (epoch 38.082), train_loss = 0.84555109, grad/param norm = 1.5025e-01, time/batch = 18.1506s	
25630/33650 (epoch 38.083), train_loss = 0.88085295, grad/param norm = 2.0463e-01, time/batch = 15.7139s	
25631/33650 (epoch 38.085), train_loss = 0.92901361, grad/param norm = 1.6276e-01, time/batch = 18.7168s	
25632/33650 (epoch 38.086), train_loss = 0.86633751, grad/param norm = 1.6863e-01, time/batch = 18.9027s	
25633/33650 (epoch 38.088), train_loss = 0.82771998, grad/param norm = 1.6205e-01, time/batch = 16.8945s	
25634/33650 (epoch 38.089), train_loss = 0.78112283, grad/param norm = 1.6660e-01, time/batch = 17.5548s	
25635/33650 (epoch 38.091), train_loss = 0.82624214, grad/param norm = 1.5303e-01, time/batch = 17.9011s	
25636/33650 (epoch 38.092), train_loss = 0.84598742, grad/param norm = 1.9702e-01, time/batch = 18.3877s	
25637/33650 (epoch 38.094), train_loss = 0.90779656, grad/param norm = 1.5855e-01, time/batch = 17.3057s	
25638/33650 (epoch 38.095), train_loss = 0.88453779, grad/param norm = 1.9348e-01, time/batch = 18.5612s	
25639/33650 (epoch 38.097), train_loss = 0.79986186, grad/param norm = 1.7203e-01, time/batch = 18.6431s	
25640/33650 (epoch 38.098), train_loss = 0.67901217, grad/param norm = 1.7061e-01, time/batch = 15.8863s	
25641/33650 (epoch 38.100), train_loss = 0.77804329, grad/param norm = 1.7152e-01, time/batch = 17.6280s	
25642/33650 (epoch 38.101), train_loss = 0.85791983, grad/param norm = 1.8068e-01, time/batch = 17.9771s	
25643/33650 (epoch 38.103), train_loss = 0.83006320, grad/param norm = 1.8142e-01, time/batch = 17.6367s	
25644/33650 (epoch 38.104), train_loss = 0.97094477, grad/param norm = 1.6350e-01, time/batch = 17.9745s	
25645/33650 (epoch 38.105), train_loss = 0.88089462, grad/param norm = 1.7828e-01, time/batch = 16.2024s	
25646/33650 (epoch 38.107), train_loss = 0.79195086, grad/param norm = 1.6185e-01, time/batch = 18.9788s	
25647/33650 (epoch 38.108), train_loss = 0.88730740, grad/param norm = 1.8205e-01, time/batch = 16.6231s	
25648/33650 (epoch 38.110), train_loss = 0.96817207, grad/param norm = 1.6007e-01, time/batch = 18.4739s	
25649/33650 (epoch 38.111), train_loss = 0.84177473, grad/param norm = 1.9251e-01, time/batch = 18.3981s	
25650/33650 (epoch 38.113), train_loss = 0.79536509, grad/param norm = 1.7643e-01, time/batch = 16.4764s	
25651/33650 (epoch 38.114), train_loss = 0.92143328, grad/param norm = 1.6250e-01, time/batch = 18.4772s	
25652/33650 (epoch 38.116), train_loss = 0.78961295, grad/param norm = 1.4974e-01, time/batch = 18.7142s	
25653/33650 (epoch 38.117), train_loss = 0.84369945, grad/param norm = 1.5757e-01, time/batch = 17.7201s	
25654/33650 (epoch 38.119), train_loss = 0.76006268, grad/param norm = 1.4100e-01, time/batch = 17.0572s	
25655/33650 (epoch 38.120), train_loss = 0.77992126, grad/param norm = 1.9905e-01, time/batch = 18.2270s	
25656/33650 (epoch 38.122), train_loss = 0.65464976, grad/param norm = 1.4827e-01, time/batch = 18.0564s	
25657/33650 (epoch 38.123), train_loss = 0.77520141, grad/param norm = 1.5775e-01, time/batch = 16.1088s	
25658/33650 (epoch 38.125), train_loss = 0.88312951, grad/param norm = 1.7544e-01, time/batch = 17.5506s	
25659/33650 (epoch 38.126), train_loss = 0.92610583, grad/param norm = 2.5248e-01, time/batch = 17.8916s	
25660/33650 (epoch 38.128), train_loss = 0.87804350, grad/param norm = 1.8559e-01, time/batch = 16.9795s	
25661/33650 (epoch 38.129), train_loss = 0.90533229, grad/param norm = 1.8880e-01, time/batch = 18.1444s	
25662/33650 (epoch 38.131), train_loss = 0.85146122, grad/param norm = 1.8363e-01, time/batch = 17.8971s	
25663/33650 (epoch 38.132), train_loss = 0.85278437, grad/param norm = 1.5749e-01, time/batch = 17.8150s	
25664/33650 (epoch 38.134), train_loss = 0.92157051, grad/param norm = 2.3613e-01, time/batch = 17.3915s	
25665/33650 (epoch 38.135), train_loss = 0.72806356, grad/param norm = 1.3937e-01, time/batch = 18.1445s	
25666/33650 (epoch 38.137), train_loss = 0.88759098, grad/param norm = 2.3878e-01, time/batch = 18.8941s	
25667/33650 (epoch 38.138), train_loss = 0.88816072, grad/param norm = 1.5681e-01, time/batch = 15.8758s	
25668/33650 (epoch 38.140), train_loss = 0.85508067, grad/param norm = 1.7266e-01, time/batch = 18.3190s	
25669/33650 (epoch 38.141), train_loss = 0.95021593, grad/param norm = 1.6145e-01, time/batch = 17.2900s	
25670/33650 (epoch 38.143), train_loss = 0.98372358, grad/param norm = 2.0271e-01, time/batch = 18.3073s	
25671/33650 (epoch 38.144), train_loss = 0.89075767, grad/param norm = 1.8100e-01, time/batch = 17.8919s	
25672/33650 (epoch 38.146), train_loss = 0.84754119, grad/param norm = 1.7074e-01, time/batch = 17.8064s	
25673/33650 (epoch 38.147), train_loss = 0.77002286, grad/param norm = 1.5834e-01, time/batch = 18.8908s	
25674/33650 (epoch 38.149), train_loss = 0.76785054, grad/param norm = 1.6367e-01, time/batch = 17.9673s	
25675/33650 (epoch 38.150), train_loss = 0.73103860, grad/param norm = 1.4162e-01, time/batch = 17.8066s	
25676/33650 (epoch 38.152), train_loss = 0.79338337, grad/param norm = 2.0085e-01, time/batch = 16.3871s	
25677/33650 (epoch 38.153), train_loss = 0.81609394, grad/param norm = 1.9287e-01, time/batch = 16.8103s	
25678/33650 (epoch 38.155), train_loss = 0.78829381, grad/param norm = 1.5145e-01, time/batch = 18.3194s	
25679/33650 (epoch 38.156), train_loss = 0.74820131, grad/param norm = 1.3703e-01, time/batch = 18.7214s	
25680/33650 (epoch 38.158), train_loss = 0.87943550, grad/param norm = 1.7203e-01, time/batch = 18.3124s	
25681/33650 (epoch 38.159), train_loss = 0.77799903, grad/param norm = 1.4535e-01, time/batch = 16.6500s	
25682/33650 (epoch 38.160), train_loss = 0.78379858, grad/param norm = 1.4682e-01, time/batch = 18.3922s	
25683/33650 (epoch 38.162), train_loss = 0.81300951, grad/param norm = 2.0207e-01, time/batch = 18.5557s	
25684/33650 (epoch 38.163), train_loss = 0.88786750, grad/param norm = 2.1123e-01, time/batch = 17.0552s	
25685/33650 (epoch 38.165), train_loss = 0.75081907, grad/param norm = 1.9257e-01, time/batch = 18.4547s	
25686/33650 (epoch 38.166), train_loss = 0.74166204, grad/param norm = 1.5828e-01, time/batch = 16.9647s	
25687/33650 (epoch 38.168), train_loss = 0.93970545, grad/param norm = 1.7802e-01, time/batch = 17.2073s	
25688/33650 (epoch 38.169), train_loss = 0.81540751, grad/param norm = 1.8591e-01, time/batch = 17.8020s	
25689/33650 (epoch 38.171), train_loss = 0.81698627, grad/param norm = 1.5106e-01, time/batch = 17.8905s	
25690/33650 (epoch 38.172), train_loss = 0.78384460, grad/param norm = 1.4969e-01, time/batch = 18.5569s	
25691/33650 (epoch 38.174), train_loss = 0.77799283, grad/param norm = 2.0018e-01, time/batch = 17.2959s	
25692/33650 (epoch 38.175), train_loss = 0.71642859, grad/param norm = 1.9492e-01, time/batch = 17.8041s	
25693/33650 (epoch 38.177), train_loss = 0.84846672, grad/param norm = 1.8854e-01, time/batch = 18.4837s	
25694/33650 (epoch 38.178), train_loss = 0.81608727, grad/param norm = 2.0303e-01, time/batch = 16.8723s	
25695/33650 (epoch 38.180), train_loss = 0.74578471, grad/param norm = 1.4676e-01, time/batch = 18.8064s	
25696/33650 (epoch 38.181), train_loss = 0.67412933, grad/param norm = 1.4579e-01, time/batch = 18.3064s	
25697/33650 (epoch 38.183), train_loss = 0.76068299, grad/param norm = 1.6099e-01, time/batch = 17.6451s	
25698/33650 (epoch 38.184), train_loss = 0.76333826, grad/param norm = 1.9269e-01, time/batch = 17.9814s	
25699/33650 (epoch 38.186), train_loss = 0.79955492, grad/param norm = 1.9739e-01, time/batch = 17.6558s	
25700/33650 (epoch 38.187), train_loss = 0.91986261, grad/param norm = 1.8497e-01, time/batch = 16.9956s	
25701/33650 (epoch 38.189), train_loss = 0.94206480, grad/param norm = 2.1381e-01, time/batch = 17.7192s	
25702/33650 (epoch 38.190), train_loss = 0.88564245, grad/param norm = 2.2167e-01, time/batch = 18.1501s	
25703/33650 (epoch 38.192), train_loss = 0.99826885, grad/param norm = 1.6790e-01, time/batch = 17.3853s	
25704/33650 (epoch 38.193), train_loss = 0.96346725, grad/param norm = 1.6317e-01, time/batch = 15.8675s	
25705/33650 (epoch 38.195), train_loss = 0.72926914, grad/param norm = 1.5826e-01, time/batch = 18.9608s	
25706/33650 (epoch 38.196), train_loss = 0.68855261, grad/param norm = 1.5581e-01, time/batch = 18.1382s	
25707/33650 (epoch 38.198), train_loss = 0.83602697, grad/param norm = 1.7021e-01, time/batch = 21.0995s	
25708/33650 (epoch 38.199), train_loss = 0.89845606, grad/param norm = 1.9132e-01, time/batch = 29.4298s	
25709/33650 (epoch 38.201), train_loss = 0.79026208, grad/param norm = 1.7928e-01, time/batch = 18.1362s	
25710/33650 (epoch 38.202), train_loss = 0.80973652, grad/param norm = 1.6475e-01, time/batch = 16.2980s	
25711/33650 (epoch 38.204), train_loss = 0.86404387, grad/param norm = 1.4831e-01, time/batch = 17.6110s	
25712/33650 (epoch 38.205), train_loss = 0.82454348, grad/param norm = 1.6971e-01, time/batch = 18.8167s	
25713/33650 (epoch 38.207), train_loss = 0.78827331, grad/param norm = 1.9159e-01, time/batch = 17.9672s	
25714/33650 (epoch 38.208), train_loss = 0.87749349, grad/param norm = 1.8630e-01, time/batch = 16.9748s	
25715/33650 (epoch 38.210), train_loss = 0.67848120, grad/param norm = 1.4919e-01, time/batch = 18.1342s	
25716/33650 (epoch 38.211), train_loss = 0.76526166, grad/param norm = 1.8288e-01, time/batch = 17.3979s	
25717/33650 (epoch 38.212), train_loss = 0.86224986, grad/param norm = 2.0425e-01, time/batch = 17.3058s	
25718/33650 (epoch 38.214), train_loss = 0.99692113, grad/param norm = 1.7461e-01, time/batch = 18.1543s	
25719/33650 (epoch 38.215), train_loss = 0.66981716, grad/param norm = 1.5343e-01, time/batch = 18.2291s	
25720/33650 (epoch 38.217), train_loss = 0.80141601, grad/param norm = 2.1306e-01, time/batch = 16.9634s	
25721/33650 (epoch 38.218), train_loss = 0.80102222, grad/param norm = 1.4616e-01, time/batch = 18.8119s	
25722/33650 (epoch 38.220), train_loss = 0.70629064, grad/param norm = 1.8750e-01, time/batch = 17.6498s	
25723/33650 (epoch 38.221), train_loss = 0.98186384, grad/param norm = 1.8839e-01, time/batch = 17.4692s	
25724/33650 (epoch 38.223), train_loss = 0.67477574, grad/param norm = 1.5393e-01, time/batch = 17.5627s	
25725/33650 (epoch 38.224), train_loss = 0.80883816, grad/param norm = 2.1152e-01, time/batch = 18.7190s	
25726/33650 (epoch 38.226), train_loss = 1.07320418, grad/param norm = 2.0054e-01, time/batch = 17.0630s	
25727/33650 (epoch 38.227), train_loss = 0.91124142, grad/param norm = 1.8154e-01, time/batch = 17.0556s	
25728/33650 (epoch 38.229), train_loss = 0.93319265, grad/param norm = 1.9676e-01, time/batch = 19.0622s	
25729/33650 (epoch 38.230), train_loss = 1.05320198, grad/param norm = 1.8611e-01, time/batch = 17.4892s	
25730/33650 (epoch 38.232), train_loss = 0.89523631, grad/param norm = 2.5903e-01, time/batch = 16.2766s	
25731/33650 (epoch 38.233), train_loss = 0.86024201, grad/param norm = 1.9003e-01, time/batch = 18.1446s	
25732/33650 (epoch 38.235), train_loss = 0.83509539, grad/param norm = 1.8101e-01, time/batch = 17.8177s	
25733/33650 (epoch 38.236), train_loss = 0.77924946, grad/param norm = 1.4234e-01, time/batch = 16.8998s	
25734/33650 (epoch 38.238), train_loss = 0.79447472, grad/param norm = 1.5714e-01, time/batch = 18.6448s	
25735/33650 (epoch 38.239), train_loss = 0.76613046, grad/param norm = 1.7332e-01, time/batch = 17.9018s	
25736/33650 (epoch 38.241), train_loss = 0.81868530, grad/param norm = 1.5153e-01, time/batch = 17.6224s	
25737/33650 (epoch 38.242), train_loss = 0.66194194, grad/param norm = 1.5387e-01, time/batch = 17.6276s	
25738/33650 (epoch 38.244), train_loss = 0.80549483, grad/param norm = 1.5810e-01, time/batch = 18.0671s	
25739/33650 (epoch 38.245), train_loss = 0.72499739, grad/param norm = 1.4315e-01, time/batch = 18.2367s	
25740/33650 (epoch 38.247), train_loss = 0.78525391, grad/param norm = 1.4251e-01, time/batch = 16.8903s	
25741/33650 (epoch 38.248), train_loss = 0.73572022, grad/param norm = 1.6661e-01, time/batch = 18.2425s	
25742/33650 (epoch 38.250), train_loss = 0.82334455, grad/param norm = 1.6854e-01, time/batch = 17.1299s	
25743/33650 (epoch 38.251), train_loss = 0.91700995, grad/param norm = 1.7635e-01, time/batch = 17.8131s	
25744/33650 (epoch 38.253), train_loss = 0.71298798, grad/param norm = 1.4280e-01, time/batch = 17.5546s	
25745/33650 (epoch 38.254), train_loss = 0.80505095, grad/param norm = 1.7383e-01, time/batch = 19.0709s	
25746/33650 (epoch 38.256), train_loss = 0.93454234, grad/param norm = 1.5497e-01, time/batch = 17.7222s	
25747/33650 (epoch 38.257), train_loss = 0.88595110, grad/param norm = 1.6114e-01, time/batch = 17.2120s	
25748/33650 (epoch 38.259), train_loss = 0.77212415, grad/param norm = 1.6149e-01, time/batch = 18.3816s	
25749/33650 (epoch 38.260), train_loss = 0.84927658, grad/param norm = 1.6492e-01, time/batch = 17.8911s	
25750/33650 (epoch 38.262), train_loss = 0.84309938, grad/param norm = 1.8375e-01, time/batch = 16.2804s	
25751/33650 (epoch 38.263), train_loss = 0.82098936, grad/param norm = 2.1282e-01, time/batch = 17.7161s	
25752/33650 (epoch 38.264), train_loss = 0.90934255, grad/param norm = 1.9969e-01, time/batch = 19.0661s	
25753/33650 (epoch 38.266), train_loss = 0.87652657, grad/param norm = 1.7156e-01, time/batch = 16.4592s	
25754/33650 (epoch 38.267), train_loss = 0.79977508, grad/param norm = 1.6191e-01, time/batch = 17.6336s	
25755/33650 (epoch 38.269), train_loss = 0.81939775, grad/param norm = 1.5933e-01, time/batch = 17.4868s	
25756/33650 (epoch 38.270), train_loss = 0.75140082, grad/param norm = 1.6604e-01, time/batch = 18.8231s	
25757/33650 (epoch 38.272), train_loss = 0.78727030, grad/param norm = 1.6105e-01, time/batch = 16.8993s	
25758/33650 (epoch 38.273), train_loss = 0.90264768, grad/param norm = 1.7924e-01, time/batch = 18.0611s	
25759/33650 (epoch 38.275), train_loss = 0.88225460, grad/param norm = 1.7466e-01, time/batch = 17.9004s	
25760/33650 (epoch 38.276), train_loss = 0.90098907, grad/param norm = 2.0073e-01, time/batch = 17.0707s	
25761/33650 (epoch 38.278), train_loss = 1.00250843, grad/param norm = 2.0252e-01, time/batch = 17.6259s	
25762/33650 (epoch 38.279), train_loss = 0.81786535, grad/param norm = 1.7529e-01, time/batch = 18.2252s	
25763/33650 (epoch 38.281), train_loss = 0.85319177, grad/param norm = 1.8202e-01, time/batch = 18.1482s	
25764/33650 (epoch 38.282), train_loss = 0.93004513, grad/param norm = 1.4342e-01, time/batch = 17.7978s	
25765/33650 (epoch 38.284), train_loss = 0.88385244, grad/param norm = 1.9127e-01, time/batch = 17.2206s	
25766/33650 (epoch 38.285), train_loss = 0.86923462, grad/param norm = 1.8448e-01, time/batch = 18.7293s	
25767/33650 (epoch 38.287), train_loss = 0.79830662, grad/param norm = 1.6054e-01, time/batch = 16.6414s	
25768/33650 (epoch 38.288), train_loss = 0.81346677, grad/param norm = 2.3991e-01, time/batch = 15.7043s	
25769/33650 (epoch 38.290), train_loss = 0.81849170, grad/param norm = 1.6352e-01, time/batch = 18.1452s	
25770/33650 (epoch 38.291), train_loss = 0.77622223, grad/param norm = 1.7723e-01, time/batch = 17.2202s	
25771/33650 (epoch 38.293), train_loss = 0.84496968, grad/param norm = 1.8162e-01, time/batch = 18.1361s	
25772/33650 (epoch 38.294), train_loss = 0.78249240, grad/param norm = 1.5135e-01, time/batch = 18.3957s	
25773/33650 (epoch 38.296), train_loss = 0.73242837, grad/param norm = 1.7219e-01, time/batch = 18.4841s	
25774/33650 (epoch 38.297), train_loss = 0.80641238, grad/param norm = 1.6629e-01, time/batch = 17.2997s	
25775/33650 (epoch 38.299), train_loss = 0.72080619, grad/param norm = 1.7145e-01, time/batch = 18.0719s	
25776/33650 (epoch 38.300), train_loss = 0.74531843, grad/param norm = 1.7817e-01, time/batch = 18.8204s	
25777/33650 (epoch 38.302), train_loss = 0.83701588, grad/param norm = 1.6385e-01, time/batch = 16.3877s	
25778/33650 (epoch 38.303), train_loss = 0.84776223, grad/param norm = 1.4561e-01, time/batch = 17.6540s	
25779/33650 (epoch 38.305), train_loss = 0.81965397, grad/param norm = 1.5755e-01, time/batch = 17.9794s	
25780/33650 (epoch 38.306), train_loss = 0.75699740, grad/param norm = 1.4003e-01, time/batch = 18.2097s	
25781/33650 (epoch 38.308), train_loss = 0.70864027, grad/param norm = 1.5911e-01, time/batch = 17.4780s	
25782/33650 (epoch 38.309), train_loss = 0.93480658, grad/param norm = 1.8140e-01, time/batch = 18.4764s	
25783/33650 (epoch 38.311), train_loss = 0.82206092, grad/param norm = 1.9029e-01, time/batch = 17.6556s	
25784/33650 (epoch 38.312), train_loss = 0.87092864, grad/param norm = 1.7921e-01, time/batch = 17.0518s	
25785/33650 (epoch 38.314), train_loss = 0.78348527, grad/param norm = 1.5400e-01, time/batch = 16.7883s	
25786/33650 (epoch 38.315), train_loss = 0.78629618, grad/param norm = 1.8329e-01, time/batch = 17.8928s	
25787/33650 (epoch 38.316), train_loss = 0.79744975, grad/param norm = 2.0589e-01, time/batch = 15.9555s	
25788/33650 (epoch 38.318), train_loss = 0.72887053, grad/param norm = 1.7110e-01, time/batch = 18.1499s	
25789/33650 (epoch 38.319), train_loss = 0.76218269, grad/param norm = 1.4497e-01, time/batch = 18.3162s	
25790/33650 (epoch 38.321), train_loss = 0.80571272, grad/param norm = 1.6147e-01, time/batch = 18.5665s	
25791/33650 (epoch 38.322), train_loss = 0.84273352, grad/param norm = 2.2549e-01, time/batch = 17.7131s	
25792/33650 (epoch 38.324), train_loss = 0.87152369, grad/param norm = 2.3421e-01, time/batch = 18.0610s	
25793/33650 (epoch 38.325), train_loss = 0.86660362, grad/param norm = 2.1870e-01, time/batch = 18.8991s	
25794/33650 (epoch 38.327), train_loss = 0.76854283, grad/param norm = 1.5354e-01, time/batch = 17.1376s	
25795/33650 (epoch 38.328), train_loss = 0.84216274, grad/param norm = 1.6365e-01, time/batch = 18.8931s	
25796/33650 (epoch 38.330), train_loss = 0.76314101, grad/param norm = 1.4710e-01, time/batch = 18.4810s	
25797/33650 (epoch 38.331), train_loss = 0.71476010, grad/param norm = 1.4417e-01, time/batch = 16.8731s	
25798/33650 (epoch 38.333), train_loss = 0.79295913, grad/param norm = 1.6441e-01, time/batch = 15.8073s	
25799/33650 (epoch 38.334), train_loss = 0.81002069, grad/param norm = 1.5762e-01, time/batch = 18.3108s	
25800/33650 (epoch 38.336), train_loss = 0.91556380, grad/param norm = 1.7044e-01, time/batch = 18.0639s	
25801/33650 (epoch 38.337), train_loss = 0.70945951, grad/param norm = 1.4653e-01, time/batch = 17.1361s	
25802/33650 (epoch 38.339), train_loss = 0.79385813, grad/param norm = 1.6969e-01, time/batch = 18.1401s	
25803/33650 (epoch 38.340), train_loss = 0.87707649, grad/param norm = 1.7548e-01, time/batch = 18.5523s	
25804/33650 (epoch 38.342), train_loss = 0.68005558, grad/param norm = 1.4917e-01, time/batch = 17.0568s	
25805/33650 (epoch 38.343), train_loss = 0.86947722, grad/param norm = 1.7399e-01, time/batch = 18.5680s	
25806/33650 (epoch 38.345), train_loss = 0.86494238, grad/param norm = 1.7875e-01, time/batch = 17.8190s	
25807/33650 (epoch 38.346), train_loss = 0.59565522, grad/param norm = 1.8267e-01, time/batch = 16.8151s	
25808/33650 (epoch 38.348), train_loss = 0.71635872, grad/param norm = 1.5381e-01, time/batch = 17.1538s	
25809/33650 (epoch 38.349), train_loss = 0.66906965, grad/param norm = 1.4515e-01, time/batch = 17.9008s	
25810/33650 (epoch 38.351), train_loss = 0.84738474, grad/param norm = 1.5980e-01, time/batch = 18.8193s	
25811/33650 (epoch 38.352), train_loss = 0.78737327, grad/param norm = 1.7453e-01, time/batch = 17.0502s	
25812/33650 (epoch 38.354), train_loss = 0.94940835, grad/param norm = 1.9955e-01, time/batch = 18.3190s	
25813/33650 (epoch 38.355), train_loss = 0.94747452, grad/param norm = 1.6419e-01, time/batch = 17.9827s	
25814/33650 (epoch 38.357), train_loss = 0.68657066, grad/param norm = 1.5611e-01, time/batch = 17.0582s	
25815/33650 (epoch 38.358), train_loss = 0.82244705, grad/param norm = 1.6116e-01, time/batch = 18.2327s	
25816/33650 (epoch 38.360), train_loss = 0.87417745, grad/param norm = 1.8491e-01, time/batch = 16.7316s	
25817/33650 (epoch 38.361), train_loss = 0.82829908, grad/param norm = 1.8052e-01, time/batch = 17.3081s	
25818/33650 (epoch 38.363), train_loss = 0.85649402, grad/param norm = 1.6691e-01, time/batch = 17.2406s	
25819/33650 (epoch 38.364), train_loss = 0.81985666, grad/param norm = 1.9146e-01, time/batch = 18.5574s	
25820/33650 (epoch 38.366), train_loss = 0.87493626, grad/param norm = 1.8223e-01, time/batch = 15.5511s	
25821/33650 (epoch 38.367), train_loss = 0.84625123, grad/param norm = 1.6163e-01, time/batch = 17.0564s	
25822/33650 (epoch 38.368), train_loss = 0.79039843, grad/param norm = 1.3760e-01, time/batch = 18.4864s	
25823/33650 (epoch 38.370), train_loss = 0.78679984, grad/param norm = 1.6648e-01, time/batch = 18.5678s	
25824/33650 (epoch 38.371), train_loss = 0.63115177, grad/param norm = 1.4958e-01, time/batch = 18.0569s	
25825/33650 (epoch 38.373), train_loss = 0.70346443, grad/param norm = 1.5436e-01, time/batch = 17.2274s	
25826/33650 (epoch 38.374), train_loss = 0.75810003, grad/param norm = 1.4244e-01, time/batch = 18.6455s	
25827/33650 (epoch 38.376), train_loss = 0.79603826, grad/param norm = 1.9294e-01, time/batch = 18.7324s	
25828/33650 (epoch 38.377), train_loss = 0.84321837, grad/param norm = 1.7177e-01, time/batch = 17.6327s	
25829/33650 (epoch 38.379), train_loss = 0.85188189, grad/param norm = 1.7751e-01, time/batch = 17.3071s	
25830/33650 (epoch 38.380), train_loss = 0.70241423, grad/param norm = 2.0505e-01, time/batch = 17.0518s	
25831/33650 (epoch 38.382), train_loss = 0.84399816, grad/param norm = 1.4580e-01, time/batch = 17.2159s	
25832/33650 (epoch 38.383), train_loss = 0.80082466, grad/param norm = 1.6719e-01, time/batch = 18.7965s	
25833/33650 (epoch 38.385), train_loss = 0.83788771, grad/param norm = 1.6581e-01, time/batch = 18.1467s	
25834/33650 (epoch 38.386), train_loss = 0.75665382, grad/param norm = 1.5587e-01, time/batch = 17.1402s	
25835/33650 (epoch 38.388), train_loss = 0.90919115, grad/param norm = 1.5834e-01, time/batch = 17.0342s	
25836/33650 (epoch 38.389), train_loss = 0.74602829, grad/param norm = 1.5732e-01, time/batch = 18.6438s	
25837/33650 (epoch 38.391), train_loss = 0.64407976, grad/param norm = 1.4016e-01, time/batch = 18.1270s	
25838/33650 (epoch 38.392), train_loss = 0.82396450, grad/param norm = 1.8301e-01, time/batch = 17.3875s	
25839/33650 (epoch 38.394), train_loss = 0.84625139, grad/param norm = 1.7745e-01, time/batch = 18.6495s	
25840/33650 (epoch 38.395), train_loss = 0.87145799, grad/param norm = 1.9292e-01, time/batch = 17.4970s	
25841/33650 (epoch 38.397), train_loss = 0.97676302, grad/param norm = 2.4383e-01, time/batch = 17.6382s	
25842/33650 (epoch 38.398), train_loss = 0.90687457, grad/param norm = 1.8424e-01, time/batch = 18.5552s	
25843/33650 (epoch 38.400), train_loss = 0.82279189, grad/param norm = 2.3489e-01, time/batch = 18.4815s	
25844/33650 (epoch 38.401), train_loss = 0.75927769, grad/param norm = 1.6876e-01, time/batch = 17.1355s	
25845/33650 (epoch 38.403), train_loss = 0.85227725, grad/param norm = 1.8865e-01, time/batch = 17.0491s	
25846/33650 (epoch 38.404), train_loss = 0.81993426, grad/param norm = 1.6411e-01, time/batch = 18.6402s	
25847/33650 (epoch 38.406), train_loss = 0.78227525, grad/param norm = 1.4669e-01, time/batch = 18.6502s	
25848/33650 (epoch 38.407), train_loss = 0.82451323, grad/param norm = 1.7126e-01, time/batch = 16.7878s	
25849/33650 (epoch 38.409), train_loss = 0.84054361, grad/param norm = 2.3348e-01, time/batch = 17.0610s	
25850/33650 (epoch 38.410), train_loss = 0.80983732, grad/param norm = 1.6451e-01, time/batch = 18.9780s	
25851/33650 (epoch 38.412), train_loss = 0.83569346, grad/param norm = 1.6825e-01, time/batch = 16.0631s	
25852/33650 (epoch 38.413), train_loss = 0.77691234, grad/param norm = 1.7442e-01, time/batch = 17.9819s	
25853/33650 (epoch 38.415), train_loss = 0.87633075, grad/param norm = 1.8205e-01, time/batch = 18.8051s	
25854/33650 (epoch 38.416), train_loss = 0.97540432, grad/param norm = 1.8594e-01, time/batch = 15.7132s	
25855/33650 (epoch 38.418), train_loss = 0.73856391, grad/param norm = 1.5266e-01, time/batch = 17.7234s	
25856/33650 (epoch 38.419), train_loss = 0.77751945, grad/param norm = 1.7132e-01, time/batch = 18.0664s	
25857/33650 (epoch 38.421), train_loss = 0.80046724, grad/param norm = 1.5225e-01, time/batch = 18.8135s	
25858/33650 (epoch 38.422), train_loss = 0.94053555, grad/param norm = 1.7796e-01, time/batch = 16.2347s	
25859/33650 (epoch 38.423), train_loss = 0.74017956, grad/param norm = 1.3755e-01, time/batch = 18.8163s	
25860/33650 (epoch 38.425), train_loss = 0.86866381, grad/param norm = 2.5773e-01, time/batch = 18.3916s	
25861/33650 (epoch 38.426), train_loss = 0.88148347, grad/param norm = 1.9806e-01, time/batch = 17.4757s	
25862/33650 (epoch 38.428), train_loss = 0.80485107, grad/param norm = 1.5669e-01, time/batch = 18.0717s	
25863/33650 (epoch 38.429), train_loss = 0.86714612, grad/param norm = 1.8653e-01, time/batch = 18.3163s	
25864/33650 (epoch 38.431), train_loss = 0.95748173, grad/param norm = 2.3926e-01, time/batch = 18.2218s	
25865/33650 (epoch 38.432), train_loss = 0.97900145, grad/param norm = 2.1379e-01, time/batch = 17.7677s	
25866/33650 (epoch 38.434), train_loss = 0.87969413, grad/param norm = 2.2210e-01, time/batch = 18.4066s	
25867/33650 (epoch 38.435), train_loss = 0.84547083, grad/param norm = 2.0704e-01, time/batch = 18.2217s	
25868/33650 (epoch 38.437), train_loss = 0.84204220, grad/param norm = 2.0683e-01, time/batch = 16.7041s	
25869/33650 (epoch 38.438), train_loss = 0.82045800, grad/param norm = 1.6966e-01, time/batch = 17.9787s	
25870/33650 (epoch 38.440), train_loss = 0.82022796, grad/param norm = 1.9882e-01, time/batch = 18.0600s	
25871/33650 (epoch 38.441), train_loss = 0.78849861, grad/param norm = 1.7107e-01, time/batch = 17.2105s	
25872/33650 (epoch 38.443), train_loss = 0.90594896, grad/param norm = 1.6138e-01, time/batch = 18.3960s	
25873/33650 (epoch 38.444), train_loss = 0.79441533, grad/param norm = 1.4574e-01, time/batch = 18.2269s	
25874/33650 (epoch 38.446), train_loss = 0.88353471, grad/param norm = 2.1617e-01, time/batch = 17.5491s	
25875/33650 (epoch 38.447), train_loss = 0.94974416, grad/param norm = 1.7542e-01, time/batch = 17.1219s	
25876/33650 (epoch 38.449), train_loss = 0.95306130, grad/param norm = 2.0964e-01, time/batch = 18.2344s	
25877/33650 (epoch 38.450), train_loss = 1.00390785, grad/param norm = 1.9254e-01, time/batch = 17.9780s	
25878/33650 (epoch 38.452), train_loss = 0.96277718, grad/param norm = 2.0463e-01, time/batch = 16.3713s	
25879/33650 (epoch 38.453), train_loss = 0.98320360, grad/param norm = 1.9325e-01, time/batch = 18.9730s	
25880/33650 (epoch 38.455), train_loss = 0.82859606, grad/param norm = 1.7279e-01, time/batch = 17.8917s	
25881/33650 (epoch 38.456), train_loss = 0.83607751, grad/param norm = 1.6259e-01, time/batch = 17.0619s	
25882/33650 (epoch 38.458), train_loss = 0.79978737, grad/param norm = 1.5574e-01, time/batch = 17.9857s	
25883/33650 (epoch 38.459), train_loss = 0.86909667, grad/param norm = 2.0098e-01, time/batch = 18.3205s	
25884/33650 (epoch 38.461), train_loss = 0.88719087, grad/param norm = 2.0737e-01, time/batch = 16.9665s	
25885/33650 (epoch 38.462), train_loss = 0.95060315, grad/param norm = 2.0210e-01, time/batch = 17.8745s	
25886/33650 (epoch 38.464), train_loss = 0.80010064, grad/param norm = 1.8388e-01, time/batch = 17.9775s	
25887/33650 (epoch 38.465), train_loss = 0.86408907, grad/param norm = 2.1371e-01, time/batch = 16.1228s	
25888/33650 (epoch 38.467), train_loss = 0.85819746, grad/param norm = 1.7216e-01, time/batch = 17.7165s	
25889/33650 (epoch 38.468), train_loss = 0.99168266, grad/param norm = 1.6970e-01, time/batch = 18.3122s	
25890/33650 (epoch 38.470), train_loss = 1.05689592, grad/param norm = 1.8976e-01, time/batch = 18.8890s	
25891/33650 (epoch 38.471), train_loss = 0.84819878, grad/param norm = 2.0109e-01, time/batch = 18.0492s	
25892/33650 (epoch 38.473), train_loss = 0.82584915, grad/param norm = 1.6811e-01, time/batch = 17.6418s	
25893/33650 (epoch 38.474), train_loss = 0.96528328, grad/param norm = 1.8772e-01, time/batch = 18.4766s	
25894/33650 (epoch 38.475), train_loss = 0.92654255, grad/param norm = 2.0386e-01, time/batch = 17.9810s	
25895/33650 (epoch 38.477), train_loss = 0.94952451, grad/param norm = 2.1318e-01, time/batch = 18.3875s	
25896/33650 (epoch 38.478), train_loss = 0.94550265, grad/param norm = 1.7883e-01, time/batch = 18.4824s	
25897/33650 (epoch 38.480), train_loss = 0.91842189, grad/param norm = 1.9949e-01, time/batch = 17.2030s	
25898/33650 (epoch 38.481), train_loss = 0.95999845, grad/param norm = 1.6601e-01, time/batch = 16.7136s	
25899/33650 (epoch 38.483), train_loss = 0.72030779, grad/param norm = 1.5437e-01, time/batch = 17.9844s	
25900/33650 (epoch 38.484), train_loss = 0.82128353, grad/param norm = 1.6023e-01, time/batch = 18.2401s	
25901/33650 (epoch 38.486), train_loss = 0.96194871, grad/param norm = 1.9142e-01, time/batch = 16.8006s	
25902/33650 (epoch 38.487), train_loss = 0.95315153, grad/param norm = 1.9281e-01, time/batch = 18.6422s	
25903/33650 (epoch 38.489), train_loss = 0.98667720, grad/param norm = 1.6778e-01, time/batch = 18.4811s	
25904/33650 (epoch 38.490), train_loss = 0.79703463, grad/param norm = 1.7762e-01, time/batch = 17.6491s	
25905/33650 (epoch 38.492), train_loss = 0.91834844, grad/param norm = 1.8950e-01, time/batch = 17.3840s	
25906/33650 (epoch 38.493), train_loss = 0.74365538, grad/param norm = 1.4034e-01, time/batch = 18.1397s	
25907/33650 (epoch 38.495), train_loss = 0.88326235, grad/param norm = 1.8502e-01, time/batch = 18.0599s	
25908/33650 (epoch 38.496), train_loss = 0.91910302, grad/param norm = 1.8928e-01, time/batch = 25.5927s	
25909/33650 (epoch 38.498), train_loss = 0.79473784, grad/param norm = 1.7462e-01, time/batch = 22.5207s	
25910/33650 (epoch 38.499), train_loss = 0.84438671, grad/param norm = 1.4379e-01, time/batch = 17.9102s	
25911/33650 (epoch 38.501), train_loss = 0.86564786, grad/param norm = 1.4710e-01, time/batch = 16.8091s	
25912/33650 (epoch 38.502), train_loss = 0.89442158, grad/param norm = 1.8083e-01, time/batch = 18.7319s	
25913/33650 (epoch 38.504), train_loss = 0.94053325, grad/param norm = 1.9677e-01, time/batch = 17.8922s	
25914/33650 (epoch 38.505), train_loss = 0.83208251, grad/param norm = 1.6949e-01, time/batch = 17.8303s	
25915/33650 (epoch 38.507), train_loss = 0.94513666, grad/param norm = 1.6605e-01, time/batch = 18.3085s	
25916/33650 (epoch 38.508), train_loss = 0.84360066, grad/param norm = 1.7139e-01, time/batch = 17.1322s	
25917/33650 (epoch 38.510), train_loss = 0.86828204, grad/param norm = 1.6782e-01, time/batch = 17.1353s	
25918/33650 (epoch 38.511), train_loss = 0.99270330, grad/param norm = 1.9859e-01, time/batch = 18.2313s	
25919/33650 (epoch 38.513), train_loss = 0.90325504, grad/param norm = 1.6634e-01, time/batch = 17.8967s	
25920/33650 (epoch 38.514), train_loss = 0.96837880, grad/param norm = 1.9386e-01, time/batch = 16.9902s	
25921/33650 (epoch 38.516), train_loss = 0.88995732, grad/param norm = 2.1569e-01, time/batch = 17.0586s	
25922/33650 (epoch 38.517), train_loss = 0.86079129, grad/param norm = 1.6993e-01, time/batch = 18.0677s	
25923/33650 (epoch 38.519), train_loss = 0.92736031, grad/param norm = 1.7526e-01, time/batch = 18.9059s	
25924/33650 (epoch 38.520), train_loss = 0.74610889, grad/param norm = 1.4166e-01, time/batch = 18.2172s	
25925/33650 (epoch 38.522), train_loss = 0.84017516, grad/param norm = 1.7343e-01, time/batch = 16.1355s	
25926/33650 (epoch 38.523), train_loss = 0.80786326, grad/param norm = 1.7863e-01, time/batch = 18.1581s	
25927/33650 (epoch 38.525), train_loss = 0.67938543, grad/param norm = 1.3195e-01, time/batch = 17.9776s	
25928/33650 (epoch 38.526), train_loss = 0.97033423, grad/param norm = 1.6369e-01, time/batch = 17.0421s	
25929/33650 (epoch 38.527), train_loss = 0.80589599, grad/param norm = 1.6096e-01, time/batch = 18.9824s	
25930/33650 (epoch 38.529), train_loss = 0.86791826, grad/param norm = 1.6288e-01, time/batch = 18.0560s	
25931/33650 (epoch 38.530), train_loss = 0.80096678, grad/param norm = 1.7707e-01, time/batch = 16.4544s	
25932/33650 (epoch 38.532), train_loss = 0.91557582, grad/param norm = 1.9366e-01, time/batch = 17.8945s	
25933/33650 (epoch 38.533), train_loss = 0.87040856, grad/param norm = 1.5825e-01, time/batch = 18.8968s	
25934/33650 (epoch 38.535), train_loss = 0.97131861, grad/param norm = 1.8510e-01, time/batch = 16.7296s	
25935/33650 (epoch 38.536), train_loss = 0.88467526, grad/param norm = 2.0703e-01, time/batch = 17.5702s	
25936/33650 (epoch 38.538), train_loss = 0.87625581, grad/param norm = 1.8036e-01, time/batch = 17.4807s	
25937/33650 (epoch 38.539), train_loss = 0.68563275, grad/param norm = 1.5960e-01, time/batch = 17.6420s	
25938/33650 (epoch 38.541), train_loss = 0.96174458, grad/param norm = 2.8346e-01, time/batch = 18.3159s	
25939/33650 (epoch 38.542), train_loss = 0.83745282, grad/param norm = 2.2464e-01, time/batch = 18.1604s	
25940/33650 (epoch 38.544), train_loss = 1.02922188, grad/param norm = 2.3353e-01, time/batch = 18.8184s	
25941/33650 (epoch 38.545), train_loss = 0.76781809, grad/param norm = 1.6726e-01, time/batch = 16.8995s	
25942/33650 (epoch 38.547), train_loss = 0.91289721, grad/param norm = 1.7964e-01, time/batch = 18.0539s	
25943/33650 (epoch 38.548), train_loss = 1.00555662, grad/param norm = 1.6227e-01, time/batch = 18.5658s	
25944/33650 (epoch 38.550), train_loss = 0.88085729, grad/param norm = 1.8134e-01, time/batch = 16.4639s	
25945/33650 (epoch 38.551), train_loss = 0.87909541, grad/param norm = 1.7670e-01, time/batch = 18.2247s	
25946/33650 (epoch 38.553), train_loss = 0.77284385, grad/param norm = 1.8558e-01, time/batch = 18.1580s	
25947/33650 (epoch 38.554), train_loss = 1.03568054, grad/param norm = 2.2238e-01, time/batch = 17.5733s	
25948/33650 (epoch 38.556), train_loss = 0.96230846, grad/param norm = 2.2061e-01, time/batch = 18.2971s	
25949/33650 (epoch 38.557), train_loss = 0.91852364, grad/param norm = 2.0084e-01, time/batch = 18.1500s	
25950/33650 (epoch 38.559), train_loss = 1.06997154, grad/param norm = 1.8956e-01, time/batch = 16.8073s	
25951/33650 (epoch 38.560), train_loss = 0.99115388, grad/param norm = 1.9437e-01, time/batch = 16.4608s	
25952/33650 (epoch 38.562), train_loss = 0.97005979, grad/param norm = 1.7436e-01, time/batch = 17.0496s	
25953/33650 (epoch 38.563), train_loss = 0.89134744, grad/param norm = 1.7520e-01, time/batch = 18.4730s	
25954/33650 (epoch 38.565), train_loss = 0.90251578, grad/param norm = 1.6501e-01, time/batch = 17.3906s	
25955/33650 (epoch 38.566), train_loss = 0.85410610, grad/param norm = 1.9548e-01, time/batch = 17.7412s	
25956/33650 (epoch 38.568), train_loss = 0.88982732, grad/param norm = 2.1052e-01, time/batch = 16.8883s	
25957/33650 (epoch 38.569), train_loss = 0.79999139, grad/param norm = 1.7423e-01, time/batch = 14.5434s	
25958/33650 (epoch 38.571), train_loss = 0.96278488, grad/param norm = 1.9041e-01, time/batch = 15.8747s	
25959/33650 (epoch 38.572), train_loss = 0.92185054, grad/param norm = 1.8198e-01, time/batch = 14.6925s	
25960/33650 (epoch 38.574), train_loss = 0.80759599, grad/param norm = 2.0529e-01, time/batch = 14.4088s	
25961/33650 (epoch 38.575), train_loss = 0.87166175, grad/param norm = 1.8568e-01, time/batch = 15.4012s	
25962/33650 (epoch 38.577), train_loss = 0.78963982, grad/param norm = 1.8489e-01, time/batch = 16.7865s	
25963/33650 (epoch 38.578), train_loss = 0.96845685, grad/param norm = 1.7646e-01, time/batch = 17.7804s	
25964/33650 (epoch 38.579), train_loss = 0.94510809, grad/param norm = 1.9093e-01, time/batch = 17.3886s	
25965/33650 (epoch 38.581), train_loss = 1.01668131, grad/param norm = 2.2547e-01, time/batch = 18.2203s	
25966/33650 (epoch 38.582), train_loss = 0.90851678, grad/param norm = 1.9222e-01, time/batch = 15.8863s	
25967/33650 (epoch 38.584), train_loss = 0.89696605, grad/param norm = 1.6729e-01, time/batch = 18.3915s	
25968/33650 (epoch 38.585), train_loss = 0.91737660, grad/param norm = 2.2804e-01, time/batch = 17.7339s	
25969/33650 (epoch 38.587), train_loss = 0.81757683, grad/param norm = 1.7565e-01, time/batch = 16.8747s	
25970/33650 (epoch 38.588), train_loss = 0.81195841, grad/param norm = 2.3979e-01, time/batch = 17.3022s	
25971/33650 (epoch 38.590), train_loss = 0.85081687, grad/param norm = 1.6463e-01, time/batch = 18.3083s	
25972/33650 (epoch 38.591), train_loss = 0.75690268, grad/param norm = 1.8318e-01, time/batch = 17.1351s	
25973/33650 (epoch 38.593), train_loss = 0.77160929, grad/param norm = 1.6358e-01, time/batch = 17.4849s	
25974/33650 (epoch 38.594), train_loss = 0.77391595, grad/param norm = 1.6588e-01, time/batch = 18.3936s	
25975/33650 (epoch 38.596), train_loss = 0.84686782, grad/param norm = 1.6909e-01, time/batch = 16.7245s	
25976/33650 (epoch 38.597), train_loss = 0.76503485, grad/param norm = 1.6812e-01, time/batch = 17.5483s	
25977/33650 (epoch 38.599), train_loss = 0.84970071, grad/param norm = 1.6628e-01, time/batch = 17.3786s	
25978/33650 (epoch 38.600), train_loss = 0.81153411, grad/param norm = 1.8444e-01, time/batch = 18.6320s	
25979/33650 (epoch 38.602), train_loss = 0.86807586, grad/param norm = 1.6671e-01, time/batch = 16.7133s	
25980/33650 (epoch 38.603), train_loss = 0.79749490, grad/param norm = 1.5559e-01, time/batch = 16.4545s	
25981/33650 (epoch 38.605), train_loss = 0.92338317, grad/param norm = 1.7066e-01, time/batch = 18.7341s	
25982/33650 (epoch 38.606), train_loss = 0.86145391, grad/param norm = 2.2573e-01, time/batch = 17.7999s	
25983/33650 (epoch 38.608), train_loss = 0.74944785, grad/param norm = 2.0719e-01, time/batch = 17.6399s	
25984/33650 (epoch 38.609), train_loss = 0.84968174, grad/param norm = 1.9325e-01, time/batch = 18.3160s	
25985/33650 (epoch 38.611), train_loss = 0.75774192, grad/param norm = 1.5478e-01, time/batch = 17.1555s	
25986/33650 (epoch 38.612), train_loss = 0.84790505, grad/param norm = 2.0092e-01, time/batch = 16.1193s	
25987/33650 (epoch 38.614), train_loss = 0.95492748, grad/param norm = 1.9619e-01, time/batch = 18.2204s	
25988/33650 (epoch 38.615), train_loss = 0.89185458, grad/param norm = 1.5823e-01, time/batch = 17.8094s	
25989/33650 (epoch 38.617), train_loss = 0.77294264, grad/param norm = 1.3184e-01, time/batch = 17.1476s	
25990/33650 (epoch 38.618), train_loss = 0.85112758, grad/param norm = 1.7691e-01, time/batch = 17.5588s	
25991/33650 (epoch 38.620), train_loss = 0.82732763, grad/param norm = 1.8580e-01, time/batch = 18.5640s	
25992/33650 (epoch 38.621), train_loss = 0.74927134, grad/param norm = 1.5435e-01, time/batch = 17.8709s	
25993/33650 (epoch 38.623), train_loss = 0.83462074, grad/param norm = 1.6104e-01, time/batch = 17.8052s	
25994/33650 (epoch 38.624), train_loss = 0.66203802, grad/param norm = 1.4959e-01, time/batch = 17.9063s	
25995/33650 (epoch 38.626), train_loss = 0.69421358, grad/param norm = 1.5858e-01, time/batch = 17.3292s	
25996/33650 (epoch 38.627), train_loss = 0.78474140, grad/param norm = 1.4842e-01, time/batch = 16.8129s	
25997/33650 (epoch 38.629), train_loss = 0.80788244, grad/param norm = 1.9659e-01, time/batch = 18.4783s	
25998/33650 (epoch 38.630), train_loss = 0.95561014, grad/param norm = 1.8795e-01, time/batch = 19.0734s	
25999/33650 (epoch 38.632), train_loss = 0.92140116, grad/param norm = 1.8819e-01, time/batch = 17.5653s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasa_johnson_epoch38.63_1.7867.t7	
26000/33650 (epoch 38.633), train_loss = 0.93369265, grad/param norm = 1.6486e-01, time/batch = 17.2974s	
26001/33650 (epoch 38.634), train_loss = 1.21760894, grad/param norm = 2.2938e-01, time/batch = 18.3787s	
26002/33650 (epoch 38.636), train_loss = 0.66075667, grad/param norm = 1.2631e-01, time/batch = 16.8855s	
26003/33650 (epoch 38.637), train_loss = 0.75701868, grad/param norm = 1.5302e-01, time/batch = 18.8179s	
26004/33650 (epoch 38.639), train_loss = 0.76622330, grad/param norm = 1.5014e-01, time/batch = 15.3972s	
26005/33650 (epoch 38.640), train_loss = 0.86452171, grad/param norm = 1.9222e-01, time/batch = 15.9699s	
26006/33650 (epoch 38.642), train_loss = 0.92523000, grad/param norm = 1.6320e-01, time/batch = 17.9880s	
26007/33650 (epoch 38.643), train_loss = 0.86303506, grad/param norm = 1.7644e-01, time/batch = 18.7394s	
26008/33650 (epoch 38.645), train_loss = 0.85181822, grad/param norm = 1.5813e-01, time/batch = 15.7221s	
26009/33650 (epoch 38.646), train_loss = 0.76252771, grad/param norm = 1.5221e-01, time/batch = 18.5607s	
26010/33650 (epoch 38.648), train_loss = 0.88151708, grad/param norm = 1.6317e-01, time/batch = 18.5518s	
26011/33650 (epoch 38.649), train_loss = 0.75421913, grad/param norm = 1.8185e-01, time/batch = 17.6491s	
26012/33650 (epoch 38.651), train_loss = 0.91595591, grad/param norm = 1.8591e-01, time/batch = 17.6467s	
26013/33650 (epoch 38.652), train_loss = 0.64063563, grad/param norm = 1.4254e-01, time/batch = 16.3082s	
26014/33650 (epoch 38.654), train_loss = 0.77040314, grad/param norm = 1.8004e-01, time/batch = 18.4868s	
26015/33650 (epoch 38.655), train_loss = 0.73873116, grad/param norm = 1.4879e-01, time/batch = 15.6094s	
26016/33650 (epoch 38.657), train_loss = 0.78796922, grad/param norm = 1.9776e-01, time/batch = 18.8239s	
26017/33650 (epoch 38.658), train_loss = 0.67341509, grad/param norm = 1.6364e-01, time/batch = 17.7342s	
26018/33650 (epoch 38.660), train_loss = 0.68364564, grad/param norm = 1.5553e-01, time/batch = 17.9738s	
26019/33650 (epoch 38.661), train_loss = 0.76708721, grad/param norm = 1.9425e-01, time/batch = 2.9589s	
26020/33650 (epoch 38.663), train_loss = 0.71625703, grad/param norm = 1.7973e-01, time/batch = 0.6646s	
26021/33650 (epoch 38.664), train_loss = 0.82268368, grad/param norm = 1.6247e-01, time/batch = 0.6426s	
26022/33650 (epoch 38.666), train_loss = 0.80863404, grad/param norm = 1.5155e-01, time/batch = 0.6478s	
26023/33650 (epoch 38.667), train_loss = 0.69631292, grad/param norm = 1.4570e-01, time/batch = 0.6426s	
26024/33650 (epoch 38.669), train_loss = 0.73691317, grad/param norm = 1.6322e-01, time/batch = 0.6407s	
26025/33650 (epoch 38.670), train_loss = 0.66500019, grad/param norm = 1.5303e-01, time/batch = 0.6412s	
26026/33650 (epoch 38.672), train_loss = 0.68414386, grad/param norm = 1.7247e-01, time/batch = 0.6893s	
26027/33650 (epoch 38.673), train_loss = 0.68992841, grad/param norm = 1.5888e-01, time/batch = 0.9400s	
26028/33650 (epoch 38.675), train_loss = 0.64327654, grad/param norm = 1.3070e-01, time/batch = 0.9418s	
26029/33650 (epoch 38.676), train_loss = 0.75986474, grad/param norm = 1.5969e-01, time/batch = 0.9421s	
26030/33650 (epoch 38.678), train_loss = 0.76883594, grad/param norm = 1.9140e-01, time/batch = 0.9397s	
26031/33650 (epoch 38.679), train_loss = 0.75448621, grad/param norm = 1.6430e-01, time/batch = 0.9460s	
26032/33650 (epoch 38.681), train_loss = 0.76187828, grad/param norm = 1.4029e-01, time/batch = 1.7283s	
26033/33650 (epoch 38.682), train_loss = 0.75740989, grad/param norm = 1.7166e-01, time/batch = 1.7883s	
26034/33650 (epoch 38.684), train_loss = 0.68672869, grad/param norm = 1.5174e-01, time/batch = 3.7967s	
26035/33650 (epoch 38.685), train_loss = 0.83977807, grad/param norm = 1.7963e-01, time/batch = 18.5669s	
26036/33650 (epoch 38.686), train_loss = 0.82075230, grad/param norm = 1.6173e-01, time/batch = 18.3964s	
26037/33650 (epoch 38.688), train_loss = 0.88045282, grad/param norm = 1.6759e-01, time/batch = 17.3026s	
26038/33650 (epoch 38.689), train_loss = 0.76129025, grad/param norm = 1.6314e-01, time/batch = 18.1539s	
26039/33650 (epoch 38.691), train_loss = 0.89969818, grad/param norm = 1.8824e-01, time/batch = 18.0681s	
26040/33650 (epoch 38.692), train_loss = 0.89533159, grad/param norm = 1.8505e-01, time/batch = 17.3062s	
26041/33650 (epoch 38.694), train_loss = 0.87647833, grad/param norm = 1.8687e-01, time/batch = 17.3733s	
26042/33650 (epoch 38.695), train_loss = 0.54837135, grad/param norm = 1.5020e-01, time/batch = 18.4015s	
26043/33650 (epoch 38.697), train_loss = 0.78776257, grad/param norm = 1.6236e-01, time/batch = 16.9819s	
26044/33650 (epoch 38.698), train_loss = 0.89177493, grad/param norm = 1.7498e-01, time/batch = 17.5734s	
26045/33650 (epoch 38.700), train_loss = 0.78994561, grad/param norm = 1.7757e-01, time/batch = 17.7336s	
26046/33650 (epoch 38.701), train_loss = 0.83701077, grad/param norm = 1.9757e-01, time/batch = 18.0388s	
26047/33650 (epoch 38.703), train_loss = 1.01948210, grad/param norm = 1.7818e-01, time/batch = 17.5437s	
26048/33650 (epoch 38.704), train_loss = 0.80503992, grad/param norm = 1.6670e-01, time/batch = 17.2990s	
26049/33650 (epoch 38.706), train_loss = 0.78743552, grad/param norm = 1.6070e-01, time/batch = 18.4761s	
26050/33650 (epoch 38.707), train_loss = 0.87661077, grad/param norm = 1.5841e-01, time/batch = 16.6464s	
26051/33650 (epoch 38.709), train_loss = 0.77477065, grad/param norm = 1.6282e-01, time/batch = 18.8940s	
26052/33650 (epoch 38.710), train_loss = 0.96352286, grad/param norm = 1.7880e-01, time/batch = 17.9757s	
26053/33650 (epoch 38.712), train_loss = 0.70920851, grad/param norm = 1.7713e-01, time/batch = 17.7986s	
26054/33650 (epoch 38.713), train_loss = 0.75810083, grad/param norm = 2.1681e-01, time/batch = 17.5559s	
26055/33650 (epoch 38.715), train_loss = 0.85976512, grad/param norm = 1.8184e-01, time/batch = 16.6312s	
26056/33650 (epoch 38.716), train_loss = 0.79567629, grad/param norm = 1.8949e-01, time/batch = 18.2997s	
26057/33650 (epoch 38.718), train_loss = 0.75555467, grad/param norm = 1.4589e-01, time/batch = 17.6349s	
26058/33650 (epoch 38.719), train_loss = 0.94386143, grad/param norm = 2.3576e-01, time/batch = 17.7354s	
26059/33650 (epoch 38.721), train_loss = 0.99207315, grad/param norm = 2.0033e-01, time/batch = 17.3067s	
26060/33650 (epoch 38.722), train_loss = 0.90568609, grad/param norm = 2.1225e-01, time/batch = 16.2857s	
26061/33650 (epoch 38.724), train_loss = 0.90658557, grad/param norm = 1.6933e-01, time/batch = 17.3959s	
26062/33650 (epoch 38.725), train_loss = 0.87141814, grad/param norm = 1.6883e-01, time/batch = 18.6325s	
26063/33650 (epoch 38.727), train_loss = 0.78762453, grad/param norm = 1.9043e-01, time/batch = 18.2225s	
26064/33650 (epoch 38.728), train_loss = 0.77813535, grad/param norm = 1.6449e-01, time/batch = 17.3882s	
26065/33650 (epoch 38.730), train_loss = 0.84321268, grad/param norm = 1.6558e-01, time/batch = 18.2310s	
26066/33650 (epoch 38.731), train_loss = 0.99115868, grad/param norm = 2.0091e-01, time/batch = 17.9746s	
26067/33650 (epoch 38.733), train_loss = 0.78884856, grad/param norm = 1.9062e-01, time/batch = 17.1460s	
26068/33650 (epoch 38.734), train_loss = 0.94344132, grad/param norm = 1.8082e-01, time/batch = 18.9849s	
26069/33650 (epoch 38.736), train_loss = 0.84088377, grad/param norm = 2.1578e-01, time/batch = 17.4087s	
26070/33650 (epoch 38.737), train_loss = 0.86545594, grad/param norm = 1.8479e-01, time/batch = 17.5293s	
26071/33650 (epoch 38.738), train_loss = 0.75188458, grad/param norm = 1.7540e-01, time/batch = 18.3052s	
26072/33650 (epoch 38.740), train_loss = 0.72076094, grad/param norm = 1.5826e-01, time/batch = 17.9851s	
26073/33650 (epoch 38.741), train_loss = 0.75801791, grad/param norm = 1.7061e-01, time/batch = 17.9751s	
26074/33650 (epoch 38.743), train_loss = 0.80384184, grad/param norm = 1.5896e-01, time/batch = 17.2224s	
26075/33650 (epoch 38.744), train_loss = 0.90392155, grad/param norm = 1.4571e-01, time/batch = 18.3179s	
26076/33650 (epoch 38.746), train_loss = 0.77792475, grad/param norm = 1.5564e-01, time/batch = 18.2394s	
26077/33650 (epoch 38.747), train_loss = 0.94756001, grad/param norm = 1.7729e-01, time/batch = 16.5518s	
26078/33650 (epoch 38.749), train_loss = 0.67196483, grad/param norm = 1.9085e-01, time/batch = 17.8851s	
26079/33650 (epoch 38.750), train_loss = 0.95873375, grad/param norm = 1.7774e-01, time/batch = 16.6503s	
26080/33650 (epoch 38.752), train_loss = 0.91193549, grad/param norm = 1.7863e-01, time/batch = 17.3046s	
26081/33650 (epoch 38.753), train_loss = 0.99090113, grad/param norm = 1.8153e-01, time/batch = 17.4747s	
26082/33650 (epoch 38.755), train_loss = 0.83271016, grad/param norm = 1.5424e-01, time/batch = 17.6364s	
26083/33650 (epoch 38.756), train_loss = 0.89755216, grad/param norm = 2.0245e-01, time/batch = 18.5632s	
26084/33650 (epoch 38.758), train_loss = 0.93436298, grad/param norm = 1.8114e-01, time/batch = 17.2985s	
26085/33650 (epoch 38.759), train_loss = 0.95094046, grad/param norm = 2.3080e-01, time/batch = 18.2291s	
26086/33650 (epoch 38.761), train_loss = 0.85533691, grad/param norm = 1.6987e-01, time/batch = 17.9854s	
26087/33650 (epoch 38.762), train_loss = 0.84842064, grad/param norm = 1.7765e-01, time/batch = 17.8978s	
26088/33650 (epoch 38.764), train_loss = 0.86148741, grad/param norm = 1.8807e-01, time/batch = 15.9550s	
26089/33650 (epoch 38.765), train_loss = 0.78107811, grad/param norm = 1.6340e-01, time/batch = 18.4794s	
26090/33650 (epoch 38.767), train_loss = 0.82362454, grad/param norm = 1.7181e-01, time/batch = 17.8117s	
26091/33650 (epoch 38.768), train_loss = 0.76868845, grad/param norm = 1.6941e-01, time/batch = 17.0587s	
26092/33650 (epoch 38.770), train_loss = 0.83299073, grad/param norm = 1.8801e-01, time/batch = 18.4904s	
26093/33650 (epoch 38.771), train_loss = 0.87176513, grad/param norm = 1.6424e-01, time/batch = 16.2300s	
26094/33650 (epoch 38.773), train_loss = 0.91509885, grad/param norm = 1.8847e-01, time/batch = 16.5533s	
26095/33650 (epoch 38.774), train_loss = 0.84550721, grad/param norm = 1.8366e-01, time/batch = 17.8030s	
26096/33650 (epoch 38.776), train_loss = 0.91786532, grad/param norm = 1.9893e-01, time/batch = 17.4769s	
26097/33650 (epoch 38.777), train_loss = 0.74893880, grad/param norm = 1.4855e-01, time/batch = 17.5458s	
26098/33650 (epoch 38.779), train_loss = 0.82928320, grad/param norm = 1.7903e-01, time/batch = 18.0588s	
26099/33650 (epoch 38.780), train_loss = 0.76605333, grad/param norm = 1.7391e-01, time/batch = 18.1466s	
26100/33650 (epoch 38.782), train_loss = 0.77147800, grad/param norm = 1.8252e-01, time/batch = 18.4677s	
26101/33650 (epoch 38.783), train_loss = 0.77183264, grad/param norm = 1.4247e-01, time/batch = 17.3636s	
26102/33650 (epoch 38.785), train_loss = 0.98207569, grad/param norm = 1.6704e-01, time/batch = 17.3114s	
26103/33650 (epoch 38.786), train_loss = 0.86342191, grad/param norm = 1.6869e-01, time/batch = 18.2190s	
26104/33650 (epoch 38.788), train_loss = 0.89349419, grad/param norm = 1.6266e-01, time/batch = 17.2296s	
26105/33650 (epoch 38.789), train_loss = 0.90881075, grad/param norm = 1.6879e-01, time/batch = 18.1414s	
26106/33650 (epoch 38.790), train_loss = 0.84902545, grad/param norm = 1.7922e-01, time/batch = 18.4018s	
26107/33650 (epoch 38.792), train_loss = 0.94681388, grad/param norm = 1.7442e-01, time/batch = 17.9746s	
26108/33650 (epoch 38.793), train_loss = 0.89563956, grad/param norm = 1.7144e-01, time/batch = 17.9807s	
26109/33650 (epoch 38.795), train_loss = 0.90613856, grad/param norm = 1.7039e-01, time/batch = 16.8794s	
26110/33650 (epoch 38.796), train_loss = 0.79961769, grad/param norm = 1.6987e-01, time/batch = 18.1379s	
26111/33650 (epoch 38.798), train_loss = 0.80038074, grad/param norm = 1.6599e-01, time/batch = 18.0392s	
26112/33650 (epoch 38.799), train_loss = 0.83697044, grad/param norm = 1.7679e-01, time/batch = 18.2290s	
26113/33650 (epoch 38.801), train_loss = 0.83948640, grad/param norm = 2.2201e-01, time/batch = 17.4042s	
26114/33650 (epoch 38.802), train_loss = 0.94185861, grad/param norm = 1.7065e-01, time/batch = 17.2921s	
26115/33650 (epoch 38.804), train_loss = 0.84864419, grad/param norm = 1.7650e-01, time/batch = 18.7304s	
26116/33650 (epoch 38.805), train_loss = 0.84026124, grad/param norm = 1.5809e-01, time/batch = 16.8062s	
26117/33650 (epoch 38.807), train_loss = 0.99052459, grad/param norm = 1.9718e-01, time/batch = 17.3881s	
26118/33650 (epoch 38.808), train_loss = 1.08076025, grad/param norm = 2.1900e-01, time/batch = 31.8107s	
26119/33650 (epoch 38.810), train_loss = 0.88322803, grad/param norm = 1.7841e-01, time/batch = 18.8069s	
26120/33650 (epoch 38.811), train_loss = 0.87119633, grad/param norm = 1.8101e-01, time/batch = 16.9739s	
26121/33650 (epoch 38.813), train_loss = 0.76984310, grad/param norm = 1.7306e-01, time/batch = 18.1326s	
26122/33650 (epoch 38.814), train_loss = 0.93448368, grad/param norm = 1.8531e-01, time/batch = 18.9768s	
26123/33650 (epoch 38.816), train_loss = 0.90557605, grad/param norm = 1.7560e-01, time/batch = 17.2285s	
26124/33650 (epoch 38.817), train_loss = 0.92271466, grad/param norm = 1.8191e-01, time/batch = 16.5562s	
26125/33650 (epoch 38.819), train_loss = 0.86929046, grad/param norm = 1.9003e-01, time/batch = 18.3102s	
26126/33650 (epoch 38.820), train_loss = 0.94761669, grad/param norm = 1.7082e-01, time/batch = 15.6392s	
26127/33650 (epoch 38.822), train_loss = 0.88313516, grad/param norm = 2.1372e-01, time/batch = 17.1344s	
26128/33650 (epoch 38.823), train_loss = 0.78499917, grad/param norm = 1.7775e-01, time/batch = 17.5614s	
26129/33650 (epoch 38.825), train_loss = 0.85376869, grad/param norm = 1.7905e-01, time/batch = 17.3197s	
26130/33650 (epoch 38.826), train_loss = 0.90098976, grad/param norm = 1.7027e-01, time/batch = 17.0508s	
26131/33650 (epoch 38.828), train_loss = 1.01732263, grad/param norm = 2.0393e-01, time/batch = 18.4717s	
26132/33650 (epoch 38.829), train_loss = 0.73957314, grad/param norm = 1.7204e-01, time/batch = 18.7187s	
26133/33650 (epoch 38.831), train_loss = 0.88511729, grad/param norm = 1.9902e-01, time/batch = 17.4816s	
26134/33650 (epoch 38.832), train_loss = 0.91743320, grad/param norm = 1.7704e-01, time/batch = 17.2250s	
26135/33650 (epoch 38.834), train_loss = 0.92094980, grad/param norm = 1.8421e-01, time/batch = 18.8213s	
26136/33650 (epoch 38.835), train_loss = 1.04770061, grad/param norm = 2.0702e-01, time/batch = 18.9823s	
26137/33650 (epoch 38.837), train_loss = 0.90930686, grad/param norm = 2.0198e-01, time/batch = 16.8055s	
26138/33650 (epoch 38.838), train_loss = 0.86773661, grad/param norm = 2.0990e-01, time/batch = 18.8937s	
26139/33650 (epoch 38.840), train_loss = 0.94069674, grad/param norm = 1.8496e-01, time/batch = 18.4061s	
26140/33650 (epoch 38.841), train_loss = 0.81103076, grad/param norm = 1.7251e-01, time/batch = 16.5658s	
26141/33650 (epoch 38.842), train_loss = 0.84982602, grad/param norm = 1.7086e-01, time/batch = 18.2251s	
26142/33650 (epoch 38.844), train_loss = 0.98004652, grad/param norm = 2.1233e-01, time/batch = 17.5552s	
26143/33650 (epoch 38.845), train_loss = 0.85090848, grad/param norm = 1.6636e-01, time/batch = 16.9686s	
26144/33650 (epoch 38.847), train_loss = 0.65862835, grad/param norm = 1.7880e-01, time/batch = 16.8848s	
26145/33650 (epoch 38.848), train_loss = 0.73780770, grad/param norm = 1.7299e-01, time/batch = 18.7361s	
26146/33650 (epoch 38.850), train_loss = 0.82125094, grad/param norm = 1.8627e-01, time/batch = 17.7265s	
26147/33650 (epoch 38.851), train_loss = 0.73108613, grad/param norm = 1.5550e-01, time/batch = 16.8812s	
26148/33650 (epoch 38.853), train_loss = 0.80288254, grad/param norm = 2.9328e-01, time/batch = 18.3148s	
26149/33650 (epoch 38.854), train_loss = 0.92625866, grad/param norm = 1.8402e-01, time/batch = 18.9007s	
26150/33650 (epoch 38.856), train_loss = 0.68256702, grad/param norm = 1.6044e-01, time/batch = 16.8952s	
26151/33650 (epoch 38.857), train_loss = 0.88213758, grad/param norm = 1.6624e-01, time/batch = 17.5522s	
26152/33650 (epoch 38.859), train_loss = 0.75236129, grad/param norm = 1.4525e-01, time/batch = 18.0662s	
26153/33650 (epoch 38.860), train_loss = 0.72636844, grad/param norm = 1.7690e-01, time/batch = 17.6554s	
26154/33650 (epoch 38.862), train_loss = 0.76657354, grad/param norm = 1.5408e-01, time/batch = 16.4630s	
26155/33650 (epoch 38.863), train_loss = 0.95091482, grad/param norm = 1.5153e-01, time/batch = 18.4771s	
26156/33650 (epoch 38.865), train_loss = 0.86165741, grad/param norm = 1.8326e-01, time/batch = 18.0731s	
26157/33650 (epoch 38.866), train_loss = 0.77367349, grad/param norm = 1.6832e-01, time/batch = 17.2211s	
26158/33650 (epoch 38.868), train_loss = 0.72136029, grad/param norm = 1.8426e-01, time/batch = 18.5615s	
26159/33650 (epoch 38.869), train_loss = 0.89352487, grad/param norm = 1.8424e-01, time/batch = 17.8165s	
26160/33650 (epoch 38.871), train_loss = 0.74152657, grad/param norm = 1.6024e-01, time/batch = 17.3105s	
26161/33650 (epoch 38.872), train_loss = 0.87393631, grad/param norm = 1.7962e-01, time/batch = 16.9063s	
26162/33650 (epoch 38.874), train_loss = 0.90260495, grad/param norm = 2.0264e-01, time/batch = 18.5672s	
26163/33650 (epoch 38.875), train_loss = 0.77842814, grad/param norm = 1.5129e-01, time/batch = 18.5746s	
26164/33650 (epoch 38.877), train_loss = 0.98257147, grad/param norm = 1.8409e-01, time/batch = 17.3064s	
26165/33650 (epoch 38.878), train_loss = 0.62669994, grad/param norm = 1.3053e-01, time/batch = 18.6555s	
26166/33650 (epoch 38.880), train_loss = 0.86763049, grad/param norm = 1.8799e-01, time/batch = 17.1365s	
26167/33650 (epoch 38.881), train_loss = 0.82079601, grad/param norm = 1.7941e-01, time/batch = 17.3869s	
26168/33650 (epoch 38.883), train_loss = 0.87106002, grad/param norm = 1.7770e-01, time/batch = 17.4181s	
26169/33650 (epoch 38.884), train_loss = 0.94820847, grad/param norm = 1.8095e-01, time/batch = 18.1559s	
26170/33650 (epoch 38.886), train_loss = 0.88169967, grad/param norm = 1.6905e-01, time/batch = 16.8817s	
26171/33650 (epoch 38.887), train_loss = 0.72252564, grad/param norm = 1.4031e-01, time/batch = 18.0591s	
26172/33650 (epoch 38.889), train_loss = 0.81398737, grad/param norm = 1.7579e-01, time/batch = 18.1581s	
26173/33650 (epoch 38.890), train_loss = 0.88388064, grad/param norm = 1.6519e-01, time/batch = 18.3164s	
26174/33650 (epoch 38.892), train_loss = 0.77993049, grad/param norm = 1.9292e-01, time/batch = 16.3545s	
26175/33650 (epoch 38.893), train_loss = 0.86887640, grad/param norm = 1.8810e-01, time/batch = 18.7163s	
26176/33650 (epoch 38.895), train_loss = 0.93576483, grad/param norm = 1.7301e-01, time/batch = 18.4675s	
26177/33650 (epoch 38.896), train_loss = 0.77231828, grad/param norm = 1.6032e-01, time/batch = 14.1323s	
26178/33650 (epoch 38.897), train_loss = 0.71281239, grad/param norm = 1.7785e-01, time/batch = 14.0607s	
26179/33650 (epoch 38.899), train_loss = 0.75919690, grad/param norm = 1.5945e-01, time/batch = 13.6569s	
26180/33650 (epoch 38.900), train_loss = 0.71958550, grad/param norm = 1.5380e-01, time/batch = 16.1494s	
26181/33650 (epoch 38.902), train_loss = 0.79337184, grad/param norm = 1.6512e-01, time/batch = 17.7197s	
26182/33650 (epoch 38.903), train_loss = 0.79888996, grad/param norm = 1.9280e-01, time/batch = 18.3946s	
26183/33650 (epoch 38.905), train_loss = 0.93168995, grad/param norm = 1.8950e-01, time/batch = 18.1421s	
26184/33650 (epoch 38.906), train_loss = 0.77920956, grad/param norm = 1.6448e-01, time/batch = 17.8087s	
26185/33650 (epoch 38.908), train_loss = 0.80589690, grad/param norm = 1.5602e-01, time/batch = 17.7868s	
26186/33650 (epoch 38.909), train_loss = 0.78348090, grad/param norm = 1.5455e-01, time/batch = 17.6959s	
26187/33650 (epoch 38.911), train_loss = 0.71236119, grad/param norm = 1.5048e-01, time/batch = 18.5502s	
26188/33650 (epoch 38.912), train_loss = 0.64641714, grad/param norm = 1.5089e-01, time/batch = 15.7148s	
26189/33650 (epoch 38.914), train_loss = 0.84113181, grad/param norm = 1.5473e-01, time/batch = 18.0522s	
26190/33650 (epoch 38.915), train_loss = 0.77922124, grad/param norm = 1.8869e-01, time/batch = 18.7249s	
26191/33650 (epoch 38.917), train_loss = 0.78494943, grad/param norm = 1.6916e-01, time/batch = 17.3888s	
26192/33650 (epoch 38.918), train_loss = 0.75426583, grad/param norm = 1.6406e-01, time/batch = 17.8989s	
26193/33650 (epoch 38.920), train_loss = 0.73547615, grad/param norm = 1.4679e-01, time/batch = 18.6433s	
26194/33650 (epoch 38.921), train_loss = 0.73645912, grad/param norm = 1.5752e-01, time/batch = 17.3000s	
26195/33650 (epoch 38.923), train_loss = 0.65716331, grad/param norm = 1.5533e-01, time/batch = 15.6110s	
26196/33650 (epoch 38.924), train_loss = 0.84715080, grad/param norm = 1.7151e-01, time/batch = 18.3798s	
26197/33650 (epoch 38.926), train_loss = 0.76973594, grad/param norm = 1.6369e-01, time/batch = 18.5450s	
26198/33650 (epoch 38.927), train_loss = 0.80040821, grad/param norm = 1.6954e-01, time/batch = 17.3905s	
26199/33650 (epoch 38.929), train_loss = 0.89264694, grad/param norm = 1.9085e-01, time/batch = 18.1309s	
26200/33650 (epoch 38.930), train_loss = 0.80913286, grad/param norm = 1.7681e-01, time/batch = 18.6490s	
26201/33650 (epoch 38.932), train_loss = 0.81743032, grad/param norm = 1.5682e-01, time/batch = 17.6365s	
26202/33650 (epoch 38.933), train_loss = 0.67904532, grad/param norm = 1.6028e-01, time/batch = 16.8878s	
26203/33650 (epoch 38.935), train_loss = 0.68633109, grad/param norm = 1.6641e-01, time/batch = 18.3236s	
26204/33650 (epoch 38.936), train_loss = 0.73044623, grad/param norm = 1.4125e-01, time/batch = 17.3685s	
26205/33650 (epoch 38.938), train_loss = 0.69095599, grad/param norm = 1.4073e-01, time/batch = 16.1612s	
26206/33650 (epoch 38.939), train_loss = 0.86684256, grad/param norm = 1.4640e-01, time/batch = 17.0015s	
26207/33650 (epoch 38.941), train_loss = 0.80672461, grad/param norm = 1.5710e-01, time/batch = 18.4716s	
26208/33650 (epoch 38.942), train_loss = 0.87459154, grad/param norm = 1.8366e-01, time/batch = 17.8138s	
26209/33650 (epoch 38.944), train_loss = 0.78710974, grad/param norm = 1.7510e-01, time/batch = 26.1033s	
26210/33650 (epoch 38.945), train_loss = 0.81214358, grad/param norm = 1.6143e-01, time/batch = 36.3375s	
26211/33650 (epoch 38.947), train_loss = 0.93880278, grad/param norm = 2.6938e-01, time/batch = 33.5879s	
26212/33650 (epoch 38.948), train_loss = 0.92131254, grad/param norm = 1.5421e-01, time/batch = 36.8216s	
26213/33650 (epoch 38.949), train_loss = 0.70223837, grad/param norm = 1.6568e-01, time/batch = 39.6607s	
26214/33650 (epoch 38.951), train_loss = 0.96358285, grad/param norm = 1.7429e-01, time/batch = 33.3474s	
26215/33650 (epoch 38.952), train_loss = 0.86096950, grad/param norm = 1.6483e-01, time/batch = 36.4030s	
26216/33650 (epoch 38.954), train_loss = 0.83421980, grad/param norm = 1.4939e-01, time/batch = 36.7474s	
26217/33650 (epoch 38.955), train_loss = 0.82472214, grad/param norm = 1.6368e-01, time/batch = 39.5669s	
26218/33650 (epoch 38.957), train_loss = 0.87977021, grad/param norm = 1.8824e-01, time/batch = 38.1730s	
26219/33650 (epoch 38.958), train_loss = 0.64779235, grad/param norm = 1.3138e-01, time/batch = 36.1048s	
26220/33650 (epoch 38.960), train_loss = 0.66374859, grad/param norm = 1.6138e-01, time/batch = 22.9783s	
26221/33650 (epoch 38.961), train_loss = 0.72221183, grad/param norm = 1.5773e-01, time/batch = 18.5553s	
26222/33650 (epoch 38.963), train_loss = 0.73857421, grad/param norm = 1.8836e-01, time/batch = 18.1365s	
26223/33650 (epoch 38.964), train_loss = 0.89558540, grad/param norm = 1.7113e-01, time/batch = 17.7068s	
26224/33650 (epoch 38.966), train_loss = 0.83821519, grad/param norm = 1.5778e-01, time/batch = 17.5371s	
26225/33650 (epoch 38.967), train_loss = 0.84584057, grad/param norm = 1.7043e-01, time/batch = 18.6501s	
26226/33650 (epoch 38.969), train_loss = 0.79874654, grad/param norm = 1.4996e-01, time/batch = 18.0566s	
26227/33650 (epoch 38.970), train_loss = 0.81938322, grad/param norm = 1.6717e-01, time/batch = 17.4029s	
26228/33650 (epoch 38.972), train_loss = 1.08105808, grad/param norm = 1.8571e-01, time/batch = 17.6499s	
26229/33650 (epoch 38.973), train_loss = 0.75666287, grad/param norm = 1.5184e-01, time/batch = 17.3814s	
26230/33650 (epoch 38.975), train_loss = 0.73165035, grad/param norm = 1.5756e-01, time/batch = 17.6530s	
26231/33650 (epoch 38.976), train_loss = 0.75056247, grad/param norm = 1.4405e-01, time/batch = 17.0586s	
26232/33650 (epoch 38.978), train_loss = 0.75683578, grad/param norm = 1.6622e-01, time/batch = 18.2413s	
26233/33650 (epoch 38.979), train_loss = 0.81019701, grad/param norm = 1.9579e-01, time/batch = 18.6464s	
26234/33650 (epoch 38.981), train_loss = 0.79674729, grad/param norm = 1.4721e-01, time/batch = 16.8921s	
26235/33650 (epoch 38.982), train_loss = 0.81168638, grad/param norm = 1.6214e-01, time/batch = 17.8972s	
26236/33650 (epoch 38.984), train_loss = 0.67941022, grad/param norm = 1.8875e-01, time/batch = 17.2229s	
26237/33650 (epoch 38.985), train_loss = 0.71009381, grad/param norm = 1.4713e-01, time/batch = 16.7942s	
26238/33650 (epoch 38.987), train_loss = 0.82804987, grad/param norm = 1.5670e-01, time/batch = 18.6499s	
26239/33650 (epoch 38.988), train_loss = 0.75955879, grad/param norm = 1.7127e-01, time/batch = 17.7306s	
26240/33650 (epoch 38.990), train_loss = 0.95543981, grad/param norm = 2.0019e-01, time/batch = 17.8864s	
26241/33650 (epoch 38.991), train_loss = 0.82059154, grad/param norm = 1.8009e-01, time/batch = 16.5482s	
26242/33650 (epoch 38.993), train_loss = 0.83353518, grad/param norm = 1.8343e-01, time/batch = 18.4780s	
26243/33650 (epoch 38.994), train_loss = 0.83018340, grad/param norm = 1.5317e-01, time/batch = 18.8104s	
26244/33650 (epoch 38.996), train_loss = 0.81450505, grad/param norm = 2.0649e-01, time/batch = 16.1936s	
26245/33650 (epoch 38.997), train_loss = 0.90129690, grad/param norm = 2.0158e-01, time/batch = 17.9878s	
26246/33650 (epoch 38.999), train_loss = 0.73492341, grad/param norm = 1.4894e-01, time/batch = 17.4069s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
26247/33650 (epoch 39.000), train_loss = 0.90966382, grad/param norm = 1.8439e-01, time/batch = 17.2397s	
26248/33650 (epoch 39.001), train_loss = 0.94244206, grad/param norm = 1.6786e-01, time/batch = 17.2282s	
26249/33650 (epoch 39.003), train_loss = 0.92279605, grad/param norm = 1.9124e-01, time/batch = 18.5666s	
26250/33650 (epoch 39.004), train_loss = 0.84708322, grad/param norm = 1.7163e-01, time/batch = 17.7383s	
26251/33650 (epoch 39.006), train_loss = 0.81777900, grad/param norm = 2.0071e-01, time/batch = 17.9596s	
26252/33650 (epoch 39.007), train_loss = 0.85158219, grad/param norm = 1.7835e-01, time/batch = 18.8099s	
26253/33650 (epoch 39.009), train_loss = 0.75062046, grad/param norm = 1.8022e-01, time/batch = 18.0633s	
26254/33650 (epoch 39.010), train_loss = 0.91477399, grad/param norm = 1.8383e-01, time/batch = 17.0436s	
26255/33650 (epoch 39.012), train_loss = 0.78718291, grad/param norm = 1.5338e-01, time/batch = 18.1432s	
26256/33650 (epoch 39.013), train_loss = 0.81685503, grad/param norm = 1.9914e-01, time/batch = 18.5641s	
26257/33650 (epoch 39.015), train_loss = 0.80889375, grad/param norm = 1.6713e-01, time/batch = 17.0638s	
26258/33650 (epoch 39.016), train_loss = 0.74447179, grad/param norm = 1.8552e-01, time/batch = 17.3120s	
26259/33650 (epoch 39.018), train_loss = 0.79391436, grad/param norm = 2.1537e-01, time/batch = 18.0591s	
26260/33650 (epoch 39.019), train_loss = 0.77310915, grad/param norm = 1.9059e-01, time/batch = 16.3162s	
26261/33650 (epoch 39.021), train_loss = 0.86234825, grad/param norm = 1.7184e-01, time/batch = 17.1444s	
26262/33650 (epoch 39.022), train_loss = 0.80748776, grad/param norm = 1.9022e-01, time/batch = 18.2233s	
26263/33650 (epoch 39.024), train_loss = 0.75343262, grad/param norm = 1.7085e-01, time/batch = 18.1528s	
26264/33650 (epoch 39.025), train_loss = 0.83787334, grad/param norm = 1.8226e-01, time/batch = 17.0612s	
26265/33650 (epoch 39.027), train_loss = 0.84238023, grad/param norm = 2.0935e-01, time/batch = 18.4042s	
26266/33650 (epoch 39.028), train_loss = 0.87232575, grad/param norm = 1.7652e-01, time/batch = 18.9041s	
26267/33650 (epoch 39.030), train_loss = 0.80764491, grad/param norm = 1.9509e-01, time/batch = 17.6479s	
26268/33650 (epoch 39.031), train_loss = 0.75448708, grad/param norm = 1.4913e-01, time/batch = 18.0730s	
26269/33650 (epoch 39.033), train_loss = 0.84310266, grad/param norm = 1.5787e-01, time/batch = 18.9878s	
26270/33650 (epoch 39.034), train_loss = 0.86434008, grad/param norm = 1.7802e-01, time/batch = 16.9119s	
26271/33650 (epoch 39.036), train_loss = 0.91502617, grad/param norm = 1.8790e-01, time/batch = 17.8081s	
26272/33650 (epoch 39.037), train_loss = 0.77980028, grad/param norm = 1.4289e-01, time/batch = 18.2344s	
26273/33650 (epoch 39.039), train_loss = 0.91197831, grad/param norm = 1.8092e-01, time/batch = 18.0638s	
26274/33650 (epoch 39.040), train_loss = 0.99715935, grad/param norm = 1.9624e-01, time/batch = 16.1434s	
26275/33650 (epoch 39.042), train_loss = 0.97775480, grad/param norm = 2.0495e-01, time/batch = 17.8874s	
26276/33650 (epoch 39.043), train_loss = 0.78508839, grad/param norm = 1.7396e-01, time/batch = 18.6584s	
26277/33650 (epoch 39.045), train_loss = 0.76580283, grad/param norm = 1.7138e-01, time/batch = 16.8017s	
26278/33650 (epoch 39.046), train_loss = 0.89592475, grad/param norm = 2.1052e-01, time/batch = 16.8187s	
26279/33650 (epoch 39.048), train_loss = 0.90571738, grad/param norm = 1.6789e-01, time/batch = 17.9884s	
26280/33650 (epoch 39.049), train_loss = 0.77072917, grad/param norm = 1.7376e-01, time/batch = 17.1551s	
26281/33650 (epoch 39.051), train_loss = 0.96695515, grad/param norm = 2.4045e-01, time/batch = 17.6224s	
26282/33650 (epoch 39.052), train_loss = 0.93973946, grad/param norm = 1.7351e-01, time/batch = 18.4795s	
26283/33650 (epoch 39.053), train_loss = 0.89838771, grad/param norm = 1.9072e-01, time/batch = 18.2220s	
26284/33650 (epoch 39.055), train_loss = 0.79008922, grad/param norm = 1.7027e-01, time/batch = 17.7200s	
26285/33650 (epoch 39.056), train_loss = 0.72902568, grad/param norm = 1.3780e-01, time/batch = 17.6411s	
26286/33650 (epoch 39.058), train_loss = 0.91860912, grad/param norm = 2.0164e-01, time/batch = 18.0642s	
26287/33650 (epoch 39.059), train_loss = 0.92169617, grad/param norm = 1.7711e-01, time/batch = 17.1460s	
26288/33650 (epoch 39.061), train_loss = 0.91740618, grad/param norm = 1.9099e-01, time/batch = 17.6462s	
26289/33650 (epoch 39.062), train_loss = 0.88244915, grad/param norm = 1.6217e-01, time/batch = 19.0657s	
26290/33650 (epoch 39.064), train_loss = 0.82309909, grad/param norm = 1.5617e-01, time/batch = 18.4831s	
26291/33650 (epoch 39.065), train_loss = 0.80270861, grad/param norm = 2.1020e-01, time/batch = 16.7947s	
26292/33650 (epoch 39.067), train_loss = 0.76040977, grad/param norm = 1.4930e-01, time/batch = 16.6329s	
26293/33650 (epoch 39.068), train_loss = 0.83922444, grad/param norm = 1.6302e-01, time/batch = 16.9735s	
26294/33650 (epoch 39.070), train_loss = 0.88852848, grad/param norm = 1.6860e-01, time/batch = 17.1412s	
26295/33650 (epoch 39.071), train_loss = 0.78597934, grad/param norm = 1.6938e-01, time/batch = 17.9000s	
26296/33650 (epoch 39.073), train_loss = 0.85516526, grad/param norm = 1.8459e-01, time/batch = 18.5659s	
26297/33650 (epoch 39.074), train_loss = 0.95558770, grad/param norm = 1.5882e-01, time/batch = 18.8994s	
26298/33650 (epoch 39.076), train_loss = 0.90784763, grad/param norm = 2.1100e-01, time/batch = 18.3069s	
26299/33650 (epoch 39.077), train_loss = 0.81561713, grad/param norm = 1.5735e-01, time/batch = 18.4145s	
26300/33650 (epoch 39.079), train_loss = 0.87266708, grad/param norm = 1.7281e-01, time/batch = 16.8040s	
26301/33650 (epoch 39.080), train_loss = 0.85052363, grad/param norm = 1.6671e-01, time/batch = 16.4010s	
26302/33650 (epoch 39.082), train_loss = 0.85687053, grad/param norm = 1.7184e-01, time/batch = 17.6478s	
26303/33650 (epoch 39.083), train_loss = 0.85952541, grad/param norm = 1.8012e-01, time/batch = 17.5721s	
26304/33650 (epoch 39.085), train_loss = 0.91504186, grad/param norm = 1.7735e-01, time/batch = 16.7200s	
26305/33650 (epoch 39.086), train_loss = 0.86790524, grad/param norm = 2.0961e-01, time/batch = 18.2340s	
26306/33650 (epoch 39.088), train_loss = 0.81705033, grad/param norm = 2.1782e-01, time/batch = 17.5648s	
26307/33650 (epoch 39.089), train_loss = 0.77785653, grad/param norm = 2.0818e-01, time/batch = 15.9119s	
